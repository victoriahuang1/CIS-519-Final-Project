<doc id="2751" url="https://fr.wikipedia.org/wiki?curid=2751" title="Sahara">
Sahara

Le Sahara (en "", , "le grand désert" ou "la grande steppe," en berbère : ⵜⵉⵏⵉⵔⵉ "Tiniri") est un vaste désert chaud situé dans la partie nord du continent africain. Il s'étend sur d'ouest en est, de l'océan Atlantique à la mer Rouge, et couvre plus de 8,5 millions de kilomètres carrés, ce qui en fait la plus grande étendue de terre aride d'un seul tenant dans le monde.

Le Sahara peut être même prolongé pour certains au-delà de la mer Rouge, les géographes parlant alors d'un grand désert saharo-arabique. Plus largement encore, le Sahara constitue la partie occidentale d'une vaste diagonale sèche qui s'étend des abords du fleuve Sénégal jusqu'en Mongolie.

Considéré comme le plus vaste désert chaud du monde, il divise le continent d'est en ouest. Il couvre d'immenses étendues de territoires et s'étend sur le territoire de dix États : le Mali, la Mauritanie, le Niger, le Tchad, le Soudan, l'Algérie, la Tunisie, le Maroc, la Libye, et l'Égypte, ainsi que sur le territoire contesté du Sahara occidental.

Contrairement à une idée répandue qui imagine le Sahara comme une vaste plaine de sable, nue et monotone, le désert de sable ne couvre que 20 % de sa superficie, cette zone géographique comprenant une multitude de paysages, de climats, d'écorégions. La plupart des voyageurs connaissent les images des déserts de sable (Grand Erg oriental et Grand Erg occidental) mais négligent celles des montagnes (Hoggar, Tassili, Tibesti), des hamadas, des regs (Tanezrouft) et des régions couvertes d'immenses nappes de sable comme la Majabat al Koubra.

Le mot « Sahara » qui signifie « désert » en arabe désigne dans toutes les langues le grand désert africain. Avant l'arabisation de l'Afrique du Nord, le nom "Tiniri" (ou Ténéré) qui signifie « désert » en langue tamacheq, la langue tamazight des autochtones Berbères (Touaregs), a été attribué par eux à l'une des régions les plus arides de ce désert, d'ailleurs ce mot a été retrouvé dans la plupart des régions du nord pour désigner le grand Sahara (en Kabylie et au Rif). « Sahara » pourrait également provenir de l'addition des mots égyptiens « sah » (pays) et « ka » (hauteur, élévation, colline).

Ce grand désert est le plus vaste et le seul vrai désert au sens géographique du terme car il comporte des régions hyperarides (moins de de précipitations annuelles mais avec une extrême irrégularité interannuelle), arides (moins de de précipitations annuelles et une végétation concentrée dans les oueds), semi-arides et sub-humides sèches. La "diagonale sèche" dont il fait partie comprend également l'Arabie, le désert de Syrie (Syrie, Jordanie et Irak), le Dasht-e Kavir (Iran), le Dasht-e Lut (Iran), le Thar (Inde) et se poursuit par les déserts de latitude moyenne d'Asie centrale (le Karakoum, le Kyzyl Kum et en Chine le Taklamakan et le désert de Gobi).

Cette aridité s'explique par la privation des deux sources principales de précipitations : le front polaire et les courants équatoriaux d'ouest et elle conduit à des épisodes de sécheresse particulièrement importants en intensité et en durée.

Selon des critères climatiques, la limite septentrionale du Sahara est l'isohyète des (+ ou - ), correspondant plus ou moins à la limite , l'une des espèces les plus caractéristiques de la zone de transition Méditerranée/Sahara. La limite sud est plus floue, elle peut être située sur l'isohyète des , voire .

Selon des critères biogéographiques ou bioclimatiques, la limite au nord correspond à la limite eptentrionale de maturité des palmiers dattiers (notamment de la culture du Phoenix dactylifera) et à la limite méridionale de l’alfa). Au sud, elle correspond à la limite méridionale de had ('), ' et "Panicum turgidum" ou à la limite septentrionale de plusieurs espèces sahéliennes, notamment le cram-cram ("Cenchrus biflorus", Poaceae sahélienne) et, parmi les plantes ligneuses, "Commiphora africana" et "Boscia senegalensis". Toutefois le cram-cram est une espèce,annuelle à durée de vie brève, n'est généralement plus visible après quelques mois de saison sèche, et son abondance varie directement en fonction des précipitations. Elle est de surcroit véhiculée sous forme d'épillets munis de glumes à crochets redoutablement efficaces par les animaux d'élevages qui peuvent ainsi la transporter loin de son aire. Pour ces raisons, des auteurs ont proposé de déterminer la limite bio-climatique saharo-sahélienne à partir d'espèces arbustives qui intègrent les conditions pluviométriques tout au long de leur vie et sont aisément repérables : "Commiphora africana" se rencontre en abondance au Nord-Sahel. "Acacia senegal" (le gommier du Sénégal) et "Zyziphus mauritiana" ont la même répartition. Du côté saharien, s'observeront "Stipagrostis pungens", (arabe : "sbot" ou "Drinn"), puissante graminée pérenne, "Calligonum comosum" (arabe : "awarach") et "Zyziphus lotus" (arabe : "Sder").

Le Sahara est le plus grand désert chaud du monde. C'est un désert zonal caractéristique lié à la présence des "calmes subtropicaux". Il est situé au sud des latitudes des chevaux (entre 30º et 35º Nord et Sud) sous la crête subtropicale, une ceinture importante de hautes pressions subtropicales semi-permanentes à cœur chaud où l'air venu des niveaux supérieurs de la troposphère tend à s'abaisser vers le sol (subsidence). Le fort écoulement descendant de l'air produit un réchauffement et un assèchement relatif en haute troposphère. La subsidence empêche les ascendances de l'air et par conséquent annihile tout refroidissement adiabatique, ce qui rend la formation de nuages très difficile à quasiment impossible. La dissipation permanente de la couverture nuageuse permet un ensoleillement et une radiation thermique ininterrompue. La stabilité de l'atmosphère au-dessus du désert empêche les mouvements convectifs, rendant ainsi les précipitations très rares voire inexistantes. En conséquence, le ciel est le plus souvent clair, le temps est sec, stable, parfois avec une présence de sable dans l'atmosphère (couche d'air saharien) avec un risque minimal de pluie. Au désert, la température va de la glace à l'extrême chaud, le chaud l'emportant largement sur le froid. La routine climatique saharienne est celle de la chaleur et de la sécheresse. Néanmoins, le climat n'est pas uniforme sur les millions de km² qui constituent le Sahara. Il existe des différences essentielles entre les plaines et les montagnes, les centres et les marges (côté polaire et côté équatorial) et entre les régions côtières et continentales. Le Sahara a en plus de son immense étendue, et de son origine éloignée, un caractère propre très prononcé et aucun des autres déserts chauds ne peut lui être comparé ; sa situation géographique est d'ailleurs très intéressante et très curieuse. Le climat saharien est caractérisé par l'extrême faiblesse, la rareté ainsi que la grande irrégularité des précipitations, les très hautes températures de l'air et du sol au cours de l'année, l'exposition continue au rayonnement solaire, l'insolation exceptionnelle, l'hygrométrie moyenne très basse, la grande siccité de l'atmosphère en dehors des côtes, des contrastes thermiques (annuels et journaliers) accentués, une évaporation potentielle considérable, la plus forte de tous les déserts chauds du monde.

Les précipitations ne peuvent être que dérisoires au sein d'un air voué à la subsidence, qui de surcroît, est d'origine purement dynamique. Les masses d'air subsident, divergent et sec associées aux anticyclones dynamiques subtropicaux sont extrêmement défavorables au développement de précipitations. La circulation atmosphérique est l'élément majeur qui explique le climat désertique chaud (Classification de Köppen "BWh") de cette vaste région. L'aridité particulière du Sahara tient à la vigueur et surtout à la permanence des hautes pressions, même en été, jusqu'aux limites de la troposphère vers à d'altitude. Dans ces conditions, l'air surchauffé au sol ne peut s'élever ; il renforce l'anticyclone en se comprimant. L'affaissement de l'air est le plus fort et le plus efficace au-dessus du Sahara oriental, où l'absence de pluie est absolue, rivalisant avec le désert d'Atacama situé au Chili et au Pérou. L'inhibition pluviométrique ainsi que la dissolution des nuages sont par conséquent les plus accentuées sur la partie orientale qu'occidentale. L'aridité plus grande du Sahara oriental vient du fait qu'il se retrouve encore plus rarement sur la trajectoire des systèmes dépressionnaires chargés de pluie. 
C'est dans le plus grand désert chaud du monde que l'on trouve les pluies annuelles les plus faibles de la planète : par exemple, la moyenne annuelle est à peine de dans la région de Taoudeni (Mali), elle descend à à Tedjerhi au sud du Fezzan (Libye) et cette dernière devient nulle () à Louxor (Haute-Égypte). Ces moyennes n'ont d'ailleurs aucune signification car la variabilité interannuelle des précipitations peut être énorme mais presque partout, la sécheresse absolue est la règle. Plus la moyenne annuelle pluviométrique est faible, plus celle-ci est variable d'année en année. C'est encore vraisemblablement au Sahara que les périodes sans pluies sont les plus longues : à Koufra, il n'est pas tombé une seule goutte de pluie pendant huit ans; à In Salah, on a également enregistré sept années consécutives pendant lesquelles la pluie a totalement fait défaut; dix-sept années sur trente, Le Caire n'a reçu aucune pluie. 

Dans ces conditions, où la condensation de la vapeur d'eau contenue dans l'atmosphère saharienne ne peut s'effectuer normalement et donc donner des précipitations, excepté sur la côte atlantique saharienne où il se forme des brouillards et des nuages bas à cause du courant des Canaries, un courant océanique frais qui longe la côte, la nébulosité (fraction du ciel couvert par les nuages) est extrêmement faible. D'ailleurs, ce qui est le plus grand désert chaud du monde constitue une des régions du monde qui voit passer le moins de nuages dans le ciel, bien que les journées partiellement couvertes ne manquent pas, surtout au printemps et en automne. Cependant, celles-ci aussi sont rarissimes, surtout dans les zones les plus centrales. L'état normal du ciel du désert est l'absence de nuages ; le ciel est immuablement bleu, telle est la règle au Sahara, mais comme toutes les règles, elle souffre d'exceptions : les ciels clairs sont courants, cependant, même dans les régions centrales les plus accentuées du Sahara, le temps peut changer d'un jour à l'autre. Il arrive qu'en hiver ou qu'au printemps, la succession éternelle de journées au ciel clair soit de temps à autre entrecoupée par des journées au ciel désespérément couvert. Ainsi le ciel peut rester nuageux plusieurs jours consécutifs mais ce sont là des cas exceptionnels, et cette menace ne se traduit quasiment jamais par de la pluie. Dans le Sahara central, ce dernier étant particulièrement éloigné de tout système nuageux, les nuages de « corps » (présents dans le corps d'une perturbation) type cirrostratus sont rarissimes, alors que les nuages de « marge » type cirrus sont beaucoup plus fréquents, surtout à l'ouest, en hiver ou au printemps. Aussi existe-t-il un fort contraste entre les jours calmes et ceux où soufflent des vents qui peuvent être violents et provoquer des tempêtes de sable. De façon générale, les phénomènes violents ne sont pas rares au désert.

Si l'on définit un jour de ciel clair par un jour où la nébulosité moyenne est inférieure à deux dixièmes, on obtient un nombre annuel moyen de jours de ciel clair extrêmement élevé dans l'ensemble du Sahara : 280,3 jours à Ghat ; 286,6 jours à Tindouf ; 290,6 jours à Taoudenni ; 292,5 jours à Adrar ; 296,9 jours à In Salah ; 302,6 jours à Tajarhi ; 310,5 jours à Touzougou (latitude : 22.37°N, longitude : 19.53°E) ; 313,0 jours à Arlit ; 317,5 jours à Bilma ; 328,3 jours à Faya-Largeau ; 329,5 jours à Dongola ; 333,6 jours à Wadi Halfa ; 336,4 jours à Talha (latitude : 20.22°N, longitude : 21.28°E). Ces nombres de jours respectifs représentent près de 76,7 % de l'année ; 78,5 % de l'année ; 79,6 % de l'année ; 80,1 % de l'année ; 81,3 % de l'année ; 82,8 % de l'année ; 85,0 % de l'année ; 85,7 % de l'année ; 86,9 % de l'année ; 89,8 % de l'année ; 90,2 % de l'année ; 91,3 % de l'année ; 92,1 % de l'année. Ces chiffres sont sans doute les plus élevés du monde ou du moins parmi ceux-ci : le Sahara, particulièrement le Sahara oriental, est la contrée du globe ayant la plus grande fréquence de ciels clairs. Pour comparer, le nombre annuel moyen de jours de ciel clair est de 60,9 à Paris (16,7 % de l'année) ; 146,4 jours à Marseille (40,1 % de l'année) ; 272,6 jours à Yuma, Arizona (74,6 % de l'année), la ville la plus ensoleillée des États-Unis. <br>
Si l'on définit un jour de ciel couvert un jour où la nébulosité moyenne est supérieure à huit dixièmes, on obtient un nombre annuel moyen de jours de ciel couvert extrêmement faible dans l'ensemble du Sahara : 19,0 jours à Ghat ; 16,0 jours à Tindouf ; 17,5 jours à Taoudenni ; 15,7 jours à Adrar ; 16,1 jours à In Salah ; 14,8 jours à Tajarhi ; 8,2 jours à Touzougou ; 8,6 jours à Arlit ; 6,1 jours à Bilma ; 4,6 jours à Faya-Largeau ; 4,2 jours à Dongola ; 5,1 jours à Wadi Halfa ; 4,9 jours à Talha. Ces nombres de jours respectifs représentent près de 5,2 % de l'année ; 4,4 % de l'année ; 4,8 % de l'année ; 4,3 % de l'année ; 4,4 % de l'année ; 4,1 % de l'année ; 2,2 % de l'année ; 2,4 % de l'année ; 1,7 % de l'année ; 1,3 % de l'année ; 1,1 % de l'année ; 1,4 % de l'année ; 1,3 % de l'année. Ces chiffres sont sans doute les plus faibles du monde ou du moins parmi ceux-ci. Pour comparer, le nombre annuel moyen de jours de ciel couvert est de 131,3 à Paris (35,9 % de l'année) ; 69,8 à Marseille (19,1 % de l'année) ; 9,0 à Yuma (2,5 % de l'année). Dans les massifs montagneux du Sahara central, où les conditions climatiques extrêmes s'atténuent, les nombres respectifs de jours de ciel clair et de ciel couvert en utilisant les mêmes critères d'appartenance sont de : 241,7 jours (66,2 % de l'année) et 24,6 jours (6,7 % de l'année) à Tamanrasset, Algérie dans le Hoggar par d'altitude ; 256,0 jours (70,1 % de l'année) et 21,6 jours (5,9 % de l'année) à Djanet dans le Tassili n'Ajjer ; 310,8 jours (85,1 % de l'année) et 9,5 jours (2,6 % de l'année) à Aozou par d'altitude ainsi que 282,4 jours (77,3 % de l'année) et 10,2 (2,7 % de l'année) à Emi Koussi dans le Tibesti par d'altitude. <br>
Le très grand nombre de jours clairs au désert et le caractère exceptionnel des jours couverts traduisent l'importance que joue le système anticyclonique saharien et le régime des alizés continentaux qu'il engendre, ce qui limite fortement les mécanismes atmosphériques générateurs de nuages (et de précipitations). 
On constate également que la partie orientale reçoit généralement encore plus de jours de ciel clair et encore moins de jours de ciel couvert que la partie occidentale.
Au Sahara, on enregistre de façon courante une durée moyenne effective de l'insolation supérieure à 3.600 h par an, soit plus de 10 h par jour. Sur les 4.400 h annuels maximum théoriques, l'astre solaire brille pendant près de 3.978 h en moyenne à Adrar en Algérie, par exemple, soit près de 10 h 55 par jour (ou 90 % du temps). Le Sahara central constitue la zone la plus étendue du monde dans laquelle la barre mythique des 4.000 h par an est dépassée, ce qui équivaut à plus de 11 h par jour. Dans le Sahara oriental, cette durée effective frôle le maximum théorique, avec une valeur extrême approximative de 4.300 h par an, ce qui revient à près de 11 h 45 par jour. Le Soleil y est couvert par des nuages pendant moins de 100 h par an. Cette valeur-record a été enregistrée à Wadi Halfa, un village situé au niveau de la frontière soudano-égyptienne, qui semble être le point le plus ensoleillé du globe à l'année. Des valeurs analogues se rencontrent dans les régions alentours où le ciel est tout aussi, sinon encore plus, clair (ex : Assouan, Louxor, Koufra, Dongola, Faya-Largeau). De façon générale, c'est dans le carrefour frontalier Égypte - Soudan - Libye - Tchad que se trouvent les espaces les plus amplement exposés au rayonnement solaire. Pour comparer, le nombre annuel moyen d'heures ensoleillées est de 1.728 à Paris (39 % du temps). Les fractions d'ensoleillement sont toujours très élevées au Sahara : on enregistre par exemple 100 % en janvier à Khartoum (Soudan) et 100 % en juillet à Kharga (Haute-Égypte) où la nébulosité mensuelle correspondante est nulle. Sur l'année, les fractions s'établissent presque toujours entre 80 % et 98 % mais cette dernière descend en dessous à 65 - 75 % sur la fine côte atlantique saharienne, beaucoup plus nuageuse. Le grand désert africain s'impose comme la région du monde où le Soleil brille le plus souvent. La moyenne des maxima de durée d'insolation oscille entre les latitudes 17º en hiver (ex : Tombouctou, Khartoum, Agadez) et 27° en été (ex : Sebha, Kharga, In Salah).

Le régime anticyclonique permanent que connaît le Sahara maintient un ciel clair, le plus souvent sans aucun nuage, et un air très sec où les obstacles naturels opposés à la pénétration du rayonnement solaire tels que l'humidité et les nuages sont rares. La quantité moyenne annuelle de chaleur reçue au sol dépasse 200.000 cal/cm²/an dans les régions sahariennes centrales, de part et d'autre du tropique (très approximativement entre les latitudes 18° et 28°) et s'abaisse à 180.000 cal/cm²/an sur les marges septentrionale et méridionale du désert. Deux zones de maxima apparaissent, l'une assez restreinte sur le centre du Sahara occidental, axée sur le tropique, particulièrement dans le Tanezrouft et dans l'Erg Chech (Bou Bernous : 212.000 cal/cm²/an) et l'autre très étendue sur le centre du Sahara oriental où elles les valeurs dépassent 220.000 cal/cm²/an, qui recouvre notamment le désert de Nubie et le désert de Bayouda (Merowe : 226.000 cal/cm²/an). Cette région du grand désert africain représente certainement sur le globe le pôle absolu de chaleur, car c'est elle qui reçoit le plus d'énergie du Soleil. Cette énergie reçue est supérieure au double ce que reçoivent les pays tempérés, ce qui corrèle naturellement bien avec des températures au sol supérieures à 80 ºC. Pour comparer, cette valeur est de seulement 96.000 cal/cm²/an à Paris, et elle peut atteindre au maximum près de 120.000 cal/cm²/an dans les régions méditerranéennes les plus ensoleillées de France.

La masse d'air dominante stationnant sur le Sahara est de l'air tropical continental (cT), une masse d'air extrêmement chaud, sec. Ces masses d'air se forment principalement au-dessus du désert nord-africain à cause de l'échauffement maximal de ces vastes terres continentales arides. Le Sahara représente le modèle des déserts chauds de la planète. Dans les hauts massifs sahariens (Hoggar, Tibesti), des nuances climatiques apparaissent cependant avec l'élévation du sol ; la nébulosité et les précipitations moyennes en termes de fréquence et aussi d'intensité augmentent car l'altitude favorise les ascendances de l'air, le refroidissement adiabatique et donc la condensation de la vapeur d'eau contenue dans l'atmosphère, ce qui contrarie occasionnellement le dispositif atmosphérique stable (hautes pressions) qui impose une aridité absolue au Sahara. De plus, les températures maximales demeurent atténuées et les températures minimales sont accentuées. Si le Sahara est le plus grand désert chaud du monde, c'est aussi le désert le plus absolu : une sécheresse comparable à celle du Sahara ne se voit qu'au nord du Chili, mais sur une étendue infiniment moindre ; partout ailleurs les déserts sont bien plus « pluvieux ». Des rayons solaires faisant avec l’horizontale un angle toujours fort, un trajet atmosphérique de ces rayons plus réduit qu’à de plus hautes latitudes et une très faible nébulosité font que, nuit et jour confondus, les températures moyennes annuelles atteignent un niveau très élevé y compris dans les régions les plus septentrionales (22,7 ºC à Ghardaia par 32° de latitude et à 489 m d'altitude ; 23,8 ºC à Ouargla par 31° de latitude et à 219 m d'altitude ; 22,9 ºC au Caire par 30° de latitude et à 64 m d'altitude pour la lisière nord du désert).

Le Sahara est une des régions les plus chaudes de la Terre, sinon la plus chaude. L'équateur thermique, ligne imaginaire passant par l'ensemble des endroits possédant la température moyenne annuelle la plus élevée (soit plus ou moins 30 ºC) à chaque longitude autour du globe, passe dans le Sahara méridional, au nord du Sahel septentrional. L'été saharien, torride, est long ou très long ; au sud, il dure d'avril à octobre inclus ; cependant des irrégularités de températures subsistent : à latitude et altitude similaires, le Sahara occidental est nettement plus chaud en période estivale que son homologue oriental et ceci est vrai particulièrement pour la partie septentrionale du désert. Cette irrégularité de température s'explique par l'influence rafraîchissante des vents étésiens qui soufflent dans l'ensemble du bassin de la Méditerranée orientale sans l'interposition d'une barrière montagneuse, et qui atténuent considérablement l'échauffement de cette partie du désert et donc les maxima de températures. Or, c'est logiquement le contraire qui devrait se produire (chaleur plus accentuée dans le Sahara oriental que chez son homologue occidental) puisque l'on sait que l'irradiation solaire est encore plus forte dans l'est que dans l'ouest. Partout au Sahara, à altitude raisonnable, la moyenne des maxima du mois le plus chaud dépasse 38 ºC, excepté dans la région du Caire en Égypte qui se situe au plus près de la mer Méditerranée où celle-ci descend légèrement plus bas, mais cette moyenne atteint des valeurs bien plus élevées dans la presque totalité du désert avec un maximum (mondial) de 47,5 - 48 ºC en juillet dans l'ensemble de la région de Taoudenni malgré les 250 - d'altitude. Il y a même une région située presque exactement au centre géographique du Sahara algérien, baptisée le « triangle de feu », délimitée par Adrar - Reggane - In Salah, trois villes sahariennes réputées parmi les plus infernales du monde pendant la longue période estivale : leurs moyennes journalières respectives de juillet s'établissent à 37,8 ºC (maxima : 46,3 ºC ; minima : 29,2 ºC); 39,8 ºC (maxima : 46,8 ºC ; minima : 32,8 ºC); 38,6 ºC (maxima : 46,4 ºC ; minima : 30,7 ºC) et leurs altitudes se situent entre 200 et 300 m. On y enregistre régulièrement des températures de plus de 50 ºC dans la zone, notamment dans la région d'In Salah. Dans la station météorologique d'Arak (Miniet) à 945 m d'altitude presque à mi-distance entre In Salah et Tamanrasset, la moyenne journalière dépasse 37 ºC pendant les trois mois d'été, juin - juillet - août, ce qui est assurément extraordinaire. Les valeurs pour la station de Reggane et d'Arak (Miniet) ont été calculées sur une courte période de seulement six-sept années d'observation, ces chiffres sont donc à prendre avec prudence. Tata, par près de 700 m d'altitude moyenne et ville réputée la plus chaude du Maroc, connaît des températures maximales moyennes de 45 °C en juillet.

Toute station saharienne au-dessous de 800 m d'altitude peut voir la colonne du mercure dépasser 50 ºC. Les étés les plus chauds se rencontrent dans les basses vallées et dépressions du Sahara central, particulièrement sur le flanc occidental de ce dernier, dans le sud de l'Algérie (Tidikelt, Tanezrouft) ainsi que dans le nord du Mali et de la Mauritanie (El Djouf, El Hank) où les maximales moyennes sont extrêmement élevées de juin à août (45 - 48 ºC). L'Erg Chech, au nord du Tanezrouft représente un îlot de chaleur avec des températures moyennes journalières de juillet, assurément jour et nuit confondus, supérieures à 40 ºC et est aussi l'une des régions les plus chaudes et les plus arides du monde en été. Pour ces raisons, d'ailleurs, il n'y a pas de mesures de températures sur ce vaste territoire, le terrain, le climat et le manque total d'eau interdisant une occupation permanente. Plus encore que ces chiffres exceptionnellement élevés, c'est surtout la durée des fortes chaleurs, la longueur des étés qui croît, grossièrement, du nord au sud qui fait aussi la dureté du climat saharien : la moyenne des maxima diurnes peut dépasser 40 ºC pendant cinq à sept mois consécutifs dans le Sahara méridional et dans le sud du Sahara central, comme c'est le cas à Bilma ( d'altitude) dans le Ténéré au Niger, à Faya-Largeau ( d'altitude) dans le Borkou au Tchad, à Atbara ( d'altitude) dans le Nil au Soudan ou à Araouane ( d'altitude) dans l'Azawad au Mali, par exemple. Les moyennes des maxima du mois le plus chaud de l'ensemble de ces lieux (soit le mois de juin) culminent facilement à 44 - 45 ºC ; À Araouane, il fait en moyenne près de 46 ºC au plus chaud du jour en juin. Aussi à Bilma, la température maximale du jour tombe rarement en dessous de 45 ºC en juin. Dans le Sahara libyen, on enregistre des valeurs de cet ordre : 39,6 °C à Sebha ; 41,9 °C à Ubari ; 42,4 °C à Mourzouk ; 43,6 °C à Al Qatrun au mois de juillet pour des altitudes comprises entre 400 et 500 m. Cette chaleur accumulée ne tient compte que de la fréquence et de l'intensité de la radiation solaire, or l'apport de chaleur solaire étant maximal dans le grand désert africain, ce dernier ne peut qu'être surchauffé une bonne partie de l'année. Si l'été est partout marqué par sa chaleur excessive, la durée et la douceur de l'hiver dépend presque exclusivement de la latitude du lieu : il est tempéré sur la marge septentrionale du désert (ex : Biskra, Ghardaia, Touggourt, Waddan, Le Caire) ; tempéré chaud dans les régions centrales au nord du tropique (ex : Adrar, In Salah, Mourzouk, Koufra, Assouan, Louxor) ; chaud quasiment partout au sud du tropique (ex : Dongola, Atar, Tessalit, Bilma, Faya-Largeau). Même en massif montagneux, l'hiver ne devient vraiment frais qu'à partir de 1.600 - 1.800 m d'altitude, il devient froid à Assekrem, par 2.200 m d'élévation.

Il n'en demeure pas moins qu'une certaine fraîcheur règne en hiver, dans le Sahara septentrional à proximité des climats méditerranéens, et cette fraîcheur peut même se répandre jusqu'au nord du Sahara central, mais très rarement : les journées hivernales douces, réchauffées par le soleil succèdent à des nuits parfois glaciales. Le gel nocturne n'est pas inconnu dans cette partie du désert, mais il est totalement inexistant dans le Sahara méridional et dans le sud du Sahara central, excepté dans le Ténéré. Cette faiblesse des températures hivernales dans le nord résulte avant tout de l'ampleur des pertes radiatives au désert, et non d'une advection d'air plus froid venu des latitudes plus élevées. Si les journées hivernales sont le plus souvent juste chaudes, elles peuvent être tout aussi brûlantes que les journées estivales : dans le désert de l'Ennedi au nord-est du Tchad, on a relevé une température maximale diurne supérieure à 45 ºC en ce début février 2015, ce qui serait probablement un record saisonnier dans la région. Cette température, ainsi que toutes celles que nous citons, sont prises « sous abri », donc à l'ombre. Au centre et au sud saharien, le climat est particulièrement torride sur l'ensemble de l'année car il ne connaît plus de réel rafraîchissement hivernal. En résumé, au Sahara, il peut faire froid en hiver, la nuit et au lever du soleil, surtout en haute montagne, mais il fait toujours très chaud en été car non seulement les journées sont brûlantes mais les nuits sont chaudes et même très chaudes dans certains secteurs, ce qui pourra en surprendre plus d'un. La célèbre idée reçue : « Dans le désert (et l'on pense évidemment au Sahara), il fait très chaud le jour et très froid la nuit » est un mythe, ou plutôt un ressenti qui s'explique à cause des températures extrêmes subies dans la journée, car une nuit froide au cours de laquelle le thermomètre descendra au-dessous de 0 ºC au Sahara ne sera jamais suivie d'une journée torride, au cours de laquelle le mercure dépassera les 50 ºC 

Les températures moyennes journalières (jour et nuit confondus) officielles de janvier, toujours le mois le plus frais au Sahara, sont par pour l'Algérie de : 12,2 °C à Timimoun (maxima : 19,3 °C ; minima : 5,2 °C) ; 13,5 °C à Adrar (maxima : 21,3 °C ; minima : 5,7 °C) ; 14,0 °C à Tindouf (maxima : 21,1 °C ; minima : 6,9 °C) ; 14,7 °C à In Salah (maxima : 22,2 °C ; minima : 7,2 °C) ; 16,0 °C à Reggane (maxima : 22,6 °C ; minima : 9,4 °C) - pour la Libye de : 12,8 °C à Houn (maxima : 19,4 °C ; minima : 6,1 °C) ; 12,8 °C à Mourzouk (maxima : 20,3 °C ; minima : 5,3 °C) ; 13,3 °C à Ubari (maxima : 21,2 °C ; minima : 5,4 °C) ; 14.1 °C à Koufra (maxima : 20,6 °C ; minima : 7,6 °C) ; 14,3 °C à Jalo (maxima : 20,4 °C ; minima : 8,0 °C) - pour l'Égypte : 12,7 °C à Al-Farafra (maxima : 20,5 °C ; minima : 4,9 °C) ; 13,1 °C à Assiout (maxima : 20,3 °C ; minima : 5,9 °C) ; 13,4 °C à Siwa (maxima : 20,3 °C ; minima : 6,6 °C) ; 15,3 °C à Louxor (maxima : 23,2 °C ; minima : 7,4 °C) ; 17,0 à Assouan (maxima : 23,6 °C ; minima : 10,2 °C). Ces valeurs pour la moitié septentrionale du désert restent relativement élevées, surtout les maxima diurnes, qui comme on le voit, restent chauds dans la plupart des cas et peinent à descendre sous la barre des 20 °C. Néanmoins, les minima nocturnes tournent souvent autour de 5 °C, et contribuent essentiellement à l'abaissement généralisée des moyennes journalières de janvier. Dans la moitié méridionale saharienne, ces valeurs, tant celles des journées que des nuits, sont bien plus élevées et très souvent les maxima moyens atteignent 27 - 30 °C ou même plus, alors que les minima descendent rarement en dessous de 15 °C. On constate également que l'élévation du sol garde, certes une influence sur les températures, mais celle-ci reste moins marquées pour les températures de l'hiver par rapport aux températures de l'été : la moyenne journalière de janvier à Tamanrasset par 1.400 m d'élévation est de 13,0 °C (maxima : 20,7 °C ; minima : 5,4 °C). 

En été, les moyennes des minima nocturnes sont toujours supérieures à 20 ºC sur l'ensemble du Sahara, et dans l'immense majorité, celles-ci se situent entre 25 ºC et 30 ºC. Dans les espaces sahariens qui se rafraîchissent le moins durant la nuit, elles dépassent 30 ºC ce qui veut bien dire qu'en moyenne, le thermomètre ne descend pas en dessous de ce seuil au plus « froid » de la nuit. Au sud-est du Tanezrouft, à Bordj Badji Mokhtar ( d'altitude), un village situé le long de la frontière algéro-malienne, la moyenne des minima nocturnes dépasse 20 ºC pendant sept mois consécutifs, d'avril à octobre, inclusivement et celle-ci excède 25 ºC pendant cinq mois consécutifs, de mai à septembre, inclusivement. La moyenne annuelle y est particulièrement élevée avec 29,2 ºC (38,3 ºC de maxima moyen ; 20,1 ºC de minima moyen). De plus, les amplitudes thermiques journalières (entre le jour et la nuit) moyennes sur l'année se situent généralement entre 15 ºC et 20 ºC au Sahara (excepté dans le Sahara atlantique où celles-ci sont bien inférieures). Ces écarts ne sont pas supérieurs à ceux de certaines régions de France. 

La caractéristique essentielle du climat du désert nord-africain est la très grande sécheresse de l'air ou plus exactement, l'énorme déficit de saturation de celle-ci. Il est dû à la forte disproportion qui s'établit entre la quantité de vapeur d'eau existant réellement dans l'atmosphère saharienne et celle que cette dernière serait susceptible de contenir à la limite de saturation étant donné sa très haute température. Le déficit de saturation explique le pouvoir évaporant de l'air considérable qui est maximal au Sahara, et ce à n'importe quelle période de l'année, de jour comme de nuit. La chaleur torride est toujours très sèche au Sahara, même au sud où la mousson abaisse occasionnellement plus ou moins les maximas diurnes tout en augmentant ou du moins en stabilisant les minimas nocturnes en augmentant plus ou moins le degré hygrométrique de l'air en juillet - août; ainsi son premier effet est de diminuer l'amplitude thermique diurne. C'est également la raison pour laquelle la chaleur des régions sahariennes est plus facilement supportable que celle des régions équatoriales, parce que l'air est très sec. Le grand désert africain est rendu particulièrement chaud par suite de sa position et de sa masse, avec une très faible nébulosité et, donc naturellement, une très grande durée de l'insolation, une forte radiation solaire directe et globale, mais aussi une radiation réfléchie par la terre et un important rayonnement obscur du sol en été.

L'absence de précipitations dans le désert n'est pas la conséquence d'une absence d'humidité atmosphérique mais d'une absence de mécanismes générateurs de pluie. Le domaine saharien et ses marges sont classés dans les climats chauds. Le balancement saisonnier de la ceinture anticyclonique engendre les divers types de temps rencontrés dans le grand désert africain. Au Sahara, nous avons toujours deux éléments permanents : l'anticyclone saharien ainsi que l'anticyclone atlantique nord (communément appelé Anticyclone des Açores), auxquels s'ajoutent un certain nombre d'éléments transitoires d'importance toujours faible et limitée dans le temps qui sont les dépressions (zones de basse pression), telles que les dépressions européennes, méditerranéennes, eurafricaines, soudanaises. Ces dernières ne sont responsables que de certaines séquences de nébulosité (passages nuageux), aussi peu effectives qu'éphémères. Le type de temps est toujours anticyclonique et sans perturbation, le plus souvent dans les marges et dans les régions montagneuses du désert mais presque en permanence dans les régions centrales où le beau temps est absolu et ne cesse quasiment jamais. En extrême périphérie méridionale du désert, au niveau de la zone climatique saharo-sahélienne également appelée sahélo-saharienne où les précipitations annuelles moyennes sont comprises entre et , la remontée latitudinaire de la zone de convergence intertropicale en été peut donner des averses brèves mais très irrégulières, comme c'est le cas à Tombouctou (Mali) entre juillet et septembre, inclusivement, où tombe l'immense majorité des faibles précipitations annuelles moyennes; dans ce cas ci, les hautes pressions ont totalement disparu de la haute troposphère car elles ont migré vers des latitudes plus septentrionales. Si la ceinture anticyclonique est toujours présente au-dessus du Sahara, elle est relativement peu épaisse en hiver sur le Sahara septentrional ou bien rejetée en altitude dans le Sahara méridional à cause de la dépression thermique qui se forme dans les basses couches de l'atmosphère en été. La pluviogenèse requiert toutefois l'intervention de processus atmosphériques extérieurs suffisamment puissants pour annuler de façon très temporaire le caractère stérilisant des structures aérologiques saisonnières, en raison de la grande vigueur des facteur contrariants. 

Sur les 9 000 000 de km² de désert au Sahara, une superficie d'environ (31 % de la superficie totale) reçoit des précipitations moyennes annuelles inférieures ou égales à alors que près de (17 % de la superficie totale) reçoivent ou moins par an. La quantité annuelle moyenne de pluie est théoriquement de sur plus de (11 % de la superficie totale) au Sahara oriental en Libye, en Égypte et au Soudan où la moyenne calculée à long-terme approche par an. L'aridité extrême des régions sahariennes ne tient pas seulement à l'excessive faiblesse des précipitations. En effet, à moyenne égale de précipitations annuelle, l'aridité sera d'autant plus forte que les températures et l'évaporation potentielle seront élevées. Malgré la chaleur suffocante qui règne au Sahara en été (les nuits hivernales peuvent être froides dans le nord, notamment dans les massifs montagneux), le climat est en général sain grâce à la sécheresse de l'air. D'après les différentes études sur le climat du grand désert africain, le minimum pluviométrique est atteint au Sahara oriental alors que le maximum thermique est atteint au Sahara occidental. Effectivement, à altitude égale, les déserts de Libye et d'Égypte sont relativement moins brûlants que les déserts d'Algérie et du Maroc. Un célèbre géographe allemand, Carl Ritter, se plaisait à répéter que le Sahara est le « Sud du monde ». Cette réflexion en apparence paradoxale signifie que c'est la région la plus aride et la plus chaude de la Terre. Le température moyenne annuelle du désert nord-africain, ramenée au niveau de la mer, est supérieure à celle de tous les autres déserts. De plus, le grand désert africain est la région du monde où le thermomètre monte le plus haut le plus souvent. 

Le Sahara est, plus encore que l'Arabie, que le Sindh (Pakistan), que le désert des Mojaves (États-Unis) et que le bassin intérieur australien, l'endroit le plus chaud du globe. Le climat saharien est un climat extrême en tous points : par exemple, Assouan ( d'altitude), grande ville de la Haute-Égypte bénéficie d'un climat torride et extrêmement aride; une température moyenne annuelle très élevée de (34,3 ºC de maxima moyen ; 19,9 ºC de minima moyen); des précipitations moyennes nulles avec à peine par an (un minimum mondial); une durée moyenne de l'insolation largement supérieure à 4.000 h par an; une radiation solaire globale reçue parmi les plus intenses du globe avec 220 kcal/cm²/an (une des valeurs les plus élevées du monde); une sécheresse de l'air très accentuée avec une humidité relative moyenne annuelle de 26 %; une évaporation potentielle supérieure à par an, soit près de évaporés par jour. 

La température maximale du Sahara est de +55°C

Le Sahara est une région aride de faible pluviométrie. Une région est dite aride lorsque les précipitations sont inférieures à l'évapotranspiration potentielle.

Le désert du Sahara constitue une écorégion terrestre, selon la classification du Fonds mondial pour la nature (WWF), appartenant au biome des déserts et brousses xériques de l'écozone paléarctique. Elle comprend la partie hyper-aride du Sahara central, où les précipitations sont minimes et sporadiques, et exclut ses marges méridionales et septentrionales, plus humides. Bien que la biodiversité et l'endémisme y soient relativement faibles, la région abrite néanmoins une faune hautement adaptée aux conditions très particulières de végétation et de température qui y règnent.

Le Sahara central abrite, selon les estimations, cinq-cents espèces de plantes, ce qui est extrêmement bas comparé à la superficie sur laquelle elles poussent. Les plantes telles que les arbres d'acacia, les palmiers et les herbes se sont adaptées aux conditions arides.

Les montagnes Hoggar (Algérie), Monts de l'Aïr (Niger), Djebel Marra (Soudan) abritent l'olivier de Laperrine.

Le désert s'anime la nuit. Là, au milieu des dunes et des rochers, une vie en majorité minuscule — elle appartient surtout au monde des insectes — sort de sa torpeur. Chacun cherche alors à se nourrir. Car si la majorité des espèces animales des espaces désertiques n'ont pas besoin de boire pour survivre, ils doivent absolument récupérer le précieux liquide dans la chair de leur proie.

Les dromadaires et chèvres sont des animaux domestiqués par l'homme. Les camélidés ont toujours été des animaux domestiqués par les nomades, en raison de leurs qualités bien connues de sobriété, d'endurance et de rapidité. Diverses espèces de scorpions jaunes le plus souvent, mais aussi noirs, et de tailles diverses. "Androctonus amoreuxi" est l'un des plus courants, son venin n'est pas des plus actifs. Il n'est sans doute pas dangereux pour l'Homme. Bien d'autres espèces présentes au Sahara ne sont également pas potentiellement létales. "Androctonus australis" qui lui ressemble, mais avec une queue bien plus large, peut atteindre comme le précédent près de 12 cm de long et son venin est des plus dangereux. Notamment pour les petits enfants et les personnes âgées. Le Varan du désert ou Varan gris ("Varanus griseus") est une espèce vulnérable et en danger d'extinction. À ce titre, il est classé en Annexe 1 de la Convention de Washington. La vipère des sables ("Cerastes vipera") dotée d'une tête plate et quelque-peu triangulaire, s'enfouit pour se protéger, ainsi que pour chasser, dans le sable grâce à des mouvements giratoires du tronc. La vipère à cornes ("Cerastes cerastes") lui est proche, mais elle est moins inféodée au sable. Le fennec appelé aussi "renard des sables" est rencontré un peu partout dans le Sahara. Le fennec passe la journée à l'abri dans son terrier. La nuit, il chasse des insectes et des rongeurs. Son ouïe extrêmement développée lui permet de localiser ses proies rapidement, grâce à ses oreilles disproportionnées.

On rencontre également de belles antilopes et gazelles dans le Sahara, elles sont particulièrement bien adaptées à cet habitat aride. Parmi ses espèces, il y a l'Oryx algazelle, l'Addax, la gazelle Dama, la gazelle de Rhim, la gazelle de Cuvier et la gazelle Dorcas qui est la plus petite.

Le guépard Saharien vit majoritairement en Algérie mais aussi au Niger, au Mali, au Bénin et dans le Burkina Faso. À ces endroits peuvent être retrouvés 250 guépards adultes très craintifs et fuyant la présence de l'homme. Le guépard évite le soleil du mois d'avril jusqu'en octobre. Ensuite, il recherche un abri dans les arbrisseaux tels que les acacias. Ils sont inhabituellement pâles.

Les autres animaux incluent les varanus, les damans du cap, les vipères des sables et une petite population de Lycaon dans peut-être 14 pays et des autruches. Il existe d'autres animaux dans le Sahara (volatiles en particulier), entre autres, tels que l'amarante masqué et le capucin bec-d'argent. Il existe également une population de crocodiles du Nil en Mauritanie et dans le plateau de l'Ennedi Tchadien.

Les activités humaines affectent les zones dans lesquelles l'eau peut être trouvée. Ici, les ressources naturelles peuvent être menacées. Les populations restantes de grands mammifères ont été fortement réduites à cause de la chasse. Récemment, des projets de développement ont été organisés dans les déserts d'Algérie et de Tunisie.

Le Sahara possède 20 % de surfaces sableuses et 80 % de surfaces rocheuses où dominent des roches sédimentaires.

Le Sahara contient plusieurs milieux secs. Les ergs sont les grands massifs de dunes, ils occupent environ 20 % de la surface du Sahara. Ils évoluent en fonction des vents dominants. Le Grand Erg occidental en Algérie et le Grand Erg oriental en Tunisie comptent parmi les plus importants. Les regs sont des étendues plates, caillouteuses et constituent le paysage le plus fréquent du Sahara. Les grands regs sont particulièrement inhospitaliers. Le reg du Tanezrouft, qui veut dire « pays de la soif » (Algérie), le serir libyen ou le reg du Ténéré qui occupent chacun des centaines de milliers de km² peuvent être cités. Ils peuvent occuper aussi le sommet des plateaux.

Les hamadas sont les plateaux rocheux tabulaires limités par des falaises. Ils sont d'origine sédimentaire, le plus souvent calcaire. Lorsqu'ils sont recouverts de grès, ils sont nommés tassilis (par exemple : Tassili des Ajjer en Algérie). En général la surface montre de la roche nue, lissée par l'érosion éolienne. Le terme « "djebel" » désigne tous les autres reliefs que ce soient des collines ou des massifs montagneux plus importants.

Les plus importants massifs sont inclus le Tibesti (région du Borkou-Ennedi-Tibesti) formé d'un massif volcanique émergeant d'une épaisse nappe sédimentaire reposant sur le socle cristallin. Il culmine à (Emi Koussi) ; le Hoggar est un autre imposant massif volcanique. Il culmine à ; l'Aïr est moins élevé les sommets sont plus tabulaires mais culminent tout de même à ; l'Adrar des Ifhoras au sud du Hoggar en est un prolongement cristallin et métamorphique qui culmine à ; et l'Ennedi (région du Borkou-Ennedi-Tibesti) est un massif gréseux au sud-est du Tibesti et atteint .

Les milieux humides désertiques concentrent l'essentiel de la biodiversité en raison de la présence temporaire ou surtout pérenne de l'eau et également, de la vie humaine. Le taux d'endémisme y est particulièrement élevé.

À la différence des précédentes, les sebkhas forment des marais salants temporaires. L'eau peut provenir du ruissellement ou de sources temporaires. La plus grande, le Chott el-Jérid, couvre . Certaines sont exploitées sous forme de salines depuis le comme à Taoudeni au Mali.

Guelta est un terme d'origine berbère (Tageyilt) qui désigne des plans d'eau temporaires ou pérennes, sans écoulement apparent : des mares dans les lits des cours d'eau ou des "citernes naturelles" dans la roche en place. Ils peuvent être trouvés dans les situations protégées d'une trop grande exposition au soleil dans les massifs montagneux comme l'Ennedi et l'Adrar des Ifoghas au Mali.

Les "dayas" (pluriel dayate ou daia (daiate), dhaia) sont des dépressions fermées d'extension limitée (quelques mètres à 1 km de diamètre), au fond en général argileux ou argilo-sableux dans lesquelles l'eau de ruissellement peut s'accumuler. Une alternance d'inondation et d'exondation associée à une érosion éolienne participe à leur formation : parfois d'origine karstique (dolines) sur certains plateaux par exemple, issues de la déflation éolienne ou mixtes. Elles constituent des zones de végétation pérennes. Elles peuvent être trouvées surtout au Nord du Sahara. Ces dépressions à fond cultivable servent l’autoconsommation familiale. Ces trois termes d'origine arabe sont en usage en géomorphologie dynamique.

Les oasis sahariennes, milieu naturel et aménagé, n'occupent qu'un millième de la surface du Sahara. Elles sont situées parfois sur le lit des oueds venant se perdre dans le désert ou au pied de massifs produisant des sources ou encore directement au-dessus de nappes phréatiques affleurantes ou peu profondes. Les oueds sont des cours d'eau à écoulement apparent temporaire (voir aréisme et endoréisme) indissociable du phénomène de crue (les deux mots en arabe sont liés). La majorité du temps, ils sont à sec, mais des poches d'eau durables peuvent persister en profondeur, et des gueltas peuvent être alimentées par une résurgence.

Ce sont les crues qui alimentent ce réseau hydrographique temporaire, leur origine est essentiellement dans les massifs montagneux et la violence du débit a des conséquences morphologiques fortes sur le lit des oueds.

La partie amont naît du rassemblement de chenaux de ruissellement, la partie médiane forme un lit large et dont les limites sont parfois difficiles à reconnaître en plaine et la partie aval peut se diviser en plusieurs bras sur un cône étendu d'alluvions. C'est le long des oueds que les seules formations arborées un peu denses dans le Sahara sont observées.


Les foggaras, sont des ouvrages souterrains de grande longueur permettant l'adduction d'eau dans certaines oasis, depuis les plateaux ou les massifs montagneux. Cette technique ancestrale se retrouve dans ce qui est aujourd'hui l'Iran, sous le nom de Qanat. Elle a été apportée du Sahara dans les steppes marocaines par les Almoravides à qui elle a permis la fondation de la ville de Marrakech.

Plus de cinq millions d'habitants vivent dans le Sahara, un habitant sur deux vit dans des villes, un habitant sur huit dans le Sahara maghrébin (estimation en 1990). Jean Bisson estimait la population saharienne à 7 millions de personnes en 2003. On peut estimer aujourd'hui que la densité de population du Sahara est d'environ un habitant au kilomètre carré (8 millions d'habitants pour 8 millions de km²). 

Les populations actuelles du Sahara incluent les Toubous (Libye, Tchad, Niger, Égypte, Soudan soit environ 600 000 personnes) ; les Touaregs (un peuple de nomades dont l'effectif est estimé à un million de personnes ; vêtus traditionnellement de tissus de couleur bleu indigo qui déteignent sur la peau, ils furent aussi appelés les « "hommes bleus" » ou les « "seigneurs du désert" » par les voyageurs occidentaux) ; les Saharaouis et les Maures.

Dans plusieurs régions, notamment au sud du Sahara, des espaces bénéficiant autrefois du climat semi-aride du Sahel tendent à se désertifier, notamment à cause de l'action de l'homme. Ce phénomène est à l'origine d'importants mouvements de population.

Au Sahara, de nombreuses traces d'une activité humaine préhistorique peuvent être découvertes (outils, poteries, et peintures rupestres).

Le climat du Sahara a subi des variations importantes durant la préhistoire. Dans l'oasis de Bilma (Niger), des cratères de salines glauques sont les vestiges des mers qui couvraient le Sahara il y a d'années (paléo-océan Téthys & Téthys alpine) et se sont retirées lors de la remontée de l'Afrique vers l'Europe, engendrant alors les Alpes et rehaussant l'Afrique du Nord. La genèse du Sahara est datée à environ 7 millions d'années après la disparition de la Thétys. Cette zone géographique est soumise aux cycles glaciaires/interglaciaires depuis 2,7 millions d'années, passant de verdoyant à désert tous les 5 à . Il y a environ , il existait de grands lacs au Sahara, peuplé alors de semi-nomades. Il y a , le Sahara était hyperaride.

De façon générale, un documentaire du scientifique naturaliste David Attenborough sorti en 2012 postule que les oscillations de la Terre autour de son axe engendrerait tous les 20.000 ans environ des cycles de verdissement/désertification du Sahara, par déplacement des flux d'airs qui assèchent actuellement le Sahara.

Vers 12 000 ans , sa limite sud-orientale était remontée à hauteur du tropique du Cancer. Vers 10 500 ans , c'est sa limite sud-occidentale qui était remontée, la surface désertique étant alors moitié moindre que l'actuelle. Le climat radouci de cette écorégion demeura tempéré jusqu'aux alentours de 8500 ans Durant la période appelée , le « Sahara vert » reçut une pluviosité abondante. Il comprenait alors des lacs, des sources où vivaient des poissons et était couvert de végétations en bordure de cours d'eau (forêt galerie) et au fond des vallées. Il était peuplé d'une faune riche et de populations de chasseurs cueilleurs qui connurent alors la révolution néolithique environ 6000 ans Des fossiles d'animaux marins ont été retrouvés ainsi que des peintures de troupeaux de bœufs sur les parois de certaines grottes de cette époque. Les massifs montagneux du Sahara montrent des reliques de souches tropicales humides (acacias, "Calotropis", "Balanites") et de souches méditerranéennes (olivier sauvage, myrte, lavande) très minoritaires, qui restent subordonnées à la végétation proprement désertique (palmier, tamaris) mais attestent du passé humide et forestier datant du temps du « Sahara vert ».

Bien que le réchauffement climatique se fût amorcé, le Sahara était encore humide vers 6500 ans Le Sahara devint aride vers 3900 (), entraînant la migration des populations du centre de l'Afrique du Nord à la vallée du Nil, ce qui a finalement conduit à l'émergence des premières sociétés complexes et très organisées.

Au Ier millénaire av. J.-C., de grands nomades libyco-berbères s'implantent progressivement dans le Sahara, le parcourant du Nil à l'Atlantique. À la même période, les Phéniciens qui ont établi des comptoirs commerciaux en Afrique du Nord, pratiquent le commerce des esclaves, notamment via le circuit transsaharien.

Les Grecs colonisent la Cyrénaïque et la Tripolitaine à partir du et établissent des comptoirs le long de la Mer Rouge qui favorisent le commerce avec les Berbères. Parallèlement, le peuple berbère des Garamantes fonde une véritable civilisation urbaine dans le Fezzan et le Carthaginois Hannon le Navigateur explore les sites côtiers du Sahara occidental sur la façade atlantique du Maroc.

La province romaine d’Afrique du Nord est conquise en 146 av. J.-C. lors de la troisième guerre punique alors que des expéditions romaines atteignent le Sahara, telles celles de Lucius Bulbus en 50 av. J.-C. ou du général romain Septimus Flaccus et de l'explorateur militaire Julius Matermus qui parviennent au Tchad à la fin du .

L'empire romain d'Orient règne sur les côtes nord du Sahara du au , puis la conquête musulmane du Maghreb atteint rapidement le Sahara à partir du . Les musulmans arabes et berbères développent les systèmes de commerce transsaharien, aussi bien sur les marchandises que les hommes (traite arabe). Le Sahara reste à cette époque l'axe principal d'échange entre l'Afrique noire et l'Afrique du Nord et cette source de revenus considérables est très convoitée. L'empire ottoman s'étend sur l'Afrique du Nord (à l'exception du Maroc, de la Kabylie et du Sahara algérien) jusqu'à son déclin à la fin du , mais il est incapable d'étendre son autorité aux régions sahariennes. Cela permet à l'impérialisme et au colonialisme européen de s'imposer, d'abord par les explorations (la traversée nord-sud du Sahara est ainsi réalisée en 1822 par les deux explorateurs anglais Hugh Clapperton et Dixon Denham. En 1828, L'explorateur français René Caillié atteint Tombouctou, seul, et il est le premier à en revenir, au terme d'une éprouvante traversée vers le Maroc, alors que l'Anglais Alexander Laing qui l'avait précédé avait été assassiné par son guide peu de temps après avoir quitté la ville). Le partage de l'Afrique consacre la domination de la France sur le Sahara (Sahara français) contrôlé par les Compagnies méharistes sahariennes fondées en 1902 par le commandant Laperrine. L'intérêt économique du Sahara, manifesté par les projets du chemin de fer transsaharien et de l'Organisation commune des régions sahariennes en 1957, explique le maintien de la présence européenne dans cette vaste région mais n'empêche pas la décolonisation de l'Afrique. 

Aujourd'hui, le Sahara est l'objet de multiples enjeux liés aux richesses de son sous-sol (hydrocarbures, minerais dont le phosphate et le fer) qui donnent une impulsion à la construction du réseau des routes transafricaines (notamment la route transsaharienne), mais aussi aux tensions et aux crises de nations en devenir.

Depuis 1900, le Sahara a progressé vers le sud de et ce sur un front qui en fait plus de . C'est ainsi que la steppe du Sahel connaît un dessèchement relativement brutal.
Néanmoins, la décennie qui suit l'année 2000 a connu un reverdissement dans le Sahel.

L'étendue, le degré d'ensoleillement et la faible population sédentaire du Sahara en font potentiellement un gigantesque « gisement » d'énergie solaire renouvelable, tant photovoltaïque que thermique. Reiser avait calculé qu'un carré de de côté en plein Sahara équipé avec les techniques de son époque aurait suffi en théorie à alimenter la totalité de l'Afrique et de l'Europe en électricité, et cela indéfiniment, bien que de façon non continue. L'Europe, de son côté, pourrait utiliser cette électricité le jour pour pomper de l'eau vers ses lacs de montagne et restituer la nuit l'énergie ainsi stockée. La mise en application de cette idée a commencé sous le nom de Projet Desertec.


Un proverbe arabe dit que « le Sahara est un puits dont le chameau est la corde ».





</doc>
<doc id="2753" url="https://fr.wikipedia.org/wiki?curid=2753" title="Webzine">
Webzine

Un webzine est un magazine publié sous forme d'un site web, sans contrepartie imprimée.

Le webzine peut être publié par des amateurs ou des journalistes professionnels. Il peut aussi être gratuit ou payant.

On parle de webzine interactif lorsque les visiteurs peuvent commenter les articles ou de webzine collaboratif lorsque les internautes peuvent publier eux-mêmes leurs chroniques sur le site.

Dans le microcosme de la littérature de science-fiction et de fantasy, on appelle couramment webzine un fichier téléchargeable contenant aussi bien des nouvelles, que des articles, des interviews et des step-by-step d'illustrateurs.

Comme les fanzines, les webzines sont souvent thématiques. Ils sont réalisés par des passionnés, souvent en équipe. Les thèmes abordés tournent souvent autour de sujets peu traités par les médias traditionnels : bande dessinée, musique alternative (rock indépendant, heavy metal, punk rock), jeu de rôle mais aussi cinéma, histoire, Internet, mode, etc.

Peu de critères objectifs différencient un webzine amateur d'un site personnel : le nombre de contributeurs, leur passion, la qualité technique de la réalisation sont comparables. Couramment, on attend d'un webzine une ambition rédactionnelle : du contenu original et une parution relativement régulière.

La compétence technique nécessaire peut être minime : la maîtrise d'un logiciel de conception de site web comme les CMS ou du langage HTML suffit. Contrairement à leurs homologues sur papier, ils bénéficient avec Internet de moyens de publication moins onéreux et de diffusion plus large. Certains webzines réalisent des audiences qui n'ont rien à envier aux médias classiques et certains jouissent d'une certaine reconnaissance.

Comme ils ont remplacé les fanzines, les webzines voient leur importance mise à mal par le développement des blogues, encore plus simples à mettre en œuvre.

On peut également citer, dans le domaine historique, le webzine "Histomag'44", bimensuel consacré à la Seconde Guerre mondiale fondé en 2001 et devenu "Histomag 39-45".


</doc>
<doc id="2755" url="https://fr.wikipedia.org/wiki?curid=2755" title="Steve Jobs">
Steve Jobs

Steven Paul Jobs, dit Steve Jobs, né à San Francisco (Californie) le et mort à Palo Alto (Californie) le , est un entrepreneur et inventeur américain, souvent qualifié de visionnaire, et une figure majeure de l'électronique grand public, notamment pionnier de l'avènement de l'ordinateur personnel, du baladeur numérique, du smartphone et de la tablette tactile. Cofondateur, directeur général et président du conseil d'administration d'Apple Inc, il dirige aussi les studios Pixar et devient membre du conseil d'administration de Disney lors du rachat en 2006 de Pixar par Disney.

Steve Jobs, Steve Wozniak et Ronald Wayne créent Apple le à Cupertino. Au début des années 1980, Steve Jobs saisit le potentiel commercial des travaux du Xerox Parc sur le couple interface graphique/souris, ce qui conduit à la conception du Lisa, puis du Macintosh en 1984, les premiers ordinateurs grand public à profiter de ces innovations. Après avoir perdu sa lutte de pouvoir à la tête d'Apple avec le directeur général qu'il avait pourtant recruté, John Sculley, il quitte l'entreprise en septembre 1985 pour fonder NeXT.

En 1986, il rachète la division "Graphics Group" de Lucasfilm, la transforme en Pixar Animation Studios et rencontre le succès commercial en 1995 avec "Toy Story", un film dont il est le producteur délégué. Il reste directeur général propriétaire de la compagnie (à 50,1 %) jusqu'à son acquisition par la Walt Disney Company en 2006.

Début 1997, Apple, alors au bord de la faillite, rachète NeXT. L'opération permet à Steve Jobs de revenir à la tête de la firme qu'il a cofondée et fournit à Apple le code source de NeXTSTEP à partir duquel est développé le système d'exploitation Mac OS X. Il supervise durant les quatorze années suivantes la création, le lancement et le développement de l'iMac (1998), de l'iPod, d'iTunes et de la chaîne de magasins Apple Store (2001), de l'iTunes Store (2003), de l'iPhone (2007) et de l'iPad (2010), présentant les différents produits à un rythme pluriannuel lors de ses fameuses "" et faisant de son entreprise une des plus riches au monde au moment de sa mort.

En 2003, Steve Jobs apprend qu'il est atteint d'une forme rare de cancer pancréatique. Il passe les années suivantes à lutter contre la maladie, subissant plusieurs hospitalisations et arrêts de travail, apparaissant de plus en plus amaigri au fur et à mesure que sa santé décline. Il meurt le 5 octobre 2011 à son domicile de Palo Alto, à l'âge de cinquante-six ans. Sa mort soulève une importante vague d'émotion à travers le monde.

Steven Paul Jobs naît le 24 février 1955 à San Francisco en Californie, d'un père d'origine syrienne étudiant en sciences politiques, Abdulfattah « John » Jandali (), et de Joanne Carole Schieble, Américaine d'origine suisse. Ils ne sont à l'époque pas mariés. Alors que Joanne est enceinte, son père la menace de la priver de son héritage si elle épouse un non-catholique, si bien qu'elle se rend chez un avocat de San Francisco pour trouver une famille adoptive.

Le nouveau-né est alors adopté par Paul Reinhold Jobs (1922–1993) et Clara Jobs, née Hagopian, d'origine arménienne (1924–1986). Adulte, lorsqu'il est questionné à propos de ses parents adoptifs, Jobs répond que Paul et Clara Jobs . Dans sa biographie autorisée, il déclare que ce sont ses parents à %. Quant à ses parents biologiques, ils se marient en 1955 et ont un second enfant, Mona Simpson en 1957, puis divorcent en 1962.

Lorsque Steve a deux ans, ses parents adoptent une fille, Patty. Trois ans plus tard, la famille Jobs déménage de San Francisco pour s'installer à Mountain View en Californie à la suite de la mutation de Paul Jobs à Palo Alto. Paul est alors machiniste pour une entreprise qui fabrique des lasers, et enseigne à son fils des rudiments d'électronique, tout comme à se servir de ses mains. Pour sa part, Clara est comptable et apprend à Steve à lire avant qu'il aille à l'école.

Jobs entame sa scolarité à la à Mountain View puis intègre la toute proche mais, à la suite de problèmes scolaires, il lance un ultimatum à ses parents : soit ils le font changer d'établissement, soit il arrête l'école. La famille déménage alors cinq kilomètres plus au sud, au 2066 Crist Drive à Los Altos, ce qui permet à Steve de poursuivre son cursus scolaire à la puis à la à Cupertino. Larry Lang, un ingénieur qui habite à cent mètres de leur ancienne maison et chez qui Jobs passe de nombreuses soirées, le fait entrer au club des Explorateurs de Hewlett-Packard. Quinze élèves s'y réunissent tous les mardis soir dans la cafétéria de l'entreprise et font venir un ingénieur en informatique de la société pour parler de ses travaux. À la suite de l'une de ces conférences, il convie l'un des élèves à visiter son laboratoire ; c'est à cette occasion que le jeune Steve voit le premier ordinateur de bureau que Hewlett-Packard développe, le 9100A. Âgé de treize ans, il n'hésite pas à téléphoner à William Hewlett, le président de l'entreprise qui porte en partie son nom. Steve est en train de construire un fréquencemètre et il a besoin de pièces. Ils discutent pendant vingt minutes, Hewlett lui expédie les composants dont il a besoin et lui offre un emploi d'été dans son entreprise.

Après sa première année à , Steve Jobs travaille donc durant l'été sur l'une des chaînes d'assemblage de Hewlett-Packard. À la même époque, un camarade de classe de Homestead High, Bill Fernandez, lui présente Steve Wozniak. Ils partagent la même passion de l'électronique, ils deviennent amis et réalisent ensemble de nombreux canulars. En septembre 1971, les deux Steve mettent la main sur un article du magazine "Esquire" qui explique comment fabriquer une ", un appareil qui permet de passer des appels longue distance de façon entièrement gratuite en fraudant donc les compagnies téléphoniques, et plus précisément AT&T. Ils décident alors d'en monter et de les vendre. Selon Jobs, cette expérience est à l'origine d'Apple.

En 1972 à sa sortie de Homestead High, il décide de poursuivre ses études à Reed College à Portland dans l'Oregon où il rencontre Daniel Kottke. À la suite de plusieurs lectures d'ouvrages sur la spiritualité orientale lors de cette première année à Reed, ils deviennent tous les deux végétariens. Toujours à Reed College, il rencontre un autre adepte de la spiritualité orientale et son futur gourou, . Ce dernier dirige une grande ferme communautaire de cent hectares, l"', où le jeune Steve se rend souvent.

Très vite, Jobs se rend compte qu'il s'ennuie à Reed, se trouvant dans l'obligation de suivre un certain nombre de cours qui ne l'intéressent pas. Il décide donc d'abandonner ce cursus, sans en informer ses parents qui se sont pourtant littéralement ruinés pour l'y inscrire, et se choisit d'autres cours où il se rend en tant qu'auditeur libre. En 2005, Steve Jobs déclare .

C'est une période où Steve Jobs expérimente assidument le LSD en écoutant les disques de Bob Dylan, des Beatles et des groupes phares de la contre-culture californienne. Il déclare plus tard que prendre du LSD a été l'une des deux ou trois expériences les plus importantes de sa vie. Il évoque cette substance psychotrope hallucinogène comme une des principales raisons de sa réussite, pour lui avoir ouvert l'esprit en grand. Il déclare également : .

Après avoir passé dix-huit mois au Reed College, Jobs revient chez ses parents à Los Altos en 1974 pour se trouver un emploi. Le hippie négligé qu'il est se présente chez Atari, firme en vogue à l'époque, avec la ferme intention d'y obtenir un emploi. Il s'attire les faveurs de son patron Nolan Bushnell qui l'embauche comme technicien, mais pas celles de nombreux employés, du fait notamment de sa forte odeur. Il estime en effet que son régime alimentaire végétarien strict et tout à fait personnel lui permet d'éviter la production de mucus et de toute odeur corporelle et ne se lave donc pas. Il se retrouve donc à devoir travailler pendant le service de nuit. Pendant son séjour chez Atari, il rencontre entre autres le dessinateur industriel Ronald Wayne, avec qui il devient ami.

Il décide à cette époque de suivre la trace de son gourou du Reed College, Robert Friedland. Il entreprend donc un voyage en Inde. Sur place, il se rend à Haridwar pour le pèlerinage du Kumbhamela puis prend la direction de Nainital au pied de l'Himalaya où vivait le gourou Neem Karoli Baba. Il y rencontre l'épidémiologiste Larry Brilliant avec qui il devient ami. Par la suite, il est rejoint par son ami Daniel Kottke. Après avoir passé sept mois en Inde, Steve revient aux États-Unis, tête rasée et portant des habits traditionnels indiens, à l'image des Hare Krishna. À son retour, il récupère son poste chez Atari. Bushnell lui demande alors de concevoir le circuit imprimé du jeu "" avec le moins de puces possibles. À la clé, en plus de la rémunération, il y aura un bonus proportionnel au nombre de puces économisées. Pour cela, il fait appel à son acolyte Steve Wozniak pour l'aider à le réaliser. Ce dernier réussit, en quatre jours, à concevoir un circuit en n'utilisant que quarante-cinq puces. Pour le travail réalisé, Jobs annonce à son compère qu'il coupe la poire en deux, trois cent cinquante dollars chacun. Bien que Jobs le nie, certains témoins, dont Bushnell, confirment que Jobs a obtenu cinq mille dollars et non sept cents pour le travail réalisé. Wozniak, qui ne découvre les faits que dix ans plus tard à la lecture de "Zap", un ouvrage sur l'épopée d'Atari, reconnaît avoir été blessé par l'attitude de son ami.

En 1975, Jobs et Wozniak participent aux rencontres du Homebrew Computer Club, où les amateurs d'informatique viennent échanger leurs idées concernant les machines de l'époque, telles que l'Altair 8800. Steve Wozniak s'initie aux microprocesseurs en découvrant l'Altair équipé d'un Intel 8080. Il conçoit à la suite de cela l'Apple I pendant l'année 1975. La machine, bien que sommaire, impressionne Steve Jobs. Munis d'un petit moniteur, ils l'emmènent pour le présenter aux Homebrew Computer Club. L'altruisme de Wozniak l'aurait amené à distribuer gratuitement ses schémas de montage. Jobs, au contraire, voit plus loin. Considérant que la plupart des gens n'ont pas le temps de monter une machine, Jobs et Wozniak pourraient donc assembler les circuits pour leur vendre l'ordinateur monté. Jobs suggère donc à son acolyte de créer leur propre entreprise.

Pour réunir les fonds nécessaires au lancement, Jobs, âgé de 21 ans, vend son Volkswagen Combi, Wozniak, 25 ans, sa calculatrice HP-65. L'acte de la fondation d'Apple est signé le par Steve Jobs, Steve Wozniak et Ronald Wayne. Moins de deux semaines après, Wayne se sépare des deux Steve et récupère sa mise mais, très vite, un élément va apporter un coup d'accélérateur à Apple : Mike Markkula, un business angel californien, apporte dollars à la nouvelle compagnie, en plus d'un business plan. Wozniak et Jobs se mettent au travail dans le garage de la maison familiale de ce dernier, à Los Altos, où, avec quelques proches, ils assemblent les cinquante premiers Apple I que Steve Jobs a vendus au magasin "Byte Shop" de Menlo Park. Le nom de l'entreprise est une idée de Jobs : ". Il est en effet dans la phase « pomme » de son régime et revient tout juste d'une plantation de pommiers. Il sait aussi qu'Apple se trouvera devant Atari dans l'annuaire. Ce nom se trouve cependant être aussi celui de la compagnie des Beatles (). Cela vaudra à son entreprise plusieurs contentieux en justice durant les décennies suivantes. 
Apple est constituée sous forme de société le 3 janvier 1977. Pour faire la promotion de ses produits, Jobs contacte le grand publicitaire de la vallée, Regis McKenna. L'une des priorités est de trouver un nouveau logo. Steve Jobs précise alors . Début juin 1977, Apple commercialise l'Apple II, conçu par Steve Wozniak. Il peut être considéré, trois ans avant la sortie de l'IBM PC, comme le premier ordinateur personnel construit à grande échelle. Il rencontre le succès et fait la richesse de la jeune entreprise. En 1978, Apple recrute Michael Scott de la National Semiconductor afin de devenir son directeur général. En décembre 1980, Apple, qui a gagné sa renommée avec l'Apple II, est introduite en bourse, ce qui fait de Steve Jobs un multimillionnaire à vingt-cinq ans et enrichit considérablement environ trois cents de ses dirigeants et cadres, mais pas Daniel Kottke. Le grand ami d'adolescence de Steve Jobs n'occupe pas un poste hiérarchique assez élevé pour détenir des actions et le jeune patron se montre intraitable avec lui en refusant catégoriquement de lui permettre de profiter de cette manne.

Au début des années 1980, Jobs est l'un des premiers à cerner le potentiel commercial de l'interface graphique couplée avec l'usage d'une souris développée au Xerox PARC. Pour avoir accès à cette technologie encore balbutiante, il propose aux responsables de Xerox d'investir dans Apple (à hauteur d'un million de dollars en actions Apple) et, en échange, Steve et ses collègues obtiennent l'autorisation en décembre 1979 de se rendre au PARC pour y voir une démonstration complète du système développé par les ingénieurs de Xerox. Ce qu'ils y voient leur sert de base à la conception de leur interface maison à laquelle ils apportent leurs propres améliorations. Cela conduira au lancement de l'Apple Lisa en 1983 puis du Macintosh en 1984, les premiers ordinateurs personnels à profiter de ces innovations qui restent encore aujourd'hui le standard général. À la question de savoir s'il s'agit de ce qui a pu être considéré comme le , Steve Jobs répond : , et ajoute à propos de Xerox qu'ils ont raté le coche, qu'ils n'avaient pas conscience du potentiel de ce qu'ils étaient en train de développer alors qu'ils auraient pu devenir les maîtres de toute l'industrie informatique.

Le projet Macintosh est lancé et mené par Jef Raskin, brutalement écarté pour des problèmes d'ego par Steve Jobs en février 1981, lorsqu'il s'en saisit pour mettre en pratique ses idées déjà développées sur le Lisa d'une machine avec interface graphique et souris. Débarqué du projet Lisa quelques mois plus tôt par Michael Scott et Mike Markkula qui trouvent que ses accès de colère empêchent son équipe de travailler sereinement, il prend dès lors la tête d'un groupe de jeunes ingénieurs talentueux (au premier rang desquels figurent Andy Hertzfeld, Bill Atkinson, Burrell Smith, Susan Kare, Joanna Hoffman, Bud Tribble) dont certains resteront ses amis. Ils sont regroupés dans un bâtiment sur lequel flotte un drapeau noir orné d'un crâne barré par deux os et se baptisent « les pirates ». Ils conçoivent ce que tous les utilisateurs d'ordinateurs ont connu : une souris à un seul bouton, qui déplace le pointeur à l'écran dans toutes les directions grâce à une unique bille placée en dessous et qui doit pouvoir comme le spécifie Jobs (bien loin du concept de départ des ingénieurs du PARC), les menus déroulants, le « glisser-déposer », le chevauchement des fenêtres, les icônes, la corbeille, apportant des évolutions décisives au principe du WYSIWYG ("/Ce que vous voyez est ce que vous obtenez) et donc à ce qui est connu sous le nom de « bureau ».

Steve Jobs veut embaucher les meilleurs pour chaque poste et sa façon de recruter peut se révéler très déstabilisante pour les candidats. Andy Hertzfeld raconte ainsi un entretien d'embauche pour le poste de responsable de la division logiciels auquel il assiste début 1982. Jobs demande à l'impétrant, interloqué : , et enchaîne : , répond le candidat. lâche Jobs devant ses plus proches collaborateurs qui répriment un fou-rire.

C'est dans cette même période, en 1983, que Steve Jobs débauche John Sculley, alors directeur général de Pepsi-Cola, pour remplacer Scott, en lui demandant . Le lancement du Macintosh est accompagné d'une campagne publicitaire d'envergure décidée par Jobs et Sculley. Pendant la mi-temps du Super Bowl le 22 janvier 1984, Apple fait diffuser à la télévision le spot publicitaire 1984 réalisé par Ridley Scott devant plus de 90 millions de téléspectateurs. Ce spot remportera plusieurs prix prestigieux et redéfinira la façon dont les entreprises envisagent leurs campagnes publicitaires, en privilégiant de montrer le signe, l'évocation, plutôt que le produit en lui-même.

Bien que Jobs soit un chef charismatique et persuasif, certains salariés d'Apple le décrivent comme erratique et capricieux. Bud Tribble invente à cette époque le terme de « champ de distorsion de la réalité » qu'il emprunte à la série "Star Trek" et qui décrit la capacité de son patron à imposer aux autres ses conceptions, quelles qu'elles soient. Ce dernier n'hésite pas en effet à humilier ses collaborateurs en public et est réputé pour sa vision « binaire » de leur travail : soit , soit, le plus souvent, . Le même principe est appliqué aux êtres humains qui sont soit , et peu nombreux, soit font partie de la masse des , des qui tirent une entreprise vers le bas et dont il faut se séparer au plus vite. Jobs est capable de repousser une idée d'un de ses collaborateurs en la qualifiant de « stupide » et de revenir plus tard en s'étant attribué cette idée. Il sait imposer des délais qui paraissent impossibles à tenir en disant juste qu'il n'acceptera aucune objection. Par ailleurs, il scelle le malheureux destin du Lisa (échec commercial, rapide arrêt de la production) en rendant le Macintosh incompatible avec cet appareil et crée un rapport de force et un lourd climat de tension entre son équipe et celle qui s'occupe de l'ordinateur qui continue encore à cette époque à assurer l'essentiel des revenus de son entreprise, l'Apple II, en expliquant notamment : 

La relation entre Jobs et Sculley devient tendue en raison des ventes en berne fin 1984. Une lutte de pouvoir interne va les amener à se tirer dans les pieds. Jobs manœuvre pour débarquer Sculley, sûr de son fait, mais, à son grand dam, ce dernier réussit dans les derniers jours de mai 1985 à ranger l'ensemble des membres du conseil d'administration de son côté, et ceux-ci décident donc d'écarter Steve Jobs, en le , déchargé de tout rôle décisionnel et opérationnel, avec le vague titre de responsable du dans un bureau éloigné du centre décisionnel de l'entreprise. Désabusé, il quitte la société en septembre 1985 pour fonder NeXT Inc. et ne parlera plus jamais à John Sculley.

Après son départ amer d’Apple, Jobs fonde NeXT Computer, en déboursant sept millions de dollars. Il s'attire par ailleurs des ennuis en justice avec Apple car il emmène avec lui quelques-uns des plus brillants ingénieurs. Un an plus tard, manquant de fonds et en l’absence d’un produit sur le marché, il se lance à la recherche d’investisseurs. Il attire l’attention du milliardaire Ross Perot qui investit massivement dans la compagnie. La station de travail NeXT, le NeXT Computer, est commercialisée en 1988 pour un prix de six mille cinq cents dollars. À l’image du Macintosh, les ordinateurs NeXT possèdent une belle avance technologique, mais leur coût se révèle prohibitif pour le secteur de l’éducation auquel ils sont destinés. Et les ventes sont très décevantes. Les produits de la marque gagnent toutefois une belle réputation pour leurs atouts techniques, au premier rang desquels figure la programmation orientée objet. Jobs veut vendre les produits NeXT aux communautés financière, scientifique et académique, soulignant les nouvelles technologies innovantes et expérimentales de l'ordinateur, telles que son noyau Mach, son processeur de signal numérique et le port Ethernet intégré.

L’ordinateur de seconde génération, le NeXT Cube, est commercialisé en 1990. Jobs qualifie ce produit de qui va remplacer l’ordinateur personnel. Avec son client de messagerie NeXTMail, un système multimédia de courrier électronique, le NeXT Cube peut pour la première fois offrir le partage de la voix, de l’image, des graphismes et de la vidéo dans un courriel. , explique un Steve Jobs visionnaire à des journalistes le 31 mai 1990. D'ailleurs, Tim Berners-Lee invente à cette époque le "" au CERN sur un NeXT Computer.

Steve Jobs dirige NeXT avec une obsession de la perfection esthétique, comme le souligne le développement et l’attention portée au cadre magnésium du NeXT Cube, en mettant une pression terrible à la division « matériel » de sa compagnie. En 1993, après n’avoir vendu que cinquante mille machines, NeXT abandonne la fabrication pour se consacrer exclusivement au développement de logiciels, avec la mise en vente du NeXSTEP/Intel. La compagnie annonce ses premiers bénéfices de en 1994. En 1996, NeXT Software, Inc. commercialise WebObjects, un système conçu pour le développement d’applications web. Après l’acquisition de NeXT Software par Apple en 1997, WebObjects est utilisé pour concevoir et exploiter les Apple Stores, l’ITunes Store et les services en ligne de MobileMe. Avec le recul il dit à propos de ces années là : .

En 1986, Steve Jobs rachète la division « graphisme par ordinateur » de Lucasfilm, le ' qui sera renommé Pixar. Il débourse dix millions de dollars dont la moitié est versée au capital de la nouvelle compagnie. L'entreprise est basée aux studios Kerner de George Lucas à San Rafael, avant de s’installer à Emeryville. Steve Jobs investit environ cinquante millions de dollars à perte dans cette société qui traverse plusieurs années sans aucune rentabilité. Ses principales activités sont de développer et fournir du matériel numérique de conception graphique haut de gamme et de vendre en petite quantité l'ordinateur « Pixar Image », notamment au secteur de la médecine. Mais, au sein de Pixar, il existe une division « animation » qui sauve finalement l’entreprise en remportant l'Oscar du meilleur court métrage d'animation avec ' en 1989. Par la suite, le studio décroche un contrat avec le studio Walt Disney Pictures pour réaliser une série de longs métrages d'animation par ordinateur, Disney assurant le financement et la distribution.

Le premier film issu de ce partenariat est ' (1995), dans lequel Steve Jobs est crédité en tant que producteur délégué. Le film apporte la célébrité ainsi qu'une reconnaissance critique et commerciale sur un plan mondial à Pixar. La recette globale est de 362 millions de dollars. Une semaine après la sortie de ', la société Pixar est introduite en bourse, avec un résultat aussi glorieux et profitable que pour Apple en 1980. Durant les quinze années suivantes, sous la houlette du créatif directeur artistique John Lasseter, le studio aligne les succès : "1001 pattes" (1998), ' (1999) "Monstres et Cie" (2001), "Le Monde de Nemo" (2003), "Les Indestructibles" (2004), ' (2006), "Ratatouille" (2007), "WALL-E" (2008), "Là-haut" (2009), ' (2010), ' (2011). Tous les films sortis à partir de 2003 (à l'exception de " en 2007) ont reçu l'Oscar du meilleur film d'animation.

Dans les années 2003-2004, alors que le contrat liant Pixar à Disney arrive à échéance, les négociations entre Steve Jobs et Michael Eisner destinées à renouveler le partenariat échouent. En février 2003, Jobs annonce que Pixar cherche un autre distributeur pour les films de son studio. En octobre 2005, Robert Iger remplace Michael Eisner à la tête de Disney et il se met rapidement à l’œuvre pour renouer de bonnes relations avec Jobs et Pixar. Le 24 janvier 2006, Jobs et Iger annoncent que Disney a décidé d’acheter Pixar pour une transaction de 7,4 milliards de dollars. Steve Jobs devient alors le premier actionnaire individuel de la plus grande compagnie de divertissement mondiale, avec environ 7 % de parts. Celles-ci sont en effet, et de loin, supérieures à celles de Michael Eisner (1,7 %) ou de l'héritier Roy Edward Disney qui détient 1 % jusqu'à sa mort en 2009 et dont les critiques envers Eisner (portant notamment sur son échec à négocier avec Pixar et Steve Jobs) ont accéléré son départ. Steve Jobs rejoint le conseil d’administration de Disney où il supervise la division « animation » de la compagnie au sein d’un comité spécial de pilotage constitué de six membres.

En décembre 1996, Apple annonce son intention de racheter NeXT. L’opération, effective le 4 février 1997, est estimée à . Propriétaire à 45 % de NeXT, Steve Jobs obtient cent millions de dollars ainsi qu'un million et demi d'actions Apple. Cela lui permet de reprendre pied dans la compagnie qu’il a cofondée en tant que « conseiller à mi-temps ». Steve Jobs déclare en janvier 1997 : Apple est à ce moment au bord de la faillite. Il redevient "de facto" le patron d'Apple lorsque le directeur général de l’époque, Gil Amelio, est remercié en juillet 1997. Jobs est officiellement nommé « directeur général par intérim » au mois de septembre. À cette époque, il est surnommé iPDG (iCEO) par ses équipes qui s'inspirent de la lettre « i » comme marque de fabrique désignant les produits à venir. Selon Adam Lashinsky dans son ouvrage "Inside Apple" publié en 2012, la lettre i faisant référence au statut d'intérimaire du PDG. Le site Reference for Business attribue cette première lettre à l'attrait vendeur d'Internet.

En mars 1998 et afin de concentrer les efforts d’Apple sur un retour aux bénéfices, il met un point final aux programmes Newton, Cyberdog et OpenDoc ainsi qu'à la vente de licence Mac OS afin d'empêcher la multiplication des « clones » et explique à ses collaborateurs qu'ils doivent désormais se concentrer sur pas plus de quatre produits. Il met au point le slogan ' avec son erreur grammaticale délibérée, en compagnie de son ami publicitaire Lee Clow, et lance une grande campagne d'affichage et un spot télévisé intitulé ' (les fous) où ce est illustré avec les plus grandes figures du , comme Albert Einstein, Gandhi, Martin Luther King, John Lennon, Alfred Hitchcock, Bob Dylan, Pablo Picasso.

La technologie de NeXT étant devenue propriété d’Apple une fois le rachat conclu, bon nombre de ses réalisations vont trouver place dans les produits de la firme à la pomme, au premier rang desquels figure NeXTSTEP qui est la base du système d’exploitation Mac OS X.

Sous la houlette de Steve Jobs, Apple se déploie avec tout d’abord l’introduction de l’iMac en 1998 puis, chaque année, de nouveaux produits qui assoient la puissance de la marque. Lors de la Macworld Expo de l’an 2000, Steve Jobs enlève officiellement « intérim » du titre de sa fonction et devient directeur-général permanent. Dans le même temps, il souligne qu’il utilisera le titre « iCEO ».
Apple continue son développement, introduisant et développant de nouveaux appareils numériques et leur environnement au cours des années 2000. Avec le lancement de l’iPod et d’iTunes en 2001 puis de l’iTunes Store en 2003, la compagnie crée une véritable révolution dans l’industrie de la musique, désormais dématérialisée. Steve Jobs supervise dans le même temps la création de la chaîne de magasins Apple Store, d'abord aux États-Unis puis dans le monde entier. Le succès est fulgurant. Le 29 juin 2007, Apple entre dans le marché des téléphones portables avec la commercialisation de l’iPhone, un appareil cellulaire doté d’un écran tactile "multi-touch" qui comprend aussi un iPod et un navigateur web, révolutionnant là aussi le marché de la téléphonie mobile, Steve Jobs ayant comme le dit le président des États-Unis Barack Obama « mis l'internet dans nos poches ». Il lance l'année suivante un véritable « écosystème » pour cet appareil, et bientôt pour tous les produits Apple : l'App Store, créant ainsi une forme de standard pour tous les smartphones.

Le 27 janvier 2010, Steve Jobs présente l’iPad, une tablette numérique reprenant le principe de l’écran tactile multipoints. C’est encore une forme de révolution, la porte ouverte à un nouveau marché dans lequel vont s'engouffrer bien des marques. Sans parvenir à égaler son succès, l'iPad captant 62 % du marché mondial des tablettes en 2011. Enfin, tous les contenus personnels des utilisateurs stockés sur les différents appareils se retrouveront dans le « nuage numérique », l'iCloud, à partir duquel ils pourront être redistribués , un service présenté par Jobs en juin 2011, lors de sa toute dernière "keynote".

Sur l'enchaînement des deux derniers produits phares d'Apple, Steve Jobs explique à Walt Mossberg lors du forum D8 en 2010 : 

À partir d'août 2011, après quatorze années de montée en puissance sous la direction de son charismatique patron et au gré des fluctuations du marché, Apple est l'entreprise la plus riche au monde par sa capitalisation boursière, son trésor de guerre dépassant notamment celui du gouvernement des États-Unis. L'entreprise qu'il a fondée continue sa course en tête à partir de 2012.

Toujours enclin à stimuler l’innovation, Jobs n’a jamais manqué de rappeler à ses collaborateurs une vieille maxime qu’il avait trouvée à l’époque du lancement du Macintosh : « », c'est-à-dire que les vrais artistes savent aussi vendre leurs créations, et que la finalité d’un produit reste d’être distribué au public. De son vivant, Steve Jobs est à la fois admiré et critiqué pour ses formidables talents de persuasion, ce fameux « champ de distorsion de la réalité », c’est-à-dire qu’il est capable d’altérer la perception de son ou de ses interlocuteurs pour leur faire adopter ses propres conceptions, qu’elles se révèlent par la suite justes ou non. Il sait ainsi décrocher des partenariats, avec l’industrie de la musique ou les opérateurs téléphoniques, à des conditions exceptionnelles pour son entreprise. Ce talent particulier apparaît au grand public lors des discours de Steve Jobs aux Macworld Expos ou aux Worldwide Developers Conferences, où il présente l’actualité de son entreprise lors de ses ', renommées pour l’occasion '. Lors de ces grandes messes où il parcourt la scène en jeans, baskets, et vêtu d'un pull à col roulé de marque, le patron d'Apple sait captiver son auditoire, notamment en répétant à l'envi des mots récurrents tels que , etc.. Il sait aussi maintenir le suspense et ravir son public avec le fameux () qu'il prononce à la fin de ses présentations pour annoncer par surprise une autre nouveauté importante.

Steve Jobs lutte durant plus de sept ans contre la maladie, subissant notamment une greffe du foie en avril 2009. Au fil des années, la santé florissante de son entreprise contraste avec son apparence de plus en plus frêle. Le 17 janvier 2011, il prend un nouveau congé « pour une durée indéterminée » qui se révélera être le dernier. Le 24 août 2011, le monde entier apprend qu'il démissionne de son poste de directeur-général d'Apple, annonçant dans une lettre adressée à tous ses collaborateurs qu'il souhaite que Tim Cook prenne définitivement sa place, et qu'il restera président du conseil d'administration afin de pouvoir continuer à superviser les activités de la marque qu'il a fondée. Quelques heures après cette annonce, les actions boursières de la compagnie chutent de 5 %.

Steve Jobs ne gagne qu’un dollar symbolique par an en tant que directeur-général d’Apple, mais il possède dans le même temps 5,426 millions d’actions de son entreprise, tout comme 138 millions d’actions Disney, celles qu’il avait reçues en 2006 lors du rachat de Pixar. Il plaisante en expliquant que son dollar annuel de revenu est divisé en cinquante cents pour participer aux réunions, et cinquante cents basés sur la performance. En plus de son salaire, il obtient de la part d'Apple le remboursement de ses frais de transport (deux cent mille dollars en 2010) mais aussi un jet Gulfstream V en tant que bonus. En 2011, Forbes estime sa fortune personnelle à sept milliards de dollars, faisant de lui la trente-neuvième plus grande fortune américaine.

Steve Jobs est un perfectionniste d’une grande exigence qui a toujours voulu positionner ses entreprises et leurs produits à la pointe de l’industrie des technologies de l’information en prévoyant les tendances du marché, mais aussi en les créant, tout du moins en termes d’innovations et de style. Jobs résume cela en janvier 2007 par une maxime de la star canadienne du hockey Wayne Gretzky : Sur un plan personnel, ce n'est pas tant la richesse qui l'intéresse (il se range dans la catégorie des grands patrons les moins ostentatoires) que de laisser sa trace, d'assurer sa place parmi les grands entrepreneurs et inventeurs de l'histoire de son pays, ainsi que la pérennité de son entreprise, qui devra lui survivre.

Il restera toute sa vie un adepte de l'intégration verticale, ou « système fermé », qui veut que son entreprise conçoive tout à la fois de façon exclusive : le matériel, le système d'exploitation qui l'anime, les logiciels, les applications, les périphériques. Cette philosophie débouchant sur des appareils « tout-en-un » qui, reliés entre eux, proposeront l'expérience unique du « foyer numérique », un environnement totalement généré par Apple : une vision que Jobs a dès le début des années 2000.
Tout doit donc être contrôlé à 100 %. L'intérieur (ce qui ne se voit pas et auquel, du premier Macintosh au dernier iPhone, on ne peut pas accéder) doit être aussi parfait que l'extérieur. Il fait par exemple changer les vis du boitier du premier Macintosh afin qu'il soit impossible pour le public de l'ouvrir avec un tournevis conventionnel et refait la même chose vingt-six ans plus tard avec l'iPhone 4. Jobs s'oppose aussi formellement, à quelques années d'écart, à la mise à disposition d'iTunes sur les plates-formes Windows ou à l'ouverture de l'App Store aux développeurs externes qui viendront y déposer leurs créations, et doit à chaque fois être convaincu par ses plus proches collaborateurs, à l'aide d'arguments imparables et dans le dernier cas, à la condition expresse que ce soit Apple qui teste et qui approuve ces « apps » venues de l'extérieur avant de les proposer en ligne.

Sa philosophie consistant à positionner son entreprise et ses productions à la convergence de l'art et de la technologie, Steve Jobs est également littéralement obsédé par le design. Il considère que c'est une absolue priorité, la beauté et la simplicité, stimulé et épaulé dans la deuxième partie de sa carrière chez Apple par le britannique Jonathan Ive, le patron de ce secteur. Une démarche globale, qui va des cordons, adaptateurs électriques ou emballages aux escaliers translucides en colimaçon des Apple Stores, pour le moins couronnée de succès. Mais elle peut aussi conduire en 2010 à l'affaire de lAntennagate", ce premier modèle de l'iPhone 4 qui rencontre des problèmes de réseau quand on le tient d'une certaine façon, car Jobs et Ive ont tenu à ce que son contour soit d'une pureté de ligne parfaite, en aluminium brossé, au détriment du fonctionnement de son antenne, et sans tenir compte des avertissements de leurs ingénieurs à ce sujet. Contraint de réagir par le "buzz" négatif qui enfle dans les semaines suivant la commercialisation de l'appareil, Jobs convoque une conférence de presse où il explique avant tout que les concurrents ne font pas mieux, que le problème a été surestimé par la sphère médiatique, et offre un contour de protection (') à tous les possesseurs de l'appareil.
Il a beaucoup été question de la personnalité agressive et exigeante de Steve Jobs. Le magazine "Fortune" (qui a sacré Jobs « directeur général de la décennie » en novembre 2009) a par exemple écrit qu’il était « considéré comme un des plus grands égotistes de la Silicon Valley ». En 1993, Jobs figure dans la liste des patrons les plus durs de "Fortune", en regard de la façon dont il dirige NeXT. Le cofondateur de cette entreprise, Dan’l Lewin, déclare dans ce même magazine que Steve Jobs, durant cette période, « avait des sautes d'humeur inimaginables ». Jef Raskin, qui fut un temps au début des années 1980 chef de projet pour le Macintosh, a déclaré que Jobs , faisant ainsi allusion à sa personnalité impérieuse et démesurée. Pour ce qui est de son style de management chez Pixar, l’animateur américain Floyd Norman déclare qu’il .

Le biographe autorisé Walter Isaacson, qui publie "Steve Jobs" en 2011, se demande tout au long de son livre si la méchanceté ou la malveillance dont fait parfois preuve son sujet est intentionnelle ou fait simplement partie d’un personnage entier, qui dit ce qu’il pense, pense ce qu’il dit même si cela s'écarte de la réalité, ne s'embarrasse jamais de considérations liées à l’empathie et ne peut pas (ou ne veut pas) contenir ses émotions. Il y a beaucoup d'exemples frappants à ce titre, le plus récent voyant un Steve Jobs très affaibli par la maladie en 2009, trouvant l'énergie de démolir littéralement et publiquement, dans l'auditorium du quartier général de Cupertino, l'équipe du service en ligne MobileMe (lancé en 2008, fermé en 2011) en lui disant et en congédiant sur-le-champ les responsables. 
On apprend aussi que le fondateur d'Apple s'estime souvent au-dessus des lois des hommes, affectant notamment de rouler dans une Mercedes sans plaques d'immatriculation et la garant n'importe où, par exemple sur les places réservées aux handicapés. Dans son ouvrage, Isaacson décrit à plusieurs reprises Steve Jobs comme un personnage qui pour le meilleur ou pour le pire .

Steve Jobs est également un grand fan de musique et, à son panthéon, figurent Bob Dylan dont il collectionne les albums depuis son plus jeune âge et les Beatles. Il se réfère souvent au groupe de Liverpool, notamment au cours de ses ' (en janvier 2007, lorsqu'il présente la fonction iPod du premier iPhone, il joue deux morceaux de ') ou la même année lors de la conférence télévisée "All Things Digital" où il partage le plateau avec Bill Gates et où il choisit un vers de la chanson "" pour décrire avec beaucoup d'émotion leurs tumultueuses relations désormais apaisées : (). 
Il déclare par ailleurs lors de l'émission "60 Minutes" de CBS en 2003 : . À propos de la conception de l'iPhone, il dit aussi : « Jamais je n'avais pris autant de plaisir à travailler sur des détails aussi complexes. C'était comme travailler sur le mixage de "Sgt. Pepper's" ». Il met également, à la fin de sa vie, toute son énergie dans les négociations avec EMI et la compagnie homonyme Apple Corps pour mettre fin au contentieux qui les oppose afin de pouvoir proposer l'œuvre de son groupe favori en téléchargement légal sur iTunes. C'est chose faite le 16 novembre 2010, et Steve Jobs s'occupe personnellement du lancement en grande pompe de cet événement.

Steve Jobs résume sa façon d’être dans son fameux discours à l’adresse des étudiants de l’université de Stanford en 2005 : 

Steve Jobs et Bill Gates, tous deux nés en 1955, sont à l'origine d'un pan entier de l'histoire de la révolution micro-informatique. Ils partagent le fait d'avoir eu très tôt la vision d'un monde où tous les foyers seraient équipés d'un ordinateur et d'avoir été des acteurs majeurs de cette évolution. Là où l'un, intuitif, développe très vite des talents de design, de persuasion et de vente, l'autre, homme d'affaires précoce et avisé, sait aussi programmer, ce qu'il ne manquera jamais de souligner. En janvier 1976, avant même la création d'Apple, Bill Gates écrit une fameuse lettre ouverte au club informatique, dont sont membres Jobs et Wozniak, pour fustiger l'utilisation libre des logiciels (en l'occurrence, son tout récent BASIC), créant un véritable précédent historique dans le monde numérique sur la question de la licence des programmes.

Comme le raconte Andy Hertzfeld, . Mais Apple est déjà sur le devant de la scène lorsque Microsoft balbutie, et c'est Apple qui « met le pied à l'étrier » à la jeune firme de Seattle en lui faisant développer son tableur (Excel) et son traitement de texte (Word) pour le premier Macintosh commercialisé en 1984. Les relations entre les deux patrons vont s'envenimer lorsque Microsoft développe son propre système d'exploitation, Windows, en reprenant le principe développé sur les ordinateurs Apple, l'interface graphique et la souris. Un accord stipulait en effet que Microsoft ne développerait rien dans ce sens pendant un an après la sortie du Macintosh programmée en janvier 1983. Mais l'appareil pommé prend un an de retard et, en novembre de la même année, Gates présente à New York les principes de son nouvel « OS ». Une scène passée à la postérité se déroule alors à Cupertino où Gates est venu seul pour prendre un véritable savon. hurle Jobs. , répond Bill, Bill Gates se trouve être une des très rares personnes totalement insensibles au champ de distorsion de la réalité de Jobs.

Cette histoire, , restera toujours un point d'achoppement entre les deux géants. À la fin de sa vie, Jobs dit encore : , à quoi ce dernier répond : Au cours des années 1990, Windows gagne haut la main la « guerre des systèmes d'exploitation » en atteignant une position quasi hégémonique. Ce qui n'empêche pas Steve Jobs de dire à cette époque : Ils s'opposent en fait sur un principe industriel : la verticalité (le système fermé) prônée par Jobs, et l'horizontalité (la mise en licence des programmes pour tous les appareils), "credo" de Gates. Les relations sont souvent houleuses, comme lorsque Gates, en position de force, refuse de créer le moindre programme pour les ordinateurs NeXT en dénigrant le nouveau produit lancé par Jobs après son départ d'Apple.

Lorsqu'il y revient, en 1997, Jobs décide d'enterrer la hache de guerre, de mettre un terme à une décennie de poursuites judiciaires avec Microsoft, et propose à Gates d'entrer au capital d'Apple en investissant cent cinquante millions de dollars tout en continuant à développer des programmes compatibles pour Apple. Il lui explique qu'en poursuivant les actions en justice pour « vol de brevets », Microsoft pourrait finir par être condamné à verser une véritable fortune à Apple, mais que cette dernière pourrait disparaitre avant cette échéance. L'accord est entériné lors de la ' de la MacWorld Expo de Boston, le 9 juillet 1997, où le patron de Microsoft apparaît en direct sur l'écran géant devant un Jobs du coup tout petit et un public stupéfait, ce qu'il considérera "a posteriori" comme une gaffe magistrale. Les observateurs ne manquent pas en effet de relever l'étonnant parallèle entre le Big Brother fracassé par Apple dans la publicité 1984 et l'apparition de Bill Gates lors de cette '.
Durant les années 2000, chaque entreprise ayant trouvé sa place dominante sur le marché de l'électronique grand public, les relations s'apaisent. Ainsi, lors du forum télévisé "All Things Digital" en mai 2007, les deux hommes qui partagent le plateau de Walt Mossberg se couvrent de louanges. Les yeux dans ceux de son rival historique, Gates déclare : , tandis que Jobs conclut cet entretien avec le vers de "" en écrasant une larme. À l'été 2011, Bill Gates rend une dernière visite à Steve Jobs, dont le cancer est en phase terminale. Ils restent plus de trois heures ensemble à discuter avec beaucoup d'émotion dans le salon de sa maison de Palo Alto, et concluent : , dit Gates. , lui répond Jobs.

Avec les autres grands patrons de l'industrie informatique américaine, Steve Jobs n'est pas toujours tendre. Ainsi, une guerre des mots éclate à la fin des années 1990 avec le constructeur d’ordinateurs Michael Dell. C’est d’abord le patron d’Apple qui qualifie les produits Dell de . Le 6 octobre 1997, lorsque l’on demande à Michael Dell ce qu’il ferait s’il possédait un ordinateur Apple, il répond : En 2006, Jobs envoie un courriel à tous les salariés de sa compagnie, au moment où la capitalisation boursière d'Apple dépasse celle de Dell : 

Son côté rancunier s'exprime aussi lorsqu'il barre l'accès de la technologie Flash d'Adobe à la plate-forme iOS en 2010. Très proche du fondateur de cette entreprise, John Warnock, il avait aidé à la lancer en lui faisant développer Adobe Illustrator pour le Macintosh au début des années 1980. Mais Warnock prend sa retraite et, en 1999, les nouveaux dirigeants refusent d'adapter leurs produits phares, tel Photoshop pour le premier iMac. Dix ans plus tard, Jobs se venge. 

Un de ses plus grands amis de l'industrie informatique est Larry Ellison, le patron fondateur d'Oracle. En 1995, Ellison veut entraîner son ami dans une tentative de putsch contre Apple, en rachetant l'entreprise et en lui donnant dans la foulée 25 % des parts pour lui permettre de reprendre les rênes. Mais Jobs n'est pas chaud. Il n'est pas un partisan de ce genre d'offensive inamicale en bourse. Il veut revenir par la grande porte, ce qu'il fera fin 1996, avant d'inviter Ellison à siéger au conseil d'administration d'Apple. Situé dans le top dix des entrepreneurs les plus nantis au monde, Ellison, qui invite souvent la famille Jobs en croisière sur un de ses luxueux yachts, est surnommé « notre ami riche » par le fils de Steve, Reed Jobs, qui souligne ainsi le refus de son père d'afficher tout signe ostentatoire. Un autre grand ami de Jobs est Millard « Mickey » Drexler, directeur général du fabricant de vêtements Gap quand il lui offre un siège dans ce conseil d'administration d'Apple qu'il taille à sa mesure lors de son retour, à la fin des années 1990. Drexler donne souvent des conseils avisés à Jobs et il dira de lui au moment de sa démission en août 2011 : 

Au début de son parcours d'entrepreneur, l'ennemi s'appelait IBM. Il est ensuite devenu Microsoft. À la fin de sa vie, Steve Jobs va ferrailler contre Google, sur un problème similaire : la naissance d'Android, le système d'exploitation ouvert pour appareils mobiles développé par le géant de Moutain View qui, selon lui, est une honteuse copie d'iOS. Il avait pourtant fait entrer le patron de Google, Eric Schmidt, au conseil d'administration d'Apple, mais en 2010, il lui explique que son entreprise a les mains sales et qu'au lieu de cinq milliards de dollars de dédommagement, il souhaiterait qu'Android cesse de voler ses idées à Apple. Il déclare aussi qu'il est prêt à lancer une guerre thermonucléaire pour détruire le système d'exploitation pour appareils mobiles de Google. Étrange parallèle avec ce qui s'est passé un quart de siècle auparavant avec Windows, et issue identique. Les éventuelles actions en justice sont vouées à l'échec. Pourtant, alors que sa mort approche, lors de son ultime congé maladie en 2011, Steve Jobs reçoit Larry Page à son domicile de Palo Alto. Ce dernier vient de reprendre les rênes de l'entreprise qu'il a cofondée avec Sergey Brin et a sollicité une « audience » pour prendre conseil auprès du patron légendaire. , dit Jobs. Il lui parle de l'importance du recrutement, du fait qu'il faut rester concentré sur pas plus de cinq produits phares car tous les autres « vous tirent vers le bas et, en un rien de temps, on se transforme en Microsoft », et raconte : 

Le sens du design de Steve Jobs a été grandement influencé par le bouddhisme qu’il a expérimenté en Inde lors d’un voyage spirituel de sept mois. Ses capacités intuitives si développées ont également connu l’influence de la spiritualité qu’il a étudiée avec différents maîtres, et selon lui, du LSD.

Au 9 octobre 2011, il est listé comme inventeur ou coinventeur de trois cent quarante-deux brevets américains liés à la technologie, allant des ordinateurs actuels et appareils portables aux interfaces utilisateurs (dont les tactiles), haut-parleurs, claviers, adaptateurs électriques, coffrets, fermoirs, pochettes, cordons et emballages. La plupart de ces brevets ont trait au design, mais quarante-trois d’entre eux sont listés comme des inventions de produits. Celui du nouveau dock du système d’exploitation Mac OS X 10.7 ("Lion") a été validé le jour précédant sa mort.

L'engagement philanthropique de Steve Jobs, comparé à celui de Bill Gates par exemple, est resté très discret. Après avoir quitté Apple et fondé NeXT, il lance la "Steven P. Jobs Foundation", mais l'abandonne un an plus tard. Lors de son retour à la tête d'Apple en 1997, il arrête le programme caritatif de la firme. Cependant, sous l'ère Jobs, Apple participe au programme Product Red en produisant des modèles rouges de ses iPods dont une partie des profits générés sont reversés au Fonds mondial de lutte contre le sida, la tuberculose et le paludisme, faisant d'Apple son contributeur le plus important. Son non-ralliement à The Giving Pledge, mouvement philanthropique lancé par Bill Gates et Warren Buffett en juin 2010, n'est pas passé inaperçu. Ces derniers invitaient les plus fortunés du pays à prendre l’engagement moral — et public — de destiner une grande partie de leur fortune à la philanthropie. Après une critique au sujet de sa philanthropie dans "The New York Times", Bono, l'un des fondateurs de (RED), prend sa défense en rapportant que, lorsqu'il a approché Steve Jobs au sujet de la marque (RED), il aurait dit : 

Les parents biologiques de Steve Jobs se rencontrent à l'université du Wisconsin. Abdulfattah « John » Jandali, un syrien musulman, y fait ses études en sciences politiques puis les enseigne fin des années 1960 à l'université du Nevada à Reno. Rapidement, il se reconvertit dans la restauration en rachetant un restaurant dans cette même ville. Il est, depuis 2006, vice-président de l'hôtel-casino Boomtown, toujours à Reno. En décembre 1955, dix mois après avoir donné leur enfant à l'adoption, Joanne Carole Schieble et Adbulfattah se marient. En 1957, ils ont ensemble une fille, Mona. Après leur divorce, en 1962, Jandali perd le contact avec sa fille. Schieble quant à elle se remarie et Mona prend alors le nom de son beau-père et devient ainsi connue sous le nom de Mona Simpson.

Dans les années 1980, Steve Jobs retrouve sa mère biologique Joanne qui lui révèle qu'il a une sœur biologique, Mona Simpson. Ils se rencontrent pour la première fois en 1985 et deviennent de proches amis. Mona décide par la suite de partir à la recherche de son père, elle le retrouve alors qu'il dirige un petit restaurant à Sacramento. Sans savoir ce que son fils est devenu, Jandali raconte à sa fille qu'il a, par le passé, dirigé un grand restaurant dans la Silicon Valley où même Steve Jobs est venu manger. . Lors d'une de ses interviews enregistrées avec son biographe Walter Isaacson, Steve Jobs dit : En parlant de ses parents, Steve déclare : Jandali rapporte, lui, de son côté au "Sun" que ses efforts pour contacter Jobs ont été vains.

La première fille de Steve Jobs, Lisa Brennan-Jobs, naît en 1978 de sa relation avec sa petite amie de l'époque, . Pendant deux ans, elle élève l'enfant seule alors que Jobs nie en être le père, prétendant qu'il est stérile. À la même époque, il lance l'ordinateur Lisa. Par la suite, au moment de l'introduction en bourse d'Apple et sous la pression de ses associés, il finit par reconnaître Lisa comme sa fille, et elle viendra vivre à ses côtés pendant quatre ans lors de son adolescence avant d'aller poursuivre ses études à Harvard.

En 1982, il rencontre la chanteuse Joan Baez avec qui il entretient une relation. Pour Elizabeth Holmes, l'amie de Steve Jobs depuis les années Reed, la principale raison de son intérêt pour Joan — hormis le fait qu'elle est belle, drôle et talentueuse — est qu'elle a eu une liaison avec Bob Dylan. Après s'être posé la question d'un hypothétique mariage avec cette femme, plus vieille que lui et qui ne voudrait probablement plus d'enfants, ils mettent fin à leur relation après trois ans. Steve Jobs passe les années suivantes auprès de Tina Redse, qui se trouve à ses côtés au moment où il doit quitter Apple en 1985, et qui restera sa petite amie jusqu'à sa rencontre avec Laurene Powell.

Steve Jobs se rend à la "" pour y donner une conférence en octobre 1989. Il y rencontre donc une autre femme, Laurene Powell, qui y poursuit des études. Ils échangent leurs numéros de téléphone, il repart, puis il raconte, dix ans plus tard : Le 18 mars 1991, Steve (36 ans à l'époque) se marie avec Laurene (27 ans), lors d'une cérémonie au Ahwahnee Hotel dans le Parc national de Yosemite. Le mariage est présidé par le moine bouddhiste zen Kobun Chino Otogawa. Le premier enfant issu de cette union, Reed, voit le jour en septembre 1991, puis naissent ses sœurs Erin en août 1995 et Eve en 1998. La famille vit depuis à Palo Alto.

Il a commandé à l'architecte Philippe Starck la construction d'un yacht de de long, "Venus", qui ne sera achevé qu'après sa mort.

En octobre 2003, les médecins apprennent à Steve Jobs qu'il est atteint d'un cancer. Il ne révèle sa maladie à ses employés et au grand public qu'en août 2004, après avoir subi une intervention pour faire retirer une tumeur cancéreuse de son pancréas. Jobs est atteint d'une forme relativement rare de tumeur, plus simple à traiter, une « tumeur neuroendocrinienne des îlots de Langerhans ». Dans un premier temps, et malgré le diagnostic des médecins, il va à l'encontre de leurs recommandations en refusant de subir une intervention chirurgicale. Il lui préfère un régime alimentaire végétarien strict avec une grande quantité de carottes et de jus de fruits frais, des séances d'acupuncture et divers remèdes à base de plantes. C'est seulement au bout de neuf mois, après que sa femme et ses amis ont tenté de le raisonner et qu'il apprend que la tumeur a encore grossi, qu'il décide de se faire opérer. Il subit alors une opération de Whipple au Stanford University Medical Center le 31 juillet 2004, tandis que Tim Cook le remplace à la tête d'Apple. Dans la foulée, il annonce dans un courriel à ses employés qu'il est guéri, qu'il n'a pas besoin de subir une chimiothérapie ou une radiothérapie et qu'il reprendra le travail en septembre. La vérité est différente, mais elle restera bien cachée : lors de l'opération, les médecins ont découvert des métastases au foie. Il évoque publiquement cet épisode lors de son discours à l'adresse des étudiants de Stanford le 12 juin 2005

Début août 2006, Steve Jobs est sur la scène de l'annuel ' pour une de ses traditionnelles '. Son extrême minceur, son apparence décharnée et sa présentation inhabituellement apathique, ajoutées à son choix de déléguer une partie importante de cette ' à ses principaux collaborateurs, alimentent un florilège de commentaires dans la presse et sur internet à propos de son état de santé. Pourtant, selon un article de lArs Technica journal", les participants à cette WWDC qui ont rencontré Jobs en personne déclarent qu'il « a l'air de bien se porter ». Un porte-parole d'Apple souligne pour sa part que « la santé de Steve est robuste ».

Deux ans plus tard, en février 2008, les rumeurs repartent de plus belle après la ' de Steve Jobs au WWDC 2008. Les responsables d'Apple déclarent qu'il est victime d'un « problème courant » et qu'il prend des antibiotiques, tandis que l'on conjecture sur son extrême pâleur qui serait due aux conséquences de l'opération de Whipple qu'il a subie. Les rumeurs ne se trompent pas, les médecins constatent que son cancer se propage. Il a par ailleurs de plus en plus de mal à s'alimenter. Mais le secret reste bien gardé. Durant une conférence téléphonique de présentation des revenus d'Apple, en juillet 2008, les participants doivent répondre à une série de questions tournant autour de la santé de leur patron et insistent sur le fait qu'il s'agit d'une « affaire privée ». Le ' publie à ce moment un article où il explique que le cancer de Jobs « n'a pas connu de récurrence ».

Le 28 août 2008, l'agence Bloomberg publie par erreur une nécrologie de Steve Jobs de deux mille cinq cents mots dans son fil d'informations qui comprend des blancs sur son âge et la cause de sa mort (le fait est que les agences de presse gardent toujours sous la main des nécrologies préparées afin de réagir rapidement lors de la disparition de personnages célèbres). Bien que cette erreur soit rapidement rectifiée, la nouvelle est reprise dans la presse et sur internet. Steve Jobs apporte sa réponse au siège d'Apple lors de la "keynote Let's Rock" en septembre, choisissant de citer Mark Twain : Plus tard, lors d'un nouvel événement médiatique, Steve Jobs conclut sa présentation en affichant sur l'écran géant une diapositive sur laquelle est inscrit « 110/70 », c'est-à-dire l'état de sa pression artérielle, expliquant par ailleurs qu'il n'acceptera aucune question supplémentaire sur sa santé.

Le 16 décembre 2008, Apple annonce que le vice-président chargé du marketing, Phil Schiller, se chargera de la "" au Macworld Conference and Expo 2009, ce qui relance à nouveau les spéculations sur la santé de Jobs. Ce dernier explique sur une page publiée le 5 janvier 2009 sur le site apple.com qu'il souffre d'un « déséquilibre hormonal » depuis plusieurs mois. 
Le 14 janvier 2009, dans une note interne à Apple, Steve Jobs écrit que, durant les semaines précédentes, il a « appris que mes problèmes de santé étaient plus complexes que ce que je croyais » et annonce un congé maladie de six mois, jusqu'à la fin juin 2009, pour lui permettre de mieux se concentrer sur sa santé. Tim Cook prend à nouveau les rênes de la compagnie tandis que Jobs reste impliqué dans les « décisions stratégiques majeures ». En avril 2009, il subit une greffe du foie au Methodist University Hospital Transplant Institute de Memphis, Tennessee. Le pronostic vital pour Jobs est à ce moment déclaré « excellent ».

Le , un an et demi après son retour consécutif à sa greffe du foie, Apple annonce qu'il prend un nouveau congé maladie. Jobs écrit à ses collaborateurs pour expliquer qu'il a pris cette décision, à nouveau, pour se concentrer sur sa santé. Comme en 2004 et en 2009, Tim Cook reprend son poste de directeur-général opérationnel tandis que Jobs continuera à superviser les décisions stratégiques majeures de l'entreprise. Malgré ce nouveau congé maladie, Steve Jobs apparaît lors du lancement de l' (le ), lors de la "" où est présenté le service iCloud (le ) et, enfin, devant le conseil municipal de la ville de Cupertino (le ), sa dernière apparition publique et télévisée où il présente le nouveau projet de campus géant d'Apple, un énorme bâtiment en forme d'anneau circulaire entouré de verdure qui doit abriter douze mille employés. 
Steve Jobs annonce finalement sa démission de son poste de directeur général d'Apple le . « Malheureusement, ce jour est arrivé », écrit-il, car il ne « peut plus, désormais, assumer [ses] fonctions et [ses] attentes en tant que directeur général d'Apple. » Il devient le président du conseil d'administration d'Apple et nomme Tim Cook comme son successeur. Steve Jobs continue à travailler pour l'entreprise qu'il a fondée jusqu'à la veille de sa mort.

Steve Jobs meurt le 5 octobre 2011 vers 15 heures (heure locale), dans son domicile de Palo Alto en Californie, des complications engendrées par la récidive de son cancer pancréatique neuroendocrinien, résultant en un arrêt respiratoire. L'annonce de sa mort est faite par Apple sous la forme d'un communiqué de presse. Sa famille déclare dans un communiqué distinct : .

Selon sa sœur Mona Simpson, présente à ses côtés, Steve . Ses derniers mots, prononcés plusieurs heures avant sa mort, ont été .

Pendant les deux semaines qui suivent sa disparition, le site web d'Apple affiche une page d'accueil sobre, comportant une photo de lui en noir et blanc, son nom ainsi que ses dates de naissance et de mort. L'hyperlien de l'image mène vers une nécrologie qui rend hommage à un visionnaire et à un génie créatif. Une adresse de courriel en fin de page permet d'adresser des condoléances, mémoires et pensées qui sont maintenant affichées sur sa page commémorative. Apple annonce avoir reçu plus d'un million de courriels à cette adresse.
La mort de Steve Jobs déclenche aux États-Unis mais aussi dans le monde entier une importante vague d'émotion. Devant tous les Apple Store du monde, la foule se presse pour déposer des fleurs, des mots de condoléance, des pommes, des appareils tactiles de la marque qui affichent des chandelles. De nombreuses personnalités, plus ou moins proches de lui, lui rendent également hommage. C'est, par exemple, le cas du président des États-Unis Barack Obama, de Bill Gates du PDG de The Walt Disney Company Robert Iger, de Steve Wozniak, de Mark Zuckerberg ainsi que d'autres grandes figures de la Silicon Valley, tout comme de nombreuses personnalités du monde du spectacle, de la politique, de l'industrie et des médias.

Ses obsèques se déroulent le 7 octobre 2011 lors d'une petite cérémonie privée dont les modalités n'ont pas été révélées par respect envers la famille Jobs. 

Après avoir fondé Apple, Steve Jobs devient un symbole pour sa firme mais aussi l'industrie informatique. Lorsque "", en 1982, nomme l'ordinateur homme de l'année, le magazine publie un long profil de Steve Jobs en l'appelant 

En 1985, le président Ronald Reagan remet à Steve Jobs et à son collègue Steve Wozniak la . Ils sont parmi les premiers à recevoir cette décoration.

En novembre 2007, le magazine "Fortune" lui donne le titre de d'. En novembre 2010, le magazine "Forbes" le classe dix-septième dans son classement des personnes les plus puissantes. En décembre 2010, le "Financial Times" nomme Jobs personnalité de l'année et conclut son article sur une déclaration de John Sculley en 1987, évoquant les ambitions de l'homme qu'il a évincé : et le journaliste y ajoute de façon rhétorique : .

Le magazine américain "TIME" lui consacre sa une de couverture le avec une photographie du Suisse Marco Grob.

Au moment de sa démission puis de nouveau après sa mort, Steve Jobs est décrit par beaucoup comme un visionnaire, un pionnier et un génie. Il est parfois considéré comme le Thomas Edison et le Henry Ford de son époque. « Nous nous sommes rencontrés il y a plus de trente ans et avons été collègues, rivaux et amis durant plus de la moitié de nos vies. Le monde a rarement vu des personnes qui ont eu autant d'impact que Steve, dont les effets se ressentiront encore pour plusieurs générations à venir. Pour ceux qui ont eu la chance de travailler avec lui, cela a été un incroyable honneur. Il me manquera terriblement » dit Bill Gates. « Merci pour avoir été un mentor et un ami. Merci de nous avoir montré que ce que l'on crée peut changer le monde », déclare Mark Zuckerberg. « Un des plus grands innovateurs américains, assez courageux pour penser différemment (« "Think different" »), assez audacieux pour croire qu'il pouvait changer le monde, et assez talentueux pour le faire », dit de lui le président des États-Unis Barack Obama.

Le 21 décembre 2011, la société Graphisoft dévoile à Budapest la première statue en bronze au monde de Steve Jobs.

L'histoire d'un entrepreneur qui révolutionna de manière durable le monde technologique malgré les nombreux obstacles sur sa route est un sujet qui attire les producteurs hollywoodiens, friands des "success-stories".

"Les Pirates de la Silicon Valley" est un téléfilm de Martyn Burke réalisé en 1999. Il relate les débuts de la micro-informatique individuelle aux États-Unis du début des années 1970 à la fin des années 1980 et met en scène la rivalité entre les célèbres duos Steve Jobs et Steve Wozniak, et William Henry "Bill" Gates III et Paul Allen. Steve Jobs y est interprété par Noah Wyle. Le narrateur de ce téléfilm est Steve Ballmer, joué par John DiMaggio.

Un biopic indépendant, "Jobs", est sorti à l'été 2013. Réalisé par Joshua Michael Stern, le film se concentre sur la naissance d'Apple, l'épisode de NeXT et s'achève avec la présentation de l'iPod. Steve Jobs est incarné par Ashton Kutcher, Steve Wozniak est joué par Josh Gad. La critique est très médiocre (y compris sur l'interprétation de Kutcher), le film est un échec au box-office.

Un autre film est développé en parallèle par Sony Pictures Entertainment. Ce biopic est plus exhaustif que le premier, en se basant sur la biographie de Walter Isaacson. Le film est réalisé par Danny Boyle et écrit par Aaron Sorkin (notamment scénariste du film "The Social Network", autre biopic sur une star des nouvelles technologies). Seth Rogen est sélectionné pour être l'interprète de Wozniak. Le rôle principal, d'abord proposé à Leonardo DiCaprio et à Christian Bale, qui l'ont tour à tour refusé, revient finalement à Michael Fassbender. Cependant, en novembre 2014, Sony Pictures renonce à produire ce film et le traitement du film est mis en vente. Le projet est ensuite relancé par Universal Pictures. Le film, simplement intitulé "Steve Jobs", est tourné au cours de l'année 2015 et sorti le en France. Il tourne autour de trois présentations majeures qui ont ponctué la carrière de Jobs (celle du Macintosh 128K en 1984, du NeXT Computer en 1988 et de l'iMac en 1998), et se penche principalement sur ses relations avec sa fille Lisa Brennan-Jobs.






</doc>
<doc id="2756" url="https://fr.wikipedia.org/wiki?curid=2756" title="Système international d'unités">
Système international d'unités

Le Système international d'unités (abrégé en SI), inspiré du système métrique, est le système d'unités le plus largement employé au monde (il n'est pas officiellement utilisé aux États-Unis, au Liberia et en Birmanie). Il s’agit d’un système décimal (on passe d’une unité à ses multiples ou sous-multiples à l’aide de puissances de 10) sauf pour la mesure du temps et d'angle. C’est la Conférence générale des poids et mesures, rassemblant des délégués des États membres de la Convention du Mètre, qui décide de son évolution, tous les quatre ans, à Paris. L’abréviation de « Système international » est SI, quelle que soit la langue utilisée.

La norme internationale ISO 80000-1:2009 décrit les unités du Système international et les recommandations pour l’emploi de leurs multiples et de certaines autres unités.

Le Système international compte sept unités de base, censées quantifier des grandeurs physiques indépendantes possédant chacune un symbole :
De ces unités de base on déduit des unités dérivées, par exemple l'unité de vitesse du Système international, le mètre par seconde. Certaines de ces unités possèdent un nom particulier.

Il existe également des préfixes officiels permettant de désigner les unités multiples et sous-multiples d'une unité. Par exemple, le sous-multiple du mètre valant est appelé centimètre (symbole cm) puisque le préfixe correspondant à 10 est "centi-".

Les principes de l'écriture des nombres, des grandeurs, des unités et des symboles forment ce que l'on peut appeler la « grammaire » de ces moyens d'expression. Les références normatives sont le Bureau international des poids et mesures, la norme internationale , le fascicule de documentation de l'AFNOR : de mai 2013.

Les unités ne peuvent être désignées que par leur nom (pouvant varier d'une langue à une autre), ou par leur symbole (international, indépendant de la langue utilisée). Il ne faut pas mélanger les symboles (entités mathématiques) et les noms des unités ; ainsi on écrira toujours « newton par kilogramme » (ou N/kg) et jamais « newton par kg », ni « newton/kg », ni « newton/kilogramme », ni « km/heure ». Sont prohibées les abréviations telles que « sec » pour la seconde (s), « mn » pour la minute (min) ou « cc » pour le centimètre cube (cm).

Les symboles des unités (et uniquement les symboles) commencent par une majuscule si l'unité dérive d'un nom propre, et une minuscule dans le cas contraire. Ainsi, on peut comparer les symboles du pascal (Pa) et de la seconde (s). La seule exception à cette règle est le symbole du litre, qui peut s'écrire au choix « l » ou « L », pour éviter les confusions avec le ou la majuscule (I) selon les polices de caractères utilisées. Les symboles des unités sont toujours écrits en caractères romains quelle que soit la police du texte où ils figurent : ils ne sont pas mis en italique ni suivis d'un point. Ils constituent des entités mathématiques et non des abréviations ; ainsi on écrit « » et non pas 

Toutes les unités, toujours à droite de la valeur, sont par conventions séparées de la valeur par une espace insécable (exceptions faites des symboles des unités sexagésimales d'angle, exemple : (symboles prime ′ pour les minutes et double prime ″ pour les secondes) et des degrés d'alcool, exemple : alcool à 90°). Ainsi, on écrit « » mais pas ; de même, on écrira « » mais pas ni « 30,2 ° C », le symbole °C étant composé du « ° » et du « C » qui sont, eux deux, indissociables.

Le nom des unités écrit en entier est quant à lui un nom commun : même si l'unité dérive d'un nom propre, la première lettre du nom d'une unité est donc toujours une minuscule (contrairement à son symbole) ; en toutes lettres, le nom d'une unité prend la marque du pluriel. On écrit ainsi trois ampères, deux teslas.

Note : contrairement au cas du kelvin, le nom du degré Celsius (°C) est composé, c'est la première lettre du mot « degré » qui prend la minuscule et la marque du pluriel : on écrit « deux degrés Celsius ».

Les notations de la division et de la multiplication s'appliquent aux symboles des unités dérivées : ainsi on peut écrire le symbole du mètre par seconde m⋅s ou m/s et celui du kilowatt-heure kWh ou kW⋅h. Lorsque deux unités sont multipliées on utilise, entre les symboles, un point à mi-hauteur [⋅], conformément à l'usage international et à la place du point sur la ligne [.]. En ce qui concerne la division, tout ce qui est affecté d'un exposant négatif est énoncé à la suite de la barre oblique ou du mot « par » : ainsi, l'unité SI de vitesse est le mètre par seconde (m/s), la forme « mètre seconde » étant incorrecte (elle désignerait le produit d'une distance par un temps). Pour éviter les notations ambiguës, on n'utilise jamais plus d'une barre oblique dans le symbole d'une unité (sinon A/m/s pourrait être le symbole de l'ampère par mètre par seconde, A⋅m⋅s, ou celui de l'ampère seconde par mètre, A⋅s⋅m ou A⋅s/m). Ainsi la conductivité thermique s'exprime par le watt mètre par mètre carré kelvin, , ou par le watt par mètre kelvin, . En cas de produit d'unités, on utilise un tiret ou une espace dans le nom de l'unité dérivée. Ainsi, les bonnes orthographes de l'unité dont le symbole est kWh sont kilowatt-heure et kilowatt heure. Dans ces deux cas, chacun des noms d'unités prend la marque du pluriel : kilowatts-heures ou kilowatts heures. En l'absence de trait d'union ou d'espace, seul le deuxième nom d'unité prend la marque du pluriel : wattheures, voltampères. Quand une même unité entre plusieurs fois dans un produit, on peut l'énoncer en faisant suivre son nom selon le cas, des adjectifs « carré », « cube » ou « bicarré », ou des expressions « au carré », « au cube » ou « à la puissance "n" » : 

Aucune adjonction au symbole d'une unité pour donner une information concernant la nature particulière de la grandeur ou le contexte de mesurage considéré n'est permise : et non (« tension efficace exprimée en volts » et non « volts efficaces »). De même, l'appellation « mètre linéaire » ne doit pas être employée, l'adjectif « linéaire » n'apportant aucune notion supplémentaire à l'unité.

Pour former les noms des unités multiples et sous-multiples, des préfixes du Système international sont simplement accolés (sans espace ni tiret) à gauche de l'unité, toujours sans mélanger les symboles (entités mathématiques) et les noms des unités et préfixes : kilomètre (ou km), milliseconde (ou ms). On ne peut pas accoler plusieurs préfixes à une unité (nanomètre mais pas millimicromètre). Ainsi, même si le décanewton (daN) est une unité correcte (qui traduit approximativement l'ancien kilogramme-force), le kilodécanewton (kdaN, qui traduirait la tonne-force) ne l'est pas. De même, un hectopascal (hPa) est un multiple correct de l'unité dérivée, le pascal, mais le kilohectopascal (khPa, qui correspond sensiblement à une pression d'une atmosphère) ne l'est pas.

Note : dans le cas du kilogramme, unité de base qui pour des raisons historiques comporte dans son nom le préfixe « kilo », les multiples et sous-multiples restent formés sur le gramme.

La première tentative notable d'établir des unités universelles (c'est-à-dire fondées sur des phénomènes physiques reproductibles) est, dans le monde anglo-saxon, celle de John Wilkins, un scientifique anglais membre de la , qui définit en 1668 une longueur puis un volume universel et enfin une masse universelle (celle de la quantité d'eau de pluie contenue dans un cube de côté valant la longueur universelle). La longueur universelle ainsi définie est prise comme valant (approximativement ) soit environ celle d'un pendule simple dont la demi-période des petites oscillations est d'une seconde.

Vers 1670 Gabriel Mouton, religieux lyonnais, propose une unité de longueur en se basant sur la mesure d'un arc de méridien terrestre. Il définit aussi la série de multiples et sous-multiples d'unité basée sur le système décimal.

En 1675, le savant italien Tito Livio Burattini renomme la mesure universelle de John Wilkins en « mètre » () et en prend pour définition exacte celle du pendule précédemment décrit (et non plus celle de ), aboutissant ainsi à une longueur de . Cette valeur dépend cependant de l'accélération de la pesanteur et varie donc légèrement d'un lieu à l'autre.

En 1790, l’Assemblée nationale constituante se prononce, sur proposition de Talleyrand, lui-même conseillé par Condorcet, pour la création d'un système de mesure stable, uniforme et simple, et c'est l'unité de Burattini qui est d'abord adoptée comme unité de base. Mais du fait que la longueur du pendule battant la seconde n’est pas la même selon l’endroit où l'on se trouve, en raison de la différence de gravité selon la distance avec l'équateur (voir "supra"), c’est finalement la dix-millionième partie d'un quart de méridien qui est choisie provisoirement en 1793. Deux savants sont chargés d'effectuer les mesures géodésiques nécessaires, Delambre et Méchain, lesquels vont, durant sept ans, mesurer la distance entre Dunkerque et Barcelone.

Avec le mètre sont définies les unités de volume et de masse : on crée ainsi le système métrique décimal, permettant de convertir plus aisément les unités puisque, désormais, pour passer d'une unité à ses multiples (et sous-multiples), il suffit de déplacer la virgule. La même année, la Convention nationale prévoit la création d'étalons pour le mètre et le grave (nom original du kilogramme). La définition ainsi choisie est définitivement adoptée le () par décret de la Convention nationale française. Ce système métrique est alors désigné par le sigle MKpS, pour mètre, kilogramme-poids, seconde.

Les étalons du mètre et du grave, en platine, prévus par les décrets de la Convention nationale sont déposés aux Archives nationales de France le (), ce qui est parfois considéré comme l’acte fondateur du système métrique.

Introduit par la loi du (), le système métrique est rendu obligatoire en France à l’occasion de son cinquième anniversaire par l'arrêté du (), l'emploi de tout autre système étant interdit. Dans ses mémoires de Sainte-Hélène, Napoléon, qui avait naguère soutenu l'expédition géodésique en vue de déterminer la nouvelle mesure, mais pris conscience de la difficulté d'acclimatation à de nouvelles unités, écrit :

Dès 1801, la République helvétique tenta d'introduire le système métrique, « mais la loi ne fut jamais appliquée » — il fallut attendre 1877. C'est le Royaume-Uni des Pays-Bas (comprenant les actuels Pays-Bas, la Belgique et une partie du Luxembourg) qui l'adopte à nouveau le premier en 1816, sur l'impulsion de son souverain Guillaume des Pays-Bas, quatorze ans avant la révolution française de 1830, qui signe sa réintroduction en France.

Le , Napoléon prit un décret impérial instaurant pour le commerce de nouvelles unités au nom conforme à l'usage ancien, comme "aune, toise, boisseau, livre", mais avec de nouvelles valeurs fixées en référence au système métrique, et surtout, autorise pour ces nouvelles unités des fractions non décimales. 

Après la Restauration française en 1814, confirme dans un premier temps vouloir poursuivre l'établissement du système métrique, mais sous la pression des plaintes, un arrêté ministériel du ordonne la suppression des fractions décimales des poids et mesures, et l'emploi exclusif des mesures « usuelles » pour la vente au détail des denrées et marchandises. 

Le système métrique ne fut néanmoins pas abandonné dans l'enseignement, et petit à petit, on prit conscience qu'il était temps de renoncer aux facilités introduites par le décret de 1812 et de s'en tenir aux unités légales établies par l'arrêté du . Ce sera l'objet de la loi du signée par Louis-Philippe, qui rend obligatoire l'usage des unités du système métrique à partir du , dans le commerce et dans la vie civile et juridique.

En 1832, Gauss travaille pour l'application du système métrique comme système d'unités cohérent en sciences physiques. Il établit des mesures absolues du champ magnétique terrestre en utilisant un système d'unités fondé sur les unités centimètre, gramme et seconde parfois appelé « Système de Gauss ».

Dans les , Maxwell et Kelvin s’impliquent au sein de la (BA), fondée en 1831, pour la mise en place d'un système d'unités composé d'unités de base et d'unités dérivées. Ceci aboutit en 1874 à la création du « système CGS » fondé sur les unités centimètre, gramme et seconde.

Dans les , la BA et le Congrès international d’électricité, ancêtre de la Commission électrotechnique internationale, s’accordent sur un système d'unités pratiques, parmi lesquelles l’ohm, le volt et l’ampère.

La Convention du Mètre est créée en 1875 et instaure le Bureau international des poids et mesures (BIPM), le Comité international des poids et mesures (CIPM) et la Conférence générale des poids et mesures (CGPM). La première CGPM a lieu en 1889 et adopte de nouveaux prototypes pour le mètre et le kilogramme. Le système d'unités consacré est donc le « système MKS », du nom de ses unités de base, le mètre, le kilogramme et la seconde.

En 1901, le physicien Giovanni Giorgi avait montré qu'il était possible de combiner les unités électriques à celles du système MKS en ajoutant à ce dernier une unité électrique. La discussion de cette proposition par des organisations internationales parmi lesquelles l'Union internationale de physique pure et appliquée (IUPPA) et la Commission électrotechnique internationale aboutit en 1946 à l'adoption par le CIPM du « système MKSA », fondé sur le mètre, le kilogramme, la seconde et l'ampère. En 1954, après une enquête du BIPM ayant commencé en 1948, la CGPM entérine l'adoption des unités de base supplémentaires que sont le kelvin et la candela.

Il reste alors peu d'étapes avant l'achèvement du système métrique tel que nous le connaissons. Tout d'abord, lui donner son nom actuel (« Système international d'unités », avec comme abréviation internationale « SI »). C'est chose faite en 1960. Ensuite, lui adjoindre comme dernière unité la mole, ce qui est fait en 1971.

La plupart des pays du monde ont fait du Système international leur système officiel d'unités. En Asie de l'Est, ce fut au début du . Durant les , le gouvernement du Canada procède à la conversion au système métrique, sous l'égide de la Commission du système métrique. Cette action (passer officiellement d'un système d'unités national au système métrique) s'appelle métrification.

En 2008, seuls trois pays dans le monde n'ont pas officiellement adopté le Système international : les États-Unis, le Libéria et la Birmanie. Cependant, aux États-Unis, signataire de la Convention du Mètre, l'usage du système métrique est licite depuis 1866. Le système métrique est le système de référence depuis le , le système recommandé par le de 1975, confirmé en 1988 par le , et il est de plus en plus répandu parmi les scientifiques, la médecine, le gouvernement, et plusieurs secteurs de l'industrie.


À cette liste, il faut également ajouter les domaines (aviation, navigation) dans lesquels . Il convient toutefois de bien faire la différence entre l'obligation légale et la tolérance ; de la même manière qu'en France on distingue le droit coutumier, l'usage, et les textes de loi.


La plupart des unités de mesures non métriques sont maintenant définies à partir des unités du Système international. Par exemple, le édite une table des définitions des unités de mesure anglo-saxonnes à partir des unités métriques.




</doc>
<doc id="2757" url="https://fr.wikipedia.org/wiki?curid=2757" title="Seconde Guerre mondiale">
Seconde Guerre mondiale

La Seconde Guerre mondiale ou Deuxième Guerre mondiale est un conflit armé à l'échelle planétaire qui dura du au . Ce conflit opposa schématiquement deux camps : les Alliés et l’Axe.

Provoquée par le règlement insatisfaisant de la Première Guerre mondiale et par les ambitions expansionnistes et hégémoniques des trois principales nations de l’Axe (Allemagne nazie, Italie fasciste et Empire du Japon), elle fut favorisée par la convergence, à partir du , d’un ensemble de conflits régionaux respectivement amorcés le en Espagne (la guerre d'Espagne), le en Chine (la guerre sino-japonaise), et le en Pologne (l'agression allemande contre la Pologne). C'est ce dernier évènement qui provoqua l'entrée en guerre de la France et du Royaume-Uni, et de leurs empires coloniaux respectifs, dès le .

Tout d'abord associée à l'Allemagne dans le partage de l'Europe, l'URSS rejoint le camp allié à la suite de l'invasion allemande le . Quant aux États-Unis, ils abandonnent leur neutralité après l'attaque de Pearl Harbor le . Dès lors, le conflit devient vraiment mondial, impliquant toutes les grandes puissances, et la majorité des nations du monde sur la quasi-totalité des continents.

La Seconde Guerre mondiale prend fin sur le théâtre d'opérations européen le par la capitulation sans condition du Troisième Reich, puis s’achève définitivement sur le théâtre d'opérations Asie-Pacifique le par la capitulation également sans condition de l'Empire du Japon, dernière nation de l’Axe à connaître une défaite totale.

La Seconde Guerre mondiale constitue le conflit armé le plus vaste que l’humanité ait connu, mobilisant plus de de combattants de , déployant les hostilités sur quelque , et tuant environ de personnes, dont une majorité de civils. N’opposant pas seulement des nations, la Seconde Guerre mondiale fut aussi la plus grande guerre idéologique de l’Histoire, ce qui explique que les forces de collaboration en Europe et en Asie occupées aient pu être solidaires de pays envahisseurs ou ennemis, ou qu’une résistance ait pu exister jusqu’en plein cœur de l’Allemagne nazie en guerre. Guerre totale, elle gomma presque totalement la séparation entre espaces civils et militaires et vit, dans les deux camps, la mobilisation poussée non seulement des ressources matérielles – économiques et scientifiques – mais aussi morales et politiques, dans un engagement des sociétés tout entières.

La somme des dégâts matériels n’a jamais pu être chiffrée avec certitude. Les pertes en vies humaines et les traumatismes collectifs et individuels ne furent pas moins considérables, la violence ayant pris des proportions inédites. Le conflit donna lieu à de multiples crimes de guerre, qui ne furent l'apanage d'aucun camp, crimes s'insérant dans une violence militaire et policière d'une intensité et d'une profondeur inégalées, cette violence notamment contre les civils étant parfois un élément de la stratégie militaire. On assista ainsi à l'émergence à une échelle inconnue jusqu'alors de crimes de masse particulièrement atroces et pour certains sans précédents, tout particulièrement à l'instigation de l'Allemagne nazie et du Japon impérial. Parmi ces crimes figure la déportation en camps de concentration, camps de travail et camps d'extermination, comportant des chambres à gaz à des fins d’extermination de populations entières (Juifs, Slaves, Tziganes) ou de catégories particulières d’individus (homosexuels, handicapés, etc.) commandée par le régime nazi. L'ampleur des crimes suscita la définition d'une incrimination nouvelle : le crime contre l'humanité, appliquée notamment au génocide des juifs d'Europe. Le régime Shōwa ne fut nullement en reste en Asie avec, à son actif, dix millions de civils chinois enrôlés de force par la "Kōa-in" au Mandchoukouo, environ « femmes de réconfort » enrôlées en Corée et dans tout l’Extrême-Orient, ainsi que l’annihilation systématique de populations civiles, principalement en Chine et notamment lors du massacre de Nankin.

Il faut ajouter à cela l'assassinat systématique de résistants et d'opposants politiques, ainsi que les représailles contre les civils, comme le firent par exemple les nazis ; les viols généralisés des femmes dans les territoires ennemis occupés, crimes perpétrés tant par un camp que par l'autre, et à une moindre échelle dans les territoires amis ; les expérimentations sur des êtres humains auxquelles se livrèrent des médecins nazis, tels le SS Josef Mengele et l’unité japonaise 731 ; les bombardements aériens massifs de civils d’abord par l’Axe en Europe (Coventry en Angleterre, Rotterdam aux Pays-Bas) et en Asie (Shanghai, Guangzhou, Chongqing, cette dernière étant la ville la plus bombardée du conflit sino-japonais), puis par les Alliés : Dresde et Hambourg en Allemagne, Tokyo avec du napalm au Japon. Pour la première fois, la bombe atomique fut utilisée contre un pays : deux larguées sur des cibles civiles par les États-Unis ont explosé à trois jours d’intervalle, à Hiroshima et à Nagasaki, au Japon.

La Seconde Guerre mondiale propulse les États-Unis et l’URSS, principaux vainqueurs, au rang de superpuissances concurrentes appelées à dominer le monde et à se confronter dans une vive rivalité idéologique et politique, pendant près d'un demi-siècle, et à s'affronter militairement par États interposés comme en Corée, au Viêt Nam, en Afghanistan. Elle scelle le déclin des vieilles puissances impériales d’Europe et ouvre le processus de décolonisation qui s’accélère dans l'après-guerre en Asie, dans le monde arabe et en Afrique, jusqu'aux années 1960. L'ampleur des destructions et des morts suscite la création d'instances internationales, politiques et économiques, visant à éviter la réapparition des conditions ayant mené à la guerre (Organisation des Nations unies, Fonds monétaire international, Banque mondiale et Accord général sur les tarifs douaniers et le commerce pour les plus connues). Enfin, ce dernier conflit d'ampleur sur le continent européen est suivi en Europe de l'Ouest par une période de prospérité sans précédent, dans la foulée de la reconstruction, et l'émergence progressive d'un projet d'unification politique pacifique porté en premier lieu par les deux adversaires historiques, l'Allemagne et la France.

 Les traités de Versailles, Saint-Germain-en-Laye, Trianon et Neuilly avaient suscité rancœurs, frustrations et désirs de reconquête chez les peuples allemand, autrichien, hongrois et bulgare. L'humiliation de la défaite de 1918 et la signature du traité de Versailles sont vécues comme un "diktat" en Allemagne. C'est l'idée que la classe politique allemande est à l'origine de cette défaite qui entraîne un sentiment de rancœur au sein de l'armée qui rejoindra les nazis dans leur ascension au pouvoir.

La crise de 1929 conduit les différents États à adopter des mesures protectionnistes et à se placer en position de rivalité les uns par rapport aux autres. Alors que l’agressivité des démocraties se situe sur le plan économique, les dictatures fascistes vont adopter une stricte autarcie et, naturellement, penser leur défense et leur expansion en termes militaires. Mais partout, des politiques d’armement sont mises en place efficacement pour sortir du marasme économique.

Ceci pourrait expliquer une guerre dans un contexte où la politique de l’Allemagne aurait été inspirée par les classes dominantes traditionnelles. La guerre en Europe est toutefois directement issue des ambitions expansionnistes du parti nazi – au pouvoir en Allemagne – exprimées dès 1924 par Adolf Hitler dans "Mein Kampf". Sur ces ambitions visant à conquérir un espace vital pour le peuple germanique se sont greffées les velléités expansionnistes du régime fasciste italien qui tenta tant bien que mal de se constituer un empire colonial en Éthiopie et en Europe du Sud.

Ulcérés par le traitement imposé à l'Empire du Japon par les puissances occidentales lors du traité de Versailles et les traités navals de Washington et de Londres, de nombreux politiciens et militaires japonais, tels Fumimaro Konoe et Sadao Araki, réactualisent la doctrine du "hakkō ichi’u" (« les huit coins du monde sous un seul toit ») et mettent en place une idéologie fondée sur la suprématie de la race japonaise et son droit à dominer l’Asie. Cette idéologie raciste présente le Japon comme le centre du monde et prend assise sur l’institution impériale et l’empereur, être divin et descendant de la déesse Amaterasu Omikami. Elle donne lieu à une tentative de restauration Shōwa.

Porté par l’influence des factions militaires, le Japon envahit ainsi la Mandchourie en 1931 puis le reste de la Chine en 1937. Le refus du Japon de se retirer de l’Indochine française, envahie en 1941, et de la Chine, à l’exclusion du Mandchoukouo, mène, l'été de la même année, à l’imposition par les États-Unis d’un embargo sur le pétrole. En réaction, Hirohito lance alors la guerre de la Grande Asie orientale ("Dai Tô-A sensô") et autorise l’attaque de Pearl Harbor ainsi que l’invasion de l’Asie du Sud-Est.

L'affrontement central du conflit oppose les « Alliés » aux « Forces de l’Axe », c'est-à-dire les signataires du Pacte tripartite et les pays qui les soutiennent. Cependant les alliances furent parfois profondément modifiées durant le conflit et ses prolégomènes. Ainsi, la Pologne participa au partage de la Tchécoslovaquie en 1938 aux côtés de l'Allemagne nazie, mais elle fut à son tour envahie et partagée par l'Allemagne nazie et l'URSS dans le cadre du pacte germano-soviétique, qui prévoyait également l'occupation des Pays baltes. La Finlande, lors de la Guerre d'Hiver en 1939 contre l'URSS, recevra le soutien des britanniques et des français, mais elle sera au côté de l'Allemagne nazie après l'invasion de l'URSS par celle-ci, avant de changer de camp en 1944. La Roumanie pro-occidentale au début de la guerre, se rangera du côté des nazis après le renversement de la monarchie par le mouvement fasciste de la Garde de fer, avant de retrouver le camp allié en 1944.

La marche à la guerre en Europe a été rythmée de façon constante par les initiatives allemandes. Selon les mots d’Yves Durand, 

Lorsque la Pologne est envahie par l’Allemagne et par l’URSS, la Chine a déjà été envahie par le Japon depuis 1937, mais les relations entre Berlin et Tokyo restent distantes, et l’Allemagne ne soutient pas le Japon. L’empire du Japon, enlisé dans une guerre estimée au départ de trois mois, occupe difficilement un territoire trop vaste. Ses exactions contre les populations civiles (massacre de Nankin) ainsi que son recours aux armes chimiques et bactériologiques produites par l’unité 731 lui valent un surcroît d’hostilité en Europe.

Le a lieu à Berlin la signature du pacte tripartite par lequel le Japon reconnaît la prédominance de l’Allemagne et de l’Italie en Europe et ces deux derniers États, la suprématie du Japon en Asie orientale : les trois pays signent un pacte d’assistance mutuelle. Quant à l’Italie, théoriquement alliée de l’Allemagne depuis 1936, elle n’a déclaré la guerre à la France et au Royaume-Uni que le et attaque le Royaume de Grèce sans consulter les Allemands, le .

L’alliance de la Hongrie avec l’Allemagne à partir de 1938 lui vaut des agrandissements territoriaux aux dépens de la Tchécoslovaquie et de la Roumanie, mais le pays n’est pas belligérant lorsqu’il rejoint l’Axe le . La Hongrie n’intervient militairement que lors de l’invasion de la Yougoslavie en avril 1941, puis lors de l’attaque contre l’URSS en juin. Le Royaume-Uni et les États-Unis lui déclarent la guerre le .

Après avoir été attaquée par l’URSS le lors de la guerre d'Hiver, la Finlande s’allie de facto à l’Allemagne (sans rejoindre l’Axe) et déclare la guerre à l’URSS le , dans le cadre de la « guerre de Continuation ». Cependant, le maréchal finlandais Mannerheim borne explicitement ses objectifs à la reprise des terres annexées à l'Union Soviétique par le Traité de Moscou du .

Après avoir dû céder un cinquième de son territoire à l’URSS le , la Roumanie subit le coup d’État du maréchal pro-nazi Ion Antonescu le , l’occupation par les troupes allemandes le et rejoint l’Axe le . Le elle participe à l’attaque allemande contre l’URSS pour récupérer les territoires perdus un an plus tôt, mais contrairement à l’armée finlandaise, l’armée roumaine est engagée dans les opérations jusqu’à Stalingrad et participe à des atrocités : massacre de civils à Odessa, déportation et extermination de Juifs en Transnistrie. Le Royaume-Uni et les États-Unis lui déclarent la guerre le .

La Hongrie et la Roumanie ont envoyé plusieurs centaines de milliers d’hommes combattre aux côtés de l’Allemagne en URSS.

Les contingents de volontaires étrangers engagés sur le front russe au nom de l’anti-bolchevisme, comme la division espagnole "Azul" ou la Légion des volontaires français, ont des effectifs beaucoup plus modestes.

Le régent du Royaume de Yougoslavie signe une alliance avec l’Allemagne en . Il s’ensuit aussitôt un coup d'État militaire anti-allemand : lorsque le nouveau roi imposé par le putsch dénonce l’alliance, l’Allemagne et l’Italie envahissent et démantèlent la Yougoslavie. L’État indépendant de Croatie devient un satellite de l’Allemagne nazie. Autre satellite de l’Allemagne, la Slovaquie, qui a adhéré au pacte tripartite en novembre 1940, déclare la guerre à l’URSS le .

Le Bulgarie rejoint l’Axe le puis laisse la Wehrmacht traverser son territoire pour envahir la Grèce. La Bulgarie profite de cette alliance pour s’agrandir aux dépens de ses voisins mais ne participe pas à l’invasion de l’URSS. Le Royaume-Uni et les États-Unis lui déclarent la guerre le . Elle n’est en guerre contre l’URSS que pendant vingt-quatre heures, les 5 et 6 .

En détruisant une partie de la flotte des États-Unis à Pearl Harbor le et en envahissant la Malaisie, possession britannique, le Japon entre résolument dans la guerre contre les États-Unis et le Royaume-Uni.

Le Japon et l’URSS s’affrontent en , sans déclaration de guerre, en Mongolie (bataille de Halhin Gol). Les Soviétiques ne déclarent toutefois officiellement la guerre au Japon que le .

Le , la Thaïlande signe un pacte défensif avec le Japon et déclare la guerre aux États-Unis et au Royaume-Uni. La chute du gouvernement de Plaek Pibulsonggram en ne rompt pas officiellement l’alliance, mais la Thaïlande se retire du conflit en évacuant les territoires pris aux Britanniques et des contacts sont pris avec les Alliés.

Le , Badoglio, qui a remplacé Mussolini, rompt l’alliance avec l’Allemagne en signant un armistice avec les Alliés. Hitler envahit aussitôt la péninsule qu’il occupe jusqu’à Naples.

À partir de la fin , la Hongrie envisage un retournement d’alliance. Informé de ces préparatifs, Hitler ordonne l’occupation de la Hongrie le , destitue le régent Horthy et offre le pouvoir à Ferenc Szalasi qui reste dans l'Axe.

Comme l’armée tchécoslovaque n’avait pas opposé de résistance lors de l’invasion de la Bohême-Moravie, le , on peut considérer que la Pologne est le premier adversaire de l’Allemagne belligérant à partir du lorsqu’elle résiste à son invasion par l’Allemagne. L’invasion de la Pologne provoque les déclarations de guerre du Royaume-Uni et de la France le , à respectivement 13 et .

Le Royaume-Uni justifiait sa déclaration de guerre à l'Allemagne par la garantie qu'elle avait donnée à la Pologne le 31 mars 1939. Après la guerre, Alexander Cadogan, qui, lors des événements, était sous-secrétaire d'État permanent aux Affaires étrangères du Royaume-Uni, déclara au sujet de cette garantie : 

Avec le Royaume-Uni, l’Australie et la Nouvelle-Zélande déclarent également la guerre à l’Allemagne. Au fil de la guerre, tous les dominions (Canada, Afrique du Sud, Terre-Neuve) et toutes les colonies (Inde, Nigeria, Kenya, etc.) de l’Empire britannique deviennent tôt ou tard partie prenante du conflit, à l'exception de l’Irlande du Sud qui reste officiellement neutre sous la direction de Éamon de Valera.

En , lorsque l’Allemagne envahit le Danemark et la Norvège, la Norvège oppose une résistance armée alors que le Danemark, trop faible militairement, tente plusieurs contre-attaques sans succès puis se place , selon les paroles de son roi.

Le , la bataille de France démarre par l'invasion par les Allemands du Luxembourg, de la Belgique et des Pays-Bas, jusqu'alors tous neutres.

Les autorités du Luxembourg, qui ne possède pas de véritable armée, opposent une protestation de forme à leurs envahisseurs qui s'emparent du pays dans la journée.

Après cinq jours, les forces militaires néerlandaises se rendent et les Pays-Bas sont entièrement occupés par l'Allemagne, tandis que la reine et le gouvernement s'exilent à Londres. Les Indes orientales néerlandaises sont encore sous le contrôle du gouvernement jusqu'à l'invasion japonaise en mars 1942.

Pour les Belges c'est la campagne des dix-huit jours, qui se termine par la reddition de l'armée belge le . Le gouvernement se réfugie en France, puis au Royaume-Uni après l'armistice du 22 juin. Avec les forces qui ont pu échapper à l'ennemi, il continue ainsi la guerre au service ou aux côtés des Alliés, utilisant notamment sa colonie du Congo.

La bataille de France entraîne la destruction de l'essentiel des armées françaises en mai et juin 1940, ce qui pousse le gouvernement français à demander l'armistice, qui sera signé le 22 juin. Le 18 juin, depuis Londres, refusant de cesser le combat, le général français de Gaulle lance un appel à le rejoindre pour poursuivre la lutte contre l'Allemagne aux côtés de l'Empire britannique. Par l'armistice, la France s'est retirée de la guerre, entreprenant avec l'Allemagne une collaboration économique forcée qui englobe tout son empire colonial.

Malgré cela, les dirigeants de l’Empire britannique écartent toute perspective de paix avec l'Allemagne. La Grande-Bretagne héberge d'ailleurs un certain nombre de gouvernements en exil ou dissidents qui mettent ce qui reste de leurs forces armées – notamment polonaises, tchèques, yougoslaves, belges, néerlandaises et françaises – plus ou moins importantes, aux côtés du Royaume-Uni.

Durant la Seconde Guerre mondiale, l’Allemagne et ses alliés, l’Italie et le Japon étaient unis selon les termes du pacte tripartite. Depuis de nombreuses années, il existait déjà entre les États-Unis et le Troisième Reich certaines tensions telles que des provocations orales ou des torpillages contre les sous-marins de la marine américaine comme le "Robin Moor" le 21 mai 1941. Cet incident a provoqué une montée des tensions entre l’Allemagne et les États-Unis et Roosevelt assura dans un discours, six jours plus tard, qu’il n’allait pas laisser les Allemands avoir la domination sur l’Atlantique. Cependant, aucun des deux pays n’était prêt à s’engager dans la guerre dans l’Atlantique, ce sont les événements qui vont se dérouler dans l’océan Pacifique qui vont amener l’Allemagne à déclarer la guerre aux États-Unis.

Par ailleurs, les relations entre le Japon et les États-Unis étaient également tendues. Hitler avait, en même temps, envie d’une attaque japonaise envers les Américains afin de les distraire du front à l’Est de l’Europe entre la Wehrmacht et les Russes. Le Führer commençait à douter, en automne 1941, lorsqu’il comprit qu’une attaque capitale japonaise contre la flotte américaine n’était pas mis en place par Hideki Tojo, le nouveau Premier Ministre japonais, arrivé récemment au pouvoir. Malgré le scepticisme d’Hitler, les affaires entre le Japon et les Allemands commencent à se concrétiser. Hitler annonce aux Japonais que s’ils attaquaient les États-Unis, les Allemands seraient les premiers à rejoindre la guerre.

Un nouvel accord remplaçant le pacte tripartite a été rédigé au début du mois de décembre 1941 et a été présenté au Japon et à l’Italie, mais il n’a pas été signé tout de suite. Ce pacte créait une aide réciproque en cas de guerre entre l’un d’eux et les États-Unis et conditionnait toute demande de paix ou d’armistice avec les États-Unis et le Royaume-Uni à l'accord de tous les signataires.

Au début du mois de décembre 1941, les tensions entre le Japon et les États-Unis commencent sérieusement à s’intensifier et à devenir aux yeux des chefs militaires allemands, le signe d’un conflit imminent entre les deux parties.

Le 7 décembre 1941, le souhait du Troisième Reich se réalise à la surprise générale : les Japonais attaquent Pearl Harbor. Cette attaque a surpris les dirigeants allemands et beaucoup s’en sont réjoui. Hitler avait l’occasion de déclarer la guerre aux États-Unis en ayant le soutien du Japon et il prit sa décision très rapidement. Mais Hitler aurait pu ne pas attaquer les États-Unis, puisque le nouvel accord n’était pas encore signé lorsque Pearl Harbor fut annoncé. Rien ne l’obligeait à le faire et il aurait pu simplement laisser le Japon détourner l’attention des États-Unis dans le Pacifique. Hitler aurait aussi pu se concentrer sur le front de l’Est, mais Hitler a déclaré la guerre pour obliger les États-Unis à se battre sur deux fronts et donc à ne pas pouvoir utiliser leur pleine puissance militaire contre l’Allemagne ou le Japon, car il pensait que leur puissance militaire maximale serait atteinte en 1942 et il fallait donc les vaincre avant.

Hitler avait aussi prévu d’utiliser cette déclaration de guerre comme un moyen de propagande afin de se montrer comme un pays fort et puissant qui déclare la guerre au lieu de la subir. Il ne voulait pas rester passif. Mais il aurait également pu attendre que les États-Unis lui déclarent la guerre afin d’utiliser cela comme un moyen de propagande.

Après l’attaque de Pearl Harbor, le , les États-Unis sont entrés en guerre contre le Japon ; et de fait contre l’Allemagne et l’Italie, puisque les deux États déclarent la guerre aux États-Unis le 11 décembre en guise de soutien affiché au régime japonais. Lors de la conférence de Washington, au début de l'année 1942, les États-Unis et le Royaume-Uni décident que l'objectif prioritaire pour remporter la guerre est de vaincre l'Allemagne (« L'Allemagne d'abord »).

La République de Chine, en guerre avec le Japon depuis 1937, se retrouve dès lors dans le camp des puissances alliées. De nombreux pays d’Amérique latine déclareront la guerre à l’Allemagne : notamment, le Brésil en et le Mexique en mai de la même année.

Après le débarquement allié en Afrique du Nord, en , la majeure partie de l’Empire colonial français se retrouve du côté des Alliés.

En le gouvernement italien Badoglio déclare la guerre à l’Allemagne, mettant l’armée italienne, grossie de nombreux engagés venus de la résistance, au service des Alliés. D’autres États auparavant membres de l’Axe, tels que la Finlande ou la Roumanie qui, amputées territorialement par l’URSS en 1940, avaient participé à l’attaque allemande contre l’URSS en 1941 pour récupérer les territoires perdus (respectivement Carélie et Bessarabie), rejoignent à leur tour les Alliés lorsque l’Armée Rouge revient sur leurs frontières, la première en (Guerre de Laponie), la seconde le (en outre, la Roumanie avait eu deux divisions engagées du côté allié dès 1941). Dans la nuit du 8 au , la Bulgarie, occupée par l’Armée Rouge depuis trois jours, déclare à son tour la guerre à l’Allemagne. Toutefois, ces ralliements tardifs et contraints ne permettront pas à ces trois pays de participer à la fondation de l’Organisation des Nations unies. À l’ouest, l’effondrement du régime de Vichy en France métropolitaine met toutes les ressources du pays et de nombreux engagés au service de la France libre.

En 1945, les Alliés avertissent tous les États que ceux qui auront déclaré la guerre à l’Allemagne seront admis à la conférence fondatrice de l’ONU. Ce qui entraîne, au printemps 1945, une cascade de nouvelles déclarations de guerre au Troisième Reich, qui pour la plupart resteront sans aucun effet militaire : il s’agit de pays sud-américains tels que le Paraguay, l’Équateur, le Pérou, l’Argentine, ou du Moyen-Orient tels que l’Égypte, la Syrie, le Liban, la Turquie (le …) et quelques autres. En tout, 52 États se sont trouvés en état de guerre avec l’Allemagne hitlérienne, sans pour autant être admis aux conférences interalliées, réservées aux « trois grands » (États-Unis, Empire britannique, URSS et, après l’été 1944, France), état de guerre auquel aucun traité de paix après 1945 n’est jamais venu mettre juridiquement fin.

Le , lendemain de la capitulation allemande, les dernières délégations diplomatiques nazies sont expulsées des États neutres : la Suisse, la république d'Irlande, l’Espagne, le Portugal, l’Afghanistan et le Chili.

Lorsque l’URSS attaque la Pologne le , conformément au protocole secret du pacte germano-soviétique, elle est, d’un point de vue polonais, dans le même camp que l’Allemagne, sans pour autant être en état de guerre déclarée avec la France et le Royaume-Uni. Lorsque l’URSS attaque la Finlande en , la Finlande se trouve plutôt du côté de la France et du Royaume-Uni. Cette agression vaut par ailleurs à l’URSS de se voir expulsée de la SDN fin 1939. Pendant la durée du pacte, Staline livre ponctuellement et à crédit du pétrole, des matières premières et des céréales permettant au Reich de contourner partiellement le blocus des Alliés. Il lui livre aussi plusieurs dizaines de communistes allemands réfugiés en URSS.

À partir du , l’URSS, attaquée par l’Allemagne, se retrouve dans le camp des Alliés. Elle bénéficie du prêt-bail américain en échange des réserves en or de la Banque d'État d’URSS. À défaut de pouvoir ouvrir avant 1944 le second front instamment réclamé par Moscou, les Alliés fournissent à l’URSS une aide importante, qui transite notamment par la dangereuse voie de navigation arctique.

Selon Raymond Cartier et John Keegan, entre et , les États-Unis livrent avions, chars, mitrailleuses, téléphones de campagne, de fil téléphonique. En 1943, des camions de l’Armée rouge viennent d’outre-Pacifique. L’Amérique fournit aussi 13 millions de bottes, 5 millions de tonnes de vivres ou encore locomotives, wagons, de rail. Trois quarts du cuivre soviétique viennent des États-Unis, mais aussi une grande partie du pétrole de haute teneur sans lequel il est impossible de fabriquer du carburant pour avion.

La défaite allemande est impensable sans l’Armée rouge, qui fixe en juin 1944 les deux tiers de la Wehrmacht, en général les troupes les plus jeunes et les mieux équipées.

La majorité des historiens situent le début de la Seconde Guerre mondiale le , lorsque après l'invasion de la Pologne par l'Allemagne, la France et le Royaume-Uni déclarent la guerre à l'Allemagne en vertu d'un traité de février 1921, les liant à la Pologne.

L'historien Eric Hobsbawm, dans son ouvrage "L'Âge des extrêmes" (1994), souligne cependant que les gouvernements britannique et français étaient enclins à négocier malgré l'invasion de la Pologne et que c'est sous la pression de leur population qu'ils furent contraints à ne pas reculer.

Après une opération de provocation connue sous le nom d'incident de Gleiwitz, les troupes allemandes envahissent la Pologne sur tous les fronts, le , à 4h45 du matin.

Le , en application des clauses secrètes du Pacte germano-soviétique, l'Union soviétique envahit à son tour la Pologne par l'est. Largement surclassée, l'armée polonaise est écrasée avant la fin septembre.

Après le refus de la Finlande d'échanger des territoires propices à la défense de Leningrad contre des terres plus au nord, l'URSS attaque la Finlande le . En dépit de la disproportion des forces, la résistance finlandaise est particulièrement vigoureuse, l'URSS subit de lourdes pertes et la Guerre d'Hiver dure jusqu'au . Elle s'achève avec le traité de Moscou du , met provisoirement un terme aux hostilités entre les deux pays. L'URSS obtient l'annexion de la Carélie dont l'isthme protège l'accès à Léningrad ainsi que plusieurs îles du golfe de Finlande.

Toujours en application du Pacte germano-soviétique, l'URSS occupe en , puis annexe, les pays baltes.

Sur le front ouest, une fois passée la démonstration sans lendemain de Gamelin dans la Sarre allemande (6-13 ), les troupes franco-britanniques, sous commandement français, ne prennent aucune initiative militaire et ne mènent aucune opération offensive pendant plusieurs mois, restant retranchées derrière la ligne Maginot.

Au printemps 1940, les Alliés se préparent à couper l'approvisionnement en fer de l'Allemagne, qui transite de la Suède vers le Reich par la Norvège, mais l'opération tourne au fiasco : c'est l'incident de Narvik. L'Allemagne envahit alors le Danemark et la Norvège le . Une majorité du corps expéditionnaire du Royaume-Uni et de la France doit rembarquer précipitamment, ce qui entraîne la chute de Chamberlain et son remplacement par Churchill le . Le , les Français de Béthouart s'emparent de Narvik, mais ils doivent l'abandonner quelques jours plus tard car, en France même, la victoire allemande est alors pratiquement acquise.

En effet, en mai-juin 1940, l'armée allemande mène à bien l'invasion foudroyante des Pays-Bas, du Luxembourg, de la Belgique et de la France. Dans cette campagne fulgurante les Allemands mettent en œuvre leur doctrine de percée et d'avance par l'usage coordonné des forces blindées, mécanisées et aériennes : la "Blitzkrieg" ou guerre-éclair. Malgré les avertissements des attachés militaires alliés à l'étranger et la communication des Belges au général en chef français Maurice Gamelin des plans allemands d'attaque par l'Ardenne
la surprise devant la tactique allemande est complète.

Dès le 25 mai, la défaite des armées franco-belgo-britanniques du nord se précise après 18 jours de combat au cours desquels les Chasseurs ardennais, troupe d'élite de l'armée belge, ont retardé la percée allemande en Ardenne pendant deux jours et que les Français percés à Sedan se soient provisoirement rendus maîtres du terrain à Gembloux, au sud de Bruxelles, dans une bataille de chars sous les ordres du général Prioux. Le fort belge d'Ében-Émael étant tombé en 24 heures, le 11 mai et l'armée hollandaise ayant retraité précipitamment vers le réduit de Zélande, découvrant la gauche de l'armée belge, celle-ci finit par livrer une bataille d'arrêt de quatre jours sur la Lys du 24 au 27 mai, après des retraites successives sur la Meuse et la Dendre en coordination plus ou moins réussie avec les armées française et britannique du nord devant les percées profondes des armées allemandes et alors que le front belge est tourné sur sa gauche par la reddition néerlandaise du 14 mai. Le roi des Belges Léopold III sait que les Britanniques préparent un réembarquement à Dunkerque et ne prévoient pas de sauver ce qui reste des combattants belges, comme l'avoue lord Keyes, attaché militaire britannique auprès du roi. Le , l'armée belge étant à court de munitions et de moyens logistiques, le roi donne un ordre de reddition -après avoir prévenu le gouvernement de Londres par une lettre personnelle à George VI et l'envoi de messages radios aux généraux français- acte purement militaire qui ne concerne pas la force armée du Congo Belge et laisse intact le pouvoir du gouvernement civil qui se réfugie en France porteur de toute sa légitimité, puis qui gagnera la Grande-Bretagne lors de la défaite française. Et dès le 28 mai, le gouverneur général du Congo belge déclare que le Congo poursuit la guerre en accord avec le ministre des colonies Albert De Vleeschauwer. C'est la première réaction anti-allemande d'un territoire européen d'outre-mer (avant même le ralliement de quelques colonies françaises au général de Gaulle).

Le Royaume-Uni réussit, du 27 mai au 3 juin, à sauver soldats au cours de la plus vaste opération de réembarquement de l'histoire militaire.

Le 5 juin, Hitler reprend l'offensive en France et perce les lignes de défense du nouveau généralissime Weygand sur la Somme et l'Aisne. L'Italie se joint alors à l'Allemagne et déclare la guerre à la France le 10 juin. Puis, en France, le nouveau gouvernement Pétain demande l'armistice le 17 et en accepte les conditions le 22. Après l'armistice franco-italien qui suit, le 24, les combats cessent le 25 juin. À la surprise générale, l'armée française, réputée depuis 1918 la meilleure du monde, s'est effondrée en quelques semaines.

Contre l'attente des stratèges nazis et des généraux français battus, le Royaume-Uni résiste avec succès à l'aviation allemande, car, malgré la faiblesse de son armée de terre, il dispose d'une flotte puissante (qui ne semble pas menacée par une mainmise allemande sur la flotte française, grâce aux clauses de l'armistice et après la destruction de quelques-unes de ses unités à Mers El Kebir) et d'une aviation bien organisée. En outre, le premier ministre Churchill, qui a remplacé Chamberlain, parvient à galvaniser le pays. Soumis d'abord à des attaques aériennes sur des cibles stratégiques, le Royaume-Uni fait face de à au bombardement de ses villes : ce "« Blitz »", qui détruit notamment la City de Londres et la ville de Coventry, ne parvient ni à entamer la résolution britannique ni à compenser les pertes de la Luftwaffe de Göring, vaincue par les pilotes de la Royal Air Force.

Pour tenir seul face à Hitler, le Royaume-Uni dispose de l'aide d'abord économique des États-Unis, puisque ceux-ci, bien qu'officiellement neutres, l'approvisionnent en armes et en ravitaillement. Roosevelt obtient du Congrès en , le vote de la « loi Prêt-Bail », qui lui permet d'apporter une aide matérielle illimitée au Royaume-Uni et à ses alliés.

En septembre 1940, les forces italiennes avaient attaqué l'Égypte, pays alors sous influence britannique. Mais dès le mois de décembre, les Britanniques, appuyés par les forces du Commonwealth, passent à la contre-attaque, et les Allemands doivent envoyer ce que l'on appellera l'Afrika Korps en renfort pour secourir leurs alliés italiens. En juillet 1942, l'Afrika Korps de Rommel n'est plus qu'à quelques dizaines de kilomètres d'Alexandrie.

Hitler, désespérant de prendre le Royaume-Uni et de l'amener à faire la paix, érige une puissante chaîne de fortifications, surnommée « mur de l'Atlantique », sur les côtes de l'Atlantique et de la Manche, et décide d'attaquer l'URSS. Mais l'Italie fasciste vient elle-même d'agresser, à partir de l'Albanie, la Grèce qu'elle croyait sans défense. Or ce sont les forces grecques du dictateur nationaliste Metaxás qui sont victorieuses : après avoir contenu l'attaque des troupes de Mussolini, l'armée grecque et un corps expéditionnaire britannique, australien, néo-zélandais, indien et sud-africain les repousse et envahit à son tour l'Albanie italienne.

C'est alors que, pour prêter main-forte aux Italiens, Hitler repousse de plusieurs semaines son opération contre l'URSS et envoie en ses troupes vers la Grèce, à travers la Hongrie sympathisante et après avoir envahi au passage la Yougoslavie. Les nazis battent les armées yougoslave et grecque, ce qui leur permet d'occuper tout le sud de l'Europe. Mais, du même coup, ils viennent de créer un front supplémentaire en Yougoslavie, où les résistances monarchiste de Draža Mihailović (Tchetniks) et communiste de Tito (Partisans), allaient immobiliser de 13 à 20 divisions allemandes jusqu'à la fin de la guerre. De plus, l'invasion de l'URSS est différée, du 15 mai au 22 juin.

Le , la Wehrmacht envahit l'URSS dans le cadre de l'opération Barbarossa. Elle mobilise 3,2 millions de soldats allemands, et soldats des États alliés de Hongrie, de Roumanie, de Finlande, de Slovaquie et d'Italie. C'est à ce jour la plus grande offensive militaire de l'histoire.

Malgré une avance foudroyante et la capture ou le massacre de plusieurs millions de Soviétiques, la Wehrmacht est stoppée en , à une trentaine de kilomètres de Moscou dans un froid glacial et sans équipement adéquat. Pour la seconde fois depuis la campagne de Russie de 1812, les Russes sont sauvés par la rigueur de leur hiver, et aussi par un appel pressant au patriotisme et au sacrifice face à des combats très meurtriers. Les Allemands restent également bloqués devant Léningrad, délibérément soumise par Hitler à un siège de 900 jours, qui fera périr de faim habitants.

Dès lors, la campagne de Russie va mobiliser l'essentiel des efforts militaires allemands.
Malgré leurs pertes énormes, les Soviétiques ont pu replier leur potentiel industriel dans l'ordre, plus de 10 millions de travailleurs et des milliers d'usines démontées étant réinstallées à l'est de l'Oural. La réintégration de l'URSS dans le camp allié lui permet aussi de recevoir une forte aide américano-britannique en matériel de qualité et en ravitaillement. Staline proclame aussi l'union sacrée et galvanise les énergies, tout en maintenant intacte la terreur contre les soldats défaillants ou les officiers vaincus. Enfin, les Soviétiques ont encore des réserves : la trentaine de divisions qu'ils ont pu rapatrier d'Extrême-Orient, après confirmation en fin septembre 1941 par leur espion établi à Tokyo Richard Sorge que les Japonais, conformément au pacte nippo-soviétique de non-agression signé le 13 avril précédent, n'attaqueront pas l'Union Soviétique mais bien les États-Unis. C'est ainsi que, redéployées par le maréchal Joukov au cours de l'hiver 1941-42, ces troupes sibériennes fraîches contre-attaquent devant Moscou et obligent l'envahisseur allemand à reculer.

En 1941, les troupes coloniales du Congo Belge battent les Italiens à Asosa, au sud de l'Abyssinie tandis que les troupes anglaises, appuyées par des forces françaises libres battent l'armée italienne et réinstallent le Négus sur son trône à Addis-Abeba.

Désireux de venger l'affront fait par la France au royaume de Siam en 1893 et 1904, la Thaïlande profite de l'invasion de celle-ci par l'Allemagne et se lance en janvier 1941 dans une série d'attaques contre l'Indochine française, déclenchant la guerre franco-thaïlandaise. Aucun camp n'étant en mesure de s'imposer, le litige est tranché par le Japon, présent au nord de l'Indochine depuis septembre 1940 et qui octroie à la Thaïlande une partie du Laos et du Cambodge.

Le , l'Empire du Japon, allié de l'Allemagne depuis 1936 et en guerre depuis 1937 avec la République de Chine, attaque les États-Unis, restés jusque-là en dehors de la guerre. Il détruit par surprise l'essentiel de la flotte américaine du Pacifique à Pearl Harbor. Au même moment a lieu l'invasion de la Malaisie britannique. L'Armée impériale japonaise envahit ensuite le Commonwealth des Philippines et les Indes orientales néerlandaises.

L’attaque de Pearl Harbor provoque l’entrée en guerre des États-Unis, bientôt suivis par le Mexique et par d’autres États latino-américains. Affaiblis par l’attaque japonaise, les États-Unis mettent toute leur puissance industrielle au service de la guerre et sont bientôt en mesure de porter des coups. En mai lors de la bataille de la mer de Corail, en dépit d'une défaite tactique, ils empêchent le débarquement japonais en Nouvelle-Guinée, puis au début de , la bataille aéronavale des îles Midway coûte quatre porte-avions au Japon, désormais placé sur la défensive dans le Pacifique. Les États-Unis commencent la reconquête de l'océan Pacifique, île par île.

En Europe, l’Union soviétique supporte presque seule l’effort de guerre contre l’Allemagne nazie. À partir de , les Allemands ont relancé leur offensive vers l’est, en direction de la Volga et des pétroles du Caucase. Mais les troupes allemandes restent bloquées devant Stalingrad.

En Afrique du Nord, les Britanniques ont repris l’initiative à partir de . Ils remportent une victoire décisive à El-Alamein et commencent à repousser l'Afrika Korps vers l’ouest.

Staline presse ses alliés d’ouvrir un deuxième front à l’ouest. Après des hésitations, Churchill et Roosevelt se décident pour l’Afrique du Nord. C’est l’opération Torch, qui se traduit par le débarquement des forces alliées au Maroc et en Algérie, le . Le 11 novembre, l’amiral Darlan, à Alger, engage l’Afrique à reprendre le combat aux côtés des Alliés. Il est officiellement désavoué par le maréchal Pétain. Cependant, les Allemands considèrent que l’armistice de juin 1940 est rompu et envahissent alors le la zone sud de la France que cet armistice avait prévu non occupée. L’armée française d’Afrique se joint aux armées alliées. En Afrique du Nord, les Allemands sont alors pris en tenaille entre les Britanniques à l’est et les Franco-Américains à l’ouest.

Au cours de l’année 1942, l’entrée en guerre des États-Unis avait entraîné une extension à tout l’océan Atlantique de la lutte des sous-marins allemands contre les navires alliés qui assurent l’approvisionnement de la Grande-Bretagne. Les convois alliés subissent de très lourdes pertes tout au long de l’année, mais à partir de la fin de l’année 1942 et plus encore au début de 1943, de nouveaux moyens techniques – décryptage des communications ennemies, radars, sonars – permettent aux Alliés de détruire de plus en plus de sous-marins allemands, et les pertes alliées décroissent inexorablement.

Au début de l’année 1943, les Allemands subissent sur le front oriental une très lourde défaite à Stalingrad. Après les capitulations du et du , les Soviétiques font prisonniers, dont le maréchal Paulus, premier militaire allemand de ce rang capturé depuis 1806. Après avoir libéré le Caucase, les Soviétiques tentent de libérer l'Ukraine alors que les Allemands et leurs alliés sont à bout de souffle, mais une contre attaque allemande à Kharkov (Ukraine orientale) stoppe l'Armée Rouge. Les Allemands mènent une offensive d'été limitée à Koursk (en Russie, au nord de Kharkov), en compensant leur manque d'infanterie, à la suite de la bataille de Stalingrad, par un fort déploiement de chars avec de nouveaux matériels. Attendus par les Soviétiques qui fortifient la région et amassent de grande quantité de blindés, les Allemands sont de nouveau défaits. Sans attendre, les Soviétiques déploient leurs chars et reprennent leurs offensives pour la libération de l'Ukraine.

Avec la prise de Tunis, le et la reddition des troupes allemandes et italiennes, les Alliés sont maîtres de toute l’Afrique du Nord. Le , ils débarquent en Sicile et prennent pied sur la péninsule italienne en septembre, le jour même où Badoglio, le successeur de Mussolini, évincé du pouvoir, annonce un armistice qui préfigure un retournement d’alliance. Les Allemands envahissent le territoire de leur ancien partenaire et bloquent de longs mois les troupes alliées de onze nationalités au Monte-Cassino. Rome ne sera libérée que le , la Toscane en . La plaine du Pô ne sera atteinte qu’en .

Pour la première fois depuis le début de la guerre, les trois dirigeants alliés, Churchill, Roosevelt et Staline se rencontrent à Téhéran à la fin du mois de pour esquisser ce que sera le monde de l’après-guerre.

Sur le front oriental, l’Armée rouge ne cesse de progresser vers l’ouest. Elle entre à Kiev, en Ukraine, en , dégage Leningrad en . Le , alors qu’un front à l’ouest a été ouvert en Normandie, elle lance la plus grande offensive de son histoire : l’opération Bagration, qui libère la Biélorussie en quelques semaines et occupe la Prusse-Orientale et la Pologne jusqu’au faubourgs de Varsovie. Toutefois, l’Armée rouge s’arrête tant pour des raisons militaires notamment « l’épuisement de la dynamique de l’offensive » face à la « contre-offensive de 3 divisions panzer SS » que politiques, en laissant écraser l’insurrection de Varsovie (-), Staline élimine en pratique la résistance non communiste du jeu politique d'après guerre et l’insurrection de Varsovie (-). Du au , le front roumain cède, Roumanie et Bulgarie passent dans le camp des Alliés, mais, en occupant le son alliée la Hongrie, Hitler empêche le régent Miklós Horthy d’en faire autant, et il faudra aux Soviétiques cinq mois de siège de Budapest pour s’ouvrir en la route de Vienne. En Yougoslavie, les partisans de Tito libèrent une grande partie du pays et entrent dans Belgrade en sans l’aide de l’Armée rouge.

Le , navires alliés réussissent le plus grand débarquement de l’Histoire sur les plages de Normandie, prenant les Allemands par surprise et ouvrant enfin le second front. Malgré l’exploit logistique, l’armée hitlérienne parvient à contenir les Anglo-Saxons en Normandie pendant plus de dix semaines dans une longue bataille d’usure (bataille des Haies, bataille de Caen), jusqu’à ce que la percée d’Avranches () ouvre la voie de la Bretagne et prenne les troupes allemandes à revers en les encerclant dans la poche de Falaise. Paris insurgée est libérée le . Auparavant, le 15 août, des troupes américaines et françaises avaient débarqué en Provence, sur la côte méditerranéenne.

La progression se fait alors rapidement et, à la mi-septembre, presque toute la France et la Belgique sont libérées par les armées Alliés. Mais alors que les Alliés espéraient une fin du conflit avant la fin 1944, la résistance nazi allemande va s’intensifier. L’opération aéroportée pour tenter une percée vers l’Allemagne par les Pays-Bas échoue (). La pénurie d’essence et les problèmes logistiques obligent à une bataille sur les abords de l’Escaut (novembre 1944) menée par les Canadiens pour libérer les accès maritimes du port d’Anvers. Dans l'est de la France, les Américains et les Français, d'abord à court de carburant, n'avancent que lentement face à une défense Allemande qui s'est renforcée. La contre-attaque allemande dans les Ardennes (Noël 1944) surprend totalement les Américains mais s'essouffle au bout d'une dizaine de jours. Elle contribue toutefois à retarder le passage du Rhin jusqu’à fin . Une large famine touche les Pays-Bas durant l'hiver de 1944, tuant plus de personnes. L'opération Manna est déclenchée par les Alliés, pour parachuter des vivres à la population.

Écrasée sous les bombes, assaillie de tous côtés, l’Allemagne nazie voit sa capitale Berlin investie le 30 avril par les Soviétiques. Hitler s’y donne la mort dans son bunker le même jour. Le à Reims au QG du SHAEF, le colonel général Alfred Jodl signe l’acte de reddition inconditionnelle des forces armées allemandes. Pour des questions de prestige, Staline exige cependant une capitulation signée à Berlin par les plus hauts représentants de la Wehrmarcht et des alliés. Un embargo est posé sur l'annonce de la capitulation de Reims. Dans la nuit du 8 au 9 mai 1945, à Berlin, le maréchal Wilhelm Keitel, l'amiral von Friedeburg et le général Stumpff signent à leur tour la capitulation du Troisième Reich en présence des représentants des Alliés, le maréchal Joukov, le maréchal Tedder, le général de Lattre de Tassigny et le général Spaatz. C’est donc officiellement le que l'Allemagne capitule, ce qui met fin à la guerre en Europe. Il est communément admis que la signature a lieu peu avant minuit (peu après à l'heure de Moscou) ; néanmoins, certains historiens la situent peu après minuit, antidatée du 8 mai, afin de se conformer à ce qui a été signé à Reims.

En Asie, si l'Empire du Japon n’a plus l’initiative, il défend pied à pied ses territoires conquis que les Américains prennent au prix de lourdes pertes. Ils s’emparent ainsi d’Iwo Jima et d’Okinawa Hontō, des îles proches de l’archipel japonais permettant aux Alliés des attaques aériennes directes et massives sur le Japon comme les bombardements successifs sur Tokyo. Le , après le largage, par les États-Unis des deux premières bombes atomiques sur les villes de Hiroshima et de Nagasaki et l’invasion de la Mandchourie et de la Corée par l’URSS, l'empereur Hirohito annonce personnellement la capitulation du Japon. Les actes de capitulation inconditionnelle du Japon sont signés le 2 septembre et clôturent pratiquement six ans jour pour jour après son début la seconde guerre mondiale.

Après s’être assuré de ne pas risquer une guerre avec l’URSS en signant le Pacte germano-soviétique, Hitler lance ses armées sur la Pologne, le , sans déclaration de guerre (voir : incident de Gleiwitz). En application de leur alliance, la France et le Royaume-Uni déclarent la guerre à l’Allemagne le . En particulier, la France a garanti après 1918 par des traités d’assistance mutuelle l’existence de la plupart des pays nouvellement créés en Europe centrale. Cependant, malgré la pression de Chamberlain, pas plus qu’elle n’a respecté ses engagements envers les précédentes victimes d’Hitler, la France rechigne à ses obligations envers la Pologne : celles-ci prévoyaient que la France attaquerait l’Allemagne 15 jours après le début de la mobilisation générale. Mais mise à part une brève offensive limitée en Sarre du 6 au 13 septembre, les Français restent l’arme au pied, alors que la Pologne fait seule face à l’agression allemande puis soviétique. Les Allemands utilisent pour la première fois leurs tactiques innovantes, communément appelées « guerre éclair » ("Blitzkrieg"), qui assurent à la "Wehrmacht" une victoire rapide, essentielle pour elle puisqu'elle écarte ainsi le risque d'avoir à mener une guerre sur deux fronts. Conformément aux clauses du pacte signé, l’URSS prend sa part de la Pologne en l'attaquant le .

Le , toujours suivant ce pacte, l'URSS attaque la Finlande pour lui prendre la région frontalière de Carélie, près de Leningrad, malgré les protestations des Franco-Britanniques qui menacent d'intervenir. Les Finlandais se battirent cinq mois, puis finissent par céder. À l'été 1940, l'URSS intégrera les États baltes et la Moldavie, sans combats.
Après sa première campagne victorieuse, Hitler se tourne vers l’ouest, mais rien ne se passe sur ce front pendant plusieurs mois. Retranchés derrière la ligne Maginot, une partie des soldats français attendent l’assaut allemand pour l’endiguer. C’est ce que les Français appelleront la "Drôle de guerre". Le généralissime Gamelin, s'attendant à une réitération de 1914, où les Allemands étaient passés par la Belgique neutre, une partie de l'armée française se prépare à s'avancer en Belgique, et éventuellement aux Pays-Bas, si les Allemands les attaquaient.

Le , l'Allemagne s'empare simultanément du Danemark et de la Norvège afin de sécuriser ses importations de fer depuis Narvik, au nord de la Norvège, où se concentre la principale réaction franco-britannique, qui se termine par le rembarquement de ces derniers le malgré le succès local rencontré.

Enfin, le , l’Allemagne, lance l’opération "Fall Gelb", une vaste offensive sur les Pays-Bas, la Belgique et le Luxembourg, violant la neutralité de ces États. Une partie importante des armées françaises se déploient alors vers la Belgique et les Pays-Bas, mais elles sont prises à revers par les blindés allemands qui passent par les Ardennes – la percée de Sedan –, jugées infranchissables par les Français et malgré des batailles de retardement livrés par les Chasseurs ardennais belges aux frontières et dans les forêts. Après une victoire éphémère des blindés français du général Prioux à Gembloux, au sud de Bruxelles, et des reculs successifs des franco-belgo-anglais sur la Meuse et la Dendre, les blindés allemands atteignent alors la Manche le puis remontent vers le nord, encerclant les Belges et les Franco-Britanniques, dos à la mer.

Les Belges, tournés sur leur gauche après l'effondrement de l'armée néerlandaise le et n'ayant plus de réserves au terme d'une ultime résistance de quatre jours, lors de la bataille d'arrêt de la Lys, cessent le combat le à court de munitions et après que les troupes britanniques qui occupaient la droite belge eurent précipitamment fait retraite vers Dunkerque.

En France, le général Gamelin, commandant en chef des armées alliées, est révoqué par le gouvernement français. Sa stratégie consistant à tenter sans cesse de recréer un front continu franco-belgo-anglais, s'est révélée impuissante face au système allemand de guerre éclair dit "blitzkrieg" fait de percées profondes par des chars suivis de troupes motorisées qui désarticulent les armées alliées. Le 19 mai, Gamelin est remplacé par le général Maxime Weygand. Mais, faute de réserves suffisantes, les Franco-Britanniques, qui n'ont jamais pu mener de contre-offensive satisfaisante, sont repoussés dans une poche autour de Dunkerque. La Royal Navy et les bateaux de plaisance britanniques parviennent à évacuer les troupes anglaises et une petite partie des forces françaises à Dunkerque (opération Dynamo) en perdant leurs équipements lourds et sans rien préparer pour évacuer ce qui reste de l'armée belge qui, faute de munitions et sans presque plus de territoire à défendre, tombe dans les mains allemandes par la reddition du 28 mai. Il s'agit d'un acte purement militaire conclu sous la contrainte des événements et dans lequel le lâchage de l'aile droite belge par les Anglais joue un rôle déterminant. Ce n'est pas une capitulation comme celle à laquelle les Français vont se résigner en juin, engageant leur gouvernement et tout l'empire français dans la voie d'une tentative de collaboration avec l'Allemagne. Le roi des Belges Léopold III est prisonnier, mais le gouvernement belge, qui refuse de baisser les bras, se réfugie en France avant, à l'armistice franco-allemand, de gagner l'Angleterre pour y représenter la Belgique à la tête de quelques forces militaires et du Congo Belge avec sa force armée et son potentiel minier et agricole.

Ayant perdu tout le nord de la France, les Franco-Britanniques entreprennent d'établir une ligne de défense le long de la Somme, de l'Aisne, jusqu’à la ligne Maginot. Ayant perdu beaucoup de leurs moyens dans la bataille qui a précédé, les Alliés ne peuvent empêcher une nouvelle percée allemande début juin. L'armée allemande se répand alors sur toute la France, prenant Paris le . Le président du Conseil Paul Reynaud démissionne et le nouveau gouvernement du maréchal Philippe Pétain choisit de demander l’armistice le 17 juin, contre l'avis de l'allié britannique. Il est signé le : l’Allemagne occupe la partie nord et ouest de la France.

En France, Pétain instaure un régime autoritaire et collaborateur, désigné sous le nom officiel d'État français, dit plus couramment .

En Belgique, c'est un gouverneur militaire qui exerce le pouvoir en concurrence avec les S.S.. Le Roi Léopold III, considéré prisonnier, n'a plus aucun pouvoir et sera déporté. Mais, quelques ministres et parlementaires sous l'autorité des principaux ministres du gouvernement, MM. Pierlot, Spaak et Gutt se sont réfugiés à Londres après l'effondrement de la France et sont reconnus par toutes les puissances belligérantes comme représentant légalement la Belgique. Le ministre Albert de Vleeschauwer, chargé des finances de la Belgique et du Grand Duché de Luxembourg (unies en vertu de l'accord économique de 1920) est aussi en possession de larges pouvoirs au Congo Belge, avec sa puissance économique et sa force armée. Les Belges exilés et les Belges d'Afrique continuent donc la guerre en allant remporter une victoire sur les Italiens d'Abyssinie, tandis que les militaires qui ont pu atteindre l'Angleterre continuent la guerre dans l'aviation et la marine.
Voyant les succès de l’Allemagne, Mussolini avait voulu aussi lancer son pays dans les conquêtes. Il avait déjà occupé l’Albanie au début de 1939 et, le , il attaque également la France, mais ne progresse que de quelques kilomètres.

N'ayant pu obtenir de paix avec la Grande-Bretagne, Hitler lance une offensive aérienne sur celle-ci, préparant un débarquement. Mais l’Allemagne ne parvient pas à vaincre la Royal Air Force dans la bataille d'Angleterre. Ainsi, elle ne peut obtenir la supériorité aérienne nécessaire pour envahir les îles Britanniques. Afin de pousser les Britanniques à la paix, Hitler commence en septembre une campagne de bombardement sur les villes anglaises (dite le Blitz, "l’éclair"), principalement sur Londres et intensifie son blocus (dit bataille de l’Atlantique), essentiellement par sous-marins, pour affaiblir le Royaume-Uni. Mais c’est un échec, l’Allemagne ne parvient pas à briser rapidement la résistance britannique, qui réussit grâce à des pilotes de la RAF. Après la Seconde Guerre mondiale, Churchill écrit : « Dans l'histoire des luttes humaines, il n'y avait jamais tant de gens qui étaient tellement obligés à si peu de gens. »

Le , sans consulter son allié allemand, Mussolini décide d’attaquer la Grèce. Mais la résistance de l’armée grecque du dictateur Metaxás parvient à arrêter les Italiens et à passer à la contre-offensive, avec succès : Les Grecs occupent alors le quart sud de l’Albanie italienne. Pour prêter main-forte aux Italiens, Hitler repousse de plusieurs semaines l’opération contre l'URSS, et envoie en avril 1941 ses troupes vers la Grèce, à travers son allié la Hongrie, et la Yougoslavie, envahie car refusant de laisser le passage, et où les Allemands sont aidés par les Oustachis, croates nationalistes d’Ante Pavelić. Les armées yougoslave et grecque sont écrasées en trois semaines, ce qui permet à Hitler d’occuper tout le sud de l’Europe. La Résistance armée sera plus vigoureuse en Yougoslavie que partout ailleurs en Europe : les résistances nationaliste de Draža Mihailović (Tchetniks) et communiste de Tito (Partisans), vont immobiliser de nombreuses troupes depuis la fin de 1942 jusqu’à la fin de la guerre.
Les opérations dans les Balkans auront retardé l’invasion de l’URSS connue sous le nom d’opération Barbarossa. Celle-ci ne commence que le 22 juin 1941. L’Allemagne, en attaquant par surprise l’Union soviétique, s’empare de grandes portions de territoires et capture de nombreux soldats.

Ils le font d’autant plus facilement que Staline a choisi de faire confiance à Hitler, alors qu’il reçoit depuis des mois des informations précises et concordantes de ses agents à l’étranger. « pour des raisons politiques, Staline s’abstient d’utiliser leurs informations. Jusqu’au dernier moment, il s’attend à une réouverture des négociations avec les Allemands… Les généraux soviétiques partagent souvent ce point de vue… » De plus, aux premières heures de l’attaque, Staline, dans l’espoir d’arranger les choses avec Hitler, interdit même aux forces soviétiques de traverser la frontière en cas de contre-attaque victorieuse, et initialement celles-ci n’osent pas ouvrir le feu alors qu’elles sont martelées par les bombes allemandes.

Cependant, pour la première fois, une armée ne s’effondre pas devant la Wehrmacht : en dépit de ses lourdes défaites, l’Armée rouge ne cesse dès le premier jour de multiplier les contre-attaques, à la surprise des officiers allemands. L’avance considérable des troupes hitlériennes se révèle en même temps plus lente que prévu, le nombre de divisions et de chars soviétiques nettement supérieurs aux estimations des services secrets. Les Soviétiques déplacent leur base industrielle dans l’Oural, reçoivent l‘aide alliée par les ports arctiques toujours en leurs mains, et produisent dès 1942 plus d’armes que l’Allemagne, tandis que l’Armée rouge oppose une défense héroïque qui, aidée par un hiver éprouvant, leur permet de défendre notamment Moscou et Leningrad.
Staline a par ailleurs su réveiller le nationalisme russe et organiser l’union sacrée face à l’agresseur : il reçoit le soutien des Églises, met en veilleuse le collectivisme agraire et une partie du contrôle policier sur la société, et substitue les références patriotiques à celles au communisme, dès son discours du où il s’adresse habilement à ses « frères et sœurs » soviétiques. Il ne néglige pas non plus de maintenir une réelle terreur contre ses officiers et ses généraux, dont beaucoup sont fusillés pour « incompétence » dans les premiers mois de la guerre, tandis que les millions de prisonniers sont officiellement reniés et considérés comme des traîtres (et leurs familles avec eux), et les soldats défaillants exposés à l’exécution ou à la déportation au Goulag : au front, des équipes spéciales du NKVD se chargent même, en 1941 comme à Stalingrad, de mitrailler les soldats qui refluent vers l’arrière.

Au printemps 1942, l’armée allemande reprend l’offensive en concentrant celle-ci vers les champs de pétrole du Caucase, au sud. À la fin de l’année, la armée, avec plus de hommes, est détruite à Stalingrad qui représente un verrou pour le contrôle du Caucase. En 1943, la "Wehrmacht" reprend l’initiative à la troisième bataille de Kharkov, mais est brisée à la grande bataille de Koursk.
En 1943, après le débarquement en Sicile, puis un autre dans la péninsule italienne, les Alliés entament la campagne d’Italie. Mussolini chassé, le pays capitule et se range du côté des Alliés. Néanmoins, l’Allemagne peut tenir une ligne de défense dans les montagnes qui freine cette progression dans la péninsule. Il faut attendre début 1945 pour que les nazis soient complètement repoussés d’Italie.

Les Alliés prennent pied en Normandie avec l’opération Overlord à partir du . Les soldats alliés qui débarquent sont principalement américains, britanniques et canadiens. Un autre débarquement est organisé en août (à partir du 15), en Provence avec l’opération Anvil Dragoon, pour libérer le sud de la France et ouvrir un deuxième front en France. L’Allemagne tente une contre-offensive désespérée dans la bataille des Ardennes en décembre, où elle perd ses dernières réserves militaires. Les derniers défenseurs du Reich seront souvent des civils, des vieillards et des enfants de la Volkssturm, une milice montée par Martin Bormann.

Fin mars 1945, les Alliés peuvent enfin franchir le Rhin et occuper de vastes secteurs de l’Ouest et du Sud de l’Allemagne, tandis que, à l’Est, les Soviétiques progressent de façon continue, libérant l’Europe centrale puis atteignant Berlin. Dans les rues de Vienne et Berlin assaillies par l’Armée rouge, des escadrons SS font encore régner la terreur en pendant en public ceux qui refusent de continuer un combat sans espoirs. Hitler se suicide le 30 avril d’une balle dans la tête dans le "Führerbunker" de la Chancellerie du Reich. Le même jour, les Soviétiques plantent leur drapeau sur le toit du palais du Reichstag, l’ancien siège du Parlement allemand, dans un Berlin en ruines. La bataille de Berlin continue jusqu’au 2 mai. L’Allemagne capitule sans condition le . Le Troisième Reich pour lequel Hitler prédisait une durée d’un millénaire n’aura finalement duré qu’un peu plus de 12 ans.

L’armée italienne, partant de sa colonie de Libye, attaque les troupes britanniques et du Commonwealth en Égypte, mais est mise en déroute jusqu’à ce que l’Allemagne la renforce. Des combats se succèdent alors, dans le désert d’Afrique du Nord, entre les forces italiennes appuyées par l’Afrika-Korps d’Erwin Rommel et la britannique.

En Abyssinie, une armée anglaise venant du nord accompagnée par un contingent français, et, au sud, une force belge venant du Congo Belge prennent les Italiens en tenaille et les battent. Le Negus est réinstallé sur son trône à Addis-Abeba.

Au Moyen-Orient, les Britanniques envahissent en avril 1941 le territoire du Royaume d'Irak, dont le gouvernement nationaliste s'était rapproché de l'Axe. En juin, les autorités vichystes permettant aux Allemands d'utiliser les territoires de la Syrie et du Liban, alors sous mandat français, les Alliés envahissent les deux pays et en prennent le contrôle. En août, le Royaume-Uni et l'Union soviétique réalisent conjointement une invasion de l'État impérial d'Iran afin d'assurer le ravitaillement "via" le corridor Perse et d'empêcher un basculement pro-allemand du pays.

En mai 1942, Rommel lance une grande offensive vers l’est pour atteindre Suez, et bouscule les forces britanniques, mais il est arrêté 14 jours à Bir Hakeim par la française libre du général Kœnig, ce qui donna le temps aux Britanniques en déroute de se regrouper sur la ligne fortifiée d’El Alamein, que Rommel ne parvient pas à franchir. Puis en octobre 1942, c’est la britannique, commandée par Montgomery, qui attaque à son tour les forces de l’Axe et remporte la seconde bataille d’El Alamein. Celle-ci met fin à la présence de l’Axe en Libye, quelques jours après le succès du débarquement allié en Afrique du Nord.

Le , a lieu l'opération Ironclad, une invasion amphibie de la colonie française de Madagascar, sur Diégo-Suarez, contrôlée par le gouvernement de Vichy.

Le 8 novembre 1942, en effet, pour soulager l’Union soviétique qui résiste seule à l’assaut allemand, les forces américaines et britanniques débarquent au Maroc et en Algérie, contrôlés par le gouvernement de Vichy : c’est l’opération Torch. Les troupes françaises de Vichy ripostent et s’opposent aux alliés débarqués jusqu’à ce qu’un accord négocié avec l’amiral Darlan mette fin aux combats.

Les alliés chassent finalement l’Axe du continent africain, avec l’aide de l’armée d’Afrique retournée et des Forces françaises libres. Depuis l’Afrique du Nord, les Alliés peuvent alors organiser les débarquements en Sicile et en Italie en 1943, et en Provence en 1944.

À compter de 1937 en Chine, l’Armée nationale révolutionnaire du Kuomintang de Tchang Kaï-chek et le Parti communiste de Mao Zedong font front commun contre les Japonais mais généralement sans coopérer.

Enlisée en Chine, l’Armée impériale japonaise a systématiquement recours, dès 1937, à l’utilisation d’armes chimiques. Selon les historiens Matsuno et Yoshimi, celles-ci furent notamment utilisées à 375 reprises lors de la bataille de Wuhan à l’automne 1938. L’emploi d’armes bactériologiques est quant à lui autorisé par le Quartier général impérial à compter de 1940 mais jamais contre des Occidentaux.

Soumis à compter de 1941 à un embargo sur le pétrole après son occupation de l’Indochine, le Japon ne peut plus désormais réaliser sa politique expansionniste sans détruire la principale menace qui peut encore s’opposer à lui dans le Pacifique : la force navale des États-Unis basée à Hawaii. Employant à nouveau la stratégie qui lui a réussi contre la Russie, le Japon décide de bombarder Pearl Harbor le par surprise. La flotte est fortement endommagée, mais les porte-avions sont en mer.

Simultanément, l’armée japonaise occupe les possessions britanniques, hollandaises et américaines d’Asie du Sud-Est comme Hong Kong, Singapour (massacre de civils), les Philippines (marche de la mort de Bataan) et s’empare des champs pétroliers de la Malaisie britannique et des Indes orientales néerlandaises, menaçant même l’Australie. L’Indochine française est déjà passée sous son contrôle militaire avec l’accord du régime de Vichy. Le . Le coup de force du 9 mars 1945 achèvera la mainmise nippone sur la péninsule : le vide politique consécutif à la guerre mondiale favorisera la prise du pouvoir par le Việt Minh de Hô Chi Minh.

Le raid de Doolittle en avril 1942 marque le début de la riposte américaine. En mai 1942, la bataille entre porte-avions de la mer de Corail tourne à l’avantage des alliés. Un mois plus tard, celui-ci est accentué par celle de Midway.

À partir du début 1942, l’Armée impériale japonaise tente de neutraliser la résistance communiste chinoise en lançant la , une stratégie de la terre brûlée, dans le Nord de la Chine, tandis que des attaques répétées sont lancées contre les place-fortes des nationalistes chinois.

En dépit de la détermination de l’armée japonaise, les Alliés reprennent peu à peu les îles du Pacifique comme à Guadalcanal, les Salomon puis les Philippines après la bataille du golfe de Leyte (octobre 1944), cette dernière restant la plus grande bataille aéronavale jamais survenue. Soumis à blocus et coupé progressivement de ses ravitaillements en matières premières, le Japon est au bord de l’asphyxie économique à l'été 1945.

L’engagement en 1944 des premiers kamikazes de l’histoire - ces avions-suicides qui se jettent sur les navires ennemis - ne peut freiner la reconquête américaine, mais prouve la détermination des Japonais.
La capture des îles proches du Japon comme Iwo Jima et Okinawa permet de lancer des attaques aériennes directes. Tokyo notamment subit un bombardement incendiaire le 10 mars 1945. Surtout, Hiroshima le 6 août et Nagasaki le 9 (ce devait être Kokura) subissent une attaque nucléaire.

Conjuguée à la déclaration de guerre de l’URSS et l’invasion du Mandchoukouo par les forces soviétiques, les bombardements atomiques provoquent finalement la reddition du Japon, annoncée par Hirohito le , confirmée par la signature des actes officiels le 2 septembre à bord de l’USS Missouri.

« "Guerre de mouvement sur de vastes espaces, la Deuxième Guerre mondiale a été une guerre du moeur" ».
L’usage généralisé des chars est une première illustration de cette tendance à la motorisation. Alors que l’armée française fait le choix d’une dispersion des chars, mis au service des unités d’infanterie, les Allemands en adoptant une tactique basée sur l’utilisation des chars groupés sortent vainqueurs de la bataille de France. La conception du char lui-même oscille entre deux tendances : la puissance et la maniabilité. L’expérience de la guerre d’Espagne a montré que le blindage est moins important que la silhouette basse, moins vulnérable, la tourelle mobile à 360° et la puissance du canon. Mais au cours de la Seconde Guerre mondiale, on assiste à une croissance en poids, en blindage et en puissance de feu. Ainsi, le char allemand Tigre I fait . L’américain Sherman M4 et le soviétique T-34, utilisés jusqu’à la fin de la guerre restent dans la gamme des . La concentration de chars dans des divisions blindées permettent de mener des guerres éclairs (Blitzkrieg), comme la Bataille de France en mai-juin 1940 remportée par les Allemands. L’Allemagne nazie commet l’erreur d’envahir l’URSS en sous-estimant le nombre de ses chars et la qualité des nouveaux, comme le T-34, rustique et endurant. La plus grande concentration de chars a eu lieu lors de la bataille de Koursk, en Russie, en .

Les progrès des chars vont de pair avec les progrès de l’armement antichar : l’usage de la charge creuse permet de percer des blindages de plus en plus épais. Des tubes lance-roquettes comme le bazooka permettent au fantassin de disposer contre les chars de la puissance d’un artilleur.

Parallèlement à l’utilisation de chars, on assiste tout au long de la guerre à un accroissement des transports motorisés des troupes, au détriment des chevaux, encore très présents tant du côté français que du côté allemand lors de la bataille de France ou encore sur le front de l’Est, principalement pour des raisons logistiques. La division blindée américaine de 1944, sera, elle, entièrement motorisée.

Les immenses progrès de l’aviation réalisés entre les deux guerres vont donner aux différents avions de guerre une place de première importance. L’amélioration des structures de l’avion permet aux chasseurs-bombardiers comme le Stuka d’opérer des bombardements en piqué et de prendre ainsi toute leur part dans les combats terrestres. Les bombardiers lourds comme la forteresse volante américaine, dont le rayon d’action atteint, à la fin de la guerre, kilomètres, sont utilisés dans des raids massifs de mille avions et plus, mettant ainsi en œuvre le concept de Bombardement stratégique. Pour contrer les bombardiers, les belligérants font usage de leurs avions de chasse et de canons de défense contre avions (DCA). C’est l’efficacité de la DCA qui oblige à organiser les opérations de bombardement la nuit. On demande aux avions de chasse d’assurer la maîtrise de l’espace aérien sur un champ de bataille ou sur un front donné.

Dominés par l'aviation alliée dans la seconde partie de la guerre, les Allemands auraient pu retrouver un certain avantage dans la bataille aérienne, grâce à la première construction en série d'avions à réaction par Messerschmitt. Mais Hitler gâche cette chance en exigeant d’en faire des bombardiers, contre l’avis de ses officiers, et non des avions de chasse, ce qui aurait été bien plus approprié.

La DCA doit son efficacité aux progrès techniques des radars qui surveillent le ciel et guident le tir des canons anti-aériens. À partir de 1942, les bombardiers alliés sont équipés de radars, des chasseurs de nuit allemands également. Grâce à leurs qualités croissantes, les radars sont également utilisés dans les navires alliés pour la direction des tirs. D’une façon générale, les télécommunications font partie intégrante de l’arsenal militaire. Les blindés allemands sont reliés entre eux par radio dès 1939 en liaison avec les avions, alors que leurs adversaires français ne le sont que très partiellement. Les techniques de chiffrage et de déchiffrage suivent l'évolution des techniques. Les Allemands utilisent la machine de codage Enigma, mais le déchiffrement d’Enigma par les alliés occidentaux est un facteur fondamental qui leur permet d’inverser le cours de la bataille de l’Atlantique et d’assurer finalement leur victoire finale.

Sur mer, après la Première Guerre mondiale, le choix guidant la construction des navires de ligne consistait en un compromis entre le blindage et la vitesse. Les croiseurs de bataille, plus rapides que les cuirassés étaient moins bien protégés. Ce n'est qu'à la fin des années 1930 qu'apparurent les premiers cuirassés rapides. Mais ces bâtiments constituaient des cibles idéales pour l'aviation embarquée à bord des porte-avions, notamment les bombardiers en piqué et les avions torpilleurs. Malgré une puissante défense aérienne, disposant parfois de conduite de tir radar, le cuirassé reste vulnérable et cesse d'être le "capital ship" de la guerre sur mer. Le porte-avions, qui peut disposer d'un parc aérien de 50 à 60 appareils, prend un rôle de plus en plus déterminant, surtout grâce à "l'allonge" que lui permet ses escadrilles embarquées, lorsque le théâtre des opérations est éloigné de toute base terrestre, comme c’est le cas pour les États-Unis ou le Japon dans les batailles du Pacifique. Le porte-avions devient la pièce centrale d’un dispositif que les Américains appellent "Task force" et où les autres navires lui servent le plus souvent d'escorteurs.

Comme lors de la Première Guerre mondiale, les sous-marins sont largement employés pour bloquer l’approvisionnement ennemi, mais la lutte anti-sous-marine a fait d'énormes progrès depuis la Première Guerre mondiale, d'abord avec l'asdic puis avec le sonar. Les destroyers, les frégates et les corvettes sont spécialisées dans la lutte anti-sous marine et assurent l'escorte des convois.

Les mines sous marines constituent un autre danger pour les navires. Elles se sont considérablement perfectionnées depuis la fin du premier conflit mondial. D'abord « de contact », explosant au choc, elles sont mises à feu par le champ magnétique et les bruits rayonnants des bateaux de guerre ou de commerce. Ce sont les mines à influences magnétiques et acoustiques. Les navires s'en protègent grâce à des circuits d'immunisation magnétique (degaussing) et une meilleure signature acoustique. Des petites unités spécialisées, les dragueurs de mines sont construites pour neutraliser ces millions d'engins de mort mouillés partout où le trafic maritime est important. Les mines sont particulièrement efficaces pour un coût modeste.

À la fin de la Seconde Guerre, de nouvelles armes font apparition sur le champ de bataille, comme l’avion sans pilote V1 lancé pour la première fois par les Allemands sur l’Angleterre dans la nuit du 13 au 14 ou le missile V2 lancé pour la première fois sur Londres le 8 . Contrairement aux craintes des alliés, les Allemands n’avaient pas de projet de bombe atomique. Les Américains, au contraire, avaient mis à partir de de gigantesques ressources dans le projet Manhattan qui aboutit le 16 juillet 1945, après la reddition de l’Allemagne, à la première explosion nucléaire dans le désert du Nouveau-Mexique et aux bombardements atomiques d'Hiroshima et Nagasaki les 6 et 9 août 1945.

À partir de la victoire éclair de l’Allemagne sur la France, et plus encore à partir de 1941, avec l’invasion des Balkans et de l’Union soviétique, et jusqu’à la fin 1944, la presque totalité de l’Europe est sous domination Allemande. Certains pays et certaines régions ont carrément été rattachés au Grand Reich, comme l’Autriche, le Protectorat de Bohême-Moravie, ou l’ouest de la Pologne. D’autres pays se sont alliés volontairement à l’Allemagne, il s’agit de la Bulgarie, de la Roumanie et de la Hongrie, mais ils sont complètement dépendants de l’Allemagne. Certains pays, comme la Slovaquie et la Croatie, doivent leur indépendance à l’Allemagne nazie. D’autres sont occupés à la suite de victoires allemandes. C’est le cas des Pays-Bas, de la Belgique, de la Norvège, du Danemark, de la France, de la Serbie, de la Grèce.

La domination allemande en Europe revêt un caractère différent à l’est et à l’ouest. Les pays de l’Est européens, au peuplement slave sont considérés par les nazis comme un « espace vital » (Lebensraum) revenant à la « Race des Seigneurs ». Dans cet espace immense, il s’agit à la fois d’implanter des colons allemands, de germaniser de force les populations qui peuvent l'être, de déplacer, stériliser ou faire mourir des millions de « sous-hommes » : Polonais, Slaves soviétiques ou Tziganes, en utilisant les survivants comme esclaves, allant jusqu'à la solution finale pour les juifs.

L’Ouest n’est pas considéré comme un espace vital à vider pour que des Allemands puissent y prendre place. Dans le nouvel ordre européen, un pays comme la France garde sa place, mais à un rang inférieur à celui de l’Allemagne. Si l’occupant allemand exerce une terreur moindre, il n’en soumet pas moins les ressources des pays conquis au pillage systématique.

En effet, sur le plan économique, le continent européen est soumis à l’hégémonie du "Reich". Pour l’Allemagne, il s’agit d’abord de mettre l’ensemble des ressources et capacités économiques du continent au service du "Reich" en guerre. D’autre part, des jalons sont posés pour une intégration de toutes les économies nationales dans un grand espace économique dominé par l’Allemagne. En France on appelle les soldats allemands « doryphores », qui ravagent tout.

Dans la pratique, les différents moyens pour mettre l'économie de l’Europe au service de l’Allemagne vont des accords de compensation avec taux de change avantageux pour les pays alliés au pillage massif pour les pays comme la Pologne ou l’Union soviétique en passant par le paiement d’indemnités pour un pays comme la France. La mise au travail des prisonniers de guerre et les déplacements en Allemagne de millions de travailleurs représentent une forme encore plus directe de l’exploitation des ressources.

Pour Yves Durand, « Les occupations engendrent parmi les occupés, des comportements qui vont de la collaboration à la résistance en passant par toute une gamme d’attitudes qui ne peuvent être réduites ni à l’une ni à l’autre ».
Tous les pays vaincus doivent accepter au moins une forme de collaboration minimale qui permet aux peuples de survivre en acceptant au moins temporairement les conditions du vainqueur. C’est ce que Werner Rings appelle la collaboration neutre qui est typiquement pratiquée aux Pays-Bas et en Belgique dont les gouvernements ont quitté le pays mais dont les administrations font le nécessaire pour permettre aux habitants de survivre et à l'économie de tourner en étant réquisitionnée au service de l’effort de guerre allemand.

Aux Pays-Bas, la résistance est surtout urbaine, vu la géographie du pays qui n'offre pas de sites isolés et difficiles d'accès où l'on puisse organiser une activité clandestine. Il s'agit d'espionnage et de presse clandestine. En Belgique, l'espionnage se manifeste à travers des agents anglais et belges recrutés et formés directement par les Anglais et aussi par des réseaux de résistance intérieure belge dont le réseau Clarence de Walthère Dewé et des réseaux d'évasion dont le Réseau Comète. À partir de 1942, les sabotages vont commencer, notamment ceux du Groupe G, une organisation d'ingénieurs qui entravent scientifiquement le potentiel militaire allemand en détruisant les équipements stratégiques comme les lignes à haute tension et des stations électriques dans le but de paralyser la production de guerre des usines réquisitionnées. Mais, en Ardenne belge, dans la province de Luxembourg, région accidentée et boisée, se développent des groupes de maquisards. Des parachutages d'armes depuis l'Angleterre les équiperont au fur et à mesure des années en vue des combats de la Libération. En 1944, beaucoup de ces résistants s'engageront dans les troupes belges participant à la libération de la Belgique et iront combattre avec elles aux Pays-Bas et en Allemagne avec les alliés.

Dans certains pays, comme pour la Norvège de Quisling à partir de 1942, ce sont les partisans des nazis qui gouvernent directement le pays. Les historiens les appellent généralement des « collaborationnistes ».
Dans d'autres pays, l'Allemagne préfère favoriser des dirigeants conservateurs comme Pétain en France ou Nedić en Serbie qui sont présumés mieux gérer leur gouvernement. En Serbie, en Croatie, ou au Monténégro, les séparatismes locaux sont encouragés pour installer des gouvernements favorables à l'Allemagne et à ses alliés.

En France, les différents gouvernements vichystes proposent d’eux-mêmes une collaboration qui va au-delà de ce qui est prévu par l’armistice de juin 1940 en espérant obtenir pour le pays une meilleure place dans l’Europe allemande. Selon les termes de Paxton, « Hitler repousse la main tendue ». C’est lui qui choisit ses alliés. Devant les compromissions de plus en plus graves du gouvernement Laval, une résistance s'organise, déjà à partir de l'été 1940. Dans le courant de la guerre, à cause des déportations d'ouvriers, des réseaux de réfractaires s'organisent qui deviennent des maquisards combattants. Grâce aux parachutages d'armes depuis Londres, ils entreprennent des sabotages et attaqueront les troupes allemandes en retraite en 1944.
En Pologne, gouvernée directement par les Allemands pour être pillée et complètement asservie, il ne peut y avoir ni collaborationnistes ni collaborateurs.

L’engagement dans la « résistance » permet aux peuples dominés de continuer à s’opposer au vainqueur, à participer à l’effort de guerre des Alliés et éventuellement à la libération de leur pays. La résistance s’organise par la création de mouvements, de réseaux et de maquis, regroupant une minorité de la population et souvent en liaison avec les gouvernements en exil ou les services de renseignement anglais, soviétique ou américain.

La guerre et la domination de l’Europe qui en est résultée ont permis au régime nazi de pousser à l’extrême son idéologie raciste. Selon les termes de Goebbels : « La guerre nous offre toutes sortes de possibilités que la paix nous refusait »

Parmi ces possibilités figure un plan de nettoyage ethnique visant les populations d'Europe de l'Est : le Schéma directeur pour l'Est ; son application dans les terres conquises aura pour effet de les désorganiser en profondeur.

Le jour même de l’entrée en guerre, en , Hitler autorise l’extermination des handicapés mentaux allemands et autres malades incurables. Officiellement stoppée en août 1941 grâce à un mouvement d’opinion, l’aktion T4 conduit à « l'euthanasie » par le gaz de plus de handicapés, nombre de techniciens de l’opération étant ensuite réaffectés au gazage massif des Juifs dans les camps de la mort.

Dès 1939, les juifs sont concentrés de force dans des ghettos misérables, surpeuplés et délibérément affamés, notamment dans le Gouvernement Général de Pologne. Leur extermination systématique, que l’on désigne sous le nom de Shoah, est d’abord mise en œuvre par des exécutions de masse pratiquées par la Wehrmacht puis par les Einsatzgruppen dans les territoires polonais et soviétiques. En URSS et dans une partie de la Pologne, la « Shoah par balles » cède en 1942 le pas à l’emploi méthodique de "camions à gaz". Après la conférence de Wannsee (20 janvier 1942), la politique d’extermination (« la solution finale de la question juive » dans la terminologie nazie) vise les Juifs de tous les pays occupés et prend un tour industriel. Les Juifs sont déportés dans des camps d’exterminations dans lesquels les victimes sont gazées en masse, et leurs corps réduits en cendres dans des "fours crématoires". Au total, environ les trois quarts des juifs de l’Europe occupée, totalisant, selon Raul Hilberg, au minimum personnes sont exterminées.
Les Tziganes sont également victimes de la politique raciale des nazis. L’extermination des Tziganes est connue sous le nom de Porajmos. En décembre 1942, Himmler prend la décision de déporter vers Auschwitz tous les Tziganes d’Europe, mais se désintéresse rapidement du sujet qui ne constitue pas un enjeu stratégique de première importance. On peut estimer que pendant la Seconde Guerre mondiale, entre et Tziganes sont morts à la suite des mesures de persécution nazies.

En plus des camps d’extermination dont la finalité est l’élimination immédiate des Juifs et autres catégories qualifiées de « sous-hommes », les nazis multiplient les camps de concentration et leurs commandos pour enfermer, et généralement exterminer par le travail forcé, les opposants réels ou présumés, ou des droits communs. Les conditions particulièrement déshumanisantes de la détention et les traitements brutaux des SS et des kapo y entraînent une mortalité extrêmement forte (40 % des déportés français ne survivent pas). Au départ, ce sont des unités mobiles qui sont chargées d’exterminer les Juifs — ainsi que les Tziganes, les cadres communistes, voire les handicapés et les homosexuels.

En Asie également, l’Empire du Japon suscite des gouvernements collaborateurs et a recours à grande échelle au pillage des matières premières et au travail forcé des prisonniers de guerre et des populations locales qu’il prétendait libérer de la servitude coloniale.

En Chine, les Japonais jouent des divisions politiques locales pour s'assurer le soutien de Wang Jingwei, ancien premier ministre et ancien chef du Kuomintang, qui dirige un gouvernement collaborateur à Nankin. Pour se donner un profil patriotique, ce gouvernement met fin au régime des concessions européenne à Shanghai.

Dans plusieurs colonies occidentales asiatiques occupées, les Japonais composent avec les indépendantistes locaux, créant des régimes comme l'État de Birmanie, dirigé par Ba Maw, ou la République des Philippines, dirigée par José P. Laurel. L'Empire du Japon use du concept de la Sphère de coprospérité de la grande Asie orientale pour promouvoir l'idée d'une Asie auto-suffisante et justifier sa politique expansionniste.

Envahie en 1931, la Mandchourie est devenue l'État du Mandchoukouo, où l'ancien empereur de Chine Puyi exerce une autorité de façade, et qui garantit au Japon d'importantes ressources naturelles.

Dans le cadre de la campagne de Birmanie, les Japonais bénéficient de l’appui du gouvernement thaïlandais de Plaek Pibulsonggram et du leader indépendantiste indien Subhas Chandra Bose, qui crée l'Armée nationale indienne. Aux Indes orientales néerlandaises occupées, qui leur fournissent de très importantes réserves de pétrole, les Japonais ne créent pas de gouvernement, mais se ménagent l'appui des leaders indépendantistes comme Soekarno (futur président de l'Indonésie).

Disséminés sur tout le territoire de la Sphère, les camps de prisonniers japonais connurent un taux important de décès car la majorité d’entre eux impliquaient le travail forcé des prisonniers. Selon le Tribunal de Tokyo, le taux de mortalité des occidentaux y était de 27,1 %, sept fois celui des prisonniers des camps allemands ou italiens. Le taux de mortalité des prisonniers chinois était bien supérieur en raison d’une directive ratifiée le 5 août 1937 par Hirohito qui éliminait les mesures de protection du droit international à l'égard de ces prisonniers. Ainsi, si prisonniers britanniques, néerlandais et américains furent relâchés après la reddition du Japon, le nombre de Chinois libérés ne fut que de 56.

Selon une étude de l’historienne Zhifen Ju, plus de 10 millions de Chinois furent mobilisés par l’armée impériale japonaise et transformés en esclaves par la Kōa-in au Manchukuo et en Chine du nord. Des documents retrouvés à la Bibliothèque du Congrès américain démontrent qu’entre 4 et 10 millions de "romusha", des civils indonésiens, ont été soumis au travail forcé à Java par le régime Shōwa et que le taux de mortalité y fut de 80 %.

En Amérique du Nord, à la suite de l’attaque de Pearl Harbor par les Japonais et à l’entrée en guerre contre l’Allemagne et l’Italie, le président Franklin Roosevelt autorise le 19 février 1942, l’internement de dizaines de milliers d’Américains d’origine japonaise, italienne et allemande : . Le Canada, dans une moindre mesure, a également détenu des citoyens originaires de ces pays dans des camps.

La Seconde Guerre mondiale contribue, à travers son bilan plus ou moins préjudiciable aux participants, à l’émergence de deux superpuissances qui vont se partager le monde : les États-Unis (États-Unis) et l’Union des républiques socialistes soviétiques (URSS).

La Société des Nations, à laquelle on impute d’avoir échoué à empêcher la guerre, est remplacée par l’Organisation des Nations unies dont la Charte est rédigée à San Francisco en .
L’Allemagne est soumise à plusieurs années d’occupation. En 1949, elle est séparée en deux États, désignés des noms d’Allemagne de l'Ouest (démocratie libérale, dans la zone occupée précédemment par les Américains, les Britanniques et les Français) et d’Allemagne de l'Est (régime communiste, dans la zone occupée par les Soviétiques). La réunification allemande n’aura lieu qu’en 1990.

L’Allemagne de l’Ouest et le Japon sont démilitarisés et démocratisés par les Occidentaux. Les principaux dignitaires de la hiérarchie nazie sont jugés, et la plupart condamnés pour crime contre l'humanité (une notion nouvelle, juridiquement définie à la suite des crimes nazis) ou pour crime de guerre lors d’un procès international à Nuremberg. Les chefs militaires japonais répondent de leurs exactions devant le tribunal international de Tokyo, mais l’empereur Hirohito et des criminels de guerre comme Shirō Ishii, ancien chef de l’unité 731, sont exempts de toute poursuite pour leur coopération avec les États-Unis. Un certain nombre d'ex-responsables nazis obtiennent aussi l’impunité grâce à des initiatives américaines comme l’opération Paperclip et retrouvent plus tard des postes de responsabilité.

En Europe centrale et en Europe de l'Est, zones investies en 1944-1945 par l’Armée rouge, les partis communistes locaux prennent le pouvoir entre 1945 et 1948 sous influence de l’Union soviétique. Dès mars 1946, Winston Churchill, qui, pour garder la Grèce dans le giron occidental, avait consenti à un partage de l’Europe en « zones d’influence » par l’accord de Moscou du , déclare qu’. En Grèce, malgré l’absence de soutien de l’URSS aux communistes grecs, majoritaires dans la résistance locale, une guerre civile se prolonge jusqu’en 1949 et manque de faire basculer la Grèce dans le camp communiste, avant que le gouvernement monarchique ne remporte à grand-peine la victoire grâce au soutien du Royaume-Uni. En Pologne, Tchécoslovaquie, Hongrie, Roumanie, Bulgarie, Yougoslavie et Albanie, où les communistes étaient largement minoritaires, des régimes communistes sont mis en place : le bloc de l'Est se constitue en Europe, signant le début de la guerre froide. Seul le régime communiste de Tito, qui avait en Yougoslavie une certaine assise populaire, surtout chez les Serbes, prend en 1948 une position indépendante vis-à-vis de l’URSS.

La République de Chine de Tchang Kaï-chek est affaiblie par les années de guerre. La guerre civile chinoise, interrompue par l’agression japonaise, reprend dès 1946. En 1949, les nationalistes de Tchang Kaï-chek sont battus par les communistes, largement soutenus par l’URSS. Mao Zedong proclame sur le continent la République populaire de Chine, tandis que Tchang Kaï-chek se réfugie à Taïwan, rendue par les Japonais.

Les institutions d’avant-guerre ne perdurent que dans une minorité d’États européens et asiatiques. Toutes les monarchies d’Europe de l’Est sont abolies par la construction rapide des régimes communistes, qui balayent également les entreprises, le tissu syndical et associatif, et les libertés publiques de ces pays. Un referendum abolit la royauté en Italie (10 juin 1946) ; elle ne se maintient en Grèce qu’au prix d’une guerre civile, et en Belgique la « question royale » posée par l’attitude de Léopold III pendant la guerre, ne trouve de réponse qu’avec son abdication en (1951). Au Japon, les Américains maintiennent l’empereur Hirohito, pourtant constamment tenu informé des crimes commis par ses armées, mais imposent l’abolition du culte impérial qui le proclamait d’essence divine. En France, la République, rendue responsable de la défaite, cède la place à une nouvelle constitution.

Partout à l’Ouest, les gouvernements s’engagent dans la construction du "Welfare State" ou État-Providence : nationalisations, planification, intervention de l’État, lois de protection sociale sont désormais à l’ordre du jour pour une trentaine d’années. Nationalisations, planification et intervention de l’État prennent des formes extrêmes à l’Est, où la sphère privée se réduit désormais aux seules familles et à leurs biens meubles.

La recherche scientifique et technique, dans l’ensemble, bénéficient d’une forte impulsion, en particulier pour la maîtrise de l’atome dans le projet Manhattan et la recherche sur les fusées qui permettra des programmes spatiaux. La guerre a aussi vu le premier usage massif des antibiotiques dont la pénicilline inventée par les Britanniques, ou encore du DDT, utile aux Américains dans les marais du Pacifique. Mais, pendant quarante ans, la guerre froide entre « zones d’influence » empêche les scientifiques de communiquer librement entre eux et draine de nombreuses ressources et technologies vers la sphère militaro-industrielle, au détriment du développement civil.

Les autres alliés en effet, et si l’on excepte le Royaume-Uni, ont un rôle mineur ou bien sont écartés des négociations qui aboutissent à la mise en place de deux zones d’influence, suivant les accords de Yalta et de Potsdam. Cette situation, qui porte en elle les germes de la guerre froide, dure jusqu’en 1989.

Le Royaume-Uni sort considérablement affaibli de la guerre. Celle-ci, en effet, a consacré le déclin des puissances coloniales : le mouvement Quit India s'est développé durant le conflit aux Indes britanniques, les indépendantismes indien et birman ayant pris des formes parfois violentes. L'Indian Independence Act de 1947 prend effet à l'été 1947, immédiatement suivi par la partition des Indes. La Birmanie obtient son indépendance en 1948. Par la suite, les îles britanniques connaissent une crise sans précédent, due à la reconstruction et à la restructuration de son économie.

Au cours de la bataille de Normandie, le général de Gaulle, accueilli en libérateur par les Français, parvient à obtenir des alliés la reconnaissance de la pleine autorité de son gouvernement, le gouvernement provisoire de la République française (GPRF) — proclamé le 3 juin à Alger —, sur la métropole. Il fait en sorte que la France soit reconnue par le camp allié comme un vainqueur. Cette reconnaissance lui permet d’occuper une partie de l’Allemagne, ou d’obtenir un siège de membre permanent au Conseil de sécurité de l’ONU.

La Libération de la France s’accompagne de l’épuration d’une partie des personnes suspectées d’avoir collaboré. Les Allemands et leurs collaborateurs ont multiplié les atrocités sous l’Occupation, puis pendant leur retraite. Aussi dans les territoires libérés par les résistants, et malgré les efforts de la plupart de leurs chefs et des commissaires de la République pour instaurer au plus vite une épuration légale et judiciaire, de nombreuses exécutions sont expéditives et pas toujours précédées de jugements. Environ femmes sont tondues pour « collaboration horizontale ». De ce fait, des erreurs sont commises dans cette libération rapide, et des innocents injustement assassinés. Les historiens estiment qu’environ exécutions sommaires ont lieu, aux trois quarts pendant les combats. L'épuration sauvage a pu être d’autant plus brutale que la population peut avoir envie de se venger des exactions de la milice et des Allemands dans leur déroute et que le gonflement des effectifs de la Résistance a permis à certains résistants de la de se dédouaner ainsi à peu de frais. On a observé le même phénomène lors de l’indépendance de l’Algérie.

À l’opposé, certains collaborateurs sont parfois acquittés ou condamnés à de faibles peines (malgré la gravité de leurs crimes) par les tribunaux réguliers dont la majorité des juges ont prêté serment à Pétain. D’autres furent jugés par la Haute Cour composée de résistants, mais l’importance des condamnations décrut avec le temps. C’est ainsi qu’en 1949, le dernier accusé jugé est acquitté : le secrétaire d'État à l’Intérieur de Pétain, René Bousquet (qui mit la police et la gendarmerie françaises à la disposition des occupants pour faire la chasse aux résistants et déporter près de Juifs) est acquitté. Les collaborateurs n’ont été poursuivis que pour trahison et non pour crime contre l’humanité.

De Gaulle empêche le développement d’une situation armée insurrectionnelle (voir Histoire de France), en amalgamant les mouvements ayant participé à la Résistance à l’armée régulière issue de l’armée d’armistice cantonnée en Afrique (dont nombre de cadres avaient été vichystes avant de se rallier en 1942). Non sans mal, les résistants des Forces françaises de l'intérieur ("FFI") et des Francs-tireurs et partisans ("FTP") sont intégrés dans l’armée régulière sans trop d’à-coups. L’intégration des milices patriotiques du PCF est négociée contre leur participation au gouvernement et l’amnistie de Maurice Thorez.

Au nom de la reconstruction du pays, qui s'effectue "via" une forte croissance et afin de permettre à la France de tenir son rang nouvellement restauré aux côtés des Alliés, l’épuration de l’administration est limitée. Certains hauts fonctionnaires invoquent la continuité de l’État comme acte de résistance. Les policiers dont une partie a poursuivi les résistants se dédouanent par une insurrection à Paris à la veille de la Libération. Certains collaborateurs se font oublier en intégrant des régiments de FFI ou en s’engageant dans le corps expéditionnaire d’Extrême-Orient (engagé en Indochine), ce qui est par la suite exploité par la propagande Việt Minh.

La France oublie qu’elle fut anglophobe et pétainiste après le bombardement de Mers el-Kébir, que des gendarmes français gardèrent le camp de concentration de Drancy et convoyèrent les convois de déportés jusqu’à la frontière. La proportion de Juifs d’avant-guerre ayant survécu n'est pas la plus importante de tous les pays occupés, les Juifs dit apatrides ont été bien moins protégés que les Juifs français. Pour un temps, la législation française considéra que seuls les Allemands peuvent être poursuivis pour crime contre l'humanité. Le procès manqué de Bousquet ainsi que les procès tardifs de Paul Touvier et Maurice Papon sont emblématiques de cette politique.

Le différend né le 28 mai 1940 entre le roi Léopold III et le gouvernement ne sera apaisé qu'en 1950 avec l'abdication du roi revenu d'exil. Voulant rester avec l'armée prisonnière, Léopold III avait veillé à ne faire signer qu'une reddition limitée aux troupes sur le terrain, ce qui permit au gouvernement de partir pour continuer la guerre avec les troupes du Congo belge et celles qu'il put reconstituer en Angleterre (armée, aviation, marine). Le reproche du gouvernement et d'une partie de la population était que le roi aurait dû se réfugier à l'étranger pour prendre la tête de la résistance à l'Allemagne. La division de l'opinion publique à ce sujet donna lieu, après la guerre, à des affrontements allant jusqu'à des manifestations violentes entre défenseurs du roi et partisans de son abdication. Des violences avaient déjà atteint le pays pendant l'occupation allemande, les collaborateurs de l'ennemi ayant perpétré des attentats contre la population (entre autres le massacre de Courcelles) et l'exécution de personnalités politiques et économiques abattues en pleine rue car suspectées d'être en faveur des alliés et de la résistance intérieure.

Les actions de résistance intérieure belge se manifestèrent d'abord par de l'espionnage, notamment par le réseau Clarence organisé dès 1939 par Walthère Dewé (qui avait déjà dirigé le réseau de la Dame Blanche en 1914-18). Dès 1942, commencèrent des actions de sabotage de voies ferrées, la destruction de lignes à haute tension alimentant l'industrie allemande avec de l'électricité belge par le Groupe G. Il en résulta des représailles sous la forme de prises d'otages et l'exécution de résistants arrêtés. Le roi lui-même, auteur de lettres à Hitler pour protester contre les déportations, reçut en réponse une menace de déportation, ce qui arriva lorsqu'il fut emmené en Allemagne avec sa famille en 1944. Mais cela ne suffit pas à le populariser auprès de ses adversaires. D'autre part, après la guerre, des centaines de procès entrainèrent l'exécution capitale par fusillade de collaborateurs de l'ennemi, mais aussi de dénonciateurs désignant aux autorités allemandes des résistants, voire des personnes innocentes dont d'aucuns voulaient se débarrasser pour des raisons privées.

Furent, entre autres, exécutés des tortionnaires du camp de concentration installé à Breendonk, entre Bruxelles et Anvers et des collaborateurs de la police allemande. Le gouverneur allemand de la Belgique, le général Alexander von Falkenhausen fut tenu prisonnier jusqu'en 1949, puis jugé, condamné à vingt ans de prison, les juges militaires belges ayant tenu compte de son opposition aux nazis -qui lui valut d'être arrêtés par ceux-ci- Après quelques années, il fut libéré et rentra en Allemagne où il épousa une ancienne résistante. Sur divers plans, la guerre et l'occupation allemande eurent des suites durables dans l'évolution historique de la Belgique. C'est surtout sur le plan des communautés linguistiques et culturelles que la politique allemande de division entre flamands et wallons s'est fait sentir. Déjà, pendant la première guerre mondiale, les Allemands -qui occupaient les neuf dixièmes du territoire belge- avaient imposé la scission des administrations belges en deux autorités séparées, l'une à Namur pour la Wallonie, l'autre à Bruxelles pour la Flandre, cette région étant considérée comme germanique pour la seule raison de la langue parlée par la majorité de sa population. D'aucuns affirment que la présence en Belgique occupée du roi Léopold III a empêché l'Allemagne de reprendre cette politique entre 1940 et 1944. Ce serait sous l'influence du gouverneur général allemand Von Falkenhausen hostile aux nazis (et que ceux-ci arrêtèrent en 1944). L'action de diplomates allemands traditionalistes non nazis aurait eu également une influence dans la relative modération politique du Reich à l'égard du régime politique de la Belgique. Modération qui prit fin en 1944 avec la division de la Belgique en deux gaus allemands, Flandre et Wallonie, sous l'égide des S.S. tandis que le roi était déporté avec sa famille. Quant à l'activité économique, elles subit des atteintes telles que la reconstruction d'après guerre et les procès d'épuration ne purent en effacer complètement les conséquences. Ce qui restait d'industrie automobile et aéronautique nationale indépendante de sociétés étrangères disparut dans les bombardements. Les destructions industrielles, pillages et déportations (entre autres dans les charbonnages du Hainaut) ne furent pas compensées par la modernisation qu'il aurait fallu mettre en œuvre après la guerre. Sur le plan culturel, des journaux disparurent, d'autres apparurent dont beaucoup ne tinrent pas longtemps.

De nombreuses personnes des milieux de presse, du cinéma et de la culture qui avaient cru pouvoir travailler sous l'égide allemande furent condamnées ou s'enfuirent ou, à tout le moins, furent mises à l'index. On peut citer quelques cinéastes dont Henri Storck avec sa symphonie paysanne, hymne dédié à l'idéologie du retour à la terre dans l'esprit mis à l'honneur en France sous le régime du gouvernement Pétain. Storck n'eut pas d'ennui à la libération, étant considéré comme un brave homme étranger aux malheurs de son époque, malgré la lettre dans laquelle il se décrivait comme étant d'ascendance pure aryenne afin de pouvoir devenir membre de la corporation du cinéma créée par l'occupant allemand. Avec un documentaire à la gloire de l'Allemagne, "Deutsche Grosse", Jan Meeuwissen se montra beaucoup plus engagé en 1943. En 1943 encore, Frans Develter produisit un film de long métrage en trois parties "Vlaanderen te Weer" destiné à montrer que la Flandre, martyrisée par la Belgique, avait retrouvé sa grandeur grâce au national-socialisme. À Anvers, Jan Vanderheyden, par ailleurs cheville ouvrière de la corporation du film, "führer" de la branche production-distribution, produisit plusieurs courts métrages et longs métrages purement distractifs. ce qui lui valut seulement quelques critiques après la guerre. En Wallonie, le peintre liégeois Auguste Mambour fut condamné parce qu'on lui reprochait sa sympathie pour l'ordre nouveau installé par les amis de l'Allemagne, notamment un voyage culturel en Allemagne comme ceux qu'organisait le ministre nazi Joseph Goebbels à l'intention d'artistes des pays occupés. Dans le domaine de la presse et de la littérature, le dessinateur de presse Paul Jamin, collaborateur du journal d’extrême droite "Le Pays Réel", d'abord condamné à mort puis, finalement, sorti de prison après une commutation de peine, devint le dessinateur attitré du journal satirique belge "Pan" fondé par un Léo Campion anarchiste et résistant. Le dessinateur et auteur de bandes dessinées Georges Remi, plus connu sous son pseudonyme Hergé, créateur de Tintin, ne passa qu'une nuit en prison pour avoir publié dans le journal "Le Soir" alors que ce plus important organe de la presse belge de l'époque avait été réquisitionné par les collaborateurs des Allemands, ce qui, depuis, fait désigner ce journal sous le nom de "Soir volé". Ce journal fut imité dans un pastiche resté célèbre en Belgique sous le nom de faux Soir. Les auteurs parvinrent à distribuer dans les kiosques cette imitation du journal collaborateur. Ils y avaient imprimé plaisanteries anti-allemandes et articles contre la collaboration qui mettaient en cause des journalistes ralliés aux occupants. Parmi ces écrivains et journalistes qui soutenaient l'Allemagne dans la presse, Robert Poulet avait fondé un quotidien "le Nouveau Journal" soutien des occupants et qui, plus tard, prétendit qu'il était . Prenant ses distances en 1943 avec la politique pro-allemande, il fut cependant condamné à mort par la justice belge, peine commuée en détention à perpétuité suivie d'une grâce avec expulsion en France où il entama une carrière de penseur et philosophe. De même, Félicien Marceau, pseudonyme de Louis Carette, journaliste à la radio sous contrôle allemand qui démissionna en 1942 pour devenir éditeur indépendant et réfugié en France en 1945, étant poursuivi notamment pour des émissions qui parurent favorables à l'appel au travail volontaire en Allemagne. Sous son pseudonyme de Félicien Marceau, il poursuivit à Paris une carrière d'écrivain et d'homme de théâtre qui lui valut le prix Goncourt et une place à l'Académie française avant de mourir à 98 ans. L'indulgence à l'égard des artistes et intellectuels de la collaboration ne fut pas toujours la règle. On peut citer le cas emblématique du brillant essayiste et critique d'art Paul Colin, qui fut apparemment de gauche comme le révèlent ses écrits d'avant guerre en faveur du surréalisme, mais qui, dès 1940, se rallia aux idées des collaborateurs de l'ennemi partisans d'un régime autoritaire. En 1942, il était abattu en pleine rue par de jeunes résistants, malgré la présence de gardes du corps allemands.

Les États-Unis prennent l’initiative d’avoir une attitude "positive". Ils imposent la démocratie, particulièrement en Allemagne de l'Ouest et au Japon, à travers une épuration et un contrôle des rouages de l'État et de l'éducation. Parallèlement, ils fournissent à partir de 1947 une aide économique à la reconstruction de l’Europe, connue sous le nom de plan Marshall. Celle-ci permet une reconstruction rapide des économies occidentales, achevée au début des années 1950, et évite aux populations la tentation de s’abandonner au communisme ou aux néo-fascismes.

À l’issue de la Seconde Guerre mondiale, les États-Unis sont avec l’URSS l’une des deux plus grandes puissances mondiales. Les États-Unis possèdent la première flotte de guerre, la première flotte de commerce, ils détiennent 75 % des stocks d’or du monde (d’où la devise « "dollar as good as gold" », le dollar est aussi sûr que l’or).

16 millions d’Américains furent incorporés dans les forces armées des États-Unis, y périrent, dont sur le champ de bataille.

Après 1945, l'Italie accuse le coup de la défaite des puissances de l'Axe : le référendum constitutionnel de 1946 signe le passage du régime monarchique qui avait survécu tout au long de la guerre, au régime républicain. Grâce à la stabilité et aux politiques keynésiennes des nouveaux gouvernements républicains, l'Italie connaît ensuite une très forte expansion , phénomène appelé les Trente Glorieuses. Le constructeur automobile Fiat devient le symbole du miracle italien, dont la période va des élections d'avril 1948 aux Jeux Olympiques de Rome en 1960 : automobiles en 1955, 10 millions cinq ans après. Le fabricant de scooters Vespa n'est pas en reste ; entre 1945 et 1965, il en vend 3,5 millions en Italie. Dans le sillage de son expansion économique et de son retour à un statut de puissance de moyenne taille, l’Italie adhère en 1949 à l'Organisation du traité de l'Atlantique nord et en 1955, elle est admise aux Nations unies.

Staline n’est pas en reste et fut l’un des grands gagnants du conflit. Le prestige et le rôle de l’Union soviétique sortent grandis bien au-delà des seuls cercles communistes. Réintégrée dans le concert des nations, l’URSS est membre permanent du Conseil de Sécurité.

Pour les Russes, cette "grande guerre patriotique" menée sur le front de l’Est invoqua la survie de la nation. En portant un toast au peuple russe lors du défilé de la victoire, le 24 juin 1945, Staline confirmait le retour de l’URSS à une forme plus accentuée de nationalisme grand-russe voire de chauvinisme, aux dépens des minorités nationales et, bien vite, des Juifs « cosmopolites ».

Les annexions de 1939-1940 sont confirmées, et d’autres sont venues s’ajouter à la victoire. L’URSS a augmenté sa superficie de et sa population de 24 millions d’habitants, aussitôt soumis à une très brutale soviétisation par la terreur. Derrière le rideau de fer, le système stalinien est progressivement imposé pour des décennies à un empire immense allant de Berlin-Est à la Corée du Nord, en attendant le basculement de la Chine et du Viêt Nam dans le camp communiste.

Cependant, l’URSS sort considérablement appauvrie de la guerre, qui lui a coûté plus de 25 millions de morts, ainsi que les pires destructions jamais subies par un belligérant dans l’histoire humaine. En 1945, une commission officielle estime que le coût des destructions équivaut au double des investissements consentis lors des deux premiers plans quinquennaux des années 1930. Enfin, technologiquement, l’Union soviétique accuse un retard sur l’Amérique, dont elle ne brise le monopole nucléaire qu’en 1949.

En tout environ 38 millions de civils furent tués par les nazis et leurs alliés.

En Europe : entre 8,8 et 10,7 millions de militaires soviétiques, 5,3 millions de militaires allemands, six millions de Polonais, dont trois millions de Juifs et trois millions de catholiques ; trois millions de Juifs des autres pays d’Europe ; deux millions de Tziganes, handicapés, homosexuels et autres.

Concernant les seules pertes militaires en Europe, selon les estimations, environ de militaires sont morts sur les champs de bataille européens, dont du côté des alliés et du côté des forces de l'Axe. Les tués de l’Armée rouge constituent 53 % du total des pertes militaires connues en Europe, ceux de la Wehrmacht 31 %, ceux du Royaume-Uni 1,8 %, ceux de la France 1,4 % et ceux de l’armée nord-américaine 1,3 %. Les pertes militaires de l’Union soviétique représentent 88 % du total des pertes alliées en Europe (Royaume-Uni 3 %, France 2,3 % et États-Unis 2,2 %). Le total des pertes militaires seules de l'Allemagne et de l'Union soviétique réunies représentent 84 % du total de toutes les pertes militaires subies en Europe. Les pertes militaires du conflit germano-russe seul sont de soit 78 % du total des pertes militaires subies en Europe.

En Asie : les historiens évaluent entre 10 et 30 millions le nombre de morts causées par les exactions japonaises, dont 2,7 millions pour la seule opération de la menée dans le Nord de la Chine par le général Yasuji Okamura.

De nombreux massacres de civils ou crimes de guerre ont été perpétrés au cours du conflit, en particulier par les "Einsatzgruppen" sur le front de l'Est, mais aussi de façon plus générale par la Wehrmacht et les SS. Dès le , les Alliés mettaient en place la « Commission des crimes de guerre des Nations unies » chargée d'enquêter sur les crimes de guerre commis par l'Axe. Une semaine plus tard, la Déclaration de Moscou énonçait la volonté de traquer les criminels de guerre nazis « jusqu'aux confins de la terre ». Non lié à l'ONU (qui ne fut fondé qu'en 1945), celle-là fut assistée à partir de mars 1945 par CROWCASS, chargé par le SHAEF d'établir une liste des criminels de guerre nazis. Cette volonté présida à l'instauration du tribunal de Nuremberg, jugeant les plus hauts responsables nazis encore vivants. CROWCASS fut cependant rapidement dépassé, la volonté initiale de traque contre les criminels de guerre cédant dès 1945 à d'autres priorités, marquées en particulier par l'éclatement de la guerre froide en 1947.

Parmi les divers crimes de guerre, on peut citer :



Il faut encore mentionner l’exécution sommaire de civils et de soldats alliés en uniforme (en particulier certains paras parachutés par le SOE afin d’encadrer les maquis ainsi que de certains pilotes, dont Martin Bormann autorisa et encouragea le lynchage en 1944).

Certaines opérations de bombardement de villes ont causé de nombreuses victimes civiles. Le nombre de victimes civiles était parfois un but recherché pour affaiblir le « moral » de l'adversaire.

La décision prise en août 1937 par Hirohito d’approuver une directive de son état-major supprimant l’application des traités internationaux sur la protection des prisonniers de guerre entraîna la mort de plusieurs millions de civils en Chine. Étendue à compter de 1941 aux autres pays conquis, cette mesure causa la mort d’une quantité phénoménale de civils et de prisonniers alliés détenus dans des conditions atroces (témoignage de Roger Cyr des Royal rifles).

Parmi les crimes de l’armée impériale japonaise au cours de l'Ère Shōwa (1926-1989), les plus notables sont les suivants :

Plusieurs rapports écrits et témoignages colligés par la Section australienne des Crimes de guerre du Tribunal de Tokyo et analysés par l’enquêteur (le futur juge en chef du Tribunal), démontrent que les soldats japonais commirent des actes de cannibalisme à l’encontre des prisonniers alliés. Dans bien des cas, ces actes étaient motivés par la famine mais selon l’historien Yuki Tanaka, « le cannibalisme était souvent une activité systématique menée par des escouades entières et sous le commandement d’officiers. »

Selon le témoignage de nombreux prisonniers comme le soldat indien Hatam Ali, les victimes étaient parfois dépecées vivantes. Les plus hauts gradés connus ayant pratiqué le cannibalisme sont le lieutenant-général Yoshio Tachibana, qui avec 11 membres de son personnel, a été jugé pour avoir fait décapiter et mangé un aviateur américain en août 1944 à Chichi Jima et le vice-amiral Mori pour avoir mangé un prisonnier lors d’une réception tenue en février 1945.

Le Service aérien de l'armée impériale japonaise et celui de la marine menèrent, de 1937 à 1945, une campagne systématique de bombardements contre des objectifs civils en Extrême-orient et même contre la ville de Darwin en Australie. Les zones les plus éprouvées furent les grandes villes chinoises comme Shanghai et Chongqing. À l’automne 1937, la violence des bombardements de Nanjing et de Guangzhou entraina une résolution de blâme du Comité aviseur de l’Extrême-Orient de la Société des Nations à l’encontre du Japon. Lord Cranborne, le sous-secrétaire d'État aux Affaires étrangères de Grande-Bretagne, émit sa propre déclaration d’indignation : 

Pour la première fois dans l'histoire de l'humanité l'arme nucléaire est utilisée par les États-Unis pour les bombardements atomiques d'Hiroshima et Nagasaki. Le nombre de victimes immédiates est estimé à pour Hiroshima et pour Nagasaki. Le nombre de victimes des suites d'irradiation est mal connu et contesté, le maire d'Hiroshima évoque un total de victimes.

En Europe, les gaz de combat ne furent pas utilisés dans les combats entre belligérants, mais seulement contre les civils déportés, dans les camps d’extermination nazis. Des réserves importantes de gaz "tabun" et "sarin" furent retrouvées en Allemagne en 1945, suffisantes pour tuer des millions de personnes. Elles furent immergées dans des caissons de béton sous la Manche. On s’inquiète de leur état de conservation aujourd’hui.

En Asie toutefois, les travaux des historiens Yoshiaki Yoshimi et Seiya Matsuno, démontrent que Hirohito permettait dès juillet 1937 l’utilisation systématique de gaz toxiques contre l’armée chinoise et les populations civiles. Par peur des représailles et afin de s’assurer que ces armes ne soient jamais employées contre des intérêts occidentaux, chaque utilisation faisait l’objet d’une directive spécifique approuvée par l’empereur et transmise par le chef d'état-major de l’armée, le prince Kotohito Kan'in (le général Hajime Sugiyama à compter de 1940). Dès 1939, les armes chimiques furent employées en URSS et en Mongolie puis aux Philippines en 1942.

En 2004, Yoshimi découvrit toutefois dans les archives nationales australiennes des documents démontrant que des gaz toxiques avaient été testés sur des prisonniers australiens et néerlandais en 1944 en Indonésie.

À ces armes chimiques, s’ajoutent les armes bactériologiques produites par l’unité 731 et employées à maintes reprises contre des civils en Chine et contre l’armée soviétique lors de la bataille de Halhin Gol.

Toutes les troupes belligérantes de la Grande Guerre avaient commis ou laissé commettre de nombreux viols de guerre. Les historiens Ian Kershaw et Rees rapportent que contrairement à la propagande de la Wehrmacht qui défendait le mythe d'une armée saine, des viols à grande échelle ont été commis par l'armée allemande.
Les estimations concernant le nombre de viols de femmes soviétiques par la Wehrmacht atteint les , avec entre et enfants nés du fait de ces viols.

L’Armée rouge fut explicitement encouragée, en représailles aux exactions massives du Reich en URSS, à terroriser les populations allemandes par le viol et les pillages à grande échelle : selon Hanna Schissler, de nombreuses Allemandes de l’Est envahi ont subi en 1945 les violences systématiques des soldats soviétiques. En Yougoslavie théoriquement alliée, Milovan Djilas se plaignit en personne à Staline de milliers de viols, le dictateur soviétique lui répondant cyniquement que l’Armée rouge avait assez enduré pour ne pas devoir s’attarder à ce genre de récriminations.

Selon l'historien Robert J. Lilly, environ femmes auraient été violées par les troupes américaines en Angleterre puis en Normandie. Quant au nombre de victimes en Allemagne, territoire ennemi, il est inconnu. Certains militaires coupables ont été exécutés, comme dans l'Affaire Clarence Whitfield, condamné à mort par pendaison le 20 juin 1944 à Canisy par la cour martiale. Vingt-et-un GIs furent condamnés en France pour viol, et les autorités militaires américaines invitèrent les victimes à assister à la pendaison des coupables.

L'historien Peter Schrijvers estime que plus de femmes ont été violées par les troupes américaines à l'occasion de la bataille d'Okinawa.

Dès avant-guerre, Staline considère les minorités vivants aux frontières de l'URSS comme suspectes d’anti-stalinisme par définition, et, dans l’éventualité d’un conflit, ordonne pendant les Grandes Purges de 1937-1938 la déportation "préventive" de centaines de milliers de Polonais, de Caréliens, de Lettons, mais aussi, à la frontière asiatique, de près de Chinois, Bouriates, Mongols et Coréens qui se retrouvent tous en Sibérie et au Kazakhstan. Lors du pacte germano-soviétique, l’URSS brise toute résistance à la soviétisation en déportant de l’automne 1939 à l’été 1941 plus d’un million de citoyens nouvellement annexés, Polonais, Moldaves, Baltes, Finlandais et autres, soit plus de par jour au total. Selon les rapports du commissaire Krouglov à Staline cités par l’historien russe Nikolaï Bougaï, la moitié meurent en déportation dans l’année de leur arrivée à destination, faute de structures adéquates pour permettre leur survie sur place.

Des forces non négligeables sont ensuite distraites du front en pleine offensive allemande de l’été 1941, afin de déporter la totalité des Allemands de la Volga et du reste de l’URSS, descendants de colons présents depuis deux siècles. Au printemps 1944, sous la fausse accusation de collaboration, quatorze peuples représentant deux millions de victimes, dont l’intégralité des Tchétchènes-Ingouches, des Tatars de Crimée, des Kalmouks, des Karatchaïs, etc. sont déportés collectivement en Sibérie et en Asie centrale. La déportation des Tchétchènes, femmes, enfants, militants communistes et soldats décorés compris, fut accomplie en six jours par le NKVD en mars 1944, ce qui reste à ce jour la plus rapide déportation de l’histoire. Les biens des peuples déportés furent cédés à des colons russes. Leurs républiques autonomes souvent supprimées et leurs villes débaptisées, et en 1949, un décret du Soviet Suprême déclara que les peuples « punis » resteraient exilés à perpétuité. Ces mesures ne furent abrogées que sous Khrouchtchev puis sous Gorbatchev.

À la reprise des Pays baltes, de l’Ukraine, de la Moldavie et de la Pologne orientale (1945), de nouvelles déportations massives au Goulag frappèrent bien sûr les collaborateurs locaux des nazis, mais aussi les résistants non-communistes et ceux qui après s'être battus contre les nazis ou leurs équivalents locaux, refusèrent de déposer les armes, enfin les populations civiles accusées à tort ou à raison de soutenir ces derniers. Selon Anne Applebaum et Jean-Jacques Marie, 6 à 10 % des populations baltes, polonaise, ouest-ukrainienne ou moldave se trouvent ainsi en déportation à la fin des années 1940. Des rafles massives de "suspects" ont également lieu au fur et à mesure de l’avancée de l’Armée rouge en Europe de l’Est, emportant sans retour des milliers d’intellectuels, démocrates, franc-maçons, réseaux juifs de résistance, prêtres ou étrangers : ainsi disparut en février 1945 à Budapest, le héros du sauvetage des Juifs hongrois, Raoul Wallenberg.

Il faut leur ajouter les centaines de milliers de soldats soviétiques déportés pendant la guerre pour « défaillance » ou pour esprit critique, tel Alexandre Soljenitsyne arrêté sur le front de Prusse-Orientale en février 1945 pour avoir mis en doute, dans une lettre privée, le génie militaire de Staline. De nombreux anciens prisonniers de guerre des Allemands (avoir été capturés faisait d’eux des « traîtres »), travailleurs civils volontaires ou forcés en Allemagne, furent également traités en coupables à leur retour (souvent forcé) au pays, au même titre que les débris de l’armée Vlassov, et allèrent former la génération d’après-guerre des captifs du Goulag. Quant aux centaines de milliers de prisonniers de guerre, les derniers Allemands ne furent relâchés qu’au milieu des années 1950, beaucoup périrent en détention, et les Japonais survivants furent définitivement assignés au Kazakhstan parmi les Coréens déjà déportés là depuis les années 1930.

Il y avait en Europe centrale (Prusse, Tchécoslovaquie, Pologne et pays baltes) des implantations allemandes depuis de nombreux siècles.

L'existence de ces implantations avait joué un rôle dans l'enclenchement des hostilités. Ainsi la demande de rattachement à l'Allemagne pour les Allemands des Sudètes avait servi de prétexte au démantèlement de la Tchécoslovaquie, accordé par les accords de Munich en 1938. De la même façon le gouvernement nazi s'était appuyé sur l'isolement géographique des populations de Prusse-Orientale pour réclamer l'annexion du corridor de Dantzig et préparer ainsi la guerre contre la Pologne.

Durant la guerre, le ralliement de ces minorités allemandes à l'occupation nazie, et la colonisation de zones conquises à l'Est, combinées aux atrocités imputables aux troupes nazies, créèrent ou renforcèrent à l'égard des populations civiles allemandes un sentiment de rejet parmi les populations autochtones. De plus, les populations civiles allemandes à l'est des territoires du Reich, redoutaient les exactions des troupes soviétiques en représailles des atrocités commises en URSS par les troupes nazies.

Enfin à l'issue de la guerre, les frontières furent redessinées, réduisant globalement l'espace de l'Allemagne d'avant-guerre.

L'ensemble de ces éléments conduit à la fin de la guerre et dans les années qui suivent à d'importants transferts de populations d'est en ouest, notamment de nombreux germanophones. En tout, 8 millions d’Allemands ont été expulsés en 1945 de l’Europe centrale et orientale, dont 2 millions des anciens territoires du Reich situés de l’est de la ligne Oder-Neisse, et cédés à la Pologne.
Des consistantes minorités italiennes existaient avant la guerre dans les Balkans, et notamment en Dalmatie et en Istrie. Entre 1945 et 1947, à la suite de la cession de l'Istrie et de la ville d Zadar à la Yougoslavie, plus de 300.000 italiens d'Istrie et Dalmatie furent obligés de quitter ces régions et de rejoindre l'Italie. De même, pour les 35.000 italiens qui habitaient les anciennes colonies italiennes de Rhodes et du Dodecanese, cédées à la Grèce.

Un phénomène comparable s’est produit en Asie : 13 millions de Japonais durent quitter la Corée, la Chine et les îles du Pacifique conquises au par l’empire du Soleil-Levant. Comme en Allemagne, cet afflux important de réfugiés dans un pays en ruines accrut dans l’immédiat la misère des civils, mais compensa les pertes démographiques pour relever les défis de la reconstruction.

Dans les pays occupés, les nazis ont volé d’innombrables œuvres d’art, collections juives en tête. Ce pillage artistique est orchestré particulièrement par Hermann Göring et Alfred Rosenberg suivant le principe du "Kunstschutz". Selon l’historien Marc Mazower, les agents de Rosenberg, rien qu’en Europe occidentale, ont pillé pour 674 trains de marchandises, meubles et objets saisis dans les appartements des Juifs déportés.

Sur le territoire soviétique, près de villes et plus de villages, entreprises industrielles, fermes collectives et étatiques, maisons, écoles, universités et bibliothèques publiques ont été détruits. Dans l’ensemble, les pertes matérielles ont été estimées à 600 milliards d’euros.

La Shoah est aussi une catastrophe culturelle irréparable. Le "yiddishland" d’Europe centrale et orientale, les derniers romaniotes de Grèce sont pratiquement anéantis, et l’on estime que les trois quarts des locuteurs du yiddish et les cinq sixièmes du yévanique ont disparu pendant la guerre. Si la France n’a perdu « que » le quart de sa population juive, de sorte que le monde israélite français a survécu, en revanche, les communautés juives d’Amsterdam, Berlin, Vienne, Budapest ou Vilnius ont été éradiquées sans retour, à plus de 90 %. Les nazis ont aussi cherché à effacer toute trace du passé juif multiséculaire en spoliant leurs victimes de tous leurs biens et œuvres d’art (aryanisation), en détruisant les synagogues, en brûlant des livres de prières, en retournant les cimetières.

Les Allemands ont aussi emmené de nombreuses archives privées et publiques de toute sorte, dont beaucoup ont été perdues, ou récupérées par les Russes qui les dissimulèrent pendant un demi-siècle. Si une partie des trésors volés est découverte par les Anglo-Saxons à la chute du Reich et rendue aux musées et aux propriétaires légitimes de France, de Belgique et des Pays-Bas, l’URSS puis la Russie ont toujours refusé de restituer certains chefs-d’œuvre figurant dans le butin de l’Armée rouge en 1945, ainsi le célèbre « trésor de Priam ». Les nazis ont aussi, çà et là, détruit des toiles représentatives de ce qu’ils qualifiaient d’« art dégénéré ». Par exemple, ils ont organisé au jardin des Tuileries, le 27 mai 1943, un autodafé de 500 œuvres de Picasso, Léger, Klee et Ernst. Quant aux Soviétiques, ils ont aussi emmené de nombreuses archives et œuvres d’art privées dans les pays qu’ils ont libéré ou occupé en 1944-45, dont fort peu ont revu, après 1990, leur pays d’origine.

Nombre de vieilles villes japonaises, surtout faites de bois et de papier, ont flambé sous les bombardements. Des villes telle Kyoto ont toutefois été épargnées par les bombardiers américains en raison de leur patrimoine prestigieux. En Europe, l’abbaye du Mont-Cassin, berceau du monachisme bénédictin au , a été bombardée par les alliés lors de la bataille du Monte Cassino en 1944.
L’historien Jörg Friedrich a établi la liste des dégâts patrimoniaux subis par les villes allemandes : ainsi ont été radicalement dévastées des villes telles Berlin, Hambourg, Cologne, Dresde, Nuremberg, Breslau, ou encore bon nombre de villes moyennes au passé très prestigieux telles Potsdam, Fribourg, Ulm, Wurtzbourg, ou Bayreuth. Les 28 villes de la Ruhr ont aussi été durement bombardées et inondées. En sus de divers cathédrales, palais et centres historiques, ont par exemple flambé les maisons natales de Goethe, de Kleist, de Martin Luther ou des frères Grimm.

Jörg Friedrich établit aussi que quelque 40 % des archives allemandes totales ont été perdues, ainsi que quelque 8 millions d’ouvrages des bibliothèques publiques, dont des milliers de thèses irremplaçables, des incunables et des manuscrits précieux. À titre d’exemple, la bibliothèque nationale bavaroise de Munich a perdu volumes, celle d’Hambourg , celle de l’université de Münster . Selon l’historien, « on n’avait jamais brûlé autant de livres de l’histoire de l’Humanité ». Toutefois, la majorité des ouvrages, documents et œuvres d’art amovibles, dissimulés dans des mines, des bunkers ou des fermes, ont été préservés.

John Keegan relève que les bombardements allemands ont détruit toute la vieille ville de Varsovie, le centre Renaissance de Rotterdam (détruit en mai 1940) et une grande partie de la City de Londres. Beaucoup de villes biélorusses (Minsk), ukrainiennes (Kiev, Kherson, Kharkov) et russes (Tsarskoïe Selo près de Petrograd/Leningrad, Tsaristyne/Stalingrad, Koursk) ont été sévèrement endommagées et ont perdu leurs centres anciens lors de leur conquête par les Allemands ou de leur reconquête par l’Armée rouge. En France, Bordeaux est le seul grand port de la côte atlantique française à sortir à peu près indemne de la guerre, mais les centres médiévaux de Caen et de Rouen ont été ravagés par les bombardements américains et les combats de rue. Vienne et Budapest ont été endommagées lors de leur conquête par les Soviétiques. Cependant, relève-t-il, des joyaux tels Oxford et Cambridge n’ont jamais été bombardées, ni Athènes ou Venise. Paris a peu souffert dans son patrimoine, alors que les Allemands ont fait sauter tous les ponts de Florence en août 1944, sauf le Ponte Vecchio, le plus ancien et le plus prestigieux (en fait le seul trop étroit pour les blindés).

Après la guerre, beaucoup de centres-villes et de monuments ont dû être reconstruits à l’identique. Quelques-uns sont restés en l'état à titre de mémorial, telle l'église du souvenir sur le Kurfürstendamm de Berlin. Des impacts de balles sont encore visibles sur certaines façades de monuments parisiens, ainsi à l’École militaire, à l’École des Mines ou sur le palais de Justice. D’autres cités ravagées ont été après-guerre le laboratoire de l’urbanisme moderne, ainsi la reconstruction du Havre confiée à l’architecte Auguste Perret.

La fin du conflit planétaire ne signifie pas partout le retour à la paix. Des guérillas à la fois antisoviétiques et antiallemandes continuent à se battre aux confins de l’Ukraine et des Pays baltes jusqu’en 1946, voire jusqu’à la fin des années 1940. La Grèce dès décembre 1944, la Chine en 1945 sombrent dans la guerre civile jusqu’en 1949, tandis que de longues guerres d’indépendance commencent immédiatement en Palestine, en Indonésie, en Indochine. En Indochine française, le Việt Minh prend le contrôle d'une partie du territoire au cours de l'épisode dit de la Révolution d'Août : son chef, Hô Chi Minh, proclame le 2 septembre l'indépendance de la République démocratique du Viêt Nam. La situation débouche l'année suivante sur la guerre d'Indochine. Aux Indes orientales néerlandaises, coupées de leur métropole par l'occupation japonaise, Soekarno proclame le 17 août 1945 l'indépendance de l'Indonésie : l'opposition des Pays-Bas débouche sur la période dite de la Révolution nationale indonésienne. En Algérie française, le massacre de Sétif, survenu le jour même de la capitulation allemande (), annonce la future guerre d'Algérie (1954). En Palestine sous mandat britannique, les conflits entre mouvements Juifs sionistes, Arabes et Britanniques débouchent à la fin 1947 sur le plan de partage de la Palestine, dont le refus par les Arabes entraîne la guerre civile de 1947-48.

Après la Seconde Guerre mondiale se sont dessinés les rapports de forces qui ont caractérisé la guerre froide, mais aussi un grand nombre de situations géopolitiques actuelles.

Le travail de reconstitution historique de cette période est toujours en cours, et sujet à de nombreuses controverses, propres à exacerber les sensibilités nationales : la collaboration française sous Vichy en est un exemple. Les affrontements violents entre collaborateurs et résistants en France, en Italie ou dans les Balkans, ont causé des traumatismes durables, et le conflit meurtrier en ex-Yougoslavie (1991-1995) a vu ressurgir explicitement bien des vieilles rancunes. En Asie, les habitants des pays limitrophes du Japon (particulièrement la Chine et la Corée) restent inquiets du révisionnisme japonais, d’autant que le gouvernement du Japon d’après-guerre a toujours fait preuve d’ambiguité concernant son rôle pendant la période impérialiste (qui commence en 1910 avec la colonisation de la Corée, c’est-à-dire bien avant le début de la Seconde Guerre mondiale) à l’image des visites répétées de politiciens japonais au très controversé sanctuaire Yasukuni ou encore du problème des manuels scolaires japonais, qui tendent à embellir le passé du Japon.

Par ailleurs, l’holocauste juif en particulier a donné lieu à un important programme de dédommagements de guerre. Toutefois, les Alliés n’ont pas souhaité répéter l’erreur des dédommagements trop lourds exigés à l’Allemagne après la Première Guerre mondiale, ce qui a permis au pays de connaître un « miracle économique », et d’intégrer la Communauté européenne du charbon et de l'acier (CECA), prélude à la Communauté européenne. Le plan Marshall a permis aux économies européennes de se reconstruire.

Ce conflit fut le plus coûteux en vies humaines de toute l’histoire de l’humanité. On recense plus de 55 millions de morts (dont 39 millions d'Européens) avec plus de victimes civiles que militaires. L’URSS a payé le plus lourd tribut avec plus de 26 millions de victimes ( en réalité), civils et militaires (14 % de sa population).

Des peuples entiers sont presque décimés : les trois quarts des Juifs d’Europe ont péri par suite du génocide. Le plus terrible s’est produit en Europe centrale et orientale : la Pologne a perdu 18 % de sa population, la Yougoslavie plus de 10,6 %. Combats, pillages, terres brûlées et sabotages ont ravagé l'économie. Les populations en sortent démunies.

Nombre de régions et de villes ont connu des bombardements ravageant plusieurs quartiers : Rotterdam, Bruxelles, Liège entre autres. D'autres sont radicalement ravagées : Caen, Le Havre, Hiroshima, Nagasaki, Tokyo, Hambourg, Dresde, Stalingrad, Leningrad, Sébastopol, Kharkov, Varsovie, Budapest, Berlin sont les plus connues. Un grand nombre de pays demandent également réparation de guerre à l'Axe. Les Pays-Bas vont jusqu'à proposer un Plan d'annexion d'une partie de l'Allemagne, et renvoient en Allemagne les citoyens allemands ayant aidé le Reich lors de son occupation du pays.

La radio fut pendant toute la guerre une arme de propagande fondamentale. Sous l’occupation nazie, des millions d’Européens écoutèrent chaque jour en cachette la BBC, dont les émissions en toutes les langues entretenaient l’espoir. Winston Churchill galvanisa le Parlement, la nation britannique et les peuples occupés à coup de discours radiodiffusés, et Charles de Gaulle, surnommé le "général Micro" par la propagande vichyste, ne fut longtemps qu’une voix pour beaucoup de Français.

La radio de Londres accueillit les célèbres chroniques de Jean Oberlé, de Maurice Schumann et de Pierre Dac dans le cadre des émissions « Honneur et Patrie » et « Les Français parlent aux Français ». L’audience énorme acquise par leur ennemi, le redoutable orateur ultra-collaborationniste Philippe Henriot, obligea la Résistance à exécuter ce dernier ().

Les Belges Jan Moedwil et Victor de Laveleye parlent au nom de leur gouvernement en exil, de Laveleye inventant un signe de propagande qui devient vite fameux. Il s'agit du signe V exécuté, pour signifier la première lettre du mot Victoire/Victory, avec l'index et le majeur de la main, signe que peuvent exécuter, par défi, les habitants des pays occupés et qui devient vite mondialement connu grâce au premier ministre anglais Winston Churchill à qui on en attribue souvent, et à tort, la paternité.

Sont également passées à la postérité les émissions antinazies de Thomas Mann, qui joutait avec Goebbels par-delà l’Atlantique, ou les chroniques de George Orwell en Grande-Bretagne. Avides de nouvelles impartiales, beaucoup de francophones appréciaient aussi la radio suisse, et notamment les éditoriaux réputés de René Payot.

Chaque camp utilisa à ses micros des ressortissants du pays ennemi pour saper le moral de ses civils et de ses soldats. Dès la Drôle de Guerre, Goebbels fit parler au micro de Radio-Stuttgart, non sans succès, un animateur francophone identifié comme étant le journaliste pro-nazi Paul Ferdonnet. William Joyce, dit « Lord Haw-Haw », un Américain d'origine nord-irlandaise, anima des émissions de propagande pro-allemande à destination du Royaume-Uni, que captèrent des millions d’auditeurs. Les Japonais utilisèrent également les services de diverses speakerines nippo-américaines ou anglophones, désignées par les GI sous le nom collectif de "Tokyo Rose" (« la Rose de Tokyo »). Inversement, le Ml Paulus, le vaincu de Stalingrad, parla à la radio de Moscou.

Cinq volumes de chroniques françaises de la BBC ont été éditées par Jean-Louis Crémieux-Brilhac sous le titre "Les voix de la liberté. Ici Londres", La Documentation française, 1975.

Nombre de grands écrivains ont été correspondants de guerre, ainsi l’Américain Ernest Hemingway qui témoigna de la libération de Paris, ou sur le front russe les romanciers Ilya Ehrenbourg et Vassili Grossman, lequel fut le premier journaliste à découvrir les ruines du camp d'extermination de Treblinka.

Étroitement censurée par les Allemands et leurs collaborateurs, et souvent compromise, la presse fut soumise à une sévère épuration en France libérée, l’historien Patrick Eveno estimant que 90 % des titres ont disparu ou changé de main.

"Le Temps" fut ainsi remplacé par "Le Monde" dès , "L’Auto" par "L'Équipe", ou "Paris-Soir" par "Le Parisien Libéré". Fondés en pleine clandestinité, de nombreux journaux de la Résistance entamaient aussi une carrière plus ou moins longue, à l’image de "Libération", de "Franc-Tireur" ou du "Dauphiné libéré". "Combat", qui s’attache Albert Camus à la Libération, perdure ainsi jusqu’en 1972, de même que "Les Lettres françaises" de Louis Aragon, revue littéraire qui a vu ses fondateurs Jacques Decours et Georges Politzer fusillés par l’occupant dès 1942. "Défense de la France", fondé dans le sous-sol de la Sorbonne le 14 juillet 1941, engendre "France-Soir" en septembre 1944.

En Belgique, la presse clandestine se déploie, parfois pour retrouver sa tradition de la Guerre mondiale, comme dans le cas de la Libre Belgique imprimée très professionnellement, mais, le plus souvent, sous la forme de feuilles imprimées avec des moyens modestes ou encore de journaux d'origine syndicale. Un coup extraordinaire est réussi par une équipe de résistants qui imite Le Soir, journal remontant au , mais réquisitionné par les Allemands pour devenir une feuille pro allemande d'où son surnom de « Soir volé ». L'imitation distribuée dans les kiosques ressemble, à première vue, à son modèle, mais le contenu en est truffé d'articles d'informations et de plaisanteries anti nazies. Des milliers d'exemplaires sont dans les mains de la population esbaudie, mais les Allemands n'auront de cesse de découvrir les coupables dont certains seront déportés et fusillés.

Parmi les nombreux photographes de guerre, on peut citer Robert Capa, présent le jour J sur les plages d’Omaha Beach.

Nombre de photos aux auteurs moins connus du grand public sont entrées dans la mémoire collective, ainsi le célèbre cliché des Américains plantant la bannière étoilée au sommet d’Iwo Jima, ou celui des Soviétiques Iegorov et Kantara attachant le drapeau rouge sur le Reichstag.

La "V-J Day in Times Square", photo emblématique du "V-J Day" ("Victory over Japan") reste celle qui fit la couverture de "Life Magazine", prise à Times Square le 14 août 1945 (heure de la Côte Est) ; on la doit au photojournaliste allemand Alfred Eisenstaedt.

De la même manière que "le jour le plus long", les photographes de presse ont tenté d'immortaliser par le cliché captant le mieux les événements suivants : Elbe Day "(jonction des troupes alliées américaines et soviétiques sur le sol allemand)", Jour V-E "(victoire en Europe)" et Jour V-J "(victoire sur le Japon)".

Fondées dans la clandestinité, les Éditions de Minuit entretinrent la résistance intellectuelle en France, publiant notamment "Le Silence de la mer" de Vercors (1941), un appel à opposer un mutisme digne aux tentatives de séduction de l’occupant.

Des recueils collectifs tels que "Le Cahier noir" ou "L’Honneur des Poètes" (1943) répliquèrent aux écrivains collaborationnistes tels que Céline, Brasillach, Lucien Rebatet. Des auteurs célèbres tels le prix Nobel norvégien Knut Hamsun ou le philosophe italien Giovanni Gentile mirent aussi leur plume au service de la cause allemande.

L'une des premières bandes dessinées destinées à édifier la jeunesse sur le déroulement du conflit fut "La bête est morte !" par Calvo (juin 1945).

Beaucoup d'écrivains choisirent de ne pas publier pendant la durée de la guerre pour ne pas devoir passer par les services d'éditeurs contrôlés par l’occupant, ainsi André Malraux ou Roger Martin du Gard. Cependant, en France, où la vie culturelle fut particulièrement animée et brillante pendant la guerre, une très large partie de la production théâtrale, littéraire ou philosophique ne fit aucune allusion au conflit en cours, bien des créateurs semblant s’accommoder plus ou moins de la mainmise allemande sur leurs éditeurs en particulier et sur la vie culturelle en général (Philippe Burrin, "La France à l'heure allemande 1940-1944", Seuil, 1995).

De nombreux poètes écrivirent pour la Résistance, ainsi Louis Aragon composant "La Rose et le Réséda" pour exalter l’union de « celui qui croyait au ciel, celui qui n’y croyait pas », ou Paul Éluard composant "Liberté" ou chantant le martyre de Gabriel Péri. Ils furent parfois victimes de la répression, ainsi Robert Desnos en France, Kak Munj au Danemark.

Des témoins cherchant à analyser les causes de la guerre et de la défaite produisirent des œuvres que leur lucidité reconnue et leur finesse d'écriture rendent toujours utilisables aujourd’hui, ainsi l’historien Marc Bloch (fusillé pour Résistance par les nazis) rédigeant "L'Étrange Défaite" dès l'été 1940, ou le philosophe catholique Jacques Maritain, militant de la France libre, publiant "À travers le désastre" à New York.

De nombreux contemporains tinrent des journaux intimes souvent de grande qualité, tels Ernst Jünger, affecté dans les forces d’occupation à Paris, le professeur résistant Jean Guéhenno en France, ou à Amsterdam la très jeune Anne Frank, victime de la Shoah.

Le traumatisme immense causé par la Déportation se reflète dès l’immédiat après-guerre dans les nombreux récits aussitôt produits par des rescapés des camps de concentration, qu’ils soient politiques ("L’Espèce humaine" de Robert Antelme, "L’Univers concentrationnaire" de David Rousset, prix Goncourt 1946) ou juifs (ainsi Primo Levi).

Après sa conclusion, la Seconde Guerre mondiale n’allait pas cesser d'être une source intarissable d’inspiration et de réflexion pour les auteurs, qu’ils aient ou non vécu les événements. En témoignerait encore, tout récemment, le succès en librairie des "Bienveillantes" de Johnattan Littel (2006).


Si l’on produit sans surprise un certain nombre de films de propagande pendant la guerre, beaucoup de réalisations visent d’abord à détendre les spectateurs dans une période très dure. Goebbels fit ainsi délibérément produire beaucoup plus de comédies musicales ou de films de style hollywoodien que d'œuvres proprement nazies ("Le Juif Süss") ; cela dit, la contribution de Leni Riefenstahl au "Triomphe de la volonté" lui sera reprochée régulièrement dans l'Allemagne d'après-guerre.

Staline commanda à Serguei Eisenstein le film Alexandre Nevski (1938), transposant le conflit à venir avec la nation germanique dans le contexte des Croisades baltes médiévales.

Aux États-Unis, ce sont les personnages de dessin animé qui prennent parti dans le conflit ; projetés avant les actualités cinématographiques, ces dessins animés avaient un fort impact sur l'opinion. "Blitz Wolf" est particulièrement représentatif, par Tex Avery.








</doc>
<doc id="2759" url="https://fr.wikipedia.org/wiki?curid=2759" title="Service public">
Service public

La notion de service public peut désigner :

L'existence de services publics au sens fonctionnel, attestée de l'époque médiévale à la Révolution de 1789, se caractérise par des moyens juridiques déjà différents : ce sont des pratiques sociales coordonnées par une autorité commune qui n'est pas forcément à l'origine l'État.

Dans l'Europe médiévale, les banalités (un four, un moulin, un pressoir, un entrepôt des grains, etc) sont un monopole du seigneur, qui perçoit à l'occasion de leur utilisation un droit d'usage. Les seigneurs concèdent quelquefois des tâches administratives communes (fiefs).

De même, à partir du , les communautés urbaines en certains lieux se substituent aux seigneurs. Les communes — outre les fours, moulins et bans de boucheries — assurent un monopole au maître d'école, fondent des léproseries et pourvoient au fonctionnement des fontaines publiques, l'entretien des remparts, le guet nocturne, etc. Elles emploient à cet effet du personnel (les esclaves ou « officiers » sont titulaires de l'office correspondant) ou imposent des corvées.

Au , Louis IX de France crée les Établissements pour le commun profit, ce que certains associent aux services publics.

Au , le terme de police apparaît dans les ordonnances royales et signifie à la fois la politique et la gestion de la chose publique.

Aux , dans le mouvement de la Monarchie absolue, l'autorité royale assure la mise en œuvre d'activités, exercées par ou pour le compte de la puissance publique : le Roi se considère comme le garant de la prospérité du Royaume et entend — par-delà la richesse de celui-ci — satisfaire la demande sociale de l'ensemble de ses sujets. De ce fait, les principaux services publics correspondent aux fonctions dites « régaliennes » et aux intitulés des différentes administrations qui se progressivement mettent en place dans un nombre croissant de domaines : ponts et chaussées, défense, justice, impôts, monnaie, commerce, etc.

À cette époque paraissent les « dictionnaires de police » qui sont de véritables codes de droit et de pratique administrative. Le "Traité de la Police de De Lamare" prend pour subdivision la santé, les vivres, la voirie, le commerce, les manufactures et les arts mécaniques…

Avec le siècle des Lumières apparaît la notion de contrat social, qui se concrétise à la Révolution française : le dirigeant n'est plus un « maître », mais un organisateur à qui l'on délègue la gestion et l'administration des biens communs. L'impôt sert alors à assurer cette gestion.

Sous la Révolution, le terme moderne de « service public » commence à faire son apparition, parfois assimilé à la fonction publique, parfois à une tâche d'intérêt général, ou à une prestation fournie aux citoyens par un organe particulier. À cette époque se forme l'idée que l'ensemble des institutions publiques constitue un ou des services publics.

Au , l'idée de service public se mue en principe volontariste, dotée d’une forte dimension idéologique, qui légitime des mouvements en faveur de l'interventionnisme d'État, du socialisme municipal ou de l'État-providence. Avec pour conséquence la constitution de diverses institutions sociales et de nouvelles administrations centrales (Santé, Éducation, Monuments historiques, Affaires sociales, etc.. La création de l'échelon du département marque la volonté d'un mouvement de déconcentration en vue de rapprocher — que l'on puisse effectuer le trajet en une journée de cheval — les citoyens-usagers de l'administration publique. Pour autant, le statut du service public n'émerge pas encore. La notion demeure intuitive, et surtout opératoire.

Fin et début du s, des juristes comme Léon Duguit posent que « le principe de tout système de droit public moderne se trouve résumé dans la proposition suivante : ceux qui en fait détiennent le pouvoir n'ont pas un droit subjectif de puissance publique, mais ils ont le devoir d'employer leur pouvoir à organiser les services publics et à contrôler le fonctionnement. » Le service public est par conséquent une donnée objective et matérielle qui ne se crée pas, mais se constate : « Toute activité dont l'accomplissement doit être assuré, réglé et contrôlé par les gouvernants, parce que l'accomplissement de cette activité est indispensable à la réalisation et au développement de l'interdépendance sociale, et qu'elle est d'une telle nature qu'elle ne peut être réalisée complètement que par les gouvernants, est un service public ».

Au lendemain de la Seconde Guerre mondiale, l'École de Bordeaux (Jèze, Rolland, Bonnard, de Laubadère) reprend le concept de service public pour le réorienter et le transformer en « technique juridique ».

Louis Rolland expose les critères qui permettent d'identifier le service public :

Pour sa part, Gaston Jèze n'hésite pas à conférer à la notion de service public un caractère pleinement subjectif : « Sont uniquement, exclusivement services publics, les besoins d'intérêt général que les gouvernants d'un pays donné, à un moment donné, ont décidé de satisfaire par le procédé du service public. »

Depuis la fin du , des analyses (d'inspiration pragmatique ou relevant de l'école libérale) pointent en réaction le coût budgétaire excessif, le service rendu insuffisant ou inadapté aux besoins réels, voire l'atteinte aux libertés ou la concurrence déloyale. Ces idées convergent et militent pour une mise en œuvre plus systématique de l'évaluation des politiques publiques, leur révision et l'évolution des institutions : fin des monopoles, évolution des entités responsables d'un service public (autonomie, indépendance, changement de statut juridique), extension du principe d'adaptation des politiques publiques aux zones géographiques ou aux publics variés par application du principe de subsidiarité et (en France) les lois de déconcentration et/ou de décentralisation, etc.

Dans les années 1970 et 1980, les milieux néo-libéraux introduisent de nouveaux concepts de gestion du service public avec la nouvelle gestion publique, qui aboutira dans de nombreux pays à la réforme de l'État et à la recherche d'une meilleure efficacité à moindre coût.

Plus récemment, le concept a bénéficié de la création début 2009 du site mon.service-public.fr permettant de centraliser toutes ces démarches administratives par internet.

Selon Prosper Weil : 

Poursuivant les travaux de Léon Duguit, Louis Rolland (1877-1956) cherche à systématiser le noyau des principes qui doivent s'appliquer à l'exploitation d'un service public, principes que la doctrine postérieure a ensuite appelés « Lois de Rolland » :
À ces trois principes basiques peuvent s'ajouter :

Les activités d'un service public sont soumises sur certains points à un régime juridique spécifique. Mais pour compléter la distinction entre service public et secteur public, on notera qu'une collectivité publique (État, collectivité territoriale) a notamment le choix entre :

Concernant les fonctions de service public remplies par le secteur public, on distingue en outre :

La raison généralement avancée dans ce dernier cas est un besoin d'intérêt général essentiel ou stratégique dont la nature est considérée non compatible avec le fonctionnement normal du marché. Sont citées par exemple certaines infrastructures uniques ou essentielles, nécessaires au fonctionnement des entreprises publiques comme privées : routes, voies ferrées principales, ports, troncs communs de réseaux téléphonique fixe…

L'exercice des activités dites régaliennes a toujours été revendiqué par la puissance publique (qu'il s'agisse des rois, puis à leur suite par les États de toute nature qui leur ont succédé). Ainsi :

Mais en réalité, l'observation historique montre que même ces fonctions n'étaient pas toujours (ou pas entièrement) sous le contrôle de l'État :

On ajoute aussi parfois l'émission de monnaie, bien que le monopole soit une création très récente, la règle sous le régime de l'étalon métallique étant, au contraire, l'existence de nombreuses monnaies circulant sur un même territoire.

On peut aussi ajouter la gestion des situations de crise et de famine, que le souverain se devait de traiter tant par charité que pour éviter les émeutes, révoltes, voire révolutions.

Ainsi, alors même que les fonctions dites régaliennes sont généralement considérées comme techniquement et moralement difficiles à sous-traiter à des sociétés privées, il apparaît que ce cas de figure s'est produit par le passé. En la matière, on observe donc une grande variation selon les lieux et les époques. L'évolution de la société peut aussi faire émerger le besoin de nouveaux services publics, comme elle peut en rendre certains inutiles (par abondance, ou par obsolescence).

Un bien public est un bien dont on ne peut éviter la consommation par ceux qui le souhaitent ("non-exclusion"), et, dans le cas d'un bien public pur, dont la disponibilité pour autrui n'est pas réduite par la consommation ("non-rivalité"), par opposition à un bien public impur. Un service public peut concerner ou non un bien public, tandis qu'inversement, un bien public peut être fourni par un service public ou privé. Les deux notions n'ont donc aucun rapport. 

De grandes « entreprises publiques » nationales comme la SNCF ou EDF appartiennent au secteur public. Cependant, les deux notions restent totalement indépendantes :


Certains services publics sont exercés dans un cadre concurrentiel (communications électroniques et audiovisuel par exemple). Une partie de la doctrine considère qu'un système monopolistique est plus adapté qu'un système concurrentiel pour atteindre tel objectif politique ou un optimum économique. On parle alors de monopole naturel ou, dans la législation et la jurisprudence européenne, de « droits exclusifs et spéciaux ». 

Enfin, certaines administrations publiques n'ont pas pour objet de fournir des prestations directes à leurs usagers. C'est le cas des centres des impôts par exemple, qui assurent une gestion administrative de la collecte publique mais n'offrent pas de prestations à proprement parler.

Un service public peut être financé directement par les bénéficiaires et ne pose alors pas de problème particulier. Mais l'affaire est fréquemment bien plus compliquée pour diverses raisons, par exemple (sans exhaustivité) :
Dans ces conditions, il faut trouver une source de financement alternative pour la "charge de service public". Le cas est, par exemple, prévu dans la Déclaration des droits de l'homme et du citoyen de 1789, qui pose comme principe à l'article 13 : La DDHC est citée par la Constitution comme étant l'un des fondements de cette dernière ;

Dans les deux derniers cas (péréquation tarifaire et lien avec un autre service rentable), on pouvait trouver commode d'instaurer un monopole, pour éviter qu'un opérateur alternatif rende le même service à un coût moindre parce que non grevé par la charge de service public. Cette solution est aujourd'hui abandonnée en Europe, pour ne pas fausser la concurrence et ne pas faciliter la hausse des prix qu'un monopole rend possible. Il reste en revanche possible d'obliger tout opérateur d'un secteur à contribuer à un service public, et donc de participer à une péréquation tarifaire ou de fournir le service même dans certaines conditions où cela lui coute plus que ne lui rapporte (en bénéficiant alors de subvention ou du droit de majorer ses tarifs sur d'autres secteurs). Voir ci-après.

On distingue la "redevance" de la "taxe". Une taxe est une perception fiscale perçue à l'occasion d'une transaction ou d'un service, qui peut s'appliquer à un service public aussi bien qu'à toute autre activité. Mais même si elle est perçue à l'occasion d'un service public, la taxe n'a pas pour autant vocation à le financer : elle alimente simplement le budget général. À l'inverse, une redevance est conçue comme spécifiquement destinée à financer le service, c'est ni plus ni moins que l'équivalent du prix qu'exigerait un prestataire privé (ou que peut exiger un prestataire public dans le cadre d'une activité concurrentielle).

L'intérêt principal d'un service public assuré par un État est qu'il fournirait un service que ne pourraient rendre dans les mêmes conditions des acteurs privés. La gestion publique de certains secteurs économiques peut conduire à des monopoles d'État pouvant, selon les libéraux, nuire à l'émulation et l'efficacité : le service rendu serait selon eux de moindre qualité et plus cher que s'il était soumis à la concurrence.

Pour les économistes non libéraux, un monopole d'État pourrait au contraire être avantageux pour l'usager (consommateur ou client dans le secteur privé) dans la mesure où le but de la structure d'État n'est pas d'être rentable, de gagner de l'argent, mais de fournir un service d'une certaine qualité pour la collectivité.

Les libéraux affirment que la concurrence stimule sans cesse l'organisation de l'activité de l'entreprise et cela conduit à la traque du gaspillage de l'argent.

Certains voient comme avantage du monopole public la suppression des coûts de concurrence (publicité, doublons). Les ressources seraient ainsi occupées à améliorer le service par la recherche et l'investissement, du fait d'un compromis sur le prix du service s'il est facturé directement (il pourrait dans certaines situations être financé par le budget de l'État ou être intégré dans la partie socialisée du salaire). L'émulation peut venir de la coopération avec des services publics étrangers.

Certains attribuent à la pensée libérale de graves menaces sur les services publics, celle-ci visant à les restreindre et les soumettre à la concurrence. Cette volonté, mais aussi le souci des États de ne pas dépendre d'entreprises qui appartiendraient à d'autres États, ni de se trouver face à une concurrence déloyale de ceux-ci, se traduit par des traités internationaux, comme l'AGCS qui conduit à la suppression progressive par commun accord des gouvernants de certains types de services publics. Selon cet accord, ces privatisations sont irréversibles.

Une autre question concerne le périmètre géographique d'un service public ce qui est lié à la question de la régionalisation et des zones économiques transnationales (Union européenne), voire mondiales.

L'Union européenne, dans ses traités, ne mentionne explicitement le service public que dans le cadre des transports (article 73 CE). La législation et la jurisprudence européennes utilisent habituellement des concepts jugés plus précis et indépendants du pays :

Il n'existe pas de réglementation des SIG dans leur ensemble au niveau européen. Le terme ne désigne d'ailleurs parfois que les seuls SIG non marchands. Les SIG restent donc de la compétence des États membres ou des collectivités locales. La Commission a toutefois reconnu en 1996 que les services d'intérêt général « sont au cœur du modèle européen de société ».

L'Union européenne s'intéresse en revanche de près aux SIEG, plusieurs fois mentionnés dans les traités (art. 16, 73, 86, 87 CE), sans toutefois les définir très précisément. La Commission et la Cour de justice tentent de concilier, dans le cadre des SIEG, le respect des missions de service public avec le principe de libre concurrence, principe fondamental de la politique économique de l'Union européenne. C'est dans ce cadre que la Commission mène une politique de libéralisation des principaux services dits « d'intérêt économique général » (SIEG). Les principaux secteurs concernés sont : l'énergie (gaz et électricité), les transports (tous modes), les services postaux et les télécommunications.

Elle veille tout particulièrement à ce que les financements de service public par les États ne faussent pas le jeu de la concurrence, en particulier sur les points suivants :

Certains services ont été reconnus comme services d'intérêt général par la jurisprudence de la Cour de justice des Communautés européennes. À titre d'exemple, la Cour a reconnu comme SIEG (dans certaines conditions précises) :

Pour permettre l'introduction de la concurrence dans les services, la Commission pousse à la scission de la gestion des infrastructures (lorsque celles-ci relèvent d'un monopole naturel) de l'exploitation des services, tous les exploitants devant se voir reconnu un droit d'accès égal à l'infrastructure. C'est ce qui a été fait pour les télécommunications (au niveau de la boucle locale, sans que soit imposée la séparation des activités de réseau et de fourniture), l'énergie (gaz et électricité), les chemins de fer, les ports et aéroports.

Le financement des SIEG est laissé à l'appréciation des États : il peut provenir de n'importe quelle combinaison des différentes ressources possibles : une redevance perçue auprès des usagers, une subvention de service public allouée par la collectivité, une péréquation entre activités rentables et non rentables de l'exploitant, de ressources commerciales complémentaires (exemple des ressources publicitaires pour la télévision), etc.

En France, les activités de service public peuvent être classées en trois catégories :


Parmi les activités concernées on citera par exemple :

Quand ils assurent conjointement des services du secteur marchand, les organismes publics correspondants relèvent à la fois du droit administratif et du droit commercial.

L'organisation des services publics en Allemagne ("Daseinsvorsorge") est géographique et non sectorielle : alors que, en France, une entité nationale gère en général de manière centralisée le service public d'un secteur donné (avec des exceptions comme la gestion de l'eau), ce sont des entreprises municipales ("Stadtwerke") qui gèrent un ensemble de services publics de plusieurs secteurs différents.

Dès le début du , les collectivités locales ont commencé à fournir des services publics sans intervention de l'État. Elles ont confié par la suite la gestion de ces services à des établissements publics. La gestion de ces services publics s'est organisée de manière transversale à plusieurs secteurs afin de bénéficier d'un accès plus aisé aux sources de financement, par exemple.

Chaque pays a sa pratique propre en matière de services publics. Il n'est pas de la compétence de l'ONU de posséder des services publics. Les structures de scolarisation et de soin mises en place à son initiative, ou celle d'organisations qui en dépendent comme l'UNESCO, sont de droit privé.

En matière maritime, certaines coutumes communes (obligation de secours, etc.) ou les services de positionnement (GPS, gLONASS et bientôt Galileo) peuvent s'apparenter au service public.







</doc>
<doc id="2760" url="https://fr.wikipedia.org/wiki?curid=2760" title="Sûreté biologique">
Sûreté biologique

La notion de « sûreté biologique » est polysémique (elle peut avoir plusieurs sens). 

De manière générale la sûreté biologique évoque les mesures à prendre pour sécuriser un patrimoine biologique (qui - selon le contexte - peut être réduit à l'agriculture, à la sylviculture, à la santé humaine ou étendu plus largement jusqu'à la biosphère).


Ces définitions découlent du document "sécurité et sûreté biologique" BWC/MSP/2008/MX/INF.1 24 juin 2008, GE.08-61893 (F) 090708 100708 de la Réunion des États Parties à la "Convention sur l'interdiction de la mise au point, de la fabrication et du stockage des armes bactériologiques (biologiques) ou à toxines et sur leur destruction".

L'expression « "sûreté biologique" » (biosecurity) peut prendre un sens différentes selon le contexte. Des lignes directrices de l'OMS publiées en septembre 2006 dans le contexte de l'alerte et de la réponse à une pandémie (virus H5N1 notamment) rappellent que cette expression a évolué simultanément dans des cadres différents, et qu'elle est donc employée différemment dans chacun de ces contextes.

Le glossaire d'un manuel de la FAO sur la production de vaccin contre la maladie de Newcastle définit la sûreté biologique comme les précautions prises pour réduire au minimum le risque d'introduire un agent infectieux dans une population animale (contexte vétérinaire).

Le glossaire du Commissaire néo-zélandais sur l’environnement définit la sûreté biologique comme l’exclusion, l’éradication et la gestion efficace des parasites et des organismes indésirables en Nouvelle-Zélande (contexte agricole).

Dans le cas des îles Galápagos, elle correspond à la protection de toutes les ressources naturelles contre les dangers liés à l'invasion d'espèces allochtones (contexte écologique).

D'autres significations peuvent être proposées (lien vers un métaglossaire en anglais).

Dans les contextes afférents à la santé publique, les connotations de l’expression « sûreté biologique » sont plus étroitement liées à la définition retenue par la "Convention sur l'interdiction des armes biologiques".

Pour plus de renseignements, on pourra se référer aux parties I et II du manuel de sécurité biologique de l'OMS ( 2005, ) .



</doc>
<doc id="2761" url="https://fr.wikipedia.org/wiki?curid=2761" title="Sharon Stone">
Sharon Stone

Sharon Stone, est une actrice et productrice de cinéma américaine née le à Meadville, (Pennsylvanie).

Après des débuts dans le mannequinat, elle commence sa carrière de comédienne dans les années 1980. Le succès arrive seulement douze ans plus tard quand elle interprète Catherine Tramell dans le thriller sulfureux de Paul Verhoeven, "Basic Instinct" (1992). Ce succès lance sa carrière cinématographique. Sa performance dans "Casino" (1995) de Martin Scorsese lui vaut le Golden Globe de la meilleur actrice dans un film dramatique et une nomination aux Oscars. Ses autres succès incluent "Total Recall", "Mort ou vif" ainsi que "Broken Flowers".
Malgré quelques déconvenues, elle reste une icône d'Hollywood et possède à ce titre son étoile sur le célèbre Walk of Fame de Hollywood Boulevard.

En parallèle à sa carrière cinématographique, Sharon Stone met sa célébrité au service de plusieurs causes humanitaires. Elle est ainsi l'ambassadrice de l'AmfAR, association de lutte contre le SIDA. En 2013, elle reçoit des mains du Dalaï-lama le Prix de la Paix pour son engagement, décerné par les lauréats du Prix Nobel de la Paix.

Sharon Yvonne Stone naît en Pennsylvanie, dans une famille d'origine irlandaise aux revenus modestes. Elle est la deuxième d'une fratrie de quatre enfants, dont un grand frère Mike Stone, une petite sœur Kelly Stone et un petit frère Patrick Stone. Sa mère, Dorothy Lawson, est mère au foyer et ex-comptable. Son père, Joseph Stone, est manufacturier.

Depuis son enfance, Sharon Stone a su prendre des risques, affichant ouvertement sa différence, ou ce qu'elle nommerait plutôt des évidences. Elle n'aime pas les jeux d'enfants, elle préfère s'isoler pour lire, sa distraction favorite depuis l'âge de 3 ans. Dans la cour de récréation, elle annonce, désinvolte, à ses camarades médusés qu'elle sera la nouvelle Marilyn Monroe. Et, si elle ne parvient pas à s'imposer comme telle, elle deviendra ténor du barreau.

On dit que Sharon Stone est encouragée très tôt à développer tout son potentiel par des parents aux valeurs féministes: . Son père, ouvrier, pousse sa fille à viser sans complexe les postes les plus hauts sans craindre de concurrencer les hommes. Elle se révèle être une élève extrêmement intelligente, sautant des classes. Elle obtient une bourse qui lui permet de s'inscrire à l'université d'Edinboro. Brillante étudiante universitaire, elle revient à sa passion et obtient finalement un diplôme en Lettres et Beaux-Arts et abandonne définitivement le droit.

Âgée de 17 ans à peine, elle s'inscrit à des cours d'art dramatique dans le cadre de ses études. Une fois celles-ci achevées, Sharon Stone remporte divers concours de beauté dont celui de Miss Pennsylvanie et part s'établir à New York. Elle a 19 ans lorsqu'un agent la remarque et l'engage comme mannequin pour l'agence Eileen Ford. Stone parcourt alors le monde: New York, Milan, Tokyo, Los Angeles, Paris, Rio de Janeiro, Moscou. Elle tourne des spots publicitaires, pose pour des magazines et travaille pour des marques prestigieuses (dont Diet Coke et Revlon). Très demandée, Stone s'installe en Europe où au gré des campagnes de publicité, son physique commence à être connu du public. Mais, elle finit par se lasser d'une carrière de mannequin vedette. À son retour à New York en 1980, elle décide de faire carrière au cinéma.

Les débuts d'actrice sont difficiles pour Sharon Stone. Elle doit continuer son métier de mannequin contre son gré. Au cours d'un défilé de mode, Woody Allen voit en elle la femme idéale qu'il croisera du regard derrière la vitre d'un train. Il la sollicite pour une apparition furtive, non créditée, dans "Stardust Memories". Claude Lelouch la contacte à son tour pour qu'elle figure deux minutes dans "Les Uns et les Autres". Ces premiers pas au cinéma lui permettent de tenir un rôle un peu plus conséquent dans une petite série B d'horreur, "La Ferme de la terreur" de Wes Craven, avant d'enchaîner dans des téléfilms divers, partenaire de Rock Hudson dans l'un d'eux, et des séries comme "Ricky ou la Belle Vie", "Les Enquêtes de Remington Steele", "Mike Hammer", "Magnum" et "Hooker", entre 1982 et 1988. Les années 1980 marquent une période dans laquelle l'artiste se cherche.

Elle enchaînera, sans grand succès, de petits rôles au cinéma pendant une dizaine d'années. L'apprentie étoile joue aux côtés d'une toute jeune Drew Barrymore dans "Divorce à Hollywood" en 1984 et l'aventurière maladroite et bavarde dans "Allan Quatermain et les Mines du roi Salomon" et "Allan Quatermain et la Cité de l'or perdu", films dans lesquels elle donne la réplique à Richard Chamberlain. Elle auditionne pour "Liaison fatale" mais Michael Douglas ne lui trouvant pas assez de piquant pour jouer les femmes fatales, elle laisse la place à Glenn Close. Son manque de notoriété serait aussi responsable du fait que "Liaison fatale" mais également "9 semaines 1/2" lui échappent. S'ensuivent des rôles plutôt oubliables comme celui d'une journaliste dans "" et une partenaire de charme pour Steven Seagal dans le film d'action "Nico". Elle s'essaie péniblement à la science-fiction pour "Beyond the stars" en 1989, se fait évincer par Kim Basinger pour le "Batman" de Tim Burton, obtient un rôle à la Catherine Tramell dans "L'Indomptée" et ne comprend pas elle-même ce qui l'a poussée à tourner dans "Les Arènes sanglantes", ("Sangre y arena", un film de Javier Elorrieta, d'après le roman éponyme de Vicente Blasco-Ibáñez), drame ibérique qui la contraint à boire dès dix heures du matin pour les besoins de son rôle. Après ces échecs successifs, elle se voit contrainte de revoir ses cachets à la baisse et, déprimée par les rôles interchangeables de blonde écervelée au service de séries B qu'on lui fait jouer, part se réfugier dans les bras paternels. Ce dernier lui conseille de s'accorder un temps de réflexion. 

Après un an d'une retraite familiale, Sharon envisage sa carrière différemment et part en quête de rôles plus conséquents. Lors d'une audition en 1990, Paul Verhoeven la choisit pour son premier véritable second rôle, "Total Recall". Elle incarne le personnage d'une tueuse face à Arnold Schwarzenegger. Le film est un succès, et on la voit en couverture de Playboy. Elle veut alors s’orienter vers des œuvres plus abouties ou plus complexes. Elle n'y parvient pas immédiatement mais elle tient un rôle remarqué dans "L'Année de plomb" de John Frankenheimer (1991). Suivent quelques revers comme "Hitman", polar dans lequel elle a pour partenaire James Belushi et Forest Whitaker.

Sharon Stone est considérée comme une actrice mineure lorsqu'elle rencontre Paul Verhoeven durant les auditions de "Total Recall" (1990). Satisfait de sa prestation, le réalisateur la montre à Arnold Schwarzenegger, instigateur du projet, qui approuve son choix. Verhoeven estime Stone. Il se souvient d'une scène en particulier, où le personnage qu'elle incarne est surpris par son mari en train de rouer de coups une autre femme. Son visage passe alors . C'est cette séquence qui conduit le cinéaste à l'imposer dans son projet suivant, "Basic Instinct" (1992), contre l'avis de Michael Douglas et du producteur Mario Kassar. Contrairement à plusieurs actrices célèbres, de Michelle Pfeiffer à Geena Davis, Sharon Stone n'a aucune réticence envers le caractère sulfureux du personnage de Catherine Tramell ou des nombreuses scènes dénudées. Sur le tournage, la relation entre Paul Verhoeven et l'actrice se révèle compliquée. Aux dires du réalisateur, Stone oublie régulièrement son texte, ou ne parvient pas à maintenir un jeu correct, lui imposant de multiplier les prises, là où Michael Douglas n'en avait généralement besoin que de quelques unes. Pourtant, il garde malgré tout une réelle estime pour sa performance et considère sa décision de l'engager comme . L'actrice estime quant à elle que le rôle de Catherine Tramell est .

"Basic Instinct" fait scandale à sa sortie, et déclenche notamment l'ire des ligues féministes et homosexuelles, pour son personnage ambivalent, ses scènes d'amour explicites, et surtout sa séquence où Sharon Stone décroise les jambes sans culotte, un selon "Libération". L'actrice déclare s'être fait piéger par le réalisateur, qui lui aurait promis que rien n'apparaîtrait à l'écran, mais celui-ci assure avoir reçu son accord, et même avec enthousiasme. Quoi qu'il en soit, le film permet à Sharon Stone d'accéder à la célébrité dès la première projection du film, présenté en ouverture du Festival de Cannes : . Le film est un grand succès commercial, avec plus de 352 millions de dollars de recettes pour un budget de 49 millions, et permet à Sharon Stone d'être pour la première fois nommée aux Golden Globes, dans la catégorie . Sa performance est jugée par le "The Washington Post" et l'actrice se voit comparée aux « blondes hitchcockiennes », notamment avec Kim Novak dans "Sueurs froides".

L'année suivante, elle apparaît dans le thriller érotique "Sliver" de Phillip Noyce. Le succès de "Basic Instinct" lui permet de négocier un salaire de 2,5 millions de dollars et un intéressement de 10% sur les recettes du film. Ce dernier rencontre un succès commercial lors de sa sortie, avec près de 117 millions de dollars de recettes, malgré un accueil critique majoritairement négatif et une nomination pour le Razzie Award de la pire actrice attribué à Sharon Stone. L'actrice reprend ensuite brièvement le rôle de Catherine Tramell le temps d'une apparition dans le film d'action "Last Action Hero" avec Arnold Schwarzenegger. En 1994, elle donne la réplique à Richard Gere dans "Intersection", remake du film français "Les Choses de la vie" de Claude Sautet, qui rencontre un échec aussi bien commercial que critique. Sharon Stone partage ensuite l'affiche de "L'Expert" avec Sylvester Stallone, film mêlant espionnage, thriller et action. Malgré les critiques négatives qu'il reçoit, le film est un succès commercial, avec un peu plus de 170 millions de dollars de recettes. L'année suivante, Sharon Stone se voit proposer le rôle principal du western "Mort ou vif". Sa notoriété lui permet d'imposer Sam Raimi à la réalisation ainsi que Russell Crowe et Leonardo DiCaprio pour être ses partenaires. Le film est présenté hors-compétition lors du Festival de Cannes et rencontre un succès commercial modéré, avec plus de 46 millions de dollars de recettes.

La même année, Sharon Stone joue l'un des rôles les plus marquants de sa carrière, celui de Ginger McKenna, une prostituée de luxe sombrant dans l’alcool et la déchéance, dans "Casino" de Martin Scorsese. Lorsqu'elle se présente à l'audition, le réalisateur, qui envisage également Kim Basinger, Nicole Kidman, Madonna ou Melanie Griffith, est immédiatement conquis par Sharon Stone chez qui il sent : . L'actrice s'immerge intensément dans son rôle au point de ressortir du tournage physiquement épuisée. Le film est un grand succès critique et commercial. La presse est unanime quant à la performance de Sharon Stone, considérée par beaucoup comme la meilleure de sa carrière. "Variety" parle de l'actrice comme d'une tandis que "The New York Times" la juge . "Casino" lui permet de remporter le Golden Globe de la meilleure actrice dans un film dramatique et d'être proposée pour l'Oscar de la meilleure actrice. Toujours en 1995, Sharon Stone reçoit son étoile sur le légendaire de .

L'actrice joue ensuite dans le thriller psychologique "Diabolique", remake du film "Les Diaboliques" d'Henri-Georges Clouzot. Sorti en 1996, le film ne rencontre pas les faveurs de la presse et des spectateurs. La même année, elle apparaît dans le drame "Dernière Danse" dans lequel elle joue une femme condamnée à mort pour avoir commis un meurtre de sang froid. Deux ans plus tard, Sharon Stone donne la réplique à Dustin Hoffman et Samuel L. Jackson dans le film de science-fiction "Sphère". Le succès n'est une nouvelle fois pas au rendez-vous. Elle est la voix de Princesse Bala dans le film d'animation "Fourmiz" (1998) avant d'être à l'affiche du drame intimiste "Les Puissants", pour lequel elle est nommée aux Golden Globes, dans la catégorie . L'année suivante, Sharon Stone reprend le rôle de Gena Rowlands dans une nouvelle version du drame de John Cassavetes "Gloria". Réalisé par Sidney Lumet, le film reçoit un accueil critique négatif et est un échec au box-office. Sa performance dans la comédie d'Albert Brooks "La Muse" lui apporte cependant une quatrième proposition pour un Golden Globe, cette fois dans la catégorie .
En 2001, l'actrice est victime d'un accident vasculaire cérébral qui la tient éloigné des plateaux. L'année suivante, elle est membre du jury des longs métrages du Festival de Cannes, présidé par le réalisateur américain David Lynch. Après trois ans d'absence cinématographique, Sharon Stone apparaît, le temps de trois épisodes, dans la série "" (2003). Le rôle qu'elle incarne, celui d'une avocate excentrique, lui permet d'obtenir le Primetime Emmy Award de la meilleure actrice invitée dans une série télévisée dramatique. Sur les conseils de son agent, l'actrice accepte ensuite deux films à vocation populaire, le premier étant le thriller "La Gorge du diable" (2003) dans lequel elle joue l'épouse de Dennis Quaid et la mère de Kristen Stewart. Le deuxième est "Catwoman" (2004) avec Halle Berry, considéré comme l'un des pires films jamais réalisés. Sa performance dans "Broken Flowers" de Jim Jarmusch en 2005 est saluée par la critique. Le "New York Magazine" écrit : . L'actrice reprend son rôle de Catherine Tramell dans "Basic Instinct 2" en 2006. Le film reçoit un accueil désastreux de la part de la critique. Le site Rotten Tomatoes résume ainsi l'avis de la presse : . Alors que le film devait marquer son grand retour au cinéma, Sharon Stone apparaît ensuite dans plusieurs films indépendants dont les sorties aux États-Unis sont limitées, principalement destinées au direct-to-video, et quasi-inexistantes en France.

En 2010, Sharon Stone joue le rôle d'un substitut du procureur dans la série "New York, unité spéciale", le temps des quatre derniers épisodes de la onzième saison. L'expérience se révèle pour l'actrice, amère sur le déclin de sa carrière : . Elle tient ensuite le rôle principal féminin de "Largo Winch 2" aux côtés de Tomer Sisley. Le tournage se révèle plus heureux que le précédent, notamment grâce à sa collaboration avec le réalisateur Jérôme Salle : . Dans le biopic "Lovelace" (2013), sur l'actrice pornographique Linda Lovelace, Sharon Stone incarne la mère de cette dernière. La même année, elle donne la réplique à Woody Allen et John Turturro dans "Apprenti Gigolo" où elle incarne une dermatologiste cherchant à vivre un ménage à trois. En 2014, Sharon Stone est pour la première fois de sa carrière l'héroïne d'une série télévisée. Dans "Agent X", l'actrice joue le rôle de la vice-présidente des États-Unis chargée d'assurer la protection de la Constitution lors d'une période de crise sans précédent. La série est cependant annulée dès la première saison en raison de son insuccès auprès des téléspectateurs.

Alors que ses apparitions au cinéma se raréfient, l'actrice déclare dans un entretien avec "Madame Figaro" : . En 2017, elle est l'une des nombreuses artistes à faire une apparition dans "The Disaster Artist" de James Franco. L'année suivante, Sharon Stone tourne sous la direction de Steven Soderbergh dans la mini-série "Mosaic". Elle y joue le rôle d'une auteure à succès de livres pour enfants, tuée lors du Réveillon de la Saint-Sylvestre. Avant sa diffusion sur la chaîne HBO, "Mosaic" est proposée au format interactif via une application mobile, où chaque utilisateur peut interagir avec les personnages et influencer l'histoire. La mini-série reçoit des critiques élogieuses et permet à Sharon Stone de voir sa prestation acclamée à l'unanimité. Elle est jugée par "The Daily Beast" et par "Collider", qui ajoute que . Pour "Libération", l'actrice et "Rolling Stone" estime qu'il s'agit de son .







C'est en 1992, après le succès de "Basic Instinct" que Sharon Stone commence à recevoir des récompenses pour ses différents rôles.

À côté de succès indéniables comme Casino et Basic Instinct pour ne citer que ceux-là, Sharon Stone a été nommée neuf fois et trois fois lauréate des Golden Raspberry Awards dont deux fois en 1995 pour sa prestation dans L'Expert et Intersection. Elle réitère en 2004 avec Catwoman.

Stone ouvre le concert du prix Nobel de la paix en 2006.

Elle a été membre de la scientologie avant de se convertir au bouddhisme tibétain en 2008.

Elle se convertit au bouddhisme tibétain après que son ami, l'acteur Richard Gere, l'eut présentée au Dalaï-lama. 
Elle est ordonnée prêtre à en 2004.

Son premier mariage avec George Englund Jr. dura peu de temps. Elle épouse, en secondes noces, Michael Greenburg, producteur de la série "Stargate SG-1", qu'elle a rencontré sur le plateau du film "The vega strip War" dont il assure la mise en scène et dont elle est la vedette aux côtés de Rock Hudson et James Earl Jones. Après lui avoir brisé son ménage, ils se marient le mais se séparent au bout de trois ans, le . Leur divorce est prononcé officiellement en 1990.

Stone se fiance au producteur Bill McDonald dont elle fait la connaissance sur les plateau de tournage du film "Sliver" en 1993. McDonald quitte sa femme, Naomi Baca pour Stone. La presse qualifie Stone de briseuse de ménages jusqu'à ce que leur attention se porte sur Baca après que cette dernière fut devenue la maîtresse de Joe Eszterhas, le scénariste de "Basic Instinct", qui a quitté sa femme pour elle. Peu après sa romance avec Eszterhas, Baca commence une liaison avec Joel Swigart, le garde du corps de Stone depuis 1998. Stone et Swighart - marié et père de deux enfants - entretiennent une relation discrète depuis 1995 lorsque la presse découvre l'affaire alors que l'actrice tourne "Mort ou Vif" ("The Quick and the dead") et relève Swighart de ses fonctions de garde du corps sous le prétexte qu'il délaisse sa famille. Stone nie toujours, à l'heure actuelle, avoir eu une quelconque relation avec Swignart. En fait, celui-ci n'est plus réapparu à Hollywood depuis 1995.

Après plus de quinze ans de vie célibataire, Sharon Stone épouse le journaliste Phil Bronstein le , jour de la Saint-Valentin. Leur contrat de mariage stipulait qu'en cas de divorce son mari ne pourrait rien toucher de la fortune de l'actrice. Après cinq ans d'union, ils décident finalement de divorcer en pour incompatibilité de caractère. En fait, le couple vivait séparé depuis que Bronstein a été victime d'un grave infarctus du myocarde. L'actrice réside à Los Angeles et le journaliste dans leur maison de San Francisco. Comme l'a souligné Nordin Blacker, l'avocat de Phil Bronstein, tous deux se dirigeraient vers 

En 2005, au cours d'un entretien télévisé à l'occasion du film "Basic Instinct 2", l'actrice avoue éprouver un intérêt pour la bisexualité: . Elle avoue avoir été, par le passé, une fille « démodée ». Pendant le tournage de certaines scènes de "Basic Instinct", sa meilleure amie était à ses côtés, hors du champ de la caméra, pour lui tenir la main. Dans "Naked Instinct", la biographie que Frank Sanelloo a écrite au sujet de l'actrice, il est fait part d'une relation sexuelle entre Stone et une autre femme dans la salle de bains du "Beverly Hills Hotel". Au cours d'un autre entretien accordé le à Londres à Michael Parkinson, l'actrice affirme être exclusivement hétérosexuelle. Cependant, en , elle déclare : .

En 2007, lors d'un entrevue avec Garry Shandling enregistrée spécialement pour le DVD de ce dernier, "Not Just The Best Of The Larry Sanders Show", Stone admet avoir entretenu une relation avec Shandling au début de 1980 et qu'elle pense avoir contribué, d'une certaine manière, à avoir amélioré ses monologues lorsque Sandling était invité au "The Tonight Show" du présentateur Johnny Carson.

À 42 ans, et après plusieurs fausses couches, Sharon Stone et son ex-époux Phil Bronstein adoptent un petit garçon né le au Texas où le couple s'est précipité, avec leur jet privé, afin de le ramener chez eux au plus vite. Ils le nomment Roan Joseph Bronstein.

Par la suite, l'actrice a recours à une mère porteuse pour avoir un deuxième garçon, Laird Vonne Stone, né le .
Le , Stone adopte un troisième enfant : Quinn Kelly. Un mois plus tard, Sharon Stone pense adopter un quatrième enfant. Une source confie au magazine "New Weekly" : . Elle renonce finalement à cette idée en estimant qu'il est difficile de s'occuper d'enfants en étant seule. Stone considère que les femmes dans ce cas ont vraiment du mérite mais assure que cela vaut la peine d'être vécu. Elle déclare au magazine "People" : Kelly, la sœur de Sharon Stone, admire l'amour maternel de son aînée : .

Pendant plusieurs années, il a été dit que Sharon Stone était membre de l'association Mensa, ce qu'elle dément formellement en . Jim Blackmore, membre de la société regroupant des individus possédant un Q.I. élevé, admet : . Et de rajouter .

Sharon Stone est atteinte de diabète insulino-dépendant. En 2016, elle affirme avoir vécu une expérience de mort imminente quinze ans plus tôt lors d'un accident cérébral.

Le , au moment du Festival de Cannes, Sharon Stone préside le gala de l'Amfar (association de lutte contre le Sida) et, de religion bouddhiste tibétaine, elle y déclare au "", chaîne d'information de "Hong Kong Cable Television Limited", au sujet du tremblement de terre qui a eu lieu dans la province du Sichuan : . Les journalistes ont alors fait remarquer que le district administratif de Wenchuan, épicentre du séisme, est situé dans la préfecture autonome tibétaine et qiang d'Aba où les Tibétains représentent plus de la moitié de la population.

La déclaration n'a évidemment pas plu en Chine, où le tremblement de terre du 12 mai 2008 a causé la mort de plus de selon un dernier bilan. D'après "The Hollywood Reporter", une des plus importantes chaînes de salles de cinéma chinoises déclare qu'elle ne projettera plus les films dans lesquelles l'actrice paraît. Le fondateur de la chaîne de cinémas UME Cineplex ainsi que le Président de la fédération des producteurs de films à Hong Kong, Ng See-Yuen, qualifient le commentaire de Stone d'« inapproprié » et que la Chaîne UME Cineplex écartera, à l'avenir, de leur programmation les films dans lesquels joue l'actrice.

Stone est bannie de la liste des invités au Festival International du Film de Shangai de 2008 et les organisateurs envisagent son bannissement.

Les publicités pour la marque Christian Dior (dont Sharon Stone est l'une des égéries publicitaires) représentant des photos de l'actrice sont également interdites en Chine. La filiale chinoise de la marque Dior craint un boycott et s'excuse au nom de l'actrice. Au cours d'un entretien avec un journaliste du "New York Times", cette dernière niera s'être excusée : Elle admet cependant Le Dalaï Lama lui-même, dit-on, aurait pris ses distances vis-à-vis de l'actrice.

Le , Stone réunit en cinq minutes des promesses de dons à hauteur d'un million de dollars (environ ) pour acheter des moustiquaires au profit de la Tanzanie en tournant un spot publicitaire à la télévision sur la pauvreté des Africains lors d'un forum économique mondial qui s'est tenu à Davos en Suisse. Beaucoup d'observateurs, dont l'Unicef, ont critiqué son action en disant qu'elle avait agi instinctivement aux propos du Président de la Tanzanie, Benjamin Mkapa sans faire son enquête sur les causes, les conséquences et les méthodes de prévention du paludisme. .

Au mois d', elle est honorée du "Spirit Award", prix décerné par le "Centre National pour les Droits des Saphistes" basé à San Francisco, Californie, pour son soutien et son implication dans la cause des Saphistes, des homosexuels et, plus généralement, dans celle des personnes atteintes du sida. Le prix lui est remis par Gavin Newsom, Maire de la ville de San Francisco
Alors qu'elle séjourne à Cannes à l'occasion du Festival de Cannes en 2008, elle préside le gala de l'Amfar (association de lutte contre le Sida). Elle y interprète "Can't Get You Out of My Head" avec Kylie Minogue au profit de la recherche sur le sida.

Sharon Stone s'est associée au joaillier Damiani pour concevoir une collection de bijoux dont un pourcentage provenant de leur vente sera reversé à une association humanitaire qui a pour but d'alimenter en eau potable des villages africains. La collection de bijoux devrait être lancée à l'automne 2009.

Le , Sharon Stone s'est rendue au poste de police le plus proche de chez elle afin d'y déposer des armes, un fusil et trois pistolets, qu'elle conservait pour assurer sa propre protection. Interrogée sur la nature de son geste, l'actrice a déclaré : « Notre monde a changé et nos enfants sont en danger. J'ai choisi de renoncer à mon droit de porter des armes, en échange de la paix de l'esprit que procure le fait de faire ce qui est juste. » Sharon Stone a également invité les Américains à suivre son exemple, à renoncer à leur peur et à faire confiance aux agents de police. Son geste intervient approximativement un mois après la fusillade de Columbine qui rouvrit le débat sur le port d'armes aux États-Unis.


En France, Micky Sébastian est la voix française de Sharon Stone. Françoise Cadol, Céline Monsarrat ou encore Béatrice Agenin l'ont également doublé occasionnellement.

Au Québec, l'actrice est doublée par Anne Dorval.











</doc>
<doc id="2763" url="https://fr.wikipedia.org/wiki?curid=2763" title="Seine">
Seine

La Seine ( ) est un fleuve français, long de , qui coule dans le Bassin parisien et arrose notamment Troyes, Paris, Rouen et Le Havre. Sa source se situe à d'altitude à Source-Seine, en Côte-d'Or, sur le plateau de Langres. Son cours a une orientation générale du sud-est au nord-ouest. Elle se jette dans la Manche entre Le Havre et Honfleur. Son bassin versant, d'une superficie de , intéresse près de 30 % de la population du pays.

La forme la plus ancienne se trouve chez César : "Sequana", ; le grec Strabon au écrit : "(S)epkoanas" ; Ptolémée "Sekoana" au ; "Sequana", 558 ; "Segona", "Sigona" au ; "Secana" ou "Sequana" au .

La plupart des spécialistes considèrent l’origine du nom "Sequana" comme obscure. Certains y voient une erreur de transcription d'un ou de plusieurs mots celtiques différents. D'autres un hydronyme préceltique, au motif que le groupe [kʷ] n'existe pas en celtique gaulois (et brittonique), où il a évolué en [p] (exemple : "pinp[etos]" « cinq[uième] » en gaulois, "pimp" en gallois, "pemp" en breton, par contre irlandais "cinc", latin "quinque" > "cinq", etc. Ils procèdent tous de l'indo-européen "*pénkʷe"). Cependant, cette évolution a pu se produire postérieurement à l'attribution du nom "Sequana" par les premiers arrivants celtes : ceux-ci semblent en effet avoir parlé un « proto-celtique » où la mutation /kʷ/ > /p/ n'était pas encore réalisée, comme l'attestent certaines inscriptions celtibères retrouvées en Espagne.

Mais rien n'empêche une réinterprétation du nom en "*se-ku-ana". L'élément "-ana" est fréquent par ailleurs en hydronymie et en toponymie. Il apparaît sous la forme à l'accusatif "anam" dans le glossaire d'Endlicher ; il y est traduit par le latin "paludem" (accusatif de "palus, -udis" « étang, marais »). Le nom de l'Yonne contiendrait plutôt l'élément "-onno" (cf. "onno" donné pour "flumen" « cours d’eau, rivière, fleuve », lui aussi répandu, dans ce même glossaire). On peut douter de la celticité de ces deux termes, notamment du mot "onno", utilisés pourtant en gaulois, semble-t-il.

Pour expliquer "Sequana", Ernest Nègre a proposé un hypothétique thème préceltique *"seikw" « verser, couler, ruisseler » suivi du suffixe gaulois "-ana". Une racine indo-européenne "*seikʷ-" de même signification a été conjecturée.

Jacques Lacroix le fait dériver d'un radical "(S)Ico-" « eau ». Albert Dauzat propose une racine hydronomique pré-celtique "*sēc"-, dont des variantes figureraient dans d'autres hydronymes "*seg-, *sac-/*sag-, *sic-/*sig-".

La Seine est partagée en cinq parties, d'amont en aval :

Le lac artificiel de la forêt d'Orient, en amont de Troyes, ainsi que le lac du Der-Chantecoq en amont de Saint-Dizier ont été créés dans les années 1960 et 1970 pour réguler le débit du fleuve.

En Île-de-France et en Normandie, la faible déclivité de la vallée de la Seine a causé la formation de multiples et profonds méandres, parfois d'une très forte sinuosité sur plusieurs dizaines de kilomètres. Pour la même raison, les effets de la marée se font sentir sur une centaine de kilomètres, jusqu’au barrage de Poses et se manifestaient jusqu’à un passé récent, par le phénomène du mascaret, appelé "barre" en Normandie. Le phénomène et le mot ont été popularisés par le roman de Maurice Leblanc appartenant à la série des "Arsène Lupin" : "La Barre-y-va".

Les « sources officielles » de la Seine sont situées sur le territoire de la commune de Source-Seine, sur le plateau de Langres, à une altitude de . Les sources de la Seine sont la propriété de la ville de Paris depuis 1864. Une grotte artificielle a été construite l'année suivante pour abriter la source principale et la statue d'une nymphe symbolisant le fleuve. Cependant, la capitale s'en est désintéressée et la parcelle devrait revenir à la région Bourgogne qui souhaite valoriser le site. Celui-ci abrite également les vestiges d'un temple gallo-romain (actuellement enfouis). Des objets témoignant du culte aux sources du fleuve "(Dea Sequana)" sont exposés au musée archéologique de Dijon.

Le bassin versant de la Seine, d'une superficie de , est quasi entièrement compris dans le Bassin parisien qui, d'un point de vue géologique, constitue un bassin sédimentaire affectant la forme d'une cuvette ouverte vers la Manche et l'Atlantique. Ce bassin est constitué par un empilement de formations géologiques à faible pente convergeant vers le centre et entre lesquelles s'intercalent d'importantes formations aquifères. Le relief du bassin versant de la Seine ne s'élève généralement pas au-dessus de , sauf sur sa marge sud-est dans le Morvan où il culmine à . La modestie de l'altitude moyenne du bassin versant explique les faibles pentes des cours d'eau (entre 0,01 et pour ) qui coulent vers l'ouest en se frayant leur chemin à travers les cuestas faisant saillie à l'est du bassin puis en incisant les plateaux du centre de la région.

Les tripoints hydrographiques aux extrémités des lignes de partage des eaux séparant le bassin versant de la Seine avec :


Le Bassin parisien connait un climat océanique avec un apport constant d'humidité véhiculé par les vents dominants d'Ouest. La pluviométrie est comprise entre et dans les régions côtières s'abaisse jusqu'à dans les régions centrales faute de relief (altitude inférieure à en Île-de-France) avec un minimum dans la Beauce pour remonter sur les marges orientales avec un maximum à dans le Morvan. La Seine et trois de ses principaux affluents qui circulent dans des régions aux caractéristiques similaires (régime océanique, faible relief et géologie identique) partagent le même régime hydrographique avec un débit maximal en janvier et un minimum en août. Le Bassin parisien comprend 9 aquifères qui s'intercalent entre les différentes couches géologiques. Le réseau hydrographique est relié en différents points directement à l'aquifère la moins profonde : en fonction de la hauteur des eaux elle alimente la Seine ou est alimentée par celle-ci. Enfin la couche d'alluvions, présente dans les vallées avec une épaisseur inférieure à , constitue une dixième formation aquifère très productive.

Voici une liste des principaux affluents (longueur supérieure à , ou bassin versant supérieur à ou débit moyen (module) supérieur à /s connu au plus proche de la confluence) directs de la Seine et situés avec leur confluence par la distance (km) avec la limite Ouest de l'estuaire de la Seine selon son écoulement à l'aval, par l'altitude (m) (du plan d'eau en débit moyen, estimé au mieux d'après carte topographique), par la rive, par le nom du département (amont si limite interdépartementale), par la commune de la pointe de confluence, par les coordonnées puis avec les 3 données comparables pour la Seine (juste à l'amont de la confluence) :

"Diagramme comparatif des bassins versants des principaux affluents, supérieurs à :"

Si, comme c'est l'usage, le cours d'eau entrant à une confluence avec le plus fort débit annuel (module) avait donné son nom au cours d'eau issu de cette confluence, le cours principal du bassin parisien ne serait pas la Seine mais l'Yonne. En effet, à leur confluent à Montereau-Fault-Yonne, l'Yonne présente un débit et un bassin versant supérieurs à ceux de la Seine (respectivement /s et près de pour l'Yonne, tandis que la Seine présente un débit de /s et ). La même situation se reproduit d'ailleurs en amont avec l'Aube dont le bassin versant est de , avec un débit de /s, contre et /s pour la Seine. D'un point de vue strictement hydrographique, la Seine est donc un sous-affluent de l'Yonne par l'Aube et c'est pour des raisons culturelles et historiques que l'on parle du bassin de la Seine. Cette situation se rencontre aussi entre la Saône et le Doubs.

Il est possible que la Loire ait été, jusqu’au Miocène ou au Pliocène, un affluent de la Seine qu’elle rejoignait par le cours de l’actuel Loing. La Seine traversait alors une vaste pénéplaine de nature argileuse sous un climat subtropical. Il y a trois millions d'années, la région subit un refroidissement et un soulèvement dû à la poussée des chaînes pyrénéenne et alpine au sud. Les glaciations de l'ère quaternaire firent baisser le niveau des mers et océans, si bien que la Seine se jetait alors au large de la Bretagne actuelle (la Manche était la vallée du Rhin augmentée de la Meuse, de la Tamise et de la Somme, entre autres). Cette période fut marquée par la migration des méandres du fleuve, encore visible en Normandie, et par une intense érosion rabotant les plateaux et formant des terrasses alluviales. L'aspect actuel de la Seine remonte à la fin de la dernière glaciation, vers .

Les régions et départements traversés sont les suivants, en allant de la source vers l'embouchure :

De Source-Seine (ex-Saint-Germain-Source-Seine) à Honfleur, il y a 164 communes riveraines de la Seine, parmi lesquelles Paris, capitale de la France. L'une d'elles, L'Île-Saint-Denis est entièrement située dans l'île du même nom.

Bien que la pluviométrie soit bien distribuée sur l'année, la Seine et ses affluents peuvent connaitre des périodes d'étiage sévère à la fin de l'été ou au contraire des crues importantes en hiver. Les crues sont de deux types : les crues rapides dans les parties amont du bassin à la suite de précipitations fortes et les crues lentes dans les vallées plus en aval qui font suite à des épisodes pluvieux prolongés. Pour maîtriser les crues et les étiages d'importants travaux de régulation ont été réalisés dans la partie supérieure du cours de la Seine et de ses affluents. Son débit moyen à Paris est d'environ /s et peut dépasser /s en période de crue. Quatre grands lacs-réservoirs ont été créés entre 1960 et 1990 sur la Seine (lac d'Orient), la Marne (lac du Der-Chantecoq), l'Aube (lac d'Amance et lac d'Auzon-Temple) et l'Yonne (lac de Pannecière agrandi qui alimentait déjà le canal du Nivernais dès le ). Ces lacs qui constituent une réserve de 800 millions de mètres cubes permettent à la fois d'écrêter les crues et d'assurer un débit minimum d'étiage. Ils sont gérés par un établissement public, l'Institution interdépartementale des barrages-réservoirs du bassin de la Seine.

À Paris, les crues sont mesurées depuis 1876 par une l'échelle hydrométrique installée au pont d'Austerlitz, néanmoins c'est la statue du zouave du pont de l'Alma qui reste l'indicateur le plus populaire (bien que cette mesure soit peu fiable à la suite des travaux du pont de l'Alma dans les années 1970 qui ont élevé la statue, rendant ainsi impossibles les comparaisons pré et post travaux). Au cours de la crue de janvier 1910, l'eau a atteint sur cette échelle la hauteur record de .

Depuis 1870, la hauteur est prise à la station Paris Austerlitz. S'il n'y a pas eu de grandes crues depuis une soixantaine d'années, cinq grandes crues se sont produites au : en 1910, 1920, 1924, 1945 et 1955. Les plus anciennes crues de la Seine connues ont été relatées par Julien (crue de 358) et Grégoire de Tours (crue de février 582).

Si les crues centennales sont redoutées, le réchauffement climatique conduit inversement à envisager plusieurs hypothèses de baisse du débit du fleuve sur la base des travaux du GIEC. Ainsi dans l'hypothèse d'une hausse des températures de d'ici 2100, le débit serait réduit de 5 % en hiver et de 10 % en été. En cas de hausse des températures de , le débit global chuterait de 30 % avec des valeurs entre 20 % et 40 % en période estivale. Ces scénarios impliquent une diminution de l'approvisionnement des nappes phréatiques et aurait aussi pour conséquence une plus forte pollution des eaux car .

Du 28 mai au 4 juin 2016, la Seine connaît une crue importante. Le niveau d'eau culmine à 6,10 mètres dans la nuit du 3 au 4 juin. C'est la plus grosse crue survenue a Paris depuis plus de 30 ans. Elle ne dépasse cependant pas les 6,18 mètres de la crue de 1982.

À la fin du mois de janvier 2018, la Seine connaît une nouvelle forte crue, dont le niveau culminant est atteint dans la nuit du 28 au 29 janvier, à 5,84 mètres.

La débâcle qui suit le gel de la Seine peut s'accompagner de crues liées à la pluie ou à la fonte de neige. En 1868, la débâcle peinte par Claude Monet ne fit monter le niveau des eaux que de 0.5 mètre à l'échelle du Pont-Royal. Après plus de 30 jours de gel, la grande débâcle qui commença le 2 janvier 1880 fut un événement unique de l'histoire du climat parisien. Elle se généralisa le 3 janvier où en 3 heures, le niveau des eaux monta de 1,50 mètres et continua de progresser. La seconde arche du pont des Invalides, côté rive droite, s'effondra. 

La Seine maritime ainsi qu'une partie de la basse Seine sont soumises au régime des marées, qui remontent jusqu'au barrage de Poses dans l'Eure ( de marnage). On pouvait encore observer jusque dans les années 1960 une imposante vague qui pouvait atteindre au moment des grandes marées et qu'on appelle mascaret, plus localement "barre". Le phénomène atteignait son maximum à Caudebec-en-Caux, à mi-distance environ entre Le Havre et Rouen. Il a pratiquement disparu à la suite des aménagements apportés au fleuve (dragage, endiguement et modification de l'estuaire).


Pour les mariniers et les services de navigation fluviale, la Seine se décompose en :
Depuis Troyes jusqu'à son confluent avec l'Aube à Marcilly-sur-Seine, elle est longée par le canal de la Haute-Seine qui n'est plus en service. De Marcilly-sur-Seine à Montereau-Fault-Yonne, la navigation est établie tantôt sur des dérivations latérales (trois au total), tantôt dans le lit du fleuve même. De Montereau-Fault-Yonne à Tancarville, la navigation se fait toujours dans le lit de la Seine. De Tancarville au Havre, les bateaux fluviaux peuvent emprunter le canal de Tancarville.

La Seine est navigable sur une grande partie de son parcours. La responsabilité de la navigation appartient à Voies navigables de France jusqu'au pont Boieldieu à Rouen, et en particulier au Service de navigation sur la Seine en amont d'Amfreville-sous-les-Monts. Le bassin de ce Service de Navigation de la Seine s'étend aussi à ses principaux affluents (Oise, Marne, Yonne) et parfois à des canaux qui y sont reliés (canal de la Haute-Seine jusqu'à Méry-sur-Seine, par exemple). En revanche, il ne comprend pas les canaux parisiens (canal de l'Ourcq, canal Saint-Denis et canal Saint-Martin) qui sont gérés par la ville de Paris.

La basse Seine, au sens maritime du terme, c'est-à-dire à partir de la mer jusqu'au pont Guillaume-le-Conquérant à Rouen est accessible aux navires de haute mer (jusqu’à de long et ). Sur cette partie du fleuve, longue d'environ , les trois seuls ponts existants (pont de Normandie, pont de Tancarville et pont de Brotonne) offrent un tirant d'air de et le fleuve est constamment dragué pour permettre aux bateaux ayant un tirant d'eau de de circuler. Compte tenu du nombre limité de ponts, plusieurs bacs permettent également de traverser le fleuve. Les installations portuaires y relèvent de l'autorité du grand port maritime de Rouen. Celui-ci, cinquième port maritime français avec environ 25 millions de tonnes de marchandises embarquées et débarquées, est spécialisé dans le trafic de céréales, engrais et produits pétroliers. Ses installations s'échelonnent le long du fleuve sur de l'agglomération de Rouen jusqu'à Honfleur.
Entre Rouen et Paris, la Seine a été canalisée au . Sept barrages éclusés situés à Poses-Amfreville-sous-les-Monts, Notre-Dame-de-la-Garenne (Eure), Méricourt, Andrésy, Bougival, Chatou (Yvelines) et Suresnes (Hauts-de-Seine) permettent la navigation de péniches automotrices ( de fret) dites « bateaux automoteurs de gabarit Freycinet », de , de chalands automoteurs de rivière (de 800 à de fret), de 48 à , de convois de barges poussées (de à de fret) et de caboteurs fluvio-maritimes ( de fret). ces barges transportent, entre autres choses, des conteneurs, des automobiles, des produits pétroliers, du ciment, etc.

Les installations portuaires situées en Île-de-France relèvent du port autonome de Paris, premier port fluvial français. Les principales installations portuaires pour le trafic de marchandises se situent à Limay (Yvelines) et Gennevilliers (Hauts-de-Seine). En projet, une plate-forme multi-modale (voie d'eau, autoroute, voie ferrée) est en cours d'étude sur la commune d'Achères en aval de Conflans-Sainte-Honorine.

À Paris existe aussi un trafic de voyageurs, principalement touristique (bateaux-mouches), mais aussi une tentative d'utiliser la Seine pour les déplacements quotidiens (Batobus). Des navettes circulent régulièrement entre la Tour Eiffel et le Jardin des plantes ; toutefois, ce service semble intéresser davantage les touristes que les Parisiens, créant ainsi une concurrence gênante pour les bateaux-mouches. Un autre service voyageur (Voguéo) est également expérimenté entre la gare d'Austerlitz et Maisons-Alfort (sur la Marne).

En aval de Rouen, seuls trois grands ponts enjambent la Seine (ponts de Brotonne, de Tancarville et de Normandie).

La Seine est une voie navigable très importante, reliant Paris à la Manche. De ce fait, deux des plus importants ports fluviaux de France s'y trouvent : Paris (port de Gennevilliers) et Rouen, qui est également un important port maritime permettant le transbordement (c'est le premier port céréalier d'Europe). Elle est navigable en amont de Paris jusqu’à Nogent-sur-Seine, important port céréalier. Autres ports fluviaux notables : Limay-Porcheville (agglomération de Mantes-la-Jolie), Montereau-Fault-Yonne (sites gérés par le port autonome de Paris). De nombreuses industries sont situées le long de la vallée de la Seine, automobile (Poissy, Flins, Cléon, Sandouville), pétrochimie (Port-Jérôme, Gonfreville-l'Orcher, Notre-Dame-de-Gravenchon, Grand-Couronne), centrales thermiques (Porcheville, Saint-Ouen).

L'eau de la Seine est utilisée pour le refroidissement de la centrale nucléaire de Nogent.

On dénombrait en 2009 52 espèces de poisson d'eau douce dans l'ensemble du bassin de la Seine. Cette faune n'est que pour moitié d'origine naturelle. Les grandes glaciations qui ont touché plus particulièrement le Nord-Ouest de l'Europe durant le Quaternaire ont appauvri la diversité de la faune piscicole naturelle de la Seine (estimée à une trentaine d'espèces) par rapport à celle des fleuves situés plus à l'est comme le Rhin (44 espèces autochtones) ou le Danube (une centaine d'espèces). Dès le Moyen Âge l'homme introduit la carpe commune. Au la grémille, le carassin doré et le carassin commun apparaissent à leur tour soit du fait d'introductions volontaires soit par colonisation depuis d'autres bassins. Mais c'est à compter de la deuxième moitié du que les introductions se multiplient. Elles résultent soit de tentatives d'acclimatation d'espèces exotiques soit de la volonté d'améliorer la productivité d'installations piscicoles. C'est à cette époque qu'apparaissent les espèces d'origine nord-américaine comme la truite arc-en-ciel, le poisson-chat et la perche soleil. Dans la deuxième moitié du débute une deuxième phase d'introduction encore plus massive avec des motivations différentes. L'extension du réseau de canaux favorise également l'arrivée d'espèces étrangères. À la fin du on comptait en tout 23 espèces non autochtones. Mais les aménagements de la Seine et de ses affluents qui débutent à compter de 1850 pour favoriser la navigation créent des obstacles et suppriment les milieux naturels nécessaires aux espèces autochtones migratrices. L'esturgeon, le saumon et la grande alose disparaissent au début du . La pollution croissante du fleuve qui culmine à la fin des années 1960 contribue à chasser les autres espèces de cette catégorie. Au début des années 1990, 7 des 10 espèces migratrices ont disparu et seule une espèce, l'anguille, est encore aujourd'hui largement répandue.

L'aménagement de la Seine en voie navigable, avec de nombreux barrages, a créé autant d'obstacles s'opposant au passage des poissons migrateurs. Un programme en cours, sous l'égide de VNF, vise à équiper tous les barrages de la Seine aval, entre Poses-Amfreville et Suresnes, de passes à poissons, ce qui permettra aux migrateurs de remonter jusqu'au confluent de la Marne. Des saumons et des truites de mer ont été observés devant le barrages de Poses, à de l'embouchure, en 2007. En 2008, ont été comptés dans la passe à poissons de ce barrage. Le 26 juillet 2008, pour la première fois depuis très longtemps, une truite de mer a été pêchée dans la Seine, au niveau du barrage de Suresnes, juste en aval de Paris. S'agissant d'espèces de poissons migrateurs très sensibles aux conditions du milieu, ces événements indiquent une amélioration de la qualité des eaux de la Seine en aval de Paris. Le 3 octobre 2008, à hauteur du barrage de Suresnes en région parisienne, un saumon de a été pêché, pour la première fois à un point aussi éloigné en amont sur la Seine depuis . Des chercheurs de l'INRA (en collaboration avec l'ONEMA et le CEMAGREF) ont été sollicités pour confirmer la présence de l'espèce sur la Seine.
Les résultats de l'étude, dévoilés en août 2009, montrent que les saumons pêchés dans la Seine ont des origines diverses. Aucun poisson issu d'élevage n'a officiellement été déversé dans la Seine depuis 1895, contrairement à ce qui a été fait dans d'autres bassins où des espèces avaient disparu.

Certains marais naturels des bords de Seine ont été revalorisés et remis en état dans le but de favoriser la faune et la flore, comme à Hénouville, Mesnil-sous-Jumièges ou au Trait.

La qualité microbiologique de l'eau de la Seine fait l'objet d'un suivi. Un bilan a été publié en 2016 dans la perspective de la baignade dans la Seine (il est interdit depuis un arrêt préfectoral de 1923 de se baigner dans le fleuve) et la Marne et d'épreuves olympiques aquatiques en 2024.

Le bassin de la Seine concentre 40 % de la production industrielle française et l'agriculture intensive occupe 60 % de la surface du bassin, avec pour résultat un fleuve dont le débit est parfois à moitié constitué d'eaux usées. Au début des années 1960, les scientifiques considèrent la Seine comme presque biologiquement morte, seules trois espèces de poissons sur les 32 endémiques étant parfois aperçues.

La loi sur l'eau de 1964 permet un redressement de l'écosystème des eaux de la Seine, complétée par la loi sur l'eau du 3 janvier 1992. Des indicateurs de pollution sont créés et une aide financière et technique est proposée aux municipalités, aux agriculteurs et aux industriels. Des 1991 à 2001, 10 milliards d'euros, dont 5,6 milliards par l'État, sont investis dans des infrastructures, dont 500 stations d'épuration.

En résultat, la qualité des eaux s'améliore de manière continue, surtout à Paris, qui abrite vingt espèces endémique de poissons. Cependant les taux en azote sont toujours trop élevés, 66 % de la pollution provenant de l'agriculture, et la pollution par les nitrates et pesticides augmente, là aussi à cause de l'agriculture. Une autre pollution est liée aux eaux de pluie qui entraînent des polluants des zones urbaines : celles de Paris représentent à elles seules l'équivalent de tous les rejets des autres municipalités du bassin.

La Seine a fait l'objet d'une pollution au plutonium 239 en 1961 et au plutonium 238 en 1975. L'origine en est connue puisque la pollution est issue des installations du CEA à Fontenay-aux-Roses. Selon l'ASN le risque sanitaire est toutefois quasi nul.

La Seine est le fleuve européen le plus pollué aux polychlorobiphényle (PCB) depuis vingt ans. Toxiques, les PCB s'accumulent dans les lipides tout le long de la chaîne alimentaire. D'après des analyses effectuées par l'Office national de l'eau et des milieux aquatiques (ONEMA) depuis 2008, 70 % des espèces de poissons sont impropres à la consommation à cause d'une contamination aux PCB. L'usage des PCB est interdit depuis 1987 mais, très utilisés dans les années 1970, ils se sont accumulés dans l'environnement. L'association Robin des Bois dénonce une absence de réglementation au niveau de la pêche afin de protéger la population d'une consommation à Paris, dans le Val-de-Marne, les Hauts-de-Seine et les Yvelines. Cette pollution aux PCB est étendue jusqu'à la baie de Seine où la pêche à la sardine est interdite en 2010.

En 2010, la Seine est touchée par une pollution de rondelles en plastique, pollution accidentelle, limitée et non dangereuse selon les autorités, provenant d'une station d'épuration.

Les déchets de la Seine normande représentent un volume d’environ ou , soit la production annuelle de déchets ménagers des habitants d’une ville de .

La Seine a inspiré de nombreux peintres, et aux , les peintres suivants :




Le cours de la Seine est jalonné de nombreux sites touristiques.

En amont de Paris :

À Paris, les rives de la Seine sont inscrites au patrimoine mondial de l'Unesco depuis 1991.

En aval de Paris :




</doc>
<doc id="2764" url="https://fr.wikipedia.org/wiki?curid=2764" title="Stanley Kubrick">
Stanley Kubrick

Stanley Kubrick est un réalisateur, photographe, scénariste et producteur américain né le dans la ville de New York à Manhattan, et mort le dans son manoir de Childwickbury, entre St Albans et Harpenden (Hertfordshire, nord de Londres).

Après des débuts dans la photographie, Kubrick, autodidacte, sera également son propre directeur de la photographie, producteur, scénariste ou encore monteur. Ses treize longs métrages en quarante-six ans de carrière l'imposent comme l'un des cinéastes majeurs du . Quatre de ses films sont classés dans le Top 100 de l'American Film Institute.

Stanley Kubrick est issu d'une famille juive originaire d'Europe centrale habitant dans le quartier du Bronx. Son père, Jacques (Jacob) Leonard Kubrick (1901-1985), né aux États-Unis d'une mère roumaine et d'un père austro-hongrois, était cardiologue, pianiste et photographe amateur. Il apprend à son fils Stanley âgé de douze ans à jouer aux échecs. Cette passion suivra Stanley Kubrick toute sa vie. Sa mère Gertrude, née Perveler (1903-1985), chanteuse et danseuse, lui a donné le goût des livres et de la lecture. Il a une sœur cadette, Barbara, née en 1934.

De 1940 à 1945, Kubrick ne trouve aucun intérêt à l'école. Mis à part la physique, rien ne l'intéresse, et il n'arrive pas à obtenir une moyenne suffisante pour s'inscrire à l'université. D'autant plus que la guerre terminée, nombre de soldats revenant du front tentent d'y entrer, mais les inscriptions sont limitées.

En 1947, à l'âge de 18 ans, il se marie avec Toba Metz, une camarade de classe de l'. Ils s'installent au Greenwich Village deux ans plus tard. Il divorce de Toba Metz en 1951.

Pour son treizième anniversaire, son père lui offre son premier appareil photo. Cette nouvelle activité le passionne et lui fait oublier sa passion de jeunesse, le jazz, et son rêve de devenir batteur de jazz professionnel. Il prend de nombreuses photos et les développe avec un ami dans la chambre noire familiale. Il devient le photographe officiel de son collège et a pour idole le reporter-photographe Weegee.

En avril 1945, à l'âge de 16 ans, il réussit à vendre au magazine illustré "Look" une photographie d'un vendeur de journaux en larmes après la mort de Franklin D. Roosevelt, qu'il a prise alors qu'il se rendait au lycée. La rédactrice en chef l'engage comme photographe indépendant, « par pitié » dira-t-il plus tard. Stanley Kubrick y travaille durant quatre ans et y apprend les ficelles du métier, la composition d'une image, les éclairages, l'usage des extérieurs et l'art de saisir le mouvement. Plutôt perfectionniste, il lui arrive de prendre plusieurs centaines de clichés pour réaliser une seule photo. Grand amateur de boxe, son premier « photos-récit » intitulé "Prizefighter" ("Le Professionnel") raconte une journée de la vie du boxeur Walter Cartier. C'est ce photo-récit qui sera à l'origine de son premier film : "Day of the Fight".

Pendant ses premières années de photographe de magazine, Kubrick fréquente assidûment les salles de cinéma. Ses goûts sont éclectiques, avec une préférence, comme il le dit en 1963 dans la revue "Cinéma", pour le cinéma d'auteur européen comme Ingmar Bergman, Michelangelo Antonioni, Federico Fellini. Les films de Max Ophüls comme "Le Plaisir" ou "Madame de..." influencent le jeune Stanley Kubrick.

En 1950, l'autodidacte Stanley Kubrick, âgé de 22 ans, se décide à sauter le pas et se lance dans le cinéma. Pour lui, sa meilleure formation, ce sont les longues séances cinématographiques qu'il s'impose, des meilleurs films au pire des navets. « Je ne peux pas faire pire » se dit-il.

Dans ses premiers films, Kubrick fait tout lui-même : il est à la fois scénariste, cadreur, ingénieur du son, monteur et réalisateur.

Entre 1950 et 1951, Kubrick réalise deux documentaires, consacrés l'un à un boxeur, l'autre à un missionnaire. Il reprend l'idée de son photos-récit "Prizefighter" et réalise avec Alexander Singer, un camarade de classe, le court métrage "Day of the Fight" — une journée de la vie du boxeur Walter Cartier —, filmé comme un reportage. Autofinancé avec un budget de , le documentaire est vendu à RKO Pictures avec seulement de bénéfice. Pour "Flying Padre", Stanley Kubrick reprend la même idée et suit durant deux jours Fred Stadtmueller, un missionnaire catholique. D'une durée de , ce film est en partie financé et distribué par RKO.

Les deux documentaires sont des succès mineurs, mais Kubrick se fait remarquer par le brillant de sa photographie. Lui-même dira : 

En 1952, à la demande de Richard de Rochemont, futur producteur de son premier film "Fear and Desire", Kubrick est réalisateur d'une deuxième équipe sur une séquence d'un omnibus consacré à Abraham Lincoln. Par la suite, il réalise plusieurs épisodes, toujours en qualité d'assistant réalisateur. C'est en 1953 qu'il réalise son premier documentaire en couleurs, "The Seafarers". Dans ce film promotionnel sur la marine marchande, on retrouve les travellings à la Max Ophüls.

Pour réaliser son premier long métrage "Fear and Desire", Kubrick emprunte à sa famille . Il persuade un ami poète de lui écrire un scénario original : l'histoire d'un groupe de soldats chargés d'éliminer une troupe ennemie dans une guerre fictive ; à la fin du film, les soldats voient leurs propres visages dans ceux de leurs ennemis. Le réalisateur tourne son film en noir et blanc près de Los Angeles. Une nouvelle fois, il fait tout. Il décide de ne pas enregistrer le son avec les images et son erreur lui coûte de post-synchronisation. Malgré tout, il est fier d'avoir réussi à terminer son film. Plus tard, il qualifiera son film de « tentative inepte et prétentieuse » et décidera de le retirer des circuits de distribution et d'en interdire toute projection.

Encouragé par une critique honorable, Stanley Kubrick quitte définitivement le magazine "Look" bien que le film soit un échec commercial. C'est lors du tournage du film qu'il rencontre sa future femme, Ruth Sobotka.

En 1954, "Le Baiser du tueur" ("Killer's Kiss"), son second long-métrage, film très court tourné dans les rues de New York, raconte l'histoire d'un boxeur minable obligé de fuir la mafia. L’histoire manque d'originalité — c'est le seul scénario original écrit par Kubrick — mais ce film démontre son talent à jouer avec l'ombre et la lumière et confirme sa maîtrise technique dans la scène de règlement de comptes dans un entrepôt de mannequins.

Sa réalisation est récompensée par un Léopard d'or au Festival international du film de Locarno.

"Le Baiser du tueur" attire l'attention de James B. Harris, producteur indépendant qui a de bonnes relations avec les majors de Hollywood. C'est Alexander Singer, qui a connu Harris quelques années auparavant, qui fait se rencontrer les deux hommes. Cette rencontre est décisive, et ensemble ils fondent la "Harris-Kubrick Pictures" alors qu'ils ne sont tous les deux âgés que de 26 ans.

Deux ans plus tard, en 1956, naît de leur association le troisième film de Kubrick, "L'Ultime Razzia" ("The Killing"), le premier grand film avec un budget de financé en partie par Harris et les United Artists. Pour la première fois le réalisateur dispose d'acteurs professionnels et d'une équipe technique complète. Encore une fois, l’histoire n'a rien d'exceptionnel : un tireur embusqué doit abattre le cheval de tête dans une course hippique pour créer une diversion et ainsi faciliter le braquage de la caisse des paris. Un film noir de braquage comme il en existe beaucoup à cette époque, mais Stanley Kubrick fragmente l'histoire que seule la voix off très influencée par "Citizen Kane" d'Orson Welles permet de reconstituer. Plus d'une décennie plus tard, la critique Pauline Kael considérait que "L'Ultime Razzia" avait lancé la carrière de Kubrick. Elle ne s'était pas trompée. Leurs chemins vont souvent se croiser par la suite car elle va détester tous ses films : 

Au cours du tournage, Kubrick affirme son autorité : alors que le directeur de la photographie, Lucien Ballard, change l’objectif que Kubrick avait choisi pour une scène avec un travelling, ainsi que son emplacement en lui expliquant que cela n’aura aucune incidence sur les changements de perspective, calmement, le cinéaste lui intime l’ordre de remettre la caméra à son emplacement d’origine avec l’objectif initial, ou bien de quitter le plateau et de ne jamais y revenir. Ballard obéit et le tournage se termine tranquillement.

Malgré un budget important, Kubrick n’apparaît encore dans ce film que comme l’un des nouveaux maîtres de la série B. Orson Welles, interrogé par André Bazin sur les autres cinéastes, déclare : « "L'Ultime Razzia" de Kubrick n'est pas trop mal ». Dans la revue "Cahiers du cinéma", Jean-Luc Godard lui reconnaît quelques qualités tempérées : « C'est le film d'un bon élève sans plus. Ce qui correspond chez Ophüls à une certaine vision du monde n'est chez Kubrick qu'esbroufe gratuite. Mais il faut louer l'ingéniosité de l'adaptation qui, adoptant systématiquement la déchronologie des actions, sait nous intéresser à une intrigue qui ne sort pas des sentiers battus. »

"L'Ultime Razzia" étant un succès, United Artists accepte de financer à hauteur d'un million de dollars le prochain film de Harris-Kubrick tiré d'un best-seller américain de 1935, "The Paths of Glory", inspiré d'événements réels s'étant produits en 1915, l'affaire des caporaux de Souain, fusillés « pour l'exemple », et pas du tout des mutineries de 1917 comme on le dit couramment. Les fusillés de Souain n'étaient aucunement des « mutins », ce qui rend leur condamnation encore plus insupportable. Harris ne disposant que d'un budget très modeste selon les critères hollywoodiens et d'un scénario de Kubrick, Calder Willingham et Jim Thompson, le projet ne suscite guère d'enthousiasme auprès des majors. Tout bascule quand Harris envoie une copie du scénario à Kirk Douglas, lequel répond : . En 1957, sept ans après son premier court-métrage, Kubrick dirige Kirk Douglas dans le film sur l’absurdité de la guerre, "Les Sentiers de la gloire".

Le film se déroule durant la Première Guerre mondiale. Un général de l'armée française décide de lancer une de ses unités dans des attaques désespérées contre les lignes allemandes retranchées à Verdun. Pour l’exemple, trois soldats innocents seront fusillés pour lâcheté. Le film est entièrement tourné en Allemagne avec 800 policiers allemands pour jouer les troupes françaises. Les scènes en intérieur sont tournées au studio Geiselgasteig à Munich. On y voit apparaître des séquences qui caractérisent Kubrick et qu'il ne cesse de perfectionner par la suite : travelling avant en caméra subjective et travelling arrière pour la marche du colonel dans la tranchée et travelling latéral pour la scène d'assaut du no man's land, utilisation de la musique et mouvements de caméra sans heurt filmés avec une Dolly pour la marche ininterrompue du colonel Dax dans les tranchées. Cette scène est d'ailleurs similaire à celle du labyrinthe de "Shining" filmée en steadicam. La scène du chant de la jeune prisonnière, jouée par sa future épouse, l'actrice allemande et nièce de Veit Harlan Christiane Susanne Harlan, montre la capacité de Kubrick à filmer l'émotion sans tomber dans la sensiblerie. Il divorce de Ruth Sobotka en 1957 pour épouser en 1958 Christiane Harlan qu'il a rencontrée pendant le tournage. Son frère, Jan Harlan, deviendra le producteur délégué du réalisateur à partir de 1975.

Dans ce film apparaissent deux thèmes de prédilection de Kubrick : la double personnalité et un monde au bord de l'effondrement. Dans le livre et dans le film, les personnages sont clairement identifiés, avec le colonel Dax (Kirk Douglas), homme sobre, intelligent et courageux, et le général Mireau (George Macready), vaniteux, ambitieux et incompétent. Le personnage le plus machiavélique du film est le général Broulard (Adolphe Menjou). Kubrick joue habilement avec la bonhomie du personnage rusé et raffiné mais s'avérant incroyablement amoral (il va détruire les dernières illusions du colonel et ruiner définitivement la carrière du général) et sans aucune pitié envers les hommes de troupe.

Le film est projeté à Munich le . Il est perçu comme une critique directe de l'armée française, par la cruauté des scènes finales et la satire violente des états-majors français, même si le film souffre de nombreuses invraisemblances. Il reçoit plusieurs récompenses dont le prix "Chevalier de la Barre". Sous la pression d'associations d'anciens combattants français et belges, le gouvernement français proteste auprès de la United Artists, mais ne demande pas la censure du film. Devant l'ampleur du mouvement contestataire, les producteurs du film décident de ne pas le distribuer. De nombreux pays en Europe, comme la Suisse, refusent également de le diffuser. C'est dix-huit ans plus tard, en 1975, que le film est finalement projeté en France.

De retour aux États-Unis, Stanley Kubrick écrit deux scénarios qui seront refusés par les majors hollywoodiens. La MGM lui propose de travailler sur le scénario d'un western avec comme vedette Marlon Brando. Après six mois de travail de préparation, le cinéaste et l’acteur se fâchent. Marlon Brando, star hollywoodienne, obtient facilement le départ de Kubrick et décide de réaliser lui-même "La Vengeance aux deux visages".

Au même moment sur un autre film, Kirk Douglas, acteur et producteur principal du péplum "Spartacus", insatisfait du travail d'Anthony Mann, sollicite Stanley Kubrick pour terminer le film. Après le succès commercial des "Sentiers de la gloire", celui-ci accepte et termine le film. Le tournage dure 167 jours, partagé entre la Californie et l’Espagne pour les scènes de combat tournées avec figurants issus de l'armée espagnole.

Mais des conflits artistiques apparaissent rapidement entre Kirk Douglas et Russell Metty, le directeur de la photographie. Kubrick intervient également sur le scénario fondé sur l'histoire vraie du soulèvement d’esclaves romains qu'il trouve moralisateur et sans intérêt. Le film sort en 1960, il obtient un grand succès critique et commercial et gagne quatre Oscars. Quelques années plus tard, Stanley Kubrick renie le film dont il garde un souvenir amer. Dans l'œuvre de Kubrick, c'est son film le plus impersonnel, le film reprenant l'intrigue et le traitement du roman historique de Howard Fast.
En 1962, pour la réalisation de "Lolita", le réalisateur préfère éviter la censure et les ligues puritaines américaines et se tourne vers l'Angleterre pour le tournage. Il avait prévu de revenir ensuite aux États-Unis mais pour son projet suivant, "Docteur Folamour", l'acteur principal qu'il a choisi, l'anglais Peter Sellers, ne peut pas quitter le territoire car il est au milieu d'une procédure de divorce. Pendant le tournage de "Lolita", Kubrick achète une grande maison au nord de Londres où il s'installera avec sa famille. Il dira : , de plus, malgré sa licence de pilote amateur, Kubrick n'aime pas prendre l'avion.

Stanley Kubrick réalise donc "Lolita", son premier film polémique, sur le sol anglais, d'après le roman éponyme de Vladimir Nabokov. Le livre avait été publié pour la première fois en France comme ouvrage pornographique. Pour la rédaction du scénario, le cinéaste travaille en étroite collaboration avec Vladimir Nabokov. Ils écrivent ensemble une nouvelle version du roman qui est jugé plus acceptable pour un film commercial et la morale imposée au cinéma en 1962.

Le film raconte l'histoire d'un homme d'âge mûr, Humbert Humbert, joué par James Mason, pris d'une passion ardente pour une adolescente, Lolita, âgée de 12 ans dans le livre, 15 ans dans le film, interprétée par Sue Lyon qui obtiendra le Golden Globe de la meilleure actrice. Peter Sellers y fait une interprétation remarquée.

Le film, tout comme le roman, provoque la colère des puritains qui le trouvent trop sulfureux malgré sa mise en scène très chaste, bien éloignée des allusions sexuelles explicites de l'ouvrage de Nabokov. À la sortie du film, Stanley Kubrick reconnaît que s'il avait pu prévoir la sévérité des censeurs américains qui l'obligent à couper des scènes au montage et à remanier certaines séquences jugées trop licencieuses, il aurait probablement renoncé à la réalisation du film.

Le film est présenté à la Mostra de Venise en 1962, mais la critique est déçue. Le schéma d'accueil de ses films par la critique, dont la plus virulente est Pauline Kael, sera toujours le même par la suite : une partie ne lui fait pas de cadeau, tandis que l'autre l'admire. Ce premier film polémique est un succès outre-Atlantique, sans nul doute nourri par la controverse. En 1963, Jean-Luc Godard décrit "Lolita" comme un . En 1998, Sue Lyon déclare à l'agence Reuters que "Lolita" est le film qui a « causé [sa] destruction en tant que personne ». Il s'agit du dernier film produit par le duo Kubrick-Harris. Après ce long-métrage, Stanley Kubrick produit et réalise seul ses films, en laissant la distribution à la Warner Bros Pictures.

En 1963, Kubrick prépare son second film polémique et le premier opus d'une trilogie de films de science-fiction, "Docteur Folamour ou : Comment j'ai appris à cesser de m'inquiéter et à aimer la bombe", considéré comme un chef-d'œuvre d'humour noir. Kubrick se tient constamment au courant de l’actualité et s’abonne à des revues militaires et scientifiques. Il lit le roman de Peter George, "Red Alert", paru en Angleterre sous le titre de "Two Hours to Doom". Il réfléchit depuis longtemps à une histoire où une guerre nucléaire serait déclenchée soit par accident, soit à cause de la folie d’un personnage. Le roman de Peter George correspond à ses attentes. Il s’associe avec Peter George et Terry Southern, scénariste d"'Easy Rider", pour préparer le script, et travaille la photographie du film avec Weegee.

Le tournage débute le , aux studios de Shepperton à Londres, pour s’achever quatre mois plus tard. La distribution comprend Peter Sellers qui tient les rôles du président des États-Unis, du docteur Folamour, ancien chercheur nazi et handicapé recruté par l'armée américaine (clin d'œil à la trajectoire de plusieurs scientifiques nazis, dont Wernher von Braun), et du colonel britannique Lionel Mandrake. Une très grande liberté d’improvisation est laissée à Peter Sellers, filmé par trois caméras, tandis que le reste de la distribution et l’équipe technique doivent observer une grande rigueur. Le film doit se conclure par une bataille de tartes à la crème dans la salle de guerre, avec le président et tous ses conseillers militaires. La scène est filmée, nécessitant des semaines de tournage, mais Kubrick décide de la retirer du montage final.

Farce burlesque où la guerre nucléaire totale est déclarée à la suite de l'action d'un commandant devenu fou et d'un système de défense automatique, ainsi que satire des milieux politico-militaires, ce nouveau film sort en pleine guerre froide. Le risque de voir l’un des deux protagonistes employer l’arme atomique est élevé. Un problème de taille apparaît : un film réalisé par Sidney Lumet, "Point limite", avec Henry Fonda dans le rôle principal, traitant du même sujet, est sur le point de sortir. Stanley Kubrick intente un procès pour plagiat, et obtient gain de cause. Le film de Lumet ne sortira qu’en tandis que "Docteur Folamour" sort sur les écrans le et se trouve nommé pour quatre Oscars (meilleur film, meilleur réalisateur, meilleur acteur, meilleure adaptation cinématographique).

À partir de ce moment, installé définitivement en Angleterre, le cinéaste travaille de plus en plus lentement, poussant de plus en plus loin son perfectionnisme et sa volonté d'expérimentation technique. Il va passer cinq ans à développer son film suivant "2001, l'Odyssée de l'espace". Le , Kubrick rencontre Arthur C. Clarke au restaurant Trader Vic's du Plaza Hotel de New York. Pour imaginer le monolithe noir, clé de voûte du film, les deux coscénaristes font la tournée des galeries d'art le mois suivant leur rencontre. Selon le sémiologue français Alexandre Bourmeyster, ils se seraient inspirés des œuvres du peintre Georges Yatridès, alors mis en valeur par un des plus grands marchands de tableaux du moment, S.E. Johnson, qui exposait les œuvres de l'artiste de manière permanente aux International Galleries à Chicago.

Le tournage du film débute le , sous le titre provisoire de "Voyage au-delà des étoiles". Il se déroule dans un premier temps aux studios de Shepperton, puis se poursuit aux Studios d'Elstree, plus proches de la villa où Kubrick a emménagé. MGM et Cinerama financent le film, dont le budget s’élève à six millions de dollars. Pour la première fois, le cinéaste interdit le plateau de tournage à la presse, ce qu’il fera systématiquement par la suite.

Artistiquement, "2001" a été un changement radical dans les films de science-fiction. Stanley Kubrick n’étant pas un partisan des films où les décors et les monstres sont en papier mâché ou en carton, il souhaite que les décors de son film soient techniquement réalisables dans le futur qu’il présente. C’est Tom Howard, lauréat de l’Oscar des meilleurs effets visuels en 1947 pour "L'esprit s'amuse" et en 1959 pour "Les Aventures de Tom Pouce", qui est chargé de concevoir la savane préhistorique. Wally Veevers conçoit les véhicules spatiaux et le bus lunaire. On construit également une centrifugeuse de . Pour les effets spéciaux, Kubrick s’entoure d’éminents collaborateurs parmi lesquels Harry Lange, ancien conseiller de la NASA, et Marvin Minsky, directeur d’un laboratoire d’intelligence artificielle.

George Lucas, créateur de "Star Wars", déclarera après la mort de Kubrick que si ce film n'avait pas été fait, il n’aurait probablement jamais réalisé sa saga. Kubrick reçoit l'Oscar des meilleurs effets visuels, le seul et unique Oscar de sa carrière, pour la qualité de son travail. Une équipe l'a aidé dans cette tâche, mais comme il est à la fois concepteur et créateur de quasiment tous les effets spéciaux du film, c'est à lui que l'on décerne la statuette. C'est également le début de la légende que le cinéaste va volontairement se forger : celle d'un homme qui, tel un ordinateur, enregistre une incroyable quantité d'informations, devenant un expert de la mise en scène et en maîtrisant parfaitement tous les rouages. Stanley Kubrick n'hésite pas à utiliser les dernières innovations techniques quand cela sert son œuvre : ordinateur et projection frontale pour "2001", éclairage à la lumière des bougies pour "Barry Lyndon", grâce à un objectif Zeiss développé pour la NASA, ou encore steadicam pour "Shining" ("The Shining").
"Orange mécanique" est un film à la violence et à l’érotisme prémonitoire réalisé en 1971, d’après le roman "L'Orange mécanique" de Anthony Burgess et adapté par Stanley Kubrick qui travaille seul. Le thème du double, cher à Kubrick, est encore une fois développé dans ce film, avec Alex qui représente l’inconscient de l’homme qui lutte entre le bien et le mal dans un monde qui s’effondre. Kubrick réalise le film très rapidement, caméra à l'épaule, et presque entièrement tourné dans la région de Londres.

Au , dans une Angleterre où l'on ne sait plus comment enrayer l'escalade du crime, Alexandre de Large (Malcolm McDowell), le chef de la bande des "droogs" ou "droogies", exerce avec sadisme une terreur aveugle sur fond de mouvement de la Symphonie de Beethoven.

En Angleterre, le film suscite une polémique importante, qui est aggravée par plusieurs faits divers où des délinquants, portant les mêmes costumes qu'Alex, déclarent s'inspirer directement du personnage principal du film. Dans un premier temps, Stanley Kubrick ne tient pas compte de ces faits divers mais les médias, frustrés par le manque d’interlocuteur, se retournent vers l’auteur du livre qui se retrouve seul à défendre un film auquel il n’a pas participé. Mais la controverse s’amplifie et, inquiété par les lettres de menaces de mort qu'il reçoit à son domicile, le réalisateur oblige la Warner à retirer le film des écrans du Royaume-Uni.

Élu meilleur film de l’année 1972 par le New York Film Critics Circle, "Orange mécanique" est l’un des plus gros succès de la Warner Bros. Pictures et reste à l'affiche durant soixante-deux semaines.

Après trois films de science-fiction, frustré de l’abandon par la Warner Bros de son projet sur Napoléon, prévu avec Jack Nicholson dans le rôle de l’empereur (Kubrick a une véritable passion pour Napoléon, il ne comprend pas comment un homme aussi intelligent a pu sombrer), Stanley Kubrick réalise son premier film historique à partir de la biographie d'un jeune Irlandais (Barry Lyndon) d'après le roman picaresque de William Makepeace Thackeray - le destin d'un jeune et intrigant Irlandais sans le sou, Redmond Barry (Ryan O'Neal), de son ascension pleine d'audace à sa déchéance.

La préparation du film dure un an. Le réalisateur veut tourner un film à l’esthétique proche des tableaux du . La réalisation du film demande plus de de tournage au Royaume-Uni et en Allemagne au château de Hohenzollern, à Potsdam et au palais de Ludwigsbourg. À la fin du tournage, Kubrick et Ryan O'Neal sont définitivement fâchés. Les contraintes techniques imposées par le réalisateur font passer le budget du film de à plus de de dollars.
Les critiques sont sévères envers le film qui est jugé trop long, trop lent, élitiste et ennuyeux. Le film obtient pourtant quatre Oscars : meilleure direction artistique, meilleure photographie, meilleurs costumes, meilleur arrangement musical.

Stanley Kubrick entreprend ensuite l'adaptation du roman "Shining, l'enfant lumière" de Stephen King. Ce film est dans la lignée de "L'Exorciste", "Halloween" et "Rosemary's Baby" le meilleur du genre selon Kubrick. Le film est moins risqué financièrement que ses productions précédentes et, après l'échec commercial de "Barry Lyndon", l'adaptation d'un best-seller de Stephen King est un gage de quasi-succès (les six derniers romans de l'auteur se sont vendus à plus de d'exemplaires). Le réalisateur et Diane Johnson modifient profondément l’histoire du livre, ce qui déplaît à Stephen King qui refuse d’apparaître au générique final du film. Il ne sera pas le seul mécontent : aux États-Unis, l'exploitation du film est un échec, le public enrageant de n'avoir pas assez tremblé et reprochant aux deux scénaristes d'avoir abâtardi le genre et trahi l'esprit du livre. Comme à leur habitude, certains critiques huent le film.
Le film relate la descente aux enfers de Jack Torrance (Jack Nicholson), écrivain ayant accepté un poste de gardien à l'hôtel Overlook, isolé dans les montagnes rocheuses et fermé pour l'hiver. Il s'y installe avec sa femme Wendy (Shelley Duvall) et son fils Danny (Danny Lloyd) qui possède un don de médium, le "Shining".

Plus que tout autre film, "Shining" va consolider la réputation de du réalisateur. Kubrick rôde dans les immenses studios de l'Estree, la barbe et les cheveux longs, les yeux cernés, tout comme son héros Jack Torrance qui erre sans inspiration dans l'hôtel Overlook. Pour les déplacements de personnages les plus complexes à filmer, son opérateur Garrett Brown utilise un système de stabilisation de caméra qu'il a inventé quelques années auparavant : le steadicam. Le tournage de plus d'un an est particulièrement difficile pour Shelley Duvall. Alors que Kubrick laisse une certaine latitude dans l’interprétation à Jack Nicholson, Shelley Duval doit répéter de 40 à 50 fois la même scène. Aujourd'hui, Shelley Duval dit : 

L'image finale du film, semblable à la fin quelque peu mystérieuse et ambiguë de "2001, l'Odyssée de l'espace", engendre plusieurs interprétations par les fervents du cinéaste comme Rodney Ascher avec son film documentaire, "Room 237", lequel propose une interprétation sous forme d'indices cachés du film ; Stanley Kubrick lui-même n'a jamais donné une réponse définitive, préférant laisser le soin aux spectateurs de décider par eux-mêmes. Kubrick considère ce film comme son œuvre la plus personnelle.
Kubrick veut tourner un vrai film de guerre, mais ni un film comme "Apocalypse Now" ou "Voyage au bout de l'enfer", ni une parodie comme "Docteur Folamour", ni un film antimilitariste tel que "Les Sentiers de la gloire". La symbolique du film "Full Metal Jacket" est proche de celle d’"Orange mécanique" où le héros, intellectuellement supérieur à ses camarades, doit lutter entre le bien et le mal dans un monde en guerre. Le personnage central du film, le soldat (Matthew Modine) va petit à petit perdre son âme aux États-Unis, symbolisé par l’agression de son le soldat (Vincent D'Onofrio) et au Viêt Nam par l’exécution sans pitié d'une prisonnière vietnamienne.

Stanley Kubrick détourne l’esprit du livre "The Short Timers" de l’écrivain Gustav Hasford pour mieux imposer sa propre vision de la guerre, et de l’âme humaine, au grand mécontentement de l'écrivain qui est tout de même crédité au générique final comme coscénariste.

La première partie du film suit l'entraînement intensif d'un groupe de jeunes recrues américaines dans un camp de marines à Parris Island, aux États-Unis en 1968 pendant la guerre du Viêt Nam, et l'affrontement entre le sergent instructeur (Lee Ermey) et une jeune recrue inadaptée (Vincent D'Onofrio). La confrontation finale entre les deux hommes clôt cette partie. La deuxième partie du film se déroule au Viêt Nam et montre le baptême du feu des marines à Da-Nang puis la sanglante bataille du Têt dans la province de Hué.
Le film est entièrement tourné en banlieue de Londres, bien loin du réalisme du film d'Oliver Stone, "Platoon". Quelques plantes exotiques servent de décors d’arrière-plan, les scènes de combat sont tournées dans une usine désaffectée et l’île de Parris Island est recréée dans une ancienne base militaire britannique. Kubrick utilise plusieurs fois l’élargissement de champ pour modifier l’interprétation du spectateur lorsqu’il voit la scène de près puis de loin. Le tournage du film est interrompu pendant quatre mois à la suite de l'accident de voiture de Lee Ermey, conseiller technique en sa qualité d'ancien instructeur des marines et acteur principal de la première partie du film.

Plus de sept ans après la sortie de son dernier film, Stanley Kubrick se lance dans l'adaptation du roman "la Nouvelle rêvée" de l'écrivain autrichien Arthur Schnitzler, livre qu'il avait lu à la fin des années 1970. Le scénario est une fidèle adaptation du livre et raconte l'errance dans la nuit new-yorkaise du docteur Harford (Tom Cruise), obsédé par la révélation de sa femme (Nicole Kidman) d'avoir failli céder à la tentation d'un autre homme et à la recherche de ses propres fantasmes. Un voyage entre le réel et l'imaginaire.

On retrouve dans "Eyes Wide Shut" ce qui a toujours fasciné Kubrick : le thème du double qui envahit tout et qui engendre la perte d'identité, . Le tournage dure quinze mois de novembre 1996 à janvier 1998 et va bloquer la carrière de Tom Cruise pendant trois ans (deux ans de tournage et la sortie du film "Mission Impossible" de Brian de Palma est retardée d'un an). Comme à son habitude, le soir venu, Kubrick visionne sur vidéo les scènes tournées dans la journée et modifie au jour le jour le scénario en fonction des performances des acteurs. Après six mois de tournage, l'acteur Harvey Keitel claque la porte et est remplacé au pied levé par Sydney Pollack.

Ce film est le testament de Kubrick, qui meurt d'une crise cardiaque dans son sommeil le . Il est enterré à côté de son arbre préféré dans le manoir de Childwickbury, dans le Hertfordshire, au Royaume-Uni. "Eyes Wide Shut" sort en salle en , quatre mois après la mort du réalisateur. Il le considérait comme son « meilleur film » selon une révélation faite à son ami Julian Senior la veille de sa mort ().
Parmi les projets inachevés de Stanley Kubrick, on peut citer un film sur Napoléon Bonaparte, abandonné à la demande des producteurs : un projet monumental (fruit de trente années d'un travail de bénédictin) qui échoue en 1969 pour des raisons techniques, financières et d'organisation.

Après "Full Metal Jacket", Kubrick travaille en même temps sur deux films dont aucun ne sera réalisé. "Aryan Papers" ("WarTime Lies", adaptation du roman "Une éducation polonaise" de Louis Begley), un film abandonné pour ne pas concurrencer "La Liste de Schindler" de son ami Steven Spielberg dont le sujet est similaire, ainsi que "A.I. Intelligence artificielle", d'après la nouvelle "Les Supertoys durent tout l'été" de Brian Aldiss, projet réalisé par Spielberg après la mort de Kubrick. "Aryan Papers" raconte l'histoire d'un enfant traversant la Pologne pendant la Seconde Guerre mondiale et échappant à la déportation vers Auschwitz ; c'est son projet de film non-réalisé le plus abouti, le casting étant établi, avec Johanna ter Steege pour le rôle de Tania et Joseph Mazzello, pour le petit garçon.

Un autre projet qui n'a jamais été réalisé était "Le Lieutenant allemand", un film sur les parachutistes allemands à la fin de la Seconde Guerre mondiale. Il y eut de même un projet d'adaptation d'un roman de Stefan Zweig, "Brûlant Secret", un projet intitulé "Natural Child" (une fable sur la libération sexuelle, trop subversive pour l'époque), un projet intitulé "One Eyed Jack" (un western qui sera finalement porté à l'écran par Marlon Brando) et un projet intitulé "Lunatic at Large", sur un scénario de Jimmy Thomson, est encore d'actualité en 2011.

Kubrick posera aussi le projet de l'adaptation du roman "Le Pendule de Foucault" (l'auteur, Umberto Eco, s'opposera à ce projet) et celui du roman "Le Parfum" de Süskind. Enfin, le satiriste Terry Southern tentera de convaincre Kubrick pour la réalisation du film pornographique "Blue Movie".

Le jeune Stanley Kubrick, autodidacte, apprend les ficelles du métier de cinéaste — la composition d'une image, les éclairages, l'usage des extérieurs et l'art de saisir le mouvement. Plutôt perfectionniste, il lui arrive de prendre plusieurs centaines de clichés pour réaliser une seule photo — lors de ses quatre ans passés comme photographe au magazine "Look". C'est à cette époque qu'il décide de commencer sa « formation » en fréquentant assidûment les salles de cinéma. Ses goûts sont éclectiques, avec une préférence, comme il le dit en 1963 dans la revue "Cinéma", pour le cinéma d'auteur européen comme celui d'Ingmar Bergman, Michelangelo Antonioni ou Federico Fellini. Cependant, c'est par les films de Max Ophüls comme "Le plaisir" ou "Madame de..." qu'il sera particulièrement influencé, notamment le mouvement complexe et sans heurt de la caméra et les nombreux travellings.

Kubrick apprend réellement tous les métiers du cinéma en faisant tout lui-même dans ses premiers films — scénariste, ingénieur du son, monteur, réalisateur… — ce qui lui permettra par la suite d'intervenir et d'imposer ses points de vue à ses techniciens lors des tournages afin d'obtenir l'image exacte qu'il recherchait. Il démontre ainsi dès 1954, avec "Le Baiser du tueur", son talent à jouer avec l'ombre et la lumière et confirme sa maîtrise technique dans la scène de règlement de comptes dans un entrepôt de mannequins. Il démontre aussi rapidement à ses équipes techniques ses connaissances et son intérêt pour la photographie et la prise de vue. Pour lui, un réalisateur est à la fois metteur en scène et technicien.
Au fil de ses films, Kubrick ajoute de nouvelles techniques à sa réalisation qu'il ne cesse de perfectionner par la suite. C'est à cette époque qu'il se fait remarquer par le brillant de sa photographie. En 1956, dans "L'Ultime Razzia", Kubrick fragmente l'histoire que seule la voix off très influencée par "Citizen Kane" d'Orson Welles permet de reconstituer.

À partir de "2001, l'Odyssée de l'espace", le cinéaste travaille de plus en plus lentement, poussant de plus en plus loin son perfectionnisme et sa volonté d'expérimentation technique. Pour son premier film en couleur, il va passer cinq ans à développer ce film, qui, par son esthétique et sa mise en scène, marque un tournant dans le cinéma mondial, en particulier dans le domaine de la science-fiction. Souhaitant une vision de l'espace éloignée des bandes dessinées et proche des observations scientifiques, il prend pour directeur de la photographie Geoffrey Unsworth, spécialisé dans la science-fiction. Celui-ci utilise le format Super Panavision 70 et bénéficie du perfectionnement de nouvelles techniques (socles, grues, perches, bras articulés), permettant rotations et mouvements aériens de la caméra comme si elle-même était en impesanteur. Il ajuste également, sur les conseils et avec l'aide d'astronautes et de spécialistes dans le domaine, ses éclairages pour être conforme à la volonté très précise du cinéaste. Le tournage nécessite quatre mois de travail pour les acteurs, et dix-huit pour les effets spéciaux.

Pour "Barry Lyndon", le réalisateur veut tourner un film à l’esthétique proche des tableaux du . Pour recréer les conditions de l'époque, les intérieurs sont éclairés à la bougie, le visage des acteurs maquillés de blanc, les cheveux ternis par la poudre. La réalisation du film demande plus de 250 jours. Pour retrouver les conditions de lumière dans les anciens châteaux anglais, le réalisateur s'astreint à un éclairage des scènes d'intérieur quasiment à la lueur des bougies. Il se procure un objectif d'appareil photo Zeiss d'une focale de et une ouverture maximale de f/0.7, développé spécialement pour la NASA pour photographier l'alunissage de la capsule Apollo, mais encore jamais utilisé au cinéma. Il le fait monter sur une caméra réaménagée spécialement. Pour Kubrick ce n’est pas un gadget ou une lubie, le réalisateur veut préserver la patine, et l’ambiance d’un château dans la nuit du . Il précise : Cette contrainte technique sera néfaste au budget du film qui passe de à plus de de dollars. Le diaphragme de l'objectif de très grande ouverture (f/0.7), limite considérablement la profondeur de champ de la scène. Le réalisateur utilise également le zoom et les longues focales, ce qui a pour effet d'« aplatir » l'image.

La musique a une grande importance dans la majeure partie de l'œuvre de Kubrick. Ce n'est pas la musique qui sert le film, mais le film qui sert la musique. Kubrick privilégie dans la plupart de ses films la musique classique et souvent déjà préexistante.

Dans "2001, l'Odyssée de l'espace", pour la première fois, Stanley Kubrick incorpore de la musique classique à un de ses films : la composition de la musique prévue ayant du retard, il meuble la bande-son avec de la musique classique pour le pré-montage. Alors que la MGM veut imposer au réalisateur une musique originale, composée par Alex North, Kubrick réussit à garder ses choix originels : "Le Beau Danube bleu" de Johann Strauss II, "Ainsi parlait Zarathoustra" de Richard Strauss, et György Ligeti pour la séquence de la porte stellaire. C'est à la musique de Wendy Carlos qu'il fait appel, entre autres, pour "Orange mécanique". À Penderecki, Bartók, ou Ligeti pour "Shining".

Kubrick voulait que la musique corresponde à l'époque de l'histoire racontée. Ainsi, dans "Full Metal Jacket", film sur la guerre du Viêt Nam, il utilise des chansons des années 1960, époque du conflit. Mais pour la musique de "Barry Lyndon", Stanley Kubrick emploie des œuvres de Bach, Mozart, Vivaldi, Haendel et Schubert, alors que ces compositeurs ne sont pas tous du . Il doit faire des concessions ; Ne trouvant d'ailleurs pas de musique d'époque suffisamment dramatique pour la scène du duel final, il demande à Leonard Rosenman de réorchestrer la "Sarabande" de Haendel à un tempo plus lent.

La musique de son dernier film, "Eyes Wide Shut" est marquante par ses motifs linéaires de piano extraits de "Musica Ricercata" de György Ligeti. Elle accentue le malaise des situations vécues par le personnage de Tom Cruise.

C'est dans "Fear and Desire" que Kubrick insère pour la première fois une voix off. Puis dans "Le Baiser Du Tueur", en 1955. Le personnage principal Davey reconstitue en effet la chronologie de la narration grâce à sa voix off. En 1956 sort le troisième film de Stanley Kubrick, "L'Ultime Razzia" ("The Killing"). Kubrick fragmente l'histoire que seule la voix "off", très influencée par le "Citizen Kane" d'Orson Welles, permet de reconstituer. Il utilisera encore plusieurs fois la voix off par la suite, notamment dans "Docteur Folamour" et "Barry Lyndon".

Dans "Orange mécanique" et "Full Metal Jacket", c'est la voix intérieure, monologue qui n'est pas prononcé par un personnage mais qui exprime ses pensées au moment de la scène, qu'il utilisera pour la narration.

Lors de la présentation à la presse de l'exposition consacrée à l'homme et à son œuvre le dans la ville belge de Gand, sa veuve Christiane déclare : 

D'un caractère réservé, voire timide, pouvant raser les murs quand il croisait quelqu'un dans un couloir, Kubrick devenait un autre homme une fois installé derrière sa caméra : il contrôlait le monde.

Malgré cela il imposait le respect ; imperturbable, très créatif, il finissait toujours par obtenir ce qu'il voulait. Son perfectionnisme lui vaut une renommée d'homme dur, coléreux et mégalomane. On fait état de scènes recommencées près d'une centaine de fois, d'une dispute violente avec Shelley Duvall (héroïne de "Shining") dans le seul but de la mettre dans un état émotionnel intense, tout comme d'une équipe technique tenant une grande bâche des heures durant sous la pluie pour ne pas interrompre un tournage.

Stanley Kubrick devient un personnage mythique, vu comme un génie paranoïaque ayant une vision très pessimiste de la nature humaine, ne sortant de sa maison ultra-protégée, une sorte de forteresse infranchissable, ceinte de 80 hectares de bois et protégée par d'imposants grillages, que pour tourner ses films. Isolé dans son château anglais, Kubrick n'est pas pour autant coupé du reste du monde. Ses archives sont monumentales, quand il prépare un film, Kubrick dort le jour et travaille la nuit (décalage horaire avec Los-Angeles oblige).

Kubrick a toujours été réticent à s'entretenir sur ses œuvres, par crainte que celles-ci n'en soient appauvries. Les documentaires tournés sur Kubrick, le seront par sa fille Vivian, pendant le tournage du film "Shining" : "The Making of the Shining (1980)" et par son beau-frère Jan Harlan "" (2001).

Les critiques sont divisées sur ses films, une partie d'entre eux ne lui fait pas de cadeau, dont la très virulente Pauline Kael, Arthur Schlesinger JR. ou Jean-Luc Godard : « Un souci méticuleux du réel, une passion de l’exactitude, la « froideur » de ses images », tandis que les autres l'admirent : « L’exceptionnelle précision de sa saisie du réel en mouvement. »

« Une histoire qui se déroule dans un monde (intérieur ou extérieur) au bord de l'effondrement, compensée par une composition très symétrique, très ordonnée des plans et du cadrage. L'apparence, la double personnalité, les thèmes fétiches de Kubrick et que l'on retrouve dans tous ses films. »

En 50 ans de carrière, Kubrick va filmer ce combat intérieur, sous une perspective différente. Trois films de guerre, deux policiers, un film d'horreur, trois films de science-fiction, deux fresques historiques et deux films « érotiques ».

« Les dialogues de ses films sont très courts… »
L'histoire est principalement racontée à travers les images et la bande son pour susciter des émotions. « Quand vous dites les choses directement, elles ont moins de poids que si vous laissez les gens les découvrir par eux-mêmes. »

« En 50 ans de carrière seulement treize films… »
Vivian Kubrick dira : « Stanley était très triste d'avoir réalisé si peu de films, mais il avait un regret dans sa vie, c'était d'être si lent. »

Depuis "L'Ultime Razzia" S. Kubrick préfère adapter des livres plutôt que d'écrire un scénario original. 
Kubrick dira : « Je suppose que c'est par paresse, mais vous pouvez diviser tous les scénarios en deux catégories : ceux dans lesquels on se demande « ce qui va arriver » et ceux dans lesquels on se demande « comment cela va arriver » ».

Orson Welles a déclaré, en 1963 : Welles est né en 1915 et Kubrick en 1928 mais les deux artistes ont de nombreux points communs. Tous deux ont réalisé des films profondément originaux, et presque le même nombre (13 films pour Kubrick, 15 pour Welles). Ils se sont essayés au film de genre, et ont vécu en Europe, à la différence près que Kubrick s'est volontairement exilé en Angleterre pour travailler en paix, alors que Welles y fut contraint par la force des choses ; il avait besoin de décrocher des rôles pour financer ses films.
Tous deux n'ont pu mener à terme certains projets : "Don Quichotte" et "It's all true", que Welles a réalisés, n'ont jamais vu le jour de la main de leur auteur, tout comme Kubrick qui dut renoncer à réaliser un film sur Napoléon et un autre, au début des années 1990, sur l'Holocauste.
"Citizen Kane" était l'un des films préférés de Kubrick.
Steven Spielberg dira : Dans l'œuvre de Kubrick, "L'Ultime Razzia" est le film préféré de Spielberg.

Une partie de la critique française décrie le cinéma de Kubrick. Jean-Luc Godard notamment dans "Cahiers du cinéma", à propos de ses premières œuvres (L'Ultime Razzia, Spartacus, Les sentiers de la gloire), le décrit ainsi : , mais parle de Lolita comme un .
Martin Scorsese s'intéresse à l'œuvre de Kubrick depuis longtemps. Il signe en 2002 la préface du livre de Michel Ciment, un des rares récits aussi complets sur le réalisateur. Il y dit au sujet de Kubrick : Il poursuit l'analyse du style de Kubrick : 

La distance que garde Kubrick par rapport à la communauté d'Hollywood joue certainement en sa défaveur. En effet, à l'instar d'autres grands réalisateurs, comme Charlie Chaplin, Orson Welles, Fritz Lang, Robert Altman, Sergio Leone ou Alfred Hitchcock, Kubrick, malgré plusieurs propositions, n'obtiendra jamais l'Oscar du meilleur réalisateur.

Parmi les quelques récompenses qu'il a emportées :

Du 23 mars au 31 juillet 2011, une exposition lui est consacrée en France à Paris, à la Cinémathèque française. Une rétrospective nationale a eu lieu à cette occasion dans de nombreux cinémas.

Kubrick, personnage mythique du cinéma, devait fatalement devenir lui-même personnage de film. On peut voir un « Stanley Kubrick » dans les films suivants :

Trois mois avant le décès du cinéaste, un certain Stanley Kubrick, demeurant à Harrow, décède d'une crise cardiaque dans son petit appartement. Il s'agit d'un imposteur, Alan Conway, qui, pendant des années, se fit passer pour le cinéaste et tira ainsi profit de dizaines de personnes plus ou moins connues. Il semblerait que l'idée ait fasciné Kubrick lui-même. Un film avec John Malkovich retrace d'ailleurs l'histoire de cet homme : "Appelez-moi Kubrick".

À la suite d'un ennui de santé du chef-opérateur Claude Renoir sur le tournage du film "L'espion qui m'aimait", et à la demande de son ami le chef décorateur Ken Adam ("Barry Lyndon" et " Folamour"), Stanley Kubrick accepte, à la condition expresse que sa contribution reste secrète, de superviser l'éclairage de la scène d'intérieur du supertanker. Il existe cependant une photo de Kubrick sur le plateau de tournage.

"2001, l'Odyssée de l'espace" est un triomphe dont l’influence est gigantesque sur l'imagination collective et sur lequel viendra se greffer la théorie visant à lui donner une influence sur la NASA ; cette dernière aurait emprunté les noms de "Jupiter", "Discovery" ou "Ulysse" pour ses projets. En réalité, Discovery fut baptisée en référence au HMS "Discovery" de l'explorateur anglais James Cook. La fusée Jupiter, quant à elle, a été lancée en 1958, 10 ans avant la sortie du film.

D'après une théorie du complot, des contacts entre la NASA et Kubrick l'auraient poussé à réaliser pour leur compte des prises de vues factices. Cette théorie se fonde sur l'investissement supposé d'un ancien conseiller de la NASA et l'intérêt de cette dernière pour le film "2001", en phase de montage à l'époque. Celle-ci aurait poussé Kubrick à participer à la réalisation en studio de faux alunissages des programmes Apollo 11 et 12. En 1968, Kubrick aurait été secrètement contacté par l'agence spatiale pour réaliser les trois premiers alunissages. Kubrick aurait d'abord refusé puis fini par accepter face aux menaces de révélation de l’« embarrassante » implication de son frère Raul dans le parti communiste américain. Il aurait ensuite proposé un scénario où la mission Apollo 13 aurait échoué mais les astronautes sauvés. Devant le refus de la NASA, Kubrick aurait cessé sa collaboration. Ces affirmations proviennent pour la plupart du documentaire fictionnel "Opération Lune" réalisé par William Karel en 2002 pour montrer les moyens de trucages et de manipulation de la vidéo et des interviews. Ce documenteur réalisé avec des acteurs et des interviews détournées a créé la confusion, certaines parties relatant des faits réels, d'autres des hypothèses et de la pure fiction, le tout monté pour servir une fiction.

Dans le documentaire "Room 237", qui présente plusieurs théories plus ou moins plausibles sur le film "Shining," l'une d'elles prétend que Kubrick aurait truffé son film d'indices qui témoignent de cette collaboration et du secret qui l'entoure : le pull « Apollo 11 » de Danny, le numéro de la chambre évoquant la distance Terre-Lune de 237 000 milles américains, etc.












Stanley Kubrick a toujours été réticent à s'entretenir sur ses œuvres, laissant au spectateur la liberté de formuler sa propre interprétation. Les deux principaux livres auxquels il a participé activement avec Michel Ciment et Alexander Walker sont consacrés au récit (image et son) et à la symbolique de ses films.





</doc>
<doc id="2765" url="https://fr.wikipedia.org/wiki?curid=2765" title="Shikoku">
Shikoku

En japonais, est composée de deux kanjis. Le premier – – veut dire « quatre » et le deuxième – – veut dire « pays ». Ce nom vient du fait que l'île était divisée en quatre provinces (Awa, Tosa, Sanuki et Iyo). Ces provinces sont devenues aujourd'hui des préfectures.

La superficie de l'île est de . Sa population est estimée à d'habitants. Le point culminant de l'île est le mont Ishizuchi dans la préfecture d'Ehime.

À l'inverse des trois autres grandes îles du Japon, Shikoku ne contient aucun volcan.

Trois autoroutes connectent Shikoku à Honshū :

Shikoku a quatre aéroports régionaux (l'aéroport de Tokushima, Takamatsu, Matsuyama et Kōchi). Ils desservent les villes de Tokyo, Ōsaka, Nagoya, Fukuoka ou encore Sapporo. Des vols internationaux existent également vers Séoul à partir de l'aéroport de Takamatsu et vers Séoul et Shanghai à partir de l'aéroport de Matsuyama.

Shikoku est la seule région japonaise qui ne bénéficie pas du Shinkansen, le train à grande vitesse japonais.



Shikoku est célèbre pour son très ancien pèlerinage dédié à Kōbō-Daishi qui consiste à faire le tour de l'île à pied et à s'arrêter dans . Malgré un réseau de sentiers long de , il est effectué chaque année par un nombre important de Japonais, en plus ou moins deux mois.

Le festival Awa-Odori a lieu dans la ville de Tokushima tous les ans du 13 au 15 août.

Le festival Yosakoi a lieu dans la ville de Kochi tous les ans du 9 au 12 août. Il s'agit d'un festival de musique et de danse au cœur de la ville.

Le shikoku est une race de chien, encore appelée chien de Kōchi, du nom de la préfecture de Kōchi d'où il est originaire.



</doc>
<doc id="2767" url="https://fr.wikipedia.org/wiki?curid=2767" title="Sciences de la Terre">
Sciences de la Terre

Les sciences de la Terre regroupent les sciences dont l'objet est l'étude de la Terre (lithosphère, hydrosphère et atmosphère) et de son environnement spatial ; en tant que planète, la Terre sert de modèle à l'étude d'autres planètes dites telluriques.

Depuis que des sondes spatiales permettent d'explorer d'autres objets du système solaire, la planétologie est aussi classée parmi les sciences de la Terre. Celle-ci étudie notamment la Lune, les planètes et leurs satellites naturels, les astéroïdes, les météorites et les comètes. On parle plus généralement des « sciences de la Terre et de l'Univers ».

La géologie est la science qui, historiquement, s'occupait de la description et de l'histoire des couches externes de la Terre. Elle s'intéresse traditionnellement à la composition, à la structure et à l'évolution de la surface et des couches superficielles de la croûte qui, au cours des processus géologiques, sont tantôt enfouies sous la surface, tantôt exposées à la surface.

Depuis le milieu des années 1960, avec l'avènement de la tectonique des plaques par une méthode géophysique (magnétisme des roches), approuvant l'ancienne théorie de la dérive des continents d'Alfred Wegener, les géologues ont trouvé un cadre plus général et plus approprié dans lequel placer et interpréter leurs observations. Le résultat en est que les géologues s'intéressent maintenant aussi à des zones plus profondes de la croûte et du manteau de la Terre, qui avant 1965 furent essentiellement l'apanage des géophysiciens. Il en résulte un brassage des idées profitables pour l'ensemble des sciences de la Terre. Néanmoins, si les géologues tiennent compte dans leurs modèles géologiques des acquis de la géophysique interne, cette dernière fait appel à des modèles physiques suffisamment simples pour être mis en équations et dégager des résultats quantitatifs, tandis que les modèles géologiques sont souvent assez complexes mais restent qualitatifs.

Les sciences géologiques, organisées à l'échelle mondiale dans l'Union internationale des sciences géologiques, comprennent plusieurs disciplines qui se recoupent et sont souvent associées :


La géodésie et la géophysique sont des sciences qui étudient la Terre par des méthodes mathématiques et physiques. Elles sont regroupées officiellement dans le cadre de l'Union géodésique et géophysique internationale, qui comprend les sept subdivisions suivantes, formant autant d'associations internationales :

Le but de la météorologie est de trouver les lois régissant la dynamique du fluide que l'on nomme l'air et de pouvoir prédire son comportement futur. L'air est un fluide compressible, formé de différents gaz et se trouvant dans une mince couche à la surface d'un référentiel en rotation (la Terre). La météorologie étant une branche de la physique, la théorie des fluides, le calcul des forces et la thermodynamique sont mises à profit pour expliquer le comportement de l'atmosphère.

L'écologie étudie les interactions entre la Terre et le vivant en s'intéressant notamment aux interfaces entre géosphère, hydrosphère, biosphère, écosystèmes, économie et sociétés, car ces dernières ont pris une importance croissante avec la conjonction d'une explosion démographique et du développement industriel qui ont fortement augmenté l'empreinte écologique de l'Humanité et des individus qui la composent. 
Les sciences de la Terre s'intéressent ainsi à l'étude des impacts du développement et aux modes d'aménagement du territoire en tant qu'impactant plus ou moins fortement la naturalité des milieux, pour trouver des moyens de gérer, restaurer et protéger les ressources primaires (eau, air, sol, diversités génétique, paysagère et spécifique).

Les sciences de la terre s'intéressent pluridisciplinairement aux conséquences des manières dont l'Homme modifie les dynamiques écopaysagères, climatiques, géomorphologiques, écologiques (biodiversité, de productivité biologique, en incluant des approches de type écotoxicologie, écoépidémiologie, bioindication...). Les sciences de la Terre tentent aussi de mesurer le degré de surexploitation de ressources pas, peu, lentement, difficilement ou coûteusement renouvelables, dans l'espace (aux échelles globales et locales) et dans le temps (écologie rétrospective, paléoécologie...), pour contribuer à élaborer des solutions pour un développement plus soutenable, des mesures conservatoires et mesures compensatoires quand cela semble possible.


</doc>
<doc id="2768" url="https://fr.wikipedia.org/wiki?curid=2768" title="Système électoral">
Système électoral

Le système électoral, mode de scrutin ou régime électoral, désigne tout type de processus permettant l'expression du choix d'un corps électoral donné, souvent la désignation d'élus pour exercer un mandat en tant que représentants de ce corps (élection), ou moins souvent le choix direct (référendum) d'une option parmi plusieurs.

Dans le cadre d'élections, les systèmes électoraux sont soit des scrutins utilisant la règle de la majorité, dits scrutins majoritaires, soit des systèmes cherchant à représenter plus ou moins fidèlement le vote des électeurs via le principe de la représentation proportionnelle, soit des systèmes mixtes alliant ces deux types de système. Différents modes de scrutin peuvent donner des résultats très différents, en particulier dans les cas où il n'y a pas de préférence clairement majoritaire en faveur d’une seule et même option. À ce jour, plusieurs systèmes sont en vigueur ou proposés.

Un système électoral est une méthode de transformation des suffrages en élus qui n'est pas sans influence sur la façon de « faire de la politique » par les parties en présence, les systèmes d'alliances, l'organisation des campagnes électorales, ou le résultat. « Il constitue aussi un facteur important d'orientation positive du vote populaire, puisque sa logique et sa dynamique [...] influencent de façon souvent déterminante le choix de l'électeur ». L'importance que revêt cet aspect du vote dans un système politique justifie que de nombreux théoriciens se soient penchés sur les modes de scrutin, leurs effets et leur fonctionnement. Leur étude, qualifiée de "théorie du vote" dans le jargon anglophone, est une discipline du droit constitutionnel qui entre en relation avec la science politique et les mathématiques.

Des aspects indépendants du fonctionnement des modes de scrutin mais entrant fatalement en relation avec lui, tels la procédure électorale (décompte, scrutin), le corps électoral, l'éligibilité et le poids attribué à chaque vote sont traités par ailleurs.

L’exercice par les citoyens, formant le corps électoral, de leur droit de suffrage permet d’assurer la représentation du peuple ou de sa volonté. L’élection est un des moyens privilégiés pour la désignation des gouvernants dans les systèmes politiques, même lorsqu'ils se veulent démocratiques (alors que le vote est par essence un système aristocratique, où seule une minorité est élue, et que les démocraties utilisent autant que possible pour la représentation du peuple ; le tirage au sort ne se fait plus guère que pour le choix des jurés lors d'un procès).

Le résultat d’une élection peut être d'un seul gagnant, ou de plusieurs gagnants comme pour l'élection d'une assemblée délibérante. Le système électoral peut également fixer de quelle manière le nombre de voix est réparti entre les électeurs, et la façon dont les électeurs sont divisés en sous-groupes (circonscriptions géographiques, tribus ou nation traditionnelles...) dont les voix sont comptées indépendamment. Le suffrage est donc conditionné par un certain nombre de règles, qui déterminent les électeurs et les mécanismes relatifs à l’expression de leur vote.

Le droit de vote a longtemps été censitaire, dans les premières démocraties représentatives à proprement parler, avant de devenir universel, très souvent pour les seuls hommes. Les femmes ont été intégrées aux corps électoraux souvent tardivement, et il faudra attendre la fin de la Première Guerre mondiale pour voir le droit de vote des femmes devenir la règle dans une majorité de démocraties représentatives. La modernisation de ces démocraties a aussi permis un abaissement progressif de la majorité électorale, ainsi que l'intégration des résidents étrangers aux corps électoraux de certains pays, tout particulièrement pour des scrutins locaux. C'est d'ailleurs la règle dans le cadre de l'Union européenne, où tout résident ayant la nationalité d'un pays membre peut prendre part aux élections européennes et municipales s'il réside dans un autre pays de l'Union que le sien. La désignation de représentants du peuple revêt une telle importance qu'elle justifie également que seuls des citoyens responsables puissent y participer, ce qui peut impliquer le retrait du droit de vote aux personnes condamnées par la justice. Les systèmes électoraux ont toujours pu fonctionner indépendamment de ce type de considérations propres au seul problème du droit de vote.

L’environnement dans lequel une élection a lieu n'est généralement pas considéré comme faisant partie du mode de scrutin. Ce sont des aspects traités par les procédures électorales et l'organisateur des élections. Par exemple, si un système électoral spécifie le mode de répartition des votes de manière abstraite, il ne précise pas si la réalité physique du scrutin (l’acte de voter) prend la forme d'une feuille de papier ou d’un écran d'ordinateur, si ou comment les votes sont tenus secrets, comment vérifier qu'ils soient comptabilisés correctement, quel jour ou dans quel lieu se déroule le vote, comment s'opère la vérification de l'identité du votant et du respect du nombre de n auquel il a droit

Une circonscription électorale est une division géographique des votants. Chaque circonscription se voit affecter un ou plusieurs représentants (ou "sièges" à pourvoir) et les électeurs ne pourront choisir qu'entre les candidats (ou les listes de candidats associés) qui se présentent dans leur circonscription.

Ce genre de découpage géographique est utilisé pour les élections à une très grande majorité d'assemblées délibérantes.

En pratique cela donne lieu à l'organisation d'autant de scrutins différents qu'il y a de circonscriptions, en général simultanément, pour élire plusieurs personnes dans les mêmes conditions et pour exercer la même fonction. C'est pour cela qu'on parle d'élections législatives (ou sénatoriale"s", générale"s", municipa"les", régiona"les"), mais d'élection présidentielle (sans 's'), où il est question de n'élire qu'une seule personne dans un même espace géographique.

Le cumul des voix pour un parti sur l'ensemble du territoire n'est pas possible car il y a des élections séparées. La subdivision d'un territoire en circonscriptions crée un phénomène de seuil, entrainant certains votes qui auraient entraînés à l'attribution de sièges sans circonscription, à ne plus en attribuer.

Par exemple, lorsqu'il y a un seul siège à pourvoir par circonscription, le siège peut être remporté :
Cet effet de seuil évolue selon le nombre de circonscriptions et le nombre de sièges par conscription :

Le découpage en circonscriptions d'un territoire pose à la fois :

Un découpage électoral équilibré permet d’organiser un scrutin juste et honnête, ce qui justifie l’intervention d’un contrôle juridictionnel attentif. En effet, si l’arbitraire devait procéder au découpage des circonscriptions, certains pourraient en profiter pour découper les circonscriptions de manière déloyale dans le seul but d’aller dans le sens des intérêts de leur famille politique. Ainsi, en 1812, Elbridge Gerry, gouverneur du Massachusetts, avait-il découpé les circonscriptions de son État afin d’assurer une victoire aussi large que possible à ses partisans pourtant moins nombreux que ses adversaires. Cette technique purement politicienne, baptisée depuis lors « gerrymandering », fait l’objet d’une vigoureuse et quasi unanime dénonciation.

Mais même en dehors de toute tentative malhonnête de déformation des résultats de la part de dirigeants politiques peu scrupuleux, il peut arriver qu’un découpage électoral, juste lors de sa réalisation, finisse par devenir, au fil du temps, un foyer de surreprésentation ou de sous représentation pour certains électeurs ; les mouvements de population sont généralement à l’origine de pareils phénomènes. Il peut dès lors être dans l’intérêt de la majorité politique alors au pouvoir de ne procéder à aucun redécoupage des circonscriptions, dans un souci de garder un avantage technique sur l’opposition, ou à l'inverse de procéder rapidement à celui-ci.
Le découpage des circonscriptions est à cet effet examiné avec attention par l'autorité électorale compétentes (en France, par le Conseil Constitutionnel notamment) dans le but de limiter d’éventuelles atteintes à la sincérité ou équité du scrutin. Une solution partielle pour tenir compte des différences de populations entre circonscriptions consiste à pondérer le vote des élus dans les assemblées : une personne élue dans une circonscription de 200 000 habitants aura une voix double par rapport à celle élue dans une circonscription de 100 000 habitants.

Comme le dit métaphoriquement Michel Hastings, les systèmes électoraux permettent . On distingue généralement trois grandes « familles » de systèmes électoraux (ou modes de scrutins).




Les modes de scrutin en vigueur dans les différentes Nations sont extrêmement nombreux et variés à tous points de vue. Cela se doit à une pluralité de facteurs (historiques, culturels, géographiques) et aux priorités envisagées par les législateurs lors de l’écriture du texte de loi. Celui-ci doit, précisément, satisfaire à deux exigences très différentes :
l’un ou l’autre niveau étant considéré prioritaire en raison du moment historique où chaque loi a eu naissance.
Certains modes de scrutins affiliés à deux familles différentes peuvent même avoir des aboutissements similaires en fonction de la représentation, alors qu'ils fonctionnent différemment. 
Cela dépend d’une pluralité de facteurs assez difficiles à reconnaître, et notamment : distribution des électeurs entre les circonscriptions, nombre des circonscriptions, nombre des partis, nature des partis (unitaires ou de coalition), rapports entre les pouvoirs constitutionnels, coexistence de différentes formules électorales (au niveau national, régional, municipal), culture nationale en matière d’élections. 
Les formules majoritaires uninominales constituent une sorte de paradoxe dans la dite dualité, parce que leur résultat ultime (au niveau "macro-électoral") est de donner naissance à une puissante majorité, disposant d’un nombre de sièges plus élevé (en pourcentage) que les votes obtenus ; mais elles ne règlent que le niveau "micro-électoral", parce que l’électeur n’est appelé qu’à exprimer son choix pour l’un des candidats de sa circonscription.

C'est pourquoi, au sein même des trois familles, on distingue plusieurs « catégories » de systèmes. Ne seront décrits que ceux ayant servi dans le cadre d'élections, et non ceux relevant seulement de la théorie (tout au plus seront-ils évoqués).

Divers exemples d'application des différents systèmes électoraux et modes de scrutin seront opérés sur la base de résultats électoraux fictifs, répertoriés dans le tableau suivant :

Les modes de scrutin majoritaires regroupent les modes de scrutin caractérisés par une victoire de la ou des personnes ayant obtenu davantage de voix que leurs concurrents. Dans un scrutin de type majoritaire, l'objectif est généralement de dégager une majorité forte et uniforme, susceptible de gouverner sans entraves.

Ici, le candidat ou le groupe de candidats élu(s) sera celui ayant obtenu le plus de suffrages, aidé en cela par de larges mouvements d'opinion et une vaste assise électorale.

Les effets recherchés "via" l'usage d'un scrutin majoritaire ont des conséquences très importantes sur la manière dont votent les électeurs, la transcription des voix en sièges et, de fait, le fonctionnement du système politique dans une démocratie représentative. Les modes de scrutin majoritaires combinent donc une certaine efficacité, brutale et indiscutable, pour la formation de majorités aptes à gouverner, à de nombreux défauts, en particulier au niveau de la représentation du corps électoral, qui leur valent des critiques importantes.

On distingue d'une part les scrutins majoritaires uninominaux (élection d'une seule personne), et d'autre part les scrutins majoritaires plurinominaux (élection d'un groupe de personnes).

La catégorie des scrutins uninominaux regroupe tout mode de scrutin où une seule personne est élue pour un territoire donné (un pays ou une circonscription). Ces systèmes impliquent en général que seul le candidat ayant rassemblé une majorité absolue ou relative de suffrages exprimés soit élu. Ils peuvent être utilisés autant pour des élections législatives que présidentielles.

Le mode de scrutin majoritaire à un tour (aussi appelé Pluralité), est un mode de scrutin reconnu pour sa grande simplicité. Le candidat ayant rassemblé le plus de voix sur un territoire donné est élu en toutes circonstances. Une majorité relative de voix suffit pour gagner une élection, c'est-à-dire qu'il est possible que le candidat élu recueille moins de la moitié des voix exprimées. Les démocraties anglo-saxonnes, notamment le Royaume-Uni, le Canada et les États-Unis, l'utilisent abondamment, en particulier pour l'élection de leurs parlementaires. Lorsqu'il est utilisé lors des élections législatives, le scrutin majoritaire uninominal à un tour est caractérisé par une très forte tendance à mal traduire en nombre d'élus le poids réel d'une formation politique au sein de l'électorat.

Il amplifie souvent de manière considérable la victoire de la formation politique arrivée en tête, lui attribuant une part des sièges bien supérieure à sa part des voix. En fonction des circonstances, il peut aussi conduire à une surreprésentation, certes moins forte, ou à une sous-représentation plus ou moins prononcée du parti ou de la coalition arrivé(e) en seconde position. Enfin les autres formations politiques présentant des candidats sont généralement lourdement sanctionnées : les petits partis sont presque constamment laissés pour compte, à moins que leurs appuis se concentrent dans des circonscriptions électorales particulières.

Ce mode de scrutin déforme les résultats d'une élection en permettant une répartition des sièges entre les différents partis très différente de l'expression de la volonté du corps électoral. Il se peut même qu'un parti majoritaire en voix se retrouve minoritaire en sièges, comme cela s'est produit au Royaume-Uni lors des élections de 1951 : les travaillistes, avec 48,8 % des suffrages exprimés, ont obtenu 295 sièges, contre 302 aux conservateurs qui n'avaient pourtant rassemblé que 44,3 % des voix.

Le vote alternatif, mode de scrutin inspiré de celui évoqué précédemment, est un système électoral à préférences multiples ordonnées, qui satisfait lui aussi à l'exigence de la majorité absolue. Les électeurs votent pour des candidats dans des circonscriptions où un seul siège est à pourvoir, mais au lieu de voter pour un seul d'entre eux, ils doivent les classer par ordre de préférence sur leur bulletin. Lors du dépouillement, on classe d'abord les bulletins en fonction des premières préférences : si un candidat réunit une majorité absolue de ces premières préférences, il est élu. Sinon le candidat arrivé dernier est éliminé et ses bulletins sont répartis entre les autres candidats suivant les secondes préférences desdits bulletins. On continue le processus jusqu'à ce qu'un candidat recueille la majorité absolue des suffrages. Ce système se rapproche donc de celui du scrutin uninominal à plusieurs tours, sauf qu'il évite aux électeurs de se déplacer autant de fois, en incluant directement un processus d'élimination.

Ce mode de scrutin sert à l'élection des députés australiens depuis 1919. Il permet à des partis alliés de se présenter séparément devant les électeurs, mais sans affaiblir leurs chances de coalition, comme c'est le cas en Australie avec les deux partis de droite (Parti libéral et Parti national). En outre les électeurs des petits candidats ne perdent pas leurs votes, puisqu'ils concourent eux aussi à la désignation des principaux candidats grâce à leurs préférences suivantes. Comme pour le scrutin uninominal à un tour, le découpage électoral peut engendrer des risques de contradiction entre la victoire en voix et celle en sièges. Le vote alternatif déforme le vote populaire de la même manière que le scrutin uninominal à un tour : aux élections fédérales australiennes de 2007, les Verts, avec 7,5 % des suffrages exprimés, n'ont obtenu aucun siège, contrairement au Parti national qui en a eu plusieurs avec un score moins important, profitant de son alliance avec le Parti libéral. Il existe d'autres méthodes par classement assez semblables, quoique plus complexes dans le décompte des voix, qui ont été peu ou pas utilisées, comme le vote par approbation (dit aussi vote par assentiment), la méthode Condorcet ou encore la méthode de Coombs.

Le scrutin majoritaire à deux tours est un mode de scrutin qui permet l'élection d'un candidat (dans une circonscription ou pour l'ensemble d'un État) après deux tours de scrutin. Les électeurs sont donc appelés à voter une première fois pour l'un ou l'autre des candidats. Un deuxième tour est ensuite organisé, ne mettant en lice que les candidats ayant le plus de voix. Lors de ce second tour, le candidat ayant récolté le plus de voix est élu. Selon les pays, deux ou plusieurs candidats peuvent être admissibles au second tour. Dans la très grande majorité des cas, la loi permet cependant à un candidat ayant rassemblé une majorité absolue de suffrages exprimés au premier tour d'être directement élu. Ce mode de scrutin est utilisé en France et dans bien d'autres pays pour l'élection présidentielle : un candidat ne peut être élu qu'avec une majorité absolue de suffrages exprimés, et si aucun ne remplit cette condition au premier tour, on organise un second tour de scrutin auquel ne sont admis que les deux premiers candidats. Au terme de ce processus, le président est donc forcément élu avec une majorité absolue de suffrages exprimés. C'est aussi ce mode de scrutin qui est utilisé en France pour les élections législatives, à ceci près que les candidats admissibles au second tour sont ceux ayant obtenu au moins 12,5 % des voix des inscrits sur les listes électorales. Il peut donc suffire d'une majorité relative de suffrages pour être élu au second tour.

Comme les deux systèmes évoqués précédemment, le scrutin majoritaire à deux tours a des effets déformateurs sur la transcription des voix en sièges. Des alliances ou accords entre partis de sensibilité proche permettent cependant à de petits partis d'envoyer quelques députés siéger à la chambre basse, comme c'est le cas en France avec le Parti communiste français, qui jouit encore de ses alliances avec le Parti socialiste, et plus encore avec le Nouveau Centre, qui ne doit la formation de son groupe parlementaire qu'à ses alliances avec l'UMP. Ce mode de scrutin sanctionne en revanche durement les partis ne bénéficiant d'aucune alliance : lors des élections législatives françaises de 1997, le Front national, avec environ 15 % des suffrages exprimés, n'avait obtenu qu'un seul siège. En 2007, le Mouvement démocrate, avec 7,6 % des suffrages exprimés, n'a eu que 3 sièges sur 577 à l'Assemblée nationale.

De très nombreux autres systèmes ont été proposés, et sont parfois utilisés dans le cadre des élections uninominales, où l'on doit choisir un et un seul candidat. Le plus connu est peut-être la Méthode de Borda. Dans ce cas l'électeur soumet un classement de tous les candidats. Avec n candidats, on attribue à chaque candidat n-1 points chaque fois qu'il apparait en tête dans un bulletin, n-2 chaque fois qu'il apparait en deuxième position jusqu'à 0 point chaque fois qu'il apparait en dernière position. Est élu le candidat qui totalise le plus de points. Plus généralement, on peut demander aux électeurs de classer tout ou parti des candidats (en autorisant ou non les ex aequo), de donner des points aux différents candidats (en étant contraint ou non sur le nombre total de points), de noter chaque candidat, d'évaluer les candidats suivant diverses échelles de valeurs La présentation et la discussion de ces différentes méthodes dépassent le cadre de cet article.

Les modes de scrutins majoritaires plurinominaux sont des systèmes électoraux qui permettent l'élection de plusieurs candidats. Ils sont donc utilisés pour l'élection de plusieurs personnes en même temps.

Le scrutin majoritaire plurinominal à un tour est un mode de scrutin où sont élus plusieurs candidats sur un territoire donné. Le nombre de candidats élus dépend du nombre de sièges à pourvoir. Sont ainsi élus tous les candidats ayant recueilli le plus grand nombre de voix, jusqu'à concurrence du nombre de sièges en élections. Il n'est plus du tout utilisé pour la désignation des députés dans les démocraties représentatives contemporaines. Deux systèmes différents existent :



Depuis 2006, un double scrutin majoritaire plurinominal à un tour est en vigueur en Italie (où il a été introduit par la loi 270/2005). Dans ce pays, les deux Chambres (nommées Camera dei Deputati et Senato della Repubblica) sont élues au suffrage universel et sont chargées de s’exprimer sur la question de confiance qui est préalable à l’entrée en fonction du Gouvernement et qui peut être posée par celui-ci plusieurs fois au cours de la législature. Cela impose l’adoption de deux systèmes d’élection produisant de résultats semblables.

Il s’agit donc d’un double système de vote limité. On appelle ainsi un système majoritaire plurinominal qui prévoit l’assignation d’un nombre préfixé de sièges au profit de la liste ou coalition de majorité relative. Ce nom lui fut attribué à la fin du , dans une perspective inversée par rapport à nos jours, car il s’agissait – à cette époque-là – d’imposer une limite à la faction majoritaire, en garantissant l’assignation de quelques sièges à la faction minoritaire.

En Italie, ce système fut introduit une première fois par Benito Mussolini en 1923 avec la « loi-Acerbo » ; ce qui déconseilla son utilisation successive, jusqu’en 1993 quand elle fut ré-adoptée pour l’élection des conseils municipaux et des Maires. Son emploi actuel dépend de l’absence d’un système de partage et balancements des pouvoirs, à la suite de laquelle le Gouvernement (central ou local) nécessite le soutien d’une majorité solide. Malgré cela, en avril 2006 le gouvernement de Romano Prodi n’a pu disposer que d’un seul siège d’avantage au Sénat, ce qui a entraîné une grande faiblesse de son gouvernement. Au bout de deux ans, les Italiens ont été contraints de se rendre une nouvelle fois aux urnes et ils ont confié un plus grand avantage de sièges à la coalition conduite par Silvio Berlusconi.

Le scrutin majoritaire plurinominal alternatif est la version plurinominale du vote alternatif. Chaque électeur doit classer les candidats par ordre préférentiel. On procède ensuite à autant de dépouillements qu'il y a de sièges à pourvoir afin de pourvoir chaque siège au cas par cas. Les voix excédentaires du premier candidat élu sont réparties entre les autres candidats en fonction des préférences exprimées par les électeurs sur les bulletins concernés. Un parti majoritaire en voix pouvait donc remporter tous les sièges à pourvoir. Ce mode de scrutin a été appliqué uniquement en Australie, de 1919 à 1946, pour les élections sénatoriales : 18 sénateurs étaient alors élus dans 6 circonscriptions comportant 3 sièges chacune. Les 10 élections sénatoriales ayant eu lieu avec ce système ont permis de prendre la mesure de sa dangerosité : en 1925, avec 45 % des suffrages, les travaillistes n'ont obtenu aucun siège, tandis qu'en 1943, ils les raflaient tous avec seulement 55 % des voix. Les sénateurs australiens sont depuis élus à la représentation proportionnelle. Une variante proportionnelle théorique très complexe de ce mode de scrutin, le vote d'approbation proportionnel, a été mise au point en 2001.

Le scrutin majoritaire plurinominal à deux tours est inspiré de son équivalent uninominal. La majorité absolue des suffrages exprimés au premier tour permet de remporter directement tous les sièges au terme de ce dernier. Le second tour doit départager les différentes listes ayant atteint un certain nombre de voix si aucune d'entre elles n'a obtenu au moins 50 % des suffrages plus une voix. Dans le cas où le panachage est autorisé, les seuls sièges non pourvus au premier tour sont en jeu au second. Dans le cas de listes bloquées, celles-ci peuvent avoir le droit de fusionner entre les deux tours, phénomène qui permet l'existence d'une certaine forme de pluralisme politique au sein de différents blocs politiques. Si la fusion est interdite entre les deux tours, le jeu des alliances devient aussi déterminant qu'avec le scrutin uninominal. Utilisé en Belgique jusqu'en 1899 et au Luxembourg jusqu'en 1918 pour la désignation des députés, ce système a pour habitude de déformer le rapport entre voix et sièges en fonction de la répartition géographique des suffrages accordés aux différentes formations politiques. Lors des élections législatives belges de 1894, les Catholiques, avec 51 % des voix, ont obtenu près de 68 % des sièges, les socialistes en ont raflé 18,4 % pour 13,2 % des voix, profitant de la forte concentration de leurs suffrages au sein de plusieurs fiefs électoraux, tandis que les libéraux, souffrant à la fois de leur infériorité en voix et d'une mauvaise répartition géographique de leurs suffrages, n'ont pourvu que 13,2 % des sièges alors qu'ils avaient obtenu 28 % des voix. Avec ce système, plus le nombre de circonscriptions est limité, plus la déformation entre voix et sièges est importante. On en trouve une illustration avec les élections municipales françaises dans les communes de moins de : chaque conseil municipal est élu sur une seule circonscription, définie par le périmètre de la commune.

Le mode de scrutin majoritaire est le plus ancien de tous les systèmes de vote. Introduit pour la première fois en 1265 pour l'élection des parlementaires britanniques, il est toujours en vigueur dans ce pays ainsi que dans plusieurs anciennes colonies anglaises, telles les États-Unis, le Canada ou la Nouvelle-Zélande. À la fin du , les différents régimes parlementaires utilisaient principalement deux types de systèmes pour la désignation de leurs députés. Les pays anglo-saxons et latino-américains, ainsi que le Danemark, la Suède, l'Espagne, le Portugal et la Grèce recouraient au scrutin à un tour, généralement uninominal, tandis que les autres régimes parlementaires d'Europe continentale, comme la France, l'Italie, l'Allemagne, les Pays-Bas, la Norvège ou encore l'Autriche lui préféraient le scrutin à deux tours, bientôt rejoints par la Suisse qui abandonne en 1900 son scrutin majoritaire uninominal à trois tours. La Belgique jusqu'en 1899, ainsi que le Luxembourg pratiquaient quant à eux le scrutin majoritaire plurinominal à deux tours. L'origine des scrutins majoritaires est donc très ancienne.

Le scrutin à un tour, de par sa grande simplicité, est sans doute celui qui a été utilisé le premier, pour désigner un chef ou un délégué quelconque. Sous l'influence de l'Église catholique romaine, l'exigence de la majorité absolue a fini par s'imposer dans certains pays, et le scrutin à deux tours a fait son apparition. Autrefois attachée à la règle de l'unanimité, l'élection pouvant faire office dans ces conditions de révélation du choix divin, l'Église interprétait le vote comme une fonction, et non comme un droit. Les minoritaires, parce qu'ils sont minoritaires, étant forcément dans l'erreur, ne pouvaient représenter des points de vue légitimes, et l'unanimité devait dès lors être un objectif incontournable. C'était tout particulièrement le cas lors des élections ecclésiastiques par acclamation, au cours desquelles les minoritaires comme les hésitants étaient incités à se joindre à la majorité. Mais dans des cadres plus politisés, faisant intervenir des personnes aux origines et aux intérêts plus divers, l'obtention d'une élection à l'unanimité semblait hautement improbable. L'Église a donc peu à peu opté pour la règle de la majorité absolue, voire pour celle de la majorité qualifiée (par exemple, lors du conclave, les cardinaux élisent le pape à la majorité des deux tiers), cette dernière exprimant le regret d'une unanimité de fait inaccessible. Au Moyen Âge, les pouvoirs civils ont fréquemment fait appel à l'Église pour l'organisation d'élections, en particulier dans le cadre des communes.

Le nombre de tours et le seuil de suffrages à atteindre étant définis par le législateur, plusieurs systèmes comportant un nombre infini de tours ont été utilisés, notamment pour l'élection du Pape, ou pour celle du Président de la République française sous les Troisième et Quatrième Républiques. Aujourd'hui encore, les présidents des deux assemblées du Parlement français sont élus au scrutin majoritaire à trois tours, comme c'était le cas en 1789 pour la désignation des représentants du tiers état aux États généraux. Le simple fait de pouvoir désigner un représentant à la majorité absolue des voix en restreignant l'accès, au second tour, aux deux candidats arrivés en tête au premier, a toutefois fait tomber en désuétude ce type de système, qui n'est plus guère utilisé actuellement pour des élections au suffrage indirect. Critiqués pour leur injustice, les modes de scrutin majoritaire ne sont en outre appliqués, pour l'élection des assemblées délibérantes, que dans des pays les utilisant traditionnellement depuis l'instauration de la démocratie chez eux. Dans les ex-dictatures d'Amérique latine, d'Europe de l'est ou d'Afrique, c'est généralement la représentation proportionnelle ou un mode de scrutin mixte qui est instauré plutôt qu'un système complètement majoritaire. En Europe, seuls le Royaume-Uni et la France continuent d'élire leurs parlementaires au scrutin majoritaire uninominal.

Mis à part les problèmes d'actualisation des découpages des circonscriptions et du gerrymandering, on peut tirer plusieurs conclusions de la transformation des voix en sièges par les différents modes de scrutin majoritaire. Cinq phénomènes peuvent être régulièrement observés :

Le phénomène d'amplification de la victoire en sièges du parti dominant a tendance à être encore plus forte avec les scrutins plurinominaux qu'avec les scrutins uninominaux. Ils respectent en outre généralement mieux le principe d'égalité des électeurs devant le suffrage. Il est également plus simple de découper un pays en de multiples petites circonscriptions qu'en quelques tranches plus ou moins larges, en particulier lorsqu'on se retrouve confronté à des frontières administratives (départements, régions, États fédérés…). La recherche de systèmes de votes toujours plus justes de la part des démocraties modernes explique donc que le scrutin plurinominal ait pratiquement disparu au profit des scrutins uninominaux. Il reste toutefois le cas des élections municipales françaises, pour les communes de moins de .

Dans toute démocratie représentative, il existe, indépendamment du mode de scrutin, une dynamique dualiste, qui tend à opposer les partisans du gouvernement en place et ceux qui s'y opposent. Mais cette dynamique tend généralement à être contrecarrée par l'existence de différents groupes idéologiques, sociaux ou sociétaux qui, dans une dynamique de dispersions, cherchent à faire en sorte d'être représentés de manière autonome. Le mode de scrutin, s'il ne peut créer la dynamique dualiste, peut néanmoins l'influencer, et la favoriser dans le cas des scrutins majoritaires. Si l'électorat s'avère être relativement homogène, un vrai système bipolarisé peut se mettre en place. Cette bipolarisation prend soit la forme d'un bipartisme, soit celle d'un regroupement de différentes forces politiques d'un côté ou d'un autre. Le Royaume-Uni, qui a toujours élu ses députés au scrutin majoritaire uninominal à un tour, a pratiquement toujours connu un bipartisme plus ou moins fort. Depuis 1945, le Parti travailliste incarne la gauche britannique, le Parti conservateur, la droite, et les libéraux, puis les Démocrates libéraux après eux, incarnant une troisième force se situant au centre de l'échiquier politique, se voient constamment marginalisés, comme le prouvent encore les résultats des dernières élections générales britanniques :

Mais la bipolarisation ne se traduit pas forcément par l'apparition d'un bipartisme. En France, sous la V République (avec élections des députés au scrutin majoritaire à deux tours), les forces politiques ont souvent été bipolarisées avec à gauche les socialistes et les communistes, et à droite les gaullistes et le centre-droit (généralement composé de deux ou trois petits groupes politiques différents). La formation de l'UDF, qui rassemblait la droite non gaulliste au sein d'un seul parti afin d'équilibrer le poids du RPR, a un temps amené la France à une situation de bipolarisation sur la base de quatre grands partis de force équivalente : d'un côté le Parti communiste et le Parti socialiste, et de l'autre l'UDF et le RPR. Cette situation a perduré jusqu'à l'effondrement du PCF dès 1981, au profit du PS, et à la formation de l'UMP, qui a englobé une grande partie de la droite française, en 2002. Depuis, on peut dire que la France a tendance à se diriger vers le bipartisme, le PS et l'UMP détenant à eux seuls environ 85 % des sièges de l'Assemblée nationale au cours des deux dernières législatures. Les sièges restants sont presque tous pourvus par des partis bénéficiant d'accords électoraux avec l'un ou l'autre des deux grands partis. C'est pourquoi il est courant de voir un petit parti mieux représenté qu'un autre si ce dernier n'a pas d'alliés suffisamment puissants.

Généralement, lors d'élections, les électeurs votent essentiellement en tenant compte d'enjeux gouvernementaux. Leur capacité à choisir personnellement un élu s'en trouve donc réduite, et plus encore s'ils ne peuvent en outre pas choisir le candidat du parti dont ils se sentent le plus proche. Les scrutins plurinominaux avec listes ouvertes permettent aux électeurs d'exprimer leur degré de préférence pour tel ou tel candidat, mais cela n'empêche en rien le fait majoritaire de l'emporter "in fine", sanctionnant les partis de moyenne ou faible importance. Le principe du « vote utile » semble donc être totalement dépendant de l'organisation d'élections au scrutin majoritaire : les électeurs sont incités à porter leurs voix sur un candidat affilié à la formation politique la moins éloignée de leurs opinions politiques personnelles. Le scrutin majoritaire, en particulier à un seul tour, incite donc l'électeur à se rabattre sur le candidat « le moins mauvais » de son point de vue, parmi ceux ayant le plus de chances d'être élus : il vote stratégiquement afin d'obtenir une représentation idéologique, même imparfaite, plutôt que pas de représentation du tout.
On a toutefois constaté que le comportement des électeurs pouvait varier selon qu'il est confronté à une élection au scrutin majoritaire se déroulant à un ou à deux tours. Les analyses décrites ci-avant sur la bipolarisation ne concernent que le poids des différents partis quant au nombre d'élus, et non quant aux voix. Il semblerait, en effet, que les scrutins majoritaires à deux tours soient nettement plus propices au multipartisme que leurs équivalents à un tour. Les scrutins majoritaires ont un effet psychologique sur les électeurs, les incitant à voter de manière stratégique. Mais ce vote stratégique peut prendre des formes totalement différentes en fonction du nombre de tours censés départager les candidats. Ainsi, dans le cas d'un scrutin à un tour, les électeurs voteront « utile », soit pour celui des candidats parmi ceux les mieux placés pour l'emporter le plus proche (ou le moins éloigné) de leurs opinions personnelles. En revanche, dans le cas d'un scrutin à deux tours, l'électeur a plutôt tendance, au premier tour, à voter stratégiquement pour un « petit » candidat, plus proche de ses opinions, de façon à adresser un « message » au candidat le moins éloigné de ses convictions parmi ceux ayant le plus de chance de l'emporter. Les résultats du premier tour de l'élection présidentielle française de 2002 illustrent parfaitement ce phénomène : l'offre politique étant très importante, avec seize candidats, les électeurs ont éparpillé leurs suffrages et pas moins de sept candidats ont passé le seuil symbolique des 5 % des suffrages exprimés, aucun n'atteignant en outre le seuil des 20 %. Les élections législatives qui ont suivi ont, dans une mesure un peu moindre, confirmé cette tendance à l'éparpillement des voix, tout en mettant en évidence les effets mécaniques caractéristiques des scrutins majoritaires lors du passage des voix en sièges (l'UMP ayant obtenu 61,5 % des sièges pour 33,3 % des voix au premier tour).

À l'échelle internationale, la comparaison entre les différents pays démocratiques organisant leur élection présidentielle au scrutin majoritaire à un seul tour, et ceux l'organisant à deux, depuis 1990, est éloquente : parmi les six pays recourant au scrutin majoritaire uninominal à un tour, 2,7 candidats en moyenne obtiennent au moins 5 % des suffrages, et l'ensemble des candidats en dehors des deux premiers rassemble en moyenne 12,1 % des voix. Parmi les 39 autres recourant au scrutin majoritaire uninominal à deux tours, 3,8 candidats en moyenne obtiennent au moins 5 % et les candidats arrivés après les deux premiers rassemblent en moyenne 28,4 % des suffrages. On en déduit que les scrutins majoritaires à deux tours incitent à l'émiettement politique lors du vote tout en favorisant la bipolarisation, voir le bipartisme, lors de la répartition des sièges. Ils se situent ainsi à mi-chemin entre la représentation proportionnelle, qui favorise l'émiettement politique y compris lors de la répartition des sièges, et les scrutins majoritaires à un tour, qui incitent au vote utile tout en favorisant le bipartisme.

Deux systèmes permettent toutefois de contrer indirectement ces différents phénomènes. Avant 1996, date de la mise en place du scrutin uninominal majoritaire à deux tours par référendum, le Président de l'Uruguay était élu via un système très particulier. Chaque parti (il y en avait essentiellement deux) pouvait présenter autant de candidats qu'il le voulait. Le nombre de voix obtenues par chaque candidat était ensuite additionné pour savoir quel parti en avait obtenu le plus au total : le candidat élu était alors celui ayant rassemblé le plus de voix parmi les candidats du parti dominant. Les électeurs n'avaient donc pas besoin de « voter utile » et choisissaient eux-mêmes le candidat à élire au sein d'un parti, ce qui permettait d'éviter les contradictions entre ses militants et l'ensemble du corps électoral : un parti ne pouvait pas « imposer » son candidat. 

Compte tenu de la simplicité de la règle de la majorité, ceux qui ne sont pas familiers des modes de scrutin sont souvent surpris que d'autres systèmes électoraux existent. L'objectif principal de la représentation proportionnelle (RP) est de permettre une représentation de toutes les tendances du corps électoral, et tout particulièrement des minorités, s'opposant en cela de manière fondamentale aux modes de scrutin majoritaire. Il s'agit en fait de répartir plusieurs mandats d'élus entre plusieurs formations politiques, proportionnellement à leur poids électoral. Cela suppose l'établissement de listes de candidats de la part de ces dernières, pour que les électeurs puissent les départager. Bien que permettant, techniquement parlant, l'organisation d'élections à l'échelle nationale, la représentation proportionnelle est généralement appliquée dans le cadre de plusieurs circonscriptions, comme c'est le cas avec les systèmes majoritaires. La représentation proportionnelle a su faire des carences des modes de scrutin majoritaire ses qualités, mais elle peut également induire des difficultés quant à la formation d'une majorité politique apte à gouverner convenablement.

Il faut retenir que la représentation proportionnelle n'est pas soumise à une seule et même règle, comme cela peut être le cas avec les modes de scrutin majoritaire. Il existe différentes méthodes de calcul, qui, en fonction de la taille des circonscriptions électorales et du niveau du seuil légal d'accès à la répartition des sièges, permettent une répartition des sièges avantageant soit les grands partis, soit les petits partis, et parfois même les partis moyens. Des systèmes expérimentaux, dits pré-proportionnels, ont été mis au point avant que les vrais systèmes proportionnels contemporains ne fassent leur apparition. Ces derniers regroupent des méthodes de répartition complexes, utilisant dans une première phase un quotient électoral, puis dans une seconde phase une méthode de répartition des sièges restants, et des méthodes beaucoup plus simples, en une phase, recourant à des séries de diviseurs.

Il existe plusieurs systèmes qui appliquent, en principe, la règle majoritaire, mais permettent techniquement une représentation des minorités plus ou moins équitable en fonction des circonstances. Arend Lijphart les qualifie de « formes inhabituelles de proportionnelles à faible proportionnalité », mais ils sont plus couramment appelés systèmes semi-proportionnels ou pré-proportionnels, rapport à leur capacité à proportionnaliser à leur manière les résultats. L'électeur dispose, avec ces systèmes, d'un vote personnalisé : il vote individuellement pour plusieurs candidats et non pour des listes partisanes entières. Il est en fait amené à choisir plusieurs candidats, quelles que soient leurs appartenances politiques, parmi l'ensemble des candidats se présentant dans sa circonscription. On distingue couramment trois formes de systèmes pré-proportionnels.

Le vote à coefficients proportionnel ou vote cumulatif est une modification du scrutin majoritaire plurinominal, où l'électeur peut accorder plusieurs voix à un même candidat. Chaque électeur a autant de voix qu'il y a de sièges à pourvoir dans sa circonscription et les candidats ayant eu le plus de voix sont élus au prorata du nombre total de sièges en jeu. Ce mode de scrutin, efficace pour représenter les minorités importantes, est assez imprévisible : il est en effet techniquement possible que la formation politique majoritaire en voix ne le soit pas en sièges si ses électeurs ont voté trop massivement pour un seul de ses candidats. Le vote cumulatif a été utilisé dans l'État américain de l'Illinois de 1870 à 1980, où il avait permis une assez forte proportionnalité entre les votes et les sièges pour les deux principaux partis politiques. Il a également été employé dans quelques circonscriptions législatives au Sri Lanka de 1946 à 1977, pour permettre à quelques populations minoritaires localisées en des endroits bien précis du territoire d'être représentées au parlement, le scrutin majoritaire uninominal à un tour les privant systématiquement de toute représentation. Plusieurs méthodes fonctionnant selon les mêmes principes, dites du vote pondéré, ont été mises au point, mais elles n'ont pour l'instant jamais été utilisées pour des élections politiques.

Le vote limité est une variante du vote cumulatif, proposée pour la première fois par le Marquis de Condorcet en 1793 à la Convention, pour l'élection du bureau des assemblées primaires. Ici l'électeur dispose de moins de voix qu'il n'y a de sièges à pourvoir dans sa circonscription, et il ne peut pas cumuler plusieurs voix sur un même candidat. Un temps utilisé à Malte, en Espagne et au Portugal, le vote limité y a depuis été supplanté par la représentation proportionnelle. Il reste toutefois encore utilisé en Espagne pour l'élection des sénateurs, dans le cadre de circonscriptions à quatre sièges, à raison de trois voix par électeur.

Le vote unique non transférable, proposé par Condorcet en 1793 à la Convention pour l'élection des jurés, est un système qui s'inspire du vote limité, mais ici l'électeur ne dispose que d'une seule voix quel que soit le nombre de sièges à pourvoir dans sa circonscription. Ce scrutin ajoute une forte proportionnalité des voix et des sièges obtenus par les partis à l'égalité de l'électeur devant le suffrage, ce qui en fait le plus juste des scrutins non proportionnels. Utilisé au Japon de 1902 à 1993 pour les élections législatives, il y a depuis été remplacé par un système mixte. On dit que le vote est non transférable puisque l'électeur ne dispose que d'une seule voix, qui ne peut servir qu'à l'élection d'un seul candidat, en opposition au vote unique transférable, avec lequel il en a plusieurs, qui peuvent servir à faire élire plusieurs candidats différents ("voir ci-dessous"). Ce système oblige les formations politiques à prendre garde au nombre de candidats qu'elles présentent dans une circonscription, ainsi qu'à la manière dont les électeurs vont répartir leur suffrage sur ces différents candidats, comme avec le vote cumulatif.

Aussi appelé système de Hare, c'est le premier système proportionnel de l'histoire des modes de scrutin. Il s'agit d'une méthode par quotient, d'un type très particulier, proposé par Thomas Wright Hill en 1821 dans le cadre d'un vote encore public. Adapté au vote à bulletin secret au Danemark en 1855, il fut popularisé par Thomas Hare courant 1857. D'origine anglaise, il s'agit en quelque sorte d'une version proportionnelle du vote alternatif : il fonctionne à partir de candidatures individuelles dans des circonscriptions n'ayant pas un trop grand nombre de sièges à pourvoir. Chaque électeur doit classer par ordre de préférence les candidats de sa circonscription : les candidats élus sont ceux ayant atteint le quotient sur la base des premières préférences. Si l'un d'entre eux a dépassé le quotient, ses bulletins en surplus sont répartis entre les autres candidats selon les préférences suivantes : c'est le principe du vote transférable (notons qu'un électeur reste libre de n'attribuer qu'une seule préférence, dans ce cas sa préférence n'est pas transférable). Ce système permet de respecter les candidatures individuelles et incite les partis à afficher leurs alliances devant les électeurs en donnant des consignes de vote bien précises. Les partis alliés ou coalisés augmentent ainsi leurs chances de victoire tandis que les partis isolés sont sanctionnés lors de la répartition des sièges.

C'est le système électoral proportionnel le plus répandu dans lequel l'électeur vote pour une liste de candidat. Le système serait parfait si l'application de la proportionnalité permettait d'obtenir un nombre de sièges entier, mais c'est rarement le cas. Il faut donc appliquer un arrondi. Cet arrondi peut se faire selon plusieurs méthodes.

Le principe régissant le fonctionnement de ces systèmes, qui présupposent un quotient électoral, est le suivant :

Le nombre de sièges que chaque formation politique obtient lors de la première phase de répartition est donc égal au chiffre entier donné par l'opération "voix du parti sur quotient électoral dans la circonscription", soit (V/Q). Le ou les sièges restants sont par la suite affectés, par ordre décroissant, aux listes disposant des plus grandes différences entre le nombre total de leurs voix et le produit de la multiplication des sièges qu'elles ont gagnés, autrement dit : V - (S×Q).

Il existe couramment quatre méthodes de fixation du quotient électoral. La plus courante est celle du quotient de Hare, qui correspond au résultat du nombre de suffrages exprimés divisé par le nombre total de sièges à pourvoir, soit Q=V/S. Le quotient de Droop correspond lui au nombre total de suffrages exprimés divisé par le nombre de ses sièges augmentés d'un point, le résultat étant toujours arrondi au premier chiffre entier supérieur. Soit Q=[V/(S+1)]+1. Ce second quotient, très bas, peut parfois rendre possible l'attribution au quotient complet de la totalité des sièges en jeu. L'arrondissement vers le premier chiffre entier supérieur permet d'éviter que ne soient répartis, lors de la première phase d'attribution, plus de sièges qu'il n'y en a à pourvoir. Restent enfin le quotient Impériali et le quotien Impériali renforcé, où les suffrages exprimés sont divisés par le nombre total de sièges à pourvoir, augmenté respectivement de deux ou de trois.

Pour les différents exemples d'application, le quotient de Hare sera utilisé. Il sera donc de (/8). On distingue principalement deux méthodes de répartition des sièges restants :

Avec la méthode des plus forts restes, on utilise le quotient simple, puis on attribue les sièges non pourvus suivant la règle des plus forts restes : les listes disposant des plus importants restes de voix obtiennent les sièges restants, à savoir ceux non attribués au quotient. Cette méthode est favorable aux petits partis. Elle donne parfois lieu à des paradoxes mathématiques, tel que le paradoxe de l'Alabama, dus à l'évolution capricieuse des restes de voix.

Avec la méthode de Jefferson de la plus forte moyenne, on applique le quotient simple dans un premier temps, mais dans un second temps, chaque siège restant est affecté successivement à chaque liste en plus de ceux déjà acquis. Cette seconde répartition s'opère sur la base de la plus forte moyenne de voix par siège (chaque siège est attribué à la liste présentant la plus forte moyenne de voix pour le siège en question). Cette méthode favorise nettement les grands partis, phénomène qui a tendance à être amplifié par le nombre de sièges à pourvoir au sein de l'espace électoral dans lequel il est appliqué : moins il y a de sièges à pourvoir, plus les grands partis sont favorisés.

La méthode d’Hondt de la plus forte moyenne, proposée par le mathématicien Victor D'Hondt, donne les mêmes résultats et produit les mêmes effets que la méthode de Jefferson, mais s'avère être beaucoup plus simple dans la présente version. On recourt ici à une série de diviseurs, qui est la suite des nombres entiers : 1, 2, 3, 4 On divise en fait le nombre de voix obtenues par chaque liste par chaque nombre entier, puis on répartit les sièges aux plus fortes moyennes : à chaque fois qu'une liste obtient une plus forte moyenne, elle reçoit un siège.

La méthode de Sainte-Laguë de la plus forte moyenne, proposée en 1910 par le mathématicien français André Sainte-Laguë, fonctionne exactement de la même manière que la méthode d'Hondt, à ceci près qu'elle prend comme série de diviseurs 1, 3, 5, 7 Cette méthode est beaucoup moins défavorable aux petits partis et ne présente pas de paradoxes mathématiques. Elle est utilisée en Norvège, en Suède et au Danemark. Ces deux derniers ont en outre modifié le premier diviseur (1,4 au lieu de 1), afin de réduire l'influence des petits partis, donnant de fait un avantage aux partis moyens.

Ces systèmes ont un but simple : permettre d'atteindre la représentativité la plus exacte possible en attribuant aux formations politiques sous-représentées par le vote de circonscription un certain nombre de sièges de compensation. On distingue principalement deux catégories :

Il s'agit généralement de systèmes permettant l'attribution de sièges de compensation, sur de larges zones géographiques, après répartition des sièges à la proportionnelle dans le cadre de circonscriptions. Les sièges compensatoires sont répartis sur la base des restes de suffrages non utilisés pour la répartition des sièges dans les circonscriptions. Les sièges compensatoires sont soit ceux qui n'ont pu être répartis au quotient dans les circonscriptions, soit un nombre de sièges prédéterminé réservés à la compensation.

L'Italie utilisait un système semblable de 1946 à 1993 pour l'élection de ses députés. 630 sièges étaient alors à pourvoir dans 31 circonscriptions de base au quotient Imperiali. Les sièges non pourvus via cette première méthode étaient ensuite attribués au niveau national, sur la base de la totalisation des restes, suivant la méthode des plus forts restes. Ce système garantissait une très forte proportionnalité, la loi électorale n'exigeant d'atteindre aucun seuil de suffrages pour accéder à la répartition des sièges. Les plus petits partis étaient généralement parfaitement représentés, tandis que les plus grands ne pouvaient bénéficier que d'une très faible amplification en sièges de leur victoire en voix. Un système similaire est utilisé depuis 1919 en Belgique, également pour l'élection des députés : les sièges à pourvoir sont répartis par arrondissement au quotient simple, et ceux non pourvus via cette méthode sont répartis au niveau des provinces sur la base des restes, en utilisant la méthode d'Hondt.

Le Danemark et la Suède utilisent un système différent : une part du nombre total des sièges à pourvoir est réservée au vote de circonscription, tandis que la part des sièges restants est attribuée au niveau national, sur la base des restes de voix des différentes formations politiques pouvant accéder à la répartition des sièges. Au Danemark, outre les 4 députés représentant les Îles Féroé et le Groenland, 135 députés sont élus à la proportionnelle dans 17 districts, puis 40 députés sont répartis proportionnellement au niveau national, sur la base des voix obtenues par les différents partis qui ne leur ont pas permis d'obtenir suffisamment de sièges dans les districts par rapport à leur poids total en nombre de suffrages. En Suède, 310 députés sont élus dans 29 circonscriptions, puis 39 députés se partagent des sièges de compensation répartis au niveau national de la même manière qu'au Danemark. Les résultats des élections générales suédoises de 2006 et des élections législatives danoises de 2007 permettent de mesurer l'ampleur de la proportionnalité de ces systèmes. Notons enfin que ces deux pays, malgré leur fort multipartisme, ont un système politique caractérisé par la bipolarisation des différentes forces politiques, ce qui garantit une bonne stabilité gouvernementale.

Ce sont ni plus ni moins des systèmes combinant scrutin majoritaire et proportionnelle par compensation. Il s'agit en quelque sorte du contraire des scrutins mixtes à finalité majoritaire : une partie des députés, généralement la moitié, est élue au scrutin majoritaire, puis la mauvaise transcription des voix en sièges résultant de cette première répartition est corrigée par une répartition des sièges restants à la proportionnelle, en fonction du degré de sous-représentativité des différents partis. Il s'agit dans la pratique de systèmes mixtes majoritaire-proportionnel, mais dans les faits il n'en est rien, la répartition s'avérant être en réalité pleinement proportionnelle.

L'Allemagne utilise un système de ce type depuis 1949 pour l'élection des membres du Bundestag. Lors des élections fédérales, la moitié des députés est élue au scrutin majoritaire uninominal à un tour, et l’autre moitié à la proportionnelle par compensation. Les électeurs ont en fait deux voix : une pour choisir le candidat à élire au scrutin majoritaire, et l’autre pour choisir une liste de parti. La répartition proportionnelle s’opère à l’échelle des Länder : c’est ainsi qu’on compense la sous représentation des tiers partis provoquée par le scrutin uninominal. C’est le second vote, celui pour les listes de partis, qui détermine la composition finale du Bundestag : la répartition est pleinement proportionnelle et cela bien qu’une moitié des députés soit élue au scrutin majoritaire uninominal à un tour. Il arrive toutefois qu'un parti ait un nombre d'élus au scrutin uninominal, dans un Land donné, supérieur à ce à quoi il devrait normalement avoir droit avec la représentation proportionnelle. Dans ce cas il garde ses sièges supplémentaires, et a finalement un nombre total d'élus supérieur à ce à quoi il aurait eu droit à la proportionnelle. Le système allemand se pare dans ces cas-là d'une infime dimension majoritaire. Il faut cependant garder à l'esprit qu'il s'agit là d'une anomalie, tolérée par la jurisprudence, et qui reste marginale quelle que soit l'élection. Ce phénomène est donc pratiquement sans conséquence sur la finalité proportionnelle du système. L'analyse des résultats détaillés des différentes élections fédérales permet de prendre pleinement acte des différences fondamentales opposant le système majoritaire au système proportionnel.

Comme le montrent les résultats des élections de 2005, la part des sièges obtenue par les différents partis est très proche de leur part de seconds votes. Cet exemple permet en outre de mettre l'accent sur le comportement des électeurs en fonction du mode de scrutin qu'on leur propose : les centristes du FDP et les écologistes ont ainsi beaucoup plus de secondes voix que de votes de circonscription. Au contraire, les sociaux et chrétiens démocrates ont plus de voix au scrutin majoritaire qu'à la proportionnelle. Le vote utile influence donc bel et bien le choix de l'électeur.

La représentation proportionnelle est parfaitement compatible avec le fait de permettre à l'électeur de choisir personnellement son élu. Les systèmes de listes permettent en effet aux électeurs d'exprimer leur préférence pour un ou plusieurs candidat(s), au sein de la liste pour laquelle ils votent, si pareille procédure est prévue par la loi électorale. Plusieurs méthodes d'attribution personnelle des sièges existent (à ceci près que la première n’en est en réalité pas une) :

Les quatre dernières méthodes tendent à prouver que la proportionnelle peut à la fois concilier une juste transcription des voix en sièges et une réelle prise en compte du choix de l'électeur parmi les candidats qui se présentent à lui.

Comme on vient de le voir, les différentes méthodes de répartition des sièges à la proportionnelle peuvent avoir des effets variables. Plus elles sont favorables aux grands partis et défavorables aux petits, moins elles sont proportionnelles. Le politologue I. Nikolakopoulos a classifié ces méthodes sur la base d'une combinaison entre deux critères : leur effet restrictif et leur effet déformateur. Le premier effet prend en compte la part d'électeurs ayant voté pour des partis privés de représentation, et le second concerne l'ampleur de la surreprésentation ou de la sous représentation des formations politiques obtenant des sièges. Ses analyses l'ont conduit à classifier les systèmes proportionnels en trois catégories distinctes :

Thanassis Diamantopoulos s'est basé sur ces différents critères pour établir une classification plus exhaustive, prenant en compte des facteurs plus fonctionnels. Il distingue ainsi quatre catégories réparties dans deux grandes familles.

Malgré leurs différences plus ou moins marquées, ces trois catégories partagent une caractéristique commune, celle d'empêcher implicitement la formation de majorités parlementaires unipartisanes, même si elles ne poursuivent pas ce but avec la même intensité. Elles conviennent donc en principe aux pays dans lesquels la formation d'alliances gouvernementales est acceptée par la classe politique dans son ensemble. Elles ne favorisent évidemment pas la structuration bipartisane du système politique et vont dans le sens d'un parlementarisme multipartisan. Rappelons encore que dans tous les cas, la représentation proportionnelle est parfaitement compatible avec la bipolarisation du paysage politique.



Le but politique de ce type de système proportionnel est l'inverse de celui de ceux évoqués précédemment. Il s'agit en effet ici de faciliter la formation de majorités gouvernementales unipartisanes, tout en assurant, dans une certaine mesure, la représentation parlementaire autonome des formations politiques minoritaires. Ces « proportionnelles à faible proportionnalité » doivent donc indirectement favoriser la surreprésentation du parti ayant reçu le plus de voix. Pour Thanassis Diamantopoulos, cette surreprésentation ne doit pas excéder dix points, « ce qui pourrait être considéré comme le maximum politique acceptable dans un pays proportionnel ». Avec ces systèmes, une formation politique obtenant au total au moins 40 % des suffrages exprimés est pratiquement assurée d'investir une majorité absolue de sièges au parlement, sous réserve de disposer d'une avance non négligeable sur son principal concurrent.

Combiné à un seuil à atteindre d'au moins 3 ou 4 %, les systèmes pouvant être utilisés pour atteindre cet objectif sont la méthode d'Hondt appliquée dans des circonscriptions pourvoyant en moyenne 7 sièges au maximum (comme en Espagne), ou un système à plusieurs niveaux d'attribution des sièges, avec tous les sièges des niveaux supérieurs réservés aux grands partis. Dans le second cas, l'instauration de seuils électoraux variables d'un niveau à un autre peut jouer un rôle déterminant. Les proportionnelles à tendance majoritaire produisent des effets très proches de ceux des systèmes mixtes, ce qui amène T. Diamantopoulos à classer ces deux familles de modes de scrutin au sein d'une grande catégorie, dite des « systèmes intermédiaires ».

Au milieu du , se fondant sur les travaux de mathématiciens ayant tenté de mettre au point diverses formules proportionnelles de traduction des voix en sièges, plusieurs philosophes politiques comme Thomas Hare et John Stuart Mill ont porté l’idée de la proportionnalité. À partir de là, différents mouvements favorables à ce nouveau mode de scrutin émergeront partout en Europe, séduisant à terme, au moins en partie, la classe politique. Les origines de la représentation proportionnelle sont anciennes. En 1846, le penseur Victor Considerant élaborait l'un des tout premiers modes de scrutin proportionnel pour l'élection des membres de l'assemblée constituante de la ville de Genève. Mais c'est en 1855 que la représentation proportionnelle servira pour la première fois à l'élection de parlementaires nationaux : cette année entre en effet en application, au Danemark, le scrutin à vote unique transférable élaboré par Carl Andrae, pour l'élection des deux tiers des députés. Ce système alors unique en son genre resta en vigueur jusqu'en 1866. Il faudra ensuite attendre 1895 pour voir la Belgique généraliser la représentation proportionnelle d'abord pour ses élections cantonales (1895), puis pour ses élections législatives (1899), en recourant à la méthode mise au point par le mathématicien Victor D'Hondt en 1885. Après d'autres expériences dans certains cantons suisses et en Serbie (avec un système de boules à défaut de bulletins de vote), la représentation proportionnelle fait son apparition dans plusieurs autres pays au début des années 1900.

Les défenseurs de la représentation proportionnelle ont en général toujours eu deux types d’arguments. D’une part, l’injustice du système majoritaire, qui ne permet pas aux minorités d’être représentées au sein des assemblées délibérantes. D'autre part, la capacité de la représentation proportionnelle à permettre la formation de gouvernements de coalition, sur la base d'une majorité parlementaire pluripartisane, plus modérés et plus consensuels que des gouvernements monopartisans. Au début du siècle dernier, les partis conservateurs ou issus de milieux bourgeois, défendaient ardemment ce mode de scrutin, pensant que la représentation proportionnelle permettrait de freiner la montée du mouvement ouvrier qui pourrait obtenir, avec une majorité relative de suffrages, une majorité absolue de sièges dans le cadre d'élections au scrutin majoritaire. L’extension du droit de vote dans de nombreux pays permettra la diffusion de ces idées, le mouvement proportionnaliste atteindra son apogée à la fin du et au début du .

Plusieurs pays abandonnèrent alors les systèmes majoritaires en faveur de formules proportionnelles. Au cours des années 1920, le nouveau mode de scrutin avait séduit bon nombre de démocraties européennes, l’Allemagne, l’Autriche, la Belgique, le Danemark, la Finlande, la France, l’Irlande, l’Italie, le Luxembourg, Malte, la Norvège, les Pays-Bas, la Suède et la Suisse ayant alors choisi de recourir à la représentation proportionnelle pour l’élection de leurs députés. Mais ce succès fut de courte durée. Au lendemain de la Seconde Guerre mondiale, la représentation proportionnelle fut mise en cause par certains pour avoir permis la montée du Parti national-socialiste en Allemagne. On reprochait alors au faible seuil d’éligibilité de la représentation proportionnelle de permettre à de nouvelles formations antidémocratiques d’investir la chambre basse du Parlement assez rapidement. Celles-ci avaient alors les moyens, comme les partis traditionnels, de faire connaître leurs idées en disposant d’un espace où elles pouvaient se structurer et se solidifier progressivement. En outre, l’instabilité gouvernementale qui avait affecté certains pays connaissant un pluripartisme important dans les années 1930 et 1940 avait décrédibilisé la proportionnelle aux yeux de certains, qui l’assimilaient à un éclatement exacerbé du paysage politique.

Au sortir du second conflit mondial, la représentation proportionnelle avait donc été délaissée par les démocraties occidentales. Il faudra attendre les années 1990 pour qu’elle regagne du crédit dans cette partie du monde, notamment dans un souci croissant d’être en mesure de représenter la société dans sa diversité. Mais les critiques à l’égard de ce mode de scrutin ont tout de même perduré. Il était alors intéressant de tenter de concilier les avantages de la représentation proportionnelle et ceux des autres modes de scrutin, notamment le scrutin uninominal. Des systèmes mixtes ont peu à peu vu le jour en Allemagne, en Italie, aux Pays-Bas ou encore au Japon.

Si elle peut techniquement conduire à une plus forte fragmentation politique des assemblées délibérantes que les scrutins majoritaires, par le fait qu'elle offre une juste représentation aux tiers-partis et ne surreprésente pas les plus grands, la représentation proportionnelle ne conduit pas automatiquement à un éclatement de la classe politique, et n'est pas fatalement un facteur d'instabilité ministérielle. Cette mauvaise réputation lui a été attribuée à la suite de la chute de la République allemande de Weimar, puis de celle de la Quatrième République française, utilisant toutes deux des systèmes très proportionnels pour l'élection de leurs députés. Ces deux arguments méritent d'être tempérés par plusieurs faits importants : d'une part, la stabilité ministérielle ayant précédé la République de Weimar était en grande partie due au caractère impérial et fort peu démocratique du régime, d'autre part, la composition des différentes législatures de la Troisième République française était, malgré l'élection des députés au scrutin majoritaire uninominal à deux tours, aussi confuse, si ce n'est plus, que celle des trois législatures de la Quatrième République. On peut même dire que le système de représentation proportionnelle sélective utilisé pour l'élection des deux assemblées constituantes et de la première Assemblée nationale de la Quatrième République, à défaut de permettre une vraie stabilité ministérielle, a permis de remettre de l'ordre dans le système politique français, les électeurs portant les trois quarts de leurs suffrages sur trois grands partis (le PCF, le MRP et la SFIO). En outre, la première législature de la Cinquième République, dont les membres étaient intégralement élus au scrutin majoritaire uninominal à deux tours, était tout aussi hétéroclite que celles du régime précédent.

Le multipartisme ne dépend donc pas, ou tout du moins pas seulement, du mode de scrutin utilisé. D'autre part la représentation proportionnelle est tout à fait compatible avec un système bipartisan : c'est notamment le cas de l'Espagne, où deux grands partis, le Parti socialiste et le Parti populaire, détiennent à eux deux environ 90 % des sièges de la chambre basse, les autres étant occupés par de petits partis régionalistes à l'électorat fortement localisé. Le pluripartisme lui-même n'est pas forcément facteur d'instabilité ministérielle : les pays scandinaves (Suède, Norvège, Danemark) connaissent ainsi un très fort pluripartisme, mais qui est très nettement tempéré par une bipolarisation quasi inébranlable du paysage politique, sur la base du clivage droite/gauche, et ce malgré le caractère très fortement proportionnalisant de leurs modes de scrutin. Il en résulte une stabilité gouvernementale régulière et solide, qui permet à des chefs de gouvernement de rester plus de dix ans au pouvoir sans interruption.

Toutefois, lorsque les conditions le permettent, il est apparu évident que la représentation proportionnelle intégrale puisse favoriser, à défaut de provoquer, une instabilité ministérielle constante et régulière. En Italie de 1945 à 1993, un système très proportionnel, dépourvu de seuil d'éligibilité, permettait à des partis recueillant de très petits scores d'envoyer au moins un député au parlement. Deux grands partis, Démocratie chrétienne (DC) et dans une moindre mesure le Parti communiste italien, recueillaient une grosse part des sièges à pourvoir, et tous les autres sièges allaient à quelques partis moyens et à une foule de petits partis, la plupart se situant au centre de l'échiquier politique. DC est resté jusqu'à sa disparition le parti à la tête de tous les gouvernements, en alliance avec de petits partis. Les efforts systématiques auxquels devaient se plier les gouvernements, assurés d'une courte durée de vie, pour maintenir l'intégrité de leur majorité au parlement, au prix d'innombrables concessions et négociations, entravaient leur action. La proportionnelle intégrale, conjuguée à un très fort émiettement de la classe politique et à la règle du vote à bulletin secret pour l'adoption des lois par les parlementaires, a contribué à la paralysie des institutions de la Première République italienne. Notons cependant que, comme en France sous les Troisième et Quatrième Républiques, les gouvernements tombaient souvent mais le personnel politique changeait peu : il n'était pas rare de voir une même personnalité exercer des fonctions de ministre dans plusieurs gouvernements différents successifs. L'Italie a recours depuis 1993 à des systèmes mixtes pour l'élection de ses parlementaires, ce qui a favorisé la bipolarisation mais n'a que très récemment permis une diminution conséquente du multiparisme (aggravé en 1993 par l'Opération Mains propres), encore responsable de la dernière crise ministérielle.

Lorsque la répartition des suffrages entre les différentes forces politiques le permet, la représentation proportionnelle peut favoriser l'importance de partis « charnière », souvent centristes. C'était notamment le cas de la Démocratie chrétienne, le principal parti politique italien jusqu'en 1994, acteur incontournable lors de la formation de coalitions gouvernementales. L'Allemagne a connu une situation relativement semblable jusqu'en 1998 : le FDP, petit parti centriste, a longtemps été le seul parti, en plus du SPD et du bloc CDU/CSU, à accéder à la représentation parlementaire. L'Allemagne utilisant un système très proportionnel, il était impossible pour l'un des deux grands partis, à moins qu'il n'obtienne une majorité absolue de suffrages exprimés, de prendre la tête du gouvernement sans le soutien du FDP. Si le Royaume-Uni utilisait un système similaire, les Démocrates libéraux auraient très souvent été dans cette situation très favorable de force d'appoint, qui détermine pratiquement à elle seule l'orientation de la nouvelle majorité après une élection. L'irruption du Mouvement démocrate en France lors des élections législatives de 2007 aurait peut-être donné de tels résultats si la France élisait, elle aussi, ses députés à la représentation proportionnelle.

Ce phénomène amène certains défenseurs des scrutins majoritaires à affirmer que la représentation proportionnelle peut donner un rôle excessif à ces partis centristes par rapport à leur influence électorale effective. Mais ce raisonnement ne se suffit de toute manière pas à lui-même, les partis charnière devant aussi tenir compte de l'opinion dans leur stratégie d'alliance. Par exemple, en 1982, le FDP a mis fin à 13 ans d'alliance avec le SPD au vu des résultats catastrophiques de ce dernier lors d'élections locales, et a ainsi formé une nouvelle coalition de centre-droit avec la CDU, dont les représentants étaient préférés par une majorité d'Allemands à un gouvernement abandonné par l'opinion. Le FDP ne bénéficiant en outre pas d'une position dominante, il n'accède jamais au poste de chef du gouvernement : la répartition des rôles reste donc juste et équitable.

On reconnaît généralement à ces partis centristes un rôle modérateur qu'ils ne peuvent obtenir dans le cadre d'un système majoritaire, forcément dominé par le dualisme et la logique du conflit. Ils peuvent en effet éviter qu'un parti n'impose des politiques excessives à la population dans son ensemble, en se reposant sur une majorité absolue de sièges attribuée par une majorité relative d'électeurs. La représentation proportionnelle, par ce moyen, peut donc donner aux partis charnière un rôle de frein aux mesures extrémistes.

La représentation proportionnelle est compatible, tout comme les modes de scrutin majoritaire, avec la mise en place de seuils d'éligibilité. Les systèmes proportionnels sont donc généralement accompagnés de seuils à atteindre pour accéder à la répartition des sièges. Le seuil peut être établi au niveau national (5 % des suffrages exprimés sur l'ensemble du territoire en Allemagne pour pouvoir recevoir des sièges à la proportionnelle dans les circonscriptions), ou au niveau des circonscriptions (en 1986, les députés français étaient élus dans les départements sur la base des seules listes ayant rassemblé au moins 5 % des suffrages exprimés). D'autres pays utilisent même concurremment ces deux types de seuils : en Suède, un parti peut accéder à la répartition des sièges en obtenant 4 % des suffrages exprimés au niveau national, ou bien 12 % dans une circonscription.

Les seuils servent généralement à limiter l'émiettement politique. Ils peuvent toutefois mettre en péril la légitimité d'une assemblée ainsi élue s'ils sont trop élevés ou si ledit émiettement est trop prononcé. En Turquie, le seuil est de 10 % au niveau national, ce qui a eu pour effet, en 2002 puis en 2007, d'exclure la communauté kurde de toute représentation formelle, ses seuls candidats élus s'étant présentés sans étiquette. En 2002, seuls deux partis, l'AKP et le CHP, ont franchi ce seuil, alors qu'ils n'avaient recueilli à eux deux qu'un peu moins de 54 % des suffrages exprimés sur l'ensemble du pays. Ce phénomène n'est d'ailleurs pas nouveau : en Bulgarie, près d'un quart du corps électoral a été exclu de toute représentation lors des élections de 1992, et ce malgré la faiblesse du seuil (4 % au niveau national).

En 1993, les députés polonais étaient élus à la proportionnelle avec un seuil de 5 % pour les partis et de 8 % pour les coalitions au niveau national. L'objectif était de lutter contre l'émiettement politique qui avait permis, lors du scrutin précédent, à pas moins de 19 partis de faire leur entrée au Parlement, le plus fort d'entre eux n'obtenant que 12,3 % des voix. L'impact de cette mesure fut catastrophique : l'émiettement politique a perduré, et 35 % des suffrages exprimés ont été exclus de toute représentation. Les ex-communistes du Parti social-démocrate et leurs alliés du Parti paysan ont ainsi investi 300 sièges sur 460 alors qu'ils n'avaient rassemblé que 36 % des suffrages exprimés. Ces effets pervers des seuils peuvent donc rendre la représentation proportionnelle encore plus injuste que les modes de scrutin majoritaire, c'est pourquoi ils doivent être utilisés avec prudence. On constate toutefois que jamais pareils phénomènes n'ont pu être observés dans les démocraties occidentales, qui recourent généralement à un seuil de 4 ou 5 %.

Les modes de scrutin mixtes combinent à la fois un aspect proportionnel et un aspect majoritaire dans la méthode de désignation des élus. Pour la plupart assez récents, ils restent rares et sont beaucoup moins utilisés que les systèmes entièrement proportionnels ou entièrement majoritaires. Ils sont généralement critiqués pour leur complexité. Cependant, le recours à des systèmes mixtes pour l’élection des députés a sensiblement progressé à l’occasion des vagues de démocratisation en Asie et en Europe de l’est. La Corée du Sud, Taïwan, la Géorgie, la Hongrie ou encore la Russie se dotèrent en effet de modes de scrutin mixte durant ces périodes. L’Italie et le Japon y recourent depuis les années 1990. Mais ce récent succès des systèmes mixtes ne remet pas en cause leur fragilité.

La Bulgarie a ainsi renoncé à son scrutin mixte pour recourir dès 1991 à la représentation proportionnelle. La Corée a quant à elle sensiblement renforcé le caractère majoritaire du sien en 1988. La Russie a également abandonné son système mixte en 2007 pour un système entièrement proportionnel. Les scrutins mixtes restent tout de même bien implantés dans les grandes démocraties d’Europe occidentale, la France et l’Italie l’utilisant pour la désignation de divers types de représentants. Cette expansion récente témoigne de la volonté des législateurs de trouver des systèmes bénéficiant à la fois des qualités des modes de scrutin majoritaire et de celles de la représentation proportionnelle. Le fait de ne pas disposer de longues séries de résultats électoraux empêche une véritable analyse de l’impact de ces systèmes mixtes sur la vie politique et sur la manière dont les différentes formations politiques sont amenées à se comporter. On remarque toutefois que l’importance des effets majoritaires et proportionnels varie fortement en fonction de l’importance de la part des sièges concernés par l’un ou l’autre des deux aspects. L’effet majoritaire n’est ainsi dominant qu’avec les modes de scrutin à finalité majoritaire, qui garantissent au vainqueur de disposer d’une majorité absolue de sièges dans l’assemblée.

Les systèmes mixtes ne constituent pas une catégorie homogène, et la souplesse des règles qui leur sont associées permet une très large variété de choix quant à la définition d’un mode de scrutin mixte par le législateur.

Ces systèmes combinent un scrutin majoritaire uninominal ou plurinominal dans les circonscriptions qui ont le plus faible nombre de sièges à pourvoir, et la représentation proportionnelle dans les circonscriptions à plus fort nombre de sièges. Ils peuvent donc permettre d’équilibrer l’amplification en sièges d’une victoire en voix, grâce au scrutin majoritaire, par une représentation des forces minoritaires, grâce à la proportionnelle. Ce type de scrutin présente cependant des caractéristiques dangereuses quant à la légitimité de la composition de l’assemblée ainsi élue. Les circonscriptions les moins peuplées concernent généralement des zones rurales, tandis que les plus peuplées se trouvent être celles concentrant des populations urbaines. Un parti, ayant une forte implantation électorale dans les zones rurales, peut ainsi remporter un très grand nombre de sièges dans les circonscriptions recourant au scrutin majoritaire, tandis qu’un autre, mieux implanté dans les zones urbaines, ne bénéficiera pas d’une amplification en sièges de sa victoire en voix, puisqu’il n’obtiendra des sièges que dans les circonscriptions où la représentation proportionnelle est en vigueur.

Un système semblable était en application en Islande, dans les années 1930, pour l'élection des députés. Il n’était alors pas rare de voir les agrariens, bien implantés dans les zones rurales, emporter une majorité absolue de sièges, tout en étant largement minoritaires en voix au niveau national. Au contraire des conservateurs qui, bien qu’ayant remporté une nette victoire en voix, se retrouvaient marginalisés à l’assemblée, leurs électeurs étant concentrés dans la capitale Reykjavik, qui élisait ses députés à la proportionnelle. Les députés islandais sont maintenant intégralement élus à la représentation proportionnelle depuis 1959. C’est aussi un système de ce type qui sert à élire les sénateurs français depuis la mise en place de la V République. Les départements élisant moins de 4 sénateurs le font au scrutin majoritaire plurinominal de liste, tandis que les autres recourent à la représentation proportionnelle. Depuis les élections sénatoriales de 1959, les formations politiques de droite et du centre-droit ont toujours disposé d’une confortable majorité de sièges au Sénat, les représentants des conseils municipaux, traditionnellement plus orientés à droite, formant 95 % du collège électoral chargé d'élire les sénateurs. Là aussi les milieux ruraux, au vote généralement plus conservateur que celui des zones urbaines, facilitent grandement les victoires des partis de droite dans les départements où les sénateurs sont élus au scrutin majoritaire.

Ces systèmes permettent d'élire une partie de l'assemblée via un mode de scrutin majoritaire, tandis que l'autre sera élue au scrutin proportionnel. L'électeur dispose généralement de deux votes, et les deux répartitions peuvent s'opérer totalement indépendamment l'une de l'autre, contrairement aux scrutins recourant à la proportionnelle par compensation. C'est pourquoi le système électoral allemand, qui est à finalité intégralement proportionnelle, n'entre pas dans cette catégorie. Ces systèmes permettent un très grand nombre de variantes. Il est en effet possible d'allier tout type de scrutin majoritaire à n'importe quelle méthode de répartition proportionnelle. Les exemples sont donc nombreux et fort différents les uns des autres.

Avec ces systèmes, une moitié des représentants d'une assemblée délibérante donnée est élue au scrutin majoritaire, et l'autre moitié à la représentation proportionnelle, de manière totalement indépendante l'une de l'autre. Ainsi, de 1993 à 2003, la Russie employait un système mixte alliant le scrutin uninominal à un tour à la représentation proportionnelle pour l'élection des membres de la Douma. 225 députés étaient élus dans autant de circonscriptions au scrutin uninominal, tandis que les 225 restants étaient élus à la représentation proportionnelle au niveau national. Bon nombre de pays d'Europe orientale ont opté pour des systèmes de ce type à la fin des années 1990, afin de concilier les revendications de l'opposition, désireuse d'être justement représentée, et la nécessité pour le pouvoir soviétique vacillant de se maintenir en place, en favorisant l'élection de notables. Notons que la part proportionnelle ne dois pas être compensatoire, sans quoi le système deviendrait pleinement proportionnel, comme dans le cadre du régime électoral allemand.

Il s'agit toujours de systèmes permettant l'élection des deux « parts », majoritaire et proportionnelle, mais ici l'une des deux parts est plus importante que l'autre. La représentation proportionnelle peut donc être, dans le cas où la part majoritaire est la plus importante, de compensation, c'est-à-dire qu'elle corrigera partiellement les défauts du scrutin majoritaire.

De 1993 à 2005, les députés et sénateurs italiens étaient élus au scrutin majoritaire uninominal pour les 3/4 des sièges, le quart restant étant réparti à la représentation proportionnelle à titre de compensation. 

Dans l’ensemble, il s’agissait de deux systèmes très compliqués, prévoyant un nombre de sièges « proportionnels » trop élevé (le pourcentage de 25 % étant né d'un accident historique qui se produisit en 1963 et d'un référendum qui en fit profit, ayant eu lieu le 18 avril 1993) ; et qui en définitive ne garantissaient pas une majorité fiable au gouvernement. En outre, la loi pour l’élection de la Chambre des Députés ne réglait pas avec précision les rapports entre les candidats des circonscriptions uninominales et les listes proportionnelles (pour lesquelles l’électeur disposait d’un deuxième bulletin). Cela a entraîné la présence de listes trompeuses (surnommées par les Italiens "listes-chouette") ayant pour but de porter en soustraction sur elles-mêmes les votes qui devaient être enlevés aux listes de parti. Ce qui entraîna une très grande confusion lors des élections de 2001, à la suite desquelles 11 sièges de la Chambre ne furent pas assignés. Elle ne fut alors composée que par 619 parlementaires au lieu des 630 prévus par la Constitution.

Les deux modes de répartition peuvent aussi être totalement indépendants l'un de l'autre, tout en permettant la domination effective des élus au scrutin majoritaire ou à la représentation proportionnelle. Par exemple, depuis 1994, 300 des 480 représentants japonais sont élus au scrutin majoritaire uninominal à un tour, les 180 restants étant élus à la représentation proportionnelle dans le cadre de 11 grandes régions électorales. L'électeur vote donc pour un candidat au scrutin majoritaire et pour une liste de candidats à la représentation proportionnelle. Le facteur majoritaire est évidemment largement dominant, et le parti arrivé premier est pratiquement assuré de disposer d'une majorité absolue de sièges à la Chambre des représentants. L'Équateur utilise au contraire un système mixte à dominante proportionnelle : les élections se déroulent exactement de la même manière qu'au Japon, mais les élus à la RP sont plus nombreux que ceux au scrutin majoritaire. Le facteur proportionnel est donc naturellement dominant, mais la composition finale de l'assemblée reste toutefois très éloignée de la proportionnalité parfaite.

Plusieurs pays d'Asie, comme la Corée du Sud ou Taïwan, combinent le vote unique (transférable ou non) à la représentation proportionnelle. La Corée du Sud a utilisé un système de ce type pour l'élection de ses députés en 1981 et en 1985. Il y avait en tout 276 sièges à pourvoir : 184 au vote unique dans le cadre de 92 circonscriptions à deux sièges, où l'électeur ne disposait que d'une voix, et 92 au niveau national, dont 61 étaient réservés au parti arrivé en tête (les 31 restants étaient répartis à la RP entre les autres listes). Chaque candidat dans une circonscription devait être membre d'une liste nationale : c'est ainsi qu'on connaissait les résultats des différents partis au niveau national pour l'attribution des 61 sièges de prime majoritaire. Bien que fort complexe, ce système était très simple pour l'électeur qui avait juste à voter pour un candidat. La forte prédominance de la règle de majorité a permis, lors des législatives de 1981 et de 1985, au PJD, le premier parti du pays, d'obtenir une majorité absolue de sièges pour seulement 35,6 puis 35,3 % des suffrages exprimés. Plus la part des sièges pourvus à la RP est faible, plus le fait majoritaire est fort. L'actuel mode de scrutin taïwanais fonctionne exactement de la même manière, mais permet au contraire une forte proportionnalité globale : 125 députés sont élus au vote unique dans le cadre de circonscriptions à plusieurs sièges (ce qui renforce l'aspect proportionnalisant du vote unique), et 36 autres sièges sont attribués au niveau national à la RP entre les partis ayant atteint un seuil de 5 % des suffrages exprimés.

Ces systèmes font intervenir la dimension majoritaire ou proportionnelle d'un système en fonction des résultats de l'élection. C'est donc soit la nature des résultats d'une élection au scrutin majoritaire qui garantit l'intervention d'un correctif proportionnel, soit celle d'une élection à la représentation proportionnelle qui garantit l'intervention de la règle de la majorité.

En France, lors des élections législatives de 1919 et de 1924, on avait allié un mode de scrutin majoritaire plurinominal à un tour à la représentation proportionnelle. L'électeur disposait d'autant de voix qu'il y avait de sièges à pourvoir dans son département. Il y avait ensuite trois façons d'obtenir des sièges : d'une part les candidats ayant obtenu la majorité absolue des suffrages exprimés étaient directement élus ; d'autre part les sièges non pourvus de cette manière étaient répartis au quotient de Hare entre toutes les listes (chaque candidat faisait partie d'une liste, il fallait donc ajouter les suffrages des candidats ayant une même étiquette pour trouver le score de la liste) ; enfin les sièges non pourvus via ces deux méthodes de répartition étaient tous attribués à la liste arrivée en tête. Ce système rendait le jeu des alliances entre formations politiques déterminant. Pour les législatives de 1951 et de 1956, la loi des apparentements permettait aux listes de partis de se déclarer « apparentées » avant le vote. Si l'addition des suffrages des différentes listes apparentées atteignait la majorité absolue des suffrages exprimés, elles recevaient tous les sièges à pourvoir dans le département (autrement la répartition s'opérait à la représentation proportionnelle entre toutes les listes). Remarquons qu'ici c'est l'aspect majoritaire qui est conditionné. Si ce dernier système a permis à la Troisième force, vaste coalition centriste, de l'emporter en 1951, il n'a été pratiquement d'aucun effet en 1956, tant l'émiettement politique était fort.

Techniquement parlant, les scrutins de type proportionnel sont à "finalité" proportionnelle, tandis que les scrutins majoritaires sont à "effet" majoritaire. Il n'est donc pas certain qu'une assemblée, dont les membres sont élus au scrutin majoritaire, se retrouve forcément dominée par un parti ou par une coalition détenant une majorité absolue de sièges. C'est également le cas des systèmes mixtes à finalité majoritaire, qui combinent le scrutin majoritaire de liste à la représentation proportionnelle. Il s'agit en fait généralement d'attribuer une part du total des sièges à pourvoir, un quart, un tiers ou la moitié, à la formation politique arrivée en tête, à titre de prime majoritaire. Les sièges restants sont ensuite répartis à la proportionnelle entre toutes les listes, y compris celle ayant bénéficié de la prime majoritaire. L'Italie et la France sont les deux principales démocraties à user régulièrement de systèmes de ce type.

L'Italie a pour la première fois élu ses députés avec un système mixte en 1924, peu après l'arrivée de Mussolini au pouvoir. Le scrutin avait lieu dans 15 circonscriptions, et la liste arrivée en tête au niveau national, si elle obtenait au moins 25 % des suffrages exprimés, recevait une prime majoritaire s'élevant aux deux tiers des sièges à pourvoir dans la chambre basse. Le tiers des sièges restants était ensuite réparti à la proportionnelle entre toutes les listes à l'échelle des circonscriptions. Cette loi ne sera pas d'une grande utilité aux fascistes et à leurs alliés, les pressions qu’ils exerçaient sur les électeurs leur ayant assuré 65 % des voix sur l'ensemble du pays.

La loi électorale de décembre 2005 se rapproche de ce système : les sièges sont répartis entre les coalitions ayant obtenu plus de 10 % des suffrages exprimés (et dans ces coalitions, parmi les listes ayant obtenu plus de 2 % des suffrages au total, plus celle ayant le plus de voix parmi les listes en dessous de 2 %), ainsi qu'entre les listes indépendantes ayant obtenu 4 % ou plus. La coalition ou la liste arrivée en tête obtient au minimum 55 % des sièges (340 parmi les 617), les 45 % restants étant répartis à la proportionnelle dans les circonscriptions. Aux élections générales italiennes de 2006, deux grandes coalitions, L'Union et la Maison des libertés, ont polarisé à elles seules 99,5 % des suffrages exprimés. L'Union, avec 49,81 % des voix, a obtenu 340 sièges, tandis que la Casa delle libertà en a eu 277 pour 49,74 % des voix : le principe de la finalité majoritaire a effectivement été atteint, et ce malgré la très courte avance de la première coalition sur la seconde, mais cela ne garantit pas la gouvernabilité.

La France recourt à des systèmes mixtes pour les élections municipales dans les communes de plus de depuis 1983, et pour les élections régionales depuis 2004. Les électeurs votent pour des listes bloquées. Lors du premier tour, si une liste obtient la majorité absolue des suffrages exprimés, elle reçoit la moitié des sièges à pourvoir (un quart dans le cas des élections régionales), et la moitié restante est répartie entre toutes les listes à la représentation proportionnelle. Sinon, un second tour de scrutin est organisé, auquel ne sont admises que les listes ayant rassemblé au moins 10 % des suffrages exprimés au premier tour (celles qui ont eu au moins 5 % peuvent fusionner avec celles passant au second tour). La liste ayant eu le plus de voix à l'issue de ce second tour obtient la prime majoritaire (50 % pour les élections municipales dans les communes de plus de 3500 habitants, et 25 % pour les élections régionales) et les sièges restants sont répartis entre toutes les listes à la proportionnelle. La répartition à la proportionnelle ne s'opère en outre que sur la base des listes ayant obtenu au moins 5 % des suffrages exprimés (pour les répartitions au premier comme au second tour).

Depuis que ce mode de scrutin est en vigueur, tous les conseils régionaux français (exception faite de l'assemblée territoriale de Corse qui utilise un système légèrement différent) disposent d'une majorité claire, de droite ou de gauche, ce qui n'était pas le cas avant, avec une répartition de tous les sièges à la RP. Les minorités sont généralement représentées, surtout à l'issue d'un second tour. La loi municipale a toutefois tendance à marginaliser l'opposition. L'Italie utilise un système légèrement différent pour ses élections municipales et provinciales, depuis 1993 : les électeurs votent à la fois pour un candidat à la mairie et pour une liste pour le conseil municipal. Finalement, les listes ayant soutenu le candidat vainqueur se partagent 60 % des sièges, les 40 % restants étant répartis à la proportionnelle entre les autres listes (et seulement elles).

Le vote a été utilisé comme un élément essentiel de la démocratie depuis le , lorsque la démocratie a été instaurée dans la ville grecque d’Athènes. Les magistrats étaient alors tirés au sort parmi les habitants bénéficiant du statut de citoyen (soit une minorité élitiste de la population) : l'arbitraire était la règle et il n'était donc pas nécessaire de faire voter un quelconque corps électoral. Par contre, Athènes pratiquait aussi l'ostracisme, qui permettait d'exclure de la ville un citoyen donné par le biais d'un vote plural. Sous la République romaine, en revanche, les magistrats étaient élus au suffrage censitaire par un corps électoral très restreint, pour un mandat d'un an, au scrutin majoritaire. Les magistratures étaient hiérarchisées et il était impossible d'accéder à une magistrature donnée sans avoir déjà officié dans la ou les magistrature(s) inférieure(s). Ce système était de fait réservé à la riche élite romaine, qui pouvait se permettre une carrière politique longue, complexe et coûteuse. La plupart des élections du début de l'histoire de la démocratie ont été organisées selon ces deux principes, mais l’État de Venise au a fait exception : on sait maintenant qu’on y utilisait un système de vote d’approbation pour l'élection du Grand Conseil.

Le système d'élection du Doge vénitien est un processus particulièrement tortueux, composé de cinq tours de tirage au sort et de cinq tours de vote d'approbation. Par tirage au sort, un corps de 30 électeurs est désigné, et est ensuite ramené à 9 électeurs par tirage au sort à nouveau. Le collège électoral de 9 membres élit ensuite 40 personnes par un vote d'approbation ; ces 40 élus formeront ensuite un deuxième collège électoral de 12 membres désignés par tirage au sort parmi eux. Le deuxième collège électoral est composé de 25 personnes élues au terme d’un vote d’approbation, puis de 9 membres désignés par tirage au sort. Le troisième collège électoral a lui élu 45 personnes, qui seront réduites à former un quatrième collège électoral de 11 personnes choisies par tirage au sort. Ils éliront à leur tour un dernier corps électoral de 41 membres, qui seront finalement chargés d’élire le Doge. En dépit de sa complexité, ce système a certaines propriétés intéressantes, en veillant à ce que le gagnant reflète les opinions de la majorité et celles des factions minoritaires. Ce processus a été utilisé avec peu de modifications depuis 1268 jusqu'à la fin de la République de Venise en 1797, et a été l'un des facteurs contribuant à la continuité de la République vénitienne.

La théorie du vote est devenue un objet d'étude universitaire à l'époque de la Révolution française. Jean-Charles de Borda a proposé en 1770 une méthode d'élection des membres de l'Académie des Sciences. Son système a été contesté par le marquis de Condorcet, qui propose plutôt la méthode de comparaison par paires qu'il avait conçue. Les systèmes électoraux découlant de cette dernière méthode sont appelés « méthodes Condorcet ». Le marquis a aussi développé des théories sur le paradoxe de Condorcet, qu'il appelait "l’intransigeance des préférences de la majorité".
Alors que Condorcet et Borda sont généralement considérés comme les pères fondateurs de la théorie du vote, des recherches récentes ont montré que le philosophe Ramon Llull avait découvert à la fois la méthode Borda et une méthode qui satisfait aux critères de Condorcet au . Les manuscrits dans lesquels il a décrit ces méthodes avaient été oubliés par l’histoire, jusqu'à leur redécouverte en 2001.

Plus tard, au , le sujet de la répartition a commencé à être étudié. L'impulsion pour la recherche sur les méthodes de répartition équitable est venue, en effet, de la Constitution des États-Unis, qui précise que les sièges à la Chambre des représentants doivent être répartis entre les États proportionnellement à leur population, mais sans préciser comment. Diverses méthodes ont été proposées par des hommes d’État, tels Alexander Hamilton, Thomas Jefferson, ou encore Daniel Webster. Certaines des méthodes de répartition découvertes aux États-Unis ont été redécouvertes en Europe au , en même temps qu’étaient mis au point les systèmes de représentation proportionnelle. Plusieurs méthodes identiques ont ainsi des noms différents : la méthode de Sainte-Laguë est également appelée méthode de Webster.

La même situation a pu être observée pour le scrutin à vote unique transférable, qui a été conçu par Carl Andrae au Danemark en 1855, mais aussi en Angleterre par Thomas Hare en 1857. Leurs découvertes peuvent ou non avoir été indépendantes l’une de l’autre. Les premières élections recourant à ce système ont eu lieu au Danemark en 1856, puis en Tasmanie en 1896 après que son utilisation a été encouragée par Andrew Inglis Clark. La représentation proportionnelle a quant à elle commencé à se généraliser en Europe au début du , la Belgique étant la première à la mettre en œuvre en 1900. Depuis, les systèmes proportionnels ou mixtes sont utilisés dans une majorité de démocraties, les pays anglo-saxons faisant toutefois figure d’exceptions.

Peut-être influencés par l'évolution rapide des multiples méthodes consacrant plusieurs gagnants, les théoriciens ont commencé à publier de nouvelles conclusions sur les méthodes à un seul vainqueur à la fin du . Cela a commencé vers 1870, quand William Robert Ware a proposé d'appliquer un nouveau type de système à un seul vainqueur à des élections, proche du vote alternatif. Peu de temps après, des mathématiciens ont commencé à revoir les idées de Condorcet et à inventer de nouvelles méthodes pour compléter ses analyses. Edward John Nanson a ainsi combiné le nouveau vote alternatif à la méthode Borda dans le but de concevoir une nouvelle méthode de Condorcet appelée « méthode de Nanson ». Charles Dodgson, mieux connu sous le nom de Lewis Carroll, a publié des brochures sur la théorie du vote, en se concentrant en particulier sur les méthodes Condorcet. Il a introduit l'utilisation de matrices de Condorcet pour analyser les élections, bien que cela ait aussi déjà été présenté sous une certaine forme par Ramon Llull.

Des systèmes de vote à préférence multiple ordonnée ont plus tard été mis en application. En Australie, le vote alternatif a été adopté pour la première fois en 1893, et continue à être utilisé aujourd'hui. Aux États-Unis, au début du , plusieurs municipalités ont commencé à utiliser le "Bucklin vote", mais les résultats n'étaient pas satisfaisants pour les électeurs. Ce système n’est plus du tout utilisé depuis, et a même été déclaré inconstitutionnel dans le Minnesota.

Après que John von Neumann et d'autres chercheurs ont mis au point le domaine mathématique de la théorie des jeux dans les années 1940, de nouveaux outils mathématiques, visant à analyser les systèmes de vote et leurs stratégies, font leur apparition. Cela a conduit à la découverte d'importants nouveaux résultats qui ont bouleversé le domaine de la théorie du vote. L'utilisation de critères mathématiques permettant d'évaluer les systèmes électoraux a été introduite par Kenneth Arrow, qui a démontré, avec son théorème d'impossibilité, que certains critères intuitivement désirables entraient aujourd'hui en contradiction, pointant du doigt les limites inhérentes aux différents théorèmes de vote.

Il est en effet impossible de dire que tel ou tel système de vote est LE système parfait, car certaines des caractéristiques, qui font qu'un système est bon, sont contradictoires. Si, par exemple, un candidat est extrêmement apprécié par la majorité des électeurs, mais aussi extrêmement haï par les autres, cela fait-il de lui un meilleur ou un pire candidat que celui qui serait modérément apprécié par tous ? Les systèmes électoraux ont chacun une vision différente de ce type de problème. Kenneth Arrow a reçu le prix de la Banque de Suède en sciences économiques en mémoire d'Alfred Nobel en 1972 pour avoir démontré, dans sa thèse de 1951, l'impossibilité de transformer des préférences individuelles en choix collectif sans violer au moins une des conditions suivantes : 

En fait, tous les différents systèmes violent de différentes façons ces conditions. Beaucoup trouvent que la méthode Condorcet reste suffisamment bonne, car elle ne viole que de façon mineure un critère parmi ceux jugés les moins importants. Le théorème d'Arrow est le plus cité comme résultat de l'étude du vote, s'inspirant de plusieurs résultats significatifs tels que le théorème de Gibbard-Satterthwaite, qui démontre que le vote stratégique est inévitable dans certaines circonstances communes.

L'utilisation de la théorie des jeux pour analyser les modes de scrutin a également conduit à des découvertes sur les effets stratégiques émergents de certains systèmes. La loi de Duverger, qui montre que le scrutin majoritaire à un tour conduit souvent à un système bipartite, en est un bon exemple. Des recherches approfondies sur les aspects du vote dans la théorie des jeux, menées par Steven Brams et Peter Fishburn, les ont conduits à définir et à promouvoir officiellement l'utilisation du vote par approbation en 1977. Bien que le vote par approbation ait déjà été utilisé auparavant, il n'avait pas été cité ou considéré comme un objet d'étude universitaire, en particulier parce qu'il viole l'hypothèse selon laquelle seules les méthodes dégageant un seul vainqueur sont fondées sur un classement préférentiel.

L'évolution politique constante des différents États pratiquant des élections poussent ceux-ci à modifier plus ou moins régulièrement leurs régimes électoraux. En fonction de la nature du régime, la préférence de celui-ci pour tel ou tel système peut varier. Dans une étude menée par André Blais et Louis Massicotte en 1997 sur 166 États, il a été mis en évidence que les modes de scrutins majoritaires à un tour et les différents systèmes de représentation proportionnelle sont les systèmes électoraux les plus couramment utilisés. Remarquons toutefois qu'en isolant les démocraties des autres formes de régimes, cette étude montre que la représentation proportionnelle est préférée par une majorité relative d'États (voir le tableau ci-dessous).

Une autre étude menée par David M. Farell en 2001, se concentrant sur 59 démocraties, peuplées d'au moins deux millions d'habitants et dont le degré de liberté politique atteint au moins 4.0 selon les critères de la "Freedom House annual survey" de 1999, offre des résultats différents. La représentation proportionnelle est cette fois utilisée par 49,2 % des États concentrant 18,4 % de la population totale concernée, tandis que les systèmes majoritaires à un et deux tours sont utilisés par 23,7 % des États pour 55,7 % de la population. Les systèmes mixtes sont quant à eux appliqués dans 27,1 % des États recouvrant 25,8 % de la population. On en déduit que près de la moitié des démocraties représentatives étudiées plébiscitent la RP tandis que les autres sont équitablement partagées entre systèmes majoritaires et mixtes, mais que les États fortement peuplés préfèrent encore les scrutins majoritaires (l'Inde et les États-Unis, notamment).

La théorie du vote est venue mettre l'accent sur les critères d'un système électoral presque autant que sur certains systèmes particuliers. Il est maintenant possible avec l'état des recherches de soutenir par un critère défini mathématiquement la plupart des descriptions d'un avantage ou d'une faiblesse dans un mode de scrutin. Des recherches récentes dans le domaine de la théorie du vote ont permis l'élaboration de nouveaux critères et de nouvelles méthodes de calcul visant à répondre à certains critères.

Parmi les éminents théoriciens de la théorie du vote contemporains, Nicolaus Tideman a officialisé les concepts stratégiques, tels que l'effet spoiler. Tideman a aussi conçu la méthode de classement par paires, une méthode Condorcet qui n'est pas soumise aux critères clones. Donald Gene Saari a quant à lui fait renaître l'intérêt pour les méthodes Borda avec les livres qu'il a publiés depuis 2001. Saari utilise des modèles géométriques de la position des systèmes électoraux pour promouvoir ses nouvelles méthodes.

La disponibilité accrue du traitement des données par ordinateur a encouragé la pratique de la méthode Condorcet avec rangement des paires par ordre décroissant, et des méthodes Schulze, qui permettent un classement des choix des plus populaires aux moins populaires.

L'avènement d'Internet a amplifié l'intérêt pour les systèmes électoraux. Contrairement à beaucoup d'autres domaines mathématiques, la théorie du vote est généralement assez accessible aux non-spécialistes, et de nouveaux résultats sont fréquemment découverts par des amateurs. C'est pourquoi de nombreuses découvertes récentes dans la théorie du vote proviennent non pas de documents publiés, mais de discussions informelles entre passionnés, sur des forums en ligne et des listes de diffusion.

L'étude des modes de scrutin a donné une nouvelle impulsion à l'idée de réforme électorale, plusieurs personnes proposant de remplacer les scrutins majoritaires par de nouvelles méthodes moins injustes. Diverses municipalités aux États-Unis ont commencé à adopter le vote alternatif dans les années 2000. La Nouvelle-Zélande a adopté la représentation proportionnelle pour les élections législatives en 1993 et le scrutin à vote unique transférable pour certaines élections locales en 2004. La province canadienne de Colombie-Britannique tiendra un deuxième référendum sur l'adoption du vote unique transférable courant 2008. La province de l'Ontario a quant à elle organisé un référendum le 10 octobre 2007, sur l'opportunité d'adopter un système mixte proportionnel/majoritaire (les électeurs rejetteront cette proposition très critiquée par une partie de la classe politique canadienne à 63 %). En outre, en septembre 2007, le Nouveau Parti démocrate uni de la Corée du Sud a commencé le premier à utiliser des systèmes de vote mobiles pour ses primaires présidentielles. Une gamme encore plus large de systèmes de vote est maintenant diffusée dans les organisations non gouvernementales.

Les différents systèmes électoraux possèdent certains avantages et certains inconvénients. Pour déterminer le système de vote qui correspond le mieux à l'objectif de l'organisateur, ont été précisés des critères de systèmes de vote. Ils permettent de faciliter le choix de l'organisateur mais il n'existe aucun système de vote vérifiant tous les critères inventoriés.

La recherche d'un système juste (et donc, a priori, proportionnel) repose sur sa capacité à transposer efficacement les voix en sièges. D'après Pierre Martin, la justice d'un système électoral doit être appréciée sur la base de trois critères : l'indice de représentativité, la monotonie et la disproportionnalité.

L"indice de représentativité" est le rapport entre les électeurs effectivement représentés, c'est-à-dire ayant voté pour un candidat élu ou pour une liste ayant reçu des sièges, et l'ensemble des électeurs. Reprenons les résultats fictifs utilisés précédemment :

Si le mode de scrutin employé est de type majoritaire à un tour, seul le candidat du Parti A sera élu (ou seule sa liste aura des sièges). La représentativité du résultat est donc de 41,5 %. Si au contraire on répartit entre les différentes listes avec la méthode d'Hondt de la plus forte moyenne, A obtiendra quatre sièges, B trois, C un et D aucun. La représentativité est ici de 92,4 %. Cet indice est très utile pour différencier un vrai système proportionnel d'un autre qui le serait par hasard, comme celui de la Chambre des représentants des États-Unis, où la répartition des sièges est très proche de celle des suffrages des électeurs. Pourtant ses membres sont tous élus au scrutin majoritaire uninominal à un tour. En réalité, la proportionnalité globale est forte mais l'indice de représentativité faible, ce qui permet de le différencier d'un véritable mode de scrutin proportionnel.

La "monotonie" d'un mode de scrutin correspond à sa capacité à respecter dans la répartition des sièges l'ordre dans lequel sont arrivés les différents partis en nombre de voix. Si tel parti obtient plus de voix qu'un autre, il apparaît juste que le premier obtienne plus de sièges que le second. L'exemple des élections législatives britanniques de 1951, abordé dans la partie sur les scrutins majoritaires, permet d'affirmer, par exemple, que le mode de scrutin uninominal majoritaire à un tour n'a pas du tout été monotone. Notons enfin qu'il est bien plus grave d'inverser l'ordre en sièges par rapport à l'ordre en voix pour les grands partis que pour les partis plus petits.

La "disproportionnalité" d'un système à une élection a été pour la première fois mesurée par des indices mis au point en 1882 par Victor D'Hondt puis en 1910 par André Sainte-Laguë. Le premier proposa de mesurer le maximum du rapport entre la proportion des sièges et la proportion des voix d'un même parti, tandis que le second proposa de calculer la somme, sur l'ensemble des partis, des carrés des différences entre la proportion de sièges reçus et celle des votes obtenus. Pour D'Hondt, il s'agissait d'abaisser le rapport maximum entre la proportion des sièges et celle des voix, et pour Sainte-Laguë, il fallait chercher à minimiser l'écart entre ces deux proportions.

Admettons que dans notre exemple évoqué précédemment, les Partis A et B ne forment plus qu'un seul parti, même chose pour C et D. On obtiendrait alors les résultats suivants dans une circonscription donnée : 73,7 % pour le Parti AB et 26,3 % pour le Parti CD. Si deux sièges sont à pourvoir, la méthode d'Hondt les attribuera tous les deux au Parti AB, tandis que la méthode de Sainte-Laguë en donnera un à chacun des deux partis. Dans le premier cas, la représentativité est de 73,7 % et dans le second, elle est évidemment de 100 %. Par contre la méthode d'Hondt s'avère être plus monotone. Ces deux méthodes correspondent en fait à deux visions bien différentes de la disproportionnalité : la méthode d'Hondt cherche à éviter que beaucoup d'électeurs soient représentés par peu d'élus, tandis que celle de Sainte-Laguë tente de remédier au problème des électeurs non représentés. D'autres indices ont été proposés depuis, le plus abouti étant pour l'instant celui des moindres carrés de M. Gallaguer :

formula_1
Où V et S représentent respectivement la part de voix et la part de sièges obtenues par chaque parti i.

De manière générale, lorsqu'un seul siège est à pourvoir dans une même circonscription, plusieurs correspondances entre les modes de scrutin peuvent logiquement être observées. Par exemple, la représentation proportionnelle appliquée dans ce cas de figure se mue en scrutin majoritaire uninominal, avec des propriétés différentes en fonction du système de calculs utilisé. De la même façon, un mode de scrutin plurinominal devient de facto uninominal en pareilles circonstances.

Les scrutins uninominaux correspondent donc à la fois à l'application la moins proportionnelle des systèmes proportionnels, et l'application la moins majoritariste des systèmes majoritaires. C'est la magnitude minimum, réduite à 1, qui provoque pareil phénomène. Le tableau suivant permet d'y voir plus clair :

En passant de la première à la seconde colonne, on est dans une logique majoritaire, mais la proportionnalité augmente au fur et à mesure que la magnitude diminue. En passant de la seconde à la troisième colonne, on passe dans une logique proportionnelle, et pourtant la proportionnalité diminue en même temps que la magnitude diminue. On en déduira :
Ces quatre remarques démontrent que si les modes de scrutin sont tous très variés et très différents les uns des autres, ils convergent au fond vers le même objectif, élire des représentants pour former une majorité et soutenir un gouvernement.

Les défenseurs de la représentation proportionnelle défendent généralement la justice de ce système électoral, qui permet une représentation plus ou moins exacte en sièges du poids en voix d'un parti ou d'une coalition politique. Face à cet argument de bon sens, les partisans des scrutins majoritaires insistent souvent sur la nécessité d'accorder au régime politique une stabilité indispensable à sa continuité. Cela les amène dès lors à affirmer que le mode de scrutin influence directement l'électorat, notamment via le principe du « vote utile ». En avantageant les grands partis lors de la répartition des sièges et en permettant, en principe, au parti ayant rassemblé le plus de voix d'obtenir une majorité absolue de représentants, les scrutins majoritaires aboutissent à la formation d'un gouvernement unicolore logiquement plus stable qu'un gouvernement de coalition.

Pour les défenseurs des scrutins majoritaires, le système politique idéal serait un système bipartisan, avec une alternance politique possible uniquement entre deux grands partis, l'un ou l'autre disposant d'une majorité absolue de représentants au parlement. Les pays anglo-saxons, et tout particulièrement les États-Unis, ont plus ou moins réalisé cet idéal. À l'inverse, pour les partisans de la représentation proportionnelle, un bon système politique est un système au sein duquel les sièges au parlement, mais aussi le pouvoir sont partagés, en encourageant la formation de gouvernements de coalition. L'Allemagne et les pays scandinaves sont sans aucun doute les meilleurs exemples de ce type de système, avec en plus une tendance à la bipolarisation des forces politiques permettant une véritable alternance gouvernementale.

Dans d'autres pays, le principe de la coopération a été poussé à son paroxysme, comme la Suisse de 1919, date de l'instauration d'un système proportionnel, au 13 décembre 2007, date à laquelle l'Union démocratique du centre est passée dans l'opposition. Les principaux partis suisses se sont en effet très tôt mis d'accord pour se partager systématiquement les responsabilités gouvernementales. Cela a eu pour conséquence l'effondrement de la participation électorale à environ la moitié des électeurs inscrits, les élections n'ayant plus pour réel objectif que de tester la légitimité des différents partis au pouvoir. Même scénario au Liechtenstein, où les deux partis représentés au parlement se partagent le pouvoir depuis 1938, le plus fort obtenant le poste de chef du gouvernement et un plus grand nombre de ministères. On remarquera au passage que le nombre de partis représentés influence grandement les enjeux de cette stratégie de partage du pouvoir. On ne peut également s'empêcher de constater que, comme cela a été le cas en Autriche et en Suisse récemment, une radicalisation des partis de droite peut aboutir à une percée électorale de ces derniers et à un bouleversement brutal du mode de fonctionnement du système politique. Le retour à l'alternance bipolaire en Autriche a toutefois contribué à la régression de l'extrême droite à partir de 2002.

La représentation proportionnelle n'est donc pas synonyme d'instabilité ministérielle ni même de morcellement du paysage politique. Comme cela a été vu précédemment, il en va de même pour les scrutins majoritaires, qui ne garantissent pas forcément une forte polarisation politique et une bonne stabilité ministérielle. C'était même tout à fait l'inverse en France sous la Troisième République. Dans un cas de figure comme dans l'autre, les modes de scrutin produisent en réalité des effets qui dépendent largement de la nature du système politique dans le pays au sein duquel ils sont utilisés.

Au-delà des problèmes de justice de la représentation électorale et des préoccupations liées à la stabilité gouvernementale, on constate souvent que les défenseurs de la représentation proportionnelle d'une part, des scrutins majoritaires d'autre part, ont deux conceptions bien différentes de la vie politique. Les scrutins majoritaires correspondent en effet à des logiques d'affrontement tandis que les scrutins proportionnels sont plus tournés vers la coopération. Dans n'importe quel système politique démocratique, les phénomènes d'affrontement et de coopération sont présents, mais on constate que dans la grande majorité des cas, le mode de scrutin amplifie l'un ou l'autre de ces phénomènes. C'est donc aussi l'influence du mode de scrutin sur le système politique qui va déterminer les contours du débat tournant autour de cette question dans une démocratie représentative donnée.

Les analystes de la politique, au fur et à mesure que la diversité des modes de scrutin s'amplifiait, ont fini par noter que ces derniers ont des effets sur le système politique qui transcendent largement la transformation des voix en sièges. Les stratégies des différentes formations politiques concurrentes et le comportement des électeurs jouent également des rôles pouvant être déterminants.

Le politologue Maurice Duverger a synthétisé l'ensemble de ces analyses et en a conclu qu'elles répondent à trois « lois » fondamentales :

Duverger a donc présenté les systèmes partisans comme une simple production des modes de scrutin. Ses conclusions ont été vivement critiquées par plusieurs autres analystes politiques. À titre d'exemple, Georges Lavau pense au contraire que la sociologie et l'histoire d'un pays influencent eux aussi considérablement son système politique, le mode de scrutin n'occupant qu'une place secondaire au sein des facteurs explicatifs. L'entretien du débat a ensuite amené Duverger à nuancer ses propos. De manière générale, les caractères des systèmes partisans répondent aux logiques évoquées par ces deux analyses.

On a parfois tendance à surestimer l'influence des systèmes électoraux d'un pays sur son système partisan. S'il paraît évident que la justice plus ou moins grande de la représentation des différentes forces politiques qu'ils permettent a un réel impact sur la composition politique des assemblées et sur les systèmes d'alliances des partis politiques, les modes de scrutin n'influencent jamais directement la structuration des systèmes partisans. Quant à la répartition des votes, cette influence est souvent trop faible pour être déterminante. Comme l'a justement affirmé Pierre Martin, « les modes de scrutins peuvent fabriquer des majorités parlementaires, pas des systèmes partisans », allant ainsi à l'encontre de l'opinion de nombreux défenseurs des systèmes majoritaires.

D'après Arend Lijphart, il est plus exact de parler de correspondances entre les systèmes partisans et les systèmes électoraux, plutôt que d'affirmer que les seconds conditionnent les premiers. Par exemple, le scrutin majoritaire uninominal à un tour correspond souvent à des systèmes bipartisans, tandis que les systèmes majoritaires à préférences multiples ordonnées ou à deux tours font intervenir le jeu des alliances entre les partis, correspondant donc plutôt à des systèmes bipolarisés. Dans le premier cas, les alliances électorales prennent la forme de répartitions de candidats de différents partis, membres d'une même alliance, dans différentes circonscriptions. Dans le second cas, des accords de désistements entre candidats membres de partis alliés sont passés entre les deux tours, en plus du système de répartition de circonscriptions dès le premier tour. Les systèmes proportionnels, bien moins contraignants, amènent les différents partis politiques, même s'ils sont alliés, à se présenter séparément devant les électeurs (exception faite du système de Hare). Les exemples illustrés ci-contre permettent de valider cette analyse tout en y apportant une contradiction avec l'exemple espagnol.

L'impact des systèmes électoraux sur la stabilité d'un système politique donné ne va pas non plus de soi. "Les scrutins majoritaires allant forcément de pair avec la stabilité gouvernementale et les scrutins proportionnels allant systématiquement dans le sens inverse" est un raisonnement faux qui a déjà été contredit par l'histoire d'innombrables fois. La stabilité ministérielle dépend bien plus de la structuration idéologique du système partisan et de certaines règles du parlementarisme, comme le montrent particulièrement bien les exemples français et italiens. À la fin de la Troisième République française, l'instabilité ministérielle était devenue la règle, alors que les députés étaient tous élus au scrutin majoritaire uninominal à deux tours (exception faite de courtes périodes au cours desquelles ont été utilisés des systèmes mixtes, comme en 1919). La situation était en tous points comparable à celle de la Quatrième République qui lui succèdera, alors que les membres de l'Assemblée nationale étaient élus à la représentation proportionnelle puis via un système mixte à partir de 1951. Le mode de scrutin n'a donc en aucun cas été un facteur déterminant de l'inefficacité de ces régimes. La puissance du Parti communiste français, alors aligné sur la politique de l'URSS de Staline, sous la Quatrième République permet en outre de douter que le scrutin majoritaire eut été vraiment apte à garantir un bon fonctionnement du régime, en donnant, par exemple, une majorité de députés au PCF. La proportionnelle intégrale en vigueur sous la République allemande de Weimar a également longtemps empêché les nazis de devenir majoritaires au Reichstag, malgré leurs excellents résultats électoraux au début des années 1930. On peut dans ces conditions difficilement affirmer qu'un système soit forcément meilleur qu'un autre.

En revanche, il est important de noter, comme le souligne Pierre Martin, que les systèmes majoritaires correspondent à des systèmes politiques valorisant la concurrence et l'affrontement, tandis que les systèmes proportionnels correspondent plutôt à des systèmes politiques valorisant la coopération, sans pour autant être incompatibles avec des systèmes politiques bipolarisés (Suède, Danemark). À titre d'exemple, le choix de la représentation proportionnelle par l'Afrique du Sud à partir de 1994 correspondait à un souhait de formation d'un gouvernement d'union nationale. Au sortir de l'apartheid, ce pays avait besoin d'un système favorisant la coopération plutôt que le conflit.




Fondements :

Procédures électorales :

Autres systèmes de vote :

Scrutins visant à l’approbation ou au rejet d’une option prédéterminée :
Ce type de scrutin doit, pour fonctionner, être combiné à une procédure pour construire et sélectionner l'option à soumettre. Cela le fait parfois considérer comme moins démocratique, en raison des contraintes pesant sur le choix. 

Théoriciens des systèmes électoraux :






</doc>
<doc id="2770" url="https://fr.wikipedia.org/wiki?curid=2770" title="Sigmund Freud">
Sigmund Freud

Sigmund Freud (prononciation allemande : ; prononciation française ou ), né Sigismund Schlomo Freud le à Freiberg (Autriche) (actuelle République tchèque) et mort le à Londres, est un neurologue autrichien, fondateur de la psychanalyse.

Médecin viennois, Freud rencontre plusieurs personnalités importantes pour le développement de la psychanalyse, dont il est le principal théoricien. Son amitié avec Wilhelm Fliess, sa collaboration avec Josef Breuer, l'influence de Jean-Martin Charcot et des théories sur l'hypnose de l'École de la Salpêtrière vont le conduire à repenser les processus psychiques. Ses deux grandes découvertes sont la sexualité infantile et l'inconscient. Elles le conduiront à élaborer plusieurs théorisations des instances psychiques, en premier lieu avec les concepts d'inconscient, de rêve et de névrose, puis il proposera une technique de thérapie, la cure psychanalytique, qu'il définit pour la première fois en 1904. C'est dans le cadre de la cure, dès les "Études sur l'hystérie", et particulièrement dans sa première analyse du « cas Dora », que Freud découvre peu à peu l'importance du transfert.

Freud regroupe une génération de psychothérapeutes qui, peu à peu, élaborent la psychanalyse, d'abord en Autriche, en Suisse, à Berlin, puis à Paris, Londres et aux États-Unis. En dépit des scissions internes et des critiques, la psychanalyse s'installe comme une nouvelle discipline des sciences humaines dès 1920. En 1938, Freud, menacé par le régime nazi, quitte Vienne pour s'exiler à Londres, où il meurt d'un cancer de la mâchoire en 1939.

Le terme de « psycho-analyse » apparaît pour la première fois en 1896 dans un article écrit en français, publié dans cette langue le 30 mars 1896, puis en allemand le 15 mai 1896. Mais « les deux articles furent expédiés le même jour », le 5 février 1896. La psychanalyse repose sur plusieurs hypothèses et concepts élaborés ou repris par Freud. « Ce qui caractérise la psychanalyse, en tant que science, c’est moins la matière sur laquelle elle travaille, que la technique dont elle se sert ». La technique de la cure, dès 1898 sous la forme de la méthode cathartique, avec Josef Breuer, puis le développement de la cure analytique, est le principal apport de la psychanalyse. L'hypothèse de l'inconscient approfondit la théorisation du psychisme. D'autres concepts vont, peu à peu, développer et complexifier la théorie psychanalytique, à la fois science de l'inconscient et savoir sur les processus psychiques et thérapeutiques.

L'histoire de la vie de Freud (prononciation allemande : [] ; prononciation française [] ou []) est celle de la psychanalyse. Elle a fait l'objet de nombreux articles et biographies dont la plus connue est celle d'Ernest Jones ("La vie et l'œuvre de Sigmund Freud", 1953 à 1958), proche contemporain de Freud. Le premier biographe fut cependant Fritz Wittels, qui publie en 1924 "Freud. L'homme, la doctrine, l'école". L'écrivain Stefan Zweig a aussi écrit une biographie ("La Guérison par l'esprit", 1932). Le médecin de Freud, Max Schur, devenu psychanalyste, a analysé son rapport à la mort, dans la clinique et la théorie puis face à la maladie qui devait l'emporter en 1939 ("La Mort dans la vie et l'œuvre de Freud", 1972).

De nombreux contemporains ou disciples lui ont également consacré une biographie, souvent hagiographique, tels Lou Andreas-Salomé, Thomas Mann, Siegfried Bernfield, Ola Andersson, Kurt Robert Eissler, Carl Schorske. Didier Anzieu a publié une biographie ("L'auto-analyse de Freud et la découverte de la psychanalyse", 1998) très détaillée de l'auto-analyse de Freud et du processus créatif qui en a découlé. Marthe Robert est l'auteur d'une biographie littéraire ("La Révolution psychanalytique", 2002). Peter Gay a écrit "Freud une vie" (1991). Henri Ellenberger a consacré une partie de son livre au devenir de certains des patients de Josef Breuer et de Freud dans "Histoire de la découverte de l'inconscient" (1970). Il est le premier à avoir insisté sur les légendes associées à l'histoire de la psychanalyse, parlant de ), arguant même qu'il faudrait, selon lui, développer une .

Les derniers ouvrages critiques édités ont pour auteurs : Mikkel Borch-Jacobsen et Sonu Shamdasani ("Le Dossier Freud. Enquête sur l'histoire de la psychanalyse", 2006), Jacques Bénesteau ("Mensonges freudiens. Histoire d'une désinformation séculaire", 2002) ou encore le philosophe Michel Onfray ("Le crépuscule d'une idole", 2010). Dans le même temps, Alain de Mijolla analyse dans "Freud et la France, 1885-1945" (2010) les relations complexes entre Freud et les intellectuels français jusqu'en 1945. En 2014, Élisabeth Roudinesco a publié une biographie de Freud intitulée "Sigmund Freud en son temps et dans le nôtre".

Il naît le 6 mai 1856. L'histoire de sa famille, originaire de Galicie, est peu connue. Troisième fils de Jakob Freud, négociant, certainement marchand de laine, et d'Amalia Nathanson (1836-1931), il est le premier enfant de son dernier mariage. Sigmund est l'aîné de sa fratrie, composée de cinq sœurs (Anna, Rosa, Mitzi, Dolfi et Paula) et de deux frères, Julius, mort dans sa première année de vie, et Alexander.

Selon Henri Ellenberger, . Sa famille suit ainsi la tendance à l'assimilation qui est celle de la plupart des juifs viennois, en effet, il n'est pas élevé dans le strict respect de l'orthodoxie juive. Bien que circoncis à la naissance, son éducation n'est pas traditionaliste et est ouverte à la philosophie des Lumières. Il parle l'allemand, le yiddish et semble connaître l'espagnol à travers un dialecte mêlé d'hébreu alors couramment employé dans la communauté séfarade de Vienne, bien qu'il fût lui-même ashkénaze.

Il passe ses trois premières années à Freiberg, ville que sa famille quitte d'abord pour Leipzig, avant de s'établir définitivement, en février 1860, dans le quartier juif de Vienne. Freud y réside jusqu'à son exil forcé à Londres en 1938, après l'anschluss . De 1860 à 1865, les Freud déménagent à plusieurs reprises, pour s'installer enfin dans la Pfeffergasse, dans le quartier de Leopoldstadt.
Recevant ses premières leçons de sa mère puis de son père, il est d'abord envoyé dans une école privée, puis réussit à neuf ans, l'épreuve d'admission au gymnase de Leopoldstadt. Brillant élève, il est le premier de sa classe pendant ses sept dernières années de scolarité secondaire au lycée communal, le « Sperlgymnasium ». Il a pour professeurs le naturaliste Alois Pokorny, l'historien Annaka, le professeur de religion juive Samuel Hammerschlag et le politicien Victor von Kraus. Il obtient la mention « excellent » à son examen de maturité en 1873. Après avoir brièvement incliné vers le droit sous l'influence d'un de ses amis, Heinrich Braun, il se montre ensuite plus intéressé par la carrière de zoologue après avoir écouté la lecture par Carl Brühl d'un poème intitulé "Nature", alors attribué à Goethe, lors d'une conférence publique. Cependant, il choisit la médecine et s'inscrit à l'université de Vienne à la rentrée d'hiver 1873. Il se passionne pour la biologie darwinienne qui sert de modèle à tous ses travaux.

Il obtient son diplôme de médecin le 31 mars 1881 après huit années d'études, au lieu des cinq attendues, durant lesquelles il a effectué deux séjours en 1876 dans la station de zoologie marine expérimentale de Trieste, sous la responsabilité de Carl Claus, puis pour travailler de 1876 à 1882 auprès d'Ernst Wilhelm von Brücke, dont les théories rigoureusement physiologiques l'influencent.

Il entre en octobre 1876 en qualité de physiologiste-assistant à l'institut de physiologie d'Ernst Brücke, où il fait la connaissance de Sigmund Exner et de Fleischl von Marxow, et surtout de Josef Breuer. Freud concentre ses travaux sur deux domaines : les neurones (dont certaines assertions sont reprises dans l'article « Esquisse d'une psychologie scientifique ») et la cocaïne. Selon Alain de Mijolla, Freud découvre à ce moment les théories positivistes d'Emil du Bois-Reymond, dont il devient un adepte, et qui expliquent la biologie par des forces physico-chimiques dont les effets sont liés à un déterminisme rigoureux.

Il a profité de sa période de service militaire, en 1879-1880, pour commencer la traduction de travaux du philosophe John Stuart Mill et approfondir sa connaissance des théories de Charles Darwin. Il assiste aux cours de Franz Brentano et lit "Les Penseurs de la Grèce" de Theodor Gomperz et surtout les volumes de l’"Histoire de la civilisation grecque" de Jacob Burckhardt. Il passe ensuite ses premiers examens en juin 1880 et en mars 1881 et obtient son diplôme le 31 mars 1881, devenant alors à titre temporaire préparateur dans le laboratoire de Brücke. Il travaille ensuite deux semestres dans le laboratoire de chimie du professeur Ludwig. Il poursuit ses recherches histologiques, et se montre impressionné par les démonstrations du magnétiseur danois Carl Hansen auxquelles il assiste en 1880.

Le 31 juillet 1881 il est recruté comme assistant chirurgien auprès de Theodor Billroth à l’hôpital général de Vienne ; il n'occupe ce poste que durant deux mois.

En juin 1882, il s'installe comme médecin praticien, sans grand enthousiasme toutefois. Deux explications existent sur ce point. Selon Freud lui-même, Brücke lui a conseillé de commencer à pratiquer en hôpital pour se faire une situation alors que pour Siegfried Bernfeld et Ernest Jones, ses biographes, c'est son projet de mariage qui l'oblige à renoncer au plaisir de la recherche en laboratoire. Sigmund Freud a en effet rencontré Martha Bernays, issue d'une famille commerçante juive, en juin 1882, et, très tôt les conventions familiales alors en vigueur obligent les deux fiancés à se marier, d'autant plus que leur situation financière est très précaire. Néanmoins, le jeune couple ne se marie qu'en 1886, Freud ayant conditionné son alliance avec Martha Bernays à l'obtention de son cabinet de consultation. En octobre 1882, il entre dans le service de chirurgie de l'hôpital de Vienne, alors l'un des centres les plus réputés du monde. Après deux mois, il travaille comme aspirant, sous la responsabilité du médecin Nothnagel et ce jusqu'en avril 1883. Il est nommé le mai 1883 "" au service de psychiatrie de Theodor Meynert dans lequel il poursuit des études histologiques sur la moelle épinière, jusqu'en 1886.

En septembre 1883, il entre dans la quatrième division du docteur Scholtz. Il y acquiert une expérience clinique auprès de malades nerveux. En décembre de la même année, à la suite de la lecture d'un article du docteur Aschenbrandt, il se livre à des expériences sur la cocaïne et en déduit qu'elle a une efficacité sur la fatigue et les symptômes de la neurasthénie. Dans son article de juillet 1884, , il conseille son usage pour de multiples troubles.<br>

Freud, à la suite de la lecture d'un texte qui propose de traiter la morphinomanie par la cocaïne, traite son ami et collègue au Laboratoire de Physiologie Ernst Fleischl von Marxow: celui-ci était devenu morphinomane après avoir eu recours à la morphine pour calmer la douleur insupportable occasionnée par une blessure à la main qui s'était infectée et du névrome qui s'y était développé. Freud, qui avait découvert la cocaïne en 1884, tenta de guérir son ami de sa morphinomanie en lui conseillant de prendre de la cocaïne, mais Fleischl . Il mourut en 1891 très détérioré physiquement et mentalement. L'administration locale de la cocaïne était une méthode à laquelle recourait Fliess pour soigner les affections nasales. Didier Anzieu note le sentiment de culpabilité de Freud lié à la personne de Fleischl, dont et qui reviendra dans plusieurs rêves de "L'Interprétation du rêve" comme « L'injection faite à Irma », la « Monographie botanique », le rêve « Non vixit »...
Bien qu'il l'ait nié publiquement à de nombreuses reprises, Freud fut consommateur de cocaïne entre 1884 et 1895, comme en atteste sa correspondance. Il travaille sur sa découverte avec Carl Koller, qui mène alors des recherches sur un moyen d'anesthésier l'œil en vue de pratiquer des opérations peu invasives. Celui-ci informe ensuite Leopold Königstein qui applique cette méthode à la chirurgie. Tous deux communiquent leur découverte lors de la Société des médecins de Vienne en 1884, sans mentionner la primauté des travaux de Freud.

Le jeune médecin est ensuite affecté au service d'ophtalmologie de mars à mai 1884, puis dans celui de dermatologie. Il y rédige un article sur le nerf auditif qui reçoit un accueil favorable. En juin, il passe l'examen oral pour le poste de "Privat-docent", et y présente son dernier article. Il est nommé le 18 juillet 1885 et, voyant sa demande de bourse de voyage acceptée, il décide d'aller étudier à Paris, auprès de Jean-Martin Charcot. Après six semaines de vacances auprès de sa fiancée, Freud s'installe donc dans cette ville. Admirateur du neurologue français, qu'il rencontre la première fois le 20 octobre 1885, il lui propose de traduire ses écrits en allemand. Dès lors, Charcot le remarque et l'invite à ses somptueuses soirées du faubourg Saint-Germain. Cependant, il semble que Freud n'ait pas passé autant de temps qu'il le dit auprès de Charcot, puisqu'il quitte Paris le 28 février 1886 ; il en retire néanmoins toujours de la fierté et fait de ce séjour à Paris un moment clé de son existence. Il reste en outre en contact épistolaire avec le Français.

En mars 1886, Freud étudie la pédiatrie à Berlin, avec Baginsky, et revient finalement à Vienne en avril. Il rédige son rapport sur l'hypnotisme, tel qu'il est pratiqué par l'École de la Salpêtrière, devant les membres du Club de physiologie et devant ceux de la Société de psychiatrie, tout en organisant les préparatifs de son mariage. Un article d'Albrecht Erlenmeyer le critique vivement quant aux dangers de l'usage de la cocaïne. Freud finit de traduire un volume des leçons de Charcot, qui paraît en juillet 1886 et dont il rédige la préface. Après quelques mois de service militaire à Olmütz comme médecin de bataillon, Freud épouse Martha Bernays le 13 octobre 1886, à Wandsbek ; ils passent leur voyage de noces sur la mer Baltique. Dès son retour à Vienne, Freud aménage son cabinet dans l' (« Premier institut public des malades pour des enfants ») et travaille parallèlement de 1886 à 1896 avec l'Institut Max-Kassowitz, un hôpital pédiatrique privé où il est affecté au service neurologique.

Le 15 octobre 1886, devant la Société des médecins de Vienne, Freud fait une allocution concernant l'hystérie masculine, discours publié sous le titre de . Ce thème est alors polémique, d'autant plus que la conception classique de Charcot oppose l'hystérie post-traumatique à une hystérie dite simulée. S'appuyant sur la distinction entre « grande hystérie » (caractérisée par des convulsions et une hémianesthésie) et la « petite hystérie », et sur un cas pratique examiné à la Salpêtrière, Freud explique que l'hystérie masculine est plus fréquente que ce que les spécialistes observent habituellement. Pour Freud, la névrose traumatique appartient au champ de l'hystérie masculine. La Société s'insurge contre cette opinion qui est, de plus, déjà connue des neurologues viennois. Selon Ellenberger, l'idéalisation de Freud pour Charcot lui vaut l'irritation de la Société, agacée par son attitude hautaine. Blessé, Freud présente alors à la Société un cas d'hystérie masculine afin d'étayer sa théorie. La Société l'entend de nouveau, mais l’éconduit. Contrairement à une certaine légende autour de cet événement, Freud ne se retire pas de la Société ; il en devient même membre le 18 mars 1887.

Cette année-là, il fait la rencontre de Wilhelm Fliess, un médecin de Berlin qui poursuit des recherches sur la physiologie et la bisexualité, avec lequel il entretient une correspondance scientifique amicale, mais toutefois ambiguë. Par ailleurs, la famille Freud accumule les dettes, le cabinet médical n'attirant pas une abondante clientèle. De plus, Meynert se brouille avec Freud en 1889, à propos de la théorie de Charcot. En 1889, Freud se dit très seul ; il ne peut communiquer réellement qu'avec ses amis Josef Breuer et Jean Leguirec. Ainsi il écrit : . Freud et Martha ont six enfants : Mathilde (1887-1978), Jean-Martin (1889-1967), Oliver (1891-1969), Ernst (1892-1970), Sophie (1893-1920) et Anna Freud (1895-1982).<br>
À partir de ce moment, la pensée de Freud évolue: la fréquentation de l'école de Bernheim en 1889 va le détourner de Charcot. Freud se prononce contre une interprétation matérialiste de l'hypnose qu'il défend à l'encontre du dénigrement dont elle fait l'objet de la part de ses adversaires : il traduit l'ouvrage d'Hippolyte Bernheim, "De la suggestion et des applications thérapeutiques" et aborde la technique de l'hypnose. Il se rend à Nancy, à l'école de Bernheim, et rencontre Ambroise-Auguste Liébeault en 1889 pour confirmer son opinion sur l'hypnose. Il y apprend que les hystériques conservent une forme de lucidité envers leurs symptômes, savoir qui peut être mobilisé par l'intervention d'un tiers, une idée qu'il reprend ultérieurement dans sa conception de l'inconscient, mais il conclut que l'hypnose n'a que peu d'efficacité dans le traitement général des cas pathologiques. Il pressent que le passé du patient doit jouer un rôle dans la compréhension des symptômes. Il préfère la « cure par la parole » de son ami Breuer. Après cette visite, il participe, en juillet, au Congrès international de psychologie de Paris.

En 1891, Freud publie son travail sur les paralysies cérébrales unilatérales chez les enfants, en collaboration avec Oscar Rie, pédiatre viennois. Puis il travaille à son étude critique des théories sur l'aphasie, "Contribution à la conception des aphasies". Sa distance avec la pensée de Charcot y est maximale ; il y esquisse un « appareil de langage » (citation?) permettant de rendre compte des troubles de la fonction langagière. Ce modèle préfigure l'« appareil psychique » de la première topique. Freud relie l'inconscient au langage. En 1892, il édite sa traduction de l'ouvrage de Bernheim sous le titre "Hypnotisme, suggestion, psychothérapie : études nouvelles" et il expose devant le Club médical viennois une conception proche de Charcot.

En 1893, Freud publie plusieurs articles sur l'hystérie en collaboration avec Josef Breuer et en particulier l'essai "Le Mécanisme psychique des phénomènes hystériques (Communication préliminaire.)". Il y défend la conception névrotique de l'hystérie, tout en proposant . En 1894, avec son article « Névro-psychoses de défense », il se focalise sur la phobie. Il souffre de symptômes cardiaques et cesse de fumer. S'occupant de l'hystérie d'une patiente, nommée « Emma », Freud, influencé par la théorie de la bisexualité de Fliess, lui demande d'opérer la jeune femme du nez, car il pense que sa névrose y est liée. Mais Fliess oublie la gaze iodoformée dans le nez de la patiente. Freud fait ensuite un rêve marquant (le rêve dit de « L'injection faite à Irma ») qu'il relie à cet incident et entreprend d'en analyser le sens au moyen de la méthode de l'association libre ; .

En 1895, Breuer et Freud publient leur "Études sur l'hystérie" qui regroupent les cas traités depuis 1893, dont celui d'Anna O.. Cette patiente de Breuer, de son vrai nom Bertha Pappenheim, est présentée comme un exemple type de cure cathartique. Avant de devenir la cure psychanalytique au sens strict, Freud a en effet dû abandonner la suggestion et l'hypnose, puis la méthode cathartique de Breuer, et prendre en compte le transfert, c'est-à-dire la reviviscence des émois pulsionnels de l'enfance du patient refoulés qui sont déplacés et adressés à l'analyste. C'est en effet le transfert qui met Freud sur la voie d'une nouvelle approche, la reviviscence du vécu infantile refoulé qui anime le transfert informant sur la nature du conflit psychique dans lequel le patient est pris.

En 1896, considérant que sa théorie a droit de cité en psychologie, Freud la baptise du nom de « psycho-analyse », mais le facteur sexuel n'est pas alors encore prédominant dans celle-ci. Composé du grec "" (qui désigne la « remontée vers l'originaire », l'élémentaire), et de "lysis" (la « dissolution »), le terme désigne dès le départ la recherche des souvenirs archaïques en lien avec les symptômes. Dès lors, Freud rompt avec Breuer, demeuré fidèle à la cure cathartique, et rédige un essai laissé inédit : "Esquisse d'une psychologie scientifique". C'est dans un autre article, écrit en français : « L'hérédité et l'étiologie des névroses », de 1896, qu'il explique sa nouvelle conception. Enfin, il rédige (« L’Étiologie de l’hystérie »). Dans les deux articles apparaît pour la première fois sous la plume de Freud le mot « psychanalyse ».

Le 2 mai 1896, devant la Société de psychiatrie viennoise, présidée par Hermann Nothnagel et Krafft-Ebing, on lui délivre le titre d’« ' ». Lors du Congrès international de psychologie à Munich en août 1896, le nom de Freud est cité parmi les autorités les plus compétentes dans le domaine alors qu'en 1897 Albert Willem Van Renterghem, psychiatre néerlandais, le cite comme l'une des figures de l'École de Nancy.

Après la mort de son père, le 23 octobre 1896, Freud s'intéresse exclusivement à l'analyse de ses rêves et se livre à un . Nourrissant de la culpabilité envers son père, il entreprend une auto-analyse. Il dit tenter d'analyser sa et ambitionner de mettre à jour la nature de l'appareil psychologique et de la névrose. Lors de cette auto-analyse, et après avoir abandonné sa théorie de l'hystérie, ses souvenirs d'enfance affluent. Celui de sa nourrice lui permet de développer la notion de « souvenir écran » par exemple alors qu'il voit dans les sentiments amoureux pour sa mère et dans sa jalousie pour son père une structure universelle qu'il rattache à l'histoire d'Œdipe et d'Hamlet. Ses analyses de patients lui apportent des arguments dans l'édification d'une nouvelle conception, qui lui permet de revoir et l'hystérie et les obsessions. La correspondance avec Fliess témoigne de cette évolution de sa pensée ; c'est notamment dans une lettre du 15 octobre 1897 que Freud évoque pour la première fois le « complexe d'Œdipe ». Le neurologue viennois explique ainsi : .

Il annonce à Fliess, au début de l'année 1898, qu'il compte publier un ouvrage sur l'analyse des rêves, et, après une période de dépression, il publie "L'Interprétation du rêve" (). Il s'agit d'un ouvrage « autobiographique » dans la mesure où Freud se base en partie sur le matériel de ses propres rêves. Cette période d'auto-analyse mêlée de névrose est, selon Henri Ellenberger, caractéristique de la , phase de dépression et de travail intense qui a permis à Freud d'élaborer la psychanalyse en dépassant ses problèmes personnels. En novembre 1898, Freud se préoccupe des phases infantiles à dominante sexuelle dans son œuvre ("La sexualité dans l'étiologie des névroses"). Dans cet ouvrage, Freud utilise le terme de « psychonévrose » délimité de la « neurasthénie »

Sa situation, tant sociale que financière, s'améliore ; de 1899 à 1900, il exerce les fonctions d'assesseur de la de Londres en psychiatrie et neurologie pour la revue . Par ailleurs, il travaille intensément à ses recherches et se dépeint comme un « conquistador ». Il jouit en effet d'une clientèle lucrative et est reconnu par la société viennoise. En septembre 1901, il se sent capable de visiter Rome, en compagnie de son frère Alexander. La « Ville éternelle » l'a et Freud, en raison de sa phobie des voyages, a toujours remis à plus tard sa visite de l'Italie. À Rome, il est « impressionné » par le "Moïse" de Michel-Ange. Quelques années après, en 1914, il publie anonymement, dans la revue "Imago", un essai intitulé (« Le Moïse de Michel-Ange »), dans lequel il oppose les deux figures, celle historique et celle mythique, du libérateur du peuple juif, Moïse.

Lors d'un passage à Dubrovnik (alors Raguse), Freud suppose que le mécanisme psychique du lapsus est révélateur d'un complexe inconscient. La même année, deux psychiatres suisses, Carl Gustav Jung et Ludwig Binswanger de Zurich, se rallient à la psychanalyse naissante et, grâce à l'« école de Zurich », le mouvement s'amplifie en Europe et aux États-Unis. Auparavant, en 1901, Eugen Bleuler, avec qui Freud commence une correspondance, est extrêmement impressionné par "L'Interprétation des rêves". Il a en effet demandé à son second, Jung, de présenter l'ouvrage à l'équipe psychiatrique du Burghölzi. La Suisse devient ainsi une alliée de poids dans le développement du mouvement psychanalytique et ce dès 1900.

De retour à Vienne, Freud rompt tout échange avec Fliess en 1902. Puis, il présente ses opinions scientifiques au cours de plusieurs conférences, devant le de Vienne, puis devant le B'nai B'rith, un cercle de juifs laïcs ; elles sont bien accueillies. En automne 1902, sur l’initiative de Wilhelm Stekel, Freud réunit autour de lui un groupe d'intéressés, qui prend le nom de (« Société psychologique du mercredi ») et qui, chaque mercredi, discute de psychanalyse. Selon Ellenberger, à partir de cette date, la vie de Freud se confond avec l'histoire du mouvement psychanalytique. En France, ses travaux sont mentionnés lors du Congrès des médecins aliénistes et neurologistes de Grenoble la même année.

En 1904, il publie "Psychopathologie de la vie quotidienne". En septembre, il se rapproche d'Eugen Bleuler, de Zurich, et leur correspondance scientifique s'accroît. Les traitements engagés par Freud sur la base de ces hypothèses l'avaient déjà conduit à découvrir que tous ses patients n’ont pas subi de réels traumatismes sexuels dans leurs enfances : ils évoquent des fantasmes et racontent un « roman familial » auquel ils croient. Simultanément, il découvre que certains patients semblent ne pas pouvoir guérir. Ils résistent notamment en répétant et en transposant des sentiments anciens vers l'analyste : mécanisme que Freud appelle le « transfert » qu'il voit encore, et essentiellement, comme un frein à la guérison.

Freud parle de la psychanalyse pour la première fois publiquement en 1904, lors d'une série de conférences à l'université Clark à Worcester, Massachusetts, où il a été invité par Stanley Hall, en compagnie de Carl Gustav Jung, Ernest Jones et Sándor Ferenczi. Freud et Jung se voient honorés du titre de « LL. D. ». C'est à ce moment qu'il désigne explicitement Jung comme son . Freud déclare lors de cette conférence que le mérite de l'invention de la psychanalyse revient à Josef Breuer mais il précise par la suite qu'il considère que le « procédé cathartique » de Breuer constitue une phase préliminaire à l'invention de la psychanalyse et qu’il en est bien l’inventeur à partir du rejet de l’hypnose et de l’introduction de l’association libre.

En 1905, il publie "Trois essais sur la théorie sexuelle", qui rassemble ses hypothèses sur la place de la sexualité et son devenir dans le développement de la personnalité. La sexualité infantile constitue un élément important de la psychanalyse. Il publie également "Fragment d'une analyse d'hystérie", qui constitue un compte-rendu du cas d'Ida Bauer, qui illustre le concept de transfert psychanalytique.

Selon Ellenberger, Ilse Bry ou Alfred H. Rifkin, les idées de Freud ont été bien reçues. Pour Ernest Jones et, ultérieurement, Jean-Luc Donnet, c'est le contraire qui est vrai. Donnet précise que le rejet violent de la psychanalyse par les médecins et surtout par les psychiatres est l'une des causes du fait que Freud s'est tellement réjoui du ralliement d'Eugen Bleuler à la psychanalyse et, de fait, c'est à Zurich que la psychanalyse obtient en premier un droit de cité en psychiatrie. La France s'est montrée d'emblée réfractaire à la psychanalyse. Ailleurs, le succès des ouvrages de Freud est important, mais inégal selon les pays ; on le lit par exemple en traductions dès les années 1900, en russe. Les premiers travaux des disciples de Freud apparaissent également : Otto Rank, âgé de 21 ans, lui remet en effet le manuscrit de son essai psychanalytique "L'artiste" ).

En 1906, il s'intéresse à "La Gradiva", une nouvelle de l'écrivain allemand Wilhelm Jensen, et rédige un essai, Le délire et les rêves dans la « Gradiva » de Jensen" dans lequel il applique les principes psychanalytiques à la création littéraire, étudiant les liens entre la psychanalyse et l'archéologie. La même année, il se brouille définitivement avec Wilhelm Fliess, qui rédige par la suite un pamphlet, "Pour ma propre cause", dans lequel il accuse Freud de lui avoir volé ses idées.

En mars 1907, l'isolement de Freud cesse définitivement. Le groupe naissant de psychanalystes tente de créer une collection intitulée « Écrits de psychologie appliquée » aux éditions Deuticke. Freud, directeur de la publication, y publie "Le Délire et les rêves dans la Gradiva de Wilhelm Jensen". La même année, il écrit "Actes obsédants et exercices religieux", dans lequel il aborde le sujet de la religion : il y présume qu'il existe un rapport entre une névrose obsessionnelle et les exercices religieux. En 1908, le petit groupe autour de Freud devient la Société viennoise de psychanalyse et, en août, Karl Abraham fonde la Société psychanalytique de Berlin. L'année suivante, la première revue psychanalytique édite leurs travaux ; elle prend le nom , souvent abrégée en , avec Bleuler et Freud comme directeurs et Jung comme rédacteur en chef. Freud inaugure cette revue avec la publication du cas du petit Hans.

Le 26 avril, le premier Congrès international de psychanalyse à Salzbourg réunit 42 membres. Freud y présente ses ("Remarques sur un cas de névrose obsessionnelle"). En 1909 paraît les ("Cinq leçons sur la psychanalyse"). Freud s'interroge par la suite sur la nature de la pratique psychanalytique dans un essai, ("À propos de la psychanalyse dite sauvage" ou « analyse profane »). L'année 1910 marque un sommet dans l'histoire de la psychanalyse et dans la vie de Freud ; lors du second Congrès international à Nuremberg organisé par Jung, les 30 et 31 mars, est créée l' (Association psychanalytique internationale, « API »), dont le premier président est Carl Gustav Jung, ainsi qu'une deuxième revue, le . L'IPA rassemble sous son égide les groupes locaux (""), ceux de Zurich (qui en est le siège), de Vienne et de Berlin ; son but est de défendre la cohésion du mouvement psychanalytique. Une patiente de Jung avec qui ce dernier était passé à l'acte, Sabina Spielrein, le met sur la voie de la théorisation du transfert amoureux envers l'analyste, ainsi que du contre-transfert (de l'analyste envers le patient) et que Freud intègre à sa théorie.
Lors de ses vacances aux Pays-Bas, en 1910, Freud analyse le compositeur Gustav Mahler, lors d'un après-midi de promenade à travers la ville. Freud voyage ensuite à Paris, Rome et Naples, en compagnie de Ferenczi. La psychanalyse naissante se heurte à sa première opposition d'importance : en octobre, répondant à l'appel d'Oppenheim, lors du Congrès de neurologie de Berlin, les médecins allemands d'Hambourg mettent à l'index la pratique psychanalytique au sein des sanatoriums locaux.

Freud publie ("Un souvenir d'enfance de Léonard de Vinci") en 1910, dans lequel apparaissent pour la première fois les concepts de « narcissisme » et de « sublimation ». Il y examine aussi les raisons psychiques de la créativité. La même année, la psychanalyse est la cible de nouvelles critiques émanant de certains milieux médicaux. Par ailleurs, les premiers schismes en son sein se font jour. L'opposition de Freud à la théorie de Jung, qui devient, en 1914, la « psychologie analytique », l'occupe en effet ces années-là. Toujours en 1910, Freud, dans un texte intitulé « Le trouble psychogène de la vision dans la conception psychanalytique », formule pour la première fois un dualisme pulsionnel : les « pulsions sexuelles » y sont opposées aux « pulsions d'autoconservation ». Ce dualisme préfigure, dans le contexte de tension que connaît l'Europe avant la première Guerre mondiale, la mise à jour des pulsions de vie et de mort (qui interviendra en 1920).

En 1911, Freud écrit un texte connu sous le titre « Le Président Schreber » mais par la suite intitulé ("Remarques psychanalytiques sur un cas de paranoïa (Dementia paranoïdes) décrit sous forme autobiographique"). Freud y retrace l'analyse du juriste et homme politique Daniel Paul Schreber. Il publie aussi un court texte métapsychologique : ("Formulations sur les deux principes du cours des événements psychiques") dans lequel il décrit le principe de plaisir et le principe de réalité.

La direction des revues et des travaux théoriques de l'Association internationale de psychanalyse, celle des séminaires également, occupent Freud à cette période, d’autant que parmi ceux qui travaillent avec lui des rivalités se font jour ainsi que des dissensions théoriques qu'il combat lorsqu'elles remettent en question les rôles de la sexualité infantile et du complexe d'Œdipe comme le font celles de Jung, Adler et Rank. Ainsi, il refuse la mise en avant de l’agressivité par Alfred Adler, car il considère que cette introduction se fait au prix de la réduction de l’importance de la sexualité. Il refuse également l'hypothèse de l’inconscient collectif au détriment des pulsions du Moi et de l’inconscient individuel, et la non-exclusivité des pulsions sexuelles dans la libido que propose Carl Gustav Jung. En juin 1911, Alfred Adler quitte Freud le premier, pour fonder sa propre théorie. L'année suivante c'est au tour de Wilhelm Stekel, alors qu'en 1913, en septembre, Freud se brouille avec Carl Gustav Jung, pourtant annoncé comme son .

En 1913, ("Totem et Tabou") permet à Freud de présenter la portée sociale de la psychanalyse. Secrètement, depuis 1912, sur l'idée d'Ernest Jones, Freud a réuni autour de lui un petit comité de fidèles partisans (Karl Abraham, Hans Sachs, Otto Rank, Sandor Ferenczi, Ernest Jones, Anton von Freund et Max Eitingon) sous le nom de ("la « Cause »") et ce jusqu'en 1929. Chaque membre reçoit de Freud une intaille grecque de sa collection privée, qu'il porte sur un anneau d'or. Après la Première Guerre mondiale, en 1924, le mouvement psychanalytique freudien voit le départ d'Otto Rank et en 1929 celui de Sandor Ferenczi.

Pendant la guerre, Freud n'exerce que peu. En 1916, il rédige ses cours universitaires, rassemblés sous le titre de ("Cours d'introduction à la psychanalyse", édité en français sous le titre "Introduction à la psychanalyse"). Le sort de ses fils, sur le front, le préoccupe. La guerre paralyse par ailleurs l'extension du mouvement psychanalytique ; en effet le congrès de Dresde, prévu en 1914, n'a pas lieu. En 1915, il se lance dans la rédaction d’une nouvelle description de l’appareil psychique dont il ne conserve cependant que quelques chapitres. Ce qu’il prépare est en fait une nouvelle conception de la topique psychique. La même année, il est proposé au prix Nobel par le médecin viennois Robert Bárány. Freud publie ("Deuil et Mélancolie") en 1917. Helene Deutsch, Magnus Hirschfeld puis Sigmund Freud font état dans leurs écrits de femmes combattantes. En janvier 1920, il est nommé professeur ordinaire. À partir de 1920, et alors que le contexte politique et économique s’améliore, Freud publie tour à tour : ("Au-delà du principe du plaisir", 1920), qui introduit à travers un nouveau dualisme pulsionnel, les pulsions agressives, nécessaires pour expliquer certains conflits intra-psychiques et ("Psychologie des masses et analyse du Moi", 1921) qui ajoute à la problématique de Le Bon, les rapports entre psychisme individuel et comportements collectifs. Freud, durant ces années de guerre, travaille à une métapsychologie qui lui permette de décrire les processus inconscients sous un triple angle, à la fois dynamique (dans leurs relations entre eux), topique (dans leurs fonctions au sein de la psyché) et économique (dans leurs utilisations de la libido).

En 1920, Freud élabore la seconde topique de l'appareil psychique composée du Moi, du Ça et du Surmoi. Elle se superpose à la première (inconscient, préconscient, conscient). Le développement de la personnalité et la dynamique des conflits sont alors interprétés en tant que défenses du Moi contre des pulsions et des affects, plutôt que comme conflits de pulsions ; les pulsions en cause sont celles de la mort. L’ambivalence et la rage étaient perçues dans la première topique comme consécutives de la frustration et subordonnées à la sexualité. Freud complète ainsi sa théorie par un nouveau dualisme pulsionnel, composé de deux types de pulsions antagonistes : la pulsion de vie (l'Éros) et la pulsion de mort (qu'il se retient toujours de nommer Thanatos). Plus fondamentales que les pulsions de vie, les pulsions de mort tendent à la réduction des tensions (retour à l’inorganique, répétition qui atténue la tension) et ne sont perceptibles que par leur projection au-dehors (paranoïa), leur intrication avec les pulsions libidinales (sadisme, masochisme) ou leur retournement contre le Moi (mélancolie). Freud défend par là une vision double de l'esprit.

Pendant le conflit mondial, Freud peut mesurer les effets de la névrose traumatique chez son beau-fils et voir l'impact de cette pathologie dans une famille. Il a ainsi une connaissance directe de ces troubles et indirecte par des disciples qui côtoient la clinique de Julius Wagner-Jauregg comme Victor Tausk où qui y ont travaillé pendant la guerre comme Helene Deutsch. En octobre 1920, le professeur de médecine légale, Alexander Löffler, invite Freud à témoigner par un exposé devant une commission médico-légale sur les névroses de guerre et les pratiques de soins. Il s'oppose à Julius Wagner-Jauregg qui, lui, prétend que les patients atteints de névrose de guerre sont des simulateurs. Puis, du 8 au 11 septembre, se tient à La Haye le de l'IPA, présidé par Ernest Jones. Freud y intervient en lisant ("Suppléments à la théorie des rêves"). D'autre part, la création d'un comité secret y est décidée, avec Jones comme coordinateur.

La psychanalyse se développe de manière importante en Grande-Bretagne et en Allemagne. Max Eitingon et Ernst Simmel créent en effet à Berlin une polyclinique psychanalytique alors que Hugh Crichton-Miller fonde la Tavistock Clinic à Londres.

La première traduction d’un texte de Freud en France, "Introduction à la psychanalyse", par Samuel Jankélévitch, est publiée en 1922. Le mouvement psychanalytique acquiert une clinique psychanalytique à Vienne, l’« Ambulatorium » (centre de soins ambulatoires), consacré au traitement des psychoses et dirigé par trois élèves de Freud, qui n'y participe que peu : Helene Deutsch, Paul Federn et Eduard Hitschmann. En 1923, Freud apprend qu'il est atteint d'un cancer de la mâchoire, qui le fait souffrir tout le restant de sa vie. La même année il choisit de se soumettre à une vasectomie afin, espérait-il, de mieux lutter contre son cancer. Il écrit Le Moi et le Ça à un moment où le mouvement psychanalytique atteint une réputation internationale, notamment en Angleterre et aux États-Unis. Il songe à constituer une édition complète de ses écrits, les .

Le Congrès de Salzbourg, en 1924, se déroule en l’absence de Freud. La même année, Otto Rank quitte le mouvement. En Angleterre, les membres de la Société britannique de psychanalyse, refondée en 1919 par Ernest Jones, créent l’.

L'année suivante, en 1925, Freud écrit "Inhibition, symptôme et angoisse" ainsi qu'une esquisse autobiographique. Le de l’Association internationale se tient du 2 au 5 septembre à Bad-Homburg. Anna Freud y lit le texte de son père : ("Quelques conséquences psychiques de la différence des sexes au niveau anatomique"). Freud ne peut en effet plus voyager, en raison de sa maladie. Il rencontre en 1925 la princesse Marie Bonaparte, petite-nièce de Napoléon, qu'il prend en analyse et qui devient son amie. Plus tard, celle-ci traduit la majorité de ses textes en France.

Freud demeure le chef de file de la psychanalyse, dont il oriente l'évolution. Ses dernières réflexions écrites sont consacrées à étudier et renforcer la psychanalyse sur le plan théorique et clinique. Dans son article « Psychanalyse et médecine » (1925), il invite les non-praticiens à utiliser la psychanalyse. À ce propos, il parle de psychanalyse « laïque » ou « profane », c'est-à-dire, pratiquée par des analystes qui ne sont pas médecins. Il revient aussi sur l'évolution de sa pensée dans son autobiographie. En 1927, sa fille Anna publie ("Introduction à la psychologie des enfants", texte lu et approuvé par son père).

Dans les dernières années de sa vie, Freud essaye d’extrapoler les concepts psychanalytiques à la compréhension de l’anthropologie et de la culture. Sa vision pessimiste de l'espèce humaine s'exacerbe, notamment après la dissolution du comité secret formé par Ernest Jones, à la suite de querelles d'héritage, des jalousies et des rivalités internes. Il rédige donc un certain nombre de textes dans ce sens, en particulier sur la religion comme illusion ou névrose. En 1927, il publie ("L'Avenir d'une illusion"), qui porte sur la religion d'un point de vue psychanalytique et matérialiste. En 1930, il publie ("Malaise dans la civilisation") dans lequel Freud décrit un processus de civilisation qui est une reproduction à plus large échelle du processus d'évolution psychique individuel.

Ne se considérant pas comme un écrivain, Freud est surpris d'obtenir le prix Goethe de la ville de Francfort, en août 1930. Puis, il retourne l'année suivante dans sa ville natale de Freiberg pour une cérémonie en son honneur. Dans une lettre du 3 janvier, l'écrivain Thomas Mann s'excuse auprès de Freud pour avoir mis du temps à comprendre l'intérêt de la psychanalyse. En 1932, Freud travaille à un ouvrage de synthèse présentant des conférences devant un public imaginaire, ("Nouvelle introduction à la psychanalyse"). La même année, il publie, en collaboration avec le physicien Albert Einstein, leur pensée sur la guerre et la civilisation, issue de leur correspondance, dans un essai intitulé ("Pourquoi la guerre ?"). À Vienne, Thomas Mann, prononce le 8 mai 1936 un éloge et un soutien public à Freud (intitulé « "" » : « Freud et l’avenir ») où il explique : , justifiant par ce discours la remise du prix Goethe de Francfort à l'inventeur de la psychanalyse. Freud et Thomas Mann se sont liés d’amitié depuis la publication par l'écrivain de "Freud et la pensée moderne" (1929) et "Chevalier entre la mort et le diable" (1931). À propos du dernier ouvrage de Freud, ("Moïse et le monothéisme", 1936), Jacques Le Rider explique qu'il .

En mai 1933, les ouvrages de Freud sont brûlés en Allemagne lors des autodafés nazis. Il refuse de s'exiler jusqu'en mars 1938, lorsque les Allemands entrent à Vienne (Anschluss, le 12 mars). La Société psychanalytique de Vienne décide alors que chaque analyste juif doit quitter le pays, et que le siège de l'organisation doit être transféré là où réside Freud. Ce dernier décide finalement de s'exiler lorsque sa fille Anna est arrêtée le 22 mars, pour une journée, par la Gestapo. Grâce à l'intervention de l'ambassadeur américain William C. Bullitt et à une nouvelle rançon versée par Marie Bonaparte, Freud obtient un visa valable pour seize personnes et peut quitter Vienne par l’Orient-Express avec sa femme, sa fille Anna et la domestique Paula Fichtl, le 4 juin. Au moment de partir, il signe une déclaration attestant qu'il n'a pas été maltraité: Selon son fils Martin, il aurait ajouté, ironique : . Pour Michel Onfray, ceci relève du et de la légende hagiographique.
Pour sortir d'Autriche, Freud aura bénéficié en outre du soutien d'Anton Sauerwald, le commissaire nazi chargé de prendre le contrôle de sa personne et de ses biens : ancien élève de , un professeur et ami de Freud, Sauerwald facilitera le départ de Freud et de ses proches pour Londres, où il ira d'ailleurs ensuite le visiter. Des rumeurs sont nées sur la liste soumise par Freud concernant les seize personnes qu'il était autorisé à faire sortir d'Autriche, car il y avait inscrit les noms de son médecin et de sa famille, de ses infirmières, de sa servante et même son chien alors que n'y figuraient pas ses quatre sœurs, Rosa, Marie, Adolfina et Paula qui finiront déportées et tuées en camp de concentration, mais ce sont ces dernières, trop âgées, qui ne voulaient pas partir, pensant être protégées par leur âge des nazis.

La famille Freud gagne d'abord Paris, où Freud est accueilli par la princesse Bonaparte de son mari, puis Londres, où elle est reçue avec tous les honneurs, notamment par l'ambassadeur américain William Bullit, que Freud connaît depuis quelques années déjà, lorsque les deux hommes avaient travaillé ensemble à une étude sur le président américain Woodrow Wilson intitulée " (publiée en 1966). Freud et sa famille s'installent dans une maison au . Il est nommé membre de la Société royale de médecine. Freud reçoit la nomination chez lui, ne pouvant se déplacer, abattu par son cancer et par trente-deux opérations et traitements successifs.

Freud meurt dans sa maison de Londres à Hampstead le , à du matin, d’un carcinome verruqueux d’Ackerman, à l'âge de 83 ans. À sa demande, et avec l'accord d'Anna Freud, Max Schur, son médecin personnel, lui a injecté une forte dose, sans doute mortelle, de morphine. Son corps est par la suite incinéré au cimetière de et les derniers hommages lui sont rendus par Ernest Jones, au nom de l'Association psychanalytique internationale, et par l'écrivain Stefan Zweig, le 26 septembre.
Après la mort d'Anna Freud, en 1982, la maison des Freud de devient le . En 2002, une " fut apposée sur le musée.

La psychanalyse regroupe trois acceptions selon Paul-Laurent Assoun, qui les reprend de l'article de Freud de 1922 "Psychanalyse et théorie de la libido". Le terme désigne en effet d'abord une certaine méthode d'investigation du psychisme inconscient, mais aussi une méthode de traitement (la cure psychanalytique), et, plus généralement une conception psychologique globale touchant à la vision même de l'homme. Selon Lydia Flem, psychanalyste et écrivain : . Le mouvement psychanalytique représente aussi le corpus de théories issues de l'expérience analytique, participant à la conceptualisation de l'appareil psychique et développées depuis Freud. Cette théorie psychanalytique (qui est dite d'orientation psychodynamique, au sein de la discipline psychologique) se fonde d'abord sur les recherches de Freud et sur les concepts majeurs qu'il a créés tels que ceux d'« inconscient », de « transfert », de « répétition » et de « pulsion ». Du point de vue de sa méthode d'approche, son objet étant l'inconscient, la psychanalyse est une discipline centrée sur l'observation et non sur l'expérimentation ; elle est donc une « science phénoménale » rattachée à la médecine et à la psychiatrie, mais possédant auprès de celles-ci une autonomie relative.

Depuis ses premiers écrits fondateurs, Freud considère que la scientificité de la psychanalyse repose sur son objet : l'inconscient. Or, la plupart des critiques envers la psychanalyse lui contestent cette qualification de scientificité. Pourtant, elle est, selon Paul-Laurent Assoun, une collection de connaissances et de recherches ayant atteint un degré suffisant d'unité et de généralité, et donc capable de fonder La psychanalyse est donc considérée par les freudiens comme une science de la nature car elle repose sur des concepts fondamentaux, notamment celui de pulsion (""). Enfin, la psychanalyse récuse toute métaphysique.

Avec sa conception de l'inconscient, Freud a permis une compréhension des névroses et, au-delà, de la psyché. Les travaux historiques d'Ernest Jones et, plus récemment, d'Henri Ellenberger montrent cependant que le concept d'« inconscient » est antérieur à Freud, mais précisent que ce dernier est un précurseur par sa manière de le théoriser, dans sa première topique d'abord, puis dans la seconde. Marcel Gauchet, dans "L'Inconscient cérébral" (1999) évoque l'idée de Freud, celle d'un . Le mouvement psychanalytique s'est développé d'abord en référence à Freud et à ses proches partisans, puis en opposition à ses détracteurs, tant internes (Carl Gustav Jung, Alfred Adler et Otto Rank parmi les principaux) qu'externes avec entre autres Pierre Janet et certains médecins et/ou psychiatres académiques. Les modalités de formation des psychanalystes se sont formalisées notamment avec son pilier central : l'analyse didactique est instaurée pour la première fois à l'Institut psychanalytique de Berlin.

Depuis 1967, les psychanalystes dits de la « troisième génération » établissent un retour historique et épistémologique sur ce mouvement. Jean Laplanche et Jean-Bertrand Pontalis (dans "Vocabulaire de la psychanalyse") isolent ainsi environ 90 concepts strictement freudiens à l'intérieur d'un vocabulaire psychanalytique contemporain composé de 430 termes alors qu'Alain de Mijolla en dresse un panorama chronologique précis. Le travail de pionnier de Freud a eu un impact sur de nombreuses autres disciplines : sur la psychologie en premier lieu, mais aussi sur la nosographie des troubles mentaux, sur la psychopathologie, sur la relation d'aide, la psychiatrie, l'éducation, la sociologie, la neurologie et même la littérature. À un niveau plus général, Freud est également considéré par certains psychanalystes (comme Wilhelm Reich ou André Green, Françoise Dolto et Daniel Lagache plus tard) comme ayant été celui qui a délivré la parole sur la sexualité et notamment la sexualité féminine, sujets jusqu'alors méprisés par beaucoup de médecins.

Après la mort de Freud (mais également de son vivant), plusieurs écoles psychanalytiques entretiennent entre elles des rapports souvent polémiques, dépendant des postulats retenus et des spécificités nationales. Deux types de courants peuvent être distingués : ceux dits « orthodoxes », proches du freudisme, et ceux s'en écartant sur des points fondateurs : les courants « hétérodoxes ». Plusieurs points théoriques vont constituer des zones de division. Ainsi, pendant la Seconde Guerre mondiale se développe la question de l'analyse groupale, avec des analystes comme Wilfred Bion, qui développe sa propre conception. Par ailleurs, c'est en Angleterre que se déroulent, à partir de 1942, les oppositions entre Melanie Klein, Anna Freud et le Groupe des "Indépendants", sur plusieurs sujets. L’ regroupe les psychanalystes freudiens orthodoxes.

En France, par exemple, la Société psychanalytique de Paris relaye la psychanalyse, essentiellement freudienne, kleinienne et winnicottienne en fonction des orientations des membres qui la composent. Le courant lacanien s'en écarte toutefois, jusqu'à la rupture dans les années 1950, notamment à propos de l'axiome lacanien selon lequel et surtout sur les modalités de formation des psychanalystes qui, pour Lacan et ses adeptes, diffèrent radicalement de celles de l'I.P.A. et des associations affiliées. Si Lacan a été en opposition avec l'IPA, il ne faut pas le voir comme étant en opposition avec Freud : en témoignent son « retour à Freud » et ce propos de Jean-Michel Rabaté : 

Avec l'immigration de nombreux psychanalystes d'Europe avant, pendant et après la guerre, la psychanalyse prend beaucoup d'importance aux États-Unis, avec l’ ou la ". Il existe aussi l'ego-psychology et les courants totalement autonomes, issus des schismes successifs : ceux d'Alfred Adler, d'Otto Rank, Wilhelm Reich et de Carl Gustav Jung. Enfin, de nombreux psychanalystes contemporains, comme Sándor Ferenczi ou Donald Winnicott, développent et propagent leur vision des conceptions freudiennes, tels ceux dits de la « nébuleuse marginale » selon Paul Bercherie, ou ceux, à la pensée plus individuelle comme : Juliette Favez-Boutonier, Daniel Lagache, Françoise Dolto, André Green ou Didier Anzieu.

La psychanalyse a eu une profonde influence sur la plupart des sciences humaines : sur l'ethnologie (avec Géza Róheim et l'ethnopsychanalyse), sur l'anthropologie et les sciences juridiques (avec le juriste Pierre Legendre), sur le marxisme (par le freudo-marxisme et avec Herbert Marcuse) et sur les sciences politiques. La philosophie du a su se nourrir des apports de la psychanalyse d'après Paul-Laurent Assoun et ce à travers des personnalités comme Jean-Paul Sartre, Gilles Deleuze, Jacques Derrida, Félix Guattari, René Girard, Jean-François Lyotard ou Michel de Certeau. Le sociologue Norbert Elias, tout en se distanciant du mouvement des psychanalystes, reconnaît l'avancée de Freud, qui propose, selon lui, . Le philosophe Paul Ricœur le situe aux côtés de Karl Marx et de Friedrich Nietzsche comme étant l'un des trois grands , de ceux qui ont induit le doute dans la conception philosophique classique du sujet.
L'étude psychanalytique de la question de la psychosomatique a également une importance en médecine avec, par exemple, les apports de Franz Alexander et ceux de Michael Balint en Angleterre : les « Groupes Balint » sont menés par des psychanalystes, pour les médecins, et en rapport avec les pratiques de ces derniers, à partir d'études de cas. En France, Pierre Marty, Michel Fain et Michel de M'Uzan pour les affections somatiques, Françoise Dolto pour la pédiatrie et Didier Anzieu pour les groupes sont des exemples d'applications de la psychanalyse en dehors du champ de la cure type. En art, le surréalisme d'André Breton se réclame de la psychanalyse. L'influence est également importante dans le champ de l'interprétation artistique ou littéraire. La notion de sublimation, et, plus généralement, la théorie freudienne en art a été reprise par Deleuze et Guattari, René Girard, Jean-François Lyotard, ainsi qu'en esthétique, en histoire de l'art et dans les ".

Freud introduit dans les sciences humaines une conception nouvelle de l'inconscient. Depuis longtemps, il avait été remarqué que certains phénomènes échappent à la conscience. Les philosophes Leibniz et Arthur Schopenhauer considèrent qu'il existe un arrière-plan à la conscience. Le poète allemand Novalis est le premier à se servir du mot « inconscient », dans la continuité des thèses post-romantiques de Karl Robert Eduard von Hartmann avec son ouvrage ("Philosophie de l’inconscient") en 1869 mais surtout de Carl Gustav Carus (, 1851), ce dernier se représentant un « inconscient absolu » et un « inconscient relatif ». La théorie de Freud est directement liée à leurs travaux. Freud doit aussi à la psychologie expérimentale, et notamment à l'approche de l'hystérie. Les phénomènes d'ivresse ou de transe donnent en effet des exemples d'abolition de la conscience. Or, l'inconscient qu'introduit Freud n'est pas simplement ce qui ne relève pas de la conscience, comme chez von Hartmann. Par « inconscient », il entend à la fois un certain nombre de données, d'informations, d'injonctions tenues hors de la conscience, mais il y englobe aussi l'ensemble des processus qui empêchent certaines données de parvenir à la conscience, et permettent aux autres d'y accéder, comme le refoulement, le principe de réalité, le principe de plaisir, la pulsion de mort. Ainsi, Freud considère l’inconscient comme l'origine de la plupart des phénomènes conscients eux-mêmes, et ce d'une manière nettement différenciée de ses prédécesseurs, car celui-ci évolue de manière dynamique.

L'inconscient est la grâce aux travaux de Freud. Dans "Quelques remarques sur le concept d'inconscient en psychanalyse" (1912), le Viennois se propose de décrire la spécificité du concept. Il y donne une présentation hiérarchique de la notion, qui désigne d'abord le caractère ou l'aptitude d'une représentation ou d'un élément psychique quelconque présent à la conscience de manière intermittente et qui semble n'en pas dépendre. Sur ce point, Freud se réfère à la théorie du psychiatre français Hippolyte Bernheim quant à l'expérience suggestive et à l'hypnose. Par ailleurs, la notion regroupe la constatation d'une dynamique propre à cette représentation inconsciente, et dont l'exemple le plus révélateur est le phénomène d'hystérie. L'inconscient freudien acquiert dès lors son qualificatif de « psychique ». Un troisième niveau vient ensuite compléter la notion telle qu'elle est acceptée en psychanalyse : le niveau systémique par lequel l'inconscient manifeste les propriétés d'un système (que Freud désigne par l'abrégé ', « Ics » en français). Les premiers psychanalystes ont pu parler à ce sujet de « subconscient », terme vite écarté par Freud, car étant imprécis pour expliquer un système existant ', et, donc indépendant de la conscience.

Dans sa première topique, c'est-à-dire dans le second modèle théorique de représentation du fonctionnement psychique proposé en 1920, Freud distingue trois instances : l'inconscient, le préconscient et le conscient. Dans la seconde topique, l'appareil psychique comprend le Ça, le Moi et le Surmoi, trois instances supplémentaires fondatrices de la psychanalyse. Le Ça (') est présent dès la naissance ; il s’agit de manifestations somatiques. Si le Ça est inaccessible à la conscience, les symptômes de maladie psychique et les rêves permettent d’en avoir un aperçu. Le Ça obéit au principe de plaisir et recherche la satisfaction immédiate. Le Moi (') est en grande partie conscient, il est le reflet de ce que nous sommes en société ; il cherche à éviter les tensions trop fortes du monde extérieur ainsi que les souffrances, grâce, notamment, aux mécanismes de défense (refoulement, régression, rationalisation, sublimation, etc.) se trouvant dans la partie inconsciente de cette instance. Le Moi est l’entité qui rend la vie sociale possible. Il suit le principe de réalité. Bien que le Surmoi ("") existe depuis la naissance et que, jusqu'à cinq ans, l’enfant héritant de l’instance parentale, groupale et sociale emmagasine quantité de règles de savoir-vivre à respecter, le Surmoi se développe particulièrement lorsque le complexe d'Œdipe est résolu. Du fait des pressions sociales, en intériorisant les règles morales ou culturelles de ses parents et du groupe, l’enfant, puis l'adulte pratiquent le refoulement. En effet, le Surmoi punit le Moi pour ses écarts par le truchement du remords et de la culpabilité.

Les pulsions sexuelles sont conçues par Freud comme une énergie, qu'il nomme « libido » (« le désir » en latin). Ces pulsions sont susceptibles de maintes transformations et adaptations selon la personnalité et l'environnement. La libido est en effet essentiellement plastique et son refoulement est le plus souvent à l'origine des troubles psychiques alors que sa sublimation explique les productions culturelles, intellectuelles et artistiques de l’humanité. La doctrine freudienne de la libido a souvent été critiquée comme étant un « pansexualisme » matérialiste. Constituant le socle de la métapsychologie freudienne, le concept de libido, décrit dans "Trois essais sur la théorie sexuelle" (1905/1915/1920), est lié à celui de pulsion : , et ce, même si la prise en compte de la fonction de procréation est à considérer. En effet, sa nature est prégénitale et symbolique, et sa fixation conditionne la formation de la névrose.

Freud est le premier à élaborer une conception de la sexualité infantile. L'idée de « sexualité infantile » est surtout formalisée en 1905 dans l'ouvrage "Trois essais sur la théorie sexuelle", mais elle provient de travaux précédents, en particulier de la théorie de la séduction, abandonnée en 1897, et par laquelle Freud met au jour la sexualité infantile à travers son aspect pulsionnel. Il y décrit l'existence d'une opposition radicale entre sexualité primaire et adulte, marquée par le primat du génital, et sexualité infantile, où les buts sexuels sont multiples et les zones érogènes nombreuses, à tel point que Freud est souvent considéré comme le découvreur de la sexualité de l'enfant. Progressivement, entre 1913 et 1923, cette thèse se trouve remaniée par l'introduction de la notion de « stades prégénitaux », précédant l'instauration du stade génital proprement dit, et qui sont : le stade oral, le stade anal et le stade phallique . Freud propose ainsi d'expliquer l'évolution de l'enfant à travers des caractères pulsionnels d'ordre sexuel qui vont évoluer au travers de plusieurs stades psycho-affectifs, pour aboutir ensuite à la sexualité génitale adulte. C'est aujourd'hui une base théorique importante en psychologie clinique ou en pédopsychiatrie.

Selon Freud, l'. Les rêves sont en effet, dans le modèle psychanalytique, des représentations de désirs refoulés dans l’inconscient par la censure psychique (le Surmoi). Les désirs se manifestent ainsi dans le rêve de manière moins réprimée qu'à l'état de veille. Le contenu manifeste du rêve est le résultat d'un travail intrapsychique qui vise à masquer le contenu latent, par exemple un désir œdipien. En cure de psychanalyse, le travail repose sur l'interprétation à partir du récit (contenu manifeste) du rêve. Les associations du patient sur son rêve permettent de révéler son contenu latent ; ce « travail du rêve » (") repose sur quatre procédés fondamentaux. Tout d'abord, le rêve condense, comme s'il obéissait à un principe d'économie psychique, c'est-à-dire qu'une seule représentation concentre plusieurs idées, plusieurs images, parfois même des désirs contradictoires. Deuxièmement, le rêve est décentré et le désir déformé est fixé sur un autre objet que celui qu'il vise, ou sur de multiples objets jusqu'à l'éparpillement, ce qui constitue . Par ailleurs, le rêve est une illustration (ou « figurabilité ») du désir dans le sens où il ne l'exprime ni en mots ni en actes, mais en images ; le symbole onirique selon la psychanalyse est donc une . Enfin, le rêve est aussi le produit d'une activité inconsciente, mais très proche de l'activité vigile en ce qu'elle s'efforce de lui donner une apparence de vraisemblance, d'organisation, de logique interne (c'est l'« élaboration secondaire »).

Au niveau épistémologique, le geste de Freud consiste à réintroduire la production onirique dans la psychologie. Il rompt avec l'idée romantique d'un rêve contenant une clé ou un secret et seul le travail du rêve en explique la nature : la production à la fois complexe et immanente de la psyché qui s'apparente à un rébus. Cette théorie des rêves (") est selon Freud ce par quoi la psychanalyse a pu s'élever : d'abord simple thérapeutique elle a pu devenir, selon lui, une métapsychologie générale. La science du rêve en psychanalyse fonde tout le reste de son édifice théorique : .

 freudienne, la pulsion (') répond à une définition polysémique. Excitation psychique, concept-frontière entre psychique et somatique, elle se définit par une poussée ('), un but ('), un objet (') et une source ("). Elle conditionne la représentation ainsi que l'affect. Les pulsions prennent leur source dans une excitation corporelle et, en cela, elles sont proches de l'instinct. Au contraire d'un stimulus, la pulsion ne peut être évitée ou fuie et demande à être déchargée dans le conscient. Il existe selon Freud trois moyens de décharger une pulsion : par le rêve, par le fantasme et par la sublimation. Freud distingue d'abord deux groupes de pulsions : celles du Moi (ou d'auto-conservation) et les pulsions sexuelles. Par la suite, et dans ses écrits les plus tardifs, il distingue deux autres grands types de pulsions : la pulsion de vie (l'« Éros ») et la pulsion de mort (le « Thanatos »). L'Éros représente l’amour, le désir et la relation, tandis que le Thanatos représente la mort, les pulsions destructrices et agressives. Le Thanatos tend à détruire tout ce que l'Éros construit (la perpétuation de l’espèce par exemple). Le masochisme en est un exemple typique.

Le refoulement ("), « pierre d'angle » de la psychanalyse, est aussi le concept le plus ancien de la théorie freudienne. Dès 1896, Freud repère en effet un mécanisme de défense primaire, qu'il assimile ensuite à la censure et qui structure "a priori" le Moi et, de manière générale, le psychisme. Le refoulement est à la fois refus d'une pulsion et action psychique de maintien de cet écart. Frontière entre le conscient et l'inconscient, la « clause de censure » atteste aussi que l'inconscient est bien « travail » et processus, et non-principe seul.

. Freud théorise le complexe d'Œdipe dans sa première topique. Celui-ci est défini comme le désir inconscient d'entretenir un rapport sexuel avec le parent du sexe opposé (c'est l'inceste) et celui d'éliminer le parent rival du même sexe (le parricide). Ainsi, le fait qu'un garçon tombe amoureux de sa mère et désire tuer son père répond à l'impératif du complexe d'Œdipe. C'est dans la lettre à Wilhelm Fliess du que Freud évoque le complexe pour la première fois, mais c'est dès 1912 et 1913 que « l'Œdipe » est entré totalement dans la pensée clinique de Freud. Ce dernier s'attache à en étudier l'universalité, dans l'ouvrage "Totem et Tabou". Freud y avance la thèse suivante : celle de la , résumée par Roger Perron : 

Pour lui, la structure de la personnalité se crée en rapport avec le complexe d’Œdipe et son rapport avec la fonction paternelle (imago du père). Le complexe d’Œdipe intervient au moment du stade phallique. Cette période se termine par l’association entre la recherche du plaisir et une personne extérieure, la mère. Le père devient le rival de l’enfant ; ce dernier craint d’être puni en conséquence de son désir pour la mère par la castration. L’enfant refoule donc ses désirs, ce qui alimente au cours de son développement son Surmoi, avec la naissance en lui des sentiments de culpabilité et de pudeur, entre autres, et par l'intermédiaire du complexe de castration. Le complexe serait donc transmis de génération en génération et avec lui le sentiment de culpabilité associé. Freud a toujours recherché en effet à relier ces concepts, et en particulier celui du complexe d'Œdipe, à une théorie générale de la phylogenèse (de l'histoire de l'humanité comme espèce).

Selon Freud, tel qu'il le décrit dans son essai « L'organisation génitale infantile » (, 1923), l'élaboration du complexe d'Œdipe représente une étape constitutive du développement psychique des enfants. Le désir envers la mère trouve en effet son origine dès les premiers jours de la vie et conditionne tout son développement psychique (psychogenèse). La mère est, d'une part, la « nourricière » et, d'autre part, celle qui procure du plaisir sensuel, via le contact avec le sein et à travers les soins corporels. L'enfant, qu'il soit fille ou garçon, en fait donc le premier objet d'amour qui reste déterminant pour toute sa vie amoureuse. Cette relation objectale est ainsi investie de sexualité et se déploie en cinq « phases » libidinales qui trouvent aussi leur origine dans la constitution de la part de l'enfant de la scène primitive. La notion de « phase » ou de « stade » n'est pas à prendre au sens littéral. Elle signale la primauté d'une zone érogène particulière, mais n'implique pas que le processus se déroule de manière mécanique et linéaire. Le complexe d'Œdipe se déploie donc à travers ces phases en fonction de leurs propriétés propres qui s'enchevêtrent pour constituer un agrégat de pulsions qui, pour les freudiens, trouve son aboutissement vers l'âge de 5 ans. Freud aboutit à ce modèle en étudiant le cas dit du « petit Hans », en 1909.

La « phase orale » constitue l'organisation psychique du premier lien. La nourriture qui passe par la bouche est en effet la première origine de sensualité. Le plaisir produit par les zones érogènes s'étaye sur ce lien vital puis s'en éloigne, par exemple lors des préliminaires sexuels des adultes. On différencie la « phase orale de succion » de la « phase orale de morsure » qui inaugure une manifestation d'agressivité reposant sur l'ambivalence inhérente à la relation d'objet. Pour les kleiniens, le complexe d'Œdipe se manifeste déjà à cette phase orale et son déclin intervient lors de l'avènement de la position dépressive. Ensuite, la « phase anale », allant de 1 à 3 ans environ, est liée au plaisir de contrôler ses voies d’excrétion. La « phase phallique » (ou « génitale infantile »), de 3 à 6 ans environ, est liée à la masturbation. Elle connaît l'émergence puis le conflit œdipien dans sa phase la plus aiguë. La « phase de latence » s'étale ensuite de 6 ans à la préadolescence, et correspond au déclin du complexe d'Œdipe par le refoulement des pulsions sexuelles qui sont mises au service de la connaissance (ou « épistémophilie ») qui dure jusqu'à l'adolescence et qui est permise par le processus de sublimation. Cette « latence » est toute relative et peut varier selon les individus, les circonstances et les moments du développement.

La cure psychanalytique, communément nommée « psychanalyse » ou encore « cure type », désigne la pratique psychothérapeutique élaborée par Sigmund Freud puis par ses successeurs et inspirée de la « "" » de Josef Breuer. La pratique psychanalytique a été peu à peu distinguée par Freud de cette dernière, ainsi que de celle de l'hypnose. La cure psychanalytique s'applique plus largement à toute une série de traitements plus ou moins dérivés de la psychanalyse au point que Jean Bergeret fait de son emploi chez certains psychanalystes un abus de langage. Vers la fin de sa vie, Freud lui-même revient sur l'efficacité de la cure, rappelant que la psychanalyse est avant tout savoir. De nature transférentielle, elle repose sur les associations libres et débute par l'étude du symptôme (dont la névrose est la manifestation générale) pour arriver à sa source, la pulsion refoulée. Ce contenu censuré doit parvenir à la conscience du malade, ce qui en constitue le traitement.

La psychothérapie psychanalytique met en œuvre tous les concepts dégagés par Freud, et en particulier ceux de « libre association » et de neutralité (l'analyste doit laisser les idées spontanées du patient s'exprimer, il doit écouter sans rien dire — et encore moins faire — qui ne perturbe les associations de l'analysant) et d'« attention flottante » (l'attention de l'analyste ne doit pas se focaliser sur un élément ou un autre du discours de l'analysant, mais rester attentif aux éléments inconscients qui pourraient surgir). Par ailleurs, le cadre éthique de l'analyse repose sur la sincérité du patient ainsi que sur l'engagement du psychanalyste à la neutralité et à la bienveillance. L’unique but de l’analyse est donc, par le travail élaboratif du patient et le travail interprétatif du psychanalyste, de supprimer le refoulement qui crée la répétition ; mais l'analysé ne peut prendre conscience du refoulement que si, auparavant, a été supprimée la résistance qui le maintient.

Freud réalise sa première analyse avec Dora, de son vrai nom Ida Bauer, qui nourrit dans deux rêves des fantasmes sexuels handicapants. Mais, en raison du transfert qui s'opère sur sa personne, Freud échoue à guérir Dora. Il ne reconnaît que plus tard, dans un post-scriptum, qu'il n'a pas su se rendre compte qu'il était l'objet transfériel de sa patiente amoureuse. Le cas Dora est décrit de décembre 1900 à janvier 1901, mais Freud ne publie son "Fragment d'une analyse d'hystérie" que quatre ans plus tard.

Freud accueille ensuite en analyse Ernst Lanzer, surnommé « l'homme aux rats ». Cette cure lui fournit un matériel clinique, notamment dans l'étude de la névrose obsessionnelle. Le patient entretient une culpabilité à la suite d'une punition paternelle pour s'être masturbé, le rendant névrosé. Un troisième cas fondateur de la pratique psychanalytique est celui d'Herbert Graf, surnommé « le petit Hans ». Ce dernier n'a cependant pas été analysé par Freud. L'enfant souffre d'une phobie du cheval, lié à une fixation psychoaffective au niveau du complexe d'Œdipe. Grâce à la compréhension de ce schéma psychique, Herbert est guéri de ses fantasmes. Un quatrième cas est célèbre en littérature psychanalytique : celui de Sergueï Pankejeff, dit « l'homme aux loups ». Enfin, avec Daniel Paul Schreber (« le président Schreber »), Freud examine les délires psychotiques et paranoïdes présents dans "Mémoires d’un névropathe" du magistrat.

Freud renonce progressivement à faire de l'homosexualité une disposition biologique ou une résultante culturelle, mais l'assimile plutôt à un choix psychique inconscient. En 1905, dans "Trois essais sur la théorie sexuelle", il parle d'« inversion », mais, en 1910, dans "Un souvenir d'enfance de Léonard de Vinci", il renonce à ce terme pour choisir celui d'« homosexualité ». Dans une lettre datant de 1919 écrite à la mère d'une jeune patiente, Freud explique : Cependant, dans l'ensemble de l'œuvre freudienne, il existe plusieurs théories et questionnements sur la naissance de l'homosexualité chez le sujet : l'homosexualité adulte y est présentée tantôt comme immature par blocage de la libido au stade anal, tantôt comme repli narcissique ou encore comme identification à la mère. Freud a en effet affirmé à une certaine époque que l'homosexualité résulte d'un 
Puis il a fini par conclure que l'homosexualité est un choix d'objet inconscient.

Selon Freud, l'homosexualité n'est pas l'objet de la cure analytique. Seule la culpabilité qui l'accompagne peut donner lieu à une névrose. Enfin, dans une note de 1915 aux "Trois essais sur la théorie sexuelle", il explique également que conclut Élisabeth Roudinesco, même si cette question a divisé les psychanalystes. Cependant il faudrait distinguer l'homosexualité psychique chez tout être humain, de l'homosexualité agie. Selon le critique Didier Eribon, les psychanalystes partageraient un alors que pour Daniel Borrillo, Freud et certains psychanalystes (tel Jacques Lacan) feraient œuvre d'homophobie en classant l'homosexualité parmi les « inversions ». Cependant, il ne faut pas négliger que Freud est sorti de cette classification.

Pour Freud, la culture (') désigne l'ensemble des institutions qui éloignent l'individu de l'état animal. La nature correspond donc aux émotions, aux instincts, pulsions et besoins. L’être humain lutte en permanence contre sa nature instinctuelle et ses pulsions, qu'il tente de réfréner afin de vivre en société, sans quoi l’égoïsme universel amènerait le chaos. Pourtant, Freud opère une confusion constante dans ses écrits entre la civilisation d'une part et la culture d'autre part. Plus le niveau de la société est élevé, plus les sacrifices de ses individus sont importants. En imposant la frustration sexuelle surtout, la civilisation a une action directe sur la genèse des névroses individuelles. Le texte de 1929, "Malaise dans la civilisation", soutient la thèse que la culture est la cause principale de névrose et de dysfonctionnements psychiques. Par les règles claires qu’elle lui impose, la culture protège l'individu, même si elle exige des renoncements pulsionnels conséquents. Ces contraintes peuvent expliquer qu’il existe une rage et un rejet – souvent inconscients – vis-à-vis de la culture. En contrepartie, la culture offre des dédommagements aux contraintes et sacrifices qu'elle impose, à travers la consommation, le divertissement, le patriotisme ou la religion.

Dans l'essai « Une difficulté de la psychanalyse » publié en 1917, et dans ses conférences d'introduction à la psychanalyse, écrites pendant la Première Guerre mondiale, Freud explique que l'humanité, au cours de son histoire, a déjà subi . La première, explique-t-il, date du moment où Nicolas Copernic établit que . La deuxième, selon lui, a lieu quand la biologie moderne – et Darwin au premier chef – . Il ajoute : . Selon Freud, c'est le qui permet à l'homme d'évoluer culturellement.

Se disant « incroyant », Freud est critique vis-à-vis de la religion. Il estime que l’être humain y perd plus qu’il n’y gagne par la fuite qu’elle propose. Selon lui, l’humanité doit accepter que la religion n’est qu’une illusion pour quitter son état d’infantilisme, et il rapproche ce phénomène de l’enfant qui doit résoudre son complexe d’Œdipe : . Dans son premier écrit sur la religion, "Actes obsédants et exercices religieux", publié en 1907, il explique que le cérémonial liturgique implique obligatoirement des « actes obsédants ». Il parle par conséquent de . Selon lui, la . Quant au lien que la pratique psychanalytique entretient avec la religion, et dans une lettre au pasteur Pfister du , Freud dit qu'.

S'appuyant sur les thèses de Charles Darwin, en 1912, dans "Totem et Tabou", Freud explique que l'origine de l'humanité se fonde sur le fantasme d'une « horde primitive » dans laquelle a lieu le meurtre primitif du père comme acte fondateur de la société. Les hommes vivaient en hordes grégaires, sous la domination d'un mâle tout-puissant, qui s'appropriait les femmes du groupe et en excluait les autres mâles. Ces derniers commettent alors le meurtre du « Père primitif », parricide qui explique ensuite le tabou de l'inceste comme élément constitutif des sociétés. Dans "Malaise dans la civilisation", Freud décompose l'évolution de l'humanité en trois phases : une phase animiste caractérisée par un narcissisme et un totémisme primaires d'abord, puis une phase religieuse marquée par la névrose collective et enfin une phase scientifique dans laquelle prédomine la sublimation. Cette conception d'héritage phylogénétique a été critiquée par les anthropologues, les historiens et invalidée par la biologie.

L'antisémitisme ne pèse pas d'une manière égale durant la vie de Freud, et ce au gré des changements politiques de l'Autriche et l'Allemagne au début du . Le sentiment antisémite joue un rôle déterminant à la fin de sa vie, lorsqu'il doit fuir l'Autriche devant la menace nazie. Avant la première guerre mondiale, comme le souligne Yerushalmi, « Je tiens à souligner que sa prise de conscience du phénomène précéda son entrée à l'Université de Vienne, ou encore la fin du Burgerminister libéral et la montée de l'antisémitisme politique ». À partir de 1917, la censure d'articles antisémites dans les journaux devient moins stricte et il devient habituel de voir traiter les Juifs de « profiteurs de guerre ». C'est en 1918 que l'antisémitisme atteint son comble, les Juifs devenant explicitement les boucs émissaires de tous les malheurs qui s'abattent sur l'Autriche. En 1933, les œuvres de Freud sont brûlées par les nazis, qui y voient une « science juive » (selon la formule du parti nazi) contraire à l'« esprit allemand » : Avec l'annexion de l'Autriche par l'Allemagne, de nombreux psychanalystes ont dû cesser leur pratique ou émigrer quand ils n'ont pas été tués ou envoyés dans des camps de concentration parce qu'ils étaient juifs. La ségrégation s'est d'abord développée en Hongrie, notamment sous le régime de Miklós Horthy. Puis, elle s'est propagée en Allemagne dès les années 1920 et en Autriche. Dès lors, la plupart de ceux qui ont survécu ont émigré au Royaume-Uni, en France, en Amérique du Sud et aux États-Unis. Max Eitingon quant à lui s'est exilé en Palestine.

Henri Ellenberger a fait une étude approfondie de la situation des Juifs dans l'ensemble de la région et affirme que Freud aurait exagéré l'impact de l'antisémitisme dans sa non-nomination à un poste universitaire de professeur extraordinaire. Il argumente sa thèse de manière documentée. D'autres historiens considèrent qu'Ellenberger a minimisé le phénomène à Vienne, qui élit comme maire Karl Lueger, ouvertement antisémite, en 1897. Le père de Freud avait été victime d'un acte antisémite, qu'il a raconté à son fils. Dès ses débuts, la psychanalyse freudienne a été accusée d'être une « science juive ». Martin Staemmler écrit, dans un texte de 1933 : . Pour Lydia Flem, Freud et Theodor Herzl, chacun à leur manière, répondent à la crise identitaire juive, le premier en imaginant une topique psychique, le second en rêvant d'un pays géographique pour le peuple juif.

Élisabeth Roudinesco, dans un article de 2004 dans lequel elle étudie une évoque la position de Freud qui refuse, dans cette lettre, de soutenir publiquement la cause sioniste en Palestine et l'accès des juifs au mur des Lamentations, comme le lui avait demandé en 1930 Chaim Koffler, membre viennois du Keren Ha Yesod. Elle rappelle dans cet article que la « judéité » de Freud, qu'il n'a, selon elle « jamais reniée », était une . Cette lettre, jugée peu favorable à la cause sioniste n'a pas été rendue publique, et est restée inédite, bien que, comme le rappelle Élisabeth Roudinesco, Freud ait eu . Il envoie d'ailleurs, le même jour, une lettre à Albert Einstein, dans laquelle il développe les mêmes idées d' dont et de .

La découverte de l'alcaloïde de la plante de coca est contemporaine des recherches de Freud, qui cherche à l'utiliser pour la guérison psychique. En 1884, les laboratoires Merck confient à Freud la charge de mener des expérimentations sur la substance. Avant de créer la psychanalyse, Freud a étudié ce produit et a pensé pouvoir lui prêter toutes sortes d'indications médicales — notamment dans le traitement de la neurasthénie. Freud travaille sur les propriétés anesthésiantes de la cocaïne avec deux collègues, Carl Köller et Leopold Königstein, dès 1884. Cependant, il n'a pas le temps de tester son pouvoir narcotique et doit s'absenter de Vienne. Ses collègues poursuivent les expérimentations, notamment dans le cadre de la chirurgie oculaire, et finissent par présenter leur découverte devant la Société médicale de médecine de Vienne sans mentionner le rôle de Freud.

Freud a par ailleurs consommé épisodiquement de la cocaïne. Il en a usé entre 1884 et 1887 et a même rédigé un texte sur cette drogue : . Il se détourne ensuite totalement de son étude après avoir suggéré à son ami Ernest von Fleischl-Marxrow de l'utiliser pour guérir de sa morphinomanie. Freud espérait guérir son addiction par une autre addiction, à la cocaïne. Cependant, Fleischl von Marxow devient dépendant de la cocaïne, puis revient à la morphine et meurt prématurément à 45 ans, laissant Freud avec un très fort sentiment de culpabilité. Freud ne reconnaît pourtant pas le phénomène d'accoutumance, malgré plusieurs cas signalés dans la littérature médicale contemporaine, et continue cependant à en consommer épisodiquement et à en prescrire en application nasale jusqu'en 1895, lorsqu'il entame son auto-analyse. Dans un article datant de 1886, le Albrecht Erlenmeyer met en garde la communauté médicale en termes précis, qualifiant la cocaïne de . Face aux critiques de plus en plus nombreuses, le Johann Schnitzler, dans un article de la revue "Internationale Klinische Rundschau", en 1887, défend Freud, accusé d'en avoir propagé le recours. Ce dernier défend l'usage de la cocaïne jusqu'en 1887 et affirme que c'est le sujet qui est prédisposé et pas la drogue qui entraîne la toxicomanie.

Les principales querelles aboutissent, au cours du développement du mouvement psychanalytique, à des scissions majeures, d'abord celle d'Alfred Adler (qui fonde ensuite la psychologie individuelle), puis celle de Carl Gustav Jung, initiateur de la psychologie analytique. Les points théoriques de désaccord sont nombreux, liés à la libido, au complexe d'Œdipe ou encore à l'importance de la sexualité dans le psychisme. Ces controverses se situent dès les années 1907 et 1911. Nommés les « apostats » par Freud, Adler, le premier, puis Jung ensuite, s'opposent à la conception de la libido comme essentiellement d'origine sexuelle et qu'ils voient plutôt comme une « pulsion de vie » au sens large. Freud craint par-dessus tout que les dissidents ne détournent la théorie et la pratique psychanalytique. Paul-Laurent Assoun souligne en effet que tous deux disent vouloir remettre la psychanalyse dans la bonne direction, et la sauver du culte de la personnalité formé autour de Freud. La concurrence entre les diverses écoles, principalement entre le cercle viennois et l'école de Zurich de Jung, porte le coup le plus rude au jeune mouvement psychanalytique, et ce dès 1913, avec la défection de Jung. Les autres divergences internes se rapportent par exemple à la précocité du Surmoi telle que la décrit Melanie Klein ou Donald Winnicott. L'opposition avec Wilhelm Reich porte elle essentiellement sur des différences foncières concernant la pratique de la cure psychanalytique, notamment à propos de la règle d'abstinence. Le post-freudisme commence ainsi avec cette nouvelle génération de psychanalystes qui s'émancipent en partie de l'héritage freudien tout en intégrant ses apports.

La plupart des controverses autour de la pertinence scientifique des conceptions psychanalytiques sont appelées les , expression venant des États-Unis. Des contemporains de Freud, comme Karl Kraus et Egon Friedell, portèrent diverses critiques ; Kraus récuse l'interprétation sexuelle psychanalytique en littérature alors que Friedell qualifie la psychanalyse de « pseudo-religion juive » et de « secte ». Paul Roazen publie quant à lui une étude sur les relations complexes entre Freud, Victor Tausk et Helene Deutsch. Tausk avait demandé une analyse à Freud, qui la lui avait refusée, avant de l'adresser à Deutsch. Cette dernière était alors elle-même en analyse chez Freud. Cette situation est abordée par Roazen, qui la met aussi en rapport avec les autres causes du suicide de Tausk. Beaucoup d'autres critiques accréditées par des documents historiques existent.

Longtemps, la plupart des ouvrages parlant de Freud se référaient presque exclusivement à la biographie d'Ernest Jones, critiquée pour ses aspects hagiographiques. Les études critiques de Pierre Janet, de Karl Popper, puis les nouvelles recherches historiques initiées par Henri Ellenberger et relayées par d'autres auteurs qui ont publié des critiques telles celles de Mikkel Borch-Jacobsen, Jacques Van Rillaer ou Jacques Bénesteau, ont finalement conduit à revoir l'histoire et la portée de l'œuvre de Freud. L'accès à certains documents relatifs à Freud demeure un point de polémique. Une très grande collection des écrits originaux et des lettres freudiennes se trouve dans la ' de la Librairie du Congrès à Washington. L'accès à certaines lettres de Freud se trouvent en partie restreinte jusqu'en 2060. Pour les examiner, il faut une autorisation spéciale du directeur du département des manuscrits après l'accord avec les ' à New York. Pour de nombreuses lettres, il n'existe même pas de date de déblocage.

En France, la critique théorique est représentée par un ouvrage collectif et multidisciplinaire, "Le Livre noir de la psychanalyse" (2005), corpus d'articles publié sous la direction de Catherine Meyer, et qui reflète plusieurs décennies de critiques à l'encontre de Freud. La plupart des points critiques sont abordés, de la scientificité de la psychanalyse à la personnalité de Freud, en passant par les contradictions, la fabrication suspectée de cas psychopathologiques et de fausses guérisons. Se basant sur des études épidémiologiques, selon ces auteurs la faible efficacité thérapeutique de la méthode psychanalytique par rapport à d'autres techniques psychothérapeutiques, comme les thérapies cognitivo-comportementales est mise en évidence. Cet ouvrage a suscité des réactions dans divers milieux psychiatriques, thérapeutiques et psychanalytiques, relançant ainsi des conflits d'intérêts sous-jacents. En réponse à ces critiques, la psychanalyste Élisabeth Roudinesco a dirigé un ouvrage intitulé "Pourquoi tant de haine ? Anatomie du Livre noir de la psychanalyse" (2005). D’autres psychanalystes et psychiatres ont critiqué l'ouvrage.

Frank Sulloway a développé quant à lui dans "Freud biologiste de l'esprit" (1979) la thèse selon laquelle Freud aurait produit un modèle « cryptobiologique » dans le but de masquer ses inspirations biologiques reconnues comme déjà obsolètes à son époque par certains de ses partisans tel Ernst Kris, afin de présenter la psychanalyse comme une théorie révolutionnaire et originale. Jacques Lacan quant à lui estime que l’œuvre de Freud est à comprendre sous l'angle du langage et non sous celui de la biologie, affirmant notamment que « l'inconscient est structuré comme un langage».

Le philosophe français Michel Onfray publie en avril 2010 "Le Crépuscule d'une idole. L'affabulation freudienne", dans lequel il reproche notamment à Freud d'avoir généralisé son cas personnel, d'avoir été un médecin médiocre, d'avoir développé la théorie psychanalytique sans suivre une démarche scientifique, en mentant sur ses observations et sur les guérisons obtenues, aux seules fins d’assurer sa réussite personnelle et financière, et d'avoir fondé la communauté psychanalytique sur des principes quasi-sectaires. Il souligne également que Freud a signé une dédicace à Benito Mussolini et qu'il a écrit "L'Homme, Moïse et le monothéisme" en plein essor du nazisme et de l'antisémitisme. Onfray reprend les critiques du freudisme connues et développées avant lui, en utilisant une grille d'interprétation d'inspiration nietzschéenne. En novembre 2010, il publie "Apostille au crépuscule. Pour une psychanalyse non freudienne", dans lequel il propose un modèle psychologique permettant de « dépasser » la psychanalyse freudienne.

Les travaux de Lionel Naccache sur les phénomènes d'amorçage sémantique inconscient ont démontré l'existence d'un inconscient cognitif qui ne saurait être assimilé à l'inconscient freudien. La théorie freudienne du rêve centrée sur la satisfaction hallucinatoire du désir dissimulé grâce aux mécanismes de déplacement, condensation et dramatisation a aussi été critiquée. Selon le psychologue, sociologue et essayiste G. William Domhoff et le psychologue cognitiviste David Foulkes l'idée selon laquelle l'association libre permet d'accéder au contenu latent du rêve est infirmée par des travaux de psychologie expérimentale qui ont conclu au caractère arbitraire de cette méthode.

Selon le neuroscientifique Winson en 1985, l’association libre de Freud est une méthode valide qui permet l'accès au contenu latent. Le neuropsychiatre Allan Hobson a critiqué l’ouvrage de Domhoff en lui reprochant de méconnaître les mécanismes neurobiologiques qu'il étudie et remarque que Foulkes partage des points de vue avec la théorie de Freud, notamment qu'il existe un contenu latent et un contenu manifeste qui en est la transformation, et que cette transformation relève d'un langage à déchiffrer. Selon le neurologue Bernard Lechevalier, il y a compatibilité entre la conception psychanalytique du rêve et les neurosciences. Selon le chercheur en neuroscience et prix Nobel Eric Kandel, la psychanalyse « représente encore la conception de l'esprit la plus cohérente et la plus satisfaisante intellectuellement ».

En 1952, le pape Pie XII prononce un discours devant les participants du Congrès international de psychothérapie et de psychologie clinique qui reconnait la psychanalyse, mais relativise le pouvoir descriptif de ses concepts. Ainsi, si la psychanalyse décrit ce qui advient dans l'âme, elle ne peut prétendre décrire et expliquer ce que l'âme est pour autant.

Avant la Révolution de 1917, la Russie est le pays où Freud est le plus traduit. Après la prise de pouvoir par les bolcheviks, il y eut des rapprochements entre la pensée de Freud et celle de Karl Marx. Cependant, par la suite, explique Eli Zaretsky. En 1949, Guy Leclerc publie dans "L'Humanité" l'article « La psychanalyse, idéologie de basse police et d'espionnage », dans lequel il considère la psychanalyse comme une science bourgeoise destinée à asservir les foules. Dès lors, après en avoir accepté l'importance avec le freudo-marxisme, le Parti communiste français commence sa campagne contre la psychanalyse, et plus largement contre la psychanalyse en France.

Une partie des critiques envers Freud et la psychanalyse porte sur la question de sa scientificité. Ludwig Wittgenstein a par exemple dit : Le philosophe Michel Haar ("Introduction à la psychanalyse. Analyse critique", 1973) et les cognitivistes Marc Jeannerod et Nicolas Georgieff dressent le panorama de ces critiques tenant de l'épistémologie. Les critiques de Freud, à son époque et aujourd'hui, mettent en effet en cause tantôt la scientificité de sa démarche, sa méthodologie (notamment le faible nombre de cas, ou l'interprétation littéraire), son aspect hautement spéculatif également, son incohérence théorique, l'absence de validation expérimentale ou d'études cliniques rigoureuses (contrôlées et reproductibles), des manipulations de données et de résultats cliniques et thérapeutiques.

Dans "La Psychanalyse à l'épreuve" (1992), Adolf Grünbaum explique que Freud ne démontre rien sur le plan scientifique : Bien que critique envers la psychanalyse, Grünbaum s'oppose par ailleurs à un autre détracteur des travaux de Freud : Karl Popper. Ce dernier explique que : Le critère de sa falsifiabilité (sa « réfutabilité » en d'autres termes) occupe l'essentiel de leur débat. Contrairement à Popper qui regarde la psychanalyse comme non réfutable donc pseudo-scientifique, Grünbaum pense que certaines assertions psychanalytiques peuvent être testées, comme le lien supposé par Freud entre paranoïa et refoulement de l'homosexualité (si le second était bel et bien la cause nécessaire de la première, des sociétés moins homophobes devraient connaître une prévalence moins importante de paranoïa).

Selon Vannina Micheli-Rechtman, les critiques de Grünbaum et Popper ne prennent pas assez en compte l'épistémologie propre à la psychanalyse. Ainsi, la psychanalyse est avant tout « une pratique de communication et une pratique de soin », selon Daniel Widlöcher, qui rappelle cette phrase de Lacan « "la psychanalyse est une science des actions humaines au même titre qu’un certain nombre de sciences des actions". C'est-à-dire que c’est une pratique d’actions (on fait quelque chose avec quelqu’un d’autre) et de cela on déduit des généralités qu’on va élaborer comme des modèles. La psychanalyse construit des modèles » descriptifs au même titre que la science économique ou d'autres sciences sociales, comme l'ethnologie. Elle n'en adopte pas moins la même rationalité que la rationalité scientifique, comme le montre, par exemple, Jean-Michel Vappereau. Mais là où les sciences expérimentales évacuent la subjectivité pour atteindre l'objectivité, la psychanalyse s'attache à ce qui est propre à structurer la subjectivité, à travers un objet (l'inconscient) et un protocole (le « divan ») qui lui sont propres et parfaitement rationnels.


En français, les premières traductions l'ont été pour des articles et notamment par Henri Hoesli pour la "Revue française de psychanalyse". Les traductions de livres, parfois recueils d'articles, sont éditées par de nombreux éditeurs : Payot , Gallimard, PUF, Alcan. Anne Berman a été par exemple la traductrice de plusieurs ouvrages de Freud, d'Anna Freud et de Ernest Jones. Les Presses universitaires de France ont publié de 1988 à 2016 les "Œuvres complètes de Freud / Psychanalyse" sous la direction scientifique de Jean Laplanche. Cette traduction a été objet de controverses, du fait de ce que Laplanche définit comme , mais que ses contradicteurs voient comme un exercice formaliste, comportant des néologismes qui en rendent la compréhension difficile. Le volume "Traduire Freud" (1989) tente d'expliquer et de justifier les principes auxquels se réfère cette grande entreprise d'une nouvelle traduction des "Œuvres complètes de Freud" en France.

En allemand, dix-sept volumes sont parus entre 1942 et 1952, intitulés "". En anglais, vingt-quatre volumes paraissent entre 1953 et 1974 sous le titre de "Standard Edition". En 2010, la situation des traductions des œuvres change radicalement puisque les écrits de Freud sont entrés dans le domaine public.

Les principaux écrits de Freud traduits en français sont présentés ci-dessous, avec la première année de publication en langue allemande entre parenthèses.

La période prépsychanalytique comprend les écrits de Freud datant de sa formation médicale et de ses premiers travaux.
















</doc>
<doc id="2772" url="https://fr.wikipedia.org/wiki?curid=2772" title="Sociologie">
Sociologie

La sociologie est l'étude des êtres humains dans leur milieu social. Elle est une branche et une discipline des sciences humaines et sociales qui a pour objectif de rechercher des explications et des compréhensions typiquement sociales, et non pas mentales ou biophysiques à des phénomènes observables, afin d'en montrer leur « nature » sociologique. Le sociologique relève de ce qui résulte d'interactions sociales qui produisent par exemple (et selon les approches) : des acteurs sociaux, des actions sociales, des faits sociaux, des identités sociales, des institutions sociales, des organisations, des réseaux, des cultures, des classes sociales, des normes sociales ainsi que toutes ces entités qui n'ont pas d'explications purement biophysiques ou mentales et qui sont produites par l'interaction sociale. Une explication sociologique est vue comme le produit d'une démarche scientifique et/ou intellectuelle, afin de rendre compte, expliquer ou comprendre, un phénomène que le sens commun permet aussi d'appréhender.

Comme les courants en sociologie ne recherchent pas tous la scientificité et la réfutabilité, le terme de discipline est plus approprié que celui de science. Cependant, la prétention scientifique de la discipline tient à ce que son émergence dans le champ scientifique moderne s’est faite par comparaison aux sciences dîtes dures. Quelques courants contemporains, ayant émergé au cours des années 1990, font d'ailleurs usage de formalismes mathématiques, tels que l'analyse des réseaux sociaux.

La sociologie peut se découper en deux grandes orientations principales : l'une de ces orientations est la recherche fondamentale et l'autre la recherche appliquée. La recherche fondamentale vise à approfondir les connaissances théoriques des processus sociaux, tandis que la recherche appliquée vise à influencer les politiques publiques. Ces deux orientations peuvent s'enchevêtrer. Il existe deux types de méthodes en sociologie : les méthodes qualitatives et les méthodes quantitatives; elles peuvent être complémentaires. La sociologie offre trois niveaux d'analyse : la microsociologie, la macrosociologie et le niveau des organisations, des réseaux et de l'agentivité (mésosociologie).

La recherche sociale informe les politiciens et les autorités publiques, les éducateurs, les travailleurs sociaux, les législateurs, et de nombreux autres organismes et décideurs ainsi que tous ceux intéressés par la résolution de problèmes sociaux. De nombreux sociologues sont aujourd'hui employés par des institutions publiques, des collectivités territoriales ou des entreprises privées à fin d'expertise ou de consultance.

Le terme de sociologie est forgé par Emmanuel-Joseph Sieyès à partir du préfixe « socio » du mot latin "socius" signifiant « compagnon, associé » et du suffixe « logie » du terme grec ancien λόγος logos, signifiant « discours, parole ». Il s'agit donc étymologiquement d'une science des relations. 

Le terme est popularisé par Auguste Comte dans le sens d'une « physique sociale » à partir de 1839. L'emploi du mot sociologie serait né d'une petite querelle : Auguste Comte, secrétaire de Saint-Simon de 1817 à 1823, veut reprendre l'idée de création d'une science de la société. Il la nomme d'abord « physique sociale » ; mais ce terme est déjà utilisé par d'autre, notamment par le Belge Adolphe Quetelet. Ce dernier l'utilise pour désigner des travaux statistiques portant sur les phénomènes sociaux. Quetelet sera plus tard considéré comme un précurseur de la démographie, discipline restant proche de la sociologie, spécialement au niveau de la démographie sociale. Comte usera alors du mot « sociologie », vocable qui restera celui de la discipline. 

S'il est possible de dater avec une relative précision l'invention du mot "sociologie", la production du premier cours de sociologie ou encore la constitution du premier département universitaire de sociologie, il est également toujours possible de reconnaître chez des auteurs antérieurs des formes de réflexion ou d'imagination sociologique. Le développement de la sociologie doit dès lors être saisi à partir d'un contexte historique spécifique, les trois révolutions, qui a suscité un développement des réflexions sociologiques et abouti à l'institutionnalisation de la discipline.

L'étude de ce que nous appelons les sociétés précède l'invention du mot sociologie. La diversité des usages et des organisations a interpellé très tôt des penseurs et des historiens qui nous ont laissé des traces par l'écriture. Ainsi en est-il de Xénophon avec son "Économique", de Platon, d'Aristote avec sa "Politique", sa "République", sa "Poétique", son "Organon", etc. de Zoroastre avec son "Avesta". Hérodote, au , s'intéressait aux Égyptiens.

Dans la civilisation arabo-islamique, Ibn Khaldoun, dans son ouvrage Muqaddima, introduit une méthode précise et critique des sources et met les évènements en perspective pour déterminer les causes de la montée et du déclin des dynasties arabes. Certains le considèrent comme le véritable père de la sociologie. Ainsi, Ludwig Gumplowicz, professeur de sciences politiques à l'Université de Graz, dans un ouvrage intitulé "Aperçus sociologiques" publié à Paris en 1900, rapporte qu'. 

Pour les "Temps modernes", c'est dans le "Novum organum", la "Grande restauration des sciences" de Francis Bacon, et dans son tableau de classification des sciences, qu'apparait, sous l'intitulé de "sciences humaines", un ensemble de disciplines portant sur les sociétés humaines, ayant le même statut épistémologique que les sciences naturelles.

Au , plusieurs auteurs commencent à reconsidérer les mondes sociaux à partir de modèles mécaniques comme l’"Homme machine" de La Mettrie ou physiques comme celui d'Isaac Newton : les positions et les relations entre les individus obéissent à des lois semblables à celle de l'attraction universelle. On trouve cette idée chez Diderot, d'Holbach, etc. Mais c'est Fourier (1772-1827) qui pousse l'analogie le plus loin avec sa "Théorie de l'attraction passionnée". Montesquieu, de même, ne doit pas être oublié, en particulier pour "De l'esprit des lois" dans lequel il propose d'appliquer une méthode inductive et comparative à l'analyse des systèmes politiques, afin d'en dégager les lois : .

Au début du émerge la volonté de constituer une « physique sociale », c’est-à-dire un savoir aussi objectif que les sciences physiques, mais qui porterait sur le domaine des organisations humaines et des relations sociales.

Le premier à proposer une théorie « scientifique » des phénomènes sociaux au début du est le comte de Saint Simon (1760-1825). Il lui donne le nom de "physiologie sociale", qu'il replace dans une physiologie générale qui comprendrait aussi l'étude des êtres collectifs et de leur organisation.

Auguste Comte développa des théories sociologiques dans le "système de politique positive" (1851-1854). Il est souvent considéré en France comme un des pères fondateurs de cette science.

Alexis de Tocqueville (1805-1859) est aussi compté parmi les précurseurs de la sociologie, pour ses études sur la Révolution française ("L'Ancien Régime et la Révolution") ou sur les États-Unis ("De la démocratie en Amérique"). Il analyse et compare la société américaine et les sociétés européennes. Il anticipe remarquablement le concept de moyennisation de la société.

Georg Simmel (1858-1918) est considéré par de nombreux sociologues comme le précurseur de l'Interactionnisme structural.

Selon la formule de Jean Duvignaud, la sociologie peut être présentée comme « "la fille des révolutions" ». Si la sociologie émerge, au , des essais et tentatives de saisir le fonctionnement de la société, c'est parce que des transformations majeures, politiques, économiques et scientifiques obligent les hommes à repenser les liens qui les unissent.

Tout d'abord, le a été un moment de grande instabilité politique dans toute l'Europe. Depuis 1789, les régimes, les mouvements et les idéologies politiques se sont multipliés. Les insurrections et les guerres entre les nations européennes marquent ce siècle. L'ordre social ancien, fondé sur l'alliance du roi et de l'Église, est discrédité, mais la possibilité qu'ont les sociétés de se définir elles-mêmes conduit d'abord à une multiplication des troubles et des revendications.

La révolution industrielle participe également de ce sentiment de vivre dans une société nouvelle. Les gestes artisanaux, qu'ils soient transmis dans la famille ou au sein d'organisations de compagnonnage, sont dévalorisés par les progrès techniques. De plus, l'exode rural détruit les formes traditionnelles d'organisation de la vie sociale. Pour les paysans devenus ouvriers, la dégradation des conditions de vie et la perte des supports communautaires conduit à une misère à la fois matérielle et morale. Aux mouvements de protestations politiques se mêlent des réactions individuelles qui inquiètent l’époque : vols, mendicité, errance.

L'ouvrage classique "Communauté et société" de Ferdinand Tönnies, d'abord publié en 1887, constitue une représentation forte de la rupture qu'a constitué le . Il oppose la chaleur de la communauté, monde affectif mais clos fondé sur la famille, à la superficialité de la société, agrégat d'individus ayant d'abord des relations utilitaires.

La sociologie naît dès lors non seulement de la volonté de décrire la vie sociale mais également d'apporter des réponses aux troubles sociaux. « Elles répondent toutes, peu ou prou, à la même question : comment mettre fin à l'évidente crise sociale que traverse l'Europe ? ».

La différence entre la sociologie et les discours politiques ou littéraires réside dans le fait que la sociologie s'efforce d'apporter une réponse « scientifique » à ces questions. Le est notamment marqué par le positivisme scientifique . La biologie, la physique et la chimie connaissent des progrès considérables qui transforment la façon dont les hommes perçoivent leur environnement matériel. Ces disciplines participent également à la révolution industrielle et trouvent des applications techniques qui modifient fortement les modes de vie. Dans ce contexte, la sociologie est influencée par ce positivisme : nombre de sociologues empruntent leurs modèles d'analyse à la biologie ou la physique. Les progrès des sciences et leurs applications semblent donc prouver qu'un discours scientifiquement fondé est capable d'intervenir sur le monde et de répondre aux problèmes que le siècle pose. Émile Durkheim – qui s'inspire d'ailleurs pour partie des théories d'Auguste Comte pour renouveler cette science humaine – affirme en particulier qu'il faut « étudier les faits sociaux comme des choses ». Pour la plupart des sociologues, il s'agit donc de produire une représentation scientifique de la vie sociale capable de répondre aux problèmes que pose le . Il s'agit donc de proposer une critique de la vie sociale moderne et des réponses aux problèmes les plus brûlants. Les questionnements des sociologues sont cependant très variables selon les pays.

En France, Durkheim tient à concilier les acquis des révolutions, et d'abord l'autonomie individuelle, avec un ordre social stable. Dans la préface à son premier ouvrage, "De la division du travail social", il affirme en effet : « Quant à la question (Qui a été à l'origine de ce travail ?), c'est celle des rapports de la personnalité individuelle et de la solidarité sociale. Comment se fait-il que, tout en devenant plus autonome, l'individu dépende plus étroitement de la société ? Comment peut-il être à la fois plus personnel et plus solidaire ? Car il est incontestable que les deux mouvements, si contradictoires qu'ils paraissent, se poursuivent parallèlement ».

Si les sociétés peuvent concilier ordre et liberté, répond Durkheim, c'est grâce à la « division du travail ». Celle-ci doit en effet permettre de passer d'une solidarité mécanique, fondée sur la similitude, au développement d'une solidarité organique, c'est-à-dire résultant de l'interdépendance qui existe entre des individus aux activités différentes mais ayant besoin les uns des autres pour vivre.

Quand Durkheim fonde la sociologie française, la France est un pays où l'unité politique et étatique est forte, mais où subsistent de fortes identités régionales. L'État doit dès lors produire une société d'individus. Ainsi que le répète Durkheim, « le fait social est un fait moral », le développement de la société doit produire des individus à la personnalité plus forte : « La morale est ce qu'est la société… la première n'est forte que dans la mesure où la seconde est organisée ».

En Allemagne, Weber s'interroge quant à lui sur les types d'actions et les formes de l'autorité. La culture allemande ayant été unifiée avant même que l'unité politique ne soit réalisée, les réflexions de Weber portent moins sur les conditions d'existence de la société que sur le dynamisme de la vie sociale. Weber s'interroge sur les modes d'actions et de domination, produisant la première critique des systèmes bureaucratiques. Travaillant sur le développement du capitalisme, il montre l'analogie qui a existé entre l'éthique protestante et l'esprit du capitalisme. Voulant vérifier leur élection par Dieu, les protestants (notamment calvinistes) vont s'investir dans le travail tout en rejetant le plaisir associé à la consommation. Ils se comportent ainsi comme des capitalistes qui réinvestissent leurs profits. Mais il montre par là comment la vie sociale a perdu son sens et son caractère volontaire. Là où les protestants choisissaient un mode de vie en accord avec leurs convictions religieuses, la modernité a produit une « cage d'acier », un mode de vie rationnel dont il n'est pas possible de s'échapper : « Pour Weber, le paradoxe central du capitalisme est celui de la naissance, dans un contexte religieux, d'un type d'homme nouveau (orienté vers la recherche de la rationalité « instrumentale » ou « formelle ») dont l'universalisation risque de conduire à une "perte de sens" des relations sociales, alors même que se poursuivrait l'expansion de la mainmise « rationnelle » sur la nature et sur le monde social ».

Chez Marx, pour qui l'étude scientifique des sociétés permet de saisir l'inéluctabilité de la révolution et de l'avènement d'une société communiste ; chez Pareto, qui cherche à saisir la naissance et la mort des élites ; ou chez Park qui veut comprendre comment la ville permet l'assimilation progressive des immigrés, la sociologie naissante apparaît donc d'abord comme un discours sur les problèmes résultant de « la modernité ». La sociologie est alors une façon de répondre aux troubles politiques et économiques qui ont poussé les hommes à s'interroger sur leurs représentations de la vie sociale. Mais la sociologie ne pourra devenir une discipline qu'en s'affirmant comme une science et en accédant à l'université.

La sociologie n'est pas à sa naissance le seul discours sur la modernité. Ainsi que le montre Georg Lukács dans "La signification présente du réalisme critique", la littérature, avec le roman et plus encore le réalisme, propose en effet des représentations de la vie sociale. Ainsi, dans "Balzac et le réalisme français", il montre comment Honoré de Balzac cherche à construire une description complète de la société française : avant d'être renommé « comédie humaine », son cycle romanesque s'intitule « études sociales ». Le lien, parfois conflictuel, entre discours sociologique et discours littéraire n'est cependant pas spécifiquement français. En Angleterre, H. G. Wells participe aux premiers congrès de sociologie ; en Allemagne, les œuvres de Thomas Mann et Max Weber se répondent.
Selon Wolf Lepenies, la sociologie se constitue dans l'espace tiers entre science et littérature. Elle cherche à se légitimer et à se différencier par son approche scientifique du monde social, sans toutefois jamais pouvoir atteindre le degré d'objectivité des sciences de la nature. La sociologie naissante s'inscrit dans d'importants débats épistémologiques auxquels elle apporte des réponses très différentes en France et en Allemagne.

Si la sociologie doit donc affronter les prétentions de la littérature à dire ce qu'est la vie sociale, elle doit également faire face, au sein des sciences, à la psychologie naissante. Les approches psychologique, sociologique et philosophique entrent en effet en concurrence, en complémentarité et/ou en confusion dès qu'il s'agit d'analyser les objets cruciaux de l'anthropologie comme les rapports de la magie et de la religion. En opposition avec son rival Gabriel Tarde, Durkheim s'efforce ainsi à distinguer la sociologie de la philosophie d'une part, et de la psychologie d'autre part. Ses inspirateurs déclarés, outre Auguste Comte, sont Montesquieu et Rousseau, ainsi que les thèmes portant sur la « division du travail » qui sont le pivot de son œuvre, là où précisément le philosophe Durkheim rencontre le scientifique.

De Comte à Durkheim, le positivisme commence par une critique de l'économie politique, tout comme le marxisme, mais sur des postulats bien différents, concernant essentiellement la réalité accordée à la société comme existence antérieure à la personne et ontologiquement fondée.

Émile Durkheim est souvent considéré comme le père fondateur de la sociologie française. Le premier, il construit les bases d'une méthodologie scientifique pour la sociologie, en particulier dans l'ouvrage "Les Règles de la méthode sociologique" (1895) dans la continuité "De la division du travail social" (1893), livre qui est issu de sa thèse. Sa méthode repose essentiellement sur la comparaison de statistiques et de caractéristiques quantitatives, cherchant à se libérer du subjectivisme lié à toute donnée qualitative et à débarrasser de tout a priori moral ou moralisateur l'effort pour comprendre un « fait social » comme dans son ouvrage intitulé "Le Suicide" (1897).

Si la sociologie voit en Durkheim son « père fondateur » c'est en partie parce qu'il est le premier à aborder la sociologie comme une discipline scientifique. Cela nécessite 

Le contemporain de Durkheim, Max Weber, selon des voies différentes, emploie la science politique, l'économie politique, la philosophie de la culture et le droit, l'étude des religions, qui sont selon lui, tout comme la sociologie, des « sciences de la culture ». Selon toute une tradition de la philosophie allemande (Wilhelm Dilthey notamment), ces sciences sont trop éloignées des sciences de la nature pour qu'elles puissent s'inspirer de leurs méthodes. Elle propose une compréhension des phénomènes collectifs plutôt que la recherche de lois (c'est la méthode dite compréhensive). Pour Weber, le but de la sociologie est de :
Karl Marx est un autre penseur qui aura une profonde influence sur la pensée sociale et critique du . C'est essentiellement en Allemagne qu'il deviendra un référent théorique majeur de la sociologie avec l'École de Francfort. Comprendre le fonctionnement des sociétés constitue l'espoir d'un moyen de lutter pour l'avènement d'un monde plus juste (Karl Marx), de fonder scientifiquement une morale laïque indépendante des prescriptions des religions (Émile Durkheim), de lutter contre les « fléaux » de la société que sont la pauvreté, l'alcool, l'immoralité (Le Play), contre la révolution parfois (Gustave Le Bon).

Dans la sociologie "française", la réception de la pensée de Marx a été notamment abordée selon trois points de vue et/ou postures :

La discipline a été enseignée avec son nom en propre pour la première fois à l'université du Kansas à Lawrence aux États-Unis en 1890 par Frank Blackmar, avec pour titre du cours : "Elements of Sociology". Le "Department of History and Sociology" à l'université du Kansas a été établi en 1891, et la première faculté indépendante de sociologie a été établie en 1892 à l'université de Chicago par Albion Small. Ce dernier a fondé en 1895 la revue "American Journal of Sociology".

Le premier département européen de sociologie a été fondé en 1895 à l'université de Bordeaux en France par Émile Durkheim. Ce dernier a fondé "L'Année sociologique" en 1896. En 1919, un département de sociologie a été établi en Allemagne à l'université Louis-et-Maximilien à Munich par Max Weber. Un autre a été mis en place en 1920 par Florian Znaniecki en Pologne. Les premiers départements de sociologie au Royaume-Uni ont été fondés après la deuxième guerre mondiale.

La coopération internationale en sociologie a commencé en 1893 quand René Worms a fondé l'Institut international de sociologie, éclipsé par l'Association internationale de sociologie en 1949 (actuellement présidée par le français Michel Wieviorka). En 1905, l'« American Sociological Association » a été fondée et Lester Frank Ward a été choisi comme son premier président.

Il existe une association regroupant les sociologues français : l'Association française de sociologie (AFS) actuellement présidée par Dan Ferrand-Bechmann. Par ailleurs, il existe une association internationale francophone : l'Association internationale des sociologues de langue française (AISLF), actuellement dirigée par Monique Hirschhorn.

Deux points de vue s'opposent souvent à l'intérieur de la sociologie : le paradigme holistique d'Émile Durkheim et le paradigme atomistique défini par Max Weber. Néanmoins les deux paradigmes ont en commun de se construire par comparaison aux modèles de scientificité des sciences de la nature : par assimilation ou par opposition. 

Celui d'Émile Durkheim est dit "paradigme holistique" (du grec "holos" : qui forme un tout). Pour lui et ceux qui se réclament de son héritage, la société est un "holon", un tout qui est supérieur à la somme de ses parties, elle préexiste à l’individu et les individus sont gouvernés par elle. Dans ce cadre, la société englobe les individus et la conscience individuelle n'est vue que comme un fragment de la "conscience collective".

Selon ce point de vue, l'objet des recherches sociologiques est le "fait social", qu'il faut traiter comme une chose, sa cause devant être cherchée dans des faits sociaux antérieurs. Le fait social, qui fait l'objet d'une institutionnalisation, est extérieur à l’individu et exerce une contrainte sur ce dernier. Les individus sont donc encadrés dans des institutions, elles-mêmes insérées dans des structures homologues les unes par rapport aux autres. La sociologie est alors la science des invariants institutionnels dans lesquels se situent les phénomènes observables.

Marcel Mauss imprimera une inflexion significative à cette doctrine en arguant de la nécessité de décrire complètement et dans leur totalité les formes dans lesquelles le phénomène apparaît pour révéler leur secret. Analyser le concret interdit de négliger la sensibilité au vécu.

Plus récent mais certainement porteur, Jean Baechler a développé un paradigme entre l'histoire et la sociologie, une méthode qui reprend certains axes des études simmeliennes, et qui se pose sur les fondements des critiques de la raison historique recensées par Raymond Aron pour rendre compte du devenir des phénomènes sociaux macroscopiques.

Le point de vue de Max Weber est différent, c'est le "paradigme atomistique". Pour lui, chaque individu est un "atome" social. Les individus agissent en fonction de motifs, intérêts, d’émotions propres et sont liés aux autres individus. Un système d'interactions constantes entre les individus produit et reproduit la société. Raymond Boudon a aussi contribué à ce courant de pensée, nommé Individualisme méthodologique.

Selon ce point de vue, l'objet des recherches sociologiques est la rationalité de l'acteur, afin de comprendre et d'expliquer l'action sociale. L’accent est porté sur la cause des actions sociales et le sens donné par les individus à leurs actions. On ne cherche plus des arrangements d’institutions mais un horizon de significations qui servent de références. L’institution est là mais elle sert les motifs et les intérêts des agents et les enserre : c'est la « cage de fer » de la bureaucratie.

D'autres paradigmes existent en sociologie. Ainsi, le constructivisme social (dont les sociologues Peter L. Berger et Thomas Luckmann ont été les initiateurs) envisage la réalité sociale et les phénomènes sociaux comme étant « construits », c'est-à-dire produits et institutionnalisés. La sociologie critique (dont une figure importante au fut Pierre Bourdieu), analysant les rapports de domination caractérisant les différentes sociétés, se présente comme un paradigme transversal à une diversité de courants sociologiques. L'émergence récente de l'Interactionnisme structural, une approche fondée sur l'étude des dynamiques relationnelles et le recours à l'analyse des réseaux sociaux suggère des pistes de recherche dépassant l'opposition entre approche holistique et approche atomistique. De même, la sociologie pragmatique (initiée par Luc Boltanski et Laurent Thévenot) a considérablement modifié les manières de lier logiques d'enquêtes, productions de modèles et styles de restitution des travaux.
Mais ce n'est pas seulement par la place respective de l'individu et du social que s'opposent les paradigmes de la sociologie mais aussi par la fonction attribuée au conflit et à l'ordre.

La sociologie contemporaine a, pour beaucoup, limité ses ambitions : elle se limite à l'étude des organisations humaines et institutions sociales, en utilisant principalement une méthode comparative ; elle s'est concentrée sur l'étude de l'organisation des sociétés industrielles complexes, c'est-à-dire des sociétés occidentales, ou dites aussi modernes. Ce recentrage a laissé le domaine de l'étude des comportements de groupe à la psychologie sociale.

Par ailleurs l'anthropologie, née des conquêtes coloniales et de l'étude des peuples qu'elle appellera trop longtemps primitifs, recherche des traces de l'évolution de l'homme (comme espèce dans le cas de l'anthropologie physique et de l'évolution des sociétés dans celui de l'anthropologie sociale). Néanmoins, certains anthropologues ont aussi mené leurs études dans les sociétés industrialisées. Aujourd'hui, la sociologie et l'anthropologie se différencient plus par leurs méthodes et leurs théories, que par l'objet de leurs études.

La sociologie n'est pas faite d'un ensemble structuré autour des mêmes fondements et dans lequel tous les auteurs partageraient les mêmes conceptions de ce qui est scientifique et de ce qui ne le serait pas, de ce qu'il faut attendre de la science, du rapport à la modernité. Les auteurs, les écoles et les courants choisissent tel critère ou tel autre (structurel, fonctionnel, conventionnel, etc.), telle accroche au réel plutôt que telle autre (interactionnisme, institutionnalisme, régulationnisme, actionnisme, etc.) sans toujours préciser explicitement ce qu'ils retiennent et ce qu'ils rejettent des plans méthodologique et métaphysique où ils déploient leur projet politique et scientifique, où se sédimentent des traditions (manifestes ou oubliées par l'histoire de la discipline) et des conceptions du rapport social divergentes et pas forcément solidaires, voire peu enclin à discuter entre elles.

En conséquence, les modélisations de cette « science », elles-mêmes différentes dans le temps, tendent à faire varier aussi bien la place relative des différentes problématiques que les ambitions de la sociologie. Selon François Dubet, « la dispersion est devenue la règle et la combinaison des modèles remplace l'ancienne unité. Dans ce cas la crise d"'une" sociologie est aussi la crise de "la" sociologie en tant que type de pensée sociale de la « modernité » et de modèle global auto-suffisant ayant été le projet même de la sociologie ».

Enfin, la question du partage de ce projet (particulièrement sensible quand il s'agit de labelliser telle ou telle pensée comme relevant de l'entreprise sociologique ou non) se répercute dans la propension de la discipline à tolérer ou exclure des objets (c'est-à-dire, en fait, à en dessiner les contours) – dit autrement, depuis la sociologie professionnelle, dans la place faite aux affects subjectifs qui déterminent le désir de chercher. Pour emprunter à Luc Boltanski, la « sociologie d'expertise » se caractériserait par son obéissance à des critères unidimensionnels d'exploration des objets qu'elle se donne, quand la « sociologie critique » viserait à assumer leur multidimensionnalité.

Depuis son origine, la sociologie se recherche en tant que science. Elle hésite sur la place à accorder au sens qu'un individu ou un groupe humain donne à son action, son intentionnalité. Dans les sciences naturelles par exemple, qui ont inspiré la sociologie à ses débuts, le sens étant invisible, il ne peut être objet d'étude, ni entrer dans un théorie. Mais, la vie humaine se constituant d'intentions, beaucoup de sociologues sont conduit à s'interroger sur elles, et à réfléchir à leur modèle scientifique. Ainsi, pour Clifford Geertz, la sociologie n’est pas .

Les domaines d'études en sociologie sont presque aussi nombreux que les phénomènes sociaux. Il peut s'agir de l'étude des mouvements sociaux, de la déviance, de la sexualité humaine, de l'éducation, de l'immigration, du travail, l'armée, etc.

L'étude des phénomènes sociaux se fait par le biais d'un certain nombre d'outils qui permettent au sociologue d'appréhender des phénomènes dont l'échelle dépasse ses possibilités de perception individuelle, mais aussi de limiter les inductions qu'il fait au cours de son travail. Parmi ces outils peuvent être trouvé : le questionnaire, le sondage, l'observation "in situ" (participante ou non), l'entretien, le récit de vie, l'analyse en groupe (ou « focus group »), l'analyse de contenu, l'herméneutique, l'analyse statistique, l'analyse des réseaux sociaux, la recherche-action.

Le sociologue est avant tout un être humain avec, entre autres, des sensations, des impressions et des opinions. Pour s'affranchir de cet état lors d'une recherche, l'application de méthodes reconnues par ses pairs permet au chercheur de légitimer son approche d'un phénomène social. , telles peuvent être les premières questions d'un chercheur sur l'objet de sa recherche. Généralement, les méthodes sociologiques se scindent en deux catégories complémentaires ; les méthodes quantitatives et les méthodes qualitatives.

Les études quantitatives permettent l'étude des ensembles, la comparaison des unités vis-à-vis de tendances générales. La précaution à prendre au préalable est de définir des unités comparables et les indicateurs, ainsi que de savoir précisément ce que le chercheur veut comparer. Les limites des études quantitatives sont atteintes lorsque le chercheur s'interroge sur un phénomène unique ou sur des trajectoires biographiques. Les statistiques et les sondages sont les outils principaux de l'étude quantitative.

Observation détaillée, description de situation, c'est-à-dire une analyse de discours, un outil de codage qui permettent de faire ressortir les typologies, des tendances générales, etc. Ainsi, parmi les méthodes utilisées dans l'enquête sociologique, on retrouvera notamment l'entretien et l'observation.

La sociologie reçoit quelques critiques provenant des anarchistes individualistes, tel l'auteur Max Stirner dans son ouvrage L'Unique et sa propriété au chapitre sur le libéralisme social, où il dénonce le concept de société comme abstraction utilisé par la bourgeoisie libérale pour nier l'individu. Le Libéralisme social Il y a également cette critique composé par Gérard de Lacaze-Duthiers pour la définition même du mot sociologie dans l'Encyclopédie anarchiste de Sébastien Faure, où il explique que « la sociologie conspire avec la morale contre la liberté de l’individu ». Sociologie - Définition





</doc>
<doc id="2773" url="https://fr.wikipedia.org/wiki?curid=2773" title="San José">
San José

San José (en français ) peut désigner :

San José ou l'un de ses composés peut désigner plusieurs toponymes du pays :

San José ou l'un de ses composés peut désigner plusieurs paroisses civiles du pays :




</doc>
<doc id="2775" url="https://fr.wikipedia.org/wiki?curid=2775" title="Sony">
Sony

, est une société multinationale japonaise basée dans l'arrondissement de Minato, à Tokyo, Japon. Elle est active dans différents domaines tels que l'électronique, la téléphonie, l'informatique, le jeu vidéo, la musique, le cinéma et l'audiovisuel en général.

Sony Corporate comprend plus de cent sociétés à travers le monde, dont Sony France SA, Sony Corporation of America, Sony Music Entertainment, Sony Pictures Entertainment, Sony Computer Entertainment et est présent dans 183 pays (voir les ).

La société a été créée le sous le nom de par Masaru Ibuka, ingénieur, et Akio Morita, physicien, embauchant une vingtaine de personnes dans une société qui réparait des équipements électroniques et qui tentait de créer ses propres produits.

Le nom Sony apparaît sur les produits dès 1955 mais la compagnie change de nom seulement en janvier 1958. Il provient du latin ' qui signifie "son", et de l'expression anglaise alors en vogue au Japon ' qui désigne une jeune personne à l'esprit libre et novateur.

En 1954 la société commence à se développer vraiment : à cette date, la société obtient une licence pour la fabrication de transistors, composant électronique de base par excellence. Ainsi, les premiers transistors japonais sortent des usines de Sony cette année-là, 6 ans après leur invention aux États-Unis. L'année suivante, Sony commercialise le premier récepteur radio entièrement à base de transistors.

Parmi les innovations importantes apportées par Sony, citons la cassette vidéo couleur en 1971, le magnétoscope Betamax en 1975, le Walkman en 1979, la disquette en 1984, un appareil photo électronique en 1981 Sony Mavica, le Disque compact en association avec Philips en 1982, le premier caméscope grand public en 1983, la vidéo en 1988, le premier numériscope en 1985, ou encore le disque Blu-ray en 2006.

Au niveau des contenus, en 1987, Sony rachète CBS qui devient en 1991 , et en 1989 via .

Sony est une société internationale. Akio Morita a estimé dès le départ que sa société devait considérer le monde entier comme marché et non se limiter au Japon. Il insista pour que le nom Sony apparaisse clairement sur tous les produits de la société.

En 2004, le chiffre d'affaires pour l'ensemble des sociétés et filiales de Sony Corporation à travers le monde s'élève à près de d'euros. La part de Sony dans le marché mondial de l'électronique grand public a été estimée en 2004 à plus de 14 % (devant Panasonic, Hitachi et Philips). En , Sony et Samsung créent une coentreprise de fabrication de dalle LCD en Corée baptisée S-LCD.

Sony fabrique aussi des semi-conducteurs mais uniquement pour ses propres filiales. En 2005, Sony pointe ainsi à la des vingt plus grands fabricants de semi-conducteurs.

Le , l'Américain d'origine anglaise Howard Stringer est nommé président de Sony Corporation après la démission de Nobuyuki Idei. Le siège social se trouve à Tokyo au Japon. La société compte dans le monde au .

En , Sony a annoncé un profit net record de près de 2,4 milliards d'euros à la suite d'une année 2007 marquée par les belles performances de ses produits phares (CyberShot, Bravia, PlayStation) mais aussi la vente des chaînes de productions à Nagasaki de processeurs Cell et RSX à Toshiba et la cession du "" de Berlin. Le , annonce une vague de licenciements touchant d'ici l'année 2010, ainsi que la réduction de 30 % des investissements en recherche et développement pour faire face à la crise économique et à la chute des ventes notamment dans le secteur des écrans LCD.

Durant 2009, Sony cherche à se relancer : l'entreprise continue notamment son plan de restructuration en créant le ', qui regroupe et les activités image et son, et le ' qui rassemble les branches jeux vidéo, informatique et services en ligne de Sony. En décembre 2009, Sony prend une part de 7 % dans la filiale Sharp Display Product qui gère l'usine de fabrication de dalles LCD de dixième génération de Sharp à Sakai, part qui doit passer à 34 % en avril 2011. Ce nouvel investissement n'a cependant jamais eu lieu, et en mai 2012, Sony annonce se désengager totalement de cette filiale.

L'an 2010 fut aussi une année charnière pour les différentes divisons du groupe; la 3D « relief » fait une entrée massive dans le catalogue des produits grand public de la marque (Bravia, PS3, etc.), des accords sont passés avec Google pour intégrer Android à divers systèmes (smartphone Xperia, Google TV...), annonce du rachat à Toshiba de l'usine de semi-conducteur de Nagasaki, pour doubler ses capacités de production de capteurs photos, et Sony Computer Entertainment redevient rentable grâce à la baisse des coûts de fabrications des consoles PlayStation.

Depuis 2010, la division électronique de Sony perd de l’argent.

L'année 2011 est l'occasion pour Sony d'élargir sa plateforme , déjà bien implanté auprès du grand public, en lançant le service Qriocity, destiné aux divers produits de la marque, et notamment aux futures tablettes Android. Cette même année, le "PSN" est mis hors ligne par des attaques DDoS ainsi que l'attaque mené par Lulzsec durant près d'un mois. Sony découvre des failles exposant les données personnelles des utilisateurs. Les utilisateurs découvrent aussi les manigances de Sony réalisées à l'aide du PSN (comme la récupération automatique de données personnelles). Le service, après sécurisation, reprendra partiellement le 15 mai. L'entreprise japonaise doit aussi faire face au tremblement de terre du , à l'incendie d'une de ses plateformes logistiques en périphérie de Londres, lors des émeutes d'août, ainsi qu'aux inondations en Thaïlande paralysant ses sites de productions d'appareils photo. Par ailleurs, le groupe annonce une restructuration de sa branche télévision, faisant suite à des ventes en baisse.

Le , Sony annonce un accord avec Hitachi, Toshiba et INCJ portant sur la mutualisation des moyens de productions de dalles LCD de petites et moyennes tailles sous la forme d'une nouvelle entreprise appelée . Le groupe annonce, le 27 octobre, le rachat des parts du suédois Ericsson dans leur coentreprise Sony Ericsson. Le 26 décembre, Samsung Electronics annonce qu'elle rachète les parts de Sony dans leur coentreprise de fabrication de dalle LCD S-LCD pour de wons ( d'euros). Fin , Sony et Panasonic annoncent qu'ils développent désormais ensemble leurs techniques de façonnage des écrans OLED (diode électroluminescente organique).

Fin , Sony annonce d'importantes pertes et une éventuelle restructuration. La direction décide de se concentrer sur les secteurs qui rapportent.

Le , Sony annonce le rachat du service de jeu à la demande Gaikai pour un montant de (environ ).

En , Sony vend sa participation (de 13,14 %) dans DeNA pour 438 millions de dollars.

En , Sony sort la PlayStation 4, sa nouvelle console de salon. .

Le , le "Nihon Keizai Shinbun" annonce que Sony va céder ses activités japonaises d'ordinateurs (marque Vaio) au fonds pour 40 à de yens (300 à d'euros). Par ailleurs à la suite de cette cession le groupe prévoit de réduire ses effectifs de dont à l'étranger. va créer pour cela le juillet une nouvelle entreprise baptisée Vaio Corporation dont Sony sera actionnaire à hauteur de 5 %.

En , Sony annonce son intention de scinder ses activités dans les capteurs électroniques dans le but de donner plus autonomie et de visibilité à ces activités. Le même mois, Toshiba vend ses activités dans les capteurs d'images à Sony pour 165 millions de dollars. En janvier 2016, Sony acquiert l'entreprise israélienne Altair Semiconductor pour 212 millions de dollars. En , Sony acquiert les 50 % qu'il ne détenait pas dans Sony/ATV Music Publishing pour 750 millions de dollars, société gérant les droits notamment des Beatles, de Taylor Swift ou d'Elvis Presley. En , Murata Manufacturing acquiert Sony Energy Devices, filiale de Sony produisant des batteries pour appareils mobiles.






Sony se lance pour la première dans la conception d'une console de jeu, c'est alors qu'en décembre 1994 sort la Playstation . Une console de jeux vidéo de la cinquième génération. La PlayStation originale fut la première machine de la gamme PlayStation, déclinée ensuite en PSone (une version plus petite et plus légère que l'originale).

La Playstation 1 devient la console de jeu vidéo la plus acheté dans le monde de son temps, le 1 janvier 1997, 12 millions de PlayStation se sont écoulées à travers le globe contre 7 millions de Saturn, sa principale concurrente de l'époque avec la Nintendo 6417. La Playstation a permis de lancer des jeux vidéo cultes qui existent encore actuellement comme Silent Hill, Rayman, Grand Theft Auto,Resident Evil, Gran Turismo, Driver,Crash Bandicoot, Metal Gear Solid.

Le 4 mars 2000, six ans après la sorti de la première Playstation, vient la Playstation 2.

Sony possède également des studios d'édition de jeux vidéo comme Unties ou Sony Marketing où des jeux sont publiés sur des consoles PlayStation mais aussi sur d'autres plateformes comme Steam ou la Nintendo Switch.

Le , Sony annonce en même temps que ses résultats financiers, l'abandon de tout développement concernant ses robots Aibo et Qrio pour se recentrer sur des segments plus rentables.



"Données juin 2010 :"

Sony possédait deux usines en France.

L'usine de Pontonx-sur-l'Adour dans les Landes, inaugurée le 26 septembre 1984, comptait 330 employés en 2008. Spécialisée dans la fabrication de cassettes et bandes magnétiques, elle est fermée en 2009.

L'usine de Ribeauvillé en Alsace a été construite en 1986 et a compté jusqu'à 1600 salariés dans les années 1990. Elle produisait lecteurs CD, autoradios, magnétoscopes, ordinateurs portables et téléphones mobiles. Après plusieurs plans sociaux l'usine compte désormais moins de 400 salariés et a été vendue au groupe Cordon Electronics en 2014. Elle est depuis spécialisée dans les activités de service après vente des produits Sony, la production de sous-ensembles électroniques et l'ingénierie.

L'usine à Fellbach qui produisait des téléviseurs a fermé en 1999.

L'usine Sony UK Technology Centre à Pencoed (Bridgend) fabrique des caméscopes professionnels ainsi que des ordinateurs Raspberry Pi. Il s'agit de la dernière usine appartenant à Sony en Europe.

L'usine Sony de Valdecavalls qui produisait des téléviseurs a été vendue en 2010 à l'équipementier automobile Ficosa.

L'usine de Gödöllö qui produisait des les lecteurs DVD et Blu-Ray a fermé en 2010. La production a été transféré en Malaisie.

L'usine Sony de Nitra qui fabrique des téléviseurs a été revendue en 2010 à Foxconn. Elle continue de fournir Sony en téléviseurs dans le cadre d'un contrat de sous-traitance.

Sony possède plusieurs usines au Japon (liste non exhaustive, 2012) :

Usines Sony Semiconductor Corporation :

Usines Sony EMCS Corporation :

Autres usines :

Sony possède de nombreuses usines en Chine et fait également appel à des sous-traitants en Chine.

Sony possède une usine d'assemblage d'appareils photo reflex et bridge à Chonburi.

Sony possède une usine à Bandar baru bangi près de Kuala Lumpur.

L'usine de East Huntingdon (Pennsylvanie) produisait des téléviseurs LCD a fermé en 2009. Il s'agissait de la dernière usine de téléviseurs aux États-Unis.

Sony France est inscrit comme représentant d'intérêts auprès de l'Assemblée nationale. L'entreprise déclare à ce titre qu'en 2015, les coûts annuels liés aux activités directes de représentation d'intérêts auprès du Parlement sont inférieurs à .

Sony Europe est inscrit depuis 2008 au registre de transparence des représentants d'intérêts auprès de la Commission européenne. Il déclare en 2015 pour cette activité 3 collaborateurs à temps plein et des dépenses d'un montant compris entre et .


"Principaux concurrents en photographie :"
Lumix Canon Fuji Nikon Olympus Pentax Sigma

"Principaux concurrents dans la téléphonie mobile :"
Nokia Samsung LG Motorola Apple HTC
Toshiba Samsung Dell HP Acer Asus - Lenovo

"Principaux concurrents dans les téléviseurs :"
Philips Haier Toshiba Samsung LG Sharp Panasonic

"Principaux concurrents dans les jeux vidéo :"
Nintendo (console portable et console de salon) Microsoft



</doc>
<doc id="2780" url="https://fr.wikipedia.org/wiki?curid=2780" title="Sénégal">
Sénégal

Le Sénégal, en forme longue la République du Sénégal, est un pays d'Afrique de l'Ouest. Il est bordé par l'océan Atlantique à l'ouest, la Mauritanie au nord, à l'est par le Mali, la Guinée et la Guinée-Bissau au sud. La Gambie forme une quasi-enclave dans le Sénégal, pénétrant à plus de à l'intérieur des terres. Les îles du Cap-Vert sont situées à de la côte sénégalaise. Le pays doit son nom au fleuve qui le borde à l'est et au nord et qui prend sa source dans le Fouta Djallon en Guinée. Le climat est tropical et sec avec deux saisons : la saison sèche et la saison des pluies.

L'actuel territoire du Sénégal a vu se développer plusieurs royaumes dont le Djolof, vassaux des empires successifs du Ghana, du Mali et Songhaï. Après 1591, il subit le morcellement politique ouest-africain consécutif à la bataille de Tondibi. Au , plusieurs comptoirs appartenant à différents empires coloniaux européens s'établissent le long de la côte, ils servent de support au commerce triangulaire. La France prend peu à peu l'ascendant sur les autres puissances puis érige Saint-Louis, Gorée, Dakar et Rufisque en communes françaises régies selon le statut des Quatre communes. Avec la Révolution industrielle, la France désirait construire un chemin de fer afin de les relier et entra en conflit avec le Damel du Cayor, Lat Dior. Ce conflit permit à la France de faire officiellement du Cayor un protectorat en 1886, un an après la fin de la conférence de Berlin. La colonisation de l'ensemble de l'Afrique de l'Ouest est alors amorcée et Saint Louis, puis Dakar deviendront les deux capitales successives de l'Afrique-Occidentale française créée en 1895. Dakar devient ensuite la capitale de la République sénégalaise au moment de l'indépendance en 1960. Contrairement aux autres anciennes colonies de l'AOF le Sénégal indépendant moderne est donc le résultat du regroupement d'un territoire peuplé d'anciens citoyens français (les Quatre communes) et d'un territoire peuplé d'anciens indigènes (le reste du pays).

Le pays fait partie de la CEDEAO. Depuis le 2 avril 2012, le président du pays est Macky Sall. Intégré aux principales instances de la communauté internationale, le Sénégal fait également partie de l'Union africaine (UA), de la Communauté des États sahélo-sahariens (CES) et de l'Organisation Internationale de la Francophonie.

L'explication de l'origine du nom Sénégal reste controversée. Dès 1850, l'abbé David Boilat, quarteron et fils de signare (riche commerçante métisse), y voyait dans ses "Esquisses sénégalaises" une déformation de l'expression wolof "suñu gaal", c'est-à-dire « notre pirogue ». Très populaire, c'est la version la plus souvent relayée par les médias. Elle est pourtant contestée depuis les années 1960 et plusieurs autres étymologies ont été avancées, par exemple celle qui rattache le toponyme à une tribu berbère du Sahara, les Zenaga. Mais le débat scientifique pencherait plutôt en faveur des Zenaga ou Sanhadja aujourd'hui. En effet disent que le nom vient du berbère signifiant le point de retour des Berbères, "syin id noughal".

Le plus souvent la préhistoire et protohistoire du Sénégal évoquent avant tout les cercles mégalithiques de Sénégambie ou les amas coquilliers artificiels, tels ceux de l'île de Fadiouth.

Des bifaces en amande du paléolithique inférieur ont été découverts dans la presqu'île du Cap-Vert, ainsi que d'autres objets en pierre plus élaborés (hachereaux, racloirs) dans la région de Rufisque et au bord des rivières du Sénégal oriental.

Au néolithique, l'outillage se diversifie et la céramique fait son apparition. Les fouilles menées dans les régions côtières ont mis au jour des restes de cuisine qui témoignent d'une importante population de pêcheurs et commerçants (marigot de Khant dans le delta, embouchure du Saloum).

La métallurgie se développe à l'époque protohistorique ( millénaire ), où l'on retrouve des tombeaux en forme de tumulus. Dans le centre du pays, débordant sur l'actuelle Gambie, on trouve un ensemble de cercles de mégalithes sur un secteur de sur . On retrouve ce type d’alignement dans le nord est de la république centrafricaine.

Les peuplements se sont progressivement consolidés pour aboutir à la création des premiers royaumes qui se forment au , les Toucouleurs fondent le Tekrour, le Royaume du Namandirou, puis le Djolof, avec de lointaines parentés avec l'empire du Ghana. Parmi les différents royaumes, le plus puissant au était l'empire du Djolof qui regroupait le Cayor, le Baol, les royaumes sérères du Sine et du Saloum, le Waalo, le Fouta-Toro et le Bambouk. Au sud du pays, l'État du Kaabu, puis le Fouladou.

Le Djolof était un empire fondé par Ndiadiane Ndiaye, premier bourba (roi) djolof. Il avait été élu comme chef dans ce qui allait devenir le royaume du Oualo, au nord-ouest de l'actuel Sénégal, dans la région du fleuve. Il avait réuni toutes les populations d'ethnie wolof pour fonder cet empire au . L'empire s'effondra en 1549, avec la mort du dernier empereur du Djolof, Lélé Fouli Fak, tué par Amary Ngoné Sobel Fall, alors chef de la région du Cayor.

Le Djolof est resté vassal de l'empire du Mali pendant un siècle. À partir de là, les autres États allaient, tour à tour, prendre leur indépendance jusqu'à réduire le grand empire du Djolof aux dimensions d'une royauté dans la partie centrale du pays. Dans la seconde moitié du , les colons français annexèrent progressivement tous les royaumes du Sénégal. Le Djolof fut le dernier royaume annexé avec le départ en exil de Alboury Ndiaye, sous l'impulsion de Louis Faidherbe.

L'islam est introduit au Sénégal pour la première fois entre le et le par le biais des commerçants arabo-berbères. Ils diffusent pacifiquement cette religion et convertissent les Toucouleurs, lesquels la propageront partout au Sénégal. Plus tard, au , les Almoravides, aidés des Toucouleurs, tentent d'islamiser les groupes de religion traditionnelle par le Djihad. C'est l'une des raisons qui entraîne la migration des Sérères vers le Sine-Saloum, des Wolofs, des Peuls et des Mandingues, qui étaient tous concentrés au Tekrour. Une légende populaire, chantée par les griots et illustrée par le poète-président Senghor, rattache d'ailleurs la filiation du premier Bourba Djolof Ndiadiane N'Diaye à la dynastie des Almoravides (fondatrice de Marrakech et responsable de l'attaque repoussée par le célèbre « Cid »). L'islam se propage très tôt dans l'empire du Djolof. Mais c'est au qu'il gagne véritablement l'ensemble des populations, pacifiquement, grâce aux marabouts et leurs confréries tels que El Hadji Malick Sy pour la tidjaniya ou Amadou Bamba, fondateur de la confrérie mouride, qui émerveillent les populations par leur érudition et leurs miracles. C'est également un moyen pour les populations de s'unir et se protéger contre les ravages que connaissent les royaumes au (djihads répétés, colonisation forcée).

Le est en effet marqué par la chute des royaumes, l'avancée des colons européens ainsi que par la résistance anticoloniale, illustrée par des personnages tels que Aline Sitoe Diatta, Sidya Ndaté Yalla Diop, El Hadj Oumar Tall, Mamadou Lamine Dramé, Bouna Alboury Ndiaye, Alpha Molo Balde, Maba Diakhou Ba, Ndeté Yalla Mbodj, Moussa Molo Balde, Djignabo Badji, Lat Dior... La religion catholique se diffuse avec les missionnaires européens à partir du , en particulier au Sine et en Casamance.

La conquête coloniale commence dès la découverte de ces terres entre 1442 et 1456 par le navigateur vénitien Cadamosto pour le compte du Portugal. Les Portugais se lancent alors rapidement dans la traite des Noirs, mais devront bientôt faire face à la concurrence des négriers britanniques, français et hollandais à travers le Commerce triangulaire.

Les Hollandais fondent un comptoir sur l'île de Gorée, la France établit en 1659 celui de Saint-Louis qui deviendra la première capitale du Sénégal. En 1677, les Français occupent à leur tour l'île de Gorée (un des principaux centres du commerce des esclaves avec Saint-Louis et le fort de l'île James en Gambie).

Le XVIII et le s voient l'apogée des signares, de riches commerçantes métisses, centrées sur Gorée et Saint-Louis, qui restent extérieures au commerce des esclaves.

La seconde République de 1848 crée un mandat de député pour Saint Louis. L'ordre colonial s'impose avec Faidherbe, gouverneur du Sénégal (territoire des Quatre Communes) de 1854 à 1861 et de 1863 à 1865, qui jette les bases de la future Afrique-Occidentale française (AOF). Respectueux des coutumes indigènes, il étend l'influence française très au-delà du Sénégal, travaille à développer l'économie locale et créé le port de Dakar. La troisième République consacre le statut des quatre communes à Saint-Louis, Gorée, Dakar et Rufisque.
La conférence de Berlin s'achève le 26 février 1885, les puissances européennes se partagent alors l'Afrique et annexent désormais les royaumes situés à l'intérieur des terres. La colonisation de l'ensemble de l'Afrique de l'Ouest s'achève quelques années plus tard. L'Afrique-Occidentale française (AOF) est créée en 1895. Deux statuts vont alors cohabiter au sein de la population, les habitants des quatre communes sont citoyens Français de plein droit tandis que les populations des territoires nouvellement colonisés seront soumis à l'indigénat. Sous l'influence du député noir Blaise Diagne, un statut particulier peut être choisi par les habitants des quatre communes à partir de 1916. Ces dernières envoient des conscrits pendant les deux conflits mondiaux. En 1919, certains troubles agitent Dakar. Le tirailleur Cheikou Cissé, né au Soudan français et blessé pendant la guerre, est condamné à la peine de déportation perpétuelle et envoyé au bagne de Nouvelle-Calédonie. Mort en 1933, il a fait l'objet d'une lutte de la part des milieux anticolonialistes français (dont le Secours rouge international et la SFIC communiste).

Après Saint-Louis, Dakar devient, en 1902, la capitale de l'Afrique-Occidentale française.

En avril 1959, la République soudanaise (actuel Mali) et le Sénégal fusionnent pour former la Fédération du Mali. Le la fédération devient indépendante suite aux transferts de pouvoirs convenus dans l'accord signé en France le . Cette date est considérée comme le jour officiel d'accession du Sénégal à l'indépendance.

Le , le Sénégal se retire de la fédération du Mali et proclame son indépendance.Alors que le Président du Conseil, Mamadou Dia, incarne le sommet de l’État dans un système parlementaire bicéphale du type de la Quatrième République en France (la politique économique et intérieure pour le gouvernement et la politique extérieure pour la présidence), ses relations avec Senghor s’enveniment peu à peu. En 1962, il est arrêté et accusé de « tentative de coup d’État » avec quatre autres ministres, Valdiodio N'diaye, Ibrahima Sarr, Joseph Mbaye et Alioune Tall. Alors que le procureur général ne requiert aucune peine, ils sont condamnés à 20 ans d'emprisonnement au centre spécial de détention de Kédougou.

Le procureur général de l'époque, Ousmane Camara, revient sur le déroulement du procès dans une autobiographie publiée en 2010 : "« Je sais que cette haute cour de justice, par essence et par sa composition, (ndlr : on y retrouve des députés ayant voté la motion de censure), a déjà prononcé sa sentence, avant même l’ouverture du procès (...) La participation de magistrats que sont le Président (Ousmane Goundiam), le juge d’instruction (Abdoulaye Diop) et le procureur général ne sert qu’à couvrir du manteau de la légalité une exécution sommaire déjà programmée »""."

De nombreuses personnalités comme Jean-Paul Sartre, le pape Jean XXIII ou encore François Mitterrand demandent leur libération mais Senghor ne décide de les gracier et de les libérer qu'en mars 1974 ; ils sont amnistiés en , un mois avant le rétablissement du multipartisme au Sénégal. .

À la suite de cet événement, Léopold Sédar Senghor met en place le 7 mars 1963 un régime présidentiel fort. En 1966, l'UPS devient le seul parti autorisé. Il faut attendre une dizaine d'années avant le rétablissement du multipartisme au Sénégal en mai 1976. Un mouvement social se déclenche en mai 1968 en faveur de réformes politiques et économiques dans le pays.

Le Sénégal et la Gambie s'unissent en 1982 pour former la Confédération de Sénégambie, mais celle-ci ne fut que théorique et n'a jamais été mise en application. Elle est finalement dissoute en 1989.Des affrontements ont lieu depuis 1982 de manière intermittente entre les séparatistes installés dans le Sud de la Casamance et les forces gouvernementales. Après plusieurs tentatives infructueuses, un nouvel accord a été signé à Ziguinchor le entre le ministre de l'Intérieur Ousmane Ngom et l'abbé Augustin Diamacoune Senghor, chef de la rébellion du Mouvement des forces démocratiques de Casamance (MFDC).

Un autre foyer de conflit entre des Casamançais et la Guinée-Bissau s'est développé en avril 2007.

En 1989, la Mauritanie et le Sénégal ont rejeté violemment et respectivement les communautés du pays voisin alors que la plupart étaient nés depuis longtemps dans leur nouveau pays d'adoption et s'étaient bien implantés dans le tissu social et économique. Selon le HCR, des réfugiés sont toujours établis le long du fleuve Sénégal. En 2007, le président de la Mauritanie a déclaré lors de sa campagne, être en faveur du retour de ses compatriotes vivant au Sénégal et au Mali contre leur gré.

Le Sénégal est l'un des pays les plus stables d'Afrique car il n'y a jamais eu de coup d’État, et le « modèle sénégalais » était souvent mis en avant dans le passé, même si Amnesty International dénonce encore quelques arrestations à caractère politique.
Le Sénégal est une république démocratique (présence de plusieurs partis politiques). Le régime est semi-présidentiel car à l'indépendance, le Sénégal a adapté le modèle politique français de 1958 comme d'autres pays africains qui étaient membres de l'AOF. La constitution du Sénégal date de 1959, elle a été révisée dès 1960 par Léopold Sédar Senghor à la suite d'un référendum. Plusieurs révisions vont se succéder notamment celle de 1963 qui instaure le régime présidentiel (à cette époque : suppression du Premier ministre) puis celle de 2001 qui ramène le mandat présidentiel de sept ans à cinq ans (le Sénat sera supprimé puis rétabli en 2007).
Le président de la République est le chef de l'État, élu au suffrage universel direct pour une durée de cinq ans renouvelable une fois. Il nomme le Premier ministre qui choisit à son tour les ministres de son cabinet et propose leur nomination au président de la République.

Le premier président est Léopold Sédar Senghor, leader charismatique et poète de renom. En 1981 son Premier ministre Abdou Diouf prend sa succession, mais en 2000 le Parti démocratique sénégalais l'emporte avec Abdoulaye Wade, réélu en 2007. L'élection présidentielle de 2012 voit la victoire de Macky Sall face à Abdoulaye Wade.

Le Parlement du Sénégal est doté d'une chambre: l'Assemblée nationale.Instituée le 20 août 1960, l’Assemblée nationale accueille 150 députés, élus au suffrage universel direct pour une durée de cinq ans. Le scrutin est majoritaire à un tour au niveau des départements à concurrence de 90 députés et proportionnel sur une liste nationale à concurrence de 60 députés. L’Assemblée est aujourd’hui présidée par Moustapha Niasse, installé le 31 juillet 2012 à la suite des législatives du , marquées par une très large victoire de la coalition présidentielle Bennoo Bokk Yakar. Les élections législatives sénégalaises de 2007 se sont soldées par une très large victoire de la coalition présidentielle, alors le PDS, mais près des deux tiers des électeurs ne s’étaient pas rendus aux urnes, notamment en raison d’un mot d’ordre de boycott de la part des partis d’opposition.
Le Sénat, supprimé en 2001 à la suite d’un référendum constitutionnel, a été rétabli en mai 2007 puis supprimé à nouveau en 2012 après l'élection présidentielle. Les sénateurs étaient au nombre de 100, 35 étaient élus au suffrage indirect dans les départements et les 65 autres étaient désignés par le chef de l’État. Le Sénat a eu comme dernier président Pape Diop, ancien maire de la ville de Dakar.

La loi sur la décentralisation, mise en application en janvier 1997, accorde des pouvoirs significatifs aux assemblées régionales.

Supprimée en 1992, la Cour suprême du Sénégal avait été remplacée par trois organes spécialisés, la Cour de cassation, le Conseil d'État et le Conseil constitutionnel, assez semblables à leurs homologues français.

En août 2008 une loi organique recrée une Cour suprême par la fusion entre la Cour de cassation et le Conseil d'État.

Le Conseil Constitutionnel comprend cinq membres qui sont nommés par décret pour six ans non renouvelables, dont un président et un vice-président. Il est partiellement renouvelé tous les deux ans, à raison de deux membres au maximum. Son rôle est de contrôler les élections législatives et de vérifier la constitutionnalité des lois et les engagements internationaux.

Le Sénégal a aboli la peine de mort le . Les rapports homosexuels sont passibles de peines de prison.

Il existe une grande diversité linguistique à travers les langues au Sénégal. La Constitution de 2001 a reconnu au français le statut de langue officielle et à six langues celui de langues nationales, le wolof — langue parlée par le plus grand nombre de personnes même appartenant à d'autres ethnies — le sérère, le peul, le mandingue, le soninké et le diola. Cinq autres langues vernaculaires ont été promues peu après : le hassaniyya, le balante, le mancagne, le noon et le manjaque ; suivies de trois autres langues : le ménik, l’oniyan et le saafi-saafi ; Au total ce sont 21 langues sur 27 répertoriées qui bénéficient du statut de langue nationale au Sénégal.

Le Sénégal est membre de l'assemblée parlementaire de la francophonie depuis 1967 ainsi que de l'organisation internationale de la francophonie depuis 1970. Le français est la langue officielle et de l'administration, parlée par 29 % des Sénégalais. L'enseignement de l'école publique se fait en français. Le wolof, parlé par 93.5 % de la population, est la langue qui compte le plus de locuteurs, principalement dans les grands centres urbains. Elle est très utilisée dans le commerce et sert de langue de communication entre personnes parlant des langues différentes. L'arabe est aussi présent dans le pays, il est souvent utilisé par les dignitaires religieux. La plupart des Sénégalais parlant cette langue ont fait des études de théologie islamique.

Les régions sénégalaises de Dakar, Diourbel, Fatick, Kaffrine, Kaolack, Kedougou], Kolda, Louga, Matam, Saint-Louis, Sedhiou, Tambacounda, Thiès et de Ziguinchor sont membres de l'Association internationale des régions francophones.

Le Sénégal a une importante façade maritime à l'ouest avec l'océan Atlantique ( de côtes). Le fleuve Sénégal constitue une frontière au nord avec la Mauritanie et à l'est avec le Mali. Au sud-est, la frontière avec la Guinée est traversée par les contreforts de la montagne du Fouta-Djalon et au sud-ouest avec la Guinée-Bissau par une forêt tropicale. La Gambie forme une enclave et sépare la région de la Casamance du reste du pays.

Le territoire sénégalais est compris entre 12°8 et 16°41 de latitude nord et 11°21 et 17°32 de longitude Ouest. Sa pointe ouest (la presqu'île du Cap-Vert) constitue la partie la plus occidentale de toute l’Afrique continentale. La ville de Dakar qui y est située bénéficie du climat le plus doux du pays.

Le pays s’étend sur .

Le bassin sédimentaire sénégalais constitue un segment du bassin sénégalo-mauritano-guinéen, vaste bassin côtier de marge continentale passive. Ce bassin sédimentaire est limité à l’est et au sud-est par la chaîne des Mauritanides et au sud, par le Bassin de
Bové. Long de , dans son extension maximale (Mauritanie-Guinée-Bissau), ce bassin atteint une largeur maximale d’environ à la latitude de Dakar.

Appuyé sur le Craton ouest-africain, le bassin côtier accumule une puissante série sédimentaire, d’origine principalement marine, qui débute au Trias-Lias et se termine au Miocène. Depuis la limite orientale du bassin, proche de Bakel, les dépôts s’épaississent vers l’ouest, d’abord progressivement, puis, passant une flexure localisée entre 15°30’W et 16°30’W (Spengler et al., 1966 ; Latil-Brun et Flicoteaux, 1986), leur épaisseur augmente rapidement, pour atteindre, à Dakar, des épaisseurs de plus de 6000 mètres à 7000 mètres (Castelain, 1965 ; Spengler et al., 1966). En Casamance, les profondeurs estimées dépasseraient huit mille mètres.

Malgré le caractère apparemment subhorizontal des couches, les données de l'exploration pétrolières indiquent une forte structuration et une importante compartimentation des dépôts, dont le Horst de Diass donne un aperçu. Au Sénégal, la série du Mésozoïque-Cénozoïque affleurante se limite aux niveaux stratigraphiques les plus supérieurs, n’interceptant les roches d'âge Campanien que très marginalement alors que le Maastrichtien est mieux exposé dans le Horst de Diass, malgré la présence d’une puissante cuirasse latéritique.

Les séries cénozoïques sont plus largement représentées à l’affleurement, exposées dans les falaises de la presqu’île du Cap-Vert et aussi dans la falaise à l’ouest et au sud de Thiès et marginalement dans le Sine, où elles sont surtout connues en puits. Les plus beaux affleurements se localisent à la marge passive atlantique. Au cœur du bassin la série sédimentaire est masquée par la cuirasse latéritique fini-Tertiaire et, vers le nord-ouest, par les dépôts de sédiments éoliens quaternaires. Dans cette région centrale et orientale, les seuls affleurements tertiaires connus sont limités aux rives du lac de Guier et à la haute vallée du fleuve Sénégal, dans la région de Matam, les grès du «Continental terminal» (renommé "Formation du Saloum" en 2009) venant largement sceller et masquer la série marine du Paléogène. En Casamance, il est connu, en forage, que la série marine monte jusque dans le Miocène.

Du volcanisme du Miocène apparaît régionalement dispersé dans la presqu’île du Cap-Vert et la région de Thiès ; il est représenté par des laves et des tufs coiffés par la cuirasse ferrugineuse cuirasse latéritique d'âge fini-Pliocène (Crévola, 1994). Le volcanisme quaternaire, polyphasé, est restreint à la pointe de la presqu’île du Cap-Vert.

De récentes cartes géologiques du Sénégal (2009) viennent d'être élaborées dans le cadre de la Coopération Sénégal – Union européenne, suivant les procédures du neuvième Fonds européen de Développement (FED) pour le compte de la Direction des Mines et de la Géologie (DMG) et existent aux échelles de 1/500 000 pour les trois quarts du territoire et de 1/200 000 le long du fleuve Sénégal.

Le climat est de type désertique dans le Nord, et de type tropical dans le Sud, avec :

Les températures suivant les saisons : 

Sur le littoral, la mer (avec le courant canarien froid) apporte de la fraîcheur, les températures sont de l'ordre de à mais le centre et l'Est du Sénégal peuvent avoir des températures allant jusqu’à .

Pendant l'hiver en Europe, le Sénégal devient une destination appréciée permettant de développer une activité touristique.

De manière générale, l'Ouest du pays, représenté par le littoral, connaît des températures plus fraîches que l'Est grâce à l'océan. Le centre et l'Est du pays connaissent des températures continentales très chaudes pendant la journée, et fraîches la nuit.

Du Nord au Sud, il existe cinq types de domaines climatiques appartenant au climat tropical :

En 1960 le premier découpage administratif issu de l'indépendance avait créé une certaine disparité entre les sept régions d'origine – celle du Sénégal oriental étant alors onze fois plus étendue que celle du Cap-Vert. Ce déséquilibre a été corrigé par plusieurs réformes successives et notamment par un décret de 1996, dans le cadre de la politique de décentralisation qui a transféré aux collectivités locales certaines compétences d'abord détenues par le pouvoir central.

L'organisation territoriale mise en place en 1996 a subi plusieurs retouches dans l'intervalle, avec la création de la région de Matam en 2001, celle du département de Koungheul en 2006 ou encore, en 2008, l'élection des départements de Kaffrine, Kédougou et Sédhiou en régions à part entière, celle de 10 localités en départements, ainsi que la création de nouvelles communautés rurales et de nombreuses communes.

En 2009, le Sénégal compte 14 régions, 45 départements, 46 communes d'arrondissement, 113 communes de ville et 370 communautés rurales. Dirigés par un chef, les villages restent les cellules de base de cette organisation. On en dénombrait lors du recensement de 1988.


Parcs et réserves naturels représentent 8 % du territoire national. Ils jouent un rôle majeur dans la préservation de l'environnement et contribuent de manière significative à l'essor touristique.

Dans ces aires protégées on dénombre au total 169 espèces de mammifères et 540 espèces d'oiseaux.

Le Sénégal compte six parcs nationaux : le Parc national du Niokolo-Koba dans l'Est du pays ; le Parc national des oiseaux du Djoudj ; le Parc national de la Langue de Barbarie dans la région de Saint-Louis ; le Parc national des îles de la Madeleine au large de Dakar ; le Parc national du delta du Saloum dans le Sud, ainsi que le Parc national de la Basse-Casamance, fermé depuis quelques années en raison des troubles dans la région.

Le pays compte également une trentaine de réserves naturelles de plus petite taille, telles que le Parc forestier et zoologique de Hann à Dakar, la Réserve de Guembeul, la Réserve de Bandia, la Réserve naturelle de Popenguine ou l'Aire marine protégée de Bamboung.

La plupart des études démographiques réalisées au Sénégal s'appuient sur les trois recensements effectués en 1976, 1988 et surtout 2002. En 2004, la Direction de la Prévision et de la Statistique, devenue Agence Nationale de la Statistique et de la Démographie (ANSD) depuis 2006, a publié en outre des « Projections de populations du Sénégal issues du recensement de 2002 » anticipant l'évolution probable de la population du pays jusqu'en 2015.
Selon ces sources, la population du Sénégal – qui comptait environ 1 million d'habitants en 1900 et 2,8 millions au moment de l'indépendance en 1960 – s'élèverait aujourd'hui à personnes (estimation au 31/12/2007) et pourrait atteindre pour 2018. Cette population croît donc très rapidement, avec un taux de fécondité supérieur à quatre enfants par femme.

On observe une grande diversité ethnique : Wolofs (53,8 %), Peuls (18,5 %), Sérères (11,5 %), Diolas (4,7 %), Malinkés (2,6 %), Soninkés (0.8 %) Manjaques (0.6 %) et quelques autres ethnies moins nombreuses et plus localisées, sans compter les Libanais, les Marocains, les Européens et les Chinois, assez présents en milieu urbain. Fin 2007, Français étaient inscrits dans les registres consulaires (y compris les binationaux).

Depuis longtemps la population était plutôt concentrée sur la façade atlantique, mais l'exode rural a accru l'inégalité de cette répartition. Désormais un Sénégalais sur quatre vit dans la presqu'île du Cap-Vert et la capitale est au bord de l'asphyxie.

Outre celle de Dakar, les régions les plus urbanisées sont Ziguinchor, Thiès et Saint-Louis. Les moins urbanisées sont celles de Kolda, Matam et Fatick. C'est dans la région de Tambacounda que l'on trouve la plus faible densité (11 habitants au km).

Selon les estimations pour 2017, les centres urbains régionaux de plus de habitants sont Touba ( – qui a connu une croissance spectaculaire –, Thiès (), Kaolack (), Mbour (), Saint-Louis (), Ziguinchor () et Diourbel ().

En 2007, le Sénégal abritait environ réfugiés et demandeurs d'asile, dont plus de étaient mauritaniens ayant fui la persécution ethnique, ainsi que certains du Libéria, de la Sierra Leone et d’autres pays.

Si le Sénégal accueille aussi des migrants, nombreux, saisonniers ou non, des pays limitrophes ou lointains, une forte communauté sénégalaise vit à l’extérieur du pays. Cette diaspora représente une ressource essentielle pour le pays, à la fois économique et identitaire. Les NTIC favorisent le maintien des liens familiaux et des réseaux traditionnels.

Ce sont principalement des hommes jeunes qui s’installent en Europe, surtout en France, ou en Amérique du Nord, notamment au Québec avec un projet de retour vers le pays au bout de quelques années. L’accroissement de l’immigration clandestine dans les pires conditions, notamment vers les îles Canaries, est une préoccupation majeure pour le Sénégal et les pays d’accueil.

Les plus désespérés veulent ignorer les risques, sensibles à la réussite de quelques-uns, et notamment de personnalités de la diaspora — nées au Sénégal ou de parents sénégalais — particulièrement dans les milieux artistiques ou sportifs.

D’abord pays d’émigration rurale soninké et hal pulaar de la vallée du fleuve Sénégal à destination de la France à partir de l'époque coloniale, puis des pays de la sous-région, le Sénégal a connu une émigration plus diverse, originaire à la fois du centre-ouest du pays et des grandes villes, lesquelles ont fait figure de lieux de passage et de transit vers l’international à partir des indépendances.

L’instabilité politique et économique des pays voisins et la fermeture des frontières européennes ont eu pour effet de modifier le système de migration tournante (ou noria) en une installation plus durable. Le contrôle de plus en plus strict des frontières françaises, à l’origine destination privilégiée, a conduit les flux migratoires à se redéployer vers de nouvelles destinations : en priorité l’Italie, l’Espagne mais aussi les États-Unis, le Canada, et plus récemment la Chine.

Le 15 avril 2010, Human Rights Watch a publié un rapport exhortant les autorités sénégalaises à règlementer toutes les écoles coraniques fréquentées par des dizaines de milliers d'enfants. Ces enfants talibés, estimés à garçons, subissent parfois des abus qui les incitent à l'exil.

Il existe près d'un million d'immigrés guinéens au Sénégal.

Cinq villes de grande taille : Dakar, Pikine, Guédiawaye, Rufisque et Thiès ont le statut de "ville" et sont divisées en communes d'arrondissement.

Jusqu'en 1814, les comptoirs coloniaux ne devaient avoir qu'une fonction commerciale et avaient pour interdiction de développer une activité de production. « Pas même un clou » selon Colbert. À partir de 1814, au contraire les colonies ont une obligation d'autosuffisance, cette obligation est confirmée en 1866.

Le Sénégal possède la quatrième économie de la sous-région ouest-africaine après le Nigeria, la Côte d'Ivoire et le Ghana. Compte tenu de sa situation géographique et de sa stabilité politique, le Sénégal fait partie des pays africains les plus industrialisés avec la présence de multinationales qui sont majoritairement d'origine française et dans une moindre mesure américaine. De plus, le Sénégal est l'un des pays les plus industrialisés de l'ensemble ouest-africain puisqu'on y retrouve plusieurs multinationales. La main d'œuvre du pays se divise comme ceci : 15,5 % est consacré à l'agriculture, 21,7 % aux industries et 62,3 % sont consacrés aux services.

L'économie sénégalaise est principalement tournée vers l'Europe et l'Inde. Ses principaux partenaires économiques sont la France, l'Inde, l'Italie. Cependant, depuis plusieurs années, la Chine est un partenaire de plus en plus grandissant comme en témoignent les sommets Chine-Afrique.
Comparé aux autres pays du continent africain, le Sénégal est très pauvre en ressources naturelles ; ses principales recettes proviennent de la pêche, du tourisme et des services :

Le Sénégal est membre de l'Union économique et monétaire ouest-africaine.
En 1994, la monnaie est dévaluée et une politique de libéralisation est activement menée. Le Sénégal essaye de rentrer dans les conditions requises par le Fonds monétaire international (FMI) afin de bénéficier d'un allègement de la dette pour le développement du pays. Depuis 2006, le Sénégal est dans la liste des pays éligibles.

Les difficultés économiques dues au poids de la dette ont entraîné un renforcement du syndicalisme :
L’Office National de Lutte contre la Fraude et la Corruption (OFNAC) créé en décembre 2012 pour lutter contre d’éventuelles tentatives de corruption. Composé de onze personnes nommées par le Président de la République.

L'aéroport international de Dakar-Léopold Sédar Senghor était le principal point d'entrée aérien vers le Sénégal jusqu'à son remplacement le 08 décembre 2017 par l'aéroport Blaise Diagne. Le 25 mai 1971, l'avion supersonique Concorde fait un premier vol de démonstration Paris-Dakar en (dont en vol supersonique) et le 21 janvier 1976 ouvre pour la première fois sa ligne commerciale Paris-Dakar-Rio. Le président Senghor assiste à son arrivée à l’aéroport de Dakar ainsi que les premiers passagers supersoniques de l'histoire de l'aviation. Le avril 1982, c'est la fin de la liaison Paris-Rio.

Créée en 2000, la compagnie aérienne Air Sénégal International, filiale du groupe Royal Air Maroc, proposait depuis le des destinations vers l'Europe et l'Afrique. Membre de l’IATA depuis le 28 mai 2002, elle fut sacrée meilleure compagnie aérienne africaine en 2003. À la suite de difficultés financières et de différends entre ses principaux actionnaires, Royal Air Maroc et l'État sénégalais, elle a cependant arrêté tous ses vols le .Une nouvelle compagnie baptisée Sénégal Airlines, dont l'État sénégalais est actionnaire minoritaire, a été créée en octobre 2009. Cette nouvelle compagnie dessert à partir de Dakar, et à compter du début 2010, une vingtaine de destinations africaines. Senegal Airlines a annoncé en novembre 2009 à l'occasion du salon de Dubai avoir commandé 2 Airbus A330 et 4 Airbus A320. Mais en 2016, l'État retire la concession de commerce de la compagnie à cause du déficit budgétaire de l'entreprise.

Le réseau routier est bon dans l'ouest, mais se dégrade en allant de plus en plus à l'intérieur du pays. Le réseau de transport est bien développé dans les grandes villes avec des taxis, des bus et/ou des « cars rapides » en plus ou moins bon état. Dans les banlieues et les villes secondaires ce sont des taxis collectifs, des « cars rapides » et des calèches qui servent de transport. À l'intérieur du pays, les taxis-brousses sont utilisés pour se déplacer entre petites villes et villages. Le transport interurbain est assuré par des berlines à sept places, des bus interurbains et des cars blancs appelés "Ndiaga Ndiaye "qui peuvent être pris en allant dans les gares routières"."

La gare de Dakar (gare de train) est la plus ancienne du Sénégal. Elle n'offre plus que la liaison Dakar-Thiès pour les voyageurs, la liaison avec Bamako (au Mali) étant désormais réservée au transport de marchandises.

Le transport maritime est constitué de chaloupes pour rejoindre l'île de Gorée à partir de Dakar, de la liaison maritime Dakar-Ziguinchor assurée par le Consortium sénégalais d’activités maritimes, de bateaux pour des croisières sur le fleuve Sénégal (comme le Bou El Mogdad). Il est constitué aussi de gros bateaux de transport de marchandises qui bénéficient du Port autonome de Dakar, qui est l'un des trois ports en eau profonde d'Afrique de l'Ouest, et de son terminal pour les conteneurs.
Les réseaux sont plus denses à l'Ouest du pays le long du littoral mais la circulation des marchandises et des personnes est particulièrement difficile vers Dakar et la presqu'île du Cap-Vert. Les infrastructures sont plus rares dans le Sénégal oriental et le désenclavement de ces régions constitue également un défi car les moyens de transport restent souvent traditionnels à l'intérieur du pays.

De gros efforts sont effectués au niveau des équipements. Ainsi de nombreux projets sont en cours. Par exemple, le futur train express régional qui est en construction et reliera la capitale Dakar au nouvel aéroport international Blaise Diagne. Sa mise en service est prévue fin 2019. 

Par ailleurs, la construction d'une autoroute à péage entre Dakar et Diamniadio (), terminé le 10 août 2013, permet dorénavant de rallier Dakar à Rufisque en moins de trente minutes. À moyen terme, elle permettra de créer de nouvelles zones d'habitations grâce à ses nombreuses bretelles de sortie afin de désengorger Dakar. Deux autres tronçons autoroutiers sont terminés de Diamniadio à l'aéroport international Blaise Diagne (nouvel aéroport international Blaise Diagne inauguré le 7 décembre 2017) et dudit aéroport à Sindia. 

D'autres projets sont à l'étude ou en travaux dont l'aménagement de Saint-Louis afin d'en faire un port de cabotage ; l'aménagement du port de Ziguinchor pour recevoir des conteneurs ainsi que la construction de nouveaux tronçons autoroutiers menant vers Thiès puis l'Est et le Sud du pays (ouvertures prévues fin 2018 ; 2019 ; 2020 et ultérieurement de plusieurs sections menant à la constitution d'un réseau de plusieurs centaines de kilomètres d'autoroutes).

La culture est au début et à la fin du développement.

Il existe une grande diversité linguistique à travers les langues au Sénégal. La Constitution de 2001 a reconnu au français le statut de langue officielle et à six langues celui de langues nationales, le wolof — langue parlée par le plus grand nombre de personnes (90 % des Sénégalais) même appartenant à d'autres ethnies — le sérère, le peul, le mandingue, le soninké et le diola. Cinq autres langues vernaculaires ont été promues peu après : le hassaniyya, le balante, le mancagne, le noon et le manjaque ; suivies de trois autres langues : le ménik, l’oniyan et le saafi-saafi ; d'autres ajouts de langues codifiées sont en cours. Au total ce sont près d'une vingtaine de langues qui pourraient bénéficier du statut de langue nationale au Sénégal.

La littérature sénégalaise a longtemps été connue dans le monde surtout à travers Léopold Sédar Senghor, à la fois poète et homme d'État, chantre de la négritude et figure emblématique de la francophonie. Parmi les autres auteurs désormais classiques figurent notamment les romanciers Cheikh Hamidou Kane, Birago Diop, Boubacar Boris Diop, mais aussi Ousmane Sembène qui portera à l'écran quelques-uns de ses propres romans. De leur côté les femmes sont particulièrement actives, voire incisives. En 1979 Aminata Sow Fall, dans « La Grève des bàttu », dépeint dans sa satire politique un petit peuple de mendiants se mobilisant contre le sort qui lui est fait. En 1980, Mariama Bâ décrit avec une grande sensibilité la société polygame dans « Une si longue lettre ».En 1978, Awa Thiam écrit le Best-Seller, ""La Parole aux négresses"." En 1996, le poète Alioune Badara Coulibaly, proche du poète Léopold Sédar Senghor, publie « Bon anniversaire, Sédar », rendant hommage au chantre de la Négritude pour ses 90 ans. Ce poète est à son cinquième livre de poésie avec le dernier intitulé « Rayons de soleil sur Saint-louis»(2009), en 1997, la romancière Fama Diagne Sène a obtenu le Grand Prix des Lettres du Sénégal avec son roman "Le chant des ténèbres". Plus récemment, Fatou Diome rencontre le succès avec « Le Ventre de l'Atlantique » (2004), un roman qui met en scène, souvent avec humour, les rêves d'évasion des jeunes Sénégalais.

Tradition et modernisme, marquent l'architecture du Sénégal. L'habitat traditionnel, sobre et fonctionnel mais plus éphémère, utilise les matériaux locaux (pierre, terre, bois, paille), comme pour les cases peules ou les cases à "impluvium" casamançaises. La période coloniale a laissé des traces comme à Gorée ou à Saint-Louis, et ces sites figurent aujourd'hui sur la liste du patrimoine mondial de l'UNESCO. Aujourd'hui, l'architecte Pierre Goudiaby Atepa a conçu plusieurs réalisations contemporaines, telle la Porte du Troisième millénaire à Dakar. À noter aussi de nouvelles constructions telles que le tunnel de la corniche ouest et le monument de la Renaissance Africaine, inauguré en 2010. L'autoroute à péage est en cours d'exécution.

Les arts plastiques ont été soutenus pendant la période où le président poète L.S. Senghor était au pouvoir à travers le mécénat d'état. Par la suite, ses successeurs ont eu des difficultés à poursuivre cette politique à cause de la crise économique. Diverses initiatives privées se sont développées afin de soutenir les artistes. Ces arts sont à l'honneur à travers le sculpteur Ousmane Sow de renommée internationale.

La série de timbres émise sous l’intitulé « Élégance sénégalaise » célèbre ces femmes belles et séduisantes qui impressionnaient déjà les observateurs d’autrefois et inspiraient les poètes : femmes peules au port altier, linguères de sang royal, signares fortunées de Sénégal ou de Gorée. Même avec de modestes budgets, le souci de l’apparence perd rarement ses droits au Sénégal : boubous, coiffures et bijoux sont choisis avec soin et fréquemment renouvelés. Qu'ils portent l'habit traditionnel ou le costume, les hommes aussi sont attentifs à leurs tenues. En contrepoint, les tenues décontractées de certains touristes déconcertent parfois.

Dans le prolongement des activités anciennes de tissage et de teinture, l’industrie de la mode s’est tout naturellement épanouie dans le pays, avec quelques personnalités de premier plan telles que Collé Ardo Sow, Claire Kane et surtout Oumou Sy, à la fois costumière, styliste, décoratrice et femme d’affaires au rayonnement international.

Le cinéma sénégalais est l'un des plus anciens d'Afrique. Ses représentants les plus connus sont les cinéastes Ousmane Sembène — également romancier — et Djibril Diop Mambéty, auxquels il faut ajouter Tidiane Aw, ou Safi Faye, réalisatrice de films documentaires. Ces productions sont souvent mieux appréciées à l'étranger qu'au Sénégal où beaucoup de salles ont fermé, concurrencées par le marché plus florissant de la vidéo. On remarque également que nombre de films d'origines diverses ont été tournés dans ce pays au climat propice et aux paysages des plus photogéniques.
Les grands noms de la musique sénégalaise contemporaine sont : Youssou N'Dour, auteur-compositeur, musicien et interprète de renommée internationale. Ashraff 30, chanteur reggae, auteur et compositeur Baba Maal est un auteur-compositeur, interprète qui se produit internationalement ainsi que Ismael Lô auteur-compositeur, interprète Omar Pène auteur-compositeur et interprète et Coumba Gawlo Seck, auteur-compositeur.

Djembé, sabar, kora, xalam, tambour d'aisselle et balafon font partie des instruments traditionnels toujours très populaires. Parmi les instruments de percussion, le sabar et le mbalax désignent à la fois l'instrument de musique, un style de musique et une danse. Ce sont des sons typiques de la culture sénégalaise. Thione Seck qui est un auteur-compositeur-interprète de mbalax a su adapter la tradition et la modernité : il est apprécié par des fans de tous âges au Sénégal. Pape Diouf et Ndongo Lô (décédé le 16 janvier 2005), Ismael Lô (appelé Bob Dylan sénégalais)sont également des artistes de l'univers du mbalax. Cheikh Lô, auteur-compositeur, musicien et interprète a su allier le mbalax et des influences reggaes. À noter, Viviane Ndour, meilleure artiste sénégalaise 2006 et reine du mbalax, une des rares artistes féminines à avoir su se faire une place. Les instruments à corde telle que la kora connue dans toute l'Afrique de l'ouest sont à présent connus en dehors du continent à travers des groupes de jazz ou de world musique.

Dans « Un grain de vie et d'espérance », la romancière Aminata Sow Fall met en scène la place essentielle occupée par la cuisine sénégalaise dans la culture et la vie quotidienne du pays. La « teranga », ce sens de l’hospitalité cher au cœur des Sénégalais, s'exprime souvent autour d'un plat unique réunissant la famille et les amis. Relativement peu connue à l’étranger en dehors des communautés issues de l'immigration et de quelques restaurants de grandes villes, la cuisine sénégalaise a attiré l'attention des médias avec la publication du livre de Youssou N'Dour, « La cuisine de ma mère », vibrant hommage aux valeurs familiales comme aux plats relevés et longuement mijotés.

Cette cuisine présente quelques similitudes avec celles des pays d'Afrique de l'Ouest, mais elle accueille d'autres influences, venues d'Afrique du Nord, du Liban, de France ou du Portugal. Elle fait un large usage du poisson et des céréales (riz et mil) dans les plats nationaux, comme la thiéboudienne, le yassa de poulet, le thiéré, le maffé, la soupe kandia ou cette préparation plus sophistiquée qu’est le mulet farci à la saint-louisienne. Dans un pays majoritairement musulman, le thé, la tisane de kinkeliba et le bissap l’emportent sur les alcools, mais les bières locales – Flag ou Gazelle – et le vin de palme en Casamance ont aussi leurs adeptes.

L'éducation au Sénégal est l'une des plus avancées sur le continent. Le Sénégal peut se targuer d'avoir un enseignement de qualité avec des équivalences de diplômes des universités étrangères les plus prestigieuses tant en France qu'aux États-Unis.

Ceci permet également des échanges avec des étudiants qui viennent étudier au Sénégal dans le cadre d'études spécifiques sur le pays ou des étudiants sénégalais qui partent à l'étranger afin de diversifier leurs connaissances dans le cadre de recherche.

La population étant très jeune, la demande en formation est très forte sans compter la jeunesse des autres pays africains plus pauvres qui tente de terminer ses études à Dakar.

Malgré un taux de réussite au baccalauréat similaire en 2000 (37,67 %) et en 2011 (38,4 %), le nombre de bacheliers est passé dans l'intervalle de à . Et naturellement, 80 % de ces bacheliers ont cherché à s'inscrire à la faculté, « objet de promotion sociale et de fierté, pour lequel les familles et les étudiants sont prêts à réaliser d'énormes sacrifices », explique le chercheur Olivier Provini, qui travaille sur les réformes universitaires africaines. Le problème majeur auquel font face ces nombreux bacheliers est l’expression française : durant toute leur cheminement scolaire, ils sont doivent jongler entre le français et la langue nationale, le wolof.

De nouvelles universités publiques ont été créées à Bambey, Thiès et Ziguinchor et les salaires des professeurs ont été revus à la hausse sous la présidence de Abdoulaye Wade. Ce qui a permis de freiner l'exode des cerveaux universitaires et à encourager le retour de certains qui étaient en Europe, aux États-Unis et ailleurs en Afrique. L'université de Kaolack va bientôt ouvrir ses portes également sous la présidence du nouveau président de la république Macky Sall. Cette nouvelle université va permettre le dés-engorgement des autres universités du pays mais aussi l'orientation d'un grand nombre d'étudiants. Ceci va aussi permettre le développement des autres régions du pays.

Le Sénégal est membre de l'organisation de la Francophonie (actuellement dirigée par son ancien Président Abdou Diouf, réélu en 2010 à la tête de cette organisation internationale) et est devenu un pays observateur au sein de la communauté des pays de langue portugaise (CPLP). alors que le portugais n'est parlé que par une très faible part de la population. L'inauguration de la deuxième université de Dakar et de celle du Sine Saloum est prévue début 2017.

Le rallye Dakar (ou « Le Dakar », anciennement rallye Paris-Dakar) est un rallye-raid professionnel, qui se dispute chaque année au mois de janvier, principalement sur le continent Africain avec arrivée en banlieue de Dakar sur une belle plage de sable face à l'océan Atlantique. Mais à la suite de morts d'enfants de villageois, la contestation est devenue internationale grâce au CAVAD, Collectif pour les Victimes anonymes du Dakar qui réunit des associations françaises, africaines, portugaises, espagnoles, marocaines, maliennes, guinéennes et sénégalaises.
Le football est un sport très apprécié des Sénégalais. L'équipe du Sénégal de football, dont les joueurs sont surnommés les Lions de la Téranga, est affiliée à la Fédération sénégalaise de football et à la FIFA depuis 1962. En 2002, au Mali, elle a manqué de peu la coupe d'Afrique face au Cameroun en finale et demi-finaliste de l'édition 2006. Elle se qualifie à la même année (2002) pour la phase finale de la coupe du monde de la FIFA, organisée en Corée et au Japon. L'équipe du Sénégal bat la France (championne du Monde et d'Europe en titre) en match d'ouverture de la coupe du monde et se qualifie pour la première fois de son histoire en quart de finale de la coupe du monde en battant la Suède 2 buts à 1 et devient par la suite la deuxième équipe d’Afrique à atteindre les quarts de finale après le Cameroun en 1990. Parmi les grands footballeurs sénégalais, on peut citer El-Hadji Diouf, Henri Camara, Khalilou Fadiga, Habib Beye, Tony Sylva, Mamadou Niang, Omar Daf, Ferdinand Coly ou, dans le passé, Jules Bocandé, mais aussi le manager Pape Diouf, ex-président de l'OM.

La lutte sénégalaise est une pratique ancrée dans la tradition. La lutte sénégalaise n'a rien perdu de sa popularité, à travers des combats aussi brefs que spectaculaires. Ce sport est incarné par d'impressionnants champions tels que Yékini, qui, en 2005, l'a emporté sur Tyson, un redoutable adversaire qui avait su conserver le titre pendant près de cinq ans, mais sera battu à deux reprises par un autre poids lourd sénégalais, Sérigne Dia, dit Bombardier. D'importants enjeux économiques sont désormais liés à ce sport. Et les cachets mis en jeu peuvent atteindre de nos jours près de FCFA, soit dollars. Tradition destinée à célébrer la fin des récoltes, la lutte est devenue le sport national, détrônant même le football. Il se pratique partout : clandestinement, sur les terrains vagues, dans des tournois amateurs et dans des championnats professionnels médiatisés. La version sénégalaise, « avec frappe », autorise les coups de poing pour surprendre l'adversaire. Les combattants sont les héritiers d'une culture : ils se préparent en s'aspergeant de potions concoctées selon les recommandations des marabouts.
La boxe a connu ses lettres de gloire avec Battling Siki (1897-1925), champion du monde à 25 ans et premier Africain à remporter un titre mondial de boxe, reste dans toutes les mémoires. Plus près de nous, le Franco-sénégalais Souleymane Mbaye est devenu champion de France WBC des lourds-légers. Léonard Tavarez fut aussi champion de France des poids légers en 1969.Le prometteur Mouhamed Ali Ndiaye évoluant en Italie il est detenteur de plusieurs titres internationaux en petite catégorie.

Le basket-ball est moins prisé que le football, c’est cependant un sport très pratiqué, stimulé par les succès de son équipe nationale de basket-ball, les Lions du Sénégal et des joueurs tels que DeSagana Diop, Boniface N'Dong, El Kabir Pene, Maleye N'Doye, Xan Dalmeida ou Gorgui Sy Dieng qui fut en 2015 pour sa première année avec les lions à l'Afrobasket meilleur pointeur et meilleur rebondeur du tournoi. 
Noté que l'équipe fut éliminé en demi finale par le Nigeria futur vainqueur de la compétition. 
Sans oublier les braves lionnes(Aya Traoré, Fatou Dieng, Mame Marie Sy, Ndèye Sène, Aminata Dièye, Fatoumata Django, Fatou Binetou Thiam, Bineta Diouf, Mame Diodio Diouf, Awa Guèye, Aminata Nar Diop et Coumba Sarr) qui, après la médaille d'argent au Liban aux jeux de la francophonie en septembre 2009, ont remporté en octobre 2009 la coupe d'Afrique des nations (CAN) jouée à Madagascar. Et ont de même remporté la dernière coupe d'Afrique des nations en octobre 2015.apres avoir gagne la can de 2015 les lionnes du basket ont eu la promesse de letat de faire un palais omnisports dont luniguration est prevu en debut 2017. en 2016 les ravaux du palais omnisports sont lances a diamniadio.

Les autres sports sont également bien représentés : l'équipe sénégalaise de pêche sportive (Moussa Mbengue, Abdoulaye Kébé, Cyril Calendini, Dominique Dussaut) est devenue championne du monde en 2002 et 2003. Séduits par des conditions météorologiques souvent clémentes et les ressources côtières, les visiteurs viennent nombreux pour pratiquer les sports nautiques tels que la plongée sous-marine ou le surf, et la réputation des Almadies ou de la vague de Ouakam n'est plus à faire. De son côté, l'aviation de loisir – notamment l'ULM – permet une approche inédite des paysages, dans une contrée dépourvue de vraies montagnes. Cap Skirring et le Sine-Saloum constituent alors des destinations de choix.
Le skate commence peu à peu à prendre de l'importance avec des associations et tournois et aussi avec la création d'un skate park a Dakar.

Même si les médias au Sénégal bénéficient d’une situation relativement favorable par rapport à d’autres pays africains, leur dépendance à l’égard du pouvoir reste forte et des incidents surviennent occasionnellement, comme ce fut le cas lors de la répression d'une manifestation contre la vie chère en mars 2008.
L'Agence de Presse Sénégalaise (APS), un organisme autonome créé en 1959, détient le monopole de la diffusion des informations distribuées au Sénégal par les agences de presse mondiales. En 2015, le Sénégal situe à la place – sur 180 pays – du classement mondial de la liberté de la presse établi chaque année par Reporters sans frontières.

La presse écrite sénégalaise a débuté au cours du pendant la période coloniale :

Aujourd’hui les principaux titres de la presse sont :
Économique et maniable, la radio constitue aujourd’hui le seul véritable média de masse et le moyen de communication le plus égalitaire au Sénégal. 

La télévision fait ses débuts au Sénégal en 1963 avec l'aide de l'UNESCO mais les émissions régulières ne débutent véritablement qu'en 1965. Grâce aux satellites, les plus fortunés peuvent capter les chaînes privées internationales, mais l'usage de la télévision reste souvent populaire et collectif.
Selon l'Observatoire sur les Systèmes d'Information, les Réseaux et les Inforoutes au Sénégal (OSIRIS), le nombre d’utilisateurs d’Internet était de en septembre 2007. Au 30 septembre 2007, il y avait abonnés, dont avec une connexion ADSL. On estime actuellement à plus de 800 le nombre de points d'accès à Internet dans le pays. En avril 2007, domaines « .sn » étaient déclarés et 540 sites étaient effectivement en ligne.

Dans un pays où la convivialité et la palabre sont au cœur de la vie familiale et sociale, la téléphonie mobile s’est développée très rapidement. Les deux opérateurs qui se partagent le marché sont la Sonatel (dont les services sont commercialisés depuis 2006 sous la marque Orange) et Tigo. À eux deux, ils comptaient abonnés le . On n'en dénombrait que pour la téléphonie fixe à la même date, mais il faut prendre en compte les télécentres disséminés sur tout le territoire.Un troisième opérateur, Expresso appartenant au soudanais Sudatel a été admis dans le marché et en 2010 un rapport de l'Union internationale des télécommunications et de l'Agence de régulation des télécommunications et des postes (Artp) a fait état de sept millions cinq cents (7,5 millions) abonnés.

Il existe plusieurs religions et croyances au Sénégal. La population sénégalaise est très majoritairement musulmane (environ 95 %). Cet Islam sunnite est essentiellement de tradition soufie et est connu pour sa tolérance et son ouverture à l'altérité. L’islamisation du pays date du (voir l’histoire du Sénégal), époque à laquelle les Almoravides conquièrent le Nord du Sénégal. Les deux principales confréries musulmanes dominante sont la Tidjaniyya et la Mouridiyya. L’apparition du christianisme est beaucoup plus récente. Aujourd'hui, les chrétiens (catholiques, évangéliques, protestants) représentent 4 % de la population du Sénégal. Finalement, l'animisme 1 %, avec ses rites et ses croyances, est toujours présent et est pratiqué principalement dans le Sud-Est du pays. Ailleurs il cohabite souvent avec les autres religions.
Le Sénégal est un modèle en matière de cohabitation pacifique religieuse. Lors des différentes fêtes religieuses, les Sénégalais ont pour habitude d'offrir des repas à leurs voisins pratiquant d'autres religions.

L'accès aux soins de santé au Sénégal reste inégal car le patient doit financer ses propres soins et il y a moins de dispensaires à la campagne. En 2015, l'espérance de vie à la naissance est de 68,6 pour les femmes et de 64,6 ans pour les hommes, soit de 66,7 ans pour la population globale et le taux de prévalence du SIDA est l'un des plus faibles d'Afrique avec 0,9 % de la population séropositive. Selon un rapport de l'OMS le Sénégal est le pays de la sous région le plus avancé dans l'organisation des soins de santé publique et privé de la sous région, plus en avance même que certain pays du Maghreb. La faculté de médecine de l'Université Cheikh-Anta-Diop et ses annexes sont dotées d'équipements à la fine pointe à l'image des pays européens, permettant ainsi des recherches telles que celles du professeur Souleymane Mboup sur le VIH.

Cependant quelques endémies restent préoccupantes, comme le paludisme ou les bilharzioses, et de grandes disparités subsistent dans le pays, si l'on songe par exemple que 70 % des médecins et 80 % des pharmaciens et des dentistes sont installés dans la capitale.

La médecine traditionnelle avec des tradipraticiens reste souvent la solution la moins onéreuse pour les plus démunis.

De nombreuses personnalités de renommée internationale ou ayant eu une influence historique, culturelle sont d'origine sénégalaise ou tout simplement nées au Sénégal. Parmi les plus connues : le Chevalier de Saint-George (musicien éminent à la cour de Louis XVI, grand escrimeur et guerrier engagé dans la Révolution, de mère sénégalaise), les érudits musulmans Oumar Tall, Malick Sy, Ayuba Suleiman Diallo (imam devenu esclave) et Ahmadou Bamba Mbacké, Limamou Laye, ainsi que Baye Niass, le premier député sénégalais en France Blaise Diagne, ou l'ancien député français puis président du Sénégal et membre de l'Académie française Léopold Sédar Senghor, l'historien physicien et anthropologue Cheikh Anta Diop, les frères Diouf (ex-membres du groupe québécois Les Colocs), ou encore le chanteur Youssou N'Dour, sans oublier le célèbre danseur et chorégraphe Maurice Béjart, quarteron, fils d'un métis de Saint-Louis, Gaston Berger, philosophe créateur de la prospective. L'œuvre de Maurice Béjart est actuellement poursuivie par son élève Germaine Acogny dans le Dialaw. Bineta Diop, née en 1950, est la fondatrice de l'ONG FAS femmes africa solidarité ; elle figure en 2011 au classement Time des 100 personnalités qui font bouger le monde.

Les personnalités politiques françaises Ségolène Royal, Rama Yade ainsi que les rappeurs Didier Awadi, Alioune Badara Thiam dit Akon, les joueurs de football Patrick Vieira et Patrice Évra, le chanteur Ycare, et encore deux membres de la Sexion d'Assaut Lefa et Adama Diallo sont nés au Sénégal. Les rappeurs français Booba (de par son père), Disiz la Peste, MHD ,16 art, Babass, Alpha 5.20, Dadoo, Mokobé (de par son père), la réalisatrice et scénariste Karine Silla et Sefyu sont d'origine sénégalaise, tout comme les joueurs de foot Gomis, Mamadou Sakho et quelques autres joueurs de l'Équipe de France.

Ordres nationaux :

Ordres ministériels/spécifiques :

Le Sénégal a pour codes :

• Régine Van-Chi - Bonnardel (éd), "Atlas National du Sénégal". Paris, IGN , 1977, 147 p.

• Karine Abdel Malek, Mamadou Cissé, Proverbes et dictons wolofs, Paris, Présence Africaine, 2014 




</doc>
<doc id="2784" url="https://fr.wikipedia.org/wiki?curid=2784" title="Science-fiction">
Science-fiction

La science-fiction est un genre narratif, principalement littéraire (littérature et bande-dessinée) et cinématographique. Comme son nom l'indique, elle consiste à raconter des fictions reposant sur des progrès scientifiques et techniques obtenus dans un futur plus ou moins lointain (il s'agit alors également d'anticipation), ou physiquement impossibles - du moins en l'état actuel de nos connaissances. Elle met ainsi en œuvre les thèmes devenus classiques du voyage dans le temps, du voyage interplanétaire ou interstellaire, de la colonisation de l'espace, de la rencontre avec des extra-terrestres, de la confrontation entre l'espèce humaine et ses créations, notamment les robots et les clones, ou de la catastrophe apocalyptique planétaire.

L'intrigue des récits de science-fiction peut se dérouler sur Terre (utopie, dystopie, contre-utopie) ou dans l'espace (vaisseau spatial, exoplanètes).

Elle peut décrire la science dure avec le "biopunk", le "cyberpunk" et "postcyberpunk" (robots) en partant des connaissances actuelles (scientifiques, technologiques, ethnologiques...).

Elle peut parfois être associée à d'autres genres, comprenant une dimension inexplicable ou imaginaire comme la religion qui associe à la fois le fantastique (steampunk et réalisme fantastique : mythologie, extra-terrestre, monde perdu, mondes parallèles) et la fantasy (space fantasy faisant souvent intervenir la magie), ainsi que la guerre ou l'humour.
Le terme français a pour origine le terme anglais "science fiction" qui est apparu pour la première fois en 1851 sous la plume de William Wilson dans un essai intitulé "A Little Earnest Book Upon A Great Old Subject". Mais il ne s'agissait alors que d'un usage isolé. En , on trouve dans les colonnes du courrier de "Amazing Stories" la phrase suivante : « "Remember that Jules Verne was a sort of Shakespeare in science fiction" ». Mais c'est en 1929, à la suite de l'éditorial d'Hugo Gernsback dans le premier numéro du pulp magazine intitulé "Science Wonder Stories", que le terme commence à s'imposer aux États-Unis, aussi bien dans les milieux professionnels que chez les lecteurs, remplaçant "de facto" d'autres vocables alors en usage dans la presse spécialisée comme « "scientific romance" » ou « "scientifiction" ».

Dans son essai intitulé "On The Writing of Speculative Fiction", publié en 1947 dans "Of Worlds Beyond", l'auteur américain Robert A. Heinlein plaida en faveur du concept de « "speculative fiction" », ou fiction spéculative réaliste pour se démarquer des récits de fantasy qui paraissaient encore à l'époque sous l'étiquette générale de "science fiction". Si le néologisme de Robert A. Heinlein connut un grand succès jusque dans les années 1960, le terme de "science fiction" s'est toujours maintenu comme référence. Exemple : "Le Meilleur des mondes" d'Aldous Huxley est un roman de type science-fiction.

Dans le monde francophone, le terme de "science-fiction" s'impose à partir des années 1950 avec pour synonyme et concurrent direct le mot "anticipation". Précédemment, il s'agissait plutôt de ou de voyages . Si le mot anglais original s'écrit le plus souvent "science fiction", le mot français s'orthographie avec un trait d'union : "science-fiction". L'abréviation française "S.F.", ou "SF", est devenue courante à partir des années 1970.

Une représentation répandue que l'on trouve dans les dictionnaires dépeint la science-fiction comme un genre narratif qui met en scène des univers où se déroulent des faits impossibles ou non avérés en l’état actuel de la civilisation, des techniques ou de la science, et qui correspondent généralement à des découvertes scientifiques et techniques à venir. Cette description générale recouvre de nombreux sous-genres, comme la "hard science-fiction", qui propose des conjectures plus ou moins rigoureuses à partir des connaissances scientifiques actuelles, les "uchronies", qui narrent ce qui se serait passé si un élément du passé avait été différent, le "cyberpunk", branché sur les réseaux, le "space opera", la "speculative fiction", le "planet opera", le policier/science-fiction et bien d’autres. Cette diversité de la science-fiction rend sa définition difficile. Mais, bien qu'il n'existe pas de consensus à propos d'une (presque tous les écrivains ont donné leur propre définition), on admet généralement que certains mécanismes narratifs caractéristiques doivent être présents dans une œuvre pour que l'on puisse la classer dans ce genre. Ainsi, "The Cambridge Companion to Science Fiction" propose-t-il une synthèse de ces caractéristiques par la formulation de plusieurs réquisits dont l'absence semblerait interdire de parler de science-fiction. Ils sont :




La science-fiction peut être un matériau pour la prospective, puisque elle construit et diffuse des représentations du futur. Elle aide les prospectivistes à imaginer les conséquences et implications des développements techniques. La science-fiction est plus à l’aise dans l’exploration imaginaire et moins sujette à des préventions. La mise en récit ou la mise en images facilite les expressions et alerte sur des tendances jugées inquiétantes.

Une définition de la "hard science fiction", ou "hard SF", fut proposée par l'écrivain américain Allen Steele en 1992 : « La "hard SF" est une forme de littérature de l'imaginaire qui se construit autour de la science établie ou de son extrapolation prudente ». L'expression fut utilisée pour la première fois en 1957 par P. Schuyler Miller dans un compte-rendu de "Islands of Space" de John W. Campbell, publié dans la revue "Astounding Science Fiction". Ce genre est représenté par exemple par les œuvres de Arthur C. Clarke, Stephen Baxter et Greg Egan.

Le voyage dans le temps peut être un genre à part entière, ou l'un des thèmes d'une œuvre. Ce genre affronte les problèmes liés aux paradoxes temporels, comme le paradoxe du grand-père, mais peut amener à des réflexions sur certains événements historiques lorsque, par exemple, un personnage crée l'histoire qu'il voulait en fait observer, comme dans "Voici l'homme" de Michael Moorcock. Le classique du genre est "La Machine à explorer le temps" de .

L’uchronie prend comme point de départ une situation historique existante et en modifie l’issue pour ensuite imaginer les différentes conséquences possibles. Un exemple est "Le Maître du Haut Château" de Philip K. Dick.
Le Steampunk est, par exemple, une forme d'uchronie rétro-futuriste, principalement caractérisée par les œuvres de Jules Verne ou de H. G. Wells, ainsi que du roman "L'Ève future" de Auguste de Villiers de L'Isle-Adam.

L’appellation cyberpunk est apparue dans les années 1980. Elle désigne un sous-genre de l'anticipation, elle-même sous-genre de la science-fiction, décrivant un monde futuriste de manière dystopique (négative). Le cyberpunk met souvent en scène un futur proche, avec une société technologiquement avancée (notamment pour les technologies de l'information et la cybernétique).
Parmi les principaux écrivains cyberpunk, on peut citer William Gibson, et plus particulièrement son roman "Neuromancien" (1984), ou Neal Stephenson.

Les récits de "space opera" articulent leur intrigue autour de voyages interplanétaires ou interstellaires. Dans ces récits, les théories d'astrophysique croisent les protocoles des récits d'aventures maritimes et en reprennent généralement le lexique (vaisseau, flotte...). Une part non négligeable de ces récits relève également de la science-fiction militaire. Ces récits, où la possibilité des déplacements à très longue distance est centrale, permettront le développement du thème d'empire interstellaire ou galactique.

Le "Space opera "apparaît en France notamment avec la Roue Fulgurante de Jean de la Hire en 1908 puis dans les années 1920 avec les romans de l'auteur américain Edward Elmer Smith, notamment "La Curée des astres" (1928), puis à une plus grande échelle dans "Triplanétaire" (1934) qui ouvrait le "Cycle du Fulgur". Après la Seconde Guerre mondiale, le space opera devient un genre prisé de la télévision, avec des séries comme "Star Trek" (États-Unis, 1964) de Gene Roddenberry et "Cosmos 1999" (Angleterre, 1975) de Gerry Anderson. Le film "Stargate, la porte des étoiles" est à l'origine, en 1997, de la série "Stargate SG-1" et de trois séries dérivées, qui connaissent un grand succès populaire tout au long des années 2000.

Côté littérature, le genre se porte bien dans les années 2000 et 2010 avec des grands auteurs et des œuvres majeures au premier rang desquels Dan Simmons (cycles Hypérion et Endymion, Ilium et Olympos), Peter F. Hamilton (cycles L'Aube de nuit, L'Étoile de Pandore, La Trilogie du vide), Alastair Reynolds (cycle des Inhibiteurs), David Weber (cycle Honor Harrington) et John Scalzi (cycle du Vieil Homme et la Guerre).

Les récits qui mêlent à des univers de "space opera" certains éléments typiques de la "fantasy" : magie, quête initiatique, atmosphère de conte. Ce genre peut réunir aussi bien les univers futuristes façon Warhammer 40000, où eldar et orques se battent à bord d'immenses machines de guerre, que d'autres plus étranges comme Spelljammer, où elfes, nains et humains explorent l'espace à bord de navires magiques, dépourvus de la moindre trace de technologie. Un cycle présentant les caractéristiques de la "space fantasy" peut également évoluer en "planet opera fantasy", comme les cycles de Ténébreuse et "La Ballade de Pern" par exemple. Pour le cinéma, le genre connaît un succès retentissant en 1977 avec le film "" (renommé "Star Wars: A New hope" à partir de 1981) (États-Unis, 1977) de George Lucas, premier volet de la trilogie originale "Star Wars", puis quatrième volet de l' octalogie du même nom.

Les récits de "planet opera "ont pour décor une planète étrangère aux caractéristiques déroutantes et mystérieuses, où les principaux personnages ont pour mission d'explorer et de découvrir sous tous ses aspects (faune, flore, ressources). La trilogie d"'Helliconia" en est l'exemple canonique.

La science-fiction post apocalyptique met en scène le monde après une catastrophe ayant détruit la planète et/ou radicalement changé la société.
La science-fiction est un genre complexe qui se prête mal à l'exégèse historique. De nombreux aspects, comme les raisons sociales, économiques, culturelles de son développement dans tel pays, n'ont pas fait, ou très peu, l'objet d'études approfondies. Les études de la science-fiction en tant que littérature à part entière sont également peu nombreuses.
De même que par un débat sans fin on tente de définir la science-fiction, ses historiens ne sont pas toujours d'accord sur les origines du genre, et c'est un poncif de l'histoire de la science-fiction que de rechercher ses origines dans les écrits les plus anciens . Ainsi, pour , cela commence très tôt avec les mythes et les religions. voient les "Histoires vraies", de Lucien de Samosate, comme le premier ouvrage relevant du genre. Ses voyages extraordinaires auront une très longue postérité. Mais cette archéologie se heurte à une objection :
D'autres, c'est le cas de Brian Aldiss dans son essai "Trillion Year Spree", considèrent que le premier roman de science-fiction n'est autre que le roman "Frankenstein" de Mary Shelley. C'est du moins le premier ouvrage dans lequel un auteur prétend créer une histoire fantastique qui ne relève pas de la pure fantaisie ou du surnaturel : 

Parmi les précurseurs sont souvent cités :

La science-fiction moderne compte notamment deux pères fondateurs : Jules Verne (1828-1905) avec "De la Terre à la Lune" en 1865 ou "Vingt mille lieues sous les mers" en 1870, et (1866-1946) avec notamment "La Machine à explorer le temps" (1895), "L'Homme invisible" (1897) ou "La Guerre des mondes" (1898). Ils appartiennent cependant à une époque qui voit fleurir de nombreux romans d'anticipation scientifique. Cette floraison est favorisée par de nombreux progrès scientifiques réels, par l'alphabétisation de la fin du et par le développement d'une littérature populaire diffusée par des revues.


Parmi les auteurs d’environ trois mille « romans scientifiques » écrits en français entre 1860 et 1950, on signalera : Maurice Renard, Gustave Le Rouge, Léon Groc, Régis Messac ("Quinzinzinzili"), Jacques Spitz ("L'Œil du purgatoire"), Théo Varlet, Jean Ray, René Barjavel et Olivier de Traynel.

Si la science-fiction a vu le jour en Europe et s’est bien développée en France, au Royaume-Uni et en Allemagne, ce sont les États-Unis, entre 1920 et 1955, qui donneront au genre son « âge d'or ». Ce déplacement de l'Europe aux États-Unis peut s'expliquer par plusieurs facteurs : d'une part, la presse populaire en Europe est plus exposée à la censure liée aux publications pour la jeunesse ; d'autre part, la littérature, en France particulièrement, est fortement hiérarchisée entre une littérature distinguée et une littérature de masse. Un autre facteur est l'industrialisation de la presse, qui permet des publications bon marché et à gros tirage. C’est à ce moment que se multiplient les revues spécialisées de science-fiction qui suivent la tradition des "pulps" (revues populaires de faible qualité et très peu chères). Citons parmi les premières du genre "Weird Tales", née en 1923 ; "Amazing Stories", née en 1926 ; "Wonder Stories", née en 1929 ; "Astounding Stories", née en 1930. Aux États-Unis, plus de 30 revues existeront simultanément. L’édition sous forme de livres des textes de science-fiction est plus tardive, et se manifestera plus particulièrement après la Seconde Guerre Mondiale, avec le livre de poche, et dans des pays dont l'industrie favorise ce type de format au détriment de la revue, comme la France. Elle précède de peu la disparition de nombreuses revues.

Certains auteurs et critiques, comme Serge Lehman, voient cependant là une sorte d'« amnésie » frappant la production française. Dans l'anthologie "Chasseurs de chimères" (2006), Lehman rassemble des textes tels que la nouvelle de J.-H. Rosny aîné, "Les Xipéhuz" (1897) ; l'épopée spatiale de Jean de La Hire, "La Roue fulgurante", parue dans "Le Matin" en 1907 ; "La Découverte de Paris", d'Octave Béliard, parue dans "Lectures pour tous" (1911) ; le roman de Maurice Renard, "Le Péril bleu" (1912), racontant la rencontre avec une autre espèce ; "Les Signaux du Soleil" (1943) de Jacques Spitz, etc. Le magazine "Sciences et voyages" publie ainsi plusieurs nouvelles au cours de la première moitié du , tandis que le Prix Jules-Verne récompense divers auteurs de 1927 à 1933 puis de 1958 à 1963. Après la Seconde Guerre mondiale, la France découvrira la SF américaine, notamment sous l'influence de Boris Vian et Raymond Queneau.

Le support de parution périodique (revue, "pulp") a fortement marqué le genre. Le format et la périodicité ont fait que beaucoup de nouvelles et de courts romans ("novellas") ont été écrits. Les œuvres longues n’étaient que le fait des auteurs les plus célèbres et paraissaient par épisodes, ce qui n’était pas sans conséquences sur le texte puisque les auteurs devaient s’y adapter. De ces premiers magazines spécialisés ont émergé la plupart des principaux écrivains classiques de science-fiction : Howard Phillips Lovecraft, Isaac Asimov, Frank Herbert, Ray Bradbury, Arthur C. Clarke, Frederik Pohl, Robert A. Heinlein, Alfred Bester, A. E. van Vogt, Clifford Donald Simak, Theodore Sturgeon Si cette période voit apparaître les auteurs de référence, les productions habituelles n'en sont pas moins médiocres :

Elle est aussi marquée par son temps, en particulier dans les années 1930-1940 où à travers les poncifs du genre transparaissent des thèmes nationaux et populistes :

La science-fiction n'échappe pas non plus à l'influence du nazisme (voir ). Cette période fut aussi marquée par l'émergence du cinéma, né en 1895. Celui-ci se tournera très tôt vers la science-fiction et le fantastique, avec "Le Voyage dans la Lune" de Georges Méliès (1902) et les films de l’expressionnisme allemand, comme le "Nosferatu" ("Nosferatu, eine Symphonie des Grauens") de F.W. Murnau (1922) et "Metropolis" de Fritz Lang (1927). Parmi les films majeurs de cette période, on peut citer "Frankenstein" (James Whale, 1931), "King Kong" (Merian C. Cooper et Ernest B. Schoedsack, 1933), qui étonna par ses effets spéciaux, "Le Jour où la Terre s'arrêta" ("The Day the Earth Stood Still", Robert Wise, 1951 — qui réalisera plus tard le premier "Star Trek, le film") et "Planète interdite" ("Forbidden Planet", Fred M. Wilcox, 1956). Mais il ne faut pas oublier une production plus populaire mais aussi emblématique, caractérisée (avant l’ère de la télévision) par les "serials", films découpés en épisodes, dont les héros s’appelaient "Flash Gordon" (1936, 13 épisodes) ou "Buck Rogers" (1939, 12 épisodes).

La bande dessinée ne fut pas en reste, avec l’explosion des "comics" comme "Buck Rogers" et "Flash Gordon", et ceux qui sont consacrés aux super-héros ("Superman", "Batman", "Wonder Woman" (de la "DC Comics"), ou bien encore "Spider-Man", "les Quatre Fantastiques", "les X-Men" (de la "Marvel")). En France, de 1953 à 1962, les publications "Artima" développèrent ce genre dans des publications de kiosque, avec des histoires originales ("Meteor", "Atome Kid"), et des traductions de matériel britannique ("La Famille Rollinson dans l’espace") ou américain ("Aventures Fiction", "Sidéral").

Depuis les années 1960-1970 émerge une science-fiction différente, moins narrative, influencée par la contre-culture et les sciences humaines. Elle porte un regard critique sur notre société et propose souvent une réflexion sur les problèmes contemporains (écologie, sociologie, rôle des médias, sexualité, drogues, rapport au pouvoir, aux nouvelles technologies, à l’histoire). Elle est ancrée dans son temps et ses problématiques, tout en restant œuvre d’évasion. Elle sert aussi d'exutoire comme le fut "La Guerre éternelle" de Joe Haldeman, roman dans lequel l'auteur exorcise sa guerre du Viêt Nam. Cela n'empêche pas les éditeurs de continuer à publier une science-fiction purement distractive.

La science-fiction a également exploré d'autres voies à travers l'expérimentation stylistique. Au Royaume-Uni, la "new wave" est née autour de Michael Moorcock et sa revue "New Worlds". Brian Aldiss et J. G. Ballard, dont le roman "Crash" est un bon exemple des recherches formelles poursuivies par cette école. Judith Merril a popularisé le genre aux États-Unis, sans toutefois employer le terme "New Wave". En France, Michel Jeury s'est inspiré du "Nouveau Roman" dans "Les Singes du temps" et "Le Temps incertain".

Depuis lors, la science-fiction est un genre riche et diversifié. Elle mêle des œuvres de grande qualité (et a gagné ses lettres de noblesse littéraires avec des auteurs comme Ray Bradbury) à de la « littérature de gare ». Parmi les auteurs contemporains, on peut citer entre autres Orson Scott Card, Dan Simmons, Iain M. Banks, Alastair Reynolds ou encore Peter F. Hamilton. Le Français Alain Damasio, propose quant à lui une science fiction libertaire et militante en réaction face aux sociétés de contrôles et à l'émergence des réseaux sociaux.

Les sous-genres, évoqués au début du texte, se sont aussi multipliés et de nouveaux continuent d’apparaître.

La science-fiction a aussi étendu son essor géographiquement, bien au-delà des États-Unis. On a vu, par exemple, une « nouvelle vague » de science-fiction française dans les années 1970 (avec, entre autres, Pierre Pelot (alias Pierre Suragne), Jean-Pierre Andrevon, Gérard Klein (également responsable de la collection Ailleurs et Demain des éditions Robert Laffont, qui a beaucoup fait pour donner à cette littérature ses lettres de noblesse), Michel Jeury, Philip Goy, Dominique Douay, Pierre Bordage et Ayerdhal ou encore Philippe Ébly (pour les enfants et adolescents des années 1970 et 1980). Et aussi René Barjavel qui excelle dans ce domaine. On compte aussi de nombreux auteurs de talent dans les pays de l’Est (rarement traduits en français) avec à leur tête le Polonais Stanislas Lem (Stanisław Lem) et les frères russes Arcadi et Boris Strougatski.

Si en France les revues spécialisées n’ont jamais joué un rôle de premier plan, comme aux États-Unis, elles n’en existent pas moins. Parmi les principales, on peut citer "Galaxies", "Bifrost", "Fiction", "Khimaira", "Lunatique", "Science fiction magazine", "Solaris", "Univers".

Actuellement, la science-fiction est toujours bien présente. Dans le monde francophone, particulièrement en France et au Québec, l'usage de l'anglicisme sci fi est très courant pour décrire ce genre cinématographique. Grâce au cinéma le lectorat a grandement augmenté et les romans de science fiction représente aujourd'hui une industrie hautement lucrative. La science-fiction est d'ailleurs un des genres majeurs du cinéma, soit sous la forme d’adaptations d’œuvres littéraires, soit sous la forme de créations originales. "Le Voyage dans la Lune" (1902) de Georges Méliès est ce que l'on peut considérer comme le premier film de science-fiction. Parmi les films importants qui imposèrent un certain nombre de standards, on peut retenir "2001, l’Odyssée de l’espace" (1968) de Stanley Kubrick, "La Planète des singes" (1968) de Franklin J. Schaffner, "Star Wars" (1977) de George Lucas, "Alien - Le huitième passager" (1979) et "Blade Runner" (1982) de Ridley Scott, "Mad Max" (1979) de George Miller. Évidemment, il faut aussi citer la série britannique "Doctor Who" apparue en 1963 et existant toujours aujourd'hui, qui est la plus longue série télévisée de science-fiction et a inspiré de nombreux auteurs de science-fiction. Les années 1980 peuvent être considérés comme la décennie de la science-fiction ; les plus grands exemples de sa popularité mondiale sont certainement "E.T. l'extra-terrestre" de Steven Spielberg et la trilogie de "Retour vers le futur" de Robert Zemeckis. La série télévisée "Star Trek" (datant de 1966) fut remise à la mode grâce à une série de films dérivés.

Le cinéma de science-fiction s'est considérablement diversifié à partir des années 1990 avec "Jurassic Park" de Steven Spielberg, ainsi qu"'Independence Day" et "Stargate, la porte des étoiles" (1994) de Roland Emmerich. Ce film engendra les séries à succès "Stargate SG-1", "Stargate Atlantis" et "Stargate Universe" (respectivement, à partir de 1997, 2004 et 2009). La combinaison avec la comédie fut de nouveau possible grâce à "Men in Black" de Barry Sonnenfeld, et le drame catastrophe avec "Armageddon" de Michael Bay. Plus récemment, "Matrix" de Lana et Lilly Wachowski ouvrit une nouvelle ère pour la science-fiction, avec pour thème le danger d'un monde informatisé. Cela n'empêcha pas les retours aux sources avec le remake "La Guerre des mondes" (d’après ) et "Minority Report" (d'après une nouvelle de Philip K. Dick) ; deux films réalisés par Steven Spielberg, l'un des maîtres incontestés du genre. L’idée perçue du film de science-fiction est souvent associée à une débauche d’effets spéciaux, mais il existe des films dits de « science-fiction minimaliste », qui mettent en scène la fiction sans aucun effet spécial, uniquement en jouant avec le cadrage, la mise en scène, le jeu d’acteurs et la musique ; citons, par exemple, "La Jetée" de Chris Marker (1962), "Solaris" et "Stalker" d’Andrei Tarkovsky (1979), "Le Trésor des îles Chiennes" de François-Jacques Ossang (1990), ou encore "Cypher (film, 2002) de Vincenzo Natali, " de Carlos Atanes (2004) et "Bienvenue à Gattaca" d’Andrew Niccol ("Gattaca", 1997).

Concernant le cinéma d’animation, les Japonais occupent une place prépondérante tant au cinéma qu’à la télévision (on parle d’"anime" ou de "manga eiga" pour désigner ces réalisations), avec notamment des réalisateurs comme Leiji Matsumoto (univers d’"Albator" et ses dérivés), Katsuhiro Otomo ("Akira") et Mamoru Oshii ("Ghost in the Shell"). Mais des réalisations françaises ("Le Secret des Sélénites" ou "Les Fabuleuses aventures du légendaire Baron de Munchausen" de Jean Image, "Gandahar" de René Laloux), ou bien américaines ("Métal hurlant"), font partie intégrante du développement de la science-fiction dans le cinéma d’animation. La déferlante des séries d’animation japonaises (parfois coproduites avec des Français ou des Américains), qui constituèrent l’essentiel des programmes « jeunesse » de la télévision française durant la décennie 1978-1988, contribua largement à populariser le genre en France, bénéficiant d’une diffusion médiatique de masse sur des chaînes hertziennes (TF1, Antenne 2, FR3, puis La Cinq) aux heures de grande audience. De ce fait, des séries telles que "Goldorak", "Capitaine Flam", "Albator", "Il était une fois... l'Espace", "La Bataille des planètes", "Les Mystérieuses Cités d'Or" et "Ulysse 31" ont marqué une génération d’enfants des années 1980.

En bande dessinée, la science-fiction est l’occasion de développer des univers esthétiques fabuleux.

Aux États-Unis, après l’explosion des comics comme "Buck Rogers" et surtout "Flash Gordon" d’Alex Raymond (1934). Les précurseurs français sont Raymond Poïvet et Roger Lécureux avec "les Pionniers de l'Espérance" (1945), Marijac et Auguste Liquois ou Pierre Duteurtre avec "Guerre à la Terre" publié par Coq hardi (1946/47) et Kline avec "Kaza le Martien" parut dans l’hebdomadaire OK (Belgique), de 1946 à 1948. Cette bande dessinée s'inspirait de "Flash Gordon". En 1947 au Québec, le journal "Le Progrès du Saguenay" publie la première bande dessinée de science-fiction du pays : "Les Deux Petits Nains", du jeune Paulin Lessard. Il est difficile de ne pas parler d’Edgar P. Jacobs, dont "Le Rayon U" fut publié en 1943. À la fin des années 1940, il crée la série des aventures de "Blake et Mortimer", un classique du genre.

Il y eut ensuite "Barbarella" (1962) de Jean-Claude Forest, "Les Naufragés du temps" (1964) de Paul Gillon et Jean-Claude Forest, "Lone Sloane" (1966) de Philippe Druillet, "Luc Orient" (1967) d'Eddy Paape et Greg et enfin et surtout "Valérian, agent spatio-temporel" devenu plus tard "Valérian et Laureline" de Jean-Claude Mézières, Pierre Christin et Evelyne Tran-Lê (de 1967 à aujourd'hui) qui popularisa le genre science-fiction en bande dessinée. Christin et Mézières souhaitaient que les aventures de Valérian et Laureline soient aussi des histoires de politique-fiction (écologie, relation de classes ou de travail, féminisme, syndicalisme) plutôt situées à gauche mais non directement ou ouvertement politique comme il peut y en avoir dans "Charlie Hebdo". "Mézières" fut largement pillé par les décorateurs et les costumiers de George Lucas, qui possédait, entre autres, nombre des albums de "Valérian" dans sa bibliothèque, pour "Star Wars" (1977).

Roger Leloup est un scénariste et dessinateur belge dont une partie de la série "Yoko Tsuno" se déroule dans un univers empreint de science-fiction. Certains albums des "Aventures de Tintin et Milou" peuvent être classés dans la catégorie science-fiction, par exemple "On a marché sur la Lune", qui raconte, avec quinze ans d’avance, le premier voyage sur la lune, ou "Vol 714 pour Sydney", qui fait intervenir des extraterrestres. Parmi les grands créateurs du genre, on compte beaucoup de dessinateurs et de scénaristes français ou travaillant en France, notamment ceux qui gravitent autour du journal "Métal hurlant" ; citons, par exemple, Enki Bilal, Caza, Philippe Druillet, Alejandro Jodorowsky, Olivier Ledroit, Moebius et Olivier Vatine. De même avec le magazine bimensuel "Ère Comprimée" avec Dick Matena, Rafa Negrete ou encore Cacho Mandrafina.

On trouve également François Bourgeon avec "Le Cycle de Cyann", une série qui invente une civilisation avec des mœurs, une faune et une flore parfaitement structurés.

Aux États-Unis, on peut citer Alex Raymond, Richard Corben, Frank Miller, et les Britanniques Simon Bisley, Pat Mills (scénariste) et Alan Moore (scénariste).

En 1950, Frank Hampson créa pour le magazine britannique "Eagle", "Dan Dare, Pilot of the Future".

Les "mangas" (bandes dessinées japonaises) exploitent elles aussi énormément les thèmes de la science-fiction et du fantastique. Citons par exemple Go Nagai, Akira Toriyama, Katsuhiro Otomo et Masamune Shirow.

La littérature de science-fiction a généré une importante activité : du fait de sa publication relativement marginale, elle a très tôt suscité la création de formes d'institutionnalisation qui lui étaient refusées par la littérature « distinguée » et la critique littéraire source de légitimité. Des communautés d'initiés se sont créées : l'expression fandom de la science-fiction ou fandom SF fait ainsi référence à la communauté de gens dont l'un des intérêts principaux réside dans la science-fiction, ces personnes étant en contact les uns avec les autres en raison de cette passion commune. La notion de fandom est donc associée à celle de sous-culture, dont la spécificité « science-fictionnesque » a été interrogée par des acteurs de ce domaine, tels Gérard Klein ou Philippe Curval.

Des prix littéraires ont aussi été créés, d'abord par les amateurs de science-fiction, puis par des éditeurs qui ont contribué à la professionnalisation du genre. Les plus importants sont les prix Hugo et Nebula pour les États-Unis et pour la France le Grand prix de l'Imaginaire et le prix Rosny aîné.

D'après certaines enquêtes, le lectorat de la science-fiction serait majoritairement composé de garçons, collégiens ou lycéens. Des études sociologiques plus rigoureuses suggèrent en revanche que le genre n'est pas le critère dominant, la SF étant, à l'école, la littérature privilégiée des bons élèves et issus de milieux aisés de même que ses lecteurs adultes disposent d'une éducation supérieure à la moyenne, technique ou non.








</doc>
<doc id="2787" url="https://fr.wikipedia.org/wiki?curid=2787" title="Société nationale des chemins de fer français">
Société nationale des chemins de fer français

La Société nationale des chemins de fer français (SNCF) est l'entreprise ferroviaire publique française, officiellement créée par convention entre l'État et les compagnies de chemin de fer préexistantes, en application du décret-loi du . Elle est notamment présente dans les domaines du transport de voyageurs, du transport de marchandises et réalise la gestion, l'exploitation et la maintenance du réseau ferré national dont elle est propriétaire.

La SNCF est composée de trois EPIC, mais elle possède de nombreuses filiales aussi bien de droit public que de droit privé qui forment le groupe SNCF.

Depuis le juillet 2015, la SNCF est constituée de trois établissements publics à caractère industriel et commercial (EPIC) : l'EPIC de tête « SNCF » chargé du pilotage stratégique du groupe, « SNCF Réseau » propriétaire et gestionnaire du réseau ferré national et « SNCF Mobilités » chargé de l'exploitation des trains.

La SNCF est donc un groupe ferroviaire intégré : elle exerce à la fois le métier d'exploitant (voyageurs et marchandises) et celui de gestionnaire d'infrastructure ferroviaire.

La Société nationale des chemins de fer français est devenue un établissement public à caractère industriel et commercial en 1983, alors qu'elle était auparavant une société anonyme d'économie mixte.

En 2015, le réseau ferré national propriété de SNCF Réseau compte environ de lignes dont de lignes électrifiées et de lignes à grande vitesse.

Chaque jour, elle fait circuler de fret et de voyageurs et transporte plus de de voyageurs. Par son volume d'activité et la taille de son réseau, c'est la troisième entreprise ferroviaire européenne, après la Deutsche Bahn et les chemins de fer russes.

Le groupe SNCF détient des participations majoritaires ou minoritaires dans des sociétés de droit privé et la tutelle de l'État est exercée par la Direction générale des infrastructures, des transports et de la mer du ministère de la Transition écologique et solidaire. Le siège social de la SNCF se trouve à La Plaine Saint-Denis, 2 place aux Étoiles, à côté de la gare du Stade de France - Saint-Denis desservie par la ligne D du RER.

En 2016, le groupe SNCF a enregistré un chiffre d'affaires de d'euros et un résultat net de d'euros contre une perte nette de d'euros en 2015 à la suite d'une dépréciation exceptionnelle des actifs.

Le reste du groupe SNCF intervient dans les domaines suivants : logistique et transport routier de marchandises, transport routier de voyageurs (Keolis), liaison maritime (SeaFrance), ingénierie (EFFIA, INEXIA), commerce en ligne (anciennement Voyages-sncf.com, devenu OUI.sncf le ), billettique (Ritmx). Le groupe possède aussi des participations dans des sociétés ferroviaire et gestionnaires d'infrastructure portuaire partagées avec d'autres partenaires comme Eurostar, Thalys, Elipsos, Lyria et Nuovo Trasporto Viaggiatori.

La Société nationale des chemins de fer français a été créée par convention du 31 août 1937 entre l’État et les différentes compagnies privées de l'époque : Nord, Est, PO, Midi, PLM, auxquelles s'ajoutent les Syndicats du Chemin de fer de Grande Ceinture et de Petite Ceinture et les deux administrations nationales, les chemins de fer d'Alsace-Lorraine et le Réseau de l’État. Le janvier 1938, l’exploitation des lignes de ces anciennes compagnies, syndicats et administrations est transférée à la nouvelle SNCF, les anciennes compagnies de chemin de fer restant propriétaire de leur domaine privé propre. Cette convention a été validée par décret-loi du 31 août 1937 alors que les réseaux comptabilisaient des pertes cumulées de de francs. La SNCF exploite alors un réseau comportant de voies dont sont électrifiées et emploie . Elle s'organise autour de 5 régions : Est, Nord, Ouest, Sud-Est et Sud-Ouest. Ces régions correspondent, approximativement, aux anciens réseaux privés et publics. Pour rétablir l'équilibre financier de la SNCF un plan de fermeture de de lignes est adopté par le gouvernement Chautemps.

La SNCF a été créée, à l'origine, sous le régime d'une société anonyme d'économie mixte, pour une durée de 45 ans, dont l'État possédait du capital, les restants appartenant aux actionnaires des sociétés financières ayant succédé aux anciennes compagnies. Les agents de la SNCF ne sont pas des fonctionnaires mais la plupart des membres du personnel (dits « cadre permanent ») bénéficient d'un statut particulier ("statut cheminot") et d'un régime spécial de retraite. Les personnels contractuels sont affiliés au régime général de la sécurité sociale créée au lendemain de la Seconde Guerre mondiale.

À la suite de la signature de l'armistice franco-allemand du 22 juin 1940, en application de l'article 13 de la convention d'armistice, les chemins de fer de la zone occupée (soit les deux tiers du réseau SNCF) et le « personnel spécialisé nécessaire » sont mis à la disposition de l'occupant, qui fixe les priorités (ce sera de même pour les routes et voies navigables). L'Alsace-Lorraine étant annexée, son réseau ferroviaire est exploitée par la Deutsche Reichsbahn.

Dès l'été 1940, l'occupant allemand effectue des prélèvements de matériel, le premier ordre portant sur 1000 locomotives et  wagons.

À partir de 1941, les locomotives à vapeur de la SNCF sont équipées du traitement intégral Armand (TIA).

Après la rafle du Vel d'Hiv, les 16 et 17 juillet 1942, les juifs arrêtés sont déportés par les autorités françaises dans des trains de la SNCF vers les camps de Drancy, Pithiviers et Beaune-la-Rolande. Le , un conducteur de locomotive, Léon Bronchart, a refusé de conduire un train de juifs vers la déportation ; c'est le seul cas connu. Des trains de déportés sont partis vers la frontière allemande jusqu'en 1944. Au total, environ et politiques ont été envoyés de France vers les camps de la mort.

Durant la Seconde Guerre mondiale, le réseau ferré est gravement endommagé. La SNCF perd près de de l'ensemble de ses moyens.

Après de longues années de reconstruction et de modernisation du réseau, la SNCF retrouve une activité commerciale équivalente à celle d'avant-guerre et peut s'enorgueillir d'exploits techniques. Les 28 et 29 mars 1955 les locomotives CC 7107 et BB 9004 de la SNCF atteignent , double record du monde de vitesse. Dans les années 1950, est définitivement mis au point, par les ingénieurs de la SNCF, l'usage de l'électrification par courant alternatif « à fréquence industrielle », qui se généralise par la suite en France et dans le monde.

La SNCF supprime la le 3 juin 1956.

Afin de reconquérir une clientèle d'hommes d'affaires, la SNCF participe, dès sa création en 1957, au réseau des trains Trans-Europ-Express (TEE). Parallèlement, elle renouvelle son matériel pour ses « trains drapeaux » en commandant des nouvelles voitures inox.

En 1967, le Capitole est le premier train à atteindre en service commercial, sur une partie de son trajet (Orléans-Vierzon) entre Paris et Toulouse.

Une convention signée le 27 janvier 1971 modifie substantiellement la convention du 31 août 1937. Cette nouvelle convention donne à la SNCF une autonomie de gestion. Elle met à la charge de l'État la compensation financières des obligations de service public qu'il lui impose. En contrepartie, la société doit rétablir son équilibre financier. Cette convention est approuvée par un décret le 7 avril 1971. Un décret du 23 décembre suivant approuve le nouveau cahier des charges auquel est soumis la SNCF.

Face à la concurrence de l'automobile ainsi qu'à l'émergence de transports guidés innovants, tel l'aérotrain, et de nouveaux avions à décollage court, la SNCF se lance dans la grande vitesse ferroviaire, avec le prototype TGV 001 livré en 1972. À la fin des années 1960, pour moderniser ses « trains drapeaux », la SNCF met en service de nouvelles voitures dites « Grand confort » sur certaines relations entre Paris et la province.

Au début des années 1970, pour accroître la vitesse sur les lignes non électrifiées et moyennement armées, la SNCF met en service de nouvelles rames automotrices ETG (éléments à turbine à gaz) propulsées par une turbine à gaz, appelées turbotrains, auxquelles succéderont les rames RTG (rames à turbines à gaz). Outre l’aspect innovant de leur propulsion, un temps envisagé pour le futur TGV, et de leur légèreté, les ETG Paris-Caen-Cherbourg marquent une rupture commerciale avec le passé ; quasi-cadencement (plusieurs trains à heure fixe au cours de la journée), accès de la vitesse aux voyageurs de classe sans supplément (en rupture avec la philosophie des « trains d’affaires avec suppléments », tels les Trans-Europ-Express). Autant de nouveautés qui seront reprises au lancement du TGV.

Le 31 mars 1974, la 141 R 73 du dépôt de Sarreguemines est la dernière locomotive à vapeur de la SNCF qui effectue un service commercial. Un an plus tard, le 9 juin 1975, apparaissent les premières voitures Corail. Leur couleur extérieure (bicolore avec porte d’accès de couleur vive), leur aménagement intérieur (sièges disposés de chaque côté d’un couloir central s’inspirant d’une cabine d’avion, climatisation dans les deux classes, siège en binôme en classe séparé d’un accoudoir amovible, tablette de lecture amovible) et leur douceur de roulement tranchaient radicalement des autres matériels classique en service, parfois datant d’avant-guerre, donnant ainsi un effet de jeunesse et de modernité au transport ferroviaire que souhaite incarner la SNCF face à la concurrence automobile.

Au cours de son histoire, la SNCF a fait appel à des designers de renom, tels que Paul Arzens, Jacques Cooper et Roger Tallon, pour l'aspect intérieur et extérieur de ses matériels roulants mais aussi pour la signalétique et son identité visuelle.

Le lancement commercial du TGV a lieu le 27 septembre 1981 entre Paris et Lyon. L’innovation est non seulement technique, mais aussi commerciale avec la réservation obligatoire. Depuis cette date, le réseau français de lignes à grande vitesse, LGV, n'a cessé de croitre avec plus de en service et en travaux en 2014.

Au janvier 1983, l'ensemble des actifs de la société d'économie mixte constituée entre l'État et les grands réseaux de chemin de fer revient à l'État selon les termes de la convention signée en 1937. L'État, anticipant cette échéance, décide de constituer un établissement public à caractère industriel et commercial qui est doté du patrimoine et du personnel de la société d'économie mixte. Le 30 décembre 1982, est promulguée la Loi d'orientation sur les transports intérieurs (LOTI) qui crée l'établissement public à caractère industriel et commercial dénommé "Société nationale des chemins de fer français". Les agents de l'ancienne société d'économie mixte sont transférés à la nouvelle entité en conservant leur statut spécifique. En lieu et place de la convention de 1937 et de ses avenants, un cahier des charges approuvé par décret et des « contrats de plan » pluriannuels règlent l'ensemble des relations entre l'État et l'entreprise.

La marque TER, Transport express régional, est créée en 1987.

Au début des années 1990, la directive européenne 91/440 vise à permettre une ouverture à la concurrence. Elle impose la séparation de la gestion de l'infrastructure et de l'exploitation des services de transport, c'est-à-dire la distinction du gestionnaire de l'infrastructure et des entreprises ferroviaires ; l'instauration de droits d'accès et de transit pour les « regroupements internationaux » de transport de fret. Elle ne sera transposée par décret dans le droit français qu'en 1995. En outre, l'article premier de cette directive a été abrogé en 2001 par la .

Cette même année 1995, une importante crise due essentiellement au projet de réforme des retraites des cheminots lancée par le gouvernement Alain Juppé se traduit par une longue grève. Le projet est finalement abandonné. Aucun contrat de plan n'a été signé, mais l'État continue d'apporter une aide correspondant aux prestations dites de service public qui incluent : les tarifs spéciaux pour les voyageurs des « Grandes Lignes » (réduction pour les familles nombreuses, pour les militaires, etc.) ; elles représentent en 2006 environ d'euros dans les comptes de la SNCF (sur un chiffre d'affaires de d'euros). L'exploitation des transports express régionaux (TER) est réalisée sur la base de conventions avec les régions, devenues autorités organisatrices de transports (AOT) de ceux-ci.

L'année 1996 voit l'arrivée de nouvelles réformes à caractère législatif. Elles sont portées par Anne-Marie Idrac, alors secrétaire d'État aux Transports. Elles comprennent la création d'un nouvel établissement public à caractère industriel et commercial chargé de gérer le réseau et l'infrastructure. C'est ainsi que Réseau ferré de France (RFF) est créé le par scission de la SNCF. RFF devient alors propriétaire de l'infrastructure et décideur en matière d'aménagement, de développement et de valorisation du réseau mais son exploitation et son entretien sont délégués à la SNCF.

Le rapport de la Cour des comptes de 2007 relève que la séparation entre gestion de l'infrastructure et de l'exploitation telle qu'elle a été effectuée en 1997 allait « au-delà des exigences » de l'article 1 de la , qui n'exigeait qu'une séparation comptable.

Concomitamment à la création de RFF, l'expérimentation de la régionalisation des services de transports régionaux de voyageurs donne aux régions qui y participent la responsabilité de définir le service public régional et leur transfère les financements de l'État. Cette expérimentation imaginée par Anne-Marie Idrac sera généralisée à toutes les régions en 2002 par le ministre Jean-Claude Gayssot. En 2007, le renouvellement de nombreuses conventions TER entre les régions et la SNCF marque le succès de cette politique de décentralisation, qui a permis une relance des investissements, notamment dans le matériel roulant, et conduit à des taux de croissance du trafic proches de 10 % par an.

Dans le cadre de cette réforme, un contrat va formaliser ces nouvelles relations : c'est le « pacte de modernisation ». L'État s'engage alors à désendetter la SNCF et à garantir les acquis des cheminots. Il garantit aussi l'exploitation exclusive de la SNCF sur le réseau ferré. La SNCF s'engage en contrepartie à rédiger un projet industriel, à se recentrer sur le client et à rééquilibrer ses comptes.

En 1997, la propriété du réseau est donc transférée à Réseau ferré de France, qui reçoit également la charge de la dette liée à l'infrastructure. La SNCF conserve la mission d'exploiter les services de transport et la partie « commerciale » des gares, et doit acquitter à RFF une redevance pour l'utilisation des voies et de la partie « ferroviaire » des gares. Par ailleurs, bien que la gestion de la circulation et l'entretien du réseau soient de la compétence de RFF qui est le gestionnaire de l'infrastructure, c'est en pratique la SNCF, gestionnaire délégué de l'infrastructure, qui exécute ces tâches pour le compte de RFF, dans le cadre d'une convention entre les deux EPIC.

Sur le premier aspect, la réforme a permis à la SNCF, désendettée, de redresser sa situation économique, ; après de nombreux conflits entre RFF et la SNCF (à propos du patrimoine, de l'exécution des prestations d'entretien…), une convention pluriannuelle passée entre les deux entreprises en 2007 clarifie ces relations pour la gestion déléguée de l'infrastructure confiée à la SNCF. La question du niveau des péages reste en revanche un sujet de débat non stabilisé. Sur le second aspect , celle-ci n'a été décidée par le gouvernement français qu'en pour le fret ; cette libéralisation conduit la SNCF à lancer un plan de restructuration de son activité fret, déficitaire depuis 1998. La prochaine étape de concurrence prévue par les textes européens est fixée au pour les trains de voyageurs internationaux.
Les années 2000 sont marquées par la chute de l'activité fret. Les volumes transportés passent de de tonnes kilomètres en 2002 à de tonnes kilomètres en 2013.

Cependant la dette de la SNCF n'a pas disparu : elle a simplement été transférée à RFF. De plus cette organisation complexe débouchait sur un système absurde : la SNCF payait à RFF le droit d'utiliser le réseau et les infrastructures et RFF payait à la SNCF l'entretien et la gestion de ces derniers. Enfin les relations entre la SNCF et RFF ont souvent été houleuses provoquant des problèmes de communication comme la commande de « trains trop larges » par rapport aux quais.

Finalement en 2012, pour les 75 ans de la SNCF, Frédéric Cuvillier, ministre des Transports, annonce une réforme ferroviaire comportant notamment la création d'un « gestionnaire d'infrastructure unifié » (GIU).

Le 2 avril 2013, la SNCF lance Ouigo, sa marque de TGV à bas coûts.

En , la SNCF lance un site de covoiturage, « IDVROOM ». Après avoir racheté « Easycovoiturage.com » et « 123envoiture.com » en 2013, la SNCF décide de créer un site dédié principalement aux trajets entre le domicile et le lieu de travail.

La nouvelle réforme du système ferroviaire est adoptée par le Sénat et l'Assemblée nationale en 2014. Elle prévoit la réunification de la SNCF et de RFF au sein d'une même entité au janvier 2015. À cette occasion une nouvelle organisation sera mise en place. La SNCF s'articulera autour de trois EPIC: un EPIC de tête SNCF qui gérera le gestionnaire de l'infrastructure SNCF Réseau et SNCF Mobilités chargé de l'exploitation des trains.

Entre décembre 2014 et janvier 2015, les de la SNCF en contact avec le public reçoivent de nouvelles tenues (bleu marine avec un liseré rouge) fabriquées par la société bretonne Armor-Lux. Celles-ci remplacent les anciennes tenues grises et violettes dessinées par Christian Lacroix en 2007 qui n'étaient guère appréciées. Déjà en 1996, la SNCF avait fait appel à un couturier, Ted Lapidus, pour créer les tenues (bleu électrique) de ses agents.

Entre 2005 et 2010, la SNCF a supprimé et entre 2010 et 2015. Entre 2015 et 2020, ce sont à qui pourraient être supprimés.

RFF cesse d'exister le 31 décembre 2014. La nouvelle organisation de la SNCF est effective le janvier 2015. La SNCF, par l'intermédiaire de SNCF Réseau et SNCF Mobilités, devient propriétaire du réseau ferré national et de l'ensemble des gares et infrastructures ferroviaires.

Le 7 janvier 2015, la SNCF annonce la suppression de au cours de l'année 2015 : seront supprimés au sein de SNCF et SNCF Mobilités, mais SNCF Réseau prévoit la création de 500 postes.

Le 10 février 2015, la direction de la SNCF prévoit la mise en place du Wi-Fi à bord des TGV à partir de mi-2016. Mi-2017, l'ensemble des lignes TGV devrait bénéficier d'une couverture réseau 2G, 3G, 4G et Wi-Fi.

En mai 2015, une note interne de la SNCF préconise une réduction du nombre de trains Intercités (ex-Corail) avec la suppression totale des trains de nuits (ex-Lunéa), mais également de certaines lignes et de plusieurs arrêts intermédiaires.

En , la SNCF lance "Digital Ventures", un fonds d'investissement de 30 millions d'euros dont la gestion est à Hi Inov. Les secteurs visés par les investissements sont l'Internet des objets, le big data, l'édition de logiciel, l'expérience client, la communication digitale et l'économie du partage.

La SNCF supprime en 2016.

Les effectifs des trois EPIC étaient de en 2016, alors qu'il y avait de la SNCF en 2017, soit de plus. Il y a "près de deux retraités pour chaque cotisant à la SNCF" alors que dans le secteur privé en France, il y a 1,3 cotisant pour un retraité. 

Les effectifs de la SNCF ont en effet été divisés par trois en et par deux depuis 1980:
Le 19 février 2016, le secrétaire d’État aux transports, Alain Vidalies, annonce le désengagement de l’État de six des huit lignes Intercités de nuit. Seules les lignes Paris – Briançon et Paris – Rodez – Latour-de-Carol seront encore financées par l’État. Par ailleurs, l’État a décidé de lancer un appel d'offres pour renouveler le matériel affecté aux trains Intercités. Conséquence de cet appel d'offres, l'usine Alstom DDF de Reichshoffen pourrait fermer après 2018.

En mars 2016, la SNCF effectue une dépréciation d'actif de d'euros.

En 2016, la SNCF mise sur le "big data", avec l'installation de capteurs intelligents pour la maintenance des rames du Transilien. En partenariat avec le cabinet de conseil Quantmetry, ce projet permettrait de prévenir et réduire les pannes de trains susceptibles de se produire dans les suivantes.

En mai 2016, la SNCF contribue à la dernière levée de fonds d'Hyperloop Technologies, la start-up californienne qui développe des trains supersoniques circulant, dans des tubes à basse pression, à une vitesse pouvant atteindre , avec pour objectif d'atteindre ensuite .

En février 2017, la SNCF contracte un accord d’une durée de trois ans avec la société américaine IBM afin d’utiliser l'informatique en nuage de celle-ci, Bluemix, et l’intelligence artificielle. La SNCF pourra ainsi connecter des capteurs ainsi que des objets en réseau et exploiter les données.

En mai 2017, la SNCF revoit sa politique commerciale sur le TGV et annonce vouloir proposer deux offres : le bas prix Ouigo et l'offre haut de gamme TGV inOui.

La SNCF dispose d'une grande variété de matériels roulants : locomotives électriques, locomotives Diesel, locotracteurs, TGV, autorails, automotrices, trams-trains, voitures voyageurs

Une importante collection de ceux-ci est conservée et exposée à la Cité du train de Mulhouse.

La SNCF contrôle plus de 650 filiales présentes dans des activités liées au transport de personnes ou de marchandises, à la logistique ou à des activités d'études et d'ingénierie des transports, mais parfois fort éloignées du chemin de fer. Ces filiales de droit privé d'entreprises sont tenues par la société de portefeuille SNCF Participations et ses sous-holdings, dont quelques-uns groupent ces filiales et participations selon la branche d'activité industrielle. Les trois EPIC et l'ensemble de leurs filiales forment le groupe SNCF ; cette « dualité de côté EPIC et côté privé » est présente dans chaque branches d'activités industrielles.

En parallèle de cette diversification des services antérieurement directement liés au transport ferroviaire : courrier, colis, bagages accompagnés (Poste, Sernam) ont été transférés du rail vers la route.

Le groupe SNCF est l'un des tout premiers groupes de transport en Europe. Le premier site web de la SNCF en fréquentation, est « voyages-sncf.com », géré par la filiale du même nom. En 2003, il a attiré 36 millions d'internautes et enregistré trois millions de transactions pour un chiffre d'affaires de 467 millions d'euros, dont 80 % pour la vente des seuls billets de trains, le reste concernant l'aérien, l'hôtellerie et la location de voitures. Il est aussi le plus gros client pour la publicité sur l'internet en France. En relation avec l'ADEME, il a lancé l'« éco-comparateur », qui permet de comparer l'impact en CO des choix de mode de transport.

La SNCF était aussi un opérateur de télécommunications via Télécom Développement, puis Cegetel. Sa participation dans cette dernière entreprise a été revendue en 2005 lors de la fusion de Cegetel avec Neuf Telecom SA.

La SNCF a lancé en décembre 2004 un nouveau mode d'exploitation et de commercialisation des voyages TGV, l'iDTGV.

Confronté à une baisse de l'activité fret, qui doit être restructurée, ainsi qu'à l'ouverture des lignes à la concurrence, la SNCF a identifié six relais de croissance (autoroutes ferroviaires, autoroutes de la mer, transport combiné, logistique urbaine innovante, investissements dans les ports et plates-formes multimodales), en complément d'un fort investissement dans la rénovation des lignes de la banlieue parisienne.

Depuis le janvier 2015, la SNCF s'organise autour de trois établissements publics à caractère industriel et commercial, SNCF, SNCF Réseau et SNCF Mobilités et cinq « métiers » :

Avant la réforme de 2014, le groupe SNCF était organisé de la façon suivante :

La réforme de 2014 a entraîné une réorganisation du groupe :

La direction de l'EPIC est ainsi constituée :

La direction de SNCF Mobilités est ainsi constituée :

La direction de SNCF Réseau est ainsi constituée :

En 2015, SNCF Réseau emploie et compte 12 directions territoriales (Alsace – Lorraine – Champagne-Ardenne, Aquitaine – Poitou-Charentes, Bourgogne – Franche-Comté, Bretagne – Pays-de-la-Loire, Centre – Limousin, Haute et Basse-Normandie, Île-de-France, Languedoc-Roussillon, Midi-Pyrénées, Nord – Pas-de-Calais – Picardie, Provence-Alpes-Côte d'Azur, Rhône-Alpes – Auvergne).

En , à la suite d'une immense panne à la gare Montparnasse, rejoint la direction et devient le troisième directeur général délégué.

Depuis sa fondation en 1938, la SNCF a été présidée par :

La SNCF possède différentes filiales et participations :

Le logo visuel actuel de la SNCF a été créé en 2005 par l'agence Carré Noir, filiale du groupe de communication Publicis. Il a été légèrement remanié en 2011 : arrondissement des angles, disparition des ombres à l'intérieur des lettres ainsi que derrière, et séparation plus nette entre elles.

Le logo sonore de la SNCF , en version chanté, a été créé en 2005 par Michaël Boumendil. David Gilmour, guitariste emblématique du groupe Pink Floyd, s'en inspire pour un morceau de son dernier album "Rattle That Lock".

Simone Hérault est la voix de la SNCF depuis 1981.

Le chiffre d'affaires global du groupe SNCF pour l'année 2010 s'est élevé à 30,466 milliards d'euros (24,882 milliards d'euros en 2009), soit une augmentation de 22 %. Cette augmentation s'explique par l'intégration de Keolis et des acquisitions de Geodis.

Le chiffre d'affaires pour l'année 2017 s'élève à 33,8 milliards d'euros, soit environ 3,4 milliards d'euros de plus en 8 années.

La contribution au chiffre d'affaires par branche d'activité se décompose de la manière suivante :


Pour l'année 2013, le groupe SNCF a vu son chiffre d'affaires global augmenter pour atteindre d'euros ( d'euros en 2012) soit une faible augmentation de 0,5 % contre 2,5 % espéré.

De manière détaillée, les évolutions suivantes apparaissent en fonction des branches :

En 1997, Alain Juppé, Premier ministre, décide de placer la dette déjà importante de la SNCF (30 milliards d'euros) dans une nouvelle entité, Réseau ferré de France (RFF). Ce « tour de passe-passe comptable » est critiqué par la Cour des comptes.

Officiellement, la dette nette (hors dette RFF) baisse passant de 7,52 milliards d'euros en 2012 à 7,39 milliards d'euros en 2013. Mais, en 2014, après la réintégration de la dette placée dans RFF, la dette de la SNCF s'élève à 45 milliards d'euros. Celle-ci pourrait atteindre 56,7 milliards d'euros en 2020.

En 2018, la dette est de 47 milliards d'euros à laquelle il faut ajouter 8 milliards d'endettement de SNCF Mobilités, une entité du groupe public chargée de la circulation des trains. L'endettement de la SNCF a augmenté de 15 milliards d'euros entre 2010 et 2016, et continue de progresser de près de trois milliards d'euros chaque année.

La dette provient essentiellement des investissements dans le réseau et des intérêts versés aux marchés financiers. D'après le syndicat SUD Rail : « Cette dette, c’est d’abord la contre-valeur d’un bien commun : un réseau de chemin de fer. Elle est visible parce qu’elle se trouve au sein d’une seule société. Si une entreprise avait, à elle seule, la charge de maintenir et de développer le réseau routier, sa dette serait infiniment supérieure. »

Le cabinet d’expertises économiques Degest souligne que : « SNCF Réseau doit payer les intérêts de sa dette passée […]. Or, il n’a plus aucune ressource pour payer ces intérêts puisque celles-ci ont été utilisées pour l’investissement : il doit donc s’endetter pour les payer. C’est un effet boule de neige. […] Quand la SNCF emprunte 100 euros pour le réseau, il ne peut en utiliser que 41. Les 59 restant sont ponctionnés par le système financier. Et plus le temps passe, plus la dette se creuse. Si l’État l’avait reprise en 2010, seulement 7,2 milliards d’euros d’endettement auraient été générés, contre 17,5 milliards actuellement [2018] ».

En 2010, le résultat revient dans le positif et la SNCF annonce un résultat net de 697 millions. Celui-ci plonge à 125 millions d'euros en 2011. La crise bancaire de 2008 ayant, selon la direction, entraîné une baisse de l'activité de la SNCF, en particulier sur les TGV, la SNCF a passé trois grosses provisions comptables pour déprécier la valeur de ses actifs en 2009, puis 2011 et 2013 et ainsi anticiper une baisse durable et à long terme de sa rentabilité car la flotte de ses TGV (480 en tout) est devenue surcapacitaire. En 2012, l'entreprise présente un bénéfice net de 383 millions d'euros et une réduction de sa dette de 952 millions d'euros en procédant à une cession quasi équivalente de créances financières. La marge opérationnelle reste toutefois insuffisante pour couvrir les besoins de financement des investissements du groupe.

Même si la SNCF affiche un bénéfice net récurrent (hors provisions comptables pour dépréciations), au cours de chacune de sept années, la prise en compte de ces trois provisions (2009, 2011 et 2013) s'est traduit par l'affichage comptable de pertes nettes en 2009 et 2013.
Plusieurs raisons ont été apportées pour expliquer le déficit structurel de la SNCF et l'augmentation rapide de la dette du groupe.






Une grande partie de la dette ferroviaire antérieure à 1997 est rattachée à RFF au nom de l'État, mais n'est pas prise en compte (contrairement à l'Allemagne) dans les critères d'endettement de la France retenus au titre du traité de Maastricht.

La tendance de l'État à ne pas assurer les dotations nécessaires d'une part à la couverture de cette dette, d'autre part au financement de l'entretien et du développement du réseau, font peser sur les péages<ref name="Décret 2003-194 - 7/03/2003">Décret -194 du 7 mars 2003 relatif à l'utilisation du réseau ferré national., JORF du 8 mars 2003, article 3-II, 2003.</ref> payés par la SNCF, qui représentent 25 à 30 % de ses coûts, une pression à la hausse. Or la possibilité pour la SNCF de répercuter dans les tarifs aux voyageurs ces augmentations des péages reste problématique.

Les « bons résultats » économiques de la SNCF constatés dans ses comptes 2007, à la fin de la présidence d'Anne-Marie Idrac, ont conduit l'État à lui demander le versement d'un dividende et d'une contribution au budget de l'Agence pour le financement des transports terrestres (AFITT). Le gouvernement a en outre indiqué que les péages seraient augmentés à l'avenir. Un nouvel équilibre devra donc être trouvé, d'autant plus que la SNCF sera confrontée à partir de 2010-2011 à la question du financement du renouvellement de son parc de rames TGV, au moment même où la concurrence sur les voyageurs internationaux sera ouverte.

La SNCF a bénéficié dans le passé d'un double monopole, sur le transport ferroviaire d'une part et sur le transport de voyageurs entre villes françaises d'autre part. Sauf cas particuliers prévus par la loi, il n'existait pas de liaisons régulières inter-villes par autocar.

Elle est cependant soumise à une vive concurrence intermodale :

Le cadre juridique pour l'exercice d'une concurrence intramodale est en place en France pour ce qui concerne le transport des marchandises (fret) en trafic international depuis le 15 mars 2003 et en trafic intérieur depuis le avril 2006. Concrètement, le premier train de marchandises privé a circulé en juin 2005 pour le compte d'une filiale du groupe Connex. Depuis avril 2006, huit nouveaux entrants ont obtenu la licence d'entreprise ferroviaire et le certificat de sécurité leur permettant d'utiliser le réseau français : B-Cargo (SNCB), CFL Cargo (CFL/Arcelor), Euro Cargo Rail (EWS, aujourd'hui DB Schenker Rail), Europorte 2 (Eurotunnel), Rail4Chem (BASF), Veolia Transport (Connex), VFLI (Groupe SNCF Geodis) et Seco-Rail (Colas). Ces entreprises représentent dès 2007 environ 5 % des trafics ; en 2008, leurs investissements en matériel roulant pourraient leur ouvrir 10 % du marché.

De son côté, la SNCF a obtenu les certificats de sécurité lui permettant de commencer à tracter ses propres trains dans certains pays voisins, notamment la Belgique, l'Italie, les Pays-Bas, l'Allemagne, le Luxembourg.

Concernant le transport de voyageurs, les textes européens prévoient l'ouverture à la concurrence du trafic international de voyageurs, incluant le cabotage (c'est-à-dire la desserte de gares intermédiaires), au janvier 2010 (troisième « paquet » ferroviaire). Pour les transports régionaux ou locaux, le texte sur les obligations de service public permet la mise en concurrence des services régionaux (TER).

Le , un accord qualifié d'historique, sur « l'amélioration du dialogue social et la prévention des conflits à la SNCF » a été signé par sept organisations syndicales (dont la CGT) représentant au total 80 % des voix aux élections professionnelles de 2004.

Cet accord a pour but de remplacer la confrontation habituelle dans l'entreprise en recherche de compromis, en mettant en place un système analogue à celui de « l'alarme sociale » qui a fait ses preuves à la RATP dont Anne-Marie Idrac était alors la présidente. L'un des objectifs de cet accord, partagé par la direction et par les syndicats, est d'éviter l'instauration d'un système de service minimum dans les services publics, demandé par certains partis politiques. La loi sur le service garanti du 28 août 2007 consolide ce dispositif en rendant obligatoire la "déclaration individuelle d'intention" pour du personnel ayant des fonctions liées à la sécurité des circulations et permettant :

La réforme du régime spécial de retraites donne lieu en octobre et novembre 2007 à des grèves massivement suivies, y compris par l'encadrement le jeudi 18 octobre. Pour la présidente, Anne-Marie Idrac, il s'agit d'un travail de deuil, en raison de la rupture du contrat social implicite entre la SNCF et ses agents.

La grève, qui a débuté le mardi 13 novembre à 20 heures, est jugée injustifiée par une partie des Français. D'après un sondage réalisé par l’Ifop pour Metro, 62 % des Français estiment que la grève du 14 novembre contre la réforme des régimes spéciaux n’est pas justifiée ; dans le même sondage, 82 % des Français sont « favorables » à « l'alignement des régimes spéciaux de retraite, RATP, SNCF, EDF, sur le régime général des salariés de la fonction publique ». Au total, ces grèves auront coûté environ 300 millions d'euros à la SNCF selon Anne-Marie Idrac, avec un effet particulièrement dommageable pour le fret. La grève à la SNCF coûte selon Christine Lagarde entre 300 et 400 millions d'euros à l'économie française chaque jour.

Fin 2007, la réforme du régime spécial de retraites est globalement acquise ; le cadre général en a été fixé par le gouvernement et l'adaptation aux spécificités cheminotes négociée dans l'entreprise par Anne-Marie Idrac.

L'alignement des durées de cotisations (41,5 ans pour une retraite "complète") a nécessité un report de l'âge de mise à la retraite d'office en deux temps, pour aboutir au décret du 18 mars 2011, qui relève l'âge maximum de maintien en service : 65 ans pour les agents nés avant le 1957 progressivement relevé à 67 ans pour les agents nés à compter du 1962.

Autre sujet, depuis 2001, le cas des chibanis de la SNCF fait l'objet de plusieurs procédures judiciaires. L'objet du conflit porte sur la reconnaissance de droits dont auraient été lésés les travailleurs immigrés d'origine marocaine et algérienne depuis leur arrivée au sein de la SNCF dans les années 1970. Les chibanis victorieux devant les prud'hommes en 2015 avec des amendes cumulées de de dommages et intérêts. la SNCF fait appel, mais est de nouveau condamnée par la cour d’appel de Paris le mais se réserve le droit d'ester en cassation.

En avril 2012, la SNCF rejoint la Fédération des garanties et assurances affinitaires.

En juin 2014, le projet de réforme ferroviaire du gouvernement Valls suscite une nouvelle grève des cheminots. Le projet de loi veut notamment abroger la loi de 1940 portant statut des cheminots en le remplaçant par un "décret-socle".

Selon un audit commandé en septembre 2004 par la SNCF et RFF, l'état du réseau ferré français serait alarmant. Les experts ont notamment relevé une baisse tendancielle de la part des dépenses d'entretien affectées au réseau classique et un déséquilibre entre les dépenses d'entretien et les dépenses de renouvellement, la part des renouvellements, qui permettent de réduire sensiblement l'entretien courant, étant nettement plus faible que dans d'autres réseaux européens. La charge de la remise à niveau du réseau est évaluée à 15,3 milliards d'euros sur dix ans. Cela représente un besoin de financement important pour le gestionnaire du réseau qui se traduira vraisemblablement par une pression accrue sur la SNCF tant comme transporteur (hausse des péages) que gestionnaire délégué de l'infrastructure (augmentation de productivité).

Le rôle joué par la SNCF en tant qu'acteur de l'aménagement du territoire est aujourd'hui en question, l'entreprise ferroviaire n'hésitant pas à fermer des relations transversales, pourtant importantes pour l'équilibre du territoire comme les relations directes Limoges – Lyon et Limoges – Clermont-Ferrand. Cette politique suscite des réactions de la part d'une partie des usagers et des riverains, impactés par cette fermeture.

Dans l'optique du renouvellement du réseau des voies ferrées françaises, sous l'égide de RFF, 85 % des horaires de la SNCF vont être modifiés à partir du 11 décembre 2011. Cette modification des horaires permettra, outre une modernisation selon RFF et une efficience accrue selon G. Pepy, de réserver des créneaux horaires aux futurs trains des entreprises ferroviaires concurrentes.

Dans son rapport public annuel 2016, la Cour des comptes souligne les problèmes persistants du réseau ferroviaire francilien : vétusté des infrastructures, ponctualité et régularité. La vétusté des infrastructures ferroviaires franciliennes avait déjà été soulignée en 2010 par un précédent rapport de la Cour. Celle-ci fait d'ailleurs un parallèle entre la priorité donnée aux lignes à grande vitesse et la vétusté du réseau ferré francilien.

L'image d'une entreprise comme la SNCF est un enjeu important.

Les principaux facteurs qui jouent sur sa perception auprès du public sont les mouvements sociaux des syndicats, les hausses de tarifs

À l’occasion de la présentation en novembre 2010 d'un projet de train à grande vitesse entre Tampa et Orlando aux États-Unis, la SNCF exprime pour la première fois ses regrets pour son rôle dans la déportation de juifs français durant la Seconde Guerre mondiale.

En décembre 2010, pour la première fois également, la justice condamne la SNCF à d'indemnités à un voyageur à la suite d'un retard imputable à la SNCF et qui lui a fait perdre une journée de travail. Ce même mois, un record est battu avec un train à double tranche Strasbourg – Port-Bou/Nice qui arrivera avec 14 heures de retard à destination.

Cependant, selon un sondage TNS SOFRES paru en 2010, 66 % des Français ont une bonne image de la SNCF.

La sécurité dans les trains est aussi souvent mise en avant. Pour ce faire, environ forment la Sûreté ferroviaire, la surveillance générale de la SNCF, dont 50 % des effectifs sont affectés dans la région Île-de-France.

En 2017, moins de 30 % des usagers interrogés dans l'enquête de satisfaction réalisée par l’UFC-Que choisir se déclarent satisfaits des trains Intercités, des TER et du réseau Transilien en matière de ponctualité et de gestion des retards.

Entre 2004 et 2014, les effectifs de cheminots sont passés de 175 000 à 154 000, soit 2000 emplois supprimés chaque année.

L’espérance de vie des cheminots est inférieure à la moyenne nationale, notamment pour les personnels de l’exécution et de la traction, dont l’espérance de vie est de quatre ans de moins que la moyenne nationale.

La SNCF est inscrite comme représentant d'intérêts auprès de l'Assemblée nationale. Elle déclare à ce titre qu'en 2012, les coûts annuels liés aux activités directes de représentation d'intérêts auprès du Parlement sont compris entre et .

La SNCF est inscrite depuis 2009 au registre de transparence des représentants d'intérêts auprès de la Commission européenne. Elle déclare en 2015 pour cette activité 2,5 collaborateurs à temps plein et des dépenses d'un montant compris entre et . La SNCF indique avoir perçu sur le même exercice de subventions des institutions de l'Union européenne.

Les archives de la SNCF sont réparties sur deux sites : le Centre national des archives du personnel situé à Béziers, et le Centre national des archives historiques qui se trouve au Mans.





</doc>
<doc id="2788" url="https://fr.wikipedia.org/wiki?curid=2788" title="Saint-Marin">
Saint-Marin

Saint-Marin, en forme longue la Sérénissime République de Saint-Marin ou République de Saint-Marin (en italien ou ou ), est le troisième plus petit État d’Europe après le Vatican et Monaco, et le cinquième au monde après ces deux mêmes États ainsi que du Nauru et du Tuvalu. C’est aussi la plus ancienne république au monde avec un système constitutionnel qui remonte au . Il est considéré comme un micro-État.

Enclavé à l’intérieur de l’Italie entre l’Émilie-Romagne et les Marches, en le pays comptait dont . Il y a résidant à l’étranger. La République fait partie intégrante de la région historique du Montefeltro.

Selon la légende locale, vers un modeste tailleur de pierres nommé Marinus aurait quitté son île natale d’Arborea en Dalmatie pour s’installer dans la ville de Rimini en tant que maçon. Avant même que la grande vague de persécutions contre les chrétiens lancée par l’empereur Dioclétien en n’ait commencée, le pieux Marinus prit la fuite et se réfugia sur le mont Titano situé à proximité. Un nombre grandissant de persécutés vinrent le rejoindre et établirent ainsi sur le Titano une communauté chrétienne. La date officielle de naissance de cette communauté est aujourd’hui conventionnellement fixée au .

En 313 à la suite de l’édit de tolérance de Constantin et de la fin des persécutions, Marinus fut ordonné diacre par l’évêque de Rimini. Une patricienne romaine convertie au christianisme du nom de lui fit par ailleurs don du mont Titano, dont elle détenait jusque-là la propriété.

L’établissement définitif de la communauté de Saint-Marin est symbolisé par la mort de son fondateur à l’automne de l’an 366, et surtout par ses derniers mots : (« Je vous laisse libres des autres hommes »).

Vers l’an , l’accroissement continuel de la population avait fini par rendre nécessaire une expansion territoriale et l’achat de châteaux voisins et de leurs dépendances fut effectué à deux reprises. Peu de temps auparavant, Saint-Marin était devenue une cité-république à part entière dotée de son propre code juridique. Le plus ancien des codes ayant pu être conservé date de . Au cours des trois siècles suivants, les lois saint-marinaises furent constamment précisées et mises à jour dans de nouvelles versions : le sixième et dernier code, publié le , est constitué de pas moins de six tomes et de . 

Dès cette époque, la république comptait pour sa protection sur une armée parfaitement formée et organisée dans laquelle tout homme âgé de était susceptible de servir en cas de conflit. À partir de , la coutume fut prise d’élire deux capitaines-régents à la tête de la cité pour un mandat de six mois, une pratique encore en usage aujourd’hui. 

La deuxième moitié du fut une période difficile pour la cité. La république de Rimini, d’obédience guelfe et alors sous la domination de la famille Malatesta, tenta de prendre le contrôle de Saint-Marin : seule une alliance contractée avec le gibelin comte d’Urbin Guy, puis son fils Frédéric, permit de contrecarrer ce projet au bout de plusieurs années de combats qui ne s’achevèrent qu’en . Cette victoire ne mit cependant pas un terme aux tentatives d’annexion visant la ville. Dès , un ecclésiastique nommé Teodorico tenta de soumettre les Saint-Marinais au pape et à l’impôt : une longue dispute juridique s’ensuivit et fut résolue par un célèbre homme de droit et érudit originaire de Rimini, Palamède, qui trancha en faveur de Saint-Marin. À peine cinq ans plus tard en , ce fut la famille Feretrani qui tenta de revendiquer ce territoire mais sans succès : un nouveau jugement de Palamède, communiqué par ailleurs au pape Boniface VIII, établit cette fois clairement la souveraineté pleine et entière des Saint-Marinais. 

Le conflit séculaire opposant la petite république à la famille Malatesta se termina en 1463 par la victoire de Saint-Marin, à l’issue de laquelle le pape Pie II attribua à la République les trois seigneuries de Fiorentino, Montegiardino et Serravalle. L’année suivante, la seigneurie voisine de Faetano fut volontaire pour intégrer à son tour la communauté saint-marinaise : cet épisode constitue à la fois la dernière guerre et la dernière expansion territoriale de Saint-Marin. César Borgia, le célèbre duc de Valentinois et fils du pape Alexandre VI, a certes envahi Saint-Marin en pour y imposer sa domination autoritaire. Néanmoins cette occupation fut de courte durée : l’armée de Borgia fut anéantie lors d’une révolte du duché d’Urbin à laquelle participèrent d’ailleurs quelques Saint-Marinais. La République abrita une petite communauté juive, forte d’une cinquantaine de personnes, jusqu’à la fin des années . La communauté était organisée autour du banquier, qui favorisait la venue d’autres Juifs, commerçants, orfèvres ou encore merciers. Si la petite communauté était concentrée dans une rue, la « " » , les Juifs de Saint-Marin, au contraire de leurs coreligionnaires des Marches, ne furent jamais reclus dans un ghetto.

Une nouvelle invasion du territoire fut l’occasion de ressusciter la fierté nationale des Saint-Marinais : le , le cardinal Giulio Alberoni, légat du pape en Romagne, s’attaqua à la République. Alberoni agissait ainsi pour son compte personnel et non par ordre du pape, et c’est vers ce dernier que Saint-Marin se tourna. Clément XII envoya sur place le cardinal Enrico Enriquez pour lui rendre compte de la situation. Sur la base des indications fournies par ce dernier, le pape enjoignit immédiatement au cardinal Alberoni de libérer Saint-Marin : le , moins de six mois après l’invasion, la République retrouva ainsi sa liberté.

Lorsqu’à partir de 1796, Napoléon Bonaparte assura sa domination à travers toute l’Italie en y fondant plusieurs États-satellites (République romaine à Rome, République parthénopéenne à Naples), Saint-Marin s’empressa de conclure des accords commerciaux avec ces nouvelles entités politiques, manifestant ainsi son alliance avec Bonaparte.

Il est souvent que Bonaparte, au cours de la campagne d’Italie, aurait donné l’ordre à ses troupes de s’arrêter aux frontières de Saint-Marin et de ne pas les franchir — le futur empereur était, selon , un grand admirateur de ce petit État qui n’avait jamais fait acte de soumission à quiconque. En guise d’hommage, il voulut même offrir à Saint-Marin deux canons, plusieurs chariots de céréales et surtout une expansion territoriale jusqu’à la mer. La perspective d’étendre leur territoire et de s’imposer aux yeux des autres nations fut déclinée : la communauté avait en effet parfaitement conscience qu’il leur aurait été par la suite impossible de vivre en harmonie avec leurs voisins et seuls les chariots de victuailles, peu compromettants, trouvèrent grâce à leurs yeux.

Pendant toute la période dite du " au cours de laquelle les mouvements révolutionnaires se multiplièrent en Italie, Saint-Marin servit de terre d’asile à de nombreux exilés. Après la répression des révolutions de 1848/49, Giuseppe Garibaldi y trouva par exemple refuge avant de recevoir la citoyenneté saint-marinaise en .

Dès le , un traité d’amitié et de coopération fut conclu entre Saint-Marin et le nouveau Royaume d’Italie, les deux États y étant considérés sur un pied d’égalité. La convention fut renouvelée le .

Après l’accession au pouvoir le des deux premiers capitaines-régents d’idéologie fasciste, le Parti fasciste saint-marinais (") remporta la majorité absolue des sièges lors des élections du 4 avril. Par la suite et malgré sa collaboration affichée avec le dictateur Benito Mussolini, la République ne fournit aucun soldat aux forces armées italiennes. Par ailleurs, la traditionnelle neutralité du petit État conduisit le gouvernement fasciste de Saint-Marin à ne pas s’engager officiellement dans la Seconde Guerre mondiale. Le  vit finalement la dissolution du Parti fasciste saint-marinais, trois jours après le renversement de Mussolini. Le petit État accueillit par la suite près de fuyant les combats plus au sud.

Après avoir chassé les troupes allemandes de la région, les États-Unis s’installèrent à Saint-Marin à titre provisoire jusqu’en , notamment pour aider au rapatriement des nombreux réfugiés qui s’y trouvaient.

Le pays a la particularité d’avoir été le premier pays d’Europe de l’Ouest à avoir un gouvernement communiste : entre 1945 et 1957, le Parti communiste saint-marinais gouverna en coalition avec le Parti socialiste saint-marinais. Saint-Marin est ainsi le premier pays au monde dans lequel un parti communiste est arrivé au pouvoir à la suite d’élections libres. Une nouvelle coalition dominée par les communistes – alliés cette fois à un autre parti socialiste minoritaire – gouverna entre 1978 et 1986, date à laquelle les communistes constituèrent un gouvernement avec leurs adversaires traditionnels du Parti démocrate-chrétien saint-marinais, les démocrates-chrétiens étant cette fois majoritaires. , le Parti communiste, imitant le Parti communiste italien, abandonna l’idéologie marxiste-léniniste et se rebaptisa le « Parti progressiste démocrate ».

Saint-Marin est devenu en 1988 un membre du Conseil de l’Europe et a adhéré en 1992 à l’Organisation des Nations Unies.

Saint-Marin est un État indépendant et la plus ancienne république du monde ayant continuellement existé depuis sa création. Sa Constitution, qui date de , est la plus ancienne constitution encore en vigueur de nos jours.

Le pouvoir législatif revient au Grand Conseil général (') dont les soixante membres sont élus par les citoyens tous les cinq ans. Le Conseil approuve le budget de l’État et nomme les deux capitaines-régents. Ces derniers sont concurremment chefs de l’État et dirigent le Congrès d’État (') : ils restent six mois en fonction et sont nommés solennellement deux fois par an le  et le . Cependant, ils peuvent être élus pour un deuxième mandat bien que cela n’arrive que très rarement. Certains ont à nouveau occupé ce poste après un certain laps de temps. Les deux capitaines-régents parlent d’une seule voix.

Le Congrès d’État, dirigé par les capitaines-régents, détient le pouvoir exécutif. Il est composé de dix secrétaires d’État ("").

Le « Conseil des Douze » ("Consiglio dei XII") est élu par le Grand Conseil général pour toute la durée de la législature. Il constitue le sommet de la juridiction administrative et la plus haute instance juridique de la République.

Le capitaine-régent, le Grand Conseil général, le Conseil des Douze et le Congrès d’État siègent en un même lieu : le palais public de Saint-Marin.

L’"Arengo" était autrefois une institution médiévale regroupant tous les chefs de famille mais ses prérogatives ont depuis été transférées au "". On désigne désormais sous le nom d’"Arengo" l’ensemble des Saint-Marinais disposant du droit de vote. Les citoyens sont convoqués deux fois par année au Conseil, le dimanche suivant l’entrée en fonction des capitaines-régents, et peuvent ainsi soumettre des questions d’intérêt public à leurs représentants.

La République de Saint-Marin entretient actuellement des relations diplomatiques et consulaires avec plus de soixante-dix pays, à l’intérieur comme à l’extérieur du continent européen. Les représentations diplomatiques du pays à l’étranger ont le plus souvent rang de consulats ou de consulats généraux, par exemple le consulat général de Francfort-sur-le-Main.

Saint-Marin est membre de nombreuses organisations internationales dont l’Organisation des Nations Unies, l’UNESCO, le Conseil de l’Europe, le Fonds monétaire international, l’Organisation mondiale de la santé ou la Cour pénale internationale. La République entretient également des relations officielles avec l’Union européenne et participe aux travaux de l’OSCE. Le , un référendum eut lieu avec comme résultat 50,28 % (soit ) en faveur de l’ouverture d’une procédure d’adhésion de Saint-Marin à l’UE ; cependant le quorum n’a pas été atteint pour valider ce vote.

Le territoire de Saint-Marin est divisé en neuf "castelli" (Châtellenie équivalant aux communes françaises) reprenant les anciennes délimitations des seigneuries. Chaque "castello" dispose d’un élu par les habitants, la ', dont la présidence est assurée par un « capitaine » (') élu tous les cinq ans.

La République de Saint-Marin (43° 56’ 06’’ N, 12° 26’ 56’’E) se situe à la pointe orientale du massif montagneux des Apennins. Le pays est frontalier de deux régions italiennes : l’Émilie-Romagne au nord-est et les Marches au sud-ouest.

Le territoire saint-marinais, de la forme d’un quadrilatère aux côtés irréguliers, est pour l’essentiel très accidenté. Sa superficie est de , c’est-à-dire inférieure à de nombreuses villes européennes moyennes. Les douze kilomètres séparant les extrémités nord et sud du pays sont dominés par l’imposant massif calcaire du mont Titano (rocher du Titan) qui culmine à . La ville de Saint-Marin se situe d’ailleurs au pied de son versant sud-ouest.

Deux cours d’eau principaux prennent leur source à Saint-Marin : l’ et le . Les deux autres rivières, le San Marino et le Marano, ne font que traverser le pays.

Saint-Marin est soumis à un climat de type méditerranéen qui a néanmoins tendance à s’adoucir par rapport à la côte en raison de l’altitude. En été, les températures varient de et en hiver de . Les saisons estivales particulièrement chaudes peuvent néanmoins conduire le thermomètre jusqu’à et il arrive en hiver de passer sous la barre des , auquel cas le mont Titano peut se couvrir de neige. Les précipitations tendent à se répartir de manière harmonieuse tout au long de l’année pour atteindre un niveau moyen de .

Les pentes abruptes du mont Titano, tout comme les autres paysages escarpés de Saint-Marin, sont recouverts d’une végétation assez dense, typique de l’écosystème méditerranéen. On y trouve aussi bien des forêts à essences feuillues, remplies d’érables et de chênes, que des étendues de conifères, en particulier de nombreux pins. Dans les zones broussailleuses et buissonnières du maquis dominent le laurier, la myrte, la lavande, des fraisiers et les oliviers.

La faune de la région se compose surtout d’espèces ayant su s’adapter ou même profiter de la présence humaine et que l’on peut par conséquent observer à proximité des habitations : c’est notamment le cas du renard, du lièvre, du hérisson et de la martre. D’autres animaux, comme le chevreuil ou la belette, ont élu domicile dans les étendues forestières qui offrent une bonne protection. Les espèces d’oiseaux sont tout aussi variées : des faucons nichent par exemple sur les rochers les plus abrupts ou au sommet des arbres. Parmi les oiseaux chanteurs, on compte entre autres le rossignol, le loriot, le chardonneret, le serin et la linotte mélodieuse.

Saint-Marin ne possède aucune ressource naturelle : son territoire est donc principalement tourné vers l’agriculture et la sylviculture, deux domaines cependant en déclin en raison de l’accroissement de la population. On cultive notamment les céréales, la vigne, les olives et les fruits. L’élevage se concentre pour l’essentiel sur les bœufs et les cochons.

Jusqu’aux années 1960, les Saint-Marinais vivaient principalement de l’agriculture, de l’élevage et de l’exploitation de quelques carrières de pierre. Depuis, les activités du petit pays se sont diversifiées avec l’essor de l’artisanat, du commerce et même de l’industrie, tous ces domaines ayant été favorisés par l’explosion du tourisme. Parmi les produits locaux, on compte des objets en céramique, des meubles, des confiseries, des liqueurs, de la peinture et du vernis, ou encore des produits textiles en soie.

Saint-Marin exporte surtout du vin et de la laine, des produits artisanaux et des timbres. La vente de timbres saint-marinais aux passionnés de philatélie à travers le monde assure en effet 10 % du PIB national. L’autre grande source de profits, le tourisme, représente directement ou indirectement plus de 60 % des revenus de l’État : aucun impôt ou presque n’est exigé des habitants. Les importations, quant à elles, consistent principalement en produits manufacturés et en biens de grande consommation. Mais Saint-Marin doit également se procurer de l’or en quantité importante pour ses nombreux orfèvres et bijoutiers.

Le revenu annuel net moyen s’élevait à en 2005. 52 % de la population active travaille dans le secteur des services, 41 % dans le secteur secondaire et 7 % dans l’agriculture. L’inflation reste modérée à 2,6 %.

Jusqu’à l’entrée en vigueur de l’Union économique et monétaire, la monnaie du pays était la lire italienne. En 1972, et après une interruption de , Saint-Marin avait recommencé à frapper ses propres pièces de monnaie (les "lires saint-marinaises"), qui pouvaient s’utiliser indifféremment de la lire italienne et avaient la même valeur. Quelques pièces en or furent également frappées un peu plus tard, mais n’avaient cours légal que sur le territoire de la République. Depuis le , à la suite d’un accord avec l’Union européenne, Saint-Marin utilise officiellement l’euro comme monnaie et a l’autorisation de frapper ses propres pièces avec une face nationale, tout comme les autres États-membres de la zone euro.


La langue officielle de Saint-Marin est l’italien. Du fait de la forte affluence touristique dans la région, presque tous les habitants peuvent cependant s’exprimer couramment dans une autre langue, le plus souvent en anglais, en allemand ou en français.

Le romagnol, un dialecte du nord-italien, est en outre assez répandu à Saint-Marin, en particulier chez les personnes les plus âgées.

92,3 % de la population est de confession catholique et seuls 3 % des habitants se déclarent sans religion. Cette prédominance de l’Église catholique se retrouve dans le paysage architectural de la République, qui compte plusieurs églises ainsi qu’une basilique monumentale. Le territoire de la République dépend du diocèse de San Marino-Montefeltro, dont la juridiction s’étend sur une partie des provinces italiennes voisines.

La population saint-marinaise s’élevait en février 2015 à . Elle se compose à 83,1 % de Saint-Marinais de souche et à 12 % d’Italiens. Près de de Saint-Marin vivent par ailleurs à l’étranger. Le pays, en raison de sa taille réduite, a une forte densité de population, de l’ordre de 475 habitants par km. Le taux de natalité atteint tandis que le taux de mortalité n’est que de , ce qui fait que la population connaît toujours un accroissement naturel positif.

La capitale Saint-Marin ne compte que  : la population se concentre en effet davantage dans les deux "castelli" de Serravalle, avec , et de Borgo Maggiore, avec . Suivent après la capitale, Domagnano (), Fiorentino (), Acquaviva () et Faetano (). Les autres "castelli" sont plutôt des villages ruraux : c’est le cas de Chiesanuova () et de Montegiardino ().

La célébration de la fête nationale, le 3 septembre (en référence au 3 septembre 301) est ponctuée de festivités populaires et folkloriques.

La nomination des capitaines-régents tous les six mois, de même, est l’occasion d’une grande cérémonie. À ce titre, la garde du Grand Conseil général ("") joue un rôle déterminant : fondée à la suite de la victoire remportée contre le cardinal Alberoni en 1740, ce corps de garde composé de citoyens volontaires utilise toujours ses uniformes historiques et reste habilité à assurer la protection des capitaines-régents et du Conseil. Les gardes, de concert avec les principales personnalités temporelles et spirituelles de Saint-Marin, organisent ainsi les festivités liées à l’entrée en fonction des deux nouvelles têtes de l’exécutif.

Saint-Marin possède une petite université, l’'. Elle comprend notamment le "Centre international d’études sémiotiques et cognitives", qui fut fondé par l’auteur italien Umberto Eco. Avant l’apparition de cet établissement, Saint-Marin disposait déjà d’un institut privé et soutenu par le gouvernement : l’Académie internationale des sciences de Saint-Marin (', ou « "AIS San Marino" ») dont l’une des langues officielles est l’espéranto. Cette dernière a néanmoins transféré la plupart de ses activités à l’étranger.

La ville de Saint-Marin compte de nombreux musées. Le palais ' abrite ainsi le musée national (') et ses milliers de pièces retraçant l’histoire de Saint-Marin : découvertes archéologiques, documents historiques, pièces de monnaie et toiles de peinture. L’édifice appelé « Deuxième Tour », quant à lui, contient un musée des Armes antiques (") proposant au visiteur plus de couvrant principalement la période allant du .

L’Italie a beaucoup influencé la gastronomie de Saint-Marin avec les pâtes, les plats de viandes grillées…

Les desserts sont aussi très présents dans la gastronomie de Saint-Marin comme la caciatello (gâteau à la crème fraîche), les beignets aux raisins d’or ou encore le bustrengo (gâteau à la polenta et aux pommes).

Saint-Marin est plus connu musicalement au niveau international pour sa participation à l’Eurovision. Le pays fit une première apparition en 2008 avant de revenir de manière régulière à partir de 2011. Valentina Monetta a représentée son pays quatre années de suite de 2012 à 2014, et en 2017 en duo avec le chanteur Jimmie Wilson. 2014 reste pour le moment la seule année où Saint-Marin s’est qualifiée pour la finale.

Le pays dispose d’une chaîne de télévision publique, San Marino RTV, créée en 1993 et diffusant ses programmes à la fois localement et par satellite. Le service public produit également deux stations de radio : RSM San Marino et San Marino Classic. La télévision et la radio italienne sont reçues dans le pays.

Le Grand Prix automobile de Saint-Marin n’avait pas lieu sur le territoire du petit pays mais cent kilomètres plus au nord-ouest à Imola, sur le circuit Enzo e Dino Ferrari. Cette circonstance tient à une suite d’événements remontant au début des années 1980.

En 1980, le Grand Prix automobile d’Italie, traditionnellement organisé à Monza, avait été transféré à Imola. À la suite de nombreuses protestations, cette décision fut annulée dès l’année suivante. Afin toutefois de ne pas avoir à renoncer au circuit d’Imola, situé au cœur de l’univers Ferrari, le Grand Prix automobile de Saint-Marin vit le jour en 1981 et continua à être organisé jusqu’en 2006. Il fut marqué notamment par les décès de Roland Ratzenberger aux essais et d’Ayrton Senna en course lors de l’édition .

La République de Saint-Marin a également servi de prête-nom à plusieurs manches du championnat du monde de vitesse moto. Le Grand Prix moto de Saint-Marin s’est disputé, à l’instar du Grand Prix de , sur le tracé d’Imola (en 1981 et 1983) mais également sur le circuit du Mugello (en 1982, 1984, 1991 et 1993) ainsi que sur celui de Misano (de 1985 à 1987 et depuis 2007).

Malgré sa population très réduite, le pays dispose de son propre championnat de football dont les modalités sont gérées par la fédération nationale (", ou FSGC). Cette dernière, fondée en 1931, regroupe quinze équipes qui s’affrontent tout d’abord au sein de deux groupes de sept ou huit équipes. Les trois meilleures équipes de chaque groupe jouent ensuite pour la coupe.

Le Saint-Marin Calcio participe cependant au championnat d’Italie de Série D3 (troisième division italienne).

Saint-Marin compte une équipe nationale de football depuis 1986. L’équipe nationale a connu en tout et n’a pour l’instant gagné qu’une seule fois : sous la supervision de l’entraîneur Giampaolo Mazza, les Saint-Marinais battent le Liechtenstein le lors d’un match amical.

Saint-Marin a pour codes :




</doc>
<doc id="2790" url="https://fr.wikipedia.org/wiki?curid=2790" title="Sport au Mexique">
Sport au Mexique

Le Mexique est l'une des plus grandes nations de boxe anglaise, de nombreux grands champions en sont originaires tels que Erik Morales, Julio César Chávez, Rafael Marquez, Juan Manuel Marquez Marco Antonio Barrera et Saúl Álvarez.

Dans le "fútbol", "diablos rojos de Toluca", "Club América" et les "Chivas de Guadalajara".

Les joueurs célèbres sont Hugo Sánchez, Claudio Suárez, Luis Hernández, Francisco Palencia, Cuauhtémoc Blanco, Jared Borgetti, Rafael Márquez, Ramón Ramírez, Jorge Campos, Omar Bravo, Ramón Morales, Oswaldo Sánchez, Óscar Pérez et Jesús Arellano.

Le Mexique a accueilli la coupe du monde de football en 1970 et en 1986.




Il existe au Mexique un grand nombre de sports traditionnels. Ils sont souvent affiliés à la Fédération Mexicaine de Jeux et Sports autochtones et traditionnels. En 2004 lors des rencontres de Colima, 80 sports et jeux étaient présents.



</doc>
<doc id="2791" url="https://fr.wikipedia.org/wiki?curid=2791" title="Séville">
Séville

Séville (en ) est une ville du Sud de l’Espagne, capitale de la province de Séville et de la communauté autonome d’Andalousie.

Quatrième ville du pays, elle accueille une population de en . Située au centre d'une riche région agricole, traversée par le Guadalquivir et connectée à un important réseau de communication, la cité est le cœur économique, politique et culturel de l’Andalousie, et constitue l’une des plus importantes villes du pays mais aussi de l'Europe du Sud.

C’est également une ville au passé prestigieux, dotée d'un patrimoine artistique d’une immense richesse, ce qui en fait une des destinations touristiques les plus prisées d’Europe et l'auréole d’un certain prestige. Ses monuments, les nombreux artistes qui y sont nés ou y ont œuvré, son histoire glorieuse, ses fêtes traditionnelles, mais aussi son climat, ont contribué à sa renommée.

Située dans le Sud-Ouest de l'Espagne, Séville bénéficie d'un emplacement privilégié, largement ouvert vers l'extérieur et qui s'appuie sur deux caractéristiques géographiques majeures.

D'une part, la cité est traversée par le Guadalquivir, navigable jusqu’à la capitale andalouse. Le fleuve lui offre un accès à la mer, distante de 70 km, ce qui explique sa place prépondérante dans l'histoire d'une ville qui s'est construite par et autour de lui. Voie de communication essentielle, le Guadalquivir a permis le développement d'un commerce fluvial encore actif à ce jour, et qui connut son apogée au moment de la constitution de l'Empire espagnol. À noter que depuis 1948, le Guadalquivir, dévié pour éviter les inondations, longe la ville par l'ouest. Le cours d'eau qui traverse Séville, et sur lequel se trouve le port fluvial, est une darse, appelée canal Alphonse-XIII.

D'autre part, Séville domine la "vega" (plaine) du Guadalquivir, la "Campiña sevillana". Cette vaste étendue de plaines légèrement ondulées est exploitée depuis des siècles pour sa fertilité qui a contribué à la richesse de la ville. Cultures céréalières, maraîchères, oléicoles, ou encore élevage de bétail (toros braves notamment), n'ont cessé d'être développés sur ces terres qui continuent à faire vivre la région.

Cette position enviable offre à Séville une franche ouverture vers les régions limitrophes, sur lesquelles s'étend son influence : l"'Alcor" et les "sierras" nord et sud de la province.

La ville, desservie par un réseau de communications dense, se trouve à de Cadix, de Cordoue, de Malaga, de Grenade, de Madrid et de Barcelone.

Située dans le Sud de l'Espagne, non loin du continent africain, Séville bénéficie d'un climat très nettement méditerranéen, tout en subissant des influences continentales.

Sa position modérément éloignée de la mer, dans la vaste plaine du Guadalquivir, lui permet de jouir d'un climat relativement doux et clément tout au long de l'année. La température moyenne annuelle s'établit à (minimales :+ ; maximales :+). Néanmoins, Séville connaît des étés particulièrement longs et torrides, avec des températures maximales moyennes atteignant ou dépassant les de mai à octobre. Les pics de températures sont atteints entre juin et septembre, à une période où le mercure dépasse ou atteint constamment la barre des , voire plus avec une température minimale de . Le maximum enregistré est de , tandis que le minimum est de . 

L’ensoleillement est l’un des plus élevés du pays, avec une durée de plus de 3000 heures par année.

Une température de a été relevée le 5 septembre 2016 à la station de Sevilla San Pablo, ce qui constitue un nouveau record mensuel, l'ancien record de ayant été pulvérisé de plus de .

Le régime pluviométrique de la capitale andalouse correspond également à celui d'un climat méditerranéen, avec en moyenne par an. Néanmoins on compte 50,5 jours de pluie par an. Les précipitations se concentrent sur la période d'octobre à avril avec en décembre 7,5 jours de pluie. Les chutes de pluie sont en revanche quasiment nulles au cœur de l'été : on compte 0,2 jour de pluie en juillet et 0,5 en août.

Le nom de "Sevilla" provient du toponyme ibère I-Spal (Isfân en carthaginois a donné l'Hispania romaine, Espana médiévale) romanisé sous la forme Hispalis, devenu Isbaliya/Isbiliya/Ishbalyia/Isbilyia au sous l'occupation musulmane.
La devise de Séville est . Le 8 représente ici un écheveau de laine, "madeja" en espagnol. La phrase se lit donc : "no madeja do", contraction de "No me ha dejado" (« elle ne m’a pas laissé »). Cette formule fait référence au roi Alphonse X le Sage, lequel, chassé du pouvoir par son fils Sanche, futur Sanche IV, en 1282, se réfugie à Séville, l’une des très rares villes de sa couronne à lui être restées fidèles face à son fils rebelle. Il y meurt en 1284. Cette devise figure sur le drapeau municipal.

Le blason, quant à lui, représente le roi Ferdinand III de Castille, conquérant de la ville en 1248, entouré de saint Isidore et de son frère saint Léandre qui furent tous deux archevêques de Séville aux . La devise de la cité figure au bas du blason.

Selon la légende, Séville est fondée par les Tartessiens autour du , sous le nom de "Ispal" ou "Spal" (selon les sources latines). Le premier site de peuplement stable a été localisé au bord du Guadalquivir, sur un petit promontoire, aujourd’hui connu sous le nom de "Cuesta del Rosario". C’est à cet endroit que le fleuve cesse d’être navigable pour les grandes embarcations.

La ville est ensuite peuplée par les Phéniciens et les Grecs.

Séville se retrouve au cœur de la Deuxième guerre punique : les Carthaginois s'en emparent en -216. La bataille d'Ilipa permet aux Romains de la conquérir en -206.

La ville est rebaptisée Hispalis et est reconstruite. Son tempérament mouvant amène néanmoins les Romains à fonder une autre cité à proximité : Itálica, qui devient la ville résidentielle, tandis qu'Hispalis conserve ses fonctions commerciales.

Jules César la dote d'une nouvelle enceinte en -49, puis l'élève en -45 au rang de colonie romaine. Elle devient alors une cité importante, dominant toute la Bétique.

Au moment des Grandes invasions, Séville est conquise successivement par les Vandales en 426, puis par les Suèves en 441.

Ces derniers seront néanmoins chassés par les Wisigoths après la bataille de la rivière Órbigo en 456.

Les Wisigoths sont chassés de Gaule par les Francs en 507. Commence alors une lente mais déterminante conquête de la péninsule ibérique, sur laquelle les Goths avaient commencé à prendre leurs marques au siècle précédent.

Hispalis est rebaptisée Spali, et se retrouve au centre des conflits qui déchirent le royaume :

La cité s'exprime désormais à travers la culture, dont elle devient un des plus brillants foyers d'Occident, grâce à l'action de saint Léandre et saint Isidore, les deux plus illustres archevêques de Séville, qui développent notamment la bibliothèque. Jacques Fontaine parle même d'une « renaissance isidorienne ».

Quelques mois à peine après l'invasion des troupes musulmanes dans la péninsule ibérique en avril 711, Moussa Ibn Noçaïr parvient à conquérir Séville. La ville occupe le cœur de l'activité politique d'Al-Andalus avant que la capitale ne se fixe définitivement à Cordoue. Les premiers temps de l'Islam à Séville sont sanguinaires. Mais la ville se relève grâce au legs des romains et wisigoths. Sa prospérité est due à ses imposantes richesses agricoles.

L'arrivée à Cordoue d' Abd al-Rahman, qui fonde l'émirat omeyyade en 756, marque le début d'une longue période de révoltes vis-à-vis du pouvoir central. Les entreprises successives de rébellion seront à chaque fois étouffées par les troupes émirales, de manière plus ou moins violente. Ces soulèvements réguliers sont néanmoins le signe de la difficulté pour le pouvoir cordouan d'imposer correctement son autorité. Le premier grand chantier entrepris, dans une cité qui se développe à un rythme soutenu, est celui de la destruction de l'église des origines aux fins de construire une mosquée, à partir de 829-830, à l'emplacement actuel de l'église du Salvador. Cette époque est également marquée par les incursions dévastatrices et répétées des Vikings, qui pénètrent jusqu'à Séville par le Guadalquivir. La première de ces incursions, en 844, est marquée par un bilan désastreux. Les autorités de l'envahisseur maure décident dès lors la construction de chantiers navals et la constitution d'une flotte, qui permet de repousser les tentatives d'incursion postérieures. Si Séville prospère économiquement et culturellement à la fin du , elle subit de plein fouet les conséquences d'une guerre ouverte opposant différents clans cherchant à accaparer le pouvoir dans la cité. Les chrétiens et les juifs subissent les différentes guerres jusqu'en 902.

L'arrivée sur le trône d'Abd al-Rahman III en 912 signe le retour en force de Séville dans le giron cordouan. La fermeté de l'émir, autoproclamé calife en 929, permet d'affermir le pouvoir des omeyyades dans la ville, dont les velléités rebelles sont matées, et les murailles abattues en guise de châtiment. Elle conserve toutefois un rôle non négligeable dans le dispositif militaire de l'État cordouan et continue son développement. Les premières pierres de ce qui deviendra plus tard l'actuel alcazar sont posées au . La chute du Califat en 1031 libère Séville de sa tutelle musulmane qui asservit les communautés. Surgissent alors dans tout Al Andalus des taïfas. Celle de Séville est l'une des plus puissantes et absorbe peu à peu nombre de territoires voisins. Sous la dynastie des Abbadides, la cité connaît une période d'apogée culturelle. La cour des souverains sévillans est le lieu d'une intense activité artistique et littéraire, marquée par un raffinement dont la renommée traverse rapidement le Guadalquivir.

Face au projet de libération que représentent les troupes d'Alphonse VI de Castille après la prise de Tolède en 1085, Abbad III al-Mutamid décide de faire appel à l'émir almoravide Youssef Ibn Tachfin. Après plusieurs interventions, il envahit Al Andalus à partir de 1090. Séville tombe en 1091. L'échec des Almoravides, incapables de s'incorporer dans la population autochtone, et de plus en plus en difficulté face aux royaumes du nord de l'Espagne, entraîne le débarquement des Almohades en 1147. La construction d'une nouvelle grande mosquée est décidée par le calife Abu Yaqub Yusuf en 1172. Son minaret, la Giralda, édifiée entre 1184 et 1198, témoigne de l'architecture de l'époque. Par ailleurs, l'alcázar est réhabilité et la muraille est reconstruite et dotée de puissants éléments défensifs, dont la Torre del Oro. La décomposition progressive du pouvoir almohade commença à la suite de la Bataille de Las Navas de Tolosa en 1212. La ville finit par être conquise par Ferdinand III de Castille, lors du siège de Séville après 18 mois de siège et d'offensives tant terrestres que fluviales.

Après la conquête opérée par Ferdinand III de Castille (siège de Séville pendant 18 mois), les rois et le clergé catholique veulent peu à peu remodeler la ville : destruction de la mosquée, remplacée par une cathédrale (que l'on veut l'une des plus vastes de la chrétienté), construction de nouveaux palais, d'églises et de couvents. En revanche la judería change peu.
Si la capitale du royaume de Castille est Burgos, la cour est en fait itinérante, et de nombreux souverains prennent plaisir à séjourner plus ou moins durablement à Séville (dont Alphonse X le Sage, Pierre le Cruel). Cela stimule l'activité du bâtiment, l'artisanat d'art, la vie culturelle. Grâce à l'irrigation développée par les Arabes, les campagnes de la région sont florissantes. Comme les navires de l'époque ont un faible tirant d'eau, on peut embarquer à Séville pour les navigations océanes (Vespucci, Magellan). La cité est débordante de vie, et Isabelle crée une Bourse du commerce en 1503. On a peut-être exagéré l'importance de Séville en lui attribuant alors habitants, mais, même si elle n'en comporte que , c'est l'une des plus grandes villes du monde de cette époque.

Ce qu'on entend habituellement par « siècle d'or » s'étend du règne de Charles Quint à celui de Philippe IV. Le bilan pour Séville est contrasté. En points défavorables : l'ensablement progressif du Guadalquivir, qui entraîne un transfert à Cadix d'une bonne partie du trafic maritime, le départ des juifs et des musulmans. En points favorables : l'existence d'une université fondée en 1504, des travaux commandés par les rois, l'existence d'une brillante école de peinture, où l'on distingue trois générations : Roela et Pacheco à la première, Herrera le Vieux et Zurbaran à la deuxième, Murillo à la troisième. Velasquez est né à Séville dans ce milieu porteur. Cette école de peinture doit beaucoup à des commandes de monastères, ce qui suggère l'existence d'une vie religieuse intense et une certaine richesse, grâce à des donations faites aux institutions religieuses et aux revenus tirés de propriétés foncières.

Le déclin du est relatif. Il semble bien que Cadix, où est transféré l'entrepôt du commerce colonial ainsi que la "Casa de contratación" (chambre de commerce) locale, marque beaucoup de points dans la compétition avec Séville, et l'ampleur des constructions baroques à Cadix en témoigne. Néanmoins, Séville n'est pas délaissée et elle reçoit une belle manufacture de tabac, due à l'architecte Sebastión Van der Borcht. Le tabac arrive d'Amérique, et on voit que Séville bénéficie de retombées du commerce atlantique. Cette manufacture emploie autour de ouvrières. Par ailleurs, le roi Charles III crée une fabrique de canons qui, pour l'époque, utilise une technologie avancée. Il y a des métiers textiles (laine, soie) et une fabrication importante de porcelaine. On est certain que la population de Séville au était de habitants, ce qui est beaucoup. Séville est alors une ville de sociétés savantes, de bibliothèques et de savoir encyclopédique.

Les troupes françaises prennent la ville en 1810. Durant l'occupation de Séville, entre janvier 1810 et août 1812, l'armée française met en œuvre une spoliation systématique des biens ecclésiastiques : le patrimoine artistique des églises et monastères est particulièrement visé. Des tableaux de Herrera le vieux, Zurbarán, Roelas, Pacheco, et surtout de Murillo, peintre auquel Soult s'intéresse tout particulièrement, sont enlevés de leurs lieux d'origine, et emmenés à l'Alcazar de Séville. L'église de l'hôpital de la Charité, le couvent Saint-François ou la cathédrale sont privés entièrement de leurs œuvres précieuses.

Une fois à l'Alcazar, Eusebio Herrera, un fonctionnaire collaborant avec les troupes françaises, les redirige vers d'autres lieux. Un total de 999 tableaux aurait donc été saisis par les troupes françaises : une sélection est envoyée au musée royal de Madrid, 150 d'entre eux – les plus beaux – partent directement au Louvre. Soult et d'autres officiers ou fonctionnaires français se serviront également au passage. Des œuvres de Murillo présentes dans Séville, seules celles conservées au couvent des capucins échapperont aux Français, déplacées par les moines préventivement à Cadix jusqu'à la fin de la guerre.

L'Exposition ibéro-américaine de 1929, longtemps repoussée, notamment à cause de la Première Guerre mondiale, marque l'entrée de Séville dans le .

La ville accueille l'Exposition universelle de 1992, année faste pour l'Espagne puisque cette même année, Madrid est désignée capitale européenne de la culture et Barcelone accueille les Jeux olympiques d'été.

Séville abrite l'Institut de prospective technologique du Centre commun de recherche de l'Union européenne.

La commune de Séville est le centre d'une agglomération qui s'étend sur , et regroupe habitants, ce qui en fait la quatrième agglomération d'Espagne.

Selon l'Institut espagnol de la statistique (INE), la ville en elle-même comptait habitants en 2013, la plaçant également au quatrième rang des villes espagnoles en termes de population, après Madrid, Barcelone et Valence.

Ces indications chiffrées sont révélatrices du dynamisme de la ville qui attire, en raison de facteurs divers, de nombreux espagnols et étrangers. Centre de l'agglomération, Séville voit néanmoins se développer autour d'elle des cités dortoirs, peuplées de travailleurs qui se rendent dans la capitale pour travailler, mais résident à l'extérieur. Cette situation explique en partie les problèmes de transports importants observés depuis plusieurs années, et le développement de lignes de tramway (dont la première ligne est entrée en service le 28 octobre 2007) et de métro, dont la première relie depuis 2009 l'est à l'ouest en passant sous le Guadalquivir.

Selon le dernier recensement complet mené par l'IAE, en 2001, une part très nettement majoritaire de la population est employée dans le secteur tertiaire, stimulé notamment par l'activité touristique. 80,60 % de la population active travaille dans ce secteur. Le secteur secondaire représente encore 17,73 % des actifs ; le secteur de la construction monopolise 39,05 % des emplois du secondaire, soit 6,92 % du total de la population active sévillane. Quant aux emplois liés à l'agriculture et à la pêche, ils ne représentent plus que 1,68 % des actifs de la ville.

L'article 140 de la Constitution, la loi 7/1985 du 2 avril 1985 portant sur les bases du régime local, ainsi que le Statut d'autonomie pour l'Andalousie définissent les attributions des municipalités et du maire. Les articles 22 et 23 de la loi de 1985 précisent par ailleurs le fonctionnement des deux assemblées d'élus chargées de la gestion de la ville, le conseil municipal et le conseil de gouvernement local.

La mairie ("ayuntamiento") regroupe l'ensemble des services municipaux. Elle est installée dans l'hôtel de ville, un bâtiment du , située sur les places Neuve et Saint-François.

Il détient le pouvoir exécutif local et a autorité sur l’ensemble des services administratifs et financiers de la ville, qu’il est chargé de diriger. La loi de 1985 lui donne notamment compétence en matière de gestion économique et financière, emploi public, police municipale… Ces compétences sont précisées par l'article 92 du Statut d'autonomie andalou.

Le conseil municipal ("Pleno") est composé de l’ensemble des 31 conseillers ("concejales") désignés à l'issue des élections municipales. Il est présidé par le maire et dispose d'un grand nombre d'attributions. Il a en charge l'élection du premier magistrat, et son éventuelle destitution, le contrôle de l'action municipale, l'approbation des projets et règlements municipaux, du budget. Les travaux du conseil municipal sont étudiés et préparés en commissions. Les sessions ordinaires ont lieu le troisième jeudi de chaque mois, à l’exception du mois d’août.

Le conseil de gouvernement local ("Junta de Gobierno local") constitue un organe plus resserré. Présidé par le maire, il se compose de conseillers municipaux désignés par ce dernier, à hauteur maximale d’un tiers du total des élus municipaux. Lors de ces réunions hebdomadaires, dont les délibérations sont tenues secrètes, les membres de ce conseil politique élaborent, discutent et approuvent les projets qui seront ensuite débattus en conseil municipal : projets de règlements, budget… Ils statuent également sur l’offre d’emplois publics à la mairie.

Le , le « Règlement des juntes municipales de districts » ("Reglamento Orgánico de las Juntas Municipales de Distritos") a divisé Séville en onze districts. Chacun des districts est organisé par une "junte municipale de district" qui possède son délégué et ses bureaux administratifs.

Même si le règlement de 2005 a défini très précisément leurs limites, la notion de quartier est, à Séville, plus souvent historique et culturelle qu'administrative et reste donc floue. Le sentiment d'appartenance des habitants influe sensiblement sur la définition des quartiers de la ville qui sont souvent constitués autour des anciennes paroisses dans le centre historique. Leur nombre et leurs frontières évolue logiquement avec le temps et la transformation de la ville. La structure du centre historique est particulièrement difficile à cerner. On y distingue de grands ensembles ou zones (Macarena, Santa Cruz…), eux-mêmes divisées en sous-unités, sans que cela ne soit tout à fait bien établi d'un point de vue légal. On trouvera ainsi à la Macarena les quartiers de Santa Marina ou San Julián, ou encore le quartier de Santa Ana à Triana, autour des églises éponymes.

La capitale andalouse est connectée à un important réseau de communications, la reliant par voies routière, aérienne et ferroviaire à l’ensemble de l’Andalousie, de la péninsule ibérique et au reste de l’Europe. L’Expo ’92 a joué un rôle primordial dans le développement des infrastructures de transports, le président du gouvernement Felipe González, sévillan d’origine, ayant activement appuyé cette politique de désenclavement de la cité.
Par ailleurs, la municipalité et le gouvernement andalou ont mis en place un réseau très dense de transports urbains par autobus. La première ligne de tramway a été inaugurée en octobre 2007 entre la plaza Nueva et le Prado de San Sebastián. De plus, la première ligne de métro est entrée en service le 2 avril 2009.

Séville dispose d'un aéroport situé à quelque du centre de la ville : l'Aéroport de "Sevilla San Pablo". Totalement restructuré et agrandi à l’occasion de l'Expo '92, le terminal est désormais relié aux principaux aéroports du pays (Barcelone, Madrid, Palma, Bilbao…) et d'Europe (Paris, Londres…). Quoique placé dans l'ombre du grand aéroport international de Málaga, San Pablo a reçu, en 2005, passagers, dont 22,30 % en provenance de l’étranger.

En prévision de l’Expo ’92, Séville s’est vu accorder la première ligne à grande vitesse espagnole (AVE), reliant la ville à Madrid, "via" Cordoue. La très moderne gare de Séville-Santa Justa a été bâtie afin d’accueillir les nouvelles rames de l’AVE, et fut inaugurée par le roi Juan Carlos peu avant l’Exposition. La gare est desservie quotidiennement par une trentaine de trains à grande vitesse, qui ont transporté passagers en 2006.
Néanmoins, la configuration des lignes classiques espagnoles ne permet pas à l’heure actuelle de relier directement Séville à toutes les grandes villes espagnoles. Seules quelques agglomérations sont connectées à elle, telles Barcelone ou Valence.

En revanche, la Renfe et le gouvernement andalou ont développé un excellent réseau régional, unissant les plus importantes localités de la province et de la communauté. D’autre part, Séville bénéficie d’un service de Cercanías (réseau de banlieue) qui la connecte régulièrement avec les communes de son aire métropolitaine.

Séville jouit d'un raccordement optimal au réseau routier ("autovías", voies rapides) et autoroutier ("autopistas", autoroutes payantes) national, qui relie la capitale andalouse aux principales villes du pays. Vers les villes andalouses, la ville, ceinte de rocades (SE-30, SE-40…) et de voies d'accès (A-8002…), est desservie par l'AP-4 (Séville - Cadix) et l'A-92 (Séville-Almería par Grenade), mais également par l'A-47 et l'A-49. Ces deux dernières infrastructures routières la relient au Portugal, par Rosal de la Frontera et par Huelva et Ayamonte, respectivement. Les liaisons avec le reste de l'Espagne sont assurées par l'autoroute A-66 (Gijón - Salamanque - Mérida - Séville) et l'A-4 (Séville - Cordoue - Madrid).
Le transport en autocar est bien plus utilisé en Espagne que dans d’autres pays d’Europe, comme la France. Séville est dotée de deux gares routières, gare routière du Prado de San Sebastián et gare routière de Séville-Plaza de Armas), d’où sont assurées des liaisons avec toute l’Andalousie, l’Espagne, le Portugal et l’Europe.

La municipalité, la diputación et la communauté autonome ont organisé un vaste réseau de transports urbains, géré par l’entreprise Tussam, qui assure le fonctionnement des dizaines de lignes d’autobus qui irriguent la ville et ses environs proches. Depuis peu, dans un souci de protection de l'environnement, certains bus roulant au gaz naturel ont été mis en circulation.
En 2003, en coopération avec le Ministère des Transports, le Gouvernement andalou et la ville ont engagé les travaux de construction de la première ligne de métro sévillane. Cette initiative répond aux besoins croissants de transport dans l'agglomération, prise dans les embouteillages quotidiens. Projetée dans les années 1970, puis abandonnée peu de temps après pour des raisons techniques et financières, cette ligne a finalement vu le jour en avril 2009. Elle devrait être complétée par d'autres liaisons souterraines durant les années suivantes.

Toujours dans le souci d'optimiser le système de transports, une ligne de tramway, baptisée "MetroCentro" a été construite sur à travers le centre de la ville (entre la gare de San Bernardo et la plaza Nueva). Elle a été inaugurée le et prolongée en avril 2011. Créée pour désengorger le centre historique en interdisant la circulation sur l'Avenida de la Constitución, elle a motivé le déplacement de la principale plaque tournante du réseau de bus (auparavant à la Puerta de Jerez) plus au nord sur le parcours du tram, au Prado de San Sebastián.

C'est également par souci de désengorgement du centre que plusieurs dizaines de kilomètres de pistes cyclables ont été mis en place ces dernières années. En parallèle, la ville a installé en 2007, par l'intermédiaire de l'entreprise SEVICI de nombreux points de location de vélos, dont le nombre ne cesse d'augmenter : en 2011, bicyclettes sont disponibles sur 250 points de location à travers la ville.

L’activité économique de Séville ne saurait être détachée du contexte géographique et urbain de la ville. La capitale de l’Andalousie est le centre d’une vaste agglomération, dont la croissance soutenue témoigne de l’attractivité de la ville et de ses alentours, qui bénéficient en retour de l’attraction qu’exerce le chef-lieu, en voyant s’installer de nombreux habitants mais aussi de vastes zones industrielles et commerciales.

Le climat et l’art de vivre sévillans sont des facteurs d’attractivité pour une ville dotée d’un excellent réseau de communications, et jouissant d’un emplacement géographique privilégié. Séville se situe ainsi à la tête des villes andalouses dans le domaine économique.

Les infrastructures dont dispose la ville contribuent à la croissance d'une économie dominée par le secteur des services, mais dans laquelle l'industrie tient encore une place non négligeable.

Le développement économique de la cité et de son aire urbaine s’explique par la présence d’infrastructures fondamentales pour la circulation des biens et des personnes, mais également pour l’évolution des entreprises et de leurs activités. Leur création a accompagné la croissance de l’agglomération sévillane.

Outre le réseau de transports optimal la desservant (voir supra), Séville dispose du seul port fluvial de la péninsule ibérique, situé à de l’embouchure du Guadalquivir. Ce complexe portuaire offre un accès à l’Atlantique et à la Méditerranée, et permet des échanges de marchandises entre le sud de l'Espagne (Andalousie, Estrémadure) et l’Europe, le Moyen-Orient et de l’Afrique du Nord. Le port a subi ces dernières années d’importants travaux de restructuration et d’agrandissement. Le tonnage annuel s’élevait à 5,3 millions de tonnes de marchandises en 2006.

Séville possède par ailleurs un Centre de transport de marchandises. Ce complexe, situé à l’est de la ville, est connecté aux réseaux ferroviaire et routiers, lesquels lui permettent un accès aux zones portuaire et aéroportuaire.

Séville s’étant tournée depuis une quinzaine d’années vers la promotion du tourisme d'affaires, elle s'est pourvue à cet effet d'un Palais des congrès. Celui-ci accueille divers foires et congrès, et s’est hissé au troisième rang espagnol en termes de fréquentation annuelle, laquelle s’élève à un million de visiteurs.

Enfin, décidés à renforcer la dimension technologique et industrielle de l'activité économique de la ville, les pouvoirs publics ont procédé à l'implantation de zones industrielles et de technopôles. Non loin, Dos Hermanas accueille la plus grande zone industrielle andalouse, tandis qu’Alcalá de Guadaíra possède la plus vaste surface industrielle de la communauté. À Séville ont par ailleurs été aménagés deux technopoles de haute qualité : 

La ville de Séville et son agglomération ont, de par leur situation au cœur de la plaine du Guadalquivir, maintenu une activité agricole dynamique, l’industrie agroalimentaire y est florissante.
Néanmoins, la région s’est depuis longtemps tournée vers l’avenir, en investissant massivement dans les activités industrielles, favorisées par les infrastructures existantes, et, de plus en plus, vers les services et les nouvelles technologies. Séville concentrait, en 2004, 31 % des grandes entreprises andalouses et 128 des plus grandes entreprises nationales. L’agglomération comptait en 2005 une population active de personnes, dont (69,81 %) pour la ville centre.



À travers ses technopôles et son tissu d’entreprises innovantes, la capitale andalouse s’est hissée parmi les toutes premières villes espagnoles en termes de recherche et développement. À cela s’ajoute l’activité scientifique et technologique des trois universités de la ville, dont certains laboratoires et centres de recherche travaillent en étroite liaison avec le milieu socio-économique local. Ainsi, le "Parque Científico Tecnológico Sevilla Tecnopolis" regroupe des acteurs privés et publics dans divers domaines de recherche.

Les principaux axes de recherche et d’innovation s’articulent autour des télécommunications, des nouvelles technologies, des biotechnologies (en relation avec les spécificités agricoles locales), de l’environnement ou encore des énergies renouvelables.

Deux universités publiques sont implantées à Séville. Ces deux établissements regroupent environ étudiants répartis sur les différents campus dont disposent les facultés.

L'Université de Séville ("Universidad de Sevilla") - communément appelée la "Hispalense", est l'université la plus ancienne de la ville. Elle fut fondée en 1505 par une bulle du pape Jules II. Elle accueille environ étudiants dans ses nombreuses facultés, écoles et instituts, couvrant la plupart des champs disciplinaires, depuis les lettres aux sciences de la santé en passant par les technologies ou les arts. Le siège de l'Université est sis dans l'ancienne Fabrique Royale de Tabac, un immense édifice du , qui accueille également les facultés de lettres, et de sciences humaines. Les autres structures sont établies dans les diverses installations de l'établissement, aux quatre coins de la ville.

L"'Université Pablo de Olavide" est une petite université publique fondée en 1997. Construite à l'écart du centre, elle accueille environ étudiants, notamment dans les domaines des sciences juridiques, économiques et sociales, des humanités et des sciences du vivant. Elle entretient par ailleurs des liens très étroits avec l'Amérique latine.

Par ailleurs, le gouvernement andalou a fondé en 1994 la "Universidad Internacional de Andalucía", qui possède quatre sites répartis sur le territoire de la communauté, dont un à Séville. Cet établissement propose des formations absentes des enseignements dispensés par les universités de la région.

La "Fundación San Pablo Andalucía", rattachée à la "Asociación Católica Nacional de Propagandistas", basée à Madrid, a fondé en 2002 deux centres d’études supérieures. Elle dispose d'un campus à Bormujos, dans l'agglomération sévillane, à Cordoue et Jerez de la Frontera.

Enfin, la Fondation Universidad Fernando III, parrainée par la Fondation San Pablo Andalucía et les Jésuites, a pour projet de créer la première université privée d’Andalousie, l’Université Fernando III. Le projet a été approuvé en mars 2007 par le Parlement d'Andalousie, et devra être par le Ministère espagnol de l’Éducation. Les responsables envisagent de mettre en place les premiers enseignements à la rentrée 2008. L’université, si son ouverture est autorisée, disposera de locaux sur le campus de Bormujos et à Cordoue.

Séville est une ville de plaine, dont l'altitude moyenne s'élève à au-dessus du niveau de la mer. Elle n'a donc pas connu les difficultés urbanistiques qui caractérisent le développement des villes au relief plus accidenté. L'horizontalité de la ville est renforcée par la faible élévation générale des bâtiments, surtout dans le centre. En dépit de la présence de tours d'habitation dans les quartiers modernes, les hauts immeubles, du type gratte-ciel, sont quasiment absents, une règle implicite d'urbanisme proscrivant de dépasser en hauteur la Giralda (). Cette règle orale est menacée par des projets de construction dans le quartier de Bellavista et surtout par la construction de la Tour Sevilla, gratte-ciel de , qui verra le jour d'ici à fin 2015 - début 2016 dans le quartier de la Cartuja.

L'urbanisme de cette cité vieille de plus de deux mille ans conserve les traces du passage des différents peuples qui l'ont occupée. Son extension sur les deux rives du Guadalquivir s’est faite progressivement, avec une accélération évidente à partir du . Parcs, larges avenues, vastes places entourent un secteur historique immense, qui conserve un habitat local à la personnalité marquée. Six ponts sont construits à Séville en 130 ans, entre 1852 et 1980, et six également entre 1988 et 1992, en seulement 5 ans.

Le centre historique constitue le cœur de la ville, c'est lui qui a le plus évolué, et qui a été le plus marqué par le passage du temps. Il se caractérise par une trame urbaine héritée de l’époque médiévale. La plupart des quartiers du centre ont conservé les rues et ruelles escarpées, et de largeur réduite pour préserver du soleil. L'habitat traditionnel y est très resserré et la présence imposante de monuments historiques de tous types et époques influence profondément la morphologie de la ville, qui s'est construite autour d'eux.

Le percement d'avenues et l'aménagement de grandes places aux restructurent le centre historique et permet de mieux l'irriguer et d'en faciliter la circulation. Ces chantiers font de Séville une ville moderne, et étendent la surface de la ville, longtemps retenue dans le périmètre de l'ancienne muraille. Malgré ces campagnes de modernisation, le trafic demeure difficile, en raison de la configuration générale du centre, en rues étroites. Une autre caractéristique essentielle de l'urbanisme sévillan est l'existence de nombreux parcs et jardins, et de la présence d'orangers sur la majeure partie des voies publiques. Séville constitue donc encore une magnifique mosaïque urbaine, entourant le patrimoine historique d'un réseau de rues étroites, alternant avec des places aérées et des voies plus larges qui drainent la circulation automobile.

C'est à compter du , et surtout du , que la ville commence réellement à déborder du périmètre de la muraille. S'établissent alors progressivement des quartiers de plus en plus nombreux et éloignés. Ce développement est marqué par l'édification du secteur du parc de María Luisa à l’occasion de l'Exposition ibéro-américaine de 1929 : jardins, pièces d’eau, grandes places, théâtre, pavillons nationaux, et nouveaux quartiers ("El Porvenir", "San Bernardo"…) prennent dès lors leur place au sud du centre historique. La construction dès le de ponts sur le Guadalquivir constitue elle aussi un formidable facteur de développement urbain : elle ouvre le centre sur la rive droite du fleuve (Triana), qui s'est considérablement étendue depuis. Le désenclavement du centre n'a cependant été rendu possible qu'avec le percement d'une longue ceinture de cours entourant le centre (les "Rondas"), qui représente en quelque sorte une frontière symbolique entre la partie historique et la ville nouvelle.

La deuxième moitié du est dominée par deux projets d'aménagement urbain majeurs. Le premier d'entre eux est l'édification à partir des années 1960 de grandes cités, dont l'objet est d'absorber l'accroissement de la population ("Las 3000 viviendas", "Los Remedios", les "Polígonos"…). Le deuxième projet voit le jour avec la tenue de l'Exposition universelle de 1992, qui amène les autorités locales et nationales à engager la construction de nouvelles infrastructures de transport et de nouveaux quartiers, le réaménagement des quais, la restauration et la réhabilitation d'un grand nombre de zones et de monuments du cœur historique de la ville, sans compter la création du site propre de l'Exposition. Les quais du canal Alphonse-XIII sont depuis lors devenus une longue promenade fleurie, qui a rendu son fleuve à la ville.

Le Guadalquivir, au bord duquel Séville voit le jour, joue un rôle primordial dans la croissance de la ville. Le fleuve, avec son accès à l'océan Atlantique et, par le détroit de Gibraltar, à la mer Méditerranée, est pendant longtemps la principale voie commerciale de la ville. De plus, Séville, par son pont de barques est pendant plusieurs siècles le seul point du sud de l'Andalousie où la traversée du fleuve est possible.

L'accroissement de la population et la nécessité de développer les communications avec l'ouest du pays (notamment avec Huelva et sa province) et avec le Portugal motivent dès 1852 la construction de ponts par-dessus le Guadalquivir.

La morphologie du fleuve change à plusieurs reprises pendant le , d'abord par le creusement d'un canal créant un raccourci au sud de la ville, puis par la déviation complète du fleuve quelques centaines de mètres à l'ouest de la ville, rendue nécessaire par les graves inondations touchant régulièrement la ville, transformant le fleuve d'origine en une darse reliée au nouveau fleuve par le sud. Ces modifications motivent bien entendu la création de nombreux nouveaux ponts.

Pour l'Exposition universelle de 1992, afin notamment d'améliorer l'image de la ville, la darse est partiellement rouverte et ses quais deviennent un lieu de promenade privilégié des Sévillans. À cette occasion, six nouveaux ponts voient le jour, dont le style architectural parfois avant-gardiste contribue à donner une image moderne à la ville.

Il existe à Séville un habitat traditionnel, semblable en de très nombreux points à celui du reste de l'Andalousie. Il était la règle avant les grandes vagues d’urbanisation des années 1960 et postérieures. On retrouve encore ces constructions typiques, tantôt modestes, tantôt luxueuses dans le centre historique de la ville et les quartiers alentour.

La demeure populaire sévillane, que l'on retrouve principalement dans les quartiers tels que la Macarena ou San Vicente se caractérise par sa faible élévation. Organisée autour d'un petit patio, elle comprend rarement plus d'un ou deux étages. Les pièces sont petites et sombres. Elle est surmontée d'un toit en terrasse, appelé "azotea", au plan à peine incliné, du fait de la faible pluviométrie locale. Une autre formule de logement dans le domaine de l'habitat populaire est incarnée par les "corrales de vecinos". Il s'agit d'immeubles collectifs, organisés autour d'un vaste patio, sur lequel s'ouvrent plusieurs appartements. Très en vogue parmi les classes sociales les plus défavorisées aux siècles passés, les "corrales" tendent à disparaître de nos jours, quoiqu'il en subsiste plusieurs dizaines à travers les différents quartiers de la ville.

À côté de cet habitat populaire se sont multipliés les édifices cossus, plus élevés, et à l'architecture plus ostentatoire, à base de moulures, balcons à consoles ou en encorbellement (oriels)… Ces maisons sont souvent très colorées et situées dans les zones les plus opulentes de Séville, aménagées dans le centre (zone de la plaza Nueva et de l'avenue de la Constitution, plaza de San Bernardo…) aux .

Comme dans toute l'Andalousie, il existe des caractéristiques communes à ces bâtisses, quel que soit leur degré de richesse. Le patio, élément fondamental, est présent dans toutes les maisons. Ses dimensions et sa décoration sont variables et généralement déterminées en fonction de la taille du bâtiment. Censé apporter l'ombre et la fraîcheur en plein été, il est un lieu de vie et de rencontres. Les patios sont toujours ornés de plantes et de fleurs, et les plus confortables d’entre eux peuvent être agrémentés d'une fontaine.
La chaux est un autre élément incontournable de la maison sévillane. Qu’elle soit humble ou opulente, faite de briques ou de pierres, la demeure est régulièrement chaulée, afin d’assurer une blancheur éclatante aux façades. On remarque cependant qu'à Séville, contrairement à ce qui se passe dans le reste de l'Andalousie, les façades sont rarement unicolores. L'habitat sévillan se distingue de par sa tendance à égayer les édifices, notamment sur les encadrements – très souvent saillants – des fenêtres et des portes, et sur la partie basse des murs. Les couleurs habituellement choisies – rouge sang de taureau et ocre – sont plus vives et offrent un net contraste avec le blanc, mettant ainsi en valeur les différents éléments de la façade.
Les fenêtres sont souvent de taille réduite, afin de limiter au maximum la pénétration de la chaleur dans les pièces. Elles sont ornées de grilles en fer forgé. Enfin, on ne saurait omettre les azulejos, carreaux de faïence assemblés en panneaux, placés à la base des murs. Ils reproduisent des motifs géométriques, végétaux ou historiés plus ou moins raffinés. Peints de couleurs vives, ils occupent une place de choix dans les maisons sévillanes.

Avec l'accélération de la construction de logements depuis quelques décennies dans les nouveaux quartiers, l'habitat traditionnel de la ville a tendance à s'effacer, au profit de bâtiments fonctionnels de grande capacité d'accueil. Souvent néanmoins, les façades restent peintes de blanc, pour préserver une certaine unité urbaine. Dans le centre, les constructions nouvelles s'intègrent en règle générale au bâti déjà existant.

L'histoire urbaine locale est marquée par le goût des jardins, qui se manifeste sous la forme de patios, squares et autres parcs. Cette préoccupation pour les espaces verts s'est maintenue jusqu'à aujourd'hui : nombreuses sont les zones de promenade aménagées dans la ville et ses alentours. Dans le droit chemin de la tradition andalouse, ces lieux de verdure mêlent harmonieusement l'élément végétal et l'élément aquatique, ce qui en fait des lieux de repos et de fraîcheur recherchés en période estivale.

Le plus célèbre des parcs sévillans est sans doute le parc de María Luisa. Le domaine sur lequel il s'étend appartenait autrefois aux jardins du Palais de San Telmo. Il fut offert à la ville en 1893 par l'infante Louise Fernande de Bourbon, Duchesse de Montpensier, puis transformé peu à peu en un vaste parc boisé, parsemé de fontaines, étangs, pavillons, et alternant les plantations à l’anglaise avec des îlots d’inspiration hispano-mauresque. Planté d’une variété d’espèces considérables, il est peuplé par plusieurs espèces d’oiseaux, poissons et batraciens. Il fut complètement restructuré à l'occasion de l’Exposition ibéro-américaine de 1929. On y implanta alors une partie des pavillons nationaux, autour de ruelles et de places, dont les plus emblématiques sont : la Plaza de España et la Plaza de América.

Les jardins de l'Alcazar forment également un des grands espaces de verdure de Séville. Aménagés à l'arrière de l'ensemble palatin, ils ont été plantés et organisés au fil des siècles. Abrités au sein des murailles du palais, ils sont disposés en terrasses, et présentent des variations d'influences, de styles, de végétation, en fonction des secteurs. De l'autre côté de l'enceinte des palais, auxquels ils appartenaient jusqu'en 1911, ont été aménagés les jardins de Murillo et la promenade de Catalina de Ribera. Richement boisés et fleuris, ils ont été décorés de divers éléments architecturaux, dont un monument dédié à Christophe Colomb.

Séville possède un patrimoine architectural d'une ampleur considérable. Elle est en cela une des plus riches cités européennes. Ses églises, palais et édifices divers en font une ville d'art de premier ordre, et une destination privilégiée des touristes.

Séville est une ville éminemment imprégnée par la religion, comme en témoignent le nombre très élevé de lieux de culte. Parmi les plus célèbres : 

La richesse de la ville a permis aux hommes de pouvoir et aux institutions laïques et ecclésiastiques de bâtir de somptueuses demeures. Parmi les plus spectaculaires édifices civils de la ville se distinguent plusieurs palais :

D'autres bâtiments civils sont dignes d'être mentionnés :

Séville conserve quelques vestiges de son enceinte fortifiée :


L’opulence passée de Séville a légué à celle-ci un patrimoine artistique d’une ampleur exceptionnelle. Couvents, églises, confréries, monarques et nobles ont dépensé des fortunes en constructions et en œuvres d’art. La folie artistique qui s’est emparée de Séville entre le a favorisé le développement d’une école sévillane reconnue, dont l’origine remonte au bas Moyen Âge. Les mécènes ont attiré les grands maîtres gothiques et baroques de la peinture, de la sculpture et des arts décoratifs : Zurbarán, Valdés Leal, Velázquez, Murillo, Herrera el Viejo, Herrera el Mozo, Pedro Millán, Juan Martínez Montañés, Juan de Mesa, etc. Les liens étroits tissés entre l’Espagne et les mondes flamand et germanique ont stimulé les échanges culturels et la venue de maîtres de l’Europe du Nord. Les œuvres de ces artistes peuvent encore être admirées de nos jours dans les lieux de culte et les palais, mais également dans les musées de la ville.


Il n’existe pas à Séville de grand musée d’art de stature internationale, à l'inverse de Madrid, où sont concentrées les imposantes collections de la Couronne espagnole et de l'État. Les musées de la capitale andalouse, sans que cela puisse remettre en cause leur importance, sont orientés vers la mise en valeur du patrimoine local et régional: patrimoine artistique, culturel ou ethnologique. Parmi ces musées, pour la plupart gérés par le gouvernement autonome, trois sont consacrés à l’art et à l’archéologie, et se hissent au palmarès des plus grandes galeries nationales de leurs catégories.

Le plus important des musées de la ville est sans conteste le musée des Beaux-Arts de Séville, où sont tout particulièrement représentées la peinture et la sculpture. Logé dans un somptueux monastère du , il abrite l'une des toutes premières collections de peinture d'Espagne. Ses collections, qui couvrent l’histoire de l'art du Moyen Âge au , mettent en valeur les productions de l’école de peinture locale, dont les plus prestigieuses réalisations appartiennent à la période baroque. Les toiles de Francisco de Zurbarán et de Bartolomé Esteban Murillo en constituent les chefs-d’œuvre, aux côtés de tableaux d’autres grands maîtres espagnols (Diego Vélasquez, José de Ribera, El Greco…) et européens (Lucas Cranach, Joos van Cleve…) et les contemporains Eugenio Hermoso, Vázquez Díaz, Zuloaga.

Dans le registre des musées d’art figurent également le Musée archéologique et le Centre andalou d’art contemporain, deux musées de premier plan au niveau national dans leurs domaines de compétences. Le premier, fondé en 1867, est installé depuis 1946 dans un pavillon de l’Exposition ibéro-américaine de 1929, sur la Plaza de América, au cœur du parc de María Luisa. Y est conservée l’une des plus importantes collections archéologiques d’Espagne, constituée de plus de pièces provenant de chantiers de fouilles andalous, de confiscations de biens ecclésiastiques menées au (les "desamortizaciones") et de diverses collections publiques et privées. Les collections comprennent principalement des objets d'époques préhistorique, protohistorique, tartessienne, romaine, mais également wisigothique et musulmane : sculptures, mosaïques, céramiques, pièces d’orfèvrerie, objets du quotidien, objets votifs et mortuaires… Deux trésors de la civilisation tartessienne y sont notamment renfermés : le trésor du Carambolo et celui d’Ébora. Le Centre andalou d’art contemporain (CAAC) a, quant à lui, été institué en 1990 par le gouvernement régional. Implanté depuis 1997 dans l’ancien monastère de la Cartuja, à proximité du site de l'Expo 92, il se consacre à la recherche, à la promotion, à la diffusion et à la conservation dans le domaine de la création artistique contemporaine. En plus d’une importante collection permanente, le CAAC organise régulièrement des expositions temporaires.

Enfin, il existe à Séville un ensemble de musées plus modestes, dont la vocation est de mettre en valeur certains aspects de la culture et de l’histoire locales. Ainsi, l’ethnologie et la culture populaire andalouse bénéficient d’une vitrine au sein du musée des Arts et Cultures populaires, installé dans le pavillon mudéjar, face au Musée archéologique. Voué à la conservation et à l’exposition de la mémoire populaire régionale, il offre aux visiteurs un vaste ensemble d’objets représentatifs de la société, du mode de vie et du quotidien andalous : habillement, mobilier, outillage agricole, photos et gravures anciennes… Deux aspects incontournables du patrimoine culturel sévillan font l’objet d’une promotion muséographique : la tauromachie, à laquelle est consacré le Musée taurin situé aux arènes de la Maestranza, et le flamenco, à l’honneur dans un musée qui lui est entièrement consacré. Le Musée naval, qui occupe la Tour de l'or, traite quant à lui de la navigation, une des activités centrales de l’histoire de Séville. D’autres musées et salles d’exposition complètent le panorama culturel local, à l’image du musée des Carrosses et du Musée militaire.


Séville, fréquentée jadis par des dramaturges de l’importance de Tirso de Molina, Cervantes et Lope de Vega, est depuis longtemps une ville de théâtre. Elle s’est également tournée plus récemment vers l’opéra.

Propriété de la ville, le Théâtre Lope de Vega, baptisé du nom de l’illustre dramaturge du Siècle d’or, occupe le Pavillon de Séville, conçu à l’occasion de l'Exposition ibéro-américaine de 1929 pour abriter un théâtre et un casino. Les représentations théâtrales d’œuvres du répertoire classique espagnol et européen composent l’essentiel des représentations, mais la salle accueille également des projections cinématographiques dans le cadre du festival du cinéma européen, ainsi que des concerts de musique et des spectacles de danse. Le Théâtre de la Maestranza fut pour sa part créé à l'occasion de l'Expo 92 et inauguré par la reine Sophie en 1991. Il figure désormais dans le peloton de tête des opéras espagnols. La programmation, de 180 spectacles annuels, fait alterner des représentations d'opéra, de théâtre, de danse et de musique classique.


La création contemporaine n’est pas absente de cette ville très ancrée dans la tradition. En témoigne l’existence du Teatro central, où se produisent divers auteurs et compagnies de théâtre, danse, musique au répertoire essentiellement contemporain et actuel, en collaboration avec des institutions culturelles locales (Centre de théâtre andalou, Ballet flamenco d’Andalousie, ..) et d’autres théâtres. Ces caractéristiques en font une des principales scènes expérimentales d’Espagne, et un outil pour la diffusion et la promotion de la création contemporaine dans le domaine des arts de la scène. Aux côtés du Théâtre central existent plusieurs salles plus modestes, où se donnent des représentations de tous types.

Il est à noter d’autre part que la présence d’une importante population juvénile et estudiantine a entraîné depuis longtemps l’émergence de salles de concerts de musique actuelle (rock, hip-hop, musique électronique…), officielles ou plus alternatives, tendance sans doute provoquée ou accentuée par le phénomène de la movida. Séville demeure toutefois moins dynamique que sa voisine Grenade, qui propose une offre plus étoffée. Enfin, Séville est le berceau de plusieurs interprètes musicaux de styles divers : La Mala Rodríguez et Dogma Crew (hip hop), Triana et Smash (rock progressif), Narco (rap et metal), Parachokes (rock), Reincidentes (punk rock).


Séville est une ville de fêtes, profanes et sacrées. Marquée par une intense religiosité, elle célèbre tout au long de l'année divers saints patrons locaux. La plus célèbre et la plus importante festivité chrétienne est la fameuse Semaine sainte, qui forme avec la non moins renommée Feria de Abril, le cycle des "Fiestas Primaverales", les Fêtes de Printemps, les plus populaires et fréquentées. C’est à cette période de l'année que les réjouissances battent leur plein.

La Semana Santa de Séville est la plus fameuse d'Espagne. Elle attire des centaines de milliers de croyants et de non-croyants ( selon des estimations de 1999) qui viennent admirer les processions des 57 confréries de la ville. La Semaine sainte a lieu du dimanche des Rameaux ("Domingo de Ramos") au dimanche de Pâques ("Domingo de Resurrección"), et atteint son paroxysme lors de la "Madrugá", dans la nuit du jeudi au vendredi saint, quand sortent les congrégations les plus emblématiques de Séville. Elle donne lieu à une grande animation dans la ville, dont les hôtels, bars et restaurants ne désemplissent pas.

La Romería del Rocío constitue le deuxième grand rendez-vous du calendrier festif religieux local. Cinq confréries sévillanes participent à ce grand pèlerinage qui conduit vers la basilique du Rocío, à Almonte dans la province de Huelva, des centaines de milliers de fidèles de toute l’Andalousie venus à pied, à cheval ou en calèche vénérer l'image de la Vierge qui est sortie de l’église les dimanche et lundi de Pentecôte. Les confréries sévillanes partent pour Huelva le mercredi précédant la manifestation, pour rejoindre sur les routes et chemins leurs coreligionnaires.

Le saint patron de la ville est célébré à l'occasion du Día de San Fernando le 30 mai. Les sévillans fêtent saint Ferdinand III de Castille, le souverain qui reprit la ville aux musulmans en 1248. Son corps est exposé à la population dans la chapelle royale de la cathédrale, où il repose. Une messe est célébrée en son honneur ; elle est suivie d’une procession menée par la corporation des ingénieurs de la ville, dont saint Ferdinand est le patron. Une fête similaire a lieu à la saint Clément, le 23 novembre, jour anniversaire de la conquête de Séville. À cette occasion, le conseil municipal, précédé par le maire qui porte l’épée du saint, effectue une procession, cette fois à l’intérieur de la cathédrale.

Le Día del Corpus représente un autre moment fort de la vie liturgique. La Fête-Dieu est célébrée depuis le Moyen Âge avec une grande ferveur. Après la messe célébrée en la cathédrale, un long cortège mettant à l'honneur le Saint-Sacrement prend possession des rues de la ville, recouvertes de thym et de romarin, au son des cloches de la Giralda et d’orchestres. Toutes les autorités civiles, militaires et religieuses de la capitale andalouse y prennent part : archevêché, mairie, université, police, armée, confréries, chapitre cathédral. Une course de taureaux est organisée à l’occasion.

La Virgen de los Reyes est célébrée le 15 août. Cette fête est organisée en l'honneur de la Vierge des Rois, patronne de Séville et de son archidiocèse depuis 1946. Sa statue, qui aurait été commandée par Ferdinand III après un rêve, trône au centre de la chapelle royale. Cette même statue aurait accompagné le saint lors de son entrée triomphale dans Séville. Toujours est-il que la sainte effigie est emmenée en procession le matin du quinze août, accompagnée par les autorités religieuses et le conseil municipal.

La Inmaculada Concepción (Immaculée Conception) est fêtée dans toute l'Espagne, le 8 décembre, en l'honneur de la conception virginale de la Vierge-Marie. À Séville, cette tradition est vécue avec une ferveur particulière. Outre les messes, la manifestation la plus populaire a lieu sur la "Plaza del Triunfo" où se regroupent les tunas de la ville pour entamer des chants en honneur de Marie de Nazareth. Il convient également de signaler l'existence de "Los Seises", un groupe de dix enfants (à l'origine six, d'où leur nom) âgés entre 9 et 12 ans, dont l'existence remonte au milieu du . Ils forment un petit groupe de danse et de chant très apprécié, chargé d’accompagner la procession du Corpus Christi et de la Inmaculada.


La Feria de Abril est la grande fête populaire de Séville, organisée depuis 1847. Des dizaines de milliers d'autochtones et de visiteurs évoluent sur le "Real de la Feria", vaste esplanade décorée et illuminée. Y sont regroupées des centaines de casetas : des baraques colorées, où l’on boit, mange et danse jusqu’à épuisement, au rythme de la sévillane. La journée, le "Real" est le théâtre d’un défilé équestre informel, et des corridas sont données chaque soir.

La Velá de Santiago y Santa Ana remonte vraisemblablement, quant à elle, au . Ces festivités ont lieu annuellement autour du 25 juillet. Elles mêlent le profane au religieux. Aux célébrations liturgiques s'ajoute en effet la fête populaire, qui s’installe au bord de la darse du Guadalquivir, dans la calle Betis, à Triana. Des casetas sont montées à cet emplacement, pour permettre à tous de s’abreuver et de se restaurer. Diverses réjouissances sont organisées durant ces quelques jours.

Séville est un des hauts lieux de la tauromachie espagnole. Berceau de nombreux toreros et capitale d’une des plus fameuses régions d’élevage de "toros bravos", elle est un des plus éminents foyers de l’"afición" en Espagne. Se produire à la "Maestranza" est le rêve de tout matador, et les triomphes en ces lieux sont gages d’un avenir prometteur.

Ces arènes, les plus anciennes d’Espagne après celles de Ronda, sont classées en première catégorie. Construites à partir du , elles sont la propriété de la "Real Maestranza de Caballería de Sevilla", une corporation nobiliaire, composée de descendants de la noblesse andalouse, et fondée par Charles II, en 1670, à partir d’anciennes confréries chevaleresques médiévales. Son rôle était de former à la cavalerie de guerre les officiers de l’armée espagnole, et d’habiliter ces derniers à intégrer les rangs. Ses activités originelles sont clairement liées à l’équitation.Elle se consacre aujourd’hui à diverses actions de bienfaisance, de mécénat artistique et culturel, ainsi qu’à la promotion de la pratique équestre et de la tauromachie. En ce sens, elle soutient l’école de tauromachie de la ville. Elle est placée sous le haut patronage du roi, Hermano Mayor, depuis le règne de Philippe V, qui lui accorda plusieurs privilèges.


La Real Maestranza délègue l’organisation des spectacles taurins à un prestataire privé, l’Empresa Pagés, tenue par la famille Canorea. Totalisant environ 35 spectacles annuels (ce qui fait de la "Maestranza" les deuxièmes arènes d'Espagne, après Madrid), la saison taurine se déroule selon un calendrier traditionnel, dont le commencement est marqué par la corrida du dimanche de Pâques (Domingo de Resurrección), la plus prestigieuse de l’année. Une à deux semaines plus tard se tient la "Feria de Abril", constituée d’une série d’une vingtaine de spectacles taurins sur deux semaines. La deuxième partie du cycle coïncide avec la semaine de "Farolillos", la "Feria de Abril" à proprement parler. Une fois la feria achevée, l'activité des arènes perd en intensité. Un cycle de novilladas dominicales a lieu en mai et juin, puis deux courses de taureaux se tiennent à des dates importantes du calendrier liturgique de la ville, pour le "Corpus Christi" (Fête Dieu), et au 15 août, en honneur de la "Virgen de los Reyes". Plus tard, le dernier week-end de septembre a lieu la Feria de San Miguel, qui compte de deux à trois corridas selon les années. Enfin, la corrida de la "Virgen del Pilar", le 12 octobre, vient clore la saison.


La tradition tauromachique est très ancienne à Séville, et surtout très bien implantée. La ville et ses alentours ont vu naître de nombreux toreros, qui ont contribué au rayonnement taurin de la cité. Plusieurs peñas (clubs) taurins rassemblent les aficionados sévillans, tandis que la ville regorge de références à la tauromachie (rues baptisées de noms de toreros, statues…).Les arènes, d'une capacité de places, accueillent un public métissé, de connaisseurs, connus pour leur tendance toreriste. Célèbres pour les silences méprisants qu'elles préfèrent aux huées, ces arènes sont également réputées pour leur propension à se livrer entièrement aux matadors qui l’honorent d’une grande faena. La récompense suprême est octroyée aux toreros ayant coupé un minimum de trois trophées : le triomphateur sort alors par l’illustre "Puerta del Príncipe", qui lui assure honneur et renommée.

Le bar est un lieu incontournable de la vie sociale sévillane. Les débits de boissons sont légion, tant dans le centre, que dans les quartiers périphériques. Ils sont un point de rencontre entre les habitants d'une rue, les habitués, les employés du secteur et les gens de passage. Une grande majorité de sévillans se rend dans les cafés aux heures du déjeuner, de l'apéritif (deux coutumes qui ont conservé toute leur vigueur), des repas, ou aux moments des pauses au travail. Les établissements sont souvent bondés à midi et, surtout dans la partie historique, le soir, en période de week-end essentiellement.

La tradition du tapeo est très largement répandue dans toute l'Espagne. Toutefois, Séville est réputée pour l’intensité de cette pratique, qui consiste à naviguer de bar en bar, en famille, entre amis, ou entre collègues, afin de partager un rafraîchissement et quelques tapas. Le vin et la bière y sont les breuvages de loin les plus consommés, vendus à un prix modique. Le tout est communément accompagné de tapas, ou de simples cacahuètes, pistaches, pipas, "altramuces" (lupins) ou olives. Cette coutume du bar appartient au rituel que tous les autochtones accomplissent à une fréquence plus ou moins élevée. Le dîner au restaurant ne répond pas à un usage aussi répandu qu'en France, ou que dans le nord du pays. Les "tabernas" (tavernes), "cervecerías" (brasseries), et autres bars concentrent les foules jusqu’à tard le soir. Parmi les zones les plus courues peuvent être citées la Plaza del Salvador, la Calle Adriano (plus généralement les alentours des arènes), le quartier de Santa Cruz (notamment la calle Mateos Gago), le quartier de l’église Santa Catalina ou encore Triana.

Plus tard dans la soirée, certaines rues et places reçoivent les amateurs de fête, qui se rassemblent dans les bars de nuit et discothèques. Le quartier de Triana, et notamment la Calle Betis, au bord de la darse du Guadalquivir, est certainement l'un des plus fréquentés, pour ses bars de nuit ou ses "tablaos". Les noctambules amateurs de bars s'agglutinent également sur la plaza de la Alfalfa et ses alentours. Le quartier de l'Arenal attire les férus des boîtes de nuit, lesquels se retrouvent en été aux abords du parc de María Luisa, où abondent les discothèques en plein air. Enfin, la jeunesse plus portée par la musique et l'ambiance alternatives tend à se concentrer le long d'une promenade, la Alameda de Hércules.

Une autre pratique nocturne reste très prisée des jeunes sévillans : la "botellona". Cette tradition bien implantée parmi les jeunes dont les moyens ne leur permettent pas de consommer dans les débits de boissons, consiste à acheter au supermarché des bouteilles d'alcool, pour les consommer ensuite en pleine rue, lors d'un "botellón", regroupement spontané et improvisé, pouvant réunir au même endroit de quelques individus à plusieurs centaines de personnes. Le gouvernement andalou, à l'instar d’autres communautés autonomes, a toutefois décidé en 2006 de réglementer la tenue des "botellones", pour limiter la gêne occasionnée au voisinage, et lutter contre l'alcoolisme. Les municipalités sont depuis lors autorisées à prohiber la tenue de "botellones" sur la voie publique, et à mettre en place des enceintes à ciel ouvert spécialement affectés à cet usage : les botellódromes, qui connaissent désormais une affluence imposante.

La gastronomie populaire sévillane est fortement influencée par la cuisine méditerranéenne, à base de poissons, d’huile d’olive, de nombreux fruits et légumes. Elle accorde également une large place aux produits régionaux des provinces voisines : charcuteries, viande de porc, de taureau… Elle se distingue par la simplicité des mets que l’on préfère généralement cuisinés nature, grillés ou sautés : les plats élaborés ou en sauce, si prisés des basques ou des navarrais, pour lesquels la cuisine est une institution, connaissent un écho plus limité.

Au premier rang de la gastronomie sévillane figurent les productions régionales, qui rentrent souvent dans la composition des tapas :

Parmi les mets les plus fréquents se retrouvent :

Les pâtisseries, généralement issues de la tradition orientale, sont fort prisées à Séville. Les plus fameuses trouvent leurs origines dans les très nombreux couvents de la ville, dont certains continuent à les produire et à les commercialiser :

La confiture d'écorces d'oranges amères est également très prisée. Une autre spécialité très appréciée au petit déjeuner est la "tostaíta", simple pain grillé, frotté à l’ail puis arrosé d’huile d’olive. On lui ajoute ensuite, selon les goûts, divers ingrédients : jambon, tomate…

La ville de Séville possède de très nombreux équipements sportifs construits durant les dernières décennies. Outre les installations de proximité, destinées à l'usage de la population, Séville possède trois stades de grande capacité, où évoluent les équipes locales, et sont organisés des évènements sportifs ou culturels nationaux et internationaux. Le stade Benito Villamarín, inauguré en 1997 et inachevé (il reste 1/4 pour le finir), accueille les matchs de l'équipe de football du Real Betis Balompié. Actuellement, il dispose de places. Le stade Ramón-Sánchez-Pizjuán date de 1958. Il est utilisé par l'équipe du Séville FC et compte places. Enfin, en 1999 fut inauguré le Stade olympique de la Cartuja, un équipement omnisports de places, qui accueille divers évènements sportifs et culturels.

À la suite de l'Exposition universelle de 1992, et la déprime qui s'est alors emparée de la ville, la municipalité a, entre autres mesures de relance de l'économie locale, lancé un plan de promotion et de développement de la dimension sportive de la ville, intitulé "Sevilla, la ciudad del deporte" ("Séville, la ville du sport").

La ville a alors présenté sa candidature à l'organisation des Jeux olympiques de 2004, sans succès, la taille modeste de la cité et la récente tenue des Jeux olympiques à Barcelone en 1992 l'ayant disqualifiée dès le départ. Le même scénario s'est reproduit pour les Jeux olympiques de 2008.

Néanmoins, en 1995 est engagé le projet de construction du stade olympique de La Cartuja, qui voit le jour en 1999, avec une inauguration par le roi d'Espagne. Ce nouvel équipement avait pour objectif de promouvoir l'image sportive de la ville et de permettre l'organisation de grands événements sportifs d'envergure internationale. Depuis 1999 ont eu lieu en ces lieux les championnats du monde d'athlétisme 1999, la finale de la Copa del Rey (en 1999 et 2001), la finale de la coupe de l'UEFA (en 2003), le championnat du monde de supercross (en 2003), la finale de la Coupe Davis (en 2004 et en 2011) ainsi que divers matchs de la sélection de football espagnole.

Par ailleurs, la ville a accueilli les événements suivants : les championnats d'Europe de natation en 1997, le mondial de gymnastique rythmique en 1998, la coupe du monde d'aviron et de canoë-kayak en 2001, les championnats du monde d'aviron en 2002, la Coupe du monde de golf 2004 et des matchs de la phase préliminaire du championnat du monde de handball masculin 2013.

Plusieurs équipes sportives sévillanes évoluent dans les compétitions nationales, les plus célèbres d'entre elles étant les équipes de football locales, le Séville FC & le Real Betis Balompié, deux clubs rivaux dont les rencontres déchaînent les passions.

Séville s'illustre dans d'autres disciplines avec des équipes telles que le C.D. Universidad de Sevilla (Hockey en salle), le Club de Rugby Universidad de Sevilla (Rugby à XV), El Monte Ciencias CR (Rugby à XV), ou encore le Club Baloncesto Sevilla "Cajasol" (Basket-ball).


"Pacte d'Amitié et de Coopération signé avec Rome (Rome n'est jumelée qu'avec Paris, et ce, réciproquement)"





</doc>
<doc id="2793" url="https://fr.wikipedia.org/wiki?curid=2793" title="Shiva">
Shiva

Shiva (sanskrit IAST : ; devanagari : ; transcrit parfois par "Çiva", « le bon, celui qui porte bonheur ») est un dieu hindou, membre de la Trimūrti avec Brahmā et Vishnou. Le premier nom de Shiva fut Indra, le fulgurant. Shiva est quelquefois considéré comme le dieu du yoga et est représenté en tant que yogi qui possède la connaissance universelle, suprême et absolue, voire dans un état « au-delà de la connaissance ». Doté d'un grand pouvoir, il mène une vie de sage sur le mont Kailash. 

La tradition shivaïte de l'hindouisme est centrée sur Shiva, considéré dans cinq grandes fonctions : il est le créateur, le préservateur, le transformateur, le dissimulateur et le révélateur (par la bénédiction). Dans la tradition smārta, il est considéré comme l'une des cinq formes primordiales du Dieu. Les hindous qui vénèrent principalement Shiva sont appelés shivaïtes ou shaïvas (sanskrit : "Śaiva"). Le shivaïsme est l'une des plus influentes variantes de l'hindouisme, avec la tradition vishnouïte ("vaiṣṇava") qui est centrée sur Vishnou et la tradition shakta ("śākta"), centrée sur la déesse Shakti.

Shiva est souvent vénéré sous la forme abstraite de Shiva linga. Il est aussi représenté plongé dans une profonde méditation, ou bien dansant le tandava sous la forme Nataraja. Shiva est aussi le père des divinités Ganesha, Murugan (Karttikeya), et Ayyappan (Dharma Sastha).

Shiva, le dieu des shivaïtes assume les fonctions de Rudra le terrible, ancien dieu védique. Cette transformation est considérée comme étant l'une des marques de la fin de l'Âge védique.

En effet, le théonyme Shiva provient d'une épithète de Rudra, l'adjectif "shiva" « gentil, aimable » utilisé par euphémisme pour ce dieu qui, dans le Rig-Véda porte également l'épithète "ghora" « terrible ». L'utilisation de l'épithète a fini par dépasser le théonyme d'origine et dans la période post-védique (dans les épopées sanskrites), le nom de Rudra a fini par être considéré comme un synonyme du dieu Shiva et les deux noms ont été utilisés de façon interchangeable.

Le symbolisme de Shiva est d'une grande complexité du fait des nombreux courants qui l'ont vénéré au cours des siècles. Shiva est le dieu de la destruction, de l'illusion et de l'ignorance. Il représente la destruction, mais celle-ci a pour but la création d'un monde nouveau : Shiva transforme, et conduit la manifestation à travers le « courant des formes ». L'emblème de Shiva est le "lingam" (représentation phallique), symbole de la création. Il a les yeux mi-clos, car il les ouvre lors de la création du monde et les ferme pour mettre fin à l'univers et amorcer un nouveau cycle.

Il est représenté avec un troisième œil ("jñāna-cakṣus") au milieu du front, symbole d'éternité et de sagesse, et avec un cobra autour du cou, symbole de puissance. Il porte un trident ("trishula") et tient un tambour à boules fouettantes ("damaru"). Il est assis sur une peau de tigre, symbole de l'énergie potentielle. Shiva représente en effet la source créatrice en sommeil. De sa chevelure, dans laquelle se trouve un croissant de Lune, symbole du cycle du temps, s'écoule le Gange, fleuve sacré de l'hindouisme. Sa monture est le taureau Nandi qui fait lui-même l'objet d'un culte.

Shiva est représenté sous différentes formes (l'ascète, le yogi, le mendiant, etc.) et possède, d'après les textes, 1008 noms distincts (Shambhu, Shankara, Pashupati, etc.). L'une de ses manifestations les plus célèbres est "Shiva Nataraja", le danseur cosmique qui rythme la destruction et la création du monde.

Shiva est marié à Shakti, la déesse-mère. Elle-même a plusieurs noms suivant la fonction qu'elle occupe (Parvati, Durga, Kâlî). Il a deux fils, l'un né de Parvati, Ganesha, l'autre de sa seule semence : Skanda. En effet, Ganesh a la particularité d'avoir été conçu par Parvati seule, Shiva l'ayant seulement ramené à la vie en le dotant d'une tête d'éléphant. La famille vit au sommet du mont Kailash dans l'Himalaya.

Parmi les attributs de Shiva, on trouve :

Comme ascète, mais aussi comme seigneur des lieux de crémation, il se couvre le corps de cendre. Shiva protège la terre de la force de Gangâ, la déesse du Gange (Gangā) ; il calme l'ardeur de ses flots en les filtrant dans les boucles de ses cheveux. Il possède un trident, symbole qui concentre, pour ses adorateurs, les pouvoirs de la trimûrti, c'est-à-dire création, perpétuation et destruction.

D'après la légende, Shiva et Vishnou se rendirent dans une forêt pour combattre . Furieux, ceux-ci envoyèrent pour attaquer Shiva un tigre, un serpent et un nain noir et féroce armé d'une massue. Shiva tua le tigre ─ il est traditionnellement assis sur une peau de tigre, car maître de la nature "Pashupati" ─, apprivoisa le serpent qu'il mit autour de son cou en guise de collier (symbole de la maîtrise des passions), posa son pied sur le nain et réalisa une danse développant une telle puissance que le nain (voir illustration) et les hérétiques reconnurent en lui leur seigneur.

Shiva est parfois représenté mêlé avec sa Shakti formant un être hermaphrodite, Ardhanari.

Shiva est habituellement représenté par un phallus stylisé, appelé shiva lingam (ou linga), symbole de création associé au yoni, une dalle de pierre représentant l'organe féminin, la matrice du monde. Par l'union du linga et du yoni, l'Absolu qui se déploie dans le monde prouve qu'il surmonte l'antagonisme mâle-femelle ou spirituel-matériel.

Le linga représente également le cosmos, mais aussi le pouvoir de connaître, la conscience comme axe de la réalité. Non plus orienté vers la finalité naturelle de force de vie et d'incarnation, le phallus dressé vers le ciel représente le rassemblement des énergies du yogi sur le plan sensible et leur conversion vers un niveau subtil.

Dans le shivaïsme brahmanique, les caractères phalliques fondamentaux du linga se retrouvent toujours nettement, tant dans les légendes expliquant l'origine de ce culte que dans les qualités corporelles occasionnellement attribuées au dieu. C'est ainsi que Shiva, ayant trouvé toutes les créatures créées (par Brahma ?), s'irrita, arracha son organe génital et le cacha dans la terre pour se vouer à une vie ascétique.

À l'origine, raconte pour sa part le "Linga Purana", lorsque l'univers était envahi par les eaux, Vishnou et Brahmâ se disputaient, affirmant chacun qu'il était le plus grand des dieux. Mais tout à coup, surgit une immense colonne de feu entre les eaux. Elle était si haute qu'elle semblait sans fin. Les deux dieux décidèrent de s'affronter en mesurant la hauteur de la colonne : Vishnou se transforma en sanglier et plongea au fond des eaux tandis que Brahmâ prit la forme d'une oie pour voler aussi haut que possible. Mais ni l'un, ni l'autre ne purent atteindre l'extrémité de la colonne incandescente. Shiva, apparaissant alors, expliqua qu'il s'agissait du "lingam", symbole de son pouvoir mais aussi Shiva lui-même. Les dieux reconnurent alors la suprématie de Shiva, qui leur adressa un discours censé instituer les principales règles de son culte (Nuit Sainte de Shiva, processions, instaurations de statues, etc.)

Une autre légende raconte que Shiva apparut nu devant un groupe d'ascètes qui méditaient dans la forêt sans comprendre sa vraie grandeur. Pour les punir, Shiva décida de séduire leurs femmes. Pour se venger, les ascètes émasculèrent Shiva en invoquant un tigre, mais à l'instant où son "lingam" tombe à terre, l'univers fut plongé dans les ténèbres. Les yogi, enfin conscients de leur erreur, prièrent Shiva de restaurer la lumière dans le monde. Celui-ci accepta, à condition que les ascètes l'adorent sous la forme du "lingam".

Ainsi, le "lingam" est une représentation religieuse tout à fait commune en Inde, sans que le caractère sexuel soit minimisé ou occulté. Pierres, galets ou fourmilières constituent les lieux d'érection de lingams « spontanés ». Les lingams "svayambhû" (« automanifestés ») sont les plus sacrés, à l'image de celui d'Amarnath, une formation de glace naturelle.

Le lingam est souvent oint de lait de buffle ou de lait de coco et de ghee (beurre clarifié) ou entouré de fruits, de sucreries, de feuilles et de fleurs.

Une forme particulière de représentation de Shiva est "Naṭarāja" ("le danseur cosmique", "seigneur de la danse", de "naṭa", danse et "rāja", roi). Il est le plus souvent inscrit dans un cercle de flammes ("prabhāmaṇḍala") qui représente la succession des cycles cosmiques. Dans cette forme, il possède quatre bras tels que la main supérieure droite porte un tambour ("ḍamaru") symbolisant la pulsion rythmique de l'univers, la main inférieure droite fait le geste de protection ("abhaya-mudrā"), la main supérieure gauche tient la flamme qui symbolise la destruction, l'inférieure gauche montre sa jambe levée qui représente .

Le pied droit prend un appui fort en écrasant le démon de l'ignorance ou des passions, le pied gauche est levé en une posture de danse. Sa tête est encadrée par les flots du Gange dont son chignon a calmé l'impétuosité et qui coule maintenant sans danger dans le monde.

Shiva dansant représente l'âme universelle et éternelle irradiant toute l'énergie ("shakti"), notamment par le symbole du feu destructeur et créateur. Cette danse continue engendre la succession des jours et des nuits, le cycle des saisons et celui de la naissance et de la mort. À terme, son énergie provoquera la destruction de l'univers, puis le fera renaître. Cette danse de création du monde symbolise le processus éternel.

"Shiva Nataraja" est une forme typique originaire du Sud de l'Inde, c'est la divinité tutélaire du temple de Chidambaram où sont sculptées dans la pierre les postures du Bharata Natyam, la danse classique sacrée de l'Inde méridionale. Il est, sous cette forme, vénéré par les artistes scéniques (musiciens, danseurs, comédiens) indiens, les yogis et « les gens de bien ».

Shiva porte de nombreuses épiclèses :

Depuis le début de l'ère chrétienne au moins, sinon plus tôt, la plupart des hindous lettrés sont des adorateurs, soit de Vishnou, soit de Shiva — c'est-à-dire qu'ils considèrent soit Vishnou, soit Shiva, comme le premier des dieux, voire comme dieu unique identifié au brahman indifférencié, tous les autres ne représentant à leurs yeux qu'une expression secondaire de la divinité. 

Ainsi, les fidèles de Vishnou ne nient pas l'existence de Shiva, mais le placent sur un plan annexe, le considérant comme une création ou une émanation de Vishnou ou de son démiurge Brahmâ. D'une façon similaire, les shivaïtes voient en Vishnou une émanation du grand dieu Shiva. De nombreux mythes, dans les "purāṇa" śivaites ou viṣṇuites, illustrent la suprématie d'un dieu sur l'autre. 

Ainsi la « lingodbhavamūrti », illustrée abondamment sur les temples, surtout en Inde du Sud, raconte comment, alors que Vishnou et Brahmâ se disputaient la suprématie divine, Shiva apparut sous la forme d'un lingam de feu infini. Pour se mettre au défi, Brahmā décida d'en trouver le sommet sous la forme d'un hamsa (oie sauvage, véhicule de ce dieu) et Vishnou décida d'en trouver la base en prenant la forme d'un sanglier fouisseur. Tous deux échouèrent dans cette tâche et se prosternèrent devant le lingam de feu, reconnaissant sa suprématie. Shiva se révéla alors en sortant du lingam et leur expliqua que tous deux étaient nés de lui-même.

Si ces différences de point de vue ont à l'occasion été la cause d'affrontements, dans l'ensemble, ces deux branches de l'hindouisme sont parvenues à préserver entre elles une harmonie.

D'ailleurs, les textes contribuent à l'inclusion réciproque des deux dieux l'un par rapport à l'autre et soulignent leur solidarité étroite :

Dans l'iconographie, ce syncrétisme est illustré par la forme de Hari-Hara, mi-Vishnou mi-Shiva.

Selon l'orientaliste, Alain Daniélou (1956-1963, membre de l'Institut français d'indologie et de l'École française d'Extrême-Orient; 1963-1977, directeur de l'Institut international d'études comparatives de la musique à Berlin et Venise.) Shiva et Dionysos seraient à l'origine d'un culte commun dont la croyance aurait décliné en Europe et se serait poursuivit en Inde. Dans l'Inde, nous pouvons revivre et comprendre de manière parfois presque intégrale les rites et les croyances qui furent celles du monde méditerranéen et du Moyen-Orient dans l'Antiquité.

Daniélou oppose deux types de religions (l'une agricole et l'autre urbaine) en se basant sur les travaux de Mircea Eliade. Dans cette logique il avance que le culte d'un dieu naturiste et phallique, assimilé au taureau, serait un modèle universel mais que cette croyance aurait été marginalisée par l'expansion de la culture urbaine monothéiste. D'après Daniélou toujours, non seulement les 2 divinités, grecque et indienne, partagent bien des mythes en commun, mais en plus leur épithètes ont des significations comparables. [...]Dionysos est le Prôtogonos (le Premier-né) comme Shiva est Prathamajâ (Premier-né), le « plus ancien des dieux », aussi appelé Bhâskara(Lumineux) ou Phanès (Celui qui illumine) dans la tradition orphique. Ce dieu qui enseigne l'unité fondamentale des choses est appelé Shiva (Bienveillant) ou Meilichios (le Bienveillant). Il est Nisah (la Béatitude), le dieu de Naxos ou de Nysa. Le nom même de Dionysos signifie vraisemblabement le « dieu de Nysa» (la montagne sacrée de Shiva)comme Zagréus est le dieu du mont Zagron. Shiva-Dionysos est aussi Bhairava (le Terrible)ou Bromios (le Bruyant), Rudra ou Eriboas (le Hurleur).[...]

Pierre Lévêque constate également des similitudes entre les deux divinités, mais il rappelle que Dionysos et Shiva représentent deux formes bien spécifiées d'un même archétype, remontant sans doute au début du Néolithique, quand les communautés humaines se sont organisées en agglomérations villageoises et que ville et territoire se sont donc séparés.

"Bernard Sergent", chercheur au CNRS, agrégé d'histoire, grâce à la recherche comparative, confirme que Śiva et Dionysos représentent un héritage religieux indo-européen car d’autres figures divines chez les Germains, les Baltes, les Anatoliens, les Thraces, les Phrygiens, les Celtes se rattachent à Dionysos et Śiva.






</doc>
<doc id="2794" url="https://fr.wikipedia.org/wiki?curid=2794" title="Satoru Iwata">
Satoru Iwata

, né le à Sapporo, île d'Hokkaidō, et mort le à Kyoto, est un développeur puis producteur de jeu vidéo et chef d'entreprise japonais, président de HAL Laboratory de 1993 à 2000 puis de la société de jeu vidéo Nintendo de 2002 à 2015.

Dès l'adolescence, il s'intéresse à la conception de jeux vidéo. Pendant ses études d'informatique à l'université de technologie de Tokyo, il devient employé à temps partiel de HAL Laboratory qu'il rejoint à plein temps à la fin de ses études. Après avoir été président de cette société, il rejoint Nintendo comme chef de la planification en 2000 puis succède fin à Hiroshi Yamauchi au poste de président-directeur général de l'entreprise Nintendo, l'un des plus grands groupes de jeux vidéo au monde. Il est à l'origine de deux consoles au concept novateur, la Nintendo DS et la Wii.

Grâce à une façon de diriger proche de ses employés et à sa constante sympathie, il est considéré en 2007 et en 2008 comme l'un des meilleurs dirigeants d'entreprise au monde par ' et par le magazine spécialisé dans la finance '. Son salaire annuel s'établit en 2009 à 187 millions de yens, soit 1,7 million d'euros, ce qui est relativement très peu par rapport aux autres PDG dans le secteur du jeu vidéo. En crise de renouvellement au début des années 2010, Iwata divise à deux reprises son salaire pour réaliser des économies à Nintendo et garder de la motivation chez ses employés créatifs.

Il meurt le des suites de complications d'une tumeur biliaire pourtant soignée un an plus tôt. Il laisse derrière lui un patrimoine vidéo-ludique en ayant contribué à de nombreuses franchises phares de Nintendo, dont les séries "Pokémon", "Kirby", ou encore "Metroid". À la suite de l'annonce officielle du décès le , Nintendo met ses drapeaux en berne en signe de deuil. Plusieurs dizaines d'acteurs du jeu vidéo rendent également hommage à Iwata en exprimant leur tristesse face à la perte d'un membre incontournable de l'industrie du jeu vidéo.

Satoru Iwata naît le 6 décembre 1959 à Sapporo, dans la préfecture de Hokkaidō au Japon, où son père est maire. Il commence à s'intéresser à la création de jeux vidéo dès sa scolarité : originaire d'un environnement propice à la programmation, il produit des jeux électroniques chez lui. Iwata partage avec ses camarades d'école les quelques jeux de chiffres qu'il programme avec la HP-65, une calculatrice électronique. Son premier jeu est un jeu de baseball, qu'il décrit plus tard comme « sans graphismes », le jeu étant représenté par des chiffres. Ses amis prennent tout de même du plaisir à y jouer, le convainquant ainsi de continuer dans cette branche.

Après le lycée, Iwata est admis à l'université de technologie de Tokyo, où il est major en informatique. Malgré le manque de cours sur le développement du jeu vidéo, Iwata poursuit sa passion : il se rend régulièrement à un magasin d'informatique de Tokyo et forme un groupe d'amis, qui développe des jeux dans un appartement loué pour l'occasion. Ce groupe fonde plus tard la société HAL Laboratory, dont Iwata affirme que HAL , et fait également référence à l'ordinateur HAL 9000 du film "2001, l'Odyssée de l'espace". Toujours intéressé par les jeux vidéo, il travaille à temps partiel en tant que programmeur de jeux dans cette société, qui devient plus tard une filiale de Nintendo, tandis qu'il poursuit ses études jusqu'à l'obtention de son diplôme.

Malgré l'ouverture d'esprit des Japonais sur les loisirs, le père d'Iwata ne lui adresse plus la parole pendant six mois, déçu par le choix de carrière de son fils. Plus tard lors d'une interview, Satoru évoque que sa famille , le jeu vidéo étant encore à l'état embryonnaire à cette époque. Pour autant, Satoru garde des points communs avec son père. En effet, ce dernier sauve plusieurs emplois lors de son mandat d'élu grâce à sa détermination, alors que Satoru redressera les finances de Nintendo plus tard grâce à cette même qualité.
En 1982, après ses études à l'université, Iwata est recruté à plein temps par . Il est alors le cinquième employé de la société et le seul spécialiste en développement de jeux vidéo. Il commence sa vie active en concevant des périphériques pour ordinateur. Cependant, il est rapidement intéressé par les projets de Nintendo : déjà connue pour ses jeux "Game & Watch", la société a l'intention de sortir sa première console de salon, la Nintendo Entertainment System. Iwata prédit un succès commercial et demande alors à HAL d'entrer en contact avec Nintendo pour obtenir des contrats sur cette console. À cette époque, HAL n'obtient qu'un projet en difficulté, "Pinball", qu'Iwata finalise seul.

Il devient le coordinateur de la "production software" en 1983 et participe au développement de jeux tels que "Balloon Fight", "EarthBound", ou ceux de la série "Kirby", ce qui lui forge une réputation de développeur chevronné, travaillant sur des jeux aux gameplays originaux.

En 1993, Iwata est promu président de HAL Laboratory, alors en difficulté financière. Iwata arrive toutefois à redresser la barre, et assiste également Tsunekazu Ishihara lors de la création de la société Creatures Inc. en 1995, principalement connue pour ses produits dérivés de l'univers "Pokémon". Malgré son poste de président, Iwata continue de participer aux développements de plusieurs jeux, dont "Kirby’s Dream Land" et "Super Smash Bros.", qui deviennent deux succès dans les années 1990. Il est également l'initiateur de plusieurs idées novatrices : alors que Hiroaki Suga, développeur en chef de "Kirby's Adventure", doute de la possibilité technique des idées de Iwata, ce dernier lui explique qu'.

Bien qu'il ne soit pas employé par Nintendo à cette période, Iwata participe au développement de plusieurs jeux de la série "Pokémon" : il est responsable de l'internationalisation de "Pokémon Rouge et Bleu" dans un premier temps. Il participe ensuite au développement de "Pokémon Stadium" sur Nintendo 64, en analysant le code du système de combat de "Pokémon Rouge et Bleu" et en le retravaillant pour ce nouveau jeu. Enfin, il intègre l'équipe de développement de "Pokémon Or et Argent", sorti sur Game Boy Color en , en créant des outils de compression, permettant d'intégrer la zone de Kanto au jeu.

En 2000, conscient de l'aide qu'Iwata a fourni à Nintendo à plusieurs reprises, Hiroshi Yamauchi, président de Nintendo, lui propose le poste de chef de la division de planification d'entreprise. Iwata accepte volontiers l'offre, heureux de pouvoir travailler aux côtés de Shigeru Miyamoto, déjà connu pour ses talents en . Dès son arrivée, il s'assigne personnellement le développement de "Super Smash Bros. Melee", dirigé par son ancienne entreprise HAL Laboratory, alors en difficulté pour sortir le jeu dans les temps. Il prend en charge l'équipe de test et s'occupe de résoudre les bugs empêchant la sortie du jeu, pendant trois semaines, dans les locaux de HAL. Ce jeu est la dernière contribution d'Iwata en tant qu'.

Quand Yamauchi, le président de la compagnie depuis 1949, prend sa retraite en , il convoque Iwata dans son bureau. S'ensuit une longue discussion sur les défis que Nintendo a dû relever lors de ses cinquante années de présidence. Alors qu'Iwata pense qu'il est sur le point d'être licencié, Yamauchi lui propose en réalité de lui succéder en tant que quatrième président. Iwata devient alors le premier président de la firme sans lien de parenté avec la famille Yamauchi. Selon l'ancien président, le choix s'est porté sur Iwata pour , estimant qu'Iwata est apte à mener la société sur tous les fronts.

Contrairement à son prédécesseur qui règne seul sur la firme, Satoru Iwata est accompagné d'un conseil exécutif de six membres. Il sort l'entreprise de l'isolement, en s'associant avec d'autres entreprises du jeu vidéo, dont Namco, Square Enix et Sega. Yamauchi reste tout de même proche de la société jusqu'à sa mort en 2013, puisqu'Iwata .

Après l'échec de la GameCube avant son arrivée comme président, les projets d'Iwata pour relancer Nintendo sont la Nintendo DS et la Wii. En 2004, deux ans après son arrivée à la présidence, l'entreprise sort la Nintendo DS (Dual Screen) , console portable qui concurrence alors la PSP de Sony, et devient un succès commercial en étant la console de jeu la plus vendue au monde.

Conforté par le marché de la console portable, Iwata souhaite une console de salon ouverte au grand public, là où ses concurrents se concentrent à la course à la performance, laissant sur le chemin beaucoup de joueurs occasionnels. Il estime que . Lors de la en 2006, Iwata reprend la même idée et annonce : (). Pour concevoir la console, il se demande pourquoi les gens sont si à l'aise pour prendre en main une télécommande de télévision, mais sont effrayés par les jeux vidéo. La Wii sort alors en 2006 et devient également un succès commercial pour l'entreprise, avec "Wii Sports" qui, neuf ans après sa sortie, demeure le second jeu vidéo le plus vendu de tous les temps.

À la même période, il rénove l'organisation de Nintendo, avec la mise en place d'un conseil de gestion permanent, où siège Shigeru Miyamoto, autre personnalité phare de la société. En interview, les deux reconnaissent être complémentaires : alors que Miyamoto a un côté créatif très poussé, que lui jalouse Iwata, ce dernier a un esprit scientifique reconnu par son acolyte. Iwata amène également de la transparence à son public en initiant les « Iwata demande » (' en version originale), qui sont une série d'interviews d'Iwata avec d'autres employés de Nintendo. En 2007 et 2008, le ' ainsi que le magazine spécialisé dans la finance " le considèrent comme l'un des meilleurs dirigeants d'entreprise au monde.

Dans les années 2010, Iwata instaure les Nintendo Direct, afin de renouer le lien avec les joueurs les plus fidèles de Nintendo. Ce sont des présentations organisées régulièrement via Internet afin de présenter les nouveautés de la société. Iwata est le présentateur des Nintendo Direct japonais et internationaux de 2011 jusqu'à son décès, en 2015. Ces présentations montrent une image décontractée et sympathique d'un président, pourtant à la tête d'une société multi-milliardaire, où Iwata se déguise notamment en Luigi ou se bat face à Reggie Fils-Aimé.

Dans les années 2010, Nintendo doit faire face à la concurrence des smartphones et tablettes, qui marquent l'arrivée des jeux gratuits ('). Iwata sera toujours critique face à ce modèle : . Il établit une comparaison avec l'arrivée de ce modèle dans le secteur de la musique, lequel s'est selon lui dégradé en s'y adaptant. Son intention n'est pas d'éviter totalement le ' mais de révolutionner le genre pour en corriger ses défauts.

Lors de la conférence E3 2010, il dévoile la Nintendo 3DS. Cependant, les ventes de cette nouvelle console sont dans un premier temps moroses. En 2011, Satoru Iwata décide ainsi de diminuer de moitié le montant de la part fixe de son salaire, lequel se montait au total en 2009 à 187 millions de yens, soit 1,7 million d'euros. Ce salaire est alors composé d'une base fixe de 68 millions de yens, portée à 187 millions avec les bonus de performances. Il reste un président modeste, puisqu'en comparaison, Shigeru Miyamoto a un salaire de 100 millions de yens, soit environ euros. En 2014, malgré le succès de la Nintendo 3DS, il divise à nouveau par deux son salaire à la suite d'une baisse des résultats en partie expliquée par un manque d’engouement pour la Wii U. Toujours proche de ses développeurs, il estime que si ceux-ci vivent dans la peur d'être licenciés, ils ne peuvent .

Grâce aux réserves de l'entreprise, il continue à pousser de nouvelles idées, en ouvrant un nouveau centre de recherche et en lançant un nouveau projet, ". De même, après des années d'une politique anti-smartphone critiquée, Iwata annonce que Nintendo publiera des jeux sur téléphones. Souvent attaqué sur les faiblesses techniques des consoles de Nintendo par rapport aux concurrents, Iwata défend son entreprise : .

En 2015, une des dernières annonces d'Iwata est la Nintendo NX, où la firme veut montrer que le marché de la machine dédiée au jeu vidéo n'est pas encore mort. Iwata promet que la console sera une surprise pour les joueurs, une fois encore innovante sur le marché du jeu vidéo. En effet, lors d'une interview, il laisse entendre que cette nouvelle console n'aura rien à voir avec les consoles précédentes, notamment la Wii U.

En 2014, Nintendo annonce l'absence de Satoru Iwata à l'E3 pour des raisons médicales. Plus tard, il est annoncé qu'Iwata a une tumeur biliaire et que ses médecins lui ont conseillé de ne pas voyager, avant une opération pour retirer la tumeur. Cela l'empêche d'assister à l'assemblée générale de Nintendo en juin 2014. Un an plus tard, Iwata meurt à l'âge de 55 ans le , des complications de cette tumeur, quelques jours après l'édition 2015 de l'E3 à laquelle il n'a pas participé non plus. Il laisse derrière lui sa femme, Kayoko. Nintendo annonce officiellement la mort de son président le 13 juillet 2015.

De nombreuses entreprises et personnalités du jeu vidéo rendent hommage à Iwata le jour de l'annonce, notamment via les réseaux sociaux. Bien que concurrents de Nintendo, des sociétés comme Sony et Microsoft relaient via Twitter leurs messages de deuil. Sony remercie Iwata pour son travail, tandis que Microsoft estime que son travail a eu un impact sur le développement de l'industrie du jeu vidéo. De son côté, Nintendo ne publie de la journée aucun message sur ses réseaux sociaux, en signe de deuil, et met en berne les drapeaux au siège social de l'entreprise. Pure coïncidence, un arc-en-ciel apparaît au-dessus du siège de Nintendo le même jour. Plusieurs fans de la société le qualifieront de , en référence à un circuit populaire de la série "Mario Kart" et au décès d'un de ses contributeurs. Des mémoriaux sont dressés par les fans de Nintendo dans le monde, notamment à l'ambassade du Japon de Moscou, au Nintendo World Store de Manhattan, où des dessins d'Iwata ou d'éléments clés de Nintendo sont déposés.

À l'annonce de sa mort, Shigeru Miyamoto et Genyo Takeda sont nommés pour prendre en charge la direction de Nintendo de façon temporaire. Dans un discours pour IGN, Miyamoto dit être surpris de la mort soudaine d'Iwata mais que les équipes de Nintendo resteront fidèles à la ligne directrice construite par Satoru Iwata, pour produire dans les années futures ce qu'Iwata aurait apprécié voir.

Ses funérailles sont organisées le 17 juillet, et plus de y assistent. Lors de sa prise de parole, au nom de Nintendo et de ses employés, Takeda dit vouloir finaliser avec Miyamoto ce qu'Iwata a commencé, ajoutant qu'.

En octobre 2015, un Amiibo unique à l'effigie d'Iwata, entouré de plusieurs objets emblématiques de Nintendo, est réalisée par l'artiste GandaKris. La figurine est vendue aux enchères sur eBay et l'argent récolté est reversé à l'association , dont le but est d'améliorer le quotidien des enfants hospitalisés via le jeu vidéo entre autres.

Lors de la cérémonie de 2015, Iwata se voit attribuer à titre posthume le prix pour ses travaux dans l'industrie du jeu vidéo et l'impact qu'il a eu. L'année suivante, il reçoit également le aux DICE Awards, organisé par l'. 

En 2016, David Hellman, artiste ayant travaillé sur "Braid", réalise un film d'animation de trois minutes afin de rendre hommage à Iwata. Enfin, le texte (littéralement ) est présent à la fin des crédits du jeu "Star Fox Zero", dernier jeu auquel il a contribué en tant que producteur exécutif avant sa mort.

Créatif et baignant dans le développement depuis son enfance, Iwata se désigne comme étant un développeur au fond de lui tout au long de sa vie. Même à des postes de manager chez Nintendo, il participe à la finalisation de plusieurs jeux, afin d'aider ses équipes en difficulté. Un exemple marquant est "Super Smash Bros. Melee" où Iwata prend la casquette d'.

Lors de la GDC en 2005, il est selon lui un développeur avant d'être un président, mais surtout un joueur au fond : . Il réitère le même discours lors d'une interview dans les années 2010, où il rit de ces situations en disant qu'il était plus un développeur qu'un président de société à l'époque de HAL Laboratory :

Ce vécu de développeur est d'ailleurs la raison pour laquelle il crée les Iwata demande, afin de permettre à ses collègues de partager leur passion. Initié au lancement de la Wii, le but de ces interviews est de discuter du processus de développement des jeux et produits de la société, ceci dans le but de les promouvoir. C'est un moyen pour Iwata de partager . Ces interviews, ponctuées de blagues et de rires montrent un président proche de ses employés, tel un bon camarade. Cette ambiance se retrouve également lors des Nintendo Direct, où Iwata se retrouve à simuler un combat à la façon "Super Smash Bros." contre Reggie Fils-Aimé, ou représenté sous forme de marionnette.

Iwata est connu pour sa vision novatrice du jeu vidéo, qui a transformé cette industrie lors de sa présidence au sein de Nintendo. Contrairement aux acteurs de l'époque qui se concentrent sur la course à la puissance, Iwata prend la décision de repenser le jeu vidéo comme un divertissement universel, et non réservé aux joueurs déjà avertis. En effet, en 2001 Nintendo se retrouve en difficulté avec la Gamecube face à la PlayStation 2 et la Xbox. Alors que la Nintendo Entertainment System s'est vendu à d'exemplaires aux alentours des années 1990, la Gamecube n'atteint que d'exemplaires. Iwata réfléchit à une nouvelle console, capable de réunir à la fois ceux qui n'ont jamais joué et les passionnés de jeux vidéo. 

Avant l'E3 2006, Nintendo annonce la sortie prochaine de la Wii, connue précédemment sous le nom de code "Revolution". Le nom n'est pas anodin et reflète l'envie d'Iwata : une console pour plusieurs (le nom se prononce « », « nous » en anglais). Alors que ses concurrents annoncent des consoles encore plus puissantes, Nintendo présente une console avec un tout nouveau système de jeu, reposant sur les gestes, via la Wiimote.

Dans une interview, Iwata compare le secteur du jeu vidéo à Hollywood, et suggère que le challenge est de . À la sortie de la console, Iwata montre bien que son idée est de réunir l'ensemble de la population : .

Ces dernières années, malgré les ventes décevantes de la Wii U et de la Nintendo 3DS, Iwata maintient le cap, voulant toujours proposer des plates-formes à la fois conviviales et ouvertes, comme ce fut le cas avec "Wii Sport" ou la série "Mario Kart" par exemple, et intéressantes pour les joueurs les plus exigeants, avec les licences "The Legend of Zelda" ou "Metroid Prime". Il n'a ainsi jamais réellement cru au mobile, et bien que des projets aient été annoncés, aucun jeu Nintendo n'est sorti sur smartphone sous la direction d'Iwata. Selon lui, le smartphone n'est pas une plate-forme adaptée pour le jeu vidéo. Même s'il n'interdit rien à ses équipes, il reste opposé à ce secteur où le développement des jeux est affecté par des prix trop faibles et le "free to start", terme qu'il préfère à celui de "". Il admet cependant que cela peut être l'occasion de développer des outils amenant l'utilisateur vers les jeux Nintendo (et donc ses consoles), via une application pour Mii par exemple.

En plus de son engagement dans la conception des consoles de la firme entre 2002 et 2015 (notamment la Nintendo DS et 3DS, la Wii et la Wii U), Iwata a aussi travaillé sur plusieurs séries populaires de Nintendo : "The Legend of Zelda", la série des Mario, la série "Animal Crossing", "EarthBound", Pokémon ainsi que la série "Metroid".

Principalement développeur pendant ses années à HAL Laboratory, il travaille sur de nombreux projets pour les consoles de Nintendo. Il devient producteur puis rapidement producteur exécutif après son entrée chez la firme nippone. Il supervise près de 150 jeux en vingt ans de carrière, notamment sur les licences les plus célèbres de Nintendo.

Tout au long de sa carrière, Iwata sait faire preuve d'audace, en insufflant une vision toujours novatrice : il n'hésite pas à remettre en question les bases du jeu vidéo et invente de nouvelles façons de jouer pour toucher le grand public. Cela se reflète via les consoles de Nintendo, dont la Wii est l'exemple le plus marquant, ce qui amène également de nouveaux concepts de jeux, comme "Wii Sports" ou la série "WarioWare", utilisant pleinement les capacités de ses consoles.






</doc>
<doc id="2795" url="https://fr.wikipedia.org/wiki?curid=2795" title="Spiritualité">
Spiritualité

La notion de spiritualité (du latin ecclésiastique "spiritualitas") comporte aujourd'hui des acceptions différentes selon le contexte de son usage
Elle se rattache conventionnellement, en Occident, à la religion dans la perspective de l'être humain en relation avec des êtres supérieurs (dieux, démons) et le salut de l'âme. Elle se rapporte, d'un point de vue philosophique, à l'opposition de la matière et de l'esprit (voir problème corps-esprit) ou encore de l'intériorité et de l'extériorité

Elle désigne également la quête de sens, d'espoir ou de libération et les démarches qui s'y rattachent (initiations, rituels, développement personnel, Nouvel Âge)
Elle peut également, et plus récemment, se comprendre comme dissociée de la religion ou de la foi en un Dieu, jusqu'à évoquer une « spiritualité sans religion » ou une « spiritualité sans dieu »

Elle désigne parfois des aspects esthétiques dans la littérature.

Bien que les aspirations et pratiques spiritualistes se soient développées de façon souvent très normative (dans le cadre d’Églises établies, ou de rites traditionnels) au point de rendre les termes religion et spiritualité synonymes pendant plusieurs siècles, la notion de spiritualité s'est de plus en plus appliquée dans les travaux de théologiens ou de sociologues pour désigner des croyances et comportements humains universels antérieurs ou postérieurs aux religions historiques et dont la motivation serait liée à l'idée d'une survie après la mort physique, à une notion plus ou moins apparentée à celle de l'âme, en tant qu'entité cohérente et indépendante du corps, ainsi qu'à des rites propitiatoires proches du chamanisme (pour appeler une bonne chasse, de bonnes récoltes, etc., voir les rites funéraires préhistoriques). Certains voient dans la spiritualité une simple expression de l'instinct de survie, voire un moyen de ne pas se confronter à la réalité de notre condition de mortels ; selon d’autres, elle révèle la mémoire intrinsèque de l’immortalité de l’âme. Si toute religion est fondée dans une spiritualité , toute spiritualité n'est donc pas une religion. Selon certains auteurs, la distinction se ferait ainsi : il y aurait dans la religion une perspective collective et dans la spiritualité une démarche plus individuelle.

La spiritualité religieuse est souvent associée à l'origine latine "religare", dont le premier sens (Félix Gaffiot) est : attacher par-derrière, relier , attacher, amarrer [les navires au rivage]. C'est une racine possible du mot "religion". Il s'agit alors essentiellement dans un sens très extensif de se relier à Dieu, au divin, à une réalité transcendante ; un lien qui conduirait, toujours par extension, l'homme à se relier aussi à lui-même, aux autres, à la nature ou à l'univers. Beaucoup d'auteurs cependant, et depuis l'Antiquité (Cicéron), s'appuient sur l'étymologie latine "relegere", « relire », peut-être par extension « réécrire », par exemple les rituels, ou se placer dans la perspective d'une nouvelle lecture. Aujourd'hui, dans les études francophones c'est l'étymologie "relegere" qui est considérée comme généralement admise, tandis que dans les études anglophones c'est plutôt celle de "religare".

Après avoir supplanté les spiritualités plus ou moins structurées du paganisme ou de l'animisme, les spiritualités juive, bouddhique, chrétienne, musulmane, se sont développées sans véritable concurrence pendant de nombreux siècles, jusqu'au siècle des Lumières. Dans tous les pays où ces religions n'étaient pas parvenues à s'imposer, des spiritualités locales ont cependant continué à se développer.

Différentes pratiques sont issues des spiritualités religieuses :

Certaines de ces activités sont solitaires, d'autres collectives, certaines se vivent dans la réclusion volontaire (cellule monastique) et d'autres « à l'extérieur » (dans la société civile). Certaines sont contemplatives, d'autres plus pratiques. Le choix des activités et l'importance relative donnée à chacune permettent d'approcher la « spiritualité » qui diffère à chaque courant spirituel.
Toutes ces activités sont expressément définies et organisées lorsque l'expérience spirituelle est vécue au sein d'un monastère (ou son équivalent couvent, ashram, confrérie), les tâches domestiques sont alors également incluses dans le champ de la pratique spirituelle et donc stipulées par la Règle monastique.

La spiritualité n'est pas limitée à une démarche conceptuelle ou dogmatique. L'expérience spirituelle (ou expérience mystique), par la recherche d'intériorité, de connaissance de soi, de transcendance, de sagesse, ou de dépassement des limitations de la condition humaine est indissociable de la démarche intellectuelle. C'est pourquoi la spiritualité débouche généralement sur des démarches corporelles, émotionnelles et mystiques, cherchant à générer une expérience transcendante, une relation (selon l'une des étymologies de "religion") avec Dieu, le Soi, la Conscience, l’Âme, le Monde, le Devenir,
etc. Pour certains, le but de la spiritualité est une exploration profonde de l'intériorité, conduisant à l'éveil spirituel, une conversion intime, ou l'accession à un état de conscience modifié et durable.

La spiritualité, en tant qu'expression d'une aspiration aussi ancienne que l'humanité, existait avant les institutions religieuses.
Après plusieurs siècles d'une spiritualité presque exclusivement religieuse, l'émergence de la philosophie, le déclin de l'adhésion aux grands courants religieux et le passage à la société postmoderne ont conduit une partie des « croyants » à revendiquer à nouveau une spiritualité sans appartenance à une institution religieuse, exprimant, par exemple, une préférence pour l'humanisme (pouvant relever de l'athéisme ou non).
Une autre origine de cette transformation se trouverait dans le fait que, par la sécularisation de la société, le « religieux » place une importance plus grande sur la spiritualité, jusqu'à la recherche d'expériences mystiques individuelles, alors qu'auparavant, « dans la société plus marquée religieusement, la demande va plutôt dans le sens d’une religion plus mondaine ».

Mais c'est surtout à partir de la seconde moitié du que se développent des approches spirituelles non religieuses, avec le New Age, l'adoption par l'Occident des pratiques orientales, souvent dissociées de la religion qui les contenait, et les psycho-spiritualités. Françoise Champion qualifie cette émergence des nouveaux mouvements religieux de « nébuleuse mystico-ésotérique », caractérisée, selon Claude Rivière, par « "la primauté accordée à l’expérience personnelle et à la voie spirituelle de chacun, (…) l’inclusion de la santé (thérapie, guérison) et du bonheur ici-bas dans la visée du salut, (…) une conception moniste du monde sans séparation du naturel (écologisme), du surnaturel, de la science, de la religion et des pratiques magiques populaires ou ésotériques" ». Dans le discours des pratiquants de diverses spiritualités postmodernes, on retrouve deux tendances principales «" se connecter à son soi profond (se relier à soi) ou se rapprocher de l’autre (se relier à l’extérieur de soi)" ». La fonction de la démarche spirituelle est alors de « "se rattacher avec ferveur à l’autre, au sens large du terme : que ce soit à Dieu (pour une connexion verticale, Ellison, 1983), à un proche, aux morts, à la nature ou à une cause (pour une connexion horizontale)" ». Mais dans l’absence du cadre strict des dogmes religieux, la spiritualité s'élargit à des champs nouveaux, par lesquels sont parfois qualifiés de « spirituels » des actes comme « "payer à manger à un SDF et ensuite manger avec lui, parler avec lui pour lui faire du bien" » ou « "aider des enfants en difficultés scolaires" » ou partager « "des moments intenses avec ses enfants, ses proches, pour être liés à eux" » ou encore « "être en harmonie avec la nature" ».

Parmi ces nouvelles émergences, une mouvance se distingue des autres et se fait appeler "spiritualité laïque". La spiritualité laïque conçoit l'existence d'une « "intuition spirituelle qui fédère l'humanité tout entière" » capable de « "développer une véritable « Science spirituelle » et une « Spiritualité scientifique" »». Elle se dit issue d'une « démocratisation de la spiritualité » aboutissant à une « spiritualité séculière affranchie du contrôle religieux institutionnel ». Le philosophe Vladimir Jankélévitch tentait d'approcher ainsi, à la suite de Bergson, au plus près de ce qu'il percevait comme les fondamentaux d'une spiritualité humaine, ou d'une « philosophie première », proche de la conception bouddhiste.

Le bouddhisme exprimait en effet, à son émergence, le besoin d'une régénération de la spiritualité hors des dogmes du védisme dominant en Inde. Encore aujourd'hui, selon Matthieu Ricard, interprète français du Dalaï Lama : « "(le Dalaï-Lama) très attaché à la notion de « spiritualité laïque », déclare que « la religion est un choix personnel et que la moitié de l’humanité n’en pratique d'ailleurs aucune et qu'en revanche les valeurs d’amour, de tolérance, de compassion prônées par le bouddhisme concernent tous les humains, et cultiver ces valeurs n’a rien à voir avec le fait d’être croyant ou non ». »
Le néo-paganisme du est une résurgence des croyances et pratiques, plus ou moins revisitées, qui précédaient le christianisme avant la fin du .

La philosophie est une approche qui repose, en principe, sur la raison. La spiritualité est fondée sur la notion plus évasive et aléatoire de l'« expérience intérieure » ou de la croyance. Pour le philosophe, le discours devrait toujours faire référence à une "expérience possible" (Kant) et ne jamais spéculer sur du vide. La philosophie concerne plutôt la « pensée » là où la spiritualité s'intéresse à l' « Esprit », dans le sens spiritualiste du terme.
Bien que pour Spinoza, il existe cependant quelque chose de l'ordre de l'intuition (ou de l'évidence, pour Descartes), donc pas seulement de l'expérience empirique, et conduisant à la vérité, pour le philosophe, en général, la spiritualité est une notion valide, aussi longtemps qu'elle ne fait pas « référence à des croyances, religieuses ou autres » et qu'elle se définit comme « l’incidence de la vérité (comme telle) sur le sujet (comme tel) ».

Dans les doctrines comme le soufisme, le taoïsme, l'hindouisme, le bouddhisme, l'être humain est considéré comme souffrant du déséquilibre de ses émotions, de ses fixations mentales, de ses « mémoires » (vāsanā et saṃskāra en sanscrit) et du manque d'harmonie entre les différentes composantes de l'être : l'intellect, le corps, la parole, etc. La « guérison spirituelle » est généralement recherchée avec l'appui et l'encadrement d'un maître, d'un guide, dénommé lama, gourou ou cheykh selon les traditions. Au travers de la relation entre le disciple et le maître, ce dernier jouait parfois le rôle d'un thérapeute avant l'heure, et le disciple était proche du « patient » de la médecine moderne.
Cette approche spirituelle reste cependant limitée aujourd'hui aux régions du monde où la relation de maître à disciple est perçue comme une composante naturelle des relations humaines.

Le psychothérapeute joue un rôle similaire (en France, le développement de cette pratique a conduit à l'élaboration d'une loi pour mieux encadrer la profession et éviter que le psychothérapeute se confonde avec l'image du gourou
). L'expérience des groupes des alcooliques anonymes a souvent été donnée en exemple ou, alternativement, montrée du doigt, comme une combinaison de psychothérapie et de spiritualité.

Dans les pays occidentaux, quelques psychanalystes en vinrent à penser que certaines pathologies pourraient ne pas trouver de résolution par l'analyse seule. Après avoir montré le rôle important de la société dans la névrose, l'analyse débouchait parfois sur des problèmes qualifiés de « spirituels ». Certains psychanalystes, dont Jung, se tournèrent vers l'étude de pratiques issues de religions traditionnelles afin de « guérir l'âme ». Ainsi, dans les années 1960, les travaux de Jung avec la collaboration d'Abraham Maslow, d'Assagioli entre autres, en collaboration avec des scientifiques et des moines bouddhistes, ont donné naissance à la psychologie transpersonnelle.

Le New Age, syncrétique, éclectique, a contribué à brouiller les signes religieux traditionnels en développant une spiritualité sans frontière ni contours bien définis. L'usage des psychothérapies les plus diverses (ainsi que des médecines non conventionnelles) y est dominant. La séparation traditionnelle entre le conseil spirituel et le conseil thérapeutique y est souvent gommée.

Selon certains auteurs, ce qu'ils qualifient de « spiritualités fugitives » (fuyant la société), serait le résultat d'un « manque de transcendance » dans l'espace social. La rupture avec le monde de ces nouvelles spiritualités les conduit à « évoluer librement » au point de ne plus pouvoir être questionnées faute de l'existence d'espaces créés à cet effet. L'affirmation courante, dans certaines formes de spiritualités « libres » issues du postmodernisme, que la spiritualité n'a pas besoin de la « vérité » (voire d'objectivité) mais uniquement de la « beauté » et d'absence de contrainte, sexuelle, intellectuelle voire financière est un sujet de débat autant pour les religions établies que pour les observateurs laïcs qui associent généralement ces nouveaux courants à des sectes par le potentiel de dérives qu'ils leur semblent contenir.




</doc>
<doc id="2798" url="https://fr.wikipedia.org/wiki?curid=2798" title="Shōjo">
Shōjo

En Occident, le mot est fréquemment utilisé pour désigner un ensemble d’œuvres possédant ses propres caractéristiques et canons. 

Son équivalent coréen est le "sunjeong manhwa".

Au milieu de l'ère Meiji (1868-1912), le système éducatif japonais devient non mixte. De cette séparation naît le concept de ' et par extension la distinction par cible démographique. Ainsi, les premiers magazines dédiés exclusivement aux ' apparaissent en 1903 avec la création de , puis en 1906, en 1908 et en 1912. En 1923, l'éditeur Kōdansha crée une gamme de magazines dédiée uniquement à la jeunesse, dont ', l'une des plus importantes revues ' de cette période. Cependant, les mangas restent sous-représentés dans ces magazines avec tout au plus quelques pages leur étant dédiées, laissant la place majoritairement aux romans, illustrations et poèmes. 

Ces histoires illustrées ont malgré tout une place importante dans la mise en place de la culture ', et par extension du '. En effet, elles posent les bases des thèmes récurrents aux ' à venir, en proposant aux jeunes Japonaises des histoires , explorant avant tout les . En tête des autrices emblématiques de cette époque, on retrouve notamment Nobuko Yoshiya, et son récit ' dépeignant une , éléments encore présents dans le ' moderne. En plus de son apport pour la culture ', cette romancière est également emblématique de son sous-genre, le '. Par ailleurs, les racines graphiques du ' puisent leurs origines dans les illustrations de ces magazines, avec notamment le travail du peintre lyrique Jun'ichi Nakahara, façonnant ses personnages féminins avec . 

Les ' mangas en sont quant à eux à leurs balbutiements. Ils se déclinent principalement sous forme de courtes histoires comiques de quelques pages, prenant place dans les lieux du quotidien . Parmi ceux-ci, les œuvres du mangaka Katsuji Matsumoto ont un impact majeur sur l'identité graphique du ' manga, et . ' (1934) propose sur 16 pages une aventure sophistiquée, mettant en scène une jeune fille aux allures de . Avec des effets graphiques novateurs empruntés au cinéma , cette œuvre avant-gardiste est considérée comme un précurseur du ' manga Princesse Saphir (1953-1956) de Osamu Tezuka. Mais l'œuvre qui lui donne sa notoriété est ' (1938-1940), aux graphismes proches de la culture ' qui se développera plusieurs dizaines d'années plus tard.

Avec le commencement de la seconde guerre sino-japonaise en 1937, la censure et le rationnement du papier étouffent les magazines, qui sont forcés à fusionner pour survivre. Il ne reste alors plus que quelques magazines, réduits à quelques pages en noir et blanc, où les illustrations se font rares. Il faut attendre la fin de la guerre, en 1945, pour retrouver une situation éditoriale normale. Pourtant, les magazines pour filles doivent faire face à une mutation importante : l'essor du ".

Avec la fin de la guerre, le peuple japonais peut enfin mettre derrière lui les années de privations et de malheur. Il se rue sur les divertissements, offrant son âge d'or au cinéma, à la radio et aux variétés. Le livre populaire connaît quant à lui une renaissance, grâce à de petits éditeurs implantés dans la région du Kansai. En effet, par l'utilisation d'un papier de mauvaise qualité à bas prix, ceux-ci proposent des livres, les , particulièrement bon marché et disponibles partout . Parallèlement, les librairies de location connaissent un essor important, proposant des livres spécialement dédiés à la location, les ", pour la somme modique de 5 yens, l'équivalent de la moitié d'un ticket de métro à l'époque. Par ailleurs, cet essor permet l'arrivée de nouveaux talents dans le monde des mangas.

De par leurs formats conséquents (100 pages et plus), Osamu Tezuka voit dans ces nouveaux supports l'occasion de transformer la narration du manga. Ainsi, et avec l'influence de l'occident, Walt Disney Pictures en lice, il lance un nouveau style de manga, le . Il renouvelle le genre avec des histoires épiques aux graphismes dynamiques, grâce aux emprunts aux conventions cinématographiques. Ce nouveau genre offre un nouveau souffle au manga, et s'intègre dans le renouveau des magazines pour enfants. Cependant, bien qu'innovant, ce nouveau genre peine à trouver sa place au sein " manga". En effet, les histoires de ces mangas ne trouvent pas leur public parmi les jeunes japonaises, la faute à des auteurs majoritairement masculins qui n'arrivent pas à saisir leurs attentes, enchaînant les tragédies mettant en scène des héroïnes torturées et passives. Mais parmi elles, une œuvre ' déroge à la règle ; "Princesse Saphir", premier ' de Tezuka créé en 1953, rencontre un fort succès. En effet, Tezuka, fort de son expérience en manga ', décide d'en appliquer le canevas narratif offrant aux lectrices une héroïne forte, active face à l'adversité, et une trame narrative riche et dynamique. Si Tezuka n'a pas inventé le ' manga , "Princesse Saphir" et son héroïne travestie reste un point d'étape important dans l'histoire du ' manga, en offrant au genre un nouveau style narratif. Par ailleurs, il pose les bases du style graphique pour les ' manga à venir. 

À la fin des années 1950, le manga pour fille demeure principalement produit par des hommes. Parmi ces auteurs, on retrouve par exemple Leiji Matsumoto, Shōtarō Ishinomori ou encore Chiba Tetsuya. Leurs œuvres, destinées aux magazines "Shōjo Friend", "Ribon" ou "Margaret" s'inspiraient de contes illustrés. On retrouve des mangas tels "La princesse rouge-gorge" de Negishi Komichi et "La mort d'Ivan Ilitch" de Mori Minoru (adaptation d'un conte de Tolstoï). Mais ces auteurs masculins laissent progressivement la place à des femmes comme Hideko Mizuno et Miyako Maki.

Parallèlement, grâce aux ', le manga gagne en visibilité et en influence. Ainsi, la proportion de mangas dans les magazines augmente. Par exemple, s'ils ne représentaient que 20 % du magazine " Club" au milieu des années 1950, ils en occupent déjà plus de la moitié à la fin de celles-ci. Avec une telle augmentation de la part des mangas, ces magazines ' deviennent rapidement des magazines ' manga. Ainsi, en décembre 1954, le mensuel "Nakayoshi" de l'éditeur Kōdansha est créé, suivi en 1955 par le magazine de Shūeisha, "Ribon". Par ailleurs, certains magazines ' suivent la lignée de leurs équivalents, les ' manga magazines, qui fort de leurs popularités, passent d'un rythme mensuel à un rythme hebdomadaire. C'est notamment le cas du magazine " Club", qui se renomme "" en 1962 et de ' en 1963.

Ainsi, au milieu des années 1960, grâce à l'augmentation de la fréquence de ces magazines pour filles, de nouveaux auteurs font leur entrée dans le monde du " manga" pour satisfaire le besoin en contenu. Jusque-là majoritairement masculin, une poignée de femmes ' rejoigne les rangs du '. Si certaines se positionnent en héritière de l'écrivaine d'avant-guerre Nobuko Yoshiya en proposant principalement des histoires évoquant la beauté et l'onirisme des premières relations amoureuses, l'une d'entre elles, Yoshiko Nishitani, tente une nouvelle approche. En effet, elle est l'une des premières à proposer des mangas mettant en scène des héroïnes à l'image de ses lectrices : de jeunes japonaises vivant leur vie d'adolescente ordinaire . L'une de ses œuvres, ', est notamment précurseur d'un sous-genre incontournable dans du ' manga moderne : la romance en milieu scolaire.
Par ailleurs, les années 1960 inaugurent les premières diversifications du ' manga. Ainsi apparaît le premier manga de genre "", "Himitsu no Akko-chan". Conçu par le "mangaka" Fujio Akazuka et publié dans le magazine "Ribon" de 1962 à 1965, il met en scène une jeune fille, Akko, qui se voit dotée d'un miroir magique lui permettant de changer d’apparence. ' est suivie par Sally, la première héroïne ' à apparaître à la télévision japonaise en 1966 dans lanime Sally la petite sorcière", basé sur le manga éponyme de Mitsuteru Yokoyama. En parallèle, des ' du ' manga proposent aux jeunes filles de nouveaux thèmes : le manga d'horreur, avec notamment "" (1965) de Kazuo Umezu et le manga sportif avec "Les attaquantes (") (1967) de Chikako Urano.

À partir des années 1970, la production des ' se féminise véritablement. Ceux-ci se complexifient, graphiquement comme thématiquement, en phase avec la révolution féminine et sexuelle. Ce renouveau résulte d'une nouvelle génération d'auteurs, nommée rétrospectivement le « Groupe de l'an 24 ». Parmi elles, on retrouve notamment Moto Hagio, Keiko Takemiya, Riyoko Ikeda, Ryōko Yamagishi, Yumiko Ōshima, Yumiko Igarashi. Elles vont offrir à leurs lectrices des histoires aux thèmes inédits — science-fiction, la ', la comédie, le manga historique, etc. — partageant comme thématique commune, l'amour, et décrivant avec profondeur la psychologie de ses personnages. Hagio et Takemiya initie un nouveau genre, le ', mettant en scène l'homosexualité masculine, avec les œuvres ' (1970) pour Takemiya et "Le pensionnat de novembre" (1971) pour Hagio. Ces fleurs de l'an 24 vont modifier les codes graphiques, avec des traits plus fins et plus légers, des visages d'une beauté frôlant l'exagération, des pages plus lumineuses, et des cases aux contours éclatés, effacés, voire dépassés. Cette évolution du "shōjo", tant graphique que thématique, le sépare alors définitivement du "shōnen manga" et pose le modèle pour l'ensemble des "shōjo manga" à venir.

En parallèle, des auteurs comme Hideko Mizuno font évoluer leurs œuvres pour les adapter à leurs jeunes lectrices devenues femmes. Ce sont les prémices du "", avant sa consécration dans les années 1980.

Les histoires romantiques sont un thème très fréquemment abordées dans le "shōjo". Elles se situent généralement dans un cadre scolaire.

Quelques exemples :


Quelques exemples :

Le est un genre de mangas dans lequel l'intrigue est centrée autour d'une relation homosexuelle entre personnages masculins, et comportant éventuellement des scènes sexuelles.

Avec des joueuses féminines dans des sports comme le tennis dans "Jeu, set et match !", le volley-ball dans "Jeanne et Serge" et "Les Attaquantes", ou dans "Ginban Kaleidoscope" avec le patinage artistique.






</doc>
<doc id="2799" url="https://fr.wikipedia.org/wiki?curid=2799" title="Septoriose du blé">
Septoriose du blé

La septoriose du blé est une maladie fongique due principalement à "Septoria tritici" et "Septoria nodorum", qui affecte le blé et d'autres espèces du genre "Triticum" et se rencontre dans toutes les zones de culture du blé à travers le monde. Elle peut causer des pertes de rendement de plus de 40 %.
Elle touche également d'autres cultures. Les épidémies peuvent être très dommageables du fait de leur développement exponentiel.


Ces deux champignons appartiennent aux Ascomycètes mais sont très différents sur le plan biologique et morphologique. "Stagonospora nodorum", qui était dominant sur blé en France au début des années 1980, a été supplanté par "Septoria tritici".

Les périthèces formés sur résidus de culture libèrent à l'automne des ascospores responsables des contaminations primaires. Les pycnospores libérées en présence d'humidité constituent ensuite le moteur de l'épidémie. Elles requièrent de l'eau libre pour germer. La phase d'incubation (apparition des premiers symptômes et des pycnides) dans les tissus de blé est relativement longue (15 à 21 jours).
Concrètement, chaque pycnospore peut être à l'origine d'une nouvelle lésion. Or, il y a en moyenne 1000 pycnospores par pycnide, 40 pycnides par lésion et de 3 à 4 lésions par feuille en cas de forte attaque. On peut donc estimer le nombre de pycnospores potentiellement infectieuses produites par chaque plante contaminée à environ 250 000.

Les symptômes engendrés par "Septoria tritici" sont observables dès la fin de l'automne et durant tout l'hiver sur les feuilles de blé.
Les principaux organes atteints sont les feuilles, les nœuds et les épis. Les semences contaminées sont à l'origine de « manque à la levée » et de fonte des semis. Les jeunes plantules attaquées sont souvent de taille réduite, mais les racines ne présentent aucune pourriture.
L'aspect des taches est assez diversifié, celles-ci débutent souvent par un pâlissement du limbe évoluant en une coloration brunâtre. La présence de minuscules ponctuations noires, les pycnides, permet de distinguer "Septoria tritici".

Le symptôme typique de "Septoria nodorum" est la présence sur les feuilles de taches brun clair nécrosées au centre en losange et bordées d'une chlorose ou d'un jaunissement. "Septoria nodorum" peut aussi provoquer des symptômes sur les gaines ou les épis (nécrose brune) et contaminer les semences.

La septoriose attaque principalement le blé de la germination à la maturité. On peut obtenir une réduction de rendement allant jusqu'à 45 % lorsque l'épi est attaqué, et 55 % lorsque la partie foliaire d'une plante est touchée dans son ensemble (dernière feuille : 35 %, avant dernière feuille : 10 %, troisième feuille : 10 %).

La principale forme d'hibernation est celle se passant sur des restes de plantes et sur les plantules du froment d'hiver. Avec les hivers doux, il peut y avoir multiplication et propagation. Le champignon se manifeste de façon massive après un printemps humide, combiné à 15 jours de temps humide au moment de l'épiaison. La propagation des spores se fait au moyen des éclaboussures de pluie et du frottement des feuilles les unes contre les autres. Des gouttelettes contenant des spores peuvent être disséminées par le vent. L'infection peut également être dispersée via la paille et les semences contaminées.
Une forte humidité pendant une à quatre heures (selon la température) suffit pour assurer l'infection. En revanche, de trop fortes pluies lessivent les spores. "Septoria tritici" se développe à des températures plus froides que "Septoria nodorum". Les souches de septorioses varient dans leur pouvoir pathogène.

Le risque de contamination peut être réduit en gardant une large rotation de cultures, en enfouissant profondément les restes végétaux et en ne laissant aucune chance de développement aux repousses et aux adventices. Un semis peu profond diminue également le risque d'infection. Les régulateurs de croissance doivent être utilisés de sorte que le raccourcissement des tiges soit minime. Il augmente en effet le risque d'attaque. La fumure azotée doit de préférence être fractionnée. L'important est que les deux feuilles supérieures soient préservées de l'infection.

En raison d'une phase d'incubation relativement longue (15 à 21 jours), il est très difficile de lutter en préventif strict contre ces agents pathogènes, à moins de faire appel aux outils de diagnostic, tels que les tests sérologiques ou moléculaires.
Le diagnostic visuel est très difficile au stade 8-9, et au-delà de ce stade des confusions sont possibles avec d'autres maladies.

À l'heure actuelle, la lutte chimique est le seul moyen permettant de lutter efficacement contre cette maladie, car elle seule semble permettre de stopper l'extension des épidémies. Les deux agents de la septoriose ont une sensibilité différente aux fongicides. Un traitement dès la montaison permet de limiter les attaques foliaires et de retarder les risques avant le traitement d'épiaison. En raison de la durée d'incubation très longue du champignon et des cycles d'infection successifs qui se superposent au cours d'une campagne, la stratégie fongicide visera à enrayer la poursuite d'une épidémie (effet curatif) tout en empêchant la contamination des nouveaux étages foliaires (effet préventif).
Dans le cadre de lutte fongicide, cela consiste à pratiquer un suivi des populations pathogènes, en fonction de leur sensibilité et de leur résistance à un fongicide donné

Seuil d'intervention : 15 % de symptômes sur la (F3). Dans des itinéraires de protection intégrée, le passage de fongicide est reculé jusqu'au stade « dernière feuille étalée » ce qui permet de protéger les deux dernières feuilles, essentielles pour le rendement. Dans ce cas, on utilise souvent une Triazole à 1/2 ou 1/3 de dose en fonction de la pression de la maladie et de la météo à venir.

Par ailleurs, la protection fongicide est un poste d'investissement important, il mérite donc d'être raisonné. Outre la connaissance des produits proposés sur le marché, et le temps passé à l'observation des parcelles, la protection fongicide nécessite la prise en compte de plusieurs paramètres : région, variété, conditions agronomiques de la parcelle et climat de l'année. Les fongicides doivent impérativement être bien positionnés, afin de bénéficier de la meilleure persistance d'action.

Dans la définition d'une stratégie fongicide, la prise en compte de la sensibilité de chaque variété est nécessaire. L'apparition sur le marché de variétés moins sensibles, voire tolérantes, permet une plus grande souplesse dans les programmes de protection, sans toutefois supprimer leur nécessité.

L'utilisation de modèles de simulation de développement de la maladie permet d'évaluer le risque de développement de la septoriose.

Liste des produits phytopharmaceutiques autorisés en France pour lutter contre la septoriose du blé : E-Phy




</doc>
<doc id="2800" url="https://fr.wikipedia.org/wiki?curid=2800" title="Ska">
Ska

Le ska est un genre musical ayant émergé en Jamaïque à la fin des années 1950. Il se caractérise par un son rythmé et reconnaissable au contretemps marqué par la guitare, les claviers et parfois les cuivres. Il est diffusé internationalement grâce notamment au label Island Records de Chris Blackwell. Laurel Aitken, Toots & The Maytals ou encore Desmond Dekker & The Aces et The Skatalites ont été des pionniers de ce style musical.

Au début des années 1950 en Jamaïque, île dépendant alors du Royaume-Uni, la grande majorité des habitants sont d'origine africaine. La vie y est rude, les noirs n'ont pas le droit de vote, la violence n'est pas rare et la religion est très présente. Les émeutes sont une plaie chronique, et seuls les bakras, riches blancs implantés en Jamaïque, ont une vie plus aisée. Musicalement, plusieurs îles des Antilles font danser le peuple sur différents rythmes : le merengue dominicain, le kompa haïtien, le calypso de Trinité très en vogue, le son cubain, la biguine de Martinique. Le folklore local, le mento jamaïcain, quant à lui, est composé d'influences européennes, bantoues et ouest-africaines. Le rythme 4/4 est doux, contrairement au calypso plus rythmé avec son temps 2/2. Le calypso est surtout joué pour les touristes. Les musiciens locaux jouent aussi du slack, chansons paillardes qui font rire le public pour oublier la dure vie.

Ceux qui possèdent une radio peuvent capter les ondes de Wins, la radio américaine de Miami, la seule qui parvienne en Jamaïque ; on y passe principalement du rhythm and blues et du jazz ; ces musiques ont déjà déferlé sur l'île avec les disques qu'ont amenés les soldats américains basés à Kingston durant la Seconde Guerre mondiale. Les jazzmen noirs américains ont alors représenté une lueur d'espoir pour les Jamaïcains des ghettos qui se sont mis à jouer tous les soirs, en plein air dans les parcs de Kingston, les chansons qu'ils essayaient de reproduire, mêlées inévitablement aux rythmes qu'ils savaient déjà jouer (mento, calypso, merengue…), produisant leur propre rhythm and blues, le Jamaican boogie ou Jamaican R&B. Un son nouveau prend forme, avec une basse plus puissante et un rythme de guitare syncopé et plus rapide, comme un avant-goût du ska : le shuffle.

En 1950, les disques 45 tours en vinyle et les sonos apparaissent, faisant naître des "sound systems" dans lesquels on peut danser à bas prix un peu partout dans l'île. La concurrence devient sauvage : les "selecters" sont obligés d'enlever les étiquettes de leurs disques pour être les seuls à les posséder. Une année plus tard, Stanley Motta réalise les premiers enregistrements pour concurrencer le calypso, mais l'île attend un nouveau son, plus branché et plus dansant que le R&B américain.

La déferlante rock n' roll s'abat sur l'île avec notamment Fats Domino et Little Richard ; ce nouveau style mêlé au boogie-woogie, au gospel, très présent dans l'île, au mento local, au jazz, au scat, au calypso, au merengue, aux musiques africaine et cubaine ainsi qu'à la culture de la rue formera un cocktail détonnant qui, en explosant, donne naissance au son que tous les Jamaïcains attendaient : le ska. Le succès est au rendez-vous : les "sound systems" se multiplient dans l'île, les gens se pressent pour venir danser sur ce rythme endiablé. En 1955, Duke Vin crée le premier sound system jamaïcain à Londres, ville où les émigrés affluent à la recherche de travail. En 1959, Chris Blackwell enregistre des dubplates qu'il teste dans les "sound systems" avant de faire presser ceux qui ont bien marché. Les juke-boxes se répandent, aidant en cela à la diffusion de la musique. C'est la naissance de l'industrie musicale jamaïcaine. En 40 ans, l'île produira plus de disques, avec parfois plus de 200 singles par semaine. La musique étant le meilleur moyen pour se sortir de la misère, il faut produire, toujours produire, car les enregistrements ne sont pas biens payés et les producteurs pas toujours honnêtes. Il faut donc jouer le plus possible pour gagner sa vie, d'où cette extraordinaire production.

Aux États-Unis, les mouvements noirs sont très actifs à la fin des années 1950 afin de mettre fin à la ségrégation raciale qui existe encore dans les États du Sud. Au fil du temps, la syncope du boogie basé sur le contretemps s'accentue au point de devenir le temps fort du rythme. Le ska se dégage peu à peu des différents styles, caractérisé par ce rythme syncopé marqué par un temps fort sur les deuxième et quatrième temps de la mesure. Le jeu de guitare correspond au contretemps du R&B et au piano du boogie. Les cuivres sont ajoutés pour les solos de jazz, ainsi qu'une contrebasse très en avant, comme pour le merengue, le calypso et le mento. Souvent, les morceaux joués sont instrumentaux, frénétiques et soutenus. En 1960, le ska se distingue et devient un genre à part entière. Aussi, certains affirment que le mot « "ska" » est né du son que produit la façon sèche de plaquer des accords sur la guitare, d'autres affirment que ce mot est la déclinaison du mot "skavoovee", crié par un pianiste qui a participé à l'émergence du genre.

Prince Buster, décidant de se démarquer des sounds spécialisés dans le R&B, préfère accentuer l'identité purement jamaïcaine de sa musique, tout comme Coxsone. En 1961, les succès, les soundsystems et les producteurs se multiplient, beaucoup se délocalisent au Royaume-Uni. Un an plus tard, Chris Blackwell a l'idée d'y distribuer des disques, où les émigrés peuvent se permettre d'en acheter. 1962 est aussi l'année de l'indépendance de la Jamaïque liée jusqu'alors au Royaume-Uni. C'est l'indépendance non seulement territoriale, mais aussi musicale, car le ska incarne maintenant l'identité de la nouvelle nation qui ne cesse de danser au rythme des cuivres, l'espoir et l'optimisme sont retrouvés. Coxsone construit un studio d'enregistrement indépendant qui deviendra le mythique Studio One. De 1962 à 1967, la marque britannique Blue Beat d'Emile Shalett publie 600 45 tours produits en Jamaïque par Prince Buster : le ska sera souvent associé, au Royaume-Uni, au nom « "blue beat" », qui désigne donc une marque et non pas cette musique. Les disques sont le plus souvent pressés dans les usines américaines « Federal Records ».

En 1964, c'est l'explosion avec le premier hit international "" de Millie Small sur le label Island Records de Blackwell. Tournant décisif aussi, la formation des Skatalites ; s'ensuivront des dizaines de reprises des vieilles chansons R&B version ska. La machine ska est désormais lancée et dévaste tout sur son passage. Les rude boys, jeunes voyous jamaïquains des ghettos tombés dans la délinquance et semant la terreur, adoptent un nouveau look caractéristique : treillis militaires, pantalons pattes d'éph, T-shirts décolorés, badges, cheveux longs… En 1965, Duke Reid monte son studio d'enregistrement ; Martin Luther King, pasteur pacifiste, est accueilli à Kingston en grande pompe, ce qui redonne espoir aux habitants, mais n'empêche pas la misère et la violence de s'accroître. Les musiciens appellent souvent, dans leurs lyrics, les rude boys à se calmer et à s'assagir en arrêtant de semer la terreur à tous les coins de rue. La musique devient le seul moyen de se sortir du ghetto. Cette violence et cette hargne se ressentent dans le rythme de plus en plus frénétique du ska, qui redevient soudainement très lent, annonçant ainsi les prémices du rocksteady. On raconte que le rythme s'est mis à ralentir à cause des vagues de chaleur de l'été 1964, les danseurs ne pouvant plus soutenir le rythme effréné de cette musique.

Le ska est peu à peu supplanté par le rocksteady, jusqu'à ce que ce dernier soit considéré à partir de 1966 comme la soul locale. Prince Buster multiplie les classiques, notamment un duo avec Lee Perry, Judge Dread (un musicien britannique, Alex Hughes, empruntera son nom, et chantera "Je t'aime moi non plus", de Gainsbourg). Au Royaume-Uni, Chris Blackwell fonde la maison de disques Trojan, spécialisée en musique jamaïcaine. Au-delà de son rythme plus lent que le ska, le rocksteady offre plus de clavier et plus de chant, mais moins de cuivres et d'instrumentaux. La contrebasse est souvent remplacée par la basse électrique. Cette fois, le temps fort marqué sur le troisième temps. On trouve surtout des trios de rocksteady chantant des chansons d'amour. Le chanteur est bien mis en avant, le musicien est confiné dans les studios et le producteur supervise tout de A à Z.

En 1969, tandis que les dancehalls vibrent au son du rocksteady, Desmond Dekker chante son « "Israelites" » sur un rythme innovant, plus rapide que le rocksteady, le reggae. Plusieurs autres artistes revendiquent le titre de premier reggae comme notamment Stranger Cole et Lester Sterling, Larry et Alvin, Bob Marley, the Beltones, the Maytals, et Lee « Scratch » Perry. De 1969 à 1970, le reggae est qualifié de , prédominé par la basse et joué sur un tempo plus rapide, dû aux influences du mento local encore très rythmé. Pour une croche jouée en rocksteady, un musicien reggae en joue deux. Pour l'anecdote, le reggae s'appelait à ses débuts le , ce qui désignait une fille facile, qui s'offre à tous les hommes. Ce titre a paru trop péjoratif au goût des radios de l'époque, et le streggae est devenu le reggae ; le slack toujours présent rappelle tout de même ce côté machiste de la musique jamaïcaine. Puis le rythme évolue encore, devenant plus lent, au tempo medium, appelé le "reggae one-drop" entre 1970 et 1972.

En Jamaïque, comme à la fin des années 1950, le peuple réclame des nouveautés et des innovations musicales. Les artistes remixent alors les morceaux destinés aux dancehalls, il s'agit du dub, nouvelle dimension de la musique jamaïcaine. Les versions purement instrumentales sont gravées en face B du 45 tours ; des effets d'écho (reverb) sont ajoutés sur les voix. En live, les DJ n'hésitent pas à prendre le micro pour se laisser aller à leur délire musical : ils . Dans le Royaume-Uni de la fin des années 1960, en particulier grâce au label Trojan Records qui publie alors la majeure partie des disques de reggae, les skinheads, jeunes des banlieues ouvrières de Londres descendant des Mods, raffolent particulièrement de ce nouveau rythme. De là naîtra le skinhead reggae. Les skins ne sont pas tous d'extrême droite comme la majeure partie des gens le pensent aujourd'hui : ils cohabitent alors pacifiquement avec leurs cousins les rude boys noirs immigrés de Jamaïque et partagent le même goût pour les vêtements chics et les musiques jamaïquaines et noires américaines. Ce n'est qu'avec la crise de la fin des années 1970, que des mouvements d'extrême-droite, British National Front en tête convaincront certains de renier leur amitié pour rejoindre le camp adverse. Ceux-ci se mettent à agresser des immigrés pakistanais, comportement appelé le « "paki bashing" » (lynchage de Pakistanais, qui fût aussi pratiqué par une partie des premiers skinheads). C'est le début d'une longue haine raciale, suscitant le besoin pour nombre de skins de se démarquer de celle-ci. Ainsi naîtra aux États-Unis puis en Angleterre sous l'impulsion de Roddy Moreno le mouvement S.H.A.R.P ("SkinHead Against Racial Prejudice" = Skinheads contre les préjugés raciaux). Ces skinheads antiracistes, las d'être confondus avec leurs frères ennemis, les skinheads d'extrême droite, décident de les surnommer les « boneheads » (tête d'os). Pour un non-initié, il est un moyen simple de savoir si un skinhead est apolitique, SHARP, red ou nazi : les badges qu'il portera.

Les skinheads sont reconnaissables à leur look : tête tondue, chemises ou t-shirts, Doc Martens aux pieds, souvent des bretelles tenant leur jean ou leur sta-prest. Ils ont comme musique emblématique le reggae, mais aussi le ska, le rocksteady et la soul, si possible avec des tempos rapides sur lesquels ils dansent jusqu'à épuisement dans les soirées. En 1971, ils commencent à se désintéresser un peu de cette musique dont le tempo se ralentit avec l'arrivée des thématiques rastas dans les morceaux. L'année suivante, 1972, apparaît comme décisive pour la Jamaïque ; le dub s'affine en séparant les pistes de basse, de batterie, de voix et des autres instruments, en réalisant des mixages plus créatifs et aussi plus complexes, annonçant la fatale arrivée de la musique technoïde quelques années plus tard. C'est aussi en 1972 que le reggae entre dans sa troisième phase d'évolution : après le early reggae et le one-drop, un nouveau rythme apparaît, au tempo encore plus lent que pendant la deuxième phase, mais plus rapide que le rocksteady, avec une basse qui s'alourdit encore plus. C'est le reggae moderne qui intéressera de plus en plus les premiers groupes punk rock du Royaume-Uni, notamment les Clash à partir de 1976, qui le mêleront souvent à leur répertoire. Parallèlement, le pays doit encaisser deux nouveaux coups durs : le dollar s'effondre, l'élite intellectuelle s'exile aux États-Unis laissant l'île sans capitaux, les violences dues aux élections approchantes se multiplient. Les messages véhiculés par la musique reflètent alors bien un fort espoir de sortir de la misère et de l'oppression omniprésentes.

En 1974 à la suite de la vague d'émigration aux États-Unis, la forte communauté de Jamaïcains installés à Brooklyn introduisent la culture des dancehalls. Mêlées au funk local, le dub donne vite une mixture ressemblant au rap et au hip-hop. Deux ans plus tard, en 1976, Bob Marley devient une superstar avec ses Wailers, après des années de galères et une collaboration avec Blackwell sur le label Island en 1974, qui l'a fait connaître du grand public. Les jamaïcains délaissent les DJ, préférant leur nouvelle idole. C'est l'âge d'or du reggae, tant du point de vue de la qualité que de la quantité et de l'innovation. Grande nouveauté, le reggae jusque-là très machiste se féminise et introduit aussi des sujets comme l'Afrique. La musique jamaïcaine s'exporte alors dans le monde entier.

Les années 1960 qui enfantent du ska Jamaïcain refilent le bébé au Royaume-Uni des années 1980 où tout se joue désormais. En 1979, le ska revient au goût du jour grâce au fondateur des Specials Jerry Dammers et son label britannique 2 Tone (avec les têtes de file The Specials, Madness, The Beat, The Selecter, Bad Manners…) qui réhabilite les esthétiques rude boy, mod et skinhead des années 1960, et met son logo à la mode en Angleterre et bientôt dans le monde entier : le damier noir et blanc, symbole d'unité entre les noirs et les blancs. Symbole aussi d'un désir de mettre fin à la haine raciale qui règne depuis des années dans le pays. Les groupes de musiciens ethniquement mixtes essaient de prôner l'unité raciale dans le Royaume-Uni déchirée avec des paroles plus engagées, mais ne peuvent empêcher les émeutes de 1981, à cause des difficultés des ghettos, des attaques fascistes, du chômage, des contrôles policiers, des émeutes raciales, du front national à son apogée, de la communautarisation des immigrés etc. Un pays en profonde crise.

En 1981 toujours, autre choc : Marley meurt le 11 mai. Les Blancs britanniques s'empresseront de jouer eux aussi du reggae, comme UB40, Boy George et Culture Club, ce qui n'est pas du goût de Chris Blackwell qui le prend comme un manque de respect à Bob Marley. Il abandonne le créneau de la musique jamaïcaine. Le continent africain se met au reggae, avec comme précurseur Alpha Blondy. En 1985, les rythmiques numériques envahissent le son reggae et virent ragga. Le dub teinté de numérique influence à l'extrême de nombreux artistes, ce qui produit inévitablement de la house music, de la techno. La jungle apparaîtra même en 1994, jouée par des descendants jamaïcains qui accélèrent le rythme du reggae en lui ajoutant des sons numériques et d'autres éléments.

Le label Two-Tone, racheté par Chrysalis Records, s'effondre en 1985, ce qui n'empêche pas au damier de rester le symbole du ska à travers le monde. Après le raz-de-marée 2 tone, Gaz Mayall relance le ska en 1986 avec son label : Gaz Records. D'autres labels apparaissent: Ska records, Moon records aux États-Unis, Skank et Unicorn en Grande-Bretagne, Pork Pie en Allemagne notamment, avec des groupes tels que les Deltones, Potato 5, et Trojans (le groupe de Gaz Mayall). Les concerts et les festivals de ska se multiplient, c'est l'époque cruciale du ska revival qui perdure bon an mal an jusqu'à aujourd'hui. Une date à retenir tout de même: 1989, c'est l'explosion du revival avec trois grands courants distincts : le courant allemand, une des scènes les plus productives encore actuellement, avec des groupes comme the Busters, Skaos, The Braces, No Sports, El Bosso und Die Ping Pongs… Un mélange de revival et de 2 Tone au rythme très soutenu et très rapide, avec 4 ou 5 cuivres par groupe. Vient ensuite le courant américain, avec certains groupes toujours présents comme The Toasters, Mighty Mighty Bosstones, Bim Skala Bim, Voodoo Glow Skulls… une scène fusion, caractérisée par un mélange détonnant de 2-tone, de hardcore, de funk et de punk, ce qui donne souvent un ska punk pêchu. Enfin, le courant international qui désire rester proche des racines jamaïcaines des années 1960 : les californiens de the Liquidators puis Jump With Joey et Hepcat ; the Trojans, Skaville Train, The Cosmics et 100 Men en Angleterre ; Dr. Ring Ding and the Senior Allstars en Allemagne ; Tokyo Ska Paradise Orchestra et Ska Flames au Japon, Les Frelons , Tchicky-Monky et La Marabunta en France.

Le ska revival est aussi appelé le (en français, ), les américains opérant cependant une dichotomie entre et pour distinguer l'approche rock/2-Tone de l'approche sixties.

Les labels notables du genre incluent : Trojan Records
, Crash Disques
, Epitaph Records
, Fat Wreck Chords
, Grover
, Small Axe
, Stomp Records
, Studio 1
, Blue Beat
, Two-Tone.



</doc>
<doc id="2803" url="https://fr.wikipedia.org/wiki?curid=2803" title="Sokaris">
Sokaris

Sokaris est, dans la mythologie égyptienne, la déification de l'acte de séparer le bâ du ka, ce qui correspond à peu près à la séparation de l'âme du corps après la mort. Cette opération est rendue possible par le rituel de l'« Ouverture de la bouche », c'est pourquoi le nom de Sokaris signifie "qui nettoie la bouche".

Le bâ, plus ou moins équivalent à l'âme, est représenté par un oiseau à tête d'homme survolant le ka, qu'on peut assimiler au corps nouvellement momifié, l'enveloppe vide du corps. C'est pourquoi Sokaris est représenté par un humain momifié à la tête de faucon, à la peau verte, symbole de renaissance. Le bâ est traditionnellement représenté donnant à Sokaris le titre de « Grand Seigneur aux Deux Ailes ». On plaçait souvent une statue de Sokaris dans les tombes, sur laquelle figurait le "Livre des Morts", participant à la bonne séparation puis libération du bâ.

Sokaris était de la nécropole de Memphis, ainsi connu comme « Celui qui est sur le sable » ; la nécropole prit ensuite le nom de Saqqarah. Il existait un festival à sa gloire à Thèbes, nommé le festival de Henou, pendant lequel une image de Sokaris était transportée dans une barque Henou, représentant le passage en bateau contenant le défunt sur les champs d'Ialou.

Son nom peut également être décomposé en "Celui qui est adoré", c'est pourquoi Sokaris est progressivement devenu le dieu des joailliers, des armuriers et autres forgerons. Ainsi, pendant le Moyen empire, lorsque Ptah devint le dieu des artisans et un dieu de la réincarnation, Sokaris, qui était déjà le dieu d'une classe d'artisans et le dieu à l'origine du processus de réincarnation, devint assimilé à Ptah. Finalement, l'identité de Sokaris fut mélangé à celle de Ptah pour devenir Ptah-Sokar. Au début du Nouvel Empire, Ptah-Sokar, en tant que dieu funéraire, fut assimilé à la divinité mortuaire plus importante Osiris, devenant Ptah-Sokar-Osiris.

On trouve parfois dans les textes une déesse Sokaret, parèdre féminin de Sokar, qui s'applique à Isis en tant que femme d'Osiris, ou à Hathor, « sœur divine de Sokar ».


</doc>
<doc id="2805" url="https://fr.wikipedia.org/wiki?curid=2805" title="Sobek">
Sobek

Sobek, en grec : Suchos ou Sucos (σοũχος ou Σοũχος) « Crocodile », est le fils de la déesse aquatique Neith et des dieux jumeaux Senwy (= les deux frères). Son statut de dieu de l’eau et de la fertilité le fait adorer partout dans le delta du Nil, le Fayoum et à Kôm Ombo.

Dans le temple de Kôm Ombo, il est adoré sur un pied d'égalité avec Haroëris, Horus l'Aîné (le temple de Sobek et Haroëris, avec deux dieux principaux, présente un fait unique en Égypte). Il y a Hathor pour parèdre, mais selon les temples, il peut avoir telle ou telle autre déesse pour compagne (Rénénouet à Médinet el Fayoum, par exemple). Dans les temples qui lui sont consacrés dans le Fayoum, il est couramment désigné comme "Sobek, Seigneur de "tel " sanctuaire". À Soknopaiou Nésos (site archéologique au nord du lac du Fayoum), il est "Sobek, Seigneur du Lac" : "So(b)k-Neb-Payou(m)", ce qui donne Soknepaiou en démotique et en grec ; à Tebtynis, à côté du village actuel de Tell Oumm el-Baragat, dans le sud-est du Fayoum, il est adoré sous l'intitulé "Sobek, Seigneur de (Teb)tynis", soit "So(b)k-Neb-Tynis", d'où les noms démotique et grec de Soknebtynis.

La présence de crocodiles dans le Nil était pour les Égyptiens l’annonce d'une crue favorable aux récoltes : les crocodiles étaient donc des animaux sacrés à cette époque. Maître des eaux, il est le dieu qui irrigue les champs.

Vers la Basse époque, les Égyptiens cherchent à gagner ses faveurs afin d’en avoir moins peur en lui offrant des figurines représentant l’animal portant le disque solaire orné du cobra protecteur. Il deviendra rapidement un dieu important dans le panthéon sous la forme syncrétique de Sobek-Rê.

Il est parfois représenté sur la barque solaire en train de terrasser le serpent géant Apophis, personnification du chaos, monstre essayant d'engloutir le Soleil. Ce rôle de protecteur de la barque solaire est aussi attribué à la déesse Sekhmet ou bien encore au dieu Seth. Il est localement considéré comme un dieu primordial.

Selon l"'Interpretatio graeca", Sobek est assimilé à Chronos, l'un des dieux grecs primordiaux et le dieu du temps. L'origine et les raisons de cette assimilation sont encore en débat chez les Historiens des religions.

Les noms d'Égyptiens composés à partir du nom Sobek sont légion. Dès la avec la reine Sobeknéferourê ("Sobek est la perfection de Rê"), puis lors de la deuxième période intermédiaire (), plusieurs rois prendront le nom ("Sobek est satisfait") dans leur titulature. Lors de la deux souverains se nommèrent Sobekemsaf ("Sobek est sa protection"), ainsi qu'une princesse, plus curieusement car c'est un nom masculin.

De nombreux Égyptiens des époques tardives (grecque et romaine) portent des noms tels que Sisoukhos, Marsisoukhos, Pétésoukhos, ou encore Khroniôn.


</doc>
<doc id="2806" url="https://fr.wikipedia.org/wiki?curid=2806" title="Sia (mythologie)">
Sia (mythologie)

Dans la mythologie égyptienne, Sia est la personnification de l'intuition qui aide à prendre les bonnes décisions. C'est l'incarnation de l'omniscience intuitive des dieux, que seul le démiurge possède. Avec Hou et Heka, il permet à celui-ci d'imaginer, d'énoncer et d'ordonner la création.


</doc>
<doc id="2808" url="https://fr.wikipedia.org/wiki?curid=2808" title="Sekhmet">
Sekhmet

Sekhmet "la puissante" est une déesse de la mythologie égyptienne. Elle est représentée par une femme à tête de lionne portant d'abord l'uraeus, puis, par la suite, le disque solaire ; de sa bouche de lionne sortent les vents du désert.

Les textes égyptiens la présentent comme la fille du dieu Soleil, Rê, incarnant l’œil de ce dernier. Déesse guerrière, elle se bat seule ou bien accompagnée de son armée de génies porteurs de flèches et de couteaux.

Déesse guerrière personnifiant la puissance destructrice du Soleil, elle est l'instrument de la vengeance de Rê. Elle aurait été spécialement créée par lui pour réprimer les hommes révoltés contre lui, comme l'indique le Livre de la vache du ciel, dont le texte est gravé sur les parois de plusieurs tombeaux de la Vallée des rois. Son corps brûlant et ses flèches incandescentes détruisent les ennemis du roi, déchaînant la fureur de Rê sur les avatars d'Isfet et les ennemis du pharaon. Elle était celle qui conseillait et guidait les pharaons au combat. Mais, épouse de Ptah et mère de Néfertoum dans la triade memphite, elle est aussi, dans ce rôle maternel, la déesse de la guérison et du foyer.

Elle est surnommée « la puissante », « Celle devant qui le mal tremble », la « colère de Rê » ou « la maîtresse des maladies ».

Elle a également été attestée comme une divinité liée au féminin, gouvernant le domaine des cycles menstruels.

La déesse chatte Bastet s'identifie parfois à Sekhmet. Les prêtres de Sekhmet étaient reconnus comme spécialistes de la médecine vétérinaire.

Elle fut souvent représentée, assise ou debout, avec un corps de femme vêtue d’une longue tunique rouge et une tête de lionne. À partir de la elle acquit également les symboles divins tels que le disque solaire, l'uræus et le sceptre ouas, et le signe de la vie appelé ânkh. Plus rarement elle fut représentée comme une femme à tête de crocodile. Une fête était célébrée en son honneur dans la saison Akhet.

Elle apporte les maladies par ses miasmes (entre autres durant les cinq derniers jours de l'année, avant le retour de l'année nouvelle). Afin d'éviter qu'elle ne tue tous les humains, Rê dut lui faire préparer un breuvage spécial de bière coloré de rouge pour apaiser sa soif de sang dans l'ivresse. De cette façon, elle est remplacée par Hathor, déesse de la fertilité. C'est cette histoire qui était répétée lors d'un festival de l'ancienne Égypte où le zythum était consommé de façon délibérément excessive.

Elle était également célébrée à chaque fin de bataille afin de calmer la fureur et de retrouver la paix, calmant ainsi son incarnation destructrice.

Cependant, l'initié peut gagner ses faveurs à condition de vaincre ses propres peurs ; car malgré sa violence, la déesse a le pouvoir de guérison, ce qui l'a consacrée déesse des médecins.




</doc>
<doc id="2810" url="https://fr.wikipedia.org/wiki?curid=2810" title="Satis">
Satis

Dans la mythologie égyptienne, Satis (ou Sati) est une déesse associée au Nil et à ses cataractes. C'est la fille de Rê, le soleil.

Son nom, qui vient de "setji" (semer, répandre) et signifie « Celle qui répand », la confirme dans la fonction de celle qui répand les eaux que son époux, Khnoum, a fait jaillir.

Si Satis est surtout représentée anthropomorphe, il semblerait que, très anciennement, elle ait été vénérée sous forme d'antilope ou de bubale, dont sa couronne Hedjet pourvue de deux cornes est la réminiscence. De même, l'antilope lui est consacrée, ainsi que le vautour, dont elle se pare parfois. Ses attributs personnels sont, outre le sceptre "ouas" et le signe "ânkh", des flèches, à l'instar de Neith. Cette dernière, avec qui elle partage sa personnalité assez virile, sportive et indépendante, peut être considérée comme son pendant du Nord.

Satis est indéniablement originaire de la du Nil, au niveau d'Éléphantine ou de Sehel, où se trouvaient ses premiers lieux de culte ; elle est généralement considérée comme la gardienne de toutes les cataractes.

Ses lieux de vénération sont multiples, et principalement situés dans le Sud : à Éléphantine, sa ville tutélaire bien sûr, où elle forme une triade avec Khnoum, son parèdre - époux durant la Basse époque - et leur fille Anoukis, en Nubie (Semna, Bouhen, Koumna, Gebel Docha, etc.) où elle est adorée en compagnie d'Amon, de Monthou ou d'Horus de la à la Période romaine, et au Fayoum, là où étaient cachées les sources mythiques du "Nil du Nord", assimilée à Ouadjet et donc porteuse de la couronne rouge Decheret.

C'était près de ses temples qu'étaient célébrées les fêtes religieuses liées à la crue du Nil.

Satis, « "Celle qui donne l'eau fraîche qui vient d'Éléphantine" » et « "La maîtresse de la première cataracte" » est une des déesses les plus importantes du cycle de l'inondation et de la crue, responsable soit de son déclenchement, soit de sa distribution. Sans être symbole de fécondité, elle apportait fertilité et prospérité, ce qui l'a rapprochée de Sothis. Les anciens Égyptiens étant néanmoins parfaitement conscients que l'inondation prenait naissance au cœur de l'Afrique, Satis était vénérée en tant que « "Maîtresse du Grand Sud" », « "Maître de la Nubie" » ou encore « "Maîtresse de Pount" », et protégeait les marchandises et les caravanes venant de ces lointaines contrées.

En outre, son association avec l'eau fait de Satis une déesse de la purification, invoquée en faveur des défunts. Ses fonctions s'étendaient également de déesse protectrice du pays, implantée à la limite méridionale de l'Égypte, lieu de nombreux conflits (« "Gardienne de la frontière sud de l'Égypte" » et, comme le flot tumultueux qui submerge et s'empare du pays, « "Celle qui a conquis l'Égypte" »), jusqu'à déesse guerrière et protectrice de la royauté (« "Celle qui lance ses flèches contre ses ennemis" »), probablement de par sa proximité avec d'autres déesses de l'inondation aux aventures nubiennes, telles que Sekhmet. À partir du Nouvel Empire, Satis porte ainsi le même tire que l'Uræus, celui de "L'Œil de Rê" qui détruit les ennemis du soleil et du pharaon.


</doc>
<doc id="2811" url="https://fr.wikipedia.org/wiki?curid=2811" title="Sarapis">
Sarapis

Sarapis ou Sérapis (en grec ancien / ) est une divinité syncrétique créée à l'époque hellénistique par Ptolémée, premier souverain de la dynastie Lagide, afin de se faire accepter par le monde égyptien. Sarapis rassemble des traits d'Hadès, du dieu-taureau Apis et d'Osiris. Aux côtés d'Isis, il devient au de notre ère, l'une des divinités les plus aimées du panthéon égyptien. Son culte s'étend alors à l'ensemble du bassin méditerranéen.

Le nom de ce dieu est apparu sur un malentendu : le taureau Api (Apis) était une manifestation terrestre du dieu Oser (Osiris). On procédait donc à un culte d'Oser-Api. Mais en grec, « o » est un article, et les prêtres grecs ont donc transformé Oser-Api en « O Serapis », « le » Serapis.

Un des aspects importants de la religion pratiquée à Alexandrie sous les Lagides est le culte de Sarapis. Si Alexandre, en devenant fils d'Ammon, a réussi à asseoir son autorité au sein du clergé égyptien, les Lagides ont eux aussi souhaité associer leur nom à une divinité. Mais pour être accepté par tous, ce dieu devait convenir autant aux Grecs qu'aux Égyptiens. Au tout début du est apparue la figure de Sarapis. On ignore lequel des deux premiers Ptolémée en est à l'origine mais selon une légende rapportée par Plutarque et Tacite, c'est Ptolémée qui l'a institué. Il aurait rêvé d'un dieu qui lui aurait demandé de transporter sa statue jusqu'à Alexandrie. À son réveil, il raconta son rêve et un homme reconnut d'après la description de Ptolémée une statue qu'il avait vue dans la colonie grecque de Sinope (au sud de la mer Noire). Le roi voulut s'emparer de la statue mais les habitants refusèrent et, après trois ans d'attente, il décida de la voler. Une autre version de la légende dit que la statue se serait dirigée toute seule vers le bateau qui devait l'emmener à Alexandrie. À son arrivée à Alexandrie, ce dieu fut assimilé par l'entourage du roi à l'Hadès des Grecs à cause du chien Cerbère représenté lui aussi sur la statue.

Le culte de Sarapis existait déjà avant les Ptolémées sous sa forme égyptienne d'Osiris Apis (en grec "Osorapis") au Sérapéum de Memphis. Ptolémée en a fait une figure mixte, qui regroupait la symbolique égyptienne (en tant que manifestation d'Apis mort, donc de l'Osiris Apis) mais surtout les fonctions des dieux grecs : il reçoit de Zeus son aspect solaire, Hadès le lie à l'au-delà, Dionysos le rapproche de la fertilité agraire et Asclépios lui permet de guérir les malades. Cela deviendra d'ailleurs sa principale fonction. Il prend en plus une apparence « à la Zeus », c’est-à-dire les longs cheveux bouclés et la barbe. Il est souvent représenté avec un "kalathos" sur la tête ou encore trônant avec le Cerbère à trois têtes d'Hadès à ses pieds. Plus tard, il fut apparenté à Isis et Harpocrate, créant ainsi une sorte de triade alexandrine.

Pendant l'époque ptolémaïque, son culte n'a vraiment été pratiqué qu'à Alexandrie et à Memphis mais à l'époque romaine il s'est répandu dans tout le pays. Il a aussi été très populaire en Grèce, en Asie Mineure et même jusqu'à Rome. Preuve de sa popularité : il est représenté sur de nombreuses monnaies provinciales romaines, par exemple au revers de tétradrachmes de Néron, ou encore sur une monnaie émise à Marcianopolis où son portrait apparaît en face à face de celui de l'empereur Gordien.






</doc>
<doc id="2813" url="https://fr.wikipedia.org/wiki?curid=2813" title="Scribe dans l'Égypte antique">
Scribe dans l'Égypte antique

Le scribe (du latin "scriba", de "scribere", écrire) désigne dans l'Égypte antique un fonctionnaire lettré, éduqué dans l’art de l’écriture et de l’arithmétique. Omniprésent comme administrateur, comptable, littérateur ou écrivain public, il fait fonctionner l’État de Pharaon au sein de sa bureaucratie, de son armée ou de ses temples. Le scribe royal domine l’administration centrale. Les scribes supérieurs font partie de la cour de pharaon, ils ne paient pas d’impôts et n’ont pas d’obligations militaires.

Les scribes sont des fonctionnaires recrutés et payés par l'État. Ils interviennent à tous les niveaux de la société, assumant, par délégation du roi, le pouvoir dans tous les domaines : économiques, politiques, militaires et religieux. À partir des textes, on connaît ainsi :

Comme l'enseignement est uniformisé dans les établissements d'enseignement, les scribes peuvent à tout moment passer d'une branche à l'autre.

Au service de la population, en majorité analphabète, ils exercent aussi le métier d'écrivain public, établissant les contrats légaux les plus divers, écrivant les lettres sous la dictée ou les lisant à ceux qui ne peuvent le faire eux-mêmes.

Le monde des scribes étant fortement hiérarchisé, pour chaque catégorie on identifie plusieurs grades : directeurs, instructeurs, inspecteurs, assistants...

Associée initialement à la déesse Seshat (celle qui écrit ; lit. celle qui est un scribe), la profession de scribe passa sous la protection du dieu Thot, au cours des dernières dynasties. D’abord recruté dans l’entourage de la famille de pharaon, le développement de l’administration à la fin de l'Ancien Empire supposa qu’une large caste d’administrateurs soit formée et renouvelée. La position de scribe est héréditaire. Elle se lègue de père en fils mais suppose une bonne transmission des connaissances, en particulier par une sérieuse éducation, dès l’âge de cinq ans et pendant une douzaine d’années, à la grammaire, aux textes classiques, au droit, aux langues, à l’histoire, à la géographie et la comptabilité, enseignements donnés dans une maison de vie, dépendant du temple, lieu tenant tout à fois d’une bibliothèque, où l’on conserve les précieux papyrus et où savants et lettrés se retrouvent, et de centre de formation pour les scribes et les prêtres.
Le scribe maîtrise les différentes formes de caractères écrits : écriture hiéroglyphique, à base de symboles, écriture hiératique, à forme cursive et logographique, écriture démotique, de type logo-syllabique et ancêtre du copte (le hiéroglyphique, le démotique et le grec ancien sont les trois langues de la fameuse pierre de Rosette). Maître de l’écrit et du savoir, le scribe en a les attributs symboliques. Représenté vêtu simplement d’un pagne, le calame (roseau taillé en pointe) à la main, un papyrus ou un ostracon (tesson de poterie) dans l’autre, le scribe exerce une profession respectée, que le texte célèbre dit « de l'enseignement de Khéty » consacre comme l’activité la plus noble et honorable dans la société égyptienne. Il est d’ailleurs remarquable que la représentation de l’unité monétaire la plus élevée du royaume soit le hiéroglyphe du scribe. À l’époque tardive, le babouin est l’animal qui lui est consacré et qui sert à le représenter.

Le scribe dispose pour écrire :

Le savoir et la connaissance, ainsi que le service de l’État, sont vénérés à un tel point que pharaon est considéré lui-même comme le premier des scribes, donc le premier des fonctionnaires de son État ; il se fait représenter en pagne, dans la modeste tenue règlementaire des scribes. D’essence divine, le souverain ne fait que se conformer au dieu Thot, créateur des langues et de l’écriture, scribe et vizir des dieux.

Représenté par un ibis au plumage blanc et noir ou un babouin, Thot capte la lumière de la lune, dont il régit les cycles, ce qui le fait surnommer « le seigneur du temps ». Un texte d'Edfou relate sa naissance :
Au sein de l'océan primordial apparut la terre émergée. Sur celle-ci, les Huit vinrent à l'existence. Ils firent apparaître un lotus d'où sortit Rê, assimilé à Shou. Puis il vint un bouton de lotus d'où émergea une naine, auxiliaire féminin nécessaire, que Rê vit et désira. De leur union naquit Thot qui créa le monde par le Verbe.

Inventeur de l’écriture et du langage, Thot est la « langue d'Atoum » et donc naturellement le patron des scribes. Incarnation de l'intelligence et de la parole, il connaît les formules magiques auxquelles les dieux ne peuvent résister. Selon la légende, celui capable de déchiffrer les formules magiques du Livre de Thot peut espérer surpasser les dieux.

Plusieurs pharaons (Snéfrou, Thoutmôsis, Amenhotep/Akhénaton, Horemheb ou Séthi) ont légués des écrits, en particulier des Enseignements destinés à leurs successeurs, entre autres le grand papyrus Harris rédigé par Ramsès à l’attention de son fils Ramsès.

Parvenu au faîte de son art et de la société, le scribe des Archives royales domine l'administration centrale. Ses compétences sont étendues : il coiffe, contrôle et enregistre les actions de toutes les autres institutions. L'ampleur de sa charge souligne, dès les plus hautes époques, l'importance que l'État accorde à l'écrit, c'est le témoin indispensable de tout ce qui constitue la vie d'un pays dont le gouvernement est fondé sur une connaissance précise des personnes, des biens et des situations.

Sous l'Ancien Empire, le scribe des Archives royales, dont on trouve trace à partir du règne de Néferirkarê Kakaï (), est responsable du département des Documents royaux, également appelé le « Double Laboratoire ». À cette institution se rattachent d'autres services d'archives et de bibliothèques.

Le scribe Khououiou, qui vivait sous la , était à la fois « chargé d'affaires du roi », « scribe des Documents royaux » et « directeur des Scribes ».

Sous la , Djâou, dont on a retrouvé la tombe à Abydos, était « scribe des Rouleaux divins », « directeur des scribes royaux » et « prêtre lecteur ».

Après le pharaon, les scribes sont les personnages les plus représentés dans la statuaire ou la peinture. Des chefs-d’œuvre de l’art égyptien que l’on retrouve au musée du Caire, au musée du Louvre ou au Neues Museum (Berlin), nous ont été légués, montrant l’importance historique et symbolique des scribes dans l’Égypte pharaonique.

Le scribe accroupi a été réalisé durant les et s. C’est à cette époque que l’Ancien Empire est au sommet de sa gloire.

Lors de la , la construction des pyramides, occupant les paysans durant les crues du Nil, seraient alors une nécessité économique et politique ; créant ainsi un État centralisé.

À la , on abandonne les pyramides monumentales pour privilégier des tailles plus modestes. Les arts se développent, les tombes sont de plus en plus complexes, l’architecture se développe dans les temples, les décorations des temples sont mises en avant et retracent toute la vie du défunt et souvent d’un règne.

Le scribe accroupi fut découvert à Saqqarah en 1850. Fait de calcaire, de cristal de roche, de cuivre et de magnésie, ce scribe était certainement un haut fonctionnaire, un personnage important de son époque. Il était placé dans la chapelle de culte d’une tombe, la statue participait aux cérémonies et recevait les offrandes pour le défunt. Sa fonction avait donc un caractère funéraire.

Le scribe est assis et est représenté en train d’écrire sur un rouleau de papyrus, il tient à la main droite un pinceau ou un roseau qui aujourd’hui n'est pas apparent. Il porte un pagne comme seul vêtement, qui est le support de ce rouleau.

Son visage est attentif et son regard est vif ; cette partie du corps est très réaliste, les os du visage ressortent : surtout ses pommettes et ses joues creuses, les yeux présentent beaucoup de détails. Les mains sont sculptées avec un certain souci du détail. Sa posture est un peu hiératique, son attitude est raide. Il présente beaucoup de formes, au niveau du ventre, qui font ressortir son obésité. Sa bonne conservation nous permet de voir la polychromie antique ; l’application des différentes couleurs de la statue.

La sculpture à l’Ancien Empire était caractérisée par une attitude assez hiératique. Les détails sont très développés au niveau du visage ; mais il n’est pas idéalisé, vu son obésité ce qui est assez rare à cette époque. Il est en activité ce qui est rare également. Souci du réalisme, les yeux sont très développés et détaillés.

Presque tout ce que nous connaissons de l’Égypte ancienne a été légué par les scribes, tant sur la vie et les réalisations des pharaons, la construction des grands monuments, la vie des classes populaires ou les événements politiques et militaires. Les scribes du monde juif ancien et moderne (sofer, en Héb. סופר) sont des docteurs de la foi enseignant la loi de Moïse et l’interprétant pour le peuple. L’importance du Verbe dans la foi juive, et par extension dans le christianisme et l’histoire occidentale, à travers la Révélation de la parole divine et le Livre sacré, la Bible, qui la contient, pourrait trouver son origine dans la figure du scribe égyptien et du dieu Thot. Le terme de scribe s’applique, dans l’Europe médiévale, aux officiers des villes, chargés de travaux de rédaction et soumis à l’autorité du chancelier.



</doc>
