<doc id="15721" url="https://fr.wikipedia.org/wiki?curid=15721" title="Nombre irrationnel">
Nombre irrationnel

Un nombre irrationnel est un nombre réel qui n'est pas rationnel, c'est-à-dire qu'il ne peut pas s'écrire sous la forme d'une fraction formula_1, où formula_2 et formula_3 sont deux entiers relatifs (avec formula_3 non nul). Les nombres irrationnels peuvent être caractérisés de manière équivalente comme étant les nombres réels dont le développement décimal n'est pas périodique ou dont le développement en fraction continue est infini.

On distingue, parmi les nombres irrationnels, deux sous-ensembles complémentaires : les nombres algébriques non rationnels et les nombres transcendants. Les nombres algébriques peuvent s'exprimer comme racine d'un polynôme à coefficients rationnels ; cet ensemble dénombrable inclut tous les nombres rationnels, mais aussi certains irrationnels. Les nombres non algébriques, comme et , sont dits transcendants ; ils sont tous irrationnels. Cependant, certains ensembles de nombres irrationnels classiquement étudiés peuvent aussi regrouper à la fois des nombres algébriques et des nombres transcendants ; c'est par exemple le cas des nombres calculables. On conjecture également qu'il existe des nombres normaux algébriques, et on en connait qui sont transcendants.

Les premiers nombres irrationnels découverts sont les racines carrées des entiers qui ne sont pas des carrés parfaits, entre autres , dont l'irrationalité a été établie dans l'Antiquité ; plus généralement les nombres constructibles irrationnels, sous-ensemble des nombres algébriques dans lequel on trouve entre autres le nombre d'or, ont une grande importance historique car ils sont liés aux problèmes de construction à la règle et au compas essentiels à la géométrie de l'époque d'Euclide. 

L'irrationalité de et de ont été établies bien plus tard, au ; ce sont les premiers nombres transcendants dont on a prouvé l'irrationalité. Il a de plus été montré au que presque tous les nombres réels sont irrationnels, et même transcendants. En 2017, on ignore le statut de plusieurs constantes importantes telle que la constante d'Euler-Mascheroni.

Les Śulba-Sūtras, originaires d'Inde et datés d'une période comprise entre 800 et , constituent le plus ancien document connu de l'utilisation de nombres irrationnels. Ils mentionnent, dans le but de construire un autel aux dimensions réglementaires pour un sacrifice, le fait que les longueurs de la diagonale et du côté d'un carré sont incommensurables l'une à l'autre. Les travaux antiques les plus connus concernant les irrationnels ont cependant été produits dans le monde grec.

L'historiographie a longtemps décomposé l'étude de l'irrationalité en trois grandes étapes : la découverte, sans doute par un pythagoricien, d'un cas particulier de grandeurs non commensurables, puis l'établissement de l'irrationalité de quelques exemples analogues et enfin, l'étude systématique de celle-ci, notamment par Euclide. Il n'est cependant pas aisé de reconstituer l'enchaînement précis des différentes phases, car tous les textes de l'époque ne sont pas connus et ceux qui le sont ont fait l'objet de controverses, concernant notamment leur interprétation.

L'une des difficultés de l'étude des textes antiques traitant d'irrationalité réside dans le fait que les termes employés pour ce faire ainsi que leur sens varient selon les époques, et que certains peuvent apparaître conjointement dans un même texte. En grec ancien, le concept d'irrationalité peut ainsi être représenté par les mots suivants : 

De tous ces termes, seul n'apparaît pas dans le livre X des "Éléments" d'Euclide. En revanche, le mot (qui d'un point de vue strictement lexical est le contraire du mot ) est employé comme le contraire du mot signifiant "irrationnel" ; sa définition inclut cependant le concept ("commensurable en carré") : le nombre serait donc « rationnel » selon cette définition, ce qui n'est pas le cas dans des textes plus anciens comme ceux de Platon. Il y a donc eu un glissement de sens entre les époques des deux auteurs, et la notion moderne d'irrationalité ne se superpose pas parfaitement à celle d'Euclide. De plus, il n'existe pas pour les Grecs de nombre irrationnel, mais des couples de grandeurs telles que la première n'est pas un multiple rationnel de la seconde.

La compréhension des textes est rendue difficile également par l'utilisation de termes techniques traduisant des concepts n'ayant pas d'équivalent dans les langues actuelles. Par exemple, le nom signifie « puissance » dans la langue courante, mais cette acception n'a pas de sens dans les textes mathématiques antiques. Il a souvent été traduit par « racine carrée » en raison du contexte dans lequel il est employé. Cependant, son sens véritable, probablement emprunté à la finance où il exprime la valeur d'une monnaie, est plutôt la désignation d'un carré dont l'aire est égale à celle d'une surface déjà identifiée ; ainsi, le d'un rectangle de longueur et de largeur est un carré d'aire . Ce terme, attesté dès l'époque d'Hippocrate de Chios, a généré de nombreux contresens dans l'interprétation de plusieurs textes, dont le "Théétète" de Platon.

La date à laquelle la notion d'irrationalité a été découverte par les Grecs n'est pas connue avec certitude : elle est généralement située entre le début du et le premier quart du . Elle est en tout cas antérieure au livre de Démocrite "des Nombres irrationnels et des Solides", qui date de cette période.

Contrairement à une idée reçue, rien n'indique avec certitude que la découverte de l'incommensurabilité provienne de l'étude de la diagonale et de l'un des côtés d'un carré, propriété équivalente à l'irrationalité de . La découverte est parfois attribuée au mathématicien Hippase de Métaponte pour ses travaux sur la section d'extrême et de moyenne raison, maintenant appelée nombre d'or, qui est également le rapport de la longueur de la diagonale d'un pentagone régulier sur celle d'un de ses cotés. Il est également possible que la notion d'irrationalité ait été mise à jour par l'étude du problème arithmétique de la recherche d'un entier qui soit à la fois un carré parfait et le double d'un autre carré parfait ; l'insolubilité de ce problème est en effet équivalente à l'irrationalité de . Si la découverte en elle-même reste entourée de mystère, l'exemple le plus connu chez les intellectuels de l'époque de Platon est celui de l'incommensurabilité de la diagonale et du côté d'un carré.

La nature exacte des premières grandeurs non commensurables découvertes n'est pas connue, et la manière dont cette non-commensurabilité a été établie ne l'est pas plus et plusieurs 
idées de démonstration ont été imaginées. L'une d'elle repose sur le principe du pair et de l'impair, elle est notamment citée par Aristote. D'autres reconstitutions des preuves antiques sont envisagées : certaines ont recours à une descente infinie, d'autres à un algorithme qu'en termes modernes on apparenterait aux fractions continues. Cette dernière technique serait héritée des cultures de Mésopotamie.

Suite à la découverte d'un cas particulier d'irrationalité, il y a longtemps eu consensus pour affirmer que l'étude des grandeurs incommensurables s'était poursuivie par l'établissement par Théodore de Cyrène d'autres exemples se ramenant aux nombres (pour entier non carré compris entre et ). Cette supposition a donné lieu à des recherches concernant la méthode utilisée pour ce faire, et les raisons qui ont empêché Théodore de Cyrène d'aller plus loin que ; il est cependant probable qu'elle soit erronée. En effet, elle résulte d'un passage du "Théétète", mais le texte de Platon ne mentionne pas de démonstration et n'indique donc pas que Théodore en aurait produit une.

Il est difficile, en l'état actuel des connaissances, de proposer une chronologie précise des débuts de l'étude grecque de l'incommensurabilité. Le livre X des "Éléments", écrit vers -300, présente une classification des grandeurs irrationnelles ; on ne sait cependant pas de quand datent les propositions qui y sont démontrées, les textes mathématiques antérieurs étant perdus.

Par la suite, les mathématiciens grecs ont développé des méthodes d'évaluation de grandeurs incommensurables. Archimède a notamment utilisé la méthode d'exhaustion pour donner une estimation de et Héron d'Alexandrie expose une méthode pour évaluer une racine carrée.

Une légende, plusieurs fois rapportée, indique qu'un pythagoricien, parfois nommé Hippase, périt noyé pour avoir révélé aux profanes l'incommensurabilité. Cette légende indiquerait que la découverte serait bien pythagoricienne et qu'elle aurait fait l'objet d'un tabou ; elle est souvent citée pour accréditer la thèse selon laquelle l'irrationalité aurait posé un problème fondamental aux mathématiciens antiques.

L'existence d'une crise profonde chez les mathématiciens et les philosophes grecs due à la découverte de l'irrationalité a été longtemps admise par les historiens, et ce dès les travaux de Paul Tannery en 1887, et plus encore dans les premières décennies du . D'autres historiens ont par la suite émis l'hypothèse que la crise engendrée par les irrationnels était plutôt une reconstruction "a posteriori" par laquelle les mathématiciens du auraient calqué leur crise des fondements sur l'Antiquité, en jugeant les travaux mathématiques grecs à l'aune de concepts mathématiques modernes. Des recherches menées dans la seconde moitié du ont ainsi battu en brèche le concept de .

Le Moyen Âge voit le développement de l'algèbre au sein des mathématiques arabes, ce qui permet aux nombres irrationnels de devenir des objets de même nature algébrique que les entiers et les nombres rationnels.
Les mathématiciens du monde arabo-musulman cessent en effet, contrairement à ceux du monde grec qui les ont précédés, de ne manipuler des grandeurs géométriques que par leurs rapports. 
Dans son commentaire du livre X des "Éléments", le mathématicien persan Al-Mahani étudie et classifie les irrationnels quadratiques et cubiques, en les considérant comme des nombres à part entière bien qu'il utilise également un point de vue géométrique pour les désigner.
Il donne en outre une approche algébrique des irrationnels, en expliquant que si l'on additionne ou multiplie un rationnel et un irrationnel, le résultat est irrationnel.

Le mathématicien égyptien Abū Kāmil Shujā ibn Aslam est le premier à accepter qu'un nombre irrationnel représenté par une racine carrée, cubique ou Racine "n"-ième puisse être solution d'une équation quadratique ou qu'il soit un coefficient d'une équation.

Les mathématiciens arabes ont aussi repris et perfectionné des méthodes d'approximation numérique ; les décimales de sont par exemple trouvées par Al-Kashi grâce à des méthodes géométriques.

Au , la communauté mathématique accueille les fractions. Au , les mathématiciens emploient de plus en plus fréquemment les fractions décimales et représentent déjà ces nombres avec la notation moderne. La notation décimale permet des calculs numériques sur les nombres irrationnels. Pourtant bien que ceux-ci soient utilisés couramment, le débat sur leur nature n'est pas tranché. Simon Stevin et Isaac Newton considèrent que les irrationnels, appelés à l'époque , sont des nombres au même titre que les entiers et les rationnels tandis que d'autres comme Blaise Pascal conservent le cadre fournit par les "Éléments" d'Euclide, dans lequel les irrationnels ne sont pas des nombres. Dans l"'Encyclopédie", D'Alembert rend compte des deux positions et prend parti pour l'idée selon laquelle les irrationnels ne sont pas des nombres, mais qu'ils sont approchables par ceux-ci avec une précision aussi fine que l'on veut. Abraham Kästner propose par la suite d'expliquer les propriétés algébriques des nombres irrationnels par celles des rationnels, qu'il peut étendre grâce à la densité des rationnels dans les irrationnels.

Isaac Newton met au point à la fin du un algorithme permettant le calcul numérique de racines de polynômes, "a priori" irrationnelles. Cet algorithme, connu depuis sous le nom de méthode de Newton, a ensuite été adapté pour calculer les zéros de fonctions non polynomiales.

Dans le cas particulier du nombre , John Machin publie en 1706 une formule donnant à l'aide de la fonction arctangente : 
formula_5.

Une amélioration de cette formule par Jurij Vega lui permet en 1789 de calculer avec une précision de .
D'autres formules permettant d'exprimer formula_6 ont été exhibées au , notamment la résolution par Euler du problème de Bâle qui donne une identité, peu utile pour un calcul pratique, reliant et la série des inverses des carrés des entiers :
formula_7.
Un autre exemple d'identité permettant le calcul numérique de est fourni par la formule de Leibniz, découverte en Europe au , mais qui était déjà connue de manière indépendante en Inde depuis deux siècles par l'école du Kerala :
formula_8.

Les fractions continues (dues à Cataldi en 1613), étroitement liées aux nombres irrationnels, sont prises en considération par Euler, qui montre ainsi notamment, en 1737, l'irrationalité de et de .

Lambert démontre en 1761 que n'est pas rationnel. Pour cela, il montre que la tangente et la tangente hyperbolique de tout rationnel non nul sont des irrationnels, en les approchant par des suites de rationnels issues de fractions continues généralisées particulières. Il conjecture par la suite la transcendance de et , mais ne remarque pas que sa méthode fournit une démonstration que est lui aussi irrationnel. Cette constatation est faite plus tard par Legendre.
Lambert montre également que l'exponentielle et le logarithme de tout rationnel non nul (et également différent de 1 dans le cas du logarithme) est un irrationnel.

Jusqu'au , l'existence et les propriétés des nombres irrationnels sont admises sans qu'en soit proposée de définition rigoureuse. En effet — contrairement aux rationnels, qu'il est facile de construire algébriquement à partir des entiers — la notion de nombre réel est encore mal définie au début de la seconde moitié du . L'une des premières tentatives en ce sens remonte aux travaux de Bernard Bolzano dans la première moitié du , mais ces travaux sont peu diffusés et n'influencent guère les constructions ultérieures. Karl Weierstrass travaille également sur la formalisation des nombres réels comme limites de rationnels, mais il ne publie rien à ce sujet et cette partie de son œuvre n'est connue que par les notes prises par son étudiant Adolf Hurwitz ayant suivi ses cours ; notes qui ne sont cependant pas publiées avant les années 1880.

Deux types de construction rigoureuse des nombres réels ont été présentées dans les années 1870 :
Ces deux approches sont équivalentes.

Plusieurs sous-ensembles particuliers de nombres irrationnels sont étudiés durant les . Il était connu depuis l'Antiquité que certains nombres irrationnels tels que sont constructibles, mais ce n'est qu'au que Wantzel caractérise l'ensemble des nombres constructibles, qui est le plus petit corps stable par la racine carrée contenant formula_10. Cela permet de montrer que les problèmes antiques de trisection de l'angle et de duplication du cube sont impossibles à l'aide de la règle et du compas seuls.

À la même période sont aussi étudiés les nombres transcendants, dont les premiers exemples sont exhibés par Liouville en 1844. Hermite montre en 1873 la transcendance de et en 1882, Lindemann montre celle de . Ce dernier résultat permet de répondre par la négative au problème de la quadrature du cercle, qui était ouvert depuis l'Antiquité grecque. Les nombres transcendants sont par ailleurs l'objet du septième problème de Hilbert, qui demande si le nombre est transcendant dès que est algébrique et différent de ou et que est algébrique et irrationnel. La réponse, affirmative, est apportée en 1934 par le théorème de Gelfond-Schneider.

Le voit également l'étude des nombres univers qui contiennent l'ensemble des séquences de chiffres possibles dans leur développement décimal, ainsi que des nombres normaux qui sont des nombres univers particuliers dans le développement décimal desquels toutes les séquences de chiffres d'une longueur donnée sont équiprobables. Bien que Borel ait prouvé en 1909 que presque tous les nombres irrationnels sont normaux en toute base, on connaît peu de nombres normaux. Parmi ceux dont la normalité a été établie au moins pour la , on peut citer la constante de Champernowne (qui est même transcendante), ou celle de Copeland-Erdős. De plus il est conjecturé que les nombres (et même tous les nombres algébriques irrationnels), et sont normaux mais bien que cela semble vrai expérimentalement, cela n'a pu être démontré pour aucun de ces exemples.

Le développement de l'informatique théorique dans les années 1930 a, parallèlement à cela, mené à l'étude des nombres calculables, c'est-à-dire pour lesquels il existe une machine de Turing capable d'en énumérer les décimales ainsi que de quantifier l'erreur d'approximation. L'ensemble des réels calculables contient l'algèbre des périodes, donc tous les nombres algébriques et , et il est stable par l'exponentielle. En particulier, tous les nombres non calculables sont transcendants et "a fortiori" irrationnels. Bien que l'ensemble des réels non calculables soit , on connait peu de nombres qui en fassent partie. Parmi ceux-ci on trouve par exemple toute limite d'une suite de Specker, dont la définition est liée au problème de l'arrêt.

Avant l'essor de l'informatique à la fin des années 1940, il était extrêmement laborieux de calculer effectivement plus de quelques centaines de décimales d'un nombre irrationnel donné. En 1940, on ne connaissait par exemple que 527 décimales exactes de , grâce au travail de William Shanks publié en 1873. En 1949, l'ordinateur ENIAC en donne en , en utilisant la formule de Machin.

Des algorithmes génériques sont développés, comme la transformée de Fourier rapide qui accélère le calcul des multiplications. Dans le même temps, la puissance de calcul des ordinateurs augmente de manière exponentielle. Ainsi en 1978, on connaissait déjà décimales de et en 2000, plus de 10 décimales de et plus d'un million de décimales de la constante d'Euler étaient calculées.

Des algorithmes spécifiques sont également conçus pour le calcul de certains nombres en particulier. Dans le cas de , les premiers algorithmes utilisant des formules proches de la formule de Machin sont ainsi abandonnés au profit d'autres formules plus efficaces, comme celle obtenue par Ramanujan en 1914 : formula_11.

Les premiers calculs d'approximations de nombres irrationnels donnaient toutes les décimales de la première jusqu'à une borne plus ou moins élevée, mais on ne savait pas calculer une décimale donnée sans connaître celles qui la précèdent. En 1995, les mathématiciens Simon Plouffe, David H. Bailey et Peter Borwein découvrent la formule BBP, qui permet de calculer tout chiffre du développement de en base 16 sans avoir à déterminer ceux qui précèdent. Avant de découvrir cette formule, ils avaient déjà établi qu'il est possible de calculer séparément tout chiffre du développement binaire du logarithme de grâce à l'égalité :
formula_12.

La caractérisation des irrationnels peut s'effectuer via leur développement décimal, grâce au théorème suivant, démontré dans l'article détaillé :

On démontre de même la caractérisation analogue via le développement dans n'importe quelle base (entière et supérieure ou égale à 2).

Ainsi le calcul du développement d'un nombre rationnel est aisé puisqu'il n'y a qu'un nombre limité de chiffres à calculer pour le caractériser complètement, tandis que le calcul des développements de nombres irrationnels nécessite généralement la mise en œuvre de techniques mathématiques d'autant plus avancées que la précision souhaitée est élevée .

Les fractions continues permettent entre autres de caractériser l'irrationalité, d'identifier des types particuliers d'irrationnels, et de fournir de bonnes approximations des irrationnels par des rationnels.

Pour tout nombre réel formula_13, le caractère fini ou infini de son développement en fraction continue peut être lié à son caractère rationnel ou irrationnel. Plus précisément :

Un irrationnel est dit quadratique s'il est solution d'une équation du second degré à coefficients entiers.
La suite des réduites du développement en fraction continue d'un irrationnel formula_13 converge vers formula_13 « rapidement » : toute réduite formula_16 du développement vérifie formula_17.

Par exemple, le début du développement en fraction continue de est [3, 7, 15, 1, 292, …]. À partir de ce début de développement, on trouve comme approximation de : formula_18 avec une erreur inférieure à formula_19, c'est-à-dire que l'on a au moins 9 décimales exactes.

Il est possible de comparer la précision obtenue en approchant un irrationnel par les premiers termes de son développement en fraction continue ou par les premiers chiffres de son développement décimal.
En effet pour presque tout irrationnel formula_13, le théorème de Lochs affirme que les formula_21 premiers entiers du développement en fraction continue de formula_13 donnent asymptotiquement formula_23 décimales exactes.

L'ensemble des nombres rationnels est dense dans celui des réels. Par conséquent, pour tout nombre réel formula_13, rationnel ou irrationnel, il existe une suite de nombre rationnels qui converge vers formula_13. Cependant, tous les réels ne sont pas aussi facilement approchables les uns que les autres. On peut ainsi définir la mesure d'irrationalité de n'importe quel réel formula_13. Il s'agit de la borne supérieure de l'ensemble des réels pour lesquels il existe une infinité de couples formula_27 d'entiers tels que formula_28 et formula_29. Grossièrement, cela signifie que si un réel formula_13 a une mesure d'irrationalité supérieure à celle d'un réel formula_31 alors, à dénominateur égal, il est possible d'approcher formula_13 plus finement que formula_31 avec un nombre rationnel.

Les deux théorèmes suivants permettent de différencier un rationnel d'un irrationnel par leur mesure d'irrationalité :

On peut renforcer le second point du théorème : si un réel formula_13 est irrationnel, l'existence d'une infinité de couples formula_27 d'entiers tels que formula_36 et formula_37 est garantie non seulement pour tout formula_38, mais même pour formula_39. Cela se déduit par exemple de l'approximation d'un irrationnel par la suite infinie des réduites de sa fraction continue , ou du théorème d'approximation de Dirichlet.

Ces théorèmes servent de base à divers résultats permettant de montrer, sous certaines hypothèses, l'irrationalité de la somme d'une série dont le terme général est rationnel et qui converge suffisamment rapidement.

Tout irrationnel formula_13 a une mesure formula_41 supérieure ou égale à 2 ; elle vaut même exactement 2 pour presque tout réel. Il n'est cependant pas toujours aisé de la calculer précisément. Elle est tout de même parfois connue ou au moins estimée :

L'ensemble ℚ a une structure de corps commutatif, cela permet de déduire des résultats généraux sur l'irrationalité de sommes et de produits impliquant à la fois rationnels et irrationnels.
L'ensemble des irrationnels vérifie par exemple la propriété de clôture suivante : si le carré (ou plus généralement, une puissance entière) d'un réel est un irrationnel, alors ce réel lui-même est irrationnel (par contraposée de la proposition selon laquelle tout produit de rationnels est rationnel). Cela permet, connaissant un nombre irrationnel, d'en construire une infinité d'autres.

On peut aussi, sachant que pour tout nombre irrationnel formula_42 et tout rationnel formula_50, les nombres formula_51 et formula_52 sont irrationnels, faire agir le groupe projectif linéaire formula_53 (ou formula_54) :
Par exemple :

En revanche, la somme et le produit de deux irrationnels peuvent être rationnels : par exemple, formula_64 et formula_65.

Un irrationnel (strictement positif) élevé à une puissance irrationnelle peut également être rationnel. Autrement dit : il existe un rationnel et un irrationnel tels que soit irrationnel. On a même : pour "tout réel" différent de , est irrationnel pour « presque tous » les irrationnels (tous sauf un ensemble dénombrable), d'après la sous-section suivante.

L'ensemble ℝ\ℚ des irrationnels a la puissance du continu, c'est-à-dire qu'il est en bijection avec ℝ, comme le prouve, au choix, l'un des trois arguments suivants :

Les parties ℚ et ℝ\ℚ sont toutes les deux denses pour l'ordre dans ℝ et "a fortiori" denses pour la topologie usuelle de ℝ. Pour tous réels formula_66, il existe un isomorphisme d'ordres entre ℚformula_67 et ℚ (c'est un cas particulier d'un théorème de Cantor, immédiat si formula_2 et formula_3 sont rationnels). Par prolongement canonique, ceci montre que l'ensemble des irrationnels de formula_70 est — au sens de l'ordre et "a fortiori" au sens topologique — dense dans formula_70 et isomorphe à ℝ\ℚ.

Alors que ℝ est connexe, le sous-espace des irrationnels est totalement discontinu (puisqu'il ne contient aucun intervalle non trivial).

Dans ℝ, les irrationnels forment un G (c'est-à-dire une intersection dénombrable d'ouverts) mais pas un F (c'est-à-dire une union dénombrable de fermés). Autrement dit : l'ensemble des points de discontinuité d'une fonction à valeurs réelles peut être égal à ℚ mais pas à ℝ\ℚ.

Alors que l'espace métrique ℝ est complet, le sous-espace des irrationnels ne l'est pas (puisqu'il n'est pas fermé dans ℝ). Cependant, par la bijection évoquée ci-dessus, cet espace topologique est homéomorphe à l'espace métrique complet formula_72, appelé l'espace de Baire. Ceci démontre que le théorème de Baire s'applique aussi à l'espace des nombres irrationnels.

Prouver qu'un réel formula_73 est irrationnel, c'est prouver qu'il n'existe aucun couple d'entier formula_74 tel que formula_75, or un résultat d'inexistence sur un cas particulier est généralement bien plus difficile à établir qu'un résultat d'existence. Ainsi même s'il est possible de montrer qu'un réel formula_73 ne peut pas s'écrire sous la forme formula_75 où formula_78 et formula_79 sont inférieurs à une certaine constante formula_80, cela ne suffit pas pour prouver son irrationalité. Par exemple, on sait que si la constante d'Euler-Mascheroni est rationnelle alors ce ne peut être qu'une fraction dont le dénominateur comporte au moins mais même si cela conduit à supposer son irrationalité, cela n'en constitue aucunement une preuve. Il existe cependant plusieurs techniques de démonstration qui ont permis de statuer sur l'irrationalité de certains cas particuliers.

Le nombre est l'un des premiers dont on ait prouvé l'irrationalité. Celle-ci peut en effet être obtenue grâce à des considérations élémentaires de parité:

On raisonne par l'absurde. Supposons que formula_81 soit un nombre rationnel, il existe alors deux entiers formula_2 et formula_3 premiers entre eux tels que formula_84 ce qui est équivalent à dire que formula_85. L'entier formula_86 est donc pair, et par conséquent formula_2 est pair, ce qui s'écrit formula_88 où formula_89 est un entier. Mais alors comme formula_85, il s'ensuit que formula_91 et donc formula_92 et formula_3 sont pairs.

formula_2 et formula_3 sont donc tous les deux pairs et ne sont donc pas premiers entre eux. On a donc abouti à une contradiction en supposant formula_81 rationnel. C'est donc un nombre irrationnel.

Toute fraction continue simple infinie représente un irrationnel .

La fraction continue la plus simple est celle du nombre d'or, que l'on peut obtenir directement à partir de l'équation formula_116 : formula_117. On retrouve ainsi à nouveau que formula_98 est irrationnel.

Il n'y a pas d'entier strictement compris entre 0 et 1. On peut exploiter cette propriété comme suit pour démontrer que et sont irrationnels. Ce résultat n'est pas optimal : on peut en effet prouver, bien que les démonstrations soient plus difficiles, que ces deux nombres sont même transcendants.

Fourier redémontre ce résultat d'Euler en utilisant le développement en série entière de la fonction exponentielle, évalué en formula_99 : formula_120.

Cela lui permet de montrer que pour tout entier , le nombre a une partie fractionnaire non nulle donc n'est pas entier, et donc que n'est pas rationnel.

Ivan Niven redémontre par l'absurde ce résultat de Lambert, en supposant que formula_121 avec formula_2 et formula_3 entiers et en construisant, à partir de cette hypothèse, une expression qui est égale à un nombre entier tout en pouvant être strictement comprise entre 0 et 1, ce qui est absurde. Supposer que formula_6 est rationnel conduit donc à une contradiction, et donc formula_6 est irrationnel.
Hardy et Wright, reprenant la méthode de Niven, démontrent de la façon suivante l'irrationalité de , qui implique celle de .

Considérons, pour tout entier naturel formula_109, la fonction polynomiale formula_127 définie par formula_128. Ses dérivées jusqu'à l'ordre formula_129 prennent une valeur entière en formula_130 (donc aussi en formula_99 par symétrie) et la dérivée suivante est nulle.

Supposons que formula_132 avec formula_2 et formula_3 entiers strictement positifs et posons formula_135. D'après ce qui précède, formula_136 et formula_137 sont des entiers.

De plus, formula_138 (par télescopage) donc

Cependant, sur formula_140, la fonction formula_141 est continue et strictement comprise entre formula_130 et formula_143 donc formula_144.

De plus, pour formula_109 suffisamment grand, formula_146 (la série est même convergente). L'entier formula_147 est alors strictement compris entre formula_130 et formula_99, ce qui est absurde.

Il est possible de prouver l'irrationalité d'un réel formula_13 en exhibant une suite de rationnels formula_151 convergeant vers formula_13 « suffisamment vite », c'est-à-dire telle que pour tout formula_109 on ait formula_154. C'est grâce à une telle technique que Roger Apéry a montré en 1978 le résultat suivant, sur l'image de 3 par la fonction de Riemann :
Tout rationnel ayant un développement périodique dans toute base, il suffit, pour prouver qu'un réel formula_13 est irrationnel, de montrer que dans une certaine base, son développement n'est pas périodique. Cela peut parfois être fait directement comme dans le cas du théorème suivant :

Ce théorème peut être démontré par l'absurde, en supposant le développement binaire périodique et en montrant que la période sépare un chiffre associé à un nombre premier d'un chiffre associé à un nombre composé.

Dans la pratique, la non-périodicité peut être obtenue en établissant l'existence de suites finies de formula_130 de longueur arbitraire. En effet si le nombre est périodique il ne peut comporter des séquences de zéros plus longues que la longueur de sa période à moins d'avoir un développement décimal fini.

Une application élémentaire est fournie par le résultat suivant : 

En effet, son développement en base formula_157 n'est pas périodique parce qu'il contient les entiers de la forme formula_158 pour formula_89 arbitrairement grand, et donc des suites de formula_130 finies arbitrairement longues. Ce nombre est en fait même normal et transcendant.

Un exemple moins trivial est le suivant :

La constante de Copeland-Erdős est définie par formula_161 où formula_162 est le "k"-ième nombre premier, et où formula_163 est la partie entière de son logarithme décimal. C'est-à-dire que le développement décimal de la constante de Copeland-Erdős est la concaténation des éléments de la suite des nombres premiers.

On montre l'irrationalité de formula_164 en exhibant des suites de zéros arbitrairement longues.
Pour tout entier naturel formula_165, d'après le théorème de la progression arithmétique, la suite arithmétique formula_166 contient une infinité de nombres premiers, donc au moins un. Il existe donc au moins un nombre premier dont l'écriture en base dix contient une succession d'au moins formula_165 zéros, encadrée par deux chiffres autres que formula_130 (le second étant formula_99). Le développement décimal de formula_164 contient ainsi des suites de zéros finies mais arbitrairement longues, ce qui prouve qu'il n'est pas périodique, et donc que formula_164 n’est pas rationnel.
L'irrationalité de formula_164 peut également se déduire du résultat plus général, mais plus difficile à démontrer, selon lequel la constante de Copeland-Erdős est un nombre normal en base 10, joint à la propriété élémentaire suivante :
Le nombre est irrationnel puisqu'il n'existe pas d'entiers "a, b" ≠ 0 tels que 2 = 10 ; plus généralement, " m" = est irrationnel pour tous entiers "m, n" > 1 qui n'ont pas le même ensemble de facteurs premiers (ou encore : le même radical). Par exemple : et sont irrationnels.

La constante d'Erdős-Borwein formula_173, obtenue comme la somme de la série des inverses des nombres de Mersenne, et la somme de la série des inverses des nombres de Fermat formula_174 sont irrationnelles. En effet, des suites arbitrairement longues de zéros ont été mises en évidence dans leur développement en base 2. Le raisonnement mis en œuvre pour ce faire est cependant bien plus technique que dans les exemples précédents.

On ne sait pas si les nombres et sont ou non irrationnels. On conjecture cependant que , et sont ℚ-linéairement indépendants.
On ne sait pas plus si , , , la constante de Khintchine ou la constante d'Euler-Mascheroni sont irrationnels.
On ignore également, pour tout entier impair , si est irrationnel. En effet, pour les entiers positifs impairs, seul le cas de est connu grâce au théorème d'Apéry. Cependant, il a été prouvé que prend une valeur irrationnelle pour une infinité de nombres impairs, dont au moins l'un des quatre nombres , , ou .
De plus, des calculs en haute précision rendent extrêmement vraisemblable l'irrationalité et même la transcendance de tous ces nombres.

Certains problèmes ouverts d'autres domaines des mathématiques peuvent être exprimés comme des problèmes d'irrationalité. Par exemple si la constante de Brun était irrationnelle, cela impliquerait la conjecture des nombres premiers jumeaux.




</doc>
<doc id="15722" url="https://fr.wikipedia.org/wiki?curid=15722" title="Control Program/Monitor">
Control Program/Monitor

CP/M, sigle de "Control Program/Monitor ou /Microcomputer", est un système d'exploitation créé en 1974 par Gary Kildall, fondateur de Digital Research.

Il est utilisé notamment sur les Amstrad CPC et Amstrad PCW, Commodore 128, TRS-80, l'Osborne 1, BBC Micro, le ZX Spectrum. Il fut utilisé sur PC, notamment livré en standard avec les Amstrad PC-1512 en plus du MS-DOS et de GEM.

Pour l'Apple II, Microsoft a créé en 1980 la carte d'extension Z-80 SoftCard qui permettait l'usage du système d'exploitation de Digital Research.

Les premières versions de MS-DOS se sont largement inspirées de CP/M.

La mémoire d'un ordinateur sous CP/M est divisée en quatre parties :
Il gérait les périphériques, disquettes, imprimantes moniteur, etc.
Habituellement, le BIOS occupe la partie « haute » de la mémoire.

Il contenait le système d'exploitation.
Habituellement, le BDOS se trouve sous le BIOS.

Habituellement, le CCP se trouve sous le BDOS. Cette partie du CP/M correspond à l'interface utilisateur.

Cette partie de la mémoire débute en 100 (adresse hexadécimale). Elle est destinée aux programmes des utilisateurs.

Ce système d'exploitation, enregistre les fichiers sur disquettes suivant une organisation logique spécifique (qui n'a pas été reprise par MS-DOS), et peut remplir les disquettes jusqu'à ce qu'elles soient complètement remplies.

CP/M peut aussi gérer des disques durs (en réalité, comme le BIOS est « ouvert » et décrit clairement dans la documentation que Digital Research fournissait avec certains de ses logiciels, il est donc possible d'adapter tout système particulier CP/M à toute mémoire de masse disponible - et aux périphériques dont on dispose). Certains ordinateurs tournant sous MP/M étaient vendus, à l'origine, avec des disques durs (l'Altos en est un exemple).

Chaque fichier a un nom et une extension (plus précisément, la syntaxe est : <nom du fichier (8 caractères maximum)>.<extension (3 caractères maximum)>).

Parmi les extensions les plus habituelles, on trouve :


exemples de noms de fichiers : STAT.COM ; dans le cas de "nomdufichier.ASM", le nom du fichier est trop long, puisqu'il y a un maximum de 8 caractères utilisables à cet effet ; donc il faudrait, par exemple, nommer ce fichier "fichier.ASM" ou "fichier1.ASM".

"READ.ME" est un nom de fichier que beaucoup d'éditeurs utilisent pour attirer l'attention de l'utilisateur sur des aspects très importants de leurs logiciels... ce sont donc des fichiers à lire avant d'utiliser le logiciel en question. Pour lire le contenu d'un tel fichier on peut, en général utiliser la commande :

TYPE READ.ME

Les invites de commandes des disquettes sont A> pour le lecteur A et B> pour le lecteur B. Comme sous MS-DOS, il faut taper la lettre du disque auquel on veut accéder, suivie de deux points.

Les commandes de CP/M peuvent être « internes » ou « externes » (comme ce fut, par la suite, le cas avec MS-DOS). Sous CP/M, pour l'utilisateur, il n'y a pas de différence entre lancer une commande « interne » (par exemple DIR as*.*), « externe » (par exemple STAT as*.*) ou un programme (par exemple LINK).

Sous CP/M, le programme « correct » le plus court n'a besoin que d'un octet (C9 en hexadécimal - l'instruction RETurn) qui fait un retour au Système (ce qui est une sortie « normale » pour un programme CP/M). Par contre, il doit être sauvegardé dans un fichier « exécutable » (donc un ".com") dont la taille minimum est un secteur (donc minimum).

Les commandes externes du CP/M ou MP/M appelaient des programmes du même nom qui portaient l'extension .COM ou .PRL (uniquement dans le cas de MP/M). Pour information, le MP/M était relativement semblable au CP/M mais était multi-utilisateurs.


Sous CP/M, l'utilisateur peut programmer en utilisant directement le code machine, un assembleur ou un langage de programmation comme le BASIC.

Les sources des logiciels écrits par DRI (c'est-à-dire, Digital Research) peuvent se trouver sur Internet (voir, par exemple, DRIPAK.zip).

Pendant de nombreuses années, CP/M a été utilisé comme système d'exploitation pour des microprocesseurs Intel 8080 et Zilog Z80.

Depuis, Zilog a commercialisé des processeurs avec des possibilités d'adressage très étendues par rapport aux processeurs 8 bits traditionnels. D'un autre côté, les capacités des mémoires (circuits intégrés) que l'on trouve sur le marché, que ce soient les RAM ou les ROM (ou les PROM) en ce début du sont très importantes et sont donc comparables aux capacités que l'on pouvait trouver sur les premières disquettes souples.

Ces deux facteurs donnent leur chance à de nouvelles architectures pour des systèmes tournant sous CP/M.

Parmi les nouvelles architectures les plus prometteuses, on peut citer :

Par ailleurs, des compilateurs CP/M ont été écrits pour de nombreux langages, par exemple :
Des langages orientés vers l'« intelligence artificielle », comme muMATH (qui est capable de résoudre des équations formelles) ou muSIMP (voir muMATH) peuvent aussi « tourner » sous CP/M.

Le cas du langage PL/M est un peu particulier, puisqu'une partie du logiciel correspondant au système d'exploitation CP/M – et à ses utilitaires – a été écrite en PL/M, pour un compilateur qui tournait sous ISIS II. Il est possible, toutefois, d'émuler ISIS II sous CP/M.

Parmi les autres logiciels disponibles, il y avait aussi dBase II, une base de données relationnelle, très interactive.

CP/M supporte aussi de nombreux traitements de texte comme WordStar, avec, le cas échéant, leurs systèmes de vérification orthographique, des tableurs comme SuperCalc ou des logiciels combinant ces deux fonctionnalités.

CP/M peut être utilisé sans disposer d'un ordinateur en étant équipé nativement, par le biais d'un émulateur CP/M, fonctionnant par exemple sous MS-DOS.

Avec des micro-ordinateurs « du commerce » utilisant un système d'exploitation moderne tel que Windows 7 et avec deux couches d'émulation superposées (une première pour MS-DOS, et une seconde pour CP/M), les performances obtenues pour des programmes « scientifiques » tournant sous CP/M sont comparables à celles obtenues sur une machine native : la fréquence actuelle des processeurs pouvant surpasser de plusieurs ordres de grandeur celle des années 1980, la machine compense aisément la surcharge occasionnée par la multiplication des couches logicielles.

Les fichiers générés par des « programmes CP/M » tournant sous émulateur sont naturellement « compatibles » avec le système d'exploitation sous lequel tourne l'émulateur. De ce fait, il est possible, par exemple, de faire générer des fichiers au format .bmp "par un programme qui tourne sous CP/M" et de les visualiser ensuite par un outil habituel du monde Windows, comme Microsoft Paint.

Un petit détail est, toutefois, à garder en mémoire :

Donc, certains programmes CP/M peuvent s'attendre à voir des 1A (hexadécimal) en fin de fichier... Petit détail qui réserve parfois des surprises... et des belles opportunités de travailler avec des programmes comme DEBUG (sous MS-DOS) ou DDT (sous CP/M) qui permettent de travailler au niveau de l'octet.

Malheureusement, certains émulateurs MS-DOS et DEBUG ne s'entendent pas bien... et les émulateurs CP/M ont des problèmes avec des fichiers dont la longueur se rapproche des 64 kilooctets... le taille maximale de la mémoire d'un système CP/M.

Intrinsèquement la structure et le fonctionnement des systèmes de gestion de fichiers par CP/M et MS-DOS sont différents, mais des programmes comme Hyperterminal et Kermit pour les univers Windows ou MS-DOS d'une part et Kermit pour les univers CP/M d'autre part, ont des modes de fonctionnement (protocoles) compatibles. Il est donc facile d'échanger des fichiers entre ces deux univers.

La conséquence est qu'il est possible de créer des fichiers par une application « temps réel » sous CP/M (qui, certes, n'est pas un système conçu pour faire du « temps réel », mais dont la fiabilité et la répétitivité se prêtent bien au temps réel) et de continuer les traitements sous MS-DOS... ou vice-versa.




</doc>
<doc id="15723" url="https://fr.wikipedia.org/wiki?curid=15723" title="Masse atomique">
Masse atomique

La masse atomique relative (ou poids atomique) est la masse d'un atome en particulier ou un élément chimique en général (auquel cas on envisage un mélange isotopique) exprimée en tant que multiple d'une masse élémentaire de référence qui se veut proche de celle d'un nucléon unique. En effet la masse d'un atome est proportionnelle en première approximation au nombre de ses nucléons, dit nombre de masse. La masse élémentaire de référence, appelée unité de masse atomique, est définie depuis les années 1960 comme le douzième de la masse de l'atome de carbone 12.

La masse atomique est généralement un nombre décimal, et ce pour plusieurs raisons. Les décimales varient selon l'unité de masse atomique choisie comme référence, ce qui explique en partie les variations historiques de ce choix.

Concernant un élément chimique en général, c'est le mélange isotopique constaté sur la Terre qui est pris comme mélange caractéristique. La masse atomique d'un élément chimique est ainsi la moyenne des masses atomiques de ses isotopes au prorata de leur présence dans la nature. Ce choix offre un intérêt pratique évident : il permet de calculer précisément les masses en jeu lorsqu'on considère des échantillons non purifiés de l'élément chimique, c'est-à-dire dans la situation expérimentale la plus courante.

Concernant un atome en particulier (isotope donné d'un élément donné, caractérisé par un nombre de protons et un nombre de neutrons donnés), seul le carbone 12 possède "a priori" une masse atomique entière, pour la simple raison que l'unité de masse atomique est définie comme 1/ de sa masse. Pour tous les autres atomes, la masse atomique exacte n'est pas un multiple entier de la masse unitaire de référence. En effet des phénomènes physiques corrélés au nombre de nucléons mais non proportionnels à celui-ci interviennent, de telle sorte que la masse d'un ensemble de nucléons assemblés dans un noyau n'est pas égale à la somme des masses des nucléons isolés : en effet, la masse d'un proton lié dans un noyau n'est pas tout à fait égale à celle d'un proton libre (énergie de liaison, défaut de masse nucléaire...).

Comme le nombre des nucléons, la masse atomique relative prend dans la nature une valeur comprise entre 1 et un peu plus de 200. C'est donc un nombre plus facile à imaginer et plus simple à écrire que celui qui caractérise la masse en kilogrammes des atomes, proche de .

Par ailleurs, la notion de masse atomique relative est née avant que l'existence de l'atome soit avérée, et donc avant qu'il soit possible de compter ou de peser des atomes. Les chimistes avaient néanmoins observé la quantification des masses des éléments chimiques, par exemple en comparant des volumes identiques de gaz différents. La masse atomique relative décrit efficacement le rapport massique des éléments "indépendamment du nombre de corpuscules concernés".


Quand la notion de masse atomique apparut, les premières mesures suggéraient que la masse atomique d'un atome était toujours un multiple entier de celle de l'hydrogène. Le choix de l'hydrogène comme masse atomique unitaire relevait donc plus d'un constat que d'un choix normatif.


On démontra dans la première moitié du que les masses atomiques n'étaient pas exactement des multiples entiers de l'unité, quelle qu'en soit la définition. Cela signifiait qu'1/ de la masse de l'oxygène 16 par exemple, n'est pas égal à 1/ de la masse du carbone 12, ni à la masse de l'hydrogène. Il était donc nécessaire de préciser la définition en choisissant un élément de référence. L'oxygène étant fréquemment impliqué dans les réactions chimiques qui nous entourent, son choix comme référence pour la mesure de l'unité de masse atomique simplifiait de nombreux calculs pour les chimistes. Toutefois ce standard s'est ensuite décliné selon deux interprétations : celle des chimistes, qui prenaient comme référence le mélange isotopique naturel de l'oxygène, et celle des physiciens, qui choisirent plus précisément l'isotope oxygène 16.


Il était nécessaire de statuer sur une référence unique. Les valeurs de masse atomique relative obtenues par référence au carbone 12 avaient l'avantage de ne pas trop différer des anciennes valeurs, que celles-ci proviennent de la chimie ou de la physique. Cela facilitait la mise en place de cette nouvelle et ultime référence.





</doc>
<doc id="15725" url="https://fr.wikipedia.org/wiki?curid=15725" title="Densité de population">
Densité de population

La densité de population est une mesure du nombre d'individus ou d'habitants occupant une surface donnée. Elle est le plus souvent exprimée en individus par unité de surface (par exemple, habitants/km).

La densité de population est une mesure biologique courante et est souvent utilisée par les protecteurs de la nature comme une valeur plus appropriée que les nombres absolus. De faibles densités de population peuvent créer une spirale d'extinction, dans la mesure où de faibles densités conduisent à une fertilité de plus en plus réduite. C'est l'effet Allee, d'après W. C. Allee qui l'a mis le premier en lumière. À titre d'exemple :


Cependant, des espèces différentes présentent à la base des densités différentes. Par exemple, les espèces à stratégie r ont d'ordinaire une densité de population élevée, tandis que les espèces à stratégie K peuvent présenter une densité de population plus faible. Une faible densité de population peut être associée avec une adaptation vers une spécialisation dans la localisation des partenaires reproductifs, comme des pollinisateurs spécialisés tels qu'on en trouve dans la famille des orchidées.

Il est aussi possible de définir la densité d'une population grâce à sa biomasse. Cette méthode est utile quand il faut comparer des densités d'espèces de taille ou de nature très différentes.

Pour les êtres humains, on définit la densité de population comme le nombre de personnes par unité de surface (qui peut inclure ou pas les eaux intérieures), bien qu'elle puisse également être exprimée par rapport aux terres habitables, habitées, arables (ou potentiellement arables) ou cultivées.

Elle est fréquemment exprimée en personnes par kilomètre carré ou par hectare et s'obtient en divisant le nombre de personnes par la surface considérée mesurée en kilomètres carrés ou en hectares.

Dans la pratique, on peut calculer ceci pour une ville, une agglomération, un pays ou le monde entier. 

À titre d'exemple, pour la plupart des pays européens de taille importante (intégrant de ce fait des zones denses et d'autres moins peuplées), la densité moyenne oscille entre 100 et 393 habitants par kilomètre carré (France : 94 /km (en comptant la Guyane), Allemagne : 231 /km, Pays-Bas : 393 /km, Belgique : 364 hab/km, Royaume-Uni : 244 /km). Un territoire très désertique a une densité proche, voire inférieure à un habitant au kilomètre carré (Groenland : 0,03 /km, Sahara occidental : 1 /km).

Concernant les États d'une certaine taille, le plus densément peuplé est le Bangladesh, où 147 millions de personnes vivent dans une zone hautement agricole autour de l'embouchure du Gange, avec une densité de population de plus de 1000 habitants par km. Avec de terres émergées et sur terre en octobre 2016, la densité de population sur l'ensemble des terres émergées est de .

La grande ville la plus densément peuplée d'Allemagne est Munich avec devant Berlin avec .

Hambourg, la deuxième ville du pays, qui inclut dans son aire urbaine le port et les grandes zones industrielles et rurales, n'a qu'une plus faible densité de population () ; cependant la ville étant également un land, elle constitue le deuxième pour la densité après celui de Berlin.

Le quartier berlinois de Kreuzberg a une densité de et le quartier munichois de Schwabing-West de .

De même qu'aux États-Unis, le district fédéral brésilien, comparable à un État fédéré est l'entité la plus densément peuplée du fait de sa taille relativement faible et de son importante population. Avec 410.9 hab /km elle est suivie de l'État de Rio de Janeiro (352) et de l'État de São Paulo (162) ; le classement étant complété par les États de l'Amazonas (2,1) et de Roraima (1,8).

Guttenberg dans le New Jersey est la ville la plus densément peuplée des États-Unis avec ; la ville de New York (hors espace métropolitain) se place au cinquième rang avec .
Le district de Columbia compte , bien qu'il ne soit pas un État fédéré affiche la plus haute densité devant le New Jersey (439,39), l'Alaska étant le moins densément peuplé (0,42).

En France, les populations sont majoritairement réparties le long des littoraux et dans les grands centres urbains (Grenoble, Toulouse, Nantes, Lyon, Rennes, Lille, Marseille, Nice, Strasbourg, Nancy, Rouen, la région parisienne) où les densités sont plus importantes. Généralement, les zones les plus denses sont aussi les plus petites en superficie. Ainsi, Levallois-Perret (superficie de ), dans les Hauts-de-Seine est la commune la plus densément peuplée de France () ; la majorité des 50 communes les plus densément peuplées se trouvant également en Île-de-France ; et Paris le département où la population est la plus concentrée () ; suivi respectivement par les Hauts-de-Seine (), la Seine-Saint-Denis () et le Val-de-Marne ().

Certains arrondissements de Paris sont très densément peuplés : le 11° arrondissement a une densité de . Les 10°, 18° et 20° arrondissements ont tous les trois une densité de population dépassant les .

Sur la base des travaux d'Eurostat, l'Insee a établi une cartographie de la densité des communes françaises. Elles sont réparties entre quatre catégories :

À l'inverse, il existe également des zones plus faiblement peuplées comme dans la diagonale du vide, allant des Landes à la Meuse.

Le borough royal de Kensington et Chelsea est le plus densément peuplé d'Angleterre, avec .

Les deux régions administratives spéciales sont le lieu d'importantes concentrations de populations ; Macao () et Hong Kong () sont bien plus densément peuplées que les municipalités de Shanghai, Tianjin et Pékin (); la première province pour la densité étant le Jiangsu (743,30) et la dernière étant la région autonome du Tibet (0,42).

Betio, une communauté urbaine de Tarawa aux Kiribati a une densité urbaine qui dépasse h/km2, ce qui est d'autant plus remarquable que tous les édifices sont de plain-pied (aucun édifice en hauteur) et constitue sans doute le record mondial de densité dans ces conditions

De 1948 à 1991, Kowloon Walled City, un quartier de Hong Kong sans aucune règlementation et devenue zone de non-droit a attiré près de sur seulement , faisant du quartier la zone la plus densément peuplée de l'Histoire de l'humanité. En effet, la densité de population atteignait pas moins de !




</doc>
<doc id="15726" url="https://fr.wikipedia.org/wiki?curid=15726" title="Acari">
Acari

Les acariens (Acari ou Acarina) sont un taxon d'arachnides.

Ils sont de taille généralement minuscule : certains sont microscopiques, ne mesurant que quelques dizaines de micromètres, les plus grands ne dépassant pas (sauf les tiques gorgées de sang qui, dans les espèces tropico-équatoriales, peuvent atteindre la taille d'une « belle » cerise).

Le corps est particulièrement compact pour un arthropode en raison de la fusion du prosome (l'équivalent du céphalothorax d'autres arthropodes) et de l'opisthosome (ou abdomen) en une masse unique et de la quasi-disparition des traces de segmentation.

Il en existe près de espèces répertoriées, mais la diversité réelle du groupe est probablement supérieure au million d'espèces. La variété de leurs modes de vie (habitat, niche écologique, mode d'alimentation…) est sans égale chez les Arachnides.

Beaucoup vivent librement dans le sol ou l'eau, mais les acariens ont aussi développé une grande diversité de relations avec d'autres êtres vivants — animaux ou végétaux —, allant de la phorésie à l'endoparasitisme. Il existe en particulier un grand nombre d'espèces parasites, éventuellement pathogènes pour les plantes, les animaux ou l'homme. 

Parmi les plus connus, figurent les tiques, le sarcopte responsable de la gale, le "varroa" parasite des abeilles, les acariens des poussières ("Dermatophagoides pteronyssinus" par exemple) susceptibles de provoquer des allergies chez certaines personnes, ou encore les aoûtats.

Les acariens mesurent entre 0,1 et 0,6 mm : de par leur taille, ils sont à la limite de la microfaune stricto sensu et de ce que l'on appelle communément la mésofaune.

En raison de la fusion des différentes régions du corps, la morphologie des acariens est unique. Les seules traces visibles de la segmentation d'origine sont les appendices, pièces buccales et pattes. Les pièces buccales, chélicères et pédipalpes, sont souvent fortement modifiées en relation avec l'alimentation correspondante. Elles constituent un ensemble qui chez les tiques prend le nom de "capitulum" (du latin « tête ») séparé du reste du corps par un sillon. Le reste du corps est nommé "idiosome" chez les tiques.

De chaque côté du corps se trouve un stigmate servant d'orifice respiratoire.

Les acariens sont essentiellement, sinon exclusivement ovipares. Comme chez les insectes, aux œufs succèdent une larve, puis nymphe et enfin l'adulte. Certains auteurs nuancent chez les acariens la notion de stade et celle de stase, différenciant, au sein de la stase nymphale différents stades, chacun d'eux séparés par une mue, mais de très faible amplitude, bien différente de celle qui transforme la larve en nymphe, et celle-ci en l'adulte. À cause de leur courte durée de vie (2 à 3 mois), les femelles se reproduisent très vite. Ainsi, une femelle peut pondre, à raison de 300 œufs par mois, jusqu'à 900 œufs dans sa vie.

Leurs conditions optimales de croissance sont un environnement humide (taux d'humidité de 60 à 80 %) et une température plutôt élevée et stable (26-32°C), ce qui détermine le maximum d'activité des acariens de mai à septembre dans la nature, en automne et en hiver dans les habitats (temps pluvieux, habitations chauffées)

Selon les espèces, l'habitat et le comportement sont extrêmement variés.

Les régimes alimentaires des acariens sont très variés selon les espèces ou les groupes : phytophages, prédateurs, hématophages et lymphophages, etc. La nourriture peut être pré-digérée avant l'ingestion, par inoculation de salive. 
Certains acariens consomment des aliments solides (animaux et végétaux) en les déchiquetant grâce à leurs chélicères en forme de pince. Les substances solides sont ensuite digérées à l'extérieur du corps grâce à des enzymes sécrétées par les glandes salivaires. D'autres acariens sont des suceurs de sang ou de sève. L'épithélium de l'intestin moyen capte les aliments par phagocytose.

Elles peuvent être marines, dulçaquicoles, terrestres. Elles peuvent être carnivores, végétariennes ou détritivores. Certaines provoquent des galles sur les végétaux. D'autres vivent sur les denrées alimentaires (Ex : "Tyrolichus casei" pour les fromages à pâte plus molle ou "Acarus siro" autrefois appelé "Tyroglyphus farinae", dit ciron qui produit les croutes de fromages durs tels que la Mimolette). D'autres vivent dans les denrées entreposées comme le blé des silos ou la farine. Une dizaine d'espèces sont responsables d'allergies chez l'Homme ("Dermatophagoides", "Acarus siro", "Lepidoglyphus destructor").

Sans être des parasites importuns, ils sont transportés par d'autres espèces.

Certains sont par exemple des acariens des plumes.

Il en existe une grande quantité et elles ne sont pas encore toutes connues. 

Plusieurs espèces de demodex vivent en parasite ou en symbiote (en tant que nettoyant les pores d'un excès de sebum) de mammifères, dont chez l'Homme "Demodex folliculorum" qui vit dans les glandes sébacées de l'Homme et "Demodex brevis" qui vit dans le follicule pileux humain.

Le tétranyque tisserand ("Tetranychus urticae") vit sur les feuilles des plantes où il tisse des toiles de soie, l'acarien rouge des pomacées ("Panonychus ulmi") est pathogène de la vigne et des arbres fruitiers. "Eriophyes vitis" provoque l'érinose de la vigne (déformation des feuilles).

La famille des Podapolipidae parasite communément les arthropodes dont les abeilles sont affaiblies par la pullulation des Varroas, acarien impliqué dans le syndrome d'effondrement des colonies d'abeilles.

Les "ixodes" ou tiques se fixent sur les mammifères et les oiseaux et sucent leur sang (hématophage). Les tiques peuvent être des vecteurs de virus, de bactéries (spirochètes) et protozoaires pathogènes. Ixodes peut transmettre Brucella, l'agent de la brucellose. "Ornithodoros moubata" est une tique africaine transmettant à l'Homme "Spirochaeta duttoni" (agent de fièvre récurrente). En Amérique du Nord, les tiques du genre "Dermacentor" transmettent l'agent de la fièvre pourpre des montagnes rocheuses. 

"Trombicula autumnalis", ou aoûtats, parasite au stade larvaire les animaux à sang chaud (y compris l'Homme).

Ils pénètrent dans le derme (ectoparasites).

À titre d'exemple, les sarcoptes ("Sarcoptes scabiei") creusent des galeries dans l'épiderme des mammifères et causent la gale (y compris chez l'Homme).

Les acarologues considèrent les acariens comme une sous-classe divisée en deux Super-ordres, tandis que les autres arachnologues leurs conservent le rang d'ordre.
Liste des ordres actuelles selon :

Acaridae, Analgidae, Anystidae, Argasidae, Ascouracaridae, Atopomelidae, Bdellidae, Carpoglyphidae, Cheyletidae, Demodicidae, Dermanyssidae, Dermationidae, Epidermoptidae, Eriophyidae, Glycyphagidae, Halarachnidae, Ixodidae, Knemidokoptidae, Kytoditidae, Laelapidae, Laminosioptidae, Leeuwenhoekiidae, Listrophoridae, Macrochelidae, Macronyssidae, Microdispidae, Penthaleidae, Phytoptidae, Phytoseiidae, Psorergatidae, Psoroptidae, Pyemotidae, Pyroglyphidae, Rhinonyssidae, Rhynchaphytoptidae, Sarcoptidae, Sitercoptidae, Tarsonemidae, Tenuipalpidae, Tetranychidae, Trombiculidae, Trombidiidae.

Les acaricides
Les prédateurs naturels





</doc>
<doc id="15727" url="https://fr.wikipedia.org/wiki?curid=15727" title="Arachnida">
Arachnida

Les Arachnides (Arachnida) sont une classe d'arthropodes chélicérés, terrestres ou aquatiques, souvent insectivores. C'est le groupe qui comprend, entre autres, les araignées, les scorpions et les acariens. Ils se distinguent au sein de l’embranchement des arthropodes par le fait qu'ils possèdent quatre paires de pattes, qu'ils n'ont ni ailes ni antennes, et que leurs yeux sont simples (ocelles) et non composés. La plupart des arachnides sont ovipares et les sexes sont généralement de morphologies distinctes (dimorphisme sexuel).

Le nom de la classe tire son origine du mot grec "arachné", qui signifie « araignée ».

Les premiers arthropodes à pinces du sous-ordre des chélicérés sont apparus il y a environ 540 millions d'années, pendant le Cambrien, la plus ancienne des périodes de l'ère Paléozoïque. La plupart se sont adaptés à la vie terrestre. Puis, pendant le Silurien supérieur (il y a 440 millions d'années), apparaissent les premiers spécimens connus de scorpions et d'araignées fort semblables à ceux que nous pouvons trouver de nos jours.

On a recensé environ espèces d'arachnides, dont plus de de scorpions et espèces d'araignées, vivant dans tous les biotopes, des régions tropicales aux régions polaires. La plupart des arachnides sont cependant terrestres.

L'organisation interne est surtout remarquable par les poumons, ou "phyllotrachées", sortes de poches s'ouvrant à l'extérieur par les stigmates, et contenant une série de feuillets parallèles, à paroi mince, à travers lesquels se font les échanges gazeux.

Le céphalothorax porte les quatre paires de pattes locomotrices, ainsi que les pédipalpes, ou pattes-mâchoires, situés à l'avant du prosoma. Ces pédipalpes jouent un rôle essentiellement tactile. Le prosoma porte également une paire de chélicères, prolongés par un crochet à venin. Le céphalothorax est fortement chitinisé chez les arachnides, procurant à l'animal une protection appréciable. Cependant, la rigidité de cette carapace contraint les membres de cette classe à des mues de croissance périodiques.

L'abdomen est segmenté chez les scorpions, mais non segmenté chez les araignées et les acariens. Il ne l'est que faiblement chez les opilions. On estime que l'importance de la segmentation abdominale est un indice du degré d’évolution : les scorpions, à l'abdomen très segmenté, sont ainsi considérés comme l'ordre le plus primitif de cette classe ; les acariens, à l'abdomen peu ou apparemment pas segmenté, sont considérés comme l'ordre le plus évolué de la classe. Cette estimation s’appuie sur ces considérations morphogénétiques, mais aussi sur l’âge respectif des fossiles découverts pour les différents arachnides.

Chez certains ordres comme les solifuges, les pédipalpes sont très développés et ressemblent à des pattes. Il s'agit bien cependant d'organes différents : les pattes comprennent sept articles, tandis que les pédipalpes n'en comprennent que six. En outre, la base des pédipalpes est souvent pourvue de soies en forme de peigne sur la face intérieure, de manière à servir de filtre devant l'orifice buccal. Enfin, les pédipalpes ne jouent aucun rôle dans la locomotion.

Le langage courant considère souvent que les araignées sont des insectes ; pour le zoologue, elles se distinguent de ceux-ci par le nombre des pattes : huit chez les arachnides, six chez les insectes.

Liste des ordres actuels selon :





</doc>
<doc id="15729" url="https://fr.wikipedia.org/wiki?curid=15729" title="Astrologie">
Astrologie

L'astrologie est un ensemble de croyances et de pratiques qui n'entrent pas dans le domaine du rationnel basées sur l'interprétation symbolique des correspondances supposées e₯ntre les configurations célestes (la position et le mouvement des planètes dans le système solaire ou des constellations dans le cosmos) et les affaires humaines, collectives ou individuelles. Ce parallélisme conjecturé fait que l'astrologie, outre l'analyse de l'existant, est souvent utilisée comme outil divinatoire.

Le présent article est consacré à l'astrologie occidentale, à laquelle renvoie généralement le terme "astrologie". Il s'agit de celle qui est partie de Sumer, a influencé l'Égypte, a dominé Babylone, et s'est démocratisée en Grèce, d'où elle nous est parvenue grâce à la médiation des Arabes. Si, selon Wilhelm Knappich, la forme la plus ancienne sous laquelle a été pratiquée l'astrologie est l'astrologie mondiale, les horoscopes des revues ou les affinités des signes du zodiaque sont ses versions populaires actuelles à l'heure de l'individualisme moderne. Si ces dernières sont généralement considérées comme des échos lointains et déformés de l'astrologie historique, elles en restent la manifestation et l'expression la plus répandue.

Les scientifiques considèrent l'astrologie comme une pseudo-science ou une superstition, l'ensemble des recherches menées depuis l'Antiquité ayant abouti au fait que l'astrologie se place, par sa méthode-même, en dehors du domaine scientifique.

Face à ces considérations, les défenseurs de l'astrologie tendent presque tous à en réduire le caractère déterministe, élément nécessaire pour utiliser le mot de . Luc Bigé, Docteur ès science en biologie et chercheur en astrologie, affirme que l'astrologie n'est pas une . Selon d'autres astrologues, leur discipline n'a même pas pour but premier la prédiction de l'avenir, l'astrologie pouvant notamment être une voie du développement personnel.

Les croyances associées à l'astrologie restent populaires (voir ci-après). Un sondage mené en France indique qu'entre 30 et 40 pour cent des concitoyens accorderaient du crédit à l'astrologie.

Le mot « astrologie » vient du grec "αστρολογία", de "άστρον", "astron" (« étoile ») et "λόγος" ("logos"), dont la signification est liée à la notion de « discours » (λογία est un suffixe désignant d'une manière générale une discipline ou une matière d'enseignement). Étymologiquement, l"'astrologie" est donc le « discours sur les astres » : elle s'intéresse principalement au soleil et aux planètes du système solaire et, dans une moindre mesure, aux étoiles (Spica, Antarès, Regulus, par exemple) et aux nébulosités (Andromède), appelés astres fixes ou étoiles fixes.

On rencontre souvent l'affirmation selon laquelle les Anciens ne distinguaient pas l'astrologie de l'astronomie. Les astronomes grecs de l'Antiquité, même s'ils ne l'affirmaient pas explicitement, faisaient clairement la différence. Ptolémée traite d'astronomie et d'astrologie dans deux ouvrages distincts, respectivement l"'Almageste" et le "Tetrabiblos".

L'astrologie s'est toujours nourrie des découvertes de l'astronomie.
En effet, l'astrologie se fonde sur des calculs astronomiques pour établir les thèmes astraux, et souhaite utiliser les éphémérides les plus précises possible pour déterminer les positions des corps célestes.
En outre, avant la diffusion à grande échelle de ces éphémérides (ou des logiciels qui les incluent), l'astrologue devait lui-même, et souvent à l'œil nu, déterminer les positions des astres. Il fallait donc nécessairement être aussi astronome avant de prétendre être astrologue.

Selon Geoffrey Cornelius et Paul Devereux, « plus d'un site archéologique antique présente des preuves irréfutables d'un alignement avec des phénomènes tels les levers de Soleil aux solstices et équinoxes, les couchers de Lune aux maxima et minima de déclinaison et, parfois, avec les étoiles ou les planètes ».

Pour l'observateur contemporain comme pour son ancêtre paléolithique, le ciel nocturne est un motif d'émerveillement. La Voie lactée a été vue dans la plupart des cultures comme une sorte d'élément fluide primordial (Voir Interprétations mythologiques de la Voie lactée). Sur un plan astronomique, nous « venons » effectivement de ce grand ensemble—c'est notre galaxie.

Ce n'est que bien plus tard dans l'histoire, avec Aristote, qu'allait être introduite la spéculation que la Voie lactée n'était qu'un phénomène atmosphérique infralunaire, croyance qui allait perdurer jusqu'au Moyen Âge.

Les astérismes sont reconnaissables par l'astronome moderne comme pour l'observateur paléolithique parce qu'ils présentent des régularités, que l'on nomme gestalts. La façon dont les observateurs perçoivent, de façon reproductible et prévisible, les constellations est un exemple paradigmatique dans la théorie de la perception gestaltiste.

Cependant, ce spectacle nocturne est remarquablement immuable. Si l'on excepte les occasionnelles météorites, seules les planètes (et bien entendu la Lune) se meuvent dans le ciel nocturne, sur ce qui semble être un chemin : l'écliptique. Ce sont ces processions, perçues comme irrégulières, et ces occasionnelles conjonctions qui sont les bases empiriques des théories astrologiques. Mercure et Vénus, qui sont plus proches du Soleil que l'est la Terre, semblent accompagner le Soleil, se trouvant tantôt « devant », tantôt « derrière » celui-ci (sur le chemin de l'écliptique), ce qui donnera lieu à des explications animistes. 

Selon certaines analyses, l'astrologie serait née du constat de "relations entre des phénomènes terrestres et ces mouvements apparents" (comme les saisons ou la conjonction entre la position de la Lune et du soleil et les marées) conduisant l'homme à créer un lien de cause à effet entre eux et parfois à diviniser les corps célestes. Dès lors, un travail d'observation (calcul des éphémérides, production de calendriers) aurait été mené de front avec un travail distinct d'interprétation d'abord à partir du soleil et de la lune seulement (« Luminaires ») puis à partir de l'ensemble connu des corps célestes du système solaire.

L'idée d'une "correspondance symbolique" entre la configuration céleste et les affaires du monde a progressivement conduit à la construction d'un symbolisme astrologique.

Cette correspondance n'est d'ailleurs pas toujours analysée comme une "influence" des astres sur les affaires du monde (par laquelle l'humain ou les circonstances seraient déterminés par la position des astres, l'interprétation la plus populaire de l'astrologie), mais comme un "miroir" céleste des affaires du monde, qui ne l'influence pas mais le reflète, une lecture de la vie offerte aux hommes par les forces de la nature.

Les différents niveaux d'interprétation (conjectures physiques et conjectures humaines) cohabitent un certain temps, puis vont progressivement en se dissociant. Ce développement des pratiques donnera naissance à l'astronomie (qui s'en tient à l'observation, à la description et aux prédictions calendaires), laissant à l'astrologie les aspects ésotériques de conjectures sur les liens entre le ciel et la conduite des activités humaines.

Son support étant les astres, l'astrologie est l'une des pratiques divinatoires particulièrement répandues dans l'histoire des cultures. On peut ainsi citer l'existence spécifique d'astrologies maya, arabe, égyptienne, chinoise, indienne et bien sûr occidentale (dont il est principalement question dans cet article).

Les astres et en particulier la lune et le soleil forment un calendrier naturel avant que les calendriers humains ne soient formalisés. Leur déplacement permettait de prédire les saisons, ou l'éclairage de la nuit par la lune. Cela a par la suite donné les calendriers lunaires, solaires, et luni-solaire.

Les premiers écrits connus concernant les astres remontent à , sous la forme de tablettes d'argile sur lesquelles ont été consignés tous les relevés des mouvements planétaires observés par des prêtres érudits de Mésopotamie. Ces observations étaient faites dans un cadre religieux. Le mouvement des astres étant perçu comme volonté divine, les prêtres ou astrologues servaient de traducteurs. Leurs connaissances étaient celles d'initiés, les enseignements des temples étant tenus secrets. L'astrologie fut longtemps le privilège des seuls souverains. Cela peut être considéré comme l'origine de l'astronomie. La fonction de prêtre était liée à celle d'astrologue, car dans l'esprit des Babyloniens, des sacrifices ou des rites expiatoires pouvaient concilier les dieux. Le déterminisme astral pouvait en principe être , selon eux, par la magie. Le "fatalisme astral" se développa tardivement, après la conquête de la Babylonie par le roi Perse Cyrus en 539 av. J-C. et la confrontation avec la doctrine de Zarathoustra, qui impliquait un destin individuel, et plus seulement collectif.

La croyance en la prédétermination du caractère et de la destinée ouvrit la voie à l'astrologie individuelle. Les plus vieux "horoscopes" connus proviennent de Babylone et datent de 410 av. J.-C.. L'historien W. E. Peuckert parle d'une première division du zodiaque en onze secteurs opérée par les Sumériens qui serait devenue une division en douze secteurs du fait des Babyloniens. Selon Jean-Pierre Nicola , les premiers thèmes astraux individuels sont apparus lors du avant notre ère, avec une référence à douze signes"'. Ces douze signes sont énumérés dans un texte cunéiforme datant de 419 ; il s'agissait alors d'un "zodiaque sidéral" (correspondant aux constellations du zodiaque).

Parallèlement à cette astrologie, des systèmes différents se forment en Chine, en Amérique précolombienne et sans doute dans d'autres civilisations. Mais l'astrologie chinoise et l'astrologie chaldéenne sont les seuls systèmes ayant perduré jusqu'à nos jours. Tous les systèmes d'astrologie actuellement connus dérivent d'un de ces deux systèmes (ou des deux, cas de l'astrologie tibétaine).

En Inde, les astrologues n'étaient pas d'anecdotiques prédicateurs. Ils avaient construit une « science des lumières célestes » et proposaient des remèdes pour les soucis du quotidien.

De Chaldée, l'astronomie-astrologie se répand en Grèce après les conquêtes d'Alexandre le Grand. De là, elle se diffusera dans tout l'empire grec, en Inde, en Égypte puis jusqu'à la Rome antique tout en devenant plus structurée, moins religieuse et donc plus populaire. En Grèce, Hippocrate et Galien (à l'exemple, sans doute, des prêtres égyptiens) feront de l'astrologie l'un des fondements de la médecine, associée à la théorie des quatre éléments qui existait déjà auparavant. Hippocrate dit que nul ne peut exercer l'art médical sans connaitre l'astrologie. Platon tient les astres pour « vivants divins et éternels », des « dieux visibles » ("Timée", 39e-40d).

Dans son "Histoire de l'astrologie", Wilhelm Knappich a écrit : 
La première synthèse magistrale de l'astrologie occidentale, le "Tetrabiblos", fut écrite par l'alexandrin Ptolémée à l'époque de la domination romaine en 140, posant les principes de ce qui va devenir l'astrologie moderne. Ce dernier a laïcisé l'astrologie hellénistique, ne faisant pas référence aux dieux grecs dans son exposé théorique, ce qui a permis sa large diffusion dans les mondes arabe et chrétien du Moyen Âge. Compilateur plutôt que praticien, à la différence de Vettius Valens, Ptolémée a cherché à bâtir un modèle rationnel pour l'astrologie basé sur la doctrine aristotélicienne causaliste et il a écarté les éléments qui le gênaient. En particulier, les maisons astrologiques se voient attribuer une faible importance dans le "Tetrabiblos" alors que Vettius Valens, qui est jugé plus représentatif des pratiques horoscopiques de cette époque, leur a accordé une grande place dans son œuvre.

Successeur d'Hipparque, qui a découvert la valeur de la précession des équinoxes, Ptolémée a remplacé le "zodiaque sidéral", qui prenait pour point de repère une étoile fixe, par le "zodiaque tropical" commençant au point vernal. D'autres l'avaient précédé dans cette démarche, mais c'est l'autorité de Ptolémée, le dont le Tetrabiblos a influencé toute l'astrologie occidentale, qui fit vraiment école.

En l'an 529, l'empereur Justinien fit fermer les écoles de philosophie d'Athènes. Les érudits de l'époque, les maîtres du néo-platonisme, se réfugièrent à Gundishapur chez les Sassanides en Perse. L'astronomie, la médecine, la philosophie, etc. se développèrent intensément dans cette académie de Gundishapur où confluèrent des érudits de tous bords. Les conquêtes musulmanes s'emparèrent de Gundishapur qui avait une grande réputation. Cette école de Gundishapur eut une grande influence sur le développement de la civilisation arabo-musulmane. À la demande des califes, les auteurs de l'Antiquité, notamment Aristote furent traduits en arabe, souvent depuis le persan ou le syriaque. Vers 850, Alkindi (c'est-à-dire Ya' kûb ibn Isâk Sabbâh al Kindi), originaire de Bassorah, traduisit de nombreux textes en arabe, dont ceux d'Aristote, mais il écrivit aussi plus de sur tous les sujets possibles, dont l'astronomie, qui à l'époque ne se distinguait pas de l'astrologie. Une de ses contributions la plus importante fut sa doctrine des conjonctions entre les planètes et leur influence sur les phénomènes naturels et sur les impulsions donnant naissance aux grands événements historiques. Son disciple, Albumasar (mort en 886) fut un astrologue de Bagdad qui propagea les idées d'Al-Kindi dans son « "Liber magnarum coniunctionum" » lequel eut une forte influence sur l'astrologie du Moyen Âge.

Un autre astrologue important fut Thébit (mort en 901). Il était Sabéen, originaire d'Harran, où il recueillit les connaissances astrologiques mésopotamiennes qui vinrent enrichir les connaissances arabo-musulmanes. Il vécut à Bagdad et devint l'astrologue du calife d'Antioche. Il enseignait notamment que chaque planète possédait un daemon, c'est-à-dire un esprit ou une intelligence qui la guidait. L'astrologie arabe s'est tout spécialement développée grâce à l'afflux des érudits perses, syriens, juifs, etc. qui à partir de 850 affluèrent vers les nouveaux centres intellectuels créés par les califes de l'Islam. Le Juif Mashallah par exemple vécut à la cour d'Al Mansur. Il fut l'auteur d'une vingtaine de traités d'astrologie. Un manuscrit arabe des et est le Kitab al-Bulhan.

Les astrologues arabes étaient très friands des "parts dites ", dont est restée la .

À la suite de l'occupation de l'Espagne par les Maures, l'astrologie revint en force dans la civilisation européenne au Moyen Âge. Pierre A. Riffard date le début de l'astrologie occidentale de 1135 avec la traduction de l'arabe à Tolède.

Pendant la période chrétienne, l’astrologie connaîtra une situation ambigüe. Mise au ban de la société par l’Église, comme toutes les pratiques divinatoires, lors du concile de Tolède de l’an 447. Pourtant, elle est pratiquée dans les cours royales, et continue à être étudiée par les érudits, même religieux (Albert le Grand, maître de Thomas d'Aquin, est l’auteur d’un traité d’astrologie). Charles s’occupait d’astrologie et fonda à Paris un collège d’astrologues. Louis consultait les siens en toutes circonstances. Catherine de Médicis avait fait élever en son hôtel (Hôtel de Soissons) une colonne qui aurait pu servir à consulter les astres. Elle rencontra Nostradamus et eût plusieurs astrologues personnels, dont le nommé Côme Ruggieri. Louis fut surnommé le juste, parce qu’il était né sous le signe de la Balance. L’astrologie est également en faveur sous les empereurs Charles, et Charles Quint avait prescrit l’enseignement de cette discipline, ce que préconisaient d’ailleurs beaucoup d’hommes éminents de l’époque. Elle fut à l’honneur à Rome sous les papes Sixte, Jules, Léon, et Paul.

L'invention de l'imprimerie (vers 1450) permit la diffusion d'éphémérides et d'almanachs, ce qui a contribué à l"'âge d'or de l'astrologie". Les éphémérides imprimées favorisèrent la précision de plusieurs techniques prévisionnelles, au rang desquelles on compte les progressions et révolutions solaires.

À la Renaissance, la découverte de l’héliocentrisme du système solaire, qui pourtant a été imaginé et défendu par les astronomes / astrologues de l’époque, vient mettre à mal, selon certains, l'anthropocentrisme de l’astrologie : Pic de la Mirandole (puis Jérôme Savonarole reprenant les arguments de celui-ci) l’ont largement condamnée. Ce n’est pas le cas d’astronomes et astrologues comme Galilée et Kepler de même que Tycho Brahe, ou Cassini, le premier directeur de l’Observatoire de Paris.

Dans la préface de ses "Tables Rudolphines", Kepler fait observer que l’astrologie, toute folle qu’elle est, est la fille d’une mère sage, et que la fille folle est indispensable pour soutenir et faire vivre sa mère. Ce commentaire sera interprété par Voltaire, dans son Traité sur la tolérance (1767), de manière restrictive : « La superstition est à la religion ce que l’astrologie est à l’astronomie, la fille très folle d’une mère très sage ». La citation de Kepler a été souvent reprise erronément, et l'est encore aujourd'hui pour soutenir la thèse que les grands esprits de la Renaissance comme Galilée, Cassini ou Kepler n'étaient astrologues que par contrainte, pour avoir les moyens de s'adonner à la véritable science :
Souvent les travaux astrologiques de Kepler et Tycho Brahe sont invoqués par les défenseurs de cette pseudo-science. Kepler est pourtant très clair sur sa valeur et justifie sans ambiguïté la pratique des prédictions en disant que la vénale astrologie permettrait à l'astronomie de vivre.
Elle ne visait pourtant que l'astrologie populaire, tant décriée pour ses excès et superstitions : « La philosophie, et par conséquent l'astrologie authentique, témoigne de l'œuvre de Dieu et est donc sacrée. Ce n'est en aucune manière une chose frivole. Pour ma part, je ne souhaite pas la déshonorer. » Dans le titre d'un manifeste adressé aux intellectuels de son temps, Kepler leur demande d'écouter, dans cette controverse sur l'astrologie, une troisième voix, d'où son titre abrégé, "Tertius Interviens" ("Warnung an etliche Gegner der astrologie das Kind nicht mit dem Bade auszuschütten" - « avertissement aux adversaires de l'astrologie afin qu'ils ne jettent pas le bébé avec l'eau du bain »). La première (celle des médecins, philosophes et théologiens) ordonne d'abandonner l'astrologie, qui ne serait qu'une superstition—la « fille folle de l'astronomie ». La seconde, celle des astrologues populaires, voudrait la conserver, avec toutes ses superstitions.

J'ai souvent exprimé combien il était mal avisé de rejeter une chose complètement à cause de ses imperfections; par ce procédé, même la science médicale n'aurait été épargnée (...) Un nombre modeste de prédictions d'événements (de nature générales) effectuées au moyen de la prédiction des mouvements célestes sont bien fondées dans notre expérience

Galilée, comme son confrère, ne doutait aucunement de la valeur de l'astrologie, bien au contraire : cela lui valut ses premiers ennuis avec l'Inquisition. Depuis le Moyen Âge, et Thomas d'Aquin en particulier, il s'exerçait une lutte d'influence au sujet des événements célestes : Roger Bacon, « père de l'empirisme moderne », en aurait été une des premières victimes, puisqu'il aurait été emprisonné pour avoir osé affirmer que la naissance de Jésus de Nazareth était sous l'influence d'une Grande Conjonction (conjonction Jupiter-Saturne). 
Le clergé surveillait ces astrologues qui, au cours de leurs prédictions, tendraient à franchir la limite qui sépare l'astrologie et la théologie, et remplaceraient la grâce de Dieu par le déterminisme des astres. Galilée, dont on a conservé notamment le thème et celui d'une de ses filles, voyait les planètes comme d'importants facteurs causaux dans le développement de la personnalité, sans toutefois être aussi déterministe que ses accusateurs le prétendaient. En effet, en 1604, un de ses domestiques, Signor Silverstro, l'aurait dénoncé aux autorités entre autres pour avoir professé une doctrine du fatalisme astral, pour ("haver ragionato che le stelle, i pianeti at gl'influssi celestine necessitino." « avoir raisonné que les étoiles, les planètes et les influences célestes déterminaient (les événements) », accusation de la plus grande gravité pour l'Inquisition.

Loin de se rétracter lors de la publication du texte fondateur de l'astronomie moderne, le Sidereus Nuncius, où il décrit le comportement des corps gravitant autour de Jupiter, il récidive, en appelant, comme il le fera lors de sa confrontation avec Bellarmin, à l'observation plutôt qu'à la théorie, à la persuasion des non-scientifiques plutôt qu'aux argumentations avec les tenants des dogmes établis.

Dès lors, il peut paraître étonnant que Galilée, tout comme Képler, aient entretenu des doutes sur la place véritable de l'astrologie au sein de la science. Tandis que Képler voyait dans la bonne astrologie une indication de tendances générales, et surtout une branche fondamentale de la philosophie, Galilée exprimait son étonnement devant le déterminisme astral absolu d'un Morin de Villefranche, mathématicien à Paris :

En France, sous la pression des jésuites, Colbert à l'Académie des Sciences en 1666 à la création de cette dernière. Le poste d’astrologue royal est supprimé à cette époque. Un "Essai de justification de l’astrologie judiciaire" (BM. Angoulême MS 23) 1696 ne sera jamais publié.

En Angleterre, elle ne sera rayée des disciplines académiques qu’un siècle plus tard. Isaac Newton l’étudie encore en université, « pour voir ce qu’il y a de vrai ». Pour des raisons religieuses, il s'opposait à l'astrologie judiciaire, mais ne contestait pas pour autant un lien astrologique entre les astres et les affaires humaines. Dans sa "Chronology of Ancient Kingdoms, Amended"("Chronologie des anciens royaumes, amendée"), il décrit comment l'astrologie serait née de sa mère, l'astronomie :

De fait, les premières tables lunaires calculées ensuite d’après la théorie de Newton, furent d’abord destinées à servir aux observations des astrologues.

Le judaïsme pour sa part, en dépit de mises en garde dans le Talmud à propos du "Mazal" – terme qui désigne les constellations – fait largement appel, au Moyen Âge, à l'astrologie pour ses commentaires de la Bible, notamment chez Abraham Ibn Ezra, par ailleurs auteur de traités d'astrologie qui seront traduits en ancien français et en latin. Mais l'influence de Maimonide marquera durablement le judaïsme moderne par son rejet de l'astrologie avec sa Lettre aux Juifs de Provence et son Épître au Yémen, où l'on dénonce l'incapacité des astrologues de Pharaon et de Nabuchodonosor de prévoir leur future débâcle.

L'astrologie est considérée par les penseurs des Lumières comme l'exemple archétypal de la superstition, de la croyance dans des forces occultes et supérieures. Pour eux, combattre l'astrologie semble relever d'un combat général ainsi que d'un engagement politique en faveur de la laïcité et du rationalisme, contre l'obscurantisme. Assez paradoxalement, leurs arguments critiques contre l'astrologie apparaissent moins logiques que rhétoriques (utilisation d'arguments principalement polémiques ou d'autorité plutôt qu'une démarche raisonnée).

Dans la toute fin du , époque du rationalisme triomphant, le divorce entre l'astronomie et l'astrologie est ainsi finalement prononcé. Le est scientiste. En France, l'astrologie se cantonne longtemps à des milieux ésotérico-clandestins (spirites, kabbalistes, théosophes...). Dans l'Empire britannique, son statut évolue avec le théosophe Alan Leo, qui en fait plus un outil d'analyse caractérologique que de prédiction, tout en soutenant que "Le caractère fait le destin".

Á partir de 1920, l'astrologie sort de la contre-culture et réapparaît dans des almanachs, magazines, puis émissions radiophoniques. L'astrologie trouve aussi une place considérable dans le mouvement "New Age". Ses nouvelles versions savantes affirment intégrer les valeurs symboliques des planètes orbitant au-delà de Saturne et des astéroïdes ainsi que de nouvelles théories, comme l'astrologie statistique.

L'astrologie rentre dans le champ scientifique au par la porte de la psychologie des profondeurs. Au cours de son exploration des symboles anciens, Carl Gustav Jung dit découvrir, contre toute attente, une relation tenace entre l'astrologie et la psychologie :

Par ailleurs, suite à la naissance de la mécanique quantique développée au début du , les astrologues qui se targuent de science revendiquent la remise en cause du principe de séparabilité. En effet, alors que selon la science classique, l'observateur est distinct de la chose observée, l'astrologie considère que l'homme est dans l'Infini et que l'Infini est extérieur à l'homme mais aussi que l'Infini est en l'homme, ce qui fonde une logique astrologique bien distincte de la Logique d'Aristote.

L'astrologie recouvre au début du des pratiques et des approches très différentes, au point qu'il est plus juste de parler d'astrologies au pluriel.

Il existe de nombreuses écoles : astrologie psychologique, astrologie conditionaliste, astrologie karmique, astrologie humaniste, astrologie sidérale"etc."

Ces pratiques astrologiques diffèrent à la fois par leurs symboliques, par les techniques utilisées, et selon les objets ou domaines auxquels elles sont appliquées, que ce soit par exemple en psychologie, ou comme technique de prévision, en politique, en bourse, en médecine ou encore à la marche du monde (Astrologie mondiale). La symbolique des astres et de leurs mouvements est très souple, pouvant changer suivant le contexte et l'école de l'astrologue. Chaque objet a des symboliques propres et parfois des techniques particulières.

Les astrologies les plus en vogue actuellement en occident sont l'astrologie occidentale, fondée sur le calendrier solaire, et l'astrologie chinoise, fondée sur le calendrier chinois. Cette dernière s'est répandue en Europe occidentale vers la fin des années 1970.

Si sa pratique de base reste l'établissement d'une carte du ciel, l'astrologie occidentale est en constante évolution, ce qui induit un certain nombre de divergences entre astrologues.
Ces divergences existaient dès l'époque traditionnelle, portant entre autres sur les différentes méthodes pour le calcul des positions des maisons, et renvoyant surtout à différentes écoles d'interprétation.

Au , l’astrologie connaît un regain d’intérêt avec une approche nouvelle. Des ingénieurs, psychologues et statisticiens abordent cette discipline à l'aide d'une approche statistique. Cette démarche rencontre très peu d'écho auprès des premiers concernés : les astrologues. Madame Soleil a déclaré : . Le "pourquoi?" ne l'intéresse pas, seul compte pour elle le "pour quoi?".

Aujourd'hui, on peut diviser l'astrologie occidentale en trois branches :


Ces pratiques sont aujourd'hui toutes sujettes à critiques et à controverses. Malgré l'apparence scientifique que pourraient donner l'usage affiché de calculs compliqués, la précision des dates de naissance (heure, géographie...) et le recours quasi systématique à l'ordinateur, l'astrologie est considérée comme une pseudo-science (ou superstition) par la communauté scientifique. Pour les astronomes notamment, le Soleil a été relégué au rang d'une étoile parmi d'autres au sein de la Voie lactée, laquelle a été ramenée au statut d'une galaxie parmi des milliards d'autres au sein du cosmos. Par ailleurs, comme le souligne l'historien de l'astrologie Jacques Halbronn, après la découverte de Neptune et de Pluton, l'astrologie s'est vue contrainte de retourner aux images pittoresques de la mythologie, ce qui lui ôte de la crédibilité scientifique.

Contrairement à des pratiquants d'autres disciplines ésotériques, certains astrologues annoncent qu'ils peuvent prévoir, notamment, des événements très précis et facilement vérifiables. En ce sens, des protocoles de tests permettant de les mettre à l'épreuve sont aisés à mettre en place. Ces protocoles comparent les prévisions des astrologues sur des sujets précis à des prévisions aléatoires émises par des sceptiques ou des ordinateurs. Les prévisions des astrologues sont alors validées si elles sont de meilleure qualité que les prévisions aléatoires. On peut citer le test sur vingt-deux prévisions de l'an 2000 entre Elisabeth Tessier qui écrit régulièrement qu'elle situe son niveau de réussite à 80 %, voire 90 %, un sceptique et un ordinateur. Résultat : Ordinateur huit réussites, Elisabeth Tessier et Sceptique sept réussites. De nombreuses expériences de ce type ont eu lieu.

Le cercle zététique de l’université de Nice a créé le Défi zététique international. L’intérêt de ce dernier test est qu’en échange d’un test gratuit, l’astrologue reçoit en cas de succès. Comme le risque financier est nul pour un gain potentiel énorme, on peut estimer que les astrologues ne se présentant pas à ces tests ne croient pas à leur don. Après quelques années de fonctionnement, très peu d’astrologues ont concouru, le test fut arrêté faute de combattants.
Toutes disciplines confondues, il y a eu et aucun réussi.

Un autre test réalisé sur cent personnes qui jugeaient l'exactitude des prévisions que l'on faisait sur eux montrait que les astrologues avaient exactement le même taux de succès qu'un système aléatoire.

En 1993 paraît dans "Les cahiers conditionnalistes" une étude statistique non scientifique qui vise à démontrer une corrélation entre les aspects Mercure-Saturne et les qualités de joueur d'échecs.

L'astrologie statistique est d'ailleurs une activité très marginale, dont les principes méthodologiques de base ne sont pas nécessairement (re-)connus des astrologues.

Les prédictions et les conjectures astrologiques sont soumises à la double question de la précision de l'information formulée et de la subjectivité de son destinataire. Il semble intéressant pour qui manipule les résultats d'une prédiction d'analyser le degré d'information qu'elle contient, c’est-à-dire à la fois son caractère informatif réel (voir effet Barnum) et la quantité d'éléments présentés.

Plusieurs éléments cités aux points précédents ("confrontation à un échantillon témoin" et "approche statistique") apportent une explication objective à l'existence de nombreux succès prédictifs de la part des astrologues.

En effet, l'illusion statistique qui consiste à ne présenter que les « succès » (cas des fraudes caractérisées) soit à ne se souvenir que des prédictions efficientes (phénomène purement psychologique) explique de façon rigoureuse une partie réelle des succès présents dans l'imaginaire populaire.

Par ailleurs, certains succès prédictifs s'expliquent par la probabilité objective de l'occurrence d'un évènement.

Exemple fameux : prédire la mort d'un pape dans l'année, durant les dernières années de la vie de Jean-Paul, était pour les astrologues un pari apparemment facile au vu de la très mauvaise santé du souverain pontife. Sa longévité a infirmé année après année ces prédictions, présentées comme solides. Il est à noter que l'année de sa mort, ces mêmes astrologues pouvaient comptabiliser cette prédiction comme un « succès ».

Les bilans prédictifs des astrologues (récapitulation des prédictions justes, au terme d'une série de séances ou d'une année) ne présentent généralement que les « succès » prédictifs, occultant les erreurs. Si l'on suppose la précision égale des prédictions, cette comparaison s'avèrerait pourtant intéressante. La constitution d'un grand nombre de ces bilans prédictifs par les zététiciens démontre, selon le modèle présenté plus haut, que les succès sont attribuables au hasard dans tous les cas étudiés.

Les résultats étant toujours présentés comme liés au « talent » et à l'expérience de l'astrologue (pour être recevable aux yeux de ses défenseurs, l'analyse doit être faite par un « praticien compétent »). Dès lors, il est impossible d'étudier les méthodes astrologiques actuelles selon les critères scientifiques de reproductibilité.

Cet aspect est vivement critiqué par les sceptiques, cet argument précis étant justement utilisé par les charlatans pour opérer une sélection a posteriori de leurs prédictions.

Il a été démontré par Henri Broch que la variabilité des résultats présentés par des sujets réputés doués correspond précisément aux résultats de prédictions « aléatoires ». Cette démonstration, très facilement reproductible, est consultable dans l'ouvrage "Devenez sorcier, devenez savant".

Le medium Bertrand Méheust, dans son ouvrage "100 mots pour comprendre la Voyance", critique les méthodes zététiciennes, en particulier celles qui sont pratiquées dans l'ouvrage "Devenez sorcier, devenez savant", et estime que, dans leur livre, Henry Broch et Georges Charpak citent principalement des expériences spontanées de la vie courante, facilement discréditables, et ignorent l'existence de chaires universitaires de parapsychologies (et donc de travaux parapsychologiques de niveau universitaire) dans beaucoup de pays développés (mais pas en France, cependant) :

«" Les auteurs ne se proposent pas d'examiner les travaux de la métapsychique, ce qui aurait été une entreprise constructive. Ils se proposent plutôt de ruiner, dans l'esprit du lecteur non averti, l'idée même qu'une telle entreprise eu pu avoir l'intérêt le plus ténu, en se gardant de lui présenter les éléments qui lui permettraient d'utiliser son jugement. En traitant le sujet sur un ton léger, ils font passer le message qu'il est sans consistance. [...] Les exemples sont toujours pris dans le répertoire non-épuré de la vie quotidienne ; ils ne mettent jamais en scène des parapsychologues au travail dans des situations construites, mais des observateurs naïfs en train de se divertir dans un salon à la fin d'une repas (). Après avoir ainsi campé l'adversaire, il leur est aisé de dénoncer l'appel universel à l'« expérience personnelle », et l'illusion qu'elle puisse constituer une preuve (). En bref, ils se comportent comme des experts qui pour accabler la compagnie des eaux, se débrouillent pour effectuer leurs prélèvements en amont de l'usine d'épuration, au lieu de le faire en aval. Tout est l'avenant dans « Devenez sorcier, devenez savant ». Une telle manière de faire relève plus de l'idéologie que de la science. "».

Il existe un grand nombre de pratiques astrologiques différentes, mais certaines constantes se dégagent :

L'astrologie est l'étude des relations supposées entre les affaires terrestres et les phénomènes célestes en général.
Plus précisément, elle repose sur 4 cycles principaux et leurs applications analogiques :

À partir de ces cycles, ont été mises au point diverses techniques, dont les principales utilisent :

- la position des planètes, des luminaires (Soleil et Lune), des comètes et des astéroïdes (depuis leur découverte au ) :

- les cycles de ces corps célestes et de certains axes (axe des éclipses, axes des équinoxes et des solstices, essentiellement) :

Dans la pratique astrologique concrète, de nombreux éléments sont utilisés.
Ces éléments sont principalement :
À ceci s'ajoutent les significations des diverses interactions de ces éléments :
À ceci s'ajoutent enfin, pour l'astrologie dite prédictive :

Si astrologie et astronomie ont en commun leurs racines historiques, les deux pratiques sont maintenant détachées et distinctes. L'astrologie ne peut être élevée au rang des sciences physiques en raison de la maigre reproductibilité de ses résultats, de l'absence totale de modèles d'explication, et de l’absence de causalité établie. Certains invoquent un phénomène "acausal" (sans lien de cause à effet), la synchronicité jungienne.

L"'astrologie occidentale" (tropicale) soutient que les influences sont le fait des planètes et non des étoiles (qui sont à des années-lumière de nous, et qui sont prises en compte par l'astrologie sidérale). En d'autres termes, l'astrologie tropicale ne s'intéresse qu'à des corps appartenant au système solaire, et à leurs déplacements par rapport au zodiaque tropical, qui est délimité par les axes des solstices et des équinoxes.

Le zodiaque dit tropical est le "zodiaque des saisons". L'animation ci-contre, qui décrit les quatre cas de figure correspondant aux levers et couchers du soleil au début de chaque saison, s'applique également aux planètes du système solaire, puisqu'elles sont toutes plus ou moins sur l'écliptique (qui est représenté ici par le disque bleu). Se levant vers l'est et se couchant vers l'ouest, ces quatre sphères représentant le soleil décrivent le comportement des planètes sur le plan de l'écliptique, à la différence près que leurs levers et couchers peuvent survenir à n'importe quel moment de la journée (exceptions faites de Mercure et Vénus, dont le passage à l'horizon est toujours juste « avant » ou juste « après » celui du soleil). Le cercle vert « en bas », au sud, correspond au tropique du Capricorne et au signe ainsi nommé; le cercle « en haut », au nord, correspond au tropique du Cancer et au signe qui porte ce nom. Ainsi, une planète en Capricorne est une planète qui, comme le soleil au début de l'hiver, séjourne longtemps chaque jour sous l'horizon, invisible, et s'élève peu dans le ciel (pour les latitudes Nord). Une planète en Balance, comme le soleil à l'automne, a un comportement « équilibré », en ce qu'elle passe autant de temps visible qu'elle en passe sous l'horizon.

Les douze divisions du zodiaque tropical sont fondées sur ces données de base. Les signes cardinaux sont définis par les axes des solstices et des équinoxes et correspondent aux premiers mois de chaque saison; les signes mutables sont ceux qui précèdent les signes cardinaux (ce sont les signes des "mutations" qui précèdent l'avènement d'une nouvelle saison) et les signes fixes sont les quatre secteurs de l'écliptique qui restent, qui ne se définissent pas par rapport à un seul axe, mais deux. Les signes fixes sont plus difficiles à circonscrire, selon les astrologues.

Ce système ne dépend pas de la position des constellations.

L'argument d'une influence gravitationnelle a parfois été avancé pour justifier l'existence d'une action à distance, et de ce fait, certains astrologues font des calculs astrologiques sur une base héliocentrique, ce qui pourrait sembler cohérent avec l'explication d'une influence gravitationnelle des configurations planétaires sur l'activité solaire.

À ce jour, aucun effet direct des planètes sur le corps humain n'a été rigoureusement observé. Par ailleurs, les forces d'attraction en jeu lors du simple phénomène d'attraction Terre-Lune sont, à l'échelle du corps humain, infiniment moins importantes que ceux qu'exercerait un immeuble ou une armoire.

Enfin, les recherches statistiques (voir Étude statistique de l'astrologie) qui auraient pu permettre de déceler une régularité des phénomènes astrologiques (influences) ne permettent pas de conclure à l'existence d'une telle régularité.

Les signes du Zodiaque, qui servent de cadre de référence et d'analyse, correspondent par analogie à des constellations situées sur l'écliptique. Or un astronome de l'Antiquité (Hipparque) a publié ses observations, qui n'ont jamais été démenties depuis plus de deux mille ans, et qui prouvent de façon irréfutable que le même jour de l'année, à la même heure, d'un siècle à l'autre, les étoiles et les constellations ne sont pas vues dans la même direction. Ce phénomène de la précession des équinoxes entraîne un décalage de plus en plus grand au fil du temps entre la position des astres dans le zodiaque (tropical, dont le point zéro est le point vernal), et leur position dans les constellations dont elles tirent pourtant leurs noms. Le décalage est actuellement de 25°. 

La constellation du Serpentaire (Ophiuchus) (située entre celles du Scorpion et du Sagittaire) n'a été officialisée qu'en 1930 par les astronomes de l'Union Astronomique Internationale, lorsque, pour la première fois dans l'histoire de l'astronomie, ont été définies les limites officielles des constellations (auparavant ces limites variaient d'un atlas astronomique à l'autre, voire d'une tradition à l'autre).

En astronomie, le zodiaque des 12 signes "astronomiques" et celui des 13 constellations "astronomiques" ne sont donc que deux systèmes de repérage "astronomique" des positions des astres sur la voûte céleste ; autrement dit, des systèmes astrocartographiques choisis parmi une infinité d'autres systèmes possibles et imaginables (Serpentaire (astrologie)).
Par contre, avec le zodiaque tropical, la logique est différente.

D'après Dane Rudhyar, par exemple (dans son livre "La Pratique de l'Astrologie") :

« "La majorité des partisans et des contempteurs de l'astrologie n'ont pas encore compris que les signes du zodiaque n'ont rien à voir avec les étoiles et les constellations, mais représentent simplement 12 phases au sein de la relation cyclique entre la Terre et le Soleil. "»

Ceci posé, et étant donné que l'axe des solstices et des équinoxes est une des bases de l'interprétation symbolique de la relation entre la Terre et le Soleil, il est logique de faire démarrer le zodiaque au point équinoxial vernal (ou à la rigueur au point opposé, ou bien à l'un des points solsticiaux, qui sont situés à 90° de part et d'autre des points équinoxiaux).

Et ensuite, la solution la plus logique (car la plus simple) est de découper le zodiaque "astrologique" en secteurs "réguliers" à partir du point de départ choisi.

Choisir des secteurs réguliers constitue même un choix plus crucial que le choix du point de départ parmi les 4 points possibles. En effet, en astrologie, un découpage "régulier" du ciel en 13 au lieu de 12, ou même en n'importe quel autre nombre, est parfaitement envisageable et pertinent, et est parfois pratiqué. Mais cependant, il ne faut pas perdre de vue que le découpage astrologique en 12 a sa raison d'être. Cette raison d'être, à la fois pratique et symbolique, se ramène tout simplement au fait qu'il est bien plus facile découper un cercle en 12 (ou en 2, 3, 4, 6, 8, 16) qu'en 13 (ou en 5, 7, 11, 17, 19, 23, etc).

Mathématiquement, la décomposition arithmétique de 12 en une multiplication d'entiers naturels, donne des factorisations de nombres simples, dont certains peuvent même être premiers (12 = 2×6 = 3×4 = 2×2×3). À l'inverse, 13 est un nombre premier ; en tant que tel, on ne peut que le multiplier, mais non pas le diviser en parties égales. Ce nombre n'est donc pas très favorable ni à un découpage pratique du ciel céleste, ni à une utilisation en tant que trame d'interprétation de la complexité astrologique, car il induit déjà lui-même une trame d'interprétation déjà complexe.

Cela est du au fait que comprendre la logique d'une succession de phases est bien plus facile avec 12 phases (ou 2, 3, 4, 6, 8, 16), qu'avec 13 phases (ou 5, 7, 11, 17, 19, 23, etc.). Tout simplement parce qu'on peut découper tout ensemble d'éléments comportant un nombre pair d'éléments (et supérieur à 4), en groupes plus petits mais égaux entre eux, qui sont plus faciles à percevoir et à comprendre (4 = 2×2) (6 = 2×3) (8 = 2×4 = 2×2×2) (12 = 2×6 = 3×4 = 2×2×3).

(Le même phénomène se retrouve en musique, où les rythmes impairs, surtout s'ils sont premiers (et sauf ceux à 3 temps), sont plus rarement utilisés que les rythmes pairs).

Au passage, on peut remarquer que l'astrologie utilise également le découpage en 360 degrés (360 = 2×2×2×3×3×5), mais surtout à des fins de repérage des aspects entre les positions des composantes utilisées (planétaires ou autres). Certes, des ensembles de 360 Images Symboliques sont parfois utilisés en astrologie pour affiner l'interprétation (par simplification, ces ensembles sont appelés Degrés Symboliques) ; mais la compréhension à la fois globale et détaillée de la logique de la succession d'un si grand nombre de phases est une branche difficile de l'astrologie.

En résumé, les découpages à base de nombres entiers impairs (qui peuvent être premiers) (supérieurs à 3) ont tout leur sens en symbolique (astrologique ou autre), mais la signification symbolique de ces découpages est plus complexe que celle des découpages construits à base de nombres entiers pairs.
Pour ces raisons au moins, le Serpentaire (Ophiuchus) n'a donc jamais fait partie des éléments astrologiques utilisés dans la pratique astrologique courante des astrologues traditionnels, contrairement aux constellations et/ou signes du zodiaque, qui sont connues depuis l'Antiquité. (Cela n'ôte rien à la signification mythologique qui est attachée à ce symbole).

En résumé, si les astrologues contemporains ne tiennent pas compte des changements dans le découpage du ciel introduits par les astronomes des siècles modernes, c'est parce que ces changements ont été effectués pour de simples raisons de facilitation de la pratique astrocartographique, et non pas pour des raisons astrologiques.

Ce ciel, avec les cycles qu'il recèle, les astrologues l'observent depuis plusieurs millénaires, selon leurs propres critères, qui sont basés sur des besoins différents de ceux de l'astronomie, comme celui de se fixer sur les saisons pour établir les signes (d'où le nom de tropical, pour le tropique du cancer et celui du capricorne, qui commencent le cancer et le capricorne selon ce système), opposé au zodiaque sidérale, qui lui est conforme à l'astronomie.

Le problème posé est qu'en supprimant le rapport entre constellations et signes, on nie la causalité entre les deux. Le phénomène mystique, certes peut-être incompris mais censé être réel, de l'influence desdites constellations sur les personnalités et les évènements ne compte plus. On devrait observer empiriquement un décalage de correspondance des personnalités à leurs signes respectifs par générations comparativement à ce qui est décrit sur le papier.

Le symbolisme des signes astrologiques est lié à la saison prévalente dans l'hémisphère nord (le Bélier est le signe du printemps, le Capricorne est le signe de l'hiver, etc.), mais dans l'hémisphère sud, les saisons sont inversées, ce qui n'est pas sans poser un problème quant à la validité du modèle astrologique. Les partisans de l'astrologie sidérale trouvent là un argument pour défendre leur cause. Un partisan de l'astrologie tropicale, François Villée, résout ce problème en disant que chaque signe a un signe opposé qui lui est complémentaire dans sa façon principale d'aborder l'existence, d'où la nécessité de .

En parallèle à l'astrologie traditionnelle ou traditionaliste, il existe d'autres courants de pensée.

Celui des astro-psychologues, qui développent une astrologie basée sur les théories de la Psychologie et la Psychanalyse.

Ce courant rejette la démarche scientifique appliquée à l’astrologie, et en récuse le bien-fondé.

Carl Gustav Jung défend les concepts de symbolisme, de synchronicité et d’archétype, et craint que « l’influence niveleuse des grands nombres» rende impossible de prouver quelque chose par la méthode statistique dans le domaine de l’astrologie.

Dane Rudhyar, promoteur d’une astrologie humaniste, déclare que « l'astrologie n'a pas pour objet principal et immédiat de prédire des événements sous forme de probabilités statistiques, mais d'enseigner […] l'ordre et la « forme » qui font le sens de l'existence individuelle et des luttes jalonnant le chemin de la réalisation de soi ».

Le corpus astrologique devrait ainsi être considéré comme une « modélisation » empirique, établie génération après génération, de la relation de l'être humain avec l'Univers. L'astrologie placerait l'être humain au centre de son questionnement, et ainsi donc, quand elle se centre sur la Terre et non sur le Soleil, même à l'heure où l'on sait que la terre n'est pas le centre du système solaire, elle ne fait que poursuivre sa propre « logique » ou étayer la cohérence de son « logos ».

C'est pourquoi, dans le cadre de ce courant de pensée, on peut affirmer que l'être humain sur la Terre reste le postulat de base de la « science » astrologique, qui reste fondamentalement géocentrique (et non héliocentrique). Du moins tant que l'être humain continuera à n'habiter que sur Terre. On peut alors résoudre le problème du décalage du référent de l'astrologie (le Zodiaque tropique) avec la réalité physique qui a fait dire aux astronomes que l'astrologie n'a rien de « scientifique » ; car ces derniers ne se réfèreraient qu'à « leur » cohérence, et non à celle de l'astrologie qu'ils méconnaissent le plus souvent.

Pour certains astrologues, ce décalage aurait une pertinence (sauf pour l'école sidéraliste, qui ne se fie qu'aux constellations), et serait même fondamental. Car c'est sur ce décalage, dû à la précession des équinoxes, que se fonde leur théorie des âges ou ères astrologiques, dont la fameuse Ère du Verseau à venir.

Selon Laurence Larzul, c'est dans une nouvelle mouvance d'esprit, née des Rencontres d'Eranos, (lieu de rencontre de Jung et d'autres personnes dont l'influence a été majeure sur la pensée scientifique du , avec notamment « le père » de l'histoire des religions : Mircea Eliade), ainsi que Wolfang Pauli, l'un des pères de la théorie quantique, que s'inscrirait l'astrologie contemporaine.

En conformité avec son école, qui affirme tenir davantage à la connaissance de soi qu'à la prédiction, Laurence Larzul est en effet revenue à une considération plus « chamanique » du rôle de l'astrologue.
Ceci jusqu'à voir en l'astrologie une forme de « chamanisme évolué », puisque cette connaissance serait fondée sur l'observation des corrélations entre la nature terrestre et les phénomènes cosmiques.

Se heurtant à la controverse, tant face à la science qu'à la religion, elle affirme que la résurgence de la conscience chamanique fait un pont permettant de sortir de l'impasse des sempiternelles querelles occidentales liées à son héritage judeo-chrétien, et permettrait de mieux comprendre le rôle de l'astrologue et de l'astrologie dans la société.

Selon ses dires, la libération de l'« ethnocentrisme » occidental qui aurait opposé science et religion dans un débat et un rapport de force où l'astrologie a trop longtemps joué le rôle de bouc émissaire permettrait de reconsidérer le rôle de l'astrologue.

Elle rappelle qu'à son origine, l'astrologue était « prêtre », faisant le pont entre le ciel et la terre, tout comme le chaman qui aurait pour charge traditionnelle de protéger son environnement des forces naturelles.

Cette nouvelle vision des choses, propre au , émergerait notamment du fait de l'ouverture à l'Est et de la chute du mur de Berlin.

Notons que depuis 1999 le chamanisme est reconnu comme religion officielle en Bouriatie, où les chamanes officient à l'égal des lamas tibétains. Ainsi, on parle à présent avec davantage de respect des « peuples premiers » perpétuant une tradition chamanique. Un article du monde diplomatique en fait état.

Ce renouveau chamanique favoriserait un « ressourcement » de la pensée européenne. À l'heure où la psychanalyse s'ouvrirait au chamanisme, l'astrologie régénèrerait ses sources, au-delà du bassin méditerranéen.

La résurgence de l'astrologie au doit sans aucun doute beaucoup à la laïcité, qui la protège des divers anathèmes jetés sur elle, tant par la religion que par la science.

Toujours selon Laurence Larzul, la (frêle) conscience écologique qui émerge à notre époque inviterait à reconsidérer sous un autre angle ce que la science verrait depuis longtemps d'un œil sarcastique, à la suite des Lumières. Car ce que la science aurait longtemps considéré comme primitif et synonyme d'archaïque, au sens péjoratif des termes, apparaîtrait aujourd'hui sous un jour plus novateur comme source d'enseignement pour notre époque.

Elle affirme donc que les connexions de l'astrologie avec le chamanisme pourraient expliquer pourquoi elle a toujours conservé son « assise » populaire, en accord avec un supposé inconscient collectif qui reconnaitrait, intuitivement et maladroitement, la valeur et le bien fondé de sa pratique ancestrale, et ce malgré les oppositions.

Dans son livre "Retour au zodiaque des étoiles", l'astrologue sidéraliste Jacques Dorsan a souligné que l'angle de sextil de soixante degrés, qui est à ses yeux , correspond aux points de Lagrange 4 et 5, notamment pour Jupiter et pour la Lune. Or 60 est divisible par 1, 2, 3, 4, 5, 6, 10, 12, 15, 20 et 30. Toute une théorie des aspects peut donc en découler.

L'astrologie est depuis longtemps un sujet de controverse et de critiques de type philosophique, théologique, scientifique ou encore épistémologique. Essentiellement développés autour de l'astrologie occidentale, les éléments des débats se sont peu à peu généralisés à l'ensemble des pratiques astrologiques. Parfois condamnée dans l'Antiquité, l'astrologie, au même titre que tous les arts divinatoires, est interdite par la Bible ; elle est peu à peu rejetée par la science qui lui reproche son absence de base rationnelle. Augustin d'Hippone, dès le , (« "De civitate Dei" », , xix) s'élève sur cette base contre la confusion faite entre l'astrologie et l'astronomie.

Ce débat sur les causes, bien que toujours présent, s'est aujourd'hui élargi à une critique objective de la réalité des effets décrits par les astrologues. Actuellement, l'astrologie n'est pas reconnue comme une science, celle-ci ne disposant pas de bases rationnelles ni de preuves expérimentales, n'ayant jamais proposé le moindre modèle de théorie expliquant ses affirmations, et n'ayant pas non plus le caractère de réfutabilité nécessaire pour être acceptée comme théorie scientifique. Néanmoins, les défenseurs de l'astrologie prétendent que leur expérience personnelle montre des effets indéniables.

L'astrologie n'ayant pas de cadre de référence rigoureux (méthodologie scientifique, recherche reconnue, publication scientifique vérifiée, etc.), elle a pu et peut être utilisée par des charlatans ou des escrocs.

De ce constat s’est développé un certain nombre de procédés d'analyses et de protocoles d'études destinés à éclairer de façon objective les différents phénomènes.

Se référant au principe fondamental qu'il n'y a pas d'effet sans cause, la science relève deux objections majeures quant à la réalité des phénomènes mis en jeu : - l'absence d'effet : les prédictions astrologiques ne font pas mieux que le hasard ; - l'absence de cause : il n'y a aucun mécanisme justifiant une quelconque influence astrale. La recherche systématique des effets a conduit aux travaux dans le domaine de l"'astrologie statistique". Quant à l'absence de cause, rédhibitoire pour un scientifique, elle n'est généralement pas reçue comme un argument pertinent par le monde astrologique, dont la vision du monde se fonde sur l'analogie plus que sur les causes efficientes.

Une autre critique de l'astrologie tient dans les modifications que les astrologues eux-mêmes introduisirent dans leurs méthodes pour prendre en compte les planètes du système solaire au fur et à mesure de leurs découvertes. Par exemple Pluton n'est associée au signe du Scorpion que très récemment puisqu'elle n'a été découverte qu'en 1930. Paradoxalement Pluton n'est plus considérée comme une planète depuis 2006 et sa masse est inférieure à celle de la planète naine Éris.

L'image négative (charlatanerie) de l'astrologie impliquerait que le scientifique qui souhaiterait la défendre publiquement, ou en faire une promotion plus ou moins volontaire, coure le risque d'être discrédité par ses pairs (voir l'affaire Michel Maffesoli - Elizabeth Teissier voir aussi la critique - toujours valable - formulée par Rémy Chauvin dans la préface de "La science devant l'étrange" (de Pierre Duval, éd. Denoël, 1973) à l'encontre du discours de ses collègues rationalistes : ). Cette objection est partiellement valide, en tant qu'elle met en lumière la tension interne entre « science établie » et la liberté de recherche scientifique (domaines d'études). La critique de l'astrologie par les philosophes des Lumières reste à cet égard l'exemple historique le plus célèbre d'une « critique de principe ».

De nombreux protocoles d'expérimentation ont été proposés aux astrologues depuis les années 1970, et de nombreux chercheurs du début du siècle se sont attelés à une étude statistique de l'astrologie. Les expérimentations menées dans ce domaine sont cependant limitées par l'absence d'une définition précise de l'effet recherché, et les difficultés de sa caractérisation éventuelle.

La motivation de la lutte contre l'obscurantisme n'est pas en soi un argument contre l'astrologie. Elle peut néanmoins sous-tendre un discours réellement argumenté. La confusion entre les dimensions idéologiques et argumentatives génère un débat souvent stérile, difficilement analysable.

Un manifeste contre l'astrologie a été publié en 1975 par un certain nombre de sommités. Celles-ci présentent simultanément des faits critiques, notamment lorsqu'elle décrivent l'astrologie comme une « superstition reposant sur la crédulité des gens ». Cette dévalorisation est souvent la seule partie du manifeste retenue par les partisans de l'astrologie, qui le présentent comme un simple « rejet sans examen » de leur pratique.

Les arguments


Paul Feyerabend, un philosophe des sciences qui s'est particulièrement intéressé aux théories physiques, remarque dans ce manifeste un ton religieux, une ignorance et des méthodes autoritaires qu'il compare, mais de façon désavantageuse, avec le Malleus Maleficarum, le manuel de lutte contre la sorcellerie de l'Église catholique publié en 1484. Dans ce manuel, dit-il, l'explication de la sorcellerie est pluraliste, incluant même de possibles étiologies matérialistes (bien que l'explication démonologique ait prévalu habituellement). Feyerabend opine : « Les auteurs du Malleus Maleficarum connaissent le sujet, connaissent leurs opposants, ils donnent une description correcte des positions de leurs opposants, ils présentent une argumentation contre ces positions et utilisent les meilleures connaissances du temps dans leurs arguments ». Le manifeste des contre l'astrologie ne présente pas ces qualités, d'après Feyerabend, mais ressemble de façon littérale à la bulle du Pape Innocent présentée en introduction du manuel de 1484.

Au professeur Bok qui affirme « clairement et sans équivoque » que la science moderne n'apporte aucun soutien, plutôt un « soutien négatif », aux principes de l'astrologie, Feyerabend oppose des « concepts modernes de l'astronomie et de la physique de l'espace » : les plasmas planétaires, baignant dans une atmosphère solaire qui s'étend bien au-delà de la terre, interagissent entre eux et avec le soleil de telle manière que l'activité solaire peut être prédite en regardant les positions des planètes. L'astronome Percy Seymour développera cette hypothèse plus avant dans les années 1990-2000.

Feyerabend ajoute que la science est à même d'évaluer combien l'influence de l'activité solaire est précise, notamment dans son action sur le potentiel électrique des arbres ; qu'il est plausible que cette activité influe sur le comportement des molécules d'eau ; que la biologie présente des exemples de sensibilité extrêmement fine aux variations de l'environnement.
Ces arguments n'ont pas pour but premier de prouver l'astrologie, mais de réfuter les prétentions des à une connaissance suffisante de la science pour conclure à l'implausibilité de l'astrologie.

Concernant l'argument des origines magiques de l'astrologie, Feyerabend réplique que cette méthode de réfutation est non seulement trop englobante, puisqu'elle mènerait à exclure bien plus que l'astrologie, mais qu'elle repose sur des postulats de l'anthropologie maintenant « antédiluviens ». Enfin, au sujet du déterminisme simpliste et rassurant de l'astrologie, Feyerabend renvoie les aux méthodes d'évaluation psychologiques (tests, questionnaires) couramment utilisées en clinique, qui elles aussi « jouent sur la tendance humaine a emprunter les chemins les plus faciles » et se substituent à une "pensée honnête" et soutenue ». L'idée que les astres inclinent mais ne déterminent point – pour les , un rempart contre la réfutation – est rapprochée d'autres approches partiellement déterministes dont, notamment, la génétique, ce qui fait dire à Feyerabend que l'astrologie n'est pas la seule à proposer un déterminisme non univoque.

L'impossibilité épistémologique de démontrer l'inexistence d'une chose illustre partiellement la difficulté intrinsèque du débat.

Il est en effet impossible de rejeter « "a priori" » la possible existence d'une influence des astres (« "absence de preuve n'est pas preuve de l'absence" »).

En effet, au-delà de la recherche d'une théorie démontrant la possibilité d'un effet des astres, les travaux méthodiques cherchant à prouver l'existence de corrélations entre les évènements astrologiques et leurs supposés effets aboutissent à l'infirmation des paradigmes astrologiques. Or, pour pouvoir valider les hypothèses de l'astrologie, il est "ab minima" nécessaire d'observer un effet, avant même de chercher à en expliquer ses tenants.

L'argument de la difficulté épistémologique du dialogue apparaît en fait fallacieux. En effet, l'astrologie est une pratique qui ne fournit pas les outils de sa propre réfutabilité, et qui reste par le fait hors du champ d'analyse de l'épistémologie. L'attitude des astrologues est de fait l'exemple retenu par Popper d'un discours qui refuse sa propre réfutation (ou « falsification » selon une mauvaise traduction : on entend par là sa possibilité d'être contredite, réfutée), interdisant ainsi une critique objective de ses affirmations.

Certaines études menées par des astrologues retiennent des dispositifs expérimentaux qui tendent à produire des résultats systématiquement positifs.

Dans leur critique de l'astrologie, les astronomes Zarka et Biraud donnent à penser que les personnes qui cherchent à faire entrer l'astrologie dans le champ de la réfutabilité manquent de probité. Ils affirment qu'il n'y a :

En ce qui concerne les efforts déployés (ou non) pour étudier la plausibilité scientifique de l'astrologie (« expliquer »), Zarka et Biraud jugent que

Selon Robert Hand, un des auteurs majeurs dans le champ de l'astrologie, une future science de l'astrologie devrait avant tout s'attaquer au paradigme « mécaniste-matérialiste » dominant et seulement en second lieu s'investir dans l'amélioration de la pratique astrologique actuelle. La science et l'art de l'astrologie devraient être distingués. Les difficultés qu'il y a à édifier une science de l'astrologie ne sont pas seulement attribuables au fait que « plusieurs idées astrologiques sont si mal formulées, si vaseuses que personne ne pourrait dire ce qu'elles impliquent en termes de conséquences observables [et] que certaines « hypothèses » astrologiques sont trop floues pour être testées. » Pour Robert Hand, la formulation d'hypothèses non-mécanistes est essentielle pour appréhender scientifiquement l'astrologie.

Patrice Guinard, philosophe, seiziémiste et fondateur du Centre universitaire de recherche en astrologie (CURA) constatait en 2010 que la doxa parmi les astrologues était que l'astrologie ne fonctionnait que dans le tête-à-tête entre l'astrologue et son client, que l'astrologie était devenue, dans bien des cas, ce que le discours orthodoxe en avait dit lorsqu'elle a été chassée des institutions : un « savoir-placebo » ne faisant pas usage de la notion de "sympathie" comme principe explicatif, mais comme outil commode dans la relation de l'astrologue à son client.

Dans son ouvrage "Les Charlatans du Ciel", Alain Gillot-Pétré dresse les critiques suivantes : les astrologues reconnaissent eux-mêmes qu'il n'y a pas d'influences astrales et que les planètes n'ont qu'un rôle symbolique ; les astrologues admettent eux-mêmes que tout n'est pas écrit, et donc, selon lui, toute l'astrologie ; enfin et surtout, la théorie astrologique prend des faux-fuyants, et elle en devient tellement complexe que l'accepter telle quelle relève de Par exemple, le printemps y est censé commencer avec le Bélier, chaud et sec, et régi par le dieu de la guerre Mars (violent) alors que, aux dires de Ptolémée, .

L'ensemble de ces polémiques présente un « cas d'école » d'un intérêt indéniable pour la sociologie des sciences et l'épistémologie.

L'engouement de vastes publics, appartenant à toutes les classes sociales, pour une pratique sans effets démontrés continue d'être mis en question, de façon souvent très rigoureuse et critique, par un grand nombre d'épistémologistes et de sociologues. Les représentants des sceptiques (sceptiques anglo-saxons ou français) expliquent l'intérêt pour les horoscopes par l'effet Barnum et ses corollaires. Ces analyses les amènent à considérer publiquement l'astrologie comme une « superstition reposant sur la crédulité des gens ». Ceci est la position généralement adoptée par le monde scientifique.

Le constat de l'engouement du public invite aussi à une double réflexion sur ses implications économiques (multiplication des applications de l'astrologie aux domaines les plus variés, astrologie boursière, astrologie hippique, etc.), mais aussi sur ses effets psychologiques.

Selon la revue "Sciences et pseudo-sciences", la croyance en l'astrologie pourrait induire une modification significative des comportements de ses adeptes conformant leurs actions avec les « prédictions » de l'horoscope, ce qui a été démontré scientifiquement.

Dans l'Antiquité romaine, alors même que l'astrologie est très populaire, les astrologues furent mis hors la loi par décret dès 130 La « mode » astrologique continuant, l'empereur Tibère met en place une législation restrictive des pratiques divinatoires et impose des critères de qualité à la profession d'astrologue (sous la suggestion de son conseiller Thrasylle de Mendès, lui-même astrologue). Ces législations sont renouvelées un siècle plus tard par Hadrien, lui-même astrologue amateur.

On retrouve la même préoccupation mille ans plus tard, quand Alphonse, auteur de traités astronomiques et astrologiques, édicte que .

Jusqu'à la fin du , en France, le Code Pénal comportait dans sa partie règlementaire l'article R. 34-5° sanctionnant . Cet article a été supprimé par la réforme du code pénal, sous la présidence de François Mitterrand.

On peut néanmoins remarquer que la Loi sanctionne des pratiques et des faits, non des pensées : ces interdictions ne s'adressent donc pas à l'astrologie en tant que telle, mais aux troubles sociaux qu'entrainent les pratiques des charlatans qui s'appuient sur l'astrologie.

L'idée de base de l'astrologie est que deux personnes nées le même jour à la même heure au même endroit connaîtront des parcours de vie "parallèles", (hérédité biologique, milieu d'origine, sexe, etc.).
Pour le grand public, la distinction entre astrologue et voyant est souvent floue. Cependant, tous les astrologues ne prétendent pas dresser des prédictions formelles. La Fédération Des Astrologues Francophones (FDAF) demande en particulier à ses membres de signer un code de déontologie qui interdit les prédictions formelles.

L'astrologue André Barbault a écrit qu'en astrologie individuelle,
au vu de la multiplicité des plans sur lesquels peut s'exprimer une même tendance susceptible de , et non en termes d'événements précis.

Le "Catéchisme de l'Église catholique" affirme : 

De plus, comme le rappelle le missionnaire Martial Bessette le martyre des premiers chrétiens qui ont préféré mourir plutôt que rendre un culte aux divinités païennes démontre que, dès le départ, la religion chrétienne a refusé l'idolâtrie.

Par ailleurs, dès le II siècle de notre ère, la tradition chrétienne a interprété l'épisode des Rois mages comme étant une défaite de l'astrologie par rapport à la naissance de Jésus-Christ.

Dans sa thèse de sociologie, Elizabeth Teissier affirme que le ressort principal du rejet de l'astrologie est la question du "déterminisme" et de son pendant philosophique, le libre-arbitre. 

L'astrologue Carol Pilkington affirme qu'une citation semble tout résumer : . Autrement dit, parmi les différentes voies possibles présentées par le thème astrologique, ce n'est que lorsqu'on "choisit" d'en emprunter une qu'on l'expérimente réellement.

Dans le "Tetrabiblos", Ptolémée répond déjà à la critique centrale de l'astrologie, son lien avec le déterminisme, en affirmant : De même, il souligne l'importance de la situation de naissance du sujet (hérédité génétique et sociale) dans les interprétations : 

Le relais de cette critique est pris par les théologiens, pour lesquels la doctrine astrologique met en danger la notion de responsabilité individuelle de l'homme face à ses actes. On trouve trace de cette préoccupation dès l'interdiction biblique (Deutéronome 18:10-12) : , interdiction relayée par les moqueries des prophètes (par exemple, Isaïe 47:12-14). Au , le concile de Tolède déclare Au , Thomas d'Aquin écrit dans sa Somme théologique : .

Pour le théologien, ce n'est pas l'idée que les astres puissent avoir une influence sur le comportement humain qui est en soi condamnable. Ce qui est (Dt 18:12) c'est d'accorder une importance absolue à cette éventuelle influence au point de suggérer que le destin « est écrit », et donc que les hommes ne sont pas libres.











</doc>
<doc id="15730" url="https://fr.wikipedia.org/wiki?curid=15730" title="Électronégativité">
Électronégativité

En chimie, l'électronégativité d'un élément est une grandeur qui caractérise sa capacité à attirer les électrons lors de la formation d'une liaison chimique avec un autre élément. La différence d'électronégativité entre ces deux éléments détermine la nature de la liaison covalente : Liaison apolaire lorsque la différence est nulle, liaison polaire quand la différence n'est pas nulle, et ionique quand la différence est tellement forte qu'un des éléments a attiré complètement les électrons: les atomes sont devenus des ions et portent des charges électriques entières. La notion d'électronégativité, qui décrit le comportement des électrons dans une liaison chimique, ne doit pas être confondue avec celle d'affinité électronique.

Le concept d’électronégativité a été introduit pour la première fois par Berzelius en 1835. Par la suite, Pauling a amélioré ce concept et a déduit que l’électronégativité repose plutôt sur l’existence des liaisons ioniques et covalentes, contrairement à ce que Berzelius avait trouvé auparavant.

L'électronégativité est notée formula_1 où formula_2 est le symbole de l'élément considéré. Plus formula_1 est grand et plus l'élément est susceptible d'attirer des électrons à lui dans une liaison chimique.

Le terme d'électropositivité est parfois employé comme l'opposé de l'électronégativité. C'est-à-dire que plus un atome est électropositif, moins il est électronégatif. Néanmoins, ces deux termes renvoient au même concept d'éléctronégativité ce qui fait que les mots "électropositif" ou "électropositivité" sont d'une utilité très limitée.

Pour calculer les écarts d’électronégativité des éléments, l’échelle de Pauling est généralement la plus utilisée. Dans le tableau périodique, l’électronégativité augmente
de gauche à droite le long d’une période et de bas en haut le long d’une famille. Ainsi le fluor, en haut à droite du tableau périodique, est l'élément le plus électronégatif avec une valeur de tandis que le francium, en bas à gauche, est le moins électronégatif avec une valeur de . Les différences d’électronégativité permettent d’identifier les liaisons covalentes non polaire, les liaisons covalentes polaires et les liaisons de coordinence (ou coordination). L’électronégativité permet d’identifier les charges partielles des atomes d’une molécule donnée. Les symboles δ+ et δ- représentent respectivement les charges partielles positives et
négatives d’une liaison dont l'atome le plus électronégatif porte la charge partielle négative.

Il y a trois types de liaisons covalentes :




Il existe plusieurs définitions de l'électronégativité (Pauling, Mulliken, Parr, Allred et Rochow) ce qui a conduit à construire plusieurs échelles.

formula_4

où formula_5, formula_6 et formula_7 sont les énergies de liaison des molécules diatomiques A-B, A-A et B-B.
Le coefficient 0,102 provient de l'unité utilisée pour les valeurs d'énergies (initialement en eV) qui doivent, dans cette formule, être exprimées en kJ.mol.
La moyenne des énergies formula_6 et formula_9 est souvent une moyenne géométrique (comme ici), mais certains auteurs utilisent la moyenne arithmétique.

Cette définition ne donne que la différence entre deux électronégativités. On a donc besoin d'une origine qui a été fixée arbitrairement en donnant la valeur de 4 à l'électronégativité du fluor (élément le plus électronégatif de la classification).
 formula_10
L'intérêt de l'échelle de Mulliken, par rapport à celle de Pauling, est d'utiliser des grandeurs atomiques, indépendant de l'environnement chimique. Elle permet ainsi de déterminer l'électronégativité des gaz nobles, ce que Pauling n'avait pu faire.
formula_11
où formula_12 est la charge effective du noyau,formula_13 la charge élémentaire et formula_14 le rayon covalent de l'élément
formula_15

Les échelles d'électronégativité les plus utilisées sont l'échelle de Mulliken, l'échelle d'Allred-Rochow et l'échelle de Pauling.

Les électronégativités des atomes impliqués dans une liaison tendent à être égales (principe d'égalisation des électronégativités de Sanderson, 1951). L'égalisation des électronégativités est réalisée par le transfert de densité électronique vers l'atome le plus électronégatif.

L'électronégativité permet d'estimer le caractère ionique d'une liaison à l'aide de la relation de Pauling

formula_16 

ou de celle de Haney et Smith

formula_17 

L'électronégativité est également la notion à l'origine de la polarité de certaines molécules. En effet, dans une molécule, lorsque les atomes de part et d'autre de la liaison covalente ont des électronégativités différentes, l'atome le plus électronégatif attire davantage les électrons. Le barycentre des charges positives n'est donc pas confondu avec le barycentre des charges négatives. La molécule reste globalement neutre mais un champ électrique apparaît au sein de celle-ci, on dit que la liaison est polarisée ou que la molécule est polaire.

Les éléments dont l'électronégativité est faible sont fréquemment dits électropositifs.

L'électronégativité des éléments chimiques d'un même groupe du tableau périodique (c'est-à-dire d'une même colonne du tableau périodique) a tendance à "décroître" lorsque le numéro atomique croît, car le noyau atomique tend alors à « s'éloigner » des électrons de valence, qui sont davantage écrantés par les électrons de cœur. En revanche, l'électronégativité des éléments d'une même période du tableau périodique a tendance à "croître" avec le numéro atomique, car la charge électrique du noyau atomique (nombre de protons) augmente et interagit davantage avec les électrons de valence. Le minimum est donc à rechercher en bas à gauche du tableau (au niveau du francium) tandis que le maximum se trouve en haut à droite (au niveau du fluor).

Tableau périodique des éléments utilisant l'échelle d'électronégativité de Pauling




</doc>
<doc id="15731" url="https://fr.wikipedia.org/wiki?curid=15731" title="Apache">
Apache









</doc>
<doc id="15734" url="https://fr.wikipedia.org/wiki?curid=15734" title="Internet Message Access Protocol">
Internet Message Access Protocol

Au sens strict, , devenu avec IMAP 4 (IMAP, est un protocole qui permet d'accéder à ses courriers électroniques directement sur les serveurs de messagerie
. Son fonctionnement est donc à l'opposé de POP qui, lui, récupère les messages localement (depuis le poste de travail) via un logiciel spécialisé. L'évolution des différentes versions d'IMAP (IMAP 4) en fait aujourd'hui un protocole permettant également de récupérer les messages localement.

Ce protocole permet de laisser les courriels sur le serveur dans le but de pouvoir les consulter de différents clients de messagerie ou . Il comporte des fonctionnalités avancées comme la possibilité de créer des dossiers ou de manipuler les messages directement sur le serveur. Il offre aussi la possibilité de trier ses courriels sur le serveur. Le langage Sieve a été conçu pour permettre de filtrer des messages sur des serveurs sur lesquels l'utilisateur n'a pas le droit d'exécuter des tâches.

Le fait que les messages soient archivés sur le serveur fait que l'utilisateur peut y accéder depuis n'importe où sur le réseau et que l'administrateur peut facilement faire des copies de sauvegarde.

L'inconvénient est qu'IMAP requiert une connexion permanente. Cependant, depuis IMAP 4, de nombreux clients de messagerie proposent un mode « hors-ligne » pour pallier ce problème. D'autre part, il limite l'utilisation de la capacité du réseau car il permet de ne récupérer qu'une partie des messages (par exemple les entêtes, sans le corps du message). Les messages peuvent être déplacés ou effacés sans être entièrement récupérés par le client.

IMAP utilise le port TCP 143. L'utilisation de TLS permet l'accès sécurisé au serveur. La , qui décrit le fonctionnement de TLS avec IMAP, déconseille l'utilisation du port 993 qui avait été préalablement enregistré pour IMAPS ().

La plupart des clients de messagerie implémentent le protocole IMAP puisque celui-ci est largement utilisé par les différents fournisseurs d'accès à Internet.

Quelques exemples :

Le protocole IMAP a été mis au point par Mark Crispin en 1986. Plusieurs versions se sont succédé, jusqu'à la version 4rev1 encore en vigueur aujourd'hui, qui fut proposée par un groupe de travail de l'IETF en 1996 et mise à jour en 2003. Les premiers serveurs IMAP à voir le jour au début des années 1990 furent notamment Cyrus (1994), Qmail (1996), UW-IMAP (1996), (1999).

Une controverse existe entre les auteurs des différentes implémentations, notamment entre Mark Crispin et Sam Varshavchik (le créateur de Courier), sur le respect des standards par les différents logiciels et sur la précision des textes des RFC définissant le protocole IMAP.




</doc>
<doc id="15735" url="https://fr.wikipedia.org/wiki?curid=15735" title="Tux">
Tux

Tux est un manchot, mascotte officielle du noyau Linux. Dessiné par Larry Ewing en 1996, son usage est libre et se retrouve dans de très nombreux projets et logotypes liés à Linux.

Le dessin du personnage a été choisi à l'issue d'un concours organisé en 1996 remporté par Larry Ewing. Il utilisa GIMP, le logiciel de traitement d'image phare sur GNU/Linux. Il s'agit d'un personnage fictif représentant très approximativement un manchot pygmée dont l'idée a été suggérée par Alan Cox puis affinée par Linus Torvalds, le créateur du noyau Linux.

Linus s'est inspiré d'une photo qu'il a trouvée sur un site FTP, montrant une figurine de manchot ressemblant aux personnages des Creature Comforts de Nick Park.

Le nom a été suggéré par James Hughes. Il s'agit de l'apocope du terme américain "tuxedo" signifiant « smoking ». James Hugues, dans un courriel envoyé le , proposa un rétro-acronyme composé à partir des mots Torvalds" et UNIX".

Certains déclarèrent de prime abord que cette mascotte était inappropriée car elle n'évoquait guère la puissance. Linus Torvalds répondit que nulle personne poursuivie par un manchot pygmée, qui court vite et dispose d'un bec très dur, ne penserait cela. Les contradictions s'éteignirent.

Il a été remplacé temporairement par Tuz comme logo de la version 2.6.29 du noyau Linux afin de soutenir la campagne pour sauver le diable de Tasmanie de l'extinction. Dès la version 2.6.30 RC-4, Tux était de retour.

Tux est un manchot.

Beaucoup pensent à tort que la mascotte de Linux est un pingouin, notamment parce qu'en anglais, le mot « manchot » se dit « "penguin" ». Ce que l'on désigne en français comme un pingouin est un oiseau de l'hémisphère nord de la famille des alcidés, qui peut voler, alors que le manchot est un oiseau qui ne vit que dans l'hémisphère sud et qui est incapable de voler. Dans le langage courant, utiliser le mot « pingouin » à la place de « manchot » est un abus de langage très fréquent.

Tux ne représente précisément aucune des 19 espèces de manchots, bien qu'il ressemble un peu à un Manchot Adélie et que Linus Torvalds ait trouvé des affinités avec un Manchot pygmée. Il dit d'ailleurs qu'il a été mordu par un manchot pygmée lors d'un de ses voyages.

Beaucoup d'artistes ont élaboré des variantes. Il en résulte de nombreuses créations burlesques, au point que l'image de Tux est de moins en moins associée à Linux...

La mascotte de Linux est employée par de nombreuses applications en tant que logo, mais a aussi été modifiée par de nombreux particuliers et développeurs. On découvrira ainsi, parmi de nombreux autres, Tux en Sherlock Holmes, en Dracula, ou encore en Charlie Chaplin ou habillé avec des maillots de football.

Des petits robots animés reliés par USB ou par Wi-Fi à un ordinateur ont aussi été développés. Par exemple, le Tux Droid est programmable (lecture d'email, de musique, mouvements, etc).

De nombreux logiciels libres, comme TuxGuitar, Tux Paint ou les jeux Tux Racer, Tux Kart et SuperTux ou des revendeurs libres reprennent Tux dans leur intitulé et/ou dans leur logo. Parmi ceux-ci, plusieurs utilisent Tux comme personnage principal.



</doc>
<doc id="15736" url="https://fr.wikipedia.org/wiki?curid=15736" title="Association pour la taxation des transactions financières et pour l'action citoyenne">
Association pour la taxation des transactions financières et pour l'action citoyenne

L'Association pour la taxation des transactions financières et pour l'action citoyenne, généralement connue par son acronyme Attac (ou ATTAC), est une organisation altermondialiste créée en France en 1998. Elle est présente dans .

Dans le numéro de décembre 1997 du journal "Le Monde diplomatique", dans un éditorial intitulé "Désarmer les marchés", Ignacio Ramonet constate que la mondialisation financière a créé son propre État, avec ses appareils, ses réseaux d'influence et ses moyens d'actions, mais que c'est un État complètement dégagé de toute société, qu'elle désorganise les économies nationales, méprise les principes démocratiques qui les fondent, presse les États à s'endetter, exige des entreprises qu'elles leur reversent des dividendes de plus en plus élevés, et fait régner partout l'insécurité. Il propose d'établir une taxe sur toutes les transactions financières, la taxe Tobin. Pour cela, il suggère de mettre en place une organisation non gouvernementale, l'« "Association pour une taxe Tobin d'aide aux citoyens" (ATTAC) », qui ferait dans tous les pays la promotion de l'idée de cette taxe. Cet appel, lancé en pleine crise des marchés asiatiques, reçut en apparence un accueil favorable, mais aucun soutien réel des dirigeants des différents pays développés.

L'association pour la taxation des transactions pour l'aide aux citoyens, Attac, est créée le au cours d'une assemblée constitutive. Depuis, Attac est présente dans 38 pays. En France, des hommes politiques, des associations, des syndicats et des particuliers sont adhérents à l'association.

L'association s'est dotée en France dès l'origine, et aussi dans certains pays, d'un « conseil scientifique » qui se veut indépendant de toute structure universitaire ou officielle. En France, ce conseil scientifique a été présidé successivement par deux professeurs d'économie, René Passet puis Dominique Plihon, avant d'être maintenant dirigé par une équipe de quatre coprésidents, Esther Jeffers, Aurélie Trouvé, Nicolas Haeringer et Jean-Marie Harribey.

Il regroupe :

Des membres d'Attac sont à l'origine du Forum social mondial de Porto Alegre et des forums sociaux européens.

Attac a reçu en France le statut d'association d'éducation populaire par arrêté ministériel.

Dès l'origine, Attac était une association très centralisée sur Paris. Elle bénéficiait d'un local situé à proximité du siège du "Monde diplomatique" dont deux salariés consacraient la majeure partie de leur temps au développement d'Attac. De même, une dizaine d'autres permanents de plusieurs associations fondatrices, notamment la Fédération des Finances CGT, la FSU, et Solidaires ont libéré pour Attac une part importante de leur temps (payé par leur propre organisation). Quelques mois après sa création, Attac a embauché quatre salariés permanents.

Cependant, les initiatives décentralisées de militants enthousiastes créant des « comités locaux d'Attac », après l'automne 1998, ont surpris la direction. Cette dernière n'avait même pas envisagé l'existence de ces formations dans ses statuts rédigés avant juin 1998.

Après 1999, Attac a ainsi fonctionné sur deux modes d'organisation parallèles :

Les comités locaux n'ayant pas d'existence dans les statuts, une conférence nationale des comités locaux (la CNCL) fut créée en 2002. C'était la première instance "ad hoc" qui leur donnait des moyens de délibération et d'expression important. Cela n'a pas empêché les critiques de plusieurs comités locaux à l'égard de la direction nationale.

En 2009, une reforme des statuts fut votée par les adhérents de l'association. Ces nouveaux statuts officialisaient la reconnaissance des comités locaux et de la conférence nationale des comités locaux (CNCL). Le nom de l'association s'est vu aussi modifié en « "Association pour la taxation des transactions financières et pour l'action citoyenne" ».

Créée en 1998, Attac France a été la première association Attac dans le monde. C'est aujourd'hui, avec Attac Allemagne, une des deux associations Attac qui a le plus d'activité et de militants dans le monde. Elle a connu une croissance rapide de ses effectifs, jusqu'à plus de fin 2003, puis une chute à partir de 2003, soit l'année qui a suivi la première Conférence nationale des comités locaux (CNCL). Près de adhérents étaient à jour de cotisation fin décembre 2013.

Parmi les adhérents figurent aussi des membres collectifs : associations, syndicats, collectivités locales, journaux, etc. Certains membres sont issus de formations associatives, politiques ou syndicales qui comprennent un grand nombre de sensibilités différentes : écologiste, socialiste, communiste, trotskiste ou chrétienne sociale. D'autres, dont beaucoup de jeunes, ont trouvé là un premier engagement politique situé en dehors des partis.

"Attac France" dispose en son sein d'un groupe d'études dénommé « conseil scientifique » qui lui fournit des études approfondies, notamment sous la forme de livres et de brochures, et des analyses détaillées des questions d'actualité pouvant alimenter ses campagnes. Parmi ses nombreux membres, on peut citer ses quatre coprésidents, Esther Jeffers, Aurélie Trouvé, Nicolas Haeringer et Jean-Marie Harribey, Jacques Cossart, son ancien secrétaire général, l'économiste Jean Gadrey, ou encore René Passet et Dominique Plihon, deux présidents successifs du Conseil scientifique, .

Attac est dirigé par un conseil de trente-cinq administrateurs, élus pour trois ans et rééligibles. Parmi ces 35 personnes, 21 sont élues par l'assemblée générale des adhérents directs et 14 sont cooptées dans le Collège des fondateurs. Ce dernier est constitué de représentants des organisations syndicales, journaux et associations ayant participé à la création d'Attac ainsi que de nombreux membres, personnes physiques et morales, cooptés depuis. 

Au début de l'année 2006, Attac était considéré par le journal "Le Monde" comme étant en perte d'influence auprès du mouvement altermondialiste. L'année 2006 a été en effet une année difficile pour Attac France, avec une baisse du militantisme et de vives polémiques internes liées à une fraude électorale commise à l'occasion du renouvellement du conseil d'administration .

La réélection de la direction en juin 2006 a été entachée d'accusations de fraude électorale notamment portées contre son président Jacques Nikonoff. Plusieurs enquêtes internes, dont une menée par le premier président de son comité scientifique, le professeur René Passet, ont prouvé la réalité de cette fraude. À la suite de ces révélations, Jacques Nikonoff s'est trouvé contraint de démissionner et une nouvelle élection a été organisée en 2007, conduisant à un nouveau Conseil d'administration.

Cette crise interne, ainsi que les désaccords concernant les prises de position sur les élections européennes et en faveur du Non lors du référendum sur le traité établissant une Constitution pour l'Europe ont conduit à une fonte importante des effectifs. Depuis 2006, l'association a ainsi perdu plus de la moitié de ses adhérents, malgré la grave crise économique de 2008-2009 qui a validé un certain nombre de ses analyses.

L'État français et des collectivités locales ont subventionné le Forum social européen de Paris, organisé par Attac France ainsi qu'un certain nombre de ses universités d'été. En dehors de ces évènements, Attac dépend exclusivement du soutien financier de ses sympathisants et adhérents pour son fonctionnement.

Présidents d'Attac France :

Présidents d'honneur : Ignacio Ramonet, Bernard Cassen, Susan George

Porte-parole :

Dans l'entre-deux-tours de l'élection présidentielle de 2017 qui oppose Marine Le Pen et Emmanuel Macron, Attac se joint à une soixantaine d'autres associations pour appeler implicitement à faire barrage à la candidate FN.

Lors de la création de l'association en 1998, on trouve parmi les membres fondateurs d'Attac France de nombreuses personnalités .

Les 11 et 12 décembre 1998, à Paris, se tient une réunion internationale qui fonde le "Mouvement international ATTAC" - . Il prône la convergence de différents réseaux militants de tous les pays contre les politiques néolibérales ; partant de la conception que les mouvements syndicaux, des droits de l'homme, écologistes, citoyens (entre autres) sont les différentes facettes de cet objectif.

Un autre de ses objectifs principaux est de pallier ce que le mouvement considère comme des dysfonctionnements de la démocratie pour le cas des pays dits démocratiques. Pour ce faire, le mouvement affiche la volonté de débattre plus collectivement, d'informer plus efficacement, de développer la démocratie participative. 

Il a été décidé lors de cette conférence que le mouvement international s'organiserait sans structures "hiérarchiques" ni centre géographique. Une plateforme commune est tout de même posée comme référence des différents comités.

Attac est présente dans 38 pays : Allemagne, Argentine, Australie, Autriche, Belgique, Burkina Faso, Canada (Québec), Chili, Colombie, Costa Rica, Côte d'Ivoire, Danemark, Équateur, Espagne, Finlande, France, Gabon, Grèce, Hongrie, Islande, Italie, Japon, Jersey, Liban, Luxembourg, Maroc, Norvège, Pays-Bas, Pérou, Pologne, Portugal, Sénégal, Suède, Suisse, Togo, Tunisie, Uruguay, Venezuela.

L'objectif initial de l'association était d'introduire une taxe sur les mouvements internationaux de capitaux afin de décourager la spéculation. Le produit de cette taxe (souvent dénommée taxe Tobin) financerait des projets de développement écologique et social. 

Depuis, Attac a élargi son champ d'intervention et s'intéresse maintenant à tous les aspects qui se rapportent au cours dominant de la mondialisation économique, qu'elle qualifie de néolibérale. Attac combat à ce titre les décisions de l'OMC, de l'OCDE, de la Banque mondiale ou du FMI, qu'elle ne voit pas comme des instances de régulation favorables.

Bien qu'Attac critique le fonctionnement de l'économie mondiale, qu'elle considère dominée par le « néolibéralisme », elle ne se dit pas opposée à la mondialisation en général. Elle souhaite encourager des politiques économiques respectueuses des aspects sociaux et environnementaux, affirmant que des politiques économiques anti-libérales sont possibles.

Les principaux sujets sur lesquels travaille Attac sont :

Attac participe aux manifestations altermondialistes dans le monde, dont celles visant à interpeller les grandes puissances lors des réunions internationales (G8, G20, OMC, FMI, Forum de Davos, etc.).

Pour diffuser ses idées, Attac cherche à être visible sur la scène publique et médiatique en utilisant divers moyens de communication : conférences, articles, communiqués de presse, manifestations diverses, campagnes de communication, projections de films documentaires, publications.
Deux slogans illustrent les thèses d'Attac : « Le monde n'est pas une marchandise » et « Un autre monde est possible ».

Attac considère ne pas porter la responsabilité des arrachages de plants d'OGM effectués selon le « principe de précaution », ni des affrontements avec les forces de l'ordre. 

Attac publie des livres de vulgarisation présentant ses thèses sur les conséquences d'une économie jugée « néo-libérale ».

Depuis sa création, l'organisation interne d'Attac repose beaucoup sur internet (listes de diffusions, site internet).

L'association condamne depuis longtemps le géant californien pour ses pratiques d'optimisation fiscale. En décembre 2017, Attac a mené plusieurs actions coup de poing en ciblant ses magasins notamment celui d'Opéra à Paris. Profitant de la sortie de l'Iphone X, l'association avait publié un rapport concernant ce "hold up" mondial. 

Face à ces opérations, Apple a décidé d'assigner Attac en justice afin de lui interdire de pénétrer dans ses magasins. L'audience se tiendra le 12 février 2018.

Vendredi 23 février 2018, le tribunal de grande instance (TGI) de Paris, qui avait été saisi en référé, a finalement débouté le groupe Apple. Le TGI a estimé que le « dommage imminent » invoqué par Apple pour justifier l'interdiction de ses magasins français à Attac n'était « pas caractérisé ». Le 7 avril, Attac mène deux actions à Paris et à Aix-en-Provence, où il déploie des portraits géants qui donnent un visage aux victimes de l’évasion fiscale.

Diverses controverses existent sur le mode de fonctionnement, les méthodes, les propositions, les ambitions politiques d'Attac. 

À l'intérieur du mouvement altermondialiste , Attac est parfois critiquée pour son réformisme face à la mondialisation néo-libérale, pour sa manière jugée parfois trop légaliste de lutter contre le néo-libéralisme.






À ces critiques, généralement adressées au mouvement altermondialiste dans son ensemble, il est répondu que celui-ci est composé d'une pluralité de points de vue et d'un grand nombre de propositions de solutions alternatives. En ce qui concerne ATTAC France, un « Manifeste altermondialiste » est cependant paru en 2006, proposant 102 mesures pour . 

Attac a été très prudente en matière de propositions d’architectures institutionnelles européennes. Pourquoi ? Parce que le sujet nous divise profondément si on veut le traiter sur le plan théorique. Il y a parmi nous des fédéralistes, partisans du dépassement des États actuels pour aller à des États-Unis d’Europe, donc à un État européen qui présupposerait l’existence d’un peuple européen ou, en tout cas, l’enfanterait rapidement. Il y a aussi des partisans d’une Europe des nations ou des patries, dans une logique à dominante confédérale ; et, entre les deux, toutes sortes de positions intermédiaires. À ce seul niveau, les termes de « Constitution » et de « processus constituant » donnent déjà lieu à de vives controverses.[…]La bibliographie explicitant chacune de ces visions est imposante, et les thèses en présence totalement incompatibles sur de nombreux aspects, dans la mesure où elles renvoient à des convictions divergentes sur l’État, la nation, le peuple, la citoyenneté, et, pour la France, sur les conceptions profondément enracinées dans l’histoire, de la République et de la laïcité. Il serait vain de tenter d’arriver à un consensus théorique entre nous sur ces questions.






</doc>
<doc id="15737" url="https://fr.wikipedia.org/wiki?curid=15737" title="Constantin Ier (empereur romain)">
Constantin Ier (empereur romain)

Flavius Valerius Aurelius Constantinus, né à Naissus en Mésie (aujourd'hui Niš en Serbie) le , est proclamé empereur romain sous le nom Constantin en 306 par les légions de Bretagne (actuel sud de la Grande Bretagne), et mort le après 31 ans de règne, est une figure prépondérante du .

L'empereur Constantin mène une politique militaire, religieuse et économique profondément réformatrice, qui lui permet de réunir sous son unique autorité un empire romain affaibli et divisé. Il se débarrasse des empereurs Maxence en 312 (bataille du pont Milvius) et Licinius en 324 (bataille d'Andrinople). Son règne voit l'établissement de la liberté de culte individuel, qui met fin aux persécutions des chrétiens (édit de Milan, 313). Il mettra provisoirement fin aux dissensions des Églises d'Orient en convoquant le concile de Nicée (325), et affirme son autorité dans le domaine religieux : c'est le césaropapisme. Il instaure une monnaie stable (le "solidus", 312), développe l'administration centrale, défend les frontières de l'Empire contre les Francs, les Alamans, les Sarmates, les Goths et les Perses. Il fonde en 330 une nouvelle capitale à son nom, Constantinople (actuelle Istanbul). Ses réformes favorisèrent largement l'essor du christianisme, vers lequel il se tourna progressivement, et dont il est même devenu l'un des saints, pour l'Église orthodoxe.

Ses noms de référence sont "Imperator Caesar Flauius Valerius Aurelius Constantinus Pius Felix Inuictus Augustus, Germanicus Maximus, Sarmaticus Maximus, Gothicus Maximus, Medicus Maximus, Britannicus Maximus, Arabicus Maximus, Adiabenicus Maximus, Persicus Maximus, Armeniacus Maximus, Carpicus Maximus".

Originaire de Dacie aurélienne, Constantin naît le 27 février d'une année qui fait l'objet de controverses, entre 271 et 277, si l'on s'en tient aux sources qui fixent son âge lors de sa mort en 337 à 60/66 ans (62 ans selon Aurelius Victor, 63 ans selon l'Épitomé de Caesaribus, 63/64 ans selon Eusèbe de Césarée, 65 ans selon Socrate le Scolastique, entre 65 et 66 ans selon Eutrope). Certains historiens modernes ont avancé l'hypothèse qu'il serait né après 280.
Constantin est né dans le contexte très particulier d'une restructuration d'un empire romain affaibli. L'empereur Dioclétien avait mis sur pied un système complexe, la Tétrarchie, dans lequel l'empire était gouverné par deux Augustes, Dioclétien et Maximien, assistés de deux Césars. Constance Chlore, le père de Constantin, devint le César de Maximien en 293. La mère de Constantin, Hélène, était une femme de « basse extraction », exerçant la profession de "stabuleria" selon Ambroise de Milan, ce qui peut se traduire par « servante d'auberge » voire par prostituée, trouvant ses clients dans les étables ("stabula") près des auberges. Elle n'était probablement pas l'épouse légitime de Constance Chlore mais sa concubine. Lors de l'élévation de Constance Chlore au titre de César, celui-ci fut contraint d'épouser Théodora, la fille de Maximien, Hélène étant reléguée dans l'obscurité.
Pendant que son père guerroyait en Gaule et en Bretagne, Constantin reçut néanmoins une bonne éducation à Nicomédie, à la cour de Dioclétien, puis de son successeur Galère. Une seule source, l’"Origo Imperatoris Constantini", le dit « peu instruit dans les lettres ». Parallèlement, il reçut aussi une bonne préparation à la carrière militaire. Il s'éleva vite dans la hiérarchie, et différentes sources célèbrent ses exploits sur le champ de bataille.

Après l'abdication conjointe de 305, l'Empire a pour dirigeants deux Augustes, Constance Chlore et Galère, et deux nouveaux Césars, Sévère et Maximin Daïa, choisis selon le principe du mérite.

Constantin s'enfuit de Nicomédie, où Galère tentait de le retenir, et rejoint son père en Bretagne (l'actuelle Grande-Bretagne) quand celui-ci devient Auguste en 305. Peu après, Constance décède à York le . On assiste alors à un conflit entre le principe tétrarchique et celui de l'hérédité, car un des deux Augustes a un fils en âge de gouverner. Lorsque Constantin est acclamé Auguste par les troupes de son père, Galère se montre pragmatique et, face au fait accompli, le reconnaît, mais seulement comme César.

Quelques mois plus tard, Maxence, fils de Maximien, est proclamé princeps par les prétoriens et le peuple de Rome, mécontent de l'impôt de capitation. Son père accourt à ses côtés et reprend le titre d'Auguste qu'il n'a abandonné qu'avec regret. Sévère, envoyé les combattre, est tué en 307.

Galère fait alors appel à Dioclétien, qui accepte le consulat, et une conférence a lieu en 308 à Carnuntum, qui réunit Dioclétien, Maximien et Galère, dans le but de rétablir la tétrarchie, mais elle se solde par un échec :

On a alors sept empereurs, une heptarchie, qui ressemble davantage à l'anarchie militaire du . Une première série de décès contribue à clarifier la situation : Maximien est assiégé dans Marseille par Constantin et se suicide en 310, Domitius Alexander est battu en Afrique par Maxence et est assassiné en 311, Galère meurt de maladie en 311.

En 311, à la mort de Galère, règnent quatre Augustes : Maximin Daïa, Constantin, Licinius et Maxence.

Constantin élimine Maxence le à la bataille du pont Milvius, prend Turin, ce qui lui permet de s'emparer de l'Italie et de régner en maître sur l'Occident. De son côté, Licinius défait Maximin Daïa à la bataille d'Andrinople (313) et règne sur l'Orient : une nouvelle diarchie se met en place entre Constantin et Licinius scellée par un mariage entre Licinius et Constantia, la demi-sœur de Constantin.

Les relations entre les vainqueurs ne tardent pas à se dégrader, tous deux faisant montre d'une énorme ambition. À partir de 320, Constantin entre de nouveau en conflit avec Licinius. En 324, Licinius est vaincu à Andrinople, puis à Chrysopolis. Il fera sa soumission à Nicomédie, et sera exécuté peu de temps après, ainsi que son fils.

Pour la première fois depuis quarante ans, l'Empire est gouverné par une autorité unique : Constantin règne seul pendant treize ans, assisté de Césars qui ne sont plus des collaborateurs mais des fils (et deux neveux) désignés successivement comme héritiers présomptifs : 

Depuis la tétrarchie, Rome n'est plus dans Rome même. Les Augustes et les Césars ont vécu dans des résidences impériales proches des secteurs qu'ils ont la charge de défendre.

La fondation d'une nouvelle capitale est décidée pendant la période aigüe du conflit pour la domination de l'Empire. À partir de 324, Constantin transforme la cité grecque de Byzance en une « Nouvelle Rome », à laquelle il donne son nom, Constantinople. Il l'inaugure en 330 après douze ans de travaux. Constantinople est bâtie sur un site naturel défensif qui la rend pratiquement imprenable, alors que Rome est alors sans cesse sous la menace des Germains. Elle est également proche des frontières du Danube et de l'Euphrate, là où les opérations militaires pour contenir les Goths et les Perses sont des plus importantes. Elle est enfin située en bordure des terres de vieille civilisation hellénique, région qui a le mieux résisté à la crise du troisième siècle de l'empire romain. Constantin la fait bâtir sur le modèle de Rome, avec sept collines, quatorze régions urbaines, un Capitole, un forum, un Sénat. Dans les premiers temps, il permet l'implantation de temples païens, mais très vite la ville devient presque exclusivement chrétienne, et ne comportera que des édifices religieux chrétiens. Dès Constantin, la ville compte habitants. Celui-ci y fait construire, le palais impérial, l'hippodrome – le nouveau nom donné aux cirques romains –, ainsi que l'église de la Sagesse Sacrée (Sainte-Sophie).

Constantin transforme l'organisation du pouvoir central, qui était demeurée sensiblement la même depuis le Haut Empire. Le préfet du prétoire est remplacé par le questeur du Palais sacré, qui rédige les édits. Celui-ci dirige le consistoire sacré, qui remplace le conseil de l'empereur. Le maître des offices dirige le personnel administratif, les fabriques d'armes et les "scholæ" de la garde ; le maître des milices, l'infanterie et la cavalerie ; le comte des largesses sacrées, le fisc ; le comte de la fortune privée, la "res privata", c'est-à-dire la caisse privée de l'empereur, les revenus personnels de ce dernier étant issus essentiellement du revenu de ses immenses domaines. La grande nouveauté est cependant la grande augmentation du nombre des fonctionnaires travaillant dans les bureaux centraux. Une foule de notaires, d'agents secrets (les "agentes in rebus"), près de fonctionnaires au , et d'employés divers font de l'Empire romain une véritable bureaucratie.

Constantin vise à harmoniser au plus haut le rang social des plus hauts serviteurs de l'Empire : le Sénat reprend la première place à partir de 312 en Occident et de 324 en Orient, quand Constantin règne sur l'ensemble de l'Empire.

L'empereur abroge les lois d'Auguste sur le célibat, impose le repos dominical, autorise l'affranchissement des esclaves par déclaration dans les églises (333), interdit (325) que l'on sépare les familles lors des ventes, autorise l'Église à recevoir des legs, et accorde le droit aux plaideurs de choisir entre le tribunal civil et la médiation de l'évêque, alors élu par le peuple.

Il promulgue des lois contre la prostitution des servantes d'auberges (profession initiale de sa mère), contre le rapt à visée matrimoniale (320), et en faveur de l'humanisation des prisons (326) - limitation des traitements cruels, allant jusqu'au marquage du visage des criminels au fer rouge.

Enfin plusieurs lois sont créées afin de lutter contre les relations extra-maritales, ce qui renforce le poids du mariage ("nuptiae") et des cérémonies religieuses chrétiennes autour de ce sacrement. Ainsi, en 329, une loi punit de mort l'adultère d'une femme avec son esclave. En 331, un rescrit freine le développement des divorces : si le divorce à l'amiable ("divortium consensu)" reste possible, le demandeur est financièrement pénalisé dans les autres cas, à moins de prouver pour la femme que le mari est coupable d'homicide, empoisonnement, ou violation de sépulture, ou pour le mari que l'épouse est coupable d'adultère, maléfices, ou faits de proxénétisme. Cette évolution limite les cas de répudiation par opportunisme politique, ce dont fut victime la mère de l'empereur. En 336, une loi pénalise les naissances illégitimes.

Après sa victoire sur Maxence en 312, Constantin remplace l'aureus, fortement déprécié, par une nouvelle monnaie d'or, le "solidus (ou solidus aureus)". Le "solidus" (« solide », « stable »), déformé en sol et sou, fonde un système monétaire qui connut une stabilité exceptionnelle jusqu'au dans l'Empire d'Orient. 

Son émission (privilège impérial par excellence) est alimentée par la confiscation des considérables stocks d'or thésaurisés depuis plusieurs siècles dans les temples païens (331) et la capture du trésor de guerre de Licinius (324). Constantin lève également de nouveaux impôts payables en or, tels que le chrysargyre (« or et argent » en grec, perçu tous les quatre ans chez les commerçants et artisans), l'or coronaire ("aurum coronarium", dû par les décurions des cités) ou l'or oblatice ("aurum oblaticium" , soit « or offert », contribution imposée aux sénateurs). 

Le "solidus" devient l'unité de compte dans l'ensemble de l'Empire. Sur l'insistance de l'empereur il devient l'instrument principal de paiement des taxes. Il joue également un rôle de valeur refuge en période d'inflation face aux dévaluations des autres monnaies circulantes en argent, en bronze (follis, centenionalis...) ou celles en cuivre utilisées au quotidien par les couches populaires, et avec lesquelles aucune parité fixe n'est établie.

L'introduction de cette nouvelle monnaie d'excellent aloi, dont la pureté et le poids sont étroitement surveillés par les ateliers émetteurs, permet de créer dans l'Empire un climat de confiance durable, propice au commerce. Les grandes métropoles retrouvent leur dynamisme. Mais la réforme monétaire se solde également par une aggravation de l'inégalité entre riches et pauvres, que ne parviendra pas à résoudre l'introduction de sous-multiples du solidus censés être accessibles aux plus modestes : le semissis ou semis, valant un demi-solidus, et le tremissis ou triens, valant un tiers de solidus.

Le solidus de 4,55 g d'or introduit par Constantin peut être considéré comme la pièce de monnaie la plus célèbre de l'histoire, la seule dont le titrage a pu rester inchangé durant plus de sept siècles.

En 312, Constantin défait l'empereur Maxence lors de la bataille du Pont Milvius et s'assure la maîtrise de l'Occident. Selon une chronique postérieure rapportée par l'évêque et hagiographe Eusèbe de Césarée, un chrisme flamboyant serait apparu dans le ciel et l'empereur aurait vu en songe la nuit même le Christ, qui lui aurait montré un chrisme en lui disant : « Par ce signe, tu vaincras » ("In hoc signo vinces"). C'est suite à cette apparition que Constantin aurait fait apposer sur l'étendard (labarum) et sur le bouclier de ses légionnaires un chrisme, formé des deux signes Khi (Χ) et Rhô (Ρ), premières lettres grecques du mot "Christ". La part de légende dans cette histoire reste largement discutée, d'autant que le chrisme (☧) est un signe ambigu, qu'en 312 l'empereur continue d'adorer le Sol Invictus et que Eusèbe de Césarée lui-même ne reprend pas à son compte cette apparition, et se contente de rapporter les propos de l'empereur. L'apparition céleste d'un chrisme flamboyant a pu être attribuée à la chute de météorites ayant formé le cratère de Sirente, mais la simultanéité des deux événements n'a pas pu être démontrée. Constantin s'appuie à nouveau sur des songes d'origine divine : en 309 une vision du dieu Apollon lui conférant un signe solaire de victoire lui serait apparue dans le sanctuaire gallo-romain de Grand. 

En 313, Constantin rencontre Licinius à Milan et conclut avec lui un accord de partage de l'Empire. Parmi les mesures prises en commun figure un édit de tolérance religieuse, appelé habituellement édit de Milan, qui renouvelle l'édit de Sardique pris par Galère en 311. Il ne s'agit pas formellement d'une officialisation du culte chrétien, mais plutôt de sa mise à égalité avec les autres cultes. Ainsi, les chrétiens ne sont plus victimes de discriminations, leur culte est autorisé et les biens qui leur ont été confisqués leur sont rendus. Cette déclaration offre à ses auteurs le soutien des chrétiens persécutés dans la partie orientale de l'Empire par l'empereur Maximin Daïa - que Licinius aura tôt fait de défaire la même année à Tzurulum.

Le problème qui divise encore les historiens est celui de la conversion de l'empereur. Il ne fut baptisé que sur son lit de mort en 337, par l'évêque chef des ariens, Eusèbe de Nicomédie. Ce baptême tardif est toutefois conforme à la coutume en vigueur à l'époque, les fidèles attendant le dernier moment pour recevoir le baptême afin d'être lavés de tous les péchés antérieurs : il peut s'interpréter comme la révélation d'un cheminement intérieur remontant à près d'un quart de siècle.

Plusieurs historiens attribuent cette conversion à l'appât du gain : Constantin se serait fait chrétien pour piller les temples païens, afin de financer Constantinople. Pour Zosime, l'empereur se serait converti en 326, pris de remords après avoir fait périr d'une part le fils aîné Crispus que lui donna sa première épouse Minervina, et d'autre part sa seconde épouse Fausta. Une autre version, rapportée par des païens de la ville d'Harran, prétend que Constantin, alors atteint par la lèpre, se serait converti car les chrétiens acceptaient dans leur rang les lépreux. Il aurait dû pour se soigner prendre un bain du sang de nouveau-nés mais, touché par les pleurs des mères, ne put s'y résoudre. C'est alors que lui seraient apparus en songe la nuit suivante saint Pierre et saint Paul, qui lui conseillèrent de retrouver l’évêque Sylvestre sur le mont Soracte : lors de cette rencontre l'empereur Constantin aurait été baptisé et soigné de sa terrible maladie. Mais la tradition chrétienne, faisant souvent référence, qui s'appuie sur les écrits d'Eusèbe de Césarée et le livre de Lactance, situe la conversion de l'empereur en 312, lors d'une vision reçue peu avant la bataille du pont Milvius.

Le père de Constantin, Constance Chlore, était un païen monothéisant, attaché au culte de "Sol Invictus" (« dieu soleil ») comme de nombreux officiers illyriens, et Dioclétien ne l'aurait jamais fait César s'il avait été chrétien. Il se comporta toutefois avec mesure lors de la "grande persécution", durant laquelle il se serait contenté de détruire quelques édifices en Gaule, selon Eusèbe de Césarée.

La mère de Constantin, Hélène, devient chrétienne à une date indéterminée. Répudiée par Constance Chlore, elle sera réhabilitée et proclamée "Augusta" (impératrice) par Constantin en 324, et œuvrera aux côtés de son fils à la propagation du christianisme. Elle est considérée comme sainte dans les religions catholique (18 août) et orthodoxe (21 mai) .

Les historiens actuels émettent plusieurs hypothèses : Constantin ne se serait jamais converti, car il aurait toujours été chrétien, ou encore sa conversion aurait été un calcul politique afin de pouvoir unifier l'empire sans imposer aux Romains sa religion personnelle.

Les chrétiens ne constituent alors qu'une faible minorité des sujets de Constantin, répartis très inégalement à travers l'Empire, essentiellement en Orient et en Afrique du Nord. Constantin est au départ un empereur païen, un polythéiste qui honore Sol Invictus, mais qui s'intéresse depuis longtemps au christianisme, qu'il finira par adopter comme religion personnelle.

Le ralliement de Constantin au christianisme s'accompagne d'une politique impériale favorable aux chrétiens, mais le paganisme n'est jamais persécuté, car pour lui, l'unité de l'empire passe avant tout. Plusieurs indices témoignent de cette évolution ambivalente. Constantin fait du jour du soleil païen ("dies solis"), le dimanche, un jour de repos légal. Il reconnaît les tribunaux épiscopaux à côté des tribunaux civils. Il entreprend la construction d'églises ou de grandes basiliques, comme la Basilique Saint-Jean-de-Latran, de Saint-Pierre de Rome, Sainte-Sophie de Constantinople ou le Saint-Sépulcre de Jérusalem, mais il frappe une monnaie aux effigies explicitement païennes et exaltant le dieu soleil. Il garde jusqu'à sa mort le titre de Grand Pontife (Pontifex Maximus), qui lui donne autorité sur les cultes publics païens.

Le processus de christianisation de l'Empire à partir de Constantin demeure un phénomène discuté, comme en témoignent les travaux des historiens Ramsay MacMullen et Paul Veyne, cités en bibliographie : ils esquissent pour le second une christianisation paisible et insensible (Veyne) et pour l'autre un processus forcé, accompagné - par effet "boomerang" - d'une paganisation du christianisme. 

Dans ces conditions, Jean-François Kahn estime que « Ce fut peut être la plus grande ruse de Constantin que de rattacher le christianisme au pouvoir plutôt que de devoir céder le pouvoir au christianisme ».

Constantin montre son désir d'assurer à tout prix, par la conciliation ou la condamnation, l'unité de l'Église, qu'il considère dès ce moment comme un rouage de l'État, et l'un des principaux soutiens du pouvoir. Il devient, ce faisant le véritable « président de l'Église ». Au début du , ce projet sera contrarié par des crises, dont les plus importantes sont la sécession donatiste et la crise arienne.

Le donatisme naît à propos d'un problème de légitimité de l'évêque de Carthage, Caecilianus, ordonné en 312 : l'un de ses consécrateurs avait livré des objets sacrés lors d'une persécution. Certains chrétiens décrètent que la cérémonie n'avait de ce fait aucune valeur, et élisent un autre évêque, Donatus. Ses partisans nient toute validité aux sacrements conférés par Caecilianus, et provoquent des affrontements pour contrôler les lieux de culte. Constantin tente en vain d'apaiser la rupture par des lettres aux adversaires, puis, devant l'intransigeance des donatistes, convoque lui-même les synodes du Latran (313) et d'Arles (314) qui condamnent le donatisme. Au début de 317, l'empereur promulgue un décret qui ordonne aux donatistes de restituer les églises qu'ils occupent. Devant leur refus, Caecilianus demande l'intervention de l'État pour le faire exécuter, mais il y a plusieurs morts. Constantin finit par céder et promulgue en 321 un édit de tolérance laissant aux donatistes les églises qu'ils contrôlent, tout en maintenant sa condamnation de principe.

À la différence du donatisme, qui resta confiné à l'Afrique, l'arianisme se répandit dans tout l'Orient. Voulant mettre fin à la querelle qui divise les chrétiens à propos des rapports entre le Fils et le Père, Constantin convoque et préside, sous l'impulsion de son conseiller Ossius de Cordoue — l'un des rares théologiens chrétiens occidentaux de l'époque — un concile œcuménique le dans la ville de Nicée, en Bithynie. La conception inspirée par les thèses du prêtre Arius (subordination du Fils au Père) y est condamnée. À partir de ce concile, par opposition au christianisme « arien » ou « homéen » et jusqu'à la séparation des Églises d'Orient et d'Occident, on parlera de christianisme « nicéen », « orthodoxe » ou « homoousien » : 

Ainsi se met en place, sous le règne de Constantin, ce qu'il est convenu d'appeler un césaropapisme, c'est-à-dire un régime, comme l'a montré l'historien Gilbert Dagron, dans lequel les pouvoirs politique et religieux, bien que séparés, ne sont pas dissociables, car le détenteur du pouvoir politique, considéré comme désigné par Dieu, participe de la nature épiscopale et exerce son autorité sur l'Église. Les évêques tentent dès le règne de Constantin, et encore davantage sous ses successeurs, d'asseoir l'autorité de l'Église face au pouvoir impérial, en particulier dans le domaine du dogme, et d'autre part de marquer qu'en tant que chrétien, l'empereur doit être soumis aux mêmes obligations morales et spirituelles que les autres fidèles.

Tout comme Dioclétien, Constantin ne rompt pas pleinement avec la tradition du Haut-Empire (l'empereur demeure un magistrat qui porte les titres romains traditionnels) ni avec les apports de la tétrarchie :

Il abandonne néanmoins les formes religieuses élaborées sous la tétrarchie, d'abord par un retour au modèle « solaire » des empereurs pré-tétrarchiques puis par l'abandon de la protection des dieux tutélaires de Rome et de l'Empire, pour un dieu nouveau, le dieu des chrétiens. Le monothéisme devient le fondement idéologique de la monarchie constantinienne, ses idées politiques étant inspirées de principes unitaires, alors que le polythéisme convenait sans doute mieux à l'idéal de la tétrarchie : il n'existe qu'un seul Dieu, il ne doit y avoir qu'un seul monarque qui gouverne selon la volonté divine. Son principal théoricien, Eusèbe de Césarée, affirme, dans le "Discours des Tricennales", que le royaume terrestre de Constantin est à l'image du royaume de Dieu, et que l'empereur est entouré de ses Césars comme Dieu l'est de ses anges : il se peut qu'à la fin de sa vie, Constantin ait jugé que l'arianisme correspondait mieux à l'idée qu'il se faisait d'une monarchie divine, avec le Fils subordonné au Père, sur laquelle se modèle sa propre monarchie, avec des Césars étroitement mis sous tutelle.

En fait, la christianisation du pouvoir impérial a été lente, car Constantin était obligé de tenir compte du poids des traditions, surtout parmi les élites :

Constantin ne néglige pas la défense de l'Empire, facilitée par les mesures prises par ses prédécesseurs à l'époque de la tétrarchie. Trois fronts retiennent tour à tour l'attention de Constantin.

D'abord celui du Rhin, où son père, Constance Chlore, s'est illustré, et où Constantin a longtemps séjourné, faisant de Trèves sa capitale. Il combat les Francs et les Alamans en 306, 309 et 313. Les opérations sont momentanément interrompues au moment de l'affrontement avec Licinius. Une fois seul maître de l'Empire, il envoie ses fils Crispus et Constantin II combattre les Francs et les Alamans. Le grand nombre de monnaies constantiniennes retrouvées dans ces régions en pays barbare atteste de la reprise des relations commerciales une fois le calme revenu.

Les guerres danubiennes sont moins bien connues. En 322, il remporte une grande victoire sur les Sarmates à Campona, puis la même année, ou en 324, il refoule les Goths, qui ont franchi le Rhin. En 332, le César Constantin II leur inflige une grave défaite.

La Perse, depuis la paix de 297 conclue sous la tétrarchie, est demeurée relativement tranquille. Les relations se dégradent à nouveau à partir de 333, année où les Perses tentent de dominer l'Arménie, et à la suite des persécutions contre les chrétiens perses, alors que Constantin prétend être partout leur protecteur, y compris hors de l'Empire. La guerre est de nouveau déclarée, peut-être par les Perses, en 337. Selon Eusèbe de Césarée dans sa "Vie de Constantin", l'empereur romain l'aurait envisagée comme une « croisade » avant la lettre : des évêques doivent l'accompagner dans son Conseil, mais l'empereur meurt en mai 337, au milieu des préparatifs de la campagne.

Constantin, tout comme ses prédécesseurs de la tétrarchie, est préoccupé par la défense de l'Empire. La nouvelle stratégie politico-militaire de Constantin admet que l'armée des frontières peut-être battue sur certains fronts, que le limes soit enfoncé et que les combats décisifs peuvent se dérouler à l'intérieur des frontières. L'empereur poursuit la politique de Gallien et de Dioclétien sur le front danubien, en introduisant des barbares sur le territoire romain : en échange de la protection des frontières et de la fourniture d'un contingent militaire, ces derniers reçoivent des subsides de l'État, des rations alimentaires et des tentes destinées à les sédentariser. L'aboutissement logique de cette évolution est, dès le règne de Constance II (337-361), l'accession de barbares aux plus hauts postes de l'état-major. L'armée romaine, sous son règne, atteint son effectif maximum de 500 000 hommes.

De nouvelles unités appellent un nouvel encadrement. Les carrières militaires et civiles sont définitivement séparées : les préfets du prétoire et les vicaires sont confinés dans des fonctions purement administratives et les gouverneurs sont déchargés de toute préoccupation militaire, au profit de professionnels de la guerre : 
Le pouvoir impérial est renforcé par le morcellement des compétences, mais une telle décision risque à terme d'affaiblir la valeur de l'armée et de ses chefs.

En 337, Constantin vient de déclencher un conflit avec la Perse Sassanide de Shapur II et s'apprête à mener une expédition contre cet empire, quand il meurt subitement près de Nicomédie. Il est baptisé sur son lit de mort et enterré dans l'église des Saints-Apôtres, qu'il a fait construire à Constantinople.

Quand Constantin meurt, il n'a pas réglé sa succession. Ses trois fils se proclament Augustes, tandis que les autres membres de la famille impériale sont assassinés (sauf les jeunes Julien et Gallus). Ils se partagent l'Empire, mais Constantin II et Constant entrent en conflit. Après les décès de ces deux frères, l'Empire sera réuni sous l'autorité du seul fils survivant de Constantin, Constance II, qui nomme deux césars, aux pouvoirs très réduits.

Le nouvel empereur poursuit la politique de son père, autant dans le domaine religieux (il favorise l'arianisme) que militaire (en luttant sur les fronts germain, rhéno-danubien, et perse).

D'après Eusèbe de Césarée, Constantin serait mort le dimanche de Pentecôte . Il est inscrit dans la plupart des calendriers orthodoxes le 21 mai avec sa mère Hélène, parfois le 22 (comme dans le lectionnaire de Jérusalem), comme Saint Constantin (Άγιος Κωνσταντίνος). Il est considéré dans l'église orthodoxe grecque comme Ισαπόστολος Κωνσταντίνος : « Constantin égal aux Apôtres ».





</doc>
<doc id="15738" url="https://fr.wikipedia.org/wiki?curid=15738" title="Masse volumique">
Masse volumique

La masse volumique, aussi appelée volumique de masse, est une grandeur physique qui caractérise la masse d'un matériau par unité de volume.

Elle est généralement notée par les lettres grecques "ρ" ("rhô") ou "µ" ("mu"). On utilise ces deux notations en fonction des habitudes du domaine de travail. Toutefois, le Bureau international des poids et mesures (BIPM) recommande d'utiliser la notation "ρ".

Elle est déterminée par le rapport
où "m" est la masse de la substance homogène occupant un volume "V".

La masse volumique est le synonyme moderne des expressions désuètes « densité absolue » et « densité propre », ou encore « masse spécifique ».

La masse volumique est l'inverse du volume massique.

L'unité de mesure de la masse volumique dans le Système international est le kilogramme par mètre cube (). Dans le système CGS, elle s'exprime en , ce qui a l'avantage de donner des valeurs numériques de l'ordre de l'unité pour les solides dans les conditions normales de température et de pression (CNTP).

On utilise couramment le , le ou la (ces trois dernières unités étant numériquement équivalentes) ou toute autre unité exprimée par le rapport d'une unité de masse et d'une unité de volume.


La densité d'un matériau est, pour les solides et les liquides, le rapport de la masse volumique de ce matériau à celle de l'eau.

Pour les gaz, la densité est calculée en rapport avec la masse volumique de l'air.

Dans les deux cas, la densité est forcément un nombre sans dimension.

La masse volumique de l'eau valant, à , , la densité d'un liquide ou d'un solide s'exprime par la même valeur numérique que sa masse volumique en g/cm³ ou en kg/ℓ : par exemple, il est équivalent de dire que la densité de l'éthanol est de 0,79 ou que sa masse volumique est de .
Ceci donne lieu à des confusions fréquentes entre les concepts de masse volumique et de densité. À noter également comme source d'erreur supplémentaire, la traduction anglaise de masse volumique qui est "density". (En anglais, densité se dit "relative density".)

Les valeurs données dans les tableaux de cet article sont définies par cette masse volumique qui est la plus couramment utilisée pour les matériaux de manière générale. C'est le rapport entre la masse de matériau et le volume apparent de l'ensemble des grains. 

Pour les matériaux usuels de construction (sable, graviers, etc.) cette masse volumique varie entre et .

C'est le rapport entre la masse de matériau et le volume réel des grains (somme des volumes élémentaires des grains y compris le volume des pores fermés).

Pour les granulats courants, cette masse volumique varie entre et et pour le ciment, elle varie entre et selon la catégorie.

Cette grandeur est intéressante pour les matériaux poreux. Pour y accéder, il faut broyer très finement le matériau et mesurer la masse volumique réelle de la poudre obtenue. C'est le rapport de la masse du matériau sur le volume réel auquel on a soustrait le volume des pores (ouverts et fermés). La masse volumique absolue est égale à la masse volumique réelle dans le cas des matériaux non poreux.

La masse volumique d'un liquide, d'un solide ou d'une pâte peut être déterminée à l'aide d'un pycnomètre ou par le débitmètre à effet Coriolis. Pour les solides, il est possible également d'utiliser une balance et d'effectuer une pesée dans l'air puis une pesée dans un liquide (l'eau de préférence), cette méthode permet une plus grande précision.

Une autre possibilité pour déterminer les densités de liquides et de gaz est d'utiliser un instrument numérique basé sur le principe du tube en U oscillant, dont la fréquence de résonance est déterminée par les matériaux, comme la masse d'un diapason est cruciale à la hauteur du son.

La masse volumique d’une solution idéale est la somme des concentrations massiques (masses volumiques partielles) des composants de la solution :

où "m" est la masse du composant "i" dans le mélange, V volume de mélange,
ρ la concentration massique du composant "i" dans le mélange.

Autre expression :

La masse volumique est une "grandeur physique" relative à une quantité de matière présente à l'intérieur d'un espace : c'est donc une grandeur physique "moyenne".

En physique des milieux continus (mécanique des milieux continus, résistance des matériaux, mécanique des fluides, thermique), la masse volumique doit pouvoir être définie en tout point situé à l'intérieur d'un corps solide ou fluide.

Une particule matérielle est, précisément, à l'intérieur d'un corps, une quantité de matière dont la masse volumique est une fonction continue des coordonnées du point, en n'importe quel point que cette particule contient. La masse volumique d'une particule matérielle est donc une "grandeur physique moyenne" qui est, aussi, à l'échelle d'un corps, une "grandeur physique ponctuelle".

La variation de la masse volumique avec la température est décrite par le coefficient de dilatation.

La masse volumique varie selon plusieurs paramètres. Elle dépend notamment de la température et, particulièrement pour les gaz, de la pression. Certains matériaux (dont le bois) pouvant absorber de l'eau, le taux d'humidité modifie aussi la masse volumique. Pour les matériaux poreux (argile, sable, sol, bois), les masses volumiques indiquées sont des masses volumiques apparentes.

Sauf indications contraires, les masses volumiques sont données pour des corps à la température de , sous la pression atmosphérique normale ().

Le bois est une matière vivante dont la masse volumique varie selon plusieurs paramètres, principalement l'essence et l'humidité. Les bois dont la masse volumique dépasse ne flottent pas.

Masse volumique des éléments à l'état standard, à température et pression ambiantes, en g·cm (les éléments d'une densité supérieure à celle de l'osmium ou de l'iridium ont seulement une densité calculée/prédite et non mesurée effectivement, ces éléments radioactifs super-lourds ont été produits en quantité trop faible ou se désintègrent trop vite pour permettre une mesure) : 
Masse volumique des éléments à leur point de fusion en g·cm :




</doc>
<doc id="15739" url="https://fr.wikipedia.org/wiki?curid=15739" title="Kiev">
Kiev

Kiev (en /ˈkɪjiu̯/, "Kyïv", "Kyiv" ; en , "Kiev" ; en /ˈkʲijuf/) est la capitale et la plus grande ville d'Ukraine. C'est aussi la capitale de l'oblast de Kiev et l'une des plus anciennes villes de Ruthénie (au sens large). Elle comptait en 2013.

Kiev se trouve sur la rivière Dnipro, au Nord-Ouest du pays. La date exacte de la fondation reste inconnue. Les fouilles archéologiques donnent lieu de croire que Kiev est devenu une ville à la fin de . Kiev a été la capitale de Ruthénie, de la principauté de Kiev, du grand-duché de Ruthénie, de la République populaire ukrainienne, de l’État ukrainien et de la République socialiste soviétique d'Ukraine. Kiev a été aussi le centre administratif du grand-duché de Ruthénie, de la voïvodie de Kiev, du gouvernement de Kiev, du district général de Kiev pendant la Seconde Guerre mondiale et de l'oblast de Kiev.

La ville est un des plus anciens centres de l'Europe de l'Est et du christianisme. La cathédrale Sainte-Sophie et la laure des Grottes de Kiev sont inscrits sur la liste du patrimoine mondial. 
La vieille ville est construite sur des collines surplombant le fleuve Dniepr ("Dnipro" en ukrainien).
La ville actuelle s'étend sur les deux rives du fleuve, près de son confluent avec la Desna.

Kiev bénéficie d'un climat continental. Si on se réfère à la classification de Köppen il est de type Dfb (climat tempéré froid sans saison sèche avec été tempéré). La neige recouvre le sol en moyenne 97 jours par an entre mi-novembre et fin mars. La hauteur de neige atteint en moyenne en février (maximum de ). Le record de précipitations reçues sur une année est de en 1933. L'année la plus sèche a été 1975 avec seulement de précipitations reçues.
La ville possède un réseau de trois lignes de métro d'une longueur totale de . Sa construction remonte à la seconde moitié du . Une quatrième ligne est en cours de construction. L'étendue de la ville et l'éloignement entre les stations exige pour le compléter un dense réseau de bus, trolleybus et tramway. Alors que les projets de construction et d'agrandissement du réseau sont loin d'être achevés, à partir de la seconde moitié des années 2000, ce système de transport en commun arrive à saturation. Les probables explications sont multiples : forte croissance de l'activité économique, augmentation de la population active et étudiante et émigration d'origine rurale.

Alors qu'à la même époque, la majorité des villes européennes construisaient de nouvelles lignes de tramway, la ville de Kiev a détruit une partie de ses lignes durant les années 1990. Une politique inverse est de nouveau à l'étude. Il y a 21 lignes. À Kiev il y a aussi les autobus (70 lignes) et trolleybus (39 lignes).

La vieille gare de Kiev a été construite entre 1868-1870 par l'architecte V. Vychnevetskyi. La gare actuelle a été construite entre 1927-1932 et conçue par O. Verbytskyi. Elle est accessible depuis le métro 1.

La compagnie PZZ, (Ukrainien: Південно-Західна залізниця) est une composante de la société Ukrzaliznytsia. Elle gère les transports ferroviaires de la région de Kiev.

Il y a 5 directions d'elektrichka (train de banlieue) à partir de Kiev : 

Kiev est desservi par trois aéroports :

Kiev est la capitale de l'Ukraine depuis 1934 et contient donc les principaux organes du gouvernement (résidence présidentielle, parlement, ministères, offices nationaux).

Kiev est une municipalité indépendante de l'oblast du même nom et gérée au niveau national. Cependant, le gouvernement de l'oblast est situé dans la ville.

D'un point de vue administratif, la transcription en alphabet latin du nom de la ville est « Kyiv » depuis la décision du 14 octobre 1995 adoptée par la Commission ukrainienne de la terminologie officielle. Cette orthographe correspond davantage à la prononciation réelle du nom que l'ancienne orthographe « Kiev » car le « e » est atténué et donne un son semblable à celui d'un « i ». De plus, cette transcription est plus proche de l'orthographe ukrainienne.

La ville de Kiev est divisée en 10 districts administratifs ("raïons").

La ville de Kiev est divisée en 10 districts ("raïons"). Trois districts sont situés sur la rive gauche du Dnipro et sept sur la rive droite. Chacun compte au moins 10 microraïons (ou microdistricts). Par exemple, le district de Petcherskyï compte les microdistricts historiques de : Petchersk, Lypky, Klov, Vydoubytchi, Zvirinets, Telytchka, Tchorna Hora etc.

La grande ville de Kiev rendait hommage aux Khazars ; le nom de Kiev provient du prénom d'un des princes slaves fondateurs de la ville : Kyi, l'ainé des quatre fondateurs de la ville avec Shchek, Khoryv et leur sœur Lybid. Durant son histoire, Kiev, l'une des plus vieilles villes d'Europe de l'Est, passa par plusieurs étapes, de la grandeur jusqu'à une relative obscurité.

L'archéologie a montré que le site de Kiev a connu une très longue occupation humaine depuis le Paléolithique jusqu'à nos jours. De très nombreuses découvertes ont été faites.

La ville fut probablement fondée au et fonctionna comme pôle commercial entre Constantinople et la Scandinavie. Entre les s'est formé le centre pré-urbain sur la colline Zamkova. Le site couvrait alors 4 hectares et devait être protégé par une palissade de terre et de bois, semblable à celle que les archéologues ont retrouvée sur la colline voisine Starokievska, protégeant un autre site pré-urbain de même époque, d'environ deux hectares. Là se trouvait le centre du pouvoir politique et religieux, comme le prouve la découverte du sanctuaire dédié à Svjatovit-Rod.

C'est entre les que Kiev, centre pré-urbain des Poljanes, se transforme en une ville importante d'environ 11 hectares. Les princes commencent alors le rassemblement des tribus slaves auxquelles ils imposent la tournée fiscale appelée "poljudie". Le nom de Kiev paraît pour la première fois dans la Chronique des Temps Passés ("Povjest vremennykh let s. a." 862). Trois frères, Kij, Scek et Khoriv sont présentés comme les fondateurs de Kiev qui, en réalité, est déjà un centre politique affirmé.

En 882, Kiev fut prise par Oleg (en ukrainien "Oleh"), un Varègue, le successeur de Riourik, prince ("kniaz") de Novgorod et elle devint la capitale du premier État ruthène (la Rus' de Kiev, connu en Europe sous le nom de Principauté de Kiev.).

Le christianisme grec y fut introduit peu de temps après par Olga (ou "Olha"), la régente de Kiev (945-964) ; puis il fut imposé par Vladimir (980-1015), considéré comme le véritable fondateur de l'empire de Kiev.

C'est au cours des que Kiev connaît un développement urbain et architectural exceptionnel, rendu possible par l'exploitation de la "célèbre route des Varègues aux Grecs", le long de laquelle s'organise un commerce important vers Constantinople, bien régulé par les traités de commerce de 912, 945 et 971.

Profitant de cette croissance économique, le prince Vladimir veut construire un État centralisé dont Kiev doit être la capitale. Après avoir échoué dans sa tentative de s'appuyer sur le dieu païen Péroun, Vladimir est baptisé à Chersonèse en 989 par le clergé byzantin et épouse la princesse porphyrogénète Anne. Il entend alors doter Kiev, sa capitale à l'architecture en bois, du signe visible de sa nouvelle foi en confiant à des maîtres grecs la construction d'une merveilleuse cathédrale en brique et en pierre, décorée de somptueuses fresques et mosaïques, l'église de la Sainte-Mère-de-Dieu, dite de la Dime (989 - 993). Elle est érigée au cœur de la ville nouvelle dit « ville de Vladimir », à proximité du marché des Grands-mères ("Babyn torzok"). Cette œuvre d'urbanisme sera encore amplifiée sous le règne de son fils et successeur, Iaroslav le Sage (1018 - 1054). La "ville de Iaroslav" est dessinée autour de trois bâtiments majeurs, les monastères Saint-Georges et Sainte-Irène qui bordent la voie qui conduit à la merveille du septentrion, la cathédrale Sainte-Sophie de Kiev (1037 - 1041), comme la désigne le métropolite Hilarion dans son célèbre "Dit sur la Grâce et la Foi".

Sur la rive gauche du Dniepr, dominant le fleuve de quelque , se dresse par ailleurs Kiev, dont les 400 églises, les 8 marchés et la foule innombrable de ses habitants provoquèrent, en 1018, l'admiration de l'évêque Thietmar de Mersebourg.

Kiev est alors une ville importante qui rassemble plus de répartis sur les de la ville haute et les de la ville basse ou "podol". Cette croissance urbaine, qui voit se multiplier les monuments religieux, est couronnée par la fondation, hors de Kiev, mais à proximité de la ville, du célèbre monastère des Grottes ("Petcherska Lavra") en 1051, sous la direction d'Antoine, puis de Théodose.

Siège de la chaire métropolitaine de Kiev, lieu de rayonnement d'églises et de monastères d'inspiration byzantine, résidence princière mais aussi centre de production de manuscrits, Kiev brille alors de toute sa splendeur. L'alliance avec la dynastie des Rurikides est recherchée par les principales cours européennes. Le roi de France Henri en fera venir Anne, fille du prince Iaroslav, qu'il épousera en 1049.

Il s'amorce peu après la mort de Iaroslav en 1054. Le système successoral de frère à frère engendre de longs et violents conflits entre oncles et neveux dont l'enjeu est la possession du trône de Kiev. En conséquence, ces conflits affaiblissent la ville et en font une proie tentante pour les peuples de la steppe, les "Polovtsi". C'est en 1169 que Kiev succombera sous les coups du prince de Vladimir, Andréj Bogoljubskij à la tête d'une coalition princière. La ville est pillée et mise à sac. Ce n'est que le début d'un long déclin, marqué par un nouveau sac perpétré en 1203 par Rjurik Rostislavic, avant la prise de la ville, ou plutôt ce qu'il en restait après le passage des Tatars de Batu Khan le . Cette fois-ci, c'en est bien fini pour Kiev de sa splendeur d'antan. En 1362, Kiev est prise une nouvelle fois par le prince Olgerd de Lituanie qui en fait un bien patrimonial pour son fils, Vladimir.

De 1363 à 1667, Kiev fait partie de l'Union de Pologne-Lituanie, qui devient, par l'Union de Lublin en 1569, la République des Deux Nations. À la fin du , Kiev adopte le droit de Magdebourg. Après l'union de Brest (1596), Kiev devient l'un des lieux majeurs de l'affrontement entre uniates et orthodoxes.

À la suite de la révolte des Cosaques de 1648, le hetman Bogdan Khmelnitski fait une entrée triomphante dans Kiev. Il cherche à établir un État ukrainien indépendant, l'Hetmanat cosaque. Cependant, la guerre avec la puissante armée polonaise devient très difficile, et Khmelnitski se tourne vers une alliance avec le tsar de Moscovie. Par le traité d'Androusovo de 1667, Kiev fait partie des territoires ukrainiens placés sous le protectorat de Moscou. Ces territoires seront incorporés par la suite dans l'Empire russe. L'Hetmanat cosaque disparaît officiellement sous le règne de la tsarine Catherine II.

Au , Kiev prit un certain essor grâce au développement du chemin de fer.

En 1834 fut fondée une université (aujourd'hui l'Université d'État de Kiev ou l'Université Tarass-Chevtchenko.

En 1917, à la suite de la révolution russe de la même année, Kiev devint la capitale de la nouvelle République populaire ukrainienne qui proclame son indépendance vis-à-vis de la Russie. La Rada centrale s'installe à Kiev et exerce le pouvoir législatif.

En 1920, la ville tomba aux mains des bolcheviks. Début de la période soviétique dans l'histoire de Kiev.

En 1934, Kiev devint la capitale de la République socialiste soviétique d'Ukraine (RSSU) en remplacement de Kharkov.

Pendant la Seconde Guerre mondiale, elle fut occupée par l'Allemagne nazie du au , date de la reprise de la ville par l'Armée rouge. La ville fut gravement endommagée par cette occupation. Les 29 et , dans un ravin situé à Babyn Yar (Babi Yar en russe) près de Kiev, les SS massacrèrent les juifs restés en Ukraine ; les autres avaient été déplacés au-delà de l'Oural par les troupes soviétiques durant l'année 1941. Le nombre de victimes de ce massacre est mal connu, mais les chiffres varient de à (voir Massacre de Babi Yar).

De 1942 à octobre 1943, 30 000 personnes furent assassinées au camp de concentration de Syrets au nord de la ville. 

À la fin de la guerre, Kiev reçut le titre de Ville héros, au même titre qu'Odessa, Sébastopol et Kertch, autres villes ukrainiennes à avoir reçu ce titre pour commémorer la résistance féroce opposée aux troupes allemandes.

En 1991, après la chute de l'URSS, Kiev devient la capitale de l'Ukraine indépendante. La ville s'ouvre alors à l'économie de marché, son aspect se modernise rapidement et prend l'allure d'une grande capitale européenne. De nos jours Kiev concentre l'attractivité et les ressources du centre économique, financier et culturel de l'Ukraine.

En novembre 2004, Kiev devient le centre d'une vaste campagne de protestation pacifique (Révolution orange) qui confirme les choix démocratiques de la société ukrainienne.

En janvier 2014, de nombreuses personnes sont blessées par des cocktails Molotov. Il y a des explosions, des barricades sont érigées et de nombreux pneus sont enflammés.Les affrontements entre la police et les manifestants qui réclament la démission du Président Ianoukovitch font plusieurs centaines de blessés; plusieurs morts sont à déplorer. Fin janvier 2014, la contestation qui a débuté à Kiev semble s'étendre à l'ensemble du pays.

En juillet 2016, le conseil municipal décide de renommer l' "Avenue de Moscou" en "Avenue Bandera" du nom du nationaliste ukrainien Stepan Bandera.

Recensements (*) ou estimations de la population :

Kiev fait partie des rares capitales d'Europe orientale a connaître depuis la fin du communisme en Europe un accroissement total (naturel et migratoire) positif de sa population. La ville a toutefois connu un accroissement naturel négatif (plus de décès que de naissances) entre 1993 et 2007 qui a été cependant compensé par l'immigration durant cette période.

Le taux de natalité en 2013 de 11,7 pour mille (contre de 12,0 pour mille en 2012) était supérieur de 5 points à la moyenne nationale tandis que le taux de mortalité était de 9,8 pour mille la même année (contre un taux de 9,8 pour mille en 2012) était inférieur d'environ 65 pour cent à la moyenne nationale.

Au , la ville a connu des changements importants de sa composition ethnique. La dislocation de l'Union soviétique a amplifié un peu le mouvement comme le montrent les tableaux officiels ci-après. Globalement, la part des Ukrainiens a fortement augmenté passant ainsi de 31 % en 1874 à 82 % en 2001, tandis qu'au cours de la même période la part des Russes a chuté de 58 % à 13 % de la population. Au niveau national (pour toute l'Ukraine) en 2001, les Ukrainiens représentent 67 %, les Russes 30 %, et les autres 3 %, ce qui montre d'une part, que la proportion des Ukrainiens à Kiev est plus forte que dans le reste du pays, et d'autre part que la proportion des "autres" est plus forte aussi, ce qui se retrouve également dans d'autres capitales.

Âge médian :

Kiev est un centre industriel, scientifique, culturel et d'éducation important de l'Europe orientale. C'est le siège de nombreuses entreprises de haute technologie, d'institutions universitaires, de musées et d'institutions artistiques.


En mai, les visiteurs de Kiev peuvent découvrir le festival du printemps.
Les week-ends, les rues du centre-ville (comme le fameux "Khrechtchatik") sont fermées à la circulation des véhicules au profit des piétons.
Au mois d'août se tient le Festival international du film de Kiev ou Stozhary.

Chaque année la ville accueille les IEM (Intel Extrem Master) OP KOREAN SKILL.

En juillet 2011, Kiev a accueilli le congrès international de la jeunesse qui rassemble des participants venant du monde entier et dont la langue de travail est l'espéranto.

Le centre spirituel et patrimonial de la ville est la laure des Grottes de Kiev et la cathédrale Sainte-Sophie de Kiev. La cathédrale, commencée en 1017 et achevée en 1037, a été conçue pour émuler la splendeur des églises byzantines. Bien qu'elle soit consacrée à la « sainte sagesse », comme la grande cathédrale de Constantinople, elle a une forme très différente. Plutôt qu'un unique dôme hémisphérique s'élevant au-dessus du corps du bâtiment, Sainte-Sophie possède 13 dômes en forme de bulbe. Le dôme central est doré et un peu plus grand que les autres qui sont verts, et tous ont des lanternes dorées.

Kiev compte aussi plus d'une cinquantaine de gratte-ciel construits quasiment tous depuis les années 2000.

Trois clubs de football jouent en première division ukrainienne: Dynamo Kiev, Arsenal Kiev et le FC Obolon Kiev (2011-2012).

Hockey sur glace : HK Sokil Kiev

Basketball : BC Kiev



La Porte dorée de Kiev inspira l'architecte et peintre russe Viktor Hartmann, pour son dessin de projet pour "La Grande Porte de Kiev". Elle devait servir lors du concours organisé par l'empereur Alexandre II en 1866, pour la construction d'une grande porte monumentale à l'entrée de la ville. Bien que le projet fut annulé faute d'argent, le dessin fut conservé.

Le compositeur russe Modeste Moussorgski s'inspira de plusieurs peintures de son ami Viktor Hartmann, exposées un an après sa mort (dont la "Porte de Kiev") afin de réaliser sa « série de dix pièces pour piano » en 1874 : "Tableaux d'une exposition".

Honoré de Balzac, écrivain français, a beaucoup voyagé pour rencontrer son admiratrice et future épouse, la polonaise Ewelina Hańska, avec qui il a d'abord entretenu une longue relation épistolaire. Il la rencontre notamment dans ses domaines de Kiev, dont l’opulence l'impressionne au point qu'il écrit . Il raconte sa découverte de la ville dans des lettres formant un ensemble de 61 feuillets (seulement écrits au recto), paru sous le nom de "Lettre sur Kiev".

À la suite de l'écrivain Mikhaïl Boulgakov, la romancière russe d'expression française Irène Némirovsky exalte dans plusieurs de ses romans ou nouvelles la splendeur du printemps en fleurs dans la ville haute de Kiev ; elle y décrit aussi sans fard la misère profonde du Podol, cœur historique de la ville devenu à l'époque impériale le ghetto des Juifs pauvres.


Kiev est en partenariat avec :





</doc>
<doc id="15741" url="https://fr.wikipedia.org/wiki?curid=15741" title="British Broadcasting Corporation">
British Broadcasting Corporation

La (BBC) fondée en 1922 est une société de production et de diffusion de programmes de radio-télévision britannique.

Ayant son siège au Royaume-Uni, c’est un (équivalent d’une autorité administrative indépendante) chargé des médias. La BBC bénéficie d’une réputation d’excellence culturelle, et est parfois affectueusement appelée « » ou « » (langage enfantin pour tante) par les Britanniques. Pendant longtemps, elle est restée la seule société diffusant des programmes de télévision et de radio au Royaume-Uni. 

C’est la plus importante société de diffusion au monde en termes de revenu brut et de téléspectateurs.

Avant la venue de ITV () en 1955 et des radios locales privées dans les années 1970, elle détenait le monopole de diffusion.

Avant le lancement de la BBC en 1922, un certain nombre de sociétés privées avaient effectué des expérimentations de diffusion radiophonique. Selon les termes de la loi de 1904 sur la télégraphie sans fil, la Poste était compétente pour l'octroi de licences de diffusion radiophonique. 
Mais en 1919, à la suite des nombreuses plaintes déposées par l'armée au sujet de nombreuses interférences d'émission de radio avec les communications effectuées par les forces armées, elle dut arrêter d'accorder toute nouvelle licence. 

En 1922, la British Broadcasting "Company" (BBC) est fondée par un consortium comprenant Marconi, GEC, British Thomson Houston, Metropolitan-Vickers, Western Electric et la Radio Communication Company. Lancement de deux radios expérimentales : 2MT et 2LO. Une première émission quotidienne débute le 14 novembre depuis le studio londonien de Marconi. En droit anglais, une "company" est une société de capitaux et l'objectif de ce consortium de droit privé est simplement d’organiser la radiodiffusion sur les ondes de manière rationnelle. 

En 1927, La BBC devient la "British Broadcasting Corporation", c'est-à-dire une société de droit public constituée par Charte royale. John Reith, qui continue à diriger la BBC jusqu’en 1936, fonde ce grand service public audiovisuel dont l'objectif est d'éduquer, d'informer et de distraire. La BBC diffuse presque partout au Royaume-Uni. Son rôle d'information est favorisé par de grandes grèves qui empêchent la diffusion des journaux : la BBC en profite pour diffuser des informations à tout moment de la journée, ce que, jusqu'alors, elle ne pouvait pas faire. En effet, les éditeurs de journaux faisaient pression pour que la BBC ne diffuse pas d'informations avant que les journaux soient disponibles dans les kiosques. La BBC réussit à se soustraire aux pressions économiques et politiques et n'a de compte à rendre qu'au Parlement qui vote les Chartes royales. Elle doit non seulement informer le public mais aussi le protéger de toute exploitation et garantir la qualité de la programmation. Les journalistes sortent des meilleures universités et leurs obligations sont détaillées dans le "Producer’s Guideline", code de déontologie très détaillé.

Pendant la Seconde Guerre mondiale, la BBC connaît son heure de gloire, notamment pendant la bataille d'Angleterre (juillet 1940-mai 1941), où elle est considérée comme une institution nationale. Au soir du 6 juin 1944, le discours du roi Georges VI est écouté par un taux record de 80 % des Britanniques.

En septembre 2004, La sous-division commerciale BBC Technology est vendue à Siemens avec un contrat de dix ans. La BBC espère ainsi économiser plusieurs dizaines de millions de livres. Siemens équipe maintenant le groupe pour la majorité des équipements techniques et informatiques. Accenture et CSC étaient les deux autres sociétés intéressées par l'achat de la sous-division. En mars 2005, le licenciement de 15 % des effectifs du groupe est annoncé, cela correspond à près de employés. En juillet 2005, la sous-division BBC Broadcast est également privatisée.

En 2010, la BBC met en plan une restructuration. Elle doit mettre en place des économies portant sur près de 1,125 milliards d'euros.

En 2012, la réputation de la BBC est éclaboussée par la révélation du scandale sexuel pédophile concernant le présentateur Jimmy Savile accusé de centaines d'agressions sexuelles dont certaines commises sur les lieux même de son travail à la BBC. Le scandale Savile plonge la BBC dans une crise profonde, l'entreprise publique étant soupçonnée d'avoir étouffé l'affaire. Le rapport d’une enquête interne publié en février 2016 révèle que « certains responsables » de la BBC « étaient au courant ». Le directeur général de la radio George Entwistle avait été contraint de démissionner fin 2012.

En juillet 2015, sur fond de confrontation avec le gouvernement de David Cameron qui reproche à la radio son manque de neutralité politique, de dénonciation des revenus des présentateurs les mieux payés de la radio (entre 700.000 et 7 millions d'euros par an et en hausse de 22% pour 2014) dans un contexte de diminution des redevances, la BBC annonce la suppression de 1 000 postes sur les 16 000 que compte l'entreprise.

En octobre 2016, le licenciement du comédien Jon Holmes pour motif de faire plus de place aux femmes et à la diversité est amplement critiqué dans les médias qui reprochent à la radio d'avoir basé cette décision sur le seul fait que Jon Holmes est « blanc et mâle ». Pour la comédienne Maureen Lipman, cela semble incroyable de licencier « quelqu'un qui a fait une partie du meilleur travail à la radio ». La radio a pour objectif d'augmenter la proportion de ses effectifs issus des milieux ethniques noirs, asiatiques et minoritaires à 15 % pour 2020, tandis que les lesbiennes, gays, bisexuels ou transgenres devraient constituer 8 % du personnel.

La BBC est une société, indépendante de l'intervention directe du gouvernement, ses activités étant supervisées par le BBC Trust. Le management général de l'organisation appartient au Directeur général, qui est nommé par le Trust : le DG est l'éditeur en chef de la BBC et préside le Conseil exécutif.

Le financement de la BBC dépend essentiellement de la redevance audiovisuelle. La BBC a le plus gros budget de n'importe quel groupe audiovisuel britannique, avec un montant de dépenses de 4,7 milliards de £ en 2007 (en comparaison, le groupe Sky a dépensé 3,8 milliards de £, 1,9 milliard pour ITV et 214 millions pour GCap Media).


La BBC édite également BBC Alba, une chaîne régionale en écossais. Elle participe aussi à la production de contenus pour S4C, chaîne régionale du Pays de Galles.

Les chaînes internationales sont produites et gérées par BBC Worldwide.

La BBC compte cinq stations nationales captables sur la FM et la DAB :
La BBC possède quarante stations de radio régionales : les "BBC Local Radio". Radio Leicester a été la première lancée le 8 novembre 1967.

Cinq radios 100 % numériques : 

La radio internationale de la BBC est World Service, station destinée à la communauté du monde, rediffusée au Royaume-Uni. Elle propose des infos, reportages, magazines, divertissements et comédies.







</doc>
<doc id="15742" url="https://fr.wikipedia.org/wiki?curid=15742" title="Homéostasie">
Homéostasie

En biologie et en systémique, l’homéostasie est un phénomène par lequel un facteur clé (par exemple, température) est maintenu autour d'une valeur bénéfique pour le système considéré, grâce à un processus de régulation. Des exemples typiques d'homéostasie sont : la température d'une pièce grâce à un thermostat, la température du corps d'un animal homéotherme, le taux de sucre sanguin, le degré d'acidité d'un milieu, la pression interne d'un milieu... Plus globalement, on désigne aussi par "homéostasie" la capacité globale d'un système à maintenir tout un ensemble de tels facteurs clés, notamment chez un organisme vivant.

Opérant comme un système de régulation, l’homéostasie requiert un capteur (naturel ou artificiel) qui mesure le facteur réel, un actionneur capable d'agir sur sa valeur, et entre les deux un processus d'ajustement permettant de faire varier l'activité de l'actionneur en fonction de la valeur mesurée. En automatisme, il s'agit d'un centre de contrôle quelconque (thermostat, variateur de vitesse...) ; dans un organisme, une multitude de phénomènes existent qui jouent le même rôle de principe. Par exemple, pour la régulation du taux de sucre sanguin, toute une cascade de processus biochimiques impliquant plusieurs hormones participe à cet ajustement. Le concept d'homéostasie en biologie est critiqué par certains auteurs car de nombreuses quantités biologiques ne varient pas autour d'une moyenne cible mais varient au contraire de manière complexe.

Initialement défini par Claude Bernard le terme "homéostasie" provient 
du grec , hómoios, « similaire », et , stásis, « stabilité, action de se tenir debout ». La notion s'est ensuite révélée utile à l’étude de toutes sortes d'organismes et systèmes en biologie, sociologie, politique, automatismes, et plus généralement dans les sciences des systèmes. L’idée d’homéostasie fut aussi abondamment utilisée par W. Ross Ashby, l'un des pères de la cybernétique, qui en a donné une illustration purement physique par la construction d'un « homéostat » composé d'éléments mobiles qui retrouvent leur position de stabilité après avoir été perturbés. Dans les neurosciences, l'homéostasie joue un rôle clé dans une théorie spéculative de la conscience et du sentiment d'unité du Soi.


Pour les animaux homéothermes (appelés aujourd'hui préférentiellement endothermes), un des paramètres principaux de l'homéostasie est la régulation de la composition du sang et de ses paramètres dynamiques (mécanique des fluides), pour éviter les déficits ou les excès, notamment :
Cette régulation se fait entre autres par

Pour Ivinza Lepapa , le concept d'homéostasie peut être expliquée dans une organisation et/ou dans une entreprise par la notion de changement d'organisation. Pour lui, « suivant l'hypothèse d'Edgar Morin qui considère que la vie d'un système implique un double mouvement (un mouvement de corruption et de désorganisation et un mouvement de fabrication et de réorganisation) », l'homéostasie est « la conjonction des processus par lesquels un système (vivant) résiste au courant général de corruption et de dégénérescence. Elle désigne donc l'ensemble des rétroactions correctrices et régulatrices par lequel la dégradation déclenche la production et la réorganisation. » Et, comme les organisations et/ou les entreprises actuelles évoluent dans des environnements qui offrent des opportunités d'une part, et des menaces d'autre part, l'homéostasie serait alors constituée à partir des caractéristiques évolutives propres à la structure d'une organisation et/ou à leurs acteurs, qui sont liées à leur tour aux opportunités et menaces présentes influençant les décisions, les actions ou le management des organisations et/ou entreprises tout en cherchent à en tirer parti pour s'assurer un avantage sur leurs concurrents. Ces facteurs sont connus sous le nom de " facteurs de contingence " et, au modèle proche d'Henry Mintzberg, l'on peut citer, comme Jak Jabes, quelques facteurs qui poussent les organisations à changer ou à réagir face au changement, à savoir :
La combinaison de ces différents facteurs crée ainsi un environnement de plus en plus concurrentiel et changeant autour de l'entreprise, l'obligeant à des efforts d'innovation de plus en plus intenses..



</doc>
<doc id="15743" url="https://fr.wikipedia.org/wiki?curid=15743" title="Réforme protestante">
Réforme protestante

La réforme protestante, également appelée « la Réforme », amorcée au , est une volonté d'un retour aux sources du christianisme et aussi, par extension, un besoin de considérer la religion et la vie sociale d'une autre manière. Elle reflète l'angoisse des âmes, par la question du salut, centrale dans la réflexion des réformateurs, qui dénoncent la corruption de toute la société engendrée par le commerce des indulgences. Les réformateurs profitent de l'essor de l'imprimerie pour faire circuler la Bible en "langues vulgaires" (notamment l'allemand après la première traduction réalisée par Martin Luther), et montrent qu'elle ne fait mention ni des saints, ni du culte de la Vierge, ni du Purgatoire. La référence à la Bible comme norme est néanmoins une des principales motivations des réformateurs. Ce principe, "Sola scriptura", les guidera.

Commencée le , par Martin Luther, alors moine catholique, dans le Saint-Empire et Ulrich Zwingli à Zurich, puis Martin Bucer à Strasbourg et plus tard Jean Calvin à Paris et Genève, la Réforme touche la majeure partie de l'Europe du Nord-Ouest. Les tentatives de conciliation ayant échoué, elle aboutit à une scission entre l'Église catholique romaine et les Églises protestantes. La Contre-Réforme catholique engagée à l'issue du concile de Trente ne permet à l'Église catholique qu'une reconquête partielle des populations passées au protestantisme.

L'adoption de la Réforme a aussi un caractère politique. C'est un moyen pour les princes d'affirmer leur indépendance face à une papauté revendiquant une théocratie universelle ou pour les populations de pouvoir se révolter face à un souverain mal accepté comme en Écosse et aux Pays-Bas espagnols. La Réforme se traduit donc au par de nombreux conflits, entre l'empereur Habsbourg et les princes allemands mais aussi des guerres civiles en France, en Angleterre et en Écosse.

De nombreux facteurs interviennent. Pendant longtemps les historiens ont pensé que les vices du clergé étaient la principale cause de la Réforme : la débauche de certains prêtres et moines qui vivent publiquement en concubinage, s'enrichissent avec l'argent des fidèles... Ces abus ne sont pas vraiment les causes de la Réforme, l'Église catholique s'est en effet sans arrêt efforcée d'y remédier. Par ailleurs, cette thèse est en quelque sorte favorable à l'Église Catholique en ce qu'elle délégitime la réforme protestante comme une réaction contre des problèmes temporels (les turpitudes du clergé, les indulgences) en occultant le souci essentiellement spirituel du peuple et des réformateurs protestants. Les conciles du ne peuvent prendre de décision efficace tant l'autorité du pape est affaiblie. De fait, les fidèles ne reprochent pas au clergé de mal vivre mais de mal croire.

En effet, le pape répond mal aux angoisses des fidèles. Depuis le et la grande peste, les fidèles vivent dans la crainte de la damnation éternelle. Les thèmes fantastiques du temps, danses macabres peintes dans les églises, livres millénaristes en sont les témoins. Les procès contre les sorcières se multiplient à partir de la fin du . La peur de la mort et de l'enfer a comme conséquence le développement du culte marial, du culte des saints, des reliques, des pèlerinages, des processions, et la pratique des indulgences. Le but est de gagner son paradis sur la terre même au prix d'un séjour au purgatoire. À la fin du , les indulgences sont un moyen de plus en plus en vogue pour réduire le nombre des années passées par une âme au purgatoire après sa mort. Ainsi, l'électeur de Saxe, Frédéric le Sage, futur protecteur de Luther, possède , censées lui épargner de purgatoire. Mais les indulgences sont ensuite vendues : dès que l'or tombe dans la sébile, l'âme s'échappe du purgatoire. La confusion du spirituel et du matériel accentue les phénomènes de désacralisation de cette époque. De plus en plus, le fidèle se confesse non pas poussé par la conscience de sa faiblesse mais par peur de la punition après la mort. À côté de la multiplication de ces pratiques, la Bible, proclamée en latin lors des messes, n'est accessible aux fidèles qu'à travers les commentaires des clercs, d'où il s'ensuit une perte de sens.

Certains humanistes contribuent à la diffusion d'idées nouvelles. Ils développent l'exégèse biblique. Le texte originel de la Bible se trouve ainsi restauré. La naissance de l'imprimerie permet la diffusion d'éditions de bibles en langue vernaculaire. Ce contact direct habitue le lecteur à avoir une relation personnelle avec les textes saints et à réfléchir par lui-même sur leur signification.

À partir du milieu du , le pouvoir d'achat s'amenuise. Les nobles regardent donc du côté des immenses biens fonciers de l'Église, soit le plus souvent 20 à 30 % des terres cultivables. De plus l'Église continue à condamner les profits bancaires, le profit monétaire dans ses tribunaux ecclésiastiques même si ses positions se sont quelque peu assouplies. Les banquiers sont particulièrement nombreux en Allemagne du Sud. Nobles et banquiers sont ainsi moins attachés à l'Église catholique.

Les facteurs politiques ne sont pas absents non plus. Le développement des États se heurte à la puissance temporelle de l'Église. De plus en plus, les princes cherchent à intervenir dans le choix des membres du Haut-clergé, évêques, abbés. En effet, les postes ecclésiastiques sont liés à des bénéfices. Celui qui contrôle l'élection du prélat, contrôle indirectement le bénéfice. L'autorité universelle du pape, proclamée par Grégoire VII depuis 1075, se heurte à l'autorité grandissante du souverain. Le pape peut lever des impôts réguliers ou exceptionnels dans tous les pays d'Occident. Les rois protestent de plus contre les sorties d'argent de leur royaume, argent dont ils ont le plus grand besoin pour leurs guerres ou pour affermir leur pouvoir. Ainsi en Angleterre, les taxes prélevées pour les bénéfices vacants sont d'un montant cinq fois plus élevé que les revenus du roi. Le pape édicte aussi des bulles, lois valables dans toute la chrétienté. Il peut ainsi lever des troupes par l'intermédiaire de bulles de croisades, cependant de moins en moins suivies d'effets. Les souverains réclament le contrôle des ordres religieux, le droit absolu de légiférer dans leurs États, de lever l'impôt ou des troupes et de rendre justice.

Mais ce qui affaiblit le plus l'Église catholique, c'est la perte de la sacralité. Les fidèles voient trop de fils de prêtres devenir prêtres, trop de clercs s'enrichir aux dépens des laïcs, trop d'évêques vivant comme des grands seigneurs.

Trois préréformateurs sont reconnus par les historiens protestants : Valdo le fondateur du mouvement des Pauvres de Lyon, John Wyclif l’universitaire anglais, Jan Hus le préréformateur tchèque brûlé en 1415 à Constance. À ces trois incontournables, certains ajoutent Bernard de Clairvaux, Lefèvre d’Étaples, Savonarole, les bibliens… La liste n'est pas close. Mais la notion même de préréforme a ses limites ; on peut en citer deux : s'il est indéniable qu'ils précédent historiquement la réforme, les préréformateurs peuvent ne pas avoir envisagé ni adopté l'ensemble des principes de la réforme ; et si l'on suit l'analyse d'Amedeo Molnár d'« une certaine manière on peut estimer que Jan Hus n’était pas un préréformateur, mais que Luther était un posthussite ».

Un des plus anciens précurseurs de la Réforme est l'anglais John Wyclif. À travers ses premiers écrits transparait l'idée que Dieu exerce par l'intermédiaire du pape, son droit sur les biens terrestres ; les rois ont donc des comptes à rendre au pape. Selon lui, la véritable Église est l'Église des chrétiens, des membres de la hiérarchie, et le pape lui-même, mais personne n'est supérieur à l'autre. Le pape dirige mais n'est pas plus saint qu'un chrétien. Cette affirmation nouvelle remet ainsi en cause la place de la hiérarchie dans l'Église. Il traduit la Vulgate en ancien anglais et reconnait aux autorités laïques le droit de percevoir les revenus ecclésiastiques en 1381, ce qui choque beaucoup les membres du clergé anglais très attachés à leurs prérogatives pécuniaires. Il pense que les Écritures doivent être la seule source de foi même s'il pense que les pères de l'Église peuvent aider à son interprétation. Il est condamné en 1376 et 1379. Son vieil ennemi Guillaume de Courtenay, devenu archevêque de Cantorbéry, convoque à Londres trois synodes en 1392, qui condamnent formellement Wyclif et ses partisans. Il meurt isolé, mais est enterré en terre chrétienne. Le Concile de Constance (1414-1418) renouvelle la condamnation de ses écrits, de même que le pape Martin V qui publie deux mois avant la fin du concile la bulle "Inter cunctas" (22 février 1418) contenant les quarante-cinq articles condamnés de Wyclif. L'exhumation de ses restes est alors ordonnée et, en 1428, ses ossements sont brûlés et jetés dans la Tamise au nord de Londres. À sa suite, les Lollards poussent le peuple à la révolte contre les évêques qui s'enrichissent grâce à leur position religieuse. Henri IV d'Angleterre sévit contre ce qu'il considère comme une hérésie majeure et une atteinte à son pouvoir absolu. Les idées de Wyclif ne remportent pas de succès en dehors de l'Angleterre.

En Bohême et Moravie, Jan Hus oppose la richesse corruptrice à la pauvreté évangélique. Pour lui, l'Évangile est la seule règle infaillible et suffisante de la foi, et tout homme a le droit de l'étudier pour son propre compte. Ceci est une grande nouveauté car l'Église catholique favorise peu la lecture personnelle des textes saints. De plus les prétentions religieuses d'Hus se doublent de prétentions nationalistes. Il lutte pour que les Tchèques soient maîtres en leur patrie. Pour les Tchèques, Hus est le premier grand héros de la nation tchèque. En 1412, il lance des réquisitoires brûlants contre les indulgences dont la vente doit financer la guerre de Jean XXIII contre Ladislas de Naples. Trois de ses jeunes disciples sont exécutés au grand scandale des Praguois. Il est frappé d'une excommunication majeure, et la ville d'interdit s'il y séjourne. Il quitte donc Prague et prêche dans les campagnes. Il écrit des traités de théologie. En 1414, il se rend au concile de Constance muni d'un laissez-passer de l'empereur Sigismond. Là, il refuse de reconnaitre ses erreurs. Ses écrits sont brûlés et lui aussi brûlé comme hérétique le 6 juillet 1415. Il est aussitôt considéré par le peuple tchèque comme un martyr et un saint. La défenestration de Prague du 30 juillet 1419, marque le début de l'insurrection des hussites qui, durant dix-huit ans, tiennent tête aux cinq croisades que l'Europe envoie à l'appel du pape et de Sigismond pour écraser les « hérétiques ». Finalement l'Église doit composer avec les Hussites. Les "Compactata" de Bâle (1433) accordent aux Tchèques la communion sous les deux espèces et la lecture en tchèque de l'Épître et de l'Évangile. Mais deux Églises issues de la prédication de Hus subsistent en Bohême au : l'église Ultramontaine et la "Communion des frères de la foi".

La "devotio moderna" est un mouvement spirituel né au aux Pays-Bas ; animée par les frères et les sœurs de la Vie évangélique, elle essaie de prendre en compte les aspirations des fidèles. C'est une méthode de piété personnelle et individuelle faite de l'imitation de Jésus-Christ, d'un examen de conscience et de prières. De plus l'idée de réforme traverse bien des milieux dans bien des États. En Allemagne, L'empereur Maximilien veut utiliser l'idée de réforme contre le saint Père pour réaliser autour de lui l'unité nationale. Après avoir fait diffuser le "Recueil des plaintes de la Nation germanique contre Rome", il charge l'humaniste Jacques Amyot de rassembler les observations des Allemands sur l'Église et le clergé catholique. La plupart des ordres religieux cherchent de leur côté à rétablir les règles monastiques dans leur dureté originelle. Savonarole parvient à prendre le pouvoir à Florence.


La réforme luthérienne est introduite par le moine augustin Martin Luther. Celui-ci vit dans l'anxiété de son époque. Depuis son entrée au couvent, Luther cherche par tous les moyens à acquérir la certitude de son salut. Mais ni la dévotion, ni les messes, ni les confessions, ni les jeûnes, ni les exercices spirituels, ni la théologie n'apportent à Luther l'apaisement et la certitude de son salut.

En 1512, il retrouve enfin la réponse à ses questions ; il écrit à ce moment-là : . La bonté de Dieu, son amour, sa générosité sont la clé de voûte de la doctrine chrétienne. Le chrétien répond à l'amour de Dieu par la foi. Luther écrira plus tard :

L'épître de saint Paul aux Romains transmet pour lui la vérité de l'Évangile : « Car en l'Évangile la justice de Dieu se révèle de la foi à la foi, comme il est écrit : "le juste vivra de la foi" » (Rm 1, 17).

Pour Luther désormais, tous les préceptes se trouvent uniquement dans l'Écriture sainte. Et c'est en suivant les lois divines que le chrétien montre sa foi.

Luther est connu pour avoir accentué et développé le sens de l'idée que « le juste vivra par la foi ». Il a en effet dû se justifier dès 1530 d'avoir ajouté le mot « seul » au verset de l'épître aux Romains (Chp. 3, verset 28) : « Car nous pensons que l'Homme est justifié par la foi seule, sans les œuvres de la loi ».

En 1515, le pape Léon X autorise une nouvelle vente d'indulgences pour financer la construction de la basilique Saint-Pierre de Rome. Celle-ci n'obtient pas un très grand succès. En 1517, Luther appose les 95 thèses contre les indulgences sur la porte de la chapelle du château de Wittenberg. Il est indigné de la dérive marchande de l'Église. Il s'engage à défendre ses propositions d'ordre théologique ou concernant les indulgences devant qui voudrait bien argumenter avec lui. Il pense qu'un débat public sur la question est salutaire. Mais les Dominicains qui vendent les indulgences préfèrent dénigrer Luther. Ils dénoncent essentiellement deux propositions de Luther : la non-nécessité des œuvres pour gagner son salut et la référence exclusive à la Bible. Le débat gagne les universités d'Europe.

Le 15 juin 1520, Léon X condamne les idées de Luther. L'empereur Charles Quint qui se veut le champion de l'autorité pontificale fait brûler les écrits de Luther à l'université de Louvain en décembre 1520. Luther ne veut pas se laisser faire. Il pense toujours qu'un débat public est nécessaire et rend coup pour coup afin de montrer sa détermination. C'est d'ailleurs sa détermination qui sera la cause de la rupture des protestants et des catholiques. Le pape ne peut supporter que son autorité soit contestée. Il est farouchement convaincu qu'il incarne seul la vérité évangélique et que Luther ne parle qu'en son nom. Luther a beau écrire « les grands écrits réformateurs », quatre ouvrages qui précisent sa pensée, le pape n'en démord pas. L'affirmation de la seule autorité de l'écriture n'implique pas que le pape est soumis à cette écriture car seul le pape peut faire face aux évolutions de la société. En effet comment interpréter les écritures au fil du temps ? Martin Luther vend le manifeste "À la noblesse chrétienne de la nation allemande" en quelques jours à quatre mille exemplaires. Il préconise la réduction des sacrements au nombre de trois : le baptême et la communion sous les deux espèces et la confession. En effet, les actes des Apôtres précisent que les premiers chrétiens confessaient leurs péchés les uns aux autres. La doctrine comprend aussi le rejet de la doctrine de la transsubstantiation, et l'affirmation de la liberté du chrétien et de l'égalité de tous les croyants devant Dieu même s'ils ne sont pas tous capables d'enseigner la parole de Dieu. On estime qu'entre 1517 et 1520 plus de des écrits de Luther furent vendus. Jusque vers 1550, il reste l'auteur le plus lu.
Après avoir été excommunié par le pape, Luther est convoqué à la Diète de Worms. Il y comparait durant deux jours devant l'assemblée. Il refuse de désavouer ses ouvrages, à moins d'être convaincu d'erreur par le témoignage de l'Écriture divine. Il est mis au ban de l'Empire par l'empereur Charles Quint le 26 mai 1521, ce qui signifie que n'importe qui à le droit de se saisir de lui et de le remettre à la police. On lui interdit d'écrire et de publier. Ceci n'empêche pas Luther de continuer à écrire des lettres et à prêcher ses idées, aidé en cela par ses disciples dont le plus célèbre est Philippe Mélanchthon. Melanchthon publie en 1521 les "Loci theologici", qui exposent, pour la première fois de manière systématique, la pensée luthérienne avec toutes ses nouveautés et ses ruptures par rapport à la pensée catholique médiévale.

Certains groupes sociaux sont plus ou moins sensibles aux idées modernes et réformistes défendues par Martin Luther, le père du protestantisme mondial. Une part non négligeable du clergé catholique romain adhère aux idées de Luther. Ce sont en général des hommes qui ont étudié l'humanisme, ou qui ont séjourné dans une université elle-même convertie à l'humanisme. D'une certaine manière, on peut dire que l'humaniste a rendu obsolète la scolastique médiévale et les démonstrations théologiques qui en découlaient. La foi chrétienne doit tenir compte de la nouvelle façon de penser. C'est tout le mérite de Luther d'avoir lié le christianisme à la modernité de l'époque. La noblesse, avec à sa tête Klaus von Falkenstein, est très favorable à Luther. Un certain nombre d'humanistes et d'artistes (Dürer, Craven) adhèrent aussi à sa doctrine. À la campagne, les idées de Luther sont diffusées par des colporteurs itinérants et des voyageurs de commerce.

Dans le Saint-Empire romain germanique, les villes impériales ne sont pas assez autonomes pour pouvoir choisir la religion de leur choix. Thomas Müntzer est un prédicateur mystique exalté et très intolérant. Il prêche de ville en ville et est parfois chassé par l'évêque qui ne veut pas de concurrence religieuse. Andreas Karlstadt est un des anciens professeurs de Luther. Il encourage ses étudiants à brûler leurs livres dans d'immenses autodafés, où de précieux manuscrits disparaissent ainsi, et à apprendre un métier. Il est le premier prêtre catholique romain à se marier, rompant ainsi ses vœux de chasteté. Il épouse une ancienne nonne, lointaine parente d'Hidelgarde von Bingen.

La Réforme est l'occasion pour certains groupes sociaux d'exprimer leur mécontentement. Ils donnent ainsi au message évangélique une dimension révolutionnaire. Les petits nobles se révoltent en 1522 sous la houlette de von Hutten et Sickingen. Pour Luther, une réforme religieuse ne devrait pas s'identifier avec une cause économique et sociale. En 1522, les paysans d'Allemagne du sud se révoltent mêlant des revendications socio-politiques à des exigences religieuses. Là encore, Luther conjure les paysans de ne pas recourir à la force. Pour lui, la Bible ne peut apporter aucune solution aux problèmes de la vie civile ou économique. Il refuse une révolte sociale au nom de la Bible, exprimant ainsi son conservatisme social. Pendant la guerre que les paysans livrent au seigneurs du Sud du Saint-Empire romain germanique, il encourage les seigneurs à châtier sans pitié les révoltés. En effet, dans une courte brochure de 1525, intitulée "Contre les bandes pillardes et meurtrières", il enjoint ses à , et les rebelles paysans (cité dans J. Lefebvre, "Luther et l'autorité temporelle, 1521-1525", Paris, Aubier, 1973, ). Ceci lui vaut de voir disparaître une grande partie du soutien des seigneurs du Sud pour qui réforme religieuse rime avec anarchie.

Présents dès les débuts de la Réforme, notamment à Zurich dans l'entourage de Zwingli, ces représentants de la Réforme radicale fédèrent les mécontents. Une de leurs branches, inspirée par la prédication de Melchior Hoffman, prône l'usage de la violence à l'encontre des non-anabaptistes, dans la perspective d'une fin du monde très proche, à laquelle il faut se préparer. Ces disciples de Melchior Hoffman, pourchassés aux Pays-Bas, en Suisse et en Allemagne, vont provoquer un nouvel épisode de troubles en se regroupant dans la ville allemande de Munster en Westphalie, où, de 1533 à 1535, ils tentent d'établir une théocratie. À partir de février 1534, la ville tombe sous leur contrôle. Sous la conduite de Jean de Leyde, qui prétendait être directement inspiré par des visions divines, la ville fut administré sous la terreur dans un climat délirant, où la polygamie fut légalisée, Jean de Leyde se mariant lui-même avec pas moins de 16 femmes. La ville fut reprise par les armes en juin 1535 par son ancien archevêque et les meneurs mis à mort. Cet épisode de la révolte de Munster a laissé une image déplorable de l'anabaptisme, malgré le fait que cette communauté religieuse soit dans son immense majorité engagée dans une non-violence absolue.

Face à l'agitation provoquée par les diverses tendances de la Réforme, Luther s'occupe en premier lieu d'organiser la nouvelle liturgie en langue allemande. C'est la première fois qu'un peuple peut prier d'un bout à l'autre de la cérémonie dans sa langue nationale. Cette révolution fait beaucoup pour le développement de la langue allemande. La messe allemande repose sur la lecture du Nouveau Testament, le sermon, élément central du culte, et les chants. Luther écrit un recueil de sermons que les pasteurs peuvent utiliser durant l'office. Ceci permet une certaine unité doctrinale. Les chants religieux, très nombreux pendant l'office, sont un puissant ressort d'émotion.

Le pasteur consacre les deux espèces qui deviennent le vrai corps et le vrai sang du Christ, bien qu'il s'agisse de pain et de vin. Dans la doctrine luthérienne, il n'y a pas changement de substance mais coexistence de deux substances : c'est la consubstantiation. Luther admet l'ordination des pasteurs, ainsi que le contrôle du pouvoir temporel sur le pouvoir spirituel, garant de l'orthodoxie face au pullulement des réformes et d'une morale stricte. Le prince, comme chrétien éminent et du fait de sa mission divine, est une sorte d'évêque chargé de faire régner l'ordre dans l'Église. Il porte le titre de "Summus episcopus". Cette mission particulière des princes leur permet d'augmenter leur pouvoir sur leurs sujets. Les fidèles adultes continuent à recevoir un enseignement religieux, ainsi que les enfants pour lesquels Luther écrit "le Grand et le Petit catéchisme" dans un langage simple et adapté. Il condamne également un grand nombre de rites catholiques : les pèlerinages, le culte des Saints, les reliques...

La réforme luthérienne partie de Saxe touche les villes libres du sud de l'Allemagne, le Brandebourg, le Brunswick et l'Anhalt. En 1529, lors de la seconde diète de Spire, six princes et quatorze villes refusent d'appliquer les décrets impériaux revenant sur les libertés religieuses des princes et déclarent : « "...nous protestons..." », d'où le nom de protestants. En 1530, les diverses mouvances de la Réforme présentent leur confession devant la Diète réunie à Augsbourg et l'empereur. La confession d'Augsbourg, une profession de foi luthérienne très modérée, est rédigée par Philippe Melanchthon. Celle présentée par Zwingli affirme que la Cène n'est qu'une commémoration. Les réformés de Strasbourg présentent une troisième confession au nom des villes alsaciennes dite Confession tétrapolitaine. La Diète d'Augsbourg montre l'impossibilité de faire l'unité des Réformés même si les Alsaciens finissent par adopter la Confession d'Augsbourg.
À l'issue de la diète d'Augsbourg, Charles Quint somme les protestants de se soumettre à Rome dans un délai de sept mois. Inquiets, ces derniers constituent en 1531 la ligue de Smalkalde. L'empereur leur accorde alors une trêve. En 1536, sous l'impulsion de Martin Bucer, les protestants d'Allemagne du nord et du sud, divisés sur le problème de la Cène, signent la "Concorde de Wittenberg" (1536), ce qui permet au luthéranisme d'étendre son influence en Allemagne du sud et isole les Suisses. En 1546, lorsque les protestants refusent de reconnaître le Concile de Trente, Charles Quint lève ses troupes dans le but de réprimer le protestantisme par les armes. Les Protestants,
qui forment la Ligue, subissent une cuisante défaite à Mühlberg en Saxe en 1547. L'empereur peut aussi imposer l'année suivante aux protestants "l'Intérim d'Augsbourg" qui leur autorise juste la communion sous les deux espèces et le mariage des prêtres. Les princes protestants obtiennent alors l'appui du roi de France Henri II en échange du droit pour celui-ci d'occuper Metz, Toul, Verdun « et autres villes de l'Empire ne parlant pas allemand ». Charles Quint laisse son frère, le futur empereur Ferdinand, signer la paix d'Augsbourg en 1555. Les sécularisations déjà accomplies de biens de l'Église catholiques sont entérinées mais il est interdit à l'avenir de lui confisquer d'autres biens. Les princes et les villes libres ont le droit de choisir leur religion mais les sujets sont obligés de professer la même religion que leur souverain ou d'émigrer, d'où l'adage : "Cujus regio, ejus religio" (tel prince, telle religion). Les deux-tiers de l'Allemagne sont devenus protestants.

Après la mort de Luther en 1546, c'est Philippe Mélanchthon qui devient le guide des Luthériens jusqu'à sa mort en 1560. En 1580, les théologiens luthériens parviennent à unir les différents États luthériens autour d'un texte de confession commun. C'est le "Livre de Concorde".

La Réforme luthérienne déborde les frontières allemandes. Les échanges culturels et commerciaux entre le monde scandinave et l'Allemagne sont très importants. Olaf et Laurent Petersen, Olaeus et Laurentius Patri, formés à l'université de Wittenberg commencent à prêcher la Réforme en Suède en 1518. Ils publient douze thèses qui présentent les principales idées de Luther. Le clergé catholique suédois qui possède 30 % des terres est très déconsidéré en Suède. De ce fait la Réforme progresse sans résistance. En 1527, la diète suédoise accepte la réforme, permet la sécularisation des biens du clergé au profit de la monarchie. Le roi devient le chef suprême de l'Église. En Finlande, le clergé se réforme de lui-même.

Au Danemark, sous le règne de Frédéric (1523-1533), la prédication luthérienne se développe grâce à Hans Tausen qui a fait ses études à Wittenberg et à Paul Helgesen. Les "Trente-trois Articles de Copenhague" posent les bases de la Réforme en 1530 même si elle n'est pas encore adoptée officiellement. Il faut attendre 1536 pour qu’à l'instigation de Johannes Bugenhagen, Christian III fasse de la confession d'Augsbourg la profession de foi du Danemark. Le roi est le chef de l'Église danoise. Il nomme des surintendants qui remplacent les anciens évêques. La Réforme est aussi prêchée en Islande où elle rencontre une forte résistance et en Norvège, unie au Danemark à partir de 1539. L'université de Copenhague devient un centre de rayonnement luthérien.

À Zurich, Ulrich Zwingli, curé de la ville, expose le 29 janvier 1523, les 95 thèses en présence des magistrats de la ville et du vicaire général de l'évêque de Constance, dont la ville dépend sur le plan religieux. Pour lui, baptême et cène sont des cérémonies symboliques, alors que les partisans de Luther les voient comme des sacrements, ce qui rend impossible tout accord avec les Allemands.

Le point de vue de Zwingli l'emporte progressivement. Zwingli obtient la sécularisation des couvents et crée en 1524 une école d'exégèse biblique. En 1525, les magistrats de la ville interdisent la messe dans la ville. Elle est remplacée par un culte très dépouillé. Un tribunal matrimonial est créé la même année. Ses compétences finissent par s'étendre à toute la vie morale et sociale des citoyens.

Le canton de Bâle passe lui aussi à la réforme en 1529 grâce à l'action de Jean Huschin, de même que Glaris, Berne, Bienne, Schaffhouse, Mulhouse et Saint-Gall. Les succès protestants divisent la Suisse en deux camps prêts à en découdre. Zwingli voudrait créer une coalition entre les protestants suisses et allemands. Mais, la rencontre de Marbourg, en 1529, ne permet pas une pleine communion avec ces derniers. En 1531, Zwingli est tué et sa petite armée est battue à Kappel, par les cantons catholiques exaspérés par le blocus économique dont ils font l'objet. En Suisse romande, la Réforme gagne d'abord Neuchâtel puis Genève et le pays de Vaud en 1536. Après la mort de Zwingli et celle d'Œcolampade (la même année), Heinrich Bullinger encourage Zurich à signer avec d'autres villes la Première Confession helvétique, qui est saluée par Luther comme un texte plus orthodoxe, bien que non satisfaisant à ses yeux. En 1549, après une correspondance volumineuse avec Calvin (et au prix de quelques modifications doctrinales) Bullinger parvient à se rapprocher de l'Église de Genève, au moyen du Consensus de Zurich. Heinrich Bullinger est une personnalité célèbre de l'Europe protestante de l'époque grâce à l'étendue de sa correspondance, à la diffusion de ses ouvrages, à l'hospitalité qu'il accorde aux persécutés (il héberge Anna Reinhart la veuve de Zwingli après sa mort) et à son rôle de conseiller auprès de l'anglicanisme. Il rédige aussi la Confession helvétique postérieure, reconnue en 1566 par la plupart des Églises réformées suisses, et acceptée en Écosse, en Hongrie et en Pologne.

Strasbourg se réforme de façon originale sous l'influence de prédicateurs locaux comme Matthieu Zell qui commente avec succès l'épître aux Romains sur le Salut, Capiton, prédicateur de talent et grand érudit et Martin Bucer, passionné par l'enseignement de Luther. En 1524, des prédicateurs enseignent l'Évangile dans les paroisses de la ville et le culte est simplifié. Il sécularise les biens des couvents. Occupant une position médiane entre Luther et Zwingli, Bucer est jugé trop proche de ce dernier par Luther, au colloque de Marbourg. C'est la raison pour laquelle, en 1530, Strasbourg présente avec les villes de Constance, Lindau et Memmingen, la Confession tétrapolitaine, à mi-chemin sur le plan eucharistique entre Luther et Zwingli. En 1533, un synode élabore une constitution ecclésiastique qui instaure une assemblée hebdomadaire du clergé avec la participation de trois laïcs (le convent). La discipline ecclésiastique est confiée aux laïcs ou anciens. En mai 1536, Bucer et les représentants de diverses Églises de la Confession Tetrapolitaine (et d'autres, comme Augsbourg ou Bâle) signent avec Luther et les Églises de Saxe, la Concorde de Wittenberg, à laquelle se ralliera l'ensemble du protestantisme, excepté principalement Zurich. Strasbourg, où Calvin fait un séjour et enseigne entre 1538 et 1541, fait donc alors double usage de la Confession tétrapolitaine et de la Confession d'Augsbourg et les autorités ne permettent pas de diffuser des enseignements contraires à cette doctrine. Toutefois, à partir de 1563, les autorités de Strasbourg ne reconnaissent plus que la Confession d'Augsbourg comme norme doctrinale.

Jean Calvin, originaire de Noyon en Picardie, fait des études à Paris puis à Orléans et à Bourges où il étudie le droit. Gagné à la Réforme, il doit quitter la France à la suite de l'Affaire des Placards en 1534. En 1536, parait en latin à Bâle la première version de son œuvre majeure, "De Institutione religionis christianae" qui comprend alors 6 chapitres. Une nouvelle version latine révisée de 19 chapitres est publiée à Strasbourg en 1539, suivie d'une autre édition de 25 chapitres immédiatement traduite en français en 1541, puis une quatrième et une cinquième version respectivement en 1550 et 1554.

La souveraineté absolue de Dieu y est proclamée. Calvin s'efforce de voir le monde du point de vue de Dieu. En désobéissant à Dieu, l'homme est esclave du péché. Il est rarement capable de mettre en œuvre sa volonté pour faire le bien. Continuant son raisonnement, Calvin pense que la foi elle-même vient de Dieu, c'est la prédestination.

Absente de l'édition de 1532 de l"'Institution", à peine mentionnée dans celle de 1536, la prédestination a pris une place croissante dans les éditions suivantes, Calvin se plaçant au cœur des polémiques en soutenant que Dieu a choisi de toute éternité ceux qui seront sauvés, formule volontairement ambigüe. Suscitant une autre polémique, il s'oppose à la doctrine de la transsubstantiation et pense que le Christ est réellement présent dans l'assemblée mais pas dans les espèces, c'est-à-dire le pain et le vin. L'homme est une créature déchue qui doit vivre dans la crainte de Dieu, il est empli du sentiment de son imperfection et de sa nature qui le porte au mal.

En 1536, le conseil de Genève qui a proscrit la messe et introduit la réforme dans la cité fait appel à Calvin, à l'instigation de Guillaume Farel. Il édicte les "Quatre Articles et une Instruction et Confessions de foi" pour doter l'Église réformée de Genève d'une solide armature disciplinaire et doctrinale. Mais la rigidité que les réformateurs cherchent à imposer mécontente le peuple qui parvient à convaincre le conseil de les chasser en avril 1538. Calvin réside alors à Strasbourg où il s'occupe des réfugiés français et enseigne à la Haute école de la ville. La ville de Genève le rappelle en 1541. Il y reste jusqu'à sa mort en 1564. Les "Ordonnances ecclésiastiques" sont publiées en septembre 1541. Elles servent de fondement à toutes les organisations inspirées par Calvin. L'échelon de base est l'Église locale avec à sa tête un conseil composé des pasteurs, des docteurs en théologie des anciens élus et des diacres. Le consistoire s'occupe de la vie morale de la communauté ; il interdit les jeux, l'ivrognerie, le vagabondage, les danses ; il cherche à préserver la paix entre les chrétiens et choisit le pasteur de la communauté parmi les candidats. Calvin fonde également l'académie de genève dans le but de former les futurs prédicateurs nécessaire à l'instruction religieuse de la population en 1559.

Jean Calvin est partisan de la Cène hebdomadaire, mais, en raison de , il consent à ne la célébrer que 4 fois par an : Noël, Pâques, Pentecôte et le premier dimanche de septembre. Il élabore une liturgie, la "Forme des prières et chants ecclésiastiques", dont beaucoup d'éléments sont empruntés au rituel de Strasbourg. Les services consistent en sermon, chants et psaumes. Il rédige aussi un catéchisme, expliquant la doctrine sans grande pédagogie.
Calvin joue un rôle important dans les controverses religieuses. Il combat les anabaptistes. Il fait arrêter le théologien et médecin espagnol Michel Servet, réfugié à Genève parce qu'il avait écrit contre la trinité. Ce dernier est brûlé vif en 1553. Le procès de Servet entraine un débat avec Sébastien Castellion qui milite pour la tolérance religieuse. Calvin polémique aussi avec ceux qui contestent la prédestination. La forte pression morale que Calvin exerce sur la cité avec l'aide principalement des réfugiés français se heurte au mécontentement populaire et aux représentants des grandes familles genevoises. Genève acquiert la réputation d'une nouvelle Jérusalem où l'identification de la cité avec la religion est complète auprès des protestants persécutés dans les pays catholiques. Elle attire des exilés de toute l'Europe. De 1540 à 1564, près de mille nouveaux bourgeois y sont admis. Le rayonnement européen de la ville est dû à Calvin qui entretient une correspondance avec des personnes de presque tous les pays d'Europe par souci d'unité protestante. Il tient aussi à la réputation de l'Académie, fondée en 1559. Cette école accueille très vite des étudiants de tout le continent. Elle forme essentiellement des pasteurs, mais aussi des juristes et une partie de l'élite réformée européenne. Après la mort de Calvin en 1564, c'est Théodore de Bèze qui anime la Réforme dans la ville. Une autre contemporaine de Calvin, Marie Dentière joue un rôle important à Genève et publie notamment un documentaire sur les épisodes genevois "La guerre et deslivrance de la ville de Genesve" (1536).

La République de Mulhouse adopte le calvinisme comme unique religion officielle en 1529. Le statut de république indépendante enclavée dans le Royaume de France va lui permettre d'échapper aux guerres de religion et de tisser des liens particuliers avec les autres communautés et États réformés d'Europe et du Nouveau Monde. En 1746, cette ouverture internationale et ce contexte politique favorable entraîne l'industrialisation de la ville dont la production manufacturée d'indiennes dépassera à partir du celle de l'ensemble du reste de la France. En 1798, les Mulhousiens votent leur rattachement à la France, il se forme alors un patronat protestant puissant disposant désormais d'une main d'œuvre bon marché et d'un libre accès au marché français. En 1812, la filature dite « "vieux-DMC" » est construite. Elle est aujourd'hui le dernier vestige des filatures géantes européennes encore debout. Le patronat protestant dote la ville d'un riche patrimoine et se fait bâtir des manoirs et villas de maître sur la colline du Rebberg. En 1816, la démographie a changé et Alexandre Moll devint le premier catholique élu maire de Mulhouse. Les familles protestantes continueront toutefois à dominer la politique de la ville jusqu'à l'annexion de l'Alsace-Lorraine en 1871. Entre 1859 et 1866 eut lieu la construction du temple Saint-Étienne de Mulhouse à la place de l'ancien temple médiéval, chef-d'œuvre architectural, il est encore aujourd'hui le plus haut monument protestant de France avec sa flèche haute de .

Le reste de la France est également touché par la réforme protestante. Dès 1520, les idées protestantes se développent. Le protestantisme apparaît dans la vallée de la Dordogne dans les années 1530. Lors du synode de Chanforan de 1536, Guillaume Farel et les vaudois, ralliés, obtiennent un budget pour imprimer la bible en langue vulgaire. À partir de 1540, la littérature protestante de plus en plus abondante s'accompagne d'une transmission orale. Elle se répand surtout après la publication en français de "l'institution chrétienne" en 1541. Calvin, de Genève, prend en charge l'organisation religieuse et unifie les protestants de France. À partir de 1555, les groupes se structurent en assemblées dirigées par un consistoire. Calvin envoya des dizaines de missionnaires pour aider à cette nouvelle organisation. En 1560, on en compte une quarantaine. Leur succès est très grand et fin 1561, il y a plus de six cent soixante-dix Églises réformées dans le royaume. On estime qu'à ce moment plus du quart de la population du royaume est devenu protestant mais essentiellement de confession réformée.

Le premier synode national des Églises réformées de France se tient à Paris en 1559. Deux textes importants sont rédigés, "La confession de foi" qui présente la prédestination et "La discipline ecclésiastique".

Le second texte organise l'Église « selon le modèle strasbourgeois et genévois ». Le pouvoir « appartient à la base, à l'église locale, sans primauté aucune », prévoyant juste un colloque biannuel réunissant les délégués de 10 à 15 paroisses, un synode provincial annuel et un synode national, annuel aussi, mais en fait peu réuni. « Le pasteur se voit confier la fonction de prêcher, de distribuer les deux sacrements évangéliques du baptême et de la cène, de représenter sa communauté aux assemblées. Cependant, il doit être élu, c'est-à-dire accepté par l'ensemble des fidèles, qui peut le récuser en certains cas ». L'objectif du synode de 1559 est de donner aux Protestants français une doctrine alors que le conflit avec les catholiques se durcit. "La confession de foi" est appelée à partir de 1571 "Confession de La Rochelle", au cours d'un synode où certaines des thèses de Calvin ne sont pas acceptées.

Le protestantisme français est combattu par François et son fils Henri II. La répression menée par François est limitée et sporadique. Mais celle d'Henri II est plus ferme. L'édit de Compiègne du 27 juillet 1557 demande d'abattre sans jugement tout protestant en fuite ou révolté. En 1559, les lettres d'Ecouen donnent mission à certains notables de se rendre en province pour réprimer l'hérésie. Ceux qui refusent comme Anne de Bourg sont exécutés. Ceci n'empêche pas la Réforme de continuer à se développer. Après la mort inopinée d'Henri II, la tentative de conciliation menée par le nouveau chancelier Michel de L'Hospital et la régente Catherine de Médicis est un échec. En 1561, les Réformés et les catholiques confrontent en vain leurs idées lors du colloque de Poissy. L'Édit de janvier 1562 qui permet l'existence du culte réformé déchaine des ambitions partisanes et les passions, à l'origine du déclenchement des guerres de Religion en 1562.

En Allemagne, l'électeur Palatin, adhère au calvinisme et fait éditer en 1563, le catéchisme d'Heidelberg repris par la plupart des églises calvinistes. Nassau, Brême, Anhalt, Hesse-Cassel, Hesse-Darmstadt, Schleswig et Deux-Ponts deviennent à leur tour calvinistes entre 1576 et 1600. Les Pays-Bas – qui englobent, à l'époque, la Hollande, la Zélande, la Belgique et une partie de nord de la France – sont pénétrés très tôt par la réforme luthérienne malgré la sévère répression de Charles Quint. Mais c'est surtout le calvinisme qui s'impose dans la population et une partie de la noblesse. Un synode clandestin a lieu à Anvers en 1561 sous la direction de Guy de Brès. Il dote les Pays-Bas d'une "confession de foi". Dans le même temps, les habitants affrontent Philippe II, roi d'Espagne et fils de Charles Quint, qui veut établir l'absolutisme aux dépens des vieilles franchises et libertés remontant aux ducs de Brabant et à leurs successeurs, les ducs de Bourgogne. En lutte contre les vieilles chartes, Philippe II veut supprimer le principe de liberté qui les imprègne et, ainsi, mieux lutter contre le protestantisme. Devant la persécution royale, les calvinistes se soulèvent durant l'été 1566. Ils pillent et détruisent les églises. La répression est féroce. Les calvinistes rescapés s'enfuient et fondent à l'étranger des Églises du Refuge qui s'organisent en 1572 sur le principe des institutions presbytéro-synodales. Une partie de la noblesse incline vers les protestants, mais la majorité reste catholique. Ceux que les partisans de Philippe II avaient appelé les gueux pétitionnent en faveur de la tolérance. C'est le Compromis des Nobles présenté à Bruxelles à la gouvernante Marguerite de Parme, fille naturelle de Charles Quint et représentant le roi d'Espagne. Rejetés par le pouvoir, les « gueux » organisent la résistance sous la direction de Guillaume d'Orange Nassau dit Guillaume le Taciturne, catholique d'origine, puis converti au calvinisme. Guillaume s'alliera par le mariage à la noblesse française de confession protestante, les Châtillon-Coligny, de la famille du chef français du parti protestant, l'amiral Coligny et parviendra à prendre le contrôle de la Hollande et de la Zélande, y instaurant la liberté religieuse. Sous les fils de Guillaume d'Orange, la lutte continuera et, après une Guerre de Quatre-Vingts Ans, la création des Provinces-Unies au , sera proclamée, les territoires du sud des Pays-Bas (actuels Belgique et Nord de la France) étant retombés sous la souveraineté espagnole, la religion catholique y est seule autorisée.

La Réforme touche aussi l'Écosse où elle rassemble les opposants à la dynastie Stuart, très liée à la religion catholique. En 1557, les Réformés s'unissent dans un "Convenant", un serment typiquement écossais pour défendre une cause et rester uni jusqu'à la mort. Après la mort de "Marie de Guise", régente pour sa fille Marie Stuart, le parlement écossais adopte la "Confession écossaise". Ce texte présenté par John Knox est d'inspiration calviniste, ayant étudié avec lui à Genève. Les statuts votés par le parlement établissent un système presbytéro-synodal. Chaque église locale est gérée par un collège composé du ministre (pasteur), des anciens et des diacres. Chaque église envoie des représentants aux synodes provinciaux. À la tête de l'Église dite presbytérienne se trouve l'Assemblée générale des Églises composée de délégués des synodes provinciaux. À cette époque la plus grande partie de la noblesse écossaise et une bonne partie de la population sont devenus protestantes. Le mariage de la reine Marie Stuart, restée catholique, avec Lord Darnley, de même confession, provoque une rébellion des régions protestantes en 1565. Marie finit par abdiquer en 1568. Son fils Jacques VI s'oriente nettement vers le protestantisme et tend vers l'établissement d'une Église de type anglicane qui devient l'Église d'Écosse.

La propagation de la Réforme en Europe centrale (Pologne, Hongrie, Bohême, Transylvanie) repose sur un fort soutien dans la noblesse régionale. La théologie de Calvin s'impose la plupart du temps dans les paroisses nouvellement créées. En Pologne, la diète du royaume (Sejm) garantit en 1572 le libre exercice des religions protestante, catholique romaine et orthodoxe.

Au début de la Réforme, Henri VIII prend position pour les idées luthériennes. Le souverain anglais veut divorcer de son épouse Catherine d'Aragon dont il n'a qu'une fille après 18 ans de mariage. Le pape refuse le divorce. Le roi se proclame donc le chef suprême de l'Église anglaise dont il est le gouverneur suprême. Thomas More et l'évêque de Rochester qui refusent de reconnaitre le roi comme chef suprême de l'Église anglaise sont exécutés. Paul III excommunie le roi, jette l'Interdit sur le royaume et prêche la croisade contre le roi bigame à ses yeux. En 1536, Henri VIII réprime un soulèvement catholique contre lui. En même temps les protestants lui reprochent de ne pas aller assez loin et de ne pas faire une réforme du dogme. En 1539, les Six Articles, votés par le Parlement maintiennent une stricte orthodoxie, transsubstantiation, communion sous une seule espèce, célibat et chasteté des prêtres.

Sous le règne d'Édouard VI (1547-1553), l'Église d'Angleterre s'oriente sensiblement vers la Réforme. Les injonctions royales, édictés en juillet 1547 sous l'impulsion d'Édouard Seymour, duc de Somerset, et chef du conseil de régence, abolissent les six articles, interdisent les processions, autorisent la communion sous les deux espèces et ordonne la lecture des textes saints en anglais. En 1549, John Dudley, duc de Northumberland remplace Somerset à la tête du conseil de régence. Il accueille les réfugiés strasbourgeois chassés par la victoire de Charles Quint sur les protestants allemands. Ils apportent aux réformés anglais leur expérience et leurs connaissances. Sous leur impulsion, les protestants anglais parviennent à faire adopter par le Parlement le "Book of Common Prayer" qui devient obligatoire dans tout le royaume par l’"Act of Uniformity" (15 janvier 1549). En 1552, le nouveau "Prayer Book" est nettement plus protestant, l’"Act of Uniformity" qui l'accompagne accentue les sanctions contre les prêtres qui n'utilisent pas le "Prayer Book" et prévoit des amendes pour ceux qui ne se rendent pas à l'office du dimanche. Enfin, en avril 1553, les "Quarante-deux articles" précisent la doctrine anglicane : le prêtre devient un simple ministre de la parole, il célèbre l'eucharistie sans référence à la transsubstantiation, le culte des Saints, la croyance au Purgatoire, les pèlerinages, les reliques sont rejetés ; la doctrine sur la justification par la foi et la prédestination est d'inspiration calviniste.

Après la mort d'Édouard VI, sa sœur ainée Marie, restée catholique, devient reine (1553). Elle obtient d'un parlement recruté avec soin l'abolition de toutes les lois antérieures. Elle gouverne avec le cardinal Pole et fait arrêter les prélats qui sont des protestants convaincus. L'annonce de son mariage avec Philippe, le fils de Charles Quint déclenche une révolte dans le Kent, réprimée durement. La religion catholique est partout restaurée et les hérétiques poursuivis. Marie meurt le 17 novembre 1558.
Lorsque Élisabeth, demi-sœur de Marie arrive au pouvoir en 1558, le clergé anglais est entièrement catholique. En 1559, un nouvel "Act of Supremacy" lui donne le titre de chef suprême de l'Église anglaise ("Supreme Head") ; le "Book of Common Prayer" est rétabli dans tout le royaume. Le clergé doit se soumettre ou démissionner. Élisabeth consolide les institutions de l'Église anglicane en leur donnant une confession, les "Trente-neuf articles", en 1571.

Pour remédier à son problème de réforme, le catholicisme a mis en œuvre tout ce qu'il pouvait. Il fallait absolument que la propagation du protestantisme soit arrêtée. Le concile de Trente et la Compagnie de Jésus sont deux exemples de ces moyens mis en œuvre pour stopper la réforme.

Le redressement interne est surtout l'œuvre du concile de Trente convoqué par le pape Paul III à la demande de Charles Quint pour faire face à la réforme protestante. Le concile s'ouvre en 1545. Quant à Charles Quint, il souhaite faire du concile une sorte de vaste forum où protestants et catholiques discuteraient librement, ce dont le pape ne veut pas. Le concile de Trente répondait aux propos des protestants et réaffirmait plus exactement qu'au départ les doctrines voulues par Rome. Le catholicisme s'appuyait beaucoup sur la tradition comme autorité englobant la Bible. Les réformateurs ne jugeaient pas le passé, les pères de l'Église ou certains conciles avec mépris, mais affirmaient qu'il y avait là des contradictions nombreuses et des superstitions populaires qui déformaient le message de l'Évangile ce qui nécessitait un retour complet à la Bible, seul livre inspiré et infaillible pour eux.

Le concile de Trente (en Italie) réaffirma l'autorité des papes, du clergé sur les laïcs, de la Tradition, des conciles, les mérites dans le salut, le purgatoire, les prières pour les morts, le sacrifice de la messe et l'intercession de Marie et des saints. Le catholicisme gardait toujours ses sept sacrements. Le concile de Trente permit d'arrêter l'expansion et même de reconquérir des endroits déjà perdus. Ce concile consacra la rupture de la chrétienté occidentale en deux : le catholicisme et le protestantisme. Le concile de Trente ne fut cependant pas la seule opération destinée à enrayer le protestantisme.

Même si le concile de Trente a beaucoup aidé à la reconquête des pays écartés, la compagnie de Jésus a amplement aidé ce travail. Leur fondateur est Ignace de Loyola (1491-1556). C'est en 1534 qu'il créa son ordre, voulant militer et être soumis au pape. Dans cet ordre existe une discipline semblable à celle de l'armée. Tous les membres devaient obéir au supérieur, appelé « général ». La Compagnie se soumettait donc aux ordres du pape pour sauver le catholicisme. Les Jésuites se consacraient surtout à la prédication et à l'enseignement. Ils n'hésitaient pas à aller partout dans le monde pour convertir les protestants. En 1556, les Jésuites se comptaient par milliers. Vingt ans plus tard, ils étaient , en Amérique latine, en Asie ou en Nouvelle-France. Les Jésuites ont finalisé l'arrêt de l'expansion du protestantisme. Après ce concile, les conflits qui avaient caractérisé le et le début du prirent une nouvelle dimension, une dimension religieuse.

Le commença dans la violence et dans le sang avec les conflits entre la France et l'Espagne pour la domination de l'Italie. Les principaux protagonistes furent François et Charles Quint. En 1529 la « paix des Dames » marquera la fin de la septième guerre d'Italie. Des considérations religieuses s'ajouteront à ces conflits dynastiques surtout après le concile de Trente et le début de la Contre-Réforme. Les guerres de religion ont été d'une ampleur incomparable, d'une extrême violence. Ces affrontements ont fait le tour de la carte de l'Europe que ce soit en Allemagne, en France ou aux Pays-Bas.

L'unité chrétienne n'étant plus qu'une utopie, des conflits d'une grande ampleur se préparèrent : nommés à tort ou à raison « guerres de religion » (on parlait à l'époque de « troubles »), la dimension religieuse étant variable selon les époques, les lieux et encore plus selon les individus. En France, aux Pays-Bas et en Allemagne les répressions sociales et religieuses étant sévères, des guerres civiles éclatèrent, puis avec les prises de position des princes et des magistrats, elles devinrent des « guerres de religion ». L'empereur Charles Quint combattit l'hérésie avec son armée. Les luthériens, pour se défendre, établirent la Ligue de Smalkade.

Après cette guerre, la paix d'Augsbourg (1555) permit aux princes de choisir eux-mêmes la religion de leurs sujets, selon le principe Cujus regio, ejus religio (tel prince, telle religion).

La France quant à elle, entra en convulsion un peu après l'Allemagne. Pendant 36 ans (1562-1598) les guerres de religion ne cessèrent pratiquement pas. C'est pendant ces guerres que les Provinces-Unies furent créées. En effet, une révolte où se mélangeaient sentiment national, intérêts commerciaux et religieux éclata en 1566. Cette révolte, dont l'origine est lointaine, confronta les partisans des réformes calvinistes aux partisans de l'hégémonie espagnole et catholique. Dans les coulisses, plusieurs alliances s'étaient formées. Parfois, ces alliances étaient contre nature : , tout en réprimant les réformés français soutiendra les princes allemands pour gêner Charles Quint, de même, il fera alliance avec les Ottomans contre ce même Charles Quint. La papauté tergiversera entre la France et l'Espagne pour contrer la Réforme, du côté protestant Maurice de Saxe combattra au côté de Charles Quint contre d'autres princes protestants avant de faire volte-face et de le défaire à Innsbruck en 1552. Tous ces conflits contribuèrent au déclenchement de la guerre de Trente Ans.

La guerre de Trente Ans commença en Allemagne en 1618 et dura jusqu'en 1648. Cette guerre débuta par une révolte des Tchèques protestants à cause de l'archevêque de Prague qui avait interdit le culte réformé dans la ville d'où il détenait son pouvoir. Richelieu essaya d'arrêter la guerre, mais n'y parvint pas entièrement. L'Allemagne était complètement ravagée par cette guerre qui fut la plus meurtrière de ce temps. La fin de cette guerre fut établie par la paix de Westphalie (1648). Celle-ci affirma de nouveau le droit des princes d'imposer leur religion à leurs sujets.

Émile G. Léonard a parlé de Calvin comme étant le fondateur d'une nouvelle civilisation, c'est probablement vrai à bien des égards mais il ne faut pas attribuer l'œuvre de la Réforme du à une seule personne ni dissocier ce mouvement de tout ce qui le préparait dans la société médiévale, des mouvements qui s'épanouirent ou s'affrontèrent lors de la Renaissance. Une chose est certaine : l'évolution des sociétés ayant adhéré à la Réforme présente de nombreux contrastes par rapport au reste de l'Europe, la France qui en fut considérablement influencée au représente ainsi un destin particulier.

Dans leur lutte contre les superstitions de Rome et les dérives de la spiritualité anabaptiste, le luthéranisme et le calvinisme contribueront au désenchantement du monde. En effet dans ces deux traditions théologiques et particulièrement dans le calvinisme, cela n'est pas le diable, les êtres célestes ou le miraculeux qui sont omniprésents, mais Dieu. Pour le chrétien, Dieu est souverain et il a révélé sa volonté dans l'Écriture : (les 66 livres qui composent la Bible). Un Dieu tout-puissant contribue à rassurer le croyant face au surnaturel, aux peurs moyenâgeuses en tout genre : enchantements, possessions, sortilèges… Dieu, ses attributs, sa volonté et ses commandements sont connus par l'Écriture, par l'emploi de moyens ordinaires (la lecture, la réflexion), d'où l'usage de la raison. Dieu ne se révèle pas par des songes, des visions, des transes, des convulsions, ou par des êtres bénéficiant de révélations ou pouvoirs surnaturels (prêtres, saints, astrologues), mais par le texte biblique. La mesure d'un homme dans la spiritualité protestante réside dans sa compréhension, sa capacité à expliquer et son obéissance à l'Écriture. Le capitalisme sera plutôt le signe d'un affaiblissement de cette piété, d'où l'apparition de mouvements de réveil avec des leaders comme John Wesley ou Charles Finney qui insisteront beaucoup sur la sanctification, le renoncement à soi et la charité.

À Worms, en 1521, Luther déclara : « Ma conscience est prisonnière des paroles de Dieu. Je ne veux ni ne puis me rétracter. Agir contre sa conscience est grave ; ce n'est ni sûr ni honnête. » Par cette déclaration, la conscience individuelle se révèle plus importante que le jugement d'un autre (le pape), et même d'un ensemble (le concile). Ce primat de la conscience individuelle est devenu pour une bonne part un acquis de l'homme moderne, même si grâce aux sciences humaines et aux enseignements de l'histoire, on en mesure mieux les limites du fait de différents types de pressions auxquelles on peut être soumis. Au début de la Réforme, dans les pays germaniques, le principe "cujus regio, ejus religio" (à chaque pays sa religion), a singulièrement réduit la liberté individuelle. La Révolution française a finalement entériné le principe de liberté de conscience, contenu notamment dans la Déclaration des droits de l'homme et du citoyen de 1789 (article 10 : « Nul de doit être inquiété pour ses opinions, même religieuses... ».





</doc>
<doc id="15744" url="https://fr.wikipedia.org/wiki?curid=15744" title="Assemblée nationale">
Assemblée nationale

L'Assemblée nationale est le nom souvent donné au Parlement d'un État ou à sa chambre basse dans le système législatif bicaméral ou dans le système monocaméral. Il est utilisé dans plus d'un tiers de tous les pays du monde (voir liste plus bas : 75 pays sur environ 195 pays reconnus dans le monde). Le terme est principalement présent dans les pays francophones ou dans ceux qui ont été une colonie française, mais pas seulement. On le trouve également dans un certain nombre de pays du Commonwealth.

Dans un seul pays, le Népal, ce terme est utilisé depuis la mise en place de la constitution de 2015 pour désigner la chambre haute d'un parlement bicaméral, dit Parlement fédéral, dont la chambre basse est appelée Chambre des représentants.





Assemblée nationale peut aussi désigner :


</doc>
<doc id="15745" url="https://fr.wikipedia.org/wiki?curid=15745" title="General Motors">
General Motors

General Motors (ou General Motors Corporation ou GM) est un constructeur automobile américain basé à Détroit dans le Michigan, aux États-Unis, qui contrôlait encore une quinzaine de marques à la fin des années 1990.

La société a été fondée en 1908 par William Crapo Durant. Son successeur Alfred P. Sloan en a fait le plus grand fabricant automobile au monde entre 1931 et 2005 et en 2011.
Alors que son titre avait perdu 95 % de sa valeur, le groupe a bénéficié d'une nationalisation temporaire, qui a duré un an et demi, ses dettes ayant été remplacées par des capitaux propres ("equity"). Depuis 2014, la directrice de GM est Mary Barra et son président est l'Américain Dan Ammann. En 2014, General Motors a vendu 9,92 millions de véhicules dans le monde (en hausse de 2 % par rapport à 2013).

Après les ventes des marques Vauxhall, Saab et Opel, ainsi que le retrait de Daewoo en 2005 puis de Chevrolet en 2014, le groupe General Motors ne possède plus de présence significative en Europe, préférant concentrer ses activités sur des marchés plus rentables.

Le fondateur de GM est William C. Durant, qui possédait dès 1890 un fabricant de chariots hippomobiles à Flint, Michigan. Recruté en 1904 par le concurrent Buick,qui était en difficulté, il augmente la production de 37 voitures en 1904 à en 1907 puis crée GM en 1908.

Le rival Ford, créé en 1903 avec 125 salariés, lance sa onze jours après la création de GM, mais sans succès immédiat : sa part de marché (20 %) revient à 14 % en deux ans. Les ventes de Ford ne décolleront qu’en 1911, avec unités, puis unités en 1913, unités en 1914 et unités en 1915.
Entre-temps, GM a émis des actions cotées en bourse, fusionné avec Buick et racheté en 1908 la marque Oldsmobile, qui avait lancé en 1901 le ', premier modèle fabriqué en série. En 1909, GM rachète aussi des fournisseurs ou des fabricants de camions, ainsi quOakland" (future Pontiac) et surtout Cadillac. Puis, il tente aussi de racheter Ford pour de dollars, sans succès, malgré un emprunt de de dollars. En échange, les banquiers obtiennent de pouvoir nommer le PDG de GM. Inquiets de voir Durant promettre de vendre un jour voitures, ils l’évincent en 1910, l'année où dix-huit constructeurs font faillite, victime de mévente. Walter Chrysler est nommé à la direction.

William C. Durant recrée un « nouveau GM », en copiant dès 1910 la Ford T, avec la "". Il réussit quasi-seul ce qu'il voulait faire par des fusions : une baisse du prix (850 dollars en 1909 et en 1915), grâce à la première ligne de montage, mise en place en 1913. Il achète aussi la société créée par le pilote Louis Chevrolet. En désaccord sur le design des voitures, William C. Durant l’évince en 1915, l’année où GM entre dans l'indice Dow Jones. Entre 1915 et 1917, sa production passe de unités à plus de , grâce à un modèle vedette, la Chevrolet 490, baptisée ainsi car vendue , quand la coûte, elle, . En 1916, l'action GM dépasse sur le New York Stock Exchange, phénomène très rare à l'époque.

Après une bataille de mandats lors de l'assemblée générale des actionnaires, William C. Durant reprend en 1916 le contrôle de GM, en apportant en échange ses actions Chevrolet, ce qui permet une fusion, le nouveau groupe s'appelant « Chevrolet ». 

Anxieux de conserver le contrôle de GM, Durant distribue un premier dividende en 1917, puis en 1919 un autre de 22 millions de dollars, sur un bénéfice de 60 millions de dollars. Il se lance dans de nouveaux achats d'actions, à crédit, détenant pour 35 millions de dollars d'actions GM, ce qui inquiète ses amis. Lors de la déflation de 1920, il est lâché par DuPont de Nemours, qui détient un quart du capital, et doit quitter la direction de GM. Henry Ford a de son côté trouvé sans difficultés les 75 millions de dollars pour acheter les parts de ses actionnaires minoritaires, grâce à 20 millions de dollars de trésorerie, le reste étant avancé par les banques, qui sont remboursées rapidement, Ford contrôlant 60 % du marché américain dès 1923. Dans les années 1930, GM prend l'avantage, grâce à ses nombreuses marques.

En 1918, il lance la marque Frigidaire, qui fabrique à l'origine des réfrigérateurs, et plus tard, une gamme complète d'électroménagers et des climatiseurs pour voitures. En 1919, GM crée General Motors Acceptance Corporation (GMAC), société de financement des concessionnaires. En 1919, les frères Dodge, fournisseurs de moteurs, qui figurent parmi les douze premiers associés, se plaignent du manque de dividendes. Ils obtiennent en justice de dollars. En 1920 William C. Durant est mis en minorité par son allié, , président du groupe chimique éponyme. La famille Dupont prend jusqu'à 40 % du capital de GM pendant la crise.

Ford profite de ces conflits d'actionnaires pour reprendre l’avantage, puis creuser l’écart. Sa Ford T prend 60 % du marché du neuf en 1921. La dix-millionième sort en 1924, soit une moyenne d’un million par an sur dix ans. Malgré l'émergence de ce géant, il reste encore quarante-quatre constructeurs américains en 1929.

En 1923, une dispute politique permet à l’industriel du roulement à billes, Alfred P. Sloan, supporteur du futur président républicain Herbert Hoover, d’évincer William C. Durant de la présidence de GM, qu’il dirigera jusqu’en 1956. Sloan planifie l’obsolescence et les politiques de prix, encourageant le consommateur américain à rester fidèle à la « famille » Chevrolet, Pontiac, Oldsmobile, Buick et Cadillac à mesure que ses goûts changent. Il obtient le remplacement des tramways par des autobus auprès des pouvoirs publics, puis en 1956 le lancement du programme autoroutier d'Eisenhower.

En 1929 et 1930, General Motors fait l'acquisition de la plus grande usine automobile d'Allemagne, celle d'Opel. Sous le régime hitlérien, la production se tourne vers le secteur militaire. Cette nouvelle orientation augmente les bénéfices engendrés par GM. Fin 1939, la valeur d'Opel dépasse les 86 millions de dollars, soit près du double de l'investissement initial de GM (45 millions de dollars).

À partir de février 1942, la GM (comme ses concurrents Ford et Chrysler ainsi que les autres constructeurs indépendants) reconvertit ses 94 usines pour l'effort de guerre américain durant la Seconde Guerre mondiale. Elle livre ainsi des véhicules militaires commandés par le ministère de la Guerre, 48 millions de munitions d'artillerie, sous-ensembles de groupes motopropulseurs d'avion, chars de combat, etc.

Durant cette période, ses usines allemandes d'Opel (acquises en 1929) sont sous le contrôle du régime nazi, mais seulement en façade. Le gouvernement allemand avait compris qu'une ingérence trop grande risquait de faire baisser la production et ainsi nuire à l'effort de guerre allemand. Durant cette période, GM continua d'engranger des bénéfices, en exploitant une main d'œuvre bon marché, qui pouvait effectuer jusqu'à par semaine. Elle utilisa une partie de ses bénéfices pour investir en Allemagne, en faisant notamment l'acquisition d'une fonderie à Leipzig en 1942, fabriquant des blocs moteurs pour Opel.

Dans les années 1980, General Motors collabore avec la dictature militaire au Brésil en lui transmettant des informations sur les activités des militants syndicaux de l'entreprise. Ces informations sont utilisées par la police pour surveiller, harceler et arrêter les syndicalistes afin d‘empêcher l‘organisation de grèves. 

En décembre 1989, GM acquiert 50 % de Saab Automobile AB. Dix ans plus tard, il acquiert l'autre tranche d'actions de Saab.

L'entreprise produit les marques Passport et Asüna au Canada au tout début des années 1990.

En 1996, GM lance la EV1, ce qui marquera le début du scandale de plus de six ans au sujet de la disparition soudaine de ce modèle entièrement électrique.

En 1998, les produits Geo ont été intégrés dans la gamme Chevrolet.

En 2000, GM noue une alliance stratégique avec le groupe italien Fiat. L'italien cède 20 % de son capital, en échange de 6,1 % de GM, l'américain bénéficiant d'une clause d'achat des 80 % jusqu'en 2006. Les difficultés de Fiat l'ont incité à se désengager, bien que GM ait dû payer un dédommagement de 1,5 milliard de dollars au constructeur italien.

Au début des années 2000, la dette de GM est trop élevée par rapport à ses capitaux propres, le groupe ayant recouru à l'effet de levier de la sous-capitalisation pour doper sa rentabilité des capitaux propres. Le sauvetage se fera en quatre temps. De 2005 à 2008, pour éviter une augmentation de capital, GM recours d'abord à des désinvestissements massifs, l'État prenant le relais en décembre 2008 par de dollars de prêts d'urgence. Cette politique se poursuit au premier semestre 2009, sur fond d'effondrement des ventes, GM cherchant toujours à éviter une augmentation de capital. Mais en juillet 2009, un tribunal exproprie les actionnaires et les créanciers, au profit d'une nouvelle société, créée de toutes pièces et dotée de de dollars de capitaux propres, quasiment sans dette. Les États américains et canadiens en sont actionnaires dès sa création en août 2009.
Après une décennie de surendettement, General Motors a ainsi vécu à l'été 2009 une mutation financière et patrimoniale du même type que celle du groupe franco-anglais Eurotunnel : créanciers et actionnaires évincés par les tribunaux, dette annulée. Le « Nouveau GM » réussira en 2010 une introduction en Bourse de de dollars, qui permet à l'état américain de revendre la moitié de sa participation de 61 %. En hausse dès le début de 2010, seulement six mois après le rachat par l'État, les ventes de voitures de GM sur le marché américain poursuivent leur hausse en 2011, une remontée de 25 % en deux ans.

La conséquence est une forte baisse des ventes, puis des bénéfices. En 2007, la part du marché américain chute à 23 % contre 28 % en 2003. Cette année-là, la dette fait boule de neige, représentant neuf fois les capitaux propres, selon Standard & Poor's. L'effet de levier financier recherché par certains actionnaires devient un effet de massue. Mais le dividende n'est « suspendu » qu'en août 2008. En décembre 2008, l'État prête d'urgence 17 milliards de dollars, sous condition de réduire la dette des deux-tiers, en la transformant en capitaux propres. GM propose aussi de supprimer en trois ans. Le groupe n'employait déjà plus que : il avait déjà supprimé dans le monde, le tiers de ses effectifs, entre 2005 et 2008. GM promet de vendre cinq de ses marques: Pontiac, Saturn, Hummer, Saab Automobile et Opel. Les quatre premières sont en réalité de toute petite taille : 0,27 millions de véhicules à elles quatre, soit 3 % des ventes de GM. La seule grande marque des cinq est l'allemande Opel, qui a vendu 1,93 millions de véhicules en 2008, soit huit fois plus que les quatre autres réunies. Elle sera en réalité conservée, GM décidant de ne plus la vendre, quelques mois après. Le groupe canadien Magna International est approché mais GM se rétracte en fin d'année. Elle sera vendue en 2017 au Groupe PSA.

General Motors revient de loin : entre 2000 et 2009, ses ventes de voitures aux États-Unis sont passées de 5 à . Une « décennie perdue » qui a contribué au vieillissement du parc automobile américain, l'âge moyen d'une voiture américaine atteignant contre 8,4 en 1995. 

Les désinvestissements massifs s'accélèrent dès 2004, pour tenter de diminuer la dette très élevée, résultant d'un effet de levier financier. Les actionnaires refusent l'indispensable augmentation de capital, qui aurait permis un désendettement moins brutal. En 2005, année de suppressions d'emplois massives, GM verse encore un dividende de par action, aussi élevé que celui du haut de cycle en 2000. L'agence Standard & Poor's juge pourtant la dette de 292 milliards de dollars beaucoup trop élevée: elle la note dans la catégorie « obligation pourrie ». Cinq mois plus tard, le , GM parvient à contourner la loi américaine sur les faillites en cédant 51 % de sa filiale de crédit GMAC au fonds de LBO Cerberus. Mais le groupe refuse d'augmenter ses capitaux propres, préférant supprimer emplois entre fin 2004 et fin 2008, pour tenter se désendetter : les effectifs mondiaux tombent à en 2008 contre en 2004. GM ferme en priorité les petits sites, pour réduire ses stocks et ainsi la dette finançant le besoin en fonds de roulement. Une alliance avec Renault-Nissan est discutée puis abandonnée.
La conséquence est une forte baisse des ventes, mais aussi des bénéfices. En 2007, la part du marché américain chute à 23 % contre 28 % en 2003. Cette année-là, la dette fait boule de neige, représentant neuf fois les capitaux propres, selon Standard & Poor's. L'effet de levier financier recherché par certains actionnaires devient un effet de massue. Le dividende n'est « suspendu » qu'en août 2008, alors que Merrill Lynch a évoqué la possibilité de la mise en cessation de paiement le 2 juillet.

Le 10 novembre 2008, Rod Lache, analyste à la Deutsche Bank, estime dans une note qu'elle vaut zéro dollar, car « sans intervention extérieure du gouvernement », GM « pourrait ne pas pouvoir financer ses opérations américaines au-delà de décembre », la seule solution étant « une infusion immédiate de capitaux ou un crédit » en provenance des autorités. Mais Washington s'efforce de l'éviter car une étude du cabinet TNS montre que 20 % des clients américains seraient moins enclins à acheter une voiture à GM s'il recevait une aide gouvernementale.

Le 17 décembre 2008, l'État américain prête d'urgence de dollars sous conditions : rémunération des dirigeants plafonnée et promesse de transformer 2/3 de la dette en capitaux propres. Pour que les parlementaires américains acceptent ce prêt, GM propose de son côté de supprimer  emplois en trois ans. GM n'employait déjà plus que . De 2005 à 2008, il avait déjà supprimé emplois dans le monde, le tiers de ses effectifs. Plusieurs fermetures d'usines sont annoncées mais la plupart ont déjà eu lieu ou sont en cours, comme celle de l'Usine de Janesville, décidée le 3 juin 2008 et dont le dernier véhicule, un Chevrolet Tahoe, sort le 22 décembre 2008 et celle de l', qui ferme ses portes dès octobre 2008.

GM propose en particulier de vendre cinq de ses marques: Pontiac, Saturn, Hummer, Saab et Opel. Les quatre premières ne représentent que 3 % des ventes de GM, soit de véhicules par an. Oldsmobile avait été fermée depuis 2004 et la participation dans Subaru vendue à Toyota en 2005.

La seule grande marque des cinq est Opel, qui a vendu de véhicules dans le monde en 2008, soit huit fois plus que les quatre autres réunies. Elle sera en réalité conservée, GM décidant de ne plus la vendre quelques mois après sa mise en vente. Le groupe canadien Magna International est approché mais GM se rétracte en fin d'année. GM annonce qu'il étudie la possibilité de fermer les sites Opel d'Anvers, Bochum, Eisenach, et l'usine de Trollhättan (Saab). Aucune ne fermera finalement.

Entre-temps, le Sénat rejette le , le plan de sauvetage. GM affirme alors craindre un dépôt de bilan. Le 30 décembre 2008, il avoue qu'il manque chaque mois à ventes de voitures sur le marché américain, à cause de la sous-capitalisation de sa filiale de crédit GMAC. Premier pas vers la nationalisation, l'État prend 18 % de la GMAC, pour 5 milliards de dollars, en arguant que le fonds de LBO Cerberus n'a pas su convaincre les créanciers de convertir leur dette en actions. L'État décide qu'il n'aura plus que 15 % des droits de vote.

Le 20 janvier 2009, Barack Obama s'installe à la Maison-Blanche. Deux mois après, il demande au PDG de GM Rick Wagoner de passer la main à Fritz Henderson. Entretemps, au cours du premier trimestre, les ventes de voitures de GM ont chuté de 49 % par rapport au premier trimestre 2008: une partie des concessionnaires ne sont plus approvisionnés en voitures et les usines sous-alimentées en composants par les fournisseurs, ce qui permet aux stocks et au besoin en fonds de roulement de diminuer et à la dette de revenir à de dollars. Mais les pertes se creusent. Le 21 avril 2009, le gouvernement révèle qu'on lui demande de prêter de dollars de plus à GM.

En tentant d'obtenir de nouveaux crédits, GM lutte contre la création par le gouvernement d'un « Nouveau GM » qui évincerait ses actionnaires existants. Pour diminuer encore plus ses stocks, et ainsi son besoin en fonds de roulement, il prévoit de réduire son nombre de concessionnaires aux États-Unis de 42 % en deux ans et de descendre à voitures en stock à fin juillet, contre encore fin mai. Le 28 mai 2009, GM annonce qu'il a l'intention de fermer treize sites employant personnes, pour réduire le nombre de ses usines américaines de 47 à 34, alors qu'il en comptait 80 rien qu'aux États-Unis en 2005, mais sans obtenir plus de crédit de l'État.

GM est finalement contraint de se placer le juin 2009 sous la protection de la loi américaine sur les faillites. Le tribunal du district sud de New York rend le jugement du 5 juillet 2009 : la société est dissoute, ses actifs vendus à un « Nouveau GM », la cotation de l'action cesse. Elle valait , soit une capitalisation boursière de de dollars. 

Le juge Robert Gerbert a examiné 850 objections, soulevées par des actionnaires et des créanciers qui auraient préféré une liquidation. Il les juge « pas valables à ses yeux » et déclare : « GM est désespérément insolvable, et il n'y a plus rien à faire pour les actionnaires », car il n'a que de dollars d'actifs au 31 mars pour de dollars de dettes, en incluant les dettes commerciales et la dette envers l'État, contractée sous la forme de de dollars d'obligations à statut protégé et remboursement prioritaire.

Les créanciers privés se plaignent, jugeant qu'il aurait mieux valu réduire plus les salaires et les effectifs. Ils perdent 97 % de leurs créances car la dette bancaire est convertie, à un prix extrêmement bas, en seulement 10 % des actions du « Nouveau GM », doté de 60 milliards de dollars de capitaux propres. L'État américain en apporte 61 %, et reprend ses créances en échange. Le gouvernement canadien, lui, apporte 12 % et le fonds de couverture médicale du syndicat automobile UAW 17 %. Le syndicat, qui avait accepté des sacrifices au cours des années précédentes, voit sa part symboliquement plus élevée que celle des banques.

Avec seulement de dollars de crédits bancaires, la charge d'intérêt du « Nouveau GM » redevient normale et même favorable. Il regagne des parts de marché aux États-Unis puis redevient leader mondial en 2011 avec de véhicules, 8 % de plus qu'en 2010. En conservant Opel et en bénéficiant d'un fort rebond de sa production, le constructeur va en réalité stabiliser voire augmenter légèrement ses effectifs entre 2009 et 2012.

Le 19 novembre 2010, le retour en bourse de GM a été une réussite avec une augmentation de 9,1 % des titres au plus fort de la journée. En novembre 2010, Pontiac (célèbre pour ses Firebird et ses GTO) ferme ses portes, ainsi que Saturn (filiale américaine de General Motors).

Le 19 décembre 2011, GM mène la mythique marque SAAB (dont il s'était déjà séparé deux ans auparavant) à une inéluctable faillite en s'opposant à sa reprise par les sociétés chinoises Youngman et Pang Da.

Le 21 février 2012, le journal "La Tribune" révèle que des discussions entre General Motors et PSA Peugeot-Citroën sont en cours pour créer un éventuel rapprochement. 8 jours plus tard, le 29 février 2012, les deux constructeurs annoncent leur alliance, GM entrant à hauteur de 7 % au capital de PSA.

Le 6 août 2012, les constructeurs automobiles Spyker et Saab Automobile portent plainte aux États-Unis contre le constructeur automobile américain pour avoir provoqué de manière intentionnelle et par ses actions la faillite de Saab en ayant refusé le projet de vente de peur de se mettre en compétition contre Saab dans le marché chinois. Les deux sociétés réclament de dollars américains, soit d'euros de remboursement de préjudice qui selon le président de Spyker Victor Müller ancien propriétaire de Saab représente la valeur du renflouement qu'aurait effectué Youngman si les accords avaient été menés à terme, General Motors est même accusé d'avoir publié de fausses informations concernant les droits que lui conféraient les contrats.

Un délai de vingt jours est donné à GM pour pouvoir répondre de la plainte le 26 août 2012, mais le 24 août 2012, Spyker donne un sursis d'un mois pour pouvoir répondre à la plainte. La réponse du géant américain est donc finalement attendue le 28 septembre 2012. Le 29 septembre 2012, General Motors refuse tout arrangement à l'amiable malgré le sursis donné par Saab. La plainte de Saab en justice est donc confirmée.

Le 27 juin 2013, l'agence Reuters annonce que face à des difficultés de trésorerie récurrentes et à de très sombres perspectives commerciales, la famille Peugeot serait prête à céder le contrôle de PSA à General Motors. Selon des sources citées par l'agence Dow Jones, elle lui a demandé de l'aide.

En décembre 2013, l'état américain sort totalement du capital de General Motors, en ayant fait une moins-value de de dollars, mais qui est inférieure aux coûts engendrés à l'État américain si General Motors avait fait faillite. Avec 9,71 millions de véhicules vendus en 2013, General Motors reste le deuxième constructeur au monde devant Volkswagen et derrière Toyota.

En août 2014, GM annonce un investissement de 2,8 milliards de dollars au Brésil sur une durée de 5 ans.

En février 2017, Isuzu acquiert la participation de 57,7 % de General Motors dans General Motors East Africa, présent au Kenya et produisant essentiellement sous licence des produits Isuzu.

En raison de nombreuses erreurs stratégiques qui entraînent des pertes cumulées de 15 milliards de dollars pour la maison-mère depuis 2000, General Motors envisage la cession de sa filiale allemande Opel au Groupe PSA. Le 3 mars 2017, le Conseil de Surveillance de PSA finalise le rachat d'Opel.

En mai 2017, General Motors annonce son désengagement de ses activités de production en Afrique du Sud et en Inde.

En 2014, General Motors est accusé d'avoir commercialisé des voitures dont le commutateur d'allumage pouvait, lors d'un cahot, provoquer l'arrêt total du moteur (bloquant la direction assistée et empêchant le déploiement des airbags). Ce défaut, connu depuis 2005, par General Motors lui vaut également d'être l'objet d'enquêtes du département de la Justice, du gendarme des marchés financiers, la SEC, et du Congrès.

En août 2014, General Motors est confronté au rappel de plus de 30 millions de véhicules dans le monde à la suite de ce scandale. Selon le fonds d'indemnisation mis en place par General Motors mi 2014, le bilan lié à ces défauts de fabrication, est de 56 morts, 9 blessés graves et 78 blessés légers (au ). Ces décès et blessés sont directement liés aux défauts de fabrication des véhicules rappelés. Mi septembre 2015, General Motors est condamné à une amende de 900 millions de dollars pour avoir dissimulé des informations concernant un défaut mécanique qui a causé la mort de 124 personnes et plusieurs centaines de blessés.

GM a produit 15 % de toutes les voitures et camions vendus dans le monde. En 2014, il compte 212 000 employés (en 1973, il était le premier employeur des États-Unis, où travaillaient 618 000 de ses 853 000 salariés mondiaux).

Le groupe GM est également présent depuis 1930, par l'intermédiaire de sa filiale General Motors Electro-Motive Division dans la construction de locomotives diesel-électriques, mais également de moteurs pour la marine et de groupes électro-générateurs. GLM a fait connaître en janvier 2005 son intention de vendre cette division à un groupe d'investisseurs.

Par ailleurs, sa filiale GMAC est présente depuis 1919 dans le secteur des services financiers et de l'assurance.

GM a aussi un accord de production avec Lada-AvtoVAZ en Russie. Encore récemment, GM possédait des participations dans Fiat (Italie), Isuzu, Subaru et Suzuki (Japon). La mauvaise situation financière du groupe a contraint ce dernier à vendre ses parts.

Les autres divisions de General Motors sont : ACDelco, Allison Transmission, et General Motors Electro-Motive Division. GM a aussi des participations dans Delta en Afrique du Sud.

De façon anecdotique, le groupe s'intéresse à la robotique et a conçu entre autres le Robonaut 2 de la NASA.



</doc>
<doc id="15747" url="https://fr.wikipedia.org/wiki?curid=15747" title="Ozone">
Ozone

L'ozone (de l'allemand ', dérivé du grec ' « exhaler une odeur »), ou trioxygène, est une substance de formule chimique : ses molécules sont triatomiques, formées de trois atomes d'oxygène. L'ozone est ainsi une variété allotropique de l'oxygène, mais bien moins stable que le dioxygène , en lequel il tend naturellement à se décomposer. Il se liquéfie à () sous forme d'un liquide bleu foncé et se solidifie à () en un solide pourpre. À température ambiante, c'est un gaz bleu pâle, voire incolore, qui se démarque par son odeur. L'ozone atteint son point critique à et .

Son instabilité se manifeste à l'état condensé par une tendance à l'explosion lorsque sa concentration est significative. L'ozone se décompose en dioxygène à température ambiante : la rapidité de la réaction dépend de la température, de l'humidité de l'air, de la présence de catalyseurs (hydrogène, fer, cuivre, chrome) ou du contact avec une surface solide.

Contrairement au dioxygène inodore, l'ozone est perçu par l'odorat humain (décelable dès la concentration de ) ; son odeur caractéristique qui rappelle l'eau de Javel est perceptible dans les endroits confinés où règne un champ électrique important (transformateur haute tension, échelle de Jacob, tubes UV, allume-gaz). Respiré en grande quantité, il est toxique et provoque la toux.

L'ozone est naturellement présent dans l'atmosphère terrestre, formant dans la stratosphère une couche d'ozone entre d'altitude qui intercepte plus de 97 % des rayons ultraviolets du Soleil, mais est un polluant dans les basses couches de l'atmosphère (la troposphère) où il agresse le système respiratoire des animaux et peut brûler les végétaux les plus sensibles. Cet oxydant énergique agresse les cellules vivantes et peut être responsable de phénomènes de corrosion accélérée de polymères (« craquelage d'élastomères par l'ozone »).

L'ozone a été découvert en 1789 par le chimiste Hollandais Martin van Marum en faisant passer un courant électrique à travers de l'oxygène enfermé dans une éprouvette. Il relève une odeur spécifique comparable à celle de l'acide sulfureux ou du phosphore. L'éprouvette trempée dans le mercure lui permet d'observer que le volume d'oxygène diminue presque de moitié et que le mercure est très rapidement oxydé. Sans savoir ce que révélait son travail, il définit cette odeur comme étant celle de l'électricité et l'élément créé comme de l'acide azotique.

Cette étude est reprise en 1840 par le chimiste allemand Christian Friedrich Schönbein qui, en approfondissant les recherches de Van Marum, parvient à isoler la molécule. Il la dénomma ainsi en se référant à la racine grecque "ozein" (exhaler une odeur, sentir). La formule de l'ozone, , n'a été déterminée qu'en 1865 par Jacques-Louis Soret puis confirmée en 1867 par Christian Friedrich Schönbein. Par la suite, de nombreuses recherches sur le mécanisme de désinfection par l'ozone suivirent. Werner von Siemens fabriqua le tout premier générateur d'ozone. Ce fabricant écrivit d’ailleurs un livre sur l'application de l'ozone dans l'eau, ce qui entraînera une multitude de projets de recherches sur la désinfection par l'ozone.

En 1907, le chimiste Français Marius-Paul Otto, qui reçut un doctorat pour ses travaux sur l'ozone, créa une entreprise appelée Compagnie des Eaux et de l'Ozone.

La relation entre l’ozone et les oxydes d’azote a été mise en évidence dans les années 1970 par Paul Josef Crutzen, prix Nobel de chimie 1995.

Le potentiel d'oxydoréduction de l'ozone est de .

Enthalpie de formation : ΔH = 

La première énergie d'ionisation est égale à 12,43 eV (gaz)

L'odeur associée à l'ozone provient de l'ionisation due à la destruction de l'ozone. Sa couleur est due à la diffusion de Rayleigh qui donne une teinte bleutée en présence de hautes concentrations de la molécule.

La molécule d'ozone est une molécule coudée à symétrie moléculaire de type C2v (semblable à la molécule d'eau). L'angle entre les atomes d'oxygène est 116,78°. L'ozone est une molécule polaire avec un moment dipolaire de .

L'ozone est un oxydant très puissant, plus puissant que l'oxygène ou le chlore. Étant très instable, il se dégrade en assez rapidement :

2 O → 3 O

Réactions avec les métaux

En présence d'humidité, l'ozone oxyde tous les métaux à l’exception de l'or, du platine et de l'iridium. Ci-dessous, l'oxydation du cuivre par exemple :

2 Cu + 2 HO + O → 2 Cu + 3 HO + O

Réactions avec les métaux alcalins

L'ozone réagit avec les métaux alcalins et métaux alcalino-terreux pour former des ozonides , instables et réagissant avec l’eau pour former du dioxygène. Cette succession de réactions chimiques explique pour la plus grande part le caractère de polluant qui est attribué à l’ozone quand celui-ci est présent dans l’atmosphère près du sol.

Réactions avec des composés azotés

L'ozone oxyde le monoxyde d'azote (NO) en dioxyde d'azote () :

NO + O → NO + O

Le dioxyde d'azote () peut à son tour être oxydé en nitrate () :

NO + O → NO + O

L'ozone peut oxyder l'ammoniac () en nitrate d'ammonium () :

2 NH + 4 O → NHNO + 4 O + HO

Réactions avec des composés carbonés

L'ozone réagit avec le carbone pour former du dioxyde de carbone :

C + 2 O → CO + 2 O

Réactions avec les composés soufrés

L'ozone oxyde les sulfures (S) en sulfates (SO). Exemple avec le sulfure de plomb(II) : 

PbS + 4 O → PbSO + 4 O

L'acide sulfurique () peut être produit avec de l'ozone, de l'eau et du soufre ou du dioxyde de soufre :

S + HO + O → HSO ou 3 SO + 3 HO + O → 3 HSO

En phase gazeuse, l'ozone réagit avec le sulfure d'hydrogène pour former du dioxyde de soufre : 

HS + O → SO + HO

En solution aqueuse, deux réactions simultanées se produisent. La première produit du soufre, la deuxième produit de l'acide sulfurique :

HS + O → S + O + HO et 3 HS + 4 O → 3 HSO


L'ozone possède une demi-vie assez courte, encore plus dans l'eau (où il se décompose en radicaux -OH) que dans l'air. Différents facteurs influencent la vitesse de décomposition de l'ozone : 


L'ozone est extrêmement nocif pour les poumons, les reins, le cerveau et les yeux. À titre d'exemple, une concentration de d'ozone dans l'air entraînera des œdèmes pulmonaires. Entre cette valeur et le seuil moyen de perception olfactive ( en moyenne), on retrouve sécheresse buccale, toux, hypersécrétion bronchique, dyspnée, douleur rétro-sternale et anomalie du système respiratoire.
Une simple concentration de 0,2 à d'ozone dans l'air peut déjà provoquer des troubles de la vision comme une diminution de la vision nocturne et une mauvaise adaptabilité à la lumière, une augmentation de la vision périphérique et une modification de la motricité oculaire. À cela s'ajoutent des troubles rénaux (néphrite aiguë) et neurologiques (vertiges, asthénies, altération du goût, trouble de la parole, mauvaise coordination du mouvement).

La réglementation française et les directives européennes fixent un objectif de qualité au maximum journalier de la moyenne sur 8 heures à ( soit ) et le seuil d'alerte à . Cet objectif de qualité correspond aux niveaux 5 (indice français) ou 50 (indice européen) des informations diffusées par les organismes tels que Airparif, Airpaca, Atmo

Dans la haute atmosphère terrestre, la couche d’ozone est une concentration d’ozone qui filtre une partie des rayons ultraviolets émis par le Soleil, ultraviolets notamment responsables du cancer de la peau. Cette couche protectrice est menacée par la pollution, en particulier par les émissions de gaz CFC (chlorofluorocarbure), qui montent dans la haute atmosphère et y catalysent la destruction de l’ozone en le transformant en dioxygène, étant ainsi à l’origine du trou dans la couche d’ozone.

Comme instrument de mesure, on peut noter l’instrument GOMOS du satellite ENVISAT.

Au-delà d'un certain seuil dans la basse atmosphère, l'ozone est l'un des polluants de l'air les plus dangereux pour la santé.

Causes naturelles :

Causes humaines :

Cette pollution dans son ensemble a un impact très important en agriculture (attaque des cuticules foliaires) avec perte de productivité, et pour la santé humaine. En effet, l'ozone irrite et attaque les muqueuses oculaires et des bronches et bronchioles, tout particulièrement chez les populations les plus sensibles. En 2010, une étude américaine a confirmé que l’ozone, même à faible dose, était directement associé à la survenue des crises d’asthme chez l'enfant. Les pics de pollutions induisent une augmentation du nombre et de la gravité des crises d'asthme. Ces pics sont aussi associés à une surmortalité des personnes ayant des problèmes respiratoires (lors de canicules notamment, mais également en hiver par temps ensoleillé). La prévalence de l'asthme ainsi que la mortalité due à l'asthme a augmenté des années 1980 à 2000, en même temps qu'augmentaient les taux d'ozone près des axes routiers, dans les grandes zones industrialisées et urbanisées et loin sous leur vent, dans les campagnes et jusqu'au-dessus de l'océan : l'ozone et les précurseurs troposphériques de l'ozone produit au Canada sont exportés par le vent jusqu'au centre de l'atlantique Nord. Ces quantités dépassent largement celles qui proviennent de la stratosphère (principale source naturelle d'ozone). Les taux d'ozone peuvent aussi fortement augmenter dans le panache d'émission riches en oxydes d'azote des centrales thermiques. Dans l'hémisphère nord au moins, la pollution anthropique par l'ozone agit donc à un effet qui dépasse l'échelle des continents. 

Les enfants des populations urbaines pauvres y sont souvent plus vulnérables. En 1994, à Atlanta, une étude épidémiologique a montré que les jours où les taux d'ozone atteignaient ou dépassaient dans l'air, et jusqu'au lendemain du pic de pollution, le nombre moyen d'hospitalisation pour asthme ou difficultés respiratoires réactives était de 37 % plus élevé que les autres jours. De plus, cette étude a aussi montré que les enfants noirs de familles pauvres étaient les plus touchés.

C'est pour toutes ces raisons que l'Association santé environnement France (ASEF), qui réunit près de en France, a réclamé une prise en charge politique du problème.

L'ozone fait l'objet de modélisations et de prévisions accessibles depuis les années 1990.

Un appareil de laboratoire couramment utilisé pour la démonstration de production d'ozone était la machine électrostatique de Whimshurst : elle utilisait la mise en rotation par une manivelle de deux plateaux isolés identiques, mais tournant en sens inverse. Des balais collectent l'électricité statique produite par le frottement, ils déchargent les plaques en produisant un arc électrique autour duquel apparait de l'ozone (alors diffusé dans l'air).

De l’ozone peut être produite par électrolyse en utilisant une batterie de , une cathode de graphite, une anode de platine et l’acide sulfurique comme électrolyte. Les demi-réactions qui ont lieu sont :

Trois équivalents d’eau sont utilisés pour produire un équivalent d’ozone. Cette réaction est en compétition avec celle de formation d’oxygène.

Une production industrielle d'ozone est permise par plusieurs techniques :

L'ozone se dégrade très vite (cfr. décomposition de l'ozone) mais il est néanmoins indispensable de pouvoir détruire l'ozone résiduel lorsque cette molécule est utilisée en industrie dans le but évident de protection du personnel. L'ozone peut être dégradé en dioxygène par différentes façons :
L'ozone résiduel peut également être rejeté dans l'atmosphère après dilution dans un grand volume d'air, opération réalisée par de puissants ventilateurs.

L'injection d'ozone dans l'eau est assez compliquée car l'ozone est très peu soluble dans l'eau.

Des diffuseurs appelés diffuseurs à poreux dont l'élément poreux est en verre de quartz permettent un rendement maximum de 20 % Le principe des diffuseurs à poreux est de diffuser des bulles d'ozone gazeux d'une taille variant entre 0.5 et dans l'eau à traiter. Ces systèmes sont idéaux pour de petites quantités d'eau à traiter. 

Les contacteurs à membrane permettent d'obtenir une haute concentration d'ozone dissous dans l'eau. La membrane permet les échanges entre l'ozone gazeux et l'eau à traiter. Le principe du contacteur suit la loi de Henry en abaissant la pression de l'ozone gazeux en contact avec l’eau (qui circule transversalement) pour créer une force conductrice permettant l'injection de l'ozone dans l'eau.

Un injecteur-venturi est utilisé le plus souvent pour obtenir une concentration maximale d'ozone dissous dans l'eau, en effet, un injecteur venturi permet un rendement d'environ 90 %.
Le principe du venturi est une application de l'équation de Bernoulli qui exprime le bilan hydraulique d'un fluide dans une conduite en régime permanent : 

formula_1


Or, à débit constant : "q" (débit en m³/s) = S"v" = S"v" = constante, avec S : surface en un point (m²) et "v" : vitesse du fluide en un point (m/s). Ceci montre que si la surface diminue comme c'est le cas dans l'injecteur venturi, la vitesse augmente.

En reprenant l'équation simplifiée de Bernoulli : si la vitesse augmente, alors la pression diminue. Il y a donc une dépression dans la zone contractée du venturi (là où le tuyau d'ozone gazeux est raccordé) ce qui permet l'aspiration de l'ozone gazeux dans l'eau à ozoner.

L’ozone est un oxydant et un désinfectant puissant. Il présente certains avantages par rapport à d’autres oxydants habituellement utilisés dans l’industrie, en particulier le chlore. 

De manière générale, les inconvénients en sont :

Pour la désinfection de l'eau potable, l’ozone présente des avantages par rapport au chlore : il ne reste pas présent dans l’eau et n'altère donc pas son goût, et ne provoque pas l’apparition de composés organochlorés, qui peuvent être cancérogènes.

Néanmoins, l'ozone ne permet pas d'inactiver tous les micro-organismes présents dans l'eau (comme les parasites "Cryptosporidium", "Giardia" et "Toxoplasma gondii"), même s'il a une efficacité certaine contre "Cryptosporidium" et "Giardia".

L’ozone est employé dans le traitement de l’eau pour plusieurs fonctions :

L'ozone est devenue une référence de qualité pour l'eau potable dans beaucoup de communes et de villes à travers le monde :

L’ozone est utilisé dans des procédés de traitement des eaux usées, en particulier pour rendre digestible par des bactéries la demande chimique en oxygène (DCO) dite « dure », pour le traitement de la couleur, et pour la désinfection de l’eau en sortie de stations d’épuration (traitement dit "tertiaire"). Ces applications nécessitent la maîtrise de plusieurs techniques : ozonisation, mais aussi bioréacteurs. Parfois la performance de l'ozone peut être améliorée en combinant l’ozonisation à un traitement UV à haute dose d’irradiation. On parle alors de "procédés d’oxydation avancés".

L'ozone est utilisé comme antiseptique et bactéricide dans le traitement des plaies.

Les propriétés oxydantes et désinfectantes de l'ozone sont encore mises à profit dans diverses situations.








C'est la méthode la plus simple et la moins coûteuse. L'échantillon d'eau à analyser passe dans un tube contenant un réactif à l'ozone (réactif DPD ou dipropyl-p-phénylènediamine appelé aussi "réactif indigo"), la lecture de la concentration se fait grâce à un disque colorimétrique ou un spectrophotomètre. Le problème de cette technique est le manque de précision. De plus, cette méthode nécessite un personnel avec une formation de laborantin.


Les sondes électrochimiques contiennent un électrolyte qui est séparé de l'eau par une membrane sélective. On mesure alors un courant électrique entre ces deux électrodes placées de part et d'autre de la membrane. La concentration d'ozone dans l'eau fera varier ce courant électrique.



Ces analyseurs utilisent la loi de Beer-Lambert. Une longueur d'eau connue est traversée par un rayon ultraviolet. On mesure l'absorption UV de l'échantillon et un simple calcul donne la concentration d'ozone dans l'eau.

Une colonne de dégazage extrait l'ozone de l'eau. La concentration d'ozone est alors mesurée dans l'air, par la suite la concentration d'ozone dans l'eau est déduite à l'aide de la loi de Henry. Le gros avantage de ces analyseurs est la possible utilisation sur des eaux non-traitées. 


C'est une méthode assez peu utilisée car elle s'appuie sur le fait que l'ozone, étant un puissant oxydant, fera varier le potentiel redox de l'eau. C'est vrai, mais il faudra alors que la qualité de l'eau reste parfaitement constante. Sans cela, les mesures de potentiel redox risque d'être erronées. De plus, cette méthode nécessite un pré-étalonnage à l'aide d'une autre méthode (colorimétrique par exemple) pour pouvoir être utilisable en pratique.


C'est la méthode la plus simple et la moins coûteuse. L'échantillon d'air à analyser passe dans un tube contenant un réactif à l'ozone (réactif DPD ou dipropyl-p-phénylènediamine), la lecture de la concentration se fait grâce à une échelle colorimétrique. Le problème de cette technique est le manque de précision.


Ces appareils utilisent un matériau semi-conducteur dont les caractéristiques électriques varient en fonction de la concentration d'ozone dans l'air.


Les analyseurs d'ozone (ou ozomètre à ozone gazeux) calculent la concentration d'ozone dans l'air à l'aide de la loi de Beer-Lambert qui détermine la concentration d'ozone en fonction de l'absorption du rayonnement UV. Ces appareils, extrêmement coûteux par rapport aux autres systèmes, présentent de nombreux avantages comme une grande précision, aucune interférence avec d'autres éléments, une réponse très rapide et aucun consommable à prévoir. À noter aussi, qu'étant donné la toxicité de l'ozone gazeux, la plupart des générateurs d'ozone sont couplés à un analyseur d'ozone gazeux qui arrête la production d'ozone lorsque la valeur seuil d'ozone dans l'air ambiant (généralement ) est dépassée.

Les variations de concentration de la couche d'ozone stratosphérique se mesurent par spectroscopie.




</doc>
<doc id="15748" url="https://fr.wikipedia.org/wiki?curid=15748" title="Jacques Prévert">
Jacques Prévert

Jacques Prévert est un poète, scénariste, parolier et artiste français, né le à Neuilly-sur-Seine, et mort le à Omonville-la-Petite (Manche). Auteur de recueils de poèmes, parmi lesquels "Paroles" (1946), il devint un poète populaire grâce à son langage familier et à ses jeux sur les mots. Ses poèmes sont depuis lors célèbres dans le monde francophone et massivement appris dans les écoles françaises. Il a également écrit des sketchs et des chœurs parlés pour le théâtre, des chansons, des scénarios et des dialogues pour le cinéma où il est un des artisans du réalisme poétique, et il a réalisé de nombreux collages à partir des années 1940.

Jacques André Marie Prévert, deuxième enfant d'André Louis Marie Prévert, un homme de lettres âgé de 29 ans, et de Marie Clémence Prévert, 22 ans, (née Catusse), naît au 19 de la rue de Chartres à Neuilly-sur-Seine (actuellement Hauts-de-Seine) le 4 février 1900. Il y passe son enfance. Jacques a un frère ainé, Jean, né en 1898, qui mourra en 1915 de la typhoïde. Il a aussi un frère cadet, Pierre, né le 26 mai 1906. Son père André Prévert (bonapartiste anticlérical), fait divers métiers pour gagner sa vie, et de la critique dramatique et cinématographique par plaisir. Il l'emmène souvent au théâtre et au cinéma. Marie Clémence, sa mère (d'origine auvergnate et ancienne vendeuse aux Halles de Paris), l'initie à la lecture. En 1906, André Prévert perd son emploi et la famille, sans le sou, déménage à Toulon, jusqu'à ce que son père lui trouve un emploi à l'Office central des œuvres charitables ; la famille s'installe alors rue de Vaugirard. Jacques Prévert s'ennuie à l'école (faisant souvent l'école buissonnière en parcourant Paris avec la complicité de son père), et dès 15 ans, après son certificat d'études primaires, il abandonne les études. Il multiplie alors les petits travaux, notamment au grand magasin Le Bon Marché. Il fait quelques larcins et fréquente des voyous mais n'est jamais inquiété par la police : , écrira-t-il plus tard. Mobilisé le 15 mars 1920, son service militaire s'effectue d'abord à Saint-Nicolas-de-Port où il rencontre Yves Tanguy, puis il réussit à se faire affecter en 1921 à Istanbul, pacifiquement occupée par les troupes alliées, où il fait la connaissance du traducteur et futur éditeur Marcel Duhamel.

En 1922, il retourne à Paris et y vivote en faisant de petits métiers. Avec Yves Tanguy, il fréquente également la Maison des amis des livres, rue de l'Odéon, tenue par Adrienne Monnier, qui leur fait découvrir la littérature et des personnalités comme André Breton et Louis Aragon. Il est hébergé de 1924 à 1928 par Marcel Duhamel qui s'est installé au 54 de la rue du Château près de Montparnasse. (Duhamel dirige l’"hôtel Grosvenor" qui appartenait à son oncle et qui est sis non loin de là.) 

L'appartement de la rue du Château devient l'endroit de rencontre du mouvement surréaliste. C'est en fait un logement « collectif » qui accueille tous les amis désargentés de Duhamel : Raymond Queneau, Yves Tanguy. C'est dans cet endroit que Prévert trouve le terme de "" pour définir le jeu littéraire auquel ses amis et lui se livrent. Le 30 avril 1925, il épouse Simone Geneviève Dienne (1903-1994), son amie d'enfance devenue violoncelliste dans un cinéma de la rue de Cluny pour accompagner les films muets. En 1928, il quitte la rue du Château et s'installe avec elle au pied de la butte Montmartre et se lance dans l'écriture (en février, il compose "Les animaux ont des ennuis", son premier poème). On lui présente également le comédien Pierre Batcheff, qui cherche un scénariste pour son premier film ; c'est un coup de foudre amical et les Batcheff, émus par les conditions de vie très modestes du couple Prévert, décident de l'héberger chez eux. En 1929, plusieurs de ses poèmes paraissent dans des revues (en 1931, "Tentative de description d'un dîner de têtes à Paris-France" est remarqué dans le milieu littéraire). Prévert est toutefois trop indépendant d'esprit pour faire véritablement partie d'un groupe constitué, quel qu'il soit. Il supporte mal les exigences d'André Breton et la rupture est consommée en 1930. 

Jacques Prévert ne se sent pourtant pas encore écrivain. Il s’installe rue Dauphine et intègre le groupe des Lacoudem, également lié par une forte amitié.

En 1932, Jacques Prévert est sollicité (à l'initiative du communiste Paul Vaillant-Couturier) par le groupe Octobre pour écrire des textes contestataires d’agitation-propagande. Sa verve, son humour, son aisance à rédiger très rapidement sur des sujets d’actualité brûlants, feront la notoriété du groupe. Le plus célèbre de ces textes, "La Bataille de Fontenoy" (présenté en 1933 aux Olympiades internationales du théâtre ouvrier à Moscou), moque les hommes politiques de l’époque. De 1932 à 1936, le groupe est très actif et se produit dans des usines en grève (Citroën), des manifestations, en pleine rue, ou encore dans des bars. Prévert est l’auteur principal, et Lou Bonin le metteur en scène. Les textes, en prise directe avec l’actualité nationale ou internationale, sont écrits à chaud et les représentations données après à peine une nuit de répétition. Aux côtés de Jacques Prévert et de son frère Pierre, on trouve Raymond Bussières, Marcel Mouloudji, Maurice Baquet, Margot Capelier, ou encore des futurs cinéastes Paul Grimault, Yves Allégret et Jean-Paul Le Chanois. Une équipe d’amis et de fidèles avec lesquels Prévert continuera de travailler par la suite. À l'été 1932, la troupe est invitée à Moscou d'où Jacques Prévert ne revient pas militant communiste. Le groupe se sépare le juillet 1936, à la suite d’une dernière représentation de leur spectacle, "Tableau des merveilles". Prévert se consacre alors pleinement au cinéma.

Toute sa vie, Jacques Prévert témoignera d'un engagement politique sincère. Surréaliste inclassable, certains observateurs n'hésitent pourtant pas à l'apparenter au courant libertaire. En 2012, Jean-Louis Trintignant l'intégrera dans son spectacle "Trois poètes libertaires", aux côtés de Boris Vian et de Robert Desnos.

Cet engagement sera à l'origine de ses plus belles réussites et de nombre de ses déboires. Le groupe Octobre, avec lequel il se fit remarquer, était une troupe de théâtre itinérante qui allait jouer dans les usines en grève. Jean Renoir, compagnon de route du Parti communiste français, travaille tout naturellement avec lui, en particulier sur "Le Crime de monsieur Lange". "Lumière d'été" de Jean Grémillon met en scène l'oisiveté et le travail, et "Les Visiteurs du soir" s'achève, après que le diable a transformé en statues de pierre les amoureux qui lui résistaient, par un battement sourd et cette réplique, que tous les Français comprirent : « Ce cœur qui bat, qui bat…».

Il est le scénariste et le dialoguiste de plusieurs grands films français des années 1935-1945, notamment "Drôle de drame", "Le Quai des brumes", "Le jour se lève", "Les Visiteurs du soir", "Les Enfants du paradis" et "Les Portes de la nuit" de Marcel Carné, "Le Crime de monsieur Lange" de Jean Renoir, "Remorques" et "Lumière d'été" de Jean Grémillon. Il adapte deux contes d'Andersen, d'abord "La Bergère et le Ramoneur", qui devient "Le Roi et l'Oiseau", film d'animation de Paul Grimault en 1957, puis, en 1964, "Grand Claus et Petit Claus", à la télévision, "Le Petit Claus et le Grand Claus" de son frère Pierre Prévert.

Pendant la Seconde Guerre mondiale, il protège son ami Joseph Kosma, qui, grâce à lui, peut poursuivre son travail de musicien, et il aide également le décorateur Alexandre Trauner à se cacher.

Ses poèmes sont mis en musique par Joseph Kosma dès 1935 ("À la belle étoile") ; ses interprètes sont, entre autres, Agnès Capri, Juliette Gréco, les Frères Jacques, Yves Montand. 

C’est en 1938 au bord du paquebot le Normandie que Jacques Prévert et Jacques Canetti se rencontrent. Destination New-York. Le premier accompagne l’actrice Jacqueline Laurent qui fait ses débuts au cinéma et dont il est amoureux. Le second, directeur artistique de Radio Cité, va à New-York pour voir comment on fait de la radio outre-Atlantique. 

L’un et l’autre se connaissent de nom. Ils ont pour amies Marianne Oswald et Agnès Capri, qui chantent déjà les chansons de Prévert au « Bœuf sur le Toit » de Jean Cocteau. Ils promettent de se revoir, mais la guerre arrive.

Pendant la Seconde Guerre mondiale, il se réfugie à Nice.

Ils se retrouveront dix ans plus tard exactement. En 1949, à Saint-Germain-des-Prés, les Frères Jacques font un triomphe avec "Exercices de style" de Raymond Queneau. Jacques Canetti, producteur musical des disques Polydor, leur propose de les enregistrer sur un disque consacré aux chansons de Prévert. Canetti fait ensuite enregistrer du Prévert par Juliette Gréco, Yves Montand, Catherine Sauvage, Serge Reggiani. Sans oublier Jacques Prévert lui-même, qu'il enregistre en le faisant accompagner à la guitare par Henri Crolla.

En 1975, ils retrouvent leur complicité grâce au compositeur espagnol Sebastian Maroto, qui compose avec Jacques Prévert ses dernières chansons ; treize chansons aux lignes mélodiques claires. Ces chansons sont, à la demande de Canetti et de Prévert, chantées par Zette, la femme du compositeur, et elles paraissent en disque vinyle aux Productions Jacques Canetti. 

Divorcé de Simone Dienne en 1935, il vit une histoire d'amour avec la comédienne Jacqueline Laurent en 1936, puis avec une jeune actrice de 15 ans, Claudy Emanuelli (dite Claudy Carter), et enfin en 1943 avec Janine Fernande Tricotet (1913-1993), élève du danseur Georges Pomiès, qu'il épouse le 4 mars 1947 et avec qui il a une fille, Michèle, née en 1946.

Au lendemain de la guerre, l’éditeur René Bertelé obtient de Prévert l’autorisation de rassembler en un recueil ses nombreux textes et poèmes parus depuis les années 1930 dans des revues littéraires. Sorti en mai 1946, "Paroles" est le premier livre signé Prévert. Il en a lui-même créé le graphisme, à partir d’une photo de graffiti de son ami Brassaï. Le succès, critique comme public, est foudroyant. Le style joyeusement iconoclaste de Prévert et ses thèmes de prédilection, les bonheurs simples, la révolte et l’amour, séduisent autant le cercle de Saint-Germain-des-Prés que le grand public. En quelques semaines, les exemplaires du premier tirage s’envolent. Une nouvelle édition enrichie est vite publiée, et ses poèmes sont traduits en anglais, en italien, en japonais, etc. D’autres recueils suivront ("Spectacle"", La pluie et le beau temps"", Histoires"", Fatras"", Imaginaires"", Choses et Autres"), dans lesquels aphorismes, dessins, collages, sketches voisinent avec les poèmes. Parallèlement à ses propres recueils, Prévert cosigne des ouvrages avec des photographes, des peintres ou des illustrateurs pour enfants (Jacqueline Duhême, Elsa Henriquez, Ylla…). Jacques Prévert prend alors ses distances avec le cinéma afin de se consacrer à l'écriture. 

En 1948, il confie à Henri Crolla la composition des musiques de ses chansons, dont "La Chanson des cireurs de souliers de Broadway" destinée à Montand. Il se sépare de Kosma qui a pris le parti du producteur dans le film "Le Roi et l'Oiseau" que Paul Grimault jugeait inachevé. Le film sort dans une première version désavouée par les auteurs Grimault et Prévert, sous le titre "La Bergère et le Ramoneur". C'est la fin de sa collaboration avec Kosma. 

Le 12 octobre 1948, à Paris, pendant une interview, il tombe accidentellement d'une porte-fenêtre et reste plusieurs jours dans le coma (il reste ensuite marqué par des séquelles neurologiques irréversibles). Le hasard a voulu que Pierre Bergé, qui était arrivé le jour même, pour la toute première fois, dans la capitale, fût témoin de l'accident alors qu'il se promenait sur les Champs-Élysées. En repos forcé à Saint-Paul-de-Vence, il se met à pratiquer assidûment le collage, qui constitue pour lui une autre forme de poésie. Parallèlement à sa production de collages, il se consacre à des dessins animés et à des films pour enfants et collabore à de nombreux ouvrages avec ses amis peintres, dessinateurs et photographes, le plus souvent pour des éditions limitées : "Grand Bal du printemps" avec le photographe Izis Bidermanas, "Les Chiens ont soif" avec Max Ernst, textes pour le peintre Miró, pour le photographe Robert Doisneau, etc. Il travaille aussi avec des illustrateurs : il réalise en 1953 "L’Opéra de la Lune" avec Jacqueline Duhême, pionnière de l’illustration pour enfants, ou encore "Lettre des îles Baladar", avec le dessinateur André François.

Jacques Prévert a longtemps vécu dans des meublés et des hôtels, avant de s'installer en 1956 dans un appartement au 6 bis, cité Véron dans le quartier des Grandes-Carrières, au fond d'une petite impasse derrière le Moulin-Rouge, sur le même palier que Boris Vian qui se produit au cabaret de son frère Pierre Prévert : La Fontaine des Quatre-Saisons où il lui plaît d'accueillir lors de ses visites les spectateurs de renom coiffé d'une casquette de chasseur marquée en lettres dorées : "La Fontaine des Quatre-Saisons".

En 1957, Jacques Prévert expose pour la première fois à la galerie Maeght une série de collages, genre artistique insolite et inclassable qu’il pratique avec passion depuis 1948. Suivront le Musée Grimaldi à Antibes en 1963 et, un an plus tard, la galerie Knoedler à Paris qui présentent 112 collages de Jacques Prévert provenant de sa collection personnelle, et de celles de ses amis Picasso, René Bertelé, Marcel Duhamel, André Villers, Betty Bouthoul et Renée Laporte. Ses collages sont un prolongement direct de son écriture imagée, inspirés de la tradition surréaliste et d’une grande liberté formelle, ils jouent sur le détournement d’aphorismes ou d’expressions populaires, la relecture ou la réappropriation d’images existantes. Ses collages s’intègreront tant et si bien à son œuvre poétique qu'il en publiera cinquante-sept dans son recueil "Fatras" (1966) et vingt-cinq dans "Imaginaires" (1970). 

Le domicile secondaire de la famille Prévert est à Antibes, mais, à la suite de la résiliation de son bail par le propriétaire qui souhaitait récupérer l'appartement des remparts, il doit quitter Antibes. Sur les conseils du décorateur Alexandre Trauner, il achète alors une maison en 1971 à Omonville-la-Petite, dans la Manche. Le , il y meurt des suites d'un cancer du poumon, lui qui fumait trois paquets de cigarettes par jour et en avait toujours une à la bouche. Il avait 77 ans.

Aux côtés de sa femme, de sa fille et de son ami Alexandre Trauner, il est enterré au cimetière d'Omonville-la-Petite, où l'on peut également visiter sa maison. Non loin de là, à Saint-Germain-des-Vaux, ses amis ont aménagé un jardin dédié au poète.

Prévert fait éclater le caractère conventionnel du discours par le jeu des mots. Sa poésie est constamment faite de jeux sur le langage (calembours, inventions burlesques, néologismes, lapsus volontaires…) dont le poète tire des effets comiques inattendus (un humour parfois noir), des significations doubles ou encore des images insolites.

Ses poèmes fourmillent de jeux de sons, de combinaisons pour l'oreille (allitérations, rimes et rythmes variés) qui paraissent faciles, mais dont Prévert fait un usage savant. Enfin, il ne faut pas négliger, comme l'a fait remarquer Danièle Gasiglia-Laster dans son introduction aux "Œuvres complètes" de Prévert dans la Bibliothèque de la Pléiade, les apports du surréalisme dont on retrouve les traces : inventaires, énumérations hétéroclites d'objets et d'individus, additions de substantifs ou d'adjectifs, etc. Il est friand des procédés de l'image, de la métaphore et de la personnification (animal, objet, humain).

Prévert s'en prend aux stéréotypes du langage, à tout ce qui est figé, imposé : « Les expressions stéréotypées, les citations célèbres, les proverbes, permettent toutes les mystifications possibles. Quand certains êtres en oppriment d'autres, ils tentent en effet de leur faire croire que ce qui se dit ou s'écrit reflète l'ordre naturel des choses : "A tout seigneur tout honneur", "Qui aime bien châtie bien", etc. Aussi Prévert va-t-il détourner de leur sens ces "messages du mensonge", les subvertir au profit de ceux qu'ils desservaient : "Cent fois sur le métier remettez votre ouvrage à demain, si on ne vous paie pas le salaire d'aujourd'hui" […], ou bien inventera à son tour des aphorismes qui insinueront d'autres rapports de force et surtout une autre conception de la société : "Quand les éboueurs font grève, les orduriers sont indignés" […]. Quand il utilise des clichés, non pas pour les mettre dans la bouche de personnages sans consistance, mais pour son propre compte, il leur fait subir une cure de jouvence, le plus souvent en les prenant à leur premier degré de signification. Ainsi, le monde de "Lanterne magique de Picasso" est-il "beau comme tout", comme la totalité de l'univers et de ses parcelles. Bousculer les automatismes se révèle en définitive vital, car à trop se contenter d'utiliser le langage tel qu'il nous est donné, avec les mêmes immuables associations, on risque de pétrifier les êtres et les choses.» explique Danièle Gasiglia-Laster (Introduction au tome 1 des "Œuvres complètes" de Prévert, Bibliothèque de la Pléiade, Gallimard).

« Jacques Prévert est très attaché à la langue. Il est un gourmet des mots qui éprouve un vrai plaisir en jouant avec eux. Et cette jouissance du verbe, il la communique à ses lecteurs. Dès que les mots jaillissent, il les attrape et s’amuse : il les associe, les oppose, les détourne, les fait sonner les uns avec les autres, joue avec leurs différents sens… Il part de mots simples, « des mots de tous les jours » comme les nomme Garance/Arletty dans Les Enfants du paradis (Marcel Carné, 1945). Et, grâce à un travail d’orfèvre, il leur donne une force et une vivacité teintées d’humour – parfois noir et féroce – qui constituent sa patte. L’humour est capital. N’oublions pas que Prévert a été élevé à la distinction de Satrape du Collège de Pataphysique en qualité de fabricant de Petits Plats dans les Grands pour la définition qu’il en avait donnée dans "La Nef" (01/1951) : " Depuis trop longtemps on prenait l’humour à la légère, il s’agit maintenant de le prendre à la lourde " » écrit Carole Aurouet dans "Jacques Prévert, Paris la belle", catalogue d'exposition.


Prévert est, avec notamment "Quai des brumes" de Marcel Carné en 1938, "Le Crime de monsieur Lange" de Jean Renoir (1936) et "Les Enfants du paradis" de Marcel Carné (1945), l'un des grands scénaristes français. 

Les réalisateurs avec qui il a travaillé lui accordaient une grande confiance sur l'histoire racontée par le film. Nombre de réalisateurs ont réalisé leur meilleur film avec lui, ou du moins le plus original. Nombre de ses répliques ( "« —T'as de beaux yeux, tu sais ? — Embrassez-moi.»") ("« — François, y a plus de François ! »") ( "« Paris est tout petit pour ceux qui s’aiment comme nous d’un aussi grand amour.»") ("« Vous êtes riche et vous voudriez être aimé comme un pauvre. Et les pauvres on ne peut quand même pas tout leur prendre, aux pauvres ! »") sont parfois plus connues que ses poèmes. Prévert qui travaillait sur les films jusqu'au mot "FIN" est souvent qualifié d'auteur sans que des réalisateurs aussi talentueux que Renoir, Carné ou Grémillon en prennent ombrage.

Il a travaillé près de trente ans avec Paul Grimault sur "Le Roi et l'Oiseau", et, alors que Paul Grimault avait enfin trouvé les moyens de finir son film, et que Prévert était à l'article de la mort, il a travaillé sur les dialogues jusqu'à son dernier souffle. La veille de sa mort, il envoie un télégramme à Paul Grimault avec ces mots : "« Et s'il n'en reste qu'un, nous serons ces deux-là.»" "Le Roi et l'Oiseau" s'achève sur la libération d'un oiseau enfermé dans sa cage par le robot destructeur, libéré lui aussi, et qui, dès que l'oiseau s'envole, écrase la cage d'un coup de poing.

Dans le cinéma, son nom est attaché aux grandes œuvres de la période du cinéma français de 1935 à 1945. Après guerre, . Il continue comme scénariste, avec encore de belles réussites, comme "Les Amants de Vérone" d'André Cayatte (1948), les films réalisés avec Paul Grimault, notamment "Le Roi et l'Oiseau" dont il est question plus haut, les films réalisés pour la télévision avec Pierre Prévert, "Le Petit Claus et le Grand Claus" (1964), "La Maison du passeur" (1965). Mais à partir de la publication de "Paroles", il se consacre davantage à ses textes publiés en recueils.

En 2007, fut créé par l'Union Guilde des Scénariste (devenu depuis la Guilde française des scénaristes) le Prix Jacques-Prévert du scénario. Avec l'accord de sa petite fille, Eugénie Bachelot-Prévert, le prix rend hommage à celui que l'on considère comme un grand scénariste. La récompense (souvent décernée le , la date d'anniversaire du poète) est remise au meilleur scénario, parmi les films français sortit dans l'année, par un jury composé de scénaristes.

La musique classique

Prévert a écrit un certain nombre de poèmes en hommage à des œuvres musicales qu'il appréciait. Il a, en 1974, participé, à la demande d'Arnaud Laster, à une émission diffusée sur France Musique, "L'Antenne de France-Musique est à Jacques Prévert". Dans cet entretien avec A. Laster, enregistré dans la maison qu'il habitait alors avec sa femme Janine à Omonville-la-Petite, il parle de son goût pour des musiciens aussi divers que Alban Berg, Georges Bizet, Igor Stravinsky, Antonio Vivaldi, Erik Satie, Haendel, Carl Orff… C'est le peintre autrichien Lucas Suppin qui a mis en relation Jacques Prévert avec Carl Orff. Nous apprenons également dans ces lettres de Suppin que Orff, Suppin et Prévert avaient un projet commun autour d'un livre (probablement autour du thème d'Œdipe), mais celui-ci ne s'est jamais réalisé.

Prévert entretenait avec Carl Orff une proximité amicale comme en témoignent ses dédicaces régulières, dont une datée de 1959 : « à Carl Orff, à sa musique - Jacques Rêve-vert ». Un poème publié dans "Choses et autres", "Carmina Burana" (titre d'une cantate scénique de Carl Orff : "Carmina Burana") rend hommage à ces chants profanes. Ce poème sera repris dans l'ouvrage "Carmina Burana" (Manus Press 1965 ) illustré de partitions de Carl Orff et de dessins de . 

Prévert entend dans la musique de Carl Orff, écrit Arnaud Laster, « un hymne à la beauté et à l'amour » et « une revendication du bonheur qui rejoint la sienne ». L'un et l'autre ont travaillé l'histoire d'Agnès Bernauer : "Die Bernauerin" pour Carl Orff en 1947 et "Agnès Bernauer" pour Prévert en 1961 dans le film "Les Amours célèbres" de Michel Boisrond.

Le titre du recueil "Paroles", notent Danièle Gasiglia-Laster et Arnaud Laster, sonne comme un défi, un refus de se soumettre à la tradition qui privilégie l'écrit et l'imprimé ; ce que confirment les propos de Prévert rapportés par un journaliste : "Il n'est pas vrai que les écrits restent. Ce sont les paroles". Propos qui font écho, en plus provocateurs, à ceux qu'il avait déjà mis dans la bouche d'un facteur - homme de lettres à sa manière, un confrère en somme : « les écrits s'envolent, les paroles restent » [Drôle d'immeuble, "La Pluie et le Beau Temps"]. Donne-t-il par là raison à un critique de "Paroles" qui se demandera - sans penser particulièrement au titre - s'il ne s'agirait pas « sous couleur de désinvolture d'une démarche poétique particulièrement ambitieuse ? » Il est permis de le soutenir, même si Prévert vise moins à substituer une hiérarchie à une autre qu'à suggérer, à la faveur d'un renversement, l'égale valeur de tous les modes d'expression.

Carole Aurouet en fait le commentaire suivant : Outre les thèmes abordés, "Paroles" est également novateur, atypique et détonant, par sa forme et son style. C’est un recueil placé sous le signe de l’éclectisme dans lequel on trouve aussi bien des textes courts que des chansons, des histoires, des instantanés et des inventaires. Prévert y mélange les genres. Il ne s’inscrit dans aucune taxinomie poétique. Par ailleurs, il tord le cou aux règles de versification classique, tant au niveau du rythme que de la disposition ou de la ponctuation. Prévert a notamment gardé de son passage par le surréalisme une façon singulière de détruire les clichés langagiers et les lieux communs. Il attire, par exemple, l’attention de ses lecteurs sur l’arbitraire du signe. Il use avec brio des contrepèteries, des calembours, des équivoques et des allégories. Il rend hommage en quelque sorte au langage populaire.
Prévert étant devenu Satrape du Collège de 'Pataphysique en 1953, et le Collège ne prenant pas en compte des transformations aussi peu importantes que le décès, il y demeure président mémorial de la Sous-Commission des Paraphrases.

Danièle Gasiglia-Laster précise, dans son analyse sur "Paroles" parue dans la collection Foliothèque de Gallimard : Que le poète sache manier l'extrême concision ne fait pas de doute, mais il excelle aussi dans les grands textes foisonnants où il met alors en scène de multiples personnages qui évoluent dans des environnements variés. 

L'écrivain Roger Bordier fera un éloge politique de Jacques Prévert dans la revue "Europe" :

« Du côté des exploités, des pauvres, des démunis, Prévert a crié la scandaleuse organisation de la misère, la honte du crime institutionnalisé, les tartufferies d'une presse aux ordres, la sadique organisation d'une puissance industrielle […] qui confond ses bénéfices personnels avec les biens de la nation . »

L'écrivain Pierre Jourde, ironisant sur l'admiration de Frédéric Beigbeder pour Prévert dans son "Dernier inventaire avant liquidation", commente :

Michel Houellebecq se montre à son tour particulièrement hermétique à la poésie de Jacques Prévert mais la conclusion de l'article où il attaque l'auteur de "Paroles" - qui fait encore polémique - montre à l'évidence que c'est le "libertaire" qui est visé :

Philippe Forest s'en prend, lui, à ceux qui attaquent Hugo, Aragon ou Prévert - dont il estime que "Tentative de description d'un dîner de têtes à Paris-France" est un texte « merveilleux » - et pense qu'il faut en finir avec « une lecture stéréotypée de l'histoire littéraire. Peu de lecteurs lucides ont ouvert la voie. Il y a eu en effet Bataille, l'un des rares à prendre au sérieux "Paroles" - l'un des plus grands livres, pourtant, du siècle passé. Mais connaissez-vous beaucoup de thuriféraires de "Histoire de l'œil" qui se souviennent du texte que Bataille a consacré à Prévert ? Voilà qui compliquerait beaucoup la réflexion routinière de la critique. Et si les mauvais sentiments, au fond, ne produisaient jamais que de la mauvaise littérature ? Et si le roman, la poésie vraie étaient en fait du parti de cette chose si désuète, démodée qu'on nommait autrefois la bonté ? Cette pensée-là, il a fallu toute sa vie à quelqu'un comme Roland Barthes pour avoir le courage de l'exprimer. Il est vrai qu'elle est assez scandaleuse pour qu'il nous faille tout le siècle à venir pour en méditer l'énigme. » (propos recueillis par Danièle Gasiglia-Laster et Arnaud Laster, "L'Echo Hugo", n°5, 2005).

En 2017, le metteur en scène Laurent Pelly propose une création au Théâtre national de Toulouse où il choisit d'explorer l'œuvre de Jacques Prévert,
non celle que l'on entend sur les bancs de l'école, mais celle de l'homme libertaire, subversif, antimilitariste et anticlérical ».



Si plusieurs livres pour la jeunesse sont parus après la mort de Jacques Prévert sous sa signature, Prévert n'y est pour rien. Ces volumes post mortem ont été constitués à partir de textes extraits de ses recueils. De son vivant, il n'avait conçu et publié que six livres pour les enfants.

Deux films pour enfants dont Jacques Prévert est le coauteur ont fait l'objet d'une version livresque :





Jacques Prévert est le deuxième homme le plus célébré au fronton des scolaires français (recensement en 2015) : pas moins de 472 écoles, collèges et lycées lui ont donné son nom, derrière Jules Ferry (642), mais devant Jean Moulin (434), Jean Jaurès (429), Jeanne d'Arc (423), Antoine de Saint-Exupéry (418), Victor Hugo (365), Louis Pasteur (361), Marie Curie (360), Pierre Curie (357), Jean de la Fontaine (335).







</doc>
<doc id="15749" url="https://fr.wikipedia.org/wiki?curid=15749" title="Guerre de Corée">
Guerre de Corée

La guerre de Corée a opposé, du au , la République de Corée (Corée du Sud), soutenue par les Nations unies (alors sans la représentation de la République populaire de Chine), à la République populaire démocratique de Corée (Corée du Nord), soutenue par la République populaire de Chine et l'Union soviétique. Elle résulte de la partition de la Corée à la suite d'un accord entre les Alliés victorieux de la guerre du Pacifique à la fin de la Seconde Guerre mondiale. C'est l'un des premiers conflits importants de la Guerre froide.

La péninsule coréenne était occupée par l'empire du Japon depuis 1910. Après la reddition du Japon en septembre 1945, États-Unis et Union soviétique se partagèrent l'occupation de la péninsule le long du parallèle, avec au sud des forces américaines d'occupation et au nord des forces soviétiques.

L'échec de la tenue d'élections libres dans la péninsule en 1948 aggrava la division entre les deux côtés ; le Nord met en place un gouvernement communiste, tandis que le Sud met en place un gouvernement pro-américain. Le parallèle devint une frontière politique entre les deux États coréens. Bien que les négociations pour la réunification eussent continué dans les mois précédant la guerre, les tensions s'intensifièrent. Des escarmouches et des raids inter-frontaliers persistèrent. La situation se transforma en guerre ouverte lorsque des forces du Nord envahirent le Sud le . En 1950, l'Union soviétique boycottait le Conseil de sécurité des Nations unies. En l'absence d'un véto de l'Union soviétique, les États-Unis et d'autres pays votèrent une résolution autorisant une intervention militaire en Corée. Les États-Unis fournirent 88 % des soldats internationaux qui aidèrent les forces du Sud, complétés par l'assistance de vingt autres pays. Si elle n'amena pas directement de troupes sur le terrain, l'Union soviétique fournit de l'aide matérielle aux armées chinoise et nord-coréenne.

Le conflit se déroula en quatre phases principales :

Les négociations reprirent alors et la guerre s'acheva le , lorsqu'un pacte de non-agression fut signé. L'accord restaurait la frontière entre les deux Corées près du parallèle et créait la zone coréenne démilitarisée, une zone tampon fortifiée entre les deux nations coréennes. Les deux pays étant encore officiellement en guerre, des incidents mineurs continuent de se produire encore aujourd'hui.

Du point de vue militaire, la guerre de Corée a combiné les stratégies et tactiques des deux guerres mondiales : elle commença par une rapide campagne offensive d'infanterie suivie de bombardements aériens, mais devint une guerre statique à partir de juillet 1951.

On estime que le conflit a fait plus de morts parmi les militaires coréens, nordistes et sudistes, et parmi les militaires des forces de l'ONU. Le nombre de victimes civiles est estimé à et le nombre de réfugiés à . La péninsule a été dévastée par les combats et les bombardements ; Séoul fut ainsi détruite à plus de 70 %.

À la conférence de Yalta (du 4 au ), Staline avait promis à Roosevelt que l’URSS entrerait en guerre contre le Japon trois mois après la capitulation de l'Allemagne. Lors de la conférence de Potsdam, en juillet-août 1945, les Alliés étaient convenus qu’en Corée les forces japonaises stationnées au nord du parallèle se rendraient aux Soviétiques et celles qui occupaient le sud aux Américains. Les Soviétiques intervinrent dans le Nord le , le lendemain même de la déclaration de guerre au Japon. Pour leur part, les Américains débarquèrent le 8 septembre suivant, au surlendemain de la proclamation à Séoul d'une éphémère « République démocratique » par les partis de gauche à majorité communiste qui avaient été actifs dans la résistance à l'occupation japonaise.

Cependant, ni les États-Unis, ni les Soviétiques, ni "a fortiori" les Coréens eux-mêmes ne considéraient comme définitive la partition "de facto" de la péninsule coréenne qui découlait de la double présence américaine et soviétique : en effet, une commission mixte américano-soviétique se mit en place dès janvier 1946, mais ses travaux n'aboutirent pas en raison de la tension croissante entre les deux superpuissances. En septembre 1947, les Américains portèrent la question coréenne devant les Nations unies. L’Assemblée générale de l'organisation désigna alors une commission chargée d’organiser et de superviser des élections libres en tant que préliminaires à la formation d’un gouvernement national. Toutefois, les Soviétiques, qui considéraient les Nations unies comme une organisation liée aux États-Unis (avant la décolonisation, la plupart de ses membres appartenaient au bloc occidental), refusèrent d’admettre la commission dans leur zone d’occupation.

Les partis de gauche de tout le pays, ainsi que des organisations nationalistes antiaméricaines, se réunirent à Pyongyang en avril 1948 et décidèrent le boycott de ces élections. Celles-ci ne furent finalement organisées que dans la zone occupée par les États-Unis, sous la surveillance de l'ONU ; elles portèrent au pouvoir le vieux leader nationaliste et anticommuniste Syngman Rhee, qui avait été le chef du gouvernement coréen en exil constitué en 1919. Le , la République de Corée fut proclamée à Séoul qui devint sa capitale. En réaction, des élections non surveillées par l'ONU furent organisées dans la zone d’occupation soviétique ; elles donnèrent la majorité aux partis de gauche dominés par les communistes. En même temps, des élections clandestines se déroulèrent dans le Sud : les délégués ainsi élus vinrent siéger à Pyongyang, où l'Assemblée populaire suprême proclama la République populaire démocratique de Corée. Tout comme la République de Corée, celle-ci prétendait représenter l'ensemble de la péninsule. L'homme fort du nouveau régime nord-coréen était Kim Il-sung, secrétaire général du Parti du travail de Corée et ancien résistant à l'occupation japonaise. Leader d’un petit groupe de partisans coréens à partir de 1930, Kim avait en effet dirigé plusieurs raids contre les avant-postes japonais en Corée à partir de la Mandchourie où, enfant, il s’était réfugié avec ses parents. En 1941, il quitta la Mandchourie, devenue un état fantoche du nom de Manchukuo, et reçut un entraînement militaire en Union soviétique. Il retourna en 1945 dans son pays en tant qu’officier de l’Armée rouge.

Syngman Rhee et Kim Il-sung désiraient tous deux réunifier la péninsule, mais chacun selon sa propre idéologie politique. Avec la conscription rétablie en 1947 dans le Nord, qui provoqua une certaine résistance armée dans une partie de la population (voir UNPIK), l'armée nord-coréenne appelée "Armée populaire de Corée", équipée en chars et en armes lourdes d'origine soviétique, était davantage en mesure de prendre l'initiative, tandis que l’armée sud-coréenne, en raison d’un soutien américain plus limité après le retrait des troupes d'occupation (décembre 1948 et juin 1949), était en état d’infériorité, matérielle (aucun char et pas d'avion de combat), mais surtout numérique.

L'historien français Bernard Droz affirmait en 1992 que la responsabilité américaine et sud-coréenne apparaissait peu crédible : D'après des documents d'archives soviétiques, Kim Il-sung décida d'envahir la Corée du Sud au plus tard début septembre 1949, alors qu' Staline considérait toutefois que pour le moment une telle initiative n’était opportune ni militairement, ni politiquement, ni économiquement. Il s'inquiéta notamment de l'impréparation de l’armée nord-coréenne ainsi que d'une possible intervention américaine et interdit en conséquence une entreprise dont le plein succès n’était pas assuré. En effet, par un télégramme daté du , le Politburo chargea l’ambassadeur soviétique à Pyongyang, le général Chtykov, d’informer Kim Il-sung qu’aux yeux des dirigeants soviétiques l’ et que par conséquent une telle attaque n’était pas « permise ». Par la suite, les Nord-Coréens renforcèrent leur armée et la transformèrent en un formidable instrument offensif sur le modèle des forces blindées de l'Armée rouge soviétique. Ainsi, en 1950, la Corée du Nord avait désormais un avantage certain dans toutes les catégories d'armement. La République populaire de Chine était d'abord réticente, car une guerre en Corée déstabiliserait toute la région. Mao Zedong estimait par ailleurs qu'un tel conflit encouragerait les Américains à intervenir en Extrême-Orient et interférerait avec la conquête prévue de Taïwan, où s’étaient retranchées les forces du Kuomintang de Tchang Kaï-chek. Néanmoins, la Chine n'accepterait pas la présence de troupes ennemies à ses frontières, ce qui laissait présager une intervention chinoise au cas où elle estimait que son territoire était menacé.

Le , le nouveau secrétaire d'État américain, Dean Acheson, déclara au Club national de la presse que le périmètre de défense américain dans le Pacifique comprenait les îles Aléoutiennes, les îles Ryūkyū, le Japon et les Philippines : l'omission explicite de la Corée pouvait laisser entendre que, en cas de guerre, les Américains n’interviendraient pas. Cependant, si telle avait été à un moment la position de Washington, le gouvernement américain y renonça dès avril 1950. Par conséquent, l'endiguement restant le principe de la politique américaine, Washington considérait la Corée du Sud comme un bastion servant à endiguer la progression communiste en Asie, plus particulièrement après la victoire des communistes chinois en 1949. Entre-temps, l'attitude de Staline avait évolué : lors d’une visite de Kim à Moscou en avril 1950, le maître du Kremlin avalisa les projets annexionnistes du dirigeant nord-coréen, car, après le départ des troupes américaines, il ne jugeait plus qu'une guerre faisait courir de graves risques à la Corée du Nord, tout en précisant cependant qu’il ne pouvait garantir un soutien officiel de la part de l’Union soviétique. Certains se sont demandé si l'omission publique de Dean Acheson en janvier 1950 ne relevait pas d'une provocation destinée à encourager l'initiative militaire nord-coréenne annexionniste, de manière à pouvoir déclencher en retour l'intervention américaine annexionniste inversée. Dans une interview accordée en 1992 à l’historien russe Sergeï Goncharov, Chung Sang-chin, ancien général de brigade dans l’armée nord-coréenne, rapporta que, selon l’interprète de Kim Il-sung, ce dernier aurait invoqué quatre arguments pour recueillir l’adhésion de Staline : l’attaque, déclenchée à l’improviste, serait décisive, de sorte que la victoire serait acquise en trois jours ; en Corée du Sud, l'offensive de l'Armée populaire serait accompagnée d’un soulèvement des deux cent mille membres du Parti ; la guérilla communiste apporterait son appui à l’Armée populaire ; et enfin, les États-Unis n’auraient pas le temps d’intervenir. Chung ajouta que Kim avait connaissance du discours Acheson.

D'après un rapport du ministère des Affaires étrangères soviétique à l'intention notamment de Brejnev, rapport daté du ,

le gouvernement nord-coréen prévoyait d’atteindre son objectif en trois étapes :

Fin mai 1950, l'état-major de l'Armée populaire, en accord avec les conseillers militaires soviétiques, annonça que l'armée coréenne était prête à commencer sa concentration le long du parallèle. Devant l'insistance de Kim Il-sung, le début des opérations militaires fut fixé au 25 juin 1950 (télégramme 468, 1950).
La fiabilité des documents soviétiques a été vivement contestée par les autorités nord-coréennes, tant ils mettent en question l'histoire officielle du pays. Par ailleurs, d’après les Nord-Coréens, qui invoquent la présence de conseillers américains, les États-Unis n’auraient pas respecté les termes de l'accord soviéto-américain sur le retrait des troupes de la péninsule et ils auraient multiplié les provocations et les attaques, certaines d’envergure, afin de déstabiliser la Corée du Nord. Ainsi, le musée de la Guerre à Pyongyang expose des documents d'archives faisant état de projets d'invasion de la République populaire démocratique de Corée.

Pour leur part, la majorité des historiens sud-coréens, à l'instar en France d'intellectuels de gauche, relevèrent dès les années 1950 la multiplication des incidents de frontière le long du parallèle et les déclarations belliqueuses de Syngman Rhee dans la période précédant la guerre, d'où ils conclurent à une responsabilité partagée. Selon Heo Man-ho, professeur agrégé au département de science politique et de diplomatie à la faculté des sciences sociales de Séoul, spécialiste de l'histoire de la Corée, « les tentatives belliqueuses antérieures à la guerre de Corée avaient déjà fait plus de morts ». En d'autres termes, selon Heo Man-ho, ces incidents de frontière ont été dans certains cas de « véritables batailles rangées dans lesquelles environ hommes ont été engagés » (et dont l'initiative venait tant du côté nord-coréen que du côté sud-coréen), ce qui rendait de plus en plus probable l'hypothèse d'un conflit ouvert, envisagé par l'un et l'autre camp. « Il est donc difficile de trancher de façon sûre sur cette question de savoir qui est l'envahisseur et l'initiateur de la guerre. Les seuls critères qui peuvent aider à dégrossir cette question se trouvent dans les préparatifs militaires mis en place par les dirigeants des deux Corées […] ainsi que dans les formes du soutien des deux super-puissances auprès de ces mêmes dirigeants. » Par conséquent, conclut le professeur Heo Man-Ho, « en nous appuyant sur ces critères, nous pourrions soutenir la thèse de l’"invasion nord-coréenne sur le Sud" ; en effet, la guerre de Corée a été préparée plus sérieusement par les dirigeants nord-coréens avec les soutiens sino-soviétiques ». S'agissant des préparatifs sud-coréens, l'envoyé spécial de Harry S. Truman en Corée du Sud, Philip C. Jessup, souligne, dans un mémorandum à son gouvernement daté du à la suite d'un entretien avec le président sud-coréen Syngman Rhee, que ce dernier a expliqué que les Coréens du Sud « auraient une ligne de défense stratégique bien meilleure, si leurs forces se dirigeaient vers la Corée du Nord, [mais] qu’il n’y a pas eu de planification pour se lancer dans une quelconque opération de conquête. Pourtant, l'impression générale de son intervention laisse croire qu'il ne s'était pas opposé lorsque des forces sud-coréennes, en bordure du parallèle, avaient pris des initiatives de temps en temps ». De son côté, M. Muccio, ambassadeur américain à Séoul, fait état qu'en 1948, lors d'une réception au palais présidentiel sud-coréen, le ministre de la Défense sud-coréen lui « raconta avec plaisir que ses hommes avaient conquis Haeju », ville située sur la péninsule d'Ongjin, « juste au-delà du parallèle, […] mais [il] n'ajouta pas que pratiquement tout le monde s'y était fait tuer ».

Toujours est-il que Kim Il-sung s'était donné les moyens d’une offensive générale en renforçant son armée et, quand il reçut finalement, après quarante-huit télégrammes, la permission de Staline en avril 1950, et celle de Mao Zedong un mois plus tard, il prit l’initiative le 25 juin 1950, profitant d’une situation qu’il jugeait favorable et cela dans un contexte de répression des mouvements de guérilla communistes qui avaient dominé politiquement en Corée du Sud au moment de la capitulation japonaise.

Les services de renseignement américains se sont montrés pour leur part incapables d'évaluer correctement les projets de Kim Il-sung et ne pensaient pas que celui-ci se lancerait dans un tel conflit.

La date du , choisie « fin mai 1950 […] devant l'insistance de Kim Il-sung », marque le franchissement du parallèle par les divisions nord-coréennes ; elle est généralement considérée par les historiens occidentaux et russes comme le début de la guerre de Corée. Pour sa part, la Corée du Nord retient une date antérieure de quelques jours, en alléguant qu'elle n'aurait fait que riposter à une importante incursion sud-coréenne sur son territoire, incursion livrée avec le soutien de conseillers américains.

Dans les heures précédant l'aube du , sous la protection d'un formidable barrage d'artillerie, Nord-Coréens franchirent la frontière entre les deux Corées. Le gouvernement nord-coréen annonça que des troupes commandées par le « traître et bandit » Syngman Rhee avaient traversé le parallèle, et que par conséquent le Nord avait été obligé de riposter « à une grave provocation des fantoches de Washington », selon "L'Humanité" du lendemain. De son côté, Jean-Paul Sartre, compagnon de route du Parti communiste français, affirma que « c’était la Corée du Sud qui avait attaqué la Corée du Nord à l'instigation des États-Unis ». Conseillée et équipée par les Soviétiques, qui ne s'engageront toutefois jamais ouvertement, l'armée nord-coréenne mit en ligne sept divisions, 150 T-34, pièces d'artillerie, 200 avions de combat et d'importantes réserves. L'attaque nordiste fut dévastatrice. Au moins les deux tiers de la petite armée sud-coréenne (à peine hommes répartis sur 4 divisions d'infanterie) étaient alors en permission, laissant le pays largement désarmé. Les Nord-coréens attaquèrent en plusieurs endroits stratégiques, parmi lesquels Kaesong, Chunchon, Uijongbu, et Ongjin. En quelques jours, les forces sudistes, surclassées en nombre et en puissance de feu, furent mises en déroute et durent battre en retraite. Tandis que l'attaque au sol progressait, l'armée de l'air nordiste bombarda l'aéroport de Gimpo à Séoul où se trouvait les 22 avions de liaison et d'entraînement de l'aviation du Sud. Séoul fut prise dans l'après-midi du 28 juin. Les Nord-Coréens n'avaient toutefois pas réussi à atteindre leur objectif principal, à savoir la reddition rapide du gouvernement de Rhee et la désintégration de son armée.

L'invasion de la Corée du Sud (République de Corée, RdC, ROK en anglais) semble avoir été une surprise complète pour les États-Unis et leurs alliés ; quelques jours avant l'offensive nord-coréenne, le 20 juin, Dean Acheson, le nouveau secrétaire du Département d'État, avait déclaré officiellement au Congrès qu'une guerre était improbable. Truman lui-même fut contacté quelques heures après le déclenchement de l'offensive ; il crut qu'il s'agissait du début de la troisième Guerre mondiale. En tout état de cause, une partie de l'état-major américain aurait accueilli avec enthousiasme l'annonce, espérant pouvoir ainsi « endiguer » (stratégie du "containment") la progression des communistes en Extrême-Orient. , aurait déclaré le secrétaire d’État Acheson quand il reçut le 25 juin la nouvelle du déclenchement des hostilités. Malgré la démobilisation partielle des forces américaines et alliées après la défaite du Japon, ce qui causa de sérieux problèmes logistiques aux troupes américaines dans la région - hormis les Marines, les divisions d'infanterie envoyées en Corée ne comptaient que 40 % de leurs effectifs et la majeure partie de leur équipement était inutilisable -, les États-Unis avaient encore hommes destinés à l'occupation du Japon répartis en trois divisions d'infanterie plus la division de cavalerie, sous le commandement du général Douglas MacArthur. À part les unités du Commonwealth en Corée, aucune autre nation ne pouvait fournir des renforts importants. Le président Harry S. Truman, à la nouvelle de l'invasion, ordonna à Mac Arthur de transférer des munitions au profit de l'armée sud-coréenne (en anglais ROK Army, ou ROKA) et de fournir une protection aérienne afin de permettre l'évacuation des citoyens américains. Toutefois, Truman était en désaccord avec ses conseillers, qui voulaient lancer des raids aériens contre la Corée du Nord. Il autorisa cependant la Septième flotte américaine à protéger Taïwan, mettant ainsi fin à la politique américaine de désengagement vis-à-vis du gouvernement nationaliste du Kuomintang, confiné à Taïwan – réplique américaine redoutée par Mao avant l'attaque nord-coréenne. Tchang Kaï-chek proposa de participer à la guerre, mais cette demande fut rejetée par les Américains au motif que cela ne ferait qu'encourager une intervention des communistes chinois.

Au Conseil de sécurité des Nations unies, les États-Unis, profitant de l'absence de l'Union soviétique (politique dite du « siège vide », pour dénoncer le refus américain d'admettre la Chine communiste au Conseil), firent adopter le la résolution 83 condamnant l'agression nord-coréenne ; le 7 juillet, la résolution 84 leur confia le commandement d'une force onusienne. Seize pays acceptèrent de venir en aide à la Corée du Sud. Parmi ceux-ci, les plus importants étaient le Royaume-Uni et diverses forces du Commonwealth dont celles du Canada, de l'Australie et de la Nouvelle-Zélande. Parmi les autres participants à la force des Nations unies, les Philippines, la Turquie, la France, la Belgique, la Grèce, la Thaïlande et la Colombie envoyèrent plusieurs milliers de soldats. Les autres pays participants se limitèrent à envoyer des équipes médicales.

En septembre les forces nord-coréennes avaient occupé la quasi-totalité de la Corée du Sud. Les débris de l'armée sud-coréenne ainsi que la armée des États-Unis envoyée en renfort avaient dû reculer jusqu'à être réduits à se défendre au sud-est de la péninsule, dans la petite poche de Busan, parvenant à stabiliser le front le long de la rivière Nakdong avec le secours d'un important appui aérien, empêchant les Nordistes de prendre le contrôle de la péninsule tout entière. Bien qu'encore en attente de renfort de nouvelles forces alliées, le général américain MacArthur décida de lancer une contre-offensive. Le , les marines débarquèrent à Incheon (Opération Chromite), prenant à revers les troupes nord-coréennes et coupant leurs lignes de ravitaillement. Celles-ci, encerclées, se désagrégèrent rapidement et Séoul fut reprise dès le .

Le , les effectifs des forces des Nations unies, essentiellement américaines, étaient de hommes dont pour les unités terrestres et pour la marine et l'aviation. Le 7 octobre, les troupes des Nations unies franchirent à leur tour le parallèle et pénétrèrent en Corée du Nord. Le 26 octobre, quelques unités atteignirent le Yalou, fleuve délimitant la frontière sino-coréenne.

La Chine intervint alors de manière non officielle en déployant une armée des volontaires du peuple chinois (中国|人民|志愿|军, 中國|人民|志願|軍 , Zhōngguó Rénmín Zhìyuàn Jūn). Le 31 octobre, les effectifs terrestres des Nations-Unies étaient montés à , forces sud-coréennes non comprises ; c'est à cette date que 54 divisions chinoises comptant hommes franchirent le Yalu, où elles entrèrent en contact avec des unités américaines.

Il s'agissait de la armée populaire, commandée par le général Peng Dehuai. Après des combats acharnés contre les forces chinoises, les Américains et les Sud-Coréens furent repoussés. Les Chinois se retirèrent et les Américains purent ainsi reprendre leur offensive jusqu'à ce que, à partir du 26 novembre 1950, plus d'un demi-million de soldats chinois de l'armée populaire de libération appuyant l'armée nord-coréenne repassent à l'attaque avec une couverture aérienne de l'aviation soviétique. Les forces des Nations unies, éparpillées et mal équipées contre le froid, furent rejetées au-delà du parallèle, entraînant dans leur retraite plus d'un million de civils nord-coréens fuyant le régime communiste ; Séoul fut repris par les Nord-Coréens et leurs alliés chinois. On assista en outre à l'évacuation par mer à Hungnam (environ soldats, civils, véhicules et d'équipements) et à Chinnampo du corps d'armée américain et du corps d'armée coréen encerclé par l'ennemi.

Le , les Chinois reprennent à nouveau Séoul. Au total, 70 % des membres de l'armée populaire de libération servirent en Corée, soit de militaires en trois ans de conflit, auxquels il faut rajouter travailleurs civils.

Pour redresser la situation, MacArthur suggère sans succès de lancer des dizaines de bombes nucléaires sur la Mandchourie et l'intervention des forces chinoises nationalistes du Guomindang. Le général Ridgway, alors commandant de la armée, parvint à reprendre Séoul le à la suite de plusieurs offensives acharnées et à repousser les forces communistes au-dessus du parallèle. En désaccord avec Truman, MacArthur est limogé le car le président redoutait un affrontement sino-américain dont l'Union soviétique aurait pu tirer profit. Il est remplacé par Ridgway. Le front se stabilisa sur la ligne de démarcation actuelle et bien que l'état-major américain eût planifié des débarquements en Corée du Nord pour réunifier la péninsule, ceux-ci furent suspendus par les autorités politiques car l’idée d’un "statu quo ante bellum" commençait alors à se répandre. Ridgway est remplacé à la tête de la armée des États-Unis par le général James Van Fleet qui quitte le service le 31 mars 1953.

Durant cette phase, le bataillon français livra encore d'importantes batailles : du 23 mai au 5 juin 1951, la bataille du Soyang également appelée le Massacre de mai, suivie d'une guerre de position. Du 5 au 10 octobre 1952, la bataille d'Arrow Head stoppe les attaques chinoises.

Le , , délégué permanent de l’URSS aux Nations-Unies, insère dans un discours un passage où il suggère une négociation sur la base d'un retour à la situation antérieure : un tel scénario avait débouché deux ans plus tôt sur la levée du blocus de Berlin. Dès le 10 juillet 1951, les délégués des deux camps se rencontrèrent à Kaesong, à proximité de l’ancienne ligne de démarcation. Mais il faudra attendre le après le décès de Staline pour que les négociations aboutissent à Panmunjeom, mettant fin à un conflit qui aura duré trois ans et causé au moins un million de morts selon la plupart des historiens occidentaux (plus de deux millions selon les Nord-Coréens). Le cessez-le-feu consacra le retour au "statu quo ante bellum" : en effet, la Zone coréenne démilitarisée entre les deux Corées (coupant le parallèle en diagonale, suivant une bande de de long sur de large) fait que la superficie de chacun des territoires des deux Corées seront sensiblement les mêmes qu'au début du conflit avec cependant un petit avantage pour le Sud, la ligne de front s'étant stabilisé un peu au-delà de l'ancienne frontière.

La proportion de pertes parmi les prisonniers de guerre sud-coréens et des Nations-Unies dans les camps nord-coréens et chinois atteint selon certaines études aux alentours de 43 %. Le caractère idéologique du conflit n’explique pas à lui seul cette extrême surmortalité, davantage conséquence des mauvaises conditions d’hygiène et de nutrition que des actions directes des geôliers, du moins après la première année de guerre. Les négociations sur les prisonniers de guerre furent très âpres et l'une des principales raisons de la lenteur des pourparlers de paix. Le , les Nations-Unies fournirent les noms de prisonniers sur captifs. Le désaccord dans les chiffres provient du fait que « soldats nord-coréens » étaient en réalité des citoyens du Sud enrôlés de force par le Nord. Il manquait aussi morts ou évadés. La liste communiste comprenait les noms de prisonniers, en contradiction avec le fait que la radio de Pyongyang, après 9 mois de guerre s'était vantée de détenir prisonniers. Mais au 18 décembre 1951, les forces communistes déclaraient détenir Sud-Coréens, Américains, 919 Britanniques, 234 Turcs, 40 Philippins, 10 Français, 6 Australiens, 4 Sud-Africains, 3 Japonais, 1 Canadien, 1 Grec et 1 Néerlandais.

Des Américains manquant, un tiers seulement avaient été retrouvés. Pas un seul des prisonniers dont les noms à un moment ou un autre avaient été cités dans les médias du bloc de l'Est n'apparaissait sur la liste. Sur les 110 noms communiqués à la Croix-Rouge, il n'en restait que 44 sur la liste. Plus grave, Sud-Coréens disparus avaient été « libérés sur les lignes de front » selon la Corée du Nord, embrigadés de force dans l'armée du Nord selon les Nations unies. Ce furent les méthodes de rapatriement des prisonniers aux mains des Nations unies qui freinèrent les négociations, la Chine et la Corée du Nord voulant que tous les prisonniers leur soient remis sans conditions tandis que les Nations unies prônaient la liberté de choix. Finalement, la deuxième solution fut adoptée, à la suite de compromis arrachés aux nations communistes qui pouvaient tenter de convaincre leurs citoyens de renoncer à leur choix. Sur les prisonniers qui avaient demandé de rester dans le camp occidental, renoncèrent à leur projet initial. Le retour des prisonniers se fit en 2 phases : l'opération « Petit Échange », en avril 1953, où les Nations unies restituèrent militaires et 416 civils nord-coréens tandis que le Nord rendait 471 Sud-Coréens, 149 Américains, 32 Britanniques, 15 Turcs, 6 Colombiens, 5 Australiens, 2 Canadiens, 1 Grec, 1 Sud-Africain, 1 Philippin et 1 Néerlandais. Puis l'opération « Grand Échange » consista en un échange massif de prisonniers après l'armistice : Nord-Coréens et Chinois furent rapatriés dans leurs pays respectifs tandis que Sud-Coréens, Américains et membres des autres contingents des Nations unies furent libérés.

Environ Chinois et Nord-Coréens choisirent de rester au Sud, tandis que 305 Sud-Coréens, un Britannique et vingt-et-un Américains restèrent dans le Nord (trois Américains changèrent d'avis après coup).

Bien que la géographie montagneuse de la Corée limite sérieusement l'utilisation des chars de combat et empêche les grandes offensives mécanisées, ceux-ci servent avec succès dans les deux camps dans l'appui de l’infanterie. Outre les T-34/85 qui firent forte impression, la Corée du Nord engagea des canons automoteurs SU-76.

Bien qu'initialement les forces aériennes américaines déclarent avoir détruit la majorité des blindés nord-coréens, les études sur les 256 chars T-34 nord-coréens perdus entre juillet et novembre 1950 montrent que seuls 63 d'entre eux l'ont été par l’aviation et 97 par des chars (32 par des M26 Pershing, 19 par des M46 Patton, 1 par un char M24 Chaffee et 45 par des M4A3E8 Sherman).

Le conflit qui éclata cinq ans après la fin de la Seconde Guerre mondiale fait apparaître combien la recherche de la supériorité aérienne devint une priorité absolue pour le commandement des Nations unies, c’est-à-dire des Américains. Il vit les premiers combats entre avions à réaction, alors que les avions à hélice vétérans de la précédente guerre furent largement utilisés. En effet, le rapport quantitatif des forces terrestres apparut, dès le début des opérations, favorable aux Sino-nord-coréens, de façon écrasante. Afin que ce grave déséquilibre n’entraînât pas un désastre pour les forces terrestres de l’ONU, il fut indispensable d’éviter que des avions nord-coréens ne puissent appuyer leurs troupes au sol. En fait, les forces aériennes nord-coréennes étaient constituées, pour une part importante, de pilotes soviétiques et polonais. La plupart des engagements en combat aérien contre les F-86 américains le fut par des MiG-15 , aux mains de pilotes soviétiques. Les escadrons soviétiques étaient relevés toutes les six semaines.

Le 64 OIAK ( corps aérien indépendant de chasse) de l'armée de l'air soviétique déployé depuis février 1950 à Shanghai contre les forces aériennes de Taïwan fut déployé dans la province de Liaoning et le 9 novembre 1950, une victoire et une perte au combat contre les forces aériennes américaines furent enregistrées. À cette situation militaire défavorable pour les forces aériennes de l'ONU (en fait américaines) s’ajouta une sévère contrainte politique. Il fut, en effet, interdit aux forces aériennes de l’ONU d’intervenir au sol comme en vol en territoire chinois, base de départ de nombreux raids « nord-coréens ». La recherche de la supériorité aérienne dut ainsi être conduite plus au sud, dans ce qui fut nommé la "MiG Alley" : par le biais de la destruction des 75 terrains militaires nord-coréens par la US Air Force, et par l’engagement en vol des forces aériennes ennemies. Même si les engagements furent fréquents dans cette « allée », les résultats des destructions en vol furent faibles. En décembre 1952, qui fut un mois particulièrement actif, MiG-15 furent aperçus par la chasse américaine, furent engagés (46 %), 27 seulement furent abattus, c’est-à-dire 1,5 % des avions engagés, la plupart du temps en combat tournoyant. De même, et sur l’ensemble de la guerre de Corée, les pertes d’appareils alliés en vol s’établirent à 44 avions détruits pour sorties, soit moins de la moitié du taux de destruction en vol constaté lors de la Seconde Guerre mondiale, malgré la pugnacité des pilotes du Nord. Ne pouvant intervenir au-dessus du territoire chinois, l’United States Air Force adopta rapidement la stratégie du "containment", c’est-à-dire de l’endiguement, le long du Yalou, dès lors que les terrains de Corée septentrionale étaient devenus inutilisables en raison des graves destructions qu'ils avaient subies. La souplesse d’emploi de l’arme aérienne autorisa le respect rigoureux de la règle d’or de l’aviation de combat occidentale : la poursuite d’un objectif unique. La concentration des moyens dans le temps et l’espace, la quasi-permanence des "sweeps" de chasse dans ce quadrilatère, la rapidité des interventions constituèrent les éléments les plus représentatifs de la stratégie aérienne occidentale.

Dans le même temps, le choix d'intensifier les campagnes de bombardement stratégique s'est traduit par la mort d'un nombre plus important de civils nord-coréens. L'US Air Force a, selon les statistiques officielles, largué de bombes durant les du conflit soit par mois (à comparer avec les larguées sur le Japon durant la guerre du Pacifique, les mensuelles durant l'ensemble de la Seconde Guerre mondiale et les mensuelles durant la guerre du Viêt Nam). Selon les Nord-Coréens, « plus de bombardiers ("chiffre cumulatif") ont mené plus de 250 raids aériens sur la seule ville de Pyongyang entre mi-juillet et mi-août 1951, les « cibles » allant des hôpitaux, aux maisons rurales avoisinant la ville. Le nord de la Corée, bien que ne faisant qu’un tiers de la superficie du Japon, a été bombardé selon eux 3,7 fois plus que ce dernier lors de la Seconde Guerre mondiale, soit de bombes (napalm et autres)». L'historien américain Bruce Cumings ajoute que les experts américains en Corée développèrent ainsi une nouvelle forme de guerre aérienne, sophistiquant des méthodes déjà utilisées contre le Japon impérial : « La guerre de Corée passe pour avoir été limitée, mais elle ressembla fort à la guerre aérienne contre le Japon impérial pendant la Seconde Guerre mondiale, et fut souvent menée par les mêmes responsables militaires américains. Si les attaques d’Hiroshima et de Nagasaki ont fait l’objet de nombreuses analyses, les bombardements incendiaires contre les villes japonaises et coréennes ont reçu beaucoup moins d’attention ».

Toujours selon la même source, Bruce Cumings observe que ces bombardements massifs ne correspondaient pas aux « bombardements de précision » invoqués par l'armée américaine : « Au sein de l’armée de l’air américaine, certains se délectaient des vertus de cette arme relativement nouvelle, introduite à la fin de la précédente guerre, se riant des protestations communistes et fourvoyant la presse en parlant de “bombardements de précision” ».

Si le conflit de Corée constitue un cas particulier, compte tenu des données politiques et géographiques, il convient toutefois de souligner que les chefs aériens, nourris des riches enseignements de la Seconde Guerre mondiale, surent s’adapter afin d’atteindre rapidement cet impératif de la supériorité aérienne, en complétant l’action de neutralisation des terrains ennemis en Corée du Nord par la fixation des forces aériennes soviétiques et chinoises dans un quadrilatère choisi par eux. Cette stratégie de l’abcès de fixation fonctionna. En effet, le taux de pertes en vol fut faible, inférieur de moitié à celui observé pendant la Seconde Guerre mondiale, et l’appui au sol des forces nord-coréennes, écrasantes numériquement, fut en conséquence insignifiant.

Les forces aériennes des Nations unies sont essentiellement issues des forces américaines. Trois armées aériennes (La 5, la et la Air Force) sont engagées sous le commandement général de la Far East Air Force. À cela s'ajoutera le groupe aéronaval, comprenant les appareils embarqués sur les 36 porte-avions qui participeront un moment ou un autre au conflit; à noter que le premier navire de ce type sur place fut de la Royal Navy. Environ 80 % des missions d'appui au sol au début de la guerre ont été assurés par des Chance Vought F4U Corsair.

Fin juillet 1953, à la conclusion de la guerre donc, les forces aériennes des Nations unies sont les suivantes : 128 B-26 Invader, 218 F-84 Thunderjet, et 297 F- Sabre ; des P-51 Mustang et F-80 Shooting Star ont également participé à la guerre en grand nombre, sans compter quelques chasseurs de nuit et les hélicoptères et, bien sûr, les quadrimoteurs B-29 basés au Japon ou à Okinawa. Plusieurs centaines d’avions embarqués ont également participé au conflit (F4U Corsair et F9F Panther, entre autres). Un total de 800 pilotes, soutenus par personnels au sol, servirent en Corée pour le compte des Nations unies. Il s’agit, encore une fois, principalement de personnel américain.

La Corée du Nord commence la guerre avec une force aérienne relativement modeste, composée de 239 appareils, tous à moteurs à pistons. On compte 129 Yaks, 43 Il-10S (version améliorée du célèbre Iliouchine Il-2 Sturmovik), ainsi que quelques Po-2 et autres appareils. Dans les premières semaines du conflit, l’armée de l’air nord-coréenne est largement surclassée par les forces des Nations unies, si bien que le , elle est réduite à seulement 65 avions. En fait, l’armée de l’air nord-coréenne ne joue elle-même qu’un rôle mineur durant le conflit. Ce sont les Chinois et surtout les Soviétiques qui assurent le gros des combats, sans que cela soit clairement explicité. En effet, s’il avait été publiquement reconnu que des pilotes et des machines soviétiques combattaient en Corée, les États-Unis auraient pu être conduits à déclarer la guerre à l’Union soviétique, malgré la menace nucléaire. À la fin de la guerre, environ 125 Mikoyan-Gourevitch MiG-15 sont directement sous le contrôle des Nord-Coréens.

Dès les derniers jours du mois de juin 1950, la force aérienne chinoise déploie sa première brigade aérienne en Corée du Nord. Elle se compose de :
Le septembre 1951, on estime que pas moins de 525 MiG-15 servaient sous les cocardes nord-coréennes. Début juin 1952, les forces aériennes de la Chine populaire sont de l’ordre de avions, dont un millier de chasseurs. Le 31 juillet 1953, la Chine populaire possède encore sur le théâtre coréen neuf corps de chasseurs (près de 500 MiG-15) et deux corps de bombardiers (54 Tu-2). Malgré des effectifs qui apparaissent donc comme non négligeables, les forces aériennes communistes ne furent jamais en mesure de soutenir efficacement leur armée de terre et encore moins d'agir stratégiquement sur les arrières américains.

Les Soviétiques fournirent, avec les Chinois, une grande partie de l’effort de guerre aérien. En effet, les pilotes nord-coréens étaient loin d’être aussi bien formés au maniement des fameux MiG-15 que les affrontements le laissaient entendre. À plusieurs reprises, des pilotes occidentaux rapportèrent avoir pu clairement apercevoir des pilotes de MiG-15 à la carrure trop forte pour des Asiatiques, des Russes probablement. Le , Staline promit d’envoyer à la Corée du Nord du matériel militaire et de transférer pas moins de 16 régiments de l’aviation soviétique afin de garantir la protection des territoires chinois et nord-coréen. Ce sont près de Soviétiques qui servirent, sur trois années, en Corée et en Chine. L'historiographie soviétique n'a pas tardé à reconnaître et revendiquer cette participation destinée à accomplir son devoir internationaliste. Il faut aussi compter avec une intervention terrestre de la Mongolie extérieure : un pays qui fut le deuxième pays socialiste par ordre chronologique de formation (1920). Cela ajouta à la qualité supérieure des pilotes chinois et surtout soviétiques qui fit de l’Armée de l’Air nord-coréenne un adversaire redoutable pour les forces de l’ONU.

Cela est d'autant plus vrai que, avant la mise en service du F-86 Sabre, les États-Unis et leurs alliés ne disposaient d’aucun avion capable de rivaliser avec le MiG-15, le meilleur chasseur du monde à cette époque. Afin de pouvoir combattre plus efficacement le MiG-15, les États-Unis tentèrent par tous les moyens d’en obtenir un exemplaire intact. Faute de défection dans les rangs communistes, ils allèrent jusqu’à offrir en avril 1953 une récompense de dollars pour un appareil intact. Cependant, aucun MiG-15 ne se présenta avant la fin de la guerre et ce n’est qu’en septembre 1953 qu’un appareil fut livré par un déserteur, qui affirma ne pas être au courant de la récompense promise.

Au , les Nations unies revendiquent 391 avions détruits ou endommagés au cours de la première année de guerre. Les pertes sont les suivantes : 188 chasseurs, 33 bombardiers, 9 transports et 17 divers. Ce jour, -86 Sabre sont déployés en Corée et le nombre total de MiG-15 disponibles pour les communistes est de l’ordre de 445. Le juillet de la même année, les Nations unies reconnaissent la perte de 246 appareils (surtout due à la DCA selon eux), 857 morts et disparus. Plus de 200 MiG sont revendiqués comme ayant été détruits. En avril 1952, les Nations unies rapportent 243 avions détruits et 290 avions endommagés en un mois. Un total de 771 avions auraient été détruits par la DCA nord-coréenne du au . Les Américains affirment de plus que le rapport MiG détruits pour F-86 détruits est de onze pour un. Le , les statistiques suivantes sont publiées par les Nations unies :


Ces chiffres sont à considérer avec précaution tant les annonces de victoires par rapport aux pertes subies par les deux camps sont discordantes. Alors que l'USAF annonce avoir perdu 16 bombardiers B-29 au combat, les pilotes soviétiques revendiquent 66 destructions en combat aérien de cet appareil sans compter les revendications chinoises et nord-coréennes. La (FEAF) a perdu un total de avions (accidents compris) et a eu hommes tués et 306 blessés au cours de la guerre. Trente hommes de la FEAF qui avaient été portés disparus ont finalement été renvoyés au contrôle militaire, 214 prisonniers de guerre ont été rapatriés sous les termes de l'accord d'armistice, tandis que 35 hommes étaient toujours détenus en captivité en juin 1954. À partir du moment où les forces communistes refluent, l’essentiel des combats aériens entre les chasseurs des Nations unies et des communistes se dérouleront dans la zone connue sous le nom de "MiG Alley". Opérant depuis des bases situées sur le territoire chinois, les MiG-15 parvinrent à s’opposer avec succès aux forces occidentales, forçant notamment les bombardiers B-29 à ne plus opérer que de nuit. Même lorsque la situation au sol était largement en leur défaveur, les pilotes communistes continuèrent à effectuer des sorties pour contester la supériorité aérienne des Nations unies.

La zone de la "MiG Alley "correspond à tout ce qui se trouve à l’ouest du triangle formé par les villes de Huichon, Changju et (en Corée du Nord actuelle). Les avions occidentaux avaient l’interdiction de franchir la frontière chinoise pour attaquer les bases des escadrons de MiG mais, dans le feu de l’action, plusieurs avions franchirent effectivement cette frontière.

En tout, 40 % du potentiel industriel du pays auraient été détruits. La dramatisation de ce rapport insiste sur les destructions causées aux écoles, hôpitaux et maisons alors que les combats firent des dégâts similaires au sud, ce qui n’est pas mentionné.

La puissance aérienne joua un rôle clé : pour la première fois dans l’histoire, on fit usage en conditions opérationnelles d’avions de combat à réaction (si l'on excepte le cas du Me 262 durant la Seconde Guerre mondiale). La Chine était devenue une puissance aérienne et militaire majeure. La moitié de ses chasseurs était des MiG-15 construits par les Soviétiques, avions considérés à juste titre comme étant les meilleurs du monde. Opérant à partir de bases situées en Mandchourie et ne s’aventurant que très rarement au-dessus des lignes de l’ONU, les MiG-15 menacèrent néanmoins la suprématie aérienne de cette dernière, en particulier au-dessus de la "MiG Alley". Il fallut attendre que les États-Unis produisent les F-86 Sabre pour que les forces de l’ONU aient enfin à disposition un avion capable de rivaliser avec le MiG-15.

Dans une note datée du 21 décembre 1951, le secrétaire d'État américain à la Défense, Robert Lovett, demanda au comité interarmées des chefs d'état-major ("Joint Chiefs of Staff") de fournir des directives « pour l'emploi d'armes chimiques et bactériologiques. » De 1938 à 1945, confrontée au même problème de l'énorme supériorité numérique chinoise, l'armée impériale japonaise avait employé à maintes reprises ces armes contre les troupes ennemies et les populations civiles, notamment lors de la bataille de Changde. Les Américains avaient par la suite soigneusement récupéré les résultats des travaux de Shirō Ishii en échange d'une exonération de poursuite devant le Tribunal de Tokyo, accordée à tous les membres de ses unités de recherche par Douglas MacArthur. Selon la Chine et la Corée du Nord, ces armes auraient été utilisées par les Américains sur une grande échelle dès le début de l'année 1952. L'utilisation de l'arme biologique fut mise en cause, à tort, le lorsque le ministre des Affaires étrangères nord-coréen, Pak Hon-yong, accusa officiellement les Américains d’avoir répandu en Corée du Nord des « insectes-vecteurs » diffusant la peste, le choléra et « d’autres maladies ». Deux jours plus tard, Zhou Enlai porta la même accusation et, le 8 mars, il affirma qu’entre le 29 février et le 5 mars des avions américains avaient répandu à soixante-huit reprises des insectes porteurs de germes pathogènes sur la Mandchourie.

Le 12 mars 1952, le secrétaire d’État américain Dean Acheson demanda officiellement au Comité international de la Croix-Rouge (CICR) de mener une enquête dans les régions signalées par les Nord-Coréens et les Chinois. Le CICR présenta sa requête le même jour à la Corée du Nord et à la Chine, puis de nouveau le 28 mars, le 31 mars et le 10 avril. Ses démarches ne reçurent jamais de réponse de la part des autorités chinoises et nord-coréennes. Les États-Unis soumirent alors au Conseil de sécurité des Nations unies un projet de résolution en vertu de laquelle le CICR serait invité à mener des investigations en Chine et en Corée du Nord. Malgré dix voix sur onze en faveur de la motion américaine, le projet de résolution ne put être adopté, l'URSS y mettant son veto. Après une nouvelle initiative américaine à l’ONU, en avril 1953, elle se déclara prête à retirer ses accusations, à condition que les États-Unis, de leur côté, renoncent à demander une investigation. Dès lors, il paraissait clair que les allégations de la Corée du Nord reposaient sur des preuves forgées de toutes pièces. En effet, des documents soviétiques publiés en 1998 évoquent une mise en scène macabre organisée par les Nord-Coréens et leurs conseillers soviétiques. Ainsi, le 18 avril 1953, le lieutenant-général V. N. Razouvaïev, ambassadeur soviétique en Corée du Nord, informa Beria, membre du Politburo et chef de la Sécurité d'État, le futur KGB, qu’en février/mars 1952, « en collaboration avec des conseillers soviétiques, un plan d’action avait été imaginé par le ministère de la Santé nord-coréen) » et que, par la suite, les mesures suivantes furent prises : mise en quarantaine de régions qu’on prétendait infectées de la peste ; enfouissement de cadavres dans des fosses communes, puis révélation de ces charniers à la presse internationale ; envoi à Pékin de « matériel » en vue de son exposition, avant l’arrivée prévue des deux commissions internationales autorisées à l'examiner.

Le 2 mai 1953, le Kremlin chargea l’ambassadeur soviétique à Pékin, V. V. Kouznetsov, de transmettre le message suivant à Mao : Et, à l’intention du chargé d’affaires soviétique en Corée du Nord : 

La thèse chinoise et nord-coréenne fut reprise en 1998 par deux historiens canadiens, Stephen Endicott et Edward Hagerman, professeurs à l'Université York (Toronto) et auteurs de "The United States and Biological Warfare. Secrets from the Early Cold War and Korea" (Indiana University Press, Bloomington et Indianapolis, 1998), puis de nouveau dans un article publié dans la collection "Manières de voir" du "Monde diplomatique" (août-septembre 2003). Dans cet article, Endicott et Hagerman disent s'être appuyés sur des archives américaines « dévoilées parcimonieusement » (cf. plus bas le commentaire du professeur Ed Regis) et sur des documents provenant des archives gouvernementales et militaires de Pékin. Ils citent par ailleurs un extrait d’une lettre du 12 avril 1977 envoyée à Endicott par John Burton, chef démissionnaire du département australien des Affaires étrangères en 1952 et membre de la "International Scientific Commission" ayant examiné le « matériel » bactériologique fourni par les Chinois (cf. plus haut le rapport de Razouvaïev à Beria). 

Les documents d'archives américains et les témoignages recueillis par les professeurs Endicott et Hagerman font état d'un programme complet d'armes biologiques : « bombes à plumes », porteuses de spores du charbon céréalier, aérosols provoquant l'infection des voies respiratoires, « insectes vecteurs » pouvant diffuser le choléra, la dysenterie, la typhoïde et le botulisme. Ces armes devaient être opérationnelles pour le juillet 1954, « avec des capacités […] susceptibles d’être mises en œuvre dès le mois de mars 1952 ». se demandent MM. Endicott et Hagerman. La réponse est positive, disent-ils, « selon des documents conservés dans les archives gouvernementales et militaires chinoises » et selon le rapport d’un expert canadien qui concluait que, « malgré quelques anomalies, les indices chinois étaient fiables. » MM. Endicott et Hagerman admettent cependant que « parmi les réfutations les mieux connues » des accusations chinoises et nord-coréennes figure « un rapport rédigé par trois savants canadiens à la demande du gouvernement américain. » Dans un article paru le dans le "New York Times", Ed Regis, professeur à la Rutgers University et auteur de "The Biology of Doom: The History of America's Secret Germ Warfare Project" (New York: Henry Holt and Company, 1999), souligne que, dans leurs travaux, Endicott et Hagerman reconnaissent implicitement que vingt années de recherches ne leur ont pas permis de découvrir un seul document d’archives américain qui prouverait une utilisation quelconque de l'arme bactériologique en Corée et en Chine. Ils acceptent les documents de circonstance fournis par les Chinois et les Nord-Coréens sans la moindre analyse quant à leur fiabilité, dit le professeur Regis, alors qu'on sait pertinemment que les Chinois et les Nord-Coréens réécrivaient l’histoire dans un but propagandiste, et qu’ils avaient les moyens, les motifs et l’occasion de forger des preuves. Par conséquent, conclut-il, l’allégation extrêmement contestable d’Endicott/Hagerman (« "their extraordinary dubious claim" ») équivaut en fait à une disculpation de l’accusé. Les historiens ont mis en évidence que la guerre bactériologique américaine n'a jamais existé et qu'elle a été montée de toutes pièces par le journaliste australien Wilfred Burchett, qui était un agent d'influence travaillant pour le compte de l'URSS (voir la maîtrise d'histoire de Bertrand Maricot, sous la direction de J.-F. Sirinelli et I. Yannakakis, "La guerre bactériologique en Corée et les intellectuels français", Lille 3, 199 pages, 1993). Le journaliste français Pierre Daix a démontré dès 1976, dans son ouvrage "J'ai cru au matin", comment l'Australien avait construit cette affaire. Peut-être même d'après Ivan Cadeau qui donne raison à la thèse d'un montage communiste, des prisonniers de guerre américains ont-ils été torturés par les Sino-Coréens pour les obliger à avouer le forfait. Malgré tout Ivan Cadeau relève que et que . En 1950 le secrétaire de la Défense reconnaît que les États-Unis mènent des recherches sur les armes bactériologiques ; le le général MacAuliffe déclare que . D'autres officiels et militaires américains avaient affirmé . Et autre fait qui nuance la version du montage communiste délibéré, les Sino-Coréens et leurs alliés exploitaient les complicités américaines d'après-guerre avec les criminels de guerre de l'Unité 731 de l'armée impériale japonaise et de son chef, qui procédèrent à des essais bactériologiques en 1939 contre les troupes soviétiques, puis à la fin de la guerre contre les populations chinoises.

Au-delà de « l'allégation extrêmement contestable » (Ed Regis) d'Endicott et Haverman, le napalm fut, selon l'historien américain , utilisé sur une plus grande échelle que pendant la guerre du Viêt Nam et les dommages furent plus importants du fait de la plus grande concentration de la population coréenne :
« La ville industrielle de Hungnam fut la cible d’une attaque majeure le 31 juillet 1950, au cours de laquelle de bombes furent lâchées à travers les nuages. Les flammes s’élevèrent jusqu’à une centaine de mètres. L’armée américaine largua de bombes sur la Corée du Nord le 12 août, un tonnage qui aurait requis une flotte de 250 B-17 pendant la Seconde Guerre mondiale. Fin août, les formations de B-29 déversaient de bombes par jour sur le Nord. Ce tonnage consistait en grande partie en napalm pur. De juin à fin octobre 1950, les B-29 déversèrent 3,2 millions de litres de napalm. ».

Cette guerre meurtrière et fratricide, qui n'amena quasiment aucun changement territorial, a laissé l’impression d’un suicide national dont le courant historiographique dominant actuellement en Occident et en Russie attribue la principale responsabilité à la Corée du Nord. Avant l’ouverture des archives du Kremlin, des historiens avaient pu tenir pour responsables des puissances extérieures, les États-Unis de Truman mais surtout l’URSS de Staline, qui auraient fait dévier une simple opposition idéologique locale (communisme contre capitalisme) en une guerre ouverte. Or, les documents d’archives soviétiques, bien que contestés par les autorités nord-coréennes, attestent au contraire que la Corée du Nord a envisagé de longue date l'offensive du 25 juin 1950, en concertation avec les Soviétiques, qui ne donnèrent « un aval peu enthousiaste [qu'] à la suite de sollicitations permanentes ». Par conséquent, d’après l’état actuel de la documentation, « l’hypothèse (…) selon laquelle la guerre de Corée aurait été une initiative de Staline est incorrecte ».

Heo Man-Ho souligne cependant que l'initiative nord-coréenne ne doit pas occulter les préparatifs, à ce stade bien moins avancés, de la Corée du Sud, de même que les nombreux incidents de frontières qui auraient causé près de morts avant la date du 25 juin 1950. Raymond Aron parle de l’« accident coréen » de la diplomatie américaine, pour mettre en évidence que celle-ci porte une part de « responsabilité "politique" » : le discours de Dean Acheson aurait transmis au gouvernement soviétique un message prêtant à une interprétation erronée et, par ailleurs, les Américains, en retirant leurs troupes de Corée du Sud, auraient créé un vide que la Corée du Nord était tentée de remplir par une agression « au sens le plus cru du terme ». Pendant la guerre, des massacres de civils et de prisonniers se produisirent de part et d’autre par exemple le massacre de Geochang et celui de Sancheong et Hamyang.

Des dizaines de milliers de Sud-Coréens et des milliers d'Occidentaux fait prisonniers par le Nord sont, à ce jour, toujours portés disparus. Les canadiens, plus tard libérés, ont été traités durement et ont été soumis à une tentative de lavage de cerveau dans le but de changer leurs opinions politiques, la Corée du Nord et la République populaire de Chine n'étant pas signataires de la Convention de Genève de 1949. La proportion de pertes chez les prisonniers de guerre dans les camps nord-coréens et chinois, selon certaines études, atteint 43 %. Ainsi, les Sud-Coréens et les Américains font état de nombreux crimes de guerre commis par les Nord-Coréens. Des témoignages et documents attestent que, lors de leur offensive, les services nord-coréens « épuraient » des villes occupées en fusillant les fonctionnaires et les « ennemis de classe » restés sur place, et que plusieurs dizaines (au minimum) de soldats sud-coréens et américains furent exécutés après leur capture notamment lors du massacre de la colline 303. Par ailleurs, lors de la contre-offensive des Nations unies en septembre 1950, ils incendièrent la prison de Sachon dans laquelle étaient enfermés 280 policiers, fonctionnaires et propriétaires terriens sud-coréens. À Anui, Mokpo, Kongju, Hamyang et Chongju, on trouva des charniers contenant plusieurs centaines de corps, parmi lesquels des femmes et des enfants. Près du terrain d'aviation de Taejon, 500 soldats sud-coréens, les mains liées derrière le dos, furent tués d'une balle dans la tête. Entre le 24 septembre et le 4 octobre, toujours dans la région de Taejon, on découvrit les cadavres de à civils sud-coréens assassinés, ainsi que ceux de 40 militaires américains. Le massacre des sympathisants communistes par les forces du Sud, longtemps attribué à la Corée du Nord, fait entre et plus de .

Les Nord-Coréens de leur côté accusèrent les forces des Nations unies - et plus particulièrement les Américains - de crimes similaires. Ainsi, des documents d'archives américains cités par la BBC prouvent que des soldats américains tuèrent un « nombre non confirmé » de réfugiés à Nogun-Ri, en juillet 1950. Des prisonniers, comme le Nord-Coréen Ri In-mo, restèrent emprisonnés au Sud pendant plus de trente-quatre ans après l'armistice, où ils furent soumis à un programme de « conversion » comportant le recours à la torture dans le but qu'ils renient leurs convictions communistes : beaucoup de prisonniers sont morts du fait des mauvais traitements auxquels ils ont été soumis (coups de bâton, ingestion forcée d’eau par les narines, brûlures, électrocution…). Il s'agit "a priori" d'éliminer la menace posée par les infiltrations de soldats nord-coréens au sein des groupes de réfugiés. Les préjugés racistes envers les « Gooks » de la part des Américains en proie à la mauvaise surprise d'affronter à leur arrivée des armées asiatiques combatives et efficaces dans un pays pauvre aurait, selon Yvan Cadeau, sa part dans les crimes. L'enjeu de la guerre de Corée – la réunification de la péninsule dans un contexte de tensions entre superpuissances - et la difficulté pratique à mener un travail de recherche historique qui confronterait les sources directes, tant au Nord qu’au Sud, doivent cependant conduire à une certaine prudence dans les prises de position, notamment en ce qui concerne la question des responsabilités - sans pour autant récuser l'évidence documentaire, car « le renoncement de l'historien à son métier risque de conduire à la pire utilisation idéologique de l'histoire ».

Avec environ un million et demi de morts et une situation militaire inchangée (la tension reste toujours vive entre le Nord et le Sud), le pays a subi la pire destruction matérielle et humaine de son histoire. Ce conflit fut le premier d'importance internationale après la fin de la Seconde Guerre mondiale. Il a aussi constitué la première intervention armée de l'ONU dans un conflit ouvert. Le coût du conflit fut estimé pour les seuls États-Unis à environ de dollars de l'époque soit environ de dollars valeur 2010.

Au total, l'armée sud-coréenne a perdu soldats, celle du Nord au moins . Les forces de l'ONU comptabilisent morts, essentiellement des Américains. Les pertes chinoises sont estimées à tués. 315 militaires soviétiques sont morts dans ce conflit.

Mais les pertes civiles sont plus considérables encore : sur les d'habitants de la péninsule. L'ampleur des pertes civiles s'explique par les bombardements massifs. Selon les statistiques officielles américaines, l'US Air Force a déversé au moins de bombes et l'historien américain Bruce Cumings a calculé que de litres de napalm avaient été utilisés par celle-ci durant la guerre de Corée.

L'armistice ne mit pas fin aux incidents de frontières et raids de commandos venus du Nord attaquer le Sud et la tension reste vive entre les deux Corées. La guerre du Crabe depuis les années 1990 a occasionné plusieurs batailles navales. Le 13 juin 2000, le leader nord-coréen Kim Jong-il - fils et successeur de Kim Il-sung - et le président sud-coréen Kim Dae-Jung se rencontrent au cours du premier sommet jamais organisé entre les dirigeants des deux Corées : une déclaration commune est adoptée, les deux pays s'engageant à rechercher la paix et travailler à une éventuelle réunification. À l'issue du second sommet inter-coréen des chefs d'État le 4 octobre 2007, Kim Jong-il et le président sud-coréen Roh Moo-hyun s'engagent en faveur d'un accord de paix dans la péninsule coréenne. Cependant en 2009 et 2010, des accrochages maritimes ont eu lieu le long de la « Northern Limit Line » (NLL), prouvant une nouvelle fois que les conflits inter-coréens sont toujours d'actualité. Le , dans le cadre de la crise nucléaire nord coréenne, la Corée du Nord déclare ne plus être liée par l'armistice qui a fait cesser les combats de la guerre de Corée.

Fin mars 2013, la Corée du Nord (désormais gouvernée par Kim Jong-un, fils de Kim Jong-il et petit-fils de Kim Il-sung) met fin aux traités de paix avec la Corée du Sud et annonce être de nouveau en état de guerre.

Fin mai 2013, Pyongyang propose à Séoul de signer un accord de paix pour officiellement mettre fin à la guerre entre les deux États. Cependant, d'un point de vue légal de la part de chacune des deux Corée, la « guerre de Corée » n'était pas une guerre au sens du droit international mais un conflit interne, chacun des deux gouvernement se considérant comme l'unique représentant légal du pays et une guerre supposant la confrontation entre deux États. Ces trois ans de combat sont donc légalement une opération, tant pour le Nord que pour le Sud, visant à restaurer l'autorité du gouvernement dans un territoire rebelle et donc dans tout le pays (c'est-à-dire toute la péninsule, nord et sud), type de conflits à la fin desquels n'a jamais été signé d'accord de paix.

Engagée dans la guerre d'Indochine, la France apporta une participation réduite mais néanmoins marquante à l'appel des Nations unies. Cela se traduisit par le détachement de l'aviso colonial "La Grandière" chargé des missions de protection des convois maritimes participant au renfort du périmètre de Pusan et au débarquement de Incheon, ainsi que par l'envoi de hommes formant le bataillon français de l'ONU, intégré, avec des renforts coréens et deux bataillons américains, dans les effectifs du régiment de la « Indianhead » Infantry Division. Cette division s'est illustrée dans plusieurs faits d'armes qui lui ont valu plusieurs citations. À l'issue de la guerre, le bataillon comptait 287 tués, dont 18 Coréens, blessés, 12 prisonniers et 7 disparus.






</doc>
<doc id="15750" url="https://fr.wikipedia.org/wiki?curid=15750" title="Versailles">
Versailles

Versailles (prononcer ) est une commune française, chef-lieu du département des Yvelines dans la région Île-de-France, mondialement connue pour son château ainsi que pour ses jardins, sites classés sous l’égide de l'UNESCO dans la liste du patrimoine mondial de l’humanité. D'après le recensement de 2012, la population de la ville est de .

Ville nouvelle, créée par la volonté du roi Louis XIV, elle fut le siège du pouvoir politique français pendant un siècle, de 1682 à 1789, avant de devenir le berceau de la Révolution française. Après avoir perdu son statut de ville royale, elle devint le chef-lieu d’un département, celui de Seine-et-Oise en 1790 puis celui des Yvelines en 1968, et d'un évêché. Versailles est aussi historiquement connue pour avoir été le lieu de signature de nombreux traités comme le Traité de Paris (1783), qui termina la Guerre d'indépendance américaine et le traité de Versailles signé à l'issue de la Première Guerre mondiale.

Située dans la banlieue ouest de la capitale française, à du centre de Paris, Versailles est au une ville résidentielle aisée avec une économie principalement tertiaire et constitue une destination touristique internationale de premier plan. C'est toujours à Versailles que se réunissent en congrès au château, députés et sénateurs, pour y ratifier toute modification de la constitution. Siège de l'Université Versailles-Saint-Quentin (UVSQ) et accueillant de nombreuses entreprises, la ville fait partie du projet de pôle de compétitivité technologique Paris-Saclay.
La commune de Versailles se trouve à au sud-ouest de la cathédrale Notre-Dame de Paris. Bien qu'elle en soit le chef-lieu, elle est totalement excentrée par rapport au département des Yvelines, puisqu'elle est en fait limitrophe du département des Hauts-de-Seine.

Les communes limitrophes sont Vaucresson, Marnes-la-Coquette et Ville-d'Avray au nord-est (toutes trois communes des Hauts-de-Seine), Viroflay à l'est, Vélizy-Villacoublay et Jouy-en-Josas au sud-est, Buc au sud, Guyancourt au sud-ouest, Saint-Cyr-l'École à l'ouest, Bailly et Rocquencourt au nord-ouest et Le Chesnay au nord.

Versailles se trouve dans une vaste cuvette aux sols sableux à base argileuse, mais aussi marno-calcaires à l'endroit du grand bassin du château, ce qui explique le caractère marécageux du lieu, à l'origine. La cuvette proprement dite est située entre 100 et d'altitude. Elle est entourée de hauteurs boisées culminant à près de : au sud le plateau de Satory, recouvert de limons des plateaux, à l'est la forêt de Meudon et le plateau de Vélizy, au nord la forêt de Fausses-Reposes. La commune est prolongée à l'ouest par la plaine de Versailles. Le relief a été aplani au moment de l'édification du château de Versailles. Les dépressions, occupées par des étangs aujourd'hui disparus ou transformés en bassins, ont été comblées. La butte Montbauron, culminant à , est un relief isolé formant une éminence au centre de la ville.

Ce site ne dispose d'aucun cours d'eau important, caractéristique assez rare pour une ville de cette importance. Il est drainé par deux ruisseaux, le ru de Marivel, qui coule vers l'est et rejoint directement la Seine à Sèvres, et le ru de Gally qui rejoint vers l'ouest la Mauldre à Beynes. Ces cours d'eau ont été modifiés par l'urbanisation : le cours du ru de Gally a été amputé lors de la construction du château et du creusement du Grand Canal dont il est l’émissaire naturel tandis que le ru de Marivel est aujourd'hui devenu un égout entièrement couvert.

Versailles connaît un climat océanique dégradé typique du centre du bassin parisien.

Les précipitations se répartissent tout au long de l'année, s'accentuant au printemps et en automne. En moyenne, il tombe de pluie par an.

Sous l'influence de l'océan, les amplitudes thermiques annuelles et journalières sont modérées mais souvent nuancées par l'influence continentale. Avec une moyenne de , le mois de janvier est le plus froid ; août affiche la température moyenne la plus élevée avec .

L'ensoleillement faible ne dépasse pas les 1664 heures par an et seuls cinquante jours en moyenne connaissent un ciel totalement dégagé.

La desserte routière est assurée depuis l'origine par la route de Paris à Chartres , devenue la RN 10, déclassée en RD 10 de Viroflay à Trappes. Dans Versailles, cette route aboutit à la place d'Armes devant le château, sous le nom d'avenue de Paris, et continue vers l'ouest à la lisière sud du parc de Versailles passant entre le château et la pièce d'eau des Suisses.
Les accès à la ville sont assurés de nos jours par une série de voies à caractéristiques autoroutières. Ce sont :

Sur le plan ferroviaire, la commune est desservie par trois lignes de voyageurs, dont les trois principales gares sont :

Plusieurs pistes cyclables ont été ouvertes depuis quelques années, comme sur le boulevard de la Reine ou du Roi, ainsi que sur les grandes avenues, et notamment avenue de Paris, de Saint-Cloud et des États-Unis. Versailles dispose aujourd'hui de de pistes cyclables. Il faut ajouter à cela l'aménagement de la ceinture verte. Une piste cyclable de qui entoure Versailles en passant par son domaine forestier. Enfin, Versailles dispose maintenant de plusieurs dizaines de kilomètres de voies de zone 30 et par conséquent de rues à sens unique avec cyclistes à contre-sens autorisé.

La commune est desservie par :

Le plan de la ville s'articule autour de la place d'Armes, située devant le château, et d'où rayonnent trois larges avenues bordées de platanes et disposées en éventail : l'avenue de Paris au centre, dans l'axe du château, l'avenue de Saint-Cloud au nord et l'avenue de Sceaux symétriquement au sud (cette dernière étant interrompue par les anciens bassins des Francine et des étangs Gobert qui alimentaient les fontaines du château). Entre ces avenues se trouvent les bâtiments des Écuries royales. De part et d'autre de cet axe central sont les deux quartiers créés sous Louis XIV, le quartier Notre-Dame et le quartier Saint-Louis, organisés en damier autour d'un « carré » central (respectivement la place du Marché-Notre-Dame et le carré Saint-Louis).

Le château coupe le territoire communal en deux, avec à l'est, la ville proprement dite, et à l'ouest, le domaine de Versailles et la campagne, si bien que, le territoire de la cité, pourtant fortement urbanisé, compte plus de 50 % d'espaces verts ou naturels. Outre les jardins situés dans la ville, ces espaces comprennent le parc du château de Versailles qui occupe la partie ouest de la commune, la forêt de Versailles dans la partie sud, relativement morcelée, et une frange de la forêt de Fausses-Reposes vers la limite est. La commune compte au total 350 hectares de forêts.
La partie urbanisée de Versailles comprend huit quartiers :

La ville de Versailles, née de la volonté d'un roi, est une création artificielle. Il ne subsiste rien du village ancien qui a été détruit pour permettre l'aménagement de la ville. Versailles était au , selon les normes de l'époque, une ville très moderne, . Excepté pour les quartiers de Notre-Dame, Saint-Louis et Montbauron, les autres parties de l'actuelle ville possèdent un tissu urbain plus récent, datant d'à partir de la seconde moitié du .

Aujourd'hui, la commune est soumise à des contraintes d'urbanisme particulières, dues à l'existence d'un « secteur sauvegardé » qui couvre une grande partie des quartiers Saint-Louis et Notre-Dame. Par ailleurs, deux tiers de la commune sont gérés par des organismes étatiques (Établissement public du musée et du domaine national de Versailles, Office national des forêts, armée), si bien que la municipalité n'a la pleine responsabilité de la politique d'urbanisme que sur 728 hectares (sur ha).

En juin 2014, le tribunal administratif de Versailles a jugé la ville responsable de l'abandon du projet initial. En octobre 2014, c'est la chambre régionale des comptes qui pointait le manque de transparence et le défaut de provision, dans cette opération en cours.

La commune comprend un site recensé dans la base de données du ministère de l'Écologie relative aux sites et sols pollués (ou potentiellement pollués) appelant une action des pouvoirs publics, à titre préventif ou curatif (BASOL). Il s'agit de l'ancienne usine à gaz de Versailles, mise en service en 1875 et fermée en 1954, dont l'emplacement est partiellement occupé depuis par les installations du centre d'études et de formation de Gaz de France. Le site, situé dans une zone urbanisée, a été dépollué en 2003 à l'occasion de la construction d'un parc de stationnement souterrain et n'est plus l'objet de surveillance particulière.

La ville de Versailles compte cinq cimetières :

Le nom de la localité est attesté sous les formes "Versalliis" en 1038, "Versalias" en 1075, "Versliæ" en 1095, "Versaliae" en 1308, Versailles en 1370.

Les plus anciennes mentions de "Versailles" étant médiévales, il est impossible de savoir si cette formation toponymique est antérieure. Cependant, comme "Versailles" est généralement un microtoponyme, il est probablement peu ancien. Il remonte ultimement à un type gallo-roman , basé sur le radical , de "versus", terme latin désignant le « versant ». Il est suivi du suffixe .

Les formes latines sont des latinisations de l'ancien français, destinées à s'insérer dans des chartes, pouillés, cartulaires rédigés en latin, langue de l'église et de l'administration jusqu'au .

Il faut sans doute y voir plutôt un dérivé roman de "verser" au sens de « renverser », terme décrivant l'action de la charrue qui « renverse » la terre, d'où l'ancien français "versa(i)l" « terres défrichées, labourées » ou éventuellement le « sillon résultant du labourage », dans lequel le suffixe "-a(i)l" a fait place à "-aille" suffixe collectif ou péjoratif. L'ancien français "versail" avait aussi le sens d'« endroit uni et débarrassé des mauvaises herbes pour servir de place de tir à l´arbalète ».

D'autres tentatives ont été faites pour attribuer au nom de lieu "Versailles", une autre origine, mais elles sont mal étayées.

Le toponyme aurait pour base une hypothétique racine gauloise "*sigl" « marais », le premier élément serait alors le gaulois "ver(o)" « au-dessus, sur, super- », d'où le sens global d'« au-dessus du marais », cette hypothèse n'a pas été reprise par les principaux toponymistes et les spécialistes modernes du gaulois. C'est en effet indémontrable car aucune forme ancienne ne vient étayer cette hypothèse, de plus le gaulois "*sigl" n'est pas attesté et semble être une création "ad hoc" de François Falc'hun à partir du brittonique dont il est spécialiste.

C'est pourquoi certains ont voulu comparer avec des toponymes dont la forme moderne ressemble apparemment à Versailles et qui avoisineraient des marais : Verseilles-le-Bas (Haute-Marne), Verseuil (Marne), Versillat (Creuse), Versailleux (Ain), etc. localités entourées de marais. Cependant les formes anciennes de ces différents toponymes ne permettent pas ce rapprochement avec les "Versailles", en effet, les "Verseilles" ont des formes anciennes du type "Vercilles" (en 1234) et se rattachent à Vercel, dont le radical est et non pas , Versillat est un ancien "*Verciliacum" et Versailleux ("Vassaleu" 1191, "Vassailliacus" 1258), également un toponyme en "-acum", dont le premier élément est radicalement différent puisqu'il s'agit du nom de personne gaulois "Vassalus", la forme moderne étant justement liée à l'attraction d'un "Versailles".

À l'époque de sa création au , la cité nouvelle, qui correspond à l'actuel quartier Notre-Dame, fut parfois appelée "La Villeneuve Saint-Louis" en hommage à son créateur, mais c'est finalement le nom du château, Versailles, qui a prévalu.

Le site de Versailles n'était probablement pas habité à l'époque préhistorique dans la mesure où on n'y a retrouvé aucun vestige archéologique. Cependant comme les terrains ont été fortement bouleversés lors des travaux de construction du château et de l'aménagement du parc, certaines traces ont pu être détruites. Dans les environs immédiats, des allées couvertes de l'époque néolithique, appartenant à la civilisation « Seine-et-Marne-Oise » ont été retrouvées à L'Étang-la-Ville et à Marly-le-Roi.

Au temps des Gallo-Romains, le site se trouvait sur le tracé de la voie menant de Paris à la Normandie via Villepreux et Neauphle-le-Château.

La première mention de Versailles est cité dans une charte, datée de l'an 1038, de l'abbaye de Saint-Père de Chartres dans laquelle est cité le nom d'un seigneur local, un certain Hugues de Versailles ("Hugo de Versalliis"). Ce serait le premier seigneur connu de Versailles.

Une deuxième allusion apparaît en 1065 dans un acte par lequel un certain Geoffroy de Gometz fonda à cette date le prieuré de Bazainville, non loin de Houdan, qu'il donna à l'abbaye de Marmoutier de Tours. Pour assurer des ressources régulières et suffisantes, il lui accorde plusieurs terres et privilèges, avec en particulier « trois prébendes à Versailles dont l'une se trouve "in domino" ». De ces trois prébendes canoniales, on peut émettre l'hypothèse que celle "in domino" relevait du seigneur de Versailles, les deux autres de l'abbaye tourangelle. Le village de Versailles serait donc né vers le milieu du d'une double initiative seigneuriale et religieuse.

Dans le système féodal de la France médiévale, les seigneurs de Versailles étaient subordonnés directement au roi, sans suzerain intermédiaire entre eux et le roi. Ils n’étaient pas alors d’un rang très important.

À la fin du , le premier village s’était établi auprès d’un manoir médiéval et autour de l’église Saint-Julien. La paroisse Saint-Julien de Versailles est citée dans une charte de 1084. Son activité agricole et sa position sur la route de Paris à Dreux et à la Normandie en firent un village prospère, surtout au cours du connu comme le « siècle de saint Louis », qui fut une période de prospérité dans le nord de la France, marquée par la construction des cathédrales gothiques.

Le apporta la peste noire et la guerre de Cent Ans, avec leurs cortèges de mort et de destruction. À la fin de la guerre de Cent Ans, au , le village commença à se reconstruire avec une population de seulement 100 habitants. À cette époque deux autres villages existaient dans le territoire de la commune actuelle : Choisy-aux-Bœufs et Trianon. Ils disparurent par la suite englobés dans le parc du château. Le nom de Choisy-aux-Bœufs rappelle que ce village se trouvait sur le chemin par lequel les troupeaux de bœufs venant de Normandie étaient conduits à Paris.

Au , Gilles de Versailles exerce la charge de bailli du roi.

En 1561, Martial de Loménie, secrétaire d’État aux finances du roi Charles IX, devint seul seigneur de Versailles. Il obtint l’autorisation d’établir quatre foires annuelles et un marché hebdomadaire le jeudi. La population de Versailles atteignait alors 500 habitants. Château et terre ne ressemblaient guère à ce qu'ils devinrent plus tard sous Louis XIV. Ils n'en excitèrent pas moins la jalousie et la convoitise de la famille de Retz. Le 6 avril 1571, Martial, poursuivi sous couleur de protestantisme, en réalité, à cause de son attachement au jeune Henri IV et à sa famille, fut privé de ses charges par arrêt et emprisonné. Le duc de Retz Albert de Gondi, originaire de Florence, arrivé en France avec Catherine de Médicis (qui devint plus tard le maréchal de Retz), alla le trouver dans sa prison. Au cours d'une scène dramatique, « usant d'atroces menaces », il lui fit signer la vente à vil prix de la Seigneurie de Versailles à son profit. Martial n'en fut pas moins égorgé dans sa prison le jour de la Saint-Barthélémy (24 août 1572).
Dès lors, Versailles fut la propriété des Gondi, une famille de juristes riches et influents au Parlement de Paris. Le petit-fils d’Albert, Henri de Gondi, qui devint cardinal, reçut à plusieurs reprises le roi Henri IV dans son manoir de Versailles. Dans les années 1610, les Gondi invitèrent plusieurs fois le jeune roi Louis XIII à des parties de chasse dans les vastes forêts de Versailles.

En 1623, le roi Louis XIII fait construire un rendez-vous de chasse sur un terrain de cent dix-sept arpents (soit environ 350 hectares) acheté à divers propriétaires.

Le 8 avril 1632, Louis XIII achète la totalité de la seigneurie de Versailles à son dernier seigneur, Jean-François de Gondi, archevêque de Paris pour la somme de livres. C'est le tournant décisif dans l'installation de la royauté à Versailles. Cette même année, il nomme son valet de chambre, Arnault, comme gouverneur de Versailles, dont la fonction était d'administrer le domaine, c'est-à-dire tant la ville que le château.

En 1634, sont achevés les travaux confiés à l'architecte Philibert Le Roy. Le premier manoir est reconstruit et agrandi sur place dans le style « Louis XIII ».

À la mort du roi, en 1643, le village de Versailles avait encore peu changé.

Pour favoriser la construction de la ville, le roi Louis XIV prit deux importantes décisions, le 22 mai 1671, en faisant don de terrains à bâtir contre l'engagement de construire et le paiement d'un droit, modeste, de cinq sols par arpent et le 24 novembre 1672 en rendant insaisissables les immeubles construits.

En 1673, est décidée la destruction du vieux village de Versailles. Une nouvelle église Saint-Julien, destinée à remplacer celle de l'ancien village, est édifiée en 1681-1682 près du nouveau cimetière de la Ville Neuve. Dès 1684, commencent les travaux de construction de la nouvelle église Notre-Dame destinée à la remplacer. Située dans l'axe de la rue Dauphine, elle est consacrée en 1686 et devient la paroisse royale de Versailles.

En 1682, sont achevées la Petite Écurie et la Grande Écurie destinées à abriter les chevaux de selle et les carrosses royaux. Construites par Jules-Hardouin Mansart, de part et d'autre de l'avenue de Paris, elles complètent la place d'Armes face au château.

En 1694, sont élus pour la première fois des représentants des habitants, les quaterniers, avec à leur tête un syndic.

En 1713, le privilège d'insaisissabilité des immeubles instauré en 1672 est révoqué pour mettre fin aux abus.

Avec l'installation du roi Louis XIV et de sa cour, le , la petite cité va connaître une destinée "flamboyante" pendant le règne de ce dernier avec une population d'environ 30 000 habitants à sa mort et continuera de grossir sous ses successeurs jusqu'à atteindre âmes lorsque arrive la Révolution.

À la mort de Louis XIV, le , le régent Philippe d'Orléans, décide de transférer la Cour à Paris. Commence alors une phase de déclin pour la ville qui voit sa population diminuer rapidement de moitié : le marché immobilier s'effondre.

La situation se rétablit sept ans plus tard, le 15 juin 1722, avec le retour du roi Louis XV, alors âgé de douze ans.

En 1737, l'étang de Clagny, situé au nord de la Ville Neuve et qui était alors devenu un cloaque recevant tous les égouts, fut comblé et permit de récupérer vingt-quatre hectares immédiatement ouverts à la construction.

En 1740, une émeute se produisit dans le magasin des farines du marché de la Ville Neuve, appelé le « Poids le Roi ». Dans un contexte de mauvaise récolte, des Versaillaises, voulant s'opposer à l'enlèvement de farines par les boulangers parisiens, furent réprimées par les gardes suisses.

En 1743, commencèrent, sous la direction de Jacques Hardouin-Mansart de Sagonne, les travaux de construction de l'église Saint-Louis qui s'achevèrent neuf ans plus tard, et contribuèrent avec la création du marché des « Carrés Saint-Louis » à l'urbanisation du quartier Saint-Louis.

En 1759, pour accueillir les services de l'État, notamment des ministères des Affaires étrangères et de la Guerre, le roi fit construire par l'architecte Jean-Baptiste Berthier, d'une part, l'hôtel de la Marine et des Affaires étrangères et, d'autre part, celui de la Guerre. De nombreux hôtels particuliers sont également construits à cette époque.

Le 18 novembre 1777, est inauguré, rue des Réservoirs, le théâtre de Versailles, l'un des plus anciens de France, à l'initiative de mademoiselle Montansier.

Un des premiers vols de ballon à air chaud eut lieu à Versailles le 19 septembre 1783. Un ballon, préparé par Étienne de Montgolfier, transportant un mouton, un coq et un canard, s'éleva de la place du château pour se reposer trois kilomètres plus loin.

En 1787, le faubourg de Montreuil est annexé à Versailles, tant pour des raisons fiscales que pour améliorer la sécurité publique en étendant le domaine d'intervention de la police.

La première municipalité de Versailles, créée par ordonnance de Louis XVI, se réunit pour la première fois le 4 janvier 1788. Elle comprenait trente-deux élus, sous la direction du syndic, Marc-Antoine Thierry, baron de la Ville-d'Avray, premier valet de chambre du roi. Sa principale mission était de voter le budget de la ville. La police restait l'apanage du bailli.

Siège du pouvoir politique, Versailles devint naturellement le berceau de la Révolution française. Les États généraux se réunirent à Versailles le à l'hôtel des Menus Plaisirs et le 17 juin 1789, sur proposition de l’abbé Sieyès, ils prennent le titre d’« Assemblée nationale ». Le roi ayant fait fermer l'hôtel des Menus Plaisirs, les membres du tiers état occupèrent la salle du jeu de paume le , où ils prononcent le célèbre serment. Après la prise de la Bastille, les premiers nobles émigrés, parmi lesquels le comte d'Artois, futur Charles X, frère de Louis XVI quittent Versailles. L’Assemblée constituante abolit le féodalisme le . Finalement, les 5 et 6 octobre 1789, une foule venue de Paris envahit le château et força la famille royale à revenir à Paris. Peu après, l’Assemblée constituante suivit le roi à Paris et ce fut la fin du rôle de capitale de Versailles.

À l'époque de la Révolution, la commune avait proposé à la Convention de rebaptiser Versailles en « Berceau-de-la-Liberté », mais a dû se rétracter devant les réticences d'une grande partie de la population.

La ville perdit, par la suite, une bonne partie de ses habitants. De , la population descendit à habitants en 1824.

Le 8 février 1791, la ville élit son premier maire, Jean-François Coste. Le 9 septembre 1792, des prisonniers d'Orléans qui devaient être conduits à Paris sont massacrés par des émeutiers étrangers à la ville, malgré le comportement courageux du nouveau maire Hyacinthe Richaud.

Le château, dépouillé de ses meubles et de ses ornements pendant la Révolution, fut laissé à l’abandon. Il n'est toutefois pas détruit. Sous le Directoire, on y installe un musée spécial de l'École française. Napoléon y séjourna brièvement, n’y passant qu’une seule nuit, avant de l’abandonner définitivement.
Le 3 janvier 1805, le pape Pie VII, venu à Paris pour couronner Napoléon, est invité à Versailles. Il fut reçu par le premier évêque de Versailles, Charrier de la Roche, à la cathédrale Saint-Louis puis bénit la foule rassemblée devant le château.

Le 31 mars 1814, l'armée prussienne occupe la ville.

Le 1er juillet 1815, la cavalerie du général Exelmans rencontra à Vélizy une avant-garde prussienne composée de deux régiments de hussards qui furent culbutés. Les Prussiens en déroute s'enfuirent par Versailles et traversant la ville, au galop, par le boulevard du Roi, la rue des Réservoirs, la place d'Armes, l'avenue de Paris, la rue des Chantiers, en cherchant à gagner Saint-Germain-en-Laye, assaillis par la cavalerie française secondés par les gardes nationaux locaux agissant en tirailleurs à la porte Saint-Antoine, ils tombent dans une embuscade à Rocquencourt. Le lendemain, 2 juillet, Blücher occupa militairement Versailles, ordonna aux habitants de livrer toutes leurs armes et quand nul ne fut plus en état de se défendre, ou de se venger, il ordonna le pillage. Un grand nombre de maisons furent ravagées et de la manufacture d'armes il ne resta que les murs. Les villages de Rocquencourt, du Chesnay et de Vélizy subirent le même sort.

Ils restèrent dans Versailles jusqu'au 12 octobre 1815 date à laquelle ils furent remplacés par les Anglais qui partirent définitivement le 12 décembre de la même année.

Le 10 juin 1837, le roi des Français Louis-Philippe, inaugure dans le château, le musée d’Histoire de France, musée de peintures et de sculptures consacré aux « Gloires de la France ».

En 1839 et 1840, sont mis en service les chemins de fer de « rive droite » et de « rive gauche (château) » qui relient la ville à Paris, respectivement, à la gare Saint-Lazare et à la gare Montparnasse.

En 1858, une nouvelle machine hydraulique, pouvant élever par jour, due à l'ingénieur Dufrayer, remplace la machine de Marly.

L'importance de cette grande ville va dès lors décliner, alors qu'elle est abandonnée par le pouvoir. Ce déclin va cesser après 1871, à la suite de l’insurrection de la Commune de Paris, date à laquelle le gouvernement de Thiers s'installe à Versailles, situation qui perdurera jusqu'en 1879.

La ville est à nouveau occupée par les troupes prussiennes à partir du 19 septembre 1870, tandis que Paris est assiégée. L'occupation durera 174 jours jusqu'au 12 mars 1871. Versailles doit faire face à de lourdes réquisitions. S'opposant à des demandes excessives, le maire, Charles-Victor Chevrey-Rameau, et trois de ses conseillers sont incarcérés le 31 décembre 1870 et libérés le 6 janvier suivant après que les commerçants ont payé la rançon. Le roi de Prusse Guillaume s'installe dans le château de Versailles et se fait proclamer empereur d'Allemagne le dans la Galerie des Glaces.

Au début de la Commune de Paris, le gouvernement de Thiers fuit le soulèvement parisien du 18 mars et s'installe à Versailles, suivi par une foule de Parisiens dont le nombre fut estimé à plus de par le maire alors que la ville ne comptait que habitants au recensement de 1866. Louise Michel a été détenue au camp de Satory, où vingt-cinq communards furent fusillés, dont le colonel Louis Rossel et le militant blanquiste Théophile Ferré. Louise Michel déclara lors de son procès :
Un hémicycle est construit en 1875 dans l'aile du midi du château pour accueillir la Chambre des Députés tandis que le Sénat siège à l'Opéra. Les deux chambres votent le 19 juin 1879 leur transfert à Paris.

Dans la seconde moitié du , la communauté juive de Versailles a vécu une grande page avec Mahir Charleville, grand rabbin de Versailles, le développement a été profondément marqué par un certain modernisme. Il inaugure, notamment, le temple de la rue Joly, offert par Cécile Furtado-Heine et la communauté versaillaise à l'aube du nouveau siècle, rejoint le consistoire de Nantes.

En 1897, Alfred Le Chatelier ouvre une fabrique de céramiques en grès et en porcelaine à Glatigny, quartier encore isolé de la ville ; cet atelier produira des pièces remarquées jusqu'en 1902.

En fin de siècle, Versailles évolue comme une ville de province avec tout le faste d'une ville touristique importante.

Il fallut attendre 1901 pour que Versailles retrouve son niveau de population de 1790, avec habitants au recensement de 1901.

En 1919, à la fin de la Première Guerre mondiale, Versailles fut à nouveau en vedette lorsque les différents traités mettant fin à la guerre furent négociés et signés dans le château lui-même ou au Grand Trianon ; notamment, le , eut lieu la signature du traité de Versailles dans la galerie des Glaces du château.

Dans les années 1923-1932, un industriel américain, John D. Rockefeller, fit des dons d'un montant total de 23 millions de dollars qui contribuèrent grandement à la restauration du château et du parc, notamment la réfection des toits.
En 1932, eut lieu l'inauguration de la gare des Chantiers par Raoul Dautry.

Pendant la Seconde Guerre mondiale, Versailles est occupée par les troupes allemandes du au , date de l'entrée des premiers blindés de la DB du général Leclerc. Elle subit, notamment en février et juin 1944, d'importants bombardements visant la gare des Chantiers et le camp de Satory et qui firent plus de 300 victimes.

Deux faits ont marqué la Résistance à Versailles. Le , au cours d'une cérémonie dans la caserne Borgnis-Desbordes (dans laquelle se trouvait la Légion des volontaires français) le jeune Paul Collette tenta d'abattre Pierre Laval et Marcel Déat en tirant cinq balles de revolver. Cet événement n’eut pas de conséquences politiques. Le 13 mai 1944, de jeunes Versaillais incendient le fichier du recensement dans les services du STO, place Hoche. Arrêtés par la suite sur dénonciation, ils sont morts en déportation.

Le , le réseau des Tramways de Versailles fut fermé et remplacé par des autobus. La même année est achevée après six ans de travaux la restauration de l'Opéra royal, qui sert également d'assemblée au Sénat.

Le , un décret fixa à Versailles le chef-lieu du nouveau département des Yvelines, créé officiellement le en application de la loi 64-707 du portant réorganisation de la région parisienne.

En 1966, la restauration et le nouvel ameublement du château du Grand Trianon, à l'instigation d'André Malraux, ministre de la Culture, est achevée. Le Grand Trianon est à la fois musée et résidence des hôtes officiels de la France.

Du 4 au 6 juin 1982, se tient au château la du G7 dit Sommet de Versailles.

Les 17 et 19 février 1986, le premier sommet de la francophonie s’est tenu à Versailles, dans le château, sous la présidence de François Mitterrand. Il réunissait, outre la France, des représentants de 42 pays, dont seize chefs d’État et dix chefs de gouvernement.

La grande tempête du ravagea les plantations du parc et permit, en contrepartie, la mise en place d'un important programme de replantation des essences originelles dans leurs alignements d'époque.
En 2002, est créée la communauté de communes du Grand Parc, qui regroupe sept communes de la plaine de Versailles auxquelles s'adjoignent par la suite Bois-d'Arcy et Bièvres. Elle prend la dénomination de communauté d'agglomération Versailles Grand Parc le janvier 2010 et regroupe désormais dix-huit communes. La population de Versailles représente 32,6 % des habitants de la communauté d'agglomération au janvier 2012, dans son nouveau périmètre de 2014.

Aujourd'hui, avec la croissance de la banlieue de Paris, Versailles, se trouve englobée dans l’agglomération parisienne. Le rôle de Versailles comme centre administratif et judiciaire s’est renforcé dans les années 1960 et 1970 ; la ville reste l'un des pôles notables de la banlieue ouest de Paris, à la démographie et à l'économie peu dynamiques ("cf. infra").

Le 25 juin 2007, la Galerie des Glaces, restaurée après quatre ans de travaux, est rouverte à la visite.

Versailles est une ville qui a une longue tradition politique ancrée à droite. Le maire actuel, François de Mazières, qui était dans l'équipe municipale sortante maire-adjoint chargé de la culture, l'a emporté en 2008 contre le candidat officiellement investi par l'UMP, Bertrand Devys. Il a ensuite été élu député en 2012 comme candidat « divers droite », avec l'investiture de l'UMP.

À l’élection présidentielle de 2002, le premier tour a vu arriver en tête Jacques Chirac avec 27,86 %, suivi de Jean-Marie Le Pen avec 12,8 %, Lionel Jospin avec 11,89 %, puis François Bayrou avec 11,37 %, Christine Boutin avec 7,51 %, Alain Madelin avec 6,35 %, Jean-Pierre Chevènement avec 5,86 %, Noël Mamère avec 4,07 %, aucun autre candidat ne dépassant le seuil des 4 %. Au second tour, les électeurs ont voté à 84,42 % pour Jacques Chirac contre 15,58 % pour Jean-Marie Le Pen avec un taux d’abstention de 17,47 %, résultat légèrement plus contrasté qu'au niveau national (respectivement 82,21 % et 17,79 % ; abstention 20,29 %).

Au référendum sur le traité constitutionnel pour l’Europe du , les Versaillais ont très nettement approuvé la Constitution européenne, avec une majorité de 68,87 % de oui contre 31,13 % de non et un taux d’abstention de 24,44 % (France entière : non à 54,67 % ; oui à 45,33 %). Ces chiffres amplifient nettement la tendance départementale des Yvelines (oui à 59,53 % ; non à 40,47 %) et celle de la région Île-de-France (oui 53,99 % ; non 46,01 %).

À l’élection présidentielle de 2007, le premier tour a vu Nicolas Sarkozy arriver en tête avec 47,06 %, suivi par François Bayrou avec 22,01 %, Ségolène Royal avec 15,57 %, Jean-Marie Le Pen avec 7,58 % et Philippe de Villiers avec 3,18 %, aucun autre candidat ne dépassant le seuil des 2 %. Le second tour a vu Nicolas Sarkozy arriver en tête à une très large majorité de 70,80 % contre 29,20 % pour Ségolène Royal (résultat national : respectivement 53,06 et 46,94 %).

Lors de l’élection présidentielle de 2012, Nicolas Sarkozy arrive à nouveau nettement en tête au premier tour avec 46,48 % des voix, devant François Hollande crédité de 19,63 %, François Bayrou de 12,37 %, Marine Le Pen de 11,21 % et Jean-Luc Mélenchon de 5,56 %. Aucun autre candidat n'a dépassé les 3 % lors de ce premier tour. Au second tour, les Versaillais votent à nouveau à contre-pied du résultat national (51,64 % pour François Hollande contre 48,36 % pour Nicolas Sarkozy), en attribuant 66,84 % des voix au candidat UMP contre 33,16 % au candidat socialiste.

Versailles est le siège de la préfecture des Yvelines et le bureau centralisateur de deux cantons.
Versailles fut désignée comme préfecture de la Seine-et-Oise dès la création des départements en mars 1790. Lors de la réforme qui a conduit à l'éclatement de la Seine-et-Oise en janvier 1968, elle a conservé ce rôle pour le département des Yvelines qui représente environ 40 % en superficie de l'ancien département.
Versailles est, depuis 2002, la ville centre de la communauté de communes du Grand Parc, en référence au grand parc de Louis XIV, qui regroupe environ habitants des Yvelines et, depuis 2003, ceux d'une commune de l'Essonne, Bièvres.

Depuis 1972, Versailles est le siège d'une des trente académies, circonscriptions administratives du ministère chargé de l'éducation, couvrant l'ouest de l'ancienne Seine-et-Oise, c'est-à-dire l'Essonne, les Hauts-de-Seine, les Yvelines et le Val-d'Oise.

En 1975, Versailles est devenue le siège d'une cour d'appel dont la circonscription s'étend sur les départements d'Eure-et-Loir, des Hauts-de-Seine, du Val-d'Oise et des Yvelines.

Versailles est également un diocèse de l'Église catholique romaine, créé en 1790, et rattaché à l'archidiocèse de Paris.

Bien que Paris soit toujours resté la capitale officielle de la France, Versailles a été à plusieurs reprises le siège effectif du pouvoir central et la capitale de fait de la France :

Le conseil municipal compte actuellement 53 membres : 44 élus de la majorité, 4 élus de liste « Versailles autrement » classée à gauche et 6 élus de listes de droite.

La liste « Union pour le renouveau de Versailles » classée extrême droite n'est plus présente depuis l'élection de mars 2014.

Depuis 1977, la municipalité a institué huit « conseils de quartier » (Chantiers, Clagny-Glatigny, Jussieu-Petit-Bois-Picardie, Montreuil, Notre-Dame, Porchefontaine, Saint-Louis et Satory) en vue de favoriser la concertation entre l'équipe municipale et les habitants. Les comptes rendus de ces conseils de quartiers sont publiés sur le site officiel de la ville.

La part communale des trois principales taxes locales est relativement modérée avec les taux suivants en 2006 : 10,85 % pour la taxe d'habitation, 13,30 % pour la taxe foncière sur les propriétés bâties et 11,38 % pour la taxe professionnelle. À ces taux s'ajoutent, respectivement, 0,23 %, 0,27 % et 0,20 % pour les charges d'intercommunalité. La part départementale s'élève respectivement à 4,8 %, 4,6 % et 4,53 %. La taxe professionnelle, acquittée par les entreprises, représentait en 2002, avec par habitant, 25 % du produit total des quatre taxes locales, contre près de 46 % pour la taxe d'habitation.

La ville est la de France, et la première des Yvelines devant Saint-Germain-en-Laye, pour le nombre d'assujettis à l'impôt de solidarité sur la fortune (ISF), qui s'élève à déclarant un patrimoine moyen de euros. Rapporté à la population totale, le taux d'assujettis à l'ISF est de 45 pour 1000 habitants, ce qui classe Versailles au troisième rang, derrière Neuilly-sur-Seine et Saint-Cloud, des villes (de plus de habitants) les plus riches de France au regard de l'ISF.

En 2006, le budget de fonctionnement dégageait un excédent de euros pour des charges totales se montant à euros (soit par habitant). Les dépenses d'investissement s'élevaient à euros et la capacité d'autofinancement à euros.

Versailles fait partie de deux circonscriptions législatives.

Le canton de Versailles-1, soit la majorité de la ville, fait partie de la première circonscription des Yvelines, qui inclut aussi les villes de Montigny-le-Bretonneux et Guyancourt.

Le canton de Versailles-2, soit le quartier des Chantiers et la partie est du quartier Saint-Louis, fait partie de la deuxième circonscription des Yvelines, qui inclut aussi les villes de Viroflay et Vélizy-Villacoublay notamment.



Versailles n'a pas établi de jumelages à proprement parler, mais entretient des relations avec des villes royales ou impériales. C'est le cas de Nara, ancienne ville impériale du Japon et de Pouchkine, ancienne résidence
d’été des tsars de Russie.
La ville pratique par ailleurs des actions ciblées de solidarité internationale avec des pays en voie de développement.

Ses habitants sont appelés les "Versaillais".

Versailles n'était à la fin de la guerre de Cent Ans, sous le règne de Charles VII le Victorieux, qu'un petit village d'une centaine d'âmes. Sa population est évaluée à la fin du à environ 500 habitants, puis à un millier vers 1632 quand Louis XIII rachète la seigneurie aux Gondi. La population fait un bond à partir de 1662 quand Louis XIV engage les travaux de transformation du château qui se traduisent par l'arrivée de milliers d'ouvriers, souvent saisonniers, logés dans des baraquements, puis à partir de 1682, année de l'installation de la Cour à Versailles. À la fin du , Versailles devait atteindre habitants et était devenu une des villes importantes du royaume (Paris comptait alors environ habitants).

La ville continua à se développer jusqu'à la fin du règne de Louis XIV pour atteindre environ habitants, mais la mort de Louis XIV en 1715 et la décision du régent Philippe d'Orléans, de transférer la Cour à Paris provoqua une récession et un reflux de la population de l'ordre de 50 %, provoquant un effondrement du marché immobilier. Le retour de la Cour de Louis XV en 1722 provoqua un nouvel afflux de population et de grands travaux d'urbanisme. La ville s'agrandit encore en 1787 en annexant le village de Montreuil. Elle comptait environ habitants à la veille de la Révolution.
La Révolution provoqua à nouveau une chute de moitié de la population qui régressa entre 1790 et 1800 de à habitants, la ville perdant l'essentiel de ses fonctions politiques et administratives, partiellement compensées par la création de la préfecture de Seine-et-Oise. Par la suite, la population continue à croître régulièrement au fur et à mesure que l'urbanisation s'étend. Ainsi les quartiers de Clagny et Glatigny se complètent vers la fin du . La crise de la Commune en 1871, suivie de l'installation du gouvernement à Versailles, provoque un afflux de Parisiens et une pointe transitoire de population qui augmente brusquement de 40 % pour dépasser habitants au recensement de 1872 avant de retomber à en 1881.

Après une croissance continue qui culmine à habitants en 1936, la guerre de 1939-1945 provoque une nouvelle crise démographique. En 1946, la ville ne compte plus que habitants. Elle s'était littéralement vidée en juin 1940, tombant à environ personnes au moment de l'exode. Par la suite, du fait de l'intense effort de construction des années 1950-1970, la population a de nouveau sensiblement augmenté, atteignant son maximum historique de habitants en 1975. Depuis lors, on constate la stagnation du nombre d'habitants, suivie d'une baisse depuis 2009.

L'évolution du nombre d'habitants depuis 1793 est connue à travers les recensements de la population effectués à Versailles depuis cette date.

La pyramide des âges de Versailles se caractérise par sa base relativement étroite, signe d'un vieillissement de la population, un peu plus marqué qu'au niveau régional. Les moins de 15 ans représentent 17,9 % de la population contre 18,8 % au niveau régional ; toutefois, contrairement à la moyenne régionale, cette tranche d'âge est en légère progression entre 1990 et 1999 (de 0,6 point contre une baisse de 0,4 point sur la région). La tranche des 15-29 ans est, en revanche, en légère progression passant de 24,8 % à 26,1 % entre 1990 et 1999.
Les plus de soixante ans représentent 38,9 % de la population totale (36,7 % en 1990), contre 35,8 % en moyenne régionale (32,2 % en 1990), suivant la même tendance au vieillissement. Les tranches intermédiaires (30-59 ans) représentent 39,5 % de la population, en légère progression, contre 43 % en moyenne régionale.

En 2014, le niveau d'éducation à Versailles est élevé, nettement plus que dans le reste du département des Yvelines. En effet, la part dans la population totale des titulaires de diplômes de niveau Bac+2 ou supérieur est, dans la commune, de 60,7 %, contre 41,8 % en moyenne yvelinoise, tandis que 14,5 % de la population n'est titulaire d'aucun diplôme (contre 23,6 % au niveau départemental). En 2014, la ville comptait 13 270 personnes relevant de la catégorie « cadres et professions intellectuelles supérieures », soit 28,4 % de la population active.

Versailles est le siège d’une académie, dont la compétence s'étend aux quatre départements de l’Essonne, des Hauts-de-Seine, du Val-d’Oise et des Yvelines, qui totalisent plus de six millions d’habitants.

On dénombre à Versailles pour la rentrée 2008, trente-quatre écoles gérées par la commune (dix-sept écoles maternelles, dix-sept écoles élémentaires dont cinq d'application), deux groupes scolaires primaires et onze écoles privées, qui au total accueillaient en 2007 environ élèves.

Les établissements de la commune dépendent de l’inspection générale de l'inspection départementale de l’Éducation nationale des Yvelines, circonscription de Versailles (qui se limite à la seule commune de Versailles).

En 1975 eut lieu la première classe de neige franco-américaine entre Versailles et Cedar Rapids, Iowa. Ce fut un bouleversement pédagogique dans les écoles primaires : enseignement de l'anglais, accueil d'une classe américaine. Puis, en 1976, eut lieu le départ de la première classe de CM2 aux États-Unis dans le courant de l'année scolaire. La grande réussite de cette classe conduisit le fondateur André Girod à l'instaurer dans de nombreuses écoles à travers les États-Unis (de l'Alaska à la Floride) et dans toute la France de Nice à Nantes. Plus de enfants participèrent à cette aventure. André Girod décrit dans ses mémoires ("Classe de neige franco-américaine", Publibook, Paris) ce que fut cette saga dans le monde de l'enseignement primaire.

Le département gère cinq collèges (Pierre-de-Nolhac, Raymond-Poincaré, Jean-Philippe-Rameau, Hoche et collège de Clagny) et la région cinq lycées (Hoche, La Bruyère, Jules-Ferry, Marie-Curie et le lycée professionnel Jacques-Prévert). Versailles compte également plusieurs établissements privés sous contrat, deux collèges (Saint-Jean-Hulst, et Sacré-Cœur) (le collège Notre-Dame ayant été intégré à l'école Blanche-de-Castille au Chesnay) et quatre lycées (Notre-Dame-du-Grandchamp, Saint-Jean-Hulst, Saint-Vincent-de-Paul et lycée polyvalent « Les Châtaigners »), ainsi que des établissements hors contrat (Institut Jeanne-d'Arc, Cours Versaillais, École technique d'informatique, comptabilité et secrétariat).

Selon le palmarès 2007 de "L'Express", les lycées d'enseignement général Notre-Dame-du-Grandchamp, Hoche et Saint-Jean-Hulst, sont classés respectivement , et pour leurs résultats au baccalauréat.

Outre les classes préparatoires aux grandes écoles présentes dans l'école Sainte-Geneviève (« Ginette »), les lycées publics Hoche, La Bruyère, Jules-Ferry, Marie-Curie et le lycée privé Notre-Dame du Grandchamp, Versailles est le siège d'une université et de plusieurs écoles spécialisées.

L'université de Versailles-Saint-Quentin-en-Yvelines (UVSQ) a ses services centraux avenue de Paris à Versailles. Cette université, créée en 1991, compte environ étudiants (année scolaire 2013-2014) et propose une formation pluridisciplinaire (sciences exactes, sciences sociales, sciences humaines, sciences juridiques et politiques, ingénierie et technologie, médecine. Université de proximité ancrée dans le territoire des Yvelines dont elle contribue au dynamisme, elle est implantée, outre Versailles et Saint-Quentin-en-Yvelines, dans six autres sites des Yvelines (Le Chesnay, Vélizy, Rambouillet, Mantes-la-Jolie, Mantes-la-Ville) et des Hauts-de-Seine (Garches).

Les écoles spécialisées sont l'école d’architecture de Versailles, installée dans la Petite Écurie face au château, l'École nationale supérieure du paysage, installée sur le site du Potager du roi, l'Institut supérieur international du parfum, de la cosmétique et de l'aromatique alimentaire (ISIPCA), et un centre d'enseignement du Conservatoire national des arts et métiers (CNAM) qui s'adresse aux adultes ayant déjà une activité professionnelle. L'institut de formation en soins infirmiers (IFSI), établissement dépendant du centre hospitalier de Versailles, forme des infirmiers et des aides-soignants.

Le Centre régional de formation professionnelle des avocats du ressort de la cour d'appel de Versailles (CRFPA de Versailles ou Haute École des avocats conseils-HEDAC) était installé à Versailles, jusqu'en 2008, date de son déménagement à Viroflay, dans le prolongement de l'avenue de Paris.

L'École européenne d'intelligence économique (EEIE) est située dans l'hôtel de madame de Pompadour à Versailles, aussi nommé Hôtel des Réservoirs, construit en 1751 par l'architecte Jean Cailleteau (« Lassurance ») pour madame de Pompadour.

Versailles est le cadre tous les ans au mois de juin de l'un des festivals de théâtre en France (environ soixante mille visiteurs), Le Mois Molière, créé en 1996 par François de Mazières et animé par plusieurs centaines de bénévoles. Organisé par la Ville, il présente plus de 250 spectacles sur une quarantaine de sites et a pour but de promouvoir le théâtre populaire sous toutes ses formes (grands classiques, comédies musicales, cirque contemporain…). Chaque année, de nombreuses créations inédites y sont présentées, des personnalités du théâtre (tels Denis Podalydès, Nicolas Vaude, Arthur Jugnot, Philippe Caubère, Romane Bohringer…) viennent y rendre un hommage au théâtre populaire et plusieurs pays étrangers sont les invités des organisateurs. Ainsi l'Espagne, la Colombie, la Russie et le Québec, entre autres, ont-ils pu fouler les planches versaillaises. Parallèlement à la programmation officielle du festival, les ensembles théâtraux et musicaux locaux y présentent leurs dernières créations.

La saison du centre de musique baroque de Versailles (dont le siège se trouve à l'Hôtel des Menus Plaisirs, lieu ayant accueilli les États généraux de 1789) propose concerts, opéras et spectacles de danse.

Jusqu'en 2014, Versailles accueille Le Potager du Rock, un festival de musiques actuelles organisé par l'association Universailles Musiques. Le festival dure une semaine et propose une dizaine de concerts dans les bars de la ville et à la "Royal Factory" (café-théâtre). Autre manifestation musicale annuelle : le Versailles jazz Festival. Plusieurs événements culturels annuels ont été également initiés par la ville depuis 2008 tels que « Histoire de Lire », le salon du livre d'histoire, les Vendredis du Rock, Trésors cachés, une chasse aux trésors à la recherche des curiosités de la ville, « L'Expo BD » qui met en scène l'univers des grandes signatures de la bande dessinée (Patrice Pellerin, l'auteur de la série "L’Épervier" en 2009, André Juillard, coauteur notamment de la reprise de la série "Blake et Mortimer" en 2010, William Vance, le dessinateur notamment de la série "XIII" en 2011, Philippe Francq, dessinateur de la série "Largo Winch" en 2012. En 2012, le prix Espoir du , dont le jury est présidé par Philippe Francq est décerné pour la première fois. En 2013, l'Expo BD est dédiée à Grzegorz Rosinski, le dessinateur de la série "Thorgal". Rosinski est le président du jury de la seconde édition du prix Espoir du Art. Un jury composé de journalistes et de plusieurs signatures de la bande dessinée dont Philippe Francq ou Patrice Pellerin.

Le centre hospitalier de Versailles comprend deux établissements dont un est situé dans la commune : la maison de retraite Despagne. Le second, qui accueille aussi le siège de l'établissement est l'hôpital André-Mignot, construit en 1981 dans la commune voisine du Chesnay. Il compte plus de 700 lits.

La ville possède également deux cliniques privées, la clinique des Franciscaines et la polyclinique de Versailles. La maison de santé « Claire demeure » est un centre de gériatrie et de soins palliatifs géré par la communauté religieuse protestante des diaconesses de Reuilly.

Versailles dispose d'un commissariat de la police nationale rattaché au district de Versailles, d'une police ferroviaire basée à la gare des Chantiers et depuis les années 1980 d'une police municipale forte de 22 policiers municipaux et d'une quarantaine d'ASVP. En février 2005 a été mis en place un conseil local de sécurité et de prévention de la délinquance, destiné notamment à assurer une meilleure coordination des acteurs.

Le taux de criminalité de la circonscription de police de Versailles (Versailles, Le Chesnay, Buc, Les Loges-en-Josas et Rocquencourt, soit habitants) est de 64,30 actes pour habitants (crimes et délits, chiffres 2005), ce qui le situe légèrement au-dessus de la moyenne française (62,30), mais inférieur à la moyenne des circonscriptions de la strate démographique ( à habitants).
Le taux de résolution des affaires par les services de police est de 24,96 %, légèrement inférieur à la moyenne du département de 26,24 %.

La ville de Versailles dispose de nombreux équipements sportifs, dont une piscine, cinq stades, treize gymnases, neuf salles de sports et cinq espaces sportifs.

Elle compte 88 clubs sportifs regroupant plus de licenciés dans quarante disciplines. Les plus notables sont la Société de natation de Versailles, le Club hippique de Versailles, le Tennis club du Grand Versailles, la Gymnastique volontaire de Porchefontaine, l'Entente Le Chesnay-Versailles et l'Union athlétique de Versailles.
Chaque année depuis 1979, Versailles accueille la course Paris-Versailles () dont l'arrivée a lieu avenue de Paris devant le château.

Versailles a été 17 fois ville-étape du Tour de France entre 1958 et 2013, dont trois fois, en 1961, 1972 et 1973, à l'occasion d'une étape contre la montre en boucle. En 1989, la dernière étape, un contre-la-montre reliant Versailles à Paris, est restée célèbre pour avoir vu la défaite finale du Français Laurent Fignon, parti en jaune, face à l'Américain Greg LeMond, pour 8 secondes après plus de de course.
Le Cercle nautique est l’une des plus anciennes sociétés sportives versaillaises : l'association « Cercle Nautique de Versailles » a été créée en 1908. Elle exerce son activité depuis l’origine sur le Grand Canal du château de Versailles et a pour but le développement de l’aviron sous toutes ses formes.
Le Grand Canal accueille régulièrement de grandes compétitions nationales ou internationales, organisées par le CN Versailles.
La pratique du ballon ovale démarre en 1893, lorsque des élèves du lycée Hoche se réunissent au sein de l’Association athlétique du lycée Hoche pour pratiquer le « football-rugby », comme l'on dit encore à l'époque. Plus d'un siècle après, le sport est toujours pratiqué à Versailles, au sein du Rugby Club de Versailles, mais aussi dans les équipes scolaires (notamment à Saint-Jean-Hulst). Depuis 2003, chaque samedi, des papas et leurs garçons se retrouvent pour jouer ensemble au rugby au sein de « Père et fils Rugby ».
Comptant 800 adhérents, le Club hippique de Versailles accueille chaque année des concours régionaux et départementaux.
La ville de Versailles accueille également l'Académie équestre de Bartabas, installée dans la Grande Écurie et qui est en même temps un centre de formation et un lieu où sont données des représentations de spectacles équestres.
En 2024, Versailles accueillera les épreuves d'équitation (dressage, saut d'obstacles et concours complet) dans les jardins du Château au bout du grand Canal.
À plusieurs reprises, Versailles a été ville de départ du rallye Paris-Dakar, les concurrents démarrant de la place d'Armes, devant le château.
Fort de sa cinquantaine d'adhérents, le Friselis Club est le premier club d'Ultimate-Frisbee des Yvelines (champion d'Europe en 2003).
Le handball est devenu, pour de plus en plus de Versaillais, un sport en vogue depuis la série de victoires de l'Équipe de France de Handball commencée en 2008 aux Jeux Olympiques de Pékin. Fondé en 1963, la section handball du Racing Club Versailles a connu la nationale 2 dans les années 1970 avant de redescendre jusqu'en départemental honneur au cours des années 1980.
Le RCV se refait une santé jusqu'à retrouver le championnat prénationale. La dissolution du RCV omnisports à la fin des années 1990 - début des années 2000 pousse le club à devenir indépendant. C'est ainsi que le RCV fait peau neuve et devient le Versailles HandBall Club aussi connu par ses initiales, VHBC.
Le VHBC compte, à ce jour, sept catégories d'âge allant de l'école du hand au seniors (+ 18 ans). Ces équipes évoluent dans les différents championnats départemental (Yvelines), régional (Paris Île-de-France Ouest - PIFO) et national. Au terme de la saison 2012-2013, l'équipe fanion du club remporte le championnat de prénationale PIFO et intègre ainsi le championnat de Nationale 3.
Le basketball à Versailles : tout d'abord dans le secteur féminin puisque celui-ci a été champion de France en 1986 et 1987 et finaliste en 1988 (sous le nom de l'union stade français Versailles).
Le secteur masculin est depuis 2004 en championnat National 3, après une brève incursion en Nationale 2 en 2006. Le secteur jeune a été vice champion de France en 2003.
L'Entente Le Chesnay Versailles compte environ 520 licenciés ce qui le place parmi les cinq meilleurs club de basketball de France.

Plusieurs médias indépendants diffusent à Versailles. Le plus important d'entre eux est "Le Petit Versaillais", un magazine mensuel gratuit qui diffuse à exemplaires. Il s'agit du premier journal de la ville et des Yvelines en termes de diffusion. Il est suivi par un autre magazine gratuit, "Versailles +", créé en 2007, dont la diffusion moyenne est de exemplaires." Toutes Les Nouvelles" est un hebdomadaire qui diffuse également à Versailles mais aussi à Saint-Quentin-en-Yvelines et à Rambouillet : sa diffusion moyenne est de exemplaires. Comme dans la plupart des grandes villes on retrouve également à Versailles un bulletin municipal diffusé mensuellement (10 numéros/an).

Des sites internet sont spécialement dédiés à la vie versaillaise.

Et depuis le décembre 2012, France Télévisions y compte une présence - avec une BIP (Borne d'information de proximité) - France 3 Versailles qui couvre l'actualité de la ville royale et des Yvelines pour France 3 Île-de-France.

France 3 Versailles est installé au 6 avenue de Paris, dans les locaux de la Communauté d'agglomération Versailles Grand Parc - dans la caserne des gendarmes.

Versailles est le siège du diocèse catholique de Versailles dont le territoire coïncide avec celui du département des Yvelines depuis 1966. La ville compte neuf paroisses : Notre-Dame, Sainte-Jeanne-d'Arc (rattachées au doyenné de Versailles-Nord), cathédrale Saint-Louis, Sainte-Élisabeth, Sainte-Bernadette, Saint-Symphorien, Saint-Michel de Porchefontaine, chapelle Notre-Dame des Armées, chapelle Saint-Maurice de Satory (rattachées au doyenné de Versailles-Sud).

La ville possède également une mosquée (rue Jean-Mermoz) construite sous le mandat de maire d'Étienne Pinte.

Un temple protestant (rue Hoche). Une église anglicane.

Une synagogue (rue Albert-Joly), construite en 1886 grâce à la générosité d'une philanthrope, Cécile Furtado-Heine. Il est impossible de situer à quel moment est née la communauté juive de Versailles. Pourtant certains historiens font remonter l'existence d’un temple à 1769. Dans "Historique sommaire de la population israélite de Versailles", écrit en 1850, l’auteur écrit : « "En 1789, Monsieur Daniel Daniel a fondé un Temple à Versailles" », il est donc fort possible que le culte juif fut célébré dans cette ville entre 1769 et 1789. La première synagogue devait se situer probablement dans un local où le culte fut exercé durant la Révolution, dans la maison dite du « Tambour », au numéro 9 de l’avenue d’Orient, aujourd’hui avenue de Saint-Cloud, au domicile du ministre-officiant. Cet oratoire fut transféré dans l’ancien hôtel du duc de Richelieu, situé au de la même avenue.

L’Église de Jésus-Christ des saints des derniers jours possède une église à Versailles (rond-point de l'Alliance). Elle possède un temple à vocation nationale, de grande dimension, au Chesnay, à la limite de Versailles.

En 2010, le revenu fiscal médian par ménage était de 43 208 €, ce qui plaçait Versailles au 1 261 rang parmi les 31 525 communes de plus de 39 ménages en métropole.

Avec emplois en 1999 pour une population de habitants, soit près d'un emploi pour deux habitants, Versailles est un pôle d'emploi important qui représente 9 % des emplois offerts dans les Yvelines.
C'est un pôle tertiaire consacré au commerce, au tourisme, à l'éducation et à l'administration.

En 1999, le secteur tertiaire, soit sur , représentait près de 89,6 % des emplois, dont près d'un tiers (27 %) dans les services aux entreprises et aux particuliers. Les autres secteurs totalisaient légèrement plus de 10 %, soit 7,4 % pour l'industrie, 2,6 % pour la construction, et 0,4 % pour l'agriculture. Versailles, qui n'a jamais été une ville industrielle, est à ce titre peu représentative des Yvelines qui comptent globalement plus de 20 % d'emplois industriels.

Les principales activités pourvoyeuses d'emplois sont l'administration publique (28,1 %), l'éducation (9,2 %), la santé et l'action sociale (8,6 %), le conseil et l'assistance (7 %), le commerce de détail et les réparations (5 %), les hôtels-restaurants (4,3 %), les activités financières (4 %), les services opérationnels (3,5 %), les services personnels et domestiques (3,4 %), les activités récréatives, culturelles et sportives (2,9 %), les transports (2,9 %).

La population active représente personnes (1999) dont 6,9 % étaient chômeurs et 92,8 % avaient un emploi, soit un taux d'activité de 56,3 %.
Elle comprend notamment 36,1 % de cadres et professions intellectuelles supérieures, 28,7 % d'employés et 22,6 % de professions intermédiaires.
Un peu plus d'un tiers (35,8 %) des personnes ayant un emploi travaillaient dans la commune même. Il en résulte que chaque jour ouvrable environ Versaillais quittent la ville pour aller travailler, notamment à Paris et dans les Hauts-de-Seine, tandis que personnes viennent de l'extérieur travailler à Versailles.

En 2005, le taux de chômage était de 6 %, un chiffre inférieur à la moyenne des Yvelines (7,1 %), ainsi qu'à la moyenne nationale (8,6 %).

L'activité économique de la ville est dominée par cinq secteurs d'activité principaux :

Certains voient cette activité économique comme très atone depuis plusieurs années, à l'image de l'évolution générale de l'économie française. Elle est, en effet, très centrée sur ses acquis : l'administration publique (14 % des entreprises locales), le tourisme (qui profite fort peu à la ville de Versailles) et les commerces de proximité. Le taux de création d'entreprises est inférieur à 15 %, avec un net décrochage depuis 2008 (en regard de l'économie générale, elle-même faible). L'économie versaillaise est peu encouragée et peu créative ; aucune initiative notable n'est prise en ce domaine.

Versailles est le siège de la Chambre de commerce et d'industrie de Versailles-Val-d'Oise-Yvelines qui gère notamment le port de Cergy, l'ESSEC et 15 autres centres de formation.

La Haute École des avocats conseils est désormais implanté à Viroflay, ville limitrophe.


Versailles est aussi une importante ville de garnison depuis la période monarchique. Les organismes de l'armée et de la défense représentent environ emplois civils et militaires, souvent hautement qualifiés, et pour l'essentiel situés dans le quartier de Satory.
Parmi les organismes militaires présents à Versailles, on peut citer notamment :

Le du génie (qui comprend une compagnie unique dans l'armée française, la CTVF, compagnie de travaux de voies ferrées) a quitté Versailles le 10 juin 2010.

La ville a accueilli la base aérienne 134 Versailles, avec les deux premières promotions de l'École de l'air, en 1935 et en 1936 (la formation des navigants y étant active depuis 1922).

Il rassemble les monuments gérés par l'établissement public du château de Versailles et comprend principalement le château de Versailles, monument classé dans la liste du patrimoine mondial de l'Unesco. Il fut le siège de la cour des rois de France sous Louis XIV, Louis XV et Louis XVI. L'Angleterre y reconnut l'indépendance des États-Unis (1783), l'unification du Reich (1871) y fut proclamée et on y signa le traité de Versailles (1919), dans la galerie des Glaces et c'est toujours au château que se réunissent en Congrès députés et sénateurs pour y ratifier toute modification de la constitution.

Dans le parc se trouvent le Grand et le Petit Trianon, ainsi que le Hameau de la Reine et en ville :




Outre le fait que Versailles possède cinq gares : "Versailles-Rive-Droite", "Versailles-Château", "Versailles-Chantiers", "Montreuil" et "Porchefontaine", divers matériels ferroviaires ont été longtemps conservés au camp des Matelots, ancienne base du du génie, notamment une grue ferroviaire pour la pose d'éléments de ponts surnommée « Diplodocus », pesant et classée à l'inventaire général des monuments historiques en 2005, ainsi que divers types de wagons et voitures.


La ville participe au Concours des villes et villages fleuris et a obtenu quatre « fleurs » en 2016. Elle a renoncé à utiliser des produits phytosanitaires pour l'entretien des parcs, jardins et voiries depuis 2005.

Dans le château :

Hors du château, mais dépendant du domaine national de Versailles :

Autres musées :

De nombreux films ont été tournés à Versailles, notamment au Château :



Traités signés à Versailles :



</doc>
<doc id="15752" url="https://fr.wikipedia.org/wiki?curid=15752" title="Génétique">
Génétique

La génétique (du grec genno γεννώ, « donner naissance ») est la science qui étudie l'hérédité et les gènes, c'est une sous-discipline de la biologie.

Une de ses branches, la génétique formelle, ou mendélienne, s'intéresse à la transmission des caractères héréditaires entre des géniteurs et leur descendance.

L'invention du terme « génétique » revient au biologiste anglais William Bateson (1861-1926), qui l'utilise pour la première fois en 1905. La génétique moderne est souvent datée de la mise en évidence de la structure en double hélice de l'ADN effectuée par James Watson et Francis Crick en 1953 .

Très tôt, la génétique s'est diversifiée en plusieurs branches différentes : 








L'hérédité, qui étudie le phénotype et tente de déterminer le génotype sous-jacent se fonde toujours sur les lois de Mendel. La biologie cellulaire et la biologie moléculaire étudient les gènes et leur support matériel (ADN ou ARN) au sein de la cellule, la biologie cellulaire pour leur expression. Les progrès de la branche ingénierie de la génétique, le génie génétique, ont permis de passer le stade de la simple étude en réussissant à modifier le génome, à implanter, supprimer ou modifier de nouveaux gènes dans des organismes vivants : il s'agit des organismes génétiquement modifiés (OGM). Les mêmes progrès ont ouvert une nouvelle voie d'approche thérapeutique : la « thérapie génique ». Il s'agit d'introduire de nouveaux gènes dans l'organisme afin de pallier une déficience héréditaire.

L'évolution sans cesse croissante de la connaissance en génétique pose plusieurs problèmes éthiques liés au clonage, aux divers types d'eugénismes possibles, à la propriété intellectuelle de gènes et aux possibles risques environnementaux dus aux OGM. La compréhension du fonctionnement de la machinerie cellulaire est ainsi rendue plus complexe : en effet, plus on l'étudie, plus les acteurs sont nombreux (ADN, ARN messager, de transfert, microARN) et le nombre de rétro-actions (épissage, édition) entre ces acteurs grandit.

En 1862, Charles Naudin est primé par l'Académie des sciences pour son "Mémoire sur les hybrides du règne végétal".

En 1865, passionné de sciences naturelles, le moine autrichien Gregor Mendel, dans le jardin de la cour de son monastère, décide de travailler sur des pois comestibles présentant sept caractères (forme et couleur de la graine, couleur de l'enveloppe), dont chacun peut se retrouver sous deux formes différentes. À partir de ses expériences, il publie, en 1866 sous l'autorité de la "Société des sciences naturelles de Brünn", un article où il énonce les lois de transmission de certains caractères héréditaires. Cet article, « », est envoyé aux scientifiques des quatre coins du monde : les réactions sont mitigées, voire inexistantes.
Ce n'est qu'en 1907 que son article fut reconnu et traduit en français.

En 1869 l'ADN est isolé par Friedrich Miescher, un médecin suisse. Il récupère les bandages ayant servi à soigner des plaies infectées et il isole une substance riche en phosphore dans le pus. Il nomme cette substance nucléine. Il trouve la nucléine dans toutes les cellules et dans le sperme de saumon.

En 1879, Walther Flemming décrit pour la première fois une mitose. La mitose avait déjà été décrite 40 ans avant par Carl Nageli mais celui-ci avait interprété la mitose comme une anomalie. Walter Flemming invente les termes prophase, métaphase, et anaphase pour décrire la division cellulaire. Son travail est publié en 1882.

En 1880, Oskar Hertwig et Eduard Strasburger découvrent que la fusion du noyau de l'ovule et du spermatozoïde est l'élément essentiel de la fécondation.

En 1891, Theodor Boveri démontre et affirme que les chromosomes sont indispensables à la vie

En 1900, redécouverte des lois de l'hérédité : Hugo de Vries, Carl Correns et Erich von Tschermak-Seysenegg redécouvrent de façon indépendante les lois de Mendel.

En 1902, Walter Sutton observe pour la première fois une méiose, propose la théorie chromosomique de l'hérédité, c'est-à-dire que les chromosomes seraient les supports des gènes. Il remarque que le modèle de séparation des chromosomes supporte tout à fait la théorie de Mendel. Il publie son travail la même année. Sa théorie sera démontrée par les travaux de Thomas Morgan. 
Première description d'une maladie humaine héréditaire par Archibald Garrod : l'alcaptonurie.

En 1909, Wilhelm Johannsen crée le terme gène et fait la différence entre l'aspect d'un être (phénotype) et son gène (génotype). William Bateson, quatre ans avant, utilisait le terme génétique dans un article et la nécessité de nommer les variations héréditaires.

En 1911, Thomas Morgan démontre l'existence de mutations en conduisant des expériences sur des drosophiles mutantes aux yeux blancs (mouches du vinaigre). Il montre que les chromosomes sont les supports des gènes, grâce à la découverte des liaisons génétiques ("genetic linkage") et des recombinaisons génétiques. Il travaille avec Alfred Sturtevant, Hermann Muller, et Calvin Bridges. Il reçoit le prix Nobel de Médecine en 1933.
Ses expériences permettront de consolider la théorie chromosomique de l'hérédité.

En 1913, Morgan et Alfred Sturtevant publient la première carte génétique du chromosome X de la drosophile, montrant l'ordre et la succession des gènes le long du chromosome.

En 1928, Fred Griffith découvre la transformation génétique des bactéries, grâce à des expériences sur le pneumocoque. La transformation permet un transfert d'information génétique entre deux cellules. Il ne connaît pas la nature de ce "principe transformant".

En 1941, George Beadle et Edward Tatum émettent l'hypothèse qu'un gène code une (et uniquement une) enzyme en étudiant "Neurospora crassa".

En 1943, la diffraction au rayon X de l'ADN par William Astbury permet d'émettre la première hypothèse concernant la structure de la molécule : une structure régulière et périodique qu'il décrit comme une pile de pièces de monnaie ("").

En 1944, Oswald Avery, Colin MacLeod, et Maclyn McCarty démontrent que l'ADN est une molécule associée à une information héréditaire et peut transformer une cellule.

Barbara McClintock montre que les gènes peuvent se déplacer et que le génome est beaucoup moins statique que prévu. Elle reçoit le prix Nobel de Médecine en 1983.

En 1950, la structure chimique de l'ADN a été définie par Phoebus Levene (post mortem) et Alexander Robert Todd.

En 1952, Alfred Hershey et Martha Chase découvrent que seul l'ADN d'un virus a besoin de pénétrer dans une cellule pour l'infecter. Leurs travaux renforcent considérablement l'hypothèse que les gènes sont faits d'ADN.

En 1953, simultanément aux travaux de recherche de Maurice Wilkins et Rosalind Franklin qui réalisèrent un cliché d'une molécule d'ADN, James Watson et Francis Crick présentent le modèle en double hélice de l'ADN, expliquant ainsi que l'information génétique puisse être portée par cette molécule.
Watson, Crick et Wilkins recevront en 1962 le prix Nobel de médecine pour cette découverte.
En 1955, Joe Hin Tjio fait le premier compte exact des chromosomes humains : 46.
Arthur Kornberg découvre l'ADN polymérase, une enzyme permettant la réplication de l'ADN.

En 1957, le mécanisme de réplication de l'ADN est mis en évidence.

En 1958, le Raymond Turpin de l'hôpital Trousseau, Marthe Gautier et Jérôme Lejeune réalisent une étude des chromosomes d’un enfant dit « mongolien » et découvre l’existence d’un chromosome en trop sur la . Pour la première fois au monde est établi un lien entre un handicap mental et une anomalie chromosomique. Par la suite, Jérôme Lejeune et ses collaborateurs découvrent le mécanisme de bien d’autres maladies chromosomiques, ouvrant ainsi la voie à la cytogénétique et à la génétique moderne.

Dans les années 1960, François Jacob et Jacques Monod élucident le mécanisme de la biosynthèse des protéines. Introduisant la distinction entre « gènes structuraux » et « gènes régulateurs », ils montrent que la régulation de cette synthèse fait appel à des protéines et mettent en évidence l'existence de séquences d'ADN non traduites mais jouant un rôle dans l'expression des gènes. Le principe de code génétique est admis.

En 1961, François Jacob, Jacques Monod et André Lwoff avancent conjointement l'idée de programme génétique.

En 1962, Crick, Watson et Wilkins reçoivent le prix Nobel de médecine pour avoir établi que les triplets de bases étaient des codes. Le comité Nobel évoquera "la plus grande réussite scientifique de notre siècle".

En 1966, J.L. Hubby et Richard C. Lewontin ouvrent la voie au domaine de la recherche sur l'évolution moléculaire en introduisant les techniques de la biologie moléculaire comme l'électrophorèse sur gel dans la recherche sur la génétique des populations.

1968 : prix Nobel décerné pour le déchiffrage du code génétique.

1975 : autre prix Nobel pour la découverte du mécanisme de fonctionnement des "virus".

La génomique devient dès lors l'objet d'intérêts économiques importants.

Dans le même temps, la sociobiologie et la psychologie évolutionniste d’Edward O. Wilson se fondent sur l'idéologie du déterminisme génétique que génère l'idée - devenue fausse - de programme génétique. De la sorte, c'est-à-dire selon une conception évolutionniste (linéaire et réductionniste) générée par le néodarwinisme et le mythe du Graal de la génétique, ces deux domaines débordent sur la sphère sociale et politique. C'est ainsi que, tout en apportant une conception scientifique selon une pensée , Stephen Jay Gould, Richard C. Lewontin et quelques autres membres du groupe de "Science for the People" ont démarré la polémique encore en cours sur la sociobiologie et la psychologie évolutionniste.

En 1980, la Cour Suprême des États-Unis admet pour la première fois au monde le principe de brevetabilité du vivant pour une bactérie génétiquement modifiée (oil-eating bacteria). Cette décision juridique est confirmée en 1987 par l’Office Américain des Brevets, qui reconnaît la brevetabilité du vivant, à l’exception notable de l’être humain.

En 1986, est réalisé le premier essai en champ de plante transgénique (un tabac résistant à un antibiotique).

En 1989, il est décidé de décoder les 3 milliards de paires de bases du génome humain pour identifier les gènes afin de comprendre, dépister et prévenir les maladies génétiques et tenter de les soigner.
Une première équipe se lance dans la course : le Human Genome Project, coordonné par le NIH (National Institutes of Health) et composé de 18 pays dont la France avec le Génoscope d'Évry qui sera chargée de séquencer le chromosome 14.

Dans les années 1990, à Évry, des méthodologies utilisant des robots sont mises au point pour gérer toute l'information issue de la génomique.

En 1992, l’Union européenne reconnaît à son tour la brevetabilité du vivant et accorde un brevet pour la création d’une souris transgénique. Elle adopte en 1998 la directive sur la brevetabilité des inventions biotechnologiques : sont désormais brevetables les inventions sur des végétaux et animaux, ainsi que les séquences de gènes. En 1998, l’Europe adopte une Directive fondamentale relative à la protection des inventions biotechnologiques : sont désormais brevetables les inventions sur des végétaux et animaux, ainsi que les séquences de gènes.

Dans le même temps les premiers Mouvement anti-OGM se forment contre le lobby du ' dans le domaine de l'OGM. Les OGM, "organismes génétiquement modifiés" sont en réalité pour le généticien Richard C. Lewontin et Jean-Pierre Berlan des CCB, "clones chimériques brevetés". Cela ouvre de nombreux débats politiques et médiatiques, divers et variés, sur l'OGM conduisant à des réglementations.

En 1992-1996, les premières cartes génétiques du génome humain sont publiées par J. Weissenbach et D. Cohen dans un laboratoire du Généthon.

En 1998, créée par Craig Venter et Perkin Elmer (leader dans le domaine des séquenceurs automatiques), la société privée Celera Genomics commence elle aussi le séquençage du génome humain en utilisant une autre technique que celle utilisée par le NIH.

En 1999, un premier chromosome humain, le 22, est séquencé par une équipe coordonnée par le centre Sanger, au Royaume-Uni.

En , le NIH et Celera Genomics annoncent chacun l'obtention de 99 % de la séquence du génome humain.
Les publications suivront en 2001 dans les journaux Nature pour le NIH et Science pour Celera Genomics.

En , des chercheurs japonais de l'Université de Tokyo ont introduit 2 nouvelles bases, S et Y, aux 4 déjà existantes (A, T, G, C) sur une bactérie de type "Escherichia coli", ils l'ont donc dotée d'un patrimoine génétique n'ayant rien de commun avec celui des autres êtres vivants et lui ont fait produire une protéine encore inconnue dans la nature. Certains n'hésitent pas à parler de nouvelle genèse, puisque d'aucuns y voient une nouvelle grammaire autorisant la création d'êtres vivants qui non seulement étaient inimaginables avant mais qui, surtout, n'auraient jamais pu voir le jour.

Le , la fin du séquençage du génome humain est annoncée.

Les années 2010 vont vers la fin du "tout gène" et du réductionnisme de la génétique moléculaire des quarante dernières années avec la découverte de phénomènes épigénétiques liés à l'influence de l'environnement sur le gène.

Un gène est une unité d'information génétique, constitué par plusieurs nucléotides (1 nucléotide est constitué par un groupement phosphate, un sucre et une base azotée). Cette information génétique est utilisée : 1/pour la biosynthèse des protéines 2/lors de la formation d'un embryon.

Plus largement dans une définition prenant en compte les découvertes récentes, notamment sur les microARN, on peut dire qu'un gène est « l'ensemble des séquences d'ADN qui concourent à la production régulée d'un ou plusieurs ARN, ou d'une ou plusieurs protéines ».

L'information génétique est portée par l'acide désoxyribonucléique, ou ADN. L'ADN est une macromolécule formée par l'enchainement de nombreux nucléotides. Chaque nucléotide est formé d'un groupement phosphate, d'un glucide, le désoxyribose, et d'une base azotée. Il existe quatre bases azotées différentes donc quatre nucléotides différents dans l'ADN : l'adénine, la cytosine, la guanine et la thymine.

La molécule d'ADN est formée de deux chaines de nucléotides enroulées en double hélice. Les nucléotides sont complémentaires deux à deux : en face d'une cytosine se trouve toujours une guanine ; en face d'une adénine se trouve toujours une thymine.

C'est la séquence, c'est-à-dire l'ordre et le nombre des nucléotides d'un gène, qui porte l'information génétique.

L'ADN sert de support pour la synthèse des protéines. L'information génétique portée par l'ADN est « reportée » dans une molécule d'ARNm (acide ribonucléique « messager ») lors de la transcription, puis l'ARNm sert de support pour la synthèse d'une protéine lors de la traduction. Chaque triplet de nucléotide (ou codon) de l'ARNm « code » un acide aminé (cela signifie que chaque triplet « appelle » un acide aminé précis), selon la correspondance établie par le code génétique. Ainsi la séquence en acides aminés de la protéine dépend directement de la séquence en nucléotides de l'ADN. Or les protéines forment le phénotype moléculaire de la cellule ou de l'individu. Le phénotype moléculaire conditionne le phénotype cellulaire et finalement le phénotype de l'organisme.

Tous les organismes vivants : animaux, végétaux, sont constitués de cellules. Ainsi, un être humain est composé de, selon les auteurs, milliards à milliards de cellules. Toutes les cellules d'un être vivant proviennent de la même cellule initiale qui s'est divisée un très grand nombre de fois, au cours de l'embryogenèse puis du développement fœtal.

Au cours d'un cycle cellulaire (succession des étapes de la vie de la cellule), la cellule réplique son ADN, c'est-à-dire que toute l'information génétique est dupliquée à l'identique : elle se retrouve avec deux « copies » complètes de son information génétique, ses chromosomes sont constitués de deux chromatides identiques. Lors de la division cellulaire, ou mitose, les deux chromatides de chaque chromosome se séparent pour former deux lots identiques de chromosomes (à une seule chromatide). Chaque cellule fille reçoit un de ces lots. Ainsi, au terme d'une mitose, les deux cellules filles issues de la cellule mère possèdent exactement le même patrimoine génétique : elles sont des copies conformes l'une de l'autre.

Les débuts de la génétique ont été influencés par deux idéologies dominantes et hégémoniques opposées et exacerbées dans les années 1930 :

Ces oppositions idéologiques s'ouvrent sur la question philosophique de l'inné ou de l'acquis de l'acquisition des connaissances des individus et du développement de la culture humaine bien qu'elle fût résolue scientifiquement par Charles Darwin dès 1871 dans le passé-inaperçu "La filiation de l'homme". Il n'y a pas d'opposition entre l'inné (génétique) et l'acquis (l'environnement). Cependant, pour les néo-darwinistes ou sociobiologistes, la question se pose encore sur le comportement de l'homme. Mais, pour le généticien Richard C. Lewontin, .

Lors de l'ouverture de la quête du Graal que fut le Projet génome humain pour les généticiens, le laboratoire Celera Genomics dirigée par Craig Venter conduit une course contre le consortium international public pour obtenir le premier des séquences génétiques dans le but de les breveter et de les vendre aux sociétés pharmaceutiques.

Une étude de 2005 révèle que 20 % des gènes humains font l’objet d’un brevet : 63 % de ces brevets appartiennent à des firmes privées, 28 % à des universités.

Le brevetage d'une partie des gènes constitue donc un frein à la découverte de leur fonction.

Par exemple, la compagnie Myriad dépose un brevet sur l’utilisation des gènes BRCA1 et BRCA2 séquencé en 1994/1995 comme indicateurs de risques pour le cancer du sein et de l’ovaire, maladie dont les gènes ont été associés. Le test coûte d'abord et son prix est passé à en 2009. Ce brevet représente l’essentiel des revenus annuels de la compagnie. Ainsi, le brevet qui donne le droit de propriété exclusif sur la séquence, empêche complètement d’autres compagnies de développer des tests alternatifs utilisant ces mêmes gènes.

Cependant en 2010, ce brevet est annulé car le caractère inventif du test est contesté par le bureau européen des brevets. En effet, le séquençage ne constitue pas une invention, mais une découverte. La méthode se limite à comparer une séquence de l’échantillon à une séquence de référence, et n’est pas brevetable en soi (Directive sur la brevetabilité des inventions biotechnologiques). Ainsi, pour une plus grande liberté de la recherche alternative la cour a donné son verdict : 



</doc>
<doc id="15754" url="https://fr.wikipedia.org/wiki?curid=15754" title="Physique quantique">
Physique quantique

La physique quantique est l'appellation générale d'un ensemble de théories physiques nées au qui, comme la théorie de la relativité, marque une rupture avec ce que l'on appelle maintenant la physique classique, qui regroupe par définition les théories et principes physiques connus au .

Les théories dites « quantiques » décrivent le comportement des atomes et des particules — ce que la physique classique (notamment la mécanique newtonienne et la théorie électromagnétique de Maxwell) n'avait pu faire — et permettent d'élucider en particulier certaines propriétés du rayonnement électromagnétique qui restaient inexpliquées par la physique classique.

Au cours du , les cristallographes et les chimistes essaient de prouver l'existence des atomes, mais ce n'est qu'au début du qu'ils seront définitivement mis en évidence, grâce à la diffraction des rayons X. Pour les modéliser, la quantification de la matière est un passage obligé, ce qui donne naissance à la physique quantique. En 1900, Max Planck émet l'hypothèse que les échanges d'énergie avec la matière se font par petites quantités : les « quanta ».

Louis de Broglie initie alors la mécanique quantique qui permet de modéliser correctement l'atome. La physique quantique finit par absorber tous les domaines de la physique classique en une seule discipline. Les accélérateurs de particules montrent alors que les atomes sont composés de particules plus élémentaires, comme le proton ou le neutron, eux-mêmes composés de quarks. C'est la théorie quantique des champs, construite à partir de l'électrodynamique quantique qui décrira l'ensemble des particules élémentaires.

La physique quantique a apporté une révolution conceptuelle ayant des répercussions jusqu'en philosophie (remise en cause du déterminisme) et en littérature (science-fiction). Elle a permis nombre d'applications technologiques : énergie nucléaire, imagerie médicale par résonance magnétique nucléaire, diode, transistor, circuit intégré, microscope électronique et laser. Un siècle après sa conception, elle est abondamment utilisée dans la recherche en chimie théorique (chimie quantique), en physique (mécanique quantique, théorie quantique des champs, physique de la matière condensée, physique nucléaire, physique des particules, physique statistique quantique, astrophysique, gravité quantique), en mathématiques (formalisation de la théorie des champs) et, récemment, en informatique (ordinateur quantique, cryptographie quantique). Elle est considérée avec la relativité générale d'Einstein comme l'une des deux théories majeures du .

La physique quantique est connue pour être contre-intuitive, choquer le « sens commun » et nécessiter un formalisme mathématique ardu. Feynman, l'un des plus grands théoriciens spécialistes de la physique quantique de la seconde moitié du , a ainsi écrit :

La raison principale de ces difficultés est que le monde quantique (limité à "l'infiniment petit", mais pouvant avoir des répercussions à plus grande échelle) se comporte très différemment de l'environnement macroscopique auquel nous sommes habitués. Quelques différences fondamentales qui séparent ces deux mondes sont par exemple :


Existe-t-il dans le monde du vivant des phénomènes obéissant à ces règles de l'infiniment petit ? Depuis quelques années, des études dans divers domaines de la biologie indiquent que c'est le cas. Ces résultats vont à contre-courant de l'idée généralement admise que le monde macroscopique est trop chaotique pour permettre des effets de cohérence quantique. Le vivant serait capable de tirer parti de cette agitation désordonnée des particules, du moins en ce qui concerne la photosynthèse. Les récepteurs de l'odorat semblent dépendre de l'effet tunnel, pour acheminer des électrons à l'intérieur même des molécules odorantes, ce qui permet de les distinguer d'autres molécules structurellement analogues. Certaines structures protéiques bactériennes se comportent comme des ordinateurs quantiques primitifs, « calculant » le meilleur canal de transport des électrons parmi tous les chemins possibles.
De récents travaux sur la photosynthèse ont révélé que l'intrication des photons joue un rôle essentiel à cette opération fondamentale du règne végétal, phénomène que l'on tente actuellement d'imiter pour optimiser la production d'énergie solaire.

L'adhérence aux surfaces des setæ des geckos fonctionne grâce aux forces de van der Waals, des interactions de nature quantique qui font intervenir des particules virtuelles sans aucune interaction moléculaire classique. Ce phénomène est également à l'étude en vue d'applications militaires et civiles.

Des physiciens américains sont parvenus à observer la trace des premiers instants du Big Bang, atteignant un des « objectifs les plus importants de la cosmologie aujourd'hui » selon les termes de John Kovac, professeur à Harvard et responsable de l'équipe à l'origine de cette découverte en mars 2014. La survenue du Big Bang marquant la naissance de l'Univers il y a 13,8 milliards d'années, s'est accompagnée de l'émission d'ondes gravitationnelles primordiales. L'observation de l'empreinte que ces ondes ont laissée sur le rayonnement fossile a été effectuée via le télescope Bicep 2.

Ces données confirment « la relation profonde entre la mécanique quantique et la théorie de la relativité générale ». Pour Tom Le Compte, physicien au CERN, cette découverte « est la plus grande annonce en physique depuis des années », et « peut être couronnée d'un prix Nobel » pour leurs auteurs. Mais cette annonce a été démentie par les mesures faites par le satellite Planck, ce dernier étant capable de différencier les effets de poussières de la Galaxie.

L'expérience originelle de Thomas Young avait mis en évidence le comportement ondulatoire de la lumière en montrant que deux faisceaux lumineux pouvaient entrer en interférence. L'expérience des fentes de Young, effectuée avec une seule particule (en faisant en sorte que la source d'émission n'émette qu"un quantum à la fois"), montrera qu'un seul électron « interfère avec lui-même » et produit des franges d'interférences au sortir des "deux" fentes, comme s'il s'agissait de deux flux de particules interférant l'un avec l'autre.

Dans la mécanique classique, la trajectoire d'une particule chargée ne peut pas être affectée par la présence d'un champ magnétique si elle se trouve hors de ce champ. L'effet Aharonov-Bohm est un phénomène quantique décrit en 1949 par Ehrenberg et Siday et redécouvert en 1959 par David Bohm et Yakir Aharonov. Il décrit le paradoxe suivant :

L'effet Aharonov-Bohm démontre donc que ce sont les potentiels électromagnétiques, et non les champs électriques et magnétiques, qui fondent la mécanique quantique. En physique quantique, une entité mathématique utile, le potentiel vecteur magnétique, peut avoir de véritables effets.

L'expérience de Stern et Gerlach fut l'une des premières à mettre en évidence la nature purement quantique du monde microscopique et plus particulièrement du spin. Construite en 1921-1922 pour tester l'hypothèse de quantification spatiale, elle ne put obtenir une description théorique satisfaisante que cinq ans plus tard grâce au développement de la mécanique quantique.

L'expérience d'Aspect est, historiquement, la première expérience qui a réfuté de manière satisfaisante les inégalités de Bell dans le cadre de la physique quantique, validant ainsi le phénomène d'intrication quantique, et apportant une réponse expérimentale au paradoxe EPR.

Concrètement, elle consiste à produire deux photons dans un état intriqué formula_1 puis à les séparer pour réaliser enfin la mesure de leur polarisation. La mesure du premier photon a alors 50 % de chance de donner formula_2 et autant de donner formula_3 tandis que le second photon est immédiatement projeté dans ce même état. Le paradoxe provient du fait que les deux photons semblent s’échanger cette information à une vitesse supérieure à celle de la lumière. Ce point n'est cependant pas pertinent car aucune information ne peut être transmise par ce moyen.

L'intrication quantique permet cependant d'échanger une clé de chiffrement de manière sûre, ce qu'exploite la cryptographie quantique.

L’expérience de la gomme quantique à choix retardé constitue une extension de celle d'Alain Aspect et des fentes d'Young, mais y introduit ce qui semble être une "rétroaction implicite dans le temps" : un effet du présent sur le passé.

Les paradoxes liés à la mesure amènent à se poser la question : la physique quantique décrit-elle la réalité ?

Théories « à variables cachées »

D’après les théories classiques de la physique, un corps noir à l'équilibre thermodynamique est censé rayonner un flux infini. Plus précisément, l'énergie rayonnée par bande de longueur d'onde doit tendre vers l'infini quand la longueur d'onde tend vers zéro, dans l'ultraviolet pour les physiciens de l'époque, puisque ni les rayons X ni les rayons gamma n'étaient alors connus. C’est la catastrophe ultraviolette.

Elle remonte aux travaux effectués en 1900 par Max Planck sur le rayonnement du corps noir à l’équilibre thermique. Une cavité chauffée émet un rayonnement électromagnétique (lumière) aussitôt absorbé par les parois. Pour rendre compte du spectre lumineux par le calcul théorique des échanges d’énergie d’émission et d’absorption (formula_4), Planck dut faire l’hypothèse que ces échanges sont discontinus et proportionnels aux fréquences (formula_5) du rayonnement lumineux : formula_6.


En 1905, à la suite d’un raisonnement thermodynamique dans lequel il donnait aux probabilités un sens physique (celui de fréquences d’états pour un système), Einstein fut amené à considérer que ce ne sont pas seulement les échanges d’énergie qui sont discontinus, mais l’énergie du rayonnement lumineux elle-même.
Il montra que cette énergie est proportionnelle à la fréquence de l’onde lumineuse :
E=hν.
Cela donnait immédiatement l’explication de l’effet photoélectrique observé 20 ans auparavant par Hertz.

L’énergie formula_10 apportée par le quantum de lumière à l’électron lié dans un atome permet à celui-ci de se libérer si cette énergie est supérieure ou égale à l’énergie de liaison de l’électron, nommée également travail de sortie formula_11, en vertu de la relation :

formula_12

où formula_13 est l'énergie cinétique acquise par ce dernier.
Cet effet de seuil était inexplicable dans la conception continue de l’énergie lumineuse de la théorie électromagnétique classique.

Einstein s’aperçut alors que cette propriété du rayonnement était en opposition de manière irréductible avec la théorie électromagnétique classique (élaborée par Maxwell).
Dès 1906, il annonça que cette théorie devrait être modifiée dans le domaine atomique.
La manière dont cette modification devrait être obtenue n’était pas évidente puisque la physique théorique reposait sur l’utilisation d’équations différentielles, dites équations de Maxwell, correspondant à des grandeurs à variation continue.

Malgré la puissance de la théorie des quanta, peu de physiciens étaient enclins à imaginer que la théorie électromagnétique classique puisse être invalidée. Einstein s’efforça alors de mettre en évidence d’autres aspects des phénomènes atomiques et du rayonnement qui rompaient avec la description classique. Il étendit ainsi l’hypothèse quantique, par-delà les propriétés du rayonnement, à l’énergie des atomes, par ses travaux sur les chaleurs spécifiques aux basses températures. Il retrouvait l’annulation des chaleurs spécifiques des corps au zéro absolu, phénomène observé mais inexplicable par la théorie classique.
D’autres physiciens (P. Ehrenfest, W. Nernst, H.-A. Lorentz, H. Poincaré) le rejoignirent peu à peu pour conclure au caractère inéluctable de l’hypothèse quantique que Planck lui-même hésitait à admettre.
Elle n’était cependant encore acceptée généralement que pour les échanges d’énergie.



Ouvrages récents

Ouvrages plus anciens









</doc>
<doc id="15756" url="https://fr.wikipedia.org/wiki?curid=15756" title="Coleoptera">
Coleoptera

Les coléoptères (Coleoptera) sont un ordre d'insectes dotés d'élytres protégeant leurs ailes. Le mot « coléoptère » vient du grec "κολεός" « fourreau » et "πτερόν" « aile ». Il s'agit de l'ordre qui comporte le plus grand nombre d'espèces (environ 360 000 décrites). Beaucoup d'espèces ou des groupes d'espèces ont des noms vernaculaires bien implantés ; les scarabées, les coccinelles, les lucanes, les chrysomèles, les hannetons, les charançons, les carabes, par exemple, sont des coléoptères. Ils vivent pratiquement dans tous les biotopes, excepté les milieux polaires et océaniques. Ils possèdent en général deux paires d'ailes. La première paire d'ailes, quelquefois très colorée, appelée élytres, forme la carapace de ces insectes et la deuxième paire, les ailes membraneuses, servent au vol.

La discipline de l'entomologie s'occupant plus particulièrement des coléoptères est nommée "coléoptérologie".

L'ordre des coléoptères est le plus nombreux de la classe des insectes. Selon les estimations, on retrouverait plus de 1 million d'espèces décrites et non décrites à travers le monde. Ce groupe constitue près de 25 % de la diversité animale. Près de 40 % des espèces d'insectes décrites font partie de cet ordre. Les familles de coléoptères les plus abondantes sont celles des staphylinidae (staphylin) et des curculionidae (charançon).

Les coléoptères sont très diversifiés et ils sont présents dans tous les principaux habitats à l'exception des régions polaires et marines. Ils sont aussi adaptés à différents rôles écologiques. On retrouve des détritivores non spécialistes, décomposant les débris de végétaux. Il y a certains coléoptères qui se nourrissent de charogne ou d'excréments. Certains se nourrissent de champignons et d'autres sont exclusifs à un type de plante. Il y a des insectes phytophages généralistes qui s'alimentent de pollens, de fleurs et de fruits. On retrouve aussi des prédateurs et des parasites qui s'attaquent à d'autres invertébrés. Bon nombre d'espèces sont utilisées comme agents de contrôle en agriculture, comme les coccinelles, les carabes et les staphylins.

Ils font également partie de la chaîne alimentaire en étant la proie de divers invertébrés et vertébrés, comme les poissons, les reptiles, les oiseaux et les mammifères. Parmi cet ordre, certains sont considérés comme des ravageurs en agriculture ou dans l'industrie alimentaire, comme le doryphore de la pomme de terre ("Leptinotarsa decemlineata"), la bruche ("Callosobruchus maculatus") et le tribolium rouge de la farine ("Tribolium castaneum").

L'orde des coléoptères est le plus abondant avec près de à espèces décrites divisées en quatre sous-ordres (Adephaga, Archostemata, Myxophaga et Polyphaga). Cela équivaut à 40 % de toutes les espèces d'insectes décrites et environ 30 % des espèces animales. Bien que la classification soit encore sujette à des changements, on retrouve environs 500 familles et sous-familles.

Les coléoptères sont caractérisés par un exosquelette particulièrement dur. Cette structure constitue également la première paire d'ailes (élytres). Cet exosquelette est fait de nombreuses plaques, nommées sclérites et celles-ci sont séparées par de minces sutures. Cette conception permet au corps d'être bien protégé tout en conservant sa flexibilité. L'anatomie générale est assez uniforme à travers l'ordre, bien que les organes et les appendices puissent varier considérablement en apparence. Comme tous les insectes, leur corps est divisé en trois sections: la tête, le thorax et l'abdomen.

La tête est largement sclérifiée et varie en taille. Les pièces buccales sont de type broyeuse et elles se retrouvent à l'avant de la tête. Les yeux sont composés et très variable d'une famille à l'autre. Comme chez les Gyrinidae, qui sont répartis de manière à permettre une vue au-dessus et en dessous de l'eau. On retrouve également des ocelles, des petits yeux simples généralement situés plus loin, sur le sommet de la tête.

Les antennes sont les organes principaux pour l'odorat. Ils peuvent également servir d'organes tactiles pour analyser l'environnement, de moyen de communication pour l'accouplement ou encore de moyen de défense. Les antennes sont très variables chez les familles de coléoptères. De plus, au sein de la même espèce, on retrouve également de légères différences entre les sexes. On retrouve plusieurs types d'antennes, les principales sont : filiforme, moniliforme, capitiforme, claviforme, styliforme, serriforme, pectiniforme, lamelliforme, et flabelliforme.

Les coléoptères ont des pièces buccales similaires à l'ordre des orthoptères. Parmi ces pièces, on retrouve les mandibules, qui apparaissent comme de grandes pinces sur le devant de la tête. Elles se déplacent horizontalement et servent à saisir, écraser ou couper la nourriture ou les ennemis. Chez certaines espèces, les mandibules des mâles sont très développés et nettement élargie comparativement à celle des femelles.

On retrouve aussi les maxillaires et les palpes labiaux, des appendices en forme de doigts qui se trouvent autour de la bouche de la plupart des coléoptères. Ils servent à déplacer la nourriture à l'intérieur de celle-ci.

Le thorax est segmenté en deux parties distinctes : le pro et le pterathorax. Le pterathorax comprend le mésothorax et le métathorax fusionnés. C'est également la partie du corps à laquelle les trois paires de pattes sont attachées. L'abdomen est postérieur au thorax.

Les pattes sont composées de plusieurs segments : coxa, trochanter, fémur, tibia et tarse. Ce dernier est segmenté généralement en deux ou cinq articles. À l'extrémité, on retrouve des griffes, généralement une paire. Les pattes servent principalement pour la locomotion et elles peuvent être de différentes formes. Chez les familles de coléoptères aquatiques, comme les Dytiscidae, Haliplidae ou Hydrophilidae, la dernière paire de pattes porte une rangée de longs poils et est adaptée pour la nage. Certains coléoptères, comme les scarabées et certains carabes, ont des pattes élargies et épineuses du type fouisseuses pour les aider à creuser. D'autres possèdent des fémurs plus larges et peuvent réaliser des bonds assez impressionnants, comme chez les altises et certaines espèces de charançons.

Les ailes antérieures, appelées élytres, sont connectées au pterathorax. Elles sont épaisses et opaques. Les élytres ne sont pas utilisés lors du vol. Au repos, ils couvrent et protègent les ailes postérieures, qui sont membraneuses et plus fragiles. Chez certains coléoptères, la capacité de voler a été perdue. Dans cette catégorie, on retrouve certains carabes, certains charançons et des espèces désertiques et cavernicoles. Dans quelques rares familles, les coléoptères ne sont pas capables de voler et n'ont également pas d'élytres. Par exemple certaines femelles de la famille des Phengodidae et des Lampyridae ne possèdent ni ailes et ni élytres.

L'abdomen est la partie derrière le métathorax et est composé d'une série d'anneaux. Ces segments possèdent une série de petits trous, appelés stigmates, qui permettent à l'insecte de respirer. Les deux principaux types sont les tergites (sur la face dorsale) et les sclérites (sur la face ventrale). Ces deux plaques sont articulées latéralement (pleure) par un repli membranaire (conjonctive) extensible, appelé repli tégumentaire pleural. Chez la plupart des coléoptères, les tergites sont membraneux et elles sont cachées sous les élytres au repos. Les sclérites sont généralement plus larges et ils sont bien visibles sous l'abdomen. Leur niveau de sclérification peut être très variable. L'abdomen n'a pas d'appendices, mais quelques insectes (par exemple : Mordellidae) ont des lobes sternaux articulés.

La plupart des coléoptères réalisent une métamorphose complète (holométabole). En général, le développement se réalise en quatre étapes : l'œuf, la larve, la nymphe et l'imago ou adulte. La nymphe est parfois appelée chrysalide. Chez certaines espèces, la nymphe peut être cachée à l'intérieur d'une cavité ou d'un cocon. Certains types de coléoptères réalisent une métamorphose du type hypermétabole. Ces insectes ont une étape de transformation de plus, entre la larve typique et la nymphe. Par exemple, chez les Meloidae, on retrouve l'œuf, la première étape larvaire qui comprend une larve mince et adaptée à la locomotion, une deuxième étape larvaire avec une larve massive et sédentaire, une nymphe et finalement un adulte.

Les comportements de reproduction chez les coléoptères peuvent être très diversifiés. Pendant la période de reproduction des insectes, la communication se réalise principalement par la sécrétion de phéromones. Le mâle peut donc trouver l'emplacement d'une femelle réceptive de cette manière. Les phéromones sont propres à chaque espèce et elles sont constituées de différentes molécules chimiques. Par exemple, les phéromones de certains scarabées de la sous-famille des Rutelinae sont composés majoritairement d'une synthèse d'acide gras. D'autres, comme dans la sous-famille des Melolonthinae, sont plutôt composés d'acides aminés et d'acides terpéniques.

Une autre technique de communication est l'utilisation de la bioluminescence. Chez les coléoptères, cette forme d'appel se limite à la famille des Lampyridae et des Phengodidae. Les individus de ces familles produisent de la lumière qui est fabriquée par des organes à l'intérieur de leur abdomen. Les mâles et les femelles communiquent de cette manière durant la période de reproduction. Les signaux sont différents d'une espèce à l'autre (la durée, la composition, la chorégraphie aérienne et dans l'intensité).

Pendant la période de reproduction, le mâle et la femelle peuvent s'engager dans une parade nuptiale. Ils peuvent faire striduler leurs ailes, créer des sons ou faire vibrer les objets sur lesquelles ils se trouvent. Chez certaines espèces, comme chez les Meloidae, le mâle monte sur le dos de la femelle et lui caresse les antennes et les palpes labiaux avec ses antennes.

La compétition est féroce et beaucoup de mâles affichent des comportements territoriaux et agressifs. Ils sont prêts à se battre pour conserver un petit territoire ou un avoir la chance de se reproduire avec une femelle. Chez certaines espèces, les mâles possèdent des cornes et des protubérances sur leur tête ou leur thorax. Ces ornements servent à combattre d'autres mâles de la même espèce.

L'accouplement est généralement rapide mais chez certaines espèces il peut durer plusieurs heures. Au cours de la liaison, les spermatozoïdes sont transférés à l'intérieur de la femelle pour féconder les œufs.

Durant sa vie, une femelle peut produire entre une dizaine d'œufs à plusieurs milliers. Les œufs sont pondus en fonction du substrat sur lequel les larves se développeront. Par exemple, dans la farine, les adultes de ténébrions déposent leurs œufs de manière aléatoire. Chez certains Chrysomelidae et les Coccinellidae, les œufs sont pondus en masse sur le feuillage ou posés individuellement sur le plant. D'autres pondent à l'intérieur des racines à l'aide d'un ovipositeur spécialisé (ex : charançon de la carotte).

Les soins parentaux apportés aux œufs varient selon les espèces, allant de la simple pose d'œuf sous une feuille à la construction de structures souterraines spécialisées. Certains coléoptères mordent certaines parties d'une feuille pour la faire rouler sur elle-même et ensuite ils pondent leurs œufs à l'intérieur. Cette structure protégera leurs œufs des intempéries et d'éventuels prédateurs.

Chez la chrysomèle "Mimosestes amicus", on retrouve une stratégie de ponte d'œufs non fécondés, empilés sur des œufs fécondés, de manière à les protéger des parasitoïdes.

L'ovoviviparité est présente chez certaines espèces. Généralement, on retrouve cette stratégie de reproduction chez les insectes qui occupent des environnements dangereux pour le développement des œufs. Certaines femelles de Chrysomelidae vivant dans les zones montagneuses ou subarctiques pratiquent l'ovoviviparité .

C'est généralement au stade de larve que l'insecte s'alimente le plus. Une fois sortie de l'œuf, ils ont tendance à être très vorace. Chez les phytophages, certaines espèces se nourrissent des parties externes des végétaux, comme du feuillage, de la tige, des fleurs ou encore des fruits. D'autres se retrouvent à l'intérieur et se nourrissent du cambium, comme chez les Buprestidae et les Cerambycidae. Les larves de plusieurs familles, comme Carabidae, Coccinellidae, Dytiscidae et Staphylinidae sont prédatrices. La période larvaire est très variable selon les espèces et des conditions environnementales présentes.

Les larves de coléoptères peuvent être identifiées par leur tête sclérifiée, la présence de pièces buccales du type broyeur et l'absence de pseudopode. Leur thorax est difficilement distinguable de leur abdomen. Comme chez les coléoptères adultes, les larves sont très variées en apparence. Chez certaines familles, les larves sont très aplaties et sont particulièrement mobiles comme les Carabidae et Staphylinidae. Chez d'autres, comme les Elateridae et Tenebrionidae, les larves sont complètement sclérifiées et ont une forme allongée. Chez les Scarabeidae, les larves sont plus sédentaires, dodues et en forme de « C ».

Pour compléter leur développement, les larves de coléoptères passent par plusieurs mues. Chez la plupart des espèces, la larve gagne en poids et en taille au cours de sa croissance. C'est ce qu'on appelle une métamorphose du type holométabole. Dans les coléoptères, on retrouve également des familles qui pratiquent un autre type de métamorphose : l'hypermétabole. Dans ce type de développement, la larve de type triongulin est très mobile pour ensuite devenir une larve plus sédentaire. On retrouve l'hypermétamorphose chez les Meloidae et certains Staphylinidae, comme le genre "Aleochara".

Comme tous les ptérygotes, à la fin du stade larvaire, la larve se transforme en nymphe. À partir de cette nouvelle forme, il en émergera un adulte entièrement formé. La nymphe ressemble à l'adulte, est généralement de couleur pâle, avec les pattes et les antennes recroquevillées sur son corps. Elle est restreinte en mouvement, souvent immobile et n'a pas de mandibule. C'est donc un stade très sensible pour la prédation.

Chez certaines espèces, la larve creuse une cavité ou se fabrique un abri à l'aide de matière organique pour pouvoir amorcer sa transformation.

Les coléoptères aquatiques utilisent plusieurs techniques pour retenir l'air sous la surface de l'eau. Lors de la plongée, les Dytiscidae retiennent une bulle d'air entre les élytres et l'abdomen. Les Hydrophilidae conservent une fine couche d'air à l'aide de petits poils à la surface de leur corps. Les Haliplidae utilisent leurs élytres et leur coxa pour retenir l'air. Les Gyrinidae portent simplement une bulle d'air avec eux lorsqu'ils plongent.

Les coléoptères ont développé une variété de moyens pour communiquer. Le langage chimique, par l'utilisation de phéromones est l'une de ces techniques. Ces signaux peuvent être utilisés pour attirer un partenaire sexuel, former une agrégation, pour prévenir d'un danger ou même pour se défendre.

Les phéromones d'agrégation sont utilisés pour attirer des individus de la même espèce sur une plante-hôte. Chez le dendroctone du pin ("Dendroctonus ponderosae), "le premier arrivé sur l'arbre hôte laisse une trace chimique d'invitation pour ses semblables. Cette invitation amène des individus mâles autant que des individus femelles. Si la population de dendroctone est trop importante, les individus sécrètent une phéromone d'anti-agrégation. Cela a pour effet d'éliminer la compétition et les effets néfastes d'une population trop importante.

Les phéromones peuvent être perturbées par les différentes conditions météorologiques, telles que le vent ou la température.

Certaines espèces communiquent par la stridulation, une création d'un son par frottement. Généralement, le son est produit par le frottement de micro-structures en forme de peigne. Chez le dendroctone du pin ("Dendroctonus ponderosae"), les adultes frottent leurs ailes avec leur abdomen pour créer un son inaudible pour l'homme. Cette technique de communication est aussi observée chez les longicornes (Cerambycidae).

Les représentants de plusieurs familles produisent des sons par le contact d'une partie de leur corps avec le substrat. Certains Anobiidae vivant dans les fournitures en bois créent un tic-tac sinistre pour communiquer leur emplacement à un partenaire sexuel.

Certains insectes produisent des sons retentissants comme moyens de défense. Par exemple, les carabes de la sous-famille des Brachininae produisent une excrétion d'une substance toxique par leur abdomen lorsqu'ils se sentent en danger. Chez les petites espèces, le son est minime et à peine audible. Par contre, chez les espèces tropicales, le bruit de la décharge peut ressembler à la détonation d'un fusil et par ce fait, effrayer d'éventuels prédateurs.

Chez les insectes, les soins parentaux sont relativement rares. Ils ont comme but de favoriser la survie des larves en les protégeant contre les prédateurs et les conditions environnementales défavorables. Un bon exemple de soins parentaux est chez le staphylin "Bledius spectabilis" qui vit dans les marais salants. Les œufs et les larves de cette espèce sont menacés par la marée montante. Pour améliorer les chances de survie des petits, la femelle les surveille minutieusement. Lorsque ceux-ci sont en danger d'asphyxie, le staphylin réagit et les aide en creusant. De plus, en créant de petites cavités pour les œufs et larves, elle les protège des guêpes parasitoïdes et des prédateurs.

Certaines espèces de bousiers (Scarabaeoidea) affichent également une forme de soins parentaux. Les bousiers recueillent des excréments d'animaux et créent des boules jusqu'à 50 fois supérieur à leur propre poids. Habituellement, c'est le mâle qui pousse la masse d'excréments et la femelle le suit. Lorsqu'ils trouvent un endroit avec un substrat idéal, ils s'arrêtent et enterrent la boule d'excréments. Après l'accouplement, ils vont préparer la bouse et la femelle pond ses œufs à l'intérieur. Cette boule devient un véritable garde-manger pour les larves. Chez certaines espèces, les adultes laissent les petits à eux-mêmes, chez d'autres, ils restent près d'eux pour les protéger.

On retrouve également des soins parentaux chez certaines espèces de Silphidae.

Les coléoptères sont capables d'exploiter une grande diversité de ressources alimentaires. Certains sont omnivores, mangeant des plantes et des animaux. D'autres sont très spécialisés dans leur régime alimentaire. De nombreuses espèces de Chrysomelidae, Cerambycidae, Curculionidae sont spécifiques et ne se nourrissent que d'une seule espèce de plante. Plusieurs coléoptères, comme les Carabidae et les Staphylinidae, sont principalement carnivores. Ils chassent et consomment beaucoup de petites proies, comme d'autres arthropodes, des vers de terre et des escargots. La plupart de ces prédateurs sont généralistes mais quelques espèces ont des préférences pour des proies plus spécifiques.

La matière organique en décomposition fait partie du régime alimentaire de nombreuses espèces. Dans cette catégorie, on retrouve les espèces dites coprophages (ex : Scarabeidae et Geotrupidae) qui consomment des excréments et les espèces nécrophages (ex : Silphidae) qui se nourrissent d'animaux morts.

Certains coléoptère (Coccinelles, Scarites, Chrysomèles) adoptent un comportement particulier, la thanatose qui consiste, à la moindre alerte, à replier leurs appendices et à se laisser tomber ou rouler sur le dos, simulant ainsi leur propre mort. Par ce moyen de défense, la proie désintéresse ses prédateurs, souvent des prédateurs qui préfèrent manger des insectes vivants plutôt que leur cadavres, et se fond dans le paysage.

Les coléoptères ont une variété de stratégies pour éviter d'être attaqués par des prédateurs ou des parasitoïdes. Parmi ces stratégies, on retrouve le camouflage, le mimétisme, la toxicité et la défense active.Les insectes qui pratiquent le camouflage utilisent une coloration ou une forme pour se fondre dans leur environnement. Ce type de coloration est répandu dans plusieurs familles de coléoptères, en particulier celles qui se nourrissent de bois ou de végétation (ex : Chrysomelidae et Curculionidae). Certains ont la coloration et la texture du substrat dans lequel ils vivent. Les larves de certaines espèces se camouflent à l'aide de leurs excréments. On retrouve cette pratique chez certaines Chrysomelidae. Certaines espèces ressemblent à s'y méprendre à une guêpe. Cette technique de défense se nomme mimétisme batésien. Ils jumellent leur mimétisme aux comportements de l'insecte imité. Par cette imitation, il bénéficie de la protection contre les prédateurs. Certains longicornes (Cerambycidae) pratiquent ce type de mimétisme. De nombreuses espèces de coléoptères, comme les coccinelles, les cantharides et les lycides, sécrètent des substances désagréables ou toxiques pour se défendre. Ces mêmes espèces présentent souvent de l'aposématisme, une stratégie adaptative qui envoie par une coloration vive ou contrastante un message d'avertissement.

La défense chimique est une autre technique de défense pratiquée par certains coléoptères. Cette stratégie n'est pas uniquement contre les prédateurs. Il semblerait qu'elle pourrait même protéger contre les infections et les parasites. Certains espèces libèrent des substances chimiques sous la forme d'un nuage de vapeur avec une précision surprenante. La pulvérisation est parfois si forte qu'elle provoque un bruit de détonation. Les toxines sont souvent issues de la consommation de plantes toxiques. Le métabolisme de l'insecte isole ces toxines et les intègre à son système. Chez les carabes africains du genre "Anthia" et "Thermophilum, "la substance chimique expulsée est de l'acide formique, la même fabriquée par certaines fourmis. Les carabes bombardiers ont la capacité de projeter un liquide corrosif en ébullition sur leurs assaillants. Cette substance est composée d'hydroquinone et de peroxyde d'hydrogène.

Certains coléoptères possèdent des attributs physiques comme des épines ou des protubérances qui les aident à se défendre et les rendent peu attrayants pour d'éventuels prédateurs. En cas de danger, ils peuvent mordre ou encore refermer leurs pattes épineuses sur l'ennemi.

Quelques espèces de coléoptères sont des ectoparasites de mammifères. "Platypsyllus castoris", une espèce de staphylin, ne vit pas réellement comme parasite mais qui, aux stades larvaires et adultes se nourrit des peaux d’excrétions du castor. Cette espèce n'a pas d'aile et de yeux comme beaucoup d'autres ectoparasites.On ne peut pas qualifier Platysyllus de parasite il ne nuit pas à son hôte comme tel, mais plutôt de commensal.

Le petit coléoptère des ruches ("Aethina tumida)" est également un type de parasite. Les larves de cet insecte se nourrissent du miel et ils endommagent ou détruisent les rayons en s'alimentant. Ils défèquent également dans le miel et cela provoque une fermentation avec une odeur caractéristique d'orange en décomposition. Lors des fortes infestations, les abeilles peuvent décider de quitter la ruche. "A. tumida" est considéré comme un insecte nuisible pour l'industrie de l'apiculture.

Les coléoptères peuvent être également des hôtes pour des guêpes parasitoïdes. Par exemple, la coccinelle maculée ("Coleomegilla maculata") est l'hôte d'une guêpe braconide nommée "Dinocampus coccinellae." Lors de l'oviposition, la femelle parasitoïde s'approche de son hôte et lui pénètre l'exosquelette à l'aide de son ovipositeur modifié. Elle déposera son œuf à l'intérieur de la coccinelle. La larve s'alimentera des corps gras de celle-ci. Lors de la pupaison, qui se produit à l'extérieur de la coccinelle, la larve manipule son hôte pour que celui-ci protège son cocon.

Les coléoptères peuvent être des pollinisateurs particulièrement importants dans certaines régions comme dans les zones semi-arides d'Afrique australe, dans le sud de la Californie et dans les prairies montagneuses de KwaZulu-natal d'Afrique du Sud.

Certains types de fleurs semblent attirer davantage les coléoptères. Les fleurs attirantes sont généralement de grande taille, verdâtre ou blanc cassé et très parfumée. L'odeur dégagée peut être épicée, fruitée ou similaire à la décomposition de la matière organique. La plupart des fleurs pollinisées par ces insectes ont une forme aplatie ou possède une partie en forme de plate-forme. Cette structure permet une meilleure accessibilité aux pollens. Les ovaires des plantes sont généralement bien protégés contre les pièces buccales du type broyeur des coléoptères.

Le mutualisme est une collaboration entre des individus d'espèces différentes. Cette relation n'est pas commune parmi les différents ordres d'insectes. Pourtant, on retrouve quelques exemples de ce type de relation chez les coléoptères, comme chez la sous-famille des Scolytinae. Le scolyte creuse des tunnels dans les arbres morts et cultive des jardins fongiques, qui en digérant le bois, deviennent leur seule source de nutrition. Lorsque l'adulte atterrit sur un arbre approprié, il creuse un tunnel dans lequel il libère des spores de son symbiote fongique. Le champignon pénètre le xylème de l'arbre, le digère et se concentre dans les parties plus nutritives. Les larves de scolytes ne sont pas capables de digérer le bois en raison des toxines présentes dans celui-ci. Il utilise donc sa relation avec le champignon pour aider à surmonter les défenses de l'arbre.

Le commensalisme est un type de relation biologique dans laquelle un hôte fournit un bénéfice au commensal. L'hôte n'obtient aucun gain en échange. Certains pseudoscorpions montent sur des longicornes et se cachent sous les élytres de ceux-ci. Ils bénéficient d'un transport vers de nouveaux territoires et sont également protégés des prédateurs. Le coléoptère n'est pas affecté par la présence des auto-stoppeurs.

Le terme « coléoptère » a été formé à partir du grec ancien ' : « dont les ailes sont recouvertes d'une sorte de fourreau, coléoptère », composé de ', "koleos" « fourreau, étui » et de "", "pteron", « aile ». Il aurait été inventé par Aristote et a été repris par Carl von Linné pour regrouper les espèces parfois appelées « vrais coléoptères », contrairement à d'autres auteurs comme Giovanni Antonio Scopoli qui y incluait les blattes ou les orthoptères. Charles de Geer, dans son ouvrage de 1774, est le premier à n'appliquer le nom de "Coleoptera" qu'à des espèces considérées aujourd'hui comme des coléoptères.

Ce groupe est aujourd'hui réparti en quatre sous-ordres :

Parmi les coléoptères on trouve de nombreuses familles dont :

L'ordre des coléoptères est l'ordre des animaux qui rassemble le plus grand nombre d'espèces (plus de ). C'est pour cela, qu'à la question « Qu'est-ce que vos études de la nature vous ont révélé de la nature de Dieu ? », le chercheur britannique John Burdon Sanderson Haldane (1892-1964) répondit : « le Créateur, s'il existe, a une passion démesurée pour les coléoptères ! ».

La perméabilité écologique des lisières pour les coléoptères a de multiples implications, tant pour la recherche en matière de biodiversité que pour la gestion agricole, sylvicole ou du territoire.
Une étude publiée en 2007 a porté (dans l'Ohio) sur ses déplacements à partir des lisières forestières vers l'intérieur des champs de maïs périphériques aux forêts, afin de voir dans quelle mesure la taille des fragments forestiers, la distance à la lisière et la matrice agricole affectaient ou non la dynamique des communautés de coléoptères. L'étude a porté sur l'abondance en coléoptères et leur diversité en espèce (diversité spécifique). Elle a montré que :

Les coléoptères, comme de nombreux autres invertébrés sont soumis à la pression croissante des pesticides (insecticides). Certaines espèces sont également menacées ou rares et recherchées par les collectionneurs.
On a récemment montré que des espèces montrant de bonnes aptitudes à voler se refusent néanmoins à traverser des espaces très artificialisés (tels que les routes). Ainsi, indépendamment du risque d'écrasement, les infrastructures routières exposent ces espèces à un phénomène de fragmentation écologique de leur habitat (même quand les routes sont fermées ou peu fréquentées).
Enfin le manque de bois-mort et sénescent dans les forêts cultivées est aussi une cause de régression ou disparition d'espèces qui peut être en partie limitée par une gestion durable des forêts exploitées améliorant artificiellement, via la réintroduction de chronoxyles, bois sénescents, brûlés (feux contrôlés), etc. ou naturellement (par arrêt localement des coupes ou de l'exportation) l'offre en bois mort et en arbres sénescents.




</doc>
<doc id="15757" url="https://fr.wikipedia.org/wiki?curid=15757" title="Élytre">
Élytre

Un élytre (du grec , « elutron » qui signifie étui) constitue une des deux ailes antérieures, durcies et cornées (partiellement ou totalement sclérifiées), qui recouvrent au repos les ailes postérieures de certains insectes, notamment ceux de l'ordre des coléoptères, à la façon d'un étui. Le nom des coléoptères vient d'ailleurs du latin ', étui.Les élytres sont parfois appelés ' (ou "" au singulier), en particulier chez les orthoptères.

Durant le vol, les élytres ne battent pas ; ils sont simplement relevés pour permettre le mouvement des ailes postérieures et donner plus de stabilité. Au repos, ils protègent principalement les ailes, mais peuvent servir de défense, soit à l'aide de couleurs vives qui effraient leurs prédateurs, soit en adoptant les tons de l'habitat naturel de l'insecte, servant ainsi de camouflage.

Dans certains groupes, les élytres ont fusionné, ce qui rend l'insecte incapable de voler : par exemple, les carabes.

Les élytres ne portent pas de système de nervures et de cellules (comme décrit dans le système Comstock Needham), mais portent généralement des stries, sillons longitudinaux, et des interstries, les espaces entre ces sillons. Les élytres peuvent aussi être parfaitement lisses ou alors porter des bosses ou des excroissances.

Dans le sous-ordre des orthoptères ensifères (comme les grillons ou les éphippigères), les élytres sont munis chacun d'un « archet » et d'un plectrum qui peuvent être frottés l'un sur l'autre. Ils sont utilisés comme organes stridulatoires, berçant ainsi les nuits de nos campagnes.




</doc>
<doc id="15761" url="https://fr.wikipedia.org/wiki?curid=15761" title="Totalitarisme">
Totalitarisme

Le totalitarisme est l'un des principaux types de systèmes politiques avec la démocratie et l'autoritarisme. C'est un régime à parti unique, n'admettant aucune opposition organisée et dans lequel l'État tend à confisquer la totalité des activités de la société. C'est un concept forgé au , durant l'entre-deux-guerres, avec une apparition concomitante en Italie, en Allemagne et en URSS. Le totalitarisme signifie étymologiquement « système tendant à la totalité ».

L'expression vient du fait qu'il ne s'agit pas seulement de contrôler l'activité des personnes, comme le ferait une dictature classique. Le régime totalitaire va au-delà en tentant de s'immiscer jusque dans la sphère intime de la pensée, en imposant à tous les citoyens l'adhésion à une idéologie obligatoire, hors de laquelle ils sont considérés comme ennemis de la communauté.

Les caractéristiques habituellement retenues pour définir le totalitarisme sont : d'une part, un monopole idéologique, c'est-à-dire la conception d'une vérité qui ne supporte aucun doute, ne tolère aucune critique, est imposée à tous et se trouve orientée par la lutte contre les ennemis du régime, et d'autre part un parti unique qui contrôle la totalité de l'appareil étatique c'est-à-dire dispose de l'ensemble des moyens de communication de masse utilisés comme des instruments de propagande, crée des structures d'embrigadement de chaque catégorie de la société et dispose d'une direction centrale de l'économie. Le parti unique est dirigé idéalement par un chef charismatique et autour duquel est formé un « culte du chef », faisant de lui plus qu'un simple dictateur mais plutôt un guide pour son peuple, lui seul en connaissant les véritables aspirations. Un monopole de la force armée, un système à la fois policier qui a recours à la avec par exemple un réseau omniprésent d'agents dormants et de surveillance des individus, basée sur la suspicion, la dénonciation et la délation ; et également concentrationnaire afin de pouvoir se prémunir contre tout individu potentiellement suspect. Ainsi ces systèmes ont systématiquement recours à l'emprisonnement, la torture et l'élimination physique des opposants ou personnes soupçonnées comme telles, et la déportation des groupes de citoyens jugés « suspects », « inutiles » ou « nuisibles ».

On peut définir le totalitarisme comme une idéologie qui « nie toute autonomie à l'individu et à la société civile et s'emploie à les supprimer autoritairement au profit d'une vision moniste du pouvoir et du monde ; recouvrant tous les aspects de la vie humaine, cette idéologie fonde et justifie la domination absolue de l'État ». À partir de cette définition simple et très généralement admise, ont été développées des interprétations et surtout des utilisations du concept de totalitarisme. Elles s'appuient en particulier sur l'analyse développée par Hannah Arendt (1906-1975) dans "Les origines du totalitarisme" (1951).

L'adjectif « totalitaire » () apparut en Italie dès le mois de mai 1923 (on prête parfois son invention à Giovanni Amendola, opposant et victime du fascisme). Ce concept fut d'emblée un instrument de pensée et de lutte politique. Son emploi se répandit dans les milieux antifascistes italiens. Ainsi Carlo Sforza (libéral républicain), Gaetano Salvemini (gauche anticommuniste) et surtout Luigi Sturzo (démocrate-chrétien) furent dans l'Entre-deux-guerres des utilisateurs du concept de totalitarisme. En 1925, les théoriciens du fascisme reprirent de manière opportuniste le terme à leur compte, en lui attribuant une connotation positive, celle d'unité du peuple italien. Benito Mussolini exaltait sa « farouche volonté totalitaire », appelée à délivrer la société des oppositions et des conflits d'intérêts. Dans la seconde moitié des années 1920, l'ancien président du Conseil des ministres italien Francesco Saverio Nitti « aurait le premier établi des rapprochements entre la structure du fascisme italien et le bolchevisme ». Giovanni Gentile, théoricien du fascisme, mentionna le totalitarisme dans l'article « doctrine du fascisme » qu'il écrivit pour "Enciclopedia Italiana" et dans lequel il affirma que « ... pour le fasciste tout est dans l'État et rien d'humain et de spirituel n'existe et il a encore moins de valeur hors de l'État. En ce sens le fascisme est totalitaire... ».

L'écrivain allemand Ernst Jünger, par son exaltation de la « mobilisation totale », décrit les contours du totalitarisme. Il célèbre la guerre et la technique moderne comme annonciatrices d'un nouvel ordre, incarné par la figure de l'ouvrier-soldat, œuvrant au sein d'une société encadrée et disciplinée comme une armée. Selon lui, la Première Guerre mondiale avait marqué un tournant historique vers cette forme nouvelle de civilisation : pour la première fois dans l'histoire de l'Europe, les forces humaines et matérielles du monde industriel moderne avaient été mobilisées dans leur « totalité » pour accomplir l'effort de guerre.

La première utilisation du terme de totalitarisme pour désigner dans le même temps les États fasciste et communiste semble avoir été faite en Grande-Bretagne en 1929. Dans les années 1930, le concept fut utilisé sous la plume d'écrivains pro-nazis. Carl Schmitt employait ce terme pour mettre en lumière la crise du libéralisme et du parlementarisme et exprimer la nécessité d'une politique plus autoritaire. Simone Weil écrivait en 1934 : « il apparaît assez clairement que l'humanité contemporaine tend un peu partout à une forme totalitaire d'organisation sociale, pour employer le terme que les nationaux-socialistes ont mis à la mode, c'est-à-dire à un régime où le pouvoir d'État déciderait souverainement dans tous les domaines, même et surtout dans le domaine de la pensée ».
Le régime autoritaire franquiste issu de la guerre civile espagnole s’est défini comme totalitaire dans ses premières années, affirmant ainsi sa parenté avec le fascisme, avant d'effacer ce terme de la constitution. Il en est de même du régime impérial japonais lors de la première partie de l'ère Shōwa, à compter de la constitution de l"'Association de Soutien à l'Autorité Impériale". En 1940, dans une entrevue accordée au New York Herald, le ministre des Affaires étrangères du cabinet de Fumimaro Konoe, Yōsuke Matsuoka, n'hésitait pas à faire l'apologie du totalitarisme, prédisant sa « victoire sans équivoque dans le monde » et « la banqueroute du système démocratique ».

Dans le monde anglo-saxon, William Henry Chamberlain et Michael Florinsky ont été parmi les premiers à faire usage du concept de totalitarisme. Divers théoriciens de gauche, comme Franz Borkenau ou Richard Löwenthal, ont employé le concept « pour caractériser tout ce qui leur paraît nouveau et spécifique dans le fascisme (ou le nazisme), en dehors de toute comparaison avec le communisme soviétique ». Le concept de totalitarisme cristallisait également la réflexion sur les formes modernes de tyrannie et, plus particulièrement, sur la violence exercée sur autrui, qui semblait inséparable du fonctionnement des régimes nazi et communiste. Finalement, les traits fondamentaux qui ont dominé la discussion de l'après-guerre sur le totalitarisme étaient déjà présents dans les années 1930. Pierre Hassner affirme : « On peut dire qu'en un sens Hannah Arendt n'a fait que nouer en une synthèse géniale [...] les différents éléments en dégageant la logique qui les sous-tendait ».

Le pacte germano-soviétique, signé en 1939 entre l'Allemagne nazie et l'URSS, fut présenté par certains comme une illustration de l'apparition d'un nouveau type de régime (l'antithèse du libéralisme) qui ferait le lien entre les idéologies fasciste et soviétique. Par exemple, dans "The Totalitarian Enemy", paru à Londres en 1940, l'ancien communiste autrichien Franz Borkenau voulait éclairer l'opinion publique sur les vrais enjeux de la guerre : il s'agissait de détruire le totalitarisme incarné dans le nazisme et le bolchevisme. Les différences entre ces deux courants étaient minimes pour l'auteur : le bolchevisme se limitait à un « fascisme rouge » et le nazisme à un « bolchevisme brun ». D'après Borkenau, la dynamique inhérente au marché capitaliste conduisait inévitablement à une centralisation et une planification de l'économie : la révolution totalitaire n'était rien d'autre que la révolution socialiste prophétisée par Karl Marx. Mais cette sous-estimation des différences entre le bolchevisme et le nazisme « ne diminue pas, selon Krzysztof Pomian, l'importance historique de "Totalitarian Enemy". Y sont évoqués, en effet, presque tous les thèmes repris plus tard par l'abondante littérature consacrée au totalitarisme ».

La philosophe Hannah Arendt a apporté une définition du concept de totalitarisme dans son livre "Les Origines du totalitarisme" (1951). Selon elle, deux pays seulement avaient alors connu un véritable totalitarisme : l'Allemagne sous le nazisme et l'URSS sous Staline. Elle distingue toutefois des tendances ou des épisodes totalitaires en dehors de ces deux cas. Elle cite notamment le maccarthisme au début des années 1950 aux États-Unis ou encore les camps administratifs français où furent enfermés les réfugiés de la guerre d'Espagne.

Ces régimes n'admettent qu'un parti unique qui contrôle l'État, qui lui-même s'efforce de contrôler la société et plus généralement tous les individus dans tous les aspects de leur vie (domination totale). D'un point de vue totalitaire, cette vision est erronée : il n'y a qu'un parti parce qu'il n'y a qu'un tout, qu'un seul pays, vouloir un autre parti c'est déjà de la trahison ou de la maladie mentale (une forme de dédoublement de la personnalité, amenant à se croire plusieurs alors qu'on est un).

Le totalitarisme tel qu'il est ainsi décrit par Hannah Arendt n'est pas tant un « régime » politique qu'une « dynamique » autodestructive reposant sur une dissolution des structures sociales.

Dans cette optique, les fondements des structures sociales ont été volontairement sabotés ou détruits : les camps pour la jeunesse ont par exemple contribué à saboter l'institution familiale en instillant la peur de la délation à l'intérieur même des foyers, la religion est interdite et remplacée par de nouveaux mythes inventés de toutes pièces ou recomposés à partir de mythes plus anciens, la culture est également une cible privilégiée. Hanns Johst avait ainsi écrit dans une pièce de théâtre : « Quand j'entends le mot culture, j'enlève le cran de sureté de mon Browning » (cette phrase a également été prononcée en public par Baldur von Schirach, chef des Jeunesses hitlériennes).

L'identité sociale des individus laisse place au sentiment d'appartenance à une masse informe, sans valeur aux yeux du pouvoir, ni même à ses propres yeux. La dévotion au chef et à la nation devient la seule raison d'être d'une existence qui déborde au-delà de la forme individuelle pour un résultat allant du fanatisme psychotique à la neurasthénie. La domination totale est réalisée : les « ennemis objectifs » font leur autocritique pendant leurs procès et admettent la sentence. Les agents du NKVD russe arrêtés avaient ainsi un raisonnement du type « si le Parti m'a arrêté et désire de moi une confession, c'est qu'il a de bonnes raisons de le faire ». Arendt remarque en outre qu'aucun agent arrêté n'a jamais tenté de dévoiler un quelconque secret d'État, et est toujours resté fidèle au pouvoir en place, même lorsque sa mort était assurée.

Les sociétés totalitaires se distinguent par la promesse d'un « paradis », la fin de l'histoire ou la pureté de la race par exemple, et fédèrent la masse contre un ennemi objectif. Celui-ci est autant extérieur qu'intérieur et sera susceptible de changer, selon la réinterprétation des lois de l'Histoire (lutte des classes) ou de la Nature (lutte des races) prévalant à un moment donné. Les sociétés totalitaires créent un mouvement perpétuel et paranoïaque de surveillance, de délation et de retournement. Les polices et les unités spéciales se multiplient et se concurrencent dans la plus grande confusion.

Contrairement aux dictatures traditionnelles (militaires ou autres), le totalitarisme n'utilise pas seulement la terreur dans le but d'écraser l'opposition. La terreur totalitaire continue même lorsque toute opposition est écrasée. Même si le groupe considéré comme un ennemi a été anéanti (par exemple les trotskistes en URSS), le pouvoir en désignera continuellement un autre. Hitler et les nazis avaient ainsi prévu l'extermination des peuples ukrainiens, polonais et russes une fois les Juifs éliminés.

Des purges régulières ordonnées par le chef de l'État, seul point fixe, donnent le tempo d'une société qui élimine par millions sa propre population, se nourrissant en quelque sorte de sa propre chair. Ce programme est appliqué jusqu'à l'absurde, les trains de déportés vers les camps de concentration et d'extermination de l'Allemagne nazie restèrent toujours prioritaires sur les trains de ravitaillement du front alors même que l'armée allemande perdait la guerre. Les régimes totalitaires se distinguent des régimes autoritaires et dictatoriaux par leur usage permanent de la terreur, contre l'ensemble de la population (y compris les « innocents » aux yeux même de l'idéologie en vigueur) et pas seulement contre les opposants réels. L'usage permanent de la terreur a pour corollaire celui de la propagande, omniprésente dans un État totalitaire.

Par ailleurs, le totalitarisme n'obéit souvent à aucun principe d'utilité : les structures administratives sont démultipliées sans se superposer, les divisions du territoire sont multiples et ne se recoupent pas. La bureaucratie est consubstantielle du totalitarisme. Tout cela a pour but de supprimer toute hiérarchie entre le chef et les masses, et garantir la domination totale, sans aucun obstacle la relativisant. Le chef commande directement et sans médiation tout fonctionnaire du régime, en tout point du territoire. Le totalitarisme est à différencier de l'absolutisme et de l'autoritarisme (où la source des lois, la légitimité du chef sont extérieures au pouvoir exercé par le régime, comme Dieu ou encore les lois de la nature, « même le plus draconien des régimes autoritaires est lié par des lois »). Dans le cas de l'autoritarisme, toute la société est hiérarchisée et le pouvoir se transmet de couche en couche, du sommet de la pyramide vers les bas alors que dans le cas du totalitarisme, aucune instance intermédiaire de ne vient relayer, voire atténuer l'autorité du chef totalitaire.

Dans son introduction d’une nouvelle édition de "The Origins of Totalitarianism", en 1966, Hannah Arendt s’est opposée à l’usage idéologique du terme de totalitarisme concernant tous les régimes communistes à parti unique.

L’ouvrage d'Arendt a convaincu la majorité de l’opinion et reçu de nombreux éloges. Michelle-Irène Brudny, traductrice de l'œuvre de Arendt, considère néanmoins que sa pensée comporte des exagérations, dans sa prétention de tout englober : « le philosophe, parfois intrépide ou, plus sûrement, devenu téméraire par sa volonté obsessive de comprendre, se sent tenu, au risque du paradoxe, de produire une interprétation "générale" ».

Dans les années 1950, le politologue Carl Joachim Friedrich et son assistant Zbigniew Brzezinski identifient comme « totalitaire » un régime dans lequel on trouve six éléments : une idéologie officielle, un parti unique, la terreur policière, le monopole des médias, celui des forces armées et une économie planifiée.

Claude Lefort fait partie des théoriciens du politique qui postulent la pertinence d’une notion de totalitarisme dont relèvent le stalinisme comme le fascisme, et considèrent le totalitarisme comme différent en son essence des grandes catégories utilisées par le monde occidental depuis la Grèce antique, comme les notions de dictature ou de tyrannie. Cependant, contrairement aux auteurs comme Hannah Arendt qui limitent la notion à l’Allemagne nazie et à l’Union soviétique entre 1936 et 1953, Lefort l’applique aux régimes d’Europe de l’Est dans la deuxième moitié du , c’est-à-dire à une époque où la terreur, un élément central du totalitarisme chez d’autres auteurs, avait perdu sa dimension paroxystique. C’est à l’étude de ces régimes, et à la lecture notamment de "L'Archipel du Goulag" (1973) d’Alexandre Soljenitsyne, qu’il a développé son analyse du totalitarisme. Sans la théoriser en un ouvrage unifié, il a publié en 1981 : "L'Invention démocratique : les limites de la domination totalitaire", recueil d’articles parus entre 1957 et 1980.

Bernard-Henri Lévy opère une critique des causes du totalitarisme proche de celles d’André Glucksmann, et des prises de position que prend Michel Foucault en 1977. Centrée par Glucksman sur la question de la responsabilité de la philosophie allemande dans la construction du nazisme et du stalinisme, la critique qu'envisage Lévy, et sa définition du schéma totalitaire, se déplacent sur le terrain de la désirabilité de la révolution, selon des données que Foucault conçoit ainsi dans un entretien publié en 1977 : « Le retour de la révolution, c’est bien là notre problème. Il est certain que, sans lui, la question du stalinisme ne serait qu’une question d’école – simple problème d’organisation des sociétés ou de validité du schéma marxiste. Or c’est de bien autre chose qu’il s’agit, dans le stalinisme. Vous le savez bien : c’est la désirabilité même de la révolution qui fait aujourd’hui problème ».

Dans son essai, "La Barbarie à visage humain", Bernard-Henri Lévy met en cause la positivité pure liée au désir de la révolution – non pas d"'une" révolution, mais de "la" révolution, décisive, radicale, finale –, et à l'optimisme conceptuel, délibéré et assumé, qui « dope » alors la pensée. L'optimisme ne dépend plus, dans ce cas, d'un trait de caractère, mais d'une construction idéologique. Désir du meilleur, l’optimisme ainsi conçu créerait la condition qui permet d’accomplir jusqu’au pire avec la conviction de s’améliorer sans cesse. Les totalitarismes, quelles que soient leurs différences par ailleurs, se reconnaîtraient, tant dans leurs théories que dans leur pratique, à l'exigence de requérir la perception d'une dynamique purement positive, optimisante et énergisante, associée à l'idée d'une providence toute-puissante et naturelle, qui mènerait nécessairement les hommes vers une « société bonne » méthodiquement « épurée » de ses éléments « corrupteurs ».

De nombreux philosophes, cherchant à trouver une explication aux tragédies du , ont traité de la question du totalitarisme. Le courant philosophique recherchant « l’essence » du totalitarisme a mis l’accent sur son contenu idéologique et ses méthodes.

Le fascisme, le nazisme et le stalinisme ont été interprétés en tant que « religions séculières ». Le philosophe allemand Eric Voegelin a construit une analyse du sur la base de cette notion. Les idéologies totalitaires remplaçaient la religion, car elles demandaient à leurs adeptes de croire à la promesse d’un salut sur terre.

Pour Marcel Gauchet, certains totalitarismes comme le stalinisme, le fascisme et le nazisme sont des « religions séculaires », des expériences de croyance qui entrainaient le fanatisme. Au delà de leur antagonisme premier, ce qui unit ces totalitarismes et font leur séduction est la restauration sous des formes modernes de sociétés passées qui étaient organisée par la religion: recours au culte de la personnalité, sacralisation du lien entre le peuple et l'État via le parti unique comme auparavant le clergé, obsession propagandiste et de l'unité de la foi.

Soutenue par plusieurs auteurs, l'assimilation plus ou moins poussée de l'idéologie totalitaire à la religion a été critiquée par Hannah Arendt pour qui le fait que l'idéologie accomplit une fonction similaire à celle de la religion ne justifie pas de confondre les deux notions.

Waldemar Gurian, historien et essayiste d’origine russe émigré aux États-Unis en 1937, a introduit la notion d’« idéocratie ». Selon Gurian, les totalitarismes bolchevique et nazi, en tant que régimes engendrés et structurés par une idée, étaient « idéocratiques ». L’idéocratie désignait toute forme d’organisation politique où il y avait fusion entre le pouvoir et une idéologie donnée. Le terme s’appliquait fréquemment aux régimes où un parti unique avait la mainmise sur l’appareil étatique.

L’historien israélien Jacob L. Talmon a également perçu le totalitarisme comme le produit d’une idée. D’après lui, le totalitarisme avait sa matrice dans la philosophie des Lumières. L’intelligentsia russe a été influencée par le messianisme politique du , c’est-à-dire par l’annonce d’un avenir radieux et par l’affirmation qu’il existe en politique une vérité, une seule. Jacob Talmon considérait Jean-Jacques Rousseau (auteur de la théorie de la volonté générale), Maximilien de Robespierre (le premier praticien de la Terreur) et Gracchus Babeuf (le premier conspirateur communiste) comme des précurseurs du totalitarisme.

Alain Besançon a repris l'analyse du totalitarisme comme idéocratie : « L'idéologie n'est pas un moyen du totalitarisme mais au contraire le totalitarisme est la conséquence politique, l'incarnation dans la vie sociale de l'idéologie ». Comme Jacob Talmon, Alain Besançon voit dans la Révolution française la matrice du totalitarisme et porte un regard très critique sur l'héritage rationaliste des Lumières.

Dans les années 1950, le concept de totalitarisme a été perfectionné en un « modèle » par des politologues soucieux d’aboutir à une catégorisation des régimes politiques. Le modèle du totalitarisme a été formé par opposition à d’autres modèles, comme les modèles des régimes « démocratiques-constitutionnels » et « autoritaires-conservateurs ».

Sous le titre de "Permanent Revolution", Sigmund Neumann a publié une étude sur le totalitarisme en 1940. Il insistait sur le fait que l'État totalitaire menait une « révolution permanente », tandis que les autoritarismes traditionnels avaient généralement été conservateurs. Selon Neumann, le caractère principal des régimes totalitaires était d'institutionnaliser la révolution, ce qui leur permettait d'assurer leur propre perpétuation.

Mais lorsque les historiens s'emparent du concept, c'est beaucoup plus selon la définition fixée, à l'origine, par le politologue Carl Friedrich, qui a permis au concept de totalitarisme d'acquérir sa pleine légitimité dans le domaine des sciences sociales. L'ouvrage écrit par Friedrich et son jeune collaborateur de l'université Harvard Zbigniew Brzezinski est, selon Enzo Traverso, « le livre qui a le plus polarisé le débat pendant les années cinquante et soixante ». Leur analyse du totalitarisme a représenté pendant longtemps le traitement théorique qui a fait le plus autorité. Les deux auteurs présentaient un « syndrome » du totalitarisme comportant cinq caractéristiques fondamentales :
Dans cette vision, les dictatures totalitaires, en tant que forme nouvelle et extrêmement moderne d'autoritarisme, étaient la forme achevée du despotisme. De plus, les sociétés totalitaires étaient présentées comme fondamentalement semblables entre elles.

On peut y ajouter comme autres aspects pratiques, la prise en main totale de l'éducation pour la fonder sur l'idéologie et la mise en place d'un réseau omniprésent de surveillance de l'individu. La technique est prépondérante : ce sont les techniques modernes qui permettent au pouvoir politique une emprise totale sur les populations. L’État totalitaire consiste en une énorme bureaucratie d’une efficacité sans failles. Une des caractéristiques du totalitarisme est d'enrégimenter physiquement et mentalement la population. L’idéologie constitue un instrument de gouvernement sans pareil, par l'endoctrinement des populations. La propagande a l’effet d’un lavage de cerveau, permettant d’obtenir l’assentiment du peuple. Selon Claude Polin, les idéologies totalitaires permettent « de mettre les esprits même en esclavage, et de tarir toute révolte à sa source vive, en ôtant jusqu’à son intention même ».

Les politologues de la période des totalitarismes européens tiraient des conclusions très pessimistes pour le futur. Selon eux, il était improbable que les dictatures totalitaires, compte tenu de leur dynamique interne, s’effondrent d’elles-même ou soient renversées par une révolution. Il y avait aussi d’énormes obstacles à la libéralisation du régime, étant donné l'arbitraire de la loi et l’absence d’initiative démocratique. Les structures du totalitarisme le rendaient incapable d’évoluer, mais pas incapable de se reproduire. Cet État tout-puissant tâchait même d’étendre son emprise sur l’ensemble du monde. Les projets totalitaires de révolution mondiale semblaient seulement pouvoir être contrecarrés par une intervention militaire extérieure, comme cela s’était passé face au nazisme.

Dans son premier livre traitant du totalitarisme soviétique, Brzezinski mettait l’accent sur la mobilisation totale des ressources par l’État, sur l’anéantissement de toute opposition et sur la terreur générale. La purge, perçue comme le noyau du totalitarisme, « satisfait les besoins du système en dynamisme et en énergie continuels ». Dans cet ouvrage, Brzezinski prévoyait la constante aggravation du totalitarisme. Les mouvements totalitaires étaient particulièrement redoutables car « leur dessein est d’institutionnaliser une révolution qui progresse en étendue, et souvent en intensité, à mesure que le régime se stabilise au pouvoir. L’objectif de cette révolution est de pulvériser toutes les unités sociales existantes afin de remplacer l’ancien pluralisme par une unanimité homogène ».

La destruction de la société ancienne, par l’application croissante de mesures de coercition, vise à reconstruire la société et l’homme lui-même selon des conceptions « idéales » définies par l’idéologie. « La terreur devient donc une conséquence inévitable, ainsi qu’un instrument, du programme révolutionnaire ». Dans son analyse du totalitarisme soviétique, Brzezinski accordait un grand poids à l’idéologie révolutionnaire qui, sous la main d'un parti unique bureaucratisé, engendrait un impact social total.

Le politologue reconnaît que « le système politique de Khrouchtchev n’est pas le même que celui de Staline, bien que les deux puissent être généralement décrits comme totalitaires ». Sous Khrouchtchev, la terreur a laissé place à une politique d’endoctrinement qui est devenue la principale caractéristique du système. Mais quand le dynamisme et le zèle révolutionnaires décroissent, « le système est renforcé par des réseaux de contrôle complexe qui imprègnent toute la société et mobilisent ses énergies à travers une pénétration très fine ».

Betty Brand Burch a résumé ainsi la définition classique du totalitarisme : « le totalitarisme est une forme extrême de dictature caractérisée par le pouvoir illimité et démesuré des dirigeants, la suppression de toutes formes d’opposition autonome et l’atomisation de la société d’une façon telle que quasiment chaque phase de la vie devient publique et donc sujette au contrôle de l’État ».

D'après la définition de Raymond Aron, le totalitarisme qualifie les systèmes politiques dans lesquels s'accomplit « l'absorption de la société civile dans l'État » et « la transfiguration de l'idéologie de l'État en dogme imposé aux intellectuels et aux universités ». L'État, relayé par le parti unique, exercerait en ce sens un contrôle total sur la société, la culture, les sciences, la morale jusqu'aux individus mêmes auxquels il n'est reconnu aucune liberté propre d'expression ou de conscience.

L'emploi du concept de totalitarisme a été refoulé durant la période de la Seconde Guerre mondiale, du fait de l'alliance des démocraties occidentales avec l'Union soviétique dans la lutte contre l'Allemagne nazie. Le concept a connu son âge d'or à partir de la proclamation de la doctrine Truman, en 1947. L'analogie entre l'Allemagne de Hitler et la Russie de Staline laissait à penser que la Guerre froide était simplement une répétition des années 1930, car la Russie soviétique pouvait se comporter de la même manière que l'Allemagne dans l'entre-deux-guerres. Selon Les Adler et Thomas Paterson, le « cauchemar d'un "fascisme rouge" a terrorisé une génération d'Américains ». La notion de totalitarisme, qui a fait l'objet d'un nombre considérable de travaux et dont l'usage était très répandu, se formulait alors dans une connotation strictement négative.
L'économiste Friedrich Hayek, dans "La Route de la servitude", décrivait le totalitarisme comme une conséquence inéluctable de l’application des mesures socialistes à l’économie. Il arguait que la socialisation de l’économie ne pouvait que déboucher sur la suppression totale des libertés, y compris des libertés politiques et donc que le socialisme était structurellement incompatible avec la démocratie. Friedrich Hayek pensait que des liens systémiques unissaient l’économie, le droit et les institutions politiques. S’opposer au libre fonctionnement des mécanismes du marché, dans lequel il voyait la source ultime de toute civilisation, reviendrait à installer un régime tyrannique. L’idée selon laquelle la planification économique serait le principe du totalitarisme a connu un important succès aux États-Unis. Dans "The Fatal Conceit", Friedrich Hayek a repris une dernière fois sa critique du socialisme, qu’il considérait comme une erreur fatale et le produit de la vanité intellectuelle.

Pour Bertrand de Jouvenel, c'est la démocratie qui est totalitaire : il a ainsi intitulé l'un des chapitres de son ouvrage principal "Du pouvoir" « La démocratie totalitaire ». Il considère que la démocratie en laissant l'espoir à chacun d'accéder au pouvoir incite à la prise du pouvoir et non à la réduction de l'« arbitraire étatique », phénomène entraînant un renforcement toujours plus grand des États.

Dans les années 1970, la notion de totalitarisme a été adoptée par des intellectuels d’Europe de l’Est émigrés en Occident, tels Leszek Kołakowski, Michel Heller ou Alexandre Zinoviev. Bien des dissidents de l’Est reproduisaient au travers de leurs travaux les descriptions les plus classiques du totalitarisme. Ils ont insisté de manière unanime sur le succès des politiques totalitaires. Kolakowski décrit le système stalinien comme « système politique où tous les rapports sociaux ont été étatisés et où l’État omnipotent se retrouve seul face à des individus réduits à l’état d’atomes » et Le stalinisme comme « un marxisme-léninisme en action », c’est-à-dire le résultat inévitable de la mise en pratique de la vision du monde marxisme-léninisme.

Les recherches sur la notion de totalitarisme se sont effectuées dans le contexte politique de la Guerre froide, où le modèle libéral s'opposait au modèle communiste. Après avoir été instrumentalisé par le maccarthisme aux États-Unis dans les années 1950, le concept de totalitarisme a commencé à être désavoué au cours des années 1960 par la recherche empirique des sciences sociales, dans le cadre d'un mouvement général de remise en question du libéralisme, favorisée par la détente. De nouvelles interprétations sont alors apparues : d'une part l’hostilité générale envers l’URSS faiblissait, d’autre part, les nouvelles relations entre les États-Unis et l’URSS ont entraîné des échanges intellectuels entre les deux pays (les chercheurs occidentaux étaient autorisés, bien plus que dans le courant des années 1950, à travailler dans les archives et les bibliothèques soviétiques). Il apparaissait évident que, dans les faits, l’État soviétique n’était pas parvenu à « atomiser » la société ou à éliminer la vie privée : les théoriciens du totalitarisme avaient surestimé les capacités du pouvoir soviétique à contrôler la société, et sous-estimé les capacités de résistance des individus. 
Tel qu'on l'avait connu, le système nazi ne manifestait aucun signe d'affaiblissement ou d'effondrement intérieur, au contraire, avant que la victoire alliée ne mette un terme à son existence. Or, après la mort de Staline, à partir de Khrouchtchev, l'Union soviétique avait commencé à changer, ce qui infirmait l’immobilisme prêté au système par le « modèle totalitaire ». La terreur s’était apaisée (pourtant considérée comme une caractéristique fondamentale du totalitarisme), le pouvoir personnel de Staline avait laissé place à une direction collective, des groupes de la nomenklatura bénéficiaient d’un rôle accru, la « purge permanente » avait laissé place au souci de sécurité de l’oligarchie. L’idéologie servait à la justification du pouvoir en place plutôt que de moteur dynamique de transformation de la société. Enfin, la consommation et l’économie parallèle progressaient et le pays s’ouvrait économiquement vers l’extérieur. Les théoriciens du totalitarisme comme Hannah Arendt et Zbigniew Brzezinski avaient mis au premier plan de leur analyse les formes extrêmes des dictatures dites totalitaires, qui se sont révélées, en URSS comme plus tard en Chine populaire, liées dans une très large mesure à la personne du tyran. La théorie du totalitarisme n’avait pas envisagé la possibilité que ces régimes s’engagent dans un processus d’apaisement de la dictature.

La pertinence du concept de totalitarisme et son utilité pour l’analyse historique et comparative ont alors été remises en question par une nouvelle génération de politologues américains. Ce concept, perçu comme une survivance de la Guerre froide, était accusé de sous-estimer la complexité des régimes auxquels il s’appliquait. Alexander J. Groth émettait des doutes sur la capacité du concept de totalitarisme à comprendre correctement l’Italie fasciste, l’Allemagne nazie et l’Union soviétique. Ce concept se concentrait sur les traits que ces régimes avaient en commun, alors que leurs différences méritaient une plus grande attention. Les Adler et Thomas Paterson partageaient cette opinion : « les différences réelles entre les systèmes fasciste et communiste ont été obscurcies ». Pourtant, poursuivaient-ils, les origines, les idéologies, les buts et les pratiques de ces systèmes étaient largement différents. La recherche historique a peu à peu mis en cause la légitimité du parallèle entre national-socialisme et communisme, en soulignant notamment la spécificité du génocide nazi, et plus généralement la singularité de régimes qui n’ont pas les mêmes origines.

Selon Robert C. Tucker, la comparaison entre l’Allemagne nazie et la Russie communiste était trop étroite. De plus, de nombreux auteurs convaincus que le régime soviétique découle de déviations historiques qui trahissent l'idéologie communiste, reprochent au « modèle totalitaire » d’établir une filiation entre le communisme, le bolchevisme et le stalinisme. Cette filiation considère le monde communiste comme un tout, et n’est que peu sensible aux différences existant entre les pays communistes. Dans un article, Herbert J. Spiro regrettait le fait que le terme de totalitarisme ait été un slogan anticommuniste durant la Guerre froide : l’usage propagandiste du terme « a eu tendance à obscurcir l’utilité qu’il pouvait avoir pour l’analyse systématique et la comparaison des entités politiques ». Benjamin Barber, pourtant ancien défenseur de la théorie du totalitarisme, appelait au dépassement d’un concept condamné « sinon par l’oubli, du moins par une désuétude croissante ». John Alexander Armstrong, intellectuel conservateur, a lui aussi critiqué explicitement le concept de totalitarisme à la fin des années 1960, arguant qu’il n’était pas capable de rendre compte de l’évolution de plusieurs régimes communistes.

L’expérience de démocratisation menée en Tchécoslovaquie lors du « printemps de Prague » de 1968 a rouvert le débat sur le changement dans les pays communistes et sur les différences entre ceux-ci. Le paradigme du totalitarisme est ainsi entré en conflit avec les nouveaux domaines de recherche qui intéressaient les spécialistes en sciences sociales et les historiens qui s’ouvraient aux méthodes des sciences sociales. Le « modèle totalitaire », par exemple, n’encourageait pas les études portant sur les rapports et les différences entre le centre et la périphérie. Georges Mink par exemple, dans "Vie et Mort du bloc soviétique", préfère parler de soviétisation/désoviétisation lorsqu'il s'agit d'aborder les pays du bloc de l'Est (URSS et pays satellites).

Néanmoins, l’idée de totalitarisme n’était pas complètement écartée : elle désignait une phase caractéristique des débuts de la domination communiste qui exigeait la mobilisation de la société, le plus souvent pour cause d’industrialisation. À la suite de cette phase d’industrialisation, l’élite révolutionnaire s’est bureaucratisée et la société communiste est devenue bien plus complexe et différenciée. C'est pourquoi, en comparaison avec l'Allemagne nazie de Hitler, certains chercheurs limitent la période totalitaire au régime de Staline, particulièrement dans ses dernières années (1950-1953), où la paranoïa de Staline atteignit son paroxysme. À partir de 1970, le constat que les régimes communistes n’étaient pas statiques, mais qu’ils traversaient au contraire différentes phases, faisait quasi-unanimité parmi les universitaires. Ils étaient nombreux à estimer que de nouveaux modèles théoriques étaient nécessaires pour étudier les États et les sociétés communistes dans la période post-stalinienne.

Dans la soviétologie, le débat autour de la notion de totalitarisme a opposé deux écoles historiographiques. L'« école du totalitarisme », après avoir été dominante aux États-Unis dans les années 1950-1960, a été contestée par une école « révisionniste », qui a remis en question les fondements de la soviétologie par le biais de l'histoire sociale.

Dans les sciences humaines, le terme a donné lieu à un débat qui n'est toujours pas clos. Le terme a donné lieu à de nombreuses définitions, différentes et parfois antagonistes selon les convictions des auteurs. Certains auteurs qualifient de totalitaires des régimes comme l'Allemagne sous Adolf Hitler, l'URSS sous Staline, le Turkménistan sous Saparmyrat Nyýazow, la Corée du Nord sous Kim Il-sung puis Kim Jong-il, le Cambodge sous Pol Pot (Khmers rouges), L'Iran sous Khomeini, Cuba sous Fidel Castro, la Chine à l'époque de Mao Zedong ou l'Afghanistan sous les Talibans. L'Empire du Japon de 1932 à 1945, la Première République française du temps de la Terreur ainsi que le Régime de Vichy présentent de nombreux caractères totalitaires.

Les politologues des débuts de la Guerre froide ont beaucoup cité Hannah Arendt pour sa comparaison entre Allemagne nazie et Russie soviétique, mais contrairement à elle, ils n’ont pas creusé le problème du point de vue social et historique. Carl Friedrich et son école se sont bornés à l’analyse des régimes totalitaires une fois constitués, quitte à négliger la question de leurs origines. Comme le dit Enzo Traverso, « l’affinité essentielle entre l’Allemagne nazie et l’URSS était postulée sur la base d’une simple comparaison phénoménologique, statique, descriptive, jamais étudiée à partir de la genèse et de la dynamique de ces régimes ». Friedrich semble s’excuser : « pourquoi les sociétés totalitaires sont ce qu’elles sont, nous ne le savons pas ». D’après l'historien Enzo Traverso, la principale conséquence de l’application des concepts d’idéocratie et de religion séculière a été « de déshistoriser le fait totalitaire, qui ne sera pas étudié comme résultat d’un processus social et politique mais réduit à l’incarnation d’une idée ».

Par ailleurs, la pertinence du concept de "totalitarisme", aussi bien que son application à l'Union soviétique en dehors de la période stalinienne, reste sujette à débat.

Dans un article au titre éloquent, Ian Kershaw marque ses fortes réticences à l'égard de la théorie du totalitarisme. Concernant le Troisième Reich, l'historien anglais conteste l'atomisation de la société civile, premier des traits du totalitarisme selon Hannah Arendt. Son étude sur la Bavière lui permet d'affirmer qu'une opinion populaire demeure, indépendamment de l'idéologie nazie. La société a su s'appuyer sur ses traditions pour exprimer ses doléances ou pour opposer une résistance ponctuelle, elle ne s'est donc pas réduite à « l'homme unique » dont Arendt parlait. Selon Kershaw, le concept de totalitarisme « aide, contre la propre volonté de la plupart de ses utilisateurs, à marquer les différences radicales qui existent » entre les deux régimes stalinien et nazi. Il conclut en considérant que « le concept de totalitarisme a un pouvoir essentiellement descriptif, très faiblement explicatif - ce en quoi il n'est peut-être d'ailleurs pas un concept ».

Dans leur ouvrage commun, paru en 2003, Alain Blum et Martine Mespoulet regrettent que l'« approche totalitaire postulant la nature essentiellement politique de l'histoire soviétique, la société n'a guère de place dans cette analyse ». Concernant l'Union soviétique, « le débat autour du totalitarisme a souvent occulté la complexité de l'organisation du commandement, et plus généralement des formes du gouvernement stalinien ». De manière plus directe, Roland Lew, historien spécialiste de la Chine maoïste, parle d'un paradigme « profondément obsolète », basé sur « une conception largement a-historique », qui « n'a continué à vivre et même à prospérer que grâce à l'affrontement idéologique ».

Le 25 janvier 2006, l’Assemblée parlementaire du Conseil de l'Europe adoptait une Résolution sur la nécessité d’une condamnation internationale des crimes des régimes communistes totalitaires.

Le Parlement européen a exprimé à plusieurs reprises son opposition aux régimes totalitaires. Le 23 septembre 2008, il publiait une déclaration sur la proclamation du 23 août comme journée européenne de commémoration des victimes du stalinisme et du nazisme. Le 2 avril 2009, il adoptait à la majorité absolue une résolution condamnant les régimes totalitaires, en particulier communistes et nazi.

Malgré les critiques, l’analyse au travers du prisme du totalitarisme n’a pas été abandonnée. De nombreux auteurs en ont défendu la valeur heuristique. Le Polonais Leszek Kołakowski reconnaissait qu’« un modèle parfait d’une société totalitaire est introuvable ». Mais d’après le philosophe polonais, cela ne constituait pas un obstacle sérieux à l’utilisation du concept, étant donné que les concepts employés pour décrire les phénomènes sociaux de grande échelle n’avaient jamais d’équivalents empiriques parfaits. Il pouvait y avoir des changements significatifs en URSS, mais sans transformation fondamentale du communisme, le contrôle total ayant toujours été l’objectif d’un parti qui se voulait omnipotent.

L'Américain Martin Malia s’est lui aussi inspiré de la pensée weberienne : le totalitarisme est un idéal-type, « toujours imparfaitement réalisé dans le domaine empirique ». Un idéal-type est une abstraction qui ne se retrouvera jamais telle quelle dans la réalité, mais qui permet néanmoins l’intelligibilité du phénomène sur le plan conceptuel, sa compréhension. Selon l'historien américain, le mot « totalitaire » ne veut pas dire que « des régimes de ce genre exerçaient de fait un total contrôle de la population (puisque c'est impossible), mais qu'un tel contrôle était leur aspiration fondamentale ». Les régimes tentent d'être totalitaires, mais la résistance des faits, de la réalité sociale ou économique, et la résistance active ou passive des populations, les en empêchent, et parviennent à préserver des espaces non-contrôlés.

La théorie du totalitarisme a connu un nouvel essor dans les années 1990. L'effondrement de l'URSS, en 1991, a partiellement donné raison à ses partisans. Les historiens de l'école révisionniste soutenaient majoritairement que le régime soviétique était un État moderne, puisqu'il était réformable. Or, les tentatives de restructuration menées par Mikhaïl Gorbatchev ont conduit à la ruine complète du système. Martin Malia annonça dès 1990 l'échec de la "perestroïka" dans un article publié anonymement qui connut un certain retentissement. Il y expliquait notamment que Gorbatchev échouerait parce qu'il restait trop « communiste » et que le système soviétique n'était pas réformable. Il présentait le régime « totalitaire » soviétique comme reposant sur quatre piliers intangibles :
Selon Malia, toucher à l'un de ces piliers, tous indispensables au maintien du système, revenait à provoquer son « écroulement total ».

Pour de nombreux historiens, le totalitarisme reste un concept-clé dans l'étude et la compréhension du . Pour Enzo Traverso, il est « un garde-fou de la pensée » : il « condense une image du dont l'oubli empêcherait de fonder une attitude responsable, tant sur le plan éthique que sur le plan politique, dans le présent ». En conclusion, l'historien italien juge le concept à la fois incontournable et insuffisant : « incontournable pour la théorie politique, soucieuse de dresser une typologie des formes de pouvoir, et pour la philosophie politique, confrontée à la nouveauté radicale des régimes visant l'anéantissement du politique ; insuffisant pour l'historiographie, confrontée à la concrétude des événements ».

Le mot « totalitarisme », entré dans le langage courant, est bien souvent utilisé sans les précautions méthodologiques nécessaires. Ayant une connotation forte, faisant penser aux régimes hitlérien et stalinien, il jette le discrédit facilement et marque les esprits. Il peut donc servir d'arme de propagande contre l'ennemi. L'usage du concept requiert une analyse approfondie de la société ou de la structure du groupe étudié, il faut en faire ressortir les catégories essentielles et les processus de dé-différenciation propres au totalitarisme.

Ainsi, la fin du et le début du ont vu fleurir de nouveaux néologismes politiques contenant « totalitarisme ». Cet usage met l’accent sur le fait que les actions ciblées aboutissent à imposer un régime qui remplit les critères du totalitarisme.

Le film libertaire "De la servitude moderne" décrit quant à lui la mondialisation et le système économique et politique qui l'accompagne comme un « totalitarisme marchand » où l'homme serait réduit à la condition d'esclave.

Michel Rostagnat considère que l'essence du totalitarisme est la mise en face-à-face entre l'individu et l'État, en supprimant les corps intermédiaires.

L'historien spécialiste de l’antisémitisme Georges Bensoussan pense que l'État islamique n'est pas islamo-fasciste car le fascisme est un concept européen qui ne rend pas compte de l'aspect complètement étranger de Daesh, mais bien une idéologie totalitaire tout comme l'était le nazisme.







</doc>
<doc id="15763" url="https://fr.wikipedia.org/wiki?curid=15763" title="Inflation">
Inflation

Linflation est la perte du pouvoir d'achat de la monnaie qui se traduit par une augmentation générale et durable des prix. Il s'agit d'un phénomène persistant qui fait monter l'ensemble des prix, et auquel se superposent des variations sectorielles des prix.

La monnaie étant l'étalon des valeurs, la variation de sa propre valeur n'est pas directement mesurable ; on l'évalue à partir des variations des prix à la consommation des biens et services, mesurée à quantité et qualité égales. L'inflation doit donc être distinguée de l'augmentation du coût de la vie car elle ne prend pas en compte la variation des quantités achetées en réponse à l'évolution des prix.

En France, l'inflation est évaluée au moyen de l’indice des prix à la consommation (IPC). Cette mesure est établie par l'Insee et employée par l'administration française comme indicateur de l'inflation. Dans le cadre européen (en particulier dans le Système européen de banques centrales), l'IPCH (Indice des Prix à la Consommation Harmonisé) est employé. Il s'agit d'un retraitement des postes de prix des indices nationaux (IPC en France, VPI en Allemagne, etc.) relevés par les instituts statistiques nationaux (Insee en France, Destatis en Allemagne, ISTAT en Italie, etc.) établi afin de rendre les indices comparables entre pays membres de la zone euro. Le retraitement consiste essentiellement en une légère modification des pondérations des différents postes entre indice national et IPCH, mais aussi à l'inclusion ou l'exclusion de certains postes de consommation (par exemple en France l'IPC considère le coût de déboursement des produits de santé, tandis que l'IPCH exige de prendre en compte la dépense de santé, nette de remboursements).

L'inflation est un phénomène à propos duquel les controverses entre économistes sont nombreuses : le débat porte sur les conséquences (qui sont parfois considérées comme positives), comme sur les causes. Justifiées par l'incidence concrète de ce phénomène sur l'ensemble de la population, ces controverses sont alimentées par les interrogations posées sur les mesures prises pour la contenir, et sur le degré d'interventionnisme étatique nécessaire pour ce faire.

Après la forte inflation des années 1970/1980, la France est en période d'inflation faible, depuis le début des années 1990.

Le terme inflation provient du latin : le substantif «"inflatio"» qui signifie gonflement, dilatation, est issu du verbe «"flare"» qui signifie souffler.

Jusque dans les années 1960, l'inflation désigne l'excès de moyens monétaires par rapport à l'offre (phénomène dont la hausse des prix et la perte de pouvoir d'achat de la monnaie résultent). Ainsi, Gaël Fain définit-il l'inflation comme .

Aujourd'hui, les définitions sont :

Assimiler donc l'inflation à la seule hausse de prix des biens de consommation, en excluant la hausse des prix affectant les valeurs patrimoniales (actifs, financiers, immobilier, etc.), peut être considéré comme un abus de langage, conséquence d'un mode de mesure restrictif de l'inflation.
Cependant, s'il est vrai que le terme d'inflation peut être appliquée à tout phénomène régulier d'augmentation du niveau des prix, la réalité demeure que la totalité des Banques Centrales ayant un objectif de politique monétaire de ciblage d'inflation visent bel et bien l'inflation des prix à la consommation, à l'exclusion notamment de l'inflation des actifs (asset price targeting).


Mesurer l'inflation consiste le plus souvent à observer un « panier » pondéré de biens représentatifs de l'ensemble des biens consommés par les ménages. En effet, ce sont les prix de consommation finale des ménages qui sont pris en compte dans la mesure d'inflation. Les prix intermédiaires (prix de transferts à l'intérieur d'une chaîne de production, prix de vente du producteur au détaillant, etc.) sont exclus du spectre de prix pris en compte pour l'inflation. Ces biens sont répartis parmi les différents postes de consommation des ménages. Les pondérations de ce panier sont définies par la part de la consommation représentée par chacun de ces biens ou services. Un indice des prix à la consommation mesure les variations enregistrées par le panier observé, traduisant ainsi la variation du coût de la vie pour les consommateurs, et de la valeur de la monnaie dans ses aspects les plus concrets pour les ménages.

Dans cette conception, les indices d'inflation se rapportent par construction exclusivement à la consommation des ménages, les prix des valeurs (mobilières comme immobilières), faisant l'objet d'un investissement potentiel de la part des ménages mais pas de consommation, sont exclus. Typiquement, les prix du logement sont exclus. Le taux d'inflation est la variation en pourcentage de cet indice sur une période donnée : si le prix moyen du « panier » passe de 100 à 102, l'inflation est de (102-100)/100 = 2/100 = 2 %.

La mesure du coût de la consommation des ménages ne suffit pas à caractériser totalement le bien-être des ménages :


Par ailleurs la politique monétaire des Banques Centrales vise de plus en plus à la maîtrise de l'inflation sur le moyen terme pour garantir la crédibilité de la monnaie : depuis les accords de la Jamaïque l'ancrage nominal des monnaies les unes par rapport aux autres, ainsi que l'ancrage des monnaies sur le métal - or ou argent - sont exclus. La crédibilité d'une monnaie est désormais assurée par la seule garantie, par l'action de la Banque Centrale afin que la valeur de la monnaie ne s'érode pas trop vite. Des débats se font jour pour savoir si le mandat de la Banque Centrale ne doit pas viser la stabilité des prix des actifs, plutôt que celle des prix à la consommation.

En effet, l'intermédiation financière produit des effets tels que les surcroîts de monnaie mis en circulation aboutissent non pas à une accélération des prix à la consommation, mais à une concentration d'argent sur des valeurs mobilières : bulles spéculatives sur l'immobilier japonais à la fin des années 1980, bulle des nouvelles technologies à la fin des années 1990, bulle financière des années 2000... D'où l'idée que la crédibilité des monnaies résulte davantage de la stabilité des prix des valeurs (mobilières et immobilières) que de celle des prix à la consommation qui se trouvent évoluer de manière plus modérée du fait du surcroît de concurrence généré par une mondialisation commerciale élargie.

Ce débat demeure très ouvert. Mais l'absence d'outil défini pour éviter que les liquidités s'accumulent sur certaines classes d'actifs (certains ensembles de valeurs mobilières ou immobilières) fait que bon nombre de Banques Centrales se réfèrent prioritairement à un objectif d'inflation mesuré par l'évolution des prix à la consommation des ménages.

La valeur de la production au cours d'une année dans un pays donné est mesurée par le PIB. Le PIB "nominal" (ou "à prix courants" ou "en valeur") est calculé avec les prix valables au cours de l'année considérée. Cette façon de mesurer fait croitre le PIB avec le déflateur du PIB.

C'est la variation du PIB en volume, et non du PIB en valeur, qui définit la croissance économique. Par définition, on a la relation suivante :
En pratique, on utilise souvent la formule linéarisée, valable pour des taux assez petits (on n'a gardé que les termes d'ordre 1, les termes d'ordre 2 étant négligés) :ou de façon équivalente :

Selon le Raymond Barre, s'il y a fréquemment divergence sur le diagnostic d'une situation d'inflation particulière, c'est qu'en effet plusieurs causes peuvent être pointées, séparément ou de manière combinée :

L'inflation a d'abord été considérée comme un désordre attribué à l'augmentation de la masse monétaire en circulation. C'est le point de vue théorique avancé par l'école quantitativiste au , à la suite d'Irving Fisher et, au avec l'École monétariste. Dans cette situation, en l'absence de création de richesse réelle, la conséquence directe se manifeste sous la forme d'une augmentation de la demande et par suite des prix. On considère que l'inflation monétaire résulte de l'émission par les autorités monétaires (l'État en général) de monnaie en trop grande quantité :
« Toutefois, il semble que de nos jours, la monnaie soit moins la cause de l'inflation que la condition permissive. »

Si la demande d'un produit ou d'un service essentiel excède l'offre, et que les producteurs ne peuvent ou ne veulent augmenter immédiatement la production, alors l'excès de demande va conduire à l'augmentation des prix. Le phénomène d'excès pouvant concerner un marché spécifique ou au contraire l'ensemble de l'économie, si, par exemple la demande générale est trop stimulée par une politique budgétaire ou par une offre de crédit bancaire trop dynamiques.

On dit qu'il y a inflation importée lorsque l'on veut souligner que les hausses de coûts résultent de l'augmentation des prix des biens importés, qu'il s'agisse de matières premières, de biens semi-finis ou de produits finis.

L'inflation est dite induite par les coûts si un élément essentiel des coûts augmente. C'est par exemple le cas quand les salaires augmentent plus vite que la productivité (le coût salarial par unité produite augmente) ou lorsque les matières premières ou l'énergie de base se renchérissent comme pendant les premiers et deuxièmes chocs pétroliers. La hausse des coûts se répercute alors dans les prix de revient, puis dans les prix de vente, d'où une hausse des prix. On parle ainsi d'effet de second tour de l'inflation.

L'inflation peut être induite par un état donné de la structure des marchés, ce qui signifie que la hausse des prix s'explique par les conditions de formation des prix sur les marchés ou dans les secteurs économiques. En particulier d'après Raymond Barre, les prix résultant de situations de concurrence imparfaites dans l'industrie ou les prix fixés par les pouvoirs publics dans le secteur agricole. En effet certains prix peuvent être qualifiés de « prix administrés » car ils sont davantage fixés non pas par les ajustements du libre marché mais par les décisions des firmes (les dirigeants entendent préserver un niveau de marge et/ou d'auto-financement) ou des considérations politiques.

Lorsque des phénomènes psychologiques s'ajoutent aux précédents, la combinaison des facteurs peut amplifier le mouvement de façon brutale :
Historiquement, quand la quantité de monnaie dépendait essentiellement de la quantité de métal monétaire (l'or ou l'argent) en réserve de la Banque centrale, une crise de production pouvait aussi produire de l'inflation, dans le cadre d'une spirale inflationniste combinant une inflation monétaire (trop de monnaie par rapport à la production), une inflation par la demande (en excès sur l'offre) et une inflation par les coûts.

Si l'inflation est modérée, elle peut favoriser la croissance en stimulant les investissements. Si l'inflation est forte, elle compromet la croissance et menace l'emploi, elle compromet la compétitivité d'une économie par la hausse des prix nationaux

L'inflation change le contexte des relations contractuelles explicite entre débiteurs et créanciers (dans le cadre d'un emprunt, mais aussi et surtout dans le cadre de toute transaction comportant un versement différé dans le temps, tel qu'un loyer, un fermage en numéraire plutôt qu'en nature, etc.). Elle change également le contexte entre les détenteurs d'actifs économiques dont la valeur n'est pas affectée par l'inflation (terrains, entreprises, etc.), et les détenteurs de monnaie ou titres financiers équivalent (rente à taux fixes, etc.) qui sont affectés par l'inflation. La déflation agit en sens inverse.

Pour être plus précis, ce n'est pas l'inflation ni la déflation qui comptent, ce sont les variations de l'inflation par rapport à celle qui était prévue ; ce qui est la même chose que l'inflation si, mais seulement si, l'anticipation était une variation nulle de la valeur de la monnaie (ce qui est implicitement le cas quand on raisonne aux prix courants). Une hausse de l'inflation ou une désinflation produisent un effet, pas une inflation égale à celle contre laquelle on a pu se prémunir.

Il faut noter que les entreprises sont des débiteurs nets (sauf exception et hors le cas d'entreprises financières), de même les autorités publiques en général, et que les ménages dans leur ensemble sont des prêteurs nets mais avec une proportion qui est débitrice (ex : les acheteurs de logement à crédit pour un montant plus élevé que leur patrimoine initial).



À noter que dans le cas de monnaie créée par le crédit adossé à des biens réels engagés par l'emprunteur, l'effet est plus complexe : l'émetteur (l'emprunteur) ne s'enrichit pas aux dépens des autres, qui peuvent toujours acheter les mêmes biens qu'avant pour le même prix ; il n'y a que si les biens gagés s'avèrent de valeur insuffisante que la monnaie correspondante devient inflationniste si elle n'est pas détruite (par le remboursement).

Lorsqu'un créancier (par exemple une banque) et un débiteur (par exemple un ménage) sont liés par un taux d'intérêt fixe, l'inflation favorise le débiteur au détriment du créancier (créditeur). Considérons un ménage qui emprunte à sa banque une somme S au taux d'intérêt nominal de 8 %, remboursable l'année suivante.

Si l'inflation est nulle, la banque touche l'année suivante la somme plus les intérêts prévus soit : S(1+0,08). La somme ayant la même valeur que celle prêtée (S ).

Avec une inflation de 3 %, la banque touche toujours la somme plus les intérêts prévus soit : S(1+0,08). Mais la somme rendue l'année du remboursement permet à la banque d'acheter moins que ce qu'elle aurait pu acheter l'année du prêt. La valeur réelle du remboursement reçu est : (1+0,08)(1-0,03)S soit approximativement (1+0,05)S de la somme prêtée. Ce qui signifie qu'en termes réels, le débiteur rembourse moins. Et même d'autant moins que le taux d'inflation excède le taux d'intérêt nominal de l'emprunt.

Lorsque le taux d'inflation est supérieur au taux d'intérêt nominal, le taux d'intérêt réel est négatif : c'est-à-dire que l'on gagne de l'argent à emprunter. Cela stimule d'ailleurs la demande et a tendance à alimenter davantage les pressions inflationnistes.

Face à une menace d'inflation, le créancier ne peut qu'imparfaitement se couvrir, l'inflation étant un phénomène imprévisible. Il peut alors soit avoir recours aux systèmes de couverture financière, notamment les swaps de taux d'intérêt pour les relations déjà établies, et demander dans les nouvelles relations des garanties, par exemple des contreparties du prêt peu sensibles à l'inflation (hypothèque sur un bien, valeur indexée sur l'inflation, valeur indexée sur un bien de référence comme l'or par exemple) ou un taux de remboursement indexé sur l'inflation (prêt à taux variable).

Pour les finances publiques, l'inflation diminue de la même manière le poids de la dette pour les États, et a parfois été délibérément utilisée à cette fin. Afin de se couvrir, lorsque l'État débiteur est suspecté de vouloir recourir à cette méthode, les investisseurs en dette publique demandent souvent une majoration du taux d'intérêt par intégration d'une prime de risques, ou l'indexation du taux selon une clause dite de révision ou selon la valeur d'un bien non contrôlable par l'État débiteur.(par ex : devise étrangère, panier de monnaies, valeur or, etc.).

Le type même de créancier perdant en période d'inflation est le rentier titulaire d'une rente fixe. Pour cet agent, la valeur de sa rente diminue proportionnellement à l'inflation sans possibilité de couverture. Les périodes de haute inflation du en France (années 1920, années 1960) ont conduit à la quasi-disparition des anciens rentiers, qui ont vu leur revenus réels laminés par l'inflation ; la leçon a été retenue et désormais la plupart des détenteurs de capitaux financiers se protègent contre l'inflation.

L'inflation réduit les revenus du travail pour deux raisons

Cela affecte le marché du travail : en effet, la réduction du coût réel de la main-d'œuvre est une des raisons expliquant une corrélation négative entre inflation et chômage, illustrée par la courbe de Phillips : la baisse du coût réel de la main-d'œuvre ouvre de nouvelles possibilités de production, ce qui entraîne une baisse du chômage.

Lorsque leur baisse de pouvoir d'achat devient sensible, les travailleurs exigent des corrections ; outre que cela ne va pas sans difficultés (relations sociales dégradées, grèves, etc.), les mécanismes d'indexation qui sont parfois obtenus nourrissent à leur tour l'inflation.

L'inflation influence la durée de détention de biens immobiliers. En effet, selon le CIPF, l'imposition sur la plus-value peut conduire à des situation où l'État impose des plus-values qui peuvent n'être en réalité que l'actualisation du prix du bien en tenant compte de l'inflation. Cet impôt sur l'inflation peut donc conduire à une durée de détention accrue des biens immobiliers afin de bénéficier davantage des abattements, ce qui réduit mécaniquement l'offre, et participe au maintien de prix de l'immobilier élevés.

Indépendamment des effets ci-dessus, essentiellement redistributifs, l'inflation a des coûts pour l'ensemble de l'économie, liés à des difficultés d'allocation efficace des ressources et aussi des gains, liés à l'irrationalité sur les marchés financiers.

Dans un premier temps, le niveau de l'inflation ou sa progression n'ont pas de conséquences directes sur l'économie. Si les agents savent que l'inflation sera de 3 % pour les années à venir, ils intégreront cette évolution dans leurs contrats, conduisant à une allocation des ressources identique à une situation sans inflation.

Cependant, l'inflation dépend souvent de décisions discrétionnaires, que les agents peuvent difficilement anticiper correctement. De ce fait, l'inflation fait peser un risque sur toute décision d'investissement ou de prêt, réduisant les incitations à des investissements productifs. Cet aspect doit toutefois être mis en balance avec l'effet négatif de l'inflation sur les investissements à revenus fixes, comme les rentes ou les emprunts d'État. En limitant la rentabilité de ces titres, un taux élevé d'inflation encourage la substitution vers les investissements à rendements liés à l'activité économique, généralement plus productifs du point de vue de l'emploi et de la création de richesses.

Dans un article de 1985, l'économiste Gregory Mankiw montre que les agents peuvent hésiter à ajuster systématiquement leurs prix face à l'inflation lorsque cela a un coût, même très faible, pour eux (l'auteur prend l'exemple du coût de changer les prix sur les menus des restaurants, qu'il faut faire réimprimer). Les agents n'ajustent alors l'allocation de leurs ressources qu'avec un retard. L'auteur montre que ces retards ont des conséquences importantes sur l'allocation d'ensemble des facteurs, conduisant à d'importantes inefficacités.

En pratique, l'arbitrage entre les différents effets de l'inflation conduit la plupart des économistes à estimer qu'un taux d'inflation stable proche des 2 % est un signe de bon fonctionnement d'une économie développée.

L'inflation agit directement sur la qualité des investissements. Un exemple permet de saisir le problème.

Alain, Bertrand et Claude investissent à l'année n (peu importe l'unité) dans un bien (par exemple une maison), dont ils se servent pendant un an, puis revendent (à l'année n+1). Supposons que les conditions économiques soient différentes pour les trois individus (zone monétaire, époque), le taux d'inflation est donc différent.

Le calcul naïf compare les valeurs en monnaie courante, sans tenir compte de l'inflation. Il semble alors que Claude a fait la meilleure affaire. Mais cela ne tient pas compte du fait que, à cause de l'inflation (ou, dans le cas d'Alain, de la déflation), ces trois personnes ne pourront pas acheter les mêmes biens de consommation avec la même quantité de monnaie : Alain pourra acheter plus, Bertrand et Claude moins. Pour gommer cet effet, il faut raisonner en monnaie constante, en déduisant l'inflation, et il apparaît alors que la meilleure affaire a été faite par Alain.

Néanmoins, l'inflation n'est pas la seule chose à prendre en compte, et le raisonnement complet devrait tenir compte des éléments spécifiques à chaque affaire, notamment l'utilisation que compte faire le vendeur de l'argent gagné et variation des prix (qui se superpose à l'inflation) dans le secteur en question. Si par exemple durant la même période le prix d'un fonds de commerce a augmenté de 30 % dans les trois pays et que les trois personnes veulent acheter un fonds de commerce, alors les trois ont perdu de l'argent durant cette période, et il aurait mieux valu pour elle acheter directement le fonds de commerce.

L'inflation peut déclencher ou aggraver des troubles sociaux, lesquels peuvent faire chuter un gouvernement. Par exemple, l'inflation est considérée comme une des raisons ayant poussé la population dans la rue lors de la révolution égyptienne de 2011 et lors de la révolution tunisienne de 2011.

L'inflation est un phénomène assez important pour que tout le monde en fasse sa propre estimation, mais cette évaluation est entachée de nombreux biais cognitifs. Outre que l'inflation "n'est pas" la simple hausse des prix des biens de consommation, c'est encore moins la hausse des prix de biens ou services qui frappent le plus l'esprit par leur répétition (l'achat de pain quotidien par exemple ; son importance symbolique est très supérieure à sa place dans le budget) ou les circonstances (service d'un plombier pendant un dégâts des eaux par exemple), pendant qu'on ignore les biens dont les prix restent stables. "L'inflation psychologique" est différente de celle calculée en pondérant correctement, ce qui conduit parfois à des polémiques sur la crédibilité des organes officiels de mesure de l'inflation.

"L'illusion monétaire" est, en sens inverse, ce biais cognitif qui consiste à raisonner en monnaie courante, sans tenir compte de l'inflation. Cette illusion conduira par exemple
On dispose de plusieurs instruments pour influer sur l'inflation, ou si nécessaire mettre fin à une hyperinflation. Pour une meilleure efficacité, il faut que ces différents moyens soient utilisés dans le même sens (par exemple, une politique budgétaire expansionniste et la politique monétaire restrictive vont se contrarier), notamment si ce sont des autorités différentes qui en sont responsables.

C'est de nos jours le principal outil de régulation de l'inflation.

Les autorités monétaires (banques centrales en général) injecteront des liquidités par différentes méthodes (planche à billet, achat de titre, baisse du taux directeur — le taux d'intérêt des emprunts ou des placements qu'on peut faire directement auprès de la banque centrale —, etc.) pour faire remonter la masse monétaire et donc le niveau d'inflation (l'objectif étant en général une inflation faible mais non nulle, pour éviter la déflation) ; pour faire baisser l'inflation elles agiront en sens inverse (arrêt de la planche à billet, vente de titre, augmentation du taux directeur, etc.).

La manipulation du taux directeur, outre qu'elle agit directement sur la masse monétaire, a d'autres effets économiques qui influeront sur l'inflation. Répercutée par les institutions financières sur leurs taux d'intérêt commerciaux (proposés aux entreprises, aux ménages, etc.), elle se traduit par une variation de la demande et de l'investissement (qui montent quand il est peu couteux de s'endetter et baissent dans le cas contraire). Le ralentissement de la demande (en cas de hausse du taux directeur) a généralement pour effet de faire baisser les prix (c'est-à-dire une baisse de l'inflation) ; inversement la baisse du taux directeur favorise l'endettement, stimule la demande et peut conduire à la hausse de l'inflation.

En régime de libéralisation financière une hausse du taux directeur destinée à freiner une économie en surchauffe peut générer des effets pervers qui contrarient les objectifs visés. La hausse des taux d'intérêt attire les capitaux étrangers à la recherche de meilleurs rendements. Cette abondance de capitaux contrarie le freinage souhaité. Les pays d'Europe centrale et orientale (PECO) se sont trouvés devant ce dilemme dans les années 1990, et principalement la Pologne et la République tchèque. Inversement une baisse des taux directeurs est susceptible de faire fuir les capitaux locaux ou étrangers et limiter les capacités de crédits que l'on voulait favoriser. Il s'agit là d'un des cas du théorème d'impossibilité évoqué par Michel Aglietta. On ne peut avoir à la fois un système national de contrôle prudentiel, un marché mondial de capitaux et une inflation contrôlée.

Les anticipations des agents sont déterminantes, de sorte qu'il suffit souvent d'une annonce par les autorités monétaires qu'elles envisagent telle ou telle action, pour que les agents économiques ajustent leurs anticipations et que la masse monétaire et l'inflation en soient affectées.

L'équilibre des forces entre offre et demande est un déterminant important des prix, donc de l'inflation. Or la politique budgétaire et fiscale peut-être utilisée sur les deux termes de l'équation :
Il s'agit d'une politique visant à exacerber les forces naturelles du marché.

Ce genre de politiques a des aspects fortement impopulaire, puisqu'elle consiste en pratique à réduire le pouvoir d'achat, à rendre encore plus cher (en termes réel) voire indisponibles les produits les plus demandés, dont il s'agit paradoxalement de juguler la hausse, même si, éventuellement, des produits qui n'augmentent pas autant sont rendus plus accessibles. On les accuse fréquemment de n'être que des politiques de récession (politique de rigueur), reproche adressé par des tenants d'une politique de la demande et d'une politique de relance, ainsi, du côté libéral du spectre, d'être des politiques interventionnistes dont la pertinence n'est pas plus assurée que les politiques opposées.

La politique de change permet de faire varier la valeur de la monnaie d'un pays par rapport aux devises extérieures. Par exemple, pour augmenter la valeur de la devise nationale (ou, de façon équivalente, pour en freiner la chute quand cette devise est « attaquée »), on rachète la devise nationale sur les marchés de change (ce qui implique de céder des devises étrangères, ou des biens de valeur comme l'or), ce qui conduit à une appréciation de la monnaie nationale. À l'inverse, quand un pays veut diminuer la valeur de sa monnaie, il achète des devises étrangères avec de la monnaie nationale (dévaluation, ou dépréciation de la monnaie nationale).

Un système de caisse d'émission ou "currency board" est l'application extrême d'une régulation de la valeur de la monnaie par la politique de change. Cela consiste à adosser la devise nationale à une monnaie étrangère dont la valeur est reconnue (ou un panier de monnaie). La valeur de la monnaie est ainsi stabilisée. Toutefois, l’État n’a plus la possibilité de financer son déficit budgétaire, ni de profiter des revenus issus de l’émission monétaire seigneuriage en faisant tourner la planche à billets, la monnaie locale ne pouvant être créée qu’en fonction des entrées dans les caisses de la Banque centrale de la monnaie référente. La caisse d'émission est donc efficace pour mettre fin à une politique monétaire victime de chocs hyper-inflationnistes. Le danger réside cependant dans le fait que bien souvent la devise nationale n'a en réalité pas la même valeur que la monnaie de parité. Cela peut notamment aboutir, via les mécanismes de marché, à faire naître une crise de confiance dans la capacité de la banque centrale à maintenir la parité. Dans certaines conditions, la seule solution pour la banque centrale est d'en sortir, mais cette sortie ne se fait pas sans douleur à l'image de la crise argentine de 2001 et de son Corralito.

En outre, la politique de change peut avoir des effets sur l'inflation, par le biais de la balance commerciale. En effet, en jouant sur la valeur de la devise nationale, l'état peut favoriser l'exportation (en dépréciant sa monnaie) ou rendre l'importation moins coûteuse (en appréciant sa monnaie). Cette dernière solution peut être utile pour diminuer l'inflation, surtout lorsqu'il s'agit d'inflation importée. Apprécier la monnaie peut aussi, théoriquement, agir sur la demande en freinant celle-ci, qui peut entraîner sur une diminution des prix (et donc une baisse de l'inflation) si l'inflation est causée par une demande trop forte.

Le contrôle des prix et des salaires est une mesure qui a une portée plus vaste et plus générale que le contrôle de l'inflation (en temps de guerre par exemple), mais il a aussi été utilisé spécifiquement pour combattre l'inflation. Cette méthode a connu des échecs retentissants (par exemple la loi du maximum général en 1793 en France, ou le contrôle général par l'administration Nixon en 1972 aux USA), cependant combinée à d'autres mesures dans un plan plus vaste on lui reconnait quelques succès ("Prices and Incomes Accord" en Australie ou "Akkoord van Wassenaar" aux Pays-Bas, tous deux dans les années 1980).

C'est que, s'il est facile de décréter un prix ou un taux d'évolution maximum, le faire appliquer est une affaire bien plus complexe. De plus, un prix maximum trop bas fait fuir les producteurs et raréfie la marchandise visée ; les producteurs se dirigent vers d'autres productions non taxées, ou d'autres clientèles (marché noir, marché étranger) ; et ce, alors que le prix bas augmente la demande. Il en résulte, paradoxalement, une forte pression inflationniste. La mesure a toutefois l'avantage de pouvoir s'appliquer immédiatement.

Un contrôle des prix et des salaires a plus de chance de fonctionner s'il est accepté par la société (notablement les syndicats, comme dans les exemples australiens et hollandais), mais il comporte de toute façon des aspects impopulaires.

Globalement, l'idée dominante est donc qu'un tel contrôle ne peut être que temporaire, le temps que des mesures réellement efficaces mais plus lentes fassent effet.

Lorsque l'inflation est engagée dans une spirale inflationniste nourrie par des indexations automatiques de salaires ou de prix sur la hausse précédemment constatée, on se dégage de cette spirale par une désindexation. En cassant les mécanismes d'indexation, on supprime un des aliments de l'inflation.

Lorsque l'inflation est trop forte, il arrive que la solution réside dans un changement complet de monnaie. La nouvelle monnaie doit avoir une valeur stable, ce qu'on peut réaliser en l'adossant à des actifs réels et reconnus (comme le Rentenmark, qui jugula l'hyperinflation de la République de Weimar en 1923).

Selon l'économiste Thomas Piketty, mis à part certains soubresauts, ayant duré quelques années voire parfois quelques décennies, durant lesquels se sont manifestés de fortes variations des prix qui ont toujours finis par se résorber, l'inflation est "...dans une large mesure [un phénomène] du ". De façon générale, poursuit-il, pour les quatre pays que sont la France, l'Allemagne, le Royaume-Uni et les États-Unis, l'inflation s'est maintenue à un taux moyen de 0,2 % - 0,3 % par an pour la période 1700 à 1913. Cette période se caractérise par une stabilité monétaire. Il en résulte un taux de change quasi fixe entre les devises des pays concernés ayant perduré durant ces deux siècles.

À partir de la Première Guerre mondiale et ce, pour la période 1913 - 1950, la France connaît une inflation de 13 % par an en moyenne et l'Allemagne de 17 % par an en moyenne (soit une multiplication des prix respectivement par 100 et par 300 pour cette période). Pour le Royaume-Uni et les États-Unis, l'inflation se serait maintenue autour de 3 % par an pour la même période. Pour la période 1950 - 1970, l'inflation s'est située en moyenne entre 2 % et 6 % par an. Elle est marquée à nouveau par une hausse pour la période 1970 - 1990 allant jusqu'à 10 % par an pour le Royaume-Uni et 8 % par an pour la France. La période 1990 - 2012 voit l'inflation revenir à un taux moyen de 2 % par an, toujours pour les quatre pays en question.

À l'époque des grandes découvertes en Amérique du Sud au , l'Espagne et le Portugal découvrent des quantités massives d'or et les importent en Europe. Cette période s'appelle le bullionisme, c'est un moment d'une extrême prospérité où l'or est abondant.

Certains financiers vont alors s'interroger sur la monnaie et son rôle, notamment Thomas Gresham avec sa Loi de Gresham. La monnaie repose sur un système de parité avec l'or : chaque pièce contient une somme d'or qui en fait sa valeur. Or, quand la quantité d'or augmente, son prix va baisser, et donc la valeur des pièces d'or de l'époque diminue: c'est la première observation de l'inflation, et amorce alors l'idée de la future théorie quantitative de la monnaie.

L'analyse économique de l'époque est essentiellement mercantiliste, selon cette théorie, chaque pays se doit d'accumuler de l'or et d'exporter pour devenir prospère. Jean de Malestroit et Jean Bodin sont connus pour leurs réflexions sur le rôle de la monnaie.

Cette école considère que toute monnaie est représentative d'actifs, qui ne sont pas nécessairement que l'or ou l'argent-métal comme le pense le bullionisme, mais peuvent être n'importe quelle valeur financière suffisamment liquide (un stock de marchandises, des actions ou des obligations, etc.). Dans ces conditions la valeur de la monnaie est dépendante de la valeur des actifs qui sont utilisés comme garantie pour l'émission monétaire, et il y a inflation ou déflation lorsque la quantité de monnaie émise (billets, etc.) ne correspond plus à la valeur réelle des actifs sous-jacents :

En 1911, Irving Fisher va être le premier économiste à modéliser mathématiquement l'inflation, en s'inspirant du bullionisme espagnol (Théorie quantitative de la monnaie). Il met en évidence une relation linéaire entre quantité de monnaie et le niveau général des prix :où formula_1 la masse monétaire, formula_2 la vitesse de circulation de la monnaie, formula_3 le niveau des prix et formula_4 le nombre de transactions pendant une période donnée).

La fonction principale de la monnaie est de permettre des transactions monétaires (par opposition au troc). Trois paramètres fixent la quantité de monnaie nécessaire :

Il en résulte que la hausse du niveau général des prix à moyen terme (si on suppose la vitesse de circulation constante) ne dépend que du rapport entre la masse monétaire et le PIB.

Le modèle classique repose sur l'idée de prix relatifs, chaque agent avec son revenu doit choisir entre deux biens selon l'utilité qu'il tire de la consommation de chacun des deux biens. Le prix des biens se fera donc selon le plaisir qu'il en tirera au détriment de l'autre bien. La monnaie est totalement absente, d'où l'utilisation de la maxime de Jean-Baptiste Say pour qualifier la neutralité de la monnaie.

On parle alors d'une dichotomie entre la sphère réelle (la production formula_5) et la sphère financière (la demande de monnaie formula_6). La monnaie n'est qu'un voile qui sert juste comme instrument d'échange sur un marché et ne peut être désirée pour elle-même, ce qui sera remis en cause d'abord par les cambridgiens, puis par Keynes.

Alfred Marshall et Pigou, deux économistes classiques de l'université de Cambridge vont créer l'équation de Cambridge. Elle traduit une fonction de demande de monnaie : c'est une légère rupture avec la pensée classique orthodoxe car elle admet que la monnaie est désirable. Elle va établir un lien entre la quantité de monnaie demandée formula_6 pour motif de transaction et le Produit intérieur brut formula_5. Soit, en notant formula_3 l’indice de prix agrégé du PIB et formula_2 la vitesse de circulation de la monnaie,
dite ici vitesse-revenu (c’est le nombre de fois où un actif monétaire change de mains au
gré de la distribution du revenu) :formula_11

Néanmoins cette équation redonne exactement les mêmes résultats que la Théorie quantitative de la monnaie.

La théorie keynésienne résulte d'une longue critique de la théorie classique par son père Keynes et ses proches, les post-cambridgiens. Deux livres fondateurs vont présenter une pensée totalement différente de la pensée classique, d'abord par "Treatise on Money" suivi du célèbre "Théorie générale de l'emploi, de l'intérêt et de la monnaie".

La monnaie est désirable pour elle-même, en effet les agents désirent et veulent de la monnaie, on parle de demande d'encaisse, pour trois motifs:

En cas de crise, les incertitudes poussent les agents à augmenter leur demande de monnaie (augmentation de l'épargne et spéculation négative), réduisent la demande de biens et l'investissement, augmente les exigences de rentabilité (le taux d'intérêt, qui traduit l'arbitrage entre la détention actuelle ou future d'un capital), ce qui renforce la dépression et valide les anticipations négatives. Keynes attribue la Grande Dépression à l'insuffisance de la demande qui fait chuter l'économie dans un équilibre de sous-emploi.

C'est une remise en cause fondamentale de l'équilibre général Walrasien. La monnaie cesse d'être considérée comme neutre.

Quelques années après la mort de Keynes (1947), William Phillips publie sa célèbre courbe en 1958 qui met en évidence (après analyse par Paul Samuelson et Robert Solow) une relation entre inflation et chômage. Cette relation va provoquer un réel engouement parmi les keynésiens qui se sont scindés en deux branches : les néo-keynésiens (école de la synthèse néo-keynésienne), et les post-keynésiens.

Les néo-keynésiens lient croissance, chômage, politique monétaire et inflation.
Grâce à cet enchainement, le modèle keynésien explique les variations de l'emploi durant les années 60s et permet de mener des politiques monétaires inflationnistes qui ont fait diminuer le chômage. On parle d'un arbitrage entre inflation et chômage.

Ce modèle montrera ses limites avec les chocs pétroliers, l'application des préconisations keynésiennes ne faisant qu'augmenter encore plus le chômage. Cela permettra l'ascension des monétaristes.

D'autres modèles néo-keynésiens, plus radicaux dans la remise en cause de l'équilibre général, vont tenter d'expliquer l'inflation ; un des modèles les plus modernes étant l'équilibre général avec rationnement mené par Robert Clower et Axel Leijonhufvud.

Les post-keynésiens sont des économistes qui se situent dans la pure tradition keynésienne. Ils remettent en cause la Théorie Quantitative de la Monnaie car ils voient l'inflation comme indépendante de la création monétaire. Selon eux l'inflation provient d'une tension sur le partage des revenus. Plusieurs raisons sont données :

Le courant monétariste a été initié par l'économiste américain Milton Friedman, « prix Nobel » d'économie 1976. Analysant lui aussi la grande dépression, Friedman estime qu'elle est due à une expansion déraisonnable du crédit, qui a provoqué une bulle spéculative dont l'éclatement marque le début de la crise, suivie d'un dégonflement tout aussi déraisonnable de la masse monétaire (réduite d'un tiers entre 1929 et 1933), qui a étranglé l'économie. Or la première partie du cycle est exactement le genre de politique que préconise Keynes. La conclusion de Friedman est donc que la manipulation de la masse monétaire est effectivement active sur l'économie, mais seulement à court terme et dans un sens négatif, soit en stimulant artificiellement le système économique en cas d'excès, soit en l'étranglant en cas de défaut. À moyen terme, sur un cycle complet, pour le monétariste la monnaie retrouve sa neutralité, liée aux caractéristiques économique du pays (le niveau normal de préférence pour la liquidité par exemple).

Dans ce cadre il considère que l'arbitrage entre inflation et chômage que la courbe de Phillips présente est un leurre : une réduction de chômage obtenue par hausse de l'inflation va rapidement conduire à une nouvelle hausse du chômage avec un niveau d'inflation plus élevé, poussant le pays vers la stagflation ou l'hyperinflation.

En opposition à la pensée keynésienne, la fonction de demande de monnaie est considérée comme stable, alors que la fonction de consommation keynésienne est estimée instable. La disparition de l'arbitrage inflation-chômage tient au fait des anticipations adaptatives des agents économiques : à court terme, lors de la négociation des salaires, ils ne connaitront pas parfaitement l'inflation et feront de mauvaises anticipations de telle sorte que leur salaire réel va diminuer et diminuera dans le même temps le chômage. Par contre, à long terme ils changeront de cadre d'évaluation (au lieu des « prix » on s'intéressera au « pouvoir d'achat »), l'illusion monétaire sera identifiée et combattue par les agents économiques, les politiques monétaires expansionnistes seront identifiées comme trompeuses et deviendront inefficaces, le chômage reviendra à son niveau naturel.

Les monétaristes en déduisent qu'il ne faut pas jouer avec la monnaie, que la politique monétaire ne doit pas subir l'influence de la politique, et donc qu'elle ne doit pas être confiée au gouvernement mais plutôt à des Banques Centrales indépendante, et que ces dernières doivent appliquer des règles stables, claires et publiques visant une quasi-stabilité du niveau des prix. La Banque centrale européenne en est un bon exemple actuel.

Robert Lucas développera le principe d'anticipation rationnelle, c'est une critique des anticipations adaptatives de Friedman. L'anticipation rationnelle stipule que les agents vont agir en moyenne de façon à anticiper au mieux l'inflation. On peut donc considérer que les salaires vont être indexés sur l'inflation.

C'est une hypothèse très forte qui a pour conséquence le rejet de toute intervention de l'État dans sa lutte contre le chômage, et prouverait que la courbe de Phillips serait totalement erronée.




</doc>
<doc id="15764" url="https://fr.wikipedia.org/wiki?curid=15764" title="République">
République

La République (avec un « R » majuscule) est l'ensemble des biens, des droits, des prérogatives de la puissance publique et des services propres à un État dont la forme de régime politique est la république. Elle est accessible également à tous ses citoyens et est la propriété collective de tous. Elle s'oppose à la propriété privée, de sorte que tout ce qui n'est pas privé est public, et réciproquement. La chose publique comprend tout ce qui est public dans un pays donné : le domaine public (routes, fleuves, canaux, forêts domaniales, nappes phréatiques, ports, domaine maritime, espace aérien, bâtiments publics, patrimoine des établissements publics, des départements et des communes…), les services publics, la fonction publique, les juridictions publiques, les registres (greffes, hypothèques, marques, sociétés, association…) et les dépôts publics (archives, musées, haras, conservatoires, bibliothèques, réserves d'or…), la langue nationale, la monnaie, les marques, sceaux, mesures et poids publics, les lois et règlements d'administration publique, les servitudes d'intérêt public, le gouvernement, le parlement, les académies, la force publique (gendarmerie, police, armée), l'Assistance publique, etc. La République est propre à un État national donné, elle est aussi ancienne que lui, elle est indépendante du régime politique de gouvernement.

La république (avec un « r » minuscule) désigne, avec le sens de régime politique se voulant démocratique, les États dont le chef est désigné par le peuple ou ses représentants. Dans ce sens, république désigne le régime politique antinomique de la monarchie (du type royaume, empire ou principauté) dans laquelle l'unité du pouvoir est symbolisée par une seule personne, appelée « monarque ». Cette définition n'implique pas que la république soit démocratique. La république est aujourd'hui la forme de régime politique la plus répandue : sur 193 pays, 136 sont des républiques, 34 des royaumes ou sultanats, trois des principautés et neuf des unions ou fédérations qui peuvent mélanger plusieurs formes d’États.

Le mot « république » provient du latin "res publica" qui signifie au sens propre « chose publique » et désigne l’intérêt général puis le gouvernement, la politique et enfin l’État. "La république (Politeia)" de Platon, "Le politique (Politikie)" d'Aristote et "De la république (De Republica)" de Cicéron traitent tous des formes de gouvernement. "Res", en langage juridique latin, désigne la cause plaidée ("Dictionnaire étymologique latin"). Historiquement il s'agit de la cause de la plèbe, plaidée par le tribun — représentant des « tribus » — devant le Sénat romain composé des patriarches des familles connues de Rome.

En 1576 Jean Bodin la définit dans "Les six livres de la République" comme le . Cet ouvrage décrit les principes symboliques et l'organisation juridique de la monarchie française où le terme de république est, bien que complexe dans son emploi, synonyme de la souveraineté d'un prince dans l'ordre de la loi naturelle. Dans "Du contrat social", Jean-Jacques Rousseau la définit comme Le terme est clairement synonyme de « gouvernement », de « bonne gouvernance ». Plusieurs courtisans du écrivent des poèmes où ils louent la bonne gestion par Louis XIV de la république.

République prend alors le sens de communauté d'esprit ou d'idée, dans le sens d'une recherche du bien commun dans un domaine donné. On trouve chez Blaise Pascal le concept de « République chrétienne » ("Pensées", liv. XXIV, 15) que reprennent Voltaire ou Rousseau dans leurs écrits. On voit encore apparaître celui de « République des Lettres » comme chez Montesquieu ("Lettres persanes", CXLII).

Au moment de la Révolution française, en référence à la République romaine qui s’est établie à la suite de la monarchie, le régime politique qui fait suite à l’Ancien Régime est baptisé « république » en référence à l'idéal de gouvernement romain. Le , en conséquence de la proclamation de l'abolition de la royauté, la Première République française est déclarée. Cependant, à cette époque, l'opposition entre république et monarchie n'est pas encore officiellement établie puisque, en 1804, Napoléon Bonaparte se considère comme "Empereur de la République française".

Par la suite, en français, le mot s'est confondu avec le mot démocratie par opposition au despotisme et à la monarchie. Une évolution de sens notable s'est opérée dans l'histoire récente, puisque jusqu'au la tradition opposait, d'après les "Politiques" d'Aristote, le régime issu de l'élection qui repose sur le choix de quelques-uns des citoyens selon leur mérite, leurs compétences ou leur richesse (l'oligarchie et l'aristocratie, qui devinrent par la suite la République), et un régime issu au moins partiellement du tirage au sort qu'il appelle démocratie. Le sens et l'intérêt du régime démocratique s'expliquait alors pour Aristote par l'idée de liberté politique, selon laquelle un citoyen est libre dès lors qu'il a alternativement le pouvoir de gouverner et d'être gouverné. Cette assimilation récente s’explique par l’histoire politique moderne des révolutions américaines et françaises, lors desquelles le problème de l'adoption de la démocratie a été débattu parmi les constituants qui la refusaient (notamment l'abbé Siéyès), lui préférant l'idée d'un gouvernement représentatif, autrement dit républicain.

Le régime de Vichy est fondé en opposition avec la République qui avait, aux yeux des partisans du Maréchal Pétain, provoqué la décadence du pays. Le nom officiel du régime politique est alors « État français ». Du fait de l'assimilation, profondément ancrée dans l'esprit des gens entre « république » et « démocratie », les deux mots sont souvent confondus. De ce fait encore, .

Une république islamique, , est la forme de gouvernement prise par un État qui n'a pas de monarque et où la gouvernance s'aligne sur le dogme de l'islam, comme c'est le cas en Iran, en Afghanistan ou au Pakistan. Une république islamique est donc une république qui fait référence à l'islam dans sa constitution.

À Rome, la République romaine (instaurée en -509) fait suite à la monarchie des rois étrusques. C’est une oligarchie patricienne. La conduite de la République est aux mains des consuls qui sont au nombre de deux et élus pour un an. Le principal organe constitutionnel est le Sénat qui réunit les représentants des familles patriciennes.

Dans la démocratie athénienne, c'est le tirage au sort qui désigne les représentants du peuple et non le vote comme pour ceux du peuple romain. Dans les deux cas, esclaves, femmes et non-citoyens sont exclus de tout rôle politique (cependant les femmes sont nécessaires pour transmettre la citoyenneté).



La définition humaniste d’un État libre, d’un État sans roi, se trouve chez Bartolus de Saxoferrato ("De regimine civitatis", vers 1350), Coluccio Salutati ("De tyranno", Florence, 1400) et Leonardo Bruni ("Laudatio fiorentinæ urbis", 1403-04). Ils utilisent alors le terme latin de "civitas" (« citoyenneté, ensemble des citoyens ») qui donne « cité » en français.

Fondée à la Renaissance, la république des Deux Nations remplace la monarchie polonaise par le gouvernement de l’aristocratie polono-lituanienne dans la droite ligne des oligarchies antiques.

En 1581, quand les Pays-Bas s’affranchissent de la tutelle espagnole et fondent la première république européenne digne de ce nom ils adoptent le nom de Provinces-Unies. Quand les Anglais secouent le joug de la royauté en 1649, ils fondent le Commonwealth, mot anglais .

La république du Bouregreg ou république de Salé est fondée en 1627, elle est de ce fait l'une des premières républiques à avoir été fondée dans le monde.

Dans les années qui suivent la proclamation de la République française, le modèle politique est largement exporté : la République batave naît en 1795, c’est la première et la plus durable république sœur de la France. La République ne s'oppose pas nécessairement à l'Empire. En effet toujours dans l'exemple de la République française, en 1804 le gouvernement français remet à l'Empereur la conduite de la République ; celle-ci ne disparaît donc pas avec le nouveau régime.




</doc>
<doc id="15765" url="https://fr.wikipedia.org/wiki?curid=15765" title="Chicago">
Chicago

Chicago (en anglais ou ) est la troisième ville des États-Unis par sa population et se situe dans le nord-est de l'État de l'Illinois. C'est la plus grande ville de la région du Midwest, dont elle forme le principal centre économique et culturel. Chicago se trouve sur la rive sud-ouest du lac Michigan, un des cinq Grands Lacs d'Amérique du Nord. Les rivières Chicago et Calumet traversent la ville.

Comptoir commercial fondé à la fin du par Jean Baptiste Pointe du Sable, un mulâtre d'origine française, Chicago devient une municipalité en 1833 et acquiert officiellement le statut de ville en 1837. Elle est le siège du comté de Cook. Chicago est aussi le siège d'une paroisse catholique francophone, signe de son histoire liée à la France.

La ville de Chicago compte et s'étend sur une superficie de . Ses habitants s'appellent les Chicagoans (ou plus rarement Chicagolais). Troisième ville des États-Unis par sa population, l'agglomération de Chicago est également la troisième du pays avec une population de s'étendant sur . L'aire métropolitaine de Chicago ("), communément appelée , compte et s'étend sur à travers trois États (Illinois, Indiana et Wisconsin), ce qui en fait la quatrième aire urbaine d'Amérique du Nord après Mexico, New York et Los Angeles.

Chicago est une ville de classe mondiale alpha. Elle constitue le deuxième centre industriel des États-Unis et appartient à la ("), mais la ville est aussi une des principales places financières du monde et la première bourse de matières premières agricoles au monde. C'est à Chicago que sont fixés les prix du blé et du soja aux États-Unis. La ville se classe au troisième rang national pour le nombre d'entreprises implantées dans son agglomération, dont les plus importantes sont Motorola, Boeing, United Airlines, McDonald's, Sears, Kraft Foods, Mondelēz ou encore les laboratoires Abbott. D'autres entreprises y ont été créées, comme Hertz, l'une des plus grandes enseignes de location de voitures. L'industrie emploie plus d'un million de personnes dans l'agglomération de Chicago.

Grâce à sa situation exceptionnelle, la ville constitue un centre de communication majeur de voies terrestres (l'un des plus importants en Amérique du Nord), et de transports aériens avec ses deux aéroports internationaux, O'Hare et Midway. Elle acquiert une grande renommée culturelle grâce à son architecture moderne de gratte-ciel et attire des millions de visiteurs chaque année. En effet, la Willis Tower (appelée jusqu'au mois de juillet 2009) a été de 1973 à 1998, le plus haut gratte-ciel du monde et est à ce jour le deuxième immeuble le plus haut du continent américain après le One World Trade Center à New York. Enfin, la ville compte de nombreux établissements d'enseignement supérieur, des musées prestigieux, des théâtres réputés et un orchestre symphonique de renommée mondiale.

Avant l'arrivée des premiers Européens, la région de Chicago est occupée par les Amérindiens Potéouatamis qui succèdent, vers le milieu du , aux Miamis et aux Sauk et Fox. Le nom de la ville proviendrait du mot miami-illinois », déformé par les Français en ou , qui signifie , ou encore , ce qui en dit long sur l'odeur pestilentielle régnant sur le site à l'origine. C'est le coureur des bois Louis Jolliet et le père jésuite Jacques Marquette qui, en 1673, revenant d'une expédition sur le Mississippi, parviennent à l'emplacement actuel de Chicago. Le site de Chicago fait d'abord partie du Pays des Illinois, dans la Louisiane française. Les Britanniques s'emparent de la région en 1763 au terme de la guerre de Sept Ans mais un nouveau conflit éclate (Rébellion de Pontiac) sur ce territoire qui prend le nom de « Territoires Indiens ». Cet ancien point de passage et de liaison des Amérindiens, des explorateurs et des missionnaires, entre le Canada et le bassin du Mississippi, devient un poste permanent de traite des fourrures.

Au , fort Chécagou ou fort Chicago est une forteresse, probablement occupée moins d'une année durant l'hiver 1685 ; le nom est désormais associé à un mythe selon lequel un Français y possède une garnison militaire. Deux mentions de ce fort qui apparut sur plusieurs cartes de la région au existent ; celle indiquant que le fort fut construit en 1685, et celle indiquant qu'Henri de Tonti envoya Pierre-Charles de Liette comme commandant du fort jusqu'en 1702. Cependant, aucune preuve archéologique ne vient confirmer ces annotations cartographiques. Le premier établissement permanent est fondé par Jean Baptiste Pointe du Sable à la fin du . Ce mulâtre, fils d'un marin français et d'une mère africaine esclave, est originaire de la colonie française de Saint-Domingue. Il épouse une Amérindienne et s'installe à l'emplacement actuel de Chicago, où il établit un comptoir commercial.

Durant la guerre d'Indépendance (1775-1783), le colonel George Rogers Clark s'empare de la totalité du Pays des Illinois au nom de la Virginie et le transforme en afin d'exercer un gouvernement théorique sur la région. En 1795, par le traité de Greenville et sous la contrainte du colonel Anthony Wayne, les Amérindiens doivent céder les terres situées à proximité de l'estuaire de la rivière Chicago. En 1803, l'achat des immenses territoires de la Louisiane française par les États-Unis renforce l'importance stratégique du lieu. La même année, le capitaine John Whistler arrive sur le site puis érige le Fort Dearborn en 1808. Entre temps, la région de la future Chicago est intégrée au Territoire du Nord-Ouest (1787-1809), puis au Territoire de l'Illinois (1809), avant de faire partie, depuis 1818, de l'État de l'Illinois. En 1821 et 1833, deux accords issus du traité de Chicago ont été conclus et signés entre les États-Unis et les peuples amérindiens Outaouais, Ojibwés et Potéouatamis (tous les trois représentés à travers le Conseil des Trois Feux) afin que ces derniers cèdent de plus grandes terres pour permettre la fondation et l'expansion de ce qui deviendra la ville de Chicago.

Le , la ville de Chicago se constitue avec une charte. Elle reçoit une charte par l'État de l'Illinois le pour se constituer en municipalité dirigée par un maire et six subdivisions appelées « wards ». Pourtant, les contraintes naturelles du site posent rapidement des problèmes d'aménagement. Chicago souffre d'un environnement marécageux qui rend très difficile l'installation de routes et d'égouts. Le développement effréné génère beaucoup de déchets industriels qui sont rejetés dans la rivière, provoquant de graves problèmes de santé publique et de contamination de l'eau potable. Pour remédier à la situation, les autorités engagent des travaux importants afin de surélever les infrastructures et d'implanter un réseau d'évacuation des eaux usées dans les années 1850. Elles décident, en 1900, de détourner la rivière pour préserver l'eau potable du lac, en creusant un canal (") qui s'ouvre sur le Mississippi. Le canal étant plus profond que le lit de la rivière, le cours fut inversé, protégeant ainsi le lac des déversements polluants. Les berges de la rivière elle-même subiront des transformations majeures, principalement à partir des années 1970, jusqu'à devenir un des pôles touristiques majeurs de la ville.

Chicago est une « ville champignon » qui grandit grâce à l'afflux d'immigrés en provenance d'Europe. Dès le milieu du , la présence des immigrés provoque l'essor du Know Nothing, un mouvement nativiste. Son candidat, Levi Boone, soutenu par la ', est élu maire. Il mène une politique discriminatoire et prohibitionniste, particulièrement préjudiciable aux immigrés allemands, ce qui provoque le , une émeute connue sous le nom de ', opposant WASP (") et immigrés catholiques.

En 1836, la ville devint un carrefour de communication avec le premier chemin de fer ("") qui joint Chicago à Clinton (Iowa) à à l'ouest. En 1860, onze lignes ferroviaires ont Chicago pour terminus et vingt autres y font un arrêt. Débutant sur la rivière Chicago et aboutissant sur la rivière Illinois sur une distance de , le Canal Illinois et Michigan est ouvert en 1848 et permet aux bateaux circulant sur les Grands Lacs de rejoindre le Mississippi en passant par Chicago. En 1854, Chicago est le plus grand marché de céréales du pays. La fondation du Chicago Board of Trade (CBOT) en 1848 s'inscrit dans ce développement économique considérable. Au , Chicago fut le plus grand marché mondial du bois, qui était transformé dans les nombreuses scieries de la ville et dans les industries du meuble, rendant l'économie de Chicago très florissante.

En 1847, Cyrus McCormick, l'inventeur de la moissonneuse, installe la production de machinerie agricole à Chicago. Les premières usines sidérurgiques ouvrent en 1858. C'est en 1865 que sont inaugurés les Union Stock Yards, les abattoirs de la ville où des méthodes modernes sont rapidement appliquées par les compagnies Armour et Swift.

En , environ sont réduits en cendres par le Grand incendie de Chicago (""). Un grand nombre d'infrastructures et d'habitations, construites en bois, permettent au feu de se propager facilement. Le bilan est dramatique puisque trouvent la mort et sont détruits, jetant à la rue environ une personne sur deux. On dénombre au moins . Quelques années plus tard, cette catastrophe permit à Chicago de mieux se développer d'un point de vue économique et urbanistique, faisant d'elle une des villes les plus importantes du continent américain.

À la fin du , l'économie de la ville se diversifie avec l'entrée dans la deuxième révolution industrielle. La reconstruction après le grand incendie de 1871 et le développement du chemin de fer stimulent les besoins en acier. Pendant la reconstruction qui fait suite au grand incendie, les abattoirs situés dans le sud de la ville connaissent un développement sans précédent grâce à la mise en service de wagons réfrigérés qui rendent possible l'expédition de la viande à New York. En 1956, les vestiges de la maison des O'Leary furent rasés pour la construction de l’Académie des Pompiers de Chicago ("Chicago Fire Department Academy"), un camp d’entraînement pour les pompiers de la ville. La sidérurgie et les besoins en matériel contribuent au développement des industries mécaniques : Chicago produit des machines agricoles, des équipements pour les automobiles, des wagons ("Pullman Company"). La confection pour homme est dynamique jusque dans les années 1920. La chimie se spécialise dans le traitement de l'eau, la production d'acide sulfurique et les phosphates. Les industries agro-alimentaires restent florissantes (transformation des céréales, conditionnement de la viande, etc).

En juillet 1877, les ouvriers du rail de Chicago se joignent et déclenchent une grève qui secoue les chemins de fer américains. Des affrontements entre la police et les grévistes ont lieu sur South Halsted Street et font 18 morts. Le , des ouvriers se rassemblent à l'usine McCormick pour revendiquer la journée de huit heures de travail quotidien, pour laquelle une grève générale mobilisant avait été lancée. Deux jours plus tard, les policiers tuent deux grévistes ce qui déclenche des émeutes qui font plusieurs morts. Sept policiers sont tués par l'explosion d'une bombe (Massacre de Haymarket Square). Quatre anarchistes sont accusés et exécutés en 1887. Le mai sert désormais de référence à la Internationale pour la fête des travailleurs. Les grévistes des usines de la Pullman Company dénoncent les baisses de salaire en 1894. À la suite de la répression organisée par le maire et le président américain Grover Cleveland, 12 ouvriers sont tués. Ayant participé à la grève, Eugene Debs, membre de l'American Railway Union, est arrêté par les forces de l'ordre.

L'industrialisation s'accompagne d'une paupérisation d'une partie de la population. En 1889, en réponse au mouvement social dénommé "settlement movement", Jane Addams fonde la première maison ("Hull House") qui sert de centre d'accueil pour les pauvres. En 1895, Florence Kelley dénonce les conditions de travail dans les "sweatshops" de la ville. En novembre de la même année, le "Chicago Times-Herald" organise l'une des première courses automobiles du pays, un concours de Chicago à Evanston. En 1905, Upton Sinclair publie "La Jungle", un roman qui décrit l'exploitation des immigrés lituaniens dans les abattoirs de Chicago.
Les femmes de Chicago obtiennent le droit de vote aux élections municipales en 1913.

Entre 1870 et 1900, la ville de Chicago se développe de manière spectaculaire passant de à presque . La ville connait alors la croissance démographique la plus rapide des États-Unis. L'économie de Chicago est alors florissante et amène des emplois à un nombre important de nouveaux résidents des communautés et des immigrés ruraux venus d'Europe. La croissance dans les secteurs de la fabrication au détail à Chicago est venue pour dominer la région du Midwest et pour influencer considérablement l'économie de la nation. Les yards d'actions des syndicats de Chicago dominent le commerce d'emballage. La ville devient le plus grand nœud de réseau de voies ferrées au monde, géré par la société Metra, disposant de plus de réparties sur différentes à travers l'agglomération.

Chicago accueille des vagues d'immigrants venus d'Europe de l'Est, de la fin de la guerre civile jusqu'à la fin de la Première Guerre mondiale. À partir des années 1910, plusieurs milliers d'Afro-Américains arrivant du Sud du pays pour fuir la ségrégation raciale devenue trop virulente s'installent à Chicago, dans l'espoir de trouver du travail dans les usines et les abattoirs de la ville. Ce mouvement, suscité par la ségrégation raciale, est appelé « Grande migration ». Avec ces nouvelles populations, concurrentes en matière de logement limité, et les travaux, particulièrement dans les quartiers sud de la ville (South Side), les tensions sociales montent dans la métropole. Dans les années 1920, on dénombre quelque du Ku Klux Klan à Chicago.

Les années qui suivent la fin de la Première Guerre mondiale sont les plus difficiles, lorsque la ville applique la ségrégation comme dans le sud du pays. Les Noirs sont alors séparés des Blancs, ayant chacun leurs écoles, leurs lieux publics, et leurs lieux de travail. Ils subissent la discrimination dans l'exercice de leurs droits politiques, n'ayant ainsi pas le droit de voter, et durant leur scolarité, restent souvent analphabètes. Dans le milieu professionnel, ils se retrouvent, la plupart du temps, au chômage ou cantonnés aux emplois les moins qualifiés. Les vétérans noirs recherchent plus de respect pour avoir servi leur nation.

Quelques mois après la réélection au poste de maire de William Hale Thompson, éclate à Chicago une émeute raciale, le dimanche . Déclenchée à la suite du meurtre d’un jeune Noir à la suite d'un jet de pierre, elle se propage à d'autres villes importantes à travers le pays et ne se termine que le 3 août, après l'intervention de plus de . Rien qu'à Chicago, ces émeutes durent , font , et des centaines de sans-abri. Une grande partie de cette violence est menée par des membres des clubs sportifs irlandais, qui ont beaucoup de puissance politique dans la ville et défendent leur « territoire » contre les Afro-Américains.

La population afro-américaine passe de en 1890 à en 1910 et en 1930. La communauté noire commence à s'organiser : ainsi le "Chicago Defender" est le premier journal consacré aux Noirs de la ville. Chicago devient un foyer majeur du jazz américain.

Lorsque l'émeute éclate, le maire se trouve à Cheyenne dans le Wyoming pour la célébration des "Frontier Days". Il rentre d'urgence à Chicago, alors que l'émeute est à son paroxysme. Malgré l'avis de ses conseillers, il refuse tout d'abord de faire intervenir la milice de l'Illinois afin de renforcer la police de Chicago. Ce n'est pas avant le 30 juillet, voyant s'accumuler le nombre de morts, de blessés et d'habitants dont les maisons ont été détruites, qu'il se décide enfin à demander l'intervention des gardes nationaux. Sa gestion plutôt hésitante de la crise ne lui vaut pas pour autant la défiance des Noirs qui voient en lui le politicien qui leur est alors le plus favorable.

Les années allant de la fin du au début du sont marquées par la présence de nombreux gangs qui se partagent le Nord et le Sud de la ville. Les secteurs se trouvant juste au sud-ouest de Downtown sont dominés par la Mano Nera (ou Main Noire), notamment le quartier de Little Italy. James Colosimo, surnommé « Big Jim » dans le milieu, réussit à s'imposer dans le quartier italien et à centraliser tous les gangs. Colosimo est né en Calabre en 1877 et émigre en 1895 à Chicago, où il devient criminel. En 1909, il domine la Mano Nera. Pour l'épauler, il fait venir son neveu Johnny Torrio de New York. Torrio amène Al Capone avec lui. Colosimo s'oppose à l'ambition de Torrio pour développer les affaires. En 1920, Torrio s'arrange avec Frankie Yale pour éliminer Colosimo.

Pendant la Prohibition, Chicago devient la capitale du crime organisé autour des figures de Frank Nitti, Bugs Moran et Al Capone. Les gangsters de la ville profitent de sa situation proche du Canada, d’où viennent les cargaisons d’alcool de contrebande. Surtout, ils trouvent des complicités auprès de juges, de politiciens municipaux et de policiers corrompus. En 1929, la guerre des gangs fait 29 morts dans la ville.

Le , une fusillade entre les deux principaux gangs fait sept morts : on parle alors du Massacre de la Saint-Valentin. C'est le temps des gangsters, de la corruption, de la violence, et de l'après : John Dillinger, célèbre braqueur de banque, est tué en 1934 au cours d'une fusillade avec les agents fédéraux dirigés par Melvin Purvis, dans le secteur de Lincoln Park alors qu'il sortait d'un cinéma en compagnie de sa fiancée Polly Hamilton. Selon les informations du FBI, Dillinger a été dénoncé par Ana Cumpanas, propriétaire d'une maison close. Les Incorruptibles ("Untouchables") est le surnom qui est donné par la presse américaine à un groupe d'agents du trésor américain (le plus célèbre est Eliot Ness) qui lutte pour faire respecter la prohibition. Ils menèrent une enquête longue et rigoureuse sur les différents gangs de la ville et en particulier sur Al Capone qui est finalement arrêté et emprisonné sur l'île d'Alcatraz, près de San Francisco. Capone meurt d’une crise cardiaque dans sa propriété de Floride en 1947.

L'ascension puis la chute de l'empire d'Al Capone dans les années 1920 et 1930 ainsi que son arrestation pour fraude fiscale n'a pas définitivement mis un terme au crime organisé dans la ville de Chicago. En effet, son gang est largement relayé depuis, car la mafia de Chicago, connue sous le nom d"'Outfit" (« l'équipe » en anglais), n'a jamais cessé ses activités et existe encore de nos jours. Aujourd'hui, le noyau de l'organisation ne comprendrait que 200 à 300 membres Affranchis et environ associés, c'est-à-dire moins que les organisations criminelles des autres villes. Les domaines dans lesquels ils opèrent incluent le prêt à taux usurier, la prostitution, les assassinats, le racket, les cambriolages, les braquages, les escroqueries financières, le blanchiment d'argent, le trafic de drogue, les trafics en tous genres, l'évasion fiscale ou encore les vols de voitures.

Sur le plan culturel, architectural et urbanistique, de la fin du jusque dans la première moitié du , Chicago se présente comme un .
L'aspect de la ville change fondamentalement. Le Grand incendie de 1871 permet aux urbanistes de penser à une reconstruction de la ville selon des critères modernes. L'exposition universelle ("World Columbian Exposition") attire 27 millions de visiteurs en 1893. Elle est l'occasion pour les promoteurs du mouvement architectural "City Beautiful" de réaliser plusieurs édifices qui font désormais partie du patrimoine de Chicago : le Musée des sciences et de l'industrie (MSI) dans le secteur de Hyde Park et le célèbre métro aérien de l'Union Loop dont le trajet forme une boucle qui délimite le secteur financier du Loop. Quelques années plus tard, fleurit l'école d'architecture de Chicago, qui connait un rayonnement international. La ville devient le laboratoire d'expériences architecturales : en 1885, le "Home Insurance Building", premier gratte-ciel au monde y est construit. Frank Lloyd Wright arrive à Chicago en 1889 et élabore un nouveau style d'architecture domestique, les "prairie houses". En 1909, l'architecte-urbaniste Daniel Burnham créé le Chicago Plan Commission, une commission mise en place pour élaborer le plan de Chicago de 1909, connu sous le nom de « Plan Burnham ». Il s'agit d'un nouveau plan d'urbanisme qui prévoit la restructuration urbaine du centre-ville, la rénovation et l'élargissement de boulevards déjà existants, la construction de plusieurs bâtiments municipaux, la mise en place d'un nouveau chemin de fer, la construction d'installations portuaires et l'aménagement de nombreux espaces verts dans les quartiers situés en bordure du lac Michigan. Chicago accueille l'architecte allemand Ludwig Mies van der Rohe dès 1938 qui contribue à diffuser l'influence du Bauhaus en Amérique.

La période 1871-1950 voit la création d'institutions culturelles qui font encore aujourd'hui la réputation de Chicago. En 1893, le Chicago Cultural Center devient la plus importante bibliothèque municipale, avant de devenir en 1977, le Centre d'art et de Culture de la ville. En 1991, la Harold Washington Library devient la bibliothèque centrale de Chicago. L'Institut d'art de Chicago (1879), le Musée Field d'histoire naturelle (1893) et le Musée des sciences et de l'industrie (1933) comptent parmi les musées les plus importants des États-Unis. En 1889, l' ouvre ses portes et accueille plusieurs compagnies de danse dont le Joffrey Ballet. Fondé en 1891, l'Orchestre symphonique de Chicago est l'un des plus anciens et des plus importants du continent américain.

Chicago devient un foyer culturel rivalisant avec les métropoles de la côte est des États-Unis, notamment New York. L'université de Chicago est inaugurée en 1892, grâce au don de l'entrepreneur John Davison Rockefeller. Elle se développe sur le modèle des universités allemandes et ouvre dès le début ses portes aux filles et aux Noirs. L'université se distingue par la création d'un département de sociologie dès 1892 (école de Chicago) qui connaît son âge d'or entre 1918 et 1935. Les sciences naturelles sont également bien représentées : l'université de Chicago fut le site de la première réaction nucléaire contrôlée, réalisée le par le physicien Enrico Fermi.

Enfin, Chicago devient avec La Nouvelle-Orléans l'un des berceaux du jazz au début du . C'est le qu'est enregistré "Livery Stable Blues" par l'Original Dixieland Jazz Band, un quintette formé de musiciens Blancs mené par le cornettiste Nick La Rocca. Dans les années 1920, la ville accueille également Louis Armstrong, qui fait ses premiers enregistrements et travaille avec Joe « King » Oliver. Une des principales raisons de la venue de musiciens Noirs à Chicago est la fermeture par décret de « Storyville », le quartier des spectacles de La Nouvelle-Orléans, déclenchant ainsi un important mouvement d'arrivée de musiciens dans la ville. À l'époque, le Friar's Inn était le lieu de prédilection de tous les amateurs de jazz de Chicago.

Amorcée pendant la guerre, l'immigration afro-américaine augmente fortement dans la ville. Les industries les plus gourmandes en superficie comme la viande et la sidérurgie ferment. Chicago réussit le tournant de l'aérien et s'affirme comme métropole mondiale. La ségrégation spatiale et la forte poussée démographique et culturelle de la communauté afro-américaine est marquée par l’action du démocrate Richard Joseph Daley, maire de Chicago de 1955 à 1976. Pendant les 21 années de son mandat, il dote la ville d'un palais des congrès, de plusieurs voies rapides dont la Kennedy Expressway, la Northwest Expressway, la Chicago Skyway, la Dan Ryan Expressway et la Southwest Expressway, aménage l'aéroport international O'Hare en 1963 et développe le secteur du Loop où plusieurs tours sortent de terre. Construite entre 1970 et 1973, la Willis Tower devient l’une des fiertés de la ville. Avec ses 110 étages et de haut, l’immeuble reste le plus haut du monde jusqu’en 1998 et le deuxième plus haut de l'hémisphère ouest à ce jour. Les ghettos noirs sont en partie rénovés. La foire internationale de 1959 célèbre l'ouverture de la voie maritime du Saint-Laurent et Chicago reçoit la visite de la reine Élisabeth II. Cependant, les mandats de Richard Daley sont marqués par la désindustrialisation : alors qu'en 1954 Chicago est la première ville américaine pour la production d'acier, la décennie suivante voit des fermetures en cascade. La sidérurgie n'est pas le seul secteur économique touché : les abattoirs sont délocalisés à Kansas City en 1971 ; le chômage augmente et les friches industrielles se multiplient.

À partir des années 1950, les classes aisées et moyennes quittent la ville pour s’installer dans les banlieues. Le , un incendie se déclare à l’école Notre-Dame des Anges dans le quartier de Humboldt Park : 92 étudiants et trois religieuses périssent dans la tragédie. Ce drame favorise l’amélioration des dispositifs anti-incendie dans les établissements scolaires du pays. En 1963, des boycotts des écoles publiques noires sont organisés pour protester contre les classes surchargées et la ségrégation opérée par le Chicago Public Schools. En 1966, Martin Luther King lançe une campagne contre la discrimination, le Chicago Freedom Movement. Une partie du mouvement pour les droits civiques se radicalise avec le Black Panther Party : le maire de l'époque fait assassiner deux membres influents par la police. Le , plusieurs quartiers noirs de West Side sont le théâtre de violentes émeutes qui font trois morts.

Les 4 et 5 avril 1968, des émeutes surviennent après l’assassinat de Martin Luther King dans les quartiers noirs de West Side et de South Side. La garde nationale doit intervenir et le bilan est de neuf morts. En août de la même année, pendant la Convention du Parti démocrate, le maire mène une politique répressive qui donne lieu à 660 arrestations, blessés et un mort. Il faut attendre 1983 pour voir la ville élire son premier maire noir, Harold Washington. Il décède durant son mandat d'une crise cardiaque en 1987, peu de temps après avoir été réélu pour un second mandat.

Entre le 13 et le 14 janvier 1979, soit 12 ans après le blizzard de 1967, une tempête de neige majeure touche Chicago et sa région. Le 13 janvier, de neige tombent sur Chicago, établissant un nouveau record de neige en une seule journée, après celui de 1967. À la fin du , de neige est tombée. Cela entraîne d'importantes complications sur le réseau de transports en commun de la Chicago Transit Authority (CTA), particulièrement pour le métro aérien sur l'Union Loop, dont les rails sont gelés. La réponse de l'administration du maire, Michael A. Bilandic, à ces intempéries est si lamentable qu'elle aboutit à l'élection de Jane Byrne, la première femme à accéder au poste de maire de Chicago.

Le 13 avril 1992, une inondation a lieu dans le secteur financier du Loop lorsque la paroi d'un tunnel de service passant sous la rivière Chicago, endommagée, ouvre une brèche qui laisse selon les estimations, un million de mètres cubes d'eau inonder les sous-sols et les équipements souterrains dans tout le quartier. Connue sous l'expression de « "Chicago Flood" », cette inondation cause de nombreux dégâts dont le montant est estimé à environ 1,95 milliard de dollars. C'est l'une des plus grandes catastrophes que la ville a connue, après le grand incendie de 1871 et le déraillement du métro sur l'Union Loop en 1977.

Depuis les années 1990, Chicago gagne à nouveau des habitants. Certains quartiers connaissent depuis quelques années un processus de gentrification, comme dans d’autres villes américaines. Ils sont rénovés et attirent de nouveau une population de classe moyenne voire aisée. Les quartiers résidentiels du nord de la ville sur le front de lac connaissent un renouveau démographique.

L’ambition de Richard M. Daley, fils de Richard J. Daley et maire de Chicago de 1989 à 2011, a été de favoriser la protection de l’environnement tout en maintenant Chicago parmi les métropoles mondiales les plus influentes. Les récents aménagements et les projets marquent cette ambition. Un grand nombre de gratte-ciel sortent de terre, manifestant ainsi la prospérité économique de Chicago. La superficie des espaces verts s'étend et le centre-ville est rendu plus sûr la nuit. Le dernier projet en date est la Chicago Spire : les travaux commencés en juin 2007 et devant s'achever en 2012 ont été stoppés à la suite de la crise financière de 2008, sans date de reprise. L'édifice devait alors être le plus haut du continent américain avec 150 étages pour de hauteur.

Avec un nouvel horizon d'ici 2020, le centre-ville se développe plus rapidement avec une atmosphère plus dense et plus respirable. Le département des buildings ("Chicago Department of Buildings") est un organisme de la ville responsable de l'application du Code du bâtiment à Chicago, régissant la construction et la réhabilitation ainsi que l'entretien des bâtiments, et le district des parcs de Chicago ("Chicago Park District"), l'organisme chargé de la gestion des parcs et des espaces verts municipaux travaillent ensemble sur le projet de rétablissement de la biodiversité et de la réhabilitation des secteurs endommagés par la restauration de certains bâtiments de la ville ainsi que par la création de nouveaux édifices, comme la création de jardin sur les toits des gratte-ciel à surface plate. C'est le cas notamment de l'hôtel de ville de Chicago ("Chicago City Hall"), qui depuis plusieurs années est doté d'un toit vert.

En matière de criminalité, la ville a presque définitivement fait oublier sa mauvaise réputation, héritée de la période agitée de la prohibition dans les années 1930. En 2006, elle ne faisait plus partie de la liste des 25 villes américaines les moins sûres. Cette baisse du sentiment d'insécurité est dû au renforcement de la présence policière, quasi permanente dans certains secteurs de South Side et de West Side qui sont restés pendant longtemps mal réputés.

Le 16 mai 2007, la ville de Chicago est sélectionnée par le Comité international olympique (CIO) comme l'une des quatre villes candidates officielles à l'organisation des Jeux olympiques d'été de 2016. Ses concurrentes sont Madrid, Rio de Janeiro et Tokyo. Malgré le soutien de nombreuses personnalités influentes, Chicago est éliminée dès le premier tour.

En 2008, Chicago obtient le titre de « Ville de l'année » par le magazine "GQ" pour ses récentes innovations architecturales et littéraires, son monde de la politique, ses musées réputés, ses universités prestigieuses, et son centre-ville qui est au premier plan dans les films "" en 2008 et "" en 2011. La ville est également évaluée, en 2003, comme ayant l'économie la plus équilibrée des États-Unis en raison de son niveau élevé de diversification. En 2009, la société de services financiers UBS place Chicago à la sur la liste des villes les plus riches du monde. En 2014, Chicago se trouve à la des villes américaines les plus visitées.

Chicago se situe dans le centre-nord des États-Unis, plus précisément dans le nord-est de l'État de l'Illinois, dont la capitale est Springfield. Elle se trouve au centre de la région agricole du Midwest (aussi appelée "Middle West"), une entité géographique comprenant huit États de la région des Grands Lacs. Ses coordonnées géographiques sont , soit la même latitude que Barcelone ou Rome. Au cours des , le territoire de la ville de Chicago se développe vers l'ouest et sur les rives du lac Michigan et atteint une longueur nord-sud d'environ sur une largeur est-ouest de , comprenant une superficie totale de (dont de terre et d'eau). Les communes de Norridge et de Harwood Heights sont enclavées dans la ville de Chicago, dans sa partie nord ouest. La majeure partie du territoire de la ville se situe dans le comté de Cook, tandis qu'une petite portion du secteur où se trouve l'aéroport international O'Hare est située dans le comté de DuPage. Il est relativement facile de se repérer dans Chicago, étant donné que les rues sont construites suivant un schéma rectangulaire. La ville est couverte par deux indicatifs téléphoniques régionaux : l'indicatif 312 (qui se restreint à Downtown Chicago) et l'indicatif 773 (qui coïncide avec tout le reste du territoire de la ville de Chicago, hormis Downtown).

Chicago se trouve à environ au sud-ouest de Toronto, la plus grande ville canadienne, à à l'ouest de Washington, D.C, la capitale fédérale, à à l'ouest de New York et à au nord-est de Los Angeles. Enfin, Chicago appartient à trois ensembles économiques importants : l'ancienne région industrielle de la "Manufacturing Belt" (la « ceinture des usines »), désormais appelée "Rust Belt" (« ceinture de la rouille »), la région agricole du Midwest (plus connue sous l'appellation de « "Corn Belt" »), et la voie de transport des Grands Lacs. Cette situation avantageuse explique en partie l'essor de l'agglomération.

La ville a une altitude moyenne d'environ au-dessus du niveau moyen de la mer. Le point le plus élevé () se trouve au sud de la ville, dans le quartier résidentiel de Hegewisch. Le site de Chicago a longtemps été une plaine marécageuse ("Chicago Plain") drainée par la rivière Chicago et la rivière Calumet. Plus à l'ouest coule la rivière Des Plaines qui se jette dans la rivière Illinois, un affluent du Mississippi. Chicago se trouve donc sur ligne de partage des eaux entre l'Atlantique et le Golfe du Mexique. Tous ces cours d'eau sont reliés entre eux par des canaux. Dans le sud-est de la ville se trouve le lac Calumet, une grande étendue d'eau qui, autrefois, se déversait par l'émissaire de la rivière Calumet vers le lac Michigan par l'intermédiaire de deux bras, le petit Calumet et le grand Calumet.

Chicago repose sur un soubassement rocheux datant du Silurien (entre 443,7 à 416 millions d'années) recouvert par les dépôts sédimentaires au cours de la dernière glaciation du quaternaire ("Equality Formation"). Le Lac Michigan se forme à la fin de la dernière ère glaciaire (glaciation du Wisconsin), il y a environ , quand l'inlandsis laurentidien recule en laissant de grandes quantités d'eau de fonte. La région des Grands Lacs fait partie de la grande dépression centrale d'Amérique du Nord s'étendant vers le sud en direction de la plaine du Mississippi. Une partie de la rive actuelle est l'effet d'une poldérisation réalisée avec les remblais du grand incendie de 1871. Le lac Michigan a toujours représenté une source d'eau potable et une voie de transport importante, faisant la liaison avec les autres Grands Lacs. Il a permis l'installation du port de Chicago et le développement d'activités de loisirs.

D'après la classification de Köppen avec la station Midway : la température moyenne du mois le plus froid est inférieure à (janvier avec ) et celle du mois le plus chaud est supérieure à (juillet avec ) donc c'est un climat continental. Les précipitations sont stables, donc il s'agit d'un climat continental froid sans saison sèche. L'été est chaud car la température moyenne du mois le plus chaud est supérieure à (juillet avec ).

Donc le climat de Chicago est classé comme Dfa dans la classification de Köppen, soit un climat continental humide avec été chaud.

Située à l'intérieur des terres, la ville est marquée par le caractère continental du climat et la circulation méridienne des masses d'air : la température moyenne annuelle est de . L'amplitude thermique annuelle est forte () ; les précipitations qui sont à peine supérieures à par an sont plus irrégulières que sur le littoral atlantique et le maximum arrive en été sous forme d'averse chaude, souvent du à des orages de chaleur qui peuvent parfois produire de la grêle, des vents violents et plus rarement des tornades. La température et le temps peuvent changer brutalement en hiver comme en été.

Les hivers sont froids voire rigoureux : le gel persiste longtemps, généralement de novembre à mars. Il est engendré par les descentes d'air froid ("coldwaves") depuis le Canada qui ne trouvent aucun obstacle montagneux. Le lac Michigan gèle partiellement chaque hiver. Si la neige peut tomber au début de l'automne et du printemps, elle est plus importante en hiver. Le blizzard se manifeste en hiver et peut paralyser la ville, comme les autoroutes et les transports en commun de la CTA. Sur l'année, il tombe en moyenne de neige.

Les étés sont chauds et humides à cause des vagues de chaleur qui remontent du golfe du Mexique et qui provoquent des canicules puis les fameux « étés indiens » au début de l'automne. Le surnom de la « Ville des vents » ("") vient en partie du fait des vents qui soufflent depuis le lac Michigan et qui s'engouffrent dans les rues de la métropole. Il existe des nuances climatiques dans l'agglomération : le climat est plus tempéré sur les rives du lac Michigan, qui agit comme un régulateur thermique en rafraîchissant les températures en été, en les rendant plus douces en hiver. Chicago bénéficie d'un ensoleillement relativement élevé pour une ville du nord avec 2508.4 heures en moyenne par an.

Le , une tempête de neige majeure touche la région de Chicago ; la hauteur de neige atteint les en moyenne avec des congères d'environ dans certaines rues. En 1979, une autre tempête de neige ayant affectée la ville génère de nombreuses critiques à l'encontre de la municipalité de Chicago. Les blizzards de 1967 et 1979 sont les plus virulents de l'histoire de Chicago.

Quelques faits météorologiques remarquables :


La ville de Chicago est divisée en 77 secteurs communautaires (en anglais : "Community Areas"), définis à la fin des années 1920 par le comité de recherche en sciences sociales de l'université de Chicago. Ces secteurs communautaires furent essentiellement créés pour les données démographiques et statistiques de la ville de Chicago et du bureau du recensement des États-Unis et servent également de base à une variété d'initiatives en matière de planification urbaine, à la fois au niveau local et municipal.

Longtemps terre d'immigration, Chicago compte parmi ses habitants de nombreuses communautés d'origine étrangère, comprenant ainsi des Irlandais, des Italiens, des Russes, des Allemands, des Espagnols, des Polonais (Chicago est la plus grande ville polonaise en dehors de la Pologne), des Chinois, des Coréens et des Mexicains. Elles affichent une volonté d'intégration, même si chacune reste attachée au quartier de sa communauté, et sont l'exemple vivant d'un « creuset démographique » ("") qui, ici plus que partout ailleurs aux États-Unis, donne à la ville son caractère cosmopolite.

D'un point de vue géographique, la ville de Chicago est divisée par la rivière Chicago ("Chicago River") en quatre sections : North Side, Downtown, West Side et South Side qui incluent chacune de nombreux secteurs et quartiers de la ville. La section correspondant à Downtown Chicago est la plus petite et se compose des trois secteurs centraux qui constituent le centre-ville (ainsi que le "central business district") : Near North Side, Loop et Near South Side. La section la plus grande est celle de South Side qui couvre à elle seule environ 60 % de la superficie totale de Chicago.

Chicago compte environ 228 quartiers ("") répartis à travers les 77 secteurs communautaires de la ville. Il s'agit pour certains d'entre-eux de quartiers « ethniques » qui maintiennent chacun une identité forte ; les plus connus sont situés non loin du secteur financier du Loop, comme Little Italy, Chinatown, Pilsen, Bronzeville, Greek Town, Bridgeport, Little Vietnam, Indian Village et Ukrainian Village ainsi que des quartiers allemands, polonais, afro-américains et hispano-américains, qui n'en sont pas très éloignés. La ville possède aussi des quartiers qui, sans être ethniques, sont très attractifs pour leurs habitants comme pour les visiteurs. Ainsi, Rogers Park, dans le North Side, secteur étudiant connu pour abriter l'université Loyola, passe pour être l'un des plus prisés de la ville. North Center et Uptown sont deux secteurs liés aux affaires et dotés de nombreux centres commerciaux, boutiques et restaurants. Jefferson Park, un secteur historique et populaire du nord de la ville, connu à Chicago pour son parc éponyme. Lakeview, situé au nord de Lincoln Park, est l'un des secteurs les plus dynamiques de la ville et jugé très attrayant avec ses bars, ses boîtes de nuit et ses commerces. Le secteur de Lincoln Park est surtout connu pour être le secteur comprenant le plus grand parc public urbain de toute la ville, Lincoln Park. Dans le South Side, le secteur historique de Pullman est connu pour avoir abrité les usines et les employés de la Pullman Company et le secteur de Hyde Park pour renfermer dans ses limites l'université de Chicago et Jackson Park.

Le secteur du Loop (qui signifie en français « la boucle ») représente la partie centrale de Downtown Chicago, qui est le deuxième plus important quartier d'affaires des États-Unis après Manhattan à New York. Le secteur du Loop s'étale sur plusieurs kilomètres de long entre les rives du lac Michigan et celles de la rivière Chicago. Il comprend plusieurs quartiers dont New Eastside, situé dans le nord-est du Loop, qui présente la particularité de posséder un réseau de rues qui s'enchevêtrent sur un triple niveau, South Loop, un quartier récent et animé, et Printer's Row, le « quartier des artistes ». La partie Est du secteur du Loop se compose de Grant Park qui renferme en son sein le Millennium Park.

L'Union Loop est l'infrastructure aérienne du métro de Chicago où s'entrecroisent toutes les lignes du réseau (hormis la ligne jaune) et dont le circuit en forme de boucle se trouve au cœur du Loop, d'où le nom du secteur. Il s'agit de l'un des réseaux de métro les plus anciens du monde.

Le système de numérotation des rues de la ville commence dans le Loop à l'intersection de State et Madison, marquant ainsi l'importance de ce quartier pour l'ensemble de la ville. Ce secteur, autrefois mal famé, a laissé place aux centres financiers, aux commerces et aux immeubles de grande hauteur qui constituent une partie de la "skyline". Il est bordé au nord et à l'ouest par la rivière Chicago, à l'est par le lac Michigan et au sud par la Roosevelt Road. Il abrite de nombreux gratte-ciel, dont le "Home Insurance Building" (détruit en 1931), considéré comme le plus ancien au monde et la Willis Tower, le deuxième plus haut du continent américain après le One World Trade Center de New York.

Situé dans le secteur de Near North Side, le quartier de Streeterville comprend de nombreux hôtels, des restaurants, des boutiques de luxe, des immeubles résidentiels de grande hauteur, des universités, des installations médicales, et des lieux culturels. Le quartier connait, ces dernières années, un essor économique et de nombreux terrains vagues dans Streeterville sont reconvertis en propriétés résidentielles et commerciales. Plusieurs quartiers historiques se trouvent à Streeterville dont le Old Chicago Water Tower District et le Michigan–Wacker Historic District. Le Old Chicago Water Tower District comprend des édifices prestigieux comme la Chicago Water Tower, un château d'eau en forme de tour de style néo-gothique, et la Pumping Station, une station de pompage datant tous les deux de 1869. Le Michigan–Wacker Historic District s'étend autour du pont de Michigan Avenue et comprend la Tribune Tower, siège de "Chicago Tribune", le Wrigley Building ainsi que plusieurs bâtiments historiques datant des années 1920 tels que le 333 North Michigan.

Situé dans le secteur d'Armour Square, au sud-ouest du Loop, le quartier chinois est très caractéristique avec sa rue commerçante, son hôtel de ville chinois et sa chambre de commerce (tous deux regroupés au sein du Pui Tak Center), son temple chinois, son musée Ling Long (qui retrace l'histoire des habitants du quartier), et son parc asiatique : le Ping Tom Memorial Park. Aujourd'hui, il abrite encore des descendants des premiers immigrants chinois arrivés dans la ville vers 1870, longtemps après les premiers peuplements de la Californie, de l'Oregon et de Washington, et ceux de la seconde vague d'immigration, qui vinrent s'établir dans les années 1950 et 1960 après la révolution communiste en Chine.

Le quartier chinois de Chicago est réputé pour ses nombreuses banques, ses restaurants chinois, ses boutiques, ses épiceries, ses magasins de médecine chinoise, et possède un grand nombre de services destinés aux personnes s'intéressant à la culture chinoise.

Outre le fait qu'il abrite une communauté chinoise, le quartier constitue un centre d'affaires d'importance régionale pour les Chinois vivants dans la région du Midwest, ainsi qu'une destination touristique. Le quartier chinois de Chicago est le troisième du pays en nombre d'habitants, derrière ceux de New York et de San Francisco. Chicago possède d'autres quartiers asiatiques comme Little Vietnam qui se trouve dans le secteur de Uptown où vit une population majoritairement d'origine vietnamienne, cambodgienne, thaïlandaise et laotienne.

Bronzeville est le principal quartier afro-américain de Chicago. Il s'étale sur les secteurs de Douglas et Grand Boulevard autour de l'Institut de Technologie de l'Illinois. Dans ce quartier se trouvent le Wabash Avenue YMCA, un centre social historique et la Ida B. Wells-Barnett House, résidence de l'avocate des droits civiques Ida B. Wells. Érigé en 1927 dans Bronzeville, le Victory Monument est un "Chicago Landmark" dédié au huitième régiment de la Garde nationale de l'Illinois, une unité afro-américaine qui a servi en France pendant la Première Guerre mondiale.

Au début du , Bronzeville est connu comme étant « la métropole noire » ; le quartier est l'un des "Chicago Landmarks" les plus significatifs de la nation en matière d'histoire urbaine afro-américaine. Entre 1910 et 1920, pendant la crête de la « Grande migration », la population du secteur augmente considérablement alors que des milliers d'Afro-Américains, opprimés et chassés par les sudistes, émigrent à Chicago à la recherche des travaux industriels.

Pilsen est un quartier mexicain situé dans le secteur de Lower West Side. À la fin du , il est habité par les immigrés tchèques qui le nomment « Plzeň », du nom d'une région et d'une ville de République tchèque. Il reçoit également, en plus petit nombre, d'autres groupes ethniques de l'empire austro-hongrois : des Serbes, des Slovaques, des Slovènes, des Croates, des Bosniaques, des Hongrois et des Autrichiens, mais aussi des immigrés d'héritage polonais, estoniens, lettons et lituaniens. Au début du , ces immigrés travaillent en nombre dans les parcs industriels et les usines environnantes, qui sont alors autant de voisinages urbains américains. Pilsen est autant peuplé de riches que de pauvres, ses habitants, pour la plupart de descendance slave, n'étant pas spécialement les bienvenus dans les autres quartiers résidentiels de Chicago. Aujourd'hui Pilsen est un quartier à dominance mexicaine et se compose essentiellement de lotissements résidentiels.

L'architecture de Chicago a pendant longtemps influencé et reflété l'histoire de l'architecture américaine. La ville de Chicago comprend certains des bâtiments figurant parmi les premiers à être réalisé par des architectes reconnus dans le monde entier. Comme la plupart des bâtiments du centre-ville ont été détruits par le grand incendie de Chicago en 1871, les bâtiments de Chicago sont réputés pour leur originalité plutôt que pour leur ancienneté. L'Exposition universelle de 1893 ("World's Columbian Exposition") fut l'occasion de mettre en œuvre les théories du mouvement "City Beautiful" et de construire des bâtiments de styles Beaux-Arts et néo-classique comme le Musée Field d'histoire naturelle, le Musée des sciences et de l'industrie, le Chicago Cultural Center ou encore l'Institut d'art de Chicago.

C'est au début des années 1880 que l'école d'architecture et d'urbanisme de Chicago acquit sa renommée internationale dans la construction en armature d'acier, puis, à partir des années 1890, dans l'utilisation des vitres pour les façades. Jusqu'aux années 1900, l'architecture de Chicago sera marquée par les réalisations de Daniel Burnham, Dankmar Adler, Louis Sullivan, William Holabird, Martin Roche et John Wellborn Root, tous issus de l'école de Chicago. Parmi les premiers bâtiments modernes de la ville, le "Home Insurance Building", construit en 1885 par William Le Baron Jenney, est souvent considéré comme étant le premier gratte-ciel de l'histoire. Bien que la majeure partie du bâtiment était faite de brique et de pierre, il est le premier immeuble de grande hauteur à ossature métallique avec des colonnes en fonte et des poutres en acier. Les architectes de l'école de Chicago se concentrent sur les bases d'une architecture spécifiquement américaine qui favorise la simplicité des formes. Au début du , Chicago fut le principal foyer du mouvement architectural de la "Prairie School" avec les bâtiments dessinés par Frank Lloyd Wright, dont beaucoup sont classés "Chicago Landmarks" tels que la James Charnley House (1892) et la Robie House (1908-1910).

Le Montauk Building, conçu entre 1882-1883 par John Wellborn Root et Daniel Burnham, est le premier immeuble dont l'acier fut le principal matériau utilisé pour sa construction. Dans son livre sur l'Exposition universelle de 1893, Erik Larson déclare que le Montauk Building est devenu le premier bâtiment à s'appeler un « gratte-ciel ». En 1885, le premier gratte-ciel à charpente d'acier s'éleva à Chicago, déclenchant l'ère des gratte-ciel aux États-Unis, notamment à New York, puis dans le reste du monde. Dans le milieu des années 1890, Daniel Burnham, Racine et Charles Atwood conçurent des immeubles avec des armatures en acier, du verre et de la terre cuite. Cette nouvelle approche de l'architecture a été rendue possible grâce aux entrepreneurs modernes comme George A. Fuller et aux ingénieurs professionnels, en particulier ceux issus de la migration européenne.

Comme les autres métropoles américaines, l'architecture de Chicago se caractérise par une grande diversité. Ainsi, les bâtiments situés sur le campus de l'université de Chicago, la Tribune Tower, et plusieurs églises comme la "Second Presbyterian Church" et le "Chicago Temple Building" sont de style néo-gothique. La basilique Notre-Dame-des-Douleurs de Chicago et l'église Sainte-Hedwige sont de style néo-Renaissance. Le style Art déco s'est imposé à la fin des années 1920 et a explosé à partir de 1930 avec notamment le Chicago Board of Trade Building, le Merchandise Mart ou encore le Carbide & Carbon Building. Le Style international s'est surtout imposé après 1945 avec le Crown Hall. Enfin, les quartiers ethniques se distinguent par leurs styles architecturaux importés comme Chinatown avec son temple chinois et sa chambre de commerce (Pui Tak Center) ou encore Ukrainian Village avec ses églises orthodoxes à bulbes, comme la cathédrale de la Sainte-Trinité. Dans les années 1960-1970, le désir de préserver le patrimoine architectural de la ville se développa. En 1966 fut créée la Chicago Architecture Foundation qui permit la sauvegarde de l'une des plus anciennes demeures de Chicago, la John J. Glessner House, construite entre 1885 et 1886 par l'architecte Henry Hobson Richardson.

Aujourd'hui, le panorama urbain de Chicago compte parmi les plus importants du monde. En effet, au mois d'août 2009, il y avait 1098 gratte-ciel dans la ville, ce qui fait de Chicago la seconde métropole du continent américain derrière New York à posséder autant d'immeubles de grandes hauteurs dans ses limites municipales. Par le nombre de gratte-ciel, Chicago est la quatrième ville dans le monde après Hong Kong, New York et Tokyo. Les bâtiments historiques du centre-ville incluent le Chicago Savings Bank Building, le 35 East Wacker, la Mather Tower ou encore le Second Leiter Building dans le Loop. De nombreux bâtiments historiques sont situés en bordure du lac Michigan et de la rivière Chicago. Deuxième centre d'affaires derrière celui de Manhattan, le secteur financier du Loop possède le deuxième plus haut immeuble du continent américain, la Willis Tower ; achevée en 1973 et comprenant 108 étages, la tour est avec ses le plus haut gratte-ciel du monde jusqu'en 1998, et des États-Unis jusqu'en 2013. Des gratte-ciel déjà construits comme le 111 W. Wacker, la et le 200 North Riverside Plaza, actuellement en construction comme le Wanda Vista (), ou en projets comme la Gateway Tower (), redessinent le panorama urbain de Chicago.

Le code postal 60602 est considéré par le magazine "Forbes" comme étant l'adresse américaine la plus charismatique du pays, comprenant ainsi dans ses limites, des bâtiments classés dans les prestigieuses listes des lieux et édifices protégés, comme les "Chicago Landmarks" (au niveau municipal) et les "National Historic Landmarks" (au niveau fédéral). Des immeubles tels que l'Auditorium Building, le Rookery Building ou encore le Fine Arts Building y sont classés. La dernière génération de gratte-ciel Chicagoans se trouve dans les secteurs de Near North Side et Near South Side, situés respectivement au nord et au sud du secteur du Loop. En effet, si la grande majorité des immeubles de grande hauteur se situe dans le Loop, le quartier des affaires de la ville ("Central business district") s'étend depuis plusieurs années sur les secteurs limitrophes. Des genres multiples de maisons urbaines, de condominiums et d'immeubles peuvent être trouvés dans les différents quartiers de Chicago. Situées en bordure du lac Michigan, de vastes zones résidentielles s'étirant sur de longues bandes nord-sud sont caractérisées par des pavillons construits pendant le début du et après la Seconde Guerre mondiale.

Depuis sa fondation en 1770, le développement de Chicago résulte d'une succession de paris des urbanistes pour en faire une ville attractive. Chicago joue un rôle de premier plan dans l'histoire des États-Unis, ayant réussi à s'imposer comme un élément clé de l'organisation territoriale. Ce devenir n'avait rien de programmé, qui aurait permis d'imaginer l'expansion de cette ville en ces lieux inhospitaliers, en quelques décennies seulement, se transformer en l'une des métropoles nord-américaines les plus puissantes.

Les contraintes naturelles du site sur le lequel est bâti Chicago posèrent des problèmes d'aménagement aux autorités. En effet, le site a pendant longtemps été une plaine marécageuse et la ville a souffert de cet environnement qui rendait très difficile l'installation de routes et d'égouts. Au cours des , la ville de Chicago s'est développée vers l'ouest et sur les rives du lac Michigan pour atteindre une longueur nord-sud d'environ sur une largeur est-ouest de (dans sa partie la plus large), comprenant au total une superficie terrestre de . Avec une altitude moyenne d'environ au-dessus du niveau moyen de la mer, la ville de Chicago est établie sur des terrains assez plats.

Comme bon nombre de villes américaines, la structure urbaine de Chicago est conçue selon un système de rues en grille (appelé « plan hippodamien ») dans lequel il est facile de se repérer car les rues sont rectilignes et se croisent en angle droit, créant des îlots urbains de forme carrée ou rectangulaire. Ce système a été repris à partir du par les urbanistes pour la construction des villes sur le continent américain comme ce fut le cas à Chicago. Le quartier de New Eastside, dans le nord-est du Loop, est constitué en grande partie d'un système de rue multi-niveaux ; à l'époque le manque d'espace constructible a conduit les ingénieurs à inventer des rues à étages.

Avant que le Grand incendie de 1871 ne ravage la majeure partie de Chicago, la ville ne comportait que des bâtiments de quelques étages. À la suite de cet événement, la reconstruction de Chicago permit aux architectes et urbanistes de penser la ville sur des critères beaucoup plus modernes. De ce fait, l’incendie constitue un tournant dans l’histoire de Chicago. Il est d’ailleurs fréquent de dater la ville telle que nous la connaissons aujourd'hui par rapport à cet événement. Il faut attendre la reconstruction de la ville pour voir émerger les premiers immeubles de grande hauteur à la fin du . Aujourd'hui, le centre financier du Loop est composé en grande partie de gratte-ciel et d'immeubles comportant au moins 10 étages. Les secteurs limitrophes au Loop se composent aussi principalement de bâtiments à haute densité. Cependant, plus on s'éloigne vers l'extérieur plus les bâtiments deviennent petits, avec moins de 10 étages. Dans un rayon de autour du centre-ville les immeubles se raréfient et les maisons urbaines de type "brownstones" comportant 4 à 5 étages se succèdent. Dans un rayon de autour du Loop, les quartiers périurbains se composent principalement de zones pavillonnaires et de lotissements constitués de maisons individuelles et de duplex avec parfois des immeubles.

En 1906, sous l'administration du maire Edward Dunne, la municipalité fit appel aux architectes-urbanistes Daniel Burnham et Edward H. Bennett dans le cadre d'un vaste projet de restructuration urbaine (appelé « Plan de Chicago ») visant à redéfinir le système de rues de Chicago à partir de critères modernes et adaptés aux contextes de l'époque, en effet la voiture se démocratise, la ville gagne par décennie, de plus l'assiette fiscale de la mairie permet de lancer de grands projets de ville. À partir de 1909, le Chicago Plan Commission, une commission mise en place par les autorités municipales de Chicago, valide le plan de Burnham et Bennett qui prévoit pour la ville un large système de rues en damier, incluant notamment la construction de nouvelles rues sur le concept d'alignement ; la restructuration, l'élargissement et l'embellissement des boulevards déjà existants ; la construction de plusieurs grands bâtiments municipaux ; l'installation de nouveaux parcs et espaces verts (comme Grant Park et Jackson Park) ; la mise en place d'un nouveau chemin de fer ; la création de nouvelles installations portuaires ; et la modernisation de la plupart des boulevards et avenues.

Quand Chicago s'incorpora en tant que municipalité durant l'année 1837, elle choisit la devise « "Urbs in Horto" », une expression latine qui signifie en français la « ville dans un jardin ». Aujourd'hui, Chicago est la deuxième ville après New York à posséder le plus de parcs et d'espaces verts de tous les États-Unis, totalisant 570 parcs municipaux soit plus de de verdure, mais aussi 33 plages, 16 lagunes historiques et 9 ports situés en bordure du lac Michigan, ce qui fait du Chicago Park District le plus grand système urbain de gestion et d'entretien d'espaces verts de la nation.

Créé en 1843, Lincoln Park s'étend sur une superficie de , constituant ainsi le plus grand parc public de la ville. Nommé en l'honneur du président Abraham Lincoln, il accueille près de 20 millions de visiteurs tous les ans, une fréquentation le classant deuxième après Central Park à New York. Le parc abrite entre autres le zoo de Lincoln Park ("Lincoln Park Zoo") et le jardin botanique de Lincoln Park ("Lincoln Park Conservatory"). Garfield Park comprend le jardin botanique de Garfield Park, l'un des plus grands conservatoires de plantes des États-Unis. Aménagé par l'urbaniste William Le Baron Jenney, le conservatoire occupe une surface d'environ et contient une grande variété de plantes rares et d'arbres provenant du monde entier. D'une superficie de , Burnham Park s'étend tout en longueur sur en bordure du lac Michigan et abrite certaines structures municipales d'importance, telles que le stade de football du Soldier Field et le centre de convention du McCormick Place. À proximité se trouve le Museum Campus (le « parc des musées »).

Grant Park est un vaste parc public d'une superficie de situé dans l'est du secteur financier du Loop (Downtown Chicago) ; on peut y voir la célèbre "Buckingham Fountain", une fontaine interactive monumentale située en son centre. Entre juin 1999 et juillet 2004, Grant Park a subi dans sa partie nord-ouest d'importants travaux d'aménagements pour accueillir l'un des lieux les plus attractifs de la ville : le Millennium Park (le « parc du millénaire ») qui connaît un véritable succès depuis son ouverture. Jackson Park, l'un des parcs les plus populaires de la ville, est situé dans le South Side et s'étend sur une superficie d'environ à cheval sur les secteurs de Woodlawn et Hyde Park. Il est surtout connu pour l'œuvre du sculpteur Henry Bacon, la statue de la République, qui fut érigée en 1918 pour la commémoration du de la l'Exposition universelle de 1893 et du centenaire de l'État de l'Illinois. Le parc, qui abrite un jardin japonais, est très prisé par les touristes et les résidents pour sa proximité avec les plages. Portant le nom de Potter Palmer, un homme d'affaires influent du Chicago des années 1900, le Palmer Park a vu le jour grâce à cet homme qui fit don à la ville de Chicago en 1904. Ce parc est fréquenté pour ses fresques murales et pour ses installations et aménagements qui incluent des terrains de baseball, une salle de fitness, des salles de réunion, une piscine extérieure et des courts de tennis.

Situé en bordure du lac Michigan, Calumet Park est l'un des parcs les plus vastes de Chicago et se trouve dans le secteur de East Side. Traversé par la rivière Calumet, il s'étend sur près de . En plus des projets continus d'embellissement pour les nombreux parcs existants, un certain nombre de parcs ont été créés ces dernières années, comme le Ping Tom Memorial Park dans le quartier chinois, aménagé au bord de la rivière Chicago, avec ses jardins de bambous et ses bateaux-dragons.

L'organisation mondiale pour la protection de l'environnement Greenpeace, en partenariat avec la ville de Chicago et le comté de Cook ont signé une charte pour la protection et la conservation des forêts situées dans le nord-ouest de la ville, notamment autour des secteurs de Dunning, O'Hare et Norwood Park. Depuis plusieurs années ces forêts qui étaient menacées par l'expansion urbaine sont désormais protégées et classées comme étant des parcs naturels. Formée en 1975, Friends of the Parks (« Les amis des parcs » en français) est une association qui a pour but de surveiller et de défendre l'environnement dans la région de Chicago ; plus précisément, elle surveille le bon entretien et la sécurité des parcs publics qui sont sous la responsabilité du Chicago Park District ainsi que les réserves forestières du comté de Cook.

Avec son développement économique, la population de Chicago explose à partir des années 1850 : elle se multiplie par 3,7 en une décennie et accède à la neuvième place des villes les plus peuplées des États-Unis. À la fin du , Chicago est la cinquième ville en importance dans le monde. Chicago est pendant près d'un siècle, la seconde ville des États-Unis derrière New York. Le maximum démographique est atteint en 1950, puis la ville entre en déclin jusque dans les années 1990, la suburbanisation des classes moyennes faisant baisser la population de la ville au profit des banlieues résidentielles, elle cède ainsi sa place de seconde ville du pays au profit de Los Angeles.

En 2016, selon les estimations du Bureau du recensement des États-Unis, la ville de Chicago compte , ce qui représente un peu plus du cinquième de la population totale de l’État de l’Illinois.

Chicago est à ce jour la troisième ville la plus peuplée des États-Unis, derrière New York et Los Angeles. La densité moyenne atteint au kilomètre carré : il s’agit d’un chiffre plus élevé qu’à Los Angeles, mais beaucoup moins important qu'à New York. Chicago est le siège du comté de Cook, qui est avec en 2012, le deuxième comté le plus peuplé des États-Unis après celui de Los Angeles.

Le revenu médian pour un ménage dans la ville est de , et de pour une famille. Les hommes ont un revenu médian de en moyenne contre pour les femmes. Le revenu par habitant dans la ville est de . 19,6 % de la population vivaient au-dessous du seuil de pauvreté dont 16,6 % comprend des familles. De toute la population, 28,1 % des moins de et 15,5 % des plus de vivent au-dessous du seuil de pauvreté. De toute la population de la ville, 26,2 % ont moins de , 11,2 % ont entre 18 à , 33,4 % de 25 à , 18,9 % de 45 à , et 10,3 % et plus. L'âge médian est de . Pour environ , il y a . Pour de et plus, il y a .

La proportion d'Afro-Américains est relativement importante (32 %) par rapport à d'autres villes comme New York (28 %) ou Los Angeles (12 %). Elle reste cependant inférieure à celle de Détroit, d'Atlanta ou de Washington, D.C. Les Hispaniques et Latinos représentent 29 % de la population, soit une proportion équivalente à celle de New York mais inférieure à celle de Los Angeles. Les trois quarts d'entre eux sont d'origine mexicaine.

En 2008, l'aire métropolitaine de Chicago (communément appelée « Chicagoland ») rassemblait quelque d'habitants, ce qui en fait la troisième des États-Unis et la quatrième d'Amérique du Nord après celles de Mexico, New York et Los Angeles. La région métropolitaine de "Chicago-Naperville-Joliet" (MSA) regroupe dont Chicago en constitue la ville centre. Elle s'étend sur trois États et comprend quatorze comtés, dont neuf comtés du nord-est de l'Illinois (Cook, DeKalb, DuPage, Grundy, Kane, Kendall, Lake, McHenry et Will), quatre comtés du nord-ouest de l'Indiana (Jasper, Lake, Newton et Porter), et un comté du sud-est du Wisconsin (Kenosha) couvrant une superficie totale de . À l'échelle du continent américain (les Amériques), elle est la septième aire urbaine après celles de Mexico, New York, São Paulo, Rio de Janeiro, Los Angeles et Buenos Aires et se classe au mondial pour sa population.

Selon l"'American Community Survey" pour la période 2010-2014, 64,11 % de la population âgée de plus de 5 ans déclare parler l'anglais à la maison, 24,5 % déclare parler l'espagnol, 2,04 % le polonais, 1,65 % une langue chinoise, 0,83 % le tagalog, 0,53 % l'arabe et 6,34 % une autre langue.

En 2015, selon une étude de l'institut de sondage Gallup, 3,8 % de la population de la ville s'identifient comme gays, lesbiennes, bisexuels ou transgenres (3,6 % au niveau national).

Avec son histoire cosmopolite, Chicago a un patrimoine religieux riche tel qu'il est représenté par l'architecture et les institutions à travers la ville.

Le christianisme est la religion dominante de la population de la ville (environ 54,14 % des Chicagoans). Il est représenté à travers ses différentes confessions, comprenant ainsi les catholiques, les protestants, les orthodoxes, les anglicans et les chrétiens orientaux (Églises des trois conciles). L'immigration en provenance de pays d'ancienne chrétienté comme de l'Irlande, de l'Italie, du Mexique, de l'Allemagne, de la Pologne, de Cuba, de la Russie, de la Lituanie ou encore de l'Espagne grossit encore les rangs de ses fidèles. La francophonie est un signe tangible de la présence historique française dans la région, Chicago se compose aussi d'une communauté catholique Francophone. D'autres religions sont représentées à Chicago, comme le judaïsme, l'hindouisme, le bouddhisme, l'islam, le sikhisme et le bahaïsme. En 2015, environ 59,87 % des habitants de Chicago étaient affiliés à une religion. En raison de cette diversité, Chicago a une architecturale religieuse variée.

Grâce à sa taille et à sa notoriété, la ville de Chicago a acquis une certaine reconnaissance mondiale, dans le domaine de la religion. Elle a accueilli les deux premières réunions du Parlement des Religions du Monde. La première eut lieu en 1893, la même année que l'Exposition universelle et la deuxième en 1993. Chicago abrite de nombreuses institutions théologiques, qui incluent des séminaires, de nombreuses écoles, des collèges tels que l'Institut Biblique Moody et des universités comme l'université DePaul et l'université jésuite Loyola par exemple. Chicago est le siège de nombreux chefs religieux et de toute une série d'évêques d'un large éventail de confessions chrétiennes. Le seul temple de la foi bahá'íe en Amérique du Nord est situé à Wilmette, en banlieue nord de Chicago.

Nombre d'éminentes personnalités religieuses ont visité la ville, dont le dalaï-lama et Mère Teresa. Le pape Jean-Paul II a visité Chicago en 1979 dans le cadre de son premier voyage aux États-Unis après avoir été élu à la papauté en 1978.

La ville possède un grand nombre d'édifices religieux, avec pas moins de deux cents églises sur son territoire. Chicago accueille l'archidiocèse catholique le plus important des États-Unis. Parmi les édifices les plus connus et les plus visités, il y a la basilique Notre-Dame-des-Douleurs de Chicago de style néo-Renaissance qui est l'une des trois paroisses de la ville de Chicago à porter le titre de basilique. Elle fut la première à obtenir ce titre en 1956 par autorisation spéciale du pape Pie XII. Il y a aussi la cathédrale du Saint-Nom de Chicago qui est l'un des principaux sanctuaires catholiques de la ville et la cathédrale Saint-Jacques de Chicago qui est l'église-mère du diocèse épiscopalien de Chicago depuis 1955. La ville compte également plusieurs églises orthodoxes dont la plus connue est sans doute la cathédrale de la Sainte-Trinité. Fondée en 1888, l'église Sainte-Hedwige de Chicago est une église catholique monumentale dépendant de l'archidiocèse de Chicago. Construite dans le style néo-Renaissance, son architecture rappelle la période faste de l'Union de Pologne-Lituanie ; elle est dédiée à sainte Hedwige.

Foyer de la Congrégation de la First United Methodist Church of Chicago, le Chicago Temple Building est avec ses l'église la plus haute du monde. Administré par l'archidiocèse de Chicago et destiné aux jeunes gens se préparant à la prêtrise, l'Archbishop Quigley Preparatory Seminary a formé près de , deux cardinaux, plus de quarante évêques, deux experts du Concile Vatican II et de nombreux récipiendaires de la Medal of Honor et de la médaille présidentielle de la Liberté.

Chicago est le siège archiépiscopal ou épiscopal de plusieurs Églises :


Chicago a presque définitivement fait oublier sa mauvaise réputation, héritée de la période agitée de la prohibition dans les années 1920 et 1930, quand les activités d'Al Capone et de la pègre lui valurent le surnom de « Capitale du crime ». Depuis la fin des années 1990, le sentiment d'insécurité a fortement baissé et il est tout à fait possible de se promener sans crainte dans la plupart des secteurs de North Side et Downtown. Cela est en partie dû au renforcement de la présence policière. Il est seulement conseillé aux touristes d'être plus vigilants et d'éviter de jour comme de nuit certains secteurs de South Side tels que Fuller Park, South Shore, Roseland, Englewood, Douglas et West Pullman, et de certains secteurs de West Side tels que West Garfield Park et Austin.

En 2006, selon le Chicago Police Department (CPD), la criminalité violente a baissé dans la ville de Chicago. Entre 1997 et 2006, le nombre de crimes et délits (vols, cambriolages, violences, viols, meurtres, incendies criminels, dégradations volontaires etc.) a baissé de 34 %, passant de à . On recensait dans la ville en 1997, 467 en 2006, puis une nouvelle légère hausse avec en 2012 dont 82,4 % avec une arme à feu ; les meurtres représentent 1,3 % des violences commises contre les personnes. Malgré un pic des homicides commis dans la ville en 2012, cela reste inférieur en comparaison avec des villes plus petites comme Détroit et La Nouvelle-Orléans.

Néanmoins en 2016, la ville connaît une recrudescence de meurtres et établit un nouveau record pour les vingt dernières années avec 762 meurtres. La ville totalise ainsi en 10 ans. Seul un tiers des affaires de meurtre ont été résolues en 2016.

Le gouvernement de la ville de Chicago est divisé en branches exécutive et législative.

Le maire de Chicago (') est le chef du pouvoir exécutif (en anglais : '). Il est élu pour quatre ans et applique toutes les ordonnances. Il est chargé de contrôler tous les services et organismes de la ville ("Departments"), ainsi que les différentes administrations spécialisées. Le maire dirige et surveille les différents chefs qu'il nomme à la tête de ces services municipaux et détient un droit de veto au conseil municipal. Il est l'homme le plus puissant de la ville. Depuis 1931, tous les maires de Chicago appartiennent au Parti démocrate.

Le conseil municipal de Chicago (') est formé de 50 élus (' ou "") qui représentent chacune des 50 circonscriptions ("wards") de la ville de Chicago et forme le pouvoir législatif du gouvernement de Chicago : il surveille le bon fonctionnement des services municipaux, vote les lois, décrète les ordonnances municipales et approuve le budget annuel en novembre. Le mandat des conseillers s'étale sur quatre ans.

L'hôtel de ville de Chicago ("Chicago City Hall") est le siège officiel du gouvernement de la ville de Chicago ("City of Chicago Government"). Adjacent des deux bâtiments du Richard J. Daley Center et du James R. Thompson Center, l'hôtel de ville abrite les bureaux du maire, du greffier municipal, du trésorier de ville et de certains services de la ville. Les chambres du conseil municipal de Chicago se trouvent sur le côté ouest du bâtiment.

En 2005, le budget de la ville s'élève à plus de de dollars: les principales dépenses sont liées à la police ("Chicago Police Department"), aux pompiers ("Chicago Fire Department"), à l'entretien et la rénovation de la voirie, des ponts et chaussées ("Chicago Department of Transportation"), ainsi qu'au remboursement de la dette.

Maire de Chicago de 1989 à 2011, Richard M. Daley reçoit plus de 70 % des voix aux élections municipales de 1999, 2003 et 2007, sans grande opposition. En effet, Daley est un maire ambitieux qui connaît de nombreuses réussites depuis son premier mandat en 1989, il est responsable de nombreuses innovations en matière de modernisation de sa ville et de rénovation urbaine, d'environnement, de résurgence dans le tourisme, et de rayonnement international au niveau économique et culturel ; il joue un rôle important dans la sélection de la ville de Chicago pour les Jeux olympiques d'été de 2016. En 2010, il est nommé « meilleur maire des cinq plus grandes villes des États-Unis» et comme étant un homme « charismatique et puissant » par le "Time magazine". Il sera également surnommé « le boss » par le journal "Libération" et plusieurs hommes politiques durant sa carrière. Cependant, en septembre 2010 il annonce ne pas se présenter pour un nouveau mandat en 2011. Richard M. Daley est resté à la tête du gouvernement de Chicago durant 22 ans. Il est remplacé par Rahm Emanuel le 16 mai 2011, élu maire de Chicago avec 55 % des voix.

Comme de nombreuses autres villes des États-Unis, Chicago est confronté à la faillite de son système de retraites. Les retraites de ses ex-fonctionnaires ne sont désormais pas toujours payées.

L’ambition du maire Richard M. Daley lors de ses mandats fut de favoriser la protection de l’environnement tout en maintenant Chicago parmi les métropoles mondiales les plus influentes. Avec un nouvel horizon urbain d'ici ces prochaines années, le centre-ville se développe plus rapidement avec une atmosphère plus dense et plus respirable. Le Chicago Park District, l'organisme responsable de la gestion des parcs et espaces verts de la ville de Chicago est commis au plan de rétablissement de la biodiversité. Il se charge de la reconversion en espaces verts des secteurs abandonnés de la ville. Les terrains vagues et les parkings à l'abandon sont transformés en parcs et des jardins sont créés au-dessus des gratte-ciel à surface plate. Les toitures de nombreux bâtiments de Chicago sont repeintes en blanc. Les toitures blanches rafraîchissent les immeubles et luttent donc contre l’effet d’îlot de chaleur qui caractérise les grands centres urbains. En effet, le blanc a un albédo important. En d'autres termes, il renvoie vers l’espace une grande quantité de rayonnement solaire.

Le Chicago Climate Exchange (CCX) est le premier système d'échange de quotas d'émissions de gaz à effet de serre au monde. En 2003, le CCX lance sa plateforme de négociation. En 2005, le CCX lance le European Climate Exchange (EXC), acteur important dans les échanges à l'intérieur du marché de l'Union Européenne. Le maire a par ailleurs signé l’"U.S. Mayors Climate Protection Agreement" (« accord des maires des États-Unis sur la protection du climat ») visant à atteindre ou à dépasser les objectifs de réduction de GES fixé par le protocole de Kyoto.

La ville de Chicago a été récemment mise en avant dans une édition du "New York Times" en tant que ville pionnière en matière de durabilité aux États-Unis. Toutefois, la ville ne recherche pas un battage médiatique autour de ses initiatives écologiques, mais plutôt des décisions intelligentes à l'égard des nouvelles infrastructures qui aideront la ville des vents à faire face aux changements climatiques drastiques qu’elle subit depuis trois décennies.

Chicago est surnommée « Green Roofs City » : les toitures végétales représentent une superficie totale de plus de répartis à travers 359 toits de la ville. L'ancien maire de Chicago Richard M. Daley a fait de sa ville la première d'Amérique du Nord en matière de « toits verts » grâce à des incitations fiscales qui ont été mises en place depuis le début des années 2000. Depuis 1989, ont été plantés à Chicago.

Chicago est l’une des villes globales de la planète : le secteur du tertiaire supérieur est bien représenté par de nombreux sièges sociaux et succursales dans les domaines de la comptabilité, de la publicité, de la finance et des services juridiques. La ville est un centre de décision économique comme le montre la concentration des sièges sociaux de firmes multinationales dans le quartier des affaires, qui reste le deuxième du pays derrière celui de New York. Chicago est le moteur économique de toute la région des Grands Lacs.

Le poids économique de l'agglomération de Chicago est considérable : le PNB de la métropole était de 349 milliards de dollars en 2002 et de 390 milliards de dollars en 2005 : si Chicago comptait comme un pays, il serait la économique du monde. Dans son histoire, Chicago a rapporté plus de 506 milliards de dollars à l'économie américaine. En 2008, la société de services financiers UBS a placée Chicago à la sur la liste des villes les plus riches du monde pour son PIB supérieur à 570 milliards de dollars. Selon "", le PIB de Chicago s'élevait à 630 milliards de dollars pour la période 2014/2015. Le "Department of Community Development" (DCD) est un organisme qui s'occupe du développement économique de l'ensemble de la ville, et gère entre autres les chambres de commerce de quartier.

L'activité économique de Chicago est diversifiée : l'industrie y tient une place relativement significative. Le secteur des transports et du commerce est très développé et offre un réseau multimodal de premier ordre dans le pays. Aujourd'hui, la ville représente la deuxième place boursière des États-Unis et détient la plus grande bourse du monde pour les matières premières. Elle est la deuxième ville américaine pour l'édition derrière New York. Elle est le centre économique et névralgique du Midwest ainsi que le siège de la Federal Reserve Bank of Chicago, le septième des douze districts de la Réserve fédérale des États-Unis couvrant près des 2/3 des États de l'Illinois, du Michigan et de l'Indiana, environ la moitié de l'État du Wisconsin, et l'intégralité de l'État de l'Iowa. Elle occupe le troisième rang dans le pays pour les salons, les et les conventions. Le McCormick Place est le plus grand centre de convention du pays et le troisième du monde. Il accueille chaque année environ 3 millions de visiteurs.

Le nombre d'actifs à Chicago est de 4,2 millions (août 2006). Le taux de chômage était de 5,5 % en juillet 2006, un chiffre plus élevé que la moyenne nationale mais en baisse depuis trois ans. Le "Mayor's Office of Workforce Development" (MOWD) aide les chômeurs à retrouver un emploi. En 2003, le premier employeur de la ville est le gouvernement fédéral (), suivi par les écoles publiques () et la municipalité ().

Les entreprises les plus importantes par le nombre de salariés sont la chaîne de supermarchés Jewel-Osco (), Advocate Health Care (), SBC Communications () et United Parcel Service (). D'autres firmes dominent la vie économique de l'agglomération : McDonald's et Portillo's (restauration rapide) ; Kraft Foods Group, Mondelēz International, Quaker Oats Company (agro-alimentaire) ; Tropicana (boissons) ; Target Corporation, Sears Holdings (grande distribution) ; Walgreens, Abbott Laboratories (industries pharmaceutiques) ; Playboy Enterprises ("Playboy Magazine, Playboy TV") (émission et magazine de charme) ; Budget (location de voiture) ; Chicago Climate Exchange (environnement et développement durable) ; BFG Technologies (matériel informatique) ; United Airlines, Boeing, Motorola (transports et communications) ; Williams Electronics Games, Stern Electronics (fabrication de jeux d'arcade) ; Yellow Cab Company (compagnie de taxi) ; Allstate, Bank One (assurance et finance), etc.

L'agroalimentaire, la métallurgie et l'imprimerie sont les trois secteurs industriels qui emploient le plus de main d'œuvre à Chicago.

Avant 1833, l'activité principale de la région est le commerce des fourrures. Puis elle connait un phase de développement industriel important, attirant investisseurs, spéculateurs et entrepreneurs, qui en fait l'une des principales villes de la "Manufacturing Belt". Le port sur le lac Michigan se développe rapidement, et avec lui, la construction navale.
La ville devient également un important centre céréalier, profitant durant tout le du débouché de la région agricole des Grandes Plaines, le grenier des États-Unis. Chicago devient, dans les années 1840, le plus grand port céréalier du monde.

À partir du milieu du , les industries agroalimentaires de transformation de la viande de porc et de bœuf s'y multiplient, notamment sous l'impulsion de Gustavus F. Swift et Philip Armour. En 1865, sur un quartier marécageux (actuel secteur de New City), y sont fondés d'immenses abattoirs appelés les Union Stock Yards, qui à partir de 1900 produit 82 % de la viande consommée aux États-Unis, faisant de la ville un centre majeur de traitement du bétail. En référence à ces activités qui font une grande partie de sa fortune et de sa réputation, le bœuf devient l'un des symboles de Chicago. Si les abattoirs sont transférés à Kansas City en 1971, le nom de l'équipe de basket, les « Bulls », fait directement référence à cette tradition bouchère.

Au milieu du , la ville devient un nœud ferroviaire important. Chicago est la ville de départ de l'Illinois Central Railroad qui la relie au sud à La Nouvelle-Orléans via Memphis en 1856. Elle est reliée à Sioux City vers l'ouest suite à l'ouverture de la Chicago Central Railroad (une branche de l'Illinois Central Railroad) en 1870. Chicago devient la ville de départ de la ligne de chemin de fer de la compagnie Union Pacific, qui atteint San Francisco suite à l'achèvement du premier chemin de fer transcontinental en 1869. Carrefour des voies ferroviaires de l'Amtrak, Chicago devient, avec Saint-Louis, Memphis et La Nouvelle-Orléans, l'une des quatre plates-formes de l'Union Pacific reliant l'est, et l'ouest des États-Unis.

Chicago est toujours l'un des premiers marchés de céréales du monde. Le puissant secteur agroalimentaire assure une grande partie de l'emploi industriel de l'agglomération. L'industrie du meuble s'est aussi développée au .

De grandes sociétés américaines se sont implantées à Chicago : Sears, Roebuck and Company, Amoco, Sara Lee, United Airlines, Wrigley Company et Walgreens. Le constructeur aéronautique Boeing y a transféré également son siège social auparavant situé à Seattle. Enfin, McDonald's possédait aussi son siège social à Chicago durant les années 1970, mais l'entreprise a ensuite été déplacée à Oak Brook, dans la proche banlieue. Cependant, d'après les dirigeants de McDonald's, il semblerait que l'entreprise veuille réimplanter son siège social à Chicago en 2018.

Centre de ravitaillement des troupes pendant la guerre de Sécession, l'industrie de l'armement prospéra aussi au . Dans le cadre du projet Manhattan, le a lieu à l'université de Chicago la première réaction nucléaire contrôlée.

Le développement industriel et urbain du poussa la municipalité à pomper l'eau du Lac Michigan de plus en plus loin. Le secteur industriel a récemment bénéficié d'une étroite alliance entre les universités, les laboratoires et les entreprises.

Cela concerne avant tout le domaine de la haute technologie : l'informatique et l'électronique avec les logiciels Spyglass, l'entreprise Motorola et la US Robotics Corporation. Cela n'empêche pas la région de continuer les productions lourdes telles que l'acier, malgré la forte concurrence étrangère.

L'importance de la métropole lui confère bien sûr des fonctions tertiaires de premier ordre. Chicago est un important centre financier, qui fut le premier à lancer le marché des contrats dérivés, à la suite des travaux des économistes de l'école de Chicago sur l'analyse quantitative financière dans les années 1950 et 1970. Il abrite désormais la première bourse du monde en volume d'opérations traitées (capitalisation de 30 milliards de dollars), du fait de la fusion entre le Chicago Board of Trade (CBOT) et le Chicago Mercantile Exchange (CME), décidée par les actionnaires le 9 juillet 2007 pour former le CME Group.

Le dynamisme touristique joue également beaucoup en la faveur du développement économique de la ville, en effet Chicago abrite certaines des attractions, musées et universités les plus réputées aux États-Unis. En 2002, Chicago a attiré plus de 28 millions de visiteurs, dont un million venu de l'étranger ont dépensé à Chicago plus de 8,7 milliards de dollars et ont généré 442 millions de dollars de taxes. La ville compte d'hôtel. De nombreux congrès et réunions s'y déroulent chaque année. Les principaux sites touristiques et de loisirs sont la jetée Navy (8,6 millions de visiteurs en 2005), le zoo de Lincoln Park (3 millions), l'aquarium John G. Shedd et le Musée des sciences et de l'industrie (1,8 million chacun).

Depuis plusieurs années, le centre-ville connaît un renouveau immobilier avec notamment la construction d'hôtels et de bureaux comme la (condominiums et lofts), l'Aqua Building et le Waldorf Astoria (hôtels de luxe), le 340 on the Park, le 300 North LaSalle, ainsi que la construction d'un quartier chic autour de River Esplanade Park, dans le secteur du Loop font partie entre autres de ces derniers projets qui témoignent de la prospérité de la ville. Depuis la récession, certains projets dont celui de la Chicago Spire (gratte-ciel résidentiel devant culminer à de haut) sont aujourd'hui annulés. Certains secteurs de la ville comme Logan Square, Uptown, Near North Side, Near South Side et Rogers Park connaissent un accroissement démographique et une gentrification rapide. L'agrandissement et la modernisation de l'aéroport international O'Hare et la reconstruction de la Dan Ryan Expressway sont également en cours et seront des modèles de développement pour les années à venir.

Chicago est un l'un des principaux nœuds de communication en Amérique du Nord. Dès le , avec la traite de fourrures et le commerce du bois et des productions agricoles, la ville est marquée par sa vocation marchande. Aujourd'hui, l'agglomération constitue un carrefour de cinq autoroutes fédérales et de six lignes de chemin de fer d'importance nationale. Les divers aménagements et infrastructures font de Chicago une plate-forme multimodale primordiale aux États-Unis.

La ville est desservie par un large réseau de bus et de métro mais également par des trains de banlieue et les trains nationaux à grande capacité de l'Amtrak. Chicago est la quatrième ville des États-Unis pour le nombre d'utilisateurs sur le réseau Amtrak. L'Amtrak est une entreprise ferroviaire publique qui relie Chicago aux principales villes américaines et le Metra est une entreprise ferroviaire publique de la région de Chicago qui fonctionne comme un système de réseau express régional (RER) à travers six comtés de l'agglomération de Chicago.

Les gares principales de Chicago desservies par l'Amtrak et par le Metra sont :

La ville de Chicago dispose d'un grand réseau de lignes de métro et possède également de vastes lignes d'autobus. La Chicago Transit Authority, connue sous l'acronyme « CTA » est l'opérateur des transports publics (gestion du métro et des bus) de la ville de Chicago. L'entreprise est la seconde du genre aux États-Unis et la quatrième en Amérique du Nord. La CTA offre des lignes de bus et de métro à l'intérieur de la ville de Chicago et à destination de quarante municipalités de la proche banlieue ainsi que la desserte des aéroports de O'Hare et Midway.

Mais la ville est confrontée à un problème de taille : l'ancienneté, le vieillissement et la vétusté de ces importantes infrastructures et du matériel roulant. En effet, son métro a été inauguré en 1892, ce qui en fait l'un des plus anciens réseaux au monde encore en service. Certaines portions actuelles du réseau datent de cette époque, la majorité des itinéraires ayant été maintenue. En outre, 500 bus de Chicago, soit le quart de la flotte, sont vieux de plus de 16 ans, avec au compteur une moyenne de . L'entretien de ces 500 bus revient à 16 millions de dollars par an (contre 3 millions afin d'entretenir les ). La Chicago Transit Authority évalue à 6 milliards de dollars l'investissement destiné à moderniser ses lignes (un investissement de 10 milliards en ajoutant les bus de banlieue). Le budget de la CTA est d'environ 1 milliard par an, provenant en grande partie des usagers (41 %) et des subventions de l'État de l'Illinois (41,5 %). La ville de Chicago et le comté de Cook n'apportent que 0,4 %. La CTA ne bénéficie pas non plus de subvention fédérale.

Chicago possède un vaste réseau de lignes de métro, fréquenté quotidiennement par usagers. Inauguré le 6 juin 1892, le métro de Chicago est l’un des plus anciens réseaux du monde encore en service, en effet il s'agit du deuxième plus ancien réseau du continent américain après celui de New York (1868) et le troisième du monde après celui de Londres (1863) ; le métro de Chicago est souvent désigné sous la lettre « 'L' » ou « EL » (de l'anglais "") car la majeure partie de son réseau est aérien ; il est également l'emblème de la Chicago Transit Authority qui le dénomme quant à elle uniquement sous l'abrévation 'L'.

Quelques sections du réseau remontent à la fin du , lorsque Chicago a suivi l'exemple de New York en construisant des lignes de métro aériennes. Contrairement à New York, qui dès le début du a commencé à remplacer ses lignes aériennes par des lignes souterraines dans Manhattan, Chicago utilise encore de nos jours la plupart de ses itinéraires originaux.

Géré par la Chicago Transit Authority, le réseau est long de ; il est composé de huit lignes, 145 stations (dont 92 sont accessibles aux personnes à mobilité réduite fin 2010), en tunnel avec 21 stations, en surface avec 42 stations et en aérien avec 89 stations. Toutes les lignes, hormis la ligne jaune, partent du centre de la ville où certaines d'entre elles forment la célèbre boucle aérienne, l'Union Loop, maintenant considérée comme la limite du secteur communautaire du Loop. Deux lignes, la bleue et la rouge, traversent le secteur du Loop en souterrain.

La majeure partie des lignes du réseau est située à l'intérieur des limites du territoire de la ville de Chicago, hormis quelques kilomètres aux extrémités des lignes rose (Cicero), mauve (Wilmette), jaune (Skokie), verte (Oak Park) et bleue (Forest Park). Le 'L' dessert les deux aéroports de Chicago, l'aéroport O'Hare par la ligne bleue (à 45 minutes du centre-ville) et l'aéroport Midway par la ligne orange (à 30 minutes du centre-ville). L'aéroport O'Hare possède son propre système de métro sur pneus entièrement automatisé appelé Airport Transit System (ATS). Fonctionnant 24 heures par jour et dont le service est gratuit, l'ATS fait une boucle dans l'enceinte de l'aéroport, desservant ainsi 5 stations.

Les stations du métro de Chicago présentent plusieurs types architecturaux qui cohabitent, allant du style Queen Anne du , au style italien du jusqu'à des structures de conception résolument moderne. Certaines stations sont décorées d'œuvres d'art tandis que d'autres conservent une forme utilitaire. Depuis la grande réorganisation du réseau et l'attribution d’une couleur distinctive à chaque ligne en 1993, les stations sont dénommées selon le nom de la rue ou de l'avenue qu'elles croisent, ou, plus généralement, de la rue où se trouve leur entrée principale.

La CTA envisage depuis de nombreuses années de créer une seconde boucle, appelée Circle Line. Ce projet de nouvelle ligne, présenté en 2002, prévoit un partage de rails avec la ligne rouge jusqu'à Chinatown, avant de suivre la ligne orange jusqu'à Ashland. De là, un nouveau viaduc permettra de rejoindre la ligne rose et l'United Center (l'arène des Bulls) au croisement avec la ligne bleue. Depuis ce croisement, un second viaduc de de long permet de retrouver la ligne rouge et le tunnel Dearborn. Ce projet est toujours à l'étude, et cette nouvelle ligne, comme les importants aménagements qu'elle suppose, ne devraient pas voir le jour avant 2025.

Géré par la Chicago Transit Authority (CTA), le réseau des bus urbains de Chicago est beaucoup plus étendu que son système de métro car il dessert, avec ses nombreux arrêts, l'intégralité de la ville et une partie de son agglomération située dans le comté de Cook. Le parc de la CTA est composé d'une flotte d'environ autobus qui circulent sur les 140 lignes du réseau qui représente un total cumulé de . En juin 2015, ces bus ont transportés plus de 25 millions de passagers par mois, soit une moyenne d'environ par jour, à travers plus de arrêts répartis sur tout le territoire de la ville de Chicago et sur celui d'une quarantaine de municipalités de sa proche banlieue. Certaines lignes ne circulent pas le week-end en banlieue.

Exploité et financé par la (RTA), le réseau de bus Pace est un réseau de bus interurbain de la grande banlieue de Chicago qui dessert un territoire vaste d'environ . Doté de 213 lignes, ce réseau est bien plus étendu que celui de la CTA car il dessert, en plus du comté de Cook, cinq autres comtés de l'agglomération de Chicago : DuPage, Lake, Will, Kane et McHenry. Prés de empruntent le réseau quotidiennement (chiffres 2016) et environ chaque année. Le réseau Pace permet de joindre entre-elles les principales municipalités de l'agglomération dont Aurora, Joliet, Waukegan, Elgin, Evanston et Naperville.

Avec 66,7 millions de passagers en 2010, l'aéroport international O'Hare de Chicago est le troisième du monde par le nombre de passagers derrière l'aéroport International de Pékin (deuxième) et l'aéroport international Hartsfield-Jackson d'Atlanta. De 1996 à 2009, l'aéroport O'Hare était classé deuxième dans le monde par le nombre de passagers. Situé à environ au nord-ouest du secteur financier du Loop (30 à 40 minutes en voiture), il est accessible par la Kennedy Expressway, le métro (ligne bleue) et les bus de la Chicago Transit Authority. Les navettes de l'ATS desservent cinq stations réparties sur une ligne faisant une boucle dans l'enceinte de l'aéroport en passant par les terminaux et les parkings les plus éloignés. L'aéroport O'Hare connaît des problèmes de saturation, de retards, voire d'annulation de certains vols. Un plan de modernisation et de refonte des pistes ainsi que de l'aérogare a été lancé pour accroître ses capacités. Il sert de hub principal d'United Airlines dont le siège se trouve en centre-ville de Chicago, ainsi que pour American Airlines.

L'aéroport international Midway de Chicago est le deuxième aéroport de Chicago avec 18,8 millions de passagers en 2006 et se situe à environ au sud-ouest du Loop. Il est principalement utilisé par des compagnies aériennes à bas prix pour des vols nationaux. La compagnie la plus représentée à Midway est la compagnie low cost texane Southwest Airlines. Les aéroports O'Hare et Midway se situent tous les deux sur le territoire de la ville de Chicago, le premier dans le secteur d'O'Hare à l'extrémité nord-ouest de la ville et le deuxième à cheval sur les secteurs de Clearing et Garfield Ridge dans le sud-ouest de la ville. Il existe également un troisième aéroport dans la région, celui de Gary/Chicago. Il se situe sur le territoire de la ville industrielle de Gary en banlieue sud-est, dans l'État voisin de l'Indiana, à environ de la limite territoriale de Chicago ( de Downtown).

Chicago possède un code AITA commun à tous les aéroports : CHI.

Chicago est le point de départ de la Route 66. Cette route historique, aujourd'hui déclassifiée, est orientée d'est en ouest et s'étend sur une longueur totale de , traversant huit États. De 1926 à 1985, elle joignait Chicago à Santa Monica (ville située sur les rives de l'océan Pacifique en Californie), en passant par les vastes étendues agricoles de l'Illinois et du Missouri, les plaines du Kansas et de l'Oklahoma, les champs de pétrole du Texas, les montagnes du Nouveau-Mexique et les déserts de l'Arizona. À Chicago, le point de départ officiel a varié selon les périodes, autrefois situé dans le Grant Park au niveau de la "Buckingham Fountain", un panneau se trouve aujourd'hui sur Adams Street, près de l'Institut d'art de Chicago dans le centre-ville.

La ville de Chicago possède dans ses limites plus de de rues, , lampadaires pour éclairer ses rues et avenues, près de routiers dont 36 ponts mobiles qui traversent la rivière Chicago, et de voies cyclables. Ces infrastructures sont prises en charge par le "Chicago Department of Transportation" (CDOT), le service municipal responsable de la maintenance, la construction et la gestion de la voirie (rues, trottoirs, ponts, signalisations routières, éclairage public...) de la ville de Chicago. Les autoroutes et les routes d'État qui traversent le territoire de Chicago sont quant à elles gérées par l'État de l'Illinois.

Chicago et sa région se trouvent au cœur d'un vaste réseau routier et autoroutier, composé notamment d'autoroutes fédérales ("U.S. highway"), d'autoroutes inter-États ("Interstate highway"), de routes fédérales ("U.S. Route") et de routes d'État ("State Route"). Ces infrastructures de transports sont essentielles pour le maintien de la croissance et la vitalité économique de Chicago, et ainsi permettre aux 9,5 millions d'habitants de l'agglomération de pouvoir se déplacer et de se connecter facilement aux accès routiers qui assurent la desserte des banlieues et la convergence vers Downtown Chicago.

Cinq autoroutes interétatiques ("Interstate highways") convergent vers le centre-ville pour faciliter les trajets à travers la ville et ses banlieues. Trois des autoroutes les plus importantes de Chicago se joignent au niveau du Jane Byrne Interchange, l'un des échangeurs autoroutiers les plus empruntés du Midwest avec une fréquentation d'environ par jour.

Longue de , la Kennedy Expressway commence à Downtown et rejoint l'aéroport international O'Hare en direction du nord-ouest, desservant ainsi les quartiers nord (North Side) où elle joint l'autoroute des Trois États ("Tri-State Expressway"), la principale autoroute nord-sud. La Eisenhower Expressway (I-290) et la Adlai E. Stevenson Expressway sont deux autoroutes qui mènent vers les banlieues ouest et sud-ouest où elles sont aussi reliées à celle des Trois États. La Dan Ryan Expressway, dans le prolongement de la Kennedy Expressway, est longue de et se dirige plein sud. La Dan Ryan se connecte à l'Interstate 94 au sud de la Chicago Skyway, sur une distance de . La Chicago Skyway, une autoroute relativement courte qui s'étend sur , relie l'Interstate 90 à la Dan Ryan Expressway et traverse les quartiers sud (South Side) avant de s'arrêter à la frontière de l'État de l'Indiana au sud-est de la ville.

La région de Chicago s'ouvre sur les vastes plaines du Midwest et possède l'avantage d'être dotée d'un complexe autoroutier qui est l'un des plus performants d'Amérique du Nord. En effet, il permet à la troisième métropole des États-Unis de rejoindre aisément d'autres villes d'importance régionale dont Milwaukee à au nord (par l'I-94), Indianapolis à au sud (par l'I-65), Détroit à au nord-est (par l'I-94), Saint-Louis à au sud-ouest (par l'I-55), Columbus à à l'est (par la Route 30), Des Moines à à l'ouest (par l'I-80), Cleveland à à l'est (par l'I-90), Minneapolis à au nord-ouest (par l'I-90), Kansas City à au sud-ouest (par l'I-55 et l'I-72), et Toronto (Canada) à au nord-est (par l'I-69 et l'I-94).

La circulation est relativement fluide, sauf à la sortie des bureaux, vers 18 h. Avec son système de rues en grille, hérité du "Plan de Chicago de 1909", il est facile de se repérer dans Chicago car les rues sont longues mais peu nombreuses et sont perpendiculaires les unes aux autres. Les tours les plus hautes peuvent servir de points de repère mais s'avèrent trompeuses et peuvent fausser la notion de distance. Pour se déplacer facilement du nord au sud de la ville et "vice versa", il est conseillé d'emprunter le périphérique Est (Lake Shore Drive) qui longe le lac Michigan et passe au milieu d'immenses pelouses avec vue sur les gratte-ciel du quartier d'affaires.

Se stationner à Chicago est très difficile, principalement dans le centre-ville. Tous les stationnements sont payants, et hors de prix : de 7 à pour 12 h. Quant aux parcomètres, ils n'acceptent que les pièces de et fonctionnent en général de 9 h à 19 h. Impossible de prépayer la nuit pour le lendemain matin. Il importe donc de vérifier scrupuleusement les panneaux d'interdiction de stationnement, car la ville de Chicago est réputée pour l'enlèvement très rapide des voitures mal stationnées et la mise en fourrière, même si elles ne gênent en rien la circulation ou les piétons.

Selon les autorités municipales, la ville de Chicago possède un peu plus de de voies cyclables couvrant une grande partie de son territoire.

Depuis 2013, la ville de Chicago est dotée d'un système de vélos en libre-service appelé « Divvy ». En 2016, il exploite répartis sur 576 stations dans un large secteur du centre de Chicago, délimité par la 75th Street au sud, Touhy Avenue au nord, le lac Michigan à l'est, et Pulaski Road à l'ouest. Nommé « Divvy » pour représenter l’idée de « Diviser et partager » ("Divide and Share"), il est le dernier ajout au système de transport collectif de Chicago. Destiné à aider les Chicagoans à parcourir le « dernier kilomètre » de leur parcours grâce à sa flotte de vélos à 3 vitesses, il rend également plus aisée l’exploration de la métropole. Selon les chiffres pour l'année 2014, les vélos étaient empruntés par plus de par jour. Les vélos ainsi que les stations sont développés à Montréal au Québec par l'entreprise PBSC Solutions Urbaines.

C'est en 2007 que vient au maire de Chicago Richard M. Daley l'idée de mettre en place un système de vélocation. En effet, c'est lors d'une visite à Paris que Daley se dit intéressé par le projet après avoir essayé des vélos en libre-service. De retour à Chicago, Richard M. Daley, connu pour son engagement en faveur de la protection de l'environnement, se fixe comme objectif de doter sa ville d'un système similaire. Il faudra attendre 2013 avant de voir le projet arriver à son terme.

Chicago est un port du lac Michigan. Ses atouts sont liés à sa situation exceptionnelle au cœur de la région des Grands Lacs et ont permis le développement industriel de la ville au . Grâce à un système de voies navigables, le port de Chicago est relié vers l'est à l'océan Atlantique par les Grands Lacs et le Saint-Laurent, et au golfe du Mexique au sud, "via" le fleuve Mississippi. Ses 14 terminaux maritimes sont gérés par l'Illinois International Port District.

Avec un trafic global situé entre 23 et 26 millions de tonnes par an, le port de Chicago occupait le aux États-Unis en 2005. La majeure partie du trafic est destinée au marché intérieur (). Diverses marchandises passent par le port de Chicago : des métaux non ferreux, des minerais, du coke, du sucre, des céréales, des produits pétrochimiques, de l'acier, du ciment, etc.

Les "water taxis" sont des bateaux taxis ("taxi-boat") qui fonctionnent comme des petits ferries sur un parcours à circuit fermé le long de la rivière Chicago et sur le lac Michigan de mars à décembre. Il possède cinq arrêts sur son trajet qui relie plusieurs points névralgiques du centre de Chicago dont Chinatown (au Ping Tom Memorial Park), Madison Street, LaSalle/Clark (près du Merchandise Mart), Michigan Avenue (sur le "Magnificent Mile"), et North Avenue (sur Goose Island). Les bateaux se déplacent également sur le lac Michigan, du côté de la jetée Navy, offrant aux visiteurs un point de vue privilégié sur la "skyline" de Chicago.

Bien que ce ne soit pas le moyen le plus efficace de se déplacer en ville, c'est certainement le plus prisé des touristes, en effet ce mode de transport offre aux visiteurs une vue imprenable sur les gratte-ciel et les bâtiments historiques situés en bordure de la rivière Chicago. En 2014, environ ont emprunté les "taxis-boats". Beaucoup sont des touristes, mais 30 % sont des Chicagoans.

Pendant l'été, les départs et les arrivées se font du lundi au vendredi de à 21 h 00, les week-ends de 10 h 00 à et le samedi soir jusqu'à 23 h 00 pour l'arrêt situé sur la jetée Navy. Les points de vente des tickets se trouvent au 400 North Michigan Avenue et sur Trump River Plaza.

Pendant des siècles, les Amérindiens utilisaient le « She-caw-gu » portage comme une liaison pratique entre les étendues supérieures du Mississippi et les vastes étendues d'eau des Grands Lacs. En 1779, Jean Baptiste Pointe du Sable, un marchand de peaux de descendance franco-africaine, créait la première colonie à cet emplacement stratégique. Depuis lors, Chicago a attiré des immigrants en provenance du monde entier. En 1930, sur une population de 3,4 millions de personnes vivant à Chicago, 2,46 millions étaient nés à l’étranger ou nés en Amérique, de parents étrangers. Leurs enclaves ethniques se réfléchissent dans les nombreux quartiers culturellement distincts. Chicago compte parmi ses habitants de nombreuses communautés incluant les irlandais, italiens, roumains, allemands, polonais, russes, suédois, croates, tchèques, portugais, espagnols, grecs, juifs, afro-américains, coréens, chinois, vietnamiens, mexicains, cubains, colombiens, haïtiens, portoricains, indiens, arabes, arméniens, jamaicains et dominicains, vivant l'exemple de ce « creuset démographique » (melting pot) qui, plus que dans toute autre ville américaine aura réussi à donner à la ville son caractère cosmopolite. Chicago est également la plus grande ville polonaise en dehors de la Pologne. Les quartiers ethniques les plus populaires de la ville comprennent Greek Town (ville grecque), Little Italy (petite Italie), Chinatown (quartier chinois), Little Vietnam (petit Viêt Nam), Little Saigon (petit Saigon), Bridgeport (quartier irlandais), Ukrainian Village (village ukrainien), Pilsen (quartier mexicain mais tchèque autrefois) et Humboldt Park (quartier portoricain) et sont tous situés près du secteur financier du Loop, et les quartiers allemands, polonais, afro-américains et hispano-américains n'en sont pas très loin. Chaque quartier offre un air culturel distinct, avec leurs épiceries, restaurants et magasins spécialisés.

La musique classique tient une place importante dans cette ville. Fondé par Theodore Thomas en 1891, l'Orchestre symphonique de Chicago est considéré comme étant l'un des meilleurs orchestres du monde. Il offre régulièrement des performances artistiques au Symphony Center. L'Orchestre Sinfonietta de Chicago est un orchestre symphonique multiculturel et beaucoup plus diversifié que l'Orchestre symphonique de Chicago. Durant l'été, de nombreux concerts en plein air sont donnés au pavillon Jay Pritzker dans le Millennium Park. Situé à Highland Park, à environ au nord de Chicago, le Ravinia Festival est également une destination de prédilection pour de nombreux Chicagoans, il s'agit du plus ancien festival en plein air des États-Unis et propose aussi des concerts de musique classique. D'autres performances comme le Joffrey Ballet et le Chicago Festival Ballet sont données au Harris Theater, une salle de spectacle d'une capacité de située à Grant Park. Le Civic Opera House est le deuxième opéra en importance en Amérique du Nord. D'une capacité de , il est le foyer de l'Opéra lyrique de Chicago depuis 1929. L'opéra Jūratė Kastytis, présenté par Kazimieras Viktoras Banaitis, s'est produit à Chicago en 1996, et le a été fondé en 1956 par la communauté lituanienne de Chicago. La ville est le foyer de plusieurs autres troupes de danse moderne et de jazz, tels que le Hubbard Street Dance Chicago.

Divers genres de musique font partie du patrimoine culturel de la ville : le Chicago blues, la Chicago soul, le Chicago jazz, la Chicago house, le Chicago punk hardcore et le Chicago rock. La ville est le berceau de la House music, un courant de musique électronique qu'elle a vu naître au début des années 1980. Durant cette période, Chicago est également un centre majeur du mouvement punk et de la new wave. Dans les années 1980 et 1990, cette influence est dominée par le rock alternatif. En 1985, la ville est l'épicentre de la culture rave, avant qu'elle ne soit peu à peu remplacée par le punk hardcore et le rock indépendant, deux cultures florissantes dans la première moitié des années 1980. La scène hip-hop de Chicago est influente depuis le milieu des années 1990, et compte des artistes reconnus comme Twista ou Common. Depuis 2005, de nombreux festivals représentant tous les genres musicaux, allant du rock à l'électro, se déroulent chaque année au Lollapalooza, de nombreux groupes et artistes internationaux s'y représentent, dont Guns N' Roses, Red Hot Chili Peppers, Rage Against the Machine, le groupe irlandais U2, le groupe français Daft Punk, le groupe allemand Scorpions ou encore les groupes anglais The Police et Oasis.

La ville compte près de 200 théâtres, dont le principal est l' qui fut construit en 1889 avec une capacité de plus de . On peut également citer l' (), le Chicago Theatre (), le Goodman Theater, le Harris Theater, le Congress Theater (), et le Mayfair Theater. Les théâtres communautaires de Chicago ont engendré les théâtres modernes d'improvisation. Le Second City et le I.O. (ImprovOlympic) sont deux troupes d'improvisation connues pour avoir lancé des acteurs tels que Bill Murray, Mike Myers ou encore John Candy. Les compagnies de théâtre d'improvisation les plus réputées de la ville incluent le , le Théâtre Goodman, et le Théâtre Victory Gardens. Les salles de théâtre et de spectacle de Chicago offrent des divertissements dignes de ceux de Broadway dans des lieux prestigieux tels que le Ford Center for the Performing Arts Oriental Theatre, le Bank of America Theatre, le , l' (dans l'Auditorium Building), et le (dans la Water Tower Place). Les productions dédiées à la communauté polonaise ont émergées à partir de 1930 et sont représentées au à Jefferson Park. Depuis 1968, le Prix Joseph Jefferson Awards est décerné chaque année aux meilleurs théâtres de Chicago.

Avec ses neuf millions d'ouvrages, la Harold Washington Library est la plus grande bibliothèque publique de Chicago. Inaugurée en 1991, elle se situe au cœur de Downtown Chicago dans le secteur financier du Loop, à proximité de l'Institut d'art de Chicago et est gérée par la Chicago Public Library (CPL), une institution municipale qui dispose de 79 bibliothèques (une moyenne d'une par secteur) à travers la ville de Chicago. Parmi les plus importantes, on peut citer les bibliothèques régionales Conrad Sulzer Regional Library et Carter G. Woodson Regional Library.

La reconstruction de Chicago, ravagée par le grand incendie de 1871, en a fait le berceau de l'architecture moderne. Depuis ce temps, Chicago entretient merveilleusement bien sa réputation de ville d'art. Outre la richesse de son architecture (allant du gothique au style Chicago en passant par le moderne et l'Art déco) qui en a fait sa renommée mondiale, la ville possède un nombre incontestable de sculptures, de fontaines et de statues, faisant ainsi de la ville un véritable musée à ciel ouvert. Durant une grande partie du , elle nourrit un style fort au surréalisme figuratif, comme dans les œuvres d'Ivan Albright et Ed Paschke. En 1968 et 1969, les membres du Chicago Imagists, tels que Roger Brown, Leon Golub, Robert Lostutter, Jim Nutt et Barbara Rossi produisent des peintures figuratives. Aujourd'hui, Robert Guinan peint des portraits réalistes de Chicagoans populaires à Paris, bien qu'il soit peu connu à Chicago même.

Chicago est une destination culinaire de renommée mondiale, avec plus de proposant toutes sortes de cuisines. Elle est aussi la seule ville du pays avec New York et San Francisco a posséder un restaurant 3 étoiles. Chicago est le domicile de chefs cuisiniers réputés comme Charlie Trotter, Rick Bayless, Art Smith, Grant Achatz, Rick Tramonto, Graham Elliot Bowles et Gale Gand. Parallèlement, la ville honore les traditions culinaires avec les spécialités locales comme la pizza de Chicago, le sandwich italien au bœuf, les hot-dogs de Chicago et le sandwich polonais de Chicago. La grande histoire culinaire de Chicago, associée aux visions des chefs et restaurateurs expérimentés ainsi que des professionnels de la restauration, a fait de la ville l'un des paradis américains pour les gastronomes.

La pizza de Chicago (appelée localement "Chicago-style pizza") est probablement la spécialité chicagoane la plus connue des États-Unis et dont la tradition remonte aux années 1940. Les habitants de Chicago, comme les visiteurs, apprécient la pizza « deep dish » de Chicago, préparée à partir d’une pâte beurrée, beaucoup de fromage, de la sauce tomate avec morceaux et une myriade de garnitures comme de la saucisse italienne, du pepperoni, des poivrons, des oignons et des champignons. Elle est servie dans des centaines de restaurants de la ville.

La ville est réputée pour son sandwich italien au bœuf ("Italian Beef Sandwich") ou simplement "Italian Beef", qui est une spécialité emblématique de la ville de Chicago depuis 1938. Ce sandwich se compose d'un pain de type baguette richement garni de fines tranches de rosbif juteuses et assaisonnées. Le pain peut avoir été préalablement trempé dans la sauce de la viande. Le tout est recouvert de petits poivrons sautés dans sa version douce, ou de garniture épicée de type Giardiniera dans sa version plus forte. On trouve ce type de sandwich principalement dans la région de Chicago.

Le fameux hot-dog de Chicago ("Chicago-style hot dog") est un autre pilier de l’art culinaire de la ville. Un hot-dog de Chicago est une saucisse de bœuf cuite à la vapeur ou bouillie sur un petit pain aux graines de pavot. Le hot-dog est garni de moutarde, d’oignon, de sweet pickle relish (cornichons à l’aigre-doux finement hachés), de cornichons à l’aneth, de tranches ou de quartiers de tomates, de piment doux, d’une pincée de sel de céleri mais jamais de ketchup.

Le sandwich polonais de Chicago (communément appelé le "Maxwell Street Polish") constitue depuis près d'un siècle une spécialité de Chicago. Créé en 1939 par Jimmy Stefanovic, ce sandwich est considéré comme étant un « classique » de la cuisine de rue de Chicago. Il s'agit d'une saucisse kiełbasa (d'origine polonaise) grillée et surmontée d'oignons sautés et de piments, servie comme un hot-dog, dans un pain de type "bun" avec des agréments comme de la moutarde.

Plusieurs établissements locaux de restauration rapide proposent la dégustation des spécialités de la ville, notamment Portillo's, Superdawg et The Wieners Circle. Ces chaînes de restauration sont représentées au festival gastronomique connu sous le nom de "Taste of Chicago". Événement incontournable pour de nombreux Chicagoans depuis 1980, il s'agit du plus grand festival dédié à la gastronomie dans le monde avec en moyenne 3,5 millions de visiteurs chaque année. La Billy Goat Tavern, une chaîne de tavernes de la ville, est connue pour la qualité de sa restauration et ses débits de boissons. Depuis plusieurs années, Chicago se fait connaître pour ses restaurants spécialisés dans la gastronomie moléculaire, avec des chefs comme Grant Achatz ou encore Homaro Cantu. En 2008, le magazine "Maxim" a donné a Chicago le titre de « "Tastiest City"» littéralement « ville savoureuse ». Enfin, Chicago propose un vaste choix de plats végétariens et végans, avec une sélection de plus de 170 restaurants végétariens dispersés à travers la ville'.

Enfin, le brownie, un gâteau au chocolat contenant des morceaux de noix, a été inventé par un chef du à Chicago en 1893, hôtel ayant appartenu à Palmer Cox. Le nom brownie est inspiré du nom des personnages Brownie que ce dernier dessinait en tant qu'illustrateur.

Chicago est mondialement connue pour être une ville de musées. Elle en abrite pas moins de 70, tous différents. Ils offrent une vue assez complète de l’Histoire, des Arts, et des Sciences de nombreuses civilisations. Parmi les principaux figure l'Institut d'art de Chicago ("Art Institute of Chicago"). Grâce à de nombreux mécènes issus des milieux aisés de Chicago, ce musée, le deuxième plus grand musée d'art aux États-Unis après le Museum of Modern Art (MoMA) à New York est particulièrement renommé pour ses collections sur les différents arts américains. Si ses collections représentent ans d'histoire de l'art dans le monde, il détient le plus grand nombre de peintures impressionnistes en dehors de Paris, et accueille environ visiteurs en 2005.

Le Musée des sciences et de l'industrie ("Museum of Science and Industry"), connu sous l'acronyme de MSI, a été inauguré à l'occasion de l'Exposition universelle de 1893 ("World Columbian Exposition"). Il se situe à Jackson Park, dans le secteur de Hyde Park et se trouve dans ce qui était à l'origine le Palais des Beaux-Arts de Chicago. Conçu par l'architecte Charles B. Atwood, le bâtiment a été construit dans le style grec de l'ère classique et a été inspiré par les bâtiments de l'Acropole d'Athènes. Ces dernières années, le musée a subi d'importantes rénovations de modernisation et couvre aujourd'hui une superficie de . Depuis 2009, il s'est classé comme étant la deuxième plus importante attraction culturelle de la ville.

Le musée d'art contemporain de Chicago ("Museum of Contemporary Art"), connu sous l'acronyme de MCA, est l'un des plus grands musées d'art contemporain du monde. Fondé en 1967 comme galerie d’expositions temporaires, il acquiert dès 1974 des collections permanentes, toujours spécialisées dans des créations de l'après Seconde Guerre mondiale. Désormais établi en centre-ville, il se situe dans le quartier de Streeterville, au 220 East Chicago Avenue, près de la Water Tower Place. Si ses expositions sont particulièrement renommées, son fond permanent, qui met un accent particulier sur le surréalisme, le minimalisme, la photographie conceptuelle et les travaux des artistes locaux, se compose de plus de œuvres contemporaines.

Chicago propose également à la visite l’un des plus grands aquarium du monde, l'aquarium John G. Shedd. Inauguré en 1930, grâce au généreux don de de l'entrepreneur John G. Shedd, l'aquarium devient à son ouverture le plus important du monde avec un total de 19 millions de litres d'eau et quelque poissons de plusieurs centaines d'espèces différentes issues des quatre coins du monde. Il reçoit chaque année la visite de plus de deux millions de touristes, ce qui en fait l'un des aquariums publics les plus fréquentés des États-Unis.

Le musée de la photographie contemporaine ("Museum of Contemporary Photography"), fondé en 1984 par le Columbia College, est situé sur Michigan Avenue, dans le secteur de Near South Side. Il s’intéresse à la photographie contemporaine, se concentrant sur l'Amérique et les résidents des États-Unis. Sa collection, composée de photographies, intègre des œuvres d'Ansel Adams, d’Henri Cartier-Bresson, Julia Margaret Cameron, Walker Evans, Dorothea Lange, Irving Penn, Aaron Siskind et Victor Skrebneski. Il permet également de découvrir différents types d'appareils photos, des tirages couleur, des morceaux numériques, des diaporamas et des photogrammes.

Le Terra Museum of American se donne pour vocation de regrouper des œuvres d’artistes américains. Situé sur Michigan Avenue, il est géré par la "Terra foundation for american art", du nom de son créateur Daniel J. Terra, un homme d’affaires américain également à l’origine de la création du musée des impressionnismes Giverny (MIG) en 1992. Le Terra Museum regroupe, dans son importante collection de peintures, de nombreuses œuvres d’artistes du mouvement impressionniste. Le 31 octobre 2004, il ferme définitivement ses portes après 24 ans d'existence.

Le Musée Field d'Histoire Naturelle ("Field Museum of Natural History") est situé au Museum Campus (parc municipal regroupant également l'aquarium John G. Shedd et le planétarium Adler), au sud-est de Grant Park entre Lake Shore Drive et le lac Michigan. Construit par l'architecte Daniel Burnham dans le style néo-classique initié lors de l'exposition universelle ("World Columbian Exposition"), il ouvre en 1893 sous le nom de "Columbian Museum of Chicago". Renommé Muséum Field en 1905, en hommage à l'homme d'affaires et donateur Marshall Field, il s’organise en quatre départements principaux : l'anthropologie, la zoologie, la botanique et la géologie. Depuis 1997, le musée abrite le plus grand squelette connu de "Tyrannosaurus rex", surnommé « Sue », du nom de Sue Hendrickson, la paléontologue l'ayant découvert. En 2006, le musée accueille 1,7 million de visiteurs, devenant ainsi la principale attraction culturelle de la ville.

Le Musée d'histoire de Chicago ("Chicago History Museum"), hérité de la "Chicago Historical Society", est un musée fondé en 1856. Situé dans le secteur de Lincoln Park, il possède plus de 22 millions d'objets et de documents qui sont autant de preuves et de témoignages permettant de retracer l’ensemble de l'histoire de Chicago, des origines de la ville avant sa fondation à la métropole moderne qu'elle est aujourd'hui.

Le Planétarium Adler ("Adler Planetarium and Astronomy Museum"), construit en 1930, est le plus ancien planétarium du continent américain. Couplé à un musée de l’astronomie et l'astrophysique, il offre une gamme d’expositions célestes et un environnement de réalité virtuelle, qui permettent de découvrir les constellations et l’histoire de l'exploration spatiale. Il met aussi en exergue les plans audacieux de l'Amérique visant à voyager sur la Lune.

L’American Police Center Museum (APCM) résulte d’une collecte commencée en 1974 par la "Chicago Patrolmen's Association" concernant le Chicago Police Department. Situé dans le quartier de South Loop, au 1717 South State Street, le musée ouvre ses portes en 1989. Il réunit diverses séries d’objets, dont des armes de contrebande et une réplique de chaise électrique. Il présente, outre des photos (dont certaines issues du massacre de Haymarket Square survenu en 1886) et des documents relatifs au maintien de l’ordre, une collection d’insignes et d’uniformes de police. Il dispose de sections consacrées aux luttes que la ville a pu mener notamment contre la mafia, ou la toxicomanie, dont la scénographie privilégie parfois le spectaculaire.

Chicago propose également des musées consacrés à l’histoire et à la culture de certaines ethnies, religions ou nationalités. Ainsi, le musée national d'art mexicain ("National Museum of Mexican Art", abrégé sous l'acronyme de NMMA), fondé en 1982 et se trouvant depuis 1987 au parc de Harrison dans le quartier mexicain de Pilsen, est le principal dépôt pour l'art mexicain et la culture chicano. Sa collection permanente réunit plus de objets. Le musée polonais d'Amérique ("Polish Museum of America"), pour sa part, se donne pour mission de , tandis que le "Ling Long Museum", situé à Chinatown, s’intéresse à l’histoire et à la culture des populations chinoises immigrées aux États-Unis. Le musée DuSable des Afro-Américains ("DuSable Museum of African American History"), issu de l’"Ebony Museum of Negro History and Art", ouvre ses portes avec la volonté de corriger l'absence de perception de l'histoire et de la culture noire dans le monde universitaire. Portant depuis 1968 le nom de Jean Baptiste Pointe du Sable, un métis né d'un père Blanc et d'une mère Noire, qui en qualité de premier colon permanent, peut être considéré comme le « fondateur de Chicago », le musée DuSable est le plus ancien du genre à être consacré à l'étude et à la conservation de l'histoire, de la culture et de l'art afro-américain. Fondé en 1896, l’Institut oriental de Chicago est le musée d’une structure universitaire, l"'Oriental Institute", elle-même rattachée à l'université de Chicago. Le musée et l’Institut bénéficient dès leur création, du soutien du milliardaire John Davison Rockefeller. Transféré dans un bâtiment qui accueille le musée et l'institut depuis 1931, sa fréquentation est d'environ par an. Il abrite plus de , principalement issus d’excavations conduites par l'Oriental Institute. Constituant une des plus importantes collections d'objets archéologiques des États-Unis, il présente un ensemble d’informations assez complet sur le Moyen-Orient antique.

Le Centre culturel de Chicago ("Chicago Cultural Center"), situé sur Washington Street dans le secteur du Loop, constitue la dixième attraction touristique de la ville. Il est construit en 1897 et constitue alors la première bibliothèque municipale de Chicago. Reconverti en centre culturel à partir de 1977, il offre quotidiennement et tout au long de l’année des programmes et des expositions qui vont des arts du spectacle et visuels aux arts littéraires. Les bâtiments présentent, en eux-mêmes, des aspects architecturaux intéressants, dont de spectaculaires dômes de vitraux, parfois inspirés de modèles compliqués de la Renaissance. La salle Preston Bradley est coiffée du plus grand dôme en vitrail du monde.

Le musée national d’Art des Anciens Combattants ("National Viêt Nam Veterans Art Museum", devenu "National Veterans Art Museum" en 2010), connu sous l'acronyme de NVAM, est issu d’une collection artistique organisée en 1981 par quelques anciens combattants du Viêt Nam, réunis au sein du "Viêt Nam Veterans Art Group". Comprise comme une déclaration humaniste et intemporelle contre la guerre, et portée dans divers musées et galeries des États-Unis, cette collection est devenue permanente en 1996, après que le maire de Chicago Richard M. Daley, personnellement ému par ce témoignage artistique, lui a alloué un bâtiment. Il présente des œuvres offrant un point de vue unique sur le sujet controversé de la guerre, avec un équilibre fragile, qui reflète la beauté et l’horreur, donnant une perspective unique sur le psychisme des anciens combattants.

Le Chicago Children's Museum (en français, Musée pour enfants de Chicago) est situé depuis 1995 sur la jetée Navy et présente l’originalité d’être un musée spécifiquement adapté aux enfants. Fondé en 1982 par une ligue associative, il se veut la réponse compensatoire à des compressions de programmes et d'activités dans les écoles publiques de la ville. Couvrant d'espace d'exposition, il comprend, sur trois étages, des expositions éducatives, des programmes d’éducation publics, des activités ludiques et des événements spéciaux. Pouvant accueillir jusqu’à personnes chaque année, il est le quatrième plus grand musée pour enfants des États-Unis.

En tant que troisième plus grande ville des États-Unis, Chicago est bien connue pour avoir la musique dans l'âme et a toujours été un centre majeur pour la musique dans le Midwest, surtout au début des années 1900, quand la « grande migration » d'ouvriers pauvres d'origine afro-américaine des villes industrielles du sud du pays a apporté les musiques traditionnelles comme le jazz et le blues à Chicago, le jazz ayant donné naissance à la scène locale connue sous le nom de Chicago Jazz. En matière de musique folk, Chicago possédait une scène prospère, en particulier dans les années 1960 et 1970 lorsque de nombreux artistes de la région se retrouvaient pour jouer dans les bars du centre ville.

La scène jazz de Chicago est remarquable pour ses nombreux musiciens de renom. Les artistes les plus importants à Chicago incluent George Lewis, Ray Anderson, Muggsy Spanier, Jimmy McPartland, Bix Beiderbecke, Eddie Condon, Bud Freeman, Benny Goodman, Gene Krupa, Frank Teschemacher, et Frank Trumbauer. Au début du , Chicago devint avec La Nouvelle-Orléans l'un des berceaux du jazz. La plupart des artistes chicagoans se produisaient à l'Aragon Ballroom, une salle de bal devenue très populaire dans les années 1930 ; elle se situe dans le quartier de Uptown et a accueilli presque tous les grands noms de l'ère du « big band » dont Frank Sinatra et Tommy Dorsey. Au , Chicago possède toujours une scène jazz vibrante et innovante, grâce notamment à son festival annuel de jazz ("Chicago Jazz Festival"). Les célébrités ayant popularisé ce festival incluent des musiciens mondialement connus comme Sonny Rollins, Ornette Coleman, Miles Davis, Benny Carter, Ella Fitzgerald, Anthony Braxton, Betty Carter, Lionel Hampton, orchestre de Chico O'Farrill, Jimmy Dawkins, Von Freeman, Johnny Frigo, Slide Hampton, Roy Haynes, et beaucoup d'autres. Les musiciens les plus importants à travers toutes les ères vivantes du jazz continuent de donner régulièrement des concerts en ville, font des enregistrements et voyagent à travers tout le pays jusqu'en Europe. John Prine, Steve Goodman et Bonnie Koloc étaient les chanteurs-compositeurs de chansons folkloriques les plus en avant de cette période. Étant un grand fan de l'équipe des Cubs, Steve Goodman reste l'artiste le plus étroitement lié à la ville.

Le groupe Earth, Wind and Fire a été formé à Chicago en 1969 par Maurice White. Earth, Wind and Fire a été l'un des groupes les plus populaires durant les années 1970 et la première moitié des années 1980, vendant des albums par millions à travers le monde. Leur style musical et un mélange de jazz-funk et de disco-funk ; ils révolutionneront le genre et influenceront un grand nombre de groupes et d'artistes.

Chicago est aussi célèbre pour être le lieu de naissance de la « House music » et de certains de ses sous-genres comme l'Acid house, la Chicago house, la Hip-house, la Deep house, la Tech house et la Diva house qui sont d'autres genres de musiques électroniques directement liés à la House Music. Ses principaux représentants sont mondialement connus et incluent les Fingers, Inc., Marshall Jefferson, Steve Hurley, Curtis Jones, Ron Carroll, Keith Farley, Larry Heard, Jesse Saunders, Paul Johnson, Adonis, Lil' Louis, Ten City, Anthony Nicholson ou Vince Lawrence.

Concernant la musique classique, Chicago possède deux orchestres majeurs, dont l'orchestre symphonique de Chicago qui est l'un des orchestres les plus anciens et les plus respectés de la nation et l'orchestre Sinfonietta de Chicago qui, avec son groupe, est reconnu en tant qu'« orchestre le plus divers de la nation ». Le Grant Park Music Festival offre une série annuelle de concerts de musique classique à Grant Park. Il est le seul festival de musique classique en plein air et se tient actuellement dans le pavillon Jay Pritzker au Millennium Park. Le Grant Park Music Festival est depuis 1931 « une tradition à Chicago », voire incontournable depuis que le maire Anton Cermak ait proposé des concerts gratuits pour remonter le moral des habitants de Chicago durant la Grande Dépression. Le festival, qui est parrainé par le Chicago Park District, le Département des affaires culturelles de Chicago et le Grant Park Orchestral Association présente les nominés aux Grammy Awards.

La scène hardcore de Chicago a développée le punk hardcore de manière inconditionnelle au début des années 1980. Elle était bien plus expérimentale que dans les autres grandes villes des États-Unis et dans le reste du monde. Elle s'est développée durant l'année 1982, dans et autour des bars et des lieux de rendez-vous dans les quartiers nord de la ville. Aujourd'hui, les groupes de punk hardcore les plus populaires sont Naked Raygun, The Effigies, Rise Against, Fall Out Boy, et The Blackad.

Au cours des années 1980 et des années 1990, la scène de musique Rock de Chicago est devenue très populaire, particulièrement la scène hard rock et punk rock, comme The Smashing Pumpkins, The Jesus Lizard, Chicago, Ministry, Survivor ou encore Patti Smith. De nos jours les scènes punk et rock de la ville sont toujours aussi populaires et depuis le début des années 1990, de nombreux groupes et artistes ont fait irruption avec notamment Chevelle, The Effigies, The Lawrence Arms, Venomous Concept, Fall Out Boy, The Killers, Sidewalk, Shellac, Gastr del Sol, Rise Against, Naked Raygun, Tar, Veruca Salt, Dark Star Orchestra, Allá et Big Black. Chicago compte également de nombreux groupes de rock underground, donc pas connus en dehors des frontières de l'Illinois, voire de la ville.

La scène hip-hop de Chicago est devenue très influente à partir du milieu des années 1990 et s'est popularisée grâce à des artistes comme Twista, Kanye West, Common, Lupe Fiasco, Da Brat, Rhymefest ou encore Shawnna. Connue aujourd'hui sous le nom de « "Chicago hip-hop" », la scène hip-hop chicagoane ne possède que peu de représentants. Le genre "Chicago hip-hop" ou "Chicago Rap Music" (littéralement « musique rap de Chicago »), n'a pas de son uniforme ou de style standard de hip-hop semblable a celui du Midwest rap ou du Rap East Coast. Le style des rappeurs de Chicago varie souvent, et suivant les quartiers chicagoans desquels les artistes proviennent, leurs styles changent, allant du Hipster rap au Gangsta rap, ou encore du Rap hardcore au Rap politique. Les rappeurs de West Side ont tendance à revendiquer le style Rap hardcore, à la différence de ceux de South Side qui revendiquent le Rap politique et le rap se mêlant aux influences soul, funk ou encore blues. Aujourd'hui, le style de rap dominant à Chicago est la Drill music, style né en 2011 dans le South Side avec la monté en popularité des rappeurs membres de gangs chicagoans tels que Chief Keef, Lil Jay, FBG Duck, Fredo Santana ou encore Lil Durk.

À Chicago, le RnB contemporain s'est développé durant la fin des années 1980 et a commencé à prendre de l'ampleur dans le milieu des années 1990, comprenant des artistes s'étant exportés jusqu'en Europe comme Donell Jones, la chanteuse Jennifer Hudson, mais aussi et surtout R. Kelly, considéré depuis ses débuts dans la première moitié des années 1990, comme étant l'artiste RnB américain le plus charismatique et l'un des plus vendeurs.

Enfin, Chicago est également réputée pour ses nombreuses scènes musicales et pour être le foyer de certains genres : le Chicago Blues, le Chicago Jazz, la Chicago Soul, la Chicago House qui a donné naissance à la « House music » au début des années 1980, le Chicago Rock, le Chicago hip-hop et le Chicago Punk hardcore.

Chicago est l'un des principaux centres de production cinématographique du pays après New York et Los Angeles. De nombreux films des années 1920 et 1930 ont été tournés à Chicago, surtout des films policiers et des films de gangsters ("Scarface", "Le Petit César", "L'Ennemi public", "Le Gangster de Chicago", "L'Affaire Al Capone", "Les Incorruptibles") qui puisent leurs origines dans le crime organisé de la ville des années 1920 et des années 1930 et ses héros comme Al Capone. Le contexte historique est généralement celui de la prohibition ou de la Grande Dépression.

En raison du passé agité et de la réputation sulfureuse de « ville mafieuse et corrompue » véhiculée dans le monde entier pendant de nombreuses décennies, Chicago tente de montrer une autre image d'elle , estimant que cette époque est bel et bien révolue et qu'aujourd'hui la ville n'est plus ce qu'elle était. C'est pour cette raison que depuis plusieurs années ce sont essentiellement des comédies romantiques ("Quand Harry rencontre Sally", "Une bouteille à la mer", "Shall We Dance ?"), des thrillers, des films policier ("Le Fugitif", "US Marshals", "Peur primale"), des films d'action ("Code Mercury", "", "Poursuite"), des films pour adolescent ("Collège Attitude", "") ou encore des films fantastiques et de science-fiction ("I, Robot", "", "", "") qui y sont tournés.

Quelques films ayant pour cadre la ville de Chicago :


De nombreux jeux vidéo, dont les plus connus sont listés ci-dessous, prennent pour cadre la ville de Chicago :

Chicago est le troisième foyer américain pour l'édition derrière New York et Los Angeles. Le "Chicago Tribune" est le principal journal de la ville et de la région du Midwest ; son siège se trouve dans la Tribune Tower et il appartient à la "Tribune Company". Fondé le , le titre est aujourd'hui conservateur ; il est vu comme l'un des meilleurs journaux des États-Unis. Il a été l'un des premiers quotidiens américains à soutenir la candidature d'Abraham Lincoln à la présidence des États-Unis et à revendiquer la suppression de l'esclavage.

Avec plus de le dimanche, le "Chicago Tribune" est l'un des dix quotidiens les plus vendus aux États-Unis. Le "Chicago Daily News" était un quotidien très populaire dans la ville entre 1876 et 1978, il a obtenu un total de treize prix Pulitzer durant son existence. Le "Daily News" était pionnier dans certains domaines de l'information, ouvrant l'un de ses bureaux à l'étranger, il s'est hissé au premier rang des quotidiens américains en 1898.

Les autres journaux réalisent des tirages inférieurs : le "Chicago Sun-Times", qui a adopté le format d'un tabloïd ou le "Daily Southtown", qui couvre le sud de l'agglomération. D'autres couvrent des domaines spécialisés tels que le "Chicago Sports Review" pour le sport ou le "Chicago Defender" pour la communauté afro-américaine. Dans les années 1940 et 1950, John H. Johnson crée les magazines "Ebony" et "Jet", tous deux consacrés à la communauté noire de Chicago. Le "Windy City Times" et le "Chicago Free Press" sont des hebdomadaires qui s'adressent à la communauté homosexuelle du quartier de Boystown et du reste de la région.

Le "Chicago Reader" est un autre magazine hebdomadaire distribué à Chicago qui fait partie de ce que les Américains nomment les "alternative newspapers" qui sont des journaux ou des magazines mettant l'accent sur les informations et enquêtes sur la vie locale d'une cité ou d'une région définie. Le "Chicago Reader" est l'un des pionniers du mouvement des publications hebdomadaires gratuites. Il a été fondé en 1971 par un groupe d'étudiants.

Certains secteurs de la ville possèdent leur propre journal, comme Hyde Park avec le "Hyde Park Herald", Bridgeport avec le "Bridgeport News" ou encore Hegewisch avec l"'Our Neighborhood Times". Ces journaux couvrent l'information dans le secteur ainsi que dans les quartiers environnants ; ils servent généralement à informer les résidents du quartier sur ce qui s'y passe et apportent plus de détails et de spécificités que les journaux de l'ensemble de la ville sont susceptibles d'apporter, comme les annonces et les recherches d'emploi, les offres immobilières, la publicité pour les commerçants locaux ou encore les fêtes de quartier.

Chicago est le berceau du "Talk show" : lOprah Winfrey Show", animé par Oprah Winfrey depuis 1986 est l'un des plus regardés des États-Unis. Le "Jerry Springer Show", animé par Jerry Springer depuis 1991 et le ' sont réalisés dans la NBC Tower.

Quelques séries télévisées ont pour cadre la ville de Chicago et son agglomération :

En 2005, le festival gastronomique "Taste of Chicago" a attiré quelque . Il s'agit du plus grand festival dédié à la gastronomie dans le monde où l'on peut goûter aux spécialités locales et régionales. Les autres grands événements de l'année sont les festivals de blues, de country, de jazz et de gospel qui ont lieu au Millennium Park et qui rassemblent chacun environ .

Quelques festivals de musique notables :


En 2015, Chicago a attiré environ 52 millions de touristes arrivant de toute la nation et de l'étranger. Ces visiteurs ont rapporté 12,8 milliards de dollars à l'économie de Chicago. Les boutiques de luxe le long du "Magnificent Mile", ses nombreux restaurants et musées, ses plages au bord du lac Michigan le long de Lake Shore Drive, mais aussi son architecture éminente et propre à Chicago, continuent à fasciner les touristes. Les halls d'exposition et les grandes salles de spectacles constituent également des atouts majeurs de la ville. La partie Est de Oak Street (entre Michigan Avenue et Rush Street), est l'une des destinations les plus prestigieuses pour l'achat à Chicago, elle comprend des chaînes de magasins, des grands centres commerciaux, et est reconnue dans le monde de la gastronomie pour ses grands restaurants.

L'une des dernières fiertés de Chicago est le Millennium Park, dont l'ouverture a été célébrée le 16 juillet 2004. Les travaux ont commencé en juin 1999 mais le chantier fut retardé durant plusieurs années. Le Millennium Park fait partie de Grant Park, l'un des plus grands jardins publics de la ville de Chicago. Il est spécialement destiné à l'architecture et l'art contemporain et comprend de nombreux aménagements publics tels que le McCormick Tribune Plaza, qui est un complexe comprenant un espace consacré aux expositions en plein air, et un restaurant avec terrasse extérieure qui se transforme en patinoire l'hiver, le Lurie Garden, qui se targue d'être le plus grand jardin public du monde à se trouver en plein cœur d'une mégapole, le Harris Theater, ainsi que diverses promenades. Le parc comprend aussi certaines des attractions les plus populaires de la ville, avec notamment la "Cloud Gate", une sculpture urbaine réfléchissante (surnommée "The Bean" - « Le Haricot »), qui a été réalisée par l'artiste britannique Anish Kapoor et financée par des investissements privés pour 23 millions de dollars. Haute de , la base de cette sculpture monumentale mesure × pour un poids total de . Son aspect s'inspire du mercure liquide. Son extérieur poli reflète et déforme la "skyline" de la ville. Les visiteurs sont invités à marcher autour et en dessous de l'arche haute de contenant une chambre concave appelée « omphalos » qui multiplie et déforme par réverbération l'image des spectateurs.

Le kiosque à musique du pavillon Jay Pritzker, conçu par l'architecte Frank Gehry, est l'un des lieux en plein air les plus performants concernant les événements festifs et culturels à Chicago. Élément central du Millennium Park, le pavillon accueille le Cœur et l'Orchestre Symphonique de Grant Park ("Grant Park Symphony Orchestra and Chorus") ainsi que le Grant Park Music Festival, l'un des derniers festivals de musique classique en plein air et gratuit des États-Unis. Il accueille aussi un large éventail d'ensembles musicaux et, chaque année, une grande manifestation de spectacles vivants. Des artistes, allant des groupes de rock à la musique classique en passant par des chanteurs d'opéra, s'y représentent. Toutes les répétitions au pavillon sont ouvertes au public. Il accueille aussi des activités de fitness comme le yoga.

La "Crown Fountain", qui fut dessinée par l'artiste catalan Jaume Plensa, représente également une attraction majeure du parc. Cette fontaine se compose d'un miroir d'eau de granite noir placé entre deux tours faites en brique de verre. Les tours, qui mesurent plus de de haut, sont constituées chacune d'un écran composé de diodes électroluminescente (LED) qui permettent d'afficher des vidéos numériques reproduisant ainsi les visages de Chicagoans célèbres sous forme de portrait, avec de l'eau jaillissant de leurs lèvres. De l'eau coule des deux tours sous forme de cascade intermittente à travers une buse placée sur la façade de chaque tour. La construction et la conception de la "Crown Fountain" a couté environ 17 millions de dollars. Lorsque le temps le permet, la fontaine est ouverte de mai à octobre.

Construit en 1929, le planétarium Adler est le plus ancien planétarium du continent américain et a été fondé par le philanthrope Max Adler. Ce musée, spécialisé dans l'astronomie et l'astrophysique, propose différentes reproductions et maquettes des planètes du système solaire. Le musée Field d'histoire naturelle, l'un des plus importants aux États-Unis, abrite le plus grand des squelettes complets de "Tyrannosaurus rex" et le mieux préservé. Ouvert en 1893, ce musée comprend quatre thèmes principaux : l'anthropologie, la zoologie, la botanique et la géologie. En 2006, le musée Field a accueilli 1,7 million de visiteurs. Le musée des sciences et de l'industrie est la quatrième plus importante attraction culturelle de la ville, il comprend près de et a accueilli 1,67 million de visiteurs en 2007. Le planétarium Adler et le musée Field se trouvent au Museum Campus, un parc comprenant également l'aquarium John G. Shedd.

Bordant les rives du lac Michigan, les plages de Chicago sont très prisées l'été. En effet, la ville de Chicago possède 33 plages sur de rivage le long des rives du lac Michigan. La plus connue et la plus fréquentée est sans doute celle d'Oak Street Beach, située à proximité du centre-ville, dans le quartier de Streeterville.

Fréquentée chaque année par plus de huit millions de visiteurs, la jetée Navy ("Navy Pier") est inscrite depuis le sur la liste du "National Register of Historic Places". Sa grande roue de offre une vue exceptionnelle sur les immeubles de Downtown, surtout de nuit. Situé au nord de Grant Park, juste en bordure du lac Michigan, son ferry est l'une des attractions les plus visitées dans toute la région du Midwest, attirant environ 8,7 millions de personnes chaque année. Servant à l'origine de bibliothèque centrale de la ville jusqu'à sa reconversion en 1977, le Centre culturel de Chicago ("Chicago Cultural Center") est aujourd'hui l'un des plus importants centre culturel du pays. Il abrite l'office de tourisme de Chicago, plusieurs galeries commerçantes, des halls d'exposition, et le Preston Bradley Hall dont le plafond est surmonté d'un dôme en verre de .

Fondé en 1868, le zoo de Lincoln Park ("Lincoln Park Zoo") est un parc zoologique qui abrite une grande variété d'animaux dont des ours polaires, des pingouins, des gorilles, différentes sortes de reptiles et de singes ainsi que d'autres espèces pour un nombre total de près de . Un "Quercus macrocarpa" se trouve au zoo de Lincoln Park, c'est une espèce arboricole datant de 1830, soit trois ans avant que la ville de Chicago soit fondée. Il existe aussi un parcours ainsi que des endroits spécifiques à l'intérieur du parc pour divertir les enfants, comme des salles de jeux, une ferme avec des tours en chevaux et poneys. En 2005, le parc a attiré plus de 3 millions de personnes.

Enfin, la ville est la principale destination conventionnelle des États-Unis et la troisième du monde. La plupart des conventions se tiennent à la McCormick Place, juste au sud du Soldier Field.


Le Chicago Public Schools (CPS) est le district scolaire qui contrôle 613 écoles primaires et secondaires publiques dans la ville de Chicago. Il concerne quelque et est dirigé par le "" (CEO) Ron Huberman. Comme d'autres districts scolaires urbains du pays, le Chicago Public Schools connaît des problèmes d'effectifs, de manque de moyens financiers et de difficultés de gestion. En 1987, le Secrétaire d'État à l'Éducation William Bennett déclare que le Chicago Public Schools est le pire de la nation ("worst in the nation"). Depuis, plusieurs réformes ont été mises en œuvre afin d'améliorer cette situation : création d'un système de conseils ("Local School Councils"), d'écoles à charte ("Charter Schools"), etc. Les établissements les plus obsolètes sont rasés, tandis que les autres sont agrandis et/ou rénovés, et de nouvelles écoles sont construites.

Il y a 9 écoles d'inscription sélective élevée dans les écoles publiques de Chicago. Elles sont conçues pour répondre aux besoins des élèves dont le niveau scolaire est plus avancé que la moyenne. Les écoles sélectives offrent un programme scolaire rigoureux et surtout proposent un programme spécifique et avancé (en anglais : "Advanced Placement").

L'archidiocèse de Chicago gère, quant à lui, les écoles catholiques de la ville. Il existe également des écoles privées, dont les plus réputées sont la Latin School of Chicago et la Francis W. Parker School dans le secteur de Lincoln Park. On peut citer également les écoles Chicago Laboratory Schools et Chicago Booth School of Business, situées dans le secteur de Hyde Park dans le South Side de la ville.

La ville de Chicago ne compte pas moins de 97 universités dont certaines comptent parmi les plus prestigieuses des États-Unis. Parmi les plus grands établissements figurent l'Institut de technologie de l'Illinois communément nommée IIT (privée), l'université de l'Illinois à Chicago communément nommée UIC (publique), et l'université DePaul (privée). Fondée en 1898 par la Société de Saint-Vincent-de-Paul, l'université DePaul est la plus grande université catholique du pays.

Depuis les années 1890, Chicago est l'une des principales métropoles mondiales pour l'éducation et la recherche. La ville compte deux des meilleurs centres universitaires des États-Unis : l'université de Chicago et l'université Northwestern, toutes deux privées. Fondée en 1890 par le philanthrope John Davison Rockefeller, l'université de Chicago s'étend sur un vaste campus situé dans le secteur de Hyde Park ; elle est réputée pour ses mouvements académiques influents comme l'école de Chicago en économie, l'école de Chicago en sociologie, pour sa critique littéraire, et pour le mouvement de loi et d'économie en analyse légale ; la Chicago Booth School of Business est la "Business School" de l'université de Chicago et possède un campus dans le centre-ville. L'université Northwestern a été fondée en 1851 par les méthodistes de Chicago ; elle dispose d'un campus de dans la ville d'Evanston, en banlieue nord. L'enseignement professionnel est localisé dans le centre de Chicago.

L'université Loyola de Chicago, une autre université catholique, possède un campus à Rogers Park, un secteur de North Side (dans le nord de la ville), un deuxième campus dans le secteur du Loop, ainsi qu'un centre médical dans la banlieue ouest à Maywood. Elle représente la plus importante université jésuite des États-Unis. Les écoles de médecine et de droit de l'université Northwestern se trouvent, quant à elles, à Streeterville, un quartier du secteur de Near North Side. Avec plus de , l'université de l'Illinois à Chicago est la plus grande université de la ville ; elle comprend la plus grande école de médecine américaine, l'University of Illinois College of Medicine. Fondée en 1867, l'Université d'État de Chicago comprend plus de . Elle figure avec l'université du Nord-Est de l'Illinois parmi les plus importants établissements supérieurs de la ville. Fondée sur les principes de justice sociale, l'université Roosevelt est baptisée en l'honneur du trente-deuxième président des États-Unis Franklin D. Roosevelt, deux semaines après son décès.

Fondé en 1940 à Chicago, l'Institut de technologie de l'Illinois ("Illinois Institute of Technology" ou IIT) possède cinq campus dont le principal se situe dans le quartier de Bronzeville ; il propose des programmes renommés en ingénierie et en architecture, et s'enorgueillit d'avoir accueilli le célèbre architecte Ludwig Mies van der Rohe pendant de nombreuses années ; en effet, l'architecte est en grande partie responsable du campus principal de l'Institut qui s'étale sur une superficie de . Il est membre du groupe "Association of Independent Technological Universities" qui regroupe notamment le Massachusetts Institute of Technology (MIT) et le California Institute of Technology (Caltech). Le et le Shimer College partagent le même campus que l'Institut de technologie de l'Illinois.

Le Rush Medical College, qui fait désormais partie de l'université Rush, est la première institution d'études supérieures créée dans l'État de l'Illinois et l'une des premières écoles de médecine ouverte à l'ouest des Alleghenies. L'université Rush comprend une école de médecine (Rush Medical College), d'infirmières (Rush University College of Nursing), de sciences médicales (Rush University College of Health Sciences) ainsi qu'un "college" (The Graduate College of Rush University). Le Rush Medical College obtient sa charte le 2 mars 1837, deux jours avant l'incorporation de la ville de Chicago.

La région de Chicago compte 12 écoles de théologie accréditées, qui représentent les Catholiques et la plupart des courants protestants. Le est la plus ancienne institution d'enseignement supérieur de la ville. Ses séminaires font partie d'un consortium connu sous le nom d"'Association of Chicago Theological Schools" (ACTS). Le "Moody Bible Institute" se situe non loin du centre ville. L'université North Park est affiliée à l'Evangelical Covenant Church et se trouve dans le secteur de North Park. Le lycée français de Chicago, établissement privé à but non lucratif appartenant au réseau scolaire français, est créé en 1995. Son enseignement, conforme à celui de l'Éducation nationale française, est dispensé en deux langues, français et anglais. Il accueille 389 élèves, de la maternelle à la terminale.

Chicago est plusieurs fois nommée meilleure ville des sports aux États-Unis par le magazine américain "The Sporting News" (en 1993, 2006 et 2010). La ville de Chicago possède deux équipes professionnelles de ligue majeure de baseball (les Cubs et les White Sox), un club de football américain (les Bears), une équipe de hockey sur glace (les Blackhawks), et la fameuse équipe de basket-ball (les Bulls). Les Cubs jouent au Wrigley Field, dans le secteur de Lakeview (North Side) tandis que les White Sox jouent au Guaranteed Rate Field (anciennement "U.S. Cellular Field"), dans le secteur d'Armour Square (South Side). Bien qu'elles appartiennent à la même ville, il existe une grande rivalité entre les deux équipes. Les White Sox ont gagné la série mondiale de la Ligue majeure de baseball en 2005. Chicago est la seule ville en Amérique du Nord à posséder plus d'une concession de la MLB depuis la création de la Ligue américaine en 1900. Les Bears de Chicago, équipe fondatrice de la NFL, ont gagné neuf championnats en NFL (1921, 1932, 1933, 1940, 1941, 1943, 1946 et 1963) et un Super Bowl (1986). Les Bears jouent leurs matchs à domicile au Soldier Field, situé à proximité du Museum Campus dans le secteur de Near South Side.

L'équipe de basket des Bulls de Chicago, qui évolue en NBA est l'une des plus célèbres du monde. Dans les années 1990, grâce notamment à Michael Jordan (qui en est le joueur vedette de 1984 à 1998), les Bulls remportent six championnats de NBA (1991, 1992, 1993, 1996, 1997 et 1998) en huit saisons. Les Blackhawks de Chicago de la Ligue nationale de hockey, jouent depuis 1926 et remportent six coupes Stanley, dont la dernière en 2014-2015. Les Bulls et les Blackhawks jouent au stade de l'United Center, situé dans le secteur de Near West Side, directement à l'ouest du secteur financier du Loop.
Trois fois vainqueurs des Séries mondiales (1906, 1917 et 2005) et de la Ligue américaine (1901, 1906, 1917, 1919, 1959 et 2005), les White Sox de Chicago, l'une des équipes les plus populaires de la LMB furent à l'origine du plus grand scandale de l'histoire du baseball, alors connu sous le nom « Black Sox ». En 1919, huit joueurs des Sox acceptent des pots-de-vin pour perdre les Séries mondiales. Ils seront radiés à vie. Richard M. Daley, ancien maire de Chicago, est depuis son enfance un fan inconditionnel des White Sox.

Fondés en 1920 par George Halas, les « Decatur Staley's » sont rebaptisés les « Chicago Staley's » en 1921 puis les Bears de Chicago en 1922. Ils remportent leur premier titre dès 1921. Le dernier succès des Bears lors du Super Bowl fut un triomphe en 1986 avec une écrasante victoire de 46 à 10 contre les Patriots de la Nouvelle-Angleterre. Leurs principaux rivaux sont les Packers de Green Bay.

Le club de football des Fire de Chicago est membre du Major League Soccer (MLS). Les Fire ont gagné un championnat MLS et quatre US Open Cups depuis leur saison inaugurale en 1998. En 2006, le club s'est déplacé en dehors de la ville de Chicago, au Toyota Park à Bridgeview, après avoir joué ses huit premières saisons au Soldier Field en centre-ville de Chicago, et au stade cardinal à Naperville, en banlieue ouest. Le club est maintenant la quatrième équipe de soccer professionnelle de Chicago, les deux premiers étant les Sting de Chicago du North American Soccer League (et plus tard de l'équipe d'intérieur du Major Indoor Soccer League) ; Chicago Power du NPSL-AISA, et finalement l'équipe professionnelle féminine des Red Stars de Chicago formée en 2007. La précipitation de Chicago, de la Ligue de Football d'arène, les "Chicago Bandits" du NPF et les Chicago Wolves, de l'AHL, jouent également à Chicago. Évoluant au sein de la Women's National Basketball Association, l'équipe féminine de basket des Sky de Chicago a commencé à jouer en 2006. L'équipe s'entraîne dans le stade omnisports de l'UIC Pavilion dans le secteur de Near West Side.

Le , Chicago est sélectionnée par le Comité national olympique américain pour représenter les États-Unis en tant que pays organisateur des Jeux olympiques d'été de 2016. Parmi les villes américaines qui se sont présentées : Los Angeles, Houston, San Francisco et Philadelphie. Le , le Comité international olympique retient Chicago parmi les quatre villes candidates pour les Jeux de 2016. Ses trois villes concurrentes sont Madrid, Tokyo et Rio de Janeiro. Chicago sera finalement éliminée dès le premier tour de scrutin, le .

Chicago a par ailleurs accueilli les Jeux panaméricains de 1959 et les Gay Games VII de 2006. La ville est également choisie pour accueillir les Jeux olympiques de 1904, mais ces derniers sont transférés à Saint-Louis dans le Missouri pour coïncider avec l'Exposition universelle.
Datant de 1870, le stade Wrigley Field demeure l'un des plus anciens parcs de baseball du pays. En 1914, Charles Weeghman décide d'édifier un nouveau terrain pour les "Chicago Whales" de la Federal League, à l'angle des rues Clark et Addison. Initialement nommé Weeghman Park, le chantier de ce nouveau stade d'une capacité de débute le 23 février 1914 et une cérémonie officielle a lieu le 4 mars 1914. Depuis les années 1940, le stade de Wrigley Field a peu changé. En 1981, la Tribune Company achète les Cubs et commence à parler du fait d'installer des lumières, après la saison 1981. Le Wrigley Field organise trois Matchs des étoiles de la Ligue majeure de baseball : en 1947, 1962 et 1990. En 1982, un babillard électronique est placé sous le tableau d'affichage du champ central.

Après la saison 2003, les Cubs ajoutent directement derrière le marbre, portant ainsi les spectateurs encore plus proche du terrain. Après la saison 2005, les Cubs ajoutent encore aux gradins, portant la capacité à un peu plus de . À l'avenir un bâtiment polyvalent hébergeant un restaurant à thème et des cages de lancement pour des joueurs sera construit sur le côté ouest de Wrigley Field.

Avec , le Soldier Field est l'un des plus grands équipements sportifs de Chicago. En 2005, le stade de baseball de Wrigley Field accueille un total de 3,1 millions de spectateurs. En 2003, la ville compte 791 terrains de baseball, 704 courts de tennis, 258 complexes sportifs, 180 gymnases, 90 piscines et 6 terrains de golf. Il existe en outre plus de de pistes cyclables.

Le Guaranteed Rate Field est inauguré le 18 avril 1991 sous le nom de Comiskey Park (le deuxième du nom) et coûte 167 millions de dollars. En juillet 2003, il est le lieu du Match des étoiles de la Ligue majeure de baseball 2003. La société U.S. Cellular a acheté les droits d'appellation du bâtiment pour 68 millions de dollars sur 20 ans.

Chaque année, le Marathon de Chicago a lieu sur la voie rapide de Lake Shore Drive ; il fait partie du World Marathon Majors et est reconnu comme étant l'un des marathons les plus rapides au monde.

Chicago est le lieu de naissance de nombreuses personnalités, dont certaines ont acquis une notoriété internationale.

Ainsi, le début du voit naître, dans une famille d'artisan charpentier domiciliée sur Tripp Avenue, celui qui devient, avec l'invention de Mickey Mouse, le maître du dessin animé, Walt Disney.

Durant les années de la prohibition, c'est un autre enfant de la ville, Eliot Ness, qui, de 1925 à 1932, livre une guerre sans merci à Al Capone, parrain de la mafia.

Les enfants de Chicago sont également présents dans l'art musical. Ainsi la ville voit naître, en 1909, un roi du swing, le clarinettiste de jazz Benny Goodman, et, en 1927, Bob Fosse, célèbre chorégraphe et metteur en scène de comédies musicales. Chicago est aussi la ville natale de Quincy Jones, et de Patricia Lee Smith, plus connue sous le nom de Patti Smith, icône de la poésie Beat des années 1960 et 1970. Née en 1968, Anastacia est célèbre pour sa voix soul et puissante. Trois autres Chicagoans sont des stars du "rap" : Twista, renommé pour la rapidité de son , « la sale gosse » Da Brat, et Common, connu pour son écriture pacifiste et érudite. Enfin, Chicago est le lieu de naissance de la star du R'n'B, R. Kelly, dont l’influence s’exerce sur le hip-hop, le rap, la soul et le gospel.

Le cinéma est une industrie dans laquelle de nombreux natifs de Chicago s’expriment, que ce soit comme acteur (Raquel Welch, Harrison Ford, John Belushi, Robin Williams, Michael Madsen, Jessica Harper, Adam Baldwin, Virginia Madsen, Gillian Anderson, Jennifer Beals, John C. Reilly…), ou comme scénariste, réalisateur, ou producteur (Vincente Minnelli, Michael Mann, Robert Zemeckis, John Landis, Stuart Gordon, Harold Ramis, Michael Crichton…).

Le joueur d’échec Bobby Fischer, champion des États-Unis à quatorze ans en 1957-1958, qui remporte en 1972, sur fond de guerre froide, le « match du siècle » contre le Soviétique Boris Spassky, est également né à Chicago. C’est aussi le cas de Phillip Brooks, un célèbre catcheur, sept fois champion du monde, plus connu sous le nom de CM Punk.

Enfin, si Chicago est le lieu de naissance d’Hugh Hefner, fondateur du magazine de charme "Playboy", la ville est également celle d'origine de trois premières dames, Betty Ford, Hillary Clinton, Michelle Obama et aussi de sportifs américains tels que l'ancien défenseur de hockey de la LNH admis en 2013 en tant que membre du Temple de la renommée du hockey, Chris Chelios, ainsi que les basketteurs Derrick Rose, Dwyane Wade, et Anthony Davis.

Chaque année, la fête des jumelages de Chicago propose des mets et de la musique issus de ces coopérations. Chicago est jumelée avec 30 villes situées aux quatre coins du monde. Elle a également signé en 1996 des pactes d'amitié et de coopération d'ordre économique, culturel et politique avec certaines villes comme Paris, la capitale française.

Les villes jumelées avec Chicago sont les suivantes :





</doc>
<doc id="15766" url="https://fr.wikipedia.org/wiki?curid=15766" title="Karl Marx">
Karl Marx

Karl Marx ( en allemand standard ), né le à Trèves en Rhénanie et mort le à Londres, est un historien, journaliste, philosophe, sociologue, économiste, essayiste, théoricien de la révolution, socialiste et communiste allemand.

Il est connu pour sa conception matérialiste de l'histoire, sa description des rouages du capitalisme, et pour son activité révolutionnaire au sein du mouvement ouvrier. Il a notamment participé à l'Association internationale des travailleurs. L'ensemble des courants de pensée inspirés des travaux de Marx est désigné sous le nom de marxisme. Il a eu une grande influence sur le développement ultérieur des sciences sociales. Ses travaux ont influencé de façon considérable le , au cours duquel de nombreux mouvements révolutionnaires se sont réclamés de sa pensée.

Karl Heinrich Marx est né en 1818 à Trèves, dans la province du Bas-Rhin, au sein du royaume de Prusse (aujourd'hui dans le land de Rhénanie-Palatinat). Il est le deuxième d'une famille de huit enfants. Son père, Heinrich Marx (1777-1838), né Herschel Marx Levi Mordechai, était un avocat issu d’une famille de rabbins juifs ashkénazes et de marchands propriétaires de vignobles dans la vallée de la Moselle. Pour exercer sa profession d'avocat, il se convertit au protestantisme en 1816 ou 1817, et changea son prénom de Herschel en Heinrich. Sa mère, Henriette Pressburg (20 juillet 1788-30 novembre 1863), est issue d'une famille juive hollandaise. Restée attachée à la religion juive, elle ne se convertira au luthéranisme qu'en 1825, après la mort de son père, qui était rabbin. Elle est la grand-tante des frères Gerard Philips et , fondateurs de la société Philips. Karl Marx est baptisé dans le luthéranisme en 1824 et confirmé à l'église de la Trinité de Trèves en 1834. Bien que son père respecte la tradition juive en donnant à son fils le prénom de son grand-père, Karl Heinrich Mordechai, il n'est pas élevé de façon religieuse (ni circoncis ni baptisé) et il n'y a aucune preuve que la famille Marx ait pratiqué la religion luthérienne ou juive.

Il entre au ' Friedrich-Wilhelm de Trèves en 1830. Après avoir obtenu son ', il entre à l'université, d'abord à Bonn en octobre 1835 pour étudier le droit et reçoit un certificat de fin d'année avec mention de , puis à Berlin à l'université Friedrich-Wilhelm à partir de mars 1836 où il se consacre davantage à l'histoire et à la philosophie. Il finit ses études en 1841 par la présentation d'une thèse de doctorat : "Différence de la philosophie de la nature chez Démocrite et Épicure" ('). Marx est reçu "" docteur de la faculté de philosophie de l'université d'Iéna le .

À Berlin, il appartient au cercle des « hégéliens de gauche », dénommés aussi « jeunes hégéliens » (avec Bruno Bauer et d'autres) qui cherchent à tirer des conclusions athées et révolutionnaires de la philosophie de Hegel.

L'hégélien de gauche Ludwig Feuerbach s'était lancé dans une critique de la théologie à partir de 1836 et avait commencé à se tourner vers le matérialisme (par opposition à l'idéalisme hégélien). En 1841, cette orientation matérialiste prend le dessus dans sa philosophie ("L'essence du christianisme") et se combine avec la dialectique dite idéaliste de Hegel pour lui donner un caractère scientifique et historique saisissant le réel dans la logique de son évolution. Cette position se heurte à la politique du gouvernement prussien qui avait enlevé à Feuerbach sa chaire en 1832, puis lui avait interdit de revenir à l'université en 1836. Pour finir, les mêmes autorités interdisent à Bruno Bauer, autre grande figure de l'hégélianisme de gauche, d'enseigner à Bonn en 1841. Marx, après avoir obtenu son diplôme universitaire, part pour Bonn avec l'espoir d'y devenir professeur. Mais face à cette politique du gouvernement, il abandonne l'idée d'une carrière universitaire.

Au début de 1842, certains bourgeois libéraux de Rhénanie, en contact avec les hégéliens de gauche, créent à Cologne un journal d'opposition au clergé catholique, la ' (« Gazette rhénane »). Il s'agissait au départ, dans l'intérêt de la Prusse protestante, de faire pièce à la Gazette de Cologne (') et à ses points de vue ultra-montains, mais les rédacteurs développent en fait une , beaucoup plus indépendante et radicale. Ils proposent à Marx et Bruno Bauer d'en devenir les principaux collaborateurs. Marx s'installe dans un premier temps à Bonn, et écrit plusieurs articles pour défendre la liberté de la presse. Moses Hess participe également au journal. En octobre 1842, Marx en devient le rédacteur en chef et s'installe à Cologne.

La tendance démocratique révolutionnaire du journal s'accentue sous la direction de Marx. Le gouvernement réagit en lui imposant une double, puis une triple censure. Puis, le , il l'interdit. Marx est contraint de démissionner avant cette date, mais cela ne sauve pas le journal, qui suspend sa publication en mars 1843.

L'un des principaux articles de Marx dans la "" est celui consacré aux conditions de vie des vignerons de la vallée de la Moselle. Ce reportage, ainsi que l'ensemble de ses activités journalistiques, lui fait prendre conscience de ses insuffisances en matière d'économie politique et le pousse à se lancer dans une étude en profondeur de celle-ci.

En 1843 à Bad Kreuznach, Marx épouse une amie d'enfance, Jenny von Westphalen, avec laquelle il s'était fiancé étudiant. Sa femme est issue de la noblesse rhénane, son frère aîné deviendra ministre de l'Intérieur du royaume de Prusse au cours d'une des périodes les plus réactionnaires que connut ce pays, de 1850 à 1858.

Le couple a eu sept enfants, mais seules trois filles parviendront à l'âge adulte : Jenny Caroline (1844-1883), Laura (1845-1911) et Jenny Julia Eleanor (1855-1898). Laura épouse en 1868 Paul Lafargue, socialiste français qui laisse dans ses "Souvenirs personnels sur Karl Marx" une biographie intimiste du philosophe. Jenny Caroline épouse en 1872 Charles Longuet, personnalité de la Commune de Paris. Eleanor se marie avec un Britannique, Edward Aveling. Les deux premiers gendres de Marx semblent l'avoir beaucoup admiré et s'être inspirés de lui dans leurs engagements, Paul Lafargue fut même avec Jules Guesde un des fondateurs du Parti socialiste de France, parti marxiste qui fusionna plus tard avec le Parti socialiste français de Jean Jaurès et quelques autres partis de moins grande ampleur en formant la SFIO. Charles Longuet est le père de Jean Longuet qui eut un rôle déterminant durant le congrès de Tours de 1920, dans l'opposition à Lénine et à la SFIC, futur PCF. Marx entretint des relations parfois conflictuelles avec ces deux gendres, ainsi qu'avec un prétendant d'Eleanor, Hippolyte Prosper Olivier Lissagaray, ancien communard comme Longuet. Marx écrivit d'ailleurs à Engels dans une lettre datée du 11 novembre 1882 : 

Karl Marx aurait également eu un fils naturel, Frederick Demuth (1851-1929), issu d'une relation avec la bonne de famille, Helene Demuth. Frederick Demuth fut reconnu par Friedrich Engels.

Outre ceux qui sont parvenus à l'âge adulte, Marx a eu trois autres enfants : Edgar (1847-1855), Heinrich Guido (1849-1850) et Franziska (1851-1852). La mort d'Edgar semble avoir été très douloureuse pour le couple de Karl et Jenny Marx.

Ses enfants comme ses amis l’appellent , son surnom préféré qui lui a été donné lors de ses études à Berlin à cause de son teint foncé, de sa barbe et de ses cheveux d'un noir d'ébène mais qui fait aussi référence à sa judéité.

À l'automne 1843, fuyant la censure prussienne, Marx s'installe à Paris afin de publier un journal radical à l'étranger avec Arnold Ruge (1802-1880). Un seul numéro des "Annales franco-allemandes" est édité. La publication s'interrompt du fait des grosses difficultés dans la distribution clandestine du journal en Allemagne et aussi par suite de désaccords entre Marx et Arnold Ruge. Les articles de Marx montrent que celui-ci se positionne déjà comme un révolutionnaire défendant une (même si ) comptant sur les masses et le prolétariat pour changer l'ordre des choses, et non plus sur quelques dirigeants éclairés.

C'est à la même époque que Ludwig Feuerbach rédige ses "Principes de la philosophie de l'avenir". , écrira plus tard Engels, qui ajoute : .

En septembre 1844 à Paris, Marx revoit Friedrich Engels qu'il n'avait fait que croiser auparavant ; c'est le début d'une profonde amitié. Étudiant par lui-même la philosophie, Engels était devenu partisan de Hegel tout en rejetant le soutien que celui-ci avait apporté à l'État prussien. En 1842, il avait quitté Brême pour prendre un poste dans une firme commerciale de Manchester dont son père était l'un des propriétaires. Là, il avait rencontré la misère prolétarienne dans toute son ampleur et en avait étudié systématiquement les conditions ("La condition des classes laborieuses en Angleterre", 1845).

Peu après leur rencontre, Marx et Engels travaillent de concert à leur première œuvre commune, "La Sainte Famille", dans laquelle ils s'attaquent à la philosophie critique de Bruno Bauer dont ils avaient été proches. Vient ensuite "L'Idéologie allemande" (essentiellement rédigée par Marx), principalement axée autour d'une critique très virulente de Max Stirner intitulée « "Saint Max" » et qui occupe près des deux tiers de l'ouvrage. Cet ouvrage défend une conception matérialiste de l'Histoire qui dépassait la conception du matérialisme de Feuerbach. Par une critique sévère de Stirner, Marx et Engels marquent ainsi une rupture non seulement avec Feuerbach, mais également avec Proudhon. Mais l’ouvrage ne trouve pas d’éditeur, et il ne sera publié que près d’un siècle plus tard. Dans les "Thèses sur Feuerbach", court texte retrouvé dans le même manuscrit, Marx écrit (Thèse XI) : .

Le 11 novembre 1843, Marx s'installe 38, rue Vaneau à Paris. Marx et Engels prennent une part active dans la vie alors bouillonnante des groupes révolutionnaires parisiens. Beaucoup d'entre eux étaient particulièrement influencés par les doctrines de Pierre-Joseph Proudhon qui est alors une sorte de conseil juridique d'une entreprise de péniches que d'anciens amis de collège avaient créée à Lyon. Marx avait témoigné une certaine admiration pour ce philosophe, parlant ainsi de l'ouvrage illustre de Proudhon, "Qu'est-ce que la propriété ?" (1840) : « L'ouvrage de Proudhon, "Qu'est-ce que la propriété ?", a, pour l'économie politique moderne, la même importance que pour la politique moderne l'ouvrage de Sieyès "Qu'est-ce que le Tiers-État ?" ». Ils se rencontrent fin 1844 ou début 1845 lors d'un séjour de Proudhon à Paris (25 sept. 1844 - fin février 1845). Marx quitte la France le février 1845, suite à un décret d'expulsion en date du 25 janvier. Dans une lettre du 5 mai 1846, il invite Proudhon à se joindre à un projet d'association internationale d'intellectuels socialistes : . Les réserves émises par Proudhon dans son acceptation font, à juste titre, comprendre à Marx qu'il s'agit d'une fin de non recevoir. En octobre de la même année paraît le "Système des contradictions économiques" ou "Philosophie de la misère." Marx en fait une critique très sévère dans "Misère de la philosophie". L'avant-propos montre le caractère polémique et ironique du style de Marx : .

De son côté, Proudhon jugera ainsi la "Misère de la philosophie" de Marx : ("Carnet", 24 sept. 1847). . Ch. Marx, Molinari, Vidal, "Univers religieux" […] ("Carnet", 20 nov. 1847). Proudhon lira en partie le livre de Marx (jusqu'au chapitre II, § 3) et portera en marge des notes manuscrites. Il prêtera ensuite son exemplaire à deux amis (Crémieux et, peut-être, Grün) qui annoteront également l'ouvrage. À part un Ch. I, § 2, les notes de Proudhon commencent au Ch. II. Les mots de , , , se succèdent. Certaines notes expliquent pourquoi Proudhon qualifie Marx de dans son "Carnet" :  ;  ;  ; (Dans ses "Carnets" Proudhon accuse Vidal de le piller) ;  ;  ; 

Sur la demande insistante du gouvernement prussien, Marx, considéré comme un dangereux révolutionnaire, est chassé de Paris en 1845 par le président du Conseil, Guizot. Il arrive alors à Bruxelles. La maison qu'il occupe au 42, rue d'Orléans, actuellement 50 de la rue Jean d'Ardenne, à Ixelles entre octobre 1846 et février 1848 sert de point de rencontre à tous les opposants politiques. Marx participe à l'Association démocratique de Bruxelles, dont il est élu vice-président.

Au printemps 1847, Marx et Engels rejoignent un groupe politique clandestin, la Ligue des communistes. Ils y prennent une place prépondérante lors de son second congrès à Londres en novembre 1847. À cette occasion, on leur demande de rédiger le "Manifeste de la Ligue", connu sous le nom de "Manifeste du parti communiste", qui paraît en février 1848.

À l'éclatement de la révolution française de février 1848, Marx quitte la Belgique pour revenir à Paris. Avec l'extension de la révolution à l'Allemagne, il part pour Cologne pour y devenir rédacteur en chef de la "Neue Rheinische Zeitung" (la « Nouvelle Gazette rhénane ») publiée du au .

Avec la victoire de la contre-révolution, Marx est poursuivi devant les tribunaux, notamment pour avoir publié dans la "Gazette" une proclamation du révolutionnaire en exil Friedrich Hecker. Il se défend devant les jurés en déclarant : . Il est acquitté le , mais le gouvernement l'expulse le 16 mai de la même année, bien qu'il soit sujet prussien.

Il retourne alors à Paris dont il est de nouveau chassé après la manifestation du . Il part ensuite pour Londres où il résidera le restant de ses jours. Sa sœur, Louise, lui rend visite dans la capitale anglaise en 1853, alors qu'elle est en route avec son mari pour s'installer dans la colonie du Cap.

La vie de Marx en exil est extraordinairement difficile comme en témoigne sa correspondance. Le soutien financier d'Engels, également installé en Angleterre, lui permet de survivre. Malgré ce soutien, Marx et sa famille doivent faire face à une extrême misère : (à Engels, ). L'un de ses enfants, Edgar, meurt de sous-alimentation.

Il écrit alors une série de sept articles, rassemblés sous le titre "Le 18 brumaire de Louis Bonaparte", décrivant les débuts de la Deuxième République française et son évolution vers le coup d'État du 2 décembre 1851 aboutissant au Second Empire. Jusqu’à la fin de l'année 1862, alors qu'il vient d'entamer la rédaction du "Capital", la situation reste critique malgré l'aide d'Engels, lui-même en difficulté financière en raison de la crise américaine, et de son oncle Lion Philips qui lui consent une avance sur héritage. En 1864, sa situation financière s'améliore grâce à l'héritage de sa mère, qui avait toujours refusé de lui verser la part qui lui revenait de celui de son père et ne lui aura fait grâce que de quelques dettes anciennes, mais le train de vie de la famille Marx reste d'un niveau modeste.

Il consacre toutes les années 1850 à rédiger des centaines d'articles « alimentaires » pour des journaux comme le "New York Tribune" tout en se livrant à des recherches approfondies en économie, histoire, politique, etc. Dans le même temps, il reste en correspondance avec les révolutionnaires du continent et rédige des brochures politiques en lien avec l'actualité. Il passe aux yeux des gouvernants prussiens pour le chef d'une organisation de conspirateurs, alors que la Ligue des communistes n'existe plus depuis son auto-dissolution en 1852. Il est en fait isolé. Sa situation économiquement précaire ralentit son travail.

Ce n'est qu'en 1859 qu'il achève et publie la "Contribution à la critique de l'économie politique". Y sont présents tous les éléments essentiels, en particulier "la loi de la valeur", du "Capital". Marx écrit à cette époque : .

En 1859, il sort de son isolement politique pour participer au journal germanophone "Das Volk", en lien avec les regroupements qui s'opèrent dans le mouvement ouvrier allemand et qui vont déboucher sur la constitution par Ferdinand Lassalle du premier véritable parti ouvrier allemand (ancêtre du SPD).

En 1867 Marx publie enfin, après plus de 20 ans de travail, la première partie de son ouvrage "Le Capital". Il continue son travail pour achever les deux tomes suivants mais, malade et manquant de temps, il ne laissera que des brouillons inachevés, qui sont ensuite mis en forme, achevés et publiés par Engels.

En 1864, il rédige l’"Adresse inaugurale" de l"'Association internationale des travailleurs", qui se fonde alors. Cette adresse devient l'âme de cette . Tout l'effort de Marx dans la rédaction de cette inauguration tend à unifier le mouvement ouvrier qui connaît toutes sortes de formes de regroupements se réclamant du socialisme sur des bases diverses et contradictoires (Mazzini en Italie, Proudhon en France, plus tard Michel Bakounine en Suisse, syndicalisme britannique, lassalliens en Allemagne, etc.). C'est pour introduire le congrès de Genève de l'AIT que Marx rédige ce qui deviendra plus tard son livre "Salaire, prix et profits".

La Commune de Paris est écrasée en 1871. Marx rédige un texte qui est adopté par l’Internationale : "La Guerre civile en France". Karl Marx tire la conclusion que le prolétariat ne peut pas se contenter de s'emparer de la machine d'État pour la faire fonctionner à son profit : il devra la détruire de fond en comble. Marx salue la nouvelle démocratie apparue avec la Commune : le principe de l'éligibilité et la révocabilité des responsables à tous les niveaux de la société (exécutif, législatif, judiciaire). Ce texte fait grand bruit, et le nom de l’auteur est alors révélé : Karl Marx acquiert pour la première fois une certaine renommée, y compris au sein du mouvement ouvrier.

Des divergences importantes apparaissent au sein de l'Internationale. En 1872, deux bakouniniens sont exclus, du fait de leur constitution en fraction secrète mais aussi à cause de la dégradation des rapports entre Marx et Bakounine. Une scission affecte alors l'AIT. S’y ajoutant la quasi-disparition du mouvement ouvrier en France du fait de la violente répression de la Commune, l'AIT cesse pratiquement d'exister en Europe (une partie importante des militants de l’Internationale ont préféré suivre les principes fédéralistes prônés notamment par Bakounine). Le Conseil général de l’AIT de Londres est transféré à New York, et une internationale ouvrière fédéraliste se constitue la même année.

La santé de Marx est minée par son travail politique inlassable d'organisation de l'Internationale et la rédaction encore plus épuisante de son œuvre. Il laisse pour l’essentiel à Engels le soin de suivre les développements du SPD, même si en 1875 Marx écrit une critique très sévère du programme de Gotha du SPD. Karl Marx se consacre ensuite essentiellement à l'achèvement du "Capital", pour lequel il collecte une masse considérable de nouveaux matériaux et, en plus des langues vivantes qu'il maîtrisait déjà (français, anglais, italien et allemand), apprend le russe. Toutefois, sa santé déclinante l'empêche d'achever les deux derniers volumes du "Capital". Engels se chargera par la suite de rassembler et mettre en forme ses notes afin de publier des matériaux partiels.

Les idées de Marx gagnent en notoriété et en influence dans les milieux socialistes, grâce entre autres au travail de vulgarisation accompli par Paul Lafargue, gendre de Marx. Mais Marx lui-même est peu convaincu par le messianisme révolutionnaire et utopiste des disciples du marxisme, notamment français ; commentant aussi bien les travaux de son gendre que les discours de Jules Guesde, il écrit : .

Jenny, sa femme qui l'avait fidèlement soutenu, décède le . En 1882, épuisé par la maladie, Marx se rend à Alger de février à mai, afin de se soigner. Sa toux tenace l'empêche de visiter le pays. C'est à ce moment-là qu'il se fait photographier pour la dernière fois. Le docteur Stéphan qui le soigne ne parvient pas à enrayer sa maladie ; il se plaint de la solitude et écrit à Engels : . Il rembarque le 2 mai et séjourne brièvement à Monaco, afin de remonter à Argenteuil, près de Paris, où demeure sa fille Jenny Longuet.

Quelques mois plus tard, Marx s'éteint paisiblement dans son fauteuil le . Il est enterré près de sa femme dans le cimetière de Highgate à Londres. Les deux époux avaient rompu avec leur milieu social et restèrent fidèles, dans l'adversité comme dans la misère, à un idéal d'émancipation humaine.

Ironie du sort quand on connaît sa critique de l'argent, depuis l'été 2015, la visite de sa tombe est payante et coûte de quatre à six livres sterling.

S'inspirant du matérialisme antique (sa thèse d'admission au doctorat portait sur l'atomisme de Démocrite et Épicure et sa théorie du clinamen, qui lui permettait de préserver la liberté de la volonté humaine au sein d'une théorie physique déterministe) et se voulant une critique de l'économie politique, la pensée de Karl Marx est résolument matérialiste : , écrit-il ainsi dans le "Manifeste communiste", rédigé peu avant les Révolutions de 1848. Comme Marx le remarque dans les "Thèses sur Feuerbach", . C'est en cela que le marxisme peut être vu comme un dépassement de la philosophie.

Marx veut remettre , et estime donc que c’est la matière qui est première, et non l’esprit, c'est-à-dire que « le mouvement de la pensée n’est que le reflet du mouvement réel, transporté et transposé dans le cerveau de l’Homme » ("Le Capital"). Il rompt ainsi avec l’idéalisme de la "Phénoménologie de l'Esprit" de Hegel, ainsi qu'avec l'Idéalisme allemand, pour lequel les objets sont de simples copies de « l’Idée » et pour lequel le « mouvement réel » de l'Esprit absolu dans l'Histoire (Hegel) ne prend conscience de lui-même que dans la conscience du philosophe.

Le matérialisme selon Marx ne s'arrête pas à la dimension purement physique de l'Homme, comme c'était le cas de ses prédécesseurs. Marx insiste sur le « matérialisme social » qui fait ("réalise") l'Homme, c’est-à-dire toutes les relations sociales qui le construisent (la famille, les rapports hiérarchiques, la réalisation (objet) de son travail au sein de la société et les formulations qu'il en donne, etc.).

Selon Jacques Ellul, il n'existe pas pour Marx une « nature humaine », mais une , qui varie selon les époques. Marx parle de .

Cependant, Marx reproche à l’ancien matérialisme le fait qu’il conçoive l’être humain comme une abstraction, et non comme le produit de l’ensemble de tous ses rapports sociaux, le fait qu’il ne serait pas historique, etc., ce qu’il qualifie de matérialisme « vulgaire » par son aspect mécaniste.

La dialectique hégélienne, essentiellement formulée sur une base idéaliste, implique l’idée selon laquelle le monde ne peut être considéré que comme (Engels), , une succession de processus complexes où les choses (y compris les reflets qui s'y impriment dans le cerveau de celui qui pense) sont en constant développement alternant entre l'être et le devenir quant à "une finalité" (Dieu). Selon Hegel, ce développement est une évolution discontinue, faite de bonds, de catastrophes, mue d'impulsions internes, de contradictions, etc., allant vers une finalité "prédéterminée" : l'Absolu.

Marx reprend la logique hégélienne et en retient la notion de l'aliénation, dont il tire une théorie concrète, fondement de ce qui a été appelé matérialisme dialectique (le terme n'est pas de Marx lui-même, qui ne l'a jamais employé, mais il a été utilisé par certains marxistes pour désigner la redéfinition de la dialectique opérée selon eux par Marx et Engels). Chez Marx, la dialectique est une méthode permettant d'analyser les relations contradictoires entre les forces sociales dans une période historique donnée, et en déduire un mouvement historique. Marx, pour étudier une réalité objective déterminée, analyse les aspects et éléments contradictoires de cette réalité, sans négliger le fait que la réalité doit être analysée dans son unité, c'est-à-dire dans son mouvement. La recherche doit s'approprier son objet en analysant et découvrant les relations internes des éléments qui le composent. La méthode marxiste, s'inspirant de Hegel, affirme que l'analyse suffisamment approfondie de toute réalité atteint des éléments contradictoires, et insiste sur le fait que la réalité à atteindre par analyse est une réalité en mouvement. Chaque objet étudié ayant son originalité, le savant doit se proposer d'atteindre la loi propre de cet objet, à savoir son devenir. La « dialectique marxiste » diffère de la dialectique hégélienne en ce que sa méthode se défie de l'abstraction et affirme que l'idée générale ne dispense pas de saisir en lui-même chaque objet. Les éléments d'un objet d'étude, par exemple un pays donné, sont analysés en tenant compte de leur réalité concrète, à savoir, s'agissant d'un pays, ses groupes concrets de populations et leurs rapports de classe concrets (capital, salariat). L'analyse rencontre partout des éléments contradictoires et indissociables et doit les distinguer sans perdre leur lien. Pour Marx, l'exposition du tout concret à partir de ses éléments est la seule méthode scientifique : la méthode dialectique analyse chaque élément dans ses conditions concrètes qui, prises dans le mouvement réel, acquièrent un caractère historique. L'analyse vise alors à exposer et à comprendre la totalité que constitue la structure économique et sociale, l'effort intellectuel se basant sur la connaissance de cette totalité concrète et non sur des conceptions abstraites.

Ce que cherche Marx à travers le matérialisme historique, c'est de trouver pourquoi des changements ou des révolutions dans les arts, les sciences, la philosophie, le juridique, etc. surviennent à des moments différents selon les pays et pourquoi ils sont différents selon les époques.

Pour Marx, les êtres humains ne peuvent survivre sans organisation. Or, ces dernières sont en grande partie déterminées par les modes de production qui ne peuvent être changés graduellement. Les modes de production à leur tour déterminent les relations de classe. . Ainsi, le travail, par les améliorations techniques que son évolution implique, conduit à transformer les structures de la société. Qu'on pense seulement à la différence entre le travail d'un paysan du siècle dernier et un informaticien, ou bien, pour reprendre un exemple de Karl Marx, extrait de "Misère de la philosophie" :
Malgré tout, le déterminisme marxien n'est que partiel. En effet, si l’ (Contribution à la Critique de l’Économie Politique), néanmoins l'être humain a son libre arbitre, ses passions , ses intérêts. Toutefois, pour Ernest Mandel, les intérêts de classe sont prédominants sur les intérêts ou les passions individuelles. Il note : . La liberté humaine est donc limitée par la lutte des classes. En fait pour Marx la liberté c'est surtout d'avoir du temps de loisir disponible pour développer ses talents, ses potentialités ce que peut faire la classe gouvernante. Le but pour lui est donc de libérer la classe ouvrière en développant assez les forces productives pour limiter le temps de travail des prolétaires et arriver à la société sans classe.

L'État pour Marx est , c'est un instrument de maintien d'une certaine structure sociale et de classes données. L'émergence de la société sans classe permet de s'en passer et d'arriver à une société d'auto-administration. Toutefois avant d'atteindre cette phase ultime, il faut passer pour Marx par la dictature du prolétariat qu'il voit comme un État qui cherche à assurer sa propre dissolution.

Au cours de l'Histoire, les progrès techniques permettent d'accroître la production. Après un certain temps, un conflit naît au sein de la société, où les rapports sociaux changent : la classe sociale qui détient les nouvelles techniques prend de l'importance sur la classe sociale dominante, fondée sur l'ancien modèle de production. Exemple : du système féodal où le suzerain possédait les terres et ceux qui la travaillaient, et le rôle du clergé sur la société, on est passé à une société dominée par la bourgeoisie au cours de la révolution industrielle du . Ainsi, selon Marx, est née une nouvelle forme de l'économie : le capitalisme, qui suppose une nouvelle forme de propriété privée, garantie par une institution juridique nouvelle.

Marx, dans son œuvre, a résumé l'histoire humaine en 4 étapes (la cinquième à venir étant, selon lui, la période socialiste), correspondant à des techniques et des modes de production différents :

Marx pense que le sens de l'Histoire est à terme inéluctable, et qu'elle aboutit toujours à cette troisième étape, critique, de restructuration sociale. Les rapports de production finissent tôt ou tard par être contestés, par ne plus être adaptés au développement, par être insupportables pour une part importante de la population : les structures de la société, qui paraissaient immuables, doivent alors changer.

L’idée que la société n’est pas homogène, mais que ses membres ont des aspirations divergentes, et parfois contradictoires, n’est pas nouvelle. Mais Marx a pour la première fois avancé l’idée que les oppositions entre ces différentes classes sociales constituent le fil conducteur qui permet de comprendre la succession des sociétés et des périodes historiques. La théorie de la lutte des classes avance qu'exceptées les communautés primitives, toutes les sociétés sont composées de classes (homme libre et esclave, patricien et plébéien, seigneur et serf, patrons et ouvriers) en opposition constante et que cette opposition est le moteur de l’histoire.

Marx étudie la manière dont la bourgeoisie moderne est née au sein même de la société féodale, a grandi jusqu’à représenter une force sociale qui est entrée en conflit avec l’ancienne classe dominante des nobles. Après avoir renversé le régime féodal, la bourgeoisie a bouleversé le monde, modifié les rapports sociaux, les valeurs, l’idéologie dominante, et développé les sciences et les techniques à un point inimaginable auparavant.

Toutefois, selon Marx, elle a également fait surgir une nouvelle classe sociale, le prolétariat moderne, c'est-à-dire la classe de tous ceux qui n’ont que leur force de travail à vendre, et dont les intérêts entrent directement en conflit avec ceux de la bourgeoisie. Marx estime que de toutes les classes existantes dans la société moderne, seule la classe ouvrière est réellement capable de transformer la société.

Le capitalisme naît du développement de l'artisanat dans le régime féodal et de l'apparition de la classe bourgeoise. Le développement de la technique demande de plus en plus à l'artisan de faire appel à de nouveaux travailleurs, qui sont alors sous l'égide du seigneur (les serfs, paysans).

Le régime capitaliste se caractérise ensuite par le développement continu des techniques, qui permettent de produire de plus en plus. Les prix diminuent alors et font disparaître les entreprises les moins rentables, augmentant la classe prolétarienne. Cette classe a de plus en plus de mal à acheter les marchandises produites par le système, qui entre en contradiction. Une autre contradiction est la concentration du capital dans un petit nombre de mains, situation qui ne peut durer face à l'organisation de la classe prolétarienne.

Marx ne s’est pas contenté de dénoncer les méfaits du capitalisme naissant de l’époque (comme l’extrême misère des ouvriers anglais d’alors), mais il a cherché à analyser les conditions qui ont permis la naissance du capitalisme, et les lois qui guident la production de marchandises. Pour cela, il s'est appuyé sur les travaux des économistes de son temps, et reconnaissait la valeur de certaines de leurs observations, mais les trouvait incomplètes.

Il reprochait à l'économie politique d'être formée comme une science exacte, qui avait éliminé l'Homme de ses paramètres, et l'avait réduit à ses qualités de producteurs et consommateurs. Un autre reproche était le manque de questionnement de ses fondements :

Dans la conception philosophique de Marx, le travail est le prolongement de l'Homme, c'est une partie de son existence individuelle. Il aboutit à une reconnaissance par les autres Hommes, et crée une solidarité entre individus. Il lie intimement le travailleur et celui qui bénéficie de ce travail. C'est aussi un moyen de subsistance, directe dans les systèmes pré-capitalistes (sociétés paysannes), indirecte dans le système capitaliste. Si Marx a cautionné cette idée hégélienne dans sa jeunesse, sur la fin de sa vie on peut douter qu'il ait gardé une telle définition (du moins après les manuscrits de 1844 et "L'Idéologie allemande"). Ainsi dans sa critique du programme de Gotha et dans son texte polémique contre le protectionnisme éducateur de List, Marx écrit : .

Dans la société capitaliste, le travail a changé de nature : il est devenu aliénant, il subordonne l'individu aux moyens de production privée. Il est dépourvu de ses valeurs humaines. Il n'a d'autres finalités qu'une production de marchandises vénales, destinées à des échanges économiques. En effet, il fait remarquer que l'ouvrier à la chaîne, ne s'identifie pas ou peu à son travail, mais plutôt à ce qu'il va faire de son salaire. Le producteur devient un anonyme aux yeux de l'acheteur. Le travail devient alors abstrait. Ce travail est abstrait justement car il se fonde sur une « moyenne » de productivité imposée par la composition organique du capital. Comme le dit Marx dans le premier chapitre du "Capital", si c'est bien le temps de travail nécessaire qui détermine la valeur d'un objet, il ne suffit pas de produire en dix heures un objet qui en moyenne en prend cinq pour pouvoir le vendre deux fois plus cher, c'est le temps socialement compris qui comptera pour déterminer la valeur. Phénomène qui explique la tendance à la concentration du capital car ceux ne pouvant s'aligner sur les taux de productivité ne peuvent suivre et sont donc contraints à la faillite).

Marx différencie la propriété des objets (propriété objective) qui existent indépendamment du travail humain (une terre, un arbre, un cheval), de la propriété subjective induite par le système capitaliste.

La propriété subjective existe lorsqu'intervient le travail humain dans la production d'un objet. Une marchandise contient du travail humain. La propriété privée subjective (subjective, parce qu'elle contient l'idée qu'un sujet l'a produite) est une appropriation du travail humain. Posséder une marchandise (une maison, une entreprise, une machine), c'est détenir du travail humain, donc cela crée une domination de l'Homme par lui-même. N'oublions pas que le travail est, chez Marx, une partie et un prolongement de l'Homme.

Ces concepts sont intimement liés chez Marx. La consommation, chez Marx, n'a pas le sens commun des économistes. Elle regroupe à la fois la consommation d'objets (matières premières, produits manufacturés, etc.) et la consommation du travail de l'Homme. L'Homme est toujours présent dans la réflexion de Marx, cela fait partie de son originalité par rapport aux économistes classiques. La production, c'est notamment la consommation du travail. Réciproquement, l'acte de consommer (au sens commun) un objet, c'est l'étape finale de la production. Il y a une identité entre les deux notions.

Dans la société capitaliste, il n'y a plus rapport direct entre le producteur d'un bien, et celui qui va le consommer. La distribution, fonction intermédiaire, dépend de la structure sociale (rapports de domination sociale, salaires, etc.).

Dans sa notion de distribution, Marx, encore une fois, inclut aussi la distribution sociale, à comprendre au sens de proportions de personnes dans les différentes classes sociales.

L'échange final du bien, qui s'opère avec de l'argent dans la société capitaliste, finalise le cycle.

Le capitalisme nécessite la libération du travail. Qu'est-ce qu'un travailleur « libre » selon Marx ? C'est un travailleur disponible pour être utilisé comme moyen de production, à la différence des sociétés paysannes, où les individus étaient la propriété du seigneur, et donc indisponible pour des activités industrielles. Une personne « non libre » dans le sens de Marx sera par exemple une femme au foyer, ou une personne âgée retraitée et étant empêchée de travailler, ou encore un mineur que des lois protègent. Les institutions (par exemple les États, par les lois) peuvent jouer un rôle empêchant ou diminuant cette « libération ». Les coutumes et les religions aussi (refus du travail des femmes, par exemple).

Une autre condition pour que le système capitaliste existe, c'est que les moyens de la production soient également « libérés », c’est-à-dire disponible pour les capitalistes. Il ne faut pas qu'ils soient détenus de façon constante par des personnes. Les personnes ne doivent pas être intimement liées à ces moyens de production, comme pouvaient l'être les serfs vis-à-vis de la terre du seigneur au Moyen Âge, ou les esclaves dans l'Antiquité ou dans les empires coloniaux. Un esclave est directement un objet pour la production. Dans le même ordre d'idées, pour être qualifié de prolétaire il ne faut pas que le travailleur possède ses instruments de travail (sinon, il pourrait subvenir lui-même à ses besoins).

Lorsque ces conditions sont réunies, les Hommes sont disponibles, le travail peut alors être acheté sous la forme du salariat.

Le capital regroupe plusieurs formes : le capital-objet (les machines, les produits), le capital-travail (les Hommes à qui on peut acheter le travail), le capital-argent.

La formation des richesses avait plusieurs origines avant Marx : les physiocrates y voyaient la productivité de la terre (cultures, élevages), les socialistes de l'époque y voyaient une exploitation des ouvriers par les patrons, et les libéraux y voyaient un prélèvement sur le prix de ventes des marchandises.

Marx nie tout cela. L'enrichissement vient de la création de la richesse. Cette création de la richesse vient du travail (la valeur-travail). L'employé vend sa force de travail à un patron qui utilise celle-ci à sa guise. Le prix de la force de travail est le salaire. Le travail permet de dégager une valeur supplémentaire, qui sera récupérée par le patron, c'est la plus-value. Ce n'est pas à proprement parler un vol : le salaire sert à couvrir les moyens de subsistance de l'employé, pour lui permettre de régénérer sa force de travail.

Ce mécanisme de production de capital va se concentrer par la circulation du capital : les patrons dans leur ensemble dégagent un bénéfice, peuvent réinvestir et bénéficient ainsi d'une croissance infinie en capital. Cependant, certains feront faillite, réduisant le nombre de capitalistes. Ils rejoindront la classe ouvrière et permettront d'augmenter la force de travail employable pour les capitalistes. Ce phénomène de concentration du capital est constant, et a nécessairement une limite, au-delà de laquelle la société capitaliste disparaîtra.

Le prolétariat selon Marx est la classe des personnes qui travaillent pour un capitaliste. On dirait aujourd'hui que cela représente l'ensemble des salariés. Un cadre en informatique est un « prolétaire » selon Marx, un employé d'une boulangerie est également un prolétaire. Selon l'analyse marxiste, le capital lié à l'activité des boulangeries, comme tout capital, se concentre. On pourrait ainsi estimer que l'apparition des réseaux de distribution de pains modernes (comme l'entreprise Banette) fait partie du sens de l'Histoire. Les anciens boulangers propriétaires disparaissent, et rejoignent le prolétariat, alors que le capital se concentre.

La théorie de la valeur consiste en l'idée que la valeur d'une marchandise vient du temps de travail socialement nécessaire pour la produire et l'amener au marché.

La plus-value correspond à la part de « surtravail » effectuée par le travail vivant, soit la quantité de travail supplémentaire effectuée par le travail vivant et ne recevant pas son équivalent en termes de salaire. Cette plus-value produite par le travail vivant est ensuite traduite en prix à travers sa réalisation dans l'échange marchand et correspond alors au concept de profit. Là où la plus-value doit être pensée en tant que valeur abstraite, le profit constitue son expression phénoménale à travers le mécanisme des prix. Mais ces deux concepts ne doivent pas pour autant être confondus puisqu'il peut arriver que, dépendamment du jeu de l'offre et de la demande sur le marché, les profits exprimés en prix ne correspondent pas nécessairement à la plus-value produite par le travail.

La monnaie (à comprendre au sens de pièces de monnaie) est la forme objective de l'argent.

Dans la pensée de Marx, l'argent en tant que concept occupe une place importante.

D'abord, l'argent apparaît lors des échanges (achat-vente de marchandises). Ensuite, il est la substance de la richesse. La richesse et l'argent sont avant tout des abstractions. La monnaie, elle, est sa forme objective.

Chez Marx, tout est marchandise en système capitaliste (objet manufacturé, comme travail humain). Dans le système capitaliste, toute marchandise a donc un équivalent-argent.

Or, dans la conception philosophique de Marx, le travail est intimement lié à l'Homme. Le travail est une caractéristique essentielle de l'Homme, et est ce qui forme les relations entre eux. Le consommateur est lié au producteur, et vice-versa.

Comme ce travail peut s'acheter avec l'argent (abstraction), dans le système capitaliste, les relations entre les Hommes tendent à être subordonnées aux relations basées sur l'argent. L'argent détruit la réalité de l'Homme en détruisant les médiations entre eux. C'est l'argent qui devient la médiation entre les Hommes (par le salaire, et les échanges économiques).

Marx pense même que les relations entre les serfs et les seigneurs au Moyen Âge étaient de ce point de vue beaucoup plus "humaines" que celle entre les ouvriers et les patrons de l'ère industrielle.

L'argent comporte également plusieurs contradictions, dont en voici une importante : l'argent n'est au début qu'un moyen d'échange de marchandises. Mais, dans le système capitaliste, il va devenir le but du capitaliste.

L'Homme a une dépendance vis-à-vis de l'argent. L'Homme ne peut rien, par contre l'argent peut tout : il est le pouvoir, il est l'équivalent des marchandises. L'Homme a donc inventé une abstraction qu'il vénère et qui le surpasse.

L'argent a également un effet sur la moralité des Hommes. Comme on peut échanger toute marchandise contre toute autre (dont le travail humain, c’est-à-dire l'Homme), la forme ultime du capitalisme est la prostitution généralisée de l'Homme.

Chez Marx, la monnaie permet de tromper le salarié. L'esclave est payé par les subsistances vitales que lui procure son maître, tandis que le salarié croit obtenir un salaire monétaire qui lui offre une liberté de choix dans sa consommation. Mais cette liberté n'est qu'une illusion qui vient tromper le salarié sur sa situation réelle : en fait son salaire monétaire ne lui permet que d'acheter le minimum vital que le maître procurait directement à l'esclave. Cette illusion est l'apport essentiel de la monnaie dans les rapports sociaux du système de production capitaliste.

Pour Marx, les idéologies sont produites par les Hommes, mais ce sont des mystifications, des illusions collectives, que les Hommes se font d'eux-mêmes, car elles sont déterminées par les rapports que l'Homme a avec le monde, elles sont déterminées par le contexte social dans lequel vit l'Homme. Si le théoricien ne fait pas un travail d'auto-analyse, il ne pourra pas construire des idées et des concepts pertinents, décrivant véritablement la réalité. Ce sont des formes de fausse conscience.

Pourquoi les Hommes construisent-ils des idéologies, selon Marx ? Essentiellement pour se justifier, et se donner bonne conscience.

Par exemple, un monde où la classe dominante exploite la classe dominée va produire une idéologie qui va non pas mettre en évidence l'exploitation, mais bien au contraire justifier les rapports entre les classes (avec des principes, des institutions, des lois, des coutumes, etc., qui sont des produits de l'idéologie de justification des inégalités de classe).

Si l'idéologie est surtout produite par la classe dominante, il est nécessaire que l'ensemble des Hommes croient en l'idéologie ainsi mise en place, aussi bien la classe dominante que la dominée. Elle doit être universellement admise. La classe dominée ne doit pas voir le produit de l'idéologie comme une construction humaine, mais plutôt comme une évidence naturelle.

C’est ainsi que Marx considère que (Manifeste du parti communiste). Contre les idéologies aliénantes issues des classes dominantes au fil du temps, Marx estime que l’Humanité doit instaurer une société sans division en classes sociales, empêchant ainsi la domination d’une classe dominante.

Marx critique vivement le rôle de la religion et les aspects philosophiques et sociaux de cette dernière. Marx est matérialiste et s’en revendique, il est ainsi athée, sans faire de l'athéisme une nouvelle « religion ».

Marx s'intéresse surtout à la religion à cause du rôle qu'elle exerce sur la société. Pour Marx, la religion est une structure créée par la société, et qui évolue selon ses besoins. La religion et les Hommes qui la font (prêtres, évêques, etc.) sont des alliés objectifs de la classe dominante (et, pour ce qui est du haut clergé, en est directement membre).

Il analyse l'évolution de la religion en Europe : d'abord, il y avait des structures religieuses païennes, qui permettaient aux Hommes de justifier des phénomènes climatiques qu'ils ne comprenaient pas. Les dieux étaient des dieux locaux, chaque peuple avait les siens, ils étaient souvent liés à des phénomènes de la nature.

Ensuite, l'expansion romaine à travers l'Europe et le bassin méditerranéen a fait naître une conscience géographique plus étendue, et les religions locales ont disparu au profit du christianisme. Pendant le Moyen Âge, la transition au catholicisme a structuré l'Église : des hiérarchies structurées sont progressivement apparues (Pape, évêques, curés), avec qui le pouvoir (les rois et la noblesse) a dialogué de façon constante pour le partage du pouvoir sur les peuples. La dîme, prélevée au peuple au profit de l'Église, a été instaurée. L'éducation des enfants était prise en charge directement par l'Église.

La naissance du capitalisme a fait apparaître une volonté de réforme du catholicisme à travers le protestantisme et le . Ce terme a valu des critiques à Marx et un débat sur son éventuel antisémitisme, bien que Marx soit juif d’origine, mais athée. Dans les faits, Marx s'oppose au judaïsme en tant que religion, car il est une oppression comme selon lui toutes les autres religions. Il rappelle également que la plupart des juifs étaient pauvres et exploités. Il critique donc le judaïsme, comme d'une manière générale le christianisme, pour avoir aidé le système capitaliste à apparaître. En revanche il milite et pétitionne auprès de son Assemblée provinciale pour obtenir l'émancipation politique des juifs sans que ceux-ci aient à renier leur religion.

Selon Marx, la religion permet de justifier les inégalités sociales, et permet au prolétariat de mieux les supporter. Elle laisse le peuple dans l'illusion que sa condition n'est pas si terrible, en lui donnant des exemples de morales religieuses, des bienfaits de la souffrance, etc.

Marx pense que si on élimine la religion, la classe ouvrière prendra conscience de sa misère, la refusera, et permettra la naissance d'une société socialiste.

Ce que dénonce avant tout Marx, c'est l’effet anesthésiant, aliénant et mystifiant des religions sur la mentalité collective. De là son expression célèbre : 

Marx pense que la racine de la croyance religieuse se trouve dans les conditions de vie misérables de la plus grande partie de la population. C'est la raison pour laquelle il ne pense pas que la lutte contre la religion doit se trouver au centre du militantisme communiste. Après avoir défini la religion comme , il poursuit : 

Dans le "Manifeste communiste", Marx considère que la première nécessité pour le prolétariat est (chapitre 2).

La démocratie réelle est selon Marx un des buts et des moyens essentiels de l’action du prolétariat. Cela est illustré par sa célèbre formule de 1864 : .

L'aliénation a des sens différents selon ses applications.

Le travail est dans le système capitaliste une simple marchandise vendue. Le travail tue l'Homme en tuant son temps de vie.

L'argent, dans la société capitaliste, est le seul signe de puissance, et le seul besoin. Les Hommes luttent pour l'argent. Il est l'objet de toutes les convoitises. Or l'argent est une pure abstraction. L'argent coupe de la réalité du monde, et en même temps devient l'unique vecteur pour pouvoir agir sur lui. La société de l’argent est une aliénation surtout pour ceux à qui il est pris, mais aussi pour ceux qui le prennent.

L'aliénation morale est l'aliénation par l'État et la religion. L'État entretient le mythe des « citoyens » égaux (alors que les inégalités demeurent), et la religion crée une morale artificielle qui sert les intérêts de certains êtres humains (en général : de sexe masculin, riches, âgés, etc.).

Pour sortir de ce système, Marx préconise la destruction des objets de l'aliénation, c'est-à-dire la destruction de l'État, de la religion, de l'argent, de la marchandisation du travail.

Cette destruction est en partie idéologique : aucune violence n'est à craindre. Il suffit d'une prise de conscience. Un jour, les Hommes peuvent décider d'arrêter de croire à l'État, ils peuvent décider de ne plus croire à la religion, ils peuvent décider que la monnaie n'a plus de valeur et refuser de s'en servir comme moyen d'échange, et ils peuvent décider d'arrêter de travailler en tant que marchandise. Cela ne signifie pas l'arrêt du travail, bien sûr, mais l'arrêt de l'idée qu'il faut le faire contre un salaire. À cette prise de conscience doit s’associer un changement radical des institutions et structures de la société, pour dépasser le stade capitaliste et créer le communisme.

Chez Marx, les prolétaires ne sont pas que les pauvres. Les prolétaires sont le résultat de la dynamique du système capitaliste, et d'un mouvement historique irréversible.

La prolétarisation est la double conjonction de la transformation de l'Homme en prolétaire et de l'augmentation de leur nombre.

Qu'est-ce qu'un prolétaire ? C'est un individu qui ne possède que sa seule force de travail, et pas les moyens de la production. Il est par conséquent obligé de vendre sa force de travail au capitaliste sous forme de salaire pour subvenir à ses besoins. Tout travailleur salarié est un prolétaire.

Marx avait très bien anticipé le développement du taylorisme à ce sujet. La division du travail est en effet un mouvement constant du capitalisme. Il est dû à l'amélioration des techniques et notamment des machines, qui ont fait apparaître les ouvriers spécialisés. Il est également la conséquence d'une recherche de rentabilité accrue.

Chaque salarié du système capitaliste ne devient capable que d'assurer une infime partie de la production. Son travail n'a pas de sens en lui-même. Il n'est qu'un rouage d'un immense mécanisme. Il ne peut plus avoir de vie individuelle.

De plus, du fait de cette division continue du travail, et du développement des techniques, le chômage est appelé à se développer. C'est l'« armée de réserve », et celle-ci, par sa simple présence, exerce une pression sur les salariés, qui ont peur de se retrouver au chômage. Le chômage empêche les travailleurs de se révolter. Les salaires ont donc une tendance continue à la baisse à long terme relativement aux possibilités qu'offre l'époque dans laquelle vivent les travailleurs, et la concentration du capital est aussi inéluctable.

La prolétarisation est donc la .

Le prolétaire possède également d'autres caractéristiques, telle que l'absence de propriété.

Comment sortir de cette misère (parfois matérielle, mais aussi surtout psychologique) ? Il faut, selon Marx, que la société se libère du capitalisme par la révolution. Cette révolution doit libérer le prolétariat, mais aussi toutes les classes sociales, notamment les classes dominantes, qui sont également aliénées (par l'argent notamment, comme on l'a vu plus haut). C'est donc une révolution pour toutes les classes visant à abolir les classes elles-mêmes (société sans classes). Cette révolution doit être globale.

Plusieurs livres de Marx sont publiés en ligne, ainsi que des listes de ses livres. Plusieurs volumes de correspondances ont également été publiés après sa mort.

Il n'existe pour le moment aucune édition exhaustive des écrits de Karl Marx. L'édition la plus complète en allemand est la « MEGA » (Marx-Engels-Gesamtausgabe), initiée par David Riazanov. L'édition la plus complète en français est constituée des quatre tomes publiés dans la "Bibliothèque de la Pléiade" par Maximilien Rubel.













</doc>
<doc id="15767" url="https://fr.wikipedia.org/wiki?curid=15767" title="Science">
Science

La est l'ensemble des connaissances et études d'une valeur universelle, caractérisées par un objet et une méthode fondés sur des observations objectives vérifiables et des raisonnements rigoureux. 

La volonté de la communauté scientifique, garante de l'actualisation du contenu des sciences, est de produire des « connaissances scientifiques » à partir de méthodes d'investigation rigoureuses, vérifiables et reproductibles. Quant aux « méthodes scientifiques » et aux « valeurs scientifiques », elles sont à la fois le produit et l'outil de production de ces connaissances et se caractérisent par leur but, qui consiste à permettre de comprendre et d'expliquer le monde et ses phénomènes de la manière la plus élémentaire possible — c'est-à-dire de produire des connaissances se rapprochant le plus possible des faits observables. Non dogmatique, la science est ouverte à la critique et les connaissances scientifiques, ainsi que les méthodes, sont toujours ouvertes à la révision. De plus, les sciences ont pour but de comprendre les phénomènes, et d'en tirer des prévisions justes et des applications fonctionnelles ; leurs résultats sont sans cesse confrontés à la réalité. Ces connaissances sont à la base de nombreux développements techniques ayant de forts impacts sur la société.

La science est .

Dans un passage du "Banquet", Platon distingue la droite opinion ("orthos logos") de la science ou de la connaissance ("Épistémé"). Synonyme de l’"épistémé" en Grèce antique, c'est selon les "Définitions" du pseudo-Platon, une .

La science est historiquement liée à la philosophie. Dominique Lecourt écrit ainsi qu'il existe . Dominique Lecourt explique ainsi que les premiers philosophes ont été amenés à faire de la science (sans que les deux soient confondues). La théorie de la connaissance en Science est portée par l'épistémologie.

L'histoire de la Science est nécessaire pour comprendre l'évolution de son contenu, de sa pratique.

La science se compose d'un ensemble de disciplines particulières dont chacune porte sur un domaine particulier du savoir scientifique. Il s'agit par exemple des mathématiques, de la chimie, de la physique, de la biologie, de la mécanique, de l'optique, de la pharmacie, de l'astronomie, de l'archéologie, de l'économie, de la sociologie, etc. Cette catégorisation n'est ni fixe, ni unique, et les disciplines scientifiques peuvent elles-mêmes être découpées en sous-disciplines, également de manière plus ou moins conventionnelle. Chacune de ces disciplines constitue une science particulière.

L'épistémologie a introduit le concept de « science spéciale », c'est la science « porte drapeau » parce qu'elle porte les problématiques liées à un type de Sciences.

L'étymologie de vient du latin, (« connaissance »), lui-même du verbe (« savoir ») qui désigne à l'origine la faculté mentale propre à la connaissance. Cette acception se retrouve par exemple dans l'expression de François Rabelais : . Il s'agissait ainsi d'une notion philosophique (la connaissance pure, au sens de « savoir »), qui devint ensuite une notion religieuse, sous l'influence du christianisme. La concernait alors la connaissance des canons religieux, de l'exégèse et des écritures, paraphrase pour la théologie, première science instituée.

La racine se retrouve dans d'autres termes tels la (étymologiquement, ), la (), l' (), par exemple.

Le mot science est un polysème, recouvrant principalement trois acceptions :

D'après Michel Blay, la science est .

Cette définition permet de distinguer les trois types de science :

Néanmoins, leurs limites sont floues ; en d'autres termes il n'existe pas de catégorisation systématique des types de science, ce qui constitue par ailleurs l'un des questionnements de l'épistémologie. Dominique Pestre explique ainsi que .

L'acquisition de connaissances reconnues comme scientifiques passent par une suite d'étapes. Selon Francis Bacon, la séquence de ces étapes peut être résumée comme suit 

Pour Charles Sanders Peirce (1839–1914), qui a repris d'Aristote l'opération logique d'abduction, la découverte scientifique procède dans un ordre différent :

Les méthodes scientifiques permettent de procéder à des expérimentations rigoureuses, reconnues comme telles par la communauté de scientifiques. Les données recueillies permettent une théorisation, la théorisation permet de faire des prévisions qui doivent ensuite être vérifiées par l'expérimentation et l'observation. Une théorie est rejetée lorsque ces prévisions ne cadrent pas à l'expérimentation. Le chercheur ayant fait ces vérifications doit, pour que la connaissance scientifique progresse, faire connaître ces travaux aux autres scientifiques qui valideront ou non son travail au cours d'une procédure d'évaluation.

Le mot , dans son sens strict, s'oppose à l'opinion ( en grec), assertion par nature arbitraire. Néanmoins le rapport entre l'opinion d'une part et la science d'autre part n'est pas aussi systématique ; l'historien des sciences Pierre Duhem pense en effet que la science s'ancre dans le sens commun, qu'elle doit .

Le discours scientifique s'oppose à la superstition et à l'obscurantisme. Cependant, l'opinion peut se transformer en un objet de science, voire en une discipline scientifique à part. La sociologie des sciences analyse notamment cette articulation entre science et opinion. 
Dans le langage commun, la science s'oppose à la croyance, par extension les sciences sont souvent considérées comme contraires aux religions. Cette considération est toutefois souvent plus nuancée tant par des scientifiques que des religieux.

L’idée même d’une production de connaissance est problématique : nombre de domaines reconnus comme scientifiques n’ont pas pour objet la production de connaissances, mais celle d’instruments, de machines, de dispositifs techniques. Terry Shinn a ainsi proposé la notion de . Ses travaux avec Bernward Joerges à propos de l’ ont ainsi permis de mettre en évidence que le critère de n'est pas dévolu à des sciences de la connaissance seules.

Le mot définit aux et s l'institution de la science, c'est-à-dire l'ensemble des communautés scientifiques travaillant à l'amélioration du savoir humain et de la technologie, dans sa dimension internationale, méthodologique, éthique et politique. On parle alors de .

La notion ne possède néanmoins pas de définition consensuelle. L'épistémologue André Pichot écrit ainsi qu'il est . L'historien des sciences Robert Nadeau explique pour sa part qu'il est . La physicienne et philosophe des sciences Léna Soler, dans son manuel d'épistémologie, commence également par souligner . Les dictionnaires en proposent certes quelques-unes. Mais, comme le rappelle Léna Soler, ces définitions ne sont pas satisfaisantes. Les notions d', d' ou de (surtout lorsque cette dernière est conçue comme étant l'unique notion en vigueur) sont l'objet de trop nombreuses controverses pour qu'elles puissent constituer le socle d'une définition acceptable. Il faut donc tenir compte de ces difficultés pour décrire la science. Et cette description reste possible en tolérant un certain épistémologique.

L'histoire des sciences est intimement liée à l'histoire des sociétés et des civilisations. D'abord confondue avec l'investigation philosophique, dans l'Antiquité, puis religieuse, du Moyen Âge jusqu'au Siècle des Lumières, la science possède une histoire complexe. L'histoire de la science et des sciences peut se dérouler selon deux axes comportant de nombreux embranchements :

Bien que très liées, ces deux histoires ne doivent pas être confondues. Bien plutôt, il s'agit d'une interrogation sur la production et la recherche de savoir. Michel Blay fait même de la notion de la véritable clé de voûte d'une histoire des sciences et de la science cohérente : 

De manière générale, l'histoire des sciences n'est ni linéaire, ni réductible aux schémas causaux simplistes. L'épistémologue Thomas Samuel Kuhn parle ainsi, bien plutôt, des comme des renversements de représentations, tout au long de l'histoire des sciences. Kuhn énumère ainsi un nombre de . André Pichot distingue ainsi entre l’histoire des connaissances scientifiques et celle de la pensée scientifique. Une histoire de la science et des sciences distingueraient de même, et également, entre les institutions scientifiques, les conceptions de la science, ou celle des disciplines.

La technique précède la science dans les premiers temps de l'humanité. En s'appuyant sur une démarche empirique, l'homme développe ses outils (travail de la pierre puis de l'os, propulseur) et découvre l'usage du feu dès le Paléolithique inférieur. La plupart des préhistoriens s'accordent pour penser que le feu est utilisé depuis ans ou ans. Les techniques de production de feu relèvent soit de la percussion (silex contre marcassite), soit de la friction de deux morceaux de bois (par sciage, par rainurage, par giration).

Pour de nombreux préhistoriens comme Jean Clottes, l'art pariétal montre que l'homme anatomiquement moderne du Paléolithique supérieur possédait les mêmes facultés cognitives que l'homme actuel.

Les premières traces d'activités scientifiques datent des civilisations humaines du néolithique où se développent commerce et urbanisation. Ainsi, pour André Pichot, dans "La Naissance de la science", la science naît en Mésopotamie, vers - 3500, principalement dans les villes de Sumer et d'Élam. Les premières interrogations sur la matière, avec les expériences d'alchimie, sont liées aux découvertes des techniques métallurgiques qui caractérisent cette période. La fabrication d'émaux date ainsi de - 2000. Mais l'innovation la plus importante provient de l'invention de l'écriture cunéiforme (en forme de clous), qui, par les pictogrammes, permet la reproduction de textes, la manipulation abstraite de concepts également. La numération est ainsi la première méthode scientifique à voir le jour, sur une base 60 ( en mésopotamien), permettant de réaliser des calculs de plus en plus complexes, et ce même si elle reposait sur des moyens matériels rudimentaires. L'écriture se perfectionnant (période dite ), les sumériens découvrent les fractions ainsi que la numération dite « de position », permettant le calcul de grands nombres. Le système décimal apparaît également, via le pictogramme du zéro initial, ayant la valeur d'une virgule, pour noter les fractions. La civilisation mésopotamienne aboutit ainsi à la constitution des premières sciences telles : la métrologie, très adaptée à la pratique, l'algèbre (découvertes de "planches à calculs" permettant les opérations de multiplication et de division, ou pour cette dernière ; mais aussi des puissances, racines carrées, cubiques ainsi que les équations du premier degré, à une et deux inconnues), la géométrie (calculs de surfaces, théorèmes), l'astronomie enfin (calculs de mécanique céleste, prévisions des équinoxes, constellations, dénomination des astres). La médecine a un statut particulier ; elle est la première science , héritée d'un savoir-faire tâtonnant.

Les sciences étaient alors le fait des scribes, qui, note André Pichot, se livraient à de nombreux qui permettaient de lister les problèmes. Cependant, les sumériens ne pratiquaient pas la démonstration. Dès le début, les sciences mésopotamiennes sont assimilées à des croyances, comme l'astrologie ou la mystique des nombres, qui deviendront des pseudo-sciences ultérieurement. L'histoire de la science étant très liée à celle des techniques, les premières inventions témoignent de l'apparition d'une pensée scientifique abstraite. La Mésopotamie crée ainsi les premiers instruments de mesure, du temps et de l'espace (comme les "gnomon", "clepsydre", et "polos"). Si cette civilisation a joué un rôle majeur, elle n'a pas cependant connu la rationalité puisque celle-ci .

L'Égypte antique va développer l'héritage pré-scientifique mésopotamien. Cependant, en raison de son unité culturelle spécifique, la civilisation égyptienne conserve au sein de laquelle les éléments anciens restent très présents. L'écriture des hiéroglyphes permet la représentation plus précise de concepts ; on parle alors d'une écriture idéographique. La numération est décimale mais les Égyptiens ne connaissent pas le zéro. Contrairement à la numération sumérienne, la numération égyptienne évolue vers un système d'écriture des grands nombres (entre 2000 et 1600 ) par . La géométrie fit principalement un bond en avant. Les Égyptiens bâtissaient des monuments grandioses en ne recourant qu'au système des fractions symbolisé par l'œil d'Horus, dont chaque élément représentait une fraction.

Dès 2600 , les Égyptiens calculaient correctement la surface d'un rectangle et d'un triangle. Il ne reste que peu de documents attestant l'ampleur des mathématiques égyptiennes ; seuls les papyri de Rhind, (datant de 1800 ), de Kahun, de Moscou et du Rouleau de cuir éclairent les innovations de cette civilisation qui sont avant tout celles des problèmes algébriques (de division, de progression arithmétique, géométrique). Les Égyptiens approchent également la valeur du nombre Pi, en élevant au carré les 8/9 du diamètre, découvrant un nombre équivalant à ≈ 3,1605 (au lieu de ≈ 3,1416). Les problèmes de volume (de pyramide, de cylindre à grains) sont résolus aisément. L'astronomie progresse également : le calendrier égyptien compte 365 jours, le temps est mesuré à partir d'une et les étoiles visibles sont dénombrées. En médecine, la chirurgie fait son apparition. Une théorie médicale se met en place, avec l'analyse des symptômes et des traitements et ce dès 2300 (le Papyrus Ebers est ainsi un véritable traité médical).

Pour André Pichot, la science égyptienne, comme celle de Mésopotamie avant elle, .

Les Chinois découvrent également le théorème de Pythagore (que les Babyloniens connaissaient quinze siècles avant l'ère chrétienne). En astronomie, ils identifient la comète de Halley et comprennent la périodicité des éclipses. Ils inventent par ailleurs la fonte du fer. Durant la période des Royaumes combattants, apparaît l'arbalète. En -104, est promulgué le calendrier , premier véritable calendrier chinois. En mathématiques, les chinois inventent, vers le , la numération à bâtons. Il s'agit d'une notation positionnelle à base 10 comportant dix-huit symboles, avec un vide pour représenter le zéro, c'est-à-dire la dizaine, centaine, etc. dans ce système de numérotation.
En 132, Zhang Heng invente le premier sismographe pour la mesure des tremblements de terre et est la première personne en Chine à construire un globe céleste rotatif. Il invente aussi l'odomètre. La médecine progresse sous les Han orientaux avec Zhang Zhongjing et Hua Tuo, à qui l'on doit en particulier la première anesthésie générale.

En mathématiques, Sun Zi et Qin Jiushao étudient les systèmes linéaires et les congruences (leurs apports sont généralement considérés comme majeurs). De manière générale, l'influence des sciences chinoises fut considérable, sur l'Inde et sur les pays arabes.

La civilisation dite de la vallée de l'Indus (-3300 à -1500) est surtout connue en histoire des sciences en raison de l'émergence des mathématiques complexes (ou « ganita »).

La numération décimale de position et les symboles numéraux indiens, qui deviendront les chiffres arabes, vont influencer considérablement l'Occident via les arabes et les chinois. Les grands livres indiens sont ainsi traduits au dans les « maisons du savoir » par élèves d'Al-Khawarizmi, père arabe de l'algorithme. Les Indiens ont également maîtrisé le zéro, les nombres négatifs, les fonctions trigonométriques ainsi que le calcul différentiel et intégral, les limites et séries. Les « Siddhânta » sont le nom générique donné aux ouvrages scientifiques sanskrits.

On distingue habituellement deux périodes de découvertes abstraites et d'innovations technologiques dans l'Inde de l'Antiquité : les mathématiques de l'époque védique (-1500 à -400) et les mathématiques de l'époque jaïniste (- 400 à 200).

Pour l'épistémologue , la méthode scientifique fait son apparition dans la Grèce du avec les philosophes dits présocratiques. Appelés par Aristote parce qu'ils tiennent un discours rationnel sur la nature, les présocratiques s'interrogent sur les phénomènes naturels, qui deviennent les premiers objets de méthode, et leur cherchent des causes naturelles.

Thalès de Milet (v. 625-547 av. J.-C.) et Pythagore (v. 570-480 av. J.-C.) contribuent principalement à la naissance des premières sciences comme les mathématiques, la géométrie (théorème de Pythagore), l'astronomie ou encore la musique. Dans le domaine de la cosmologie, ces premières recherches sont marquées par la volonté d'imputer la constitution du monde (ou ) à un principe naturel unique (le feu pour Héraclite par exemple) ou divin (l' pour Anaximandre). Les pré-socratiques mettent en avant des principes constitutifs des phénomènes, les . 
Les présocratiques initient également une réflexion sur la théorie de la connaissance. Constatant que la raison d'une part et les sens d'autre part conduisent à des conclusions contradictoires, Parménide opte pour la raison et estime qu'elle seule peut mener à la connaissance, alors que nos sens nous trompent. Ceux-ci, par exemple, nous enseignent que le mouvement existe, alors que la raison nous enseigne qu'il n'existe pas. Cet exemple est illustré par les célèbres paradoxes de son disciple Zénon. Si Héraclite est d'un avis opposé concernant le mouvement, il partage l'idée que les sens sont trompeurs. De telles conceptions favorisent la réflexion mathématique. Par contre, elles sont un obstacle au développement des autres sciences et singulièrement des sciences expérimentales. Sur cette question, ce courant de pensée se prolonge, quoique de manière plus nuancée, jusque Platon, pour qui les sens ne révèlent qu'une image imparfaite et déformée des Idées, qui sont la vraie réalité (allégorie de la caverne).

À ces philosophes, s'oppose le courant épicurien. Initié par Démocrite, contemporain de Socrate, il sera développé ultérieurement par Épicure et magnifiquement exposé par le Romain Lucrèce dans "De rerum natura". Pour eux, les sens nous donnent à connaître la réalité. La théorie de l'atomiste affirme que la matière est formée d'entités dénombrables et insécables, les atomes. Ceux-ci s'assemblent pour former la matière comme les lettres s'assemblent pour former les mots. Tout est constitué d'atomes, y compris les dieux. Ceux-ci ne s'intéressent nullement aux hommes, et il n'y a donc pas lieu de les craindre. On trouve donc dans l'épicurisme la première formulation claire de la séparation entre le savoir et la religion, même si, de manière moins explicite, l'ensemble des présocratiques se caractérise par le refus de laisser les mythes expliquer les phénomènes naturels, comme les éclipses.

Il faudra attendre Aristote pour aplanir l'opposition entre les deux courants de pensée mentionnés plus haut.

La méthode pré-socratique est également fondée dans son discours, s'appuyant sur les éléments de la rhétorique : les démonstrations procèdent par une argumentation logique et par la manipulation de concepts abstraits, bien que génériques.

Avec Socrate et Platon, qui en rapporte les paroles et les dialogues, la raison : "", et la connaissance deviennent intimement liés. Le raisonnement abstrait et construit apparaît. Pour Platon, les sont le modèle de tout ce qui est sensible, ce sensible étant un ensemble de combinaisons géométriques d'éléments. Platon ouvre ainsi la voie à la des phénomènes. Les sciences mettent sur la voie de la philosophie, au sens de ; inversement, la philosophie procure aux sciences un fondement assuré. L'utilisation de la dialectique, qui est l'essence même de la science complète alors la philosophie, qui a, elle, la primauté de la connaissance discursive (par le discours), ou en grec. Pour Michel Blay : . Socrate en expose les principes dans le "Théétète". Pour Platon, la recherche de la vérité et de la sagesse (la philosophie) est indissociable de la dialectique scientifique, c'est en effet le sens de l'inscription figurant sur le fronton de l'Académie, à Athènes : .

C'est surtout avec Aristote, qui fonde la physique et la zoologie, que la science acquiert une méthode, basée sur la déduction. On lui doit la première formulation du syllogisme et de l'induction. Les notions de , de , de et d' deviennent les premiers concepts de manipulation abstraite. Pour Aristote, la science est subordonnée à la philosophie (c'est une dit-il) et elle a pour objet la recherche des premiers principes et des premières causes, ce que le discours scientifique appellera le causalisme et que la philosophie nomme l'. Néanmoins, dans le domaine particulier de l'astronomie, quant à la place de la terre dans l'espace. À la suite d'Eudoxe de Cnide, il imagine un système géocentrique et considère que le cosmos est fini. Il sera suivi en cela par ses successeurs en matière d'astronomie, jusqu'à Copernic, à l'exception d'Aristarque, qui proposera un système héliocentrique. Il détermine par ailleurs que le vivant est ordonné selon une chaîne hiérarchisée mais sa théorie est avant tout fixiste. Il pose l'existence des premiers principes indémontrables, ancêtres des conjectures mathématiques et logiques. Il décompose les propositions en nom et verbe, base de la science linguistique.

La période dite « alexandrine » (de -323 à -30) et son prolongement à l'époque romaine sont marqués par des progrès significatifs en astronomie et en mathématiques ainsi que par quelques avancées en physique. La ville égyptienne d'Alexandrie en est le centre intellectuel et les savants d'alors y sont grecs.

Euclide (-325 à -265) est l'auteur des "Éléments", qui sont considérés comme l'un des textes fondateurs des mathématiques modernes. Ces postulats, comme celui nommé le « postulat d'Euclide », que l'on exprime de nos jours en affirmant que « par un point pris hors d'une droite il passe une et une seule parallèle à cette droite » sont à la base de la géométrie systématisée.

Les travaux d'Archimède (-292 à -212) sur sa poussée correspond à la première loi physique connue alors que ceux d'Ératosthène (-276 à -194) sur la circonférence de la terre ou ceux d'Aristarque de Samos (-310 à -240) sur les distances terre-lune et terre-soleil témoignent d'une grande ingéniosité. Apollonius de Perga modélise les mouvements des planètes à l'aide d'orbites excentriques.

Hipparque de Nicée (-194 à -120) perfectionne les instruments d’observation comme le dioptre, le gnomon et l'astrolabe. En algèbre et géométrie, il divise le cercle en , et crée même le premier globe céleste (ou orbe). Hipparque rédige également un traité en 12 livres sur le calcul des cordes (nommé aujourd'hui la trigonométrie). En astronomie, il propose une « théorie des épicycles » qui permettra à son tour l'établissement de tables astronomiques très précises. L'ensemble se révélera largement fonctionnel, permettant par exemple de calculer pour la première fois des éclipses lunaires et solaires. La machine d'Anticythère, un calculateur à engrenages, capable de calculer la date et l'heure des éclipses, est un des rares témoignages de la sophistication des connaissances grecques tant en astronomie et mathématiques qu'en mécanique et travail des métaux.

Ptolémée d’Alexandrie (85 à 165) prolonge les travaux d'Hipparque et d'Aristote sur les orbites planétaires et aboutit à un système géocentrique du système solaire, qui fut accepté dans les mondes occidental et arabe pendant plus de mille trois cents ans, jusqu'au modèle de Nicolas Copernic. Ptolémée fut l’auteur de plusieurs traités scientifiques, dont deux ont exercé par la suite une très grande influence sur les sciences islamique et européenne. L’un est le traité d’astronomie, qui est aujourd’hui connu sous le nom de l’"Almageste" ; l’autre est la "Géographie", qui est une discussion approfondie sur les connaissances géographiques du monde gréco-romain.

La technologie romaine est un des aspects les plus importants de la civilisation romaine. Cette technologie, en partie liée à la technique de la voûte, probablement empruntée aux Étrusques, a été certainement la plus avancée de l'Antiquité. Elle permit la domestication de l'environnement, notamment par les routes et aqueducs. Cependant, le lien entre prospérité économique de l'Empire romain et niveau technologique est discuté par les spécialistes : certains, comme Emilio Gabba, historien italien, spécialiste de l'histoire économique et sociale de la République romaine, considèrent que les dépenses militaires ont freiné le progrès scientifique et technique, pourtant riche. Pour J. Kolendo, le progrès technique romain serait lié à une crise de la main-d'œuvre, due à la rupture dans la d'esclaves non qualifiés, sous l'empereur Auguste. Les romains aurait ainsi été capables de développer des techniques alternatives. Pour L. Cracco Ruggini, la technologie traduit la volonté de prestige des couches dominantes.

Cependant, la philosophie, la médecine et les mathématiques sont d'origine grecque, ainsi que certaines techniques agricoles. La période pendant laquelle la technologie romaine est la plus foisonnante est le et le , et surtout à l'époque d'Auguste. La technologie romaine a atteint son apogée au avec le ciment, la plomberie, les grues, machines, dômes, arches. Pour l'agriculture, les Romains développent le moulin à eau. Néanmoins, les savants romains furent peu nombreux et le discours scientifique abstrait progressa peu pendant la Rome antique : , mis à part quelques grands penseurs, comme Vitruve ou Apollodore de Damas, souvent d'origine étrangère d'ailleurs. Les Romains apportèrent surtout le système denumération romain pour les unités de mesure romaines en utilisant l'abaque romain, ce qui permet d'homogénéiser le comptage des poids et des distances.

Bien que cette période s'apparente généralement à l'histoire européenne, les avancées technologiques et les évolutions de la pensée scientifique du monde oriental (civilisation arabo-musulmane) et, en premier lieu, celles de l'empire byzantin, qui hérite du savoir latin, et où puisera le monde arabo-musulman, enfin celles de la Chine sont décisives dans la constitution de la , internationale, institutionnelle et se fondant sur une méthodologie. La période du Moyen Âge s'étend ainsi de 512 à 1492 ; elle connaît le développement sans précédent des techniques et des disciplines, en dépit d'une image obscurantiste, propagée par les manuels scolaires.

Les byzantins maîtrisaient l'architecture urbaine et l'admission d'eau ; ils perfectionnèrent également les horloges à eau et les grandes norias pour l'irrigation ; technologies hydrauliques dont la civilisation arabe a hérité et qu'elle a transmis à son tour. L'hygiène et la médecine firent également des progrès. Les Universités byzantines ainsi que les bibliothèques compilèrent de nombreux traités et ouvrages d'étude sur la philosophie et le savoir scientifique de l'époque.

L'Europe occidentale, après une période de repli durant le Haut Moyen Âge, retrouve un élan culturel et technique qui culmine au . Néanmoins, du au la période dite, en France, de la Renaissance carolingienne permit, principalement par la scolarisation, le renouveau de la pensée scientifique. La scolastique, au préconise un système cohérent de pensée proche de ce que sera l'empirisme. La philosophie naturelle se donne comme objectif la description de la nature, perçue comme un système cohérent de phénomènes (ou "pragmata"), mus par des « lois ». Le Bas Moyen Âge voit la logique faire son apparition — avec l'académie de Port-Royal des Champs — et diverses méthodes scientifiques se développer ainsi qu'un effort pour élaborer des modèles mathématiques ou médicaux qui jouera . D'autre part le monde médiéval occidental voit apparaître une , concomitant à l'.

Le monde arabo-musulman est à son apogée intellectuelle du au ce qui permet le développement d'une culture scientifique spécifique, d'abord à Damas sous les derniers Omeyyades, puis à Bagdad sous les premiers Abbassides. La science arabo-musulmane est fondée sur la traduction et la lecture critique des ouvrages de l'Antiquité. L'étendue du savoir arabo-musulman est étroitement liée aux guerres de conquête de l'Islam qui permettent aux Arabes d'entrer en contact avec les civilisations indienne et chinoise. Le papier, emprunté aux Chinois remplace rapidement le parchemin dans le monde musulman. Le Calife Harun ar-Rachid, féru d'astronomie, crée en 829 à Bagdad le premier observatoire permanent, permettant à ses astronomes de réaliser leurs propres études du mouvement des astres. Abu Raihan al-Biruni, reprenant les écrits d'Ératosthène d'Alexandrie (), calcule le diamètre de la Terre et affirme que la Terre tournerait sur elle-même, bien avant Galilée. En 832 sont fondées les Maisons de la sagesse (Baït al-hikma), lieux de partage et de diffusion du savoir.

En médecine, Avicenne (980-1037) rédige une monumentale encyclopédie, le Qanûn. Ibn Nafis décrit la circulation sanguine pulmonaire, et al-Razi recommande l'usage de l'alcool en médecine. Au , Abu-l-Qasim az-Zahrawi (appelé Abulcassis en Occident) écrit un ouvrage de référence pour l'époque, sur la chirurgie.

En mathématiques l'héritage antique est sauvegardé et approfondi permettant la naissance de l"'algèbre". L'utilisation des chiffres arabes et du zéro rend possible des avancées en "analyse combinatoire" et en "trigonométrie".

Enfin, la théologie motazilite se développe sur la logique et le rationalisme, inspirés de la philosophie grecque et de la raison (logos), qu'elle cherche à rendre compatible avec les doctrines islamiques.

La Chine de l'Antiquité a surtout contribué à l'innovation technique, avec les quatre inventions principales qui sont : le papier (daté du ), l'imprimerie à caractères mobiles (au ), la poudre (la première trace écrite attestée semble être le "Wujing Zongyao" qui daterait des alentours de 1044) et la boussole, utilisée dès le , dans la géomancie. Le scientifique chinois Shen Kuo (1031-1095) de la Dynastie Song décrit la boussole magnétique comme instrument de navigation.

Pour l'historien Joseph Needham, dans "Science et civilisation en Chine", vaste étude de dix-sept volumes, la société chinoise a su mettre en place une science innovante, dès ses débuts. Needham en vient même à relativiser la conception selon laquelle la science doit tout à l'Occident. Pour lui, la Chine était même animée d'une ambition de collecter de manière désintéressée le savoir, avant même les universités occidentales.

Les traités de mathématiques et de démonstration abondent comme "Les Neuf Chapitres" (qui présentent près de 246 problèmes) transmis par Liu Hui () et par Li Chunfeng () ou encore les "Reflets des mesures du cercles sur la mer" de Li Ye datant de 1248 étudiés par Karine Chemla et qui abordent les notions arithmétiques des fractions, d'extraction de racines carrée et cubique, le calcul de l'aire du cercle et du volume de la pyramide entre autres. Karine Chelma a ainsi démontré que l'opinion répandue selon laquelle la démonstration mathématique serait d'origine grecque était partiellement fausse, les Chinois s'étant posé les mêmes problèmes à leur époque ; elle dira ainsi : on ne peut rester occidentalo-centré, l'histoire des sciences exige une mise en perspective internationale des savoirs.

Les mathématiques indiennes sont particulièrement abstraites et ne sont pas orientées vers la pratique, au contraire de celles des Égyptiens par exemple. C'est avec Brahmagupta (598 - 668) et son ouvrage célèbre, le "Brahmasphutasiddhanta", particulièrement complexe et novateur, que les différentes facettes du zéro, chiffre et nombre, sont parfaitement comprises et que la construction du système de numération décimal de position est parachevée. L'ouvrage explore également ce que les mathématiciens européens du ont nommé la « méthode chakravala », qui est un algorithme pour résoudre les équations diophantiennes. Les nombres négatifs sont également introduits, ainsi que les racines carrées. La période s'achève avec le mathématicien Bhaskara II (1114-1185) qui écrivit plusieurs traités importants. À l'instar de Nasir ad-Din at-Tusi (1201-1274) . On y trouve des équations polynomiales, des formules de trigonométrie, dont les formules d'addition. Bhaskara est ainsi .

Mais c'est surtout avec Âryabhata (476-550), dont le traité d’astronomie (nommé l’"Aryabatîya") écrit en vers aux alentours de 499, que les mathématiques indiennes se révèlent. Il s'agit d'un court traité d'astronomie présentant 66 théorèmes d'arithmétique, d'algèbre, ou de trigonométrie plane et sphérique. Aryabhata invente par ailleurs un système de représentation des nombres fondé sur les signes consonantiques de l'alphasyllabaire sanskrit.

Ces percées seront reprises et amplifiées par les mathématiciens et astronomes de l'école du Kerala, parmi lesquels : Madhava de Sangamagrama, Nilakantha Somayaji, Parameswara, Jyeshtadeva, ou Achyuta Panikkar, pendant la période médiévale du au . Ainsi, le "Yuktibhasa" ou "Ganita Yuktibhasa" est un traité de mathématiques et d'astronomie, écrit par l'astronome indien Jyesthadeva, membre de l'école mathématique du Kerala en 1530. Jyesthadeva a ainsi devancé de trois siècles la découverte du calcul infinitésimal par les occidentaux.

C'est au tournant du , et notamment avec la création des premières universités de Paris (1170) et Oxford (1220) que la science en Europe s'institutionnalisa, tout en conservant une affiliation intellectuelle avec la sphère religieuse. La traduction et la redécouverte des textes antiques grecs, et en premier lieu les "Éléments" d'Euclide ainsi que les textes d'Aristote, grâce à la civilisation arabo-musulmane, firent de cette période une renaissance des disciplines scientifiques, classées dans le "quadrivium" (parmi les Arts Libéraux). Les Européens découvrirent ainsi l'avancée des Arabes, notamment les traités mathématiques : "Algèbre" d'Al-Khwarizmi, "Optique" d'Ibn al-Haytham ainsi que la somme médicale d'Avicenne. En s'institutionnalisant, la science devint plus ouverte et plus fondamentale, même si elle restait assujettie aux dogmes religieux et qu'elle n'était qu'une branche encore de la philosophie et de l'astrologie. Aux côtés de Roger Bacon, la période fut marquée par quatre autres personnalités qui jetèrent, en Europe chrétienne, les fondements de la science moderne :

Roger Bacon (1214-1294) est philosophe et moine anglais. Il jeta les bases de la méthode expérimentale. Roger Bacon admet trois voies de connaissance : l'autorité, le raisonnement et l'expérience. Il rejette donc l'autorité de l'évidence, qui s'appuie sur des raisons extérieures et promeut . Les œuvres de Bacon ont pour but l'intuition de la vérité, c'est-à-dire la certitude scientifique, et cette vérité à atteindre est pour lui le salut. La science procédant de l'âme est donc indispensable.

Robert Grosseteste (env. 1168-1253) étudia Aristote et posa les prémices des sciences expérimentales, en explicitant le schéma : observations, déductions de la cause et des principes, formation d'hypothèse(s), nouvelles observations réfutant ou vérifiant les hypothèses enfin. Il développa les techniques d'optique et en fit même la science physique fondamentale (il étudia le comportement des rayons lumineux et formule même la première description de principe du miroir réfléchissant, principe qui permettra l'invention du télescope).
Le religieux dominicain Albert le Grand (1193-1280) fut considéré par certains contemporains comme un alchimiste et magicien, néanmoins ses études biologiques permirent de jeter les fondations des disciplines des sciences de la vie. Il mena ainsi l'étude du développement du poulet en observant le contenu d'œufs pondus dans le temps et commenta le premier le phénomène de la nutrition du fœtus. Il établit également une classification systématique des végétaux, ancêtre de la taxonomie. Il décrit également les premières expériences de chimie.

L'Europe sortait ainsi d'une léthargie intellectuelle. L'Église, . Ce n'est qu'avec Saint Thomas d'Aquin que la doctrine aristotélicienne fut acceptée par les papes.

Saint Thomas d'Aquin, théologien, permit de redécouvrir, par le monde arabe, les textes d'Aristote et des autres philosophes grecs, qu'il étudia à Naples, à l'université dominicaine. Cependant, il est surtout connu pour son principe dit de l"'autonomie respective de la raison et de la foi". Saint Thomas d'Aquin fut en effet le premier théologien à distinguer, dans sa "Somme théologique" (1266-1273) la "raison" (faculté naturelle de penser, propre à l'homme) et la "foi" (adhésion au dogme de la Révélation). Celle-ci est indémontrable, alors que la science est explicable par l'étude des phénomènes et des causes. L'une et l'autre enfin ne peuvent s'éclairer mutuellement.

Guillaume d'Occam (v. 1285- v. 1349) permit une avancée sur le plan de la méthode. En énonçant son "principe de parcimonie", appelé aussi rasoir d'Occam, il procure à la science un cadre épistémologique fondé sur l'économie des arguments. Empiriste avant l'heure, Occam postule que : , littéralement . Il explique par là qu'il est inutile d'avancer sans preuves et de forger des concepts illusoires permettant de justifier n'importe quoi.

La Renaissance est une période qui se situe en Europe à la fin du Moyen Âge et au début des Temps modernes. Dans le courant du et au , cette période permit à l'Europe de se lancer dans des expéditions maritimes d'envergure mondiale, connues sous le nom de grandes découvertes ; de nombreuses innovations furent popularisées, comme la boussole ou le sextant ; la cartographie se développa, ainsi que la médecine, grâce notamment au courant de l'humanisme. Selon l'historien anglais John Hale, ce fut à cette époque que le mot Europe entra dans le langage courant et fut doté d'un cadre de référence solidement appuyé sur des cartes et d'un ensemble d'images affirmant son identité visuelle et culturelle. La science comme discipline de la connaissance acquit ainsi son autonomie et ses premiers grands systèmes théoriques à tel point que Michel Blay parle du . Cette période est abondante en descriptions, inventions, applications et en représentations du monde, qu'il importe de décomposer afin de rendre une image fidèle de cette phase historique :

Francis Bacon (1561-1626) est le père de l'empirisme. Il pose le premier les fondements de la science et de ses méthodes. Dans son étude des faux raisonnements, sa meilleure contribution a été dans la doctrine des "idoles". D'ailleurs, il écrit dans le "Novum Organum" (ou par opposition à celle d’Aristote) que la connaissance nous vient sous forme d'objets de la nature, mais que l'on impose nos propres interprétations sur ces objets.

D'après Bacon, nos théories scientifiques sont construites en fonction de la façon dont nous voyons les objets ; . Pour Bacon, . S’opposant à la logique aristotélicienne qui établit un lien entre les principes généraux et les faits particuliers, il abandonne la pensée déductive, qui procède à partir des principes admis par l’autorité des Anciens, au profit de l’, où l’expérience enrichit réellement le savoir. En somme, Bacon préconise un raisonnement et une méthode fondés sur le raisonnement expérimental :

Pour Bacon, comme plus tard pour les scientifiques, la science améliore la condition humaine. Il expose ainsi une utopie scientifique, dans "la Nouvelle Atlantide" (1627), qui repose sur une société dirigée par composé de savants et de praticiens.

Directement permise par les mathématiques de la Renaissance, l'astronomie s'émancipe de la mécanique aristotélicienne, retravaillée par Hipparque et Ptolémée. La théologie médiévale se fonde quant à elle, d'une part sur le modèle d'Aristote, d'autre part sur le dogme de la création biblique du monde. C'est surtout Nicolas Copernic, avec son ouvrage "De revolutionibus" (1543) qui met fin au modèle aristotélicien de l'immuabilité de la Terre. Sa doctrine a permis l'instauration de l'héliocentrisme : explique Jean-Pierre Verdet, Docteur ès sciences. Repris et développé par Georg Joachim Rheticus, l'héliocentrisme sera confirmé par des observations, en particulier celles des phases de Vénus et de Jupiter par Galilée (1564-1642), qui met par ailleurs au point une des premières lunettes astronomiques, qu'il nomme « télescope ». Dans cette période, et avant que Galilée n'intervienne, la théorie de Copernic reste confinée à quelques spécialistes, de sorte qu'elle ne rencontre que des oppositions ponctuelles de la part des théologiens, les astronomes restant le plus souvent favorables à la thèse géocentrique. Néanmoins, en 1616, le Saint-Office publie un décret condamnant le système de Copernic et mettant son ouvrage à l'index. En dépit de cette interdiction, , c'est-à-dire qu'il permettra la diffusion des thèses héliocentriques. Kepler dégagera les lois empiriques des mouvements célestes alors que Huygens décrira la force centrifuge. Newton unifiera ces approches en découvrant la gravitation universelle.

Le danois Tycho Brahe observera de nombreux phénomènes astronomiques comme une nova et fondera le premier observatoire astronomique, « Uraniborg ». Il y fit l'observation d'une comète en 1577. Johannes Kepler, l'élève de Brahe qu'il rencontre en 1600, va, quant à lui, amorcer les premiers calculs à des fins astronomiques, en prévoyant précisément et en énonçant ses « trois lois » publiées en 1609 et 16l9. Avec Huygens la géométrie devient la partie centrale de la science astronomique, faisant écho aux mots de Galilée se paraphrasant par l'expression : .

Avec tous ces astronomes, et en l'espace d'un siècle et demi (jusqu'aux "Principia" de Newton en 1687), la représentation de l'univers passe d'un selon l'expression d'Alexandre Koyré.

Art ésotérique depuis l'Antiquité, l'alchimie est l'ancêtre de la physique au sens d'observation de la matière. Selon Serge Hutin, docteur ès Lettres spécialiste de l'alchimie, les bloquèrent néanmoins le progrès scientifique, surtout au et au . Il retient néanmoins que ces mirages qui nourrirent l'allégorie alchimique ont considérablement influencé la pensée scientifique. L'expérimentation doit ainsi beaucoup aux laboratoires des alchimistes, qui découvrirent de nombreux corps que répertoriés plus tard par la chimie : l'antimoine, l'acide sulfurique ou le phosphore par exemple. Les instruments des alchimistes furent ceux des chimistes modernes, l'alambic par exemple. Selon Serge Hutin, c'est surtout sur la médecine que l'alchimie eut une influence notable, par l'apport de médications minérales et par l'élargissement de la pharmacopée.

En dépit de ces faits historiques, le passage de l'alchimie à la chimie demeure complexe. Pour le chimiste Jean-Baptiste Dumas : . . Pour la conscience populaire, ce sont les premiers chimistes modernes — comme Antoine Laurent de Lavoisier surtout, au , qui pèse et mesure les éléments chimiques — qui consomment le divorce entre chimie et alchimie. De nombreux philosophes et savants sont ainsi soit à l'origine des alchimistes (Roger Bacon ou Paracelse), soit s'y intéressent, tels Francis Bacon et même, plus tard Isaac Newton. Or, selon F. Hartmann, pour qui elle est davantage comparable à la botanique. En somme, bien que les deux disciplines soient liées, par l'histoire et leurs acteurs, la différence réside dans la représentation de la matière : combinaisons chimiques pour la chimie, manifestations du monde inanimé comme phénomènes biologiques pour l'alchimie. Pour Bernard Vidal, l'alchimie a surtout .

La chimie naît ainsi comme discipline scientifique avec Andreas Libavius (1550-1616) qui publie le premier recueil de chimie, en lien avec la médecine et la pharmacie (il classifie les composés chimiques et donne les méthodes pour les préparer) alors que plus tard Nicolas Lémery (1645-1715) publiera le premier traité de chimie faisant autorité avec son "Cours de chimie, contenant la manière de faire les opérations qui sont en usage dans la médecine, par une méthode facile, avec des raisonnements sur chaque opération, pour l’instruction de ceux qui veulent s’appliquer à cette science" en 1675. Johann Rudolph Glauber (1604-1668) ou Robert Boyle apportent quant à eux de considérables expérimentations portant sur les éléments chimiques.

Les découvertes médicales et les progrès effectués dans la connaissance de l’anatomie, en particulier après la première traduction de nombreuses œuvres antiques d’Hippocrate et de Galien aux et permettent des avancées en matière d'hygiène et de lutte contre la mortalité. André Vésale jette ainsi les bases de l'anatomie moderne alors que le fonctionnement de la circulation sanguine est découverte par Michel Servet et les premières ligatures des artères sont réalisées par Ambroise Paré.

Le domaine des techniques progresse considérablement grâce à l’invention de l’imprimerie par Johannes Gutenberg au , invention qui bouleverse la transmission du savoir. 
Le nombre de livres publiés devient ainsi exponentiel, la scolarisation de masse est possible, par ailleurs les savants peuvent débattre par l'intermédiaire des comptes-rendus de leurs expérimentations. La science devient ainsi une communauté de savants. Les académies des sciences surgissent, à Londres, Paris, Saint-Pétersbourg et Berlin.

Les journaux et périodiques prolifèrent, tels le "Journal des sçavans", "Acta Eruditorum", "Mémoires de Trevoux" etc. mais les domaines du savoir y sont encore mêlés et ne constituent pas encore totalement des disciplines. La science, bien que s'institutionnalisant, fait encore partie du champ de l'investigation philosophique. Michel Blay dit ainsi : .
Finalement la Renaissance permet, pour les disciplines scientifiques de la matière, la création de disciplines et d'épistémologies distinctes mais réunies par la scientificité, elle-même permise par les mathématiques, car, selon l'expression de Pascal Brioist : . Michel Blay voit ainsi dans les débats autour de concepts clés, comme ceux d'absolu ou de mouvement, de temps et d'espace, les éléments d'une science classique.

Au , la « révolution scientifique » est permise par la "mathématisation" de la science. Les universités occidentales avaient commencé à apparaître au , mais ce n'est qu'au cours du qu'apparaissent les autres institutions scientifiques, notamment l'Accademia dei Lincei, fondée en 1603 (ancêtre de l'Académie pontificale des sciences), les , les sociétés savantes. Les sciences naturelles et la médecine surtout se développèrent durant cette période.

Un second changement important dans le mouvement des Lumières par rapport au siècle précédent trouve son origine en France, avec les Encyclopédistes. Ce mouvement intellectuel défend l’idée qu’il existe une architecture scientifique et morale du savoir. Le philosophe Denis Diderot et le mathématicien d’Alembert publient en 1751 l’"Encyclopédie ou Dictionnaire raisonné des sciences, des arts et des métiers" qui permet de faire le point sur l'état du savoir de l'époque. L'Encyclopédie devient ainsi un hymne au progrès scientifique.

Avec l'Encyclopédie naît également la conception classique que la science doit son apparition à la découverte de la méthode expérimentale. Jean le Rond D'Alembert explique ainsi, dans le "Discours préliminaire de l'Encyclopédie" (1759) que : 

La période dite des "Lumières" initia la montée du courant rationaliste, provenant de René Descartes puis des philosophes anglais, comme Thomas Hobbes et David Hume, qui adoptèrent une démarche empirique, mettant l’accent sur les sens et l’expérience dans l’acquisition des connaissances, au détriment de la raison pure. Des penseurs, également scientifiques (comme Gottfried Wilhelm von Leibniz, qui développa les mathématiques et le calcul infinitésimal, ou Emmanuel Kant, le baron d'Holbach, dans son "Système de la nature", dans lequel il soutient l’athéisme contre toute conception religieuse ou déiste, le matérialisme et le fatalisme c'est-à-dire le déterminisme scientifique, ou encore Pierre Bayle avec ses "Pensées diverses sur la comète") firent de la Raison (avec une majuscule) un culte au progrès et au développement social. Les découvertes d'Isaac Newton, sa capacité à confronter et à assembler les preuves axiomatiques et les observations physiques en un système cohérent donnèrent le ton de tout ce qui allait suivre son exemplaire "Philosophiae Naturalis Principia Mathematica". En énonçant en effet la "théorie de la gravitation universelle", Newton inaugura l'idée d'une science comme discours tendant à expliquer le monde, considéré comme rationnel car ordonné par des lois reproductibles.

L'avènement du sujet pensant, en tant qu'individu qui peut décider par son raisonnement propre et non plus sous le seul joug des us et coutumes, avec John Locke, permet la naissance des sciences humaines, comme l'économie, la démographie, la géographie ou encore la psychologie.

La majorité des disciplines majeures de la science se consolident, dans leurs épistémologies et leurs méthodes, au . La botanique apparaît avec Carl von Linné qui publie en 1753 "Species plantarum", point du départ du système du binôme linnéen et de la nomenclature botanique. La chimie naît par ailleurs avec Antoine Laurent de Lavoisier qui énonce en 1778 la "loi de conservation de la matière", identifie et baptise l'oxygène. Les sciences de la terre font aussi leur apparition. Comme discipline, la médecine progresse également avec la constitution des examens cliniques et les premières classification des maladies par William Cullen et François Boissier de Sauvages de Lacroix.
La biologie connaît au de profonds bouleversements avec la naissance de la génétique, à la suite des travaux de Gregor Mendel, le développement de la physiologie, l'abandon du vitalisme à la suite de la synthèse de l'urée qui démontre que les composés organiques obéissent aux mêmes lois physico-chimique que les composés inorganiques. L'opposition entre science et religion se renforce avec la parution de "L'Origine des espèces" en 1859 de Charles Darwin. Les sciences humaines naissent, la sociologie avec Auguste Comte, la psychologie avec Charcot et Wilhelm Maximilian Wundt.

Claude Bernard (1813-1878) est un médecin et physiologiste, connu pour l'étude du syndrome de Claude Bernard-Horner. Il est considéré comme le fondateur de la médecine expérimentale. Il rédige la première méthode expérimentale, considérée comme le modèle à suivre de la pratique scientifique. Il énonce ainsi les axiomes de la méthode médicale dans son "Introduction à l'étude de la médecine expérimentale" (1865) et en premier lieu l'idée que l'observation doit réfuter ou valider la théorie : .

Les Première et Seconde Révolutions Industrielles sont marquées par de profonds bouleversements économiques et sociaux, permis par les innovations et découvertes scientifiques et techniques. La vapeur, puis l'électricité comptent parmi ces progrès notables qui ont permis l'amélioration des transports et de la production. Les instruments scientifiques sont plus nombreux et plus sûrs, tels le microscope (à l'aide duquel Louis Pasteur découvre les microbes) ou le télescope se perfectionnent. La physique acquiert ses principales lois, notamment avec James Clerk Maxwell qui, énonce les principes de la théorie cinétique des gaz ainsi que l'équation d'onde fondant l'électromagnétisme. Ces deux découvertes permirent d'importants travaux ultérieurs notamment en relativité restreinte et en mécanique quantique. Il esquisse ainsi les fondements des sciences du , notamment les principes de la physique des particules, à propos de la nature de la lumière.

Tout comme le , le connaît une accélération importante des découvertes scientifiques. On note l'amélioration de la précision des instruments, qui eux-mêmes reposent sur les avancées les plus récentes de la science ; l'informatique qui se développe à partir des années 1950 et permet un meilleur traitement d'une masse d'informations toujours plus importante et aboutit à révolutionner la pratique de la recherche, est un de ces instruments.

Les échanges internationaux des connaissances scientifiques sont de plus en plus rapides et faciles (ce qui se traduit par des enjeux linguistiques) ; toutefois, les découvertes les plus connues du précèdent la véritable mondialisation et l'uniformisation linguistique des publications scientifiques. En 1971, la firme Intel met au point le premier micro-processeur et, en 1976, Apple commercialise le premier ordinateur de bureau. Dans "La Société post-industrielle. Naissance d'une société" d'Alain Touraine, le sociologue présente les caractéristiques d'une science au service de l'économie et de la prospérité matérielle.

De en révolutions scientifiques, la science vit ses disciplines se spécialiser. La complexification des sciences explosa au , conjointement à la multiplication des champs d'étude. Parallèlement, les sciences viennent à se rapprocher voire à travailler ensemble. C'est ainsi que, par exemple, la biologie fait appel à la chimie et à la physique, tandis que cette dernière utilise l'astronomie pour confirmer ou infirmer ses théories (c'est l'astrophysique). Les mathématiques deviennent le « langage » commun des sciences ; les applications étant multiples. Le cas de la biologie est exemplaire. Elle s'est divisée en effet en de nombreuses branches : en biologie moléculaire, biochimie, biologie génétique, agrobiologie, etc.

La somme des connaissances devient telle qu'il est impossible pour un scientifique de connaître parfaitement plusieurs branches de la science. C'est ainsi qu'ils se spécialisent de plus en plus et pour contrebalancer cela, le travail en équipe devient la norme. Cette complexification rend la science de plus en plus abstraite pour ceux qui ne participent pas aux découvertes scientifiques, en dépit de programmes nationaux et internationaux (sous l'égide de l'ONU, avec l'UNESCO - pour "United Nations Educational, Scientific and Cultural Organization") de vulgarisation des savoirs.

Le siècle est également marqué par le développement des sciences humaines. Institutionnalisées dans la séparation que l'université française fait entre les facultés de sciences et médecine d'une part, et celles de lettres, droit et sciences humaines d'autre part, les sciences humaines comportent de nombreuses disciplines comme l'anthropologie, la sociologie, l'ethnologie, l'histoire, la psychologie, la psychanalyse, la linguistique, la morale, l'archéologie, l'économie entre autres.

Le est caractérisé par une accélération des découvertes de pointe, comme la nanotechnologie. Par ailleurs, au sein des sciences naturelles, la génétique promet des changements sociaux ou biologiques sans précédents. L'informatique est par ailleurs à la fois une science et un instrument de recherche puisque la simulation informatique permet d'expérimenter des modèles toujours plus complexes et gourmands en termes de puissance de calcul. La science se démocratise d'une part : des projets internationaux voient le jour (lutte contre le SIDA et le cancer, programme SETI, astronomie, détecteurs de particules etc.) ; d'autre part la vulgarisation scientifique permet de faire accéder toujours plus de personnes au raisonnement et à la curiosité scientifique.

L'éthique devient une notion concomitante à celle de science. Les nanotechnologies et la génétique surtout posent les problèmes de société futurs, à savoir, respectivement, les dangers des innovations pour la santé, et la manipulation du patrimoine héréditaire de l'homme. Les pays avancés technologiquement créent ainsi des organes institutionnels chargé d'examiner le bien-fondé des applications scientifiques. Par exemple, des lois bioéthiques se mettent en place à travers le monde, mais pas partout de la même manière, étant très liées aux droits locaux. En France, le Comité Consultatif National d'Éthique est chargé de donner un cadre légal aux découvertes scientifiques.

La science peut être organisée en grandes disciplines scientifiques, notamment : mathématiques, chimie, biologie, physique, mécanique, informatique, psychologie, optique, pharmacie, médecine, astronomie, archéologie, économie, sociologie, anthropologie, linguistique. Les disciplines ne se distinguent pas seulement par leurs méthodes ou leurs objets, mais aussi par leurs institutions : revues, sociétés savantes, chaires d'enseignement, ou même leurs diplômes.

Plusieurs axes de classification des disciplines existent et sont présentées dans cette section : 
Par ailleurs, le terme de « science pure » est parfois employé pour catégoriser les sciences formelles, construites sur des entités purement abstraites. Il s'agit en occurrence de la mathématique et la logique, mais également de la phénoménologie. À ne pas confondre avec les sciences dites « dures » désignant les sciences de la nature, ou sciences naturelles, s'opposant ainsi aux sciences dîtes « molles » telles que les sciences humaines et sociales.

Ceci dit, l'anthropocentrisme historique a toujours donné aux sciences humaines une position privilégiée. 
On distingue les sciences humaines et sociales des sciences de la nature. Les premières, comme la sociologie, portent sur l'étude des phénomènes liés à l'action humaine, les secondes, comme la physique, portent sur l'étude des phénomènes naturels. Plus récemment, quelques auteurs, comme Herbert Simon, ont évoqué l'apparition d'une catégorie intermédiaire, celle des sciences de l'artificiel, qui portent sur l'étude de systèmes créés par l'homme - artificiels - mais qui présentent un comportement indépendant ou relativement de l'action humaine. Il s'agit par exemple des sciences de l'ingénieur. On peut également distinguer les sciences empiriques, qui portent sur l'étude des phénomènes accessibles par l'observation et l'expérimentation, des sciences logico-formelles, comme la logique ou les mathématiques, qui portent sur des entités purement abstraites. Une autre manière de catégoriser les sciences consiste à distinguer les sciences fondamentales, dont le but premier est de produire des connaissances, des sciences appliquées, qui visent avant tout à appliquer ces connaissances à la résolution de problèmes concrets. D'autres catégorisations existent, notamment la notion de science exacte ou de science dure. Ces dernières catégorisations, bien que très courantes, sont beaucoup plus discutables que les autres, car elles sont porteuses d'un jugement (certaines sciences seraient plus exactes que d'autres, certaines sciences seraient « molles », c'est-à-dire sans véritable consistance.). Il existe aussi une Classification des sciences en poupées russes.

De manière générale, aucune catégorisation n'est complètement exacte ni entièrement justifiable, et les zones épistémologiques entre elles demeurent floues. Pour Robert Nadeau : .

Les « sciences fondamentales » visent prioritairement l'acquisition de connaissances nouvelles. Cette classification première repose sur la notion d'utilité : certaines sciences produisent des connaissances en sorte d’agir sur le monde (les sciences appliquées), c’est-à-dire dans la perspective d’un objectif pratique, tandis que d'autres (les sciences fondamentales) visent prioritairement l’acquisition de connaissances nouvelles abstraites.
Néanmoins, cette limite est floue. Les mathématiques, la physique, la chimie ou la biologie peuvent ainsi aussi bien être fondamentales qu'appliquées, selon le contexte. Les sciences appliquées (qu'il ne faut pas confondre avec la technique en tant qu'application de connaissances empiriques) produisent des connaissances en sorte d'agir sur le monde, c'est-à-dire dans la perspective d'un objectif pratique, économique ou industriel.

Certaines disciplines restent cependant plus ancrées dans un domaine que dans un autre. La cosmologie est par exemple une science exclusivement fondamentale. L'astronomie est également une discipline qui relève dans une grande mesure de la science fondamentale. La médecine, la pédagogie ou l'ingénierie sont au contraire des sciences essentiellement appliquées (mais pas exclusivement). Sciences appliquées et sciences fondamentales ne sont pas cloisonnées. Les découvertes issues de la science fondamentale trouvent des fins utiles (exemple : le laser et son application au son numérique sur CD-ROM). De même, certains problèmes techniques mènent parfois à de nouvelles découvertes en science fondamentale. Ainsi, les laboratoires de recherche et les chercheurs peuvent faire parallèlement de la recherche appliquée et de la recherche fondamentale. Par ailleurs, la recherche en sciences fondamentales utilise les technologies issues de la science appliquée, comme la microscopie, les possibilités de calcul des ordinateurs par la simulation numérique, par exemple.

Par ailleurs, les mathématiques sont souvent considérées comme autre chose qu'une science, en partie parce que la vérité mathématique n'a rien à voir avec la vérité des autres sciences. L'objet des mathématiques est en effet interne à cette discipline. Ainsi, sur cette base, les mathématiques appliquées souvent perçus davantage comme une branche mathématique au service d'autres sciences (comme le démontrent les travaux du mathématicien Jacques-Louis Lions qui explique : ) seraient bien plutôt sans finalité pratique. "A contrario", les mathématiques possèdent un nombre important de branches, d'abord abstraites, s'étant développées au contact avec d'autres disciplines comme les statistiques, la théorie des jeux, la logique combinatoire, la théorie de l'information, la théorie des graphes entre autres exemples, autant de branches qui ne sont pas catalogués dans les mathématiques appliquées mais qui pourtant irriguent d'autres branches scientifiques.

Un classement des sciences peut s'appuyer sur les méthodes mise en œuvre. Une première distinction de cet ordre peut être faite entre les sciences nomothétiques et les sciences idiographiques :

C'est à Wilhelm Windelband, philosophe allemand du , que l'on doit la première ébauche de cette distinction, la réflexion de Windelband portant sur la nature des sciences sociales. Dans son "Histoire et science de la nature" (1894), il soutient que l'opposition entre sciences de la nature et de l'esprit repose sur une distinction de méthode et de . Jean Piaget reprendra le vocable de "nomothétique" pour désigner les disciplines cherchant à dégager des lois ou des relations quantitatives en utilisant des méthodes d'expérimentation stricte ou systématique. Il cite la psychologie scientifique, la sociologie, la linguistique, l'économie et la démographie. Il distingue ces disciplines des sciences historiques, juridiques et philosophiques.

Une catégorisation a été proposée par l'épistémologie, distinguant les et les . Leur point commun reste les mathématiques et leur usage dans les disciplines liées ; cependant, selon les mots de Gilles-Gaston Granger, . Selon Léna Soler, dans son "Introduction à l’épistémologie", distingue d’une part les sciences formelles des sciences empiriques, d’autre part les sciences de la natures des sciences humaines et sociale.


Selon Gilles-Gaston Granger, il existe une autre sorte d'opposition épistémologique, distinguant d'une part les "sciences de la nature", qui ont des objets émanant du monde sensible, mesurables et classables ; d'autre part les "sciences de l'homme" aussi dites sciences humaines, pour lesquelles l'objet est abstrait. Gilles-Gaston Granger récuse par ailleurs de faire de l'étude du phénomène humain une science proprement dite.

Le sens commun associe une discipline à un objet. Par exemple la sociologie s’occupe de la société, la psychologie de la pensée, la physique s’occupe de phénomènes mécaniques, thermiques, la chimie s’occupe des réactions de la matière. La recherche moderne montre néanmoins l’absence de frontière et la nécessité de développer des transversalités ; par exemple, pour certaines disciplines on parle de ou de , expressions qui permettent de montrer les liens forts des spécialités entre elles. Une discipline est finalement définie par l’ensemble des référentiels qu’elle utilise pour étudier un ensemble d’objets, ce qui forme sa "scientificité". Néanmoins, ce critère n'est pas absolu.

Pour le sociologue Raymond Boudon, il n'existe pas une scientificité unique et transdisciplinaire. Il s’appuie ainsi sur la notion d’, notion déjà théorisée par le philosophe Ludwig Wittgenstein selon laquelle il n'existe que des ressemblances formelles entre les sciences, sans pour autant en tirer une règle générale permettant de dire ce qu'est . Raymond Boudon, dans "L’art de se persuader des idées douteuses, fragiles ou fausses" explique que le relativisme « s'il est une idée reçue bien installée […], repose sur des bases fragiles » et que, contrairement à ce que prêche Feyerabend, « il n'y a pas lieu de congédier la raison ».

Selon Emmanuel Kant, la logique formelle est . Les mathématiques et la logique formalisées composent ce type de raisonnement. Cette classe se fonde par ailleurs sur deux principes constitutifs des systèmes formels : l'axiome et les règles de déduction ainsi que sur la notion de syllogisme, exprimée par Aristote le premier et liée au (on parle aussi de raisonnement ), qu'il expose dans ses "Topiques" et dans son traité sur la logique : "Les Analytiques".

Il s'agit également du type qui est le plus adéquat à la réalité, celui qui a fait le plus ses preuves, par la technique notamment. Le maître-mot du type formel pur est la démonstration logique et non-contradictoire (entendu comme la démonstration qu'on ne pourra dériver dans le système étudié n'importe quelle proposition). En d'autres termes, il ne s'agit pas à proprement parler d'un raisonnement sur l'objet mais bien plutôt d'une méthode pour traiter les faits au sein des démonstrations scientifiques et portant sur les propositions et les postulats.

On distingue ainsi dans ce type deux disciplines fondamentales :

Le type formel fut particulièrement développée au , avec le logicisme et la philosophie analytique. Bertrand Russell développe en effet une (ou atomisme logique) qui s’efforce de diviser le langage en ses parties élémentaires, ses structures minimales, la phrase simple en somme. Wittgenstein projetait en effet d’élaborer un langage formel commun à toutes les sciences permettant d'éviter le recours au langage naturel, et dont le calcul propositionnel représente l'aboutissement. Cependant, en dépit d'une stabilité épistémologique propre, "a contrario" des autres types, le type formel pur est également largement tributaire de l'historicité des sciences

Le modèle de ce type, fondé sur l'empirisme, est la physique. L'objet est ici concret et extérieur, non construit par la discipline (comme dans le cas du type formel pur). Ce type est en fait la réunion de deux composantes :

Le type empirico-formel progresse ainsi de la théorie — donnée comme "a priori" — à l'empirie, puis revient sur la première via un raisonnement circulaire destiné à confirmer ou réfuter les axiomes. Le est alors l'intermédiaire entre la théorie et la pratique. Il s'agit d'une schématisation permettant d'éprouver ponctuellement la théorie. La notion de est depuis longtemps centrale en philosophie des sciences, mais elle est remplacée, sous l'impulsion empiriste, par celle de modèle, dès le milieu du . L'expérience (au sens de mise en pratique) est ici centrale, selon l'expression de Karl Popper : .

Parmi les sciences empiriques, on distingue deux grandes familles de sciences : les sciences de la nature et les sciences humaines. Néanmoins, l'empirisme seul ne permet pas, en se coupant de l'imagination, d'élaborer des théories novatrices, fondées sur l'intuition du scientifique, permettant de dépasser des contradictions que la simple observation des faits ne pourrait résoudre.

Il existe néanmoins des débats quant à la nature empirique de certaines sciences humaines, comme l'économie ou l'histoire, qui ne reposent pas sur une méthode totalement empirique, l'objet étant virtuel dans les deux disciplines.

Les sciences herméneutiques (du grec "", ) décodent les signes naturels et établissent des interprétations. Ce type de discours scientifique est caractéristique des sciences humaines, où l'objet est l'homme. Dans la méthode herméneutique, les effets visibles sont considérés comme un texte à décoder, à la signification cachée. La phénoménologie est ainsi l'explication philosophique la plus proche de ce type, qui regroupe, entre autres, la sociologie, la linguistique, l'économie, l'ethnologie, la théorie des jeux, etc. Il peut s'agir dès lors de deux catégories de discours :
Par rapport aux deux autres types formels, le statut scientifique du type herméneutique est contesté par les tenants d'une science mathématique, dite .

À la conception de l’unité de la science postulée par le positivisme tout un courant de pensée va, à la suite de Wilhelm Dilthey (1833-1911), affirmer l’existence d’une coupure radicale entre les sciences de la nature et les sciences de l’esprit. Les sciences de la nature ne cherchent qu'à expliquer leur objet, tandis que les sciences de l'homme, et l'histoire en particulier, demandent également à comprendre de l'intérieur et donc à prendre en considération le vécu. Ces dernières ne doivent pas adopter la méthode en usage dans les sciences de la nature car elles ont un objet qui lui est totalement différent. Les sciences sociales doivent être l'objet d'une introspection, ce que Wilhelm Dilthey appelle une , c’est-à-dire une démarche d’interprétation des manifestations concrètes de l’esprit humain. Le type herméneutique marque le , avec des auteurs comme Hans-Georg Gadamer qui publia en 1960, "Vérité et Méthode" qui, s'opposant à l'empirisme tout-puissant, affirme que .

La connaissance acquise ne peut être qualifié de scientifique que si la scientificité des processus d'obtention a été démontrée.

La est . Elle est étroitement liée au but recherché et à l'histoire des sciences. La méthode scientifique suit par ailleurs cinq opérations distinctes :

La scientificité est la qualité des pratiques et des théories qui cherchent à établir des régularités reproductibles, mesurables et réfutables dans les phénomènes par le moyen de la mesure expérimentale, et à en fournir une représentation explicite.

Plus généralement, c'est le . De manière générale à toutes les sciences, la méthode scientifique repose sur quatre critères :

Néanmoins, chacun de ces points est problématique, et les questionnements de l'épistémologie portent principalement sur les critères de scientificité. Ainsi, concernant la cohérence interne aux disciplines, l'épistémologue Thomas Samuel Kuhn bat en brèche ce critère de scientificité, en posant que les paradigmes subissent des « révolutions scientifiques » : un modèle n'est valable tant qu'il n'est pas remis en cause. Le principe d'objectivité, qui est souvent présenté comme l'apanage de la science, est, de même, source d'interrogations, surtout au sein des sciences humaines.

Pour le sociologue de la science Roberto Miguelez : . La sociologie des sciences étudie en effet de plus en plus les critères de scientificité, au sein de l'espace social scientifique, passant d'une vision interne, celle de l'épistémologie, à une vision davantage globale.

L' est une méthode scientifique qui consiste à tester par des expériences répétées la validité d'une hypothèse et à obtenir des données quantitatives permettant de l'affiner. Elle repose sur des protocoles expérimentaux permettant de normaliser la démarche. La physique ou la biologie reposent sur une démarche active du scientifique qui construit et contrôle un dispositif expérimental reproduisant certains aspects des phénomènes naturels étudiés. La plupart des sciences emploient ainsi la méthode expérimentale, dont le protocole est adapté à son objet et à sa scientificité. De manière générale, une expérience doit apporter des précisions quantifiées (ou statistiques) permettant de réfuter ou étayer le modèle. Les résultats des expériences ne sont pas toujours quantifiables, comme dans les sciences humaines. L'expérience doit ainsi pouvoir réfuter les modèles théoriques.

L'expérimentation a été mise en avant par le courant de l'empirisme. Néanmoins, le logicien et scientifique Charles Sanders Peirce (1839-1914), et plus tard mais indépendamment, l'épistémologue Karl Popper (1902-1994), lui opposent l'abduction (ou méthode par conjecture et réfutation) comme étape première de la recherche scientifique. L'abduction (ou conjecture) est un procédé consistant à introduire une règle à titre d’hypothèse afin de considérer ce résultat comme un cas particulier tombant sous cette règle. Elle consiste en l'invention "a priori" d'une conjecture précédant l'expérience. En somme, cela signifie que l'induction fournit directement la théorie, alors que dans le processus abductif la théorie est inventée avant l'expérience et cette dernière ne fait que répondre par l'affirmative ou par la négative à l'hypothèse.

L’ est l’action de suivi attentif des phénomènes, sans volonté de les modifier, à l’aide de moyens d’enquête et d’étude appropriés. Les scientifiques y ont recours principalement lorsqu'ils suivent une méthode empirique. C'est par exemple le cas en astronomie ou en physique. Il s'agit d'observer le phénomène ou l'objet sans le dénaturer, ou même interférer avec sa réalité. Certaines sciences, comme la physique quantique ou la psychologie, prennent en compte l'observation comme un paradigme explicatif à part entière, influençant le comportement de l'objet observé. La philosophe Catherine Chevalley résume ainsi ce nouveau statut de l'observation : .

La science définit la notion d’observation dans le cadre de l’approche objective de la connaissance, observation permise par une mesure et suivant un protocole fixé d'avance.

Une (du grec "" soit ) est un modèle ou un cadre de travail pour la compréhension de la nature et de l'humain. En physique, le terme de théorie désigne généralement le support mathématique, dérivé d'un petit ensemble de principes de base et d'équations, permettant de produire des prévisions expérimentales pour une catégorie donnée de systèmes physiques. Un exemple est la « théorie électromagnétique », habituellement confondue avec l'électromagnétisme classique, et dont les résultats spécifiques sont obtenus à partir des équations de Maxwell. L’adjectif « théorique » adjoint à la description d'un phénomène indique souvent qu'un résultat particulier a été prédit par une théorie mais qu'il n'a pas encore été observé. La théorie est ainsi bien souvent plus un modèle entre l'expérimentation et l'observation qui reste à confirmer.

La conception scientifique de la théorie devient ainsi une phase provisoire de la méthode expérimentale. Claude Bernard, dans son "Introduction à la médecine expérimentale" appuie sur le rôle clé des questions et sur l'importance de l'imagination dans la construction des hypothèses, sorte de théories en voie de développement. Le neurobiologiste Jean-Pierre Changeux explique ainsi : 

En effet, si l'expérimentation est prépondérante, elle ne suffit pas, conformément à la maxime de Claude Bernard : , la théorie et le modèle permettant d'éprouver la réalité "a priori".

La est la . Elle est directement liée à l'utilisation de l'informatique au . Il existe deux types de simulations :

Le terme de regroupe plusieurs types de communications que les chercheurs font de leurs travaux en direction d'un public de spécialistes, et ayant subi une forme d'examen de la rigueur de la méthode scientifique employée pour ces travaux, comme l'examen par un comité de lecture indépendant par exemple. La publication scientifique est donc la validation de travaux par la communauté scientifique. C'est aussi le lieu de débats contradictoires à propos de sujets polémiques ou de discussions de méthodes.

Il existe ainsi plusieurs modes de publications :

Les publications qui entrent dans un des cadres ci-dessus sont généralement les seules considérées pour l'évaluation des chercheurs et les études bibliométriques, à tel point que l'adage (publier ou périr) est fondé. La scientométrie est en effet une méthode statistique appliquée aux publications scientifiques. Elle est utilisée par les organismes finançant la recherche comme outil d'évaluation. En France, ces indicateurs, tel le facteur d'impact, occupent ainsi une place importante dans la LOLF (pour : Loi Organique relative aux Lois de Finances). Les politiques budgétaires dévolues aux laboratoires et aux unités de recherche dépendent ainsi souvent de ces indicateurs scientométriques.

Le vocable d' remplace celui de philosophie des sciences au début du . Il s'agit d'un néologisme construit par James Frederick Ferrier, dans son ouvrage "Institutes of metaphysics" (1854). Le mot est composé sur la racine grecque signifiant et sur le suffixe signifiant . Ferrier l'oppose au concept antagoniste de l', ou théorie de l'ignorance. Le philosophe analytique Bertrand Russell l'emploie ensuite, dans son "Essai sur les fondements de la géométrie" en 1901, sous la définition d'analyse rigoureuse des discours scientifiques, pour examiner les modes de raisonnement qu'ils mettent en œuvre et décrire la structure formelle de leurs théories. En d'autres mots, les se concentrent sur la démarche de la connaissance, sur les modèles et les théories scientifiques, qu'ils présentent comme autonomes par rapport à la philosophie.

Jean Piaget proposait de définir l’épistémologie , dénomination qui, selon Jean-Louis Le Moigne, permet de poser les trois grandes questions de la discipline :


Avant ces investigations, la science était conçue comme un corpus de connaissances et de méthodes, objet d’étude de la Philosophie des sciences, qui étudiait le discours scientifique relativement à des postulats ontologiques ou philosophiques, c'est-à-dire non-autonomes en soi. L'épistémologie permettra la reconnaissance de la science et des sciences comme disciplines autonomes par rapport à la philosophie. Les analyses de la science (l'expression de est parfois employée) ont tout d’abord porté sur la science comme corpus de connaissance, et ont longtemps relevé de la philosophie. C'est le cas d'Aristote, de Francis Bacon, de René Descartes, de Gaston Bachelard, du cercle de Vienne, puis de Popper, Quine, Lakatos enfin, parmi les plus importants. L’épistémologie, au contraire, s'appuie sur l'analyse de chaque discipline particulière relevant des épistémologies dites . Aurel David explique ainsi que .

Pour le prix Nobel de physique Steven Weinberg, auteur de "Le Rêve d'une théorie ultime" (1997) la philosophie des sciences est inutile car elle n'a jamais aidé la connaissance scientifique à avancer.

Le terme de "progrès" vient du latin qui signifie l'action d'avancer. Selon cette étymologie le progrès désigne un passage à un degré supérieur, c'est-à-dire à un état meilleur, participant à l'effort économique. La civilisation se fonde ainsi, dans son développement, sur une série de progrès dont le progrès scientifique. La science serait avant tout un moyen de faire le bonheur de l'humanité, en étant le moteur du progrès matériel et moral. Cette identification de la science au progrès est très ancienne et remonte aux fondements philosophiques de la science. Cette thèse est distincte de celle de la science dite pure (en elle-même), et pose le problème de l'autonomie de la science, en particulier dans son rapport au pouvoir politique. Les questions éthiques limitent également cette définition de la science comme un progrès. Certaines découvertes scientifiques ont des applications militaires ou même peuvent être létales en dépit d'un usage premier bénéfique.

Selon les tenants de la science comme moyen d'amélioration de la société, dont Ernest Renan ou Auguste Comte sont parmi les plus représentatifs, le progrès offre :

La thèse de la science pure pose, quant à elle, que la science est avant tout le propre de l'humain, ce qui fait de l'homme un animal différent des autres. Dans une lettre du 2 juillet 1830 adressée à Legendre, le mathématicien Charles Gustave Jacob Jacobi écrit ainsi, à propos du physicien Joseph Fourier : . D'autres courants de pensée comme le scientisme envisagent le progrès sous un angle plus utilitariste.

Enfin des courants plus radicaux posent que la science et la technique permettront de dépasser la condition ontologique et biologique de l'homme. Le transhumanisme ou l'extropisme sont par exemple des courants de pensée stipulant que le but de l'humanité est de dépasser les injustices biologiques (comme les maladies génétiques, grâce au génie génétique) et sociales (par le rationalisme), et que la science est le seul moyen à sa portée. À l'opposé, les courants technophobes refusent l'idée d'une science salvatrice, et pointent au contraire les inégalités sociales et écologiques, entre autres, que la science génère.

L'épistémologie pose un ensemble de questions philosophiques à la Science et à la "science en train de se faire". La science progressant de manière fondamentalement discontinue, les renversements de représentations des savants, appelées également selon l'expression de Thomas Samuel Kuhn, sont également au cœur des interrogations épistémologiques. Parmi ces questions centrales de l'épistémologie on distingue :

Nombre de philosophes ou d'épistémologues ont ainsi interrogé la nature de la science et en premier lieu la thèse de son unicité. L'épistémologue Paul Feyerabend, dans "Contre la méthode", est l'un des premiers, dans les années soixante-dix, à se révolter contre les idées reçues à l'égard de la science et à relativiser l'idée trop simple de . Il expose une théorie anarchiste de la connaissance plaidant pour la diversité des raisons et des opinions, et explique en effet que . Le philosophe Louis Althusser, qui a produit un cours sur cette question dans une perspective marxiste, soutient que qu’il appelle (). Dominique Pestre s'attache lui à montrer l'inutilité d'une distinction entre et , dans "Introduction aux Science Studies".

L'histoire des sciences et de la philosophie a produit de nombreuses théories quant à la nature et à la portée du phénomène scientifique. Il existe ainsi un ensemble de grands modèles épistémologiques qui prétendent expliquer la spécificité de la science. Le a marqué un tournant radical. Très schématiquement, aux premières réflexions purement philosophique et souvent normatives sont venus s’ajouter des réflexions plus sociologiques et psychologiques, puis des approches sociologiques et anthropologiques dans les années 1980, puis enfin des approches fondamentalement hétérogènes à partir des années 1990 avec les "Science studies". Le discours sera également interrogé par la psychologie avec le courant du constructivisme. Enfin, l'épistémologie s'intéresse à la (expression de Bruno Latour), c'est-à-dire à sa mise en œuvre au quotidien et plus seulement à la nature des questions théoriques qu'elle produit.

Le Concile de Nicée de 325 avait instauré dans l'Église l'argument dogmatique selon lequel Dieu avait créé le ciel et la terre en sept jours. Cependant, des explications scientifiques furent possibles dès ce credo, qui ne se prononçait pas sur l'engendrement du monde, œuvre du Christ. Cette lacune théologique avait permis une certaine activité scientifique au Moyen Âge, dont, en premier lieu, l'astronomie. Dès le , la science arabo-musulmane prospérait et développait la médecine, les mathématiques, l'astronomie, et d'autres sciences. À cette époque, dans l'islam, la science était particulièrement encouragée, le monde étant vu comme un code à déchiffrer pour comprendre les messages divins. Les pays de culture chrétienne en profitèrent largement à partir du lors d'une période de renouveau appelée Renaissance du par l'historien Charles H. Haskins.

Au sein du christianisme, le premier pas en faveur de l'héliocentrisme (qui place la Terre en orbitation autour du Soleil) est fait par le chanoine Nicolas Copernic, avec le "De revolutionibus" (1543). Le Concile de Trente (1545-1563) encouragea les communautés religieuses à mener des recherches scientifiques. Mais Galilée se heurte à la position de l'Église en faveur du géocentrisme, en vertu d'une interprétation littérale de la Bible, qui recoupait la représentation du monde des savants grecs de l'Antiquité (Ptolémée et Aristote). Le procès de Galilée, en 1633, marque un divorce entre la pensée scientifique et la pensée religieuse, pourtant initiée par l'exécution de Giordano Bruno en 1600. L'opposition des autorités religieuses aux implications des découvertes faites par des scientifiques, telle qu'elle s'est manifestée dans le cas de Galilée, est apparue "a posteriori" comme une singularité dans l'Histoire. Le procès de Galilée devint le symbole d'une science devenant indépendante de la religion, voire opposée à elle. Cette séparation est consommée au , pendant les Lumières.

Au , les scientismes posent que la science seule peut expliquer l'univers et que la religion est l' comme dira plus tard Karl Marx qui fonde la vision matérialiste de l'histoire. Les réussites scientifiques et techniques, qui améliorent la civilisation et la qualité de vie, le progrès scientifique en somme, bat en brèche les dogmes religieux, quelle que soit la confession. Les théories modernes de la physique et de la biologie (avec Charles Darwin et l'évolution), les découvertes de la psychologie, pour laquelle le sentiment religieux demeure un phénomène intérieur voire neurologique, supplantent les explications mystiques et spirituelles.

Au , l'affrontement des partisans de la théorie de l'évolution et des créationnistes, souvent issus des courants religieux radicaux, cristallise le dialogue difficile de la foi et de la raison. Le « procès du singe » (à propos de l'« ascendance » simiesque de l'homme) illustre ainsi un débat permanent au sein de la société civile. Enfin, nombre de philosophes ou d'épistémologues se sont interrogés sur la nature de la relation entre les deux institutions. Le paléontologue Stephen Jay Gould dans « Que Darwin soit ! » parle de deux magistères, chacun restant maître de son territoire mais ne s'empiétant pas, alors que Bertrand Russell mentionne dans son ouvrage "Science et Religion" les conflits les opposant. Nombre de religieux tentent, comme Pierre Teilhard de Chardin ou Georges Lemaître (père de la théorie du Big bang), d'allier explication scientifique et ontologie religieuse.

L'encyclique de 1998, "Fides et ratio", de Jean-Paul II cherche à réconcilier la religion et la science en proclamant que « la foi et la raison sont comme les deux ailes qui permettent à l'esprit humain de s'élever vers la contemplation de la vérité ».

Les explications de la science restent limitées aux phénomènes. La question des fins ultimes reste donc ouverte, et comme le remarquait Karl Popper :

Une est une démarche prétendument scientifique qui ne respecte pas les canons de la méthode scientifique, dont celui de réfutabilité.
Ce terme, de connotation normative, est utilisé dans le but de dénoncer certaines disciplines en les démarquant des démarches au caractère scientifique reconnu. C'est au (sous l'influence du positivisme d'Auguste Comte, du scientisme et du matérialisme) que fut exclu du domaine de la science tout ce qui n'est pas vérifiable par la méthode expérimentale. Un ensemble de critères explique en quoi une théorie peut être classée comme pseudo-science. Karl Popper relègue ainsi la psychanalyse au rang de pseudo-science, au même titre que, par exemple, l'astrologie, la phrénologie ou la divination. Le critère de Popper est cependant contesté pour certaines disciplines ; pour la psychanalyse, parce que la psychanalyse ne prétend pas être une science exacte. De plus, Popper a été assez ambigu sur le statut de la théorie de l'évolution dans son système.

Les sceptiques, comme Richard Dawkins, Mario Bunge, Carl Sagan, Richard Feynman ou encore James Randi considèrent toute pseudo-science comme dangereuse. Le mouvement zététique œuvre quant à lui principalement à mettre à l'épreuve ceux qui affirment réaliser des actions scientifiquement inexplicables.

Si le terme normatif "pseudoscience" démarque les "vraies" sciences des "fausses" sciences, le terme protoscience (du grec πρῶτος, protos : premier, initial) inscrit les champs de recherche dans un continuum temporel : est protoscientifique ce qui "pourrait", dans l'avenir, être intégré dans la science, ou ne pas l'être. Le terme anglophone de fringe science désigne un domaine situé en marge de la science, entre la pseudo-science et la protoscience.

La "technique" . La technique couvre ainsi l'ensemble des procédés de fabrication, de maintenance, de gestion, de recyclage et, même d'élimination des déchets, qui utilisent des méthodes issues de connaissances scientifiques ou simplement des méthodes dictées par la pratique de certains métiers et l'innovation empirique. On peut alors parler d'art, dans son sens premier, ou de . La science est elle autre chose, une étude plus abstraite. Ainsi l'épistémologie examine entre autres les rapports entre la science et la technique, comme l'articulation entre l'abstrait et le savoir-faire. Néanmoins, historiquement, la technique est première. , explique le philosophe Bergson. Contrairement à la science, la technique n’a pas pour vocation d’interpréter le monde, elle est là pour le transformer, sa vocation est pratique et non théorique.

La technique est souvent considérée comme faisant partie intégrante de l’histoire des idées ou à l'histoire des sciences. Pourtant il faut bien admettre la possibilité d’une technique « a-scientifique », c'est-à-dire évoluant en dehors de tout corpus scientifique et que résume les paroles de Bertrand Gille : . La technique au sens de connaissance intuitive et empirique de la matière et des lois naturelles est ainsi la seule forme de connaissance pratique, et ce jusqu'au , époque où se développeront les théories et avec elles de nouvelles formes de connaissance axiomatisées.

Hervé Fischer parle, dans "La société sur le divan", publié en 2007, d'un nouveau courant artistique prenant la science et ses découvertes comme inspiration et utilisant les technologies telles que les bio-technologies, les manipulations génétiques, l'intelligence artificielle, la robotique, qui inspirent de plus en plus d'artistes. Par ailleurs, le thème de la science a été souvent à l'origine de tableaux ou de sculptures. Le mouvement du futurisme par exemple considère que le champ social et culturel doit se rationaliser. Enfin, les découvertes scientifiques aident les experts en Art. La connaissance de la désintégration du carbone 14 par exemple permet de dater les œuvres. Le laser permet de restaurer, sans abîmer les surfaces, les monuments. Le principe de la synthèse additive des couleurs restaure les autochromes. Les techniques d'analyse physico-chimiques permettent d'expliquer la composition des tableaux, voire de découvrir des palimpsestes. La radiographie permet de sonder l'intérieur d'objets ou de pièces sans polluer le milieu. La spectrographie est utilisée enfin pour dater et restaurer les vitraux.

La vulgarisation est le fait de rendre accessibles les découvertes ainsi que le monde scientifique à tous et dans un langage adapté.

La compréhension de la science par le grand public est l’objet d’études à part entière ; les auteurs parlent de « "Public Understanding of Science" » (expression consacrée en Grande-Bretagne, « "science literacy" » aux États-Unis) et de en France. Il s'agit du principal vecteur de la démocratisation et de la généralisation du savoir selon les sénateurs français Marie-Christine Blandin et Ivan Renard.

Dans nombre de démocraties, la vulgarisation de la science est au cœur de projets mêlant différents acteurs économiques, institutionnels et politiques. En France, l'Éducation nationale a ainsi pour mission de sensibiliser l'élève à la curiosité scientifique, au travers de conférences, de visites régulières ou d'ateliers d'expérimentation. La Cité des sciences et de l'industrie met à disposition de tous des expositions sur les découvertes scientifiques alors que les quelque trente centres de culture scientifique, technique et industrielle ont « pour mission de favoriser les échanges entre la communauté scientifique et le public. Cette mission s'inscrit dans une démarche de partage des savoirs, de citoyenneté active, permettant à chacun d'aborder les nouveaux enjeux liés à l'accroissement des connaissances ».

Le Futuroscope ou Vulcania ou le Palais de la découverte sont d'autres exemples de mise à disposition de tous des savoirs scientifiques. Les États-Unis possèdent également des institutions telles que l'Exploratorium de San Francisco, qui se veulent plus près d'une expérience accessible par les sens et où les enfants peuvent expérimenter. Le Québec a développé quant à lui le Centre des sciences de Montréal.

La vulgarisation se concrétise donc au travers d'institutions, de musées, mais aussi d'animations publiques comme les Nuits des étoiles par exemple, de revues, et de personnalités (Hubert Reeves pour l'astronomie), qu'énumère Bernard Schiele dans "Les territoires de la culture scientifique".

La valeur universelle de la science fait débat depuis le début du , tous les systèmes de connaissances n'étant pas forcément assujettis à la science. La croyance en une universalité de la science constitue le scientisme.

Le scientisme est une idéologie apparue au , selon laquelle la connaissance scientifique permettrait d'échapper à l'ignorance dans tous les domaines et donc, selon la formule d'Ernest Renan dans « l'Avenir de la science », d'.

Il s'agit donc d'une foi dans l'application des principes de la science dans tous les domaines. Nombre de détracteurs y voient une véritable religion de la science, particulièrement en Occident. Sous des acceptions moins techniques, le scientisme peut être associé à l'idée que seules les connaissances scientifiquement établies sont vraies. Il peut aussi renvoyer à un certain excès de confiance en la science qui se transformerait en dogme. Le courant zététique, qui s'inspire du scepticisme philosophique, essaye d'appréhender efficacement la réalité par le biais d'enquêtes et d'expériences s'appuyant sur la méthode scientifique et a pour objectif de contribuer à la formation chez chaque individu d'une capacité d'appropriation critique du savoir humain, est en ce sens une forme de scientisme.

Pour certains épistémologues, le scientisme prend de toutes autres formes. Robert Nadeau, en s’appuyant sur une étude réalisée en 1984, considère que la culture scolaire est constituée de qui formeraient une sorte de qui ne serait pas sans rapport avec une sorte de scientisme. Ces clichés tiennent soit à l'histoire de la science, résumée et réduite à des découvertes qui jalonnent le développement de la société, soit à des idées comme celles qui met en avant que les lois, et plus généralement les connaissances scientifiques, sont des vérités absolues et dernières, et que les preuves scientifiques sont non moins absolues et définitives alors que, selon les mots de Thomas Samuel Kuhn, elles ne cessent de subir révolutions et renversements.

Enfin, c'est surtout la sociologie de la connaissance, dans les années 1940 à 1970, qui a mis fin à l'hégémonie du scientisme. Les travaux de Ludwig Wittgenstein, Alexandre Koyré et Thomas Samuel Kuhn surtout ont démontré l'incohérence du positivisme. Les expériences ne constituent pas, en effet, des preuves absolues des théories et les paradigmes sont amenés à disparaître. Pour Paul Feyerabend, ce sont des forces politiques, institutionnelles et même militaires qui ont assuré à la science sa dominance, et qui la maintiennent encore dans cette position.

Pendant la Première Guerre mondiale, les sciences ont été utilisées par l'État afin de développer de nouvelles armes chimiques et de développer des études balistiques. C'est la naissance de l'économie de guerre, qui s'appuie sur des méthodes scientifiques. L', ou Organisation Scientifique du Travail de Frederick Winslow Taylor est ainsi un effort d'améliorer la productivité industrielle grâce à l'ordonnancement des tâches, permis notamment par le chronométrage. Néanmoins, c'est pendant la Seconde Guerre mondiale que la science est le plus utilisée à des fins militaires. Les armes secrètes de l'Allemagne nazie comme les V2 sont au centre des découvertes de cette époque.

Toutes les disciplines scientifiques sont ainsi dignes d'intérêt pour les gouvernements. Le kidnapping de scientifiques allemands à la fin de la guerre, soit par les Soviétiques, soit par les Américains, fait naître la notion de « guerre des cerveaux », qui culminera avec la course à l'armement de la Guerre froide. Cette période est en effet celle qui a le plus compté sur les découvertes scientifiques, notamment la bombe atomique, puis la bombe à hydrogène. De nombreuses disciplines naissent d'abord dans le domaine militaire, telle la cryptographie informatique ou la bactériologie, pour la guerre biologique. Amy Dahan et Dominique Pestre expliquent ainsi, à propos de cette période de recherches effrénées, qu'il s'agit d'un régime épistémologique particulier. Commentant leur livre, Loïc Petitgirard explique : . La conception de ce qu'on nomme alors le complexe militaro-industriel apparaît, en lien très intime avec le politique.

Dès 1945, avec la constatation de la montée des tensions due à l'opposition des blocs capitalistes et communistes, la guerre devient en elle-même l'objet d'une science : la polémologie. Le sociologue français Gaston Bouthoul (1896-1980), dans « le Phénomène guerre », en fonde les principes.

Enfin, si la science est par définition neutre, elle reste l'affaire d'hommes, sujets aux idéologies dominantes. Ainsi, selon les sociologues relativistes Barry Barnes et David Bloor de l'Université d'Édimbourg, les théories sont d'abord acceptées au sein du pouvoir politique. Une théorie s'imposerait alors non parce qu'elle est vraie mais parce qu'elle est défendue par les plus forts. En d'autres termes, la science serait, sinon une expression élitiste, une opinion majoritaire reconnue comme une vérité scientifique et le fait d'un groupe, ce que démontrent les travaux d'Harry Collins. La sociologie des sciences s'est ainsi beaucoup intéressée, dès les années 1970, à l'influence du contexte macro-social sur l'espace scientifique. Robert King Merton a montré, dans « Éléments de théorie et de méthode sociologique » (1965) les liens étroits entre le développement de la Royal Society de Londres, fondée en 1660, et l'éthique puritaine de ses acteurs. Pour lui, la vision du monde des protestants de l'époque a permis l'accroissement du champ scientifique.

Historiquement, la science et la religion ont longtemps été apparentées. Dans « Les Formes élémentaires de la vie religieuse » (1912), Émile Durkheim montre que les cadres de pensée scientifique comme la logique ou les notions de temps et d'espace trouvent leur origine dans les pensées religieuses et mythologiques.

La philosophie des sciences modernes a abouti à la nécessité pour la science et la religion de marquer leurs territoires. . Selon ce principe, la pensée religieuse et la pensée scientifiques doivent poursuivre des buts différents pour cohabiter. La science explique le fonctionnement de l'univers (le « comment ») tandis que la religion propose des croyances qui donnent un sens à l'univers (le « pourquoi »). En grande partie, cette division est un corollaire du critère de réfutabilité de Karl Popper : la science propose des énoncés qui peuvent être mis à l'épreuve des faits, et doivent l'être pour être acceptés ou refusés. La religion propose des énoncés qui doivent être crus sans pouvoir être vérifiés.

Les conflits entre la science et la religion se produisent dès lors que l'une des deux prétend répondre à la question dévolue à l'autre.

Cette violation peut se produire dans les deux sens. La religion empiète sur la science quand des personnes prétendent déduire des textes religieux des informations sur le fonctionnement du monde. Le conflit de ce type le plus évident est celui du créationnisme face à la théorie de l'évolution. Scientifiquement, la création de l'ensemble des êtres vivants en six jours n'est pas tenable. Mais différents courants religieux radicaux défendent l'exactitude du récit de la Genèse (depuis, l'Église catholique, par exemple, a résolu la contradiction apparente en déclarant que ce récit est métaphorique, ce qui assure de ne pas empiéter sur le domaine scientifique).

L'autre cas de violation est celui où on extrapole à partir de données scientifiques une vision du monde tout à fait irréfutable (au sens de Popper), empiétant sur le domaine du religieux. Dans le cadre du non-recouvrement, les propositions scientifiques doivent rester compatibles avec toutes les positions religieuses qui cherchent à donner du sens à l'univers (sauf celles qui violent elles-mêmes la démarcation). Albert Einstein et Paul Dirac utilisent le concept de Dieu en commentant la physique quantique, mais les résultats qu'ils établissent ne dépendent pas de son existence.

Le pape François, dans l'encyclique "Laudato si'" « sur la sauvegarde de la maison commune » (2015), estime cependant que « la science et la religion, qui proposent des approches différentes de la réalité, peuvent entrer dans un dialogue intense et fécond pour toutes deux ».

Si la science est avant tout une affaire de méthode, elle dépend aussi beaucoup du statut de ceux qui la font. L'ancêtre du chercheur reste, dans l'Antiquité, le scribe. Le terme de n'apparaît qu'au ; se distinguant du clerc et de l'humaniste. Au cette figure s'estompe et laisse place à celle du et du aux côtés desquels évoluent le et le . Aujourd'hui c'est la figure du qui domine selon les auteurs Yves Gingras, Peter Keating et Camille Limoges, dans leur « Du scribe au savant. Les porteurs du savoir, de l'Antiquité à la Révolution industrielle ». C'est la création d'institutions comme le Jardin royal des plantes médicinales ou l'Académie royale des sciences de Paris qui marquent l'avènement du statut de chercheur spécialisé au . Elles fournissent en effet des revenus et un cadre de recherche exceptionnels. C'est en Allemagne, avec Wilhelm von Humboldt, en 1809, que la recherche est affiliée aux Universités. Dès lors commence l'industrialisation de la production de chercheurs, qui accéléra la spécialisation du savoir. Depuis la Seconde Guerre mondiale, ce sont les instituts de recherche et les organismes gouvernementaux qui dominent, à travers la figure du chercheur fonctionnaire.

Les sociologues et anthropologues Bruno Latour, Steve Woolgar, Karin Knorr-Cetina ou encore Michael Lynch ont étudié l'espace scientifique, les laboratoires et les chercheurs. Latour s'est en particulier intéressé à la production du discours scientifique, qui semble suivre un processus de stabilisations progressives, ce qui permet aux énoncés d'acquérir de la crédibilité au fur et à mesure alors que Jean-François Sabouret et Paul Caro, dans « Chercher. Jours après jours, les aventuriers du savoir » présentent des portraits de chercheurs venant de tous les domaines et travaillant au quotidien.

La communauté scientifique désigne, dans un sens assez large, l'ensemble des chercheurs et autres personnalités dont les travaux ont pour objet les sciences et la recherche scientifique, selon des méthodes scientifiques. Parfois cette expression se réduit à un domaine scientifique particulier : la communauté des astrophysiciens pour l'astrophysique, par exemple. La sociologie des sciences s'intéresse à cette communauté, à la façon dont elle fonctionne et s'inscrit dans la société.

On peut parler de lorsqu'il s'agit d'une association d’érudits et de savants. Elle leur permet de se rencontrer, de partager, confronter et exposer le résultat de leurs recherches, de se confronter avec leurs pairs d'autres sociétés du même type ou du monde universitaire, spécialistes du même domaine, et le cas échéant, de diffuser leurs travaux via une revue, des conférences, séminaires, colloques, expositions et autres réunions scientifiques. Un congrès ou conférence scientifique est un événement qui vise à rassembler des chercheurs et ingénieurs d'un domaine pour faire état de leurs avancées. Cela permet également à des collègues géographiquement éloignés de nouer et d'entretenir des contacts. Les congrès se répètent généralement avec une périodicité fixée, le plus souvent annuelle.

La collaboration est de mise au sein de la communauté scientifique, en dépit de guerres internes et transnationales. Ainsi, l'outil du "peer review" (aussi appelé dans certains domaines universitaires) consiste à soumettre l’ouvrage ou les idées d’un auteur à l’analyse de confrères experts en la matière, permettant par là aux chercheurs d’accéder au niveau requis par leur discipline en partageant leur travail avec une personne bénéficiant d’une maîtrise dans le domaine.

La recherche scientifique désigne en premier lieu l’ensemble des actions entreprises en vue de produire et de développer les connaissances scientifiques. Par extension métonymique, la recherche scientifique désigne également le cadre social, économique, institutionnel et juridique de ces actions. Dans la majorité des pays finançant la recherche, elle est une institution à part entière, voire une instance ministérielle (comme en France, où elle fait partie du Ministère de l'Éducation Nationale et de la Recherche) car elle constitue un avantage géopolitique et social important pour un pays. Le prix Nobel (il en existe un pour chaque discipline scientifique promue) récompense ainsi la personnalité scientifique qui a le plus contribué, par ses recherches et celles de son équipe, au développement des connaissances.

Les « "Science studies" » sont un courant récent regroupant des études interdisciplinaires des sciences, au croisement de la sociologie, de l’anthropologie, de la philosophie ou de l’économie. Cette discipline s'occupe principalement de la science comme institution, orientant le débat vers une .

La sociologie des sciences vise à comprendre les logiques d'ordre sociologique à l'œuvre dans la production des connaissances scientifiques. Néanmoins, il s'agit d'une discipline encore récente et évoluant au sein de multiples positions épistémologiques ; Olivier Martin dit qu'. Dans les années 1960 et 1970, une grande part de ces études s’inscrivait dans le courant structuraliste. Mais, depuis le début des années 1980, les sciences sociales cherchent à dépasser l’étude de l’institution « science » pour aborder l’analyse du contenu scientifique. La sociologie du , concept créé par Pierre Bourdieu, porte ainsi une attention particulière aux institutions scientifiques, au travail concret des chercheurs, à la structuration des communautés scientifiques, aux normes et règles guidant l'activité scientifique surtout. Il ne faut cependant pas la confondre avec l'étude des relations entre science et société, quand bien même ces relations peuvent être un objet d'étude des sociologues des sciences. Elle est en effet plus proche de l'épistémologie.

Le de la sociologie des sciences est Robert K. Merton qui, le premier, vers 1940, considère la science comme une formant un ensemble qu'il appelle l' (les principes moraux dirigeant le savant) et dont les règles sont censées guider les pratiques des individus et assurer à la communauté son autonomie (Merton la dit égalitaire, libérale et démocratique). Dans un article de 1942, intitulé "The Normative Structure of Science", il cite quatre normes régissant la sociologie de la science : l'universalisme, le communalisme, le désintéressement, le scepticisme organisé. Ce que cherche Merton, c'est analyser les conditions de production de discours scientifiques, alors que d'autres sociologues, après lui, vont viser à expliquer sociologiquement le contenu de la science. Pierre Duhem s'attacha lui à analyser le champ scientifique du point de vue constructiviste. À la suite des travaux de Thomas Samuel Kuhn, les sociologues dénoncèrent la distinction portant sur la méthode mise en œuvre et firent porter leurs investigations sur le processus de production des connaissances lui-même.

Si la philosophie des sciences se fonde en grande partie sur le discours et la démonstration scientifique d'une part, sur son historicité d'autre part, pour Ian Hacking, elle doit étudier aussi le style du laboratoire. Dans « Concevoir et expérimenter », il estime que la philosophie des sciences, loin de se cantonner aux théories qui représentent le monde, doit aussi analyser les pratiques scientifiques qui le transforment. Le sociologue américain Joseph Ben David a ainsi étudié la sociologie de la connaissance (« "sociology of scientific knowledge" ») dans ses « Éléments d'une sociologie historique des sciences » (1997).

L’ d’une science à une autre est l'usage qu’on fait des principes ou des procédés d’une science pour étendre et perfectionner une autre science. L' est d'abord une méthode, une technique, un moyen nouveau par lequel il est possible de résoudre un problème pratique donné. Le concept est très proche de celui d'une innovation. Par exemple, Alastair Pilkington a inventé le procédé de fabrication du verre plat sur bain d'étain dont on dit qu'il s'agit d'une innovation technologique majeure.

Une se distingue d'une invention ou d'une découverte dans la mesure où elle s'inscrit dans une perspective applicative. L'une et l'autre posent des enjeux majeurs à l'économie. Dans les pays développés, les guerres économiques reposent sur la capacité à prévoir, gérer, susciter et conserver les applications et les innovations, par le brevet notamment. Pour les économistes classiques, l'innovation est réputée être l'un des moyens d'acquérir un avantage compétitif en répondant aux besoins du marché et à la stratégie d'entreprise. Innover, c'est par exemple être plus efficient, et/ou créer de nouveaux produits ou service, ou de nouveaux moyens d'y accéder.

Ce sont tout d'abord les sociologues de la science Norman Storer et Warren Hagstrom, aux États-Unis, puis Gérard Lemaine et Benjamin Matalon en France, qui proposent une grille de lecture pour le champ économique des disciplines scientifiques. Ils envisagent en effet la science comme un système d'échange semblable à un marché sauf que la nature des biens échangés est du domaine du savoir et de la connaissance. Il y existe même une sorte de loi de la concurrence car si le scientifique ne publie pas, il ne peut prétendre voir ses fonds de recherche être reconduits l'année suivante. Cet esprit de compétition, selon Olivier Martin . Mais c'est surtout le sociologue Pierre Bourdieu qui a su analyser l'économie du champ scientifique. Dans son article intitulé « le champ scientifique », dans les "Actes de la recherche en sciences sociales", il indique que la science obéit aux lois du marché économique sauf que le capital est dit « symbolique » (ce sont les titres, les diplômes, les postes ou les subventions par exemple). Par ailleurs, ce capital symbolique dépend de l'intérêt général et institutionnel : ainsi toutes les recherches se valent mais les plus en vue sont favorisées. Enfin, le milieu scientifique est dominé par des relations de pouvoir, politique et communautaire.



Généralités

Actualité


</doc>
<doc id="15769" url="https://fr.wikipedia.org/wiki?curid=15769" title="Ammonium">
Ammonium

L'ion ammonium de formule brute NH est un ion polyatomique de charge électrique positive. Ce cation polyatomique possède une structure tétraédrique, l'atome d'azote N occupant le centre et les quatre atomes d'hydrogène occupant les sommets équivalents du tétraèdre. Il est obtenu par protonation de l'ammoniac (NH) ; il est parfois présenté comme une molécule d'ammoniac ionisée.

L'ion ammonium est présent dans de nombreux produits nettoyants et désinfectants, à commencer par l'ammoniaque. Avant la découverte de sa véritable structure par les chimistes, il était l'analogue d'un métal alcalin ou d'un alcali. D'où par exemple la désignation d'alcali volatil de l'ammoniaque. Son usage est antique, il est présent dans le "sal ammoniac" , c'est-à-dire le corps minéral naturel salmiac. Il est présent aussi dans le sulfure d'ammonium , ancien réactif prisé par l'analyse chimique.

La mise en solution de NH dans l'eau correspond à l'équation suivante :
formula_1.
Alors que la préparation d'une solution aqueuse d'hydroxyde d'ammonium (ammoniaque) est :
formula_2.
Ce sont des réactions acido-basiques, d'où le couple acide/base suivant : formula_3. 

Ce couple a une constante d'acidité Ka = ; on dit donc que la constante de dissociation acide de est p"K" = 9,25. Dans l'eau, l'ammoniac se dissocie partiellement et forme une solution ionique qui conduit l'électricité.

Dans le cas général, on a :
formula_4
Il s'agit d'une réaction réversible, qui forme l'acide très faible de Brönsted ammonium. Le taux d'ammonium formé dépend du pH si on travaille en solution. Si on travaille avec de la vapeur d'ammoniac, elle peut réagir avec HCl pour former le complexe formula_5.

L'ammonium forme souvent un sel avec un anion. La plupart des sels d'ammonium sont solubles dans l'eau.

Chaque atome d'hydrogène de l'ion ammonium peut être remplacé « "substitué" » par un groupe alkyle ou par un autre groupe organique constitué de chaînes carbonées ou d'autres substituants pour former un ion dit "ammonium substitué", « "ion ammonium" » ou ions "ammonium" « "primaire" », « "secondaire" », « "tertiaire" » ou « "quaternaire" » (selon le nombre d'atomes d'hydrogène substitués).
Ces ions sont les acides conjugués d'amines, sauf pour les ammoniums quaternaires qui ne peuvent pas céder de proton.
Hormis l'ammonium quaternaire, ils existent en équilibre avec leurs amines remplacées, selon le pH.

La formule est de type , où un ou plusieurs atomes d'hydrogène sont remplacés par un radical organique (groupe représenté par le symbole R).
Un exemple d'une réaction de formation d'un ion ammonium est celle entre la diméthylamine, , et un acide, pour donner le cation diméthylammonium, :
Le "cation ammonium quaternaire" présente quatre groupes organiques liés à l'atome d'azote (N). 
Ils n'ont plus d'atome d'hydrogène lié à l'atome d'azote pouvant jouer le rôle de base, et sont donc chargés de manière permanente. 
Ces cations, tels que le cation "tétra-n-butylammonium", sont parfois utilisés pour remplacer les ions de sodium ou de potassium pour augmenter la solubilité d'un composé dans l'ensemble des solvants organiques, selon le principe HSAB, ce qui leur donne une importante toxicologique et écotoxicologique. Pour la même raison, ils sont aussi utilisés comme catalyseurs de transfert de phase.

Les sels d'ammonium et l'ammoniac ne devraient pas être utilisés en piscine car pouvant former le trichlorure d'azote () avec le chlore. Les hydrogènes des sels d'ammonium et des amides primaires (exemple : urée) ou secondaires peuvent aussi être remplacés par du chlore.

Le couple Acide-Base concerné est :

La demi-équation Acide-Base est donc :

Les demi-équations Acide-Base sont :


L'équation Acide-Base de dilution est donc :

Plus simplement :
D'où l'équation Acide-Base de solvatation :

L'ion ammonium est généré par la réaction de l'ammoniaque (une base faible) avec un acide de Brønsted (donneurs de protons) :

La paire libre d'électrons de l'atome d'azote dans l'ammoniac est représentée comme une paire de points. Cette paire d'électrons forme la liaison avec un proton (H).

L'ion ammonium est un acide conjugué relativement fort, qui réagit avec les "bases de Brønsted" pour revenir à l'état de molécule d'ammoniac non chargé :

Lorsque l'ammoniac est dissous dans de l'eau, une quantité importante de celui-ci réagit avec l'ion hydronium de l'eau pour donner des ions "ammonium" :

Le taux d'ammoniac converti en ion ammonium dépend du pH de la solution. 
Si le pH est bas (c'est-à-dire s'il y a une forte concentration en ions hydronium), les changements s'équilibrent en produisant une plus grande conversion d'ammoniac (par protonation) en ions ammonium. Si au contraire le pH est élevé (la concentration en ions hydronium est faible), l'équilibre est obtenu avec captage de protons de l'ion ammonium par les ions hydroxyde, générant de l'ammoniac.

La formation de composés d'ammonium peut également se produire en phase vapeur, par exemple, lorsque la vapeur d'ammoniac entre en contact avec la vapeur de chlorure d'hydrogène (HCl), un nuage blanc de forme de chlorure d'ammonium qui se déposera éventuellement en une fine couche blanche sur les surfaces.

Les cations "ammonium" ressemblent à des ions de métal alcalin tels que ceux du sodium, Na, ou du potassium, K, et peuvent être trouvés dans des sels comme le bicarbonate d'ammonium, chlorure d'ammonium ou nitrate d'ammonium. 

La plupart des sels d'ammonium simples sont très solubles dans l'eau.

Ces ions ammonium ont une grande importance en chimie car :

Dans l'ion ammonium, l'atome d'azote forme quatre liaisons covalentes (dont une liaison covalente de coordination), au lieu de trois comme dans l'ammoniaque, formant une structure qui est isoélectronique (électroniquement semblable) à celle d'une molécule de méthane.


</doc>
<doc id="15770" url="https://fr.wikipedia.org/wiki?curid=15770" title="Pharmacophore">
Pharmacophore

Un pharmacophore est constitué par une partie pharmacologiquement active d'une molécule servant de modèle. Les pharmacophores sont donc des ensembles d'atomes actifs utilisés dans la conception de médicaments. Le pharmacophore est une représentation géométrique idéalisée, seule la modélisation en 3D peut permettre une utilisation optimale pour la création de nouveaux médicaments.

Un pharmacophore est l'ensemble des groupements fonctionnels disposés selon un arrangement spatial adéquat, assurant la fixation du médicament sur le récepteur et donc capable d'induire la réponse physiologique. Le squelette de la molécule assure le maintien de cet échafaudage et ne joue a priori pas de rôle déterminant dans le déclenchement de la réponse (pour autant qu'il n'empêche pas l'interaction pour raisons d'encombrement stérique). En théorie les médicaments qui provoquent une réponse physiologique donnée sur un récepteur donné devraient posséder le même pharmacophore.


</doc>
<doc id="15771" url="https://fr.wikipedia.org/wiki?curid=15771" title="Phényléthylamine">
Phényléthylamine

Les phényléthylamines (PEA) sont des alcaloïdes monoaminés. Dans le cerveau, elles jouent le rôle de neurotransmetteurs. Dans la nature, les phényléthylamines sont synthétisées à partir de phénylalanine, un acide aminé. On les retrouve également telles quelles dans les aliments ayant subi une fermentation, comme le fromage. Ce sont des liquides incolores qui forment un sel avec le dioxyde de carbone () au contact de l'air. Les phényléthylamines d'origine alimentaire pourraient avoir des effets psychoactifs, mais leur catabolisme rapide par l'enzyme MAO-B empêche des concentrations élevées.

Les phényléthylamines substituées constituent une branche et diverses classes de composés qui peuvent être des alcaloïdes, des hormones, des neurotransmetteurs, des stimulants divers, des produits hallucinogènes, entactogènes, anorexigènes, bronchodilatateurs ou antidépresseurs.

La structure des phényléthylamines peut être retrouvée dans la MDMA, la mescaline et les amphétamines de manière générale. Le chocolat en contient aussi. Il est cependant suspecté que cette phényléthylamine soit dégradée par la digestion et n'atteigne jamais le système circulatoire.

Les phényléthylamines substituées modifient l'anneau phényl et le groupe aminé :



</doc>
<doc id="15772" url="https://fr.wikipedia.org/wiki?curid=15772" title="Traité sur le fonctionnement de l'Union européenne">
Traité sur le fonctionnement de l'Union européenne

Le Traité sur le fonctionnement de l'Union européenne (TFUE), aussi appelé traité de Rome, est l'un des deux traités fondamentaux des institutions politiques de l'Union européenne avec le traité sur l'Union européenne. Il portait à sa création le le nom de traité instituant la Communauté économique européenne, jusqu'à la signature du traité sur l'Union européenne le qui en modifia son contenu et le renomma en traité instituant la Communauté européenne. Il fut à nouveau modifié en profondeur à la signature du traité de Lisbonne le et devint le traité sur le fonctionnement de l'Union européenne.

Nommé à l'origine « Traité instituant la Communauté économique européenne », il a constitué l’acte fondateur de la Communauté économique européenne (CEE). Il a été signé le dans la salle des Horaces et des Curiaces du Capitole à Rome, par l’Allemagne, la France, l’Italie et les trois pays du Benelux : Belgique, Luxembourg et Pays-Bas, les délégations ayant la volonté de s'engager dans un processus irréversible. Selon son préambule, le traité vise notamment à « établir les fondements d'une union sans cesse plus étroite entre les peuples européens ».

Le même jour, les mêmes pays ont signé le traité Euratom.

Toutes les ratifications ayant été acquises à la fin de l'année 1957, le traité a pu entrer en vigueur dès le . Il a institué le marché commun européen et a défini les bases de la politique agricole commune mise en œuvre en 1962.

Le Traité de Maastricht du a renommé la Communauté économique européenne en Communauté européenne. Le nom du traité est donc devenu officiellement : « Traité instituant la Communauté européenne ».

Le Traité a été modifié à plusieurs reprises.


Le traité sur le fonctionnement de l'Union comprend sept parties, suivies de trente-sept protocoles et deux annexes. Par ailleurs, 65 déclarations d'États membres ont été annexées à l'acte final de la Conférence intergouvernementale qui a adopté le traité de Lisbonne.

La première partie contient :

La deuxième partie comprend des dispositions relatives au principe de non-discrimination au sein de l'Union et à la citoyenneté de l'Union (articles à ).

La troisième partie apporte un fondement juridique aux grandes politiques et actions de l'Union (articles à ) : marché intérieur, libre circulation des marchandises, agriculture et pêche, libre circulation des personnes, des services et des capitaux, espace de liberté, de sécurité et de justice, transports, concurrence et fiscalité, politique économique et monétaire, emploi, politique sociale, éducation et formation, culture, santé publique, protection des consommateurs, Réseau transeuropéen de transport, industrie, politique de cohésion, recherche et développement, environnement, énergie, tourisme, protection civile, coopération administrative.

La quatrième partie (articles à ) décrit les relations entre l'Union européenne et certains territoires extra-européens liés au Danemark, à la France, aux Pays-Bas et au Royaume-Uni. Ces pays et territoires d'outre-mer ne doivent pas être confondus avec les régions ultrapériphériques qui, bien que situées loin du continent européen, font partie de l'Union.

La cinquième partie (articles à ) décrit notamment la politique commerciale commune, la coopération avec les pays tiers et l'aide humanitaire et les relations avec les pays et organismes internationaux tiers. 

La politique européenne de sécurité et de défense est décrite dans le traité UE.

La sixième partie regroupe les dispositions relatives :

La septième partie fonde la capacité juridique de l'Union et contient diverses dispositions générales et finales (articles à ).

Des protocoles, annexes et déclarations complètent le TFUE et le traité sur l'Union européenne. Aux termes de l'article du traité sur l'Union européenne, les protocoles et annexes ont la même valeur juridique que le traité lui-même.
Onze odonymes commémorent en France et en Belgique la signature du traité de Rome :



Texte du traité :

Autres liens :


</doc>
<doc id="15774" url="https://fr.wikipedia.org/wiki?curid=15774" title="Association des nations de l'Asie du Sud-Est">
Association des nations de l'Asie du Sud-Est

L’Association des nations de l'Asie du Sud-Est (ANASE ou ASEAN) est une organisation politique, économique et culturelle regroupant dix pays d'Asie du Sud-Est. Elle a été fondée en 1967 à Bangkok (Thaïlande) par cinq pays dans le contexte de la guerre froide pour faire barrage aux mouvements communistes, développer la croissance et le développement et assurer la stabilité dans la région. Aujourd'hui, l'association a pour but de renforcer la coopération et l'assistance mutuelle entre ses membres, d'offrir un espace pour régler les problèmes régionaux et peser en commun dans les négociations internationales. Un sommet est organisé chaque année au mois de novembre. Son secrétariat général est installé à Jakarta (Indonésie).

En 2013, les pays de cette organisation représentaient :

L'ASEAN a été fondée par cinq États, principalement de l'Asie du Sud-Est maritime :
Philippines, Indonésie, Malaisie, Singapour, et Thaïlande. Le Brunei les rejoint 6 jours après son indépendance du Royaume-Uni le 8 janvier 1984. Le Viêt Nam entre en 1995, suivi du Laos et de la Birmanie (actuel Myanmar) le 23 juillet 1997 et du Cambodge le 30 avril 1999.

La Papouasie-Nouvelle-Guinée a le statut d'observateur depuis 1976 et réfléchit à une possible candidature . Le 23 juillet 2006, le Timor oriental a posé sa candidature et pourrait devenir membre d'ici à 2012. L'Australie est aussi intéressée mais .


Possibilité d'adhésion :

L'ASEAN a été précédée par l'organisation appelée Association of Southeast Asia (ASA), une alliance entre les Philippines, la Malaisie et la Thaïlande formée en 1961.

L'ASEAN se forme le 8 août 1967 quand les ministres des affaires étrangères de cinq pays (Indonésie, Malaisie, les Philippines, Singapour et Thaïlande) se rencontrent à Bangkok où ils signent la déclaration ASEAN communément appelée Déclaration de Bangkok. Les cinq ministres des affaires étrangères, Adam Malik pour l'Indonésie ; pour les Philippines ; Tun Abdul Razak pour la Malaisie, S. Rajaratnam pour Singapour et Thanat Khoman pour la Thaïlande sont considérés comme les pères fondateurs de l'organisation. Cette création peut surprendre si on considère les différences de taille, de culture, d'expérience coloniale et les tensions dans la région depuis la fin de la Seconde Guerre mondiale. Elle a abouti grâce à la diplomatie thaïlandaise qui s'est appuyée sur l'ASA.

Le souhait originel était de promouvoir la croissance, le développement et la coopération dans les domaines économiques, sociaux, culturels, scientifiques et administratifs, ainsi que la stabilité et la paix dans la région.

Deux facteurs expliquent cette nouvelle dynamique : Premièrement, la volonté de lutte contre la subversion communiste par le développement économique et social. Deuxièmement la volonté que la région ne soit pas utilisée comme terrain de bataille de la guerre froide, notamment par une extension de la guerre du Viêt Nam. L'ASEAN n'a jamais été envisagée comme une alliance militaire.

L'ASEAN reste minimale durant la première décennie et s'articule principalement autour de la rencontre annuelle des ministres des affaires étrangères. L'organisation remplit néanmoins des fonctions importantes.

En 1971, ils signent la Déclaration de Kuala Lumpur qui proclame la région neutre et indépendante vis-à-vis des puissances extérieures, souhaitant éviter d'être impliqué dans la guerre froide.

La première rencontre des chefs de gouvernement a lieu avec le Sommet de Bali de 1976 qui aboutit au Treaty of Amity and Cooperation in Southeast Asia et à la Declaration of ASEAN Concord qui affirment les principes de non-ingérence dans les affaires intérieures des pays membres, la résolution des conflits par des moyens pacifiques, le développement de l'identité régionale et la poursuite de la coopération pour le développement économique et social.

Ces déclarations traduisent le souhait des pays membres de coexister pacifiquement avec leurs voisins communistes : le Cambodge, le Laos et surtout le Viêt Nam unifié l'année précédente. Ces États signent le Treaty of Amity and Cooperation in Southeast Asia à l'invitation de l'ASEAN. Une seconde rencontre en 1977 à Kuala Lumpur réaffirme la politique de 1976.

Fin décembre 1978, le Viêt Nam envahit le Cambodge des Khmers rouges qu'il occupera pendant une décennie. Cette action va à l'encontre du "Treaty of Amity and Cooperation in Southeast Asia" et menace la stabilité de la région.

Les pays de l'ASEAN sont divisés entre d'une part la Thaïlande et Singapour souhaitant opposer une réponse forte et d'autre part la Malaisie et l'Indonésie qui souhaitent une réponse modérée justifiée par leurs craintes que la Chine profite du trouble pour intervenir et renforcer son influence dans la région.

Les pays membres cherchent à résoudre la crise en passant par l'ASEAN. Un accord émerge entre eux, consistant en l'isolement du Viêt Nam tout en offrant au Viêt Nam la possibilité de négocier pour retirer ses troupes du Cambodge. Ils convainquent les institutions internationales et les pays occidentaux d'exercer une pression diplomatique et financière sur le Viêt Nam pour permettre, entre autres facteurs, de mettre fin à la crise. L'opposition commune à l'occupation du Viêt Nam permet aux pays de l'ASEAN de consolider leurs liens politiques. Elle acquiert ainsi une stature et une crédibilité dans la communauté internationale, ce qui, en retour, renforce les pays membres.

Le bloc s'agrandit avec l'entrée du Brunei le 8 janvier 1984, une semaine après son indépendance.

À côté du renforcement politique de l'ASEAN, les pays membres connaissent une forte croissance économique grâce au flot d'investissement direct provenant du Japon qui y installe des usines, suivi par les entreprises d'autres pays qui cherchent à rester concurrentielles (Corée du Sud, Hong Kong, Taïwan, États-Unis, Allemagne, Royaume-Uni).

Les grandes puissances commencent à considérer les pays de l'ASEAN comme des partenaires commerciaux. De plus les pays d'Afrique et d'Amérique latine se tournent vers eux pour trouver un modèle de développement économique.

En 1989 est créée la Coopération économique pour l'Asie-Pacifique qui réunit les pays du Pacifique (pays de l'ASEAN, EU, Japon, Canada et Nouvelle-Zélande).

En 1994 est créé le Forum Régional ASEAN qui permet de discuter des questions de sécurité d'Asie du Sud-Est. L'ASEAN réussit à rassembler les grandes puissances et les pays membres sont ainsi garantis d'être au centre et de peser sur les débats sur la sécurité de la région.

La fin de la guerre froide en Asie du Sud-Est peut être datée du retrait de l'armée vietnamienne du Cambodge en 1989. La crainte du Viêt Nam constituait le ciment de l'ASEAN. Les pays membres cherchent donc de nouvelles directions pour l'ASEAN qui se traduisent au Sommet de Singapour de 1992 par deux initiatives, l'AFTA et l'élargissement vers les pays de l'ex-Indochine.

Le projet de coopération économique remonte à la fondation de l'ASEAN, mais ne démarre sérieusement qu'en 1991 sur l'initiative thaïlandaise de créer la zone de libre-échange des pays de l'ASEAN. L'AFTA doit servir à augmenter les investissements dans la région et à poursuivre la libéralisation des économies des pays membres. Les négociations et la crise financière de 1997 font que l'accord n'est signé qu'en 2002. Il diminue radicalement les barrières douanières.

Les négociations pour aboutir à l'ASEAN 10 débutent après le sommet de Singapour et aboutissent à l'entrée du Viêt Nam (1995), puis du Laos et de la Birmanie (1997) et enfin du Cambodge (1999). L'ASEAN regroupe alors la quasi-totalité des États d'Asie du Sud-Est. Elle renforce son poids démographique grâce aux 80 millions d'habitants du Viêt Nam, offre un grand marché pour l'AFTA, améliore la stabilité de la région et améliore la visibilité internationale de la région.

L'ASEAN élargie connaît cependant des problèmes et des divisions entre les pays fondateurs et les nouveaux arrivants. Les premiers sont en partie des démocraties (Thaïlande, Philippines, Indonésie), sont plus riches et veulent accélérer l'intégration alors que les seconds sont parfois autoritaires (Birmanie et Viêt Nam), plus pauvres et souhaitent le statu quo dans les institutions. En particulier, ils souhaitent que soit maintenue la politique de non-ingérence et préfère que l'accent soit mis sur l'aide et l'assistance et non sur le commerce. Ces divisions affaiblissent l'ASEAN dans les négociations internationales et donnent le sentiment à la fin de la décennie que l'organisation stagne.

La crise économique asiatique débute par une crise monétaire, avec la dévaluation du baht thaïlandais en juillet 1997 et se répand en Indonésie et en Malaisie et dans une moindre mesure aux autres pays de l'ASEAN. L'intégration des économies d'Asie du Sud-Est, l'action contre-productive du FMI et des problèmes structurels transforment la crise monétaire en grave crise financière qui atteint toute l'Asie.

Parallèlement, émerge l'ASEAN Plus Trois (APT) à partir d'une idée de Singapour en 1995. Il comprend les pays de l'ASEAN ainsi que la Chine, le Japon et la Corée du Sud. Il prend ses origines dans la préparation de la première Réunion Asie-Europe (ASEM).

La première rencontre APT a lieu informellement en 1997 lors du sommet de Singapour, puis à tous les sommets de l'ASEAN afin d'établir des positions communes en vue de l'ASEM.

En mai 2000 à Chiang Mai, ils s'accordent pour lutter contre une nouvelle crise financière. En 2001, la Chine lance une initiative majeure destinée à établir une Zone de libre échange entre elle et l'ASEAN. Un accord cadre est signé en 2002 en vue d'établir la zone en 2010 pour l'ASEAN 6 et en 2015 pour l'ASEAN au complet. Des initiatives similaires ont été lancées en réponse par le Japon et la Corée. L'APT a également d'autres projets comme le développement de la région du bassin du Mékong, la formation dans les technologies environnementales, la promotion du tourisme.

À la fin des années 2000 les pays de l'ASEAN réalisaient plus de 50 % de leur commerce extérieur avec l'ASEAN + 3, ce qui représente un niveau d'intégration supérieur à celui de l'ALENA et proche des 65 % atteints par les quinze États membres de l'UE entre 1995 et 2004. En 2005 près de 70 % des investissements directs étrangers dans les quinze États ou régions d'Asie orientale (ASEAN + 3, Hong Kong et Taïwan) provenaient également de la région, un niveau d'intégration comparable à celui alors observé au sein de l'UE.

L'APT permet aux pays de l'ASEAN de se renforcer dans les négociations internationales notamment à l'OMC pour contrebalancer l'influence de l'UE et de l'ALENA.

La question du terrorisme islamiste émerge après les attentats du 11 septembre 2001 contre le World Trade Center. L'ASEAN a signé trois accords antiterroristes avec la Chine, le Japon et les États-Unis. Ce dernier est le plus important des trois et a été signé .

L'attentat de Bali du 12 octobre 2002 accroît la pression sur les pays de l'ASEAN. Ils craignent pour leur économie, notamment par une baisse du tourisme et des investissements.

Au sommet de janvier 2007, ils ont signé un pacte antiterroriste qui facilitera les procédures d'extradition régionale.

L'ASEAN est composée d'une présidence tournante qui comprend le sommet des chefs d'État et de Gouvernement ASEAN, les conférences ministérielles des États membres, un comité permanent qui se réunit tous les mois et des commissions spécialisées chargées des questions maritimes, de transport, d'aviation, du commerce et de l'industrie, des télécommunications, etc.

Le secrétariat général n'a qu'une fonction administrative, les décisions sont prises en réunion par les représentants des pays membres.

L'ASEAN tient des sommets où les chefs de gouvernement de chaque pays membre discutent des questions régionales. D'autres rencontres ont lieu avec des pays non membres de l'organisation.

Le premier sommet se tient à Bali en Indonésie en 1976. Au de 1987 de Manille, il est décidé qu'il aura lieu tous les cinq ans. Le se tient donc à Singapour en 1992 où les dirigeants décident de se réunir tous les trois ans. En 2001, les sommets deviennent annuels. Les pays accueillent le sommet de l'ASEAN par ordre alphabétique, à l'exception de la Birmanie qui a renoncé à ce droit en 2006-2007 devant les pressions des États-Unis et de l'Union européenne (elle fut remplacée par les Philippines). Chaque pays préside à tour de rôle l'organisation pour l'année civile.

Le sommet dure trois jours et se compose généralement de :


À côté de ces rencontres, d'autres réunions ont lieu. Elles incluent la rencontre annuelle ministérielle de l'ASEAN ainsi que d'autres rencontres qui se concentrent sur des sujets spécifiques comme la défense ou l'environnement où les ministres discutent et non les chefs de gouvernement. Il existe des centres tels que le Southeast Asian Fisheries Development Center.

Le sommet de l'Asie de l'Est (EAS) est un forum asiatique annuel regroupant les chefs d’État de 16 pays d'Asie de l'Est avec l'ASEAN en position de meneur. La Russie a posé sa candidature pour être membre et a le statut d'observateur. Le premier sommet s'est tenu à Kuala Lumpur le 14 décembre 2005.
L'ASEAN Regional Forum (ARF) est le premier grand forum multilatéral de la région pour des consultations officielles sur les questions de sécurité en Asie Pacifique. Initié en 1993, il regroupe désormais 26 membres.

L'ASEAN Plus Trois est une rencontre entre l'ASEAN, la République populaire de Chine, le Japon et la Corée du Sud qui se tient durant les sommets de l'ASEAN.

Le Dialogue Asie-Europe (ASEM) est un processus de dialogue informel créé en 1996, réunissant l'Union européenne et le groupe ASEAN + 3.

Le sommet ASEAN-Russie est une rencontre entre les chefs d’État de l'ASEAN et le président de la Russie.

La zone de libre-échange de l'ASEAN (AFTA) est un accord entre les nations de l'ASEAN.

AIPO (ASEAN Interparliamentary Organisation) est une organisation parlementaire régionale, lancée en 1977, comprenant des délégations des Parlements des États de l'ASEAN (le sultanat de Brunei, qui n'a pas de Parlement, est membre de l'ASEAN, mais pas de l'AIPO).
L'AIPO a laissé place en 2007 à l'AIPA (ASEAN Interparliamentary Assembly) lors de la session d'avril à Kuala Lumpur. Cette modification a été conçue comme une intégration nouvelle de la coopération inter-parlementaire dans la région.

L'organisation accueille des activités en vue d'améliorer l'intégration régionale.

Le S.E.A. Write Award est une récompense donnée aux écrivains et poètes d'Asie du Sud-Est depuis 1979. La récompense est donnée pour une œuvre spécifique ou pour l'ensemble de l'œuvre d'un auteur.

ASAIHL ou Association of Southeast Asian Institutions of Higher Learning est une ONG créée en 1956 qui cherche à renforcer les institutions d'enseignement supérieur ; en particulier pour l'enseignement, la recherche et le service public, avec l'intention de cultiver l'identité régionale.

ASEAN Heritage Park est une liste de parcs naturels créée en 1984 puis relancée en 2004. Elle a pour but de protéger les trésors naturels de la région. Elle comprend 35 parcs.

Les Jeux d'Asie du Sud-Est ("Southeast Asian Games", abrégés SEA Games), sont une compétition multisports qui a lieu tous les deux ans et auxquels participent 11 pays. Les jeux sont organisés par la Fédération des Jeux d'Asie du Sud-Est et supervisés par le Comité international olympique et le Conseil Olympique d'Asie.

Le Championnat de l'ASEAN de football ("ASEAN Football Championship") est une compétition sportive internationale opposant les sélections nationales de football de l'association. Cette compétition est organisée par la fédération de l'ASEAN de Football, accréditée par la FIFA. Elle a débuté en 1996 sous le nom Tiger Cup.

Les ASEAN ParaGames (Jeux sportifs d'Asie du Sud-Est pour handicapés) sont une rencontre multisports pour athlètes handicapés auxquels participent 11 pays d'Asie du Sud-Est qui a lieu tous les deux ans.





</doc>
<doc id="15776" url="https://fr.wikipedia.org/wiki?curid=15776" title="Dévaluation">
Dévaluation

Une monnaie subit une dévaluation lorsque les autorités monétaires décident d'abaisser son taux de change par rapport à une monnaie de référence, ou un panier de monnaie. La dernière en France date de 1983. Le contraire est une « réévaluation », également décidée par les autorités monétaires.

Lorsque la valeur de la monnaie baisse sur le marché des changes, sans décision officielle, on parle simplement de dépréciation, le contraire étant une "appréciation". Différentes causes sont possibles : récession, déficit commercial, émission de monnaie par la banque centrale.

Le système monétaire européen était un régime de changes fixes autorisant une légère dépréciation des monnaies, limitée à 2,5 %. Cette limite a été fixée à 15 %, en juillet 1993, lorsque les autorités monétaires ont reconnu que la spéculation gagnait systématiquement, les banques centrales n'ayant pas assez de réserves de change pour empêcher que la dépréciation devienne dévaluation.

Dans un régime de change fixe, les autorités monétaires s'engagent à assurer la conversion de la monnaie à un taux de change défini. Elles disposent pour cela de réserves de change. 

Mais si ces réserves ne suffisent pas, le taux de change n'est plus tenable. Les autorités monétaires pratiquent alors des dévaluations à titre préventif, pour éviter de perdre toutes leurs réserves de change. Le cas s'est produit à maintes reprises après la création du système monétaire européen, qui a coïncidé avec celle des eurodollars et le choc pétrolier de 1974, générant une forte spéculation sur les monnaies, qui a redoublé après le choc pétrolier de 1980 puis la réunification allemande de 1990.

La dévaluation peut avoir un autre motif : servir la politique économique pour relancer la croissance économique, par la relance des exportations et le rééquilibrage de la balance commerciale.

La dévaluation vise à augmenter la compétitivité économique, en rétablissant un équilibre, par une correction du déséquilibre étant apparu (déficit commercial). Les effets prévisibles sont de deux natures :

Ces effets contradictoires sont résumés dans la courbe en J : la dévaluation cause d'abord une brève dégradation de la balance commerciale (effet prix, dans la partie gauche du J), avant de permettre une amélioration d'une plus grande ampleur (effet volume, dans la partie droite du J).

Sur le plan financier, la dévaluation pénalise les investisseurs étrangers qui détiennent des emprunts publics et des actions. Historiquement, ils s'en sont toujours méfiés.

Le risque de cercle vicieux se concrétise si un pays dévaluant sa monnaie, qui voit la balance commerciale se détériorer (l'effet prix de la partie gauche de la lettre J), fait preuve d'impatience et décide de dévaluer une nouvelle fois sans attendre l'effet volume de la partie droite de la courbe en J. Il court alors le risque d'enchaîner les dégradations de sa balance commerciale. 

Le risque de cercle vicieux est plus élevé en période de forte inflation causée par un triplement ou quadruplement du prix du pétrole, comme ce fut le cas après les chocs pétroliers de 1973 et 1979. Il a été accru par les fragilités du système monétaire européen, mal organisé car il offrait une récompense quasi-certaine aux spéculateurs : pour défendre sa monnaie, le pays attaqué relevait ses taux d'intérêt, ce qui affaiblissait encore plus ses entreprises exportatrices, rendant la dévaluation très probable, voire certaine, encourageant la spéculation.

La dernière dévaluation du franc remonte à mars 1983. Les 17 dévaluations du franc ont eu lieu de 1928 à 1983. Elles visaient à restaurer la compétitivité économique. Par exemple, le , Robert Schuman dévalue de 44,40 % le franc, qui se dépréciait depuis la Première Guerre mondiale. Le cours du dollar US était passé de 119 à 214 francs.

Les dévaluations des années 1950 et 1960 ne permirent pas d'obtenir une balance commerciale durablement stable. L'Allemagne, dont le deutschemark reste un modèle de stabilité, a mieux résisté aux chocs pétroliers de 1974 et 1980 car c'est le seul pays d'Europe à n'avoir pas été pénalisé par les dysfonctionnements spéculatifs du système monétaire européen.



</doc>
<doc id="15778" url="https://fr.wikipedia.org/wiki?curid=15778" title="Prédateur">
Prédateur

Un prédateur est un organisme vivant qui tue des proies pour s'en nourrir ou pour alimenter sa progéniture. La prédation est courante dans la nature où les prédateurs jouent un rôle prépondérant dans le maintien des équilibres écologiques.

La prédation est à distinguer de la nécrophagie, qui consiste à se nourrir d'un animal déjà mort, ou du parasitisme, qui en général ne requiert pas la mort de l'animal consommé.

Les relations entre "proie" et "prédateur" déterminent le fonctionnement et l'organisation des réseaux alimentaires dits « "réseaux trophiques" » (ou pyramides alimentaires), avec à leur sommet des prédateurs dits « "absolus" » (ceux qui ne sont pas eux-mêmes la proie d'autres prédateurs).

Les prédateurs influent sur la dynamique prédateurs/proies et donc sur les populations des proies. Ils contribuent à maintenir l'équilibre biologique des écosystèmes et influent indirectement sur le paysage et les habitats naturels. C'est pour protéger les arbres qu'on a réintroduit en 1994 des loups "d'Alberta" dans le Parc national de Yellowstone afin qu'ils régulent les populations de wapitis et autres grands herbivores qui étaient devenues assez importantes pour mettre en péril la forêt (par consommation des jeunes plants, écorçage… et surexploitation du milieu).

La dynamique de l'évolution des effectifs relatifs d'un système proie/prédateur est un sujet complexe. Même le modèle le plus simple, basé sur l'équation logistique, comporte des développements très poussés sur le seul plan mathématique.

Le terme de prédateur est à ne pas confondre avec la notion de déprédateur, qui désigne un animal qui commet des dégâts sur une plante ou des denrées, le plus souvent dans le but de se nourrir et parfois pour marquer son territoire.

Ils se nourrissent d'un large éventail de proies, leur population est relativement stable, et ils contribuent à exercer un contrôle continu sur le niveau des populations de proies.

Ils se nourrissent d'une ou d'un petit nombre d'espèces (ex : Chouette arctique et lemmings). Chez les mammifères, les véritables prédateurs spécialistes semblent rares. Le putois (Mustela putorius L.) est par exemple considéré comme . Ce type de prédateur est souvent apparemment spécialiste d'une espèces quand celle-ci est très abondante (ex : hermine face au campagnol), et il diversifie ses proies en cas de nécessité.

A la différence de la murène qui passe sa vie au même endroit, certains requins et d'autres prédateurs spécialistes font des milliers de km à la recherche de proies dispersées ou en migration. Sur terre, ainsi des loups suivent les troupeaux de caribous ou des hyènes et des lions suivent les migrations de troupeaux de gnous : Les prédateurs nomades qui se déplacent là où leurs proies sont les plus abondantes ou suivent leurs migrations saisonnières sont supposés mieux contribuer à la stabilisation des populations-proies dont ils vivent.

Terme parfois employé dans certains contextes pour désigner les espèces prédatrices de petite taille (musaraigne, etc.) ou des espèces de petites taille par rapport à celle de ses proies dont il se nourrit en s'attachant à ces dernières (ex tiques moustiques).


Depuis qu'il a maîtrisé l'agriculture et l'élevage, l'homme n'a que peu recours à la prédation pour se nourrir - à l'exception notable du cadre de la pêche en mer et moindrement de la chasse (la recherche de viande de brousse reste une activité importante dans certains pays (y compris pour l'approvisionnement urbain), et il reste quelques populations autochtones vivant essentiellement de la chasse et/ou de la pêche).

Il n'en reste pas moins capable, si nécessaire (ou s'il le souhaite, dans le cadre de la pêche ou de la chasse sportives ou de loisir), de tuer n'importe quelle espèce animale et de consommer sa chair.

Inversement, aucune espèce animale, dans des conditions normales, ne s'attaque à l'homme pour se nourrir. L'homme est donc parfois considéré comme le superprédateur ultime.

Les prédateurs - selon l'espèce et/ou selon les conditions du milieu - chassent en groupe ou en solitaire.

Trois grandes stratégies existent :

Remarque : Quelques familles ou espèces sont herbivores ou omnivore à l'état de larve et prédatrices à l'état adulte (ex : grenouilles, crapauds). Dans ce cas elles ont aussi changé de milieu de vie (aquatique à semi-aquatique ou terrestre). Inversement certaines espèces peuvent être prédateurs insectivores jeune, puis plutôt granivore ensuite (la perdrix par exemple).

La nature présente une variété considérable de modes et stratégies de prédation. En voici quelques-unes :

De nombreux petits prédateurs sont depuis longtemps considérés comme auxiliaires de l'agriculture ou du jardinage (hérisson, grenouille, crapaud, orvet et certains oiseaux consommateurs de limaces, coccinelle prédatrice de pucerons, etc).

Quelques espèces (rapaces, nocturnes notamment) ont souvent été mal aimés avant que ce rôle leur soit reconnu. Pour des raisons culturelles, sociologiques, historiques (l'Ours des cavernes et le lion des cavernes ont sans doute été des prédateurs redoutables pour l'homme jusqu'à leur disparition il y a moins de ans), les grands prédateurs carnivores ont longtemps été considérés comme « nuisibles » et pourchassés jusque dans leurs derniers refuges. Leur réapparition ou réintroduction ne se fait pas sans compromis, parfois difficiles avec une partie des habitants et usagers du milieu, qui ont perdu l'habitude de vivre avec eux.

Dans les écosystèmes des terres émergées, il a été constaté que les interactions biotiques (notamment la concurrence interspécifique et la prédation) augmentent de manière générale en intensité aux altitudes basses et aux latitudes supérieures selon un gradient retrouvé aux échelles mondiales et régionales. La prédation est plus intense en forêt tropicale humide. Dans les zones plus chaude le développement est plus rapide, mais la pression de prédation est également plus intense.

Par exemple, Roslin et al. (2017) ont disposé de fausses chenilles (plasticine verte) sur des sites situés sur six continents et sur un gradient latitudinal de plus de 11 600 km. En observant les traces de morsures ou de bec laissés par les prédateurs, ils ont constaté que le taux de prédation sur ces pseudo-chenilles augmentait en s'approchant de l'équateur. De plus, les prédateurs y sont plus souvent des prédateurs d'arthropodes (comme les fourmis) que des oiseaux et mammifères. 

Pour les espèces de cours d'eau des évènements tels que les étiages de sécheresses peuvent augmenter l'exposition d'espèces telles que les poissons ou écrevisses à la prédation.

L'évaluation de l'intensité de la prédation dans un territoire se fait généralement par le suivi de proies représentatives (espèces sentinelles le cas échéant) ou parfois de proies artificielles (chenille artificielle par exemple). Diverses méthodes ont été établies pour inventorier les proies de prédateurs invertébrés, éventuellement microscopiques.

Les prédateurs (naturels), de par leur position en tête de pyramide alimentaire et de par leurs fonctions écosystémiques sont considérés comme de bons bioindicateurs. Leur organisme bioconcentre de nombreuses substances toxiques et écotoxiques (métaux lourds, PCB, dioxines, pesticides, perturbateurs endocriniens…) qui sont souvent cause de leur régression ou disparition et qui peuvent alerter les décideurs, épidémiologues et écoépidémiologistes. Ce sont aussi - pour les mêmes raisons - de bons biointégrateurs qui peuvent être utilisés pour un monitoring de l'environnement.

Introduit volontairement ou accidentellement hors de son milieu naturel, un prédateur spécialiste meurt généralement assez rapidement, car fragile, se reproduisant peu, et mal adapté à une autre niche écologique que la sienne. On ne connaît pas d'exemples d'invasions rapides d'un milieu par un grand prédateur introduit ou échappé.

Inversement un petit prédateur généraliste, souvent caractérisé par une plus grande plasticité écologique (adaptabilité) peut rapidement pulluler et devenir invasif et poser des problèmes écologiques, allant jusqu'à la disparition d'espèces devenues leurs proies (ex : coccinelle asiatique face à la coccinelle à 7 points, chat domestique lâché sur une île riche en oiseaux).

Une espèce introduite peut aussi en éliminer une autre par concurrence dans une même niche écologique. Par exemple, le vison d'Amérique tend à éliminer le vison d'Europe depuis son introduction sur ce continent.

En termes d'évolution et de sélection naturelle, on considère que les prédateurs coévoluent avec leurs proies, apprenant avec le temps à déjouer leurs stratégies adaptatives, ce qui explique aussi l'extrême spécialisation de certains prédateurs (ex : fourmilier, et les nombreux insectes hyperparasites qui ne s'attaquent qu'à une seule espèce-cible).




</doc>
