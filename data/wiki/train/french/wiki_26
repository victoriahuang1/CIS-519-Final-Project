<doc id="2814" url="https://fr.wikipedia.org/wiki?curid=2814" title="Seconde (temps)">
Seconde (temps)

La seconde est une unité de mesure du temps de symbole s (sans point abréviatif).

C'est une des unités de base du Système international, ainsi que du système CGS. 

Qualitativement, la seconde est une durée égale à la soixantième partie de la minute (une minute se décompose en ), la minute étant elle-même la soixantième partie de l'heure. 

C'est d'ailleurs l'étymologie du mot qui provient de la francisation écourtée de l’expression en latin médiéval, qui signifie littéralement "minute de second rang", c’est-à-dire "seconde division de l’heure".

Quantitativement, la seconde du Système international d'unités est définie par un nombre d'oscillations, exactement, de l'atome de césium. La mesure et le comptage de ces oscillations sont effectuées par les horloges atomiques.

À partir du début du millénaire av. J.-C., les Mésopotamiens ont compté en base 60 en utilisant une numération de position dérivée du système de numération de type additif et de base mixte des Sumériens. Ce système est généralement associé à la civilisation babylonienne, qui occupe le sud mésopotamien après -1800 et jusqu'au début de notre ère. Cette base a traversé les siècles : on la retrouve aujourd'hui dans la notation des angles en degrés (360° = 6 × 60°) ou dans le découpage du temps (1 heure = 60 minutes = 60 secondes).
La définition de la seconde, l'unité de temps dans le Système international, a été établie selon les connaissances et les possibilités techniques de chaque époque depuis la première Conférence générale des poids et mesures en 1889.

La seconde est la durée de de la radiation correspondant à la transition entre les deux niveaux hyperfins de l’état fondamental de l’atome de césium 133. Il en résulte que la fréquence de la transition hyperfine de l’état fondamental de l’atome de césium est égale à exactement, ν(hfs Cs) = .
La seconde, étalon de mesure du temps, est ainsi un multiple de la période de l’onde émise par un atome de césium 133 lorsqu’un de ses électrons change de niveau d'énergie. On est ainsi passé de définitions, en quelque sorte "descendantes", dans lesquelles la seconde résultait de la division d’un intervalle de durée connue en plus petits intervalles, à une définition "ascendante" où la seconde est multiple d'un intervalle plus petit.

Lors de sa session de 1997, le Comité international a confirmé que la définition de la seconde se réfère à un atome de césium à une température de , c'est-à-dire au zéro absolu. Cette dernière précision souligne le fait qu’à , la transition en question subit, par rapport à sa valeur théorique, un déplacement en fréquence dû aux effets de rayonnement du corps noir. Cette correction a été apportée aux étalons primaires de fréquence et donc au Temps atomique international (TAI) à partir de 1997, quand elle a cessé d’être négligeable par rapport aux autres sources d’incertitude.

On dispose aujourd’hui d’une exactitude allant jusqu’à la (10). L’exactitude et la stabilité de l’échelle dite du TAI obtenue principalement à partir d’horloges atomiques à jet de césium sont environ supérieures à celles du temps des éphémérides. C’est d’ailleurs l’unité du SI la plus précisément connue.

Les préfixes du Système international d'unités permettent de créer des multiples et sous-multiples décimaux de la seconde. Si les sous-multiples décimaux (milliseconde, microseconde, nanoseconde, etc.) sont d’un emploi assez fréquent, les multiples (kiloseconde (ks) pour , mégaseconde, etc.) sont très peu usités, les multiples de 60 (minute, heure) puis 24 (jour) leur étant préférés.

Les multiples de la seconde en usage avec le Système international sont :

Il existe d’autres unités usuelles non décrites dans le SI, mais dérivées de celui-ci :

L'emploi d'une ou de deux primes (caractères « ′ » et « ″ ») comme symboles respectifs de la minute et de la seconde temporelles est incorrect, ces signes désignant la minute et la seconde d'arc, subdivisions du degré d'arc.

De même il n’est pas correct d’utiliser des abréviations pour les symboles et noms d’unités, comme « sec » (pour « s » ou « seconde »).

Les préfixes du Système international d'unités permettent de créer des multiples et sous-multiples décimaux de la seconde. Comme indiqué plus haut, les sous-multiples sont employés fréquemment contrairement aux multiples.

Voici la table des multiples et sous-multiples de la seconde :

On peut noter que l'âge de l'univers, exprimé en secondes, est voisin de , ce qui donne peu de sens aux durées bien plus grandes exprimées en zettasecondes ou yottasecondes. 

De même un milliard de secondes correspondent environ à et , plus parlant à l'échelle humaine. 

À l'opposé, dans le domaine des durées extrêmement courtes, l’ a mesuré en 2004 la durée du trajet d’électrons excités par les impulsions de d’un laser à ultraviolets ; position mesurée toutes les , correspondant à - à titre de comparaison, une attoseconde est à une seconde ce qu'une seconde est à environ 31,54 millions d'années. Pour avoir une meilleure idée de la prouesse, dans le modèle d’atome d’hydrogène de Niels Bohr, l’orbite d’un électron autour du noyau dure (mais les modèles atomiques actuels considèrent que l’électron ne tourne pas).

L'Institut Max Born d’optique non linéaire et de spectroscopie (MBI) de Berlin est parvenu à établir en 2010 le record de la plus faible durée d'impulsion contrôlable, atteignant la durée de .

Les unités de temps plus petites, zeptoseconde et yoctoseconde, ont peut-être encore un sens à des échelles subatomiques, mais ne sont pas mesurables avec les instruments actuels.

D'autres unités usuelles ne correspondent pas à un nombre précis de secondes, et ne sont donc pas des unités de temps dans le SI, ni même dérivées directement de celui-ci puisque ce ne sont que des approximations dans leur propre système non linéaire, d’une durée réelle en secondes SI :


Toutefois, dans de nombreux pays, l’heure légale dans une journée calendaire est maintenant déterminée par une durée exprimée en heures, minutes et secondes du SI : le réajustement des jours calendaires avec les jours solaires se fait aujourd'hui de temps en temps au moyen des secondes intercalaires, insérées ou supprimées à certaines dates en fin de journée (de sorte que les jours calendaires légaux font le plus souvent 24 heures dans le SI, mais certains jours sont raccourcis ou augmentés d’une ou deux secondes du SI). Cela a permis d’éliminer dans de nombreux domaines l’emploi des traditionnelles secondes, minutes et heures solaires, et même celui des secondes, minutes et heures calendaires, au prix d’une complexification de la durée légale d’une journée calendaire.

Les développements récents d'horloge atomique, basés sur des transitions électroniques à des fréquences optiques, ont permis de construire des horloges plus stables que les meilleures horloges à jet de césium. Lors de la Conférence générale des poids et mesures, ces atomes et leurs fréquences ont été ajoutés aux représentations secondaires de la seconde.

D'après les publications sur les performances de ces étalons de fréquence (dont "Nature" de juillet 2013), ces horloges pourraient dans le futur conduire à une nouvelle définition de la seconde.




</doc>
<doc id="2816" url="https://fr.wikipedia.org/wiki?curid=2816" title="Sejong le Grand">
Sejong le Grand

Sejong le Grand (세종대왕), né le et mort le , est le quatrième roi de la dynastie coréenne Joseon, de 1418 à 1450. C'est lui qui est à l'origine du "Hunmin Jeongeum", les "Sons corrects pour l'éducation du peuple" (que l'on appelle hangeul de nos jours), alphabet destiné à remplacer le système d'écriture chinois utilisé dans le pays à l'époque mais jugé bien trop complexe. Les historiens confirment qu'il serait le seul à l'origine de l'alphabet national coréen, le hangeul, puisque les chroniques de l'époque indiquent que les savants lui reprochèrent de l'avoir rédigé seul et en secret. En effet il était très probablement l'homme le plus apte en matière de phonétique, il envoya treize fois ses savants consulter un grand phonéticien chinois exilé à la frontière sino-coréenne pour leur faire entendre raison.

Selon Louis-Jean Calvet, « le hangeul se fonde sur une analyse très précise de la phonologie de la langue, et la précision de cette écriture, sa parfaite adéquation à la langue coréenne, font que le hangeul est souvent présenté comme le meilleur alphabet du monde » .

Fils du roi Taejong, il devient le Grand prince Chungnyeong (충녕대군, 忠寧大君) à dix ans et épouse une fille de Sim On (심온, 沈溫), connue sous le nom de Sim-ssi, et qui devint plus tard la princesse consort Soheon (소헌왕비, 昭憲王妃).

Certains indices incitent à lui attribuer le seul mérite de l’invention du hangeul. Pour certains, il s’est fait aider de parents ou de lettrés. Cependant, la majorité des lettrés, formés à l’utilisation des caractères chinois, les hanjas, se sont opposés à l’introduction du nouvel alphabet.

On lui attribue aussi l’invention d’une mesure des pluies, d’une horloge à eau et d’un cadran solaire. Tous ces objets sont développés dans son palais par l'inventeur Jang Yeong-sil.

Suivant les principes du néo-confucianisme, Sejong est également un roi humaniste, qui introduisit trois degrés de justice, avant que le jugement soit définitif, et qui interdit les punitions brutales ou cruelles, comme la flagellation.

Ses écrits sont également estimés : il a composé le célèbre "Yongbi Eocheon Ga" ("Chansons des dragons volants") en 1445, "Seokbo Sangjeol" ("Épisodes de la vie de Bouddha") en juillet 1447, Worin Cheon-gang Jigok ("Chansons du clair de lune sur des milliers de rivières") en juillet 1447, et son œuvre majeure qui fait référence, "Dongguk Jeong-un" (un dictionnaire de prononciation sino-coréenne) en septembre 1447.

L'efficacité de Sejong dans l'administration de son pays s’est manifestée dans plusieurs domaines.

Il est d’abord un planificateur et un organisateur militaire de premier ordre. Sous son règne, l’armée coréenne débarque à Tsushima pour éliminer les pirates japonais qui ravageaient la côte méridionale de la Corée.

Au nord, il repousse la frontière jusqu’au fleuve Yalou après avoir vaincu les Jurchens. Il construit quatre forts et six postes de surveillance pour protéger son peuple des incursions des nomades de Mandchourie. Il établit également divers règlements militaires et unités spécialisées pour renforcer la sécurité du royaume.

Il établit le Cercle des vénérables au palais royal en 1420, pour réunir les intellectuels de Corée. Les élèves de ce Cercle des vénérables ont écrit des chroniques, ont rédigé des documents et ont compilé des livres dans différentes sciences.

Sejong meurt à 53 ans et est enseveli au mausolée Yeong (영릉, 英陵). Son fils aîné Munjong lui succède.

La nouvelle capitale administrative de la Corée du Sud a été nommée Sejong en son honneur.

L'avenue Sejong (세종로) et le centre Sejong des arts vivants — au centre de Séoul — portent son nom, et il est représenté sur le billet de 10 000 wons. Une université a également pris son nom en 1987, l’université de Sejong.


</doc>
<doc id="2828" url="https://fr.wikipedia.org/wiki?curid=2828" title="Shibuya">
Shibuya

En même temps qu'au nom de l'arrondissement, le nom "Shibuya" se rapporte à la gare et au quartier d'affaires autour de la gare. La gare de Shibuya est une des plus fréquentées dans la région de Tokyo, ce qui est particulièrement visible au niveau du "Shibuya Crossing". L'arrondissement de Shibuya est connu comme un centre de la mode et c'est un quartier bien animé. Un symbole de ce quartier pour les jeunes est la tour 109 qui renferme une centaine de boutiques consacrées aux dernières tendances de la mode.

En plus du quartier Shibuya, il y a d'autres quartiers importants dans l'arrondissement de Shibuya : Daikanyama (代官山), Ebisu (恵比寿), Harajuku (原宿), Hiroo (広尾), Sendagaya (千駄ヶ谷), Omotesando (表参道) et Yoyogi (代々木).



Près de la gare de Shibuya se trouve une petite statue de chien célèbre : , qui resta fidèle à son maître même après le décès de celui-ci et jusqu'à sa propre mort et dont on honore la mémoire encore aujourd'hui. La place où se trouve cette statuette est un haut lieu de rendez-vous.

Dōgen-zaka est une rue en pente du centre de Shibuya célèbre pour ses boîtes de nuit et ses "love hotel" avoisinants.

Il y a plusieurs gares dans l'arrondissement, dont la principale, la gare de Shibuya. Il y aussi plusieurs lignes ferroviaires et de métro. 










Le quartier de Shibuya a inspiré de nombreuses œuvres. En musique, une chanson de l'album "À plus tard crocodile" du groupe Louise Attaque s'appelle "Shibuya Station" et le clip de la chanson "Panic Station" de Muse a été tourné dans le quartier. Plusieurs jeux vidéo se déroulent à Shibuya, notamment "Jet Set Radio," "The World Ends with You", "Shin Megami Tensei: Imagine" et "". L'action du film d'animation "Le Garçon et la bête" prend également place dans le quartier. En littérature, Le "visual novel" "Chaos;Head" se déroule à Shibuya et dévoile de nombreux lieux connus du quartier, dont le nom a parfois été légèrement modifié pour des questions de copyright. Le manga "Tokyo Tribe" y prend également place, le quartier étant le théâtre d'affrontements entre les différents gangs de Tokyo, ainsi que la bande dessinée "Spirou et Fantasio à Tokyo" : le chien Hachikō y prend notamment vie avant d'être abandonné par Spirou et Fantasio à l'un des aéroports de Tokyo.




</doc>
<doc id="2829" url="https://fr.wikipedia.org/wiki?curid=2829" title="Syndrome d'immunodéficience acquise">
Syndrome d'immunodéficience acquise

Le syndrome d'immunodéficience acquise, plus connu sous son acronyme SIDA, est un ensemble de symptômes consécutifs à la destruction de cellules du système immunitaire par le virus de l'immunodéficience humaine (VIH). Le sida est le dernier stade de l'infection au VIH, lorsque l'immunodépression est sévère. Il conduit à la mort des suites de maladies opportunistes. Une personne malade du sida est désignée par le terme « sidéen » ou plus rarement « sidatique ».

Trois modes de transmission du VIH ont été observés :


Une pandémie s'est développée à partir de la fin des années 1970, faisant de cette maladie un problème sanitaire mondial. La prévention, telle que l'usage du préservatif, constitue de loin la meilleure option, car il n'existe actuellement aucun vaccin permettant de se protéger du virus, et les traitements antiviraux disponibles actuellement ne permettent aucune guérison. Bien qu'ayant une certaine efficacité, ils ne peuvent que stopper la prolifération du VIH au sein de l'organisme et non l'éradiquer. De plus, ces thérapeutiques, coûteuses, ne sont facilement accessibles que dans les pays développés qui peuvent assurer la charge financière ; dans les pays en développement, plus de 95 % des patients ne bénéficient aujourd'hui d'aucun traitement efficace. Pour cette raison, l'ONU, à travers son programme ONUSIDA, a fait de la lutte contre le sida une de ses priorités.

Les trois modes de transmission du VIH ont chacun leurs particularités : par voie sexuelle, par voie sanguine et durant la grossesse et l'allaitement.

La plupart des infections par le VIH ont été ou sont encore acquises à l'occasion de rapports sexuels non protégés. La transmission sexuelle se fait par contact entre les sécrétions sexuelles (ou du sang contaminé par le virus) et les muqueuses génitales, rectales ou buccales. La probabilité de transmission varie entre 0,005 % et 0,5 % par acte sexuel avec une personne infectée selon le type de rapport sexuel. Le meilleur moyen de protection contre le VIH dans ce mode de transmission est le préservatif. À la suite de la synthèse de plusieurs études, il a été montré que l'usage du préservatif lors de chaque rapport et de manière correcte fait baisser le risque d'infection de 85 %.

Le mode de contamination par voie sanguine concerne tout particulièrement les usagers de drogues injectables, les hémophiles et les transfusés. Les professionnels de santé (soins infirmiers, laboratoires) sont aussi concernés, bien que plus rarement. Il ne faut pas négliger les risques de contamination lors des modifications corporelles telles que le piercing et le tatouage, si le protocole d'hygiène n'est pas respecté. La probabilité de transmission varie entre 0,67 % pour le partage de seringue avec un toxicomane séropositif au VIH et 90 % pour la transfusion sanguine avec du sang contaminé.

La transmission mère-enfant du virus peut survenir dans les dernières semaines de la grossesse, au moment de l'accouchement, et lors de l'allaitement. À noter une tendance à la fausse séropositivité au VIH chez les multipares. En l'absence de traitement, le taux de transmission, entre la mère et le fœtus, avoisine les 20 %. L'allaitement présente aussi un risque supplémentaire de contamination du bébé, de l'ordre de 5 %, ce qui explique qu'il soit déconseillé en cas d'infection de la mère. Cependant, trois études, l'une menée par PJ. Illif au Zimbabwe, l'autre par H. Coovadia en Afrique du Sud, la dernière par M. Sinkala en Zambie, montrent que l'allaitement exclusif précoce réduit le risque global de transmission postnatale à 4 % et accroît la survie des enfants. Actuellement, les traitements disponibles alliés à une césarienne programmée ont réduit ce taux à 1 %. Les résultats sont plus mitigés dans les pays en voie de développement, le risque de transmission postnatale diminuant grâce à l'utilisation de la Névirapine jusqu'à 13 % selon HIVNET012, 18 % selon Quaghebeur 

Le VIH désorganise le système immunitaire en infectant les lymphocytes T CD4+. Ces cellules sont en effet les « coordinatrices » de la réponse immunitaire : elles jouent un rôle tout à fait central. La mort des cellules infectées est consécutive au détournement de la machinerie des lymphocytes, qui ne peuvent plus fabriquer leurs propres molécules, ainsi qu'à la destruction de l'intégrité membranaire au moment de la sortie des virus néoformés. Par ailleurs, les cellules infectées exposent à leur surface membranaire des protéines virales (complexe "Env"). Ces protéines sont reconnues par des cellules immunitaires saines et s'accolent au lymphocyte infecté. S'ensuit un processus de « baiser de la mort » ("") par lequel la cellule saine est détruite par activation de la voie de l'apoptose. Dans ce sens, Luc Montagnier rappelle lors d'un colloque (Bruxelles, décembre 2003) : 

En l'absence de traitement, la quasi-totalité des patients infectés par le VIH évolue vers le sida, phase ultime de la maladie. La durée d'évolution vers le sida a semblé être de deux ou trois ans au début de la pandémie, mais est plutôt de l'ordre de dix ans, ainsi que l'ont montré des études faites en Ouganda. Les raisons de la latence de l'apparition de la maladie demeurent inexpliquées de façon satisfaisante.

Un certain nombre de patients ne développent pas le SIDA, même sans traitement : ce sont les asymptomatiques à long terme dont un sous-groupe est composé de contrôleurs du VIH (estimés à 1 % des séropositifs) ; leur dénombrement – rendu plus difficile depuis le développement des antirétroviraux – a pu faire l'objet de contestation.

Il existe deux classifications pour décrire la progression de l'infection VIH, fondées sur les manifestations cliniques et les anomalies biologiques avec CD4<200/mm3





Cette classification est hiérarchique et historique, c’est-à-dire qu’une fois le patient a atteint une classe, lorsque les signes cliniques ont disparu, il conserve cette classe. Par exemple un patient classé B, ne pourra plus passer dans la catégorie A, même si les signes cliniques de la classe B ont disparu.




Les divers modes de transmission du VIH sont désormais parfaitement connus. Il n'existe, à ce jour, aucune vaccination efficace contre le sida. Le préservatif reste actuellement la meilleure prévention.

Les rapports réceptifs sont plus à risque que les rapports insertifs, et les rapports anaux réceptifs sont ceux qui comportent le risque de transmission le plus élevé. Selon le ministère de la Santé français, la probabilité de transmission par acte varie de :

Ces quatre types de rapports sont classés à haut risque dans le document cité en référence, alors que les rapports oraux réceptifs ou insertifs avec ou sans éjaculation sont tous classés à faible risque, mais sans estimation chiffrée du risque réel. 

Les infections sexuellement transmissibles (IST) favorisent la transmission du virus VIH, par les micro-ulcérations et l'inflammation qu'elles entraînent localement. Répondent à cette définition la syphilis, la gonococcie, la chlamydiose (CT), l’"herpès virus" (HSV), la papillomatose et la trichomonase. Être déjà séropositif pour le VIH ne protège pas d'une surinfection VIH par une nouvelle souche virale potentiellement plus virulente. Les rapports oro-génitaux ne sont pas dénués de risques. Plusieurs cas prouvés de transmission du VIH au cours de rapports oro-génitaux, essentiellement par fellation passive, mais aussi par rapport oro-anal, ont été rapportés.

Les personnes séropositives au VIH ne souffrant d’aucune autre MST et suivant un traitement antirétroviral efficace, c'est-à-dire ayant une virémie indétectable depuis au moins six mois, ne risquent de transmettre le VIH par voie sexuelle que de façon négligeable, avec un risque inférieur à 1 sur .

Lors d'une relation sexuelle, seuls les préservatifs, qu'ils soient masculins ou féminins, protègent du VIH et des principales infections sexuellement transmissibles. Ils doivent être utilisés lors de tout rapport sexuel avec pénétration (qu'elle soit vaginale, anale ou buccale), avec un partenaire séropositif ou dont le statut sérologique est inconnu.
La condition pour l'efficacité du préservatif masculin est qu'il soit utilisé correctement à chaque rapport. Les lubrifiants à base de corps gras, comme la vaseline, des pommades ou des crèmes, voire du beurre, doivent être proscrits car ils fragilisent les préservatifs en latex et augmentent les risques de rupture. Il faut leur préférer des lubrifiants à base d'eau. Il est préférable d'utiliser un préservatif non lubrifié pour la fellation. Il est par ailleurs indispensable de vérifier sur la pochette du préservatif l'inscription de la date de péremption et d'une norme reconnue (CE-EN 600 pour l'Union européenne).

Le préservatif féminin représente une alternative au préservatif masculin. Il est en polyuréthane — ce qui autorise les lubrifiants à base de corps gras ou aqueux — avec un anneau externe et interne. Il se place à l'intérieur du vagin grâce à un anneau souple interne. Il peut être mis en place dans le vagin ou dans l'anus quelques heures avant un rapport sexuel, et n'a pas besoin d'être retiré tout de suite après le rapport, à l'inverse du préservatif masculin. Le principal obstacle à sa diffusion reste son coût élevé.

L'usage du préservatif permet une diminution du risque d'infection.

Malgré la large diffusion d'informations sur la maladie et la prévention, certaines personnes ont néanmoins des comportements à risque (voir article prise de risque du SIDA), ce qui nécessite des actions de prévention.
Selon certains études la circoncision permettrait de réduire la propagation du sida de 38 % à 66 % lors des rapports vaginaux pour le partenaire masculin. L'hypothèse de cette réduction des risques d'infections fut avancée dès 1986, puis confirmée au cours des années 2000 par trois essais contrôlés randomisés. Fortes de ces résultats, en , l’OMS et ONUSIDA ont indiqué que la circoncision médicale est une stratégie additionnelle dans la lutte contre l’épidémie de sida dans les zones qui connaissent une épidémie généralisée du virus (prévalence supérieure à 3 %) et où sa transmission est essentiellement hétérosexuelle.

Un agent rétroviral, le ténofovir ( l'emtricitabine/ténofovir) est la seule molécule utilisable à titre préventif. Déjà prescrite aux personnes séropositives dans le cadre d'une thérapie médicamenteuse, elle est également proposée pour les personnes particulièrement exposées au virus, comme les homosexuels séronégatifs n'utilisant pas le préservatif et ayant des partenaires multiples, ou encore pour les couples dits "sérodiscordants" (une personne séronégative et une personne séropositive sous traitement). Cet agent est autorisé en France et aux États-Unis pour la prévention du risque, même s'il est indiqué de continuer l'utilisation du préservatif. Les études menées aux États-Unis, notamment, indiquent des taux d'efficacité variant entre 50 et 100% selon les posologies.

L'usage de drogue peut permettre la contamination par le partage de seringues par exemple, avec au moins une personne infectée mais de plus certaines drogues peuvent avoir en elles-mêmes une action nocive sur le système immunitaire ; le risque pour la santé peut donc être double.
Là encore, certains prônent l'abstinence tandis que d'autres, jugeant que cette position n'est pas réaliste, préfèrent mettre à disposition des toxicomanes un matériel stérile ou des traitements de substitution.

Les drogues comme la cocaïne, l'héroïne, le cannabis, sont des corps toxiques étrangers. Elles provoquent donc une réponse immunitaire plus ou moins aiguë, dépendant de la nature de la substance, de sa concentration et de la fréquence à laquelle elle est consommée. Par exemple, le THC présenterait en particulier des effets immunosuppresseurs sur les macrophages, les cellules NK et les lymphocytes T. L'ecstasy a également des effets néfastes sur les cellules CD4+ du système immunitaire.

Le partage et la réutilisation de seringues usagées et souillées par du sang contaminé constituent un risque majeur de contamination par le VIH, mais aussi par les virus des hépatites B et C. En France, des mesures de réduction des risques sanitaires ont été mises en place : vente libre de seringues (depuis 1987), trousses de prévention contenant le matériel nécessaire pour réaliser une injection à moindre risque, mise en place d'automates de distribution et de récupérateurs de seringues, offre de traitements de substitution par voie orale.

Le risque d'infection par le virus du sida peut être augmenté lorsque la personne à l'origine de la contamination est porteur du VIH "et" d'un virus de l'hépatite (A, B ou C). Dans ce cas très particulier, la surinfection simultanée est même à envisager (voir test VIH).

Pour prévenir ces contaminations, il est essentiel de ne pas partager le matériel d'injection ou d'inhalation. Ceci comprend les seringues, les cotons, les cuillères et cupules, eau de dilution de la drogue, mais aussi les pailles et les pipes à "crack", surtout si elles sont ébréchées. Le matériel d'injection doit être à usage unique.

L'efficacité de ces mesures reste toutefois controversée : une étude datant de 1997 indique qu'à Montréal, ceux qui participaient aux programmes « seringues stérilisées » auraient eu un taux de transmission plus élevé que ceux qui n'y participaient pas. Des associations de lutte contre la drogue reprochent à ces mesures de rendre la toxicomanie plus accessible et de ne pas assez insister sur les possibilités de désintoxication. Elles mettent en avant que résoudre le problème de la drogue résoudrait un des modes de transmission du sida.

En 2009 en France, il était estimé qu'un tiers des séropositifs ne connaissaient pas leur statut sérologique. Il n'y a pas de dépistage obligatoire, si ce n'est lors d'un don de sang, de sperme ou d'organe ainsi que lors d'une fécondation in vitro. Il est proposé lors des tests à passer avant la grossesse. Chacun est libre de se poser la question de son propre statut sérologique vis-à-vis du VIH, et d'aller faire un test de dépistage.

Souvent, la primo-infection est silencieuse et l'infection par le VIH passe inaperçue jusqu'à ce que la maladie SIDA apparaisse ou qu'un test de séropositivité soit effectué.

Le diagnostic de l'infection par le VIH fait appel à la détection dans le sang des patients des anticorps dirigés contre le VIH. C'est la recherche de séropositivité au VIH, qui est un signe de l'infection ; mais l’absence de séropositivité au VIH ne veut pas dire qu'il n'y a pas eu une contamination (ce qui peut être le cas au tout début de l'infection).

La législation française actuelle exige l'utilisation de deux trousses sérologiques différentes lors du test de dépistage, car le test Elisa, s'il présente une sensibilité de 99,9 % (c'est-à-dire qu'il ne passera pas à côté d'une personne infectée), peut donner des résultats faussement positifs, en particulier lors de grossesses multipares, lors de maladie grippale, chez les porteurs de facteur rhumatoïde, etc. Deux tests différents sont donc réalisés issus de deux laboratoires différents. Ces tests sont des "tests à limite", c'est-à-dire que la séropositivité au VIH est déclarée si le taux d'anticorps dépasse une certaine valeur fixée par le fabricant du test.

Afin d'éliminer le risque de résultat faussement positif, la séropositivité au VIH sera confirmée par un second prélèvement pour confirmation par un " (immunoblot). Le malade est considéré séropositif au VIH si des anticorps dirigés contre les protéines constitutives du virus et contre les protéines internes du virus sont observés.

De nouveaux tests de dépistage permettent d'identifier des patients porteurs de l'antigène . En effet en cas de prélèvement trop précoce, l'organisme n'a pas fabriqué d'anticorps en quantité détectable, et la recherche de l'Ag ou la mesure de l'ARN-VIH plasmatique permettent un diagnostic plus précoce mais qui doit toujours être confirmé par un second prélèvement.

Il est également à noter que les tests de séropositivité au VIH dans les pays en voie de développement se réduisent le plus souvent à un seul test Elisa effectué auprès des femmes enceintes, qui constituent les populations les plus faciles à dépister à l'hôpital.

Une étude a montré que des souris alloimmunes peuvent produire les antigènes GP120 et créés lors d'une infection par le VIH, bien qu'elles n'aient pas été exposées au VIH. Chez l'être humain, les antigènes GP120, et dans certains tissus placentaires spécifiques (") de femmes à termes non infectées ont été retrouvés.

Les tests de dépistage (Elisa) peuvent se révéler faussement positifs chez les personnes atteintes de lupus (ainsi que d'autres maladie auto-immunes tel qu'il a été confirmé au congrès de Yokohama en 1994) mais cela ne se retrouve généralement pas pour les tests de confirmation (). Pendant les mois qui suivent une vaccination anti-grippale (deux à cinq mois), le dépistage peut également se révéler faussement positif dans certains cas, y compris pour les tests de confirmation.

Il existe plusieurs lieux concernant le dépistage. En France, les cas peuvent être observé dans les centres de dépistage anonyme et gratuit CDAG, dans les hôpitaux (centres de planification, centres de la Femme), dans les centres de santé universitaires (pour les étudiants) et dans les laboratoires de ville. Le test est remboursé à 100 % sur prescription médicale.

La quantification par PCR (Réaction en chaîne par polymérase) de l'ARN viral plasmatique est le test permettant de suivre l'intensité de la réplication virale dans l'organisme infecté et est appelé "charge virale". Ce test, couplé à la mesure du taux de lymphocytes T CD4+, est utilisé pour suivre l'évolution virologique d'un patient avant ou après la mise sous traitement. Il ne peut être utilisé comme seul moyen de diagnostic.

On considère qu'une variation de la charge virale n'est significative qu'au-delà de , soit des variations d'un facteur (multiplication) de 3,6 environ à la hausse ou à la baisse. La charge virale est exprimée en "copies par ".

Les valeurs temporelles de la phase de latence clinique (ou phase asymptomatique) ne sont qu'une moyenne. Cette phase peut en effet aussi bien durer que 16, selon l'individu.

Les signes cliniques de l'infection par le VIH varient selon le stade de la maladie. Dans son livre "Des Virus et des Hommes", le professeur Luc Montagnier indique que cette maladie n'a aucun symptôme spécifique constant.

Les symptômes de la primo-infection sont peu spécifiques. Ils apparaissent entre une et six semaines après la contamination, sous forme d'un syndrome pseudogrippal, ou mononucléosique. La fièvre est quasi constante, accompagnée de céphalées, de myalgies, d'asthénie. Les signes cutanéomuqueux associés sont une angine érythémateuse ou pseudomembraneuse comme dans la mononucléose infectieuse, et une éruption cutanée maculopapuleuse touchant essentiellement le tronc et la face. Peuvent s'y associer des ulcérations cutanéomuqueuses superficielles, surtout génitales et buccales.

Dans plus de la moitié des cas, apparaissent au cours de la deuxième semaine des adénopathies multiples, cervicales, axillaires et inguinales. Des manifestations digestives à type de diarrhée avec douleurs abdominales sont présentes dans un tiers des cas. 
La durée d'évolution d'une primo-infection est en moyenne de deux semaines. En l'absence de dépistage précoce et donc de traitement, tant prophylactique que curatif, de nombreux patients découvrent leur séropositivité au VIH au stade sida, à l'occasion de l'apparition d'une maladie opportuniste. La liste en est longue : atteintes pulmonaires (pneumocystose, tuberculose, pneumopathie interstitielle lymphoïde, lymphome), digestives (diarrhée, cryptosporidiose), neurologiques (toxoplasmose cérébrale, démence à VIH, méningites), dermatologiques (sarcome de Kaposi, dermite séborrhéique), oculaires (rétinite à cytomégalovirus qui peut entraîner une cécité).

Il n'existe à l'heure actuelle pas de traitement permettant de guérir du sida, malgré l'existence de traitements comme les trithérapies rétrovirales qui permettent de contenir l'action du virus avec plus ou moins d'efficacité ; de nombreux morts sont déplorés chaque jour en particulier dans les pays en développement où ces traitements sont difficilement accessibles en raison de leur coût. Des recherches continuent pour la mise au point d'un vaccin, mais les progrès dans ce domaine sont lents.

Les traitements ne sont pas généralement prescrits au début de la séropositivité au VIH, car ils présentent des effets indésirables, ainsi qu'une certaine toxicité. La nécessité de suivre un traitement à l'aide des bilans sanguins, notamment le rapport Charge virale/Taux de CD4 est évaluée. Une fois le traitement débuté, il doit être poursuivi avec une très grande régularité (une mauvaise observance peut rendre le virus « résistant »). Les tentatives d'arrêt des traitements n'ont pour l'instant pas donné de résultats probants.

Les principaux effets indésirables à court terme des multithérapies s'atténuent généralement rapidement : fatigue, maux de tête, troubles digestifs (nausées, diarrhées), fièvre ou plaques rouges sur la peau. Après plusieurs mois de traitement, une lipodystrophie (graisse disparaissant du visage pour aller sur le ventre pour les hommes et les cuisses pour les femmes), des dyslipidémies (augmentation du cholestérol et des triglycérides) ; ainsi qu'une perturbation du métabolisme glucidique (mauvaise assimilation du sucre) peuvent survenir. Certains de ces effets indésirables peuvent être atténués par une activité physique adaptée ou une adaptation des traitements médicamenteux.

L'espérance de vie actuelle sous traitement chez le sujet jeune infecté peut dépasser .

Au cours d'une grossesse, le risque de transmission "de la mère à l'enfant" est de 20 % à 40 %. Ce risque peut être considérablement réduit à l'aide d'un traitement préventif. Un traitement antirétroviral associé à la césarienne et à l'allaitement artificiel permet de réduire le risque de transmission à moins de 1 %. La durée courte du travail et le délai court de prise en charge après la rupture de la poche des eaux sont des facteurs de protection contre la transmission maternofœtale. Les dernières recommandations favorisant l'allaitement maternel complet jusqu'à l'âge de au moins proviennent d'études très récentes qui montrent que celui-ci réduit le taux de transmission à 4 %.

Selon son président, , sur du Sida sont pris en charge par l'institution internationale Unitaid dont le financement est fondé pour l'essentiel sur une taxe sur les billets d'avion.

En 2012, l'Américain Timothy Brown serait le premier cas connu de guérison du VIH. Il aurait été soigné indirectement à la suite d'une greffe de moelle osseuse alors qu'il était atteint d'une leucémie en 2007.

Entre partenaires sérodiscordant (un positif, un négatif), il est possible de limiter (mais pas de supprimer) les risques de contamination sans usage de préservatif sous certaines conditions : les partenaires s'engagent sur la fidélité, le séropositif doit avoir une charge virale indétectable depuis au moins 6 mois et ne jamais manquer de prise de médicament selon les conseils du médecin. Dans ces conditions, le risque de contamination reste présent, à hauteur de 4%. Ces conditions sont définies par le Conseil Supérieur de la Santé de Belgique dans le cadre d'un Plan VIH 2014-2019. Ce concept doit faire partie d'une prévention globale intégrée (prévention primaire, dépistage et prise en charge) qui fait intervenir le traitement comme outil de prévention. L'utilisation du préservatif et du lubrifiant, la distribution de seringues stériles et l'éducation à la sexualité et à la prévention des infections sexuellement transmissibles restent néanmoins les éléments clés de la prévention pour tous les groupes à risques (les hommes qui ont des relations sexuelles avec des hommes, les personnes migrantes, personnes vivant avec le VIH, adolescents, travailleurs du sexe, personnes qui s’injectent des drogues et détenus).

L'objectif premier d'un traitement anti-rétroviral est de maintenir le nombre de CD4 au-dessus de 500/mm³. Pour atteindre cet objectif, un traitement anti-rétroviral doit maintenir une charge virale plasmatique au-dessous de 50 copies/mL. Ceci a pour effet de réduire la morbidité du VIH, d'améliorer le profil de tolérance clinique et biologique ainsi que la qualité de vie.

Comparons le cas du sida à celui du paludisme. Le traitement contre le paludisme est aujourd’hui efficace dans 99 % des cas. Ce traitement coûte 1 $. Il y a pourtant 600000 personnes, principalement des enfants, qui meurent de cette maladie chaque année en Afrique. Dans ce cas le problème se situe clairement au niveau de l’organisation, de l’éducation des parents et de la formation des personnels de santé. Concernant le sida, qui a touché des populations riches, l’investissement de la recherche est très important. Et les résultats ont été remarquablement rapides (première trithérapie en 1995). Contrairement aux idées reçues, et grâce notamment à l’action des associations de patients et de certaines institutions, ONG, lobbys, etc., des traitements qui étaient hors de prix sont devenus accessibles en Afrique, pour environ la moitié des malades, alors qu’en Europe et aux États-Unis, les prix des mêmes traitements sont restés exorbitants. Sur ce sujet plus général du marché pharmaceutique des pandémies, l’action des gouvernements peut, elle aussi, être primordiale. Mais les grands laboratoires pharmaceutiques pratiquent parfois des marges bénéficiaires irrationnellement abusives, tout à fait déconnectées du coût réel de développement et de fabrication de ces médicaments. Il en est de même pour les plus récents traitements de l’hépatite C par exemple, qui sont devenus très accessibles en Inde grâce à l’action gouvernementale et aux produits génériques, et qui restent extrêmement chers dans les pays développés (70000 $ / an pour le plus récent).

Depuis l'année 2002, le sida est considéré comme une pandémie mondiale. Les dernières estimations fournies par le rapport ONUSIDA 2007 portent à , le nombre de personnes séropositives au VIH dans le monde ; , le nombre de personnes nouvellement séropositives au VIH en 2007 ; et , le nombre de personnes mortes du sida en 2007.
Ce qui permet d'estimer à plus de le nombre de morts depuis le début de la maladie en 1981. L'organisation note une stabilisation du taux d'infection (c'est-à-dire du nombre de personnes infectées par rapport à la population globale), ce qui amène à penser que le pic de l'épidémie a été atteint et que celle-ci se stabilise. Cependant, le nombre de personnes infectées a augmenté, en raison de l'augmentation de la population et de l'accès aux trithérapies (qui retarde les décès).

Ces estimations sont obtenues grâce à l’"Epimodel" utilisé par l'ONUSIDA. L'évolution de la prévalence de la séropositivité au VIH est alors obtenue par modélisation utilisant plusieurs paramètres démographiques et médicaux déterminés sur des échantillons de la population, en particulier les études antenatales.

Cependant, les chiffres de cette pandémie ne sont que des chiffres officiels, car certains États sont trop pauvres pour pouvoir avancer avec certitude un chiffre exact à un niveau national, surtout en Afrique. Par exemple, la Somalie, État qui n'existe plus, en proie à une guerre civile depuis 1989 est dans l'impossibilité de pouvoir engager une enquête sanitaire à grande échelle, pour connaître le nombre exact de malades ; autre exemple, le Sud-Soudan, nouvellement indépendant, qui sort de de guerre civile, n'a pas les moyens d'établir des statistiques à grande échelle, et tout au plus, donne des estimations basses. À ces chiffres, il faut ajouter des populations aux modes de vies traditionnels qui vivent dans une économie de subsistance, qui, la plupart du temps, ne se font pas soigner, ou optent pour une médecine « traditionnelle » inefficiente et où le poids des traditions, coutumes et croyances est lourd. Souvent le SIDA n'est pas diagnostiqué. Ainsi de nombreux malades meurent du SIDA sans le savoir.

La Chine offre un autre exemple : depuis des années, de nombreuses ONG dénoncent les chiffres discutables donnés par l'État chinois. Il semblerait que pour des raisons politiques sensibles, l'État chinois donnerait des chiffres loin de ceux de la réalité. Par exemple, un scandale a éclaté dans les années 2000, où il était question, que pour des campagnes de vaccinations, les seringues n'étaient pas changées, d'où un nombre important de contaminations au VIH. De nos jours encore, l'ampleur de ce désastre est méconnu, et l'État chinois n'avance aucun chiffre, et seules quelques ONG peuvent avancer des estimations basses. Pour d'autres pays, il y a aussi le poids de la religion : un État comme l'Arabie Saoudite, par exemple, communique peu, le SIDA étant considéré comme une honte en ce pays. Souvent, les causes des décès sont cachées, et on parle le plus souvent de tuberculose, alors que la raison de la mort est le SIDA. Régulièrement, l'OMS communique que la pandémie du SIDA se stabilise. Mais dans les faits, rien ne permet de dire si c'est vraiment le cas, car derrière la pandémie se cachent de nombreux tabous, tout comme des enjeux politiques importants, ce qui entraine la raison d'État, où la Chine est un parfait exemple. Parler de la stabilisation de la pandémie du SIDA est aléatoire, mais le SIDA reste une pandémie, ce qui explique que l'OMS reste vigilante. Ce qui est certain, est que les chiffres de la pandémie restent très importants, et qu'elle a toujours un impact majeur surtout en Afrique. Sans doute, les chiffres de l'ampleur de la pandémie sont sous-estimés, tout comme ils peuvent aussi correspondre peut-être à la réalité. Dans le monde, l'union Sud-Africaine semble être l'un des rares pays où le SIDA fait des ravages, à communiquer en toute transparence des chiffres et des données qui correspondent à la réalité. Dans ce pays, le système de santé est performant, et de plus, il y a de nombreux hôpitaux, contrairement à d'autres pays africains qui en sont dépourvus, par exemple l'Éthiopie, pays très pauvre, qui malgré sa bonne volonté a du mal à donner des chiffres exacts sur l'impact du SIDA, en ce pays de plus de d'habitants.

L'épidémie s'étend en Asie rapidement (plus d'un million de personnes ont été nouvellement contaminées dans cette région) et poursuit son expansion en Europe orientale. En s'étendant aux pays les plus peuplés du monde, elle peut avoir des conséquences potentiellement catastrophiques. Alors que dans les premières années elle touchait principalement les consommateurs de drogues injectables, les hommes homosexuels et travailleurs sexuels ainsi que leurs partenaires, ce n'est plus le cas aujourd'hui où la majorité des contaminations sont hétérosexuelles.

Dans les pays occidentaux, la prévalence de la séropositivité au VIH a quelque peu diminué, grâce aux campagnes de sensibilisation, ainsi que dans les pays d'Afrique centrale. Par exemple, en Ouganda, elle est passée de 30 % en 1995 à 5 % en 2003. Néanmoins, parmi certaines parties de la population telles que les jeunes homosexuels, le taux d'infection montre de légers signes d'un possible retour à la hausse. Cela constitue un problème majeur pour les professionnels de la santé publique. Le sida demeure également extrêmement problématique en ce qui concerne les prostitué(e)s et les toxicomanes. Le taux de décès a considérablement chuté, à la suite de l'utilisation des trithérapies qui se sont avérées très efficaces, sans toutefois jamais arriver à le guérir (selon le rapport 2004 d'ONUSIDA, il y a en 2003 environ séropositives au VIH en Europe de l'Ouest).

Selon l'UNICEF, de moins de ont été infectés par le VIH en 2006, essentiellement par transmission mère-enfant, malgré les progrès faits en Afrique, notamment dans le Sud et l'Est dans la prévention de ce type de transmission. 50 % des bébés infectés mourront avant d'avoir deux ans s'ils ne sont pas traités. Le nombre de femmes infectées est plus élevé que celui des hommes. En Afrique, les antirétroviraux (ARV) manquent toujours : 9 % des femmes enceintes séropositives au VIH en ont reçu en 2005 dans les pays pauvres ou moyennement riches, pour empêcher la transmission du VIH au bébé, contre 3 % en 2003.

Toutefois, dans les pays en développement (surtout en Afrique sub-saharienne), les conditions économiques et le manque de campagnes de sensibilisation ont contribué à maintenir des taux d'infection élevés. Certains pays d'Afrique comptent actuellement jusqu'à 25 % de leur population active séropositive au VIH.

Si ces populations atteignaient effectivement le stade sida, elles deviendraient inaptes au travail et nécessiteraient des soins médicaux intensifs. De telles situations pourraient, à l'avenir, provoquer dans la région l'effondrement de certaines sociétés, la chute de gouvernements, augmentant d'autant plus la détresse de ces pays.

Pendant des années, nombre de ces gouvernements ont nié l'existence de ce problème, et commencent seulement à y rechercher des solutions. Le manque de soins médicaux adéquats, l'ignorance vis-à-vis de la maladie et de ses causes, ainsi que le manque de moyens financiers pour éduquer et soigner sont actuellement les principales causes de décès par le sida dans les pays en développement.

Pour l'essentiel, la rapidité de diffusion du VIH dans ces pays est due aux coinfections VIH et virus de l'Herpès (HSV). Ce dernier favorise, lors des rapports sexuels, la transmission du VIH, en particulier la transmission hétérosexuelle en rendant les muqueuses génitales davantage perméables aux virus.

En 2004 la mortalité globale en Afrique du Sud, par exemple, était de par an dont décédées suite au HIV, soit 2,39 % des décès et la cause de mortalité par effectifs, pour une population de à la même date.

En France, les dernières statistiques datent de 2010. On dénombre 7000 à 8000 nouvelles contaminations par an. Dans 40 à 50 % des cas, le virus est contracté dans le cadre de relations sexuelles homme-homme (HSH), témoignant de ce que l'épidémie n'est pas encore contrôlée dans cette population (le nombre de nouveaux diagnostics chez les HSH a augmenté par paliers, puis s’est stabilisé depuis 2010 autour de cas). Font suite par ordre d'incidence, les personnes d'origine d'Afrique subsaharienne et les usagers de drogues par voie intraveineuse. Le taux d’incidence est estimé à 39 pour en Île-de-France et à 11 pour pour le reste de la Métropole. La majorité des découvertes de séropositivité en 2011 (72 %) correspondent à des personnes de 25 à 49 ans.

Certaines personnes ou groupes remettent en question le lien de causalité entre le VIH et le sida, voire nient l'existence du virus. Le virologiste Peter Duesberg, dont les travaux ont depuis été contredits, soutient que le sida est causé par la consommation à long terme de drogues ou d'antirétroviraux. Ce point de vue a été repris pendant un temps par le gouvernement d'Afrique du Sud et, plus particulièrement, son président de l'époque, Thabo Mbeki. C'est pourquoi il a convoqué une conférence contradictoire entre les tenants de la position officielle et ceux soutenant des hypothèses alternatives, en demandant une réévaluation. Il a également remis en cause l'innocuité de certains antirétroviraux, tels l'A.Z.T., et présenté la pauvreté comme origine du sida. Malgré cela, l'Afrique du Sud a été un moteur dans le développement légal des génériques, en contournement de la position dominante des grands laboratoires occidentaux. Malgré la réticence du gouvernement à fournir des médicaments aux séropositifs au VIH et sous la pression intérieure et internationale, les fonds consacrés à la lutte contre le sida n'ont cessé d'augmenter, atteignant leur point d'orgue aux campagnes nationales de traitement gratuit annoncées en 2003, mais peu développées depuis. Les délais dans l'accès aux soins et aux traitements mais aussi dans la prévention sont ainsi imputés à ces attitudes controversées, même si de nombreux autres facteurs peuvent légitimement être invoqués pour expliquer que l'Afrique du Sud soit un des pays les plus touchés par le sida.

En réaction à ces controverses, la "Déclaration de Durban" entend rappeler que les preuves que le sida est causé par le VIH sont claires, sans ambiguïté et conformes aux plus hauts standards de la science.

En Chine, la province du Henan a été contaminée massivement dans les années 1990 par des collectes de sang et de dérivés sanguins effectuées selon un protocole dangereux (réutilisation de matériel usagé, mise en commun du sang collecté), et a également nié la réalité du sida, pour protéger les responsables. Dans les années 2000, le mal est identifié, mais les traitements ne suivent pas.

Selon une autre hypothèse, leur sida était l'effet des collectes de sang rémunérées trop fréquentes parmi une population très pauvre (et donc déjà mal nourrie), qui aurait causé son effondrement immunitaire.

Les premiers signes de l'épidémie remontent à la fin des années 1970, lorsque des médecins de New York et de San Francisco s'aperçoivent que beaucoup de leurs patients homosexuels souffrent d'asthénie, de perte de poids et parfois même de forme rare et atypique de cancer (comme le sarcome de Kaposi qui s'attaque aux leucocytes). L'existence d'un problème sanitaire est avérée en juillet 1981 lorsque le Centre pour le contrôle et la prévention des maladies (CDC) d'Atlanta relève une fréquence anormalement élevée de sarcomes de Kaposi, en particulier chez des patients homosexuels. La maladie est d'abord connue sous le nom de « » ou « », GRID () ou encore aux États-Unis. Ces diverses appellations s'avérèrent inappropriées dès que s'affirma l'universalité de la maladie : à l'été 1982, débuta aux États-Unis l'usage du sigle AIDS, qui signifia d'abord puis . Le terme "AIDS" avec la notion d’ (acquis) sont réputés être donnés par le chercheur Bruce Voeller, mort lui-même d'une complication liée à cette maladie. 

À la fin de 1981, le Bureau d'épidémiologie du Ministère de la santé nationale et du bien-être social du Canada demandait au Bureau de la traduction du gouvernement canadien l'équivalent français du terme « acquired immune deficiency syndrome » ou « AIDS ». Ces deux appellations apparaissaient dans un communiqué diffusé par le Center for Disease Control (CDC) d'Atlanta, aux États-Unis. Or, conformément à la Politique sur les langues officielles en vigueur au Canada, tout bulletin émis par un ministère fédéral devait être diffusé simultanément en anglais et en français. Le Bureau d'épidémiologie devait donc absolument trouver le terme correct pour décrire cette réalité en français. À l'époque, aucun ouvrage médical francophone ne traitait de ce syndrome, exception faite d’un rapport qui faisait mention des travaux du Professeur Luc Montagnier de l'Institut Pasteur, en France, où il était question d’ « immuno-dépression acquise » et de « déficience immunitaire acquise ».

 L’experte du Bureau de la traduction en matière de terminologie médicale, Sylvie DuPont établit avec son interlocuteur du Ministère de la santé qu'il s'agissait toutefois d'un syndrome, c'est-à-dire d'un ensemble de symptômes constituant une entité clinique. Le Ministère de la santé souhaitait également trouver un sigle, de préférence aussi convivial que le « AIDS » anglais. En manipulant les composantes du syntagme, elle proposa différents équivalents, dont « syndrome d'immunodéficience acquise » qui pouvait être abrégé en « SIDA ». Au fil des ans, ce terme est passé dans l'usage et a subi une dernière transformation : depuis la fin des années 1980 on utilise le sigle « sida » plutôt que « SIDA ».

Il convient de préciser que pour désigner la personne atteinte de sida, le terme « sidatique » avait été proposé, conformément aux règles de dérivation néologique et basé sur l'exemple du terme « trauma » qui donne traumatique, traumatisé, traumatisant, traumatologie, etc. Toutefois, ce terme ayant été malencontreusement utilisé dans un contexte discriminatoire par Jean-Marie Le Pen, en 1987, les usagers ont préféré se distancer de cet usage. La ministre française de la santé de l'époque, Madame Barzach, avait donc commencé à utiliser le terme « sidéen » lors des conférences de presse. Puisque la presse écrite française jouit d'une plus grande diffusion à l'échelle internationale, c'est ce terme qui est tranquillement entré dans l'usage.

L'origine virale ne fut pas d'emblée évoquée, et l'hypothèse d'une intoxication par des produits comme les "poppers" (stimulants sexuels contenant du nitrite d'amyle) a pu être émise au début, car les six premières personnes malades en avaient toutes été de gros consommateurs. De même, l'identification du virus responsable a été difficile, beaucoup de scientifiques parlant d’"HTLV" comme cause de l'épidémie. C'est à la même période que de nombreux transfusés sont contaminés par des lots de sang contenant le VIH. En quelques années, le virus va s'étendre pour finir par toucher toutes les couches de la population.

En janvier 1983, l'équipe du professeur Jean-Claude Chermann, qui travaille à l'Institut Pasteur sous la direction de Luc Montagnier, isole un virus étroitement associé au SIDA ; à ce stade, cependant, le lien entre le LAV () et le sida n'est pas clairement établi par l'équipe de Luc Montagnier.

Le , une conférence de presse est organisée par le département de la Santé et des Services sociaux des États-Unis. À cette occasion, la secrétaire américaine à la Santé Margaret Heckler annonce d'abord que Robert Gallo et ses collaborateurs ont découvert l'agent causal du sida, un rétrovirus baptisé HTLV-. Elle annonce ensuite que cette équipe est en mesure de produire le virus en masse. Enfin, elle annonce la prochaine distribution d'un test de diagnostic. En , une commission de nomenclature virologique forge un sigle pour désigner le virus isolé : HIV (), que les Français transcrivent en VIH. En , sous le gouvernement Chirac, le sida devient une maladie à déclaration obligatoire. En , les cas de sida avérés obtenant le statut de maladie de longue durée ouvrent droit à une prise en charge à 100 %.

Les VIH font partie d'un groupe de virus entraînant des maladies semblables au sida chez les primates, les virus de l'immunodéficience simienne (VIS). Les différents virus humains (VIH) sont le résultat de la transmission à l'Homme de différents virus au , notamment des VIS des chimpanzés (pour les VIH-1) et des mangabeys (probablement, pour les VIH-2). Bien que les VIS n'infectent habituellement pas l'Homme, certaines mutations, dont quelques-unes ont été identifiées, ont permis ces transmissions. 

Les études scientifiques suggèrent qu'HIV-1 est apparu dans le bassin du Congo dans les années 1920. À cette époque, le développement économique du Congo belge s'est accompagné d'un développement des liaisons ferroviaires et d'une forte croissance de la population de Kinshasa, ce qui pourrait avoir favorisé la propagation du virus. Le premier échantillon recensé du VIH fut recueilli en 1959 à Léopoldville (aujourd'hui Kinshasa), dans l'actuelle République démocratique du Congo. Parmi les premiers échantillons recueillis, le cas d'un Américain homosexuel en 1969 et d'un marin hétérosexuel norvégien en 1976.

Au début de l'épidémie, des recherches ont été entreprises pour déterminer le patient zéro qui aurait propagé le virus aux États-Unis. Pendant un temps les soupçons se sont portés sur Gaëtan Dugas, un steward canadien homosexuel qui est mort le . Une étude fait remonter l'entrée du VIH aux États-Unis vers 1969.

Dès le début du , le SIDA se transforme en une pandémie. Il y a eu de 1981 à 2006 environ de morts dus aux maladies en rapport avec le sida. En 2007, l'épidémie semble marquer le pas, le nombre de séropositifs au VIH ayant sensiblement diminué de en 2006 à de personnes séropositives au VIH. L'ONUSIDA indique cependant que cette diminution provient d'une meilleure utilisation des outils statistiques, et met en garde contre un optimisme exagéré.

L'Église catholique ne reconnaît pas l'utilisation du préservatif dans la lutte contre le sida. Elle prône en effet de combattre l'épidémie exclusivement par la fidélité dans le mariage et l'abstinence avant celui-ci, conformément à sa doctrine. Cette position est une source récurrente de controverses.

Les propos du pape , concernant l'utilisation du préservatif dans le cas de prostituées, semblent cependant attester de l'adoption dans certains cas d'une doctrine du moindre mal.

Les séropositifs au VIH étrangers peuvent difficilement entrer dans plusieurs pays, comme la Russie. Aux États-Unis, l'interdiction a été levée par l'administration Obama en janvier 2010.













</doc>
<doc id="2830" url="https://fr.wikipedia.org/wiki?curid=2830" title="Soudan">
Soudan

Le Soudan ( ; en '), en forme longue la république du Soudan ( '), est un pays africain.

Le pays est bordé par la Libye et l’Égypte au nord, la mer Rouge, l'Érythrée et l'Éthiopie à l'est, le Tchad et la République centrafricaine à l'ouest et par le Soudan du Sud au sud. Les langues officielles du pays sont l’arabe, et depuis peu (2005), l'anglais.

Son nom vient de l'arabe "balad as-sūdaan", qui signifie littéralement « pays ("balad") des Noirs » ("sūdaan", ce terme étant le pluriel d"'aswad") ; cette expression désigne le Soudan, une région d'Afrique plus grande dont fait partie l'Ouest du pays.

Dans l'Antiquité, le pays correspondait en grande partie à l'ancienne Nubie (voir l'article détaillé sur l'histoire du Soudan).

Dans les années 1820, l'Égypte est gouvernée par le Pacha Méhémet Ali. L'Égypte étant une province de l'Empire ottoman, il est en théorie vassal du Sultan de Constantinople, mais s'est en pratique libéré de la tutelle de celui-ci et mène une politique indépendante d'expansion territoriale.

Après d'infructueuses tentatives pour conquérir la Palestine et la Syrie, il se lance avec succès à la conquête du Soudan dans les années 1820.

En 1885 le chef religieux Muhammad ibn Abdallah, s'étant proclamé « le Mahdi » (« l'attendu »), tenta d'unifier les tribus de l'Ouest et du Centre du Soudan contre la domination égyptienne. Il prit la tête d'une révolte religieuse que le gouvernement égyptien s'avéra incapable de réprimer et infligea une défaite écrasante à l'armée envoyée contre lui par Le Caire : commandée par le colonel anglais Hicks, celle-ci commit l'imprudence de s'aventurer dans le désert à la poursuite du Mahdi qui, lorsqu'elle fut bien épuisée et démoralisée, se retourna contre elle et l'anéantit.

Cette victoire, outre qu'elle laissait l'Égypte presque sans moyen militaire, apporta au Mahdi les moyens qui lui manquaient pour donner à l'insurrection une plus grande ampleur : le ralliement de nouvelles tribus et surtout des milliers de fusils Remington, 5 millions de cartouches et des pièces d'artillerie. Jusque-là cantonnée au désert et à des opérations de guérilla, l'insurrection mahdiste pouvait désormais s'attaquer aux villes et garnisons égyptiennes du Soudan, à commencer par la capitale : Khartoum. Le Khédive d'Égypte demanda l'aide de la Grande-Bretagne, mais le gouvernement de Gladstone refusa d'engager des troupes dans une aventure qui ne le concernait pas. Il consentit tout au plus à mettre à la disposition de l'Égypte le général Gordon avec pour mission d'organiser l'évacuation des garnisons égyptiennes du Soudan, abandonnant le pays au Mahdi.

Si Gordon connaissait bien le Soudan (dans les années 1870, il en avait été gouverneur général, nommé par le Khédive) et s'il était un chrétien convaincu, il ne comprit pas vraiment la signification de la révolte, ni la raison pour laquelle elle mobilisait largement la population. Pour reprendre les remarques d'un des meilleurs observateurs britanniques de l'époque, Wilfred Scawen Blunt, il ne se rendit pas compte que tous les gens de bien au Soudan étaient du côté du Mahdi.

Encerclé à Khartoum, il refusa de l'abandonner et organisa la défense, persuadé que l'opinion publique britannique et en particulier la très influente Ligue contre l'esclavage exercerait sur le gouvernement une pression telle que celui-ci se verrait contraint d'envoyer des troupes à son secours, ce qui fut le cas.

L'expédition de secours, commandée par Sir Garnet Wolseley, arriva trop tard et se trouvait encore à quelques jours de marche de Khartoum lorsqu'elle apprit la chute de la ville et la mort de Gordon (janvier 1885). Les instructions qu'avait reçues Sir Garnet étaient claires : sa mission était de sauver Gordon, pas de conquérir le Soudan. Il fit donc demi-tour et regagna l'Égypte, ramenant avec lui les dernières garnisons égyptiennes ; le Mahdi restait maître de tout le pays. Ce dernier ne profita guère de sa victoire, il mourut quelques semaines plus tard, peut-être d'une méningite. Dirigé par le Khalifa Abdullah, le pouvoir mahdiste survécut jusqu'en 1898 où il fut anéanti à la bataille d'Omdurman par une armée anglo-égyptienne commandée par Sir Herbert Kitchener. Cette bataille fit tués du côté soudanais et 48 du côté anglo-égyptien, ce qui en fait un massacre plus qu'une bataille, et personne ne s'interrogea sur le fait que presque aucun des Soudanais blessés ne survécut. Kitchener était en route vers Fachoda et sa dramatique confrontation avec l'expédition française du Commandant Marchand.

1916 est l'année de la défaite et de la mort d'Ali Dinar, dernier sultan du Darfour.

L'indépendance fut proclamée en 1956, mais le gouvernement de Khartoum revint sur les promesses faites aux provinces du Sud de créer un État fédéral, ce qui conduisit à une mutinerie menée par des officiers du Sud, qui fut le début d'une guerre civile de dix-sept ans (1955-1972).

Des élections eurent lieu en avril 1965 mais les gouvernements successifs furent incapables de se mettre d'accord sur une constitution permanente ou de résoudre les problèmes de la lutte entre factions, de la stagnation économique et de la dissidence ethnique. Le mécontentement amena un deuxième coup d'État militaire le . Son meneur, le colonel Gaafar Muhammad Nimeiri, devint Premier ministre, et le nouveau régime supprima le Parlement et interdit tous les partis politiques.

Des luttes entre les marxistes et les non-marxistes à l'intérieur de la coalition militaire au pouvoir provoquèrent un nouveau coup d'État en juillet 1971, dirigé par le Parti communiste soudanais. Quelques jours après, des troupes anti-communistes restaurèrent Nimeiri.

En 1972, l' mit fin à la guerre civile Nord-Sud et instaura un certain degré d'autonomie régionale.

En septembre 1983, le président Nimeiri annonça sa décision d'étendre au droit pénal le domaine du droit musulman, cantonné depuis la colonisation au droit personnel. Bien que le droit pénal soit en théorie uniquement personnel et proportionné.

Cette décision est l'élément déclencheur d'une guerre civile qui oppose le Gouvernement (GOS) à des groupes armés du Soudan du Sud. Ce conflit s'analyse le plus souvent comme une guerre de religion entre le Nord et le Sud — chrétien. Si cette dimension religieuse existe certainement, comme en témoigne le déclenchement de la guerre civile consécutive à l'instauration de la charia par le gouvernement du Nord, il n'en demeure pas moins qu'elle est à tempérer, le Sud étant minoritairement chrétien et plutôt animiste. Ce sont donc plutôt deux cultures, une tribale traditionaliste au sud et une arabo-musulmane au nord, qui s'opposent. On peut aussi y analyser une opposition entre le Centre et la périphérie, expliquant ainsi aussi les moteurs des conflits au Darfour, à l'ouest du pays, et dans le Béjaland, à l'est du pays.

Après une pénurie de pain et d'essence, une insurrection grandissante dans le Sud, une période de sécheresse et de famine, un autre coup d'État, mené en 1985 par le général Souwar ad-Dahab, restaura un gouvernement civil. Cependant la guerre civile faisait de plus en plus de morts et la situation économique continuait à se dégrader.

En 1989, à la suite d'un coup d'État, le général Omar al-Bashir devint chef de l'État, Premier ministre et chef des forces armées. La loi pénale de 1991 institua des peines sévères dans tout le pays, telles que l'amputation et la lapidation. Bien que les États du Sud non musulmans soient officiellement exemptés de ces dispositions, la loi permet cependant une possible application future de la charia dans le Sud.

La guerre civile a déplacé plus de quatre millions d'habitants du Sud et fait deux millions de morts. Certains ont fui dans des villes du Sud comme Djouba, d'autres ont cheminé vers le nord jusqu'à Khartoum ou ont pris le chemin de pays voisins comme l'Éthiopie, le Kenya, l'Ouganda ou l'Égypte. Ces gens ne pouvaient pas produire de la nourriture ou gagner de l'argent pour se nourrir, et la malnutrition et la famine se sont répandues. Le manque d'investissement dans le Sud a également abouti à ce que les organisations humanitaires internationales appellent une « génération perdue », mal éduquée, sans accès aux soins de base et sans grandes chances de trouver un emploi productif que ce soit dans le Sud ou dans le Nord.
Les pourparlers de paix entre les rebelles du Sud et le gouvernement ont fait des progrès notables en 2003 et au début de l'année 2004, même si des accrochages se seraient encore produits dans certaines régions méridionales.

Une nouvelle rébellion dans la province occidentale du Darfour a commencé début 2003. Le gouvernement et les rebelles ont été accusés d'atrocités au cours de cette guerre. En février 2004, le gouvernement a proclamé sa victoire sur la rébellion mais les rebelles disent garder le contrôle des zones rurales et certaines sources indiquent que des combats continuent à de nombreux endroits. Les milices janjawids sont accusées du massacre de plus de cinquante mille personnes, le conflit ayant fait, en trois ans, plus de trois cent mille morts et trois millions de déplacés et réfugiés, selon certaines estimations.

Le , un accord de paix a été signé à Nairobi entre John Garang (APLS) et le vice-président Ali Osmane Taha, représentant le gouvernement soudanais. Il met fin à vingt-et-un ans de guerre civile dans l'État, dominé par les musulmans et les miliciens chrétiens de Garang. Cet accord prévoit un régime d'autonomie de six ans au Soudan du Sud, période à l'issue de laquelle un référendum d'autodétermination sera organisé.

Le , la nouvelle constitution, élaborée grâce aux accords de Nairobi, est appliquée et permet le retour du mouvement de John Garang à Khartoum. Un gouvernement d'union nationale est instauré pour cette période de transition.

Le , John Garang meurt dans l'accident de l'hélicoptère ougandais qui le transportait, dans le Sud du Soudan. Cela provoque plusieurs jours d'émeutes dans la capitale ainsi qu'à Djouba entre les partisans de Garang et ceux du gouvernement. Les partisans de l'ancien chef rebelle John Garang ne croient en effet pas à la thèse officielle du gouvernement selon laquelle l'hélicoptère a été victime de problèmes techniques. Ils déclenchent des émeutes à Khartoum, provoquant les représailles de militants nordistes. Ces violences font, d'après le bilan du , cent trente morts et plus de trois cent cinquante blessés.
Le référendum d'autodétermination du Soudan du Sud prévu par les accords de paix a eu lieu le . Les votants se sont exprimés en faveur de la sécession à 98,83 %. Le , Omar el-Béchir a officiellement reconnu ce résultat. Ce nouvel État a accédé à son indépendance dès le . En perdant plus d'un quart de son territoire, le Soudan perd également son « statut » de plus grand État d'Afrique (au profit de l'Algérie) qu'il détenait depuis son indépendance en 1956.

Selon certains observateurs, la sécession du Sud ne manque pas d'alimenter une certaine inquiétude au sein de la population quant à l'avenir du pays. Jusqu'ici, le gouvernement central profitait des ressources pétrolières du Sud (qui assurait 85 % de la production nationale) pour, « acheter » la paix civile avec les différents groupes rebelles qui sévissaient dans le Nord. Avec des revenus en baisse, il lui sera difficile de poursuivre ce type de politique. Ainsi, selon Fouad Hikmat, analyste à l'International Crisis Group : . Cette manne pétrolière permettait également de limiter les conséquences économique de la crise en jugulant l'inflation, garantissant une certaine « paix sociale ».

Face à ces nombreux défis intérieurs, ces mêmes observateurs craignent que les durs du régime, « débarrassés » du Sud chrétien et animiste, n'en profitent pour se radicaliser en accélérant l'islamisation du reste du pays, comme le président Bashir l'avait laissé entrevoir, d'autant plus que les effectifs des communautés chrétiennes se trouvant dans le Nord se sont largement réduits par le fait que l'essentiel de leurs membres, originaires du Sud, ont regagné leur région d'origine en prévision de l'indépendance de celle-ci.

Le Soudan est une république de type présidentiel dont l'actuel président est Omar al-Bashir. Avec son parti, il contrôle le pays depuis le coup d'État militaire du .

De 1983 à 1997, le pays était divisé en cinq régions dans le Nord et trois dans le Sud, chacune dirigée par un gouverneur militaire. Les parlements régionaux ont été suspendus après le coup d'État militaire du . Le Conseil révolutionnaire a été aboli en 1996 et le Front national islamique au pouvoir a pris le nom de Congrès national. Après 1997, les structures administratives régionales ont été réformées vers un système de 26 États. Les membres des exécutifs régionaux sont nommés par le président de la République. Le budget des États est entièrement dépendant du pouvoir central de Khartoum.

À la suite d'une décision de la cour pénale internationale (CPI), Omar al-Bashir est désormais sous le coup d'un mandat d'arrêt international.

Du 11 au 15 avril 2010 ont eu lieu les premières élections régionales, législatives et présidentielle tenues depuis 1986. Les deux principaux rivaux du général Omar al-Bashir, , un musulman laïque soutenu par le Mouvement populaire de libération du Soudan (SPLM, ex-rebelles sudistes) et Sadek al-Mahdi, ancien Premier ministre et chef du parti Umma (nationaliste) ont décidé de boycotter le processus électoral et retiré leur candidature. Entaché de graves irrégularités mais porteur d'espoir aux dires de Véronique de Keyser, chef de la mission d'observation de l'Union européenne, le scrutin a reconduit le général Omar El-Béchir dans ses fonctions de chef de l’État.

Le Soudan est situé dans le Nord de l'Afrique, en bordure de la mer Rouge, entre l'Égypte et l'Érythrée. Il est traversé de part en part par le Nil.

Avec une superficie de , le Soudan est le troisième plus grand pays d'Afrique après l'Algérie et la République démocratique du Congo. Avant l'indépendance du Soudan du Sud en 2011, le Soudan était le plus grand pays d'Afrique.

Le Soudan est une très grande plaine entourée à l'est et à l'ouest par des montagnes. Le climat y est semi-aride dans le Sud et désertique dans le Nord, avec la saison des pluies d'avril à octobre. La désertification qui s'étend vers le sud et l'érosion des sols sévissent sur le pays.

Le Soudan est un État fédéral divisé en dix-sept États ou "wilayat".

L'agriculture est la principale activité économique locale du pays, bien que 90 % des ressources économiques proviennent du pétrole que contient ses sols (ce qui explique les tensions ou conflits dans ce pays).

La superficie des terres cultivables au Soudan est estimée à kilomètres carrés. Seulement 18 % sont actuellement exploités. Seule une paix dans ce pays lui permettrait de devenir le grenier à blé de l'Afrique.

Les principaux produits agricoles sont le coton, le sésame, l’arachide, la gomme arabique dont le Soudan est le premier producteur mondial et le sucre (troisième pays producteur de sucre en Afrique).

Le cheptel, le deuxième du continent africain, est à la base d'un intense trafic clandestin avec les pays voisins.

L'exploitation pétrolière a commencé dans le Sud et modifie les conditions économiques du pays.

Le Nord possède les raffineries et contrôle la répartition des profits.


En 2014, la population du Soudan est estimée à environ 35,5 millions d'habitants.

Le Soudan est majoritairement peuplé d'Arabes (70 %), de , de Fours, de Bejas et de Noubas.

Les langues officielles de la république du Soudan sont l'arabe et l'anglais. Selon l'article 8 de Constitution de 2005 :

Le Soudan est un pays majoritairement musulman dont la constitution prévoit la liberté de religion ; cependant, en pratique le gouvernement soudanais traite l'islam comme la religion d'État et certains préceptes de la charia sont en vigueur dans tout le pays.

En réaction à la sécession du Soudan du Sud, peuplé majoritairement d'animistes et de chrétiens qui se sont affranchis du régime islamique et de la charia, à la suite du référendum d'autodétermination du , le président Omar el-Béchir a annoncé un renforcement de la charia dans les régions septentrionales du pays restant sous le contrôle de Khartoum.

Il y aurait au Soudan 93 % de musulmans (majorité de sunnites, et minorité chiite), 5 % de chrétiens coptes (il y a une cathédrale de l'église copte à Khartoum), les 2 % restants sont composés d'animistes, de protestants, et de baha'is.

Le jeudi 14 mai 2014, un tribunal de Khartoum a condamné une femme enceinte de huit mois à la pendaison, pour avoir adopté la religion chrétienne. Née de père musulman mais élevée par sa mère chrétienne-orthodoxe, Meriam Yahia Ibrahim Ishag est mariée à un chrétien-catholique. Elle a été aussi condamnée pour cela à 100 coups de fouet, cette union étant considérée comme un adultère. Libérée officiellement le 24 juin 2014, réfugiée à l'ambassade des États-Unis le 27, elle a quitté le Soudan avec sa famille le 24 juillet pour l'Italie, où elle a été reçue par le pape au Vatican.

Tayeb Saleh, , Jamal Mahjoub et Abdallah Al-Tayeeb sont les principaux visages de la littérature soudanaise et arabe.

Adam D. H. Hinawi dit Adam Dalfalla et Nezar Musa Noreen sont les peintres contemporains les plus connus.

Le Soudan a pour codes :


</doc>
<doc id="2831" url="https://fr.wikipedia.org/wiki?curid=2831" title="Salaryman">
Salaryman

Plus qu'un type de poste ou de responsabilités, ce mot désigne un style de vie masculin, dans lequel le travail et les collègues de travail occupent l'essentiel du temps et des centres d'intérêts du .

Contrairement à ce que suppose le terme « cadre », ce type de poste est accessible au Japon à la plupart de ceux qui terminent leur premier cycle universitaire (quatre années d'études).



</doc>
<doc id="2832" url="https://fr.wikipedia.org/wiki?curid=2832" title="Saltimbocca">
Saltimbocca

Le saltimbocca, littéralement « saute en bouche », est un mets italien. Il est aussi populaire dans le sud de la Suisse, en Espagne et en Grèce.

Probablement d'origine bresciane, il est aujourd'hui une spécialité de la cuisine romaine, plus connu comme "saltimbocca alla romana".

Il s'agit d'une escalope de veau coupée très finement, sur laquelle est appliquée une tranche de "prosciutto crudo" avec une feuille de sauge. Légèrement enfariné, l'ensemble est roulé et maintenu fermé par un cure-dents, puis cuit dans du beurre avec ajout de vin blanc en fin de cuisson.

Pour accompagner ce mets, il est traditionnellement servi le même vin blanc qui a été utilisé lors de la cuisson.





</doc>
<doc id="2837" url="https://fr.wikipedia.org/wiki?curid=2837" title="Système immunitaire">
Système immunitaire

Le système immunitaire d'un organisme est un système biologique constitué d'un ensemble coordonné d'éléments de reconnaissance et de défense qui discrimine le soi du non-soi. Il est hérité à la naissance, mais autonome, adaptatif et doué d'une grande plasticité, il évolue ensuite au gré des contacts qu'il a avec des microbes ou substances environnementales étrangères au corps.

Ce qui est reconnu comme non-soi est détruit, comme les pathogènes : virus, bactéries, parasites, certaines particules ou molécules « étrangères » (dont certains poisons). Le système immunitaire est responsable du phénomène de rejet de greffe.

On dénombre plusieurs types de systèmes immunitaires parmi les espèces animales, et généralement plusieurs mécanismes immunitaires collaborent au sein d'un même organisme. De nombreuses espèces, dont les mammifères, utilisent la "variante" décrite ci-après.

Les principaux effecteurs du système immunitaire sont les cellules immunitaires appelées leucocytes (ou globules blancs) produites par des cellules souches, au sein de la moelle osseuse rouge.

Il existe deux grands types de mécanismes de défense :

On appelle réponse immunitaire l'activation des mécanismes du système immunitaire face à la reconnaissance de non-soi, agressive ou pas, face à une agression ou à une dysfonction de l'organisme. 
L'ensemble de ces systèmes (y compris chez l'homme lors de la vaccination) permet la résilience immunitaire, notion qui recouvre la somme des mécanismes efficaces de défense d’un organisme vis-à-vis d’un agent pathogène (du grec "pathos" : souffrance) ; il se dégrade avec l'âge (Immunosénescence).

L'organisme se défend contre les dysfonctions de ses cellules et les agressions, c'est-à-dire des processus qui ont pour conséquence de détruire des êtres vivants. Ces agressions peuvent revêtir différentes formes :


Les leucocytes phagocytaires ou phagocytes sont des cellules immunitaires qui reconnaissent les microorganismes grâce à de nombreux récepteurs cellulaires présents à leur surface. Ces récepteurs permettent aux phagocytes de reconnaître certaines structures présentes à la surface des microorganismes infectieux et d'internaliser ces derniers à l'aide d'une vacuole digestive. Par la suite, ils fusionnent la vacuole contenant les microbes avec un lysosome. Les lysosomes peuvent contenir des formes toxique d'oxygène comme du monoxyde d'azote (NO) ou du peroxyde d'hydrogène (), et ils peuvent aussi contenir du lysozyme et d'autres enzymes digestives qui dégradent des structures microbiennes. Il existe 4 types de leucocytes phagocytaires :

Le système du complément est un ensemble de protéines faisant partie de l'immunité non spécifique et agissant par une cascade protéolytique. Elles se situent dans le plasma sanguin, où elles vont combattre l'infection. Normalement inactives, elles seront activées par des substances présentes à la surface de beaucoup de pathogènes. La cascade de réactions qu'elles entraînent va mener à la destruction des cellules étrangères.

La pierre angulaire de ce système est la protéine C3b. Elle permet :

On arrive à la protéine C3b du complément de 3 façons différentes :

La réaction inflammatoire donne des symptômes qui sont causés par la libération de médiateurs chimiques. C'est l'histamine qui est le plus actif dans l'inflammation. Libéré par des mastocytes situés dans le tissu conjonctif, il va provoquer la dilatation des vaisseaux. 
Les quatre signes de l'inflammation sont : rougeur, chaleur, douleur et œdème.

Les globules blancs passent la majeure partie de leur temps hors du système circulatoire, et patrouillent dans le liquide interstitiel des cellules où se déroulent la plupart des luttes contre les agents pathogènes. Certains macrophages résident en permanence dans les organes (poumons, foie) ou dans le système lymphatique.

Le système lymphatique comprend divers organes (thymus, moelle osseuse, rate, amygdales, appendice et ganglions lymphatiques) qui jouent un rôle important dans le système immunitaire. Le Tissu lymphoïde du tube digestif est quantitativement le plus important ; réparti dans plusieurs organes du tractus digestif il joue un rôle essentiel pour la défense de l’organisme contre les organismes extérieurs.

Les capillaires lymphatiques drainent une partie du liquide interstitiel qui baigne les tissus. Le liquide, alors appelé lymphe, finit par retourner dans la circulation sanguine via le canal thoracique. Sur son parcours, la lymphe traverse de nombreux ganglions lymphatiques dans lesquels tout agent pathogène rencontre des globules blancs.


De même que, si les molécules présentes à la surface des agents pathogènes ou des cellules cancéreuses proviennent du soi ou en sont suffisamment proches, le système immunitaire les considèrera comme du soi et ne déclenchera pas de réaction immunitaire.
Le problème est similaire pour les muqueuses où la frontière entre le soi et le non-soi est très ténue. Des molécules habituellement bien tolérées peuvent donc y devenir allergisantes quand elles pénètrent dans des espaces d'où elles devaient être absentes.

Le système immunitaire "humoral" agit contre les bactéries et les virus dans les liquides du corps humain (tels que le sang en sécrétant des substances susceptibles d'aider à la destruction des agents pathogènes- historiquement le sang et la lymphe étaient nommés les "humeurs" du corps). Ses principaux moyens d'action sont les immunoglobulines, aussi appelées "anticorps". Les anticorps sont des molécules ayant une forme de «Y» formées de quatre chaines polypeptidiques: deux chaines légères (environ 200 acides aminés chacune) et deux chaines lourdes (environ 450 acides aminés chacune). Il existe 5 classes d'anticorps: les IgM, les IgG, les IgA, les IgE et les IgD. Les IgM sont les premiers anticorps à être produits lorsque le corps reconnait un nouvel antigène. Ceux-ci se retrouvent dans le corps sous forme de pentamère et ils sont très efficaces pour activer le complément. Les IgG sont la classe d'anticorps la plus retrouvée dans le sang, c'est aussi la seule classe d'anticorps qui peut traverser le placenta et donner au fœtus une immunité passive. Ces anticorps favorisent l'opsonisation (marquage de l'antigène pour qu'il soit phagocyté), la neutralisation (empêcher les microbes de se lier au cellules de l'hôte) et l'agglutination (formations d'agrégat de microbes qui sont facilement phagocytés) des antigènes. Les IgA se retrouvent dans les sécrétions (salive, larme, mucus, etc.) sous la forme de dimères. Cette classe d'anticorps permet la neutralisation et l'agglutination d'antigène. De plus, la présence de ce type d'anticorps dans le lait de la femme permet aux nouveau-nés de recevoir une immunité passive durant la période d'allaitement. Les IgE sont les anticorps impliqués dans les réactions allergiques puisqu'ils provoquent la libération d'histamine et d'autres substances impliquées dans ce genre de réaction par les granulocytes basophiles. Finalement, les IgD sont retrouvés à la surface des lymphocytes B dit «naïfs» (qui n'ont pas encore été exposés à un antigène) et servent de récepteurs cellulaires à ceux-ci. Contrairement aux quatre autres classes d'anticorps, les IgD ont une région transmembranaire qui leur permet de se fixer à la membrane cellulaire des lymphocytes B. Les quatre premières classes d'anticorps sont produites par les plasmocytes qui sont l'« évolution » des lymphocytes B ("B" car les lymphocytes B ont été découverts chez l'oiseau dans la bourse de Fabricius ; par la suite le « B » fut conservé car "bone marrow", (la moelle osseuse en anglais) correspond au lieu de maturation de ces cellules à la suite de la reconnaissance par certains de leurs récepteurs membranaires d'interleukine (molécule chimique permettant le clonage des LB et leur différenciation) produite par les lymphocytes T4.

Notons l'existence d'une maladie impliquant le système immunitaire adaptatif. Il s'agit du "Bare Lymphocytes Syndrome" (). Les patients souffrant de cette maladie ne peuvent présenter d'antigène à la surface des cellules présentatrices d'antigène et il ne peut donc pas y avoir production d'anticorps. Cette maladie a notamment permis des avancées en biologie moléculaire en permettant l'identification par complémentation d'un facteur de transcription essentiel, le transactivateur de classe II (CIITA).

Le système immunitaire cellulaire s'occupe des cellules infectées par des virus, bactéries, et les cellules cancéreuses. L'action s'effectue via les lymphocytes T ("T" parce que ces cellules mûrissent dans le thymus après leur naissance dans la moelle osseuse). Les lymphocytes T sont capables d'interagir avec les cellules de l'organisme grâce à leurs récepteurs cellulaires formés de deux chaînes polypeptidiques: la chaîne α (alpha) et la chaîne β (bêta). Ces récepteurs sont tout aussi spécifiques aux antigènes que les anticorps ou que les récepteurs de lymphocytes B, mais, contrairement aux anticorps et aux récepteurs de lymphocytes B, les récepteurs de lymphocytes T ne reconnaissent que de petits antigènes qui doivent être présentés par une molécule de CMH à la surface d'une cellule infectée. On distingue deux grandes familles de Lymphocytes T :

Aux lymphocytes T s'ajoutent aussi les lymphocytes NK (natural killer). Ces cellules sont impliquées dans une réponse à mi-chemin entre spécifique et non spécifique, selon les situations. Ils jouent notamment un rôle en début de grossesse, le fœtus devant se protéger contre elles pour pouvoir survivre dans le ventre de sa mère.

Chaque individu acquiert en vieillissant une « mémoire immunologique ». Elle conserve un certain temps les traces de "lutte" passée contre des pathogènes ou parasites, et des cellules spécifiques, permettant une réaction immunitaire plus rapide et efficace. Cette mémoire se constitue de manière naturelle, ou à l'aide de vaccins mais semble se dégrader avec l'âge (phénomène d'immunosénescence).

En effet, l'exposition antérieure à un antigène modifie la vitesse, la durée, et l'intensité de la réaction immunitaire. La réaction immunitaire première consiste en la production de cellules effectrices des lymphocytes lors d'une première exposition à l'antigène. Lors d'une seconde exposition au même antigène, la réaction immunitaire secondaire sera plus rapide et efficace car l'organisme aura conservé en mémoire certains lymphocytes de la première attaque.
C'est le principe de la vaccination : on injecte un antigène à la personne pour qu'elle se crée une « "mémoire humorale" », qui sera directement efficace lors d'une éventuelle attaque ultérieure.
Une étude en 2015, basée sur la comparaison de la santé de « vrais » et « faux » jumeaux (210 jumeaux au total, de 8 à 82 ans, suivis pour plus de 200 paramètres de leur système immunitaire, ce qui est une première en nombre de paramètres d'intérêt immunologique), confirme qu'après la naissance, l'environnement a plus d'effets que nos gènes sur le fonctionnement et l'efficacité de notre immunité, notamment via l'exposition antérieure de l'organisme à des agents pathogènes (et/ou à des vaccins). Les réponses différentes des vrais jumeaux à la vaccination anti-grippale montrent aussi que les réactions (production d'anticorps) ne dépendent pratiquement pas des traits génétiques mais presque entièrement de l'éducation immunitaire de chacun, et donc de nos relations antérieures à l'environnement microbien et parasitaire (dans ce cas liées à des contacts précédents avec diverses souches du virus de la grippe). Face au cytomégalovirus, qui sommeille dans une fraction importante de la population humaine (ne causant que de rarement des symptômes), les conclusions sont les mêmes.

Bien qu'une analyse de l'immunité en facilite la compréhension, dans la réalité il existe une synergie des différentes composantes de son système. En effet, la vie perpétue des échanges incessants avec son environnement. En rejetant ses déchets dans le monde qui l'entoure et en s'appropriant ses informations, son énergie et sa matière, elle s'efforce de subsister, voire de croître et de se reproduire. Le non-soi devient alors du soi et le soi du non-soi.
Chez les organismes complexes, ces frontières sont parfois difficiles à préciser. Ainsi les aliments appartiennent au non-soi et, grâce à la mastication et aux autres processus de la digestion ils se transforment en partie en soi, sauf pour les déchets qui sont éliminés principalement via les excréments, l'urine et moindrement via l'expiration, la peau et les phanères.
Les molécules libérées constituants un excellent milieu de développement pour certaines autres formes de vie, le système immunitaire digestif est très efficace et il semble que plus de 70 % des anticorps de l'organisme y soient synthétisés. D'ailleurs, au cours des conjonctivites et des rhinopharyngites, les sucs digestifs de l'estomac coupent les virus et les microbes en petits morceaux qui, en dehors des repas, sont présentés aux globules blancs du système digestif pour qu'ils synthétisent les anticorps appropriés.
Qu'une des étapes de ce processus soit perturbée et l'immunité tarde à se mettre en place ou réagit excessivement (ex : "« tempête de cytokines »"). 
Ainsi, en 2004, Liuzzi et al. ont démontré que le pancréas et l'intestin grêle étaient les organes de l'homéostasie du zinc. Or, cet oligoélément joue un rôle primordial dans la digestion des aliments, des microbes, des virus, etc. De même l'immunité diminue lors des carences en vitamine D, et l'équilibre entre l'inflammation et la cicatrisation repose sur le ratio des apports en acides gras saturé/acides gras insaturés, etc.
De plus, au cours de l'allergie, la présence de certaines molécules dans des territoires où elles ne devraient pas être déclenche des réactions pathologiques.

La meilleure compréhension des mécanismes globaux de l'immunité pourrait peut-être à l'avenir permettre de réduire les problèmes de rejet de greffe car la compatibilité entre un receveur et un donneur ne provient pas que de l'ADN, mais aussi d'enzymes et de facteurs d'immunité qu'on commence à rechercher dans le domaine de la biologie adaptative (via l'immunoséquencage notamment). À l'échelle d'une vie, l'évolution du système immunitaire peut être comparée aux mécanismes complexes en jeu à d'autres échelles dans l'évolution adaptative. De même des vaccins plus "personnalisés" pourraient être imaginés.

Le système immunitaire peut se dégrader en réagissant excessivement ou insuffisamment.

S'il s'attaque aux cellules de l'organisme qui ne sont pas pathologiques (par mauvaise reconnaissance), il va alors se créer une maladie auto-immune qui va se caractériser par une inflammation continue de certains tissus ou par la nécrose complète de certains tissus (par exemple le diabète de type I).

S'il y a un défaut du système immunitaire, dans ce cas les pathogènes ou les cancers pourront se développer plus aisément.




</doc>
<doc id="2840" url="https://fr.wikipedia.org/wiki?curid=2840" title="Serment d'Hippocrate">
Serment d'Hippocrate

Le serment d'Hippocrate est un serment traditionnellement prêté par les médecins en Occident avant de commencer à exercer. Le texte original de ce serment, probablement rédigé au , appartient aux textes de la Collection hippocratique, traditionnellement attribués au médecin grec Hippocrate. Le serment d'Hippocrate peut être considéré comme le texte fondateur de la déontologie médicale.

Dans sa forme historique, ce serment n'a pas de valeur juridique, les médecins étant soumis à des codes nationaux régulièrement actualisés. Dans ses formes modernes, la prestation d'un serment médical a gardé sa valeur symbolique.

Traduction par Émile Littré du serment d'origine :

En 1839, parait à Paris, chez l'éditeur J-B. Baillière, le premier tome des Œuvres complètes d'Hippocrate, édition critique en français, avec le texte grec en regard, traduction d'Emile Littré. Ce dernier a placé dans ce premier tome, les textes éthiques, et en premier de ces textes, celui intitulé "Le Serment." Il s'agit d'un texte très court, sans présentation, ni commentaire, tel qu'on peut le lire ci-dessus.

On peut comparer la version de Littré avec une version plus moderne, qui serait plus proche du Grec ancien, celle de Jouanna. Toutefois, la version de Littré reste une référence, par sa fidélité à l'original, et sa qualité littéraire (langue française du ).

Les textes hippocratiques sont un ensemble de textes d'auteurs différents (dont Hippocrate lui-même) rédigés sur une période d'un siècle à peu-près, probablement autour de 440-360 av. J.-C. On sait peu de choses sur la datation exacte du Serment, ni pourquoi, ni dans quel but il a été rédigé, ni même qui étaient précisément les prestataires de ce serment.

En Grèce antique, l'exercice de la médecine n'était pas règlementé comme aujourd'hui. L'art de soigner était entièrement libre, depuis les prêtres-guérisseurs des temples et sanctuaires, jusqu'aux exorcistes et rebouteux. De ce vaste ensemble émergent des communautés familiales spécialisées dans l'art médical. Ce sont les Asclépiades, qui se transmettent savoirs et pratiques, de père en fils, par apprentissage dès l'enfance. Hippocrate appartenait à l'une de ces familles qui faisaient partie de l'élite culturelle, au contact des grands courants philosophiques et scientifiques grecs. "Le Serment" semble se placer au moment où ces communautés familiales s'élargissent aux étrangers (par adoption ou contre rémunération) pour leur enseigner la médecine.

Les Asclépiades se seraient séparés des prêtres-guérisseurs, pour envisager les maladies comme un phénomène naturel et logique, et non pas comme une colère divine. Ce ne sont pas des athées : la nature est bien d'origine divine, mais la nature elle-même est soumise à des règles autonomes, accessibles à la raison humaine. « Le médecin-philosophe est l'égal des Dieux » (Hippocrate. "De la Bienséance", 5)

Ces médecins sont itinérants, pratiquant la médecine de cités en cités, la plupart des cités grecques de cette époque ne dépassant guère quelques milliers d'habitants. Venant de l'extérieur, le médecin doit inspirer la confiance en offrant des marques de respect. Notamment en transposant le respect des sanctuaires sacrés à celui du domicile du malade.

Selon A. Debru, presque chaque mot du Serment a fait l'objet de controverses et de nouvelles hypothèses.

Ce serment commence par une invocation aux Dieux, puis il se compose de deux parties bien distinctes et sans transition. La première concerne les devoirs de l'élève envers son maître, cette partie a l'allure d'un contrat (engagement contractuel). La deuxième concerne les devoirs envers les malades, avec des obligations et des interdits, cette partie a l'allure d'un code ou d'une table de commandements. Enfin le texte se termine par une louange et une malédiction, selon la teneur de l'engagement.

L'invocation aux Dieux se comprend aisément. Apollon est Dieu et médecin en tant que père d'Asclépios (Esculape), le héros guérisseur, lui-même père de deux filles, Hygie, déesse de la santé, et Panacée, déesse des soins. L'engagement au sein d'une famille (réelle ou symbolique) de médecins se fait sous l'égide d'une famille divine. Les médecins hippocratiques étaient appelés Asclépiades car ils prétendaient descendre d'Asclépios.

La première partie montre la force de la relation maître-élève en médecine, elle équivaut à la relation père-fils. Le respect du maître relève de la piété filiale. C'est une vieille idée de l'antiquité qui a longtemps persisté : dans certains métiers, on ne peut être bon que de père en fils, car seul l'apprentissage dès l'enfance permet d'acquérir les dispositions nécessaires. Le nouveau-venu ou le tard-venu dans le domaine médical souffrait d'un préjugé défavorable. L'ouverture de l'enseignement médical à l'extérieur de la famille doit tenir compte de ce préjugé. L'élève est vraiment un nouveau fils, puisqu'il s'engage à pourvoir, si nécessaire, aux besoins du maître et à l'enseignement gratuit des enfants du maître. Son insertion professionnelle est aussi une insertion générationnelle.

Cette partie du serment se présente comme un contrat associatif entre maître et élève, c'est l'expression d'une libre volonté entre individus privés. Ce n'est pas une loi, ou un règlement imposé, de la Cité qui s'appliquerait à des citoyens. Ce type d'engagement est différemment interprété par les historiens. Selon Edelstein, la force quasi-mystique et religieuse de cet engagement n'a qu'un seul équivalent en Grèce antique : le rituel d'initiation des Pythagoriciens qui, eux aussi ont une relation maître-élève analogue. C'est un des arguments qui font dire à Edelstein que le Serment d'Hippocrate serait imprégné de pythagorisme. D'autres, comme Debru, pensent que cette partie du serment ne reflète qu'une confrérie professionnelle, une guilde qui prend sa place dans la société.

Le bien du malade, au physique et au moral, est la priorité du médecin. Celui-ci doit faire ce qui est utile et avantageux pour le malade.

Cela commence par la direction du régime (diététique). Selon la doctrine hippocratique, un régime approprié peut corriger le déséquilibre des humeurs. Les avis divergent sur le sens de « je m'abstiendrais de tout mal et de toute injustice », il faudrait lire « je les écarterai de tout mal et de toute injustice », c'est-à-dire, non seulement proposer ce qui est bon, mais aussi interdire ce qui est mauvais pour le malade. Selon Edelstein, les Pythagoriciens définissent les appétits du corps comme des conséquences des tendances de l'âme. Le médecin doit aider le malade à lutter contre des désirs malsains et incontrôlés d'une nourriture qui ne lui convient pas.

L'interdiction du poison a fait l'objet d'un débat. Cela a été interprété comme l'interdiction du meurtre ou de la complicité d'assassinat, ou encore comme une mesure de sécurité pharmaceutique (remèdes dangereux). Les commentateurs modernes considèrent qu'il s'agit bien de l'interdiction de faciliter le suicide assisté.

Il existait dans l'antiquité païenne, ce que Danielle Gourevich appelle le suicide philosophique rationnel, qu'elle décrit ainsi : le candidat au suicide (faisant partie de l'élite intellectuelle) s'informe et réfléchit, il prend l'avis de médecin sur la gravité et le pronostic de sa maladie. Le médecin ainsi consulté sait parfaitement qu'il s'agit de suicide. Le candidat discute avec sa famille et ses amis. Il prend sa décision, les réunit, fait un dernier sermon sur les valeurs de sa vie, et avale une coupe de poison, fournie par son médecin. L'Histoire a retenu le nom de Thrasyas de Mantinée, un médecin qui aurait inventé une « drogue de la mort douce », à base de pavot et de cigüe.

Edelstein passe en revue toutes les écoles philosophiques grecques et leur positionnement sur le suicide. Une seule pose un interdit absolu, sans aucune exception : celle des Pythagoriciens. Il explique ainsi pourquoi ce passage du serment ne correspond pas avec ce qu'on sait de son cadre social. L'auteur du serment ferait partie d'un groupe isolé et minoritaire.

Cette interdiction est contradictoire avec d'autres textes hippocratiques ("De la nature de l'enfant", "De la nature de la femme") où le médecin conseille ou participe à des manœuvres abortives. John M. Riddle interprète ce passage comme une interdiction des pessaires en tant que moyens, mais pas de l'avortement en lui-même.

La quasi-totalité des commentateurs considère qu'il s'agit bien d'une interdiction, par principe, de l'avortement. Mais les avis divergent encore, car il existe plusieurs théories antiques du fœtus (du statut de l'embryon). Selon l'une, le fœtus ne nait que de la semence paternelle, la mère n'étant qu'un réceptacle (le sol qui reçoit la graine). Le fœtus ne prendrait vie que lors de son animation (lorsque la mère en perçoit les mouvements), ce qui correspond à peu près au de grossesse. L'interdiction du Serment ne concernerait que les avortements tardifs.

En fait la théorie dominante des textes hippocratiques est celle de l'union des semences paternelles et maternelles, où le fœtus croît sous l'harmonie du chaud (chaleur de la mère) et du froid (respiration de la mère). Le fœtus est vivant dès sa conception. Cette théorie est aussi celle des Pythagoriciens. Edelstein fait remarquer que les interdictions du poison et de l'avortement s'enchaînent en une seule phrase, aussitôt suivies d'un appel à l'innocence et à la pureté du médecin. Il en conclut qu'il s'agit plus que de simples interdits éthiques, mais bien de véritables tabous, conformes au Pythagorisme.

 La taille était l'opération chirurgicale qui consistait à extraire un gros calcul (la pierre) de la vessie (lithiase vésicale). De nos jours, dans les pays développés, la lithiase vésicale est devenue une maladie rare (contrairement à la lithiase rénale ou urétérale), mais elle se rencontre encore dans les pays les plus pauvres. Elle était très fréquente dans l'antiquité, où elle touchait principalement les enfants en étant liée à des carences alimentaires et vitaminiques, surtout au moment du sevrage ; la maladie n'apparaissant aux yeux des médecins antiques que des années plus tard. L'opération se pratiquait donc le plus souvent chez le grand enfant, ou le très jeune adulte. Elle nécessitait de la part de l'opérateur du sang-froid, de la dextérité, et de la rapidité. Un opérateur doué et chanceux peut l'effectuer en une minute. Cette opération dite "taille par le petit appareil" sera délaissée à partir du apr. J.-C.

Les avis divergent sur les raisons d'interdiction d'une opération commune à l'époque. Emile Littré pensait qu'il s'agissait de ne pas prendre le risque de castration (en fait de vasectomie, section d'un canal déférent) ; Debru, le risque mortel d'infections. La plupart des commentateurs y voient plus simplement l'avertissement de ne pas aller au-delà de ses compétences : il faut laisser cette opération « à ceux qui s'en occupent ». L'expression a donné à penser qu'il existait des chirurgiens spécialistes dès cette époque, mais cela peut vouloir dire aussi qu'il faut laisser cette opération à « ceux qui en ont l'expérience », ou à « ceux qui osent en assumer le risque ».

Pour Edelstein, l'auteur du Serment ne fait que respecter un tabou pythagoricien : l'interdiction d'inciser. Pour les autres, il s'agit tout aussi bien d'éviter de léser le malade (« d'abord ne pas nuire ») que d'éviter d'y laisser sa réputation.
Au domicile du patient, le médecin maitrise sa conduite par la force de ses vertus. Dans le texte hippocratique "Du Médecin", cela passe d'abord par l'attitude qui convient pour plaire au malade. Le médecin doit être d'aspect propre et avenant « en ayant une physionomie réfléchie, sans austérité ; autrement il paraitrait arrogant et dur ; d'un autre côté [il ne faut pas] se laisser aller au rire et à une gaieté excessive (...) ce ne sont pas de petits rapports que ceux du médecin avec les malades ; les malades se soumettent au médecin, et lui, à toute heure, est en contact avec des femmes, des jeunes filles, des objets précieux ; il faut, à l'égard de tout cela, garder les mains pures » ("Du Médecin", 1).

Le Serment met en valeur ce refus d'abuser de la situation (méfaits, faveurs sexuelles). Le médecin sait résister à la tentation tout en restant accessible. C'est ce qu'on appellerait aujourd'hui « la neutralité bienveillante », qui s'applique ici à tous, libres ou esclaves. Dans d'autres textes hippocratiques, on retrouve ce refus de distinguer entre riches et pauvres, concitoyens et étrangers, comme le fameux « S'il y a lieu de secourir un homme étranger et pauvre, c'est surtout le cas d'intervenir ; car là où est l'amour des hommes est aussi l'amour de l'art ».

La discrétion sur ce que le médecin voit ou entend, peut être comprise comme une façon de préserver la confiance du malade et de sa famille. Cependant le texte précise « même en dehors de l'exercice de ma profession », Edelstein s'en étonne pour en conclure qu'il ne s'agit pas là d'une discrétion de précaution, mais bien d'un devoir de secret. en toutes circonstances. Attitude qui serait à mettre en parallèle avec les pratiques de silence et de secret des Pythagoriciens. Pour d'autres commentateurs, il s'agit d'un moyen d'asseoir la réputation sociale du médecin.

Enfin, le Serment se termine sur une louange et une imprécation, avec l'espérance d'une réputation éternelle, mais bien terre à terre, et dans la mémoire des hommes.

Selon Edelstein, "Le Serment" peut être compris comme un véritable manifeste Pythagoricien (rituel initiatique, importance du régime, divers tabous, abstinence sexuelle, silence et secret, etc.) d'une faible minorité de médecins. Cette interprétation, vraie ou fausse, est devenue moins importante aujourd'hui. Un autre aspect émerge, celui d'un texte de défense professionnelle, dans un contexte précaire, où les médecins, pour exister, doivent surtout compter sur leur image et leur réputation.

La renommée d'Hippocrate existait de son vivant et grandit après sa mort. Son œuvre sera abondamment commentée et reprise tout au long des siècles suivants. Mais le Serment, lui, aura un faible impact sur la réalité des pratiques médicales de l'antiquité, surtout dans le monde romain.

Pline l'Ancien se vantait de ce que les Romains ont vécu pendant six siècles sans avoir besoin de médecins, c'est-à-dire de professionnels prétendant posséder un savoir réfléchi. A ses yeux, le médecin est une invention grecque. Les premiers médecins Grecs arrivent à Rome vers le av. J.-C. Pas plus que les Grecs, les Romains n'ont de législation précise sur l'enseignement ou la pratique de la médecine. Il n'existe pas de règles, ni de sanctions. Les médecins se répartissent tout au long de l'échelle sociale : du médecin de haut rang, médecin-ami d'un riche et puissant personnage, au sorcier-guérisseur de campagne, en passant par le médecin-fonctionnaire des gladiateurs.

Du au apr. J.-C., les interdits du Serment ne sont pas appliqués : la plupart des médecins fournissent du poison, des remèdes abortifs, et pratiquent l'opération de la taille. La littérature latine forge même l'image de l'anti-Hippocrate, du médecin marron, assassin, fraudeur, menteur, voleur et séducteur. Néron avait ses médecins-bourreaux qu'il envoyait pour aider au " suicide " de ses ennemis. Lorsqu'une femme ou son médecin était condamnés pour avortement, c'était pour avoir lésé les droits du père. En effet, le fœtus appartient au père, qui dispose du droit de vie et de mort sur le nouveau-né, la naissance étant le seul moyen d'en vérifier le sexe.

Cependant, il existe toujours des médecins hippocratiques fidèles à l'esprit du Serment. On cite plusieurs cas de médecins qui ont préféré se suicider plutôt que d'aider au suicide demandé (cas du médecin de l'Empereur Hadrien). Par leurs écrits, des médecins entretiennent et développent une réflexion éthique, comme Scribonius Largus, Soranos d'Ephèse, Celse, Galien... avec des inflexions nouvelles. L'avortement reste interdit mais avec des exceptions liées à la santé de la mère (grossesse à risque). Aux valeurs hippocratiques de justice, pureté, discrétion... s'ajoutent celles de compassion et d'empathie. Mais ces dernières peuvent vite se transformer en complaisance, surtout avec les malades du sommet de l'échelle sociale.

Le Serment d'Hippocrate se retrouve dans une position fragile, voire impossible. C'est alors que de nouvelles croyances surgissent dans le cadre du monothéisme juif. Le Serment va servir de pont entre le savoir médical et la foi en un Dieu unique et créateur.

Dans le monothéisme juif (et plus tard chrétien et musulman), le monde a été créé par un Dieu unique, la nature procède de sa parole. De même, l'homme a été créé à l'image de Dieu. Ce Dieu parle aux hommes pour leur inculquer sa Loi. Si la maladie et la guérison viennent de Dieu, les trois religions doivent résoudre le conflit, du moins la tension, entre le fatalisme de la maladie et le devoir de soigner.

Dans le monde juif, les pratiques de soins sont étroitement liées aux pratiques religieuses. Outre la Bible, le Talmud ( av. J.-C. au apr. J.-C.), et différents autres textes rabbiniques énoncent les exigences rituelles de pureté (séparation du pur et de l'impur, purifications, régime alimentaire...), ainsi que les devoirs envers les malades. Ces devoirs s'accompagnent d'interdits concernant l'avortement, l'infanticide (exposition des nouveau-nés), le suicide etc. autant de contenus qui ne sont pas contradictoires avec l'éthique du Serment d'Hippocrate. Dans le Talmud apparaissent des distinctions entre le prêtre chargé de dire le pur et l'impur (le « cohanim »), « hygiène préventive » selon Isidore Simon, et un médecin plus professionnel, chargé des techniques de soins (le « rophé »).

Au contact du monde gréco-romain et des doctrines hippocratiques, une évolution apparait. Au proche-Orient, à l'époque pré-islamique, des juifs étudient aussi la médecine dans les écoles du Nestorianisme (Antioche, Alexandrie, Ninive...). La maladie reste toujours perçue comme d'origine divine, mais soigner devient noble en soi. Le premier serment post-Hippocratique est le serment d'Assaph. Assaph Ha-Yehoudi aurait vécu à Tibériade en Palestine, à une date indéterminée, entre le et le apr. J.-C., pour enseigner la médecine en Syrie. Son serment est connu comme manuscrit du apr. J.-C. Il s'agit d'un pacte entre maître et élèves, faisant référence à Hippocrate et Galien. La guérison est l'œuvre de Dieu, le médecin n'est qu'un instrument dans la main de Dieu, mais c'est un instrument autonome qui cherche les remèdes dans la nature, car si le mal est d'origine divine, le remède l'est aussi. Assaph reprend le triangle hippocratique du médecin, de la maladie et du malade, pour ré-affirmer avec Hippocrate que le médecin aide le malade dans sa lutte contre la maladie. Le médecin doit soigner gratuitement les pauvres, ne commettre aucun crime dans sa pratique, ni infliger d'infirmités.

Isaac Israeli (), dans son "Guide du Médecin" ou "Morale médicale", traite de la noblesse de la médecine. L'homme est à l'image de Dieu, mieux connaitre l'homme pour le soigner, c'est mieux connaitre l'œuvre de Dieu. Il en est de même pour la nature, création de Dieu. Le médecin prépare l'action de la nature, « il est celui qui enlève les pierres du chemin » de la guérison. Israeli donne une grande place à l'aspect spirituel (« psychologique ») de la relation médecin-malade. Ainsi, selon lui, promettre la guérison a, en soi, une valeur thérapeutique.

L'éthique de la médecine hébraïque est finalement contenue dans le serment de Maïmonide (médecin du ), mais il s'agit d'un texte d'un médecin juif de Berlin, rédigé en 1783, qui se serait inspiré de la prière des médecins de Zahalon (médecin juif de Rome du ). Il existe, de toute façon, une continuité éthique, faite de prières et de serments, qui intègre ou recycle le Serment d'Hippocrate aux préoccupations des communautés médicales juives.

L'islam apparait en Arabie au . La nouvelle religion doit se confronter à la mentalité païenne des tribus nomades bédouines, à leur morale faite d'honneur et d'hospitalité, mais aussi de vengeance guerrière, de polygamie et d'infanticides (exposition des nouveau-nés de sexe féminin), et dont la médecine est de type magique (djinns et démons). Dans les centres urbains les juifs et les chrétiens entretiennent leurs savoirs traditionnels. En Perse et en Égypte, les musulmans rencontrent la culture de langue syriaque (langue sémitique) qui transmet le savoir gréco-romain. Ils vont réaliser un vaste travail de synthèses et de compromis pour appuyer leur foi nouvelle. La morale coranique prend en compte les idéaux des philosophes grecs, la distinction pur/impur de la tradition hébraïque, des éléments de la morale chrétienne (nestorienne), Cette morale met en avant les devoirs et l'humilité à l'égard de Dieu, et la fraternité des croyants.

Il existe une médecine prophétique, populaire, qui insiste sur la dimension spirituelle, la foi et le fatalisme, qui tente de réunir toutes les opinions, authentiques ou non, de Mahomet sur la santé et les maladies. Le Coran et ses versets peuvent avoir en eux-mêmes une valeur magique thérapeutique. Il existe aussi une médecine plus ouverte et plus professionnelle, représentée par des médecins cultivés (philosophie grecque et médecine gréco-romaine). Au fur et à mesure de la conquête musulmane, tout le savoir connu (y compris indien, voire chinois) est pris en compte.

Le plus important, et le plus ancien, texte d'éthique médicale est celui de Ruhawi (Ishaq ibn 'Ali al-Ruhawi) (), auteur de « "Adab al-Tabib »" ("Morale pratique du médecin"), qui se réfère à Aristote, Platon, Hippocrate et Galien. En 20 chapitres, l'auteur cherche à montrer la dignité de la médecine, conçue comme une aide aux malades avec l'aide de Dieu. Le médecin est « le gardien du corps et de l'âme ». Forces du corps et forces morales vont de pair. Le médecin doit être au malade, ce qu'un bon gouvernant est à son pays. Le médecin doit être pieux, sensible, lettré, il agit sans hâte. Il agit par la crainte de Dieu, qui lui donne la force d'être clément et miséricordieux, vrai et utile pour le malade. Le médecin reste humble face à Dieu, et digne devant les hommes. Ruhawi critique les soignants indignes : les charlatans et les empiriques non-lettrés qui lèsent le petit-peuple, et les médecins mondains qui flattent leurs malades riches et puissants, pour profiter d'une vie de cour. Pour lui, devenir médecin nécessite une prédisposition vertueuse. Il suggère de faire passer un examen aux élèves, basé non seulement sur le savoir médical, mais aussi sur les idées et les forces morales du candidat.

De même qu'il existe une tradition islamique de la mémoire des actes et des paroles du Prophète, il existe une tradition des actes et des paroles des grands médecins, où Hippocrate et Galien sont en position prééminente. La personne même d'Hippocrate est mise en valeur (ce que ne font ni les juifs ni les chrétiens). C'est le médecin-modèle, l'ancêtre exemplaire qui sera considéré comme tel dans le monde arabe jusqu'au . L'image retenue est celle d'un Hippocrate, sage et modéré, ferme et courageux dans ses valeurs morales, qui méprise l'argent, et qui tient tête aux puissants qui veulent l'utiliser ou le corrompre. Bien entendu, les musulmans (comme les juifs et les chrétiens) vont adapter le Serment d'Hippocrate, en supprimant les références aux Dieux païens, le naturalisme trop terrestre, et la recherche de renommée.

Selon J.C Sournia on ne connait pas de serment musulman, mais selon G. Strohmaier un serment d'Hippocrate adapté a pu être prêté par les futurs médecins, probablement à Bagdad à partir du . Ibn al-Ukhuwwa (mort en 1329) est un muthasib (inspecteur fonctionnaire de la cité et des marchés), auteur d'un ouvrage où il énumère les devoirs de sa fonction, notamment de vérifier les médecins en les questionnant sur leurs études faites, leurs instruments, en leur faisant prêter le serment d'Hippocrate. Toutefois, comme ceci n'est appuyé par aucune loi, il s'agirait plus d'un idéal à atteindre que d'une obligation.

Dans les Evangiles, Jésus apparaît comme un guérisseur, faiseur de miracles. Il rend la vue aux aveugles, et il fait marcher les paralytiques. Plus exactement, c'est la foi en Jésus qui guérit, mais Jésus est aussi souffrant sur la croix, il est sauveur par son corps meurtri et humilié. Pour les premiers chrétiens, le corps est un problème : une source de péchés et de désirs à réprimer. Il y a aussi la souffrance rédemptrice, la résurrection de la chair, l'immortalité de l'âme... autant de concepts apparemment étrangers à la doctrine hippocratique. Au maximum, quand l'Église deviendra riche et influente, un mouvement monastique ascétique se produira en réaction. Des moines iront affronter les démons dans les déserts, la maladie apparaissant même nécessaire et désirable pour leur salut 

Toutefois, les médecins hippocratiques (enseignants et élèves éduqués aux écoles de Cos) n'ont pas été écartés de la vie quotidienne des païens convertis à la foi chrétienne. Selon O.Tomkin, malgré le mouvement ascétique, il se produit une infiltration de la médecine hippocratique, dans le monde chrétien, dès le apr. J.-C. Les pères de l'Église qui élaborent une doctrine chrétienne de la nature humaine, vont aussi se servir du savoir et du comportement hippocratique, le rendant compatible avec la foi en Jésus-Christ.

Déjà dans le Didaché, on trouve le concept judéo-chrétien (et hippocratique) du respect de la vie (interdit du meurtre, de l'avortement, de l'abandon des nouveau-nés). Au III siècle Origène cherche une synthèse entre foi chrétienne et philosophie grecque. Toutes les sagesses et connaissances (y compris médicales) doivent être attribuées à Dieu. Saint Jérôme se réfère à Hippocrate comme modèle de vertus et d'étiquette (langage, habillement, manières, discrétion).

Saint Basile et Saint Jean Baptiste parlent de l'utilité de la médecine, des plantes médicinales, de la nécessité de combattre la maladie. Le corps est la demeure (voire le temple) de l'âme, et mérite le respect en tant que tel. Une distinction est créée entre médecine du corps et médecine de l'âme qui entrent en résonance, chacune prenant modèle sur l'autre. Le Christ reste le médecin suprême de l'âme, en retour le médecin chrétien du corps reçoit un peu de prestige du Christ. Le naturalisme hippocratique est reconnu par l'Église, comme un ensemble de principes d'ordre et de règles, d'observation et de méditation personnelle, principes créés et voulus par Dieu.

Cassiodore (490-585) mentionne les serments sacrés des hommes de l'art de médecine. En Occident, on trouve une médecine monastique (pratiquée dans les couvents et les monastères), faite de rituels, prières, et plantes médicinales. Les moines-médecins sont engagés dans les soins aux pauvres. Ils accomplissent l'œuvre de Dieu car « ce que Hippocrate dit, c'est ce que Dieu permet ». Le malade est objet d'amour car il reproduit l'image du Christ souffrant et nécessiteux. Le Serment d'Hippocrate est cité ou reproduit dans de nombreux manuscrits médicaux anonymes du IX au XI siècle, y compris jusqu'en Europe du Nord. La présentation du texte en forme de croix (voir illustration en début d'article) montre l'intégration chrétienne d'un texte païen (l'invocation aux Dieux étant remplacée par l'invocation à Dieu).

Toutefois les mondes juifs, chrétiens et musulmans ne sont pas séparés, ils s'imbriquent et s'influencent mutuellement, ce sont ces influences conjointes qui touchent l'occident après le avec la création de l'école de médecine de Salerne, puis celle des Universités de Médecine, comme celle de Montpellier. Durant le , cinq conciles restreignent puis interdisent la pratique médicale aux religieux (trop de moines s'absentent de leurs monastères pour apprendre la médecine et la pratiquer à titre privé).

À partir du , la médecine devient peu à peu entièrement laïque (les médecins sont laïques, mais les Universités de médecine sont patronnées par l'évêque local). C'est la médecine scolastique, qui voit la séparation progressive de la médecine et de la chirurgie. La médecine dite « art libéral » est enseignée à l'Université, alors que la chirurgie dite « art manuel » s'enseigne entre compagnon et apprenti. Dans les Universités françaises, selon C. Allix, on ne prêtait pas de serment identique ou analogue à celui d'Hippocrate. En revanche, les chirurgiens organisés en confréries ou compagnonnages pratiquaient des serments rituels.

La première version imprimée du serment d'Hippocrate est la traduction latine du grec de Fabio Calvo. Elle se trouve dans la première édition des Œuvres d'Hippocrate ("Hippocratis Octoginta volumina...") imprimée à Rome en 1525.

En Allemagne, les universités de médecine se dotent de statuts faisant prêter un serment d'Hippocrate, incluant la loyauté envers l'Université et ses Autorités (Heidelberg et Iéna, en 1558).

Après la Renaissance, une multitude de théories et de systèmes médicaux rivalisent avec la médecine hippocratique, mais les idéaux du Serment gardent leur prestige. En Angleterre, sous la période Elizabethaine (), apparaissent les premières règlementations professionnelles des médecins qui s'appuient directement sur le Serment d'Hippocrate. On connait 4 versions anglaises du Serment, ce sont les premières adaptations modernes. Aux idéaux hippocratiques se superposent des préoccupations sociales. Ainsi « enseigner gratuitement les enfants du maître » est changé en « soigner gratuitement les pauvres ». Le Serment engage l'intégrité et la dignité de la profession médicale, en retour l'État assure la régulation des activités des médecins et sanctionne les illégaux.

Au , cette dignité ne résiste guère à la réalité sociale. Les médecins de Molière sont bien une réalité, puisqu'un médecin, Samuel Sorbière (1610-1670), rédige un petit ouvrage au titre significatif « "Avis à un jeune Médecin sur la manière dont il doit se comporter en la pratique de la médecine, vu la négligence que le public a pour elle, et les plaintes qu'on fait des médecins »""."

Au , des médecins des Lumières citent toujours le Serment d'Hippocrate, mais avec ce commentaire « existe-t-il un païen plus honnête ? », façon ironique de laisser entendre qu'il existe des chrétiens plus malhonnêtes.

La Révolution française détruit radicalement l'Ancien Régime. Les fondations d'un nouveau monde médical sont posées sous l'Empire (commencées sous le Directoire, et terminées sous la Restauration). Médecine et chirurgie sont réunifiées, enseignées dans des hôpitaux publics. La génération médicale révolutionnaire, qui rejette toutes les vielles théories et anciens systèmes, a vraiment l'impression de repartir de zéro : « Supposons que rien n'est encore fait, que tout est à faire », tel est le mot de François Magendie. La médecine est refondée par la méthode anatomo-clinique et la physiologie expérimentale. Les doctrines d'Hippocrate et de Galien sont totalement rejetées. En moins d'un demi-siècle, la Grande-Bretagne et l'Allemagne adoptent cette révolution médicale, suivis par le monde entier.

Pourtant Hippocrate reste encore debout. L'Hippocrate doctrinaire, celui des 4 humeurs, est oublié, mais l'Hippocrate clinicien, celui qui observe les malades sans idées préconçues, est un précurseur prestigieux pour les médecins Français. L'Hippocrate environnemental, celui qui observe les airs, les lieux et les eaux où se trouvent les malades, est un modèle non moins prestigieux pour les médecins Anglais. Le Serment d'Hippocrate lui, se ritualise, il s'imprime à la fin des thèses de doctorat. En France, la Faculté de Montpellier est la première à faire un long serment d'Hippocrate en latin, au nom de Dieu, en 1804, puis en français au nom de « l'Être suprême » en 1872.

Elle sera imitée par la plupart des autres facultés, celle de Paris d'abord, puis Strasbourg, qui adopteront des versions plus courtes (parfois réduites à une seule phrase) du Serment de Montpellier. Le Serment a du mal à entrer dans la modernité. Par exemple, dans son ouvrage sur l'histoire française de la contraception et de l'avortement au , A. McLaren met bien les médecins comme acteurs du débat, mais sans jamais citer une morale hippocratique. Les médecins ne font pas appel à une morale, mais à leur savoir : ils sont là pour justifier médicalement l'ordre social dominant, notamment l'infériorité de la femme, et son incapacité foncière à prendre des décisions qui doivent rester sous le contrôle de la société masculine.

Les limites du Serment sont d'autant plus apparentes que l'on utilise un nouveau vocabulaire : les termes d'éthique et de déontologie. En Angleterre, Thomas Percival (1740–1804) est le premier médecin à rédiger un code moderne d'éthique médicale. En 1803, il publie « "Medical Ethics, or a Code of Institutes and Precepts, Adapted to the Professional Conduct of Physicians and Surgeons »". Ce code aura une grande influence dans les pays anglophones, il sera adopté par les médecins américains dès 1847, et périodiquement révisé aux États-Unis. Il en est de même pour le Canada et l'Australie.

En France, le médecin M. Simon réalise un travail analogue en 1845 « "Déontologie médicale ou des devoirs et des droits des médecins dans l'état actuel de la civilisation" », mais son impact sera plus limité. Contrairement aux pays anglo-saxons, la France du et de la République n'a pas un ensemble fiable et écrit de consignes éthiques, ni de règlementation précise sur la pratique médicale. Le Code Napoléon ne prévoit pour les professionnels de santé qu'un seul article, l'article 378 du code pénal, sur le secret médical. La loi s'applique surtout aux médecins au courant des faits biologiques et sexuels de leurs patients. Au départ, il s'agissait, pour le législateur, de préserver la réputation des familles, et d'assurer la transmission des biens (héritages). Le médecin remplace le curé en tant que gardien de secret.

Pour défendre leurs intérêts et leur réputation, les médecins anglais s'associent sur le modèle du club de gentlemen, en France ils doivent le faire sur le modèle du syndicat. De fait, la déontologie française d'origine répond d'abord aux besoins intra-professionnels des médecins (entre eux et avec les autres professionnels de santé) et seulement indirectement aux intérêts des patients. Cette déontologie restant informelle, les syndicats médicaux français proposent la création d'un Conseil de l'Ordre dès la fin du . Il sera créé sous le régime de Vichy, le 7 octobre 1940, dissous à la Libération et recréé par l'Ordonnance du 24 septembre 1945, signée par le ministre communiste de la Santé François Billoux (premier gouvernement de Gaulle). Ce nouvel Ordre, plus autonome, est chargé de rédiger un code de déontologie qui sera inscrit dans la loi en 1947. Depuis cette date, tous les médecins français ont l'obligation légale de se conformer à ce code, périodiquement révisé.

Le Serment d'Hippocrate n'est plus qu'un symbole rituel, mais qui garde son prestige. Au cours de l'histoire, il apparait comme un nucleus, un noyau sans cesse retaillé, qui cristallise autour de lui toutes les nouvelles préoccupations d'une époque ou d'une civilisation. Ce que l'on croit comprendre du serment d'Hippocrate diffère souvent d'une période ou d'un contexte à l'autre. Même les médecins criminels nazis, au cours de leur procès, se sont situés dans le cadre du serment, en étant indignés que l'on puisse rejeter leur interprétation.

« Dans de telles circonstances, l'histoire du Serment d'Hippocrate devient l'histoire de l'éthique médicale en elle-même. Son sens peut disparaître, ou devenir si étroit qu'il ne s'applique qu'à peu de thèmes comme l'avortement, l'euthanasie, ou le secret médical, hors du contexte plus large de la médecine hippocratique ancienne. Il est sorti de l'histoire de la médecine pour devenir un argument de rhétorique ».

Après la seconde guerre mondiale, l’« Association médicale mondiale » (AMM) est créée en 1947, prenant la suite de l’Association professionnelle internationale des Médecins d'avant-guerre. C'est une organisation internationale officielle sur les problèmes d'éthique médicale. 

Sa première mission a été de formuler un équivalent moderne du serment d’Hippocrate, connue comme la Déclaration de Genève ou serment de Genève (1948). Elle a aussi élaboré un Code international d’éthique médicale (1949) puis un « Manuel d’éthique médicale ».
La Déclaration ou Serment de Genève a été amendé plusieurs fois, sa dernière révision (octobre 2017) est la suivante :« En qualité de membre de la profession médicale, Je prends l'engagement solennel de consacrer ma vie au service de l’humanité ; Je considérerai la santé et le bien-être de mon patient comme ma priorité ; Je respecterai l’autonomie et la dignité de mon patient ; Je veillerai au respect absolu de la vie humaine ; Je ne permettrai pas que des considérations d’âge, de maladie ou d’infirmité, de croyance, d’origine ethnique, de genre, de nationalité, d’affiliation politique, de race, d’orientation  sexuelle, de statut social ou tout autre facteur s’interposent entre mon devoir et mon patient ;Je respecterai les secrets qui me seront confiés, même après la mort de mon patient ; J’exercerai ma profession avec conscience et dignité, dans le respect des bonnes pratiques médicales ; Je perpétuerai l’honneur et les nobles traditions de la profession médicale ;Je témoignerai à mes professeurs, à mes collègues et à mes étudiants le respect et la reconnaissance qui leur sont dus ; Je partagerai mes connaissances médicales au bénéfice du patient et pour les progrès des soins de santé ;Je veillerai à ma propre santé, à mon bien-être et au maintien de ma formation afin de prodiguer des soins irréprochables ; Je n'utiliserai pas mes connaissances médicales pour enfreindre les droits humains et les libertés civiques, même sous la contrainte ; Je fais ces promesses sur mon honneur, solennellement, librement.»Dans les années 1990, plus de 110 pays font prêter un serment dans les facultés de médecine. À part l'Extrême-Orient et l'Australie, on retrouve un peu partout un serment inspiré du Serment d'Hippocrate ou du Serment de Genève.

Au niveau européen, il n'y a pas encore d'harmonie entre les codes nationaux de  déontologie médicale. Des conférences internationales travaillent à l'unification européenne du droit médical (Principes d'éthique médicale européenne, en 1987). Il n'existe pas de serment européen, la référence restant le serment mondial de Genève (ci-dessus).

Les médecins sont soumis au code de déontologie, inscrit dans le Code de santé publique, qui a force de loi. Toutefois les facultés de médecine font encore généralement réciter un serment aux nouveaux médecins (dans les années 1990, un serment médical est prêté dans au moins 25 facultés de médecine sur 37). Ce serment moderne, le plus souvent toujours appelé "serment d'Hippocrate" même s'il s'en éloigne, s'inspire généralement du texte d'origine et a pour principal objectif de rappeler aux nouveaux médecins dans un cadre solennel qu'ils sont liés à des obligations légales, morales et éthiques. On peut aussi considérer son énonciation, comme un rite de passage du statut d'étudiant à celui de médecin, de valeur morale, mais sans portée juridique.

De plus, lors de l'inscription à l'Ordre, les médecins s'engagent sous serment et par écrit, à respecter le code de déontologie médicale. Les médecins français sont responsables, devant la loi, du respect de ce code.

Les médecins militaires possèdent un règlement de déontologie qui leur est propre.

Serment du Conseil de l'Ordre des médecins (2012) :

Serment d'Hippocrate, tel qu'il est prêté à la Faculté de médecine de Montpellier :

Les jeunes diplômés médecins prononcent un serment lors de l'inscription à l'Ordre des médecins, dont la version juillet 2011 est : 

Serment professionnel des médecins, en usage au Québec depuis le 15 décembre 1999 :
Les médecins suisses sont soumis à un code de déontologie, il n'y a pas de serment au niveau fédéral. Le symbolisme du serment n'existe que dans une petite minorité de cantons.





</doc>
<doc id="2841" url="https://fr.wikipedia.org/wiki?curid=2841" title="Inclusion (mathématiques)">
Inclusion (mathématiques)

En mathématiques, l’inclusion est une relation d'ordre entre ensembles. On dit qu'un ensemble est inclus dans un ensemble si tous les éléments de sont aussi éléments de . On dit dans ce cas que est un sous-ensemble ou une partie de , ou encore que est sur-ensemble de .

Cette relation n'est pas symétrique "a priori", car il peut y avoir des éléments du deuxième ensemble qui n'appartiennent pas au premier. Plus précisément, il y a inclusion dans les deux sens entre deux ensembles si et seulement si ces deux ensembles sont égaux.

L'inclusion se note majoritairement avec le symbole « ⊂ » introduit par Schröder, même si beaucoup d'auteurs réservent ce symbole à l'inclusion stricte (c'est-à-dire excluant le cas d'égalité), suivant ainsi la norme ISO. L'inclusion au sens large peut alors être notée avec le symbole « ⊆ » de Felix Hausdorff, par analogie avec les symboles de comparaison numériques. Pour lever l'ambiguïté, l'inclusion stricte peut aussi être notée « ⊊ », à ne pas confondre avec la négation de l'inclusion, qui se note « ⊄ » ou « ⊈ ». Tous ces symboles peuvent être réfléchis pour représenter les relations réciproques.

Soient deux ensembles et . Par définition, est inclus (au sens large) dans si tout élément de est un élément de . est inclus (au sens strict) dans si de plus .

En notation symbolique, l’inclusion au sens large est notée ; donc par définition (« » désigne l'implication logique) :

On peut aussi définir l'inclusion au sens large à partir de l'intersection ou de la réunion :
 est le symbole de l'inclusion stricte selon la norme de l'organisation internationale de normalisation (qui mentionne toutefois l'autre usage).
L'usage du symbole pour l'inclusion stricte s'explique par l'analogie avec le symbole .
L’inclusion au sens strict est parfois notée :
Variantes d'écriture : formula_1 formula_2.

La relation formula_3 peut se lire :
et peut aussi s'écrire formula_10, qui se lit :


Sont également utilisés « formula_5 contient formula_4 » et « formula_4 est contenu dans formula_5 », qui peuvent par ailleurs signifier formula_21.

Certains auteurs, tels que Paul Halmos et George Boolos, recommandent d'utiliser systématiquement « formula_5 inclut formula_4 » et jamais « formula_5 contient formula_4 » pour traduire formula_10, afin d'éviter toute confusion avec l'appartenance.

La relation formula_27 peut se lire :


et peut aussi s'écrire formula_34, qui se lit :



Une propriété des éléments d'un ensemble définit un sous-ensemble de celui-ci. Ainsi, en reprenant l'un des exemples ci-dessus, la propriété « être pair » définit, sur l'ensemble des entiers naturels N, l'ensemble 2N des entiers pairs. On dit que l'ensemble a été défini par compréhension et on note :
Toute propriété (quand on l'exprime dans un langage précis on parle de "prédicat" de ce langage) définit par compréhension un sous-ensemble d'un ensemble donné.

L'ensemble de tous les sous-ensembles d'un ensemble "E" donné est appelé ensemble des parties de "E", et noté habituellement « formula_41("E") », ou (écriture gothique) « formula_42("E") », voire simplement « "P"("E") » (lire dans tous les cas « "P" de "E" » ). 
On a ainsi :
Par exemple si "A" = { "a", "b" }, alors formula_41("A") = { Ø, { "a" }, { "b" }, "A" }.

Dans ce cas on aura par exemple "a" ∈ "A", donc {"a"} ⊆ A, c'est-à-dire {"a"} ∈ formula_41("A").

Les propriétés de l'ensemble des parties, en particulier celles ayant trait à la cardinalité, sont détaillées dans l'article ensemble des parties d'un ensemble. Pour le cas fini, qui relève de la combinatoire, voir aussi l'article combinaison.

Un sous-ensemble "A" d'un ensemble "E" peut être défini par sa "fonction caractéristique"   formula_46 formula_47, définie par χ("x") vaut 1 si "x" est élément de "A", et 0 sinon :
et donc (χ étant à valeurs dans {0,1})

Réciproquement toute fonction χ de "E" dans {0,1} définit un sous-ensemble de "E" qui est {"x" ∈ "E" | χ("x") = 1}. On a donc une correspondance bijective entre les sous-ensembles de "E" et les fonctions de "E" dans {0,1}, c'est-à-dire entre formula_50("E") et {0,1}.

 En formula_51, une formulation de la théorie des types, l'inclusion est représentée par le terme formula_52défini comme l'abréviation du terme formula_53

Par exemple l'ensemble des entiers naturels non nuls est inclus dans l'ensemble des entiers naturels , de même que l'ensemble des entiers naturels pairs , mais n'est pas inclus dans car , mais :
On peut remarquer que, comme il existe des entiers naturels non nuls qui ne sont pas pairs, 1 par exemple, n'est pas non plus inclus dans : . On dit alors que ces deux ensembles ne "sont pas comparables pour l'inclusion".
L'ensemble vide est l'ensemble qui n'a pas d'éléments, et on le note Ø.

Proposition (ensemble vide). L'ensemble vide est sous-ensemble de tout ensemble, c'est-à-dire que pour tout ensemble "A" :
Démonstration :
nous devons démontrer que Ø est un sous-ensemble de A, c'est-à-dire
que tous les éléments de Ø sont des éléments de A, mais il n’existe pas d’éléments de Ø.
Pour qui a un peu la pratique des mathématiques, l'inférence « Ø n’a pas d’éléments, donc tous les éléments de Ø sont des éléments de A » est évidente, mais cela peut être dérangeant pour le débutant. Il peut être utile de raisonner différemment (par l’absurde).
Si nous avions supposé que Ø n' était pas un sous-ensemble de A, nous aurions pu trouver un élément de Ø n’appartenant pas à A.
Comme il n’existe pas d’élément de Ø, c’est impossible et donc Ø est par conséquent un sous-ensemble de A.

Nous avons aussi la proposition suivante.

Proposition (réflexivité). Tout ensemble est inclus dans lui-même, c'est-à-dire que pour tout ensemble "A" :
On dit que l'inclusion est une relation réflexive.
Pour le prouver, il suffit de reprendre la définition de l’inclusion.

Une autre propriété qui elle aussi repose seulement sur la définition de l'inclusion est la transitivité.

Proposition (transitivité). Pour trois ensembles quelconques A, B et C, si A est un sous-ensemble de B et B est un sous-ensemble de C, alors A est un sous-ensemble de C, c'est-à-dire que :
de même

Contrairement aux propositions précédentes, qui se démontrent de façon purement logique, en revenant aux définitions, la propriété d'antisymétrie repose sur la notion même d'ensemble : c'est en fait la simple traduction d'une propriété fondamentale des ensembles, dite propriété d'extensionnalité, à savoir que deux ensembles sont égaux si et seulement s'ils ont les mêmes éléments.

Proposition (antisymétrie). Deux ensembles A et B sont égaux si et seulement si A est un sous-ensemble de B et B est un sous-ensemble de A, c'est-à-dire :

Quel que soit l’ensemble "E", l’inclusion munit donc son ensemble des parties formula_41("E") d’une relation d'ordre, qui n'est plus un ordre total dès que "E" possède au moins deux éléments. En effet si "a" et "b" sont deux éléments distincts de "E", les singletons {"a"} et {"b"} sont des parties de "E" qui ne se comparent pas pour l'inclusion. Cet ordre a toujours un plus petit élément, Ø l'ensemble vide, et un plus grand élément, l'ensemble "E".

Cet ordre n'est donc pas total en général mais a d'autres propriétés remarquables.

Proposition (intersection finie).
Pour deux ensembles "A" et "B" quelconques, on peut définir l'intersection de "A" et "B", qui est l'ensemble des éléments communs à "A" et à "B", noté "A" ∩ "B". Cet ensemble est le seul à être inclus dans "A" et dans "B", et à inclure tout ensemble inclus à la fois dans "A" et dans "B" :

On dit que l'ensemble "A" ∩ "B" est la borne inférieure de "A" et "B" pour l'inclusion.

On a une propriété analogue (on dit duale, en un sens précis) pour la réunion.

Proposition (réunion finie).
Pour deux ensembles "A" et "B" quelconques, on peut définir la réunion de "A" et "B", qui est l'ensemble des éléments appartenant à "A" ou à "B", noté "A" ∪ "B". Cet ensemble est le seul à inclure à la fois "A" et "B", et à être inclus dans tout ensemble incluant à la fois "A" et "B" :

On dit que "A" ∪ "B" est la borne supérieure de "A" et "B" pour l'inclusion.

Pour tout ensemble "E" l'inclusion munit donc formula_41("E") d'une structure d'ordre que l'on appelle un treillis. Du fait des propriétés de distributivité de la réunion vis-à-vis de l'intersection, et de l'intersection vis-à-vis de la réunion, ce treillis est dit distributif.

Des propriétés des intersections et réunions binaires, on pourrait déduire facilement un résultat analogue pour les intersections et réunions finies, mais on a un résultat plus fort :

Proposition (intersection et réunion quelconques).
Pour une famille quelconque d'ensembles ("A"), on peut définir l'intersection des éléments de la famille, ∩"A", et leur réunion ∪"A". L'intersection des "A" est le plus grand des ensembles inclus dans chacun des "A", la réunion des "A" est le plus petit des ensembles incluant tous les "A".

Le treillis de l'inclusion sur formula_41("E") est dit complet. Il s'agit même d'une algèbre de Boole, puisque tout sous-ensemble de "E" a un complémentaire dans "E".

Proposition (complémentaire). Soit "E" un ensemble. On appellera complémentaire d'un sous-ensemble "A" de "E", le sous-ensemble de "E" constitué des éléments de "E" qui ne sont pas dans "A", et on le notera formula_57. On a :
On montre alors que :

En théorie des ensembles, dans la théorie des ensembles de Zermelo ou de Zermelo-Fraenkel, l'inclusion n'est pas une notion primitive. elle est définie à partir de l'appartenance comme indiquée au début de l'article. Comme déjà mentionné, des propriétés de l'inclusion, comme la réflexivité et la transitivité, sont des conséquences purement logique de cette définition et l'antisymétrie de l'inclusion est exactement l'axiome d'extensionnalité.

L'existence d'un plus petit élément (ensemble vide) se montre par compréhension (voir axiome de l'ensemble vide). Il n'y a pas de plus grand élément pour l'inclusion dans l'univers de la théorie des ensembles : s'il existait un ensemble incluant tous les ensembles on pourrait, en utilisant le schéma d'axiomes de compréhension, dériver le paradoxe de Russell.

L'existence d'une borne inférieure (intersection) se démontre par compréhension. L'existence d'une borne supérieure (réunion) dans le cas d'un ensemble d'ensembles, nécessite un axiome spécifique, l'axiome de la réunion. À chaque fois l'axiome d'extensionnalité est utile pour démontrer l'unicité.

L’existence de l'ensemble des parties d'un ensemble nécessite également un axiome spécifique, l’axiome de l'ensemble des parties, et son unicité est encore une fois assurée par l’axiome d'extensionnalité.

L'appartenance et l'inclusion sont en général bien distinctes dans les mathématiques ordinaires. En théorie des ensembles une notion très utile est celle d'ensemble transitif : un ensemble dont tous les éléments sont aussi des sous-ensembles ! En particulier Les ordinaux sont des ensembles transitifs. La restriction de l'inclusion à un ordinal définit un bon ordre (et donc un ordre total), l'ordre strict correspondant est l'appartenance.

Si on introduit la notion de classe (que la notion de classe soit ou non formalisée dans la théorie, voir l'article correspondant), comme celle-ci correspond à la notion de prédicat, on peut définir de façon tout à fait analogue l'inclusion entre classes. La classe de tous les ensembles est maximale pour l'inclusion. On peut définir l'intersection et la réunion de deux classes, et donc d'un nombre fini de classes par conjonction et disjonction, le passage au complémentaire, par négation. Le complémentaire d'un ensemble dans une classe propre, en particulier dans la classe de tous les ensembles, ne peut cependant être un ensemble (par réunion). Il n'est pas question par contre non plus d'ensemble, ou même de classe, des parties d'une classe propre, celles-ci pouvant être elles-mêmes des classes propres.



</doc>
<doc id="2847" url="https://fr.wikipedia.org/wiki?curid=2847" title="Langues sames">
Langues sames

Le same (ou « lapon », terme d'origine scandinave), dénommé sámegiella ou sápmelaš ou encore sápmi ou sámi, est une langue qui fait partie de la famille des langues finno-ougriennes. Il est parlé par environ Samis exclusivement en Laponie, une vaste région transnationale allant du centre de la Suède à l'extrémité de la péninsule de Kola (Russie), en passant par le nord de la Norvège et de la Finlande.

Le same se subdivise en neuf aires linguistiques (plus deux langues éteintes), parfois considérées comme des variantes dialectales d'une même langue. (hors du conseil same et des institutions linguistiques norvégiennes et suédoises) les considèrent toutefois aujourd’hui comme des langues à part entière. Les langues sames sont classées de la manière suivante :

En 1948, les spécialistes des dialectes sames K. Bergsland et I. Ruong décident de réformer l'écriture du same du nord en vue de préserver la langue. Les Saami de Finlande dont la tradition écrite est plus marquée décident de rester à l'écart de cette réforme et choisissent de conserver leur orthographe basée sur leur propre phonétique. Les Saamis de la péninsule russe de Kola utilisant un alphabet cyrillique adapté n'étaient donc pas concernés pas cette réforme.
Depuis 1979, le same du nord est officiellement employé par les trois pays nordiques et promu par les différentes administrations scolaires, les radios, la télévision et la presse écrite. Les institutions sami comme le conseil saami ou la Fédération nationale des Saami de Suède en ont fait leur langue officielle. Elle apparaît aussi dans la signalisation routière locale.

Rasmus Rask, après avoir discuté avec Nils Vibe Stockfleth, définit, en 1832 dans "Ræsonneret lappisk sproglære", une orthographe du same du Nord basée sur le principe de transparence orthographique, c’est-à-dire d’un graphème par son.

Nils Vibe Stockfleth, inspiré par Rask, reprend ce principe dans ces ouvrages linguistiques et sa traduction de l’Ancien Testament en same du Nord, remplaçant quelques graphèmes.
Jens Andreas Friis, aidé de Hans Jacobsen Hætta et de locuteurs sames, retravaille et termine la traduction du Nouveau Testament de Stockfleth, et publie plusieurs ouvrages. Friis publie aussi un Ancien Testament avec Hætta et Just Knud Qvigstad en 1895.

Konrad Nielsen publie plusieurs grammaires et dictionnaires. 

Depuis 1948, les langues sames des pays nordiques sont écrites au moyen de l'alphabet latin, complété de quelques lettres. Cet alphabet a subi quelques modifications en 1985.

Les caractères supplémentaires sont :

N. B. : Si le est simplement redoublé "ii" à l'écrit, le "á" représente une voyelle longue mais a une aperture différente de son homologue court : á = (très ouvert, comme en finnois, entre ê et a dans "bar"), mais a = , avec une couleur postérieure comme dans "pâte".

Plus rarement :

Les résidents de la Péninsule de Kola utilisent un alphabet cyrillique adapté : ainsi, un conte bilingue (sames de Kildin et du Nord) pour enfants, publié en 1994, est titre ("Mon ami"), où l'on voit l'utilisation des macrons et de signes employés dans d'autres langues non-slaves.

Il est difficile de trouver un cours de same (les meilleurs sont en norvégien bokmål, mais de bons cours de base sont également disponibles en anglais auprès du groupement d'éditeurs Davvi Girji o.s. Par ailleurs, il existe en français une introduction à la langue et à la culture same (du Nord, essentiellement) : "Parlons lapon".




</doc>
<doc id="2848" url="https://fr.wikipedia.org/wiki?curid=2848" title="Ensemble flou">
Ensemble flou

La théorie des sous-ensembles flous est une théorie mathématique du domaine de l’algèbre abstraite. Elle a été développée par Lotfi Zadeh en 1965 afin de représenter mathématiquement l'imprécision relative à certaines classes d'objets et sert de fondement à la logique floue.
Les sous-ensembles flous (ou parties floues) ont été introduits afin de modéliser la représentation humaine des connaissances, et ainsi améliorer les performances des systèmes de décision qui utilisent cette modélisation.

Les sous-ensembles flous sont utilisés soit pour modéliser l'incertitude et l'imprécision, soit pour représenter des informations précises sous forme lexicale assimilable par un système expert.

Une partie formula_1 d'un ensemble formula_2 est usuellement associée à sa fonction caractéristique. Celle-ci s'applique sur les éléments "x" de formula_2. Elle prend la valeur 0 si "x" n'appartient pas à formula_1 et 1 si "x" appartient à formula_1.

On souhaite définir une partie formula_1 floue de formula_2 en attribuant aux éléments "x" de formula_2 un degré d'appartenance, d'autant plus élevé qu'on souhaite exprimer avec certitude le fait que "x" est élément de formula_1. Cette valeur vaudra 0 si on souhaite exprimer que "x" de façon certaine n'est pas élément de formula_1, elle vaudra 1 si on souhaite exprimer que "x" appartient à formula_1 de façon certaine, et elle prendra une valeur comprise entre 0 et 1 suivant qu'on estime plus ou moins certain l'appartenance de "x" à formula_1. On est donc amené à définir une partie floue de la façon suivante :

Une partie floue (ou sous-ensemble flou) d'un ensemble formula_2 est une application de formula_2 dans [0,1].

Plus généralement, si formula_15 est un treillis complet, distributif et complémenté, on définit une partie L-floue comme étant une application de formula_2 dans formula_15. Si formula_18, on retrouve la définition précédente de partie floue, et si formula_19, on retrouve la notion usuelle de partie de E.








En observant comment les opérations usuelles se comportent vis-à-vis des fonctions caractéristiques de parties, on étend ces opérations aux fonctions d'appartenance des parties floues.

Soient formula_53 une famille de parties floues d'un ensemble formula_2 indexées selon un ensemble formula_55, données par leur fonction d'appartenance formula_56. On définit la réunion formula_57 de ces parties au moyen de la fonction d'appartenance suivante :

De même, on définit l'intersection de ces parties au moyen de la fonction d'appartenance suivante :

Réunion et intersection restent distributives l'une par rapport à l'autre.

Le complémentaire d'une partie floue donnée par sa fonction d'appartenance formula_57 est la partie floue dont la fonction d'appartenance est formula_63.

Le complémentaire d'une intersection reste égal à la réunion des complémentaires, et le complémentaire d'une réunion est l'intersection des complémentaires. Le complémentaire du complémentaire redonne la partie initiale.

Cependant, la réunion d'une partie floue et de son complémentaire ne donne pas toujours l'ensemble formula_2, et l'intersection d'une partie floue et de son complémentaire ne donne pas l'ensemble vide.

En effet, considérons, par exemple, la partie floue formula_65 de formula_2 donnée par la fonction d'appartenance:
formula_67

Cette partie floue est égale à son complémentaire car sa fonction d'appartenance vérifie formula_68.

On déduit alors de formula_69 que formula_70

Soient formula_2 et formula_65 deux ensembles et formula_73 une application de formula_2 dans formula_65. Considérons une partie floue de formula_65 donnée par sa fonction d'appartenance formula_57. On appelle image réciproque de cette partie floue par formula_73 la partie floue de formula_2 donnée par la fonction d'appartenance suivante, notée formula_80 :

Soient formula_2 et formula_65 deux ensembles et formula_73 une application de formula_2 dans formula_65. Considérons une partie floue de formula_2 donnée par sa fonction d'appartenance formula_57. On appelle image directe de cette partie floue par formula_73 la partie floue de formula_65 donnée par la fonction d'appartenance suivante, notée formula_91 :

Dès 1968, Chang a appliqué la théorie des ensembles flous à la topologie, donnant naissance à la topologie floue.

Soit formula_2 un ensemble. Une topologie floue est donnée par une collection formula_94 de fonctions d'appartenance vérifiant les propriétés suivantes :

Les éléments de formula_94 sont les ouverts flous. Leurs complémentaires sont les fermés flous. La propriété (i) exprime que l'ensemble formula_2 et l'ensemble vide sont des ouverts flous, la propriété (ii) qu'une intersection finie d'ouverts flous est un ouvert flou et la propriété (iii) qu'une réunion quelconque d'ouverts flous est un ouvert flou.

Par exemple, étant donné un espace formula_2 muni d'une topologie formula_103 au sens usuel, on peut lui associer une topologie floue naturelle formula_104 en prenant pour formula_94 la collection des fonctions semi-continues inférieurement à valeurs dans [0,1]. La topologie floue ainsi définie est dite engendrée par la topologie initiale formula_103 de formula_2. Réciproquement, si formula_94 est une topologie floue définie sur formula_2, on peut lui associer une topologie formula_110 au sens usuel, à savoir la topologie la moins fine rendant toutes les fonctions de formula_94 semi-continues inférieurement.

On peut alors introduire des notions plus complexes de topologie floue.

Ainsi une fonction est continue floue si et seulement si l'image réciproque d'un ouvert flou de l'ensemble d'arrivée est un ouvert flou de l'ensemble de départ. Les fonctions constantes sont continues floues si et seulement si la topologie floue de l'espace de départ contient tous les ouverts flous définis par des fonctions d'appartenance constantes.

Par analogie à la notion topologique usuelle, un espace topologique flou est compact si, de tout recouvrement par des ouverts flous, on peut extraire un recouvrement fini. Si l'image d'un compact par une application continue floue est compacte, en revanche, le théorème de Tychonoff n'admet qu'une version limitée : seul le produit fini de compacts en topologie floue est compact. Plus généralement, soit formula_15 un treillis complet, distributif et complémenté d'élément maximum 1, soit formula_113 un nombre cardinal et soit formula_114 une famille de compacts en topologie L-floue, où formula_55 est de cardinal formula_113. Alors le produit des formula_117 est compact pour la topologie produit L-floue si et seulement si 1 vérifie la propriété suivante : pour toute famille formula_118 d'éléments de formula_15 strictement inférieurs à 1, formula_120 est strictement inférieur à 1 (théorème de Tychonoff pour la topologie L-floue). Dans le cas où formula_19, donnant la topologie usuelle, cette propriété est vérifiée pour tout cardinal formula_113 et un produit quelconque de compacts est compact. Mais si formula_123, donnant la topologie floue, la propriété n'est vérifiée que pour les cardinaux finis.

Lowen a proposé une autre définition des compacts en topologie floue. En effet, si la topologie floue comprend toutes les fonctions d'appartenance constantes, il n'existe pas de compact au sens précédent : les fonctions formula_124 sont telles que formula_125 donc ces fonctions définissent un recouvrement de l'espace mais il n'en existe pas de sous-recouvrement fini. Un espace formula_2 est compact pour la topologie floue au sens de Lowen si, pour toute fonction d'appartenance constante formula_127, tout formula_128 et toute famille d'ouverts flous formula_129 telle que formula_130, il existe une sous-famille finie formula_131 telle que formula_132. Avec cette définition, un espace muni d'une topologie formula_103 usuelle est compact si et seulement s'il est compact muni de la topologie floue formula_104 engendrée par formula_103, et un produit quelconque d'espaces compacts est compact (théorème de Tychonoff pour la topologie floue au sens de Lowen).

Enfin, on montre que le théorème de Tychonoff pour la topologie L-floue et le théorème de Tychonoff pour la topologie floue au sens de Lowen sont, comme le théorème de Tychonoff usuel, équivalents à l'axiome du choix.



</doc>
<doc id="2849" url="https://fr.wikipedia.org/wiki?curid=2849" title="Sculpture">
Sculpture

La sculpture est une activité artistique qui consiste à concevoir et réaliser des formes en volume, en relief, soit en ronde-bosse (statuaire), en haut-relief, en bas-relief, par modelage, par taille directe, par soudure ou assemblage. Le terme de sculpture désigne également l'objet résultant de cette activité.

Le mot sculpture vient étymologiquement du latin « "sculpere" » qui signifie « tailler » ou « enlever des morceaux à une pierre ». Cette définition, qui distingue « sculpture » et « modelage », illustre l'importance donnée à la taille de la pierre dans la civilisation romaine. Au , on parle d'« ymagier » et la plupart du temps, le travail du sculpteur est un travail d'équipe avec un maître et des tailleurs de pierre (Voir architecture romane et art roman). Plusieurs équipes travaillent simultanément sur les grands chantiers des cathédrales.

 
Les plus anciennes sculptures réalisées par l'homme et ayant traversé le temps sont de petites figurines rudimentaires taillées, en pierre ou en os, qui servaient probablement à des pratiques magiques, d'ex-voto, d'échanges, de rituels qui permettaient de réaliser des transactions avec des forces surnaturelles ou sociales. La "Vénus de Lespugue", sur ivoire de mammouth, en est un bel exemple. Certaines sculptures de taille plus imposante ont survécu aux millénaires qui nous séparent de leur créateur comme les bisons d'argile crue retrouvés dans la grotte du Tuc d'Audoubert en Ariège, les bas reliefs de l’abri sous roches du Roc-aux-Sorciers dans la Vienne ou les monolithes sculptés de Göbekli Tepe en Turquie. Il est probable que des objets modelés, en terre, ont aussi existé, mais en l'absence de techniques de pérennisation (cuisson), cela reste une hypothèse. D'autres sculptures, comme celles du Roc-aux-Sorciers, représentent des animaux sauvages, sans doute représentations de l’alimentation des peuples de chasseurs-cueilleurs du magdalénien.

Bien que cet usage, chamanique sans doute, ait décliné, la représentation humaine reste un thème fréquent des sculpteurs . Selon les époques et les civilisations, les artistes ont exécuté ces figurines de manière réaliste, ou bien, au contraire, ils ont pris une plus grande liberté pour interpréter leur sujet.

En occident la sculpture a tardivement été dissociée de la peinture. À Paris ces deux catégories d'artiste, que l'on distingue nettement aujourd'hui, appartenaient au Moyen Âge à la même communauté de métier des peintres et tailleurs d'images. En effet, avant l'invention des représentations en perspective modernes, le relief d'une image de grand format était rendu par un traitement en bas-relief du plan du tableau, comme sur les sculptures des églises romanes et des cathédrales gothiques (par exemple sur la cathédrale Notre-Dame de Paris dont les couleurs disparues viennent d'être retrouvées).

En France, c'est avec la création des académies de peinture et de sculpture et d'architecture que les deux métiers deviennent officiellement distincts, même si, à la Renaissance, beaucoup d'artistes restent aussi bon peintres que sculpteurs.

Au , on distingue encore le « sculpteur » qui taille des matériaux solides : la pierre, le bois ou l'ivoire, pour créer une forme unique originale et le « statuaire » qui réalise des modèles en terre (argile), en plâtre ou en cire destinés à être reproduits (technique indirecte de la « taille avec mise aux points ») ou moulés (technique de la « fonte à cire perdue » pour être coulés en métal, en bronze) le plus souvent.

Pour créer une œuvre, plusieurs manières peuvent être envisagées, voire combinées entre elles.

Traditionnellement, en occident, les matériaux utilisés en sculpture sont généralement d'origine minérale, la pierre (marbre, granite, calcaire, jade), le ciment (qui peut être moulé) ou le béton (en taille directe dans la période de prise), l'argile (porcelaine, terre cuite, pâte Fimo qui sèchent au four ou la terre glaise qui sèche à l'air libre en 24 heures), mais peuvent également être en métal (bronze, acier, aluminium, étain) et encore d'origine animale tels que l'os et l'ivoire, et végétale tel le bois, certains fruits, légumes ou cucurbitacées (la citrouille d'Halloween). La sculpture moderne et contemporaine utilise également le textile (déjà utilisé depuis le , comme sur « Marietta »), le verre, le sel, le sable (les châteaux de sable), la glace, l'eau, les cristaux liquides et d'autres matériaux fabriqués par l'homme, tels que les matières plastiques, et en particulier les PMMA (polymétacrylate de méthyle) connus sous des noms déposés comme Plexiglas ou Altuglas, ainsi que n'importe quel objet trouvé. Le papier mâché est également un matériau extrêmement économique, et les techniques de réalisation de sculptures avec ce matériau sont simples à mettre en œuvre. L'utilisation du chocolat est également en vogue et de manière générale, le monde de la cuisine créer ce qui ressemble à de la sculpture. Aussi, les possibilités d'associations avec d'autres matières sont quasi illimitées.

Dans ses derniers écrits, Joan Miró affirmait même qu'à l'avenir, on pourrait imaginer des sculptures utilisant les gaz comme matériaux. Lui faisant écho, Louis Leygue, dans son discours de réception de Nicolas Schöffer à l'Académie des beaux-arts, définissait ainsi la sculpture :

Ainsi, d'autres sculpteurs contemporains, ont ouvert la voie à des recherches nouvelles, associant des matériaux traditionnels à la haute technologie. Dans ces réflexions sur la création contemporaine, certains adoptent une position radicalement opposée aux dérives encouragées par d'importants mécènes, considérant comme sculpture, le fait de présenter dans une vitrine, un véritable veau sectionné et conservé dans du formol (œuvre de Damien Hirst).

Marta Pan, intéressée par les rapports de l'architecture et de la sculpture, a réalisé des sculptures monumentales intégrées dans l’architecture des espaces publics et urbains comme "La Perspective" dans le Parc des Sources de la Bièvre à Guyancourt.

On distingue deux grandes catégories de sculptures : le "relief" et la "ronde-bosse"

Le relief est une sculpture qui demeure attachée à un arrière-plan, se dressant hors de cet arrière-plan. Selon le degré de projection des figures au-dessus du plan, les reliefs sont qualifiés différemment : le "relief écrasé" ("stacciato relievo") : dont le relief est très faible. Les contours des figures sont finement incisés (ex : certains reliefs assyriens). 

La ronde-bosse est une sculpture conçue de façon à pouvoir être observée de tous les côtés, ou presque tous les côtés. La ronde-bosse repose souvent sur le sol ou sur un socle. Elle est parfois logée dans une niche.

On remarquera Michel-Ange jouant avec ces deux principes et exécutant des statues dont les personnages émergent du bloc (de marbre) mais pas complètement.

Dès le début du , on note chez plusieurs artistes une forte envie de se dissocier du naturalisme, réalisme et l'art figuratif : « Ce n’est pas la forme extérieure des choses qui est réelle, mais leur essence. À partir de cette vérité, personne ne peut exprimer la réalité en imitant la surface externe des choses » (Brancusi).

Si Brancusi est l’incontestable fondateur de la sculpture moderne et le maître la réduction afin de parvenir à la forme artistique pure, Marcel Duchamp est «l'inventeur» des ready-made.

Brancusi suit, systématiquement, l’esprit primordial et les principes fondamentaux de la forme, la dégageant des aspects éphémères, accidentels ou contingents. Le ready-made est un objet trouvé considéré pour son caractère esthétique comme une œuvre d'art. La «réalisation» d'un ready-made consiste, en effet, à choisir un objet manufacturé et le désigner, donc le définir, comme œuvre d'art. La démarche initiée par Brancusi et Duchamp a donné naissance à une grande partie de pratiques artistiques modernes et contemporaines telles que le non-figuratif, l'assemblage, l'accumulation, l'installation, le in-situ, le Concept Hundertwasser, le Concept Gaudi, le Concept Botarro, et plusieurs autres.

Chaque année, au début de février, se déroule à l'occasion du festival de la neige de Sapporo un grand concours de sculpture sur glace. En France, l'équivalent est le festival de Valloire, et au Québec, celui du Carnaval de Québec.

Les sculptures de sable en bord de mer sont souvent éphémères.







</doc>
<doc id="2851" url="https://fr.wikipedia.org/wiki?curid=2851" title="Liste de sculpteurs">
Liste de sculpteurs







</doc>
<doc id="2852" url="https://fr.wikipedia.org/wiki?curid=2852" title="Stéganographie">
Stéganographie

La stéganographie est l'art de la dissimulation : son objet est de faire passer inaperçu un message dans un autre message. Elle se distingue de la cryptographie, « art du secret », qui cherche à rendre un message inintelligible à autre que qui-de-droit. Pour prendre une métaphore, la stéganographie consisterait à enterrer son argent dans son jardin là où la cryptographie consisterait à l'enfermer dans un coffre-fort — cela dit, rien n'empêche de combiner les deux techniques, de même que l'on peut enterrer un coffre dans son jardin.

C'est un mot issu du grec ancien / (« étanche ») et / (« écriture »).

Dans ses "Histoires", l'historien grec Hérodote (484-445 av. J.-C.) rapporte ainsi une anecdote qui eut lieu au moment de la seconde guerre médique. En 484 av. J.-C., Xerxès, roi des Perses, décide de préparer une armée gigantesque pour envahir la Grèce (Livre VII, 5-19). Quatre ans plus tard, lorsqu'il lance l'offensive, les Grecs sont depuis longtemps au courant de ses intentions. C'est que Démarate, ancien roi de Sparte réfugié auprès de Xerxès, a appris l'existence de ce projet et décide de transmettre l'information à Sparte (Livre VII, 239) : 

Un autre passage de la même œuvre fait également référence à la stéganographie : au paragraphe 35 du livre V, Histiée incite son gendre Aristagoras, gouverneur de Milet, à se révolter contre son roi, Darius, et pour ce faire, 
En Chine, on écrivait le message sur de la soie, qui ensuite était placée dans une petite boule recouverte de cire. Le messager avalait ensuite cette boule.

Dès le , Pline l'Ancien décrit comment réaliser de l'encre invisible (ou « encre sympathique »). Les enfants de tous les pays s'amusent à le faire en écrivant avec du lait ou du jus de citron : le passage de la feuille écrite sous une source chaude (fer à repasser chaud, flamme de bougie...) révèle le message.

Durant la Seconde Guerre mondiale, les agents allemands utilisaient la technique du micropoint de "Zapp", qui consiste à réduire la photo d'une page en un point d'un millimètre ou même moins. Ce point est ensuite placé dans un texte normal. Le procédé est évoqué dans une aventure de Blake et Mortimer, "S.O.S. Météores". Il reçoit aussi une belle illustration dans le film de Claude Pinoteau, "Le Silencieux".

Un couple célèbre d'artistes de music-hall des années 1960, Myr et Myroska, communiquait les yeux bandés, en apparence par « transmission de pensée » et, en réalité, par un astucieux procédé stéganographique à base de phrases codées (dont, en particulier, des variantes de la phrase : « Myroska, êtes-vous avec moi ? »).

Le principe alors utilisé est toujours largement repris aujourd'hui.

Supposons, pour notre exemple, que, durant la Seconde Guerre mondiale, une résistante, Alice, doive envoyer tous les jours le nombre de bateaux en rade de Marseille à son correspondant à Paris, Bob. Ils conviennent qu'Alice enverra tous les jours à Bob les prix moyens de divers fruits observés sur le marché de Marseille. Il faut, bien sûr, qu'un agent ennemi, Oscar, 

Alice peut envoyer un message contenant :


Bob découvrira qu'il y a, ce jour-là, 132 bateaux.

La technique informatique citée ci-dessous comme "Codage sous forme d'une apparence de spam"
s'apparente à cette méthode.

L'avantage de la méthode est qu'Alice pourra envoyer à Bob une information très longue. Toutefois, la méthode ne peut être utilisée qu'une seule fois car Oscar pourra rapidement se rendre compte du procédé.

Alice peut envoyer un message contenant :


Les techniques informatiques décrites ci-dessous dans les rubriques
"Usage des bits de poids faible d'une image (LSB)" et
"Modulation fine d'un texte écrit" correspondent à cette technique.

L'avantage de la méthode est qu'Alice pourra envoyer à Bob une information relativement longue. Toutefois, Oscar pourrait comparer les prix transmis avec les prix réels (dans le cas du procédé LSB, faire une comparaison bit à bit), pourrait s'étonner d'une précision superflue, pourrait interdire une trop grande précision (cf. plus bas : "stérilisation").

Alice peut, le lundi, envoyer un message contenant :


et, le mardi, dans un ordre différent (Alice étant fantasque), mais avec des prix parfaitement exacts :


Le contenu réel du message est dissimulé dans la variation de l'ordre des fruits par rapport à l'ordre de la veille.

L'inconvénient de la méthode est que le message est relativement limité en taille. Si Alice se limite à 5 fruits, elle peut transmettre chaque jour à Bob une valeur comprise entre 1 et 120 (factorielle de 5). L'avantage réside dans la difficulté pour Oscar de repérer l'existence du procédé stéganographique.

Une technique informatique correspondante consiste à maintenir une image intacte mais à y incorporer une table des couleurs ou "palette" construite dans un ordre qui paraît arbitraire. Le contenu caché peut être une clef donnant accès à un message plus long. En outre, le contenu doit normalement inclure un procédé (généralement un checksum) permettant de vérifier sa validité. L'image qui sert de vecteur à un contenu caché peut être un extrait d'une image connue mais ne peut jamais être sa reproduction exacte, au risque de permettre par comparaison de révéler l'utilisation d'une technique stéganographique.

Cette technique est à risque mesuré dans la mesure où il s'applique à l'information. Son point faible réside donc dans la transmission et la diffusion de cette information.

Une société qui désire contrer l'usage de la stéganographie essayera d'empêcher, de modifier ou de détruire la transmission, la diffusion ou le message lui-même. Par exemple, en interdisant tous contenus arbitraires, abstraits, interprétables, nuancés, fantaisistes, fantasques, poétiques, etc. Elle imposera le respect de critères formels stricts. Ou, au contraire, s'efforcera, dans le secret, de stériliser toutes les informations (cf. paragraphe sur l'imagerie) à des points clés de la transmission des informations (offices postaux, …). Ce risque de manipulations est encore plus grand avec l'informatique dans la mesure où les interventions humaines sont moins nombreuses assurant ainsi la discrétion des mesures de coercition et les possibilités d'intervention plus grandes (piratage, cheval de Troie…). La destruction systématique de toute information ou des diffuseurs ou récepteurs est sans doute le plus vieux procédé dont la fiabilité n'est pas assurée (de par sa non-exhaustivité dans la pratique ; l'information étant humainement vitale).

Dans l'exemple ci-dessus, elle supprimera l'usage de décimales, imposera un ordre alphabétique, interdira les messages dont le contenu ou la langue ne sont pas compris par un préposé, etc.

De nos jours, la stéganographie peut être utilisée à deux fins distinctes : les communications humaines (humains à humains) et machines (machines à machines). Dans les deux cas de figure, il faut au strict minimum qu'il y ait deux parties : un émetteur et un receveur. Cependant, les deux peuvent ne pas se trouver dans le même « espace-temps ». Autrement dit, rien n'empêche de communiquer une information à un tiers n'existant pas encore. Il n'est donc pas improbable de trouver des messages dissimulés jadis. La problématique des contre-mesures à adopter prend alors une toute autre dimension.

La transmission de l'information étant naturelle et vitale à toute société humaine, il n'est pas envisageable de la détruire intégralement (d'où son efficacité limitée intrinsèquement). En revanche, dans le cas des communications machines, des moyens efficaces et terriblement dangereux existent (tels que le nucléaire via la destruction de tout dispositif électronique par ondes électromagnétiques…). Cette contre-mesure extrémiste mettrait à mal toute la société visée. La stéganographie peut être utilisée comme moyen de coercition dans le cadre de communications machines. Par exemple, les virus informatiques et certaines techniques de piratage peuvent en revêtir une forme. La technique du trojan en est également une.

Si l'on occulte les possibilités extrémistes, le meilleur moyen coercitif reste la modification de toute information transmise entre humains ou machines par interventions discrètes ou radicales et non leur destruction.

La coercition a l'inconvénient d'engendrer systématiquement des moyens de la contourner, et ce, sans fin envisageable (de par la nécessité de l'information).

La redondance de l'information, des transmissions ou de la diffusion reste le moyen de lutte le plus simple.

L'autre est de ne pas cacher l'information ou de la noyer. Par exemple, cacher de l'information inutile dans un message ouvert utile : le réflexe étant alors de se focaliser sur l'information cachée plutôt que d'admettre l'évidence du message en clair.

Actuellement, à la vue de la quantité du flot continu d'informations qui inonde nos sociétés modernes, il est mathématiquement impossible d'empêcher l'utilisation de la stéganographie qui a l'avantage de pouvoir revêtir d'innombrables formes cumulatives.

L'idée est de prendre un message et de le modifier de manière aussi discrète que possible afin d'y dissimuler l'information à transmettre. Le message original est le plus souvent une image. La technique de base --- dite LSB pour least significant bit --- consiste à modifier le bit de poids faible des pixels codant l'image : une image numérique est une suite de points, que l'on appelle pixels, et dont on code la couleur à l'aide d'un triplet d'octets, par exemple pour une couleur RGB sur 24 bits. Chaque octet indique l'intensité de la couleur correspondante --- rouge, vert ou bleu (Red Green Blue) --- par un niveau parmi 256. Passer d'un niveau "n" au niveau immédiatement supérieur ("n+1") ou inférieur ("n-1") ne modifie que peu la teinte du pixel, or c'est ce que l'on fait en modifiant le bit de poids faible de l'octet.

Donnons un exemple, considérons l'image
Chaque entrée de ce tableau représente un pixel couleur, nous avons donc une toute petite image 2×2. Chaque triplet de bits (0 ou 1) code la quantité de l'une des trois couleurs primaires du pixel (une image couleur aura dans presque tous les cas des groupes de 8 bits, appelés octets, mais on n'utilise que 3 bits pour clarifier l'exemple). Le bit le plus à droite de chaque triplet est le fameux bit de poids faible --- LSB. Si on souhaite cacher le message 111 111 101 111, l'image est modifiée de la façon suivante : le bit de poids faible du i octet est mis à la valeur du i bit du message ; ici on obtient :
D'autres techniques similaires sont possibles. Par exemple, l'encodage du message peut être basé sur le mode de colorisation TSL (Teinte Saturation Luminance) plutôt que RGB (Red Green Blue / Rouge Vert Bleu). Mais toutes ces techniques ont l'inconvénient d'entrainer une déformation - voire une perte - des informations de l'image et sont facilement détectables soit par comparaison avec l'image originelle, soit par analyse linéaire simple (de la parité par exemple !).

Ces techniques de stéganographie très basiques s'appliquent tout particulièrement au format d'image BMP, format sans compression destructive, avec codage des pixels entrelacé sur comme énoncé ci-dessus. Réciproquement, tout procédé de compression-décompression d'images avec pertes ou de redimensionnement de l'image est susceptible de détruire un message stéganographique codé de ces façons. On parle alors de "stérilisation". Un pays totalitaire pourrait "stériliser" à tout hasard toute image BMP entrant ou sortant de son territoire, moyennant les ressources techniques nécessaires.

Certains formats graphiques tels que GIF ou PNG permettent le stockage des couleurs de l'image par référence à une palette de couleurs insérée dans le même fichier.

Ainsi, au lieu de stocker bleu, blanc, rouge dans une image du drapeau français, on trouve dans un format de fichier la description de l'objet la suite couleur1, couleur2, couleur3 ainsi qu'une palette qui définit que couleur1 est le bleu, couleur2 le blanc et couleur3 le rouge.

La même image peut-être stockée de la façon suivante : couleur2, couleur3, couleur1 avec une palette qui définit que couleur2 est le bleu, couleur3 est le blanc et couleur1 est le rouge.

Ces deux images sont visuellement identiques, mais leur stockage est différent. Pour une image contenant 256 couleurs uniques dans sa palette, on a factorielle 256 (formula_1) façons de stocker cette image. En utilisant un code connu entre l'émetteur et le récepteur de l'image, on peut donc communiquer un message de petite taille formula_2, soit un peu moins de bits caché dans la permutation des couleurs de la palette de l'image.

Tout semble suggérer l'impossibilité de cacher un message dans un format d'image utilisant une compression "avec perte". La plupart des programmes de stéganographie sérieux s'attaquent cependant au format JPEG qui utilise ce type de compression.

L'idée n'est pas de cacher une information dans les couleurs ou dans la palette (puisqu'il n'y en a pas) mais dans les choix de compression. En effet, tout algorithme de compression nécessite une succession de choix.

Avec des algorithmes de compression tels que Zip ou Gzip, on peut choisir la puissance de compression. En consommant plus de temps calcul et/ou plus de mémoire pour les opérations intermédiaires, on peut obtenir de meilleurs résultats de compression. Ainsi deux fichiers compressés de tailles différentes peuvent être décompressés en deux fichiers identiques.

La compression dans le format JPEG est double. La première compression consiste à découper l'image en blocs de 8 fois 8 pixels et de transformer ces carrés sous une forme mathématique simplifiée. Cette compression introduit des pertes et la version mathématique peut être légèrement différente du carré original tout en étant visuellement très semblable. Une fois tous les blocs compressés, il faut coder les formes mathématiques en consommant le moins possible d'espace. Cette deuxième compression n'introduit pas de perte et elle est similaire dans les principes à ce que l'on peut retrouver dans Zip ou Gzip. C'est en introduisant dans cette phase des bits d'informations que l'on arrive à transporter un message caché.

Décaler une lettre de quelques pixels ne pose aucun problème sur une imprimante à laser et c'est pratiquement invisible à l'œil nu. En jouant sur les interlettrages d'un texte très long et à raison de deux valeurs d'espacement correspondant à 1 et 0, il est possible de transmettre un message sous forme papier, qui ne révélera son vrai sens qu’une fois analysé par un scanner ayant une bonne précision.

Historiquement, le procédé fut utilisé dès les années 1970 en utilisant non pas des imprimantes laser, mais des imprimantes à marguerite "Diablo", qui permettaient de jouer sur l'espacement des caractères au 1/120 de pouce près.

Une technique similaire — mais plus facilement détectable — consiste à marquer certains caractères d'un document. Des points peuvent par exemple être placés sous les lettres d'un texte afin de dissimuler un message. Étalées sur un texte de plusieurs pages, ces marques peuvent s'avérer relativement efficaces vis-à-vis d'un œil non-averti. Un ordinateur n'est pas indispensable à la mise en œuvre de cette technique.

N'importe quel texte de spam peut servir de base à de la stéganographie, sur la base d'un codage binaire simple de quasi synonymes. Par exemple pactole = 1, fortune = 0 ; richesse = 1, aisance = 0 ; succès = 1, réussite = 0 ; etc. Des sites du Web proposent à titre de curiosité ce genre de codage et de décodage. Des textes écrits en "langue de bois" ou en "style administratif" se prêtent particulièrement bien à l'exercice.

Dans les formats sonores, il existe à peu près les mêmes possibilités de cacher des messages que dans les images.

Dans un fichier sonore au format MIDI, il n'existe pas de palette de couleurs mais bien différentes pistes qui peuvent être permutées.

Dans un fichier sonore avec compression sans perte, on peut cacher de l'information dans des variations imperceptibles du son, les bits faiblement significatifs.

Dans un fichier sonore avec compression avec perte, on peut cacher de l'information dans les choix de compression.

Il est aussi possible de cacher des informations dans bien d'autres types de fichiers couramment échangés sur des réseaux telle la vidéo ou bien dans des textes (ce fut une des premières formes de la stéganographie) ou encore dans des zones d'un disque dur inutilisées par le système de fichiers.

Des informations peuvent aussi être cachées sur d'autres supports que des supports informatiques.

La stéganographie est exploitable dans de nombreux domaines. Elle trouve ainsi comme application commerciale le "watermarking" (apposition de filigranes électroniques), technique permettant de « tatouer » un fichier électronique (pour y introduire notamment des informations utiles à la gestion des droits d'auteur).

Il ne faut pas confondre le "watermarking", par essence invisible, avec le fait que certains formats de fichiers
offrent la possibilité d'inclure des méta-informations...
Après les attentats du 11 septembre 2001, on a soupçonné Oussama ben Laden de transmettre ses ordres en les cachant par des procédés stéganographiques dans des images transmises ou hébergées sur internet (ces suppositions n'ont jamais été étayées par des éléments concrets).
Si la cryptographie, qui permet de protéger la vie privée et l'activité industrielle sans cacher cette protection, est souvent maltraitée par les États totalitaires et les sociétés démocratiques à tendance sécuritaire, il n'en va pas nécessairement de même pour la stéganographie, qui est pourtant une technique beaucoup mieux adaptée à une activité criminelle éventuelle. 




</doc>
<doc id="2853" url="https://fr.wikipedia.org/wiki?curid=2853" title="Sarcophage">
Sarcophage

Un sarcophage est une cuve destinée à recueillir un cadavre ou un cercueil. Le plus souvent sculpté dans la pierre et placé au-dessus du sol, il est parfois enterré. Comme objet funéraire, le sarcophage est présent dans des cultures et civilisations diverses et éloignées les unes des autres ; il ne semble donc lié à aucun courant religieux particulier. 

Par homologie, le terme de sarcophage est parfois utilisé dans d'autres domaines, notamment pour désigner certaines enceintes de confinement.

Le mot français "sarcophage" vient du latin "sarcophagus" désignant le tombeau. Il s'agit d'un emploi substantivé de l'adjectif "sarcophagus" (du grec "σαρκοφάγος" (σάρξ, "sarx" désignant la chair, φαγεῖν "phagein", manger) et veut dire « mangeur de corps ou de chair ». Une pierre calcaire (d'où l'expression "lithos sarkophagos", λίθος σαρκοφάγος) était utilisée pour des sépultures antiques et qui, d'après les croyances de l'époque, hâtait la disparition des chairs (détruisait les cadavres non incinérés) ; "sarx", "sarcos" signifie « chair, viande » ; "phagein" sert à compléter le verbe "esthein" qui signifie « manger, dévorer ».

Le mot sarcophage, après avoir apparemment désigné dans l'Antiquité tous les réceptacles funéraires, donne en français vers l'an 1050 le mot "cercueil" (par une forte réduction phonétique, "sarqueu" au , serqueu au ), qu'on utilise pour parler d'un coffre allongé dans lequel on dépose le corps avant de l'ensevelir, alors que le mot sarcophage est utilisé dès le pour désigner les cercueils en pierre.

En Égypte ancienne, le sarcophage est nommé « "neb ânkh" », ce qui en traduction littérale signifie « maître de la vie », et sa forme symbolise une barque.

Par extension, le terme de sarcophage est également utilisé pour dénommer les structures servant au confinement de sites très sensibles, comme celui servant au confinement du réacteur de la centrale nucléaire de Tchernobyl après la catastrophe nucléaire en 1986, ou celui présent sur l'atoll d'Eniwetok, lieu d'essai de la première bombe H.

Le peintre Frédéric Halbreich désigne par ce nom les châssis sur lesquels il peint et qu'il fabrique à cet effet.

Dans l'Égypte antique, un sarcophage forme la couche externe de protection d'une momie d'une personne de haut rang social et est généralement composé d'une cuve extérieure et de l'emboîtement de cuves intérieures (autres sarcophages ou cercueils le plus souvent en bois). Il est souvent orné de représentations peintes ou sculptées du défunt, à l'exception du sarcophage de l'Ancien Empire. La cuve est rectangulaire avec couvercle plat ou voûté ou imite la forme du corps (sarcophage momiforme ou anthropoïde), elle a pour matériau la pierre (calcaire, albâtre, granit, basalte, quartzite, etc.), le métal (argent, or pour les souverains) ou le bois, peut être plaquée d'or, de pierres semi-précieuses.

Les sarcophages minoens, tel celui d'Aghia Triada, sont richement décorés et percés de trous dans leurs fonds, sans doute pour permettre aux liquides de s'évacuer.

Les sont des cuves en terre cuite, peintes, rappelant parfois la forme anthropoïde des sarcophages orientaux.

Le a une décoration typique de l'époque avec des représentations symboliques de la victoire. Traduisant des influences grecques et perses, il est sans doute du plus beau et du plus grand sarcophage de la période lycienne classique .

Pendant l'ère étrusque en Italie pré-romaine, suivant les époques, le sarcophage est à destination traditionnelle (inhumation) ou cinéraire (même forme mais de taille plus réduite pour les cendres du mort obtenues par crémation).

Les sarcophages romains aux cuves rectangulaires sont aussi bien en pierre, en plâtre qu'en plomb. Ils servaient à enterrer les morts issus de familles fortunées. Les sarcophages sont souvent ornés de scènes et de décorations sculptées.

L'inhumation au Moyen Âge se réalise essentiellement sur une bière (du francisque "bëra", « civière ») du au avant d'être progressivement remplacée par le cercueil en bois, les sarcophages (aux cuves souvent trapézoïdales et dont un gisant repose parfois sur le couvercle de la cuve) étant destinés à cette époque aux personnages au statut social élevé. Selon le Dictionnaire historique de la langue française, .

À partir du , la peur de la décomposition des chairs et de la disparition des corps voit la réemergence du cercueil ou du sarcophage en plomb qui permettent une meilleure conservation du corps, le sarcophage en plomb devenant à la mode au chez les personnes de haut rang social.

Si dans de rares cas, des sarcophages sont encore confectionnés pour des particuliers, l'acception la plus courante est celle des ouvrages de grandes dimensions servant au confinement de zones susceptibles de contaminer l'environnement, appelées dans certains cas enceinte de confinement. Si le plus célèbre est le sarcophage de Tchernobyl, il en existe d'autre :



</doc>
<doc id="2854" url="https://fr.wikipedia.org/wiki?curid=2854" title="Sarcophage paléochrétien">
Sarcophage paléochrétien

Un sarcophage paléochrétien est un sépulture sculptée dans la pierre, datant du christianisme ancien (art paléochrétien), entre les et .

La production des sarcophages romains à décor sculpté se répand largement dès le début du , à la suite de l'abandon progressif de l'incinération en faveur de l'inhumation (qui dans le courant du s'impose dans tout l'Empire), tout en restant un moyen de l'ensevelissement réservé aux familles fortunées à cause de son coût. Dans le contexte de la grande crise économique, politique, sociale et religieuse du , « la petite paix de l'Église » (introduite par l'édit de tolérance sous Gallien en 260 et qui assure au christianisme la tranquillité jusqu'au tournant du siècle) permet au christianisme de gagner les classes supérieures de la société (restées l'un des derniers bastions du paganisme). Les chrétiens fortunés, souvent présents dans l'armée, dans la haute administration et jusque dans l'entourage de l'empereur, sont les commanditaires des sarcophages qui apparaissent dans la deuxième moitié du et dont le traitement plastique suit les tendances contemporaines du décor sculpté. 

Ces nouveaux commanditaires sont souvent des provinciaux installés à Rome, qui sont en partie à l'origine de l'évolution du style artistique. Leur goût pour « l'art plébéien » (plus expressif et individuel à cause du lien étroit avec les réalités de la vie quotidienne), qui se mêle à la tradition hellénistique, fait naître dans les ateliers de sculpture romains une nouvelle expression artistique. Les premières manifestations de sculpture d'inspiration chrétienne s'inscrivent dans ce mouvement. 
André Grabar décèle dans ce mouvement les caractéristiques suivantes : « schématisation du dessin, simplification des formes tendant souvent à s'approcher d'une figure géométrique simple ; concentration sur un petit nombre de traits expressifs qu'on maintient et souligne, tandis que l'on réduit ou supprime d'autres traits, sacrifiés pour la clarté de l'ensemble; insensibilité à l'espace et à la corrélation, qui définit les dimensions des objets instables dans le même espace; insensibilité à la forme plastique, au poids. »

Dès la deuxième moitié du , la production des sarcophages est surtout concentrée à Rome, où elle restera importante jusqu'au début du . Cependant il existe aussi des ateliers régionaux, comme ceux de Marseille et de Carthage. Ce sont souvent les mêmes ateliers qui produisent des œuvres chrétiennes et celles qu'on peut appeler « païennes » (mais qui généralement sont simplement « profanes »). C'est pour cette raison que le décor des sarcophages chrétiens reste conforme aux pratiques de l'époque.

Le marbre utilisé pour la confection des sarcophages sculptés venait principalement de Carrare ou de Grèce (Proconnèse, île de Marmara ; Aliki de Thasos, Paros), ou encore d'Asie Mineure. Le matériau pouvait aussi bien être importé en bloc qu'après avoir été travaillé en partie, voire exécuté en œuvre finie dans les ateliers près des carrières. Ces importations de sarcophages finis ou ébauchés apportaient à Rome différentes solutions formelles, qui participèrent à la création de différents types de sarcophages.

Les trois types de sarcophages « païens » les plus courants sont utilisés aussi pour réaliser des sarcophages chrétiens : 1) à frise, 2) à colonnes; 3) à strigiles (ce dernier type, qui dérive de la cuve pour la fermentation du vin, à l'origine en forme de baignoire ornée de têtes de lion par lesquelles l'on faisait couler le vin, était décoré de scènes dionysiaques et de cannelures parallèles en forme de "s"). Le "clipeus", portant le portrait du défunt ou une épigraphe, apparaît très rapidement sur les sarcophages chrétiens. Souvent, l"'imago clipeata" prend la forme d'une coquille, à l'exemple des œuvres « païennes ». 

Mais ces types évolueront avec le temps. Celui à strigiles perd rapidement sa forme ovale, mais reste pour l'essentiel fidèle à la disposition originelle du décor. Le type à frise, dont les côtés peuvent être composés de personnages juxtaposés ou comporter de petites scènes à des hauteurs différentes, s'organisera en registres horizontaux avec un "clipeus" au centre. Dans le courant du , le type à colonnes se complexifie dans son ornement architectural (parfois remplacé par des éléments végétaux), jusqu’à prendre une forme qui associe la division en bandes horizontales des registres et la division verticale par éléments architecturaux, comme le sarcophage de l'ancien consul Junius Bassus daté de 359.

Les images chrétiennes qui apparaissent à cette époque ne sont pas liées à la nécessité de propager le christianisme, mais répondent plutôt à un goût pour la représentation figurée qui est profondément enraciné dans le monde méditerranéen.

Il est difficile de cerner le moment où certaines formes, dans l'art funéraire, deviennent des manifestations de la foi chrétienne, à cause de ce phénomène qu'Henri-Irénée Marrou appelle la "pseudomorphose" (en cristallographie, le terme désigne l'état d'un minéral qui, après un changement de composition chimique, conserve sa forme cristalline primitive au lieu de cristalliser selon sa substance nouvelle): les images des premiers sarcophages chrétiens et des sarcophages païens sont puisées dans le même répertoire. On peut distinguer deux approches.

La première est une reprise sans modification des motifs existants: pour représenter des images allégoriques d'idées abstraites, les artisans ont recours à des scènes qui servent à représenter des idées semblables dans l'art païen. C'est le cas par exemple des motifs bucoliques qui, par leur univers champêtre, peuvent évoquer la paix éternelle (l'âge d'or = paradis). Le pasteur ou le criophore symbolisant la philanthropie dans l'art païen, ou encore l'Orphée en berger, sont investis de l'idée chrétienne du Bon Pasteur, le Christ conducteur d'hommes, qui va chercher la brebis égarée, l'allégorie de l'âme chrétienne. L'orante (ou dans certain cas son pendant masculin) qui symbolisait la piété sera la personnification de la foi chrétienne ou l'évocation d'un chrétien ordinaire. Elle est souvent représentée sous les traits de la défunte pour montrer que celle-ci avait été une bonne chrétienne (le geste de prière debout paumes de main tournées vers le ciel est repris par les chrétiens). Il n'est pas possible d'identifier ces représentations comme étant chrétiennes tant qu'elles figurent seules sur les sarcophages, mais elles acquièrent une connotation chrétienne quand elles se trouvent associées à des scènes bibliques.

La deuxième approche consiste à reprendre des modèles formels existants dans l'art païen ou profane pour présenter une nouvelle narration. Le meilleur exemple est l'histoire de Jonas, un des thèmes bibliques les plus anciens et les plus fréquents, souvent représenté en plusieurs scènes sur les sarcophages. Dans la première scène du cycle, qui est généralement réduite à la représentation du bateau, ce dernier est une transposition du motif funéraire de la barque avec des Amours ailés (ou des enfants) remplacés par des marins. Le poisson des scènes suivantes est représenté en monstre-dragon qui faisait partie du cortège de Neptune dans le décor des sarcophages païens (d'où la présence de Neptune à côté de la barque sur le sarcophage de Santa Maria Antica). Jonas lui-même en repos dans la quatrième scène est représenté d'après le modèle de Dionysos sous la treille ou à l'image du berger Endymion endormi. Dans les cas où seule cette dernière scène est représentée, c'est la coloquinte qui permet d'identifier le personnage comme étant Jonas.

Les premières illustrations des scènes bibliques apparaissent dans la deuxième moitié du . Le choix des scènes vient probablement des prières pour les mourants (et des liturgies funéraires) qui se référaient aux exemples de salut accordé par Dieu dans l'Ancien et le Nouveau Testament. En s'appuyant sur ces exemples, les fidèles souhaitent que leurs demandes d'intervention divine, exprimées dans les prières, soient en quelque sorte prolongées sur les parois de leurs tombes. Cela explique pourquoi les sarcophages richement décorés étaient souvent enterrés, les scènes représentées étaient adressées à Dieu et non à la contemplation des fidèles.

Les thèmes vétérotestamentaires qui prédominent au début sont mêlés aux univers pastoraux. Au , ils cèdent peu à peu la place dominante aux sujets néotestamentaires. Parmi les scènes de l'Ancien Testament qui reviennent le plus souvent figurent celle de Jonas (déjà mentionnée), les trois Hébreux dans la fournaise (), Daniel entre les lions (), Noé (, , ), Moïse et la source miraculeuse (), le sacrifice d'Isaac (), et moins systématiquement l'histoire de Suzanne (), Adam et Ève créés par Dieu () ou dans la scène du péché originel (), la remise de la Loi à Moïse sur le mont Sinaï (). L'iconographie de plusieurs de ces scènes n'est pas figée et peut varier, des personnages sont rajoutés, comme l'ange et le serviteur dans la représentation des Hébreux.

Les scènes les plus fréquentes du Nouveau Testament, qui se multiplient dès le début du sont les miracles du Christ: la multiplication des pains (), le miracle de Cana (), la guérison de l'aveugle (), de l'hémorroïsse (, ) et de l'infirme (), la résurrection de Lazare (). Les scènes de l'Adoration des Mages (), la Nativité () et le Baptême du Christ (), qui rappellent l'importance de l'Incarnation pour la Rédemption, sont porteuses d'un message du salut aussi bien individuel que collectif. Des éléments apocryphes s'insèrent dans le récit, tels le bœuf et l'âne dans la Crèche. Pierre, distingué dans l'assemblée des disciples, trouve rapidement sa place dans le décor, probablement à cause de son importance pour Rome : les scènes les plus courantes étant celles de son arrestation (avec deux soldats en « bonnet pannonien », en usage dans l'armée romaine au ) et l'annonce du reniement ()

Mais dans le courant du , le répertoire s'élargit : les scènes des vies de Pierre et de Paul, le Christ parmi les apôtres, différents moments du cycle de la Passion, l'entrée dans Jérusalem ( ; ; ), le lavement des pieds (), Jésus devant Pilate et le lavement des mains (). Dans la scène de Crucifixion le Christ est représenté couronné de lauriers, avec au pied de la croix deux soldats-gardiens.

Ces différentes scènes et personnages sont répartis sur les parois sans chronologie ou lien direct, c'est l'ordre de l'ensemble qui semble diriger le plus cet agencement. La scène de Daniel entre les lions, à la composition symétrique, se place souvent dans le centre (par exemple sous le médaillon), le sacrifice d'Isaac et la remise de la Loi, dessinant des diagonales, s'insèrent à côté du médaillon. La source miraculeuse et la résurrection de Lazare se trouvent dans les extrémités des cuves, en raison de la verticalité de leur composition. La scène des trois Hébreux dans la fournaise est régulièrement placée sur le bandeau du couvercle à cause de son horizontalité.

L'art chrétien présente à ses débuts davantage d'unité, aussi bien dans l'art des sarcophages que dans celui des catacombes, l'iconographie étant la même dans les grandes lignes. Il n'y a pas non plus de différence importante entre les sarcophages romains et provinciaux des et s. Mais la manière simple et expressive des premiers sarcophages, exécutés dans le style plébéien, s'effacera au devant le courant qu'on a appelé le « classicisme constantinien ». Le bas-relief, se rapprochant de la ronde-bosse, retrouve alors son élégance, et le traitement poli accentue la sérénité des personnages qui vient remplacer le naturel des expressions du .




</doc>
<doc id="2858" url="https://fr.wikipedia.org/wiki?curid=2858" title="Signature numérique">
Signature numérique

La signature numérique (parfois appelée signature électronique) est un mécanisme permettant de garantir l'intégrité d'un document électronique et d'en authentifier l'auteur, par analogie avec la signature manuscrite d'un document papier. 

Elle se différencie de la signature écrite par le fait qu'elle n'est pas visuelle, mais correspond à une suite de caractères.

Un mécanisme de signature numérique doit présenter les propriétés suivantes :

Pour cela, les conditions suivantes doivent être réunies :

En pratique, l'essentiel des procédures de signature numérique existantes s’appuie sur la cryptographie asymétrique, dans le reste de l'article nous nous placerons dans ce cas le plus courant. Les exemples d'échanges de données sont illustrés par les personnages Alice et Bob.

Supposons qu'Alice souhaite envoyer à Bob un message dont il puisse vérifier l'authenticité.

Le message que souhaite envoyer Alice est un fichier binaire M de nature quelconque (texte, image, exécutable…) qui peut être assimilé à un fichier texte.

Voici la description d'une méthode classique de signature par chiffrement asymétrique.

Alice et Bob ont convenu au préalable des choix :

Pour le chiffrement choisi, Alice a généré une clé privée K et une clé publique K : 

C, D, H et K n'ont pas besoin d'être secrets.

Alice prépare le message signé, pour cela :

Alice transmet M, le message signé, à Bob par un canal non sécurisé.

Bob réceptionne le message signé, pour vérifier l'authenticité du message :

Dans le cas où la signature est authentique, D et H(M) sont égaux car, de par les propriétés du chiffrement asymétrique :
D=D(K,S)=D(K,C(K,H(M)))=H(M). Le message est alors authentifié.

Supposons qu'une adversaire appelée Mallory souhaite envoyer un message malveillant M'à Bob en se faisant passer pour Alice.

Mallory connaît les éléments C, D, H et K qui ne sont pas secrets.

Pour que Bob soit trompé et authentifie le message comme provenant d'Alice, Mallory doit être en mesure de générer à partir de ces éléments une signature falsifiée S qui soit telle que : D(K,S)=H(M').

La tâche que Mallory doit effectuer est donc d'inverser la fonction de déchiffrement D pour la clé publique K, sans connaître la clé privée K.

Les chiffrements asymétriques sont précisément conçus et choisis pour que cette opération soit mathématiquement difficile.

Du point de vue théorique la résistance du dispositif de chiffrement va dépendre de la force du chiffrement asymétrique retenu et de la taille des clés choisies. Les normes en œuvre sont généralement considérées comme mathématiquement sûres.

Du point de vue pratique :

Historiquement, les premières signatures ont été individuelles. Ont été introduites par la suite :



Des variantes existent comme les "K parmi N", où la signature est considérée comme valable si K membres du groupe parmi les N définis ont signé. Ce système sera utilisé par exemple lorsque l'autorisation de plusieurs services sera nécessaire pour déclencher un dispositif d'une gravité dépassant les prérogatives de chacun d'eux. Tel serait le cas par exemple pour une procédure de mise sur écoute téléphonique nécessitant les accords à la fois d'une instance autorisée de l'exécutif "et" d'une instance autorisée du législatif. On interdit ainsi l'usage de renseignements d'États à des fins personnelles, puisque le déblocage nécessite une coordination externe qui sera donc elle-même tracée.

La législation européenne définit les conditions d'interopérabilité des signatures numériques au sein de l'Union. Une condition majeure d'interopérabilité est que la signature numérique avancée doit être basée sur un certificat qualifié. Chaque pays membre doit rendre disponible une liste d'autorités de confiance (autorités de certification, autorités de certification des temps) et la Commission européenne publie une liste reprenant ces listes de confiance nationales.

Seule la "signature électronique présumée fiable" (ou "qualifiée") a même valeur légale qu'une signature manuscrite dans l'ensemble de l'Union européenne. Il s'agit d'une signature électronique avancée interopérable créée sur un dispositif sécurisé de création de signature (typiquement une carte à puce).

À partir du , c'est la version électronique du "Journal officiel de l'Union européenne" qui a valeur légale. Cette édition électronique est publiée sous forme d'une collection de documents au format PDF correspondant à toutes les versions linguistiques d'un même numéro, à laquelle s'ajoute un document XML assurant l'intégrité de l'ensemble. Ce document XML, qui contient un hash de chaque document PDF membre de ladite collection, est signé par une personne autorisée de l'Office des publications de l'Union européenne au moyen d'une signature électronique qualifiée horodatée.

À partir du la signature numérique sera officiellement reconnue en Europe puisque le règlement eIDAS (identification électronique et services de confiance) sera mis en application. Cette signature bénéficiera du même statut et des mêmes effets juridiques que son équivalent manuscrit .
Depuis 2000, la signature électronique d'un document a en France la même valeur légale qu'une signature manuscrite, conformément aux textes suivants :

Selon ce décret, un dispositif sécurisé de création de signature électronique doit être certifié conforme aux exigences définies plus haut :


La transposition complète de la directive européenne 1999/93/CE a toutefois nécessité un processus plus long.

Depuis 2010, d'autre part, le concept de signature numérique, définie comme la conservation sous forme numérique d'une signature manuscrite produite via un écran tactile, a été introduite dans le droit français par du code de procédure pénale.

Le référentiel général de sécurité définit les règles que les administrations et collectivités doivent respecter en matière de sécurité des systèmes d'information. En particulier, les annexes du précisent le format des certificats électroniques que les administrations doivent utiliser pour mettre en œuvre la signature électronique au sein des téléservices. Les infrastructures de gestion de certificats conformes au référentiel sont certifiées selon une méthode appelée « qualification ». Ces infrastructures de gestion de certificats sont appelées Autorité de Certification. Tiers de confiance, elles garantissent l'identité électronique de l'entreprise et de ses collaborateurs. ChamberSign France délivre depuis 2000 des certificats de signature électronique conformes RGS et eIDAS.

Le législateur belge a transposé en 2001 la directive européenne du 13 décembre 1999 sur un cadre communautaire pour les signatures électroniques. Cette transposition en droit belge s'est faite par l'adoption de deux lois : la Loi du 20 octobre 2000 introduisant l’utilisation de moyens de télécommunication et de la signature électronique dans la procédure judiciaire et extrajudiciaire qui modifie notamment du Code civil et la Loi du 9 juillet 2001 fixant certaines règles relatives au cadre juridique pour les signatures électroniques et les services de certification. C'est cette dernière loi qui explique la question des services de certification (P.S.C), leurs rôles et responsabilités.

La signature électronique fait désormais partie du droit belge et a la même valeur juridique que la signature manuscrite. Bien qu’elle ait fait couler beaucoup d’encre du côté de la doctrine, on peut considérer qu’elle fait aujourd'hui l’objet d’une réglementation claire et rationnelle. L’ère de l’Internet et de l’électronique étant arrivée au sein du domaine juridique et il était logique que la signature y trouvât sa place. L’objectif premier de la directive européenne 1999/93/CE du 13 décembre 1999 sur un cadre communautaire pour les signatures électroniques était de favoriser les échanges commerciaux au-delà des frontières, d’instaurer une certaine confiance dans ces transactions et de conférer à l’ensemble une valeur juridique équivalente à celle de la signature manuscrite.

La signature numérique (appelée signature "électronique" dans les textes législatifs) est reconnue en droit suisse depuis 2003. Elle équivaut, de ce fait, à la signature écrite qu'exige la loi pour certaines formes de contrat.

Peu utilisé en pratique, le secrétariat d'État à l'économie (SECO) lance en mai 2010 la « SuisseID » pour promouvoir et faciliter l'accès à cette technologie pour les entreprises et les particuliers. Censé faciliter les transactions d'affaire par voie électronique, le système permet aussi, depuis 2011, la commande par internet de documents officiels (notamment du casier judiciaire ou d'un extrait de l’office des poursuites) auprès des administrations publiques, conformément à la volonté de mise en place d'une « cyberadministration » pour faciliter l'accès à de tels documents et réduire la bureaucratie.

La loi concernant le cadre juridique des technologies de l'information dispose que .




</doc>
<doc id="2861" url="https://fr.wikipedia.org/wiki?curid=2861" title="Système de positionnement par satellites">
Système de positionnement par satellites

Un système de positionnement par satellites également désigné sous le sigle anglais GNSS (pour "Global Navigation Satellite System") est un ensemble de composants reposant sur une constellation de satellites artificiels permettant de fournir à un utilisateur par l’intermédiaire d'un récepteur portable de petite taille sa position 3D, sa vitesse et l'heure. Cette catégorie de système de géopositionnement se caractérise par une précision décamétrique, sa couverture mondiale et la compacité des terminaux. Certains systèmes d'augmentation et de fiabilisation de portée régionale ou mondiales, gratuits ou payant, permettant de fiabiliser et d'améliorer encore la précision disponible (DGPS, EGNOS).

Le premier système de positionnement par satellites est développé par les États-Unis avec TRANSIT à usage uniquement militaire en 1964 puis avec le Global Positioning System (GPS) devenu opérationnel en 1995 qui fixe les principes de fonctionnement repris par les systèmes de navigation par satellites développés par d'autres pays. Le système GPS repose sur une constellation d'une trentaine de satellites qui permet à un utilisateur, situé sur n'importe quel point du globe, d'avoir toujours au minimum quatre satellites à portée. Le terminal de l'utilisateur calcule sa position grâce au signal émis par chacun des satellites. 

L'URSS à la suite des États-Unis développe GLONASS entré en fonction en 1996 et qui, après une période d'éclipse liée à l'éclatement de l'Union soviétique, est redevenu opérationnel en 2010. L’Union européenne avec le système Galileo et la Chine avec le système Beidou-2 (COMPASS) développent leur propre système qui devrait être complètement opérationnel en 2020. Le Japon (QZSS) et l’Inde avec l'IRNSS développent de leur côté un système assurant une couverture uniquement régionale dont la Chine dispose également avec Beidou-1.

L'utilisation de terminaux s'est généralisée pour répondre aux besoins des professionnels et grands publics (militaire, navigation, topographie et synchronisation du temps). Les terminaux permettent souvent d'exploiter les signaux de plusieurs systèmes notamment GLONASS et GPS. Ces systèmes passifs peuvent être complétés par des émetteurs de radiolocalisation pour des applications de suivi logistique (APRS), de sauvetage (SAR), de surveillance de trafic maritime (AIS), d’étude océanographique, de biologie (radiotracking).

Un système de positionnement par satellites fournit sur un récepteur les coordonnées géographiques (longitude, latitude), la vitesse de déplacement et l'heure à son utilisateur. Cette information est obtenue en mesurant la distance à un instant donné entre le récepteur de l'utilisateur et un satellite artificiel dont la position dans l'espace est connue avec précision. En combinant la mesure simultanée de la distance d'au moins quatre satellites, le récepteur est capable par trilatération de fournir la position et l'altitude avec une précision de l'ordre d'une dizaine de mètres et la vitesse avec une précision de quelques cm/s. Le récepteur peut être au sol ou embarqué ou positionné dans un véhicule en déplacement : automobile, navire, avion.

Pour mesurer la distance entre le récepteur et le satellite, la trajectoire précise de ce dernier doit être connue. Celle-ci est reconstituée à partir de deux types de message envoyé par le satellite au récepteur :

Connaissant la trajectoire que suit le satellite, le récepteur, pour calculer la position, doit théoriquement utiliser la même heure que le satellite. En effet, compte tenu de la vitesse à laquelle circule le signal (), une désynchronisation de 10 millisecondes entre l'horloge du satellite et celle du récepteur engendre une erreur de calcul de la position de . La précision et la stabilité de l'heure du satellite est garantie par l'emport de plusieurs horloges atomiques qui fournissent une heure qui ne dérive que de quelques nanosecondes par jour. Le récepteur, par contre, ne peut être équipé d'une horloge aussi précise pour des raisons de coût et d'encombrement. L'heure est fournie par un oscillateur à quartz dont la dérive journalière moyenne est de 10 millisecondes.

Pour déterminer sa position, sa vitesse et l'heure, le récepteur calcule la distance à laquelle se trouve le satellite à partir des données de l'éphéméride et en se basant sur son horloge interne. Mais ce calcul est entaché d'erreur (on parle de pseudo-distance) du fait de la désynchronisation des horloges mais également parce que différents phénomènes viennent perturber la propagation du signal :

La méthode de trilatération permet théoriquement de calculer position, vitesse et temps en utilisant le signal de trois satellites : la distance à laquelle se situe un satellite positionne l'utilisateur à la surface d'une sphère dont le centre est le satellite. L'intersection de 3 sphères permet d'identifier un point unique dans l'espace. Un quatrième satellite est néanmoins requis pour permettre de déterminer le décalage des horloges et réduire les incertitudes liées aux autres sources de perturbation du signal.

Pour assurer des performances de précision et de sécurité garanties, des signaux supplémentaires sont émis par des satellites ou des balises de correction, appelés systèmes d'augmentation.

Le récepteur est souvent couplé à un calculateur qui détermine le cap à suivre pour rejoindre un point de coordonnées connues ou qui affiche une carte numérique sur un écran. Le récepteur peut également être interfacé à un ordinateur portable muni d'un logiciel cartographique, ou à une centrale de navigation intégrant également tous les autres senseurs de bord (compas, tachymètre, autres systèmes de radionavigation…).

Le récepteur peut aussi être couplé à un téléphone cellulaire ou satellitaire qui retransmet automatiquement la position du mobile à un central. Ce central peut alors contrôler, gérer ou surveiller le déplacement des mobiles.

Les systèmes satellitaires ont été précédés par les systèmes terrestres de radionavigation, comme le DECCA, le LORAN et l’Oméga, qui utilisaient des émetteurs terrestres et non des satellites. Certains de ces systèmes sont encore opérationnels, particulièrement en aéronautique, en raison de leur fiabilité et de leur précision locale, comme le VOR ("VHF Omnidirectional Range"), le DME, le TACAN, l’ILS ou l’ADF. Tous ces systèmes reposent sur un réseau de stations terrestres qui émettent un signal radio. En analysant le signal de plusieurs stations émettrices, le système de radionavigation détermine la position. Ces systèmes présentent les inconvénients suivants :

Le début de l'ère spatiale modifie la donne. Les États-Unis développent le premier système de positionnement par satellites TRANSIT qui devient opérationnel en 1964. Celui-ci utilise l’effet doppler et permet de localiser l'utilisateur avec une précision comprise entre 200 et . Mais le nombre de satellites limité à six ne permet pas une couverture de l'ensemble du globe et il s'écoule parfois avant de pouvoir obtenir une position précise. Le signal à du Transit contenait les éphémérides (la position orbitale précise) du satellite, indispensable pour le calcul du point. Ces éphémérides étaient déterminées par le US Naval Observatory (USNO) qui mettait à jour ces données à bord des satellites.

Au début des années 1970 les États-Unis décident de concevoir un système plus précis pour répondre à leurs besoins militaires. Les concepts du système GPS sont définis entre 1973 et 1978. Une première phase pré-opérationnelle est atteinte après les lancements de onze satellites dits du bloc I d'une durée de vie de qui s'échelonnent entre 1978 et 1985. En 1983 le gouvernement américain décide que le système GPS sera ouvert aux civils dès qu'il deviendra opérationnel. Entre 1989 et 1997 28 autres satellites aux durées de vie allongée en version II () et IIr () sont lancés. Le système est déclaré opérationnel en février 1994. Le signal est alors volontairement dégradé pour l'usage civil (précision de l'ordre de au lieu de ) mais en 2000 le gouvernement américain décide de mettre fin à cette dégradation. Cela permit la navigation routière.

Les systèmes actuels sont plus directs pour l’utilisateur : le satellite transmet un signal contenant sa position et l’instant exact d’émission. Ce message est superposé au code qui contient la référence temporelle. La synchronisation des signaux est obtenue par des horloges atomiques à bord de chaque satellite.

Le récepteur compare l’instant d’arrivée vis-à-vis de son horloge propre, avec l’instant d’émission indiqué et mesure ainsi la distance du satellite. Ces mesures sont répétées sur tous les satellites visibles et permettent de calculer une position en continu.

Chaque mesure de distance, quel que soit le système utilisé (constellation basse ou géostationnaire ou balise locale) place le récepteur sur une sphère centrée sur l’émetteur. En utilisant au moins trois émetteurs, ces sphères ont un seul point d’intersection. Ce principe simple se complique cependant :
Le récepteur intègre donc ces diverses erreurs, utilisant des corrections et des mesures de divers satellites ou balises, puis des techniques d’intégration et de filtrage comme les filtres de Kalman, pour obtenir le point le plus probable et sa précision estimée, sa vitesse ainsi que le temps universel.

Pour les applications demandant une sécurité absolue du point (atterrissage sans visibilité, anticollision...) les signaux de navigation sont complétés par un signal dit d’«intégrité» qui permet d’éliminer toute mesure issue d’un émetteur en défaut temporaire ou prolongé.

Les systèmes de navigation satellitaires ont été développés d’abord pour le besoin militaire. Ils permettent en effet une précision inégalée dans le guidage des missiles au but, augmentant leur efficacité et réduisant les risques de dégâts collatéraux. Ces systèmes permettent également aux forces terrestres de se positionner avec précision, réduisant les incertitudes tactiques, aux marines et aux forces aériennes de naviguer avec précision, indépendamment de tout support au sol.
Ainsi, les satellites de navigation agissent en multiplicateur de puissance militaire, et dans les conflits très médiatisés, réduisent les retentissements des pertes civiles. Toute nation ayant des ambitions militaires souhaite donc se doter de ces systèmes.

La possibilité de distribuer des signaux de radionavigation inclut également la possibilité de les interdire d’emploi sur certaines zones sans une clé de décryptage. Le signal civil du GPS était muni jusqu’en 1990 d’un code d’étalement aléatoire de précision, pour éviter son emploi militaire (« selective availability »), qui réduisait la précision à au lieu des actuels.

Les systèmes sont caractérisés par leurs performances pour les applications souhaitées, principalement :

La précision de la localisation dépend du nombre de satellites reçus et du temps d’intégration, ainsi que de la géométrie des mesures. Les récepteurs les plus simples permettent de localiser en quelques secondes un mobile avec une précision meilleure que . Les récepteurs sophistiqués tels que ceux embarqués sur les avions civils et militaires permettent une précision inférieure au décamètre, voire au mètre. Un récepteur fixe au sol permet, après une intégration sur une période de plusieurs minutes, de connaître la position d’un point avec une précision centimétrique.

La position est calculée par rapport au système géodésique World Geodetic System en 1984 WGS 84), mais les références cartographiques sont souvent basées sur des systèmes géodésiques plus anciens (WGS 72 ou antérieurs). L'écart entre ces systèmes cartographiques locaux et le système de référence (jusqu'à dans certaines iles océaniques) peut entraîner une erreur de positionnement supérieure à l'imprécision du système. Ces corrections doivent donc être introduites.

L'intégrité est le terme officiel de l'Organisation de l'aviation civile internationale (OACI) pour désigner la fiabilité du point fourni: une position utilisée en navigation au large, par exemple, peut être occasionnellement erronée (faible intégrité) sans conséquences graves, si le mobile possède des instruments autonomes, alors qu'une position utilisée pour un atterrissage sans visibilité doit au contraire avoir une intégrité absolue.

Un système de positionnement par satellites peut avoir une couverture globale ou régionale, il peut être indisponible pendant des périodes plus ou moins longues, avoir des manques de satellites (par exemple GLONASS). Le but des systèmes combinés comme les GNSS-1 et GNSS-2 est de pallier les défauts de chaque système individuel grâce à des combinaisons et compléments dits d'« augmentation ».

Les systèmes de positionnement satellitaires avec une couverture globale sont :


Les systèmes de positionnement avec une couverture régionale :

Le système GPS, se développe, à partir de 1978 (année de mise en service du premier satellite) et devient disponible librement en 1994 (avec un accès qui n'est alors plus réservé à l'armée américaine) et pleinement opérationnel en 1995 (avec une constellation de 24 satellites). Il est alors, pendant un an, le seul système de positionnement par satellite, pleinement efficace et fonctionnel.

Un an plus tard (1996), le système GLONASS russe devient, lui aussi, pleinement opérationnel. Cependant, entre 1999 et 2010 (à cause de l’obsolescence de GLONASS), le système GPS était redevenu le seul système mondial de navigation satellitaire entièrement opérationnel. En 2015, Il est constitué de 31 satellites (24 à l'origine) en orbite intermédiaire (MEO) en six plans orbitaux. Le nombre exact de satellites varie en fonction des remplacements de satellites en fin de vie.

Le système GLONASS de l’ex union soviétique, aujourd’hui Russie (en russe "Global'naya Navigatsionnaya Sputnikovaya Sistema"), était également une constellation fonctionnelle apparue en 1995 et rendue opérationnelle dès 1996, mais avec l’écroulement de l’union soviétique, il n’était plus entretenu, provoquant des pannes matérielles dès 1997 (deux ans après son lancement), s'aggravant entre 1997 et 2000 et générant des trous de couvertures, rendant obsolète et non-fonctionnel, ce système de positionnement. Entre 2000 et 2010, la disponibilité était donc devenue partielle. En 2005, cependant, la fédération russe s’est engagée à le restaurer avant 2010, avec une collaboration indienne dans ce projet. Entre 2008 et 2010, de nouveaux satellites sont lancés, le rendant de nouveau, progressivement fonctionnel. Depuis 2010, il est enfin redevenu opérationnel et depuis 2011, sa précision s'améliore, le rendement pleinement efficace. Entre octobre et décembre 2011, pour la première fois, la constellation GLONASS couvre 100 % de la surface de la planète. L'iPhone 4S et le Samsung Wave III deviennent en 2011, les premiers smartphones grand public (en dehors du marché russe) à recevoir nativement les signaux GLONASS et à les utiliser pour évaluer le positionnement.

L’Union européenne a signé avec l’agence spatiale européenne en mars 2002 l’accord sur le développement du système global Galileo. Le coût est estimé à environ d’euros. La constellation finale sera constituée de 24 satellites qui devraient être opérationnels en 2017, ainsi que de 6 satellites de secours. Le premier satellite expérimental a été lancé le 28 décembre 2005. Un second satellite de validation a été lancé en 2008. Le 11 septembre 2015, dix satellites étaient d'ores et déjà en orbite, et on en comptait huit de plus fin 2016. Les premiers services sont opérationnels à partir du 15 décembre 2016.

Les signaux de navigation de Galileo sont compatibles avec ceux du GPS, permettant aux récepteurs de les combiner pour augmenter la précision ainsi que la véracité du point.

La Chine a commencé à transformer son système régional Beidou en système global. Ce programme est appelé « "Compass" » par l’agence d’informations chinoises officielle Xinhua News Agency.

Le système Compass doit comporter trente satellites en orbite MEO et cinq géostationnaires. Cette annonce est accompagnée d’une invitation à d’autres pays désirant y collaborer, alors que la Chine est également engagée dans le programme Galileo.

Le système IRNSS "(Indian Regional Navigational Satellite System)" est un projet de système autonome de navigation régionale construit et contrôlé par le gouvernement indien. Il doit permettre une précision absolue de sur l’Inde et s'étendrait jusqu’à autour de son voisinage. Le but est d'avoir un système entièrement sous contrôle indien, le segment spatial, terrestre et les récepteurs étant développés par l’Inde.

Le projet a été approuvé par le gouvernement indien en mai 2006, avec un objectif de développement en six à sept ans.

Le système QZSS "(Quasi-Zenith Satellite System)", est développé par le Japon pour un premier lancement en 2008. Il est constitué de trois satellites géostationnaires permettant le transfert de temps et une augmentation du GPS. Il couvrira le Japon et sa région

Le système français Doppler Orbitography and Radiopositioning Integrated by Satellite (DORIS) peut être considéré comme l’inverse des GNSS : à partir de balises au sol, il permet de déterminer avec précision la position d’un satellite. Il est utilisé par exemple sur les satellites d’observation

Les systèmes Argos et Cospas-Sarsat ne sont pas à proprement parler des systèmes de navigation, mais de positionnement à distance : le mobile ne contient qu'un émetteur, et la position est connue par le centre de calcul du système. Quoique de précision médiocre (1 à ), ils sont utilisés pour la sécurité aérienne et maritime ou le radiotracking d'animaux, grâce à la simplicité des balises embarquées. Ils fonctionnent, comme le TRANSIT, par mesure d'effet Doppler.

Les systèmes satellitaires existants (GPS et GLONASS) peuvent être complétés par des systèmes dits d'« augmentation » ou d'« "overlay" » qui délivrent en temps réel des corrections permettant d'accroître la précision ainsi que des informations garantissant l'intégrité de ces corrections. Le principe de ces systèmes est qu'une ou plusieurs stations au sol mesurent en permanence l'erreur et transmettent un signal de correction aux utilisateurs.

Il existe de nombreux systèmes différents selon les corrections fournies au récepteur. Certains systèmes transmettent des informations sur les sources d’erreur (écarts d’horloge, éphémérides, retards ionosphériques), d’autres fournissent l’écart constaté total (différentiel), d’autres ajoutent des informations issus du véhicule lui-même (vitesse, altitude..).

On classe généralement ces systèmes d'augmentation en trois catégories, selon la manière dont la correction est calculée et transmise :

Ces systèmes permettent d'obtenir une précision allant jusqu'au centimètre. Pour la navigation aérienne, l'OACI demande que l'intégrité des systèmes de navigation par satellite soit surveillée, et qu'une alerte soit émise à bord en cas de perte de l'intégrité nécessaire (qui dépend de la phase du vol).

Les systèmes de positionnement par satellites capables de fournir une précision et une intégrité compatible avec les exigences de la navigation aéronautique civile sont définis ainsi par l'OACI:

Le GNSS-1 est la première génération de système de positionnement par satellites, combinant l’utilisation des systèmes GPS et GLONASS, avec des systèmes d’augmentation satellitaires (SBAS) ou terrestres (GBAS).
Aux États-Unis, le complément satellitaire est le WAAS, en Europe, c’est EGNOS, et au Japon, le MSAS.
Les systèmes complémentaires terrestres (GBAS) sont généralement locaux, comme le "Local Area Augmentation System" (LAAS).
Les performances du GNSS1 sont compatibles avec la navigation « en route » (suivi des couloirs aériens et des espacements) et éventuellement d’approche si un système LAAS est disponible.

Le GNSS-2 est la seconde génération de systèmes, capable de fournir tous les services civils, dont l’exemple le plus avancé est le Galileo européen. Ces systèmes procureront simultanément la précision et l’intégrité nécessaire à la navigation civile dans toutes les phases de vol.
Le système GPS en développement doit inclure également la porteuse L5 d’intégrité, le mettant ainsi au niveau GNSS2.

Les usages civils des systèmes de positionnement par satellites sont multiples :

En 2014 le nombre de terminaux GPS opérationnels est estimé à . Il s'agit en majorité de téléphones mobiles équipés de composants électroniques permettant de traiter le signal des satellites de navigation. Selon les projections effectuées début 2015 ce nombre devrait passer à sept milliards en 2019 et neuf milliards en 2023. Le taux d'équipement en 2014 était de 1,4 terminal par personne en Amérique du Nord (2,5 en 2023), 1,1 en Europe (2,1 en 2023), 0,8 en Russie (2,3 en 2023), 0,5 en Amérique du Sud (1,1 en 2023), 0,4 en Asie (1 en 2023) et 0,2 en Afrique (0,8 en 2023). Une majorité de terminaux a désormais la capacité d'exploiter le signal des satellites de plusieurs systèmes de positionnement : 23 % peuvent utiliser les signaux GPS et GLONASS, 8 % les signaux GPS, GALILEO et GLONASS et 21 % les signaux des quatre systèmes de positionnement ayant une couverture mondiale (GPS, GALILEO, BEIDOU et GLONASS).
Les systèmes de positionnement par satellites ont plusieurs répercussions économiques :

Pour arriver à ce but, les États cherchent une indépendance vis-à-vis du GPS des États-Unis, afin de développer des applications civiles ou militaires nationales. Le développement d'un système de navigation satellitaire est également un élément de prestige pour les nouvelles nations spatiales (Chine et Inde). Dans cette même optique, la commission européenne a apporté son soutien à la création du Master GNSS par l'École nationale de l'aviation civile et l'Institut supérieur de l'aéronautique et de l'espace.

La pratique croissante de la géolocalisation d'individus ou de véhicules, d'objets connectés (smartphones et tablettes notamment) ou d'opérations effectuées par des individus (sur un ordinateur en consultant internet ou sur de nombreux terminaux fixe ou mobile de paiement par carte, de distribution d'argent liquide, bornes de contrôle de passage, etc.) est source de stockage d'une grande quantité données personnelles relatives à la position et aux déplacement des personnes, qui s'ils sont mal sécurisés peuvent poser des problèmes de protection de la vie privée. 

La production de tels fichiers ou le suivi de véhicules ou de personnes par géolocalisation GSM/GPS sont des « traitements de données à caractère personnel », qui nécessitent en France une autorisation ou une déclaration à la CNIL (. La non déclaration de traitement de ce type de données par l'employeur est une faute grave Il existe une différence dans le cas du suivi de véhicule entre un véhicule de société (qui n'est utilisé théoriquement que durant les heures de travail) ou de fonction (qui est un avantage en nature).





</doc>
<doc id="2863" url="https://fr.wikipedia.org/wiki?curid=2863" title="Sommet mondial sur le développement durable">
Sommet mondial sur le développement durable

Le Sommet mondial sur le développement durable, aussi appelé sommet de la Terre de Johannesburg ou sommet de Johannesburg, s'est tenu du 26 août au , à Johannesburg en Afrique du Sud. Sommet mondial du développement durable organisé par les Nations unies, il a réuni plus de cent chefs d'État et environ 60 000 personnes, parmi lesquelles des délégués, des représentants d'ONG, des journalistes et des entreprises.

Cette quatrième édition visait à faire le bilan du précédent Sommet de la Terre, tenu à Rio de Janeiro en 1992. Centré sur le développement durable, sa finalité résidait dans l'adoption d'un plan d'action en 153 articles décomposés en 615 alinéas sur de nombreux sujets : pauvreté et paupérisation, consommation, les ressources naturelles et leur gestion, globalisation, respect des Droits de l'homme, etc.

Certains thèmes particulièrement préoccupants ont été au cœur des débats de ce sommet.

Alors que la consommation mondiale ne cesse de croître, notamment avec l'émergence de Nouveaux Pays Industrialisés (N.P.I.) comme l'Inde et la Chine, les ressources en eau deviennent des facteurs sociaux, économiques et politiques majeurs et critiques, sources de conflits potentiels.

Ainsi le Sommet de la Terre 2002 fut le lieu de débats et d'orientations sur la gestion de ces ressources, la nécessité d'une consommation rationnelle, et l'accès des populations démunies à l'eau potable. Un des objectifs fut de réduire d'ici 2015 la population ne disposant pas d'assainissement adéquat des eaux usées.

L'énergie fut un autre dossier sensible étudié lors de cette édition. Les pays du Nord, notamment les États-Unis d'Amérique, sont régulièrement montrés du doigt pour leur surconsommation d'énergie, et les NPI peinent à satisfaire leur demande. Les réserves d'énergies fossiles sont menacées d'épuisement dans les prochaines décennies, et les cours du pétrole le rendent prohibitif pour les pays du Sud.

Malgré ce contexte de tensions économiques internationales, les énergies renouvelables et leurs utilisations restent confidentielles et hors de prix pour bon nombre de pays émergents.

La productivité agricole par l'agriculture intensive suscite quelques remous dans la communauté scientifique et chez les consommateurs. En sus de la régression et de la dégradation des sols, cette méthode de production provoque, par l'usage d'engrais et de pesticides, une pollution des produits finaux et des nappes phréatiques. D'autres systèmes de production agricole ont connu un engouement, telle l'agriculture biologique, mais reste hors de portée des pays du Sud qui peinent parfois à s'auto-suffire.

Sous l'effet de la pression démographique, et des activités humaines, de nombreuses réserves écologiques voient leur surface grignotée ou leur existence menacée par les nécessités économiques des pays. Ainsi de nombreuses espèces végétales, animales, microbiennes et de champignons disparaissent sous l'effet de la déforestation ou de la destruction ou fragmentation de leur milieu.

Les États se sont engagés lors de ce sommet à assurer avant 2010 une forte réduction du rythme de perte de biodiversité aux niveaux mondial, régional et national, dont pour contribuer à l’atténuation de la pauvreté, et au profit de toutes les formes de vie sur la planète (« objectif de biodiversité de 2010 »). L'ONU note que cela nécessitera des mesures multi-niveaux, et la mise en œuvre des stratégies et des plans d’action nationaux pour la préservation de la biodiversité, ainsi qu'une allocation de ressources financières et techniques supplémentaires aux pays en développement.

Durant ce même sommet, les États de l'Union européenne ont préparé un objectif plus ambitieux : stopper la perte de biodiversité avant 2010 en Europe, et ils se sont mis d'accord, sur l'objectif de reconstitution des ressources halieutiques d'ici 2015, dans un objectif de développement durable.

Suites :

Alors que les laboratoires recherchent de nouveaux principes actifs parmi les espèces des pays du Sud, nombre de ceux-ci n'ont toujours pas accès aux pharmacopées des pays développés, privant de soins des populations entières souvent confrontées aux fléaux du Sida et du paludisme.

Le Sommet de la Terre présente un enjeu symbolique important. Il se veut la preuve du développement d'une culture mondiale de respect de l'écologie mais est marqué, d'un point de vue français, par le cri pessimiste lancé par Jacques Chirac devant l'assemblée plénière : « "Notre maison brûle et nous regardons ailleurs" ».

C'est aussi à cette occasion que le Président Chirac proposera de voir dans la culture « le quatrième pilier du développement durable aux côtés de l’économie, de l’environnement et de la préoccupation sociale ».

Il vise à démontrer la capacité collective à gérer les problèmes planétaires et à s'opposer à une version unilatérale de la puissance principale, celle des États-Unis. Il affirme la nécessité d'une croissance devant se faire dans le respect de l'environnement, avec le souci de la santé, de l'instruction et de la justice. Des dirigeants politiques importants de la nouvelle démocratie sud-africaine y participent, comme Cheryl Carolus.

L'enjeu politique du Sommet est également important puisqu'il s'agit de démontrer que la guerre contre le terrorisme n'est pas l'unique problème mondial actuel.

Le gouvernement des États-Unis n'avait pas souhaité participer au Sommet. L'Union européenne indiqua à l'ouverture du Sommet de la Terre qu'elle ne renégocierait pas les accords récemment conclus à Monterrey et à Doha (Qatar). Ces accords portaient sur les montants d'aides publiques au développement (APD) et sur la libération du commerce international. Elle estima que le Sommet de la Terre n'était pas le lieu de négociations pour le démantèlement progressif des subventions des pays développés.

Deux dossiers-clés bloquèrent l'adoption d'un Plan d'action :

Certains points ont été difficiles à négocier. Ainsi, les États-Unis s'opposèrent à la mention du principe de précaution dans le texte, ainsi qu'à l'évocation, même indirecte, du Protocole sur la biosécurité, qui concerne les organismes génétiquement modifiés (OGM). Ils refusèrent également l'adoption d'objectifs chiffrés sur l'énergie ou la dépollution de l'eau.

Les pays du Nord entendirent impliquer les entreprises privées en mettant en place des partenariats entre gouvernements et entreprises privées. L'ONU avait d'ailleurs rendu publique une liste de partenariats, passés avec des entreprises ayant reçu son aval comme respectueuses de l'environnement. Les partenariats sont connus sous le nom de "Type II agreements".

Certains, notamment des représentants d'ONG, protestèrent alors contre l'attitude des États-Unis et de l'Union européenne, qui défendaient, selon eux, les intérêts des multinationales. Beaucoup virent cette solution, promue par Washington, comme une manière pour l'État de renoncer à ses responsabilités.

Le coût du Sommet de Johannesburg atteint le montant de 80 millions d'euros, réparti entre l'Organisation des Nations unies (47 millions d'euros) et l'Afrique du Sud (33 millions d'euros).

Catherine Kamping, a d'ailleurs fait remarquer lors des déclarations de clôture que tandis "qu'un tiers de la planète gagne moins d'un dollar par jour, ils ont passé dix jours dans ce paradis de richesse pour aboutir à des résultats décevants." 




</doc>
<doc id="2864" url="https://fr.wikipedia.org/wiki?curid=2864" title="Standard Generalized Markup Language">
Standard Generalized Markup Language

En 1969, , qui est alors chef de projet chez IBM, fait lancer par cette compagnie un langage descriptif, ou "Generalized Markup Language" (Charles Goldfarb, Edward Mosher et Raymond Lorie), destiné à encapsuler l'ancien langage "Script" trop lié physiquement aux possibilités techniques des imprimantes. L'ensemble est commercialisé sous le nom de DCF ("Document Composition Facility"). Un fichier spécial nommé le "profile", ainsi qu'une bibliothèque de macros, indiquent comment seront interprétées les marques.

Goldfarb, que ce langage rend vite célèbre, quitte alors cette compagnie pour développer un successeur de GML appelé SGML (""), publié en 1986 comme norme ISO (ISO 8879:1986).

Les Communautés européennes s'associent à ce développement novateur dès 1984 et adoptent alors le SGML comme standard pour leurs très nombreuses publications officielles, dans le cadre du projet FORMEX (Formalized Exchange of Electronic Publications). Elles développent aussi Mark-It, le premier parser SGML qui ne souffre pas de restrictions par rapport aux spécifications les plus avancées du SGML.

L'un des principes fondamentaux sur lequel repose le SGML est la séparation complète entre la structure logique d'un document (titres, chapitres, paragraphes, illustrations…), qui est identifiée par des balises insérées dans le document lui-même, et sa mise en page, qui dépend du support de présentation (livre, journal, écran, graphique même) et qui est définie en dehors du document dans une ou plusieurs feuilles de style (police, style, taille et couleur des caractères, alignement et espacement des paragraphes…).

SGML rationalise les systèmes documentaires d'IBM ; plus de 90 % de la documentation est écrite en GML. Il a beaucoup facilité en France le travail des avionneurs, Airbus reprenant ainsi la documentation de la SNECMA aussitôt affichable sous ses propres normes, et récupérée à leur tour par ses propres clients qui les affichaient à "leurs" normes ; ou par des arsenaux livrant facilement à leurs clients (armée de l'air, marine et armée de terre, et parfois armées étrangères) des documentations à ces normes personnalisées sans aucun surcoût.

Ce langage devient notamment un standard de représentation au CERN, qui a besoin d'unifier de façon rigoureuse la présentation des documents de ses équipes mais sans pour autant les déconcentrer en leur imposant des détails techniques de typographie. L'INRIA réalisera un des premiers éditeurs SGML, appelé Grif, avec une interface voisine de celle de Word.

HTML, créé par Tim Berners-Lee pour le World Wide Web, est une application de SGML.

Depuis la mise en place de la norme ISO 8879 1986 SGML, lorsqu'on analyse un document, il apparaît comme étant composé de trois parties :
La DTD ("Définition de Type de Document" en français) définit la structure du document :

Chaque DTD définit une classe de documents à laquelle sont rattachées toutes les instances similaires.

Une feuille de style décrit comment sera publié le document. Cela permet, par exemple, de décrire une feuille de style pour le papier (format A4) et une feuille de style pour les écrans (format 4/3) ; l'avantage étant de pouvoir, par exemple, créer une feuille de style pour les écrans (format 16/9) sans réécrire ni la structure ni les instances et bénéficier d'un niveau de réutilisation maximal. Les nouveaux supports matériels ne nécessitent plus que la création de la feuille de style correspondante.

Une instance est un document ou une partie de document balisée selon une DTD. Toutes les instances d'une même DTD appartiennent à la même classe de document.



On notera et cela distinguera les avantages et inconvénients de chaque classe de document :

Dans le HTML et le GML il manque la dissociation complète entre les 3 parties : le contenu (instance), la présentation (feuille de style), et la structure (DTD).

Pour illustrer les différences, trois exemples :





</doc>
<doc id="2865" url="https://fr.wikipedia.org/wiki?curid=2865" title="Sphinx">
Sphinx

Sphinx ou Sphynx (du grec ancien ) est un nom d'origine grecque qui peut avoir plusieurs sens.
















</doc>
<doc id="2868" url="https://fr.wikipedia.org/wiki?curid=2868" title="Substance active d'un produit phytopharmaceutique">
Substance active d'un produit phytopharmaceutique

Les substances actives d'un produit phytopharmaceutique sont définies par la directive 91/414/CEE du 15 juillet 1991, comme suit :

"les substances ou micro-organismes, y compris les virus exerçant une action générale ou spécifique :"



Les substances sont définies comme "les éléments chimiques et leurs composés tels qu'ils se présentent à l'état naturel ou tels que produits par l'industrie, incluant toute impureté résultant inévitablement du procédé de fabrication".

Les végétaux sont "les plantes vivantes et les parties vivantes de plantes, y compris les fruits frais et les semences".



</doc>
<doc id="2869" url="https://fr.wikipedia.org/wiki?curid=2869" title="Syntaxe">
Syntaxe

La syntaxe est, à l'origine, la branche de la linguistique qui étudie la façon dont les mots se combinent pour former des phrases ou des énoncés dans une langue.

On distingue la syntaxe, qui concerne les expressions [les mots], de la sémantique, qui concerne ce qui est visé par les expressions [le sens, la signification/les choses].

Le terme de syntaxe est aussi utilisé en informatique, où sa définition est similaire, "modulo" une terminologie différente. Ainsi, la syntaxe est le respect, ou le non-respect, de la grammaire formelle d'un langage, c'est-à-dire des règles d'agencement des "lexèmes" (en informatique, ce sont des entités lexicales d'un langage informatique) en des "termes" plus complexes, souvent des programmes. Dans la théorie des langages formels, ce qui joue le rôle de lexème est en général appelé "lettre" ou "symbole", et les termes produits sont appelés "mots".

D'un point de vue purement linguistique, la syntaxe étudie :

Les œuvres sur la grammaire ont été écrites longtemps avant que la syntaxe moderne soit arrivée ; en [[Inde ancienne]], l’"Aṣṭādhyāyī" de [[Panini]] (vers le 4ème siècle avant J.C.) est souvent cité comme une exemple d’une œuvre prémoderne qui frise la sophistication d’une théorie syntactique moderne. À l’Ouest, le courant de pensée qui est connu comme « la grammaire traditionnelle » a commencé avec les œuvres de [[Denys le Grammairien]].

Pendant des siècles, le travail en syntaxe était dominé par un cadre connu comme la "grammaire générale", ce qui a été exposé d’abord en 1660 par [[Antoine Arnauld]] dans un livre du même nom. Ce système fonctionnait sous la supposition que la langue est un reflet direct des processus mentaux et ainsi il existe une seule manière la plus naturelle d’exprimer une pensée.

Cependant, au 19ème siècle, avec le développement de la [[linguistique historique]], les linguistes ont commencé à réaliser la diversité des langues humaines et questionner les suppositions fondamentales en ce qui concerne la relation entre le langage et la logique. Il est devenu évident qu’il n’existe pas une façon plus naturelle d’exprimer une idée, et ainsi la [[logique]] ne pouvait plus être invoquée comme base pour étudier la structure du langage.

La [[grammaire de Port-Royal]] a calqué l’étude de la syntaxe sur celle de la logique. (D’ailleurs, des grandes parties de la [[Logique de Port-Royal]] étaient copiées ou adaptées de la "Grammaire générale.") Les catégories syntactiques étaient identifiées avec celles de la logique, et chaque phrase était analysée en termes de « Sujet – Copule – Prédicat. » Initialement, cette opinion a été adoptée par les premiers linguistes comparatifs comme [[Franz Bopp]]. Le rôle central de la syntaxe dans le cadre de la [[linguistique théorique]] est devenu évident seulement au 20ème siècle.

Une caractéristique fondamentale de la syntaxe d’une langue est la séquence dans laquelle le [[Sujet (grammaire)|sujet]] (S), le [[verbe]] (V), et l’[[Objet (grammaire)|objet]] (O) apparaissent dans les phrases. La grande majorité des langues placent le sujet en premier lieu, soit dans la séquence [[Langue SVO|SVO]], soit dans la séquence [[Langue SOV|SOV]]. Les autres séquences possibles sont [[Langue VSO|VSO]], [[Langue VOS|VOS]], [[Langue OVS|OVS]], et [[Langue OSV|OSV]], ces trois derniers sont plus rares.

Il existe un certain nombre d’approches théoriques dans la discipline de la syntaxe. Un courant de pensée, fondé dans les œuvres de [[Derek Bickerton]], voit la syntaxe comme une branche de la biologie, parce que ce courant conçoit la syntaxe comme l’étude de la connaissance linguistique qu’incarne l’[[esprit]] humain. D'autres linguistes (p. ex. [[Gerald Gazdar]]) ont un point de vue plus [[platonicien]], parce qu’ils considèrent la syntaxe comme l’étude d’un [[système formel]] abstrait. Encore d'autres (p. ex. [[Joseph Greenberg]]) considèrent la syntaxe comme un système taxonomique avec le but d’atteindre de grandes généralisations à travers des langues. Les courants de syntaxe principaux incluent :







[[Catégorie:Syntaxe|*]]

</doc>
<doc id="2871" url="https://fr.wikipedia.org/wiki?curid=2871" title="Stethorus">
Stethorus

Le genre Stethorus comprend des insectes coléoptères prédateurs de la famille des Coccinellidae, dont les larves et les adultes ont pour proies principalement les acariens sur les arbres fruitiers, la vigne, les grandes cultures, et les forêts.

Selon :



</doc>
<doc id="2872" url="https://fr.wikipedia.org/wiki?curid=2872" title="Scymnus">
Scymnus

Scymnus est un genre d’insectes coléoptères prédateurs, de la famille des Coccinellidae, dont les larves et les adultes ont pour proies principalement les pucerons vivant sur les arbres fruitiers, la vigne et dans les forêts.

Selon les classifications, ce genre est classé dans la sous-famille des Scymninae ou des Coccinellinae (tribu des Scymnini dans les deux cas).

Selon :
Selon :

Selon :



</doc>
<doc id="2874" url="https://fr.wikipedia.org/wiki?curid=2874" title="Saturne (planète)">
Saturne (planète)

Saturne est la sixième planète du Système solaire par ordre de distance au Soleil et la deuxième après Jupiter tant par sa taille que par sa masse.

Saturne est une planète géante, au même titre que Jupiter, Uranus et Neptune, et plus précisément une géante gazeuse de type Jupiter froid comme Jupiter. D'un diamètre d'environ neuf fois et demi celui de la Terre, elle est majoritairement composée d'hydrogène et d'hélium. Sa masse vaut 95 fois celle de la Terre et son volume 900 fois celui de notre planète. Sa période de révolution est d'environ . Elle était au périhélie le . Elle sera à l'aphélie le .

Saturne a un éclat bien plus faible que celui des autres planètes observables à l’œil nu. Sa magnitude apparente peut atteindre lors de l'opposition un maximum de 0,43, tandis que son diamètre apparent varie de 14,5 à 20,5 secondes d'arc et que sa distance à la Terre varie de 1,66 à 1,20 milliard de kilomètres.

Saturne possède un système d'anneaux, composés principalement de particules de glace et de poussière. Saturne possède de nombreux satellites, dont cinquante-trois ont été confirmés et nommés. Titan est le plus grand satellite de Saturne et la deuxième plus grande lune du Système solaire après Ganymède autour de Jupiter. Titan est plus grand que la planète Mercure et est la seule lune du Système solaire à posséder une atmosphère significative.

Plus lointaine des planètes du Système solaire observables à l'œil nu dans le ciel nocturne depuis la Terre, elle est connue depuis la Préhistoire.

Saturne a la forme d'un sphéroïde aplati : la planète est aplatie aux pôles et renflée à l'équateur. Ses diamètres équatoriaux et polaires diffèrent de près de 10 % ( pour le premier, pour le second, soit un diamètre moyen volumétrique de 116 464 km), conséquence de sa rapide rotation sur elle-même et d'une composition interne extrêmement fluide. Les autres géantes gazeuses du Système solaire (Jupiter, Uranus et Neptune) sont également aplaties, mais de façon moins marquée.

Saturne est la deuxième planète la plus massive du Système solaire, 3,3 fois moins que Jupiter, mais plus que Neptune et plus qu'Uranus. En comparaison avec la Terre, Saturne est plus massive. Son diamètre étant environ plus grand que celui de la Terre, son volume est 900 fois supérieur.

Saturne est la seule planète du Système solaire dont la masse volumique moyenne est inférieure à celle de l'eau : . Cela vient à dire que si on trouvait un océan assez grand pour contenir Saturne, celle-ci flotterait. Ce chiffre masque d'énormes disparités dans la répartition de la masse à l'intérieur de la planète : si son atmosphère, essentiellement composée d'hydrogène (le gaz le plus léger), est moins dense que l'eau, son noyau l'est considérablement plus.

La haute atmosphère de Saturne est constituée à 93,20 % d'hydrogène et à 6,7 % d'hélium en termes de molécules de gaz (96,5 % d'hydrogène et 3,5 % d'hélium en termes d'atomes). Des traces de méthane , d'éthane , d'ammoniac , d'acétylène et de phosphine ont également été détectées. Les nuages les plus en altitude sont composés de cristaux d'ammoniac, tandis que les nuages plus bas semblent être constitués soit d'hydrosulfure d'ammonium soit d'eau . Par rapport à l'abondance des éléments du Soleil, l'atmosphère de Saturne est sensiblement plus pauvre en hélium.

La quantité d'éléments plus lourds que l'hélium n'est pas encore connue avec précision, mais on suppose que leurs proportions correspondent aux abondances initiales lors de la formation du Système solaire. La masse totale de ces éléments est estimée à 19 à 31 fois celle de la Terre, une fraction significative étant située dans la région du noyau de Saturne.

La structure interne de Saturne serait similaire à celle de Jupiter, avec un noyau rocheux de silicates et de fer, entouré d'une couche d'hydrogène métallique, puis d'hydrogène liquide, puis enfin d'hydrogène gazeux. Des traces de glaces diverses seraient également présentes. Les transitions entre ces différentes couches seraient progressives et la planète ne comporterait pas de surface à proprement parler. La région du noyau posséderait entre 9 et 22 fois la masse de la Terre.

Saturne a une température interne très élevée, atteignant probablement dans le noyau, et dégage, à l'instar de Jupiter, plus d'énergie qu'elle n'en reçoit du Soleil. La majeure partie de cette énergie provient d'un effet de compression gravitationnelle (mécanisme de Kelvin-Helmholtz), mais cet effet ne suffit pas à lui seul à expliquer la production thermique. Une explication proposée serait une « pluie » de gouttelettes d'hélium dans les profondeurs de Saturne, dégageant de la chaleur par friction en tombant dans une mer d'hydrogène plus léger.

Bien que saturne soit composée majoritairement d’hydrogène et d’hélium, les gaz ne représentent qu’une faible partie de sa masse car l’hydrogène devient liquide lorsque la densité dépasse . Cette frontière est atteinte sur une sphère correspondant à 99,9 % de la masse de Saturne. En s’approchant du cœur de la planète, la densité continue de croître jusqu’à transformer l’hydrogène en métal.

Le noyau rocheux est comparable à celui de la Terre si ce n’est qu’il est plus dense. En 2004, la masse de ce noyau a été estimée entre 9 et 22 fois la masse de la Terre par une équipe d’astronomes français. Cette estimation a été effectuée à partir du champ gravitationnel et des modèles géophysiques des planètes gazeuses. De plus, on estime que le diamètre du noyau est de . Ce noyau est entouré d’un épais manteau d’hydrogène liquide puis, à mesure que l’on s’écarte du centre, d’hélium liquide saturé en hydrogène avant que l’hydrogène et l’hélium deviennent gazeux sur environ .

Saturne, bien que calme en apparence, possède un climat violent. Au pôle sud de la planète se trouve un ouragan dont la taille est supérieure à celle des États-Unis avec près de 8 000 km de large. À la différence de la Grande tache rouge de Jupiter, cet ouragan possède un œil qui le rend proche des ouragans terrestres. 

La vitesse du vent sur Saturne peut atteindre , une valeur supérieure à celles relevées sur Jupiter mais moindre que sur Neptune.
La composition des nuages de Saturne varie avec l’altitude. Dans les régions les plus hautes, où les températures évoluent entre 100 et et la pression entre 0,5 et , les nuages se composent de glace d’ammoniac. Entre 2,5 et se trouve de la glace d’eau à des températures de 185 à . Ces nuages s’entremêlent à des nuages de glace d’hydrosulfure d’ammonium à partir de . Ces derniers se maintiennent jusqu’à . La dernière couche contient des gouttes d’ammoniaque (ammoniac en solution aqueuse) pour des pressions de 10 à entre 270 et .

De manière similaire à Jupiter, l'atmosphère de Saturne est organisée en bandes parallèles, même si ces bandes sont moins visibles et plus larges près de l'équateur. En fait, le système nuageux de Saturne ne fut observé pour la première fois que lors des missions Voyager. Depuis, les télescopes terrestres ont fait suffisamment de progrès pour pouvoir suivre l'atmosphère saturnienne et les caractéristiques courantes chez Jupiter (comme les orages ovales à longue durée de vie) ont été retrouvées chez Saturne. En 1990, le télescope spatial Hubble a observé un énorme nuage blanc près de l'équateur de Saturne qui n'était pas présent lors du passage des sondes Voyager. En 1994, un autre orage de taille plus modeste a été observé.

Le nuage de 1990 est un exemple de grande tache blanche, un phénomène saturnien éphémère qui se reproduit environ tous les 30 ans (c'est-à-dire environ chaque année saturnienne). Des grandes taches blanches ont été observées en 1876, 1903, 1933 et 1960. Si la périodicité se maintient, une autre tempête devrait se produire vers 2020.

Dans les images transmises par la sonde "Cassini", l'atmosphère de l'hémisphère nord apparaît bleue, de façon similaire à celle d'Uranus. Cette couleur est probablement causée par diffusion Rayleigh.

L'imagerie infrarouge a montré que Saturne possède un vortex polaire chaud, le seul phénomène de ce type connu dans le Système solaire.

Un système ondulatoire hexagonal existe autour du pôle nord, vers 78° de latitude. Il a été remarqué pour la première fois lors du passage des sondes "Voyager". Les bords de l'hexagone mesurent environ . La structure tourne sur elle-même avec une période de . Le système ne se décale pas en longitude comme les autres structures nuageuses de l'atmosphère visible. Son origine n'est pas connue. La plupart des astronomes semblent penser qu'il s'agit d'un ensemble d'ondes stationnaires. Parmi les autres théories, il pourrait s'agir d'un type inconnu d'aurore polaire. Des formes polygonales ont été reproduites en laboratoire à l'intérieur de seaux de fluides en rotation.

Les images prises par le télescope spatial Hubble indiquent la présence au pôle sud d'un courant-jet, mais pas d'un vortex polaire ou d'un système hexagonal analogue. Cependant, la NASA a signalé en novembre 2006 que "Cassini" a observé une tempête analogue à un ouragan, stationnant au pôle sud, et qui possède un œil clairement défini. Il s'agit du seul œil jamais observé sur une autre planète que la Terre.

De 2004 à 2009, la sonde Cassini a également pu observer la formation, le développement et la fin de 9 violents orages. Les orages de Saturne sont particulièrement longs. Un orage s'étala de novembre 2007 à juillet 2008. De même, un très violent orage débuta en janvier 2009 et dura plus de 8 mois. Ce sont les plus longs orages observés jusque-là dans le Système solaire. Ils peuvent s'étendre sur plus de de diamètre autour de la région appelée « Allée des tempêtes » située à 35° au Sud de l'équateur.
Les décharges électriques provoquées par les orages de Saturne émettent des ondes radio dix mille fois plus fortes que celles des orages terrestres.

La magnétosphère de Saturne est une cavité créée dans le vent solaire par le champ magnétique de la planète. Découverte en 1979 par la sonde "Pioneer 11", la magnétosphère de Saturne est la deuxième plus vaste au sein du système solaire, après celle de Jupiter. La magnétopause, frontière entre la magnétosphère de Saturne et le vent solaire, se trouve à environ vingt fois le rayon de Saturne depuis le centre de la planète, tandis que la queue magnétique s'étire derrière sur des centaines de fois le rayon de la planète. 

La magnétosphère de Saturne est rempli de plasma originaire de la planète et de ses satellites, notamment Encelade qui éjecte jusqu’à 600 kg/s de vapeur d’eau par ses geysers au pôle sud. Le champ magnétique se charge ainsi de 100 kg d’ions par seconde. Ce plasma se déplace de l’intérieur du champ vers la magnéto-queue.

L’interaction de la magnétosphère et des vents solaires crée des aurores polaires sur les pôles de la planète dans le domaine du visible, de l’infrarouge et de l’ultraviolet.

À l’intérieur de la magnétosphère se trouve une ceinture de radiation qui contient des particules d’énergie pouvant atteindre la dizaine de mégaélectronvolts. Ces particules ont alors une forte influence sur la surface des lunes glacées de Saturne.

Saturne génère un champ magnétique bipolaire et symétrique de () à l’équateur, ce qui est légèrement plus faible que le champ magnétique terrestre.

Le rayon de la magnétosphère est 19 fois plus grand que celui de Saturne, soit , d’après Voyager 2. L’origine de cette magnétosphère est probablement l’effet dynamo des courants d’hydrogène métallique liquide. C’est la magnétosphère qui rejette les particules des vents solaires.

Le champ magnétique de Saturne est plus faible que celui de Jupiter et sa magnétosphère est plus petite.

L'atmosphère de Saturne subissant une rotation différentielle, plusieurs systèmes ont été définis, avec des périodes de rotation propres (un cas similaire à celui de Jupiter) :

Ce dernier système, mesuré lors du passage des sondes "Voyager", était celui généralement utilisé pour parler de la rotation de la planète. Cependant, lors de son approche de Saturne en 2004, la sonde "Cassini" mesura que la période de rotation radio s'était légèrement accrue, atteignant 10 h 45 min 45 s (± 36 s). La cause exacte du changement n'est pas connue.

En mars 2007, il a été annoncé que la rotation des émissions radio ne rend pas compte de la rotation de la planète, mais est causée par des mouvements de convection du disque de plasma entourant Saturne, lesquels sont indépendants de la rotation. Les variations de période pourraient être causées par les geysers de la lune Encelade. La vapeur d'eau émise en orbite saturnienne se chargerait électriquement et pèserait sur le champ magnétique de la planète, ralentissant sa rotation par rapport à celle de Saturne. Si ce point est vérifié, on ne connaît aucune méthode fiable pour déterminer la période de rotation réelle du noyau de Saturne.

Étant donnée sa distance au Soleil, Saturne est une planète très froide en surface : 

Les anneaux de Saturne sont les anneaux planétaires les plus importants du Système solaire. Bien qu'ils semblent continus vus depuis la Terre, ils sont en fait constitués d'innombrables particules de glace (95 à 99 % de glace d'eau pure selon les analyses spectroscopiques) et de poussière dont la taille varie de quelques micromètres à quelques centaines de mètres ; ils ont chacun une orbite différente. Les anneaux forment un disque dont le diamètre est de 360 000 km (les anneaux principaux s'étendent de 7 000 à 72 000 km) comportant plusieurs divisions de largeurs variées et dont l'épaisseur va de 2 à 10 mètres.À la différence de ceux des autres géantes gazeuses, ils sont extrêmement brillants (albédo de 0,2 à 0,6) et peuvent être vus depuis la Terre à l'aide de simples jumelles.

Ils ont été aperçus en 1610 par le savant italien Galilée grâce à une lunette astronomique de sa conception. Celui-ci interpréta ce qu'il voyait comme de mystérieux appendices. Bénéficiant d'une meilleure lunette que Galilée, le néerlandais Christian Huygens va découvrir qu'il s'agit en fait d'un anneau entourant Saturne.

Il y règne une agitation permanente : vagues, collisions et accumulations de matières.
"("R" désigne le rayon équatorial de Saturne (), pris ici comme unité de longueur.)"

En 2009, un anneau a été mis en évidence par le satellite Spitzer en infrarouge. Ce nouvel anneau, très peu dense, a été trouvé à l'endroit même où évolue un des satellites de Saturne, Phœbé, qui en serait peut-être à l'origine.

Saturne possède un grand nombre de satellites naturels. Il est difficile de dire combien, dans la mesure où tout morceau de glace des anneaux est techniquement un satellite et qu'il n'est pas possible de faire la distinction entre une grande particule et une petite lune.

En 2009, 62 satellites ont été identifiés, ainsi que 3 autres corps qui pourraient n'être que des amas dans les anneaux. 53 satellites ont été confirmés et nommés.

La plupart des lunes connues sont petites : 13 mesurent moins de de diamètre et 31 autres moins de . Seules sept sont suffisamment massives pour avoir pu prendre une forme sphéroïde sous leur propre gravité. Titan, la plus grande d'entre elles, plus grande que Mercure ou Pluton, est le seul satellite du Système solaire à posséder une atmosphère dense.

Tous les satellites pour lesquels la période de rotation est connue, à l'exception de Phœbé et d'Hypérion, sont synchrones. Les orbites des trois paires Mimas-Téthys, Encelade-Dioné et Titan-Hypérion sont en résonance : Mimas et Téthys sont en résonance 1:2 (la période de révolution de Mimas est exactement la moitié de celle de Téthys) ; Encelade et Dioné sont également en résonance 1:2 ; Titan et Hypérion sont en résonance 3:4.

Traditionnellement, la plupart des lunes de Saturne ont été nommées d'après des Titans de la mythologie grecque.

Saturne, comme les autres planètes géantes gazeuses du système solaire, se serait formée au-delà de la ligne des glaces. Cette ligne désigne la zone au-delà de l’orbite de Mars, où la matière est suffisamment froide pour que ses composés de glace volatile restent à l'état solide. Les glaces qui formèrent les géantes gazeuses étaient plus abondantes que les métaux et les silicates qui formaient les planètes telluriques. Ceci permit aux géantes de devenir suffisamment massives pour qu'elles finissent par capturer l'hydrogène et l'hélium, les plus légers mais aussi les plus abondants des éléments de l'univers. Les planétésimaux formés par-delà la ligne des glaces accumulèrent jusqu'à plus de quatre masses terrestres sur une période de d'années. La masse significativement plus réduite de Saturne par rapport à Jupiter s'expliquerait par le fait qu'elle se serait formée quelques millions d'années après Jupiter, alors qu'il y avait moins de gaz disponible dans son environnement.

Le nom de Saturne correspond à "Phaénon" () dans l'astronomie grecque, à "Zohal" () dans l'astronomie arabe ainsi qu'à "Tǔxīng" ( / ) dans l'astronomie chinoise.

Elle est ainsi désignée, à la suite d'un usage antique, d'après Saturne, un dieu de la mythologie romaine, assimilé au titan Cronos de la mythologie grecque. Son symbole « », d'origine ancienne représenterait la faucille du dieu Saturne ou serait dérivé de la lettre grecque "kappa" minuscule, initiale du grec ancien . Néanmoins, l'Union astronomique internationale recommande de substituer au symbole « » l'abréviation , correspondant à la lettre latine S majuscule, initiale de l'anglais "".

Saturne est la plus lointaine des cinq planètes visibles à l'œil nu la nuit, des observations étant attestées depuis la préhistoire.

En 1610, Galilée, en braquant son télescope vers Saturne, en observe les anneaux mais ne comprend pas ce qu'il en est, décrivant que la planète aurait des « oreilles ». En 1612, la Terre passant dans le plan des anneaux, ceux-ci disparaissent. En 1613, ils réapparaissent sans que Galilée puisse émettre une hypothèse quant à ce qu'il observe.

En 1655, Christian Huygens, découvre près de Saturne un astre qui sera nommé plus tard Titan.

En 1656, Christian Huygens, en utilisant un télescope bien plus puissant, comprend que la planète est en réalité entourée d'un anneau, qu'il pense être solide.

En 1675, Jean-Dominique Cassini détermine que l'anneau est composé de plusieurs petits anneaux, séparés par des divisions ; la plus large d'entre elles sera plus tard appelée la division de Cassini.

En 1859, James Clerk Maxwell démontre que les anneaux ne peuvent pas être solides. Il émet l'hypothèse qu'ils sont constitués d'un grand nombre de petites particules, toutes orbitant autour de Saturne indépendamment. La théorie de Maxwell fut prouvée correcte en 1895 par des études spectroscopiques menées par James Keeler à l'observatoire Lick.

Dans le dernier quart du , Saturne fut visitée par plusieurs sondes spatiales : Pioneer 11 en 1979, Voyager 1 en 1980 et Voyager 2 en 1981.

Pioneer 11 passa à des nuages de Saturne en septembre 1979. La sonde prit des photographies en basse résolution de la planète et de quelques-uns de ses satellites, lesquelles n'étaient pas assez bonnes pour distinguer les caractéristiques de leur surface. Elle étudia l'étalement des anneaux, découvrit l'anneau F et le fait que les divisions ne sont pas vides de matériaux. Pioneer 11 mesura également la température de Titan.

En novembre 1980, Voyager 1 visita le système saturnien. La sonde renvoya les premières images en haute résolution de la planète, de ses anneaux et de ses satellites. Les surfaces de plusieurs lunes furent vues pour la première fois. Voyager 1 effectua un survol de Titan, accroissant les connaissances sur l'atmosphère de cette lune. Cependant, elle prouva également que cette atmosphère était imperméable aux longueurs d'onde de la lumière visible. Le survol éjecta la sonde hors du plan du Système solaire.

En août 1981, Voyager 2 continua l'étude de Saturne. Elle prit plus de gros plans des lunes et apporta des preuves d'évolution de l'atmosphère et des anneaux. Malheureusement, pendant le survol, la plateforme de caméra orientable resta coincée pendant deux jours et certaines photographies ne purent être prises selon l'angle prévu. La gravité de Saturne fut utilisée pour diriger la sonde vers Uranus (voir cette planète) qui, à son tour, la dirigea vers Neptune.

Les sondes découvrirent et confirmèrent plusieurs satellites orbitant près ou à l'intérieur des anneaux de Saturne. Elles découvrirent également la division de Maxwell et la division de Keeler.

La sonde "Cassini-Huygens" s'est placée en orbite autour de Saturne le afin d'étudier le système saturnien, avec une attention particulière pour Titan. En juin 2004, elle effectue un survol de Phœbé.

L'orbiteur réalise deux survols de Titan et largue le 25 décembre 2004, le module atterrisseur "Huygens". Celui-ci se pose sur Titan le 14 janvier 2005, transmettant un flot de photographies et de données pendant la descente et après l'atterrissage. Pendant l'année 2005, "Cassini" effectue plusieurs autres survols de Titan et d'autres satellites.

Le 10 mars 2006, la NASA annonce que "Cassini" a mis en évidence sur Encelade des réservoirs d'eau liquide s'échappant en geyser.

Le 20 septembre 2006, "Cassini" photographie un anneau planétaire non encore découvert, en dehors des anneaux principaux et situé à l'intérieur des anneaux E et G.

En juillet 2006, "Cassini" détecte la première preuve de lacs d'hydrocarbures près du pôle nord de Titan, ce qui sera confirmé en janvier 2007. En mars 2007, de nouvelles images du pôle mettent en évidence des mers d'hydrocarbures, la plus grande ayant presque la taille de la mer Caspienne.

La mission de la sonde devait en principe s'achever en 2008, après 74 orbites autour de Saturne, elle est dépendante de la réserve de carburant nécessaire à moduler chaque orbite ; mais début 2008, au vu des réserves encore existantes, elle a été prolongée de 2 ans.

En avril 2013, "Cassini" enregistre les images d'un vaste ouragan frappant le pôle nord de Saturne dont l'œil, de de diamètre, est 20 fois plus large que celui des ouragans terrestres, avec des vents supérieurs à . Il se peut qu'il soit là depuis plusieurs années.

Le 15 septembre 2017, après 15 ans de services, la sonde "Cassini", à court de carburant, est désintégrée volontairement dans l'atmosphère de Saturne pour éviter le risque d'un écrasement sur Titan (et donc d'une possible contamination par des composés chimiques et micro-organismes terrestres).








</doc>
<doc id="2876" url="https://fr.wikipedia.org/wiki?curid=2876" title="Systèmes de prise de décision">
Systèmes de prise de décision

Les responsables politiques ont besoin d'utiliser des systèmes de prise de décision applicables à un collectif; de même, chaque individu s'invente aussi de tels systèmes pour lui-même.

Pour prendre une décision, il faut réunir de multiples conditions:

Selon les modalités adoptées, on classe chaque système dans un régime politique. On notera en particulier que :


À noter : 


</doc>
<doc id="2878" url="https://fr.wikipedia.org/wiki?curid=2878" title="La Société du spectacle (livre)">
La Société du spectacle (livre)

La Société du spectacle est un essai de Guy Debord publié initialement le chez Buchet/Chastel. Le livre connut un fort retentissement après les événements de Mai 68.

L'ouvrage est composé de 221 « thèses » et subdivisé en neuf chapitres comme suit : 

Le livre est agencé comme un essai politique et vise à exposer son sujet de manière assertive. En effet, Debord ne cherche pas à démontrer ni même à convaincre, mais à montrer. Il rejoint ainsi la conception de Marx en disant que la philosophie doit trouver sa réalisation et non plus sa discussion. 
L'auteur prolonge dans cet essai la critique du fétichisme de la marchandise que Marx développe en 1867 dans "Le Capital", elle-même un prolongement de la théorie de l'aliénation exposée par Marx dans ses Manuscrits de 1844. L'originalité de la réflexion de Debord consiste à décrire l'avance contemporaine du capitalisme sur la vie de tous les jours, c'est-à-dire dans son emprise sur le monde "à travers" la marchandise.
Cette filiation s'exprime par un certain nombre de « clins d'œil » ou de reprises, dont la première phrase du livre est l'annonce. En effet, la phrase d'ouverture de "la Société du Spectacle" est un détournement de la phrase d'ouverture du "Capital" de Karl Marx :

"La Société du spectacle" est essentiellement une critique radicale de la marchandise et de sa domination sur la vie, que l'auteur voit dans la forme particulière de l'« aliénation » de la société de consommation. Le concept de spectacle se réfère à un mode de reproduction de la société fondé sur la reproduction des marchandises, toujours plus nombreuses et toujours plus semblables dans leur variété. Debord prône une mise en acte de la conscience qu'on a de sa propre vie, envers une illusoire pseudo-vie que nous impose la société capitaliste, particulièrement depuis l'après-guerre.

"La Société du spectacle" décortique les processus d'individuation dans la société post-industrielle alors naissante. Il y est décrit l'évolution de la pratique de « séparation » comme dispositif économique capitaliste. Comment depuis l'introduction des chaines de montages où le travailleur est séparé de ce qu'il produit, la société libérale-marchande depuis les années 1950 produit le sujet/consommateur en tant qu'être séparé de ses véritables désirs par divers industries socio-culturelles (cinéma, télévision etc.) : par exemple comment le stéréotype du jeune branché ou du rebelle deviennent des modèles de comportements à suivre faisant de notre volonté de se montrer à l'autre un pastiche d'une reproduction consommable, interchangeable (« Le spectacle n'est pas un ensemble d'images, mais un rapport social entre des personnes, médiatisé par des images ». Thèse 4 du chapitre premier, « Le vrai est un moment du faux » ; thèse 9 du chapitre premier).

Il soutient, dans le premier chapitre essentiellement, que la direction immanente du spectacle en est aussi le but et qu'ainsi, au fur et à mesure de son application, elle se justifie elle-même de façon exponentielle.

Selon Debord, le spectacle est le stade achevé du capitalisme, il est un pendant concret de l'organisation de la marchandise. Le spectacle est une idéologie économique, en ce sens que la société contemporaine légitime l’universalité d’une vision unique de la vie, en l’imposant aux sens et à la conscience de tous, via une sphère de manifestations audio-visuelles, bureaucratiques, politiques et économiques, toutes solidaires les unes des autres. Ceci, afin de maintenir la reproduction du pouvoir et de l’aliénation : la perte du vivant de la vie.
Aussi le concept prend plusieurs significations. Le « spectacle » est à la fois l'appareil de propagande de l'emprise du capital sur les vies, aussi bien qu'un « rapport social entre des personnes médiatisé par des images ».

Dans les sociétés spectaculaires la marchandise devient le vecteur, le dispositif des conditions économiques et sociales les produisant (« Sous toutes ses formes particulières, information ou propagande, publicité ou consommation directe de divertissements, le spectacle constitue le modèle présent de la vie socialement dominante. Il est l'affirmation omniprésente du choix déjà fait dans la production, et sa consommation corollaire. Forme et contenu du spectacle sont identiquement la justification totale des conditions et des fins du système existant ») - thèse 6.
Dans les sociétés dites libérales, l'abondance et l'hétérogénéité des entreprises productrices et de leurs produits est décrite par Debord selon le terme « spectaculaire diffus » (thèse 65) tandis que dans les sociétés dites « socialistes » la gestion des marchandises et de leurs productions sont centralisées par les structures bureaucratiques gérant la totalité de ces États. Debord la décrit selon le terme « spectaculaire concentré » (thèse 64).

En 1988, dans "Commentaires sur la société du spectacle", Debord décrit l'évolution de la société spectaculaire en ceci que ces rapports marchands se sont totalement fondus dans la société à tel point qu'ils sont devenus systémiques. Il la décrit en tant que combinaison des deux formes précédentes selon le terme « spectaculaire intégré » (commentaire IV).







</doc>
<doc id="2881" url="https://fr.wikipedia.org/wiki?curid=2881" title="Sémantique">
Sémantique

La sémantique est une branche de la linguistique qui étudie les signifiés, ce dont on parle, ce que l'on veut énoncer. Sa branche symétrique, la syntaxe, concerne pour sa part le signifiant, sa forme, sa langue, sa graphie, sa grammaire ; c'est la forme de l'énoncé.

En particulier, la sémantique possède plusieurs objets d'étude :

Le terme de "sémantique" est utilisé en opposition à celui de syntaxe dans l'étude des langages de programmation en informatique, pour laquelle elle a été développée de manière formelle (voir sémantique des langages de programmation). Il y a entre la sémantique et la syntaxe le même rapport qu'entre le fond et la forme. George Lakoff a étudié la sémantique influençant la syntaxe.

Le mot "sémantique" est dérivé du grec σημαντικός (sêmantikos), « signifié » lui-même formé à partir de σημαίνω (sêmainô), « signifier, indiquer » ou σῆμα (sêma), « signe, marque ». Il a été repris à la fin du par le linguiste français Michel Bréal, auteur du premier traité de sémantique.

L'analyse syntaxique aussi bien que l'analyse sémantique en linguistique a pour finalité de caractériser l'énoncé dans son ensemble principalement par la détermination des structures de l'énoncé. Dans les deux cas, la détermination des structures sera basée sur une caractérisation de ses éléments de base, les mots, et leurs propres constituants, mais de façon différente selon ces deux approches.

L'analyse syntaxique va s'occuper des syntagmes et elle s'en occupera par rapport à une phrase. On ne peut pas faire d'analyse syntaxique du mot "petites" par exemple s'il n'est pas inclus dans une phrase, en relation avec d'autres mots compléments ou chefs de groupe.

L'analyse syntaxique peut ainsi être identifiée comme une analyse des structures fonctionnelles pouvant être obtenues au moyen de l'exercice des règles de la grammaire.

L'analyse sémantique de son côté s'intéresse à ces structures en observant les mécanismes propres à la construction du sens. À savoir : un sème est la plus petite unité de sens.

La sémantique peut s'intéresser à un mot pour le mot. On analysera ainsi le mot « petites » :

PETIT (Adj. ⇒ qui n'est pas grand) + E (marque de féminin) + S (marque de pluriel)
[PETIT – la base ou le radical du mot (signe lexical), E + S - sont des signes grammaticaux].

Pour le mot « petites » nous avons donc trois sèmes.

À partir de ce même mot, d'autres analyses sont possibles sans forcément mettre en lumière un énoncé entier. (cf introduction)

La distinction entre analyse syntaxique et analyse sémantique qui est établie ici correspond à l'approche la plus répandue en linguistique contemporaine, celle qui hérite du structuralisme introduit par Ferdinand de Saussure. On rencontrera les termes d'analyse structurale ou analyse componentielle employés comme équivalents pour signifier au plus directement l'approche utilisée pour effectuer l'analyse sémantique selon cette théorie. La structure est perçue comme directement sous-jacente à la phrase, cette dernière étant une structure ainsi qu'il est mis en évidence par la syntaxe ou la grammaire, et le mot étant considéré comme associé à ses "traits sémantiques". D'autres approches, comme principalement la grammaire de dépendance de Lucien Tesnière, antérieure au structuralisme, réservent la qualification de structure au niveau syntaxique. Pour Tesnière, le niveau syntaxique est appelé "plan structural" tandis que le "plan sémantique" est considéré comme relevant de la psychologie, et également de la logique.

Les méthodes d'exploration de données permettent de dégager du sens d'un ensemble de données d'allure a priori disparates (voir aussi intelligence artificielle) et donc "créent" de la sémantique.
La sémantique dégagée prend généralement trois formes (traduction par des signifiants formels) issues de l'intelligence artificielle :

Ce sont des signifiants, au sens où ils "représentent" les connaissances. De telles structures sont ensuite annotées dans les données de départ, chaque donnée portant alors la marque de son appartenance à une branche de l'arbre, une case du tableau, etc. L'analyse reprend alors à un niveau de compréhension plus complexe.

Toutefois, la machine ne manipulant que des signifiants, il est impératif que la démarche de "forage de données" fasse intervenir un expert humain du domaine. Celui-ci va restituer la sémantique extraite et lui donner du sens, de la valeur. Trois critères sont exhibés à cette fin :
L'idéal est d'avoir un triplet NON/OUI/OUI.

Un tel projet est appelé « découverte des connaissances dans les bases de données », en anglais KDD, "Knowledge Discovery in Databases".

Finalement, la sémantique extraite tient le rôle d'une cartographie de l'information, elle permet de situer les informations les unes par rapport aux autres. Ce rôle « cartographique » permet de stocker l'information, de la ranger et plus tard de la retrouver. Tout modèle, jeu de catégories, "topique" freudienne est alors "de facto" une cartographie de l'information, c'est-à-dire un contexte formalisé.

Ce sont en fait des données sur les données, des métadonnées. Des architectures informatiques spécifiques permettent de gérer ces métadonnées, on parle de "client" ou de "serveur" de métadonnées. Un système connu est le "Dublin Core Metadata Initiative" (DCMI). (voir Dublin Core).

Le Web sémantique est un projet du même type que DCMI, visant à créer, gérer et exploiter des métadonnées systématiques pour chaque page web. Ainsi le contenu de chaque page web étant explicité vers des signifiants, la machine serait capable de raisonner sur la pertinence du contenu et non plus sur des statistiques lexicales. Cela peut avoir des conséquences remarquables sur les technologies de recherche d'informations, ainsi que l'allure et le fonctionnement des moteurs de recherche.

La fouille textuelle consiste à transformer un objet « texte » en un objet « tableau », « arbre » ou « graphe » à l'aide de traitements sémantiques ou syntaxiques puis à appliquer des techniques de fouille textuelle sur cet objet formalisé. Les résultats attendus sont généralement :

L'approche sémantique a une littérature plus féconde que l'approche syntaxique : même si cette dernière a des résultats supérieurs, les ressources de calcul demandées font souvent pencher la balance en faveur de l'analyse sémantique.

L'analyse sémantique transforme un ensemble de textes en une "matrice lexicale" :

Le terme « ontologie » a une signification philosophique, mais en gestion des connaissances, il représente la forme probablement la plus évoluée de représentation sémantique des connaissances.Il s'agit d'une sorte de « superthésaurus » destiné à indexer toutes les productions documentaires, stockées, entrantes ou sortantes dans un groupe social donné, typiquement une entreprise. Ainsi, un courrier électronique, un ouvrage de référence, un document de travail partageant les mêmes thèmes seront automatiquement mis en lien, donc mis en contexte, dégageant ainsi des connaissances sémantiques.La structuration d'une ontologie est pratiquement un métier en soi, à l'instar de la conception et de la maintenance des thésaurus de bibliothèques. La construction est toujours collective et par agglomération de domaines de compétence.

L'articulation de base d'une ontologie est la suivante :
Exemple : OISEAU > AIGLE {aigle royal}. La machine peut alors inférer que l'aigle royal est un oiseau.
En pratique, on pourrait ainsi traduire automatiquement un manuel d'histoire en ontologie, en considérant cinq types de concepts (date, lieu, événement, personne physique, personne morale) et une trentaine de catégories de liens verbaux.

Pour la machine, raisonner sur les connaissances ainsi représentées revient à « se promener » dans le réseau de concepts, à la manière d'un réseau routier. Il existe des algorithmes spécifiques, par exemple les "chercheurs de chemins (Pathfinder)", qui cherchent le plus court chemin d'un concept à l'autre en respectant un critère d'économie : « plus petit nombre de concepts », « plus grand nombre de langues », « plus grand nombre de synonymes », etc. Les résultats peuvent être spectaculaires, surtout si l'on garde présent à l'esprit que le point de départ et le point d'arrivée ne sont pas les concepts, mais bien les URI indexés (documents de l'entreprise).





</doc>
<doc id="2882" url="https://fr.wikipedia.org/wiki?curid=2882" title="Suzuki">
Suzuki

Suzuki Motor Corporation est un constructeur japonais de motos, d'automobiles et de moteurs de bateaux ; il est avant tout un important fabricant de motos.

Suzuki se fait connaître sur le marché automobile durant les années 1960. Toutefois, ses origines se situent en 1909, lorsque Suzuki Michio fonde la « Suzuki Looms Works » près de Hamamatsu (浜松) (préfecture de Shizuoka / Japon). À cette époque, elle se concentrait uniquement sur des machines à coudre et à tisser destinées à l'industrie textile.

1952 voit apparaître la première motocyclette Suzuki animée d'un petit moteur à deux temps de , elle est dénommée « Power Free ». La transmission est assuré par une courroie. Grâce à cette motocyclette et à la gamme qui va en découler, Suzuki peut se faire une place sur la scène commerciale et sportive. En 1954, la firme prend le nom de « Suzuki Motors » et présente son premier modèle de voiture, la « Suzulight » (スズライト), un mini modèle de qui ne sortit qu'à 43 exemplaires.

En 1955, Suzuki commercialise sa première véritable moto : la Colleda, mue par un monocylindre de . En 1956, la Colleda TT est mue par un bicylindres de .

En 1961, les motocyclettes Suzuki débarquent en France.

En 1962, la firme atteint enfin une production conséquente en sortant des usines Suzulight 30 TL. Grâce à ce succès, la firme va ouvrir des usines dans les villes japonaises suivantes : Toyama(冨山), Iwata (磐田), Osuka (大須賀) et Kosai (湖西). La production, va également se diversifier et Suzuki va pouvoir proposer à ses clients, non seulement des motocyclettes et des automobiles, mais également des véhicules utilitaires, des moteurs de bateau ou encore des maisons préfabriquées.

En 1965 Suzuki présente la fameuse T20, motocyclette avec un moteur bicylindre de , très performante pour l'époque et ainsi que son premier moteur hors-bord.

Durant les années 1970, les modèles « Fronte » (dans des déclinaisons différentes telles que la 360 ou l'Alto) ou « Jimny » (le petit tout-terrain) permettent d'élargir les exportations et ainsi faire connaître la marque, entre autres sur le continent américain.

En 1972 lancement de la Suzuki GT380, refroidissement par air amélioré par une écope spéciale dite Ram Air System motocyclette de 3 cylindres de (il en existera une déclinaison de plus forte cylindrée, la GT 550) suivi en 1973 du lancement de la Suzuki GT 750, motocyclette grand tourisme, avec un moteur 3 cylindres de .

Après le choc pétrolier et les nouvelles mesures anti-pollution appliqué aux états-unis, Suzuki doit changer sa gamme de motocyclette pour se tourner vers des moteurs 4 temps, il lance en 1974 la Suzuki RE-5, une motocyclette révolutionnaire ayant un moteur a piston rotatif de sous licence Wankel acquise plus tôt dans les années 1970. Ce fut un échec cuisant dont la firme aura du mal à se remettre,tant ce ratage a mis à mal les finances de Suzuki.

Pour rattraper la situation Suzuki lance en 1976 la Suzuki GS750, et la Suzuki GS400 qui ont été des succès commerciaux, permettant de renflouer les caisses de l'entreprise.

En 1981, Suzuki passe un accord avec General Motors pour répondre à la demande croissante de « petites voitures » aux États-Unis et elle lance la GSX 1100S Katana, motocyclette au design révolutionnaire pour l'époque

De fil en aiguille, la collaboration se fait de plus en plus forte, et, avec l'aide d'Isuzu (filiale japonaise de General Motors), on voit la naissance d'une voiture de qui sera vendue au Japon sous le nom de « Suzuki Cultus », aux États-Unis, sous le nom de « Chevrolet Sprint ».

En 1983, Suzuki exporte ses modèles aux États-Unis sous la marque Geo, créée de toutes pièces par General Motors. Suzuki prend aussi une part importante dans le capital de la société indienne Maruti , lancement de la motocyclette RG250, première motocyclette de série équipée d'un cadre en aluminium mue par un moteur bicylindres de et lancement du premier quad de série le Suzuki QuandRunner 125.

En 1985, Suzuki lance deux motocyclettes révolutionnaires la Suzuki GSX-R 750, et la RG500 Gamma . Pour la première fois les motards pouvaient avoir accès à des replicas tout droit sorties du paddock.

En 1987, Suzuki lance la motocyclette DR800 Big, motocyclette de série ayant le plus gros monocylindres au monde de .

En 1989, Suzuki lance les motocyclettes à succès suivantes : la Suzuki GS500E et la Suzuki GSF 400 Bandit.

C'est également à la même époque que Suzuki prend contact avec Land Rover pour que cette dernière fabrique sous licence, la « Jimny », puis sa descendante, la « Vitara ».

En 1992, ouverture de l'usine Magyar Suzuki corporation en Hongrie. En juin 1993, ouverture de l'usine Changan Suzuki Automobile en Chine. En 1995, la production totale de Suzuki atteignait plus de voitures.

Durant la même année Suzuki lance également une motocyclette qui a été un succès pour la firme à travers le monde la Suzuki GSF 600 Bandit .

En septembre 1998, Suzuki et GM nouent des liens stratégiques qui se concrétiseront avec une prise de participation de GM. Au début du , la part de GM devient majoritaire.

En 1999, Suzuki lance la GSX1300R Hayabusa, première motocyclette de série dont le carénage a été modelé par des études en soufflerie et conçu pour atteindre + de .Ce modèle est surtout réputé pour avoir défrayé la chronique à sa présentation en 1998. En effet, c'est la première moto de série à revendiquer plus de 300 km/h de vitesse de pointe. L'usine a annoncé 312 km/h à 13 000 tr/min.

En avril 2003, Suzuki et le constructeur italien Fiat Auto signent un double accord de coopération :


En mars 2006, GM, en grave difficulté financière, revend ses parts pour ne garder que 3 % symboliques du capital de Suzuki. GM sort complètement du capital en 2008.

En 2007, Suzuki perd au Japon sa place de leader sur le marché des keijidosha, modèles limités à moins de et de moins de de long, très important au Japon, au profit de Daihatsu, filiale de Toyota. Suzuki tenait ce segment de marché depuis 34 ans.

En décembre 2009, c'est au tour de l'allemand Volkswagen de monter dans le capital de Suzuki. Il prend 19,9 % du capital pour de yens soit d'euros. Cette coopération sera de très courte durée car dès le milieu de l'année 2011, Suzuki renouvelle son accord de coopération avec Fiat Group Automobiles, licence de fabrication de moteurs Fiat au Japon, mais pire, il accuse Volkswagen ne n'avoir aucune technologie de niveau intéressant et signe avec Fiat un accord de fourniture supplémentaire de moteurs Diesel par an, pour ses productions japonaises, indiennes et hongroises.

Toujours en 2009 création de Chongqing Haojue Suzuki Motorcycle, entreprise co- créée par Suzuki avec un partenaire chinois, l’entreprise Chongqing Haojue Industrial.

En 2012, Suzuki annonce se retirer du marché des États-Unis. La diffusion sur ce marché cesse en 2013, l'entreprise entreprend une restructuration en profondeur et se consacre davantage sur les marchés émergents dont elle tire du profit.

L'aboutissement de cette réflexion donne naissance à des produits conçus mondialement comme pour la motocyclette suivante la Suzuki GW 250 Inazuma, celle-ci s'inspire de la motocyclette Suzuki B-King.

Le 31 mars 2013, Suzuki annonce la fermeture de l'usine espagnole de Suzuki moto. Le 28 janvier 2014, Suzuki annonce la construction d'une usine d'assemblage en Inde pour 350 millions d'euros.

En août 2015, suite aux nombreux désaccord avec Volkswagen, une instance de médiation mandatée par les deux entreprises demande à cette dernière de vendre sa participation de 19,9 % dans Suzuki à Suzuki elle-même, participation ayant environ une valeur de 3,4 milliards d'euros. De plus Suzuki devra payer des compensations, l'instance ayant reconnu que celle-ci est responsable de l'arrêt d'une partie des accords entre les deux sociétés.

En août 2016, Suzuki annonce la vente de sa participation dans Fuji Heavy pour 515 millions de dollars.

Dès les années 1960, Suzuki a brillé en Grand Prix.

En 1964, Suzuki sort une deux-temps à deux cylindres, distributeurs rotatifs, boîte à 14 rapports et refroidissement liquide. Cette machine connaitra de nombreux succès jusqu'en 1968. En 1967, Suzuki sort une à quatre cylindres, utilisant la même technique que la .

De nombreux pilotes, tels Barry Sheene ou Kevin Schwantz, champion du monde en 1993 et Kenny Roberts Jr, champion du monde 500 en 2000, ont défendu la marque en Grand Prix.

En moto-cross, Suzuki peut s'enorgueillir d'être la marque ayant remporté le plus de titres de Champion du monde.

En Championnat du monde Superbike, l'australien Troy Corser remporta le titre au guidon d'une GSX-R 1000 en 2005.

Aujourd'hui, Suzuki fait également ses preuves au Master of Endurance (championnat composé de six courses dont les 24 Heures Moto). Le team officiel se nomme Suzuki Endurance Racing Team et Dominique Méliand en est le team Manager.

Dans le domaine automobile, Suzuki est plutôt reconnu pour ses petits véhicules. La plupart de ses voitures furent équipées d'un moteur de trois cylindres, la majorité du temps de moins d'un litre de cylindrée. La Suzuki Swift ("Cultus" au Japon) est un modèle bien-aimé dans le monde du tuning et on la modifie partout dans le monde.

Depuis la fin de l'année 2005, Suzuki est sorti du giron de l'américain GM. Il utilise les moteurs Diesel Fiat Powertrain : le 1,3 MJet dans ses versions 75 et ainsi que le 1,9 MJet dans la seule version pour motoriser le tout-chemin conçu avec Fiat Auto.








Suzuki est un grand constructeur de moteurs hors bord: 

Actuellement sa gamme couvre un grand éventail de puissances de 2 à 300 cv
Les moteurs 2 temps sont référencés DT (T comme Two, deux en anglais) suivi du chiffre de puissance en cv (Chevaux Vapeur)

Les séries DT ont une réputation de très grande robustesse et bien que la production ait évolué vers le quatre temps pour raisons écologiques, de très nombreux DT de toutes puissance servent encore au quotidien. Leur seul défaut connu , pour les versions à carburateur est d'être assez gourmands en carburant. 

Certains moteurs 2 temps ont bénéficié d'un système d'injection, plus sobre, notamment le DT 140 , extrapolé du DT 115 à carburateurs (4 cylindres en ligne) et le DT 150 (4 cylindres en V) les couleurs de présentation on varié avec les années millésimes (blanc et orange pour les premiers modèles des années 1970, puis gris métallisé , marron métallisé et finalement noir et rouge .

Les moteurs 4 temps sont référencés DF (F comme four, quatre en anglais) suivi du chiffre de puissance en cv (chevaux vapeur).

Ils sont de couleur noire ou blanc (Suzuki a fourni des moteurs commercialisés aux USA et en Europe sous la marque Johnson, exactement semblables mais peints en blanc).

Les moteurs 4T Suzuki sont plus lourds et complexes que les 2 temps équivalents en puissance , mais ils sont plus économes en carburant et moins polluants.

Les gros 4T Suzuki ont un système original de double réduction de la transmission par un engrenage entre le bloc moteur et l 'arbre vertical qui améliore la poussée et l'équilibrage de la tête motrice. 

Jusqu'à 175 cv, il s'agit de moteurs en ligne, à 1, 2 ou 4 cylindres en ligne et de moteurs V 6 pour les puissances supérieures .



</doc>
<doc id="2884" url="https://fr.wikipedia.org/wiki?curid=2884" title="Système expert">
Système expert

Un système expert est un outil capable de reproduire les mécanismes cognitifs d'un expert, dans un domaine particulier. Il s'agit de l'une des voies tentant d'aboutir à l'intelligence artificielle.

Plus précisément, un système expert est un logiciel capable de répondre à des questions, en effectuant un raisonnement à partir de faits et de règles connues. Il peut servir notamment comme outil d'aide à la décision. Le premier système expert est DENDRAL. Il permettait d'identifier les constituants chimiques.

Un système expert se compose de 3 parties :

Le moteur d'inférence est capable d'utiliser faits et règles pour produire de nouveaux faits, jusqu'à parvenir à la réponse à la question experte posée.

La plupart des systèmes experts existants reposent sur des mécanismes de logique formelle (logique aristotélicienne) et utilisent le raisonnement déductif. Pour l'essentiel, ils utilisent la règle d'inférence suivante (syllogisme) :

Les plus simples des systèmes experts s'appuient sur la logique des propositions (dite aussi « "logique d'ordre 0" »). Dans cette logique, on n'utilise que des propositions, qui sont vraies, ou fausses. D'autres systèmes s'appuient sur la logique des prédicats du premier ordre (dite aussi « "logique d'ordre 1" »), que des algorithmes permettent de manipuler aisément.

Il faut maintenir une certaine cohérence de l'ensemble des règles:

Enfin, pour faciliter la description de problèmes réels sous forme de règles logiques, on a recours à des opérateurs ou des valeurs supplémentaires (notions de nécessité/possibilité, coefficients de plausibilité, etc.).

Il existe de nombreux types de moteurs, capables de traiter différentes formes de règles logiques pour déduire de nouveaux faits à partir de la base de connaissance.

On distingue souvent trois catégories, basées sur la manière dont les problèmes sont résolus :

Si les algorithmes de manipulation de faits et de règles sont nombreux et connus, la détermination de l'ensemble des faits et règles qui vont composer la base de connaissances est un problème délicat. Comment décrire le comportement d'un expert face à un problème particulier, et sa manière de le résoudre, là est la question. Car ce que l'on souhaite obtenir n'est ni plus ni moins que l'expérience, la connaissance pratique de l'expert, et non la théorie que l'on peut trouver dans les livres ni exclusivement les règles logiques d'inférence. Equivalents des méthodes d'analyse de l'informatique traditionnelle, des méthodes d'acquisition des connaissances sont développées.

Les systèmes d'apprentissage automatique constituent une voie nouvelle d'acquisition des connaissances.

L'intelligence artificielle permettra peut-être de résoudre le problème de la complexité, mais avec le risque d'une perte de contrôle des systèmes dits "intelligents" .

Le premier système expert fut "Dendral" en 1965, créé par les informaticiens Edward Feigenbaum, Bruce Buchanan, le médecin Joshua Lederberg et le chimiste Carl Djerassi. Il permettait d'identifier les constituants chimiques d'un matériau à partir de spectrométrie de masse et de résonance magnétique nucléaire, mais ses règles étaient mélangées au moteur. Il fut par la suite modifié pour en extraire le moteur de système expert nommé "Meta-Dendral".

En 1972-73 fut créé , un système expert de diagnostic de maladies du sang et de prescription de médicaments, avec un vrai moteur et une vraie base de règles. Ses règles étaient affectées de coefficients de vraisemblance affectant chacune d'entre elles d'un poids relatif aux autres. Le moteur produisait un chaînage avant simple tout en calculant les probabilités (au sens bayésien) de chaque déduction, ce qui rendait difficile d'expliquer la logique de son fonctionnement et encore plus d'en détecter les contradictions. Quant aux experts, ils étaient obligés de trouver des poids de vraisemblance pour chacune de leurs inférences, démarche complexe, peu naturelle et éloignée de leur mode de raisonnement, en tout cas conscient.

Opérationnel dans les années 1990 le projet "Sachem" (Système d'Aide à la Conduite des Hauts fourneaux En Marche, chez Arcelor) était conçu pour piloter des hauts-fourneaux en analysant les données fournies en temps réel par un millier de capteurs. Le projet a couté entre 1991 et 1998 environ 30 millions d'euros, et le système économise environ 1,7 euros par tonne de métal.

Les systèmes experts sont courants, notamment dans la finance et le secteur médical .

Parmi les systèmes grand public, on peut citer "."




</doc>
<doc id="2885" url="https://fr.wikipedia.org/wiki?curid=2885" title="Saint-André-de-Cubzac">
Saint-André-de-Cubzac

Saint-André-de-Cubzac est une commune du Sud-Ouest de la France, située dans le département de la Gironde, en région Nouvelle-Aquitaine.

Commune de l'aire urbaine de Bordeaux située sur la rive droite de la Dordogne, lieu renommé pour son carrefour routier important et les ponts (le pont routier de Cubzac, le pont ferroviaire de Cubzac et le pont autoroutier de Cubzac) qui franchissent la Dordogne et qui sont les seuls passages routier et ferroviaire entre l'estuaire de la Gironde et Libourne. Ces ponts sont toutefois plus au sud, dans la commune voisine de Cubzac-les-Ponts.

Située au nord de Bordeaux, Saint-André-de-Cubzac est le carrefour entre la RN 10 d'Hendaye à Paris entre Bordeaux et Angoulême et l'ancienne RN 137 de Saint-André-de-Cubzac à Saint-Malo, aujourd'hui route départementale, longe l'autoroute A10 qui va vers Paris et se dirige vers Saintes. Autrefois rond-point entre la RN 10 et la RN 137, le carrefour entre l'A10 et la RN 10 est maintenant une jonction autoroutière.

La route départementale part du centre-ville et de ce carrefour pour aller vers l'est à Libourne.

La route départementale part du centre-ville et longe la rive droite de la Dordogne pour aller vers Bourg puis Blaye par l'estuaire. C'est le début de la "Route touristique de la corniche".

Le nom de la commune est "Sant Andrieu de Cubzac" en gascon.

La commune compte quelques vestiges préhistoriques et protohistoriques et plusieurs villas gallo-romaines qui témoignent de l’ancrage d’un habitat ancien qui s’est fixé dans cette zone dès la période antique.

La période médiévale est surtout marquée par l’importance notable de la forteresse royale de Cubzac, construite en 1249 par Simon V de Montfort sur les bords de la Dordogne. Son plan en bastide prévoyait un fonctionnement qui reposait principalement sur l’auto-suffisance et l’autarcie, essentiel pour une place forte. Cependant, la proche petite ville de Saint-André avait été dotée par l’abbaye de la Sauve, dès la fin du , d’un prieuré. Il était le centre d'une mise en valeur des sols, l'habitat était déjà conçu comme une petite sauveté, et s'organisait avec des rues tracées à partir des deux premiers axes antiques, le cardo (axe nord-sud) et le decumanus (axe est-ouest). C’est au croisement même de ces deux voies qu’avait été érigée la première église Saint-André, agrandie depuis, et un peu plus haut dans le bourg une autre, plus modeste, l’église Saint-Étienne. Saint-André a toujours fondé son développement sur l’ouverture à l’économie locale et au commerce : dotée d’un marché important dès le , la ville s’ancrait fermement dans les échanges sur toute la rive droite de la Dordogne, voire avec l’Entre-deux-Mers. Elle apparaît comme un carrefour commercial dès la fin du  et, à partir de là, elle ne cessera plus de prospérer, notamment avec le commerce de ses vins.

En 1341, Édouard III d’Angleterre érigea la terre du Cubzaguais en châtellenie et la donna à Bérard III d’Albret, en raison de services rendus. Un peu plus d’un siècle plus tard, après la victoire de Castillon en 1453, les places anglaises revenaient à la France et Cubzac –dont la vocation à l’origine était principalement militaire– n’avait plus véritablement de raison d’exister. Suite à ce déclin, le siège de la châtellenie se déplaçait du château de Cubzac à la maison noble du Bouilh, qui donnait à la région une impulsion nouvelle, à dominante clairement économique. Elle  devint si prospère que le puissant voisin, le marquis de Fronsac, chercha plus tard à l’acquérir, en vain.

Les guerres de religion ont sévi dans cette zone. Au cours de la période de la Convention nationale (1792-1795), la commune a adopté le nom révolutionnaire de "Montalon".

Les archives départementales de la Gironde, notamment les terriers, présentent certains plans, parcellaires et croquis divers de lieux-dits, d’habitats et de routes du territoire de ce qui deviendra l’actuel Saint-André-de-Cubzac. Des plans originaux, inconnus jusqu'alors, levés par le célèbre et méticuleux géographe Claude Masse et colorés à la main, ont été découverts il y a quelques années ; ils se sont avérés être les plus fidèles et les plus anciens à ce jour et ils apportent beaucoup. Leur précision permet d'observer l’emplacement de monuments aujourd’hui disparus en partie (cloître des Cordeliers) ou totalement (église Saint-Étienne, anciens cimetières), et prouve que le clocher carré de l’église, en 1723, portait déjà une horloge, ce qui était rare au début du . Ces mêmes plans, très détaillés, permettent entre autres de comprendre les routes, les accès à la Dordogne, l’ancienne bastide de Cubzac et donnent une bonne indication de la mise en valeur du territoire. Pour la première fois il est possible d'examiner un relevé précis -et remarquable par sa rareté- de ce qu’était en 1723 l'ancienne maison forte du Bouilh (dont on sait qu'elle se trouvait sur une maison forte érigée dès 1331), ses jardins et ses dépendances agricoles avant qu’elle ne soit en très grande partie rasée vers 1780 et que les grands travaux de 1785-1790 n’en fassent l’édifice (château du Bouilh) que l’on connaît aujourd’hui. Les plans en couleur les plus importants, en raison de leur intérêt, ont été repris et publiés dans un ouvrage consacré à l'étude d'ensemble de Cubzac et de sa région.

Un certain nombre d'érudits locaux et d'historiens se sont penchés, depuis plusieurs années déjà, sur l’histoire plus récente de Saint-André-de-Cubzac, y compris par l’examen des cartes postales anciennes qui témoignent, dans le début du , d’une ville en plein essor et en activité. Le cœur de la ville était alors symbolisé par une magnifique halle de pierre, construite vers 1780 par Jean de La Tour Gouvernet, lieutenant-général de la région, halle malheureusement démolie depuis. L'ancien petit port de Plagne, qui a connu un certain succès grâce à la pêche et au transport de marchandises a subi de plein fouet la concurrence des moyens de transports modernes. Il connaît depuis quelques années un certain renouveau en raison, entre autres, de la navigation de plaisance.

Depuis quelques années, Saint-André-de-Cubzac, qui avait fréquemment eu peine à trouver sa voie entre ses deux grandes « rivales », Bourg-sur-Gironde à l’ouest et Libourne à l’est, ne semble qu'avec difficulté être parvenue à s’adapter à la période contemporaine dominée par une société de consommation et d’échanges, qui ne cesse de monter en puissance. Son centre historique est traversé par la rue Nationale qui a toujours constitué une sorte de poumon économique, où s’étaient fixés, parfois depuis longtemps, des commerces de proximité. Depuis l’étirement de la ville plus au nord, en direction de "la Garosse", cette rue principale (cardo), dans sa partie basse et dans le centre de la vieille ville, a été transformée en voie à sens unique dotée d’une piste cyclable presque aussi large que la chaussée. En quelques années il semble que les nombreux commerces de proximité qui s’y trouvaient se déplacent ou disparaissent des anciens axes routiers, dont il convient de reconnaître qu'ils sont peu pratiques à la circulation automobile contemporaine alors que se créent, loin du cœur historique de la ville, des zones commerciales. 

Les habitants sont appelés les "Cubzaguais".

La population de la commune est relativement jeune. Le taux de personnes d'un âge supérieur à 60 ans (20,2 %) est en effet inférieur au taux national (21,6 %) et au taux départemental (21,4 %).
À l'instar des répartitions nationale et départementale, la population féminine de la commune est supérieure à la population masculine. Le taux (51,9 %) est du même ordre de grandeur que le taux national (51,6 %).

La répartition de la population de la commune par tranches d'âge est, en 2007, la suivante :







</doc>
<doc id="2890" url="https://fr.wikipedia.org/wiki?curid=2890" title="Sothis">
Sothis

Sopdet (ou Sôpdit) est une déesse égyptienne, son nom en grec est Sothis.

Personnification divine de l'étoile Sirius (l'étoile du Chien en grec), elle symbolise l'arrivée de la crue annuelle du Nil qui coïncidait autrefois avec l'apparition de l'étoile au début du mois de juillet (le "lever héliaque" - en août à l'époque actuelle du fait de la précession des équinoxes). Cette crue annuelle étant indispensable pour fertiliser les terres arides des rives du Nil (par l'apport en eau et en limon), Sothis a été naturellement associée à la fertilité et à la prospérité à partir de la .

Elle avait deux apparences, celle d'une femme ou celle d'une vache, toutes les deux portant une étoile sur la tête et entre les cornes. La crue du Nil était liée à la symbolique du fleuve nourricier, tel le lait de la vache qui nourrit aussi les hommes. C'est pourquoi Sopdet est illustrée soit par une vache, soit par une femme.

Sopdet est représentée en général avec une étoile au-dessus de la tête. Cette étoile est la plus lumineuse du ciel, seulement dépassée en luminosité par les planètes principales (Vénus, Mars, Jupiter et Saturne).

Sopdet a été associée au culte de la déesse Neith comme le précise Françoise Dunand dans son livre "Le Culte d'Isis dans le bassin oriental de la Méditerranée: le Culte d'Isis" publié en 1973. C'est ainsi que les Grecs se sont inspirés de la déesse Neith (et la forme de sa constellation) et l'ont remplacée par Artémis, la Diane romaine qui, comme la déesse égyptienne, arbore un arc, mais a en plus un compagnon: un chien.

Les Grecs ont transposé leur mythologie sur celle de l’Égypte antique. Il faut attendre le pour que Claude Ptolémée publie son "Almageste" dans lequel on découvre pour la première fois le nom de Sirius et la forme d'un chien.

Entre-temps avait eu lieu la précession des équinoxes; de fait, les constellations vues de la Terre s'étaient décalées. Le ciel grec n’étant plus comparable au ciel égyptien du fait du basculement de l'axe oblique de la Terre, Claude Ptolémée a jugé nécessaire de l'adapter à son époque. C'est ainsi qu'il a a remplacé la déesse Neith l'archère par un chien. C'est ce chien que, depuis, on appelle Sirius.

L’émergence du christianisme a fait disparaître un certain nombre de déesses du ciel dont Artémis-Diane, c'est pourquoi les Anciens se contentèrent du compagnon canin de leur déesse pour représenter la constellation Canis Major.

Il est donc nécessaire d'éviter l'anachronisme entre deux époques différentes et la confusion entre deux cultures différentes. Sopdet, puis Isis n'ont jamais été représentées sous la forme d'un chien à l'époque de l'ancienne Égypte.

La constellation de la vache Sopdet et la constellation de Neith l'archère étaient très voisines, les Anciens en firent une seule et même constellation, qu'ils nommèrent Canis Major, avec pour étoile principale Sirius.

Paradoxalement l'étoile Sirius était présente pendant les périodes de grande chaleur qui étaient connues comme périodes d'épidémies. Le Nil débordant était, certes, une bonne chose pour la fertilité et l'agriculture, il mais était aussi très destructeur et a provoqué de nombreuses maladies pour le peuple habitant ses bords.


</doc>
<doc id="2891" url="https://fr.wikipedia.org/wiki?curid=2891" title="Sommet de la Terre">
Sommet de la Terre

Les Sommets de la Terre sont des rencontres décennales entre dirigeants mondiaux organisées depuis 1972 par l'ONU, avec pour but de définir les moyens de stimuler le développement durable au niveau mondial. Le premier sommet a eu lieu à Stockholm (Suède) en 1972, le deuxième à Nairobi (Kenya) en 1982, le troisième à Rio de Janeiro (Brésil) en 1992, et le quatrième à Johannesburg (Afrique du Sud) en 2002. Le dernier Sommet de la Terre, appelé Rio+20, a également eu lieu à Rio de Janeiro en 2012.

Preuve du développement d'une culture mondiale de respect de l'environnement, les sommets de la Terre présentent un enjeu symbolique important. Ils visent à démontrer la capacité collective à gérer les problèmes planétaires et affirment la nécessité du respect des contraintes écologiques. Le sommet de 1972 a donné naissance au Programme des Nations unies pour l'environnement (PNUE), tandis que le sommet de 1992 a lancé la Convention-cadre des Nations unies sur les changements climatiques (CCNUCC) dont les pays signataires se rencontrent annuellement depuis 1995. 

L'entrée en vigueur d'un traité international prend généralement plusieurs années. Il s'agit d'un processus complexe, car chaque pays doit compléter deux étapes pour y adhérer. La première étape consiste à signer le traité. La seconde consiste à le ratifier formellement. Le traité n'entre en vigueur que lorsqu'un nombre suffisant de pays l'ont ratifié (nombre variable d'un traité à l'autre).

Les pays signataires de ce type de traité organisent, une fois par an en général, une conférence des parties (CP, ou COP en anglais). Avant chaque conférence est organisée une réunion préparatoire appelée SBSTTA (Organe subsidiaire chargé de fournir des avis scientifiques, techniques et technologiques) où les gouvernements négocient les détails techniques du traité. Le processus est similaire pour le sommet de la Terre, lequel comporte une série de conférences préparatoires préalables.

La conférence des Nations unies sur l'environnement humain (CNUEH) s'est tenue du 5 au 16 juin 1972 à Stockholm (Suède). Elle a placé pour la première fois les questions écologiques au rang de préoccupations internationales. Les participants ont adopté une déclaration de 26 principes et un vaste plan d'action pour lutter contre la pollution, dont une délégation des victimes de la maladie de Minamata a été témoin. Ce sommet a donné naissance au Programme des Nations unies pour l'environnement (PNUE). Au même moment, le Club de Rome a publié un rapport intitulé « Halte à la croissance ? ».

À cette époque, les dirigeants mondiaux se sont engagés à se rencontrer tous les dix ans pour faire le point sur l'état de la Terre. A posteriori, cette conférence a parfois été qualifiée de Sommet de la Terre.

Un Sommet de la Terre s'est tenu à Nairobi (Kenya) du 10 au 18 mai 1982. Les événements de l'époque (Guerre froide) et le désintérêt du président des États-Unis, Ronald Reagan (qui a nommé sa fille déléguée des États-Unis) ont fait de ce sommet un échec. Il n'est d'ailleurs même pas évoqué comme un sommet de la Terre officiel.

Ce Sommet de la Terre s'est tenu à Rio de Janeiro du 3 juin au 14 juin 1992, sous l'égide de l'Organisation des Nations unies. Cette Conférence des Nations unies sur l'environnement et le développement (CNUED) est généralement considérée comme une réussite : les priorités mondiales ont changé en dix ans, et avec la participation d'une centaine de chefs d'État et de gouvernement très diversifié, ce sommet demeure aujourd'hui le plus grand rassemblement de dirigeants mondiaux. Plus de ONG étaient également représentées.

Le Sommet de Rio s'est conclu par la signature de la Déclaration de Rio. Cette déclaration, qui fixe les lignes d'action visant à assurer une meilleure gestion de la planète, fait progresser le concept des droits et des responsabilités des pays dans le domaine de l'environnement. Cependant, elle n'est pas juridiquement contraignante. Au contraire, elle reconnaît la souveraineté des États à « exploiter leurs propres ressources selon leur politique d'environnement et de développement ».

Par ailleurs, le Sommet de Rio a conduit à l'adoption du programme Action 21, qui comprend environ recommandations (dont la plupart n'ont jamais été mises en œuvre), la Déclaration sur la gestion, la conservation et le développement durable des forêts et la gestion durable des forêts, de même que les trois conventions de Rio :

Il a donné le coup d'envoi à un programme ambitieux de lutte mondiale contre les changements climatiques, l'érosion de la biodiversité, la désertification, et l'élimination des produits toxiques. Bien que ces conventions soient perfectibles, elles ont engagé les États dans un effort de mise en œuvre et, dans certains cas, dans un processus de négociations en vue de parvenir à l'adoption de protocoles contraignants, tel que le Protocole de Kyoto.

Ce sommet s'est tenu du 26 août au 4 septembre 2002 à Johannesburg (Afrique du Sud) sous l'égide des Nations unies. Il est aussi officiellement appelé « Sommet mondial sur le développement durable » (SMDD). Ce sommet constituait une occasion pour le monde entier de faire le bilan et de compléter le programme lancé lors du Sommet de Rio ; il était axé autour du développement durable.

La rencontre de Johannesburg visait donc à inciter les États à réitérer leur engagement politique en faveur du développement durable, ainsi qu'à favoriser le renforcement d'un partenariat entre le Nord et le Sud. L'événement a rassemblé une centaine de chefs d'État et quelque délégués, ce qui en a fait la plus grande rencontre jamais organisée par les Nations unies.

Le sommet a adopté un plan d'action en 153 articles, décomposés en 615 alinéas sur de nombreux sujets : pauvreté, consommation, ressources naturelles, globalisation, respect des Droits de l'homme... Les thèmes prioritaires étaient :
L'enjeu politique du Sommet fut également important puisqu'il s'agissait de démontrer que la guerre contre le terrorisme n'est pas l'unique problème mondial actuel.

Vingt ans après le Sommet de Rio de 1992, la Conférence des Nations unies sur le développement durable (CNUDD), mieux connue sous le nom de Rio+20, a eu lieu du 20 au 22 juin 2012 à Rio de Janeiro, au Brésil. Avant cet événement, un premier comité préparatoire (PrepCom-1) s'était tenu à New York (États-Unis), du 17 au 19 mai 2010 et un second du 7 et 8 mars 2011. Un troisième et dernier Comité préparatoire a eu lieu du 13 au 15 juin 2012 à Rio de Janeiro (Brésil) mais, comme on s'y attendait, il n'a pas permis de conclure la négociation du "zero draft", de sorte que les négociations se sont poursuivies de manière informelle, sous l'égide du gouvernement brésilien, pendant les quatre jours qui séparaient cette réunion de l'arrivée des chefs d'État et de gouvernement. Même si Rio +20 devait porter sur « l'économie verte » et « le cadre institutionnel du développement durable », des divergences ont rapidement émergé sur ces deux thèmes, de sorte que le principal résultat de ce « Sommet de la Terre » est plutôt le lancement d'un processus devant conduire à l’établissement d’Objectifs du développement durable (ODD).




</doc>
<doc id="2894" url="https://fr.wikipedia.org/wiki?curid=2894" title="Strasbourg">
Strasbourg

Strasbourg ( ) est une commune française située dans le département du Bas-Rhin. Préfecture du département, elle est également, depuis le janvier 2016, le chef-lieu de la région Grand Est. Strasbourg se trouve dans la région historique d'Alsace, dont elle est considérée comme la capitale, et était le chef-lieu de la région administrative du même nom de 1982 à 2015.

La ville accueille de multiples institutions européennes et internationales, notamment le Conseil de l'Europe dont dépendent la Cour européenne des droits de l'homme et la Pharmacopée européenne, le Parlement européen ou encore le Médiateur européen. Elle revendique ainsi le titre de « capitale européenne ».

Par sa population, Strasbourg "" est la première commune du Grand Est français et la huitième de France. Son aire urbaine est la neuvième de France, comptant en 2012 dans sa partie française. Ses habitants sont appelés les "Strasbourgeois". Elle est l'un des principaux pôles économiques du nord-est et se distingue par un secteur secondaire très diversifié et un secteur tertiaire essentiellement tourné vers les activités financières, la recherche et le conseil aux entreprises.

Ville frontière avec l'Allemagne, Strasbourg a été marquée par les différentes administrations germaniques et françaises. Son histoire, riche et tourmentée, a laissé un patrimoine architectural remarquable. Son centre-ville, situé sur la Grande Île, est entièrement inscrit au patrimoine mondial de l'humanité par l’UNESCO depuis 1988 et comprend notamment la cathédrale Notre-Dame de Strasbourg et le quartier de la Petite France. En 2017, le périmètre classé est étendu à une partie de la "Neustadt", quartier construit par les autorités allemandes à partir de 1880.

Strasbourg est également devenue le symbole de la réconciliation franco-allemande et plus généralement de la construction européenne. La ville s’est progressivement spécialisée dans les fonctions politiques, culturelles, et institutionnelles. Elle est ainsi l’une des seules villes au monde à être le siège d'organisations internationales sans être capitale d’un pays. Strasbourg est une ville de congrès internationaux, la deuxième de France après Paris.

La présence de plusieurs établissements nationaux renommés, comme le théâtre national, la bibliothèque nationale et universitaire et l’Opéra national du Rhin en fait un centre culturel important.

Strasbourg est aussi une grande ville étudiante, son université, ses grandes écoles et son hôpital universitaire forment un pôle universitaire majeur tourné vers l’international avec plus de 20 % d'étudiants étrangers et plus de cent nationalités représentées. L'université qui a accueilli 18 prix Nobel dans ses murs, a été lauréate de nombreux appels d'offres dans le cadre des investissements d'avenir, visant à en faire un pôle d'excellence dans l'enseignement supérieur et la recherche au niveau mondial.

Excentrée par rapport au reste de la France, dont la plaine d'Alsace représente l'extrême façade nord-est, Strasbourg occupe en revanche une position centrale en Europe occidentale, sur une importante voie de passage nord-sud. Il faut en effet la replacer dans l'entité plus vaste dont elle fait partie de la vallée du Rhin supérieur qui, de Bâle à Mayence, forme un couloir naturel.

À la limite de l'Europe atlantique et de l'Europe continentale, elle communique au sud par les vallées de la Saône et du Rhône avec l'Europe méditerranéenne et s'ouvre au nord, au-delà des massifs hercyniens allemands, sur les grandes plaines de l'Europe du Nord jusqu'à la vallée de la Ruhr. À vol d'oiseau, Strasbourg se trouve ainsi à égale distance (environ ) de la Baltique et du littoral atlantique. Elle se situe aussi à égale distance (environ ) de la Méditerranée, de la mer du Nord et de l'Adriatique.

Strasbourg est distante de de Stuttgart, de de Zurich, de de Luxembourg, de de Francfort-sur-le-Main, de de Marseille, de de Toulouse, de de Bruxelles, de de Lyon, et de de Paris (distance orthodromique). La ville est par ailleurs située à du massif des Vosges à l'ouest, à une trentaine de la Forêt-Noire à l'est et à du massif du Jura.

Strasbourg étant située à l'intérieur des terres, le climat qui y règne est de type semi-continental ("Cfb" selon la classification de Köppen). Les températures peuvent être très contrastées entre les saisons (caractéristique du climat continental). Ainsi, les hivers sont froids, voire rigoureux (la température moyenne est de et peut descendre par moment à ) avec souvent de la neige. La ville est la plus concernée par la neige en France à basse altitude (inférieure à ) Les étés, quant à eux, sont chauds, voire étouffants (la température moyenne est de et peut atteindre par moments ). L'amplitude thermique est importante entre ces 2 saisons.

En hiver, entre le mois de décembre et le mois de mars, l'ensoleillement est très dérisoire sur la ville. En grande majorité, il y a de nombreuses journées avec du brouillard et de la bruine, qui peuvent perdurer. La ville ne bénéficie pas d'un ensoleillement conséquent et se classe sous la moyenne nationale en cumul d'heures annuel et au-dessus de la moyenne nationale en journées avec du brouillard.

L'été est, quant à lui, relativement chaud bien que des orages sont fréquents, en particulier lors de journées avec des fortes chaleurs. Des chaleurs précoces peuvent se produire dès le mois de mai.

Située dans une cuvette entre deux massifs montagneux (les Vosges et la Forêt-Noire) la ville est peu exposée aux vents. De même, les précipitations sont relativement faibles et irrégulières comparées aux autres régions françaises grâce à la protection naturelle contre les vents d'ouest dominants que constituent les Vosges (effet de foehn). Le cumul annuel de pluie à Strasbourg est de contre 733 pour Nice et pour Brest, ce qui la situe sous la moyenne nationale de par an. La ville est souvent sujette à de violents orages, surtout à la fin du printemps et en été. Avec 29 jours d'orage par an, c'est une des villes de France avec le plus d'orages (moyenne nationale : 22 j/an).

L'absence récurrente de vent, les températures élevées en été ainsi que la situation géographique favorisent régulièrement l'apparition de pics de pollution et d'orages.

À la station de l'aéroport de Strasbourg-Entzheim, le record absolu de froid est de (23 janvier 1942) et le record absolu de chaleur est de (7 août 2015).

Située à une altitude moyenne de au-dessus du niveau de la mer, Strasbourg est caractérisée par un relief relativement plat. Ainsi au centre-ville, on ne perçoit que de très légères ondulations du terrain, culminant notamment à proximité de la cathédrale et à la croisée de la Grand'Rue et de la rue du Fossé-des-Tanneurs, correspondant aux zones d'habitation les plus anciennes, établies à l'origine sur une butte émergeant des marais environnants.
La ville est construite sur l'Ill ainsi que le long de la rive gauche du Rhin. L'Ill est la colonne vertébrale de la ville, reliée au Rhin par des anciens bras désormais canalisés (le canal de jonction et différents bassins portuaires). Plusieurs affluents traversent les différents quartiers de la ville : la Bruche et le canal de la Bruche à la Montagne Verte et à Koenigshoffen, l'Aar au Contades et au Wacken, le Krimmeri et le Ziegelwasser (anciens bras du Rhin) à la Meinau, au Neuhof et au Neudorf, le canal de la Marne au Rhin au nord. Ainsi Strasbourg est constituée de plusieurs îles dont l'ellipse insulaire du centre historique, l'île Sainte-Hélène dans le quartier du Contades, l'île aux Épis et l'île du "Rohrschollen" dans le quartier du Port du Rhin.

La ville est par ailleurs située sur l'une des plus grandes réserves d'eau potable d'Europe (près de 35 milliards de m). La densité importante de l'hydrographie cumulée à l'affleurement de la nappe phréatique contribue à rendre le secteur très sensible aux inondations. C'est pourquoi la plupart des extensions urbaines de la ville puis de l'agglomération se sont faites au moyen de remblais importants (notamment pour la construction du quartier allemand), accompagnées du comblement ou de la canalisation des multiples bras d'eau, réduisant d'autant les surfaces d'épandage et augmentant la rapidité et le débit des eaux en cas de crue.

Strasbourg est aujourd'hui confrontée à un risque d'inondation important dans certains quartiers (Montagne Verte au sud-ouest et Robertsau au nord) qui pèse sur les projets d'extension urbaine et de densification de l'habitat.

Dès l'origine, Strasbourg doit son nom à sa position — « à la croisée des chemins ». Encore aujourd'hui, la ville bénéficie d'une situation géographique privilégiée qui en fait un important carrefour européen, à l'intersection de quelques-uns des principaux axes de communication du continent.

Strasbourg se dote d'un premier réseau de tramway en 1878. À son apogée, en 1937, celui-ci comptait près de de lignes urbaines tandis que le réseau suburbain était composé d'une centaine de kilomètres de lignes dans le Bas-Rhin. Au lendemain de la Seconde Guerre mondiale, le tramway entre dans une période de déclin et les dernières lignes sont définitivement fermées en 1960.

Le réseau moderne du tramway, exploité par la Compagnie des transports strasbourgeois (CTS), est aujourd'hui le deuxième plus étendu de France (derrière celui de Lyon), avec près de et de lignes. Le maillage du réseau permet d'utiliser un tronçon pour plusieurs lignes. La capacité de transport est de par jour.

La première ligne du tramway moderne fut inaugurée le 25 novembre 1994. Depuis cette date, le réseau n'a cessé de se développer et compte actuellement six lignes en service : A, B, C, D, E et F. Les dernières extensions sont réalisées en 2016 et 2017. Le 23 avril 2016, la est étendue de vers le centre d'Illkirch-Graffenstaden ; le même jour, la est prolongée jusqu'au Campus d'Illkirch (en utilisant l’infrastructure déjà existante et de voies nouvelles). Le 28 avril 2017, la est prolongée de jusqu'à la gare de Kehl en Allemagne.

Une extension de la jusqu'au centre socio-culturel l'Escale, au cœur du quartier de la Robertsau, verra le jour au deuxième semestre 2019. Enfin, une extension de la vers le quartier de Koenigshoffen est prévue pour 2020.

Par ailleurs, le projet de tram-train devant relier Strasbourg à Gresswiller et Barr est abandonné fin 2012.

Une ligne de bus à haut niveau de service, reliant la gare centrale à l'Espace Européen de l'Entreprise à Schiltigheim, est mise en service le 30 novembre 2013. Elle est complémentaire du réseau de tramway et prend ainsi la désignation de .

Un réseau de bus, également exploité par la CTS, dessert l'ensemble de l'agglomération strasbourgeoise. Avec ses de lignes, il offre un maillage dense sur l'ensemble du territoire de l'Eurométropole de Strasbourg. Réorganisé avec l'arrivée du tramway et autour de celui-ci, il compte aujourd'hui et . Les lignes de bus portent un numéro pour les distinguer des lignes de tram et du BHNS, ces dernières étant désignées par une lettre.

L'ensemble du réseau de la CTS (tram, bus et BHNS) transporte annuellement , tout en parcourant .

La ville compte également deux gares routières : place des Halles pour le trafic départemental () et place de l'Étoile pour les lignes nationales et internationales.

Strasbourg se situe sur un axe est-ouest qui la relie d'une part à Paris "via" Reims et Nancy/Metz (autoroute A4/RN4) et d'autre part à Munich "via" Stuttgart (E52). La ville est également placée sur un axe nord-sud qui la relie d'une part au sud de la France "via" Lyon (autoroute A6, autoroute A7) et d'autre part à Francfort-sur-le-Main "via" Karlsruhe (E35). Strasbourg est par ailleurs reliée à l'Allemagne par deux ponts : le pont de l'Europe, situé à l'est de la ville et le pont Pierre-Pflimlin, situé dans l'agglomération sud et qui permet une meilleure desserte des villes d'Offenbourg et de Fribourg.

Du fait de la conception des autoroutes - comme étant à la fois des voies de transit et des voies de desserte des grandes agglomérations - qui prévalait dans les années 1970 et 1980, Strasbourg voit son agglomération traversée par des voies autoroutières portées aujourd'hui à deux fois trois voies (deux fois quatre voies sur un court tronçon prolongeant un tronçon surélevé condamné à rester en deux fois deux voies), et ce à moins d'un kilomètre du centre-ville. Il en résulte de fortes nuisances dans certains quartiers (Gare, Cronenbourg). L'autoroute A35, avec environ par jour à hauteur de Cronenbourg, est en effet la plus saturée de France après le périphérique parisien. Entre 1990 et 2000, le trafic a en outre augmenté de 40 %.

Le projet de construction d'une nouvelle autoroute de deux fois deux voies (Autoroute A355), dite grand contournement ouest (GCO) de Strasbourg est évoqué depuis les années 1970. Il a pour objectif de capter le trafic de transit nord-sud et de délester la rocade ouest. Il permettra une réduction de la pollution et des nuisances sonores à proximité de la ville grâce à la requalification de l'A35 en boulevard urbain. Le tracé, de , prévoit de relier l'échangeur de Hœrdt au nord, à Innenheim au sud. Les travaux devraient démarrer en août 2018 pour une mise en service en 2020. Cependant, le projet a de nombreux opposants qui craignent un effet d´aspirateur du trafic nord-sud européen et un accroissement des nuisances.

La gare de Strasbourg-Ville, aussi appelée "gare centrale", est le centre d'une importante étoile ferroviaire à cinq branches. Elle est le principal pôle d'échanges de l'agglomération. La ville compte également deux haltes ferroviaires voyageurs dédiées au trafic TER, les gares de Krimmeri-Meinau et Strasbourg-Roethig.

Strasbourg est l'une des étapes de la « Magistrale européenne », principal axe ouest-est de l'Europe, de Paris à Budapest (soit le trajet de l'ancien Orient-Express). Le premier tronçon de la LGV Est européenne - reliant la gare de Paris-Est à Baudrecourt en Moselle - a été mis en service le , ramenant le meilleur temps de trajet vers Paris de 4 heures à 2 heures 20. Les travaux du second tronçon - entre Baudrecourt et Vendenheim - ont commencé en juillet 2010, pour une mise en service commerciale le 3 juillet 2016. Le temps de parcours entre Paris et Strasbourg est désormais d'environ 1 heure 50. L'ouverture de la LGV Rhin-Rhône, fin 2011, permet de placer la ville sur un deuxième axe à grande vitesse entre mer du Nord et Méditerranée.

Le trafic de la gare de Strasbourg-Ville était d'environ passagers par jour en 2006, mais l'arrivée des TGV Est puis Rhin-Rhône et le développement des TER portent ce nombre à passagers en 2012 et par jour en 2015. La gare accueille un total de 550 trains dont environ 50 TGV par jour.

Les autres gares voyageurs de l'Eurométropole sont les gares de Bischheim, Entzheim-Aéroport, Fegersheim - Lipsheim, Geispolsheim, Graffenstaden, Hœnheim, Lingolsheim, Mundolsheim, Vendenheim et La Wantzenau. Par ailleurs, la gare de Kehl (en Allemagne) est située sur la ligne d'Appenweier à Kehl, qui relie la ligne de Strasbourg-Ville à Strasbourg-Port-du-Rhin à la ligne de Mannheim à Bâle.

Depuis le 11 décembre 2016, les abonnés de la Compagnie des transports strasbourgeois résidents dans une commune de l'Eurométropole peuvent également utiliser les trains du réseau TER Alsace au sein de l'agglomération.

La gare de Hausbergen, au nord de Strasbourg, est une importante gare de triage. Enfin, la ville dispose de trois gares aux marchandises, les gares de Strasbourg-Cronenbourg, Strasbourg-Neudorf et Strasbourg-Port-du-Rhin.

L'aéroport de Strasbourg-Entzheim, situé à une quinzaine de kilomètres au sud-ouest de la ville, à Entzheim, est le de France par le nombre de passagers en 2009. Son trafic s'était stabilisé depuis 1996, oscillant autour de 2 millions de passagers annuels (avec un pic à 2,2 millions en 1999). La mise en service de la première phase de la LGV Est européenne en juin 2007 et la suppression des vols vers Paris-Charles-de-Gaulle et Paris-Orly ont provoqué une chute du trafic qui oscille aux alentours de 1,1 million de passagers par an au milieu des années 2010. L'aéroport de Strasbourg souffre également de la proximité des aéroports de Bâle-Mulhouse-Fribourg (), de Stuttgart () et de Francfort (). Une cinquantaine de destinations sont desservies, essentiellement en Europe. La gare d'Entzheim-Aéroport permet de relier ce dernier à la gare centrale de la capitale alsacienne et européenne en une dizaine de minutes, à la fréquence d'un train tous les quarts d'heure en période de pointe.

Pour les vols long-courrier, un service de bus réguliers effectue la liaison entre la gare centrale et l'aéroport de Francfort, qui est l'un des principaux hubs européens avec plus de 300 destinations autour du monde.

L'aéroport de Karlsruhe-Baden-Baden, situé à une soixantaine de kilomètres de Strasbourg et accessible en voiture en moins de trois quarts d'heure, fait office d'aéroport « low cost » avec des lignes régulières vers de nombreuses destinations dont plusieurs capitales européennes comme Londres, Berlin, ou encore Vilnius. Cet aéroport est desservi principalement par la compagnie Ryanair.

L'aérodrome du Polygone, située dans le quartier du Neuhof, est utilisé exclusivement pour l'aviation de loisir.

Strasbourg a été fondée sur l'Ill et les activités batelières y ont toujours été très importantes vu la densité du réseau hydrographique. En 2016, on compte visiteurs sur les bateaux-promenades de "Batorama", le service touristique du Port autonome de Strasbourg (PAS). La ville accueille chaque année près de visiteurs grâce au tourisme fluvial.

La ville possède d'importantes installations portuaires sur le Rhin, qui constitue la première voie navigable d'Europe et le premier fleuve commercial du monde. En 1920, le siège de la Commission centrale pour la navigation du Rhin fut transféré de Mannheim à Strasbourg et logée dans l'ancien palais impérial, rebaptisé palais du Rhin. Le Port autonome de Strasbourg est le deuxième port fluvial de France et le quatrième d'Europe (après Duisbourg, Paris et Liège) avec, en 2016, un trafic de 7,54 millions de tonnes de marchandises transbordées et conteneurs. Les principales marchandises qui transitent par le port sont les céréales, les graviers et les produits pétroliers.

Située à la jonction des deux EuroVelo routes EV5 et EV15, Strasbourg possède le premier réseau cyclable de France et l'un des plus importants d'Europe avec de pistes et bandes cyclables en 2017.

Dès 1869, la municipalité strasbourgeoise édite un arrêté sur l'usage du vélo, complété par une réglementation détaillée en 1892. La première piste cyclable de la ville, reliant le cimetière Sainte-Hélène à la place du Faubourg de Pierre, est réalisée en 1930. Un « schéma directeur vélo » est adopté en 1978. Dix ans plus tard, la ville compte de pistes cyclables. D'autres plans d'action en faveur du vélo sont adoptés en 1994 puis en 2010.

Strasbourg est reliée à Rotterdam, au nord, et à Andermatt en Suisse, au sud, par la Véloroute Rhin (EuroVelo 15). Une jonction directe au réseau allemand s'effectue par la passerelle des deux rives empruntée par une piste européenne transfrontalière de près de de long qui relie Molsheim, sur la Route des Vins d'Alsace, à Offenbourg, étape du « Drei Täler Radweg » sur la Route des Vins badoise, en longeant le canal de la Bruche. Une autre piste revêtue de longueur similaire, partie intégrante de l'EV5 (Via Francigena de Londres à Rome/Brindisi), entre dans l'agglomération par le canal de la Marne au Rhin depuis la sortie du tunnel d'Arzviller à proximité du plan incliné de Saint-Louis-Arzviller via Saverne. À Strasbourg, l'EV5 croise l'EV15 (Véloroute Rhin) et quitte la capitale européenne vers l'ouest par le canal de la Bruche pour rejoindre la Véloroute du vignoble d'Alsace à Soultz-les-Bains. Quant à l'EuroVelo 15, elle quitte la ville par le sud sur le chemin de halage du canal du Rhône au Rhin pour rejoindre la Suisse par Bâle.

Le principal itinéraire cyclable de l'agglomération est la "Piste des Forts". Celle-ci propose un parcours de , de part et d'autre du Rhin, permettant de découvrir l'ancienne ceinture de forts construite durant l'annexion de l'Alsace-Lorraine.

La ville s'est dotée d'infrastructures adaptées et compte aujourd'hui plus de . Strasbourg compte également plusieurs parkings à vélos répartis en son centre. Le plus grand d'entre eux, couvert et sécurisé, est situé près de la gare et compte 850 places.

Inauguré le , l'Eurométropole propose un service de location de vélos, le Vélhop. Basé sur la technologie Smoove et géré par la Compagnie des transports strasbourgeois (CTS), il permet de louer une bicyclette pour une courte (heure, journée) ou longue durée (semaine, mois, trimestre, année). Ne permettant pas de trajets occasionnels d'une station à une autre (« "" »), le Vélhop n'est pas un service de vélos en libre-service.

Enfin, la Fédération française des usagers de la bicyclette (FUB), qui fédère plus de 170 associations locales de promotion du vélo en tant que mode de transport au quotidien, s'est implantée à Strasbourg à sa création en 1980.

Le centre historique de Strasbourg, qui occupe la Grande Île, se caractérise par des rues étroites typiquement médiévales, notamment autour de la cathédrale Notre-Dame et dans le quartier de la Petite France. Au nord, le vaste quartier allemand construit entre 1880 et 1914 s'étend de la gare centrale aux portes de l'Allemagne. Il est irrigué par de larges avenues rectilignes qui débouchent sur des zones moins denses, notamment sur le quartier des XV dont les premières constructions remontent au début du . Le sud-est est occupé par le quartier de la Krutenau, l'un des plus anciens de la ville. Un peu plus à l'est se trouve le quartier de l'Esplanade. Construit à partir des années 1960 pour faire face à la poussée démographique, ce quartier est essentiellement composé de grands immeubles (plus de dix étages) ce qui en fait le plus dense de Strasbourg. Ce quartier accueille le campus principal de l'Université de Strasbourg.

Les quartiers centraux sont entourés par la « ceinture verte ». Il s'agit de l'ancienne zone "non aedificandi" qui faisait partie des défenses de la ville. Les constructions y sont limitées à 20 % de surface bâtis au sol (les routes, autoroutes et voies ferrées ne sont cependant pas considérées comme des constructions).

À l'ouest et au nord, les quartiers de Cronenbourg, Koenigshoffen et la Robertsau ont conservé leur aspect d'anciens faubourgs.

Au sud, les habitations de densité moyenne prédominent, comme dans le quartier de Neudorf. Les habitations les plus récentes sont réparties dans l'agglomération, mais aussi au sein de la commune, notamment dans les quartiers sud et sud-est de la ville "Danube", "Rives de l'Étoile" et "Porte de France". Dans les quartiers ouest et sud-ouest, on retrouve la plupart des logements sociaux de la ville construits dans les années 1960 et 1970 : cité Nucléaire à Cronenbourg, Hautepierre, Koenigshoffen, Montagne Verte, Elsau et Neuhof.

La ville compte deux zones industrielles : la plaine des Bouchers au sud-ouest et le Port du Rhin sur toute sa frange est.

Afin d'améliorer la desserte du Port du Rhin et du pont de l'Europe, la route du Rhin (RN4) a été réaménagée en avenue. Elle doit permettre à terme de désengorger le trafic des poids lourds sur cet axe majeur et ainsi contribuer à créer une nouvelle centralité transfrontalière en désenclavant le quartier du Port du Rhin. L'objectif principal étant de paysager l'entrée en France depuis l'Allemagne autour du symbole de la frontière et encourager une plus grande mobilité sur l'axe est-ouest, en sus de l'axe nord-sud. Strasbourg doit reconquérir les berges du Rhin en comblant sur cet axe les vides successifs provoqués par les dépendances et les friches industrielles. De l'habitat plus dense devrait donc apparaître, et connecter durablement Strasbourg aux franges du Rhin.

Strasbourg compte 15 quartiers administratifs. Ces 15 quartiers ont vu le jour en 2013 après que la ville décida d'affiner le découpage des quartiers, qui comportait au départ 10 quartiers calqués sur les cantons de la ville, formant des regroupements de plusieurs véritables quartiers.


L'architecture est une spécificité intéressante de la ville, car elle est profondément biculturelle. Le centre historique regroupe de nombreuses maisons à colombages, notamment dans le quartier de la Petite France, aux abords de l'hôpital civil (quartier du Finkwiller) et de la cathédrale. Ces maisons ont été construites pour la plupart entre le et le ; les plus emblématiques sont la maison Kammerzell et la maison des tanneurs. D'autres courants architecturaux sont représentés par certains bâtiments remarquables : la Renaissance avec le Neue Bau et le Classicisme avec le palais Rohan et l'Aubette. À partir de l'arrivée de Louis XIV, Strasbourg reprend certains codes architecturaux français, notamment la construction d'hôtels particuliers : l'hôtel de Hanau (actuel hôtel de ville, place Broglie), l'hôtel de Deux-Ponts, le palais épiscopal, l'hôtel de Klinglin (actuelle résidence du préfet).

Le grès rose des Vosges est l'une des pierres les plus utilisées, du fait de sa proximité géographique. On le retrouve donc sur de nombreux monuments, et notamment sur la cathédrale. La couleur de cette pierre est cependant très variable. Ainsi, l'église Saint-Paul utilise un grès pâle, tandis que l'Aubette présente une teinte très marquée. Le grès des Vosges est cependant une pierre très friable qui nécessite une attention régulière.

Entre 1880 et 1914, le quartier allemand, dit de la "" (« nouvelle ville » en allemand) est construit. Il forme un ensemble particulièrement homogène à prédominance résidentielle et au style typiquement germanique (wilhelmien). Les architectes allemands reprennent de nombreux codes esthétiques : néo-renaissance pour le palais du Rhin (ancien palais impérial), néo-gothique pour l'hôtel des Postes, néo-classique pour le campus historique ; on note aussi la présence d'immeubles Art nouveau (notamment allée de la Robertsau, à l'intersection des rues Foch et Castelnau ou encore le palais des Fêtes) qui font de Strasbourg l'un des centres de cette architecture (Jugendstil allemand). Strasbourg est aussi la seule ville avec Metz qui a gardé une trace de l'architecture monumentale allemande du à travers la place de la République (palais du Rhin, préfecture, trésorerie générale, bibliothèque nationale et universitaire et théâtre national). Les immeubles résidentiels utilisent généralement la pierre de taille (pour le rez-de-chaussée et les ornements) associée à la brique (rouge ou ocre, pour le reste de la façade). Le grès rose est lui aussi couramment utilisé pour certaines parties.

En 2014, Strasbourg compte bâtiments. La ville possède bâtiments soit 12,4 % du total tandis que l’État en détient 325 soit 1,2 %. Parmi ces bâtiments, 44,6 % appartiennent à des copropriétés, 722 immeubles sont détenus par des SCI, 95 par des compagnies d'assurances et 78 par des banques. L'ensemble de ces bâtiments est estimé à 28 milliards d'euros.

En 2005, la commune de Strasbourg comptait logements. Par rapport à 1999, le nombre de logements a augmenté de 1,9 % alors que le nombre de ménages a grimpé de 6,8 % sur cette même période. Néanmoins, Strasbourg compte plus de 9 % de logements vacants.

Selon le recensement complet de 1999, la ville compte 87,9 % de résidences principales contre seulement 0,4 % de résidences secondaires. Les logements individuels représentent 6,6 % du parc immobilier, ce qui est très faible comparé à des villes comme Bordeaux (26,9 %) ou Nantes (23,4 %) mais supérieur à Lyon (3,3 %). La ville se caractérise aussi par l'importance des logements anciens puisque 35,5 % d'entre eux ont été construits avant 1949. En revanche, les logements construits après 1990 ne représentent que 8,9 % du parc. Enfin, les logements strasbourgeois sont essentiellement de grande taille avec 38,3 % de 4 pièces et plus.

Entre 1999 et 2005, la part des propriétaires a légèrement augmenté en passant de 24 % à 26 %, mais reste relativement faible. La part des locataires s’établit à 71 %.

Les logements sociaux représentent environ 22 % des logements. Parmi les logements sociaux que compte la ville, 3,4 % d’entre eux sont vacants. Ces logements sont essentiellement des 3 pièces (37,6 %) et des 4 pièces (31,0 %). On dénombre en revanche peu de petits appartements (studios et 1 pièce).

Le développement de la ville s'appuie sur plusieurs grands projets urbains, notamment :

Depuis les années 1990, la ville envisage la requalification des anciennes zones portuaires situées aux abords de la place de l’Étoile.

Lancé en 2011, le projet d'aménagement urbain « Deux-Rives » consiste à urbaniser l'axe Strasbourg - Kehl soit environ du Heyritz jusqu'au Port du Rhin. Selon la municipalité, cela devrait permettre d'ouvrir Strasbourg « à 360° ». Il s'agit d'un projet urbain de grande ampleur concernant près de et visant à la construction de logements. L'opération est articulée autour de l’extension de la ligne D du tramway de Strasbourg vers Kehl qui est inaugurée le 28 avril 2017. À cette occasion, un nouveau pont sur le Rhin est mis en service. Dans ce projet, on trouve notamment l'aménagement du quartier du Heyritz, la construction de l'écoquartier "Danube" ou la requalification du quartier du Port du Rhin avec le lancement d'un concours d'urbanisme pour les anciennes emprises douanières de Kehl et Strasbourg. La réalisation est échelonnée de 2012 à 2025.

La presqu'île Malraux, ou se trouvait l'ancien Armement Seegmuller, constitue le cœur du projet « Deux-Rives ». Celui-ci comprend, entre autres, la construction de trois tours de de haut, baptisées « "Black Swans" », dont la réalisation a été confié à l'architecte Anne Demians fin 2012 (les travaux sont prévus de 2014 à 2018), la construction d'une tour à énergie positive (la tour Elithis Danube) et l'aménagement de l'espace urbain.

En 2015, plusieurs projets ont déjà été réalisés : la création du parc du Heyritz, le réaménagement de la place de l’Étoile et de la route du Rhin, la construction de la cité de la musique et de la danse, le centre commercial Rivetoile, le cinéma multiplexe UGC Ciné Cité Strasbourg Étoile, la médiathèque André Malraux ainsi que la réhabilitation de la tour Seegmuller en « Maison universitaire internationale » et d'un ancien bâtiment portuaire comportant logements, commerces et un lieu dédié à la culture numérique, le Shadok.

Le projet comprend la construction d'un nouveau parc des expositions (PEX), la rénovation et l'agrandissement du palais de la musique et des congrès (PMC) mais principalement la réalisation d'un quartier d'affaires à la place de l'ancienne patinoire et d'anciens halls du parc des expositions. L'extension et la restructuration du palais de la musique et des congrès sera achevée en 2016. Quant au quartier d'affaires, à proximité directe du Parlement européen, il était planifié pour être réalisé en deux phases, la première réalisée par Bouygues à partir de 2013 avec de bureaux (dont destinés aux institutions européennes), d'hôtels, de logements et de commerces et services et une seconde phase de plus de de bureaux à partir de 2017. Finalement, la municipalité revient sur son projet et présente une version plus modeste du projet fin 2012. Cette nouvelle version prévoit de bureaux, hôtels et commerces, de logements et de réserves pour les institutions européennes. Le chantier débute en 2015 par la démolition de l'ancienne patinoire et des halls du parc des expositions. La municipalité prévoit de répartir le projet entre plusieurs promoteurs. Les premiers bureaux seront livrés début 2018.

En raison de la crise économique et de la baisse des dotations de l’État, le projet d'aménagement du nouveau parc des expositions est reporté à une date indeterminée.

Le nom initial du projet, « Wacken-Europe », est changé pour celui d'« Archipel » en mars 2017.

Le projet d'aménagement de la gare basse de Strasbourg se tient à un horizon plus lointain ; 2025, car c'est le délai que la SNCF estime nécessaire pour déplacer toutes les installations ferroviaires de cette partie de la gare. À cette échéance, la ville souhaite aménager ce secteur pour permettre l'ouverture à 360° de la gare. Un quartier d'affaires prendra place sur ces emprises, en lien direct avec la LGV Rhin-Rhône et la LGV Est. Toutefois, en 2014, ce projet est au point mort.

Le nord-est et le sud-est de la commune sont couverts de vastes forêts : la forêt de la Robertsau () et la forêt du Neuhof (). Elles sont les vestiges de l'ancienne luxuriante forêt rhénane qui occupait tout le lit majeur du Rhin, fleuve tumultueux et sauvage jusqu'au . Cette forêt présentait une vitalité et une richesse en espèces remarquables, abritant une avifaune très diversifiée. Si l'endiguement et les aménagements successifs du fleuve l'ont fortement réduite, elle conserve son caractère de zone humide et abrite, dans la partie sud du quartier du Port du Rhin, la réserve naturelle de l'île du Rohrschollen. Elle demeure un terrain d'élection pour la LPO. En outre, le programme « Rhin vivant » dans le cadre du projet « LIFE Nature conservation et restauration des habitats naturels de la bande rhénane » a été lancé avec l’objectif de restaurer les écosystèmes rhénans.

En 2016, le domaine public de la ville compte arbres. Près de spécimens ont été plantés entre 2013 et 2015.

Par ailleurs, la ville compte de parcs et de jardins dont le plus réputé est le parc de l'Orangerie. Situé face au palais de l'Europe, il comporte des attractions telles qu'un zoo, une mini-ferme, un élevage de cigognes et s'agrémente d'un lac avec une cascade romantique ainsi que d'un pavillon construit en 1804 en l'honneur de l'impératrice Joséphine. Il couvre une superficie de .

Le jardin botanique possède quant à lui des origines très anciennes. Le premier jardin botanique de la ville est créé en 1619 puis transformé en cimetière en 1870 après le siège de la ville par les Allemands. Le jardin actuel, situé à l'arrière du palais universitaire, a été inauguré en 1884 pour les étudiants de la faculté de médecine et de pharmacie. Il regroupe espèces réparties sur une surface de .

Très original puisque situé sur les vestiges de la citadelle de Vauban construite en 1681 à l'Esplanade, le parc de la Citadelle s'étend sur . Plus conventionnel, le parc du Contades créé au par le maréchal de Contades est d'abord une promenade arborée extérieure à la ville. Aujourd'hui, il fait partie intégrante de la "Neustadt" et couvre .

De nombreuses places de la "Neustadt" comportent un jardin central, caractéristique typiquement germanique.

Situé à la Robertsau, aux abords de la forêt, le parc de Pourtalès est un espace de entourant le château du même nom qui abrite notamment une collection de sculptures contemporaines. Une grande partie des berges est également aménagée, notamment dans le centre, à la Montagne Verte, à la Robertsau et à la Meinau.

Le nouveau quartier des Poteries situé à l'ouest de Strasbourg a été aménagé autour du parc du même du nom, de conception très contemporaine, inauguré en 1995.

Le jardin des Deux Rives, ancien parc du Rhin, est quant à lui un parc transfrontalier situé de part et d'autre du Rhin, en partie sur la commune de Kehl. La superficie de sa partie française est d'environ . Les deux rives du Rhin sont reliées par la passerelle piétonne Mimram.

En 2003, la place de l’Étoile a été réaménagée pour devenir un parc. Non loin de là, le nouveau parc du Heyritz a été inauguré en 2014.

Enfin Strasbourg est la première ville en France à soutenir un projet de jardin partagé en permaculture sur dans le quartier de Koenigshoffen.

Strasbourg a également été récompensée par deux fleurs au palmarès 2007 du concours des villes et villages fleuris et a obtenu sa troisième fleur en 2013.

La ville de Strasbourg est aussi propriétaire des forêts du Hohwald (), du Herrenwald près de Brumath (), de l'Oedenwald près de Cosswiller () et de l'Elmerforst près de Balbronn ().

Le territoire de la commune se situe au sein de la plaine d'Alsace. Ce fossé rhénan d'effondrement, séparant le massif des Vosges à l'ouest de celui de la Forêt-Noire à l'est, est né il y a à l'occasion de l'érection des Alpes. Des fissures orientées Nord-Sud se formèrent alors ; la partie médiane s'effondra et fut envahie par la mer à l'Éocène supérieur (vers ) et à l'Oligocène inférieur (Rupélien, vers ). D'abord comblée par des dépôts marins qui recouvrirent le socle hercynien, la plaine accueillit le cours du Rhin qui y déposa ses alluvions fluviatiles, il y a un million d'années seulement. Le bassin houiller de la vallée de Villé s'étend à quelques kilomètres de la banlieue strasbourgeoise, au sud-ouest et au centre du département, quelques lambeaux de ce gisement sont dispersés vers le nord.

Attestations anciennes : "Argentorate", "Argentoratum", "Argentina" (Antiquité), "Stradeburgum" (590), "Strateburgo" (590), "Stratburgo" (728), "Strasburga" (762), "Strazburc" (1061), "Straborc" (1262), "Estrabourch" (1289).

Le premier nom de la ville fut en celtique "Argantorati" < "Argentorate", romanisé en "" ("Argentoraton" ), même nom qu'Argentré (Mayenne, "Argentrato" ). L’étymologie de ce terme est discutée, certains y voyant un lien avec la Grande déesse celte, dont "Argantia" est une des épithètes et qui est identifiée avec la lune. L’acception la plus courante voudrait que la racine celtique "arganto-" ("argent, luisant") renvoie à la couleur et la brillance argentée d'un cours d'eau ( l’Argens, l'Arc, etc.), en l'occurrence de l'Ill ("Ainos" en gaulois). Cette hypothèse est renforcée par l’ancien nom de Horbourg ("Argentovaria"), commune également située sur l’Ill, dont l'élément "ver" / "var" désigne précisément un cours d'eau en indo-européen.

"-rate" de "rāti" désigne une levée de terre ou une fortification ( vieil irlandais "ráith" / "ráth", fortin, fortification). Cette hypothèse affirme donc qu' est l'enceinte sur l'Argenta, "" la cité de la rivière, du fleuve. Ce nom était alors en parfaite cohérence avec la perception de ce lieu frontière, situé à proximité du Rhin, partie intégrante du réseau de camps défendant le "limes" nord de l’empire romain.

Puis, à la suite de son intégration dans l'entité germanique, cette ville n'était plus frontalière, mais au cœur du réseau des cités allemandes. Sa perception n’était dès lors plus sur un axe fluvial et orienté nord-sud, mais routière et sur un axe est-ouest. Strasbourg était en effet au niveau d’un des rares ponts permettant de franchir le Rhin et de ce fait placée sur une route majeure est-ouest. Son nom évolua alors en ', le château (', bâtiment fortifié ) sur la route ('), issu de ' nom antérieur à la mutation consonantique haut-allemande mentionné pour la première fois au par saint Grégoire.

La commune est appelée ou ' en allemand, ' en alsacien et "" en francique rhénan.

De nombreux objets du néolithique, de l’âge de bronze et de fer ont été retrouvés lors de fouilles archéologiques. Mais c’est des environs de 1300 av. J.-C. que date l’installation durable de peuples protoceltes.

Vers la fin du le site est devenu une bourgade celte du nom d’"Argentorate", dotée d’un sanctuaire et d’un marché. Grâce à d’importants travaux d’assèchement, les maisons sur pilotis cèdent leur place à des habitations bâties sur la terre ferme.

Les Romains arrivent en Alsace en 58 av. J.-C. et s’installent sur le site de Strasbourg. En 12 av. J.-C. la ville devient un camp militaire fortifié positionné sur le limes du Rhin faisant partie des forts de Drusus. Au fil du temps, la ville va prendre de l’importance. Promue colonie militaire, "Argentorate" est déjà un carrefour commercial important et aux alentours de l’an 20 la population est estimée à près de habitants, armée romaine incluse. La ville reste néanmoins essentiellement militaire et donc totalement dépendante de cette activité. Au cours des s, avec l’agrandissement de l’Empire romain, "" va servir de base de repli pour les troupes romaines installées en Germanie. Mais en 260, les légions quittent la Germanie et Strasbourg redevient une ville frontière.

En 355, la ville est saccagée par les Alamans. Julien reconquiert la ville en 357 après une victoire décisive sur les Alamans lors de la bataille de Strasbourg. Mais en 406 les Germains envahissent à nouveau la Gaule puis en 451, la ville est complètement détruite par Attila.

Elle est restaurée sous le nom de "Strateburgum" en 496 par les Francs qui favorisent le développement de la ville, après la conversion de Clovis au christianisme. En effet, Argentorate est l’une des rares villes de la région à être le siège d'un évêque, véritable gouverneur de l’époque.

En cette période de paix, la ville se développe à nouveau. Dès le , sous l’impulsion de l’évêque Arbogast de Strasbourg, une première cathédrale et un couvent sont édifiés.

Sous l’ère mérovingienne, Strasbourg devient ville royale mais reste de taille très modeste. Au , la ville compte habitants. Les activités sont essentiellement agricoles mais on exporte déjà du vin, du blé et du bois de chêne vers l’Allemagne, les Pays-Bas, l’Angleterre et la Scandinavie. En 842, la ville accueille Charles le Chauve et Louis le Germanique qui s’allient contre leur frère Lothaire pour le partage de l’Empire légué par leur grand-père Charlemagne et prononcent les Serments de Strasbourg, le plus ancien texte rédigé en langue romane (ancêtre du français, entre autres) et en langue tudesque (ancêtre de l’allemand).

En 843, le traité de Verdun attribue Strasbourg à Lothaire. Mais peu après sa mort, en 870, la ville revient à Louis le Germanique. En 962, Otton le Grand fonde le Saint-Empire romain germanique et Strasbourg va connaître une période d’expansion : au cours du une nouvelle enceinte fortifiée et un hôpital voient le jour tandis que la construction de l'actuelle cathédrale débute.
En seulement deux siècles, la ville passe de à habitants et devient l’une des plus grandes villes du Saint-Empire.

L'enceinte fortifiée est agrandie aux et s et le système défensif des ponts couverts édifié. Les quatre tours actuelles faisaient partie des remparts (qui comptaient 80 tours) et étaient reliées par des ponts couverts d'une toiture en bois, disparue au . Elles abritaient les corps de garde mais servaient aussi de prison.

En 1201, Philippe de Souabe élève Strasbourg au rang de ville libre. Peu après, en 1220, naît le conseil municipal. Il est alors chargé de fonctions jusque-là attribuées au clergé, notamment l’administration et la justice. La bourgeoisie acquiert une autonomie remarquable vis-à-vis du pouvoir épiscopal. Mais en 1260, Walter de Geroldseck est élu évêque de Strasbourg et exige qu’on lui restitue les pleins pouvoirs. Très vite, une guerre éclate entre les Strasbourgeois et l’armée épiscopale. En 1262, le prélat est vaincu à la bataille de Hausbergen, par les troupes strasbourgeoises, bien aidées par Rodolphe du Saint-Empire.

Strasbourg tombe alors entre les mains des plus grandes familles nobles de Strasbourg dont les rivalités incessantes, ainsi que leur mépris des bourgeois, finissent par agacer et en 1332 une guerre civile éclate. Le pouvoir revient alors à la classe marchande.
Au milieu du , la peste envahit toute l’Europe et atteint Strasbourg. Comme dans de nombreuses villes, les Juifs sont accusés d’avoir empoisonné les puits. Le 14 février 1349 près de Juifs sont brûlés vifs.

Affranchie du pouvoir épiscopal, Strasbourg est reconnue ville libre (au sein de l'empire) par Charles IV. En cette période de trouble politique, la cité va cependant accroître sa notoriété et de nombreux édifices y seront construits.
Le commerce fluvial se développe sous l'égide de la corporation des bateliers, chargée de taxer les marchandises.
À la fin du , un nouvel agrandissement de la ville est entrepris. Toute la cité se transforme en un véritable chantier d'églises et de couvents, fondés par des moines ou des familles nobles. De cet ensemble demeurent le cloître de l'église Sainte-Madeleine et celui de Saint-Pierre-le-Jeune. En 1439, après quatre siècles de construction, la flèche de la cathédrale Notre-Dame est achevée. Elle est alors le monument le plus haut de la chrétienté et symbolise la puissance de la ville. Cinq ans plus tard, en 1444, Strasbourg compte habitants - dont réfugiés de la guerre de Cent Ans qui vivent "extra muros" - et peut lever, à tout moment, une armée de hommes.
Son enceinte fortifiée et son impressionnant dispositif d’artillerie en font une place fortifiée de tout premier plan. La ville est à son apogée.

S’ensuit au début du une période de conflits qui oppose les bourgeois strasbourgeois gouvernant la ville, à la noblesse alsacienne. Ville bancaire par excellence, Strasbourg est en effet une ville riche qui suscite la convoitise. La vie intellectuelle est marquée au par la révolution de l'imprimerie. Né à Mayence et installé à Strasbourg depuis 1434, Johannes Gensfleisch, dit Johannes Gutenberg conçoit l’imprimerie à caractères mobiles. On note cependant que Gutenberg est retourné à Mayence entre 1444 et 1448 ce qui fait qu’on ignore exactement où a été finalisée cette invention majeure. Toujours est-il que Strasbourg devient très vite un des grands centres de l'imprimerie, puisque dès la fin du la ville compte une dizaine d’ateliers d’imprimerie, notamment la prestigieuse officine des Grüninger. De fait, Strasbourg va attirer nombre d’intellectuels et d’artistes. Sculpteurs, architectes, orfèvres, peintres, horlogers, la ville excelle dans de nombreux domaines.

Le développement de l'imprimerie favorise le courant humaniste qui fait jour à Strasbourg et qui va préparer l'avènement de la réforme protestante.

En effet, l’humanisme et la Réforme sont les faits marquants de l'époque et Strasbourg est une des premières villes qui appelle au changement. Dès 1519, les thèses de Martin Luther sont affichées aux portes de la cathédrale et les dirigeants de la ville, notamment Jacques Sturm, sont favorables à ce changement. La ville adopte la Réforme en 1525 et devient protestante en 1532 avec l’adhésion à la Confession d'Augsbourg. Strasbourg est alors l’un des principaux bastions de la Réforme protestante, ce qui va largement contribuer à son rayonnement.

La ville devient une terre d’accueil pour les huguenots, ces protestants chassés de France pour leur croyance. Parmi eux, notamment Jean Calvin qui s’installera plus tard à Genève. Cependant, devenue ville protestante, Strasbourg ne sera pas autorisée à créer sa propre université. La ville propose déjà de nombreux enseignements, notamment en médecine et en théologie depuis 1538 grâce au gymnase de Jean Sturm, mais ceux-ci ne donnent pas lieu à un grade universitaire reconnu.

Dans les années 1530, l’empereur Charles Quint, catholique, entre en guerre contre les princes protestants et leurs alliés et les vainc en 1547 à la bataille de Muehlberg. Strasbourg va alors conclure plusieurs alliances, notamment avec Zurich. Mais en 1592, après d’interminables délibérations, la cathédrale est partagée en deux avec l’élection de deux évêques : un catholique et un protestant. Commence alors la longue et ridicule guerre des évêques qui va plonger la ville dans d’importantes difficultés financières. Ce conflit qui durera jusqu’en 1604 se solde par la victoire des Catholiques, Charles de Lorraine devenant l'unique évêque de la ville. En 1605, l'éditeur Johann Carolus commence à Strasbourg à produire la première gazette hebdomadaire du monde au nom de « Relation aller Fürnemmen und gedenckwürdigen Historien » (« Communication de toutes histoires importantes et mémorables »).
Dans toute l’Europe, la tension monte entre les protestants et les catholiques et en 1618, la guerre de Trente Ans éclate. Strasbourg, à l’abri dans ses fortifications modernisées par Daniel Specklin, n’intervient pas dans le conflit.

À l’issue de la guerre en 1648, par les traités de Westphalie, une partie de l’Alsace (les possessions des Habsbourg) est rattachée à la France, mais Strasbourg demeure ville libre impériale. Épargnée par la guerre, la ville est néanmoins isolée, financièrement affaiblie, et n’a rien à attendre de l’Empire germanique vaincu. Le , la ville est assiégée par une armée de sous le commandement de Louis XIV et deux jours plus tard, après de rapides négociations, Strasbourg accepte la reddition. Les privilèges et les institutions de Strasbourg sont confirmés et liberté de culte garantie, mais la cathédrale est rendue aux Catholiques. Le , le roi Louis XIV fait une entrée somptueuse à Strasbourg, au son des cloches et des canons pour célébrer l'annexion de la ville à la France, qui sera confirmée en 1697 par le traité de Ryswick.

Un accord est passé entre Louis XIV et Strasbourg visant à préserver les libertés essentielles de la cité, sur les plans politique, administratif et religieux. Par contre, elle est privée de son artillerie et de ses milices et doit accepter l'installation d'une troupe de garnison. De surcroît, un prêteur royal doit veiller à ce qu’aucune décision ne soit préjudiciable aux intérêts du roi.

Si la ville a changé de nationalité, elle reste une ville frontière et un point de passage important pour rejoindre l’empire germanique. De fait, Louis XV séjournera à Strasbourg durant la guerre de Succession d'Autriche. La société aristocratique se développe et de nombreux hôtels particuliers voient le jour. Si l’allemand reste la langue courante, Strasbourg accueille de nombreux immigrants : entre 1681 et 1697, la ville passe de à habitants. Par ailleurs, Strasbourg abrite environ soldats français, basés pour la plupart à la citadelle de Vauban dont les travaux ont débuté dès 1682.

Au niveau religieux, la ville prend un tournant important. En 1704, un prince de la famille Rohan devient évêque de la ville. La famille conservera le pouvoir épiscopal jusqu’en 1790 et fera construire le fameux palais des Rohan de Strasbourg, situé tout près de la cathédrale, sur les rives de l’Ill. Durant toute cette période, le catholicisme va se développer même si les protestants restent majoritaires. En 1716, peu après la mort de Louis XIV, des sociétés françaises de colonisation de l'Amérique décident de faire un vaste appel à l'émigration alsacienne, en particulier strasbourgeoise. Des publicités attirent en Louisiane des Alsaciens, qui fondent la ville Des Allemands (Louisiane).

Assoupie depuis l’annexion de Strasbourg à la France, l’université de Strasbourg retrouve peu à peu son éclat d’antan et entre 1721 et 1755 la ville va accueillir plus de étudiants. L’université est déjà internationale : les étudiants étrangers viennent généralement d’Allemagne, de Scandinavie ou des Pays-Bas, mais aussi de Grande-Bretagne et de Russie. Certains d’entre eux sont devenus célèbres, comme Goethe qui y fit des études de droit. Le rayonnement universitaire de Strasbourg est important et certains enseignements comme le droit et la médecine sont très réputés.

Lorsque le la Bastille tombe aux mains des révolutionnaires, la population strasbourgeoise se soulève. Le 21 juillet, l’hôtel de ville est saccagé. Le calme revient très vite jusqu’en 1792, date à laquelle la France entre en guerre contre la Prusse et l’Autriche. Le 26 avril, le jeune Rouget de l’Isle compose, à la demande du maire de Strasbourg, "Un chant pour l’armée du Rhin" sans se douter qu’il deviendra un symbole de la Révolution française en devenant la Marseillaise.
Cette même année, François Christophe Kellermann, natif de Strasbourg, est nommé à la tête de l'armée de la Moselle, avec laquelle il remporte la bataille de Valmy, arrêtant les troupes ennemies à Verdun et Longwy, et sauve la France. Il sera par la suite nommé Duc de Valmy par Napoléon en 1808 en souvenir de son rôle historique.

C'est également à cette époque que Jean-Baptiste Kléber, natif lui aussi de Strasbourg, commence à s'illustrer dans de nombreuses batailles pour la défense de la jeune République française. Lors de la déclaration de guerre de 1792, Kléber s'engage dans l'armée du Rhin et s'illustre dans la défense de la forteresse Mayence assiégée en 1793. Il meurt assassiné au Caire, durant l'expédition napoléonienne. Sa statue trône au centre de la place Kléber, l'ancienne place d'Armes au cœur de la cité. Sa statue est l'œuvre de Philippe Grass de 1840.

En 1797, l’armée française prend plusieurs villes allemandes, notamment Kehl et Offenbourg. Strasbourg est hors de danger, mais la révolution a profondément désorganisé la ville. Deux ans plus tard, Napoléon Bonaparte prend le pouvoir et plusieurs institutions voient le jour : la préfecture, la bourse de commerce en 1801, la chambre de commerce en 1802. Un nouveau pont sur le Rhin est construit et les routes sont rénovées. Autant d’évolutions qui vont favoriser les activités commerciales de la ville. Strasbourg redevient un carrefour commercial important ; on vend notamment du tabac, du vin, du coton et des épices.

À la fin du , la ville est engoncée dans ses murailles, et d’importants travaux débutent au début du . C'est le début de la révolution industrielle. De nouveaux canaux vont être construits, reliant la Marne et le Rhône au Rhin. La ligne Strasbourg - Bâle est mise en service entre 1840 et 1844 par la Compagnie du chemin de fer de Strasbourg à Bâle. La gare provisoire est alors installée à Koenigshoffen, en dehors des murs de la ville. La première gare intra-muros de Strasbourg est ouverte en 1846. La ligne de chemin de fer reliant Paris à Strasbourg est achevée en 1852. Le télégraphe électrique est mis en place la même année. Néanmoins, la ville reste essentiellement tournée vers le commerce et la finance, contrairement à Mulhouse dont l’industrie connaît un véritable essor.

À partir de 1853, le français devient la seule et unique langue d’enseignement, mais l’allemand et l’alsacien restent les langues les plus utilisées au quotidien.

La ville est prospère, mais en juillet 1870, une nouvelle guerre éclate. Dès le mois d’août, les Prussiens, sous le commandement du général August von Werder, envahissent l’Alsace et assiègent Strasbourg. La ville est mal préparée et son enceinte fortifiée du n’est pas adaptée aux tirs de l’artillerie moderne.

Le 28 septembre 1870, après plus d’un mois de bombardements discontinus, Strasbourg capitule. Le traité de Francfort, signé le 10 mai 1871, rattache le Bas-Rhin, le Haut-Rhin (moins l'arrondissement de Belfort), une partie de la Moselle, une partie de la Meurthe et quelques communes des Vosges à l’Empire allemand. Strasbourg devient la capitale du ". Les Strasbourgeois sortent traumatisés de cette guerre, et le rattachement de la ville à l’Allemagne est très mal vécu.

Mais Strasbourg retrouve rapidement la prospérité, grâce notamment à la volonté du gouvernement qui souhaite faire de la ville une vitrine du savoir-faire allemand. Un vaste plan d’urbanisation est mis en place, la "" voit le jour. Celui-ci s’organise selon deux axes, les avenues des Vosges et de la Forêt-Noire d'ouest en est et l'actuelle avenue de la Paix vers le nord. La place impériale (aujourd’hui place de la République) constitue alors le nouveau centre névralgique de la ville, regroupant l’hôtel des Postes, le palais impérial, la bibliothèque universitaire et, un peu plus loin, la nouvelle université. Une nouvelle gare est édifiée, ainsi que plusieurs églises, notamment l’église Saint-Paul. La ville s’agrandit considérablement et se modernise jusqu’à la Première Guerre mondiale.

À partir de 1870, l’industrie va ainsi connaître un développement rapide, principalement dans les secteurs alimentaire (brasseries, conserverie) et mécanique. Ces nouvelles activités sont bien relayées par un réseau de tramway étendu (électrifié en 1894) et le nouveau port autonome, construit hors de la ville. Les anciennes glacières, ensemble de bâtiments situés sur les canaux de l’Ill dans le quartier de la Petite France, ont abrité de 1897 à 1990 une usine de froid artificiel. Ils ont aujourd'hui été reconvertis en un hôtel cinq étoiles. Parallèlement, les activités bancaires s’intensifient, notamment depuis la création de la banque mutualiste du Crédit mutuel.
Entre 1871 et 1914, la ville va gagner près de habitants et la vie culturelle se développe. La Première Guerre mondiale va cependant mettre un terme à cette prospérité. Contrairement au conflit de 1870, Strasbourg est bien préparée à la guerre.
Dès le début du conflit, les manifestations francophones sont interdites. Rudolf Schwander, maire de la ville, va cependant œuvrer de sorte que la population ne soit pas touchée par la faim et à l’issue de la guerre, Strasbourg sort relativement indemne. Par le traité de Versailles, l'Alsace-Moselle est rendue à la France. Le changement de nationalité se fait sinon dans la violence, du moins dans la brutalité : les Allemands sont expulsés de la ville et certains monuments impériaux sont détruits, notamment la statue de Guillaume. Le bilan démographique est plus lourd. Aux Allemands chassés de la ville ou partis de leur plein gré s’ajoutent Strasbourgeois morts au combat sous l’uniforme allemand. Durant les années 1930, la croissance démographique va reprendre avec l’arrivée de juifs d’Europe centrale qui fuient la montée rapide de l’antisémitisme.

La ville retrouve une certaine prospérité et le trafic fluvial augmente considérablement malgré une conjoncture économique peu favorable, due à la crise des années 1930. Le port autonome ainsi que le réseau de chemin de fer vont favoriser le développement de l’industrie et en 1932, une nouvelle bourse de commerce est édifiée.

Mais une nouvelle guerre se dessine. Dès le 2 septembre 1939, le gouvernement français fait évacuer de Strasbourg personnes. Après l'armistice du 22 juin 1940, l'Alsace-Lorraine est, de fait, annexée au Troisième Reich. Contrairement à l'annexion de 1871 à 1918, les deux départements alsaciens et la Moselle ne sont pas réunis. L'Alsace devient le CdZ-Gebiet Elsass et est intégrée au Gau Baden-Elsaß.

Une politique de germanisation et de nazification est menée sous l'impulsion de Robert Wagner. Lorsqu’en juillet 1940 les premiers réfugiés reviennent dans la ville, seuls les habitants d’origine alsacienne sont acceptés. Les juifs sont refoulés et la synagogue est incendiée. Les rues retrouvent leurs noms allemands ou sont rebaptisées et la langue française est interdite.

Dès septembre 1940, Marcel Weinum, âgé de 16 ans, organise un réseau de résistance constitué de 25 garçons de 14 à 16 ans et spécialisé dans la propagande, le sabotage et le renseignement appelé La Main noire. Le groupe uni et déterminé débuta ses actions de manière « modeste » mais non moins courageuses à la lumière des sanctions encourues. Leurs premières mesures se concentrèrent sur la distribution de tracts et pamphlets en faveur de la France libre et contre l'occupant allemand, la levée du drapeau tricolore sur le fronton des enceintes publiques mais également le caillassage des boutiques Allemandes ou des commerçants affichant le portait d'Hitler sur leur devanture. C'est par un jeu de circonstance que le jeune Marcel découvrit la voiture du régent de la nouvelle entité administrative, et décida de fomenter son attentat. Celui-ci fit grand bruit et irrita les plus hautes instances du pouvoir occupant. À la suite de l'attaque contre le Gauleiter Robert Wagner qui blessa le prélat, une traque fut mise en place et les membres du groupe furent tous arrêtés. Dix d'entre eux furent jugés par un tribunal spécial. Marcel Weinum quant à lui est condamné à mort et décapité à Stuttgart le 14 avril 1942. Il déclarera la veille de sa mort dans une lettre adressée à ses parents : « si je dois mourir, je meurs avec un cœur pur ». Ses compagnons, pour leur part, n'ont eu d'autre choix que l'incorporation forcée dans une armée et une guerre qui n'était pas la leur. Ils périront sur le front de l'est en Russie.

À partir de 1942, l'embrigadement est obligatoire et les jeunes d’Alsace et de Moselle sont enrôlés de force dans l'armée allemande. Les malgré-nous sont envoyés sur le front russe et très peu d’entre eux reviendront.
Le , la ville est bombardée par une vingtaine d'appareils Américains. Ce premier bombardement fit 195 victimes. Quatre autres suivront les avril, 27 mai, 11 août et 25 septembre 1944. On dénombre morts et environ 20 % des bâtiments de la ville sont touchés. L'église Saint-Jean et l'ancienne douane sont entièrement détruites (elles seront reconstruites à l'identique après la guerre), le palais du Rhin, l'hôtel des Postes, l'église Saint-Paul et le palais de la diète d'Alsace-Lorraine (actuel Théâtre national de Strasbourg) sont endommagés. Les secteurs de la place de l'Homme-de-Fer, de la place Gutenberg et de la place du Corbeau sont également touchés. Neudorf est le quartier qui subit le plus de dégâts. Cependant, Strasbourg est libérée assez facilement, de par la rapidité de l'offensive menée par le général Leclerc, et de par la reddition tout aussi rapide du général Vaterrodt. Le , le drapeau français est hissé au sommet de la cathédrale.

En 1947, lors d’un discours à Strasbourg, le général de Gaulle annonce la création du Rassemblement du peuple français. Jusqu’en 1962, la droite gaulliste domine la scène politique, dont l’une des figures les plus emblématiques est Pierre Pflimlin.

En 1949, Strasbourg se voit attribuer les premières institutions européennes, notamment le Conseil de l'Europe. À ce titre, le ministre britannique des Affaires étrangères, Ernest Bevin a déclaré « Nous cherchions un centre qui puisse convenir aux nations européennes et devenir un symbole de l'unité de l'Europe. Le choix de Strasbourg m'a paru évident. Cette grande cité avait été témoin de la stupidité du genre humain qui essayait de régler les affaires par la guerre, la cruauté et la destruction ». Un an plus tard, Strasbourg accueille la Cour européenne des droits de l'homme. Puis, en 1952, la Communauté européenne du charbon et de l'acier (CECA). En 1969, l'Institut des Droits de l'Homme. En 1972, le Centre européen de la jeunesse. En 1979, le Parlement européen est élu pour la première fois au suffrage universel et son maintien à Strasbourg confirmé.

Le nouveau pont de l'Europe, reliant Strasbourg et Kehl, est inauguré le 23 septembre 1960.

La Communauté urbaine de Strasbourg (CUS) est créée le 4 décembre 1967. Elle regroupe 27 communes et est l’une des quatre premières communautés urbaines de France avec Lyon, Lille et Bordeaux. Son objectif est d’optimiser la gestion des différentes communes. Durant les années 1970, le port autonome va se développer et le charbon va progressivement laisser place à des marchandises à plus forte valeur ajoutée (pétrole, produits chimiques).

En 1967, le Conseil de l'Europe donnait à la ville de Strasbourg le Prix de l'Europe.

Durant les Trente Glorieuses, de grands projets urbains sont mis à pied d’œuvre. Les édifices historiques sont restaurés et le quartier de l’Esplanade est construit. Les logements sociaux se multiplient, notamment dans les quartiers de Neuhof et de Hautepierre. En 1970, l’université de Strasbourg est scindée en trois.

La ville célèbre son bimillénaire en 1988. À cette occasion, la fontaine de Janus, dessinée par l'artiste strasbourgeois Tomi Ungerer, est érigée au nord de la place Broglie.

Disparu depuis 1960, le tramway de Strasbourg réapparaît en 1994 et connaît un vif succès. Les dernières extensions, qui s’achèvent en avril 2017, font du réseau strasbourgeois l'un des plus grands de France. La quasi-totalité de la ville est accessible en tram qui se divise en six lignes. En novembre 2013, la première ligne du Bus à haut niveau de service de Strasbourg est mise en service.

L'achèvement du premier tronçon de la LGV Est européenne en 2007 place Strasbourg à de Paris et renforce la position centrale de la ville au sein de l'Europe. Le second tronçon de cette ligne à grande vitesse est mis en service le 3 juillet 2016. La capitale alsacienne est désormais à de Paris.

Actuellement, Strasbourg mise beaucoup sur la coopération transfrontalière. La convention relative à la création de l'Eurodistrict Strasbourg-Ortenau a été paraphée en 2005. Son objectif est double : développer les échanges entre Strasbourg et l'Allemagne d'une part, et d'autre part franchir une nouvelle étape dans la construction de l'Europe en posant les jalons de ce qui pourrait être une métropole binationale de près d'un million d'habitants. L'accord de 2005 vise en effet à développer des projets communs dans les principaux domaines (transports, urbanisme, éducation, santé, emploi, environnement). L'Eurodistrict regroupe notamment les villes de Strasbourg, Kehl, Offenbourg, Lahr et Achern. Un arrêté préfectoral paru le rend officiel l'Eurodistrict dans sa forme de groupement européen de coopération territoriale (CEGT).

Pour des raisons de rationalisation et d'internationalisation, le marque la fusion des trois universités strasbourgeoises : Louis-Pasteur pour les sciences, Robert-Schumann pour le droit, et Marc-Bloch pour les lettres. L'université de Strasbourg redevient ainsi un établissement unique tel qu'il avait été fondé au .

Les 3 et 4 avril 2009, Strasbourg accueille le de l'OTAN.

Entre septembre 2014 et septembre 2015, la ville célèbre le millénaire des fondations de la cathédrale par une série d’événements et de manifestations.

Le janvier 2015, la Communauté urbaine de Strasbourg devient l'Eurométropole de Strasbourg.

De 1982 à 2015, Strasbourg accueillait le conseil régional d'Alsace. Depuis le janvier 2016, la ville est le chef-lieu de la nouvelle région Grand Est.

En changeant quatre fois de nationalité en 75 ans (entre 1870 et 1945), Strasbourg est devenue la ville symbole de la réconciliation franco-allemande et, plus globalement, de l'unité européenne. Strasbourg est considérée comme du fait de la présence de nombreuses institutions de l'Union européenne mais également de l'Europe continentale, au même titre que Bruxelles, Luxembourg et Francfort-sur-le-Main. Par ailleurs, Strasbourg est la deuxième ville diplomatique française avec 1 ambassade, 41 consulats (dont Allemagne, Belgique, Luxembourg, Portugal...), 47 représentations permanentes d'États membres auprès du Conseil de l'Europe, ainsi qu'une centaine d'ONG à caractère international. Strasbourg est par ailleurs la seule ville française siège d’institutions européennes et une des rares villes avec New York, Genève et Lyon à accueillir des institutions internationales sans être la capitale d'un État.

Strasbourg est, depuis 1920 et en conséquence du Traité de Versailles, le siège de la première institution intergouvernementale jamais créée, la Commission centrale pour la navigation du Rhin. Cette commission avait été instituée à la suite du traité de Vienne, en 1815, et siégeait auparavant à Mannheim. Elle regroupe cinq pays : la France, l’Allemagne, la Suisse, la Belgique et les Pays-Bas.

Créé en 1949, le Conseil de l’Europe a pour objectif la défense des droits de l’homme, la mise en valeur de l’identité culturelle de l’Europe, la recherche de solutions aux problèmes de société (notamment la discrimination, le terrorisme, la bioéthique…), le développement de la stabilité démocratique. Cette institution regroupe 47 États. Le budget 2007 du Conseil de l’Europe est de 197 millions d’euros.

Strasbourg regroupe d'autres administrations européennes comme le Secrétariat général du Conseil de l'Europe dont le rôle est d'assurer la préparation et le bon fonctionnement de ses travaux. Il conserve également les actes et archives du Conseil. La ville abrite le Comité des ministres du Conseil de l'Europe qui est l'instance décisionnelle du Conseil de l'Europe et les 47 missions diplomatiques auprès du Conseil de l'Europe.

L'Assemblée parlementaire du Conseil de l'Europe, dont la première session date du 5 mai 1949, est la plus ancienne assemblée pluraliste internationale. Elle se réunit quatre fois par an en sessions plénières au palais de l'Europe à Strasbourg afin d'examiner les rapports et les projets relatifs à l'actualité européenne. Elle est ainsi un organe décisionnel, l'assemblée devant être consultée sur tous les traités internationaux émanant du Conseil de l'Europe.

Créée en 1959, la Cour européenne des droits de l'homme (CEDH) occupe le palais des Droits de l'Homme construit entre 1991 et 1995. Cette cour est un organe juridictionnel rattaché au Conseil de l'Europe qui est chargé de traiter les requêtes relatives à la violation de la Convention européenne des droits de l'homme.

C’est l’organe parlementaire de l’Union européenne. Il regroupe 751 députés, depuis les élections de juin 2014, élus par les citoyens européens. Il joue un rôle essentiel dans l'élaboration de la législation, notamment sur la protection de l'environnement, le droit du consommateur, le transport et la lutte contre les discriminations.

Lors du Conseil européen d'Édimbourg, les 11 et , les gouvernements des États membres sont parvenus à un accord sur les sièges des institutions, aux termes duquel :
Cette décision a suscité des critiques de la part de certains députés partisans du siège bruxellois. Cependant la Cour de justice (arrêt du  - C 345/95) a confirmé qu'elle fixe bien le siège du Parlement conformément à l' 289 CE. Le contenu de cette décision a été inclus dans le traité d'Amsterdam sous forme d'un protocole annexé aux traités communautaires, ce que le Parlement européen a regretté. Le , le Parlement a officialisé l'achat de l'ensemble de ses bâtiments strasbourgeois, scellant par là son ancrage dans la ville.

Le calendrier des sessions est fixé chaque année par le Parlement, sur proposition de la Conférence des présidents.

Strasbourg accueille d'autres institutions ou organismes européens, la plupart d'entre elles n'ont de rapport ni avec le Conseil de l'Europe ni avec l'Union européenne :

Le contrat triennal instauré en 1980 sous l’impulsion de Pierre Pflimlin, a pour objectif d’accroître le rayonnement de la ville en finançant d’importants projets culturels, éducatifs ou d'infrastructures. Le dernier contrat en date, 2015-2017, pèse 146 millions d'euros. La région Alsace y apporte 13,17 millions, l’État 37,68 millions, le conseil général du Bas-Rhin 3,46 millions, la ville et sa communauté urbaine 81,1 millions et d’autres partenaires 10,86 millions. 32,18 millions seront destinés à l'Orchestre philharmonique de Strasbourg, les liaisons aériennes bénéficieront de 24,11 millions de subventions et 16 millions seront réservés pour les extensions du tramway et les études sur le futur tram-train.

Le contrat arrivé à échéance en 2011 pesait 244,5 millions d’euros. 110,4 millions d'euros étaient destinés à améliorer l'accessibilité de la ville (accélération des projets de ligne à grande vitesse, financement du déficit de certaines lignes aériennes notamment), 61,8 millions étaient destinés à l'enseignement supérieur, la recherche et l'éducation et 72,1 millions ont été consacrés au renforcement culturel de Strasbourg. La participation de l'État s’élevait au total à 117,5 millions d'euros.

Depuis l’arrivée du TGV Est en juin 2007 et du TGV Rhin-Rhône en 2011, l'accessibilité de la ville s'est améliorée. Strasbourg est reliée à Stuttgart, Munich et Francfort-sur-le-Main par TGV, grâce à la reconstruction du pont ferroviaire sur le Rhin.

Achevé en 2002, le pont Pierre-Pflimlin est tout un symbole puisque depuis le , seuls huit ponts reliant la France à l’Allemagne ont été construits. Si l’idée d’un nouveau pont reliant les deux pays à hauteur de Strasbourg remonte aux années 1950, ce n’est qu’en 1996 que le projet a pris sa forme définitive. Ce pont est un instrument économique important : il améliore sensiblement l’accessibilité de la ville depuis l’Allemagne, assurant une meilleure desserte du port autonome de Strasbourg et de l’aéroport de Strasbourg Entzheim.

La ville est au centre de nombreuses initiatives franco-allemandes ; aménagé en 2004, le jardin des Deux Rives est un parc situé le long du Rhin. Il relie Strasbourg à la ville allemande de Kehl par une passerelle piétonne, la passerelle Mimram.

Autre initiative : le Forum franco-allemand créé en 1998, qui est à la fois un salon de recrutement et un salon de l’étudiant. Organisé tous les ans à l’automne par l’Université franco-allemande, le forum a lieu à Strasbourg pendant deux jours. Son objectif est de réunir sous un même toit lycéens, étudiants et doctorants, entreprises, établissements d’enseignement supérieur français et allemands, ainsi que toutes les institutions engagés dans le rapprochement franco-allemand, afin de favoriser la prise d’information et les contacts en vue d’une formation binationale, d’un stage ou d’une embauche.

Lancé en 2007, le programme « " - Avancer ensemble" » vise quant à lui à intensifier les échanges scolaires franco-allemands.

La municipalité projette par ailleurs la construction d'une piscine franco-allemande, située sur la rive française du Rhin. Les rives du fleuve constituent en effet une zone vaste à fort potentiel, mais qui a été délaissée jusqu'au milieu des années 1990.

En 2010 est lancé un projet transfrontalier d´expérimentation de 100 véhicules hybrides rechargeables entre Strasbourg, Offenbourg et Karlsruhe.

Strasbourg est la préfecture du département du Bas-Rhin et le chef-lieu de la région Grand Est (auparavant de la région Alsace). Elle est en outre le siège de l'académie de Strasbourg et de l'archidiocèse de Strasbourg.

En 2010, la commune de Strasbourg a été récompensée par le label « Ville Internet @@@ ».

Le conseil municipal strasbourgeois compte, en plus du maire et de son délégué, 49 conseillers municipaux et 14 adjoints au maire.
À la suite des élections municipales de mars 2008, Roland Ries (PS) devient maire de Strasbourg et succède à Fabienne Keller (UMP). Roland Ries avait déjà exercé cette fonction entre 1997 et 2000 à la suite de la nomination de Catherine Trautmann (PS) au sein du gouvernement Jospin.

Historiquement, Strasbourg n'a pas d'ancrage politique particulier au sein d'une région qui est pourtant traditionnellement de droite. Avant la Seconde Guerre mondiale, la ville était majoritairement de gauche, voire d'extrême-gauche avec l'élection de Charles Hueber en 1929. En 1935, la droite prend la tête de la ville avec Charles Frey, qui sera réélu à la fin du conflit, en 1945. Après le long mandat de Pierre Pflimlin, qui dirige la ville entre 1959 et 1983, les forces politiques se sont équilibrées.

Lors de l'élection présidentielle de 2007, le candidat Nicolas Sarkozy a remporté 51,08 % des suffrages contre 48,92 % pour la candidate socialiste Ségolène Royal. Quelques semaines plus tard, lors des élections législatives, le seul député PS d'Alsace est réélu dans la première circonscription (centre de Strasbourg) avec plus de 56 % des voix.

François Hollande est arrivé en tête lors des premier et second tours de l'élection présidentielle de 2012, avec 54,7 % des voix au second tour. Lors des élections législatives de la même année, la première circonscription du Bas-Rhin, entièrement localisée sur Strasbourg, a vu Armand Jung (PS) remporter le scrutin. La deuxième, située sur certains cantons de la ville et la commune voisine d'Illkirch-Graffenstaden, a vu remporter Philippe Bies (PS). En revanche, c'est un candidat UMP, André Schneider, qui a remporté les élections dans la troisième circonscription (quartiers nord de Strasbourg et quelques communes voisines).

L'Eurométropole de Strasbourg (ancienne Communauté urbaine de Strasbourg) est présidée par Robert Herrmann depuis le 11 avril 2014. Il succède à Jacques Bigot (PS), maire d'Illkirch-Graffenstaden.

Strasbourg est divisée en six cantons :

Le taux de criminalité à Strasbourg est de 78,18 actes pour habitants en 2009 et est donc sensiblement supérieur à la moyenne nationale (). Nonobstant, la ville se place dans la moyenne basse des grandes villes françaises, à mi-chemin Nice () et Orléans (). On compte un policier pour 398 habitants en 2011.

Le taux d'élucidation des crimes et délits est de 27,21 % soit légèrement sous la moyenne nationale (28,76 %) mais dans le peloton de tête des grandes villes de France. Au cours du mandat de Fabienne Keller (2001-2008), les caméras de vidéosurveillance se sont multipliées.

Le nouvel hôtel de police (NHP) situé route de l'hôpital, derrière le centre administratif de l'Eurométropole, a été inauguré en 2002. Il remplace l'ancien commissariat central qui se trouvait rue de la Nuée Bleue et qui a définitivement fermé en 2009. Strasbourg compte également huit bureaux de police: à la Meinau, à Hautepierre, à Koenigshoffen, à la Robertsau, au Neuhof, au Neudorf, à l'Esplanade et à la gare.

Une Compagnie républicaine de sécurité () est installée à la Robertsau. La CRS autoroutière est située à Cronenbourg.

La Gendarmerie nationale occupe deux sites à proximité du Musée d'art moderne, la "caserne Ganeval" et le "quartier Sénarmont". Par le passé il existait aussi de petites gendarmeries à Neudorf, à Koenigshoffen et à la Robertsau.

Avec 158 policiers (en 2012), la Police municipale de Strasbourg est l'une des plus importantes de France. Ces derniers sont dotés de motos, vélos, scooters et de voitures. Le bureau de la Police municipale est situé au rue du 22 novembre.
À noter la présence d'une direction régionale des Douanes et droits indirects qui occupe l'hôtel des Douanes au avenue de la Liberté.

Strasbourg accueille également le centre d’hébergement des bases de données de l'espace Schengen (Système d'information Schengen), dépendant de l'Agence de l'Union européenne pour la gestion opérationnelle des systèmes d'information à grande échelle (EU-Lisa), installé dans le quartier du Neuhof.

En raison de sa situation géographique privilégiée, Strasbourg a toujours été un site stratégique. Lors de l'annexion, les autorités allemandes y stationnent une importante garnison (tout comme à Metz). En 1895, la ville compte habitants dont militaires. De nombreuses casernes sont construites, notamment dans le cadre de l'aménagement de la Neustadt, la plupart ont conservé leur affectation d'origine comme la vaste "Manteuffel Kaserne" actuel "quartier Stirn", la "Illthor Kaserne" actuelle "caserne Turenne", la "Train Kasernement" actuel "quartier Lecourbe", la "Neue Feldartilleriekaserne" au Neuhof actuel "quartier Lizé", la "Flieger Bataillon Nr.4 Kaserne" également au Neuhof actuel "quartier Aubert de Vincelles" ("caserne Guynemer" jusqu'en 1953) ou encore la "Fuss-Artillerie Kaserne" actuel "quartier Sénarmont" et la "St Margarethen Kaserne" en partie reconstruite en tant que "caserne Ganeval" (ces deux dernières sont aujourd'hui occupées par la Gendarmerie nationale). L'ancienne manutention militaire, "Proviantamt", a elle été réhabilitée pour accueillir le Pôle européen de gestion et d'économie.

En plus des casernes, les Allemands érigent aussi une ceinture de forts autour de la ville afin d'en assurer la défense (12 sont situés en Alsace et 3 sur la rive droite du Rhin).

Strasbourg disposait également d'un hôpital militaire d'abord situé dans le quartier de la Krutenau, l'hôpital militaire Gaujot, celui-ci est transféré dans le quartier du Neuhof en 1946 et l'ancien hôpital Gaujot devient une cité administrative. Dès 1945 le chirurgical d’évacuation mobile s'installe au "quartier Lyautey" (ancien "quartier Lizé Nord") au Neuhof. Il devient ensuite hôpital des armées puis hôpital régional des armées en 1980 et enfin centre hospitalier des armées en 1986 (communément appelé "hôpital militaire Lyautey"). Il est fermé en 1996.

Jusqu'à sa dissolution en 1994, la base aérienne 124 partageait ses infrastructures avec l'aéroport de Strasbourg-Entzheim.

La ville est le siège de la zone de défense et de sécurité Est depuis 2016, auparavant le siège était situé à Metz. Le préfet de la région Grand Est étant également le préfet de la zone de défense et de sécurité. Les services de la préfecture de la zone Est restent quant à eux localisés à Metz.

En 2017, la garnison de Strasbourg est composée des organismes suivants : le centre de formation interarmées au renseignement (CFIAR), l'état-major du corps européen et son bataillon de soutien, le groupement de soutien de la base de Défense de Strasbourg-Haguenau (GSBdD), l'unité de soutien de l'infrastructure de la Défense de Strasbourg (USID, ancien établissement du génie de Strasbourg), un centre du service national (CSN), un centre information recrutement des forces armées (CIRFA) ainsi qu'un poste d'information et de recrutement de la Légion étrangère (PILE). Notons aussi la présence d'un établissement public d'insertion de la Défense (EPIDE).

Depuis le juillet 2016, le commandement du renseignement (COM RENS) est basé à Strasbourg. La ville accueille également le centre du renseignement Terre (CRT) qui devrait compter 200 personnels en 2019.

L'École militaire de Strasbourg (EMS) est dissoute en 1985. L'École interarmées du renseignement et des études linguistiques (devenue par la suite le CFIAR) s'est alors installée dans les anciens locaux de celle-ci au "quartier Stirn".

Le du génie, installé dans la commune voisine d'Illkirch-Graffenstaden était le régiment de tradition de la garnison de Strasbourg. Dissous en juin 2010, en même temps que la brigade du génie dont l’état-major était aussi situé à Strasbourg, le "quartier Leclerc" qu'il occupait abrite aujourd'hui l’état-major de la blindée, la de commandement et de transmissions ainsi que le Jägerbataillon de la Bundeswehr.

Strasbourg est l'une des sept villes françaises possédant un Gouverneur militaire, celui-ci réside dans l'hôtel de Deux-Ponts place Broglie. Juste en face se trouve le cercle mixte de garnison. Strasbourg est également l'une des dernières villes qui dispose d'un maître bottier et d'un maître tailleur.

Autres unités ayant tenu garnison à Strasbourg :

La capacité d'autofinancement de la commune de Strasbourg reste élevée en 2010 grâce à l'augmentation des recettes d'investissement (+37,8 millions d'euros) ainsi qu'à la baisse des dépenses (-69,1 millions d'euros).

En 2010, la dette représentait 4,7 % du buget de fonctionnement de la communauté urbaine de Strasbourg, soit ~200 millions d'euros (~ par habitant), ce qui reste faible. En revanche, la dette a tendance à augmenter du fait d'importants projets d'investissement (1 milliard d'euros sur la période 2011-2014). Les dépenses d'investissement étant sensiblement supérieures aux recettes, la capacité de désendettement de la communauté urbaine pourrait passer de 2,3 ans actuellement à environ 8,0 ans.

Le budget pour l'année 2009 est d'environ 340 millions d'euros pour le fonctionnement et de 103 millions pour l'investissement. Le budget de la communauté urbaine de Strasbourg est de 696 millions d'euros pour le fonctionnement et de 179 millions pour l'investissement.

Strasbourg est jumelée avec les villes suivantes:

La commune entretient des coopérations avec les villes suivantes :

La commune entretient des partenariats de coopération décentralisée avec 10 autres villes :

La ville a aussi conclu des accords de coopération avec :

En , la commune de Strasbourg comptait habitants répartis sur , ce qui fait de la ville la plus peuplée du Bas-Rhin et d'Alsace, et la de France. La ville se caractérise par une faible densité de population, à peu près équivalente à celle de Toulouse et presque trois fois moindre que celle de Grenoble. Entre 1990 et 1999, le taux de croissance annuel moyen était de 0,5 %. Ce taux est légèrement plus faible entre 1999 et 2008, avec 0,3 % par an.

Strasbourg est par ailleurs l'une des premières villes de France à avoir fusionné la majeure partie de son administration avec celle de la communauté urbaine, fusion motivée en 1966 par un souci d'efficacité et d'économie budgétaire et qui a donné naissance à la communauté urbaine de Strasbourg (CUS), devenue Eurométropole de Strasbourg le janvier 2015. Sur ses , elle comptait habitants en 2008.

L'unité urbaine de Strasbourg, c'est-à-dire l'agglomération au sens de l'Insee, comptait dans sa partie française habitants au recensement de 2011.

L'aire urbaine de la ville a été évaluée en 2010 à habitants sans la partie allemande, dans la nouvelle délimitation de 2010, ce qui en fait la urbaine de France. Avec une augmentation moyenne de 0,6 % par an entre 1999 et 2008, la croissance de la population de l'aire urbaine de Strasbourg est l'une des plus rapides du nord-est de la France. En 2005 la CUS a créé l'Eurodistrict Strasbourg-Ortenau, en partenariat avec les villes françaises et allemandes (notamment Kehl, Offenbourg, Lahr et Achern). Il regroupe à ce jour habitants et sera amené à remplacer la CUS à plus long terme.

Strasbourg est une ville jeune puisque les moins de 20 ans représentent 25,1 % de la population. 46,2 % des Strasbourgeois ont moins de 30 ans. De fait, les petits ménages (une ou deux personnes) sont largement majoritaires puisqu'ils représentent 65,3 % des ménages. Par ailleurs, même si l'écart tend à se résorber, l'espérance de vie en Alsace est légèrement inférieure à la moyenne nationale, et plus particulièrement celle des femmes.

La ville est également très cosmopolite, multiculturelle et hétéroclite puisqu'elle compte immigrés en 2008 soit 19 % de sa population (dont 6 % nés en Europe et 13 % nés hors d'Europe). Elle se place donc loin devant les moyennes nationale (8,5 %) et régionale (10,5 %) et se classe en derrière Paris (20 %) parmi les villes françaises ayant plus de habitants. Les immigrés non européens sont principalement d'origine maghrébine (28,4 %), turque (12,9 %) et d'Afrique noire (12,5 %). Les nouveaux immigrants originaires d'Europe méditerranéenne et d'Algérie sont de moins en moins nombreux (les Italiens étaient majoritaires dans les années 1960). Depuis les années 2000, la majorité des immigrés viennent de Turquie, d'Allemagne et du Maroc. Enfin, la répartition des immigrés est très disparate. Ils représentent près de 40 % dans le quartier du Polygone, contre 3,6 % dans le quartier du Contades.

Pour l'année 2004-2005, la ville comptait 128 écoles maternelles ( élèves), 117 écoles élémentaires ( élèves) et 43 collèges ( élèves). Strasbourg comptait aussi lycéens répartis dans 38 établissements.

À la rentrée 2008, la première école européenne de France est inaugurée à Strasbourg, accueillant une école maternelle et les deux premières années du cycle primaire et secondaire ; elle est destinée en priorité aux enfants du personnel des institutions européennes siégeant à Strasbourg.

Le lycée Kléber, fondé en 1871 et reconstruit entre 1955 et 1959, est l'un des plus grands établissements publics d'Alsace. Il accueille chaque année plus de élèves dont 900 étudiants en classes préparatoires. Le taux de réussite au baccalauréat oscille entre 90 % et 94 % suivant les années, dont 45 % de mentions. Le lycée Kléber dispose de plus de 250 chambres d'étudiants individuelles.

Le lycée international des Pontonniers qui est une ancienne école de jeunes filles fondée en 1815, est le plus réputé. Il occupe un édifice du tout début du et propose un enseignement résolument tourné vers l'international et les activités artistiques (théâtre, histoire des arts). Son taux de réussite au baccalauréat était de 100 % en 2006 et de 99,6 % en 2007. Le lycée international est par ailleurs le dixième mieux coté de France.

Le lycée Fustel-de-Coulanges, situé en plein cœur de Strasbourg, jouxte la cathédrale Notre-Dame de Strasbourg. C'est l'ancien Collège Royal de Jésuites construit en 1685 par Louis XIV quand la ville de Strasbourg est devenue française. C'est l'un des 39 lycées impériaux que Napoléon crée en 1804. Il accueille des classes du second cycle, de la seconde à la terminale, ainsi que des classes préparatoires aux grandes écoles littéraires. Le lycée est d’ailleurs l’un des trois lycées de France préparant à l’École des chartes, sections classique et moderne.

Par ailleurs Strasbourg accueille le plus grand établissement privé protestant de France, le pôle Comenius, qui regroupe les classes de la première section de maternelle à la terminale. Cette école est le résultat de la fusion entre les lycées Gymnase Jean-Sturm et Lucie-Berger.

Avec plus de étudiants en 2009, Strasbourg est une ville étudiante importante. Mais elle est surtout résolument tournée vers l'international. En effet, plus d'un étudiant sur cinq n'est pas de nationalité française (21 % des étudiants universitaires en 2008), près de la moitié d'entre eux étant originaires d'Europe. Un tiers de ces étrangers vient d'Afrique. Au total, ce sont plus de cent nationalités qui sont représentées.
96 % des étudiants sont localisés à Strasbourg (75 % à elle seule) et Mulhouse. Viennent ensuite par ordre décroissant Illkirch, Colmar, Schiltigheim et Haguenau.

Les étudiants en Alsace sont majoritairement des filles : elles représentent 56 % des inscrits. Elles sont sur-représentées dans les langues (73 %), les lettres et arts (69 %) ou encore le droit et Sciences-Po (63 %). En revanche, dans les sciences dites « dures », elles n'y sont plus que 26 %.
Près de 70 % des étudiants en Alsace ont obtenu leur bac dans la région. En 2017, le site l'Etudiant a élue Strasbourg comme meilleure ville de France pour la vie étudiante.Trois points ont été pris en compte : les initiatives locales telle que l'accueil des étudiants ou l'accessibilité à l'offre culturelle, le nombre d'étudiants pour 100 habitants et le score "offre culturelle". 

L’origine de l’université de Strasbourg remonte à 1538, avec la création d’un gymnase protestant, transformé en académie en 1566 par l’empereur Maximilien II, puis en université luthérienne en 1621. Après le rattachement de Strasbourg à la France, Louis XIV transfère en 1702 dans la ville l’ancienne académie catholique de Molsheim, qui devient université épiscopale. La Révolution supprime les anciennes structures, d’obédience religieuse, et les remplace par deux écoles spécialisées : l’école de santé en 1794, qui deviendra école de médecine en 1802, et l’école d’accouchement en 1796. En 1803, Napoléon met sur pied un enseignement universitaire cohérent fondé sur des facultés et entretenu par l’État. L’université impériale perdurera jusqu’en 1870 et s’illustrera par des savants tels que Fustel de Coulanges, Louis Pasteur ou encore Charles Frédéric Gerhardt, inventeur de l’aspirine.

Après la défaite de 1870, l’Alsace et une partie de la Lorraine sont annexées à l’Empire allemand. Un décret impérial de 1871 conduit à la création de la « Kaiser Wilhelm Universität » à Strasbourg. La volonté politique des gouvernements successifs, allemands et français, d'ancrer l'Alsace dans leurs espaces respectifs les conduit à investir Strasbourg en tant que pôle scientifique et universitaire. Dès la création de l'université allemande, un ensemble complet de nouveaux bâtiments sont érigés en quelques années et l'Université est dotée de 124 postes d'enseignants, dont 62 professeurs en chaire, alors que Berlin et Leipzig n’en comptent à l'époque que 102. Après 1918, la reconstitution d'une université française passe par la création de 150 postes de professeurs et de maîtres de conférences, ce qui fait de Strasbourg une université mieux dotée que la plupart des autres universités de province.

Ces enjeux ont particulièrement marqué, davantage que d'autres disciplines, les sciences sociales naissantes de l'époque. La chaire de sociologie qui est occupée jusqu'en 1918 par Georg Simmel, un père fondateur de la discipline côté allemand, est maintenue après la guerre de sorte que, jusqu'en 1945, Strasbourg est la seule autre université en France, avec la Sorbonne, à bénéficier d'un enseignement de chaire professorale en sociologie. Le poste est occupé successivement par Maurice Halbwachs et Georges Gurvitch.

En 1970, l'université de Strasbourg est scindée en trois établissements, l'université Louis-Pasteur (ULP) - Strasbourg-I (sciences) qui couvrait l'ensemble des domaines scientifiques, de la médecine aux sciences économiques en passant par la physique-chimie, l'université Marc-Bloch (UMB) - Strasbourg-II (nommée auparavant "université des sciences humaines de Strasbourg", USHS) dont les filières étaient essentiellement consacrées aux sciences humaines et sociales et l'université Robert-Schuman (URS) - Strasbourg-III (droit, sciences politiques, gestion) qui était spécialisée dans les sciences politiques et juridiques. Dès les années 1990, les universités strasbourgeoises s'étaient regroupées au sein du pôle universitaire européen.

Le janvier 2009, les trois entités ont fusionné pour constituer une université multidisciplinaire, l'université de Strasbourg. Elle fait partie des premières universités françaises à accéder à l'autonomie au et est aussi l'une des premières à se doter d'une fondation, la fondation Université de Strasbourg. L'université est aujourd'hui avec près de (dont 20,5 % d’étudiants étrangers), enseignants et enseignants-chercheurs , 38 composantes (unités de formation et de recherche, facultés, écoles, instituts) et 76 unités de recherche la seconde université française en termes d'étudiants et d'enseignants. Elle est aujourd'hui membre de plusieurs réseaux universitaires en Europe tel que la confédération européenne des universités du Rhin supérieur (réseau EUCOR), un réseau regroupant les universités de Bâle, Fribourg-en-Brisgau, Karlsruhe et Mulhouse, ou encore la ligue européenne des universités de recherche, regroupant de prestigieuses universités européennes et dont elle est l'un des membres fondateurs. Elle fut parmi les trois premiers lauréats des initiatives d’excellence (IDEX) en 2011.

La plus ancienne des grandes écoles d'ingénieurs de Strasbourg a été fondée en 1875. Il s'agit de l'INSA de Strasbourg (anciennement ENSAIS, École nationale supérieure des arts et industries de Strasbourg). C'est la plus importante de toutes les grandes écoles de Strasbourg avec ces 1300 élèves et ces 8 spécialités (du génie-civil à la plasturgie, en passant par le génie électrique). Elle est à l'origine du réseau Alsace Tech, qui regroupe les 9 grandes écoles d'ingénieurs d'Alsace. L’INSA de Strasbourg est également une des grandes école d'architecte en France. Elle est la seule école française à délivrer les deux diplômes et l’habilitation à exercer la maîtrise d’œuvre en son nom propre. Une autre école d'ingénieurs, l'École nationale supérieure d'informatique pour l'industrie et l'entreprise, possède un campus dans la ville.

Créé en 1919, l'Institut européen d'études commerciales supérieures (IECS) est une école supérieure de commerce tournée vers l'international (cursus "grande école" de trois ans, dont un à l'étranger) et membre de la conférence des grandes écoles. L'IECS est à l'origine du réseau HERMES, projet coopératif basé sur le principe du double diplôme. L'IECS publie par ailleurs le "Strassbuch", guide gratuit des bonnes adresses de Strasbourg réactualisé chaque année. L'IECS est devenue en 2007 l'École de Management Strasbourg en fusionnant avec l'IAE.

Au niveau du centre-ville, on compte aussi la présence de l'Institut supérieur européen de gestion Group. L'ISEG Group propose trois écoles en 5 ans : ISEG Marketing & Communication School, ISEG Business School et ISEG Finance School.
Concernant l'école ISEG Business School, la valeur ajoutée de l'école est "Sports, santé et loisirs".
Le groupe se situe au sein d'un ancien hôtel particulier près de la place Broglie, en marge donc du Campus central de l'Esplanade.

Strasbourg abrite plusieurs autres écoles d'ingénieurs, membres de la Conférence des grandes écoles, comme l'École pour l'informatique et les techniques avancées. La ville bénéficie par ailleurs d'une spécialisation dans les secteurs de la chimie, des biotechnologies et de l'environnement avec l'école européenne de chimie, polymères et matériaux (ECPM), l'école nationale du génie de l'eau et de l'environnement de Strasbourg (ENGEES), l'école supérieure de biotechnologie de Strasbourg (ESBS) et l'École et observatoire des sciences de la Terre (EOST).
Enfin, l'école nationale supérieure de physique de Strasbourg (ENSPS), école associée de l'Institut Télécom offre une formation généraliste dans les domaines des TIC, et de la physique. L'établissement propose 7 options à ses élèves ingénieurs: Acquisition et traitement des images, Génie logigiel, systèmes et réseaux, Ingénierie des systèmes, automatique et vision, Ingénierie et sciences physiques du vivant, Micro et nanoélectronique : du composant au système sur puce, Physique et modélisation, Physique et technologies photoniques, ainsi qu'un master, Master IRIV (Images, Robotique et Ingénierie pour le Vivant), proposé aux élèves ingénieurs et à tout autre élève ayant validé les acquis nécessaires dans les matières concernées. L'école ne compte pas moins de 7 laboratoires : LSIIT, InESS, SERTIT, LSP, IPCMS, IREPA LASER, IMFS. Un partenariat avec l'école supérieure des arts décoratifs de Strasbourg (ESAD) existe également, et permet à certains élèves des deux écoles de travailler ensemble sur des projets communs.

Créée en 1921, l'École Hôtelière de Strasbourg connut plusieurs dénominations et changements depuis sa création. Elle est aujourd'hui installée aux portes de Strasbourg à Illkirch-Graffenstaden, s'appelle « Lycée des métiers de l'hôtellerie et du tourisme Alexandre Dumas » et offre des formations à plusieurs niveaux (CAP cuisine et Service, BEP, BTH, BTS).

Depuis 1992, sous l'impulsion d'Édith Cresson, Strasbourg accueille les élèves de l'École nationale d'administration (ENA) qui y suivent l'intégralité de leur scolarité depuis 2004. La ville abrite d'autres établissements spécialisés dans les fonctions politiques et géopolitiques, notamment l'Institut d'études politiques de Strasbourg (« Sciences Po Strasbourg »), l'Institut national des études territoriales (INET) et le Centre universitaire d'enseignement du journalisme (CUEJ). Enfin, Strasbourg accueille deux universités étrangères : l'université anglo-saxonne spécialisée dans le domaine spatial, l'International Space University (ISU) et la Schiller International University.

Les arts graphiques sont représentés par l'école supérieure des arts décoratifs de Strasbourg (ESAD) et l'Institut Supérieur des Arts Appliqués (LISAA) et l'école nationale supérieure d'architecture de Strasbourg (ENSAS).
Enfin, l'école supérieure d'art dramatique, implantée au sein du Théâtre national de Strasbourg, assure une formation théâtrale de grande qualité.

Les Hôpitaux universitaires de Strasbourg comptent six établissements publics à Strasbourg et dans sa banlieue qui emploient salariés pour un total de lits. 83,0 % des patients sont d'origine Bas-Rhinoise. Les principaux sites sont l'hôpital civil (hôpital pavillonnaire d'une capacité de 889 lits et existant depuis 1398), l'hôpital de Hautepierre ( lits) et l'hôpital de la Robertsau (395 lits). En avril 2008 a été mis en service le Nouvel Hôpital Civil (NHC) d'une capacité de 715 lits et places, il tend à moderniser la prise en charge médicale offerte par les Hôpitaux universitaires de Strasbourg ; plus grand chantier hospitalier de France, le NHC a été conçu par l'architecte Claude Vasconi. Le budget 2006 des hôpitaux universitaires de Strasbourg est de 688 millions d'euros et 5,12 millions d'euros sont consacrés à la recherche et à l'innovation.

Le centre Paul Strauss, créé en 1923, est spécialisé dans la lutte contre le cancer.

Strasbourg dispose aussi d'un Institut Universitaire de Réadaptation, le centre Clemenceau.

La ville compte également plusieurs cliniques privées : la clinique Sainte-Anne (qui a repris les activités de l'ancienne clinique Bethesda fermée fin 2008), la clinique Sainte-Barbe, la clinique de l'Orangerie et la clinique de la Toussaint.

Le regroupement des cliniques Adassa, Diaconesses et Sainte-Odile aboutit à la création de la clinique « Rhéna », ouverte fin février 2017, dans le quartier Port du Rhin.

Outre la tradition hospitalière strasbourgeoise existant depuis le , les hôpitaux universitaires de Strasbourg font partie des pionniers de la télé-chirurgie. En 2001, lors de l'opération Lindbergh dont le nom fais référence à l'aviateur Charles Lindbergh, le chirurgien Jacques Marescaux opère depuis New York une patiente située à Strasbourg. La création du pôle de compétitivité Alsace Biovalley dédié aux sciences de la vie et de la santé favorise les synergies entre les hôpitaux de Strasbourg et les entreprises impliquées dans le secteur de la santé. Le pôle est constitué de plus de 400 entreprises et 60 laboratoires publics. Il a permis depuis sa création en 2005, de générer en Alsace la création de plus de emplois directs et indirects et la création de 46 entreprises, tout en labellisant plus de 63 projets de recherche-développement impliquant des entreprises et des laboratoires publics. Ce pôle de compétitivité à vocation mondiale est implanté au cœur de la "Biovalley". Cet équivalent de la « Silicon Valley » dans le domaine de la chimie, de la biologie et des technologies médicales regroupe les régions frontalières du Rhin Supérieur que sont l'Alsace, le Bade-Wurtemberg en Allemagne et la région de Bâle en Suisse. Strasbourg compte également plusieurs centres de recherche et organismes spécialisés dans la santé, comme l'institut de recherche contre les cancers de l'appareil digestif (IRCAD), l’institut de Pharmacologie Clinique Roche. (IPCR), l'institut national de la santé et de la recherche médicale (INSERM, dont Strasbourg gère le quart nord-est de la France) et l'institut de génétique et de biologie moléculaire et cellulaire (IGBMC, fondé par le généticien Pierre Chambon).

Avec plus de licenciés (soit 26,9 % de la population) répartis dans 220 clubs, Strasbourg est une ville résolument tournée vers le sport et dotée d'un équipement de qualité. L'Eurométropole de Strasbourg abrite une trentaine de stades (dont le stade de la Meinau), une cinquantaine de gymnases, 9 piscines (dont 5 à Strasbourg) et une patinoire de places.

De plus en 2003 a été inauguré le Rhénus Sport, un hall à vocation sportive d'une capacité de places ( places assises). La plupart des sports sont représentés dans l'agglomération tandis que la proximité du massif des Vosges permet la pratique du ski en hiver. Strasbourg disposait d'un centre aquatique, l', situé dans le parc du Rhin. Ouvert en 1986, il est définitivement fermé en 1996.

Selon le classement du journal L'Équipe, Strasbourg est la sixième ville sportive de France. La part du budget des sports s'élève à 6,3 %, soit par habitant. La ville propose aux seniors des activités sportives gratuites. Au printemps 2015, la ville a mis en place plusieurs parcours de santé urbains baptisés « "Vitaboucle" ».

Strasbourg abrite plusieurs clubs de renommée nationale.

En football d'abord, avec le Racing Club de Strasbourg. Ce club, fondé en 1906 est basé au Stade de la Meinau. Après une rétrogradation administrative en CFA2 prononcé en août 2011, le Racing retrouve le football professionnel en 2016 grâce à sa montée en Ligue 2 après avoir été sacré Champion de France de National.

Le 18 mai 2017, le Racing Club de Strasbourg retrouve l'élite du football français en terminant Champion de France de Ligue 2.

En basketball, avec la SIG Strasbourg, fondée en 1928, qui évolue en Pro A ( division). Le club est sacré champion de France en 2005 et est présent dans l'élite du basket français depuis quelques années, notamment en participant à cinq finales consécutives en championnat de France entre 2013 et 2017, ne parvenant cependant pas à s'imposer (record).

En hockey sur glace, avec l'Étoile noire qui participe au championnat de Ligue Magnus, élite du hockey français. L'équipe évolue dans la patinoire de l'Iceberg.

D'autres sports sont représentés au niveau national comme le handball. L'Entente Strasbourg Schiltigheim Alsace Handball (fusion de l'ASL Robertsau Handball et du Handball Club Schiltigheim) porte les couleurs de l'Eurométropole. Les sports aquatiques sont bien représentés à Strasbourg grâce à une solide équipe de water polo évoluant en pro A et à des nageurs de niveau national, le tout sous le nom d'un même club: le Team Strasbourg. En badminton, la ville est représentée par de nombreux clubs : le CEBA Strasbourg a été sacré champion de France en 1993 tandis que l'ASPTT, avec ses nombreux joueurs en équipe de France et évoluant en première division Top 12 et a champion de France par équipes 2013. En rugby à XV, le Racing Club Strasbourg Rugby évolue en Fédérale 1 depuis la saison 2015-2016. Les Kangourous de Strasbourg représentent le football australien, un sport encore peu connu en France. En 2006, l'équipe a participé au championnat d'Allemagne et décroché la cinquième place. En 2009, les Kangourous prennent la deuxième place du premier championnat de France. Le CES (Cercle d'Échecs de Strasbourg) de la rue des Glacières, avec 15 coupes de France et 3 champions de France en individuel, est certainement l'un des clubs sportifs strasbourgeois le plus titré. L'handibasket est aussi présent au plus haut niveau national avec l'ASHPA Strasbourg.

Le football américain est également représenté avec le Minotaure qui évolue en Division 3 du championnat de France et se qualifie régulièrement pour les playoffs.



Strasbourg est le siège de la chaîne culturelle franco-allemande Arte depuis 1991 et de France 3 Alsace, qui diffuse notamment un journal en dialecte alsacien, le "". La ville abrite également Alsace20, chaîne locale privée (groupe Dernières Nouvelles d'Alsace). En 2008, StrasTV.com, la première web-tv française fut créée à Strasbourg. Par ailleurs, Strasbourg accueille l'antenne MEDIA Strasbourg, succursale d'information et d'assistance technique du programme MEDIA de l'Union européenne, ainsi que l'Observatoire européen de l'audiovisuel. La ville concentre l'essentiel des activités audiovisuelles de la région. Le secteur emploie en effet plus de personnes à Strasbourg sur les en Alsace.

Plusieurs radios sont installées à Strasbourg en plus des stations nationales. Les plus renommées sont :

Malgré sa grande superficie et la diversité des radios proposées, Strasbourg est dépourvue de grandes radios nationales (RMC, Fun Radio, RTL2, Chérie FM, Rire & Chansons, Radio Nova, Radio Classique...) du fait de sa proximité allemande l'empêchant d'exploiter de nouvelles fréquences. Skyrock (96.0) et Oui FM (106.5) ne sont arrivées que récemment sur Strasbourg après de nombreux mois de négociations avec les autorités outre-Rhin. Ces deux radios émettent depuis la Tour de Chimie, sur la rue Blaise Pascal, alors que les autres radios privées diffusent leurs programmes depuis le site TDF du Port du Rhin. À noter que Radio France a renoncé au 94.2 pour Mouv', sélectionné en même temps que Skyrock et Oui FM.

La presse locale est quant à elle dominée par le quotidien régional "Dernières Nouvelles d'Alsace" (DNA), fondé en 1877 et dont le siège est à Strasbourg. Ce quotidien fait partie du groupe Est Bourgogne Rhône Alpes. Son tirage quotidien d'environ exemplaires fait qu'il devance aisément l'autre journal régional "L'Alsace" implanté à Mulhouse.

Les quotidiens gratuits "Métro" et "20 minutes" (qui offre une édition locale) sont diffusés depuis 2005. Le petit format hebdomadaire wik-Strasbourg (anciennement "Repères") diffusé gratuitement sur papier et sur internet rapporte les programmations cinéma et culturelle de l'agglomération. Est également diffusé gratuitement dans les cafés et cinémas le mensuel CUT, revue de cinéma, placée sous le parrainage de Gustave Kervern.

Début 2012, le paysage des médias locaux a également vu l'arrivée d'un nouveau média en ligne spécialisé dans l'information locale, Rue89 Strasbourg.

La municipalité édite deux mensuels officiels gratuits et distribués dans les boites aux lettres : "Strasbourg Magazine" et "CUS Magazine".

Jadis, Strasbourg était surnommée la « ville aux mille églises » en raison du grand nombre d'édifices religieux qui s'y trouvait. Strasbourg fut d'ailleurs jusqu'au un centre théologique important puisque les principaux acteurs de la Réforme y prêchèrent, notamment Calvin. Ainsi, Strasbourg possède toujours de nombreuses églises et chapelles qui ont survécu aux guerres et aux destructions que la ville a subies.

Dans le département du Bas-Rhin, les dispositions juridiques de la loi du concordat de 1801 demeurent en application.

En 2014, la ville compte 185 lieux de cultes, toutes confessions confondues, soit 0,7 % du parc immobilier. Il s'agit du taux record rencontré en France.

Strasbourg est le siège d'un évêché depuis le . Depuis 1988, la ville a été élevée au rang d'archidiocèse ; l'archevêque actuel étant .

La faculté de théologie catholique dispense ses cours aux séminaristes et aux laïcs intéressés.

Strasbourg est connue notamment pour sa cathédrale. L'édifice se distingue aisément par sa couleur, due à l'utilisation de grès rose, et par sa tour unique. Les travaux commencent, en 1176, par le chœur, le transept et l'abside dans un style qui évoque le roman tardif. La construction de la façade ne débute qu'en 1276 dans un style clairement gothique qui s'apparente à la cathédrale Notre-Dame de Paris, avec notamment deux tours rectangulaires.

C'est au cours du que la cathédrale va prendre progressivement son apparence définitive, avec l'arrivée de nouveaux architectes rhénans. Un beffroi est construit entre les deux tours, l'ensemble formant une immense façade rectangulaire. En 1439, la première tour est achevée. Haute de , elle a fait de la cathédrale de Strasbourg l'édifice le plus haut de la chrétienté entre 1625 et 1847. La seconde ne fut jamais construite, même si plusieurs architectes ont dessiné les plans d'un tel projet au cours des , et s. Ces projets n'ont pas abouti d'une part pour des raisons financières mais aussi parce que l'édifice, construit sur un sol instable, risquait de s'effondrer.

La cathédrale de Strasbourg est aussi connue pour son horloge astronomique chef-d'œuvre de l'art et de la science, sa grande rosace de de diamètre et son rayon vert créé par le vitrail de Juda (patriarche) qui se manifeste aux équinoxes lorsque le soleil brille sur la ville. Aussi spectaculaire soit-il, ce rayon n'a pas cependant, selon André Heck, directeur de l'Observatoire astronomique de Strasbourg, de signification particulière : son origine est vraisemblablement accidentelle et très récente.

La cathédrale abrite en outre un impressionnant buffet d'orgue de de haut. La Fondation de l'Œuvre Notre-Dame suit et soigne l'édifice depuis 1246.


La ville se caractérise, de par son histoire, par une forte implantation protestante. Strasbourg possède donc une faculté de théologie protestante qui, à l'instar de la faculté catholique, est intégrée au système d'enseignement public (dû au statut particulier du droit local maintenant le régime des cultes reconnus).

L'unité d'enseignement de théologie protestante est également, depuis toujours, une formation privée pour les élites intellectuelles de la ville. Ainsi, Catherine Trautmann, ancien maire socialiste de la ville, y a fait ses études de premier cycle. La communauté a, pour autorité reconnue, le président de l'Union des Églises protestantes (EPCAAL, EPRAL).

L'église luthérienne Saint-Guillaume est particulièrement pittoresque. Achevé en 1667, l'ouvrage se distingue en effet par une obliquité flagrante et des vitraux pré-Renaissance. Cette église enferme également un exceptionnel tombeau à gisants du exécuté par Woelflin de Rouffach. Le long de l'Ill, se dresse également l'église Saint-Nicolas, de style gothique. Sa construction commence en 1381 mais le clocher ne sera édifié qu'en 1585. Cette église protestante présente des fresques médiévales. Albert Schweitzer y joua de l'orgue.

L'église Sainte-Aurélie abrite une nef baroque, un orgue d’André Silbermann et une horloge de Jean-Baptiste Schwilgué. Certains éléments de l'église originelle du sont encore visibles aujourd'hui. Elle a cependant été remaniée à plusieurs reprises, notamment en 1765 (portail principal). Construite non loin du quartier de la "Petite France", l'église Saint-Thomas, a été construite à la fin du . Protestante depuis 1524, elle est d'un type architectural très particulier puisqu'il s'agit d'une église-halle à cinq nefs d'égale hauteur, s'opposant ainsi à la conception d'église à plan basilical habituelle. Elle conserve dans son chœur le célèbre tombeau du Maréchal de Saxe, dont l'auteur est le sculpteur du Jean-Baptiste Pigalle. Mozart et Albert Schweitzer ont joué sur son orgue Silbermann.

L'église Saint-Pierre-le-Vieux, autre édifice religieux particulier, est constituée de deux édifices perpendiculaires : une église protestante et une église catholique. La partie protestante a été bâtie entre 1381 et 1428 où le simultaneum est imposé par Louis XIV en 1683. De nouveaux aménagements sont entrepris en 1867 avec la construction d'une église catholique séparée. D'autres travaux ont été effectués au début du . L'église Saint-Pierre-le-Jeune protestante, abrite quant à elle un remarquable "simultaneum" (Le "simultaneum" est une réglementation instaurée par Louis XIV, qui permettait aux catholiques d'utiliser les églises protestantes : les catholiques et les protestants, luthériens ou réformés, utilisaient alternativement la même église, désormais appelée église simultanée ou mixte. Souvent présentée comme un modèle de tolérance, c'est une mesure de force à sens unique, imposée seulement dans les églises protestantes, afin de favoriser la pénétration catholique.), un cloître récemment rénové, des fresques du et une sépulture mérovingienne du . L'édifice est commencé au milieu du et sera remanié à plusieurs reprises. Devenue simultanée en 1681 sous ordre de Louis XIV, l'église est redevenu uniquement protestante en 1893.

Le Temple Neuf, édifié en 1260 par les dominicains, est devenue la première paroisse réformée. En effet, dès 1538 cette église devient le lieu de culte des protestants et Jean Calvin y prêchera entre 1538 et 1541. L'édifice est malheureusement détruit lors du siège de Strasbourg, en 1870. Une nouvelle église est construite par l'architecte strasbourgeois Émile Salomon entre 1873 et 1876, dans un style néo-roman. Son clocher culmine à de hauteur. L'église réformée, dite du Bouclier, a elle aussi adopté la Réforme au cours du .

D'autres églises sont construites sous l'ère allemande, au sein des nouveaux quartiers qui voient le jour. La plus fameuse d'entre elles est sans doute l'église Saint-Paul, anciennement "" (église luthérienne de la garnison). Située avantageusement entre le Palais universitaire et la place de la République, elle est aujourd'hui vouée au culte réformé. Cette église aux proportions remarquables a été construite entre 1892 et 1897 dans un style néo-gothique par l'architecte Louis Muller. Ses flèches élancées, hautes de , en font l'église la plus haute de la ville. Le cœur comprend deux loges surélevées réservées à l'empereur et à l'impératrice.

L'église protestante de la Robertsau date de 1864. L'église protestante de la cité de l'Ill a été achevée en 1966.

Un certain nombre d'églises orthodoxes y sont représentées, notamment de rite byzantin : églises serbe, russe, bulgare, roumaine, grecque.

Dans le quartier du Port du Rhin, l'église Saint-Jean-Cassien est aujourd'hui affectée au culte orthodoxe.

L'église orthodoxe serbe Saint-Georges a été achevée en 2007 dans le quartier de Koenigshoffen.

Enfin la construction d'une église orthodoxe russe a débuté en 2014 dans le quartier des Quinze au bord du canal de la Marne au Rhin. Celle-ci sera coiffée d'un bulbe doré culminant à de hauteur et comportera également un centre culturel. Actuellement la communauté de l'Église orthodoxe de tous les saints de Strasbourg se reunit dans un ancien garage près du boulevard Clemenceau.

Strasbourg compte une importante communauté juive avec environ familles, dont 60 % d'Ashkénazes.

Les juifs furent pourtant bannis de Strasbourg durant plus de quatre siècles (de 1389 à la suite du Pogrom de Strasbourg à 1789), époque où ils s'installèrent dans les villages et petites villes des environs. Au , l'Alsace était la région où habitait le plus grand nombre de Français de confession hébraïque. Strasbourg compte plusieurs synagogues, notamment la vaste "Synagogue de la Paix" près du Parc du Contades, la "Synagogue de Cronenbourg" et la "Synagogue de la Meinau". La ville est aussi dotée d'une clinique privée (la clinique Adassa, place de Haguenau), d'un hospice pour seniors (l'EHPAD/maison de retraite de la fondation Élisa, situé sur le territoire de Geispolsheim) ainsi que de plusieurs écoles et établissements secondaires (école Akiba, école Yehouda Halévi, l'ORT) gérés par la communauté juive, elle-même guidée par le grand rabbin René Gutman. Il existe plusieurs cimetières israélites : à Cronenbourg, 3 route d'Oberhausbergen, à Koenigshoffen, à l’angle de la rue de la Tour (29) et du Breuscheckweg, Adath Israël, 5 rue Jean-Pierre Clause à Cronenbourg.

La ville compte également 35 lieux de cultes musulmans, mosquées et salles de prière sous l'égide de M. Mohamed Latahy, le président du culte musulman du Bas-Rhin.

Située dans le quartier du Heyritz, la grande mosquée de Strasbourg est ouverte au culte le août 2011, lors du du Ramadan 1432. Elle est la deuxième plus grande mosquée de France après celle d’Évry-Courcouronnes et sa capacité d’accueil est de .

Elle est officiellement inaugurée le 27 septembre 2012 en présence du ministre français de l’intérieur et des cultes Manuel Valls, du grand rabbin de Strasbourg René Gutman, de Christian Kratz, évêque auxiliaire de Strasbourg et de M. Christian Krieger, président du Consistoire Réformé de Strasbourg.

Le premier cimetière musulman municipal de France a été inauguré à Strasbourg le .

La ville a également de forts liens avec le bouddhisme. Ainsi, l'association France Tibet Libre et le Lycée international des Pontonniers ont-ils organisés la venue du dalaï-lama, dans les années 1980, et des échanges réguliers avec des moines bouddhistes sont maintenus.

Le centre de bouddhisme zen de Strasbourg a été fondé par Maître Deshimaru en 1970. Il se situe rue des Magasins dans le quartier des Halles.

Depuis juin 2014 un centre d’information sur le bouddhisme est installé dans un ancien octroi près du parc de l'Orangerie.

Enfin un temple bouddhiste, Phô Hiên, est en construction dans le quartier de la Robertsau. D'une surface totale de et pouvant accueillir 600 fidèles, il est conçu par les architectes Noël Kirtz et Jean-Luc Thomas pour l’association cultuelle bouddhique vietnamienne de Strasbourg. La première pierre a été posée le 20 janvier 2015. La communauté bouddhiste de Strasbourg compte environ fidèles.

Fondée à New York le 17 novembre 1875, par Helena Petrovna Blavatsky, ainsi que par le Colonel Henry Steel Olcott, William Quan Judge, Charles Sotheran, le Seth Pancoast, George H. Felt et quelques autres, les quartiers généraux de la Société théosophique furent établis en Inde, d'abord à Varanasi puis à Adyar (près de Chennai). Elle compte alors parmi ses plus éminents membres Charles Leadbeater, Francesca Arundale, Annie Besant et Rudolf Steiner. Le Mahatma Mohandas Karamchand Gandhi confiait à son biographe Louis Fischer son admiration pour la théosophie : "La théosophie est la fraternité des hommes [...]. C'est l'hindouisme dans ce qu'il a de meilleur". Une statue du Mahatma Gandhi, œuvre du sculpteur indien Ram Sutar a été érigée en son honneur place de L'Étoile à Strasbourg le en présence du maire de la ville.

La Société théosophique se présente ainsi :

Dès 1920 Strasbourg compte une section autonome (appelée "branche") fondée par Caroline Marthe North-Siegfried (1866-1939): l'Association Philosophique et Humanitaire de la Bibliothèque Pythagore, qui a son siège actuel au 2 rue des Hallebardes à Strasbourg. Caroline Marthe North-Siegfried (1866-1939), était la présidente et fondatrice de la Croix-Rouge dans les départements du Bas-Rhin et du Haut-Rhin, présidente et fondatrice de la Société de Protection des Animaux à Strasbourg, présidente de l'Association des Dames Françaises, Officier de l'instruction publique, médaille de la Reconnaissance française (1920). Elle soutint activement des œuvres pour aveugles, la léproserie de la chartreuse de Valbonne, le Foyer de la jeune fille et l'Armée du Salut de Strasbourg. Elle fonda en 1920 la Bibliothèque Pythagore de Strasbourg, association philosophique et humanitaire, siège de la Société théosophique de Strasbourg. Elle repose au cimetière de Strasbourg-Cronenbourg et sa tombe est toujours fleurie. La loge de la Société théosophique de Strasbourg est actuellement peu active. La plupart de ses membres sont très âgés ou décédés. Seuls se poursuivent les activités régulières de la Bibliothèque Pythagore de Strasbourg sous forme de conférences.

L'église catholique libérale (ECL), mouvement religieux d'inspiration théosophique est implantée sous forme de paroisse à Strasbourg. Son église Saint Raphaël se situe à Illkirch-Graffenstaden. On y pratique une "communion ouverte", à laquelle chacun qui le désire sincèrement, peut participer. Cérémonialiste, cette église se rattache à une tradition historique (messe de Saint Pie V en langue française). Son but est de combiner la forme catholique du culte avec son rituel et son mysticisme. Non dogmatique, l'ECL affirme être attachée à la liberté intellectuelle et de respect pour la conscience individuelle.

La Franc-Maçonnerie est d'implantation ancienne à Strasbourg, l'un des centres de l'humanisme rhénan. Elle s'appuie sur l'héritage de la « maçonnerie opérative », présente à Strasbourg dès le sous forme de loges appelées "Hütten" de compagnons tailleurs de pierre, les "Steinmetzen". En atteste le "Livre des frères" comportant les ordonnances et règles de la loge de Strasbourg datant de 1563. À la suite de l'achèvement de la cathédrale de Strasbourg et aux troubles engendrés par la guerre de Trente Ans, d'« opérative », la maçonnerie strasbourgeoise devient de plus en plus « spéculative » : on parle de "Briefmaurer" (maçons de diplôme) face aux "Grüssmaurer" (maçons de salut). Le rattachement de Strasbourg à la France en 1681 accélère cet état de choses et la loge-mère de Strasbourg perd son rôle dirigeant sur les autres guildes rhénanes dès 1707. Le décret royal de 1731 interdisant les réunions compagnoniques, les maçons opératifs glissent vers la clandestinité et trouvent accueil dans les loges « spéculatives ». Dès le début du , se mettent en place une multitude de loges maçonniques à Strasbourg.

On peut noter : la loge La Candeur, la Grande Loge Écossaise, la loge Saint-Louis d'Alsace (fondée en 1760), les loges La Modestie (fondée en 1763), L'Amitié (fondée en 1764), La triple Union de Sainte-Cécile (fondée en 1765) et de nombreuses autres loges, ainsi que la présence d'une branche des Illuminés de Bavière ou Illuminatenorden. Joseph Balsamo dit Cagliostro fonde et préside dès 1780 une loge maçonnique « égyptienne » à Strasbourg, sous la protection et lettres patentes du cardinal de Rohan, prince-évêque de Strasbourg. Une ancienne loge maçonnique située au 21 avenue de la Liberté était fréquentée par le Kronprinz Guillaume de Hohenzollern, fils de l'empereur Guillaume II d'Allemagne.

Quelques loges maçonniques strasbourgeoises :

La ville de Strasbourg dispose de treize cimetières. Le cimetière du Polygone, le cimetière israélite "Adath Israël", le cimetière israélite de Cronenbourg, le cimetière juif de Koenigshoffen, la Nécropole militaire, le cimetière Musulman, le cimetière Nord, le cimetière Ouest, le cimetière Saint-Gall, le cimetière Saint-Urbain, le cimetière Saint-Louis, le cimetière Sainte-Hélène, et le cimetière Sud.

Strasbourg est le siège de la Chambre de commerce et d'industrie de Strasbourg et du Bas-Rhin. Elle gère l’aéroport international de Strasbourg-Entzheim. Elle est également le siège de la Chambre régionale de commerce et d'industrie d'Alsace et de la Chambre de métiers d'Alsace.

L'économie strasbourgeoise est marquée par l'implantation de cinq pôles de compétitivité labellisés :

Grâce à son emplacement géographique, Strasbourg a toujours été un lieu de passage pour les biens et les personnes. Au centre de l’Europe, la ville se situe au carrefour d’un axe nord-sud historiquement très utilisé et d’un axe est-ouest. Son emplacement sur le Rhin favorise les échanges par voie fluviale. Comme toute grande ville, le secteur d’activité prédominant est le secteur tertiaire, bien que l’industrie représente encore une part non négligeable des emplois, en particulier dans les communes voisines. Strasbourg et son agglomération accueillent plusieurs grands sièges sociaux, notamment Lidl-France, le Crédit mutuel, Steelcase (à Schiltigheim), Wienerberger France (à Achenheim), Le coq sportif (à Entzheim), Puma France (à Illkirch-Graffenstaden). En 2018, Adidas implantera son siège social pour la France (précédemment installé à Landersheim) dans le nouveau quartier d'affaires du Wacken. La ville possède plusieurs pôles de compétitivité dont Alsace Biovalley, à vocation mondiale, consacré aux biotechnologies et à la santé. Ces pôles favorisent l'implantation d'entreprises des secteurs automobile et pharmaceutique. Sénerval, filiale de Séché Environnement, gère depuis 2010 l’Usine d’Incinération des Ordures Ménagères, qui est arrêtée en novembre 2014 pour présence d’amiante.

Strasbourg est classée française préférée des entrepreneurs derrière Lyon et Lille.

En 2006, la commune de Strasbourg comptait actifs dont voici la répartition :

La CUS (aujourd'hui Strasbourg Eurométropole) comptait environ actifs dont voici la répartition :

Le taux de chômage a Strasbourg est, comme dans beaucoup de grandes villes françaises, supérieur à la moyenne nationale. Mais cela n'a pas toujours été le cas. Pendant longtemps, la ville s'est distinguée par un taux de chômage remarquablement faible, bien aidée par un secteur secondaire dynamique. Cependant, le recul des activités industrielles en France a progressivement réduit l'écart entre les moyennes strasbourgeoise, française et régionale. La ville est en outre la la plus inégalitaire de France, avec un coefficient de Gini de 0,445.

Les activités industrielles à Strasbourg ont pour particularité d'être totalement diversifiées. Elles représentent 14,6 % des emplois. Sur les entreprises industrielles, plus de 30 % sont à capitaux étrangers, notamment allemands et américains. Les principaux secteurs sont l’automobile avec Punch Powerglide (anciennement General Motors), une plateforme logistique et un centre d'appel de BMW et Adient (Johnson Controls) ; l’industrie pharmaceutique avec Lilly, Octapharma, Prestwick Chemical, Carex, Boiron, JZ Produits Naturels et l’agroalimentaire avec une usine Suchard-Mondelez, les Grands Moulins de Strasbourg, la Société des Malteries d'Alsace (Groupe Soufflet), la malterie Cargill, les cafés Sati, Reck et Henri.

L'activité brassicole est également importante à Strasbourg et dans ses environs. La commune voisine de Schiltigheim est surnommée "la capitale de la bière", toutefois seule brasserie de l'Espérance (groupe Heineken) est toujours en activité. Les brasseries Adelshoffen, Schutzenberger et Fischer ont fermé au cours des années 2000. La société Brasseries Kronenbourg a définitivement quitté son site historique du quartier de Cronenbourg pour Obernai, à de Strasbourg, début 2014. Enfin la brasserie Meteor est implantée à Hochfelden, à de Strasbourg.

Citons également la papeterie Lana installée à la Robertsau depuis 1872.

Depuis les années 1990, la création du pôle de compétitivité Alsace Biovalley a apporté de nombreux emplois dans l’industrie pharmaceutique. Outre les emplois de recherche créés par les laboratoires universitaires, avec la création de nouveaux centres de recherche comme l’institut de génétique et de biologie moléculaire et cellulaire ou l’institut clinique de la souris sur le campus d'Illkirch, un certain nombre de multinationales se sont implantées à Strasbourg ou dans sa périphérie. Le point d’orgue de ce développement a été le transfert du siège social d’Aventis à Strasbourg en 2002, mais le rachat de la société par Sanofi-Synthélabo en 2004 a retransféré le siège social du nouveau groupe à Paris.

Le port autonome de Strasbourg et la facilité de transport des marchandises sur le Rhin ont joué un rôle important dans le développement économique de la ville. Aujourd'hui, certains des espaces du port autonome sont des friches industrielles ; les anciens bassins situés près du centre-ville ont été revalorisés. Il reste des aciéries de part et d’autre du Rhin, celles du côté français avaient tendance à péricliter avant la remontée du prix de l’acier dans les années 2000 ; celles du côté allemand (groupe BSW - Badische Stahlwerke) se sont muées en micro-aciéries très rentables, embauchant alors beaucoup de travailleurs frontaliers.

Électricité de Strasbourg et Gaz de Strasbourg, deux entreprises ayant échappé à la nationalisation au lendemain de la Seconde Guerre mondiale, assurent la distribution d'électricité et de gaz.

La raffinerie de Reichstett, située au nord de Strasbourg, employait 250 personnes. Elle est définitivement fermée en 2011, seul subsiste un dépôt pétrolier.

L'activité commerciale représente plus de emplois à Strasbourg.

Deux vastes zones commerciales concentrent l'essentiel de l’activité commerciale : celle de la Vigie au sud et celle de Vendenheim au nord. La Grande Île et le centre-ville rassemblent de nombreuses boutiques ainsi que la "Place des Halles", centre commercial abritant près de 120 boutiques et 8 restaurants. Au Neudorf, un nouveau centre commercial baptisé "Rivetoile" a ouvert ses portes en octobre 2008.

En 2014, le chiffre d'affaires commercial du centre-ville était de 891 millions d'euros soit 38 % du total de l'Eurométropole.

Selon une étude menée en 2016, le centre-ville de Strasbourg est le plus dynamique de France. Il compte mètres² de surfaces commerciales et emplois.

Strasbourg est l’une des premières places financière et bancaire de France et jouit d'une spécificité importante dans ce domaine. La ville compte plusieurs sièges sociaux de banques (notamment : le Crédit mutuel, le CIC Est, la Caisse d’épargne d’Alsace, le Crédit agricole Alsace-Vosges, le Crédit lyonnais Alsace-Lorraine, le Centre financier de la Banque postale, la Banque populaire Alsace-Lorraine-Champagne, le Crédit foncier et communal d'Alsace et de Lorraine), cinq salles de marchés et de nombreux établissements étrangers (UBS, Barclays, HSBC, Legal & General, Monte dei Paschi di Siena, etc.). Strasbourg s'est également doté en 1979 du premier World Trade Center de France. Les activités financières emploient plus de personnes sur Strasbourg, secteur immobilier inclus.

En 2009, la ville a lancée des études concernant deux quartiers d'affaires. Le premier se situera au Wacken, les travaux débutent en 2015. Le second devrait prendre place au niveau de la "Gare basse", bien que ce projet soit, début 2016, au point mort.

Le tourisme est une activité importante pour l'Alsace. Le secteur y emploie près de personnes dont à Strasbourg.
L'arrivée du TGV Est a permis d'enrayer la baisse des activités touristiques qui touchait la région depuis 2004. En revanche, la part des touristes étrangers continue de baisser : ils représentaient 32 % en 2007 contre 38 % en 2004. Par ailleurs, les touristes étrangers sont davantage présents l'été (environ 44 % des touristes) que l'hiver (environ 26 %). Chaque année, depuis 1570, le célèbre marché de Noël (ou Christkindelsmärik) ouvert pendant le mois de décembre, draine un nombre considérable de visiteurs, les capacités hôtelières de la ville et de toute la région faisant le plein à cette période. Malheureusement, ces capacités d’accueil sont sous-utilisées le reste de l’année avec un taux d'occupation moyen des chambres de 54,7 % contre 60,4 % pour la France. Située à la jonction des EuroVéloroutes EV5 (Via Francigena - de Londres à Rome/Brindisi) et EV15 (Véloroute Rhin de la source du Rhin à Rotterdam), Strasbourg, par ailleurs première ville cyclable de France, est visitée par de nombreux cyclistes de Pâques à fin octobre.

La restauration est très développée à Strasbourg, notamment dans la vieille ville. En plus de restaurants traditionnels français et plus spécifiquement alsaciens (brasseries, winstubs), des restaurants dits gastronomiques, des établissements à thème et de la restauration rapide, la cuisine du monde est très représentée, avec de nombreux restaurants italiens, asiatiques, du proche-Orient (dont de nombreux Döner Kebab). "Aller plus loin à la section Gastronomie."

Le centre historique, la "Grande Île" (ou "ellipse insulaire"), a été classé patrimoine mondial par l’UNESCO en 1988. En 2017, la partie centrale de la "Neustadt", vaste extension de la ville réalisée à partir de 1880, est également inscrite au patrimoine mondial dans le cadre d'une extension du périmètre classé. Strasbourg est aussi labellisée ville d'art et d'histoire par le ministère de la Culture depuis 2014. Si les vestiges de la ville romaine ont quasiment disparu, Strasbourg conserve en revanche un patrimoine architectural remarquable qui s'étend du Moyen Âge à aujourd'hui.

Strasbourg abrite de nombreux témoins du Moyen Âge et de la Renaissance, notamment en son centre historique. Parmi les plus anciens vestiges de la ville, les ponts couverts, construits au avaient pour rôle de protéger l'accès fluvial. Le système défensif est revu à plusieurs reprises jusqu'à la fin du . Les tours visibles encore aujourd'hui sont les dernières des 90 que comptaient les défenses de la ville jusqu'au . Le barrage Vauban est la suite logique du système défensif des ponts couverts. Écluse fortifiée construite à partir de 1685 par Vauban, ce barrage vise à renforcer les défenses de la ville. Il pouvait servir à inonder l'accès sud de la ville afin de ralentir (voire de stopper) la progression ennemie.

Strasbourg compte aussi de nombreuses maisons à colombages. La maison Kammerzell est sans doute l'une des plus emblématiques. Construite au , elle prend son aspect actuel en 1589 à la suite d'importants travaux. Cette maison se distingue par sa structure originale : un premier niveau en pierres, puis trois niveaux en bois de type Renaissance rhénane, et enfin trois niveaux de combles. Les ornements extrêmement nombreux et détaillés évoquent l'Antiquité, les cinq sens, le travail des hommes.

Les maisons à colombages sont nombreuses dans le quartier de la "Petite France". Miraculeusement épargné par les guerres, ce quartier implanté sur l'Ill offre un véritable panorama de la Renaissance rhénane. Les maisons les plus remarquables sont la maison des tanneurs (construite en 1572 et retouchée au début du par son propriétaire) et la maison Haderer.

Édifiée en 1358 le long de l'Ill, l'ancienne douane est l'un des rares témoins du commerce médiéval de la ville. Détruite par les bombardements de 1944, elle a été restaurée en 1956 et accueille aujourd'hui un restaurant traditionnel ainsi qu'un magasin de producteurs alsaciens. Toujours le long de l'Ill se trouve l'ancienne boucherie. Construit entre 1586 et 1588, l'édifice en forme de « U » se caractérise par la sobriété de son architecture. Il n'abandonne sa fonction initiale qu'en 1859 et abrite aujourd'hui le musée historique.

Situé au sud du centre historique, l'hôpital civil est édifié à la fin du . En 1716, un incendie le détruit partiellement. La construction d'un nouvel hôpital (encore visible aujourd'hui) commence dès 1717 sous le contrôle de l'architecte Rodolphe Mollinger. Ses immenses toitures abritent trois étages de greniers. L'édifice est agrandi en 1741. Parmi les rares éléments ayant subsisté à l'incendie du , la cave historique est sans doute le plus remarquable. Construite entre 1393 et 1395, elle est utilisée pour élever le vin servi aux malades. Cette cave abrite notamment un vin blanc de 1472. Ce nectar de plus de 500 ans n'a été servi qu'à trois reprises : en 1576, en 1716 ainsi qu'en 1944 aux libérateurs de la ville.

Sur la place Gutenberg, l'un des plus anciens sites de Strasbourg, se trouve le "Neubau" qui abrite la chambre de commerce et d'industrie. Construit à partir de 1582 sous l'impulsion d'entrepreneurs suisses, le bâtiment est représentatif du style Renaissance. Il fit notamment office d'hôtel de ville. Il a été agrandi en 1867 dans le respect du style originel.

L'hôtellerie du Corbeau est un autre lieu intéressant. Fermée au , elle a reçu des hôtes illustres tels que Frédéric le Grand, Jean-Jacques Rousseau ou encore Alexandre Dumas. Le lycée Fustel-de-Coulanges (anciennement collège royal, lycée impérial et école centrale sous la République), jouxtant la cathédrale, a d'abord été le petit séminaire pour les Jésuites après sa construction en 1685. Mais le lieu est surtout connu pour avoir abrité la première imprimerie de Strasbourg, dans la maison dite "".

Strasbourg abrite plusieurs témoins de cette époque. L'Aubette, dessinée par l'architecte Jacques François Blondel est édifiée entre 1765 et 1778 dans un style néo-classique sur la place Kléber. Ce bâtiment qui utilise un grès rose très coloré, sert dans un premier temps de corps de garde. Endommagé en 1870, il abrite par la suite le conservatoire de musique. Ce bâtiment est, avec la place du Marché Gayot construite en 1769, la seule réalisation issue du plan d'embellissement Blondel qui prévoyait une restructuration complète de la Place Kléber. Un important projet de restauration a été achevé en 2010. L'Aubette abrite désormais une galerie commerçante.

Le palais des Rohan est lui aussi remarquable. C'est notamment l'un des rares édifices de l'époque à utiliser un grès clair et non rose. Cet ancien palais épiscopal est construit entre 1728 et 1741 par l'architecte royal Robert de Cotte. Sa façade est ornée de nombreuses sculptures que l'on doit à Robert le Lorrain, de personnages religieux ou mythiques. Il accueille aujourd'hui trois musées : le musée archéologique, le musée des beaux-arts et le musée des arts décoratifs. Près de la place Broglie, on retrouve l'hôtel de Klinglin, imaginé par Jean-Pierre Pflug et construit entre 1731 et 1736 à la demande de François-Joseph de Klinglin alors prêteur royal de la ville. Il accueille un temps la préfecture du Bas-Rhin, c'est aujourd'hui la résidence du préfet. Détruit en 1870 pendant le siège de Strasbourg, il est rapidement restauré. Juste à côté, le bâtiment du Théâtre municipal (où joue l'Opéra national du Rhin), est édifié entre 1804 et 1821 par l'architecte Villot. Il est partiellement détruit en 1870 à la suite de bombardements allemands. Lors de sa restauration en 1888, la façade arrière est enrichie d'un avant-corps circulaire. Toujours aux abords de la place Broglie se trouve l'hôtel de Hanau, imaginé par Joseph Massol et achevé en 1736. Sa construction est financée par Régnier III de Hanau-Lichtenberg qui meurt avant la fin des travaux. Le bâtiment devient hôtel de ville en 1806. Aujourd'hui, il est principalement utilisé pour les célébrations de mariage.

Dans le quartier de la Robertsau, le château de Pourtalès est un monument remarquable. Construit au , il a été remanié à plusieurs reprises au cours du puis au début du . Les pavillons sont agrandis, un parc à l'anglaise est aménagé, un nouveau corps de bâtiment voit le jour. Ce château est aujourd'hui la propriété d'une université américaine, la Schiller International University.

On prétend qu'après les destructions massives de la Seconde Guerre mondiale, où les grandes villes allemandes furent rasées par les bombardements alliés, c'est à Strasbourg qu'on peut admirer les plus beaux exemples de l'architecture wilhelmienne. Notamment dans le vaste quartier bâti par les Allemands, la (nouvelle ville en allemand) dont le point central est la "" (place impériale) actuelle place de la République. C'est pourquoi récemment un projet de la ville et de la région Alsace prévoit de proposer la au patrimoine mondial de l'UNESCO.

On retrouve en effet sur la place de la République plusieurs bâtiments caractéristiques comme le palais du Rhin, ancien palais impérial construit entre 1883 et 1888 par l'architecte Hermann Eggert dans le plus pur style germanique. Édifié pour accueillir l'empereur lors de ses visites à Strasbourg, il marque le rattachement de la ville à l'Empire allemand, et s'inscrit dans un programme de rénovation urbaine de grande ampleur. Il abrite depuis 1920 la Commission centrale pour la navigation du Rhin. L'actuel Théâtre national de Strasbourg, dû aux architectes Hartel et Neckelmann, est un autre bâtiment important. Construit entre 1888 et 1899, il accueille dans un premier temps les sessions de la Délégation régionale. En 1911, il devient le Parlement d'Alsace-Lorraine, "Landtag", jusqu'à la fin de la Première Guerre mondiale. Rattaché depuis 1972 au Ministère de la culture, il est le premier théâtre national implanté en province.

On doit aussi à ces deux architectes la Bibliothèque nationale et universitaire de Strasbourg de style néo-renaissance, inaugurée en 1895. Elle est aujourd'hui, avec ses trois millions d'ouvrages, la deuxième bibliothèque de France.

Strasbourg abrite d'autres bâtiments publics remarquables construits à la même époque, comme la préfecture (ancien ministère d'Alsace-Lorraine), édifiée en 1911, mais aussi, l'hôtel des Postes dessiné par l'architecte Von Rechenberg dans un style néo-gothique. Édifié entre 1896 et 1899 par l'administration des Postes, ce bâtiment a été lourdement endommagé en 1944. Lors de sa reconstruction, on utilisa du grès rose. Aujourd'hui encore il est utilisé par La Poste. Les bains municipaux imaginés par Fritz Beblo, construits de 1905 à 1908 s'éloigne des standards d'alors, avec son imposante façade rouge et son style néo-roman. Le palais de justice, dû à Skjöld Neckelmann et construit entre 1894 et 1897 est aussi un témoin intéressant de l'époque. À l'instar de la plupart des édifices publiques construits sous l'ère allemande, ce palais utilise un grès gris clair.

Plusieurs bâtiments affectés à l'enseignement font également partie du patrimoine strasbourgeois, notamment le palais universitaire « "Kaiser-Wilhelms-Universität Strassburg" » édifié en 1884 sous le contrôle du jeune et talentueux Otto Warth. Il accueille aujourd'hui encore certaines filières universitaires (histoire, archéologie, histoire de l'art, arts plastiques, théologie) et est considéré comme l'un des plus beaux monuments construits sous l'ère allemande. Le lycée international des Pontonniers est un ex-lycée de jeunes filles inauguré en 1904 qui rompt clairement avec les tendances néo-renaissance allemandes.

La Neustadt offre également d'autres bâtiments publics à l'architecture caractéristique comme la gare centrale, inaugurée en 1883. Celle-ci est l'un des premiers édifices entrepris après le rattachement de l'Alsace-Lorraine à l'Empire allemand. La façade du bâtiment n'a quasiment pas été retouchée, elle est aujourd'hui surmontée d'une grande verrière. Le bâtiment de la « Gallia » (« Germania » à sa construction) achevé en 1885 est également typique de la ville et de l'époque. Il a d'abord abrité une compagnie d'assurances. Depuis les années 1920, il est le siège d'associations étudiantes (aujourd'hui le CROUS et l’Association fédérative générale des étudiants de Strasbourg). On doit le quartier Stirn à l'architecte Von Lilienstern. Construit entre 1884 et 1897, cet édifice est très moderne à l'époque. Il couvre une superficie de et peut accueillir trois bataillons d'infanterie. Après la guerre de 1870, Strasbourg devient en effet une base importante de l'armée allemande.

Enfin, la ville offre des exemples remarquables d'ensembles architecturaux "Jugendstil", comme le 22, rue du général Castelnau (architectes F. Lütke et H. Backes), la villa Schützenberger, au 76, allée de la Robertsau (architectes : Berninger & Krafft) ou encore l'hôtel Brion, 22, rue Sleidan (architecte : Auguste Brion).

Citons aussi la capitainerie du Port du Rhin de style néo-gothique avec son haut beffroi.

Strasbourg possède également de nombreux monuments plus contemporains comme le monument aux morts de Strasbourg, œuvre symbolique situé dans une région qui fut tantôt allemande et tantôt française au gré de l'Histoire. Situé place de la République et inauguré en 1936 par le président de la République Albert Lebrun, il porte comme seule inscription « À nos morts » sans mentionner la patrie pour laquelle les soldats sont tombés. La sculpture représente une mère (symbolisant la ville de Strasbourg) tenant sur ses genoux ses deux enfants mourants, l'un allemand et l'autre français. Ils se sont combattus et devant la mort enfin ils se rapprochent. La sculpture a été réalisée par Léon-Ernest Drivier. C'est un des rares Monuments aux morts pacifistes français.

La ville compte aussi quelques représentants du style art déco : rue du Travail et place des Halles, à l'angle de l'avenue des Vosges et de la rue Oberlin ou encore le parc des expositions au Wacken.

Plusieurs bâtiments modernes se trouvent dans le quartier européen. Le palais de l'Europe, dessiné par l'architecte Henry Bernard et inauguré en 1977, abrite le Conseil de l'Europe. Le palais des Droits de l'Homme dû à Richard Rogers accueille depuis 1998 la Cour européenne des droits de l'homme. Le bâtiment épouse le cours de l'Ill, d'où sa forme en arc de cercle. Enfin, le parlement européen que l'on doit au cabinet Architecture Studio est un autre bâtiment remarquable. Inauguré en 1999, il fait suite au sommet d'Édimbourg qui, en 1992, fixe définitivement le siège du parlement européen à Strasbourg. Sa surface totale est de pour de hauteur.

L'architecture contemporaine est également marquée par des édifices à vocation culturelle comme le musée d'Art moderne et contemporain dû à l'architecte Adrien Fainsilber. Inauguré en 1998 il est situé à proximité du barrage Vauban et fait face à l'hôtel du Département (1989) dont l'architecture rappelle celle d'un paquebot. Plus récemment, le zénith, imaginé par Massimiliano Fuksas a été achevé en 2008 après deux ans de travaux. D'autres bâtiments culturels sont intéressants comme la Cité de la musique et de la danse, qui, depuis son inauguration en 2006, est occupée par le pôle des écoles de musique de Strasbourg et principalement par le Conservatoire à rayonnement régional de Strasbourg. Enfin, la maison de la Radio-Télévision, inaugurée en 1961 et aujourd'hui siège de France 3 Alsace, est un édifice qui abrite une mosaïque de de long imaginée par Jean Lurçat et intitulée "La Création du monde". Dans le domaine éducatif, on citera l'Escarpe, de l'université Robert-Schuman que l'on doit aux architectes Knecht et Schweitzer et surtout le Pôle européen de gestion et d'économie qui loge dans une ancienne manutention en briques rouges subtilement modernisée.

L'hôtel de la Région imaginé par le cabinet Chaix et Morel et construit entre 2002 et 2004 dans le quartier du Wacken est également intéressant. Plus controversée, l'immense verrière de de long et de de haut conçue par Jean-Marie Duthilleul recouvre la façade historique de la gare centrale depuis l'arrivée du TGV Est en 2007. Les façades du grand magasin Printemps, place de l'Homme-de-Fer, ont été modernisées en 2013 par l'architecte Christian Biecher.

Côté urbanisme, la Cité-jardin du Stockfeld et la cité ouvrière Ungemach ont été construites au début du selon un concept d'intégration d'un lotissement de logements sociaux dans des espaces verts. La passerelle Mimram, du nom de son architecte Marc Mimram est également une œuvre importante de l'urbanisme de strasbourgeois. Située dans le jardin des Deux Rives et exclusivement piétonne, elle relie Strasbourg à la ville allemande de Kehl. Sa fonction, essentiellement symbolique, traduit la volonté de rapprocher les deux rives du Rhin et donc les deux pays.

L'ancien môle Seegmuller donnant sur le bassin d'Austerlitz, près de la place de l’Étoile, est un témoignage remarquable de l'architecture portuaire et industrielle des années 1930, les anciennes grues de manutention ont même été conservées. Le site est actuellement en pleine réhabilitation (médiathèque, logements, commerces, résidence étudiante), la ville veut en faire le cœur d'un vaste projet d'urbanisme reliant le quartier du Heyritz jusqu'au Port du Rhin.

La ville compte quelques immeubles et édifices de grande hauteur. Outre la cathédrale et ses , l'église Saint-Paul, avec ses deux clochers, culmine à ; elles sont suivies par : la tour de chimie () , le Parlement européen et ses , deux silos de 69 et au Port du Rhin, l'église Saint-Maurice dont le clocher atteint , la tour Europe (haute de ) de la Place des Halles, et la tour Schwab de la cité de l'Ill avec ses .

La future tour Elithis Danube, qui sera livrée en 2017, dans l'écoquartier Danube, atteindra également , tandis que les trois tours dites « Black Swans », près du môle Seegmuller, en mesureront 55.

L'ensemble immobilier « Porte de France », près de la place de la Bourse, mesure environ de hauteur au maximum, tandis que l'ancienne « Maison du Bâtiment », place de Haguenau, atteint . Enfin, l'ancien silo Seegmuller et le centre administratif de l'Eurométropole sont hauts de respectivement 50 et . Par ailleurs, la tour Valentin-Sorg, avec , surplombe la place de l'Homme-de-Fer.

Le château d'eau de la brasserie de l'Espérance, à Schiltigheim, domine le nord de l'agglomération avec ses .

Le Théâtre national de Strasbourg (TNS), est l'un des hauts-lieux culturels de Strasbourg. C'est le seul théâtre national de France ne se trouvant pas à Paris. Descendant du Centre dramatique de l'Est, il obtient son statut de Théâtre national en 1968. Idéalement implanté aux abords de la place de la République, il propose entre 15 et 20 pièces par saison. La programmation laisse une place importante aux œuvres européennes, souvent méconnues du public français. Premier établissement national décentralisé, le TNS est également membre de l'Union des théâtres de l'Europe dont l'objectif est de développer une action culturelle commune.

Strasbourg abrite d'autres structures, comme le TJP, fondé en 1974 par André Pomarat, et qui est spécialisé dans les arts de la marionnette. Aujourd'hui centre dramatique national, ce théâtre accueille environ spectateurs par an. Autre scène de qualité, Le Maillon est un théâtre à la programmation particulièrement contemporaine. Essentiellement basé au Wacken (deux salles : 600 et 150 places) cette institution culturelle dispose aussi d'une salle (en travaux) à Hautepierre - son siège historique.
Les scènes du TAPS (Théâtre Actuel et Public de Strasbourg), que l'on retrouve sur le site de la Laiterie (TAPS Gare) et dans le quartier de Neudorf (TAPS Scala) sont gérées par la direction des affaires culturelles de la ville.

Pôle Sud, scène conventionnée pour la musique et la danse, se situe dans le quartier de la Meinau. Ce lieu peut accueillir 320 spectateurs.

Le Hall des Chars est un lieu interdisciplinaire géré par l'association La Friche Laiterie et consacré aux arts vivants. Il propose au public de découvrir la scène émergente du Grand-Est, sur ses trois espaces.

Le café-théâtre et l'humour sont représentés par le Kafteur ainsi que le Camionneur, tous deux situés dans le quartier de la gare.
Le Cube noir du CREPS, à Koenigshoffen, est davantage tourné vers le théâtre amateur.

L'activité théâtrale de Strasbourg est aussi orientée vers les traditions régionales, avec la Choucrouterie, cabaret de Roger Siffer. Ce petit théâtre de 80 places accueille spectateurs chaque année et propose des spectacles humoristiques sur le thème de l'Alsace. Le théâtre alsacien de Strasbourg, créé en 1898 est lui aussi essentiellement réservé aux metteurs en scène épris de théâtre dialectal.

L'Opéra national du Rhin est né de la fusion des opéras municipaux de Colmar, Mulhouse et Strasbourg. Il a obtenu le statut d"'opéra national" en 1997 et propose plus de 130 représentations par an avec la collaboration de l'orchestre philharmonique de Strasbourg. Fondé en 1855, ce dernier est composé de 110 musiciens et donne plus de 30 concerts par an à Strasbourg. L'orchestre se produit également à l'étranger et a obtenu plusieurs récompenses nationales et internationales. La cité de la musique et de la danse, consacré à la musique classique et contemporaine organise régulièrement des concerts.
Son festival de musique, le plus ancien de France, y est organisé depuis 1932.

Les musiques d'aujourd'hui sont également très diffusées grâce à La Laiterie - salle des musiques actuelles. Ce lieu inauguré en 1994 sur une friche industrielle est devenu, malgré sa taille modeste (deux salles : et 300 places), un lieu renommé avec 200 concerts et spectateurs par an. Sa programmation est très éclectique. Strasbourg abrite d'autres petites salles, comme le Pôle Sud qui est essentiellement consacré au jazz et à la danse. Le Molodoï, centre autonome jeune crée en 1988, est pour sa part essentiellement tourné vers les musiques alternatives (hip-hop, punk, hardcore). Le centre culturel de Neudorf possède une salle de 700 places et accueille spectacles de danse, concerts et meetings politiques. La salle est également équipée d'un bar et offre occasionnellement des services banquet.

La ville compte aussi trois grandes structures. Le palais de la Musique et des Congrès qui s'étend sur et abrite notamment deux auditoriums (de et places), accueille des concerts de musique classique. Il s'y déroule environ 350 manifestations pour participants chaque année. Le Rhenus est l'une des plus vastes salles de concerts de la ville. Ce hall peut accueillir spectateurs et couvre . Il n'est néanmoins pas adapté aux concerts, sa vocation première étant d'accueillir des manifestations sportives et des expositions temporaires. D'où la construction du Zénith Europe à Eckbolsheim. Inauguré en janvier 2008, sa capacité maximale est de spectateurs ce qui en fait le plus grand de France.

Dans un domaine plus éducatif, Les Percussions de Strasbourg, sont un groupe instrumental créée en 1962 par six percussionnistes et qui se produit régulièrement dans le cadre de manifestations musicales. Les percussions de Strasbourg proposent aussi des cours, des stages et des interventions scolaires.

Strasbourg est également réputée pour la quantité et la variété de ses orgues baroques, néo-classiques, romantiques, "germaniques", modernes et éclectiques, dont beaucoup sont classés monument historique. La présence d'organistes réputés comme Marie Joseph Erb, Albert Schweitzer et Helmut Walcha a contribué au renom des instruments de la ville et a favorisé la restauration des plus anciens de ceux-ci. Plusieurs dynasties de facteurs d'orgues sont représentés dans les églises mais aussi les salles de concert (Palais des Fêtes, ancien Conservatoire, Cité de la musique et de la danse) de Strasbourg : les Silbermann, André et Jean-André, (église Saint-Thomas, église Saint-Guillaume, église Saint-Pierre-le-Jeune protestante, église Sainte-Aurélie) ; les Schwenkedel, Georges et Curt (église Saint-Jean) ; les Walther ; les Roethinger, Edmond-Alexandre et Max (église Sainte Madeleine, église Saint-Pierre-le-Vieux catholique) ; les Kern, Alfred, Gaston et Daniel (cathédrale Notre-Dame). D'autres grands noms de la facture d’orgues incluent Joseph Merklin (Temple Neuf, chœur de la cathédrale Notre-Dame) et Eberhard Friedrich Walcker (église Saint-Pierre-le-Vieux protestante).

Strasbourg accueille plusieurs festivals musicaux. Le plus ancien d'entre eux est le Festival de musique de Strasbourg. Créé en 1932 par la "Société des amis de la musique de Strasbourg", il est consacré à la musique classique et à l'art lyrique.

On doit aussi à cette société le Festival de jazz de Strasbourg, créé en 1987. Le festival Jazzdor réunit lui aussi les passionné de musique jazz. Fondé en 1986, il organise environ 40 concerts à Strasbourg. Le festival produits également des concerts en Allemagne ; à Offenbourg depuis 2002 et à Berlin depuis 2007 avec son édition berlinoise jazzdor berlin. Le Festival Musica, ou "Festival international des musiques d'aujourd'hui", créé en 1982, réunit plus de spectateurs chaque année. En 2007 58 compositeurs ont proposé une centaine d'œuvres contemporaines.

Les musiques actuelles sont représentées essentiellement par Le Festival des Artefacts, créé au début des années 1990. Il se déroule sur plusieurs jours au mois d'avril, au Zénith Europe et à La Laiterie. Au mois de juin se déroule dans divers lieux de l'agglomération, le festival electro-groove et cultures urbaines Contre-Temps. La musique électronique est représentée par les Nuits électroniques de l'Ososphère, qui se déroulent chaque année en septembre à La Laiterie, à la Friche Laiterie et au Molodoï. Enfin l'un des événements de la rentrée culturelle strasbourgeoise, est le festival des Nuits Européennes, investissant l'Eurométropole en collaborant avec ses institutions culturelles et ses lieux de vie nocturne dans un dialogue constant avec les grandes cités européennes.

Strasbourg accueille plusieurs festivals de danse et de théâtre, dont le festival Nouvelles Strasbourg Danse au mois de mai, qui investit les salles les plus importantes de la ville ainsi que les places et les rues; mais également au mois de juin le festival de théâtre Premières durant lequel de jeunes metteurs en scène européens présentent leurs premiers travaux.

La ville possède également une importante structure polyvalente : le parc des expositions du Wacken, qui regroupe quatre halls d'une superficie de à pour un total . Il accueille notamment la Foire européenne ( exposants et visiteurs par an) et le salon des vignerons indépendants. Strasbourg organise également la foire européenne d'art contemporain St-art. Créé en 1995, cet évènement accueille visiteurs annuels et met l'accent sur l'ouverture européenne puisque près de 50 % des 95 galeries sont d'origine européenne.

Depuis 2005 ont lieu chaque année en mars les Rencontres européennes de littérature à Strasbourg, organisées par l'Association Capitale Européenne des Littératures (ACEL) en partenariat avec l'université de Strasbourg. C'est notamment dans le cadre de ces Rencontres que sont remis le Prix européen de littérature, le Prix de littérature francophone Jean Arp et le Prix du patrimoine Nathan Katz. Le but de ces Rencontres est de promouvoir, en collaboration avec l'ensemble des acteurs culturels locaux, nationaux et européens, la place de Strasbourg en tant que capitale européenne des littératures et de mettre en valeur, dans une perspective largement ouverte sur l'espace européen comme sur l'espace francophone, le très riche patrimoine littéraire de l'Alsace, qui reste largement encore à découvrir.

En septembre 2008, Strasbourg a accueilli la première édition de la manifestation consacrée au , StrasBULLES.

Depuis les années 1990, l'offre culturelle s'est développée et diversifiée. D'abord avec le nouveau musée d'art moderne et contemporain de Strasbourg (MAMCS), inauguré en 1998 et qui expose sur ses des œuvres contemporaines de 1870 à nos jours. Puis avec la réouverture du musée historique, situé dans le bâtiment de l'ancienne grande boucherie. L'édifice de 1586 nécessitait en effet d'importants travaux de stabilisation. Ce musée est essentiellement axé sur l'histoire urbaine, militaire et économique de la ville. On y découvre notamment une maquette à l'échelle 1/600 de Strasbourg en 1727.

La culture alsacienne est représentée par le musée alsacien, des arts et traditions populaires. On y découvre notamment la vie rurale alsacienne entre 1750 et 1860 à travers des objets de toutes sortes : mobilier, jouets, documents, couverts et autres ustensiles.

Le musée des Arts décoratifs, situé dans l'enceinte du palais Rohan nous fait également découvrir l'artisanat strasbourgeois du sous toutes ses coutures, ainsi que les appartements du palais. Le palais Rohan abrite aussi le musée archéologique, qui propose une importante collection d'objets anciens (de -600 000 à 800 ans ) découverts en Alsace et le musée des beaux-arts, qui retrace l'histoire de la peinture en Europe. Ce musée propose entre autres de nombreuses œuvres italiennes dont la plus ancienne, de Sandro Botticelli, est datée de 1485. Le cabinet des estampes et dessins, fondé en 1890, abrite quant à lui environ œuvres dont les plus anciennes datent du .

Non loin de là, face à la cathédrale de Strasbourg, le musée de l'Œuvre Notre-Dame déploie une riche collection d'œuvres anciennes, bien souvent à caractère religieux. On y retrouve notamment l'un des plus anciens vitraux de France, la "tête romane de Wissembourg" de 1060, ainsi que la statuaire du de la Cathédrale.

Plus ludique, le musée zoologique, rattaché à l'université, propose une collection impressionnante d'animaux, parfois rarissimes. Le musée abrite aussi une collection gigantesque d'un million d'insectes.

Le musée de minéralogie, lui aussi universitaire, abrite plus de minéraux. S'y trouve notamment la deuxième collection de météorites en France (450 échantillons). L'observatoire astronomique avec son planétarium est un autre lieu intéressant. Sous sa coupole se cache la troisième lunette astronomique de France après celles de Meudon et de Nice. Le planétarium propose de nombreuses séances destinées à la découverte de l'Univers.

Ouvert en 2005, le Vaisseau est un espace de découverte scientifique destiné aux enfants. Il propose au public jeune d'apprendre tout en s'amusant.

Inauguré en novembre 2007, le musée Tomi Ungerer - Centre international de l'Illustration présente la collection Tomi Ungerer, donation de l'artiste à sa ville natale. Il est désormais installé à la "villa Greiner", à deux pas du centre historique. Ce musée possède un fonds de dessins originaux et jouets anciens.

Dans un registre plus surprenant le musée de la Coop, installé dans les locaux historiques de l'entreprise au Port du Rhin, permet de découvrir l'histoire de la fameuse coopérative alsacienne. Un musée du parachutisme est présent à l'aérodrome de Strasbourg-Neuhof. La chocolaterie Schaal à Geispolsheim comporte également un musée du chocolat.

En janvier 2014, un musée Vodou s'installe dans l'ancien château d'eau de la gare.

Le premier musée français permanent dédié au jeu vidéo, « Pixel Museum », accueille ses premiers visiteurs le 25 février 2017 à Schiltigheim. Quelques jours plus tard, le mars, c'est le musée militaire « MM Park France » qui ouvre ses portes à La Wantzenau.

La bibliothèque nationale et universitaire de Strasbourg (BNUS) est, avec sa collection de trois millions de volumes la deuxième bibliothèque de France. Elle a été fondée à la suite des bombardements de 1870 qui ont détruit l'ancien édifice et les ouvrages qu'il abritait. Reconstruite sous l'ère allemande, la bibliothèque obtiendra son statut de bibliothèque nationale en 1926. Selon les chiffres de 2006, elle compte lecteurs inscrits dont 64 % d'étudiants. La BNUS fait acquisition de nouveaux ouvrages chaque année et se modernise profondément (bornes Wi-Fi, mise en ligne de documents). Les domaines favorisés par la BNUS sont l'Europe, l'Allemagne, l'Alsace, l'Antiquité et la religion.

La bibliothèque municipale de Strasbourg (BMS), moins élitiste, propose un fonds de documents, dont destinés au jeune public et CD audio. Bibliothèque de proximité, la BMS compte neuf succursales réparties dans la ville. Elle accueille également des rencontres, des conférences et des ateliers pour enfants. Enfin, la bibliothèque propose le service "Bibliobus", un bus équipé comme une bibliothèque et qui s'arrête à certaines heures près des établissements scolaires.

La ville abrite dix médiathèques. La plus importante est la médiathèque André Malraux, occupant un ancien bâtiment portuaire dans le quartier des Fronts de Neudorf. Il s'agit d'une médiathèque de l'Eurométropole, elle fait donc partie du réseau des "Médiathèques de la Ville et de l'Eurométropole de Strasbourg". Elle regroupe documents en accès libre ainsi que livres anciens.

En tant qu’un des premiers centres européens de l’imprimerie (Jean Mentel et autres), Strasbourg s’est longtemps enorgueilli d’une très importante collection d’incunables. Celle-ci cependant fut presque totalement anéantie à la suite du bombardement de la bibliothèque et des archives municipales, en 1870. D’importants efforts de reconstitution des fonds menés à partir de 1872 sous les auspices notamment de Rodolphe Reuss font que Strasbourg peut aujourd'hui se vanter à nouveau de posséder un nombre considérable d’incunables dans ses bibliothèques, nombre réparti comme suit : bibliothèque nationale et universitaire, env. ; médiathèques et bibliothèques de la Ville et de l'Eurométropole, 349 ; bibliothèque du Grand Séminaire de Strasbourg, 237 ; médiathèque protestante, 66 et bibliothèque alsatique du Crédit mutuel, 5.

Au 

Au 

En 2008, l'intrigue de "Dans la ville de Sylvia" de José Luis Guerín se déroule à Strasbourg. En 2011, Philippe Claudel filme une grande partie des scènes de "Tous les soleils" au centre ville de Strasbourg et sur les quais.

Tourné en 1967 à Strasbourg, le premier épisode de "L'Homme du Picardie" se déroule dans le centre ville et sur le Port du Rhin. Ce feuilleton télévisé francais réalisé par Jacques Ertaud a été diffusé à partir du 16 décembre 1968 sur la première chaîne de l'ORTF.

L'intrigue de "" de Guy Ritchie (2011) débute par un attentat à Strasbourg sur le parvis de la cathédrale.

Strasbourg compte cinq cinémas dont un multiplexe. Le centre-ville est investi par les cinémas indépendants à vocation culturelle, notamment l"'Odyssée". Ce petit cinéma situé dans les locaux d'un ancien théâtre cinématographique de 1913 propose par ailleurs une bibliothèque consacrée au cinéma ( revues, photographies). Strasbourg abrite en son centre deux autres cinémas d'art et d'essai, le "Star" (4 salles) et le "Star Saint-Exupéry" (5 salles, surnommé "Star Saint-Ex"). Le "Vox" (6 salles) a une offre plus généraliste.

Près de la place de l’Étoile, le multiplexe UGC Ciné Cité Strasbourg est le plus grand complexe UGC d'Europe (22 salles, places, un écran de ). Un multiplexe Pathé (12 salles, 2750 places) est situé dans la commune périphérique de Brumath à une quinzaine de kilomètres au nord de Strasbourg.

L'arrivée des multiplexes de cinéma a entraîné le déclin des salles en centre-ville, plus particulièrement dans la rue du Vieux Marché aux Vins : le "Pathé Club" a fermé ses portes en 1999, le "Méliès" en 2000, et enfin l'ancien "UGC Capitole" situé rue du 22 novembre en 2003. On trouvait également avant cela un cinéma dans le quartier du Neudorf, "Le Scala", aujourd'hui reconverti en théâtre.

L'association des "Films du Spectre" organise depuis 2006, le Spectre Film Festival, un événement annuel, se déroulant en septembre et consacré au cinéma de genre science-fiction, horreur et fantastique.

L'Association La Cigogne Enragée organise depuis 2011 le Festival Chacun son Court, un festival dédié aux courts métrages professionnels mais également étudiants.

Dans le quartier de la Robertsau se trouve le "CINE (Centre d'initiation à la nature et à l'environnement) de Bussierre". Aménagé en 2001 dans l'ancienne grange et ouvert en 2003, il est géré par l'association SINE ("Strasbourg Initiation Nature Environnement") et a vocation à « organiser, coordonner et promouvoir des actions d'éducation à la nature et l'environnement de tout public sur tout le territoire de la métropole de Strasbourg ». Le CINE de Bussierre s'appuie sur les compétences d'un vaste réseau associatif.

En raison de l'activité touristique, des congrès, de la présence des institutions européennes, mais aussi de la fidélité, cependant moindre que dans le passé, de la clientèle locale, les restaurants de toutes catégories et de qualités gastronomiques très diverses abondent à Strasbourg.

Cinq restaurants sont récompensés par un macaron (« étoile ») Michelin en 2017. Le guide rouge, qui n'a plus attribué ses "trois étoiles" depuis le relatif déclassement du "Crocodile", vendu par Émile Jung, et le départ d'Antoine Westermann, étoile cinq établissements en 2017 : 1"741, Le Crocodile, Buerehiesel" (sous l'égide d'Éric Westermann, fils du triple étoilé Antoine parti à Paris en "rendant ses étoiles"), "Unami, Gavroche".

L’équipe de Frédéric Lefèvre de "La Carambole" à Schiltigheim, dans les faubourgs de la ville, obtient la seconde place au Trophée Paul Haeberlin en 2014.

Strasbourg fut longtemps célèbre pour ses ', « bistrots à vins (d'Alsace) » typés et conviviaux auxquels une clientèle locale était très attachée. Cela notamment grâce à la présence constante de patrons au comportement familier, de personnages tels qu'Yvonne Haller, dont l'accueil marqua longuement un établissement de caractère, toujours existant, mais moins « personnalisé » : "Chez Yvonne", dont le nom alsacien est '. "Le Clou", d'ancienne notoriété, le "Coin des Pucelles", le "" et quelques autres établissements perpétuent la tradition, bien que les étrangers à la ville y fussent souvent beaucoup plus nombreux que les Strasbourgeois. Mais beaucoup d'affaires ont été reprises, sont gérées de façon autre par des propriétaires ou investisseurs ne participant pas au service, moins proches de la clientèle.

"L’Ami Schutz", dans le secteur touristique des Ponts-Couverts, entretient une atmosphère appréciée de sa clientèle peu locale, internationale. L'endroit se flatta longtemps d'être une "bierstub". Terrasse et salles agréables, ambiance se voulant "alsacienne".

"Au Pont du Corbeau", près du Musée alsacien, garde un répertoire terroir et une clientèle strasbourgeoise.

Deux restaurants de renom sont installés dans des maisons historiques célèbres : la "Maison Kammerzell", qui avait été reprise et a été cédée par Guy-Pierre Baumann (le créateur de la choucroute au poisson), à la fin des années 1960, et "La Maison des Tanneurs", quasi institutionnelle (remaniée, cette demeure spectaculaire date pour l'essentiel de 1572 : François Lenhardt, qui reprit la maison après sa mère, fêta les 440 ans de l'édifice en 2012).

Strasbourg est une ville de , ou prétendues telles, plus que de « brasseries alsaciennes ». La disparition de l'affaire familiale Schutzenberger en 2006, dernière brasserie indépendante de Schiltigheim, entraîna la fermeture du très contemporain restaurant-bar "Le Schutzenberger", immédiatement proche de la place Kléber. De gros investissements avaient été faits par Schutzenberger au cœur de Strasbourg, pour ce vaste établissement aux multiples niveaux, aménagé par Jean Nouvel, mais il ne connut pas le succès et demeure fermé depuis des années malgré la réouverture de la brasserie en 2013. Les restaurants-brasseries existants ne se différencient guère de ceux d'autres régions.

L'alsacien est le nom donné aux variantes dialectales de l'allemand pratiquées en Alsace. Ces dialectes sont l'alémanique (du sud de la région jusque vers Haguenau) et un peu le francique (vers Wissembourg et la Moselle). Le parler strasbourgeois, bien qu'étant de l'alémanique, se différencie de ses alentours par une forte influence du francique qui marque son vocabulaire.

En France, l'alsacien est la deuxième langue régionale après l'occitan, connu par quelque 39 % de la population de la région (beaucoup moins dans les villes, notamment Strasbourg, mais vivace dans les espaces ruraux). Comme pour toutes les langues non établies, l’orthographe n’est pas fixée, car la prononciation, en particulier, varie, ou variait, d’un secteur à l’autre, voire d’un village à l’autre, quand ce n'est pas d'un quartier à l'autre. Les différences phonologiques, et dans une moindre mesure morphologiques, entre les parlers du nord au sud de l'Alsace sont importantes. Une méthode comme orthal tente de remédier à cet état des choses. De nombreux mots français ont été intégrés et ont enrichi le lexique alsacien au fil du temps.

À l'heure actuelle, le dialecte est de moins en moins parlé à Strasbourg, surtout par les jeunes générations. A contrario, il est pratiqué encore par de nombreuses personnes d'un certain âge. Quelques expressions se perpétuent dans le langage courant, certains mots restent usuels (notamment sur les cartes des ).

L'astéroïde (4690) Strasbourg a été nommé en honneur de la ville.

Plusieurs personnalités sont nées à Strasbourg et la ville a accueilli de nombreux personnages historiques.

Johannes Gutenberg y résida plus de dix ans. Il y conçut en partie l'impression à caractères mobiles.

De nombreux humanistes et propagateurs de la Réforme s'installèrent à Strasbourg, notamment Didier Érasme et Jean Calvin. Après le passage de Goethe qui suivit des études de droit et y élabora sa pensée, Strasbourg accueille Rouget de Lisle qui composera la Marseillaise.

Le vit passer d'autres personnalités, comme Victor Hugo, celui-ci brièvement et ne s'intéressant qu'à « la munster » (la cathédrale), Louis Pasteur et Albert Schweitzer.

L'écrivain et aviateur Antoine de Saint-Exupéry effectua son service militaire à Strasbourg en 1921.

Les illustrateurs Boulet, John Howe et Marjane Satrapi furent élèves de l'École supérieure des arts décoratifs de Strasbourg.






Le , le blason de la ville a été apposé sur la de la SNCF.

Le drapeau de la ville dérive de son blason, il présente une large bande rouge diagonale sur un fond blanc. Le rouge et le blanc sont également les couleurs traditionnelles de l'Alsace.

Le premier logo de la ville et de la communauté urbaine, adopté dans les , représente la flèche de la cathédrale stylisée. Le cercle coloré symbolise le mouvement et la dynamique.

Le logo actuel est adopté en 2015. Il est dérivé de celui créé en 2010, qui a été adapté à l'occasion de la transformation de la communauté urbaine en métropole. Le « ".eu" » fait directement référence au site internet de la ville ; il montre également que Strasbourg est tournée vers les nouvelles technologies et confirme la vocation européenne de la ville. Ledit logo est généralement accompagné d'une vignette rouge portant la mention "Capitale européenne". Le plus souvent, le logo est vert, mais il existe également des variantes de différentes couleurs : bleu, rouge, noir, orange

Devise : "", le nom latin de la ville.








</doc>
<doc id="2895" url="https://fr.wikipedia.org/wiki?curid=2895" title="Shuffle (musique jamaïcaine)">
Shuffle (musique jamaïcaine)

Le Shuffle, aussi qualifié de rhythm and blues jamaïcain, est un style musical précurseur du ska. Né à la fin des années 1950, il était joué par des musiciens jamaïcains qui essayaient de reproduire les chansons des jazzmen noir américains qu'ils entendaient sur les radios de Miami et de La Nouvelle-Orléans, en les mêlant aux rythmes qu'ils savaient déjà jouer (mento, calypso, merengue...). La basse est puissante et le rythme de guitare est déjà syncopé et plus rapide.




</doc>
<doc id="2896" url="https://fr.wikipedia.org/wiki?curid=2896" title="Slack">
Slack





</doc>
<doc id="2897" url="https://fr.wikipedia.org/wiki?curid=2897" title="Stephen King">
Stephen King

Stephen King est un écrivain américain né le à Portland (Maine).

Il publie son premier roman en 1974 et devient rapidement célèbre pour ses contributions dans le domaine de l'horreur mais écrit également des livres relevant d'autres genres comme le fantastique, la fantasy, la science-fiction et le roman policier. Tout au long de sa carrière, il écrit et publie plus de cinquante romans, dont sept sous le pseudonyme de Richard Bachman, et environ deux cents nouvelles, dont plus de la moitié sont réunies dans dix recueils de nouvelles. Après son grave accident en 1999, il ralentit son rythme d'écriture. Ses livres sont vendus à plus de d'exemplaires à travers le monde et il établit de nouveaux records de ventes dans le domaine de l'édition durant les années 1980, décennie où sa popularité atteint son apogée.

Longtemps dédaigné par les critiques littéraires et les universitaires car considéré comme un auteur « populaire », il acquiert plus de considération depuis les années 1990 même si une partie de ces milieux continue de rejeter ses livres. Il est régulièrement critiqué pour son style familier, son recours au gore et la longueur jugée excessive de certains de ses romans. À l'inverse, son sens de la narration, ses personnages vivants et colorés, et sa faculté à jouer avec les peurs des lecteurs sont salués. Au-delà du caractère horrifique de la plupart de ses livres, il aborde régulièrement les thèmes de l'enfance et de la condition de l'écrivain, et brosse un portrait social très réaliste et sans complaisance des États-Unis à la fin du et au début du siècle suivant.

Il a remporté de nombreux prix littéraires dont treize fois le prix Bram-Stoker, sept fois le prix British Fantasy, cinq fois le prix Locus, quatre fois le prix World Fantasy, deux fois le prix Edgar-Allan-Poe et une fois le prix Hugo et l'O. Henry Award. Il a reçu en 2003 le National Book Award pour sa remarquable contribution à la littérature américaine et a été décoré de la National Medal of Arts en 2015. Ses ouvrages ont souvent été adaptés pour le cinéma ou la télévision avec des fortunes diverses, parfois avec sa contribution en tant que scénariste et, une seule fois, comme réalisateur.

Les parents de Stephen King sont Donald Edwin King, né le sous le nom de Donald Pollock, ancien capitaine de la marine marchande devenu représentant, et Nellie Ruth Pillsbury, née le , pianiste. Ils se marient le . Le , le couple, qui pense ne pas pouvoir avoir d'enfant, adopte un nouveau-né, David Victor King. Néanmoins, Ruth finit par tomber enceinte et Stephen Edwin King naît le au ' de Portland, dans le Maine. En 1949, Donald King, coureur de jupons invétéré à qui le rôle de père de famille ne convient pas, abandonne soudainement le domicile familial pour ne jamais réapparaître. Dès lors, Ruth King et ses deux enfants vivent dans des conditions financières souvent très difficiles et déménagent fréquemment, Ruth occupant de petits emplois et s'installant tour à tour près du domicile de ses nombreuses sœurs. De 1949 à 1958, la famille King réside ainsi successivement à Fort Wayne (Indiana), West De Pere (Wisconsin), Chicago, Malden (Massachusetts) et Stratford (Connecticut). À l'âge de quatre ans, le jeune Stephen connaît ses premières rencontres avec l'horreur. Dans la vie réelle tout d'abord, quand un train écrase un camarade de jeu sous ses yeux. Puis en écoutant l'adaptation radiophonique d'une nouvelle de Ray Bradbury, ', qui le terrifie. Pendant l'année scolaire 1953-1954, il est retiré de l'école en raison de divers problèmes de santé et passe l'essentiel de son temps à la maison, où il écrit ses premières histoires d'enfant.

En 1958, la famille King retourne dans le Maine, à Durham, pour que Ruth puisse s'occuper de ses parents dont la santé est déclinante. Cette année-là, elle offre à son fils sa première machine à écrire pour Noël et Stephen écrit plusieurs nouvelles, largement inspirées par les bandes dessinées d'EC Comics, notamment "Les Contes de la crypte", et les films de science-fiction et d'horreur. En 1960, Stephen découvre une caisse de livres qui appartenaient à son père et dans laquelle se trouve ', une anthologie de nouvelles de H. P. Lovecraft qui constitue sa première lecture d'horreur « sérieuse ». Entre 1958 et 1966, il se rend en stop quasiment tous les samedis au cinéma Ritz de Lewiston, distant d'une vingtaine de kilomètres de Durham, pour satisfaire sa passion du cinéma. En 1961, il expédie pour la première fois une de ses nouvelles, ', à un magazine publié par Forrest J Ackerman. Il autopublie ses premiers récits vers la même période à l'aide d'une machine à ronéotyper que son frère utilise pour publier le journal ' ("Le Torchon de Dave") auquel Stephen contribue. Il vend ainsi sa première histoire, une novélisation du film "La Chambre des tortures" (', 1961), aux élèves de son école mais la principale l'oblige à rembourser ses gains.

De 1962 à 1966, Stephen King va à l'école secondaire de Lisbon Falls. Il est bon élève, sauf en physique et en chimie, mais n'est ni très sociable, ni athlétique en raison de ses problèmes de poids. Il joue au poste d'offensive tackle dans l'équipe de football américain du lycée. En 1963, il écrit son premier roman, ', texte de resté inachevé et jamais publié. À partir de 1964, il travaille comme journaliste sportif pour le journal hebdomadaire de Lisbon Falls et y apprend de son rédacteur en chef à corriger ses textes en supprimant les mots superflus. La première histoire qu'il réussit à faire publier, après de nombreux refus, est ' qui paraît en 1965 dans un fanzine d'horreur sous le titre "". Durant sa dernière année de lycée, il écrit la première version de "Rage" mais la laisse inachevée.

Après avoir obtenu son diplôme de fin d'études secondaires, King étudie la littérature à l'université du Maine d'Orono de 1966 à 1970. C'est pendant sa première année à l'université, qu'il écrit "Marche ou crève", premier roman qu'il complète. Il le présente à un concours du premier roman organisé par Random House, qui le rejette rapidement à la grande détresse de l'écrivain. En 1967, il réussit pour la première fois à vendre une nouvelle, ', au magazine ', qui la lui achète . Il écrit aussi des nouvelles qui paraissent dans le magazine littéraire du campus, "Ubris", et dans le journal des étudiants, ', pour lequel il écrit également des articles dans une rubrique intitulée ' ("Le Camion à ordures de King") à partir de 1969.

Le professeur Burton Hatlen aide King à développer son talent à travers ses ateliers littéraires et l'encourage à persévérer dans l'écriture. Sa deuxième vente professionnelle est la nouvelle "L'Image de la faucheuse", qui lui rapporte au printemps 1969. Quelques mois plus tard, King rencontre Tabitha Jane Spruce, elle aussi étudiante en lettres, à la bibliothèque du campus et tombe amoureux d'elle. Durant sa dernière année à l'université, il achève le roman ', une histoire très sombre qui a pour toile de fond une émeute raciale dans une petite ville, mais il ne réussit pas à la vendre à un éditeur et ce roman demeure inédit. Au printemps 1970, il écrit également les deux premiers récits de ce qui constituera plus tard "Le Pistolero" ainsi que la nouvelle "Poste de nuit", que le magazine masculin ' lui achète .

Stephen King sort de l'université du Maine avec un diplôme et un certificat d'enseignant en anglais ainsi qu'une mention en élocution et en art dramatique. Il emménage dans un appartement à Orono avec Tabitha mais il n'arrive pas à trouver un poste d'enseignant et doit se résigner à travailler dans une blanchisserie industrielle. Il essaie de compléter les maigres revenus de son ménage en envoyant des nouvelles à des magazines et se marie avec Tabitha le alors qu'elle est enceinte de leur premier enfant, une fille prénommée Naomi qui naît cinq mois plus tard. En 1971, King trouve un poste de professeur d'anglais à l'école secondaire de Hampden, pour un salaire de par an, mais continue à travailler dans la blanchisserie pendant les vacances d'été car la situation financière du foyer, qui vit de 1971 à 1973 dans une caravane à Hermon, est devenue plus précaire encore avec la naissance d'un deuxième enfant, Joseph Hillstrom, en 1972. Durant cette période difficile, où trois romans qu'il a écrits, "Rage", "Blaze" et "Running Man", sont refusés par les éditeurs, King développe une dépendance à l'alcool en cherchant du réconfort dans la boisson. Par ailleurs, il vend notamment les nouvelles "Le Cinquième Quart", histoire de gangsters qui est la seule qu'il ait publiée sous le pseudonyme de John Swithen, et "Cours, Jimmy, cours", achetée par "" , la plus forte somme qu'un récit lui a rapporté jusqu'alors.

En 1972, alors que Stephen King a , il entreprend la rédaction de "Carrie", l'histoire d'une adolescente souffre-douleur de ses camarades de classe qui développe un pouvoir de télékinésie, mais, doutant de la qualité de son récit, il jette les premières pages à la poubelle. Tabitha les retrouve et, après les avoir lues, encourage son mari à persévérer dans sa tentative. King termine donc "Carrie" et expédie le manuscrit à la maison d'édition Doubleday. L'éditeur accepte le roman en et fait signer à King un contrat type qui l'engage pour cinq romans. Doubleday programme sa publication pour l'année suivante, versant à King une avance sur les droits d'auteur de . La famille King déménage pour Bangor et Stephen commence à écrire un nouveau roman, "Salem", quand Doubleday l'informe que les droits en édition de poche de "Carrie" ont été vendus pour , somme dont la moitié lui revient. King décide alors d'arrêter sa carrière d'enseignant et de se consacrer uniquement à l'écriture. Sa mère meurt en décembre 1973 d'un cancer de l'utérus diagnostiqué quelques mois auparavant, sa sœur Ethelyn lui ayant fait la lecture de "Carrie" un mois avant sa mort. "Carrie" est finalement publié par Doubleday le à , sont vendus la première année.

Après la mort de sa mère, King et sa famille déménagent à Boulder, dans le Colorado, où il entreprend la rédaction de "Shining, l'enfant lumière" après avoir imaginé les bases de l'histoire lors d'un bref séjour au "" d'Estes Park. Ils reviennent s'installer dans le Maine en 1975, King achetant sa première maison à Bridgton, et "Salem" est publié par Doubleday le . Ce roman est une sorte de version modernisée de "Dracula" dans laquelle le vampire s'installe dans une petite ville du Maine. Il s'inspire aussi de "Peyton Place" pour le regard qu'il porte sur la mentalité régnant dans les petites villes. Toujours en 1975, "Carrie" est publié en édition de poche et se vend à plus de en moins d'un an. "Salem", dont les droits en édition de poche ont été vendus par Doubleday pour , sort dans le même format en août 1976 et se vend à en six mois.

En 1976, King ressent le besoin d'engager un agent littéraire pour le représenter car il n'est pas satisfait du faible pourcentage qu'il touche sur les droits d'auteur et que Doubleday refuse de renégocier son contrat. Il choisit de se faire représenter par Kirby McCauley, qui a gagné sa confiance en vendant certaines de ses nouvelles à des magazines généralistes, et ce dernier négocie en 1977 un nouveau contrat avec Viking Press qui engage King sur trois livres pour .

"Shining, l'enfant lumière" paraît le . Le roman met en scène la famille Torrance qui passe l'hiver seule dans un hôtel hanté par une présence maléfique, laquelle veut s'emparer du jeune Danny, doté d'un pouvoir télépathique, en utilisant son père. Considéré comme l'un des meilleurs romans de King, "Shining, l'enfant lumière" étudie la désintégration de la cellule familiale à travers l'isolement, la folie et l'alcoolisme, ce dernier facteur reflétant de façon inconsciente les problèmes de King avec la boisson. Le roman se vend la première année à environ en édition cartonnée et dépasse légèrement les ventes de "Salem" en édition de poche. Il entre brièvement sur la liste des best-sellers du "New York Times", tous les romans de King allant devenir des best-sellers à partir de ce moment, à l'exclusion de ceux parus en édition limitée ou sous son pseudonyme.

King se crée en effet le pseudonyme de Richard Bachman d'une part car les standards de l'édition de l'époque ne permettent pas à un auteur de publier plus d'un livre par an, et d'autre part pour se libérer de la pression que sa notoriété grandissante lui apporte désormais. Le premier roman qu'il publie sous son pseudonyme, et qui sort directement en édition de poche en septembre 1977, dans l'indifférence générale, est "Rage", roman de jeunesse entamé en grande partie au lycée et auquel il a mis la dernière main en 1971. Le sujet de ce drame psychologique est un lycéen qui abat son professeur, prend ses camarades de classe en otage et les pousse à confier publiquement ce qu'ils ont sur le cœur.

Toujours en 1977, King vend sa maison de Bridgton et emménage en Angleterre avec sa famille, qui comprend désormais un troisième enfant, Owen, né en février, dans le but d'y rester un an pour y écrire un roman se déroulant dans ce pays. Cette tentative est toutefois un échec et la famille King revient dans le Maine au bout de seulement trois mois, King achetant une maison à Lovell qui deviendra par la suite sa résidence estivale. Durant son bref séjour en Angleterre, il rencontre l'écrivain Peter Straub et les deux hommes sympathisent rapidement, évoquant une possible collaboration dans le futur.

En 1978, King accepte un poste de maître de cours offert par l'université du Maine et s'installe à Orrington pour un an. Cette année-là, deux nouveaux livres de King sont publiés par Doubleday. "Danse macabre", qui paraît en février, est un recueil de vingt nouvelles dont la plupart ont déjà été publiées dans divers magazines. C'est ensuite "Le Fléau" qui paraît au mois de septembre. Roman épique et post-apocalyptique dans lequel la quasi-totalité de la population meurt à la suite d'une pandémie de grippe créée en laboratoire et où les survivants sont ensuite irrésistiblement attirés par deux puissances opposées pour reproduire la lutte éternelle du Bien contre le Mal, "le Fléau" est l'une des œuvres les plus ambitieuses de King et est considérée comme l'un de ses chefs-d'œuvre. Doubleday ayant jugé le roman trop volumineux, King doit opérer d'importantes coupures, supprimant environ . Les ventes du "Fléau" connaissent un niveau comparable à celles de "Shining, l'enfant lumière".

"Marche ou crève", le deuxième roman de King édité sous son pseudonyme de Richard Bachman, est publié en édition de poche en . Écrit dix ans auparavant, c'est un récit dystopique dans lequel les États-Unis sont devenus une dictature militaire et où une grande marche réunissant cent jeunes gens est organisée annuellement, la fortune étant promise au dernier marcheur survivant. Il est souvent considéré comme le meilleur roman publié sous le pseudonyme de Bachman. Un mois plus tard, c'est au tour de "Dead Zone" de sortir en librairie. Premier livre publié chez le nouvel éditeur de King, Viking Press, "Dead Zone" présente un contenu nettement moins horrifique que les précédents romans que l'auteur a publiés sous son nom et narre l'histoire de Johnny Smith, un enseignant qui se réveille d'un long coma avec le don de voir le passé ou le futur des gens par un simple contact. Ce don tourne peu à peu à la malédiction et provoque chez le héros un dilemme moral quand il découvre qu'un politicien en pleine ascension va être dans le futur responsable d'un désastre à grande échelle. "Dead Zone" se vend à la première année et est le premier roman de King à parvenir à la première place de la liste des best-sellers du "New York Times".

Stephen King continue d'écrire à un rythme effréné et son roman suivant, "Charlie", sort en . Dans ce livre, Andrew McGee et sa fille Charlie, dotée d'un pouvoir de pyrokinésie, sont traqués par une agence secrète gouvernementale qui veut étudier le pouvoir de la petite fille, King exprimant dans ce roman toute la méfiance qu'il éprouve envers le gouvernement américain. Ce roman confirme que King est désormais l'une des valeurs sûres du milieu de l'édition avec une nouvelle première place sur la liste des best-sellers du "New York Times" et vendus la première année. La même année, il achète la "", une demeure victorienne de Bangor comportant 23 pièces et dont il fait sa résidence principale.

King publie trois nouveaux livres en 1981. "Chantier", qui paraît en mars sous le pseudonyme de Richard Bachman, est l'étude de l'obsession d'un homme refusant de quitter sa maison, qui doit être détruite pour permettre la construction d'une autoroute, et sombrant peu à peu dans la folie. Le mois suivant, l'écrivain publie son premier livre non-fictif, "Anatomie de l'horreur", dans lequel il étudie le genre horrifique à travers ses différents médias. Cet essai écrit dans son style narratif habituel remporte le prix Hugo et le prix Locus. Enfin, dans le roman "Cujo", édité en août, un énorme Saint-Bernard se fait inoculer le virus de la rage et se transforme en redoutable machine à tuer qui piège dans leur voiture une femme et son enfant. Ce livre ressemble à un roman de Bachman dans le sens où aucun élément fantastique n'y intervient et l'idée initiale de King était d'ailleurs de le publier sous son pseudonyme. "Cujo" se vend à la première année et remporte le prix British Fantasy.

Ce rythme élevé de trois parutions par an est maintenu en 1982. Comme l'année précédente, King publie un nouveau roman sous le pseudonyme de Bachman, "Running Man", qui paraît en mai et dont il a écrit la première version en une semaine au début des années 1970. Ce roman dystopique situé dans un futur proche met en scène un homme qui participe à un jeu télévisé dans lequel il doit échapper pendant un mois à des tueurs lancés à ses trousses, et représente la première incursion importante de King dans le domaine de la science-fiction. En juin, l'auteur publie, dans une édition limitée à , "Le Pistolero", court roman composé de cinq nouvelles publiées auparavant dans un magazine et qui est le premier volume du cycle de "La Tour sombre", épopée au croisement de plusieurs genres littéraires retraçant la longue quête de la mythique Tour sombre par le pistolero Roland de Gilead. Enfin, "Différentes Saisons", publié en août, est un recueil de quatre récits trop longs pour une nouvelle et trop courts pour un roman et dont seul le dernier comporte un élément surnaturel. Ces récits sont considérés comme les meilleures œuvres de taille intermédiaire de King, particulièrement "Le Corps", qui fait partie de ses fictions les plus autobiographiques. Malgré son format inhabituel, le livre est un succès commercial, parvenant à la première place de la liste des best-sellers du "New York Times".

King poursuit le même rythme de parution en 1983 avec trois nouveaux romans. "Christine", sorti en avril, qui narre l'histoire d'un adolescent tombant sous l'influence d'une Plymouth Fury modèle 1958 hantée par une présence maléfique, puis "Simetierre" et "L'Année du loup-garou", publiés tous deux en novembre. "L'Année du loup-garou" est un récit sur le thème de la lycanthropie paru en édition limitée. Il devait à l'origine être un calendrier avec des vignettes de écrites par King avant de se transformer en un court roman accompagné d’illustrations de Bernie Wrightson. Dans "Simetierre", Louis Creed est émotionnellement dévasté par la mort de son fils, âgé de deux ans, et décide de le ramener à la vie en l'enterrant dans un cimetière micmac que son voisin lui a fait découvrir. Roman sur la perte d'un enfant et l'idée que certaines choses sont pires que la mort, il est considéré comme le plus sombre ayant été écrit par King. L'écrivain, trouvant son histoire trop terrifiante, décide initialement de ne pas le publier avant de changer d'avis car son contrat avec Doubleday l'oblige à fournir encore un roman à son ancienne maison d'édition. Précédé par sa réputation, "Simetierre" est le plus grand succès commercial de King jusqu'alors, se vendant à la première année. "Christine" s'étant pour sa part vendu à , King classe pour la première fois deux de ses romans dans les dix meilleures ventes de fiction annuelles aux États-Unis avec la pour "Simetierre" et la pour "Christine".

En 1984, l'auteur aborde le genre de la fantasy avec la parution de deux romans, "Les Yeux du dragon" et "Le Talisman". "Les Yeux du dragon" est un conte pour enfants classique que King écrit pour sa fille Naomi après avoir réalisé qu'elle n'a jamais lu un de ses livres par manque de goût pour ses récits horrifiques. Il paraît en édition illustrée et limitée à chez "", petite maison d'édition fondée par King en 1982 pour pouvoir imprimer des livres destinés à ses relations. "Le Talisman", coécrit avec son ami Peter Straub, est la concrétisation d'un projet dont les deux hommes discutaient depuis plusieurs années. Mêlant fantasy et horreur, il retrace la quête initiatique du jeune Jack Sawyer, qui voyage à travers les États-Unis ainsi que dans un univers parallèle où la magie a remplacé la science pour trouver le talisman seul capable de sauver sa mère. Bénéficiant d'une promotion de grande envergure de la part de Viking Press, "le Talisman", sorti le 8 novembre, se vend à en moins de deux mois et se classe en tête des meilleures ventes de fiction aux États-Unis en 1984.

"La Peau sur les os", cinquième roman publié sous le pseudonyme de Richard Bachman, sort quelques jours après "le Talisman". Ce roman, dans lequel un homme est frappé par une malédiction qui lui fait perdre par jour, est le premier signé Bachman à sortir en édition cartonnée ainsi que le premier publié sous ce pseudonyme à faire intervenir un élément surnaturel. Les similitudes de "la Peau sur les os" avec les romans de King attirent l'attention des spécialistes et Steve Brown, un employé de librairie, découvre la supercherie en examinant les formulaires de copyright de la Bibliothèque du Congrès. En , Brown écrit une lettre à King dans laquelle il lui annonce sa découverte et son intention de tout dévoiler publiquement, et l'écrivain le prend alors de vitesse en avouant en février que Bachman et lui sont la même personne. Les ventes de "la Peau sur les os" explosent, passant en quelques semaines de à .

King publie "Brume", un recueil de nouvelles composé de vingt textes, le . "Brume" est souvent perçu comme contenant bon nombre des meilleures nouvelles de l'écrivain, la nouvelle homonyme et "Le Chenal", qui a remporté le prix World Fantasy de la meilleure nouvelle en 1982, étant particulièrement mises en avant. Le livre reste neuf semaines consécutives à la première place de la liste des best-sellers du "New York Times", fait sans précédent pour un recueil de nouvelles, et remporte le prix Locus du meilleur recueil de nouvelles. En octobre, et pour répondre à l'énorme demande du public qui n'arrive pas à se les procurer, les quatre premiers romans de Richard Bachman sont publiés en un seul volume sous le nom de '. C'est à cette époque que la popularité de King atteint des sommets et que l'écrivain devient un phénomène médiatique. Dans la semaine du 17 au 24 novembre 1985, il établit un nouveau record en plaçant cinq de ses livres sur la liste des best-sellers.

"Ça", le roman suivant de King, est publié le et confirme la popularité de l'écrivain. Pour la première fois dans l'histoire de l'édition, le premier tirage d'un roman atteint le chiffre d'un million d'exemplaires. Condensé de tout ce que l'écrivain sait de l'horreur et de l'enfance, "Ça" retrace la lutte entre sept enfants, puis adultes, et une entité maléfique qui prend la forme des peurs les plus profondes de ses victimes. Roman complexe qui est le plus long publié par King jusqu'alors, il suit une structure de narration non linéaire en alternant entre deux périodes de temps principales ainsi qu'entre les différentes perspectives des personnages principaux, et est généralement considéré comme l'un de ses chefs-d'œuvre. "Ça" se classe en tête des meilleures ventes de fiction aux États-Unis en 1986 et remporte le prix British Fantasy.

En , une version légèrement remaniée des "Yeux du dragon" est publiée par Viking Press, l'éditeur habituel de King. Ce roman très éloigné du style et du genre habituels de l'écrivain devient néanmoins lui aussi un best-seller avec plus de vendus la première année. Trois nouveaux romans de King sont édités la même année. "Les Trois Cartes", de "la Tour sombre" dans lequel Roland de Gilead se rend à New York à trois époques différentes pour en ramener des compagnons de quête, sort en mai et toujours en édition limitée. "Misery", huis clos dans lequel un écrivain est, après un grave accident, recueilli et séquestré par une admiratrice schizophrène qui l'oblige à écrire un roman pour elle, paraît le mois suivant. Commencé en 1984, ce roman exempt de toute trace de surnaturel était à l'origine prévu pour être publié sous le pseudonyme de Bachman avant que King ne soit obligé de changer ses plans à la suite de la révélation de son identité secrète. "Misery" remporte la première édition du prix Bram-Stoker. Enfin, "Les Tommyknockers" est publié en novembre. King mêle horreur et science-fiction dans ce long roman où un vaisseau extraterrestre exerce son influence néfaste sur les habitants d'une petite ville lorsqu'il est déterré. "Les Tommyknockers" et "Misery" sont deux nouveaux best-sellers qui se classent respectivement aux première et quatrième places des meilleures ventes de fiction aux États-Unis en 1987.

Écrits en grande partie en 1985 et 1986, "Misery" et "les Tommyknockers" sont aussi une métaphore de l'addiction de King à cette époque. À sa dépendance à l'alcool, l'écrivain a en effet désormais ajouté une dépendance à la cocaïne et aux médicaments. Réalisant à quel point la condition de son mari se dégrade, Tabitha intervient pour lui faire prendre conscience de la situation. Réunissant ses proches, elle vide devant lui un sac contenant les restes de sa consommation récente de drogues et d'alcool et lui donne le choix : se faire soigner ou quitter la maison. Mis devant ses responsabilités, King part suivre une cure de désintoxication. Il cesse toute forme de consommation de drogue et demeure sobre par la suite. Cette épreuve interrompt néanmoins son activité créatrice et il a beaucoup de mal à retrouver son rythme, connaissant un blocage de l'écrivain de presque un an auquel il met fin en complétant la nouvelle "La Saison des pluies".

La conséquence directe de cette pause créative forcée est qu'aucun nouveau livre de King ne sort en 1988, à l'exception de "", un livre de photographies de gargouilles avec des textes accompagnateurs de King. Son premier véritable livre à paraître depuis "les Tommyknockers" est le roman "La Part des ténèbres", publié le , dans lequel le pseudonyme d'un écrivain prend vie et cherche à s'emparer de celle de son créateur. "La Part des ténèbres" est directement inspiré par l'expérience vécue par King avec Richard Bachman, son « double littéraire ». Deux ans après son dernier succès, King quitte les années 1980 avec un nouveau best-seller, au classement des meilleures ventes de fiction aux États-Unis en 1989.

Après de longues négociations avec son ancien éditeur Doubleday, il est enfin libre de publier "Le Fléau" sous la forme qu'il souhaitait. Une nouvelle édition du roman, comprenant environ cent cinquante mille mots supplémentaires, ce qui en fait le livre le plus long de King, et réactualisée sur le plan des références culturelles et politiques, est éditée le . Les ajouts introduisent plus de variations de rythme, enrichissent la psychologie des personnages, intègrent deux longs passages certainement supprimés en 1978 pour cause de censure, et solidifient la conclusion du roman. En septembre 1990, c'est un deuxième recueil de quatre récits de taille intermédiaire qui paraît. ', "Minuit 2" et "Minuit 4" dans l'édition française, est néanmoins très différent de "Différentes Saisons" car les histoires qui le composent se placent résolument dans les genres fantastique et horrifique. Ce recueil remporte le prix Bram-Stoker dans sa catégorie. ' / "" et la nouvelle édition du "Fléau" se classent respectivement aux et des meilleures ventes de fiction aux États-Unis en 1990.

Ayant retrouvé son rythme d'écriture, King publie deux nouveaux romans en 1991. "Terres perdues", publié en août dans une édition limitée à trente mille exemplaires, est le troisième volume du cycle de "La Tour sombre". Le petit groupe de pistoleros formé par Roland de Gilead s'y retrouve désormais au complet et se lance sur ce qui constitue la première étape de sa quête dans un monde post-apocalyptique. Dans "Bazaar", édité en octobre, King fait ses adieux à la petite ville de Castle Rock, apparue pour la première fois dans "" et dans plusieurs de ses récits depuis lors, en l'entraînant dans une spirale de violence et de destruction provoquée par les manigances du mystérieux propriétaire d'un nouveau magasin. Avec ce roman se terminant de façon cataclysmique pour Castle Rock, King semble vouloir tourner une page de sa carrière.

Avec ses deux romans suivants parus en 1992, "Jessie" et "Dolores Claiborne", les deux premiers volets d'une , King confirme ce sentiment en prenant ses distances avec le genre qui a fait sa gloire. "Jessie", huis clos psychologique où l'héroïne est menottée à un lit pendant l'essentiel du récit, et "Dolores Claiborne", écrit sous la forme d'un monologue ininterrompu où une femme avoue le meurtre de son mari abusif, sont deux portraits de femmes qui se libèrent chacune à leur manière de la domination masculine. De cette trilogie, poursuivie plus tard avec "Rose Madder", "Dolores Claiborne" est généralement considéré comme le roman le plus abouti. Bien qu'ils soient, à l'exception d'une scène commune, dépourvus de tout élément surnaturel, les lecteurs de King lui demeurent indéfectiblement fidèles, "Dolores Claiborne" et "Jessie" parvenant tous deux à la première place de la liste des best-sellers du "New York Times" et se classant respectivement aux première et troisième places des meilleures ventes de fiction aux États-Unis en 1992.

Après "Rêves et Cauchemars", un recueil de vingt-deux nouvelles et de deux textes sur le baseball, supprimés de la version en français, publié en , King continue à surprendre ses lecteurs avec son nouveau roman. "Insomnie", édité en , est en effet un roman méditatif au rythme lent et dont les personnages principaux sont deux personnes âgées souffrant d'insomnies et de visions impliquant trois êtres rappelant les Parques. Le roman prend une autre tournure quand l'écrivain vient y greffer un débat social, le droit à l'avortement, et le relie de façon prononcée au cycle de "la Tour sombre". King publie ensuite le troisième volet de sa , "Rose Madder", en . Ce roman aborde directement le thème de la violence conjugale avec son héroïne qui, après des années de sévices, cherche à refaire sa vie loin de son mari, un policier sadique qui entend la retrouver. L'élément fantastique est introduit au milieu du récit par le biais d'un tableau qui est un portail vers un univers parallèle. Bien que ces trois livres se classent dans les dix meilleures ventes annuelles de fiction aux États-Unis, ils ne connaissent pas le succès obtenu par la plupart de leurs prédécesseurs depuis le début des années 1980 et King semble sur le déclin, le magazine "Entertainment Weekly" soulignant sa baisse de popularité.

King retrouve cependant les sommets dès 1996. Sa nouvelle "L'Homme au costume noir", qui narre la rencontre d'un jeune garçon avec le Diable, remporte cette année le prestigieux O. Henry Award, récompensant la meilleure nouvelle parue dans la presse nord-américaine l'année précédente, après avoir également obtenu le prix World Fantasy de la meilleure nouvelle. L'écrivain se lance ensuite dans deux concepts originaux. Il remet tout d'abord à l'honneur le genre du roman-feuilleton, tombé en désuétude, en publiant en édition de poche les six épisodes de "La Ligne verte" au rythme d'un épisode par mois entre mars et août 1996. "La Ligne verte", dont l'action se situe dans les années 1930, a pour cadre le quartier réservé aux condamnés à mort d'un pénitencier où est enfermé John Caffey, accusé du viol et du meurtre de deux fillettes et doté d'un pouvoir curateur. King continue à mettre en avant des thèmes sociaux en y dénonçant le racisme et la peine de mort.

Ses deux romans suivants, "Désolation" et "Les Régulateurs", ce dernier étant publié sous le nom de Richard Bachman, sortent simultanément le 24 septembre 1996. Les deux livres mettent en scène des personnages portant les mêmes noms et qui sont confrontés au même adversaire, une force maléfique nommée Tak, mais dans des situations et des décors radicalement différents. Dans le « match » opposant King à Bachman, c'est le premier qui sort vainqueur, "Désolation" devançant "les Régulateurs" au classement des meilleures ventes de fiction aux États-Unis en 1996 avec une contre une et étant mieux accueilli par la critique. L'écrivain américain établit cette année-là un nouveau record en plaçant huit livres sur la liste des best-sellers du "New York Times". "La Ligne verte" remporte par ailleurs le prix Bram-Stoker alors que "Désolation" est le lauréat du prix Locus du meilleur roman d'horreur.

"Magie et Cristal", le quatrième volume de "la Tour sombre", est publié le en édition limitée à quarante mille exemplaires et revient en grande partie sur un épisode crucial de la jeunesse de Roland de Gilead. À la même période, King change de maison d'édition pour la deuxième fois de sa carrière et signe un contrat avec Scribner après vingt ans de collaboration avec Viking Press. Mais l'avocat qui lui tient lieu d'agent littéraire depuis 1988 négocie ce nouveau contrat avec fracas, attirant l'attention du milieu de l'édition en demandant dix-sept millions de dollars d'à-valoir pour le prochain roman de King. Ce dernier, gêné par le battage médiatique, renonce à cette considérable avance sur droits d'auteur pour devenir à la place le partenaire de Scribner en négociant une avance de deux millions de dollars par livre et un partage à 50 % des profits. Le premier roman publié chez Scribner est "Sac d'os", qui paraît le . À travers son personnage principal, un écrivain, veuf depuis peu, qui doit simultanément faire face à des fantômes hantant sa résidence et à un multimillionnaire qui veut séparer une mère de son enfant, King y évoque certains aspects de son métier. Cette , comme l'appelle King, est généralement considérée comme faisant partie de ses meilleures œuvres. "Sac d'os" est aussi son premier livre à remporter trois prix majeurs, le prix Bram-Stoker, le prix British Fantasy et le prix Locus, et se classe à la troisième place des meilleures ventes de fiction aux États-Unis en 1998.

En 1999, King publie deux nouveaux livres. Dans "La Petite Fille qui aimait Tom Gordon", édité en avril, une petite fille se perd dans les bois du Maine et cherche à retrouver la civilisation en puisant du réconfort dans le joueur de baseball des Red Sox de Boston Tom Gordon qui devient son ami imaginaire. "Cœurs perdus en Atlantide", publié en septembre, est un recueil de nouvelles assez particulier, les cinq récits le composant, dont deux constituent la plus grande partie du livre, étant reliés par le personnage de Carol Gerber, qui sert de fil rouge. Avec ce recueil, King revient sur les années 1960 et la guerre du Viêt Nam, un sujet qu'il voulait évoquer depuis longtemps, et intègre le seul élément fantastique à travers le pouvoir psychique du personnage de Ted Brautigan, qui fera sa réapparition dans le dernier volume de "la Tour sombre". "Cœurs perdus en Atlantide" et "La Petite Fille qui aimait Tom Gordon", deux livres au contenu très peu horrifique, se classent respectivement aux sixième et huitième places des meilleures ventes de fiction aux États-Unis en 1999.

Entre la publication de ces deux livres, la vie de Stephen King a toutefois radicalement changé. Il est en effet victime d'un grave accident survenu à proximité de sa maison de Lovell le samedi . Alors qu'il marche sur le bord de la route, il est renversé par une camionnette dont le conducteur, Bryan Smith, est distrait par son chien se trouvant sur le siège arrière. Souffrant de nombreuses fractures, neuf à la jambe droite et une au col du fémur, d'un poumon perforé et de quatre côtes cassées, il reste hospitalisé trois semaines durant lesquelles il subit cinq interventions chirurgicales. Il sort de l'hôpital le 9 juillet et se remet à écrire le 24 du même mois, les premières séances étant très laborieuses en raison de la douleur constante qu'il éprouve à rester longtemps en position assise mais l'écriture ayant à moyen terme un effet thérapeutique. King rachète le véhicule à l'origine de cet accident pour le détruire afin qu'il ne puisse pas être revendu sur des sites de ventes aux enchères à des fans trop intéressés par sa « proximité tragique » avec leur auteur favori. À la suite de cet accident, il achète une maison à Sarasota, en Floride, afin de passer l'hiver sous un climat plus favorable à son état de santé.

King commence les années 2000 en étant l'un des premiers écrivains à explorer le marché du livre numérique. En mars, il publie sous ce format la nouvelle "Un tour sur le Bolid'", écrite pendant sa convalescence. L'expérience est une grande réussite avec le premier jour et une demande qui demeure élevée pendant plusieurs semaines, faisant de ce le premier best-seller numérique. Encouragé par ce succès, l'écrivain va plus loin en proposant de télécharger le premier chapitre du roman "The Plant" de son site web et de payer de façon optionnelle, l'écrivain s'engageant à continuer tant qu'un nombre suffisant de lecteurs acceptent de payer. Les trois premiers chapitres de "The Plant" ont été écrits entre 1982 et 1985 et distribués par King à ses relations pour Noël avant que l'écrivain n'abandonne l'histoire après avoir réalisé qu'elle se rapprochait trop de "La Petite Boutique des horreurs". Entre juillet et décembre 2000, il remanie puis écrit six chapitres du récit au rythme d'un par mois mais le nombre de lecteurs payants diminue progressivement et l'écrivain finit par abandonner le projet.

"", livre qui tient à la fois de l'essai sur l'art d'écrire et de l'autobiographie et sur lequel King travaillait déjà avant son accident, est publié le . Ce livre remporte le prix Bram-Stoker et le prix Locus dans sa catégorie. En 2001, King publie deux romans qui sont les premiers à avoir été entièrement écrits après son accident. "Dreamcatcher", qui paraît en mars, mêle horreur et science-fiction, les victimes d'un virus extraterrestre développant à l'intérieur de leur corps des créatures qui les tuent en arrivant à maturité. "Territoires", édité en septembre, est la deuxième collaboration de King avec Peter Straub et reprend le personnage principal du "Talisman" vingt ans après les événements de ce roman. King y établit plusieurs connexions avec "La Tour sombre". "Dreamcatcher" et "Territoires" se classent respectivement aux et des meilleures ventes de fiction aux États-Unis en 2001.

En 2002, King annonce qu'il va prendre sa retraite d'écrivain après avoir terminé le cycle de "la Tour sombre" en raison du sentiment qu'il éprouve de se répéter et des douleurs engendrées par les séquelles de ses blessures. Il renonce à ce projet, mais ralentit néanmoins son rythme d'écriture. Deux livres sortent cette année-là. "Tout est fatal", paru en mars, est un recueil de 14 nouvelles dont la grande majorité ont été écrites dans la deuxième moitié des années 1990. "Roadmaster", publié en septembre, est l'histoire d'un étrange véhicule entreposé dans un hangar par les policiers d'une petite ville. Ce roman dont le premier jet a été écrit par King avant son accident est moins bien accueilli que la plupart de ses livres. Même s'il occupe pendant une semaine la place de la liste des best-sellers du "New York Times", il n'intègre pas les dix meilleures ventes annuelles de fiction aux États-Unis, première fois que cela arrive à un roman de King, à l'exception de ceux parus en édition limitée ou sous le pseudonyme de Richard Bachman, depuis la première édition du "Fléau" en 1978.

Depuis , King partage environ toutes les trois semaines ses opinions sur la culture populaire dans une colonne de l"Entertainment Weekly" appelée ' (« La Pop de King »). En novembre, il reçoit le National Book Award, prestigieuse récompense de la National Book Foundation, pour sa remarquable contribution à la littérature américaine, ce qui provoque quelques remous dans le milieu académique. Environ à la même période, il souffre d'une pneumonie, causée indirectement par son accident qui a fragilisé son poumon, et met plusieurs mois à s'en remettre.

King s'est entretemps attaché à terminer le cycle de "la Tour sombre", commençant par remanier le premier volume, "Le Pistolero", pour le rendre plus cohérent avec les tomes ultérieurs. "Les Loups de la Calla", édité en novembre 2003, est inspiré par le western de John Sturges "Les Sept Mercenaires". Les deux tomes concluant la saga, "Le Chant de Susannah" et "La Tour sombre", sont publiés en juin et septembre 2004 et voient la quête de Roland de Gilead et de ses compagnons parvenir à son terme. King s'y adonne à la métafiction en se mettant en scène comme personnage, relatant notamment son accident sous la forme de fiction, mais de façon assez fidèle, dans le dernier volume. Le du cycle, au titre homonyme, remporte le prix British Fantasy.

L'écrivain américain change ensuite complètement de genre avec la publication de "Colorado Kid", un roman policier dans lequel deux vieux journalistes content à leur jeune stagiaire l'affaire la plus mystérieuse de leur longue carrière. Ce court roman paraît directement en édition de poche le . L'année suivante, King revient à son genre de prédilection avec "Cellulaire", publié en , et dans lequel un signal transmis via les téléphones portables contamine les gens et les transforme en fous furieux assoiffés de sang. Ce roman est à la fois un hommage aux films de zombies et une attaque directe contre l'utilisation massive des téléphones portables. "Histoire de Lisey", paru en octobre 2006, présente un contenu nettement moins horrifique et est considéré par son auteur comme le meilleur livre qu'il ait écrit. Inspiré par la pneumonie qui l'a atteint en 2003, ce roman met en scène la veuve d'un écrivain qui suit un jeu de pistes post-mortem laissé par son défunt mari, qui était à la fois affligé d'une malédiction familiale et doté d'un don bien particulier, tout en étant harcelée par un déséquilibré. "Histoire de Lisey" et "Cellulaire" se classent respectivement aux et des meilleures ventes de fiction aux États-Unis en 2006, et "Histoire de Lisey" remporte par ailleurs le prix Bram-Stoker.

Le , King reçoit le titre de de la Mystery Writers of America à l'occasion de la des prix Edgar-Allan-Poe. En juin, il publie sous son pseudonyme de Richard Bachman le roman "Blaze". Écrit au début des années 1970, c'est un roman à suspense psychologique, hommage littéraire à "Des souris et des hommes", où un kidnappeur légèrement attardé se prend d'affection pour l'enfant qu'il a enlevé. King le remanie profondément avant de le soumettre à la publication. Le roman suivant, "Duma Key", paraît en . Premier roman de King qui a pour cadre principal la Floride, son histoire est celle d'un homme qui s'installe sur un key après un grave accident et qui peint des tableaux, en rapport avec le passé trouble de l'île, qui peuvent altérer la réalité. Quelques mois plus tard, en novembre, il publie "Juste avant le crépuscule", un recueil de treize nouvelles écrites, à une exception près, au cours de la décennie écoulée. "Duma Key" et "Juste avant le crépuscule" remportent tous deux le prix Bram-Stoker dans leurs catégories respectives.

En , l'auteur renoue avec le marché du livre numérique en publiant une nouvelle, "Ur", à l'occasion du lancement de la deuxième génération de l'Amazon Kindle et disponible uniquement sur le site Amazon.com. Cette nouvelle présente un Kindle ayant une fonction de recherche dans des univers parallèles. King coécrit également avec son fils Joe Hill une autre nouvelle, "Plein Gaz", à l'occasion d'une anthologie rendant hommage à Richard Matheson. Le paraît le roman "Dôme", un projet que King a par deux fois déjà abandonné dans le passé et qui est son troisième livre le plus volumineux après "le Fléau" et "Ça". Dans ce roman allégorique sur des questions écologiques et politiques, une petite ville est brusquement coupée du reste du monde par un dôme transparent et infranchissable.

En 2010, King coscénarise avec Scott Snyder les cinq premiers numéros de la série de comics "American Vampire". En novembre de la même année, il publie "Nuit noire, étoiles mortes", son troisième recueil de quatre récits de taille intermédiaire, dont un seul relève du genre fantastique. Ce livre remporte le prix Bram-Stoker ainsi que le prix British Fantasy du meilleur recueil. "22/11/63", le roman suivant, paraît le , après avoir demandé un travail de recherches en amont bien plus important que l'écrivain n'en a l'habitude. Dans ce thriller uchronique que King avait l'intention d'écrire depuis le début de sa carrière, un enseignant remonte le temps par l'intermédiaire d'un portail qui conduit en 1958 dans le but d'empêcher l'assassinat de John Fitzgerald Kennedy. Ce roman est le plus grand succès commercial de King depuis "Sac d'os", avec quatre semaines passées à la place de la liste des best-sellers du "New York Times" et une au classement des meilleures ventes de fiction aux États-Unis en 2011 avec plus de vendus.

L'écrivain retrouve ensuite l'univers de "La Tour sombre" avec "La Clé des vents", le du cycle, dont les événements se situent entre "Magie et Cristal" et "Les Loups de la Calla", et qui est publié en . Il utilise pour ce livre la technique du récit dans le récit, le récit encadrant cédant rapidement la place à une histoire de jeunesse de Roland de Gilead au cours de laquelle il conte une autre histoire, l'essentiel du roman, à un jeune garçon. Il collabore ensuite à nouveau avec son fils Joe Hill pour l'écriture de la nouvelle "", publiée en deux parties dans un magazine pendant l'été 2012.

En 2013, King publie deux nouveaux romans. Il renoue tout d'abord avec le roman policier avec "Joyland", paru le 4 juin directement en édition de poche, qui met en scène un jeune employé d'un parc d'attractions se lançant sur la piste d'un tueur en série ayant sévi dans ce parc. "Docteur Sleep", roman qui reprend le personnage de Danny Torrance, le jeune héros de "Shining, l'enfant lumière" désormais adulte, en le mettant aux prises avec un groupe d'immortels se nourrissant d'enfants possédant le même don que lui, est édité le 24 septembre. Pour assurer la promotion de ce roman très attendu, l'écrivain américain se rend pour la première fois en France et en Allemagne et y donne plusieurs interviews et conférences. "Docteur Sleep" remporte le prix Bram-Stoker et se classe à la des meilleures ventes de fiction aux États-Unis en 2013 avec plus de vendus.

Son livre suivant, publié le , est un autre roman policier, dont le titre est "Mr. Mercedes", dans lequel un criminel qui a tué plusieurs personnes en les écrasant avec sa voiture nargue le policier à la retraite qui était chargé de l'affaire et prépare un nouvel attentat encore plus meurtrier. Ce roman, lauréat du prix Edgar-Allan-Poe, est le premier d'une trilogie centrée sur le personnage de Bill Hodges, policier à la retraite. Le second volume, dont le titre est "Carnets noirs", sort le et traite d'un admirateur déséquilibré qui assassine un écrivain et tente, plusieurs années plus tard, de récupérer son carnet de notes inédites. Entre ces deux ouvrages, le , King publie "", roman dans lequel un guitariste retrouve un ancien pasteur fasciné par l'électricité qui a renié Dieu à la suite d'un terrible drame familial, et devient son assistant pour une ultime expérience. Ce roman aborde les thèmes du fanatisme religieux, de l'addiction et de la musique.

Le 10 septembre 2015, King est reçu à la Maison-Blanche pour y être décoré de la National Medal of Arts, la plus haute distinction accordée par le gouvernement américain à des artistes. Son nouveau recueil de nouvelles, intitulé "Le Bazar des mauvais rêves" et composé de vingt textes, est publié le . L'écrivain termine ensuite sa trilogie sur Bill Hodges en confrontant à nouveau l'ancien policier au tueur à la Mercedes dans "Fin de ronde", publié le .

2017 est une année placée sous le signe de la collaboration. Il coécrit avec Richard Chizmar la novella "", publiée en mai, puis avec son fils Owen le roman "Sleeping Beauties", publié en septembre. Dans ce roman, une étrange épidémie plonge les femmes dans un profond sommeil durant lequel elles sont enveloppées d'un cocon. Le , il publiera chez Scribner le roman "The Outsider".

Stephen King vit avec sa femme Tabitha qu'il a épousée le et avec laquelle il a eu trois enfants prénommés Naomi (née le ), Joe (né le ) et Owen (né le ), les deux derniers étant également écrivains. Stephen King a été élevé dans la religion méthodiste et affirme qu'il croit en Dieu mais n'a pas besoin de religion organisée. Il possède et occupe trois maisons suivant les époques de l'année : une à Bangor dans le Maine, une à Lovell dans le Maine et une à Sarasota en Floride, où il passe l'hiver. Il est propriétaire de deux stations de radio à Bangor : WZON, station d'informations sportives retransmettant les rencontres locales, et WKIT, station de rock classique. Atteint d'une prédisposition génétique à la dégénérescence rétinienne, il évoque la possibilité de devenir aveugle.

Stephen King s'intéresse au baseball depuis son enfance et est devenu un fan inconditionnel de l'équipe des Red Sox de Boston en 1967. Il assiste fréquemment à leurs matchs, tant à domicile qu'à l'extérieur.

En 1989, King est entraîneur assistant de l'équipe de baseball de son fils Owen, la , qui évolue dans la du Maine et qui remporte cette année-là le championnat de l'État. Il raconte son expérience dans ', un essai paru dans le "New Yorker" et dans la version américaine de "Rêves et Cauchemars". Dans ce même recueil se trouve un deuxième texte en rapport avec le baseball, ', un poème qui ne fut également pas traduit dans la version française du recueil. En 1992, Stephen King offre à la ville de Bangor pour la construction d'un terrain de baseball pour les équipes de jeunes. Ce terrain est baptisé officiellement ', en hommage au fils d'un entraîneur local mort d'une méningite, mais est plus connu sous le surnom de ' (« Terrain des hurlements »).

Son roman "La Petite Fille qui aimait Tom Gordon", paru en 1999, présente une jeune protagoniste qui est elle-aussi une fanatique des Red Sox et qui perdue en forêt, maintient un lien avec la civilisation en écoutant les matchs de l'équipe sur sa radio portable, suivant en particulier les exploits de son joueur favori, le lanceur de relève Tom Gordon. En 2004, King coécrit avec Stewart O'Nan ', retraçant la saison 2004 des Red Sox jusqu'à leur victoire en Série mondiale de baseball, la première pour l'équipe depuis 1918. En 2005, il apparaît dans le film "Terrain d'entente" (') où il lance la première balle de la journée d'ouverture de la saison. En , il publie un court roman, "Billy Barrage", dont le personnage principal est un joueur de baseball détenteur d'un terrible secret.

L'écrivain est également un passionné de la marque de motos Harley-Davidson. À l'automne 1994, il traverse les États-Unis avec sa Harley à l'occasion de la tournée promotionnelle du roman "Insomnie", s'arrêtant dans dix villes, du Vermont à la Californie, pour des séances de dédicaces dans des librairies indépendantes. En novembre 1997, il passe ses vacances en traversant l'Australie en Harley de Sydney jusqu'à Perth.

Musicien amateur, King joue de la guitare dans un petit groupe, ', alors qu'il est étudiant à l'université du Maine. Plus de vingt ans plus tard, devenu célèbre, il assure la guitare rythmique au sein du groupe , créé en 1992 et presque uniquement composé d'écrivains, dont font également partie Matt Groening, Barbara Kingsolver, Al Kooper, Greil Marcus et Amy Tan. Le concert que le groupe donne en 1992, dans lequel il interprète des reprises de standards du rock 'n' roll des années 1950, a tellement de succès que King propose de faire une tournée de huit concerts en 1993, tournée relatée dans le livre ' (1994), écrit en commun par les membres de la formation. Le groupe se réunit par la suite à quelques occasions et donne son dernier concert en 2012.

King a également collaboré à plusieurs reprises avec des musiciens. En 1988, il enregistre une introduction pour une chanson de l'album-concept "Imaginos" du groupe Blue Öyster Cult. Il écrit dans les années 1990 la première version du scénario, profondément remaniée par la suite, du court-métrage "Ghosts" (1997) de Michael Jackson. En 2010, il réécrit les dialogues, dont il est le narrateur, de l'album-concept ' de Shooter Jennings. En 2012, il concrétise un projet plusieurs fois repoussé avec ', une comédie musicale dont il a écrit le livret avec une musique de John Mellencamp et une production de T-Bone Burnett. La comédie musicale est présentée pour la première fois sur scène à Atlanta en avril 2012, et le CD de " est sorti le 19 mars 2013.

Stephen King vote pour la première fois lors de l'élection présidentielle américaine de 1968 et apporte sa voix au candidat républicain Richard Nixon en croyant sa promesse selon laquelle il sortirait les États-Unis de la guerre du Viêt Nam. Voyant ses espoirs vite détrompés, il se tourne en moins d'un an vers le radicalisme contre la guerre, appelant dans ses articles les étudiants de l'université du Maine à la grève et faisant des comptes-rendus de manifestations pacifiques. Depuis cette époque, il soutient le parti démocrate. Il apporte notamment son soutien aux candidats Gary Hart durant la campagne présidentielle de 1984 puis Barack Obama durant celle de 2008. Pour celle de 2016, il soutient Hillary Clinton mais est beaucoup plus remarqué pour ses nombreux tweets contre le républicain Donald Trump.

En 1986, l'écrivain américain prend publiquement position contre la censure à l'occasion d'un référendum organisé dans le Maine sur l'interdiction à la vente de produits obscènes (par exemple les magazines pornographiques). King, dont plusieurs livres ont été retirés des bibliothèques scolaires à travers le pays, s'exprime à ce sujet dans les médias locaux et affronte le président de la du Maine, à l'origine du référendum, lors d'un débat radiophonique. Il fait notamment valoir l'argument que la définition de l'obscénité est particulièrement floue et que cette loi ouvrirait la porte à certaines dérives. La proposition de censure est rejetée à une large majorité.

Il s'est également exprimé à plusieurs reprises sur la législation des armes à feu aux États-Unis, faisant part de son désir de restreindre l'accès aux armes à feu. Dans son essai ", paru sous forme de livre numérique en , il milite pour l’interdiction de vendre et de posséder des armes automatiques et semi-automatiques.

En 2011, il prend la parole lors d'un rassemblement de protestation contre la politique budgétaire du gouverneur de Floride Rick Scott et exprime son rejet du mouvement Tea Party et son désir que la tranche d'imposition la plus haute, dont il fait partie, soit taxée à 50 % au lieu de 28 %. En mars 2015, il est accusé d'évasion fiscale par le gouverneur du Maine Paul LePage, à qui il s'est déjà plusieurs fois opposé. Il réfute l'accusation et révèle avoir payé 1,4 million de dollars d'impôts en 2014. L'annonce de LePage, qui s'est révélée erronée, est corrigée par le bureau du gouverneur.

Stephen King et sa femme Tabitha participent à de nombreuses œuvres philanthropiques dans le Maine. Ils fondent en 1986 la "" afin d'assister les déshérités de cet État, notamment dans les domaines de l'éducation et des soins médicaux. Par l'intermédiaire de la fondation, ils donnent chaque année 10 % de leurs revenus à diverses organisations, caritatives pour la plupart.

Parmi ses nombreux dons, l'écrivain a offert : plusieurs millions à la ', école privée de Milton où ses trois enfants ont étudié, pour la construction d'un théâtre baptisé ' en 1989 ; pour financer les travaux de construction d'une aile pour la bibliothèque publique de Bangor en 1989 ; pour permettre la création d'une nouvelle unité pédiatrique à l' de Bangor en 1992 ; pour la construction d'une piscine municipale, le ', à Bangor en 2004 ; afin d'aider les familles du Maine dans le besoin à payer les factures de chauffage en 2011 ; pour permettre la construction d'un toit pour la bibliothèque de Bangor en 2013.

Stephen King écrit dans son , publiée en 2000, qu'il s'est fixé un quota journalier de deux mille mots, environ dix pages, et ne s'arrête pas d'écrire tant qu'il ne l'a pas atteint, avouant par ailleurs qu'il était plus prolifique au début de sa carrière. En 2006, il affirme que son rythme d'écriture a encore diminué et qu'il est désormais plus proche des mille mots par jour. Il s'appuie sur une méthode de travail intuitive en partant d'une situation de départ et en écrivant spontanément, sans bâtir d'intrigue à l'avance, à l'exception de quelques romans comme "Dead Zone", "Insomnie" ou "Rose Madder". L'évolution des personnages détermine alors celle de l'histoire et sa conclusion, qui est souvent différente de celle qu'il a envisagée initialement. Après avoir terminé le premier jet du récit, il se sert ensuite de l'étape de relecture pour mettre en avant la thématique ou le symbolisme qu'il a repéré.

La principale qualité de Stephen King, reconnue même par ses détracteurs les plus acharnés, est son sens de la narration, son talent de conteur capable de captiver le lecteur à travers une histoire rendue très rapidement intéressante. Ses personnages vivants et colorés, qui prennent une identité bien définie en quelques phrases, et son aisance à susciter la frayeur en frappant l'imagination de ses lecteurs, font également partie de ses forces en tant qu'écrivain. Le réalisme de ses personnages et des situations qui les introduisent sont d'ailleurs un facteur déterminant dans sa réussite à faire accepter par ses lecteurs l'irruption de l'horreur.

À l'inverse, il lui est régulièrement reproché d'avoir écrit des romans trop longs qui auraient été bien meilleurs sous une forme plus condensée, comme "Les Tommyknockers" ou "Insomnie". Son style, notamment au début de sa carrière, a été qualifié par certains critiques de laborieux, voire de maladroit, et son recours à des scènes explicites pour provoquer la révulsion a également été critiqué. Sa méthode d'écriture intuitive est enfin la cause de conclusions parfois qualifiées de . Néanmoins, le style familier, les dialogues parfois vulgaires et le recours à des scènes choquantes sont totalement assumés par King, qui les justifie par un souci de réalisme et d'efficacité.

King crée un grand nombre d'interactions entre ses livres où certains faits, certains personnages se croisent ou se retrouvent d'un roman à un autre. "Dolores Claiborne" et "Jessie" en sont un exemple flagrant ainsi que le diptyque "Désolation" et "Les Régulateurs". Ses œuvres présentent également une unité géographique, la majorité se situant dans le Maine et la ville fictive de Castle Rock étant emblématique. Des histoires semblant souvent n'avoir aucun lien entre elles sont en fait liées par des personnages secondaires récurrents ou des références à des événements s'étant déroulés dans une histoire précédente, par exemple, le personnage de Cynthia reliant "Rose Madder" à "Désolation".

"La Tour sombre", constitué de huit volumes, est un cycle qui lui permet de lier tous ces romans à une seule réalité, constituée d'univers parallèles, et de donner à son œuvre une dimension épique plutôt que de considérer ses crossover comme anecdotiques. King qualifie d'ailleurs le cycle de . Bon nombre de ses romans font référence au cycle de "la Tour sombre" et vice-versa, souvent à travers des détails plus ou moins mineurs mais parfois de façon beaucoup plus essentielle, les connexions avec "Insomnie", "Cœurs perdus en Atlantide", "Salem" et "Territoires" étant les plus signifiantes. L'un des personnages de King qui revient le plus fréquemment est Randall Flagg, incarnation du mal dont la présence se décline sur plusieurs mondes parallèles ; il est ainsi l'homme en noir dans "La Tour sombre", le sorcier maléfique dans "Les Yeux du dragon", ainsi que le principal antagoniste du "Fléau" et, sans doute, de "Bazaar".

King interrompt régulièrement la narration, parfois au milieu d'une phrase, pour indiquer en italiques ou entre parenthèses les pensées d'un personnage ou un souvenir qui ressurgit, et use très souvent de comparaisons et de métaphores, donnant ainsi un style très visuel à sa narration. De plus, il intègre dans son récit de multiples références à la culture populaire et des détails précis, résultant de son observation de la société, dans un souci de réalisme et afin que le lecteur puisse aisément s'identifier au monde présenté.

Les romans publiés sous le nom de Richard Bachman se caractérisent par des éléments plus ancrés dans la réalité, une narration plus compressée qui traduit un sentiment d'urgence avec le temps qui passe ou un compte à rebours qui s'égrène, et un personnage principal qui poursuit une obsession. Bachman peut aussi être considéré comme , les quatre premiers romans publiés sous ce pseudonyme ayant comme point commun une forte connotation sociale et politique avec leur dénonciation du système éducatif, de l'esprit de compétition permanent, des pressions gouvernementales, de l'exclusion des marginaux et du pouvoir grandissant des médias.

Son œuvre est parsemée de références à l'histoire et à la culture américaines, et particulièrement leurs côtés les plus sombres. Elles apparaissent le plus souvent dans les histoires de ses personnages, étant un facteur d'explication de leurs peurs les plus primaires. La violence, en particulier la violence au sein de la cellule familiale, le racisme et les aspects négatifs de la nature humaine en général sont des thèmes récurrents dans ses œuvres, qui portent un regard quasiment naturaliste et dénué de complaisance sur la société américaine, et notamment la vie dans les petites villes.

Les livres de King se placent souvent dans le courant littéraire naturaliste qui part du principe que l'être humain est soumis à la destinée mais qu'il peut l'influencer dans une certaine part en prenant des décisions dictées par sa morale. L'élément le plus terrifiant, dans son œuvre, n'est pas l'intrusion du surnaturel mais le degré d'implication qu'elle exige de la part de l'humanité, ce qui met ainsi en lumière la vulnérabilité de nos institutions : le gouvernement, le système scolaire, les communautés locales et la cellule familiale.

Les personnages principaux sont très souvent des écrivains : Ben Mears dans "Salem", Bill Denbrough dans "Ça", Paul Sheldon dans "Misery", Thaddeus Beaumont dans "La Part des ténèbres", Mike Noonan dans "Sac d'os"… King expose divers aspects de son métier dans sa . Il évoque les rapports parfois délicats entre un écrivain et ses admirateurs dans "Misery" (1987), la puissante influence que peut exercer sur lui ses créations dans "La Part des ténèbres" (1989) et la hantise du plagiat dans "Vue imprenable sur jardin secret" (1990). Plus tard, il aborde également le blocage de l'écrivain et se livre à une satire du monde de l'édition dans "Sac d'os" (1998). À travers ses personnages écrivains, King étudie sous plusieurs facettes le qui unit l'auteur à ses créations, la frontière séparant la réalité de l'imaginaire, le , les mystères de l'inspiration et l'angoisse de perdre celle-ci.

L'enfance est également un thème majeur de l'œuvre de King, surtout dans ses premières œuvres, et les enfants jouent fréquemment des rôles essentiels dans ses histoires : "Shining, l'enfant lumière", "Charlie", "Le Talisman", "Ça", "Désolation"… La séparation entre le monde des adultes et celui des enfants est clairement établie et, dans les romans où des enfants ou des adolescents jouent les premiers rôles, les parents, et la famille en général, sont généralement définis comme ayant une influence destructrice sur leurs rejetons. Le thème de , au centre de la plupart des romans de King depuis "Carrie", trouve sa résolution dans "Ça", roman dans lequel l'auteur aborde tout ce qu'il voulait exprimer sur le sujet. L'écrivain brosse un portrait objectif de l'enfance, avec une prédilection pour la période qui s'étend de neuf à douze ans, en mêlant ses souvenirs personnels à son expérience de la paternité. L'enfance est souvent décrite comme un où l'imagination n'est pas encore limitée par les préoccupations du monde adulte mais aussi comme une période dangereuse où l'innocence est malmenée.

La confrontation entre le Bien et le Mal est l'un des thèmes récurrents de l'univers de King, comme dans "Le Fléau", le cycle de "la Tour sombre" et "Bazaar". L'œuvre étant essentiellement morale, le Bien triomphe la plupart du temps mais le Mal ne disparaît jamais vraiment et corrompt régulièrement l'humanité. Le Mal se concentre souvent dans un bâtiment qui en est son émanation directe, un , par exemple "" dans "Salem", l'hôtel dans "Shining, l'enfant lumière", l'hôtel noir dans "Le Talisman", la maison de Neibolt Street dans "Ça", et le manoir de dans "Terres perdues". La morale étant en Amérique indissociable de la religion, celle-ci est omniprésente dans l'œuvre à travers plusieurs aspects. Ainsi, le fanatisme de la mère de Carrie et de celle de Johnny Smith dans "Dead Zone", de madame Carmody dans "Brume" ou encore des enfants du maïs permet à l'auteur de dénoncer le puritanisme encore très présent dans certaines régions du pays. À l'inverse, les action de personnages comme la mère Abigaël et Tom Cullen dans "Le Fléau", David Carver dans "Désolation" et John Caffey dans "la Ligne verte" semblent même s'ils doivent consentir à de terribles sacrifices, une façon de souligner le paradoxe entre l'existence de Dieu et les événements effroyables qui se produisent sur Terre.

La méfiance envers la technologie et les institutions est lui aussi un thème récurrent. King se montre ainsi régulièrement préoccupé par la dépendance croissante de l'homme envers la technologie et le potentiel destructeur de cette dernière. L'accident technologique causé par une erreur humaine ou par malveillance et provoquant une catastrophe fait ainsi partie intégrante de récits tels que "Le Fléau", "Brume", "Le Talisman" et "Cellulaire". L’asservissement de l'homme envers la technologie figure quant à lui au centre de romans comme "Christine" et "Les Tommyknockers" et de nombreuses nouvelles ("Poids lourds", "La Presseuse", "Le Camion d'oncle Otto"…). La dénonciation de l'abus du pouvoir politique ou économique, souvent relié au thème de la technologie, est lui aussi une constante de l'œuvre. L'utilisation abusive du pouvoir politique est ainsi présent dans "Charlie", "Dead Zone", "Le Talisman" ou encore "Dôme", alors que les sirènes du capitalisme sont notamment dénoncées dans "Bazaar" et "".

Stephen King dit de Richard Matheson qu'il est . Les deux auteurs, entre autres parallèles stylistiques, intègrent régulièrement les pensées d'un personnage dans une narration à la troisième personne. La lecture de Matheson a notamment prouvé à King qu'un récit d'horreur pouvait tout à fait s'intégrer dans un cadre urbain, et même de proximité. À la suite de la disparition de Matheson, en , King lui a rendu un vibrant hommage.

Il doit son premier contact avec le fantastique à Ray Bradbury et s'est inspiré de ses récits dans ce genre, comme "La Foire des ténèbres" (1962), dont l'action se déroule dans une petite ville, affirmant que .

Il admire le travail de H. P. Lovecraft, dont l'influence se ressent par l'invention d'anciennes et étranges divinités et l'insertion dans le récit de coupures de presse ou d'autres documents comme instruments de narration. Sa nouvelle "Crouch End" est un hommage non déguisé au mythe de Cthulhu, et les nouvelles "Celui qui garde le ver" et "Mémé" font également particulièrement référence à Lovecraft. Cependant, King met l'accent sur les dialogues et la représentation des personnages, deux éléments notablement absents chez Lovecraft. King critique d'ailleurs ouvertement cette pauvreté des dialogues chez Lovecraft, prenant comme exemples des passages de "la Couleur tombée du ciel".

Edgar Allan Poe a exercé lui aussi une certaine influence sur le style de King. Il lui rend hommage dans "Shining, l'enfant lumière", avec des références au "Masque de la mort rouge", et surtout dans sa nouvelle "La Cadillac de Dolan" dont l'intrigue reprend celle de "La Barrique d'amontillado".

Il a déclaré son admiration pour Shirley Jackson. "Salem" s'ouvre sur une citation de "Maison Hantée", roman qui a également influencé la création de l'hôtel dans "Shining, l'enfant lumière" et de la bâtisse hantée de "Rose Red", alors qu'une scène décisive de "La Tempête du siècle" s'inspire de sa nouvelle "la Loterie".

Il a dédicacé sa nouvelle "le Molosse surgi du soleil" à John D. MacDonald qui, pour sa part, a écrit la préface de "Danse Macabre" et fait partie des auteurs de romans noirs qui ont le plus influencé King avec Raymond Chandler, James M. Cain et Ross Macdonald. La nouvelle "La Dernière Affaire d'Umney" est un pastiche des romans noirs se déroulant dans les années 1930.

Le roman "Sa Majesté des mouches" (1954), de William Golding, est l'un des préférés de King et est évoqué dans plusieurs de ses livres, notamment "Cœurs perdus en Atlantide". La ville de Castle Rock tire son nom d'un lieu de ce roman, qui l'a également influencé par son utilisation des personnages enfantins.

"Le Seigneur des anneaux" de J. R. R. Tolkien a exercé une grande influence sur l'écriture du "Fléau" et du cycle de "la Tour sombre", qui sont les deux œuvres de King les plus proches de l'épopée.

Parmi les écrivains « classiques » que King a étudié, et qui ont laissé leur empreinte sur son œuvre, se trouvent notamment les écrivains du courant naturaliste Thomas Hardy, Theodore Dreiser et surtout Frank Norris, dont il a repris le credo selon lequel un bon écrivain en s'attachant à ce que ses œuvres de fiction soient toujours . King a également clamé son admiration pour "La Bête humaine" (1890), d'Émile Zola, chef de file du naturalisme français. Il s'est par ailleurs inspiré de l'œuvre de William Faulkner, aussi bien au niveau de la narration, en imbriquant le passé avec le présent, que dans son utilisation d'une géographie régionale fictive très précise, la région de Castle Rock étant construite sur le modèle du comté de Yoknapatawpha.

L'horreur étant considéré comme un sous-genre littéraire par une grande partie des critiques et des universitaires, Stephen King a été rejeté d'emblée par ces milieux, et souvent même sans qu'ils n'aient lu un seul de ses romans. Cette situation commence néanmoins à changer dans les années 1990 quand un nombre de plus en plus important d'études sérieuses paraissent dans des publications universitaires alors que les critiques sont de plus en plus favorables. En 2008, à l'occasion de la sortie de "Duma Key", King explique ce revirement en partie par le fait que la plupart des critiques qui l'ont éreintés au début de sa carrière sont morts ou ont pris leur retraite et que la relève a grandi avec ses livres et est donc mieux disposée à son égard.

Une fraction importante des critiques et des universitaires continue néanmoins de penser que King, en tant qu'auteur « populaire » qui touche un très large public, ne mérite pas d'être pris en considération sur le plan de la valeur littéraire. La polémique déclenchée par le National Book Award lui ayant été décerné en 2003 illustre la division qui règne à son sujet parmi les intellectuels. Harold Bloom, critique littéraire connu pour ses attaques envers les écrivains connaissant un grand succès populaire, a notamment vu dans cette récompense une preuve supplémentaire de la décadence culturelle des États-Unis. Des écrivains acclamés par la critique ont pris publiquement la défense de King : Joyce Carol Oates, considérée pour le prix Nobel de littérature, l'a présenté dès 1997 comme un ; Michael Chabon, lauréat du prix Pulitzer, a affirmé après la lecture d"Histoire de Lisey", .

Dans les années 1980, Douglas E. Winter, critique littéraire, et Michael R. Collings, professeur de littérature à l'université Pepperdine, sont les premiers à s'intéresser de façon académique à l'œuvre de Stephen King. En 1995, Michael R. Collings estime que certains livres, notamment "Salem", "Shining, l'enfant lumière", "Dead Zone", "Ça" et la version intégrale du "Fléau", tous déjà étudiés de façon académique, ont de bonnes chances de résister à l'épreuve du temps et de devenir des classiques. Des correspondances ont été établies entre Stephen King et Charles Dickens : tous deux sont des écrivains prolifiques et populaires qui ont été en butte à la critique de leur vivant et dont une constante de leur œuvre respective est de dépeindre un portrait réaliste et sans complaisance de la société de leur époque.

Depuis "Ça", la traduction de la plupart des romans de Stephen King, y compris ceux écrits sous le pseudonyme de Richard Bachman, a été principalement assurée par William Olivier Desmond. Avant cela, quasiment chaque livre avait un traducteur différent. Depuis, seules certaines œuvres ont été traduites par d'autres personnes, par exemple "La Petite Fille qui aimait Tom Gordon" et "Roadmaster", traduits par François Lasquin, les derniers tomes de la saga de "La Tour sombre", traduits par Marie de Prémonville (hormis "La Clé des vents", traduit par Jean-Daniel Brèque), ou encore "Histoire de Lisey", traduit par Nadine Gassie. Après "Dôme", dernier roman traduit par William Olivier Desmond, mort en 2013, Nadine Gassie a repris, en compagnie d'Océane Bies, le rôle de traductrice principale de l'écrivain. Néanmoins, "Sleeping Beauties", paru en français en mars 2018, est traduit par Jean Esch.










En 1976, Brian De Palma réalise "Carrie au bal du diable", premier film adapté de l'œuvre de Stephen King. Le film est un succès commercial et critique et contribue à lancer la carrière de l'écrivain en le faisant connaître du grand public. À partir des années 1980, plusieurs réalisateurs renommés adaptent à leur tour des livres de King : Stanley Kubrick avec "Shining" (1980), David Cronenberg avec "Dead Zone" (1982), John Carpenter avec "Christine" (1983) et Rob Reiner avec "Stand by Me" (1987) et "Misery" (1990). À côté de ces adaptations réussies, auxquelles il faut ajouter celles de Frank Darabont, plusieurs autres films tirés de l'œuvre de King sont considérés comme très médiocres, notamment "Les Démons du maïs" (1984), "Charlie" (1984), "La Créature du cimetière" (1990), "The Mangler" (1995), "La Peau sur les os" (1996) et "Dreamcatcher" (2003).

King fait ses débuts au cinéma en 1982 en écrivant le scénario de "Creepshow", réalisé par George Romero avec qui il se lie d'amitié et qui réalisera plus tard "La Part des ténèbres" (1993). En 1986, King se lance dans la réalisation en adaptant "Poids lourds", une de ses nouvelles. Mais le film, "Maximum Overdrive", est un cuisant échec artistique et commercial et vaut à King une nomination pour le Razzie Award du pire réalisateur. En 1991, il développe un scénario original pour la mini-série "Contretemps" mais les audiences sont décevantes.

La seule adaptation que King a totalement désavouée est "Le Cobaye" ("", 1992), dont une seule scène présente un lien avec "La Pastorale", nouvelle ayant donné son nom au film. Furieux de voir son nom associé à ce film dans un seul but publicitaire, King intente un procès à la société de production New Line Cinema afin que son nom soit retiré de tout le matériel promotionnel du film. Le tribunal lui donne raison et condamne de plus à lui verser .

King autorise les réalisateurs débutants, la plupart étant des étudiants en cinéma, à adapter ses nouvelles sous forme de court métrage contre la somme d'un dollar symbolique à condition que le film ne soit pas distribué dans un but commercial sans son autorisation et qu'une copie lui soit envoyée. Ce système, surnommé "" par l'écrivain, permet à Frank Darabont de réaliser en 1983 une adaptation de "Chambre 312" qui impressionne King quand celui-ci la visionne. Darabont établit par la suite sa réputation en réalisant trois adaptations qui comptent parmi les plus réussies de l'œuvre de King, "Les Évadés" (1994), "La Ligne verte" (1999) et "The Mist" (2007), et les deux hommes sont amis depuis 1994. King est également ami avec le réalisateur Mick Garris et les deux hommes ont collaboré à plusieurs reprises, avec des hauts, notamment l'adaptation du "Fléau" (1994), et des bas, "La Nuit déchirée" (1992), film d'après un scénario original de King.

King a écrit plusieurs scénarios adaptés de ses livres, notamment ceux du film "Simetierre" (1989) et de la mini-série "Le Fléau" (1994). Il a toujours affirmé qu'il n'était pas satisfait du traitement de "Shining, l'enfant lumière" dans le film de Kubrick et, en 1997, il produit et scénarise une nouvelle adaptation de son roman sous forme de mini-série, réalisée par Mick Garris et plus fidèle à l'œuvre originale, qui remporte le Saturn Award du meilleur téléfilm. En 1998, il écrit la première version, révisée ensuite par Chris Carter, du scénario d'un épisode de la série télévisée "", dont il est devenu un admirateur trois ans plus tôt après avoir rencontré David Duchovny sur le plateau d'un jeu télévisé. L'épisode, intitulé "La Poupée", se déroule dans le Maine et met en scène une petite fille possédée par une poupée maléfique.

King écrit ensuite notamment trois scénarios originaux pour des mini-séries, le premier étant celui de "La Tempête du siècle" (1999), qui remporte le Saturn Award du meilleur téléfilm. C'est ensuite le tour de "Rose Red" (2002), mini-série pour laquelle l'écrivain organise une campagne de marketing qui pousse des milliers de personnes à croire que la maison hantée nommée "Rose Red" existe vraiment. Il développe enfin "Kingdom Hospital" (2004), série de 13 épisodes basée sur "L'Hôpital et ses fantômes" de Lars von Trier et qui s'ouvre sur une scène directement inspirée par le grave accident dont il a été victime en 1999.

King interprète souvent de petits rôles dans des adaptations cinématographiques ou télévisées de ses histoires, ainsi qu'un rôle plus important dans "". En plus de ces caméos, il prête sa voix à son propre personnage dans "Une fille de clown" (2000), un épisode des "Simpson", et il incarne un « nettoyeur » nommé Bachman, chargé de faire disparaître un cadavre, dans un épisode de la série télévisée "Sons of Anarchy" (2010).

King déclare en 2008 que ses trois adaptations préférées sont ', "Les Évadés" et '. L'année suivante, il dévoile dans le livre "" ses dix adaptations favorites sans donner d'ordre de préférence. Outre les trois déjà citées, on y trouve "Chambre 1408", "Cujo", "Dolores Claiborne", "La Ligne verte", "La Tempête du siècle", "Misery" et "Un élève doué".

Le 18 février 2017, Stephen King et J. J. Abrams annoncent sur les réseaux sociaux l'arrivée prochaine de la série télévisée "Castle Rock". Cette annonce est accompagnée d'un teaser. La série sera produite par la société Hulu qui a déjà produit la série "22.11.63". Ce projet très attendu pourrait être la première tentative de mettre en place un adapté de l'œuvre de l'écrivain. Mais l'année 2017, très riche au niveau des adaptations, est surtout celle du film "Ça", qui explose le record de recettes pour un film adapté de Stephen King tout en étant un succès critique.




en français

en anglais




</doc>
<doc id="2898" url="https://fr.wikipedia.org/wiki?curid=2898" title="Musique soul">
Musique soul

La musique soul, ou simplement soul, est une musique populaire afro-américaine ayant émergé à la fin des années 1950 aux États-Unis, dérivée, entre autres, du gospel et du rhythm and blues. Elle est considérée par certains comme un retour du rhythm and blues aux racines dont il est issu : le gospel (musique d’église).

Le terme (en anglais, ' qui signifie « musique de l'âme ») est associé à la musique noire américaine et apparaît pour la première fois dans le titre de deux albums de Ray Charles : ' en 1958, et "" en 1961. Le développement de la musique soul est stimulée par deux tendances principales : l'urbanisation du rhythm and blues et la sécularisation du gospel. C'est Ray Charles qui mélangea sa passion pour le gospel avec les rythmes saccadés du rhythm and blues pour donner naissance à la soul. Se retrouve donc dans la soul une partie de l’émotion sacrée mêlée à des thèmes profanes, souvent à forte connotation sexuelle. La soul plonge ses racines dans le pop, le gospel et le negro spiritual. La jeunesse noire l'a utilisée comme un mouvement contestataire pour réagir face à la communauté blanche et à l'envahissement du rock 'n' roll, qu'il soit blanc ou noir.

À la fin des années 1950, la volonté de proposer au public blanc des artistes noirs originaux conduit plusieurs labels à rechercher des versions commercialisables de la . Les deux labels les plus influents sont alors Stax (près de Memphis) et la Tamla Motown à Détroit. On les oppose souvent et l’on parle alors de southern soul avec Stax, plus proche des racines (soul rapide et incisive), et de northern soul, plus dansante et plus influencée par la pop. De même, en termes de management, Motown — dont le slogan « la musique de la jeune Amérique » épouse les volontés d'émancipation de l'époque — est le premier label fondé et dirigé par un noir américain, le redoutable Berry Gordy. À l'inverse Stax est fondé par un blanc, Jim Stewart, et nombre de ses plus fameux musiciens de séance sont blancs eux aussi (Steve Cropper, Donald « Duck » Dunn, et Tom Dowd).

La soul explose véritablement dans les années 1960. Alors que, dans un style plus classique, s'impose le son du studio Muscle Shoals de Rick Hall et de ses compositeurs Dan Penn et Spooner Oldham (Muscle Shoals Recording:Aretha Franklin, Percy Sledge, Wilson Pickett, notamment), James Brown et Curtis Mayfield introduisent des rythmes plus syncopés et donnent alors une nouvelle orientation à cette musique. C'est la création du "funk", un style inséparable de la soul, qui atteindra son apogée dans les années 1970 et 1980, avec des groupes comme The JB's (les musiciens de James Brown), Sly and the Family Stone, Kool and The Gang, suivis par Bootsy Collins et George Clinton avec leurs formations déjantées (Parliament et Funkadelic) : le P-funk. Un son beaucoup plus axé sur les basses et les "beats", les prémisses du neo soul. En 1966, les latinos de New York inventent la latin soul, également appelée boogaloo.

Durant les années 1970, des albums sont produits et deviennent des classiques du genre (notamment ' de Marvin Gaye et "Super Fly" de Curtis Mayfield), mais la "soul" décline dans la seconde partie de la décennie, les ventes de disques étant alors dominées par le disco. À la fin des années 1970 et au début des années 1980, de nouveaux artistes renouvellent le genre, à l'image de Michael Jackson avec ', Rick James, Roger & Zapp, Prince et Luther Vandross. Ils popularisent définitivement la soul. Un peu plus tard, en samplant les standards des années 1960 et 1970, le rap contribuera à une nouvelle popularité de la musique soul. Certains groupes iront plus loin et fusionneront soul et rap, pour donner naissance au new jack swing, devenu hip-hop, puis enfin au neo soul dans la seconde partie des années 1990 (fusion d'instrumentations organiques mais typées hip-hop et de textes et vocalises toujours dans l'esprit soul). D'Angelo, De La Soul, Erykah Badu, Maxwell et Omar, seraient à l'origine de ce mouvement.

La soul tient ses racines du gospel traditionnel afro-américain, du rhythm and blues, et de l'hybridation de leurs styles respectifs séculaires et religieux, dans leurs contenus lyriques et instrumentaux, qui s'organise dans les années 1950. Selon le musicologue Barry Hansen 

D'après AllMusic, la La phrase en elle-même, désignant la musique orientée gospel aux paroles séculaires, est d'abord attestée en 1961. Le terme "soul" met en avant la culture et la fierté de la communauté afro-américaine. Le jazz auto-consciemment dérivé du gospel s'appellera soul jazz. Tandis que des chanteurs commencent à utiliser des éléments issus du gospel et du soul jazz dans la musique afro-américaine populaire des années 1960, le terme de est peu à peu utilisé pour désigner de cette musique de l'époque.
Pendant les années 1950, des innovateurs importants tels que Clyde McPhatter, Hank Ballard, et Etta James, contribuent à l'émergence de la musique soul. Ray Charles est souvent cité pour avoir popularisé le genre soul avec des chansons à succès qui démarreront depuis son album "I Got a Woman" (1954). Le chanteur Bobby Womack explique que 

Little Richard (qui inspirera Otis Redding) et James Brown sont également des contributeurs importants du genre. Brown est connu sous le nom de ' (parrain de la soul) et Richard s'autoproclame ', car sa musique implique des éléments de ces trois genres qu'il cite.

Sam Cooke et Jackie Wilson sont aussi des principaux contributeurs du genre. Cooke se popularisera en tant que chanteur dans le groupe de gospel The Soul Stirrers, avant sa reconversion controversée dans la musique séculaire. Sa chanson ' en 1957 propulse sa carrière dans la pop et son ' (1962) est décrit comme Jackie Wilson, contemporain de Cooke et James Brown, atteint le succès grâce à son titre "Reet Petite" (1957).

L'écrivain Peter Guralnick est l'un des premiers à identifier Solomon Burke comme une personnalité clé dans l'émergence la musique soul, et Atlantic Records comme label discographique clé. Les premières chansons de Burke au début des années 1960, comme ', ' et "" sont considérées comme des classiques du genre. Guralnick explique que 

Ben E. King parvient également à atteindre le succès en 1961 avec sa chanson "Stand By Me", directement basée sur du gospel. Au milieu des années 1960, le succès initial de Burke, King, et d'autres, surpasse celui des nouveaux chanteurs de soul comme ceux de Stax incluant Otis Redding et Wilson Pickett. Selon Jon Landau 

La musique soul domine des classements afro-américains aux États-Unis dans les années 1960. Otis Redding atteint le succès lors du Monterey Pop Festival de 1967. Le genre se popularise en parallèle au Royaume-Uni. Différentes régions et villes américaines comme New York, Détroit, Chicago, Memphis, La Nouvelle-Orléans, Philadelphie, et Muscle Shoals, Alabama (localité des FAME Studios et Muscle Shoals Sound Studios) sont notées pour l'émergence de différents sous-genres dérivés de la soul et leurs styles d'enregistrement.

En 1968, le mouvement de la soul commence à se scinder. Des artistes comme James Brown et Sly & the Family Stone se lancent dans la funk, tandis que d'autres tels que Marvin Gaye, Stevie Wonder, Curtis Mayfield et Al Green se concentrent sur une variété d'autres genres, parfois politiquement engagés. Cependant, 

Dominée par l'empire Motown Records de Berry Gordy, la Detroit soul est très rythmée et inspirée du gospel. Le style sonore Motown inclut des claquements de mains, des lignes de basse puissantes, et des violons. AllMusic cite Motown pour avoir lancé la pop-soul, un style de soul aux paroles agressives. Ce style inclut des artistes tels que Diana Ross, les Jackson 5, Stevie Wonder, et Billy Preston. Populaire dans les années 1960, le style s'adoucit dans les années 1970 et conduit au lancement du disco.

Les termes "deep soul" et "southern soul" désignent généralement un style de soul énergique et entraînant mêlant l'énergie du R&B à un son gospel sudiste américain. Le label Stax Records développera un son distinct de ce style.






</doc>
<doc id="2899" url="https://fr.wikipedia.org/wiki?curid=2899" title="Sound system">
Sound system

Au sens strict, le terme « sound system » (en français « système de sonorisation » transportable aussi parfois appelé discomobile selon le contexte) désigne le matériel de sonorisation utilisé lors d'une fête ou d'un concert.

Par extension, il désigne également le groupe d'organisateurs de soirées mettant ce matériel à disposition, et la culture y étant associée.

La culture "sound system" est apparue en Jamaïque dans les ghettos de Kingston (Jamaïque) à la fin des années 1940. Née de l'exclusion d'une population pauvre et noire, n'ayant pas accès aux salles de spectacles et aux clubs (monopolisées par les riches blancs et métisses), les Jamaïcains plus modestes diffusaient alors leur musique dans la rue .

Le concept de « "sound system" » est d'abord devenu populaire dans les années 1950 dans les ghettos de Kingston. Les DJ chargeaient un camion avec un générateur, des platines vinyles et des haut-parleurs et installaient une "fête de rue" (street party). Au début, les DJ jouaient du R&B américain mais au fur et à mesure, la production musicale jamaïcaine de rap se mit à s'étoffer et les sons prirent des sonorités locales typiques.

Les sound systems étaient de « grosses » affaires car ils représentaient un moyen sûr de se faire de l'argent dans une économie instable. L'organisateur (le DJ) pouvait faire du profit en demandant un petit droit d'accès et en vendant de la nourriture et de l'alcool. La concurrence était sévère entre les différents "sound systems" et deux DJs émergèrent comme des "stars" de la scène : Clement « Coxsone » Dodd et Duke Reid.

La popularité d'un DJ de sound system tenait surtout à sa capacité à jouer de la musique innovante. C'est pourquoi les deux DJs stars se mirent à la production de disques, augmentant non seulement leur potentiel mais réduisant leur utilisation de musique américaine. Au début, ils ne produisaient des titres que pour leur propre sound system, limités donc à une copie.

Ce qui commença par une simple copie du R&B américain fait par des musiciens locaux devint la première musique originale issue de Jamaïque : le ska. Au fur et à mesure que cette nouvelle tendance prit du succès, les deux DJs s'investirent de plus en plus dans la production. Le studio de production de Coxsone devint un studio réputé, alors que Duke Reid fonda le connu "Treasure Isle".

À la suite de l'émigration de nombreux Jamaïcains vers l'Angleterre, les "sound systems" s'y implantèrent peu à peu. Ils finirent par se répandre dans différents pays en variant les différents styles de musique qu'ils produisaient, d'abord ska, rocksteady, reggae, dub, puis raggamuffin ou ragga - Jamaïque oblige - et enfin de plus en plus de musiques différentes, souvent électroniques, telles que l'électrodub, la hardtechno, la jungle, le drum and bass, etc.

C'est ce type de sound systems dub qu'ont côtoyé à leurs débuts les sound systems anglais, considérés comme les parents du « mouvement free party ».

En France, les sound-systems sont arrivés à la fin des années 1980 avec comme pionniers, des sounds comme Dread Lions, Reality, Youthman Unity, Kwame Nkrumah, High Fight, King Dragon, Blues Party, Stand Tall, Earthquake, Jah Wisdom, Ragga Dub Force, Ital Posse...

Aujourd'hui, il existe de nombreux sound-systems français, diffusant la musique jamaïcaine sous sa forme originale, le 45 tours ou exclusive sous forme de dubplates specials (morceaux uniques joués par chaque sound).

Le sound system en France a commencé ses balbutiements au début des années 1980 dans les squats sur des chaines hi-fi et surtout grâce à l'équipe des DJs de Radio Ivre (Radio Irie).
Les premiers gros sounds avec plus de 100 personnes ont été organisés vers 1982 à l'église des Panoyaux à Ménilmontant dans le de Paris avec Ras Gugus.

En France l'appellation sound system a longtemps désigné une équipe constituée de selectas et de chanteurs (en particulier dans le ragga/dancehall parisien) ; l'utilisation était impropre, et est maintenant consacrée à une équipe qui dispose de son propre matériel de diffusion (console, amplis, enceintes...)

La scène sound system française est, dans les années 2010, en pleine expansion, 

Les sound systems sont un argument de poids qui attire un public de plus en plus important dans les festivals, tels que le Dub Fest (2013) et le Dub Camp (2014), qui voient d'ailleurs le jour, regroupant scène française et internationale.

Une carte des sound systems français a été publiée en 2013 par le crew I-Leaf.

Les sounds systems dub ont leur intérêt dans la séparation des fréquences. En effet, joue sur une platine unique, on ne mélange pas les morceaux, et on ne joue pas sur les transitions. Les différences d'enceintes dans le sound system permettent aux artistes de mixer en live les fréquences d'un morceau. Ainsi, les scoops, en bas, jouent les basses, les bas médium, au dessus, jouent les fréquences médiums, puis les hauts médiums et les aigus, jouent les fréquences hautes.

Les transitions entre les morceaux sont assurées par le MC, quoi que de plus en plus de sound system jouent sur deux platines, afin d'enlever ces transitions. Certains artistes abandonnent peu à peu le vinyle, et jouent leurs propres morceaux par ordinateur.

Dans le milieu free party ou rave party, un "sound system" désigne avant tout le matériel de sonorisation utilisé lors de la fête. Il se compose d'un ensemble d'enceintes (souvent appelé « mur », métaphore comparant l'enceinte à une brique), de plusieurs amplificateurs et autres appareillages (égaliseur, etc.), ainsi que d'un moyen pour le DJ/Liver de diffuser la musique (platines vinyles ou CD et table de mixage, ordinateur, etc.).

Par extension, le terme désigne la tribu (une bande d'amis plus ou moins nomades, voir free party) qui possède ce matériel, englobant également les dispositifs d'éclairage (spots et stroboscopes), la décoration, les moyens logistiques (souvent des camionnettes et utilitaires, type de véhicules très prisés dans le milieu des free parties).

Le terme « 6tm » fait référence au mot "system" en langage SMS/texto français.

Les "sound systems" (autant les individus que le matériel) bénéficient d'un respect quasi-totémique de la part des participants aux free parties. Il n'est pas rare, dans le cadre de certaines free parties, de voir ces derniers former un mur humain pour empêcher les forces de l'ordre d'accéder « derrière le son », endroit presque sacré réservé aux DJ et à leur entourage. Cet endroit est d'ailleurs plutôt une cachette, contrairement aux fêtes commerciales, où les organisateurs et les DJ se mettent en valeur sur une scène.

Ces moyens matériels sont le point névralgique des free parties : ce sont donc naturellement eux qui ont été visés, en France par les lois votées depuis 2001 et leurs propriétaires menacés de saisie dans le cas de fêtes non-déclarées dépassant 250 participants. Le Décret - 334 du 21 mars 2006 modifiant le décret - 887 du 3 mai 2002 pris pour l'application de l'article 23- 1 de la loi - 73 du 21 janvier 1995 et relatif à certains rassemblements festifs à caractère musical a ramené le nombre de participants à 500 (et modifié quelque termes de l'amendement dit « Mariani » de la Loi sur la sécurité quotidienne (LSQ))




</doc>
<doc id="2902" url="https://fr.wikipedia.org/wiki?curid=2902" title="Skinhead">
Skinhead

Skinhead (des mots anglais "skin" « peau » et "head" « tête » : « cuir chevelu – à nu ») désigne à l'origine un jeune prolétaire britannique aux cheveux tondus ou non. Le phénomène skinhead est né au Royaume-Uni à la fin des années 1960. Il est une évolution de la mouvance "modernist" (les "mods"). En évoluant et en se diversifiant la culture Skinhead va adopter divers styles musicaux. Si au début leur culture musicale emprunte principalement à leurs ainés Mods la soul américaine et le ska, à partir de 1967 les Skinheads accompagnent l'explosion du rocksteady et du reggae naissant, dont l'impact en Grande Bretagne en font les principaux amateurs en dehors de la communauté immigrée. Avec les années 70, le Glam Rock vient s'ajouter à cette engouement, puis le retour des skinheads à partir des 1978 accompagne la naissance d'une partie de la scène Punk Rock puis de la Oi!. Il est à noter que le Hardcore punk aux U.S.A est un style qui est adopté par les skinheads à la fin des années 80.

À la fois mode vestimentaire et musicale, cette première vague skinhead n'est rattachée à aucun mouvement politique tout en étant fortement influencée par ses origines ouvrières. En s'étendant au reste du monde dix ans plus tard, le phénomène skinhead a connu des évolutions importantes.

À l'origine les skinheads n'étaient en aucun cas des militants politiques ou syndicaux. Leurs points communs étaient leur origine sociale modeste, leur amour de la musique noire, en particulier jamaïcaine, et leur goût pour la bagarre. Cette mode rassemblait aussi bien des blancs que des noirs. C'est avec l'apparition du punk rock en 1977, et surtout du chômage qui frappe de plein fouet l'Europe à la fin des années 1970, que le mouvement skinhead se scinde, et qu'une partie des skinheads est séduite par les textes néonazis de la seconde formation du groupe britannique Skrewdriver (voir Rock anticommuniste), tandis que d'autres se tournent vers l'extrême gauche ou refusent la politique.

Actuellement, les skinheads sont nombreux à travers le monde, mais profondément divisés, tant par leurs références musicales, que par leurs attaches idéologiques. Le clivage principal demeure l'opposition politique, entre une tendance marquée par l'extrême droite, les apolitiques d'autre part, et l'extrême gauche par ailleurs. Il n'existe pas de mouvement global skinhead mais une mouvance hétérogène. Cette mouvance peut être définie et comprise comme un ensemble de références musicales et vestimentaires revendiquées en partie ou en totalité par des groupes d'individus aux comportements et aux idées très différentes .

Certains détails historiques semblent ancrer le phénomène skinhead dans une filiation plus ancienne bien que sujette à caution. Pendant la Première Révolution anglaise (1641-1649), les partisans du Parlement menés par Oliver Cromwell étaient appelés les "round heads" (têtes rondes) par leurs ennemis en raison de leur coupe de cheveux courte opposée à la longue chevelure des aristocrates partisans du roi Charles d'Angleterre. La ressemblance avec les skinheads s'arrête là, car les partisans de Cromwell, même s'ils recrutaient beaucoup parmi les classes populaires, étaient avant tout des protestants puritains d'inspiration calviniste qui refusaient les prétentions absolutistes du roi et la possibilité d'un rétablissement du catholicisme en Angleterre.

Il y aurait également mention d'individus répondant à la définition et à l'appellation du "skinhead" dès le début du dans la presse du Royaume-Uni, le terme désignait de jeunes voyous issus des quartiers pauvres et aux cheveux courts, l'équivalent des « Apaches de la zone » en France. Un ouvrage édité en 1908 "The Classic Slum" de Robert Roberts décrit de manière troublante les "corner kids", jeunes ouvriers violents vêtus de chaussures de sécurité, de chemises de travail et de bretelles, les cheveux tondus qui effraient la « bonne société » dans les quartiers malfamés du nord de l'Angleterre.

Néanmoins, dans son acception moderne claire et stricte, "skinhead" s'applique à un mouvement de jeunesse né progressivement dans la seconde moitié des années 1960 au Royaume-Uni. Il s'agit en fait de la fusion progressive en une entité propre des "rude boys", jeunes noirs d'origine antillaise (surtout jamaïcaine), et des plus prolétarisés des mods, jeunes blancs fans de scooters et de musique soul (qui seront rétrospectivement appelés Hardmods à la fin des années 1970). Dans son sens grand public le terme Skinhead signifie « un jeune aux cheveux rasés, vêtu de manière paramilitaire et exprimant avec violence idées racistes et néo nazis ». Pourtant la réalité des faits et leur histoire est bien plus complexe. En effet une partie des skinheads actuels dénie aux adeptes des thèses d’extrême droite le droit de s'appeler eux-mêmes "skinheads" et les qualifie de "boneheads" (littéralement « crânes d'os », ce qui familièrement signifie « crétins »).

À l'inverse, les skinheads d'extrême droite se considèrent comme les seuls skinheads authentiques dans la continuité du paki-bashing, d'un patriotisme de plus en plus exacerbé par rapport aux skins originaux. Ces skins nationalistes, voire néonazis, surnomment les skinheads antiracistes "reds" (littéralement « rouges»).

Ces ramifications, complexes et parfois incompréhensibles pour les non-initiés,rendent extrêmement difficile une description claire et définitive.

Certains prétendent que les premiers skinheads se sont tondus les cheveux pour se distinguer des hippies. Rien n'est plus faux puisque l'évolution des "Mods" vers les Skinheads est antérieure à la naissance des hippies britanniques. On raconte encore qu'il s'agit d'un moyen d'échapper à la police montée lors des émeutes ou des bagarres. En réalité, beaucoup de ces jeunes sont ouvriers. Ils portent les cheveux courts, en raison des normes de sécurité imposées sur leur lieu de travail. Dans les familles issues de milieux populaires, porter les cheveux courts c'est faire partie de la société sérieuse et laborieuse. Ces explications nombreuses alimentent la mythologie skinhead : les skinheads ne veulent pas ressembler à des hippies, les skinheads sont issus de la classe ouvrière, les skinheads aiment se battre et détestent la police.

Le look skinhead est beaucoup plus standardisé par rapport à l'individualisme forcené et en permanente évolution des "Mods" originaux : cheveux courts (tondus ou coupés courts, mais rarement rasés à blanc à cette époque), favoris, bretelles étroites dont les pinces sont posées parallèlement, blue-jeans Levi Strauss & Co., modèle 501 ou Sta press (pantalon cigarette à plis permanent) ou Wrangler coupé court ou pantalons du même type. Le classement des chaussures de sécurité comme armes à partir de 1969 et l' interdiction de les porter en dehors du lieu de travail va favoriser la généralisation du port du vêtement le plus emblématique de la garde robe skinhead, les chaussures de marque Dr. Martens.

S'il s'agit à la base de chaussures orthopédiques de sécurité, les modèles sans coques sont les plus prisés. En effet les « docs coquées » classées comme arme, très peu de skinheads originaux se risquent à en porter contrairement aux idées reçues. Les Doc Martens — alors que curieusement des marques autant portées à l'époque telles Hawkins (et son modèle Astronaut), Solovair ou Grafters sont tombées dans l'oubli — sont devenues la marque symbolisant à elle seule la mouvance skinhead. Un des plus gros succès des charts Pop 1969 (une reprise reggae du tube de Nancy Sinatra de 1966 "These Boots Are Made for Walkin'") y fait explicitement référence : le refrain du "These boots are made for stomping" des anglo-jamaïcains Symarip précise : , (le "stomping" est une des danses des skinheads consistant à lever et reposer lourdement ses pieds en rythme).
Les "Monkey boots" sont essentiellement portés par les skinhead girls (parfois affublées du terme légèrement péjoratif de "birds"), Doc Martens ne proposant à l'époque pas de petites tailles pour leurs chaussures montantes. Loafers, Bowling shoes, Clarkes "desert boots" sont autant de reliquats de la période Mod ou plus rarement des chaussures de sport de type baskets (à l'image des "kicks" ou "samba" de chez Adidas qui se populariseront lors du revival des années 1980).

La garde-robe est assortie de vêtements conçus pour le climat de la Grande-Bretagne et inspiré notamment du style Ivy league Américain (Harrington) ou Monkey Jacket (parfois appelé Mod Jacket). Le blouson Harrington — commercialisé par la marque Barracuta, porté par les mods, puis les skinheads et enfin, dix ans plus tard les punks —, n'est pas une marque mais un type de veste légère en toile de coton unie doublée de tissus à carreaux écossais (tartan). Le nom vient du héros de la série télévisée américaine "Peyton Place", très populaire au début des années 1960, Rodney Harrington, qui portait ce vêtement. D'une manière générale et indépendamment de l’allégeance à un de ces mouvements, le Harrington est une icône vestimentaire partagée par toutes les classes et toutes les générations de Britanniques dans les années 1960 et 1970.

D'autres manteaux et pardessus sont couramment utilisés par les skins selon qu'ils soient au travail, à l'école ou en soirée. On peut citer le "donkey jacket" (manteau d'ouvrier inclus dans le paquetage des vêtements de travail, docker, mineur ou éboueur), enfin le Crombie (veste anglaise mais ressemblant au style des jeunes Jamaïcains) est considéré comme le plus élégant. Marginalement avant 1979, certains blousons tels le bombers jacket sont parfois portés.

Dans les soirées, le costume de couleur noir ou en tissus "Tonic" (tissu changeant légèrement de couleur à la lumière), est porté pour danser ou frimer en soirée dans certains cercles skinheads les plus « pointilleux » et représente le « Saint Graal » de ces jeunes qui peuvent ainsi dépenser leurs premières paies en les faisant tailler sur mesure ("bespoke").

D'autres accessoires viennent parfaire la panoplie : écharpe de football ou aux motifs Kashmer (Paysley), en soie et à pois (Polka dot). Les casquettes plates (en feutre, en tweed, unie ou à chevrons) sont parfois portée en concurrence avec le chapeau "pork-pie" ou "trilby" pour afficher son appartenance à cette tribu urbaine. Les jeunes filles skinheads portent des pulls mohair, des mini-jupes, des costumes longs à quatre ou cinq boutons, des mocassins type Penny Loafers. La coupe de cheveux typique des "skinhead girls", dite "chelsea", est à l'origine une coupe « à la garçonne » telle que celle arborée par le mannequin Twiggy (cheveux coupés court sur le sommet du crâne avec une frange longue sur le devant et quelques mèches longues dans le cou et sur les côtés) elle raccourcira progressivement à la fin des années 1970 seulement à l'instar de la coupe de leurs homologues masculins, de même qu'il faut attendre cette période pour les voir adopter progressivement un look de plus en plus similaire aux hommes.

Marqueur aussi fréquemment associé aux skinheads : le tatouage. Les Britanniques de milieux modestes les affectionnent et les skinheads en font une véritable institution. Il serait vain ici de décrire la vaste gamme des tatouages spécifiquement skinhead, mais on doit considérer qu'il faut attendre le revival de 1979 pour les voir popularisés.

Le look skinhead est donc inspirés des ouvriers de l'époque auquel se sont ajoutés des vêtements de travail et progressivement des références "sportswear", voire de surplus militaire. Ces adolescents et ces jeunes adultes s'approprient, comme ceux d'aujourd'hui, certaines marques qui deviennent ainsi emblématiques : Fred Perry, Lonsdale, Ben Sherman, Jaytex, Arnold Palmer, Loakes, Brutus ou encore Adidas.

Les skinheads sont issus de la vague "modernist". Il faut donc rappeler brièvement qui sont les "mods" et de quelle manière ces skins vont devenir une entité autonome, puis totalement distincte des Mods.

Dans un premier temps, il s'agit principalement de jeunes Londoniens de la petite classe moyenne, souvent issus de famille juive ou grecque établies dans le négoce de vêtements dans les quartiers Est de Londres. A l'avant-garde de la mode, ils s'habillent de façon à la fois luxueuse et décontractée. Ils aiment les costumes italiens, le style américain, se passionnent pour le "modern jazz" et les musiques noires américaines, les films français... Vers 1963-1964, cet underground élitiste commence à devenir un phénomène de masse, notamment en raison de l'explosion du swinging London : de nombreux adolescents deviennent "mods". Plusieurs groupes se réclamant de cette tendance émergent (parfois grâce à l'influence de managers avisés). Le "mod beat", adaptation locale du rythm'n'blues puis de la soul des artistes afro-américains apparait. Les artistes réunissant les plus grands publics sont les Who, Small Faces, The Action, The Artwoods... Un des hymnes Mod les plus célèbres est « My Generation » de The Who . Le paradoxe est que ce dernier groupe n'est pas considéré comme strictement Mod. La fascination des Mods va en effet prioritairement vers la musique Afro-Américaine.

Les faits divers, probablement exagérés, rendent les mods célèbres. Les batailles rangées entre mods et rockers (autre mouvement de jeunesse, axé sur les motos, les blousons de cuir et le rock'n'roll) font les gros titres des "tabloïds" de la presse à scandale populaire, et ce qui était un confidentiel courant underground devient alors un vrai phénomène de masse. L'image des bandes de mods en scooter et de rockers à moto se donnant rendez-vous à Brighton pour de mémorables bagarres devient une image de marque et attire de nombreux jeunes sans l'élitisme très recherché des précurseurs. Cette nouvelle vague de mods méprise les rockers, les jugeant arriérés et passéistes. Les rockers trouvent les mods maniérés et dégénérés. Ces considérations ne sont qu'un prétexte à la bagarre. le mouvement Mod n'échappe pas à la culture des gangs et au hooliganisme, d'autant plus que la coupe du monde de 1966 organisée en Angleterre voit ces jeunes, bénéficiant du pouvoir d'achat des trente glorieuses, aller seuls en bande dans les stades, sans leurs parents, comme c'était le cas auparavant.

Vers 1966-1967, la scène "Mod" a vécu et il ne reste que des jeunes scooteristes à cheveux très courts. Cette tendance pratique le hooliganisme. Les vêtements de sport ou de travail pour traîner dans la rue (polo Fred Perry, chaussures Doc Martens noires ou rouges) commencent à remplacer les costumes sur mesure. Ils prennent le contre-pied de la mode branchée de l'époque (telle la vague psychédélique ou le mouvement hippie) et affichent et fièrement leurs origines ouvrières ("working class"). Ce clivage est particulièrement fort dans le Nord de l'Angleterre (Manchester) et en Ecosse (Glasgow) où cette radicalité s'inspire du style vestimentaire des milieux liés à la pègre. Ces "hard mods" , tels qu'il seront surnommés en 1972 par le sociologue Stanley Cohen dans le cadre d'une étude portant sur l'opposition entre Mods et Rockers - se crispent sur l'identité "modernist" de la période 1963-1965 : musique noire américaine (r'n'b, Soul), style urbain et moderne, scooters Vespa et surtout Lambretta.

Vivant dans les mêmes banlieues et quartiers ouvriers, les "hard mods" fréquentent les "rude boys", ou "rudies", jeunes immigrés antillais, surtout jamaïcains avec qui ils partagent le goût pour la musique noire américaine (soul, rhythm and blues) et jamaïcaine (ska puis un nouveau courant, le rocksteady). Vers 1968, ces "hard mods" et ces "rudies" se confondent, et en septembre 1969, les grands titres de "Fleet Street" (la grande rue londonienne où sont regroupés les principaux quotidiens du pays) baptisent ces jeunes de plus en plus nombreux du nom de "Skinheads" .

En 1969, un véritable raz-de-marée skinhead envahit le Royaume-Uni pour quelques très courts mois. Il faut considérer que le gros de la vague skinhead en tant que tel s'abat outre-Manche en septembre 1969, pour être déjà dépassé par ses "séquelles" vers juin 1970. Cette "mode" "skinhead" explose en même temps que la musique reggae, qui est la musique émergente de l'été 1969 au Royaume-Uni. De fait, pour nombre de jeunes cela ne se prolonge guère. Beaucoup n'ont été skinheads qu'un an ou deux, voire quelques mois. Cette contre-culture, en devenant soudain très à la mode, rapproche les jeunes des quartiers ouvriers, tant blancs que noirs. Les premiers skinheads écoutent de la soul, du rythm'n'blues (labels Stax, Motown ou encore Chess records), du mod beat, du ska, pourtant presque passé de mode en 1969 , du rocksteady, mais surtout le son du moment : le reggae. Les skinheads seront la première population européenne à écouter massivement du reggae. Les artistes qui recueillent le plus de succès sont des artistes noirs venus directement des Caraïbes, Desmond Dekker, les Upsetters, Jimmy Cliff, The Harry J Allstars, Derrick Morgan, Dave Barker, ou produits spécifiquement pour ce public par des musiciens immigrés en Grande Bretagne tels Simaryp, Laurel Aitken, Hot Rod Allstars, Joe The Boss ou encore Freddy Notes et son groupe The Rudies.

Le reggae et le rocksteady apparaissent alors comme le son skinhead par excellence. Pour les puristes, on parle de "Boss Sound" (probablement en référence à un titre des Symarip). Un terme sera d'ailleurs inventé au début des années 1980 pour qualifier le son de ces années 69-71 : le "skinhead reggae" (les personnes étrangères à la scène skinhead parlent de "early Reggae"). Dans la tradition moderniste, les skinheads aiment danser. Ils rivalisent de pas de danse compliqués pour frimer lors des "discoes", l'équivalent des « boums » françaises, organisées dans les Maisons de jeunes ou de manière clandestine chez des particuliers contre une modeste participation ("Blues Parties"). Les chansons traitent de thèmes transposables à leur vie quotidienne : romances, sexe, danse, émeutes, problèmes de tous les jours, mais aussi de nombreux thèmes variés et souvent amusants, tels le western, le kung fu, les monstres en tout genre ou la conquête spatiale.

Les principales maisons de disques éditrices de "reggae" au Royaume-Uni sont Trojan Records, Pama Records et Torpedo Records. Le logo du label Trojan (un casque d'hoplite grec, comme on en portait lors de la guerre de Troie) a été repris par la suite pour désigner les skinheads traditionnels qui perpétuent l'esprit originel.

Les skinheads constituent donc à la fois une mode vestimentaire liée à des goûts musicaux, mais aussi une véritable sous-culture de jeunes avec ses comportements typiques (phénomènes de bandes, clanisme, frime, violence, esthétique, danse...) et son argot. On parle de "bovver boys", littéralement « les jeunes mecs qui ne se laissent pas embrouiller », d' "Aggro" (agressivité, agression...) pour désigner la baston, de "bashing" ("To bash" signifie « casser la gueule »). Les leaders organisent des bandes (« crews », « fleets » ou « firms » selon un argot urbain préexistant) où les plus élégants et respectés sont les "boss skinheads" (à l'instar des « Faces », Mods les plus considérés par leur pairs).

Ces gangs de jeunes qui ont régulièrement un comportement violent vont hisser le "hooliganisme" au rang de problème de société. Certains avancent que les skinheads sont issus du hooliganisme. C'est à la fois vrai et faux : les jeunes Britanniques des classes moyennes et populaires se comportent souvent en hooligans dans les stades de football, mais le hooliganisme est plus ancien que la mode skinhead (il date du début du ) et les codes vestimentaires des hooligans varient beaucoup dans le temps (la plupart des hooligans actuels n'ont absolument pas le look skinhead).

L'abus d'alcool et de drogues diverses (surtout les amphétamines pour pouvoir danser toute la nuit, les skinheads étant peu portés sur les opiacés et les drogues psychédéliques), n'arrange rien à l'image des skinheads. La presse tabloïd peut dès lors stigmatiser les skinheads, comme elle l'avait fait auparavant pour les "mods" ou les "rockers" ; c'est la "nouvelle menace".

En 1969 et 1970, la mode skinhead est devenue si importante que certains artistes de rock l'adoptent afin de gonfler leur audience : c'est le cas du groupe Slade, pionnier du glam-rock. En 1969, influencé par l'opportunisme de son manager Chas Chandler, le groupe en adopte provisoirement les codes vestimentaires. Même s'il s'agit d'un calcul commercial, Slade peut être considéré comme un des premiers groupes skinhead composé de blancs. Fait moins connu, d'une manière plus underground et plus sincère, le groupe The Neat Change, arbore un look pré skinhead dès 1967, dix ans avant l'émergence du street-punk et de la oi!.

Cette première vague skinhead est donc avant tout une mode et un style musical et vestimentaire largement méconnu hors du Royaume-Uni. Il n'y a pas de skinheads à cette époque en Europe continentale ou en Amérique du Nord. Seuls certains adolescents émigrés à cette époque en famille en Australie (donnant naissance à la sous-culture "sharpie") et au Canada exportent le style hors de Grande-Bretagne. Pour la plupart des journalistes britanniques, les skinheads ne sont qu'une nouvelle sorte de voyous incontrôlables (comme la France a ses « blousons noirs » à la même époque).

La mouvance skinhead n'est pas véritablement politisée pour plusieurs raisons. Les jeunes qui s'y reconnaissent sont très jeunes (14-15 ans), ne bénéficient pas du droit de vote et ont des préoccupations d'adolescents. Les marqueurs idéologiques sont hérités de leur classe sociale mais si leurs parents votent majoritairement pour le Labour (travailliste), l'époque n'est pas encore à une remise en cause réfléchie du système. Pareillement, s'il y a le même taux de fils d'immigrés chez les skinheads que dans la société britannique, il est délicat de mettre en avant un antiracisme originel conscient, ou l'inverse "(paki bashing)" selon les critères de cette période où le racisme est très largement répandu . Deux éléments vont cependant marquer durablement l'image « éthique » des skinheads.

D'une part l'usage fréquent des couleurs nationales (Union Jack pour l'ensemble des Britanniques ou Saint Georges Cross pour les Anglais) par les skinheads de cette époque est interprété comme un glissement vers le nationalisme, voire le fascisme. Cette affirmation est très exagérée, même si les jeunes Britanniques font souvent preuve d'un patriotisme très marqué, tel qu'on peut le rencontrer dans les tribunes des stades de football ("jingoism", équivalent du mot français « chauvinisme »). Les "mods" arboraient auparavant les couleurs nationales pour le côté « pop art » et les "punks" feront de même par la suite, par désespoir social et ironie. Cette fierté d'appartenir à la nation britannique est même selon certains un élément unificateur pour les jeunes Britanniques blancs et les Antillais noirs venus de la Jamaïque ou de Sainte-Lucie (États du Commonwealth, dont les habitants sont assimilés aux Britanniques puisque sujets de la même reine).

Par ailleurs, il est vrai qu'une partie des skinheads de cette époque (qu'ils soient noirs ou blancs) fait preuve de violence à l'encontre des jeunes Indiens et Pakistanais, dont le style vestimentaire et les goûts musicaux les rapprochent selon eux des hippies (alors que ce serait plutôt l'inverse). Ils organisent régulièrement de véritables ratonnades à leur encontre : le "paki bashing". Cette violence, bien que largement non théorisée, n'empêche pas les ponts entre certains skinheads et Enoch Powell (homme politique conservateur, populiste et anti-immigrés).

À l'opposé de l'échiquier politique, une minorité de skins est proche des centrales syndicales de la gauche travailliste, particulièrement dans le nord de L'Angleterre. De même, les bagarres entre bandes de skins de différents quartiers prennent une signification toute différente dans le Belfast déchiré par le conflit entre protestants et catholiques (chaque camp ayant des adolescents suivant ce "mode de vie").

Vers 1970, la vague skinhead s'essouffle. De nouvelles tendances musicales apparaissent, comme le glam rock, et une évolution du reggae vers le mouvement rastafari notamment par Bob Marley ainsi que vers le nationalisme noir (beaucoup de Rude Boys deviendront de farouches défenseurs de la cause noire des États-Unis.) éloigne les skins d'une musique qui leur « parle » moins, de par son mysticisme et sa revendication afro-identitaire. Lassés d'être interdits de stades et de se voir refuser l'entrée dans les clubs de par leur comportement discutable, les "rescapés" adoptent un style qui incorpore des éléments vestimentaires classiques à un look plus élégant (souvent inspiré des parrains de la pègre britannique), les cheveux repoussent et on parle maintenant des suedeheads (crâne de velours) : les skins peuvent désormais se fondre dans la masse plus facilement.

Le mouvement skinhead originel n'a donc qu'une durée de vie de quelques mois, nombre de "hard mods" le laissant tomber par dégoût dès que celui-ci est identifié par le plus grand journal britannique comme une entité à part du mouvement mod, le 3 septembre 1969. La vague skinhead se prolonge encore pendant environ une année, puis elle se diluera les cinq années suivantes dans le hooliganisme, les scènes Northern Soul ou le phénomène scooteriste...

Après 1971, l'esprit skinhead ne disparaît pas pour autant et survit, à travers les suedeheads puis les "smoothies" (ces derniers portent les cheveux assez longs). Les deux adoptent le style "bootboy" lorsqu'ils descendent dans la rue : blue jean retroussé, Doc Marten's montantes, bretelles… C'est un style vestimentaire assez proche de celui arboré dans le film de Stanley Kubrick "Orange mécanique". Coïncidence troublante, les jeunes décrits dans le roman d'Anthony Burgess, dont s'inspire le film, portent déjà cet uniforme plus de dix ans auparavant. L'œuvre est violente, mais le message est plus subtil qu'il n'y paraît : il s'agit en fait d'une critique des théories comportementalistes et une caricature des aspects les plus ridicules des sociétés modernes. Par la suite, ce film constituera une source d'inspiration pour de nombreux groupes punks et surtout skinheads, contribuant à forger l'image du jeune rebelle violent, incontrôlable mais cyniquement lucide.

Les "mods" ne font plus la une, mais restent nombreux, en particulier dans le nord de l'Angleterre où ils constituent les premiers bataillons de "Soul Boys", à l'origine d'un fort engouement pour une scène musicale particulière, la "Northern soul". Style musical aux définitions multiples, il s'agit de la redécouverte sur les pistes de danse de morceaux de soul rares et énergiques sortis de manière confidentielle par des labels existant en marge du « poids lourd » du genre, Motown.

Les codes musicaux changent. Chez les "bootboys", le reggae, le rocksteady et le ska ont laissé la place au glam rock (cf. David Bowie, T-Rex, Slade, Mott The Hoople, The Sweet pour les plus écoutés en Grande Bretagne), au pub rock (cf. Dr. Feelgood, Eddie and the Hot Rods) puis au punk-rock (genre musical inspiré aux États-Unis par les Stooges, encore les New York Dolls ou les Ramones). Nombre des premiers "punks" britanniques (fin 1976-début 1977) ont une image qui emprunte certains éléments au style "bootboy", à commencer par les Clash (par ailleurs fans déclarés de reggae et de pub rock). Il est à noter que certaines personnalités centrales de cette scène naissante ont eux même été skinheads auparavant tel Paul Simonon (The Clash) ou Steve Jones ( Sex Pistols). 

Cette explosion médiatique "punk" de 1977 redonne une certaine vigueur à d'autres tribus urbaines. Les skinheads et même les mods réapparaissent et se mêlent aux "punks". Ils sont alors peu nombreux, noyés dans la masse punk qui constitue l'essentiel des « tribus urbaines » du moment. Les groupe The Jam, Secret Affair -qui compte un solide contingent de ces néo-skinheads dans son public- , The Chords, participent à la relance du courant "modernist" et de certains de ses avatars (look, musique, scooters...). Le film "Quadrophenia" (1979) par ailleurs est un immense succès et remet le mouvement Mod au centre de l’intérêt de la jeunesse, y compris continentale , au grand dam des puristes. 

Après 1979 cependant, le punk-rock en voie d'extinction ou de récupération selon les groupes n'a plus la faveur des médias de masse, et le look "punk" d'une certaine frange se radicalise : les punks deviennent "not dead" (de l'expression "punk's not dead" – le punk n'est pas mort). En écho la chanson du groupe Crass créé la polémique avec son titre provocateur "Punk is Dead". C'est l'époque où apparaissent blousons en cuir cloutés avec slogans ou noms de groupes peints et crêtes iroquoises colorées. Certains sont surnommés à cette époque "the posers" (les poseurs) en raison de leurs prestations photographiques, généralement rémunérées, sur les cartes postales.

Le fossé s'accroît entre jeunes membres de groupes issus des écoles d'arts et jeunes des quartiers défavorisés qui ont adhéré à l'explosion punk avant de voir celle-ci récupérée par le "mainstream", l'industrie discographique et médiatique destinée à la grande masse. Beaucoup de punks de la première vague adoptent alors le style skinhead, ce qui passe à la fois comme un retour aux sources et une radicalisation. Le phénomène skinhead connaît une nouvelle jeunesse. Cette scission donne naissance à une forme de punk plus axée sur les préoccupations de la rue, les réalités sociales et économiques, et on parle alors de "reality punk", puis de Oi ! music, c’est-à-dire une forme liée à la culture "cockney" (l'argot populaire), vulgaire voire violente, et de là, à une forme radicale de punk-rock. L'expression « "street-punk" » sera utilisée à partir des années 1990 pour se dissocier de la connotation sulfureuse du terme Oi! music, mais il désigne le même sous-genre musical.

On retrouve dans cette musique la base du punk-rock, mais aussi l'influence des chants de supporters de football et les styles glam-rock ou pub rock des années précédentes. Les groupes punks de 1977 disaient rejeter les autres courants. Les groupes Oi! assument au contraire leur amour de groupes tels que les Who, Mott the Hoople, Slade, Small Faces ou Animals, vus comme des fondateurs et des références essentialistes. La violence de la musique (ce n'est pas toujours le cas, certains groupes étant même réputés pour être des groupes « mélodiques ») et aussi la force qui se dégage des refrains repris en chœur peuvent évoquer les tribunes des stades ou encore les chants de marche militaires. Oi !, dans l'argot "cockney", est la contraction de l'apostrophe : "Hey you !" (Hey, toi !). Ce punk-rock « de la rue » désigne aussi bien la musique de groupes punks que skinheads ou issus du mélange des deux. Les deux groupes précurseurs de la oi ! sont Sham 69 et Slaughter and the Dogs, arrivent par la suite Menace, Cock Sparrer (qui existe depuis 1973, mais produisait alors un pub-rock teinté ensuite de punk-rock à la suite d'un changement de line-up), puis viendront enfin la masse des groupes considérés comme tels, Cockney Rejects (les spécialistes de l'apostrophe Oi ! scandée, devenue cri de ralliement), The Business, The 4 Skins, Last Resort, The Oppressed, Blitz, Angelic Upstarts…

Paradoxalement, si le terme Oi! music est assimilé aux seuls skinheads, très peu des membres des groupes qui portent cette étiquette sont skinheads. Une partie est punk ou assimilée, et la plupart sont en fait des "herberts", à savoir des jeunes issus de milieux modestes qui arborent un look minimaliste et passe-partout. Sham 69, groupe emblématique de nombreux skinheads, n'ont jamais adopté un look skinhead bien que Jimmy Pursey, a lui-même été skinhead dans son adolescence. Les vidéos de la fin des années 1970 montrent souvent ce look "herbert" (mi-punk ou skinhead, mi-monsieur tout le monde). Les membres de Blitz ou de The Oppressed affichent quant à eux une apparence skinhead beaucoup plus standardisée (cheveux rasés ou tondus, chaussures montantes, polos Fredc Perry, bretelles...).

Cette époque connaît aussi un revival ska, rocksteady et "skinhead reggae" qui contribue à repopulariser le style skinhead avec des groupes comme Madness, The Specials, The Selecter poussés par la maison de disques 2 Tone, ou encore Bad Manners. Ces musiciens adoptent un style vestimentaire plutôt "modernist" ou "hard mod", mais le public comme certains musiciens de ces groupes sont largement skinheads. De nombreux artistes jamaïcains tombés dans l'oubli refont alors surface (comme le chanteur Laurel Aitken, "surnommé le "godfather of ska"" , ou le tromboniste Rico Rodriguez. Cette version du ska et du reggae énergisée par le bouillonnement punk constitue avec le phénomène Oi! Music le fond sonore de cette deuxième vague skinhead.

En 1979, contrairement à 1969, cette vague skinhead est nettement moins métissée tant dans ses influences que dans sa composition ethnique. C'est aussi à cette époque qu'apparaît l'habitude de se raser le crâne et que le slogan "ACAB" ("All the Cops Are Bastards" – Tous les flics sont des bâtards) fait son apparition, marquant une nette radicalisation des propos et des attitudes. À partir de cette année 1979, la mode skinhead dépasse le Royaume-Uni et touche l'Amérique du Nord et l'Europe de l’Ouest. En France, la première compilation skin-punk "Chaos en France - Vol 1" sort en 1982 sur le label Chaos Records créé par des membres des groupes Komintern Sect et Reich Orgasm, d'autres productions suivront). Chaque pays voit la formation d'un ou plusieurs groupes fondateurs de ces scènes locales: Nabat en Italie, Decibelios en Espagne, Daily Terror en Allemagne...

C'est une contre-culture particulièrement vivace dans les années 1980, même si elle n'attire pas, tant s'en faut, la majorité des jeunes. En France, le street punk de Camera Silens, de Komintern Sect ou de La Souris Déglinguée attire un large public skinhead. Les groupes se multiplient parmi lesquels on peut citer Wunderbach (archétype du groupe skunk, c'est-à-dire skin/punk), R.A.S, L'Infanterie Sauvage, Swingo Porkies ou encore les très nationalistes (proches du groupuscule néo-fasciste l'Œuvre Française) Tolbiac's Toads de Paris. Les skinheads sont nombreux à évoluer en marge de la scène dite « alternative » des années 1980, Les Garçons Bouchers (en particulier le multi-instrumentiste François Hadji-Lazaro) ou François Thilloy dit Fanfan des Bérurier Noir s'affichent en skinhead. Aux États-Unis, c'est autour de la scène musicale (punk) Hardcore que la mouvance skinhead se développe. Trois villes sont à l'origine de cette émergence avec chacune des groupes emblématiques de cette tendance: Washington avec le groupe Iron Cross, Boston avec Slapshot et surtout New York avec Agnostic Front, Murphy's Law, Cro-Mags. 25 ans plus tard nombreux sont les groupes musicaux qui, bien que parfois très éloignés du style skinhead en revendiquent encore l'héritage: Sick Of It All, Madball, MOD.

Cette seconde époque skinhead est aussi marquée par la politisation du mouvement. Sans que ce disque en soit la seule cause, "Strength Thru Oi!", une compilation sortie en mai 1981, cause quelques controverses. Ce qui devait être la compilation phare de cette nouvelle vague punk surnommé Oi! est à la base d'un scandale sans précédent dans l'industrie discographique britannique. Les groupes participant ne sont pas d'extrême droite, même si certains groupes assument un discours très ambigu. Mais depuis plusieurs mois, les journalistes épinglent les actes xénophobes ou racistes de certains skinheads. Or le titre de la compilation est calqué sur "strength thru joy" (de l'allemand "Kraft durch Freude", la force par la joie), organisme des loisirs nazis du Troisième Reich. La presse révèle qu'une personne représentée sur la pochette, Nicky Crane est un néo-nazi emprisonné pour violences racistes, la production ne tentera même pas de gommer les tatouages gênants du modèle. Pour l'opinion publique britannique, il semble désormais évident que les skinheads sont des activistes d'extrême droite. Le 3 juillet 1981, un concert à la Hamborough Tavern de Southall, où jouent The Business, The 4-Skins, et The Last Resort, est incendié par des jeunes Asiatiques armés d'un nombre conséquent de cocktails molotov.

Surfant sur cette vague de tension, dans une stratégie d'occupation du champ socioculturel, l'extrême droite cherche à s'implanter. Déjà certains skinheads à la fin des années soixante étaient sensibles au discours de Enoch Powell. À la fin des années 1970, le National Front fait des efforts financiers conséquents pour séduire les jeunes punks et skinheads blancs touchés de plein fouet par les effets de la crise.Cette organisation créé une presse spécialisée diffusée massivement dans les stades ou les concerts. La stratégie s'avère dans un premier temps payante puisque il multiplie ses effectifs en réussissant à intégrer dans ses rangs les plus jeunes d'entre eux. Cet entrisme a pour conséquence d'emmener des jeunes sensibles au discours de droite à adopter le style de vie skinhead sans en avoir les références culturelles et historiques. De 1979 à 1980 il existe même un éphémère "Punk Front" qui travaille activement à la diffusion des du National Front parmi la scène punk. Le "British National Party", né en 1982, suit la même trajectoire politique quelques années plus tard. Précisons qu'encore aujourd'hui, malgré une tentative de diluer son discours, ce parti refuse l'adhésion des Britanniques de couleur. Ian Stuart, chanteur du groupe punk Skrewdriver, est un exemple typique de cette dérive. Skrewdriver est en 1977, au début de sa carrière, un groupe glam-punk parfaitement apolitique (comme l'immense majorité des groupes punks à cette époque), mais particulièrement provocateur. Après une séparation de courte durée , Ian Stuart , qui jusque-là cachait son engagement auprès du National Front depuis 1975, reconstitue le groupe sous une forme politisée ouvertement néonazi. Il se trouve au cœur du dispositif créé par le National Front qui appuie financièrement la création du White Noise Club, principale cellule de promotion de ce courant culturel naissant. En 1987, la percée éléctorale du National Front amène ce dernier à repenser cette stratégie couteuse qui le coupe d'une potentielle base électorale effrayé par les débordements des émules de Ian Stuart et lui coupe les vivres. Il crée alors "Blood and Honour" . Initialement une revue, Blood and Honour devient un mouvement ultranationaliste, raciste et en particulier antisémite. Ian Stuart ne cache plus sa fascination pour Hitler et apporte directement son soutien aux associations néonazies, aussi bien au Royaume-Uni qu'en Allemagne. Il est suivi par une partie des skinheads et certains punks qui adoptent un comportement de plus en plus violent et basculent vers l'extrême droite. Beaucoup sont des hooligans fascinés par la violence sous toutes ses formes. Ils hurlent "Sieg Heil!" ou "Heil Hitler" dans les concerts et déclenchent de fréquentes rixes avec les autres skinheads ou les punks dans les rues des métropoles européennes. Mais leurs principales cibles sont les Noirs ou les immigrés. Le "paki bashing" reprend, motivé par le racisme. Ian Stuart Donaldson ne cache pas ses arrière-pensées politiques lorsqu'il déclare à la télévision belge : 

Idéologiquement ces premiers skinheads et punks néonazis ratissent très large dans leurs influences: rescapés du nazisme britannique des années trente qui servent de mentors, partisans des milices loyalistes d' Irlande du Nord, antisémites de tout poil, xénophobes échaudés par l'immigration , anticommunistes qui dénoncent les États soviétiques, hooligans ultra-violents, se mélangent pour ces punks et skinheads dépourvus de repères idéologiques qui aiment provoquer en arborant des insignes nazis. Le contexte extrêmement dur de la Grande-Bretagne thatcheriste précipite le phénomène.

Écœurés par une évolution de plus en plus xénophobes de cette contre-culture et fidèles à leurs musiques noires, les skinheads non racistes ont commencés à se regrouper à partir de 1979-80 dans divers groupes affinitaires ou politisés. Il existe marginalement "Skinheads Against the Nazis" (SAN, impulsé et contrôlé par le Socialist Worker's Party, trotskiste) groupe basé dans l'East End (pourtant bastion des skins d’extrême droite) qui aura un écho quasi nul.
En parallèle certains individus ou bandes participeront activement à la campagne Rock against Racism initiée par l'Antinazi League, ils constituent les premiers noyaux qui n'ont pas encore été nommés Redskins ).

Enfin certaines Firms de skins (London Trojan Skins, Glasgow Spy Kids) tenteront de faire survivre, non sans mal, le style traditionnel. Faute de trouver un espace d'expression et une coordination suffisante au grand jour, ces derniers seront réduits à l'underground. Ils sont cependant les fondateurs du courant traditionnel qui essaimera jusqu'à nos jours.

C'est aux États-Unis que va naître le premier réseau international de skins antiracistes avec l'acronyme SHARP ("SkinHeads Against Racial Prejudice"). Ce mouvement, fondé à New York en 1987, est lui-même inspiré d'un groupe de skinheads de Cincinnati appelé "Baldies Against Racism" (Les rasés contre le racisme) existant depuis 1985. La figure emblématique du mouvement SHARP est Roddy Moreno, leader du groupe de Oi ! gallois The Oppressed et importateur en 1988 du SHARP au Royaume-Uni. The Oppressed chantent "Work together", hymne à la classe ouvrière de toutes les origines. Mais avant que les « pare-feux » ne se mettent à fonctionner, l'image des skinheads, et même de certains groupes emblématiques de la scène, a eu à pâtir de la dérive vers le néonazisme d'une partie d'entre eux. Ainsi les Sham 69 sont désespérés que de nombreux skinheads d'extrême droite fréquentent leurs concerts (la "SHAM Army", cohorte de fans du groupe, étant même largement volontairement noyauté par le National Front ). Son chanteur Jimmy Pursey décide alors de remettre les pendules à l'heure en faisant jouer le groupe dans les festivals RAR ("Rock Against Racism") ou, par exemple, contre l'apartheid en Afrique du Sud.

Ces festivals seront les points de ralliement des skinheads proches des mouvements antifascistes radicaux ou de l’extrême gauche. Les Sham 69 adaptent le chant révolutionnaire chilien "El pueblo unido jamas sera vencido" (Le peuple uni ne sera jamais vaincu) en "If the kids are united they will never be defeated" (Si les jeunes sont unis, ils ne seront jamais battus). Ces groupes réaffirment leur fierté d'appartenir à la classe ouvrière et de partager ses valeurs : fraternité, solidarité, luttes sociales… À la même époque les Dead Kennedys (groupe punk californien) dénoncent la dérive des punks et skinheads nazis dans le morceau "Nazi punks Fuck off !".

Certains skinheads antiracistes sont engagés au sein du SWP, "Socialist Worker's Party", organisation marxiste révolutionnaire trotskiste qui participe aux mouvements en réaction à la politique libérale du gouvernement Thatcher (remise en cause d'acquis sociaux, restructurations dans l'industrie et les mines…). Le noyau dur de ces skinheads devenus militants révolutionnaires gravite autour du groupe de soul-rock The Redskins, animé par des militants du SWP. Malgré les accusations des militants nationalistes de vouloir faire basculer l'Europe Occidentale dans la sphère soviétique ces militants trotskistes, sont anti-staliniens et opposés à l'URSS. La plupart des skinheads antiracistes sont cependant de cette époque au Royaume-Uni sont plutôt proches du travaillisme (l'aile gauche du "Labour Party" anime le "red wedge", le "coin rouge", à destinations des jeunes notamment punks et skinheads) et du syndicalisme réformiste.

Les skinheads antiracistes considèrent les nationalistes et les néonazis comme de faux skinheads et les appellent "boneheads" (littéralement « crânes d'os », en fait l'équivalent anglais de « crétin »). Les skinheads d'extrême droite appellent leurs opposants "reds" (« rouges » ou « gauchos » en français). Ces termes, péjoratifs dans l'esprit de ceux qui les utilisent, ont toujours cours aujourd'hui.

Actuellement, le phénomène skinhead est profondément divisé et hétéroclite, le terme mouvance est celui qui correspond le mieux à une culture urbaine devenue plurielle. Le néophyte aura bien du mal à les distinguer, d'autant plus que les codes vestimentaires sont parfois similaires malgré des tendances politiques très différentes. Comme la culture skinhead est fondée sur un support musical, la lecture des chansons, l'imagerie des pochettes de disque, les labels de distribution, de production, les logos ou slogans affichés permettent souvent de localiser politiquement les artistes. Cependant il faut bien comprendre que l’affiliation ou non à un courant politique n'est qu'une des composantes de l'identité skinhead.

Il y a des points communs qui rassemblent (presque) tous les skinheads : ils sont généralement issus des classes sociales modestes ou moyennes et sont fiers de leurs origines sociales, ils font de la rue, des bars et des salles de concerts leur espace de sociabilité. Enfin, les skinheads sont également très actifs dans la rédaction et la diffusion de fanzines dédiés à la musique, au football et à d'autres cultures (comme le tatouage ou le scooterisme par exemple).

Parmi les branches de la mouvance skin qui n'ont pas forcément de coloration politique générale, on rencontre en particulier les "Trojan skinheads" ou skinheads traditionnels. Perpétuant « l'esprit de 1969 » (en référence à l'ouvrage de Georges Marshall), fans de reggae, de soul, de rocksteady et de ska, ils circulent souvent en scooter et sont parfois assimilables à la scène "mod". Ils ne mêlent pas forcément musique et politique, même s'ils constituent le gros des bataillons du S.H.A.R.P. Le terme "Trojan skin" (ou "Sussed skin") est à l'origine une précision utilisée dans la scène britannique pour se dissocier des groupes néonazis. Cette catégorie de skinheads met un point d'honneur à suivre de manière très précise (voire stricte) le "dress code" et les valeurs des skins originaux.

Ils affichent un antiracisme sincère à travers leur amour pour les musiques d'origine jamaïcaine ou afro-américaine et revendiquent leur appartenance à la classe ouvrière. Ils sont, au sens historique, les fidèles continuateurs de la première vague skinhead. Ces skins vont accompagner la renaissance du courant traditionaliste au niveau international. Collectionneurs passionnés d'une musique dont les 45 tours ne coûtent plus rien au début des années 1980 en Angleterre, le pèlerinage à Londres et le shopping qui en découle favorisent l'extension du phénomène au niveau international. Ils seront les « gardiens du temple » en rédigeant un nombre incroyable de publications, en organisant des soirées, ou en s'impliquant dans le support à la scène dite du second revival (scène ska qui fait suite au mouvement 2 Tone, avec des groupes tels que les 100 Men, Maroon Town, No Sports, Frelons, Braces et de nombreux autres).

Cette scène permettra la survie dans la mémoire collective et la redécouverte de vieilles stars tels Laurel Aitken ou Derrick Morgan. Il faudra attendre le milieu des années 1990 pour voir un prolongement de cette scène se transformer en nouvelle vague de fond notamment grâce à des groupes tels les Toasters, à des labels allemands comme Porkpie ou Grover, américains tel Moon Ska ou Stubborn, ou espagnols comme Liquidator, et à la reprise en main instiguée par le Sharp au niveau international. Cette effervescence finit par dépasser le strict milieu skin/ska et des groupes, dont les membres sont parfois issus de cette tribu, connaissent un succès qui semble concerner le grand public, comme The Slackers, Hepcat ou Aggrolites. 

En France, des groupes Ska sont fortement marqués à la fois par le son original et le mode de vie skinhead, comme les Rudeboy System, les 8°6 Crew et les Branlarians. Aujourd'hui la scène des skins d'obédience Trojan est essentiellement présente dans les sound-systems avec des villes où ces évènements drainent un public international : Barcelone, San Francisco, Hambourg pour ne citer que les capitales les plus importantes du genre.

Ces termes renvoient à la nébuleuse footballistique. Les "hooligans" sont des supporteurs qui utilisent la violence . Les hooligans habillés en skinheads représentent aujourd'hui une infime minorité, tant au Royaume-Uni que dans le reste du monde. Les "casuals" sont des hooligans bien habillés, très éloignés par leur allure vestimentaire du skinhead ou du « jeune de banlieue ». Leur style est un emprunt sans cesse renouvelé aux tendances les plus avant-gardistes du "sportswear", ils s'inscrivent à leur manière dans une certaine filiation moderniste tout en tentant de se rendre inaperçu par les forces de police.

L'assimilation parfois exagérée entre skins et « tribus » de casuals repose essentiellement sur le fait que nombre d'entre eux sont souvent d'anciens skins au début du mouvement.

Les skinheads politisés sont des skinheads affichant des opinions politiques voire s'investissant dans des organisations, politiques, syndicales ou associatifs. Ils évoluent généralement à la périphérie des différents courants de l'extrême gauche ou d'extrême droite. Dans ces groupes, le mode affinitaire est priorisé mais force est de constater que l'engagement réel dans des structures militantes dépend de la vitalité des scènes locales. Leur allégeance à un courant politique est visible au travers de leurs concerts, leurs fanzines et leur manière de s'afficher auprès du grand public. En dehors de similitudes vestimentaires et musicales (musique oi!), les skinheads d'extrême droite et d'extrême gauche s'opposent radicalement, parfois par la violence, aucune de ces tendances ne reconnaissant de légitimité à l'autre.

Une partie des skinheads affiliés à l’extrême droite est initialement proche des partis électoralistes (particulièrement le "British National Party" Au Royaume-Uni).

Les skinheads nationalistes ne sont pas tous racistes mais sont contre l'immigration et pour l'extrême droite, ils se rapprochent des skinheads néonazis du fait qu'ils partagent plus de points communs que d'opposition. Les skinheads nationalistes s'opposent à la présence de minorités « majoritaires » parmi les minorités. Par exemple, les maghrébins en France, les Turcs en Allemagne, et partout où ils se trouvent, ils s'attaquent aux militants d'extrême gauche (anarchistes, antifa, communistes, etc.), et sont antisionistes, d'autres vont plus loin et sont ouvertement antisémites.

Surnommés «Boneheads» (bien qu'ils soit probable qu'ils haïssent cette appellation), ils sont ouvertement antisémites, racialistes ou racistes, ils sont connus pour leurs agressions et faisaient parfois la une des médias dans les années 80, ils sont contre les antiracistes, communistes, juifs, homosexuels, et contre les skinheads rivaux. Ils sont parfois très organisés, en gang ou en groupes armés.

En France, la seule tentative partiellement réussie d'organiser politiquement les skinheads d'extrême droite est l'œuvre de Serge Ayoub, à travers le groupuscule Jeunesses nationalistes révolutionnaires qui a entretenu des relations très complexes avec le Front national de Jean-Marie Le Pen, puis de Marine Le Pen. La tentative de Roger Holeindre d'intégrer directement des skinheads au Front national dans les années 1980 se solde par un échec partiel. Les skinheads et leur comportement violent et indiscipliné semblent inconciliables avec la stratégie de respectabilité d'une force politique en pleine expansion. Après le remplacement de Roger Holleindre par Bernard Courcelle comme responsable du service d'ordre du Front national, le Département protection sécurité (DPS), le Front national restructure son fonctionnement dans les années 1990 et met en place des critères plus stricts de sélection. De plus, la scission du Mouvement national républicain (MNR) de Bruno Mégret réduit d'autant la présence de radicaux dans ses rangs. Par la suite, la stratégie de normalisation du Front national mise en œuvre par Marine Le Pen à partir de 2011 conduit « les éléments les plus radicaux [à se tourner] vers des groupuscules plus en phase avec leurs idées. Et des groupes skinheads ont eux aussi recommencé à se développer, en Picardie, dans le Nord, en Alsace ou dans la région lyonnaise. Ce sont des bandes pas forcément très politisées mais qui entretiennent des rapports plus ou moins forts avec les organisations nationalistes.

Les rapports avec le Front national sont marqués par des visées stratégiques divergentes : .

Les skinheads nationalistes et leurs frères néonazis, les skinheads NS , sont généralement homophobess. Les détracteurs les surnomment 'boneheads' (littéralement, crâne d'os), terme péjoratif utilisé par leurs opposants, ou de "naziskins". Ils sont parfois très actifs et constituent généralement les troupes de choc de l’extrême droite la plus radicale. En France, dans la période 1985-89, ils représentaient la partie la plus visible des skinheads et probablement la plus importante numériquement. Les skinheads néonazis ont leur propre réseau pour se regrouper tels Blood and Honour, Hammerskins. D'autres groupes non spécifiquement skinheads comme Combat 18, un groupe terroriste Britannique organisé à partir du kop fasciste des "Chelsea Headhunters" ou le Ku Klux Klan américain les accueillent. Ces skinheads "WP" sont très visibles en Scandinavie, en Allemagne de l'Est (ex-RDA), dans certaines régions des États-Unis, ainsi qu’en Europe de l’Est, notamment en Pologne, Serbie ou surtout Russie, pays qui compte le plus grand nombre d'entre eux (où ils défraient souvent la chronique par leurs nombreuses agressions contre des immigrés ou Russes orientaux, allant couramment jusqu'au meurtre).

L'apparence vestimentaire a évolué du look traditionnel avec des apports des années 1980 (jean passés à l'eau de Javel, treillis camouflage) parfois jusqu'à un look paramilitaire exacerbé, le tout accessoirisé de symboles du Reich et de groupes néofascistes (selon ce que permet les législations des différents pays où cette tendance est présente). Les skinheads néonazis se réclament de la classe ouvrière. Dans les années 1980, beaucoup d'entre eux se considéraient comme les fils spirituels des SA (Sections d'assaut, brigades de militants nazis des années 1930 en Allemagne, recrutés généralement dans la pègre). Les S.A. tenaient un discours à la fois nationaliste, raciste mais aussi social peu développé et étaient issus du monde ouvrier et de la petite bourgeoisie. Les membres d'organisations néonazis au début des années 1980 ont cherché à instrumentaliser en valorisant la conduite des skins les plus racistes par le biais d'une assimilation aux S.A.

En France on peut citer le Mouvement Nationaliste Révolutionnaire de Jean Gilles Malliarakis qui à l'instar de Roger Holleindre tentera de recruter dans les milieux skins. Un certain nombre de la bande « Nazi Klan » de Serge Elie Ayoub, deviennent les Jeunesses Nationalistes Révolutionnaires qui avant de prendre leur autonomie politique sont la branche jeunesse du mouvement.

Le lien qui unit les skinheads NS du monde entier est le racisme : ils pensent représenter l'élite de la race blanche européenne et se préparent à la « guerre des races ». En Amérique du Nord, le terme « suprémaciste » désigne ceux qui croient en la supériorité de la race blanche. À ce racisme et ces références historiques vient parfois s'ajouter l'imagerie ésotérique relevant du paganisme, du celtisme.

La musique des skinheads N.S est le R.A.C : "Rock Against Communism" (ou rock anticommuniste). Paradoxalement le terme R.A.C n'est pas un style à proprement parler, il vient du nom des premiers festivals de rock NS de la première moitié des années 80. Ce qui constitue le fondement du R.A.C est le message politique généralement minimaliste. Les thèmes abordés sont les mots d'ordre et slogans de l’extrême droite dans sa version la plus radicale. La plupart des groupes R.A.C sont diffusés de façon discrète, par la vente par correspondance depuis des pays où la législation sur le racisme est la moins contraignante, ou lors des concerts. Les bénéfices générés par les productions sont parfois conséquents, le contrôle des revenus de la vente de disques et de merchandising pouvant être réinvestis dans les organisations politiques, donne parfois lieu à de véritables guerres internes (c'est particulièrement le cas depuis le décès accidentel de Ian Stuart Donaldson, vocaliste de Skrewdriver).

Beaucoup de « distros » (petites organisations indépendantes de distribution musicale) en France ou en Allemagne refusent de vendre des disques R.A.C (soit par antifascisme, soit pour éviter les ennuis). Ceux qui acceptent de distribuer cette musique, comme Bords de Seine, à Paris, sont alors identifiés par les skinheads antifascistes comme des agents sournois de l'extrême droite. Chez les skinheads le simple commerce n'est jamais neutre.

Parmi la multitude de groupes musicaux néonazis, souvent d'une durée de vie éphémère, on peut citer existant ou séparés à l'heure actuelle: Les Allemands Landser, les Français Légion 88, Bunker 84, Division Skinhead, les Australiens Fortress, les Polonais Konkwista 88, les Américains Bound For Glory ou encore les Suédois Pluton Svea. Le groupe de référence reste les Anglais de Skrewdriver (cf la première partie de l'article).

Si les premiers groupes s'affichant comme tels sont assimilables musicalement à la Oi! music britannique, le style a progressivement évolué vers le métal, le hardcore, etc.

Il existe, depuis quelques années, un rapprochement entre les skinheads "white power" et certains milieux black metal philonazi regroupés sous l'appellation national socialist black metal (NSBM), créant un style hybride qui commence à prendre une certaine ampleur, notamment en Europe de l’Est et aux États-Unis. Si l'on constate aussi une adhésion aux idées d'extrême droite dans une partie minoritaire des scènes industrielle et dark folk, la mouvance gothique est loin d'adhérer massivement à l'extrême droite. Il y a là encore une récupération partielle. Seul le R.A.C peut être considéré, par les idées qu'il véhicule, comme authentiquement d'extrême droite. Il s'agit d'ailleurs de la première stratégie réussie par l’extrême droite de création d'une contre culture destinée aux jeunes. Cependant nationalistes et néonazis fréquentent aussi d'autres univers musicaux qui ne leur sont pas réservés.

À l'origine, il s'agit d'un groupe de soul-rock britannique The Redskins (1978 - 1987), dont plusieurs membres appartenaient au "Socialist Workers Party" et en étaient des permanents. Le nom vient d'une bande de skins de Sheffield proche du minuscule "British Communist Party". Le groupe, qui tient un discours révolutionnaire sur fond de musique soul mâtinée de punk rock, passera la majorité de sa courte carrière à soutenir les luttes de résistance contre les dégâts sociaux et politiques du libéralisme de Margaret Thatcher. Notable signe d'indépendance et de radicalisme, ils refuseront de devenir animateurs du "Red Wedge" (le « coin rouge ») avec d'autres groupes et artistes (Style Council, Billy Bragg, Bronski Beat/The Communards…) jugeant celui-ci trop proche du Parti Travailliste. Leurs incessantes tournées leur permettent d'être le point de rencontre où se regroupent d'authentiques skinheads « rouges » qui commencent plus ou moins à s'organiser pour reprendre la rue aux fascistes ou défendre les concerts. Ces skinheads sont regroupés dans la "Red Action Skinhead", fraction skinhead de la "Red Action", un petit groupe politique trotskiste issu d'une scission du SWP sur la question de l'antifascisme dans la rue, ou issus de bandes à caractère particulier, comme celle des skinheads de Coventry. Enfin ils permettront de fédérer nombre de skins traditionnels déçus par le tournant raciste de la scène, d'ex-punks rejetant le folklore "punk's not dead" et des étudiants en rupture de fac en amenant au grand public leurs thèmes de prédilection : anti-apartheid, soutien aux mineurs en grève et antiracisme dans les quartiers populaires.

En France, les premiers redskins sont portés par l'émergence de la scène dite du rock alternatif, représentée par Bérurier Noir, Nuclear Device, Ludwig von 88, Babylon Fighters, Les Kamioners du Suicide, Laid Thénardier. Ils sont particulièrement actifs et reconnus nationalement durant les luttes étudiantes de l'hiver 86 où ils contribuent à sécuriser les manifestations contre les attaques de militants d'extrême droite. Ils affichent un look empruntant autant aux skinheads qu'aux tribus « rock » en général (punks, mods, psychobillys…).

Nombre de ces redskins ont aussi gravité autour du réseau SCALP (sections carrément anti-Le Pen ou section de contre-attaque à la peur) et en particulier du SCALP-REFLEX parisien. C'est le cas de l'une des premières bandes de « chasseurs de skins », les Red Warriors.

Au reflux de la vague alternative, à partir de 1989, certains se sont ensuite rapprochés du style skinhead originel en conservant parfois quelques particularismes hérités de cette première vague redskin : bomber retourné côté doublure orange, lacets rouges, insignes et patches communistes divers...

C'est dans le Sud de la France, à Toulouse, Marseille et Bordeaux que la jonction avec un mouvement skin plus traditionnel va s'opérer encore plus avant. Mais tous les redskins ne se considèrent par pour autant comme skinheads. Si la majeure partie d'aujourd'hui peut être rattachée aux skinheads (musiques, style vestimentaire ou de vie…), il subsiste un courant qui n'en reste qu'à la marge ou, même, s'en éloigne parfois au niveau culturel (investis dans le rap…) et ne cultivant souvent avec les autres redskins qu'un lien social et politique.

Fondé à New York au tout-début des années 1990, le réseau RASH (Red and Anarchist Skinheads), surtout européen et – depuis quelques années – latino-américain ou encore indonésien, regroupe d'anciens redskins de la première vague et de nouveaux skinheads engagés à l'extrême gauche, parfois issus de la mouvance SHARP, le premier groupe Rash étant issu du SHARP new-yorkais et de l"'Anti Fascist Action". Ses membres considèrent leur appartenance au mouvement skinhead comme un complément de leur engagement militant, le skinhead devenant une forme d'idéal ouvriériste, mais l'inverse est parfois vrai : certains skinheads « sentimentalement » ou culturellement de gauche, mais sans engagement, deviennent militants par les fréquentations, la formation ou l'acquisition expérimentale au sein de bandes et groupes où sont présents des militants du RASH.

En France, le sigle Rash (deux haches croisées, visuel popularisé par le groupe indépendantiste basque Negu Gorriak) apparaîtra tout d'abord au Havre puis à Bordeaux autour des rédacteurs du bulletin Red'n'Skinhead (1995), puis du fanzine The Shaven Republic (ou RASH est décliné en Red Action Skin Head), pour ensuite s'implanter à Paris. La plupart des skinheads RASH en France gravitent principalement autour de la, CNT-AIT, Ligue communiste révolutionnaire (ou de nos jours le NPA), le réseau No Pasaran (issu du SCALP) mais aussi la Fédération anarchiste, l'Union anarchiste / the Anarchist Black Cross, l'Organisation communiste libertaire et différents groupes trotskistes ou guévaristes, voire marginalement autonomes post-maoïstes…

Ce mouvement revendique un antiracisme viscéral et un antifascisme radical et joue parfois la surenchère vis-à-vis du SHARP, tantôt considéré comme un allié, tantôt comme un concurrent (mais pas comme un ennemi). Les thèmes de la lutte des classes, de l'urgence révolutionnaire ou de l'internationalisme sont récurrents. Un slogan des skinheads Rash est : « Pas de guerre entre les races, pas de paix entre les classes. »

Durant les années 2000 en Allemagne, au Royaume-Uni et en France, des skinheads Rash ou proches d'autres mouvements libertaires (tels l"'anarchist black cross") ont été impliqués dans les "black blocks". Ces derniers sont des môles de contestation musclés présents dans les manifestations anticapitalistes et altermondialistes. Ces "black blocks" s'en prennent aux forces de l'ordre mais aussi aux symboles du capitalisme comme les banques ou certaines chaînes de restauration rapide.

Parmi la scène skinhead d'extrême gauche, on peut citer les italiens de Banda Bassotti, Erode, Los Fastidios ou les groupes indépendantistes catalans marxisants Opcio K-95 et Pilseners, les madrilènes de kaos Urbano, Guerilla Oi! ou Non Servium, les basques de Suburban Rebels ou Mossin Nagant, les groupes libertaires parisiens Brigada Flores Magon et Ya Basta ! ou les groupes bordelais Los Foiros et Redweiler.

Nombre de groupes, sans être d'ailleurs idéologiquement marqués, soutiennent certaines initiatives du réseau Rash. On peut citer : les Allemands de Stage Bottles, les légendes britanniques Angelic Upstarts, le premier groupe Oi! Italien Nabat ou encore les très Sharp The Oppressed…

À noter que certains skinheads Sharp, Rash et de nombreux redskins s'affichent aussi comme indépendantistes, voire nationalistes. Ils se réclament des nationalismes de libération nationale en particulier au sein de minorités qui luttent pour leur reconnaissance ou leur indépendance : Bretons, Basques, Catalans, Québécois, Occitans… Ce nationalisme est généralement inspiré des groupes marxisants et internationalistes des années 60 et 70, il n'y a donc pas d'équivoque possible.

Partout dans le monde où il y a une scène skinhead, nombreux sont ceux et celles qui refusent et rejettent à des degrés divers toute affiliation politique à un parti ou une tendance à travers leur identité skinhead. Ils constituent une part numériquement très importante du monde skinhead. Toutefois, cela ne signifie pas que ces skinheads sont dépourvus de conscience politique. En réalité, cette tendance se distingue par un refus de mélanger musique et culture skinhead avec quelconque engagement. Il est probable que la plupart d'entre eux votent, participent à des débats de société, s'engagent par ailleurs. Mais ils ne l'affichent pas sur leurs vêtements. Pour certains, le militantisme politique au sein de la scène skinhead est un poison et le mouvement skinhead doit redevenir aussi apolitique que les scènes mod, psycho, scooteriste ou rocker. Cette mouvance apolitique n'est ni structurée ni organisée, mais cette tendance qui met paradoxalement son apolitisme comme identité politique fédératrice au centre de ses préoccupations est présente internationalement et se trouve parfois prise dans les affrontements de factions politisées antagonistes.

Dans les scènes marqués à gauche de l'échiquier politique, les apolitiques sont parfois considérés comme des crypto-fascistes ou des spécialistes du retournement de veste. Il est vrai que certains skinheads français des années 1980 ont commencé par être apolitiques avant de devenir néonazis et que des passerelles existent entre « apos » et skins plus marqués à droite, mais aussi à gauche. On peut évoquer ici le très controversé chanteur du groupe L'Infanterie Sauvage, eurasien qui finira chanteur dans un groupe néonazi, mais il y eut aussi des parcours inverses. Les skinheads apolitiques se sentent parfois aujourd'hui pris entre « le marteau et l'enclume » de camps à l'antagonisme irréductible. Il est vrai que les tensions entre différentes tendances de skins rendent la situation pour ces skinheads plus que délicate, conduisant parfois ces derniers à prendre position d'une manière qui est justement politique. Lorsque le groupe français "Œil pour œil", autoproclamé apolitique, choisit d'intituler son album "RAC - Rock Anti Caillera", il provoqua un mini scandale. De fait, un certain nombre de thèmes abordés dans ses chansons le sont d'un manière idéologiquement proche de l’extrême droite identitaire. Le sigle RAC désigne en fait la musique des skinheads néonazis et signifie "rock against communism" (rock anticommuniste). D'autant plus que de nombreux skinheads d'extrême droite avaient fait de la chasse aux délinquants et dealers (« la caillera », c'est-à-dire « la racaille ») un de leurs fantasme de prédilection.

D'une manière générale, on trouve des skins « apolitiques » gravitant dans tous les courants de la scène skin.

À l'origine, il s'agit d'un regroupement de skins refusant l'embrigadement par l'extrême droite au début des années 1980 aux États-Unis. Le mouvement SHARP américain peut être considéré comme initialement apolitique. Les fondateurs du SHARP en 1987, Marcus Pochelo et Bruce Kreitman, sont basés à New-York et sont principalement liés à la base du NYC hardcore et non à la scène traditionnelle. Ils refusent l'affiliation à une tendance politique précise et affichent un patriotisme US farouchement antiraciste. La réalité est différente en Europe où ils sont globalement liés aux groupes antifascistes radicaux issus des milieux autonomes et alternatifs.

Le mouvement SHARP ("Skin Heads Against Racial Prejudice", en français : « Skinheads contre les préjugés raciaux ») désigne donc de façon générale un mouvement de skinheads issus des différentes tendances musicales (reggae, Oi !, hardcore Punk, ska) qui se positionnent contre le racisme et le fascisme. Le SHARP est une tendance active dans les groupes luttant contre l’extrême droite. Si le SHARP a très fortement contribué au développement de la scène skinhead en étant un de ses courants dominants au début des années 1990, il s'agit davantage de nos jours d'un positionnement individuel que d'un réel réseau actif organisé tel qu'il avait commencé à l'être dans la seconde moitié de la décennie.

Le positionnement des skinheads chrétiens est ouvertement antiraciste et antinazi (mais pour autant, il existe aussi des skinheads d'extrême droite chrétiens affiliés au Ku Klux Klan). Présents essentiellement en Amérique du Nord (Canada et États-Unis) où la scène rock chrétienne est importante, les skinheads chrétiens font rarement parler d'eux en Europe.

Aux États-Unis, ils sont souvent issus de la mouvance évangélique progressiste plutôt que du catholicisme ou de l'évangélisme conservateur. Ils sont cependant beaucoup plus présents dans les milieux ska/rocksteady que dans le milieu "Oi!". Parmi les groupes skins chrétiens, on peut citer le groupe de ska/rocksteady américain "The Israelites", le groupe de punk hardcore américain "The Deal", le groupe street-punk américain aux sonorités écossaises "Flatfoot 56" par contre il s'est avéré que le groupe Oi! allemand Jesus Skins qui fut un temps le fer de lance de cet épiphénomène ultra marginal était en fait un canular orchestré par des anarchopunks et des skins hambourgeois.
Il convient de distinguer l'existence d'individus gays et lesbiens au sein de la mouvance skinhead et la sous-culture gayskin.
Les premiers sont investis dans la scène skin au-delà des questions d'identité sexuelle. Ils sont cependant parfois regroupés au sein de collectifs antihomophobes et antiracistes dans la mouvance SHARP américaine (collectif Brotherhood), espagnol (collectif Joligan) ou Rash (notamment en Allemagne). Il s'agit de personnes partageant une culture identique à leurs homologues hétérosexuels mais homosexuels affirmés et revendiqués comme tels, ils ne constituent pas un mouvement ou une tendance en tant que telle.

Les seconds sont plus déroutants à cerner. La mode skinhead est ostensiblement réinvestie par certains homosexuels (dans sa version la plus "militariste"), appelés "gayskins", . Dans la pornographie homosexuelle masculine, le skinhead est un avatar du "working class boy" (jeune ouvrier), généralement teinté de sadomasochisme. L'avatar fantasmé de cette tendance est Nicky Crane. Ancien membre de la sécurité du groupe néonazi Skrewdriver il tenta d'organiser les "Gay Aryan Skinheads" (skinheads aryens gays), qui se référaient aux S.A et aux mœurs « grecs antiques » de ces derniers. Ce dernier mourra du S.I.D.A après avoir renié ses engagements politiques. Très connu dans le milieu homosexuel Londonien pour son image de dur, mort prématurément, Nicky Crane est devenu une figure symbolique de la mouvance Gayskin indépendamment de ses convictions.

Plus marginalement encore des groupuscules de skinheads néonazis homosexuels existeraient. Ces skinheads homosexuels nazis tentent surtout, à travers leurs contradictions, de faire exister une identité marginale en soi autant que dans leur propre espace socio-politique.
La culture gabber, sous-culture imprégnée de musique techno hardcore de genre gabber, s'est développée aux Pays-Bas dans les années 1990. Le style vestimentaire de ses membres, les gabbers, a souvent été assimilée à tort par les médias à celui de la scène skinhead.

Politiquement, la majorité des gabbers affiche des convictions antiracistes et antifascistes , une part relativement restreinte de ses auditeurs évolue dans la sphère d'influence de l'extrême droite, part estimée à 5 %. Néanmoins, un certain nombre de groupes politisés tentent de s'attirer les bonnes grâces de ces jeunes, souvent issus des milieux populaires, particulièrement les groupes nationalistes et identitaires à la recherche de jeunes militants dans ces milieux. Une minorité de membres de ce courant culturel, politisés, ont été désignés sous le nom de , appellation pas toujours revendiquée par ces personnes.

Le look des gabbers a fait le jeu d'amalgames, apparentant faussement le mouvement gabber au mouvement skinhead, simplement dans sa version la plus « streetwear », et pour certains des éléments vestimentaires identifiant les groupes hooligans (marques de sports Lonsdale, Fred Perry...) les faisant nommer, pour la frange la plus violente, les .

Cependant, la consommation fréquente de stupéfiants par les gabbers, les bagarres et la violence des thèmes abordés par la musique qu'ils écoutent ont fait des gabbers une cible toute choisie des politiques, stigmatisant l'ensemble de la scène gabber du fait de ces débordements, que toutefois nul organisateur d'événement gabber ne nie.

Autre élément identitaire, la minorité gabba-skin pratique le hakken tout comme les autres gabbers ; ce style de danse, proche du style jumpstyle quoique plus rapide et syncopé, est parfois considéré comme une sorte de marche crypto-fasciste voire nazie. Toutefois, les danseurs clament haut et fort qu'il ne s'agit que d'une danse inoffensive à l'image du style musical, visant à , .

Géographiquement, cette mouvance gabba-skin est peu présente en France (dans le Nord essentiellement), au Royaume-Uni, au Canada, en Suisse et aux États-Unis. En revanche elle, est plus importante aux Pays-Bas, en Belgique et en Allemagne. Globalement, les liens de cette scène avec les différentes composantes de la scène skin sont très faibles, pour ne pas dire inexistants.

Enfin, les gabbers revendiquent souvent la consommation de drogues comme un marqueur identitaire. S'il y a un rapprochement à faire sur le caractère antiraciste des causes de ces deux sous cultures il y a disjonction nette entre gabbers et skinheads.






</doc>
<doc id="2903" url="https://fr.wikipedia.org/wiki?curid=2903" title="Straight edge">
Straight edge

Le straight edge est une sous-culture et un sous-genre musical du punk hardcore dont les adhérents ne consomment ni alcool, ni tabac et autres drogues récréatives. C'était une réaction directe au dévoiement de la révolution sexuelle, à l'hédonisme destructeur et aux excès associés au punk rock. Pour certains, cela s'étend à ne pas s'engager dans la promiscuité sexuelle, à suivre un régime végétarien ou végétalien et à ne pas consommer de caféine ou de médicaments. Le terme a été adopté et popularisé à partir de la chanson "" du groupe de punk hardcore des années 1980 Minor Threat.

Le "straight edge" émerge au milieu des années 1980 à partir de la scène hardcore. Depuis lors, une grande diversité de convictions et idées ont été intégrées dans le mouvement, véganisme abolitionniste (végétarisme participant ou non à l'exploitation animale selon les positions), bien-être animal, communisme ou croyances de la conscience de Krishna.
Bien que certains groupes "straight edge" soient assimilés à un par les forces de l'ordre aux États-Unis, une étude de 2006 démontre que la majeure partie des groupes "straight edge" sont parfaitement pacifiques. Mais si la scène punk hardcore à Washington D.C. par exemple est félicitée pour son implication dans des changements sociaux positifs, le mouvement youth crew des années 1980 et le mouvement végétalien des années 1990 suscitent de nombreuses polémiques. De par la rigidité de certains de ses défenseurs, le "straight edge" est parfois perçu avec scepticisme, moquerie ou hostilité malgré l'idéologie moins dogmatique de certains autres.

En 1999, le sociologue William Tsitsos, professeur associé au Department of Sociology, Anthropology and Criminal Justice de l'Université de Towson, identifie trois ères durant lesquelles s'est impliqué le "straight edge" depuis son lancement au début des années 1980. Depuis cette analyse, d'autres observateurs ont identifié une nouvelle ère dans le mouvement. Le "straight edge" émerge depuis la scène punk hardcore de la fin des années 1970 et du début des années 1980 et se caractérise principalement par des hurlements plutôt que par des chants. Les individus associés au "straight edge" de cette première ère sont également associés aux idéaux punk comme l'individualisme, le refus de travailler et à des attitudes souvent dangereuses.

Le "straight edge" est le sujet de plusieurs chansons des années 1980, notamment du groupe Minor Threat et très explicitement dans sa chanson ', dans la chanson ' du groupe punk britannique The Vibrators ou dans la chanson "" du groupe des années 1970 Modern Lovers (dans laquelle il rejette l'usage des drogues). En tant que personnalité de la scène hard rock rejetant l'alcool et la drogue, Ted Nugent a particulièrement influencé l'idéologie du "straight edge". Ian MacKaye, le chanteur de Minor Threat, refuse l'étiquette de fondateur du "straight edge" qui lui est accolée et affirme que Minor Threat n'est pas un groupe "straight edge". Il avance au contraire que le mouvement est né d'un malentendu qui a pris de l'ampleur, tenant au sens des paroles de sa chanson : 

Le "straight edge" apparaît d'abord sur la côte est américaine et à Washington D.C., puis se propage rapidement dans le reste des États-Unis et jusqu'au Canada. Dans les années 1980, des groupes originaires de la côte est, comme America's Hardcore, Stalag 13, Justice League ou Uniform Choice rencontrent une certaine popularité. À l'aube du mouvement, les concerts se composent souvent de groupes punk et straight edge. Cette situation change néanmoins assez vite et le début des années 1980 est considéré comme la période . Les premiers groupes "straight edge" impliquent Minor Threat, , Government Issue, Teen Idles, The Faith, 7 Seconds, SSD, DYS, Negative FX, Cause for Alarm ou The Abused.

Un contre-courant du "straight edge", le "bent edge" ou "curved edge", est lancé par des membres de la scène hardcore de Washington D.C. frustrés par la rigidité et l'intolérance de leur scène. Ce mouvement prend de l'ampleur mais s'avère être par ses propres excès (jets d'alcool et de matériel destiné à l'usage de drogues durant les concerts) une simple antithèse du "straight edge" et ne sera finalement que de courte durée, s'effaçant rapidement à la fin des années 1990.

À l'aube de la youth crew, sous-genre musical du punk hardcore lancé au milieu des années 1980, son influence s'accroît rapidement et significativement sur la scène "straight edge". Les premiers groupes du genre impliquent Minor Threat, Bad Brains, Negative Approach, Cro-Mags ou Agnostic Front. Bien qu'une partie de la musique youth crew soit similaire au hardcore mélodique, l'autre partie s'inspire du thrash metal et la plupart des groupes youth crew s'inspirent désormais du heavy metal. Les groupes notables de cette approche incluent Youth of Today, Gorilla Biscuits, Judge, Bold, , ou Slapshot.

Au milieu des années 1980, le groupe Youth of Today devient largement associé au "straight edge" et sa chanson ' exprime un désir de rassembler la scène et l'organiser en mouvement. C'est durant cette ère que le végétarisme devient un thème important et récurrent du "straight edge", à commencer par la chanson ' de Youth of Today, sortie en 1988, dont les paroles se réclament anti-consommation de viande. La défense des droits des animaux et le véganisme atteignent leur pic de popularité dans le mouvement "straight edge" pendant les années 1990. .

Au début des années 1990, un mouvement "straight edge" militant se fait entendre dans la scène punk et DIY. Néanmoins, les punks militants "straight edge" ne sont pas connus pour leur tolérance. Ils se réclament fiers de leur militantisme et n'hésitent pas à faire usage de la force et de la violence pour faire entendre leur voix. Ces militants "straight edge" se veulent également plus conservateurs et moins tolérants envers l'homosexualité ou l'avortement. Au milieu des années 1990, un certain nombre de groupes qui défendent la justice sociale, le droit des animaux, le véganisme et les pratiques courantes du "straight edge" se convertissent au metal. À cette période, de nouvelles subdivisions apparaissent dans le "straight edge" : hardline et conscience de Krishna.

Au début et au milieu des années 1990, le "straight edge" s'étend de façon parallèle aux États-Unis dans les pays nord-européens, en Europe de l'Est, au Moyen-Orient ou en Amérique du Sud et se popularise dans le monde grâce notamment aux tournées permanentes de groupes de la youth crew. C'est également la décennie où le mode de vie "straight edge" dépasse son obédience d'origine pour essaimer dans des scènes voisines ou connexes (skinheads oi ! et hardcore principalement) mais toutefois avec une ampleur moindre et dans des versions généralement plus souples, souvent limitées à la non-consommation d'alcool et de drogues et à la promotion du respect de soi.

Le 17 octobre 1999 est célébré pour la première fois le National Edge Day, jour férié non officiel fondé par des gens qui s'associent au mouvement straight edge.

Au début des années 2000, seule une poignée de groupes "straight edge" militants parvient pourtant à survivre. Contrairement à certains médias qui considèrent les groupes "straight edge" comme un gang, de nombreuses études démontrent que les membres associés au mouvement sont pacifiques et non violents. Par ailleurs, une tolérance pour ceux qui ne participent pas au mouvement s'installe durablement dans la scène "straight edge" au cours des années 2000. Dans cette incarnation du "straight edge", les styles musicaux adoptés par les groupes peuvent varier, oscillant entre youth crew, metalcore et . Cette scène "straight edge" des années 2000 implique des groupes comme Champion, , , Have Heart ou Throwdown.

Le straight edge a notamment été représenté par l'ancien catcheur et actuel combattant de l'UFC Phillip Jack Brooks, plus connu sous de CM Punk qui a notamment évolué à la WWE de 2006 à 2014 et grâce à son passage à Stamford a permis au mouvement Straight Edge de se faire davantage connaître à travers le monde.






</doc>
<doc id="2904" url="https://fr.wikipedia.org/wiki?curid=2904" title="Surréalisme">
Surréalisme

Le surréalisme est un mouvement artistique du , comprenant l’ensemble des procédés de création et d’expression utilisant toutes les forces psychiques (automatisme, rêve, inconscient) libérées du contrôle de la raison et en lutte contre les valeurs reçues. Il est caractérisé par sa transdisciplinarité (peinture, objet, collage, cinéma, costume...) et l'importante collaboration entre ses membres. En 1924, André Breton le définit dans le premier "Manifeste du surréalisme" comme un « automatisme psychique pur, par lequel on se propose d'exprimer, soit verbalement, soit par écrit, soit de toute autre manière, le fonctionnement réel de la pensée. Dictée de la pensée, en l'absence de tout contrôle exercé par la raison, en dehors de toute préoccupation esthétique ou morale […] ». 

Le surréalisme repose sur la croyance à la réalité supérieure de certaines formes d'associations négligées jusqu'à lui, à la toute-puissance du rêve, au jeu désintéressé de la pensée. Il tend à ruiner définitivement tous les autres mécanismes psychiques et à se substituer à eux dans la résolution des principaux problèmes de la vie (). En réactualisant la dimension poétique de la peinture, le surréalisme se heurte à la question de la représentation du non-figurable et de l'indicible. 

Dans le courant du , le « super naturalisme » de Gérard de Nerval, et aussi le symbolisme de Charles Baudelaire et de Stéphane Mallarmé et, enfin surtout, le romantisme allemand de Jean Paul (dont les rêves annoncent l'écriture automatique) et d'Hoffmann peuvent être considérés comme des mouvements précurseurs du surréalisme. Plus proches, les œuvres littéraires d'Alfred Jarry, d'Arthur Rimbaud et de Lautréamont, et picturales de Gustave Moreau et Odilon Redon sont les sources séminales dans lesquelles puiseront les premiers surréalistes (Louis Aragon, André Breton, Paul Éluard, Philippe Soupault, Pierre Reverdy). Quant aux premières œuvres plastiques, elles poursuivent les inventions du cubisme.

À partir de 1917, et du ballet "Parade", Cocteau et Apollinaire réfléchissent sur ce qu'ils ressentent être un "esprit nouveau". Apollinaire reprend les "Mamelles de Tirésias", qu'il avait rédigé en 1903, pour y ajouter des éléments qui lui semblent découler tout naturellement des sensibilités de l'époque : tout un peuple représenté par une seule personne, un kiosque à journaux parlant, ou diverses provocations. Ce courant, se nourrissant de la période dada, trouve une nouvelle concrétisation avec la pièce "Les Mariés de la tour Eiffel", en 1921. Pour cette pièce, Cocteau, à une musique bruitiste, préfère un amalgame de music-hall et d'absurde, poussant autant que possible la pataphysique de Jarry. À partir de là, débordant le mouvement dada, mais nourris par lui, les artistes recherchent des idées nouvelles.

Après avoir été séduits par le dadaïsme, les surréalistes s'inscrivent en rupture par rapport à ce mouvement : ils considéraient que le surréalisme susciterait l'arrivée de nouvelles valeurs, ce que n'acceptaient pas les dadaïstes. Le dada, absolu dans sa dénonciation, ne survit pas à une querelle relative à l'engagement, suscitée par la Révolution soviétique et le risque d'une nouvelle guerre et, en 1924, naît le surréalisme avec la publication du premier "Manifeste du surréalisme" d'André Breton, soucieux d'agir sur la société, sinon sur l'individu, sans tomber dans l'embrigadement. Dalí affirme d'ailleurs être sûr que le surréalisme « changerait le monde ». Étant lui-même adepte de ce mouvement, il s'y investit comme un devoir.

Cette aventure (« une attitude inexorable de sédition et de défi ») passe par l'appropriation de la pensée du poète Arthur Rimbaud (« changer la vie »), de celle du philosophe Karl Marx (« transformer le monde ») et des recherches de Sigmund Freud : Breton s'est passionné pour les idées de Freud qu'il a découvertes dans les ouvrages des Français Emmanuel Régis et Angelo Hesnard, en 1917. Il en a retiré la conviction du lien profond unissant le monde réel et le monde sensible des rêves, et d'une forme de continuité entre l'état de veille et l'état de sommeil (voir en particulier l'écriture automatique). Dans l'esprit de Breton, l'analogie entre le rêveur et le poète, présente chez Baudelaire, est dépassée. Il considère le surréalisme comme une recherche de l'union du réel et l'imaginaire : 

Freud lui-même ressentit la plus grande méfiance envers les représentants du mouvement jusqu’à sa rencontre avec Salvador Dali le 19 juillet 1938. Dans une lettre à Stefan Zweig datée du lendemain, Freud avoue : « J’étais jusque-là enclin à considérer les surréalistes, qui semblent m’avoir choisi pour saint patron, comme des fous absolus (disons à 95% […]. » Mais il avait changé d’avis devant l’incroyable technique du peintre et l’intérêt analytique de l’œuvre qui lui avait été présentée .

En France, en 1966, la mort du poète André Breton, chef de file du groupe, va entraîner de grands soubresauts dans le surréalisme. Trois ans plus tard, Jean Schuster signa officiellement, dans le quotidien "Le Monde", l’acte de décès du mouvement dans un article intitulé « Le Quatrième Chant », mais la majorité des membres du groupe refuse cette décision brutale. Pour la plupart des surréalistes stupéfaits par la décision de Jean Schuster, celle-ci est fondée sur une manipulation politique dont l’origine se trouve dans l’engagement pro-cubain de Jean Schuster. Jean-Louis Bédouin écrit un virulent article de protestation publié dans "Le Monde" du 25 octobre 1969, Vincent Bounoure lance au sein du groupe l’enquête "Rien ou quoi?" dont les réponses mettent en évidence l’écartèlement du groupe sur la question de la dissolution, puis va constituer au début de 1970 le Groupe de Paris du mouvement surréaliste, dont l’activité se poursuit jusqu’aujourd’hui. Outre Jean-Louis Bédouin et Vincent Bounoure, Robert Benayoun, Gilles Bounoure, Micheline Bounoure, Jorge Camacho, Pierre Cheymol, Nicole Espagnol, Alain Joubert, Gherasim Luca, Alberte Maere, Marianne van Hirtum, Jacques Abeille, Ludwig Zeller, Carlos M. Luis, Guy Hollart, vont refuser cette décision brutale et vont poursuivre l’aventure surréaliste. Dans le "Bulletin de liaison surréaliste" (10 numéros parus entre 1970 et 1976), dirigé par Jean-Louis Bédouin, puis dans les deux numéros de "Surréalisme" (1977-78), on retrouve, entre autres, aux côtés de Vincent Bounoure, les noms de Michel Zimbacca, Joyce Mansour, Jorge Camacho, Michaël Löwy, Roger Renaud, Yves Elléouët. Après la mort de Vincent Bounoure en 1996, le Groupe de Paris du mouvement surréaliste, réuni autour de Michel Zimbacca, se dote jusqu’en 2005 de la revue "S.U.RR". animée par Marie-Dominique Massoni et Guy Girard, que rejoignent progressivement, notamment, Joël Gayraud, Pierre-André Sauvageot, Claude-Lucien Cauët, Virginia Tentindo, Jean-Raphaël Prieto, Ana Orozco, Elise Aru, Sylvain Tanquerel. L’activité du groupe parisien se poursuit aujourd’hui. 

À côté de ce courant qui continue d’affirmer la présence surréaliste au-delà même de la dissolution officielle du mouvement, les anciens membres ayant accepté cette dissolution, autour de Gérard Legrand, José Pierre et Jean Schuster, publieront au début des années 1970 la revue "Coupure". Mais certains des auteurs de "Coupure" s’opposeront à leur tour à Jean Schuster et José Pierre pour rejoindre un peu plus tard les éditions Maintenant, créées par Radovan Ivsic et le jeune poète libertaire Pierre Peuchmaurd. Y participeront, entre autres, Jean Benoit, Georges Goldfayn, Gérard Legrand, Toyen et Annie Le Brun. Plus tard encore, un autre des derniers compagnons d’André Breton, Sarane Alexandrian, tout en considérant acquise la mort du surréalisme historique, constatant que rien n’est venu le remplacer, crée et anime la revue "Supérieur inconnu" (1996-2011), tentant lui aussi de fédérer les forces surréalistes en France (avec entre autres Alain Jouffroy, Jean-Dominique Rey, Marc Kober, Christophe Dauphin, Odile Cohen-Abbas, Lou Dubois, Basarab Nicolescu, Virgile Novarina et Virginia Tentindo, laquelle a rejoint en 2015 le Groupe de Paris du mouvement surréaliste). 

Parallèlement, dès les années 1970, paraissent des revues émanant de collectifs se situant ouvertement dans la lignée du surréalisme ("Le Melog", "La Crécelle noire", "Camouflage") que fondent ou viennent rejoindre de plus jeunes recrues (Jimmy Gladiator, Jehan van Langenhoven, Pierre Peuchmaurd, Anne Marbrun, Alice Massénat, Guy Girard, Peter Wood). Le poète surréaliste irakien Abdul-Kader El Janabi anime "Le Désir libertaire" (deux séries, la première en arabe, la seconde en français) puis "Homnésies" et les éditions "Arabie-sur-Seine" qui publient des textes de Pierre Peuchmaurd, Jean-Pierre Le Goff, Karl Kraus, Teodor W. Adorno. Dans les années 1980 et 1990 paraissent les revues "Intersigne" dirigée par François Leperlier, "Le Château-Lyre" où l'on retrouve les noms de Peuchmaurd, Leperlier, Guy Girard, et "Le Cerceau", animée notamment par Alain Joubert et Nicole Espagnol. On peut joindre à cette liste nécessairement incomplète la série des "Cahiers de l'Umbo" suivie de la collection de l'Umbo animée jusqu'à ce jour par le plasticien Jean-Pierre Paraggio. 

Il faut noter que dans les principaux autres pays marqués par le surréalisme (Royaume-Uni, États-Unis, Tchécoslovaquie notamment), les groupes surréalistes existants n’ont guère été touchés par la décision de Jean Schuster de 1969 et que des groupes surréalistes y ont continué leurs activités de façon ininterrompue, y compris, pour le cas de la Tchécoslovaquie (avec entre autres Vratislav Effenberger, Pavel Reznicek, Jan Svankmajer, Eva Svankmajerova) le groupe réapparu après le Printemps de Prague dans les conditions hostiles d'un pouvoir totalitaire censurant la vie intellectuelle. 

Le poète et écrivain français André Breton (1896-1966) fut le principal fondateur du surréalisme, le seul artiste, avec Benjamin Péret, à avoir appartenu au mouvement depuis son origine et jusqu'à sa mort. En 1924, c'est lui qui pour la première fois décrit le surréalisme dans le premier "Manifeste", puis, la même année, il contribue à la création du . Louis Aragon, Robert Desnos, Paul Éluard, René Magritte, Giorgio De Chirico, Philippe Soupault, Marcel Duchamp, Salvador Dalí et Jacques Prévert sont quelques-uns des plus connus de ses camarades écrivains, poètes, peintres, artistes en somme. Nombre d'entre eux vont également adhérer au Parti communiste français pour soutenir leurs idées de révolution sociale : Breton rejoint le parti en 1927, mais n'assiste qu'à quelques réunions de cellule. Il en est exclu en 1933.

Le poète Arthur Rimbaud (1854-1891) voulait être un visionnaire, se mettre en état de percevoir la face cachée des choses, une autre réalité. C'est en poursuivant les tentatives de Rimbaud que Guillaume Apollinaire (1880-1918) part à la recherche de cette réalité invisible et mystérieuse. Le substantif « surréalisme » apparaît pour la première fois en mars 1917 dans une lettre de Guillaume Apollinaire à Paul Dermée : C'est le poète Pierre Albert-Birot qui suggéra à Apollinaire de sous-titrer la pièce que celui-ci était en train d'achever, "Les Mamelles de Tirésias", « drame surréaliste » plutôt que « surnaturaliste ».

Le concept est divulgué par la plaquette de présentation qu'Apollinaire est chargé, par Serge Diaghilev, de rédiger pour la première de "Parade, ballet réaliste en un tableau", le 18 mai 1917 au théâtre du Châtelet, à Paris. Du spectacle total conçu par Jean Cocteau conjuguant , où , il explique : 

Ainsi, Apollinaire entend théoriser le sursaut poétique provoqué par la Première Guerre mondiale par lequel Jean Cocteau, comme quatre ans plus tard dans le spectacle des "Mariés de la Tour Eiffel", dédouble la représentation « réaliste » du quotidien bourgeois du spectateur par celle de la fantaisie inhumaine et rêvée de personnages-machines. Dans ce manifeste se trouve déjà tout ce que ses détracteurs trouveront à reprocher au surréalisme : rupture avec tout traditionalisme, élitisme, modernité, c'est-à-dire progrès scientifique et, à l'instar des futuristes, industrialisme.

Dans une chronique de mai 1917, consacrée au même ballet, Apollinaire, admiratif des décors créés par Picasso, revient sur le concept d'. Dans une lettre du 16 juin 1917, adressée à Théodore Fraenkel, Jacques Vaché annonce la première des "Mamelles de Tirésias" pour le 24 : 

Pour Gérard Durozoi, le mot surréalisme est . Cependant, Alain et Odette Virmaux pensent que cette et qu'elle .

Le surréalisme connaît une fortune particulière dans la littérature francophone belge. Paul Nougé, dont la poésie présente un aspect ludique très marqué, fonde en 1924 un centre surréaliste à Bruxelles avec entre autres les poètes Camille Goemans et Marcel Lecomte. Un autre groupe important, Rupture, se crée en 1932, à La Louvière, autour de la personnalité d'Achille Chavée.

Le surréalisme belge prend ses distances à l'égard de l'écriture automatique et de l'engagement politique du groupe parisien. L'écrivain et collagiste E. L. T. Mesens fut l'ami de René Magritte. Les poètes Paul Colinet, Louis Scutenaire et André Souris et, plus tard, Marcel Mariën appartiennent également à ce courant. La francophonie d'outre-mer trouvera notamment en Jean Venturini, poète franco-marocain révolté et rimbaldien, un porte-parole original et indépendant, mort trop tôt pour donner sa pleine mesure, et auquel le poète Max-Pol Fouchet rendra un hommage fort.

Le surréalisme exercera une action stimulante sur le développement de la poésie espagnole, mais à la fin des années 1920 seulement, et en dépit de la méfiance suscitée par l'irrationalisme inhérent à la notion d'écriture automatique. Ramón Gómez de la Serna définit ses rapprochements insolites, "greguerias", comme « humour + métaphore ». Le courant « ultraïste » déterminera un changement de ton chez les poètes de la « Génération de 27 », Federico García Lorca, Rafael Alberti, Vicente Aleixandre et Luis Cernuda. Les principes surréalistes se retrouvent en Scandinavie et en URSS. Le « poétisme » tchèque peut être considéré comme une première phase du surréalisme. Il s'affirme dès 1924 avec un manifeste publié par Karel Teige, qui conçoit la poésie comme une création intégrale, donnant libre cours à l'imagination et au sens ludique. Ses représentants les plus éminents furent Jaroslav Seifert et surtout Vítězslav Nezval, dont Soupault souligna l'audace des images et symboles. Le mouvement surréaliste yougoslave entretient d'étroits contacts avec le courant français grâce à Marko Ristić.

En dépit d'une perte de prestige à partir de 1940, le surréalisme a existé comme groupe jusqu'aux années 1960, en se renouvelant au fur et à mesure des départs et des exclusions. Le surréalisme fut également revendiqué comme source d'inspiration par l'Alternative orange, un groupe artistique d'opposition polonais, dont le fondateur, le Major (Commandant) Waldemar Fydrych, avait proclamé "Le Manifeste du surréalisme socialiste". Ce groupe, qui organisait des happenings, peignait des graffiti absurdes en forme de lutins sur les murs des villes et était un des éléments les plus pittoresques de l’opposition polonaise au communisme, utilisait largement l’esthétique surréaliste dans sa terminologie et dans la place donnée à l’acte spontané.

Parmi les grands noms du surréalisme japonais, nous trouvons entre autres Junzaburō Nishiwaki (1894-1982), Shūzō Takiguchi (1903-1979), Katsue Kitazono (1902-1978). Parmi les peintres peuvent être cités Harue Koga (1895-1933), Ichirô Fukuzawa (1898-1992), Noboru Kitawaki (1901-1951), ou encore le photographe et poète Kansuke Yamamoto (1914-1987). Quant aux romanciers, les œuvres les plus marquantes nous ont été laissées par Kōbō Abe (1924-1993). Concernant les mangas, une brèche fut ouverte à la possibilité d'emploi de tournures surréalistes avec l'œuvre Nejishiki (ねじ式) de Yoshiharu Tsuge (publiée dans le numéro de juin du magazine "Garo", en 1968), puis le secteur put obtenir un appui écrasant de la génération du Zenkyōtō (équivalent de Mai 68), sous l'influence considérable d'artistes et de nombreux intellectuels non initiés à ce type d'œuvre. Le surréalisme japonais ne s'inscrit pas dans la continuité du dadaïsme. Au Japon, la quasi-totalité des écrivains appartenant au mouvement dadaïste (groupe d'écrivains faisant partie du MAVO) ne sont pas devenus surréalistes, et inversement, la plupart des surréalistes japonais n'œuvrent pas en tant que dadaïstes.

Il appartenait à l'écrivain majeur de la Bolivie au , Jaime Sáenz, de porter le flambeau du surréalisme en Amérique latine, plus d'ailleurs en héritier libre et indépendant qu'en sectateur fanatique.

Les surréalistes cherchent à libérer l'inconscient. Pour ce faire, ils utilisent les diverses techniques ci-dessous.

L'écriture automatique est un mode d'écriture cherchant à échapper aux contraintes de la logique, elle laisse s'exprimer la voix intérieure inconsciente, dévie l'inconscient de la pensée. Il s'agit d'écrire ce qui vient à l'esprit, sans se préoccuper du sens.

Par l'écriture automatique, les surréalistes ont voulu donner une voix aux désirs profonds, refoulés par la société. L'objet surréaliste ainsi obtenu a d'abord pour effet de déconcerter l'esprit, donc de « le mettre en son tort ». Peut se produire alors la résurgence des forces profondes : l'esprit « revit avec exaltation la meilleure part de son enfance ». On saisit de tout son être la liaison qui unit les objets les plus opposés, l'image surréaliste authentiquement est un "symbole". Approfondissant la pensée de Baudelaire, André Breton compare, dans "Arcane 17", la démarche du surréalisme et celle de l'ésotérisme : elle offre .

Les récits et les analyses de rêves consistent à décrire ses rêves et à trouver le « fil conducteur » qui les relie à la réalité. Des jeux d'écriture collectifs faisant intervenir le hasard sont également pratiqués ; le cadavre exquis en est un. Dans ce jeu, tous les participants écrivent tour à tour une partie de phrase sur une feuille sans connaître ce que les personnes précédentes ont marqué. L'ordre syntaxique nom-adjectif-verbe-COD-adjectif doit être respecté : on obtient ainsi une phrase grammaticalement correcte. Le nom de « cadavre exquis » vient de la première phrase obtenue de cette manière : « Le cadavre — exquis — boira — le vin — nouveau ». Enfin, pendant les séances de sommeil hypnotique, les participants notent leurs délires et hallucinations parfois provoqués par prise de drogues ou d'alcool.

À l'opposé des techniques automatiques, se trouve la méthode paranoïaque-critique, . Patrice Schmitt, à propos d'une rencontre entre Dalí et Lacan, nota que . Elle est à la fois méthodique et critique. Elle a un sens précis et une dimension phénoménologique et s'oppose à l'automatique, dont l'exemple le plus connu est le cadavre exquis. Faisant le parallèle avec les théories de Lacan, il conclut que le phénomène paranoïaque est de type pseudo-hallucinatoire. Les techniques d'images doubles sur lesquelles Dalí travaillait depuis Cadaqués ("L'Homme invisible", 1929) étaient particulièrement propres à révéler le fait paranoïaque.

Le mouvement dada était antibourgeois, antinationaliste et provocateur. Les surréalistes continuèrent sur cette lancée subversive. (tract "La Révolution d'abord et toujours"). Ces principes débouchent sur l'engagement politique : certains écrivains surréalistes adhèrent, temporairement, au Parti communiste français. Aucun parti cependant ne répondait exactement aux aspirations des surréalistes, ce qui fut à l'origine de tensions avec le Parti communiste français. André Breton dénonce en 1924 "". Dès 1930, pourtant, Louis Aragon soumet son activité littéraire « "à la discipline et au contrôle du parti communiste" ». La guerre fit que Tristan Tzara et Paul Éluard le suivirent dans cette voie. Condamnation de l'exploitation de l'homme par l'homme, du militarisme, de l'oppression coloniale, des prêtres pour leur œuvre qu'ils jugent obscurantiste et bientôt du nazisme ; volonté d'une révolution sociale et plus tard d'une dénonciation du totalitarisme de l'Union soviétique, tels sont les thèmes d'une lutte que, de la guerre du Maroc à la guerre d'Algérie, les surréalistes ont menée inlassablement. Ils ont tenté la synthèse du matérialisme historique et de l'occultisme, en se situant au carrefour de l'anarchisme, et du marxisme, fermement opposés à tous les fascismes et aux religions.


Une collection de coffrets DVD + Livre retraçant la vie et l'œuvre de chaque artiste et illustré de documents inédits, consacrée aux artistes du mouvement surréaliste. 

La Collection Phares, créée en 2003 par Aube Elléouët-Breton (fille d’André Breton et de Jacqueline Lamba), sa fille Oona Elléouët et en coproduction avec Seven Doc, leur collaboration résulte d’une volonté de réaliser un travail de mémoire afin de transmettre l’histoire du surréalisme.

Yves Tanguy, André Breton, Yves Elléouët, Jacqueline Lamba, Marcel Duchamp, Robert Desnos, Alan Glass, Wifredo Lam, Leonora Carrington, Max Ernst, André Masson, Alice Rahon, Jacques Hérold, Remedios Varo, Dorothea Tanning, Victor Brauner, Toyen, Benjamin Péret, Claude Cahun, Dora Maar et Jean-Claude Silbermann. Plusieurs titres sont en cours de production ...

Langues des films : français, sous-titres anglais, espagnol




</doc>
<doc id="2906" url="https://fr.wikipedia.org/wiki?curid=2906" title="Super Mario Sunshine">
Super Mario Sunshine

Cet épisode retrace les aventures du héros Mario sur l'île Delfino. Accompagné de la Princesse Peach, Papy Champi (qui fait ici sa première apparition) et de quelques Toads, pour ce qui devait être de simples vacances, il est de nouveau confronté à Bowser et Bowser Jr. (qui fait lui aussi sa première apparition). Pour les empêcher d'accomplir leurs plans, Mario se fait aider par J.E.T., un appareil créé par le professeur K. Tastroff.

Comme "Super Mario 64" six ans auparavant, "Super Mario Sunshine" constitue l'épisode GameCube de la série principale "Super Mario" commencée en 1985. En septembre 2009, les ventes sont estimées à 6,3 millions d'unités.

"Super Mario Sunshine" prend place dans un monde imaginaire exotique. L'histoire se déroule sur l'île Delfino, une île tropicale en forme de dauphin. Cette île ne fait pas partie du Royaume Champignon. Sa géographie est assez homogène : elle se compose de collines, d'un volcan, de falaises et de quelques petites plaines où se trouvent les plages et la majeure partie de la population. Cette population est essentiellement composée de deux espèces : les Piantas et les Noki.

Delfino est divisée en dix lieux : un aéroport, un volcan (le Mont Corona), une ville (Place Delfino), trois villages (Collines Bianco, Baie Noki et Village Pianta), un port (Port Ricco), un parc d'attractions (Parc Pinna), un hôtel situé sur la Plage Sirena et une plage (Gelato-les-Flots).

L'île est réputée pour son climat très favorable. Ce climat est dû à une multitude de soleils qui se concentrent autour de la Porte du Soleil située à Place Delfino. Leurs énergies se rassemblent et donnent ce temps ensoleillé. Delfino est donc l'endroit idéal pour se détendre et s'abandonner au farniente.

Le joueur contrôle Mario (doublage anglais : Charles Martinet). Lorsque le jeu débute, l'avion de Mario subit un atterrissage mouvementé. Sur la piste d'atterrissage, il découvre une substance mouvante qui a l'aspect d'une peinture. Plus loin, il fait la connaissance de J.E.T., un Jerrycan Expérimental Transformable qui est en fait une sorte de pompe à eau. Ce J.E.T. peut être considéré comme un outil par ses fonctions ou alors comme un personnage du fait qu'il parle et le joueur a la possibilité de le contrôler par le biais de Mario. Ainsi grâce à cette rencontre, Mario et J.E.T. vont pouvoir nettoyer l'aéroport.

Pour ses vacances, Mario est accompagné de Princesse Peach, l'héritière du trône du Royaume Champignon, Papy Champi, le fidèle sujet de la princesse et de cinq Toads (Toad Violet, Toad Vert, Toad Rouge, Toad Bleu et Toad Jaune), eux aussi sujets de la princesse.

Alors que Mario s'apprête à profiter de vacances paisibles sur l'île Delfino avec Peach, Papy Champi et les Toads, ils découvrent une île polluée et salie par des graffitis. À cause de cette pollution, les soleils ("Shines sprites") ont disparu, ce qui plonge l'île dans l'ombre. Mario est arrêté car un criminel a, sous son apparence, saccagé l'île en peignant des graffiti un peu partout. Mario est jugé et reconnu coupable. Il est alors condamné à nettoyer les dégâts et à rétablir la tranquillité sur l'île. Pour la nettoyer, Mario est aidé par J.E.T., un canon à eau en forme de sac à dos.

Entre temps, la princesse Peach est kidnappée par le mystérieux individu qui s'appelle Antimario et Mario doit la sauver. Il suit Antimario jusque sur l'île Pinna où est construit un parc d'attractions. Là, Mario doit faire face à un gigantesque robot en forme de Bowser. Après le combat, Antimario révèle sa véritable identité : il s'agit en fait de Bowser Jr., le fils de Bowser. Ce dernier a annoncé à son fils que Peach était en réalité sa mère même si cette question reste ambiguë. Bowser Jr. s'enfuit en ballon vers le Mont Corona. Mario aura de nouveau affaire à Bowser Jr. toujours déguisé en Antimario dans les autres endroits de l'île. L'affrontement final a lieu dans le volcan, Mario grimpe la cheminée puis y trouve Bowser dans une baignoire ainsi que son fils et Peach. Mario sauve Peach en détruisant les extrémités de la baignoire et tous tombent. On retrouve Mario et Peach sur un petit îlot, en face de Place Delfino, qui assistent au retour des soleils sur l'île. Durant la chute, J.E.T. sera endommagé mais ensuite réparé. Enfin, les vacances peuvent commencer pour Mario tandis que Bowser de son côté, explique à son fils que Peach n'est pas réellement sa mère.

Le "gameplay" de "Super Mario Sunshine" ressemble beaucoup à celui de l'opus précédent, "Super Mario 64", mais Mario peut utiliser de nouvelles fonctions comme l'attaque en vrille, qui lui permet de sauter et d'attaquer tout en tournant sur lui-même. Toutefois, les deux jeux n'ont aucun lien scénaristique. À la différence de "Super Mario 64", dans "Super Mario Sunshine", Mario dispose d'un Jerrican Expérimental Transformable (J.E.T.) sur son dos. Comme dans "Super Mario 64", le joueur peut découvrir l'environnement dans toutes les directions sans limite de temps. Toutefois, l'environnement de "Super Mario Sunshine" est plus réaliste que dans son prédécesseur comme le montre certains éléments du décor (habitations, parc d'attractions, fruits, insectes...) et le fait que Mario peut avoir une insolation. Les niveaux regorgent d'ennemis qui attaquent Mario mais aussi de personnages qui aident Mario ou demandent un service.

"Super Mario Sunshine" est un jeu qui se joue en solo. L'écran d'accueil propose de choisir entre trois profils (A, B et C) qui permettent de jouer à trois parties différentes.

Dans ce jeu, Mario dispose de plusieurs mouvements distincts. La plupart des mouvements tire parti du stick analogique (par exemple, Mario marche ou court selon l'inclinaison du stick), du bouton A (ce bouton permet à Mario de sauter, nager...) et du bouton B (Mario peut parler, porter, lancer ou encore glisser). Il est possible d'exécuter des sauts spéciaux : le triple saut (consiste à sauter trois fois de suite), la roue ou les rebonds sur un mur qui lui permettent d'atteindre des endroits élevés. Il est possible de nager et de plonger avec le bouton B mais le joueur doit faire attention à surveiller sa réserve d'air. Mario peut aussi se servir de J.E.T. avec le bouton R.

Mario ne possède aucune transformation mais J.E.T., la pompe à eau, en a quatre. Ces quatre fonctions sont appelées buses. La buse d'arrosage, qui est active en permanence chez J.E.T., permet de projeter de l'eau devant soi, à la manière d'un tuyau d'arrosage, et est utilisée principalement pour nettoyer les différents graffitis de l'île, et faire disparaître la boue souillant les niveaux. Elle peut aussi servir à tuer certains ennemis. Mais le J.E.T a d'autres buses interchangeables. En effet, on peut utiliser, en plus de la buse d'arrosage, trois buses différentes : la première, l'Aérobuse, est disponible dès le début du jeu et permet à Mario de planer un court instant dans les airs ; la deuxième, la Catabuse, sert de réacteur vertical et permet de faire des sauts gigantesques et de détruire certains blocs ; la troisième enfin, la Turbobuse, est une autre sorte de réacteur, mais horizontal cette fois, donnant à Mario la possibilité de courir ou de nager très rapidement.

Sur l'île, Mario peut aussi chevaucher Yoshi en lui donnant le fruit qui est demandé. Yoshi peut ainsi cracher du jus. La couleur du dinosaure et de son jus diffère selon le fruit mangé. Ce jus peut servir à dissoudre des obstacles comme les substances orange et transformer les ennemis en plates-formes qui peuvent être utilisées comme ascenseurs suivant le fruit mangé. Yoshi disparaît quand il plonge dans une eau profonde ou lorsque son réservoir de nectar est vide.

Le principe du jeu est d'alterner les différentes buses selon la situation et d'utiliser Yoshi pour atteindre de nouvelles zones dans les niveaux et récolter ainsi les 120 soleils.

Ces soleils sont équivalents aux étoiles de puissance de "Super Mario 64" et le but du jeu est de tous les obtenir. Pour cela, le joueur peut se rendre librement et dans n'importe quel ordre dans les huit lieux de l'île, depuis Place Delfino. Chaque lieu est divisé en 8 épisodes, présentant chacun ses propres objectifs (généralement évoqués dans le titre de l'épisode) et donnant donc accès à un soleil distinct. Ces défis peuvent inclure un combat contre un boss, récupérer les huit pièces rouges, battre Antimario ou encore réussir une épreuve sans l'aide de J.E.T. De plus, le joueur devra collecter 100 pièces dans chaque lieu (y compris Place Delfino) et trouver les deux soleils cachés. D'autres soleils se trouvent en dehors des lieux (sur la Place Delfino, dans le Mont Corona, ou sur l'Aéroport) et sont accessibles selon des manières que doit découvrir le joueur. Il faut également retrouver les 240 pièces bleues qui ont été disséminées sur toute l'île. Ces pièces intéressent une certaine personne qui les achète en l'échange d'un soleil. Il faut 10 pièces bleues pour obtenir un soleil.

Une suite de "Super Mario 64" était déjà en projet depuis plusieurs années. "Super Mario 64 2" et "Super Mario 128", dont les sorties ont été annulées, présentaient déjà quelques idées pour une suite de "Super Mario 64". Certains éléments de "Super Mario 128" ont été utilisées pour la conception de "Super Mario Galaxy". "Super Mario Sunshine" a été présenté, pour la première fois, au Spaceworld 2001 puis a été présenté une nouvelle fois à l'E3 2002.

Au cours d'une interview avec le producteur Takashi Tezuka et les réalisateurs Yoshiaki Koizumi et Kenta Usui au sujet du développement de "Super Mario Sunshine", ceux-ci disent qu'ils ont rapidement eu beaucoup d'idées comme de pouvoir nettoyer les graffitis ou de planer dans les airs. Certaines avaient déjà été évoquées dans "". Takashi Tezuka dit : « le concept a repris des éléments de "Super Mario 64" en ajoutant leurs idées ». Les développeurs ont d'abord commencé par l'ajout d'une pompe à eau dans le "gameplay". Il y avait dix sortes de buses à eau différentes, mais J.E.T. a été retenu en raison de sa convenance dans le décor du jeu bien qu'il ne soit pas le favori. Certains types de buses ont dû être retirés car ils ont créé la polémique aux États-Unis. Par ailleurs, certaines caractéristiques de Yoshi ont également été enlevées. Les développeurs ont aussi créé un univers quatre fois plus grand que dans "Super Mario 64" et l'ont rendu plus réel.

La musique a été composée par Koji Kondo et Shinobu Tanaka. Certaines pistes proviennent d'anciens jeux de Mario mais celles-ci ont été modifiées comme le thème "Underground". Pour les voix dans "Super Mario Sunshine", ce sont les acteurs habituels qui prêtent leur voix aux personnages. Ainsi Charles Martinet a donné sa voix à Mario et Papy Champi, Jen Taylor pour Peach et Toad, Scott Burns pour Bowser et Dolores Roger pour Bowser Jr.

"Super Mario Sunshine" est développé par le studio Nintendo EAD pour Nintendo. L'équipe complète comporte une centaine de membres environ. Les réalisateurs sont Yoshiaki Koizumi et Kenta Usui tandis que la production est dirigée par Shigeru Miyamoto et Takashi Tezuka. Futoshi Shirai dirige le "map design" et Koichi Hayashida l'équipe des programmeurs.

"Super Mario Sunshine" a été un succès commercial à l'échelle du marché mais un échec au sein de la série, où il est à l'époque de sa sortie et jusqu'à celle de "New Super Mario Bros. U" (2012) l'un des jeux les moins vendus, deux fois moins que son prédécesseur "Super Mario 64" et que son successeur sur console "Super Mario Galaxy". Il a été vendu à près de 5,5 millions d'unités en juin 2006 puis 6,3 au . Le jeu était en 2002, le dixième meilleur jeu vendu aux États-Unis selon le NPD Group.

"Super Mario Sunshine" a reçu les éloges de la presse spécialisée. "IGN" a apprécié l'ajout d'un canon à eau pour améliorer le "gameplay" ; Mario n'a plus à attendre qu'une plate-forme arrive vers lui, il peut utiliser J.E.T. et "GameSpy" a ajouté une critique positive sur la conception du décor et des niveaux aux hauteurs. Le jeu a reçu une très bonne note de la part de "Nintendo Power" qui commente la qualité des graphismes, de la musique, de la mise en scène, des cinématiques et des énigmes. "GamePro" a également donné une note parfaite au jeu toujours pour la qualité des niveaux. L"'Official Nintendo Magazine" place le jeu à la parmi les 100 meilleurs jeux Nintendo de tous les temps.

Néanmoins, la presse a trouvé des inconvénients. GameSpot a critiqué le système de caméra et que le jeu peut parfois être ennuyeux car il oblige à refaire les niveaux plusieurs fois pour finir le jeu. Il a également critiqué certains ajouts comme Yoshi qui « n'est pas très utile ». Il a critiqué les voix des personnages : la voix de Mario est limitée à des interjections, et les voix de Peach et des ennemis sont décevantes. Les voix des habitants sont elles aussi limitées à des interjections et des onomatopées alors qu'il aurait été plus agréable de les entendre parler.

Super Mario Sunshine présente de nouveaux personnages dans la série. Tout d'abord les habitants de l'île, Piantas et Nokis font ici leur première apparition. Les Piantas sont des montagnards forts, sociables et curieux. Les arbres sur leurs têtes les protègent du climat de l'île. Les Nokis sont recouverts par des coquilles qui sont les vestiges du temps où ils vivaient dans la barrière de corail. Ils s'occupent du Parc Pinna.

Bowser Jr. apparaît aussi dans ce volet, déguisé en Antimario. Il est devenu un personnage récurrent de la série principale en tant qu'adversaire ("New Super Mario Bros" où il est l'antagoniste principal, "New Super Mario Bros Wii", "Super Mario Galaxy", "Super Mario Galaxy 2" et "New Super Mario Bros. U") et dans les "spin-off" sportifs en tant que personnage jouable (dans la série des "Mario Kart" depuis "", "", "Mario Power Tennis", "Mario Strikers Charged Football", "Mario Super Sluggers" ou encore "Mario & Sonic aux Jeux Olympiques d'Hiver)".

Ce fut la première apparition de Papy Champi, qui revient souvent dans les jeux sportifs en tant qu'arbitre (ou plus rarement jouable comme dans "Super Mario Sluggers") et surtout dans la série des "Mario & Luigi".

Flora Piranha, le boss des Collines Bianco, est devenue un personnage récurrent de l'univers de Mario. Il est devenu un personnage jouable dans "" avec pour partenaire le Roi Boo, et tant que boss dans "New Super Mario Bros.", "", "Super Smash Bros. Brawl" ou encore "".

J.E.T. réapparait en tant que mouvement d'attaque de Mario et en trophée dans "Super Smash Bros. Brawl" et sa suite, "Super Smash Bros. for Nintendo 3DS / for Wii U".

Une réédition de "Super Mario Sunshine" intitulée "Super Mario Sunshine (Player's Choice)" est sortie en 2003. Le Player's Choice sélectionne les jeux les plus populaires et les vendent à des prix réduits.

Sur la console de la génération suivante, la Wii, Nintendo publie en 2007 une suite, "Super Mario Galaxy", puis une autre, "Super Mario Galaxy 2", sortie le 11 juin 2010. Le "gameplay" reste le même sauf que les développeurs ont cette fois-ci préféré des plates-formes de type sphériques qui ressemblent à des planètes. Ces éléments ont été introduits dans un décor ressemblant à l'espace puis la gravité a été ajoutée. Shigeru Miyamoto confirma lors de l'E3 2007, la sortie du jeu le en Amérique du Nord et quatre jours plus tard en Europe, c'est-à-dire le . "Super Mario Galaxy" ne reprend aucune nouveauté de "Super Mario Sunshine". Cependant dans "Super Mario Galaxy 2", il est possible de chevaucher Yoshi (comme dans "Super Mario World") et ce dernier peut manger des fruits (comme dans "Super Mario Sunshine") qui lui donnent des capacités particulières.



</doc>
<doc id="2907" url="https://fr.wikipedia.org/wiki?curid=2907" title="Studio One">
Studio One

Studio One est un label discographique créé à Kingston en 1962 par le producteur jamaïcain Clement Seymour Dodd, dit Coxsone.

Tout commence en 1954, lorsque C.S. Doddd décide de monter son propre sound system. Il y passe des disques de jazz, rhythm and blues ou boogie qu'il importe lui-même des États-Unis, il grave quelques années plus tard ses propres productions, enregistrées avec des musiciens locaux, sur des dubplates, disques tirés à un seul exemplaire, destinés uniquement à être passés lors des soirées de son sound system. En effet, aux États-Unis, les productions R&B noires appréciées par le public jamaïcain deviennent de plus en plus rares, éclipsées par le rock'n roll blanc.

C'est seulement en 1959 qu'il produit ses premiers 45 tours destinés à la commercialisation. Il s'agit, entre autres, d'artistes comme Theophilus Beckford, Delroy Wilson. C'est la naissance de l'industrie musicale jamaïcaine.
En 1962 apparaît un nouveau style : le ska. C'est cette même année que Dodd fonde son studio d'enregistrement, à Kingston, sur Brentford Road : Studio One. Son groupe de musiciens compte des légendes telles que le tromboniste Don Drummond, les saxophonistes Tommy McCook, Roland Alphonso, le trompettiste Johnny "Dizzy" Moore, ou encore le jeune organiste Jackie Mittoo. En 1964, ce groupe prend le nom de The Skatalites.

Au cours des années 1960, Studio One enregistre de nombreux artistes jamaïcains de premier plan : The Wailers, Ken Boothe, The Skatalites, Marcia Griffiths, The Heptones, ou encore Delroy Wilson.

Dans les années 1970, Studio One continue de découvrir et produire des musiciens d'immense talent : Johnny Osbourne, The Gladiators, Dennis Brown, Sugar Minott, The Wailing Souls, etc.
Il lance en outre le concept de « discomix », versions longues des morceaux spécialement destinées aux pistes de danse. Il est à l'origine d'un grand nombre de riddims considérés aujourd'hui comme des classiques : le "Real Rock", le "Rock Fort Rock", le "Declaration of Rights" ou encore le "Still In Love".

Dans les années 50, les différentes formations travaillant et enregistrant pour Coxsone Dodd sont dans un premier temps : "The Joe Williams Band", "The All Stars" et "The Blues Blasters" qui sont habituellement dirigés par Cluett Johnson (basse). Le groupe, avec des musiciens comme Theophilus Beckford (piano et chant) et Roland Alphonso (saxophone), jouent essentiellement du rhythm and blues. 

Dans la période de 1959 à 1963 ce seront des formations avec des hommes plus connus comme "Roland And His Alley Cats" ou "His Upsetters", "Don Drummond And His Greenlanders", "Studio One Band" et "Monty And The Cyclones", vers 63, 64, "Tommy McCook And His Group". 

Vers la fin 64 "The Skatalites" (écrit Ska-Talites) et vers la fin de 1965 avec l'internement et la mort de Don Drummond émergent les "Soul Brothers". 

Début 1967, suit un autre changement avec le rocksteady et les "Soul Vendors", les "Soul Defenders", "The New Establishment" ou les "Sound Dimension". Dans le début des années 70 les formations s'appellent "The Brentford Road Disco Set" et les "Underground Vegetables".



</doc>
<doc id="2909" url="https://fr.wikipedia.org/wiki?curid=2909" title="Stanislas Lem">
Stanislas Lem

Stanisław Lem, francisé en Stanislas Lem, né le à Lviv (aujourd'hui en Ukraine, Lwów en polonais) et mort le à Cracovie, en Pologne, est un écrivain de science-fiction polonais. Son œuvre, traduite en , caractérisée par l'étendue de sa palette, est construite autour d'une vision critique du comportement humain. Stanislas Lem est également l'un des écrivains polonais les plus traduits aux côtés de Gombrowicz et Sienkiewicz. "Solaris" est sans doute son roman le plus célèbre et a été porté au cinéma par Andreï Tarkovski en 1972 puis par Steven Soderbergh en 2002. Certains de ses romans mêlent récit d'anticipation et intrigue policière, notamment dans "Le Rhume" ("Katar", 1976).

Fils d'un médecin oto-rhino-laryngologue, Stanislas Lem voit ses études de médecine à l'université de Lviv interrompues par la Seconde Guerre mondiale. Il travaille alors comme mécanicien et soudeur, et prend part à la résistance contre les Allemands. À l'issue de la guerre, l'Armée rouge occupe la Pologne et l'Union soviétique contrôle le pays.

En 1946, Lem reprend les études de médecine à l'Université Jagellonne de Cracovie. Pour éviter une carrière de médecin militaire, il ne passe pas ses derniers examens et obtient seulement un certificat de fin d'études. Assistant de recherche d'une institution scientifique, il écrit ses premières histoires pendant son temps libre. En 1981, il reçoit un doctorat "honoris causa" de l'École polytechnique de Wrocław. Plus tard, l'Université d'Opole, l'université de Lviv et enfin l'Université jagellonne de Cracovie (1998) font de même.

Stanislas Lem écrit sur l'incommunicabilité entre les humains et les civilisations extraterrestres, et sur le futur technologique de l'humanité. Il développe des idées sur une société idéale et utopique et explore les problèmes liés à l'existence de l'homme dans des mondes où le progrès technologique supprime tout effort humain. Ses sociétés extraterrestres mettent en scène des essaims de mouches mécaniques ("L'Invincible") ou l'océan pensant ("Solaris") avec lesquels les Terriens ne peuvent pas communiquer. Des utopies technologiques apparaissent dans "Pokoj na Ziemi" (Paix sur la Terre) ou dans "La Cybériade".

Lem est un partisan de la civilisation occidentale. Malgré la censure inhérente au régime staliniste dans lequel il vécut, son œuvre contient une sévère critique du collectivisme.

Lem est intronisé membre honoraire de la Science Fiction and Fantasy Writers of America (SFWA) en 1973. La SFWA annule cette décision en 1976 après les critiques de Lem contre la science-fiction américaine bas de gamme, mais lui propose toutefois une adhésion ordinaire, ce qu'il refuse. Il décrit cette littérature comme kitsch, pauvrement écrite et plus intéressée par la rentabilité que par les idées ou les nouvelles formes littéraires. Par ailleurs, de tous les auteurs américains de science-fiction, il n'adresse des éloges francs qu'à Philip K. Dick.

À l'issue d'une longue maladie, Stanislas Lem décède à l'hôpital de Cracovie d'une crise cardiaque le lundi .

Günther Anders rend hommage à Stanislas Lem à l'égal de Jules Verne pour ses visions sur la révolution technique moderne.

Lem écrivit principalement deux types d’œuvres, les textes de fiction (les plus connus et les plus traduits), et les textes qu'il regroupa lui-même sous le terme d'apocryphes (Apokryfy) en 1998, et qui correspondent pour la plupart à de fausses critiques de livres qui n'ont jamais existé. Ces derniers textes ont parfois paru dans divers ouvrages, et sous des titres différents. Le plus connu, et le seul traduit en français, est "Bibliothèque du " ("Biblioteka XXI wieku").

Cette section contient une sélection d'ouvrages traduits en français. Les dates de première édition polonaise diffèrent selon les sources, ceci vient bien souvent d'imprécisions au niveau du numéro de l'édition utilisée pour la traduction.










</doc>
<doc id="2910" url="https://fr.wikipedia.org/wiki?curid=2910" title="Sun Microsystems">
Sun Microsystems

Le , est racheté par .

Avant son rachat, le chiffre d’affaires de l’entreprise était de 13.8 milliards de dollars pour l'année fiscale 2007-2008 et l’effectif d’environ (2006). était présent dans plus de (2005).

Le nom vient de (réseau de l’université Stanford).

L’idée originelle des stations de travail UNIX a été pensée lorsque ses fondateurs étaient étudiants à l’université Stanford (Palo Alto, en Californie).

Le prototype de ce qui allait devenir la première station de travail UNIX de Sun, le Sun-1, a été assemblé par Andy Bechtolsheim lorsqu'il était étudiant en maîtrise à l’Université Stanford, à Palo Alto, en Californie. Bechtolsheim avait conçu la station de travail comme un poste de CAO individuel, dans le cadre du projet de réseau de l'université (le "Stanford University Network"). C'était un ordinateur conçu autour d'une carte-mère Motorola 68000 avec une Unité de gestion mémoire (MMU) suffisamment sophistiquée pour faire tourner le système d'exploitation Unix avec une mémoire virtuelle. Il construisit les premiers exemplaires avec des composants fournis par le département d'informatique de Stanford et des grossistes de la Silicon Valley.

Le 24 février 1982, Vinod Khosla, Andy Bechtolsheim et Scott McNealy, tous étudiants à Stanford, décidèrent de créer "Sun Microsystems". Bill Joy de Berkeley, un des développeurs du shell BSD, les rejoignit peu après et est reconnu comme l'un des créateurs de la marque. « Sun » est l'acronyme de Stanford University Network. Sun s'est avérée rentable dès le premier trimestre d'activité, en juillet 1982.

Les premiers titres de Sun ont été mis sur le Marché en 1986 sous la mnémonique "SUNW", pour "Sun Workstations" (et par la suite, "Sun Worldwide"). En 2007, les titres ont changé de nom et sont devenus "JAVA"; Sun estimant que sa plate-forme Java reflétait mieux la stratégie du moment de la compagnie

Le logo de Sun, qui représente quatre "sun" entrelacées, a été conçu par le professeur Vaughan Pratt, de Stanford. Dans sa version initiale, il était de couleur orange et en forme de carré horizontal/vertical; il a ensuite été tourné de 45° pour le faire reposer sur un sommet, et est devenu d'abord violet (photo ci-contre), puis bleu.

Avec la demande en serveurs des "startups", Sun a d'abord tiré d'énormes profits de la bulle Internet : ses actions battaient record sur record en bourse, et simultanément, l'entreprise multipliait les investissements et augmentait ses effectifs. C'était une conséquence logique de la demande, mais une demande tirée par des petites sociétés qui spéculaient sur des gains de court terme. Lorsqu'en 2000, la bulle éclata, les ventes du département Matériels de Sun, le plus gros de la société, s'effondrèrent, car les clients mettaient la clef sous la porte et inondaient le marché d'ordinateurs d'occasion.

Au bout de plusieurs trimestres de chute ininterrompue des ventes, il fallut comprimer les coûts de production, les cadres quittèrent la compagnie et il y eut des charrettes de licenciements. Au mois de décembre 2001, l'action était retombée à son cours de 1998, environ 100 $, et elle continuait à perdre de la valeur, et même plus rapidement que celles des autres sociétés industrielles. Un an après, elle était même tombée sous le cours des 10 $ (soit un dixième de sa valeur de 1990) mais finit par rebondir à 20 $. À l'été 2004, Sun ferma son usine de Newark (Californie) et concentra sa production à Hillsboro (Orégon) ; en 2006, cette usine a fini par fermer elle aussi ses portes.

En 2004, Sun a renoncé à deux projets de développement de processeur parallélisme à gros grain et à fréquence d'horloge élevée, pour privilégier les processeurs optimisés pour le multi-threading et multiprocessing, comme le processeur UltraSPARC T1 (dit "Niagara"). Sun a par ailleurs passé des accords avec Fujitsu pour équiper ses serveurs moyen et haut de gamme (Serie M de SPARC Enterprise, 2007) de composants japonais.

En février 2005, Sun a annoncé le déploiement du "Sun Grid", plate-forme de stockage et de calcul destinée aux entreprises moyennant un tarif de et de de stockage. C'était en fait une façon de rentabiliser les calculateurs du département R&D de la société, quelque CPU en service depuis 10 ans, et jusque-là inutilisés pendant 97 % du temps. Au mois d'août 2005, Sun annonça que cette grille était louée pour effectuer des calculs de simulations financière.

En janvier 2005, Sun annonça un bénéfice net de , le premier bilan positif depuis trois ans. Ce bon résultat fut suivi d'un déficit net de au troisième trimestre 2005. Au mois de janvier 2007, Sun annonçait de nouveau un bénéfice net de pour un chiffre d’affaires de au second trismestre. Peu après cette annonce, on apprit que Kohlberg Kravis Roberts (KKR) se préparait à investir dans la société.

Sun employait alors des équipes techniques à Bangalore, Pékin, Dublin, Grenoble, Hambourg, Prague, Saint-Pétersbourg, Tel Aviv, Tokyo, et Trondheim.

En 2007–2008, Sun annonçait un chiffre d’affaires de et une trésorerie de cash ; mais au premier trimestre 2008 elles affichait des pertes de , faisant chuter son chiffre d’affaires de 7 % à . De novembre 2007 à novembre 2008, l'action Sun avait perdu 80 % de sa valeur, faisant tomber la valeur de la société à . La perte de plusieurs gros clients contraignit Sun à licencier 5 à salariés, soit 15–18 % de sa main-d’œuvre. Elle espérait ainsi retrouver une marge de 700 à par an, moyennant de charges en plus.


 a aidé à de nombreuses reprises le monde du logiciel libre, par exemple :
De plus, a rendu libre le "design" de certains de ses processeurs : les OpenSPARC.

 a conçu, fabriqué et commercialisé différents matériels, classés en différentes gammes :



</doc>
<doc id="2911" url="https://fr.wikipedia.org/wiki?curid=2911" title="Syncrétisme">
Syncrétisme

Un syncrétisme est un "mélange" d'influences. Le terme de syncrétisme vient du mot ("") signifiant « union des Crétois ». Initialement appliqué à une coalition guerrière, il s'est étendu à toutes formes de rassemblement de doctrines disparates, et est surtout utilisé à propos de religion.

Le terme s'utilise surtout en histoire des religions, pour qualifier des confessions à part entière, mais dont plusieurs composants d'origine sont encore reconnaissables. C'est une religion dont la doctrine ou les pratiques sont un mélange d'éléments pris dans différentes croyances.

On retrouve cette pratique très tôt dans l'antiquité. La Bible fait mention du syncrétisme religieux du peuple d'Israël à l'époque du Roi de Juda, Hoshéa (). Le donne un exemple frappant de ce mélange religieux entre la Loi Mosaïque que Yahvé donna à Israël et .

Les Romains avaient pour politique d'incorporer les dieux locaux des pays qu'ils conquéraient au panthéon romain. Ce choix leur évitait ainsi au moins toute opposition d'ordre religieux dans les pays polythéistes.

Une situation semblable s’est développée, mais involontairement, lorsque des missionnaires ont introduit la religion catholique en Amérique du Sud. Ils ont converti la majeure partie de la population, mais, à l’image des Samaritains de l’Antiquité, la population n'a pas oublié pour autant ses anciens rites. Ainsi, au Brésil, des chrétiens pratiquent toujours les rites vaudou et célèbrent des fêtes en l’honneur d’anciennes divinités, telle la déesse Iemanjá. On observe le même phénomène dans d’autres pays d’Amérique du Sud.

Ernest Renan considère la croyance éventuelle à une vie post-mortem comme un effet de la captivité des Hébreux en Égypte. Celle-ci possédait ce concept dont la religion juive était seule, selon lui, à faire l'économie à l'époque.

À l'époque moderne, la rencontre d'Assise de 1986 fut taxée de syncrétisme par quelques cardinaux du Vatican, bien que cela ne fût pas l'intention des organisateurs.

Le concept de syncrétisme est suffisamment abstrait pour être appliqué à de nombreuses traditions. Le sikhisme est composé d'un mélange de l'hindouisme et de l'islam. L'approche syncrétique permet d'analyser les influences qui constituent une religion, elle doit s'arrêter avant de perdre ce qui en fait l'identité. Les religions de l'Antiquité étaient très caractérisées par le syncrétisme, qu'il soit d'assimilation ou d'association, rendant les influences entre religions très complexes. Le culte de Mithra associé à Apollon dans le panthéon romain en est un exemple.

La cohabitation du bouddhisme et du shintoïsme au Japon depuis le est un excellent exemple de syncrétisme, toujours observable aujourd'hui, et appelé "shinbutsu shūgō". Ainsi en 2005, selon les chiffres officiels on comptabilisait de shintoïstes (84 % de la population) et de bouddhistes (71 % de la population). Dans les faits, la plupart des Japonais fêtent les mariages et les naissances suivant les rites shintoïstes et les funérailles suivant les rites bouddhistes. De plus, on peut trouver dans la plupart des temples bouddhistes japonais un petit sanctuaire shinto et un petit autel bouddhiste dans de nombreux sanctuaires shinto.

Un autre exemple de syncrétisme est la situation indonésienne, dans laquelle les gens, tout en se déclarant adeptes des « grandes » religions (bouddhisme, christianisme, hindouisme, islam), continuent d'adhérer à des croyances et à observer des rituels relevant des religions traditionnelles.

Le caodaïsme vietnamien constitue aussi un exemple typique de syncrétisme, de même que la coexistence du vaudou et du christianisme dans certains pays africains ou en Haïti. Le culte antoiniste propose aussi une forme de syncrétisme religieux selon le sociologue Régis Dericquebourg, tandis que la jurisprudence belge l'a défini comme un « mouvement syncrétiste, qui admet en son sein toutes les religions ».

En linguistique, le terme signifie la fusion en un seul élément de plusieurs traits grammaticaux. 

On distingue parfois syncrétisme d'éclectisme, car des éléments fusionnés ne sont pas triés, ainsi que d'une synthèse, car les éléments mélangés sont encore distinguables.

On parle de syncrétisme culturel lorsqu'un système religieux (comme dit précédemment) ou philosophique tend à faire fusionner plusieurs doctrines différentes. 

Lors d'une coexistence culturelle au niveau global, le syncrétisme est un métissage culturel, c’est-à-dire, une véritable création de nouveaux ensembles culturels qui trouvent une nouvelle cohérence à partir de plusieurs cultures différentes.




</doc>
<doc id="2912" url="https://fr.wikipedia.org/wiki?curid=2912" title="Sacré">
Sacré

Le sacré est une notion d'anthropologie culturelle permettant à une société humaine de créer une séparation ou une opposition axiologique entre les différents éléments qui composent, définissent ou représentent son monde : objets, actes, espaces, parties du corps, valeurs, etc. Le sacré fait signe vers ce qui est mis en dehors des choses ordinaires, banales, communes ; il s'oppose essentiellement au profane, mais aussi à l'utilitaire.

Il est d'usage de considérer que l'acte de sacraliser est spécifique des tribus primitives, des peuples isolés et des civilisations anciennes. Certains penseurs, tels C. G. Jung, Roger Caillois ou Jacques Ellul, estiment toutefois que la sacralisation reste un phénomène constant dans les sociétés modernes mais qu'il opère de façon totalement inconsciente.

Le sacré a toujours une origine naissant d'une tradition ethnique et qui peut être mythologique, religieuse ou idéologique (c'est-à-dire non religieuse). Il désigne ce qui est inaccessible, indisponible, mis hors du monde normal, et peut être objet de dévotion et de peur.

Le sacré est synonyme d'espoir, d'authentification de l'homme en un principe supérieur, celui du monde non intelligible. Ainsi, le sacré peut s'exprimer sous diverses formes, on peut prendre l'exemple de Robinson Crusoé dans Vendredi ou les Limbes du Pacifique de Michel Tournier, qui découvrant la grotte, le nombril de l'île Esperanza, enlace le Cosmos en redécouvrant son corps et vit une expérience exceptionnelle. Robinson, comprimé par les règles sociales, découvre en cette île la bonne position. « Il était suspendu dans une éternité heureuse », cette redécouverte verticalisante du monde, hors de la civilisation, c'est le sacré.

Selon Camille Tarot, le concept du sacré est conçu par les anthropologues contemporains comme la réponse à un ensemble d'expériences propres non seulement aux sociétés archaïques et traditionnelles mais aussi à toutes les autres cultures qui leur ont succédé. Il semble devoir être admis comme une donnée constitutive de la condition humaine, c'est-à-dire comme : « une catégorie universelle de toute conscience humaine », face à sa finitude et à sa condition de mortel. 

Sur le plan phénoménologique, nous pouvons entrevoir ce qui, dans les cultures humaines, est visé dans les expériences du sacré : avant tout, le numineux. Le numineux est un concept avancé par Rudolf Otto et ensuite largement utilisé. Dans son ouvrage "Das Heilige - Über das Irrationale in der Idee des Göttlichen und sein Verhältnis zum Rationalen" ("Du sacré - Sur l'irrationnel des idées du divin et de leur relation au rationnel") publié en 1917, Otto traduit le concept de "sacré" en référence au latin, où le terme "numen" se rapporte à la divinité, soit en un sens personnalisé, soit en référence à la sphère du divin en général. Pour Otto, le numineux regarde toute expérience non rationnelle du mystère, se passant des sens ou des sentiments, et dont l'objet premier et immédiat se trouve en dehors du soi.

Le numineux est aussi, selon Carl Gustav Jung : « ce qui saisit l'individu, ce qui, venant d'ailleurs, lui donne le sentiment d'être », traduisant, par conséquent, une expérience affective d'être. Le sacré entre ainsi selon Camille Tarot dans « la composition d'une essence, celle de son identité ». Cette définition évoque irrésistiblement « la profondeur ontologique dans laquelle s'enracine le "sentiment" du sacré et donc l'importance de celui-ci dans toutes les cultures ».

Sur le plan historique, « tantôt il [le sacré] semble s'identifier ou se confondre avec le divin : c'est le cas des religions archaïques, tantôt c'est le sacré qui s'estompe au profit du divin ou de la transcendance : c'est le cas des formes religieuses qui relativisent mythes et rites ou préconisent l'accès au divin ».

Pour Roger Caillois, il n'existe que deux attitudes face au sacré : le respect de l'interdit ou sa transgression. Si l'Homme fait l'expérience du sacré, c'est qu'il veut précisément échapper à sa condition d'être fini et mortel ; pour ce faire, il y a "a priori" trois solutions : le tabou (totémisme), la magie (animisme) et la religion (surtout les religions dites naturistes).

Enfin, toujours pour Camille Tarot, le sacré serait à l’origine du fait religieux, lequel serait à reconnaître « dans la conjonction du symbolique et du sacré ».

Dans la religion romaine et la religion grecque, sont sacrés les objets qui ont été officiellement, et par un acte rituel, retranchés du monde profane pour en donner la propriété à une divinité. Dans le catholicisme, l'expression "le sacré" désigne spécialement l'Eucharistie.

Cette notion est aujourd'hui utilisée de façon plus générale dans d'autres contextes : une nation peut définir comme sacrés ses principes fondateurs ; une société peut définir comme sacrées certaines de ses valeurs, etc. Les anthropologues contemporains disent d'ailleurs que la notion de sacré est trop floue pour pouvoir être utilisée dans l'étude des religions — même s'ils continuent à travailler dessus.

Les éléments du sacré sont généralement considérés comme intouchables : leur manipulation, même en pensée, doit obéir à certains rituels bien définis. Ne pas respecter ces règles, voire agir à leur encontre, est généralement considéré comme un péché ou crime réel ou symbolique : c'est ce qu'on nomme un sacrilège. Le pire des sacrilèges est la profanation, qui est définie comme l'introduction d'éléments profanes dans une enceinte sacrée (réelle ou symbolique). 

Pour Durkheim, les représentations religieuses sont en fait des représentations collectives : l'essence du religieux ne peut être que le sacré, tout autre phénomène ne caractérise pas toutes les religions. Le sacré, être collectif et impersonnel, représente ainsi la société elle-même.

La « voie du sacré » est à l'origine de ce que Mircea Eliade appelle "l'homo religiosus", « celui qui peut connaître lui-même l'irruption d'une vision transcendante et globalisante ». Mircea Eliade a montré que c'est autour de la conscience de la manifestation du sacré que s'organise le comportement de "l'homo religiosus." Ce dernier croit à une réalité absolue, le sacré, et de ce fait assume dans le monde un mode d'existence spécifique. Le sacré se manifeste sous une multitude de formes : rites, mythes, symboles, homme, animaux, plantes, etc. Il se manifeste qualitativement différent du profane et on appelle "hiérophanie" l'irruption du sacré à travers le monde profane. L'homme saisit l'irruption du sacré dans le monde et découvre ainsi l'existence « "d'une réalité absolue, le sacré qui transcende ce monde-ci mais qui s'y manifeste et de ce fait, le rend réel" »"." En se manifestant, le sacré créé une dimension nouvelle. Découvrir cette dimension sacrale du monde est le propre de l"'homo religiosus", pour qui le profane n'a de sens que dans la mesure où il est révélateur du sacré ».

Mircea Eliade souligne que la religion ne doit pas être interprétée seulement comme « une croyance en divinités », mais comme « l'expérience du sacré ». Il analyse la dialectique du sacré. Le sacré est présenté en relation avec le profane. La relation entre le sacré et le profane n'est pas d'opposition, mais de complémentarité, car le profane est vue comme une hiérophanie.

« On pourrait dire », écrit Mircea Eliade, « que l'histoire des religions, des plus primitives aux plus élaborées, est constituée par une accumulation de hiérophanies […]. L'occidental moderne éprouve un certain malaise devant certaines formes de manifestations du sacré : il lui est difficile d'accepter que, pour certains êtres humains, le sacré puisse se manifester dans des pierres ou dans des arbres. Or, […] il ne s'agit pas d'une vénération de la pierre ou de l'arbre en eux-mêmes. Les arbres sacrés ne sont pas adorés en tant que tels ; ils ne le sont justement que parce qu'ils sont des hiérophanies, parce qu'ils “montrent” quelque chose qui n'est ni pierre ni arbre, mais le sacré, le "ganz anderes" ». 

Et Eliade d'ajouter : 

"On n'insistera jamais assez sur le paradoxe que constitue toute hiérophanie, même la plus élémentaire. En manifestant le sacré, un objet quelconque devient autre chose, sans cesser d'être lui-même, car il continue de participer à son milieu cosmique environnant. Une pierre sacrée reste une pierre ; apparemment (plus exactement : d'un point de vue profane) rien ne la distingue de toutes les autres pierres. Pour ceux auxquels une pierre se révèle sacrée, sa réalité immédiate se transmue au contraire en réalité surnaturelle".

Mais hormis ces considérations sur l’aspect duel de l’objet sacré, Eliade, en dépit d’une œuvre considérable dédiée au sujet, ne dit, en revanche, jamais rien sur la nature probable de cet « autre chose », invisible, qui irradie, effectivement, de l’objet en question. Quant aux forces qui déterminent le profane « à devenir une hiérophanie, ou à cesser de l'être à un moment donné », Eliade reconnaît explicitement que « le problème dépasse la compétence de l'historien des religions ».
Selon Daniel Dubuisson, l’approche eliadienne, compte tenu de son incapacité foncière à définir « quels principes, quelles règles, quels mécanismes régissent la disposition et l'organisation » de ce phénomène, conduit l’historien des religions sur une voie sans issue.

« La seule chose qu'on puisse affirmer valablement » à propos du sacré, écrit Eliade, « c'est qu'il s'oppose au profane ». 

Selon Albert Assaraf, une telle explication reste fondamentalement à la périphérie du phénomène. « Autant, dit-il, expliquer le feu – comme le faisaient autrefois les aristotéliciens – en l’opposant à l’eau ; la terre, en l’opposant à l’air… ». 

Toujours selon cet auteur, la grande erreur d’Eliade – erreur d’où découleront les séries d’impasses précitées – est précisément là, dans sa tentative d’expliquer le sacré en l’opposant au profane, comme si sacré et profane étaient deux entités différentes que rien ne peut rapprocher alors que sacré et profane découlent d’un phénomène commun : à savoir la propension qu'ont les signes de lier et de délier les hommes.

Même Eliade, fait remarquer Albert Assaraf, n’est pas sans admettre implicitement l’origine relationnelle du sacré : 

« Paysage natal », « site des premiers amours », « une rue ou un coin de la première ville étrangère visitée dans la jeunesse », ne sont-ce pas là tout simplement des objets d’attachements initiaux que l’esprit humain place très haut sur une échelle imaginaire verticale ?

Afin de rendre la chose plus intelligible (et pourquoi pas exploitable par un ordinateur), Albert Assaraf propose dans son article, « Le sacré, une force quantifiable ? », paru en 2006 dans "Médium" , d’inscrire sur une échelle de forces graduée de 1 à 10 la charge émotive irradiant d’un signe ou d’un objet.

La règle de son échelle de forces est simple.

Ce qui du coup, écrit-il par ailleurs, en paraphrasant l’égyptologue Henrietta Mac Call – « les mythes concernent les êtres divins ou semi-divins, les légendes concernent les êtres historiques ou semi-historiques » – les mythes concernent les signes de forces 8 à 10 ; les légendes, les signes de forces 1 à 7.
Sur l’échelle de forces d’Albert Assaraf, un yaourt, par exemple, n’évoluera pas dans la même classe de signes qu’un chien. Et le signe "chien", de graviter autour d’une sphère de force en deçà du signe "enfant". D’où la différence patente d’affect se dégageant des trois énoncés ci-dessous dont seuls varient les mots en gras : 
« J’aime mon yaourt à la folie »« J’aime mon chien à la folie »« J’aime mon enfant à la folie »
À l’autre bout de son échelle verticale, un prix Nobel de médecine ne jouera pas dans la même orbite qu’un médecin lambda. Le général de Gaulle surfera sur une plage de force nettement supérieure à celle d’un simple général. Un drapeau c’est bien plus qu’un bout de tissu ; un hymne national, bien plus qu’un morceau de musique. Les mots "patrie", "roi", "père de la nation"… de caracoler naturellement sur des niveaux d’énergie pouvant atteindre les 7. 

Quant aux signes de forces supérieures à 7 (esprits, anges, dieux…), Albert Assaraf pense que seuls des neurones humains peuvent se les représenter. Que seuls des neurones humains peuvent être sensibles au fantastique amplificateur émotionnel que représentent l’idée de Dieu, le mot "Dieu". Au point, dit-il, que dans une cité à haute teneur en signes de forces 10, toucher à iota d’une parole divine déchaîne invariablement convulsions et persécutions. Comme s’il se dégageait du signe "Dieu" (force 10) – au même titre que, sur l’échelle logarithmique de Richter, d’un séisme d’amplitude 10 – une énergie d’une magnitude colossale.

Albert Assaraf montre dans un autre article, « Le "ligasigne" », paru dans la revue "Équivalences" (Haute école de Bruxelles, ISTI, /1-2, 2009), que plus, au sein d’un groupe, un signe gravite autour d’une orbite de forces 6 à 10, plus il augmente son pouvoir attractif. D'où le fait, précise-t-il, que les signes de forces supérieures à 7 incarnent la ligne de démarcation séparant les groupes religieux. Ou encore le fait que quiconque ose s’en prendre – dans un groupe à haute teneur en signes de forces 8 à 10 - à des signes de forces 8 à 10, déclenche invariablement sentiments d’horreur et réprobation.

Au reste, dit-il, plus un signe ou un objet caracole au sommet de l’échelle imaginaire d’un humain, plus il favorise des comportements paroxystiques. À l'exemple du comportement de l’impératrice byzantine Zoé (978-1050) au contact de son icône sacrée :

Enfin, fait remarquer Albert Assaraf : 

Albert Assaraf souligne encore que la force qui irradie d’un signe ou d'un objet varie sans cesse au gré de l’histoire. Il arrive même, dit-il, qu’un signe perde totalement de sa charge émotive en chemin. Exemple, le signe "Osiris". 

Il y a trois mille ans, écrit-il, en l'Égypte ancienne, prononcer : « "Osiris n'est pas ressuscité" », c'était commettre un terrible blasphème. Seule la mort pouvait expier un acte aussi impie. Si énoncer aujourd'hui une telle phrase dans les rues du Caire porte à sourire, c'est parce que le signe "Osiris" s’est vidé de son pouvoir "ligatif" d'antan. C’est parce qu’il est passé d’une force 9 à 10 à une force ridicule de 2 à 3 (fables et légendes).

Grâce à son concept d’échelle de forces, Albert Assaraf parvient même à coder, comme suit, à l’attention d’un ordinateur, la charge émotive (ou "ligative" : du latin "ligare", « lier ») irradiant du signe "Osiris" du temps des pharaons par opposition à celle qui a cours aujourd’hui.

Il n’est pas jusqu’au robots intelligents du futur qui ne soient, écrit Albert Assaraf, condamnés à hiérarchiser les objets du monde selon une échelle de forces graduée.

Pourquoi ?

Supposons, dit-il, que je fasse part à un robot intelligent de mes sentiments pour les yaourts en général et pour ma belle-mère en particulier en ces termes : 
« J’aime les yaourts à la folie »« J’aime beaucoup ma belle-mère »

En cas de danger, qui le robot intelligent ira-t-il sauver en premier, mes yaourts ou ma belle-mère ?

Sans une échelle de forces (de type logarithmique) inscrite dans le cerveau électronique du robot intelligent, mes yaourts !... 
Pour qu’un automate intelligent, dit Albert Assaraf, s’empresse invariablement de sauver en premier une belle-mère (qu’on aime [juste] beaucoup) avant un yaourt (qu’on aime à la folie), encore faut-il qu’il se dégage du signe "belle-mère" quelque chose de plus que n’a pas le signe "yaourt". Et ce quelque chose d’invisible à l’œil nu, c’est la quantité de valeur que notre imaginaire attribue de façon systématique aux signes qui se présentent à la conscience. 
C’est dire combien le sacré, et donc la hiérarchisation des objets du monde selon une échelle de forces graduée, a une fonction vitale. Même pour un cerveau électronique.

Il est une idée répandue que l'expérience du sacré est celle de la transcendance, l'ouverture à une entité ressentie comme "absolue". La notion renvoyant à celle d'infini, il est "a priori" impossible de la définir. René Guénon considère que l'on ne peut avoir recours qu'à une formule négative : « l'infini est ce qui n'a pas de limite » et Mircea Eliade lui-même recourt à une approche approximative : « Le monde n'est pas un chaos mais un cosmos (...) cette œuvre divine garde toujours une transparence, elle dévoile spontanément les multiples aspects du sacré ». 

S'attachant à distinguer l'« expérience » du sacré et la « force irradiant un objet », Albert Assaraf considère que la première est impossible à définir mais que l'on peut "mesurer" l'autre d'« "après une échelle graduée de 1 à 10, permettant d'évaluer "la distance infinie" séparant le sacré du profane" »"."

Le terme « sacré » est régulièrement utilisé dans les sociétés modernes dans un sens non religieux, pour qualifier des valeurs jugées essentielles : parfois de façon banale (exemple : « le respect de la propriété est une chose sacrée »), parfois de façon solennelle. Il apparaît ainsi dans le couplet de l'hymne de la Marseillaise : "Amour sacré de la Patrie, conduis, soutiens nos bras vengeurs ! Liberté, Liberté chérie, combats avec tes défenseurs").

Plusieurs penseurs émettent l'idée qu'en société « sécularisée », la notion de sacré non seulement ne s'oppose pas à celle de profane mais s'exprime à travers des formes institutionnelles habituellement considérées comme profanes. Étudiant ainsi les raisons expliquant la montée et la légitimation du nazisme, C. G. Jung considère que l'entité la plus sacralisée dans les sociétés modernes est l'État et que les dictatures ne sont que l'expression la plus extrême de cette sacralisation.

Roger Caillois est le premier à mener une étude comparative des sociétés archaïques et celles qualifiées de « développées ». Selon lui, quelles que soient les périodes, le sacré se révèle principalement à travers la fête et la guerre. En apparence opposés, ces deux phénomènes sont régis par les mêmes principes : la transgression des règles, l'abolition des interdits, la dépense d'une énergie ayant pour fonction de renforcer les structures sociales.

Jacques Ellul estime que l'État et la Technique sont sacralisés l'un autant que l'autre, de façon étroitement corrélée, et que toute sacralisation non conscientisée est source d'aliénation : Dans "Les nouveaux possédés" (1973), Ellul développe cette thèse en s'appuyant sur toute une série d'arguments. Tout d'abord, dit-il, l'homme moderne est persuadé que, grâce à ses inventions il est devenu « adulte », qu'il est sorti de l'âge de la magie, du religieux, que la société qu'il a forgée est sécularisée, etc. Or, souligne Ellul, cette conviction constitue elle-même une croyance. Premièrement, avance-t-il, il est nécessaire de déconnecter le sacré des notions de religiosité et de transcendance, auxquelles le sacré est traditionnellement associé : il convient en revanche de le rattacher à la notion de "respect", un respect élevé à son plus haut degré d'intensité. L'action de sacraliser une chose a en effet pour visée, chez les humains, de s'attirer les faveurs de cette chose, parce qu'ils ont le sentiment qu'elle les dépasse, face à laquelle ils se sentent petits et démunis et dont ils craignent certains effets. Ainsi, ce que les humains ont sacralisé en premier lieu pendant les siècles, c'est la nature. Deuxièmement, tout en sacralisant la nature, les humains ont conçu et fabriqué des outils sans cesse plus perfectionnés que les précédents, ils ont également revu leur façon de travailler et leur façon de vivre ensemble, L'outillage, la division du travail et l'État ont eu pour fonction commune d'optimiser l'action sur la nature, de réduire le nombre et la puissance de ses contraintes, et même d'accéder à un confort matériel inégalé. La « recherche de l'efficacité maximale en toutes choses », afin de limiter le poids des contraintes naturelles, s'est trouvée ainsi, au fil du temps, érigée en valeur quasi absolue. Troisièmement, et conséquence des deux premières étapes du processus, en même temps qu'ils désacralisaient la nature, les humains ont sacralisé à sa place, les processus leur ayant permis de la désacraliser, et qu'Ellul rassemble sous le nom de « technique ». Ils n'ont bien sûr pas sacralisé "les" techniques, "séparément" (les outils, les procédures, l'État...), mais "l'ensemble" qu'ils forment et qu'Ellul appelle « la technique » ou le système technicien. Depuis l'informatique et l'automation, la technique constitue aujourd'hui un "cadre de vie" à part entière, exactement au même titre qu'autrefois la nature.



</doc>
<doc id="2913" url="https://fr.wikipedia.org/wiki?curid=2913" title="Sexisme">
Sexisme

Le sexisme est une attitude discriminatoire basée sur le sexe ou idéologie se fondant sur l’adhésion à des croyances discriminatoires basées sur le critère du sexe. Il s'appuie en partie sur des stéréotypes de genre, c’est-à-dire des croyances concernant les caractéristiques généralement associées aux femmes et aux hommes.

Ce terme est apparu dans les années 1960 avec le nouvel essor du féminisme. Ce mot, calqué sur « racisme », a pour vocation de dénoncer les croyances, valeurs et attitudes fondées sur des modèles stéréotypés et intériorisés, en d'autres termes une société sexuellement discriminatoire. La thématique du sexisme peut être abordée selon différentes disciplines comme l'analyse des médias, la sociologie, les sciences politiques, la psychologie, la philosophie...

Le sexisme peut être défini comme « l’adhésion à des croyances discriminatoires ou préjudiciables basées sur le sexe ». Par ailleurs, ce concept est « "typiquement assimilé à des conceptions stéréotypées des sexes et l'adhésion à une idéologie quant aux rôles traditionnellement assignés en fonction du sexe"». Il peut également être considéré comme recouvrant « des attitudes, des croyances et des comportements qui soutiennent l’inégalité entre le statut des femmes et des hommes ».

Selon son éditeur français le terme anglais "sexism" apparaît pour la première fois en 1965 dans un discours de Pauline Leet Pittenger, traduit en français sous le titre "« Sexisme, le mot pour le dire ! »" dans une traduction par Sarah Gurcel Vermande et publié aux éditions iXe. Le mot apparait ensuite pour la 1ère fois dans un dictionnaire américain en 1972 (American Heritage School Dictionary).

La misogynie et la misandrie sont deux formes de sexismes.

La misandrie exprime le mépris, voire la haine, d’une personne pour le sexe masculin.

La misogynie exprime le mépris, voire la haine, d’une personne pour le sexe féminin.

Ces deux derniers sentiments amènent à rejeter l'égalité de statut entre femmes et hommes.

Il faut distinguer le sexisme d'autres concepts proches avec lequel il est souvent confondu tels que le racisme, le machisme.

Le racisme exprime l'idéologie fondée sur la croyance qu'il existe une hiérarchie entre les groupes humains, les « races ».

On parle de machisme lorsque l’on se réfère plus précisément à l’idéologie fondée sur l’idée que l’homme domine la femme et qu’à ce titre il a droit à des privilèges de maître. Le machisme est par conséquent un type de sexisme. Un « macho » refuse ainsi d'accomplir les tâches traditionnellement attribuées aux femmes, comme le travail domestique, car cela porterait atteinte à l'idée qu'il se fait de sa virilité.

« La psychologie évolutionniste repose sur le postulat que nos pensées et comportements, ainsi que nos caractéristiques physiques, sont le résultat de l'évolution soumise aux mécanismes de la sélection naturelle et de la sélection sexuelle. » En d’autres termes, pour les évolutionnistes, l’évolution aurait rendu les hommes et les femmes statistiquement différents, pas uniquement sur le plan physique, mais également sur le plan psychologique.

Selon l'approche évolutionniste, dans la plupart des cultures, les femmes ont toujours été considérées comme devant s’occuper des enfants, notamment en raison de facteurs biologiques (grossesse, allaitement). De plus, elles auraient tendance à chercher des hommes qui sont non seulement en bonne santé (« en forme ») mais également capables de fournir des ressources pour elles-mêmes ainsi que leur(s) enfant(s). Les hommes, quant à eux, ont toujours dû faire face à « l’incertitude de la paternité » (un homme n’est jamais sûr d’être le père de l’enfant, alors qu’il n’y a aucun doute concernant la maternité de la femme). De cela, aurait découlé une jalousie naturelle, et par la suite le développement de diverses pratiques culturelles telles que, par exemple, le mariage (afin de s’assurer que la femme « n’appartienne » qu’à un seul homme). C’est également à cause de cela que les hommes seraient plus agressifs, car une compétition s’est développée entre eux, ce qui n’a pas été le cas pour les femmes.

« L’essentialisme est la tendance à voir les membres d’une même catégorie (par exemple, tous les hommes et toutes les femmes) comme partageant des caractéristiques profondes et immuables qui déterminent qui ils sont. ». Pour les partisans de l’essentialisme, les différences entre hommes et femmes (que ce soit sur leur manière de penser, de ressentir ou encore d’agir) seraient donc biologiquement fixées et immuables, et ce sont leurs différences biologiques qui détermineraient leurs différences psychologiques. Dans le cas de l'essentialisme appliqué aux catégories des hommes et des femmes, on pourrait dire que « les hommes sont naturellement supérieurs aux femmes », non seulement en force physique, mais aussi en intelligence, en culture, dans les sciences, les arts, la politique, etc. La domination masculine s'expliquerait par une supériorité essentielle (ou naturelle) des hommes sur le « beau sexe », admiré mais relégué aux tâches subalternes et sans grand intérêt (bavardages et commérages).

Deux raisons permettent d'expliquer la popularité de l'approche essentialiste. Tout d'abord, le sexe est sous-tendu par une dichotomie explicite (généralement visible) : on est soit une femme, soit un homme, ce qui n’est pas le cas pour d'autres catégories sociales. Du point de vue de l'approche essentialiste, les femmes et les hommes sont donc biologiquement divisés. Il existe une opposition claire entre les deux sexes, que l'on distingue très facilement, contrairement à d'autres catégories pour lesquelles les frontières sont plus floues. Par exemple, la religion n'est pas une catégorie bien distincte, on peut changer de religion au cours du temps. Ensuite, des caractéristiques physiques évidentes (y compris les organes génitaux) différencient les hommes et les femmes. Par exemple, les hommes sont plus grands et pèsent plus lourd que les femmes.

L’essentialisme divise les hommes et les femmes en catégories mutuellement exclusives, et de ce fait renforce la perception des deux sexes comme biologiquement opposés. Dans l'approche essentialiste, c'est la nature qui l’emporte sur la culture.

Certaines théories évolutionnistes sur les différences de genre peuvent être considérées comme essentialistes dès lors qu'elles ancrent ces différences dans des traits immuables d'origine biologique. L'adhésion à une conception essentialiste dans la perception et la division des sexes pourrait être à l'origine du sexisme.

Pour les défenseurs du constructivisme, ce sont principalement les croyances culturelles qui seraient à l’origine des différences comportementales entre les deux sexes.

Ainsi, les constructivistes mettent en avant diverses théories. On peut par exemple citer la théorie de l'apprentissage social, selon laquelle les nouveaux comportements sont acquis via un processus d’observation : en observant la manière dont se comportent les autres personnes (et dans ce cas précis, les autres personnes du même sexe), on acquiert de nouveaux comportements similaires. Cette théorie explique que les enfants découvrent et apprennent ce que c’est qu’être un homme / une femme via l’observation des personnes du même sexe qu’eux.

Une autre théorie est celle de la « socialisation du genre ». Il s’agit d’un processus dans lequel les enfants découvrent les identités féminines et masculines. Cela s’explique principalement par le fait que dès leur venue au monde, les enfants sont traités différemment selon qu’ils soient de sexe masculin ou féminin. Les enfants jouent un rôle actif dans ce processus.

Les constructivistes mettent également l’accent sur la manière dont la société communique les croyances culturelles, partagées par tous, sur la manière dont les hommes et les femmes devraient se comporter. Ces croyances culturelles touchent des domaines multiples tels que les couleurs (ex : rose pour les filles, bleu pour les garçons) ou encore les métiers (ex : docteur pour les garçons, infirmière pour les filles). Ces croyances culturelles sont à l’origine de ce que l’on appelle des "schémas de genre" : ces schémas guident les perceptions que les gens ont d’eux-mêmes et des autres (leur comportement, leurs préférences, etc.) et forment leur vision du monde social, ils apparaissent dès l’enfance et persistent à l’âge adulte.

Par ailleurs, on peut relever trois catégories d'acteurs qui joueraient un rôle capital dans la transmission des croyances culturelles qui influencent les enfants, à savoir : les médias (ex : la télévision, Internet, etc.), les figures d’autorité (ex : les parents, les professeurs, etc.) et les pairs. Étant donné que ces acteurs renvoient à des croyances culturelles, ils joueraient indirectement un rôle dans l’apparition des stéréotypes de genre.

Le constructivisme, via un mécanisme d'apprentissage des rôles sociaux, des valeurs, des normes et des attentes culturelles d'une société, peut expliquer l'apparition de certaines formes de sexisme.

On peut définir le stéréotype en général comme « une croyance concernant les traits caractérisant les membres d’un groupe social ». En particulier, les stéréotypes de genre (ou stéréotypes de sexe) concernent les attributs généralement associés aux femmes et aux hommes.

Les stéréotypes de genre sont à la fois descriptifs et prescriptifs. D’une part, la composante descriptive des stéréotypes de genre concerne les attributs constitués à partir des croyances que les gens ont de ce à quoi devraient ressembler les membres d’un groupe (exemple pour les femmes : émotives, dépendantes, passives, faibles, non compétitives, non confiantes). Autrement dit, ils suscitent des attentes relatives aux comportements que les hommes et les femmes sont susceptibles de présenter (exemple : les femmes aiment acheter des chaussures). D’autre part, la composante prescriptive est composée des comportements qui sont appropriés pour le groupe cible (exemple : les femmes doivent avoir de bonne compétences relationnelles, elles doivent être passives et dociles et doivent coopérer avec les autres). Cette dimension des stéréotypes de genre impose aux hommes et aux femmes de correspondre strictement et uniquement à des rôles et attributs stéréotypés, sous peine d’être perçus comme étant déviant par rapport à leur genre (exemple : les hommes doivent avoir un travail, ils ne peuvent pas être des hommes au foyer).

Pour un groupe qui souscrit à cette vision stéréotypée des genres, il est plus grave de violer un stéréotype prescriptif plutôt que descriptif (exemple : un homme au foyer est plus sévèrement jugé par le groupe qu'une femme qui n'aime pas acheter des chaussures). Tous les stéréotypes incluent des composantes descriptives et prescriptives mais les stéréotypes de genre sont plus prescriptifs que les autres. Cela est dû au fait que les individus côtoient de plus en plus les deux genres. En effet, en observant et en interagissant avec les autres, ils développent une multitude d’idées complexes à propos de comment les membres de chaque genre doivent se comporter.

Les stéréotypes de genre peuvent être associés à des attributs incluant:

Par ailleurs, les stéréotypes portant sur des groupes sociaux peuvent être abordés selon deux grandes dimensions : la "chaleur" (le groupe est-il chaleureux, sociable, ouvert et sympathique ?) et la compétence (le groupe est-il intelligent, travailleur, efficace et autonome ?). Ces deux dimensions peuvent être croisées avec le statut social relatif entre deux groupes et la compétition entre ceux-ci, ce qui aboutit à la matrice suivante:

Le modèle de Fiske porte sur les stéréotypes en général mais peut également s'appliquer aux stéréotypes de genre. Selon ce modèle, par exemple, les femmes au foyer sont considérées (sous un angle stéréotypé) comme très chaleureuses mais peu compétentes. Ceux qui adhèrent à une vision stéréotypée les prendront donc en « pitité » ou éprouveront de la compassion pour elles. A contrario, toujours selon le modèle de Fiske, le groupe "féministe" sera perçu comme plus compétent mais plus froid, pouvant susciter des réactions de jalousie chez les individus adhérant aux stéréotypes de genre.

D'autre part, la théorie des rôles sociaux d'Eagly offre une autre typologie du contenu des stéréotypes de genre. En effet, Eagly considère que les stéréotypes portant sur le sexe féminin concernent des traits dits "communaux" (centrés sur le relationnel et l'affectif) tandis que ceux sur les hommes sont "agentiques" (relatifs à l'indépendance et à l'autonomie). On peut dès lors constater que les stéréotypes de genre sont complémentaires. En effet, les femmes sont essentiellement stéréotypées comme étant sociables, chaleureuses et axées sur les relations humaines (plus que les hommes) alors que les stéréotypes concernant les hommes les définissent comme étant compétents, indépendants et axés sur la réussite (plus que les femmes). En d’autres termes, les stéréotypes de genre attribuent à chaque groupe un ensemble de qualités que l’autre groupe ne possède pas. En outre, ces qualités propres à chaque groupe contrebalancent les faiblesses attribuées par les stéréotypes de genre (exemple de stéréotype complémentaire : les femmes sont chaleureuses mais peu compétentes alors que les hommes sont indépendants mais peu sociables).

Une étude menée en 1974 et reconduite en 2000 aux États-Unis a déterminé les adjectifs stéréotypés les plus souvent attribués : 


Cette étude met en évidence le clivage entre les traits communaux (ou de "chaleur") chez les femmes et les traits agentiques (ou de "compétence") chez les hommes.

Le processus de naissance des stéréotypes de genre peut être expliqué par la théorie du rôle de genre d’Alice Eagly. Cette théorie repose sur deux aspects structurels : la division du travail et la hiérarchie sociale basées sur le genre. Selon Eagly, ces facteurs structurels fondés sur le genre génèrent des représentations partagées socialement sur les hommes et les femmes. Par exemple, l’éducation des enfants réclame des qualités de pourvoyeur de soin et de tendresse, entre autres. Or, comme ce sont les femmes qui ont longtemps hérité de cette tâche de par leur grossesse, il est socialement attendu d’elles qu’elles soient douces et qu’elles prennent soin de leur entourage pour remplir leur rôle. Cette répartition genrée des rôles sociaux expliquerait l’émergence des stéréotypes de genre mais également les différences de comportements entre les genres en créant une réalité correspondante. En effet, les individus sont élevés dans l'idée d'endosser les traits dictés par ces rôles de genre (exemple : on apprend aux filles à être chaleureuses et sont récompensées lorsqu'elles agissent de la sorte). Par la suite, ces mêmes individus adoptent les traits qui leur ont été appris sur base de leur genre, ce qui augmente l'intensité avec laquelle ils démontrent des comportements correspondant à ces rôles (exemple : lorsque les femmes deviennent mères, leur rôle social les incite à adopter des comportements de pourvoyeur de soin).

La théorie des rôles sociaux d’Alice Eagly présuppose que les stéréotypes de genre proviendraient de différences réelles entre les hommes et les femmes. Ce "noyau de vérité" des stéréotypes de genre a été remis en cause par Hoffman et Hurst. Pour les besoins de leur expérience, ils ont imaginé une planète fictive composée de deux groupes : les Orinthiens et les Ackmiens. Pour une moitié des sujets de l'expérience, les Orinthiens travaillent en ville tandis que les Ackmiens s'occupent des enfants. Pour l'autre moitié des sujets, les proportions sont inversées : les Ackmiens sont travailleurs et les Orinthiens s'occupent des enfants. Chaque individu de chaque groupe imaginaire présentait des traits de personnalité concernant soit la chaleur, soit la compétence, de sorte que chaque groupe obtienne globalement le même ratio chaleur/compétence. Les traits de personnalité étaient donc équivalents entre les deux groupes, seuls les rôles sociaux différaient. Il n'y avait pas de différence réelle entre les Orinthiens et les Ackmiens, le "noyau de vérité" n'était alors pas présent. Pourtant, les sujets de l'expérience attribuaient plus de chaleur au groupe s'occupant des enfants et plus de compétence aux travailleurs alors que les groupes avaient été construits pour être équivalents sur ces deux dimensions. Autrement dit, les participants stéréotypaient les groupes alors qu'ils n'y avaient pas de différence de personnalité entre les Orinthiens et les Ackmiens. Hoffman et Hurst ont tiré la conclusion que les stéréotypes de genre seraient le résultat d'une inférence effectuée par les individus : ils permettent d'expliquer, voire de justifier, la manière dont l'environnement social est structuré.

Le processus de maintien des stéréotypes de genre s’opère notamment via un mécanisme de prophétie autoréalisatrice. Cette « prophétie » consiste en un cercle vicieux composé de quatre éléments :





Les stéréotypes de genre peuvent avoir différentes conséquences sur les hommes et sur les femmes.

Les travaux sur la menace du stéréotype sont relativement récents. Ce courant de recherche ambitionne d’étudier les conséquences des stéréotypes sur les individus qui en font l’objet.

La menace du stéréotype représente donc l'effet qu'un stéréotype peut avoir sur une personne visée par celui-ci. Par conséquent, le stéréotype associé à un groupe aurait un effet direct sur lui-même. De nombreux domaines et groupes sont touchés par la menace du stéréotype, notamment celui de la différence de genre. 

C’est un phénomène complexe impliquant multiples facettes. Schmader, Johns et Forbes ont développé en 2008 un modèle pour tenter d'expliquer comment la menace du stéréotype influence la performance dans des tâches cognitives et sensorimotrices. La mémoire de travail joue un rôle crucial pour la bonne efficience de ces tâches. Les auteurs ont essayé de mieux déterminer ce qui pourrait la perturber. 

Le fait d’être confronté à cette menace du stéréotype provoquerait du stress, une plus grande surveillance de soi, des pensées et des émotions négatives, une motivation afin de ne pas se comporter de manière conforme avec le stéréotype et des efforts pour éliminer les pensées négatives. Finalement, l’ensemble de ces efforts consommeraient d’importantes ressources en mémoire de travail et entraîneraient donc une baisse de performance. 

On remarque par exemple que les femmes performent en moyenne moins bien que les hommes lorsqu’elles passent la tâche de la figure complexe de Rey-Osterrieth (exercice consistant à reconnaître des figures en trois dimensions) et que cette étude est présentée comme un test de géométrie. A contrario, lorsque cette tâche est présentée comme un test de mémorisation ou un exercice de dessin, les différences entre hommes et femmes ne sont plus observées.

Une autre étude a aussi montré que, lorsqu'on fait travailler deux groupes de femmes sur un même exercice de mathématiques, le groupe auquel on aura préalablement précisé que les filles ne réussissent généralement pas l'exercice récoltera de plus mauvais résultats que dans celui où rien n'est dit.

Les différences de comportement entre homme et femmes pourraient donc être modifiées à cause de cette menace du stéréotype.

De par la menace que peut représenter le groupe si un individu ne se conforme pas aux stéréotypes de genre (surtout concernant leurs aspects prescriptifs), ces derniers peuvent engendrer un effet de contrecoup ("backlash effect" en anglais), c'est-à-dire des « représailles économiques et sociales suite à des comportements qui vont à l'encontre des stéréotypes de genre ». Cet effet de contrecoup a été particulièrement étudié dans le cadre du travail car c'est notamment dans ce domaine que les stéréotypes de genre sont particulièrement prégnants.

Tout d'abord, il faut rappeler que la composante prescriptive des stéréotypes de genre fait que toute violation de ces derniers est sévèrement punie et engendre des réactions négatives de ceux qui y adhèrent, même de façon plus ou moins inconsciente. Ce côté prescriptif est particulièrement problématique pour les femmes sur leur lieu de travail. En effet, puisque ces stéréotypes ne leur attribuent que très peu de traits de compétence (ou traits "agentiques"), elles sont obligées d'aller à l'encontre de ces stéréotypes dans le but d'évoluer dans leur carrière. Elles seraient forcées d’agir « comme des hommes » (c’est-à-dire en adoptant des comportements davantage axés sur la compétence que sur la chaleur et les relations humaines) afin de percer sur un lieu de travail. Même si ces femmes sont généralement perçues comme compétentes, elles peuvent être mésestimées par leurs collègues, qu’ils soient féminins ou masculins. Par exemple, les femmes qui réussissent dans une fonction de manager sont perçues comme étant plus hostiles et égoïstes que leurs homologues masculins. Bien que les hommes subissent aussi l'effet de contrecoup s'ils n'agissent pas en fonction des stéréotypes de genre, ils ne doivent pas nécessairement aller à l'encontre de ces derniers pour avancer dans leur carrière puisque les stéréotypes leur attribuent naturellement des traits de compétence. 

L'effet de contrecoup des stéréotypes de genre aurait tendance à saper la carrière des femmes à tous ses niveaux dont, entre autres:

Même si l'effet de contrecoup est particulièrement ressenti par les femmes, il faut noter qu'il peut également concerner les hommes dont le comportement ne correspondrait pas aux normes fixées par les stéréotypes de genre. Il peut par exemple s'agir d'hommes qui présentent plus de traits "communaux" (ou de chaleur) que de traits "agentiques" (ou de compétence). Dans ce cas, ils seront jugés encore plus sévèrement sur leur lieu de travail que les femmes dont le comportement est agentique.

Le sexisme ambivalent comprenant le sexisme hostile et le sexisme bienveillant est issu de la théorie du sexisme ambivalent développée par Glick et Fiske en 1996. Celle-ci postule que les relations entre les genres sont caractérisées par deux éléments : 
D'une part les hommes dominent au sein des différentes dans la société, ce qui constitue le pouvoir structurel. D'autre part, les hommes sont dépendants des femmes en ce qui concerne les besoins affectifs, les besoins de reproduction ainsi que pour gérer l'éducation des enfants, ce qui constitue le pouvoir dyadique. 

La coexistence de ces deux pouvoirs entraînerait une ambivalence au niveau des attitudes traditionnelles envers les hommes et les femmes. Celles-ci présenteraient des composantes à la fois hostiles et bienveillantes. Selon cette vision, le sexisme pourrait mêler des sentiments positifs à des sentiments antipathiques envers une même personne quel que soit son genre.

Ce sexisme hostile découle du pouvoir structurel et correspond, lui, à la conception traditionnelle du sexisme, c’est-à-dire qu’il se caractérise par des attitudes explicitement négatives envers les femmes, qui sont considérées comme des manipulatrices et des séductrices. Il peut se manifester au travers de comportements tels que : 

Celui-ci aurait pour objectif de punir les femmes ne respectant pas leurs rôles traditionnels liés au genre.

Les auteurs d'une étude réalisée auprès de 244 enfants d’école primaire (CM2) interprètent l’ensemble des dessins collectés comme relevant d'« humour pour dénigrer l’autre, en général la footballeuse. Cette dernière était significativement plus souvent dessinée sans les atours sportifs habituels. Pas de maillot numéroté, pas de short mais une jupe, pas de crampons aux chaussures, etc. Maquillée à outrance parfois, elle est fréquemment renvoyée à des signes extérieurs à la pratique sportive. Un dessin mettait en scène la footballeuse sous les traits d’une mamie au nez crochu, penchée sur sa canne. »

Lorsqu'un autre dessin collecté « soulignait la confrontation entre le footballeur (prénommé Roméo) et sa Juliette. Le joueur avait une cible dessinée sur le short et la joueuse expédiait manifestement le ballon dans cette direction sensible alors qu’il criait apeuré : - pitié, pitié ! - » cette posture anti-masculine chez une enfant de dix ans n'est pas perçue par les auteurs de l'étude comme de l'humour sexiste mais plutôt comme révélatrice de tensions existant sur les terrains sportifs en France au début des années 2000.

Le sexisme hostile à l'encontre des hommes justifie le pouvoir des hommes par dérogation de celui des femmes. Il se caractérise par des attitudes explicitement négatives envers les hommes qui ne satisfont pas aux clichés de pouvoir et de dominance lié à leur genre. Ceux-ci sont alors considérés comme manipulés et faibles. Il aurait pour objectif de punir les hommes ne respectant pas leurs rôles traditionnels liés au genre.

Les hommes en perçoivent les effets au quotidien :

Une étude portant sur 503 femmes se déclarant comme hétérosexuelles a mis en évidence une corrélation entre carences affectives et sexisme hostile à l'encontre des hommes.

Des femmes adoptent des attitudes sexistes à l'égard des hommes en ayant des idées, attitudes, actes ou préjugés et en généralisant les hommes à leur seul genre. On peut ainsi citer la féministe intellectuelle Valérie Solanas qui écrit dans son pamphlet "SCUM Manifesto" que « Le mâle est un accident biologique : le gène Y (mâle) n’est qu’un gêne incomplet, une série incomplète de chromosomes. En d’autres termes, l’homme est une femme manquée, une fausse couche ambulante, un avorton congénital. Être homme c'est avoir quelque chose en moins, c'est avoir une sensibilité limitée. La virilité est une déficience organique, et les hommes sont des êtres diminués, incapables d'émotion. » Elle y propose aussi de « supprimer le sexe masculin ».

Elles peuvent aussi développer des attitudes hostiles à l'égard de la domination et des abus dont les hommes peuvent faire preuve à leur égard, ou dans d'autres cas, certaines développent des attitudes positives en réponse au rôle protecteur qu'adoptent les hommes.

En France, suite à l'Affaire Jacqueline Sauvage une proposition de loi de la députée Valérie Boyer, soutenue par des associations féministes, avait pour objet de légitimer le concept de légitime défense différée dans un contexte de violences conjugales, mais uniquement au bénéfice des femmes. L'avocate Isabelle Steyer soutenait que Pour Luc Frémiot, avocat général, une application aux seules femmes victimes de violences conjugales constituerait une rupture inconstitutionnelle d'égalité devant la loi, puisqu'il existe aussi des hommes victimes de violences conjugales, physiques ou morales, ponctuelles ou habituelles, et que nul n'entend leur reconnaître pour autant le droit de tuer leur partenaire par surprise et de façon différée en invoquant ensuite la légitime défense.

Le sexisme bienveillant parfois appelé effet Les femmes sont formidables ("Women are wonderful" en anglais), est un phénomène observé par Alice Eagly et Antonio Mladinic en 1994, puis théorisé dans la notion de "sexisme ambivalent" par Peter Click et Susan Fiske en 1996.

Contrairement à l’idée qu'il est possible de se faire du sexisme traditionnel, le sexisme bienveillant à l'encontre des femmes se caractérise par une attitude subjectivement positive et tendre des hommes envers les femmes. De même que le sexisme bienveillant à l'encontre des hommes impose une dépendance de l'homme vis-à-vis de la femme qu'il se devrait d'idéaliser tel un être "pur" à protéger.

Cette forme de sexisme découlerait du pouvoir dyadique et par conséquent, de la relation d’interdépendance existant entre les hommes et les femmes qui induirait, notamment, un certain sentiment de dépendance sentimentale d'un conjoint sur l'autre qui lui permettrait d’être épanoui. Cette dépendance favoriserait donc le sexisme bienveillant car elle les amène d’une part, à reconnaître qu'un genre précis est une ressource précieuse qu’il faut protéger et d’autre part, à donner de l’affection aux personnes qui satisfont leurs besoins. Le sexisme bienveillant vise, en réalité, à récompenser les femmes et les hommes qui respectent leurs rôles traditionnels liés au genre.

Le sexisme bienveillant est rarement vécu comme un préjugé et se trouve de la sorte mieux accepté, il est aussi plus difficile à percevoir car plus discret. Ce dernier serait donc bel et bien une forme implicite de sexisme car il repose sur la domination traditionnelle d'un genre et partage quelques-uns des présupposés du sexisme hostile, à savoir que les personnes sont mieux adaptées à certains rôles et à certains espaces en fonction de leur genre, qu’elles sont ainsi prédisposées comme étant «plus fortes» ou «plus faibles» et par conséquent que cela justifie la bienveillance à leur attribuer. En fait, le sexisme bienveillant peut même se révéler plus néfaste que le sexisme hostile, puisqu’il peut être utilisé pour compenser ou légitimer le sexisme hostile.

Le caractère implicite du sexisme bienveillant rendrait la lutte contre le sexisme plus difficile et résiste donc aux dispositions législatives relatives au sexisme.

Une étude récente relative aux expressions verbales et non-verbales manifestées chez les hommes sexistes quand ceux-ci conversent avec des femmes a mis en évidence que les hommes sexistes bienveillants sont plus patients, plus souriants et complimentent davantage les femmes dans leurs conversations. Ceci n'est pas du tout le cas pour les sexistes hostiles, pour lesquels les corrélations sont d'ailleurs négatives si nous reprenons les dimensions relatives aux sourires et aux compliments . Les sexistes bienveillants montrent également plus d'expressions verbales d'affiliation (accessibilité, comportements amicaux, chaleur) et semblent plus à l'aise avec ces dernières. On peut classer la dénonciation des pratiques de mansplaining dans ces illustrations du sexisme bienveillant. La notion de galanterie est parfois considérée comme liée au sexisme bienveillant.

D'autres auteurs démontrent que plus les hommes sont sexistes bienveillants, plus ils sont restrictifs à l'égard des femmes enceintes. De la sorte, ils leur imposent toute une série de règles arbitraires concernant leurs actions afin de protéger leur santé mais en réalité, elles ne courent aucun risque. A titre d'exemple, le mari de la femme enceinte va interdire à sa femme durant sa grossesse de conduire parce qu'il juge selon lui que cela est trop risqué.

Toutefois, du sexisme hostile peut également se manifester à l'égard des femmes enceintes et mères. Par exemple, une femme qui reviendrait de son congé de maternité et qui avait souhaité une promotion avant son départ peut ne plus l'avoir parce que son patron juge arbitrairement qu'elle n'est plus capable de gérer de telles responsabilités ou qu'elle n'est plus intéressée puisqu'elle est devenue mère.

Dans une étude portant sur 488 étudiants au sujet du sexisme ambivalent à l'encontre des hommes, il a été noté que les femmes qui ne s'identifiaient pas comme féministes étaient plus facilement portées à faire preuve de sexisme envers les hommes que les femmes qui se déclaraient elles-mêmes féministes. Il a aussi été noté que les femmes qui ne s'identifiaient pas comme féministes étaient plus susceptibles de faire preuve de bienveillance envers les hommes, alors que les femmes se qualifiant de féministes soutenaient la cause féministe en faisant usage d'arguments misandres.

Les sexismes hostile et bienveillant forment une combinaison puissante: ils articulent récompenses et punitions pour que les victimes aient conscience de la place qu’elles doivent occuper. En isolation, le sexisme hostile seul amènerait de la rébellion. En revanche, le sexisme bienveillant permettrait d’affaiblir la résistance des victimes à l’égard de l'autorité par son côté gratifiant. 

Du reste, les deux formes de sexisme sont corrélées positivement d’après les recherches empiriques. Il semble d'ailleurs que les femmes adhéreraient d'autant plus au sexisme bienveillant dans des sociétés dans lequel le sexisme hostile chez les hommes est intense. En effet, c'est dans ce type de société que la protection par les hommes, et donc le sexisme bienveillant, leur apparaissent comme les plus précieux.

Le sexisme ambivalent peut avoir des conséquences négatives sur les performances et sur l'estime de soi

Le fait d'être confronté à des formes de sexisme bienveillant pourrait exercer des effets négatifs sur la performance. Il semblerait, en effet, que le sexisme bienveillant soit plus dommageable que le sexisme hostile en ce qui concerne les performances.

Le sexisme bienveillant opère grâce à deux mécanismes : d'une part, les individus valorisent les compétences sociales de la femme et d'autre part, ils dévalorisent sa performance dans les aspects typiquement associés aux hommes tels que la puissance, l’indépendance, l’intérêt de l’accomplissement personnel. La présence conjointe de ces deux mécanismes entraîne une détérioration cognitive. 

En effet, le sexisme bienveillant engendre dans l’esprit des femmes des pensées intrusives liées au doute de parvenir à réaliser la tâche. Cela entraîne une surcharge mentale qui consomme une partie des ressources cognitives qui ne peuvent donc plus être utilisées pour se concentrer sur la tâche en question. Par conséquent apparaît une détérioration de la performance à la tâche puisque les femmes adoptent la croyance qu'elles ne sont pas compétentes pour accomplir certaines tâches davantage associées au rôle masculin. 

Par exemple, dans une étude menée en Belgique, des femmes sont amenées à réaliser des entrevues de sélection en vue de l'obtention d'un poste dans une industrie chimique au sein de laquelle la population est majoritairement masculine. Le recruteur va adopter avec ces femmes différentes attitudes : 

Lors de cette entrevue, il leur est proposé une tâche de résolution de problème géométrique dans laquelle elles doivent trouver le chemin le plus court pour se rendre d'un point à un autre sur une carte. 
Cette étude montre que la performance des femmes dans la condition hostile est meilleure que dans la condition bienveillante. 
Ils en concluent donc que le sexisme bienveillant va avoir un impact négatif sur les performances. Ce qui n'est pas le cas pour le sexisme hostile qui est néanmoins source de préjudice, ou encore pour les attitudes non sexistes.

Une étude réalisée aux Pays-Bas a montré l'influence du sexisme bienveillant sur l'estime de soi des femmes

Au cours de cette étude, les participantes sont tout d'abord amenées à lire un texte faisant soit référence à du sexisme bienveillant, soit à du sexisme hostile. Deux groupes sont ainsi constitués: un groupe de femmes exposé au sexisme bienveillant et un autre groupe exposé au sexisme hostile.

Le texte bienveillant indique que les femmes :

Le texte hostile indique lui que les femmes : 

Les participantes sont ensuite amenées à répondre à des questions sur l'estime de soi et sur les compétences. 

Les résultats obtenus à la suite de cela indiquent que les femmes exposées au sexisme bienveillant ont une perception d'elles-mêmes plus négative en ce qui concerne l'aspect « réalisation de tâches » (aspect habituellement associé aux hommes). Elles se décrivent également davantage en termes relationnels (aspect traditionnellement associé aux femmes) que celles exposées au sexisme hostile. 

En conclusion, les femmes exposées au sexisme bienveillant s'estiment plus orientées "relationnel" et moins orientées "tâches" que les femmes exposées au sexisme hostile. Cela est en accord avec les caractéristiques traditionnellement associées à chaque sexe par les stéréotypes de genre.

Deux échelles ont été conçues par Glick et Fiske. Celles-ci visent à mesurer les différences individuelles du sexisme ambivalent (hostile et bienveillant). Celle consacrée à l'hostilité à l'encontre des femmes se compose de 22 items . Celle consacrée à l'hostilité à l'encontre des hommes se compose de 20 items. Tous les items sont évalués à travers une échelle de Likert. Chaquer échelle est répartie en deux sous-échelle du sexisme : la sous-échelle du sexisme hostile (SH) et la sous-échelle du sexisme bienveillant (SB).
La sous-échelle du sexisme hostile à l'encontre des femmes se compose de 11 items. Ceux-ci visent à évaluer la perception négative à l'égard des femmes selon laquelle elles rechercheraient à avoir du contrôle sur les hommes.

La sous-échelle du sexisme hostile à l'encontre des hommes se compose de 10 items. Ceux-ci visent à évaluer la perception négative à l'égard des hommes selon laquelle ils rechercheraient à avoir du contrôle sur les femmes.

Cette sous-échelle est composée de 11 items décrivant la femme comme une personne à adorer et à protéger. Ils se répartissant en trois dimensions. Ces dernières évaluent en fait les différents aspects du sexisme bienveillant : l'intimité hétérosexuelle (IH), la Protection Paternaliste (PP) et la différenciation de Genre (DG).

Cette sous-échelle est composée de 10 items. Ils se répartissent en trois dimensions : Maternalisme (M), la différenciation de Genre (DG), l'intimité hétérosexuelle (IH), .

Le sexisme moderne et le néo-sexisme correspondent à une forme actuelle du sexisme . Ces deux formes du sexisme sont relativement proches et sont sous-tendues par les mêmes croyances :

Le sexisme moderne est un concept inventé par Swim et al . Il correspond au fait que certains individus pensent que la discrimination à l'encontre des femmes et que l'égalité entre les femmes et les hommes ne constituent plus un problème.

Le sexisme moderne se fonde sur trois mythes :


Le sexisme moderne engendre des réactions négatives et un manque de soutien à l'égard des personnes qui se plaignent de sexisme. Il peut donner lieu à des réactions défavorables quant aux efforts effectués en vue de réduire les inégalités. Par conséquent, le sexisme moderne semble en partie maintenir les inégalités.

Le néo-sexisme serait un conflit entre des valeurs d’égalité et des vestiges de croyances et de sentiments négatifs envers un genre. Il affecterait le genre féminin, et le genre masculin tel que le souligne le philosophe Pierre-André Taguieff.

Les individus néo-sexistes seraient donc empreints d'égalité mais conserveraient néanmoins des sentiments négatifs à l'égard d'un genre. En outre, le néo-sexisme se réfère à des caractéristiques dites "externes", soit à la tâche et non à l'individu.

Le sexisme moderne et le néo-sexisme ont des caractéristiques communes avec le sexisme bienveillant : tous trois ne s’affichent pas de manière explicite, comme le fait le sexisme traditionnel. En revanche, le néo-sexisme et le sexisme moderne diffèrent du sexisme bienveillant parce qu’ils donnent l'illusion d'une égalité entre genres tout en omettant la discrimination touchant les femmes. Le sexisme bienveillant, quant à lui, se dissimule sous une apparence chevaleresque mettant les femmes sur un piédestal.

Le système patriarcal est un système dans lequel les hommes exercent « un contrôle structurel sur les institutions politiques, juridiques, économiques et religieuses. »
Il se base sur six structures : l’emploi, le travail domestique, la culture, la sexualité, la violence et l’État. Ces structures sont indépendantes mais il existe des interactions entre elles, et ces interactions sont à l’origine de différents types de patriarcats, regroupés entre deux extrémités : d’un côté le patriarcat privé, de l’autre le patriarcat public. Le patriarcat privé englobe les tâches domestiques qu’on associe à la femme, qui est ainsi maintenue dans la famille mais exclue de l’espace public. Le patriarcat public, quant à lui, comprend le travail salarié et l’État, il ségrègue et subordonne la femme dans l’espace public. Pour les féministes, le patriarcat est « un système de domination des hommes sur les femmes permettant d’expliquer la prévalence des inégalités hommes-femmes ainsi que leur continuité dans l’histoire. » On peut donc mettre en lien direct ce concept avec celui de sexisme.

Selon la théorie de la justification du système, les stéréotypes de genre et le sexisme bienveillant permettraient à trois mécanismes de maintenir un système patriarcal et de le justifier :




Il faut néanmoins noter que ces trois mécanismes ne sont pas autosuffisants, il faut qu'ils agissent en interaction pour être efficaces. En effet, la complémentarité des stéréotypes de genre ne peut justifier un système sexiste que si elle est soutenue par le processus de justification des rôles ainsi que par celui de cooptation.

La théorie de la justification du système suppose que le sexisme est une conséquence d'une société inégalitaire. D'autres travaux démontrent le contraire : le sexisme produirait les inégalités et non l'inverse. Dans cette ligne de conduite, une étude internationale menée en 2005 et 2007 dans 58 pays s'est penchée sur la relation entre le taux de sexisme et la présence d'inégalités au sein d'un pays. Les résultats démontrent que les inégalités entre les genres sont renforcées lorsque le sexisme hostile augmente dans une société. Autrement dit, si deux pays ont un niveau d'inégalité identique au départ et si le niveau de sexisme est plus élevé dans l'un que dans l'autre, le pays avec le niveau de sexisme plus élevé verra les inégalités entre les genres se marquer davantage avec le temps.

La réification (fait de considérer les femmes comme des objets) et l'hypersexualisation (fait de donner un caractère sexuel à la femme) sont des formes de manifestation du sexisme qui peuvent entraîner des conséquences préjudiciables pour les femmes.

La réification est un processus cognitif à travers lequel un individu s'évalue ou est évalué par les autres comme étant un objet. Ainsi, le corps d'une personne devient la principale représentation de son identité. Ce processus découle de la théorie de la réification développée par Barbara Fredrickson et Tomi-Ann Roberts en 1997 et qui vise à étudier les effets entraînés par le fait d'être considéré comme un objet.

Ce processus de réification peut, comme les stéréotypes, affecter certaines catégories de personnes (femmes, minorités ethniques...). Ainsi, par rapport aux hommes, les femmes auraient plus tendance à être victimes de réification sexuelle et par conséquent elles seraient davantage vues comme étant des objets sexuels. À force d'être considérées comme telles, les femmes en viendraient à percevoir leur propre corps comme étant destiné au désir d'autrui.

La réification d'autrui consiste pour une personne, à évaluer le corps ou des parties du corps d'un individu comme étant des objets.

La philosophe Martha Nussbaum identifie 7 façons de considérer une personne comme un objet:

Trois autres catégories ont été ajoutées par Rae Langton à celles de Nussbaum:

Par rapport aux hommes, les femmes auraient plus tendance à être victimes de réification sexuelle et par conséquent elles seraient davantage vues comme étant des objets sexuels.

Deux éléments permettent de démontrer cela : le face-isme et l'effet d'inversion.

Force est de constater que les hommes et les femmes ne sont souvent pas représentés de la même manière que ce soit dans les publicités, dans les articles de journaux, dans les portraits et les auto-portraits , ou encore dans les dessins.

Dans la publicité, il n'est pas rare que le corps de la femme soit mis en avant. Même s'il arrive, dans certains cas, d'apercevoir le corps d'un homme dans une publicité, un constat marquant peut être fait : les compétences de l'homme sont davantage mises en avant (homme d'affaires par exemple). Ce qui n'est pas le cas pour les femmes qui sont bien souvent réduites à la simple image d'un corps.

De plus, les représentations des femmes laisseraient davantage apparaître, en plus du visage, une partie du buste. Ce qui n'est pas le cas pour les hommes. Les représentations de ces derniers laisseraient uniquement apparaître le visage. Ce phénomène porte le nom de face-isme.

Il a d'ailleurs été démontré que la vision d'un visage plus proéminent serait associé à des qualités comme l'intelligence et l'ambition. Les photos des hommes, laissant apparaître uniquement le visage, maintiendraient donc la présence de stéréotypes de genre.

Les objets et les corps (ou visages) humains sont analysés différemment par notre cerveau. Ainsi, les objets sont analysés selon un mode analytique, c'est-à-dire en tenant uniquement compte des parties constituantes de ceux-ci. À l'inverse, les personnes (corps ou visages) sont analysées selon un mode configural. Cela signifie que les relations spatiales entre les différentes parties du corps sont prises en compte. Il est, par conséquent, plus facile de reconnaître des objets présentés à l'envers que des visages ou des corps humains puisque le traitement des objets ne tient pas compte des relations spatiales (mises à mal lors d'une inversion de l'image perçue).

Ainsi, une étude réalisée en Belgique a montré que les femmes en petite tenue seraient davantage analysées selon un mode analytique que les hommes en petite tenue. Par conséquent, ces dernières seraient davantage associées à des objets que les hommes.

Cela a pu être démontré en présentant des photos de femmes et d'hommes en petite tenue à des étudiants. Une première photo leur était montrée à l'endroit. Ensuite, cette même photo, accompagnée d'une photo identique mais présentée en miroir leur était montrée soit à l'endroit, soit à l'envers. Ils devaient alors dire laquelle des deux photos montrées en deuxième lieu correspondait à la première image. Il a pu être constaté que les photos présentant un homme étaient plus facilement reconnues lorsqu'elles étaient présentées à l'endroit et moins bien reconnues lorsqu'elles étaient présentées à l'envers. Cela montre que le corps de l'homme est donc analysé comme étant un tout. Tandis que pour les images présentant une femme, celles-ci sont bien reconnues, tant à l'endroit qu'à l'envers. Le corps des femmes sexualisées serait, dès lors, analysé de manière analytique tout comme le sont les objets.

L'auto-réification consiste à se percevoir soi-même comme un objet en adoptant, pour cela, le regard d'un observateur extérieur.

Cette manifestation du sexisme touche davantage les femmes que les hommes. Par conséquent, ces dernières porteraient une plus grande attention sur leur apparence, leurs vêtements, leur maquillage, etc sous le poids de l'auto-réification. Elles s'imposeraient également une alimentation stricte ou pratiqueraient du sport de manière intense pour être satisfaites de leur image et pour modifier le regard que les autres portent sur elles.

Il existe deux types d'auto-réification:

L'auto-sexualisation correspond à l'ensemble des actions entreprises par une personne afin de mettre en évidence sa fonction sexuelle.

Cette stratégie, étant guidée par des buts individuels comme la recherche d'attention, peut être associée à la stratégie du faible. En effet, celle-ci est utilisée pour compenser un manque de pouvoir ou encore pour acquérir de bonnes relations sociales. Ainsi, elle est souvent utilisée par des femmes se trouvant dans une position sociale faible. Afin d'y voir plus clair, donnons l'exemple de deux femmes hétérosexuelles s'embrassant en soirée afin d'attirer l'attention des hommes ou encore des magazines affichant des femmes à moitié dénudées.

L'auto-réification entraîne différentes conséquences psychologiques sur les femmes:
L'auto-réification augmente l'anxiété des femmes par rapport à leur sécurité physique, c'est-à-dire leur peur d'être violées ou agressées. Elle augmente également leur anxiété quant à leur apparence physique. Celles-ci ont en effet peur de la manière dont leur corps va être jugé et regardé.

L'auto-réification amène aussi un certain sentiment de honte chez les femmes vis-à-vis de leur corps étant donné qu'elles se comparent à des standards de beauté et ne les atteignent pas.
L'auto-réification diminue la capacité des femmes à être totalement absorbées dans des activités mentales et physiques complexes (=le "flow"). Ainsi, ces activités ont tendance à être interrompues quand leur apparence ou une fonction de leur corps fait l'objet d'attention de la part d'autrui .
Elle diminue également la capacité des femmes à prendre conscience de leurs sensations internes telles que la faim, la soif, etc.
L'ensemble des éléments ci-dessus ainsi que les expériences extérieures de réification sexuelle peuvent mener à des problèmes mentaux tels que les troubles des conduites alimentaires, la dépression et des troubles sexuels.
Le schéma suivant permet d'illustrer le mécanisme de l'auto-réification et ses conséquences :
L'usage de la stratégie d'auto-sexualisation, souvent utilisée par des femmes se trouvant dans une position sociale faible, entraîne des risques. En effet, elle peut rendre encore plus vulnérables au harcèlement et aux violences sexuelles. De plus, cette stratégie maintient les femmes dans leurs rôles d'objet sexuel et justifie donc leur position subalterne.

L'hypersexualisation (en anglais « "sexualization" ») consisterait à donner un caractère sexuel à un comportement ou à un produit qui n'en a pas en soi. Elle se caractérise par un usage excessif de stratégies axées sur le corps dans le but de séduire et apparaît comme un modèle de sexualité réducteur, diffusé par les industries à travers les médias, qui s'inspirent des stéréotypes véhiculés par la pornographie : homme dominateur, femme-objet séductrice et soumise.

Pour l’APA (American Psychological Association), il y a hypersexualisation lorsque l'un des quatre critères suivants est rencontré :

Elle peut prendre diverses formes :



Cette surenchère à la sexualité est présente dans tous les aspects de notre quotidien et concerne tant les hommes que les femmes, bien que ces dernières soient plus touchées. L’hypersexualisation serait également une tendance à ramener l’identité des individus à leur seule dimension sexuelle, c’est-à-dire au fait d’avoir un sexe et des relations sexuelles .

C'est un phénomène qui se développe chez les jeunes adolescents et adolescentes qui adoptent des attitudes et des comportements sexuels jugés trop précoces comme l'utilisation précoce d’éléments issus de la mode féminine adulte ou encore « des attitudes de petites femmes sexy ».

Ces pratiques s’inscrivent dans des transformations plus générales. En effet, les enfants revendiquent aujourd’hui une autonomie plus précoce et en bénéficient, non seulement du fait de l’évolution des modèles familiaux, mais aussi par l’arrivée des nouveaux médias de masse et des nouveaux outils de communication.

Cette autonomie s’exprime sur de nombreux plans culturels que ce soit dans les domaines de la musique, des nouvelles technologies ou encore de la mode. L’hypersexualisation du corps des jeunes filles interroge par conséquent les modalités contemporaines de construction des adolescents. Plusieurs travaux de recherche se sont penchés sur cette question et ont mis en exergue les liens existant entre médias et construction de la sociabilité. Certains montrent, par exemple, qu’en s’identifiant au modèle des stars de la musique et du cinéma, les filles expérimentent et s’approprient les codes de la séduction corporelle. D’autres insistent sur le fait que les adolescents utilisent les médias, notamment la musique pop, pour explorer les limites de la séduction et apprendre à devenir des adultes.

Des chercheurs remarquent que les mères des enfants des classes supérieures se montrent bien plus critiques à l’égard de ce phénomène qu’elles trouvent trop précoce. Cela implique, selon elles, un danger aussi bien physique que scolaire. Elles tentent par conséquent de le retarder et, dès lors qu’elles acceptent l’usage de vêtements issus du vestiaire féminin adulte, l’accompagnent au plus près.

Les recherches féministes s’attachent aussi à dénoncer le discours sur l’apparence proposée aux « préadolescentes » par les médias et, plus particulièrement, des magazines. Elles insistent sur l’idée d’imprégnation idéologique liée aux médias qui, sous couvert de libération sexuelle et d’épanouissement de soi, prépare en réalité les filles à leur place asymétrique dans les rapports sociaux de sexe.

Les médias joueraient, au moment de l’entrée dans l’adolescence, un rôle essentiel dans la socialisation vestimentaire des filles et, plus particulièrement, dans leur prise en compte des normes dominantes de la féminité. Nombre de ces figures féminines issues de la chanson pop, ou encore du monde du RN’B qu’affectionnent les filles au collège, leur proposent un modèle de féminité axé sur une apparence hypersexualisée.

L'hypersexualisation serait donc en partie véhiculée par les différents médias. Or, les médias, avec le concours d’autres institutions sociales, sont des agents de socialisation qui contribuent à l’intériorisation des normes de conduite, à la construction de l’identité et à l’élaboration de références communes. De nombreux spécialistes soulignent les dérives possibles d’un « sexocentrisme » relayé par les médias qui véhiculent une image du corps à travers le culte de la performance sexuelle et de l’apparence physique. De plus, la publicité et les médias utilisent, en général, de plus en plus des représentations de la femme et de l'homme "objet sexuel" à des fins strictement commerciales. Cette pratique modifierait les rapports sociaux égalitaires entre les femmes et les hommes.

Une étude Belgeanalysant la presse, des publicités, et des programmes (clips, téléréalités, dessins animés, feuilletons) à destination des préadolescents nous enseigne que :




Outre une représentation des femmes souvent près d’une fois et demie supérieure à celles des hommes (248 femmes pour 152 hommes dans les publicités et 92 femmes pour 72 hommes pour les clips), l’analyse de ces programmes met en avant une mise en scène morcelée du corps. Le corps de la femme est présenté sous forme de « plans coupés », parties du corps anonymisées et sexualisées. Les plans courants étant ceux des fesses, des seins, de la bouche. Cette présentation des personnages féminins renforce donc l’idée de la femme en tant qu’objet sexuel.

Les Clips de R’n b et de Rap présentent également des images très clivées entre les femmes et les hommes. Les hommes sont généralement présentés comme décontractés, aucune partie de leur corps n’est spécialement mise en avant généralement. Les femmes sont quant à elles plus souvent présentées avec des postures évoquant la sexualité.

La pornographisation peut donc se comprendre comme un processus qui a permis de transférer certaines valeurs (comme le culte de la performance sexuelle, l’importance donnée à l’apparence physique, les stéréotypes de l’homme viril et de la femme-objet) ainsi que certaines pratiques (comme la dissociation entre l’agir sexuel et les sentiments, les danses lascives, les mimiques faciales et positions corporelles suggestives, une grande diversité de pratiques sexuelles avec un grand nombre de partenaires différents, des façons de s’habiller) du monde de la pornographie vers la société en général par l’intermédiaire des médias. Ces attitudes comprendront des caractéristiques sexuelles dont les codes seront issus du monde de la pornographie et seront clairement identifiables grâce aux stéréotypes sexistes mis en œuvre.

Le « porno chic » est un exemple de cette pornographisation de la culture. Le «porno chic » désigne une pratique publicitaire qui puise son inspiration directement dans la pornographie. Le but principal de cette publicité, outre le fait qu’elle vise à élargir la clientèle, est de retenir l’attention du public et d’influencer son opinion à l’égard de la marque. Le « porno chic » est né aux États-Unis au début des années 1970 pour désigner les premiers films pornographiques. C'est un phénomène qui touche beaucoup la publicité des produits hauts de gamme, de luxe (parfums, haute couture, mode, etc.). Il consiste en une représentation souvent déshumanisée de l'être humain en utilisant tantôt la nudité, tantôt la soumission ou encore l'asservissement sexuel.

La stratégie du « porno chic » des grandes marques de luxe a pour objectif de susciter un désir chez le consommateur tout en lui faisant mémoriser la marque, ce pourquoi la provocation est très utile. En impliquant fortement le consommateur, le shockvertising (publicité provocatrice) garantit la remarquabilité de l’annonce et augmente son taux de mémorisation.

On distingue généralement trois formes de publicité porno chic :



Les jeunes adolescents subiraient diverses pressions des médias et de leur entourage. Ils deviendraient dépendants de l’appréciation des autres et, par le fait même, vulnérables avec des conséquences néfastes sur leur santé mentale. Cette survalorisation de l’apparence et de la séduction comme mode de rapport à l’autre comporterait également des risques pour la santé physique des jeunes filles comme des troubles des conduites alimentaires, l’utilisation récurrente de régimes amaigrissants dès le plus jeune âge, la consommation de drogue et d’alcool, le tabagisme, le recours aux chirurgies esthétiques, les relations sexuelles. Selon des études, même si les filles sont meilleures dans plusieurs domaines, leur estime de soi serait plus faible que celle des garçons.

L'APA (American Psychological Association) distingue trois types de problèmes de santé mentale rattachés à la l'hypersexualisation chez les jeunes filles:



D'autres enjeux identitaires comme l'insatisfaction face à leur image corporelle serait également une des conséquences de ce processus d'hypersexualisation entraînant des comportements à risques (malnutrition, comportements sexuelles sans protection...).

L'hypersexualisation toucherait également les hommes et mènerait à une diminution de l’attirance pour leur partenaire, mettrait en péril la capacité d’être empathique avec leur partenaire féminin et interférerait sur leur capacité à conserver une relation.

L’hypersexualisation renforcerait également les stéréotypes sexuels et l'idée selon laquelle la femme doit être soumise et l’homme doit avoir le pouvoir. Ce phénomène entraînerait également une compréhension plus mécanique du corps (un corps malléable que l’on peut et doit modifier à des fins esthétiques et sexuelles.) La sexualité deviendrait également un simple rapport de communication et de consommation dans la société.

En conditionnant l'image des hommes et des femmes, les médias accentueraient donc les inégalités de genre dès le plus jeune âge. Ce processus d'hypersexualisation s'impose donc comme un véritable argument marketing auprès de marques.

La ligne de sous-vêtements "Jours Après Lunes", lancée en janvier 2011, propose des soutien-gorge à partir de quatre ans. La marque "Abercrombie & Fitch" propose également des bikinis rembourrés vendus « dès 7 ans ». Les fillettes peuvent même allaiter leur poupée "Breast Milk Baby" à l’aide d’un débardeur avec tétons intégrés. La marque Tammy (Etam pour les 8-16 ans) a également commercialisé des strings pour enfants.

Ce phénomène de sexualisation précoce serait pour certains auteurs l'une des explications du sexisme. Selon eux, puisque les enfants apprennent du monde des adultes, ceux-ci sont vulnérables face aux compagnies de marketing. Or les modèles et les produits qu’on leur propose sont très sexualisés tels : poupées, vêtements, jeux, dessins animés et télé-réalités diffusées aux heures de grande écoute. Outre cela, ce phénomène contribuerait à la demande de plus en plus croissante de pornographie en mettant en scène des mineurs.

Cependant, d'après certains auteurs, il serait important de mentionner que si les jeunes s’inscrivent dans de telles démarches ou sont tentés de le faire, c’est que ces comportements servent de support à leur sociabilité. Y adhérer serait non seulement pour eux une manière d’affirmer qu'ils grandissent, mais aussi de marquer leur adhésion aux normes du groupe dans lequel ils sont insérés.

L’hypersexualisation contribuerait également à l'augmentation des violences et des agressions sexuelles. Un nombre grandissant de magazines, vidéos, calendriers, jouets, vedettes de la chanson, sites Internet pornographiques et publicités de toutes sortes accentueraient quotidiennement le message que le corps des filles et des femmes peut être utilisé, exploité, vendu, agressé.

En effet, la surexposition des jeunes à des contenus pornographiques peut être vécue comme une « effraction psychique » sur un plan psychologique. Les représentations véhiculées dans la pornographie autour de la violence et de la domination sur les femmes en particulier induiraient une certaine forme de légitimation de la violence entre pairs. Ces mécanismes sont à l’œuvre dans le cyberharcèlement, le harcèlement sexuel entre adolescents et toutes les pratiques déviantes.

Face à l’apparition de l’hypersexualisation, il convient de développer la capacité d’analyse des jeunes et leur esprit critique en encourageant l’éducation aux médias et au décodage publicitaire.

La sensibilisation auprès de la société et surtout auprès des jeunes, en montrant l'impact de l'hypersexualisation, serait selon divers auteurs un moyen utile de lutte contre ce phénomène. En outre, un périmètre juridique doit, selon certains auteurs, être envisagé pour prévenir les risques. De nombreuses pétitions voient d'ailleurs le jour pour un meilleur contrôle face à l’érotisation des images d’enfants dans toutes les formes de publicités. Au Royaume-Uni, par exemple il est maintenant interdit aux enfants d'être l’égérie des marques avant 16 ans.

Au Québec, les articles 248 et 249 de la Loi de protection du consommateur interdisent la publicité télévisée destinée aux enfants de moins de 13 ans. En Suisse, la publicité est interdite aux enfants de moins de 12 ans. En France, face à un message publicitaire jugé non conforme (contenu sexiste, hypersexualisation...), il est possible d’adresser une plainte à un jury de déontologie publicitaire (JDP) qui statuera sur son bien-fondé au regard des règles déontologiques que la profession s’est fixées.

En 2013, sur les 606 plaintes adressées au jury de déontologie publicitaire, 438 ont été considérées comme recevables. Il y a donc, de plus en plus, une lutte pour sensibiliser la société face aux effets de ce phénomène d'hypersexualisation.

Certains spécialistes expliquent également l'importance de discuter avec notre entourage de la question de l’hypersexualisation, les sensibiliser aux messages communiqués dans les vidéos, la musique, les magazines, la publicité, les télé-réalités, les concours des plus belles filles, etc. Ils mentionnent également l'importance d'éviter la promotion de produits sexistes

D’autres outils didactiques développés par plusieurs organismes et chercheurs, par exemple ceux du projet " "Outiller les jeunes face à l’hypersexualisation : Osez…être soi-même" " sont également mis en place dans le but sensibiliser les gens. Le " "Y des femmes"" produit également plusieurs outils qui peuvent servir à cette sensibilisation.

Diverses vidéos de sensibilisation analysent et préconisent des solutions afin d'attirer davantage l’attention de notre société sur les conséquences néfastes du phénomène auprès des jeunes filles et des femmes.

Les objets du quotidien sont fondamentaux dans l’explication de l’apparition du sexisme chez les enfants, puisqu’ils induisent déjà chez eux des stéréotypes que ces derniers ne soupçonnent même pas. En effet, ces objets rendent concrètes les différences qui existent entre les filles et les garçons. Ce phénomène est très bien illustré dans les magazines de jouets qui sont publiés en période de fêtes de fin d’année : on distingue clairement les jouets destinés aux filles et ceux destinés aux garçons, les premiers étant la plupart du temps de couleur rose, les seconds de couleur bleue.

Les livres sont également importants. Ils touchent en effet les enfants de manière très précoce. Ainsi, il existe déjà des livres pour les tout petits enfants, ce sont souvent des livres d’images, cartonnés ou en tissu. Par la suite, quand ces mêmes enfants grandissent, ils passent alors aux bandes dessinées, et plus tard encore aux histoires de plus grande envergure sous forme de romans. Ce qu’il est important de soulever ici, c’est que les garçons et les filles n’occupent pas des places égales au sein des livres, en particulier dans la littérature jeunesse. En effet, une étude menée en 1994 montre que les personnages féminins y sont largement sous-représentés (en termes de proportions, dans la littérature jeunesse, les personnages principaux de sexe féminins ne représentent que 40 % des cas). De façon contradictoire, on y retrouve toutefois davantage de mères et grands-mères que leurs équivalents masculins, alors que le versant du monde du travail est, quant à lui, en grande partie constitué de personnages de sexe masculin. Par ailleurs, dans ces histoires, les personnages féminins sont limités en termes de métiers, puisque la plupart du temps elles exercent des métiers en lien avec l’enseignement, les enfants ou la vente (caissière, etc.). À l’opposé, les hommes y occupent souvent des postes divers et variés, et qui les valorisent d’un point de vue social. Ces représentations renvoient des modèles d’identification différents aux jeunes filles et aux jeunes garçons : les premières n’ont d’autre choix que de constater qu’elles sont absentes de la littérature jeunesse (ou de s’identifier à un personnage de sexe masculin), et les seconds n’ont que très peu de modèles féminins auxquels s’identifier.

Le mouvement du féminisme, apparu au, plus ou moins, avec Christine de Pisan, Marie de Gourney au , a pris de l'ampleur après la Première et surtout la Seconde Guerre mondiale, permettant une avancée vers l'émancipation des femmes et la visibilité et la critique de plus en plus grande des phénomènes de discrimination sexiste, quels que soient ses domaines. Malgré ce processus général amorcé d'abord dans les sociétés de l'Europe du Nord et de l'Amérique du Nord dans les années 1960, et suivi plus tardivement dans l'Europe latine (en particulier dans les pays méditerranéens où des régimes conservateurs, tels le franquisme, l'Estado Novo de Salazar ou le régime des colonels en Grèce étaient en place) et en Amérique latine (où des dictatures militaires conservatrices étaient aussi en place, parfois ).

Les premières revendications ont porté sur le droit à l'éducation. Marie de Gournay, dans "L'égalité des hommes et des femmes" (1622), réclame l'accès à l'éducation pour les femmes et affirme que leur prétendue infériorité ne tient qu'au fait qu'elles n'aient pas accès à l'école. L'égalité hommes-femmes est le principal objectif du féminisme. Dès le , les féministes réclamèrent le droit de vote des femmes, mouvement qui se poursuivra au début du avec les suffragistes (couramment désignées par le terme péjoratif "suffragettes") au Royaume-Uni, pour ne l'obtenir qu'au milieu du (1945 pour la France par exemple). Le mouvement revendique aussi l'égalité dans la sphère du droit personnel (mariage, divorce, autorité parentale, etc.), à l'autonomie économique et financière (droit au travail, droit d'utiliser un compte bancaire, etc.), et à la disposition de son corps, déliant la sexualité de la reproduction sexuelle (révolution sexuelle avec l'apparition des différents moyens de contraception et luttes pour le droit à l'avortement...).

Ce mouvement n'a pas été restreint aux pays occidentaux, émergeant par exemple en Égypte dans les années 1920 (fondation de l'Union féministe égyptienne par Huda Sharawi en 1923), en même temps qu'aux États-Unis, ou en Tunisie (Tahar Haddad). Il n'a cependant pas eu autant d'influence dans ces pays qu'en Europe ou aux États-Unis. En Amérique latine, il a aussi été considérablement retardé. Depuis peu, on voit cependant des ébauches de mouvements en faveur des droits des femmes se diversifier dans le monde entier. On peut ainsi citer le congrès sur le féminisme musulman à Barcelone du 3 au 5 novembre 2006, ou encore une série de lois indiennes du qui ont modifié l'essentiel du droit de la famille dans un sens égalitaire.

Aujourd'hui, le féminisme en France lutte pour conserver le droit à l'avortement, il a pour but l'émancipation complète des femmes et la totale égalité entre femmes et hommes. Il lutte contre la construction de genre qui perpétue le modèle de la domination masculine. Ailleurs le féminisme lutte toujours pour le droit à l'éducation des filles (parce que près des trois cinquièmes des enfants non scolarisés dans le monde sont des filles), pour l'acquisition de leurs droits politiques, pour la libre disposition de leurs corps, etc.

L’hominisme (presque systématiquement appelé masculinisme dans les médias et par les organisations féministes) est un mouvement issu de pays francophones dont le but est d'intégrer la préoccupation de la condition masculine à la préoccupation de la condition humaine en général.

Certaines revendications hoministes dénoncent les jugements en matière de divorce ou de séparation qui auraient selon eux tendance à favoriser les femmes. Le droit des pères, notamment en ce qui concerne la garde des enfants, y serait insuffisamment reconnu. Ainsi, si d'après Gérard Réverend, président de l'association Les papas=les mamans, à peine 1 père sur 5 (20%) demande à avoir la résidence principale de son enfant, en 2009 selon le ministère de la Justice seulement 1 enfant sur 12 (8%) est confié au père contre 74,6 % à la mère et 16,9 % en résidence alternée aux deux parents. D'après Marc Juston, juge aux affaires familiales à Tarascon, mais restent dans un .

Pour les hoministes, les violences contre les hommes, en particulier conjugales, ne sont ni reconnues ni combattues par les pouvoirs publics. Au Canada, jusqu'en 1999, seules les femmes étaient interrogées lors d'enquêtes importantes sur la victimisation en milieu conjugal. Ils dénoncent également la sur-mortalité masculine, résultante d'une sous-prise en compte de la santé des hommes.

Les positions "queers" (désignant les personnes LGBT, soit les lesbiennes, gays, bisexuels et transsexuels) mettent l'accent non seulement sur le genre, mais aussi sur tous les phénomènes d'inter-genre ou encore de « troisième sexe » : transsexualisme (lorsque le genre subjectivement ressenti entre en conflit avec « le sexe naturel » ), intergenres (hermaphrodisme, etc.), dragqueens, etc., et soutiennent que la division même de l'humanité entre hommes d'un côté, femmes de l'autre, est une bipartition socio-historique ayant des effets de violence symbolique et parfois concrète dans l'imposition de catégories juridiques (c'est un homme ou une femme?) pour des personnes intersexuées).

Les Principes de Jogjakarta réaffirme en citant les mots de la Convention sur l'élimination de toutes les formes de discrimination à l'égard des femmes qu'il faut « abroger l'idée de l'infériorité ou de la supériorité de l'un ou l'autre sexe ou d'un rôle stéréotypé des hommes et des femmes. »

Concernant les systèmes de retraite, les retraites par capitalisation (fonds de pension) désavantagent mécaniquement les femmes, contrairement aux systèmes par répartition, en étant calculées en fonction de l'espérance de vie. Ainsi, au Chili, en 2008, la différence entre une femme médecin et un homme ayant cotisé à un fonds de pension depuis 1981, date de son instauration par la junte militaire, sur les mêmes bases, était flagrante: pour une femme et pour un homme. En France, les inégalités sont aussi criantes puisqu'en 2011 selon la DREES, un homme touche en moyenne une pension 42 % plus élevée qu'une femme (en moyenne 1603€ pour un homme contre 932€ pour une femme).

Le BIT préconise une rémunération égale entre les hommes et les femmes (principe "À travail égal, salaire égal").

Cependant, toutes les statistiques relatives à la rémunération signalent un net désavantage aux professions historiquement féminines. À poste identique, les salaires des femmes sont souvent inférieurs à ceux des hommes dans plusieurs pays. Des politiques tentent de pallier ce déséquilibre par la promotion légale de la parité.

L'exercice du pouvoir en entreprise ou en politique est historiquement masculin et possède un salaire élevé.

D'après l'INSEE les salaires des femmes sont en moyenne plus faibles que ceux des hommes à mêmes poste et niveau de formation équivalents. Si cette différence de revenus est généralement attribuée aux discriminations, d'après plusieurs études celle-ci serait liée à la présence d'un enfant dans le foyer familial. Ainsi

Les usages linguistiques, comme l'utilisation du masculin grammatical (ou plus rarement du féminin grammatical) dans les langues comportant le neutre ou l'absence de titres professionnels ne faisant pas référence au genre (voir féminisation des noms de métiers en français) sont également considérés par des linguistes comme Marina Yaguello comme des formes de sexisme.

En France, malgré de régulières mesures sur la parité, les femmes politiques ne représentaient encore dans les années 2000 qu'une minorité des gouvernants. Leur égalité juridique n'est venue que dans les années 1960-70 (permission d'utiliser un carnet de chèque sans l'autorisation du mari, responsabilité parentale, etc.).

Diverses mesures législatives ont été prises dans plusieurs États pour promouvoir l'égalité homme-femmes. Le Parti travailliste britannique proposait ainsi, en 2010, la promulgation de l' qui reprendrait la plupart des mesures promulguées antérieurement, en en ajoutant quelques-unes; le pape Benoît XVI s'est durement opposé à cette proposition de loi.

La discrimination fondée sur le sexe est anticonstitutionnelle et illégale dans de nombreux pays. Dans les États-membres du Conseil de l'Europe, elle tombe sous le coup de l'article 8 (vie privée et familiale) et de l'art. 14 de la Convention européenne des droits de l'homme. Mais même dans les pays ayant établi l'égalité des sexes dans la loi, il peut rester des lois conférant une prérogative ou un devoir à un genre plutôt qu'à l'autre, par exemple concernant :

De telles mesures sont parfois présentées comme étant « positives » envers un genre. 

La Constitution Européenne spécifie en son article II-81 qu' « est interdite toute discrimination fondée notamment sur le sexe (...) », mais qui précise en son article II-83 - spécifique à l'égalité entre femmes et hommes - que « le principe de l’égalité n’empêche pas le maintien ou l’adoption de mesures prévoyant des avantages spécifiques en faveur du sexe sous-représenté.»

Avec comme argument de leur apporter plus de sécurité ou de confort certains pays acceptent l'instauration de mesures en faveur des femmes. Cela peut concerner les moyens de transport, les places de parking. 

En Chine et en Corée du Nord des mesures similaires ont été prises avec comme argument de faciliter les manœuvres automobiles aux femmes en leur proposant des emplacements plus larges et une signalisation plus voyante.

En France, suite à l'affaire Jacqueline Sauvage un projet de loi proposait de modifier la loi sur la légitime défense pour en exclure le critère de riposte immédiate en cas de violences conjugales lorsque la victime était une femme. La loi n'a jamais vu le jour.

Ces mesures ont été souvent dénoncées, avec comme argument soit que cela constituerait une discrimination à l'encontre des hommes soit que cela conforterait les clichés de la femme fragile ou maladroite.

Les diverses méthodes contraceptives (pilules, préservatifs, stérilets) et l'avortement sont illégaux dans de nombreux pays. La morale dominante et la loi y dénient le plus souvent à la femme un pouvoir de disposition total de son corps en matière de procréation. Dans ces pays le divorce peut y être limité, notamment au divorce pour faute à la demande du mari. Certaines sociétés admettent également des sévices corporels à l'encontre des femmes, à la discrétion du mari.

En France le divorce fait polémique, notamment concernant le droit de garde des enfants. Sur ce point, en 2013 une étude du Ministère de la Justice démontre que dans toutes les configurations de divorce concernant un ou plusieurs enfants, les pères sont désavantagés par rapport aux mères.

La polygamie est presque toujours exclusivement polygyne (un homme pour plusieurs femmes).

La polyandrie n'existe que dans quelques rares sociétés comme les Guanches aux îles Canaries, ainsi que dans des peuples minoritaires ou aux faibles effectifs (comme au Mali).

Un peu moins d'un tiers des pays tolèrent la polygynie sans l'encourager ouvertement. C'est le cas non seulement de la totalité des pays à forte population musulmane (à l'exception de la Turquie et de la Tunisie où la polygamie est interdite), mais également de quelques pays animistes africains. Quelques États autorisent aussi la polyandrie.

Selon Jacques Attali ("Amours. Histoires des relations entre les hommes et les femmes", 2007), « la polygynie est encore autorisée - ou tolérée - aujourd'hui, dans des pays représentant près du tiers de la population de la planète. Seulement 10 % des hommes y ont plusieurs femmes, essentiellement les plus riches ». À titre d'exemple, un des pays à autoriser la polygamie est le Qatar où pourtant, il y a déjà un manque de femmes. En effet, au Qatar, il y a 3,39 fois plus d'hommes que de femmes (voir CIA Factbook Qatar) ... Autre exemple, l'Inde où il y a pourtant un manque criant de femmes (CIA Factbook Inde).

Chez les Juifs ashkénazes, la polygamie a définitivement été interdite pour les Juifs ashkénazes au XI siècle par Rabbenu Gershom, l'un des pères de la tradition rabbinique ashkénaze. Cette interdiction a également été adoptée par les Juifs séfarades.

La majorité des grandes religions actuelles, dans leurs textes fondateurs ou leurs pratiques, attribuent des fonctions différentes à la femme et à l'homme. C'est le cas pour les trois religions monothéistes : christianisme, judaïsme, islam. C'est aussi le cas de l'hindouisme, du bouddhisme, ou du confucianisme, mais pas celui de la religion bahá'íe. Plusieurs contre-exemples se trouvent dans des religions anciennes, telles que l'ancienne religion égyptienne, le shintoïsme à ses origines, l'ensemble des cultes de la période néolithique, et dans des créations récentes telles que la Wicca, ou néo-paganisme. Les religions des cultures amérindiennes matrifocales, toujours pratiquées aujourd'hui par des amérindiens et des adhérents du néopaganisme, s'articulent autour d'une égalité dans la différence, voire d'une certaine prédominance de la femme et de la Nature, tandis que les hommes trouvent leur place à la périphérie (chasse, défrichage, affaires diplomatiques). La réalité politique contemporaine des réserves amérindiennes, entourées de systèmes capitalistes et patriarcaux, fait en sorte que ces rôles périphériques, autrefois subordonnés à la gestion surtout féminine du politique et du sacré, deviennent prépondérants et contribuent à subvertir ces religions amérindiennes matrifocales .

Certaines religions amérindiennes encouragent le jeu avec les rôles sociaux de genres.

À l'époque néolithique, la majorité des divinités étaient féminines , la capacité d'enfanter étant probablement ressentie comme magique, et liée symboliquement à la fertilité de la terre . Selon Élisabeth Badinter, la divinisation des femmes connait son apogée avec le développement de l'agriculture, pour ensuite connaitre une période de basculement vers, dans un premier temps, une parité des statuts entre les et millénaires puis vers les religions concomitantes à l'avènement du patriarcat. Élisabeth Badinter met en doute l'explication de , qui y voit les conséquences de la découverte des mécanismes de la sexualité et attribue notamment cette évolution à la montée d'une classe guerrière à l'âge du bronze, soit mixte comme dans le cas des celtes, soit essentiellement masculine.

Dans le cas du shintoïsme, c'est Amaterasu, la déesse-mère, qui est la divinité à l'origine du monde. Dans l'ancienne Europe, du paléolithique au néolithique, Marija Gimbutas relève elle aussi, à travers l'analyse de l'art, de nombreux cas de cultes dédiés aux divinités féminines. Dans l'hindouisme, on trouve un contre-exemple avec la persistance du culte de la déesse-mère avec les traditions liées aux "kumaris" dans la vallée du Népal.

La légende du "Livre des Anciens", présentée par Hiramash dans "La Magie d'Hénok", se sert du mythe égyptien de la lutte entre Horus et Seth pour symboliser le renversement du pouvoir matriarcal (Seth) au profit du pouvoir patriarcal (Horus) il y a environ 7000 ans de cela. Cette légende contemporaine, mêlant mythologie égyptienne et lecture originale du Livre d'Hénoch, avance une thèse d'anthropologie politique, expliquant que les États, nécessairement policiers et gaspilleurs des ressources naturelles, sont une création typiquement masculine et patriarcale qui va à l'encontre du fonctionnement naturel du cerveau humain, fait pour évoluer dans des groupes de moins de quarante personnes sur le mode coopératif. C'est pourquoi, selon cette légende, la notion d'État est à terme condamnée, quelle que soit son utilité et sa légitimité philosophique. C'est cette domination masculine qui fait passer pour indispensables les valeurs de bestialité et de hiérarchie sociale que connaissent la plupart des sociétés contemporaines.

Dossiers, monographies 


</doc>
<doc id="2918" url="https://fr.wikipedia.org/wiki?curid=2918" title="Simple Mail Transfer Protocol">
Simple Mail Transfer Protocol

SMTP est un protocole assez simple (comme son nom l'indique). On commence par spécifier l'expéditeur du message, puis le ou les destinataires d'un message, puis, en général après avoir vérifié leur existence, le corps du message est transféré. Il est possible de tester un serveur SMTP en utilisant la commande telnet sur le port 25 d'un serveur distant.

Le SMTP commence à être largement utilisé au début des années 1980. Il est alors un complément à l'UUCP, celui-ci étant plus adapté pour le transfert de courriers électroniques entre des machines dont l'interconnexion est intermittente. Le SMTP, de son côté, fonctionne mieux lorsque les machines qui envoient et reçoivent les messages sont interconnectées en permanence.

Le logiciel Sendmail est l'un des premiers, sinon le premier serveur de messagerie électronique à utiliser SMTP. Depuis, la plupart des clients de messagerie peuvent utiliser SMTP pour envoyer les messages. Certains nouveaux serveurs sont apparus, comme Postfix, Qmail de Daniel J. Bernstein, Exim et Exchange de Microsoft.

Comme le protocole utilisait du texte en ASCII (7 bits), il ne fonctionnait pas pour l'envoi de n'importe quels octets dans des fichiers binaires. Pour pallier ce problème, des standards comme MIME ont été développés pour permettre le codage des fichiers binaires au travers de SMTP. Aujourd'hui, la plupart des serveurs SMTP acceptent le MIME sur 8 bits, ce qui permet de transférer des fichiers binaires presque aussi facilement que du texte simple.

SMTP utilise TCP pour le transfert des données.

SMTP ne permet pas de récupérer à distance des courriels arrivés dans une boîte aux lettres sur un serveur. Les standards Post Office Protocol (POP) et IMAP ont été créés dans ce but.

Le transfert de messages entre serveurs de messagerie électronique se fait généralement sur le port 25 qui est le port standard enregistré auprès de l'IANA. Les serveurs utilisent les
enregistrements MX des serveurs DNS pour acheminer le courrier.

Les clients de messagerie utilisaient aussi le port 25 (smtp) pour soumettre des messages en utilisant le protocole SMTP. Mais la nécessité de mieux contrôler les envois des clients, en particulier par l'authentification, a conduit à l'attribution du port 587 (submission).

Les administrateurs de serveur peuvent choisir si les clients utilisent le port TCP 25 (SMTP) ou le port 587 (soumission), tel que formalisé dans la (2476 précédemment), pour relayer le courrier sortant vers un serveur de messagerie. Les spécifications et de nombreux serveurs supportent les deux. Bien que certains serveurs prennent en charge le port 465 (historique) pour le SMTP sécurisé en violation des spécifications, il est préférable d'utiliser les ports standard et les commandes ESMTP (Extended SMTP) standard selon la , si une session sécurisée doit être utilisée entre le client et le serveur.

Le test par telnet mentionné ci-dessus donnerait un "dialogue" du genre (les messages du serveur sont en ) :

Notons que la fin du texte est repérée par un point seul sur sa ligne. Lorsque le texte doit contenir un point seul sur sa ligne, il est donc nécessaire de le doubler (<CR><LF>..<CR><LF>).

Comme on le constate dans l'exemple ci-dessus, il existe une syntaxe précise pour envoyer les messages et une série de codes retour sur trois chiffres pour indiquer le statut de la demande. Le premier chiffre du code retour indique le statut global de la demande, les deux autres chiffres donnent le détail du statut :

Messages les plus courants : 

Une des limitations de SMTP vient de l'impossibilité d'authentifier l'expéditeur. Pour ceci, l'extension SMTP-AUTH a été définie. Malheureusement, l'impossibilité d'imposer largement SMTP-AUTH a rendu ce protocole impuissant face au phénomène du spam.

Le spam est dû à un certain nombre de facteurs dont : l'implémentation de logiciels Mail Transfer Agent (MTA) ne respectant pas les standards, les failles de sécurité dans les systèmes d'exploitation autorisant les spammeurs à contrôler à distance des PC utilisateurs pour leur faire envoyer du spam et enfin un manque d'intelligence de certains MTA.

Afin de lutter efficacement contre ce phénomène, il existe deux approches : modifier profondément SMTP (voire le remplacer) ou bien lui adjoindre d'autres protocoles pour combler ses lacunes. Modifier SMTP de manière importante, ou le remplacer complètement, ne paraît pas faisable, à cause de l'importance du réseau de serveurs déjà installé. Malgré tout, des solutions alternatives ont été développées comme ou ePost.

Une autre approche consiste à créer des systèmes visant à assister les opérations du protocole SMTP. Le groupe de recherche anti-spam (ASRG) de l', travaille actuellement sur l'authentification des courriers électroniques dans le but de fournir un système flexible, léger, extensible, et évolutif. L'ensemble de ces recherches ont abouti au protocole en 2004 ainsi qu'au protocole DomainKeys Identified Mail en 2006.

En 2006, l'AFA recommande aux fournisseurs d'accès internet (FAI) de bloquer les paquets TCP/IP sortant à destination du port 25. L'idée développée est qu'

À l'époque entre 50 % et 80 % du spam était généré par des ordinateurs infectés.

En France et au Canada, les principaux FAI ont suivi cette recommandation : Orange, Bell, Videotron et CCAPcable bloquent le port 25 depuis juin 2007, Free depuis décembre 2006 (c'est une option, le blocage peut être désactivé), AOL depuis 2003.

La pratique aujourd'hui est la soumission du message par l'utilisateur au serveur de messagerie en utilisant du SMTP authentifié (port 587). Le port 25 sert uniquement aux serveurs SMTP entre eux.




</doc>
<doc id="2920" url="https://fr.wikipedia.org/wiki?curid=2920" title="Samuel Beckett">
Samuel Beckett

Samuel Barclay Beckett, né le à Foxrock (Dublin) et mort le à Paris, est un écrivain, poète et dramaturge irlandais d'expression principalement française, anglaise et aussi allemande, prix Nobel de littérature en 1969.

Il est l'auteur de romans, tels que "Molloy", "Malone meurt" et "L'Innommable" et de poésies en prose, mais il est surtout connu pour son œuvre théâtrale. Sa pièce de théâtre la plus célèbre est "En attendant Godot", chef-d'œuvre du théâtre de l'absurde. Son œuvre est austère et minimaliste, ce qui est généralement interprété comme l'expression d'un profond pessimisme face à la condition humaine. Ce pessimisme n'exclut cependant pas l'usage d'humour omniprésent chez l'auteur, l'un étant au service de l'autre, pris dans le cadre plus large d'une immense entreprise de dérision.

Avec le temps, il traite ces thèmes dans un style de plus en plus lapidaire, tendant à rendre sa langue de plus en plus concise et sèche. En 1969, il reçoit le prix Nobel de littérature pour « son œuvre, qui à travers un renouvellement des formes du roman et du théâtre, prend toute son élévation dans la destitution de l'homme moderne ».

Samuel Barclay Beckett naît le , jour du Vendredi Saint, dans une famille de la bourgeoisie protestante irlandaise, issue de huguenots français réfugiés en Irlande. La demeure familiale, "Cooldrinagh", située dans une banlieue aisée de Dublin, Foxrock, est une vaste maison bourgeoise. Il est le deuxième fils de William Frank Beckett, métreur, et May Barclay Roe, infirmière.
Il vit une enfance heureuse, partagée entre les études, les parties de tennis, de cricket, les baignades en compagnie de son père, les randonnées à bicyclette et les parties d'échecs, loisirs qui, avec la lecture, occuperont également sa vie adulte et alimenteront ses œuvres. Beckett reçoit ses premiers rudiments de français et apprend le piano dès l'école primaire, puis entre en 1915 à la Earlsfort House School, établissement multiconfessionnel, pour quatre années, mêlant études et sport.

L'ambiance change en 1920, lorsqu'il rejoint son frère à l'internat de la d'Enniskillen (comté de Fermanagh), au règlement plus strict, et qui lui apporte des valeurs comme le sens de l'honneur, de la loyauté et de l'intégrité.

Entre 1923 et 1927, Beckett étudie le français, l'italien et l'anglais au Trinity College de Dublin. Il suit notamment les cours de Thomas Rudmose Brown qui aura l'influence la plus déterminante sur son parcours intellectuel, lui faisant découvrir de nombreux auteurs français et anglais. Il suit également des cours d'italien et éprouve une véritable révélation pour Dante. Beckett acquiert ainsi les fondements d'une culture qui fera de lui l'un des écrivains les plus érudits du vingtième siècle. Ses études à Dublin favorisent son accès à la culture avec, par exemple, la découverte du théâtre de Synge, de la peinture à la National Gallery ou du cinéma.

Il éprouve de réelles difficultés d'insertion sociale, en raison de son refus de toute compromission, mais aussi de la conscience qu'il a de sa propre valeur intellectuelle, isolement à l'origine d'une tendance dépressive. C'est aussi le début des troubles physiques, cardiologiques et pneumologiques, qui compliqueront son existence pendant de nombreuses années. C'est enfin l'époque d'une première expérience sentimentale, malheureuse, puis d'un début d'idylle avec l'une de ses cousines mais qui sera l'occasion d'une scène violente avec sa mère et qu'il rompt.

Il obtient cependant une bourse de troisième cycle, voyage à nouveau en France et en Italie, puis est admis comme lecteur d'anglais à l'École normale supérieure de la rue d'Ulm et il arrive à Paris en . Après le conformisme et le puritanisme de Dublin, ce séjour lui paraît enchanteur, pour sa richesse culturelle. Il se lie d'amitié avec Thomas MacGreevy, qui sera son seul confident jusqu'à la guerre. MacGreevy l'initie à la vie parisienne intellectuelle et artistique, et surtout l'introduit dans le cercle des intimes de James Joyce, rencontre qui marque profondément Beckett.

Son retour à Dublin en comme maître de conférence au Trinity College marque le début d'une longue période d'instabilité. Alors que ses parents l'incitent à trouver un « emploi stable », il comprend que les fonctions d'enseignant ne lui procureront aucune satisfaction. Il trouve quelques compensations littéraires avec des traductions et la publication de poèmes mais reste en marge de la vie universitaire de Trinity College, et ne parvient décidément pas à s'intégrer dans la société irlandaise. En fin d'année 1931, il démissionne de l'université brusquement, voyage en France et en Allemagne, travaille à un roman et tente de s'établir à Paris, puis à Londres comme critique littéraire. Mais son manuscrit est refusé par tous les éditeurs, et il doit rentrer à Dublin à la fin de 1932. Dans l'atmosphère déprimante de Cooldrinagh, sans indépendance financière, il se met à trop boire. Son père, auquel il était uni par une vraie complicité, meurt en 1933, et il hérite d'une somme qui lui sera versée par mensualités. En 1934 il parvient à publier un premier recueil de nouvelles, qui reçoit un accueil mitigé, dont les ventes sont très lentes, et censuré en Irlande.

Sur les conseils d'un ami, il part à Londres pour entreprendre une psychothérapie. L'analyse qu'il effectue avec Wilfred Bion lui fait identifier, comme cause de ses angoisses et de ses maux physiques, les relations avec sa mère. Celle-ci, par une éducation rigide tout en le mettant sur un piédestal, aurait contribué à son isolement social par un sentiment de supériorité intellectuelle. Cette période aura cependant été relativement fructueuse sur le plan littéraire, avec la publication de plusieurs articles critiques, la rédaction d'un roman, "Murphy" et la publication des poèmes "Echo's bones". En , il part en Allemagne pour un voyage de six mois essentiellement consacré à la peinture : visites d'ateliers d'artistes, de musées et de galeries, mais qu'il qualifie de désastre.

Il revient à Cooldrinagh mais toujours incapable de s'entendre avec sa mère, il part pour Paris où il retrouve l'ambiance et les amis qu'il avait connus en 1930. Il y rencontre en particulier les peintres Bram et Geer Van Velde avec lesquels il ressent une véritable complicité. En il est victime d'une agression au couteau par un voyou et la blessure est grave, mais c'est à cette occasion qu'il retrouve une amie qu'il avait connue au tennis à l'ENS et qui sera sa compagne jusqu'à sa mort, Suzanne Descheveaux-Dumesnil, . Sa vie commence ainsi à se stabiliser , "Murphy" reçoit un accueil plutôt favorable de la presse anglaise, et à partir de ce moment il passera chaque année un mois auprès de sa mère.

Beckett se trouve auprès de sa mère en Irlande lorsqu'il apprend l'entrée en guerre de la France. Le , il écrivait : . Il rentre donc immédiatement à Paris et se porte volontaire comme ambulancier. Mais il doit quitter la capitale et, aidé par Joyce, puis Valéry Larbaud et Marcel Duchamp, il se réfugie à Arcachon avant de revenir finalement à Paris et rejoindre la Résistance, au sein du réseau Gloria le .

Averti d'une trahison, il échappe juste à temps aux arrestations et s'enfuit avec Suzanne. Aidés cette fois par Nathalie Sarraute, ils arrivent six semaines après à Roussillon dans le Vaucluse où il est rejoint par un ami peintre, juif, Henri Hayden. Il aide aux travaux des champs et écrit, elle donne des leçons de piano. Le , il se voit décerner la Croix de Guerre et la Médaille de la Résistance. L'œuvre de Beckett est profondément marquée par les récits de déportation et par la guerre.

De retour à Paris au début de 1945, Beckett effectue rapidement un voyage à Dublin pour revoir sa mère qu'il n'a pas vue depuis six ans. C'est au cours de ce séjour, alors qu'il se trouve dans la chambre de sa mère, touchée par la maladie de Parkinson, âgée de soixante-quatorze ans, qu'il a une sorte de « révélation » (le mot est de lui), aboutissement d'un cheminement personnel après l'analyse avec Bion, les années de Résistance, l'éloignement hors de l'Irlande maternelle. Cette « vision » change sa conception de l'écriture. Il revient à Paris convaincu que c'est là qu'il doit vivre et se fait d'abord engager comme économe-interprète par la Croix-Rouge irlandaise qui construit un hôpital à Saint-Lô. Il y fait l'expérience d'une immense misère collective. Son dévouement infatigable reflète la mutation psychologique qui s'est opérée en lui, contrastant avec l'attitude de réserve et d'isolement de ses années dublinoises.

Malgré les conditions matérielles difficiles, entraîné par la certitude de sa vocation et la compréhension offerte par cette « révélation », il va vivre pendant huit années une véritable « frénésie d'écriture ». À la mort de sa mère, il hérite d'une somme qui lui permet de faire construire une maison modeste à Ussy-sur-Marne où il vient avec Suzanne régulièrement pour écrire au calme. Les écrits s'accumulent et c'est Suzanne qui parvient à trouver un éditeur, Jérôme Lindon (, pour les romans, mais les ventes restent modestes. Ce n'est qu'en 1953, grâce encore aux démarches de Suzanne, que Roger Blin monte la pièce "En attendant Godot", premier véritable succès, qui le fait accéder à la notoriété et lui apporte une aisance financière.

Dès lors, le théâtre prend une place nouvelle dans sa vie d'artiste, par l'écriture mais aussi comme metteur en scène de ses pièces. L'Irlande lui reste pourtant « étrangère » : en 1958, il interdit jusqu'à nouvel ordre toute représentation de ses pièces pour protester contre la censure dont y est victime Seán O'Casey. À Paris, il assume une vie littéraire et artistique intense (nombreuses rencontres avec des peintres) chargée de rendez-vous et de dîners, de concerts avec Suzanne, et doit effectuer de nombreux déplacements en Europe pour monter ses pièces. Ussy est alors un refuge pour l'écriture et les traductions, mais il part aussi en vacances au soleil de l'Afrique du Nord ou en Sicile.

Les années 1960 représentent une période de profonds changements pour Beckett, dans sa vie personnelle comme dans sa vie d'écrivain. En 1961, au cours d'une cérémonie civile discrète en Angleterre, il épouse sa compagne Suzanne Déchevaux-Dumesnil, principalement pour des raisons liées aux lois successorales françaises. Ils déménagent boulevard Saint-Jacques, dans un appartement qui domine la prison de la Santé.

Sa notoriété n'en finit pas de s'étendre, entraînant d'innombrables sollicitations. En plus d'une production littéraire constante, prose et théâtre, son écriture évolue vers des œuvres toujours plus minimales, et des formes variées : mimes, pièces radiophoniques ou télévisuelles, cinéma. Ce rythme de travail intense s'accompagne de nombreux problèmes de santé, et il souffre d'un abcès au poumon dont le traitement et le repos nécessaire le maintiennent cloîtré pendant les événements de mai-juin 1968.

Le prix Nobel de littérature lui est attribué en 1969 : il considère cela comme une « catastrophe » ; en fait, il rejette par là une certaine industrie beckettienne, au sens où cette récompense accroît considérablement l'intérêt de la recherche universitaire pour son œuvre. D'autres écrivains s'intéressent à lui, et un flot constant de romanciers et de dramaturges, de critiques littéraires et de professeurs passent par Paris pour le rencontrer. Son désarroi de recevoir le prix Nobel s'explique aussi par son désintérêt pour les mondanités et les devoirs qui y sont liés. . Son éditeur Jérôme Lindon va tout de même chercher le prix dont il redistribue la somme à ses amis.
Les dernières années sont marquées par la disparition de nombreux amis, et le besoin de solitude. Sa production littéraire reflète cette situation personnelle mais sans apitoiement, avec des personnages orientés vers l'examen. Ainsi "Mal vu mal dit", évoquant sa mère, et appréhendant la disparition de Suzanne, ou "Solo" décrivant un mur de photographies de famille.

Suzanne Beckett, son épouse, décède le . Samuel Beckett, atteint d' et de la maladie de Parkinson, part dans une modeste maison de retraite où il meurt le 22 décembre de la même année. Il est enterré le 26 décembre au cimetière du Montparnasse ( division), dans une tombe aux côtés de son épouse, .

Le cheminement d'artiste de Beckett est décrit en particulier par quatre critiques proposant des analyses complémentaires sur l'évolution de son écriture. décrit les conditions de narration et d'énonciation ; Gilles Deleuze met en évidence trois niveaux de langage, et l'intervention de formes musicales ; Pascale Casanova étudie l'auto-référence comme une voie vers l'abstraction et pour concilier les deux directions de la recherche beckettienne, le langage et la forme, elle évoque ; enfin Lassaad Jamoussi montre comment Beckett radicalise le dépouillement du langage.

Dès 1937, Beckett annonce dans une lettre l'entreprise langagière dans laquelle il souhaite s'engager : . Cette déclaration définit son ambition esthétique, qui le conduira progressivement vers l'abstraction. En conduisant son intellect vers la création d'un monde abstrait où il n'y aurait plus rien à perdre, cette voie lui permet aussi d'assumer son radicalisme spirituel mais en évitant toute réaction émotionnelle. Une telle ambition formelle est sans précédent en littérature, où elle opère une subversion de ses fondements, dans une démarche s'appuyant sur la recherche esthétique déjà réalisée en peinture, et sur les procédés de la musique contemporaine.

Ludovic Janvier souligne la présence dans toute l’œuvre de et propose, comme métaphore de cette obligation de parler, la contrainte, l'impulsion première donnée au bébé à la naissance pour ouvrir la bouche, commencer à respirer une « nourriture aérienne » : la parole, qui vous « soulage sans fin » et qui s'opposerait au . En effet, Beckett avait entrepris une psychanalyse en 1935, qui révèla des souvenirs d'étouffement liés à la naissance : .

Au début des années 1960, il entreprend ainsi une démarche formelle au sein de la littérature. Il est convaincu qu'une forme émergera et .
Il ne faut cependant pas concevoir son travail d'écriture comme l'accomplissement d'un projet maîtrisé par avance, mais plutôt comme un "Work In Progress" à la manière de Joyce, opérant par ruptures, mais aussi par mises au point successives. Dans la progression des premières œuvres aux dernières pièces, au fur et à mesure que le processus de réduction et d'abstraction de l'écriture accroît le pouvoir d'évocation, musicale ou visuelle, du texte, l'écriture de Beckett se rapproche de la peinture et de la musique, et fait de l'élaboration du récit ou de l'image théâtrale un travail plastique de plus en plus tangible.
Dans ses premiers romans, Beckett fait encore intervenir un narrateur extérieur, d'abord omniscient (), puis, plus ambigu, subordonné au personnage ( et ). Cependant, il peine à être publié et son audience reste encore confidentielle, aucune reconnaissance artistique ne vient justifier ses choix esthétiques ou littéraires. Mais lors d'un séjour en Irlande en 1946, « tout devient clair » pour lui, comme il le raconte en 1958 dans : 
Beckett n'explicite pas la nature de cette solution, mais ses essais critiques et sa correspondance montrent que c'est en considérant les questions formelles posées, et les réponses apportées, par les peintres d'avant-garde, qu'il a pu sortir de l'aporie littéraire dans laquelle il était enfermé et rompre avec les évidences de la représentation. Gilles Deleuze considère que Beckett utilise à ce moment un premier niveau de métalangage « Langue I » exprimant une imagination (production d'images) encore entachée de raison, une langue , culminant avec , dont il dit cependant quelques années plus tard 

Dans les ouvrages suivants (, ), le personnage devient son propre narrateur et adopte le "je" du monologue, puis est évincé du discours comme une entité inconsistante. Gilles Deleuze remarque que dans , , ce qu'annonce d'ailleurs explicitement Beckett : . Au refus de l'intériorité psychologique, Beckett ajoute celui des métaphores , et de la transcendance. Il n'est plus question de constituer un univers fictif, mais de s'interroger sur la possibilité de la narration. Le langage est reconnu impuissant à décrire le réel et à rendre compte de soi, le "je" est un sujet grammatical sans substance psychologique, le discours est décomposé, « poussière de verbe ».

Avec l', Beckett reste dans la continuité de ses innovations précédentes, mais les radicalise. Il attaque les conventions littéraires restant encore, considérées comme fondements de l'« effet de réel ». Les premières lignes du roman () mettent en cause les repères spatio-temporels de la création littéraire. Gilles Deleuze identifie dans l' un deuxième niveau de métalangage, « Langue II », procédant non plus avec des noms mais avec des voix, et une imagination débarrassée de la raison mais encore dépendante de la mémoire Mais une telle 

Une critique de Maurice Nadeau à la sortie du livre, comprend et explicite la recherche que Beckett poursuit avec l"'Innommable" et Beckett l'en remerciera chaleureusement : 
Beckett cherche ainsi à opposer une « littérature du non-mot » à la démarche inverse de Joyce d'apothéose du mot. Mais cette recherche, constitue, avec les et jusqu'à , une nouvelle impasse pour Beckett : .
Il cherche la forme la plus faible, la plus proche de l'expression du rien, le pire, le moindre, la voix qui s'écoute se taire mais .
Avec les "Textes pour rien", qui il tente de sortir de cette impasse, et Ludovic Janvier explique que ces textes ne sont pas "pour rien" mais qu"'ils ont le rien pour sujet".

Plus de sujet, plus de contenu, presque plus de signification, c'est l'impossibilité d'écrire qui doit devenir l'objet de l'écriture, il n'y a plus à dire que et Beckett reprend à son compte la réflexion qu'il avait décelée dans certains tableaux de Braque, ressemblant à .

Mais il doit pour cela trouver d'autres dispositifs littéraires, et il se tourne vers le théâtre, où la scène dispense le discours d'indiquer textuellement le processus énonciatif, et permet une nouvelle épuration littéraire par un ascétisme dramaturgique et par l'évidement du discours scénique. Les grandes et premières pièces (, et ) ne contiennent pas d'intrigue (il s'agit surtout de meubler une attente), ont un espace simplifié, les personnages sont rares et réduits à leur parole puisque sur la scène particulièrement, , et le langage se substitue même parfois à l'enveloppe corporelle.

Alain Chestier décrit les dernières étapes de l'écroulement du langage. Le vacillement, dans la syntaxe et la sémantique, avait débuté dans "Oh les beaux jours" . Il s'accroît dans les pièces suivantes (, et ). Le langage achève de se disloquer avec dans un discours décousu, des répétitions de syntagmes nominaux ou de propositions participiales, un discours non daté, sans mode, sans aspect, ni objet ni sujet, discours intérieur des voix du silence. Dans , , et le parleur se retrouve finalement seul avec sa voix dans : .

C'est dans , qui totalise selon Pascale Casanova l'ensemble de ses innovations littéraires précédentes, que Beckett approche le mieux (le pire) l'objet de sa recherche, de son processus d'« abstractivation ». Au bout de cette révolution formelle, pour laquelle , Beckett a « tant bien que mal » abstrait le langage, jusqu'au point où il n'y a « plus moyen ».
Déjà dans , qui est en quelque sorte le discours préliminaire à son œuvre ultérieure, Beckett évoquait (voir encadré).

Pierre Longuenesse souligne cet effet d'abstraction, lorsqu'il évoque l'influence de la musique devenue un principe structurant, dans , pièce très formaliste, fragmentée en trois voix, monologues eux-mêmes fragmentés par des silences. Cette pièce, , et produit une musique concrète de bruits et de mots. (pièce sans paroles) peut être vue comme une « fugue de mouvements ». La critique utilise ainsi fréquemment des termes musicaux pour désigner littéralement ou métaphoriquement la structure des pièces.

Gilles Deleuze propose de voir une étape littéraire ultime dans l’œuvre théâtrale tardive de Beckett, avec par exemple , et , pièces proches du ballet, où dominent les images (visuelles ou auditives), associant sans hiérarchie son, lumière, mouvements, au langage, avec le développement d'un imaginaire sonore et musical dans les textes. Les pièces du recueil "Quad" constituent des « ritournelles d'images » mettant ainsi en œuvre un troisième niveau de métalangage, la « Langue III » de Gilles Deleuze, celui des images sonnantes et colorantes, que Lassaad Jamoussi appelle langue picturale et que Beckett maîtrise de plus en plus dans les œuvres les plus tardives.

Ce sont des "parmi les ombres appesanties" avec .

Les que Beckett perçoit dans l'art pictural, révélant les tensions internes de l'artiste, sont également la problématique essentielle de sa création littéraire. La réalité est constituée en chaos, et l'enjeu de son œuvre, comme de ses amis peintres est de . Mettre en forme des objets dans l’œuvre d'art, en littérature comme en peinture, c'est poser un leurre, et Beckett est là aussi en accord avec Malevitch : 


Pour échapper à l'illusion mensongère d'une possibilité de représenter le monde, l'artiste doit créer une œuvre d'art . L’œuvre d'art est alors de fait un agrégat de détails rebelles qui se donnent à prendre et non à comprendre, chacun étant indépendant causalement des autres, mis dans un rapport d'interférences, de superpositions, de contiguïté.

Beckett considère, en prenant exemple sur la peinture, que . Tous ces détails (objets de la peinture ou de la littérature, issus de la ) sont issus du même effort de représentation et du même désarroi dans l'impossibilité d'être représentés, caractérisant la « choseté », et Beckett leur affecte une couleur indistincte entre le « noir clair » et « blanc sombre ». C'est cette « choseté », concept final résumant la quête théorique de Beckett, qui, en se substituant au principe de représentation, permet au récepteur de se mettre en symbiose avec l’œuvre : .

Ainsi que l'exprimait déjà Proust, . Dans sa propre création littéraire, Beckett met en œuvre ces principes que la peinture a élaborés, son projet poétique est de présenter ce monde, mais .


Beckett rejoint Merleau-Ponty pour considérer que seule une vision polysensorielle évite de figer et appauvrir l’œuvre d'art, en retardant la prise de conscience de l'objet par une démarche qui sinon serait réductrice et univoque. La vision polysensorielle (musicale, picturale) du Rien, a un potentiel de surpuissance créatrice (puisqu'il ne s'agit pas d'une imitation du réel) qui se dissémine dans les textes et les pièces de Beckett : le chaos, caractérisé par le Choseté, est le matériau de sa création. L'indistinct de cette choseté permet à la prose artistique d'être une pensée positive de l'indistinct.
Selon Lassaad Jamoussi, .
Les images tiennent lieu de pensée dans le projet poétique de Beckett (), et sont, avec la voix des dernières pièces radiophoniques et télévisuelles, l'objet du discours en même temps qu'un élément narratif. « L’œil écarquillé », qui est alors scène et spectateur de tout, accède au statut de personnage, et le discours lui-même se présente comme une sorte d'image, brille et s'éclipse : .

Les figures sont des personnages conceptuels. 

Ce n'est plus seulement l’œil qu'il faut écarquiller afin de faire, d'avoir, l'image, ce sont les mots qu'il faut réinvestir : la main qui écrit se substitue à l’œil qui voit, pour « écarquiller la langue » et retrouver derrière les concepts les mots, et derrière les mots, les images.

Selon Saussure, . Dès qu'on donne une forme verbale aux phénomènes inintelligibles, qu'on donne des mots aux choses, les phénomènes deviennent des images dotées de signification. La poétique beckettienne cherche à s'en affranchir, et se caractérise par cette recherche de langages nouveaux transgressant la raison commune, se libérant de tout ancrage dans un espace-temps, et s'affranchissant par là d'une nécessité de produire du sens. Tout en utilisant des mots, ils se rapprochent des procédés de la peinture (reptation, formes...) pour atteindre, chez le lecteur, non pas son intellection, mais ses facultés sensibles.

En décembre 1977, un éditeur interroge Beckett en reprenant la question posée par Hölderlin à propos des poètes : "" ? Mais à propos de la poésie comme du théâtre, Beckett refuse de fournir des réponses sur l'utilité de l'écriture poétique ou sa signification sociale ou morale. Il ne s'intéresse qu'à , et les derniers mots de sa dernière œuvre, un poème écrit quelques mois avant sa mort, sont : "comment dire".

Les poèmes de Beckett ne représentent que trois des volumes des Éditions de Minuit, mais la poésie est présente partout dans cette œuvre protéiforme. Dès sa jeunesse d'écrivain, ami de Thomas McGreevy, il aborde la poésie, se plaçant dans une filiation de Yeats et de James Joyce.

L'œuvre est dominée par les textes courts, où Beckett s'exprime par la forme et par l'image, , son projet est de susciter des affects puissants par des images saillantes et . L'enjeu de sa réflexion littéraire est de parvenir à un texte qui soit ni prose ni poème, ou prose et poème à la fois, et c'est finalement l'ensemble de l’œuvre qui est un vaste poème, pourtant Beckett n'existe pas en tant que poète dans les anthologies ou dans les livres consacrés à la poésie, probablement parce qu'.

Les Éditions de Minuit ont publié trois volumes désignés comme recueils de poèmes.


Selon Ludovic Janvier . Ainsi :


On peut citer en particulier :


Pourtant Beckett estimait la poésie incompatible avec le théâtre : .

L'Irlande fournit des paysages de désolation où ses créatures déambulent sans pouvoir s'en évader, et les mots sont issus de grands système de signification ("Purgatoire" de Dante pour "Le dépeupleur", la Crucifixion pour "Bing"...).

L'aporie et l'aposiopèse sont employées pour représenter faisant dire à Benjamin Britten que ces figures de style donnent à la langue de Beckett .

Le style est sans emphase, au profit d'un prosaïsme dépourvu d'adjectifs, les phrases nominales prolifèrent dans des textes proches d'un discours didascalique, entraînant parfois le texte presque vers le silence. Poésie du prosaïque, poésie brisée dans un rythme brisé, une cadence syncopée. Les métaphores ne sont pas descriptives (le caractère descriptif des métaphores employées par Baudelaire dans le poème "Les phares" l'avait empêché de traduire ce poème), et elles postulent pour leur compréhension non pas un dictionnaire, mais une encyclopédie, faisant référence à des lieux communs propres à l’œuvre de Beckett dans son ensemble. En quête de nouveauté et d'originalité, le langage chez Beckett perd sa nature représentative et ne peut plus assurer sa fonction traditionnelle de communication et d'expression.

Beckett s'intéresse au théâtre depuis ses années d'étudiant, lorsqu'il découvre le théâtre irlandais avec John Millington Synge et le théâtre français avec Racine alors qu'il manifeste une aversion pour Corneille. Il présente Racine en 1930 à ses étudiants de Trinity College où il est maître de conférences de français, et il revendiquera toujours son influence sur sa propre écriture théâtrale. C'est pendant cette période à Dublin qu'il aura son unique expérience d'acteur, dans une pochade d'étudiant sur le thème du Cid (« le Kid »). Avant Godot, Beckett entreprend d'écrire deux autres pièces : "Human Wishes" dans les années 1930, inachevée, et en 1947, jamais jouée.

Quand il écrit , il n'a donc encore aucune expérience théâtrale : , et Jean Martin qui fut "Lucky" à la création de "Godot" avoue . La pièce, mise en scène par Roger Blin, obtient un succès critique (Armand Salacrou, Jean Anouilh, Jean Duvignaud) mais déclenche des polémiques. Le scandale, que ni Beckett ni Blin n'avaient prévu, assure cependant le succès de la pièce qui reste à l'affiche pendant des mois. Beckett passe du statut confidentiel de poète et romancier irlandais à celui d'auteur de théâtre d'avant-garde et sa réputation de critique et théoricien littéraire se renforce par son refus de toute explicitation de son œuvre. Il prend alors beaucoup d'assurance vis-à-vis du phénomène théâtral qu'il ne connaissait pas mais « devinait superbement », et Roger Blin qui a mis en scène le premier "Godot" au Théâtre de Babylone va le faire connaître dans le milieu des petits théâtres de la rive gauche où il trouvera sa consécration d'écrivain mais aussi réalisera son initiation de praticien du théâtre.

Le réseau professionnel et amical de Roger Blin lui ouvre ensuite les portes de théâtres plus importants comme à Paris le Théâtre de l'Odéon mais aussi à l'étranger, surtout Londres et Berlin, les plus ouverts à l'écriture française d'avant-garde. Il reste pourtant encore un auteur irlandais, proche de Synge, et dont les pièces sont destinées à de petites salles.

Beckett reste cependant toujours en retrait vis-à-vis du public, et n'assiste jamais à une représentation publique de l'une de ses pièces, laissant parfois Suzanne, sa femme, y assister. Une seule fois il assiste à la première, au Schlossparktheater de Berlin en 1953, et accepte de venir saluer le public. Le directeur général raconte : .

Les précédentes tentatives d'écriture théâtrale, en particulier "Eleuthéria" achevé mais jamais joué, sont purement littéraires, alors que les didascalies sont très nombreuses dans "Godot", révélant la préoccupation de l'auteur pour la dimension scénique de son œuvre. Ces didascalies reflètent la confusion initiale qui fut la sienne, entre la vision préalable de l'auteur, et la réalisation scénique, mais dont il prend rapidement conscience .

Les pièces de Beckett ont une tonalité philosophique qui met les acteurs et les metteurs en scène à la recherche d'un sens : , interprétations que découragent systématiquement le texte, par l'épanorthose, et l'auteur lui-même, qui refuse de fournir interprétation et refuse toute herméneutique. Il se crée ainsi , et la présence de l'auteur devient indispensable pour donner aux acteurs les indications nécessaires.
La création de "Godot" en 1953 l'amène ainsi à s'intéresser à ce processus de la création théâtrale à partir du texte de l'auteur. Il assiste d'abord aux répétitions, et Roger Blin l'initie à cet art. En 1958, il conseille Georges Devine à la création à Londres, puis est assistant de Blin à l'Odéon en 1961. En 1966 il assure seul la mise en scène de "L'hypothèse" de Pinget puis celle de et sera dès lors en mesure de mettre en scène ses propres pièces. Son implication dans la mise en scène l'amène à réduire les didascalies dans les pièces suivantes, et, inversement, c'est la mise en scène qui devient nécessaire pour finaliser le texte. En 1956, pour "Fin de partie", il précise ainsi . D'autre part, son travail avec Blin l'amène à prendre en compte le travail sur le corps rendu possible par la mise en scène, et il entreprend, après "Godot", d'écrire un mime, le "Mime du rêveur", qui reste cependant inachevé.

Beckett se révèle alors être aussi un artiste du théâtre, capable de créer des images puissantes et souvent ambiguës, et il est également sollicité par Robert Pinget qui lui demande en 1966 de mettre en scène sa propre pièce, l"Hypothèse" : . James Knowlson évoque .

Il est prêt, à l'occasion de la mise en scène de ses pièces traduites (en allemand, en anglais, en français), à apporter des modifications importantes les versions déjà publiées, sur la base des données concrètes mises en lumière par le travail scénique. Il s'agit généralement d'aller vers un amoindrissement par des suppressions, mais aussi d'un travail sur la dimension « musicale » du texte, en établissant des rythmes ou des structures de mots et de sons.

Pour Beckett, la mise en scène n'est donc pas simplement une nouvelle représentation de quelque chose contenu dans le texte, mais c'est surtout l'occasion de lui donner une forme visuelle et sonore. Elle devient pour lui un moyen de prolonger, par une coopération auteur / metteur en scène avec lui-même, son projet artistique par la création théâtrale.
Il produit également par ce travail scénique, comme par la traduction, des variantes littéraires qui ne sont pas des désaveux des versions précédentes, ni des équivalents littéraires, mais des textes nouveaux, par re-création. Le rapport direct au théâtre devient alors un élément crucial de son activité créatrice, après un « épuisement » de sa création narrative.

Beckett redoute de voir des interprétations occulter les enjeux internes de ses pièces, ce qui n'est pas dénué de fondements puisque Jean-Paul Sartre regrettait que "Godot" soit une pièce "bourgeoise" parce que sans références aux réalités sociales, et que Bertolt Brecht a envisagé de transposer les personnages de "Godot" dans un contexte politique : Estragon en prolétaire, Vladimir en intellectuel, etc. Cette crainte, et son refus constant d'expliciter le sens de ses pièces, sont à l'origine d'incompréhensions récurrentes entre Beckett et les comédiens ou les autres metteurs en scène.
Il demande aux comédiens de se concentrer sur le jeu corporel, sur l'effectuation du discours, pour les détourner de toute posture intellectuelle et éviter toute tentation rhétorique ou herméneutique, et ainsi éviter de parler du sens. Ses personnages sont des figures qui se précisent par le travail scénique, comme il l'indique à Carlheinz Caspari qui met en scène "Godot" à Bonn : .

En laissant le sens dériver au gré de libres associations, on obtient , et que Beckett refuse au metteur en scène, mais aussi au comédien qui substituerait son "roman" au texte de l'auteur. Il veut laisser cette liberté au spectateur. Les enjeux d'interprétation au sujet du matériel de la mise en scène, ou du décor, sont également évacués : , c'est d'ailleurs ce que proclamait Molloy qui n'étant porteurs d'aucun sens, ne peuvent donner le prétexte à interprétation.

L'énoncé du texte tend finalement à être distinct du personnage-figure, et Beckett envisage même d'aller jusqu'à une disparition du comédien : 

Le théâtre de Beckett est engagé, selon Jean-Baptiste Frossart, dans une rupture totale avec les règles du théâtre traditionnel, en revisitant et radicalisant en fait la règle des unités. Beckett imite en cela Racine, dont il admire la simplicité, qui représente dans Bérénice un monde statique, préservé de tout changement, et dont il remarquait que . Pour Beckett, l'environnement du drame, c'est la scène elle-même, et la première qualité des personnages est d'être "en scène", irrémédiablement présents, jouant à être des acteurs : .

En éliminant les références temporelles il refuse de sortir de et déroute le spectateur. Les personnages sont incapables de se situer au sein d'une histoire et n'ont pas d'autre activité qu'attendre et meubler l'attente : . Vladimir et Estragon attendent Godot, Hamm et Clov attendent que ça finisse, Winnie attend la fin de la journée. Attentes sans objet, dont l'action est donc "a priori" exclue. Dans les pièces télévisuelles, Beckett rejette même la notion classique de « personnage en action » du drame, l'attention est concentrée sur un visage ou simplement une bouche dans des pièces très courtes, où une voix intérieure incarne une image très concentrée de l'existence et où l'action est remplacée par une intensification des tensions : .

Pour Beckett, tout est déjà dans le texte : et . Le lieu est le décor, et il propose même à Blin de remplacer certains éléments du décor par des pancartes "ceci est un arbre" ou d'intégrer dans le texte l'information sur le décor.

Il s'oppose à toute théâtralité, qu'il stigmatise par le terme de "wagnérisme" : . Il refuse ainsi la cohabitation des arts, par la présence de musique ou de peinture sur scène, sous forme de musique de scène ou de décors peints, qui seraient de l'esthétisme, un simple « agrément », voire « un pénible contresens ».

. Au bout de l'amoindrissement se trouve « le moindre », qui n'est pas seulement un amenuisement mais : il ne s'agit donc pas d'un art minimaliste mais de l'invention d'un spectaculaire dénué des fastes wagnériens, et . Plus aucune transcendance ne peut intervenir sur scène, et la « parole vaine » des personnages n'est pas une façon de combler le vide, mais c'est ce qui permet au rien de se dire et de se montrer dans des figures.

Beckett se situe dans une évolution, et peut-être à son terme, de la forme théâtrale. Le théâtre avait vu la mort de la tragédie et l'avènement du drame, le théâtre psychologique s'imposant, et remplaçant le cadre mythique de la représentation classique par un ancrage contextuel des pièces et par un approfondissement psychologique et social. Au contraire de cette tendance, Beckett s'inscrit dans la tradition racinienne et décontextualise ses pièces par un temps et un lieu vagues. Le dépouillement et le « style humble » de ses mises en scène suggèrent une tragédie tout en évitant philosophie et sensibilité, dans « une construction rhétorique et poétique éblouissante ». La souffrance, tue, essentielle, reste suggérée en arrière-plan, évitant l'écueil de la dramatisation passionnelle.

Le théâtre de Beckett, que ce soit dans ses premières grandes pièces ou dans les pièces suivantes, ne demande cependant pas que le spectateur soit immédiatement capable de décoder les enjeux intellectuels, parfois complexes, sous-tendus par le texte. Au contraire, le spectateur doit d'abord laisser sa sensibilité accessible à l'impact global des images, inoubliables, composées d'une manière absolument neuve d'un grand nombre d'éléments linguistiques, visuels, dramatiques. Beckett fabrique et met devant les spectateurs des objets et des figures, mais le public vient parfois au théâtre en espérant, par un mécanisme de défense contre une vérité inacceptable, qu'à la fin du spectacle il aura donné des réponses ou des remèdes (voir encadré).

Les trois « grandes pièces » ("En attendant Godot", "Fin de partie" et "Oh les beaux jours", peut-être complétées par "La dernière bande") sont encore d'une facture relativement traditionnelle, celle d'un romancier venu au théâtre, et le langage repose encore sur des personnages. Mais au début des années 1960, Beckett s'engage dans un théâtre de plus en plus formaliste, accordant au visuel une part aussi grande qu'au langage, produisant un théâtre plus statique qu'actif, et plus lyrique que dramatique, mimodrames, dramaticules, ou pièces radiophoniques. Il se tourne également vers la télévision (, , , , ) où la réalisation est plus souple, avec un regard plus « féroce », plus froid.

Ses mises en scène font souvent référence à des tableaux, mais il ne cherche surtout pas à contrefaire la peinture, ou à composer des tableaux sur scène. Il s'agit plutôt d'une picturalité « en sourdine », et la scène beckettienne relève de l'image et non du tableau, . Pour les trois grandes pièces, on cite ainsi, parce qu'on sait que Beckett connaissait ces tableaux, "Deux hommes contemplant la lune" de Caspar David Friedrich pour "En attendant Godot", un tableau de décollation pour "Fin de partie" : "Salomé avec la tête de Saint Jean Baptiste" de Caravage, et "Portrait de Frances Day" d'Angus Mc Bean pour "Oh les beaux jours". Pour "Fin de partie" encore, Roger Blin estime que Beckett voyait la pièce . Il s'inspire également de modèles musicaux, utilisant un vocabulaire musical de tempo et de mouvement pour « orchestrer » le langage, mais aussi pour installer le comédien dans une modélisation formelle plutôt qu'une interprétation littéraire.

Dans cette évolution vers le « moindre », représente l'impasse créatrice, qui imprègne la structure de l’œuvre, et le manque est devenu le texte. Au bout de ce parcours, , pièce de trente-cinq secondes, scène dépeuplée, vestiges d'une présence humaine, .

Le terme « prose narrative » désigne les romans et nouvelles écrits entre en 1934 puis surtout en 1938 et les nouvelles du recueil en 1955, les textes en prose ultérieurs s'apparentant plutôt à des poèmes en prose. Cet ensemble comprend également en 1942, en 1945 et en 1946. Parmi cet ensemble, trois ouvrages forment une trilogie : (1951), (1952) et (1953) selon les indications de Beckett lui-même : .

Ces ouvrages sont parfois classés à tort par le public dans la catégorie du "Nouveau Roman". Mais seul Alain Robbe-Grillet tente de l'intégrer dans cette famille, contrairement à Claude Simon ; Jean Ricardou ne le mentionne pas en 1967 dans son ouvrage théorique "Problèmes du Nouveau Roman", et il n'est pas non plus inclut en 1971 au programme du colloque du Centre culturel international de Cerisy-la-Salle consacré à ces auteurs. Beckett propose en fait une refondation du « geste de la littérature » et rejette toute tradition littéraire. Il a toujours refusé une quelconque affiliation à un style, effectuant au contraire un travail progressif de démystification de la littérature par la mise en crise de l'original, du style et du langage : il ne se passe généralement rien dans ces romans et nouvelles, sauf la production du texte. Sa prose ne peut être rattachée à aucune tradition littéraire : rupture avec les anciens genres (« vieux styles ») et pas de disciples. C'est donc faute d'un concept plus adéquat qu'il faut bien appeler « romans » ou « nouvelles » ces curieuses narrations.

Les textes ont en commun une forme de plus en plus abstraite, mettant en œuvre des images souvent puissantes et poétiques, au service d'une réflexion informelle et réflexive sur l’œuvre en train de s'écrire et sur l'art. Beckett y pratique souvent un mélange des genres, en insérant, au milieu d'une situation ordinaire de son roman, une référence à un « discours noble » (scientifique, moral, philosophique) produisant un effet burlesque. Cet effet d'érudition, très présente dans les premiers ouvrages de cette série de proses, risquant d'éblouir mais aussi de lasser le lecteur, se réduit au profit d'une écriture plus sensible qu'intellectuelle, avec le choix du français et la prise de distance par Beckett par rapport au style de Joyce.

L’œuvre narrative est à la fois une fiction et un discours sur cette fiction, et la place du commentaire dans l'écriture de Beckett s'accroît graduellement, non seulement dans la construction du roman lui-même, mais aussi par le travail de retour sur le texte que constitue l’auto-traduction. Depuis "Murphy", puis "Watt" et "Mercier et Camier" qui marquent la transition de l'anglais vers le français avant la Trilogie en français, jusqu'à "l'Innommable", le style évolue en multipliant les répétitions et les retours, les digressions ou l'énumération obsessionnelle (l'« épuisement ») de toutes les solutions d'une situation donnée, sapant ainsi les fondements du genre romanesque.

Les aléas de la voix du narrateur constituent alors la dernière aventure romanesque, voix toujours en danger de narration, risquant de filer le coton de la fiction. Parmi les romans qui précèdent la "Trilogie", et qui forment selon Beckett lui-même une série, "Watt" représente un tournant, établissant une opposition entre d'une part le monde des hommes et des choses et d'autre part les mots. Cette opposition est ensuite approfondie dans les romans ultérieurs, où le « soulas sémantique » vient au secours de la détresse des personnages, jusqu'à devenir le sujet principal de "l'Innommable".

Les personnages de Beckett sont bavards, il racontent des histoires, le plus souvent dans le registre de l'absurde et de l'insignifiant, anecdotes que chacun raconte pour passer le temps, monologues souvent si désaccordés que ce sont des monologues parallèles. Ces histoires finissent pourtant par produire du sens, et Beckett parvient finalement à exprimer quelque chose de la vie en ne disant rien ou très peu. Raymond Federman montre comment Beckett mêle pseudo-réalité et sous-fiction, et fait converger les voix de l'auteur, du narrateur et du héros, pour dénoncer l'aspect illusoire de toute fiction, ces histoires qui prétendent passer pour la réalité.

Contrairement aux pièces de théâtre, les personnages des romans s'agitent beaucoup, mais en succédanés d'action, parfois comiques, souvent absurdes, insignifiantes. Personnages très peu personnifiés, difficiles à définir, beaucoup ont tendance à se confondre à travers une initiale M, ou inversée en W, et se ramènent finalement à une seule et même personne non identifiée objet de "l'Innommable", masques du narrateur. Ils vont par couples, illustrant un dilemme : autrui me permet de croire à mon existence ; autrui m'empêche d'être moi-même. Ces romans et nouvelles font intervenir de nombreux souvenirs d'enfance et de jeunesse et d'éléments personnels, pour finalement une écriture de soi, mais sans pour autant que l'auteur raconte l'histoire de sa vie, formant ainsi une « autographie ».

 bien qu'il ait lu de nombreux philosophes, J.-F. Louette le rappelle, cette remarque est valable aussi bien pour la prose que pour l’œuvre théâtrale, Beckett décourage toute interprétation définitive en interdisant de les prendre au sérieux. Dans les premiers ouvrages, il affiche avec une érudition bouffonne et sûre, mais sans se soucier des conventions, des références et allusions à des spéculations philosophiques diverses (Descartes, Geulincx, Vico, Schopenhauer...) par des persiflages, collages et transpositions caricaturales. Les ouvrages suivants font appel de plus en plus aux figures rhétoriques, qui deviendront habituelles, pour créer la confusion : épanorthose, humour, et syllepse de sens.
J.-F. Louette recense par exemple pour "Molloy" cinq interprétations proposées par des auteurs critiques, avant de suggérer la sienne en synthèse, selon laquelle Beckett propose un « non-savoir paisible », forme de renoncement à la sagesse, qui serait la forme ultime de la sagesse.
Ce qui pourrait échapper à la confusion et au désastre du savoir érudit, Beckett le dégrade encore par le burlesque et la trivialité, comme le souligne Adorno, et Beckett fait ainsi subir à la philosophie une « métamorphose prosaïque » donnant aux spéculations abstraites une dimension de banalité quotidienne, athéisme artistique qui rejette toute croyance en un au-delà littéraire, pour une refondation matérielle du geste de la littérature.

Le narrateur beckettien, aux prises avec les mots, n'a de cesse de ruiner sa crédibilité, contribuant ainsi au discrédit du sens, et ce narrateur problématique devient le sujet de l’œuvre, d'un récit en train de s'écrire, avec l'ambition d'une littérature entrant dans l'âge de l'abstraction pour exprimer la vie en ne disant rien, ou très peu.
Beckett n'écrit aucune fin dans son œuvre, radicalisant ainsi l'idée d'un « work in progress », mouvement de poursuite d'un ouvrage à l'autre. Cette voix, . Effet de ressassement et d'épuisement du dernier ouvrage en prose, "L'Innommable", « ton fiévreux » où il semble que la voix dise toujours la même chose, c'est-à-dire rien ou un « presque rien » dans un mouvement qui se dérobe constamment à sa propre fin, laissant ainsi indécidables, faute de sens, toutes les interprétations.

Beckett enferme ainsi dans sa dialectique le lecteur, pris dans sa quête d'un sens à donner à ces fictions, prétention à la vérité que les images employées peut susciter, mais qui lui est refusée dans le même temps, et le jeu poétique apparaît comme un échec incessant de la quête de vérité. Mais le lecteur qui se convainc alors que ces interprétations qui s'imposent à son esprit lui sont en fait interdites par le texte, et qui se rabat sur une lecture purement abstraite des romans, se heurte encore à cette injonction de Beckett : « imagination morte, imaginez », puisque l'esprit humain est ainsi fait qu'il ne peut s'empêcher de donner du sens.

Les allers-retours de Beckett entre les deux langues, anglaise et française, font naître un « ton beckettien », tiers-langage neuf incorporant en l'infléchissant le génie propre à chacune.

Dans sa recherche d'une abstraction dans la littérature, Beckett porte dans ses romans ce langage à une sorte d'apothéose non pas en tendant vers le silence comme dans ses textes ultérieurs, mais en exploitant toutes ses ressources en l'absence de choses à exprimer ou à raconter. .
Oralité feinte, par l'ordre de la phrase, ou par les répétitions, phrases nominales, commentaires méta-énonciatifs ou d'impuissance devant le langage, récits désorganisés par du spontané, ou des digressions incontrôlables.
La langue de Beckett est « sans style », minimaliste : de longues phrases parataxiques, complexes mais non subordonnées, ponctuées de virgules, à l'époque où il se libère, dans ses romans, de l'influence de Joyce pour créer une « littérature du non-mot » qu'il souhaite.

Pourtant, malgré les apparences, la langue de la prose de Beckett n'est pas simple, et chaque ouvrage oppose à la lecture une résistance en raison d'une grammaire particulière, fondée sur des règles que le lecteur doit discerner. .

L'étude des variantes de ses écrits montre que Beckett apportait un soin particulier à la ponctuation, pour imposer le rythme à la lecture et produire les effets rhétoriques ou stylistiques recherchés. Sa prose narrative fait apparaître certains écarts par rapport aux usages, habituels en français et reconnus par les grammaires normatives : présence plus fréquente de virgules en fin de phrase, plus rare en début de phrase (relevée par Karine Germoni) ; usage ou absence inhabituels de points d'exclamation (relevés par Georges Mathieu). Le lecteur français perçoit automatiquement ces écarts et identifie la motivation de l'auteur.



Beckett s'écarte généralement de l'usage majoritaire, et recommandé en français, de l'exclamation, pour des raisons métadiscursives et réflexives, surtout dans les trois romans de la "Trilogie". Après des termes tels que "ah", ou "quel", une absence de point d'exclamation donne au lecteur un sentiment de monologue intérieur, où l'intonation est généralement considérée comme absente. Cette absence produit également une exclamation à demi-étouffée, avec là encore un effet d'épanorthose. Cet usage de Beckett, comme son refus d'utiliser des points de suspension, peut aussi être de sa part un refus d'un usage pléonastique, lorsque le contexte ne permet pas l'équivoque.

Beckett utilise par contre toujours le point d'exclamation pour souligner un effet de réduplication, lorsqu'il répète des termes déjà employés dans la phrase précédente, cet usage étant assez courant dans sa prose.

Les textes en prose de la seconde période de Beckett sont ceux écrits après "Godot" et "Fin de Partie", alors qu'il compose également des œuvres de genres très divers : poèmes, pièces radiophoniques, télévisuelles ou théâtrales, scénarios. Les versions anglaises de trois de ces textes en prose ("Compagnie", "Mal vu mal dit", "Cap au pire") ont été regroupées en une seconde trilogie sous le titre "Nohow On" par ses éditeurs américain (Grove Press) et anglais (Calder), malgré l'opposition de l'auteur mais cette présentation est reprise ensuite par beaucoup de critiques. Les textes de cette période, qui rassemblent également "Comment c'est", "Soubresauts", et les "Foirades", ont cependant peu de chose en commun dans leur forme : certains sont écrits en anglais, les autres en français, dans une grande diversité formelle et avec des techniques d'écriture non comparables.

Après l'exubérance baroque de la première période, ces textes constituent une œuvre plus resserrée, de plus en plus brefs : en 1961 "Comment c'est" compte 257 pages, "Compagnie" 88 pages en 1979, et "Soubresauts" seulement 28 pages en 1989. Au-delà de cette épure formelle, une certaine unité thématique apparaît cependant. À travers un nombre limité de mots ressassés et quelques images obsédantes, on atteint . Il s'agit encore de récits qui sont en même temps des réflexions sur ces récits mêmes : .

Le thème de l'écriture se resserre autour de l'expérience du deuil et de la mélancolie . Les personnages sont souvent des vieillards. À force de chuter, ils sont réduits à l'immobilité, dénuement ultime et l'écriture fragmentaire constitue une mise en scène de cette perte. Par son degré de compression, une part de l'œuvre reste obscure au lecteur, et sa lecture devient une expérience de cette mélancolie : dans ces tragédies dépourvues d'action, .

Dans , Clov et Hamm évoquent le risque de la signifiance (serions-nous en train de signifier quelque chose ?), en présence d'un intelligence susceptible de les surprendre. Par l'épanorthose, ou plus explicitement, chaque ouvrage tourne en ridicule les tentatives de comprendre ses enjeux. Pour Beckett c'est même l'épanorthose qui semble être la « chose à dire » et Bruno Clément souligne que et invalide toute tentative herméneutique. Toutes les interprétations sont généralement possibles, y compris l'absence de sens, mais chaque interprétation devrait être accompagnée de la mention : "sauf erreur".

Beckett s'est ainsi toujours opposé à fournir une interprétation à ses œuvres, citant Proust , et n'a même jamais laissé entendre que ses ouvrages puissent faire l'objet d'interprétations philosophiques (sans pour autant affirmer explicitement le contraire). Dans une lettre à Michel Polac qui l'interrogeait en 1952 à propos de , il exprime très clairement ce refus : 

Il décourage ainsi toute démarche herméneutique, mais est encore plus explicite sur le principe même d'un symbolisme : . Tout au plus évoque-t-il en 1967, et à contre cœur, deux pistes lors d'un entretien : .

L'abstention suprême est ainsi ce . Sur l'exemple de , Martin Mégevand estime malgré tout que le projet de l’œuvre semble être de susciter chez le lecteur (au-delà de l'ironie toujours présente dans la représentation) et produisant un « sentiment de sens » qui continue de hanter le lecteur une fois refermé le livre.

Dans une étude sur , Antoinette Weber-Caflisch montre que ce texte peut être « interprété » comme une allégorie de la lecture interprétative, Beckett y évoquant ce que le lecteur peut, ou doit, attendre quant à une éventuelle interprétation de ses textes.

Dans "Le dépeupleur", Beckett met en scène, à l'intérieur d'un cylindre, un « fonctionnement », et un « personnel », et ce texte serait auto-référentiel car une partie des agents constituant le personnel, et qui s'appellent les « chercheurs », pourraient symboliser le lecteur obsédé par la quête d'un sens. Or Beckett ajoute deux précisions relatives à la quête de ces chercheurs :
et, comme le remarque finement Antoinette Weber-Caflisch, on peut dire qu'à l'intérieur du cylindre où ils restent confinés, .
Ces chercheurs seraient alors une image en abyme des lecteurs, lorsqu'ils tentent d'accéder par des échelles à des « niches » pour y loger des hypothèses de lecture, alors que le texte, abstrait, se refuse à toute interprétation. Le lecteur pourrait alors tenter de se convaincre de cette impossibilité d'interpréter le texte, mais Beckett lui refuse même cette sortie, considérant que l'esprit humain est ainsi fait qu'il ne peut s'empêcher d'interpréter : .

Comme tous les ouvrages de Beckett, "Le dépeupleur" défie la vraisemblance, n'est pas une vision réaliste du monde. Il se termine sans s'achever, donc sans épuiser les possibles de sa signification. Antoinette Weber-Caflisch propose ainsi douze interprétations possibles pour ce seul texte, qui semble même fait pour les "susciter". L'écriture de Beckett mobilise ainsi moins d'énergie pour créer le sens que pour empêcher sa détermination. Il crée .

Beckett refuse particulièrement la qualification de « théâtre de l'absurde » et Alain Badiou repousse les interprétations habituellement attachées à l’œuvre de Beckett : , avant de proposer lui-même sa propre interprétation de cette œuvre.
Dans , certains « chercheurs » sont qualifiés de « vaincus ». Alain Badiou souligne cependant, comme Antoinette Weber-Caflisch, que les chercheurs vaincus ne sont pas défaits de n'avoir pas trouvé, ou défaits par quelqu'un d'autre, mais d'avoir renoncé à leur recherche, à leur désir. Badiou "interprète" ainsi le "Dépeupleur" : pour ceux qui malgré tout, après avoir renoncé, désireraient désirer de nouveau, la défaite est cependant réversible, car si le désir s'amoindrit ou s'annule, ce choix de renoncer détruit tout, mais la "possibilité" reste indestructible car l'esprit humain ne peut se soustraire à cette injonction : "Imagination morte, imaginez".
Son œuvre est gonflée de signification, mais si la motivation originaire de Beckett a été affective, elle n'en laisse plus rien paraître. Le sens en est étroitement solidaire de ses choix formels, et s'épuise avec eux, mais son but est d'. Elle est devenue un produit intellectuel d'où sont chassés l'intuition et les battements de cœur du « vieux style », et affiche un « non-savoir ». Si l’œuvre de Beckett peut avoir non pas une signification mais une influence, c'est pourtant bien dans le domaine de l'éthique. Eoin O'Brien, médecin, exprime ainsi cette influence : .

Le bilinguisme distingue cette œuvre de toutes les autres et en constitue l'essence même. Le projet d'écrire, avant même d'écrire, prend en compte cette composante. En 1937 déjà Beckett écrivait en allemand à un destinataire germanophone et Joyce lui avait conseillé de lire Vico : . Ces questions sont présentes également chez Barthes ou Blanchot, mais Beckett y apporte une réponse originale avec le bilinguisme. Joyce se démarque de l'anglais par le lexique, alors que Beckett choisit de travailler sur la syntaxe.

En 1945, , écrit en anglais, est une œuvre académique, raffinée, et apparaît à Beckett comme une impasse littéraire. Il choisit alors de se détourner de l'anglais, coupable de maintenir l'ancien ordre littéraire, et qui représente . De plus sa véritable langue maternelle est le gaëlique, et il pourrait dire de l'anglais, comme Joyce, . De l'irlandais, il gardera sa faconde et l'humour, parfois de mauvais goût.

Doué d'une extraordinaire faculté à assimiler les secrets d'une langue, ses dons linguistiques sont remarqués dès ses années d'étudiant à Trinity College, et il n'éprouve aucune difficulté à s'exprimer en français (ainsi qu'en allemand et en italien). Déjà en 1937 il écrivait des poèmes en français, en 1939 achevait la traduction de son premier roman, , et il choisit cette langue comme moyen d'expression. Il affecte cependant en français une maladresse fondamentale, un langage voué à manquer l'essentiel, maladroit, faible, simple, familier, hésitant, mais qui se corrige et se moque de son ignorance.

Beckett répond parfois par des boutades () lorsqu'on l'interroge sur les raisons de l'écriture en une langue étrangère. Michael Edwards, autre écrivain parfaitement bilingue, remarque cependant qu'au-delà de la recherche vers l'abstraction littéraire, sa véritable motivation, il invoque également le plaisir de l'écrivain et la joie simplement de travailler le langage . Beckett se justifie finalement par la quête d'une langue « sans style » du fait de l'étrangeté qu'on éprouve à l'égard d'une langue acquise, lui permettant de se libérer des clichés et d'obtenir une certaine maladresse dans l'expression. Il évite ainsi le 

L'exercice de décalage linguistique trouve cependant sa limite avec les "Foirades", et les . Mais l'usage du français lui a permis de déstabiliser la langue maternelle, et il peut dès lors revenir parfois à l'anglais comme à une langue étrangère. Ce changement de langue n'est cependant pas un simple changement de tonalité ou de technique (l'anglais langue théâtrale, le français langue narrative...), le bilinguisme libère l'auteur des automatismes propres à chaque langue.

Pour , Beckett écrit le premier texte en anglais, puis le traduit et le publie d'abord en français avant de réviser le texte anglais. Chiara Montini met en évidence des écarts de traduction entre les deux textes, qui ne sont ni original ni copie, jouant parfois sur les mots pour valoriser un léger écart de métaphore entre les deux langues. Pour , elle met même en évidence des interactions entre les deux textes, l'un commentant l'autre par intertextualité.
Michael Edwards suggère que la meilleure compréhension est celle d'un anglophone lisant la version française, peut-être parce qu'il est en mesure lui-même de percevoir ces subtilités culturelles propres à chaque texte.

C'est donc à Beckett qu'il revient de faire les traductions de ses textes, et, s'il en laisse le soin à d'autres (Bowles, Pinget), il doit les reprendre mot à mot : . Il considérait cependant comme intraduisible du fait de la disparition des pronoms dans la version anglaise.

Ces auto-traductions constituent en fait des re-créations, et produisent deux œuvres originales (et même trois pour "Godot" que Beckett traduit également lui-même en allemand). Il travaille beaucoup sur la voix, le rythme des phrases (en particulier à travers les combinaisons et répétitions), travaille ainsi plusieurs versions de "Malone meurt", mais peut apporter des modifications plus fondamentales, par exemple dans , où il semble poursuivre l'épanorthose en passant de la version française à l'anglaise, et pour .

Enfin, Antony Cordingley souligne avec de nombreux commentateurs que les couples de personnages, si fréquents chez Beckett, prennent la forme d'allégorie de l’œuvre bilingue, , la figure de l'auto-traduction est ainsi présente en particulier dans , et .

L'humour est très présent dans la prose et le théâtre de Beckett. Depuis les premières œuvres, traduites de l'anglais ("Murphy", "Watt"...) dans lesquelles on perçoit cette tradition irlandaise, et jusqu'à "Comment c'est", l'humour est en fait omniprésent sous forme d'ironie, de jeux de mots, de plaisanteries ou de situations comiques. Il permet à Beckett d'être selon Clément Rosset, en particulier par un humour « bien irlandais », parfois de mauvais goût, empreint d'obscénité, contrastant aussi avec d'autres passages où le comique naît de l'usage d'un français pur, pédant ou archaïque.
Sa nature évolue cependant dans sa nature, d'« un rire énorme à propos du monde » dans les premiers romans à une ironie plus personnelle. Il devient progressivement moins comique, plus discret, après "Comment c'est", puis s'estompe et se raréfie après "Compagnie", enfin est absent des derniers textes comme "Soubresauts".

Il n'est cependant jamais destiné à faire rire. Il est d'abord, selon Clément Rosset, , et renforce l'originalité de l’œuvre, sans en être pour autant un élément principal.

L'humour y relève souvent de l'insolite, de détails pittoresques ou de commentaires incongrus, dans un écart créé entre les mots et les situations, et en cela participe de l'épanorthose (), autre figure de style omniprésente, en amoindrissant la dimension tragique des situations dans lesquelles sont plongés ses personnages. Rire sans joie, c'est le rire noétique, sa fonction est ainsi de montrer sans prendre parti, en refusant d'appuyer le sens, et en évitant .

Beckett explique que , et il présente dans son théâtre .
Alain Badiou estime ainsi que la vraie destination du comique de Beckett est humaniste : , et c'est bien ainsi que Beckett met en scène .

Le comique joue alors un rôle central pour éviter l'abstraction philosophique et l'esthétique de la sensibilité et préserver le tragique de l'écueil de la sentimentalité : le seul moyen de se garder du ridicule est de l'assumer entièrement, et Beckett parvient à préserver l'émotion tout en faisant échec au pathétique grâce à l'humour (associé à une hypertrophie de la rationalité). Il prend simplement acte du malheur, en le représentant, parfois en l'exagérant, mais sans l'analyser ni le contester.

Ionesco croit retrouver chez Beckett « le sentiment d'une fissure profonde entre Dieu et l'homme » que présentait déjà Synge, et estime que en regrettant cependant que l'ironie n'y soit pas encore plus présente dans « la plainte de l'homme contre Dieu ». Cette ironie, Beckett l'applique également à lui-même s'observant dans l'acte d'écrire, dimension réflexive qui est également présente dans toute l’œuvre.
Samuel Beckett a eu une activité de traduction constante et importante, et Christine Lombez rappelle qu'il est issu d'une nation irlandaise réellement bilingue, avec le gaëlique et l'anglais.

Si des motivations prosaïques sont mises en avant, cette activité fait cependant partie intégrante de son œuvre. Traduire d'autres auteurs est également , cette activité a un impact sur sa conception de la littérature, et ces influences (en particulier celle d'Apollinaire, sur sa poésie) fournissent des éléments permettant de mieux comprendre son œuvre déroutante.

De l'anglais vers le français, Beckett participe surtout, en collaboration avec Alfred Péron, à une traduction d'Anna Livia Plurabelle que Joyce ne retiendra finalement pas. Depuis le français, il réalise l'auto-traduction d'une grande partie de son œuvre, traduit des poètes modernes (Rimbaud, Apollinaire, Éluard) qu'il a , des surréalistes (Breton, Tzara, Crevel) sans pour autant se sentir proche de ce mouvement, mais aussi des œuvres classiques (Chamfort). Il envisage également de traduire Sade qui dont il admire le style, y renonce par crainte de l'impact sur sa réputation littéraire, mais reste cependant intéressé par cet auteur dont il traduit plus tard quelques lettres qui seront publiées par Gilbert Lely et qu'il trouve « extrêmement belles ».

Il réalise également des traductions vers l'anglais d'auteurs italiens (Montale), allemands (Rilke) et espagnols (anthologie mexicaine réunie par Octavio Paz)

Samuel Beckett dispose d'une mémoire visuelle stupéfiante, gardant la mémoire de chaque exposition et des tableaux, leur composition, leur couleur et leur impact. Cette disposition naturelle favorise la prise en compte constante de la peinture dans sa conception littéraire et dans ses œuvres. Il entretient, tout au long de sa vie, des relations profondes et durables avec le monde des arts plastiques. Ses écrits critiques sur la peinture, éclairent son œuvre littéraire.

Avant la guerre, il court les musées et les galeries à Dublin, pendant ses voyages en Allemagne qu'il décrit comme un , et à Paris. Thomas MacGreevy puis Georges Duthuit l'initient à l'histoire de l'art. Il admire la peinture allemande des années 1920 et 1930, s'intéresse surtout à la peinture moderne et d'avant-garde, et rejette le courant surréaliste. Sa culture comprend une variété de genres, la peinture à l'huile traditionnelle, la sculpture, la gravure, les collages et les dessins de la tapisserie moderne.

Au cours de cette exploration de la peinture, il se lie d'amitié avec de nombreux artistes, leur achète des toiles (souvent pour les aider financièrement), publie des articles critiques et il restera en relation avec eux jusqu'à la fin : Jack Butler Yeats de ses années d'étudiant à Dublin, Bram et Geer van Velde avant la guerre, Henri Hayden compagnon d'exil en 1943, Giacometti, Marcel Duchamp, Avigdor Arikha. Il est en relation également avec des collectionneurs et galeristes : Aimé Maeght, Peggy Guggenheim avec qui il a une relation amoureuse et qui lui présente Suzanne, sa future femme, Thomas McGreevy, Georges Duthuit. Geer et Bram van Velde font la rencontre de Beckett en 1937 et en 1990, Elisabeth, la veuve de Geer, se souvient : .

La peinture réalisait des recherches formelles considérables depuis les années 1930, et comme d'autres écrivains de cette époque (Apollinaire, Gertrude Stein et ses logogrammes...), Beckett travaille à la remise en cause des présupposés littéraires en s'inspirant des travaux des peintres .

Il écrit des articles critiques dans la revue "transition" dès 1929 avec quelques textes, puis à partir de 1947 par des traductions d'études sur la peinture et participe aux discussions de groupes d'artistes réunis autour de Georges Duthuit qui dirige cette revue. Il traduit pour cette revue des textes de René Char sur Gustave Courbet, de Paul Eluard sur Picasso, de Francis Ponge sur Braque, mais ne parvient pas à traduire les "Phares" de Baudelaire, qui le « paralysent ».

Ses rares essais critiques sont pratiquement, avec sa correspondance, les seuls témoignages dont nous disposions sur ses conceptions artistiques.

C'est avec la peinture de Bram van Velde que Beckett éprouve le plus d'affinités pour ses propres recherches littéraires, il y voit . Cette peinture de Bram van Velde rompt avec les évidences de la représentation, et les problèmes qu'elle soulève correspondent aux questions littéraires que Beckett se pose lui-même : . Jean Frémon lui ayant proposé en 1974 de faire illustrer par une lithographie de Bram l'un de ses textes, Beckett choisit le correspondant, selon Frémon, à la personnalité du peintre.

En 1946, Beckett publie dans une revue d'art un texte (ensuite publié sous le titre ), consacré à l’œuvre des frères van Velde : c'est un questionnement profond sur la représentation et l'origine de l'image. Pour Beckett, Bram représente l'espoir d'un grand bouleversement général de la peinture, révélant la seule vérité, c'est-à-dire , et Beckett condamne l'image et le .

En 1955, son article sur Henri Hayden ne parle plus de l’œuvre : il témoigne seulement d'une amitié, et correspond à une renonciation, à ses exigences éthiques. Il chemine vers l'iconoclasme, faisant écho au "logoclasme" qu'il appelait de ses vœux dès 1937. Cette évolution () se produit dans le cadre de discussions entre Beckett et Duthuit, que les deux hommes ont à propos surtout de la peinture de Bram van Velde. Il tente de convaincre Bram de ce qui est devenu clair pour lui, , réflexion à dessein ironique et paradoxale mais qui paralyse son ami en lui faisant penser que peindre est un acte impossible.

Beckett prend conscience, à partir de 1949, de l'influence qu'il a pu avoir sur l'art de Bram, contaminant sa peinture avec ses propres catégories littéraires, et lui faisant porter la charge fantasmatique d'une peinture à côté de la tradition occidentale, entraînant le peintre dans une dérive que sa vulnérabilité psychique ne lui permettait pas d'assumer. Il choisit de ne plus écrire sur la peinture.

Autre ami proche de Beckett, Giacometti , parle lui aussi de son propre travail toujours en termes d'échec à saisir sa vision, à représenter une figure, poursuivant l'inaccessible. Bram, Giacometti et Beckett ont en commun le mystère de la représentation et de la présence dans l'image, l'infatigable recommencement et l'économie de moyens, une probité à toute épreuve et le profond dédain de la carrière.

Au-delà des réflexions sur les conceptions esthétiques, les influences réciproques et les échanges entre Beckett et les peintres sont nombreux dans la réalisation de son œuvre. Ses premiers romans contiennent de nombreuses allusions à la peinture. Ainsi l'image centrale de lui est inspirée par "La décollation de Saint Jean le Baptiste", du Caravage et la conception visuelle de par un tableau de Caspar David Friedrich, "Deux hommes contemplant la lune", il dispose ses comédiens en conséquence, et en 1961 demande à Giacometti d'en dessiner l'arbre. Par contre, il repousse la proposition de Nicolas de Stael d'un décor réalisé par un peintre, ce qui serait de l'esthétisme, un simple « agrément » qui détournerait l'attention du spectateur : Il accepte cependant des illustrations non figuratives pour des éditions de bibliophilie de ses œuvres non théâtrales. Ainsi, en 1972, il demande ainsi à Arikha d'illustrer une édition des (, puis du "Dépeupleur", et Sean Scully intitule l'un de ses tableaux .

Selon Lois Oppenheim, le lien avec l'expressionnisme allemand est évident, en raison des personnages de Beckett qui appréciait par exemple Kirchner, et Nolde, dont il avait pu voir les œuvres dans les musées en Allemagne avant la guerre. Si Beckett nie, avec une fausse modestie, une inspiration consciemment expressionniste pour son théâtre, c'est bien pour repousser toute tentative herméneutique : . Dans la même lettre, il rejette plus nettement le symbolisme : 

Un lien avec le cubisme peut être également établi en raison d'une géométrisation présente dans les mises en scène et les textes , mais aussi par les mentions à Braque dans sa correspondance.

Et l'accent de Bram van Velde (Bram, encore), son vocabulaire, se retrouvent dans le "Texte pour rien XIII" et dans : 

La musique est présente au quotidien pour Beckett qui possédait une solide formation musicale. Il écoute surtout Mozart, Beethoven, les quatuors de Haydn et Schubert. Très bon pianiste, érudit, amateur de concerts, il connaît les classiques et les compositeurs contemporains, et fréquente le milieu musical avec Suzanne, sa femme, pianiste professionnelle. Ludovic Janvier estime que sa vie était « adossée » à la musique, obsédé par la voix et n'aimant rien tant, métaphoriquement, que la musique dans la langue, par exemple chez Racine ou Apollinaire.

Plus encore que la peinture, la musique accroît l'écart entre le sensible et l'intelligible et s'éloigne encore plus du réel qu'elle ne peut, contrairement au texte et à la peinture, représenter. Elle correspond ainsi à la réflexion de Beckett sur le langage et la structure du récit et lui fournit des modèles pour une abstraction du texte. Par l'usage de formes utilisant la répétition (reprises, variations, réexposition d'un thème, sérialisme...), la musique « dé-linéarise » le récit. Beckett y trouve des modèles pour donner une « narrativité musicale » au texte, une au théâtre, ou rendre possible, par une syntaxe dominée par les modèles musicaux, la suspension du narratif.

James Knowlson trouve des analogies entre la méthode de composition dramatique de Beckett et la composition musicale, que Beckett lui-même avait constatées : . Cette influence est particulièrement sensible dans les derniers textes de Beckett () tels que ou "(texte encadré)", échappant au récit linéaire, donnant forme au murmure, vers une « littérature du non-mot », faisant entendre l'« insondable gouffre de silence » qui est au fond de tout : .

La recherche littéraire de Beckett vers l'abstraction a produit de nombreux textes dont se sont ensuite inspirés des compositeurs contemporains, et certains de ces textes ( ou par exemple) sont aussi ultra-radicaux et modernistes que le fut le système de composition musicale dodécaphonique de l'École de Vienne. Ainsi Dutilleux, son neveu John Beckett, Heinz Holliger pour et , Philip Glass pour et , Luciano Berio pour l'. Morton Feldman compose à la demande de Beckett, pour "(texte encadré)" une pièce musicale pour soprano solo, dans un registre aigu, égrainant les vers du poème, à peine intelligibles, fragments d'un monde perdu.

L'effort de recherche de Beckett se poursuit avec sa collaboration à la composition d'un opéra par Marcel Mihalovici, "Krapp" d'après , pour lequel il envisage, avant d'y renoncer, l'idée d'. Il reprend pourtant cette idée avec succès dans , selon l'interprète de la version anglaise, Billie Whitelaw : Marcel Mihalovici rend un hommage appuyé au travail musical de Beckett dans sa coaboration pour : 
Cependant Beckett repousse toute proposition de musique de scène pour ses pièces et précise pour "Godot" que ce serait , admettant par contre l'idée d'une musique , éventuellement "inspirée" par la pièce : . De la même manière, il désapprouve violemment "Endgame" mis en musique par Philip Glass, lors de sa représentation à l'American Repertory Theatre de Cambridge, Massachusetts, sous la direction de JoAnne Akalaitis. Toutefois, il finit par accepter, de la musique composée pour "Company", quatre pièces courtes et intimes pour quatuor à cordes qui sont jouées entre les phases dramatiques. Cette dernière composition était originellement vue par Philip Glass comme une musique de fond. Par la suite, "Company" fut publié en tant que "Quatuor à cordes " de Glass.

Le compositeur français Pascal Dusapin écrit, en 1994, un concerto pour trombone intitulé "Watt", inspiré du roman de Beckett. En tête de l'ouvrage, une citation du roman fait référence au caractère indicible, innommable des choses du monde, et des états dans lesquels se trouve le narrateur. Le musicologue Harry Halbreich parle, à propos de ce concerto, d'un « voyage autistique destiné à s'achever dans le désespoir complet ».

La musique est présente sous différentes formes dans de nombreuses œuvres de Beckett : le reprend des thèmes d'une œuvre de Beethoven en . Dans et , la musique intervient comme un personnage. Les grandes pièces ("Godot", "Oh les beaux jours", "Fin de partie") contiennent des chansons.

Beckett est né quelques années seulement après le cinéma. Il découvre le cinéma avec les films burlesques américains, comme Laurel et Hardy, Chaplin ou Buster Keaton, qui ont pu lui inspirer certaines scènes des personnages de ses pièces, par exemple . En 1936, il envisage de se former à l'art cinématographique, lit des livres sur ces techniques et écrit même à Eisenstein en lui demandant de le prendre en stage. Mais il craint déjà, après la sortie d'un premier film Disney en Technicolor, la .

Ce n'est cependant qu'en 1964 qu'il sera en mesure de travailler pour un film, sur le tournage de avec Buster Keaton dont il fut, aux côtés de Alan Schneider, le véritable réalisateur comme le reconnaît celui-ci : . Pour ce film unique, Beckett utilise le noir et blanc (la couleur risquant de détourner l'attention du spectateur), et les gros plans pour un film « bidimensionnel ». Le film est pratiquement muet, le seul mot audible est « Ssssh ! » demandant le silence. Il souhaite ainsi proposer une forme .

Il écrit et réalise des pièces pour la télévision, où , cette forme trouvant son apogée dans , « drame chorégraphié corpusculaire », que Deleuze appelle : comme dans le cinéma de Marguerite Duras, 

Beckett accepte une transposition de au cinéma, mais le résultat s'avère peu satisfaisant. Par contre il refuse catégoriquement les offres qui lui sont faites pour une adaptation de ses « grandes » pièces de théâtre au cinéma

Un projet (scénario et croquis) de dessin animé est proposé en 1960 par William Scott (Jay Ward Productions, Hollywood) à partir de Acte sans Paroles I. Beckett, qui aime beaucoup le dessin animé, se déclare très intéressé par ce projet dont le scénario suit fidèlement le texte. Il trouve l'idée charmante et l'accepte immédiatement, mais le film ne fut jamais réalisé.

Le terme d"influences" est peut-être inadéquat s'agissant de Beckett, alors que sa recherche esthétique est celle d'un ailleurs, et que l’œuvre est pleine de excluant toute filiation.





Bilingue et auto-traducteur, Beckett a produit de fait deux œuvres originales, donnant lieu à deux traditions critiques. Dans "Watt" il met en scène Sam réorganisant les mots de Watt, épreuve répétée par les traductions, et Chiara Montini montre que Beckett démystifie ainsi la notion d"original" qui se présente finalement comme un brouillon, la traduction devenant elle-même une œuvre originale de l'auteur. Le bilinguisme problématise et enrichit toute analyse lexicale par la différence des deux corpus lexicaux utilisés.

Le bilinguisme est donc une caractéristique constitutive, essentielle, de son œuvre, écrivant et traduisant en anglais et en français. Pour chacun de ses textes, le choix de la langue originale et, lorsqu'il ne traduisait pas lui-même, du traducteur, sont significatifs.

Les informations reportées dans le tableau et la bibliographie des œuvres de Beckett proviennent de la biographie par Knowlson, du Cahier de l'Herne, de la bibliographie réunie par Bruno Clément, et du catalogue des Éditions de Minuit. Pour la période de 1945 à 1950, la plus créatrice, les dates et la chronologie sont cependant moins fiables, cette époque étant, de l'aveu de Beckett, une époque confuse et chaotique.

Le premier livre de Samuel Beckett à être publié en français, "Murphy", a été publié par les éditions Bordas en 1947. Ensuite, les œuvres de Samuel Beckett sont toutes publiées aux Éditions de Minuit. Elles sont publiées en anglais chez Faber & Faber (théâtre) ou chez (romans) et chez Grove Press aux États-Unis.









</doc>
<doc id="2921" url="https://fr.wikipedia.org/wiki?curid=2921" title="San Francisco">
San Francisco

San Francisco (prononcé en anglais ), officiellement ', est une ville américaine et un comté et l'État de Californie. Elle est située à l'extrémité nord de la péninsule de San Francisco, entre l'océan Pacifique à l'ouest et la baie de San Francisco à l'est. Son nom est couramment abrégé en SF et la ville est surnommée "'.

Fondée en 1776 par des Espagnols au sein de la Viceroyauté de la Nouvelle-Espagne, la ville, nommée en l'honneur de San Francisco de Asís, prend son essor lors de la ruée vers l'or et son prolongement, l'embellissement de San Francisco par les millionnaires du Nevada. Puis, elle devient le berceau du jeans avec la fondation de Levi Strauss & Co. Les années 1950 voient la naissance de la Beat Generation. À partir de la deuxième partie du , l'industrie des hautes technologies se développe dans la région de la baie. Aujourd'hui San Francisco est la ville la plus densément peuplée des États-Unis après New York. La municipalité-comté de San Francisco compte dans ses limites administratives et plus de de personnes vivent dans l'aire métropolitaine de La Baie, la quatrième métropole des États-Unis par sa population. La partie sud de cette dernière est occupée par la municipalité de San José et la Silicon Valley, premier pôle de hautes technologies des États-Unis qui accueille un nombre important d'entreprises de technologie de pointe de renommée mondiale telles que Cisco, Apple, Tesla Motors, Hewlett-Packard, Google, Intel ou encore Facebook. Dans le domaine universitaire, elle accueille les prestigieuses université Stanford et université de Californie à Berkeley. San Francisco est également le siège de la Wikimedia Foundation dont fait partie le projet Wikipédia. Au nord s'étendent la Napa Valley et la Sonoma Valley, renommées pour leur viticulture. San Francisco fait partie des villes progressistes dans le domaine de l'écologie et du développement durable.

Troisième destination touristique des États-Unis, la ville est célèbre pour le pont du Golden Gate, l'île et ancienne prison d'Alcatraz, Fisherman's Wharf, la Transamerica Pyramid, la Coit Tower, ses maisons victoriennes, ses "" et ses nombreuses collines découpées de rues en pente. Haut lieu de la contre-culture, ville de tolérance et d'émancipation des minorités, San Francisco est également connue pour son Chinatown, ses quartiers homosexuels et hippie. Elle représente un foyer culturel et économique majeur aux États-Unis et accueille chaque année plusieurs événements d'ampleur mondiale mais vibre également au rythme des festivités animées par les différentes communautés locales. Elle se revendique comme une ville sanctuaire pour les sans papiers depuis 1989. Sur le plan sportif, les 49ers au football américain, les Giants au baseball et les Warriors au basket-ball sont les équipes phares de la ville.

Les plus anciennes traces d'occupation humaine sur le territoire de la ville actuelle remontent à environ . Les premiers habitants connus de la région de la baie de San Francisco sont les Amérindiens Ohlones (ou Costanoan), terme indien signifiant « le peuple de l'ouest ». La région était également peuplée des tribus Pomo, Wintun, Yokut et Miwoks.

Le navigateur anglais Francis Drake longe la côte californienne en 1579, mais il n'entre pas dans la baie de San Francisco. Les Espagnols sont les premiers Européens à explorer et à coloniser la région, en faisant un établissement renforçant leur domination sur l'océan Pacifique, le « lac espagnol », avec leurs possessions philippines et américaines notamment.

San Francisco représentait ainsi l’extrémité septentrionale d'un chapelet plus ou moins continu d'implantations militaires et religieuses destinées à assurer physiquement la souveraineté espagnole et peut-être française sur ce vaste territoire. L'expédition de don Gaspar de Portolà arrive le , dans la baie de San Francisco.

Le , les Espagnols fondent un "presidio" et le 9 octobre la mission nouvellement construite (mission Dolores) est dédiée au patron des missionnaires : "San Francisco de Asís" (saint François d'Assise). Comme le reste de la Californie, San Francisco passe sous la souveraineté mexicaine en 1821. Ce n'est cependant qu'en 1836 que sont installées les premières habitations d'un village sur le bord de la baie, en un endroit appelé "Yerba Buena" (« la bonne herbe »), par référence à la menthe qui pousse sur les collines environnantes. La ville fut ensuite prise par les Américains en 1846 et perdue en 1848 lorsqu'ils gagnèrent la guerre faite au Mexique pour agrandir leur territoire. Cette année-là le Mexique perdit également toute la Californie ainsi que les États actuels de l'Arizona, du Colorado, du Nevada, du Nouveau-Mexique et de l'Utah. Yerba Buena devient alors San Francisco.

La ville ne prend son essor qu'avec la ruée vers l'or de 1848-1849, accueillant les émigrants à la recherche du précieux minerai. Elle est le terminus du premier chemin de fer transcontinental. Les aventuriers du monde entier sont attirés par ce pays de l'or où l'on arrive par la porte dorée (""). Quelques années plus tard, la découverte de gisements d'argent dans la Sierra Nevada accélère le développement de l'agglomération. De 1847 à 1850, la ville passe de quelques centaines d'habitants à plus de : elle devient alors, la plus grande agglomération de la côte ouest.

En 1847, Levi Strauss s'installe à San Francisco et crée les premiers jeans qui remportent un grand succès auprès des prospecteurs et des chercheurs d'or. Pendant la guerre, les usines Levi Strauss & Co. fournissent l'armée américaine en jeans.

San Francisco compte dès 1862. La ville se couvre de bâtiments modernes, des sociétés en pleine expansion viennent s'y implanter. Les actions de centaines de compagnies minières du Comstock Lode s'échangent à la Bourse de San Francisco, produisant plusieurs millionnaires qui animent la vie politique et culturelle : James Graham Fair, John William Mackay, James C. Flood et leur Banque du Nevada, Adolph Sutro, William Sharon et sa Bank of California ou encore John P. Jones et Alvinza Hayward. Ils ont fait construire le ', le Théâtre de Californie, le ', le ' et le palais du '.

C'est également dans la deuxième moitié du que la diaspora chinoise commence à s'installer à San Francisco ; ils surnommaient alors la Californie la « montagne dorée ». Les émigrés fuyaient les conséquences des guerres de l'opium et ont prospéré dans la restauration, le commerce, la pêche et la blanchisserie : San Francisco était alors une ville d'hommes (mineurs, aventuriers) qui avait besoin de laveries. Les Chinois constituèrent des sociétés secrètes pour régler leurs différends. Le quartier chinois n'avait pas bonne réputation. Dans certains bars, on avait aménagé une porte étroite pour retarder l'avance des policiers. Au début du , des Juifs issus de la bourgeoisie allemande s'installent à San Francisco.

À partir de 1896, San Francisco devient le principal port de départ pour la ruée vers l'or du Klondike, immortalisée par Jack London dans L'Appel de la forêt. San Francisco fut également la ville de Joshua Norton, empereur autoproclamé des États-Unis.

En 1906, elle subit un tremblement de terre et une grande partie de la ville est détruite par un gigantesque incendie déclenché à la suite du séisme. Il fallut trois jours pour circonscrire le sinistre. La ville fut ensuite rapidement reconstruite, notamment grâce à l'afflux d'une main-d'œuvre étrangère venue d'Europe et d'Asie.

En 1915, l'Exposition internationale de San Francisco attire 19 millions de visiteurs. Pendant la Grande Dépression, la ville est affectée par l'agitation sociale : la devint générale le à la suite du « Jeudi sanglant » (deux dockers tués par les policiers) le 5 juillet mais finit par échouer. Les travaux du Golden Gate Bridge débutent le , sous les auspices du ' (PWA) puis à partir de 1935 du ' (WPA), programmes lancés à l’initiative du président Franklin Delano Roosevelt dans le cadre de sa politique de grands travaux. Il s’agissait de créer des emplois dans les travaux publics, payés par les fonds fédéraux afin de réduire le chômage. L'Exposition internationale du Golden Gate a lieu en 1939 et 1940 sur l'île artificielle de fraîchement construite. La Seconde Guerre mondiale voit le développement des industries militaires en Californie : le port de San Francisco sert de point de départ des troupes pour les batailles du Pacifique contre l'Empire japonais.

Après la Seconde Guerre mondiale, une première conférence de la paix se réunit à San Francisco. Elle aboutit le à la signature de la charte de l'ONU par cinquante pays. En 1951, la deuxième « Conférence de la paix » s'y est tenue, et a débouché sur le traité de San Francisco. Ce traité entre en application le et met fin à la période d'occupation (1945-1952 au Japon). La révolution industrielle de la deuxième moitié du transforme l'économie de la région : le développement de la , au sud de la ville, donne une image dynamique et moderne de cette région de la Californie. La ville constitue la « dernière frontière », la cité américaine la plus à l'ouest.

San Francisco est, de par sa tradition de tolérance, souvent à l'avant-garde de l'émancipation des minorités et des droits civiques. Le programme « "" », du mouvement révolutionnaire afro-américain , est parti de San Francisco. La ville fut également dans les années 1960 un foyer important de la contre-culture hippie, du psychédélisme et du . Elle fut le berceau du mouvement Beatnik. San Francisco est également devenue une ville emblématique de la cause homosexuelle, notamment dans les années 1970, avec l'activisme politique d'Harvey Milk, assassiné en 1978 avec le maire George Moscone. Depuis les années 1980, la ville est à la pointe dans le domaine de la mutation écologique et de la lutte contre le changement climatique. En 1989, la ville adopte la "City of Refuge ordinance" dans laquelle elle refuse de collaborer avec les autorités fédérales sur le plan de la lutte contre les étrangers en situation irrégulière. Cette ordonnance fait d'elle une ville sanctuaire pour les sans papiers. Aujourd'hui, la concentration d'entreprises de dimension internationale contribue à attirer des « cerveaux » du monde entier.

San Francisco se trouve sur la côte Ouest des États-Unis dans l'État de Californie. La ville se situe sur l'extrémité nord de la péninsule de San Francisco. Elle est entourée à l’est par les eaux de la baie de San Francisco, au nord par le détroit du et à l’ouest par l’océan Pacifique. Plusieurs ponts relient la ville aux rives de la baie : les plus célèbres sont le pont du Golden Gate (au nord-ouest) et le , qui relie San Francisco à Oakland vers l’est.

Plusieurs îles appartiennent à la commune de San Francisco (île d'Alcatraz : , ), de même que de petits secteurs d' et , près du pont Richmond-San Rafael. Les îles Farallon, situées dans l'océan Pacifique à au nord-ouest de la côte, dépendent administrativement de la municipalité, mais ne sont pas habitées et servent de réserve naturelle.

La commune de San Francisco s’inscrit grossièrement dans un carré d’environ de côté, mais elle est en fait légèrement plus petite. D'après le Bureau du recensement américain, la ville s'étend sur , dont de terre et de surface aquatique. Les eaux occupent donc 79,869 % de la surface totale.

San Francisco est célèbre pour les plus de 50 collines situées à l'intérieur des limites de la commune. Une « colline » san-franciscaine est définie par une altitude de plus de . Certaines d'entre elles correspondent à un quartier, comme , , ou ; d'autres sont des jardins publics ou des parcs comme ceux de central park (à new york) Twin Peaks, Mont Sutro, Mont Davidson et Buena Vista.

Une série de collines moins densément peuplées couvrent le centre géographique de la ville. Le Mont Sutro domine cette zone surmontée de la , une tour de transmission rouge et blanche imposante bien connue des San-Franciscains. À proximité se trouvent les , deux collines tout aussi populaires, formant l'un des plus hauts points de la ville. À environ un kilomètre et demi au sud de là se dresse le point culminant de San Francisco, Mont Davidson, à d'altitude. Une croix de de haut y fut dressée en 1934.

San Francisco se trouve à proximité des failles de San Andreas, qui traverse la « région de La Baie » du nord au sud, et de Hayward, ce qui explique la fréquence des séismes dans la région. Les deux principaux tremblements de terre ayant touché la ville sont ceux de 1906 et de 1989 (7,1 sur l'échelle ouverte de Richter). Les normes parasismiques ont limité les dégâts et le nombre des victimes de ce dernier.

La péninsule de San Francisco est le résultat de l'affrontement de deux plaques tectoniques : la plaque pacifique et la plaque nord-américaine. Les roches qui composent les fondations géologiques de la ville se sont formées à la marge d'une zone de subduction entre 200 millions et 100 millions d'années avant notre ère. Pendant cette période, les roches du manteau ont été métamorphisées et ont subi d'importantes transformations physiques. Ce substrat rocheux a ensuite été recouvert par des sédiments lorsque le niveau de la mer s'est élevé. La géologie de San Francisco est complexe. Les terrains superficiels sont dominés par des couches sédimentaires, sauf au centre : ils se sont formés il y a quelques milliers d'années et recouvrent un substrat rocheux plus profond. Au nord et le long de la côte Pacifique se trouvent des sables du quaternaire. Le quartier de Mission District est construit sur des alluvions datant du pléistocène. Les quartiers sud-ouest reposent sur des couches de boue de la fin de l'holocène.

Les collines du centre (Twin Peaks, Forest Hill, Diamond Heights) sont composées de roches de natures diverses : le complexe franciscain de silex ("") a été formé à la fin du crétacé ou au début du jurassique. Mais on trouve également des roches volcaniques et métamorphiques datant de la même époque. Les secteurs de et comprennent des couches de serpentinite, une roche métamorphique du Jurassique.

Des quartiers entiers de la ville reposent sur des remblais (de type polder, composés de boue, sable et des débris de précédents tremblements de terre) et d'autres terres créées artificiellement le long de la baie lorsque l'espace vint à manquer. Les anciens docks furent ainsi comblés et l'on trouve dans les sous-sols du Financial District plusieurs dizaines d'épaves des bateaux utilisés par les "forty-niners" pour rallier la ville lors de la ruée vers l'or.

Ce type de terrain devient extrêmement instable lors d'un séisme, et la liquéfaction qui en résulte cause des dégâts considérables aux structures qui y sont bâties, comme on put le constater dans le quartier de la Marina lors du séisme de Loma Prieta en 1989. est certainement l'exemple le plus spectaculaire de quartier construit sur de tels remblais. Bâtie à partir de matériaux directement creusés dans la baie et résultant du perçage du tunnel de lors de la construction du , cette île fut le site de l'Exposition internationale du Golden Gate en 1939 et 1940. Elle devait également accueillir l'aéroport municipal de San Francisco, mais devint une base navale au début de la Seconde Guerre mondiale. En 1997, fut rendue à San Francisco, de laquelle elle offre une vue unique sur la ville.

Le climat de San Francisco est de type méditerranéen frais, avec des caractères propres et bien marqués : les spécialistes le rangent dans le type californien. La classification de Köppen le classe comme un climat méditerranéen avec été tempéré, la température du mois le plus chaud étant de . La moyenne des précipitations annuelles s'élève à , dont 85 % tombent de novembre à mars. Ce total des pluies et la période de sécheresse estivale font qu'il est considéré comme un climat méditerranéen. L'amplitude thermique est modérée et la moyenne annuelle des températures plutôt tiède. Les températures maximales moyennes oscillent l'été entre 15 à , et l'hiver entre 10 et pendant la journée, mais peuvent tomber à la nuit. Le climat de San Francisco est très comparable à celui que l'on trouve sur la côte atlantique du Maroc ou encore au centre du Chili.

Les hivers sont pluvieux et doux. Le gel est quasi inexistant et la neige reste un phénomène peu fréquent. En janvier, les températures matinales minimales avoisinent , et l'après-midi . Les étés sont généralement brumeux mais secs et la canicule est extrêmement rare. En septembre, pendant l'été indien de San Francisco, la température minimale moyenne est de , et les maximales tournent autour de . Septembre et octobre sont les mois les plus chauds de l'année.

La situation de San Francisco explique l'originalité de son climat : la ville se trouve à la même latitude que Palerme en Sicile, mais sa position sur le littoral du Pacifique lui donne des caractéristiques particulières. Le courant froid de Californie apporte des perturbations chargées de pluies en hiver. Ainsi, les eaux de l'océan Pacifique, qui bordent la côte occidentale de la ville, sont rafraîchies tout au long de l'année, et avoisinent . Les surfeurs se protègent toute l'année avec des combinaisons, même l'été, où l'eau est à sa surface souvent encore plus fraîche que l'hiver en raison du courant maritime sud-ouest qui l'été provoque la remontée d'eaux froides à la surface. Ensuite, l'association du courant froid et de la chaleur de la Californie intérieure est responsable des nappes de brouillard caractéristiques qui se forment dans certains quartiers de la ville et au-dessus des eaux de la Baie pendant l'été et au début de l'automne. Ces brumes peuvent couvrir l'agglomération jusqu’à à l'intérieur des terres. De ce fait, les températures estivales à San Francisco sont généralement beaucoup plus basses que dans d'autres endroits de la Californie, notamment la vallée centrale, où la chaleur peut atteindre . Le brouillard est moins prononcé à la fin du printemps et pendant les mois de septembre et octobre, qui sont considérés comme les véritables mois d'été à San Francisco. Il dure une centaine de jours dans l'année. Cette fraîcheur estivale est sans doute à l'origine d'une légende urbaine selon laquelle Mark Twain aurait écrit "".

La combinaison de l'eau froide océanique et des chaleurs intenses de l'intérieur de la Californie est à l'origine du brouillard caractéristique qui peut couvrir la moitié occidentale de la ville pendant parfois toute la journée en été et au début de l'automne. Le brouillard est moins prononcé dans les quartiers à l'est, à la fin du printemps, et pendant les mois de septembre et d'octobre.

Le relief prononcé et les influences maritimes sont à l'origine d'une multitude de micro-climats qui coexistent au sein même de la ville, et sont généralement plus marqués l'été que l'hiver. Les collines les plus hautes, dans le centre géographique de la ville, sont responsables pour une variation de l'ordre de 20 % dans les précipitations annuelles enregistrées dans différents endroits de la ville. Les collines protègent les quartiers situés sur leur côte est des conditions brumeuses et fraiches qui affectent les quartiers du Sunset ou de Richmond. À l'inverse, les quartiers les plus ensoleillés sont SoMa, Bayview, Mission et Noe Valley.

San Francisco possède un Japantown et un Chinatown, et tous deux sont parmi les quartiers de ce type les plus vieux des États-Unis. La ville comprend aussi une population vietnamienne importante dans le quartier du Tenderloin et une concentration de Philippins dans les quartiers de Crocker-Amazon et South of Market (SOMA), une communauté italo-américaine historique dans North Beach, un modeste quartier français parfois appelé "Little France" dans le Financial District, et des communautés d'origine irlandaises, chinoises et russes dans le Richmond District.

Le quartier de Mission est le plus ancien quartier de la ville — il a été construit autour de la Mission Dolores, fondée en 1776 par les missionnaires espagnols. La communauté hispanique y est prédominante, mais l'endroit est en cours de gentrification. Russian Hill est un quartier résidentiel connu notamment pour le tronçon sinueux de Lombard Street qui le traverse. Haight-Ashbury a été l'épicentre de la contre-culture hippie des années 1960, et le quartier du Castro est réputé pour sa forte concentration d'homosexuels. Il existe aussi d'autres quartiers où la communauté gay et lesbienne est particulièrement présente, notamment Noe Valley, Diamond Heights, Bernal Heights, Potrero Hill, Haight-Ashbury, Hayes Valley, Twin Peaks et SOMA.

San Francisco est célèbre pour ses nombreuses demeures victoriennes, dont les plus connues sont certainement l'alignement des "painted ladies" d'Alamo Square. Les "", les fameux tramways à traction par câble, mis en service en 1873, sont l'un des symboles de la ville et il est toujours possible de les emprunter pour monter ou descendre Nob Hill ou Russian Hill. Coit Tower, qui trône sur Telegraph Hill, est également un monument instantanément reconnaissable de San Francisco.

L'expansion démographique actuelle se concentre dans l'est et le sud de la ville. Le quartier de SOMA a été l'un des épicentres du "dotcom boom" de la fin des années 1990, et subit actuellement un renouveau immobilier et économique. La commission d'urbanisme de la ville a proposé une transformation du quartier autour du terminal de bus situé dans SOMA, qui consisterait notamment en un trio de gratte-ciel dont le plus haut culminerait à . Le quartier récent de Mission Bay, à l'extrémité orientale de SOMA, est en cours de réaménagement, et compte le stade de baseball AT&T Park et une annexe de l'école médicale de l'Université de Californie à San Francisco.

Les quartiers de Bayview et Excelsior, dans le sud-est de la ville, comptent une population pauvre et majoritairement afro-américaine. Les récents efforts de la municipalité pour y réduire le taux de criminalité n'ont eu guère de succès.

Le plus connu et le plus grand des espaces verts de San Francisco est le Golden Gate Park, s'étendant du centre jusqu'à la côte pacifique ouest de la ville. Ce parc compte plus de 70 hectares de plus que le Central Park de New York, mais qui reste moins étendu que Griffith Park à Los Angeles. Autrefois recouvert d'herbacées indigènes et de dunes, le parc a été créé dans les années 1860 en y plantant des milliers d'arbres et plantes importés. Ce vaste parc est riche de points d'intérêts naturels et culturels tels que le Conservatory of Flowers, Japanese Tea Garden et le Jardin botanique de San Francisco.
Au sud du Golden Gate se trouve un autre parc célèbre, la base militaire désaffectée du Presidio. Ce dernier fait partie de la "Golden Gate National Recreation Area (GGNRA)", qui inclut l'île d'Alcatraz et de nombreuses autres aires protégées. Ce parc national américain est l'un des plus visités parmi l'ensemble des parcs gérés par l'agence fédérale National Park Service avec plus de 13 millions de visiteurs chaque année. Dans le parc du Presidio se situe aussi Crissy Field, un ancien terrain d'aviation dont on a réapproprié l'écosystème de Marais maritime autrefois présent. la GGNRA gère aussi Fort Funston, Lands End, Fort Mason, et Alcatraz. De son côté, le National Park Service gère le San Francisco Maritime National Historical Park, une flotte de navires historiques ainsi que la propriété maritime autour de l'Aquatic Park.

Buena Vista Park, situé dans le quartier de Haight-Ashbury, est le plus ancien jardin public de la ville, créé en 1867. Non loin de là, Alamo Square est célèbre pour ses vues sur la ville et sa rangée de demeures victoriennes surnommées les "Painted Ladies". Un important lac d'eau douce, Lake Merced, s'étend dans le sud-ouest de la ville près de l'Université d'État de San Francisco et Fort Funston. Il est entouré d'un vaste espace vert et se trouve près du zoo de San Francisco qui abrite plus de 250 espèces, dont beaucoup d'entre elles sont considérées comme des espèces menacées.

Finalement, on compte plus de 200 parcs différents dans la ville.

Parmi les autres points d'intérêts de la ville, on peut compter Baker Beach, une plage faisant partie du Presidio, ainsi que Ocean Beach, autre plage qui longe la côte ouest de San Francisco et souvent fréquentée par une communauté dynamique de surfeurs. Mais ces plages sont réputées dangereuses pour les nageurs à cause de leurs eaux froides et leurs courants qui se révèlent régulièrement fatals aux surfeurs ou baigneurs imprudents.

Au recensement de 2010, San Francisco comptait , et . La municipalité, dont les limites correspondent à celles du comté de San Francisco, est la quatrième de Californie en nombre d'habitants, derrière Los Angeles, San Diego et San José. Cependant, l'agglomération de San José-San Francisco-Oakland, qui regroupe plusieurs municipalités autour de la baie, rassemble près de 7 millions d'habitants. Cette aire urbaine se classe au mondial et au pour les États-Unis.

Avec près de par kilomètre carré, San Francisco est la seconde grande ville américaine en termes de densité de population après New York. En 2000, le comté de San Francisco occupait la cinquième place en tant que comté américain.

Population des dix villes de Californie les plus peuplées (2016)
Lors du recensement de 2010, la ville compte , dont :
La population de la ville s'élève en 2010 à , dont :

Selon l"', pour la période 2011-2015, 13,2 % de la population vit sous le seuil de pauvreté (15,5 % au niveau national). Ce taux masque des inégalités importantes, puisqu'il est de 31,6 % pour les Afro-Américains et de 9,0 % pour les Blancs non hispaniques.

Selon l"', pour la période 2011-2015, 55,76 % de la population âgée de plus de 5 ans déclare parler l'anglais à la maison, 18,58 % une langue chinoise, 11,10 % l'espagnol, 2,88 % le tagalog, 1,47 % le russe, 1,32 % le vietnamien, 1,10 % le français, 0,81 % le japonais, 0,80 % le coréen, 0,57 % l'allemand, 0,54 % l'hindi et 5,07 % une autre langue.

Avec 33,3 % de sa population s'identifiant comme asiatique . Les Sino-Américains représentent la plus importante population asiatique de la ville, en 2010 21,4 % des San-Franciscains appartenant à cette communauté, et le Chinatown est le plus peuplé des États-Unis après celui de Manhattan. Les Philippino-Américains représentent quant à eux 4,2 % de la population de la ville. D'autres quartiers possèdent une forte concentration asiatique comme Sunset, Richmond et Visitacion Valley. 

La population afro-américaine, qui ne cesse de reculer. Les principaux quartiers afro-américains sont Bayview et Hunter's Point, dans lesquels les Noirs représentent plus de 40 % de la population. 

La part des Hispaniques est la plus élevée à Mission District, Ingleside, Excelsior et Crocker Amazon. 

8,8 % des San Franciscains revendiquent une origine irlandaise, 7,7 % une origine allemande, et 6,1 % des racines anglo-saxonnes.

San Francisco est réputée pour accueillir la part la plus importante de parents homosexuels du pays, ainsi que celle des célibataires gays. Les hommes homosexuels sont plus nombreux que la population lesbienne, qui se concentre davantage dans les banlieues de l'est de la baie. 

D'après une étude de William McFarland pour les services de santé publique de la ville, en 2006, un homme sur cinq à San Francisco est gay, et un peu plus d'un homosexuel san-franciscain sur quatre est infecté par le VIH.

San Francisco dispose d'un gouvernement consolidé ville-comté depuis 1856. La ville fait ainsi partie des 58 comtés de Californie tout en étant une municipalité. Ce statut fait que la ville est administrée par une structure particulière : le maire est également le chef de l'exécutif du comté et le conseil du comté ("Board of Supervisors") officie en tant que conseil municipal.

Depuis 1900, le maire de San Francisco et les conseillers municipaux sont élus par l'ensemble des électeurs de la municipalité ; avant cette date, le maire était désigné par le conseil de la ville.

En 1989, la municipalité a voté une ordonnance dite « sanctuaire » qui implique la non-coopération avec les autorités de contrôle de l'immigration. En 2007, elle a décidé d'octroyer des papiers d'identité à toute personne pouvant prouver un lieu de résidence, y compris aux immigrés clandestins. Au printemps 2008, la ville a lancé une campagne d'information pour les immigrés clandestins, diffusée sur des brochures et à la radio en plusieurs langues, afin de leur faire savoir qu'ils ne seront pas dénoncés par les services municipaux (hôpitaux, écoles, police) aux services fédéraux de l'immigration.

La municipalité mène une politique environnementale ambitieuse. Elle a interdit les sacs plastiques et 69 % des déchets y sont recyclés à la fin des années 2000. En 2014, ce taux est supérieur à 80 %, et les bouteilles d'eau en plastique sont également interdites à la vente dans l'espace public. En 2005, la Journée mondiale de l'environnement eut lieu à San Francisco autour du thème « Des villes vertes, un plan pour la planète ! »

Le budget municipal pour l'année fiscale 2011-2012 était de 6,83 milliards de dollars. La municipalité emploie environ .

Le , la ville vote un décret interdisant le nudisme dans les rues, et qui devait entrer en vigueur en février 2013.

Dans le passé, San Francisco a tiré sa prospérité de l'exploitation de l'or, de l'argent et du pétrole. Pendant la Seconde Guerre mondiale, avec les opérations militaires dans l'océan Pacifique contre le Japon, la base navale de San Francisco fournit des milliers d'emplois directs et indirects. Dans les années 1960, les activités portuaires déclinent. C'est le port d'Oakland qui prend alors le relais.
Les PME sont une force majeure dans l'économie de San Francisco, puisque d'après la Chambre de Commerce de la ville, près de 90 % des entreprises san-franciscaines comptent moins de 100 salariés.

San Francisco est l'une des rares villes américaines à imposer son propre salaire minimum, prenant précédent sur celui de l'état, qu'il dépasse. En novembre 2006, les électeurs san-franciscains ont également approuvé une mesure qui instaurerait des congés maladie obligatoires pour les employeurs de la ville, à la hauteur d'une heure maladie par 30 heures travaillées.

Le tourisme est l'activité économique principale de San Francisco, qui compte parmi les dix principales destinations américaines. San Francisco est la américaine qui attire le plus de touristes étrangers. Fisherman's Wharf est la troisième attraction touristique des États-Unis. D'après "The Economist", la ville a été visitée en 2004 par quelque 15 millions de touristes, rapportant 6,7 milliards de dollars. San Francisco a reçu 15,8 millions de touristes en 2006. Ceux-ci ont engendré des revenus de de dollars. Les touristes français privilégient les grandes villes américaines : ainsi, sur les 20 premières destinations touristiques des Français, cinq sont américaines. La première est New York, la cinquième San Francisco et la huitième Las Vegas.

Grâce à ses infrastructures (Moscone Center), la ville se classe dans les dix premières places pour les conventions et les conférences en Amérique du Nord.

L'héritage de la ruée vers l'or a fait de San Francisco le centre financier et bancaire principal de la côte pacifique. Dans la foulée, plusieurs banques voient alors le jour et administrent les richesses de la ruée et de l'argent extrait à Comstock Lode au Nevada dans les années 1850 et 1860. Entre autres, Amadeo Giannini fonde une Banque d'Italie qui deviendra plus tard la Bank of America.

Montgomery Street dans le centre financier est souvent considéré comme le « Wall Street de l'ouest ». Il est le siège du de la Réserve fédérale et des institutions Wells Fargo Charles Schwab Corporation et Visa. De nombreuses autres banques, institutions financières et sociétés de capital risque y ont élu domicile afin de pouvoir y faire affaires avec les firmes de Silicon Valley. Bank of America a été fondée à San Francisco dans les années 1960 et son siège social occupe l'immeuble du 555 California Street. Avec plus de 30 institutions financières internationales, sept sociétés classées au Fortune 500, San Francisco est considérée comme l'une des dix villes mondiales. La ville se place au mondial des villes les plus riches et au mondial des places financières, selon le "Global Financial Centres Index".

Au cours des dernières années, San Francisco s'est progressivement imposée comme un pôle de compétence dans les secteurs des biotechnologies, de la biomédecine et l'informatique. En mai 2005, San Francisco a été choisie pour héberger le siège du programme de recherche californien de cellules souches. Le plus gros de ces industries se concentre dans le quartier de Mission Bay, dans le sud-est de la ville. Le CBD abrite plusieurs sièges sociaux : McKesson, une entreprise de médicaments, qui se classait au des entreprises mondiales par le chiffre d'affaires en 2009 ; Pacific Gas and Electric Company dans le secteur de l'électricité et du gaz ; la chaîne de magasins de vêtements Gap.

Plus récemment dans le secteur informatique, la société Twitter Inc. a implanté son siège social au cœur de la ville. De nombreuses autres startups ont suivi le mouvement comme la société Square, Inc.

Les quartiers de SOMA et de Mission hébergent aujourd'hui de nombreux incubateurs de startups et la ville cherche à attirer les talents de la Silicon Valley par des mesures fiscales incitatives.

En raison des contraintes géographiques (collines, site de péninsule) et de l'opposition des San-Franciscains à la construction d'autoroutes urbaines à la fin des années 1950, San Francisco est l'une des rares métropoles américaines à avoir des artères urbaines plutôt que de nombreuses voies express. 
Le Bay Bridge, dont une partie est en cours de rénovation, est l'unique axe routier rejoignant directement San Francisco à l'est de la baie "via" Treasure Island. De la même façon, le célèbre pont du Golden Gate, rejoint San Francisco au comté de Marin, au nord de la baie.

Les axes routiers principaux dans San Francisco sont l'Interstate 80, qui commence sur le Bay Bridge et continue vers l'est, l'U.S. Route 101, qui prolonge l'Interstate 80 vers le sud vers Silicon Valley. Dans sa direction nord, l'US 101 se confond avec deux des artères principales de la ville, Van Ness Avenue et Lombard Street pour ensuite suivre le Golden Gate Bridge et traverser le comté de Marin. L'Interstate 280 commence dans South of Market vers l'ouest et bifurque ensuite vers le sud vers Silicon Valley et la "Highway 1" et "via" Park Presidio Boulevard à travers l'ouest de la ville. Après le séisme de 1989, les autorités municipales ont décidé de détruire l'Embarcadero Freeway ainsi qu'une partie de la Central Freeway et de les convertir en boulevards urbains.

La California State Route 35 qui traverse la majeure partie de la péninsule de San Francisco le long des monts Santa Cruz, entre dans la ville par le sud avec le Skyline Boulevard et se termine à son intersection avec la Highway 1. La California State Route 82 arrive à San Francisco par le sud avec Mission Street, suit la route historique du Camino Real et se termine à la jonction avec l'autoroute 280. Le terminus occidental de la route historique Lincoln Highway se trouve dans le Lincoln Park. Les principales artères est-ouest sont le Geary Boulevard, le Lincoln Way, la Fell Street, Portola Drive et Market Street.

San Francisco a probablement le réseau de transport public le plus dense sur la côte occidentale des États-Unis. C'est aussi l'un des réseaux les plus utilisés, puisque 32 % des San-Franciscains l'empruntent quotidiennement, ce qui classe la ville au premier rang de la Côte Ouest et au troisième rang des États-Unis. Le réseau de transport public municipal, Muni, est géré par la ville. Il comprend le réseau de tramways de la ville (notamment en métro léger), y compris les " si appréciés des touristes, et un réseau de bus et trolleybus. Muni est le septième plus grand réseau de transport public des États-Unis avec en 2006. L'ensemble de la région est desservie par un réseau ferroviaire express, BART ("Bay Area Rapid Transit"), inauguré en 1974, qui relie San Francisco à l'est de la baie par un tunnel (le Transbay Tube) et au nord du comté de San Mateo, où se situe notamment l'aéroport international de San Francisco. Caltrain est une ligne ferroviaire dont le terminus san-franciscain est dans le quartier de SOMA. La ligne, qui relie San Francisco à la ville de Gilroy, via San José, suit plus ou moins en parallèle l'avenue El Camino Real, et dessert de nombreuses gares le long de la péninsule de San Francisco. Il existe plusieurs lignes régionales de cars dont le terminus est le Transbay Terminal. La compagnie ferroviaire Amtrak propose une navette en bus entre San Francisco et la gare d'Emeryville, située de l'autre côté de la baie. Un projet de train à grande vitesse, accepté par les Californiens lors du référendum du reliera San Francisco à Anaheim, dans l'agglomération de Los Angeles, soit une distance de . La bicyclette est un mode de transport apprécié des San-Franciscains, l'utilisant chaque jour. Le système de vélos en libre-service Bay Area Bike Share a été mis en place en 2013 et compte pas moins de 104 stations et fournis par une l'entreprise canadienne PBSC Solutions Urbaines.Enfin, une modeste flotte de ferries fait la navette entre le quartier The Embarcadero et le comté de Marin, Oakland, Vallejo et le comté de Solano. Les principales stations sont situées dans le Ferry Building et au Pier 39.

Le coût d'utilisation du réseau reste toutefois assez élevé. Il faut compter pour un ticket de bus, pour un accès unique aux , pour un abonnement à la journée et 70 à pour un abonnement mensuel . Ces formules ne permettent qu'un accès au seul territoire de la ville de San Francisco dans la mesure où la ville se confond avec le comté (les comtés sont les autorités organisatrices des transports en commun aux États-Unis) contrairement à l'agglomération de Los Angeles regroupée dans un seul et même comté. Pour rejoindre les villes voisines, il faut acheter d'autres tickets ce qui additionne à chaque fois les coûts. Les tickets MUNI ne sont pas non plus utilisables sur les autres réseaux de transports en commun que sont le Golden Gate Bridge, Highway and Transportation District ou le BART et ce même sur le territoire de la ville de San Francisco (sauf abonnements longue durée). La compréhension de la tarification du réseau de transports en commun s'avère d'ailleurs très peu aisée pour les touristes contrairement aux autres métropoles des États-Unis.

L'aéroport international de San Francisco (SFO) (en anglais, "San Francisco International Airport") se situe à au sud de la ville, dans le comté de San Mateo, au bord de la Baie de San Francisco. C'est le deuxième plus gros aéroport en Californie, après celui de Los Angeles, et se classe mondial pour le trafic de passagers en 2010. Il est connecté au réseau ferroviaire BART et via BART ou navette à Caltrain. Il est sous la juridiction du comté et de la ville de San Francisco.

L'aéroport de San Francisco est un hub important pour les compagnies américaines United Airlines et Virgin America.
Il détient le plus grand terminal international d'Amérique du Nord. Les deux autres aéroports principaux de l'agglomération sont l'aéroport international d'Oakland, à à l'est de San Francisco, et l'aéroport international de San José, à au sud-ouest.

Le port de San Francisco était autrefois le plus large et le plus fréquenté de la côte occidentale américaine, mais ce titre est désormais détenu par les ports de Los Angeles et Long Beach. Même si la baie de San Francisco reste une destination portuaire importante, c'est désormais le port d'Oakland qui accueille la plupart des cargos, disposant de plus d'espace et d'une meilleure infrastructure, notamment pour accueillir les porte-conteneurs. Le trafic total de marchandises dans le port de San Francisco était de en 2011.

Comme nombre de vieux ports américains, celui de San Francisco a été construit à base de pontons ("piers") perpendiculaires à la côte. Le cargo était ensuite déchargé par grues et transporté manuellement vers des hangars construits sur les quais. C'est à travers ces pontons que transita le très important commerce du bois de la côte occidentale.

L'avènement de l'ère des conteneurs sonna le glas du port de San Francisco, qui n'était pas équipé pour ce type de cargo. Nombre de ses hangars devinrent obsolètes et restèrent à l'abandon jusqu’à leur récente reconversion en bureaux, centres commerciaux ou espaces d'exposition. Le port de San Francisco continue à être actif, mais ses activités son désormais limitées aux ferries qui transitent à partir du Ferry Building, à la plaisance et au tourisme. Le Pier 39 accueille un centre commercial touristique et les vaisseaux de croisière : le port de San Francisco accueille chaque année entre 60 et 80 paquebots et . Les croisières passant par San Francisco vont vers l'Alaska et le Mexique. Une rénovation des Piers 27-31 est en projet.

San Francisco accueille plusieurs équipes professionnelles. L'équipe de football américain des 49ers de San Francisco, qui évolue en National Football League (NFL), est la plus renommée et la plus ancienne de la ville. Cette équipe a débuté en 1946 et joue depuis 1971 dans le Candlestick Park. Elle a connu son apogée dans les années 1980 et 1990 en remportant cinq titres du Super Bowl grâce à des joueurs comme Joe Montana, Steve Young, Ronnie Lott ou encore Jerry Rice. En 2006, les propriétaires de l'équipe ont annoncé leur intention de déménager en 2015 l'équipe à Santa Clara, toujours en Californie, bien que l'équipe conservera son nom en référence à San Francisco.

L’équipe de baseball des Giants de San Francisco, qui évolue en Ligue majeure de baseball (LMB), est l'autre équipe phare de la ville. La franchise fut créée à New York et y resta jusqu'au déménagement à San Francisco en 1958. Bien que bénéficiant de joueurs importants tels que Willie Mays, Willie McCovey et Barry Bonds, le club a attendu 52 années jusqu'à son premier titre Série mondiale en 2010, pour ensuite en remporter deux autres en 2012 et en 2014. Depuis 2000, les Giants jouent à l'AT&T Park, que les San-Franciscains continuent d'appeler "Pac Bell Park". Ce stade de plus de fait partie du projet de rénovation de South Beach et de Mission Bay.

Il y a également d'autres équipes professionnelles telles que le Victory de la Californie (Première division des United Soccer Leagues) ou les Deltas de San Francisco (North American Soccer League) pour le football, les Dragons de San Francisco (Major League Lacrosse) pour la crosse et les Pilotes de San Francisco (American Basketball Association, Red Conference) pour le basket-ball, et les Bulls de San Francisco, dans l'ECHL.

La ville compte aussi plusieurs équipes universitaires, parmi lesquelles les Dons de l'université de Californie à San Francisco qui jouent en Division de la National Collegiate Athletic Association (NCAA) et qui ont gagné le championnat en 1955 et 1956 à lépoque de Bill Russell, les Rams du City College of San Francisco et les Gators de l'université d'État de San Francisco et les Urban Knight de l'Academy of Art University qui sont en Division II de la NCAA. La coupe de l'Emerald Bowl de la ligue de football américain NCAA se tient à San Francisco chaque mois de décembre.

La course à pied Bay to Breakers a lieu chaque année depuis 1912. Elle est l'occasion pour certains participants d'y courir en costumes. Le marathon de San Francisco a lieu chaque année au mois de juillet, et inclut traditionnellement une boucle qui comprend le pont du Golden Gate. Le triathlon Escape from Alcatraz a lieu depuis 1980 annuellement. L'Olympic Club, fondé en 1860, est le plus ancien club d'athlétisme aux États-Unis. Son parcours de golf privé, situé sur la frontière avec Daly City, a accueilli l'US Open de golf à cinq reprises. Le parcours public de golf, le TPC Harding Park, est une étape occasionnelle sur le PGA Tour.

La Route de l'Or est une compétition nautique qui relie New York à San Francisco sans escale. San Francisco sera l'hôte de la Coupe de l'America 2013.

Avec un climat idéal pour les activités de plein air, San Francisco a de vastes ressources et possibilités pour la pratique du sport amateur et les loisirs. Il y a plus de de voies et pistes cyclables dans la ville et le cyclisme se développe. The Embarcadero et Marina Green sont des lieux favorables à la pratique du skateboard. De vastes installations publiques de tennis sont disponibles dans le Golden Gate Park et le Dolores Park, ainsi que de plus petites à travers la ville. Le nautisme, la planche à voile et le kitesurf sont parmi les activités les plus populaires sur baie de San Francisco, et la ville conserve un port de plaisance dans le Marina District.

Dans les années qui ont suivi la Seconde Guerre mondiale, San Francisco a accéléré sa transformation en un pôle de cultures et modes de vie alternatifs. Les mouvements qui ont contribué à cette évolution sont nombreux : la "Beat Generation", incarnées par les beatniks (un terme né de la plume de l'éditorialiste local Herb Caen), la Renaissance de San Francisco des années 1950, la culture hippie, la libération sexuelle, les droits civiques homosexuels et le fameux « Été de l'Amour » dans le quartier de Haight-Ashbury dans les années 1960. 
Les liens de San Francisco avec l'Asie sont déterminants pour comprendre la ville : la communauté chinoise est l'une des plus importantes d'Amérique du Nord ; San Francisco a le deuxième Chinatown le plus peuplé des États-Unis derrière celui de New York. La ville est notamment jumelée avec Shanghai et a développé des liens étroits avec la culture asiatique : la célébration du Nouvel An chinois, le Musée d'Art asiatique et le jardin japonais du Golden Gate Park témoignent de cette relation. En 1975, une exposition temporaire de vestiges archéologiques chinois avait attiré quelque en deux mois.
Les habitants de la région de San Francisco désignent généralement la ville tout simplement par "the City" (qui signifie littéralement "la Ville") et l'ensemble de la métropole par "Bay area" ou "the Bay" (qui signifie littéralement la "région de la Baie" ou simplement "la Baie"). San Francisco est parfois poétiquement appelée en anglais "The City by the Bay", et l'éditorialiste san-franciscain Herb Caen l'a aussi baptisée "Baghdad by the Bay" et "The City that Knows How". Les habitants de la région de la Baie n'utilisent jamais le surnom de "Frisco", que seuls les touristes semblent affectionner. "San Fran" n'est pas non plus très populaire chez les San-Franciscains, qui en revanche abrègent le nom de la ville par ses initiales, « SF ».

La géographie particulière du site de San Francisco a conditionné de nombreux aménagements qui marquent aujourd'hui la ville : les ponts comme le pont du Golden Gate en sont l'exemple le plus significatif. En raison de sa position stratégique, des structures à but défensif ont été érigées comme Fort Point dans les années 1860. Les bâtiments anciens sont rares à San Francisco car la ville a été fondée tardivement et a été en grande partie détruite par l'incendie qui suivit le séisme de 1906. La Mission San Francisco de Asís est l'un des plus vieux bâtiments de la ville. De nombreux quartiers sont marqués par l'architecture civile victorienne de la deuxième moitié du comme Nob Hill ou Haight-Ashbury : ils sont composés de maisons mitoyennes en bois et peintes de couleurs vives appelées "painted ladies". Le style Beaux-Arts est bien représenté avec les édifices du Civic Center (hôtel-de-ville, opéra, bibliothèque) et de l'Exposition universelle de 1915 (Palace of Fine Arts). L'influence européenne se retrouve également dans l'architecture du Ferry Building (1898). Parmi les monuments les plus visités de San Francisco, la Coit Tower est une tour de style Art déco construite dans les années 1930, à la même époque que le pont du Golden Gate. L'installation de diverses communautés à San Francisco se lit dans l'architecture : immeubles de style chinois dans le Chinatown, pagodes japonaises du jardin de thé. À cause des tremblements de terre, les constructions de la ville doivent être consolidées ou élaborées selon des normes parasismiques comme c'est le cas pour les gratte-ciel du centre des affaires. L'architecture contemporaine est bien représentée à San Francisco qui se veut une ville d'avant-garde : achevée en 1972, la Transamerica Pyramid avait suscité bien des débats en raison de sa forme originale. Elle est toujours le plus haut bâtiment de la ville avec de hauteur. La préoccupation écologique marque aussi les dernières réalisations architecturales : ainsi Renzo Piano a dessiné les plans de la California Academy of Sciences (2008) en suivant des normes environnementales strictes.

La vie culturelle de San Francisco est particulièrement riche grâce à ses nombreux musées. Le plus ancien est la California Academy of Sciences : fondée en 1853, cette institution est dédiée aux sciences. Après le séisme de 1989, l'académie des sciences a dû intégrer un nouveau bâtiment situé dans le Golden Gate Park qui abrite des aquariums, un planétarium, un cinéma 3D et des salles d'exposition. Dans le domaine des sciences, l'Exploratorium (1969) est l'un des plus populaires de la ville puisqu'il reçoit chaque année la visite de , dont de nombreux élèves de l'agglomération.

Les liens culturels avec l'Asie sont symbolisés par le Musée d'art asiatique. Il s'agit du plus riche musée d'art asiatique du monde après celui de Taïpeh.

Le Musée des beaux-arts de San Francisco, est la plus grande institution d'arts de la ville et l'un des plus grands musées de Californie. Il est composé du 

Le musée d'art moderne de San Francisco (SFMOMA) est dédié à l'art contemporain. Il a ouvert ses portes en 1935 et était alors le seul musée de ce type sur la côte ouest des États-Unis. Il abrite quelque d'Henri Matisse, Georges Braque, Jackson Pollock, Andy Warhol, Paul Klee, Marcel Duchamp, Ansel Adams, parmi d'autres.

Des musées plus petits retracent l'histoire de la ville (San Francisco Cable Car Museum, San Francisco Railway Museum, Society of California Pioneers), des minorités ethniques (Museum of the African Diaspora) ou des groupes culturels (Contemporary Jewish Museum).

Enfin, la vocation maritime de San Francisco est soulignée par le San Francisco Maritime National Historical Park (1988) qui comprend le musée maritime de la ville et plusieurs navires datant de la fin du et du début du .

La bibliothèque publique de San Francisco est un réseau de 28 bibliothèques réparties dans les quartiers de la ville et d'une bibliothèque centrale qui se trouve dans le Civic Center. La première bibliothèque municipale de San Francisco ouvre ses portes au public en 1879 sur Bush Street. En 2007, l'ensemble des bibliothèques publiques de San Francisco compte plus de 3,4 millions de documents, dont 1,9 million sont conservés dans la bibliothèque centrale. L'actuel bâtiment qui abrite la bibliothèque centrale a été construit en 1993-1995 et coûta 109,5 millions de dollars. Sa superficie totale est de répartis sur six étages et un sous-sol. La nouvelle bibliothèque est deux fois plus grande que l'ancienne, qui avait été endommagée par le séisme de Loma Prieta en 1989.

La ville comprend de nombreuses salles de spectacles, à commencer par celles de l'Orchestre symphonique de San Francisco, l'Opéra de San Francisco et le Ballet de San Francisco. Créés dans l'entre-deux-guerres, l'opéra et le ballet de la ville comptent parmi les troupes les plus anciennes des États-Unis. La ville est également le siège de l'American Conservatory Theater, souvent abrégé A.C.T., une institution majeure de la scène théâtrale de la région de la Baie depuis sa fondation en 1965.

Le Roxie Theater (1909) est le plus ancien cinéma de la ville encore en activité. Le Castro Theatre se distingue par son architecture hispanique des années 1920 : ce cinéma compte actuellement 1407 places. Le et le datent de la même époque.

Au , Jules Verne fait passer les héros du "Tour du monde en quatre-vingts jours" par San Francisco ; il la décrit (sans l'avoir jamais visitée) comme l'archétype de la ville cosmopolite et portuaire : 
Dans le roman fantastique "Les Héritiers de l'Aube", t.2 "Des profondeurs" de Patrick McSpare, l'action se situe pendant le séisme de 1906 à San Francisco.

San Francisco est probablement l'une des villes les plus pittoresques d'Amérique du Nord, ce qui lui vaut d'être le décor de nombre d'œuvres cinématographiques et de séries télévisées. Aux débuts du cinéma, Charlie Chaplin tourne deux films muets en noir et blanc dans la ville : "Charlot veut se marier" et "Charlot dans le parc". Les collines de San Francisco ont servi de décor à maintes poursuites de voitures, de "Bullitt" à "The Rock", mais aussi à de nombreuses comédies romantiques comme "La Blonde ou la Rousse", "Madame Doubtfire" ou "En direct sur Ed TV". La ville a aussi été le cadre de nombreux films noirs ou à suspense, des "Passagers de la nuit" à "Zodiac" en passant par "Sueurs froides" ou "The Game". Enfin, le pont du Golden Gate apparaît dans plusieurs films, dans lesquels il est détruit ("Fusion" (2003) ; "Magnitude 10,5" (2004) ; "" (2006)). C'est aussi le lieu où se déroule l'intrigue dans "La Planète des singes". 

San Francisco accueille chaque année un festival international du film (Festival international du film de San Francisco), ainsi que de nombreux autres plus spécialisés.

De nombreuses séries télévisées se situent dans la « Cité près de la Baie ». La ville a été immortalisée dans la série policière "Les Rues de San Francisco" ou par l'adaptation des "Chroniques de San Francisco". À noter cependant que depuis les années 1980, nombre de séries ou mini-séries ayant la ville comme décor sont pour l'essentiel tournées soit en studio dans la région de Los Angeles (comme les comédies de situation "La Fête à la maison" ou "La vie à cinq" ou les séries "" ou "Charmed"), soit au Canada, à Toronto, Montréal ou plus fréquemment en Colombie-Britannique, où les coûts de production sont moindres. La dernière exception à cette règle était la série "Nash Bridges", intégralement filmée à San Francisco et dans sa région entre 1996 et 2000. Mais les épisodes de "Monk" sont ainsi tournés à Vancouver à l'exception de quelques rares scènes extérieures, la série vite annulée "Bionic Woman" était intégralement tournée elle aussi en Colombie-Britannique. "Journeyman", diffusée en 2007, était en grande partie tournée dans la région de Los Angeles, tout comme "Eli Stone" et "Women's Murder Club" (2007). Depuis le milieu des années 2000, la ville de San Francisco a tenté de séduire les sociétés de production en baissant notamment les coûts des permis de tournage et en simplifiant le système, mais avec pour l'instant un succès limité. Une série est cependant en production depuis 2009, "Trauma", qui doit être tournée principalement à San Francisco. La série "Sense8", se déroulant en partie à San Francisco, a filmé toutes les scènes de la ville sur place.


Le "San Francisco Sound" est une composante de la musique rock née dans les années 1960. De nombreux groupes s'y rattachent comme Sly and the Family Stone, The Charlatans, The Beau Brummels, Jefferson Airplane, Grateful Dead, Big Brother and the Holding Company, Quicksilver Messenger Service, It's a Beautiful Day, Steve Miller Blues Band, Fifty Foot Hose, Carlos Santana, Moby Grape, Blue Cheer, ou encore Uther Pendragon. Parmi toutes les salles de concert de San Francisco, "The Fillmore" a été dans les années 1960 l'épicentre de la musique psychédélique et de la contre-culture hippie. Des artistes comme Pink Floyd ou Janis Joplin y firent leurs débuts.

La ville a inspiré de nombreux auteurs et interprètes, de Henry Mancini aux Arctic Monkeys, en passant par les Village People et Chris Isaak. Maxime Le Forestier a immortalisé dans "San Francisco" son expérience bohémienne pendant l'âge d'or du mouvement hippie de la ville, et Otis Redding a chanté la nostalgie d'un natif de la Géorgie dans "(Sittin' on) The Dock of The Bay".

Les deux chansons les plus prisées des San-Franciscains sur leur ville restent cependant "San Francisco", chantée par Jeanette Mac Donald dans le film du même titre, et "I Left My Heart in San Francisco", par Tony Bennett.
San Francisco accueille notamment le fameux San Francisco Gay Men's Chorus, un chœur de 230 chanteurs homosexuels, ainsi que le San Francisco Lesbian/Gay Freedom Band, la première fanfare gay et lesbienne du monde. La ville compte aussi deux autres chœurs gays, le Gay Chorus of San Francisco et le Golden Gate Men's Chorus.

Plusieurs festivals de musique ont lieu chaque année à San Francisco, parmi lesquels le San Francisco Blues Festival, le plus vieux festival de blues américain, tenu chaque automne depuis 1973, et le San Francisco Jazz Festival, chaque automne depuis 1982. Depuis 1993, le festival Noise Pop célèbre par ailleurs les dernières tendances musicales rock, le San Francisco Electronic Music Festival a été lancé en 2000, et le Mission Creek Music Festival met à l'affiche des interprètes locaux depuis 1996.

San Francisco a une vie nocturne intense et variée, offrant nombre de bars, "lounges" et clubs à ceux qui y sortent. Les quartiers qui vivent le plus la nuit sont North Beach, le Mission District, la Marina, le Castro et South of Market. Certaines salles de concert san-franciscaines sont légendaires, comme The Fillmore et The Warfield. Bimbo's 365 et le Great American Music Hall sont également connues pour accueillir des interprètes à la popularité grandissante, et 1015 Folsom et Ruby Skye sont parmi les boîtes de nuit les plus fréquentées.
À cause d'un éclairage nocturne intense, de la réverbération de la lumière sur l'eau et de l'humidité et de la pollution de l'air, la ville est souvent couverte d'un halo nocturne qui traduit un phénomène de pollution lumineuse affectant notamment les oiseaux à l'époque des migrations.

L'année est rythmée par une série de parades et d'événements qui animent les rues de San Francisco. La parade du nouvel An chinois est la plus importante du monde en dehors du continent asiastique. Elle existe depuis les années 1860. Un carnaval est organisé en février dans le quartier de Mission. La gay pride qui a lieu en juin depuis 1970 est la plus importante des États-Unis.

Plusieurs journaux sont publiés à San Francisco : le "San Francisco Chronicle" constitue le quotidien le plus important de Californie du nord en matière de distribution. Il a été créé en 1865 et fait partie de la Hearst Corporation, et son tirage quotidien atteint en semaine, et le dimanche. Herb Caen y travailla à partir de la fin des années 1930. "The San Francisco Examiner" fut l'un des journaux les plus remarquables de l'empire médiatique de William Randolph Hearst ; puis il déclina pour devenir aujourd'hui un petit tabloïd. "Sing Tao Daily" se place parmi les plus grands journaux chinois de la Baie de San Francisco.

Plusieurs quotidiens et hebdomadaires gratuits sont distribués à San Francisco, notamment "San Francisco Bay Guardian", un hebdomadaire progressiste, ou le "SF Weekly".

La ville accueille également les sièges des magazines citadins "San Francisco Magazine" et "7x7", ainsi que de nombreuses autres publications, comme les mensuels culturels "The Believer" et "Planet", le magazine de mode et design "Surface" ou le magazine asio-américain "Hyphen".

L'agglomération de San Francisco est la cinquième région sur le marché américain en termes d'audience télévisuelle, et la quatrième en termes d'audience radiophonique. Tous les réseaux de télévision américains (ABC, NBC, CBS, Fox, The CW, PBS) y ont une chaîne affiliée, et la ville accueille également d'autres stations de télévision indépendantes et non affiliées, ainsi que des bureaux régionaux pour CNN et la BBC.

San Francisco est aussi le siège de nouveaux médias tels que le webzine "Salon.com", la firme CNET Networks et la société de publication orientée LGBT PlanetOut.


Liste des villes jumelées à San Francisco :

La ville a par ailleurs signé un pacte d'amitié et de coopération avec Paris en 2009.

De nombreuses personnalités sont originaires de San Francisco ou y ont résidé. On peut notamment citer les photographes Ansel Adams et Dorothea Lange, la danseuse Isadora Duncan, souvent considérée comme la fondatrice de la danse moderne, l'écrivain contemporain Armistead Maupin, le romancier écossais Robert Louis Stevenson, et la plupart des membres de Metallica. La peintre Margaret Keane y habite toujours et à une galerie d'art.

San Francisco est aussi le repaire de nombreux réalisateurs et acteurs, parmi lesquels Robin Williams et Sean Penn. Clint Eastwood y est né et y a notamment filmé la saga de "L'Inspecteur Harry", Francis Ford Coppola y a vécu et y a installé sa maison de production American Zoetrope, et George Lucas, qui réside au nord de la ville, vient d'y déplacer le siège de ses sociétés Lucasfilm, Industrial Light & Magic et LucasArts dans le parc du Presidio.


Géographie


Architecture, urbanisme et société

Histoire, politique et administration

Culture, art et littérature

Population et société


</doc>
<doc id="2922" url="https://fr.wikipedia.org/wiki?curid=2922" title="Tigrigna">
Tigrigna

Le tigrigna, également écrit tigrinya ou tigriña (autonyme : ትግርኛ ; dans l'alphabet phonétique international : []) est une langue chamito-sémitiques appartenant a la famille des langues sémitiques parlée essentiellement au nord-est de la Corne de l'Afrique. C'est la langue officielle de l'Érythrée et, en Éthiopie, de l'État régional du Tigray.

Le tigrigna avait locuteurs en Éthiopie en 2007, en Érythrée en 2006, et quelque tous pays confondus. Il est aussi beaucoup parlé en seconde langue, autant en Érythrée et Éthiopie, mais aussi au sud-est du Nord Soudan, et à Djibouti, ce qui rend les estimations des locuteurs de cette langue difficiles. 

Comme plusieurs langues de la Corne de l'Afrique, le tigrigna s'écrit au moyen d'une version de l'alphasyllabaire guèze.

À la suite de la colonisation de l'Érythrée par l'Italie entre 1885 et 1941, de nombreux mots italiens s'intègrent au tigrigna. Depuis 1950, les nouveaux termes proviennent plutôt de l'anglais et de l'arabe. 

Le tigrigna s'écrit à l'aide de l'alphasyllabaire guèze auquel s'ajoutent quelques caractères. Dans le tableau qui suit, les graphèmes sont rangés par ligne selon leur consonne initiale, et par colonne selon la voyelle qui la suit. Par exemple, la première ligne se lit "hä, hu, hi, ha, he, h(ə), ho".





</doc>
<doc id="2924" url="https://fr.wikipedia.org/wiki?curid=2924" title="Théorie quantique des champs">
Théorie quantique des champs

En physique, la théorie quantique des champs (en anglais "quantum field theory", en abrégé QFT) fournit un cadre théorique pour la construction de modèles quantiques de certains systèmes. Plus précisément cette théorie permet de décrire des systèmes ayant un très grand nombre ou une infinité de degrés de liberté.

La plupart des théories de la physique moderne des particules, y compris le modèle standard, sont considérées comme des théories des champs quantiques relativistes. C'est aussi le langage permettant de parler de manière quantitative des milieux condensés. La théorie quantique des champs permet la description quantique des phénomènes critiques et des transitions de phase, et intervient également dans la théorie de la supraconductivité. La théorie quantique des champs est considérée généralement comme la seule façon correcte de combiner les règles de la mécanique quantique avec celles de la relativité restreinte.

L'utilisation de la théorie de la perturbation amène à considérer les forces entre les particules comme provenant en fait d'échanges d'autres particules, appelées "médiateurs". Ainsi, la force électromagnétique entre deux électrons est causée par un échange de photons, les bosons W et Z sont les médiateurs de l'interaction faible, et les gluons ceux de l'interaction forte. Il n'y a pas actuellement de théorie quantique complète de la dernière des forces fondamentales, la gravité, mais beaucoup de théories revendiquent l'existence d'une particule appelée graviton qui en serait le médiateur. Ces médiateurs sont des particules virtuelles et, par définition, ne peuvent pas être détectées lors de la manifestation de la force.

Les photons QFT ne sont pas considérés comme des « petites boules de billard » ils sont considérés comme des champs quantiques – nécessairement coupés en ondulations dans un champ, ou des « excitations », qui 'ressemblent' à des particules. Le fermion, comme l'électron, peut seulement être décrit comme des ondulations/excitations dans un champ, quand chaque sorte de fermion a son propre champ. En résumé, la visualisation classique de « tout est particules et champ », dans la théorie quantique des champs, se transforme en « tout est particules », puis « tout est champs ». à la fin, les particules sont considérées comme des états excités d'un champ (champ quantique). 

Le champ gravitationnel et le champ électromagnétique sont les deux seuls champs fondamentaux dans la Nature qui ont une infinité de gammes et une correspondance à la limite classique de l'énergie faible, qui diminue fortement et cache les excitations des « particules ressemblantes ». Albert Einstein, en 1905, attribue la « particule ressemblante » et les échanges discrets d'un momentum et d'une énergie, la caractéristique d'un « champ quantique », au champ électromagnétique. Initialement, sa principale motivation était d'expliquer les radiations thermodynamiques. Bien qu'il soit souvent revendiqué que l'effet photo-électrique et les effets de Compton nécessitent une description quantique du champ électromagnétique, cela est maintenant reconnu comme faux, preuve en est que la nature de la radiation quantique est désormais prise en optique quantique moderne comme l'effet de dégroupement. 

Le mot « photon » a été inventé en 1926 par le grand physicien chimiste Gilbert Newton Lewis (voir aussi les articles le dégroupement du photon et le laser).

La description de la « limite énergie faible » correcte d'un champ théorique quantique d'un champ électromagnétique, appelée électrodynamique quantique, est attribuée à la théorie de James Clerk Maxwell développée en 1864, bien que la « limite classique » de l'électrodynamique quantique n'ait pas été aussi largement explorée que la mécanique quantique. Vraisemblablement, là encore inconnue, le traitement quantique des champs théoriques du champ gravitationnel deviendra et « ressemblera exactement » à la théorie de la relativité générale dans la « limite énergie faible ». En effet, la théorie des champs quantiques elle-même est probablement la théorie du champ de l'énergie faible, limite d'une théorie plus fondamentale telle que la théorie des super-cordes. Comparer dans ce contexte l'article de la théorie des champs effectifs.

La théorie quantique des champs prend ses origines dans les années 1920, lorsqu'est survenu le problème de la création d'une théorie quantique du champ électromagnétique. En 1925, Werner Heisenberg, Max Born et Pascual Jordan construisent cette théorie en exprimant les degrés internes du champ libre comme une infinité d'ensembles d'oscillateurs harmoniques et en employant la procédure canonique de quantification de ces oscillateurs. Cette théorie ne contient alors pas de courants ou de charges électriques. Aujourd'hui on appellerait cette théorie, la théorie du champ libre. 

La première théorie assez complète de l'électrodynamique quantique, qui inclut à la fois le champ électrodynamique et la matière électriquement chargée (spécifiquement, les électrons) comme objets mécaniques quantiques, a été élaborée par Paul Dirac en 1927. Cette théorie des champs quantiques peut être utilisée pour modéliser des processus importants tels que l'émission d'un photon par un électron tombant dans un état quantique d'énergie faible, un processus dans lequel le nombre de particules change – un atome dans un état initial donne un atome plus un photon dans un état final. Il est maintenant connu que la possibilité de décrire un tel processus est l'une des caractéristiques les plus importantes de la théorie quantique des champs.

Il était évident depuis le début que le bon traitement quantique du champ électromagnétique devait en quelque sorte intégrer la théorie de la relativité d'Einstein, qui avait grandi sur l'étude de l'électromagnétisme classique. Cela doit être mis ensemble, la relativité et la mécanique quantique était la seconde motivation majeure dans le développement de la théorie quantique des champs. Pascual Jordan et Wolfgang Pauli montrèrent en 1928 que les champs quantiques pouvaient être amenés à se comporter de la façon prédite par la relativité restreinte au cours des transformations de coordonnées (spécifiquement, ils montrent que les champs commutateurs étaient invariants de Lorentz). 

Un nouvel élan pour la théorie quantique des champs est venu avec la découverte de l'équation de Dirac, qui était initialement formulée et interprétée comme une équation à une inconnue analogue à l'équation de Schrödinger, mais contrairement à l'équation de Schrödinger, l'équation de Dirac satisfait à la fois l'invariance de Lorentz (les exigences de la relativité restreinte) et les règles de la mécanique quantique. L'équation de Dirac a intégré la valeur de la rotation d'un demi électron et a représenté son moment magnétique et a aussi donné des prévisions précises pour le spectre de l'hydrogène. 

La tentation de l'interprétation de l'équation de Dirac comme une équation à une seule inconnue ne pourrait pas tenir longtemps cependant, et finalement il a été montré que plusieurs de ses propriétés indésirables (comme un état négatif de l'énergie) pourrait prendre sens en remodelant et en réinterprétant l'équation de Dirac comme une vraie équation de champ, dans ce cas pour le « champ Dirac » quantifié ou le « champ électron », avec la « solution d'une énergie négative » montrant l'existence des anti-particules. Ce travail a été effectué par Dirac lui-même avec l'invention de la théorie des trous en 1930 et par Wendell Furry, Robert Oppenheimer, Vladimir Fock, et d'autres. Schrödinger, durant la même période a découvert sa fameuse équation en 1926. Il a également trouvé indépendamment la généralisation de la relativité de celle-ci connue comme l'équation de Klein-Gordon mais l'a rejetée, car sans rotation, elle prédisait des propriétés impossibles pour le spectre de l'hydrogène (Voir Oskar Klein et Walter Gordon). Toutes les équations d'onde relativiste qui décrivent une rotation-zéro de particules sont dites de type Klein-Gordon.

Les études des physiciens Viktor Ambartsumian et de Dmitri Ivanenko sont d'une grande importance, en particulier les hypothèses d'Ambarzumian-Ivanenko sur la création massive de particules (publiées en 1930) qui est la pierre angulaire de la théorie quantique des champs contemporaine. L'idée est que non seulement les quanta du champ électromagnétique, les photons, mais aussi d'autres particules (incluant les particules ayant une masse non nulle au repos) peuvent naître et disparaître résultant de leurs interactions avec d'autres particules. Cette idée de Ambartsumian et Ivanenko a formé la base de la théorie des champs quantiques moderne et la théorie des particules élémentaires.

Une analyse subtile et attentive en 1933 et plus tard en 1950 effectuée par Niels Bohr et Leon Rosenfeld montre qu'il y a une limitation fondamentale sur la capacité de mesurer simultanément les intensités de champs électriques et magnétiques qui entrent dans la description des charges en interaction avec le rayonnement, imposée par un principe d'incertitude, qui doit s'appliquer à toutes les grandeurs conjuguées canoniquement. Cette limitation est cruciale pour le succès de la formulation et de l'interprétation de la théorie des champs quantiques des photons et des électrons (électrodynamique quantique), et même, toute la théorie des champs quantiques perturbatifs. L'analyse de Bohr et de Rosenfeld explique les fluctuations dans les valeurs du champ électromagnétique qui diffèrent des valeurs classiquement « admises » distantes des sources du champ. Leurs analyse était cruciale pour montrer que les limitations et les implications physiques du principe d'incertitude s'appliquent à tous les systèmes dynamiques, autant qu'aux champs et qu'aux particules. Leur analyse a aussi convaincu beaucoup de personnes que toute possibilité d'une description fondamentale de la nature fondée sur la théorie classique des champs (Einstein, malgré de nombreuses tentatives, n'a pas abouti à une théorie du champ unifié classique) était tout simplement hors de question.
La troisième étape dans le développement de la théorie des champs quantiques a été la nécessité de manipuler les statistiques des systèmes à plusieurs particules de façon cohérente et avec facilité. En 1927, Jordan, a essayé d'étendre la quantification canonique des champs aux fonctions d'ondes à plusieurs corps des particules identiques, une procédure qui est parfois appelée quantification secondaire. En 1928, Jordan et Eugene Wigner ont trouvé que le champ quantique décrivant les électrons, ou les autres fermions, devait être étendu en utilisant la création des anti-navettes et des opérateurs d'annihilation dû au principe de l'exclusion de Pauli. Cette étape du développement a été incorporée dans la théorie des corps multiples et a influencé fortement la physique des matières condensées et la physique nucléaire.

Malgré les premiers succès, la théorie des champs quantiques a souffert de plusieurs difficultés théoriques graves. Les quantités physiques de base, telles que l'indépendance énergétique de l'électron, le changement d'énergie des états des électrons dû à la présence du champ électromagnétique, a donné d'infinie, contributions divergentes—un résultat absurde — lorsqu'il est calculé en utilisant les techniques perturbatives disponibles dans les années 1930 et dans la plupart des années 1940. 

Le problème de l'indépendance de l'énergie de l'électron était déjà un problème sérieux dans la théorie classique du champ électromagnétique, la tentative d'attribuer une taille finie ou étendue à l'électron (le rayon classique de l'électron) a mené immédiatement à la question en quoi les contraintes du non électromagnétisme devait être invoquées, qui porterait sans doute l'électron ensemble pour contrecarrer la répulsion de Coulomb dû à sa taille finie. La situation était désastreuse, et a rappelé certains traits de la « difficulté de Rayleigh-Jeans ». Ce qui a fait que la situation des années 1940 soit si désespérée et sombre, cependant, le fait était que les ingrédients (la seconde équation du champ quantisé de Maxwell-Dirac) pour la description théorique des photons et des électrons en interaction était bien en place, et aucun changement conceptuel majeur n'était nécessaire pour celle-ci, qui a nécessité un comptage physiquement minutieux du comportement radioactif des objets chauds, comme prévu par la loi de radiation de Planck.
Ce « problème de divergence » a été résolu dans le cas de l'électrodynamique quantique durant la fin des années 1940 et le début des années 1950 par Hans Bethe, Tomonaga, Schwinger, Feynman et Dyson, à travers la procédure connue sous le nom de « renormalisation ». 

Un grand progrès a été réalisé après avoir remarqué que tous les infinis dans l'électrodynamique quantique sont liés par deux effets : l'énergie propre de l’électron/positron et la polarisation du vide. La renormalisation est l'affaire de faire très attention à ce que l'on veut dire par, comme exemple, les concepts de « charge » et de « masse » en apparaissant tels quels, dans les champs d'équations « non-interagissant ». Le « vide » est lui-même polarisable et, d'où, peuplé de paires de particules virtuelles (sur le cosse et dedans), et, d'où, est un système dynamique bouillonnant et chargé. Ceci était une étape cruciale dans l'identification de la source des « infini » et des « divergences ». La « masse nette » et la « charge nette » d'une particule, les valeurs qui apparaissent dans le champ libre d'équations (non interagissant dans ce cas), sont des abstractions qui sont simplement non détectées dans l'expérimentation (dans l'interaction). Ce que nous mesurons, et donc, ce que nous devons prendre en compte de nos équations, et quelles solutions nous devons prendre en compte, sont la masse « renormalisée » et la « charge renormalisée » de la particule. C'est-à-dire, les valeurs, ces quantités doivent inclure, quand les précautions sont prises tous les écarts par rapport à leur « valeurs nettes » dictée par la nature même des champs quantiques.

L'équation de Schrödinger décrit l'évolution de la fonction d'onde d'une particule. Le besoin de généraliser cette équation à un nombre arbitraire de particules variable a été une des bases de la théorie quantique des champs.

De plus, il fallait trouver une théorie incorporant la mécanique quantique et la relativité restreinte. Si on transforme l'équation de Schrödinger de façon à la rendre invariante de Lorentz, on obtient les équations de Dirac et de Klein-Gordon. Mais leur interprétation en tant qu'évolution d'une fonction d'onde fait naître de nombreux problèmes conceptuels (par exemple, les valeurs propres de l'énergie peuvent être infiniment négatives, ce qui pose le problème de la définition d'un état fondamental).

En mécanique quantique, l'idée est de promouvoir les degrés de liberté d'une particule (position, moments) en opérateurs.

La théorie quantique des champs suit la même idée, mais puisqu'elle traite de champs, les degrés de liberté sont les valeurs du champ en tout point de l'espace des positions et des moments. Ainsi, c'est le champ lui-même qui va être promu en opérateur. Contrairement à la mécanique quantique, la position et le moment restent eux des variables indexant les opérateurs champs.

La théorie quantique possède deux formulations principales qui sont appelées "canonique" et "covariante". La première consiste à partir d'un Lagrangien (manifestement covariant), déterminer son hamiltonien correspondant (non-manifestement covariant) qui est alors quantifié canoniquement. La deuxième formulation consiste à ne travailler qu'avec le Lagrangien (d'où le nom de formulation covariante), on appelle aussi cette formulation "par intégrales de chemin".

La façon dont la théorie des champs fut introduite par Dirac à partir des particules élémentaires est connue pour des raisons historiques sous l'appellation de seconde quantification.


Les particules élémentaires possèdent déjà cette dualité dans l'acceptation du terme de la mécanique classique. Ce que l'on entend par champ est un concept qui permet la création ou l'annihilation de particules en tout point de l'espace. Comme tout système quantique, un champ quantique a un hamiltonien et obéit à l'équation de Schrödinger :


Supposons que "N = 3", avec une particule dans l'état φ et deux dans l'état φ, alors la fonction d'onde est :

alors qu'avec la seconde quantification, cette fonction est simplement

Quoique la différence soit minime, la deuxième permet d'exprimer facilement des opérateurs "création" et "annihilation", qui ajoutent ou enlèvent des particules à l'état. Ces opérateurs sont très similaires à ceux définis par un oscillateur harmonique quantique qui, en mécanique quantique, crée ou détruit des quanta d'énergie. 

Par exemple, l'opérateur "a" a l'effet suivant :

Enfin, il faut introduire « les opérateurs de champ » de création ou d'annihilation d'une particule en un point de l'espace.

De même que pour une seule particule la fonction d'onde s'exprime avec son moment cinétique, de même les opérateurs de champ peuvent s'exprimer à l'aide des transformées de Fourier.

Par exemple, formula_8, qu'il ne faut pas confondre avec une fonction d'onde, est l'opérateur de champ d'annihilation de boson.

Les hamiltoniens, en physique des particules, sont écrits comme une somme d'opérateurs création et annihilation de champ : 

Cela exprime un champ de bosons libres, où "E" est l'énergie cinétique. Cet hamiltonien est utilisé pour décrire des phonons.

L'expérimentateur qui enregistre un « clic » dans son détecteur aimerait relier cet événement, qu'il interprète comme la détection d'une « particule » relativement bien localisée dans l'espace (et dans le temps), au champ quantique et à ses excitations, ce qui conduit au "problème de la localisation" en physique quantique relativiste. Pour certains types de « particules », l'opérateur de position de Newton-Wigner apporte des éléments de réponse.





</doc>
<doc id="2927" url="https://fr.wikipedia.org/wiki?curid=2927" title="Modèle standard (physique des particules)">
Modèle standard (physique des particules)

Le modèle standard de la physique des particules est une théorie qui concerne l'électromagnétisme, les interactions nucléaires faible et forte, et la classification de toutes les particules subatomiques connues. Elle a été développée pendant la deuxième moitié du , dans une initiative collaborative mondiale, sur les bases de la mécanique quantique. La formulation actuelle a été finalisée au milieu des années 1970 à la suite de la confirmation expérimentale des quarks. Depuis, les découvertes du quark top (1995), du neutrino tauique (2000) et du boson de Higgs (2012) ont donné encore plus de crédibilité au modèle standard. Toutes les particules du modèle standard ont désormais été observées expérimentalement. Par son succès à expliquer une large variété de résultats expérimentaux, le modèle standard est parfois vu comme une « théorie de presque tout ».

C'est une représentation qui s'applique à des objets quantiques et qui tente d'expliquer leurs interactions. Elle est bâtie sur le triptyque "particule, force, médiateur", c'est-à-dire qu'elle distingue des familles de particules par les forces auxquelles elles sont sensibles, chaque force s'exerçant au moyen de médiateurs échangés par les particules qui y sont soumises. Ces médiateurs sont connus comme étant des bosons, alors que les particules constituant la matière sont appelés fermions (quarks et leptons).

Le modèle standard possède, en 2016, dix-neuf paramètres libres pour décrire les masses des trois leptons, des six quarks, du boson de Higgs et huit constantes pour décrire les différents couplages entre particules. La valeur de chacun de ces paramètres n'est pas fixée par des principes premiers, elle doit être déterminée expérimentalement.

Pour les théoriciens, le modèle standard est un paradigme de la théorie quantique des champs, qui met en œuvre un large spectre de phénomènes physiques. Il est utilisé pour bâtir de nouveaux modèles qui incluent des particules hypothétiques, des dimensions supplémentaires ou des supersymétries.

L'idée que toute matière est composée de particules élémentaires remonte au moins au . Au , John Dalton, au travers de ses travaux sur la stœchiométrie, conclut que chaque élément de la nature était composé d'un seul et unique type de particule. 
Le mot "atome", d'après le mot grec ἄτομος, "atomos" (« indivisible »), renvoie depuis lors à la plus petite particule d'un élément chimique, mais les physiciens découvrirent bientôt que les atomes ne sont pas, en fait, les particules fondamentales de la nature, mais un conglomérat de particules plus petites, tels que les électrons, autour de son noyau, lui-même composés de protons et de neutrons. 
Les explorations du début du en physique nucléaire et en physique quantique culminèrent avec la découverte de la fission nucléaire en 1939 par Lise Meitner (fondée sur des expériences de Otto Hahn) et de la fusion nucléaire en 1932 par Mark Oliphant ; les deux découvertes ont aussi conduit au développements des armes nucléaires. 
Le développement des accélérateurs de particules après la Seconde Guerre mondiale, a permis, tout au long des années 1950 et 1960, de découvrir une grande variété de particules lors d'expériences de diffusion profondément inélastique. Il était alors question de « zoo de particules ». Ce terme est tombé en désuétude après la formulation du modèle standard durant les années 1970 dans lequel le grand nombre de particules a été expliqué comme des combinaisons d'un relativement faible nombre d'autres particules encore plus élémentaires.

La découverte du boson de Higgs a permis le consensus et la mise à jour en 2014 du tableau des composants de la matière qui avait été établi en 2005 à l'occasion de l'année mondiale de la physique.

À ce jour, la matière et l'énergie sont mieux comprises en termes de cinématique et d'interaction des particules élémentaires. Jusqu'ici, la physique avait réduit les lois régissant le comportement et l'interaction de toutes les formes connues de matière et d'énergie à un petit nombre de lois fondamentales et de théories. Un des objectifs principaux de la physique est de trouver une base commune unifiant toutes ses théories dans une théorie du tout, dans laquelle toutes les autres lois connues seraient des cas particuliers.
Bien que le modèle standard soit considéré comme une théorie autonome et cohérente, et qu'il ait eu beaucoup de succès en fournissant des prédictions expérimentales (symétrie CP ou le problème de la hiérarchie), il laisse plusieurs phénomènes inexpliqués et ne peut prétendre être une théorie du tout.
Il n'apporte ainsi pas de justification théorique à la gravitation, telle que la décrit la relativité générale, ni ne rend compte de l'accélération de l'expansion de l'univers (qui pourrait être expliquée par une énergie sombre). Ce modèle ne contient non plus aucune particule qui pourrait composer la matière noire, possédant toutes les propriétés requises par les observations cosmologiques. Il ne décrit pas non plus correctement l'oscillation des neutrinos ni leur masse.

Le modèle standard inclut les membres de plusieurs classes de particules élémentaires (les leptons, les quarks, les bosons de jauge, et le boson de Higgs), qui peuvent à leur tour être différenciées par d'autres caractéristiques, telles que leur charge de couleur.

Le modèle standard inclut douze particules élémentaires de spin ½ (spin demi-entier), qui sont donc des fermions. Selon le théorème spin-statistique, les fermions respectent le principe d'exclusion de Pauli. À chaque fermion correspond une antiparticule.

Les fermions obéissent à la statistique de Fermi-Dirac et ne peuvent pas coexister entre eux dans le même état quantique (sur la même orbitale atomique par exemple). 

Les fermions élémentaires se répartissent en leptons et en quarks, suivant trois "générations" qui ne diffèrent l'une de l'autre que par la masse, plus élevée à chaque génération. Seules les particules de première génération forment la matière ordinaire. En effet, les particules de deuxième et troisième générations sont instables et se désintègrent rapidement en particules de première génération, plus légères.

Bien qu'élémentaires, les quarks ne peuvent exister isolément. Ils sont regroupés dans des hadrons qui se présentent sous forme de paires quark-antiquark (les mésons), ou de trios de quarks (les baryons). Par exemple, les protons sont formés de deux quarks "up" et d'un quark "down", tandis que les neutrons sont formés d'un quark "up" et de deux quarks "down".

Les tableaux ci-dessous regroupent les différents leptons et quarks par génération. Pour ne pas surcharger ce tableau, les antiparticules n'y sont pas représentées. La charge électrique y est indiquée en charges élémentaires.

Dans le modèle standard, les bosons de jauge sont vecteurs ou supports de force et jouent un rôle de médiateur entre les forces fondamentales : faible, forte et électromagnétique.

Les bosons de jauge obéissent à la statistique de Bose-Einstein ; ils sont de spin entier et peuvent coexister entre eux dans le même état quantique (des milliards de photons identiques cohabitant dans un faisceau laser). 

Le boson de Higgs n'est pas un médiateur de force, et n'appartient donc pas à la classe des bosons de jauge.

Ces particules de champ peuvent être "réelles" ou " virtuelles". Dans ce dernier cas, elles ont une durée d'existence extrêmement brève et sont observées indirectement par leur action, qui consiste essentiellement à transmettre les forces fondamentales. C'est d'ailleurs pourquoi ces particules virtuelles sont aussi appelées « particules messagères » ou « médiateurs ».

Les photons « γ » (de spin 1, de masse et charge nulles) sont médiateurs de la force électromagnétique entre particules chargées électriquement.

Les bosons de jauge W, W et Z (de spin 1 et de masse élevée) sont médiateurs des interactions faibles entre les particules de différentes saveurs (tous les quarks et les leptons).

Les huit gluons (de spin 1 et de masse nulle) sont médiateurs des interactions fortes entre les particules ayant une charge de couleur (les quarks).

Le boson de Higgs (de spin 0, qui est un champ scalaire), est supposé conférer leur masse aux autres particules par un mécanisme de brisure spontanée de symétrie appelé dans ce cadre le mécanisme de Higgs.
Le CERN a annoncé le 4 juillet 2012 avec une confiance de 5 sigma (99,9999 %) avoir découvert grâce au LHC une particule d'une masse de 125,3 GeV⋅c ± 0,6. Cette particule pourrait être le boson de Higgs, mais des études plus poussées restent nécessaires pour pouvoir l'affirmer en toute certitude.

Si on compte les particules en distinguant leurs différentes couleurs et leurs antiparticules, on dénombre en tout 61 particules élémentaires.

D'un point de vue mathématique, les théories quantiques des champs ont été formalisées dans le cadre de théories de jauge à l'aide de groupes de symétrie locale prenant la forme de groupes de Lie complexes sous-tendant chacun les symétries de jauge modélisées. Ainsi :

Les dix-neuf paramètres libres du modèle standard sont les masses des neuf fermions, quatre paramètres de la matrice CKM, les constantes de couplages pour les trois forces, l'angle thêta de la chromodynamique quantique et deux paramètres de Higgs.

Le modèle standard n'est pas une théorie complète des interactions fondamentales car elle n'inclut pas la gravitation.

Parmi les multiples théories qui tentent d'unifier mécanique quantique et théorie de la relativité, il y a entre autres celle qui envisage l'existence du graviton, un hypothétique boson.

Selon Alain Connes, .

Le modèle standard ne prédit pas pourquoi il existe trois générations de fermions portant les mêmes charges, mais dans des gammes de masse très différentes. La masse du quark "u" est de l'ordre du MeV.c alors que celle du "t" est de l'ordre de .c. D'autre part, rien ne dit qu'il n'existe pas d'autres familles. En date de 2008, aucune théorie au-delà du modèle standard n'explique de manière précise l'existence de ces trois familles. L'unitarité de la matrice CKM est un test sensible de l'existence d'une autre génération de fermions.

Le lagrangien de jauge du modèle standard est composé de trois symétries internes aux particules formula_1, formula_2 et formula_3. De la même façon que pour les familles de fermions, rien n'interdit l'existence de sous-groupes de symétries. Ceci est d'ailleurs un sujet cher aux théories de grande unification, qui permettent en principe d'expliquer ces symétries en les incluant comme sous-groupes d'un groupe plus large que les trois premiers. Le groupe mathématique formula_4 aurait pu convenir et c'est sur lui que reposait la théorie de la Grande Unification ("GUT" en anglais). Mais cette symétrie de jauge compliquait le modèle standard en obligeant à postuler 24 bosons, et surtout, elle prédisait la désintégration des protons, qui n'a jamais été observée expérimentalement.

Le modèle standard intègre le fait qu'à chaque particule correspond une antiparticule. Leurs caractéristiques physiques sont quasiment identiques. Une particule et son antiparticule ont la même masse, mais des charges (baryonique et leptonique) opposées.

Le modèle ne décrit pas la matière noire dont serait composé une grande partie de l'univers.

La plus légère des hypothétiques particules supersymétriques serait un des candidats pour la matière noire.

Il reste à formuler une théorie complémentaire au modèle standard qui expliquerait pourquoi aucune de ces particules n'a été détectée jusqu'à maintenant (par le LHC ou par un autre détecteur).

Les expériences sur le volume de la charge électrique du proton donnent deux chiffres différents, et les scientifiques ne peuvent pas déterminer si l'erreur est dans les conditions de l'expérience ou si c’est la théorie elle-même qui est incomplète.

Le modèle standard suppose que les interactions des leptons chargés, c'est-à-dire les électrons, les muons et les tauons, varient uniquement du fait de leurs différences de masses. Les expériences réalisées avec les électrons et les muons ont confirmé cette hypothèse, mais des études récentes sur la désintégration du méson B impliquant le lepton tau dans les hautes énergies montrent des déviations par rapport à la théorie. Si ces résultats sont confirmés, cela pourrait ouvrir la voie à de nouvelles interactions entre les particules.




</doc>
