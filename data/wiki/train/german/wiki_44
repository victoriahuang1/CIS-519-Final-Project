<doc id="5012" url="https://de.wikipedia.org/wiki?curid=5012" title="Stochastik">
Stochastik

Als stochastisch werden Ereignisse oder Ergebnisse bezeichnet, die bei Wiederholung desselben Vorgangs nur manchmal eintreten und deren Eintreten für den Einzelfall nicht vorhersagbar ist. Die Stochastik (von "stochastikē technē", , also ‚Kunst des Vermutens‘, ‚Ratekunst‘) ist ein Teilgebiet der Mathematik und fasst als Oberbegriff die Gebiete Wahrscheinlichkeitstheorie und Mathematische Statistik zusammen.

Die historischen Aspekte werden im Artikel Geschichte der Wahrscheinlichkeitsrechnung dargestellt.

Mathematische Stochastik beschäftigt sich mit der Beschreibung und Untersuchung von Zufallsexperimenten wie zum Beispiel dem Werfen von Reißzwecken, Würfeln oder Münzen sowie vom Zufall beeinflussten zeitlichen Entwicklungen und räumlichen Strukturen.

Solche Ereignisse, Entwicklungen und Strukturen werden oft durch Daten dokumentiert, für deren Analyse die Statistik geeignete Methoden bereitstellt. In diesem Fall entstehen die zufälligen Einflüsse in der Regel im Rahmen der zufälligen Auswahl einer Stichprobe aus einer eigentlich interessierenden Grundgesamtheit.

Insgesamt beinhaltet damit die Stochastik ein Spektrum an Methoden, mit denen man sowohl die Wahrscheinlichkeit für Lottogewinne oder die Größe der Unsicherheit bei Meinungsumfragen bestimmen kann. Die Stochastik ist auch für die Finanzmathematik von Bedeutung und hilft mit ihrer Methodik beispielsweise bei der Preisfindung für Optionen.

Unter einer Prognose versteht man:

Wahrscheinlichkeiten werden mit dem Buchstaben formula_1 (von frz. "probabilité", eingeführt von Laplace) oder formula_2 dargestellt. Sie tragen keine Einheit, sondern sind Zahlen zwischen null und eins, wobei auch null und eins zulässige Wahrscheinlichkeiten sind. Deshalb können sie als Prozentangaben (20 %), Dezimalzahlen (formula_3), Brüche (formula_4), Quoten (2 von 10 beziehungsweise 1 von 5) oder Verhältniszahlen (1 zu 4) angegeben werden (alle Angaben beschreiben dieselbe Wahrscheinlichkeit).
Häufig treten Missverständnisse auf, wenn nicht richtig zwischen „zu“ und „von“ unterschieden wird: „1 "zu" 4“ bedeutet, dass dem einen gewünschten Ereignis 4 ungewünschte Ereignisse gegenüberstehen. Damit gibt es 5 Ereignisse, "von" denen eins das Gewünschte ist, also „1 "von" 5“.

Führt man ein Zufallsexperiment mehrmals hintereinander durch, so kann die relative Häufigkeit eines Ereignisses errechnet werden, indem man die absolute Häufigkeit, also die Anzahl geglückter Versuche, durch die Anzahl der unternommenen Versuche dividiert. Für eine unendliche Anzahl von Versuchen geht diese relative Häufigkeit in die Wahrscheinlichkeit über. In der Praxis wird die Anzahl der für eine annehmbare Übereinstimmung von relativer Häufigkeit und Wahrscheinlichkeit nötigen Versuche oft unterschätzt.

Dass einem Ereignis die Wahrscheinlichkeit Null zugeordnet wird, heißt nur dann, dass dessen Eintritt prinzipiell unmöglich ist, wenn es nur endlich viele verschiedene Versuchsausgänge gibt.

Dies wird durch folgendes Beispiel veranschaulicht: In einem Zufallsexperiment wird eine beliebige reelle Zahl zwischen 0 und 1 gezogen. Es wird davon ausgegangen, dass jede Zahl gleich wahrscheinlich sei – es wird also die Gleichverteilung auf dem Intervall formula_5 vorausgesetzt. Dann ist, da es in dem Intervall unendlich viele Zahlen gibt, für jede einzelne Zahl aus dem Intervall die Eintrittswahrscheinlichkeit gleich null, dennoch ist jede Zahl aus formula_5 als Ziehungsergebnis möglich.

Ein unmögliches Ereignis ist im Rahmen dieses Beispiels etwa die Ziehung der 2, also das Elementarereignis formula_7.

Ein Ereignis wird „sicher“ genannt, wenn es die Wahrscheinlichkeit 1 hat. Die Wahrscheinlichkeit, dass ein unmögliches Ereignis nicht eintritt, ist 1 und es handelt sich um ein sicheres Ereignis. Ein Beispiel für ein sicheres Ereignis beim Würfeln mit einem sechsseitigen Würfel ist das Ereignis „es wird keine Sieben gewürfelt“.

Grundsätzliche Annahmen der Stochastik sind in den Kolmogorov-Axiomen nach Andrei Kolmogorov beschrieben. Aus diesen und ihren Folgerungen lässt sich schließen, dass:

Die Wahrscheinlichkeit des Ereignisses, das alle möglichen Versuchsausgänge umfasst, ist formula_8:

Die Wahrscheinlichkeit eines unmöglichen Ereignisses ist formula_10:

Alle Wahrscheinlichkeiten liegen zwischen einschließlich null und eins:

Die Wahrscheinlichkeit des Eintretens eines Ereignisses und die seines Nichteintretens addieren sich zu Eins:

In einem vollständigen System von Ereignissen formula_14 (hierfür müssen alle formula_14 paarweise disjunkt sein und ihre Vereinigungsmenge gleich formula_16 sein) ist die Summe der Wahrscheinlichkeiten gleich formula_8:

Als Laplace-Experimente, benannt nach dem Mathematiker Pierre-Simon Laplace, werden Zufallsexperimente bezeichnet, für die die folgenden beiden Punkte erfüllt sind:

Einfache Beispiele für Laplace-Experimente sind das Würfeln, das Werfen einer Münze (wenn man davon absieht, dass sie auf dem Rand stehen bleiben kann) und die Ziehung der Lottozahlen.

Die Wahrscheinlichkeit formula_19 eines Laplace-Experimentes berechnet sich nach


Kombinatorik ist ein Teilgebiet der Mathematik, das sich mit der Bestimmung der Zahl möglicher Anordnungen oder Auswahlen von
beschäftigt. In der modernen Kombinatorik werden diese Probleme umformuliert als Abbildungen, sodass sich die Aufgabe der Kombinatorik im Wesentlichen darauf beschränken kann, diese Abbildungen zu zählen.

Die Spieltheorie ist ein Teilgebiet der Mathematik, das sich damit befasst, Systeme mit mehreren Akteuren (Spieler, Agenten) zu analysieren. Die Spieltheorie versucht dabei unter anderem, das rationale Entscheidungsverhalten in sozialen Konfliktsituationen abzuleiten.

Statistik ist eine auf Mathematik basierende Methodik zur Analyse quantitativer Daten. Dabei verbindet sie empirische Daten mit theoretischen Modellen.


Siehe auch, Anwendungsbeispiele




</doc>
<doc id="5013" url="https://de.wikipedia.org/wiki?curid=5013" title="Semitische Sprachen">
Semitische Sprachen

Die semitischen Sprachen sind ein Zweig der afroasiatischen Sprachfamilie. Sie werden heute von ca. 260 Millionen Menschen in Vorderasien, in Nordafrika und am Horn von Afrika gesprochen. Wichtige semitische Sprachen sind Arabisch, Hebräisch, die neuaramäischen Sprachen, eine Reihe von in Äthiopien und Eritrea gesprochenen Sprachen wie Amharisch und Tigrinya sowie zahlreiche ausgestorbene Sprachen des Alten Orients wie Akkadisch. Zu den semitischen Sprachen zählt auch das in Europa beheimatete Maltesische.

Die Bezeichnung „semitisch“ wurde 1781 von dem Göttinger Philologen August Ludwig von Schlözer geschaffen. Sie lehnt sich an die biblische Person Sem an, die als Stammvater der Aramäer, Assyrer, Elamiter, Chaldäer und Lyder gilt.

Ähnlichkeiten zwischen Hebräisch, Aramäisch und Arabisch fielen jüdischen Grammatikern bereits im Mittelalter auf. Als in der Renaissance auch in Europa die Beschäftigung mit orientalischen Sprachen einsetzte, verfassten christliche Hebraisten erste Ansätze zu einer vergleichenden Grammatik des Semitischen, wobei sie jedoch die unzutreffende Schlussfolgerung zogen, dass Aramäisch und Arabisch entartete Mischsprachen seien, die aus dem Hebräischen, der vermeintlichen Sprache des Paradieses, entstanden sind. Erst im 18. Jahrhundert begann sich eine neuere Betrachtungsweise durchzusetzen, als man erkennen musste, dass das Arabische, obwohl wesentlich jünger als das Hebräische und Aramäische, besonders archaische Züge aufweist.

Während das Altäthiopische bereits seit dem 16. Jahrhundert in Europa bekannt war, wurden seit dem 18. Jahrhundert weitere Sprachen entdeckt, die als semitisch identifiziert werden konnten: die modernen äthiosemitischen Sprachen, das Akkadische, das Altsüdarabische, epigraphische Zeugnisse antiker Sprachen in Syrien und Palästina und schließlich auch die modernen arabischen, aramäischen und neusüdarabischen Dialekte sowie erst 1928 das Ugaritische. Besonders die Entdeckung und Erschließung des Akkadischen hatte für die Semitistik nachhaltige Folgen, da es trotz seines hohen Alters von den damaligen Ansichten über das Protosemitische stark abweicht. Als letzte semitische Sprache wurde 1975 das Eblaitische entdeckt.

Im 19. Jahrhundert wurden auch die Beziehungen zu anderen Sprachfamilien in Afrika und damit die afroasiatische Sprachfamilie entdeckt, wodurch sich für das Verständnis des Semitischen neue Perspektiven ergaben.

Im Altertum waren die semitischen Sprachen noch im Wesentlichen auf das Gebiet des Vorderen Orients beschränkt. Seit dem 1. Jahrtausend v. Chr. erlebten sie dann eine räumliche Verbreitung auf den afrikanischen Kontinent, als in Äthiopien und dem heutigen Eritrea semitische Sprachen auftauchten − falls dies nicht schon viel früher geschehen war − und sich das Arabische durch die Islamische Expansion im 7. Jahrhundert über ganz Nordafrika und Teile Südeuropas, insbesondere die Iberische Halbinsel, verbreitete. Heute umfasst das semitische Sprachgebiet Vorderasien, das Horn von Afrika, Nordafrika und mit der Insel Malta sogar einen kleinen Teil Europas. Zahlreiche geografische Namen zeugen auf der Iberischen Halbinsel vom arabischen Erbe dieser Region.

Im Mesopotamien ist ab dem 3. Jahrtausend v. Chr. das Akkadische überliefert. Als Sprache der internationalen Korrespondenz wurde es bis nach Ägypten benutzt. Ein Dialekt des Akkadischen war das in Syrien gesprochene Eblaitische. Im Laufe des 1. Jahrtausends v. Chr. wurde das Akkadische als gesprochene Sprache vom Aramäischen verdrängt, konnte sich aber noch bis in die ersten Jahrhunderte n. Chr. als Schriftsprache halten.

Bruchstückhaft ist das Amurritische überliefert, das nur durch die Personennamen der Amurriter aus der Zeit zwischen 2000 und 1500 v. Chr. bekannt ist. Aus Syrien ist das Ugaritische durch umfangreiche Inschriftenfunde aus der Zeit zwischen 1400 und 1190 v. Chr. überliefert. In Kanaan sprach man im Altertum die kanaanäischen Sprachen. Hierzu gehörte das Hebräische, die Sprache der Israeliten und Judäer, in der das Alte Testament verfasst ist. Als gesprochene Sprache befand es sich seit der Mitte des 1. Jahrtausends v. Chr. auf dem Rückzug und starb wahrscheinlich im 2./3. Jahrhundert n. Chr. aus. Doch diente es weiterhin als Sakralsprache des Judentums sowie zur Verständigung zwischen jüdischen Gemeinden in aller Welt. Im Mittelalter diente es teilweise als Zwischenstufe für Übersetzungen aus dem Arabischen in das Lateinische. Das Phönizische wurde ursprünglich im heutigen Libanon (Tyros, Byblos, Sidon) von den Phöniziern gesprochen und gehört ebenfalls zum Kanaanäischen. Durch die phönizische Kolonisation verbreitete sich die Sprache in Form des Punischen nach Nordafrika, vor allem Karthago und weiter bis in das heutige Spanien. Dort blieb es bis in das 6. Jahrhundert n. Chr. in Gebrauch. Kleinere, nur durch wenige Inschriften belegte kanaanäische Sprachen waren Moabitisch, Ammonitisch und Edomitisch. Die Unterschiede zwischen einzelnen kanaanäischen Sprachen scheinen sehr gering gewesen zu sein, sodass gelegentlich von einer einzigen Sprache ausgegangen wird, die lediglich zu Dialekten und Soziolekten ausdifferenziert war.

Das seit dem 10./9. Jahrhundert v. Chr. belegte Aramäisch war ursprünglich nur in den Stadtkönigreichen Syriens verbreitet. Die Sprachform jener Zeit bezeichnet man als Altaramäisch. Nachdem die aramäischen Königreiche im 8. Jahrhundert v. Chr. von den Assyrern erobert worden waren, wurde das Aramäische in Form des Reichsaramäischen zur Verwaltungssprache zunächst im Neuassyrischen Reich sowie später im Neubabylonischen Reich (610–539 v. Chr.) und im persischen Achämenidenreich (539–333 v. Chr.). Dadurch verbreitete es sich im gesamten Vorderen Orient als Lingua franca. Durch die islamische Expansion wurde das Aramäische zurückgedrängt, doch blieb es sowohl für das Judentum (durch die Targum-Tradition und vor allem den Palästinischen und den Babylonischen Talmud) als auch für das Christentum (etwa durch die Peschitta der Orientalischen Kirchen und als Kirchensprache orientalischer Christen) bedeutsam.

Die Stämme der Arabischen Halbinsel gehörten im Altertum unterschiedlichen Sprachgruppen an. Im Norden war das Frühnordarabische mit mehreren Dialektgruppen verbreitet. Es ist seit etwa dem 8. Jahrhundert v. Chr. schriftlich überliefert und starb während der Ausbreitung des Islams aus. Die antike Sprache Zentralarabiens war eine frühe Form des heutigen Arabisch. Als Sprache des Korans gewann sie mit der Ausbreitung des Islams schnell an Bedeutung und verdrängte auch die antiken Sprachen im heutigen Jemen, darunter das Altsüdarabische und möglicherweise andere, kaum belegte Sprachen wie das Himjarische.

Spätestens seit dem 1. Jahrtausend v. Chr. wurden auch im Bereich der heutigen Staaten Äthiopien und Eritrea semitische Sprachen gesprochen. Bereits in der Antike spalteten sie sich in einen nördlichen und einen südlichen Zweig. Der nördliche Zweig weist in Form des Altäthiopischen unter den äthiopischen Sprachen die längste Schrifttradition auf. Altäthiopisch war die Sprache des Aksumitischen Reiches (etwa 1. bis 7. Jahrhundert n. Chr.) und später die Sakralsprache der äthiopischen Christen.

Heute ist das Arabische mit ca. 230 Millionen Sprechern mit Abstand die größte aller semitischen Sprachen und eine der größten Sprachen der Welt. Ihr Verbreitungsgebiet erstreckt sich von Mauretanien bis nach Oman. In insgesamt 25 Staaten der Arabischen Welt dient es als Amtssprache. Die arabischsprachigen Länder befinden sich in einer ausgeprägten Diglossie-Situation: Während die arabische Schriftsprache auf dem klassischen Arabisch des 8. Jahrhunderts beruht, dienen als Umgangssprache die regional unterschiedlichen arabischen Dialekte (auch: Neuarabisch). Auch das Maltesische, die einzige in Europa beheimatete semitische Sprache, geht auf einen arabischen Dialekt zurück; aufgrund der katholisch-europäischen Tradition Maltas wird es in lateinischen Buchstaben geschrieben und unterliegt keinen hocharabischen Einflüssen mehr. Als Sprache des Korans hat das Arabische auch in nicht arabischsprachigen Ländern der islamischen Welt Verbreitung erfahren und die autochthonen Sprachen insbesondere im Wortschatz maßgeblich geprägt. Arabische Lehnwörter sind im Türkischen und Persischen allgegenwärtig und ähnlich häufig wie die lateinischen in den europäischen Sprachen. Heute gibt es migrationsbedingt in zahlreichen Staaten Europas arabischsprachige Minderheiten, vor allem in Frankreich, den Niederlanden und Belgien.

Trotz seiner weitaus kleineren Sprecherzahl nimmt das Hebräische durch die Bedeutung, die ihm als Jahrtausende verwendete jüdische Kultur- und Literatursprache zukommt, eine bemerkenswerte Position ein. Auch in christlichen Kreisen wurde es als Sprache des Alten Testaments seit dem Mittelalter erforscht und studiert. Seit dem 19. Jahrhundert, insbesondere im Zuge des Zionismus, belebten jüdische Intellektuelle das Hebräische zu einer alltagstauglichen Umgangssprache (Ivrit), die 1948 zusammen mit Arabisch Amtssprache des Staates Israel wurde und schon zuvor eine der offiziellen Sprachen des britischen Mandatsgebiets Palästina war. Heute wird Hebräisch in Israel von etwa sieben Millionen Menschen als Erstsprache oder weitere Sprache (nach Arabisch, Russisch, Äthiopisch o. a.) verwendet; nur schätzungsweise die Hälfte der Hebräischsprecher in Israel sind Muttersprachler. Auch nach der Räumung palästinensischer Gebiete durch Israel ist das Hebräische dort als Verkehrssprache gebräuchlich, wenigstens im Kontakt mit Israel. In der jüdischen Diaspora (besonders in Westeuropa, Nord- und Südamerika) wird es als Religionssprache und Sprache des jüdischen Volkes gepflegt, sodass außerhalb Israels von mehreren zehn- oder sogar hunderttausend Personen ausgegangen werden kann, die über kommunikative Kompetenz in dieser Sprache verfügen.

Obwohl das Aramäische viel von seiner einstigen Bedeutung verloren hat, hat es als gesprochene Sprache bis heute überlebt, etwa in der Osttürkei, dem Irak und dem Iran (Aserbaidschan). Insgesamt gibt es über Vorderasien verstreut ca. 500.000 Aramäischsprachige. Ihre Zahl dürfte durch den von Repression, Krieg und Emigration geprägten demografischen Wandel im 20. und zu Beginn des 21. Jahrhunderts (nach dem Ersten Weltkrieg Christenverfolgungen unter türkischer Herrschaft, der Irakkrieg und seine Folgen etc.) stark rückläufig sein. Hingegen sind Exilgemeinden in Nord- und Westeuropa (etwa in Gütersloh/Westfalen und Södertälje/Schweden) und Nordamerika gewachsen, in denen die aramäischen Mundarten als Haus-, Familien- und Gemeindesprache bisher überleben. Das Neuwestaramäische wird noch von ca. 10.000 Menschen in drei Dörfern in Syrien gesprochen. Zu den neuostaramäischen Sprachen gehören unter anderem Turoyo (schätzungsweise 50.000 Sprecher im Nahen Osten) und Neumandäisch. In der Regel gehören die Aramäischsprecher christlichen Kirchen an, in denen ältere Sprachformen des Aramäischen als Sakralsprache verwendet werden oder wurden. Da kein eigenes Bildungssystem besteht, das Aramäisch als moderne Hochsprache etablieren und ausbauen könnte, sind die meisten modernen Varietäten des Aramäischen schriftlos; in Syrien gab es um 2010 eine staatliche Initiative, die Mundart des Aramäerdorfes Maalula mit dem heute als hebräisch bekannten Alphabet zu verschriftlichen. Die Quadratschrift, die heutige hebräische Druckschrift, basiert auf einem reichsaramäischen Alphabet, das in der Antike die althebräische Schrift ersetzt hat. Auch jüdische Minderheiten, etwa die kurdischen Juden, haben lokale Formen des Aramäischen als Muttersprache. Infolge der Emigration nach Israel in den 1950/60er Jahren und durch die Umstellung auf das Hebräische im israelischen Alltag und Bildungswesen muss angenommen werden, dass es nur noch wenige jüngere Sprecher jüdisch-aramäischer Dialekte gibt. Trotzdem führte der staatliche israelische Rundfunk Kol Israel in seinem Einwandererprogramm noch 2011 eine tägliche Sendung auf Aramäisch ein.

Im Süden der Arabischen Halbinsel, Jemen und Oman spricht man die neusüdarabischen Sprachen. Diese sind trotz ihres Namens weder mit dem Altsüdarabischen noch dem (Nord-)Arabischen näher verwandt, sondern bilden einen eigenständigen Zweig der semitischen Sprachen. Die sechs neusüdarabischen Sprachen Mehri, Dschibbali, Harsusi, Bathari, Hobyot und Soqotri haben insgesamt ca. 200.000 Sprecher, die größte Sprache ist Mehri mit 100.000 Sprechern.

In Äthiopien und Eritrea ist eine größere Zahl semitischer Sprachen vom Zweig der äthiosemitischen Sprachen verbreitet, die insgesamt von ca. 29 Millionen Menschen gesprochen werden. Die größte äthiosemitische Sprache und zweitgrößte semitische Sprache überhaupt ist Amharisch, die Nationalsprache Äthiopiens, die ca. 20 Millionen Menschen sprechen. Tigrinya ist neben Arabisch Amtssprache in Eritrea und hat etwa sieben Millionen Sprecher. Neben diesen werden die verschiedenen Gurage-Sprachen im südlichen Zentraläthiopien von ungefähr 1,9 Millionen Menschen gesprochen. Ebenfalls in Eritrea verbreitet ist Tigre (0,8 Millionen Sprecher). Auch in Israel lebt seit der Massenemigration äthiopischer Juden in den 1980er Jahren eine äthiopischsprachige Minderheit. Als aus der jüdischen Diaspora importierte Sprache ist sie dort durch die Verwaltungs- und Bildungssprache Hebräisch ähnlich bedroht wie Jiddisch, Judenspanisch, Jüdisch-Aramäisch, Russisch, Französisch u. a.

Die interne Klassifikation der semitischen Sprachen ist noch nicht abschließend geklärt. Die semitischen Sprachen werden in zwei Hauptzweige eingeteilt: Ost- und Westsemitisch. Das Ostsemitische besteht aus dem Akkadischen und dem nah verwandten Eblaitischen. Der Hauptunterschied zwischen diesen beiden Zweigen liegt darin, dass die Suffixkonjugation im Ostsemitischen (wahrscheinlich im Einklang mit dem Protosemitischen) einen Zustand ausdrückt, während dieselbe Form im Westsemitischen die Funktion des Perfekts hat. Traditionell wurde das Westsemitische – vornehmlich nach geografischen Kriterien – weiter in die nordwestsemitischen Sprachen (Kanaanäisch, Aramäisch, Ugaritisch) und die südsemitischen Sprachen (Arabisch, Altsüdarabisch, Neusüdarabisch, Äthiopisch) unterteilt. Somit ergäbe sich folgende Struktur:

Diese Klassifikation stellte Robert Hetzron ab 1969 durch die Einbeziehung des Konzepts der „gemeinsamen Innovation“ ("shared innovation") erheblich in Frage. Eine zentrale Rolle kommt dabei der Stellung des Arabischen zu. Tatsächlich hat das Arabische mit den übrigen traditionell als südsemitisch zusammengefassten Sprachen drei auffällige Merkmale gemeinsam: Das Vorhandensein der inneren Pluralbildung, den Lautwandel von ursemitischem "*p" zu "f" und einen durch Vokaldehnung gebildeten Verbalstamm (Arabisch "qātala" sowie mit t-Präfix "taqātala"). Laut Hetzron erfüllen diese Gemeinsamkeiten nicht das Kriterium der genetischen Verwandtschaft, da der Lautwandel "*p" > "f" ein "areal feature" und die innere Pluralbildung ein ursemitisches Phänomen sei, das in den übrigen Sprachen ersetzt wurde. Hingegen teile das Arabische mit den nordwestsemitischen einige Innovationen im Verbalsystem. Hierzu gehört die Imperfektform "yaqtulu", während das Äthiopische und Neusüdarabische eine Form aufweisen, die auf das ursemitische "*yaqattVl" zurückgeht. Daher fasst Hetzron das Arabische und Nordwestsemitische zu einem zentralsemitischen Unterzweig zusammen. Die Frage der Klassifikation des Arabischen ist bislang nicht eindeutig geklärt, in der Forschung gewinnt jedoch Hetzrons Gliederung an Zustimmung.

In jüngster Zeit wurden weitere Modifikationen von Hetzrons Modell vorgeschlagen: Das Altsüdarabische weist offenbar auch eine Imperfektform vom Typ "*yaqtulu" auf und wäre somit ebenfalls dem Zentralsemitischen zuzuordnen. Zudem wird die Existenz eines südsemitischen Zweigs gänzlich in Frage gestellt: Weil die Imperfektform "*yaqattVl" als gemeinsames Merkmal der beiden verbliebenen Unterzweige keine gemeinsame Innovation, sondern eine Konservation darstellt, müssten das Neusüdarabische und Äthiopische als jeweils eigenständige Unterzweige des Westsemitischen angesehen werden. Somit ergibt sich für die Klassifikation der semitischen Sprachen folgende Struktur:

Die Einordnung des Himjarischen ist ungewiss, da zu wenige Daten zu seiner Einordnung vorliegen; es handelt sich zwar allem Anschein nach um eine semitische Sprache, aber sie muss unklassifiziert bleiben, und nur zusätzliche Texte könnten diese Situation verbessern.


Semitische Sprachen sind seit dem 3. vorchristlichen Jahrtausend in schriftlicher Form überliefert. Für das Akkadische wurde seit dem 3. Jahrtausend v. Chr. die von den Sumerern übernommene mesopotamische Keilschrift, hauptsächlich eine Silbenschrift, angewendet. Zum Schreiben westsemitischer Sprachen dienten dagegen seit den frühesten Zeugnissen aus der ersten Hälfte des 2. Jahrtausends v. Chr. alphabetische Schriften. Deren Wurzel war vermutlich die protosemitische Schrift, die über die phönizische Schrift zum Ursprung nicht nur aller semitischen Alphabete, sondern auch zahlreicher anderer Alphabetschriften wurde. Eine Sonderstellung nahm dabei die ugaritische Schrift ein, die formal eine Keilschrift, tatsächlich aber ein Konsonantenalphabet war.

Die alphabetischen Schriften waren ursprünglich reine Konsonantenschriften, so dass die meisten Vokale in ausgestorbenen semitischen Sprachen unbekannt bleiben. Seit dem 1. Jahrtausend n. Chr. wurden einige Systeme jedoch zur Vokalbezeichnung erweitert. Die äthiopische Schrift entwickelte eine sekundäre Vokalbezeichnung durch angefügte Kreise und Striche. In anderen jüngeren Alphabeten wurde eine Vokalbezeichnung durch über- oder untergesetzte Elemente eingeführt, die im Hebräischen als Nikud („Punktierung“) bezeichnet werden.

Das Semitische ist einer der sechs Primärzweige der in Nordafrika und dem Vorderen Orient verbreiteten afroasiatischen Sprachfamilie, zu der neben dem Semitischen auch das Ägyptische, Kuschitische, Berberische, Omotische und Tschadische gehören. Mit etwa 260 Millionen Sprechern ist es der meistgesprochene Hauptzweig des Afroasiatischen. Mit anderen afroasiatischen Sprachfamilien hat es nicht nur einen Teil des Lexikons gemein, sondern auch wesentliche strukturelle Eigenschaften wie die Wurzelmorphologie, die Verbalkonjugation, das Kasussystem, das Lautsystem sowie die Personalpronomina. Die folgende Tabelle bietet einige Beispiele für Parallelen mit den anderen Hauptzweigen des Afroasiatischen:

Der in allen Zweigen des Semitischen zu findende Wortschatz enthält insbesondere typische Wörter des Grundwortschatzes: Bezeichnungen für Verwandtschaftsverhältnisse, Körperteile, Tiere, Bestandteile der Welt („Himmel“, „Wasser“) sowie wichtige Adjektive („groß“, Farben) und Wörter aus Religion und Mythologie. Die folgende Liste nennt einige Beispiele für gemeinsemitische Wörter:

Das gemein-semitische Konsonanteninventar umfasst 29 Phoneme, die sich lediglich im Altsüdarabischen und einem Teil des Frühnordarabischen noch in dieser Zahl finden, das klassische Arabisch folgt mit 28 erhaltenen konsonantischen Phonemen, im Akkadischen sind diese hingegen zu nur noch 17 Lauten zusammengefallen. Das semitische Konsonanteninventar teilt einige wesentliche Charakteristika mit anderen Primärzweigen des Afroasiatischen: es finden sich durch Glottalisierung oder Pharyngalisierung gebildete „emphatische“ Konsonanten, die mit stimmhaften und stimmlosen Konsonanten häufig triadische Gruppen bilden; auch die Existenz zweier pharyngaler sowie – heute allerdings auf das Neusüdarabische beschränkt – lateraler Konsonanten ist kennzeichnend. Wenngleich die Anzahl und die Entwicklung der protosemitischen Konsonanten gesichert ist, wird deren Realisierung diskutiert. Die folgende Tabelle stellt eine mögliche neuere Rekonstruktion dar (in Klammern steht die auf dem Arabischen und Hebräischen beruhende konventionelle Transkription):

Für das Proto-Semitische werden unumstritten die Vokale "a", "i" und "u" sowie ihre langen Gegenstücke "ā", "ī", "ū" rekonstruiert. Dieses System hat sich jedoch nur in sehr wenigen Sprachen, wie dem klassischen Arabisch, vollständig erhalten, während in den meisten semitischen Sprachen teilweise erhebliche Veränderungen eingetreten sind. Diphthonge waren im Proto-Semitischen zwar durch die starken Beschränkungen des Silbenbaus unmöglich, doch wurden vermutlich wie im klassischen Arabisch Kombinationen aus "a" und den Halbvokalen "w" und "y" als Diphthonge realisiert. Vor allem in den modernen semitischen Sprachen werden diese Kombinationen monophthongisiert, vergleiche arabisch "ʿayn-" − akkadisch "īnu-" „Auge“, arabisch "yawm-" − hebräisch "yōm" „Tag“.

In den semitischen Sprachen sind ursprünglich nur Silben der Form Konsonant-Vokal (CV; offene Silbe) und Konsonant-Vokal-Konsonant (CVC; geschlossene Silbe) erlaubt. Falls durch Schwund eines Vokales ein Wort gegen diese Gesetze verstößt, kann in Tochtersprachen ein Sprossvokal eingefügt werden: arabisch "ʾuḏn-u-" „Ohr“ − hebräisch "ʾōzæn". Es ist umstritten, ob im Proto-Semitischen einige Konsonanten auch wie Vokale silbenbildend auftreten konnten, etwa in *"bn̩-" „Sohn“ > arabisch "ʾibn-", akkaddisch "bin-".

Grundlage der Morphologie und des Lexikons ist – wie für das Afroasiatische typisch – die aus einer Folge von in der Regel drei Konsonanten, den Radikalen, bestehende Wurzel, die ausschließlich lexikalische, aber keine grammatische Information enthält. Durch die Anfügung weiterer Morpheme können hiervon Wörter und Wortformen gebildet werden. Diese Morpheme, die auch als "Schema" bezeichnet werden, können Affixe, Infixe und insbesondere eine Folge von Vokalen sein, sodass die Wurzel für einen Begriff, das Schema dagegen für ein Wort sowie dessen grammatische Form kennzeichnend ist. Dies möge die folgende Auflistung von Formen der Wurzel "ktb" „schreiben“ im Arabischen illustrieren:

Wurzeln, die "y" oder "w" als Stammkonsonant haben und solche, deren letzte beiden Konsonanten identisch sind, werden – in Einzelsprachen mit gewissen anderen Gruppen – als "schwache Wurzeln" bezeichnet; sie weisen bei der Formenbildung diverse Unregelmäßigkeiten auf. Eine weitere Ausnahme stellen neben Pronomina und diversen Partikeln auch einige zweikonsonantige Substantive dar, beispielsweise *"dam-" „Blut“, *"yam-" „Meer“. Ihre abweichende Struktur ist auf ihr hohes sprachgeschichtliches Alter zurückzuführen.

Nach einer auf das 19. Jahrhundert zurückgehenden Theorie sind viele oder alle dreikonsonantigen Wurzeln des Semitischen auf ursprünglich zweikonsonantige Formen aufgebaut. Als Indizien werden insbesondere die schwachen Wurzeln angeführt, die ihren Halbvokal in bestimmten Formen verlieren, Wurzeln der Form CCC; sowie Wurzeln ähnlicher Bedeutung, die zwei Konsonanten gemeinsam haben. So finden sich im Hebräischen die Verben "qṣṣ" „abschlagen, abschneiden“, "qṣh" „abschlagen, abschneiden“, "qṣb" „abschneiden“, "qṣp" „reißen, brechen“, "qṣʿ" „einschneiden“, "qṣr" „abschneiden“, die alle mit "qṣ-" beginnen und in ihrer Bedeutung mit „schlagen, schneiden“ verwandt sind. Zusätzlich hat das Arabische die Verben "qṣm" "(zusammen)brechen" und "qṣl" "abschneiden, maqṣala = Guillotine"

Im Bau der Wurzeln finden sich wie im Ägyptischen und Berberischen Beschränkungen, die das Auftreten ähnlicher und identischer Konsonanten betreffen. So sind Wurzeln mit identischem ersten und zweiten Radikal unmöglich, darüber hinaus kommen verschiedene Konsonanten, die den gleichen Artikulationsort haben, nicht gleichzeitig in einer Wurzel vor.

Jedes Substantiv gehört einem der beiden Genera Maskulinum oder Femininum an. Während das Maskulinum generell unmarkiert ist, findet sich als Femininmarker die Endung -"(a)t". Eine Ausnahme stellen einige unmarkierte Nomina dar, die sich dennoch wie feminine Substantive verhalten. Dieses Phänomen findet sich insbesondere bei Substantiven mit weiblichem natürlichen Geschlecht (*"ʾimm-" „Mutter“) und Namen für Körperteile, die doppelt vorkommen (*"ʾuḏn-" „Ohr“).

Für das Proto-Semitische lassen sich die drei Numeri Singular, Dual und Plural rekonstruieren. Singular und Dual werden durch ihre Kasusendungen gekennzeichnet, die Bildung des Plurals ist dagegen wesentlich komplexer. Hier lassen sich prinzipiell zwei Bildungsarten unterscheiden: der im Südsemitischen einschließlich des Altsüdarabischen und Arabischen vorherrschende "Innere Plural" ("gebrochener Plural") und der vor allem in den übrigen Sprachen auftretende "Äußere Plural". Der äußere Plural wird vorrangig durch seine von Singular und Dual abweichenden Kasusendungen markiert (siehe das Kapitel zu den Kasus), wogegen zur Bildung des stets als Singular deklinierten inneren Plurals das Vokalschema des Singulars durch ein anderes Schema ersetzt wird: arabisch "bayt" „Haus“ – "buyūt" „Häuser“, "raǧul" „Mann“ – "riǧāl" „Männer“. Eine zweite Bildungsart des maskulinen äußeren Plurals stellt eine Endung "-ān" dar, vergleiche akkadisch "šarr-ān-u" „Könige“ neben dem gleichbedeutenden "šarr-ū". In vielen Fällen tritt bei der Pluralbildung eine Genuspolarität auf. Dabei wird zu einem maskulinen Singular ein femininer äußerer Plural gebildet: akkadisch "lišān-u-m" „Zunge“ – "lišān-āt-u-m" „Zungen“. Im Akkadischen, Arabischen und Ugaritischen findet sich der Dual zur allgemeinen Bezeichnung der Zweizahl. In den meisten Sprachen ist er dagegen auf paarweise vorkommende Dinge beschränkt, beispielsweise Körperteile wie im hebräischen Dual "yāḏ-ayim" „die (beiden) Hände“.

In mehreren semitischen Sprachen finden sich drei Kasus, die je nach Numerus unterschiedliche Endungen aufweisen. Da die Endungen sowohl im Akkadischen als auch in zwei zentralsemitischen Sprachen (klassisches Arabisch und Ugaritisch) weitgehend übereinstimmend vollständig überliefert sind, können sie wohl auf das Protosemitische zurückgeführt werden. In einigen anderen Sprachen sind zumindest Reste des Systems erhalten. Ihre rekonstruierten protosemitische Formen sind:

Der Nominativ dient als Subjektskasus, als Prädikat eines Satzes mit nominalem Prädikat, sowie als Zitierform. Der Genitiv markiert Possessoren und das Objekt von Präpositionen, während der Akkusativ Objekte von Verben und adverbiale Nominalphrasen markiert: akkadisch "bēl bīt-i-m" „der Herr des Hauses“ (Genitiv), arabisch "qatala Zayd-u-n ʿAmr-a-n" „Zayd (Nominativ) hat Amr (Akkusativ) getötet“, arabisch "yawm-a-n" „eines Tages“ (Akkusativ).

Weitere, vor allem im Akkadischen zu findende, Kasus sind der Lokativ auf -"u" und ein hauptsächlich adverbialer Kasus auf -"iš", die jedoch beide nur beschränkt produktiv sind.

Allen semitischen Sprachen ist gemeinsam, dass das Substantiv je nach seiner syntaktischen Umgebung in mehrere "Status" treten kann, die gewisse formale Unterschiede aufweisen. Für das Proto-Semitische lassen sich vermutlich zwei Status rekonstruieren: frei und an einen folgenden Genitiv (substantivisch oder pronominal) gebunden ("Status constructus"). Freie Substantive unterschieden sich von Substantiven im Status Constructus durch eine der beiden Endungen *-"n" und *-"m", die nach den arabischen Buchstabennamen für "m" und "n" als Mimation (-"m") und Nunation (-"n") bezeichnet werden.

Für das Proto-Semitische lassen sich keine Mittel zur Unterscheidung von Determination und Indetermination rekonstruieren. Viele semitische Sprachen haben jedoch formale Mittel hierzu entwickelt. Einige Sprachen greifen hierzu auf Nunation und Mimation zurück, meist wurden aber neue Suffixe oder Präfixe entwickelt. Die folgende Tabelle bietet Beispiele aus einigen semitischen Sprachen:

Nach Josef Tropper lassen sich die Formen des Artikels im Zentralsemitischen sämtlich auf die Grundform *"han-" zurückführen, die auf einer deiktischen Partikel beruhe.

Im Semitischen können Personalpronomina je nach ihrer syntaktischen Stellung in mehreren unterschiedlichen Formen auftreten. Im Klassisch-Arabischen lauten sie:

Die unabhängigen Pronomina stehen als Subjekt von Sätzen, etwa in arabisch "huwa raǧulun" „er (ist) ein Mann“. Enklitische Formen werden an ein Bezugswort suffigiert; dieses kann eine Verbform, ein Substantiv im Status constructus oder eine Präposition sein. Hinter Verbformen und Präpositionen drücken sie deren Objekt aus: arabisch "daʿā-hu" „er rief ihn“, während sie mit Substantiven ein Besitzverhältnis angeben: akkadisch "šum-šu" „sein Name“. Einige semitische Sprachen verfügen zusätzlich über eine auch außerhalb des Semitischen zu findende Reihe absoluter Pronomina wie akkadisch "kâti" „dich“, die mit einem Suffix -"t" gebildet sind. Im Akkadischen, im Altsüdarabischen, wo sie als adjektivische Demonstrativpronomina auftreten, und im Ugaritischen stehen sie als oblique Formen, während das Phönizische sie im Nominativ verwendet. Isoliert stehen einige weitere nur im Akkadischen zu findende Bildungen.

Die Kardinalzahlen weisen besonders bei den niedrigeren Zahlen eine große Konsistenz auf, es fallen jedoch in einzelnen Sprachen Neubildungen für „eins“ und „zwei“ auf. Kardinalzahlen treten sowohl im Maskulinum als auch – durch die Endung protosemitisch -"at" markiert – im Femininum auf. Für Kardinalzahlen von drei bis zehn gilt die Regel der "umgekehrten Polarität", das heißt weibliche Formen der Zahlwörter werden mit männlichen Formen des Nomens verbunden und umgekehrt. Insofern sind sie mit ihrem Bezugswort morphologisch genusinkongruent (zum Beispiel arabisch "ṯalāṯ-at-u ban-īna" „drei Söhne“,"ṯalāṯ-u banāt-i-n" „drei Töchter“).

Diese (mit einigen Ausnahmen, zum Beispiel Äthiosemitisch oder Ugaritisch) in allen semitischen Sprachen geltende Regel der morphologischen Genusopposition geht auf das Protosemitische zurück. Ihr Ursprung ist nicht endgültig geklärt, obwohl verschiedene Erklärungsversuche vorliegen. So wurde beispielsweise vorgeschlagen, die Endung -"at" habe ursprünglich nicht das Femininum, sondern das nomen unitatis (Individualbezeichnung, abgeleitet von einem Grundwort, das Kollektivum oder Gattungsbezeichnung ist) und damit die Zählbarkeit markiert. Die Ordinalia werden als Adjektive gebildet und sind mit ihrem Bezugswort regelmäßig genuskongruent.

In allen semitischen Sprachen existiert eine Konjugation mittels präfigierter und teilweise suffigierter Personalmarkierungen. Im Akkadischen finden sich drei derartige Tempora/Aspekte (Präsens, Präteritum und „Perfekt“), die sich durch eine unterschiedliche Stammvokalisation unterscheiden. Im Äthiosemitischen und im Neusüdarabischen findet sich ein eigener Imperfekt-Indikativ-Stamm, der dem akkadischen Präsens ähnelt, während der Stamm -CCVC- die Funktion eines Subjunktivs übernimmt. In den zentralsemitischen Sprachen wird dagegen ausschließlich das Imperfekt auf diese Weise konjugiert, dessen Stamm die Form -CCVC- aufweist und somit mit dem akkadischen Präteritumstamm formal identisch ist ("qtl" „töten“, "prs" „schneiden“):

Vermutlich ist für das Protosemitische (und möglicherweise auch das Proto-Afroasiatische) ein Präsens *"ya-CaCCVC" und ein Präteritum *"ya-CCVC" zu rekonstruieren. Hierfür spricht auch die vereinzelte Vergangenheitsbedeutung des „zentralsemitischen“ Imperfekts.

In mehreren zentralsemitischen Sprachen und im Neusüdarabischen gibt es ein Passiv, das durch ein abweichendes Ablautmuster gebildet wird (klassisches Arabisch "ya-qtul-" „er tötet“, "yu-qtal-" „er wird getötet“) und im Zentralsemitischen auch mehrere (ursprünglich) durch Suffixe gebildete Modi.

Mit dem Stamm der Präfixkonjugation *"ya-CCVC" verwandt ist der Imperativ, der im Singular Maskulinum endungslos ist und im Singular Femininum und im Plural durch vokalische Endungen markiert wird, so bildet das Arabische zu "ya-qtul-u" „er tötet“ Imperative wie "ʾuqtul" „töte!“ (maskulin), "ʾuqtul-na" „tötet!“ (feminin).

Allen semitischen Sprachen ist ein weiterer Satz von Personalaffixen gemeinsam, der in der Verwendung jedoch wesentliche Unterschiede aufweist. Im Akkadischen kann er an jedes Substantiv oder Adjektiv angefügt werden und damit einen zeitlich nicht näher definierten Zustand ausdrücken: "zikar" (= "zikar-∅") „er ist/war ein Mann“, "damq-āku" „ich bin/war gut“. In den westsemitischen Sprachen dient dieser Satz von Endungen dagegen mit einem Verbalstamm der Form CaCVC- als Tempus/Aspekt analog zur Präfixkonjugation, meist zum Ausdruck des Perfekts: arabisch "qatal-a" „er tötete“, Altäthiopisch "nägär-ku" „ich habe gesagt“. Es wird gemeinhin angenommen, dass der im Akkadischen zu findende Zustand im Wesentlichen auch dem Proto-Semitischen zugeschrieben werden kann. Das gesamte Paradigma lautet:

Es fällt auf, dass die Endungen der 1. und 2. Person Singular und der 2. Person Plural, die im Protosemitischen wie im Akkadischen teils "t", teils "k" enthielten, in südlichen Sprachen (Äthiosemitisch, Altsüdarabisch, Neusüdarabisch) nach "k" und in den anderen zentralsemitischen Sprachen (außerhalb des Altsüdarabischen) dagegen nach "t" hin vereinheitlicht wurden.

Vom meist dreikonsonantigen "Grundstamm" des Verbs lassen sich mehrere Verbalstämme ableiten, die mit diesem in ihrer Bedeutung in Bezug stehen. Als Bildungsmittel dienen Affixe, Vokaldehnung und Gemination. Die folgenden Beispiele stammen aus dem Akkadischen; sie finden sich in anderen semitischen Sprachen in sehr ähnlicher Form wieder.

Einzelne abgeleitete Stämme lassen sich auch miteinander kombinieren, besonders stark ist dies im Südsemitischen ausgebildet. So lassen sich im Altäthiopischen von dem Intensivstamm "qättälä" drei weitere abgeleitete Stämme (jeweils die 3. Person Singular maskulinum der Suffixkonjugation) bilden:

Das aktive Partizip des Grundstamms weist in allen semitischen Sprachen Formen auf, die auf protosemitisches *"CāCiC" zurückgehen. Im akkadischen Verbaladjektiv und dem westsemitischen Perfekt hat sich außerdem wohl ein Verbaladjektiv der Form *"CaCVC" erhalten, das ursprünglich bei transitiven Verben passive, bei intransitiven Verben dagegen aktive Bedeutung hatte. In den abgeleiteten Stämmen weisen die Partizipien ein Präfix "ma-" oder "mu-" auf.

Für den Infinitiv sind in den Einzelsprachen verschiedenartige Schemata in Gebrauch, was sich wohl auch auf das Proto-Semitische übertragen lässt.

Sätze, deren Prädikat eine finite Verbform ist, haben im Westsemitischen vorwiegend die Stellung Verb – Subjekt – Objekt (VSO): arabisch "ḍaraba Zayd-u-n ʿAmr-a-n" „Zayd hat Amr geschlagen“. Während die gleiche Reihenfolge auch für frühe akkadische Personennamen gilt, findet sich im Akkadischen sonst das Verb am Satzende: "Iddin-sîn" „Sin hat gegeben“ (Personenname), aber "bēl-ī šum-ī izzakar" „mein Herr hat meinen Namen genannt“. Gewöhnlich wird diese Abweichung auf den Einfluss des Sumerischen, der ältesten Schriftsprache in Mesopotamien, zurückgeführt.

Im Semitischen muss ein Satz kein verbales Prädikat enthalten, um vollständig zu sein. Stattdessen können auch Substantive, Adjektive, Adverbien und Präpositionalphrasen als Prädikat dienen. Derartige Sätze heißen in der Semitistik Nominalsätze. Beispiele:





</doc>
<doc id="5014" url="https://de.wikipedia.org/wiki?curid=5014" title="Stammbaum">
Stammbaum

Ein Stammbaum (neuzeitliche Lehnübertragung von mittellateinisch "arbor consanguinitatis" = Baum der Blutsverwandtschaft) ist im allgemeinen Sinne die baumförmige Darstellung der Abstammung von Lebewesen, Sachen oder Ideen voneinander, ausgehend von einem oder zwei zugrundeliegenden Exemplaren an der Baumwurzel. In der Familienforschung (Genealogie) ist ein Stammbaum die Darstellung der namentlich bekannten Nachkommen einer (früheren) Person oder eines Paares; dabei wird die Person oder das Paar zuunterst angezeigt mit nach oben verzweigenden Verbindungslinien zu ihren „Abkömmlingen“ und deren Nachfahren.

Umgangssprachlich wird unter einem Stammbaum auch fälschlich die Darstellung einer Stammlinie oder Stammliste in der Form eines Baumstammes verstanden („Familienstammbaum“), bei der nur die Erbfolge in der Väterlinie an den jeweils ältesten ehelichen Sohn über mehrere Generationen abgebildet wird. Dadurch enthält diese Darstellung allerdings nur einen sehr kleinen Ausschnitt der Nachkommenschaft der ursprünglichen "Stammeltern", denn alle Vorfahren der jeweiligen Mütter sowie die Geschwister der Erbsöhne und deren Nachkommen bleiben unberücksichtigt, der Darstellung fehlen die Verästelungen in "Seitenlinien". Selbst das in genealogischen Kreisen bekannte "GenWiki" definiert "Stammbaum" als eine solche „männliche Line“. Ein geschichtliches Vorbild für diese Form der Darstellung ist der "Jessebaum (Wurzel Jesse)", ein verbreitetes Bildmotiv der christlichen Kunst vor allem im Mittelalter, das einen Stammbaum von Jesus Christus abbilden soll (siehe auch Baum des Lebens in der Religionsgeschichte).

Das Gegenteil eines Stammbaums, also die Darstellung der Vorfahren einer Person, wird richtig als Ahnentafel (oder Vorfahrentafel) bezeichnet. Auch der Duden beschreibt die Bedeutung von "Stammbaum" ebenfalls falsch als „Nachweis möglichst vieler Vorfahren“ und setzt ihn gleich mit einer „Abstammungstafel“ (Ahnentafel). Falsch ist bei diesem Verständnis auch der Wechsel von der "Nachkommen-" zur "Vorfahrenschaft" und wie „möglichst viele Vorfahren“ in der Form eines sich nach unten verjüngenden Baumes dargestellt werden sollten.

Andere Darstellungsformen der Verwandtschaft sind die "Nachkommentafel" oder die "Nachkommenliste", dabei steht die Ausgangsperson zuoberst oder links. Genealogisch wird nur dann von einem "Stammbaum" gesprochen, wenn die grafische Darstellung in Baumform erfolgt (siehe auch das Baum-Konzept in der Graphentheorie). Stammbäume werden auch für Tier- oder Pflanzen-Individuen erstellt, im übertragenen Sinne auch für Objekte und Ideen (siehe unten).
Eine Kombination von Vorfahren und Nachkommentafeln ist die in der Genealogie benutzte Verwandtschaftstafel, bei der die Eltern und weitere Ahnen und Kinder und weitere Nachkommen einer Person oder eines Paares dargestellt werden. Aus der Form der Darstellung wird das auch als Sanduhr-Darstellung bezeichnet.

Man schmückte in der Antike solche Darstellungen, zurückgehend auf die biblische Stelle der "Wurzel Jesse" (Jes. 11,1), ornamental und figürlich reich.

Im Frühmittelalter stellten Hochgeborene ihre Einmaligkeit und Heiligkeit ihrer Verwandtschaftsbeziehungen (Blutslinie) dar. Vom Hochmittelalter bis in die beginnende Neuzeit wurde der Nachweis, von "edlem Geblüt" zu sein (eine bestimmte Anzahl von freigeborenen Ahnen haben), wichtig, um die Berechtigung zu Ritterschlag und Turnierteilnahme zu erlangen, im weiteren Sinn auch die Berechtigung zum Eintritt in einen Ritterorden oder in einen adligen Dom- oder Stiftskapitel. Diese Form der Darstellung – oft ausgeschmückt mit Wappendarstellungen wird als Aufschwörungstafel bezeichnet. Die Verwandtschaftsbeziehungen waren damals im Ehe- und Erbrecht wichtig. Das Streben nach möglichst weit zurückliegenden prominenten, sagenhaften Vorfahren führte gelegentlich zu abstrusen Behauptungen der Abstammung.

Verwandtschaft und Abstammung können in verschiedenen Formen beschrieben werden. Neben der graphischen Darstellung in Baumform sind auch Listendarstellungen üblich, die platzsparender sind.

Beim Stammbaum wird die Stammmutter und/oder der Stammvater als Bezugsperson ganz unten dargestellt, gleichsam als Wurzel eines Baumes. In den Ästen darüber finden sich die Kinder und deren Nachfahren, dabei steht in jeder Generation bei Geschwistern das ältere Geschwisterteil links vom jüngeren, unabhängig von seinem Geschlecht. Die Darstellung kann schematisch erfolgen oder dekorativ ausgeschmückt werden.

Stammbäume existieren in verschiedenen Ausprägungen. Traditionelle Stammbäume konzentrierten sich auf eine „Stammlinie“ mit vorwiegend männlichen Nachfahren (und Erbnachfolgern) der Vorfahren, zusammen mit ihren Ehefrauen. So wurden beispielsweise nur Personen gleichen Familiennamens einbezogen; da verheiratete Töchter den Namen ihres Ehemannes annahmen, fielen sie aus derartigen Stammbäumen ihrer eigenen Familienangehörigen heraus.

In Hinblick auf die medizinische Diagnose von Erbkrankheiten sind aber die weibliche "und" die männliche biologische Abstammungslinie von gleicher Bedeutung, beispielsweise bei der humangenetischen Beratung. Die moderne Familienforschung strebt deshalb nach umfangreichen, sämtliche Abstammungslinien umfassenden Ahnenlisten – anstelle von Stammlinien, die sich nur auf die männliche Seite der Abstammung beschränken.

Für die Erstellung des Stammbaums einer Person bedarf es einer zeitaufwändigen Recherche zu den genauen Daten aller Vorfahren und gegebenenfalls Nachfahren; diese Informationsbeschaffung kann sich über viele Jahre hinziehen. Erst mit dem Erreichen des ursprünglichen „Spitzenahns“ (Stammmutter, Stammvater) kann mit der graphischen Darstellung der gesammelten Verwandtschaftsinformationen begonnen werden.

Die ersten Anlaufstellen sind die Familienstammbücher der Eltern oder der Großeltern. Standesämter und Pfarreien mit ihren Kirchenbüchern sind die nächste Stufe der Datenbeschaffung. Kann auf ein vorhandenes Ortsfamilienbuch zugegriffen werden, findet sich dort bereits eine umfangreiche Zusammenstellung. Die Daten können durch Suchanfragen bei der "Ahnenstammkartei des deutschen Volkes" und der "Ahnenlistensammlung" ergänzt werden, ohne die zugrunde liegenden Quellen einsehen zu müssen.

Früher oder später kommt die Suche an einen „toten Punkt“. Spätestens mit dem Ende oder dem geschichtlichen Beginn der Kirchenbuch-Aufzeichnung werden andere Quellen benötigt. Alte Steuerlisten können weiteren Aufschluss bieten. Die Online-Recherche im Internet ist zwar ein zeitlicher Gewinn, kann aber nur mit größter Vorsicht und nur zur Quellenunterstützung genutzt werden. Viele Genealogieforen bieten dazu GEDCOM-Dateien aus privaten Recherchen zum Herunterladen.

Die Bezeichnung „Stammbaum“ ist auch in anderen Anwendungsgebieten gebräuchlich, die mit Abstammung und Vererbung zu tun haben. Sie benutzen das gleiche Bild und die gleiche Systematik auch für Objekte oder Sachgebiete, die sich auseinanderentwickelt haben:












</doc>
<doc id="5015" url="https://de.wikipedia.org/wiki?curid=5015" title="Somalia">
Somalia

Somalia (Somali "Soomaaliya"; ) oder Bundesrepublik Somalia bezeichnet einen föderalen Staat im äußersten Osten Afrikas am Horn von Afrika. Der Name ist vom Volk der Somali abgeleitet, das die Bevölkerungsmehrheit bildet und auch in den Nachbarländern ansässig ist.

Somalia entstand aus dem Zusammenschluss der Kolonialgebiete Britisch- und Italienisch-Somaliland, die 1960 („Afrikanisches Jahr“) gemeinsam unabhängig wurden. Das Staatsgebiet grenzt an den Indischen Ozean im Osten, den Golf von Aden im Norden, Dschibuti und Äthiopien im Westen und Kenia im Süden. Nach dem Sturz der autoritären Regierung unter Siad Barre 1991 existierte aufgrund des noch andauernden Bürgerkrieges mehr als 20 Jahre lang keine funktionierende Zentralregierung mehr. Die ab dem Jahr 2000 unter dem Schutz der internationalen Staatengemeinschaft gebildeten Übergangsregierungen blieben weitgehend erfolglos; sie vermochten zeitweise kaum die Hauptstadt unter ihrer Kontrolle zu halten. Weite Teile des Landes fielen in die Hände lokaler Clans, Warlords, radikal-islamistischer Gruppen oder Piraten.

Auf dem Staatsgebiet haben sich verschiedene De-facto-Regimes gebildet. Von diesen strebt jedoch nur Somaliland im Nordwesten seit 1991 nach internationaler Anerkennung als eigenständige Nation. Die übrigen, darunter Puntland, Galmudug und Azania, beanspruchten zwar Autonomie als selbstverwaltete Teilstaaten, haben die Idee des gemeinsamen somalischen Staates aber nicht aufgegeben. Mit Inkrafttreten der neuen Verfassung am 1. August 2012 sind diese autonomen Teilstaaten nun Mitglieder der neuen "Bundesrepublik Somalia" (zuvor "Republik Somalia"). Erfolge gegen die radikal-islamistischen Milizen im Jahr 2012 ermöglichten es, im August 2012 erstmals auch wieder eine gemeinsame somalische Regierung zu wählen und mit der Reorganisation staatlicher Strukturen zu beauftragen, die zunehmend von anderen Staaten und internationalen Organisationen als Vertretung Somalias anerkannt wird.

Somalia liegt im Osten des afrikanischen Kontinents, am Horn von Afrika auf der Somali-Halbinsel. Der nördliche Teil des Landes ist größtenteils bergig und liegt im Somali-Hochland durchschnittlich 900 bis 2100 m über dem Meeresspiegel; der höchste Berg ist der Shimbiris (2460 m). Nach Süden hin erstreckt sich ein Flachland mit einer durchschnittlichen Höhe von 180 m. Die Flüsse Jubba und Shabeelle entspringen in Äthiopien und fließen durch den Süden Somalias und damit durch die Somali-Wüste in den Indischen Ozean.

Somalia wird durch Monsunwinde, ein ganzjähriges heißes Klima, unregelmäßige Regenfälle und stetig wiederkehrende Trockenperioden beeinflusst. Außer in den Berg- und Küstenregionen liegt die durchschnittliche Maximaltemperatur am Tag zwischen 30 und 40 °C.
Der südwestliche Monsun sorgt in der Gegend um Mogadischu in den Monaten von Mai bis Oktober für ein relativ mildes Klima. Zwischen Dezember und Februar bringt der nordöstliche Monsun ein ähnliches mildes Klima. In der sogenannten "Tangambili"-Periode zwischen den beiden Monsunen (Oktober bis November und März bis Mai) ist es heiß und feucht.

Erosion und die Ausbreitung der Wüste sind die wesentlichen Umweltprobleme Somalias. Ursachen sind Überweidung und die Abholzung der verbleibenden Wälder, da Holz die Hauptenergiequelle des Landes ist und seit Ausbruch des Bürgerkrieges in größerem Umfang Holzkohle in die Staaten der Arabischen Halbinsel exportiert wird.

Die Mangrovengebiete zwischen Kismaayo und der kenianischen Grenze im Süden des Landes und die Korallenriffe am Golf von Aden und nahe Kenia sind ebenfalls von Bodendegradation und Schädigung betroffen.

In Abwesenheit einer wirksamen Küstenwache wird vor der Küste des Landes illegale Atommüll- und Giftmüllentsorgung (Verklappung) betrieben, und ausländische Fangflotten überfischen unkontrolliert die Gewässer.

Die Einwohner Somalias heißen "Somalier". Gelegentlich wird auch unpräzise die Bezeichnung "Somali" verwendet, die jedoch nur die ethnischen Somali einschließt, also die Nicht-Somali-Minderheiten im Land nicht umfasst.

Die letzte Volkszählung, deren Ergebnisse veröffentlicht wurden, gab es 1975. Die UNFPA hat im Jahr 2014 eine Studie veröffentlicht, in der mit Hilfe von Umfragen und Satellitenaufnahmen eine Gesamtbevölkerung von über 12,3 Millionen ermittelt wurde. 

Heute leben ca. 25 Prozent aller Somalier teilweise oder vollständig als Nomaden. 22 Prozent der Menschen leben als Bauern, die sich in der fruchtbarsten Region des Landes zwischen den Flüssen Shabeelle und Jubba niedergelassen haben. Der größte Teil der Bevölkerung (42 Prozent) lebt in städtischen Gebieten. Es sind immer noch über eine Million Menschen (9 Prozent der Gesamtbevölkerung) in Somalia auf der Flucht und leben überwiegend in 107 Flüchtlingscamps.

Somalia galt lange als eines der ethnisch homogensten Länder und als „einziger Nationalstaat“ Afrikas, da die große Mehrheit der Bevölkerung zum Volk der Somali gehört. Dieses Bild hat sich gewandelt, seit im Bürgerkrieg die Differenzen zwischen den verschiedenen Clans der Somali sowie zwischen Somali und ethnischen Minderheiten vor allem in Südsomalia deutlicher wurden.

Die anteilmäßig bei weitem bedeutendste Ethnie sind die Somali, deren Siedlungsgebiet sich auch auf Ost-Äthiopien (Somali-Region), Dschibuti und Nordost-Kenia erstreckt und die nach heutiger Kenntnis von kuschitisch-afrikanischer und teilweise arabisch-persischer Abstammung sind.

Von großer Bedeutung für Gesellschaft und Politik Somalias ist das Clansystem der Somali, das wahrscheinlich von der Stammesgesellschaft der Araber beeinflusst wurde. Jeder Somali gehört über seine väterliche Abstammungslinie einem Stamm oder Clan an. Die fünf großen Clanfamilien "(qaabiil)" sind:

Dabei gelten die traditionell nomadisch lebenden Dir, Darod, Isaaq und Hawiye als „echte Somali“ oder "Samaal", während die sesshaft-bäuerlichen Rahanweyn als „unechte Somali“ oder als "Sab" bezeichnet werden. Sie gelten, ebenso wie diverse ethnische Minderheiten, aus Sicht eines Teils der Samaal als nicht gleichberechtigt und unterliegen traditionell einer gesellschaftlichen Benachteiligung.

Jede dieser Clanfamilien zerfällt in eine große Zahl Subclans und „Geschlechter“ (Somali: "reer", was „Leute aus“, „Nachkommen von“ bedeutet). Diese umfassen jeweils einige Hundert bis Tausend Männer, die das für Verbrechen fällige Blutgeld "(diya, mag)" gemeinsam bezahlen bzw. erhalten. Dieses System verschafft dem einzelnen Somali traditionell Schutz für Leben und Eigentum, führt jedoch auch zu Blutfehden, die sich nicht nur auf einzelne Verbrechen beziehen, sondern auch Auseinandersetzungen um Wasser- und Weiderechte und um die politische Macht umfassen.

Nicht-Somali-Minderheiten machen etwa 15 % der Bevölkerung aus. Zu diesen gehören verschiedene schwarzafrikanische Volksgruppen in Südsomalia, die von den Somali zusammenfassend als "Jarer" („harthaarig“ oder „kraushaarig“) bezeichnet werden. Ein Teil von diesen stammt von Sklaven ab, die im 19. Jahrhundert durch den ostafrikanischen Sklavenhandel aus Tansania, Malawi, Mosambik und Kenia nach Somalia gebracht wurden und sich nach ihrer Flucht oder Freilassung größtenteils im Tal des Jubba niederließen. Sie sind seit den 1990er Jahren als Somalische Bantu bekannt. Für andere "Jarer"-Gruppen wie etwa die Shidle gilt die Herkunft bis heute als ungeklärt; möglicherweise stammen sie von einer Bevölkerung vor den Somali ab.

Weitere Minderheiten sind Angehörige der Swahili-Gesellschaft und Gruppen von gemischter Herkunft an der Küste (z. B. Bajuni, Brawanesen, Benadiri/Reer Hamar), im ganzen Land verbreitete Gruppen wie die Yibir und Midgan, die auf bestimmte Berufe beschränkt sind, sowie einige Tausend Araber und einige Hundert Inder und Pakistaner.

Hauptsprache Somalias ist das Somali (Eigenbezeichnung "Af-ka Soomaali-ga") – eine ostkuschitische Sprache aus dem Sprachzweig der kuschitischen Sprachen und damit Teil der afroasiatischen Sprachfamilie –, das heute von etwa 12 Millionen Menschen in Somalia und angrenzenden Gebieten gesprochen wird. Die Sprache des Somali-Volkes wird in Somalia auch von allen Minderheiten verwendet.

Als Handels- und Bildungssprachen werden auch Arabisch und – als Erbe der Kolonialzeit – Italienisch und Englisch genutzt. Ein kleiner Teil der somalischen Bantu hat die Bantusprache Zigula beibehalten. An der Küste sprechen kleine Minderheiten (die Bajuni in und um Kismaayo und die "Brawanesen" in Baraawe) Dialekte des Swahili.

Als einziger afrikanischer Staat neben Tansania entwickelte sich Somalia nach seiner Unabhängigkeit weg vom Gebrauch der europäischen Kolonialsprachen. Somalische Nationalisten strebten nach einer Standardisierung und Verschriftung des Somali. Diese wurde 1972 unter Siad Barre verwirklicht und zur Amtssprache gemacht. Somali setzte sich daraufhin rasch in Verwaltung, Bildungswesen und Medien durch, während Italienisch, Englisch und Arabisch entsprechend an Bedeutung verloren. Als Basis für das Standard-Somali diente die vor allem im Norden gesprochene Variante "Maha Tiri (Maxaa Tiri)"; die andere Hauptvariante ist das im Süden verbreitete "Maay", daneben gibt es weitere Dialekte.

Die somalische Übergangsverfassung von 2004 legt als offizielle Sprachen Somali (Maay und Maha Tiri) und Arabisch fest. Italienisch und Englisch haben einen Status als Sekundärsprachen.

Die Bevölkerung Somalias gehört zu fast 100 % dem sunnitischen Zweig des Islam an. Davon sind etwa 80 % Schafiiten und 20 % Hanafiten. Die einzigen Nicht-Muslime in Somalia sind einige hundert Christen, die fast sämtlich ausländischer Herkunft sind. Die wenigen christlichen Somalier gehören der äthiopisch-orthodoxen Tewahedo-Kirche an. Einzelne Missionierungsversuche und der Bau einer Kathedrale mit angeschlossenem katholischem Kloster in Mogadischu in der Kolonialzeit blieben ohne größere Wirkung. Beide wurden während des Bürgerkriegs zerstört. Damit löste sich auch das römisch-katholische Bistum Mogadischu faktisch auf. Der letzte Bischof war bereits 1989 in der Kathedrale erschossen worden.

Die traditionelle Ausübung des Islam in Somalia ist in den Dörfern und unter Nomaden eher gemäßigt und vermischt mit dem Gewohnheitsrecht der Clans. Dort sind die durch missionierende Scheichs verschiedener Sufi-Orden im 19. Jahrhundert verbreiteten Glaubenschulen im Alltag präsent. Die älteste und größte dieser Bruderschaften ist die Qadiriyya, gefolgt von der Salihiyya im Norden. Kleinere Gruppen sind die Dandarawiyya, der Ende des 19. Jahrhunderts von Muhammad ibn Ahmad al-Dandarawi gegründete, am weitesten verbreitete Zweig der Idrisiyya, und die Rifaiyya, ein Ableger der Qadiriyya, der unter arabischen Einwanderern in Mogadischu populär ist. Seit den 1970er Jahren gibt es vor allem in den Städten radikale wahhabitische Strömungen, die während des Bürgerkriegs ebenso wie die Religion insgesamt an Bedeutung gewonnen haben.

Seit Ausbruch des Bürgerkrieges gehören islamische Einrichtungen zu den wenigen Institutionen, die Bildung, medizinische Versorgung oder auch Rechtsprechung anbieten. Auf die Lage der Frauen wirkt sich der wachsende Einfluss des Islam unterschiedlich aus: Das islamische Recht bringt ihnen gegenüber dem Gewohnheitsrecht gewisse erbrechtliche Verbesserungen, und einige Geistliche sprechen sich heute auch gegen die weit verbreitete Mädchenbeschneidung aus; andererseits werden Frauen zunehmend gedrängt, sich stärker zu verhüllen oder ganz aus dem öffentlichen Raum zurückzuziehen. Al-Shabaab setzt in Süd- und Zentralsomalia eine strenge Auslegung der Schari’a durch. Sie hat auch Verbindungen zu al-Qaida und hat Dschihadisten aus dem Ausland in ihren Reihen.

Die Verfassung der Übergangsregierung bestimmt den Islam als offizielle Religion der Republik Somalia und legt fest, dass die Gesetzgebung auf der Schari’a basieren soll. Auch die Verfassung des einseitig für unabhängig erklärten Somaliland erklärt den Islam zur Religion der Nation und verbietet das „Propagieren“ – darunter fällt bereits die öffentliche Ausübung – anderer Religionen in Somaliland.
Der Abfall vom Islam wird mit drakonischen Strafen, u. a. durch Auspeitschung bestraft.

Schätzungsweise 13 % der Jungen und 7 % der Mädchen besuchen eine Schule. Unterricht findet heute in Abwesenheit eines offiziellen Bildungssystems hauptsächlich in Koranschulen und privaten Einrichtungen statt. Im faktisch autonomen Somaliland wurde das Bildungswesen seit der Unabhängigkeitserklärung ausgebaut.

Mangelernährung und Infektionskrankheiten sind verbreitet. 70 % der Bevölkerung haben keinen Zugang zu sauberem Trinkwasser und medizinischer Versorgung. Die Kinderzahl pro Frau liegt bei durchschnittlich 6,1. Die Müttersterblichkeit liegt bei 12 von 1000 Geburten. Die Kindersterblichkeit ist hoch: Vor dem 1. Geburtstag sterben 108 und vor dem 5. Geburtstag 180 von 1000 lebend geborenen Kindern. Die durchschnittliche Lebenserwartung bei der Geburt wird mit 50,7 bis 51,2 Jahren angegeben.

Der Anteil von HIV-Infizierten wird auf 0,5 % geschätzt und ist damit im afrikanischen Vergleich sehr niedrig. Begründet wird dies mit der islamischen Religion und damit, dass seit Kriegsausbruch verhältnismäßig wenige Menschen von außen in das Land kamen. Das Wissen um Übertragungswege und Prävention von HIV/Aids ist kaum verbreitet.

2008 vermeldete die Weltgesundheitsorganisation, dass durch großangelegte Impfkampagnen das Kinderlähmung verursachende Poliovirus in Somalia ausgerottet worden sei. Das Land war bereits 2002 poliofrei geworden, doch war das Virus zwischenzeitlich aus Nigeria wieder eingeschleppt worden.

Auf der anderen Seite gibt es auch Berichte über einen starken Anstieg von Fehl- und Missbildungen bei Neugeborenen und kleinen Kindern. Bei der Suche nach Ursachen wird ein Zusammenhang mit der illegalen Verklappung von Atom- und Giftmüll vor der Küste angenommen. Aber die diagnostischen Möglichkeiten der Krankenhäuser reichen zu einer Ermittlung der Ursachen nicht aus, und die weiterhin politisch unsichere Lage, vor allem in von islamistischen al-Shabaab-Milizen kontrollierten Küstengebieten, erlaubt keine nähere Untersuchung bereits angespülter Fässer auf einen radioaktiven oder giftigen Inhalt.

Somalia ist eines der Länder mit der weltweit größten Bevölkerung an Flüchtlingen und intern Vertriebenen. 
2016 gibt es ungefähr 977.000 somalische Flüchtlinge, die sich bei der UNHCR registriert haben. 414.000 von ihnen sind nach Kenia geflohen: 327.000 davon sind in Dadaab, dem weltweit größten Flüchtlingslager, 54.000 im Lager Kakuma und 32.000 leben in der Hauptstadt Nairobi. 215.000 somalische Flüchtlinge sind nach Äthiopien geflohen und leben dort in fünf Lagern in der Dollo-Ado-Region. 235.000 somalische Flüchtlinge gibt es auch in Jemen und sie sind dort in den Lagern Al-Kharaz and Al-Mazrak untergebracht, aber auch in Städten wie Aden, 'Amran, Al Mukalla and Sana'a. In Jemen ist die Situation ähnlich der in Somalia, da das Land sich ebenfalls im Bürgerkrieg befindet: 10 % der Bevölkerung von Jemen verloren ihr Haus und sind intern vertrieben und 80 % sind auf humanitäre Hilfe angewiesen. 37.000 Somalier sind nach Uganda geflüchtet.

Zusätzlich zu den außer Landes geflüchteten gibt es 2016 noch 1,1 Millionen intern vertriebene (IDPs) Somalis innerhalb Somalias. Die Mehrheit von ihnen lebt in Zentral- und Südsomalia (893.000), in Puntland (129.000) und in Somaliland (84.000). Es wird angenommen, dass zwischen 70 und 80 % dieser Haushalte von Frauen geführt werden und dass 60 % der intern Vertriebenen Kinder sind. Intern vertriebene Frauen werden häufig Opfer sexueller Gewalt oder sind sogar darauf angewiesen, sich Hilfe durch Sex zu erkaufen; Kinder werden eventuell von Milizen zwangsrekrutiert, ethnische Minderheiten werden stark diskriminiert und ihnen wird häufig jegliche Unterstützung verweigert. Auch gelangen internationale Hilfslieferungen häufig nicht zu denen, die sie benötigen, und verschwinden stattdessen in dunklen Kanälen.

Trotz allem ist Somalia aber auch ein Land, das selbst Flüchtlinge aufnimmt: viele Äthiopier, die vor Dürre und Verfolgung flohen, und viele Flüchtlinge aus Jemen. Häufig zeigt sich, dass diese in Somalia unerwünscht sind.
So ist es Somaliern verboten, ihnen Wohnraum anzubieten. Deshalb befinden sich viele von ihnen in den Lagern für die intern vertriebenen Somalis; einige haben aber auch Fuß gefasst und Geschäfte eröffnet.

Die ältesten bekannten Spuren von Menschen im heutigen Somalia wurden in Buur Heybe in Südsomalia gefunden. Es handelt sich um Skelette, die mit der Radiokohlenstoffdatierung auf bis zu 6.000 v. Chr. datiert wurden. Höhlenmalereien in Laas Geel bei Hargeysa stammen aus der Zeit von 4.000 bis 3.000 v. Chr.

Die Vorfahren der Somali wanderten um 500 v. Chr. bis 100 n. Chr. aus dem südlichen äthiopischen Hochland ein und vermischten sich – insbesondere in den Handelsstädten an der Küste, wie Zeila, Hobyo und Mogadischu – mit arabischen und persischen Einwanderern, welche ab dem 7. Jahrhundert auch den Islam einführten. Es entstanden muslimische Sultanate und Stadtstaaten. Im 16. Jahrhundert gerieten die Städte an der Nordküste unter türkische bzw. ägyptische Herrschaft, jene an der südlichen Benadirküste kamen im 17. Jahrhundert unter die Oberhoheit Omans bzw. im 19. Jahrhundert Sansibars.

Ende des 19. Jahrhunderts erfuhr das von Somali bewohnte Gebiet seine bis heute nachwirkende Aufteilung. Der Norden des heutigen Somalia wurde von Großbritannien als Britisch-Somaliland, der Süden und Osten als Italienisch-Somaliland von Italien kolonialisiert. Am 1. Juli 1960 wurden die beiden Kolonien gemeinsam als Somalia unabhängig. Erster Präsident des Landes wurde Aden Abdullah Osman Daar, ihm folgte 1967 Abdirashid Ali Shermarke.

Das Verhältnis zu den Nachbarstaaten war wegen der von Somalia gestellten Gebietsansprüche ("siehe" Groß-Somalia), insbesondere auf die heute äthiopische Region Ogaden, gespannt. Auch innenpolitische Spannungen zwischen dem Norden und dem Süden und Osten, zwischen Clans und Parteien bestanden weiter. 1969 wurde Präsident Shermarke von einem Leibwächter getötet, woraufhin pro-sowjetische Militärs unter Siad Barre die Macht übernahmen.

Barre lehnte sich zunächst an die Sowjetunion an, versuchte einen „wissenschaftlichen Sozialismus“ einzuführen und den traditionellen Einfluss der Clans einzuschränken. 1977/78 führte er den Ogadenkrieg gegen Äthiopien, den Somalia verlor. Weil die Sowjetunion in diesem Krieg das gegnerische, kommunistische Derg-Regime Äthiopiens unterstützte, wandte sich Siad Barre wirtschaftlich und politisch von der Sowjetunion ab und den USA zu. Im Inneren regierte er zusehends diktatorisch, verschiedene Clans waren Repressionen ausgesetzt. Mehrere Rebellengruppen begannen einen bewaffneten Kampf gegen die Barre-Regierung, was 1991 zu deren Sturz führte.

Die siegreichen Rebellengruppen konnten sich jedoch nicht auf eine Nachfolgeregierung einigen. Der am Sturz Barres führend beteiligte "Vereinte Somalische Kongress" zerbrach infolge des Machtkampfes seiner Führer Mohammed Farah Aidid und Ali Mahdi Mohammed. Somalia zerfiel in umkämpfte Machtbereiche von Clans und Warlords. Der Norden des Landes erklärte sich als Somaliland einseitig für unabhängig, ohne hierfür internationale Anerkennung zu erreichen.
Für die Bevölkerung hatten die Kämpfe und Plünderungen eine Verschlechterung der Versorgungs- und Sicherheitslage bis hin zur Hungersnot im Süden des Landes zur Folge. Ab 1992 sollte deshalb die UN-Mission UNOSOM unter US-amerikanischer Führung die Lieferung von Nahrungsmittelhilfe sichern und den Frieden wiederherstellen. Nach den Ereignissen der „Schlacht von Mogadischu“ im Oktober 1993 zogen die USA jedoch ihre Truppen wieder aus dem Land ab. 1995 musste sich auch die UNOSOM II ohne Erfolg zurückziehen. Die Kampfhandlungen gingen weiter, wenn auch weniger intensiv. Im praktisch autonomen Somaliland blieb es seit 1996 weitgehend friedlich. Nach diesem Vorbild gründete der Harti-Darod-Clan in Nordostsomalia die autonome Region Puntland. Die Rahanweyn versuchten in Südwestsomalia ebenfalls, eine Regionalregierung zu etablieren, scheiterten jedoch, weil Südwestsomalia wie auch Jubaland umkämpft blieb. In der Hauptstadt Mogadischu bekämpften sich verschiedene Kriegsherren und Milizen der Hawiye.

2000 wurde nach Friedensverhandlungen in Dschibuti eine nationale Übergangsregierung (engl.: "Transitional Federal Government", abgekürzt TFG) unter Präsident Abdiqasim Salad Hassan gebildet. Sie war den moderaten Islamisten in Somalia gegenüber freundlich gesinnt, wurde aber von den mächtigen Warlords im Land abgelehnt. Die nationale Übergangsregierung konnte keine Macht in Somalia gewinnen und zerfiel 2003. Auf einer Friedenskonferenz in Kenia wurde 2004 eine neue föderale Übergangsregierung unter Präsident Abdullahi Yusuf Ahmed etabliert. Sie hatte nicht die Unterstützung der Islamisten und der meisten Hawiye, die Mogadischu kontrollierten. Diese neue Übergangsregierung ließ sich daraufhin in Baidoa nordwestlich von Mogadischu nieder. Mitte 2006 eroberte die Union islamischer Gerichte Mogadischu und weite Landesteile von den bis dahin dort herrschenden Kriegsherren, setzte ein gewisses Maß an — unterschiedlich streng gehandhabter — Ordnung nach der Scharia durch und kämpfte an den Grenzen der beiden Machtbereiche gegen die Übergangsregierung.

Das benachbarte Äthiopien fühlte sich von der Union bedroht, da es eine islamistische Vereinnahmung seiner eigenen muslimischen Bevölkerung fürchtete und Teile der Union zum Dschihad zur Eroberung des heute äthiopischen, mehrheitlich von Somali bewohnten Gebietes Ogaden aufgerufen hatten. Am 24. Dezember 2006 erklärte Äthiopien der Union offiziell den Krieg, marschierte in Somalia ein und konnte in wenigen Tagen die Union verdrängen. Die Übergangsregierung versuchte sich mit militärischer Unterstützung Äthiopiens in Mogadischu und im übrigen Land zu etablieren, stieß jedoch auf erheblichen Widerstand von Islamisten, verschiedenen Clans und weiten Teilen der Bevölkerung, die die äthiopische Militärpräsenz ablehnten.

2007 und 2008 lieferten sich regierungstreue Truppen und deren diverse Gegner vor allem in Mogadischu heftige Kämpfe, die Hunderttausende in die Flucht trieben. Tausende Zivilisten wurden getötet, und über eine Million mussten zeitweise aus ihren Häusern vor allem in Mogadischu fliehen. Anfang 2009 zogen die äthiopischen Truppen wieder aus Somalia ab. Die militanten Islamisten waren nicht besiegt worden, sondern waren im Gegenteil deutlich stärker geworden. Im Kampf gegen die brutale äthiopische Besatzung hatten sie in den Augen vieler Somalier (auch in der Diaspora) an Legitimität gewonnen. Der gemäßigte Islamist Sheikh Sharif Sheikh Ahmed wurde neuer Präsident der Übergangsregierung, die jedoch weiterhin von der radikaleren al-Shabaab bekämpft wird. 2009 verloren die Regierungstruppen fast überall im Land an Einfluss. Vor allem in Südsomalia übernahmen die islamistischen Gruppierungen al-Shabaab und Hizbul Islam die Macht und bekämpften sich auch gegenseitig.

Die USA unterstützen die somalische Übergangsregierung politisch, durch finanzielle Hilfen und mit Waffen. Sie stufen die radikalislamische Miliz al-Shabaab als Terrororganisation ein, die mit al-Qaida zusammenarbeitet. Die USA haben auch mehrmals gezielte Luftangriffe auf Einrichtungen der Islamisten durchgeführt. Die Europäische Union unterstützt finanziell die Übergangsregierung und die Friedenstruppe der Afrikanischen Union (AMISOM) zu ihrem Schutz.

Die Kampfhandlungen waren auch 2009 und 2010 vornehmlich auf Mogadischu konzentriert. Hier starben weiter tausende Menschen oder wurden zu Flüchtlingen. Die militanten Islamisten, besonders al-Shabaab, kontrollierten bis Ende 2010 den Großteil Süd- und Zentralsomalias. Die Übergangsregierung unter Sheikh Sharif Sheikh Ahmed musste sich in Teilen Mogadischus verschanzen und wurde täglich von mehreren tausend AMISOM-Soldaten beschützt. Al-Shabaab unterwarf die Bevölkerung strikten Regeln, denen eine extreme Interpretation des Islam zu Grunde lag. Jede Zuwiderhandlung sowie der bloße Verdacht, mit dem Feind zusammenzuarbeiten, wurden hart bestraft. Es gab aber durchaus auch Somalier, die al-Shabaab zugutehielten, dass sie Ruhe und Ordnung herstellte und die Kriminalität wirksam bekämpfte.

Mitte August 2010, zu Beginn des Fastenmonats Ramadan, starteten al-Shabaab und Hizbul Islam eine gemeinsame, großangelegte Militäroffensive, um TFG und AMISOM endgültig zu besiegen. Zusammen hatten die Islamisten ungefähr 8000 Kämpfer. AMISOM hatte inzwischen fast die Sollstärke von 8000 Mann erreicht. Auch das TFG hatte 2010 ungefähr 3000 eigene Soldaten zur Verfügung, dank Militärhilfe der USA und Training (auch durch private Militärunternehmen), das vornehmlich mit Geldern von EU-Ländern bezahlt wurde. Die Offensive geriet rasch ins Stocken. Die Gründe waren die militärische Stärke des Gegners und Spannungen innerhalb des islamistischen Lagers. Hizbul Islam zerfiel zusehends. Viele ihrer Truppen desertierten, einige liefen zum TFG über. Im Dezember 2010 wurden die Reste von Hizbul Islam offiziell in al-Shabaab integriert. Dies sorgte innerhalb von al-Shabaab für Unruhe.

Der UNO-Sicherheitsrat gewährte im Dezember 2010 die Erhöhung der maximalen Truppenstärke von AMISOM um 4000 auf 12.000 Soldaten. Ab Februar 2011 gingen das TFG und AMISOM, unterstützt von ASWJ-Einheiten und Teilen der äthiopischen und kenianischen Armee, gegen al-Shabaab vor. Die Hauptkampfplätze waren Mogadischu, die Region Gedo in Westsomalia und Teile Zentralsomalias. Al-Shabaab war angeschlagen und verlor zunehmend an Rückhalt in der Bevölkerung. Ein Grund dafür war die unbefriedigende Reaktion der al-Shabaab-Führung um Emir Ahmed Abdi Godane auf die sich seit Monaten zuspitzende Dürre in Somalia. Als der Hunger begann, weigerte sich al-Shabaab, internationale Hilfe zuzulassen. Die Hungersnot wurde vom Sprecher der Gruppe im Juli 2011 als westliche Propaganda dargestellt. Im August 2011 mussten sich al-Shabaab aus Mogadischu zurückziehen. Auch in anderen Teilen Süd- und Zentralsomalia geriet al-Shabaab in Bedrängnis. Es gelang dem TFG und seinen Unterstützern bis Mitte 2011 jedoch nicht, al-Shabaab entscheidend zu schlagen.
Zwei Bataillone der kenianischen Streitkräfte (Kenya Defence Forces; KDF) mit rund 2.400 Soldaten marschierten in der "Operation Linda Nchi" (deutsch: Verteidigt die Nation) am 16. Oktober 2011 in Somalia ein, um Al Shabaab zu bekämpfen. Die kenianischen Truppen rückten auf Afmadow und die für al-Shabaab wirtschaftlich und finanziell wichtige Hafenstadt Kismayu im Süden Somalias zu. Auch die kenianische Luftwaffe flog Einsätze gegen Stellungen der al-Shabaab, u. a. gegen ein Ausbildungslager in Jilib. Auslöser für die Militäraktion waren Entführungen von Ausländern in Kenia. Bis Februar 2012 konnte die kenianische Armee rund 110 km tief nach Somalia vordringen und kontrolliert nach eigenen Angaben eine Fläche von 95.000 km².

Am 1. August 2012 nahm das Parlament Somalias eine neue provisorische Verfassung an. Mit ihr wurde die Übergangsregierung Somalias abgelöst und erstmals wieder eine normalisierte Staatsordnung hergestellt. Somalia wurde in eine Bundesrepublik umgewandelt, wobei zunächst noch keine Teilstaaten gebildet wurden. Laut Verfassung sollten die Abgeordneten bestimmen, über wie viele Teilstaaten Somalia verfügen werde. Allerdings könnten sich zwei oder mehr Regionen von sich aus zu Bundesstaaten zusammenschließen.

Als erster Bundesstaat wurde im August 2013 Jubaland im Rahmen eines Versöhnungsabkommens von der Bundesregierung anerkannt. Es besteht aus den Regionen Gedo, Jubbada Hoose und Jubbada Dhexe. Ein Jahr später wurde ein zweiter Bundesstaat in Zentralsomalia geschaffen, der die Regionen Mudug und Galguduud umfassen soll. Die vor Ort existierenden De-facto-Regimes der "Ahlu Sunna Waljama'a"-Miliz, "Galmudug" und "Himan & Heeb" sollen gemeinsam neue Strukturen etablieren.

Somalia wird oft als „gescheiterter Staat“ bezeichnet. Seit 1991 hat es keine im gesamten Land anerkannte nationale Regierung mehr. Im Norden streben Teile des Landes ganz offen nach Unabhängigkeit (Somaliland) oder haben sich zu autonomen Teilstaaten Somalias erklärt (Puntland und Galmudug). In weiten Teilen im Süden und Zentrum von Somalia herrschten zumindest bis vor kurzem lokale Clans, Warlords, islamistische Gruppen oder unklare Verhältnisse. In der Region Himan & Heeb bildet der ehemalige IT-Berater Mohamed Aden eine Art informelle Regierung.

Die Bundes-Übergangsregierung war international anerkannt und repräsentierte das Land in den Vereinten Nationen, der Arabischen Liga und anderen internationalen Organisationen. Seit ihrem Bestehen 2000 hatte sie sich im Land selbst aber nicht durch die Schaffung von Ruhe und Ordnung und die Bereitstellung von Dienstleistungen ausgezeichnet. Im Gegenteil, die Übergangsregierung war intern seit Jahren zerstritten, und ihren Anführern wurde immer wieder vorgeworfen, korrupt zu sein und sich auf Kosten der eigenen Bevölkerung an ausländischer Hilfe zu bereichern. Seit Anfang 2011 sah es zum ersten Mal so aus, als ob die Übergangsregierung die Macht in Mogadischu und Teilen Südsomalias übernehmen könnte – bisher aber nur mit massiver militärischer Hilfe von AMISOM, Kenia und Äthiopien. Ob der mögliche militärische Sieg über Dschihadisten-Miliz al-Shabaab schon eine wirkliche Wende für Somalia nach über zwanzig Jahren Staatslosigkeit und Bürgerkrieg bedeutet, ist fraglich. Anfang 2012 tauchte erstmals die Idee auf, Somalia in eine Bundesrepublik zu verwandeln. Im August wurde dann die Übergangsregierung aufgelöst und durch eine international anerkannte föderale Regierung ersetzt. Seitdem verfügt Somalia über ein Bundesparlament.

Auf dem Korruptions<nowiki>wahrnehmungs</nowiki>index 2016 von Transparency International liegt Somalia auf dem letzten Platz; gemäß "Mo Ibrahim Foundation" ist es das am schlechtesten regierte Land Afrikas. In der Rangliste der Pressefreiheit 2017 von Reporter ohne Grenzen rangiert Somalia auf Platz 167 von 180 Ländern. Im Jahr 2017 sind drei Journalisten in Somalia getötet worden. Laut dem Bericht von Reporter ohne Grenzen steht der Tod der Opfer in direktem Zusammenhang mit deren journalistischer Tätigkeit. In Somalia sitzt ein Journalist in Haft. 

Die Sicherheitslage in Somalia ist aufgrund des anhaltenden Bürgerkrieges und der Piratenüberfälle vor der Küste schlecht. Die Sicherheitskräfte sind nicht in der Lage, die Kriminalität nachhaltig zu bekämpfen. Das deutsche Auswärtige Amt (AA) hat für Somalia eine Reisewarnung ausgegeben und seine Botschaft geschlossen (Stand: Januar 2018). Ausländer werden immer wieder Opfer von Mordanschlägen und Entführungen, in medizinischen oder kriminalitätsbedingten Notfällen ist keine ausreichende Infrastruktur zur Versorgung vorhanden.

Die internationale Staatengemeinschaft hatte sich in kurzzeitige Interventionsmaßnahmen – gegen die Terroristen und die Piraten – verrannt und interveniert nun gegen den Hunger, ohne ein wirkliches Konzept zu haben. 
Mitte 2011 waren mehr als drei Millionen Menschen und damit mindestens ein Drittel der Bevölkerung Somalias auf humanitäre Hilfe angewiesen. Die Notlage betrifft allerdings nur Südsomalia. Hier fielen der Krieg zwischen den islamistischen al-Shabaab-Milizen einerseits und der Übergangsregierung und den Truppen der AMISOM andererseits ab Anfang 2011 mit dem Höhepunkt einer Dürre zusammen. Viele internationale Hilfsorganisationen hatten Somalia aufgrund der anhaltenden Unsicherheit schon länger verlassen. Andere waren, wie das Welternährungsprogramm (WFP), von den Islamisten aus den von ihnen kontrollierten Gebieten hinausgedrängt worden. Al-Shabaab warf dem WFP vor, die Umsätze der somalischen Bauern zu drücken und Hilfe an Forderungen westlicher Politik zu binden. Tatsächlich leisteten die USA ab 2009 ihre Beiträge für Hilfsorganisationen nur noch, wenn sichergestellt war, dass Leistungen nicht den „Terroristen“ zugutekommen. Krieg, Fanatismus und ausbleibender Regen führten zu einer Hungerkatastrophe, die viele Somalis das Leben kostete oder zu Flüchtlingen im benachbarten Kenia machte. Die Lage im weitgehend friedlichen Nordsomalia, wo mit Somaliland und Puntland zwei de facto autonome Staatsgebilde bestehen, ist weit weniger dramatisch.

Einem Bericht der FAO zufolge starben zwischen Oktober 2010 und April 2012 258.000 Menschen an den Folgen der Nahrungsmittelknappheit im Land.

Eine weitere schwere Hungersnot folgte im Zuge der Dürrekatastrophe im südlichen Afrika und in Ostafrika ab 2015. Im Mai 2017 kam es zur London Somalia Conference von Vertretern zahlreicher Staaten und Organisationen in London, um die Versorgung der Bevölkerung sicherzustellen. Dabei wurde auch die Sicherheitslage in Somalia diskutiert und Schritte zu einer Stärkung der nationalen Sicherheitskräfte initiiert.

Mitarbeiter von humanitären Organisationen, Journalisten und Menschenrechtsverteidiger nehmen bei ihrer Arbeit in Somalia große Risiken auf sich und laufen unter anderem Gefahr, entführt oder ermordet zu werden. Auch 2009 wurden gravierende Menschenrechtsverstöße, einschließlich Kriegsverbrechen, nicht bestraft.
Der UN-Generalsekretär, der unabhängige UN-Experte für die Menschenrechtssituation in Somalia und der Beauftragte des UN-Generalsekretärs für die Menschenrechte Binnenvertriebener sprachen in ihren Berichten von Menschenrechtsverstößen, einschließlich der Rekrutierung von Kindern für den bewaffneten Kampf. Appelle aus dem Ausland und von Kräften in Somalia, Verbrechen im Sinne des Völkerrechts endlich strafrechtlich zu ahnden, blieben wirkungslos.
Alle am laufenden somalischen Bürgerkrieg beteiligten Parteien haben in den letzten Jahren schwerste Menschen- und Kriegsrechtsverbrechen begangen. Äthiopische Truppen, die Armee der Übergangsregierung, AMISOM und die islamistischen Milizen al-Schabaab und Hizbul islam haben ihre Waffen unterschiedslos im dicht besiedelten Gebiet (in Mogadischu) eingesetzt. Zudem wurden die Feinde der jeweiligen Seite oft erbarmungslos verfolgt und Verdächtige ohne rechtliches Verfahren eliminiert. Alle Kriegsparteien haben schwerste Übergriffe auf die Zivilbevölkerung Südsomalias begangen. Frauen wurden massenweise vergewaltigt und Männer, Jugendliche und sogar Kinder von allen Parteien im Krieg zwangsrekrutiert. Al-Shabaab-Milizen sind zusätzlich für die Tötungen und Bestrafungen von Menschen verantwortlich, die sich ihrer Auslegung des islamischen Rechts nicht beugten. In den von ihnen kontrollierten Landesteilen war ein dramatischer Anstieg öffentlicher Hinrichtungen, darunter auch Steinigungen, zu verzeichnen. Gleiches galt für die Zwangsamputation von Gliedmaßen und Auspeitschungen. Al-Shabaab-Milizen schändeten auch Gräber führender Geistlicher der islamischen Sufi-Gemeinschaft. Außerdem mussten sich Frauen nach bestimmten Regeln kleiden und durften sich nicht frei bewegen. Auch die Situation vieler Kinder bereitet Sorgen. Dadurch, dass das Bildungssystem marode ist, haben die Kinder kaum die Möglichkeit, in die Schule zu gehen. Die Hälfte aller Kinder zwischen fünf und 14 Jahren müssen arbeiten. Schätzungen zufolge gibt es ca. 70.000 Kindersoldaten, die von verschiedenen Milizen unter Waffen gehalten werden. In einer Erklärung der UNICEF wurde bekannt gegeben, dass in Somalia der Einsatz von Kindern ansteigt. Kinder ab neun Jahren werden mittlerweile rekrutiert. Die Kindersoldaten werden oft geschlagen oder gar exekutiert, wenn sie von der gegnerischen Seite gefangen genommen werden. Nicht zuletzt ist auch die Lage der Menschenrechte von Homosexuellen in Somalia extrem schlecht. Nach Angaben der International Lesbian, Gay, Bisexual, Trans and Intersex Association (ILGA) wird die Todesstrafe für gleichgeschlechtliche Beziehungen bzw. homosexuelle Handlungen verhängt. Somalia weist weltweit die höchste Rate von weiblicher Genitalverstümmelung auf. Etwa 98 % der Mädchen und Frauen zwischen 15 und 49 Jahren sind genitalverstümmelt. Sehr häufig wird eine Infibulation des weiblichen Genitals vorgenommen. Diese Praktik war unter der Regierung Siad Barres gesetzlich verboten worden, blieb jedoch weitverbreitet. Im faktisch autonomen Puntland beschloss das Regionalparlament 1999 ein Verbot. Am 8. März 2004 begann eine landesweite Kampagne, in deren Rahmen der damalige Präsident der Übergangsregierung, Abdikassim Salat Hassan, von einem Verbrechen gegen die Religion und gegen die Menschlichkeit sprach. Am 26. Oktober 2005 veröffentlichten islamische Geistliche in Mogadischu eine Fatwa, die sich gegen die Mädchenbeschneidung richtet. Darin wird diese in Afrika weit verbreitete traditionelle Praxis als „unislamisch“ verurteilt. Nach den Angaben des Somalia 2015 Human Rights Report, welcher jährlich vom Außenministerium der Vereinigten Staaten herausgegeben wird, befinden sich die betriebenen Gefängnisse in einem sehr schlechten Zustand. 2013 teilte der damalige Premierminister von Somalia, Abdi Farah Shirdon, in einem Bericht mit, dass die Zustände im Zentralgefängnis von Mogadischu erbärmlich seien. Er bat die internationale Gemeinschaft um Rat, damit nachhaltige Verbesserungen erreicht werden können. Auch das Büro der Vereinten Nationen für Drogen- und Verbrechensbekämpfung (UNODC) teilte mehrfach mit, dass die Zustände im Zentralgefängnis unhaltbar seien. Nach Angaben der UNODC seien im Zentralgefängnis etwa 1.200 Gefangene untergebracht.

Das Land ist offiziell in 18 Regionen eingeteilt. Diese Einteilung hat seit dem Zerfall des Staates jedoch nur beschränkte praktische Bedeutung:

Somalia gehört zu den ärmsten und am wenigsten entwickelten Ländern der Welt, wobei die politische Lage die Erhebung genauer Wirtschaftsdaten schwierig macht. Schätzungsweise rund 70 % der Bevölkerung leben von der Landwirtschaft. Ein Großteil davon lebt als Nomaden oder Halbnomaden mit Kamelen, Schafen und Ziegen, in fruchtbareren Gebieten auch mit Rindern. Ackerbau wird vor allem an den Flüssen Jubba und Shabelle und zwischen diesen beiden Flüssen in Südwestsomalia betrieben, daneben auch in kleineren Gebieten Nordsomalias. Vieh und Bananen sind wichtige Exportgüter.

Des Weiteren werden Fisch, Mais, Hirse und Zucker für den inländischen Bedarf angebaut oder hergestellt. Der kleine industrielle Sektor, der hauptsächlich landwirtschaftliche Nutzgüter produziert, beträgt nur 10 % des BIP. Viele Fabriken wurden wegen des Bürgerkriegs geschlossen. Ein Großteil der somalischen Bevölkerung ist auf Geldüberweisungen von Verwandten im Ausland angewiesen, sodass im Dienstleistungssektor Geldüberweisungsinstitute – die meist nach dem informellen Hawala-System funktionieren – mit stetiger Nachfrage rechnen können.

2008 war auch Somalia infolge von hoher Inflation, Trockenheit, verschlechterter Sicherheitslage sowie globalen Faktoren von steigenden Nahrungsmittelpreisen betroffen. Die Vereinten Nationen gingen im Juni 2008 davon aus, dass in den Folgemonaten bis zu 3,5 Mio. Menschen von Nahrungsmittelhilfe abhängen könnten. Damit wurde die Situation als noch dramatischer eingeschätzt als in Darfur.

Teile der Wirtschaft profitieren von dem Zustand ohne funktionierende Regierung und damit ohne staatliche Steuern und Regulierungen. So gilt das Telekommunikationssystem mit Mobiltelefonnetzbetreibern wie "NationLink Telecom" als günstiger und zuverlässiger als in den Nachbarstaaten. Da keinerlei staatliche Regulierung vorhanden ist, können aber auch Aktivitäten wie Geldfälschung, die Piraterie vor der somalischen Küste oder der ökologisch problematische Holzkohleexport weitgehend ungestört stattfinden.

Der IWF schätzt das Bruttoinlandsprodukt des Landes im Jahre 2016 auf ca. 6 Milliarden US-Dollar. Pro Kopf ergibt sich damit eine Wirtschaftskraft von knapp unter 500 US-Dollar womit Somalia zu den 10 ärmsten Ländern der Welt gehört. Die Wirtschaftsleistung wuchs in den letzten Jahren mit 3 bis 4 Prozent pro Jahr und damit nicht bedeutend schneller als die Bevölkerung des Landes. 

Im Korruptionswahrnehmungsindex 2017 nimmt Somalia den letzten Platz unter 180 Ländern ein, ebenfalls letzter ist das Land im Ease of Doing Business Index 2018 der Weltbank. Aufgrund der zusammengebrochenen staatlichen Ordnung ist es extrem schwierig im Land an Strom, Kapital oder qualifizierte Arbeitskräfte zu kommen.

Die unsichere politische Lage erschwert vor allem in Süd- und Zentralsomalia die Tätigkeit internationaler Hilfsorganisationen, die hier vorwiegend in der humanitären Hilfe tätig sind. UN-Organisationen wie UNICEF und das Welternährungsprogramm der Vereinten Nationen liefern humanitäre Hilfe. Im stabileren Norden (Somaliland und Puntland) wird auch (Wieder-)Aufbau betrieben, dies vor allem mithilfe der Geldüberweisungen von Auslands-Somaliern, aber auch durch internationale Organisationen. Wegen des sichereren Umfeldes fließt die internationale Hilfe für Somalia vermehrt in diese nördlichen Gebiete.

Einheimische Organisationen engagieren sich in diversen Bereichen.

Mitte 2008 töteten radikale Islamisten mehrere ausländische und einheimische Helfer, die sie der „Spionage“ verdächtigten.

Somalia liegt in unmittelbarer Nähe wichtiger internationaler Schifffahrtswege. Zugleich besteht seit Anfang der 1990er Jahre keine wirksame Küstenwache. Unter diesen Umständen hat sich die Piraterie vor der Küste Somalias zu einem profitablen Geschäft und einer Gefahr für die internationale Schifffahrt entwickelt. Somalische Fischer, Bürgerkriegskämpfer und Geschäftsleute nehmen ausländische Schiffsbesatzungen in Geiselhaft, um Lösegeld zu erpressen oder rauben sie aus. Als Ursache für diese Piraterie gilt auch das illegale Eindringen europäischer und asiatischer Fangflotten in somalische Gewässer, wodurch einheimische Fischer ihre Lebensgrundlage verloren und zum Teil auf Piraterie umstiegen. Die Zahl der Piratenangriffe vor der Küste Somalias ist in den letzten Jahren zurückgegangen, die Situation bleibt jedoch weiterhin angespannt und unsicher.

So stellt die Regierung der teilautonomen Region Puntland laut einem Artikel von IRIN fest, dass die illegale Fischerei durch fremde Fangflotten seit der Präsenz von ausländischen Kriegsschiffen an somalischen Küsten noch zugenommen hat, und fordert, dass die Kriegsschiffe auch ausländische Fischer kontrollieren.

Weil der Staat Somalia faktisch nicht existent ist, gibt es derzeit auch keinen Haushalt für den Gesamtstaat. Die Staatsverschuldung betrug 1993 1,9 Mrd. US-Dollar oder 189 % des BIP. Die Staatsverschuldung wurde 2013 auf ca. 2,2 Mrd. USD (IWF) bzw. 3,2 Mrd. USD beziffert. Die Schulden sollen im Rahmen der HIPC-Initiative erlassen werden.

Die Kultur Somalias ist vom Nomadentum, dem Islam und (mündlich überlieferter) Dichtung geprägt.

Die somalische Küche variiert von Region zu Region, insbesondere vom Norden des Landes zum Süden, und enthält Einflüsse von den traditionellen Küchen der Somali, Äthiopier, und mit Abstrichen der Jemeniten, Perser, Türken, Inder und Italiener.

Zum Frühstück gibt es meist Tee und pfannkuchenartiges Brot, welches Canjeero genannt wird. Als Mittagessen wird oft ein gekochtes Hauptgericht auf Reisbasis gekocht, welches häufig mit Kreuzkümmel, Kardamom, Gewürznelken oder Salbei verfeinert wird. Eine abgewandelte Form der italienischen Pasta wird ebenfalls häufig gegessen. Als Getränk dazu gibt es häufig Fruchtsäfte oder Limonaden. Das Abendessen gibt es meist erst gegen 21 Uhr, in der Zeit des Ramadan sogar erst gegen 23 Uhr. Die beliebteste Abendspeise der Somali nennt sich "Cambuulo" und besteht hauptsächlich aus gekochten Adzukibohnen, Butter und Zucker. Die Kochzeit der Bohnen kann bis zu fünf Stunden betragen. Als Getränk wird abends vor allem mit Kardamom gewürzte Milch getrunken. Zwischendurch werden neben vielen Früchten und Süßwarenspezialitäten wie Halva vor allem spezielle somalische Samosa gereicht.

Musikalisch zeichnet sich das Land vor allem durch die traditionelle somalische Folklore aus. Beim ersten Hören weist die somalische Musik durchaus Ähnlichkeiten mit derer umliegender Gebiete wie Äthiopien, dem Sudan oder Arabien auf, aber beim genaueren Zuhören erkennt man die speziellen somalischen Melodiestile. Eine bekannte somalische Sängerin war Magool (1948–2004). Neben Maryam Mursal (* 1950) ist Magools Neffe K’naan (* 1978), der mit Wavin’ Flag in zahlreichen internationalen Charts Platz 1 erreichte, der wohl bekannteste lebende somalische Musiker.

Im Land gab es seit langem viele Märchen und Volksgeschichten, welche oft von Generation zu Generation weitergegeben wurden und häufig eine Verbindung zum Islam besaßen. In den 1960er Jahren förderten die beiden Periodika "Sahan" (dt. etwa „Aufklärung“) und "Horseed" (dt. etwa „Vorhut, Avantgarde“) die Niederschrift der reichen, bis dahin jedoch ausschließlich mündlichen traditionellen Literatur. Die moderne Literatur entwickelte sich erst nach der Verschriftung der somalischen Sprache. Von da an veröffentlichten verschiedene somalische Autoren Romane, welche zum Teil weltweit erschienen, so auch der somalische Romancier Nuruddin Farah, der mit Werken wie "Maps" (1986) zu einem der bedeutendsten afrikanischen Schriftsteller der Gegenwart wurde. Ein weiterer populärer somalischer Autor war Farah Mohamed Jama Awl, der vor allem durch sein Buch "Ignorance is the enemy of love" (1974/1982 englisch) berühmt wurde.





</doc>
<doc id="5017" url="https://de.wikipedia.org/wiki?curid=5017" title="Spielkonsole">
Spielkonsole

Spiel(e)konsolen sind Computer oder computerähnliche Geräte, die in erster Linie für Videospiele entwickelt werden. Neben dem Spielen können sie weitere Funktionen bieten – zum Beispiel Wiedergabe von Audio-CDs und DVD-Video. Es wird geschätzt, dass Spielekonsolen 25 % der weltweit gesamten Rechenleistung von Mehrzweckcomputern im Jahr 2007 ausmachten. Als gegenwärtige Hersteller von Spielekonsolen konnten sich Sony, Microsoft und Nintendo etablieren.

Man unterscheidet zwischen stationären Geräten, die in der Regel an ein Fernsehgerät oder einen Monitor angeschlossen werden, und tragbaren Spielkonsolen mit eingebautem Monitor (siehe Handheld-Konsole).

In ihrem jeweiligen Entwicklungszeitraum entspricht die Grafikleistung einer Spielkonsole meist ungefähr der der jeweils aktuellen Computermodelle oder übertrifft sie sogar. Zum Teil gibt es Konsolen, deren Prozessorleistung ebenfalls über der von aktuellen PCs liegt, gewöhnlich ist sie aber geringer.

Aus Sicht der Spieleentwickler liegt der größte Vorteil von Spielkonsolen gegenüber PCs darin, dass sie es mit einer jeweils einheitlichen Hardware-Plattform zu tun haben, für die sie die Software optimieren können. PCs bestehen dagegen aus den unterschiedlichsten Komponenten. Es ist aufwendig, ein reibungsloses Funktionieren des Spiels mit allen diesen Komponenten zu gewährleisten oder gar die Software zu optimieren.

Obwohl bei Spielkonsolen die Hardwarekomponenten im Vergleich zu zeitgleich angebotenen PCs meist weniger leistungsfähig sind, wirkt ein Konsolenspiel oft flüssiger als ein PC-Spiel. Das wird einerseits durch die Programmierer erreicht, die es verstehen, die Ressourcen der Konsole voll auszuschöpfen. Anderseits wird schon in der Entwicklungsphase einer Konsole darauf geachtet, Bauteile zu benutzen, die nur fürs Spielen gedacht sind. Auf unnötige Peripherie und Anschlüsse wird aus Kostengründen verzichtet. Moderne Spielkonsolen haben zwar erweiterte Anschlüsse, doch diese dienen als Gadgets und werden selten genutzt. Für den Benutzer besteht der Vorteil darin, dass bei Konsolen keine Systemwartung und aufwändige Betriebssysteminstallation nötig ist. Eine fest gespeicherte Firmware bootet das Gerät.

Der Nachteil der Konsolen besteht darin, dass die Plattform auf einem bestimmten Entwicklungsstand eingefroren ist und die Leistungsfähigkeit im Lebenszyklus der Spielkonsole zunehmend hinter der aktueller PCs zurückbleibt. Eine Leistungssteigerung durch Austausch von Einzelkomponenten ist in der Regel weder möglich noch vorgesehen – im Gegensatz zu PCs. Auch die Bedienungsmöglichkeiten der Konsole sind gegenüber dem PC eingeschränkt. Des Weiteren sind die Preise für Videospiele in der Regel aufgrund von Lizenzgebühren, die Spielehersteller an den jeweiligen Konsolenhersteller zahlen müssen, höher als die ihrer PC-Pendants (auch wenn es sich um das gleiche Spiel handelt). Auch diverse Hardware und Gadgets sind für Spielkonsolen teurer, da es sich um Spezialentwicklungen für das jeweilige Konsolenmodell handelt, während PC-Peripherie meist mit ziemlich allen zeitgleich erhältlichen PCs funktioniert und daher in größeren Stückzahlen produziert werden kann.

Diese kann man grob in mehrere Abschnitte und Generationen einteilen (s. Literatur), wobei die Zuordnung und Zählweise variiert. Einige Angaben ignorieren beispielsweise die Anfänge vor dem 1983er-Crash und zählen die hier „dritte Generation“ genannten Geräte als „erste Generation“. Siehe auch Geschichte der Videospiele und Liste der Videospielkonsolen.

Die erste Spielkonsole der Welt war die 1968 von Ralph Baer entwickelte "Brown Box" und die 1972 erschienene lizenzierte Version "Magnavox Odyssey". Da die Geräte der ersten Generation für den Anschluss an handelsübliche Fernseher konstruiert waren, wurden sie in Deutschland meist "Telespiele" genannt. Zu den ersten Spielen gehörte Pong. Die Telespiele boten nur vorgegebene Spielvarianten, austauschbare Spielmodule waren meistens nicht vorgesehen. Bei diesen Geräten handelte es sich noch nicht um Computer im eigentlichen Sinne; es gab keine Programme, sondern die einzelnen Spiele wurden direkt durch fest verdrahtete elektronische Schaltkreise erzeugt. Zu den Konsolen der ersten Generation zählen auch die Home-Pong-Konsolen von Atari sowie der Coleco Telstar von Coleco.

Die zweite Generation besaß einfache 2D-Grafikfähigkeiten, konnte nur wenige Farben darstellen, besaß keine Grafikbeschleunigung und nur einen sehr beschränkten Speicher. Es handelte sich aber schon um „richtige“ Computer. Als CPU kamen meist 8-bit-Prozessoren (zuerst auch 4-bit-Prozessoren) zum Einsatz, als Speichermedien wurden Steckmodule benutzt.


Im Jahr 1983 brach der Videospiele-Markt ein, die Lücke in der Spielkonsolen-Geschichte wurde durch Heimcomputer gefüllt; siehe Geschichte der Videospiele. Man prophezeite das Ende der Spielkonsolen-Ära, bis neue Konsolen einen Teil des Marktes zurückeroberten.

Die dritte Generation bot verbesserte 2D-Grafikfähigkeiten, mehr Farben, Grafikbeschleunigung und etwas größeren Speicher. Auch hier wurden noch 8-bit-Prozessoren verwendet.


Die vierte Generation besaß meist 16-Bit-Prozessoren, umfangreiche 2D-Grafikfähigkeiten, rudimentäre 3D-Fähigkeiten und Möglichkeiten für größere Speichermodule und Erweiterungen. Erstmals wurde auch die CD als Speichermedium verwendet.


Die fünfte Generation bot 3D-Grafikfähigkeit, gerenderte Videosequenzen und besseren Sound. Die meisten Konsolen verwendeten jetzt CDs anstelle von Modulen als Speichermedium. Dazu kamen Vibrationsfunktionen an Controllern, Memory-Cards zum Speichern von Spielständen, das Abspielen von Audio-CDs und in Ausnahmefällen ein Online-Zugang.


Die sechste Generation bot teils erweiterte Multimediafähigkeiten (Video-DVDs abspielbar, Onlinezugang, Mehrkanalton, Fernbedienung optional), teilweise optische Audio-Ausgänge, USB- und Netzwerkanschlüsse, bessere 3D-Grafik und einen optionalen Einbau von Festplatten.


Die Konsolen der siebten Generation sind via Dial-up, Ethernet oder WLAN onlinefähig und bieten erweiterte Multimedia-Fähigkeiten. Noch bedeutender in dieser Generation war der vermehrte Einsatz bzw. die feste Etablierung von Spielsteuerungen mittels Bewegungen. Dabei unterscheiden sich die verschiedenen Konzepte der Hersteller zur Umsetzung einer Bewegungssteuerung enorm.


Microsoft und Sony entwickelten ihre Konsolen konsequent weiter in Richtung Steigerung der Rechenleistung und Grafikfähigkeiten sowie der Wiedergabe von DVD-Nachfolgerformaten. Sony benutzte zudem einen kabellosen bewegungsempfindlichen Controller (Sixaxis), der dem ursprünglichen äußeren Design der PS2-Controller entspricht. Seit Juli 2008 sind auch aus den Vorgängermodellen bekannte Controller mit "Dualshock"-Funktion erhältlich.

Nintendo grenzte sich dagegen deutlich von seinen beiden Mitbewerbern ab und setzte bei kaum verbesserter Grafikleistung auf innovative Controller (Wiimote), die Bewegungssensoren und eine eingebaute infrarotempfindliche Kamera besitzen. Damit wird sowohl eine Lage- und Beschleunigungserkennung möglich wie auch die genaue Erkennung des anvisierten Punktes am Fernsehbild, ähnlich einer Maus am PC. Mit vergleichsweise günstigem Preis und zugänglichem Spieledesign wurde versucht, zusätzliche Käuferschichten anzusprechen. Der Stromverbrauch liegt unter dem der beiden Mitbewerber.

Später, im Jahr 2010, veröffentlichten auch Sony und Microsoft verbesserte Bewegungssteuerungen als Erweiterungen für ihre Konsolen. Während Sonys PlayStation Move sowohl einen bewegungsempfindlichen Controller als auch eine Kamera (PlayStation Eye), die diesen erkennt, beinhaltet, verzichtet Microsofts Kinect auf einen Controller und wird mithilfe einer Tiefensensor- und Farbkamera alleine durch Körperbewegungen gesteuert.

Die erste Konsole der achten Generation, war Nintendos Wii U, die am 18. November 2012 in Nordamerika erschien. Der Verkauf in Europa und Australien begann am 30. November 2012 und in Japan am 8. Dezember 2012. Die Konsole ist abwärtskompatibel sowohl zur Software als auch zum Zubehör des Vorgängers Wii. Technisch liegt das Gerät etwas über dem Leistungsniveau der PlayStation 3 und Xbox 360. Hauptmerkmal ist ein Gamecontroller mit einem berührungssensitiven, integrierten Zweitbildschirm, der u. a. in Verbindung mit dem Spielgeschehen am Monitor/Fernseher für die Darstellung ergänzender Inhalte genutzt werden kann.

Die PlayStation 4 wurde von Sony am 20. Februar 2013 der Öffentlichkeit präsentiert. Sie basiert erstmals auf einer x86-Mikroarchitektur, dem AMD Jaguar, und wurde als eine APU ("Accelerated Processing Unit") realisiert. Prozessor und Grafikeinheit befinden sich somit auf einem gemeinsamen Chip. Die Auslieferung der Konsole erfolgte ab November 2013.

Die Xbox One von Microsoft wurde am 21. Mai 2013 präsentiert und ebenfalls ab November 2013 ausgeliefert.

Daneben präsentierten mehrere Anbieter neue Konsolenkonzepte, die häufig auf dem Betriebssystem Android für Mobilgeräte beruhen. In einem Beitrag, der sowohl auf der US-amerikanischen Branchenwebsite Gamasutra als auch vom britischen Spielemagazin Edge veröffentlicht wurde, bezeichnete Autor und Spieleentwickler Tadgh Kelly diese in Anlehnung an den Begriff Mikrocomputer für kostengünstige Heimcomputer wie den BBC Micro, den Commodore 64, den Sinclair Spectrum oder den Amiga als „microconsoles“ (Mikrokonsole). Dabei handele es sich um nicht sonderlich große und im Vergleich zu den bisherigen Anbietern weniger leistungsfähige Geräte, die dafür wesentlich kleiner und günstiger seien und deren Spiele ebenfalls zu einem weitaus günstigeren Preis über den integrierten Onlineshop veröffentlicht würden. Laut dem US-amerikanischen Spielemagazin 1UP ziele außerdem keine dieser Konsolen darauf ab, mit anderen Anbietern um die Stellung als alleinige Spielemaschine zu konkurrieren.

Zu den bekanntesten Vertretern dieser Mikrokonsolen zählt die mit Hilfe einer Crowdfunding-Kampagne über Kickstarter finanzierte Ouya. Mit der Auslieferung der Ouya wurde im April 2013 begonnen. Als Betriebssystem wird eine Android-Variante verwendet. Ausgerüstet mit einem NVIDIA Tegra 3-SoC (Quad-Core mit 1,4 GHz) verfügt die Konsole über 1 GB RAM und unterstützt über HDMI 1080p.

Die Playstation 4 Pro erschien am 10. November 2016 und ist eine leistungsstärkere Konsole als die normale PlayStation 4. Das PlayStation-VR-Headset erschien am 12. Oktober 2016.

Die Nintendo Switch wurde am 20. Oktober 2016 auf YouTube sowie der offiziellen Website von Nintendo offiziell zum ersten Mal vorgestellt. Am 13. Januar 2017 gab es eine einstündige Präsentation über die kommende Konsole aus dem Hause Nintendo, am 3. März schließlich wurde sie zum Verkauf freigegeben. Die Switch ist ein Hybrid aus Heim- und Handheld-Konsole.

Im Rahmen der E3 2017 wurde Microsofts neue Spielekonsole Xbox One X (Codename "Xbox Scorpio") vorgestellt. Sie wurde am 7. November 2017 veröffentlicht.





</doc>
<doc id="5022" url="https://de.wikipedia.org/wiki?curid=5022" title="Tom Tykwer">
Tom Tykwer

Tom Tykwer [] (* 23. Mai 1965 in Wuppertal) ist ein deutscher Filmregisseur, Drehbuchautor, Filmproduzent und Filmkomponist. Seine bekanntesten Arbeiten sind "Lola rennt", "Heaven", "Das Parfum – Die Geschichte eines Mörders", "The International" und der Science-Fiction-Film "Cloud Atlas" mit den Wachowski-Geschwistern.

Tom Tykwer drehte mit elf Jahren seine ersten Super-8-Filme und arbeitete mit dreizehn als Filmvorführer. In Berlin wurde er 1988 Manager des Moviemento-Filmtheaters in Kreuzberg. 1992 gründete er mit dem Produzenten Stefan Arndt die Firma "Liebesfilm" und inszenierte zunächst als Regisseur zwei Kurzfilme.

Mit "Die tödliche Maria" und "Winterschläfer" gelangen ihm sodann viel beachtete Anfangserfolge. Er gründete 1994 zusammen mit Stefan Arndt, Dani Levy und Wolfgang Becker die Produktionsfirma X Filme Creative Pool. 1998 wurde sein dritter Film, "Lola rennt", auch ein großer Publikumserfolg. Es folgten 2000 "Der Krieger und die Kaiserin" und 2002 seine erste internationale Produktion "Heaven". 2004 drehte er den Kurzfilm "True", der ein Teil des Kompilationsfilms "Paris, je t’aime" ist. Danach führte er bei "Das Parfum – Die Geschichte eines Mörders" Regie, einer Verfilmung des gleichnamigen Romans von Patrick Süskind.

2008 beendete Tykwer die Arbeit an der deutsch-amerikanischen Koproduktion "The International" mit Clive Owen und Naomi Watts in den Hauptrollen. Der Film stellt einen Interpol-Agenten und eine New Yorker Staatsanwältin in den Mittelpunkt, die planen, die illegalen Aktivitäten einer mächtigen Großbank aufzudecken. Zum weiteren Schauspielensemble gehören unter anderem Armin Mueller-Stahl, Ulrich Thomsen und James Rebhorn. Der Thriller eröffnete Anfang Februar 2009 die 59. Auflage der Filmfestspiele von Berlin, wo er außer Konkurrenz gezeigt wurde.

Im gleichen Jahr erschien der von Tykwer initiierte Episodenfilm "Deutschland 09", an dem mit Fatih Akin, Wolfgang Becker, Dominik Graf, Sylke Enders, Romuald Karmakar, Nicolette Krebitz, Isabelle Stever, Hans Steinbichler und Hans Weingartner namhafte deutschsprachige Regisseure beteiligt waren. Das Projekt war an den Film "Deutschland im Herbst" (1978) angelehnt. Von Tykwer selbst stammt der Kurzfilm "Feierlich reist" mit Benno Fürmann in der Hauptrolle. "Deutschland 09" wurde am 13. Februar 2009 auf der 59. Berlinale uraufgeführt und lief dort außer Konkurrenz.

Im November 2009 drehte Tykwer in und um Berlin den tragikomischen Film "Drei", seinen ersten in deutscher Sprache seit zehn Jahren. In den Hauptrollen spielen Sophie Rois, Devid Striesow und Sebastian Schipper. Die Weltpremiere fand auf den 67. Internationalen Filmfestspielen von Venedig statt, wo der Film auch im offiziellen Wettbewerb um den Goldenen Löwen lief. 2011 folgten für "Drei" sechs Nominierungen für den Deutschen Filmpreis 2011, darunter in den Kategorien "Bester Film", "Beste Regie" und "Beste Filmmusik" (gemeinsam mit Johnny Klimek, Reinhold Heil und Gabriel Isaac Mounsey). Tykwer wurde mit dem Regiepreis ausgezeichnet.

Ab 2009 arbeitete Tykwer zusammen mit den Wachowski-Geschwistern an der Verfilmung des Buches "Der Wolkenatlas" von David Mitchell. Tykwer ist als Regisseur, aber vor allem als Komponist seit 2015 an deren Serie "Sense8" beteiligt. "Cloud Atlas" hatte seine Premiere am 8. September 2012 auf dem Toronto International Film Festival. Zusammen mit den Regisseuren Chris Kraus, Robert Thalheim, Axel Ranisch und der Regisseurin Julia von Heinz drehte Tykwer den Dokumentarfilm "Rosakinder" (2012) über die Beziehung zu ihrem gemeinsamen „Filmvater“ und Mentor Rosa von Praunheim. 

Tykwer war einer der Regisseure der im September 2017 angelaufenen Fernsehserie "Babylon Berlin", die auf einer Romanreihe von Volker Kutscher basiert. Im November 2017 wurde Tykwer als Jury-Präsident der Internationalen Filmfestspiele Berlin 2018 bestimmt.

Tykwer hatte einige Jahre musikalischen Unterricht bei dem Wuppertaler Jazzpianisten Bernd Köppen. Zusammen mit Reinhold Heil und Johnny Klimek schreibt er auch die Musik für seine Filme. Seit 2000 ist er Mitglied der Akademie der Künste, Sektion Film- und Medienkunst, in deren Archiv sich auch sein eigenes Archiv befindet. Tykwer gehört seit der Gründung des Michael-Althen-Preis für Kritik im Jahre 2012 dessen Jury an.

Bis 2002 war Tykwer mit Franka Potente liiert. Seit 2009 ist er mit Marie Steinmann verheiratet, das Paar hat zwei Kinder.










</doc>
<doc id="5023" url="https://de.wikipedia.org/wiki?curid=5023" title="Terry Gilliam">
Terry Gilliam

Terry Vance Gilliam [] (* 22. November 1940 in Medicine Lake, Minnesota) ist ein amerikanisch-britischer Filmregisseur, Drehbuchautor und Schauspieler. Bekannt wurde er als Mitbegründer der Gruppe Monty Python.

Gilliam studierte Politikwissenschaft am Occidental College in Eagle Rock bei Los Angeles. Seine Laufbahn startete er 1962 als Zeichner des in New York produzierten Satire-Magazins "HELP!", einer Schwester-Publikation von "MAD", wo er John Cleese kennenlernte. Er zeichnete auch zwei Kurzgeschichten für das französische Magazin "Pilote".

John Cleese vermittelte ihm nach seinem Umzug nach England 1967 eine Stelle bei der BBC. Dort traf er auf weitere Komiker, mit denen er und Cleese die Gruppe "Monty Python" gründeten. Hier war Gilliam anfangs als Autor und Regisseur, später auch als Schauspieler tätig. Die Art von Humor der Sketche der Pythons unterschied sich enorm von dem bislang gewohnten Humor. Teils waren die Einfälle sehr hintergründig, teils aber auch bewusst taktlos und provozierend. Die Sketche mussten keinen Sinn ergeben, sondern beruhten auf einem meist absurden Humor; sie wiesen häufig keine Pointe auf, und gelegentlich gab es noch nicht mal ein Ende.
Vor allem aber war Gilliam für die skurrilen Trickfilme der Komikertruppe verantwortlich, für deren Animation er eine Legetricktechnik verwendete.

Sein Regiedebüt im Realfilm gab er 1975 in Zusammenarbeit mit Terry Jones mit dem Monty-Python-Film "Die Ritter der Kokosnuss". Vorher erwarb er Erfahrungen im Animationsfilm mit "Storytime" (1968) und "The Miracle of Flight" (1974). 1977 folgte sein erster eigener Film: "Jabberwocky", der – wie einige andere Filme von Gilliam – fälschlicherweise häufig als Monty-Python-Film bezeichnet wird.

Nachdem er zusammen mit den übrigen Pythons deren größten Erfolg "Das Leben des Brian" vollendet hatte, begann er, sich vollständig um seine eigene Regiekarriere zu kümmern. 1981 erschien die Komödie "Time Bandits". Für den letzten Python-Kinofilm "Der Sinn des Lebens" drehte er eigenständig den „Vorfilm“ "The Crimson Permanent Assurance", einen 15-minütigen surrealistischen Kurzfilm, dessen Produktionskosten die des Hauptfilms überschritten. Für den eigentlichen Film, "Der Sinn des Lebens", war er wieder für die Animationen zuständig, schrieb am Drehbuch mit und spielte in einigen der Sketche kleine Rollen.

1985 erschien "Brazil", der ihn als eigenständigen Filmemacher unabhängig von "Monty Python" etablierte und bis heute als eines seiner ambitioniertesten Werke gilt. Der Film behandelt auf surreale und oft satirische Weise die Dystopie eines paranoiden Überwachungsstaates. Drei Jahre später wurde "Die Abenteuer des Baron Münchhausen" veröffentlicht, bei dem unter anderen John Neville als Münchhausen und Robin Williams als Mondkönig zu sehen sind.

Nachdem "Münchhausen" an den Kinokassen erfolglos geblieben war, nahm Gilliam in den 1990ern mehrere Auftragsarbeiten an: Zunächst 1991 "König der Fischer" mit Robin Williams und Jeff Bridges und dann 1995 seinen größten Erfolg "12 Monkeys" mit Bruce Willis, der seine Rolle deutlich unter den sonst für ihn üblichen Gagen übernahm, um mit Gilliam zusammen einen Film machen zu können, und Brad Pitt, der zur Drehzeit noch vor seinem Durchbruch zum Star stand.

1998 folgte "Fear and Loathing in Las Vegas", für den Gilliam erstmals auch wieder am Drehbuch mitschrieb, der in kommerzieller Hinsicht zwar deutlich weniger Erfolg als die beiden Vorgängerfilme hatte, aber dennoch „Kultstatus“ erlangte.

Georg Seeßlen (in epd Film, 10/2005) attestierte Terry Gilliam, er sei:

2000 widmete sich Gilliam mit "The Man Who Killed Don Quixote" einem Projekt, das er bereits zehn Jahre lang geplant hatte, welches dann aber katastrophal scheiterte (siehe unten). 2002 führte Gilliam Regie bei dem Nike-Werbespot "The Secret Tournament", der auch in Deutschland als Teil der Nike-Werbekampagne zur Fußballweltmeisterschaft gezeigt wurde.

2005 vollendete Gilliam die Filme "Brothers Grimm" und "Tideland".
"Brothers Grimm" kam am 25. August 2005 in die US-amerikanischen Kinos und wurde von der Kritik nahezu einhellig verrissen. Die Besucherzahlen jedoch waren in der ersten Woche besser als bei jedem seiner anderen Filme zuvor. Vor allem das als schlecht empfundene Drehbuch und die unausgegorene Story standen im Blickpunkt der Kritik, während Gilliams Visualisierung teilweise positiv bewertet wurde.

"Tideland" dagegen zeichnete sich durch die typische Gilliam-Skurrilität aus und wurde unter anderem auf dem San Sebastián International Film Festival ausgezeichnet. Das zur Verfügung stehende, niedrige Budget führte jedoch dazu, dass die Produzenten den Film kaum bewarben und dieser in Europa daher überhaupt nicht im Kino gezeigt wurde.

Im Dezember 2007 begannen in London die Dreharbeiten zu Gilliams Film "Das Kabinett des Doktor Parnassus" mit Heath Ledger und Christopher Plummer in den Hauptrollen und mit Tom Waits als „Mr. Nick“ (dem Teufel). In die Kinos sollte der Film zunächst Anfang 2009 kommen. Durch Ledgers überraschenden Tod im Januar 2008 musste die Produktion jedoch unterbrochen werden. Die Dreharbeiten, Ledgers Rolle betreffend, waren zu diesem Zeitpunkt noch nicht abgeschlossen, konnten im März 2008 in Vancouver aber fortgesetzt werden. Teile von Ledgers Rolle, die in fantastischen Parallelwelten spielen, wurden von Johnny Depp, Colin Farrell und Jude Law übernommen.

Der englische Kinostart für "The Imaginarium of Doctor Parnassus" war am 16. Oktober 2009, in Nordamerika brachte der US-Verleih Sony Pictures Classics den Film am 25. Dezember in die Kinos. In Deutschland war der Film unter dem Titel "Das Kabinett des Doktor Parnassus" ab dem 7. Januar 2010 zu sehen.

Im Januar 2009 wurde bekannt, dass Gilliam nach Abschluss von "The Imaginarium of Doctor Parnassus" einen neuen Versuch machen würde, "The Man Who Killed Don Quixote" zu drehen. 2012 begann Gilliam aber zunächst mit der Produktion des Films "The Zero Theorem", die ursprünglich bereits für 2009 geplant gewesen war. Die Hauptrollen übernahmen unter anderem Christoph Waltz, Mélanie Thierry und Matt Damon. Der Film befand sich ab Anfang 2013 in der Postproduktion und wurde auf den Filmfestspielen von Venedig am 2. September 2013 der Öffentlichkeit vorgestellt.

Im Jahr 2000 wollte sich Gilliam, der seinen Ruf als respektabler Filmemacher nach den Erfolgen in den 90ern wiederhergestellt sah, endlich um ein Projekt kümmern, an dem er bereits etwa zehn Jahre lang gearbeitet hatte: "The Man Who Killed Don Quixote", für dessen Hauptrollen er Johnny Depp und Jean Rochefort gewinnen konnte.

Doch die Dreharbeiten wurden zur Katastrophe, Jets einer nahen Nato-Basis stiegen ständig während des Drehs auf, ein Wolkenbruch machte die Wüstenlandschaft ungeeignet für die Continuity der Filmaufnahmen, und als schließlich der Hauptdarsteller Jean Rochefort wegen gesundheitlicher Probleme nicht mehr reiten konnte, wurden die Dreharbeiten eingestellt. Der Dokumentarfilm "Lost in La Mancha" von Keith Fulton und Louis Pepe zeigt das Scheitern dieser Dreharbeiten. Die Rechte am Film gingen über in den Besitz der deutschen Versicherungsfirma, die den Film versichert hatte, was eine Neuaufnahme der Dreharbeiten jahrelang unmöglich machte.

Im Juli 2006 berichtete Gilliam, dass die rechtlichen Streitigkeiten mittlerweile beigelegt seien, so dass "The Man Who Killed Don Quixote" in absehbarer Zeit realisiert werden könne. Im Oktober 2009 erklärte er, dass mittlerweile das Drehbuch wieder freigegeben sei und das Budget und die Hauptdarsteller festständen. Zu diesem Zeitpunkt waren Johnny Depp und Robert Duvall als Besetzung im Gespräch. Der seinerzeit geplante Erscheinungstermin 2011 konnte dann aber nicht realisiert werden.

Im Januar 2014 gab Gilliam die Wiederaufnahme der Vorproduktion für den Film bekannt. Im Juni 2017 gab er den Abschluss der Dreharbeiten bei Facebook bekannt.

"The Defective Detective" war ein Film über einen heruntergekommenen Detektiv, der in der Fantasiewelt eines Kindes endet. Er war nach "König der Fischer" und später noch einmal nach "12 Monkeys" geplant, Nicolas Cage hatte für die Hauptrolle zugesagt, und auch Bruce Willis hatte großes Interesse an dem Film, doch die Paramount-Studios wollten den Film nicht finanzieren. Danach kehrte Gilliam Hollywood zunächst den Rücken aus Enttäuschung darüber, dass man nach den Erfolgen "König der Fischer" und "12 Monkeys" immer noch kein Vertrauen in ihn setzte.

2001 schrieb Gilliam zusammen mit Tony Grisoni (mit dem er schon das Drehbuch zu "Fear and Loathing in Las Vegas" geschrieben hatte) ein Drehbuch auf Basis des Romans "Ein gutes Omen" (OT: "Good Omens") von Neil Gaiman und Terry Pratchett. Dessen Verfilmung wurde zugunsten anderer Projekte vorerst zurückgestellt, da ein Filmstudio ihm zwar ein Budget von 45 Millionen US$ zur Verfügung stellte, zusätzlich benötigte 15 Millionen US$ trotz bestehender Zusagen von Johnny Depp und Robin Williams für die Hauptrollen jedoch nicht zustimmte. Zurzeit arbeitet Gilliam an einer möglichen Wiederaufnahme dieses Projekts, hat aber bislang noch nicht ausreichend Investoren gefunden.

"Theseus and The Minotaur" war ein Projekt, an dem Gilliam nach der Vollendung von "Jabberwocky" arbeitete. Da er mit dem von ihm selbst geschriebenen Drehbuch nicht zufrieden war, wandte er sich anderen Projekten zu. Nach "12 Monkeys" arbeitete er noch einmal daran, ließ es aber wieder fallen. Derzeit ist es eher unwahrscheinlich, dass dieses Projekt realisiert wird.

"A Tale of Two Cities" war ein Projekt, dem sich Gilliam 1994 widmete. Mel Gibson war für die Hauptrolle vorgesehen, doch dieser wandte sich sehr früh wieder von dem Projekt ab, um "Braveheart" zu drehen. Liam Neeson sollte danach die Rolle übernehmen, doch die Filmstudios waren daraufhin nur noch bereit, weniger als die Hälfte an Produktionskosten bereitzustellen. Gilliam hielt den Film mit weniger als der Hälfte des ursprünglichen Budgets für nicht mehr realisierbar.

Mitte der 1990er arbeitete Gilliam an einem Drehbuch für eine Fortsetzung von "Time Bandits", 2002 arbeitete ABC an einem entsprechenden Fernsehserienformat. Über den gegenwärtigen Status des Projekts ist nichts bekannt.

Gilliam arbeitete 1995/1996 etwa ein halbes Jahr lang an einer Neuverfilmung des Stoffs, für die er Gérard Depardieu in der Hauptrolle vorsah. Als Gilliam jedoch erfuhr, dass Disney zeitgleich an einer Zeichentrickfilm-Version arbeitete, wandte er sich von dem Projekt ab.

"A Scanner Darkly – Der dunkle Schirm" war ebenfalls ein Projekt, an dem Gilliam nach "König der Fischer" arbeitete. Wieder einmal scheiterte auch dies an den Filmstudios, die für das Projekt kein grünes Licht gaben. Es handelt sich um eine düstere Science-Fiction-Geschichte von Philip K. Dick (dt. Buchtitel „Der dunkle Schirm“). Nach den neuen Anti-Terror-Gesetzen in den USA schien die Geschichte vielen jedoch wieder so aktuell, dass der Film mit mehr als zehn Jahren Verspätung realisiert wurde. Er kam im Sommer 2006 in die Kinos, nachdem er im selben Jahr bereits auf dem Fantasyfilmfest gezeigt worden war. Die Hauptrolle spielt Keanu Reeves. Terry Gilliam war an dem Projekt jedoch nicht mehr beteiligt, Regie führte Richard Linklater.

Die Verfilmung des gleichnamigen „Anti-Superhelden-Comics“ von Alan Moore (auf Deutsch "Watchmen – Die Wächter") wurde Gilliam erstmals 1989 angeboten, wofür er zunächst auch zusagte. Der Film musste dann aber wegen mangelhafter Finanzierung verschoben werden. 1996 wurde Gilliam erneut gefragt, ob er noch Interesse an einer Verfilmung hätte, doch Gilliam war in der Zwischenzeit zu der Überzeugung gelangt, dass die Geschichte zu komplex sei, um als Kinofilm realisiert werden zu können. Er schlug stattdessen eine Miniserie vor, was jedoch auf wenig Gegenliebe beim Produzenten stieß. 2005 wurde das Projekt wiederbelebt, diesmal jedoch ohne Gilliam. Nachdem Paramount den Film anfänglich nicht finanzieren wollte, wurde das Projekt aufgrund der vorhergehenden Einspielerfolge mit Verfilmungen von Alan Moore-Comics nun unter der Regie von Zack Snyder umgesetzt.

Gilliam war auch der Wunschkandidat von Joanne K. Rowling als Regisseur für die Verfilmung von Harry Potter, doch das Filmunternehmen Warner Bros. weigerte sich, mit Gilliam zusammenzuarbeiten und entschied sich für Chris Columbus. Gilliam war über die ablehnende Haltung von Warner Bros. gegenüber seiner Person sehr verärgert: „Ich wäre der perfekte Mann für Harry Potter gewesen. Ich verließ das Treffen [mit den Produzenten], stieg in mein Auto und fuhr für etwa zwei Stunden wütend den Mulholland Drive entlang. Ich meine, Chris Columbus’ Version ist fürchterlich. Einfach stumpfsinnig.“

Auch Philip Pullman sprach sich für eine Verfilmung seines Bestsellers "Der goldene Kompass" durch Gilliam aus. Wie auch bei Harry Potter folgten die Produzenten jedoch nicht dem Wunsch des Autors.

Ebenso wollte die Witwe des Autors Roald Dahl Gilliam als Regisseur für die Neuverfilmung von "Charlie und die Schokoladenfabrik" verpflichten. Auch dies scheiterte am Veto der Produzenten.

Mit seinem Projekt „past people of Potsdamer Platz“ zeigte Terry Gilliam im Mai 2006 (4. Mai bis 8. Juni 2006) eine Video-Installation in Berlin am Potsdamer Platz und wagte sich damit auf das Feld der „Kunst im öffentlichen Raum“. Er entwarf lebensgroße Figuren aus Metall, welche statt des Kopfes ein Loch hatten. Sah man in eine solche Figur hinein, konnte man Videoaufzeichnungen vom Leben auf dem Potsdamer Platz der letzten 50 Jahre betrachten. Dabei wurden die Besucher fotografiert und anschließend als aus einzelnen Teilgesichtern gemorphte „Big faces“ auf der Licht- und Medienfassade gezeigt. Ziel seiner Arbeit war es, die Passanten mit der Geschichte des Platzes und mit sich selbst zu konfrontieren.


In vielen seiner eigenen Filme hatte Gilliam Cameo-Auftritte, die nicht in den Darstellerlisten auftauchen.

Seit 1973 ist Terry Gilliam mit Maggie Weston verheiratet, die als Maskenbildnerin an vielen Monty-Python- und Gilliam-Produktionen mitwirkte. Zusammen haben sie zwei Töchter Amy Gilliam (* 1978 als Amy Rainbow Gilliam) sowie Holly Dubois Gilliam (* 1980), die später eine kleine Rolle in "Brazil" spielte, außerdem haben sie noch einen Sohn namens Harry Thunder Gilliam (* 1988).

1968 nahm Terry Gilliam zusätzlich zur US-amerikanischen auch die britische Staatsbürgerschaft an. Im Januar 2006 gab er seinen US-amerikanischen Pass ab und besitzt seitdem keine weitere Staatsangehörigkeit als die britische. Nach einigen Quellen geschah dies aus Protest gegen die Regierung Bush. In einem am 3. Januar 2010 publizierten Interview sagte Gilliam hingegen, dies sei kein politisches Statement gewesen, sondern geschah, um seine latente Kapitalgewinnsteuerpflicht in den USA zu beenden, welche gemäß US-Recht auf seiner Liegenschaft in London gelastet hatte, solange er US-Bürger war, obwohl er sein Domizil in Großbritannien hat. Allerdings kritisiert er George Bush und Dick Cheney in dem Interview, weil diese aus ihrer Amtszeit angeblich ein nicht autorisiertes reales Remake seines Films "Brazil" über einen Überwachungsstaat gemacht hatten.

2017: Aufnahme in die Science Fiction Hall of Fame




</doc>
<doc id="5024" url="https://de.wikipedia.org/wiki?curid=5024" title="Takeshi Kitano">
Takeshi Kitano

Takeshi Kitano (jap. "Kitano Takeshi"; * 18. Januar 1947 in Adachi, Tokio) ist ein japanischer Regisseur, Schauspieler, Dichter, Autor, TV- und Radiomoderator, Maler und populärer Comedian. In Deutschland ist er vorrangig dank der Filme Hana-Bi, Battle Royale, Zatoichi – Der blinde Samurai, Kikujiros Sommer, aber auch der Gameshow Takeshi’s Castle bekannt geworden. Seit April 2005 ist er außerdem Dozent an der Tokyo National University of Fine Arts and Music. In Japan ist er auch unter dem Pseudonym "Beat Takeshi" bekannt.

Geboren wurde Kitano im Januar 1947 in Adachi, einem Arbeiterviertel am Stadtrand Tokios. Er war das vierte und jüngste Kind seiner Mutter Saki († 1999) und seines Vaters Kikujiro († 1979). Zusammen mit seinen Geschwistern – Shigekazu, Yasuko und Masaru – musste Kitano eine sehr unangenehme und harte Kindheit erfahren: Sein Vater – Anstreicher von Beruf – gab sein Geld meist für das Trinken und Spielen aus, sodass die Familie in Armut lebte. Wenn sein Vater schlafen wollte, wurde der junge Takeshi wohl zum Lesen unter die Straßenlaterne geschickt, um die einzige Lichtquelle im Zimmer, eine Taschenlampe, zu schonen. 
Seine Mutter Saki hingegen arbeitete hart und ermöglichte all ihren Kindern eine gute Ausbildung. Dank dieser schaffte es Kitano bis auf die Meiji-Universität, welche er aber nur kurze Zeit später verließ. Zur selben Zeit rannte er von zu Hause weg.

Nach verschiedenen Gelegenheitsjobs, beispielsweise als Taxifahrer oder Kellner, begab er sich nach Asakusa. Im Strip-Lokal France-za bot man Kitano, der von nun an Komiker werden wollte, einen Job als Fahrstuhljunge an. Später bekam er eine Ausbildung von seinem Meister Fukami Senzaburo. Nach einigen holprigen Auftritten lernte er den Komiker Kaneko Kiyoshi kennen. Zusammen bildeten sie das Komikerduo „The Two Beats“, woher auch Kitanos heutiger Künstlername "Beat Takeshi" stammt, Kitano spielte den traditionellen „Boke“, den Dummkopf (Manzai). Schon bald wurde das Duo bekannt, denn vor allem Kitanos aggressiver und sozialkritischer Humor fand Anklang bei der Jugend. Einer seiner bekanntesten Gags ist bis heute: „Akashingo, minna de watareba kowakunai“ („Wenn alle bei Rot über die Straße gehen, ist es ungefährlich“) und sein „Comaneci“, welchen er noch heute verwendet und der nach der rumänischen Turnerin Nadia Comăneci benannt ist. Als Kiyoshi der Humor von Kitano zu provokant wurde, trennte sich das Duo und dieser machte erfolgreich als Solokünstler weiter.

1976 lernte Kitano bei einem Gastauftritt in einer Fernseh-Show die Komikerin Mikiko kennen. Die beiden heirateten im Jahr 1978.

Ab 1981 hatte Kitano vor allem Erfolg mit der Show „Ore-tachi hyokinzoku“ („Wir sind eine Komikerfamilie“), in der er zusammen mit seinem Kollegen Akashiya Sanma „Takechan Man“ spielte. Akashiya stellte jeweils die Gegner Takechan Mans dar, welche mit den Jahren wechselten. Im selben Jahr startete seine wöchentliche Radioshow „All night nippon“. Die Sendung baute Kitano auf ihm zugeschickten Postkarten des Publikums auf und schuf so eine verhältnismäßig enge, beinahe schon brüderliche Beziehung zu seiner Zuhörerschaft – die zum großen Teil aus Jugendlichen bestand – auf. Die Themen reichten von Familiengeschichten bis hin zu Tipps für das Masturbieren.

Am 31. März 1981 wurde Kitanos Sohn Atsushi geboren. Am 5. Oktober 1982 kam seine Tochter Shoko zur Welt.
Das schauspielerische Talent Takeshi Kitanos wurde von dem bis heute renommierten Filmemacher Nagisa Ōshima entdeckt.

1983 durfte Kitano in einer Nebenrolle den glatzköpfigen japanischen Sergeanten „Gengo Hara“ eines Kriegsgefangenenlagers im Film „Furyo – Merry Christmas, Mr. Lawrence“ spielen. Für ihn ein positiv besetzter und pointiert sympathischer Auftritt, da er im Finale an Heiligabend betrunken und schmunzelnd als „Weihnachtsmann“ zwei Lagerinsassen ihre Strafen erlässt. Entsprechend fand Kitano Gefallen am Kino. Zwar folgten Fernsehfilme, in denen man einen ernsten Kitano in dramatischen Rollen erlebte, jedoch wurde diese Facette erst ab Ende der 1990er wirklich akzeptiert.

1986 war ein sehr ereignisreiches Jahr für Kitano. Die Zeitschrift „Friday“ publizierte ein Foto von ihm und einer jungen Frau und behauptete, sie sei seine Geliebte. Daraufhin überfielen Kitano und seine Anhänger, die Takeshi Gundan, die Redaktion der Zeitung. Kitano wurde verhaftet. Ihm drohten sechs Monate Haft, letztlich kam er jedoch mit einer Geldstrafe davon. Daraufhin nahm er eine monatelange Pause vom Fernsehen und damit von der Öffentlichkeit, nachdem ihn dieser Skandal beinahe seine Ehe gekostet hätte, da Kitano schon des Öfteren mit jungen Damen gesehen worden war. Tatsächlich sind Kitano und Mikiko bis heute verheiratet.

1989 sollte Kitano die Hauptrolle in einem Film von Kinji Fukasaku übernehmen. Da Kitano aber nicht Fukasakus Terminplan einhalten konnte, trennte sich Letzterer von dem Projekt und Kitano drehte seinen ersten Film "Violent Cop" bzw. "Sono otoko, kyobo ni tsuki" ("Vorsicht, dieser Mann ist gefährlich"). Einer der nächsten Filme Kitanos, die ebenso blutige wie poetische Gangsterballade "Sonatine", wurde 1993 bei den Filmfestspielen von Cannes in der Reihe „Un Certain Regard“ gezeigt. Doch auch wenn die internationale Presse ihm sehr positiv gegenüberstand, blieben Kitanos Filme außerhalb Japans wenig erfolgreich.

Kurz nach dem Ende der Dreharbeiten seines Filmes "Minna Yatteruka – Getting any", am 2. August 1994 hatte Kitano einen schweren Unfall. Im Bezirk Shinjuku nahm Kitano mit seinem Motorroller eine Rechtskurve zu hart, prallte gegen einen Pfeiler und flog vier Meter weit, ehe er auf den Asphalt prallte. Dabei erlitt er eine schwere Kopfverletzung.

Nach zwei Tagen im Koma wachte Kitano auf, ohne sich an den Unfall erinnern zu können. Tatsächlich konnte nie geklärt werden, ob es sich um einen Unfall oder um einen Suizidversuch handelte, welchen Kitano vor dem Unfall auch in Erwägung zog. Nach langer Rehabilitation, während der er auch seine Bilder malte, die später in den Filmen "Hana-Bi" und "Kikujiros Sommer" zu sehen sein sollten, trat Kitano wieder im TV auf. Die Integration in die Fernsehwelt lief problemlos ab, obwohl Kitano seit dem Unfall in der rechten, mit einer großen Narbe gekennzeichneten Gesichtshälfte gelähmt ist. Zudem kann man bisweilen ein minimales unwillkürliches Zucken der einen Gesichtshälfte bemerken.

Nach einer Umfrage des Magazins „Spa!“ aus dem Jahre 1995 war Beat Takeshi der beliebteste Mann Japans, bei der alljährlichen Publikumsbefragung des Fernsehsenders NHK wurde er zwischen 1990 und 1995 sechs Mal in Folge zum Fernsehstar des Jahres gewählt.

1996 drehte er den Film Kids Return, der auch in Cannes gezeigt wurde und auf eine ausgezeichnete Kritik stieß. Trotzdem blieben seine Filme außerhalb Asiens kommerziell nur mäßig erfolgreich.

Unter dem Titel ここがヘンだよ日本人 Koko ga hen da yo, nihonjin (Das hat keinen Sinn, liebe Japaner) wurde eine Fernsehshow Kitanos seit 1998 bekannt. Dabei sprachen klassische Gaijin wie Christoph Neumann über Seltsamkeiten und abstruse Verhaltensweisen der Japaner und der Japanischen Kultur.

Erst 1997 kam der Durchbruch außerhalb Japans. Sein Film "Hana-Bi" gewann bei den Internationalen Filmfestspielen von Venedig 1997 den Goldenen Löwen. Von einem Tag auf den anderen war Kitano nun auch außerhalb Japans ein großer Filmstar.

1999 folgte der Film "Kikujiro no natsu" ("Kikujiros Sommer"), der in Cannes als Favorit galt, jedoch leer ausging. Der Film ist trotz des Titels keine direkte Hommage an Kitanos Vater Kikujiro; er weist keine Elemente auf, die an seinen Vater erinnern. Allerdings räumte Kitano ein, dass er seinem Vater damit Respekt zolle, „anstatt sein Grab zu besuchen“.

Im Jahr 2000 wurde eine englischsprachige Dokumentation über das Leben und das Werk von Kitano unter dem Titel „Scenes by the Sea: Takeshi Kitano“ veröffentlicht. Zwei Jahre zuvor, im Jahr 1998, war bereits ein französischsprachiges Porträt unter dem Titel „L’imprevisible“ („Der Unvorhersehbare“) erschienen, gedreht von Jean-Pierre Limousin.

2000 drehte Kitano seinen ersten Film im Ausland und nahm selbst die Hauptrolle ein. Der zweisprachige, wieder blutigere Film Brother spielt in Los Angeles und behandelt auch die Thematik der Kulturunterschiede und die daraus resultierenden Missverständnisse. Danach folgte der Film "Dolls", ein farbenfroher und prächtiger Episodenfilm, in dem er alle Klischees der letzten Filme abarbeitet.

2003 folgte mit "Zatoichi" ein großer kommerzieller Erfolg in Japan. In Venedig gewann Kitano mit dem Film den Silbernen Löwen. "Zatoichi" ist ursprünglich eine Serie von Filmen, die von 1962 bis 1989 lief. Kitano griff damit seit dem Tod des Zatoichi-Darstellers Shintaro Katsu als erster das Sujet wieder auf in ironisierender Form.

2004 bekleidete er die Hauptrolle in dem bitteren Drama "Blood & Bones" ("Chi to hone") von Yoichi Sai. Für die sehr physische Darstellung eines patriarchalen Scheusals gab es von der Kritik überwiegend Lob.

Mit einem zunehmenden Maß an Selbstreferentialität lieferte er mit den folgenden Komödien die surrealistischen Fußnoten zu seinem Gesamtwerk nach, und ließ mit einem „Ultra Variety Movie“ die Weltöffentlichkeit an einem künstlerischen Neuorientierungsprozess von unbestimmtem Ausgang teilhaben: 

Im Jahr 2005 lief sein Film "Takeshi's" bei den Filmfestspielen in Venedig. Dort fand er aber nur mäßigen Anklang. Im Rahmen des Filmfests München 2006 wurde er in Deutschland präsentiert.

Sein Film "Glory to the Filmmaker!" ("Kantoku! Banzai!") wurde als erster Film mit dem neuen "Glory to the Filmmaker!"-Preis der Internationalen Filmfestspiele von Venedig 2007 ausgezeichnet. Ein Jahr später 
2008 erhielt Kitano für "Achilles to kame" ("Achilles und die Schildkröte") eine Einladung in den Wettbewerb der 65. Filmfestspiele von Venedig 2008. In Deutschland wurde der Film 2009 zum Filmfest München erstmals gezeigt.

Für die Filmfestspiele von Cannes erstellte er eine Episode von „Chacun son cinéma“.

Im März 2010 wurde Kitano in Frankreich zum Commandeur des Arts et Lettres ernannt. Sein Film "Outrage" erhielt im selben Jahr eine Einladung in den Wettbewerb der 63. Filmfestspiele von Cannes.

Takeshi löste im Mai 2012 eine Kontroverse aus, als er im Fernsehen bezüglich Barack Obamas Forderung der Öffnung der Ehe für gleichgeschlechtliche Paare verlautbaren ließ, dies würde am Ende zur Legalisierung von zoophilien Ehen führen. Nachdem Bürgerrechtler Takeshi Homophobie vorwarfen, führte dieser an, missverstanden worden zu sein, entschuldigte sich aber nicht. Im selben Jahr erhielt er für seinen Spielfilm "Outrage Beyond" seine siebte Einladung in den Wettbewerb der Filmfestspiele von Venedig.

Markenzeichen seiner Arbeit sind der Einsatz kontrastierender Genre-Elemente, eine lakonisch agierende Hauptfigur, sein Sinn für Absurdität, gepaart mit echtem Mitgefühl, die Verletzung narrativer Muster (insbesondere durch elliptische Auslassung) und die Enttäuschung von Erwartungen, visuell die vorherrschende Statik und eine unkonventionelle Fotografie bzw. überraschende Montage bei insgesamt „ruhiger“ Inszenierung. Das Starren in die Kamera gemahnt an den Kuleschow-Effekt. Bei Kitano "explodiert" die Gewalt darum regelrecht. Der Humor in den frühen Filmen basiert auf Wiederholung und Übertreibung und dem Kontrast, von seiner Präsenz als Schauspieler ist dies kaum zu trennen. Die Filme werden von repetitiver, oft elektronischer, oft romantischer Musik bestimmt (die Zusammenarbeit mit Joe Hisaishi beendete er 2003). Seit 1990 führt Katsumi Yanagishima bei ihm die Kamera.

War Goldener-Löwe-Gewinner "Hana-Bi" eine fatalistische Meditation über Trauer und Verzweiflung, scheint im späteren Werk (wieder) Verspieltheit, Selbstironie oder Slapstick in den Vordergrund zu treten. Nach "Zatoichi" kann man alle Regelmäßigkeiten in Kitanos Kino als aufgehoben betrachten.

Regisseur


Darsteller (Auswahl)







</doc>
<doc id="5025" url="https://de.wikipedia.org/wiki?curid=5025" title="Tautologie (Sprache)">
Tautologie (Sprache)

Tautologie (von altgriechisch = "to autó" ‚dasselbe‘ sowie "lógos" ‚Sprechen, Rede‘) bezeichnet in der Stilistik und Rhetorik eine rhetorische Figur, bei der mit einer inhaltlichen Wiederholung, sprich einer semantischen Redundanz, gearbeitet wird. Ein Gegenbegriff zu Tautologie ist das Oxymoron. Bewusste Tautologien werden in sogenannten „Zwillingsformeln“ geprägt.

Ein verwandter Begriff ist Pleonasmus. Die Ausdrücke „Tautologie“ und „Pleonasmus“ werden teils synonym, teils in unterschiedlicher Bedeutung verwendet. Die Abgrenzung hängt weitgehend von terminologischen Entscheidungen ab und ist dem jeweiligen Zusammenhang (Kontext) zu entnehmen.

„Tautologie“ kann zum einen bedeuten, dass dasselbe (dieselbe Sache, derselbe Sachverhalt) mit einem sinngleichen oder sinnverwandten Ausdruck noch einmal gesagt wird.


Tautologie in diesem Sinne einer „Wiedergabe des gleichen Sachverhalts durch mehrere Synonyme“ dürfte dabei der Regelfall sein.

Zum anderen ist es aber auch möglich, dass derselbe Ausdruck verwendet wird.


Einen Sonderfall stellt das Sprichwort „Dienst ist Dienst, und Schnaps ist Schnaps“ dar. Hierbei werden zwei Tautologien verwendet, um die Gesamtbedeutung, nämlich die Auffassung, dass Arbeit und Privatleben möglichst getrennt bleiben sollten, darzustellen. Insofern stellt das Sprichwort ein aus zwei Tautologien bestehendes Hendiadyoin dar.

Was auf den ersten Blick wie eine simple Tautologie (im logischen Sinn) aussieht – und mitunter auch auf einem Versprecher beruht  – kann, eingesetzt als stilistisches oder rhetorisches Mittel, der Verstärkung und Hervorhebung der Bedeutung (Emphase) dienen. Man spricht dann auch von "scheinbaren Tautologien".

In der Rhetorik werden normalerweise auch Wendungen als „Tautologien“ bezeichnet, in denen einem Substantiv ein Adjektiv beigefügt wird, dessen Bedeutung schon im Substantiv enthalten ist. Beispiele sind „schwarzer Rappe“, „alter Greis“ und „tote Leiche“. Der Ausdruck „weißer Schimmel“ ist das klassische Schulbeispiel für einen Pleonasmus. Allerdings ist dieses Beispiel weniger geeignet, da „Schimmel“ auch für junge Pferde beliebiger Fellfarbe verwendet wird, die aber aufgrund genetischer Bestimmung später weiß werden.

In einer anderen terminologischen Tradition wird „Tautologie“ denn auch als der Fall „gleichbedeutende(r) Wörter "derselben Wortart"“ vom Pleonasmus abgegrenzt. Entsprechend sind Ausdrücke wie „tote Leiche“, „inneres Gefühl“ keine Tautologien, sondern Pleonasmen.

Ähnlich unterscheidet man, wenn man nicht auf die Identität der Wortart, sondern auf eine Unter- bzw. Überordnung (dann Pleonasmus) oder Beiordnung (dann Tautologie) abstellt.

„Tautologie“ und „Pleonasmus“ werden weiterhin auch wertend unterschieden, was wiederum eine Frage terminologischen Beliebens ist, ohne dass sich ein fester Sprachgebrauch ausmachen lässt. Die Tautologie soll dann eine „Verdopplung zum Zwecke der rhetorischen Verstärkung“ sein, der Pleonasmus hingegen eine „überflüssige Häufung, die zum Teil als abweichend empfunden wird“. Tautologien im Sinne „gleichbedeutender Wörter derselben Wortart“ („angst und bange“ etc.) „gelten als rhetorische Stilmittel und sind daher über jede sprachliche Kritik erhaben.“
Die stilistische Erhabenheit von Tautologien hat aber anscheinend Grenzen. Oft rühren Tautologien aus nicht verstandenen Begriffen oder Fremdwörtern her („die La-Ola-Welle“, „der Guerillakrieg“, „der Düsenjet“, „die Salsa-Sauce“, „die Frontlinie“) oder werden in Form redundanter Akronyme verwendet, wie bei „HIV-Virus“ (HIV steht für "Human Immunodeficiency Virus"), „ABM-Maßnahme“ (ABM = Arbeitsbeschaffungsmaßnahme), „ABS-System“ (ABS = Antiblockiersystem), „ISBN-Nummer“ (ISBN = Internationale Standardbuchnummer), „LCD-Display“ (LCD = Liquid Crystal Display) oder „IGeL-Leistungen“ (IGeL = Individuelle Gesundheitsleistung). Sofern man diese Ausdrücke als Tautologien qualifiziert, dürfte die in ihnen enthaltene Redundanz eigentlich auf Un- oder Missverständnissen beruhen, die aber durch eine weitgehende Lexikalisierung stilistisch unschädlich geworden sind.




</doc>
<doc id="5027" url="https://de.wikipedia.org/wiki?curid=5027" title="Total-Quality-Management">
Total-Quality-Management

Total-Quality-Management (TQM), bisweilen auch umfassendes Qualitätsmanagement, bezeichnet die durchgängige, fortwährende und alle Bereiche einer Organisation (Unternehmen, Institution etc.) erfassende, aufzeichnende, sichtende, organisierende und kontrollierende Tätigkeit, die dazu dient, Qualität als Systemziel einzuführen und dauerhaft zu garantieren. TQM wurde in der japanischen Automobilindustrie weiterentwickelt und schließlich zum Erfolgsmodell gemacht. TQM benötigt die volle Unterstützung aller Mitarbeiter, um zum Erfolg zu führen.

Zu den wesentlichen Prinzipien der TQM-Philosophie zählen:


Das meistverbreitete TQM-Konzept in Deutschland ist das EFQM-Modell für Excellence der "European Foundation for Quality Management". Dieses Modell hat einen ganzheitlichen, ergebnisorientierten Ansatz. Die Kriterien dieses Modells werden zur Vergabe des wichtigsten deutschen Qualitätspreises, des Ludwig-Erhard-Preises herangezogen.

"Siehe auch:" Kaizen

Als Pionier forschte William Edwards Deming in den 1940er Jahren im Bereich Qualitätsmanagement. Doch in den USA schenkte ihm nach Beendigung des Zweiten Weltkriegs niemand Beachtung, da die Maximierung des Produktionsvolumens angesichts der nach dem Krieg weltweit insgesamt reduzierten Produktionskapazitäten im Fokus stand. Im kriegszerstörten Japan hatten seine Arbeiten dagegen mehr Erfolg. Das Total-Quality-Management wurde hier schnell zu einer viel beachteten Management-Philosophie; bereits 1951 wurde zum ersten Mal ein japanisches Unternehmen mit dem so genannten Deming-Preis für besonders hohe Qualitätsanforderungen ausgezeichnet.

Die Japaner eroberten in den folgenden Jahrzehnten mit qualitativ hochstehenden und doch preisgünstigen Produkten Marktanteile auf der ganzen Welt. Dies ging so weit, dass selbst die stolzen US-Unternehmen einen Blick nach Japan warfen und dabei auf die Deming’sche Qualitätsphilosophie stießen. In den siebziger und achtziger Jahren kam diese schließlich auch bei namhaften US-amerikanischen Unternehmen zur Anwendung. Von staatlicher Seite setzte sich vor allem Malcolm Baldrige, der von 1981 bis 1987 als Secretary of Commerce agierte, für Qualität in den Unternehmen ein. Der US-Kongress rief 1987 ein Belohnungsprogramm für Organisationen mit hohen Anforderungen an Qualität und Leistung ins Leben. Der Baldrige Award wird bis heute jährlich verliehen. Er basiert auf einem Qualitätsmodell, das auf den Ideen von Deming beruht und durch die Befragung von zahlreichen Unternehmen stetig weiterentwickelt wird.

Das Konzept dieses Preises schwappte auch nach Europa über. 1988 gründeten 14 große Unternehmen (unter ihnen Nestlé, Bosch, Philips, Ciba-Geigy und Sulzer) die "European Foundation for Quality Management (EFQM)", die sich die Entwicklung eines europäischen Modells für Qualitätsmanagement auf die Fahne schrieb. Das so genannte EFQM-Modell für Business-Excellence wird bis heute von der Organisation betreut und mit Hilfe der Praxis kontinuierlich angepasst. 1992 wurde zum ersten Mal ein Preis für Qualität auf europäischer Ebene verliehen.

Der Grundgedanke ist bei allen Modellen derselbe: Qualitätsmanagement soll sich nicht auf die technischen Funktionen zur Sicherstellung der Produktqualität beschränken, sondern wird auf die Beziehung zwischen dem Unternehmen und seinen Kunden definiert. Qualität ist nach Philip B. Crosby – einer der US-amerikanischen „Qualitäts-Gurus“ – die Erfüllung von Anforderungen. Oberstes Ziel ist die Kundenzufriedenheit, die nur durch eine langfristige Entwicklung des Unternehmens selbst dauerhaft gewährleistet ist. Das EFQM-Modell ist eine Art große "Checkliste", welche die Wirkungszusammenhänge in einem Unternehmen aufzeigen soll.
Das Modell umfasst acht Leitgedanken:

Diese sind im Sinne des so genannten Radar-Konzeptes ("Results", "Approach", "Deployment", "Assessment" und "Review") umzusetzen. Ein Unternehmen muss also zuerst die gewünschten Ergebnisse bestimmen, dann das Vorgehen für die Umsetzung planen, die Umsetzung durchführen und schließlich sowohl das Vorgehen (war es effektiv?) wie auch die Umsetzung (war sie effizient?) bewerten und überprüfen. Ein wesentlicher Gedanke des Modells ist der, das eigene Handeln und die eigenen Ergebnisse ständig mit dem Wettbewerb, und zwar mit den Besten im Wettbewerb, zu vergleichen. Zudem können die fünf Denkweisen (proaktiv, sensitiv-intuitiv, ganzheitlich, potentialorientiert und ökonomisch) auch für diesen Ansatz als immanent angesehen werden.

Das Modell kann grundsätzlich von allen Unternehmen angewandt werden. Es ist branchen- und größenunabhängig. In der Schweiz hat sich laut Liedtke aber gezeigt, dass kleine und mittlere Unternehmen (KMU) das Modell schneller umsetzen können. Große Firmen müssten mit mehr als sechs Jahren rechnen, bis sie sich zu Organisationen entwickelt haben, die eine umfassende Qualität mit entsprechenden Ergebnissen aufweisen. Die Finalisten des Esprix-Preises (dem Schweizer Qualitätspreis) waren in den vergangenen Jahren denn auch vorwiegend KMU; dieses Jahr waren erstmals vier der fünf Finalisten Großunternehmen. Bei großen Konzernen können aber auch einzelne Sparten, Divisionen oder gar Abteilungen das Excellence-Modell individuell anwenden. Ausschlaggebend für die erfolgreiche Umsetzung des Modells ist laut Liedtke vor allem das persönliche Engagement der obersten Führung.

Der Nutzen des EFQM-Modells ist zwar noch nicht genau analysiert worden, derjenige seines Pendants jenseits des Atlantiks indessen schon. In den USA haben wissenschaftliche Studien gezeigt, dass Unternehmen, die dem Excellence-Modell nachleben, höhere Umsätze und Gewinne, eine höhere Produktivität, eine bessere Aktien-Performance und eine schneller wachsende Zahl von Arbeitsplätzen als ihre Konkurrenten aufweisen können.

Den überzeugendsten Nachweis lieferte die Langzeitstudie von Vinod Singhal vom Georgia Institute of Technology und Kevin Hendricks von der University of Western Ontario aus dem Jahr 2000, in der die Leistung von beinahe 600 Gewinnern von Qualitätspreisen fünf Jahre lang verfolgt wurde. Das Ergebnis: Der Aktienpreis der Gewinner lag um 44 %, der Betriebsertrag um 48 % und der Umsatz um 37 % höher als in der Vergleichsgruppe.

Die Einführung von TQM gestaltet sich zum Teil schwierig, da die Unternehmenskultur gegebenenfalls verändert werden muss.
Im Kontext schnelllebiger Wirtschaft und kurzfristiger Gewinnerwartungen ist es schwer, Qualität als Firmenphilosophie zu erfassen.




</doc>
<doc id="5028" url="https://de.wikipedia.org/wiki?curid=5028" title="Trojanisches Pferd (Begriffsklärung)">
Trojanisches Pferd (Begriffsklärung)

Trojanisches Pferd bezeichnet


Siehe auch:


</doc>
<doc id="5032" url="https://de.wikipedia.org/wiki?curid=5032" title="Tom Hanks">
Tom Hanks

Thomas „Tom“ Jeffrey Hanks (* 9. Juli 1956 in Concord, Kalifornien) ist ein US-amerikanischer Schauspieler, Regisseur, Filmproduzent sowie Synchronsprecher vieler amerikanischer Film- und Fernsehproduktionen. Er gehört zu den profiliertesten Charakterdarstellern Hollywoods und wurde zweimal in Folge mit dem Oscar als Bester Hauptdarsteller ausgezeichnet (was außer Hanks bisher nur Spencer Tracy gelang) – für seine Hauptrollen in den Filmen "Philadelphia" (1993) und "Forrest Gump" (1994). Darüber hinaus hat er vier Golden Globes erhalten und wurde 2002 als bisher jüngster Darsteller mit dem AFI Life Achievement Award für sein Lebenswerk geehrt.

Nach eigenen Angaben kommt Tom Hanks aus „turbulenten Familienverhältnissen“. Seine Eltern, Amos Hanks und Janet Marylyn, geb. Frager († 2016), ließen sich früh scheiden, und er wuchs mit seinen Geschwistern Sandra und Lawrence bei seinem Vater und wechselnden Stiefmüttern auf, während der jüngere Bruder Jim Hanks bei der Mutter blieb.

1978 heiratete Hanks die Schauspielerin Samantha Lewes, 1987 wurde die Ehe geschieden. Aus dieser Ehe gingen zwei Kinder hervor, Colin (* 1977) und Elizabeth (* 1982). Samantha Lewes starb 2002 an Knochenkrebs. Im April 1988 heiratete Hanks erneut. Mit der Schauspielerin Rita Wilson hat er zwei Söhne (Chet Hanks, * 1990 und Truman, * 1995). Hanks brachte zudem seine ersten zwei Kinder mit in die Ehe. Vor seiner Heirat konvertierte er zur griechisch-orthodoxen Kirche.

Sein Interesse an der Schauspielerei entdeckte Tom Hanks während seiner Zeit an der High School, in der er häufig ins Theater ging und in Schauspielkursen erste eigene Erfahrungen sammelte. Dementsprechend begann er nach dem Abschluss der High School ein Studium der Schauspielerei. Nebenbei arbeitete er drei Jahre lang beim „Great Lakes Theater Festival“ in Cleveland, wo er Erfahrungen in allen das Theater betreffenden Bereichen vom Bühnenbild bis zur Licht- und Tontechnik sammelte. Außerdem spielte er dort unter anderem die Rolle des Proteus in Shakespeares "Zwei Herren aus Verona", für die er mit dem „Cleveland Critics Circle Award“ als bester Hauptdarsteller ausgezeichnet wurde. 

1979 zog er nach New York, wo er erste Film- und Fernsehrollen erhielt. Unter anderem wirkte er in der Sitcom Bosom Buddies mit und hatte Gastauftritte in den Serien "Taxi" (mit Tony Danza und Christopher Lloyd) und "Happy Days". In dieser Zeit lernte er Ron Howard kennen, mit dem er später bei vielen Projekten zusammenarbeitete. Durch Howard kam er auch an seine erste Hauptrolle in einem Kinofilm – in der Komödie "Splash – Eine Jungfrau am Haken", bei der Howard Regie führte.
Nach weiteren Komödien wie "Geschenkt ist noch zu teuer" oder "Scott & Huutsch" erhielt er schließlich auch Angebote für seriösere Rollen, wie zum Beispiel in "Fegefeuer der Eitelkeiten" und "Eine Klasse für sich". Das Jahr 1993 brachte ihm den Durchbruch mit den erfolgreichen Filmen "Schlaflos in Seattle" und "Philadelphia". Für seine Rolle des an Aids erkrankten "Andrew Beckett" in "Philadelphia" wurde Hanks mit dem Oscar als bester Hauptdarsteller ausgezeichnet. Bereits im darauffolgenden Jahr erhielt er für die Darstellung des geistig zurückgebliebenen "Forrest Gump" in dem gleichnamigen Film seinen zweiten Oscar. Die Auszeichnung mit zwei Oscars in Folge für die Kategorie „Bester Hauptdarsteller“ gelang vor ihm nur Spencer Tracy. Seine Dankesrede bei der Verleihung der Oscars für "Philadelphia", bei der er einem schwulen Lehrer dankte, gab den Anstoß für den Film "In & Out".

Es folgten zahlreiche erfolgreiche Kino-Produktionen, bei denen Hanks die Hauptrolle übernahm, darunter in "Apollo 13", "Der Soldat James Ryan", "Cast Away" und in "The Da Vinci Code".

1996 wechselte Hanks erstmals hinter die Kamera. Er gründete zusammen mit dem Produzenten Gary Goetzman die Produktionsfirma Playtone, mit welcher er fortan Filme produziert. Bei der ersten Playtone-Produktion, dem Film "That Thing You Do!", zeichnete er als Drehbuchautor und als Regisseur verantwortlich, übernahm eine Hauptrolle und wirkte an der Filmmusik mit. Zusammen mit seiner Frau Rita Wilson produzierte er die Komödie "My Big Fat Greek Wedding". Auch bei den TV-Serien "From the Earth to the Moon" und "Band of Brothers" trat er als Produzent und Autor auf. Darüber hinaus übernahm Hanks Sprechrollen für Trickfilme wie "Toy Story", "Der Polarexpress" und "Die Simpsons – Der Film".

Um seine Rollen möglichst glaubhaft darstellen zu können, nimmt Hanks auch in körperlicher Hinsicht Strapazen auf sich. So musste er für den Film "Cast Away" in relativ kurzer Zeit wesentlich an Gewicht zu- bzw. abnehmen, um die Rolle eines Schiffbrüchigen glaubhaft darstellen zu können. Die Dreharbeiten wurden hierfür mehrere Monate unterbrochen, nachdem die Szenen vor dem Flugzeugabsturz mit ihm als Manager von FedEx mit noch kräftigem Körperbau abgedreht waren.

Einen sehr kurzen und wortlosen Auftritt hatte Tom Hanks 2004 in dem Film "Elvis Has Left the Building". Darin wird er als Motorradfahrer von einem Briefkasten tödlich getroffen und bleibt in diesem stecken.

2017 veröffentlichte Hanks die Kurzgeschichtensammlung "Schräge Typen" (OT:"Uncommon Type"), welche unter anderem von seiner Schreibmaschinensammlung handelt.


Oscars

Auszeichnungen

Nominierungen

Golden Globe Awards

Auszeichnungen

Nominierungen

Screen Actors Guild Awards

Auszeichnungen

Nominierungen

British Academy Film Awards

Nominierungen

Weitere Auszeichnungen




</doc>
<doc id="5037" url="https://de.wikipedia.org/wiki?curid=5037" title="Tour de France">
Tour de France

Die Tour de France [], auch "Grande Boucle" [] (französisch für "Große Schleife") oder einfach "Le Tour" [] genannt, ist das berühmteste und für die Fahrer bedeutendste Radrennen der Welt.

Seit 1903 wird es alljährlich im Juli ausgetragen und führt dabei in wechselnder Streckenführung quer durch Frankreich und das nahe Ausland. Während des Ersten Weltkriegs fiel die Tour zwischen 1915 und 1918 aus, der Zweite Weltkrieg bedingte eine Unterbrechung von 1940 bis 1946. Das Etappenrennen wird von der Amaury Sport Organisation (ASO) veranstaltet. Die Tour wird oft als das nach den Olympischen Spielen und der Fußball-Weltmeisterschaft drittgrößte Sportereignis der Welt oder als das größte jährlich stattfindende Sportereignis bezeichnet und gilt als das härteste Radrennen der Welt.

Eine "Tour de France der Frauen", "La Grande Boucle Féminine Internationale", wurde mit Unterbrechungen von 1984 bis 2009 ausgetragen. Länge und Bedeutung waren im Vergleich zur Tour der Männer gering. Als Nachfolgeveranstaltung wird seit 2014 La Course by Le Tour de France, zu Beginn als Rundstreckenrennen vor der Schlussetappe der Tour de France 2014, ausgetragen.

"Le Grand Départ", französisch für "die große Abfahrt", ist die traditionelle Bezeichnung für den Beginn der Landesrundfahrt. Dieser Auftakt findet seit 1989 meistens am ersten Samstag im Juli statt; zuvor wurde auch wochentags begonnen. Traditionell lagen Start und Ziel in der Hauptstadt Paris. Von diesem Prinzip wich die Direktion erstmals 1926 ab, als sie die Gemeinde Évian-les-Bains im Osten Frankreichs als Ausgangspunkt wählte. Dies blieb vorerst die Ausnahme, erst mit dem Grand Départ in Metz 1951 wandelte sich das Bild. Seither startete die Tour nicht mehr in Paris, lediglich im Jubiläumsjahr 2003 machte die Rennleitung aus historischen Gründen eine Ausnahme.

Seit 1967 beginnt die Tour de France gewöhnlich mit dem so genannten Prolog. Er wird meist als Rundkurs in einer größeren Stadt ausgetragen und dient hauptsächlich dazu, die Fahrer einem möglichst großen Publikum zu präsentieren. Unabhängig davon werden die Teilnehmer aber schon am Vorabend des Prologs auf einer Art Pressekonferenz einzeln vorgestellt. Außerdem ergeben sich durch den Prolog – im Gegensatz zu einer regulären Etappe, die möglicherweise mit einer gemeinsamen Zielankunft des Pelotons enden würde – bereits Zeitabstände zwischen den Fahrern.

Überschreitet das Eröffnungs-Zeitfahren die vom Weltradsportverband UCI festgelegte Maximaldistanz von derzeit acht Kilometern, so wird es als erste Etappe bezeichnet. Dies war in den Jahren 2000 (16,5 Kilometer), 2005 (19,0 Kilometer), 2009 (15,5 Kilometer), 2015 (13,8 Kilometer) und 2017 (14 Kilometer) der Fall. 2008, 2011, 2013, 2014 und 2016 verzichtete die Rennleitung sogar ganz auf ein Zeitfahren zu Beginn und begann die Tour de France, wie bis in die 1960er-Jahre üblich, mit einer regulären Etappe über knapp 200 Kilometer.

Die auf den Grand Départ folgenden Etappen, meist zwanzig an der Zahl, zeichnen das französische Hexagon nach. Die Streckenführung und die Etappenorte wechseln dabei jedes Jahr. In den ersten zehn Jahren wurde dabei ausschließlich im Uhrzeigersinn gefahren, von 1913 bis 1932 dann nur gegen die Uhr. Seither ändert sich die Fahrtrichtung in immer rascherer Folge, zwischen 1998 und 2009 wurde sogar konsequent jährlich gewechselt.

Die ersten Tage der Tour de France sind fast immer von schnellen und sprinterfreundlichen Flachetappen im Norden Frankreichs geprägt, bevor sich dann im Hochgebirge der Pyrenäen und der Alpen die Gesamtwertung der Tour entscheidet. Wird die Tour im Uhrzeigersinn gefahren, so erreichen die Fahrer zuerst die Alpen, wird in der Gegenrichtung gefahren, so stehen die Pyrenäen zuerst auf dem Programm. Besonders spektakuläre Bergetappen werden dabei bevorzugt auf das zweite und dritte Wochenende im Verlauf der Tour oder den Französischen Nationalfeiertag am 14. Juli gelegt. Dadurch möchte man möglichst vielen Zuschauern eine Teilnahme am Renngeschehen ermöglichen.

Ergänzend dazu finden auch in den beiden Mittelgebirgen Vogesen und Zentralmassiv Bergetappen statt, wenngleich diese vom Schwierigkeitsgrad nicht mit jenen im Hochgebirge zu vergleichen sind. Flache Etappen zwischen zwei Gebirgen nennt man Übergangs- oder Überführungsetappen. Heute werden während der Tour de France in der Regel zwei Zeitfahren ausgetragen, das zweite meistens am Vortag der Schlussetappe nach Paris. Vereinzelt wird das erste Zeitfahren nicht als Einzelzeitfahren, sondern als Bergzeitfahren (zuletzt 2004) oder als Mannschaftszeitfahren (zuletzt 2015) ausgetragen.

Die insgesamt zu absolvierende Streckenlänge wurde nach dem Dopingskandal von 1998 deutlich reduziert und beträgt seitdem rund 3500 Kilometer. Die längste Tour wurde 1926 gefahren und war 5745 Kilometer lang, die kürzeste war die allererste Tour im Jahr 1903 mit insgesamt 2428 Kilometern. Auch die einzelnen Etappen sind kürzer als früher, heute werden zwischen 150 und 250 Kilometer täglich gefahren. Die längste jemals gefahrene Etappe führte 1919 über eine Entfernung von 482 Kilometern von Les Sables-d’Olonne nach Bayonne. Nicht mehr ausgetragen werden sogenannte "Halbetappen", die zwischen 1934 und 1991 üblich waren. Dabei mussten die Fahrer zwei- oder sogar dreimal an einem Tag antreten, typischerweise vormittags zum gewöhnlichen Rennen und nachmittags zum Zeitfahren.

Die Tour de France wird traditionell von mehreren Ruhetagen unterbrochen. In der Gegenwart sind dies meist der zweite und der dritte Montag während des Rennens. Anders als früher wird heute nur noch vergleichsweise selten in dem Ort gestartet, in welchem die Rennfahrer am Vortag angekommen sind. Ursächlich hierfür ist der Wunsch, möglichst viele Gemeinden in den Parcours einzubinden. Die Folge sind Transfers nach vielen Etappen. Diese erfolgen mit Kraftfahrzeugen. Für die Fahrer stehen speziell adaptierte Reisebusse ihrer jeweiligen Mannschaft zur Verfügung. In der Regel sind ein oder zweimal während jeder Tour de France auch längere Überführungen nötig. Sie finden entweder an einem der beiden Ruhetage oder am Abend nach einer Etappe statt. Solche längeren Strecken legen die Fahrer im Flugzeug oder im TGV zurück.

Die Tour hat in ihrer Geschichte alle Départements auf dem französischen Festland durchfahren. Im Jahr 2013 bei der 100. Austragung der Tour wurden schließlich auch die beiden Départements auf Korsika berücksichtigt. Die fünf Übersee-Départements Französisch-Guayana, Guadeloupe, Martinique, Mayotte und Réunion wurden bisher aus geografisch-logistischen Gründen nicht in das Programm aufgenommen.
Großstädte werden bei der Streckenführung heute eher gemieden. Die nachmittägliche Ankunft der Tour de France und die damit verbundenen Straßensperrungen führen dort, mitten in der Hauptverkehrszeit, häufig zu Verkehrsproblemen. Ebenso scheiden besonders kleine Gemeinden als Etappenort meistens aus. Grund hierfür sind logistische Probleme, insbesondere fehlende Unterkünfte für den Begleittross der Tour. Prinzipiell bevorzugt werden Kommunen, die noch nie Teil des Parcours waren. Der Zusage seitens der Tourdirektion geht ein aufwändiges Bewerbungsverfahren voraus. Manche Kommunen müssen viele Jahre lang darauf warten, bei der Streckenführung berücksichtigt zu werden. Für die Jubiläumstour 2013 haben beispielsweise gleich 250 Orte ihr Interesse als Etappenort angemeldet. Der Tourverlauf wird meist im Oktober des Vorjahres auf einer Pressekonferenz vorgestellt, davor unterliegt er strikter Geheimhaltung. Lediglich der Startort und der Verlauf der ersten Etappe werden schon früher publik gemacht.

Nicht selten werden eigens für die Tour Straßenbeläge erneuert. Typischerweise putzen sich die durchfahrenen Dörfer besonders heraus. Beliebt ist beispielsweise die besondere Gestaltung der Innenflächen von Kreisverkehren.

Paris ist der mit Abstand meist frequentierte Etappenort, bis einschließlich 2010 war die Tour 135-mal an der Seine zu Gast. An zweiter Stelle folgt Bordeaux, wo die Tour 80-mal gastierte, an dritter Stelle Pau, das 62-mal Etappenort war. Eine weitere Konstante in der Streckenführung sind bestimmte Gebirgspässe, die bei fast jeder Austragung passiert werden.

Die letzte Etappe findet seit 1967 immer an einem Sonntag statt, zuvor aber auch an anderen Wochentagen. Sie beginnt traditionell im Umland von Paris, der Île-de-France, und endet seit 1975 stets mit mehreren Schlussrunden auf den Champs-Élysées im Zentrum der Hauptstadt.

Die Gesamtwertung der Tour entscheidet sich in jedem Jahr neben den Zeitfahren vor allem im Hochgebirge. Einige Berge und Pässe stehen sehr häufig im Programm der Tour und haben im Laufe der Jahre einen geradezu mythischen Ruf erworben. Die damit verbundenen Bergwertungen werden entweder bei der Passage der Kulminationspunkte oder als sogenannte Bergankunft am Ende einer Etappe abgenommen. Die schwierigste Bergetappe eines Jahres, zumeist der Tag mit den meisten Höhenmetern oder den bedeutendsten Anstiegen, wird häufig auch als "Königsetappe" bezeichnet.

27 Anstiege erreichen eine Höhe von über 2000 Metern. Mit 2802 Metern ist die Cime de la Bonette der höchste bisher angefahrene Punkt, gefolgt vom Col de l’Iseran (2764 m) und dem Col Agnel (2744 m).

Die vier sogenannten "heiligen Berge" der Tour de France sind der Col du Tourmalet (2114 m, Pyrenäen), der im Jahre 1910 als erster Hochgebirgspass erklommen wurde, der Col du Galibier (2645 m, Alpen), der ein Jahr später ins Programm aufgenommen wurde, der Mont Ventoux (1909 m, Provence), dessen einsam aufragender Gipfel erstmals 1951 befahren wurde und durch den Tod von Tom Simpson 1967 zu trauriger Berühmtheit gelangte, und der Anstieg zur alpinen Skistation L’Alpe d’Huez, dessen legendäre 21 Kehren hinauf auf 1850 Meter zum ersten Mal 1952 in der Geschichte der Tour bewältigt wurden. Dies war gleichzeitig die erste Bergankunft des Rennens.

Weitere legendäre Tour-Berge sind der Col d’Aubisque in den Pyrenäen und der Col de la Madeleine in den Alpen. Der Col d’Aubisque gilt, wenn er von Nordwesten, meist von Pau herkommend angefahren wird, als besonders schwere Bergprüfung, weil er den Fahrern eine abrupte Umstellung vom Flachland aufs Hochgebirge abverlangt. Der Col de la Madeleine wird von Fahrern, aktuellen wie ehemaligen, wie zum Beispiel dem ehemaligen Bergspezialisten Tony Rominger, als eine der schwierigsten im gesamten Tour-Programm genannt. In früheren Jahren spielte außerdem der Vulkanberg Puy de Dôme eine große Rolle bei der Tour, er war zwischen 1952 und 1988 dreizehnmal Teil des Parcours, wird seitdem aber aus logistischen und ökologischen Gründen nicht mehr angefahren.

Die zehn am häufigsten angefahrenen Pässe sind:


Die Berge werden je nach Länge und Steigung des Anstiegs in fünf Schwierigkeitsgrade eingeteilt, diese nennt man Bergkategorien. Nach ihnen richten sich auch die maximal erzielbaren Punkte für das Gepunktete Trikot der Tour de France:

Die Punkte werden nach den Sonderreglement der jeweiligen Austragung vergeben: z. B. im Jahr 2012 gestaffelt zwischen 25 und zwei Punkten für die ersten zehn Fahrer und einem Punkt für den ersten Fahrer bei einem Anstieg der 4. Kategorie.

Traditionell führt die Tour de France über sechs Bergetappen, davon meist drei in den Alpen und drei in den Pyrenäen. Darin enthalten sind circa fünfzehn für die Fahrer nennenswerte Anstiege, das heißt Berge der 1. Kategorie oder der Hors Catégorie.

Schon in der Frühzeit des Rennens wurden die französischen Landesgrenzen bei einzelnen Etappen überschritten. Erstmals war dies 1906 der Fall, als die Tour Lothringen und das Elsass passierte. Beide Gebiete hatte Frankreich 1870/71 im Deutsch-Französischen Krieg an das Deutsche Reich verloren. Dabei wurde erstmals auch die für den deutsch-französischen Konflikt symbolträchtige Stadt Metz durchfahren. Noch im selben Jahr führte die Tour außerdem durch Italien und Spanien. Schon 1907 war Metz schließlich auch erster ausländischer Etappenort.

Nachdem 1908, 1909 und 1910 drei weitere Zielankünfte in Metz stattfanden, begannen die Zuschauer daraus ein chauvinistisches Ereignis zu machen und stimmten die Marseillaise an. Deshalb untersagten die deutschen Behörden aus politischen Gründen nach 1910 weitere Gastspiele der Tour. Anschließend dauerte es bis 1964, ehe die Tour infolge der Deutsch-französischen Freundschaft wieder einen Abstecher nach Deutschland machte; seither geschieht dies regelmäßig.
Im Laufe der Jahre wurden dann in unregelmäßigen Abständen auch alle anderen heutigen Nachbarstaaten in den Parcours einbezogen, so die Schweiz (erstmals 1907, 1913 erstmals mit Etappenort Genf), Monaco (erstmals 1939), Belgien (erstmals 1947), Luxemburg (erstmals 1947) und Andorra (erstmals 1964). Auch im teilautonomen Saarland (1947 bis 1956), das wirtschaftlich an Frankreich angeschlossen war, war die Tour zweimal zu Gast, nämlich 1948 und 1953.

Später kamen auch Staaten dazu, die keine gemeinsame Grenze mit Frankreich haben. Dies waren die Niederlande (erstmals 1969), Großbritannien (erstmals 1974) und Irland (1998). Ferner auch West-Berlin (1987), das damals noch vom Gebiet der DDR umschlossen war und einen politischen Sonderstatus genoss. Seit 1954 findet auch der Grand Départ in unregelmäßigen Abständen im nahen Ausland statt, bisher


Nicht selten orientiert sich die Tour dabei an politischen Gesichtspunkten oder sonstigen Großereignissen. Dem ersten Nachkriegs-Abstecher nach Deutschland 1964 ging beispielsweise im Jahr zuvor der Élysée-Vertrag voraus. Das erste Gastspiel in Großbritannien fand im Jahr nach dem Beitritt des Landes zur Europäischen Gemeinschaft statt, das nächste 1994 ein Jahr nach Eröffnung des Eurotunnels. Dieser wurde auch für den Transfer der Fahrer und der Begleitpersonen genutzt.

Der Abstecher nach West-Berlin fand anlässlich der 750-Jahr-Feier Berlins statt. Gleichzeitig unterstrich er, mitten im Kalten Krieg, die Position Frankreichs als Garantiemacht im Rahmen des Viermächte-Status. In der DDR wurde diese Aktion als Provokation wahrgenommen, so wurde daraufhin der Start der Internationalen Friedensfahrt 1987 von Warschau nach Ost-Berlin verlegt.

Mit dem Befahren von Spanien, Frankreich, Belgien, den Niederlanden, Deutschland, Luxemburg und Italien war die Tour 1992 erstmals im selben Jahr in sieben Ländern zu Gast. In allen Ländern fanden zudem Etappenankünfte beziehungsweise Etappenstarts statt. Anlass hierfür war die vorangegangene Unterzeichnung des Vertrags von Maastricht am 7. Februar desselben Jahres.

Der langgehegte Plan, die Tour in den Vereinigten Staaten (New York) oder Kanada (Québec) zu starten, wurde hingegen aufgrund des immensen Aufwands bisher nicht umgesetzt. Für die Jubiläumstour 2013 bewarben sich – neben Korsika – mit Katar, Lugano, Salzburg, Schottland, Tokio und Utrecht weitere Städte, Regionen beziehungsweise Staaten, in welchen die Tour bislang noch nicht zu Gast war.

Seit 1969 wird die Tour de France durch von Unternehmen zu Werbezwecken betriebenen oder gesponserten Profimannschaften bestritten, wie auch schon in der Anfangszeit des Rennens. Von 1930 bis 1961 und dann noch einmal 1967 und 1968 traten dagegen Nationalmannschaften an.

Derzeit werden jährlich 21 bis 22 Profimannschaften mit je neun Fahrern zu der Tour de France eingeladen. Die 18 UCI WorldTeams haben nach dem UCI-Reglement für World-Tour-Rennen das Recht und die Pflicht zur Teilnahme. Die übrigen Mannschaften wählt der Veranstalter aus dem Kreis der Professional Continental Teams aus. Die meisten Teams kommen üblicherweise aus Frankreich, Italien und Spanien, dazu einzelne Mannschaften aus Belgien, den Niederlanden, Deutschland, Dänemark, der Schweiz und den USA. Diese Nationen stellen auch den Großteil der Fahrer. Einzelne Radprofis stammen aus dem übrigen Mitteleuropa, Skandinavien, Osteuropa sowie Kasachstan, Kolumbien, Australien, Südafrika und Japan.

Mit je 17 Starts sind der Mecklenburger Jens Voigt, der US-Amerikaner George Hincapie, der Australier Stuart O’Grady und der Franzose Sylvain Chavanel die vier Rekordteilnehmer der Tour de France. Sie alle erreichten allerdings nicht immer das Ziel in Paris. Dagegen fuhr der Niederländer Joop Zoetemelk die Tour zwar nur 16 Mal, beendete sie aber jedes Mal, davon siebenmal auf dem Podium und 1980 einmal als Gesamtsieger. Damit ist er alleiniger Rekordhalter bei den Zielankünften. Je 15 Mal bestritten die Tour der mehrfache Gewinner der Bergwertung und Gesamtsieger von 1976 Lucien Van Impe und sein Landsmann Guy Nulens (bester Rang Platz 22), beide aus Belgien, sowie der Russe Wjatscheslaw Wladimirowitsch Jekimow. Letzterer erreichte ebenfalls stets Paris.

Mit 17 Teilnahmen hält Jens Voigt den deutschen Rekord, mit 14 Teilnahmen gefolgt von Erik Zabel, dem sechsmaligen und damit Rekordgewinner der Punktewertung.

Die Tour de France wurde im Jahr 1903 von der auf eine Auflagensteigerung bedachten Sportzeitung L’Auto gegründet. Diese musste sich damals insbesondere gegen das 1892 gegründete Konkurrenzblatt "Le Vélo" bewähren, von dem es sich 1900 abgespalten hat (zunächst unter dem Namen "L’Auto-Vélo"). Letztendlich setzte sich "L’Auto" (so der Name seit Januar 1903) durch, schon 1904 erschien "Le Vélo" zum letzten Mal.

Der Chefredakteur von "L’Auto", Henri Desgrange, übernahm bis zu seinem Tod 1940 den Posten des Tour-Direktors. In diesem Amt konzentrierte er alle wichtigen Entscheidungsprozesse zur Organisation des Rennens. Um das Rennen attraktiver zu machen, führte Desgrange 1919 das Gelbe Trikot und 1933 die Bergwertung ein. Zu seinem Nachfolger, sowohl als Chefredakteur als auch als Tourdirektor, baute Desgrange den Journalisten Jacques Goddet auf, der ihn als Renndirektor ab 1936 vertrat und als Tourdirektor von 1924 bis 1945 amtierte. Goddet war dem Einsatz technischer Neuerungen im Gegensatz zu seinem Vorgänger aufgeschlossen: Gleich in seinem ersten Jahr als Co-Direktor 1937 erlaubte er die Gangschaltung.

Nach der Befreiung Frankreichs 1944 wurde "L’Auto" verboten. Zwei Jahre später wurde die neue Sportzeitung L’Équipe als Nachfolgetitel durch die Amaury-Verlagsgruppe gegründet, die unter Goddet weiterhin die Tour organisierte. Später wurde dem bis dahin fast allmächtigen Direktor Goddet einen zweiten, vor allem für die wirtschaftliche Seite verantwortlichen Direktor bei. 1989 begleitete erstmals Jean-Marie Leblanc, der wie seine Vorgänger ebenfalls aus dem Journalismus kam, die Tour als Direktor. Die Organisation des Rennens ging auf die Amaury Sport Organisation (ASO) über, deren Chef seitdem offiziell die oberste Kontrolle über die Tour ausübt. Die konkreten Entscheidungen wurden allerdings weiterhin von Leblanc getroffen, unter dessen Direktion die Vermarktung der Tour de France einen neuen Grad der Professionalität erreicht hat. 2006 übernahm Christian Prudhomme die Direktion der Tour. Die markante Stimme für den Tour-Kommentar liefert Daniel Mangeas.


Die 1903 ins Leben gerufene Tour de France war das erste echte Etappenrennen in der Geschichte des Radsports. Enorme Distanzen waren schon zuvor bei Fernfahrten wie Paris–Brest–Paris (erstmals 1891, 1200 Kilometer) und Bordeaux–Paris (erstmals 1891, 577 Kilometer) zurückgelegt worden. Neu war aber die von dem französischen Journalisten Géo Lefèvre entwickelte Idee, mehrere Radrennen quer durch Frankreich direkt nacheinander zu veranstalten und die Zeiten zu addieren. Der programmatische Titel „Tour de France“ bediente dabei durchaus bewusst die patriotische Stimmung der Zeit.

Am 1. Juli 1903 begann die erste Tour de France an der ehemaligen „Auberge Reveil-Matin“ in Montgeron bei Paris. Es beteiligten sich 60 Fahrer. Die Rundfahrt führte über sechs Etappen mit insgesamt 2428 Kilometern von Paris über die Etappenstädte Lyon, Marseille, Toulouse, Bordeaux und Nantes zurück nach Paris. Zwischen den Etappen wurden mehrere Ruhetage eingelegt. Der favorisierte Franzose Maurice Garin war der Sieger der ersten Tour der Geschichte, mit einem Stundenmittel von über 25 km/h; das Preisgeld für den Sieg betrug 6075 Francs.

Die folgenden Ausgaben der Tour waren zunächst von einer Reihe von Skandalen geprägt, gipfelnd im Ausschluss der ersten Vier des Gesamtklassements bei der Tour de France 1904 unter anderem aufgrund von unerlaubter Benutzung der Eisenbahn. Bis circa 1910 konnte sich die Tour de France allerdings etablieren. Die Zeit vor dem Ersten Weltkrieg wird rückblickend als "heroische Epoche" der Tour bezeichnet, weil damals regelmäßig Tagesdistanzen von über 400 Kilometer zurückgelegt wurden. Aus heutiger Sicht erscheint dies genauso unglaublich wie die bescheidene damalige technische Ausstattung der Rennräder und die unzureichende Qualität der Straßen, die man heute nur noch bei kurzen Kopfsteinpflaster-Passagen der Radklassiker Paris–Roubaix und Flandern-Rundfahrt findet.

Später sorgte dann die Austragung von Etappen im Gebirge zusätzlich für den wachsenden Mythos des Rennens als "Tour der Leiden". So wurde die erste Bergwertung 1905 am Ballon d'Alsace in den Vogesen ausgetragen. Später folgten auch Etappen im Hochgebirge, so beispielsweise in den Pyrenäen (erstmals 1910) und in den Alpen (erstmals 1911), zumeist auf abenteuerlichen Viehwegen, die damals noch ohne Gangschaltung bezwungen werden mussten. Die Skulptur Le Géant du Tourmalet soll an die erste Überquerung des Col du Tourmalet im Jahre 1910 erinnern.

Die Zahl der Etappen wurden nach und nach auf elf (1905), fünfzehn (1910), achtzehn (1925) und schließlich bis zu vierundzwanzig Etappen (1931) erhöht. Die Gesamtlänge der Tour stieg auf bis zu 5500 Kilometer. Im Gegenzug wurde jedoch die Länge der einzelnen Etappen stetig verkürzt. Die Anzahl der Ruhetage, die ab 1906 regelmäßig nach jeder Etappe eingelegt worden waren, verringerte sich. Seit den 1950er-Jahren wird die Tour de France weitgehend in ihrer heutigen Gestalt ausgetragen.

Ab 2005 gehörte die Tour zu der damals neu eingeführten UCI ProTour, einer Serie der wichtigsten Radrennen des Jahres. Nach drei Saisons wurde die Tour, zusammen mit anderen großen Etappenrennen wie Giro d'Italia oder Vuelta, ab 2008 nach Unstimmigkeiten zwischen der ASO und dem Weltverband UCI aus der Rennserie genommen. Seit 2011 gehört das Rennen zur Nachfolgeserie UCI World Tour.

Jeweils fünf Siege erreichten Jacques Anquetil (Frankreich, 1957 und 1961–1964), Eddy Merckx (Belgien, 1969–1972 und 1974), Bernard Hinault (Frankreich, 1978/1979, 1981/1982 und 1985) und Miguel Induráin (Spanien, 1991–1995). Die meisten Platzierungen auf dem Podium erreichte Raymond Poulidor, der dreimal Zweiter und fünfmal Dritter wurde, die Tour aber weder gewinnen, noch ein einziges Mal das Gelbe Trikot erobern konnte.
Der jüngste Toursieger war der zwanzigjährige Henri Cornet 1904, der allerdings erst nachträglich zum Sieger erklärt wurde. Als ältester Fahrer gewann 1922 Firmin Lambot im Alter von 36 Jahren. Den knappsten Sieg feierte Greg Lemond bei der Tour de France 1989, als er mit nur acht Sekunden Vorsprung vor Laurent Fignon gewann. Den größten Abstand in der modernen Ära der Tour (seit 1947) legte Fausto Coppi 1952 mit über 28 Minuten zwischen sich und den Zweiten Stan Ockers.

Die größte Zeitspanne zwischen dem ersten und letzten Toursieg eines Fahrers liegt bei zehn Jahren (1938 und 1948) und wurde vom Italiener Gino Bartali aufgestellt. Kein weiterer Fahrer hat es bislang geschafft, zehn Jahre nach seinem ersten Toursieg nochmals zu gewinnen. Zwischen den beiden Siegen Bartalis fielen sieben der neun möglichen Austragungen wegen des Zweiten Weltkriegs aus.

Der erste Nicht-Franzose, der die Tour gewinnen konnte, war der Luxemburger François Faber (1909), und der erste Fahrer, der das gelbe Trikot von der ersten bis zur letzten Etappe trug, war ebenfalls ein Luxemburger, Nicolas Frantz (1928). 1924 eroberte Ottavio Bottecchia das Gelbe Trikot auf der ersten Etappe und gab es nicht mehr ab; 1935 gelang dies auch dem Belgier Romain Maes sowie 1961 dem Franzosen Jacques Anquetil.

Mit 36 Erfolgen konnte bisher Frankreich die weitaus meisten Toursiege erreichen, gefolgt von Belgien mit 18. Allerdings konnte seit 1985 (Sieger Hinault) kein Franzose mehr die Rundfahrt gewinnen. Mit deutlichem Abstand folgen in der Siegerliste Spanien (zwölf), Italien (neun), Luxemburg (fünf), die Vereinigten Staaten (drei), die Schweiz und die Niederlande (je zwei). Seit Mitte der 80er Jahre hat sich eine Reihe von neuen Nationen in die Siegerliste eingetragen: 1986 gab es den ersten US-amerikanischen, 1987 den ersten irischen und 1996 den ersten dänischen Sieg. 1997 schließlich errang der damals dreiundzwanzigjährige Jan Ullrich den ersten und bisher einzigen deutschen Toursieg. Allerdings gab Bjarne Riis zu, bei seinem Sieg 1996 gedopt zu haben, der Sieg Ullrichs steht bis heute im Schatten des Dopingverdachts.

2011 gewann zum ersten Mal ein Australier, 2012 gab es den ersten Sieger aus Großbritannien.

Der US-Amerikaner Lance Armstrong gewann von 1999 bis 2005 die Tour als erster Fahrer siebenmal. Diese Titel wurden jedoch aufgrund einer von der US-Antidopingagentur ausgesprochenen Disqualifikation wegen Dopings durch die UCI am 22. Oktober 2012 aberkannt. Die UCI entschied am 26. Oktober 2012, diese Titel nicht neu zu vergeben.

Die Rangliste der mehrfachen Etappensiege wird vom fünfmaligen Gesamtsieger Eddy Merckx angeführt. Er gewann bei sieben Teilnahmen insgesamt 34 Etappen. Es folgen Mark Cavendish mit 30 und Bernard Hinault mit 28 Etappensiegen und der zweimalige Toursieger André Leducq mit 25 Siegen. 22 Siege gelangen dem Franzosen André Darrigade und Lance Armstrong. Letzterem wurden aber am 22. Oktober 2012 von der UCI 20 Etappensiege aberkannt, wodurch er nur noch mit zwei Etappensiegen gewertet wird.

Die Durchschnittsgeschwindigkeit des Rennens nahm im Laufe der Jahre kontinuierlich zu. Nachdem die erste Tour mit 25,67 km/h absolviert worden war, überschritt sie 1934 erstmals die Grenze von 30 km/h, 1956 die von 35 km/h. Sie stieg mit Lance Armstrong 1999 erstmals über 40 km/h. 2005 wurde die bisher schnellste Durchschnittsgeschwindigkeit mit 41,65 km/h (ebenfalls von Lance Armstrong) erreicht. Die Leistungen von Armstrong müssen allerdings kritisch bewertet werden: Die UCI annullierte alle seine Toursiege wegen nachgewiesenen Dopings.

Die schnellste einzelne Etappe einer Tour gewann 1999 Mario Cipollini nach einer Distanz von 194,5 Kilometern mit einer Durchschnittsgeschwindigkeit von 50,35 km/h.

Jedoch ist zu bedenken, dass in den ersten Jahrzehnten die zu bewältigende Gesamtstrecke häufig über 5000 Kilometer lag, wobei die einzelnen Etappen meist doppelt so lang waren wie heute und zudem noch auf teilweise schlecht ausgebauten Straßen ohne Gangschaltung zurückgelegt werden mussten.

Der steile Anstieg der gefahrenen Geschwindigkeit ab 1927 dürfte hauptsächlich mit der Verkürzung der Etappen- und Gesamtlänge zusammenhängen, da die Erlaubnis des Einsatzes einer Gangschaltung erst zehn Jahre später erteilt wurde. Des Weiteren spielt aber auch die sukzessive Verbesserung der Straßenverhältnisse eine Rolle.

Auffällig ist auch der starke Leistungsanstieg seit Ende der 1980er-Jahre, der je nach Sichtweise auf verbesserte Trainingsmethodik und/oder den Einsatz von Doping-Mitteln zurückgeführt werden kann.

Die langsamste Tour wurde nach dem Ersten Weltkrieg 1919 mit 24,1 km/h gefahren, die mit 5560 Kilometern auch die zweitlängste der Tourgeschichte war.

Seit Gründung der Tour wurden für die Radprofis Preisgelder ausgelobt, im ersten Jahr 1903 insgesamt 20.000 Francs. Seitdem wurde das Preisgeld immer weiter aufgestockt. Bei der Tour de France 2004 schütteten die Organisatoren insgesamt rund drei Millionen Euro aus, davon allein rund 400.000 Euro für den Gesamtsieger. Obwohl dies absolut gesehen große Summen sind, liegt die Dotierung der Tour jedoch weit unter der etwa von Tennis- oder Golfturnieren. Die Bedeutung der Preisgelder für die Tour nahm im Laufe der Jahre tatsächlich eher ab, da die besten Fahrer den Großteil ihres Gehalts nicht über Preisgeld, sondern durch die langfristigen Verträge mit ihren Radsportteams erzielen. Zudem bemisst sich der Marktwert eines Radprofis sehr stark nach seiner Bilanz bei der Tour de France, so dass sich ein Erfolg bei der Tour indirekt finanziell enorm auswirkt. Dies ist einer der Gründe, warum es üblich ist, dass die Tour-Sieger ihre Preisgelder in die Mannschaftskasse abgeben, um damit eine Anerkennung der Mannschaftsleistung zum Ausdruck zu bringen: Sie selbst können mit weit höheren Einnahmen durch die nach dem Toursieg höher dotierten Anstellungs- und Werbeverträge rechnen.

Bereits 1924 veröffentlichte der Journalist Albert Londres in seinem bekannten Artikel "Les Forçats de la Route" ("Die Zwangsarbeiter der Straße)", was ihm Henri Pélissier und andere Fahrer über das Doping bei der Tour berichtet hatten. Sie leerten damals ihre Trikottaschen und präsentierten Londres Chloroform, Kokain und eine Pille namens "Dynamit".

Der erste Dopingtest fand am 28. Juni 1966 in Bordeaux statt. Zwei Ärzte kontrollierten mehrere Fahrer auf Einstiche von Injektionsnadeln und nahmen Urinproben. Am nächsten Tag kam es zu einer Protestaktion der Teilnehmer, indem die Fahrer auf den ersten Metern der Etappe ihre Räder schoben. 1967 war das erste Doping-Todesopfer der Tour zu beklagen: Tom Simpson starb während der Etappe auf den Mont Ventoux nach Einnahme von Amphetamin und Alkohol.

Während der Tour de France 1998 erlebte der Radsport eine schwere Glaubwürdigkeitskrise. Bei der sogenannten Festina-Affäre wurde im Spitzenteam Festina (mit den Stars Richard Virenque und Alex Zülle) eine systematische, flächendeckende Dopingpraxis aufgedeckt, nachdem bei Willy Voet, einem Betreuer der Mannschaft, durch Zufall große Mengen unerlaubter Substanzen – vor allem EPO – gefunden worden waren. Diese Entdeckung verdeutlichte auch die Unwirksamkeit der damaligen Dopingkontrollen: Keiner der Festina-Fahrer war positiv getestet worden. Es kam schließlich zum Ausschluss der Mannschaften Festina und TVM; die spanischen Mannschaften zogen sich aus Protest gegen die Ermittlungsmethoden der französischen Behörden von der Tour zurück. Die Tour de France 1998 wurde schließlich von Marco Pantani gewonnen, der dann ein Jahr später selbst wegen eines auf Doping hinweisenden, überhöhten Hämatokritwerts vom Giro d’Italia ausgeschlossen wurde.

Die Festina-Affäre stellte allerdings nur den vorläufigen Höhepunkt der die Tour de France seit Jahrzehnten begleitenden Dopingproblematik dar. Schon der erste fünffache Toursieger, Jacques Anquetil, hatte als aktiver Fahrer jede Dopingprobe verweigert und darauf verwiesen, dass man sich bloß nicht vorstellen solle, Leistungen wie die bei der Tour erbrachten seien nur mit Mineralwasser zu erreichen. In den 1970er- und 1980er-Jahren wurden trotz äußerst mangelhafter Kontrollen wiederholt Fahrer positiv getestet. Darunter auch die Gesamtsieger Felice Gimondi, Joop Zoetemelk, Pedro Delgado und Laurent Fignon.

Seit 1999 ist ein Doping-Befund von Lance Armstrong während der Tour de France 1999 offiziell dokumentiert, der zusammen mit 16 anderen Fahrern einen ungewöhnlichen Kortikoid-Wert in einem zehn Tage vor der Tour neu eingeführten Test aufwies. Dieser Befund wurde mit einem nach dem Test eingereichten Rezept erklärt und blieb folgenlos, obwohl die Satzung bei dieser Art Vergehen eine Strafe für den betroffenen Fahrer vorsieht.

Einen Tag vor der Tour de France 2006 erschütterte ein neuer Dopingskandal die Radsportszene, als die spanischen Behörden eine Liste mit 58 Dopingverdächtigten publizierten. Dies führte zum Ausschluss der Tourfavoriten Jan Ullrich, Ivan Basso, Francisco Mancebo, Joseba Beloki, Oscar Sevilla und weiterer Fahrer noch vor Beginn der Rundfahrt. Die Fahrer wurden nicht ersetzt, so dass die betroffenen Teams reduziert beziehungsweise gar nicht in die Tour de France starteten. Diese Episode ist später unter dem Begriff "Dopingskandal Fuentes" bekannt geworden.

Nach der Tour de France 2006 wurde bekannt, dass Gesamtsieger Floyd Landis auf der entscheidenden Etappe mit Testosteron gedopt war. A- und B-Probe ergaben ein positives Ergebnis. Floyd Landis wurde daraufhin mit sofortiger Wirkung aus seinem Team Phonak Hearing Systems entlassen. Im September 2007 wurde Landis der Titel aberkannt. Damit ist Óscar Pereiro neuer Gesamtsieger. Es war das erste Mal in der Geschichte der Tour de France, dass einem Fahrer wegen eines Dopingfalles nachträglich der Gesamtsieg zuerkannt wurde.

Im Vorfeld und auch während der Tour de France 2007 war Doping wieder das beherrschende Thema. Trotz Bemühungen der Teams und Organisation kam es zu zahlreichen Vorfällen: Nachdem der T-Mobile-Fahrer Patrick Sinkewitz des Dopings überführt wurde, brachen ARD und ZDF ihre Liveübertragungen der Tour ab. In der letzten Tourwoche zogen die Teams Cofidis und Astana alle ihre Fahrer vom Rennen zurück, nachdem in ihren Teams je ein Fahrer in der sogenannten A-Probe positiv getestet wurde. Wenige Tage vor Rennende wurde der dominierende Gesamtführende Michael Rasmussen von seinem Team Rabobank aus der Tour genommen, nachdem ihn der dänische Radsportverband wegen mehrfacher Missachtung der Meldepflicht seiner Aufenthaltsorte an Dopingkontrolleure suspendierte.

Der Sieger von 1996, der Däne Bjarne Riis, wurde im Juni 2007 nach seinem Dopinggeständnis von den Organisatoren offiziell aus der Siegerliste der Frankreich-Rundfahrt gestrichen. Der frühere Kapitän des Team Telekom und ehemalige Chef der Team-Saxo-Bank-Mannschaft hatte EPO-Doping zwischen 1993 und 1998 zugegeben. Der Sieg kann ihm jedoch wegen der bereits verstrichenen Verjährungsfrist von acht Jahren von der UCI nicht mehr aberkannt werden.

Nachdem während der Tour 2008 bereits mehrere Fahrer des Dopings mit dem EPO-Präparat CERA überführt worden waren, wurden im Oktober 2008 weitere, seit der Tour eingefrorene, Blutproben nachgetestet. Dabei wurden weitere positive Dopingfälle entdeckt, darunter die Gerolsteiner-Fahrer Stefan Schumacher und Bernhard Kohl. Als Reaktion darauf beschlossen die Sendeanstalten ARD und ZDF, aus der Übertragung der Tour de France 2008 dauerhaft auszusteigen.

Auch die Tour 2009 hatte bereits drei Tage vor ihrem offiziellen Start den ersten Dopingfall. Damals wurde der Niederländer Thomas Dekker des Betrugs überführt.

Dem Sieger der Austragung 2010, dem Spanier Alberto Contador wurde im Februar 2012 vom Internationalen Sportgerichtshof CAS wegen einer positiven Dopingprobe bei der Tour 2010 der Titel aberkannt. Er wurde zudem mit einer zweijährigen Sperre belegt. Zum neuen Tour-Sieger 2010 wurde der Luxemburger Andy Schleck ernannt.

Während der Tour 2012 wurde Andy Schlecks Bruder Fränk am 14. Juli positiv auf das Diuretikum Xipamid getestet. Diuretika wurden häufig dazu verwendet, die Einnahme von Dopingmitteln zu verschleiern. Fränk Schleck wurde anschließend von seinem Team RadioShack-Nissan aus dem Rennen genommen, obwohl er von der UCI nicht gesperrt wurde. Am 20. Juli wurde das Ergebnis nach der Analyse der B-Probe bestätigt.

Im Oktober 2012 wurden Lance Armstrong alle seit dem 1. August 1998 gewonnenen Titel, Siege und Platzierungen wegen seines jahrelangen und systematischen Dopings aberkannt.

Bereits 1999 sagte der Präsident des Internationalen Radsportverbandes (UCI) Hein Verbruggen, "Wenn die Leute damit zufrieden wären, dass die Tour de France mit 25 km/h gefahren wird, gäbe es kein Doping-Problem. Wenn man aber 42 km/h will, gibt es nur einen einzigen Weg, das zu erreichen: Mit Doping." Dies ist das grundsätzliche Problem, das sich mit entsprechenden Kontrollen minimieren, aber nicht beseitigen lässt.

Das Farbspektrum der Trikots ist von der Tourleitung streng festgelegt. Eine Reihe von farblich abgehobenen Trikots kennzeichnen die besten Fahrer verschiedener Wertungen. Die Trikots werden den Fahrern nach jeder Etappe in einer feierlichen Zeremonie angezogen. Auch der Etappensieger wird hier geehrt, erhält aber kein spezielles Trikot. Jedes der Trikots wird dabei von einem eigenen Sponsor präsentiert. Im Gegensatz zu Schleichwerbung wird hier also die Interessenlage wie bei vielen Sportveranstaltungen klar gekennzeichnet. Die Fahrer sind verpflichtet, die entsprechenden Wertungstrikots zu tragen. Wenn ein Fahrer im Besitz mehrerer Trikots ist, trägt er das wichtigere. Dabei gilt folgende Reihenfolge: Gelbes, Grünes, Gepunktetes, Weißes Trikot. In diesem Fall wird das nächstniedrigere Trikot von dem Zweitplatzierten in der jeweiligen Wertung präsentiert. Als Träger gilt dennoch der Führende, auch wenn er es – außer bei der Siegerehrung – gar nicht tatsächlich trägt. Als bislang einzigem Fahrer gelang es Eddy Merckx 1969, im selben Jahr die drei wichtigsten Wertungen zu gewinnen.

Der Fahrer mit der geringsten Gesamtzeit trägt das berühmte "Gelbe Trikot," französisch "le maillot jaune", des Führenden der Gesamtwertung. Dafür werden die von den Fahrern benötigten Zeiten aller Etappen zusammengerechnet. Eventuelle Zeitgutschriften wurden früher von der Gesamtzeit subtrahiert: So erhielt jeder Etappensieger bis zur Tour 2008 eine Zeitgutschrift von 20 Sekunden, die Etappenzweiten und -dritten zwölf beziehungsweise acht Sekunden. Bei Zwischensprints wurden sechs, vier beziehungsweise zwei Sekunden Gutschrift für die ersten drei Fahrer vergeben. Diese Zeitgutschriften sind entfallen. Wer nach der letzten Etappe die kürzeste Gesamtzeit auf seinem Konto hat, gewinnt die Tour. Haben mehrere Fahrer einen Zeitunterschied von weniger als einer Sekunde, werden die mit Hundertstelsekunden gestoppten Zeitfahrergebnisse zu Rate gezogen. Die besten Fahrer trennen heutzutage meist nur wenige Minuten, während der Letzte des Klassements rund drei bis vier Stunden Rückstand aufweist.

Das Gelbe Trikot wurde 1919 eingeführt, um die Identifizierung des Spitzenreiters für die Zuschauer zu vereinfachen. Der erste Träger des Trikots war der Franzose Eugène Christophe. Am längsten trug der fünffache Toursieger Eddy Merckx das gelbe Trikot – insgesamt 96 Etappen lang. Inklusive Ruhetage waren es sogar 111 Tage. Der einzige Fahrer, der von der ersten bis zur letzten Etappe im gelben Trikot fuhr, war der Luxemburger Nicolas Frantz im Jahr 1928. Als Vorjahressieger trug er das gelbe Trikot bereits auf der ersten Etappe und legte es bis zur Schlussetappe nicht wieder ab.

Bei der Siegerehrung am Etappenende wird dem Gewinner zunächst ein Gelbes Trikot mit Reißverschluss am Rücken überreicht. Es wird ihm vor dem Publikum angezogen. Am Abend werden dem Fahrer weitere Trikots überreicht, die er auf der nächsten Etappe trägt. Am Ende der Tour werden ihm weitere 10–30 Gelbe Trikots ausgegeben.

Der Gewinn des gelben Trikots ist nicht nur prestigeträchtig, sondern auch finanziell lukrativ. Das Preisgeld beträgt für den Sieger der Gesamtwertung am Ende der Rundfahrt 450.000 Euro, der Zweitplatzierte erhält 200.000 Euro und der Dritte 100.000 Euro.

Seit 1953 wird der Sieger der Punktewertung mit dem "Grünen Trikot," französisch "le maillot vert" geehrt. Die Wertung addiert Punkte, die bei Etappenankünften, aber auch Zwischensprints vergeben werden. Flachetappen werden hierbei deutlich höher bewertet als Bergetappen und Zeitfahren, um Sprinter zu bevorzugen, die gewöhnlich in der Gesamtwertung eher hintere Plätze belegen. Hier unterscheidet sich die Tour de France u. a. von der Giro d’Italia, die immer die gleiche Punktzahl für einen Etappensieg vergibt, egal in welchem Gelände. Auch wenn diese Wertung regelmäßig von Sprintern gewonnen wird, gelang es früher auch einigen Gesamtklassementfahrer wie Eddy Merckx und Bernard Hinault diese Wertung zu gewinnen. Der Berliner Erik Zabel hat das Grüne Trikot von 1996 bis 2001 sechsmal in Folge nach Paris tragen können und ist damit alleiniger Rekordhalter. Allerdings erlangte er zumindest 1996 den Titel unter der Verwendung von Doping. Zweitplatzierter ist der Slowake Peter Sagan, er konnte von 2012 bis 2016 fünf Siege in Folge in dieser Wertung verbuchen.

Ein Bergpreis wird bereits seit 1933 ausgelobt, aber erst seit 1975 wird auch hier das "Gepunktete Trikot" – weiß mit roten Punkten, französisch "le maillot à pois rouges" – verliehen. Das Trikot wurde 1975 von der Schokoladenfabrik "Menier" gesponsert, deren Schokolade in weißem Papier mit roten Punkten verpackt war. Punkte für das Gepunktete Trikot werden nach Anstiegen der Kategorien 4 (leicht) bis 1 (schwer) sowie der "hors catégorie" – kurz: "HC" – (außerordentlich schwer) vergeben. Als einzigem Fahrer gelang es Richard Virenque zwischen 1994 und 2004 die Bergwertung siebenmal zu gewinnen, gefolgt von Federico Bahamontes (zwischen 1954 und 1964) und Lucien Van Impe (zwischen 1971 und 1983) mit je sechs Siegen.

Seit 1975 wird bei der Tour das "Weiße Trikot" für den besten Jungprofi vergeben. Diese Wertung ermittelt die besten Fahrer, die im Jahr der jeweiligen Tour höchstens 25 Jahre alt sind. Zwischen 1989 und 1999 wurde für dieses Klassement bei der Tour de France kein weißes Trikot vergeben. Das weiße Trikot wurde jedoch im Jahr 2000 wieder eingeführt.

Bisher konnten Laurent Fignon (1983), Greg LeMond (1984), Jan Ullrich (1996, 1997 und 1998), Marco Pantani (1994 und 1995) sowie Andy Schleck (2008, 2009, 2010) zuerst die Nachwuchswertung und später auch das Gelbe Trikot gewinnen. Jan Ullrich war bei seinem Toursieg 1997 sogar erst 23 Jahre alt, so dass er gleichzeitig das Gelbe Trikot und die Nachwuchswertung gewann. Auch Alberto Contador bei seinem Toursieg 2007 und Andy Schleck bei seinem Toursieg 2010 (beide im Alter von 25) konnten sowohl das Weiße als auch das Gelbe Trikot zeitgleich gewinnen.

Die "rote Rückennummer" wird nach jeder Etappe an den kämpferischsten Fahrer des gesamten Fahrerfeldes vergeben. Diese Auszeichnung ist die einzige bei der Tour, die durch eine Fachjury ermittelt wird. Die Jury, bestehend aus acht Mitgliedern (darunter Sportler, Rennleiter und Journalisten), entscheidet nach jeder Etappe, welcher der Fahrer den besten Kampfgeist gezeigt hat. Der Preis wird dann jeden Morgen auf dem offiziellen Podium dem Fahrer überreicht, wobei 2.000 Euro pro getragenem Tag in die Mannschaftskasse fließen. Am Ende der Tour wird in Paris der kämpferischste Fahrer der gesamten Tour gewählt, das Preisgeld für diese Sonderwertung beträgt 20.000 Euro.

Seit 1930 wird auch die beste Mannschaft ermittelt. Für die "Mannschaftswertung" werden bei jeder Etappe die Zeiten der besten drei Fahrer einer Mannschaft addiert. Das beste Team der Gesamttour erhält ein Preisgeld von 50.000 Euro. Besteht eine Mannschaft aus weniger als drei Fahrern, so wird sie aus dieser Wertung gestrichen.

Als weitere Auszeichnung tragen die Fahrer des besten Teams in der Teamwertung „gelbe Rückennummern“, das heißt schwarze Ziffern auf gelbem Grund. Früher wurden sie zur Erkennung mit gelben Mützen ausgestattet. Dies ist jedoch seit Einführung der Helmpflicht nicht mehr möglich. Daher wird seit dem Jahr 2012 dem führenden Team gestattet gelbe Helme zu tragen.

Die Tour de France wird nach dem Reglement des Weltradsportverbands UCI, insbesondere dem Reglement für Etappenrennen, ausgetragen. Im Einklang mit diesen Vorschriften gilt für die Tour de France ergänzend ein Sonderreglement.

Im Ziel werden die Abstände zwischen den einzelnen Fahrern beziehungsweise Fahrergruppen registriert. Alle Fahrer einer geschlossenen Gruppe werden mit der gleichen Zeit bewertet. Seit 2005 werden bei einem Sturz auf den letzten drei Kilometern die darin verwickelten Fahrer mit der gleichen Zeit gewertet wie die Gruppe, der sie zum Zeitpunkt des Sturzes angehörten. Diese Regelung gilt jedoch nicht bei Einzelzeitfahren und bei Etappen mit Bergankünften. Bei allen Etappen außer dem Prolog wird ein Zeitlimit ("Karenzzeit") festgelegt, innerhalb dessen jeder Fahrer ins Ziel kommen muss. Das Zeitlimit wird nach Schwierigkeitsgrad und Durchschnittsgeschwindigkeit der jeweiligen Etappen berechnet. Das Limit schwankt dementsprechend zwischen 103 und 120 Prozent (bei Einzelzeitfahren 125 Prozent, bei Mannschaftszeitfahren 130 Prozent) der Zeit des Etappensiegers. Allerdings hat die Rennleitung die Möglichkeit, das Zeitlimit flexibel zu verlängern, wenn sonst mehr als zwanzig Prozent der Fahrer nach Kontrollschluss einträfen oder einzelne Fahrer beeinflusst durch einen Unfall oder vergleichbares Unglück das Zeitlimit verpassen.

2001 kam es auf einer regnerischen Etappe im französischen Jura zu der Situation, dass eine Ausreißergruppe um den Australier Stuart O’Grady einen Vorsprung von 35 Minuten auf das Hauptfeld um den späteren Gewinner der Tour, Lance Armstrong, hatte. Ohne die Sonderregelung hätte Andrei Kiwiljow die Tour gewonnen. So reichte es nur für den vierten Platz. Dieses Szenario wiederholte sich während einer Überführungsetappe im Jahr 2006. Das Hauptfeld um Spitzenreiter Floyd Landis ließ eine Spitzengruppe um den Spanier Óscar Pereiro so weit ziehen, dass sowohl das Zeitlimit verpasst wurde, als auch das Maillot Jaune seinen Träger wechselte. Zwar konnte Landis in den Alpen das Maillot Jaune zurückerobern, doch musste er es nach einer positiven Dopingprobe wieder abgeben. Anders als Kiwiljow fünf Jahre zuvor, gewann Pereiro trotz dieser Ausnahmeregelung die Tour.

Auf der 18. Etappe der Tour de France 2011 von Pinerolo nach Galibier Serre-Chevalier hatte eine Gruppe von 88 Fahrern das Zeitlimit überschritten. Der Tourveranstalter verbannte diese Fahrer nicht von der Tour, da sonst das Fahrerfeld um mehr als die Hälfte geschrumpft wäre. Stattdessen wurden jedem dieser Fahrer 20 Punkte in der Sprintwertung abgezogen. Dies betraf unter anderem den Führenden der Sprintwertung Mark Cavendish.

Bei Etappenankünften, außer bei Zeitfahren, gab es bis 2007 für die ersten drei Fahrer abgestufte Zeitgutschriften zusätzlich zur real gefahrenen Zeit in Höhe von 20, 12 oder acht Sekunden. Bei bis zu drei Zwischensprints gab es sechs, vier oder zwei Sekunden Gutschrift. In den Austragungen von 2008 bis 2014 wurden keinerlei Zeitgutschriften vergeben.

Zur Tour de France 2015 wurden Zeitgutschriften wieder eingeführt. Auf jeder Etappe mit Ausnahme der Zeitfahren erhalten die ersten drei Fahrer im Ziel einen Bonus von zehn, sechs oder vier Sekunden.

Die Verpflegung der Fahrer ist außerordentlich wichtig, da sie bei einer schweren Bergetappe 6.000 bis 10.000 Kilokalorien verbrauchen. Auf jeder Etappe gibt es daher ein bis zwei als solche gekennzeichnete Verpflegungszonen, wo die Mitarbeiter der Teams den Fahrern von der Tourorganisation genehmigte Verpflegungsbeutel reichen dürfen. Nahrung und Getränke, die Zuschauer den Profis anbieten, dürfen diese auf eigene Gefahr entgegennehmen. Bis zwanzig Kilometer vor Ende der Etappe dürfen zudem die sportlichen Leiter ihren Fahrern Getränke und Esswaren aus dem Teamfahrzeug reichen. Jeder Mannschaft der Tour stehen dabei vier Fahrzeuge zur Verfügung, von denen nur zwei im Rennen genutzt werden dürfen. Die Fahrzeuge müssen immer rechts fahren, hinter den Autos der Tourleitung und des ärztlichen Dienstes. Die Mannschaftswagen dürfen nur nach der Aufforderung durch das interne „Radio Tour“ nach vorne fahren.

Übereinstimmend mit dem UCI-Reglement wurde am 6. Januar 2004 die Helmpflicht bei der Tour de France eingeführt.

Eine Pannenhilfe wird entweder vom Team oder den neutralen Materialwagen geleistet. Pannenhilfe ist immer nur hinter einer Ausreißergruppe und hinter dem Hauptfeld am rechten Straßenrand erlaubt. Offiziell dürfen bei einer Reifenpanne die Räder nur innerhalb der Mannschaft ausgetauscht werden. Benötigt ein Fahrer einen Arzt, darf es nur ein Arzt des offiziellen ärztlichen Dienstes sein. Der Fahrer wird dann am Ende des Pelotons behandelt, oft während der Fahrt vom Arztauto aus. Bei Stürzen oder Pannen auf den letzten drei Kilometern werden die Fahrer mit derselben Zeit wie die Gruppe, der sie angehörten, gewertet.

Die Regeln werden von den Rennkommissaren überwacht, die auf Motorrädern das Rennen begleiten. Sehen sie Rennverstöße, können sie diese nach den Regeln des Weltradsportverbands UCI ahnden. Verstöße gegen das Reglement werden mit Geldstrafen (in Schweizer Franken), Zeitstrafen, der Zurücksetzung an das Ende der Gruppe bzw. des Feldes oder der Disqualifikation geahndet. Verboten ist u. a. das Verlassen der Fahrlinie im Sprint, das Festhalten an anderen Fahrern, das Anschieben zwischen Fahrern und durch Zuschauer, sich von Autos oder Motorrädern ziehen zu lassen oder den Windschatten dieser Fahrzeuge zu benutzen.

Eine Ausnahme stellt dar, wenn der Fahrer während der Fahrt vom offiziellen Tourarzt medizinisch behandelt wird oder sein Rad von einem Mechaniker reparieren lässt. Wenn ein Fahrer eine Panne hatte, benutzt er oft die Autos der Sportlichen Leiter, um in deren Windschatten wieder Anschluss an das Peloton zu bekommen. Solche Verstöße werden fast nie geahndet.

Fahrer, die das Rennen aufgeben, müssen ihre am Rahmen sowie am Trikot befestigte Startnummer am Besenwagen abgeben.

Die Tour de France gilt als eine der publikumsträchtigsten Sportveranstaltungen der Welt. Jedes Jahr verfolgen Millionen Radsportfans und interessierte Anwohner das Geschehen.

Für die Bewohner der zu durchfahrenden Orte ist die Tour ein großes Ereignis. Dies wird dann verstärkt, wenn ein Tourteilnehmer aus dem zu durchfahrenden Ort stammt. Oft setzt er sich dann kurz vom Feld ab oder hält an und begrüßt Freunde und Familie. Solche „Begrüßungsaktionen“ werden vom Peloton durch Passivität geduldet. Zum Ende einer jeden Etappe wird auf solche Boni jedoch keine Rücksicht mehr genommen.

Oftmals sieht man in den Übertragungen an exponierter Stelle Grüße oder Wünsche oder auch tourbezogene Kunstwerke der Fans. Darunter etwa Strohballen, die von Landwirten zu Situationen der Tour arrangiert wurden, oder kunstvolle Riesenfahrräder. Weit verbreitet ist es außerdem, die Fahrbahn im Vorfeld mit Namen von Fahrern, Flaggen und Anfeuerungsparolen zu bemalen.

Insbesondere bei den Bergetappen ziehen zahlreiche Wohnmobile beziehungsweise Caravans mit dem Tourtross mit, um jeden Tag von neuem die Radfahrer anzufeuern. Gute Standplätze sind dabei oft schon Tage vorher belegt. Bekanntester deutscher Fan ist Didi Senft, der als Teufel verkleidet seit Jahren bei Tour-Übertragungen im Fernsehen zu sehen ist. Von der Berichterstattung nicht erfasst sind die unzähligen aktiven Fans, die jedes Jahr auf eigene Faust oder durch Veranstalter organisiert Originaletappen nach- oder vorfahren. Organisiert werden hierzu zum Beispiel auch Jedermannrennen, die über eine Originaletappe führen.

Die französische Post überreicht nach Etappenende eingegangene Fanschreiben direkt an die Fahrer. Um einen Brief korrekt an einen bestimmten Tourteilnehmer zu adressieren, genügt die Anschrift „Coureur X, Tour de France“.

Neben der Vermarktung der Rundfunkübertragungsrechte ist die ASO bei der Tour de France auf die Unterstützung durch Sponsoren angewiesen. Dominierend sind dabei die vier Hauptsponsoren, die jeweils eine Art langjährige Patenschaft für eines der vier Trikots übernehmen. Dies sind aktuell die Großbank Crédit Lyonnais beim gelben Trikot, der halbstaatliche Anbieter von Pferdewetten PMU beim grünen Trikot, die Supermarktkette Champion beim Gepunkteten Trikot und der tschechische Automobilhersteller Škoda Auto (seit 2004 Sponsor, davor Fiat) beim weißen Trikot. Typisch für diese Art des Sponsorings: Das jeweilige Corporate Design dieser vier Unternehmen stimmt weitgehend mit den Farben der Trikots überein. Weitere bedeutende Werbepartner der Tour de France sind der Uhrenhersteller Festina (welcher unter anderem die Zeitmessung übernimmt) und der Lebensmittelkonzern Nestlé mit seiner Mineralwassermarke Vittel (etwa bei der Patenschaft für die flamme rouge). Bei Zwischenwertungen und im Zielbereich einer jeden Etappe bietet die ASO auch Bandenwerbung auf den Absperrgittern an.

Eine weitere wichtige Einnahmequelle für die ASO ist die sogenannte Werbekarawane, französisch "caravane publicitaire". Sie wurde in den 1930er-Jahren eingeführt und besteht aus einer Kolonne von derzeit 180 aufwändig gestalteten Reklamefahrzeugen, die ein bis zwei Stunden vor dem Fahrerfeld die Rennstrecke abfahren. Hierbei werden von Hostessen, ähnlich wie bei einem Karnevalsumzug, kleine Werbegeschenke an die Zuschauer verteilt. Darunter befinden sich häufig Lebensmittel-Probierpackungen oder Wasserflaschen. Die Karawane hat sich im Lauf der Jahre als eigenständige Attraktion etabliert, viele Zuschauer kommen eigens ihretwegen bereits früher an die Strecke. Um drei Fahrzeuge platzieren zu können, muss ein Unternehmen gegenwärtig 150.000 Euro an die Organisatoren der Tour de France zahlen. Neben den oben genannten Hauptsponsoren kommen dabei auch weitere Unternehmen zum Zug.


Neben einzelnen Opfern bei den Fahrern ist es in der Geschichte der Tour auch beim Begleitpersonal und bei den Zuschauern immer wieder zu tödlichen Unfällen gekommen. Dieses Todesrisiko ist jedoch für Zuschauer deutlich niedriger als etwa bei Motorsportveranstaltungen. Ursächlich hierfür ist der kleinere Energiegehalt und die geringere Beschleunigung eines kollidierenden Radfahrers im Vergleich zur Masse und der Geschwindigkeit eines Kraftfahrzeugs. Dennoch sind die Sicherheitsbestimmungen auch bei der Tour in der Folge mehrerer Zwischenfälle stetig verschärft worden.








</doc>
<doc id="5038" url="https://de.wikipedia.org/wiki?curid=5038" title="Thermografie">
Thermografie

Die Thermografie, auch Thermographie, ist ein bildgebendes Verfahren zur Anzeige der Oberflächentemperatur von Objekten. Dabei wird die Intensität der Infrarotstrahlung, die von einem Punkt ausgeht, als Maß für dessen Temperatur gedeutet.

Eine Wärmebildkamera wandelt die für das menschliche Auge unsichtbare Infrarotstrahlung in elektrische Signale um. Daraus erzeugt die Kamera ein Bild in Falschfarben bzw. für thermographische Zwecke eher seltener ein monochromes Graustufenbild.

Im Gegensatz zur Nahinfrarotspektroskopie ist für die Thermografie keine externe Lichtquelle erforderlich.

Der Astronom und Musiker Wilhelm Herschel entdeckte im Jahr 1800 die Wärmestrahlung, indem er Sonnenlicht durch ein Prisma lenkte und den Bereich hinter dem roten Ende des sichtbaren Spektrums mit einem Thermometer untersuchte. Die Temperatur stieg in diesem Bereich, und Herschel schloss daraus, dass dort eine unsichtbare Form von Energie wirksam sein müsse. Seine Bezeichnung „Wärmestrahlung“ ist auch heute noch üblich und wurde etwa 100 Jahre später durch „Infrarot“ — im deutschen Sprachraum war einige Zeit auch der Begriff „"Ultrarot"“ geläufig — ersetzt.

Andere Forscher zweifelten seine Entdeckung zuerst an, weil noch nicht bekannt war, dass die Transparenz für IR stark von der Glassorte des Prismas abhängt. Auf der Suche nach einem besseren Material entdeckte 1830 der italienische Physiker Macedonio Melloni, dass Prismen aus kristallinem Steinsalz IR-Strahlung kaum dämpfen und dass sich Wärmestrahlung mit Linsen aus diesem Material bündeln lässt. Bereits ein Jahr vorher konnte Melloni die Messgenauigkeit erheblich steigern, indem er die relativ ungenauen Quecksilberthermometer durch die von ihm erfundene Thermosäule ersetzte. Beides – Linsen aus Steinsalz und Anordnungen von Thermosäulen – waren die wesentlichen Bauelemente der ersten Wärmekameras.

Die Temperaturverteilung auf Oberflächen (so genannte „Wärmebilder“) wurden 1840 von Herschel durch unterschiedliche Verdampfungsraten eines dünnen Ölfilms sichtbar gemacht. Später ermittelte man die Temperatur durch unmittelbaren Kontakt mit ausgedrücktem Thermopapier, das sich bei Berührung mit ausreichend warmen Oberflächen verfärbt. Alle diese Verfahren haben sehr an Bedeutung verloren, weil sie nur in einem eng begrenzten Temperaturbereich funktionieren, weder zeitliche Änderungen noch geringe Temperaturunterschiede anzeigen und bei gekrümmten Oberflächen schwierig zu handhaben sind. Im Vergleich zur heute allgemein verwendeten kontaktlosen Technik waren sie aber erheblich billiger.

Der Durchbruch in der Entwicklung der kontaktlosen Temperaturmessung gelang Samuel Pierpont Langley im Jahr 1880 mit der Erfindung des Bolometers. Einsatzbereiche waren unter anderem Aufspüren von Eisbergen und verborgener Personen. Die weitere Entwicklung vor allem auf dem Gebiet der Bildgebung erfolgte meist im Geheimen und Forschungsberichte durften wegen militärischer Geheimhaltungsvorschriften erst nach 1950 veröffentlicht werden. Seit etwa 1960 sind die Geräte auch für nichtmilitärische Zwecke erhältlich.

Die Technik der Bildgebung hat sich in der allgemeinen Verwendung inzwischen grundlegend geändert. Eine Wärmebildkamera wandelt heutzutage die für das menschliche Auge unsichtbare Wärmestrahlung (Infrarotlicht) eines Objektes oder Körpers auch aus größerer Entfernung mit Hilfe von Spezialsensoren in elektrische Signale um, die durch Computer leicht verarbeitet werden können. Dadurch ist der Temperaturmessbereich (Dynamikumfang) deutlich ausgeweitet worden, zudem lassen sich winzige Temperaturunterschiede feststellen. Heutzutage wird Thermografie meist als Synonym für die Infrarotthermografie verwendet.

Jeder Körper mit einer Temperatur oberhalb des absoluten Nullpunktes sendet Wärmestrahlung aus. Im Idealfall (Emissionsgrad formula_1) entspricht das Spektrum der ausgesandten Strahlung dem eines Schwarzen Strahlers, bei realen Oberflächen weicht es ab. Bei polierten Metallflächen sinkt formula_2 im IR-Bereich auf Werte unter 0,1. Bei üblichen Baumaterialien gilt formula_3.

Mit steigender Temperatur verschiebt sich das ausgesandte Spektrum zu kürzeren Wellenlängen (Wiensches Verschiebungsgesetz).
Die Thermographie wird bevorzugt im infraroten Bereich eingesetzt, also bei Objekttemperaturen um 300 K, die im Bereich der gewöhnlichen Umgebungstemperaturen um 20 °C liegen. Damit die Messungen an weiter entfernt liegenden Objekten nur wenig durch die zwischen Objekt und Kamera liegenden Atmosphäre verfälscht werden, arbeiten die Kameras in der Regel in eingeschränkten Wellenlängenbereichen, in denen die Atmosphäre kaum Eigenstrahlung emittiert (und absorbiert). Ein solches „Fenster“ liegt beispielsweise im Bereich von etwa 8 bis 14 µm (siehe atmosphärische Gegenstrahlung / atmosphärisches Fenster).

Drei Wärmeleistungen tragen zum Ergebnis bei:

Alle drei Anteile werden beim Durchlaufen der Luft geschwächt, für Entfernungen um zwei Meter kann man mit einem Transmissionsgrad von formula_5 rechnen.

Die gesamte empfangene Leistung berechnet sich zu

Streustrahlung von Sonnenlicht und heißer, seitlicher Strahler sind bei sorgfältiger Messung am leichtesten zu vermeiden. Problematisch ist aber die Strahlungsleistung der Luftmasse zwischen Objekt und Sensor, wenn der Abstand zunimmt. Deshalb sind erdgebundene Infrarotteleskope nur für die Beobachtung der relativ nahen Sonne brauchbar. Weiter entfernte Objekte lassen sich nur erkennen, wenn die Dicke der Luftschicht (wie beim Stratosphären-Observatorium für Infrarot-Astronomie) stark verringert oder (wie bei Wide-Field Infrared Survey Explorer und Spitzer-Weltraumteleskop) ganz ausgeschaltet wird.

Reale Flächen emittieren weniger Strahlung als ein Schwarzer Strahler. Das Verhältnis liegt immer zwischen Null und eins und heißt Emissionsgrad. Es ist vom Material, der Oberflächenbeschaffenheit, jedoch kaum von der Temperatur abhängig und für polierte Metallflächen besonders klein. Ein Beispiel illustriert die damit verbundene Problematik: Eine stark verrostete Eisenplatte einheitlicher Temperatur 30 °C = 303 K wird streifenweise poliert, das ergibt wegen der stark unterschiedlichen Emissionsgrade einen „Lattenzauneffekt“ starker und schwacher IR-Strahlung. Aus dem Stefan-Boltzmann-Gesetz

folgt für die abgestrahlte Leistung pro Flächeneinheit

Die Wärmebildkamera wertet nur Unterschiede der empfangenen Leistung aus, weshalb sich ein scheinbarer Temperaturunterschied von

errechnet. Wird die Wärmebildkamera so eingestellt, dass der verrosteten Oberfläche 303 K zugeordnet wird, sollte sie den polierten Streifen die absolute Temperatur 149 K zuordnen, das entspricht −124 °C. Tatsächlich wird wohl eine deutlich höhere Temperatur angezeigt werden, weil unerwünschte IR-Strahlung aus der Umgebung an der reflektierenden Oberfläche „eingeblendet“ wird.

An jeder Wärmebildkamera lässt sich der vermutete Emissionsfaktor vorwählen. Würde man diesen so einstellen, dass die Temperatur der polierten Flächen mit der Wirklichkeit übereinstimmt, würde dieses Messgerät von den verrosteten Stellen so viel mehr Strahlungsleistung registrieren, dass es eine Temperatur von 342 °C = 615 K errechnen würde. Strahlungsmessungen sind also mit Vorsicht zu betrachten. Muss die Temperatur blanker Metalloberflächen bestimmt werden, empfehlen Messgerätehersteller, eine ausreichend große Fläche zu lackieren oder mit Klebeband abzudecken.

Der Einfluss der Temperatur auf den Emissionsgrad kann bei Messungen im Temperaturbereich von 0 °C bis 100 °C in den meisten Fällen vernachlässigt werden.

Viele Nichtmetalle besitzen im mittleren Infrarot einen Emissionsgrad nahe eins. Beispiele sind Glas, mineralische Stoffe, Farben und Lacke beliebiger Farbe, Eloxalschichten beliebiger Farbe, Plastwerkstoffe (außer Polyethylen; siehe nebenstehende Bilder), Holz und andere Baustoffe, Wasser und Eis.

Die Temperatur von Oberflächen mit geringem Emissionsgrad wie Metalle lässt sich mit Thermografie oft nicht verlässlich bestimmen.

Bei der passiven Thermografie wird die durch die Umgebung oder den Prozess bedingte Temperaturverteilung der Bauteiloberfläche erfasst. Dies wird beispielsweise in der Bautechnik zum Auffinden von Wärmebrücken oder an technischen Geräten im Betrieb genutzt, um Verlustwärmequellen und Defekte zu erkennen. Eine weitere Anwendung ist z. B. die zerstörungsfreie Prozessüberwachung beim Spritzgießen, bei der die eingetragene Prozesswärme zur zerstörungsfreien Prüfung genutzt wird. Bedingt durch die unterschiedlichen Abkühlgeschwindigkeiten oberflächennaher und -ferner Bereiche ergeben sich Wärmeströme innerhalb des Bauteils. Innenliegende Strukturen wie unbeabsichtigte Fehlstellen können dabei wie eine thermische Barriere wirken, sodass sich dies durch eine veränderte Temperaturverteilung an der Oberfläche äußert.

Entsprechend der DIN 54190-1 wird das zu prüfende Bauteil bei Anwendung der aktiven Thermografie thermisch angeregt, wodurch ein Wärmefluss im Objekt erzeugt wird. Grundsätzlich wird zwischen einer periodischen Anregung z. B. bei der Lock-in-Thermografie und einer einmaligen Anregung bei der Impuls-Thermografie unterschieden.

Die thermische Anregung erfolgt z. B. mittels Blitzlampen, Lasern, Ultraschall oder induktiver Erwärmung Bei der Ultraschallanregung wird die Energie akustisch in das Bauteil eingekoppelt, die vorzugsweise im Defektbereich gedämpft oder an losen Kontaktstellen durch Reibung in Wärme umgewandelt wird und folglich zu einer lokalen detektierbaren Erwärmung führt. Auch Materialien wie Kohlefaserverbundwerkstoffe lassen sich induktiv anregen. Hier verursachen z. B. Brüche in den leitfähigen Fasern eine veränderte detektierbare Wärmeerzeugung.

Inhomogenitäten beeinflussen den Wärmeabfluss in das Bauteilinnere (Anregung und Kamera auf der gleichen Seite, sogenannte Reflexionsanordnung) oder durch das Bauteil hindurch (Anregung von hinten, also transmissiv, z. B. bei beidseitig zugänglichen Wandungen, Gehäusen, Karosserieteilen anwendbar) und führen dadurch zu lokalen Temperaturunterschieden an der Oberfläche.

Nachteilig sind u. U. die thermische Belastung sowie die Kosten und Gefahren der Anregungsquelle.

Erfahrungsgemäß gilt u. a. bei Kunststoffen, dass lediglich Fehler erkannt werden können, deren Tiefe im Bauteil maximal ihrer auf die Oberfläche projizierten Ausdehnung entspricht.

Bei der Lock-in-Thermografie erfolgt die Anregung intensitätsmoduliert und periodisch. Die Lock-in-Thermografie ist frequenzselektiv, d. h., sie spricht nur auf Temperaturänderungen bei der spezifischen Anregungsfrequenz an. Das durch eine pixelweise diskrete Fourieranalyse erhaltene Phasenbild zeigt im Gegensatz zum Amplitudenbild unabhängig von der Ausleuchtungsqualität und dem Emissionsgrad die thermischen Strukturen unterhalb der Oberfläche. Die Eindringtiefe hängt primär von der Modulationsfrequenz und der Temperaturleitfähigkeit ab. Je geringer die Anregungsfrequenz ist, desto höher sind die Eindringtiefe und auch die erforderliche Messzeit.

Die aktive Thermografie eignet sich besonders zur berührungslosen Untersuchung von homogenen großflächigen und dünnwandigen Bauteilen einfacher Geometrie. Bei Kunststoffen ist die Anwendung meist auf geringe Wandstärken im Millimeterbereich beschränkt. Thermografie kann vor allem oberflächennahe dreidimensionale Fehler darstellen, aber auch flächige Fehler wie Delaminationen, fehlende Anbindung bei Schweißnähten oder das Fehlen von Faserlagen erfassen. Selbst das Fehlen einzelner Rovings in Faserverbundbauteilen wie Rotorblättern von Windturbinen kann erfasst werden.

Zur Bilderzeugung im Mittleren Infrarot werden kalibrierte Wärmebildkameras verwendet.

Aufgebaut ist eine Wärmebildkamera im Prinzip wie eine normale elektronische Kamera für sichtbares Licht, die Sensoren unterscheiden sich aber in Aufbau und Funktionsweise je nach zu detektierender Wellenlänge. Es ist nicht möglich, mit herkömmlichen Filmen solch langwellige Strahlung aufzunehmen.

Durch ein Objektiv wird ein Bild auf einen elektronischen Bildsensor projiziert. Kameras für den Wellenlängenbereich von 8 bis 14 µm verwenden Objektive aus einkristallinem Germanium oder Zinkselenid. Auch einkristallines Natriumchlorid wäre geeignet, ist aber feuchteempfindlich.

Als elektronische Bildsensoren werden oft tief gekühlte Fotohalbleiter verwendet, Mikrobolometerarrays oder pyroelektrische Sensoren müssen hingegen nicht zwingend gekühlt werden.

Die photoelektrisch arbeitenden Detektoren werden oft auf Temperaturen um 77 K (flüssiger Stickstoff) gekühlt, damit die Sensoren überhaupt als Fotoempfänger arbeiten können. Die thermische Empfindlichkeit (Temperaturauflösung) des Thermografiesystems lässt sich gegenüber ungekühlten Systemen entscheidend erhöhen. Auch ungekühlte Infrarot-Sensoren werden oft thermoelektrisch thermostatiert, um Signaldrift der Empfänger-Elemente zu verringern. Solche Geräte sind deutlich kleiner und kostengünstiger als tief gekühlte Systeme. Sie liefern aber ein vergleichsweise schlechteres Ergebnis.

Die Detektorzelle eines Mikrobolometerarrays besteht aus einer nur wenige Mikrometer dicken, absorbierenden Scheibe, welche durch zwei gebogene Kontakte gehalten wird (sogenannte Mikrobridges). Die Scheiben bestehen aus einem Material mit einem stark temperaturabhängigen Widerstand (zum Beispiel Vanadiumoxid). Die absorbierte Infrarotstrahlung führt zu einer Temperaturerhöhung des Scheibchens, was wiederum den Widerstand ändert. Der gemessene Spannungsabfall wird als Messsignal ausgegeben.

Pyroelektrische Sensoren liefern dagegen nur bei Temperatur"änderung" eine Spannung mit sehr hoher Quellimpedanz.

Pyrometrische Sensoren benötigen einen mechanischen Chopper, Mikrobolometerarrays zumindest eine periodische Abschattung des Bildsensors. Der Grund ist bei pyrometrischen Sensoren, dass diese nur auf Temperaturänderungen reagieren können. Bei Bolometerarrays dient der Chopper oder "shutter" dazu, ein Dunkelbild zu gewinnen, welches als sensorspezifische Referenz (jedes Pixel besitzt einen individuell unterschiedlichen Widerstand) vom aufgenommenen Bild Pixel für Pixel abgezogen wird.











</doc>
<doc id="5039" url="https://de.wikipedia.org/wiki?curid=5039" title="Transurane">
Transurane

Die Transurane sind die Elemente mit einer höheren Ordnungszahl als Uran (größer als 92).

Alle Transurane sind radioaktiv mit Halbwertszeiten zwischen einigen 10.000.000 Jahren (selten, z. B. Plutonium-244) über Minuten bis zu Bruchteilen einer Sekunde (häufig). Einige Isotope der leichteren Transurane von Neptunium bis Curium haben Halbwertszeiten von einigen Jahrmillionen, Jahrtausenden oder Jahrhunderten. Sie entstehen in Kernreaktoren und machen einen Teil der langlebigen radioaktiven Abfälle aus.

Nach dem Uran mit der Ordnungszahl 92 beginnt die Reihe der Transurane mit dem Neptunium (Element 93). Neben dem für die Kernspaltung bedeutenden Element Plutonium (94) gehören auch Americium (95), Curium (96), Berkelium (97), Californium (98), Einsteinium (99), Fermium (100), Mendelevium (101), Nobelium (102) und Lawrencium (103) sowie alle weiteren schwereren Elemente (Transactinoide) zu den Transuranen.

Die hier namentlich genannten Transurane wurden in der Arbeitsgruppe um Glenn T. Seaborg hergestellt und charakterisiert; Seaborg erhielt dafür 1951 den Nobelpreis für Chemie.

Bis einschließlich des Elements 103, des Lawrenciums, gehören sie zusammen mit Thorium (90), Protactinium (91) und Uran (92) zur Gruppe der Actinoide.

Aufgrund der geologisch gesehenen kurzen Halbwertszeiten kommen Transurane in der Natur nicht oder nur in Spuren vor, die durch Neutroneneinfang und nachfolgenden Beta-Zerfall des Urans entstehen, z. B.:

Einzige Ausnahme bildet das Plutonium Pu, das noch aus der Entstehungszeit des Sonnensystems stammt.

Transurane lassen sich technisch aus Uran oder anderen Elementen mit hoher Ordnungszahl herstellen. Dazu werden solche Atomkerne mit Neutronen oder anderen Atomkernen beschossen; dabei auftretende Neutroneneinfänge und anschließender Beta-Zerfall ergeben Transurane.

Ursprünglich war Transuran eine kürzere Bezeichnung für ein "künstliches superschweres Element". Das in winzigsten Spuren vorkommende Plutonium-244 aus der Entstehungszeit des Sonnensystems wurde erst 1971, lange nach der Prägung des Begriffes "Transuran", entdeckt. In der ursprünglichen Bedeutung müsste man daher heute von "Transplutonium-Elementen" sprechen.




</doc>
<doc id="5041" url="https://de.wikipedia.org/wiki?curid=5041" title="Titan">
Titan

Titan steht für





Titan steht im weiteren Sinn für:


Siehe auch:



</doc>
<doc id="5042" url="https://de.wikipedia.org/wiki?curid=5042" title="Thulium">
Thulium

Thulium ist ein chemisches Element mit dem Elementsymbol Tm und der Ordnungszahl 69. Im Periodensystem steht es in der Gruppe der Lanthanoide und zählt damit auch zu den Metallen der Seltenen Erden.

Die Entdeckung des Thuliums erfolgte im Zuge der genaueren Untersuchungen des Gadolinits und der daraus isolierbaren Elemente. Carl Gustav Mosander und anderen gelang es zunächst, Gadolinit in Erbinerde (Erbiumoxid), Terbinerde (Terbiumoxid) und Yttererde (Yttriumoxid) zu trennen. Die Erbinerde stellte sich bald darauf ebenfalls als Gemisch heraus, als zunächst durch Jean Charles Galissard de Marignac das Ytterbium, dann durch Lars Fredrik Nilson das Scandium abgetrennt werden konnte.

1879 stellte Per Teodor Cleve durch Vergleich von Absorptionsspektren verschiedener Proben, die beim Trennen von Erbium und Ytterbium entstanden waren, fest, dass diese bestimmte Absorptionsbanden in unterschiedlicher Stärke enthielten, also weitere Elemente enthalten sein müssten. Er identifizierte zwei Elemente, die er Holmium und Thulium nannte. Die charakteristische Absorptionsbande des Thuliums lag dabei bei 684 nm. Der Name Thulium wurde nach einem alten Namen von Skandinavien gewählt. Zwar hatte Jacques-Louis Soret schon vor Cleve die Absorptionsbanden für Thulium und Holmium entdeckt, jedoch nur ein neues Element („X“ genannt), das dem Holmium entsprach, identifiziert.

Nach seiner Entdeckung des Thuliums versuchte Cleve 1880, reines Thuliumoxid zu erhalten, er konnte dieses jedoch nicht vollständig von Ytterbium trennen und daher nur eine ungefähre Atommasse bestimmen. Charles James stellte 1911 erstmals reines Thuliumoxid durch 15.000-fache fraktionierte Kristallisation und Trennung der Bromate von Erbium, Thulium und Ytterbium dar.

Elementares Thulium wurde erstmals 1936 von Wilhelm Klemm und Heinrich Bommer erhalten. Sie gewannen das Metall durch Reduktion von Thulium(III)-chlorid mit Kalium bei 250 °C. Weiterhin bestimmten sie die Kristallstruktur und die magnetischen Eigenschaften des Metalls.

Thulium ist auf der Erde ein seltenes Element, seine Häufigkeit in der kontinentalen Erdkruste beträgt etwa 0,52 ppm. Es ist damit abgesehen vom instabilen Promethium das seltenste Lanthanoid. Thulium ist jedoch häufiger als Elemente wie Iod oder Silber.

Das Element kommt ausschließlich als Nebenbestandteil von verschiedenen Seltenerd-Mineralen, insbesondere von Yttererden der schweren Lanthanoide vor. So enthält Monazit je nach Vorkommen 0,01-0,51 % Thulium, Xenotim bis zu 0,9 % des Elementes. Minerale mit dem Hauptbestandteil Thulium oder natürliches elementares Thulium sind nicht bekannt.

Thulium ist zwar nur sehr aufwändig und teuer herzustellen, wird jedoch auch nur in sehr geringen Mengen eingesetzt. Darum wird die Versorgung mit Thulium nicht als kritisch angesehen.

Nach einer aufwändigen Abtrennung der anderen Thuliumbegleiter wird das Oxid mit Lanthan zum metallischen Thulium reduziert. Anschließend wird das Thulium absublimiert.

Das silbergraue Metall der seltenen Erden ist sehr weich, gut dehnbar und schmiedbar.

In trockener Luft ist Thulium recht beständig, in feuchter Luft läuft es grau an. Bei höheren Temperaturen verbrennt es zum Sesquioxid.

Mit Wasser reagiert es unter Wasserstoffentwicklung zum Hydroxid. In Mineralsäuren löst es sich unter Bildung von Wasserstoff auf.

In seinen Verbindungen liegt es in der Oxidationsstufe +3 vor, die Tm-Kationen bilden in Wasser pastell-bläulich-grüne Lösungen.

Thulium ist das seltenste Metall der seltenen Erden, kommt aber in der Erdkruste immer noch häufiger vor als Gold oder Platin. Neben einer minimalen Verwendung in Fernsehgeräten (zur Aktivierung der Leuchtstoffe auf der Bildschirmfläche) gibt es nur wenige kommerzielle Anwendungen:

Thulium und Thuliumverbindungen sind gering toxisch. Thuliumstäube sind feuer- und explosionsgefährlich.




</doc>
<doc id="5043" url="https://de.wikipedia.org/wiki?curid=5043" title="Thallium">
Thallium

Thallium ist ein chemisches Element mit dem Elementsymbol Tl und der Ordnungszahl 81. Im Periodensystem steht es in der 3. Hauptgruppe, bzw. der 13. IUPAC-Gruppe, der Borgruppe. Das weiche, graue und dem Blei sehr ähnliche Metall ist äußerst giftig.

Thallium (von altgriechisch "thallós" ‚grüner Zweig‘; wegen seiner grünen Spektrallinie bei 535 nm) wurde 1861 in England von Sir William Crookes spektroskopisch im Bleikammerschlamm einer Schwefelsäurefabrik anhand der charakteristischen grünen Spektrallinie entdeckt. Zur gleichen Zeit gelang dem Franzosen Auguste Lamy die Darstellung des Metalls auf elektrolytischem Wege.

Thallium ist kein seltenes Element, aber es gibt sehr wenige Mineralien mit hohem Thalliumgehalt: so den Crookesit (Schweden und Russland), den Lorandit (Allchar, Mazedonien; USA) und den Hutchinsonit. Die überwiegende Menge ist als Begleitelement in kaliumhaltigen Tonen, Böden und Graniten enthalten. Der natürliche Gehalt liegt dabei zwischen 0,4 und 6,5 mg/kg. Zur Bedarfsdeckung ist die aus der Verhüttung von Kupfer, Blei, Zink und anderen sulfidischen Erzen anfallende Menge ausreichend.

Für Trinkwasser geht das Bundesinstitut für Risikobewertung von einem Toleranzwert bis zu 5 µg/L aus.

Das Isotop Tl ist das Endnuklid des radioaktiven Zerfalls von Bi (Halbwertszeit 1,9 · 10 Jahren) aus der Neptunium-Reihe.

Metallisches Thallium wird meist durch Ausfällen mit Zink gewonnen. Die Weltproduktion von Thallium beträgt 5 Tonnen pro Jahr.

Frische Schnittflächen des weichen und hämmerbaren Metalls sind hochglänzend, nach kurzer Zeit überziehen sie sich mit einem blaugrauen Oxidfilm. In feuchter Luft und Wasser bildet sich Thallium(I)-hydroxid, das eine sehr starke Base ist. In Alkalilaugen ist es unlöslich.

Im Gegensatz zu den leichteren Gruppenmitgliedern kommt Thallium überwiegend in der Oxidationsstufe +I vor, auch +II und +III sind möglich. Daher kann Thallium als Begleiter in vielen verschiedenen Mineralien vorkommen.

In vielen Eigenschaften ähnelt Thallium in der Oxidationsstufe +I stark dem wesentlich leichteren Kalium, was nicht zuletzt auf sehr ähnliche Ionenradien zurückzuführen ist. So ist Thalliumcarbonat das einzige leicht wasserlösliche Schwermetallcarbonat. Andererseits existieren auch Parallelen zur entsprechenden Oxidationsstufe des Silbers (Thalliumhalogenide sind schwerlöslich und lichtempfindlich).

Thalliumverbindungen zeigen eine intensiv grüne Flammenfärbung, im Spektroskop ist eine scharfe Emissionslinie bei 535 nm charakteristisch (wichtig in der Forensik).

Mit Halogenen reagiert Thallium schon bei Zimmertemperatur. Die sich bildenden Thalliumhalogenide (mit Ausnahme der Fluoride) werden durch Aufnahme geringer Spuren von Wasser bei –180 °C fluoreszenzfähig.


Thallium wird gut vom Körper aufgenommen, vor allem über den Magen-Darm-Trakt oder die Lunge. Dreiwertiges Thallium (Tl) wird im Körper rasch zu einwertigem Thallium (Tl) reduziert und elementares zu Tl oxidiert, das sich sehr schnell verteilt und über die Na/K-Pumpe aus dem Blutkreislauf ins Zellgewebe und in die Organe transportiert wird. Aufgrund des Ionenradius des Tl wird es vom Körper wie Kalium-Ionen K angesehen und transportiert. Hohe Konzentrationen von Tl finden sich in Niere und Leber sowie im Dickdarmgewebe und in bestimmten Knochen. Nach einer überstandenen Vergiftung ist Tl noch lange in Nägeln und Haaren zu finden. Weiterhin ist Tl bei der Ausscheidung aus dem Körper bedenklich. Ähnlich wie die Amatoxine bei einer Knollenblätterpilzvergiftung unterliegt auch Tl dem sogenannten enterohepatischen Kreislauf. Die versuchte Entgiftung über Leber und schließlich mit dem Gallensekret wird durch die Rückresorption der Tl-Ionen im Darm verhindert. Zwar ist dieser Ausscheidungsweg mengenmäßig kleiner als der über die Niere, diese ist aber ganz besonders von der Schädigung durch Tl betroffen. Deswegen setzt bei der Ausscheidung über die Galle und den Darm (biliäres System) die medizinisch induzierte Entgiftung mit Eisen(III)hexacyanoferrat(II) (landläufig als Berliner Blau bekannt) an. Die über die Gallensekrete in den Zwölffingerdarm abgegebenen Tl werden dort bzw. im Darm von „Berliner Blau“ chemisch gebunden und schließlich über den Kot ausgeschieden.

Für Thallium wurde noch keine biologische Funktion bestätigt.

Thallium und thalliumhaltige Verbindungen sind hochgiftig und müssen mit größter Vorsicht gehandhabt werden.

Die tödliche Dosis für Erwachsene beträgt zirka 800 mg. Die akute Vergiftung verläuft in vier Phasen, deren erste relativ allgemeinsymptomatisch mit sich abwechselnden Durchfällen und Verstopfungen verläuft. In dieser Phase sind bereits Veränderungen der Haarwurzeln zu erkennen, die dann meist mit dem 13. Tag in den für eine Thalliumvergiftung typischen Haarausfall an bestimmten Körperstellen in unterschiedlicher Ausprägung übergeht. In der zweiten Phase stellen sich neurologische und psychische Veränderungen ein, die sich als übermäßige Schmerzwahrnehmung an peripheren Körperteilen bemerkbar machen. Die Vergiftung kulminiert dann in der dritten Phase nach dem 10. Tag der Aufnahme. Es stellen sich schwere Sehstörungen ein, die durch die Lähmung der entsprechenden Hirnnerven bewirkt werden. Die erhöhte Herzaktivität (Tachykardie) erklärt sich durch Einwirkung des Thalliums auf die Erregungsbildung des Sinusknotens und auf die Erregungsweiterleitung, die durch die daraus resultierenden Herzrhythmusstörungen in die letal verlaufende Tl-Vergiftung mündet. Mit der dritten Woche der Vergiftung erhöht sich die Wahrscheinlichkeit eines letalen Ausganges und die Spätphase (u. a. Darmperforation) stellt sich ein. Hier zeigen sich meist irreversible Schäden an Nervenfortleitungen der unteren Körperteile, gestörte Reflexe und Muskelschwund. Es kann eine dauerhaft herabgesetzte geistige Leistungsfähigkeit zurückbleiben, wobei sehr schwere Vergiftungen zu schwersten irreversiblen Gehirnschäden führen können. Die Körperbehaarung entwickelt sich nach wenigen Monaten wieder neu. Geringere Mengen führen zu einer chronischen Vergiftung, die längere Zeit unerkannt bleiben kann (eventuell sind Mees-Nagelbänder zu beobachten), dies weist dann allerdings meist auf eine beabsichtigte Vergiftung hin, da eine natürliche Aufnahme toxischer Mengen kaum möglich ist.

Bei der Zementherstellung kann sich Thallium in Form seiner flüchtigen Halogenide im Abgasreinigungssystem anreichern.

Tierische und pflanzliche Nahrungsmittel enthalten in der Regel nicht mehr als 0,1 mg/kg Tl. Dennoch können zum Beispiel Pilze und einige Kohlsorten Thallium bis zu 1 mg/kg akkumulieren.



</doc>
<doc id="5044" url="https://de.wikipedia.org/wiki?curid=5044" title="Tantal">
Tantal

Tantal [] ist ein chemisches Element mit dem Symbol Ta und der Ordnungszahl 73; im Periodensystem steht es in der fünften Nebengruppe oder Vanadiumgruppe. Es ist ein selten vorkommendes, duktiles, graphitgraues, glänzendes Übergangsmetall. Tantal wird vorwiegend für Kondensatoren mit hoher Kapazität bei gleichzeitig geringer Größe verwendet. Da das Metall ungiftig und in Bezug auf Körperflüssigkeiten inert ist, wird es auch für Implantate, etwa für Knochennägel, eingesetzt.

Das Element wurde 1802 von Anders Gustav Ekeberg sowohl in einem Tantalit-Erz aus Kimito in Finnland als auch in Yttererde aus Ytterby in Schweden gefunden. Er trennte ein sehr beständiges Oxid (Tantal(V)-oxid) ab, das sich in keiner Säure löste. Benannt ist es nach Tantalos, einer Figur aus der griechischen Mythologie. Diesen Namen wählte Ekeberg, um auf das Unvermögen, auch bei großer Menge an Säure nichts von dieser aufnehmen zu können, anzuspielen.

Etwas früher, im Jahr 1801, fand Charles Hatchett in einem Erz aus Massachusetts ein ihm unbekanntes Element, das er "Columbium" nannte. Die aus den beiden Erzen gewonnenen Oxide wurden 1809 von William Hyde Wollaston verglichen und für Oxide eines einzigen Elementes gehalten. Die gemessenen Unterschiede im spezifischen Gewicht der Oxide erklärte er durch unterschiedliche Oxidationszustände des Elementes. Erst Heinrich Rose misstraute diesem Ergebnis und untersuchte die Erze genauer. Ihm gelang es 1844 zu beweisen, dass es zwei unterschiedliche Elemente in Columbit- und Tantalit-Erzen gibt, wobei er das leichtere, im Columbit vorkommende, nach Niobe, der Tochter des Tantalos, Niob nannte.

Nach der Entdeckung des neuen Elements wurde von verschiedenen Chemikern versucht, Tantal auch elementar darzustellen. Der erste, der elementares Tantal durch Reduktion von Kaliumheptafluorotantalat mit Kalium darstellte, war 1824 Jöns Jakob Berzelius. Allerdings bestand sein Metall wie das von Rose dargestellte Tantal nur zu 50 % aus Tantal. Henri Moissan versuchte 1902, Tantal im elektrischen Ofen herzustellen, sein Produkt war jedoch durch den enthaltenen Kohlenstoff sehr hart und spröde.

Der erste, der reines, duktiles Tantal herstellen konnte, war Werner von Bolton 1903. Er erreichte dies durch Reduktion der glühenden Oxide im Vakuum sowie durch Schmelzen von unreinem Tantalmetall im Vakuum und elektrischem Flammenbogen.

Die erste Anwendung des neuen Elementes war diejenige als Glühfaden in Glühlampen. Der Grund für den Wechsel vom vorher verwendeten Osmium zu Tantal lag darin, dass es leichter zu verarbeiten ist und eine höhere mögliche Nutztemperatur bis zu 2300 °C besitzt. Später wurde es durch Wolfram ersetzt, das einen noch höheren Schmelzpunkt besitzt und damit ein dem Sonnenlicht näheres Lichtspektrum und eine höhere Lichtausbeute ermöglicht.

Im Jahr 1922 wurde mit der Verwendung in Gleichrichtern und ein Jahr später in Radioröhren ein neuer Einsatzzweck für Tantal gefunden.

Tantal ist mit einem Gehalt von 2 ppm in der kontinentalen Erdkruste bzw. 8 ppm in der Erdhülle ein seltenes Element auf der Erde. Die Häufigkeit ist vergleichbar mit der von Arsen und Germanium. Innerhalb der Gruppe nimmt die Häufigkeit jeweils um eine Zehnerpotenz ab. Im Sonnensystem ist Tantal sogar das seltenste stabile Element.

Tantal kommt nicht gediegen, sondern nur in Form seiner Verbindungen in verschiedenen Mineralen vor. Auf Grund der Ähnlichkeit der beiden Elemente enthalten Tantalerze stets Niob und umgekehrt (Vergesellschaftung). Die wichtigsten Minerale sind die der Columbit- und Tapiolit-Reihe, in der verschiedene Minerale mit der allgemeinen Formel (Mn, Fe)(Nb,Ta)O zusammengefasst werden. Tantalreiche Columbite werden auch als "Tantalite" bezeichnet. Beispiele für Tantalhaltige Minerale dieser Reihen sind Ferrotapiolith (Fe, Mn)(Ta, Nb)O und Manganotantalit MnTaO. Häufig werden diese Erze auch als Coltan bezeichnet. Seltenere Minerale sind Mikrolith oder Thoreaulith.

2011 entfielen geschätzte 40-50 % des weltweiten Tantalabbaus auf Ruanda und die Demokratische Republik Kongo. 2007 waren dagegen noch Australien mit 850 Tonnen und Brasilien mit 250 Tonnen die wichtigsten Förderländer von Tantalerzen. Zwei Minen in Australien waren bedeutend: Die Wodgina Mine im Nordwesten und die Mine in Bridgetown-Greenbushes Shire in Westaustralien. Daneben findet man Coltan auch in Kanada und verschiedenen afrikanischen Ländern wie Äthiopien, Mosambik und Ruanda. In den Medien bekannt geworden sind die Vorkommen im Osten der Demokratischen Republik Kongo, die im Kongokrieg 1996–2008 stark umkämpft waren und in den nachfolgenden bewaffneten Konflikten weiterhin eine wichtige Rolle spielen.

Einige Tantalerze wie Tantalit und Coltan, sowie deren Derivate wurden 2012 von der US-amerikanischen Börsenaufsicht SEC als so genanntes "Konfliktmineral" eingestuft, dessen Verwendung für Unternehmen gegenüber der SEC berichtspflichtig ist. Als Grund hierfür werden ebendiese Produktionsorte im Osten des Kongo angeführt, die von Rebellen kontrolliert werden und so im Verdacht stehen, bewaffnete Konflikte mitzufinanzieren.

Da in den zur Tantalgewinnung verwendeten Erzen Tantal und Niob immer zusammen vorliegen, müssen sie für eine Gewinnung der Reinmetalle getrennt werden. Dies wird durch die große Ähnlichkeit der beiden Elemente erschwert.

Das erste Verfahren zur Trennung wurde 1866 von Jean Charles Galissard de Marignac entwickelt. Er nutzte dabei die unterschiedliche Löslichkeit der beiden Elemente in verdünnter Flusssäure. Tantal bildet das gering lösliche KTaF, Niob das gut lösliche KNbOF ·2 HO.

Das heute technisch verwendete Verfahren beruht auf Extraktion und nutzt die unterschiedliche Löslichkeit von komplexen Fluorsalzen in Wasser und bestimmten organischen Lösungsmitteln. Dabei wird das Erzgemisch zunächst in konzentrierter Flusssäure oder Gemischen aus Fluss- und Schwefelsäure gelöst. Es bilden sich die komplexen Fluoride <nowiki>[</nowiki>NbOF<nowiki>]</nowiki> und <nowiki>[</nowiki>TaF<nowiki>]</nowiki>. Nachdem unlösliche Bestandteile abfiltriert wurden, kann die Trennung durch Flüssig-Flüssig Extraktion mit Hilfe von Methylisobutylketon erfolgen. Wird die Lösung mit Methylisobutylketon versetzt, gehen die Niob- und Tantalkomplexe in die organische Phase über, während andere Elemente, wie Eisen, oder Mangan in der wässrigen Phase zurückbleiben. Bei Zugabe von Wasser zur abgetrennten organischen Phase, löst sich nur der Niobkomplex in diesem, das Tantal bleibt im Methylisobutylketon zurück.

Das Tantal kann mit Hilfe von Kaliumfluorid als schwerlösliches Kaliumheptafluorotantalat K<nowiki>[</nowiki>TaF<nowiki>]</nowiki> gefällt werden. Die Reduktion zu elementarem Tantal erfolgt meist durch Natrium.

Eine mögliche Alternative zur Extraktion besteht in der fraktionierten Destillation. Dazu werden die unterschiedlichen Siedepunkte der beiden Chloride Niob(V)-chlorid und Tantal(V)-chlorid genutzt. Diese können bei hohen Temperaturen aus den Erzen mit Chlor und Koks gewonnen werden. Nach der Trennung wird das Tantalchlorid ebenfalls mit Natrium zum Metall reduziert.

Neben den Columbit-Tantalit-Erzen sind Schlacken aus der Zinnverhüttung eine wichtige Quelle für die Tantalgewinnung (enthalten wenige Prozent Tantal).

Tantal aus Kondensatoren wird fast gar nicht recycelt. Die bei der Pulverherstellung entstehenden internen Abfälle dagegen kommen für internes Recycling in Frage. Bei der Herstellung von Tantal-Walzerzeugnissen (20 % des Verbrauchs) fallen Späne und Fehlchargen an, die durch Umschmelzen effektiv zu recyceln sind. Außerdem sind Tantalcarbid-Legierungzusätze recycelbar.

Tantal(V)-oxid aus Gläsern und solches in Form von Lithiumtantalat-Einkristallen in Elektronikbauteilen erfordert einen aufwendigen chemischen Recyclingprozess. Dieser umfasst Rösten, Auflösen in Flusssäure oder Schwefelsäure, Solventextraktion mit Ketonen sowie die Fällung von Tantal(V)-oxid oder die Kristallisation von Kaliumfluorotantalat. Diese werden anschließend im Elektronenstrahlofen aufgeschmolzen.

Tantal ist ein deutlich lilagraues, stahlhartes (Vickershärte: 60–120 HV), hochschmelzendes Schwermetall, das in den meisten seiner Eigenschaften dem Niob ähnelt. Es kristallisiert in einer kubisch-raumzentrierten Kristallstruktur. Neben der kubischen α-Struktur ist auch β-Tantal bekannt, das in einer tetragonalen, dem β-Uran entsprechenden, Kristallstruktur mit den Gitterparametern a = 1021 pm und c = 531 pm kristallisiert. Diese Modifikation ist metastabil und lässt sich durch Elektrolyse einer Tantalfluoridschmelze gewinnen.

Mit einem Schmelzpunkt von etwa 3000 °C besitzt Tantal den höchsten Schmelzpunkt aller Elemente nach Wolfram, Kohlenstoff und Rhenium. Ist im Metall nur eine geringe Menge Kohlenstoff oder Wasserstoff eingelagert, steigt der Schmelzpunkt deutlich an. Ein unterstöchiometrisches Tantalcarbid besitzt mit einem Schmelzpunkt von 3983 °C einen der höchsten Schmelzpunkte aller Substanzen.

Unterhalb einer Sprungtemperatur von 4,3 Kelvin wird Tantal zum Supraleiter.

Während reines Tantal duktil ist und sich stark dehnen lässt (Zugfestigkeit: 240 MPa), verändern schon kleine Mengen Beimengungen an Kohlenstoff oder Wasserstoff die mechanische Festigkeit deutlich. Das Material wird spröde und schwer zu verarbeiten. Man nutzt diesen Sachverhalt zur Herstellung von Tantalpulver. Es wird in der Technik mit Wasserstoff beladen und somit versprödet, dann entsprechend zerkleinert und bei höherer Temperatur durch Ausheizen wieder vom Wasserstoff befreit.

Tantal ist ein unedles Metall und reagiert bei hohen Temperaturen mit den meisten Nichtmetallen, wie Sauerstoff, den Halogenen oder Kohlenstoff. Bei Raumtemperatur ist das Metall allerdings durch eine dünne Schicht aus Tantal(V)-oxid geschützt und damit passiviert. Eine Reaktion findet erst ab einer Temperatur von etwa 300 °C statt. Als Pulver ist es ein entzündbarer Feststoff, der durch kurzzeitige Einwirkung einer Zündquelle leicht entzündet werden kann und dann nach deren Entfernung weiterbrennt. Die Entzündungsgefahr ist umso größer, je feiner der Stoff verteilt ist. Das Metall in kompakter Form ist nicht brennbar.

In den meisten Säuren ist Tantal wegen der Passivierung nicht löslich, sogar Königswasser vermag das Metall nicht zu lösen. Angegriffen wird Tantal nur von Flusssäure, Oleum (einer Mischung von Schwefelsäure und Schwefeltrioxid) und Salzschmelzen.

Es sind insgesamt 30 Isotope sowie 26 Kernisomere von Ta bis Ta bekannt. Natürliches Tantal besteht fast ausschließlich (zu 99,988 %) aus dem Isotop Ta. Daneben kommt zu 0,012 % das Kernisomer Ta vor.

Ta ist das einzige langlebige, natürlich vorkommende Nuklid, das nicht in seinem Grundzustand, sondern in einem angeregten Zustand vorliegt. Es wurde bislang kein radioaktiver Zerfall beobachtet, die Halbwertszeit des Isomers muss bei mindestens 2 · 10 Jahren liegen. Der Grundzustand Ta ist dagegen instabil und zerfällt mit einer Halbwertszeit von nur 8,125 Stunden. Ta hat im Sonnensystem eine Häufigkeit von 2,49 · 10 (bezogen auf Silicium = 1 · 10).

Der größte Teil des Tantals (weltweite Jahresproduktionsmenge 1.400 t) wird für sehr kleine Kondensatoren mit hoher Kapazität verwendet. 2007 wurden 60 % des Tantals für die Herstellung von Kondensatoren gebraucht. Diese Tantal-Elektrolytkondensatoren werden überall in der modernen Mikroelektronik, beispielsweise für Mobiltelefone und im Automobilbau, eingesetzt. Die Wirkung beruht auf der selbst in sehr dünner Ausführung noch stabilen und sicher isolierenden Tantaloxidschicht auf der Oberfläche der aufgewickelten Tantalfolie. Je dünner die Schicht zwischen den Elektroden ist, desto höher wird die Kapazität bei gleichbleibender Folienfläche; zudem hat Tantaloxid eine extrem hohe Permittivität, die ebenfalls die Kapazität erhöht.

Da Tantal nicht giftig ist und nicht mit Körpergewebe oder -flüssigkeiten reagiert, wird elementares Tantal für medizinische Implantate und Instrumente eingesetzt. Es werden beispielsweise Knochennägel, Prothesen, Klammern und Kieferschrauben aus Tantal gefertigt. Als Beschichtung auf einem porösen Karbon-Gitter erzielt es eine besonders gute Osseointegration, weshalb Tantal-beschichtete Implantate vor allem in der Rekonstruktionschirurgie bei größeren tumor- oder infektbedingten Knochensubstanzverlusten eingesetzt wird, ohne dass es allerdings antimikrobiell wirkt. 
Daneben ist es ein aufgrund der hohen Kosten wenig eingesetztes Röntgenkontrastmittel.

In der chemischen Industrie wird Tantal wegen seiner Beständigkeit eingesetzt. Es dient als Auskleidungsmaterial für Reaktionskessel und wird für Wärmeaustauscher und Pumpen verwendet. Für diese Zwecke wird meist kein reines Tantal, sondern Legierungen, die 2,5–10 % Wolfram enthalten, verwendet. Diese sind stabiler und widerstandsfähiger als reines Tantal. Gleichzeitig bleibt die erwünschte Duktilität erhalten. Weitere Verwendungszwecke sind Laborgeräte, Spinndüsen und die Kathoden von Elektronenröhren. Hier kommt Tantal zugute, dass es in der Lage ist, bei 800 °C bis zu 740 Volumenteile Gase aufzunehmen (Getterwirkung), was ein hohes Vakuum in den Röhren gewährleistet.

Superlegierungen, die im Bau von Turbinen und Flugzeugtriebwerken eingesetzt werden, enthalten bis zu 9 % Tantal. So erhöht der Zusatz von 3–4 % Tantal zu einer Nickel-Superlegierung die Festigkeit des Materials bei hohen Temperaturen.

Unter Laborbedingungen verursacht der Umgang mit Tantal und seinen Verbindungen normalerweise keine Probleme. Elementares Tantal wie auch Tantalverbindungen sind nicht toxisch. Es gibt aber vage Hinweise auf krebsauslösendes Verhalten einiger Tantalverbindungen. Von Tantalpulver und -staub geht – wie auch von anderen fein verteilten Metallen – eine hohe Feuer- und Explosionsgefahr aus.

Tantal(V)-oxid TaO ist ein weißes Pulver, das zur Herstellung hochlichtbrechender Gläser und spezieller Kristallmaterialien verwendet wird.

Tantalcarbid TaC dient mit seiner Schmelztemperatur von 3880 °C und einer Härte, die ähnlich der von Quarz ist, als Schutzschicht auf hochwarmfesten Legierungen in Triebwerken und Schneidwerkzeugen.




</doc>
<doc id="5045" url="https://de.wikipedia.org/wiki?curid=5045" title="Technetium">
Technetium

Technetium ist ein chemisches Element mit dem Elementsymbol Tc und der Ordnungszahl 43. Es kommt auf der Erde natürlicherweise vor, wenn auch in sehr geringen Mengen. Technetium war das erste künstlich hergestellte Element und erhielt deswegen seinen aus dem altgriechischen Wort τεχνητός "technētós" („künstlich“) hergeleiteten Namen.

Es zählt zu den Übergangsmetallen, im Periodensystem steht es in der 5. Periode und der 7. Nebengruppe (Gruppe 7) oder Mangangruppe. Schon 1925 war die Entdeckung des Elements durch Walter Noddack, Ida Tacke und Otto Berg berichtet worden, die ihm den Namen Masurium gaben. In einigen älteren Büchern wird Technetium daher mit „Ma“ abgekürzt.

Alle Technetium-Isotope sind radioaktiv, das heißt, sämtliche Atomkerne, die 43 Protonen enthalten, sind instabil und zerfallen. Technetium und das schwerere Promethium (61) sind die einzigen Elemente mit kleinerer Ordnungszahl als Bismut (83), die diese Eigenschaft besitzen.

Viele Jahre gab es in dem von dem russischen Chemiker Dmitri Mendelejew vorgeschlagenen Periodensystem der Elemente eine Lücke zwischen den Elementen Molybdän (42) und Ruthenium (44), die auf ein bisher unidentifiziertes Element hinwies. Mendelejew selbst gab ihm den Namen "Eka-Mangan" und sagte mit guter Näherung unter anderem seine Masse voraus. In der Folgezeit versuchten zahlreiche Forscher, das fehlende Element zu entdecken; seine Position im Periodensystem stärkte die Annahme, dass es leichter zu finden sei als andere, noch unentdeckte Elemente mit höheren Ordnungszahlen.

Die Anzahl der vermeintlichen Nachweise des Elements, sowie der mit dem Element in Verbindung gebrachten Entdeckungen ist ungewöhnlich groß. Die erste vermeintliche Entdeckung, die mit Technetium in Verbindung gebracht wurde, ist die von "Polinium" 1828 durch Gottfried Osann. Dieser meinte, neben der tatsächlichen Entdeckung des Rutheniums, auch ein Element entdeckt zu haben, das er Polinium nannte. Es stellte sich allerdings bald heraus, dass es sich bei dem Fund um unreines Iridium handelte. Aufgrund der Lage im damals noch nicht vollständig bekannten Periodensystem wurde die Entdeckung mit Technetium in Verbindung gebracht.

Das nächste vermeintliche Element, das für das spätere Technetium gehalten wurde, war das 1846 entdeckte "Ilmenium". Über dieses, angeblich dem Niob und Tantal ähnliche Element (wahrscheinlich war es unreines Niob) wurde von seinem Entdecker R. Hermann 30 Jahre nach der Entdeckung und unter Einbeziehung des inzwischen erfundenen Periodensystems behauptet, es würde das fehlende Eka-Mangan sein. Auch das 1847 von Heinrich Rose vermeintlich gefundene "Pelopium" wurde für Technetium gehalten.

Die erste Fehlentdeckung, bei der tatsächlich nach dem fehlenden Element mit der Ordnungszahl 43 gesucht wurde, war das "Davyum". 1877 meldete der russische Chemiker Serge Kern die Entdeckung des fehlenden Elements in Platin-Erz und gab dem vermeintlichen Element nach dem englischen Chemiker Sir Humphry Davy den Namen "Davyum". Der Fund stellte sich jedoch als Mischung aus Iridium, Rhodium und Eisen heraus.

Eine weitere vermeintliche Entdeckung fand im Jahr 1896 mit "Lucium" statt, dabei handelte es sich jedoch um Yttrium. Schließlich schloss der japanische Chemiker Masataka Ogawa aus der Analyse eines Minerals auf die Anwesenheit von "Nipponium" (benannt nach "Nippon", dem japanischen Wort für Japan), das er für das Element mit der Ordnungszahl 43 hielt. Spätere Analysen deuteten stattdessen auf Rhenium hin.

Die deutschen Chemiker Walter Noddack, Ida Tacke und Otto Berg berichteten im Jahr 1925 von der Entdeckung des Elements 43 und gaben ihm den Namen "Masurium", abgeleitet von Masuren, der Heimat von Walter Noddack. Die Gruppe beschoss an der Physikalisch-Technischen Reichsanstalt Berlin das Mineral Columbit mit einem Elektronenstrahl und schloss aus den Röntgenspektren auf die Anwesenheit von Element 43. Das beobachtete Signal war jedoch nahe an der Nachweisgrenze und konnte von anderen Arbeitsgruppen zu dieser Zeit nicht reproduziert werden. Eine präparative Reindarstellung gelang – im Einklang mit der Mattauchschen Isobarenregel – nicht. Die Entdeckung wurde deshalb nicht anerkannt. Noch im Jahr 1933 verwenden etliche Artikel über die Entdeckung der Elemente den Namen Masurium für das Element 43.

Im Jahr 1998 wurde die Zurückweisung jedoch in Frage gestellt. John T. Armstrong vom US-amerikanischen National Institute of Standards and Technology simulierte die Experimente mit einem Computer und kam zu vergleichbaren Resultaten wie Noddack, Berg und Tacke. Unterstützung kam durch eine Arbeit von David Curtis vom Los Alamos National Laboratory, der das sehr geringe natürliche Vorkommen von Technetium mit den Methoden von Noddack, Tacke und Berg nachwies. Die Debatte über die umstrittene Erstentdeckung ist daher wieder offen.

1937, 66 Jahre nachdem Dmitri Mendelejew viele der Eigenschaften des Technetiums vorhergesagt hatte, wurde das Element schließlich auf unumstrittene Weise nachgewiesen. Emilio Segrè und Carlo Perrier, beide an der Universität Palermo tätig, isolierten das neue Element aus einer mit Deuteronen bombardierten Molybdänfolie, die Segrè zu Anfang des Jahres von Ernest Lawrence von der University of California, Berkeley, USA, erhalten hatte:

Segrè und Perrier benannten das erste künstlich hergestellte Element nach dem griechischen Wort "τεχνητός" (Transkription "technētós") für „künstlich“ als Technetium und gingen damit nicht auf Wünsche von Verantwortlichen der Universität Palermo ein, die nach dem lateinischen Wort für Palermo, "Panormus", stattdessen den Namen "Panormium" vorgeschlagen hatten.

Powell Richards veröffentlichte im Juni 1960 die erste Studie zur Anwendung von Tc (Halbwertszeit 6 h) in der Nuklearmedizin. Tc wird mittels Technetium-99m-Generatoren aus dem stabileren Mo (Halbwertszeit 66 h) gewonnen. Die erste Methode zur wirtschaftlichen Trennung von Mo und Tc wurde in den 1960er-Jahren von den US-amerikanischen Forschern Walter Tucker und Margaret Green am Brookhaven National Laboratory entwickelt.

1952 wies der US-amerikanische Astronom Paul Willard Merrill auf spektroskopische Weise in Roten Riesensternen der S-; M- und N-Klasse größere Mengen Technetium nach. Weil diese Sterne am Ende ihrer Entwicklung stehen und dementsprechend alt sind, die längste Halbwertszeit eines Technetium-Isotops aber nur wenig mehr als 4 Millionen Jahre beträgt, war dies der erste eindeutige Beweis dafür, dass Technetium und andere schwere Elemente durch Kernfusion im Inneren von Sternen entstehen. Bei Hauptreihensternen wie der Sonne ist die Temperatur im Sterninneren allerdings nicht hoch genug für die Synthese von Elementen schwerer als Eisen. Bedingungen, wie sie im Inneren von Roten Riesen herrschen, sind für die Technetium-Synthese daher unerlässlich.

Seit man die Existenz eines Elements mit der Ordnungszahl 43 annahm, wurde auf der Erde nach natürlichen Vorkommen gesucht. Erst 1961 gelang es, aus 5,3 kg Pechblende aus Katanga in Afrika ungefähr 1 ng Technetium zu isolieren und spektrografisch nachzuweisen. Aus der Spontanspaltung von U-Kernen entsteht dabei das Element 43, wobei aus 1 kg reinem Uran 1 ng Technetium entstehen.

Alles auf der Erde natürlich vorhandene Technetium ist ein temporäres Zwischenprodukt des nuklearen Zerfalls schwerer Atomkerne und zerfällt nach einiger Zeit selbst wieder. Das Vorkommen dieses Elements auf der Erde ist daher nicht mit dem eines stabilen Elements gleichzusetzen. Insgesamt liegt der Technetium-Gehalt der Erdkruste nur wenig höher als der des Franciums und Astats, beides ebenfalls radioaktive Elemente, die nur im Mikrogramm-Maßstab auf der Erde vorhanden sind.

In der Biosphäre kommt Technetium ausschließlich als Resultat menschlicher Aktivitäten vor. Bei oberirdischen Kernwaffentests wurden bis 1994 etwa 250 kg Technetium in der Atmosphäre erzeugt, dazu kommen etwa 1.600 kg, die bis 1986 weltweit aus Wiederaufarbeitungsanlagen und Kernreaktoren freigesetzt wurden. Allein aus der Anlage im britischen Sellafield wurden von 1995 bis 1999 etwa 900 kg des Metalls in die Irische See eingeleitet, seit dem Jahr 2000 ist die gesetzlich erlaubte Eintragsmenge allerdings auf 140 kg pro Jahr begrenzt.

In Lebewesen lässt sich Technetium nur in Ausnahmefällen nachweisen, etwa bei Hummern der stark belasteten Irischen See. Im menschlichen Körper findet es sich in der Regel nur bei Patienten, die sich einer technetiumbasierten nuklearmedizinischen Anwendung unterzogen haben.

Für medizinische Zwecke wird Technetium meist durch Neutronenbeschuss von Mo gewonnen:

Die Mo-Kerne zerfallen unter Aussendung von Betastrahlung mit einer Halbwertszeit von 2 Tagen und 19 Stunden in angeregte (metastabile) Tc-Kerne:

In der Praxis ist Molybdän nicht als Element, sondern in Form seines an Aluminiumoxidsäulen adsorbierten Salzes Molybdat (MoO) der Ausgangsstoff der Technetium-Gewinnung, so dass nicht elementares Technetium, sondern das Pertechnetat-Ion (TcO) entsteht und zwar in typischen Konzentrationen von zwischen 10 und 10 Mol pro Liter. Dieses wird an seinem Einsatzort zunächst von dem verbliebenen Molybdat getrennt, bevor es in Gegenwart geeigneter Liganden, organischer Substanzen, die sich mit Technetium zu Komplexen verbinden, durch Wasserstoffgas H zum reinen Element reduziert werden kann. Das solcherart komplexgebundene metastabile Isotop Tc geht mit einer Halbwertszeit von nur sechs Stunden durch Aussendung von Gammastrahlung in den Grundzustand Tc über:

Es ist diese Strahlung, die in der medizinischen Diagnostik genutzt wird.

Daneben entstehen pro Jahr in Atomreaktoren mehrere Tonnen Technetium aus der Spaltung des Uranisotops U; sie haben an allen Spaltprodukten eines abgebrannten Brennelements einen Anteil von etwa 6 %. Die bis zu Beginn des 21. Jahrhunderts künstlich hergestellte Gesamtmenge des Metalls liegt bei mehr als 78 Tonnen und damit weit über den natürlichen Technetiumvorkommen.

Der größte Teil des reaktorproduzierten Metalls bildet nur unerwünschten radioaktiven Abfall. Bei seiner Lagerung muss das mit einer Halbwertszeit von mehr als 200.000 Jahren recht langlebige Isotop Tc berücksichtigt werden, das in der Zeit zwischen etwa 10.000 und etwa 1.000.000 Jahren nach seiner Erzeugung die dominante Strahlungsquelle darstellt. Zur Entsorgung werden in erster Linie als stabil angesehene geologische Formationen wie Salzstöcke in Betracht gezogen; Kritiker äußern allerdings die Befürchtung, dass das Element dennoch durch Wasser in die Umgebung ausgewaschen werden könnte. Daneben wird auch die Möglichkeit der Transmutation, der Umwandlung des Metalls in andere Elemente durch Neutronenbeschuss, erwogen.

Zur kommerziellen Verwendung wird Technetium im Kilogramm-Maßstab in Wiederaufarbeitungsanlagen aus abgebrannten Nuklearbrennstäben gewonnen. Dazu wird es zunächst zu Pertechnetat TcO oxidiert und dann nach einer Abklingzeit von mehreren Jahren in gelöster Form durch Extraktion und Ionenaustauschverfahren von Uran-, Plutonium- und anderen Verbindungen getrennt. Die Produkte Ammoniumpertechnetat NHTcO oder auch Ammoniumtechnetiumhexachlorid (NH)TcCl können dann bei hohen Temperaturen durch thermische Zersetzung in Wasserstoffgas H zu elementarem Technetium reduziert werden. Alternativ kann das Metall durch Elektrolyse von Ammoniumpertechnetat in mit Wasserstoffperoxid (HO) angereicherter Schwefelsäure (HSO) gewonnen werden.

Technetium ist ein radioaktives Metall, das in der häufigen Pulverform mattgrau erscheint. Als makroskopischer Festkörper hat es dagegen eine silbergraue Farbe und ähnelt dadurch dem Element Platin. Charakteristische Spektrallinien der Technetiumatome liegen bei 363, 403, 410, 426, 430 und 485 Nanometern.

Sowohl der Schmelz- als auch der Siedepunkt von jeweils 2157 und 4265 °C liegen zwischen den entsprechenden Werten der Gruppennachbarn Mangan und Rhenium. Technetium kristallisiert im hexagonalen Kristallsystem (hexagonal-dichteste Kugelpackung, Magnesium-Typ) in der mit den Gitterparametern a = 275,3 pm und c = 440 pm sowie zwei Formeleinheiten pro Elementarzelle.

Metallisches Technetium ist leicht paramagnetisch, das heißt seine magnetische Suszeptibilität Χ ist positiv, die magnetischen Dipole im Inneren des Materials richten sich parallel zu einem externen Magnetfeld aus und die Substanz wird in selbiges hineingezogen. Bei Temperaturen unterhalb von 7,7 Kelvin ist das reine Element ein Supraleiter 2. Art, verliert also seinen elektrischen Widerstand; schon kleinste Verunreinigungen heben diese Temperatur allerdings auf 11,2 Kelvin an. Die Eindringtiefe magnetischer Felder im supraleitenden Zustand ist für Technetium nach Niob die zweitgrößte aller Metalle. Kernspinresonanz-Untersuchungen mit Technetium sind aufgrund der hohen Empfindlichkeit des Isotops Tc möglich.

Technetium liegt im Periodensystem in seiner Gruppe zwischen den beiden Elementen Mangan und Rhenium, ähnelt in seinen chemischen Eigenschaften jedoch nur dem letzteren.

Das Technetium-Atom besitzt sieben Valenzelektronen, eins davon im 5s-Orbital, die restlichen sechs im 4d-Orbital, die maximale Oxidationsstufe beträgt daher +VII. Die ersten drei Ionisierungsenergien von 702, 1472 und 2850 Kilojoule pro Mol (kJ/mol) liegen allesamt unter den entsprechenden Werten des leichteren Gruppennachbarn Mangan, was sich qualitativ auf den größeren Abstand der Valenzelektronen zum Kern und ihre dadurch verminderte elektrische Wechselwirkungsenergie zurückführen lässt. Insbesondere ist die Differenz zwischen zweiter und dritter Ionisationsenergie von 1378 kJ/mol bedeutend geringer als die des Mangans von 1739 kJ/mol. Anders als dieses Element, dessen Chemie daher im Wesentlichen die des "zweifach" positiv geladenen Mn-Ions ist, findet man Technetium häufig in anderen Oxidationsstufen. Die wichtigsten sind +IV, +V und +VII, daneben findet man Verbindungen, in denen Technetium die Oxidationszahlen −I, 0, +I, +III oder +VI einnimmt, während der für Mangan so charakteristische +II-Zustand nur selten auftritt.

In feuchter Luft läuft das Metall durch Oxidation langsam an. Die Pulverform ist nicht nur brennbar, sondern allgemein reaktiver und verbindet sich heftig mit Halogenen. Technetium löst sich nur in oxidierenden Säuren wie konzentrierter Schwefelsäure (HSO) oder Salpetersäure (HNO), nicht jedoch in Salzsäure (HCl) oder Flusssäure (HF); in gasförmigem Chlor- und Fluorwasserstoff ist das Metall beständig.

Von Technetium sind bisher 34 Isotope bekannt, deren Massenzahlen zwischen 85 und 118 liegen. Das langlebigste davon ist mit einer Halbwertszeit von 4,2 Millionen Jahren Tc, gefolgt von Tc mit einer Halbwertszeit von 2,6 Millionen Jahren und Tc mit einer Halbwertszeit von 211.100 Jahren. Letzteres ist zugleich das häufigste und ökonomisch wichtigste Isotop und setzt mit einer Aktivität von 620 Millionen Becquerel pro Gramm eine weiche Betastrahlung der Energie 293,6 Kiloelektronenvolt (keV) frei.

Der Zerfallsmechanismus bei den Isotopen mit Massenzahlen unterhalb von 98 ist der Elektroneneinfang, so dass Molybdän-Isotope entstehen; bei schwereren Technetium-Isotopen kommt es dagegen zum Betazerfall und zur Bildung von Ruthenium-Isotopen. Eine Ausnahme stellt lediglich Tc dar, das über beide Zerfallswege in ein anderes Element übergehen kann.

Neben den durch ihre Neutronenzahl unterschiedenen Isotopen existiert eine Reihe angeregter, "metastabiler" Zustände wie Tc, Tc und Tc, die mit Halbwertszeiten von (in dieser Reihenfolge) 61 Tagen, 90 Tagen und 6,01 Stunden in den zugehörigen Grundzustand übergehen. Das wichtigste metastabile Isotop ist Tc, das eine große Rolle in der Nuklearmedizin spielt.

Die Instabilität des Technetiums lässt sich kernphysikalisch damit erklären, dass seine Ordnungszahl ungerade ist und die benachbarten Elemente Molybdän und Ruthenium sehr viele stabile Isotope haben (Mattauchsche Isobarenregel).

Nur geringe Mengen Technetium werden wirtschaftlich genutzt; der größte Anteil kommt in der Medizin als Bestandteil von Radiopharmaka zur Anwendung, es findet jedoch auch als Korrosionsschutz und als Betastrahlenquelle Verwendung.

Metastabiles Tc ist aufgrund seiner kurzen Halbwertszeit, der emittierten Gammastrahlung mit einer Energie von 140 keV und seiner Fähigkeit, sich an viele aktive Biomoleküle anzulagern, das bei weitem wichtigste, als Tracer für szintigrafische, also bildererstellende nuklearmedizinische Untersuchungen eingesetzte Nuklid. Dazu werden organische Liganden mit einer hohen Neigung, sich an Zellen des zu untersuchenden Organs zu binden, oder monoklonale Antikörper, Proteine des Immunsystems, die sich an ausgewählte Antigene von Tumorzellen heften, an Technetium gekoppelt und intravenös in den Blutkreislauf des Patienten gespritzt. Das Metall konzentriert sich auf diese Weise in den gewünschten Organen und Geweben oder dem zu untersuchenden Tumor; die charakteristische Gammastrahlung kann dann durch mit Thallium dotierte Natriumiodid-Detektoren registriert und zur nicht-invasiven Diagnose, etwa des durch die Antikörper markierten Tumors, herangezogen werden. Auf diese Weise können das Gehirn, die Schilddrüse, die Lungen, die Leber, die Gallenblase, die Milz, die Nieren, Knochengewebe, aber auch schwer zugängliche Teile des Darms untersucht werden. Die Kopplung von Technetium-Zinn-Verbindungen an Erythrozyten, die roten Blutkörperchen, ermöglicht eine Diagnose von Erkrankungen des Blutgefäßsystems; Bindung von Technetium-Pyrophosphaten an Calciumablagerungen des Herzmuskelgewebes wird bei der Diagnose von Herzinfarkt-Patienten eingesetzt.

Die von Tc emittierte energiereiche Gammastrahlung ermöglicht eine niedrige Dosierung. Nach der Untersuchung wird der größte Teil des bei einer nuklearmedizinischen Diagnose aufgenommenen Technetiums wieder ausgeschieden. Das verbliebene Tc zerfällt schnell in Tc. Dieses besitzt eine lange Halbwertszeit von 212.000 Jahren und trägt wegen der relativ weichen Betastrahlung, die bei seinem Zerfall frei wird, nur zu einer geringen zusätzlichen Strahlenbelastung über die restliche Lebenszeit bei. In den USA werden für Diagnose-Zwecke pro Jahr etwa sieben Millionen Einzeldosen Tc verabreicht.

Technetium für nuklearmedizinische Zwecke wird – aufgrund der kurzen 6-Stunden-Halbwertszeit – in der Regel aus Technetium-99m-Generatoren gewonnen. Allerdings gibt es auf der Welt nur fünf Reaktoren, in denen Molybdän-99 als Mutternuklid des Technetium-99 gewonnen wird (drei in Europa, einer in Südafrika und einer in Kanada). Wegen des großen Alters der meisten dieser Reaktoren und der damit verbundenen technischen Probleme ist es in letzter Zeit zu mehreren Ausfällen einiger Reaktoren gekommen, was die Produktion von Technetium stark eingeschränkt hat. Mittlerweile (Mai 2010) befürchtet man in der Nuklearmedizin, dass es infolge dieser Reaktorprobleme bald zu einer gravierenden Verknappung des für die Tumordiagnose wichtigen Isotops kommen kann.

Das nicht-angeregte Isotop Tc selbst wird als wirtschaftlich gut nutzbare Quelle für Betastrahlen eingesetzt. Es bietet den Vorteil, dass bei seinem Zerfall keinerlei Gammastrahlung auftritt, so dass nur relativ geringe Sicherheitsvorkehrungen notwendig sind.

Daneben ist Technetium in Form seiner Salze eines der besten Rostschutzmittel: Ammonium- oder Kaliumpertechnetat könnte als Korrosionsschutz für Stahl Anwendung finden. Ein Zusatz von 55 ppm (Millionstel Teilen) Kaliumpertechnetat (KTcO) in belüftetem entionisiertem Wasser schützt dieses Material bis zu einer Temperatur von 250 °C vor Korrosion. Wegen der Radioaktivität von Technetium ist eine potentielle Anwendung allerdings auf von der Umwelt abgeschlossene Systeme wie etwa Siedewasserreaktoren beschränkt.

Pertechnate dienen als wichtige Ausgangsstoffe der Technetiumchemie und spielen auch als Katalysatoren in der anorganischen Chemie eine gewisse Rolle.

Technetium bildet im Gegensatz zu Mangan kaum Kationen. Es ähnelt darin, wie auch in seiner geringeren Reaktivität und in der Fähigkeit, kovalente Bindungen einzugehen, seinem anderen Gruppennachbarn Rhenium. Im Gegensatz zu diesem sind die hohen Oxidationszustände allerdings etwas unbeständiger gegenüber Reduktion, dem Übergang in einen niedrigeren Oxidationszustand durch (formale) Aufnahme von Elektronen.

Bei der Reaktion von Technetium mit Wasserstoff entsteht der anionische, also negativ geladene Hydridokomplex [TcH], dessen zentrales Technetiumatom wie nebenstehend zu sehen in einem trigonalen Prisma aus Wasserstoffatomen liegt; lotrecht über dem Mittelpunkt der drei Seitenflächen befindet sich zudem je ein weiteres Wasserstoffatom. Der Ladungsausgleich kann zum Beispiel durch je zwei Natrium- (Na) oder Kalium-Ionen (K) erfolgen.

Es existieren zwei verschiedene Technetiumoxide (TcO und TcO). Bei Temperaturen von etwa 400–450 °C reagiert das Metall direkt mit Sauerstoff zu blassgelbem Ditechnetiumheptoxid:

Das Molekül besteht aus zwei über ein Sauerstoffatom miteinander verbundenen Technetiumatomen, die ihrerseits durch je drei Doppelbindungen an die verbleibenden Sauerstoffatome gebunden sind und ist das Anhydrid der Pertechnetiumsäure HTcO, die sich bei Lösung des Oxids in Wasser bildet. 

Das schwarze Technetiumdioxid (TcO) lässt sich durch Reduktion von Ditechnetiumheptoxid mit elementarem Technetium oder Wasserstoff darstellen.

Pertechnetiumsäure (HTcO) bildet sich, wenn Technetiumheptoxid in Wasser oder Technetium in oxidierenden Säuren wie Salpetersäure, konzentrierter Schwefelsäure oder Königswasser, einem Salpetersäure-Salzsäure-Gemisch, gelöst wird. Die dunkelrote, wasseranziehende (hygroskopische) Substanz zählt zu den starken Säuren und liegt in Wasser stark dissoziiert vor, das Proton ist also fast immer auf ein Wassermolekül übertragen.

Das verbliebene Pertechnetat-Anion TcO besteht aus einem Technetium-Atom, das im Zentrum eines Tetraeders liegt, an dessen vier Ecken die Sauerstoffatome sitzen. Es ist im Gegensatz zum Permanganat-Ion MnO verhältnismäßig reduktionsstabil, so dass die farblosen Salze wie Kalium- (KTcO) oder Ammoniumpertechnetat (NHTcO) nur relativ schwache Oxidationsmittel sind. Natrium-, Magnesium- und Calciumpertechnat sind gut, Barium- und Ammoniumpertechnat moderat, Kalium- sowie Thalliumpertechnat dagegen nur geringfügig wasserlöslich.

Durch Reduktionsmittel kann Pertechnetat zum Technetat [TcO] (purpurfarben) reduziert werden.

Neben den Technetiumhalogeniden, in denen Technetium an Halogenatome gebunden ist, sind zahlreiche Technetiumoxidhalogenide bekannt, in denen neben den Halogenatomen zusätzlich noch Sauerstoff gebunden ist.

Durch direkte Reaktion der Ausgangsstoffe entstehen die beiden Fluor-Verbindungen, das gelbe Technetiumpentafluorid (TcF) und das gleichfarbige Technetiumhexafluorid (TcF). Ebenfalls direkt synthetisieren lassen sich die beiden Chlor-Verbindungen, das grüne Technetiumhexachlorid (TcCl) und das rote Technetiumtetrachlorid (TcCl). Letzteres ist paramagnetisch und liegt in polymerisierter Form, also als Kette aneinandergereihter TcCl-Untereinheiten vor und lässt sich auch durch Reaktion von Technetiumheptoxid (TcO) mit Tetrachlormethan (CCl) darstellen. Wichtige Technetiumhalogenid-Salze werden von den beiden Anionen [TcCl] und [TcCl] gebildet. Die wichtigste Bromverbindung ist das rotbraune Technetiumtetrabromid TcBr, daneben existiert das Anion [TcBr].

Die Technetiumoxidhalogenide sind für Fluor die Verbindungen Technetiumfluoridtrioxid TcOF, Technetiumtrifluoriddioxid TcOF, Technetiumpentafluoridoxid TcOF und Technetiumtetrafluoridoxid TcOF, in denen das Metall in den Oxidationsstufen +VII und +VI auftritt, für Chlor die Verbindungen Technetiumchloridtrioxid TcOCl, Technetiumtetrachloridoxid TcOCl und Technetiumtrichloridoxid TcOCl mit den Oxidationsstufen +VII, +VI und +V und für Brom und Iod die einander analogen Verbindungen Technetiumbromidtrioxid TcOBr und Technetiumiodidtrioxid TcOI. Bei letzteren Substanzen nimmt das zentrale Technetiumatom die maximale Oxidationszahl +VII an. Technetiumtrifluoriddioxid TcOF liegt ebenso wie Technetiumtrichloridoxid TcOCl und Technetiumtribromidoxid TcOBr in polymerisierter Form vor.

Alle Halogen-Sauerstoff-Verbindungen des Technetiums zersetzen sich bei Kontakt mit Wasser leicht zu Pertechnetat und Technetiumdioxid. Insbesondere hoch fluorierte Verbindungen wie Technetiumpentafluoridoxid TcOF lassen sich nur durch starke Fluorierungsmittel wie Xenonhexafluorid XeF oder Kryptondifluorid KrF darstellen, wie die folgenden Reaktionsschritte exemplarisch zeigen:




Mit Schwefel bildet Technetium zwei verschiedene Sulfide. Während Technetiumdisulfid TcS durch direkte Reaktion der Ausgangsstoffe entsteht, kann das schwarze Ditechnetiumheptasulfid TcS wie folgt dargestellt werden:

Technetium wird in diesem Fall "nicht" reduziert, anders als bei der analogen Reaktion des Mangans, bei dem sich aus MnO das stabile Mn-Ion bildet. Thermische Zersetzung des Heptasulfids führt zu einer Aufspaltung in das Disulfid und elementaren Schwefel:

Mit Selen und Tellur bildet Technetium die analogen Substanzen zu Technetiumdisulfid, also Technetiumdiselenid (TcSe) und Technetiumditellurid (TcTe).

Es existieren zwei wichtige Technetium-Cluster, der Tc- und der Tc-Cluster. In beiden sind jeweils zwei Technetiumatome durch eine Dreifachbindung miteinander verbunden. Diese Paare sind parallel zueinander angeordnet und senkrecht zur Ausrichtung der Dreifachbindung aneinander gebunden, so dass sich durch die Lage der Einfachbindungen für den Tc-Cluster zwei parallele gleichseitige Dreiecke und für den Tc-Cluster zwei parallele Quadrate ergeben. Im letzteren Fall ist je eine zusätzliche Einfachbindung entlang einer Diagonale dieser Quadrate ausgerichtet. Technetiumatome beider Cluster gehen allesamt sechs Bindungen ein; fehlende Bindungen können etwa durch Halogenatome wie Chlor oder Brom abgesättigt werden.

Technetium ist Bestandteil zahlreicher Komplexverbindungen, die aufgrund der Bedeutung des Elements für die Nuklearmedizin verhältnismäßig gut erforscht sind.

Ein Beispiel ist der Technetium-Carbonyl-Komplex Tc(CO), der einen weißen Feststoff bildet. In ihm liegen zwei schwach aneinander gebundene Technetium-Atome vor, die wie nebenstehend zu sehen in Oktaeder-Symmetrie von je fünf Carbonyl-Liganden umgeben sind. Die Bindungslänge von 303 pm ist charakteristischerweise größer als der Abstand zweier benachbarter Atome im metallischen Technetium. Isostrukturelle Komplexe, also solche von gleicher Struktur, finden sich auch bei den beiden Nachbarelementen Mangan und Rhenium. Ein Technetium-Carbonyl-Komplex, in dem Technetium in der negativen Oxidationsstufe −I auftritt, ist [Tc(CO)], während sich in Wasser der oktaedrische Aquakomplex [Tc(HO)(CO)] bildet.

Ein Beispiel für einen Komplex mit einem organischen Liganden, der in bildgebenden Verfahren der Nuklearmedizin zum praktischen Einsatz kommt, ist nebenstehend angegeben und zeichnet sich durch ein im Zentrum einer Kohlenstoff-Stickstoff-Kette gelegenes und über vier Stickstoffatome angebundenes Technetiumatom aus, das durch eine Doppelbindung mit einem Sauerstoffatom gebunden ist. Diese Technetium-Sauerstoffeinheit kann in den so genannten Nitridokomplexen durch eine Technetium-Stickstoffeinheit ersetzt sein, in der eine Dreifachbindung zwischen einem Stickstoff- und einem Technetiumatom besteht.

Einstufungen nach der CLP-Verordnung liegen nicht vor, weil diese nur die chemische Gefährlichkeit umfassen und eine untergeordnete Rolle gegenüber den auf der Radioaktivität beruhenden Gefahren spielen. Auch Letzteres gilt nur, wenn es sich um eine dafür relevante Stoffmenge handelt.

Technetium hat nach bisher vorliegenden Erkenntnissen nur eine geringe chemische Toxizität. Alle Isotope des Elements sind jedoch wie angesprochen radioaktiv und müssen entsprechend ihrer Strahlungsintensität in Strahlenschutzbehältern aufbewahrt und als radioaktives Material gekennzeichnet werden. Die Betastrahlung des häufigsten Isotops, Tc, wird bereits durch Glas aufgehalten; die Strahlenbelastung durch die dabei als Bremsstrahlung freiwerdende weiche Röntgenstrahlung gilt als gering, wenn ein Sicherheitsabstand von 30 Zentimetern eingehalten wird. Eingeatmeter Technetium-Staub, der sich in den Lungen festsetzt, trägt hingegen zu einem höheren Risiko für Krebserkrankungen bei. Laborarbeiten müssen daher unter einer Abzugshaube stattfinden; daneben werden Augenschutz und das Tragen von Handschuhen empfohlen.



</doc>
<doc id="5046" url="https://de.wikipedia.org/wiki?curid=5046" title="Tellur">
Tellur

Tellur [] (lat. "tellus" „Erde“) ist ein seltenes chemisches Element mit dem Elementsymbol Te und der Ordnungszahl 52. Im Periodensystem steht es in der sechsten Hauptgruppe, bzw. der 16. IUPAC-Gruppe, und 5. Periode und zählt damit zu den Chalkogenen. Seine Häufigkeit entspricht ungefähr der von Gold, mit dem es auch verschiedene Verbindungen eingeht, die in der Natur als Minerale auftreten. Kristallines Tellur ist ein silberweißes, metallisch glänzendes Halbmetall, das im Aussehen Zinn und Antimon ähnelt. Es reagiert spröde auf mechanische Belastung und kann daher leicht pulverisiert werden. In chemischen Verbindungen mit Nichtmetallen steht es in seinem Verhalten Schwefel und Selen nahe, in Legierungen und intermetallischen Verbindungen zeigt es jedoch sehr ausgeprägte (halb-)metallische Eigenschaften.

Tellur wurde 1782 von dem österreichischen Chemiker und Mineralogen Franz Joseph Müller von Reichenstein (1740–1825) bei Untersuchungen von Gold-Erzen aus der Grube Mariahilf am Berg Faczebaja bei Zlatna (dt. "Klein Schlatten", ung. "Zalatna") nahe Sibiu (dt. Hermannstadt, Siebenbürgen, Rumänien) entdeckt, die eine geringere Goldausbeute als erwartet erbrachten. Er war durch die wissenschaftliche Abhandlung "Nachricht vom gediegenen Spiesglaskönig in Siebenbürgen" von Ignaz von Born (1742–1791) auf die Erze aufmerksam geworden. "Spiesglaskönig" bezeichnet gediegenes Antimon, "Spiesglas" ist eine alte Bezeichnung für das Mineral Antimonit ("Stibnit, Grauspießglanz" SbS). Von Born hielt das gediegene Metall in den Golderzen für Antimon und führte die geringe Ausbeute auf eine Verbindung des Goldes mit Antimon zurück. Müller von Reichenstein widersprach dieser Ansicht und hielt es zunächst für „"geschwefelten Wismuth"“. Nach weiteren Untersuchungen, deren Ergebnisse er zwischen 1783 und 1785 in einer vierteiligen Abhandlung publizierte, schloss er jedoch auch Bismut aus, da das Metall, im Gegensatz zu Antimon und Bismut, praktisch nicht mit Schwefelsäure reagierte. Er verlieh der metallischen Phase den Namen "metallum problematicum" (auch "aurum problematicum" beziehungsweise "aurum paradoxum"). Nach heutiger Erkenntnis besteht es neben gediegenem Tellur aus den Mineralen Nagyágit ("Blättererz", AuPb(Pb,Sb,Bi)TeS) und Sylvanit ("Schrifttellur", (Au,Ag)Te). Müller von Reichenstein vermutete, dass "metallum problematicum" „…vielleicht ein neues bisher noch nicht gekanntes Halbmetall seye?“, wollte seine Befunde jedoch erst von dem schwedischen Mineralogen und Chemiker Torben Olof Bergman (1735–1784) bestätigen lassen. Im Jahr 1783 schickte er Proben des Erzes zur Begutachtung an Bergman, jedoch erhielt er keine definitiven Antworten. Bergman verstarb 1784 und die Untersuchungen an "metallum problematicum" wurden 1785 vorerst eingestellt.

Erst zwölf Jahre später, im Jahr 1797, erhielt Martin Heinrich Klaproth (1743–1817) in Berlin Proben der Erze von Müller von Reichenstein. Klaproth bekräftigte die Schlussfolgerungen aus Müller von Reichensteins Untersuchungen und sah genügend Hinweise für die Entdeckung eines neuen Elements. Im Januar 1798 würdigte Klaproth die Verdienste Müller von Reichensteins in einem Vortrag und schrieb ihm die Entdeckung des neuen Elements zu. Da Müller von Reichenstein dem Element keinen Namen gegeben hatte, entschied sich Klaproth für den Namen "Tellur" (lat. "tellus": „Erde“):

Die originalen Handstücke des Probenmaterials von der Typlokalität Zlatna, das Klaproth zur Verfügung hatte, befinden sich heute im Museum für Naturkunde in Berlin.

Unabhängig von Müller von Reichenstein und Klaproth entdeckte 1789 der ungarische Chemiker und Botaniker Paul Kitaibel (1757–1817) das Tellur bei Untersuchungen von Golderzen aus dem Bergbauort Nagybörzsöny (Deutsch-Pilsen) in Ungarn. Klaproth erwähnte in seinem veröffentlichten Vortrag jedoch nur Müller von Reichenstein, obwohl er seit 1796 durch ein Manuskript Kitaibels auch Kenntnis von seinen Untersuchungen hatte. In einem Brief an Kitaibel erklärte Klaproth, der Inhalt des Manuskripts sei ihm entfallen und er habe bei den Untersuchungen der Erze Müller von Reichensteins keinen Zusammenhang mit seiner Arbeit gesehen. Klaproth überzeugte Kitaibel schließlich, dass die Entdeckung des Tellurs allein Müller von Reichenstein zugeschrieben werden sollte, da dieser bereits einige Jahre früher dieselben Beobachtungen an dem neuen Element machte.

Das Elementsymbol „Te“ wurde 1814 von Jöns Jakob Berzelius (1779–1848) vorgeschlagen und wird bis heute verwendet. Die erste Strukturaufklärung von kristallinem Tellur mit Hilfe der Röntgenbeugung erfolgte 1924.

Tellur ist ein selten vorkommendes Element; sein Anteil an der Erdkruste beträgt ca. 0,01 ppm (g/t). Mit Gold, untergeordnet auch mit Silber, Kupfer, Blei und Bismut sowie den Platinmetallen kommt es selten gediegen, also in elementarer Form in der Natur, vor.

Gediegen Tellur gehört als Mineral zur Gruppe der Elemente, genauer der Halb- und Nichtmetalle und wird in der Systematik der Minerale nach Strunz unter der Nummer I/B.03-40 (8. Auflage) bzw. 1.CC.10 (9. Auflage), und nach Dana unter der Nummer 1.3.4.2 geführt.

Spuren bis hin zu größeren Mengen an Selen können in gediegen Tellur enthalten sein ("Selentellur"). Obwohl es sich bei Tellur um ein seltenes Element handelt, ist eine relativ große Anzahl von Mineralen bekannt, denn Tellur bildet eigene Minerale, weil es nur selten in Sulfiden oder Seleniden beziehungsweise Sulfaten oder Selenaten eingebaut wird; für diese Kristallgitter der leichteren Homologen ist es zu groß. Umgekehrt dagegen vertreten die beiden leichteren Homologen häufiger das Tellur auf seinen Gitterplätzen in Kristallstrukturen tellurhaltiger Minerale.

Tellur zeigt von allen Elementen die höchste Affinität zu Gold und findet sich daher in der Natur häufig in Form von Gold-Telluriden, Mineralen mit Tellurid- (Te) beziehungsweise Ditellurid-Anionen (Te). Neben Gold und anderen Edelmetallen bilden vor allem Blei und Bismut weitere natürliche Telluride, oft begleitend (Paragenesen) zu den gediegenen Metallen und Gold-Erzen.

Seltener sind Minerale mit Te-Kationen in der Kristallstruktur, wobei auch das wichtigste Oxid des Tellurs, das Tellurdioxid TeO in zwei Modifikationen als orthorhombischer "Tellurit" und tetragonaler "Paratellurit" in der Natur auftritt. Bei den weiteren Mineralen mit Tellur(IV)-Kationen handelt es sich um Oxotellurate(IV) ("Tellurite"), die komplexe [TeO]- oder [TeO]-Anionen enthalten. Minerale mit Te-Kationen in Form von oktaedrischen [TeO]-Komplexanionen sind äußerst selten, es sind 21 Minerale bekannt, die größtenteils Kupfer und Blei enthalten. Neben den genannten Mineralen existieren in der Natur auch gemischtvalente Tellurminerale, darunter das Calcium-Oxotellurat(IV,VI) Carlfriesit CaTeO mit einem Te:Te-Verhältnis von 2:1. Bei den Mineralen mit Te und Te-Kationen handelt es sich um Sekundärminerale, die aus der Verwitterung von gediegen Tellur und Telluriden entstanden sind.

Tellurhaltige Minerale sind für die technische Gewinnung von Tellur ohne Bedeutung, da sie zu selten vorkommen und praktisch keine abbauwürdigen Lagerstätten existieren. Zu den bekannten Fundorten von gediegen Tellur beziehungsweise tellurhaltiger Minerale zählen neben der Typlokalität Zlatna (Siebenbürgen, Rumänien) auch Moctezuma (Mexiko), Cripple Creek (Colorado), Kalgoorlie (Australien) und Calaveras (Kalifornien). Bisher (Stand: 2012) sind 154 tellurhaltige Minerale bekannt, von denen allerdings fünf (Dilithium, Imgreit, Kurilit, Sztrokayit, Protojoseit) bisher noch nicht von der International Mineralogical Association (IMA) als eigenständige Minerale anerkannt bzw. als solche diskreditiert wurden. Eine Auswahl bekannter Minerale mit Tellur in verschiedenen Oxidationsstufen ist in der nachfolgenden Tabelle dargestellt.

Tellur wird zusammen mit Selen industriell ausschließlich aus Nebenprodukten der großtechnischen elektrolytischen Kupfer- und Nickel-Herstellung gewonnen. In den anfallenden Anodenschlämmen sind wasserunlösliche Edelmetall-Telluride und -Selenide der allgemeinen Formel MCh (M = Cu, Ag, Au; Ch = Se, Te) enthalten, die bei Temperaturen oberhalb 500 °C unter Luftsauerstoff (O) mit Soda (Natriumcarbonat NaCO) zur Reaktion gebracht werden. Die Edelmetall-Kationen (M) werden dabei zu elementaren Metallen (M) reduziert, die Tellurid-Anionen zu Oxotelluraten(IV) (TeO) oxidiert:

Alternativ kann diese Umsetzung auch mit Salpeter (Natriumnitrat NaNO) unter Luftausschluss und Bildung von Stickoxiden (NO und NO) erfolgen:

Das entstandene Natriumtellurat(IV) NaTeO wird anschließend in Wasser gelöst, wo es basisch reagiert und Hydrogentellurat(IV)-Ionen HTeO bildet. Die Abtrennung der Tellurate(IV) von den ebenfalls entstandenen Selenaten(IV) in der basischen Lösung erfolgt durch Neutralisation unter Zugabe von Schwefelsäure (HSO), wodurch in Wasser nahezu unlösliches Tellurdioxid TeO ausfällt:

Das Tellurdioxid kann entweder in Laugen durch Elektrolyse oder auf chemischem Weg durch Lösung in konzentrierten Mineralsäuren und Einleitung von Schwefeldioxid SO zu elementarem Tellur reduziert werden, wobei der Schwefel aus den SO-Molekülen (bzw. den daraus in der Lösung gebildeten Sulfit-Ionen SO) oxidiert wird und Sulfat-Ionen (SO) entstehen:

Zur Gewinnung von hochreinem Tellur (> 99,9 %) wird das Zonenschmelzverfahren angewendet.

Die Weltjahresproduktion von Tellur lag in den Jahren 2011 bis 2015 bei durchschnittlich 155,8 Tonnen pro Jahr (t/a). Zu den Hauptproduzenten zählen die USA (50 t/a), Japan (∅ 37,4 t/a), Russland (∅ 33 t/a), Schweden (∅ 19 t/a), Kanada (∅ 9,4 t/a) und China (∅ 7 t/a). Eine Übersicht der Produktionsmengen der einzelnen Länder ist in der Tabelle dargestellt. Weitere Industrienationen wie Deutschland und Belgien produzieren wahrscheinlich ebenfalls Tellur, es liegen jedoch keine Zahlen vor. Der United States Geological Survey (USGS) schätzt die weltweit verfügbaren Reserven von Tellur im Jahr 2018 auf rund 31.000 Tonnen.

Bei Standardbedingungen ist von Tellur nur eine kristalline Modifikation (Te-I oder α-Te) bekannt, die als "kristallines" oder "metallisches" Tellur bezeichnet wird. Es ist isotyp zu α-Selen, das heißt, es hat die gleiche Kristallstruktur. Tellur kristallisiert im trigonalen Kristallsystem in der Raumgruppe  mit den Gitterparametern "a" = 446 pm und "c" = 592 pm und drei Formeleinheiten in der Elementarzelle (kleinste Baueinheit der Kristallstruktur).

Die nach der Hermann-Mauguin-Symbolik beschriebene Raumgruppe  erläutert die Zentrierung der Elementarzelle sowie die vorhandenen Symmetrieelemente. "P" bedeutet, dass das Bravais-Gitter "primitiv" ist. Auf die Angabe der Zentrierung folgen die vorhandenen Symmetrieelemente der Raumgruppe: 3 beschreibt eine dreizählige Schraubenachse (Vervielfältigung eines Teilchens durch Drehung um 120° und Verschiebung (Translation) um / in Richtung der Drehachse) parallel zur kristallographischen c-Achse ([001]), 2 beschreibt eine zweizählige Drehachse (Vervielfältigung durch Drehung um 180°) parallel zu den drei kristallographischen a-Achsen (<100>), 1 das Symmetrieelement der einzähligen Symmetrieachse oder Identität (Vervielfältigung durch Drehung um 360°, das Teilchen bildet sich also auf sich selbst ab) in Richtung senkrecht zu den a-Achsen und der c-Achse (<120>).

Die Kristallstruktur enthält nur ein kristallographisch unterscheidbares Telluratom mit den Lagekoordinaten x = 0,2636, y = 0 und z = /. Alle weiteren Atome der Kristallstruktur können durch die vorhandenen Symmetrieelemente der Raumgruppe auf dieses eine Atom zurückgeführt werden. Da das Telluratom in seiner Lage mit der zweizähligen Symmetrieachse der Raumgruppe () zusammenfällt, wird es ausschließlich durch die dreizählige Schraubenachse (3) vervielfältigt. Dadurch entstehen spiralförmige Ketten aus kovalent gebundenen Telluratomen parallel zur c-Achse. Die Telluratome sind innerhalb der Kette 284 pm voneinander entfernt, der Bindungswinkel beträgt 103,1°. Die Bindungen innerhalb der Kette sind in den Abbildungen rot hervorgehoben, jeweils eine Kette ist zur Verdeutlichung blau dargestellt, wobei sich das dunkelblaue Atom auf z = /, das mittelblaue auf z = / und das hellblaue auf z = 1 beziehungsweise z = 0 befindet. Jedes dritte Atom innerhalb der Kette ist also deckungsgleich. Jede Kette wird von sechs weiteren Ketten umgeben. Zwischen den Ketten existieren Van-der-Waals-Bindungen mit Te-Te-Abständen von 349 pm (grün gestrichelt), die durch die Unterschreitung des Van-der-Waals-Radius (2 · 206 pm = 412 pm) der Telluratome zustande kommen. Für ein einzelnes Telluratom ergibt sich dabei eine Koordinationszahl von 6, genauer 2+4, da 2 Atome aus der gleichen Kette stammen und damit einen geringeren Abstand als die weiteren 4 aus Nachbarketten aufweisen. Als Koordinationspolyeder ergibt sich damit ein verzerrtes Oktaeder (gelb hervorgehoben).

Tellur kann auch in der Raumgruppe  statt kristallisieren. Die 3-Schraubenachse vervielfältigt ein Atom ebenfalls durch Drehung um 120°, anschließend wird es jedoch um / statt / in Richtung der Drehachse verschoben. Dadurch entstehen ebenfalls spiralförmige Ketten, die sich jedoch im Uhrzeigersinn statt im Gegenuhrzeigersinn (bei der 3-Schraubenachse) entlang der c-Achse winden. Die Kristallstruktur in der Raumgruppe  („Linksform“) ist somit das Spiegelbild der Struktur in der Raumgruppe  („Rechtsform“). Das Auftreten von spiegelbildlichen Kristallformen wird in der Kristallographie als Enantiomorphie bezeichnet.

Das Kristallsystem von Tellur wird oft als hexagonal angegeben. Dem hexagonalen und trigonalen Kristallsystem liegt die gleiche Elementarzelle zugrunde, jedoch würde eine hexagonale Symmetrie das Vorhandensein einer sechszähligen Symmetrieachse (6, Vervielfältigung eines Teilchens durch Drehung um 60°) voraussetzen. Die Kristallstruktur von Tellur beinhaltet jedoch nur die dreizählige Schraubenachse (3) und gehört damit zweifelsfrei in das niedriger symmetrische trigonale Kristallsystem.

In Hochdruckexperimenten mit kristallinem Tellur (Te-I oder α-Tellur) wurden weitere Modifikationen entdeckt. Die angegebenen Druckbereiche für die Stabilität der Modifikationen variieren zum Teil in der Literatur:

Die unbeständige amorphe Modifikation ist ein braunes Pulver und kann aus Telluriger Säure (HTeO) durch Reaktion mit Schwefliger Säure (HSO) beziehungsweise Sulfit-Ionen (SO) dargestellt werden. Die Sulfit-Ionen werden dabei zu Sulfat-Ionen (SO) oxidiert während die Te-Kationen zu elementarem Tellur reduziert werden:
Amorphes Tellur wandelt sich unter Standardbedingungen langsam in die kristalline Modifikation um.

Kristallines Tellur ist ein intrinsischer direkter Halbleiter mit einer Bandlücke von 0,334 eV. Die elektrische Leitfähigkeit lässt sich wie bei allen Halbleitern durch Temperaturerhöhung oder Belichtung steigern, dies führt bei Tellur jedoch nur zu einem geringen Anstieg. Die elektrische Leitfähigkeit und Wärmeleitfähigkeit verhält sich bei Tellur richtungsabhängig, das heißt anisotrop. Kristallines Tellur ist ein weiches (Mohshärte 2,25) und sprödes Material, das sich leicht zu Pulver verarbeiten lässt. Durch Druckerhöhung wandelt sich Tellur in weitere kristalline Modifikationen um. Oberhalb von 450 °C geht Tellur in eine rote Schmelze über, bei Temperaturen über 990 °C liegt Tellur als gelbes diamagnetisches Gas aus Te-Molekülen vor. Bei Temperaturen über 2000 °C zerfallen die Te-Moleküle in einzelne Atome.

Kristallines Tellur ist unlöslich in Wasser und schlecht löslich in den Mineralsäuren Salzsäure und Schwefelsäure sowie in Laugen. Gut löslich ist es hingegen in Salpetersäure, da diese ein sehr starkes Oxidationsmittel ist und elementares Tellur zu Telluraten mit der stabilen Oxidationsstufe +IV oxidiert. Tellurschmelzen greifen Kupfer, Eisen und rostfreien Edelstahl an.

In Verbindungen mit Nichtmetallen verhält sich Tellur wie das leichtere Gruppenmitglied Selen. An Luft verbrennt es in einer grün gesäumten, blauen Flamme zu Tellurdioxid TeO:
Tellur reagiert spontan mit Halogenen unter Bildung von Tellurhalogeniden. Bemerkenswert ist hierbei, dass Tellur im Gegensatz zu den leichteren Homologen Selen und Schwefel auch thermodynamisch stabile Iodide bildet, darunter Telluriodid TeI mit der Oxidationsstufe +I. Mit unedlen Metallen wie zum Beispiel Zink reagiert es heftig zu den entsprechenden Telluriden.

Von Tellur sind Isotope mit Massenzahlen zwischen 105 und 142 bekannt. Natürliches Tellur ist ein Mischelement, das aus acht Isotopen besteht, von denen fünf (Te, Te, Te, Te, Te) stabil sind. Das Isotop Te sollte theoretisch unter Elektroneneinfang zu Sb zerfallen. Dieser Zerfall wurde jedoch noch nicht beobachtet; die untere Grenze für seine Halbwertszeit beträgt 9,2 · 10 Jahre (92 Billiarden Jahre). Das Isotop Te geht über den doppelten Elektroneneinfang direkt in Sn über. Die Isotope Te und Te wandeln sich durch Emission von Betastrahlung (Doppelter Betazerfall) in Xe beziehungsweise Xe um.

Den größten Anteil an natürlichem Tellur bildet zu ungefähr einem Drittel das Isotop Te mit einer Halbwertszeit von 7,9 · 10 Jahren, gefolgt vom Isotop Te. Die durchschnittliche Atommasse der natürlichen Tellur-Isotope beträgt daher 127,60 und ist damit größer als die des im Periodensystem folgenden Reinelements Iod mit 126,90. Te gilt als das Isotop mit dem langsamsten Zerfall aller nichtstabilen Isotope sämtlicher Elemente. Der äußerst langsame Zerfall mit einer Halbwertszeit von 7,2 · 10 Jahren (7 Quadrillionen Jahren, d. h. in 1 Kilogramm zerfällt alle 18 Monate ein Atom) konnte nur aufgrund der Detektion des Zerfallsproduktes (Xe) in sehr alten Proben natürlichen Tellurs festgestellt werden.

Von den übrigen Isotopen hat das Kernisomer Te mit 154 Tagen die längste Halbwertzeit. Auch bei den Isotopen Te und Te liegen die Halbwertszeiten der Isomere über denen des Grundzustands. Als Tracer wird am häufigsten das Isotop Te verwendet, gefolgt von Te. Die Isotope Te und Te treten auch als Spaltprodukte bei der Kernspaltung in Atomreaktoren auf.

"→ Siehe auch: Liste der Tellur-Isotope"

Tellur ist ein technisch weniger bedeutendes Element, da es teuer in der Herstellung ist und in der Verwendung häufig andere Elemente beziehungsweise Verbindungen gleichwertig sind. 2016 wurde für elementares, polykristallines und dotiertes Tellur thermoelektrisches Verhalten mit einer hohen Gütezahl im Bereich zwischen Raumtemperatur und 400 °C nachgewiesen. Elementares Tellur wird in der Metallindustrie unter anderem als Zusatz (< 1 %) für Stahl, Gusseisen, Kupfer- und Blei-Legierungen sowie in rostfreien Edelstählen verwendet. Es fördert die Korrosionsbeständigkeit und verbessert die mechanischen Eigenschaften sowie die Bearbeitbarkeit. Als Halbleiter wird reines Tellur bisher nur wenig eingesetzt, meist wird Tellur in II-VI-Verbindungshalbleitern verwendet. Cadmiumtellurid CdTe wird z. B. in Fotodioden und Dünnschicht-Solarzellen zur Stromerzeugung aus Licht verwendet.

Bismuttellurid BiTe wird in Thermoelementen zur Stromerzeugung in thermoelektrischen Generatoren (z. B. in Radionuklidbatterien) bzw. in Peltier-Elementen zur Kühlung eingesetzt.

Kombinationen aus Germanium- GeTe und Antimon-Telluriden SbTe werden in Phasenwechselmaterialien als Bestandteil optischer Speicherplatten (z. B. CD-RW) oder in neuartigen Speichermaterialien wie Phase Change Random Access Memory verwendet.

Gläser aus Tellurdioxid TeO werden aufgrund der hohen Brechungsindices anstelle von Kieselglas SiO in Lichtwellenleitern eingesetzt.

In der Mikrobiologie wird mit farblosem Kaliumtellurat(IV) KTeO versetzter Agar als selektives Nährmedium zum Nachweis von Staphylokokken und Corynebacterium diphtheriae benutzt. Die Bakterienkolonien erscheinen dabei als kleine schwarze Kugeln, da sie die Te-Kationen zu elementarem Tellur reduzieren und in ihre Zellen einlagern.

Medizinische Verwendung fand Tellur (bzw. Kaliumtellurat) erstmals 1890 zur Behandlung von nächtlichen Schweißausbrüchen bei an Tuberkulose erkrankten Patienten.

Weiterhin werden geringe Mengen von Tellur zur Vulkanisierung von Gummi, in Sprengkapseln und zum Färben von Glas und Keramik verwendet. Die Salze des Tellurs werden teilweise zur Erzeugung einer grasgrünen Farbgebung bei Feuerwerken verwendet.

Tellur ist in löslicher Form ein für den menschlichen Organismus giftiges Element und wurde daher in der Vergangenheit als giftig eingestuft. Da elementares Tellur jedoch sehr schlecht in Wasser und körpereigenen Säuren löslich ist, wurde es auf gesundheitsschädlich herabgestuft. Studien der Niederländischen Organisation für Angewandte Naturwissenschaftliche Forschung (TNO) zeigten, dass der LD-Wert für Ratten bei > 5000 mg/kg liegt. Der in vielen Sicherheitsdatenblättern angegebene Wert von 83 mg/kg aus dem Buch "Toxicometric Parameters of Industrial Toxic Chemicals under single Exposure" von N.F. Ismerow, der aus dem Jahr 1982 stammt, gilt nur für leichtlösliche Tellurverbindungen. Trotzdem verwenden verschiedene Hersteller für elementares Tellur (Pulver) weiterhin den alten LD-Wert und die Einstufung "giftig" in Verbindung mit dem H-Satz 301 („Giftig beim Verschlucken“).

Tellur ist nicht so giftig wie das Selen. Dies steht in Analogie zu den benachbarten Elementen der 5. Hauptgruppe, wo das Antimon ebenfalls weniger giftig als das Arsen ist. Gelangt Tellur vor allem in Form von leichtlöslichen Tellurverbindungen wie Alkalimetall-Tellurate (zum Beispiel NaTeO) durch Verschlucken (peroral) in den Körper, bildet sich durch Reduktion giftiges Dimethyltellurid (MeTe: HC−Te−CH), das zur Schädigung von Blut, Leber, Herz und Nieren führen kann. Da leichtlösliche Tellurverbindungen dabei weit mehr Tellur freisetzen, werden diese auch als gefährlicher eingestuft. Tellurvergiftungen machen sich durch einen intensiven, zuerst 1824 von Christian Gottlob Gmelin (bei seinen erstmals vorgenommenen Untersuchungen der Wirkung von Tellur auf Lebewesen) beschriebenen Knoblauchgeruch der Atemluft bemerkbar, der durch das Dimethyltellurid hervorgerufen wird. Dieser entfernt sich erst nach mehreren Wochen und entfaltet sich selbst bei sehr geringen Mengen, die noch keine schwerwiegenden Vergiftungen hervorrufen. Dieser Knoblauchgeruch kann, im Gegensatz zu echtem Knoblauch, nicht durch Zähneputzen entfernt werden. Auch setzt dieser sich in einem Raum fest und entfernt sich erst nach mehreren Stunden. Es wird ebenfalls über die Haut langsam ausgeschieden.

Tellurstäube können sich in Luft selbst entzünden und fein verteilt in entsprechender Konzentration auch explosiv reagieren, wobei sich jeweils Tellurdioxid TeO bildet. Wie andere Metallstäube kann Tellurpulver auch mit Interhalogenverbindungen wie Brompentafluorid BrF explosiv reagieren. Eine Maximale Arbeitsplatz-Konzentration (MAK) für Tellur ist nicht festgelegt.

Elementares Tellur kann in heißer konzentrierter Schwefelsäure (HSO) durch Oxidation des Tellurs unter Bildung des roten Te-Kations ("Tetratellur-Dikation") nachgewiesen werden. Ein Teil der Schwefelsäure wird bei der Reaktion zu Schwefliger Säure (HSO) reduziert, die aufgrund der hohen Temperaturen in Wasser (HO) und ihr Anhydrid Schwefeldioxid (SO) zerfällt, welches als Gas entweicht:
Die Farbe des quadratisch-planar aufgebauten Te-Kations kommt durch sechs delokalisierte π-Elektronen zustande, die einen Teil des sichtbaren Lichts absorbieren. Die übrigen, nicht absorbierten Wellenlängen des Lichts ergeben die Komplementärfarbe Rot.

Tellurat und Tellurit können mittels Polarographie speziiert, d. h. selektiv nebeneinander bestimmt werden. Während die Stufe des Tellurats bei −1,66 V liegt, erscheint diejenige des Tellurits bei −1,22 V (gegen SCE, 0,1 M Natronlauge). Beide Tellurspezies werden dabei in einem Schritt zum Tellurid reduziert. Spuren von 0,03 % Tellurat bzw. 0,003 % Tellurit sind auf diese Weise erfassbar. Wesentlich nachweisstärker sind die Methoden der Atomspektroskopie. Während man mit der Flammen-AAS eine Nachweisgrenze von 20 µg/l erreicht, liegt dieser Wert bei der Graphitrohr-AAS (0,2 µg/l) sowie der Hydridtechnik (0,02 µg/l) noch wesentlich niedriger.

In Verbindungen tritt Tellur am häufigsten in den Oxidationsstufen −II (Telluride) und +IV (Tetrahalogenide, Tellurdioxid und Tellurate(IV), veraltet "Tellurite") auf. Seltener sind die Oxidationsstufen +VI (Tellurate(VI)) und +II (Dihalogenide) sowie −I (Ditelluride) und +I (Monohalogenide, nur bekannt als TeI).

Tellurwasserstoff HTe ist ein farbloses, sehr giftiges Gas, das durch Reaktion von Telluriden (MTe) mit starken Säuren, zum Beispiel Salzsäure HCl, entsteht. Aus den Elementen (Wasserstoff und Tellur) ist die Verbindung als stark endotherme Verbindung nur bei Temperaturen über 650 °C darstellbar. In Wasser gelöst ("Tellurwasserstoffsäure") reagiert es sauer, wobei die Säurestärke in etwa der Phosphorsäure entspricht. An der Luft zersetzt sich die wässrige Lösung umgehend zu Wasser und elementarem Tellur.

Tellurdioxid ("Tellur(IV)-oxid") TeO ist ein farbloser kristalliner Feststoff und das wichtigste Oxid des Tellurs. Es entsteht bei der Verbrennung von elementarem Tellur mit Luft. Es ist das Anhydrid der schwach amphoteren und unbeständigen Tellurigen Säure HTeO. Tellurdioxid existiert in einer orthorhombischen ("Tellurit") und einer tetragonalen ("Paratellurit") Modifikation, die in der Natur auch als Minerale auftreten.

Tellurtrioxid ("Tellur(VI)-oxid") TeO ist ein gelber, trigonal/rhomboedrisch kristallisierender Feststoff und das Anhydrid der Orthotellursäure HTeO. Es entsteht bei der Entwässerung der Orthotellursäure durch starke Temperaturerhöhung. Die gelbe Farbe kommt durch Elektronenübertrag des Sauerstoffs auf das Tellur („Charge-Transfer“) zustande.

Tellurmonoxid ("Tellur(II)-oxid") TeO ist ein weiteres, bei Standardbedingungen jedoch instabiles Oxid des Tellurs. Es wird als schwarzer amorpher Feststoff beschrieben und reagiert in feuchter Luft mit Sauerstoff zum stabileren Tellurdioxid TeO.

Ditellurpentoxid ("Tellur(IV)-Tellur(VI)-oxid") ist ein gemischtes Telluroxid mit Te- und Te-Kationen. Es ist neben Tellurtrioxid ein weiteres Produkt bei der thermischen Zersetzung der Orthotellursäure und kristallisiert im monoklinen Kristallsystem.

Tellurate sind die Salze der Orthotellursäure HTeO und Metatellursäure HTeO mit den Anionen [TeO] beziehungsweise [TeO]. Die Salze der Tellurigen Säure HTeO mit dem Anion [TeO] werden als Tellurate(IV) (veraltet "Tellurite") bezeichnet.

"Tetrahalogenide" TeX mit Tellur in der Oxidationsstufe +IV sind die häufigsten Tellur-Halogenide. Diese sind mit allen Halogenen (Fluor, Chlor, Brom und Iod) bekannt. Bei allen Verbindungen handelt es sich kristalline Feststoffe.

"Dihalogenide" TeX mit Tellur in der Oxidationsstufe +II sind nur mit Chlor, Brom und Iod bekannt, sie existieren nur in der Gasphase.

"Monohalogenide" TeX existieren von Tellur nur mit Iod als Telluriodid TeI. Es ist das einzig bekannte thermodynamisch stabile Mono-Iodid der Chalkogene und ein dunkler kristalliner Feststoff. Tellur hat in dieser Verbindung die ungewöhnliche Oxidationsstufe +I.

"Subhalogenide" enthalten Te mit einer Oxidationsstufe, die kleiner als +I ist. Stabile Vertreter sind TeI, TeBr und TeCl.

"Hexahalogenide" TeX mit Tellur in der Oxidationsstufe +VI sind nur als Tellurhexafluorid TeF oder Tellurpentafluoridchlorid TeFCl bekannt. Beides sind farblose Gase. Tellurhexafluorid ist das reaktivste Chalkogenhexafluorid (neben Schwefelhexafluorid SF und Selenhexafluorid SeF) und wird als einziges in Wasser hydrolysiert.

Weiterhin existieren von Tellur in der Oxidationsstufe +IV in wässriger Lösung auch Komplexverbindungen [TeX] (X = F, Cl, Br, I) mit allen Halogenid-Ionen. Mit Ausnahme des Hexafluoro-Komplexes sind alle anderen perfekt oktaedrisch aufgebaut und können auch als Salze aus der Lösung gefällt werden (zum Beispiel gelbes Ammonium-hexachloridotellurat(IV) (NH)[TeCl], rotbraunes Ammonium-hexabromidotellurat(IV) (NH)[TeBr] oder schwarzes Cäsium-hexaiodidotellurat(IV) Cs[TeI]).

Tellur bildet eine Reihe von metallorganischen Verbindungen. Diese sind aber sehr instabil und werden in der organischen Synthese wenig verwendet. Als reine Tellurorganyle sind Verbindungen der Form RTe, RTe, RTe und RTe (R jeweils Alkyl-, Aryl-) bekannt.

Daneben sind noch Diorganotellurdihalogenide RTeX (R = Alkyl-, Aryl-; X = F, Cl, Br, I) und Triorganotellurhalogenide RTeX (R = Alkyl-, Aryl-; X = F, Cl, Br, I) bekannt.

]

Durch vorsichtige Oxidation von Tellur können neben dem schon erwähnten Te zahlreiche "Tellurpolykationen" Te dargestellt und mit einem geeigneten Gegenion kristallisiert werden. Das Gegenion muss eine schwache Lewis-Base sein, da die Tellurpolykationen verhältnismäßig starke Lewissäuren sind. Geeignete Oxidationsmittel sind häufig Halogenide der Übergangsmetalle, die bei Temperaturen von typischerweise 200 °C direkt die gewünschte Verbindung ergeben:

Häufig ist die Kristallisation unter den Bedingungen des chemischen Transports erfolgreich, bisweilen müssen aber wasserfreie Lösungsmittel wie Zinn(IV)-chlorid oder Siliciumtetrabromid verwendet werden. Auch Salzschmelzen stellen in Einzelfällen geeignete Reaktionsmedien dar.
Ist das Metallhalogenid kein geeignetes Oxidationsmittel, wie das bei Halogeniden der Hauptgruppenelemente in der Regel der Fall ist, können die entsprechenden Tellurtetrahalogenide als Oxidationsmittel verwendet werden:

Durch Variation des Gegenions und des Reaktionsmediums konnte eine große Vielfalt von Polykationen dargestellt werden; auch gemischte Selen-Tellurpolykationen sind durch entsprechende Wahl der Reaktanten der Synthese zugänglich. Neben den gezeigten ketten- bzw. bandförmigen Polykationen gibt es auch isolierte Polykationen wie Te, Te und Te.





</doc>
<doc id="5047" url="https://de.wikipedia.org/wiki?curid=5047" title="Terbium">
Terbium

Terbium ist ein chemisches Element mit dem Elementsymbol Tb und der Ordnungszahl 65. Im Periodensystem steht es in der Gruppe der Lanthanoide und zählt damit auch zu den Metallen der Seltenen Erden. Terbium ist nach dem ersten Fundort, der Grube Ytterby bei Stockholm, benannt, wie auch Yttrium, Ytterbium und Erbium.

Die Entdeckung des Elementes Terbium ist sehr verworren und bis heute nicht geklärt. Allgemein sieht man Carl Gustav Mosander als Entdecker an, der Anfang der 1840er die von Johan Gadolin entdeckte "Yttererde" untersuchte. Die vermeintlich reine Terbium-Verbindung war aber eine Mischung mehrerer Lanthanoide (Bunsen).

Reines Terbium wurde erst mit Aufkommen der Ionenaustauschtechnik nach 1945 hergestellt.

Aus dem Namen der schwedischen Grube Ytterby leitete Mosander die Elementbezeichnung ab.

Terbium kommt in der Natur nur in Verbindungen vor. Bekannte terbiumhaltige Minerale sind :

Nach einer aufwendigen Abtrennung der anderen Terbiumbegleiter wird das Oxid mit Fluorwasserstoff zum Terbiumfluorid umgesetzt. Anschließend wird mit Calcium unter Bildung von Calciumfluorid zum Terbium reduziert. Die Abtrennung verbleibender Calciumreste und Verunreinigungen erfolgt in einer zusätzlichen Umschmelzung im Vakuum.

Das silbergraue Metall der Seltenen Erden ist duktil und schmiedbar. Bei Temperaturen oberhalb 1315 °C wandelt sich α-Terbium (hcp-Kristallgitter) in β-Terbium um. In Luft ist Terbium relativ beständig, es überzieht sich mit einer Oxidschicht. In der Flamme verbrennt es zum braunen Terbium(III,IV)-oxid (TbO). Mit Wasser reagiert es unter Wasserstoffentwicklung zu Hydroxid.

Terbium wird zum Dotieren von Calciumfluorid, Calciumwolframat und Strontiummolybdat zur Verwendung in Halbleitern (solid-state devices) verwendet. Zusammen mit Zirconium(IV)-oxid dient es zur Gefügestabilisierung in Hochtemperatur-Brennstoffzellen. Das Oxid wird dem grünen Leuchtstoff in Bildröhren und Fluoreszenzlampen zugesetzt. Natriumterbiumborat dient als Lasermaterial zur Erzeugung von kohärentem Licht mit einer Wellenlänge von 546 nm (grün).

Terbium-Eisen-Cobalt- oder Terbium-Gadolinium-Eisen-Cobalt-Legierungen dienen als Beschichtung auf wiederbeschreibbaren magneto-optischen (MO) Disks. Terbium-Dysprosium-haltige Legierungen zeigen eine starke Magnetostriktion (Längenänderung durch ein Magnetfeld oder magnetische Impulse bei Längenänderung). Solche Legierungen werden in der Materialprüftechnik eingesetzt.

In Neodym-Eisen-Bor-Magneten erhöhen sie die Koerzitivität, das heißt die Entmagnetisierungs-Resistenz wird erhöht.

Der durchsichtige künstliche Kristall Terbium-Gallium-Granat TbGaO zeigt einen starken Faraday-Effekt und wird daher für optische Isolatoren verwendet.

Terbium und Terbiumverbindungen sind als gering toxisch zu betrachten. Das Element hat keine biologische Bedeutung für den menschlichen Organismus. Terbiummetallstäube sind wie fast alle Metallstäube feuer- und explosionsgefährlich.




</doc>
<doc id="5048" url="https://de.wikipedia.org/wiki?curid=5048" title="Thorium">
Thorium

Thorium (nach dem germanischen Gott Thor) ist ein chemisches Element mit dem Elementsymbol Th und der Ordnungszahl 90. Im Periodensystem steht es in der Gruppe der Actinoide (7. Periode, f-Block).

Hans Morten Thrane Esmark fand 1828 auf der norwegischen Insel Løvøya (Løvø), in der Nähe der Ortschaft Brevik im Langesundsfjord ein schwarzes Mineral. Er übergab diese Probe seinem Vater Jens Esmark, einem führenden norwegischen Professor für Geologie. Esmark konnte diese Probe keinem bisher bekannten Mineral zuordnen und sandte die Probe, in der er eine unbekannte Substanz vermutete, an den schwedischen Chemiker Jöns Jakob Berzelius. Der stellte dann im gleichen Jahr fest, dass dieses Mineral (Thorit) zu nahezu 60 % aus einem neuen Oxid (Thoriumdioxid) bestand. Das dem Oxid zugrunde liegende Metall benannte er nach dem Gott Thor "Thorium". Die Entdeckung des neuen Minerals veröffentlichte Berzelius 1829.

Berzelius besaß bereits 1815 eine Gesteinsprobe, die er für ein neues Mineral hielt. Er ordnete dieses Mineral einem neuen Oxid zu und nannte das dazugehörige Metall nach dem skandinavischen Gott des Donners Thor. 1824 stellte sich jedoch heraus, dass es sich bei diesem vermeintlich neuen Mineral um Xenotim (Yttriumphosphat) handelte.

1898 entdeckten Marie Curie und Gerhard Schmidt (1865–1949) zeitgleich die Radioaktivität von Thorium.

1914 gelang Lely und Hamburger erstmals die Reindarstellung des Metalls.

Thoriumverbindungen finden sich häufig in Monazitsanden (Ce,La,Nd,Th) <nowiki>[</nowiki>PO<nowiki>]</nowiki> + 4...12% ThO, im mit Zirkon isomorphen Mineral Thorit ThSiO sowie in Thorianit (Th,U)O. Auch Titanit und Zirkon selbst enthalten geringere Mengen Thorium.

In der Erdkruste kommt Thorium mit einer Häufigkeit von 7 bis 13 mg pro kg vor; damit ist es doppelt bis dreimal so häufig wie Uran. Generell ist das Element aufgrund seines lithophilen Charakters in geringen Mengen in fast allen silikatischen Gesteinen vertreten.

Die weltweit jährlich für die Stromerzeugung verwendete Kohle enthält unter anderem etwa 10.000 t Uran und 25.000 t Thorium, die entweder in die Umwelt gelangen oder sich in Kraftwerksasche und Filterstäuben anreichern.

Das radioaktive Metall wird in Australien, Norwegen, Sri Lanka, Kanada, USA, Indien, Lappland und Brasilien abgebaut. Stille Vorkommen von ca. 800.000 Tonnen liegen in der Türkei, überwiegend in der Provinz Eskişehir im Landkreis Sivrihisar. Menschliche Knochen enthalten zwischen 2 und 12 µg Thorium pro kg Knochenmasse. Durch Nahrung und Wasser werden täglich zwischen 0,05 und 3 µg aufgenommen.

Reines Thorium ist ein silberweißes Metall, das an der Luft bei Raumtemperatur stabil ist und seinen Glanz für einige Monate behält. Ist es mit seinem Oxid verschmutzt, läuft es langsam an der Luft an und wird grau und schließlich schwarz.

Die physikalischen Eigenschaften von Thorium hängen stark von seiner Verschmutzung durch sein Oxid ab. Viele „reine“ Sorten enthalten oft einige Promille Thoriumdioxid. Es ist aber auch hochreines Thorium verfügbar. Reines Thorium ist weich und sehr dehnbar, es kann kalt gewalzt und gezogen werden.

Thorium ist polymorph mit zwei bekannten Modifikationen. Bei über 1400 °C wandelt es sich von einer kubisch-flächenzentrierten zu einer kubisch-raumzentrierten Struktur um.

Von Wasser wird Thorium nur sehr langsam angegriffen, es löst sich auch in den meisten verdünnten Säuren (Fluss-, Salpeter-, Schwefelsäure) und in konzentrierter Salz- und Phosphorsäure nur langsam. In rauchender Salpetersäure und Königswasser löst es sich gut. Pulverförmiges Thorium wirkt bei feiner Verteilung pyrophor. Thorium verbrennt an der Luft mit weißer, hell leuchtender Flamme.

Thorium kommt in primären und sekundären Lagerstätten vor. Bei Erzaufbereitung werden die Erze der primären Lagerstätte gebrochen und gemahlen. Die Anreicherung geschieht in der Regel durch Flotation. Begleitende Erdalkalikarbonate werden durch eine Salzsäure-Behandlung gelöst. Bei den sekundären Lagerstätten wird in der Regel zuerst eine Schwerkrafttrennung der Mineralfraktionen durchgeführt, gefolgt von einer magnetischen Separation. Der Monazit kann durch seinen Paramagnetismus so von den ferromagnetischen Mineralien und unmagnetischen Mineralien getrennt werden.

Durch Eindickung, Filtration und Kalzinierung wird dann ein Konzentrat aus Thorium- und Seltene-Erden-Verbindungen erzeugt.

Monazit ist ein relativ inertes Mineral. Das einfachste Verfahren ist der Aufschluss mit heißer Schwefelsäure bei über 200 °C mit anschließender Fällung durch Verdünnung mit Wasser. Die Probleme des Verfahrens sind dabei die langsame Lösung der Körner sowie die Komplexierung der gelösten Metall-Ionen durch Phosphate und Sulfate und die damit verbundenen kleinen Prozessfenster. Daher wurde ein alkalischer Aufschluss mit heißer Natronlauge entwickelt, der eine Abtrennung der Phosphat-Ionen erlaubt. Allerdings setzte sich dieser Prozess nicht durch.

Ab etwa 1950 stieg das Interesse an Thorium höherer Reinheit (Nuclear Grade). Dies führte zu einer Erweiterung des Schwefelsäure-Prozesses um eine Fällung mit Oxalaten, die im Anschluss zu Thorium-Hydroxid umgesetzt werden. Dieses ist noch mit Seltenen Erden verunreinigt. Daher wurden die Hydroxide mit Salpetersäure in Form von Nitraten gelöst. Aus der Lösung wurde mittels Lösemittelextraktion – Tri-n-butyl-phosphat (TBP) in Kerosin – das Thorium extrahiert, zur Funktionsweise siehe auch PUREX-Prozess.

Da Thorium eine geringe Elektronegativität besitzt, kann eine direkte Reduktion seiner Verbindungen nicht mit Hilfe von Kohlenstoff oder Wasserstoff erfolgen, es würden sich z. B. hochschmelzende Thorium-Carbide oder -hydride bilden.

Eine Möglichkeit ist die Elektrolyse von Thorium-Haliden in Salzschmelzen, üblich sind z. B.:


bzw. die Umsetzung mit unedlen Metallen:


oder über einen Gasphasentranport:


Das so gewonnene Pulver oder der Metallschwamm werden unter Schutzgas oder im Vakuum zu massivem Material umgeschmolzen.

In der Natur kommt fast nur das Isotop mit der längsten Halbwertszeit Th vor. Thorium trägt durch seinen Zerfall zur Erdwärme bei. Weil Th lange für den Anfang einer der natürlich vorkommenden Zerfallsreihen gehalten wurde, ist diese nach ihm benannt worden. Die Zerfallsprodukte des natürlich vorkommenden Thoriums-232 sind in folgender Reihenfolge:
Für die komplette Zerfallsreihe bis zu ihrem Anfang siehe: Thorium-Reihe.

Thorium wurde in Form seines Oxides für die Herstellung von Glühstrümpfen verwendet. Diese Glühstrümpfe stellte man her, indem man Stoffgewebe mit einer Lösung aus 99 % Thoriumnitrat und 1 % Cernitrat tränkte. Beim ersten Anzünden verbrannte das organische Gewebe, und das Thoriumnitrat zersetzte sich in Thoriumdioxid und nitrose Gase. Hierbei blieb eine zerbrechliche Struktur zurück, die in der Gasflamme ein weißes Licht abgab. Dieses Leuchten hatte nichts mit der sehr schwachen Radioaktivität des Thoriums zu tun, sondern ist chemisch angeregtes Leuchten und gewöhnliches Glühen durch die Hitze der Gasflamme. Aufgrund der Radioaktivität ist man inzwischen zu anderen Materialien übergegangen.

Thorium kann zur Herstellung des spaltbaren Uranisotops U verwendet werden. Anders als im Uran-Plutonium-Brutreaktor (dem "schnellen Brüter") ist dies auch in einem Reaktor möglich, in dem die Kernspaltung durch thermische Neutronen erfolgt. Das liegt am besonders hohen Wirkungsquerschnitt von Th für den Einfang eines thermischen Neutrons. Die erreichbaren Brutraten sind bei einem solchen "thermischen Brüter" aber geringer als beim schnellen Brüter.

Aus Thorium Th wird durch Neutronenbestrahlung Th erbrütet; dieses zerfällt über Protactinium Pa in Uran U.
Versuche mit Thorium in MOX-Brennelementen waren schon in den 1970er Jahren in Lingen durchgeführt worden. Als thermischer Brüter war der Leichtwasserreaktor Shippingport von 1977 bis 1982 in Betrieb. Die frühen Hochtemperaturreaktoren (HTR) mit Thoriumverwendung, z. B. der THTR-300, erbrüteten weniger U, als sie an Spaltstoff verbrauchten, waren also keine Brutreaktoren. Nur etwa 4 % des Thoriuminventars konnten zur Energieerzeugung genutzt werden. Diese HTR waren neben Thoriumzugabe also auf ständige Spaltstoffzufuhr in hochangereicherter, waffenfähiger Form (93 % U) angewiesen, was sich aus Gründen der Proliferationssicherheit bald als inakzeptabel erwies, sodass neuere HTR-Konzepte sich auf den klassischen U/Pu-Zyklus mit niedrig angereichertem Uran, d. h. ohne Thorium, konzentrieren. Der deutsche THTR-300 wurde nach 423 Tagen Volllastbetrieb und vielen Problemen 1989 stillgelegt. 2002 fanden in Obrigheim Tests mit Thorium statt. Eine neue, auf fünf Jahre angelegte Versuchsreihe zur Verwendung von Thorium in MOX-Brennelementen läuft seit April 2013 im norwegischen Forschungsreaktor Halden. Ziel ist es, das Verfahren in kommerziellen Kernkraftwerken anzuwenden und auch das Plutonium abzubauen. Als aktuelles Konzept für einen thermischen Brüter auf Thoriumbasis ist der Flüssigsalzreaktor zu nennen. Ein solcher thermischer Brüter zeigt aber Sicherheitsprobleme; deshalb wird das Konzept eines schnellen Flüssigsalzbrüters diskutiert. Auch das Konzept des beschleunigergetriebenen Rubbiatron-Reaktors basiert auf Thorium.

Da Thorium häufiger als Uran ist, könnte es nach der zu erwartenden Abnahme der weltweiten Uranvorräte möglicherweise in Zukunft eine wichtige Energiequelle sein. Speziell im angelsächsischen Raum gibt es Anfang der 2010er Jahre eine intensive Kampagne für eine Thoriumnutzung zur angeblichen Lösung fast aller Energieprobleme. Kritiker dieser Kampagne sprechen von Thorium-Hype oder sogar von Astroturfing. Studien für die norwegische und die britische Regierung warnen vor hohen Erwartungen bzgl. Thoriumnutzung. Neuere Studien weisen zudem darauf hin, dass eine Nukleartechnik unter Einbeziehung von Thorium erhebliche Proliferationsrisiken beinhaltet.

Zurzeit wird vor allem in Indien Forschung zur Nutzung von Thorium in Kernkraftwerken betrieben, da in diesem Land die weltweit größten Thoriumvorkommen zu finden sind. Ende 2017 soll der "Prototype Fast Breeder Reactor" (Prototyp schneller Brutreaktor, PFBR) fertiggestellt werden. Der PFBR soll eine Leistung von 500 MW haben und im Brutmantel Thorium haben, das in U umgewandelt wird.<ref name="https://sputniknews.com/science/201611301048028430-india-nuclear-reactor/">https://sputniknews.com/science/201611301048028430-india-nuclear-reactor/: India Delays Completion of its Indigenous Nuclear Reactor, abgerufen am 22. Februar 2017.</ref>

Eine stabilisierte Suspension von kolloidalem Thoriumdioxid wurde von 1931 beginnend unter diesem Handelsnamen bis Ende der 1940er Jahre als Röntgenkontrastmittel für die Angiographie verwendet. Es reichert sich jedoch im retikulohistiozytären System an und kann aufgrund örtlich erhöhter Strahlenbelastung zu Krebs führen. Klare Assoziationen bestehen zwischen Thorotrast und dem Gallengangs-Karzinom; außerdem kann ein Angiosarkom der Leber, ein sonst sehr seltener bösartiger Tumor der Leber, durch Thorotrast induziert sein. Karzinome der Nasennebenhöhlen nach der Verabreichung von Thorotrast sind beschrieben. Typischerweise treten die Erkrankungen 30–35 Jahre nach der Exposition auf.

An Stelle von Thorotrast werden heute Bariumsulfat und deutlich verbesserte aromatische Iodderivate als Röntgenkontrastmittel verwendet.

Zur Verbesserung der Zündeigenschaften der beim Wolfram-Inertgas-Schweißen (WIG-Schweißen) eingesetzten Elektroden wurde Thoriumdioxid in der Größenordnung von 1 bis 4 % beigemischt. Diese Verwendung ist inzwischen wegen der Strahlenbelastung durch Dämpfe und Schleifstaub nahezu eingestellt worden. Moderne WIG-Elektroden arbeiten mit Cer-Zusätzen.

Als Glühelektrodenwerkstoff eingesetzter Wolframdraht wird zur Verringerung der Elektronen-Austrittsarbeit mit etwa 1–3 % Thoriumdioxid dotiert. Dies ermöglicht die Reduzierung der zu einer vergleichbaren Emission notwendigen Temperatur in Elektronenröhren und verbessert das Startverhalten von Entladungslampen. Im Lampenbau wird Thorium ferner als Getter in Form von Thoriumdioxid-Pillen oder Thoriumfolie eingesetzt.
Thoriumdioxid wurde dem Glas für hochwertige optische Linsen zugesetzt, um Linsen mit sehr großem optischen Brechungsindex bei kleiner optischer Dispersion zu produzieren. Optische Geräte aus der Zeit des Zweiten Weltkriegs (z. B. das "Aero-Ektar" von Kodak) bzw. der frühen Nachkriegsjahre (z. B. einige Summicron-Objektive von Leitz) enthalten gelegentlich Thoriumglas. Thoriumhaltige Linsen haben einen leichten, sich mit der Zeit verstärkenden Gelbstich, der durch intensive Bestrahlung mit UV-Licht zumindest teilweise entfernt werden kann. Wegen der vom Thorium ausgehenden Strahlung wird thoriumhaltiges Glas heute nicht mehr kommerziell hergestellt. Lanthan-haltige Gläser (z. B. LaK9) können Thoriumglas ersetzen.

Einstufungen nach der CLP-Verordnung liegen nicht vor, weil diese nur die chemische Gefährlichkeit umfassen, die eine völlig untergeordnete Rolle gegenüber den auf der Radioaktivität beruhenden Gefahren spielt. Auch Letzteres gilt nur, wenn es sich um eine dafür relevante Stoffmenge handelt.

Die akute chemische Toxizität von Thorium wird als gering eingeschätzt und im Wesentlichen auf die Radioaktivität zurückgeführt. Dies hängt mit der schlechten Wasserlöslichkeit von 0,0001 μg pro Liter des reinen Metalls sowie des meist vorkommenden Thoriumdioxids zusammen. Lediglich in sehr saurem Milieu ab einem pH-Wert von 4 löst sich Thorium besser. Auch Oxalate und andere Komplexbildner erhöhen die Wasserlöslichkeit.

Das Thoriumisotop Th ist mit seiner Halbwertszeit von 14,05 Mrd. Jahren noch wesentlich schwächer radioaktiv (geringere Dosisleistung) als Uran-238, da durch die längere Halbwertszeit weniger Zerfälle pro Sekunde stattfinden und auch die Konzentration der kurzlebigen Zerfallsprodukte geringer bleibt. Thorium ist sowohl ein α-Strahler, als auch ein γ-Strahler und aufgrund dieser Strahlungsart gefährlich bei Inhalation und Ingestion. Metall-Stäube und vor allem -Oxide sind aufgrund ihrer Lungengängigkeit radiotoxisch besonders gefährlich und können Krebs verursachen. Beim Lagern von und Umgang mit Thorium und seinen Verbindungen ist auch die dauernde Anwesenheit der Elemente aus der Zerfallsreihe zu beachten. Besonders gefährlich sind starke Beta- und die mit einem hohen 2,6-MeV-Anteil sehr energiereichen und durchdringungsfähigen Gammastrahlen. Ferner entsteht in der Zerfallsreihe als Ergebnis eines Alphazerfalls das auch als Thoron bekannte Radonisotop Rn, das wiederum in einem Alphazerfall zu Polonium-216 und Blei-212 zerfällt. Bei gleicher Aktivitätskonzentration ergibt sich aus den Thoron-Folgeprodukten eine 14-fach höhere Strahlenbelastung als aus den Folgeprodukten des Rn.

In Übereinstimmung mit seiner Stellung im Periodensystem tritt Thorium in seinen Verbindungen normalerweise in der Oxidationsstufe +4 auf; Thorium(III)- und Thorium(II)-Verbindungen sind seltener. Eine Besonderheit bilden die Carbide der Actinoide ohne feste Stöchiometrie.

Bei der auch als "Weltvernichtungsmaschine" titulierten „Cobalt-Thorium-G“-Bombe in Stanley Kubricks Film handelt es sich in erster Linie um eine Kobaltbombe. Verwendet man im Bombendesign Thorium (möglicherweise anstelle von Uran in der Fissionsstufe oder im Mantel), so entsteht bei der Explosion u. a. radioaktives, giftiges und langlebiges Protactinium-231, was das Kontaminationspotential des Fallouts beträchtlich steigern würde. Die Halbwertszeit von Protactinium-231 beträgt allerdings 32760 Jahre und weicht somit von der im Film genannten (93,7 bzw. 100 Jahre) deutlich ab.

Unter der Bezeichnung Thorium-X wurden vor allem in der 1. Hälfte des 20. Jahrhunderts verschiedene Lösungen gehandelt, die Thorium- und andere radioaktive Nuklide enthielten. In den USA kam z. B. eine Tinktur dieses Namens bis etwa 1960 in der Radiotherapie von Hautkrankheiten zur Anwendung. In Deutschland gab es um 1930 Badezusätze und Ekzemsalben der Marke „Thorium-X“, die wegen der offenkundigen Gesundheitsgefahren allerdings kurz darauf aus dem Handel genommen wurden. Des Weiteren gab es eine Thorium-X-haltige Zahnpasta mit dem Namen Doramad. Ferner wurde in den 1960ern in der Universitätsklinik Münster (Hüfferstiftung) Thorium-X bei Morbus-Bechterew-Patienten gegen eine weitere Versteifung der Wirbelsäule eingesetzt. Der Patient erhielt während eines circa dreimonatigen stationären Aufenthaltes einmal pro Woche eine Thorium-X-Injektion. Die fortschreitende Versteifung wurde dadurch für ca. 15 Jahre weitgehend gestoppt.

Als Ionium wurde in der Kernphysik das Isotop 230-Th bezeichnet. In der Altersdatierung wird der Begriff "Ionium-Methode" immer noch für die 230-Th/232-Th-Datierung verwendet.




</doc>
<doc id="5051" url="https://de.wikipedia.org/wiki?curid=5051" title="Tonne">
Tonne

Tonne (ahd. "tunna"; mittellat. "tunna" ‚Fass‘) steht für:

die Maßeinheiten:

Personen:

Tonnenförmige Behälter:

Tonne steht für:

Siehe auch:



</doc>
<doc id="5052" url="https://de.wikipedia.org/wiki?curid=5052" title="Thermodynamik">
Thermodynamik

Die Thermodynamik (von "thermós" „warm“ sowie "dýnamis" „Kraft“), oder Wärmelehre ist eine natur- und ingenieurwissenschaftliche Disziplin. Sie hat ihren Ursprung im Studium der Dampfmaschinen und ging der Frage nach, wie man Wärme in mechanische Arbeit umwandeln kann. Dazu beschreibt sie Systeme aus hinreichend vielen Teilchen und deren Zustandsübergänge anhand von makroskopischen Zustandsgrößen, die statistische Funktionen der detaillierten Vielteilchenzustände darstellen. Als Ingenieurwissenschaft hat sie für die verschiedenen Möglichkeiten der Energie­umwandlung Bedeutung und in der Verfahrenstechnik beschreibt sie Eigenschaften und das Verhalten von Stoffen, die an Prozessen beteiligt sind. Als Begründer gilt Sadi Carnot, der 1824 seine wegweisende Arbeit schrieb.

Eine große Bedeutung haben die Hauptsätze der Thermodynamik, die eine ähnliche Stellung einnehmen wie die Newtonschen Axiome in der klassischen Mechanik oder die Maxwell-Gleichungen in der Elektrodynamik. Der erste Hauptsatz besagt, dass die gesamte Energie in einem abgeschlossenen System konstant ist, und hat als Energieerhaltung in der gesamten Physik Gültigkeit. Der zweite Hauptsatz drückt aus, in welcher Richtung Energieumwandlungen möglich sind. So ist es beispielsweise möglich, mechanische, elektrische oder chemische Energie vollständig in Wärmeenergie (thermische Energie) umzuwandeln. Wärmeenergie dagegen lässt sich nur teilweise und nur mit hohem technischen Aufwand in diese Energien umwandeln.

In der Thermodynamik gibt es zwei verschiedene Herangehensweisen, die sich darin unterscheiden, ob Stoffe als Kontinuum betrachtet werden, die sich beliebig teilen lassen, oder ob sie als Ansammlung von Teilchen wie Atomen oder Molekülen gesehen werden:

Die Thermodynamik befasst sich einerseits mit verschiedenen Prozessen, wenn daran Wärme beteiligt ist, ohne auf die Besonderheiten der daran beteiligten Stoffe einzugehen. Von besonderer Bedeutung sind Kreisprozesse, die in der Technik häufig vorkommen. Andererseits macht sie Aussagen über Stoffe wie die verschiedenen Aggregatzustände und ihren Wechsel (schmelzen, sieden, verdampfen …) oder chemische Reaktionen, die sehr stark von den jeweilige Stoffen abhängen.

Innerhalb der Naturwissenschaften hat die Thermodynamik große Bedeutung, da bei sämtlichen in der Natur ablaufenden Prozessen auch Energie beteiligt ist. Dies schließt auch Lebewesen mit ein. Zudem bietet sie einen tieferen Einblick in die Eigenschaften der Materie, was einerseits für das Verständnis physikalischer Eigenschaften oder Änderungen von Aggregatszuständen hilfreich ist und andererseits wichtig ist um zu verstehen, welche chemischen Reaktionen ablaufen können und welche nicht. Innerhalb der Physik wird auch betont, dass die Thermodynamik verschiedene unabhängig entstandene Fachgebiete wie die klassische Mechanik oder die Quantenmechanik miteinander verbinden kann, was insbesondere über den universellen Begriff der Energie möglich wird.

In den Ingenieurwissenschaften ist die Thermodynamik wichtig für die Konstruktion, Berechnung und Analyse von zahlreichen Maschinen oder Anlagen. Dazu zählen die verschiedenen Wärmekraftmaschinen (Dampfmaschine, Gas- oder Dampfturbine, Dieselmotor), die Arbeitsmaschinen (Pumpen, Verdichter,…), Klima- und Kältetechnik, Wärme- und Stoffübertragung, Industrieöfen, Ver- und Entsorgungstechnik oder Energietechnik (Kraftwerke).

Der französische Physiker Nicolas Léonard Sadi Carnot untersuchte die Wärmemengen einer Dampfmaschine (1824). Er stellte fest, dass heißer Wasserdampf ein kälteres Wasserreservoir erwärmt und dabei mechanische Arbeit geleistet wird. Carnot vermutete, dass bei diesem Prozess keine Wärme verloren geht. Carnot beschrieb die Vorgänge in der Dampfmaschine als Kreisprozess, der in späteren Jahren von Émile Clapeyron in mathematischer Form dargestellt wurde (Carnotscher Kreisprozess).

Der deutsche Arzt Julius Robert Mayer formulierte (1841) die These, dass Energie in einem abgeschlossenen System eine konstante Größe sein sollte. Energie kann nicht verschwinden, sondern nur in eine andere Form umgewandelt werden. Diese Erkenntnis ist als Energieerhaltungssatz bekannt. Mayer machte Berechnungen zur Umwandlung von Wärme in mechanische Energie. Er gab an, wie viel Energie der Temperaturerhöhung von 1 g Wasser um 1 °C entspricht und berechnete, dass diese Energiemenge einer mechanischen Energie entspricht, die 1 g Materie 367 Meter in die Höhe heben könnte (tatsächlich sind es 426 Meter). Diese Berechnungen bildeten die Grundlage zum Ersten Hauptsatz der Thermodynamik. James Prescott Joule bestimmte im Jahr 1844 noch genauer das mechanische Wärmeäquivalent.

Im Jahr 1840 veröffentlichte der schweizerisch-russische Chemiker Hermann Heinrich Hess eine Abhandlung mit dem Titel "Thermochemische Untersuchungen," die auf dem Satz von der Erhaltung der Energie bei Molekülen bzw. Atomen aufgrund von chemischen Reaktionswärmen basierte.

Während Carnot noch vermutete, dass die Wärmemengen bei einer Dampfmaschine vollständig erhalten bleiben, nahm Mayer eine Umwandelbarkeit von Energieformen ineinander an. Der deutsche Physiker Rudolf Clausius verknüpfte 1854 die Ideen von Mayer und Carnot. Er zeigte, dass beim Betreiben einer Dampfmaschine immer Wärme von einem wärmeren Reservoir in ein kälteres Reservoir fließt und damit die Grundthese von Carnot korrekt ist. Jedoch bleibt die Wärmeenergie nicht – wie Carnot annahm – konstant, sondern sie wird zum Teil in mechanische Arbeit umgewandelt. Clausius stellte fest, dass die Wärmeenergie einer Maschine (Dampfmaschine) immer nur zu einem Teil in mechanische Arbeit umgewandelt werden kann; der andere Teil der Energie wird an die Umgebung abgegeben. Der Wirkungsgrad einer Maschine gibt das Umwandlungsverhältnis von gewonnener mechanischer Energie zur zugeführten Wärme an. Clausius Erkenntnis bildet den Zweiten Hauptsatz der Thermodynamik: „Es gibt keine periodisch arbeitende funktionierende Maschine, die nichts anderes tut, als Wärme in mechanische Arbeit zu verwandeln.“
Die Wärmemenge, die nicht zur mechanischen Arbeit genutzt werden kann, wird an die Umgebung abgegeben. Diese nicht nutzbare Wärmemenge verknüpfte Clausius mit der entsprechenden Temperatur zu einer neuen Funktion, der Entropie. Alle natürlichen Energieumwandlungsprozesse enthalten einen irreversiblen Entropieanteil, bei dem nicht genutzte Wärme an die Umgebung abgegeben wird.
Entropie bedeutet eine „nach innen gekehrte, d. h. nicht mehr verwandlungsfähige oder nutzbare Energie.“ Später fasste Boltzmann, recht anschaulich, die Entropie als Maß der Unordnung der Bewegungen eines Systems auf. Nur in einem abgeschlossenen System und bei einer reversiblen Zustandsänderung bleibt die Entropiedifferenz zwischen Anfangs- und Endzustand gleich Null.

Der französische Chemiker Marcelin Berthelot nahm als Triebkraft für eine chemische Reaktion die sich dabei entwickelnde Wärme an (1862).

Hermann Helmholtz verknüpfte die elektrische Energie bei Batterien mit der chemischen Energie und der Wärmeenergie. Er entwickelte in seiner Abhandlung "Ueber die Erhaltung der Kraft" unabhängig von Mayer den Energieerhaltungssatz.

Helmholtz befasste sich in späteren Jahren mit energetischen Fragen bei chemischen Reaktionen. Helmholtz gab Berthelot recht, dass bei vielen chemischen Umwandlungen Wärme frei wird; es gab jedoch auch Umwandlungen, bei denen Kälte erzeugt wurde. Helmholtz unterteilte in seiner Abhandlung "Die Thermodynamik chemischer Vorgänge" die Energie bei Stoffumwandlungen in freie und gebundene Energie. Die innere Energie und die Freie Energie verknüpfte Helmholtz mit dem Produkt aus Entropie und Temperatur. Stoffumwandlungen sind nach Helmholtz nur möglich, wenn die Freie Energie abnimmt. Auch der amerikanische Physikochemiker Josiah Willard Gibbs kam nahezu gleichzeitig zwischen 1875 und 1878 zu ähnlichen Überlegungen wie Helmholtz. Die Beziehung zwischen Enthalpiedifferenz abzüglich des Produkts aus Entropiedifferenz und Temperatur bezeichnet man als Differenz der Freien Enthalpie. Die Beziehung heißt zu Ehren der beiden Wissenschaftler Gibbs-Helmholtz-Gleichung. Mit dieser Gleichung kann der Chemiker Aussagen über eine stoffliche Umsetzung von Molekülen treffen und die nötigen Temperaturen und Konzentrationen von chemischen Umsetzungen berechnen.

Neben der klassischen Thermodynamik wurde die kinetische Gastheorie entwickelt. Gase bestehen danach aus Teilchen, Atomen oder Molekülen, die sich zwischen relativ seltenen Stößen frei im leeren Raum bewegen. Bei Temperaturerhöhung bewegen sich die Teilchen schneller und üben durch häufigere und heftigere Stöße einen stärkeren Druck auf die Gefäßwände aus. Wichtige Vertreter dieser Theorie waren August Krönig (1822–1879), Rudolf Clausius, James Clerk Maxwell und Ludwig Boltzmann. Maxwell und Boltzmann nutzten die Wahrscheinlichkeitsrechnung, um thermodynamische Größen auf molekularer Basis zu beschreiben.

Im Jahre 1999 wurde von den Physikern Elliott Lieb und Jakob Yngvason eine axiomatische Systematik vorgestellt, bei der die Definition der Entropie auf dem Konzept der adiabatischen Erreichbarkeit beruht und auf einer streng mathematischen Basis in Form von 15 Axiomen steht. Dabei ist die Temperatur nur noch eine aus der Entropie als Grundgröße abgeleitete Größe. Das Konzept der adiabatischen Erreichbarkeit basiert auf einer axiomatischen Begründung von Constantin Carathéodory aus dem Jahr 1909. Da diese Theorie auf die Ergebnisse keine Auswirkungen hat, hat sie in die Praxis bisher keinen – und in die Lehre nur ausnahmsweise – Eingang gefunden.

Aufgrund der relativ langen Historie der Thermodynamik und der breiten Anwendungsgebiete verwenden die Beschreibungen in der "technischen Thermodynamik" (z. B. bei der Beschreibung eines Verbrennungsmotors oder eines Kühlschranks), der "chemischen Thermodynamik" (z. B. bei der Beschreibung einer chemischen Reaktion) und der "statistischen Thermodynamik" (z. B. bei der Beschreibung von geordneten Quantenzuständen in Festkörpern) oft deutlich unterschiedliche Formalismen.

Die Thermodynamik bringt die Prozessgrößen Wärme und Arbeit an der Systemgrenze mit den Zustandsgrößen in Zusammenhang, welche den Zustand des Systems beschreiben.

Auf der Basis von vier fundamentalen Hauptsätzen sowie materialspezifischen, empirischen Zustandsgleichungen zwischen den Zustandsgrößen (siehe z. B. Gasgesetz) erlaubt die Thermodynamik durch die Aufstellung von Gleichgewichtsbedingungen Aussagen darüber, welche Änderungen an einem System möglich sind (beispielsweise welche chemischen Reaktionen oder Phasenübergänge ablaufen können, aber nicht wie) und welche Werte der intensiven Zustandsgrößen dafür erforderlich sind. Sie dient zur Berechnung von frei werdender Wärmeenergie, von Druck-, Temperatur- oder Volumenänderungen, und hat daher große Bedeutung für das Verständnis und die Planung von Prozessen in Chemieanlagen, bei Wärmekraftmaschinen sowie in der Heizungs- und Klimatechnik.

Um Systeme und Eigenschaften kurz und präzise zu beschreiben, werden in der Thermodynamik immer wieder bestimmte Begriffe und Vereinbarungen verwendet:

In thermodynamischen Formeln werden immer wieder bestimmte Buchstaben für bestimmte Größen verwendet. Dabei bezeichnen Großbuchstaben in Formeln eine "absolute Größe", beispielsweise V als Volumen [m³]. Kleinbuchstaben bezeichnen "spezifische Größen", beispielsweise v als Volumenstrom (Volumen bezogen auf eine Masse, [m³/kg]), einen Massenstrom [kg/s] oder eine Stoffmenge [m³/mol].






Wenn ein System A sich mit einem System B sowie B sich mit einem System C im thermischen Gleichgewicht befindet, so befindet sich auch A mit C im thermischen Gleichgewicht. Die Zustandsgröße, die bei diesen Systemen übereinstimmt, ist die Temperatur, die skalar, intensiv und überall im System gleich ist.

Anders formuliert: ist das Gleichgewicht transitiv, so haben zwei in Kontakt stehende Systeme genau dann die gleiche Temperatur, wenn sie sich im thermischen Gleichgewicht befinden, d. h. wenn zwischen ihnen keine Wärme (mehr) ausgetauscht wird.

Beispiel: Ein Thermometer ist selbst ein System und soll als B bezeichnet werden. Wenn B die gleiche Temperatur für ein System A, wie auch für ein System C anzeigt, lässt sich daraus schließen, dass auch A und C untereinander im thermischen Gleichgewicht stehen werden, wenn man sie in Kontakt bringt. Dieser Hauptsatz wurde erst nach den drei anderen Hauptsätzen formuliert. Da er aber ein Fundament der Thermodynamik bildet, wurde er später als "„nullter“ Hauptsatz" bezeichnet.

Allerdings ist im Gravitationsfeld zu beachten, dass das Gleichgewicht bei im Allgemeinen verschiedenen Temperaturen zwischen den Systemen A, B und C liegt, denn die Photonen der Schwarzkörperstrahlung erfahren im Gravitationsfeld aufgrund des Äquivalenzprinzips eine Rot- bzw. Blauverschiebung; durch die Zeitdilatation werden sie in unterschiedlichen Höhen mit verschiedenen Raten emittiert. Zudem sind deren Flugbahnen gekrümmt, so dass nicht alle von unten startenden Photonen auch oben ankommen können. All diese Effekte bewirken eine mit der Höhe abnehmende Temperatur. Auf der Erde beträgt dieser Effekt aber nur 1,6·10 K/m und ist daher unmessbar klein. Bei einem Neutronenstern ist er aber nicht vernachlässigbar.

Der 1. Hauptsatz der Thermodynamik beschreibt die Energieerhaltung in thermodynamischen Systemen. Er sagt aus, dass die Energie eines abgeschlossenen Systems konstant ist. Ausgehend von dieser Aussage lassen sich Energiebilanzen für geschlossene und offene Systeme bilden.

Jedes System besitzt eine innere Energie formula_2 (= extensive Zustandsgröße). Diese kann sich nur durch den Transport von Energie in Form von Arbeit formula_3 und/oder Wärme formula_4 über die Grenze des Systems ändern, das heißt:

Dabei ist formula_6 die infinitesimale Änderung der an dem System geleisteten Arbeit formula_7(genauer: die Summe aus der Volumenarbeit und der im System dissipierten Arbeit, z. B. Reibungsarbeit). Anstelle der Volumenarbeit können äquivalente extensive Arbeitsausdrücke verwendet werden. So wird beispielsweise für ein magnetisches System in einem Magnetfeld "H" bei Erhöhung des magnetischen Momentes formula_8 der Probe die extensive Arbeit formula_9 geleistet.

Die Gleichung gilt für das ruhende System. Beim bewegten System kommen die äußeren Energien formula_10 (potentielle und kinetische Energie) hinzu:

Die Energie eines abgeschlossenen Systems bleibt unverändert. Verschiedene Energieformen können sich demnach ineinander umwandeln, aber Energie kann weder aus dem Nichts erzeugt noch kann sie vernichtet werden.
Deshalb ist ein Perpetuum mobile erster Art unmöglich (kein System verrichtet Arbeit ohne Zufuhr einer anderen Energieform und/oder ohne Verringerung seiner inneren Energie).

Eine Einschränkung der Umwandelbarkeit von Wärme in Arbeit ergibt sich erst aus dem zweiten Hauptsatz der Thermodynamik.

Auf das offene System angewendet, wird der erste Hauptsatz mathematisch anders formuliert.Beim offenen System fließen über die bestimmte Systemgrenze zusätzlich zur mechanischen Arbeit an der verschiebbaren Systemgrenze (Volumenänderungsarbeit z. B. am Kolben in einem Zylinder) die Verschiebearbeiten der Massenströme am Ein- und Austritt. Sie sind das Produkt aus Druck und Volumen. Statt mit der inneren Energie wird beim offenen System deshalb mit den Enthalpien bilanziert, die diesen Term enthalten.

Die Bilanz für ein instationäres System, bei dem sowohl Masseinhalt als auch Energieinhalt sich zeitlich ändern, lautet:

Dabei sind:


Dabei ist formula_30 die Wellenleistung der Maschine. Da vom System abgegebene Energien in der Thermodynamik negativ definiert sind, wird die Leistung einer Turbine aus dieser Gleichung negativ. In der Praxis wird das Vorzeichen deshalb gewechselt. In vereinfachten Berechnungen vernachlässigt man auch die äußeren Energien.

Da nach dem Durchlaufen eines Kreisprozesses das Arbeitsmedium zum Ausgangszustand zurückkehrt, vereinfacht sich die Bilanz, es entfallen die Änderungen der Zustandsgrößen, und es verbleiben die Prozessgrößen Wärme und Arbeit. Wie noch im Zusammenhang mit dem 2. Hauptsatz erläutert wird, kann nicht nur Wärme zugeführt werden, die komplett in Arbeit umgewandelt wird, sondern es muss auch Wärme abgeführt werden. Die einfache Bilanzgleichung lautet:

Dabei summiert das Kreisintegral alle Wärmeströme auf. Sie sind positiv, wenn sie in das System eintreten und negativ, wenn sie es verlassen. formula_32 ist die gesamte Arbeit des Zyklus. Sie ist negativ, wenn sie abgegeben wird.

Die Beziehung wird auch oft mit den Wärmebeträgen geschrieben:

wobei die Wärmeabfuhr deutlicher erkennbar wird.

Der Zweite Hauptsatz der Thermodynamik trifft Aussagen über die Richtung von Prozessen und das Prinzip der Irreversibilität. Aus dem Zweiten Hauptsatz lassen sich die Definition der thermodynamischen Temperatur und die Zustandsgröße Entropie herleiten. Ebenso folgt aus dem Zweiten Hauptsatz der Thermodynamik die Unterscheidung von Exergie und Anergie und die Tatsache, dass der Wirkungsgrad einer Wärmekraftmaschine den Carnot-Wirkungsgrad nicht überschreiten kann.

Der zweite Hauptsatz der Thermodynamik in der Formulierung von Clausius lautet:


Einfacher ausgedrückt: Wärme kann nicht von selbst von einem Körper niedriger Temperatur auf einen Körper höherer Temperatur übergehen. Diese Aussage scheint zunächst überflüssig zu sein, denn sie entspricht der alltäglichen Erfahrung. Dennoch ist sie gleichbedeutend zu allen weiteren, weniger „selbstverständlichen“ Aussagen, denn alle Widersprüche zu den anderen Aussagen lassen sich auf einen Widerspruch zu dieser zurückführen.

Der zweite Hauptsatz der Thermodynamik in der Formulierung von Kelvin und Planck lautet:


Dem ersten Hauptsatz würde die Annahme nicht widersprechen, dass es möglich sei, einer – wie immer auch gearteten – Kraftmaschine einen stetigen Wärmestrom zuzuführen, den diese vollständig als mechanische oder elektrische Leistung abgibt. Eine solche Maschine wird als Perpetuum mobile zweiter Art bezeichnet. Eine entsprechende Formulierung des zweiten Hauptsatzes lautet:

Nimmt man an, es gäbe diese von einer Wärmesenke zur Wärmeabfuhr unabhängige Kraftmaschine, so könnte damit der Umgebung, z. B. dem Meerwasser, Wärme entzogen und in mechanische Arbeit umgewandelt werden. Man könnte damit auch gemäß dem Bild rechts die Wärme aus einem Reservoir oder Behälter entziehen und mit der umgewandelten Energie eine Wärmepumpe antreiben, die mit einem reversiblen Carnot-Prozess Wärme aus einem anderen Behälter mit niedrigerer Temperatur in den Ersteren mit höherer Temperatur fördert. Die in den wärmeren Behälter eingespeiste Wärmemenge wäre dann größer als die von der Kraftmaschine aufgenommene, weil die abgegebene Energie der Wärmepumpe aus der Summe von aufgenommener Wärme und Antriebsarbeit besteht. Denkt man sich die Systemgrenze um beide Maschinen einschließlich der beiden Wärmebehälter gezogen, so wäre innerhalb dieses abgeschlossenen Systems – also ohne Energie- und Stoffaustausch mit der Umgebung – letztlich Wärme von einem kälteren zu einem wärmeren Körper geflossen. Dies ist ein Widerspruch zur ersten Aussage. Prinzipiell derselbe Widerspruch ergibt sich aber auch mit der Annahme, man könnte eine Kraftmaschine bauen, die einen größeren Wirkungsgrad aufweist als eine mit einem Carnot-Prozess arbeitende Maschine. Auch diese Maschine würde dem wärmeren Behälter weniger Wärme entnehmen als die von ihr angetriebene Carnot-Wärmepumpe dort einspeist. Die entsprechende Aussageform des zweiten Hauptsatzes lautet:


Die Nennung der mittleren Temperaturen ist deshalb von Bedeutung, weil in der Regel durch Wärmezufuhr oder Wärmeentnahme ein Wärmereservoir seine Temperatur ändert.

Dabei ist formula_35 nicht irgendeine Temperatur (z. B. nicht die Grad Celsius- oder die Fahrenheit-Temperatur) des Systems, sondern die von der Zustandsgleichung des „idealen Gases“ her, oder besser durch den gerade angegebenen Wirkungsgrad des Carnot-Prozesses definierte „absolute Temperatur“ (Kelvin).

Unmittelbar in diesem Zusammenhang lässt sich weiter formulieren:


und:


Mit den in der modernen Thermodynamik festgelegten Begriffsdefinitionen (Wärme, Arbeit, Innere Energie, Zustandsgröße, Prozessgröße, adiabat…) und mit der systematischen Einteilung der Systeme kann über die von Clausius eingeführte Zustandsgröße Entropie eine für alle geschlossenen Systeme und Prozesse in offenen Systemen allgemein gültige Aussage des zweiten Hauptsatzes in mathematischer Form gegeben werden. Bei offenen Systemen bezieht sich die Bilanz auf ein Fluidteilchen, das sich durch das System hindurch bewegt und als geschlossenes bewegtes System betrachtet werden kann (siehe oben).

Dabei ist formula_37 die innerhalb des Systems dissipierte Arbeit (Arbeit, die nicht nach außen gelangt, sondern infolge von Reibungs-, Drosselungs- oder Stoßvorgängen die innere Energie erhöht). Sie ist immer positiv. Man bezeichnet den entsprechenden Term in der Gleichung als „produzierte Entropie“ – im Gegensatz zum ersten Term, der „transportierte Entropie“ genannt wird und auch negativ sein kann.

Für das adiabate System mit formula_38 ergibt sich daraus:


Auch hier ist die Äquivalenz mit der ersten Aussage von Clausius leicht zu erkennen. Ein selbsttätiger Wärmefluss vom kälteren zum wärmeren Behälter in der oben skizzierten Anordnung würde bedeuten, dass die Entropie des kälteren Behälters (geringere Temperatur formula_35 im Nenner) stärker abnimmt, als die des wärmeren zunimmt, d. h. die gesamte Entropie im System abnimmt, was nicht möglich ist.

Alle spontan ablaufenden Prozesse sind irreversibel. Dort findet immer eine Entropiezunahme statt. Beispiele sind die Vermischung von zwei unterschiedlichen Gasen und der Wärmefluss von einem heißen zu einem kalten Körper ohne Gewinnung von Arbeit. Die Wiederherstellung des (oft „geordneter“ genannten) Anfangszustandes erfordert dann den Einsatz von Energie oder Information (siehe maxwellscher Dämon). Reversible Prozesse sind nicht mit einer Erhöhung der Gesamtentropie verbunden und laufen daher auch nicht spontan ab. Durch die theoretische Beschreibung spontan ablaufender Prozesse zeichnet der Zweite Hauptsatz der Thermodynamik eine Richtung der Zeit aus, die mit unserer intuitiven Erfahrungswelt übereinstimmt (vgl. das Beispiel weiter unten).

Mit den beschriebenen Zusammenhängen ist auch der folgende Satz eine Aussageform des zweiten Hauptsatzes:

Die Exergie ist der in andere Energieformen umwandelbare Anteil der thermischen Energie. Wird ein Körper bzw. System mit einem Zustand, der von dem der Umgebung abweicht, reversibel in den Umgebungszustand gebracht, so wird seine Exergie als Arbeit abgegeben. Die Wärme, die ein Körper (z. B. ein heißes Rauchgas im Kessel eines Kraftwerks) abgibt, wenn es sich auf Umgebungstemperatur abkühlt, kann theoretisch über eine Folge von differenziellen Carnot-Prozessen, wie im Bild rechts dargestellt, zur Umwandlung in Arbeit genutzt werden. Der exergetische Anteil ergibt sich durch Aufsummieren der differenziellen (pinkfarbenen) Flächenanteile oberhalb der Umgebungstemperatur formula_40.

Die Wärmesenke für diese Prozesse zur Aufnahme der Anergie (blauer Flächenanteil unterhalb formula_40) ist die Umgebung. Herrscht bei einem Gas im Ausgangszustand gegenüber dem Umgebungszustand nicht nur eine höhere Temperatur, sondern auch ein höherer Druck, so besteht die gesamte Exergie nicht nur aus dem exergetischen Anteil der Wärme, sondern zusätzlich aus einem Anteil Volumenarbeit.

Der thermische Wirkungsgrad der realen Wärmekraftmaschine ist also immer kleiner als 1 und – bedingt durch die von den Maschinen vorgegebene Prozessführung und die unvermeidlichen dissipativen Effekte – auch immer kleiner als der der idealen Wärmekraftmaschine:

wobei formula_40 die Umgebungstemperatur ist und formula_45 die mittlere Temperatur der Wärmezufuhr. Sie ergibt sich, wenn die gelbe Fläche der Exergie durch ein flächengleiches Rechteck oberhalb der Linie der Umgebungstemperatur ersetzt wird.

Der Zweite Hauptsatz hat somit erhebliche technische Auswirkungen. Da viele Maschinen, die mechanische Energie liefern, diese über einen Umweg aus thermischer Energie erzeugen (z. B. Dieselmotor: chemische Energie formula_46 thermische Energie formula_46 mechanische Energie), gelten für ihre Wirkungsgrade immer die Beschränkungen des 2. Hauptsatzes. Im Vergleich dazu bieten Wasserkraft­anlagen, die bei der Umwandlung keine Zwischenstufe über thermische Energie benötigen, erheblich höhere Wirkungsgrade.

Dieser Hauptsatz wurde von Walther Nernst im Jahr 1906 vorgeschlagen und ist auch als Nernst-Theorem bekannt. Er ist quantentheoretischer Natur und äquivalent zur Aussage von der Unerreichbarkeit des Nullpunktes der absoluten Temperatur:

Bei der Annäherung der Temperatur an den absoluten Nullpunkt (formula_48) wird die Entropie formula_49 unabhängig von thermodynamischen Parametern. Damit geht formula_49 gegen einen festen Grenzwert formula_51:

Die konstante Entropie bei formula_48 lässt sich als formula_54 darstellen, wobei formula_55 die Boltzmann-Konstante und formula_56 die Anzahl der möglichen Mikrozustände im Grundzustand (Entartung) ist. Zum Beispiel würde sich für einen formula_57-atomigen Kristall, dessen Atome im Energiegrundzustand zwei mögliche Spineinstellungen haben, formula_58 ergeben.

Für alle physikalisch-chemischen Reaktionen, bei denen die teilnehmenden Stoffe am absoluten Nullpunkt als ideale kristalline Festkörper vorliegen, gilt:

Es gibt nur eine Realisierungsmöglichkeit für ideale Festkörper am absoluten Nullpunkt, formula_60.

Die genannten Aussagen können mit Methoden der Quantenstatistik streng bewiesen werden.

Die Energiebilanz hat in der Thermodynamik einen hohen Stellenwert.

Bei einer Phasenumwandlung (fest-flüssig-gasförmig) oder Mischungen (Salz in Wasser, Mischung verschiedener Lösungsmittel) werden Umwandlungsenergien (Schmelzenthalpie, Verdampfungsenthalpie, Sublimationsenthalpie) oder Umwandlungsenthalpien benötigt bzw. werden in umgekehrter Richtung frei. Bei einer chemischen Stoffumwandlung können Reaktionswärmen oder Reaktionsenthalpien frei werden oder müssen umgekehrt zugeführt werden.

Zur Berechnung von frei werdenden Reaktionswärmen bei Stoffumsetzungen wird zunächst die entsprechende Reaktionsgleichung mit den dazugehörigen stöchiometrischen Faktoren aufgestellt. Die Standardbildungsenthalpien der Einzelstoffe sind für 25 °C in Tabellenwerken verzeichnet. Man addiert die Summe der Enthalpien der Produkte entsprechend den stöchiometrischen Faktoren und zieht davon die Enthalpien der Ausgangsstoffe ab (Hess’scher Wärmesatz).

Die Reaktions- oder Umwandlungsenthalpie, die bei einer chemischen Umsetzung oder Phasenumwandlung an die Umgebung abgegeben wird, hat ein negatives Vorzeichen. Ist eine Energiezufuhr von der Umgebung für eine Phasenumwandlung oder eine chemische Umsetzung nötig, so hat diese ein positives Vorzeichen.

Die Zustandsgröße Enthalpie ist, ausführlich:

Die Freie Enthalpie ist

Durch Bildung des totalen Differentials der Freien Enthalpie und anschließende Integration lässt sich berechnen, ob eine chemische Umsetzung möglich ist.

Ist die Differenz der Freien Enthalpien formula_64 der Produkte zu den Ausgangsstoffen (Edukte) "negativ", ist eine Phasenumwandlung oder eine Stoffumsetzung möglich. Ist die Differenz der Freien Enthalpie einer Reaktion, einer Phasenumwandlung negativ, erfolgt eine Reaktion – soweit diese nicht kinetisch gehemmt ist – bis zu einem Punkt, an dem formula_65 wird.
Das Massenwirkungsgesetz ist ein Spezialfall eines solchen Gleichgewichtes. Ist die Differenz der Freien Enthalpie "positiv", so ist eine Reaktion oder Phasenumwandlung unmöglich.

Im Jahr 1869 glaubte Marcellin Berthelot noch, dass nur chemische Umwandlungen möglich seien, bei denen Wärme frei wird. Mittlerweile sind Umwandlungen und Reaktionen bekannt, bei denen keine Reaktionswärme oder Umwandlungswärme frei wird. Dies liegt am Entropieterm formula_66

Beispiele:


Neben der klassischen Gleichgewichtsthermodynamik wurde im 20. Jahrhundert die "Nichtgleichgewichtsthermodynamik" oder auch "Thermodynamik irreversibler Prozesse" entwickelt. Für diese Arbeiten wurden die Nobelpreise der Chemie im Jahr 1968 an Lars Onsager und 1977 an Ilya Prigogine verliehen.

Die klassische Thermodynamik macht über Nichtgleichgewichts­prozesse nur die qualitative Aussage, dass diese nicht umkehrbar sind, beschränkt sich aber in ihren quantitativen Aussagen auf Systeme, die stets global im Gleichgewicht sind bzw. nur inkrementell davon abweichen. Demgegenüber behandelt die Nichtgleichgewichtsthermodynamik Systeme, die sich nicht in einem globalen thermodynamischen Gleichgewicht befinden, sondern davon abweichen. Oft wird jedoch noch ein "lokales" thermodynamisches Gleichgewicht angenommen.

Ein wichtiges Ergebnis der Nichtgleichgewichtsthermodynamik ist das Prinzip der minimalen Entropieproduktion für offene Systeme, welche nur wenig vom thermodynamischen Gleichgewicht abweichen. Dies ist der Bereich der so genannten "linearen irreversiblen Thermodynamik". Sie beschreibt in einem vereinheitlichten formalen Rahmen lineare Zusammenhänge zwischen "Flüssen" und ihren "korrespondierenden Kräften". Diese Kräfte werden normalerweise als Gradienten einer skalaren Größe aufgefasst und die Flüsse durch bekannte lineare Naturgesetze beschrieben, wie zum Beispiel das "ohmsche Gesetz" (Stromfluss), das "Ficksche Gesetz" (Diffusion), das "Fouriersche Gesetz" (Wärmeleitung) oder die "Kinetik" einer chemischen Reaktion (Reaktionsgeschwindigkeit). Durch die Bilanzierung der Entropie, in die die "Produktion" der Entropie in dem System und die über die Systemgrenzen fließende Entropie eingehen, lässt sich durch den zweiten Hauptsatz die Invarianz dieser Gesetze zeigen. Für das Beispiel der Wärmeleitung zeigt sich, dass mit der Thermodynamik nur ein Wärmefluss vom heißen zum kalten vereinbar ist, und dass die Wärmeleitfähigkeit immer eine positive Größe sein muss. Durch die mathematische Analyse wird außerdem gezeigt, dass eine "thermodynamische" Kraft (z. B. Temperaturdifferenz oder Spannungsdifferenz) in einem System einen zusätzlichen indirekten Fluss verursacht (Beispiel: elektrischer Stromfluss verursacht durch Wärmeleitung ("Seebeck-Koeffizient"), oder Wärmestrom verursacht durch einen elektrischen Stromfluss ("Peltier-Koeffizient")). Von Lars Onsager wurde gezeigt, dass die Einflüsse zwischen Flüssen und den nicht dazu korrespondierenden Kräften gleich groß sind ("Reziprozitätsbeziehungen"). Da die Entropiebilanz in einem geschlossen System immer positiv sein muss, folgt zusätzlich: Die Größe der Kreuzeffekte ist immer wesentlich kleiner als die direkten Effekte. Für das Beispiel mit den zwei Kräften gilt, dass die Kreuzeffekte (Peltier-Koeffizient und Seebeck-Koeffizient) maximal zweimal der Wurzel aus den Produkten der Koeffizienten der beiden direkten Effekte (elektrische und thermische Leitfähigkeit) entspricht.

Weicht ein offenes System stark vom Gleichgewicht ab, kommt die "nichtlineare" Nichtgleichgewichtsthermodynamik zum Zug. Wichtiges Ergebnis in diesem Bereich ist das Stabilititätskriterium von Ilya Prigogine und Paul Glansdorff, das angibt, unter welchen Bedingungen der Zustand mit der minimalen Entropieproduktion instabil wird und ein System bei gleichzeitigem Entropieexport eine höher geordnete Struktur annehmen kann. In diesem Bereich können also spontan so genannte dissipative Strukturen entstehen, die experimentell bestätigt wurden (beispielsweise Bénard-Zellen). Da in diesem nichtlinearen Bereich auch biologische Prozesse anzusiedeln sind, ist dieses Resultat besonders auch in Hinsicht auf die Entwicklung des Lebens von großer Bedeutung.











</doc>
<doc id="5053" url="https://de.wikipedia.org/wiki?curid=5053" title="Tag">
Tag

Der Tag (mhd. "tag tac", asächs. "dag", got. "dags", urgerm. "*dagaz") wird in verschiedener Weise als vom scheinbaren Lauf der Sonne um die Erde bestimmter Zeitbegriff verwendet.


Der mittlere Sonnentag ist 24 Stunden lang. Seine gleichmäßig lange Stunde wird in 60 gleichmäßig lange Minuten und die Minute in 60 gleichmäßig lange Sekunden unterteilt. Die Sekunde – der 86.400-ste Teil des mittleren Sonnentages – ist die Zeiteinheit des Internationalen Einheitensystems (SI).









Ausgehend von dem Grundkonzept – in Bezug auf die Phase der Belichtung an einem Aufenthaltsort einen zeitlichen Verhalt anzugeben – sind eingeschränkte oder erweiterte, besondere und allgemeine Begriffe des Tages entwickelt worden:


Die Benennung Tag wird also sowohl für Zeitspannen wie für Maßeinheiten verwendet.

Unterschiedliche Definitionen der Tagesgrenzen – ob dies nun der wahre, scheinbare oder mittlere Aufgang, Untergang oder Durchgang von Rand oder Mitte der Sonne als ein beobachtetes, errechnetes, festgelegtes oder verkündetes Datum sei – sowie verschiedene für präzise Zeitbestimmungen zu berücksichtigende Umstände – wie die Zeitgleichung, Zeitzonen, Schalttage, Schaltsekunden, Referenzorte und Referenzsysteme – führen dazu, dass beispielsweise auch der Anfang eines Kalendertages abhängig vom kulturellen Kontext anders gesetzt werden kann.

Die Begriffe Tag und Nacht können damit einzeln oder zusammen je verschieden gefasst werden. Dem Begriff des "lichten Tags" – tagsüber gegenüber nachts – entspricht als veränderter Sonnenstand idealisiert der astronomische Begriff "Tagbogen der Sonne".

Im Messwesen wird eine Maßeinheit „Tag“ der physikalischen Größe Zeit (Dauer) als ein bestimmtes Vielfaches der Basiseinheit Sekunde des Internationalen Einheitensystems (SI) definiert. Das Einheitenzeichen ist der kleine Buchstabe „d“, nach dem lateinischen Wort "dies" für Tag.
Zeit kann in Tagen mit Stunden und Unterteilungen, oder in Tagesbruchteilen angegeben werden.

Die Einheit „Tag“ gehört zwar nicht zum Internationalen Einheitensystem (SI), ist zum Gebrauch mit dem SI aber zugelassen. Sie ist außerdem, ebenso wie Stunde und Minute, gesetzliche Maßeinheit gemäß der EU-Richtlinie 80/181/EWG (Einheitenrichtlinie) sowie auch gemäß der deutschen und der Schweizer Einheitenverordnung. Die Definition ist so gewählt, dass „d“ ungefähr der mittleren Dauer von sonnenbezogenen Tagen auf der Erde entspricht.

Da die natürlich auftretenden Sonnentage infolge der periodischen Schwankungen und auch wegen nicht periodischer Verschiebungen ja verschieden lange dauern, ergeben sich denn Differenzen zu einem Bezugsmuster, dem die Maßeinheit „d“ als Standard für Tag zugrunde gelegt wird. Erst mit einem Referenzsystem im Hintergrund kann dann für die unterschiedlichen Zeitspannen tatsächlicher Tage über die Zeitgleichung ein wiederholbares Zeitmaß konstruiert, auf eine Maßeinheit bezogen und durch Schaltsekunden gegebenenfalls angepasst werden.

In ähnlicher Weise wird heute die Koordinierte Weltzeit (UTC) gebildet.

Der Kalendertag ist in der Kalenderrechnung als "Zeitspanne" neben dem Kalenderjahr und bisweilen dem Kalendermonat die grundlegende Größe.

In dem heute weltweit gebräuchlichen gregorianischen Kalender ist ein Tag die Zeitspanne von einer Mitternacht bis zur nächsten Mitternacht.

Eine Kombination wie "5. Mai", also bestimmt durch Monat und Tagesnummer, aber ohne Jahr, nennt man einen "Kalendertag".

Die Kalendertage werden nach der ISO 8601 innerhalb eines Monats von „1“ ausgehend als Kalenderdatum fortlaufend nummeriert und in einem Datumsformat schriftlich fixiert. Außerdem wird ihnen, von Monat und Jahr unabhängig, in fester Reihenfolge ein Wochentag zugewiesen. Damit beschreibt das Datum des Tages eine fortlaufende Zeitskala "(lineare Zeit)", in Unterscheidung zum Wochentag, das sich in seinem Ablauf regelmäßig wiederholt "(zyklische Zeit)".

Beginn und Ende eines solchen Tages sind abhängig von der Zeitzone, auf die sich die Angabe bezieht.

Der Tagesbeginn um "Mitternacht" ist eine Übereinkunft angelehnt an Konventionen der Astronomie. Andere Kalendersysteme setzen den Tagesbeginn auf den "Sonnenaufgang". Im jüdischen und islamischen Kalender umfasst der Tag die Zeit von einem "Sonnenuntergang" bis zum nächsten Sonnenuntergang. Diese Auffassung war im europäisch-vorderasiatischen Raum insgesamt lange vorherrschend. Die römische Zählung der Nachtstunden "(vigiliae)" und bestimmte Elemente des christlichen Ritus können als Beispiele genannt werden. Das bekannteste Beispiel dürfte der Beginn des Weihnachtsfestes (25. Dezember) bereits an seinem Vorabend sein, der nach moderner Rechnung noch zum 24. Dezember gehört (Heiligabend). Die Setzung des Tagesbeginns auf den Sonnenuntergang ist besonders in Kombination mit Mondkalendern zweckmäßig, bei denen der Monat ebenfalls abends mit der dann sichtbaren neuen Mondsichel beginnt.

Noch heute werden viele Feiertage schon am Vorabend begangen, zum Beispiel als Heiligabend oder Nikolausabend, denn in manchen früheren Kalendern im europäischen Raum begann der neue Tag ähnlich wie in jüdischen und islamischen Kalendern nicht erst um Mitternacht, sondern schon mit der lokalen Abenddämmerung, und so ein Feiertag mit dem Feierabend.

"Siehe auch:"

Eine Besonderheit sind die synodischen lunaren Tage "Tithi" der vedischen Zeitrechnung, die in ihrer Dauer zwischen 19 und 26 Stunden variieren, mit 1 "masa" (Lunarmonat) = 30 "tithi"

Herkömmlich wird die Dauer eines "Tages" definiert als jener Zeitumfang, den die Erde oder ein Himmelskörper braucht, um eine einzelne Drehung in Bezug auf einen Stern zu vollziehen, präzise gemessen von einer Kulmination zur nächsten beziehungsweise zwischen einem Meridiandurchgang und dem nachfolgenden gleichartigen. In Hinsicht auf einen fernen Stern, als fixiert angenommen, ist dies ein Siderischer Tag und gleichwertig einer vollständigen Umdrehung des Körpers um sich selbst. Im Hinblick auf die Sonne, bezogen als zentrales Gestirn, ist solch ein Sonnentag nicht gleich einer ganzen Rotationsperiode des Körpers um seine Achse – denn der Lauf um die Sonne bringt ja für sich genommen während des jährlichen Umlaufes schon einen Tag-Nacht-Zyklus hervor.

Es gibt verschiedene dem Kalendertag ähnliche Größen, die ihren Ursprung in den komplexen Bewegungen der Himmelskörper und den verschiedenen Bezugspunkten himmelsmechanischer Berechnungen haben:







Für die Festlegung der Weltzeit oder zum Auffinden von Sternörtern wird die Sonnenzeit beziehungsweise die Sternzeit in Referenz auf den Nullmeridian angegeben.

In allgemeinerer Form wird unter einem Tag die Zeitspanne zwischen zwei aufeinanderfolgenden gleichen oder vergleichbaren Belichtungsphasen auf einem Himmelskörper verstanden. Bezogen auf dessen Belichtung durch das umlaufene Zentralgestirn ergibt sich ein Tag dann, wenn die Rotationsbewegung des Körpers und seine Umlaufbewegung zueinander ins Verhältnis gesetzt werden nach ihrer Dauer, Ebene und Richtung.

So gibt es neben dem Tag auf der Erde beispielsweise auch einen „Marstag“ („Sol“ genannt) und einen „Merkurtag“; gemessen in irdischen Zeitnormen – d als Maßeinheit Tag auf Basis der SI-Sekunde – dauert ein Tag auf dem Mars etwa 24 Stunden und 40 Minuten und auf Merkur etwa 176 Tage d. Der „Mondtag“ als Tag auf dem Erd-Mond ist im Mittel etwa 29,53 Tage d lang; diesem entspricht dann eine Periode der Mondphasen, wenn sie von der Erde aus betrachtet werden – von einem Neumond bis zum nächsten Neumond ist das gleich einem synodischen Monat.

Da die Rotation der Erde im Laufe der Zeit abgebremst wird – insbesondere durch Gezeitenwirkungen des Mondes – werden künftige Erdtage tendenziell länger; umgekehrt dauerte ein Tag auf der Erde früher nicht so lange wie heute. Vor etwa 600 Millionen Jahren vollzog die Erde eine volle Drehung um sich selbst in etwa 22 heutigen Stunden. Da der Umlauf um die Sonne etwa genauso lange wie heute dauerte, hatte ein Jahr damals knapp 400 Sonnentage. Belege dafür finden sich unter anderem in den zyklisch abgelagerten Sedimenten (Warven) präkambrischer Gesteine.

Für die sehr junge Erde vor etwa 4,5 Milliarden Jahren ergaben numerische Simulationen eine Tagesdauer von etwa 6 Stunden. Die Verhältnisse noch früherer Zeiten vor der Entstehung des Mondes und einer mutmaßlich vorangegangenen Kollision des hypothetischen Protoplaneten Theia mit der Proto-Erde lassen sich nur schwer rekonstruieren.

Im täglichen Leben wird der "subjektive Tag", englisch auch "awake time period", durch den Rhythmus von Aufstehen und Schlafengehen bestimmt. Der Tag wird oft in die Abschnitte Morgen, Vormittag, Mittag, Nachmittag, Abend und Nacht gegliedert.

Biologische Rhythmen treten mit verschiedener Periodendauer auf – mehrere Jahre, etwa ein Jahr oder ein Monat oder ein Tag oder auch kürzere, ultradiane Zeitspannen – und können als wiederholte Muster der Anpassung innerer Zustände an äußere Umstände verstanden werden. Dabei wird die Änderung der inneren Prozessbereitschaft eines Organismus als endogener Rhythmus organisiert und über gewisse Signale an die zeitlichen Schwankungen im Ablauf von Veränderungen seiner Umgebung gekoppelt. Verändert sich die Umgebung kaum oder fehlen entsprechende externe Signale, so läuft der endogene Rhythmus frei mit einer eigenen Periodenlänge. Beträgt die ungefähr einen Tag, wird von Circadianem Rhythmus gesprochen. Erzeugt wird dieser endogene Circadiane Rhythmus in einem Organismus – man findet ihn bei Pflanzen und Tieren wie dem Menschen – durch ein schwingendes Teilsystem, Oszillator oder Innere Uhr genannt, das als Schrittmacher fungierend nun mögliche Takte als Phase vorgibt, deren Länge oder Intervall dann über äußere Reize, Zeitgeber genannt, feiner abgestimmt wird. Dadurch können innere und äußere Verhältnisse hinsichtlich ihrer zeitlichen Struktur in Einklang gebracht werden und so synchron sein wie innere Schwingungen veränderten äußeren Schwankungen angeglichen wurden (Entrainment).

Die meisten chronobiologisch untersuchten Lebewesen konstruieren den passenden tatsächlichen Tagesrhythmus mit Licht als dem wichtigsten Zeitgeber; für die Organisation passender natürlicher Bezüge wirkt also das Licht des Tages zeitgebend.

Daher bildet der lichte Tag auch die Basis der sozialen und subjektiven Tagesbegriffe: Bis zur Einführung künstlicher Beleuchtung musste für fast alle Arbeiten das natürliche Licht ausgenutzt werden – in vielen Branchen und auch Weltgegenden bis heute.
Für die überwiegende Mehrzahl der Menschen fallen innerlich erlebter subjektiver Tag und äußerlich verlangter „objektiver“ Zeitbezug wenig auseinander. In den gemäßigten Breiten korrespondiert allerdings der Tagesablauf gegenwärtig zumeist nicht mehr mit dem lichten Tag; im Sommerhalbjahr erwacht man im Allgemeinen erst lange nach Tagesanbruch, im Winter wird man schon vorher wach – und während die Sonne über dem Horizont steht, halten sich viele Menschen gar nicht im Freien auf. Das wird als eine der Ursachen der saisonalen Depression (Winterdepression) gesehen; die Stärke künstlicher Beleuchtung beträgt nur Bruchteile der Leuchtdichte eines natürlich hellen Tages.

Weniger leicht ist die Situation für Menschen, deren subjektiver Tag oft oder regelmäßig nicht dem bürgerlichen Tagesablauf "(sozialer Tag)" folgt. Nach Schichtarbeit bis, über oder ab Mitternacht empfinden manche dieser Personen intuitiv die nachfolgende Zeit als zum vorhergehenden Tag gehörig. Die Verschiebung zum Kalendertag fällt ihnen dann etwa beim Verfassen schriftlicher Datumsangaben auf. Problematischer aber ist die Verschiebung des Schlafrhythmus gegen den lichten Tag, die auch zu gesundheitlichen Störungen "(Schichtarbeitersyndrom)" führen kann. Bei manchen Zirkadianen Schlaf-Wach-Rhythmusstörungen verschiebt sich der persönliche Tag so weit, dass er sich mit dem nächsten sozialen Tag überschneidet. Menschen, deren persönlicher Tag als individueller Lebensstil permanent gegenüber dem lichten Tag verschoben scheint, bezeichnet man als Nachtmenschen.

Eine andere Problematik ergibt sich aus der möglichen Zeitverschiebung gegenüber anderen Zeitzonen. Im modernen Alltag helfen Zeitzonenuhren abzuklären, welcher Tag an anderem Ort "heute" ist, oder es werden E-Mails in UTC datiert und erst vor Ort umgerechnet. Bei Fernreisen in andere Zeitzonen kann aufgrund des fehlenden Entrainments der inneren Uhr ein Jetlag auftreten.


</doc>
<doc id="5054" url="https://de.wikipedia.org/wiki?curid=5054" title="Tesla (Einheit)">
Tesla (Einheit)

Das Tesla (T) ist eine abgeleitete SI-Maßeinheit für die magnetische Flussdichte. Die Einheit wurde im Jahr 1960 auf der "Conférence Générale des Poids et Mesures" (CGPM) in Paris nach Nikola Tesla benannt.

Im CGS-System, das vor allem noch in der theoretischen Physik verwendet wird, ist die entsprechende Einheit Gauß:

Die Geophysik benutzte auch die Einheit Gamma (γ):

Beispiele für verschiedene magnetische Flussdichten in der Natur und in der Technik:


</doc>
<doc id="5055" url="https://de.wikipedia.org/wiki?curid=5055" title="Torr">
Torr

Das Torr (Einheitenzeichen: Torr) oder die Millimeter-Quecksilbersäule, Einheitenzeichen: mmHg (früher auch und aktuell in der Schweiz nur Millimeter Quecksilbersäule) ist eine Maßeinheit des Druckes. Ein Torr ist der statische Druck, der von einer Quecksilbersäule von 1 mm Höhe erzeugt wird. Normaler Luftdruck entspricht einer Quecksilbersäule von 760 Millimeter. 

Das mmHg ist keine SI-Einheit, aber in den Staaten der EU und der Schweiz eine gesetzliche Einheit, zulässig für den Anwendungsbereich „Blutdruck und Druck anderer Körperflüssigkeiten“. 

Das Torr ist benannt nach Evangelista Torricelli (einem Assistenten Galileo Galileis), der das Quecksilberbarometer erfand.


Damit ist formula_2

Die Millimeter-Quecksilbersäule – nicht das Torr – ist in der Europäischen Union und in der Schweiz (dort ohne Bindestrich geschrieben) gesetzliche Einheit bei der Angabe von Drücken von Körperflüssigkeiten, insbesondere Blutdrücken. Die Weltorganisation für Meteorologie (WMO) hatte 1954 für ihren Bereich festgelegt, dass der Druck 1 mmHg am Orte der Normfallbeschleunigung (9,80665 m/s²) bei 0 °C gilt. Ein Blutdruck von »120 zu 80« entspricht etwa einem systolischen Druck von 16 kPa (oder 160 mbar bzw. hPa) und einem diastolischen von 10,6 kPa (oder 106 mbar bzw. hPa), wobei hier nicht der absolute, sondern der relative Druck (gegenüber dem Luftdruck) gemeint ist.

Die Einheit war früher unter anderem in der Physik und der Meteorologie (Luftdruck) gebräuchlich; in Deutschland und Österreich sind das Torr und die konventionelle Millimeter-Quecksilbersäule seit 1. Januar 1978 nicht mehr allgemein zulässig. Drücke von Körperflüssigkeiten dürfen in der Medizin weiterhin in „mmHg“ angegeben werden. Nur in der Thermodynamik ist es ansonsten teilweise noch üblich, Drücke in „mmHg“ anzugeben. 

In der Schweiz wird die Einheit cmHg (Zentimeter Quecksilbersäule) als Unterdruckanzeige der Vakuumbremse bei Eisenbahnen verwendet. 

In den USA ist Torr neben psi die gängigste Druckeinheit.

Der Zusammenhang 1 Torr = 1 mmHg gilt streng nur bei einer Temperatur von 0 °C und bei Normfallbeschleunigung, da die Dichte von Quecksilber temperaturabhängig ist und die Gewichtskraft von der geographischen Länge und Breite abhängt. Noch strenger genommen gilt dies in Deutschland nicht; die offiziellen Umrechnungsbeziehungen sind hier 1 mmHg = 133,322 Pa und 1 Torr = (101325/760) Pa = 133,322368… Pa.

Für die konventionelle Millimeter-Quecksilbersäule ist heute nur noch das Einheitenzeichen „mmHg“ gebräuchlich, früher wurden auch „mm“, „mm Hg“ (nur so noch in der Schweiz) und „mm“ bzw. „mmQS“ benutzt.


</doc>
<doc id="5056" url="https://de.wikipedia.org/wiki?curid=5056" title="Temperatur (Begriffsklärung)">
Temperatur (Begriffsklärung)

Temperatur (von lat. "temperare" „ins richtige Mischungsverhältnis bringen“) steht für: 

Siehe auch:


</doc>
<doc id="5057" url="https://de.wikipedia.org/wiki?curid=5057" title="The Cure">
The Cure

The Cure ist eine britische Pop-/Rock-/Wave-/Gothic-Band, die 1976 im südenglischen Crawley als Malice gegründet wurde. Zunächst spielte Robert Smith nur Gitarre. Nach dem Ausstieg einiger Mitglieder benannte sich die Band 1977 zunächst in Easy Cure und 1978 schließlich in The Cure um. Seit diesem Zeitpunkt fungiert Robert Smith, der mit seinen toupierten Haaren und seinem geschminkten Gesicht zur Identifikationsfigur der Gruppe wurde, als Bandleader, Komponist und Sänger. Er ist außerdem das einzig dauerhafte Mitglied.

1976 gründete Robert Smith im Alter von 17 Jahren zusammen mit seinen Klassenkameraden Michael Dempsey (Bass), Lol Tolhurst (Schlagzeug) und Porl Thompson (Gitarre) von der "St. Wilfrid's Catholic Comprehensive School" in Crawley, Sussex, die Band Malice. Im Jahr 1977 spielte die Band als Easy Cure bei der Plattenfirma Hansa Records vor und erhielt einen Vertrag zur Aufnahme einer Single, die jedoch nie erschien. Im Jahr 1978 trennte sich Porl Thompson aufgrund künstlerischer Differenzen von der Band. Die Band benannte sich in The Cure um und unterschrieb einen Vertrag bei dem gerade gegründeten Label Fiction Records. Die erste Single, "Killing an Arab", erschien im Dezember zunächst auf dem kleinen Indie-Label Small Wonder und wurde 1979 von Fiction Records neu aufgelegt. Auch wenn sich die Band aufgrund des Titels teils starken Anfeindungen ausgesetzt sah, hat das Stück keinerlei ausländerfeindlichen Bezug, sondern entstand nach der Lektüre von "Der Fremde" des Existenzialisten Albert Camus. Die Single (B-Seite: "10:15 Saturday Night") wurde von der Musikzeitschrift "New Musical Express" (NME) zur Single der Woche erhoben und machte den BBC-DJ John Peel auf die Band aufmerksam.

1979 veröffentlichte The Cure ihr erstes Album "Three Imaginary Boys", welches stilistisch zwischen dem Punk der 70er-Jahre und dem New Wave der 80er-Jahre steht. Dieses Album erreichte nach der Veröffentlichung Platz 44 der englischen Charts und erntete gute Kritiken in den englischen Musikzeitschriften. Der "Melody Maker" betitelte seine Kritik mit der Überschrift "The 80's start here". Die Band selbst war mit dem Album nicht zufrieden, da sie relativ wenig Kontrolle über die Zusammenstellung der Lieder und das Artwork hatte. So ist auf dem Album die Coverversion des Jimi-Hendrix-Stücks "Foxy Lady" zu finden, welches eigentlich nur als Soundcheck aufgenommen wurde. Auf "Three Imaginary Boys" folgten als Einzelveröffentlichungen die Singles "Boys Don’t Cry" und "Jumping Someone Else's Train". Außerdem erschien die Single "I’m a Cult Hero" des Nebenprojektes Cult Hero mit Frank Bell als Sänger. "Boys Don’t Cry" war in den USA ein kleinerer Hit, sodass Anfang 1980 "Fiction Records" in den USA das Album "Boys Don’t Cry" herausbrachte, welches eine Wiederveröffentlichung von "Three Imaginary Boys" mit leicht veränderter Tracklist und anderem Artwork darstellt. So sind auf dem Album die zuvor erwähnten Singles zu finden, sowie "World War", ein Lied, das Robert Smith später als "terrible piece of rubbish" bezeichnete.

Für das nächste Album hatte Robert Smith Pläne, die bei dem Bassisten Dempsey auf Widerstände stießen, woraufhin dieser zu den "Associates" wechselte, die beim gleichen Label und mit The Cure auf Tour waren. Dafür kamen Simon Gallup am Bass sowie Mathieu Hartley am Keyboard als neue Mitglieder in die Band. Anfang 1980 erschien das Album "Seventeen Seconds". Es war erfolgreicher als "Three Imaginary Boys" und erreichte Platz 20 in den englischen Charts. Die Single "A Forest" stieg bis auf Platz 31 der Single-Charts und wurde später live immer wieder gegenüber der Studioversion ausgedehnt und mit Improvisationen angereichert. Live verwendete Sänger Smith inzwischen Lippenstift, was von nun an zu seinem Markenzeichen wurde. Außerdem half Smith bei der Band Siouxsie and the Banshees als Gitarrist aus.

1981 erschien das dritte Album "Faith". Der Keyboarder Hartley hatte die Band inzwischen verlassen. Der Tod und der Glauben waren wiederkehrende Themen des Werks, nach Angaben von Smith waren es Todesfälle in seinem Umkreis, die zur depressiven Grundstimmung des Albums führten. Die Single "Primary" war ein poppiger, treibender Song über Unschuld und das Älterwerden. Seit dieser Zeit prägte ein sechssaitiger Fender-Bass (Fender VI, eine um eine Oktave tiefer gestimmte Gitarre) viele Stücke von The Cure. Die Kassettenversion von "Faith" enthielt auf der B-Seite den 23-minütigen Instrumental-Soundtrack "Carnage Visors", welcher offiziell erst 2005 wiederveröffentlicht wurde.

1982 erschien das Gothic-Album "Pornography". Die depressive Stimmung wurde besonders verdeutlicht durch die erste Zeile des ersten Lieds "One Hundred Years": "„It doesn’t matter if we all die“". Adam Sweeting, Journalist der Zeitschrift "Melody Maker", umschrieb die Musik von "Pornography" seinerzeit mit den Worten "„It’s downhill all the way into ever-darkening shadows...“". Der fortdauernde Drogenmissbrauch und das anstrengende Tour-Leben forderten schließlich ihren Tribut: Es kam zum Streit. Simon Gallup schied aus der Band aus und gründete die Gruppe Cry, aus der später Fools Dance hervorging. 1985 erschien unter diesem Namen eine gleichnamige EP, die sich stilistisch an den frühen The-Cure-Werken orientiert.

In dieser Zeit änderte sich der Sound von The Cure: Es erschienen Singles wie "Let’s Go to Bed", "The Walk" und das jazzige "The Lovecats", die alle zusammen auf dem Album "Japanese Whispers" veröffentlicht wurden. Smith wollte diese Singles ursprünglich nicht unter dem Namen The Cure veröffentlichen, da er der Meinung war, dass sie eigentlich nichts mit The Cure zu tun hätten: „es sind einfach nur Singles und kein Album“. Mit dem Video zu "Let’s Go to Bed" beginnt die langjährige Zusammenarbeit der Band mit dem Regisseur Tim Pope. Nach einer Wette mit Parry: Sollte "Let’s Go to Bed" kein Top-20-Hit werden, wovon Parry fest überzeugt war, würde er Smith entgegen seinen Verträgen ein Solo-Album aufnehmen lassen. So wurde ihm die Zusammenarbeit mit dem Siouxsie-and-the-Banshees-Mitglied Steve Severin unter dem Namen The Glove gestattet.
Während Smith sich seinem Projekt The Glove und Siouxsie and the Banshees widmete, produzierte das einzig neben ihm verbliebene The-Cure-Mitglied Lol Tolhurst die ersten beiden Singles und das Debütalbum der englischen Band And Also the Trees.

1984 folgte das Album "The Top" (Robert Smith: Gesang und Instrumente; Laurence Tolhurst: weitere Instrumente; Andy Anderson: Schlagzeug und Perkussion; Porl Thompson: Saxophon (auf "Give Me It")). Phil Thornally spielte nicht, wie manchmal behauptet wird, den Bass auf "The Top"; er war während der Aufnahmen zu diesem Album als Toningenieur bei der Gruppe Duran Duran beschäftigt. "The Top" experimentierte mit einer Reihe von Stilmitteln wie arabisch beeinflussten Melodien und Marsch-Rhythmen. Ebenfalls 1984 erschien das Live-Album "The Cure – Live in Concert" (mit Phil Thornally am Bass). Wie zuvor bei "Faith" ist die Kassettenversion erheblich länger als die LP oder CD und enthält unter dem Titel "Curiosity" zehn zusätzliche Demo- und Live-Aufnahmen, die erst nur hier veröffentlicht wurden und 2005 teilweise auf den so genannten Deluxe-Editions von "Three Imaginary Boys", "Seventeen Seconds", "Faith" und "Pornography" erschienen.

Wiederum änderte sich die Besetzung – heraus kam die Konstellation Smith, Porl Thompson (Gitarre), Gallup (wieder zurück am Bass), Boris Williams (Schlagzeug, vormals Mungo Jerry) und Tolhurst (Keyboards). 1985 veröffentlichten sie das Album "The Head on the Door", das sie mit den Singles "Inbetween Days" und "Close to Me" auskoppelten.

Das darauf erschienene Album "Standing on a Beach" (CD-Titel: "Staring at the Sea") beinhaltet alle bis dahin erschienenen Singles. Die um zwölf Stücke erweiterte Kassettenversion "(The Unavailable B-Sides)" enthält dieses Mal alle zugehörigen B-Seiten. Als zugehörige Singles wurden 1986 eine neu abgemischte Version von "Boys Don’t Cry" und zum zweiten Mal "Charlotte Sometimes" sowie "Let’s Go to Bed" veröffentlicht. Unter dem Namen "Staring at the Sea" erschien auch eine Video-Compilation der von 1978 bis 1986 erschienenen Singles.

1987 stieß der Keyboarder Roger O’Donnell zur Band, und The Cure veröffentlichte das Doppel-Album "Kiss me Kiss me Kiss me". Es beinhaltet unter anderem den gitarrenlastigen Opener "The Kiss" (Smith: „Einer der schrecklichen Songs, die ich für "Pornography" immer gesucht hatte.“), das balladeske "How Beautiful You Are", das saxophon-getriebene "Icing Sugar", das funkige "Hot Hot Hot!!!" und die Pop-Single "Just Like Heaven".

1988 heiratete Smith seine langjährige Freundin Mary Poole.

Im Jahr 1989 kam das Album "Disintegration" heraus. Das Album erreichte Platz 3 der britischen Album-Charts und stellt eine Rückbesinnung auf die Grundstimmung der frühen Alben "Faith" und "Pornography" dar. Die daraus ausgekoppelten Singles "Pictures of You", "Lullaby", "Lovesong" und das treibende "Fascination Street" erzielten ähnliche Erfolge. Später verließen jedoch sowohl Tolhurst als auch O’Donnell die Band. Dafür kam der langjährige Roadie Perry Bamonte ans Keyboard. Später erschien das zunächst limitierte und für karitative Zwecke gedachte Live-Album "Entreat", aufgenommen in der Wembley-Arena.

1990 erschien "Mixed Up", ein Doppel-Album mit Remixen diverser Cure-Singles und einer neuen Single, "Never Enough".

Ein Jahr später veröffentlichte die Band das "Wish"-Album. Unter dem Einfluss junger Noise-Bands wie Ride fiel es rockiger aus als "Disintegration"; das Spektrum reicht vom gitarrenlastigen Opener "Open", über Pop-Singles wie "High" und dem aggressiven "Cut" zur Ballade "To Wish Impossible Things". Der Sommerhit "Friday I’m in Love" ist bis heute die meistverkaufte Single der Band. The Cure lud die junge Indie-Band Cranes ein, die während der gesamten Tour als Vorgruppe spielten. Auch in den Folgejahren kam es wiederholt zur Zusammenarbeit beider Gruppen. Die "Wish"-Tour dokumentierten die Live-Alben "Show" und "Paris", wobei letzteres vor allem eher selten gespielte Songs aus der Ära vor 1983 enthält. Unter dem Titel "Show" brachte The Cure ähnlich dem 1986er "In Orange" einen Konzertfilm heraus, der zunächst weltweit durch ausgewählte Programmkinos tourte und danach auf Video erschien. 1994 wirkte die Band unter anderem mit dem Stück „Burn“ auf dem Soundtrack zu der Comic-Verfilmung The Crow – Die Krähe mit.

Danach wurde es eine Weile ruhiger um die Band. Williams und Thompson gingen und hinterließen eine Lücke. Thompson spielte zunächst als Gitarrist bei Page & Plant'. Für Thompson wechselte Bamonte an die Gitarren, Roger O'Donnell kehrte an die Keyboards zurück und ein neuer Schlagzeuger wurde per Anzeige gesucht.

Dies ist auf dem nächsten Album "Wild Mood Swings" zu verfolgen: die verschiedenen Songs wurden mit verschiedenen Drummern eingespielt. Schließlich entschied sich die Band für den jungen Jason Cooper. Erstmals setzte The Cure bei verschiedenen Liedern echte Streicher ein, was einigen Stücken einen für sie eher untypischen Sound ergab. Die Auswahl der ersten Single "The 13th", einem Stück mit Salsa-Elementen, wurde gemeinhin und zum Teil von Robert Smith selbst als unglücklich angesehen.

1997 erschien die Compilation "Galore" auf der alle Singles von 1987 bis 1997 enthalten sind. Der einzig neue Track darauf ist das an "Never Enough" erinnernde "Wrong Number". Außerdem wurde das Video "Galore – The Videos" veröffentlicht, auf dem alle Clips zu den Singles zu sehen sind.

Im Jahr 2000 veröffentlichte die Band ein neues Studioalbum namens "Bloodflowers", auf dem es mehr akustische Gitarren zu hören gab. Zu diesem Album wurden erstmals weder Singles ausgekoppelt noch Video-Clips produziert.

Ende 2001 beendeten The Cure mit der Veröffentlichung von "Greatest Hits" den Plattenvertrag mit Fiction/Polydor. Die Platte stellte nach Aussagen Smiths einen Kompromiss dar, da die Plattenfirma früher oder später auch ohne Einverständnis der Band eine Zusammenstellung ihrer größten Hits herausgebracht hätte. Da die Band noch unter Vertrag stand, hatte sie auf diese Weise wenigstens Mitspracherechte. So finanzierte sie die Bonus-CD, die Akustikversionen der Hits enthält, selbst, um den Fans einen Mehrwert zu bieten.

Im November 2002 gab The Cure drei "Trilogy"-Konzerte – eines in Brüssel und zwei in Berlin. An allen drei Abenden spielte die Band die Alben "Pornography" (1982), "Disintegration" (1989) und "Bloodflowers" (2000) in voller Länge und chronologischer Reihenfolge durch, jeweils unterbrochen von 20-minütigen Pausen. Die Band benutzte dabei zumeist die Instrumente, die zum Einspielen der Originalaufnahmen genutzt wurden. Am letzten "Trilogy"-Abend in Berlin verließ die Band erst nach viereinhalb Stunden die Bühne. Dieser Auftritt ist auf der im Juni 2003 erschienenen Doppel-DVD "Trilogy" dokumentiert, die einen Zusammenschnitt der Berlin-Konzerte enthält.

Zur gleichen Zeit unterschrieb The Cure einen Vertrag bei I AM Records, dem Label des Produzenten Ross Robinson, der als Entdecker und Förderer von Bands wie Korn und Limp Bizkit gilt. Dass vor allem junge Bands wie Interpol oder Mogwai in Interviews immer wieder The Cure als großen Einfluss bezeichnen, führte gegen Ende des Jahres zu einem regelrechten Hype um die Band, wohl auch ein Grund, dass Robert Smith im Oktober den "Inspirational Award" der britischen Musikzeitschrift "Q" entgegennehmen durfte. Zwischendurch nahm er an verschiedenen Nebenprojekten teil, etwa dem Dance-Remake des Cure-Klassikers "A Forest" von Blank & Jones.

Anfang 2004 begannen die Aufnahmen für das zwölfte Studioalbum in London, das ebenfalls von Ross Robinson produziert wurde. "The Cure", erschienen im April 2004, wurde trotz aller Voraussagen von Smith ein „klassisches“ Cure-Album mit der typischen Mischung aus Rocksongs und eher poppigem Material, wie den beiden Singleauskopplungen "The End of the World" und "Taking Off". Während der darauffolgenden Festivaltournee spielte The Cure auf den größten Open-Airs Europas und starteten danach ihr eigenes Festival in den USA namens "Curiosa". Zur Besetzung gehörten unter anderem Interpol, Muse, Melissa Auf der Maur, Mogwai und Thursday. Die Bands spielten in 25 Städten abwechselnd auf zwei Bühnen. Danach gab die Band noch vier Konzerte in Mexiko. Im September 2004 erhielt The Cure von MTV den ICON-Preis, mit dem Künstler für Ihren großen Einfluss auf die Popkultur gewürdigt werden. Zur Zeremonie in London spielten unter anderem die Deftones und blink-182 auf.

Im folgenden Jahr veröffentlichte The Cure dann die ersten der lange angekündigten "Deluxe Editions" aller Cure-Alben. Im Januar erschien "Three Imaginary Boys", drei Monate später folgten "Seventeen Seconds", "Faith" und "Pornography", die allesamt mit einer zweiten CD ausgestattet sind auf der neben Demo-Versionen bekannter Songs auch bisher unveröffentlichte Studio-Outtakes vertreten sind.

Ende Mai 2005 verließen der Keyboarder Roger O'Donnell und der Gitarrist Perry Bamonte die Band. Für ein paar Festivalauftritte kam wieder Porl Thompson an der Gitarre zum Einsatz. Der erste gemeinsame Auftritt fand beim Live-8–Konzert in Paris/Versailles statt.

Am 16. November 2005 kündigte Robert Smith auf der offiziellen Homepage an, dass man im Januar 2006 wieder ins Studio gehen werde, um ein neues Album einzuspielen. Porl Thompson entschloss sich nach guten Erfahrungen bei den Festivalauftritten dazu, wieder als vollwertiges Bandmitglied bei The Cure einzusteigen. In der Zwischenzeit veröffentlichte die Band weitere „Deluxe Editions“: "The Top", "The Head on the Door", "Kiss Me Kiss Me Kiss Me" und "Blue Sunshine" von "The Glove" (mit Robert Smith). Außerdem erschien die DVD "Festival 2005", die aus einen Zusammenschnitt von 30 Liedern der Festival-Tournee 2005 besteht.

Am 24. Oktober 2008 erschien das bereits für 2005 angekündigte, bislang letzte Studioalbum der Band mit dem Titel "4:13 Dream". Zuvor hatte die Band an jedem 13. Tag der Monate Mai bis August des Jahres eine Single veröffentlicht, die jeweils auch eine Non-Album-B-Seite enthielt. Den Anfang machte am 13. Mai "The Only One" mit der B-Seite "NY Trip". Weiter ging es am 13. Juni mit "Freak Show", B-Seite "All Kinds of Stuff", am 13. Juli mit "Sleep When I’m Dead", B-Seite "Down Under" sowie "The Perfect Boy" mit der B-Seite "Without You" am 13. August. Am 13. September folgte eine Remix-EP der vier Singles.

Obwohl alte Alben weiterhin als „Remastered Edition“ erscheinen, wie beispielsweise "Disintegration" am 28. Mai 2010, ist die Band derzeit (2011) ohne Plattenvertrag.

Seit Jahren engagiert sich The Cure für Amnesty International. Im Dezember 2005 haben die Bandmitglieder für die Amnesty-Kampagne "Make Some Noise" ein Cover des John-Lennon-Klassikers "Love" produziert.

Im Jahr 2011 gab die Band unter dem Titel "Reflections" zwei Konzerte im Sydney Opera House (31. Mai und 1. Juni 2011), ein Konzert am 15. November 2011 in London sowie je drei Konzerten in Los Angeles (21.-23. November 2011) und New York (25.-27. November 2011). Dem "Trilogy"-Konzept 2002 in Berlin folgend, nahm die Band diese zwei Konzerte zum Anlass, ihre ersten drei Alben "Three Imaginary Boys" (1979), "Seventeen Seconds" (1980) und "Faith" (1981) inklusive weiterer drei Zugabeblöcke live zu präsentieren und für eine spätere DVD-Veröffentlichung aufzunehmen. Für diese beiden Auftritte kamen zu der aktuellen Stammbesetzung Robert Smith, Simon Gallup und Jason Cooper auch die beiden ehemaligen Cure-Mitglieder Lol Tolhurst und Roger O'Donnell zurück auf die Bühne. Der erste Teil des Abends wurde als Trio bestritten, der zweite Teil als Quartett und der dritte Teil sowie die Zugaben als Quintett.

Am 10. September spielte The Cure auf dem „Bestival 2011“ in der Besetzung Robert Smith, Simon Gallup, Jason Cooper und Roger O'Donnell. Anfang Dezember wurde ein Konzertmitschnitt als Doppel-CD veröffentlicht („Bestival Live 2011“), der erste vollständige Live-Mitschnitt seit „In Orange“ (1988). Am gleichen Tag teilte Roger O'Donnell mit, dass er wieder offizielles Bandmitglied sei. Da der zweite Gitarrist Porl Thompson bei dem Auftritt sowie bei den "Reflections"-Konzerten nicht dabei war, nahm die Fangemeinde an, dass er nicht mehr Teil der Band ist, obwohl dies nicht offiziell bekannt gegeben wurde. Am 1. Mai 2012 wurde auf der Fan-Seite „Chain Of Flowers“ ein Kommentar von Thompson veröffentlicht, das den erneuten Ausstieg von ihm bestätigt.

Im Jahr 2012 spielten The Cure Konzerte auf 19 europäischen Festivals. Als zweiten Gitarristen heuerten sie Reeves Gabrels an. Reeves Gabrels war früher Mitglied von David Bowies Band Tin Machine und arbeitete Ende der 1990er Jahre mit The Cure (bei "Wrong Number") und insbesondere Robert Smith zusammen (Nebenprojekt "Cogasm", gegenseitige Mitwirkung an einzelnen Songs).

Im April 2013 tourten The Cure durch Lateinamerika. Der Höhepunkt war das Konzert in Mexiko am 21. April 2013, bei dem die Band kurz nach einem Erdbeben vor 57.304 Besuchern vier Stunden lang spielte. Auf den insgesamt acht Stationen gab es fast 150.000 Besucher. Die Konzerte wurden von Tim Pope gefilmt, der in den 1980er Jahren eine Vielzahl von The-Cure-Musikvideos gedreht hatte. Eine spätere Veröffentlichung ist geplant.

Darauf folgten fünf Konzerte, überwiegend im pazifischen Raum (Korea, Japan, Hawaii) und beim Lollapalooza-Festival, die die Band als die "Great Circle Tour 2013" bezeichnete.

Im Jahr 2016 tourten The Cure in Nordamerika, Australien und Europa. In Deutschland fanden Konzerte in Hamburg, Berlin, Leipzig, München, Köln, Stuttgart und Frankfurt am Main statt. Die Vorgruppe waren The Twilight Sad aus Schottland.




</doc>
<doc id="5060" url="https://de.wikipedia.org/wiki?curid=5060" title="Toulouse">
Toulouse

Toulouse ([] []; deutsch veraltet: "Tholosen") ist eine Stadt in Südfrankreich am Fluss Garonne.

In der Kernstadt lebten (Stand: ) Einwohner, im Ballungsgebiet 920.402 Einwohner und in der gesamten Metropolregion 1.291.517 Einwohner – damit ist Toulouse die viertgrößte Stadt Frankreichs.

Toulouse ist die Hauptstadt der Verwaltungsregion Okzitanien sowie Verwaltungssitz des Départements Haute-Garonne. Bis zur Französischen Revolution war die Stadt offizielle Hauptstadt der Provinz Languedoc. Im Mittelalter war sie Hauptstadt der Region Okzitanien.

Toulouse liegt am Fluss Garonne auf einer Höhe von 146 m. Die Stadt ist durch Kanäle – den Canal du Midi und den Garonne-Seitenkanal – mit dem Mittelmeer und dem Atlantik verbunden. Toulouse ist (Luftlinie) 589 km von Paris entfernt.

Toulouse war unter dem Namen "Tolose" eine wichtige gallische Stadt, welche sich damals acht Kilometer südlich bei Vieille-Toulouse befand. Hier trug sich 106 v. Chr. der Raub des "Goldes von Tolosa" durch Quintus Servilius Caepio zu. Toulouse wurde ab diesem Zeitpunkt eine wichtige Stadt des Römischen Reichs und "Tolosa" (lat.) genannt. Es war die Hauptstadt der Provinz Gallia Narbonensis zwischen Mittelmeer und Atlantik und hatte zwischen 20.000 und 50.000 Einwohner. Etwa im Jahr 8 v. Chr. wurden die Einwohner, vermutlich auf römischen Befehl, an die Stelle der heutigen Stadtmitte umgesiedelt. Ab dem 4. Jahrhundert war Toulouse Sitz des Erzbistums Toulouse. Zahlreiche Straßen in der Toulouser Innenstadt folgen noch dem Grundriss der römischen Siedlung.

413 wurde Toulouse Teil des Westgotenreichs. 418 schlossen die Westgoten einen Pakt mit dem römischen Kaiser. 507 kam es zur Niederlage der Westgoten und so zum Ende des Toulouser Westgoten-Königreichs. 721 wurde die Stadt in der Schlacht von Toulouse mehrere Monate erfolglos von Arabern belagert. Zwischen 781 und 843 war Toulouse Sitz des Königreichs von Aquitanien, danach erfolgte die Gründung der selbständigen Grafschaft Toulouse. In dieser Zeit war die Stadt Zentrum der Languedoc-Kultur.

1208 rief Papst Innozenz III. nach der Ermordung seines Legaten Pierre de Castelnau zum Kreuzzug gegen die Albigenser auf. Der Aufruf hatte Erfolg. Die Stadt wurde geplündert. 1228 gab Graf Raimund VII. von Toulouse nach einem zermürbenden und zerstörerischen Krieg von fast 20 Jahren den Widerstand auf und unterschrieb den Vertrag von Paris (1229).

1271 wurde Toulouse unter die Herrschaft der französischen Krone gestellt, blieb jedoch bis 1790 weitgehend unabhängig. Obwohl zur Zeit der Reformation viele Protestanten in Toulouse lebten, stellte sich die Stadt in den Religionskriegen auf die römisch-katholische Seite. 1562 wurden ca. 4.000 Hugenotten ermordet.

In der Renaissance (etwa 1450 bis 1550) zählte Toulouse zu den reichsten Städten Frankreichs. Pastel "(isatis tinctoria)", eine Pflanze, die damals den einzigen beständigen blauen Farbstoff lieferte, gedieh auf den kalkhaltigen Böden des südöstlich der Stadt gelegenen Lauragais besonders gut. Bedeutende Profanbauten der Pastelgroßhändler im Renaissance-Stil, wie beispielsweise das Hôtel d’Assézat oder das Hôtel de Bernuy, entstanden in dieser Zeit.
Die beherrschende Marktstellung der Stadt endete allmählich nach 1550, als die Portugiesen damit begannen, aus ihren Kolonien das preisgünstigere Indigo zu importieren.

Von 1444 bis 1790 war Toulouse Sitz des "Parlement de Toulouse", das für den Großteil Südfrankreichs zuständig war und dort im Auftrag der Krone Legislative, Jurisdiktion und Exekutive ausübte. Insbesondere entschied es als Appellationsgericht in letzter Instanz alle Zivilprozesse (im schriftlichen Verfahren) und sämtliche Strafprozesse (im mündlichen Verfahren).

Im 19. Jahrhundert nahm Toulouse an der Industrialisierung Frankreichs kaum teil. 1856 bekam Toulouse einen Anschluss an das französische Eisenbahnnetz. Die Stadt wuchs und veränderte sich mit dem Bau der großen Boulevards wie zum Beispiel "rue Alsace-Lorraine" und "rue de Metz". 1875 wurde Toulouse von der Garonne überschwemmt.

Seit den 1920er Jahren deutete sich die Entwicklung der Flugzeugindustrie in der Stadt an. Die Stadt hatte Bedeutung in der Luftpost; sie wurde im Jahre 1927 von Pierre-Georges Latécoère eingeführt. Jean Mermoz, Henri Guillaumet und Antoine de Saint-Exupéry waren berühmte Flieger. Sie transportierten die Briefpost in ganz Europa und nach Südamerika. 1933 fusionierte die Luftpost mit anderen Fluggesellschaften und Air France wurde gegründet. Toulouse hat heute einen Technologiepark und ist die Flugzeug- und Weltraumhauptstadt Frankreichs.

2001 kam es zu einer verheerenden Explosion, als Teile der Firma AZF in der Explosion in Toulouse zerstört wurden. Sie produzierte Düngestickstoff. Es gab 31 Tote, 2.500 Verletzte und viele Schäden im Südwesten der Stadt. Man hörte den Lärm der Explosion bis zu 40 Kilometer weit.

Im Jahr 2012 kam es in Toulouse und Umgebung zu einer Anschlagsserie, bei der sieben Menschen getötet wurden.


Seit den 1980er Jahren hat sich Toulouse zu einem der bedeutendsten Luftfahrtzentren der Welt entwickelt. Etwa 34.000 Beschäftigte arbeiten in diesem Industriezweig, der in Toulouse bereits eine lange Tradition hat:

Die Stadt besitzt neben der Luft-(Airbus und ATR) und Raumfahrtindustrie (EADS: European, Aeronautic, Defense and Space Company) auch Maschinenbau, Eisen- und Textilindustrie und ist dazu ein großes Handels- und Verkehrszentrum.

Toulouse hat ein modernes Konferenzzentrum und seit 1999 eine "Zénith" genannte Multifunktionshalle mit 9.000 Plätzen.

Joseph de Rigaud, Professor an der Universität für Rechtswissenschaft, wurde am 28. Februar 1790 zum ersten Bürgermeister von Toulouse gewählt und regierte zwei Jahre lang. Davor wurde die Stadt von Stadträten (Capitouls) geführt.
Heute beträgt die Amtszeit in der Regel vier Jahre.

Die Bürgermeister von 1944 bis heute:

Toulouse pflegt Partnerschaften mit den folgenden Städten:

Außerdem wurden Kooperationsabkommen geschlossen mit:

Toulouse ist eine Schüler- und Studentenstadt mit insgesamt über 97.000 Studenten. Somit ist sie nach Paris und Lyon die Stadt mit den meisten Studenten in Frankreich. Die frühere Universität Toulouse wurde 1229 gegründet; sie wurde in drei Nachfolgeinstitutionen aufgespalten:

An der UPS werden hauptsächlich Naturwissenschaften wie Biologie, Physik, Pharmazie und Informatik gelehrt. Aber auch Sprachen machen einen erheblichen Anteil der universitären Ausbildung aus.
Die UT1 beherbergt vor allem die Fachrichtungen Wirtschafts-, Rechts- und Politikwissenschaften. Auch hier spielen Fremdsprachen im universitären Alltag eine große Rolle und der Anteil der internationalen Studierenden ist sehr groß.

Darüber hinaus ist man stolz auf Paul Sabatier, den Chemie-Nobelpreisträger von 1912.

Die Bedeutung des Hochschullebens in Toulouse manifestiert sich auch in dem Reichtum und der Vielfalt an Forschungslaboratorien auf dem Campus. Die wichtigsten Ingenieursschulen sind:

Am Institut catholique de Toulouse, der katholischen Hochschule, werden neben Theologie, Philosophie und Geschichte auch Psychologie und Sprachen gelehrt. In der Stadt gibt es außerdem die Toulouse Business School.

Da in Toulouse auch über 5.000 Deutsche leben, viele von ihnen aus beruflichen Gründen (insbesondere als Angestellte des europäischen Gemeinschaftsunternehmens Airbus), gibt es seit den 1970er Jahren vor allem für deren Kinder, aber auch für die Kinder aus binationalen Familien, das Angebot einer Schule, in der sie in deutscher Sprache und nach dem deutschen Schulsystem unterrichtet werden:

Die Einwohner von Toulouse heißen frz. "Toulousains" bzw. "Toulousaines".

Mit 15.000 bis 20.000 jährlichen Zuzügen ist die Metropolregion Toulouse derzeit (2007) die am schnellsten wachsende Frankreichs.

Toulouse wird aufgrund seiner zahlreichen Bauwerke aus roten Ziegelsteinen auch "la ville rose" – die „rosarote Stadt“ - genannt. Bekannte Sehenswürdigkeiten sind:


Bei Toulouse liegt der Flughafen Toulouse-Blagnac. Er wird sowohl für den Linienverkehr als auch als Werksflughafen vom Flugzeughersteller Airbus genutzt. Der Hauptbahnhof von Toulouse, der "Gare Matabiau," befindet sich nordöstlich des Stadtkerns, der Busbahnhof in seiner direkten Nachbarschaft. Heute dauert die Fahrt in die Hauptstadt knapp viereinhalb Stunden; mit der geplanten Schnellfahrstrecke LGV Bordeaux–Toulouse soll die Fahrtzeit nach Paris auf rund drei Stunden verkürzt werden.

Seit 1993 gibt es eine U-Bahn (Métro Toulouse), die mit der Linie A zunächst einen verbesserten Transport zwischen Osten und Westen der Stadt gewährleistete. Die Linie B, die in Nord-Süd-Richtung verläuft, wurde im Sommer 2007 eingeweiht. Im Dezember 2010 kam eine elf Kilometer lange Straßenbahnlinie vom Verkehrsknotenpunkt Arènes in Richtung Nordwesten, unter anderem nach Blagnac, hinzu, die im Dezember 2013 über die Pont Saint-Michel hinweg bis an den Rand der Innenstadt verlängert wurde. Eine Zweigstrecke zum Flughafen wurde 2015 eingeweiht. Darüber hinaus wird der Personennahverkehr durch Busse unterstützt.
Als wichtiges Verkehrsmittel hat sich auch der Fahrrad-Leihservice „VélôToulouse“ etabliert. An 253 Stationen in der Stadt können rund um die Uhr Fahrräder entliehen werden.

Die Stadt ist von einem typisch französischen, gebührenfreien Autobahnring (Périphérique) umgeben, der in den Stoßzeiten, zwischen 8:30 Uhr und 9:30 Uhr sowie von 16:30 Uhr bis 18:00 Uhr, von hohem Verkehrsaufkommen geprägt ist. Im Stadtzentrum gilt jeweils am ersten Sonntag im Monat ein Fahrverbot für Pkw.

Bis zum Beginn des 20. Jahrhunderts hatte der Canal du Midi noch wesentlich zur wirtschaftlichen Prosperität von Toulouse beigetragen. Heute wird die Wasserstraße vor allem touristisch genutzt, etwa für Hausboote. Beispielsweise können Besucher mit Bootstouren Toulouse vom Canal du Midi oder auf der Garonne erkunden. Mit dem Projekt Grand Parc Garonne sollen in den nächsten Jahren die Ufer der Garonne aufgewertet werden. Geschaffen werden soll ein großer Park, der zur Erholung und für kulturelle Ereignisse dienen soll. Die Arbeiten schließen rund 32 km der Flussufer ein und betreffen auch umliegende Gemeinden.

Sportliches Aushängeschild der Stadt ist zuallererst der 1907 gebildete Verein Stade Toulousain, mit bisher 19 Titeln französischer Rekordmeister im Rugby Union, das im Südwesten Frankreichs sehr populär ist. Als erfolgreichster Club auf nationaler und internationaler Ebene gewann Stade zudem viermal den zwischen 1995 und 2014 ausgetragenen europäischen Pokalwettbewerb Heineken Cup Die Heimspiele werden im Stade Ernest-Wallon im Nordwesten der Stadt ausgetragen.

Auch im weniger verbreiteten Rugby League ist Toulouse vertreten: Toulouse Olympique XIII, 1937 gegründet, konnte bisher sechs französische Meistertitel gewinnen und spielt ab 2016 in der dritten englischen Liga (League 1). In der französischen Meisterschaft wird Toulouse nun durch das Farmteam Toulouse Olympique Broncos repräsentiert.

Fenix Toulouse Handball ist ein Handballverein aus Toulouse, der 1964 gegründet wurde. Ihre Heimspiele trägt die Mannschaft im insgesamt 5000 Plätze fassenden Gymnase Compans Cafarelli aus. Als größten Erfolg der Vereinsgeschichte kann man den Gewinn des französischen Handballpokals im Jahr 1998 zählen.

Auch im Fußball ist die Stadt schon lange in der höchsten Liga Frankreichs vertreten, bei den Männern durch den 1970 gegründeten Toulouse FC, der sich zudem auf die Traditionen seines von 1937 bis 1967 existierenden, gleichnamigen Vorgängers beruft. Einen französischen Meistertitel haben bisher aber beide nicht gewinnen können. Ihre Heimspiele trägt die Mannschaft des "Téfécé" im Stadium Municipal aus. Erfolgreicher waren die Fußballerinnen aus der „rosafarbenen Stadt“. Olympique Mirail und Olympique Aérospatial Club spielten ebenfalls über Jahre erstklassig, und der TOAC wurde um die Jahrtausendwende sogar drei Mal Landesmeister; einen vierten Titel gewannen die Spielerinnen, nachdem die Frauenfußballabteilung zum Lokalrivalen TFC gewechselt war, 2002 unter dessen Namen.

Typisch für die Küche von Toulouse ist das Cassoulet, ein Eintopf aus weißen Bohnen und verschiedenen Fleischsorten, zu dem in Toulouse in jedem Fall "Confit d’oie" – eingemachtes Gänsefleisch – und Landwurst gehört. Auch "Terrines de foie gras" (Geflügelstopfleber) und "magret de canard" – Entenbrust mit grünen Bohnen – gehören zur stadttypischen Küche. "Violettes de Toulouse" sind gezuckerte Veilchen, mit denen Süßspeisen aller Art verziert sind; dazu Veilchenlikör. Rund um den Marché Victor Hugo finden sich zahlreiche Chocolatiers und Käsegeschäfte.

Berühmte, aus Toulouse stammende Persönlichkeiten sind unter anderem der Staatsmann Jean-Baptiste de Villèle, der Sänger und Dichter Claude Nougaro, der Politiker Jean-Louis Debré, der Schriftsteller Bernard Werber sowie der Fußballspieler Gaël Clichy.

Von 1631 bis 1665 war Pierre de Fermat, der bedeutendste Mathematiker der ersten Hälfte des 17. Jahrhunderts, Parlamentsrat ("conseiller au parlement") von Toulouse. Er ist zwar im nahegelegenen Beaumont-de-Lomagne geboren, wird aber von der Stadt Toulouse und ihren Historikern als "gloire de Toulouse" („Ruhm von Toulouse“) vereinnahmt.




</doc>
<doc id="5062" url="https://de.wikipedia.org/wiki?curid=5062" title="Thomas von Aquin">
Thomas von Aquin

Thomas von Aquin (* um 1225 auf Schloss Roccasecca bei Aquino in Italien; † 7. März 1274 in Fossanova; auch Thomas Aquinas oder der Aquinat; ) war Dominikaner und einer der einflussreichsten Philosophen und Theologen der Geschichte. Er gehört zu den bedeutendsten Kirchenlehrern der römisch-katholischen Kirche und ist als solcher unter verschiedenen Beinamen wie etwa "Doctor Angelicus" bekannt. Seiner Wirkungsgeschichte in der Philosophie des hohen Mittelalters nach zählt er zu den Hauptvertretern der Scholastik. Er hinterließ ein sehr umfangreiches Werk, das etwa im Neuthomismus und der Neuscholastik bis in die heutige Zeit nachwirkt. In der römisch-katholischen Kirche wird er als Heiliger verehrt.

Thomas von Aquin, auch „der Aquinat“ bzw. nur „Thomas“ genannt, wurde kurz vor oder kurz nach Neujahr 1225 im Schloss Roccasecca, von Aquino 9 km entfernt, als siebtes Kind des Grafen Landulf von Aquino und Donna Theodora, Gräfin von Teate, geboren. Mit fünf Jahren wurde er als Oblate in das Benediktinerkloster Montecassino geschickt, wo Sinibald, der Bruder seines Vaters, als Abt wirkte. Thomas’ Familie folgte damit der Tradition, den jüngsten Sohn der Familie in ein geistliches Amt zu geben. Es lag im Interesse der Familie, dass Thomas seinem Onkel nachfolgte. Von 1239 bis 1244 studierte er im "Studium Generale" der Universität Neapel. 1244 trat er gegen den Willen seiner Verwandten bei den Dominikanern ein, die 1215 als Bettelorden gegründet worden waren. Um Thomas dem Einfluss seiner Eltern zu entziehen, sandte der Orden ihn zunächst nach Rom und dann nach Bologna. Auf dem Weg dorthin wurde er jedoch von seinen im Auftrag der Mutter handelnden Brüdern überfallen und für kurze Zeit auf die Burg Monte San Giovanni Campano und anschließend nach Roccasecca gebracht. Von Mai 1244 bis Herbst 1245 hielt ihn seine Familie fest. Da Thomas fest in seinem Entschluss blieb, Dominikaner zu bleiben, gab die Familie nach und ließ ihn in den Dominikanerkonvent von Neapel zurückkehren.

An der Universität Paris studierte er von 1245 bis 1248 bei Albertus Magnus, dem er dann nach Köln folgte. Von 1248 bis 1252 war er dort Student und Assistent des Albertus. Ab 1252 war er wieder in Paris, wo er von 1252 bis 1256 als "Sentenzenbakkalareus" erste eigene Lehrveranstaltungen über die "Sentenzen" des Petrus Lombardus hielt. Von 1256 bis 1259 lehrte er in Paris als Magister der Theologie. 1259 kehrte er nach Italien zurück und lehrte zunächst in Neapel (was allerdings nicht gesichert ist) und dann 1261 bis 1265 als Konventslektor des Dominikanerkonvents in Orvieto. Von 1265 bis 1268 war er Magister in Rom, wo er mit der Abfassung der "Summa Theologiae" begann. Von 1268 bis 1272 lehrte er zum zweiten Mal als Magister in Paris. In dieser Zeit entstanden besonders viele seiner Schriften, unter anderem der größte Teil der "Summa Theologiae" und die meisten seiner Aristoteles-Kommentare. Im Frühjahr 1272 verließ er Paris. Von Mitte 1272 bis Ende 1273 unterrichtete er als Magister in Neapel.

Der schier unglaublichen Menge seiner Schriften nach zu urteilen liegt es nahe, dem Zeugnis seines Hauptsekretärs zu glauben: Demnach hat der Aquinat drei oder vier Sekretären gleichzeitig diktiert.

Thomas starb am 7. März 1274 auf der Reise zum Zweiten Konzil von Lyon im Kloster Fossanova. Dante deutet an, dass Karl I. von Anjou für seinen Tod verantwortlich gewesen sei. Villani (IX 218) teilt ein Gerücht mit („si dice“: „man sagt“), dem zufolge Thomas von einem Arzt des Königs mit vergiftetem Konfekt ermordet wurde. Nach dieser Darstellung handelte der Arzt zwar nicht im Auftrag des Königs, aber in der Absicht, ihm einen Gefallen zu erweisen, weil er befürchtete, dass ein Mitglied aus dem Geschlecht der gegen Karl rebellierenden Grafen von Aquino in den Kardinalsrang erhoben werden sollte. In unterschiedlichen Versionen, die meist Karl die Verantwortung zuschreiben, wurde das Gerücht vom Giftmord auch in den frühen lateinischen und volkssprachlichen Dantekommentaren kolportiert, die in der Zeit nach Dantes Tod entstanden. Tolomeo da Lucca, ein ehemaliger Schüler und Beichtvater des Aquinaten, spricht in seiner "Historia ecclesiastica" nur von einer schweren Erkrankung auf der Reise bei der Ankunft in Kampanien, bietet jedoch keinen Hinweis auf eine unnatürliche Todesursache.

Papst Johannes XXII. sprach Thomas 1323 heilig. 1567 wurde er in den Rang eines Kirchenlehrers erhoben. Seine Gebeine wurden am 28. Januar 1369 nach Toulouse überführt, wo sie seit 1974 wieder in der Kirche des Dominikanerklosters "Les Jacobins" ruhen. Von 1792 bis 1974 waren sie in der Basilika Saint-Sernin bestattet.

Die Argumentationen des Aquinaten stützen sich zu einem großen Teil auf die sich im Hochmittelalter wieder ausbreitenden Gedanken des Aristoteles, die er – selbst Schüler des Begründers der mittelalterlichen Aristotelik, Albertus Magnus, – in seinem universitären Wirken weitergibt und in seinen Werken mit der christlichen Theologie verbindet. So identifiziert er den Unbewegten Beweger aus der Physik des Aristoteles mit dem christlichen Gott. Gleichwohl arbeitet er in seiner Gotteslehre die Bedeutung der Offenbarung heraus, die für philosophische Überlegungen allein unerreichbar bleibe.

Thomas von Aquin und Albertus Magnus waren nicht die ersten katholischen Aristoteliker. Schon der Kirchenvater Johann Damaszenus begründete seine Dogmatik ausdrücklich mit Aristoteles und seiner Methode; dies geschah 100 Jahre vor der ersten arabischen Aristotelesübersetzung. Papst Eugen III. ließ die Werke von Damaszenus ins Lateinische übersetzen. Struktur und Inhalt der damaszenischen Dogmatik sind – neben anderen Werken wie dem des Hilarius – auch Grundlage für die Zusammenstellung autoritativer Lehraussagen durch Petrus Lombardus. Dessen sog. "libri sententiarum" wurden dem theologischen Grundstudium zugrunde gelegt und durch den Magister kommentiert; viele hunderte dieser "Sentenzenkommentare" zum Werk des Lombarden sind erhalten, darunter auch derjenige des Thomas. Auch in der thomasischen Summe der Theologie wird Damaszenus sehr häufig zitiert.

Thomas von Aquin zitiert zudem häufig die Schrift "De natura hominis" ("Über die Natur des Menschen") des Bischofs Nemesius, welche er, dem Übersetzer Burgundio von Pisa (1110–1193) folgend, für ein Werk des Kirchenvaters Gregor von Nyssa hält.

Ein Kernelement der thomistischen Ontologie ist die Lehre von der Analogia entis. Sie besagt, dass der Begriff des Seins nicht eindeutig, sondern analog ist, also das Wort „Sein“ einen unterschiedlichen Sinn besitzt, je nachdem, auf welche Gegenstände es bezogen wird. Danach hat alles, was ist, das Sein und ist durch das Sein, aber es hat das Sein in verschiedener Weise. In höchster und eigentlicher Weise kommt es nur Gott zu: Nur er "ist" Sein. Alles andere Sein hat nur Teil am Sein und zwar entsprechend seinem Wesen. In allen geschaffenen Dingen muss also "Wesen" ("essentia") und "Existenz" ("esse") unterschieden werden; einzig bei Gott fallen diese zusammen.

Auch die Unterscheidung von "Substanz" und "Akzidenz" ist für das System des Thomas bedeutend. Er folgt dabei der aristotelischen Lehre, wonach dem Akzidens kein eigenes Sein zukommt, sondern nur ein Sein an der Substanz. Hierzu findet sich bei zahlreichen Scholastikern die Wendung „accidens (…) non est ens, sed entis“. Viele Kompendien zur thomasischen Summe der Theologie führen in ihrem Index ebenfalls diese Wendung und verweisen auf ähnlich lautende Stellen im thomasischen Werk. Thomas nennt allerdings durchaus Akzidentien "ens" (secundum quid), auch wenn "ens" im Vollsinn und am Treffendsten die Substanz beschreibt.

Eine weitere wichtige Unterscheidung ist die von "Materie" und "Form". Einzeldinge entstehen dadurch, dass die Materie durch die Form bestimmt wird (siehe Hylemorphismus). Die Grundformen "Raum" und "Zeit" haften untrennbar an der Materie. Die höchste Form ist Gott als Verursacher ("causa efficiens") und als Endzweck ("causa finalis") der Welt. Die ungeformte Urmaterie, d. h. der erste Stoff, ist die "materia prima".

Um die mit dem Werden der Dinge zusammenhängenden Probleme zu lösen, greift Thomas auf die von Aristoteles geprägten Begriffe Akt und Potenz zurück. Weil es in Gott keine (substanzielle) Veränderung gibt, ist er actus purus, also reine Wirklichkeit.

Zu den besonders bedeutenden Aussagen der thomistischen Erkenntnistheorie gehört ihre Wahrheitsdefinition der "adaequatio rei et intellectus", d. h. der Übereinstimmung von Gegenstand und Verstand.

Thomas unterscheidet zwischen dem „tätigen Verstand“ ("intellectus agens") und dem „rezeptiven oder möglichen Verstand“ ("intellectus possibilis"). Der tätige Verstand zeichnet sich vor allem durch die Fähigkeit aus, aus Sinneserfahrungen (sowie bereits geistig Erkanntem) universale Ideen bzw. allgemeingültige (Wesens-)Erkenntnisse zu abstrahieren. Dagegen ist es der rezeptive Verstand, der diese Erkenntnisse aufnimmt und speichert.

Hintergrund ist die auf Platon zurückgehende Ideenlehre, der zufolge die sinnlich wahrnehmbaren Einzeldinge ihre Existenz und ihr Wesen den Ideen ("ideae") verdanken, durch die sie bestimmt werden. Dieser Hintergrund ist aber kaum mehr sichtbar. Während Thomas an Aristoteles wenig Kritik übt, zitiert er Platon ausschließlich, um ihn zu kritisieren. Selbst zu dem sonst von ihm hochgeschätzten Kirchenvater Augustinus zeigt Thomas Distanz, insoweit dieser „platonismo imbutus“ („vom Platonismus benetzt“) ist.

Die Erkenntnislehre des Thomas von Aquin unterscheidet sich fundamental von der Platons. Für Platon ist die Welt der sinnlich wahrnehmbaren Objekte nur ein sehr unvollkommenes Abbild der eigentlichen Realität hinter den Dingen, was er in seinem Höhlengleichnis veranschaulicht. Für Aristoteles und Thomas ist aber die physische Existenz eine Vollkommenheit und nicht bloßes Abbild von etwas Höherem. Daraus ergibt sich, dass sich die platonische Ideenlehre, wenn überhaupt, nur sehr beschränkt auf die thomistische Erkenntnislehre anwenden lässt.

Der tätige Verstand kann durch Abstraktion (wörtl.: das Abziehen) der Formen ("formae") aus den einzelbestimmten Dingen, deren Wesen- bzw. „Was“-heit („quidditas“) sowie in weiteren Schritten die Akzidenzien erkennen. Als letzte bzw. erste Ursache des Seins und Soseins der Dinge erkennt der menschliche Geist Gott (siehe unten), in dessen Geist die ewigen Ideen die Vorbilder für die Formen ("formae") der Dinge sind.

Thomas’ Anthropologie weist dem Menschen als leib-geistiges Vernunftwesen einen Platz zwischen den Engeln und den Tieren zu. Gestützt auf Aristoteles’ "De Anima" zeigt Thomas, dass die Seele den Geist als Kraft besitzt, oder besser gesagt, dass das Erkennen die Form der Seele ist ("scientia forma animae"), während die Seele wiederum die Form des Leibes ist: Dies zeigt sich in der Formulierung "anima forma corporis". Weil der Geist („intellectus“) eine einfache, also nicht zusammengesetzte Substanz ist, kann er auch nicht zerstört werden und ist somit unsterblich. Der Geist kann auch nach der Trennung vom Leib seinen Haupttätigkeiten, dem Denken und Wollen, nachkommen. Die nach der Auferstehung zu erwartende Wiedervereinigung mit einem Leib kann zwar nicht philosophisch, wohl aber theologisch erwiesen werden.

In der Ethik verbindet Thomas die aristotelische Tugendlehre mit christlich-augustinischen Erkenntnissen. Die Tugenden bestehen demnach im rechten Maß bzw. dem Ausgleich vernunftwidriger Gegensätze. Das ethische Verhalten zeichnet sich durch das Einhalten der Vernunftordnung aus (Naturrecht) und entspricht damit auch dem göttlichen Gesetzeswillen. Als Kardinaltugenden werden von Thomas prudentia (Klugheit), iustitia (Gerechtigkeit), temperantia (Mäßigung) und fortitudo (Tapferkeit) bezeichnet. Unabhängig davon zu sehen seien die drei christlichen Tugenden Glaube, Liebe und Hoffnung. (Für Glaube, Hoffnung und Liebe ist der Oberbegriff "christliche Tugenden" zwar gebräuchlich, aber richtiger sind es die "göttlichen" Tugenden, nicht in dem Sinn, als seien sie Tugenden Gottes, sondern dies meint, dass Gott das "Objekt" dieser Tugenden ist: Glaube "an" Gott, Hoffnung "auf" Gott, Liebe "zu" Gott.)

Das höchste Gut ist die ewige Glückseligkeit, die – im jenseitigen Leben – durch die unmittelbare Anschauung Gottes erreicht werden kann. Es zeigt sich daran der Primat der Erkenntnis vor dem Wollen.

Thomas von Aquin war einer der einflussreichsten Theoretiker für das mittelalterliche Staatsdenken. Dabei sah er den Menschen als ein soziales Wesen, das in einer Gemeinschaft leben muss. In dieser Gemeinschaft tauscht er sich mit seinen Artgenossen aus, und es kommt zu einer Arbeitsteilung.

Für den Staat empfiehlt er die Monarchie als beste Regierungsform, denn ein Alleinherrscher, der mit sich selbst eins ist, kann mehr Einheit bewirken als eine aristokratische Elite. Hier müssen sich mehrere einigen, was immer nur zu einem Kompromiss, also einer Angleichung, einer Anpassung, einer Aufgabe seiner eigenen Meinung und Überzeugung führt. Außerdem ist immer dasjenige am besten, was der Natur entspricht, und in der Natur haben alle Dinge nur "ein" Höchstes.

Thomas stellt der Monarchie als der besten die Tyrannis als die schlechteste aller denkbaren Regierungsformen gegenüber. Dabei merkt er an, dass aus der Aristokratie leichter eine Tyrannis entstehen kann als aus einer Monarchie.

Um die Tyrannei zu verhindern, muss die Gewalt des Alleinherrschers eingeschränkt sein. Eine Tyrannei ist dennoch zunächst zu ertragen, da die Gefahr einer Verschlimmerung bestehe (z. B. durch Anomie) . Der Tyrannenmord ist laut der Lehre der Apostel keine Heldentat .

So schlussfolgert Thomas, dass es besser ist, gegen eine Bedrückung nur nach allgemeinem Beschluss vorzugehen.

Wie viele Staatsdenker des Mittelalters zieht auch Thomas von Aquin den organischen Vergleich zum Staatsgebilde heran. Hierbei sieht er den König, als Vertreter Gottes im Staat, analog der Vernunft bzw. Seele für den menschlichen Körper, dessen Glieder und Organe die Bevölkerung darstellen. Seine Erfüllung findet, angelehnt an Aristoteles, jedes einzelne Glied in der Tugendhaftigkeit.

Dennoch sieht Thomas das Priestertum über dem Königtum; der Papst als Oberhaupt der Kirche steht also in Glaubens- und Sittenfragen über dem König. Deshalb sind die weltlichen Herrscher verpflichtet, ihre Gesetze entsprechend den dogmatischen und ethischen Vorgaben der Kirche zu gestalten und durchzusetzen. Beispielsweise müssen sie die Todesstrafe für Menschen, die die Kirche wegen Häresie verurteilt hat, vollstrecken und gegen Gruppen von Häretikern wie die Albigenser oder Waldenser militärisch vorgehen. Die Trennung von Staat und Kirche ist von dieser Position aus nicht möglich.

Den Gedankengängen des Aristoteles folgend, legitimiert Thomas die Sklaverei aus dem Naturrecht als sittlich und rechtmäßig.

Thomas beansprucht, der Theologie den Charakter einer Wissenschaft zu geben (siehe unten). Dies wird kirchlicherseits als eines seiner wesentlichen Verdienste gesehen. Zur Klärung der Glaubensgeheimnisse zieht er dabei die natürliche Vernunft heran, insbesondere das philosophische Denken des Aristoteles. Thomas hat die Gegensätze aufgelöst, die zu seiner Zeit zwischen den Anhängern zweier Philosophen bestanden: denen des Augustinus (der das Prinzip des menschlichen Glaubens betont) und des wiederentdeckten Aristoteles (der von der Erfahrungswelt und der darauf aufbauenden Erkenntnis ausgeht). Thomas versucht zu zeigen, dass sich diese beiden Lehren nicht widersprechen, sondern ergänzen, dass also einiges nur durch Glauben und Offenbarung, anderes auch oder nur durch Vernunft erklärt werden kann. Vor allem in dieser Synthese der antiken Philosophie mit der christlichen Dogmatik, die gerade auch für die Moderne von unabschätzbarer Bedeutung sei, wird seine Leistung gesehen. Thomas konnte aber 1270 die Verurteilung des Aristotelismus durch den Bischof von Paris Étienne Tempier nicht verhindern.

Thomas von Aquin legte im Rahmen der Philosophischen bzw. Natürlichen Theologie Argumente dafür dar, dass der Glaube an die Existenz Gottes nicht vernunftwidrig ist, sich also Glaube und Vernunft nicht widersprechen. Seine "Quinque viae" („Fünf Wege“), dargestellt in seinem Hauptwerk, der "Summa Theologica" (auch "Summa Theologiae"), hat Thomas zunächst nicht als „Gottesbeweise“ bezeichnet, sie können jedoch als solche aufgefasst werden, da sie rationale Gründe für Gottes Existenz darlegen. Die Argumentationskette endet jeweils mit der Feststellung „das ist es, was alle Gott nennen.“

Prägend wurde Thomas‘ Theologie auch für die katholische Eucharistielehre. Er wandte die Begriffe der Substanz und der Akzidenzien auf das Geschehen in der heiligen Messe an: Während die Akzidenzien, d. h. die Eigenschaften von Brot und Wein erhalten bleiben, ändert bzw. verwandelt sich demnach die Substanz der eucharistischen Gaben in Leib und Blut des auferstandenen Christus, der ebenfalls aus Seele und Leib besteht (Transsubstantiation). Charakteristisch für die thomistische Eucharistielehre ist seine strenge Beobachtung metaphysischer Prinzipien. So lehnt er die Multilokation ab. Christus ist in den heiligen Gestalten an mehreren Orten präsent. Der Ort ist aber nicht der Ort Christi (sein Ort ist jetzt im Himmel). Die örtliche und zeitliche Bestimmung der heiligen Gestalten ist laut Thomas weiterhin die des ehemaligen Brotes oder Weines.

In seiner "Summa contra gentiles" geht Thomas u. a. auch auf die Hölle ein und übernimmt dabei die Sicht von Augustinus. Er verwirft die Apokatastasis:

Allerdings führt er eine neue Begründung für die angenommene Endlosigkeit und Grauenhaftigkeit solch einer Strafe ein, die aufgrund einer einzigen falschen Entscheidung über den Menschen kommen soll:

Er argumentiert auch, dass die Strafen, die die Gottlosen erleiden müssen, sowohl eine psychische oder seelische Seite (Gottesferne) als auch eine physische Seite (körperliche Schmerzen) haben, so dass die Gottlosen also zweifach gestraft seien.

Thomas ist in erster Linie wegen seiner Verdienste um die Theologie und die Philosophie in die Geschichte eingegangen. Darüber hinaus wird sein Werk aber auch wegen einer tiefen Frömmigkeit geschätzt.

Am Nikolaustag 1273 soll Thomas laut einem Bericht des Bartholomäus von Capua während einer Feier der heiligen Messe von etwas ihn zutiefst Berührendem betroffen worden sein und anschließend jegliche Arbeit an seinen Schriften eingestellt haben. Auf die Aufforderung zur Weiterarbeit soll er mit den Worten reagiert haben:

In der Hagiographie wird dieser Ausspruch als Reaktion auf eine Gotteserfahrung gedeutet.

Von ihm stammen unter anderem die Sequenz zu Fronleichnam "Lauda Sion" sowie die eucharistischen Hymnen "Pange Lingua", dessen letzten beiden Strophen als "Tantum ergo" oft selbständig gesungen werden, und "Adoro te devote". Er wurde mit der gesamten Verfassung des Fronleichnamsoffiziums (den Texten für Messe und Brevier) betraut.

Das "Tantum ergo" wird in der katholischen Kirche häufig bei der eucharistischen Anbetung gesungen.

Die Dreieinigkeit bzw. Dreifaltigkeit oder Trinität Gottes sieht Thomas zwar als ein Geheimnis (Mysterium), sie kann jedoch unter Zuhilfenahme der göttlichen, d. h. biblischen Offenbarung teilweise „verstanden“ werden. Demnach ist der eine Gott in drei Personen (Subsistenzen) die "eine" göttliche Natur und darum gleich ewig und allmächtig. Weder der Begriff der „Zeugung“ beim Sohn (Jesus) noch derjenige der „Hauchung“ beim Heiligen Geist darf Thomas zufolge im wörtlichen bzw. weltlichen Sinne verstanden werden. Vielmehr ist die zweite und dritte Person Gottes die ewige Selbsterkenntnis und Selbstbejahung der ersten Person Gottes, d. h. Gott Vaters. Weil bei Gott Erkenntnis bzw. Wille und (sein) Wesen mit seinem Sein zusammenfallen, ist seine vollkommene Selbsterkenntnis und Selbstliebe von seiner Natur, also göttlich.

Zu den heute schwer nachvollziehbaren Teilen von Thomas‘ Lehre gehört es, dass er neben der Exkommunikation die Hinrichtung von Häretikern für legitim gehalten hat, da er deren Vergehen im Vergleich zu Falschmünzern, welche damals dem Tode überliefert wurden, als schwerwiegender ansieht. (Falschmünzer-Vergleich) ("Summa theologiae", II-II, q. 11, art. 3). Mit dem Satz lieferte er den theoretischen Unterbau für die mittelalterliche Inquisition.

Auch war er gegen das Verleihen gegen Zins, musste jedoch im Laufe seiner ökonomischen Beschäftigung mit dem Thema von einem vollständigen Zinsverbot zurückstehen.

Thomas von Aquin wurde am 18. Juli 1323 von Papst Johannes XXII. heiliggesprochen. Sein Orden bemühte sich mit einigem Erfolg, seinen Lehren Verbindlichkeit zu schaffen. Die Schule von Salamanca machte seine Summa theologica zum Unterrichtsmaterial und sorgte für eine Thomas-Renaissance im 16. Jahrhundert. Sein Werk und seine Ideen wurden 1879 durch die Enzyklika "Aeterni Patris" von Papst Leo XIII. zur Grundlage der katholischen akademischen Ausbildung erhoben. Über Jahrzehnte stabilisierte diese Engführung die römisch-katholische Lehre. Auch das Zweite Vatikanische Konzil empfiehlt Thomas ausdrücklich als den Lehrer, nach dessen Lehre sich die Theologie sowie die Philosophie im Studium der zukünftigen Priester zu richten haben ("Optatam totius"). Die Enzyklika "Fides et ratio" von Papst Johannes Paul II. und das neue Kirchenrecht haben diese Empfehlung erneut bestätigt.

Schon um 1300 trat der Franziskaner Johannes Duns Scotus gegen Thomas auf und gründete die philosophisch-theologische Schule der Scotisten, mit der die Thomisten an den Universitäten in Fehde lebten. Thomas‘ Anhänger verteidigten die strenge Lehre des Augustinus von der Gnade und bestritten die Unbefleckte Empfängnis Mariens, der Mutter Jesu. In der Frage der Freiheit der Gottesmutter von Erbsünde hat sich die spätere Kirche von den Zweifeln, die in der thomistischen Schule häufig anzutreffen sind, abgegrenzt, wobei umstritten bleibt, inwieweit Thomas tatsächlich ein Gegner des Dogmas war.

Auch Ramon Llull hat sich gegen die thomististische Scholastik ausgesprochen und damit indirekt die jahrelange Indizierung der Werke und die Verfolgung der Lullisten bewirkt.
Ende des 19. und Anfang des 20. Jahrhunderts gab es einerseits ein verstärktes Interesse an der philosophiegeschichtlichen Erforschung der Werke des Thomas (z. B. Martin Grabmann), und andererseits wurde im Thomismus, Neuthomismus und der Neuscholastik auf Grundlage seines Werkes eine philosophische Weiterentwicklung vorgenommen (z. B. Konstantin von Schaezler). In neuerer Zeit hat Josef Pieper sowohl die Tugendlehre als auch die Philosophie und Theologie des Thomas in zahlreichen Büchern und Vorträgen behandelt. Karl Rahner interpretierte Thomas von Aquin auf dem Hintergrund seiner Transzendentaltheologie.


Im Gegensatz zu anderen großen Philosophen wie etwa Albertus Magnus, der verschiedene Ämter innehatte, gab sich Thomas ganz der Wissenschaft hin. Er schuf ein monumentales Werk, das in sechs Kategorien eingeteilt wird:


Die "Summa contra gentiles" und insbesondere die "Summa theologica" bilden einen Höhepunkt thomanischen Schaffens. Sein Werk wurde im 19. Jahrhundert von der römisch-katholischen Kirche zur Grundlage der christlichen Philosophie erklärt.






Mehrere Werke

Theologische Summen

Sonstige Einzelwerke

Linksammlungen





</doc>
<doc id="5063" url="https://de.wikipedia.org/wiki?curid=5063" title="Theologie">
Theologie

Theologie (, von "theós" ‚Gott‘ und λόγος "lógos" ‚Wort, Rede, Lehre‘) bedeutet „die Lehre von Gott“ oder Göttern im Allgemeinen und die Lehren vom Inhalt eines spezifischen religiösen Glaubens und seinen Glaubensdokumenten im Besonderen.

Der Begriff "theologia" trat in der griechischen Antike auf. Dort bezeichnete er die „Rede von Gott“, das Singen und Erzählen (gr. „mythein“) von Göttergeschichten. (Später verstanden christliche Theologen wie zum Beispiel Karl Barth unter diesem Begriff „Gottes Rede zu den Menschen“.) Der älteste Beleg für dieses mythische Verständnis von Theologie findet sich in Platons "Staat" (379a). Platon legt an die Göttermythen der kritisierten Theologie den kritischen Maßstab der Frage nach der Wahrheit als dem Einen, Guten und Unveränderlichen an. Bei Aristoteles zeigt sich eine Umprägung des Theologiebegriffs: Theologie als die oberste der theoretischen Wissenschaften richtet sich darin auf das Göttliche als das erste und eigentliche Prinzip (Metaphysik (Aristoteles) 1064a/b). Die Theologie hat sich damit von der Mythologie hin zur Metaphysik gewandelt.

Im zweiten Jahrhundert wurde der Begriff von christlichen Autoren, den Apologeten, aufgegriffen, die ihn im Kontrast zur "mythologia" (Erzählen von Göttergeschichten) der polytheistischen heidnischen Autoren verwendeten. Bei Eusebius bedeutet der Begriff etwas wie „das christliche Verständnis von Gott“. Bei allen patristischen Autoren bezog sich der Begriff jedoch nicht auf die christliche Lehre im Allgemeinen, sondern nur auf die Aspekte von ihr, die sich direkt auf Gott bezogen. So wurden als einzige frühchristliche Autoren der Autor des Johannesevangeliums und Gregor von Nazianz spezifisch als „Theologen“ bezeichnet, weil Gott in ihrer Lehre im Mittelpunkt stand. Die Fragen nach dem Heilshandeln und der Heilsordnung Gottes für die Menschen wurden unter dem Begriff der "Ökonomie" (gr. „oikonomia“) behandelt.

Theologen in der Alten Kirche waren häufig Bischöfe, im Mittelalter in der Regel Mönche. Mit der Entstehung der Universitäten als Ordenshochschulen im Mittelalter bildete die Theologie meist die erste Fakultät. Im Hochmittelalter bekam der Begriff bei Peter Abaelard (Frühscholastik) und Bonaventura (Hochscholastik) erstmals die allgemeinere Bedeutung „das Gebiet des heiligen Wissens“, das die gesamte christliche Lehre umfasste. Zum feststehenden Begriff in diesem Sinn wurde Theologie insbesondere aufgrund der Summa theologica von Thomas von Aquin, der Theologie in erster Linie als spekulative, theoretische Wissenschaft ansah.

Die Reformatoren betonten den praktischen Aspekt der Theologie wieder stärker. Damit steht Martin Luther auch in der Tradition der monastischen Verankerung der Theologie wie sie im Mittelalter zum Beispiel bei Anselm von Canterbury und Bernhard von Clairvaux wirksam war. Praktische Wissenschaft war die Theologie in dem Sinne, dass sie ganz auf die Zueignung des Heils durch Gott, also auf den praktischen Vollzug des Glaubenslebens bezogen war. In diesem Sinne bestimmten auch zahlreiche Vertreter der lutherischen Orthodoxie die Theologie als eine "scientia practica", die allerdings in ihrer Durchführung auch Anleihen bei der theoretischen Wissenschaft machen müsse. Deshalb gewannen die theologischen Systeme der lutherischen Orthodoxie vielfach äußerlich einen ähnlichen Charakter wie die alten scholastischen Summen, waren inhaltlich aber anders angelegt und auch in ihrem systematischen Aufbau (der sich an den analytischen ordo des Aristoteles anlehnte) stärker auf die Glaubenspraxis hin ausgerichtet. Teilweise etablierte sich auch wieder ein stärker oder rein theoretisches Verständnis der Theologie.

Die Unterscheidung der Theologie als Wissenschaft von der Glaubenspraxis und der unmittelbaren Erkenntnis des Glaubens wurde zur Zeit der lutherischen Orthodoxie durch den Theologen Georg Calixt vorbereitet. In Ansätzen liegt sie auch bei Abraham Calov und Johann Andreas Quenstedt vor. Während diese allerdings die Theologie dem Glauben vorordnen, wird das Verhältnis in der Aufklärung umgekehrt: Die Theologie ist als Reflexionsform gegenüber dem Glauben beziehungsweise der Religion sekundär. Diese Verhältnisbestimmung tritt erstmals bei Johann Salomo Semler auf. Friedrich Daniel Ernst Schleiermacher begriff die Theologie als eine positive Wissenschaft, die auf die Kirchenleitung bezogen ist. Während die Unterscheidung von Theologie und Glaube bis heute für den theologischen Diskurs maßgeblich ist, bleibt die Ausrichtung der Theologie auf die Kirchenleitung umstritten.

Die Theologien im Christentum verstehen sich als wissenschaftliche Auseinandersetzungen mit den Quellen des Glaubens (Biblische Theologie und Historische Theologie) und der Glaubenspraxis (Praktische Theologie) sowie als systematische Analyse und Darstellung des Glaubens (Systematische Theologie, unter anderem Fundamentaltheologie, Dogmatik und Ethik). Im 20. Jahrhundert kam als Disziplin die Interkulturelle Theologie hinzu, die das Verhältnis der christlichen Theologie und Praxis im Kontext verschiedener Kulturen, Religionen und Gesellschaften untersucht und sich den Fragen des interkulturellen wie interreligiösen Miteinanders widmet.

Christliche Theologie bezieht sich meist auf eine bestimmte Konfession. Hierbei werden nicht nur die dargestellten Inhalte, sondern oft auch die Denkweisen und angewandten Methoden von der jeweiligen Konfession bestimmt. In der wissenschaftlich betriebenen Theologie wird diese Tatsache selbst noch einmal problematisiert und reflektiert.
Kritik begleitet die ganze Kirchengeschichte, denn Auseinandersetzungen zwischen der etablierten Kirche und abweichenden Strömungen sind stets mit Kritik (an den Ansichten der anderen) verbunden. Daneben gibt es von Beginn an auch ein selbstkritisches Hinterfragen des eigenen Verständnisses. Paulus mahnte: „Prüft alles und behaltet das Gute!“ (), und verwies auf die Vorläufigkeit unseres jeweiligen Erkenntnisstandes („unser Erkennen ist Stückwerk …“ ). Gegenwärtig betonen theologische Lexika die kritische Aufgabe der Theologie. Für Heinzpeter Hempelmann ist Kritik „die einzig angemessene Antwort auf (einen) Offenbarungsanspruch“, denn die Spuren eines die menschliche Vernunft derart in Frage stellenden Ereignisses wie die Menschwerdung Gottes seien „unterscheidend und prüfend“ wahrzunehmen. Das Thema Kritik im Bereich der christlichen Religion behandelt Franz Graf-Stuhlhofer grundsätzlich im Buch "Christliche Bücher kritisch lesen" sowie in der Studie "Facetten kritischen Denkens".

Einige Wissenschaftstheoretiker sprechen jeder (christlichen) Theologie aufgrund ihrer Bekenntnisgebundenheit die Wissenschaftlichkeit ab und kritisieren ihre Präsenz und Finanzierung an staatlichen Universitäten in Form von theologischen Fakultäten.

Kritik an der Theologie richtet sich zum Beispiel gegen 

Auf diese Anfragen gibt es verschiedene Reaktionen seitens der Theologen:

Manche Theologen sehen Gott nicht als unmittelbaren Gegenstand einer theologischen Wissenschaft; zum Beispiel sieht Wolfhart Pannenberg Gott als Gegenstand des "Glaubens".

Mitunter beruht Kritik an der Theologie auf einem naturwissenschaftlich orientierten „objektiven“ Wissenschaftsbegriff. Hier kam es im Rahmen der Wissenschaftstheorie seit den 1960er Jahren zu einer veränderten Sichtweise, etwa durch Thomas S. Kuhns Hinweis darauf, dass bei der Entscheidung von Forschern für oder gegen einen Paradigmenwechsel psychologische Faktoren mitwirken. Auch die Analytische Philosophie war einflussreich.

Der Begriff „Theologie“ ist eigentlich im Christentum beheimatet. Wenn er heute auch auf andere Religionen (vor allem auf Judentum und Islam) übertragen wird, so können sich dabei Probleme ergeben, da der Begriff innerhalb dieser Religionen meist kritisch betrachtet wird. So sprechen viele jüdische Gelehrte (die sich eben nicht „Theologen“ nennen) eher von jüdischer Rechtsauslegung, Kasuistik oder einfach nur Lehre (Tora). 

Konfessionell gebundene Fakultäten und Seminare gibt es nur für Christentum, Judentum und Islam. Es findet zwar im Rahmen der Vergleichenden Religionswissenschaft eine wissenschaftliche Beschäftigung mit vielen Religionen und ihren Inhalten statt, und es werden Studiengänge wie Judaistik und Islamwissenschaft angeboten, jedoch ist die Perspektive und Methodik hierbei deutlich von einer theologischen Herangehensweise unterschieden, und es gibt dabei auch keine konfessionelle Festlegung. 

Im Judentum gibt es keine allgemeinverbindlichen Dogmen und demzufolge auch keine Theologie im eigentlichen Sinne („Lehre von Gott“). Die "Hochschule für Jüdische Studien" in Heidelberg wird vom Zentralrat der Juden in Deutschland getragen. Sie widmet sich der Wissenschaft des Judentums. Auch gibt es an mehreren Universitäten Studiengänge für Judaistik, die unabhängig von der Religionszugehörigkeit besucht werden können.

Die islamwissenschaftlichen Institute und Seminare der Universitäten beschäftigen sich mit der Geschichte und Praxis des Islams.

Im Islam selbst gibt es eine traditionelle Theologie, die Ilm al-Kalam genannt wird. Bedeutungsvoll sind allerdings auch die islamischen Rechtswissenschaften Fiqh und Schari'a.

Die Verwendung des deutschen Begriffs „Gott“ in Bezug auf den Hinduismus kann verwirren, auch die Begrifflichkeit „Gott“ betreffend. 

Brahman ist das unbeschreibbare, unerschöpfliche, allwissende, allmächtige, nicht körperliche, allgegenwärtige, ursprüngliche, erste, ewige und absolute Prinzip. Es ist ohne einen Anfang, ohne ein Ende, in allen Dingen versteckt und die Ursache, die Quelle und das Material aller bekannten Schöpfung, selbst jedoch unbekannt und doch dem gesamten Universum immanent und transzendent. Die Upanishaden beschreiben es als das eine und unteilbare, ewige Universalselbst, das in allem anwesend ist und in dem alle anwesend sind. 

Von manchen Richtungen wird der Ishvara (wörtlich: der „höchste Herr“) als die manifestierte Form (siehe Avatara) von Brahman gesehen. Die Illusionskraft, durch die das Brahman als die materielle Welt, die einzelnen Seelen und der Ishvara gesehen zu werden, wird Maya genannt. Es gibt auch ihm unterstellte Wesen, die Devas genannt werden. Sie gelten gemäß dieser Sichtweise als die weltlichen Äußerungen des einen Ishvara.

Nach Auffassung des Advaita Vedanta ist der Mensch in seinem innersten Wesenskern mit dem Brahman gleich, und diese Einheit gilt es zu erkennen. Advaita Vedanta ("Nichtdualität") ist die Lehre Shankaras (788–820 n. Chr), die auf diese Erkenntnis der Einheit zielt. Nach der Lehre des Vishishtadvaita von Ramanuja dagegen ist das höchste Prinzip alles, was existiert. Es besteht jedoch ein qualitativer Unterschied zwischen individueller Seele und höchstem Prinzip. Am anderen Ende des Spektrums steht die rein dualistische Philosophie des Dvaita Vedanta des Madhvas, die streng zwischen Seele und höchstem Prinzip unterscheidet (siehe: Indische Philosophie).


Für Weblinks zu den Theologien bestimmter Religionen vgl. jeweiligen Nachbarartikel, z. B. den Hauptartikel Christliche Theologie.


</doc>
<doc id="5064" url="https://de.wikipedia.org/wiki?curid=5064" title="Tumor">
Tumor

Ein Tumor (Plural "Tumoren", umgangssprachlich auch "Tumore"; von , , m. ‚Wucherung‘, ‚Geschwulst‘, ‚Schwellung‘) im weiteren Sinn ist jede Zunahme des Volumens eines Gewebes von höheren Lebewesen unabhängig von der Ursache. Synonyme in einer zweiten, engeren Bedeutung sind die Begriffe Neoplasie (‚Neubildung‘) und „Gewächs“. Tumoren treten bei allen höheren Lebewesen (auch bei Pflanzen) auf. Dieser Artikel geht aber ausschließlich auf Tumoren bei Menschen ein, also auf die humanmedizinische Bedeutung.

Dementsprechend gibt es in der Medizin zwei Definitionen des Begriffs Tumor:

Neoplasien können jegliche Art von Gewebe betreffen, sie können gutartig (benigne) oder bösartig (maligne) sein. Die maligne Variante wird umgangssprachlich auch als Krebs bezeichnet. Neoplasien können alleinstehend („solitär“) oder mehrfach an verschiedenen Stellen im Organismus („multizentrisch“ oder „multifokal“) auftreten. Üblicherweise werden Tumoren als "multizentrisch" bezeichnet, wenn die Distanz zwischen den einzelnen Läsionen mehr als fünf Zentimeter beträgt und als "multifokal", wenn die Distanz fünf Zentimeter oder kleiner ist, allerdings existiert keine exakte radiologische Definition für diese Begriffe. Je nach Ort (Lokalisation) des Tumors und der Funktion des durch ihn geschädigten Gewebes können sie zu einer Zerstörung von Organen mit Beeinträchtigungen des Gesamtorganismus bis hin zum Tod führen.

Tumoren sind Gewebeveränderungen, die auch vererblich, aber beim Menschen generell nicht ansteckend sind. Ihre Einteilung erfolgt nach ihrem biologischen Wachstumsverhalten und nach dem Ursprungsgewebe der Neoplasie.

In Abhängigkeit von der Dignität des Tumors, also seiner Fähigkeit, Metastasen auszubilden, unterscheidet man benigne (gutartige), maligne (bösartige) und semimaligne Tumoren. Die malignen Tumoren werden nochmals in niedrig-maligne und hoch-maligne Tumoren unterteilt.


"Gutartige Tumoren" und "semimaligne Tumoren" werden nach ihrer Herkunft weiterdifferenziert. Die Benennung erfolgt durch die angehängte Endung „-om“ an den lateinischen Namen des Ursprungsgewebes.

"Bösartige Tumoren" werden ebenfalls – soweit das Ursprungsgewebe noch erkennbar und der Tumor nicht völlig entdifferenziert ist – nach diesem Ursprungsgewebe benannt. Allerdings wird diese Nomenklatur nicht konsequent durchgehalten, so dass auch andere Begriffe dafür verwendet werden (z. B. "Siegelringzellkarzinom" nach dem Aussehen der Tumorzellen). Bösartige Tumoren werden im Deutschen als Krebs bezeichnet (auch wenn "Krebs" die Übersetzung des Griechischen Wortes 'Καρκινος' ist, und damit nur eine – wenn auch die häufigste – Gruppe von bösartigen Tumoren bezeichnet wird).

Bösartige Tumoren können sich aus noch nicht bösartigen Vorstufen, sogenannten Präkanzerosen, entwickeln. Diese werden unterteilt in fakultative und obligate Präkanzerosen.

Die bösartigen Tumoren werden folgendermaßen untergliedert:

Die weitere Einteilung bösartiger Tumoren erfolgt analog der TNM-Klassifikation der UICC. Es handelt sich um eine klinisch-empirische Einteilung, welche die weitere Diagnostik, Therapie und Prognose bösartiger Tumoren bestimmt.

Quelle

Tumoren sind nach WHO in Grade eingeteilt (TNM-Klassifikation):
T: Tumor, 
N: Nodus (LymphkNoten), 
M: Metastasen (Fernmetastasen), 
R: Resektion (Resttumor).
G: Grading

"T-Klassifikation" (Größe des Tumors):

"N-Klassifikation" (Lymphknoten):

"M-Klassifikation" (Metastasen):

"R-Klassifikation" (Resektion):

"G-Klassifikation" (Grading):

Die Lokalisation der Tumoren ist die wesentliche Grundlage der Einteilung der Neubildungen in der von der WHO herausgegebenen "Internationalen statistischen Klassifikation der Krankheiten und verwandter Gesundheitsprobleme" (ICD-10). 
Tumoren entstehen durch Entartung, genauer durch eine Anhäufung von Mutationen in bestimmten Genen (engl. ). Diese bestimmten Gene sind typischerweise Protoonkogene oder Tumorsuppressorgene. Alternativ kann eine Entartung durch Onkoviren und onkogene Bakterien erfolgen, bei denen eine fortlaufende Stimulation mit Zytokinen durch die Immunreaktion und mit Wachstumsfaktoren zum Ersetzen der zerstörten Zellen auftritt, z. B. beim Hepatitis-B-Virus. Durch eine häufige Zellteilung wird die Entstehung von Mutationen beim Kopieren des Genoms begünstigt. Bei einigen persistenten Viren (die "genomisch-integrierenden Viren") erfolgt zusätzlich eine Insertionsmutation durch das Einfügen des viralen Genoms in das Genom des Wirts, was meistens in entfalteten und transkriptionsaktiven Bereichen der DNA erfolgt, z. B. bei Retroviren. In seltenen Fällen kann ein Tumor auch übertragen werden, z. B. durch eine Organtransplantation und die begleitende Immunsuppression oder – bei Hunden, Beutelteufeln und Hamstern – durch infektiöse Tumoren.

Benigne Tumoren wachsen in der Regel langsam und beeinträchtigen den Körper nicht. Einige benigne Tumoren können aber zu malignen Tumoren mutieren. Hier sind vor allem Dickdarmpolypen ("Kolonadenome") zu nennen, die sehr häufig zu Adenokarzinomen entarten (sogenannte Adenom-Karzinom-Sequenz). Hormonproduzierende Adenome können allerdings durch ihre Hormonwirkung zu schwerwiegenden Erkrankungen führen.

Komplikationen benigner und maligner Tumoren sind:

Komplikationen maligner Tumoren sind:

Die Tumortherapie erfolgt durch operative Tumorentfernung (Resektion, auch Wachkraniotomie bei bestimmten Hirntumoren), Bestrahlung mit ionisierenden Strahlen und/oder (Poly-)Chemotherapie. Betroffene Menschen können eine Tumorberatung besuchen. 

Bei einigen bestimmten bösartigen Tumoren gibt es zusätzliche, spezielle Therapieoptionen. Gegen das Maligne Melanom, den sogenannten schwarzen Hautkrebs, gibt es im Stadium der Entwicklung befindliche Krebsimmuntherapien, bei denen der Körper mit speziellen Oberflächenantigenen, also Zellmerkmalen des Malignen Melanoms, geimpft wird. Ein ähnliches Konzept wird bei einigen Tumoren, zum Beispiel den gastrointestinalen Stromatumoren, mit der Behandlung durch Immunmodulatoren verfolgt, bei denen das Immunsystem des Körpers angeregt wird, sich gegen Tumorzellen zu richten.

Weitere Tumoren werden zusätzlich mit örtlicher Wärme, durch das Verkleben von blutzuführenden Gefäßen oder mit örtlich verabreichten Giften behandelt. Diese Therapieoptionen sind aber alle bestimmten bösartigen Tumoren vorbehalten und machen nur einen geringen Teil der ausgeführten Therapie aus. Bekannt ist, dass die Tumorvakzinierung gegen Melanome bei Hunden mindestens den gleichen Therapieerfolg wie eine Chemotherapie hat, dies aber bei weitaus geringeren bzw. keinen Nebenwirkungen (I. Kurzman, University of Wisconsin, Madison). Bei Pferden gibt es bereits zahlreiche positive Erfahrungen bei bösartigen Tumoren und Sarkoiden mit einer Vakzine mit dendritischen Zellen. Außerdem gibt es Behandlungsformen im Bereich der Komplementärmedizin, die die vorgenannten jedoch keinesfalls ersetzen können, sondern lediglich als ergänzende Maßnahmen zu verstehen sind.

Bösartige Tumoren sind nach den Herz-Kreislauf-Erkrankungen die zweithäufigste Todesursache in den industrialisierten Ländern.

Gutartige Tumoren sind sehr häufig. Die meisten Menschen besitzen mehrere gutartige Tumoren, vor allem an der Haut. Einige primär gutartige Tumoren können zu bösartigen Tumoren entarten und müssen entfernt werden. Dies ist vor allem bei Polypen der Dickdarmschleimhaut der Fall. Häufig empfinden Menschen gutartige Tumoren der Haut auch als kosmetisch störend, manchmal können diese z. B. in Körperfalten gereizt werden, so dass auch hier eine Entfernung sinnvoll erscheint.



</doc>
<doc id="5065" url="https://de.wikipedia.org/wiki?curid=5065" title="Terrorismus">
Terrorismus

Unter Terrorismus ( ‚Furcht‘, ‚Schrecken‘) versteht man Gewaltaktionen gegen Menschen oder Sachen (wie Entführungen, Attentate, Sprengstoffanschläge etc.) zur Erreichung eines politischen, religiösen oder ideologischen Ziels. Terrorismus ist das Ausüben und Verbreiten von Terror. Er dient als Druckmittel und soll vor allem Unsicherheit und Schrecken verbreiten oder Sympathie und Unterstützungsbereitschaft erzeugen bzw. erzwingen. Es gibt keine allgemein akzeptierte wissenschaftliche Definition von Terrorismus. Schwierigkeiten bereitet insbesondere die Abgrenzung von Terrorismus zu politischem Widerstand und Aktivismus. Typischerweise werden Personen und Bewegungen, die von einer Seite als gewalttätige, aber legitime Untergrund- oder Widerstandskämpfer angesehen werden, aus einem anderen Blickwinkel als Terroristen bezeichnet, und umgekehrt. Die verschiedenen juristischen Definitionen des Begriffs, ob im nationalen Strafrecht oder im internationalen Recht, sind häufig aus ähnlichen Gründen umstritten.

Terroristen streben zunächst nach Anerkennung, doch greifen sie nicht militärisch nach Raum (wie der Guerillero), sondern wollen nach einer klassischen Formulierung Franz Wördemanns „das Denken besetzen“ und dadurch Veränderungsprozesse erzwingen. So ist Terrorismus keine Militär-, sondern primär eine Kommunikationsstrategie. 

Personen und Gruppen, welche Anschläge verüben („Terroristen“ oder „Terrororganisationen“), werden von Politik und Medien oft vereinfachend als „der Terrorismus“ bezeichnet, etwa in Begriffen wie „der internationale Terrorismus“. Der Begriff Staatsterrorismus bezeichnet staatlich organisierte oder geförderte Gewaltakte, die nicht immer auf gesetzlicher Grundlage beruhen bzw. als terroristisch bewertet werden.

Die Worte "Terrorismus", "Terrorist" und "terrorisieren" wurden erstmals im 18. Jahrhundert zur Bezeichnung einer gewaltsamen Regierungsmaßnahme verwendet. Im Zusammenhang mit der Französischen Revolution wurde der „Terror des Konvents“ von 1793 bis 1794 ausgerufen, als die Regierung alle als konterrevolutionär eingestuften Personen hinrichten oder inhaftieren ließ. Dabei wurden unter anderem Ludwig XVI., Marie Antoinette und Gräfin Dubarry guillotiniert. Bereits 1795 findet der Begriff Terrorismus Eingang in den deutschen Sprachgebrauch. Er ist zunächst synonym mit der Schreckensherrschaft der Jakobiner in Frankreich und wird ab den 1820er Jahren auf Kunst und Ästhetik übertragen.

Eine objektive Eingrenzung des Begriffs Terrorismus ist schwierig, da er von den jeweils herrschenden Regierungen gerne als Legitimation, zur Denunzierung ihrer Gegner – manchmal auch unabhängig davon, ob diese Gewalt anwenden oder nicht – und zur Rechtfertigung eigener Gewaltanwendung gegen vermeintliche oder tatsächliche Feinde der gegenwärtigen Staatsordnung herangezogen wird. Schwierigkeiten bereitet insbesondere die Abgrenzung zwischen verbrecherischen Handlungen und legitimen Akten des Widerstands.

Von Widerstandsbewegungen, Guerillas oder nationalen Befreiungsbewegungen unterscheidet sich der Terrorismus weniger durch die Wahl seiner Waffen als in der Wahl seiner Ziele: Eine nationale Befreiungs- oder Widerstandsbewegung ist zumeist militärisch raumgreifend, der Terrorismus dagegen versucht, mit seinen Gewaltakten möglichst große Aufmerksamkeit zu erlangen, um geschlossene Machtstrukturen zu untergraben und die Angreifbarkeit solcher Strukturen zu exemplifizieren und der Bevölkerung öffentlich zu erschließen.

Auch verschwimmen in länger bestehenden terroristischen Organisationen nicht selten durch eine Kommerzialisierung („Gewaltunternehmertum“ nach Elwert) die Grenzen zur organisierten Kriminalität (zum Beispiel finanzierten sich IRA und ETA teilweise durch Schutzgelderpressung bei örtlichen Unternehmern.)

Was als Terrorismus zu bezeichnen ist und was nicht, dazu gibt es weder in der politischen Praxis noch in der Forschung eine einheitliche Definition. Der Sicherheitsrat der Vereinten Nationen erarbeitete 2004 in Resolution 1566 eine völkerrechtlich verbindliche Definition, wenngleich sie bislang noch keine umfassende Anerkennung gefunden hat. Die Grenze zwischen „Widerstandskämpfer“ und „Terrorist“ ist weltanschaulich geprägt und daher oft strittig. Der Soziologe Henner Hess findet in der Begrifflichkeit ein Problem, da es im Auge des Betrachters läge. Wen manche als Terroristen nennen, können andere als „Gotteskrieger“, Revolutionär oder Freiheitskämpfer definieren. Richard Reeve Baxter, ehemaliger Richter am Internationalen Gerichtshof, äußerte sich wie folgt:
So existiert für nahezu jeden Staat eine andere Definition von Terror. In den USA gelten darüber hinaus verschiedene Definitionen der einzelnen Behörden. Dabei spiegelt die Definition die Prioritäten und besonderen Interessen der jeweiligen Behörde. So begreift das US-Außenministerium gewaltsame Akte dann als terroristisch, wenn sie sich gegen Nichtkombattanten richten, während das Ministerium für Innere Sicherheit schon dann von Terror spricht, wenn wichtige Infrastruktur angegriffen wird.

Im Jahre 1988 existierten bereits 109 verschiedene Definitionen von dem Wort „Terror“ und diese Anzahl dürfte speziell nach dem 11. September 2001 weit gestiegen sein. Einige Terrorismusforscher unterscheiden zwischen den Begriffen „Terrorismus“ und „Terror“. Demnach wird eine gewaltsame Methode als Terror verstanden, wenn sie von einem Staat angewendet wird, was auch als Staatsterrorismus bezeichnet wird. Diese Bezeichnung ist aber zumindest in den anderen Definitionen nicht enthalten. In der Terrorismusforschung wird Terrorismus als gewaltsame Methode verstanden, die nicht zuletzt gegen Zivilisten und zivile Einrichtungen gerichtet ist. Der Freiheits- oder Widerstandskämpfer wendet zwar physische Gewalt an, doch beschränkt er sich dabei vornehmlich auf militärische Ziele und beabsichtigt damit unmittelbar die Ziele seiner Organisation zu erreichen. Im Gegensatz dazu geht es dem Terroristen primär um die psychischen Folgen der Gewaltanwendung. Die Violenz des Terroristen ist kommunikativ und indirekt, der Terrorist kann sein Ziel nur über Umwege erreichen. Seine Kommunikation ist an sein Opfer, das ein Staat und seine Apparate sein kann, oder auch Zivilisten gerichtet. Der Widerstands- oder Freiheitskämpfer beschränkt sich dabei vornehmlich auf militärische Ziele.

Die Disziplin der Terrorismusforschung ist neueren Datums und hat bisher ebenfalls keine allgemeingültige wissenschaftliche Definition hervorgebracht. Erstmals fand der Begriff während der Französischen Revolution Anwendung, hatte jedoch im Gegensatz zu seiner heutigen negativen Behaftung einen positiven Beiklang. Für das sogenannte „regime de la terreur“, auch "La Grande Terreur" der Jahre 1793/94, von dem sich sowohl das englische Wort „terrorism“, wie auch der deutsche Begriff herleitet, galt "terreur" (Schrecken) als Instrument zur Durchsetzung von Ordnung in der von Unruhen und Aufständen gezeichneten anarchischen Zeit nach der Erhebung von 1789. Es zielte darauf ab die Macht der neuen Regierung durch die Einschüchterung von Kontrarevolutionären und Andersdenkenden zu festigen. Einer der geistigen Motoren der Revolution, Maximilien de Robespierre, fasst sein Verständnis von Terror in jener Zeit wie folgt: „Terror ist nichts anderes als Gerechtigkeit, sofortige, unnachsichtige und unbeugsame Gerechtigkeit; er stellt daher eine Ausdrucksform der Tugend dar“ (Berhane 2011).

Jedoch erst die Verkopplung mit den Massenmedien machte den Terrorismus zu einer weltweit politisch-militärischen Strategie. Nach Carsten Bockstette kann Terrorismus wie folgt definiert werden: Terrorismus ist der nachhaltige und verdeckt operierende Kampf auf allen Ebenen durch die bewusste Erzeugung von Angst durch schwerwiegende Gewalt oder der Androhung derselben, zum Zweck der Erreichung eigener politischer Ziele. Dies geschieht unter teilweiser Nichtachtung von existierenden Konventionen der Kriegsführung. Hierbei wird versucht, höchstmögliche Publizität zu erlangen. Demnach ist die Erzeugung von Schrecken ein wichtiger Bestandteil der Definition.

Terrorismus kann nach Bockstette ein Teil eines asymmetrischen Konfliktes sein und trägt einen Konflikt mit geringfügigen Ressourcen gegen eine deutlich überlegene Macht mit gewaltsamen Mitteln aus dem Untergrund aus. Oft reklamieren terroristische Gruppen für sich, Guerilleros zu sein und einen Partisanenkampf mit unkonventionellen Methoden des Gewaltgebrauchs aufgrund ihrer militärischen Unterlegenheit führen zu müssen. Terroristen allerdings sind im Vergleich zu Partisanen normalerweise nicht in der Lage, eine direkte militärische Konfrontation zu überstehen und meiden diese, da sie dem Gegner in Anzahl und Ausrüstung unterlegen sind. Terroristen achten, anders als Partisanen, nicht auf die physischen, sondern schwerpunktmäßig auf die psychischen Folgen ihrer Anschläge.

Nach der umfangreichen Definition von Pehlivan ist Terrorismus „[…] die Erzeugung von Schrecken

Vom Terrorismus unterschieden werden kann der Terror, die Schreckensherrschaft als ein Machtmittel (prima ratio) durch Staaten gegenüber der eigenen Bevölkerung.“

Eine weltweit einmalige Ausweitung hat der Begriff seit 2013 in der Türkei erfahren. Im Mai 2016 stellte die in Ankara ansässige Denkfabrik TARK fest, dass es in der Türkei 11.000 aus politischen Gründen Inhaftierte gäbe, nicht zuletzt Akademiker, Journalisten und andere Intellektuelle, wobei es ein weltweit einmaliger Zustand sei, dass in der Türkei auch dann wegen Terrorismus verurteilt werden könne, wenn selbst mittelbar keinerlei Bezug zu politischer Gewalt angeklagt sei. Hierfür sei durch die AKP-Regierung der Begriff „unbewaffneter Terrorismus“ erfunden und durch die Rechtsprechung angewandt worden.

"„Der […] Guerilla besetzt tendenziell den Raum, um später das Denken gefangen zu nehmen, der Terrorist besetzt das Denken, da er den Raum nicht nehmen kann.“" Dieser Satz Franz Wördemanns ist möglicherweise die umfassendste Begriffsdefinition von Terrorismus. Er grenzt den Terrorismus von anderen Gewaltkonflikten ab wie zwischenstaatlichen Kriegen, Guerillakriegen und vom Kriegsunternehmertum. Dies schließt jedoch nicht aus, dass sich Akteure letztgenannter Konflikte auch terroristischer Mittel bedienen. Terroristische Aktionen sind nach gängiger Auffassung Gewaltanwendungen gegen zivile Ziele und Nichtkombattanten mit dem Vorsatz, Furcht und Schrecken zu verbreiten sowie möglicherweise bei einer Drittpartei um Sympathie und Schadenfreude zu werben mit der Absicht auch, das bestehende Herrschaftssystem auszuhöhlen und umzustürzen.

Anstelle eines Versuches, den Begriff Terrorismus an sich zu definieren, soll das schon beschriebene moralische Dilemma am Beispiel des Umgangs der Vereinten Nationen mit dem Terrorismus illustriert werden, das auch von Hoffman 2002 beschrieben wird:

Nach der Geiselnahme von München bei den Olympischen Spielen 1972, in deren Verlauf elf israelische Sportler getötet wurden, schlug der damalige UN-Generalsekretär vor, dass die Vereinten Nationen sich aktiv im Kampf gegen den Terrorismus engagieren sollten. Dem widersprachen verschiedene arabische, afrikanische und asiatische Mitgliederstaaten mit der Begründung, dass jede Befreiungsbewegung von den Unterdrückern unausweichlich als Terrorismus bezeichnet würde. Völker aber, die unterdrückt und ausgebeutet werden, hätten jedes Recht, sich zur Wehr zu setzen, einschließlich der Gewalt. Daher würde eine Entscheidung für einen aktiven „Kampf gegen den Terrorismus“ die etablierten Strukturen über die nicht etablierten Herausforderungen stellen und damit den status quo festigen. Syrien fügte hinzu, dass es die moralische und rechtliche Pflicht der Vereinten Nationen sei, den Kampf für Befreiung zu unterstützen.

Aus dieser Debatte ergab sich eine definitorische Lähmung der Vereinten Nationen, die bis heute nicht überwunden wurde. Auch in der Mitteilung vom 8. Dezember 2004 zur 59. Vollversammlung der Vereinten Nationen wird empfohlen, die ausstehende Definition von Terrorismus in Angriff zu nehmen. Dies war allerdings auch schon in vorangegangenen Mitteilungen empfohlen worden, verbunden mit einer Deklaration zur Terrorismusbekämpfung.

Nach Kofi Annans Definition handelt es sich bei all jenen Handlungen um Terrorismus, die die Absicht haben, den Tod oder schwere körperliche Verletzungen bei Zivilisten und nicht Kämpfenden herbeizuführen mit dem Ziel, die Bevölkerung einzuschüchtern oder eine Regierung oder eine internationale Organisation dazu zu zwingen, etwas zu tun oder zu unterlassen. Dabei sei es nicht nötig, darüber zu diskutieren, ob Staaten sich des Terrorismus schuldig machen können oder nicht, denn der uneingeschränkte Einsatz von Waffengewalt seitens eines Staates gegen eine Zivilbevölkerung sei schon durch das internationale Recht klar untersagt.

Mitunter finden sich auch Stimmen, die für einen ideologisch und politisch neutraleren Zugang zum Thema Terrorismus werben.

Als Terrorist wird eine Person bzw. als Terroristen werden Personengruppen bezeichnet, die Anschläge und andere terroristische Aktionen bzw. Wirkungen beabsichtigen, ankündigen, planen und durchführen. Die Zuordnung wird typisch von den davon betroffenen Gruppen getroffen. Für den Terroristen gehören teils das Leben im Untergrund, der bewaffnete Kampf und die Inkaufnahme oder gar die Einplanung des eigenen Tods (Selbstmordattentäter) zu den typischen Merkmalen. Weiterhin prägend ist eine für die jeweilige Person durchgehende, akzeptierte und teils selbst artikulierte Überzeugung in Kombination mit einer starken Radikalisierung.

Terrorismus ist weltweit verbreitet und ein aktuelles, aber keineswegs ein neues Phänomen (siehe Sikarier, Zelot, Assassinen und die Bewegung Junges Italien um Giuseppe Mazzini). Einen Überblick geben die Listen bekannter Attentate, Sprengstoff- und Terroranschläge. Die moderne Form des Terrorismus entwickelte sich in Europa wohl in der Sattelzeit um 1800 und wird in der Regel mit einer Ideologie begründet, die sich gegen die angegriffenen Personen, Personengruppen oder den Staat richtet und die mit friedlichen Mitteln nicht durchsetzbar sei (siehe dazu auch Fundamentalismus und Extremismus). Die Historikerin Carola Dietze kam 2016 in ihrer Studie über die "Erfindung des Terrorismus" zum Ergebnis, dass die moderne Ausprägung – mit Rückgriffen auf die Amerikanische und Französische Revolution – sich erst mit dem Attentat Felice Orsinis auf Napoleon III. 1858 und dessen transnationaler Rezeption in Europa, Russland und den Vereinigten Staaten verdichtet habe.

Der Terrorismusexperte David C. Rapoport hat "vier Wellen" des Terrorismus seit dem 19. Jahrhundert identifiziert – eine anarchistische, eine antikoloniale, eine neu-linke und eine religiöse –, die von Beginn an transnationale Medienereignisse gewesen seien (während frühere terroristische Aktivitäten wie die des Ku-Klux-Klan regional isoliert geblieben seien): In der ersten hätten Anarchisten den modernen Terrorismus in den 1880er Jahren vom russischen Zarenreich ausgehend begründet, was etwa eine Generation lang angedauert habe. Die folgenden, teilweise überlappenden Wellen seien ebenso globale Phänomene gewesen: Ab den 1920er Jahren sei für etwa 40 Jahre die antikoloniale Welle beherrschend gewesen, ab den 1960er Jahren die neulinke Welle, die Ende des 20. Jahrhunderts abgeebbt und von der ab 1979 prävalenten religiösen Welle abgelöst worden sei. Bedeutende Beispiele der neulinken Welle sind die Rote Armee Fraktion (RAF), die Irish Republican Army (IRA), die Brigate Rosse (BR) und die Euskadi Ta Askatasuna (ETA).

Nach dem 11. September 2001 führte der „Krieg gegen den Terrorismus“ der US-Regierung zu einer neuen Dimension des Terrorismus durch gezielt geplante Selbstmordattentate von Islamististen, insbesondere durch das Terrornetzwerk Al-Qaida. Dessen Mitglieder beriefen sich auf einen historischen Hintergrund, der bis in Zeit der Kreuzzüge zurückreicht. So bezeichnete Osama bin Laden die Völker des Westens als „Kreuzfahrer“ und forderte von den Muslimen des Ostens einen „Krieg der Religionen“, um die muslimische Gemeinschaft im Westen zu unterstützen. Historischer Bezugspunkt ist die islamische Religionsgemeinschaft der Ismailiten, eine Splittergruppe der Schiiten, was jedoch mit deren theologischen und philosophischen Traditionen nicht vereinbar ist.

Ziel der Terroristen ist, auf ihre politischen, moralischen oder religiösen Anliegen aufmerksam zu machen und deren Beachtung mit Gewalt zu erzwingen. Das terroristische Kalkül wird durch eine Dreiersequenz gekennzeichnet:


Vergeltungsmaßnahmen erzeugen (im besten Fall) Sympathie und Unterstützungsbereitschaft bei der Zielgruppe. Das System, so lautet die Hoffnung der Terroristen, „demaskiert“ oder „entlarvt“ sich. Wenn durch zunehmende Unterstützung zum offenen Guerillakampf übergegangen werden kann, ist das terroristische Kalkül aufgegangen.

Durch die in der Bevölkerung durch Anschläge aufkommende Angst wächst tendenziell der Glaube, die Regierung könne nicht für den Schutz der Bürger im Lande sorgen. Die Macht der Regierung wird somit von „innen“ geschwächt. Dass der Staat zu Gegenmaßnahmen greift, war z. B. von der deutschen RAF geradezu beabsichtigt: Die staatlichen Reaktionen sollten die Bürger dazu bewegen, sich gegen den Staat und seine Herrschaftsgewalt aufzulehnen.

Terrorismus ist eine Gewaltstrategie nichtstaatlicher und staatlicher Akteure, die damit politische, ideologische, aber auch religiöse und sogar geschäftliche Ziele durchsetzen wollen. In Bezug auf das Verhältnis von Aufwand und Ergebnis kann Terrorismus gleichzeitig eine sehr effiziente Form der Kriegsführung sein. Ohne großen Aufwand und Ausrüstung kann sehr großer Schaden angerichtet und großer Eindruck verschafft werden.

Die Strategie des Terrorismus setzt vor allem auf psychologische Effekte. Die betroffene Zielgruppe soll schockiert und eingeschüchtert, zum Beispiel der Krieg somit in das vermeintlich sichere „Hinterland“ des Feindes getragen werden. Durch die Verbreitung von Unsicherheit und Verwirrung soll der Widerstand gegen die Terroristen gelähmt werden.

In der Tat teilen sämtliche terroristische Verbände gewisse Grundzüge, zum Beispiel eine relativ schwache Position gegenüber dem angegriffenen Machtapparat. Die Gewalt richtet sich häufig gegen Ziele mit hohem Symbolgehalt (z. B. religiöse Orte, Regierungsgebäude), um den Gegner zu demütigen und zu provozieren, vermehrt aber auch gegen so genannte weiche Ziele, also Plätze des öffentlichen Lebens, die nur schwer geschützt werden können (z. B. öffentliche Verkehrsmittel, Restaurants). Ferner kommt es zu Geiselnahmen und Entführungen, u. a. auch offizieller Vertreter des „Gegners“. Typischerweise sind die Opfer von Terrorakten am Konflikt vollkommen Unbeteiligte (Frauen und Kinder, Bürger von am Konflikt nicht beteiligten Staaten).

Die Wirkung terroristischer Aktivitäten kann durch die Berichterstattung in den Massenmedien verstärkt werden; einige Terroristen verwenden diesen Effekt bewusst, etwa durch die Verbreitung von Hinrichtungs-Videos von Entführungsopfern.

Ein weiteres Ziel terroristischer Aktivitäten ist die Mobilisierung von Sympathisanten und die Radikalisierung politisch nahestehender Bewegungen. Hierbei sehen sich Terroristen als Befreier der „Unterdrückten“.

Die Mobilisierung von Unterstützern wird oft vor allem durch die Gegenreaktionen des „Gegners“ auf Anschläge erreicht. Lässt dieser sich zu unverhältnismäßigen, brutal wirkenden Maßnahmen provozieren, so soll ihn dies „entlegitimieren“ (z. B. Einschränkung der Freiheitsrechte durch Ausgangssperren). Auf diese Weise können Terroristen in die Rolle des Angegriffenen wechseln.

In jüngster Zeit zielt die Gewaltstrategie von Terroristen auch auf die Erzeugung von wirtschaftlichen Effekten. Indem schwer zu schützende Ziele von wirtschaftlicher Bedeutung angegriffen werden (z. B. Anschläge auf Ölförderanlagen oder auf Touristenzentren), sollen die Ökonomie und die Regierungen der „Gegner“ destabilisiert und die eigenen politischen Ideologien durchgesetzt werden.

Ein bedeutendes Merkmal terroristischer Gruppen ist, dass sie meistens als Terrorzellen taktisch völlig unabhängig voneinander operieren. Jede Terrorzelle entscheidet autonom, wann und wo sie die Initiative ergreift. Das führt dazu, dass Terroristen nicht als klar erkenn- und abgrenzbare Kampfeinheiten angreifbar sind (siehe Terrorismusbekämpfung).

Terroristische Gruppen entfalten häufig zugleich kriminelle Aktivitäten, die nicht primär politisch motiviert sind, sondern etwa der Beschaffung von Finanzmitteln dienen. Daher weisen sie (wie z. B. ETA oder die PKK) oft zwangsläufig eine Verbindung zur organisierten Kriminalität auf.

Zwei Möglichkeiten, Terrorismus zu untergliedern, erscheinen sinnvoll. Zum einen nach der räumlichen Ausdehnung, zum anderen nach Motivation und Zielsetzung. Nach der räumlichen Ausdehnung lassen sich drei Typen des Terrorismus unterscheiden:


Legt man jeweils Motivation und Zielsetzung zu Grunde, so lassen sich folgende Hauptformen des Terrorismus erkennen:

Der politisch links motivierte, sozialrevolutionäre Terrorismus hat seinen geistigen Ursprung in der Propaganda der Tat des 19. Jahrhunderts, der nicht auf die Zivilbevölkerung zielte.

Im Umfeld der „Neuen Linken“ entstand Anfang der 1970er Jahre in Westdeutschland eine neue Spielart des linken Terrorismus, der durch die Ablehnung der Bundesrepublik gekennzeichnet war. Seine bekanntesten Ausläufer hatte der linke Terrorismus in der RAF und in den italienischen Roten Brigaden hinsichtlich der Öffentlichwirksamkeit ihrer Anschläge. Die Anschläge zielten dabei auf die revolutionäre Umwälzung bestehender gesellschaftlicher Herrschafts- und Besitzverhältnisse im betroffenen Land ab, bisweilen auch auf den Versuch, einen revolutionären Bürgerkrieg zu entfesseln. Sie stießen jedoch in Deutschland auf eine große allgemeine Ablehnung. In den Ländern der westlichen Welt scheiterten derartige Bewegungen durchweg und verloren mit dem Fall des Eisernen Vorhangs völlig an Bedeutung. In Lateinamerika war er Ursprung für heutige Guerillavereinigungen wie die FARC oder die ELN. Gegenwärtig gibt es diesen marxistisch inspirierten Terrorismus in Gestalt „maoistischer Bewegungen“ in einigen Ländern Süd- und Südostasiens.

Rechtsterroristische Aktivitäten speisen sich zumeist aus rassistischen und völkischen Überzeugungen.
Die größte Anzahl von Toten ist in Deutschland durch den Rechtsterrorismus zu verzeichnen. Der Beginn rechtsterroristischer Aktivitäten in Deutschland kann mit dem Mord an Kurt Eisner 1919 angegeben werden. In der Weimarer Republik begingen Rechtsradikale bis zu 400 „Fememorde“, unter den Opfern der zumeist in Freikorps organisierten Tätern waren vor allem Politiker der Sozialdemokratie und Kommunisten. Mit der Machtübernahme der Nationalsozialisten 1933 wurde Rechtsterrorismus staatliche Politik. Für die ersten beiden Jahrzehnte der Bundesrepublik Deutschland sind keine rechtsterroristischen Aktivitäten nachweisbar. Ende der 1960er Jahre bildete sich ein gewaltbereiter neonazistischer Untergrund und 1968 wurde von der Gruppe um Bernd Hengst das Büro der DKP beschossen. Der bekannteste Anschlag der Wehrsportgruppe Hoffmann war das Bombenattentat auf das Münchner Oktoberfest mit 12 Toten. Deutsche Aktionsgruppen unter Manfred Roeder begingen sieben Anschläge mit zwei Toten. In den 1980er und 1990er Jahren verlagerte sich der Schwerpunkt rechtsterroristischer Aktivitäten von politischen Gegnern zu rassistischen Attacken wie dem Mordanschlag von Mölln und dem Brandanschlag von Solingen und der Mord- und Anschlagsserie des Nationalsozialistischen Untergrunds. Neben den organisierten Gruppen agierten Einzeltäter wie Kay Diesner. Mehrere Anschläge wie jener auf die Münchner Synagoge durch das Aktionsbüro Süd konnten im Vorfeld aufgedeckt werden. Ähnliche Aktivitäten sind im gesamten europäischen Raum nachweisbar, die größte Anzahl an Todesopfern forderten die Anschläge in Norwegen 2011.
In den Vereinigten Staaten ist der Rechtsterrorismus zudem religiös begründet und erklärt sich aus endzeitlicher Eschatologie und dem Kampf gegen als satanisch identifizierte Personen und Gruppen und weist Überschneidungen mit dem Militia- sowie Abtreibungsgegner­milieu auf. In den USA lässt sich der rechtsextreme Terrorismus mit dem Ku-Klux-Klan bis ins 19. Jahrhundert zurückverfolgen. Breit rezipierte Vorkommnisse neuerer Zeit sind Ruby Ridge und Branch Davidians sowie der Bombenanschlag auf das Murrah Federal Building in Oklahoma City.

Der nationalistische bzw. ethnisch-nationalistische Terrorismus ist der Kampf eines Volkes oder einer ethnischen Minderheit mit dem Ziel vermehrter Autonomie oder der Gründung eines eigenen Staates unter Berufung auf „historisch gewachsene Besonderheiten“. Zur Politik dieser Terrorismusform gehört die Tradition der Konfliktivität und der gewaltsamen Selbsthilfe.

Beispiele: Die ETA (Basken), ASALA (Armenier), die PKK (Kurden), die IRA, UVF und UDA (alle drei Nordiren) in Europa und Vorderasien.

Der Ausdruck „religiöser Terrorismus“ stößt weithin auf Widerspruch, sowohl bei den Vertretern der Religionen selbst als auch bei Außenstehenden, die der Religion an sich oft kein terroristisches Potential zusprechen. Historisch hat sich jedoch gezeigt, dass als terroristisch einzustufende Aktionen vielfach in religiösem Kontext erfolgen, allerdings zeitlich und räumlich so unterschiedlich und vielschichtig, dass die Möglichkeit einer Definition immer wieder angezweifelt wird.

Eine Betrachtung des religiösen Terrorismus konzentriert sich auf das Motiv, durch das "religiöse" Menschen zu terroristischen Aktionen bewegt werden. Als Merkmal des religiösen Terrorismus gilt daher in erster Linie die persönliche Überzeugung der Täter. Der Philosoph Jakob Friedrich Fries schuf dafür im 19. Jahrhundert nicht nur für religiöse Attentäter eine theoretische Grundlage. Nach Bruce Hoffman stellt Gewalt für den religiösen Terroristen „zuerst und vor allem einen sakramentalen Akt oder eine von Gott gebotene Pflicht dar“.

Vor allem seit Mitte der 1980er Jahre hat der religiöse Terrorismus an Bedeutung gewonnen. Er geht aus Sekten oder fundamentalistischen Strömungen innerhalb bestimmter Religionen hervor. Insbesondere radikal-islamische Organisationen wie die palästinensische Hamas, die libanesische Hisbollah und nicht zuletzt die Terrornetzwerke Al-Qaida und Islamischer Staat sind bekannte Beispiele für islamistisch motivierten Terrorismus.

Als Gründe für islamistischen Terror werden materielle und spirituelle Motive genannt. So meint der Ökonom Muhammad Yunus: „Nehmen Sie die Islamisten: Sie geben den Armen etwas zu essen, außerdem Waffen und eine Ideologie. Es gibt gar keinen Zweifel, dass Armut die Brutstätte von Terrorismus ist.“ Einige islamistische Terroristen wie Umar Farouk Abdulmutallab stammen allerdings aus der gebildeten Oberschicht, sodass Armut zwar als ein Faktor, nicht aber als alleinige Ursache gelten kann.

"Homegrown Terrorism" („hausgemachter Terrorismus“) bezeichnete ursprünglich Terror, der von Personen ausgeht, die im Zielland des Terrors unscheinbar aufwuchsen und erst dort zu ihrer terroristischen Überzeugung gelangten. Der Begriff wird vor allem im anglophonen Sprachraum bei islamistischem Terror der neueren Zeit angewandt.

Man bezeichnete damit zum Beispiel die Terroranschläge am 7. Juli 2005 in London, wo bei insgesamt vier Explosionen in drei U-Bahnen und einem Bus 56 Menschen ums Leben kamen und mehr als 700 verletzt wurden. Die größtenteils aus Pakistan stammenden Täter wurden in Großbritannien geboren, entstammten säkularen Familien und waren ins Gemeindeleben integriert, bevor sie sich islamistischen Organisationen anschlossen und Terror gegen das eigene Land ausübten. Der Begriff wurde eingeführt, weil bisherige islamistische Terroranschläge in westlichen Ländern vorwiegend von extra zu diesem Zweck eingereisten Menschen ausgeübt wurden. Dessen ungeachtet ging Terror in Europa bis in die 1980er vor allem von Personen aus, die aus dem jeweiligen Zielland stammten, so etwa die Rote Armee Fraktion in der Bundesrepublik Deutschland oder die Action directe (AD) in Frankreich.

Seit Beginn des 21. Jahrhunderts bezeichnen Sicherheitskreise Deutschlands mit "hausgemachtem Terrorismus" eine Art des islamistischen Terrorismus, dessen Akteure nicht mehr traditionell aus islamischen Ländern stammen oder Nachkommen islamischer Immigranten sind. Der „neue“ hausgemachte Terrorismus rekrutiert sich vielmehr aus gebürtigen deutschen Staatsangehörigen, vor allem Jugendlichen, die zum Islam konvertiert und ins Fahrwasser des Islamismus geraten sind. Sie werden in speziellen Trainingscamps islamischer Länder ausgebildet und mit den technischen wie ideologischen Voraussetzungen zur Durchführung von Terroraktionen ausgestattet.

Als typisches Beispiel des hausgemachten Terrorismus charakterisierte der deutsche Bundesminister des Innern Wolfgang Schäuble die am 5. September 2007 deutschen Fahndern ins Netz gegangenen drei Mitglieder der Islamischen Dschihad-Union, von denen zwei zum Islam konvertierte Deutsche seien.

Der Präsident des Bundeskriminalamtes Jörg Ziercke sieht Deutschland damit nicht mehr nur als Ruheraum, sondern auch als Ziel des internationalen Terrorismus.

Der konservativ motivierte „vigilantistische Terrorismus“ zielt im Gegensatz zu anderen Formen des Terrorismus nicht auf die Schwächung, sondern auf die "Stärkung" der bestehenden staatlichen Ordnung ab, allerdings indem die Gesetze, auf denen diese Ordnung beruht, durch Selbstjustiz gebrochen werden. Der rassistische Ku-Klux-Klan in den USA und paramilitärische Gruppierungen in Lateinamerika und Nordirland sind als vigilantistischer Terrorismus zu bezeichnen, ebenso – laut dem Soziologen Matthias Quent – der rechtsterroristische Nationalsozialistische Untergrund in Deutschland.

Der Terror war auch in Staaten mit etabliertem Rechtssystem gelegentlich eine Antwort der in ihren Rechten tatsächlich oder vermeintlich verletzten Schwächeren gegenüber den Stärkeren. Ein Beispiel bildet die von Kleist in der Novelle Michael Kohlhaas literarisch verarbeitete blutige Fehde des Kaufmanns Hans Kohlhase gegen den Kurfürsten von Sachsen. Gerhard Gönner beschreibt diese Form von Terror als „Antwort der verletzten verabsolutierten Rechtschaffenheit“. Sie resultiere aus einer eigentlich passiven Haltung zur Welt, die in ständiger Furcht vor Verletzung zu einem Aggressionsstau führe. Dieser könne angesichts einer ungesühnten Rechtsverletzung zu terroristischen Ausbrüchen führen.

"Staatsterrorismus" bezeichnet Gewaltakte, die als terroristisch eingestuft sind und von Staatsorganen oder zumindest informell durch einen Staat kontrollierten Akteuren (z. B. Todesschwadronen oder Untergrundbewegungen) vollzogen beziehungsweise durch eine souveräne Regierung gefördert werden. So sind aus der jüngeren Vergangenheit Fälle dokumentiert, in denen Staaten bzw. deren Geheimdienste unter „falscher Flagge“ Terrorakte initiierten, die dann etwa unerwünschten politischen Gruppierungen untergeschoben wurden, um diese zu diskreditieren.

"Staatsterror" bezeichnet staatsphilosophisch den gezielten Einsatz der Angst der Bürger vor dem Gewaltmonopol des Staates als Zwangsmittel zur Erzwingung der Gesetzestreue seiner Bürger. Am prominentesten wurde der Begriff vom Liberalismus des Hobbesschen Kontraktualismus in seinem Werk "Leviathan" geprägt. Für Hobbes verlieh der Terror dem Staat ("terror of legal punishment") das notwendige und legale Zwangsmittel zu seiner Konstitution.

In der Totalitarismustheorie bildet der staatliche Terror, etwa durch Kontrolle und Überwachung und den Verzicht auf rechtsstaatliche Prinzipien, ein zentrales Merkmal totalitärer Staaten. Insbesondere wird von Staatsterror gesprochen, wenn sich ein totalitäres System gewaltsam seiner Gegner entledigt: Als im 20. Jahrhundert hervorstechende Beispiele für solchen Staatsterror werden zuvorderst die innenpolitische gewaltsame bis zur willkürlichen Ermordung reichende Unterdrückung von auch vermeintlichen Oppositionellen während der NS-Diktatur in Deutschland sowie unter der Herrschaft Josef Stalins in der Sowjetunion benannt, dort insbesondere die sogenannten Stalinschen Säuberungen, auch bezeichnet als „Großer Terror“. Bei anderen geschichtlichen Vorgängen ist die Begriffsverwendung nicht eindeutig, so wird etwa die Entführung und Ermordung von bis zu 30.000 Menschen durch die argentinische Militärdiktatur ab 1976 je nach Quelle sowohl als "Staatsterrorismus" als auch als Staatsterror bezeichnet.

Der Begriff bezeichnet Taten (ausdrücklich auch Straftaten), die eine politische Dimension haben (Terrorismus) und im Zusammenhang mit der Umwelt (Ökologie) stehen. Nach verschiedenen Verständnissen bezeichnet man damit

Die Nutzung biologischer Kampfstoffe wird als Bioterrorismus bezeichnet.

Demokratie kann man definieren als „Herrschaft durch das Volk“. Dies beinhaltet eine verantwortliche Regierung, die auf die Interessen des Volkes eingehen muss und die vom Volk abhängig ist. Das Volk verfügt über die Macht, bei Wahlen die Regierung abzuwählen. Damit bestimmt das Elektorat zu einem großen Teil die Richtung der Politik. Wenn Terrororganisationen (vor allem in der Zeit vor Wahlen) die Präferenzen des Elektorats beeinflussen, dann kann dies die Innenpolitik eines Staates direkt oder indirekt beeinflussen und/oder sich auf den Wahlausgang auswirken.

Der Effekt von Terrorismus auf Präferenzen der Wählerschaft lässt sich exemplarisch am Nahostkonflikt darlegen. Bei einer zeitlichen Betrachtung des Konflikts ergibt sich hinsichtlich der politischen Orientierung einzelner Gebiete, dass Terrorismusereignisse in rechtsorientierten Bezirken die Unterstützung rechter Parteien erhöhen. In linksorientierten Gebieten hingegen nimmt die Unterstützung rechter Parteien ab, wenn sich die Anschläge außerhalb des jeweiligen Bezirks ereigneten. Damit erzielen terroristische Aktivitäten eine Polarisierung des Elektorats. Diese Ergebnisse beziehen sich hauptsächlich auf anhaltenden innerstaatlichen Terrorismus. Dem gegenüber steht der Einfluss transnationalen Terrorismus’. Die spanischen Parlamentswahlen kurz nach den Madrider Zuganschlägen bieten hier einen Einblick. Die Anschläge mobilisierten Bürger, die für gewöhnlich wenig partizipieren, darunter jüngere oder weniger gebildete Bürger. Zudem wurden Wähler der Mitte und der Linken mobilisiert und einige wechselten zur Opposition. Nicht zuletzt beeinflussten die Anschläge die Wahlentscheidung der Bürger. Die Misswirtschaft der konservativen Partei Partido Popular (PP) und deren Außenpolitik im Irak und Afghanistan hatten nachweislich Einfluss auf die Präferenzen des spanischen Elektorats; die PP verlor bei den Wahlen kurz nach den Anschlägen Wählerstimmen und musste in die Opposition. Wenn Terroranschläge also kurz vor Parlamentswahlen stattfinden, löst dies seitens der Opposition und der Medien eine Bewertung der bisherigen Politikergebnisse der regierenden Parteien aus. Terrorismus trägt somit zur Mobilisierung des Elektorats bei.

Neben dem direkten Einfluss von Terrorismus auf die Präferenzen der Wähler wirken sich Terroranschläge auch auf die Koalitionsbildung innerhalb repräsentativer Demokratien aus. Somit werden sich eher Koalitionen bilden, die externen Schocks standhalten können. Angesichts terroristischer Bedrohungen bilden sich deshalb eher übergroße Koalitionen, da angenommen wird, dass Politiker durch übergroße Koalitionen in dieser Zeit eine Instabilität der Regierung vermeiden wollen. Außerdem führen externe Bedrohungen zu ideologisch homogenen Koalitionen, da ein interner Konsens eher zu Stabilität führt. Dieser Effekt entsteht insbesondere bei transnationalen Terroranschlägen, da Parteien in Bezug auf innerstaatlichen Terrorismus bereits politische Positionen einnehmen und Koalitionsmöglichkeiten somit ohnehin eingeschränkt sind. Transnationaler Terrorismus fördert daher übergroße, ideologisch homogene Regierungen, da diese angeblich konsequenter gegen externe Bedrohungen vorgehen können.

Ein weiteres Problem stellt das Verbot terroristischer Parteien dar, da dies im Widerspruch zu dem Recht der Bürger innerhalb einer Demokratie steht, sich kompetitiven Wahlen zu stellen. Kommt es also zum Verbot politischer Parteien, werden fundamentale Prinzipien der Repräsentation und Gleichheit übergangen – ein demokratisches Paradox entsteht (vgl. streithafte Demokratie). Gleichwohl ist es in einigen post-kommunistischen Ländern sowie in zahlreichen afrikanischen und indischen Verfassungen möglich, Parteien zu verbieten. Auch in Israel und Deutschland besteht die Möglichkeit, mit einem sogenannten Parteiverbot eine Partei zu verbieten, weil sie Terrorhandlungen oder bewaffnete Auseinandersetzungen gegen den Staat unterstützt oder ermutigt. Terrorismus beeinflusst somit das Legitimitätsprinzip repräsentativer Regierungen.

Zusammenfassend kann davon ausgegangen werden, dass Demokratien die Gefahr von terroristischen Anschlägen erhöhen: Das Elektorat, aber auch die Regierung eines Staates reagieren auf Terroranschläge, was Terroristen Einflussmöglichkeiten auf die Innenpolitik eines Staates bietet. Allerdings ist dieser Zusammenhang nicht eindeutig, da die Responsivität demokratischer Systeme zu einer Mäßigung extremistischer Gruppen führen könnte und außerdem den Nutzen terroristischer Aktivitäten verringert. Die Beziehung zwischen Demokratien und Terrorismus lässt sich somit auch unter Berücksichtigung der politischen Konsequenzen nicht eindeutig herausarbeiten.

Im Wesentlichen kann man hier zwei Ansätze unterscheiden: Bekämpfung des Terrorismus

Dazu treten Maßnahmen der Überwachung—insbesondere

Inzwischen nimmt jedoch die Skepsis vor übertriebenem Abhören und Überwachen zu, insbesondere seit den Enthüllungen Edward Snowdens über die NSA. In europäischen Medien wurde diesbezüglich der Begriff „Terror-Paranoia“ geprägt, der vor allem mit den USA assoziiert wird.

Der "Krieg gegen den Terrorismus" (engl. „War on Terrorism“) ist ein von der US-Regierung unter George W. Bush verbreitetes politisches Schlagwort, das eine Bandbreite politischer, militärischer und juristischer Schritte gegen den als Problem identifizierten internationalen Terrorismus zusammenfasst.

Eine ‚terroristische Vereinigung‘ (deutscher Rechtsbegriff seit 1976) oder ‚terroristische Organisation‘ (Vereinte Nationen) ist eine auf eine längere Dauer angelegte Organisation mehrerer Personen (Terroristen), deren Ziel es ist, durch Handlungen, die unter rechtsstaatlichen Voraussetzungen als Straftaten bewertet werden, vor allem politische Ziele zu erreichen. Diese Ziele können von anderen (zum Beispiel religiösen oder wirtschaftlichen) Motiven begleitet sein. Terroristische Vereinigungen versuchen durch Gewaltaktionen, Schrecken (lat. "terror") in ein Land zu tragen, um ihre Ziele zu erreichen.

Der unter () StGB dargelegte Straftatbestand „Bildung terroristischer Vereinigungen“ wurde 1976 im Zuge der Terrorismusbekämpfung in das StGB aufgenommen und führte den Begriff „Terroristische Vereinigung“ als Rechtsbegriff ein. 129a StGB ist Bestandteil eines von Kritikern als "Lex RAF" bezeichneten Gesetzesbündels, das mit besonderem Bezug auf die Rote Armee Fraktion (RAF) verabschiedet (= eingeführt) wurde.

Die Liste der durch das Außenministerium der Vereinigten Staaten ausgewiesenen terroristischen Organisationen im Ausland wird von vielen Staaten als Rechtsgrundlage für eine entsprechende Strafverfolgung benutzt.

Laut National Counterterrorism Center (NCTC) der USA starben 2011 insgesamt 12.500 Menschen durch terroristische Angriffe. Einer Studie des Institutes for economy & peace zufolge fielen weltweit im Jahr 2012 11.133 Menschen und im Jahr 2013 17.958 Menschen terroristischen Attacken zum Opfer. Im Jahr 2013 verloren über 80 % der Opfer in einem der folgenden fünf Länder ihr Leben: Irak, Afghanistan, Pakistan, Nigeria und Syrien. 66 % der Anschläge wurden von einer der folgenden Terrorgruppen (oder ihren Partnern) verübt: Islamischer Staat, Boko Haram, von den Taliban und al-Qaida.

Im Jahr 2014 gab es etwa 32.685 Tote durch terroristische Angriffe. Dabei wurden 78 % in einem der fünf Ländern Irak, Nigeria, Afghanistan, Pakistan und Syrien getötet. Boko Haram tötete 6.644, ISIL 6073, die Taliban 3.310 und Islamisten aus dem Volk der Fulbe 1.229 Menschen.

Zwei sehr detaillierte Studien über den Nordirlandkonflikt der Jahre 1969 bis 1998, das CAIN-Projekt von der University of Ulster und Lost Lives, errechnete rund 1.800 Todesopfer. 

Zwischen 1970 und 1998 wurden durch Anschläge der RAF 34 Menschen ermordet. Laut dem "National Consortium for the Study of Terrorism and Responses to Terrorism" (Global Terrorism Database der University of Maryland, USA) sind in Europa allein von 2000 bis 2015 durch Terrorismus 675 Menschen ums Leben gekommen.

Siehe auch Innere Sicherheit

Die Gefahr eines Terroranschlags in westlichen Staaten wird im Allgemeinen in der Bevölkerung erheblich überschätzt. Terroranschläge sind äußerst seltene Ereignisse, werden jedoch in der medialen Berichterstattung überproportional hervorgehoben. Es ist in Deutschland (Stand Frühjahr 2016) etwa 1,13-fach wahrscheinlicher, von einem Blitz erschlagen als Opfer eines islamistischen Terroranschlags zu werden, die Wahrscheinlichkeit, an einer Grippe zu sterben, 3797-fach höher.




</doc>
<doc id="5066" url="https://de.wikipedia.org/wiki?curid=5066" title="Talk (Mineral)">
Talk (Mineral)

Das Mineral Talk (Steatit, Magnesiumsilikathydrat, in pulverisierter Form "Talkum"; nicht zu verwechseln mit Talg) ist ein sehr häufig vorkommendes Schichtsilikat mit der chemischen Zusammensetzung Mg[SiO(OH)].

Es kristallisiert je nach Modifikation als Talk-1A im triklinen oder als Talk-2M im monoklinen Kristallsystem und entwickelt überwiegend blättrige, massige bzw. derbe Mineral-Aggregate, sehr selten auch makroskopisch erkennbare, tafelige oder pseudotrigonal-pyramidale Kristalle von meist mattweißer oder blassgrüner Farbe. Ebenso findet sich Talk in Form von Pseudomorphosen nach Quarz oder Anthophyllit.

Talk gehört zu den gesteinsbildenden Mineralen in der Epizone der kristallinen Schieferreihe und ist Hauptbestandteil des Specksteins.

Speckstein und damit auch Talk sind bereits seit dem Altertum bekannt. Die Sprachwissenschaftler vermuten, dass die Bezeichnung ursprünglich aus der persischen Sprache stammt und dann über das arabische "talq" in den gesamten indogermanischen Sprachraum übernommen wurde. Einige oberdeutsche Dialekte verwenden noch heute die Bezeichnungen „talket“ und „talkert“ zur Beschreibung der Eigenschaft "weich" bzw. "unfest".

In der älteren Version (8. Auflage) der Systematik der Minerale von Hugo Strunz gehört der Talk zur Abteilung der „Schichtsilikate (Phyllosilikate)“ und bildet dort zusammen mit Ferripyrophyllit, Kegelit, Macaulayit, Minnesotait, Pyrophyllit und Willemseit eine eigene Gruppe.

Seit der Überarbeitung der Strunz'schen Mineralsystematik in der 9. Auflage werden die Schichtsilikate präziser nach der Struktur der Silikatschichten unterteilt, wobei das Mineral entsprechend in der Unterabteilung der „Schichtsilikate (Phyllosilikate) mit Glimmertafeln, zusammengesetzt aus tetraedrischen und oktaedrischen Netzen“ zu finden ist.

Die Systematik der Minerale nach Dana sortiert den Talk ebenfalls in die Abteilung der Schichtsilikate ein, und auch in der Systematik von Dana wird nach der Kristallstruktur weiter präzisiert. Allerdings wird hier die Unterabteilung beschrieben als „Schichtsilikate mit Schichten von sechsgliedrigen Ringen mit 2:1-Lagen“. In dieser Unterabteilung bildet der Talk zusammen mit Pyrophyllit als Leitmineral die nach ihnen benannte „Pyrophyllit-Talk-Gruppe“, in der außer diesen beiden noch Brinrobertsit, Ferripyrophyllit, Minnesotait und Willemseit zu finden sind.

Talk-1A kristallisiert triklin in der mit den Gitterparametern "a" = 5,291 Å; "b" = 9,460 Å; "c" = 5,290 Å; α = 98,68°; β = 119,90° und γ = 85,27° sowie zwei Formeleinheiten pro Elementarzelle.

Talk-2M kristallisiert monoklin in der Raumgruppe mit den Gitterparametern "a" = 5,287 Å; "b" = 9,158 Å; "c" = 18,95 Å und β = 99,30° sowie vier Formeleinheiten pro Elementarzelle.

Reiner Talk ist farblos oder durch Gitterbaufehler bzw. mikrokristalline Ausbildung in massigen Aggregaten weiß. Durch Fremdbeimengungen kann er aber auch von grauer, hell- bis dunkelgrüner oder gelblicher Farbe sein. Als Mineralgemenge im Speckstein sind weitere Farbvarianten möglich.

Eine grünliche Farbe kann ein Hinweis auf den möglichen Einbau von Fe durch Einlagerung von Minnesotait sein.
Talk besitzt die geringstmögliche Mohshärte 1 und ist damit ein Referenzmineral auf der Mohs'schen Härteskala. Aufgrund seiner geringen Härte neigt er häufig zu Stapelfehlern in der Kristallstruktur.

Das Mineral ist wasserabweisend und fühlt sich seifig oder fettig an, daher wird er synonym oft auch als Speckstein bezeichnet.

In blättrigen und grobschuppigen Aggregatformen zeigt Talk eine sehr vollkommene Spaltbarkeit mit permuttähnlichem Glanz auf den Spaltflächen. Einzelne Blättchen sind milde biegsam. Auch in Bezug auf optische und sonstige Eigenschaften ist Talk den Glimmern sehr ähnlich.

Vor dem Lötrohr ist das Mineral fast unschmelzbar. Er blättert allerdings durch die Hitzeeinwirkung auf, leuchtet stark und wird nach dem Austreiben des Kristallwassers feuerfest. Seine Mohshärte steigt dabei auf 6.

Der seit 1979 nicht mehr als eigenständiges Mineral angesehene Kerolith wird heute als die grüne, nickelhaltige Varietät des Talkes angesehen.

Talk bildet sich meist sekundär durch Umwandlung von aluminiumoxidfreienbzw. -armen Mineralen wie beispielsweise Olivinen oder Enstatit, aber auch metamorph Gesteinen bis etwa 500 °C wie z. B. Marmor, Metaultrabasiten und Dolomit oder hydrothermal in Gängen. Begleitminerale sind unter anderem Aktinolith, Anthophyllit, Calcit, Chlorite, Dolomit, Pyroxene, Serpentine, Tremolit und Vermiculit.

Weltweit sind bisher (Stand: 2011) fast 2300 Fundorte bekannt. Erwähnenswert sind unter anderem die Fundorte Brumado im brasilianischen Bundesstaat Bahia, wo tafelige Kristalle von bis zu zwei Zentimetern Größe gefunden wurden, sowie das Gotthardmassiv in der Schweiz mit Funden von Pseudomorphosen nach Quarz.

In Deutschland tritt das Mineral unter anderem im Schwarzwald in Baden-Württemberg, im Frankenland, Niederbayern und der Oberpfalz in Bayern, im hessischen Odenwald, im niedersächsischen und thüringischen Harz, im Sauerland und Siegerland in Nordrhein-Westfalen, an mehreren Fundpunkten in Rheinland-Pfalz, im Erzgebirge und in der Oberlausitz in Sachsen sowie im Thüringer Wald auf.

Weitere ergiebige Fundorte (drei oder mehr Regionen) sind unter anderem in Australien, Brasilien, China, Finnland, Frankreich, Indien, Italien, Japan, Kanada, Madagaskar, Mexiko, Namibia, Norwegen, Österreich, Peru, Russland, Sambia, Schweden, Schweiz, Simbabwe, Slowakei, Spanien, Südafrika, Südkorea, Ungarn, den Vereinigten Staaten sowie im Vereinigten Königreich (Großbritannien).

Auch in Gesteinsproben vom Mittelatlantischen Rücken und vom Roten Meer sowie in der Nähe der japanischen Forschungsstation Shōwa-Station in der Antarktis konnte Talk nachgewiesen werden.

Der weltweit größte Förderer von Talk ist die "Talc de Luzenac", die zur Imerys-Gruppe gehört.

Talk ist aufgrund seiner besonderen Eigenschaften (weich, wasserabweisend) vielseitig verwendbar und wird bevorzugt in pulverisierter Form als Gleitmittel mit geringer Scheuerwirkung eingesetzt oder Stoffen beigemengt, um ihnen wasserabweisende oder abdichtende Eigenschaften zu verleihen.

Fein gemahlen wird Talk zum einen als Füllstoff in der Papier- und Zellstoffindustrie, der Farben- und Lackindustrie sowie der Gummi-, Kunststoff- und Keramikindustrie verwendet und zum anderen als Trennmittel in Kabeln und zwischen Reifen und Schlauch.

In der Kunststoffindustrie finden Verstärkungsstoffe auf Basis von Talkum beispielsweise bei der Verstärkung von Polyolefinen, wie HDPE oder PP, einen vielseitigen Einsatz in der Auto- oder Bauindustrie. Ende der 1960er-Jahre wurden erstmals talkum- (TV) und glasfaserverstärkte (GFV) Produkte auf Basis PP angeboten. Mit Talkum verstärkte Polypropylencompounds finden seit etwa 1975 in einem breiten Einsatzgebiet Verwendung.

Talk bzw. gemahlener Speckstein ist Rohstoff und Hauptbestandteil der technischen Keramik "Steatit", ein in der Elektrotechnik häufig verwendetes Isoliermaterial, z. B. für Sicherungs-Schmelzeinsätze und Isolatoren.

Talkumpuder wird bei vielen Produkten auf Puderbasis in der Kosmetik eingesetzt wie beispielsweise in Babypuder und anderen Körper- und Gesichtspudern wie Kompaktpuder, Bronzer, Rouge oder Kajalstiften und Liplinern. Früher puderten Eltern ihre Kinder in der Windelgegend, um die Haut zu trocknen und Hautrötungen oder einer Windeldermatitis vorzubeugen. Aufgrund von inzwischen weit verbreiteten modernen, saugstarken Einwegwindeln ist das Pudern der Windelgegend bei Babys inzwischen unnötig. Zudem belegen Aufzeichnungen seit den frühen 1980er Jahren, dass mehrere Tausend Kleinkinder jedes Jahr sterben bzw. ernsthaft erkranken, nachdem sie versehentlich diesen Puderstaub eingeatmet hatten. Eine weitere Studie konnte nachweisen, dass Frauen, die häufig (zwischen einmal pro Woche bis täglich) Talkumpuder im Genitalbereich anwenden, ein um 40 % höheres Risiko haben, an Eierstockkrebs zu erkranken. Die Verwendung von talkumhaltigen Produkten sollte daher möglichst komplett vermieden werden.

In der Medizin wird es zur Pleurodese (gewollte, permanente Verklebung des Rippenfells mit der Lungenoberfläche) verwendet (Talkumpleurodese). Es wird speziell für medizinische Zwecke hergestellt, ist steril und garantiert asbestfrei. Eine weitere Besonderheit besteht in einer definierten Körnchengröße. Dadurch wird die Migration (Wanderung) des Talkumpulvers in andere Gewebe vermieden.

Außerdem wird "Talkum" bzw. "Talcum" in der Pharmaindustrie sowohl als Pudergrundlage als auch als Gleitmittel bei der Tablettenherstellung verwendet. Es wird in der Zahnmedizin als Füllstoff für starre Abformmaterialien wie beispielsweise thermoplastische Kompositionsmassen verwendet. Talkumpuder wird auch bei der Benutzung von Diaphragmen und Kondomen benutzt.

In der Bildenden Kunst ist Talk als Hauptbestandteil des Werkstoffs Speckstein bekannt.

In der Lebensmitteltechnologie findet Talk als Trennmittel und Trägersubstanz (für Farbstoffe) Verwendung. Es ist in der EU als Lebensmittelzusatzstoff mit der Nummer "E 553b" zugelassen.


Das Einatmen von feinem Talkpulver kann zu Entzündungen in den peripheren Atemwegen führen, die zu sogenannten Fremdkörpergranulomen führen können (siehe auch: Pneumokoniose). Granulombildung erfolgt auch auf der Haut, wenn zu grobkörniges Puder (Partikelgröße > 100 µm) angewendet wird. Dies ist besonders bei offenen Wunden problematisch.

Mit einer möglichen Krebsgefahr befassen sich seit Jahrzehnten etliche Studien und Gegenstudien. Gesundheitliche Probleme sind bei faserhaltigem Talkum zu erwarten, das eine ähnliche Wirkung wie Asbest hat. Faserhaltiges Talkum darf daher zu pharmazeutischen Zwecken nicht eingesetzt werden. Zudem konnte auch nachgewiesen werden, dass Talkpartikel Tumore in den Eierstöcken und in der Lunge verursachen können. Inwiefern eine sorgsame Kontrolle bei Kosmetikprodukten erfolgt, ist jedoch unklar.

2006 hat die Internationale Agentur für Krebsforschung Talkumpuder als mögliches Karzinogen klassifiziert, wenn es im weiblichen Intimbereich benutzt wird.

Wegen fehlender Warnhinweise auf seinen talkumhaltigen Produkten ist der US-Kosmetik-Konzern Johnson & Johnson von einem US-Gericht im Februar 2016 zu 72 Millionen Dollar (rund 65 Mio. Euro) Schadenersatz verurteilt worden. Geklagt hatten die Angehörigen einer Oktober 2015 an Eierstockkrebs gestorbenen Frau, die jahrzehntelang Puder der Firma verwendet hatte. Babypuder aus Talkum ist seit 1893 im Sortiment von Johnson & Johnson, das Puder „Shower to Shower“ wurde 2012 an den kanadischen Konzern Valeant Pharmaceuticals International verkauft. Johnson & Johnson bietet heute auch Babypuder aus Maisstärke an; feuchte Maisstärke kann jedoch – im Gegensatz zu Talkum – einen Nährboden für Hefepilze abgeben.

2017 musste Johnson & Johnson einer Krebspatientin in Kalifornien rund 350 Millionen Euro zahlen. Ein Gericht in Los Angeles verhängte die Rekordstrafe gegen den global agierenden Konzern.




</doc>
<doc id="5069" url="https://de.wikipedia.org/wiki?curid=5069" title="Tobey Maguire">
Tobey Maguire

Tobias Vincent „Tobey“ Maguire [] (* 27. Juni 1975 in Santa Monica, Kalifornien) ist ein US-amerikanischer Filmschauspieler und Filmproduzent.

Tobey Maguires Vater Vincent war Koch, verließ aber die Familie zwei Jahre nach Tobeys Geburt. Während seiner Kindheit wechselte Maguire mit seiner alleinerziehenden Mutter häufig den Wohnsitz und lebte u. a. in Kalifornien, Oregon und Washington.

2007 erzählte Maguire in einem Interview mit der Zeitschrift „Player“, er habe während dieser Zeit zwölfmal die Schule gewechselt und durch die ständigen Neuanfänge einen Großteil seines Selbstbewusstseins verloren, schließlich sogar Magenprobleme bekommen. Früh war er alkoholabhängig geworden, besiegte aber mit 19 Jahren die Sucht mit Hilfe der Anonymen Alkoholiker, zu denen er sich öffentlich bekannte. Maguire wollte eigentlich wie sein Vater Koch werden, doch seine Mutter bot ihm 100 Dollar, wenn er statt des Hauswirtschaftskurses an der High School den Schauspielkurs belegen würde. Dieses Angebot nahm er an.

Nachdem er nach der neunten Klasse die Schule endgültig verlassen hatte, folgten Auftritte in diversen Werbefilmen und kleine Nebenrollen in Fernsehserien.

Beim Vorsprechen für die Fernsehserie "Parenthood" lernte Maguire Leonardo DiCaprio kennen, mit dem er inzwischen eng befreundet ist.

1992 bekam Maguire seine erste Hauptrolle in der Fernsehserie "Great Scott!". Ein Jahr später bekam er eine Rolle neben DiCaprio und Robert De Niro im Spielfilm "This Boy’s Life". Während der Film für DiCaprio den Durchbruch im Filmgeschäft darstellte, musste sich Maguire danach noch mit Rollen in Fernsehfilmen begnügen. Erst die Zusammenarbeit mit Ang Lee in "Der Eissturm", einem Werk über die sexuelle Revolution der 1970er Jahre, verhalf Maguire 1997 zu größerer Bekanntheit. Woody Allen wurde auf ihn aufmerksam und besetzte ihn in seinem Film "Deconstructing Harry". 

In negative Schlagzeilen geriet er, als der Regisseur R. D. Robb den Kurzfilm "Don’s Plum", entgegen der Abmachung mit den Hauptdarstellern DiCaprio und Maguire, veröffentlichen wollte. In dem spontan entstandenen Film unterhielten sich beide Schauspieler an einer Bar über vermeintlich anstößige Themen. Danach folgte ein kurzer Auftritt in "Fear and Loathing in Las Vegas" und die männliche Hauptrolle in "Pleasantville – Zu schön, um wahr zu sein", bevor er in Lasse Hallströms Oscar-prämiertem Film "Gottes Werk & Teufels Beitrag" nach John Irvings gleichnamigem Roman die Rolle des „Homer Wells“ neben Michael Caine spielte. Durch diese Rolle wurde Maguires Ruf als talentierter Schauspieler gefestigt, den er durch eine weitere Zusammenarbeit mit Ang Lee beim Bürgerkriegsdrama "Ride with the Devil" und seiner Rolle in "Die WonderBoys" neben Michael Douglas und Robert Downey Jr. bestätigte.

Bedeutende Hauptrollen spielte Maguire in "Seabiscuit – Mit dem Willen zum Erfolg" sowie in den Comic-Verfilmungen "Spider-Man" und "Spider-Man 2". Für den ersten der Spider-Man-Filme trainierte Maguire sechs Monate lang, um seinen Körper für die Rolle des Superhelden in Form zu bringen. Für seine Jockey-Rolle in "Seabiscuit" nahm er direkt im Anschluss zehn Kilogramm ab, um möglichst dünn und leicht zu wirken. 

Der Film "Spider-Man 3", in dem Maguire erneut die Hauptrolle spielte, lief am 1. Mai 2007 in den deutschen Kinos an. Entgegen zunächst anderslautenden Aussagen gaben Maguire und seine Filmpartner Kirsten Dunst und Sam Raimi im Januar 2010 bekannt, dass sie aus der Produktion für weitere Spider-Man-Filme ausgestiegen seien. Als Gründe wurden Differenzen über das Drehbuch und die Verjüngung des Protagonisten angegeben. Der Filmstart des vierten Teils der Reihe wurde auf Sommer 2012 verschoben, der nun aber mit anderen Schauspielern verfilmt wurde.

Im Jahr 2013 spielte er an der Seite seines engen Freundes Leonardo DiCaprio in Baz Luhrmanns 3-D-Romanverfilmung "Der große Gatsby" eine Hauptrolle. Danach war er 2014 in einigen Produktionen zu sehen, 2015 und 2016 trat er nicht als Schauspieler in Erscheinung, 2017 war er im Original in "The Boss Baby" zu hören.

Maguire trat auch als Produzent in Erscheinung, darunter in Spike Lees New-York-Film "25 Stunden". Zudem ist er Eigentümer der Produktionsfirma Material Pictures.

Tobey Maguire war seit dem 3. September 2007 mit Jennifer Meyer verheiratet. Das Paar hat zwei Kinder, eine Tochter (* 2006) und einen Sohn (* 2009). Am 18. Oktober 2016 gab das Paar die Trennung und bevorstehende Scheidung bekannt.

Seit 1992 war Maguire überzeugter Vegetarier und seit 2009 ernährt er sich vegan.

Als professioneller Pokerspieler hat Maguire bereits über 200.000 US-Dollar an Preisgeldern gewonnen. Im Juni 2011 wurde gegen ihn Anklage wegen illegalen Glücksspiels erhoben.



In Der Eissturm und Gottes Werk & Teufels Beitrag wurde Tobey Maguire von Florian Bauer synchronisiert. Meistens ist aber seine deutsche Standardstimme die von Marius Clarén.



</doc>
<doc id="5070" url="https://de.wikipedia.org/wiki?curid=5070" title="Taliban">
Taliban

Die Taliban, manchmal auch Taleban (), sind eine deobandisch-islamistische Miliz, welche von September 1996 bis Oktober 2001 große Teile Afghanistans beherrschte. Der Name ist der persische Plural des arabischen Wortes "talib" (arabisch ), das „Schüler“ oder „Suchender“ bedeutet. Diplomatisch wurde das Islamische Emirat Afghanistans der Taliban nur von Pakistan, Saudi-Arabien und den Vereinigten Arabischen Emiraten anerkannt.

Die Taliban-Bewegung hat ihre Ursprünge in religiösen Schulen für afghanische Flüchtlinge in Pakistan, welche meist von der politischen pakistanischen Partei Jamiat Ulema-e-Islam geführt wurden. Die Ideologie der Bewegung basiert auf einer extremen Form des Deobandismus und ist zudem stark vom paschtunischen Rechts- und Ehrenkodex, dem Paschtunwali, geprägt. Der Anführer der Taliban war bis 2013 Mullah Mohammed Omar. Omars Nachfolger Akhtar Mansur wurde 2016 bei einem Drohnenangriff getötet. Mansurs Nachfolger ist Haibatullah Achundsada.

Die Taliban traten erstmals im Jahre 1994 in der südlichen Stadt Kandahar in Erscheinung. Sie belagerten und beschossen zwei Jahre lang die Hauptstadt Kabul, nahmen sie im September 1996 ein und errichteten das Islamische Emirat Afghanistan. Im Oktober 2001 wurde ihre Regierung durch Truppen der afghanischen Vereinten Front in Zusammenarbeit mit amerikanischen und britischen Spezialeinheiten während der US-geführten Intervention in Afghanistan gestürzt. Ihre Führer konnten sich durch einen Rückzug nach Pakistan halten. Seit 2003 führen die Taliban ausgehend von Pakistan eine terroristisch-militärische Kampagne gegen die demokratische Islamische Republik Afghanistan und die internationalen Truppen der ISAF in Afghanistan. Hierbei verüben die Taliban mehr als doppelt so häufig gezielte Anschläge gegen die afghanische Zivilbevölkerung als gegen die afghanischen oder internationalen Truppen. Ein Bericht der Vereinten Nationen zeigt, dass die Taliban in den Jahren 2009 und 2010 für über 3/4 der zivilen Todesopfer in Afghanistan verantwortlich waren. Menschenrechtsorganisationen haben den Internationalen Strafgerichtshof in Den Haag dazu veranlasst, eine vorläufige Untersuchung gegen die Taliban wegen systematischer Kriegsverbrechen durchzuführen.

Sabiullah Mudschahid gilt als Sprecher der Taliban.

Nach dem Zusammenbruch des sowjetgestützten Regimes von Präsident Mohammed Nadschibullāh einigten sich die sieben wichtigsten sunnitischen Mudschaheddin-Parteien im Jahr 1992 auf einen Friedensvertrag, die Peschawar-Abkommen, der den Islamischen Staat Afghanistan begründete und eine Übergangsregierung einsetzte. Das Abkommen konnte allerdings nicht den Zusammenbruch des Staats verhindern: Die neue Regierung verfügte über keinerlei Einnahmen und in der Hauptstadt herrschte Chaos: Gulbuddin Hekmatyār und seine Hizb-i-Islāmi-Miliz, von Pakistan bewaffnet, finanziert und angeleitet, starteten eine umfassende Bombenkampagne gegen Kabul und die Übergangsregierung. Dies geschah, obwohl Hekmatyār wiederholt das Amt des Ministerpräsidenten angeboten worden war.

Zusätzlich eskalierten Mitte 1992 Spannungen zwischen der von Saudi-Arabien unterstützten radikal-sunnitischen Ittihad-i Islami und der vom Iran unterstützten schiitischen Hizb-i Wahdat. Die Milizen starteten einen blutigen Krieg. Die Hizb-i-Wahdat-Miliz ging Ende 1992 eine Allianz mit Hekmatyār ein. Abdul Raschid Dostum und seine Dschunbisch-i-Milli-Miliz schlossen sich dieser Allianz Anfang 1994 an. Während der intensivsten Phase des Bombardements durch die Allianz Hekmatyārs starben in Kabul über 25.000 Menschen.

Auch Kandahar, eine Stadt im Süden des Landes, welche nicht unter Kontrolle des neu gegründeten Staates stand, und Masar-e Scharif im Norden, erlebten blutige Kämpfe. Dagegen waren die im Sowjetisch-Afghanischen Krieg verwüsteten ländlichen Regionen von Kämpfen kaum betroffen und der Wiederaufbau begann.

Der Süden Afghanistans war weder unter der Kontrolle der Zentralregierung noch unter der Kontrolle von Milizen wie der Hekmatyars. Lokale Milizen- oder Stammesführer beherrschten den Süden. 1994 traten die Taliban in der südlichen Stadt Kandahar erstmals in Erscheinung. Als auslösender Moment wird in verschiedenen Quellen die Entführung und Vergewaltigung zweier Mädchen durch einen Milizenführer genannt, zu deren Befreiung sich 30 Männer unter der Führung von Mullah Omar zusammenschlossen.

Im Herbst 1994 traten sie erstmals militärisch in Erscheinung und brachten am 5. November 1994 die Stadt Kandahar unter ihre Kontrolle. Bis zum 25. November 1994 kontrollierten sie die Stadt Laschkar Gah und die Provinz Helmand. Im Laufe des Jahres 1994 eroberten sie weitere Provinzen im Süden und Westen des Landes, die nicht unter Kontrolle der Zentralregierung standen.

Ebenfalls Ende 1994 besiegte der afghanische Verteidigungsminister Ahmad Schah Massoud die Milizen, die um die Kontrolle der Hauptstadt Kabul gekämpft hatten. Die Bombardierung der Hauptstadt kam zu einem Halt. Massoud initiierte einen landesweiten politischen Prozess mit dem Ziel nationaler Konsolidierung und demokratischen Wahlen. Es fanden drei Konferenzen mit Vertretern aus den meisten Provinzen Afghanistans statt. Massoud lud die Taliban ein, sich diesem Prozess anzuschließen und sich an der Schaffung von Stabilität zu beteiligen. Die Taliban lehnten eine demokratische Staatsform ab.

Anfang 1995 starteten die Taliban großangelegte Bombenkampagnen gegen Kabul. Amnesty International schrieb: Die Taliban erlitten schwere Niederlagen gegen die Truppen Massouds. Internationale Beobachter vermuteten bereits das Ende der Talibanbewegung. Mit militärischer Unterstützung Pakistans und finanziellen Hilfen aus Saudi-Arabien formierten sie sich jedoch neu. Zwei Jahre belagerten und bombardierten sie Kabul. Im September 1996 planten die Taliban eine erneute Großoffensive gegen Kabul. Maßgeblich beteiligt an der finanziellen und materiellen Förderung der Taliban durch Pakistan waren der damalige General und spätere Präsident Pervez Musharraf und Innenminister Nasirullah Babar, der die Taliban als „unsere Jungs“ bezeichnete.

Am 26. September 1996 befahl Massoud einen strategischen Rückzug seiner Truppen in den Norden Afghanistans. Am 27. September 1996 marschierten die Taliban in Kabul ein und errichteten das Islamische Emirat Afghanistan, welches lediglich von Pakistan, Saudi-Arabien und den Vereinigten Arabischen Emiraten anerkannt wurde. Die Regierung des Islamischen Staates Afghanistans blieb die international anerkannte Regierung Afghanistans (mit einem Sitz bei den Vereinten Nationen).

Die Taliban verhängten über die Gebiete unter ihrer Kontrolle ihre politische und juristische Interpretation des Islam. Frauen lebten quasi unter Hausarrest.

Nach einem Bericht der Vereinten Nationen begingen die Taliban systematische Massaker gegen die Zivilbevölkerung, während sie versuchten, ihre Kontrolle im Westen und Norden Afghanistans zu konsolidieren. Die Vereinten Nationen benannten 15 Massaker in den Jahren 1996 bis 2001. Diese seien „höchst systematisch gewesen und alle auf das Verteidigungsministerium [der Taliban] oder Mullah Omar persönlich zurückzuführen.“ Die sogenannte 055 Brigade al-Qaidas war ebenfalls an Gräueltaten gegen die afghanische Zivilbevölkerung beteiligt.<ref name="Ahmed Rashid/The Telegraph"></ref>

Ahmad Schah Massoud und Abdul Raschid Dostum, frühere Gegner, gründeten die Vereinte Front ursprünglich als Reaktion auf massive Talibanoffensiven gegen die Gebiete unter der Kontrolle Massouds auf der einen Seite und die Gebiete unter der Kontrolle Dostums auf der anderen Seite. Schon bald entwickelte sich aus der Vereinten Front jedoch eine nationale politische Widerstandsbewegung gegen die Taliban. Dieser traten die von den Taliban durch "ethnische Säuberungen" verfolgte Volksgruppe der Hazara bei, ebenso wie paschtunische Anti-Taliban-Führer wie der spätere Präsident Hamid Karzai, der aus dem Süden Afghanistans stammt, oder Abdul Qadir. Qadir entsprang einer einflussreichen Familie, welche großen Einfluss im paschtunischen Osten Afghanistans um Dschalalabad genoss.

Die Situation der Menschenrechte hing von den jeweiligen Kommandeuren ab, die bestimmte Gebiete kontrollierten. Human Rights Watch verzeichnet keine Menschenrechtsverbrechen für die Truppen unter der direkten Kontrolle Ahmad Schah Massouds für den Zeitraum von Oktober 1996 bis zu Massouds Ermordung im September 2001. Massoud hatte Kontrolle über Pandschschir, Thakar, einige Teile Parwans und Badachschans. Zwischenzeitlich waren auch Nuristan, Kunduz und die Gebiete nördlich Kabuls unter seiner Kontrolle.

Nach Angaben von Human Rights Watch datieren die meisten Menschenrechtsverletzungen, die von Mitgliedern der Vereinten Front begangen wurden, in dem Zeitraum von 1996 bis 1998, während Abdul Raschid Dostum weite Teile des Nordens kontrollierte. Bis zu seiner Niederlage im Jahr 1998 kontrollierte Dostum Samangan, Balch, Dschowzdschan, Faryab und Baglan. Im Jahr 1997 exekutierten Dostums Truppen unter dem Kommando von Abdul Malik Pahlawan 3000 Taliban-Gefangene in und um Masar-e Scharif. Im Jahr 1998 besiegten die Taliban Abdul Raschid Dostum in Masar-e Scharif. Dostum ging ins Exil. Wenig später verloren auch die Hezb-i-Wahdat-Truppen ihre Gebiete an die Taliban. Die Taliban ermordeten in der Folge um die 4000 Zivilisten in und um Masar-e Scharif in einer gezielten Kampagne.

Ahmad Schah Massoud blieb der einzige Kommandeur, der seine Gebiete erfolgreich gegen die Taliban verteidigen konnte. Pakistan unterstützte die Offensiven der Taliban, konnte jedoch keine Niederlage Massouds herbeiführen. Die Taliban boten ihm wiederholt eine Machtposition an. Massoud lehnte dies ab. Er erklärte in einem Interview: 
Massoud wollte die Taliban davon überzeugen, sich einem politischen Prozess anzuschließen, welcher letztendlich zu demokratischen Wahlen führen sollte.

Anfang 2001 wandte die Vereinte Front eine neue Strategie von lokalem militärischem Druck und einer globalen politischen Agenda an. Ressentiments und Widerstand gegen die Taliban, ausgehend von den Wurzeln der afghanischen Gesellschaft, wurden immer stärker. Dies betraf auch die paschtunischen Gebiete. Insgesamt flohen schätzungsweise eine Million Menschen vor den Taliban. Hunderttausende Zivilisten flohen in die Gebiete von Ahmad Schah Massoud. Der Regisseur David Keane kam in seiner Dokumentation "Inside the Taliban" für den National Geographic Channel zu folgendem Schluss: In den Gebieten unter seiner Kontrolle trainierte Massoud verstärkt Polizeikräfte, die eine Wiederholung des Chaos’ von Kabul (1992–1994) verhindern sollten, würde die Vereinte Front erfolgreich sein.

Im Frühling 2001 sprach Ahmad Schah Massoud vor dem Europäischen Parlament in Brüssel und bat die internationale Gemeinschaft um humanitäre Hilfe für die Menschen Afghanistans. Er erklärte, dass die Taliban und al-Qaida eine „sehr falsche Interpretation des Islam“ eingeführt hätten und dass die Taliban, wenn sie nicht die Unterstützung Pakistans hätten, ihre militärischen Kampagnen in dem Zeitraum eines Jahres nicht mehr aufrechterhalten könnten. Auf seinem Besuch in Europa, bei dem ihn die europäische Parlamentspräsidentin Nicole Fontaine den „Pol der Freiheit in Afghanistan“ nannte, warnte Massoud davor, dass sein Geheimdienst Informationen habe, denen zufolge ein großangelegter Anschlag auf amerikanischem Boden unmittelbar bevorstehe.

Am 9. September 2001 ließen zwei arabische Selbstmordattentäter, die sich als Journalisten ausgegeben hatten, während eines Interviews mit Massoud in Takhar, Afghanistan, eine Bombe detonieren, die sie in ihrer Videokamera versteckt hatten. Massoud starb wenig später an seinen Verletzungen. Obwohl die Beerdigung in dem sehr ländlichen Pandschschir-Tal stattfand, nahmen hunderttausende trauernde Afghanen an ihr teil. Viele befürchteten nach der Ermordung Massouds den endgültigen Sieg der Taliban.

Zwei Tage nach der Ermordung Massouds wurden terroristische Anschläge in den USA verübt, die zu dem Tod von mindestens 2993 Menschen führten und als terroristischer Massenmord angesehen werden.

Vier Verkehrsflugzeuge wurden am frühen Morgen des 11. September entführt. Zwei wurden in die Türme des World Trade Centers (WTC) in New York City und eines in das Pentagon in Arlington (Virginia) gelenkt. Das vierte Flugzeug, wahrscheinlich mit einem weiteren Anschlagsziel in Washington D.C., brachten die Entführer gegen die heftigen Widerstand leistenden Passagiere um 10:03 Uhr über dem Ort Shanksville in Pennsylvania zum Absturz. Etwa 15.100 von ungefähr 17.400 Personen konnten rechtzeitig vor dem Kollaps der WTC-Türme evakuiert werden.

Die USA identifizierten Mitglieder der al-Qaida, welche ihre Basis in dem Emirat der Taliban hatte und mit den Taliban verbündet war, als ausführende Täter der Anschläge.

Nach den Anschlägen vom 11. September 2001 bekräftigte der UN-Sicherheitsrat den Vereinigten Staaten in der Resolution 1368 vom 12. September 2001 das Recht zur Selbstverteidigung. Nach Auffassung der USA und anderer Regierungen wurde dadurch ein militärischer Einsatz in Afghanistan völkerrechtlich legitimiert. Noch am 19. September 2001 forderte der UN-Sicherheitsrat die Talibanregierung in Afghanistan dazu auf, Osama bin Laden „sofort und bedingungslos“ auszuliefern und bezog sich dabei auf die UNO-Resolution 1333 vom Dezember 2000. Am 22. September 2001 verweigerten die Taliban in Afghanistan auch weiterhin die Auslieferung bin Ladens und gaben bekannt mit einem „Gegenschlag“ der USA zu rechnen. US-Präsident George W. Bush hatte die Regierung in Afghanistan zuvor im Zuge einer Rede vor dem US-Senat dazu aufgefordert, bin Laden auszuliefern: „Sie werden die Terroristen ausliefern oder ihr Schicksal teilen.“

Ab dem 7. Oktober 2001 intervenierten die Vereinigten Staaten mit der Operation Enduring Freedom militärisch in Afghanistan. Sie unterstützen zunächst mit massiven Luftangriffen Bodentruppen der Vereinten Front (Nordallianz) in einer Großoffensive gegen die Taliban. In den darauffolgenden Monaten wurde das Talibanregime in Afghanistan gestürzt (siehe auch Krieg in Afghanistan). Die Talibanführung um Mullah Omar floh nach Pakistan.

Bei Kämpfen aufgegriffene Taliban-Kämpfer und Personen, die verdächtigt werden, die Taliban zu unterstützen, werden seitdem inhaftiert. Sie werden von den Truppen der NATO überwiegend in Internierungslagern innerhalb Afghanistans festgehalten. Als ungefährlich eingestufte Häftlinge werden wieder freigelassen. Bis Herbst 2004 wurden teilweise auch Häftlinge in die international kritisierten Internierungslager in Guantánamo Bay auf Kuba überstellt.

Unter der Schirmherrschaft der Vereinten Nationen wurde eine Übergangsregierung gebildet, die durch UN-mandatierte ausländische Truppen (ISAF) unterstützt wurde. Im Jahr 2004 wurde in Afghanistan eine demokratische Verfassung verabschiedet, das Land wurde dadurch offiziell eine demokratische Islamische Republik.

In Pakistan formierten sich die Taliban neu. 2003 traten sie erstmals wieder in Erscheinung. Seit Anfang 2006 verüben sie zusammen mit dem Haqqani-Netzwerk und der "Hezb-i Islami" Gulbuddin Hekmatyārs verstärkt Anschläge gegen afghanische Zivilisten oder Soldaten der ISAF. Einige Dörfer und ländliche Gebiete gerieten erneut unter Kontrolle der Taliban.

Pakistan spielt eine zentrale Rolle in Afghanistan. Ein Bericht der London School of Economics aus dem Jahr 2010 sagt aus, dass der pakistanische Geheimdienst ISI eine „offizielle Politik“ der Unterstützung der Taliban betreibt. Der ISI finanziert und bildet die Taliban aus. Dies passiert, obwohl Pakistan sich offiziell als Verbündeter der NATO ausgibt. Der Bericht der London School of Economics kommt zu dem Schluss: 
Amrullah Saleh, der ehemalige Geheimdienstchef Afghanistans, kritisierte: Die Taliban richten sich in Anschlägen gezielt gegen die afghanische Zivilbevölkerung. Im Jahr 2009 waren sie laut Angaben der Vereinten Nationen für über 76 % der Opfer unter afghanischen Zivilisten verantwortlich. Auch im Jahr 2010 waren die Taliban für über 3/4 der zivilen Todesopfer in Afghanistan verantwortlich. Zivilisten sind mehr als doppelt so häufig das Ziel tödlicher Anschläge der Taliban als afghanische Regierungstruppen oder Truppen der ISAF.

Die Unabhängige Afghanische Menschenrechtskommission (AIGRC) nannte 2011 die gezielten Anschläge der Taliban gegen die Zivilbevölkerung ein „Kriegsverbrechen“. Religiöse Führer verurteilten die Anschläge der Taliban als Verstoß gegen die islamische Ethik.

Menschenrechtsgruppen haben 2011 den Internationalen Strafgerichtshof in Den Haag dazu bewogen, eine vorläufige Untersuchung gegen die Taliban wegen Kriegsverbrechen durchzuführen.

2011 nahmen auch kriegsähnliche Gefechte zwischen ISAF-Truppen und ihren Gegnern an Ausmaß und Schärfe zu.

Im Juni 2011 bestätigten die USA überraschend, dass sie mit den Taliban direkt verhandeln. Im Januar 2012 erklärten die Taliban ihre Bereitschaft, ein Büro in Katar einzurichten. Dieses soll für Verhandlungen genutzt werden. Zu dem Zweck reisten Anfang 2012 acht Vertreter der Taliban von Pakistan nach Katar, im Juni 2013 wurde dieses eröffnet. An dem Büro enthüllten sie eine Plakette mit der Aufschrift „Islamisches Emirat Afghanistan“, auf dem Gelände hissten sie die Taliban-Flagge. Die USA kündigten wenige Stunden nach der Eröffnung des Büros an, direkte Friedensgespräche mit den Taliban in Doha aufzunehmen.

Seit 2015 versuchen die Taliban in Afghanistan, Regionen zu erobern. Im Sommer 2016 standen 36 von 400 Regionen oder bis ein Drittel Afghanistans nicht mehr unter Kontrolle der Regierung.

Russland unterstützte seit 2015 Verhandlungen mit den Taliban. Die größte sicherheitspolitische Gefahr für Russland sei der Islamische Staat. Auch eine Unterstützung in Form von Waffenlieferungen kam laut Auskunft eines Experten für Russland in Betracht oder war bis 2017 im Gange. Russland setzt sich zudem mit China und Pakistan dafür ein, dass Taliban-Vertreter von internationalen Sanktionslisten gestrichen werden. Bei einer ersten Gesprächsrunde zu Afghanistan im Jahr 2016 war die afghanische Regierung nicht eingeladen. Auch 2017 ging es bei den Verhandlungen weniger um das Voranbringen eines Friedensprozesses, sondern sehr viel mehr um die Interessen der umliegenden Länder.

Der Obersten Schura der Gründungsmitglieder der Taliban gehörten im Zeitraum 1994 bis 1997 folgende Mitglieder an:

Die Taliban selbst gehören mehr der ideologischen Schule der Deobandis an, einer fundamentalistischen Gruppe mit Hauptsitz in Deoband, Indien. In der Koranschule in Peschawar, dem größten pakistanischen Ableger der Dar-ul-'Ulum-Haqqania-Koranschule, rekrutierten sich viele hochrangige Taliban. Politischer Zweig und Unterstützer der Schulen der Deobandis ist die Partei Jamiat Ulema-e-Islam in Pakistan.
Die USA forderten die pakistanische Regierung auf, diese Religionsschulen (Madrasas) zu schließen. In Pakistan sind diese offiziell jedoch nicht registriert. 2007 schätzte das pakistanische Innenministerium ihre Zahl auf etwa 13.500, andere Schätzungen gehen von 20.000 aus.

Während der Regierungszeit der Taliban im Islamischen Emirat Afghanistan von 1996 bis 2001 wurde das System der Taliban durch die Unterdrückung von Frauen weltweit bekannt. Das erklärte Ziel der Taliban war es, ein „sicheres Umfeld für die Frau zu schaffen, in der ihre Keuschheit und Würde wieder unantastbar ist“. Frauen wurden gezwungen, in der Öffentlichkeit die Burka zu tragen, weil, wie ein Sprecher der Taliban es ausdrückte, „das Gesicht der Frau eine Quelle der Korruption für die mit ihr nicht verwandten Männer ist“. Es wurde Frauen verboten zu arbeiten, und sie durften ab einem Alter von acht Jahren nicht mehr unterrichtet werden.

Die Taliban haben gezielt kulturelle Zeugnisse zerstört, die sie als unislamisch werteten. Dazu gehörten die von der UNESCO als Weltkulturerbe aufgeführten Buddha-Statuen von Bamiyan sowie buddhistische Ausstellungsstücke des Museums in Kabul.

Die Taliban verübten systematische Massaker gegen die Zivilbevölkerung, insbesondere gegen Angehörige der mehrheitlich schiitischen Hazara-Volksgruppe, während sie versuchten, ihre Kontrolle im Westen und Norden Afghanistans zu konsolidieren. Die Vereinten Nationen benannten 15 Massaker in den Jahren 1996 bis 2001. Vertreter der Vereinten Nationen verglichen die Massaker mit den ethnischen Säuberungen, die während des Bosnienkriegs stattgefunden haben. Die Massakerkampagnen der Taliban seien „höchst systematisch gewesen und alle auf das Verteidigungsministerium [der Taliban] oder Mullah Omar persönlich zurückzuführen.“ Die sogenannte 055 Brigade al-Qaidas war ebenfalls an Greueltaten gegen die afghanische Zivilbevölkerung beteiligt. Der Bericht der Vereinten Nationen zitiert Zeugenaussagen, welche beschreiben, dass arabische Milizionäre lange Messer mit sich trugen, mit denen sie Kehlen aufschnitten und Menschen häuteten.

Die Taliban verfolgten zudem eine Politik der Verbrannten Erde. Sie verbrannten ganze Landstriche und rissen ganze Städte nieder. Die Stadt Istalif, welche über 45.000 Einwohner hatte, wurde z. B. gänzlich zerstört und umliegendes Agrarland in Brand gesteckt. Einwohner wurden ermordet oder vertrieben.

Anfang 1998 schnitten die Taliban ganz Zentralafghanistan, das Hauptsiedlungsgebiet der Hazara, systematisch von UN Hilfslieferungen ab. Diese Hungerblockade von etwa einer Million Menschen war das erste Mal in 20 Jahren Krieg, dass eine Partei Nahrungsmittel als Waffe einsetzte.

Taliban- und al-Qaida-Kommandeure unterhielten ein Netzwerk zu Menschenhandel. Sie entführten Frauen und verkauften sie in die Sexsklaverei in Afghanistan und in die Zwangsprostitution in Pakistan.

Das "Time Magazine" schrieb: „Die Taliban haben oft argumentiert, dass ihre brutalen Restriktionen, die sie Frauen auferlegt haben, nur ein Weg seien, das andere Geschlecht zu beschützen. Das Verhalten der Taliban während der sechs Jahre, in denen sie ihre Herrschaft in Afghanistan ausweiteten, machen diese Aussagen zu einer Farce.“

Während einer Offensive in den Schomali-Ebenen im Jahre 1999 ließen die Taliban sowie arabische und pakistanische al-Qaida-Milizionäre allein mehr als 600 Frauen verschwinden. Sie wurden in Busse und Transporter gepfercht und nicht mehr wiedergesehen. Das Time Magazine schrieb: „Die Spur der vermissten Shomali-Frauen führt nach Jalalabad, nicht weit der pakistanischen Grenze. Dort wurden die Frauen nach Zeugenaussagen in dem Lager ‚Sar Schahi‘ in der Wüste eingesperrt… Einige wurden nach Peshawar [Pakistan] weitertransportiert… andere wurden nach Khost in die Trainingslager von bin Laden gebracht.“ Hilfsorganisationen gehen davon aus, dass viele Frauen nach Pakistan gebracht wurden, wo sie an Bordelle verkauft oder als Sklavinnen in privaten Haushalten eingesetzt wurden.

Einige Talibankämpfer weigerten sich, an dem Menschenhandel teilzunehmen. Ein Talibankommandeur mit dem Namen Nuruludah erklärte z. B., dass er sah, wie pakistanische al-Qaida-Kämpfer Frauen in einen Transporter zwangen. Nuruludah und seine Kämpfer befreiten die Frauen daraufhin aus dem Transporter. In einem weiteren Vorfall befreiten Talibankämpfer Frauen aus einem al-Qaida-Lager in Jalalabad.

Nachdem sie die politische Herrschaft über Afghanistan erkämpft hatten, erließen die Taliban zudem Edikte, die die Rechte der Frauen stark einschränkten. Sie betrafen die Bereiche Bildung, medizinische Versorgung, Kleidung und Verhalten in der Öffentlichkeit. Mädchen war es verboten, zur Schule zu gehen. Viele Schulen wurden geschlossen, worauf die Mädchen, wenn überhaupt, nur noch privat unterrichtet wurden. Frauen in Kabul durften nicht mehr ihre Berufe ausüben und saßen immer häufiger als Bettlerinnen in Burkas auf der Straße. Da durch die Wirren des Krieges allein in Kabul ca. 30.000 Frauen als Witwen ohne jegliche männliche Verwandtschaft lebten, hatten diese Frauen meist keine andere Chance als zu betteln, um ein wenig Geld zum Überleben aufzutreiben. Dass die Restriktionen lebensbedrohend waren, verdeutlicht Folgendes:

Laut den „Physicians for Human Rights“ bekamen 53 Prozent der ernsthaft Kranken keine Behandlung. Zugang zu medizinischer Versorgung war vor allem den Frauen fast unmöglich. Es gab zur Zeit der Talibanherrschaft in Kabul ein einziges Krankenhaus, in dem Frauen behandelt werden durften. Dort allerdings war die Grundausstattung mangelhaft, Röntgen- oder Sauerstoffgeräte und Medikamente fehlten, fließendes Wasser war nicht vorhanden. Um überhaupt behandelt werden zu können, mussten die Frauen mehrere Hürden überwinden: Ohne männlichen Begleiter durfte eine Frau nicht behandelt werden. Da es männlichen Ärzten generell verboten war, Frauen anzuschauen oder zu berühren, konnten Frauen nur noch sehr eingeschränkt untersucht werden. Das Tragen der Burka war auch während der Behandlung Pflicht. Eine einfache Untersuchung oder ein Zahnarztbesuch war fast unmöglich, da der Schleier nicht hochgehoben werden durfte. Um die Einhaltung der Gesetze zu wahren, waren regelmäßig Taliban-Mitglieder in den Krankenhäusern anwesend. Falls sich Afghanen den Taliban-Gesetzen dennoch widersetzten, wurden schwere Strafen verhängt. Ärzten drohten Schläge, Berufsverbot und Gefängnisstrafen.

Sowohl in den Städten als auch auf dem Lande waren (und sind teilweise heute noch) die hygienischen Verhältnisse auf niedrigstem Niveau. Öffentliche Bäder waren, soweit noch vorhanden, Frauen generell nicht mehr zugänglich.

In den Städten trafen die Gesetze die Frauen besonders hart, da dort die westliche Orientierung vor der Taliban-Gewaltherrschaft am stärksten ausgeprägt gewesen war, Frauen in vielen Fällen einer regelmäßigen Erwerbstätigkeit nachgingen und westliche Kleidung getragen hatten.

Die Taliban richten sich bei Anschlägen gezielt gegen die afghanische Zivilbevölkerung. Im Jahr 2009 waren sie laut Angaben der Vereinten Nationen für über 76 % der Opfer unter afghanischen Zivilisten verantwortlich. Auch im Jahr 2010 waren die Taliban für über 3/4 der zivilen Todesopfer in Afghanistan verantwortlich. Zivilisten sind mehr als doppelt so häufig das Ziel tödlicher Anschläge der Taliban als afghanische Regierungstruppen oder Truppen der ISAF.

Die Unabhängige Afghanische Menschenrechtskommission (AIGRC) nannte die gezielten Anschläge der Taliban gegen die Zivilbevölkerung ein „Kriegsverbrechen“. Religiöse Führer verurteilten die Anschläge der Taliban als Verstoß gegen die islamische Ethik.

Menschenrechtsgruppen haben den Internationalen Gerichtshof in Den Haag dazu veranlasst, eine vorläufige Untersuchung gegen die Taliban wegen Kriegsverbrechen durchzuführen.

Neben dem Drogenhandel finanzieren sich die Taliban über Spenden aus dem Ausland, dem Abzweigen internationaler Hilfsgelder, Schutzgelderpressung und der Erhebung von Steuern in den von ihnen kontrollierten Gebieten. 2012 nahmen die Taliban etwa 400 Millionen Dollar ein, darunter über hundert Millionen Dollar aus abgezweigten Hilfsgeldern. Im Jahr 2017 behauptete der katarische Nachrichtensender Al Jazeera, dass Russland die Taliban mit Waffenlieferungen unterstützt.

Im von den Taliban regierten Afghanistan in den späten 1990er Jahren verdienten die Taliban am Anbau von Drogen und am Schmuggel mit Opium, Heroin, Haschisch und anderen Rauschgiftmitteln. Dabei ließen die Taliban den Bauern als Produzenten des Rohopiums und dem "informellen Sektor für Weiterverarbeitung" desselben zu Heroin freie Hand und erhoben auf Anbau sowie Handel Steuern.

Für das Jahr 1999 wurden die Einnahmen der Taliban aus dem Drogenhandel auf 40 Millionen Dollar geschätzt. Für den Transport wurden Flugzeuge der Ariana Afghan Airlines benutzt. Mit der Resolution 1267 des UN-Sicherheitsrats wurden internationale Flüge von Ariana Air verboten, der Drogenschmuggel lief von nun über Land.

Im Jahr 2001, vor den Terroranschlägen am 11. September, setzten die Taliban ein rigoroses Anbauverbot für Schlafmohn in Afghanistan durch, welches weltweit den bis dato größten Rückgang an Drogenproduktion innerhalb eines Jahres in einem Land zur Folge hatte.

Daraufhin wurde nur noch im nicht von den Taliban kontrollierten Norden Afghanistans Schlafmohn angebaut. Jedoch handelten die Taliban weiterhin mit Opium und Heroin aus Lagerbeständen.
Der Anbaustop führte zu einer „humanitären Krise“, da sich Tausende Kleinbauern ohne Einkommen wiederfanden. Mit dem Anbaustopp wollten die Taliban zum einen eine Lockerung der Sanktionen der Resolution 1267 des UN-Sicherheitsrats erreichen. Einem Bericht der CRS nach vermuteten einige Mitglieder der U.S.-amerikanischen Drogenbekämpfung dahinter lediglich eine Strategie, um die Preise nach oben zu treiben. In der Tat stieg der Rohopium-Preis von einem Allzeittief von 28 $/kg auf ein Allzeithoch von 746 $/kg am 11. September 2001. In den Wochen nach den Terroranschlägen fiel er wieder auf 95 $/kg, wahrscheinlich weil Lagerbestände in großem Stil verkauft wurden angesichts einer drohenden Invasion.

Im Jahr 2002 stieg die Anbaufläche für Schlafmohn von 8000 auf 74.000 Hektar.
Die Taliban befanden sich nach dem Krieg in einer Phase der Reorganisation. Einzelne Talibanführer verkauften ihre Lagerbestände an Opium. Manche Drogenschmuggler „investierten“ in die Taliban.

In den von Taliban kontrollierten Gebieten erheben lokale Taliban-Kommandeure oft eine zehnprozentige Steuer (uschr) nicht nur auf den Verkauf von Rohopium, sondern auch auf diverse andere Geschäfte, z. B. die von kleinen Läden und Kleinbetrieben. Zahlungsmittel können dabei Rohopium oder sonstige Naturalien sein.
Bei Nichtzahlung der Steuer wurde über Gewalt berichtet und ähnlich den Strukturen in einer Mafia finanzieren sich Taliban-Kommandeure auf Dorf-Ebene aus weiteren mafiösen Geschäften, z. B. Wegzöllen, müssen aber einen Teil davon an die ranghöheren Kommandeure abgeben.

Taliban-Kommandeure schützen Produktion und Schmuggel von Opium militärisch und verlangen dafür bis zu 20 % der Einnahmen. Dabei schrecken sie nicht vor Waffengewalt gegenüber staatlicher Polizei zurück und überfallen mitunter Kontrollpunkte, um Drogenkonvois freie Fahrt zu garantieren. Daneben sind Taliban-Kommandeure an der Besteuerung oder dem Betrieb von bis zu 60 Heroin-Laboren beteiligt.

Für das Jahr 2009 schätzte das Büro der Vereinten Nationen für Drogen- und Verbrechensbekämpfung die Gewinne der Taliban aus dem Opiumhandel auf 150 Millionen Dollar, den der afghanischen Drogenhändler auf 2,2 Milliarden Dollar und jenen der afghanischer Bauern auf 440 Millionen Dollar.

2012 betrug die Anbaufläche für Schlafmohn in Afghanistan 154.000 Hektar und die Taliban finanzierten sich weiter durch Drogengelder.

Spendengelder erhalten die Taliban aus allen Teilen der Welt, vor allem aber aus der Golfregion. Genaue Zahlen zu den Spendensummen seien nach Einschätzung des US-Gesandten für Afghanistan und Pakistan Richard Holbrooke aus dem Jahr 2009 zwar schwierig zu ermitteln, jedoch seien Spendengelder „wichtiger“ als der Drogenhandel.






</doc>
<doc id="5071" url="https://de.wikipedia.org/wiki?curid=5071" title="Terroranschläge am 11. September 2001">
Terroranschläge am 11. September 2001

Die Terroranschläge am 11. September 2001 waren vier koordinierte Flugzeugentführungen mit anschließenden Selbstmordattentaten auf wichtige zivile und militärische Gebäude in den Vereinigten Staaten von Amerika. Die Ereignisse dieses Tages werden auch kurz als "11. September", "Nine-Eleven" oder "9/11" bezeichnet.

Drei Verkehrsflugzeuge wurden auf Inlandsflügen von jeweils fünf, eines von vier Tätern zwischen 8:13 Uhr und etwa 9:30 Uhr Ortszeit entführt. Die Täter lenkten zwei davon in die Türme des World Trade Centers (WTC) in New York City und eines in das Pentagon in Arlington (Virginia). Das vierte Flugzeug, das wahrscheinlich ein Regierungsgebäude in Washington, D.C. treffen sollte, wurde nach Kämpfen mit Passagieren vom Piloten der Entführer bei Shanksville (Pennsylvania) zum Absturz gebracht.

Die Anschläge verursachten den Tod von etwa 3.000 Menschen und gelten als terroristischer Massenmord. Etwa 15.100 von 17.400 Personen konnten sich aus den WTC-Gebäuden retten.

Die 19 Flugzeugentführer gehörten zur islamistischen Terrororganisation al-Qaida. Die USA reagierten unter anderem mit dem Krieg in Afghanistan seit 2001, um dort al-Qaida zu zerschlagen, deren Anführer Osama bin Laden zu fassen oder zu töten und das mit ihm verbündete Regime der Taliban zu entmachten. Sie begründeten auch den Irakkrieg 2003 unter anderem mit den Anschlägen. Bin Laden bekannte sich 2004 erstmals als deren Initiator. Er wurde am 2. Mai 2011 von US-Soldaten bei der Operation Neptune’s Spear getötet.

Einige Historiker beurteilen den 11. September 2001 als historische Zäsur, andere widersprechen dieser These. Der am 14. September 2001 in den USA ausgerufene Ausnahmezustand ist nach wie vor in Kraft.

Um 8:14 Ortszeit, so wurde später ermittelt, entführten die Täter das in Boston gestartete Flugzeug von American-Airlines-Flug 11. Um 8:19 Uhr stellten sie dessen Transponder ab, sodass es nur noch vom Primärradar erfasst und seine Flughöhe, Geschwindigkeit und Kennung nicht mehr zugeordnet werden konnten. Zwei Flugbegleiterinnen informierten die Federal Aviation Administration (FAA) und ihr Luftfahrtunternehmen ab 8:19 über die Entführung. Um 8:37 Uhr bat die FAA das North American Aerospace Defense Command (NORAD) darum, Kampfjets zur Kontrolle des Flugkurses aufsteigen zu lassen. Um 8:45 Uhr starteten zwei F-15 dazu, erhielten jedoch keine Zielangaben. Sie flogen zunächst über das offene Meer.

Um 8:46 Uhr flog AA-11 in den Nordturm des WTC. Darüber berichteten ab 8:48 immer mehr Fernsehsender. Man glaubte zunächst an einen Unfall und forderte die Menschen im Südturm des WTC auf, Ruhe zu bewahren und am Arbeitsplatz zu bleiben.

Zwischen 8:42 und 8:46 wurde der ebenfalls in Boston gestartete United-Airlines-Flug 175 entführt. Um 9:03 Uhr flog diese Boeing 767 von Süden her in den Südturm des WTC. Damit erkannten die US-Behörden, dass hier gezielte Angriffe geschahen, und leiteten eine Evakuierung des gesamten WTC ein.

American-Airlines-Flug 77 wurde zwischen 8:51 und 8:54 entführt. Das Flugzeug traf das Pentagon bei Washington, D.C. um 9:37 Uhr und schlug eine Bresche durch drei Gebäudeteile der Westseite. Das explodierte Flugbenzin löste einen Großbrand aus. Dadurch stürzte die betroffene Fassade gegen 10:10 Uhr ein. Um 9:42 befahl das FAA-Hauptquartier allen Passagierflugzeugen im Luftraum der USA, beim nächstgelegenen Flughafen zu landen.

United-Airlines-Flug 93 wurde um 9:28 entführt und änderte seinen Kurs um 9:32 Uhr nach Osten. Um 9:55 Uhr wählte sich einer der Entführer als Pilot in die Anflughilfe des Ronald-Reagan-Flughafens ein und ließ so den Flug nach Washington, D.C. dirigieren. Die Flugüberwachung bestätigte den Kurswechsel. Als Anschlagsziel wurden später das Weiße Haus, das Kapitol oder der Landsitz des US-Präsidenten in Camp David vermutet. In einem Interview mit dem Al-Jazeera-Redakteur Yosri Fouda vom Juni 2002 sagte das al-Qaida-Mitglied Ramzi Binalshib, das vierte Flugzeug habe das Kapitol treffen sollen.

Einige Passagiere dieses Fluges erfuhren bei Bordanrufen von den Anschlägen auf das WTC und versuchten ab 9:57, in das Cockpit vorzudringen und die Entführer zu überwältigen. Daraufhin lenkte deren Pilot das Flugzeug um 10:03 Uhr zu Boden. Es zerschellte bei Shanksville, rund 100 Kilometer östlich von Pittsburgh. Erst um 10:15 erfuhr NORAD von der Entführung dieses Fluges. Der "Northeast Air Defense Sector" (NEADS) in Rome (New York) erhielt erst gegen 10:30 den Befehl, entführte Flugzeuge abzufangen und eventuell abzuschießen.

Beim Aufprall der ersten beiden Flugzeuge gelangten rund 58,1 Tonnen Flugbenzin (Kerosin) in die WTC-Gebäude, verteilten sich über die Fahrstuhlschächte in vielen Stockwerken und verursachten, genährt durch brennbare Materialien, anhaltende Brände. Der Südturm stürzte um 9:59 Uhr, der Nordturm um 10:28 Uhr (56 bzw. 102 Minuten nach den Einschlägen) ein. Trümmer des einstürzenden Nordturms beschädigten das WTC 7 schwer und lösten anhaltende Innenbrände aus. Das Gebäude wurde wegen Einsturzgefahr evakuiert und kollabierte um 17:20 Uhr.

Rettungseinsätze oder -versuche begannen spätestens nach dem zweiten Einschlag in das WTC. Die New Yorker Feuerwehr (FDNY) wollte die im Nordturm tätigen Angestellten nach dem ersten Einschlag evakuieren und eventuell Brände löschen. Dieses Ziel gab sie jedoch bald nach dem zweiten Einschlag auf, da man nun mit Teileinstürzen der Gebäude rechnete. Die Hafenbehörde von New York unterstützte die städtische Feuerwehr und Polizei bei Evakuierungs- und Löschversuchen im WTC mit eigenen Polizei- und Rettungseinheiten. Deren Arbeit wurde erschwert, weil die Flugzeugeinschläge einige ihrer Leitstellen in den WTC-Türmen zerstört hatten. Trotz eines Räumungsbefehls setzten einige Feuerwehreinheiten im Nordturm ihre Evakuierungen fort; viele davon wurden beim Einsturz des Südturms verschüttet. Begonnene Bergungsversuche mussten nach dem Einsturz des Nordturms erweitert werden. Zudem waren nun weitere Gebäude im Umkreis von 500 Metern durch Trümmerschäden einsturzgefährdet. Die Befehlsinfrastruktur des FDNY war großenteils zerstört und musste neu aufgebaut werden.

Die New Yorker Polizei sperrte zunächst die nähere, dann auch die weitere Umgebung des WTC ab, unterstützte die Evakuierung der Türme und begann, den Ablauf der Angriffe zu ermitteln. Mit Helikopterflügen erhielt die Polizeiführung Informationen über die Lage in den Türmen, die die Einsatzleitung der Feuerwehr jedoch kaum erreichten.
Trotzdem konnten sich rund 87 Prozent der ungefähr 17.400 Menschen, die sich zum Zeitpunkt des ersten Einschlags in den WTC-Gebäuden fanden, selbst retten oder wurden von Feuerwehr, Hafenbehörde und Polizei gerettet. Ab dem 12. September retteten sie nur noch wenige Überlebende in der direkten Nachbarschaft.

Beteiligt waren ferner die Stadtverwaltung, New Yorks Bürgermeister Rudy Giuliani mit seinem Stab, der Staat New York, die Bundesregierung, das FBI, die FEMA, das National Military Command Center (NMCC) und weitere staatliche Behörden.

Bis Mai 2002 waren etwa 40.000 Personen an Rettungs- und Aufräumarbeiten an Ground Zero beteiligt. Sie und andere wurden dabei in unterschiedlichem Maß mit Schadstoffen vom WTC in der Atemluft belastet. Ausmaß und Bewältigung der gesundheitlichen Spätfolgen werden in den USA seit etwa 2005 verstärkt diskutiert. Die Stadt New York bewilligte im November 2010 ein Hilfspaket von 625 Millionen US-Dollar für zehntausend betroffene Helfer. Zudem unterschrieb US-Präsident Barack Obama am 2. Januar 2011 ein Gesetz, wonach Polizisten, Feuerwehrleute und andere Helfer insgesamt 4,2 Milliarden US-Dollar Entschädigungszahlungen für gesundheitliche Spätfolgen erhalten sollen.

Die Anschläge töteten mindestens 2.989, nach anderen Angaben 2.992 Menschen. Darunter sind 2.759 Getötete in New York, darunter 127 Passagiere, 18 Besatzungsmitglieder und zehn Entführer der beiden Flugzeuge, etwa 200 Personen, die bewusstlos oder absichtlich aus den Türmen in den Tod stürzten, um einer Verbrennung zu entgehen, sowie 411 Helfer (343 Feuerwehrleute, 60 Polizisten und acht Sanitäter). 189 Menschen starben beim Pentagon, darunter 125 Behördenmitarbeiter, 53 Flugzeugpassagiere, sechs Besatzungsmitglieder und fünf Entführer. 44 Personen, davon 33 Passagiere, sieben Besatzungsmitglieder und vier Entführer, starben bei Shanksville.

372 Todesopfer waren Ausländer, die meisten darunter aus dem Vereinigten Königreich, der Dominikanischen Republik sowie aus Indien. Elf Opfer waren Deutsche, zwei Schweizer.

Da nicht alle Opferfamilien vermisste Angehörige meldeten oder Todesbescheinigungen beantragten und nicht alle Verfahren dazu abgeschlossen waren, weichen die Zahlen verschiedener privater oder behördlicher Opferlisten voneinander ab. Bei den Aufräumarbeiten erfolgte Sterbefälle blieben unberücksichtigt. Weitere Todesfälle gab es später bei den Helfern der Aufräumarbeiten. Ob diese an deren Spätfolgen starben, ist zum Teil umstritten.

Die Zahl der am 11. September akut Verletzten wird auf über 6.000 geschätzt. Über 3.200 Kinder verloren durch die Anschläge Eltern. Viele davon erlitten traumatische Trennungsängste. Für die Schäden und Opferangehörigen legte die US-Bundesregierung ein Acht-Milliarden-US-Dollar-Programm auf, die sogenannten Liberty Bonds.

Bis zum 23. Februar 2005 arbeitete das gerichtsmedizinische Institut von New York an der gentechnischen Identifizierung von Körperbestandteilen der Opfer. 1.600 Opfer konnten auf diese Weise identifiziert werden. Etwas über 10.000 Fragmente blieben bislang unidentifizierbar. Von 1.100 in New York getöteten Personen fehlen jegliche Körperbestandteile, so dass sie nicht identifiziert werden konnten. Am 2. April 2009 konnte das 1624. Opfer beim WTC identifiziert werden.

Beim Einsturz der Türme wurden viele Karzinogene im Bauschutt freigesetzt. Die Befürchtung, diese würden viele Krebserkrankungen auslösen, bestätigte sich bis 2008 nicht: Unter den vor Ort arbeitenden Rettungskräften und Helfern, die den Karzinogenen ausgesetzt waren, zeigten sich gleichbleibende Inzidenzraten.

Aus Angst veränderten viele Amerikaner ihr Reiseverhalten und nutzten den PKW anstatt von Flugzeugen. Der Flugverkehr brach dadurch um bis zu 20 % ein, der Straßenverkehr stieg um bis zu 5,2 % an. Dadurch kam es in den ersten 12 Monaten nach den Anschlägen zu 1.500 mehr tödlichen Unfällen mit 1.600 mehr Verkehrstoten, als statistisch zu erwarten waren. Nach einem Jahr hatten sich diese Zahlen wieder normalisiert.

Das FBI gab die aus Passagierlisten und mit Klarnamen gebuchten Sitzplatznummern ermittelten Namen aller 19 Flugzeugentführer am 13. September 2001 bekannt:

Am 27. September 2001 veröffentlichte das FBI Fotos und persönliche Daten der 19 Entführer, darunter alternative Namensschreibweisen, da einige Namen mit denen lebender Personen verwechselt worden waren. Am 28. September veröffentlichte das FBI einen vierseitigen handschriftlichen Brief, dessen Kopien man an drei Stellen gefunden hatte, und ordnete ihn den Piloten von drei der vier entführten Flüge zu. Attas Exemplar wurde in einer zu spät aufgegebenen Reisetasche am Flughafen Boston gefunden. In diesem mit einer „Fibel für Selbstmordattentäter“ kombinierten Testament stand etwa: Abdelghani Mzoudi bestätigte die Echtheit des Dokuments im Oktober 2001.

Die Identität von drei der 19 Attentäter wurde durch DNA-Spuren bestätigt. DNA-Spuren von 9 weiteren Entführern wurden durch ein Ausschlussverfahren im Abgleich mit eingesandten DNA-Spuren aller an Bord der entführten Maschinen befindlichen Personen festgestellt. 15 der 19 Entführer waren Staatsbürger Saudi-Arabiens.

2002 veröffentlichte das FBI einen Zeitablauf zum Werdegang der Entführer. Sie stammten alle aus wohlhabenden, angesehenen, eher säkular eingestellten Familien und genossen eine Ausbildung, die sie zu Auslandsstudien qualifizierte. Erst dort suchten und fanden sie Kontakte zu radikal-islamischen Predigern, die den Dschihad gegen den Westen propagierten. Zu ihrer Ideologie gehörten der Glaube an eine jüdische Weltverschwörung, das Bild eines imperialistischen Westens, der die islamische Welt kolonisiere und fortgesetzt demütige, und ein Hass auf die von der Globalisierung erzeugte weltweite soziale Ungerechtigkeit. Seit 1996 wollte Atta einen Märtyrertod sterben, seit 1999 auch seine Freunde. Dabei planten sie zunächst keinen Selbstmordanschlag im Westen. Die Entscheidung dazu fiel eventuell nach dem ersten Kontakt mit einem al-Qaida-Mitglied im Herbst 1998.

Atta, Jarrah, Al-Shehhi und Ramzi Binalshibh lebten seit 1998 in Hamburg und gehörten dort zu einer Gruppe islamistischer Studenten an der Technischen Universität Hamburg-Harburg. Sie sollen nach Zeugenaussagen dort als „Hamburger Terrorzelle“ seit Frühjahr 1999 die Anschläge auf das WTC und das Pentagon zu planen begonnen haben. Im November 1999 reisten sie nach Afghanistan und trafen im Dezember Bin Laden in Kandahar, der sie und andere wegen technischer und sprachlicher Fähigkeiten für die Anschläge auswählte und in seinen Trainingslagern ideologisch und technisch darauf vorbereitete. Dort verkündeten sie am 18. Januar 2000 auch ihren letzten Willen, kurz bevor sie zurück nach Hamburg flogen.

Im Mai 2000 erhielten Atta, Al-Shehhi und Jarrah Einreisevisa für die USA, nicht aber Binalshibh, worauf Bin Laden als Ersatz Hani Hanjour, der in den USA studierte, bestimmte. In Florida und Arizona absolvierten diese vier bis Dezember 2000 eine verkürzte Pilotenausbildung für Passagierlinienflugzeuge und erwarben eine Lizenz zum Steuern von Düsenjets. Jarrah und Hanjour buchten Übungsflüge mit Kleinflugzeugen im Raum New York und Washington, D.C., um Flugrouten, Luftverkehr und Topografie kennenzulernen. Atta erhielt beim Treffen mit Binalshibh im Frühjahr 2001 in Europa nähere Instruktionen von Bin Laden und erfuhr als einziger auch die Anschlagsziele. Er koordinierte alle beteiligten Attentäter, die Bin Laden ausgesucht hatte und die im April 2001 in die USA eingereist waren. Er soll auch den 11. September als Anschlagstermin und das Kapitol anstelle des schwieriger erreichbaren Weißen Hauses als Anschlagsziel festgelegt haben.

Der FBI-Antiterrorexperte Dale Watson bezeugte 2002 die Verbindungen der 19 Attentäter zu al-Qaida und zu Bin Laden. Das FBI setzte seine Ermittlungen mit etwa 7.000 von 11.000 Angestellten unter der Bezeichnung PENTTBOM jahrelang fort.

Die US-Regierung beschuldigte Osama bin Laden (1957–2011) wegen der von ihren Geheimdiensten gesammelten Indizien, die Anschläge initiiert, in Auftrag gegeben und mitfinanziert zu haben. Dieser begrüßte die Anschläge als Willen Allahs, bestritt aber anfangs jede Beteiligung daran. Im November 2001 fand die US-Armee in Dschalalabad ein Videoband, in dem Bin Laden mit Mitgliedern seiner Gruppe über die Anschlagsplanung sprach, einige Entführer namentlich nannte, sie lobte und erklärte, er habe ihnen die Anschlagsziele erst in den USA genannt und nicht mit dem vollständigen Einsturz der WTC-Gebäude gerechnet. Mögliche Übersetzungsfehler wurden von US-Medien überprüft: Sie fanden neun Namen beteiligter Entführer und weitere Hinweise auf Vorkenntnisse von den Anschlägen in Bin Ladens Aussagen.

Im März 2002 schilderten Ramzi bin asch-Schaiba und Khalid Scheich Mohammed dem Al-Jazeera-Redakteur Yosri Fouda in Karatschi detailliert die etwa zehnjährige Vorbereitung der Anschläge im Auftrag Bin Ladens. Anhand abgehörter Telefongespräche, Geldüberweisungen und Zeugenaussagen sehen die USA Khalid und Mohammed Atef als Hauptplaner der Anschläge an. Muhammad Haidar Zammar gilt als Rekrutierer der Attentäter. Bin Laden wählte 1999 die späteren Attentäter aus, finanzierte den Anschlagsplan mit und befahl den späteren Flugzeugentführern im November 1999, in die USA zu fliegen.

Am 1. November 2004, drei Tage vor der Wiederwahl von George W. Bush, wandte sich Bin Laden an die US-Bevölkerung und erklärte, wann und warum er auf die Idee der Anschläge gekommen sei und dass weitere dieser Art folgen würden, falls die USA ihre Politik nicht änderten. In weiteren Video- und Tonband-Botschaften machte er seine Planung der Anschläge deutlich. Als Hauptmotiv dafür nannten er und seine wichtigsten Mitplaner stets die Unterstützung der USA für Israel und dessen Politik gegenüber den Palästinensern.

Am 2. Mai 2011 töteten US-Soldaten Bin Laden bei der Operation Neptune’s Spear in Pakistan.

Die Terrorgruppe al-Qaida orientiert sich seit dem Zweiten Golfkrieg der USA gegen den Irak 1991 und der anschließenden Stationierung von US-Militär in Saudi-Arabien auf den Kampf gegen „den Westen“ und seine Werte. Ihre Mitglieder sehen die USA als den „großen Satan“, der den „kleinen Satan“ (den Staat Israel) decke, um die islamische Nation zu unterdrücken, zu spalten, ihre Reichtümer auszubeuten und sie an ihrer Einigung und an der Ausbreitung des Islam zu hindern. Sie behaupten, der Westen sei von „Ungläubigen“ und „Kreuzzüglern“ (Juden und Christen) beherrscht. Daraus leiten sie das Recht zum wahllosen Töten von Zivilisten und Bürgern verschiedenster Nationen ab, darunter auch Muslimen in den USA.

Die von der al-Qaida geplante und gescheiterte Operation Bojinka war 1995 ein erster Versuch, Flugzeuge als Bomben zu benutzen, indem sie in wichtige Gebäude gelenkt werden. Al-Qaida-Mitglieder verübten Anschläge gegen US-amerikanische Ziele, darunter den Sprengstoffanschlag auf das WTC (1993), Bombenattentate auf die US-Botschaften in Kenia und Tansania (1998) und einen Selbstmordanschlag auf das Kriegsschiff "USS Cole (DDG-67)" im Jemen (2000). Die USA antworteten unter Präsident Bill Clinton 1998 mit Raketenangriffen auf vermutete afghanische Ausbildungslager der al-Qaida und bombardierten die von der CIA als Chemiewaffenfabrik eingestufte Asch-Schifa-Arzneimittelfabrik im Sudan.

Am 9. September 2001 verübten Selbstmordattentäter der al-Qaida einen Anschlag auf Ahmad Schah Massoud und die Taliban begannen eine Offensive gegen dessen Truppen im afghanischen Pandschschirtal.

Andrew Card, der damalige Stabschef des Weißen Hauses, informierte US-Präsident George W. Bush bei einer Schülervorlesung in Sarasota (Florida) gegen 9:00 Uhr Ortszeit vom ersten, kurz darauf vom zweiten Anschlag auf das WTC: Bush setzte die Schulveranstaltung vor laufender Kamera noch sieben Minuten lang fort. Er gab nach kurzer Besprechung mit seinem Stab eine erste Stellungnahme ab und flog dann mit dem Präsidentenflugzeug "Air Force One" zu verschiedenen US-Air-Force-Stützpunkten. Gegen 19:00 Uhr erreichte er nach einem Zwischenstopp Washington, D.C. und das Weiße Haus.

Verzweifelte Angehörige brachten in den ersten Tagen an Absperrzäunen und Wandflächen Vermisstenanzeigen an. Sehr schnell entwickelten sich diese Orte zu spontanen Gedenkstätten, nachdem weitere Menschen mittels Fotos, Kerzen, Briefen und Gegenständen (z. B. Spielzeug von vermissten Kindern) Anteil nahmen.

In einer großen, landesweit im Fernsehen übertragenen Trauerfeier im Footballstadion von New York gedachten Vertreter aller in New York beheimateten Gruppen und Religionen gemeinsam der Toten und bekräftigten gegenseitig ihre multikulturelle Toleranz als wesentliches Merkmal der Weltmetropole New York.

Bereits an den ersten Tagen nach den Anschlägen gab es Angebote den Opfern zu helfen: Blutspenden, kostenfreie Hotelbenutzung, medizinische Versorgung und Medikamente für Menschen ohne Aufenthaltsnachweis oder mietfreien Büroraum für Gruppenzusammenkünfte und so weiter. Später gab es eine Vielzahl von Konzerten oder CDs, deren Einnahmen zum großen Teil an die Angebote ging. Zum Teil entstanden neue Hilfsfonds oder es wurde innerhalb bestehender Hilfsfonds ein neuer Schwerpunkt für betroffene Familien und Kinder gegründet. Bekannt wurden z. B. die "Coalition of 9/11 Families, Children of September 11th, der New York Police and Fire Widows’ and Children’s Benefit Fund "oder der" New York Times 9/11 Neediest Cases Fund." 2001 wurden viele Selbsthilfegruppen gegründet, deren spezielle Schwerpunkte sich aus der Gruppenzusammensetzung der Opfer und der Situation der Angehörigen ergaben.

In den ersten Tagen nach den Anschlägen wurden hunderte Muslime, Araber oder arabisch aussehende und Turban tragende Menschen, oft Sikhs, in den USA beleidigt, angegriffen, bedroht und einige ermordet. Auch wurden Brandanschläge auf islamische Einrichtungen verübt. US-Präsident Bush besuchte daraufhin am 17. September 2001 eine Moschee, verurteilte die Angriffe, unterschied den Islam vom Terror und rief zu Toleranz gegenüber muslimischen US-Bürgern auf.

Mit einer Schweigeminute und Trauerfeiern gedachten viele Menschen weltweit in den Folgetagen der Opfer der Anschläge. Führende Politiker vieler Staaten verurteilten diese und sandten Beileidsschreiben an die USA.

Der deutsche Bundespräsident Johannes Rau erklärte am Abend des 11. Septembers 2001: Am 14. September 2001 bei einer von rund 200.000 Personen besuchten Solidaritätsdemonstration in Berlin sagte Rau: Dies wurde als Kontrast zu der von Bundeskanzler Gerhard Schröder zuvor erklärten „uneingeschränkten Solidarität“ und Absage an einen Krieg aufgefasst.

In der St. Paul’s Cathedral in London fand ein Trauergottesdienst statt. Die Guards vor dem Buckingham Palace spielten die Nationalhymne der USA.

Am 12. September 2001 verurteilte der UN-Sicherheitsrat mit Resolution 1368 die Anschläge einstimmig und erlaubte den USA militärische Selbstverteidigung. Die NATO rief erstmals seit ihrem Bestehen den „Bündnisfall“ aus: Ein kriegerischer Angriff auf das Staatsgebiet eines NATO-Mitgliedsstaates sei geschehen, der nach Artikel 5 des NATO-Vertrages als Angriff auf alle Vertragspartner zu werten sei und deren militärischen Beistand erfordere.

Am 20. September 2001 erklärte US-Präsident Bush in einer außerordentlichen Regierungserklärung vor dem US-Kongress zunächst den Dank der USA für die internationale Solidarität und hob den „treuen Freund“ Großbritannien besonders hervor. Dann benannte er das internationale Terrornetzwerk al-Qaida unter Osama bin Laden als für die Anschläge verantwortliche Organisation, auf die alle Beweise hindeuteten, und verlangte Bin Ladens sofortige Auslieferung durch das Regime der Taliban in Afghanistan. Andernfalls kündigte er einen „Krieg gegen den Terror“ an. Dabei betonte er den Unterschied zwischen dem afghanischen Volk und seiner Regierung, deren Menschenrechtsverletzungen er kritisierte. Ferner forderte er alle Nationen ultimativ auf, sich für die Unterstützung der USA zu entscheiden: „Entweder seid ihr auf unserer Seite oder auf der der Terroristen.“ Dann differenzierte er den Islam vom Terror im Namen Allahs: Er respektiere den Glauben der Muslime; al-Qaida befinde sich in einem gotteslästerlichen Gegensatz dazu. Er nannte Anschläge auf Muslime in den USA „unamerikanisch.“ Die Rede wurde parteiübergreifend begrüßt; die Zustimmungsraten für Bush stiegen in den USA zeitweise auf über 90 Prozent.

Während Verteidigungsminister Donald Rumsfeld Afghanistan baldmöglichst angreifen wollte, erreichte Außenminister Colin Powell, dass den Taliban zuvor ein Ultimatum zur Auslieferung Bin Ladens gestellt wurde. Deren Angebot, ihn nach islamischem Gastrecht an ein befreundetes islamisches Land auszuliefern, wurde abgelehnt. Am 7. Oktober 2001 begann die US-Armee mit Bombenangriffen auf Taliban-Stellungen und Infrastruktur in Afghanistan. Eigene Bodentruppen schlossen die USA zunächst aus. Am 13. November nahm die mit ihnen verbündete Nordallianz Kabul kampflos ein; Kunduz wurde am 25. November, Kandahar am 7. Dezember besetzt. Bis zum Jahresende wurde das Regime unter Mullah Omar gestürzt. Bin Laden konnte bei der Schlacht um Tora Bora im Dezember entkommen. Annahmen, er sei im Grenzgebiet zu Pakistan untergetaucht, stellten sich 2011 als falsch heraus.

Ab Dezember 2001 unterstützten einige europäische Staaten, darunter die Bundesrepublik Deutschland mit Bundeswehrsoldaten, die weiteren Sicherheits- und Aufbau-Missionen OEF und ISAF.

Unter dem Begriff "Disaster Preparedness" verstärkte die US-Regierung Mittel, Personal, Kompetenzen und Aufgaben für den Katastrophenschutz, die Flughafensicherheit und Luftsicherheit. Am 14. September 2001 wurde der Ausnahmezustand verhängt.

Im Oktober 2001 wies Vizepräsident Dick Cheney acht Inlandsgeheimdienste an, ein bestehendes Gesetz aus den 1970er Jahren, das Schleppnetz- und Rasterfahndung ohne richterliche Anordnung verbot, zu umgehen. Am 26. Oktober 2001 trat der "USA PATRIOT Act" in Kraft, der „inländischen Terrorismus“ als Beeinflussen der Regierung durch Einschüchterung oder Zwang definiert und US-Bundesbehörden weitreichende Eingriffe in Bürgerrechte für Anti-Terror-Ermittlungen erlaubt: etwa das Überwachen verdächtigter Personen ohne richterliche Anordnung, das geheime Abhören von Telefonaten, Speichern von Verbindungsdaten und Ausspionieren von E-Mail-Kontakten, das Einholen von personengebundenen Informationen bei Versicherungen, Geldinstituten und Arbeitgebern, das Inhaftieren und Ausweisen terrorverdächtiger Ausländer ohne Angaben und richterliche Prüfung von Verdachtsmomenten und mit erschwerten Haftprüfungsrechten. Danach wurden bis 2003 über 5000 Ausländer, meist junge männliche Muslime mit Kontakten in arabischen Staaten, verhaftet, davon 531 ausgewiesen, manche bis zu acht Monaten festgehalten, aber keiner von ihnen wurde angeklagt. Zwar erklärte der Supreme Court einige dieser Bestimmungen seit 2004 für verfassungswidrig, doch im März 2006 verlängerte der US-Kongress 14 von 16 Bestimmungen des "USA PATRIOT Act" unbefristet. Bush brach die Gesetzesauflage, dem Kongress vollständig Auskunft über die Umsetzung der Maßnahmen zu geben – insgesamt wurden in den USA neben dem zentralen Ministerium für Heimatsicherheit mit 170.000 Beschäftigten 263 Sicherheitsbehörden neu gegründet oder reorganisiert; 1200 staatliche Organisationen und 1931 private Firmen befassen sich seither mit Gefahrenabwehr.

Ähnliche Gesetze verabschiedeten auch andere westliche Staaten, verschärften Einreisebedingungen und weiteten Personenüberwachung aus. Die Bundesrepublik Deutschland führte die Rasterfahndung und Kronzeugenregelung aus der RAF-Bekämpfung der 1970er Jahre wieder ein und verabschiedete zwei „Antiterrorpakete“. Gesetzesentwürfe zur Einführung einer Präventionshaft (2004), zur Telekommunikationsüberwachung (2005), zur Erlaubnis von Abschüssen entführter Flugzeuge und zur präventiven Rasterfahndung (2006), zur geheimen Online-Durchsuchung privater Computer (2008) sowie zur Vorratsdatenspeicherung (2010) erklärte das Bundesverfassungsgericht jeweils für verfassungswidrig.

Der Europäische Rat beschloss am 21. September 2001, den Terrorismus im Gebiet der Europäischen Union (EU) vorrangig zu bekämpfen. Mit dem Gemeinsamen Standpunkt 931 vom 27. Dezember 2001 trafen die EU-Mitgliedstaaten einstimmig zusätzliche Maßnahmen zur Terrorbekämpfung. Besonders mit Verordnung (EG) Nr. 2580/2001 wurde eine einheitliche Liste mit Personen, Vereinigungen oder Körperschaften beschlossen, die zur Terrorbekämpfung und -prävention mit Finanzsanktionen belegt werden (Einfrieren von Geldern und wirtschaftlichen Ressourcen, Bereitstellungsverbot von Geldern und wirtschaftlichen Ressourcen) dürfen. Damit und mit der sogenannten EU-Terrorliste erfüllte die EU die UN-Resolution 1373.

Im Afghanistankrieg und im Zuge weiterer Ermittlungen nahm die US-Armee über 1.000 Verdächtige gefangen, größtenteils Personen arabischer oder asiatischer Herkunft. Sie wurden in das Internierungslager Guantánamo Bay, das Militärgefängnis Bagram und andere Lager außerhalb der USA gebracht, dort von der Außenwelt isoliert und jahrelang ohne Anklage und Bekanntgabe ihrer Identität festgehalten. Rechtlich definierte die US-Regierung sie als „irreguläre Kämpfer“ und versuchte so, sie geltendem Völkerrecht, etwa Artikel 4 des III. Genfer Abkommens über die Behandlung von Kriegsgefangenen, und US-Strafrecht zu entziehen. Ferner benutzten Verhörsspezialisten der CIA bei einigen als Hauptverdächtige geltenden Gefangenen Methoden wie Schlafentzug und Waterboarding, die nach internationalem Recht als Folter definiert sind. Dies führte zu anhaltenden internationalen Protesten von Menschenrechtsorganisationen und verbündeten westlichen Staaten.

Die Folterpraktiken und Militärausnahmeverfahren, denen die Gefangenen unterzogen und unterstellt wurden, stießen auch in den USA auf Widerspruch. Eine Klage auf öffentliche Strafverfahren vor US-Gerichten wurde in der Berufungsinstanz abgewiesen. Ein Urteil im Juni 2008 verpflichtete die US-Regierung, diese Gefangenen nach US-amerikanischen Rechtsstandards zu behandeln. Im November 2009 kündigte US-Justizminister Eric Holder an, dass die mutmaßlichen Drahtzieher der Terroranschläge vor ein Zivilgericht in New York gestellt werden. Chalid Scheich Mohammed und vier Mitangeklagte aus dem Lager Guantánamo sollen sich in der Nähe des früheren World Trade Center für ihre Taten verantworten. Die Zivilverfahren sollen die bisherigen Militärverfahren vor umstrittenen Sondertribunalen in Guantánamo ersetzen, die vom früheren US-Präsidenten George W. Bush eingesetzt worden waren. Manche Opferangehörige kritisierten diese Entscheidung.

Im September 2002 leitete Bush aus dem "Kampf gegen den Terror" das Recht der USA auf Präventivschläge ab (sogenannte Bush-Doktrin) und begründete den seit Ende September 2001 angestrebten Irakkrieg zum einen mit einer angeblichen Zusammenarbeit des Diktators Saddam Hussein mit Al-Qaida, zum anderen mit seiner angeblichen Verfügung über Massenvernichtungsmittel, die er gegen die USA und in Saudi-Arabien stationierte US-Truppen einsetzen könne und wolle. Deutschland, Frankreich, Russland und China lehnten diese Doktrin, die US-Kriegsbegründungen und ihre Teilnahme am Irakkrieg ab. Der UN-Sicherheitsrat verweigerte den USA im Februar 2003 die Legitimation des Irakkrieges. Die US-Regierung bildete daraufhin eine „Koalition der Willigen“, an der auch einige NATO-Staaten teilnahmen, und begann den Irakkrieg im März 2003 ohne UN-Mandat. Er führte zum Sturz Saddam Husseins, gefolgt von jahrelangen Terroranschlägen eines neuen, irakischen Zweigs der al-Qaeda und anderer Gruppen im Irak.

Der Politikwissenschaftler Jochen Hippler ordnete 2003 den Afghanistan- und den Irakkrieg der USA nicht nur als Reaktion auf die Anschläge ein, sondern auch als Fortsetzung einer unilateralen US-Außenpolitik. Diese habe ihre Stellung als einzige verbliebene Supermacht nach dem Kalten Krieg genutzt, um ein seit etwa 1995 vorliegendes neokonservatives Programm zu verwirklichen, „Schurkenstaaten“ und feindliche Regimes zu entmachten, US-Macht im Mittleren Osten und Zentralasien auszudehnen und ihre weltweite Führungsrolle zu stärken. Diese Sicht vertreten auch Wissenschaftler in den USA, etwa George Leaman.

Die Terroranschläge hätten diese Politik zunächst erheblich erleichtert, doch der mit Vorwänden herbeigeführte Sturz des Baath-Regimes habe Gewalt und Terror im Irak enorm verschärft, die Kluft zwischen vom Westen unterstützten arabischen Diktaturen und ihrer Bevölkerung vertieft und so die Instabilität der Nahostregion verstärkt. Zugleich habe er die internationale Solidarität mit den USA beendet, die Autorität der UNO und des Völkerrechts und das Verhältnis des Westens zur islamischen Welt beschädigt, eine Kluft zwischen USA und Europa und zwischen Unterstützer- und Ablehnerstaaten in der EU erzeugt und so eine einheitliche Außen- und Militärpolitik der EU erschwert.

Jährlich am 11. September wird mit Gedenkfeiern an die Opfer der Anschläge erinnert, insbesondere in New York, am Pentagon und in Shanksville. In New York werden üblicherweise die Namen der 2791 Menschen, die hier bei dem Anschlag ums Leben kamen, durch deren Angehörige in alphabetischer Reihenfolge verlesen. Es nehmen hochrangige Politiker teil, wobei jedoch auf Wunsch der Angehörigen auf Ansprachen verzichtet wird und stattdessen literarische oder historische Texte verlesen werden.

Nachts leuchtete unter anderem in NYC eine Lichtinstallation, der Tribute in Light. Sie wurde bis 2011 jährlich wiederholt, aber deren Zukunft ist ungewiss.

An der Stelle des World Trade Centers befindet sich eine Gedenkstätte im Ausbau – sie wurde am 11. September 2011 eingeweiht. Der Entwurf des National September 11 Memorial and Museum stammt von Daniel Libeskind, Michael Arad und dem Landschaftsarchitekten Peter Walker. Es handelt sich dabei um zwei Wasserbecken, die den Grundriss der beiden Hochhaustürme anzeigen (wie „Fußabdrücke“) – ihr Name "Reflecting Absence" ist übersetzbar mit ‚Nachdenken darüber, was fehlt‘. Außerdem gehört ein Pavillon mit Museum zum Mahnmal. Dem Bau der Gedenkstätte ging eine Diskussion der Frage voraus, ob sie direkt an der Stelle, an der die Opfer starben, errichtet werden sollte.

Am 10. Juni 2006 wurde an der Außenwand der "Feuerwache Liberty Street", genau gegenüber vom ehemaligen WTC-Komplex, ein Denkmal der Feuerwehr (FDNY, vor allem ein Wandrelief) und 2008 das Pentagon Memorial in Arlington als flächenhafte Installation bei Washington eingeweiht.

Fünf weitere WTC-Gebäude, darunter das benachbarte WTC 7, wurden ebenfalls zerstört, ebenso vier U-Bahn-Stationen. 23 weitere Gebäude, die das WTC umgaben, wurden zum Teil so schwer beschädigt, dass sie später abgerissen wurden. Komplett zerstört wurde die kleine St. Nicholas Greek Orthodox Church, stark beschädigt wurden das ehemalige Bankers Trust Building, 90 West Street, 130 Cedar Street, das New York Telephone Building, 30 West Broadway ("Fiterman Hall"), drei Gebäude des World Financial Centers sowie der Wintergarten dazwischen. Fast alle beschädigten Gebäude konnten wiederhergestellt werden. Das schwer beschädigte Deutsche Bank Building (130 Liberty Street) wurde nach langem Versicherungsstreit bis 2009 abgerissen. Zuvor war es jahrelang komplett schwarz umhüllt und trug eine große US-Flagge auf der zum Ground Zero gerichteten Seite. An der Stelle entsteht das neue Five World Trade Center. Auch das Gebäude 30 West Broadway ("Fitterman Hall") wurde von November 2008 bis Sommer 2009 abgerissen und durch einen Neubau ersetzt – die Eröffnung fand am 12. August 2012 statt.
Am 2. April 2006 wurde mit dem Bau des One World Trade Center (erster Name des Entwurfs "Freedom Tower", deutsch: "Freiheitsturm") als Nachfolgebebauung an der Stelle des zerstörten und abgetragenen World Trade Centers begonnen. Das Hauptgebäude wurde von dem Architekten David Childs entworfen. Dem ging eine lange Diskussion um die Art der Neubebauung voraus. Im Mai 2013 erreichte das Bauwerk seine Endhöhe und wurde am 3. November 2014 eröffnet.

Das Gebäude ist 541,3 Meter hoch, was 1776 Fuß entspricht. Dies soll an die Unabhängigkeitserklärung der Vereinigten Staaten von 1776 erinnern und geht auf den Entwurf von Daniel Libeskind zurück. Im Jahr 2002 hatte die Stadt New York zunächst das angesehene Büro "Beyer Blinder Belle" mit der Erstellung von sechs unterschiedlichen Entwürfen beauftragt. Diese fielen jedoch in der Meinung vieler New Yorker durch, da die darin geplanten Hochhäuser auf dem Gelände niedriger waren als das frühere World Trade Center und vor allem nicht spektakulär genug seien. Der Turm wurde im Herbst 2014 fertiggestellt. Daneben sollen drei weitere Gebäude entstehen (Two World Trade Center, Three World Trade Center und Four World Trade Center).

Ein neu errichtetes Gebäude mit der Bezeichnung 7 World Trade Center des Vorgängerbauwerkes wurde bereits ab 2002 erbaut und im Mai 2006 eröffnet.

Mounir al-Motassadeq war in der al-Qaida an den Vorbereitungen der Terroranschläge beteiligt. Er wurde daher nach einem mehrjährigen Verfahren schuldig gesprochen, bei der Entführung der Flugzeuge und der Ermordung der Passagiere und Besatzungsmitglieder mitgewirkt zu haben. Die Vernichtung des World Trade Centers war ihm strafrechtlich nicht anzulasten. Er wurde daher wegen Beihilfe zum Mord in 246 Fällen und Mitgliedschaft in einer terroristischen Vereinigung am 8. Januar 2007, rechtskräftig seit 2. Mai 2007, zu einer Freiheitsstrafe von 15 Jahren verurteilt.

Seit 11. Februar 2008 sind Chalid Scheich Mohammed, Ramzi Binalshibh, Ali Abdel Asis Ali, Mustafa Ahmed al-Hausaui und Walid bin Attasch von den Vereinigten Staaten im Zusammenhang mit der Planung und Durchführung der Anschläge angeklagt. Das Strafverfahren gegen einen weiteren Angeklagten wurde 2008 eingestellt.

Am 5. September 2012 wurde eine Klage der World Trade Center Properties LLC gegen American Airlines und United Airlines in den Vereinigten Staaten zugelassen. Den Fluggesellschaften wird vorgeworfen, durch mangelhafte Sicherheitskontrollen fahrlässig den Zustieg von 19 Terroristen auf ihre Flugzeuge zugelassen zu haben, womit sie eine rechtliche Verantwortung an der Vernichtung der Gebäude des World Trade Centers tragen sollen. Der Kläger hatte kurz vor den Anschlägen das World Trade Center für 99 Jahre gepachtet. Die Streitsumme beläuft sich auf 2,8 Milliarden US-Dollar.

Entgegen den ursprünglichen Erwartungen wurden die Aktienkurse an der Wall Street von den Anschlägen des 11. Septembers nicht sehr hart getroffen. Dagegen waren die Folgen der Finanzkrise ab 2007 weitaus stärker. Im Jahre 2010 hatte die Wertpapierbranche in New York nur noch 163.000 Beschäftigte, knapp 19 Prozent weniger als 2000, während in ganz USA nur ein Rückgang von vier Prozent auf 804.000 zu verzeichnen war. Somit war der Anteil der Arbeitsplätze am Standort New York in der Branche von 25 auf 20 Prozent innerhalb von zehn Jahren gesunken. Allerdings nahm die relative Bedeutung von New York in der Finanzbranche schon seit den 1990er Jahren ab, sodass die Terroranschläge nicht als einziger Faktor für diese Entwicklung betrachtet werden können.

Je ein Ausschuss des Senats und des US-Repräsentantenhauses führten von Februar bis Dezember 2002 die „Gemeinsame Untersuchung der Aktivitäten der Geheimdienste vor und nach den Terroranschlägen am 11. September 2001“ durch. 2002 erschien auch der „Gemeinsame Bericht der Feuerwehrführung und der Beratungsfirma McKinsey & Co“ über Führungsstrukturen und Einsatzrichtlinien am 11. September 2001 und daraus zu ziehende Konsequenzen.

Auf Drängen von Opfervereinen setzte das Repräsentantenhaus gegen erhebliche Widerstände der US-Regierung im Herbst 2002 die parteiübergreifende 9/11-Kommission ein. Sie bestand aus je fünf Abgeordneten der Demokratischen und Republikanischen Partei unter dem Vorsitz von Ex-Gouverneur Thomas Kean sowie 78 Stabmitgliedern. Sie sollte Vorgeschichte, Verlauf der Anschläge und Reaktionen der US-Behörden darauf aufklären und sicherheitspolitische Maßnahmen vorschlagen, die solche Anschläge zukünftig verhindern sollen. Die physikalischen Einsturzursachen der WTC-Gebäude sollte sie nicht untersuchen. Sie arbeitete von Januar 2003 bis August 2004 und befragte etwa 1200 Zeugen, darunter 120 Regierungsangehörige inklusive George W. Bush, Vizepräsident Dick Cheney und Sicherheitsberaterin Condoleezza Rice. Ihr Abschlussbericht (22. Juli 2004) zeigte gravierende systemische Fehler der US-Behörden auf, die die Anschläge ermöglicht hatten: etwa fehlende Durchleuchtung von Inlandspassagieren vor dem Einchecken am Flughafen, zu langwierige und umständliche Verfahrenswege und Befehlshierarchien, die ein rasches Eingreifen der NORAD verhinderten, unterlassene Überprüfung von Flugschulen in den USA auf terrorverdächtige Flugschüler, fehlende Verfolgung von in die USA eingereisten Al-Qaida-Mitgliedern, fehlender Informationsaustausch zwischen CIA und FBI über Verdächtige und Passivität der Bush-Regierung gegenüber akuten Anschlagswarnungen. Diese hatte von Mai bis 6. August 2001 40 Tageskurzberichte zu Al Qaida erhalten, darunter mehrere, die vor einem multiplen Anschlag in den USA gewarnt hatten, möglicherweise mit Flugzeugentführungen und Zielen in New York. Abstimmungsprobleme, Missverständnisse, Informationsmängel, Nichtweitergabe von Befehlen, unklare Vorgaben und falsche Reaktionen auf allen Ebenen wurden im Detail nachgewiesen. Dafür verantwortliche Personen wurden nicht benannt und persönliche Konsequenzen nicht gefordert. Infolge dieser Analyse wurden etwa die Einsatzrichtlinien des FDNY, der New Yorker Polizei, des FBI und der CIA geändert. Das Ministerium für Innere Sicherheit wurde neu gegründet und die Städte-Kampagne „Preparedness“ eingerichtet.

Die Katastrophenschutzbehörde FEMA untersuchte bis Mai 2002 erstmals die Gebäudesicherheit und bautechnischen Probleme, die den Einsturz der WTC-Gebäude verursachten. Nachdem ihr Bericht als unzureichend kritisiert wurde, erhielt das National Institute of Standards and Technology (NIST) einen genau definierten Forschungsauftrag, den es in eigener Regie in Einzelaufgaben unterteilte und an Experten verschiedener Fachrichtungen delegierte. Es gab in der Folge mehrere Berichte heraus:

Im September 2005 erschien eine ausführliche Studie über alle relevanten Aspekte der Einstürze von WTC 1–6. An den dreijährigen Untersuchungen waren über 300 Experten und Wissenschaftler beteiligt. Zwei "Fact Sheets" vom August 2006 und Dezember 2007 fassten die Antworten des NIST auf die wichtigsten Fragen zum technischen Ablauf der Einstürze und deren Erklärung zusammen. Der mehrfach verschobene Abschlussbericht für WTC 7 erschien am 21. August 2008.

Zudem untersuchten unabhängige Wissenschaftler die WTC-Einstürze ohne Regierungsauftrag und gaben Aufsätze dazu heraus. Die bisher detailliertesten Hochpräzisionssimulationen wurden von Wissenschaftlern der Purdue University (Indiana) durchgeführt. Sie erschienen 2007 und belegen, dass im Nordturm 17 von 47 tragenden Stützen zerstört wurden, so dass der Einsturz nach knapp zweistündigem Feuer unausweichlich wurde. Zuvor war das NIST von sechs zerstörten Stützen ausgegangen, die zusammen mit den anhaltenden Innenbränden für den Kollaps der Stockwerke über der Einschlagszone ausgereicht hätten.

Zu den längerfristigen und tiefergehenden Ursachen des islamistischen Terrors gibt es verschiedene Theorien: „Antiimperialistische“ Erklärungsmuster machen den Westen, besonders die Nahostpolitik der USA und Israels, für den Hass und die Radikalisierung vieler Muslime verantwortlich. Weil die Mudschaheddin in Afghanistan seit 1980 erhebliche militärische, finanzielle und logistische Unterstützung der USA erhielten, um die sowjetischen Besatzer im Sowjetisch-Afghanischen Krieg erfolgreich bekämpfen zu können, wurde Osama bin Laden oft als Produkt der CIA und seine Anschlagsplanung als Folge einer verfehlten US-Außenpolitik im Kalten Krieg betrachtet. Diese sei schließlich auf die USA selbst zurückgefallen (Blowback).

Auch das Versagen der reichen westlichen Industriestaaten gegenüber dem Problem der Armut durch eine einseitige Globalisierung habe dem Terror (nicht jedoch ihren Drahtziehern) einen Nährboden geschaffen. Diese Sicht vertreten vielfach linke Intellektuelle wie Noam Chomsky oder Menschenrechtler wie die Inderin Arundhati Roy.

Aus kultursoziologischer Perspektive wird das Phänomen des sogenannten "Islamischen Terrorismus" auch als Frontbildung gegen kulturelle Modernisierung im jeweiligen Heimatland gedeutet. Die Verunsicherung, die mit dem Brüchigwerden alter tradierter Strukturen und Ideologien einhergehe, werde durch verstärkte Besinnung auf die eigenen Wurzeln (z. B. den Salafismus) kompensiert und im terroristischen Kampf gegen die westliche Welt ausgelebt. Durch den spektakulären Anschlag im Zentrum der westlichen Welt wollten die Täter die Verletzlichkeit der „Juden und Kreuzfahrer“ symbolisch demonstrieren. In dieser Perspektive wird die Ideologie der Täter als „Islamfaschismus“ gedeutet und die Komponente des Antisemitismus darin betont.

Viele Musiker reagierten auf die Anschläge mit besonderen Werken. In vielen dieser Titel standen Betroffenheit, Trauer, Gedenken und der Wunsch nach Toleranz im Vordergrund.

In den USA wurde der Song "Only Time" von Enya in der Version mit eingeblendeten Stimmen Betroffener zur inoffiziellen Hymne zum 11. September. Das Hardcore-Techno-Lied "We Will Never Forget" von American Hardcore Alliance gedenkt der Opfer. Der Country-Musiker Alan Jackson komponierte den Song "Where were you when the world stopped turning?", Darryl Worley den Song "Have You Forgotten?". Weitere solche Themenwerke sind das Studioalbum "The Rising" von Bruce Springsteen, "Let’s Roll" mit Bezug auf den Widerstand der Passagiere auf Flug UA-93 von Neil Young, „Believe“ von Yellowcard, der Instrumentaltitel "Darkness of Sept. 11th" des Gitarristen Chris Mike und "Towers On Fire" von der brasilianischen Thrash-/Death-Metal-Band Torture Squad. "When the Eagle Cries" von Iced Earth bezieht sich auf den Weißkopfseeadler, das Wappentier der USA, dessen Tränen die Trauer der USA symbolisieren. Der deutsche Rapper Curse veröffentlichte am 16. September 2001 den Freetrack "Nichts wird mehr so sein wie es war", in dem er zu mehr Toleranz und Verantwortung aufforderte.

Andere widmeten ihre Auftritte und Aufnahmen den Opfern. Michael Jackson schrieb das Lied "What More Can I Give" mit dem Ziel, 50 Millionen Dollar für die Opferangehörigen einzunehmen. Paul McCartney war am 11. September 2001 in New York und schrieb danach den Song "Freedom" für ein Tribute-Konzert. Sting widmete sein für den 11. September in der Toskana angesetztes Konzert den Opfern, nachdem seine ausgewählten Konzertgäste sich gegen eine Absage ausgesprochen hatten. Die Konzertaufnahme erschien als Live-Album mit dem Titel "All This Time", der Klassiker "Fragile" daraus erschien auf dem Album "America: A Tribute to Heroes". Der Saxophonist Sonny Rollins gab am 15. September 2001 ein Konzert in Boston, dessen Live-Aufnahme unter dem Titel "Without a song: the 9/11 Concert" erschien.

Einige Musiker befassten sich mit den Folgen der Anschläge: so die Band Tomte mit ihrem Song "New York" oder die Eagles mit "Hole In The World" (2003). Die Gruppe Mono für Alle! setzt sich mit ihrem Lied "11. September" kritisch mit dem Gedenken daran auseinander. "Heads Will Roll" von Pro-Pain beschreibt Rachegefühle und kritisiert die Entwicklung zum Irakkrieg. Der Techno-Musiker Chris Korda fügte in einem umstrittenen Musikvideo "I Like To Watch" Medienbilder von den Anschlägen mit pornografischen Filmausschnitten zusammen. Die Duisburger Hip-Hop-Band Die Bandbreite kritisiert mit ihrem Titel "9/11 Selbst gemacht" die vorherige US-Politik. Schließlich thematisierte die Thrash-Metal-Band Slayer im Lied "Jihad" die Anschläge aus Sicht der Terroristen.

Der ungarische Komponist Robert Gulya, der in den Jahren 2000 bis 2002 in den USA lebte, schrieb im Herbst 2001, kurz nach den Anschlägen des 11. September, ein neues Gitarrenkonzert. Im ersten Satz dieses Konzerts wählte Gulya ein Thema, das an jenen Terroranschlag erinnert. Die Uraufführung dieses Werkes wurde gefilmt und auf der DVD "Live in Budapest" der österreichischen Gitarristin Johanna Beisteiner veröffentlicht.

Nach den Terroranschlägen am 11. September 2001 gestaltete Eric Fischl die Werkreihe "ten breaths" mit Gouachen und Plastiken, die stürzende und abgestürzte Personen zeigen. Die Skulptur "Tumbling Woman", die eine Frau im freien Fall darstellt, wurde in den USA kontrovers diskutiert. Die Werkreihe verarbeitet die Pressebilder von den Verzweifelten, die sich nach den Anschlägen aus den Fenstern der brennenden Türme vom World Trade Center in die Tiefe stürzten, um dem Feuertod zu entgehen.

Von Gerhard Richter wurde das Bild „September“ in Auseinandersetzung mit dem Ereignis angefertigt. Den Opfern der Terroranschläge vom 11. September 2011 und dem von 1993 ist das Kunstwerk To the Struggle Against World Terrorism gewidmet.

In seinem 2003 erschienenen Roman "Windows on the World" erzählt Frédéric Beigbeder minutiös von einem Vater und seinen zwei Söhnen, die sich während der Anschläge im Restaurant Windows on the World im Nordturm des World Trade Centers befinden.

Jonathan Safran Foers 2005 erschienener Roman "Extrem laut und unglaublich nah" erzählt die Geschichte eines traumatisierten neunjährigen Jungen, dessen Vater bei den Anschlägen ums Leben gekommen ist.

Der Protagonist von Don DeLillos 2007 erschienenem Roman "Falling Man" ist ein Überlebender der Anschläge. Leitmotivisch ziehen sich durch den Roman die Auftritte eines Performancekünstlers namens Falling Man, der an einem Seil hängend die berühmt gewordene Fotografie The Falling Man von Richard Drew nachstellt.

Der 2006 erschienene Roman Die Habenichtse von Katharina Hacker spielt vor dem Hintergrund der Terroranschläge und des beginnenden Irakkriegs.

2014 erschien der Roman "Joe 9/11" des österreichisch-finnischen Autorenduos Thomas Antonic und Janne Ratia, der im Jahr 2001 spielt und in dem neben einer Kriminalstory die Geschichte des amerikanischen Fotografen Peter Novak erzählt wird, der am 11. September eine Ausstellung in Manhattan eröffnen soll. Der Verlag Edition Atelier bewirbt das Buch mit dem Satz: "JOE 9/11 setzt allen Verschwörungstheorien zu 9/11 ein furioses Ende. Oder setzt er ihnen noch eins drauf?"

Mehr oder minder schwarzer Humor unter dem Motto "Wo war King Kong, als wir ihn brauchten?" sowie insbesondere online verbreitete Witze kamen bereits am Tag nach dem Anschlag auf. Sie haben auch Niederschlag in der volkskundlichen Forschung gefunden.

Die britisch-pakistanische Comedienne Shazia Mirza wurde überregional bekannt, als sie bei ihrem ersten Bühnenauftritt nach den Terroranschlägen in einem Hidschāb auftrat und mit den Worten begann:
Wiglaf Droste interpretierte 2011 in einem Beitrag für die marxistische Zeitung Junge Welt die Angriffe auf die Twin Towers satirisch als Architekturkritik:

Der Spielfilm Postal des deutschen Regisseurs Uwe Boll setzt sich mit dem Thema auseinander.

Im Januar 2015 sind in der IMDb 353 Titel zu diesem Thema gelistet.

Zu den Anschlägen vom 11. September haben sich viele Verschwörungstheorien entwickelt. Deren Vertreter gehen meist davon aus, dass die US-Regierung und/oder ihre Geheimdienste die Anschläge wissentlich zugelassen oder selbst durchgeführt haben. Sie bezweifeln die ermittelten Ursachen für die Anschlagsschäden und behaupten andere Ursachen, etwa eine kontrollierte Sprengung der WTC-Gebäude. Anhänger des sogenannten 9/11 Truth Movement fordern seit 2005 eine neue Untersuchung der Ereignisse. Ihren Thesen widersprechen neben den Experten der FEMA und des NIST auch unabhängige Wissenschaftler.














</doc>
<doc id="5073" url="https://de.wikipedia.org/wiki?curid=5073" title="Tommy Lee Jones">
Tommy Lee Jones

Tommy Lee Jones (* 15. September 1946 in San Saba, Texas) ist ein US-amerikanischer Schauspieler und Filmregisseur sowie Golden-Globe- und Oscar-Preisträger.

Jones kam 1946 als Sohn des Ölarbeiters Clyde Jones und der Polizistin Lucille Marie (geborene Scott) im texanischen San Saba zur Welt. Jones hatte eine indianische Großmutter (Cherokee) und jobbte als Jugendlicher mit seinem Vater in den Ölfeldern. Sein Vater verließ die Familie, um in den Ölfeldern Libyens zu arbeiten. Jones schaffte es über Football-Stipendien in die Eliteschule St. Mark’s School of Texas in Dallas, eine Jungenschule, die auf das Hochschulstudium vorbereitet, und ging dann an die Harvard University, wo er Anglistik studierte und 1969 cum laude abschloss. In Harvard hat er zudem erfolgreich American Football gespielt (1966–1968) und hatte die Option, als Profi-Spieler zu den Dallas Cowboys zu gehen. Mit seinem damaligen Zimmergenossen, dem Demokraten Al Gore, ist Jones seit seiner Studienzeit befreundet und hat im August 2000 dessen Präsidentschaftskampagne unterstützt.

Jones’ erste Frau war Katherine (Kate) Lardner, Enkelin von Ring Lardner, mit der er sieben Jahre verheiratet war. 1981 heiratete er die Fotografin Kimberlea Gayle Cloughley, von der er sich 1996 scheiden ließ. Mit ihr hat er zwei Kinder. Seit März 2001 ist er mit der Kameraassistentin Dawn Maria Laurel verheiratet. Jones ist in verschiedenen karitativen Projekten aktiv und lebt fern von Hollywood in San Antonio, Texas. In der Umgebung bewirtschaftet er zwei Ranches, auf denen Rinder und Polo-Ponys gezüchtet werden.

Erste Erfahrungen mit der Schauspielerei machte Jones in der Schule. Während seines Studiums wirkte er unter anderem in Shakespeare-Aufführungen mit. Nach seinem Abschluss in Harvard ging er 1969 nach New York, wo er ein paar Jahre lang für Theater und Fernsehen spielte. Sein Debüt am Broadway gab er mit "A Patriot For Me" (1969) von John Osborne. Eine erste kleine Filmrolle hatte Jones in "Love Story" (1970), die sein Harvard-Mitbewohner Erich Segal verfasst hatte. Jones spielte den Mitbewohner des Hauptdarstellers Ryan O’Neal und kommentiert in zwei Szenen dessen Liebesleben. 1975 zog Jones nach Los Angeles und spielte eine Nebenrolle in der Pilotsendung der Serie "Charlie's Angels". Seine erste Hauptrolle war 1976 der flüchtende Gefängnisinsasse in "Vergewaltigt hinter Gittern".

1983 bekam Jones einen Emmy für seine Darstellung eines Mörders in der Todeszelle "The Executioner’s Song", womit sein Bekanntheitsgrad stieg und er sich als Hollywood-Schauspieler etablierte. Bekannt wurde Jones vor allem als Darsteller in Actionfilmen. Er ist einer der wenigen Schauspieler, die einen eigenständigen Fortsetzungsfilm erhielten, obwohl er im ersten Film lediglich eine Nebenrolle hatte: In "Auf der Jagd" nimmt er die Oscar-gekrönte Rolle des Deputy US Marshal Sam Gerard aus "Auf der Flucht" wieder auf. Seine Gage für Hollywood-Produktionen soll zu Spitzenzeiten bei 20 Millionen US-Dollar gelegen haben "(Men in Black II)".

Sein Regiedebüt gab Jones 1995 mit dem Fernsehfilm "Einmal Cowboy, immer ein Cowboy" ("The Good Old Boys") nach einer Vorlage von Elmer Kelton, in dem er auch die Hauptrolle spielte. Die Produktion erhielt Nominierungen u. a. für den Cable Ace Award und den Preis der Actor’s Guild. 2005 führte er bei "Three Burials – Die drei Begräbnisse des Melquiades Estrada" ("The Three Burials of Melquiades Estrada"), einem zeitgenössischen Western, in dem er ebenfalls eine Hauptrolle spielte, zum zweiten Mal Regie. Diese Produktion war sein erster Kinofilm, bei dem er die Regie übernahm. Jones produzierte den Film zusammen mit Luc Besson, Michael Fitzgerald und Chris Menges und wurde für die Rolle des Pete Perkins bei den Filmfestspielen von Cannes mit dem Darstellerpreis ausgezeichnet. 2011 folgte mit "The Sunset Limited – Eine Frage des Glaubens" ein weiterer Fernsehfilm, den Jones inszenierte. Seine vierte Regiearbeit "The Homesman" kam 2014 in die Kinos.

Jones wird hauptsächlich vom Schauspielkollegen Ronald Nitschke synchronisiert.








</doc>
<doc id="5074" url="https://de.wikipedia.org/wiki?curid=5074" title="Tom Jones">
Tom Jones

Sir Thomas John Woodward OBE (* 7. Juni 1940 in Treforest, Pontypridd, Wales), besser bekannt als Tom Jones, ist ein britischer Popsänger.

Jones war ursprünglich Staubsaugervertreter, versuchte aber schon 1963 eine Karriere als Sänger mit der Beat-Band "Tommy Scott and the Senators". In jenem Jahr nahm er insgesamt sieben Stücke in Joe Meeks Studio auf, die aber erst 1965 nach seinem ersten großen Erfolg veröffentlicht wurden. Die Band war nicht sehr erfolgreich, und so entschloss sich Jones zu einer Solokarriere.

Als Clubsänger tingelte er zunächst abends unter dem Pseudonym „Tiger Tom“ (der Spitzname „Tiger“ ist ihm bis heute geblieben) durch die Arbeiterkneipen von Wales und ab 1964 durch die Londoner Bars. Dort fiel er dem Manager Gordon Mills auf, der mit ihm Platten produzierte. Die erste Single "Chills and Fever" floppte, doch schon der Nachfolgetitel "It’s Not Unusual" landete als Nummer 1 in den britischen Charts. Viele Hits folgten. Im Jahr 1965 sang er die Titelsongs zu den Filmen "Was gibt’s Neues, Pussy?" ("What’s New, Pussycat?") und "Feuerball" ("Thunderball"). Auch in Deutschland erzielte Jones große Erfolge. Er kam 1968 mit Delilah und "Help Yourself" zweimal auf Platz 1 der deutschen Hitlisten. Jones spielte erfolgreich mit seiner erotischen Ausstrahlung. Er trat in hautengen Hosen und mit sehr weit geöffneten Hemden auf, die seine üppige Brustbehaarung zeigten. Live-Konzerte waren ausverkauft und mit kreischenden Mädchen und Frauen überfüllt.

Anfang der 1970er Jahre zog er nach Las Vegas, wo er in Clubshows auftrat. In jener Zeit hatte er sich auf Country-Pop spezialisiert, was ihm einige Hits einbrachte. Danach wurde es etwas stiller um ihn. 1987 tauchte er mit dem Song "A Boy from Nowhere" erneut in der englischen Hitparade auf. 1988 coverte Jones zusammen mit den Electronic-Avantgardisten Art of Noise die Prince-Komposition "Kiss". Im Jahr 1991 sang Jones im Duett mit Van Morrison "Carrying a Torch".

Sein Gastauftritt 1993 in der NBC-Fernsehserie "Der Prinz von Bel-Air" (Staffel 3, Folge 18) als Carltons Schutzengel sorgte unter den amerikanischen und deutschen Serienfans allgemein für Aufsehen.

Im Jahr 1994 moderierte Jones die ersten MTV Europe Music Awards in Berlin, und 1996 hatte er einen selbstironischen Auftritt in dem Film "Mars Attacks!" von Tim Burton. Im Jahr 2000 landete er den von Mousse T. geschriebenen und produzierten Hit "Sex Bomb" und bot mit dem Album "Reload" 1999/2000 eine Mischung von Duetten, so mit Nina Persson von den Cardigans, Robbie Williams, den Stereophonics oder den Manic Street Preachers. Die Coverversion des Talking-Heads-Titels "Burning Down the House" zusammen mit Nina Persson wurde international erfolgreich und erreichte Platz 10 in den englischen Charts.

Tom Jones wurde 2006 von Königin Elisabeth II. zum Knight Bachelor geschlagen. Durch seine Nobilitierung heißt er jetzt Sir Thomas.

Im November 2008 veröffentlichte Tom Jones sein 25. Studioalbum, "24 Hours". Für dieses Album war Tom Jones erstmals selbst als Songschreiber tätig. Kara DioGuardi steuerte mit "Give a Little Love" ein Stück bei, und mit "The Hitter" von Bruce Springsteen findet sich ein weiterer Coversong auf dem Album.

Jones ist seit der ersten Staffel im Jahr 2012 Jurymitglied und Coach in der britischen Gesangs-Castingshow "The Voice UK", die auf BBC One ausgestrahlt wird.

2016 trat er in der Weihnachts-Show von Helene Fischer im ZDF auf und zeigte im Duett mit Fischer einen seiner größten Hits "Sexbomb".

Jones war seit 1957 mit Melinda Rose Woodward verheiratet, mit der er einen Sohn hat. Sie starb am 10. April 2016 an den Folgen einer Krebserkrankung.

Studioalben
Livealben
Kompilationen





</doc>
<doc id="5075" url="https://de.wikipedia.org/wiki?curid=5075" title="Theodor Heuss">
Theodor Heuss

Theodor Heuss (* 31. Januar 1884 in Brackenheim; † 12. Dezember 1963 in Stuttgart) war ein deutscher Journalist, Politikwissenschaftler und fast 60 Jahre aktiver liberaler Politiker (NSV, FVg, FVP, DDP, FDP/DVP). Mit der Gründung der FDP 1948 wurde er deren Vorsitzender. Er war von 1949 bis 1959 der erste Bundespräsident der Bundesrepublik Deutschland.

Heuss kam in der württembergischen Oberamtsstadt Brackenheim als Sohn des Regierungsbaumeisters Ludwig „Louis“ Heuss (1853–1903) und der Elisabeth Heuss, geb. Gümbel (1853–1927), zur Welt. Er hatte zwei ältere Brüder, Ludwig (1881–1932), später Heilbronner Stadtarzt, und Hermann (1882–1959), später Architekt und Professor für Bauwesen. Heuss war evangelisch.

Nach zehn Jahren als Oberamtsbaumeister in Brackenheim wurde Heuss’ Vater 1890 Leiter des Tiefbauamtes im größeren Heilbronn, was den Umzug der Familie dorthin nach sich zog. Theodor Heuss besuchte in Heilbronn die Volksschule und das humanistische "Karlsgymnasium", dessen Nachfolger heute ihm zu Ehren Theodor-Heuss-Gymnasium heißt. 1902 machte er dort sein Abitur. Wegen einer Verletzung leistete Heuss keinen Militärdienst.

Heuss studierte Nationalökonomie, Literatur, Geschichte, Philosophie, Kunstgeschichte und Staatswissenschaften an der Münchner und an der Berliner Universität. 1905 wurde er in München bei Lujo Brentano über "Weinbau und Weingärtnerstand in Heilbronn am Neckar" promoviert. Nach seinem Studium war er politischer Redakteur. Er leitete von 1905 bis 1912 für Friedrich Naumann die Zeitschrift "Die Hilfe" in Berlin. Als Geschäftsführer und Vorstandsmitglied des Deutschen Werkbundes schrieb er 1918 die Einführung zur Dokumentation des Architektenwettbewerbs zum „Haus der deutsch-türkischen Freundschaft“ in Konstantinopel (1. Preis: German Bestelmeyer), das nach der Niederlage im Ersten Weltkrieg und dem Zusammenbruch des Deutschen wie des Osmanischen Reiches nie gebaut wurde.

Heuss war seit dem 11. April 1908 mit Elly Heuss-Knapp (1881–1952) verheiratet, mit der er einen Sohn – Ernst Ludwig – hatte. Die beiden wurden von Albert Schweitzer getraut, mit dem seine Frau gut befreundet war.

Von 1912 bis 1918 war Heuss Chefredakteur der "Neckar-Zeitung" in Heilbronn; zudem verfasste er Feuilletons für die in München erscheinende Zeitschrift "Der Kunstwart" und die Fachzeitschrift "Die dekorative Kunst", wo er über Architektur und Design schrieb. 1913 übernahm er die Leitung der Wochenschrift März. Von 1918 bis 1933 war er Geschäftsführer und Vorstandsmitglied des Deutschen Werkbundes. Von 1920 bis 1933 war er Studienleiter und Dozent an der Deutschen Hochschule für Politik in Berlin und gab von 1923 bis 1926 die Zeitschrift "Die Deutsche Nation" heraus. Eine Gedenktafel über dem Eingang des Hauses Fregestraße 80 in Berlin-Schöneberg erinnert daran, dass er dort von 1918 bis 1930 wohnte.

Als Anhänger Friedrich Naumanns nahm Heuss 1903 als Delegierter am letzten Parteitag von dessen "Nationalsozialem Verein" teil. Nach der Auflösung des Vereins trat er zusammen mit der großen Mehrzahl der Nationalsozialen im Sommer 1903 der linksliberalen "Freisinnigen Vereinigung" bei, die sich mit anderen linksliberalen Parteien 1910 zur "Fortschrittlichen Volkspartei" zusammenschloss. 1918 war er Gründungsmitglied der "Deutschen Demokratischen Partei" (DDP), deren Gründungsaufruf von Theodor Wolff stammte. 1919 wurde Heuss Stadtverordneter in Berlin-Schöneberg. 1930 fusionierte die DDP mit der Volksnationalen Reichsvereinigung zur Deutschen Staatspartei (DStP). 1931 reiste Heuss zu einer Konferenz liberaler Parteien, die in Athen stattfand. Im Anschluss machte er eine Rundreise durch Griechenland, über die er eine Reihe von Artikeln veröffentlichte, u. a. über die griechische Landschaft, die Situation von Flüchtlingen aus der Türkei, die Moderne in Griechenland und die Industrialisierung. Diese Reise sollte später eine Rolle spielen, als Heuss die diplomatische Isolation der Bundesrepublik brechen konnte.

Von 1924 bis 1928 und von 1930 bis 1933 war Heuss Abgeordneter des Deutschen Reichstags. Er gehörte während der Weimarer Republik der Republikschutzorganisation Reichsbanner Schwarz-Rot-Gold an.

Am 23. März 1933 stimmte Heuss zusammen mit den vier anderen Abgeordneten seiner Partei – Hermann Dietrich, Heinrich Landahl, Ernst Lemmer und Reinhold Maier – bei der Abstimmung über das Ermächtigungsgesetz im Reichstag zu, obwohl er sich vorher in seiner Fraktion gegen die Zustimmung ausgesprochen hatte. Auf den Seiten der Stiftung Bundespräsident-Theodor-Heuss-Haus heißt es: „Theodor Heuss hat sich vorher in der Fraktion gegen die Zustimmung ausgesprochen und auch schon einen Redeentwurf vorbereitet, mit dem er seine Stimmenthaltung begründen will – doch er beugt sich der Fraktionsdisziplin“.

Die Begründung für die Zustimmung ist in der Rede von Reinhold Maier nachzulesen. Nach den Angaben von Heuss in seinen 1967 erschienenen Erinnerungen (zwei nachgelassene Kapitel der "Erinnerungen 1905 bis 1933") war der Ausschuss seiner Partei zu keiner einheitlichen Meinung in Bezug auf das Ermächtigungsgesetz gekommen. Deshalb wurde der Reichstagsgruppe die Entscheidung überlassen mit der Bitte, einheitlich abzustimmen. Hermann Dietrich und Heuss waren dagegen oder zumindest für eine Stimmenthaltung, die anderen drei liberalen Reichstagsabgeordneten waren für die Zustimmung. Heuss und Dietrich schlossen sich dann der Mehrheitsmeinung an, nachdem sie, wie Elfriede Kaiser-Nebgen berichtet, Heinrich Brüning konsultiert hatten, der ihnen erklärt hatte, die Zentrumspartei werde aufgrund der von Hitler gegebenen „Garantien“ dem Gesetz zustimmen.

Als Buchautor war er von der Bücherverbrennung 1933 in Deutschland selbst betroffen, da auch drei Werke von ihm indiziert und verbrannt wurden, darunter "Hitlers Weg" (1932). Zunächst äußerte er, dies sei „nicht zu tragisch“. Er verfasste einen (nicht abgedruckten) Artikel für die "Vossische Zeitung", in dem er die Bücherverbrennungen in der Tradition des ersten Wartburgfestes 1817 sah.
Die von ihm mitherausgegebene Zeitung "Die Hilfe" stellte die Bücherverbrennung mit dem Boykott jüdischer Geschäfte des 1. April 1933 in Zusammenhang, sah das deutsche Volk sich sogar gegen die „Presse der Welt“ „wehren“: Berichte über „deutsche Greuel“ und „deutsche Progrome [sic!] mit Massenopfern“ seien durch „ostjüdisch-kommunistische Zirkel von London und New York angezettelt“ worden. Es tauchten Unterscheidungen wie „alteingesessene deutsche Judenheit“ und „Ostjuden“ im Nazi-Jargon auf, wenige Monate nachdem ein Gesetz Mitte Juli 1933 16.000 sogenannten Ostjuden mit dem Entzug der Staatsbürgerschaft gedroht hatte. Am 7. Mai 1933 kommentierte Heuss in einem privaten Brief das Geschehen: „Einige der Leute, die auf der Liste stehen, sind ja menschlich keine schlechte Nachbarschaft, aber daneben findet sich auch das entwurzelte jüdische Literatentum, gegen das ich durch all die Jahre gekämpft habe.“ Es sei „weniger schön, mit diesen in die Geschichte einzugehen“. Andererseits half er zur selben Zeit der befreundeten deutsch-jüdischen Familie Gustav und Toni Stolper bei der Emigration.

Im Juli 1933 wurde ihm – wie auch den anderen Reichstagsabgeordneten der DStP – sein Abgeordnetenmandat aberkannt, weil er „auf Reichswahlvorschlag der SPD gewählt worden“ war (Verordnung zur Sicherung der Staatsführung vom 7. Juli 1933).

Heuss gab noch drei Jahre lang "Die Hilfe" heraus. 1936 erhielt er ein Publikationsverbot und verlor sein Lehramt. Karl Christian von Loesch beschäftigte Heuss ab 1936 an dem von ihm geleiteten Institut für Grenz- und Auslandsstudien (IGA). Später ernährte seine Frau durch Tätigkeiten in der Werbung die Familie. Sie gilt als Erfinderin des Jingle.
Sie produzierte auch Radiowerbung für Nivea, wo Heuss in einem Spot einen „Gastauftritt“ hatte.

1941 wurde Heuss fester Mitarbeiter der liberalen "Frankfurter Zeitung", in der er vor allem historische und kulturpolitische Aufsätze veröffentlichte. 1942 verbot das NS-Regime auf Anweisung Adolf Hitlers den deutschen Zeitungen, Texte von Heuss abzudrucken. Er schrieb aber weiter unter dem Pseudonym "Thomas Brackheim" und dem Kürzel "r.s." Unter eigenem vollem Verfassernamen veröffentlichte er einige Biographien: 1937 über den Politiker und Weggefährten Friedrich Naumann, 1939 über den Architekten Hans Poelzig (1869–1936), 1940 über den Zoologen Anton Dohrn (1840–1909) und 1942 über den Chemiker Justus von Liebig (1803–1873). Wegen der unerlaubten Veröffentlichung dieser Werke wurde 1941 von der Reichsschrifttumskammer eine Ordnungsstrafe in Höhe von 50 Reichsmark gegen Heuss verhängt, gegen die er sich aber erfolgreich zur Wehr setzte.

Zudem publizierte er biographische Artikel auch in anderen Tageszeitungen wie der "Potsdamer Tageszeitung".
Heuss schrieb während des Krieges bis 1941 auch für die NS-Wochenzeitung "Das Reich".

Er zog mit der Familie 1943 nach Heidelberg (wo er vor allem an einer Biographie über Robert Bosch arbeitete, um die Bosch ihn noch kurz vor seinem Tod gebeten hatte) und lebte dort bis 1945.

Nach dem Zweiten Weltkrieg wurde Theodor Heuss 1945 Lizenzträger (zusammen mit Rudolf Agricola und Hermann Knorr) der US-Militärregierung für eine der ersten Nachkriegszeitungen – die heute noch bestehende "Rhein-Neckar-Zeitung" (RNZ). Die amerikanische Militärregierung ernannte ihn am 24. September 1945 zum ersten Kultusminister Württemberg-Badens, in Württemberg-Baden verwendete man die Amtsbezeichnung „"Kult"minister“. Er trat in das Kabinett Maier I der Allparteienregierung (DVP, CDU, SPD, KPD) seines Parteifreundes Reinhold Maier ein. In den ersten Landtagswahlen im Spätherbst 1946 errangen die Liberalen 19 Prozent der Stimmen und konnten somit nur noch ein Regierungsmitglied stellen. Heuss, der für die von ihm mitgegründete Demokratische Volkspartei (DVP) in den Landtag gewählt worden war, verzichtete im Dezember zugunsten von Reinhold Maier auf das Amt des Kultministers, blieb aber wie seine Frau (die von 1946 bis 1949 Mitglied des Landtages von Württemberg-Baden war) zunächst für die "Demokratische Volkspartei" (DVP) und später für die "Freie Demokratische Partei" (FDP), die 1948 durch den Zusammenschluss nationalliberaler und linksliberaler Gruppen entstand, bis 1949 Abgeordneter im Landtag.

Zur Klärung der verschiedenen Motive beim Abstimmungsverhalten zum Ermächtigungsgesetz vom 24. März 1933 wurde im Frühjahr 1947 im württembergisch-badischen Landtag ein parlamentarischer Untersuchungsausschuss eingesetzt, den einige Landtagsabgeordnete beantragt hatten, die als Reichstagsabgeordnete dem Gesetz ebenfalls zugestimmt hatten. Heuss, Reinhold Maier und Hermann Dietrich sagten vor dem Untersuchungsausschuss aus. Die Aussagen sind in den stenografischen Berichten des württembergisch-badischen Landtages zu finden.

1946 und 1947 lehrte Heuss als Professor an der TH Stuttgart Geschichte, 1948 wurde er zum Honorarprofessor an der TH Stuttgart berufen.

Am 17. März 1947 wurde er gemeinsam mit Wilhelm Külz zum Vorsitzenden der Demokratischen Partei Deutschlands gewählt, diese gesamtdeutsche liberale Vereinigung scheiterte jedoch innerhalb eines Jahres. Auf dem Gründungsparteitag der "Freien Demokratischen Partei (FDP)", deren Ziel es war, die liberalen politischen Strömungen und Parteiverbände zumindest der westlichen Besatzungszonen zu bündeln, wurde Heuss dann am 12. Dezember 1948 zu deren Vorsitzendem gewählt. 1948 war er Mitglied des Parlamentarischen Rates, der das Grundgesetz für die Bundesrepublik Deutschland ausarbeitete und beschloss.

Das bei der Bundestagswahl 1949 gerade erworbene Mandat im ersten Deutschen Bundestag legte Heuss nieder, als er am 12. September 1949 gegen Kurt Schumacher von der Bundesversammlung ins höchste Staatsamt der Bundesrepublik Deutschland gewählt wurde (siehe Wahl des deutschen Bundespräsidenten 1949) und seinen vorläufigen Amtssitz auf der Viktorshöhe bezog.

Für Heuss war der 8. Mai 1945 „einer der furchtbarsten Tage der deutschen Geschichte“. Es ging ihm nach 1945 um eine „Entkrampfung der Deutschen“. Eine „Kollektivschuld“ wies er als „simple Vereinfachung“ zurück, bekannte sich aber zu einer „Kollektivscham“ wegen des Holocaust.

Ab den frühen 1950er Jahren beschäftigte sich der sehr gestaltungsaffine Heuss mit dem Thema Industriedesign und verteidigte Begriffe wie "deutsche Wertarbeit" und "Arbeitsfreude" gegen die Vereinnahmung durch Regime bzw. Propaganda in der NS-Zeit. Er erkannte als einer der ersten die Bedeutung von Design und Industriedesign für die exportorientierte deutsche Wirtschaft und initiierte eine staatliche Designförderung.

1959 wurde er mit dem Friedenspreis des Deutschen Buchhandels ausgezeichnet. Er ist Ehrenbürger der Städte Berlin, Bonn, Brackenheim, Darmstadt, Frankfurt am Main, Heilbronn, Kiel, Köln, Recklinghausen, Soest, Stuttgart und Trier.

Elly Heuss-Knapp teilte Heuss’ politische Ziele zeit ihres Lebens, so arbeitete die studierte Lehrerin u. a. im sozial-politischen Kreis der "Hilfe" mit. Wie er selbst kandidierte sie auch für politische Ämter, zunächst in der Weimarer Republik ebenfalls (allerdings im Gegensatz zu Heuss erfolglos) bei der DDP, später erfolgreich für die DVP bzw. FDP im württemberg-badischen Landtag. Zu Heuss’ Übernahme des Amts des Bundespräsidenten legte sie schweren Herzens ihr eigenes Mandat in Württemberg-Baden ab, um seine Arbeit besser unterstützen zu können. Noch 1950 gründete sie mit Antonie Nopitsch das Müttergenesungswerk, gerade zwei Jahre später jedoch, am 19. Juli 1952, starb sie und ließ Heuss als Witwer zurück.

Nach Ende seiner zweiten Amtszeit als Bundespräsident zog sich Heuss im September 1959 in seinen Altersruhesitz (heutiges Theodor-Heuss-Haus) auf dem Stuttgarter Killesberg zurück. Dort starb er am 12. Dezember 1963, nachdem er im August 1963 noch die Amputation seines linken Beins („Raucherbein“) überstanden hatte. Der Trauergottesdienst fand im Rahmen eines Staatsbegräbnisses am 17. Dezember 1963 in der Stiftskirche (Stuttgart) statt. Das Doppelgrab von Theodor Heuss und seiner Frau befindet sich auf dem Waldfriedhof Stuttgart.

Am 6. Februar 1952 übernahm er das Protektorat über die Schutzgemeinschaft Deutscher Wald (SDW) und brachte damit nicht nur als Staatsmann, sondern auch als Privatperson seine Verbundenheit mit dem Wald zum Ausdruck. Beim ersten deutschen „Tag des Baumes“ am 25. April 1952 pflanzte Heuss zusammen mit dem SDW-Präsidenten, Bundesinnenminister Robert Lehr, im Bonner Hofgarten einen Ahorn. 1953 gründete er die Deutsche Künstlerhilfe.

Bei der Wahl des deutschen Bundespräsidenten 1954 mit 88,2 Prozent Zustimmung im ersten Wahlgang wiedergewählt, blieb er bis zum 12. September 1959 im Amt. Eine dritte Amtszeit, die eine Änderung des Grundgesetzes erforderlich gemacht hätte, lehnte er 1959 ab.

Heuss prägte das Amt durch seine überparteiliche Amtsführung. Als Repräsentant der demokratisch-liberalen und kulturellen Traditionen Deutschlands vermochte er im In- und Ausland Vertrauen für die Nachkriegsrepublik zu gewinnen. Die Weltgemeinschaft hielt sich mit Kontakten zurück und lud auch den Bundespräsidenten nicht ein. Dies änderte sich mit einem Vorstoß Griechenlands: Ernst August von Hannover überbrachte Heuss die Einladung des griechischen Königs Paul, seines Schwagers. Der Staatsbesuch wurde ein großer Erfolg, tausende Athener gingen, um das Staatsoberhaupt zu begrüßen, zum Bahnhof, wo das Begrüßungszeremoniell stattfand. Bei seiner Rückkehr nach Deutschland bezeichnete Heuss die Reise als „Rückwanderung in die eigene geistige Heimat“. Der Außenminister Heinrich von Brentano nahm die euphorische Stimmung zum Anlass, bilaterale Abkommen im Bereich Kultur und Erziehung abzuschließen. Ausländische Botschafter blieben dem offiziellen Empfang demonstrativ fern, es folgte jedoch eine Einladung der Türkei, der sich Heuss wie zu Griechenland persönlich verbunden fühlte.

Heuss liebte es, seine Reden selbst zu schreiben; er beschäftigte keinen Redenschreiber. Im eigenen Lande wurde Heuss entsprechend authentisch empfunden und im Volksmund liebevoll "Papa Heuss" genannt.

Die Londoner "Times" schrieb anlässlich des Todes von Theodor Heuss’ Nachfolger Heinrich Lübke:

1951 stiftete Heuss den Verdienstorden der Bundesrepublik Deutschland mit seinen Stufen. 1952 erneuerte er den Orden Pour le Mérite und wurde sein Protektor.

Als neu gewählter Bundespräsident wollte Heuss eine neue Nationalhymne für die Bundesrepublik durchsetzen, was jedoch von Adenauer verhindert wurde. Das alte Deutschlandlied, argumentierte Heuss, sei infolge des Missbrauchs durch die Nazis für die neue Demokratie nicht mehr tragbar. Die erste Strophe passe nicht mehr in die geschichtliche Landschaft. Die zweite Strophe („Deutsche Frauen, deutsche Treue …“) sei schon „immer trivial gewesen, die dritte allein für sich zu wenig“. Doch gerade die dritte Strophe setzte Adenauer wieder als Nationalhymne durch – diesmal mit Zustimmung seines großen Widersachers, des SPD-Oppositionsführers Kurt Schumacher. Heuss stimmte schließlich zu, verzichtete aber darauf, die Hymne durch eine präsidiale Proklamation zu verkünden.


1964 wurde die nach ihm benannte "Theodor-Heuss-Stiftung" gegründet. Sie vergibt jährlich den "Theodor-Heuss-Preis" und die "Theodor-Heuss-Medaille" für bürgerschaftliche Initiative und Zivilcourage.

Die bundesunmittelbare "Stiftung Bundespräsident-Theodor-Heuss-Haus" wurde zur Förderung politischer Bildung und zeitgeschichtlicher Forschung ins Leben gerufen.

Das "Theodor-Heuss-Kolleg" ist ein Förderprogramm der Robert Bosch Stiftung für junge Menschen.

Die 1967 eröffnete Bildungsstätte der von Heuss mitgegründeten Friedrich-Naumann-Stiftung für die Freiheit in Gummersbach heißt "Theodor-Heuss-Akademie". Sie wurde mit Wissen von Heuss seit 1963 geplant und nach ihm benannt. Das dort angebaute Archiv des Liberalismus verfügt u. a. auch über Briefe und Dokumente von Heuss.

Heuss’ ehemaliges Wohnhaus auf dem Stuttgarter Killesberg am Rande der Feuerbacher Heide ist seit dem 7. März 2002 als Theodor-Heuss-Haus der Stiftung Bundespräsident-Theodor-Heuss-Haus ein der Öffentlichkeit zugängliches Museum. In seinem Geburtsort Brackenheim gibt es ein Theodor-Heuss-Museum.

Nach Heuss sind der Seenotrettungskreuzer "Theodor Heuss", das erste Fährschiff der Vogelfluglinie, ein VIP-Airbus der Flugbereitschaft des Bundesministeriums der Verteidigung, eine Kaserne der Bundeswehr in Stuttgart sowie zahlreiche Straßen, Plätze und Schulen in ganz Deutschland benannt.

Als in den 1950er Jahren die Kopfskulptur eines Obergaden-Wimpergs der gotischen Katharinenkirche in Oppenheim (Südseite) erneuert werden musste, gab man ihr die Gesichtszüge des damaligen Bundespräsidenten Theodor Heuss.

Bis zur Einführung des Euro am 1. Januar 2002 war sein Abbild auf einer Prägeausgabe des Zweimarkstücks zu sehen. Außerdem gab es zwei deutsche Briefmarkenserien: "Bundespräsident Theodor Heuss" (1954–1957) und "Heuss Medaillon" (1959). Anlässlich des 125. Geburtstages erschien 2009 eine 145-Eurocent-Briefmarke der Deutschen Post AG mit einem Fotoporträt von Heuss.







 


</doc>
<doc id="5076" url="https://de.wikipedia.org/wiki?curid=5076" title="Tübingen">
Tübingen

Tübingen (im schwäbischen Dialekt "Diebenga", amtlicher Name "Universitätsstadt Tübingen") ist eine Universitätsstadt im Zentrum von Baden-Württemberg. Sie liegt am Neckar rund 30 Kilometer südlich von Stuttgart. Die Stadt ist Sitz des Landkreises Tübingen sowie des gleichnamigen Regierungsbezirks und war von 1947 bis 1952 Landeshauptstadt von Württemberg-Hohenzollern. Sie gehört zur Region Neckar-Alb und zur europäischen Metropolregion Stuttgart. Gemeinsam mit der östlichen Nachbarstadt Reutlingen bildet sie eines der 14 Oberzentren des Landes. Seit dem 1. April 1956 ist Tübingen "Große Kreisstadt". Als zwölftgrößte Stadt Baden-Württembergs hat Tübingen etwa 87.000 Einwohner (Mai 2016) und besitzt von allen Städten Deutschlands den niedrigsten Altersdurchschnitt (39,1 Jahre am 31. Dezember 2015). Tübingen ist hinter Ludwigsburg und Esslingen am Neckar die drittgrößte Mittelstadt in Baden-Württemberg.

Mit der 1477 gegründeten Eberhard Karls Universität gehört die Stadt zu den ältesten deutschen Universitätsstädten. Das städtische Leben wird stark geprägt von den rund 26.900 Studenten (Stand: Sommersemester 2016).

Tübingen liegt im mittleren Neckartal zwischen Nordschwarzwald und Schwäbischer Alb. In Tübingen mündet der Goldersbach in die Ammer, die wie die Steinlach in den Neckar mündet. Im Zentrum der Stadt liegen der Schlossberg und der Österberg, an den Stadträndern befinden sich unter vielen anderen der Schnarrenberg, der 475 m hohe Spitzberg als Hausberg des Stadtteils Hirschau, der Herrlesberg und die Härten. Der niedrigste Punkt des Tübinger Stadtgebiets befindet sich mit im östlichen Neckartal, der höchste ist der Hornkopf im Schönbuch nördlich des Stadtteils Hagelloch mit 515,2 m Höhe. Im Norden Tübingens beginnt der Naturpark Schönbuch. Die Schwäbische Alb beginnt etwa 13 km (Luftlinie Tübingen Mitte zum Roßberg(turm) (869 m)) weiter südöstlich.

In Tübingen liegt in dem kleinen Wald "Elysium", unterhalb des Luise-Wetzel-Wegs in der Nähe des Botanischen Gartens auf , der geographische Landesmittelpunkt von Baden-Württemberg nach der Schwerpunkt-Berechnungsmethode. Ein drei Tonnen schwerer, kegelförmiger Stein aus dem Frankenjura symbolisiert diesen Punkt. Er hat eine Neigung von 11,5°; dies soll die Hälfte der Erdneigung darstellen.
Wird der geographische Landesmittelpunkt dagegen nach der Mittelungsmethode der jeweiligen Landes-Extrempunkte berechnet, liegt er in Böblingen.

Folgende Städte und Gemeinden grenzen an die Stadt Tübingen, im Uhrzeigersinn von Norden beginnend genannt:

Die Stadt Tübingen ist in 23 Stadtteile eingeteilt, darunter 10 sogenannte äußere Stadtteile. Von den letztgenannten sind acht erst bei der jüngsten Gemeindereform der 1970er Jahre eingegliedert worden und heute zugleich Ortschaften im Sinne der baden-württembergischen Gemeindeordnung. Das heißt, sie haben einen von den Wahlberechtigten bei jeder Kommunalwahl zu wählenden Ortschaftsrat mit einem Ortsvorsteher an der Spitze. Ferner gibt es jeweils eine Verwaltungsstelle. Die beiden bereits 1934 eingemeindeten Stadtteile Derendingen und Lustnau haben je einen Ortsbeirat und eine Geschäftsstelle der Stadtverwaltung. Sie sind in drei bzw. vier statistische Stadtteile untergliedert, die in der nachfolgenden Übersicht dahinter eingerückt genannt sind. Verwaltungs- und Geschäftsstellen sind quasi Stadtteil-Rathäuser, bei denen man die wichtigsten städtischen Angelegenheiten erledigen kann.

Innerhalb einiger Stadtteile gibt es teilweise weitere Stadtviertel, die sich im Laufe der Zeit ergeben haben. Dabei handelt es sich meist um Neubausiedlungen oder Wohngebiete, deren Grenzen durchaus auch fließend sein können. Jeder Stadtteil und dessen Untergliederungen tragen für statistische Zwecke eine dreistellige Nummer.

Tübingen liegt im Süden des "Verdichtungsraums Stuttgart" (Umfang siehe unter Stuttgart). Die Stadt bildet mit der Nachbarstadt Reutlingen das Oberzentrum der Region Neckar-Alb, dem folgende Mittelzentren zugeordnet sind:


Für folgende Städte und Gemeinden des Landkreises übernimmt Tübingen auch die Aufgaben des Mittelbereichs:


Der oberflächennahe geologische Untergrund Tübingens wird überwiegend von den Gesteinen der Mittleren Keuper (km) gebildet. Auf die steilen Keuperhänge folgen Schichtflächen, die von den Tonsteinen des Schwarzen Jura (Lias α1) gebildet werden. Die Schichtflächen liegen zwischen 440 und und weisen meist eine gering mächtige Löss-Überdeckung auf, die während der Kaltzeiten dort abgelagert wurde.

Folgende Schichtenabfolge ist aufgeschlossen:


Die von Alluvium, Stubensandstein und Lias α gebildeten Verebnungen haben eine wichtige Bedeutung als stabiler Baugrund und auch für die Anlage große Flächen in Anspruch nehmender Gebäude. Universität und Gewerbe wurden auf der alluvialen Schwemmlandebene angesiedelt. Neue Kliniken, der Stadtteil "Waldhäuser Ost" und die Naturwissenschaftlichen Fakultäten auf der Morgenstelle entstanden auf Stubensandstein und Lias α.

Hinderlich für die Bebauung und deshalb die bauliche Entwicklung hemmend ist der Knollenmergel. Deswegen sind beispielsweise der Nordhang des Österbergs sowie der Steinenberg frei von Bebauung.

Ca. 5 km nördlich von Tübingen befindet sich ein geologischer Lehrpfad am Kirnberg (Schönbuch), bei dem die Keuperschichten auf mehreren Schautafeln erläutert werden. Der Lehrpfad Kirnberg liefert einen guten geologischen Überblick zur Tübinger Geologie.

1831 wurde für den Bau des neuen Anatomiegebäudes (Österbergstraße 3) eine rund 70 m tiefe Brunnenbohrung zur Wasserversorgung abgeteuft, die auch wissenschaftlich beschrieben wurde und eine der ältesten geologischen Keuper-Profile von Süddeutschland darstellt.

Das Tübinger Klima bewegt sich etwa im Durchschnitt Baden-Württembergs. Die mittlere Jahrestemperatur beträgt 9,0 °C und liegt damit ungefähr in der Mitte zwischen den Werten der klimatisch begünstigten Städte im Rheintal (z. B. Karlsruhe: 10,5 °C) und den kalten Orten auf den Hochflächen (z. B. Villingen-Schwenningen: 6,7 °C). Auch die im langjährigen Mittel gemessene jährliche Niederschlagsmenge von 741 mm liegt etwa im Durchschnitt der Werte anderer Städte in Baden-Württemberg (z. B. Stuttgart: 679 mm / Freiburg im Breisgau: 954 mm).

Der regelmäßig wärmste Monat in Tübingen ist der Juli mit einer Durchschnittstemperatur von 18 °C, der kälteste der Januar mit einem Durchschnitt von −0,7 °C. Mit mittleren 101 mm fällt der meiste Regen im Juni. Die regenärmsten Monate sind der März und der Dezember mit einem langjährigen Durchschnitt von 39 mm.

Das Stadtklima ist stark durch die zahlreichen Erhebungen geprägt. So ist es im Winter keine Seltenheit, dass die am Neckar gelegenen Stadtteile völlig schneefrei sind, während die Höhenlagen eine geschlossene Schneedecke aufweisen. Auch die Lage der Hänge hat klimatische Auswirkungen. So ist beispielsweise der Südhang des Spitzbergs ausgesprochen warm und artenreich, während die Nordseite wesentlich kälter ist und nur einen Bruchteil der biologischen Vielfalt der Südseite aufweisen kann.

Die Region um die Stadt Tübingen ist spätestens seit dem Magdalénien, dem jüngsten Abschnitt des Jungpaläolithikums, von eiszeitlichen Jägern und Sammlern aufgesucht worden. Im Folgenden lässt sich in Form von Werkzeugfunden, Bestattungen, Hausgrundrissen oder Siedlungsresten in nahezu alle prähistorischen Epochen die Anwesenheit von Menschen nachweisen, z. B. die der Bandkeramischen, der Rössener, der Schnurkeramischen und auch der Großgartacher Kultur. Die Bronzezeit ist in Tübingen u. a. durch den sensationellen Fund des „Menhirs von Weilheim“ vertreten. Aus der älteren Eisenzeit sind auf dem Stadtgebiet Tübingens zahlreiche Grabhügel der Hallstattzeit bekannt, wie etwa der Grabhügel von Tübingen-Kilchberg. Aus der Zeit um 85 n. Chr. stammen Spuren der Römer, die etwas weiter nordöstlich den Neckar-Limes errichteten. Im Zusammenhang mit der Belagerung von „castrum twingia“ (Zwingburg) durch König Heinrich IV. wird Schloss Hohentübingen 1078 zum ersten Mal urkundlich erwähnt.
Es ist von einer ländlichen Vorgängersiedlung auszugehen, die im Bereich des hochwassersicheren Sattels zwischen Schloss- und Österberg zu verorten ist. Darauf gibt allein schon der Ortsname den Hinweis: der Name des Ortsgründers "Tuwo" in der Vorsilbe und die Namensendung auf -ing(en) deuten auf Gründung während der Völkerwanderungszeit hin. Die Tübinger Unterstadt hat dort ihren Ursprung. Die Oberstadt entstand erst später als Erweiterung der Burgmannensiedlung unterhalb der Burg.

Aus dem Jahre 1191 stammt die erste Erwähnung von Kaufleuten, was als Beweis für einen Marktplatz gilt. Mitte des 11. Jahrhunderts gehört das Gebiet um Tübingen den Grafen von Zollern. Stadtrechte werden 1231 zum ersten Mal genannt. Im Jahre 1262 gründete Papst Alexander IV. ein Augustiner-Eremitenkloster, mit einem Franziskanerkloster folgte das zweite Kloster in Tübingen, gegründet mit Unterstützung des Pfalzgrafen Heinrich von Tübingen, genau zehn Jahre später. Im 13. Jahrhundert erhielt Tübingen eine Lateinschule, die spätere Schola anatolica. 1342 gelangen Burg und Stadt an die Grafen von Württemberg. Die Stadt wurde kurz darauf Sitz eines Amtes.

Mit der Verlegung des Sindelfinger Martinsstiftes nach Tübingen 1476 wurde ein Kollegiatstift gegründet, das die wirtschaftlichen und personellen Voraussetzungen für die Gründung einer Universität bot. Die Pfarrkirche St. Georg wurde zur Stiftskirche. Die Gründung der Eberhard Karls Universität erfolgte ein Jahr darauf.

Am 8. Juli 1514 wurde der Tübinger Vertrag, der als wichtigstes Verfassungsdokument des Herzogtums Württemberg gilt, geschlossen. Als Ort des Vertragsabschlusses darf Tübingen seither die württembergischen Geweihstangen in seinem Wappen führen. Mit der Einführung der Reformation endete zwischen 1534 und 1535 die Geschichte der Klöster der Stadt. 1535 nahm Leonhart Fuchs einen Ruf an die Universität an, ein Jahr später wurde von Herzog Ulrich von Württemberg als Stipendium für evangelische Theologiestudenten das Evangelische Stift Tübingen gegründet, das 1547 in das ehemalige Augustinereremiten-Kloster einzog.

Zwischen 1622 und 1625 besetzte nach der Schlacht bei Wimpfen am 6. Mai die Katholische Liga das evangelische Herzogtum Württemberg. 1629 trat dann das Restitutionsedikt in Kraft. Während des „Kirschenkriegs“ vom 28. Juni bis 11. Juli wurde Tübingen geplündert. Nach der Schlacht bei Nördlingen übergab der Kommandant Johann Georg von Tübingen im September 1634 das von 70 Bürgern besetzte Schloss Hohentübingen kampflos an die kaiserlichen Truppen. Immerhin wurde Tübingen dank des Engagements eines Tübinger Bürgersohns, der als (evangelischer) Rittmeister im Fürstenbergischen Regiment in kaiserlichen Diensten stand, nicht geplündert. Tübingen war anschließend meist von bayerischen Truppen besetzt.

In den Jahren 1635 und 1636 starben 1485 Menschen in der Stadt an der Pest. Zwei Jahre später fiel die schwedische Armee in Tübingen ein. Kurz vor Ende des Dreißigjährigen Krieges wurde Schloss Hohentübingen 1647 von den Franzosen belagert (Belagerung von Schloss Hohentübingen). Am 14. März wurde der Südostturm mit Hilfe einer Mine gesprengt. Die bayerische Besatzung gab auf und erhielt ehrenvollen Abzug. Die Franzosen blieben bis 1649 in Tübingen.

Bei einem Stadtbrand im Jahre 1771 wurden Teile der westlichen Altstadt um die Ammergasse zerstört. Ein weiterer Stadtbrand traf 1789 Teile der östlichen Altstadt im Bereich der heutigen Neuen Straße. Sie wurde auf begradigten Grundrissen im klassizistischen Stil wieder aufgebaut. 1798 gründete Johann Friedrich Cotta, der Verleger deutscher Klassiker wie Goethe und Schiller, in Tübingen die Allgemeine Zeitung, die in den folgenden Jahren zur führenden politischen Tageszeitung Deutschlands werden sollte.

Von 1807 bis 1843 lebte Friedrich Hölderlin in Pflege im Hölderlinturm am Neckar. Ab Anfang des 19. Jahrhunderts wuchs die Stadt erstmals nennenswert über die mittelalterlichen Grenzen hinaus mit der rechtwinkligen Wilhelmsvorstadt an der Neuen Aula und dem Botanischen Garten. Im sogenannten Gôgenaufstand von 1831 zogen etwa 60 Handwerksburschen und Weingärtner als Protest gegen Polizeiwillkür durch die Stadt und sangen das Schiller’sche Räuberlied. Die lokale Obrigkeit richtete einen Hilferuf an die offiziell nicht bestehenden und verbotenen Studentenverbindungen, und bewaffnete studentische Sicherheitswachen wurden gegen die Aufständischen eingesetzt. Beim Tübinger Brotkrawall von 1847 wurde ein aus etwa 150 Studenten bestehendes akademisches Sicherheits-Corps der Universität Tübingen unter der Führung von Carl Heinrich Ludwig Hoffmann aus den Arsenalen der Universität bewaffnet. Das Sicherheitscorps beendete die Unruhen, indem es entschlossen gegen die sozialen Interessen der armen Bevölkerungsschichten antrat.

Ab 1873 ist Tübingen Militärstandort, südlich der Stadt wird eine Infanterie-Kaserne eingerichtet, in der das 10. Württembergische Infanterieregiment Nr. 180 stationiert wird. Im Jahr 1938 erhält die Kaserne den Namen "Thiepval-Kaserne", benannt nach dem in der französischen Provinz Picardie gelegenen Weiler Thiepval, wo während der Sommeschlacht im September 1916 Soldaten dieses Regimentes kämpften. Eine Tafel an der Kasernenmauer erinnert daran. Bei einem französischen Luftangriff im Ersten Weltkrieg wurden 16 Häuser beschädigt. Von 1914 bis 1916 wird eine zweite Kaserne errichtet, die zunächst als "Neue Kaserne" bezeichnet wird und ebenfalls 1938 zur Erinnerung an die Lorettoschlacht den Namen "Loretto-Kaserne" erhält. 1935 wird eine dritte Kaserne eröffnet, die 1938 von "Burgholzkaserne" in "Hindenburg-Kaserne" umbenannt wird.

Durch die Deutsche Gemeindeordnung wurde Tübingen 1935 zum Stadtkreis erklärt, blieb aber innerhalb des Landkreises Tübingen, dessen Gebiet 1938 erheblich vergrößert wurde. 1933 bis 1943 bestand in Tübingen eine Außendienststelle der Gestapo. Beim Novemberpogrom 1938 wurde die Synagoge in der "Gartenstraße 35–37" von SA-Männern niedergebrannt. An 14 jüdische Opfer der Shoa erinnert heute ein Gedenkstein auf dem Jüdischen Friedhof nördlich der B 28 Richtung Wankheim. Der jüdischen Opfer der NS-Diktatur wird auch an der Mauer zur Stiftskirchenseite auf dem "Holzmarkt" seit 1983 mit einer Gedenktafel gedacht, ebenso seit 2000 mit dem Denkmal Synagogenplatz an der Gartenstraße. 

Am 19. April 1945 endete für Tübingen der Zweite Weltkrieg. Drei Luftangriffe hatten 82 Häuser völlig zerstört, 104 schwer und 607 leicht beschädigt. Tübingen wurde durch Luftangriffe insgesamt zu 5% zerstört. Durch die Initiative des Standortarztes Theodor Dobler wurde die Stadt kampflos an die französischen Truppen übergeben.
1946 wurde Tübingen Hauptstadt des Landes – ab 1949: Bundeslandes – Württemberg-Hohenzollern, bis dieses im neuen Land Baden-Württemberg aufging. Die Stadt wurde „unmittelbare Kreisstadt“. 1952 wurde Tübingen Sitz des Regierungsbezirks Südwürttemberg-Hohenzollern, der bei der Kreisreform zum 1. Januar 1973 in den Regierungsbezirk Tübingen überführt wurde. 1956 erhielt Tübingen die Bezeichnung Große Kreisstadt.
1965 wurde Tübingen mit dem Europapreis für hervorragende Bemühungen um den europäischen Integrationsgedanken ausgezeichnet.
Durch die Eingliederung von acht Gemeinden erreichte das Stadtgebiet zwischen 1971 und 1974 seine heutige Ausdehnung. Bei der 1973 durchgeführten Kreisreform erhielt der Landkreis Tübingen ebenfalls seine heutige Ausdehnung.

Bis in die 1990er Jahre blieb Tübingen französische Garnisonsstadt. Die französischen Soldaten prägten das Stadtbild mit. Außer den drei Tübinger Kasernen nutzte die französische Garnison zahlreiche Wohngebäude, insbesondere in der Südstadt.

2015 wurde Tübingen der Ehrentitel „Reformationsstadt Europas“ durch die Gemeinschaft Evangelischer Kirchen in Europa verliehen.

Die Orte, die als Folge der Eingemeindung in den 1970er Jahren eine Ortschaftsverfassung mit eigenem Ortschaftsrat und Ortsvorsteher haben, werden als "Ortschaft" bezeichnet, sind aber laut Hauptsatzung der Stadt ebenso "Stadtteile" wie die früher eingemeindeten Stadtteile. Ferner gibt es noch einen "Wohnplatz", der nie eine selbständige Gemeinde war.












In die Stadt Tübingen wurden folgende Gemeinden und Gemarkungen eingegliedert:


Im Mittelalter und der frühen Neuzeit hatte Tübingen wenige tausend Einwohner. Die Bevölkerung wuchs langsam und ging durch die zahlreichen Kriege, Seuchen und Hungersnöte immer wieder zurück. So forderten Pestepidemien 1348 und während des Dreißigjährigen Krieges in den Jahren 1634 und 1635 zahlreiche Todesopfer. Erst mit dem Beginn der Industrialisierung im 19. Jahrhundert beschleunigte sich das Bevölkerungswachstum. Lebten 1818 erst 7.500 Menschen in der Stadt, so waren es 1900 bereits 15.000. Bis 1939 verdoppelte sich die Einwohnerzahl auf 30.000. Durch die Eingemeindung von acht kleineren Nachbargemeinden Anfang der 1970er Jahre wuchs die Bevölkerung von 55.000 im Jahre 1970 auf 70.000 im Jahre 1973. Am 31. Dezember 2008 betrug die „Amtliche Einwohnerzahl“ für Tübingen nach Fortschreibung des Statistischen Landesamtes Baden-Württemberg 85.344. Seit 2009 wird auch in Tübingen eine Zweitwohnungsteuer erhoben. Der Steuersatz beträgt seit dem Jahr 2012 10 % der Jahreskaltmiete. Innerhalb eines Jahres hat sich deshalb die Zahl der Personen mit Hauptwohnung um ca. 3000 Personen erhöht. OB Boris Palmer (GRÜNE) strebt mittelfristig eine Einwohnerzahl von 100.000 an. Nachdem sich durch ZENSUS 2011 die Einwohnerzahl Tübingens um 6,5 Prozent auf rd. 85.000 verringert hat, dürfte dieses Ziel in naher Zukunft schwer zu erreichen sein. Zu diesem Zweck verfolgt die Stadt die Politik, Baulücken zu schließen. Sie will damit auch einer immer stärkeren Zersiedelung entgegenwirken.

Tübingen gehörte zunächst zum Bistum Konstanz und war dem Archidiakonat „vor dem Wald“ (Kapitel Sülchen) zugeordnet. Infolge der Zugehörigkeit zum Herzogtum Württemberg wurde hier, wie im übrigen Württemberg, ab 1535 die Reformation eingeführt. Die in der Stadt tätigen Reformatoren waren Ambrosius Blarer und Balthasar Käuffelin. Danach war Tübingen über viele Jahrhunderte eine überwiegend protestantische Stadt. 1559 trat die große Kirchenordnung in Kraft. Tübingen wurde auch bald Sitz eines Dekanats (siehe Kirchenbezirk Tübingen) innerhalb der Württembergischen Landeskirche, das zunächst zur Generalsuperintendentur Bebenhausen gehörte. Ab 1692 gab es ein Dekanat Lustnau. 1806 wurde Tübingen Sitz einer eigenen Generalsuperintendentur. Seit 1911 gehört das Dekanat Tübingen zur Prälatur Reutlingen.

Die evangelische Hauptkirche Tübingens ist die Stiftskirche, die wohl aus einer um 1188 erwähnten Kapelle hervorging. Die St. Georg, später St. Georg und Maria geweihte Kirche wurde 1476 zur Stiftskirche erhoben, nachdem das Chorherrenstift Sindelfingen an die Tübinger Pfarrkirche übertragen worden war. Die heutige Kirche wurde ab 1470 errichtet. Der Turm stammt von der Vorgängerkirche. Die zweite alte Kirche der Stadt ist die 1337 erstmals erwähnte Jakobuskirche. Auch sie war ursprünglich eine Kapelle, die nach der Reformation mit dem Spital verbunden wurde. Die im Kern romanische Kirche wurde im 16. Jahrhundert gotisch umgestaltet. An ihr wurde 1910 eine Pfarrei errichtet. Weitere evangelische Kirchen sind die Eberhardkirche aus dem Jahr 1911 (Pfarrei ab 1911), die Martinskirche von 1955 (Pfarrei ab 1957), die Stephanuskirche von 1968 (Pfarrei ab 1965), die Albert-Schweitzer-Kirche und die Dietrich-Bonhoeffer-Kirche, die zwischen 1983 und 1985 erbaut wurde. Diese sieben Kirchengemeinden der Kernstadt Tübingen bilden die Evangelische Gesamtkirchengemeinde Tübingen.

Aus dem im 13. Jahrhundert gegründeten Augustinerkloster ging nach der Reformation das Evangelische Stift hervor. Das um 1272 gegründete Franziskanerkloster wurde nach der Reformation in das Collegium Illustre umgewandelt. Hier zog 1817 das katholische theologische Seminar aus Ellwangen ein. Seither wird es als Wilhelmsstift bezeichnet.

Mit Ausnahme von Bühl und Hirschau wurde in den Stadtteilen Tübingens infolge der überwiegenden Zugehörigkeit zu Württemberg ebenfalls die Reformation eingeführt. Daher gibt es dort bis heute meist auch eine evangelische Kirchengemeinde oder zumindest eine evangelische Kirche. Derendingen hatte bereits um 1189 eine Kapelle. Die heutige Kirche wurde 1514 erbaut. Die evangelische Kirche Hagelloch wurde 1904 im neoromanischen Stil erbaut. Eine Pfarrei gab es in Hagelloch jedoch bereits seit 1545. In Kilchberg wurde die Reformation durch Georg II. von Ehingen eingeführt. Die Pfarrkirche in Kilchberg hat verschiedene Bauphasen. Der älteste Teil ist wohl romanisch. Zur Gemeinde Kilchberg gehören auch die Protestanten in Bühl. Die Kirche St. Martin in Lustnau wurde Ende des 15. Jahrhunderts erbaut, doch gab es bereits im 12. Jahrhundert eine Kirche und Pfarrei. Von der Pfarrei Lustnau wird auch die Kirchengemeinde Bebenhausen betreut. Doch hat die Gemeinde mit der ehemaligen Klosterkirche auch eine eigene Kirche. Pfrondorf war zunächst eine Filiale von Lustnau. 1833 erhielt der Ort eine eigene Pfarrei und auch eine eigene Kirche. Unterjesingen hatte schon im 11. Jahrhundert eine Pfarrei und eine der Hl. Barbara geweihte Kirche aus dem 14. Jahrhundert. Die heutige Kirche wurde 1470 bis 1494 erbaut. In Weilheim gab es eine dem Hl. Nikomedes geweihte Kirche. Die heutige Kirche wurde 1499 bis 1521 im spätgotischen Stil erbaut. Zur Gemeinde gehören auch die Protestanten aus Hirschau. Alle genannten Kirchengemeinden gehören ebenfalls zum Dekanat Tübingen der Evangelischen Landeskirche in Württemberg.

Bereits 1750 errichtete das Kloster Marchtal im Weiler Ammern eine katholische Gemeinde, die 1806 aufgehoben wurde, als die katholische Stadtkirchengemeinde Tübingen gegründet wurde. Die Gottesdienste wurden zunächst in der Jakobuskirche – der ehemaligen Spitalkirche – gehalten. Der Direktor des Wilhelmsstifts war ab 1817 zugleich katholischer Stadtpfarrer. 1818 konnte die Gemeinde ihr eigenes Gotteshaus, die Kirche St. Wilhelm in der Nähe des Wilhelmsstifts bauen. Die 1806 gegründete Gemeinde gehörte zunächst noch zum Bistum Konstanz, dann ab 1808 zum Generalvikariat Ellwangen und ab 1821 zum neu gegründeten Bistum Rottenburg (heute Diözese Rottenburg-Stuttgart). Die heutige Tübinger Pfarrkirche St. Johannes Evangelist wurde 1875 bis 1878 erbaut. Nach dem Zweiten Weltkrieg entstanden weitere katholische Gemeinden und Kirchen in Tübingen und zwar St. Michael (1949, Pfarrei ab 1958) und St. Paulus (1974, Pfarrei ab 1975). Ein Klinikkirche wurde 1961 gebaut, wo eine Pfarrei bereits 1896 errichtet worden war. Das Hochschulpfarramt wurde 1933 errichtet. Zur Gemeinde St. Johannes Evangelist gehören auch die Katholiken aus Hagelloch und Unterjesingen. Die Katholiken aus Weilheim werden von der Gemeinde St. Michael betreut.

Im Stadtteil Bühl wurde 1275 eine Kirche und Pfarrei genannt. Da Bühl über verschiedene Herrschaften schließlich unter die Oberhoheit Österreichs gelangte, blieb der Ort katholisch. Dennoch wurde durch Georg II. von Ehingen und David vom Stain im 16. Jahrhundert vorübergehend die Reformation eingeführt, doch 1609 wieder rückgängig gemacht. Die heutige Pfarrkirche St. Pankratius in Bühl wurde 1902 erbaut, der Turm stammt noch vom Vorgängerbau 1599. Zur Gemeinde gehören auch die Katholiken aus Kilchberg. Die Einwohner aus Hirschau gehörten zunächst zur Pfarrei Sülchen bei Rottenburg, teilweise auch zu Wurmlingen. 1461 wurde die Kapelle St. Ägidius in Hirschau zur Pfarrei erhoben. Die heutige Kirche St. Ägidius ist im Kern gotisch, wurde aber zwischen 1851 und 1852 überwiegend neu erbaut. In Lustnau wurde 1956 die Kirche St. Petrus erbaut und 1961 zur Pfarrei erhoben. Dazu gehören auch die Katholiken aus Pfrondorf. Alle katholischen Kirchengemeinden im Tübinger Stadtgebiet gehören heute zum Dekanat Rottenburg des Bistums Rottenburg-Stuttgart.

Neben den beiden großen Kirchen gibt es in Tübingen auch eine Griechisch-orthodoxe Gemeinde sowie Freikirchen, darunter die Evangelisch-methodistische Kirche (Friedenskirche), eine Evangelisch-Freikirchliche Gemeinde (Baptisten – Kreuzkirche), die TOS-Gemeinde Tübingen, eine Freie Christliche Gemeinde, eine Selbständige Evangelisch-Lutherische Gemeinde (Philippus-Gemeinde), eine Adventgemeinde (Siebenten-Tags-Adventisten) und eine Freikirchliche Pfingstgemeinde (Arche). Auch die Neuapostolische Kirche, die Kirche Jesu Christi der Heiligen der Letzten Tage und die Christengemeinschaft sind in Tübingen vertreten.

Es existieren drei Moscheen in Tübingen:


Seit dem Wintersemester 2011/2012 besteht das Zentrum für Islamische Theologie, das zur Universität Tübingen gehört.

Die Tübinger Buddhisten sind in mehreren Gruppierungen organisiert, die verschiedenen Traditionen des Buddhismus angehören:

In Tübingen ist seit etwa 1300 ein Rat und ein Gericht nachweisbar, wobei der Rat das Gericht einschloss. Beide Gremien vertraten die Bürgerschaft gegenüber der Herrschaft. Nach dem Übergang an Württemberg gab es zunächst nur ein Gericht. Ein Rat wurde erst wieder 1477 eingerichtet, doch hatte er völlig andere Aufgaben. Im 16. Jahrhundert wurden beide Gremien auch als „Magistrat“ bezeichnet.

Ursprünglich war es die Aufgabe der jeweils bis zu zwei gleichzeitig amtierenden Bürgermeister, die Steuern einzuziehen und das städtische Rechnungswesen zu führen, das städtische Bauwesen zu beaufsichtigen, sowie den Verlauf der Ammer außerhalb der Stadt unter Kontrolle zu halten. Ab Mitte des 16. Jahrhunderts wuchsen die Aufgaben und die Bedeutung der Bürgermeister stetig an. Ihre Zahl erhöhte sich um 1600 auf vier. Das entsprach einem Viertel des Tübinger Gerichtspersonals. Sie waren auf Lebzeiten im Amt, aber es führten nur jeweils die zwei „rechnenden Bürgermeister“ die Amtsgeschäfte. Als Landschafts-Abgeordnete spielten die Bürgermeister darüber hinaus in der Landespolitik eine wichtige Rolle.

Im 16. Jahrhundert standen dem Amtsbürgermeister nur 30 fl. Fixum zu. Vom Steuereinzug empfing er zusätzlich 25 Pfund Heller und von der Frucht-Verwaltung 5 Pfund Heller. Am 24. Dezember 1674 entschied Herzog Wilhelm Ludwig, der Amtsbürgermeister solle in Zukunft 50 fl. aus der Stadtkasse beziehen, die andern Gerichts-Verwandten und Bürgermeister aber 24 fl. jährlich. Dafür musste die Stadt aber 12 Geldgulden als Taxe zur fürstlichen Kanzlei zahlen. Der Amtsbürgermeister erhielt laut fürstlicher Resolution von 1710 außer dem Wartgeld und dem gesetzlichen Zählgeld jährlich eine fixe Besoldung von 150 fl. Er durfte auch seit 1749 das Zwingergärtchen am Schmiedtor nutzen.

Mit der Einführung der württembergischen Gemeindeverfassung 1819 gab es keinen Unterschied mehr zwischen Gericht und Rat. Das Gremium wurde nunmehr als Stadtrat bezeichnet. Das Stadtoberhaupt hieß zunächst Oberbürgermeister, ab 1823 Stadtschultheiß und ab 1903 erneut Oberbürgermeister. Dieser wird heute von den Bürgern für eine Amtszeit von acht Jahren direkt gewählt. Er ist Vorsitzender des Gemeinderats und Leiter der Verwaltung. Seine allgemeinen Stellvertreter sind der Erste Beigeordnete mit der Amtsbezeichnung „Erster Bürgermeister“ sowie der Zweite Beigeordnete mit der Amtsbezeichnung „Bürgermeister“.

Bei der Wahl des Oberbürgermeisters am 22. Oktober 2006 wurde bei einer Wahlbeteiligung von 51,6 % Boris Palmer (Bündnis 90/Die Grünen) mit 50,4 % der Stimmen im ersten Wahlgang zum neuen Oberbürgermeister gewählt und setzte sich dabei unter anderem gegen die Amtsinhaberin Brigitte Russ-Scherer (SPD, 30,2 %) und Hans-Jörg Stemmler (CDU, 11,9 %) durch. Er hat sein Amt am 11. Januar 2007 angetreten.

Bei der Wahl des Oberbürgermeisters am 19. Oktober 2014 wurde bei einer Wahlbeteiligung von 55,0 % Amtsinhaber Boris Palmer (Bündnis 90/Die Grünen) mit 61,7 % der Stimmen im ersten Wahlgang im Amt bestätigt. Die von CDU und FDP unterstützte Herausforderin Beatrice Soltys kam auf 33,2 %.

Der Gemeinderat besteht aus dem Oberbürgermeister als Vorsitzendem und 40 ehrenamtlich tätigen Stadträtinnen und Stadträten. Das Gremium legt die Ziele und die Rahmenbedingungen des kommunalpolitischen Handelns fest und entscheidet über alle wichtigen Gemeindeangelegenheiten, soweit nicht der Oberbürgermeister Kraft Gesetzes zuständig ist oder ihm der Gemeinderat bestimmte Aufgaben übertragen hat.

Der Gemeinderat wird alle fünf Jahre direkt gewählt. Die letzte Kommunalwahl fand am 25. Mai 2014 statt.

Im Jahr 1999 wurde zum ersten Mal der Tübinger Jugendgemeinderat gewählt. Er besteht aus 20 Mitgliedern und wird alle zwei Jahre von allen 12- bis unter 19-Jährigen im Tübinger Stadtgebiet gewählt. Mitglieder dürfen zum Wahlzeitpunkt nicht älter als 18 Jahre sein. Wie andere Jugendgemeinderäte arbeitet er mit dem Oberbürgermeister zusammen. Eine Besonderheit des Jugendgemeinderat ist, dass er neben einem Rede- und Anhörungsrecht auch über ein Antragsrecht im Gemeinderat verfügt. Seit 2002 wird jährlich der Lilli-Zapf-Jugendpreis vom Jugendgemeinderat zusammen mit dem Verein Courage e. V. im Bereich Zivilcourage und Soziales verliehen.

Das Wappen der Stadt Tübingen zeigt in Gold an drei roten Trageringen die dreilatzige rote Fahne der Pfalzgrafen. Auf dem Schild zwei schräg gekreuzte, mit roten, golden geschlitzten Puffärmeln bekleidete Männerarme, die zwei mit Spitzen aufwärts zeigende Hirschstangen halten. Die Stadtflagge ist rot-gelb.

Das älteste Siegel der Stadt stammt aus dem Jahr 1272 und zeigt bereits die Fahne der Pfalzgrafen, die auch in den Wappen von Böblingen und Herrenberg abgebildet ist. Auch nachdem die Stadt württembergisch wurde, blieb das Wappensymbol erhalten. Doch verlieh Herzog Ulrich von Württemberg am 18. August 1514 als besonderes Ehrenzeichen für die Treue der Stadt beim Aufstand des Armen Konrad das so genannte Oberwappen, die Hirschstangen mit den beiden Landsknechtarmen.

Tübingen unterhält mit folgenden Städten eine Städtepartnerschaft:


Auch einige Stadtteile von Tübingen haben Partnergemeinden:


Die Wirtschaft Tübingens ist stark vom öffentlichen Dienst geprägt. Größte Arbeitgeber sind die Universität und das Klinikum mit zusammen über 12.000 Beschäftigten. Die rund 30 Behörden in Tübingen beschäftigen etwa 2.500 Arbeitnehmer. Insgesamt arbeiten circa 40.400 sozialversicherungspflichtig Beschäftigte in Tübingen. Dazu kommen noch die in Tübingen tätigen Beamten und Selbstständigen. Fast 24.000 der sozialversicherungspflichtig Beschäftigten pendeln nach Tübingen ein, etwa 10.000 Tübinger arbeiten auswärts. Bei der Agentur für Arbeit waren in den 2000er-Jahren bis zu 2.843 Bürger arbeitslos gemeldet, darunter etwa ein Drittel länger als zwölf Monate. Im Juni 2012 erreichte die Zahl der Arbeitslosen den langjährigen Tiefststand von 1.317 Menschen. Bis zum August 2015 stieg sie auf 1.661 Arbeitslose, im Dezember 2015 waren 1.489 arbeitslos gemeldet.

Im Gegensatz zu vielen anderen Städten Württembergs war Tübingen nie ein namhafter Industriestandort. Heute verfügt die Stadt nur noch über drei größere industrielle Arbeitgeber - die Walter AG, die Hugo Brennenstuhl GmbH & Co. KG sowie die CHT/BEZEMA-Gruppe. Daneben gibt es eine Reihe von kleineren Unternehmen im Maschinenbau, in der Medizintechnik und der Textilbranche. Ausgehend von den Forschungsinstituten der Universität kamen in den letzten Jahren einige Unternehmen in den Bereichen Informations-, Bio- und Nanotechnologie hinzu, einige davon sind auf der Oberen Viehweide im Technologiepark Tübingen-Reutlingen ansässig, Deutschlands größtem Gründerzentrum für Biotechnologie, beispielsweise immatics und CureVac. Viele alteingesessene Handwerksbetriebe haben sich in der Weststadt im Handwerkerpark zusammengeschlossen.

Bis in die 1990er Jahre hinein bestanden noch drei weitere größere Industrieunternehmen, die zusammen mehrere tausend Arbeitnehmer beschäftigen. Namentlich waren dies die Württembergische Frottierweberei Lustnau (Insolvenz 1992), der Haushaltsgerätehersteller Zanker (Auflösung 1993) und die Beka-Werke, in denen bis 1999 Küchenartikel hergestellt wurden. Die historisch geringe Industrialisierung Tübingens und die damit einhergehende geringe Bedeutung Tübingens für die Rüstungsproduktion im Zweiten Weltkrieg war mit ein Grund, warum die Stadt von größeren alliierten Luftangriffen verschont blieb.

Die Stadtwerke Tübingen GmbH (SWT) sind für die Strom-, Wasser-, Gas-, Fernwärme- und Telekommunikationsversorgung der Stadt zuständig. Außerdem betreiben sie die Tübinger Bäder sowie Parkhäuser. Die Tochtergesellschaft Stadtverkehr Tübingen organisiert den Busverkehr. Mit dem Wasserkraftwerk Neckarwerk betreibt die SWT außerdem ein Laufwasserkraftwerk.

Der Öffentliche Personennahverkehr (ÖPNV) wird durch den Stadtverkehr Tübingen (SVT), einen Betriebszweig der Stadtwerke Tübingen GmbH, organisiert. Die einzelnen Stadtbuslinien werden ausgeschrieben und für einen bestimmten Zeitraum an ein Busunternehmen vergeben. In den Nächten von Donnerstag auf Freitag, von Freitag auf Samstag sowie von Samstag auf Sonntag verkehren Nachtbusse. Der Nahverkehr ist in den Verkehrsverbund Neckar-Alb-Donau (NALDO) eingebunden. Für Studenten der Eberhard Karls Universität wird ein Semesterticket angeboten, das im gesamten NALDO-Netz gültig ist.

Auf dem Stadtgebiet Tübingens befinden sich die Bahnhöfe bzw. Haltepunkte

Der Tübinger Hauptbahnhof ist ein Eisenbahnknotenpunkt mehrerer Bahnstrecken.

Auf der Neckar-Alb-Bahn von Tübingen über Reutlingen und Plochingen nach Stuttgart fahren neben Regionalbahnen nach Wendlingen (Fahrzeit ca. 40 Minuten) auch Regional-Express-Züge nach Stuttgart Hauptbahnhof (Fahrzeit ca. 61 Minuten). Am Bahnhof Plochingen besteht Anschluss über die Filstalbahn nach Ulm und weiter nach München. Zusätzlich fährt ein zweistündlicher Interregio-Express (IRE) mit nur einem Halt in Reutlingen Hauptbahnhof nach Stuttgart (Fahrzeit ca. 45 Minuten) und stellt dort Verbindung zum Fernverkehr her. Seit dem 13. Dezember 2009 hat Tübingen auch einen Fernverkehrsanschluss. Ein täglich verkehrender Intercity verbindet Tübingen mit Stuttgart, Mannheim, Köln und Düsseldorf, an bestimmten Tagen auch mit Berlin.

Mit den Zügen der "Kulturbahn" kann man zweistündlich umsteigefrei via Horb, Nagold und Calw nach Pforzheim fahren (Fahrzeit etwa eine Stunde und 40 Minuten). Die Bahnstrecke Tübingen–Horb über Rottenburg wird im 30-Minuten-Takt befahren. In Horb besteht Anschluss an die Gäubahn Stuttgart–Singen und weiter nach Zürich.

Die Ammertalbahn führt nach Herrenberg. Dort ist ein Umstieg in die Linie S1 der S-Bahn Stuttgart über Böblingen nach Stuttgart möglich (Gesamtfahrzeit nach Stuttgart Hbf 68 Minuten).

Über die Bahnstrecke Tübingen–Sigmaringen, auch als "Zollernalbbahn" bezeichnet, verkehren Züge via Hechingen, Balingen, Albstadt und Sigmaringen nach Aulendorf.

Seit einigen Jahren wird die Einrichtung einer Regionalstadtbahn Neckar-Alb nach dem Karlsruher Modell geplant. Hierzu soll insbesondere eine Stadtbahnstrecke vom Hauptbahnhof über Universität und Universitätskliniken zum Wohngebiet Waldhäuser Ost entstehen, die mit dem regionalen Zugverkehr durchgebunden wird. Eine Standardisierte Bewertung ergab eine positive volkswirtschaftliche Nutzen-Kosten-Relation von 1,4. Die Innenstadtstrecke in Tübingen wird von der Bürgerschaft kontrovers diskutiert, sodass Verwaltung und Gemeinderat einen Bürgerentscheid zugesichert haben. 2013 wurde mit den Vermessungsarbeiten der Regionalstadtbahn begonnen.
Die Regierung des Landes Baden-Württemberg hat 2014 die Finanzierung des Projekts gesichert.

Touristikzüge der Hohenzollerischen Landesbahn aus gekuppelten Triebwagen ab Tübingen nach Kleinengstingen (Wagen 4–5), Schömberg (Wagen 3) bzw. nach Sigmaringen (Wagen 1–2) erreichen den Naturpark Obere Donau, wo ein vertaktetes Angebot auf allen Stecken gefahren wird. Seit 2015 ermöglicht ein Frühzug Ganztagesausflüge.

Verschiedene Fernbuslinien verbinden die Stadt unter anderem mit Karlsruhe, München, Villingen-Schwenningen und Freiburg.

Zwar hat die Stadt keinen unmittelbaren Autobahnanschluss, jedoch kreuzen sich in Tübingen zwei wichtige Bundesstraßen: Die B 27 Schaffhausen–Villingen-Schwenningen–Tübingen–Stuttgart–Heilbronn und die B 28 Straßburg–Freudenstadt–Tübingen–Reutlingen–Ulm. Die B 27 ist in Richtung Norden autobahnähnlich ausgebaut, so dass die Bundesautobahn 8 bei Stuttgart schnell erreicht werden kann. Der vierspurige Ausbau ab Derendingen bis Dußlingen wurde im Herbst 2006 fertig gestellt. Zur Entlastung der Südstadt fehlt dazwischen der Schindhautunnel. Zudem ist geplant, die Bundesstraße 28 a in Richtung Rottenburg bis zur Anschlussstelle der Bundesautobahn 81 durchgehend vierspurig auszubauen. Das Stück bis zum Hirschauer Knoten wurde im Herbst 2007 als vierspurige Straße fertiggestellt.

In Tübingen wurde 2008 eine Umweltzone eingerichtet, so dass die Stadt bis auf wenige Ausnahmen nur noch mit Feinstaubplakette befahren werden darf. Ausgenommen sind die größeren Durchfahrtsstraßen B 27, B 28, Stuttgarter und Pfrondorfer Straße durch Lustnau, Wilhelmstraße zwischen Lustnau und Nordring, Nordring, Schnarrenbergstraße stadteinwärts bis zum Breiten Weg, Breiter Weg, Gmelinstraße stadteinwärts bis zum Universitätsklinikum sowie der Hagelocher Weg. In der Innenstadt sind ferner das Neckarparkhaus an der Wöhrdstraße über die Friedrichstraße und das Parkhaus Metropol an der Reutlinger Straße über die Hechinger Straße ausgenommen.

Bedingt durch die topographischen Verhältnisse gibt es in Tübingen erhebliche Kapazitätsprobleme im innerstädtischen Nord-Süd-Verkehr. Bereits im 19. Jahrhundert führten Engpässe in der Verbindung zwischen dem nördlich der Altstadt gelegenen Universitätsviertel und dem im Süden angelegten Bahnhof 1885–1887 zum Ausbau der in der Senke zwischen Altstadt und Österberg gelegenen Mühlstraße. Starke Belastung führte bereits 1938 zum Bau einer östlichen Umgehung im Zuge der damaligen Reichsstraße 27, die jedoch nicht alle Verkehrsbeziehungen abdecken konnte. Zur westlichen Umgehung der Innenstadt wurde daher 1979 der vierspurige Schlossbergtunnel im Zuge der B 28 in Betrieb genommen. Zur Entlastung der Mühlstraße wurde 1992 eine halbseitige Sperrung für den motorisierten Individualverkehr in Fahrtrichtung Süden eingerichtet. Eine 2009 durchgeführte Umgestaltung des Straßenraums in der Mühlstraße mit dem Ziel eines besser geschützten Radverkehrs führte zu Problemen im Busverkehr, obwohl die Breite der von den Bussen genutzten Fahrbahn nicht reduziert worden war. Eine generelle Verbreiterung des Straßenquerschnitts ist in diesem Bereich nicht möglich.

Weltweit sind mehr als 50 Tübinger Straßen nach Tübingen benannt.

Der Radverkehrsanteil im Binnenverkehr liegt in Tübingen bei rund 23 Prozent und erreicht damit Größenordnungen typischer Radverkehrsstädte. Beim Radverkehr wird eingeschätzt, dass die Qualität des derzeitigen Radverkehrsnetzes nicht der sehr hohen Bedeutung des Radverkehrs in Tübingen entspricht. Auch begünstigt die lokale Topographie nicht das Radfahren.

Durch die Stadt führt vom Schönbuch herkommend der Hohenzollern-Radweg, der als Fernradweg den Großraum Stuttgart mit dem Bodensee verbindet und damit im deutschen Fernradnetz ein wichtiges Zwischenglied darstellt.
Desgleichen durchläuft der Neckartal-Radweg die Stadt. Dieser Weg begleitet auf 410 km als "Flussradroute" den Neckar von seiner Quelle bis zur Mündung.

Am Kloster Bebenhausen in Tübingen beginnt der Jakobspilgerweg, der als Via Beuronensis bekannt und seit 2009 ausgeschildert ist. Er führt über die Schwäbische Alb nach Konstanz an den Bodensee. Von dort führt er durch die Schweiz, dann durch Frankreich und Spanien nach Santiago de Compostela. Er ist durchgehend mit einer stilisierten Jakobsmuschel markiert.

Über das lokale Geschehen im Raum Tübingen berichtet das Schwäbische Tagblatt, die Lokalzeitung mit der Südwest-Presse als Mantelteil. Außerdem erscheint einmal wöchentlich das kostenlose Anzeigenblatt Tübinger Wochenblatt.

Der Südwestrundfunk betreibt in Tübingen ein Landesstudio, aus dem unter anderem auch das Regionalprogramm „Radio Tübingen“ innerhalb von SWR4 Baden-Württemberg produziert und ausgestrahlt wird. Weitere Hörfunkprogramme sind die Uniwelle Tübingen, die Wüste Welle, das Freie Radio für Tübingen und Reutlingen und die helle welle. Aus dem Raum Reutlingen und Tübingen sendet auch das private Regionalfernsehen RTF.1. Außerdem berichtet das Universitätsfernsehen der Eberhard Karls Universität Tübingen CampusTV Tübingen über studentische Veranstaltungen und regionale Themen.

Tübingen ist Sitz des Regierungspräsidiums und des Landratsamts Tübingen.

Ferner gibt es ein Land- und ein Amtsgericht , sowie ein Finanzamt. Vormals gehörten die Tübinger Gerichte zum Oberlandesgericht Württemberg-Hohenzollern.

Neben dem Uniklinikum gibt es seit 1957 die Berufsgenossenschaftliche Unfallklinik mit 327 Betten und seit 1916 das Paul-Lechler-Krankenhaus für Tropenkrankheiten mit 101 Betten.

In Tübingen ist der Sitz der Baden-Württembergischen Versorgungsanstalt für Ärzte, Zahnärzte und Tierärzte, eine dem Ministerium für Arbeit und Soziales Baden-Württemberg nachgeordneten Dienststelle.

Die Stadt ist Sitz des Kirchenbezirks Tübingen der Evangelischen Landeskirche in Württemberg.

Die Stadtbücherei Tübingen besitzt eine Hauptstelle (in der Nonnengasse) und drei Zweigstellen (Derendingen, Waldhäuser-Ost, Wanne). Bei einem Bestand von etwa 218.000 Medien wurden 2015 über 1.102.000 Entleihungen erzielt.

Die Eberhard Karls Universität Tübingen ist eine der ältesten und renommiertesten deutschen Universitäten und wurde 1477 gegründet. Diese Bildungseinrichtung war zeitweise Studienort von Männern der Widerstandsbewegung vom 20. Juli 1944. Im "Foyer der Neuen Aula" wird seit 1984 an diese Widerstandskämpfer mit einer Gedenktafel erinnert. 

2016 waren an der Eberhard-Karls-Universität 27.500 Studenten immatrikuliert. Damit liegt die Stadt Tübingen im Ranking der größten deutschen Hochschulstädte auf Position 38.

Einen bedeutenden und bundesweit einmaligen Beitrag zur Studienorientierung leistet das Leibniz Kolleg, eine ehemalige Einrichtung der Universität, die nun von einer Stiftung geleitet wird.

Der Universität ist das Universitätsklinikum Tübingen mit 17 verschiedenen Kliniken und circa 1.500 Betten angeschlossen. Seit 1998 wird das Klinikum als eine selbstständige Anstalt des öffentlichen Rechts geführt.

Das Evangelische Stift der Evangelischen Landeskirche in Württemberg existiert seit 1536. Des Weiteren befindet sich in Tübingen die Evangelische Hochschule für Kirchenmusik Tübingen, die 1999 von Esslingen am Neckar weggezogen ist.

Tübingen hat ein Staatliches Seminar für Didaktik und Lehrerbildung (Gymnasien). Die Stadt ist außerdem „Korporativ Förderndes Mitglied“ der Max-Planck-Gesellschaft.


In Tübingen gehen mehr als 15.000 Kinder und Jugendliche zur Schule. Insgesamt befinden sich mehr als 30 Schulen im Stadtgebiet, darunter 15 Grund-, zwei Werkreal-, drei Realschulen, fünf Gymnasien, drei Berufsschulen, eine Förderschule, eine Schule für Geistigbehinderte und eine Schule für Erziehungshilfe sowie eine Waldorf- und eine Freie Aktive Schule.

Für einen Großteil der Tübinger Bevölkerung war der Weinbau bis ins 19. Jahrhundert der dominierende Erwerbszweig. Die damaligen Weingärtner wurden als Gôgen bezeichnet und verspottet. Noch heute erzählt man sich so genannte Gôgenwitze, die besonders derb sind und das beschwerliche Leben der Weingärtner in früherer Zeit widerspiegeln. In der ersten Hälfte des 20. Jahrhunderts kam der Weinbau in Tübingen fast vollständig zum Erliegen, da der Anbau hochwertiger Weine im Raum Tübingen nicht möglich ist. Zwar bieten die reichlich vorhandenen Südhänge ausreichend Wärme, aber keine für den Weinbau geeigneten Böden. Die oberen Erdschichten bilden nur eine relativ dünne Auflage über dem darunter liegenden Gestein aus Gipskeuper, Buntem Mergel und Stubensandstein. Die Böden der Hanglagen sind daher karg und für die landwirtschaftliche Nutzung wenig geeignet. Dementsprechend liegt der überwiegende Teil dieser Flächen heute brach.

An den Südseiten von Schlossberg, Spitzberg und Schnarrenberg ist noch heute die Terrassierung der Hänge aus den Tagen des Weinbaus weitgehend erhalten, an vielen Stellen aber von Wald oder Gestrüpp überwachsen. Seit 2004 gibt es wieder ein privates Weingut in der Stadt. Außerhalb des eigentlichen Stadtgebiets befinden sich am Südhang des Spitzberges oberhalb des Stadtteils Hirschau sowie am südlichen Schönbuchrand im Ortsteil Unterjesingen eine Reihe privater Weingüter. Die Tübinger Weinlage "Sonnenhalden" zählt zum Bereich "Oberer Neckar" des "Weinbaugebietes Württemberg".

Der Tübinger Wein ist heute aufgrund der geringen Anbaumenge nur begrenzt in Tübingen und Umgebung erhältlich. Häufig wird er zeitlich befristet in Besenwirtschaften ausgeschenkt. Nicht aus Tübinger Wein hergestellt ist der Sekt "Schloss Hohentübingen", der in einigen Lokalen in der Altstadt erhältlich ist.

Im Jahr 2001 entstand in Tübingen mit dem Kauf der Immobilien des Wohnprojekts Schellingstraße das erste Wohnprojekt unter dem Dach des Mietshäusersyndikats außerhalb der Freiburger Region. Mittlerweile gibt es vier Mietshäuser-Syndikats-Wohnprojekte in Tübingen. Im Herbst 2010 beschloss der Tübinger Gemeinderat, das Wohnprojekt „Vierhäuser Projekt“ mit einem Kredit von 150.000 Euro zu unterstützen.

Das Rathaus und die Altstadt sind vollständig erhalten. Es gibt zahlreiche Fachwerkhäuser und viele enge Gassen. Die Neckarfront mit dem Hölderlinturm ist ein weithin bekanntes Fotomotiv der Stadt und eines ihrer bekanntesten Wahrzeichen.

Vom Rathaus ertönt ein Stundenschlag und mehrfach täglich ein Glockenspiel (MP3; 223 kB).

Die Stiftskirche Tübingen von 1470 ist die evangelische Hauptkirche der Stadt. Dort sind die württembergischen Herzöge Eberhard im Bart (gestorben 1496), Herzog Ulrich (1550) und Herzog Christoph (1568) in dem mit dem Lettner abgetrennten Chorraum der Stiftskirche begraben. Seit 2014 verfügt die Stiftskirche über ein Glockenspiel, das unterschiedliche Melodien spielt.

Die zweite alte Kirche der Stadt ist die 1337 erstmals erwähnte Jakobuskirche, die aus einer Kapelle hervorging. Die im Kern romanische Kirche wurde im 16. Jahrhundert gotisch umgestaltet.

Aus dem im 13. Jahrhundert gegründeten Augustinerkloster ging nach der Reformation das Evangelische Stift hervor. Das um 1272 gegründete Franziskanerkloster wurde nach der Reformation in das Collegium Illustre, das heutige Wilhelmsstift, umgewandelt.

Die katholische Pfarrkirche St. Johannes wurde 1875 bis 1878 erbaut, die evangelische Eberhardkirche im Jahr 1911. Ein interessantes Beispiel des Neuen Bauens in der Weimarer Republik ist die 1931 erbaute Neuapostolische Kirche von Karl Weidle.

Nach dem Zweiten Weltkrieg wurden viele neue Kirchen errichtet. Evangelische Kirchen sind die Martinskirche von 1955, die Stephanuskirche von 1968, die Albert-Schweitzer-Kirche und die Dietrich-Bonhoeffer-Kirche, die zwischen den Jahren 1983 und 1985 erbaut wurde. Katholische Kirchen aus dieser Zeit sind St. Michael (1949), St. Petrus (1956) und St. Paulus (1974).

Zu den Kirchen in den Tübinger Stadtteilen siehe den Abschnitt Religion.

Weitere Sehenswürdigkeiten sind das Schloss Hohentübingen, die Eberhard Karls Universität, das Rathaus, das Stadtmuseum, das Goethehäuschen, das Nonnenhaus, das Kloster Bebenhausen, der Bebenhäuser Pfleghof, das Französische Viertel („Stadt der kurzen Wege“, ab 1991 im Entstehen, ebenso wie das Loretto-Viertel), der Österbergturm, Bismarckturm und der Steinenbergturm.

Bekannte Tübinger Museen sind die Kunsthalle Tübingen, das Museum im Schloss Hohentübingen als wichtiger Teil im Museum der Universität Tübingen MUT, wo unter Federführung der Universität Exponate aus denkmalorientierten Wissenschaftsbereichen ausgestellt werden, das Stadtmuseum Tübingen mit der Lotte-Reiniger-Scherenschnittsammlung und das Auto- und Spielzeugmuseum Boxenstop Tübingen in der Brunnenstraße.

Das Museum der Universität Tübingen MUT beherbergt als weltweit einzige universitäre Einrichtung Artefakte mit Welteerbestatus, wie den ältesten erhaltenen figürlichen Kunstwerken und Musikinstrumenten der Menschheit, den Mammutelfenbeinfiguren und den Fragmenten von Knochenflöten. Diese stammen aus der Vogelherdhöhle (Schwäbische Alb), die seit 2017 Teil des UNESCO-Welterbes „Höhlen und Eiszeitkunst im Schwäbischen Jura“ sind. Diese Objekte wurden vom Institut für Ur- und Frühgeschichte der Eberhard Karls Universität Tübingen archäologisch ausgegraben.
Zudem können verschiedene kunst-, aber auch natur- und geowissenschaftliche Sammlungen – insgesamt 66 – des MUT, wie die Graphische Sammlung, die Mineralogische Sammlung oder die Paläontologische Sammlung der Universität mit zahlreichen Saurier-Präparaten besucht werden. Andere Sammlungen der Universität öffnen nach Voranmeldung ihre Türen. Seit 2012 gibt es außerdem die Ausstellung „MindThings – KopfSache“, eine Kooperation zwischen dem Museum der Universität Tübingen MUT, dem Fachbereich Psychologie und dem Career Service der Uni.

Zusätzlich gibt es noch den von Herbert Rösler umgebauten G91-Bau, der Ausstellungszwecken dient.

Das bekannteste Theater der Stadt ist das Landestheater Tübingen ("LTT"). Daneben gibt es das Zimmertheater Tübingen, ein kleines und zeitgenössisches Theater in der Bursagasse inmitten der Altstadt. Das Zimmertheater betreibt auch eine Spielstätte im ehemaligen Kino Löwen. Daneben gibt es an der Universität mehrere studentische Theatergruppen sowie Aufführungen freier Theatergruppen im soziokulturellen Zentrum Sudhaus. Im Juli/August findet jährlich an wechselnden Spielorten das Tübinger Sommertheater statt, abwechselnd ausgerichtet vom LTT, Zimmertheater und Theater Lindenhof.

Zahlreiche Chöre und Orchester, die der Universität oder Kirchengemeinden zugeordnet sind oder selbständig sind, prägen das Musikgeschehen der Stadt. Überregionale Bekanntheit hat die Tübinger Motette in der Stiftskirche als allwöchentliche musikalische Samstagabend-Andacht nach Leipziger Vorbild erlangt.

Wichtigster Veranstaltungsort für Rock- und Pop-Musik ist das Sudhaus, das Kulturzentrum des Sudhaus e. V.

Kulminationspunkt der Tübinger Jazzszene ist der Jazzclub mit dem eigenen Domizil "Jazzkeller" in der Haaggasse, dem Veranstaltungsort regelmäßiger Jam-Sessions und 15 bis 20 Livekonzerten im Jahr. Der Jazzclub ist auch Veranstalter der Konzertreihen "Jazz im Prinz Karl", "Jazz im Studio" und der "Jazz & Klassik Tage". Ab 2017 finden die Veranstaltungen im Club Voltaire statt.

Von 1975 bis 1992 prägte das Tübinger Folk- und Liedermacher Festival das Tübinger Musikleben. Alljährlich vom Club Voltaire und der sozio-kulturellen Tübinger Szene zu einem speziellen Thema organisiert, lockten Veranstaltungen mit nationalen und internationalen Musikgrößen über die Pfingsttage Zehntausende nach Tübingen. Der Club Voltaire erhielt für sein Festival-Programm 1985 den Kulturpreis der Kulturpolitischen Gesellschaft.

Zu den Lokalmatadoren der Tübinger Musikszene zählt seit über 30 Jahre die Bluesrock-Gruppe "Black Cat Bone".

Herausragend unter den Bläsergruppen sind der seit 1911 bestehende Musikverein Derendingen mit über 40 Aktiven und eigener Jugendblaskapelle, die Winzerkapelle Harmonie Unterjesingen mit über 60 Aktiven Musikern, Jugendkapelle und Flötenausbildung und der Musikverein Pfrondorf mit 30 Aktiven und Jugendblasorchester. Alle bereichern das Kulturleben der Universitätsstadt durch ein jährliches Platzkonzert.
Das Schwäbische Tagblatt mit Sitz in Tübingen ist die auflagenstärkste Tageszeitung im Landkreis Tübingen.

Grünanlagen bilden Ruheorte, Flanier- und Spielplätze im Stadtzentrum Tübingens und sind stark frequentierte Naherholungsgebiete.
Im Zentrum der Stadt befindet sich der Alte Botanische Garten mit altem und artenreichem Baumbestand und dem Hölderlin gewidmeten Denkmal "„Genius des Ruhms“". Auf der grünen Neckarinsel befindet sich die über 180 Jahre alte malerische Platanenallee gegenüber der Neckarfront mit Denkmälern für Friedrich Silcher und Ottilie Wildermuth, unweit davon der Park am Anlagensee zwischen Bahnhof und den drei „alten“ Tübinger Gymnasien: Uhland-, Kepler- und Wildermuthgymnasium. Zwischen Neckar und Altstadt liegt der Österberg, der auf einer Seite fast vollständig unbebaut ist und im Sommer den Spaziergängern und Gleitschirmfliegern, im Winter den Rodlern dient. Die Tübinger Parkanlagen sind im Sommer auch Studententreffpunkte und Lernorte.

Der Neue Botanische Garten Tübingen auf der Morgenstelle beherbergt verschieden temperierte Gewächshäuser, darunter ein Fuchsien-Haus mit einer Sammlung von nach dem Tübinger Pflanzenkundler Leonhart Fuchs benannten Pflanzenarten.

Zu den innerstädtischen Grünanlagen sind auch die 14 Friedhöfe der Stadt einschließlich des Bergfriedhofs und des Stadtfriedhofs mit den zahlreichen Gräbern prominenter Bürger zu zählen. Auf dem Gräberfeld X des Stadtfriedhofs befindet sich die Bestattungsstelle des Anatomischen Instituts, wo fast 600 Opfer staatlicher Gewalt bestattet sind, die keines natürlichen Todes starben: Politische Gegner des NS-Systems, Zwangsarbeiter, Deserteure, Kriegsgefangene. An sie erinnern Gedenkplatten mit ihren Namen. 1980 ließ die Universität eine weitere Gedenkplatte für die Opfer der NS-Medizin hinzufügen.

Am Fuß des Spitzbergs befand sich von 1907 bis 1919 der privat betriebene Tiergarten Tübingen.
Die Basketballer des SV 03 Tübingen spielen als Walter Tigers Tübingen in der 1. Bundesliga. In der Basketball-Regionalliga sind die Derendingen Academics sowie die 2. Mannschaft des SV 03 („Tigerle“) vertreten.
Daneben spielt das Tübinger Modell in der Regionalliga Süd. Zudem tragen die Erstligisten des TV Rottenburg (Volleyball) und des TuS Metzingen (Frauen-Handball) alle bzw. einzelne Heimspiele(TuS) in Tübingen aus. Tübingen ist daher neben Berlin die einzige Stadt in Deutschland, in der gleichzeitig drei Vertreter von Hallensportarten in der ersten Bundesliga ihre Heimspiele austragen.

Bekannt sind die Leichtathleten wie Dieter Baumann von der LAV ASICS Tübingen und Marius Broening, der Speerwerfer Stefan Wenk sowie die Turnerinnen Marie-Sophie Hindermann und Kim Bui.

Seit Oktober 2004 gibt es an der Europastraße eine Großsporthalle, die zunächst "TüArena" genannt wurde und heute Paul Horn-Arena heißt. Schwimmen kann man in einem modernen Freibad und zwei Hallenbädern, darunter dem historischen Uhlandbad. Außerdem hat das Institut für Sportwissenschaft der Universität ein breites Angebot.

Weitere Sportvereine in Tübingen sind die TSG Tübingen (gegründet 1845; Badminton, Fußball, Handball, Klettern, Kunstturnen, Lacrosse (Tuelax), Leichtathletik, Parkour, Rhythmische Sportgymnastik, Tennis und Volleyball), der SSC Tübingen (1988; American Football (Red Knights Tübingen), Fußball, Volleyball), der SV Bühl (1925; Fußball, Tennis, Männer- und Frauengymnastik, Kinderturnen, Pilates, Nordic Walking, Fitness-Gymnastik, Tanzkurse für Kinder, Rückengymnastik, Tischtennis), der TV Derendingen 1900 (Basketball, Fußball, Tennis, Tischtennis, Turnen), der TSV Hagelloch (1913; Fußball, Turnen, Leichtathletik, Volleyball, Handball), der TSV Hirschau (1923; Fußball, Tennis, Tischtennis, Volleyball, Turnen/Leichtathletik, Freizeit), der TSV Lustnau (1888; Badminton, Fußball, Handball, Leichtathletik, Rehasport, Tennis, Tischtennis, Turnen), der SV Pfrondorf 1903, der SV Unterjesingen 1923 (Fußball, Leichtathletik, Turnen) sowie der SV Weilheim (1979; Aerobic, Badminton, Basketball, Leichtathletik, Tennis, Tischtennis, Volleyball, Walking). Die ATV Arminia zu Tübingen ist eine nicht schlagende Sportverbindung an der Eberhard-Karls-Universität in Tübingen.

Nur einer Sportart gewidmete Vereine sind u. a. der Bowlingverein BSV Tübingen (1964), die Tübinger Sportfechter, der Hockey Club Tübingen (1984), die Flugsportvereine Tübingen (1950) und Unterjesingen (1934), der Tübinger Ruderverein Fidelia (1877), die RV (Radfahrvereine) Tübingen („RV Pfeil“) und Derendingen (beide 1905), die Radsportgemeinschaft Tübingen (Fahrradtrial), die Reitsportvereine RSV Roseck (Unterjesingen), Reit- und Fahrverein Bühl, Stadtgarde zu Pferd 1514 (ältester Verein Tübingens) und Tübinger Reitgesellschaft, die Schachvereine Schachgemeinschaft Hohentübingen (2006) und SV Tübingen 1870, der Tübinger Schwimmverein (1913), der Squash-Insel-Sportclub (1980), Schützenvereine in Tübingen (1562), Bühl (1892), Derendingen (1954), Pfrondorf und Hagelloch (1963), der Akademische Ski-Club Tübingen (1908), der Skiclub Hirschau (1975), der TC (Tennis-Club) Tübingen (1909), das Karate-Team Tübingen (2009), der TSC Astoria Tübingen, der Tanzsportverein TTC Rot-Gold Tübingen (1972) Tübingen Hawks Baseball & Softball e.V. (1985) und das Karate-Team Tübingen (2011).

Prägend für das sportliche Leben der Stadt Tübingen ist auch der vom Institut für Sportwissenschaft organisierte Hochschulsport mit umfangreichem Wettkampf- und Breitensportprogramm. An vorderster Stelle der universitären und das gesellschaftliche Leben Tübingens prägenden Sportveranstaltungen steht der 100-Kilometer-Staffellauf und der jährliche Stadtlauf.

In Tübingen gibt es derzeit 32 Studentenverbindungen, die insbesondere durch ihre stattlichen Häuser das Stadtbild von Tübingen prägen. Vor allem der vordere Österberg und der Schloßberg sind von Verbindungshäusern gesäumt. Das alljährlich im Frühsommer stattfindende Stocherkahnrennen lebt auch von den teilnehmenden Studentenverbindungen. Mehr als ein Viertel sind "schlagende Verbindungen", der Rest setzt sich aus nichtschlagenden, „gemischten“ oder reinen Damenverbindungen zusammen.



Die "Liste von Persönlichkeiten der Stadt Tübingen" enthält in Tübingen geborene Persönlichkeiten sowie solche, die in Tübingen gewirkt haben, dabei jedoch andernorts geboren wurden.




</doc>
<doc id="5079" url="https://de.wikipedia.org/wiki?curid=5079" title="Tokio">
Tokio

Tokio (auch "Tokyo", älter "Tokjo", "Tokei", vor 1868 bekannt als "Dscheddo, Yeddo, Yedo, Jeddo, Jedo, Edo", jap. , "Tōkyō" ) ist eine Weltstadt in der Kantō-Region im Osten der japanischen Hauptinsel Honshū. Mit Einwohnern ist sie nicht nur die bevölkerungsreichste Metropole des Landes, sondern als Sitz der japanischen Regierung und des Tennō auch die Hauptstadt Japans. Sie umfasst die 23 Bezirke auf dem Gebiet der 1943 als Verwaltungseinheit abgeschafften Stadt Tokio und ist damit keine eigene Gebietskörperschaft mehr; stattdessen bilden die Bezirke zusammen mit den Städten und Gemeinden der westlich gelegenen Tama-Region und den südlichen Izu- und Ogasawara-Inseln die Präfektur Tokio. Diese bildet wiederum das Zentrum der Metropolregion Tokio-Yokohama, in der mehr als 37 Millionen Menschen leben (Stand 2014), was die Region zum größten Ballungsraum der Welt macht.

Die Stadtgeschichte beginnt im Jahr 1446, als Ōta Dōkan in einem Sumpfgebiet am Nordufer der heutigen Bucht von Tokio mit dem Bau der Burg Edo begann, umgeben von einigen Fischerdörfern. 1590 ging diese Burg an Tokugawa Ieyasu, der hier nach seinem Sieg in der Schlacht von Sekigahara sein neues Shogunat und damit die Edo-Zeit begründete. Edo wurde neben Kyōto zum politischen und kulturellen Zentrum des Landes. Mit der Meiji-Restauration 1868 wurde das Shogunat abgeschafft und der Sitz des Tennō nach Edo verlegt, die Burg wurde zum Kaiserpalast und Edo bekam seinen neuen Namen Tokio, der „Östliche Hauptstadt“ bedeutet. Von da an wuchs auch die Bevölkerung der Stadt, die bereits um 1910 mit rund zwei Millionen Einwohnern zu den größten der Welt zählte. Im Zweiten Weltkrieg war Tokio zahlreichen Luftangriffen durch die USA ausgesetzt, bei denen rund die Hälfte der Stadtfläche zerstört wurde. Nach dem Ende der amerikanischen Besatzungszeit folgte ein rasanter wirtschaftlicher Aufschwung, einhergehend mit einem erneuten Bevölkerungszuwachs.

Tokio ist heute das Industrie-, Handels-, Bildungs- und Kulturzentrum Japans mit zahlreichen Universitäten, Hochschulen, Forschungsinstituten, Theatern und Museen. Mit den Flughäfen Narita und Haneda und als Ausgangspunkt der meisten Shinkansen-Linien ist es auch das Verkehrszentrum des Landes. Der Finanzplatz Tokio ist nicht nur der größte Japans, sondern zählt neben London, New York und Hongkong auch zu den fünf größten der Welt. Zudem weist die Stadt ein hohes Preisniveau auf und lag in einer Studie 2014 auf Platz 9 der teuersten Städte weltweit. Neben modernen Sehenswürdigkeiten wie dem Tokyo Tower oder Tokyo Skytree bietet sie auch historische Anlagen wie die Kaiserlichen Gärten in Chiyoda, den Ueno-Park oder den Asakusa-Kannon-Tempel. In den vergangenen Jahren wurde Tokio zu einem zunehmend beliebten Tourismusziel und befindet sich mit jährlich bis zu acht Millionen Besuchern aus dem Ausland unter den 20 meistbesuchten Städten.

Tokio liegt an der Bucht von Tokio auf der Insel Honshū, der größten der vier Hauptinseln des japanischen Archipels, in der Kantō-Ebene ("Kantō-heiya") durchschnittlich sechs Meter über dem Meeresspiegel. Kantō ist das Gebiet, das in weitem Bogen um die Tokiobucht liegt. Der Name Kantō bedeutet „östlich der Barriere“ – eine historische Bezeichnung. (Kansai, also „westlich der Barriere“, ist das Gebiet um Ōsaka.) Mit „Barriere“ ist die alte Zollschranke gemeint, die West- und Ostjapan trennte, westlich der Stadt Hakone.

Die Kantō-Ebene ist die größte Ebene in Japan. Durch frühere, gewaltige Vulkanausbrüche des in den letzten Jahrhunderten eher ruhigen Fujisan wurde fast die komplette Ebene mit fruchtbarer, vulkanischer Asche eingedeckt – dem sogenannten "kantō rōmu sō". Dazu kommt die große Tokiobucht, die tief genug ist, um als Hafen zu fungieren, und flach genug, um dem Meer größere Flächen abzuringen.

Im administrativen Sinn existiert keine Stadt Tokio. Stadtgebiet im Sinne dieses Artikels sind die 23 Bezirke Tokios. Ihre Fläche beträgt 621,98 Quadratkilometer. Sie bilden den städtischen Kernbereich des Ballungsraums und befinden sich auf dem Gebiet der ehemaligen Stadt Tokio, die als politische Einheit 1943 aufgelöst wurde. Jeder Bezirk (jap. "ku") ist administrativ eine eigenständige Kommune. Offiziell bezeichnen sich die Bezirke auf Englisch als "City" (z. B. "Shinjuku City", "Shibuya City").

Die Präfektur Tokio (jap. "Tōkyō-to"; engl. "Tokyo Metropolis") umfasst neben den 23 Bezirken auch den westlichen Teil des Ballungsraumes, bis zu den Ausläufern der Japanischen Alpen, die Tama-Region. Außerdem gehören die südlich im Pazifik gelegenen Izu-Inseln und Ogasawara-Inseln sowie Okinotorishima zur Präfektur. Die Präfektur hat über 13 Millionen Einwohner und erstreckt sich bis zum nördlichen Wendekreis.

Obwohl Tokio (im Sinne der 23 Bezirke) allein bereits über neun Millionen Einwohner beherbergt, ist die Stadt selbst umgeben von Millionenstädten, Saitama im Norden, Chiba im Osten sowie Yokohama und Kawasaki (Präfektur Kanagawa) im Süden. Im Westen schließt sich die Tama-Region mit vier Millionen Einwohnern an.

Zusammen bilden diese Städte mit ihrem Umland die Metropolregion Tokio. In Japan wird das Gebiet als Tokiobereich (, "Tōkyō-ken"), Hauptstadtbereich (, "Shuto-ken") oder Südkantō (, "Minami-Kantō") bezeichnet. Die unterschiedlichen Namen bezeichnen unterschiedliche Definitionen für die Grenzen der Metropolregion, die im Allgemeinen die Präfektur Tokio selbst, allerdings ohne Pazifikinseln, und komplett oder teilweise die Nachbarpräfekturen Chiba, Kanagawa und Saitama umfasst, sowie kleinere Teile von Gunma, Ibaraki und Tochigi, und sogar Yamanashi. Die Metropolregion umfasst 13.572 km² und besitzt rund 37,555 Millionen Einwohner (2014). In jedem Fall ist das Ballungsgebiet um Tokio die größte Metropolregion der Welt.

Das Gebiet der früheren Stadt Tokio mit ihren 35 Stadtbezirken, also den urbanen Kernbereich Tokios, füllen seit 1947 die 23 Bezirke ( "-ku") aus, die weitgehend als eigenständige Kommunen fungieren:
Die Stadt befindet sich im Bereich des subtropischen Ostseitenklimas (nach Neef). Laut Köppenscher Klimaklassifikation ist die Stadt dem warmgemäßigten Seeklima zuzurechnen. Die Sommer sind heiß und feucht (30 °C tagsüber und 20 °C nachts), die Winter trocken und sonnig (10 °C tagsüber und um 0 °C nachts); manchmal fällt auch Schnee. Die Regenzeit (Tsuyu) mit täglichen Regenschauern dauert von Ende Juni bis Mitte Juli. Sie wird von feuchten Passatwinden aus dem Westpazifik hervorgerufen. Anschließend – von Mitte Juli bis Ende August – ist es anhaltend heiß mit hoher Luftfeuchtigkeit.

Taifune drohen im September oder Oktober, dauern aber selten länger als einen Tag. Sie entstehen meist im Sommer oder Frühherbst im Nordpazifik westlich der Datumsgrenze und nördlich des 5. nördlichen Breitengrades am Rand des Kalmengürtels und wandern dann meistens zuerst nordwestlich in Richtung Vietnam, Philippinen und China. Wenn sie das Festland nicht erreichen, drehen sie in nordöstliche Richtung ab und suchen Korea und Japan heim. In Tokio bringen Taifune starke Windböen und Regenfälle, schwächen sich dann aber allmählich ab, je weiter sie ins Inland vordringen, da sie kein Wasser mehr aufnehmen.

Die durchschnittliche Jahrestemperatur in Tokio beträgt 15,6 °C, die jährliche Niederschlagsmenge im Mittel 1466,8 Millimeter. Der wärmste Monat ist der August mit durchschnittlich 27,1 °C, der kälteste der Januar mit 5,2 °C im Mittel. Der meiste Niederschlag fällt im September mit durchschnittlich 208,5 Millimeter, der wenigste im Dezember mit 39,6 Millimeter im Mittel.

Tokio liegt in einer der aktivsten Erdbebenzonen der Welt. Kleine Erdbeben sind in der Stadt nichts Außergewöhnliches. Während der sehr aktiven Phasen können kleine, bemerkbare Erdbeben fast täglich auftreten. Trotz aller Anstrengungen ist den Wissenschaftlern eine wirksame Erdbebenvorhersage noch nicht gelungen.

Eine der bekanntesten Theorien stammt von Kawasumi Hiroshi, dem Präsidenten des Instituts für Erdbebenforschung der Universität von Tokio. Er hat alle Erdbeben in Tokio seit dem Jahre 818 mit einer Magnitude von über 5 auf der Richter-Skala analysiert und festgestellt, dass sich durchschnittlich alle 69 Jahre ein größeres Erdbeben ereignet. Demnach hätte das nächste große Beben im Jahre 1992 kommen müssen. Allerdings ist dies eine rein statistische Berechnung, die keine geologischen Gegebenheiten berücksichtigt und deshalb zur kurzfristigen Vorhersage völlig ungeeignet ist. Eine erheblich differenziertere Betrachtung nahm Ishibashi Katsuhiko von der Universität in Kōbe vor. Nach seiner Feststellung ereignen sich die Erdbeben immer in einem gewissen Zyklus. Am Anfang kommen mehrere kleinere Beben; ein großes Beben bildet dann immer den Abschluss dieses Zyklus.

Eines der schwersten Erdbeben war das Große Kantō-Erdbeben mit einer Magnitude von 7,9, bei dem am 1. September 1923 in Tokyo und Yokohama rund 140.000 Menschen starben und etwa 380.000 Häuser zerstört wurden. Weitere schwere Beben ereigneten sich in den Jahren 1615 (Magnitude 6,4), 1649 (7,1), 1703 (8,2), 1855 (6,9) und 1894 (7,0). Bei dem Genroku-Erdbeben am 31. Dezember 1703 wurden Tokio (damals: Edo) und andere Städte in der Umgebung zerstört. Über 10.000 Menschen kamen in der Region ums Leben.

Wie archäologische Funde belegen, war das Stadtgebiet schon in der Steinzeit besiedelt. Ursprünglich war Tokio unter seinem früheren Namen "Edo" ein kleiner Fischereihafen. Um das Jahr 1457 ließ der damalige Daimyō Ōta Dōkan nahe dem Dorf eine Burg bauen. Die Siedlung erlangte erst 1590 Bedeutung, als sie in den Besitz des Shōgun Tokugawa Ieyasu (1543–1616) überging.

Tokugawa Ieyasu bestimmte Edo 1603 zur Hauptstadt des Shogunats, der wahren Macht in Japan, während der machtlose Tennō (Kaiser) weiterhin in der offiziellen Hauptstadt Kyōto residierte. Die Edo-Burg wurde während seiner Regierungszeit restauriert und erweitert. Das Gebiet um die Edo-Burg wurde als Yamanote bezeichnet.

Tokio wurde häufig von verheerenden Erdbeben und großen Bränden heimgesucht. So forderte etwa 1657 ein Großbrand mehrere Tausend Menschenleben und zerstörte mehr als 60 Prozent des damaligen Stadtgebietes. Das Shogunat nutzte diese Gelegenheit für eine Neuordnung der Stadtstrukturen, die hauptsächlich der Brandverhütung und der Verstärkung der Verteidigungsanlagen der Edo-Burg diente. In dieser Phase wurden systematisch Schreine und Tempel in Außenbezirke transportiert und Stadtbewohner in neu gebaute Außenbezirke umgesiedelt.

Zu einem schnelleren Wachstum der Stadt führte der Befehl Tokugawa Ieyasus an seine Daimyō, in Edo eigene Residenzen zu errichten, wo ihre Familien praktisch als Geiseln gehalten wurden (Sankin-kōtai-Verfügung). Zahlreiche Handwerker und Kaufleute, die zur Versorgung des Hofes gebraucht wurden, ließen sich Anfang des 18. Jahrhunderts in Edo nieder.

Im Jahre 1868 wurde auf Veranlassung des Meiji-Tennō (Mutsuhito, 1852–1912) der kaiserliche Hof nach Edo verlegt und die Stadt in für „östliche Hauptstadt“ oder genauer „kaiserliche Residenzstadt im Osten“ umbenannt. Die Schriftzeichen wurden damals teils in der Han-Lautung "Tōkei", teils auch schon in der Wu-Lautung "Tōkyō" (Tokio) gelesen.

1872 zerstörte ein Großbrand die Bezirke Ginza und Marunouchi. Der Wiederaufbau und die damit verbundene Modernisierung des Stadtbildes erfolgten nach westlichem Vorbild. Die Planung hierfür wurde einem englischen Architekten übertragen, der das Stadtbild mit einer Mischung europäischer Stile prägen wollte (Straßen nach Pariser und Bauweise der Häuser nach Londoner Vorbild). Trotz einer gewissen Ambivalenz in der Bevölkerung ob der vollkommen neuen, westlichen Bauten, die ein geschlosseneres Wohngefühl vermittelten, ließ der damalige Gouverneur der Präfektur Tokio Yuri Kimimasa Handwerker und Bauleute nach Tokio kommen, um mit den Arbeiten zu beginnen. Gerade im Stadtteil Ginza sollte der Wiederaufbau so schnell wie möglich beginnen, da dort eine Bahnlinie zwischen Yokohama und Shimbashi eingeweiht werden sollte. Indem man traditionelle Wohn- und Lagerhäuser in Nebenstraßen versetzte, machte man Platz für die neue Architektur.

Die schwerste Naturkatastrophe in der neueren Geschichte Tokios war das Große Kantō-Erdbeben und Feuer vom 1. September 1923, bei dem ein Großteil der Stadt zerstört wurde. Beim im Jahre 1930 beendeten Wiederaufbau entstanden über 200.000 neue Gebäude, darunter viele nach westlichem Muster, sowie sieben Stahlbetonbrücken über den Fluss Sumida und einige Parks.

1943 wurde mit Erlass des Tōkyō-tosei die Stadt Tokio als administrative Einheit aufgelöst. Im Zweiten Weltkrieg begannen die Vereinigten Staaten am 24. November 1944 mit der Bombardierung Tokios, und auch am 25. Februar und am 10. März 1945 flogen amerikanische Bomber schwere Luftangriffe. Mehr als 100.000 Menschen starben, als ganze Stadtteile mit Gebäuden in traditioneller Holzbauweise ein Raub der Flammen wurden. Auf einer Fläche von 15 Quadratmeilen waren sämtliche Häuser zerstört, auch der historische Kaiserpalast wurde vernichtet.

Während der Besatzungszeit war Tokio von September 1945 bis April 1952 von amerikanischen Truppen besetzt. Gegenüber dem Kaiserpalast residierte General Douglas MacArthur, der als "Supreme Commander for the Allied Powers" die Besatzungsbehörden leitete. Besonders ab dem Beginn des Koreakriegs erlebte die Stadt eine Phase raschen Wiederaufbaus und wirtschaftlichen Wachstums.

Vom 10. Oktober bis 24. Oktober 1964 fanden in Tokio die XVIII. Olympischen Sommerspiele statt.

Am 20. März 1995 verübten Mitglieder der Ōmu Shinrikyō (Aum-Sekte) einen Sarin-Anschlag auf die Tokioter U-Bahn. Dabei starben dreizehn Menschen, und über 6.200 wurden verletzt.

Laut der Forbes-Liste der "World's Most Expensive Cities To Live" von 2009 gilt Tokio als teuerste Stadt der Welt.
Im März 2013 benannte die Forbes-Liste Tokio auf Platz zwei (hinter Hongkong).

Am 7. September 2013 wurde Tokio vom Internationalen Olympischen Komitee (IOC) als Gastgeber für die Olympischen Sommerspiele 2020 ausgewählt.

Für die nähere Zukunft sagen Seismologen für Tokio ein verheerendes Erdbeben in der Größenordnung des Großen Kantō-Erdbebens von 1923 vorher. Dies und die exorbitanten Grundstückspreise sind die Gründe, weshalb seit den 1990er Jahren eine Verlegung der Hauptstadt weg von Tokio diskutiert und geplant wird – Hauptstadtverlegungen gab es aus religiösen und politischen Gründen in der japanischen Geschichte schon oft. Auf Grundlage eines Gesetzes aus dem Jahr 1992 wurden bis 1999 drei Kandidatenregionen ermittelt: Tochigi-Fukushima im Nordosten, Gifu-Aichi in Tōkai und Mie-Kiō. Bisher sind noch keine Aktivitäten erfolgt.

Seit den 1880er-Jahren leben in Tokio mehr als eine Million Einwohner. Seit den späten 1940er Jahren ist die Metropolregion Tokio erneut rasch gewachsen, sowohl nach Fläche als auch nach Einwohnerzahl. In ihr lebt ungefähr ein Viertel der Gesamtbevölkerung Japans. Ihre äußere Grenze liegt zwischen 40 und 70 Kilometer vom Stadtzentrum entfernt. Nach einem Zwischenhoch 1965 hatte sich die Bevölkerung der 23 Bezirke verringert, steigt aber momentan durch Reurbanisierung wieder an und hat mittlerweile auch den Stand von 1965 übertroffen.

Die 23 Bezirke haben zusammen Einwohner (Stand: ). Der Großraum Tokio bildet gemeinsam mit den angrenzenden Präfekturen Kanagawa, Saitama und Chiba das größte zusammenhängende urbane Gebiet der Erde (Megaplex) mit 34,5 Millionen Einwohnern (2005). Die Metropolregion beherbergt 27 Städte mit mehr als 200.000 Einwohnern, 17 Städte mit einer Bevölkerung von über 300.000, und acht mit einer Einwohnerzahl von mehr als 500.000.

Tokio hat drei weitere Millionenstädte als Vororte: Yokohama, Saitama und Kawasaki. Im östlichen Vorort Chiba leben etwa 900.000 Menschen. Yokohama im Süden Tokios hat mit 3,6 Millionen Einwohnern etwa ebenso viele Einwohner wie Berlin oder Madrid.

Die folgende Übersicht zeigt die Einwohnerzahlen der früheren Stadt Tokio, also des Gebiets der heute 23 Bezirke, nach dem jeweiligen Gebietsstand. Bis 1914 handelt es sich um Schätzungen, von 1920 bis 2005 um Volkszählungsergebnisse.
Eine gemeinsame politische Struktur ausschließlich für Tokio existiert nicht. Gemeinsame Verwaltungsaufgaben für Tokio werden direkt von der übergeordneten Präfektur Tokio ("Tōkyō-to", engl. "Tokyo Metropolis") mit Sitz im Tokyo Metropolitan Government Building in Shinjuku wahrgenommen. Die 23 Bezirke haben deshalb als "tokubetsu-ku" („Sonder-“ oder „Spezial-Bezirke“) einen einzigartigen Status unter den Kommunen Japans. Sie arbeiten durch einige gemeinsame Institutionen wie der „Sonderbezirksbürgermeisterkonferenz“ in verschiedenen Bereichen wie der Organisation von Pferderennen oder bei der Rekrutierung kommunaler Beamten zusammen; eine Reihe dieser stadtweiten Institutionen haben ihren Sitz im "Tōkyō kusei kaikan" (etwa „Haus der Tokioter Bezirkspolitik“) in Iidabashi im Bezirk Chiyoda.

Versuche einiger Politiker, z. B. in den 2000er Jahren ein Vorstoß von Shigefumi Matsuzawa und Kiyoshi Ueda, den damaligen Gouverneuren der Nachbarpräfekturen Kanagawa und Saitama, zusätzlich eine enge, gemeinsame Verwaltungsstruktur für die Metropolregion Tokio aufzubauen, sind bisher ohne konkretes Ergebnis. Existierende Kooperationsforen sind die regionale Gouverneurskonferenz Kantō ("Kantō chihō chijikai") aus zehn Gouverneuren der Region sowie die "kyū-tokenshi-shunō-kaigi" (etwa „Konferenz der Verwaltungschefs von neun Präfekturen und Städten“, manchmal auch "shutoken summit"), die die Gouverneure der Präfekturen Saitama, Chiba, Tokio und Kanagawa sowie die Bürgermeister der Städte Yokohama, Kawasaki, Chiba, Saitama und Sagamihara versammelt.

Auf Landkarten auch von staatlichen Stellen wird Tokio häufig nach wie vor als ganzes als Hauptstadt der Präfektur Tokio gekennzeichnet, auch wenn sie es rein technisch betrachtet seit der Auflösung der Stadt als Verwaltungseinheit 1943 nicht mehr sein kann; formal ist seit dem Umzug der Präfekturverwaltung 1991 der „Sonderbezirk“ Shinjuku Sitz der Präfekturverwaltung. Betrachtet man Tokio als Präfekturhauptstadt, ist sie unter allen 47 Präfekturhauptstädten diejenige mit dem höchsten Anteil an der Präfekturbevölkerung – in den 23 Bezirken leben mehr als zwei Drittel der Einwohner der Präfektur Tokio; damit läge sie noch deutlich vor der Stadt Kyōto, wo rund 56 % der Einwohner der Präfektur Kyōto leben. Berücksichtigt man dagegen nur existierende Gemeinden, so ist Shinjuku mit weniger als 3 % die Präfekturhauptstadt mit dem niedrigsten Anteil an der Präfekturbevölkerung.

Elf der Tokioter Bürgermeister und 21 der 23 Kommunalparlamente werden bei den „einheitlichen Regionalwahlen“ in Jahren vor Schaltjahren gewählt (zuletzt 2015). Bei Wahlen zum Parlament der Präfektur Tokio stellt Tokio 89 der 127 Abgeordneten, wobei die 23 Bezirke als SNTV-Wahlkreise dienen, aber ein sehr unterschiedliches Stimmgewicht haben: Bei der Wahl 2009 wählten die knapp 40.000 Wahlberechtigten des Bezirks Chiyoda einen Abgeordneten, das präfekturweit zweithöchste Stimmgewicht hinter den Izu- und Ogasawara-Inseln. Dagegen wählten im Bezirk Edogawa über 500.000 Wahlberechtigte fünf Abgeordnete, mit über 100.000 Wahlberechtigten pro Abgeordneter das viertniedrigste Stimmgewicht vor drei Wahlkreisen westlich von Tokio.

Im nationalen Unterhaus umfasst Tokio 17 der insgesamt 25 Einzelwahlkreise der Präfektur Tokio, wobei einer davon auch die zur Präfektur Tokio gehörigen Pazifikinseln enthält. Auch dabei ist das Stimmgewicht unterschiedlich, ist aber im landesweiten Vergleich generell niedrig: So gab es 2009 in den meisten Wahlkreisen in Tokio über 400.000 Wahlberechtigte pro Abgeordneter, während der eher ländliche, westlichste Wahlkreis der Präfektur Tokio nur rund 320.000 Wahlberechtigte verzeichnete – zum Vergleich: in sieben Wahlkreisen auf Shikoku lebten 2009 jeweils weniger als 250.000 Wahlberechtigte.

Nur bei Gouverneurs- und nationalen Oberhauswahlen unterscheidet sich das Stimmgewicht der Bewohner Tokios nicht vom Rest der Präfektur Tokio, da dabei die gesamte Präfektur einen Wahlkreis bildet.

Tokio besitzt viele Theater, in denen sowohl traditionelle Formen des Theaters – wie zum Beispiel Nō und Kabuki – als auch moderne Stücke aufgeführt werden. Mehrere Sinfonieorchester und viele kleinere Orchester haben westliche und traditionelle japanische Musik in ihrem Repertoire.

Nahe dem Tokyo Opera City Tower liegt im Bezirk Shibuya das Neue Nationaltheater ("Shin kokuritsu gekijō"), das in den Theatern "Opera Gekijō" („Opernhaus“; engl. "Opera Palace"), "Chū-gekijō" („Mittleres Theater“, "Play House") und "Shō-gekijō" („Kleines Theater“, "The Pit") Opern, Ballett und zeitgenössischen Tanz zeigt. Auch in der Opera City befindet sich das Konzerthaus von Tokio mit sinfonischer Musik im Spielprogramm. Die Suntory Hall ist ein Konzerthaus im Stadtteil Akasaka, es zählt zu den weltweit renommiertesten Konzerthäusern. In Partnerschaft mit mehreren europäischen Theaterhäusern zeigt das Panasonic Globe Theatre westliche Dramen. Das Takarazuka Grand Theatre ist ein Theater für Revuen und Musicals und Heimstätte der Musiktheatergruppe Takarazuka Revue. Nō und Kabuki werden in zahlreichen kleineren Theaterhäusern der Stadt aufgeführt.

Im Nationaltheater in Hayabusachō werden überwiegend Aufführungen traditioneller japanischer Theaterformen gegeben.

Im "Ueno-Park" im Bezirk Taitō befinden sich das Nationalmuseum Tokio, das größte und älteste Museum Japans. Es werden rund 110.000 Exponate der japanischen Kunst und Archäologie gezeigt. Weitere wichtige Kunstmuseen sind das Nationalmuseum für westliche Kunst, das Tokyo Metropolitan Teien Art Museum, das Bridgestone Museum of Art und das Nationalmuseum für moderne Kunst.

Das 1871 gegründete Nationalmuseum der Naturwissenschaften zeigt eine Auswahl der 3,5 Millionen Einzelstücke, darunter eine Sammlung zur Wissenschaft vor der Öffnung Japans. Das Edo-Tokyo-Museum und Fukagawa-Edo-Museum befassen sich mit der Stadtgeschichte Tokios. Dort wurde das alte Tokio in Miniatur nachgebaut, einzelne historische Häuser werden auch in Originalgröße gezeigt.

Ende September 2017 eröffnete die international bekannte japanische Künstlerin Yayoi Kusama in Tokyo das Yayoi Kusama Museum.

Der historische Stadtkern Tokios im Bezirk Chiyoda wird vom Kaiserpalast Kōkyo dominiert. Die kaiserliche Residenz liegt auf dem ehemaligen Gelände der Burg Edo und ist von einer weitläufigen Parkanlage umgeben. Im südlich und westlich der Palastanlage gelegenen Stadtteil Nagatachō liegt das Regierungsviertel mit dem Amtssitz des Premierministers (Kantei), das Gebäude des japanischen Parlaments und dem Obersten Gerichtshof.

Östlich des kaiserlichen Palastes liegt der Stadtteil Marunouchi, das bedeutendste Geschäftsviertel des Landes. Viele der großen Konzerne Japans und eine große Anzahl an Einrichtungen des Finanzwesens haben hier ihre Hauptgeschäftsstelle. Im Jahre 1914 erlangte dieser Bezirk nach der Eröffnung des Hauptbahnhofs große Bedeutung. Im Osten von Marunouchi liegt das größte Einkaufsviertel Tokios. Es erstreckt sich vom nördlich gelegenen Stadtteil Nihombashi bis nach Ginza im Süden. Viele Kaufhäuser, internationale Mode-Marken, traditionelle Spezialitätengeschäfte, Vergnügungslokale und Restaurants haben sich entlang der Straßen dieser Bezirke angesiedelt.

Im Stadtbezirk Minato befindet sich der 333 Meter hohe Tokyo Tower, eines der Wahrzeichen der Stadt, und der Hochhauskomplex Tokyo Midtown. Ein weiteres Einzelhandels- und Geschäftszentrum ist der Bezirk Shinjuku um den Bahnhof Shinjuku, wo ebenfalls bedeutende Firmenzentralen und die Präfekturregierung angesiedelt sind. Weitere bedeutende Stadtzentren und Sehenswürdigkeiten sind Akihabara, auch als "Electric City" (, "denki-machi") bekannt, ein großes Elektronik- und Computereinkaufsviertel und Treffpunkt der Otaku, der Tsukiji-Fischmarkt (größter Fischmarkt der Welt), der Tokyo Dome, der Ueno-Park mit der Einschienenbahn Ueno-Zoo, das Kaufhaus Mitsukoshi und die Rainbow Bridge. Im Bezirk Sumida wurde am 18. März 2011 der Tokyo Sky Tree fertiggestellt, obwohl in der Woche zuvor das Tohoku-Erdbeben auch Tokio erreichte. Die Eröffnung erfolgte am 22. Mai 2012. Mit 634 Metern ist der Turm der höchste Fernsehturm der Welt sowie das zweithöchste freistehende Bauwerk nach dem Burj Khalifa im arabischen Dubai.

Bedeutende Sakralbauten sind der Meiji-Schrein und der Sensō-ji in Taitō, der älteste Tempel in Tokio.

Auch wenn in Tokio der Eindruck von dichter Stadtlandschaft mit wenig Grün überwiegt, gibt es im Stadtgebiet über hundert öffentliche Parks, wobei allerdings schon ein Spielplatz mit ein paar Bäumen als Park gilt. Die größten innerstädtischen Parks Tokios sind der Ueno-Park in Taitō, der Yoyogi-Park und der Shinjuku Gyoen, gefolgt vom Shinjuku-Chūō-Park, dem Hibiya-Park und den Grünanlagen rund um den Kaiserpalast (namentlich Ni-no-Maru-Park, Kita-no-Maru-Park, Chidori-ga-Fuchi-Park und Soto-Bori-Park).

Weitere Parks sind der Inokashira-Park zwischen den Städten Musashino und Mitaka, der Koishikawa-Kōrakuen, ein Landschaftsgarten auf dem Grundstück eines ehemaligen Daimyō-Anwesens direkt neben dem Tokyo Dome, und der Odaiba-Kaihin-Park, ein beliebter Pärchentreff mit Blick auf die Bucht von Tokio. Die bekanntesten Vergnügungsparks in Tokio sind der Tokyo Sea Life Park, Hanayashiki, Toshimaen, Tokyo Disney Resort, der Tama-Zoo und der Ueno-Zoo.

Der Tama-Zoo ist der größte Zoo von Tokio. Er wurde am 5. Mai 1958 eröffnet und umfasst ein Gelände von 52,3 Hektar. Der Zoo ist in drei ökologische Areale eingeteilt, den asiatischen Garten, den afrikanischen Garten und den australischen Garten. Dazu besitzt er ein Insektarium. In den jeweiligen Gärten werden typische Tiere des jeweiligen Erdteils gezeigt. Er liegt vor dem Bahnhof "Tama Dōbutsu Kōen" der "Keiō-Dōbutsuen-Linie" und der Einschienenbahn Tama.

Der Ueno-Zoo ist der älteste Tierpark Japans. Er ist kleiner als der Tama-Zoo und befindet sich im Ueno-Park mitten in der Tokioter Innenstadt. Der Zoo ist durch eine in einem Einschnitt liegende Straße in zwei Teile geteilt, die mit einer Brücke und der Ueno-Zoo Monorail verbunden sind.

Der „Hama-Rikyū-Garten“ an der Mündung des Sumida, ursprünglich der Garten der kaiserlichen Villa, ist bekannt für seinen Meerwasserteich, der auch Ebbe und Flut hat sowie seine mit Wisteria bewachsenen Brücken. Der „Kiyosumi-Garten“ bekam seine gegenwärtige Gestalt von Baron Iwasaki im Jahre 1878. Ein kleiner Teich mit circa 10.000 Karpfen ist umgeben von großen Felsen, die aus ganz Japan stammen. 1924 wurde er der Stadt Tokio geschenkt. Sehenswert sind auch die weiter im Westen, hinter den Vororten, gelegenen Teile der schönen Gebirgslandschaft des Chichibu-Tama-Nationalparks.

Neben der Sportart Sumō, dessen Turniere in Tokio im Januar, Mai und September im Ryōgoku Kokugikan stattfinden, sind Baseball und Fußball in Japan sehr populär. Tokio ist die Heimat der „New York Yankees von Japan“, dem Rekordmeister Yomiuri Giants, sowie der Tōkyō Yakult Swallows – beide aus der Central League. Im Großraum spielen außerdem die Yokohama BayStars und in der Pacific League die Chiba Lotte Marines und die Saitama Seibu Lions. J-League-Fußballmannschaften aus Tokio sind der FC Tokyo und Tokyo Verdy, aus der Region kommen außerdem der Rekordmeister Kashima Antlers, JEF United Ichihara Chiba, die Yokohama F. Marinos, die Urawa Red Diamonds, Kawasaki Frontale, Ōmiya Ardija und Kashiwa Reysol.

Die traditionellen Sportarten wie Aikidō, Judo, Karate, Kyūdō und Kendō sind überwiegend nur in den jeweiligen Schulen zu bestimmten Zeiten zu besichtigen. Wer in Tokio joggen möchte, findet am Wassergraben um dem Kaiserpalast viele Gleichgesinnte.

Mehrere olympische Bauten, unter anderen das Olympiastadion und die Yoyogi Arena befinden sich in der Nähe des Meiji-Schreins. Die Sportstätten wurden anlässlich der Olympischen Spiele im Jahre 1964 nach Plänen des Architekten Kenzō Tange (1913–2005) erbaut.
Die Olympischen Spiele 2020 werden in Tokio stattfinden.

Jährlich Anfang April öffnen sich in Tokio die Kirschblüten ("sakura no hana"). Sie symbolisieren Schönheit, Perfektion, aber auch Vergänglichkeit auf der Höhe des Ruhmes. Die Menschen in Japan verehren die blassrosa Pracht deshalb als Sinnbild für ein kurzes, aber erfülltes Leben. Die Kirschblüte ist auch die offizielle Pflanze von Tokio.

In den etwa zwei Wochen, in denen die Kirschen in der Stadt blühen, treffen sich Japaner zum Picknick (Hanami, wörtlich Blütenschau) in den Parks mit Freunden, Kollegen und Familie. Die Kirschblüte ist auch ein Anlass, zu für ihre Kirschblüte besonders berühmten Parks und Gegenden zu reisen oder bekannte Sehenswürdigkeiten neu zu erleben. Berühmt für ihre Kirschblüten sind der Ueno-Park und der Park des Kaiserpalasts.

In Tokio hat man die Auswahl unter mehr als 50.000 Restaurants. Diese bieten eine überraschend große Auswahl von preiswerten Nudelsuppen bis zum aristokratischen Kaiseki. Die Hauptrolle in der traditionellen japanischen Küche spielen Fisch, Reis, Sojabohnen und Gemüse. Am bekanntesten ist Sashimi (roher Fisch). Eine lokale Spezialität ist Monjayaki – insbesondere auf der Tsukishima Monja Street gibt es über 70 Monjayaki-Lokale.

Für die Haute Cuisine in Japan steht Kaiseki. Dieses aufwändige Gericht verkörpert die drei Ideale der einheimischen Küche: aufwändige Zubereitung, dekoratives Anrichten und erlesenes Ambiente. Es gilt als Krönung der japanischen Kochkunst und es werden nur absolut frische und möglichst naturbelassene Lebensmittel verwendet. Kaiseki, das sich aus einer Zwischenmahlzeit zur Teezeremonie entwickelte, wird heute in noblen Restaurants und Hotels serviert.

Die Japaner haben aber auch mit Rind, Geflügel und Schwein experimentiert und Gerichte wie Teppanyaki, Shabu shabu und Sukiyaki entwickelt. Bekannt ist das marmorierte einheimische Rindfleisch, dessen teuerste Marke das Kobe-Rind ist. Ein einfaches Mittag- oder Abendessen für jeden Tag bieten die zahlreichen Nudelrestaurants, die Udon, Soba oder Ramen preiswert an. Viele der kleinen Nudellokale in Tokio sind selbst nachts geöffnet und es gibt sie in fast jeder Straße.

Genauso beliebt sind nationale Spezialitätenrestaurants, „ethnic food“ genannt. Unter diesem Begriff verstehen Japaner alles, was nicht japanische oder westliche Küche ist. Vorrangig finden sich hier chinesische, koreanische (Yakiniku), indische (Curry), thailändische und vietnamesische Restaurants. Auch gibt es in Tokio eine signifikante Anzahl deutscher Restaurants. Modewellen bringen alle paar Jahre neues "ethnic food" nach Japan, die letzten Trends waren Bali food und Okinawa-Küche. Tokio als Weltstadt versammelt auch eine große Anzahl nationaler und internationaler Fastfood-Restaurant- und Café-Ketten, darunter MOS Burger, Royal Host, Yoshinoya, Kentucky Fried Chicken, McDonald’s und Starbucks.

Viele Fabriken, Universitäten, Krankenhäuser und andere Einrichtungen haben seit den 1930er Jahren ihren Standort in die Außenbezirke Tokios verlagert. Ab Mitte der 1950er Jahre beschleunigte sich dieser Prozess, als Japan einen bemerkenswerten wirtschaftlichen Aufschwung erlebte. Aufgrund des Bevölkerungswachstums entstanden Subzentren in den (damaligen) Randgebieten wie Ikebukuro, Shinjuku und Shibuya. Dort haben sich verschiedene Dienstleistungsbetriebe – unter anderem des Einzelhandels und des Finanzwesens – angesiedelt. Mittlerweile ist die Großstadt Tokio (, "shutoken"; wörtlich: Hauptstadt-Gebiet) in die umliegenden Präfekturen Ibaraki, Tochigi, Gunma, Saitama, Chiba, Kanagawa und Yamanashi hineingewachsen.

Am Ufer der Tokiobucht konzentrieren sich die modernen Großindustrien der Stadt. Dort liegt zwischen Tokio und Yokohama das größte Industriegebiet Japans. Der dominierende Wirtschaftszweig ist die Schwerindustrie, die mehr als zwei Drittel des Gesamtproduktionswertes erwirtschaftet. Die Leichtindustrie ist breit gefächert: Hergestellt werden chemische Produkte, Kameras, Maschinen, Metallwaren, Nahrungsmittel, optische Geräte und Textilien sowie eine große Vielfalt an Konsumgütern.

Die Wirtschaft der Stadt ist hoch effizient, ihre Stärken liegen besonders im internationalen Handel und in der forschungsintensiven Hochtechnologie. Aufgrund des hohen Lohnniveaus haben Tokioter Firmen schon in den 1970er Jahren begonnen, ihre Produktion besonders nach Südostasien auszulagern. Die in diesen Ländern geschaffene Infrastruktur hat es aber in den letzten Jahren auch dortigen einheimischen Unternehmen erlaubt, zu ausgewachsenen Konkurrenten für die Tokioter Industrie heranzuwachsen.

In den 1980er Jahren stiegen in Tokio die Grundstückspreise stark an. Es kam zu einem Immobilien-Boom (Bubble Economy), wobei die Grundstücke von Unternehmen als Sicherheiten für immer höhere Kredite benutzt wurden. Gleichzeitig stieg der Wert der Aktien und der Wert des Yen gegenüber dem US-Dollar, aber auch die Staatsverschuldung des Landes. Die Unternehmen hatten sehr viel Kapital zur Verfügung, das teilweise zur Akquirierung von Unternehmen außerhalb Japans, vor allem in den USA, verwendet wurde, aber auch zu großer Geldverschwendung führte.

Die Situation wurde riskant, als die Banken begannen, durch die überbewerteten Immobilien gegenfinanzierte Kredite auszugeben. Im Jahre 1990 platzte die Blase. Die Grundstückspreise sanken auf ein Viertel zurück, der Wert der Aktien kollabierte, und die Banken saßen auf ihren „faulen Krediten“. Seitdem befand sich die Tokioter Wirtschaft in einer Phase der Wirtschaftsflaute und Deflation, auch die Asienkrise 1997/1998 verhinderte eine Erholung.

Das Kabinett um Premierminister Jun’ichirō Koizumi hat am Anfang dieses Jahrtausends teilweise vergeblich Anstrengungen zur Privatisierung von Staatsunternehmen und zur Deregulierung der japanischen Wirtschaft unternommen. Hinweise auf eine Besserung der Lage geben der China-Boom, der in den letzten Jahren eingesetzt hat, und Fortschritte in der Robotik-Forschung. Auch ist es den Banken seit Anfang der 1990er Jahre gelungen, eine Vielzahl der „faulen Kredite“ abzuschreiben und durch Fusionen den Sektor zu stabilisieren. Tokio ist heute neben New York und London einer der bedeutendsten globalen Finanzplätze.

In der Meiji-Zeit zwischen 1868 und 1912 wurde in Japan ein Eisenbahnnetz errichtet, in dessen Zentrum Tokio liegt. Die Stadt ist über Hauptlinien mit allen Teilen des Landes verbunden und ein gut ausgebautes Nebenliniennetz durchzieht das nahe Hinterland. Von den wichtigsten Bahnhöfen der Stadt – Ikebukuro, Shibuya, Shinagawa, Shinjuku, Tokio (Hauptbahnhof) und Ueno – werden täglich mehrere Millionen Pendler befördert. Da die existierenden Hauptverbindungen bald überlastet waren, sind ab den 1960er Jahren mehrere Shinkansen-Strecken eröffnet worden.

Der Flughafen Haneda an der Tokiobucht südlich des Stadtzentrums diente lange Zeit sowohl dem internationalen als auch dem inländischen Flugverkehr, bis im Jahre 1978 der neue Flughafen Tokio-Narita 55 Kilometer östlich des Stadtzentrums in der Präfektur Chiba eröffnet wurde. Auf diesem ist im April 2002 eine zweite Start- und Landebahn in Betrieb genommen worden, die dem Kurz- und Mittelstreckenbetrieb innerhalb Asiens dienen soll. Über den Flughafen Haneda wurden zwischenzeitlich vorwiegend Inlandsflüge abgewickelt. Der zentraler gelegene Flughafen Haneda übernimmt seit 2010 wieder internationalen Flugverkehr.

Der Flughafen Narita wird von fast allen internationalen und nationalen Fluggesellschaften angeflogen. Er kann über zwei Bahnlinien erreicht werden. Dies sind der Narita Express mit den Haltestellen in Tokio, Shinjuku, Ikebukuro und Yokohama und die private Keisei-Linie mit den Zügen Skyliner und Limited Express, die den Bahnhof Ueno mit dem Flughafen Narita verbinden. Der Flughafen Haneda ist durch die Tokyo Monorail an die Yamanote-Linie angebunden.

Der Hafen von Tokio bildet in der Bucht von Tokio zusammen mit dem Westen von Yokohama und dem Osten von Chiba eine Einheit. 25 Prozent aller Industriegüter werden hier weltweit verschifft. Der jährliche Güterumschlag beträgt damit über 360 Millionen Tonnen. Die meisten Industrien sind am Hafen angesiedelt, was die rasche Expansion der baulichen Maßnahmen erklärt.

Der Aufbau eines modernen Straßennetzes gestaltete sich besonders schwierig, da die Straßen der alten Hauptstadt Japans sehr eng und gewunden und für den Autoverkehr völlig ungeeignet waren. Vor den Olympischen Sommerspielen 1964 wurden jedoch strahlenförmig vom Stadtzentrum ausgehende Hauptverkehrsstraßen und Stadtautobahnen gebaut. Sie verbinden das Zentrum Tokios mit einem System von acht breiten Ringstraßen.

Seit den 1960er Jahren ist der private Autoverkehr allmählich zugunsten des öffentlichen Busverkehrs reduziert worden. Der Straßenverkehr wird auch heute noch durch die meist engen Straßen und die fehlenden Parkplätze eingeschränkt. Die rund 300 Kilometer der kostenpflichtigen Tokioter Autobahnen werden heute von der privatrechtlichen Shuto Kōsokudōro K.K. („Hauptstadt-Autobahnen“ AG; engl. "Metropolitan Expressway Co., Ltd.") betrieben.

Seit der Eröffnung des ersten Streckenabschnitts der Tokioter U-Bahn am 30. Dezember 1927 entstand ein Netz mit zwölf Linien und einer Gesamtlänge von über 300 Kilometern, eines der größten der Welt. Die U-Bahn von Tokio ist eine der am stärksten in Anspruch genommenen U-Bahnen weltweit. Im Unterschied zu den meisten Metros anderer Städte werden auf den verschiedenen Linien der Tokioter U-Bahn Fahrzeuge mit verschiedenen Spurweiten, Stromabnehmersystemen und Spannungen eingesetzt, sodass diese Fahrzeuge jeweils nur auf ihren Linien verkehren können. Die U-Bahn wird von zwei Betrieben geleitet, der "Tokyo Metro" und der "Toei" (Verkehrsamt der Präfektur Tokio).

Die Stadt ist auch von einem dichten Netz von S-Bahnen der JR East und privaten Vorortbahnen durchzogen. Wichtigste S-Bahnen sind die Yamanote-Linie und die Chūō-Hauptlinie. Der öffentliche Verkehr wird außerdem von städtischen und privaten Bussen sowie der Toden Arakawa-Linie, der letzten verbliebenen Straßenbahn, und diversen alternativen Schienensystemen wie dem Nippori-Toneri Liner bewältigt. Über 80 Prozent der beförderten Personen werden in Tokio mit dem Bahnnetz befördert. Trotzdem gibt es in Tokio aufgrund des hohen Verkehrsaufkommens noch große Kapazitätsprobleme.

Weil der Platz knapp ist, arbeiten einige Fahrschulen auf Flachdächern. Die älteste Fahrschule liegt im Norden Tokios, arbeitet seit 1966 auf dem Dach eines Supermarktes („Ito-Yokado“) und unterhält dort 35 Autos mit Fahrlehrern, die ein Verkehrswegenetz mit nachgebauten Kreuzungen und Zebrastreifen nutzen. Der Motorrad-Unterricht wurde wegen der Absturzgefahr gestrichen. Diese Idee haben längst auch andere japanische Städte aufgegriffen.

Tokio ist der Mittelpunkt des Bildungswesens in Japan. Die zahlreichen staatlichen und privaten Universitäten der Metropolregion machen ein Viertel aller Universitäten des Landes aus, an denen ungefähr ein Drittel aller Studenten Japans eingeschrieben sind.

Die Universität Tokio ("Tōkyō daigaku", bekannt unter der Abkürzung "Tōdai") ist die älteste und renommierteste staatliche Universität Japans. Sie besitzt fünf Campus – vier in den Tokioter Stadtbereichen "Hongo", "Komaba", "Shirokane" und "Nakano", und einen in "Kashiwa" in der Präfektur Chiba – sowie zehn Fakultäten mit insgesamt circa 28.000 Studenten, von denen 2100 Ausländer sind.

Die Keiō-Universität ist Japans älteste für höhere Bildung. Sie wurde 1858 von Fukuzawa Yukichi als Privatschule für westliche Studien gegründet und richtete 1890 ihre erste Fakultät ein.

Die Waseda-Universität liegt im Norden des Stadtbezirks Shinjuku. Die Schule wurde von dem gelehrten Samurai Ōkuma Shigenobu im Jahre 1882 gegründet und 1902 zu einer vollwertigen Universität erklärt.

Weitere Universitäten sind die Technische Hochschule Tokio, die Hōsei-Universität, die Rikkyō-Universität, die Sophia-Universität, die Tōkyō Joshi Daigaku (engl. "Tokyo Woman’s Christian University") und die Landwirtschaftsuniversität Tokyo. Einige der über 100 Universitäten mit Sitz in der Präfektur Tokio, die einen Campus oder Außenstellen in Tokio unterhalten, sind die Hitotsubashi-Universität, die Chūō-Universität, die Tōkyō Geijutsu Daigaku (engl. "Tokyo University of the Arts") und die Kunsthochschule Musashino. Tokio ist außerdem Sitz der Universität der Vereinten Nationen (UNU).

Nahe dem Kaiserpalast befinden sich die Nationale Parlamentsbibliothek und das Staatsarchiv.

In Tokio sind zahlreiche bekannte Persönlichkeiten geboren. Dazu gehören unter anderem die US-amerikanische Sängerin Nikka Costa, die US-amerikanischen Filmschauspielerinnen und Schwestern Joan Fontaine und Olivia de Havilland, der Maler Takashi Murakami, der US-amerikanische Japanologe Edwin O. Reischauer, die japanische Prinzessin Takamatsu, die norwegische Schauspielerin und Regisseurin Liv Ullmann, der deutsche Fernsehjournalist und Moderator Ulrich Wickert sowie der deutsche Künstler Jonathan Meese.




</doc>
<doc id="5080" url="https://de.wikipedia.org/wiki?curid=5080" title="Theismus">
Theismus

Theismus (gr. /ϑεός "theós" „Gott“) bezeichnet den Glauben an Götter, wobei der Monotheismus den Glauben an einen Gott und der Polytheismus den Glauben an mehrere Götter bezeichnet.

Der Theismus begreift Gott als Schöpfer der Welt, der sie auch erhält und lenkend in sie eingreift. Damit unterscheidet sich der Theismus vom Deismus, der jeden Eingriff eines Gottes in die Welt bestreitet. Der Gott theistischer Religionen ist überwiegend transzendent, teilweise hat er auch immanente Elemente/Erscheinungsformen. Er wirkt zwar in der Welt (etwa durch Wunder und Offenbarungen), ist jedoch in der Substanz komplett von ihr verschieden (Dualismus von Schöpfer und Schöpfung). Darin unterscheidet der Theismus sich vom Pantheismus und Panentheismus.

Die Bezeichnung wurde als ein kategorisierender Begriff der Religionsphilosophie in der Aufklärung (18. Jahrhundert) geprägt gegenüber dem Atheismus, aber auch als Abgrenzung zum Deismus.

Innerhalb des Theismus kann unterschieden werden zwischen

Theistische Religionen sind unter anderen
sowie einige historische, meist dem Henotheismus zuzuordnende Religionen; unter anderen

Ein wichtiger Einwand gegen den theistischen Gottesbegriff entsteht aus dem Theodizeeproblem. Wenn ein Gott lenkend und leitend in den Lauf der Welt eingreifen kann, so stellt sich die Frage, warum er es dann zulässt, dass Unschuldige großes Leid erfahren. Dabei werden bei diesem Gott die Eigenschaften Allmacht und Allgüte vorausgesetzt.

Ein mögliches Eingreifen eines Gottes in die Welt wird auch deswegen von einigen abgelehnt, weil dies darauf hinausliefe, „aus Gott ein Seiendes neben anderen zu machen“.

Der Theismus wird unterschieden von anderen Positionen zur Existenz Gottes oder zum Wesen des Göttlichen, beispielsweise
Eine scharfe Abgrenzung ist häufig nicht möglich, da es vielfache Überschneidungen gibt.





</doc>
<doc id="5081" url="https://de.wikipedia.org/wiki?curid=5081" title="Thymiane">
Thymiane

Die Thymiane ("Thymus", von altgriechisch θύμος "thýmos") oder Quendel sind eine Pflanzengattung innerhalb der Familie der Lippenblütengewächse (Lamiaceae). Einige Arten und ihre Sorten sind Heil- und Gewürzpflanzen, am bekanntesten ist der Echte Thymian ("Thymus vulgaris"). Auch der Sand-Thymian ("Thymus serpyllum"), der Zitronen-Thymian ("Thymus" ×"citriodorus") und der Breitblättrige Thymian ("Thymus pulegioides") sind in der abendländischen Kultur und Pflanzenheilkunde von Bedeutung. Nicht zur Gattung "Thymus" gehört der nahe verwandte Kopfige Thymian ("Thymbra capitata").

Thymian-Arten sind ausdauernde Halbsträucher oder Sträucher. Gelegentlich scheinen sie krautig zu sein, sind jedoch zumindest an der Basis verholzt. Sie wachsen aufrecht bis niederliegend, sind gelegentlich rasenbildend und an den Stängeln wurzelnd. Die Stängel können rundum behaart sein oder aber nur an zwei gegenüberliegenden Seiten oder an den Kanten Behaarung aufweisen.

Die Laubblätter sind einfach und ganzrandig oder gelegentlich gezähnt. Oftmals sind die Ränder umgebogen. Die Behaarung der Blätter ist innerhalb der Gattung sehr variabel, sie können komplett unbehaart bis zu vollständig behaart sein.

Die Blütenstände sind ährenartig zusammengesetzt und scheinwirtelig auseinandergezogen oder können köpfchenförmig sein. Sie enthalten Tragblätter, die entweder in der Form den Laubblättern gleichen oder auch sehr unterschiedlich gestaltet sein können. Die Blüten können gestielt oder sitzend sein, meist werden sie von kleinen Vorblättern begleitet, die an der Basis des Blütenstiels stehen.

Die zwittrigen Blüten sind zygomorph und fünfzählig mit doppelter Blütenhülle. Der Kelch ist mehr oder weniger glockenförmig oder zylindrisch, von meist zehn Adern durchzogen und deutlich zweilippig, wobei beide Lippen manchmal nahezu gleichgestaltig sind. Die obere Lippe ist mit drei dreieckigen Zähnen besetzt, die jedoch manchmal zu einem einzigen Zahn reduziert sind. Die zwei langen dreieckigen Zähne der Unterlippe können nach oben gebogen oder abgespreizt sein. Der Kelchschlund ist bärtig behaart. Die Krone ist mehr oder weniger röhrenförmig und in zwei Lippen unterteilt, die manchmal nahezu gleichgestaltig sein können. Die Kronröhre ist manchmal sehr lang und kann dann bis zu 20 mm lang werden. Der Kronsaum ist in vier Lappen unterteilt. Die Farbe der Krone kann Weiß, Creme, Pink oder Violett sein, oftmals finden sich im Kronschlund oder an der Basis der Kronlappen durchscheinende Punkte. Die obere Lippe ist mehr oder weniger gerundet, gebuchtet und gerade. Die Unterlippe und die seitlichen Lappen sind rechteckig bis nahezu kreisförmig, abgerundet und stehen senkrecht auf der Kronröhre.

Die vier Staubblätter setzen in der oberen Hälfte der Kronröhre an und können über diese hinaus stehen. Die Staubbeutel bestehen aus zwei parallel zueinander stehenden Theken. Die Pflanzen können gynodiözisch sein, dann sind die Staubblätter zurückgebildet oder nicht ausgeprägt. Die Spitze des Griffels ist verzweigt.

Die Früchte sind eiförmige Nüsschen, die runde Samen enthalten.

Verschiedene Arten und ihre Sorten werden in Gärten und Gartenbaubetrieben angebaut. Die Thymiane bevorzugen helle und trockene Standorte mit nährstoffarmen und sandigen Böden und finden sich an Wegrändern, auf trockenen Wiesenflächen und auf Mauern.

Im antiken Griechenland diente Thymian als Zusatz zu Räuchermitteln, mit denen man eine Anregung von Geist und Gemüt erzielte. Im Mittelalter wurde Thymian bereits als wertvolle Heilpflanze genutzt, zum Beispiel bei Asthma oder Atemnot.

Heute kommt Thymian in unterschiedlicher Art und Weise zum Einsatz. Verwendung finden Arten der Gattung "Thymus" als getrocknete oder frische Küchenkräuter, als Quelle von ätherischen Ölen und Oleoresinen, als Gartenpflanze sowie als Arzneipflanze in der Volksmedizin, der Homöopathie und verstärkt auch in der klassischen Medizin. Dabei ist jedoch nur ein kleiner Teil der Arten von kommerzieller Bedeutung, nämlich "Thymus mastichina", der Sand-Thymian ("Thymus serpyllum"), der Echte Thymian ("Thymus vulgaris") und der Joch-Thymian ("Thymus zygis"), zusätzlich noch der nach der hier verwendeten Systematik nicht mehr zur Gattung zählende Kopfige Thymian ("Thymbra capitata").

Für die Gewinnung der pharmazeutischen Droge Thymian (Thymi herba) sind nach dem Europäischen Arzneibuch nur die beiden Arten "Thymus vulgaris" und "Thymus zygis" oder eine Mischung beider Arten erlaubt. Stammpflanze der Droge Quendelkraut ist "Thymus serpyllum".

Der wirksamkeitsbestimmende Inhaltsstoff des Echten Thymians ist das ätherische Öl (1,0–2,5 %). Dieses besteht vorwiegend aus den Monoterpenen Thymol (25–50 %) und Carvacrol (3–10 %) sowie p-Cymen, Borneol und Linalool. Das ätherische Öl hat eine sekretolytische, sekretomotorische und bronchospasmolytische Wirkung. Darüber hinaus ergibt sich aufgrund des Thymols und Carvacrols über eine Hemmung der Cyclooxygenase ein entzündungshemmender Effekt.

Die Gattung "Thymus" wurde durch Carl von Linné aufgestellt. Synonyme für "Thymus" sind: "Cephalotos" , "Mastichina" , "Serpyllum" 

Die Gattung "Thymus" gehört zur Subtribus Menthinae aus der Tribus Mentheae in der Unterfamilie Nepetoideae innerhalb der Familie Lamiaceae. 

Die Verbreitungsgebiete liegen in Afrika, Europa und im gemäßigten Asien. Das Zentrum der Artenvielfalt ist der Mittelmeerraum.

Die Gattung "Thymus" wird in acht Sektionen gegliedert, die zum Teil in Untersektionen unterteilt sind und insgesamt 214 bis 245 Arten enthalten:

Sektion "Micantes" :

Sektion "Mastichina" :

Sektion "Piperella":

Sektion "Teucrioides" :

Sektion "Pseudothymbra" :

Sektion "Thymus": 
Sektion "Hyphodromi" : 

Sektion "Serpyllum" :

Nicht mehr zur Gattung "Thymus" gehört:

Es gibt zahlreiche Hybriden. Hier eine Auswahl:

Bereits in Schriften aus dem 1. Jahrhundert werden Thymiane erwähnt. So sprach beispielsweise Pedanios Dioscurides von einer Pflanze namens "Thymo". Laut einer Übersetzung aus dem 16. Jahrhundert der Werkes von Dioscurides ist damit jedoch eine Pflanze der Gattung "Satureja" gemeint. Auch Plinius der Ältere erwähnte in seiner "Naturalis historia" eine weiße und eine schwarze Form des Thymians.

Sein Wissen über die Thymiane hat Carl von Linné größtenteils von anderen Autoren übernommen, in seinen Veröffentlichungen wechselt das Konzept der Gattung oft. Im Jahre 1737 beschrieb er in "Hortus Cliffortianus" sechs Arten, von denen zwei heute nicht zur Gattung, sondern zu "Satureja" beziehungsweise "Acinos" gezählt werden. In "Hortus Upsaliensis" aus dem Jahre 1747 werden nur noch zwei Arten, nämlich "Thymus vulgaris" und "Thymus mastichina" erwähnt. Mit der Einführung der binären Nomenklatur in der ersten Auflage des Werkes "Species Plantarum" beschrieb er hingegen wieder acht Arten und den heutigen "Thymus mastichina" als "Satureja mastichina". Bereits in der zweiten Auflage ist diese Art wieder den Thymianen zugeordnet, dafür ist "Thymus pulegioides" nicht mehr aufgeführt. Eine weitere Art, "Thymus piperella", wurde durch Linné 1767 in der 12. Auflage der "Systema Naturae" beschrieben.

Die erste nach Linné neu beschriebene Art der Gattung ist die 1804 von Felix de Avellar Brotero beschriebene "Thymus caespititius". Weitere Arten aus Portugal wurden 1809 von Johann Centurius von Hoffmannsegg und Johann Heinrich Friedrich Link beschrieben. Eine erste Einteilung der Gattung in Sektionen stammt von George Bentham, der 1834 die Sektionen "Mastichina", "Serpyllum" und "Pseudothmbra" unterteilt. 

Weitere Erstbeschreibungen stammen vom Schweizer Botaniker Pierre Edmond Boissier, der vor allem Arten von der Iberischen Halbinsel, aber auch aus dem Norden Afrikas, Griechenlands und der Türkei beschrieb und auch die Sektion "Pseudothymbra" aufstellte. Eine Unterteilung der Gattung in die fünf Sektionen "Mastichina", "Zygis", "Piperella", "Serpyllum" und "Pseudothymbra" stammt aus dem Jahr 1868 von Heinrich Moritz Willkomm und Johan Martin Christian Lange. Weitere Sektionskonzepte stammen von John Isaac Briquet, der die Lippenblütler in Adolf Englers "Die Natürlichen Pflanzenfamilien" bearbeitete und zwei Sektionen aufstellte, sowie von Josef Velenovský, der 1906 eine Monographie der Gattung veröffentlichte und dort zehn Sektionen anerkannte.

Ein Großteil der Autoren der jüngeren Zeit, die Beiträge zur Erforschung der Gattung geliefert haben, stammt aus Spanien. Jedoch gibt es auch eine bedeutende Zahl von Forschern, die außerhalb Spaniens an der Erforschung der Gattung arbeiten.




</doc>
<doc id="5083" url="https://de.wikipedia.org/wiki?curid=5083" title="Thelonious Monk">
Thelonious Monk

Thelonious Sphere Monk (* 10. Oktober 1917 in Rocky Mount, North Carolina; † 17. Februar 1982 in Weehawken, New Jersey) war ein US-afroamerikanischer Jazz-Musiker, der als Pianist und Komponist bekannt wurde.

Er war neben Charlie Parker, Dizzy Gillespie, Charlie Christian und Kenny Clarke einer der Mitbegründer des Bebops. Mit seinem eigenwilligen Klavierstil und seinen unverwechselbaren Kompositionen gilt Monk als einer der großen Individualisten und bedeutenden Innovatoren des Modern Jazz.

Thelonious Monk zog als Kind Anfang der 1920er Jahre mit seiner Familie in den südwestlich von Harlem gelegenen und weit überwiegend von Afro-Amerikanern bewohnten New Yorker Stadtteil San Juan Hill, der dann in den 1950er Jahren abgerissen wurde. Der Vater, Thelonious Monk Sr., verließ die Familie jedoch bereits wenige Jahre später. So lag die Verantwortung für Erziehung und Lebensunterhalt von Thelonious und seinen beiden Geschwistern allein bei seiner Mutter Barbara, die als Angestellte für die Stadtverwaltung arbeitete. Monk wurde von seiner Mutter in seinen musikalischen Neigungen unterstützt und erhielt bereits als Kind Klavierunterricht. Im Alter von dreizehn Jahren hatte er einen Klavierwettbewerb im Harlemer Apollotheater so oft gewonnen, dass er von der weiteren Teilnahme ausgeschlossen wurde.

Die Stadt New York entwickelte sich in Monks Jugendzeit zu einer der großen Jazzmetropolen. Besonders der Stadtteil Harlem wurde mit seinen vielen Clubs zu einem Brennpunkt dieser Entwicklung. So wuchs Monk in einer musikalisch sehr lebhaften Umgebung auf und hörte viele Jazzmusiker „live“. Als frühe Einflüsse gelten Duke Ellington, Fats Waller, Earl Hines und der Stride-Pianist James P. Johnson, der in der Nachbarschaft der Familie Monk lebte.

Erste Erfahrungen sammelte Monk, wie viele Musiker jener Zeit, als Pianist auf „House-Rent-Parties“. Diese waren in von Schwarzen bewohnten Stadtteilen weit verbreitet. Mieter, die ihre Miete "(Rent)" nicht aufbringen konnten, luden die Menschen ihrer Nachbarschaft ein, sorgten für musikalische Unterhaltung und ließen dann „den Hut herumgehen“. Davon bezahlten sie die Musiker und die Miete. Daneben begleitete Monk auch den Gesang seiner Mutter in der Kirche auf der Orgel. Ein New Yorker Auftritt des Klavier-Virtuosen Art Tatum im Jahr 1932 hinterließ bei dem fünfzehnjährigen Monk einen tiefen Eindruck.

Mit siebzehn Jahren verließ Monk die High School. Danach ging er mit einer Wanderpredigerin zwei Jahre lang als Pianist auf Tour. Er trat dabei auch in Kansas City auf, das damals eine pulsierende Jazz-Stadt war. Sie ist u. a. die Heimat der Count Basie Band und der Pianistin Mary Lou Williams. Diese hörte Monk spielen, erkannte sein Talent und ermutigte ihn in seinen musikalischen Ambitionen. Ihr zufolge verfügte Monk schon damals über einen rhythmisch und harmonisch sehr eigenwilligen Stil. Den Eindruck, den Monks Musik auf sie und andere Musiker machte, beschreibt Mary Lou Williams später so: „Wir nannten es damals ‚Grusel-Musik‘ und behielten es uns fast ausschließlich für die frühen Morgenstunden vor, wenn wir Musiker unter uns waren. Wieso ‚Grusel-Musik‘? Weil die schauerlichen Akkorde uns an Musik erinnerten, die in ‚Frankenstein‘ und ähnlichen Gruselfilmen vorkam.“

Wieder zurück in New York City, schlug sich Monk einige Jahre mit Gelegenheitsjobs als Pianist durch. Anfang der 1940er Jahre wurde er Hauspianist im Harlemer Club Minton’s Playhouse, der Treffpunkt eines losen Verbandes junger Musiker war, die bei Jam-Sessions nach neuen musikalischen Wegen abseits des Swing-Mainstreams suchten. Neben Charlie Parker, Dizzy Gillespie, Charlie Christian und Kenny Clarke zählte Monk damit zu dem Kreis der Musiker, die später als Keimzelle eines neuen Stils – des Bebop – und damit des Modern Jazz gelten sollten.

Während Parker und Gillespie später zu den Protagonisten des Bebop avancierten, blieb Monk diese Anerkennung jedoch zunächst versagt. Dies lag zum einen an Monks individualistischer, für viele nur schwer nachvollziehbaren Spielweise, zum anderen aber auch an seiner notorischen Unzuverlässigkeit, die selbst bei großzügiger Auffassung von Pünktlichkeit kaum regelmäßige Proben mit ihm möglich machten. Zwar wurde er 1946 von Dizzy Gillespie als Pianist für dessen Big Band engagiert, da er jedoch wiederholt verspätet oder überhaupt nicht zu Proben oder Auftritten erschien, wurde er gefeuert.

Der Tenorsaxophonist Coleman Hawkins war in dieser Zeit einer der wenigen Bandleader, die Monk als Pianisten engagierten. Hawkins, ein Veteran des traditionellen Swing-Stils, wurde dafür jedoch heftig kritisiert, da das rhythmisch und harmonisch unkonventionelle Spiel Monks beim Publikum auf schroffe Ablehnung stieß. Trotz dieser Widerstände hielt Hawkins den Pianisten in seinem Quartett und machte im Jahr 1944 mit Monk dessen erste Studioaufnahmen.

Da Monk noch immer bei seiner Mutter lebte, die auch für seinen Lebensunterhalt sorgte, musste er nicht aufgrund wirtschaftlicher Zwänge künstlerische Zugeständnisse machen oder seinen eigensinnigen Lebensrhythmus an die Gewohnheiten seiner Mitmenschen anpassen. Stattdessen konnte er sich ungehindert ausschließlich seiner musikalischen Leidenschaft widmen und seine kompositorischen Ideen verwirklichen.

Zu dieser Zeit hielt Monk auch eine Art „Hausseminare“ für befreundete Musiker ab. Der junge Miles Davis, Sonny Rollins, Bud Powell und andere gingen in der Wohnung der Familie Monk ein und aus und ließen sich von Thelonious dessen Kompositionen am Klavier erklären. Dabei achtete er penibel darauf, dass seine oft sehr komplizierten Stücke korrekt gespielt werden. Miles Davis, der ein Jahrzehnt später mit Monks Komposition "’Round Midnight" seinen Durchbruch beim breiten Publikum erleben wird, sagte später, dass diese Lektionen für seine musikalische Entwicklung von großer Bedeutung gewesen seien.

Erst 1947, im Alter von 30 Jahren, nahm Monk durch die Vermittlung des Saxophonisten und Talentscouts Ike Quebec seine erste Schallplatte als Bandleader für das aufstrebende Plattenlabel Blue Note Records auf, später erschienen unter dem Titel Genius Of Modern Music. Seine Partner bei den Aufnahmen der folgenden Jahre waren u. a. der Vibraphonist Milt Jackson und die Schlagzeuger Art Blakey und Max Roach.

Im gleichen Jahr heiratete er Nellie Smith (1921–2002), ein Mädchen aus der Nachbarschaft. Aus der Ehe gingen zwei Kinder hervor, Thelonious und Barbara (1953–1984).

Monk hatte zu dieser Zeit bereits viele seiner Stücke komponiert, die erst Jahre oder Jahrzehnte später Anerkennung erlangen würden. Dazu zählen seine bekanntesten Kompositionen "Well, You Needn’t", "’Round Midnight" und "Straight, No Chaser". Auch sein individualistischer Klavierstil mit dem für ihn typischen perkussiven Anschlag war jetzt bereits voll ausgeprägt. Seine künstlerische Entwicklung war damit weitgehend abgeschlossen: Im Laufe seiner weiteren Karriere erfuhr seine Musik keine wesentlichen stilistischen Veränderungen und Brüche mehr. Viele der auf Blue Note veröffentlichten Aufnahmen stellen mustergültige Interpretationen seiner Kompositionen dar und gelten heute als Klassiker.

Monks erste Aufnahmen unter eigenem Namen verkauften sich jedoch nur schleppend. Seine eigenwillige Musik traf beim Publikum auf Unverständnis. Auch unter Musikerkollegen und Musikkritikern blieb er umstritten. Häufig wurde ihm sogar mangelndes technisches Können unterstellt.

Auch ein Vorfall Ende 1951 behinderte Monks Karriere in den folgenden Jahren empfindlich: Bei einer Polizeikontrolle wurden in einem von Monk geparkten Auto Drogen gefunden. Da er nicht gegen den wirklichen Drogenbesitzer – seinen Freund Bud Powell – aussagen wollte, wurde er zu 60 Tagen Gefängnis verurteilt. Weit schwerer wog jedoch ein mehrjähriger Entzug der „Cabaret Card“, die damals für Engagements in Night Clubs in New York erforderlich war. Dadurch konnte Monk jahrelang kein Club-Engagement in seiner Heimatstadt bekommen.

Das Label Prestige machte Monk 1952 ein Angebot für Aufnahmen. Da sich seine bisherigen Platten nur schlecht verkauft hatten, ließ Blue Note Records ihn ziehen. Das auf einigen seiner Prestige-Aufnahmen zu hörende, deutlich verstimmte Klavier lässt entweder auf eine gewisse Nachlässigkeit bei der Produktion schließen oder Monk setzte es bewusst ein. Doch auch während dieser Periode macht Monk einige bemerkenswerte Aufnahmen. Hervorzuheben sind seine Alben mit Sonny Rollins und die Aufnahmen vom Heiligabend 1954 mit Miles Davis als Leader, Milt Jackson, Percy Heath und Kenny Clarke: Diese gelten vielen Kennern als eine Sternstunde des Jazz.

Der Jazzproduzent und Monk-Fan Orrin Keepnews gründete 1953 das Label Riverside. Für nur 108 Dollar kaufte er Monk 1954 aus dessen Vertrag bei Prestige heraus. Doch er zögerte zunächst, Aufnahmen mit Monks Eigenkompositionen zu veröffentlichen. In der Absicht, das Publikum schrittweise an Monks exzentrische Musik heranzuführen, wurden stattdessen zwei LPs mit Standards bzw. Interpretationen von Stücken Duke Ellingtons veröffentlicht, die bei Publikum und Kritik zumindest bescheidene Achtungserfolge erzielten.

Einen Wendepunkt in Monks Karriere stellte das Jahr 1957 dar. Zum einen erlangte er auf Betreiben der einflussreichen Baroness Pannonica de Koenigswarter seine „Cabaret Card“ (Auftrittsgenehmigung für New York) zurück, die er 1951 verloren hatte. Diese ehemalige Diplomatengattin aus dem Hause Rothschild kümmerte sich in der Art einer Patronin um Jazz-Musiker. Dies ermöglichte Monk ein erfolgreiches mehrmonatiges Engagement im New Yorker Five Spot Café mit dem Tenorsaxophonisten John Coltrane.

Zum anderen wurde das dritte auf Riverside veröffentlichte Album "Brilliant Corners" zu einem Meilenstein in Monks Diskografie: Begleitet von dem Tenorsaxophonisten Sonny Rollins, dem Altsaxophonisten Ernie Henry, dem Bassisten Oscar Pettiford und dem Schlagzeuger Max Roach entstand ein sorgfältig konzipiertes und produziertes Album, auf dem sich Monks Musik voll entfaltete. Großen Anteil daran hatte Sonny Rollins, der als früherer Besucher von Monks „Seminaren“ mit dessen Musik bestens vertraut war und diese entsprechend zu spielen verstand. Höhepunkte waren die vertrackte Neukomposition "Brilliant Corners" und der ausgedehnte Blues mit dem lautmalerischen Titel "Ba-Lue Bolivar Ba-Lues-Are". Dieser Titel bezog sich auf das Bolivar-Hotel in New York, in dem die Baroness de Koenigswarter in einer Suite residierte. Als zusätzlichen Dank für ihre Unterstützung nannte Monk eine seiner schönsten Balladen, in der er mit der rechten Hand Celesta und mit der linken Klavier spielte, "Pannonica". Mit diesem Album gelang Monk endlich der Durchbruch beim Publikum. Im Herbst dieses Jahres trafen Monk, sein ehemaliger Mentor Coleman Hawkins und erneut Coltrane aufeinander, veröffentlicht auf der "Riverside"-LP "Monk’s Music".

Im weiteren Verlauf der 1950er Jahre nahm Monk zahlreiche bedeutende Schallplatten auf. Darunter waren Einspielungen mit Musikern wie John Coltrane und Gerry Mulligan und Solo-Einspielungen. Erfolgreiche Tourneen durch die USA und Europa schlossen sich an. 1958 wurde Monk im Down Beat Critics Poll erstmals zum besten Pianisten gekürt. Im Februar 1959 kam es zu einem Konzert in der renommierten New Yorker Town Hall, bei dem Monk seine Musik in den orchestralen Bearbeitungen des Arrangeurs Hall Overton mit einem Tentett aufführte.

Im Jahr 1960 wurde der Tenorsaxophonist Charlie Rouse Monks fester Partner in seinem Quartett. Rouse war zwar kein Saxophonist vom Format eines John Coltrane oder eines Sonny Rollins, aber seine Spielweise fügt sich ideal in Monks Klangwelt ein. Diese Verbindung sollte bis Ende der 1960er Jahre bestehen bleiben.

Mit einem Vertragsabschluss beim Schallplattenlabel Columbia, das zu CBS gehörte und für das bereits andere Jazz-Größen wie Miles Davis oder Dave Brubeck arbeiteten, wurde Monk 1962 endgültig zu einem international gefeierten Jazz-Star. Die ersten für Columbia aufgenommenen Schallplatten zeigten das Thelonious-Monk-Quartett mit Charlie Rouse am Tenorsaxophon, dem Bassisten John Ore und dem Schlagzeuger Frankie Dunlop in gereifter, perfekt aufeinander eingespielter Form und zählen mit zu seinen besten Aufnahmen. Ende 1963 kam es im New Yorker Lincoln Center zu einer zweiten erfolgreichen Aufführung seiner Musik in Big-Band-Besetzung. Seine Proben mit dem Arrangeur Hall Overton wurden vom Fotografen W. Eugene Smith in Bild- und Ton-Dokumenten festgehalten, die 2009 im "Jazz Loft Project" veröffentlicht wurden. Monk unternahm nun Tourneen nach Europa und sogar bis nach Japan. Das Time-Magazine zeigte ihn im Februar 1964 auf der Titelseite.

Monks kompositorische Aktivität ging im Verlauf dieser Zeit jedoch mehr und mehr zurück. Aufnahmen neuer Kompositionen wurden immer seltener. Einige seiner für Columbia aufgenommenen Schallplatten enthielten kein einziges neues Stück. Abgesehen von einigen Improvisationen stammte seine letzte Komposition aus dem Jahr 1967. Er spielte in dieser Zeit – anders als in den 1950er Jahren – auch nur noch selten mit Musikern außerhalb seines festen Quartetts und erhielt dadurch weniger Impulse von außen. So erstarrte die einst so unkonventionelle und aufregende Musik Monks allmählich in einer vorhersehbaren Formelhaftigkeit.

Gegen Ende der 1960er Jahre erhielten Monks Schallplatten nur noch mittelmäßige Kritiken in der Presse, und auch die Verkaufszahlen gingen zurück. Aus kommerziellen Erwägungen drängte ihn Columbia 1968, ein Album mit Orchester-Begleitung aufzunehmen. Die sehr glatt geratenen Arrangements von Oliver Nelson wurden Monks Musik jedoch in keiner Weise gerecht. Den Vorschlag, eine Platte mit Beatles-Kompositionen einzuspielen, lehnte er ab. Daraufhin beendete Columbia die Zusammenarbeit mit Monk. Sein Quartett löste sich in den Folgejahren allmählich auf. Danach machte er mit wechselnden Begleitern nur noch vereinzelt Aufnahmen für kleinere Labels. Doch auch während dieser Zeit blieb er sich stilistisch treu und spielte auf hohem Niveau.

Nach 1970 verschwand Monk offenbar aus gesundheitlichen Gründen von der Bühne. Der ohnehin introvertierte Musiker zog sich mehr und mehr zurück. Er zeigte Anzeichen von Depression und hörte nach und nach mit dem Klavierspielen auf. In den letzten Jahren seines Lebens rührte er sein Instrument nicht mehr an und verfiel in Apathie. Seine letzte Aufnahme stammt aus dem Jahr 1971, seinen letzten öffentlichen Auftritt hatte er 1976.

Monk wird von Zeitgenossen als introvertierter Exzentriker beschrieben. Er fiel äußerlich durch seine hünenhafte Gestalt, seine Vorliebe für ungewöhnliche Kopfbedeckungen und Sonnenbrillen sowie seinen Ziegenbart auf. Damit prägte er neben Dizzy Gillespie das Bild des Hipsters der 1940er und 1950er Jahre.

In der Öffentlichkeit war Monk äußerst wortkarg und folgte ausschließlich seinem eigenen Lebensrhythmus, was sich unter anderem so äußern konnte, dass er schlief, wann und wo es ihm beliebte. Gesellschaftliche Konventionen wie z. B. Pünktlichkeit hatten für ihn nur bedingt Gültigkeit. Seine Unzuverlässigkeit zu Beginn seiner Laufbahn ist geradezu legendär. Seinen Mitmenschen gegenüber zeigte er sich oft desinteressiert. Selbst gegenüber der Musik anderer Musiker war er gelegentlich ignorant oder äußerte sich sogar abfällig darüber. Mochte Monk auch ein liebevoller Ehemann und Vater sein, so war er im Privaten unzuverlässig und unfähig, Verantwortung für seine Familie zu übernehmen. Als seine Frau Nellie aufgrund ihrer Schwangerschaft ihren Job aufgeben musste, war von Monk keine finanzielle Unterstützung zu erwarten. Die werdende Familie musste zurück in das nun völlig überfüllte Appartement von Monks Mutter ziehen. Während dieser schwierigen Zeit war Monk tagelang verschwunden. Auch als sein Sohn schließlich am 27. Dezember 1949 geboren wurde, war der Musiker nicht aufzufinden.

Wie viele Musiker seiner Generation nahm Thelonious Monk Drogen. In den schwarzen Ghettos der 1930er Jahre gehörten Drogen zum Alltag, auch Monk wuchs in einer solchen Umgebung auf: In den frühen 1930er Jahren wurde der Stadtteil San Juan Hill zu einem Hauptumschlagplatz für Heroin. Möglicherweise durch seine Kindheit prädisponiert, suchte Monk in beruflich und familiär problematischen Phasen Ablenkung im Rausch harter Drogen. Mit Heroin betäubte er etwa die Zukunftsängste, hervorgerufen durch die Geburt seines Sohnes und die neue Verantwortung als Familienvater. Von der Forschung ist zudem eine Wechselwirkung zwischen Monks psychischer Störung und seinem Drogenkonsum hergestellt worden. Dass der Pianist ein starker Trinker war, ist vermutlich ein Nebeneffekt seiner manischen Depression, die wiederum durch den hohen Alkoholkonsum verstärkt wurde. Gleiches gilt für Monks Lieblingsdroge Benzedrin (Speed), deren Einnahme die Symptome der Krankheit verstärken kann. Möglicherweise kann man also die Ruhelosigkeit, Schlaflosigkeit und Unsicherheit Monks zu einem Teil der Kombination aus Amphetaminen und seiner bipolaren Störung zuschreiben.

Seine Angehörigen schilderten den in der Öffentlichkeit so schweigsamen und einzelgängerischen Monk als einen in seiner vertrauten Umgebung kommunikativen und geselligen Menschen. Er spielte gerne Karten und galt als ausgezeichneter Schach- und Tischtennis-Spieler. Thelonious Monk führte nicht nur über Jahrzehnte ein intaktes Familienleben. Mit Bud Powell, Coleman Hawkins und der Baroness de Koenigswarter verband ihn auch eine lebenslange enge Freundschaft. Er war außerdem ein durchaus guter Geschäftsmann, der sich nie unter Wert verkaufte.

Die meiste Zeit seines Lebens lebte Monk in der Wohnung seiner Kindheit und verließ New York nur ungern. So beharrlich und souverän er in seiner Musik war, so unsicher, gar hilflos war er oft außerhalb seiner vertrauten Umgebung. Nachdem er 1959 auf dem Bostoner Flughafen von der Polizei aufgegriffen und wegen seines verwirrten Verhaltens für drei Tage in psychiatrische Beobachtung gegeben wurde, ließ Monk sich auf Reisen meist von seiner Frau Nellie begleiten, die ihm auch oft bei seinen seltenen Interviews zur Seite stand. Sein Sohn Thelonious Jr. berichtet davon, dass Monk tagelange Phasen tiefer Depression oder Euphorie, gefolgt von extremen Erschöpfungszuständen durchlief. Er wurde deswegen mehrmals von seiner Familie ins Krankenhaus eingeliefert, was aber nicht öffentlich gemacht wurde.

Die Musik Thelonious Monks war stark von seiner introvertierten, individualistischen Persönlichkeit geprägt. So eigenwillig Monk an dem ihm eigenen Lebensrhythmus und seinen oft exzentrischen Gewohnheiten festhielt, so eigenwillig war auch seine Musik. Seine Frau Nellie berichtete, dass Monk sich seiner Umgebung innerlich fast vollständig entziehen konnte und sich zeit seines Lebens ausschließlich mit seiner Musik beschäftigt hat.

Auf Filmaufnahmen des Klavier spielenden Monk ist zu sehen, wie der Pianist mit den Beinen tanzende Bewegungen aufführt. Während der Soli seiner Band-Mitglieder liebte Monk es, mit der Klavierbegleitung auszusetzen und offenbar völlig in sich versunken, fast wie in Trance auf der Bühne zu tanzen. In diesem „monkischen“ Tanz vollzog er die eigentümliche Rhythmik und Harmonik seiner Musik nach. Vordergründig betrachtet erscheint dies oft behäbig und ungeschickt. Tatsächlich besaß Monk ein sehr individuelles Gefühl für Zeit, Bewegung und Rhythmus, das sein Verhalten auf Außenstehende oft befremdlich wirken ließ. Seine seltsam wirkenden Gewohnheiten entsprachen aber auf eine sehr spezielle Art seiner musikalischen Sprache, so dass vieles von seinem exzentrischen Verhalten bei näherem Hinsehen Parallelen zu seiner Musik erkennen lässt und nachvollziehbar wird.

Bezeichnenderweise beziehen sich viele Kompositionen des introvertierten Pianisten im Titel direkt auf Verwandte, enge Freunde oder sogar auf den Komponisten selbst. "Little Rootie Tootie" bezieht sich auf den Spitznamen seines Sohnes Thelonious Jr., "Boo Boo’s Birthday" auf den seiner Tochter Barbara. "Crepuscule With Nellie" ist seiner Ehefrau gewidmet, "Pannonica" der Baroness de Koenigswarter. "Thelonious", "Blue Monk" oder "Monk’s Mood" sind nur drei der Stücke, die den Namen des Komponisten im Titel tragen.

Monk wurde während seines gesamten Lebens von Frauen in seiner unmittelbaren Umgebung gefördert und umsorgt: anfangs von seiner Mutter, später von seiner Frau Nellie, die in für Monk wirtschaftlich schwierigen Zeiten auch den Lebensunterhalt der Familie sicherte, und zuletzt von der Baroness de Koenigswarter, in deren Villa in New Jersey er sich 1973 im Alter zurückzog. Dort verbrachte er mit seiner Frau Nellie fast völlig zurückgezogen seinen Lebensabend. Sein psychischer Zustand verschlechterte sich in dieser Zeit zunehmend. Er starb 1982 nach einem Gehirnschlag.

Sein Sohn Thelonious Monk junior folgte dem Vater als Musiker, schlug eine Karriere als professioneller Schlagzeuger ein und rief das „Thelonious-Monk-Institute for Jazz“ ins Leben. Dessen Ziel ist es, musikalisch begabte Jugendliche zu fördern. Es verleiht jährlich den renommierten Thelonious-Monk-Award an herausragende Talente.

Monk gilt als Mitbegründer und führender Musiker des Bebop. Er nimmt innerhalb dieses Genres jedoch eine Außenseiterposition ein: zum einen wegen seiner eigenwilligen Kompositionen, zum anderen wegen seines nicht weniger individuellen Improvisationsstils. Monk entwickelt eine sehr eigenständige musikalische Ästhetik, die zwar etwa zeitgleich mit dem Bebop entsteht und auf diesen einwirkt, aber im Wesentlichen von diesem unabhängig ist. Auf die Frage, wer ihn musikalisch am meisten beeinflusst habe, antwortete Monk einmal: „Na, ich selbst natürlich.“

In für den Bebop atypischer Weise sind Monks Kompositionen nicht bloße Neuharmonisierungen bekannter Standards, sondern meist vollständig neue Themen. Diese sind teils hochkomplex und enthalten ungewöhnliche Harmoniefolgen – wie etwa "Round Midnight" (siehe Beispiel), teils aber auch frappierend einfach, zum Beispiel ausgerechnet das Stück "Thelonious", das auf einem einzigen Ton aufbaut.

Monk hatte eine Vorliebe für besonders kurze, prägnante Themen. Sie beruhen zwar oft auf dem 12-taktigen Blues-Schema oder der 32-taktigen Standardform populärer Songs, doch er verfremdete gern symmetrische 8-, 16- oder 32-taktige Formteile, indem er scheinbar völlig unlogisch und überraschend ungerade Takte anhängte, einschob oder die Melodie um einen halben Beat vorverlegte. Themen wie "I mean you" oder "Straight no chaser" basieren auf solchen rhythmischen Verschiebungen und Unregelmäßigkeiten. Diese Besonderheiten geben Monks Stücken einen sperrigen und irritierenden, aber gerade dadurch auch reizvollen Charakter. Sie sind an ihrer individuellen Formensprache leicht als seine Werke zu erkennen.

Als Pianist improvisierte Monk selten wie typische Bebop-Solisten in rasanten, sondern bevorzugt eher moderate Tempi. Ihm lag nicht daran, seine Virtuosität unter Beweis zu stellen, sondern die verborgenen Strukturen eines Themas aufzudecken und den Hörer dabei mitzunehmen. Er variierte ständig die Melodien und Harmonien der kompositorischen Vorlagen, indem er Motive, Phrasen und Akkorde daraus abstrahierte, dehnte oder verkürzte. Seine kantigen, bizarren Improvisationen wurden spontan erfunden, bildeten aber keine losgelöste und frei assoziierte Linie, sondern bezogen sich immer auf das zu Grunde liegende Thema.

Monk benutzte damals sehr ungewöhnliche Akkorde, Intervalle und Skalen, etwa den übermäßigen Dreiklang, die Ganztonleiter, die zum Tritonus erhöhte Quarte (das „Bebop“-Intervall) und kleine, als besonders dissonant empfundene Sekunden. Als Beispiel sei das Klavierintro aus der Komposition "Brilliant Corners" genannt.

Er kombinierte diese Elemente auf bizarre Weise miteinander und verteilte seine Akkorde über die ganze Klaviatur. Er setzte diese sowohl als harmonische Wendungen als auch als eigene „Farben“ ein.

Auch rhythmisch setzte Monk in dem für ihn typischen perkussiven Stil unerwartete, aber umso effektvollere Akzente. Er setzte diese sparsam, aber immer an Stellen, wo sie ein Höchstmaß an Aussagekraft erreichen. Er spielte mit Pausen und Gegenrhythmen, die den weiterlaufenden Swing kontrastieren. Indem er die Form verfremdete und neue großräumige thematische Bezüge herstellte, erzeugte er außergewöhnliche Spannungsmomente und öffnet neue Horizonte. Der Hörer kann miterleben, wie Monk das Stück improvisierend kommentiert, durchdenkt und nochmals ganz neu erfindet.

Monks Art der Komposition und Improvisation sind untrennbar miteinander verbunden. Der Kritiker Whitney Balliett fasst diese Wechselbeziehung so zusammen: „Seine Improvisationen sind verflüssigte Kompositionen, seine Kompositionen sind gefrorene Improvisationen.“

Innerhalb des Modern Jazz geht Monk bis an die Grenze zur Auflösung jeder Tonalität, Phrasierung und Rhythmik. Deswegen war er lange Zeit dem Unverständnis von Publikum und Kritik ausgesetzt. In der Bebop-Ära wurde er deshalb oft heftig abgelehnt und angefeindet. Seine Kritiker führten seine Art, Spannung zu erzeugen, auf mangelndes technisches Können und fehlendes Swing-Gefühl zurück. Monks Musik gewann jedoch gerade durch seine konsequent skurrile Exzentrik eine innere Stimmigkeit und Geschlossenheit, wie sie auch im Jazz nur selten zu finden sind. Sein sehr persönlicher Improvisationsstil findet daher nur wenige Nachahmer.

Monk lotete die kompositorischen und improvisatorischen Möglichkeiten des modernen Bebop-Idioms aus: Er ironisierte vermeintlich Bekanntes, parodierte Klischees, unterlief die Erwartungshaltung des Hörers und schaffte neue, unvermutete Bezüge. Dabei gab er aber die Tradition niemals auf, sondern blieb im Rahmen der funktionalen, vom Blues „getränkten“ Jazzharmonik und konventionellen Songformen. Diese vorgegebenen Strukturen sind als Basis seiner Spielweise immer erkennbar und werden gerade durch ihre Verfremdung hervorgehoben. Ein besonderer Reiz seiner Musik liegt daher in dem stets spürbaren Spannungsverhältnis zwischen den traditionellen musikalischen Formen und ihrer individualistischen Transformation.

Durch seine verspätete Anerkennung macht sich Monks Einfluss erst ab etwa 1955 bemerkbar. Er eröffnete dem Jazz in den 1950er Jahren neuartige Perspektiven: Sein experimenteller Stil nahm vieles von dem vorweg, was später in den 1960er Jahren im Free Jazz üblich und breit entfaltet wurde. Durchsetzt von seinem zynischen Humor klang bei Monk Vieles erstmals an, was ebenso geniale Jazz-Avantgardisten später weiterentwickelten. So beeinflusste Monk zahlreiche Jazzmusiker der 1960er Jahre wie John Coltrane, Ornette Coleman, Sonny Rollins und Eric Dolphy.

Er selbst war jedoch nicht bereit, die radikalen Umwälzungen mitzumachen, sondern stand dem Free Jazz der 1960er Jahre ablehnend gegenüber. Er warf den jungen Avantgardisten vor, unzusammenhängend und unlogisch einfach nur „einen Haufen Noten“ nacheinander zu spielen. Den Free-Jazz-Pionier Ornette Coleman beschuldigt er sogar, mit seinen neuartigen musikalischen Konzepten den Jazz zu zerstören. Hier zeigt sich, dass der Komponist und Strukturalist Monk auf die traditionelle Form angewiesen blieb, um seine individuelle musikalische Sprache sprechen zu können.

Monk komponierte im Laufe seines Lebens nur genau 71 Themen (Duke Ellington zum Beispiel komponierte etwa 2000). Dennoch gilt er als einer der wenigen großen Jazz-Komponisten. Viele seiner Stücke wurden wegen ihrer genialen eigenwilligen, oft bizarren Formensprache ihrerseits zu Jazzklassikern (sogenannten „Standards“). Sie haben in dem, was man als Modern Jazz bezeichnet, eine absolut überragende Stellung eingenommen und gelten als Paradebeispiele für diese Musikrichtung, an der kein bedeutender heutiger Jazzmusiker und Jazzpianist vorbeikommt.

Seit Monks Tod erlebt seine Musik eine regelrechte Renaissance, die bis heute anhält. Viele namhafte Musiker beschäftigen sich bis heute intensiv mit seinem Werk und spielen seine Kompositionen ein. Dazu gehören unter anderen Anthony Braxton, Misha Mengelberg und Chick Corea. Der Pianist Alexander von Schlippenbach führt mit einer Gruppe junger Musiker in einem Konzertprogramm das Gesamtwerk Monks auf und hat dieses im Jahr 2004 komplett aufgenommen. Der Sopransaxophonist Steve Lacy, selbst in den 60ern kurzzeitig Mitglied in Monks Band und auf der Columbia-Aufnahme von 1964 zu hören, spielte einige Jahre seiner Karriere sogar ausschließlich Monk-Kompositionen.

Monks Einfluss reicht jedoch weit über den Jazz hinaus. So erschien 1984 das von Hal Willner produzierte Doppelalbum "That’s The Way I Feel Now", auf dem sowohl Jazz- als auch Popmusiker Monk ihre Reverenz erweisen. Unter ihnen sind Gil Evans, Dr. John, Donald Fagen und John Zorn. Auch das Kronos Quartet hat eine kammermusikalische Hommage an Monk aufgenommen.

1989 produzierte Clint Eastwood den Dokumentarfilm "Thelonious Monk: Straight, No Chaser", ein sensibles und lebhaftes Porträt Thelonious Monks, unter der Regie von Charlotte Zwerin.

Im April 2006 wurde Thelonious Monk für sein Werk posthum ein Pulitzer-Preis verliehen.

Nach ihm ist ein angesehener Nachwuchswettbewerb für Jazzmusiker (Thelonious-Monk-Wettbewerb) benannt.

Bereits zu Lebzeiten wurden mehr als 50 Aufnahmen Thelonious Monks unter seinem eigenen Namen oder dem anderer Leader veröffentlicht. Seit seinem Tode wurden seiner Diskografie bis heute zahlreiche weitere, bislang unveröffentlichte Aufnahmen oder Zusammenstellungen hinzugefügt. So wurde im Jahr 2005 eine bislang unbekannte Live-Aufnahme Monks mit John Coltrane veröffentlicht. Eine vollständige Auflistung an dieser Stelle ist weder sinnvoll noch möglich. Stattdessen wird hier exemplarisch auf einige besonders hervorzuhebende Aufnahmen hingewiesen.

Alben

Zusammenstellungen


Andere

Es existieren zahlreiche Schallplatten, auf denen andere Musiker ausschließlich Kompositionen Thelonious Monks spielen, oder bei denen diese einen Schwerpunkt bilden. Diese Liste kann daher nur eine kleine Auswahl wiedergeben.






</doc>
<doc id="5088" url="https://de.wikipedia.org/wiki?curid=5088" title="Ablauf der Terroranschläge am 11. September 2001">
Ablauf der Terroranschläge am 11. September 2001

Der zeitliche Ablauf der Terroranschläge am 11. September 2001 ist Gegenstand der historischen Forschung.

Als wichtige Forschungsbeiträge gelten der Abschlussbericht der 9/11-Kommission vom 22. Juli 2004, der sich auf viele Dokumente und Zeugenaussagen stützt, und das Buch "The Terror Timeline" von "Paul Thompson" vom August 2004, das sich auf in einem kollaborativen Internetprojekt gesammelte öffentlich zugängliche Quellen stützt. Das Gemeinschaftswerk bildete die Grundlage für öffentliche Kritik der Opferfamilien des 11. Septembers am 9/11-Kommissionsbericht. Dessen Angaben wurden in spätere Ausgaben der "Terrortimeline" aufgenommen.

Alle Zeitangaben folgen der Eastern Daylight Saving Time (EDT), der am Tag der Anschläge in New York geltenden Sommerzeit.

Als wichtige Daten des Tagesverlaufs unter anderen wurden veröffentlicht:

Bei Entführungen von Flugzeugen lag damals und somit auch am 11. September die Verantwortung in den USA bei der zivilen Federal Aviation Administration (FAA) und dem militärischen North American Aerospace Defense Command (NORAD). Deren Verfahrensprotokolle setzten voraus, dass man entführte Flugzeuge identifizieren könne und die Kommandokette beider Behörden genug Zeit zu angemessenen Maßnahmen hätte. Die Flugkontrollzentren der FAA erwarteten einen Notruf der Piloten, der zugleich Position und Höhe des Fluges übermitteln würde. Bei abgebrochenen Funkkontakten und ausgefallenen Transponder-Signalen sollten sie zunächst den Kontakt wiederherzustellen versuchen und dann das FAA-Operationszentrum in Herndon (Virginia) alarmieren. Dieses musste dann einen Koordinator im FAA-Hauptquartier in Washington, D.C. informieren, der das National Military Command Center (NMCC) des Pentagon um Hilfe ersuchen konnte. Dieses brauchte einen Befehl des Verteidigungsministers, um Kampfjets aufsteigen zu lassen, die den entführten Flugzeugen folgen und ihren Kurs überwachen sollten. NORADs Nordostsektor "NEADS", in dessen Bereich alle vier Flüge entführt wurden, verfügte 2001 über vier startbereite Kampfjets zur Sicherung des Luftraums, zwei in der Otis Air National Guard Base in Cape Cod, Massachusetts, und zwei in der Langley Air Force Base in Hampton (Virginia). Abschüsse oder erzwungene Landungen sahen die Protokolle nicht vor. Den Fall von Selbstmordanschlägen mit entführten Flugzeugen, die vom Radar verschwinden, hatte man nicht bedacht. Die beteiligten FAA- und NORAD-Personen mussten daher am 11. September 2001 improvisieren, so flogen die Kampfjets zum Beispiel Routen über dem Atlantik, die noch aus dem Kalten Krieg stammten und zur Abwehr sowjetischer Bomber gedacht waren. Sie erfuhren im Verlauf nur Einzeldetails der vierfachen Entführungen und trafen daher häufig verspätete, falsche oder gar keine der Situation angemessene Entscheidungen.




</doc>
<doc id="5109" url="https://de.wikipedia.org/wiki?curid=5109" title="Thorwald Dethlefsen">
Thorwald Dethlefsen

Thorwald Dethlefsen (* 11. Dezember 1946 in Herrsching am Ammersee; † 1. Dezember 2010 in Wien) war ein deutscher Diplompsychologe und Esoteriker, der sich mit psychotherapeutischen Methoden beschäftigte und mehrere Bücher verfasste.

Dethlefsen lernte Astrologie bei Wolfgang Döbereiner und vertrat bald die Auffassung, man könne mit ihrer Hilfe psychologische Diagnosen durchführen.

In den frühen 1970er Jahren führte Dethlefsen als Psychologiestudent Hypnose-Experimente durch, um unter seinen Freunden und Bekannten die Erinnerungen an vermeintliche frühere Leben zu demonstrieren. Nach seinem Psychologie-Diplom entwickelte er die Reinkarnationstherapie, die bis heute in verschiedenen Varianten von anderen Therapeuten angewandt wird, darunter von Ruediger Dahlke, der sich jedoch 1989 von Dethlefsen löste.

1974 gründete Dethlefsen das "Institut für außerordentliche Psychologie", das er 1993 in den "Kawwana-Konvent" umwandelte. 1996 ließ er beim Amtsgericht München Kawwana – Kirche des Neuen Aeon eintragen, die er unter der selbstgewählten Bezeichnung „Vicarius“ leitete und die von 1999 bis Januar 2003 halböffentliche Veranstaltungen durchführte. Diese religiöse Gemeinschaft orientierte sich an Lehren des Zürcher Psychologen und Esoterikers Oskar Rudolf Schlag. 2003 erklärte Dethlefsen, die Kawwana-Kirche sei „in die Welt von Briah“ erhoben worden, legte die Bezeichnung „Vicarius“ ab und zog sich bis auf gelegentliche Vorträge weitgehend aus der Öffentlichkeit zurück. Der Tempel der Kirche wurde im Jahr 2009 abgerissen; zu diesem Zeitpunkt war die Webseite der Kirche schon seit geraumer Zeit permanent "under construction".

Am 1. Dezember 2010 verstarb Thorwald Dethlefsen, der die letzten Jahre seines Lebens abgeschirmt von der Öffentlichkeit in Wien verbracht hatte. Sein Tod wurde erst einige Wochen später bekannt.

Dethlefsen hat seine Position in dem Buch "Schicksal als Chance" ausführlich erläutert. Dethlefsen war davon überzeugt, dass der Mensch den Gesetzen des Schicksals unterworfen ist, das ihm Themen zum Lernen, das heißt Möglichkeiten zur Erweiterung seines Bewusstseins aufzeigt. In der Weigerung des Menschen, diese neuen Themen in sein Bewusstsein zu integrieren, sah Dethlefsen eine Missachtung der Schicksalsgesetze bzw. der (kosmischen) Ordnung, was zu Leid führt:

Dethlefsen zufolge gibt es eine Reihe von „Schicksalsgesetzen“ wie das „Gesetz des Anfangs“ oder das „Resonanzgesetz“. Aus letzterem folgt:

Das wichtigste Gesetz sei das Polaritätsgesetz, wonach das menschliche Bewusstsein „polar“ ist.

Um sein Konzept der Reinkarnation auszubauen, arbeitete Dethlefsen anfangs mit der Hypnose, in der er eine Möglichkeit sah, Erlebnisse früherer Leben und die eigene Geburt während der Trance erneut zu durchleben und damit ins Bewusstsein zu bringen. Bereits in "Schicksal als Chance" erklärte er, dieses Mittel nicht mehr zu benötigen und übte scharfe Kritik an dem Versuch, mittels des Hypnotisiertwerdens zu Heilung gelangen zu wollen, da dies zwar – wie seiner Meinung zufolge auch die Schulmedizin – unter Umständen das Verschwinden von Krankheitssymptomen bewirkt, mangels eines bewussten Lernschrittes den Menschen aber nicht heile im eigentlichen Sinn.

Dethlefsen war der Ansicht, dass der Mensch an sich krank, unheil bzw. sündig und schuldig ist. Diese Bezeichnungen verwendet er synonym, um aufzuzeigen, dass Krankheit nicht eine zeitweilige oder umgehbare „unliebsame Störung“ sei, sondern vom Wesen des Menschen impliziert ist.

Dieser Unheilszustand wiederum ist damit verbunden, dass der Mensch nicht alle Bewusstseinsinhalte (oder „Seinsprinzipien)“ gleichzeitig verwirklichen kann und die nicht gelebten Pole verdrängt, welche den Schatten eines Menschen bilden und ihm unbewusst sind bzw. im Bewusstsein zur Vollkommenheit "fehlen." Dethlefsen übernimmt diesen Begriff von C. G. Jung und fügt hinzu, dass Krankheitssymptome immer in die Stofflichkeit gesunkene Schattenaspekte des Menschen sind. Dadurch zwinge das Schicksal den Menschen, sich doch mit den abgelehnten Lebensbereichen zu beschäftigen. Somit soll sich der Mensch bei jedem Symptom fragen, welchen Schattenteil seiner selbst es verkörpert, um in der Integration (Einswerdung) des Schattens zur Ganzheit bzw. zum Heil zu finden.

Außerdem vertrat er die Auffassung, dass Krankheit häufig zur Machtausübung missbraucht werde: „Eine der häufigsten Formen in der heutigen Zeit, Macht auszuüben, ist die Krankheit. Krankheit garantiert in unserer Zeit dem einzelnen einen kritiklosen Freiraum für seine unbewußten Machtansprüche.“ Der Mensch habe sich „zu bemühen, eine möglichst nützliche Zelle zu sein, so wie er es von seinen Körperzellen erwartet, damit er nicht zum Krebsgeschwür dieser Welt wird. Verlässt er dennoch die Ordnung mutwillig, um seine missverstandene Freiheit auszukosten, so sollte er sich nicht wundern, wenn er eliminiert wird“, wobei Dethlefsen unter der „Elimination“ (dem Tod) lediglich die äußerste Eskalationsstufe einer Krankheit versteht. Mit „Tod“ ist allerdings nur der der Person gemeint, nicht der des Bewusstseins, denn dieses wird Dethlefsens Ansicht nach wiedergeboren.

Weigert sich ein Mensch, die Lernaufgaben, mit denen er (vom Schicksal bzw. der Welt) konfrontiert wird, zu bearbeiten, sinkt dieser Aspekt in sieben „Eskalationsstufen“ tiefer in den Schatten und äußert sich (1.) psychisch in Gedanken, Wünschen und Phantasien, (2.) in funktionalen Störungen, (3.) in akuten, körperlichen Störungen wie Entzündungen oder Unfällen, (4.) in chronischen Störungen, (5.) in unheilbaren Organveränderungen oder Krebs, (6.) im Tod des Menschen und (7.) in seinem Karma, welches sich wiederum in angeborenen Missbildungen ausdrücken kann.

In dem Buch "Krankheit als Weg" vertrat er zusammen mit Ruediger Dahlke nach wie vor die Überzeugung, dass Krankheit unmittelbar zum Schicksal des Menschen gehört: „Die Menschen haben Krebs, weil sie Krebs sind.“ Lernt der Mensch jedoch, mit den Gesetzen des Schicksals in Einklang zu leben, sprich die an ihn gestellten Lernaufgaben zu akzeptieren und zu meistern, wird der Grund für das Krankheitssymptom obsolet und es verschwindet:

Dethlefsen vertrat die Auffassung, dass Seelen immer wieder wiedergeboren werden mit der Bewusstseinsstufe, die sie beim Tod der vorhergehenden Inkarnation hatten (Reinkarnation); diese bildet sein Karma.

Somit hat jedes Leben einen seit der Geburt determinierten individuellen „Lehrplan“ (Prinzipien, mit denen er sich auseinandersetzen muss), der aus dem Radixhoroskop herausgelesen werden könne.

In der Homöopathie sah Dethlefsen ein „Urprinzip“ und vertrat die Hochpotenz-Homöopathie.

Der Journalist Oliver Schröm schrieb in seinem am 28. Mai 1998 in der Zeit veröffentlichten Artikel ""Braune Esoterik auf dem Vormarsch: Viele Bücher aus der New-Age-Szene zeichnen ein rassistisches Weltbild"" über Thorwald Dethlefsen und sein Buch "Schicksal als Chance. Das Urwissen zur Vollkommenheit" (Goldmann, München 1998): 





</doc>
<doc id="5112" url="https://de.wikipedia.org/wiki?curid=5112" title="Tetraeder">
Tetraeder

Das (auch, v. a. österr.: "der") Tetraeder [] (v. griech. "tetráedron" „Vierflächner“), auch Vierflächner oder Vierflach, ist ein Körper mit vier dreieckigen Seitenflächen. Es ist das einzige konvexe (dreidimensionale) Polyeder (Vielflächner) mit vier Flächen.

Das Wort wird jedoch nur selten in dieser allgemeinen Bedeutung gebraucht. Meist ist mit Tetraeder das regelmäßige (oder gleichseitige) Tetraeder, das einer der Platonischen Körper ist, gemeint. Das allgemeine Tetraeder wird je nach Symmetrie als dreiseitige Pyramide, Dreieckpyramide, Disphenoid oder dreidimensionales Simplex bezeichnet.

Das regelmäßige Tetraeder (reguläre Tetraeder) ist einer der fünf platonischen Körper, genauer ein Polyeder mit

Das regelmäßige Tetraeder ist auch eine gleichseitige dreiseitige Pyramide (mit einem gleichseitigen Dreieck als Grundfläche).

Wegen seiner hohen Symmetrie – alle Ecken, Kanten und Flächen sind untereinander gleichartig – ist das regelmäßige Tetraeder ein reguläres Polyeder. Es hat
Insgesamt hat die Symmetriegruppe des Tetraeders – die Tetraedergruppe – 24 Elemente.
Sie ist die symmetrische Gruppe "S" (die Punktgruppe "T"
nach Schoenflies bzw. 3m nach Hermann-Mauguin) und bewirkt alle "4! = 24" Permutationen der Ecken bzw. der Seitenflächen. Sie ist Untergruppe der Oktaedergruppe (Würfelgruppe).

Im Einzelnen gehören zur Tetraedergruppe


sowie


Die geraden Permutationen bilden eine Untergruppe der Tetraedergruppe, die so genannte alternierende Gruppe formula_1 (die Punktgruppe "T" bzw. 23). Manchmal wird der Begriff Tetraedergruppe auch nur für diese unter Ausschluss der Spiegelungen verwendet.

Durch Verbinden der Flächenmittelpunkte erhält man wieder ein Tetraeder. Man sagt deshalb: Das Tetraeder ist zu sich selbst dual, kurz: "selbst-dual". Die Seitenlänge des neuen Tetraeders beträgt ein Drittel der ursprünglichen Seitenlänge.

Mit Hilfe dieser beiden Tetraeder können Körper konstruiert werden, die ebenfalls die Tetraedergruppe als Symmetriegruppe haben. So erhält man zum Beispiel

Siehe dazu auch das Beispiel weiter unten.

Das Tetraeder kann in einen Würfel so einbeschrieben werden, dass seine Ecken zugleich Würfelecken und seine sechs Kanten Diagonalen der Würfelflächen sind. (Die acht Ecken des Würfels bilden zwei disjunkte Mengen von je vier Ecken, die den beiden möglichen Lagen des Tetraeders entsprechen.)
Das Volumen dieses Würfels ist das Dreifache des Tetraedervolumens.

Dual dazu kann das Tetraeder einem Oktaeder so umbeschrieben werden, dass vier der Oktaederflächen in den Begrenzungsflächen des Tetraeders liegen und die sechs Ecken des Oktaeders die Mittelpunkte der sechs Tetraederkanten sind.

Der Diederwinkel zwischen zwei Begrenzungsflächen des regelmäßigen Tetraeders (in der Zeichnung mit formula_2 bezeichnet) beträgt 70,53° (Rundungsgenauigkeit wie bei den nachfolgenden Angaben zwei Nachkommastellen). Jede Kante bildet mit der gegenüberliegenden Fläche einen Winkel (formula_3) von 54,74°. Die Verbindungsstrecken zwischen dem Tetraedermittelpunkt und zwei Ecken schließen jeweils einen Winkel von formula_4 ein, dies entspricht 109,47°. Der zuletzt genannte Winkel (formula_5) wird als Tetraederwinkel bezeichnet und spielt eine wichtige Rolle in der Chemie, beispielsweise bei der Geometrie des Methan-Moleküls. Die Größen der angegebenen Winkel lassen sich durch Anwendung trigonometrischer Funktionen ermitteln. Man betrachtet dazu die Schnittfigur des Tetraeders mit einer seiner sechs Symmetrieebenen. Daraus ergibt sich exakt: formula_6

Zur Berechnung des Tetraederwinkels siehe Artikel Stumpfer Winkel.

Das regelmäßige Tetraeder kann so in zwei Teile geschnitten werden, dass die Schnittfläche ein Quadrat ist. Die Teile sind kongruent zueinander.

Liegt die Schnittebene durch ein regelmäßiges Tetraeder parallel zu einer der vier Seitenflächen, dann ergibt der Querschnitt ein gleichseitiges Dreieck.

Liegt die Schnittebene durch ein regelmäßiges Tetraeder parallel zu zwei gegenüberliegenden Kanten, dann ergibt der Querschnitt ein Rechteck. Hat die Schnittebene zusätzlich noch von diesen beiden Kanten den gleichen Abstand, also teilt sie die übrigen vier Kanten genau zur Hälfte, dann ist das Schnittbild ein Quadrat. Das Quadrat hat eine Kantenlänge, die genau halb so lang ist wie die Länge einer Kante des Tetraeders.

Die Einbettung des Tetraeders in einen Würfel bietet eine einfache Möglichkeit, ein regelmäßiges Tetraeder zu konstruieren. Bezeichnen wir die Eckpunkte des Würfels an der Basis mit formula_7 und formula_8 sowie die darüberliegenden Eckpunkte mit formula_9 und formula_10, so bilden formula_11 und formula_10 sowie formula_13 und formula_14 jeweils die Ecken eines Tetraeders. Betrachtet man z. B. in einem räumlichen kartesischen Koordinatensystem den Würfel, dessen Ecken die Koordinaten formula_15 und formula_16 haben, so erhält man für das erste Tetraeder die Ecken
Die Kanten sind: formula_19 und formula_20. Die Seitenflächen sind die Dreiecke formula_21 und formula_22.

Das zweite Tetraeder hat die Ecken

Der Durchschnitt dieser beiden Tetraeder ist das von den Punkten formula_25 und formula_26 bestimmte Oktaeder. Ihre Vereinigung ist ein Sternkörper mit 8 Spitzen (in jeder Ecke des Würfels eine). Seine konvexe Hülle ist daher der Würfel.

Obwohl das Tetraeder nicht Stein einer Parkettierung des Raumes ist, tritt es im kubischen Kristallsystem auf (siehe oben).
In der Chemie spielt das Tetraeder bei der räumlichen Anordnung von Atomen in Verbindungen eine große Rolle. Einfache Molekülgestalten lassen sich mit dem VSEPR-Modell vorhersagen. So sind die vier Wasserstoffatome im Methanmolekül tetraedrisch um das Kohlenstoffatom angeordnet, da so der Bindungswinkel am größten wird. Auch die Kohlenstoffatome im Diamantgitter sind tetraedrisch angeordnet, jedes Atom ist von vier weiteren Atomen umgeben. Das Kohlenstoff-Atom befindet sich dann nach dem Orbital-Modell in sp-Hybridisierung.

Das Tetraeder war auch für den Tetra Pak wegen dessen ursprünglicher Form namensgebend.

Alexander Graham Bell hat mit vielzelligen Kastendrachen (Flugdrachen) experimentiert, deren Einzelzellen die Form eines Tetraeders haben. Diese meist imposanten Drachen werden als „Bell-Tetraeder“ bezeichnet. Meistens werden 4 oder 10 oder 20 Einzelzellen zu einem Verbund zusammengefügt, welcher dann auch wieder die Form eines Tetraeders hat. Es sind aber auch andere Verbundformen möglich.

In vielen Pen-&-Paper-Rollenspielen werden Tetraeder als vierseitige Spielwürfel (W4) verwendet.

Weitere technische Anwendungen lehnen sich an die Struktur an, die sich durch die vom Tetraederzentrum in die vier Raumecken weisenden Strecken ergibt:

Ein Tetraeder im allgemeinen Sinn, also ein Körper mit vier Seitenflächen, ist immer eine dreiseitige Pyramide, also mit einem Dreieck als Grundfläche und drei Dreiecken als Seitenflächen, und hat daher auch vier Ecken sowie sechs Kanten. Da er die für einen Körper im Raum kleinste mögliche Zahl von Ecken und Seiten hat,
wird er in der Fachsprache (dreidimensionales) Simplex oder 3-Simplex genannt. Die zweidimensionalen Simplizes sind die Dreiecke.

Im formula_27 kann ein Tetraeder auch durch einen Punkt und den drei Vektoren zu den angrenzenden Punkten beschrieben werden. Bezeichnet man diese Vektoren mit formula_28, so berechnet sich das Volumen des Tetraeders mit
formula_29, also formula_30 des Betrags des Spatproduktes.

Ein Tetraeder besitzt 6 Kanten. Ein Dreieck ist durch die Angabe dreier Seiten bestimmt. Jede weitere Kante kann (in gewissen Grenzen) frei gewählt werden. Liegen also 6 voneinander unabhängige Angaben zur Größe von Kanten und/oder Winkeln vor, kann man daraus die jeweils fehlenden übrigen Kanten und/oder Winkel berechnen.

Die Analoga des Tetraeders in beliebiger Dimension formula_31 werden als (formula_31-dimensionale) Simplizes bezeichnet. Das formula_31-dimensionale Simplex hat formula_34 Ecken und wird von formula_34 Simplizes der Dimension formula_36 (als "Facetten") begrenzt. Ein nulldimensionales Simplex ist ein Punkt, ein eindimensionales Simplex ist eine Strecke, ein zweidimensionales Simplex ist ein Dreieck. Das vierdimensionale Äquivalent zum Tetraeder, das Pentachoron, hat 5 Ecken, 10 Kanten, 10 Dreiecke als Seitenflächen und 5 dreidimensionale Tetraeder als Facetten.

Koordinatenbeschreibung eines regulären formula_31-Simplex:
Beispielsweise für formula_39 ergibt sich hier ein gleichseitiges Dreieck, das von den Punkten formula_40 im dreidimensionalen Raum aufgespannt wird.





</doc>
<doc id="5113" url="https://de.wikipedia.org/wiki?curid=5113" title="Tierreich">
Tierreich

Tierreich steht für:


Siehe auch:


</doc>
<doc id="5114" url="https://de.wikipedia.org/wiki?curid=5114" title="Tcl">
Tcl

Tcl (Aussprache oder auch als Abkürzung für "Tool command language") ist eine Open-Source-Skriptsprache.

Tcl wurde ursprünglich ab 1988 von John Ousterhout an der University of California, Berkeley als Makrosprache für ein experimentelles CAD-System entwickelt. Aus dieser Zeit stammt das Konzept, den Tcl-Interpreter als Bibliothek in z. B. ein C-Programm einzubinden, was auch noch heute möglich ist.

Die Wahlsprüche von Tcl lauten: "„radically simple“", also „radikal einfach“, was sich insbesondere auf die Syntax der Sprache bezieht und „everything is a string“, „Alles ist Text“, was sich auf den Umgang mit Befehlen und Daten in Tcl bezieht.

Die verbreitete Kombination aus Tcl und dem GUI-Toolkit Tk wird als Tcl/Tk bezeichnet.

Die Tcl-Syntax folgt der polnischen Notation. Sie verzichtet auf reservierte Wörter, ordnet jedoch einigen Zeichen eine feste Bedeutung zu:
Alle anderen Bestandteile der Sprache können umdefiniert werden. Zwischen eingebauten und von Programmen oder Tcl-Bibliotheken hinzugefügten Funktionen besteht kein Unterschied.

Tcl ist eine (nach außen hin) typlose Sprache. Jede Variable hat eine Zeichenkette als Wert. Dazu kann eine interne Repräsentation z. B. einer Ganzzahl, Gleitkommazahl oder Liste treten. Die Verwendung einer nicht definierten Variablen führt zu einem Fehler – im Gegensatz zur Programmierung mit dem Unix-Kommandozeileninterpreter (Shell) oder awk. Konstrukte wie assoziative Arrays (Hashtabelle) und Listen werden in Tcl oft angewendet. Darüber hinaus gibt es Wörterbücher für komplexere Datenstrukturen (vergleichbar mit JSON) und Objekte mit Klassen, Mehrfachvererbung und Mixins. Letztere sind genauso wie die Steuerelemente der grafischen Oberfläche Tk Kommandos innerhalb von Tcl.

Tcl kennt sehr leistungsfähige Kommandos zur Bearbeitung von (auch langen) Zeichenketten, ebenso Dateibearbeitung, TCP/IP-Netzkommunikation und über Tk grafische Programmierung und ist in all diesem völlig plattformunabhängig. Tcl hat einen Mechanismus eingebaut, um mit regulären Ausdrücken arbeiten zu können, wobei auch komplexere Ausdrücke als die von grep unterstützt werden, vergleichbar mit denen von Perl.

Zur Einbindung externer Bibliotheken besitzt Tcl ein eigenes Paketsystem, das diese auch bei Bedarf automatisch nachladen kann. Weiterhin ist es möglich, Tcl-Programme um Bibliotheken zu erweitern, die in C oder einer anderen kompilierten Sprache geschrieben sind; hierfür existiert in Form der TclStubs eine standardisierte Schnittstelle. Außerdem können mithilfe der CriTcl-Erweiterung zeitkritische Programmteile in C-Quellcode innerhalb des Tcl-Quellcodes notiert werden. Diese werden automatisch kompiliert und eingebunden.

Tcl-Programme können sich sehr einfach zur Laufzeit selbst modifizieren. Da es ohne weiteres möglich ist, eigene Kontrollstrukturen in reinem Tcl zu implementieren, ist es möglich, verschiedene Programmierparadigmen direkt in Tcl umzusetzen, zum Beispiel funktionale oder objektorientierte Programmierung.

Außerdem kann durch die Selbstmodifizierbarkeit Code aus Konfigurationsdateien oder über das Netzwerk gelesen und ausgeführt werden. Um dies in einer sicheren Form zu ermöglichen, stellt Tcl eine beliebige Zahl von Sandboxen in Form eigens gestarteter Interpreter mit beschränkter Funktionalität zur Verfügung. Diese "Kind-Interpreter" können jeweils mit eigenen Funktionen erweitert werden, die über definierte Schnittstellen mit ihrem "Mutter-Interpreter" kommunizieren.

Tcl enthält im Kern (ab Version 8.6) die bisherige Erweiterung TclOO mit Einfach- und Mehrfachvererbung sowie Mixins, sodass vollständig objektorientierte Anwendungen geschrieben werden können – aber nicht müssen. Klassen enthalten Konstruktoren und Destruktoren sowie Methoden. Im Gegensatz zu anderen Programmiersprachen sind Klassen und Objekte als Kommandos implementiert und müssen explizit mittels "destroy" zerstört werden, was durch Überwachung von Variablen mittels "trace" automatisiert werden kann, wenn die Variable ihren Gültigkeitsbereich verlässt.

Da es keine Zeiger gibt, wird stattdessen mithilfe des Objektnamens auf andere Objekte verwiesen.

Tcl implementiert nach Wunsch auch Nebenläufigkeit. Jeder Thread besitzt einen eigenen Interpreter und damit auch eigene Variablen. Ein Thread kann einen anderen Thread beauftragen, Kommandos auszuführen. Threads stehen zueinander in Eltern-Kind-Beziehung. Die Synchronisation erfolgt über Mutexes oder über "join". Eine alternative Implementierung von Nebenläufigkeit über Coroutinen steht ab Version 8.6 ebenfalls zur Verfügung.

Tcl-Routinen werden vom Interpreter jeweils beim ersten Ausführen in Bytecode übersetzt. Beim zweiten Ausführen einer Routine steht dann bereits der Bytecode zur Verfügung und der Ablauf geschieht schneller. Es existieren auch Erweiterungen, die den Quelltext zur Ladezeit des Programms komplett in Bytecode übersetzen.

Bekannt ist Tcl auch durch das Toolkit Tk, mit dem sich plattformunabhängige grafische Benutzeroberflächen leicht programmieren lassen. Der grafische Werkzeugkasten „Tk“ steht für eine Vielzahl von Betriebssystemen mit dem für das jeweilige System üblichen Aussehen („native look and feel“) zur Verfügung. Diese Programmierschnittstelle wird auch für viele weitere Programmiersprachen angeboten, wie z. B. Common Lisp, Perl, PHP, Ruby, Python oder R. Neben der Standard-Schnittstelle zum Tk Toolkit existieren unter anderem auch Schnittstellen zu den Toolkits FLTK und GTK+.


Tcl ist im Grundsatz sehr einfach aufgebaut und grenzt sich gegen Sprachen wie Perl, APL und C durch absolut konsequenten Einsatz einer einheitlichen Syntax ab.
Wer mit Kommandozeileninterpretern (Shell, MS-DOS) vertraut ist, kennt auch die Grundstruktur von Tcl-Kommandos. Ein Tcl-Skript besteht aus mehreren Kommandos. Ein Kommando besteht aus einem Kommandowort gefolgt von Argumenten (Parameter). Ein Kommando wird von einem Zeilenende oder Semikolon begrenzt.
Gegenüber einfachen Kommandozeileninterpretern verfügt Tcl aber über die Möglichkeit, Kommandos ineinander zu verschachteln. Statt eines Arguments in einem Kommando, kann in eckigen Klammern ein weiteres Kommando angegeben werden. Die Unterkommandos werden zuerst ausgeführt. Ihr Resultat wird dann jeweils als Argument im übergeordneten Kommando eingesetzt. Der Mechanismus entspricht dem der Backquotes bei der Unix-Shell.

Auch Konstrukte wie if und while oder Zuweisungen sind Kommandos. Die Kommandos folgen der Polnischen Notation, wie Lisp, und werden ebenfalls als Liste verarbeitet. Das Kommandowort steht am Anfang, dann folgen die Parameter:

Tcl ist in den meisten Unix-Installationen bereits vorinstalliert oder lässt sich über die Paketverwaltung nachinstallieren, auch bei Apple macOS; nicht jedoch bei Microsoft Windows. Für andere Betriebssysteme einschließlich Windows bestehen auch verschiedene Installationspakete. Tcl ist plattformunabhängig und verhält sich auf allen Systemen, für welche es vorhanden ist, gleich. Üblicherweise wird ein Tcl-Programm (Skript) über die Tcl-Shell "tclsh" für Programme mit nicht-grafischer Ein-/Ausgabe oder die Tcl-Windowing-Shell "wish" für Programme mit grafischer Benutzeroberfläche gestartet.

Tcl wird auf der Kommandozeile, als eingebettete Sprache, als CGI-Sprache (wie sonst oft Perl), als Modul im Apache-Webserver (wie sonst oft PHP) und als Sprache für Prozeduren in der Datenbank PostgreSQL eingesetzt. Sie ist über eine einfache Schnittstelle zu C leicht erweiterbar.

puts "Hello World!"

codice_2

Der Befehl "puts" erwartet einen String als Eingabe und gibt diesen direkt aus, gefolgt von einem Zeilenumbruch.
Hier die gleiche Ausgabe unter Verwendung des Befehls zum Setzen eines Variablen-Wertes:
set hw "Hello World!"
puts $hw

codice_2

Dies definiert einen neuen Befehl "mean", der wie folgt aufgerufen werden kann

"data" ist also eine Liste von Zahlen. Der Befehl "join" formt aus seinem 1. Parameter "$data" (Inhalt von "data") mithilfe des 2. Parameters "+" einen String der Form "5+4.2+1.2+6.7+9+1+0". Dieser String wird nun in die Stelle eingesetzt, an der zuvor der von eckigen Klammern umschlossene "join"-Befehl stand. Der Befehl "llength" gibt die Länge einer Liste zurück. Die eckigen Klammern funktionieren hier genauso. Die Funktion double() bewirkt, dass die Zahlen nicht als Integer mit Rest, sondern als Gleitkommazahlen mit Dezimalstellen dividiert werden (das ist bei Mittelwerten in der Regel beabsichtigt).

Es ergibt sich für das Beispiel:

expr (5+4.2+1.2+6.7+9+1+0)/double(7)

Der Befehl "expr" berechnet nun den mathematischen Ausdruck.

Das Beispiel zeigt, wie einfach in Tcl Stringverarbeitung und Berechnungen gemischt werden können, um Algorithmen prägnant zu formulieren.

Tcl macht die Entwicklung grafischer Benutzerschnittstellen sehr einfach:
Das folgende Mini-Programm erstellt einen Button im Fenster, der beim Anklicken die Anwendung beendet.

package require Tk
pack [button .b -text "Goodbye World" -command exit]
Zusätzlich zum klassischen Tk-Widget-Set, das je nach Plattform das Aussehen von Motif, Microsoft Windows, oder Mac OS Classic simuliert, gehört ab Version 8.5 auch das Widget-Set "Ttk" (themeable Tk) fest zu Tk. Dabei kann ein Theme aus einer Theme-Bibliothek ausgewählt oder selbst erstellt werden.

package require Tk
ttk::setTheme clam
pack [ttk::button .b -text "Goodbye World" -command exit]
Datenbankoperationen sind mit Tcl ebenfalls sehr einfach, wie das folgende Beispiel zeigt:

package require sqlite3
sqlite3 meinedatenbank ./meinedatenbank.sqlite
set var 3
meinedatenbank eval {CREATE TABLE tabelle1 (id int, spalteA char(20))}
meinedatenbank eval {INSERT INTO tabelle1 (id, spalteA) VALUES (1, 'foo'), (2, 'bar'), (3, 'ßülz')}
meinedatenbank eval {SELECT * FROM tabelle1 WHERE id = :var} ergebnis {
meinedatenbank eval {DELETE FROM tabelle1}
meinedatenbank eval {DROP TABLE tabelle1}
meinedatenbank close

Dabei werden Variablenreferenzen nicht expandiert, sondern der Datenbankengine übergeben, so dass keine Sicherheitslücke durch SQL-Injection entstehen kann.

Diese direkte Anwendung der SQLite3-Schnittstelle gilt mittlerweile als veraltet, weil es die datenbankunabhängige Schnittstelle TDBC gibt, deren Name sich an ODBC und JDBC anlehnt. Im Lieferumfang von TDBC sind die Treiber für SQLite3, MySQL, ODBC (ähnlich der JDBC-ODBC-Bridge) und PostgreSQL.

Tcl kann als prozedurale ebenso wie als funktionale Programmiersprache eingesetzt werden, da Namen von Funktionen auch Argumente von Funktionen sein können. Über Erweiterungen wie stooop, Snit, Incr Tcl und Incr Tk sowie XOTcl ist Tcl auch objektorientiert – bis hin zur Mehrfachvererbung. Ab Version 8.6 ist TclOO im Kern enthalten, Incr Tcl basiert nun auf TclOO.






</doc>
<doc id="5115" url="https://de.wikipedia.org/wiki?curid=5115" title="Telnet">
Telnet

Telnet ("Teletype Network") ist der Name eines im Internet weit verbreiteten Netzwerkprotokolls. Dieses alte und bekannte Client/Server-Protokoll basiert auf einem zeichenorientierten Datenaustausch über eine TCP-Verbindung. Neben dem Protokoll wird der Name "Telnet" auch für die Dienste Telnet-Server und insbesondere für Telnet-Client verwendet. Beide Dienste verwenden das Telnet-Protokoll zur Kommunikation.

Das Telnet-Protokoll besteht aus einem Satz von Kernfunktionen sowie einigen Erweiterungen. Das Kernprotokoll wird in den IETF-Dokumenten RFC 854 und RFC 855 (STD 8) beschrieben. STD 8 beschreibt einige grundsätzliche Arbeitsweisen des Protokolls und Erweiterungsmöglichkeiten.

Es gibt zahlreiche Erweiterungen des Protokolls, einige davon wurden als Internetstandards aufgenommen. Die IETF-STD-Dokumente 27–32 beschreiben diese Erweiterungen.

Telnet-Clients sind auf allen gängigen Betriebssystemen wie Linux, Unix, macOS und auf allen netzwerkfähigen Versionen von Windows standardmäßig unter dem Namen "telnet" aufrufbar. Seit macOS High Sierra wird Telnet, unter dem Namen "telnet," nicht mehr unterstützt. Ein bekannter freier Open-Source-Client ist PuTTY.

Unter Microsoft Windows muss seit Vista der Telnet-Client erst aktiviert werden. Auf einem Windows Server 2008 muss der Dienst zunächst installiert und gestartet werden. Für den Fernzugriff muss zudem der Benutzer in die definierte Gruppe „TelnetClients“ hinzugefügt und die Firewall so eingestellt werden, dass der Standardport 23 nicht blockiert wird.

Entwickelt wurde Telnet 1969 im Rahmen des Projektes ARPANET (Advanced Research Projects Agency Network), mit dem Ziel, teure Rechenzeit, Anwendungsprogramme und Datenbanken auch entfernt nutzen zu können. Es kam aber erst 1974 zum ersten Einsatz.

Telnet wird typischerweise zur Fernsteuerung von Computern in Form von textbasierten Ein- und Ausgaben eingesetzt. Hierzu baut der Telnet-Client eine unverschlüsselte Verbindung zu einem Telnet-Server auf. In dieser Phase wird ein notwendiges Kennwort im Klartext übergeben. Nach dem Verbindungsaufbau wird das Telnet-Protokoll optional initiiert. Auf diese Art können Programme ohne grafische Benutzeroberfläche bedient werden. Üblicherweise handelt es sich um eine Login-Konsole mit voller Befehlsgewalt. Und genau dieses Szenario gilt als unsicher und sollte durch eine ssh-Verbindung ersetzt werden, die auch das Telnet-Protokoll umsetzt, aber verschlüsselt überträgt.

Die Verbindung eines Telnet-Clients mit einem Telnet-Server wird häufig auch Telnet-Dienst genannt.

Dabei kann die steuernde Einheit sowohl ein abgesetztes Gerät als auch ein auf einem Computer installiertes Programm sein. Die Darstellung der übertragenen Informationen kann je nach Endgerät variieren.

Sobald die Verbindung zwischen dem Telnet-Client und dem Telnet-Server hergestellt wurde, werden die Tastatureingaben vom steuernden Endgerät zum fernen Computer gesendet und von dort wiederum Texte an das Endgerät zurück übertragen. Der ferne Computer überträgt so z. B. die textbasierten Ausgaben eines Programmes, etwa eine Schnittstelle zur Eingabe von Befehlen an das Betriebssystem. Auf diese Weise lässt sich von einem Computer aus ein anderer Computer fernbedienen. Dieser Fernzugriff kann sogar über mehr als zwei Stufen erfolgen.

Heutzutage gibt es wenige wesentliche Einsatzgebiete für einen Telnet-Client:

Der Telnet-Dienst (Zusammenspiel zwischen Client und Server) wird u. a. für folgende Einsatzgebiete verwendet:

Viele dieser Anwendungen sind nur einem versierten Fachpublikum bekannt. Z. B. benutzen Internet-Schachspieler oft den Free Internet Chess Server und Gospieler den Internet Go Server, auch Pandanet genannt. Deren grafische Benutzeroberfläche (GUI) interpretiert die Textausgabe der Konsole und zeigt den Spielzug des Gegners auf dem Schach- bzw. Go-brett an. Der eigene Spielzug wird mit der Maus durchgeführt, aber die Information darüber wird wiederum als Text übermittelt. Blindschach wird dann ohne GUI gespielt.






</doc>
<doc id="5117" url="https://de.wikipedia.org/wiki?curid=5117" title="Kanton Thurgau">
Kanton Thurgau

Der Thurgau ( , ) ist ein deutschsprachiger Kanton im Nordosten der Schweiz. Der Hauptort ist Frauenfeld.

Der Kanton grenzt im Norden an das deutsche Land Baden-Württemberg und den Kanton Schaffhausen. Im Süden ist in der Nähe des Hörnli der Grenzpunkt mit den Kantonen St. Gallen und Zürich. Unterhalb des Gipfels des Grat liegt in der Gemeinde Fischingen mit 991 Metern über dem Meeresspiegel der höchste Punkt des Kantons.

Der Hauptort und Sitz des Regierungsrates sowie des Obergerichts ist Frauenfeld. Sitz des Grossen Rates sind halbjährlich wechselnd Frauenfeld und Weinfelden. Der Kanton Thurgau hat seinen Namen vom Fluss Thur, der ihn von Südosten nach Nordwesten durchquert und weiter westlich im Zürcher Bezirk Andelfingen in den Rhein mündet.

Im Kanton werden 61,0 Prozent der Gesamtfläche als landwirtschaftliche Flächen genutzt.

"ThurGIS Viewer" ist das offizielle Portal des Kantons Thurgau zur Darstellung von Geodaten der kantonalen Verwaltung über das Internet.

Die im Thurgau gesprochenen deutschen Mundarten gehören dem Hochalemannischen und innerhalb dessen dem Nordostschweizerdeutschen an.

Gegenüber dem Vorjahr ist 2017 vor allem der Bevölkerungsanteil, der konfessionslos ist oder einer anderen Glaubensgemeinschaft ausserhalb der Landeskirchen angehört, kräftig gestiegen (+3'900 Personen bzw. +4,4 %). Insgesamt waren Ende 2017 93'750 Personen keiner Landeskirche zugehörig. Mit 34,4 % liegt ihr Anteil erstmals höher als jener der evangelischen (33,9 %) oder katholischen Bevölkerung (31,7 %).

Als ehemalige gemeine Herrschaft (gemeinsames Untertanengebiet mehrerer eidgenössischer Orte) ist der Thurgau konfessionell nicht einheitlich. Im grösseren Teil des heutigen Kantons dominiert die reformierte Konfession, doch gibt es mehrere Landstriche mit katholischer Konfession. Nach dem ersten und zweiten Kappeler Religionskrieg im 16. Jahrhundert wurde auf der von den katholischen Ständen dominierten Tagsatzung im zweiten Landfrieden festgehalten, dass die neugeschaffenen religiösen Zustände geschützt sein sollen, dass aber auf Wunsch von drei Gläubigen in einer Kirchgemeinde die katholischen Gottesdienste wieder eingeführt werden müssen und die Pfrundgüter gemeinsam verwaltet werden sollen. Im Weiteren wurde meist das Territorialitätsprinzip angewandt, die Grundherren (der Thurgau war in sehr viele lokale Herrschaften aufgeteilt) konnten massgeblich die Religion der Untertanen beeinflussen, sich aber nicht immer durchsetzen. Es bildeten sich auch viele paritätische Kirchgemeinden, in denen die Kirchen von beiden Konfessionen gemeinsam genutzt wurden, dabei ging es allerdings mehr oder weniger friedlich zu. Als erste reformierte Kirche, die im Thurgau errichtet wurde, gilt die 1617/1618 unter dem Patronat (Kollatur) des Frauenklosters Münsterlingen erbaute Kirche von Scherzingen. Mit dem vierten Landfrieden von 1712 wurden die Reformierten der katholischen Konfession gleichgestellt. Die gemeinsamen Pfrundgüter, aber auch vielerorts die Friedhöfe, wurden nach der Proportion der Konfessionen aufgeteilt. Manche reformierten Kirchgemeinden so zum Beispiel Schönholzerswilen (1714), Roggwil (1746) und Erlen (1764), konnten im 18. Jahrhundert neue Kirchen errichten, was ihnen vor 1712 verwehrt war. Bis 1798 kam es oft vor, dass katholische Kollatoren in den reformierten Kirchgemeinden die sogenannten Prädikanten (Pfarrer) bestimmten. Mit der Aufhebung vieler geistlicher Stifte und des Bistums Konstanz fielen diese Kollaturrechte an den Kanton Thurgau, der sie nach 1820 an die einzelnen Kirchgemeinden vergab.

Die gegenwärtige Verfassung datiert vom 16. März 1987. Sie bildet die Grundlage für die Behördenorganisation, die Volksrechte und die Erfüllung der Staatsaufgaben.

Zu den öffentlichen Aufgaben gehören die Gewährleistung der öffentlichen Ordnung und Sicherheit, die Förderung der sozialen Sicherheit (vor allem die Ausrichtung der Sozialhilfe), die Beaufsichtigung und Koordination des Gesundheitswesens, die Sicherstellung einer ausreichenden medizinischen Versorgung und einer genügenden Bildung im obligatorischen Schulbereich, die Bereitstellung eines leistungsfähigen und vielseitigen öffentlichen Schulangebots (Kindergärten, Volksschulen, Berufsschulen, Mittelschulen), die Förderung des kulturellen Schaffens, der Umweltschutz, das Bauwesen und die Raumplanung, die Förderung des öffentlichen Verkehrs sowie die Versorgung der Bevölkerung mit Energie und Wasser.

Gesetzgebendes Organ (Legislative) ist der Grosse Rat, der 130 Mitglieder zählt und gemäss Verhältniswahlrecht vom Volk auf vier Jahre gewählt wird.

Das Volk ist darüber hinaus direkt an der Gesetzgebung beteiligt, indem Verfassungsänderungen dem obligatorischen und Gesetzesänderungen dem fakultativen Referendum (von mindestens 3000 Stimmberechtigten innert dreier Monate verlangt) unterliegen, ferner besteht für höhere Staatsausgaben ein Finanzreferendum. Das Volk hat sodann das Recht der Verfassungs- und Gesetzesinitiative (von mindestens 4'000 Stimmberechtigten verlangt), und es kann (mit mindestens 20'000 Unterschriften) die Abberufung des Grossen Rats vor Ablauf der ordentlichen Amtszeit verlangen, worüber jeweils eine Volksabstimmung anzuordnen ist.

Ausführendes Organ (Exekutive) ist der Regierungsrat, der aus fünf Mitgliedern besteht und vom Volk gemäss Mehrheitswahlrecht auf ebenfalls vier Jahre gewählt wird.

Das Volk kann (wenn von mindestens 20'000 Stimmberechtigten verlangt) die vorzeitige Abberufung der Regierungsrates beantragen, über die dann eine Volksabstimmung angeordnet werden muss.

Der Regierungsrat setzt sich seit 1. Juni 2015 wie folgt zusammen:

Mit der Wahl von Cornelia Komposch stellen die Frauen erstmals eine Mehrheit in der Thurgauer Regierung. – Die Staatskanzlei führt Staatsschreiber Rainer Gonzenbach (seit 1. Juni 2000).

Richterliche Behörden sind auf kantonaler Ebene das Obergericht, das Verwaltungsgericht und das Zwangsmassnahmengericht.

Auf regionaler Ebene gibt es fünf erstinstanzliche Bezirksgerichte, denen auf Kreisebene zwanzig Friedensrichterämter vorgeschaltet sind.

Die Christlichdemokratische Volkspartei (CVP), die Freisinnig-demokratische Partei (FDP), die Schweizerische Volkspartei (SVP) und die Sozialdemokratische Partei (SP) sind in der Exekutive (Regierungsrat) vertreten. Im Parlament sind überdies die Grüne Partei (GP), die Evangelische Volkspartei (EVP), die Eidgenössisch-Demokratische Union (EDU), die Grünliberale Partei (GLP) und die Bürgerlich Demokratische Partei (BDP) repräsentiert.

Bis Ende 2010 war der Kanton Thurgau in acht Bezirke organisiert; im Zuge der Bezirks- und Justizreform wurde die Zahl auf fünf reduziert (siehe auch "Bezirke des Kantons Thurgau"). Die Bezirke fungieren als Gerichts- und Wahlkreise. Die Zivilstandsämter sowie die Kindes- und Erwachsenenschutzbehörden sind ebenfalls bezirksmässig organisiert.

Die fünf Bezirke mit gleichnamigem Hauptort heissen:

Organe der örtlichen Selbstverwaltung sind die politischen Gemeinden. Der frühere sogenannte Gemeindedualismus, der durch ein Nebeneinander von Orts- und Munizipalgemeinden charakterisiert war und aus napoleonischer Zeit stammte, wurde durch die neue Verfassung von 1987 abgeschafft. Weiterhin bestehen aber auch öffentlichrechtlich anerkannte Schul-, Bürger- sowie die evangelisch-reformierten und römisch-katholischen Kirchgemeinden.

Das Rückgrat der Thurgauer Volkswirtschaft bildet eine Vielzahl kleiner und mittlerer Unternehmen. Eine überragende Bedeutung hat im Thurgau das verarbeitende Gewerbe, darunter insbesondere die Metallindustrie und der Maschinenbau. Weitere bedeutende Branchen sind die Nahrungs- und Genussmittelindustrie, Elektronikindustrie sowie das Segment der Kunststoffwaren. Eigentliche Wachstumsbranchen sind der Fahrzeugbau sowie das Verlags- und (Tele)-Kommunikationswesen.

Ende Dezember 2011 arbeiteten im Kanton Thurgau rund 130'000 Beschäftigte in rund 20'000 Arbeitsstätten. Die Beschäftigung verteilt sich wie folgt auf die drei Wirtschaftssektoren: Land- und Forstwirtschaft 5,9 Prozent; Industrie und Bau 36,6 Prozent; Dienstleistungen 57,5 Prozent.

Der langfristige Trend der Beschäftigungsverlagerung vom agrarischen und vom industriellen in den Dienstleistungssektor hält nach wie vor an. Trotz der Abnahme von Arbeitsplätzen im primären Sektor um gut 2 Prozent in den Jahren 2005 bis 2008 liegt dessen Anteil an der Gesamtbeschäftigung im Thurgau mit 6,5 Prozent immer noch über dem gesamtschweizerischen Durchschnitt von 3,3 Prozent. Ähnlich verhält es sich im industriell-gewerblichen Sektor, dessen Beschäftigungsanteil ebenfalls deutlich über dem gesamtschweizerischen Mittel von 28,5 Prozent liegt (Thurgau: 39,5 Prozent). Hingegen haben fast alle Dienstleistungsbranchen im Thurgau ein geringeres Gewicht als in der Gesamtschweiz und dies, obwohl die Beschäftigung im Dienstleistungssektor zwischen 2005 und 2008 um rund 10 Prozent gewachsen ist. Die Wachstumstreiber im dritten Sektor waren das Gesundheits- und Sozialwesen sowie der Detailhandel.

Im Jahr 2013 wurde knapp ein Drittel (29,4 Prozent) aller Thurgauer Exporte in Deutschland abgesetzt. Mit Abstand folgen Italien (9,8 Prozent) sowie Frankreich (6,6 Prozent) und Österreich (5,5 Prozent). Insgesamt gingen im Jahr 2013 73,3 Prozent des Ausfuhrvolumens in die Europäische Union. Ausserhalb der Europäischen Union waren die Vereinigten Staaten (5,1 Prozent) und asiatische Transformations- (3,3 Prozent) und Schwellenländer (2,8 Prozent) wichtige Handelsstaaten.

Die sanfte Hügellandschaft und das 70 Kilometer lange Thurgauer Bodenseeufer eignen sich besonders zum Radfahren, Wandern und Inline-Skaten. 900 Kilometer beschilderter Radwege auf Nebenstrassen und landwirtschaftlichen Nutzwegen machen aus dem Thurgau ein Paradies für Velofahrer.
Dazu kommen 220 Weiher und Kleinseen, 1600 Kilometer Flüsse und Bäche, diverse natürliche öffentlich zugängliche Badeplätze sowie traditionelle Badeanstalten.

Im Jahr 2013 wurden über 421'006 Logiernächte registriert. Die ausländischen Gäste kamen überwiegend aus Deutschland in den Thurgau.

Ein wichtiges Standbein bildet der Seminar- und Tagungstourismus. Durch gegenseitige Unterstützung, Erfahrungsaustausch und Koordination fördert und entwickelt "Seminarland Thurgau", eine Arbeitsgemeinschaft verschiedenen Tagungs- und Seminarhotels sowie Ausbildungszentren, den Seminar- und Tagungstourismus im Kanton Thurgau.
Schlösser am Bodensee und kulturhistorisch bedeutsame Klöster, verwinkelte Ortschaften und selbstverständlich auch die zeitgenössische Kunst und Kultur in unseren Kunsträumen und originellen Museen gilt es zu entdecken. Um diese Vielfalt einladend zu präsentieren, gibt es die Arbeitsgemeinschaft "Kulturland Thurgau". Ihre Partner haben sich zur Aufgabe gemacht das vielseitige und qualitativ hochstehende kulturelle Angebot zu vernetzen, gemeinsam zu präsentieren und damit die Ausstrahlung der kulturellen Vielfalt und Qualität zu fördern.
Unter dem Titel "Schlaraffenland Thurgau" wird der Thurgau als Genussregion beworben. In Zusammenarbeit mit Gastronomiebetrieben und Produzenten aus dem Thurgau werden saisonale und regionale Produkte gefördert und Genuss-Angebote entwickelt. Ziel ist es, den Thurgau in der übrigen Schweiz als kulinarische Destination zu positionieren.

In Zusammenarbeit mit den touristischen Leistungsträgern übernimmt der Thurgau Tourismus als Destinationsmanagementorganisation (DMO) sowie als Gesellschafter der Internationalen Bodensee Tourismus GmbH (IBT GmbH) die touristische Vermarktung dieser Reiseregion.

Der Kanton Thurgau liegt zwischen Zürich, der Ostschweizer Hauptstadt St. Gallen und dem Bodensee.

Die Nähe zur Schweizer Wirtschaftsmetropole Zürich und zum Flughafen Zürich (30 Minuten ab Frauenfeld) sichern die schnelle Verbindung zu nationalen und internationalen Zielen. Ebenfalls in Reichweite sind die Flughäfen von Friedrichshafen (Deutschland) und St. Gallen-Altenrhein.

Der Kanton ist durch zwei Autobahnen (A1 und A7) sowie zwei Schnellzugsachsen (Zürich–Konstanz/Romanshorn und Zürich–St. Gallen) mit den Zentren in der Schweiz und des nahen Auslands (Deutschland und Österreich) verbunden.

Die Verbindungen zu den Nachbarregionen sowie die innerkantonalen Verbindungen werden einerseits durch ein gut ausgebautes Kantons- und Gemeindestrassennetz sowie durch eine Vielzahl von regionalen Bahn- und Buslinien gewährleistet. Der öffentliche Verkehr ist in den vergangenen Jahren sukzessive ausgebaut worden. Im Jahr 2009 sind für alle öffentliche Verkehrsmittel (Bahn- und Buslinien, Ortsverkehr und Schifffahrtslinien) rund 12,5 Millionen Kilometer an Leistung geplant. Im Jahr 2008 beförderten sie über 32 Millionen Passagiere. Dies sind beinahe elf Millionen Personen mehr als im Jahr 2000.

Das schulische Angebot umfasst zunächst Kindergärten, Primarschulen und Sekundärschulen in 60 Schulgemeinden des Kantons Thurgau. Diese sind dem kantonalen Amt für Volksschule unterstellt.

Ein Gymnasiumsabschluss (Matura) kann an den Kantonsschulen Frauenfeld, Kreuzlingen und Romanshorn abgelegt werden. Dank eines Abkommens mit dem Kanton St. Gallen besuchen die Thurgauer Schülerinnen und Schüler die Kantonsschule Wil zu gleichen Bedingungen wie jene aus St. Gallen. Die Kantonsschulen Frauenfeld und Romanshorn bieten eine Fachmittelschule mit Fachmatura an. Ausserdem unterhält die Kantonsschule Frauenfeld eine Handelsmittelschule und eine Informatikmittelschule, beide mit Berufsmaturität. Ein überkantonales Angebot stellt die Thurgauisch-Schaffhauserische Maturitätsschule für Erwachsene dar.

Die Pädagogische Hochschule Thurgau (PHTG) wurde 2003 mit Sitz in Kreuzlingen gegründet. Sie ist eine Einrichtung auf Tertiärstufe und dient der Aus- und Weiterbildung von Lehrpersonen auf Vorschulstufe, Primarschulstufe, Sekundarstufe I, Sekundarstufe II sowie, in Form eines Masterstudiengangs, Frühe Kindheit. Kooperationspartner ist dabei die Universität Konstanz. Daneben ist die Pädagogische Hochschule Thurgau in Form von Studiengängen und Kursen im Bereich der Weiterbildung tätig. Sie betreibt Forschung und unterhält ein Medien- und Didaktikzentrum mit dem Schwerpunkt Dienstleistungen für Lehrpersonen und Studierende.

Orte der Vermittlung von Wissen sowie der Begegnung ganz unterschiedlicher Menschen und Gruppen stellen die Thurgauer Bibliotheken dar: die Kantonsbibliothek Thurgau, das Medien- und Didaktikzentrum der Pädagogischen Hochschule, die Bibliotheken der Berufsinformationszentren in Amriswil, Frauenfeld und Kreuzlingen, je 22 Gemeinde- sowie Fach- und Spezialbibliotheken und ein vielseitiges Angebot an Schulmediotheken. Ihr Dienstleistungsangebot wird durch institutionenübergreifende Zugänge wie etwa die Digitale Bibliothek Ostschweiz ergänzt.

Auf die Auseinandersetzung mit der Thurgauer Kulturgeschichte, die Kenntnis der Natur und ihrer Zusammenhänge sowie die Begegnung mit zeitgenössischer Kunst sind die kantonalen Museen ausgerichtet, so das Napoleonmuseum Schloss und Park Arenenberg, das Kunstmuseum Thurgau, das Ittinger Museum, das Historische Museum Thurgau im Schloss Frauenfeld, das Naturmuseum Thurgau sowie das Museum für Archäologie, beide in Frauenfeld.

"Thurgau Wissenschaft" ist ein Netzwerk für Wissenschaft und Forschung im Kanton Thurgau. Partner sind: das kantonale Amt für Archäologie, das Bildungs- und Beratungszentrum Arenenberg, das Biotechnologische Institut Thurgau, die Dienststelle für Statistik, das Institut für Werkstoffsystemtechnik Thurgau, die Kantonsbibliothek Thurgau, das Napoleonmuseum Thurgau, die Pädagogische Hochschule Thurgau, das Thurgauer Wirtschaftsinstitut, die Thurgauer Naturforschende Gesellschaft. Das Netzwerk führt eine eigene Webseite und einen Newsletter über seine Aktivitäten.

Nachfolgend aufgelistet sind die zehn grössten politischen Gemeinden per :

In der Schweiz heisst der Kanton Thurgau scherzhaft auch «Mostindien». Geschaffen wurde der Begriff von der Redaktion der humoristischen Zeitschrift "Der Postheiri," die 1845–1875 von Alfred Hartmann in Solothurn herausgegeben wurde. In diesem Blatt wurde der in Form einer Mostbirne gezeichnete Thurgau erstmals 1853 mit «Most-India» beschriftet. Das Bestimmungswort «Most-» ist eine Verballhornung von «Ost» und verquickt die östliche Lage des Thurgaus mit dem im Thurgau bedeutsamen Obstbau beziehungsweise dem einst berühmten Thurgauer Birnenmost; der Gesamtname «Mostindien» ist ein sinnfreies Wortspiel mit "Ostindien," einem damals bekannten geographischen Raum, der als Gegensatz zum karibischen Westindien das heutige Südasien und Südostasien bezeichnete. Schon 1849 war im "Postheiri" von der «Mostschweiz» (in Anlehnung an Ostschweiz) die Rede, und 1854 folgten das «Mostindische Meer» (an Ostindisches Meer anklingend) und die «Mostsee» (an Ostsee anklingend), beide für den Bodensee. Das Grundwort «-Indien» hat somit nichts mit Indien zu tun; auch andere Wortschöpfungen des "Postheiris" wie «Honolulu» für Solothurn, «Mesopotamien» beziehungsweise «Mutzopotamien» für Bern und «Persepolis» für Zürich spielen nur formal auf die namengebenden realen Örtlichkeiten an.

Die Hymne des Kantons ist das Thurgauerlied "O Thurgau du Heimat". Die Melodie stammt von Johannes Wepf, der Text von Johann Ulrich Bornhauser.



</doc>
<doc id="5118" url="https://de.wikipedia.org/wiki?curid=5118" title="Telepathie">
Telepathie

Telepathie (altgr. "tēle" „fern“, „weit“ und "páthos" „Erfahrung“, „Einwirkung“) ist eine von Frederic W. H. Myers geprägte Bezeichnung für eine manchen Menschen zugeschriebene Fähigkeit, Gedanken, Antriebe, Empfindungen oder Gefühle in einer Art Fernwirkung von sich auf eine andere Person oder von einer anderen Person auf sich zu übertragen; mitunter als "Gedankenlesen" oder "Gedankenübertragung" bezeichnet.

Die sogenannte Parapsychologie versucht unter anderem, Nachweise für telepathische Wahrnehmungen zu finden.

Telepathie ist eine Wortschöpfung des britischen Autors, Dichters, Kritikers und Essayisten Frederic W. H. Myers, die von ihm erstmals im Dezember 1882 vor der Society for Psychical Research (SPR) in London veröffentlicht wurde. Die bis dahin gebräuchliche Bezeichnung "thought transference" (deutsch: „Gedankenübertragung“) für das Phänomen wurde durch Myers’ Wortschöpfung abgelöst. 

Myers’ Wortschöpfung erfolgte im England des Viktorianischen Zeitalters, in dem etwa seit 1850 der Glauben an Spiritismus und besondere psychische Kräfte weit verbreitet und Séancen ein gängiger Zeitvertreib in wohlhabenden bürgerlichen Kreisen waren. Diese Bewegung wurde damals auch von durchaus renommierten Wissenschaftlern wie William Crookes unterstützt, der überzeugt war, bei der Untersuchung der damals berühmten Medien Daniel Home und Florence Cook eine neue psychische Kraft experimentell nachgewiesen zu haben. Auch der Elektroingenieur Cromwell Fleetwood Varley und der Biologe Alfred Russel Wallace waren von der Möglichkeit der Gedankenübertragung überzeugt, die allerdings schon damals von den führenden naturwissenschaftlichen Vertretern wie den Mitgliedern des X-Clubs als lächerlich zurückgewiesen wurde. Das Konzept der Telepathie war ursprünglich eher ein Versuch, das Konzept der Gedankenübertragung aus dem Zusammenhang mit Spiritismus, Medien und Geistern zu lösen und zu versachlichen. Die überwiegend mit der Cambridge University verbundenen Gelehrten der neu gegründeten Society for Psychical Research, zu deren Gründungsmitgliedern Myers zählte, sahen auf das Treiben bei den damals üblichen Séancen mit Verachtung herab und nahmen sich vor, die dahinterliegenden Phänomene von Schwindel und Leichtgläubigkeit zu reinigen und wissenschaftlich zu erforschen. Für sie war Telepathie ein beschreibender Begriff, der nicht mit Vermutungen über die dahinterliegenden Kräfte vermischt werden sollte. Insbesondere sei es nicht zwingend, dafür Kräfte oder Wirkungen anzunehmen, die im Widerspruch zur wissenschaftlichen Physik stünden. Durch den Mediziner Charles Richet wurden sogar im Jahr 1884 einige der ersten randomisierten kontrollierten Studien überhaupt zur Erforschung des Phänomens vorgeschlagen, als dieses Konzept in der Wissenschaft noch völlig neu und ungebräuchlich war (wenn auch die meisten Parapsychologen von den geringen durch Richet dafür ermittelten Wahrscheinlichkeiten enttäuscht waren).

Untersuchungen nach wissenschaftlichen methodischen Standards werden durch Psychologen, überwiegend aber durch Parapsychologen, seit mehr als hundert Jahren durchgeführt. Ein Hauptziel dieser Untersuchungen war von Anfang an ein wissenschaftlicher Nachweis dafür, dass Telepathie existiert. Dieser Nachweis konnte bis heute, zumindest nach Einschätzung der Mehrheit der Wissenschaftler, nicht erbracht werden. 

Um die statistische Aussagekraft der Resultate zu erhöhen, wurden dabei bald anstelle freier Fragen, die zahlreiche Interpretationsmöglichkeiten der Antworten zulassen, standardisierte Versuchsprotokolle eingeführt. Zu diesem Zweck wurden zum Beispiel die sogenannten „Zenerkarten“ entwickelt. Die Bezeichnung stammt von Joseph Banks Rhine, der die Karten nach seinem Kollegen Karl Zener benannt hat. Auf den Karten sind fünf verschiedene Symbole abgebildet: ein Kreis, ein Kreuz, drei Wellenlinien, ein Quadrat und ein fünfzackiger Stern. Ein gebräuchlicher Satz besteht aus 25 Karten (je fünf Karten von jedem Symbol). Wenn eine Versuchsperson (der „Empfänger“) darauf getestet werden soll, ob sie zum Beispiel die Reihenfolge der Aufdeckung von Karten einer anderen Person (des „Senders“) durch „Psi-Kräfte“ ersehen kann, liegt ihre Ratewahrscheinlichkeit, bei fünf Karten, bei 20 Prozent. Kann sie einen signifikant höheren Anteil richtig angeben, wäre dies ein Hinweis auf Telepathie. Durch die Standardisierung ist es möglich, den Versuch später zu wiederholen (wissenschaftlich Replikation genannt), was für eine wissenschaftliche Anerkennung entscheidend wäre. Diese einfachen Ratetests wurden schon Anfang des 20. Jahrhunderts eingeführt und später verfeinert. Der Höhepunkt ihres Einsatzes lag in den 1940er Jahren. In den 1970er und 1980er Jahren wurden verstärkt die sogenannten Ganzfeld-Versuche populärer.

Parapsychologen vertreten den Anspruch, mit diesen Tests und Methoden statistisch signifikante Versuchsergebnisse erzielt zu haben, die auf – kausal unerklärliche – telepathische Fähigkeiten zumindest einiger Versuchspersonen hinweisen, und meinen dies auch durch Metaanalysen absichern zu können. Diesem Anspruch wird von Psychologen und anderen Wissenschaftlern allerdings vehement widersprochen. Dabei wird den Parapsychologen im Allgemeinen guter Wille und methodisch durchaus hochwertiges Versuchsdesign unterstellt (obwohl einige Forscher auch unter Betrugsverdacht gerieten). Die Vertreter der „orthodoxen“ Wissenschaft unterstellen ihnen aber methodische Fehler bei der Durchführung oder der Datenanalyse. Wichtige Fehlerquellen, die die wissenschaftliche Psychologie oft in gleicher Weise betreffen und dort möglicherweise ein ebenso großes Problem darstellen, sind zum Beispiel: Durchführung des Versuchs, bis das erwünschte Ergebnis signifikant ist, und sofort danach Abbruch (ehe der möglicherweise nur zufällige Effekt wieder verschwinden kann), Durchführung zahlreicher Tests, von denen nur die mit erwünschtem, oder mit signifikantem, Ergebnis publiziert werden, Messung zahlreicher Variablen und ihrer Kombination, wobei die ohne erwünschtes Ergebnis verschwiegen werden. Außerdem werden sehr oft Untersuchungen mit sehr geringen Datenmengen (wenigen Versuchspersonen und Durchgängen) veröffentlicht, die eine sinnvolle Beantwortung der Frage (aufgrund zu geringer Power) gar nicht zulassen. Oft zeigt sich dadurch in einzelnen Studien zunächst ein scheinbar sehr großer, für sich betrachtet signifikanter Effekt, der aber bei den Replikationen scheinbar immer kleiner wird und letztlich verschwindet.

Obwohl Statistiker den Parapsychologen bescheinigt haben, dass einige ihrer Studien den in der Psychologie akzeptierten Standards durchaus entsprechen, erreichte bisher keine ihrer Untersuchungen zur Telepathie ein Niveau, das Wissenschaftler überzeugen konnte, denn keiner der zunächst vielversprechend aussehenden Befunde konnte letztlich repliziert werden. 

Ein weiteres Problem ist es vermutlich, dass Parapsychologen es bis heute nicht vermocht haben, ein schlüssiges Erklärungsmodell für ihre Befunde anzubieten, oder sogar offen über Effekte und Phänomene spekulieren, die das physikalische Weltbild widerlegen oder zumindest unvollständig machen würden. Für solche weitreichenden Schlussfolgerungen verlangt die Wissenschaft besonders gut abgesicherte Gründe, die über bei „durchschnittlichen“ und erwartbaren Resultaten akzeptierte Standards hinausgehen müssen.

An einigen Universitäten wird an Telepathie im Rahmen der Parapsychologie als Teilgebiet der Psychologie geforscht, darunter, seit 2001, keine deutsche oder deutschsprachige Universität mehr. Von 1954 bis 1998 existierte an der Universität Freiburg die von Hans Bender geleitete Abteilung "Grenzgebiete der Psychologie", deren Forschungsarbeit durch das von Bender 1950 gegründete Institut für Grenzgebiete der Psychologie und Psychohygiene in Freiburg weitergeführt wird.

Angeblich telepathische Phänomene werden vielfach auf Fehleinschätzungen von Wahrnehmungen zurückgeführt. Es gibt Studien, die zu dem Ergebnis kamen, dass Personen, die paranormale Phänomene für möglich halten, auch wissenschaftlich beschreibbaren Phänomenen eher paranormale Erklärungen zusprechen, und dass der Glaube an paranormale Phänomene einhergeht mit einer erhöhten Fähigkeit zum Phantasieren, einem geringeren Maß an kritischem Denkvermögen und einer verringerten Fähigkeit zur Abschätzung von Wahrscheinlichkeiten. Bei einigen dieser Personen wurde eine erhöhte Aktivität der rechten Gehirnhälfte festgestellt, die angeblich Rückschlüsse auf Stärken im gefühlsmäßigen, kreativen Bereich und Schwächen beim Lösen von logischen Aufgaben zulässt.

Cold Reading ist eine Methode, die suggerieren kann, dass eine angeblich hellsehende Person Informationen besitze, die sie nur auf übernatürlichem Wege erhalten haben kann.

Seit 1922 werden von verschiedenen Organisationen Preisgelder für den Nachweis von parapsychologischen Fähigkeiten ausgeschrieben. Aktuell existieren weltweit mehr als 20 verschiedene Organisationen, die eine Gesamtsumme von über 2,4 Millionen US-Dollar ausgeschrieben haben. Das höchste Preisgeld für den Nachweis von übersinnlichen Fähigkeiten wie Telepathie wird aktuell mit einer Million US-Dollar von der James Randi Educational Foundation ausgeschrieben. Seit 1922 war kein einziger durch diese Organisationen durchgeführter Test auf paranormale Fähigkeiten erfolgreich.

Autoren, die telepathische Fähigkeiten trotz der fehlenden allgemein anerkannten Beweise und der Skepsis der Wissenschaftsgemeinde aufgrund ihrer eigenen Forschungen, Eindrücke und Indizienfunde für existent halten, sind zum Beispiel der Biologe Rupert Sheldrake (Morphische Felder), der Sozialpsychologe Daryl J. Bem und Charles Honorton (Ganzfeld-Versuche), der Systemtheoretiker Ervin László, der Ethnologe Adolphus Peter Elkin (hielt Telepathie aufgrund seiner Studien in Australien bei sogenannten Naturvölkern für ziemlich alltäglich) oder die Psychologin Hanna Rheinz (Traum-Suggestion im Schlaflabor am New Yorker Maimonides Medical Center; telepathische Kommunikation eineiiger Zwillinge).

Innerhalb der Science-Fiction-Literatur gibt es zahlreiche Erzählungen und Romane, die sich mit dem Thema Telepathie befassen.
In seinem Roman "Psi-Patt" beschrieb der US-amerikanische Science-Fiction-Autor Lester del Rey mit der Gabe der Telepathie verbundene psychische Gefahren und Qualen für die Betroffenen. Die Schriftstellerin Marion Zimmer Bradley ("Die Nebel von Avalon") schuf in ihren Darkover-Romanen eine Welt, deren Geschichte, Kultur und Technologie weitgehend auf den vererbbaren telepathischen Fähigkeiten aristokratischer Familien basiert.

Neben literarischen Verarbeitungen gibt es eine Reihe von filmischen Umsetzungen des Themas. Eine der ältesten ist "Das Dorf der Verdammten" (1960, Originaltitel "Village of the Damned") von Wolf Rilla. Der Film basiert auf dem Roman "Kuckuckskinder" (Originaltitel "The Midwich Cuckoos") von John Wyndham und beschreibt am Beispiel von zwölf aus unerklärlichen Gründen geborenen Kindern, wie eine außerirdische Macht mittels telepathischer Beeinflussung versucht, Menschen zu beherrschen. Der gleichnamige Horrorfilm "Das Dorf der Verdammten" (1995) von John Carpenter ist eine Neuverfilmung des Films von Wolf Rilla. In dem Film "Ghostbusters – Die Geisterjäger" (1984) wird zu Beginn ein Experiment mit Zenerkarten durchgeführt. In dem Film "Scanners – Ihre Gedanken können töten" (1981) von David Cronenberg sowie den beiden Fortsetzungen ist Telepathie das zentrale Thema.

Vier Wissenschaftler der japanischen Universität in Kyoto haben im Januar 2018 eine künstliche Intelligenz vorgestellt, die aus den gemessenen Gehirnaktivitäten (Magnetresonanzscans) eines Menschen in etwa erkennen kann, welches Bild sich der Mensch gerade ansieht oder sogar nur ausdenkt. Die KI visualisiert die Bilder dann auf einem Bildschirm. Die Bilder sind nicht akkurat, aber Formen und Farben sind schemenhaft erkennbar. Auch Symbole und Buchstaben kann die KI so identifizieren. Die KI wurde über 10 Monate mit drei Probanden und 1000 Bildern, die wiederholt angeschaut wurden, trainiert. Dies stellt erste Ansätze von Telepathie zwischen Mensch und Maschine dar, was für die Maschinensteuerung nützlich sein kann.



</doc>
<doc id="5119" url="https://de.wikipedia.org/wiki?curid=5119" title="Telekinese">
Telekinese

Der Begriff Telekinese oder Psychokinese (von altgriechisch: "tēle" „fern“ und "kínēsis" „Bewegung“) bezeichnet eine Bewegung oder Ortsveränderung von Gegenständen, die angeblich im Zusammenhang mit spiritistischen Erscheinungen oder durch geistige Kräfte bestimmter Personen auftreten. Die Parapsychologie beschäftigt sich mit der Suche nach Belegen für die Telekinese. Ein wissenschaftlich nachvollziehbarer Nachweis oder Wirkungszusammenhang ist nicht erbracht worden.

Oft wird unterschieden zwischen der Makropsychokinese, bei der Gegenstände sichtbar verformt oder bewegt werden, und der Mikropsychokinese, bei der elektronische Schaltkreise oder radioaktiver Zerfall beeinflusst werden sollen. Bei der Retro-Psychokinese sollen Daten beeinflusst werden, die bereits in der Vergangenheit erzeugt wurden. Seltener verwendet werden die Begriffe Pyrokinese für die angebliche Fähigkeit, Feuer allein durch Gedanken zu entzünden, Kryokinese für das allein durch Gedanken verursachte Gefrieren von Wasser, Aerokinese für die Einflussnahme auf Luft, Ferrokinese für die Manipulation magnetisch beeinflussbarer Metalle und Biokinese für die Einflussnahme auf biologische Systeme.

In den 1970er Jahren experimentierte der deutsch-amerikanische Physiker Helmut Schmidt mit einem selbst entwickelten Zufallsgenerator auf der Basis von radioaktivem Zerfall, dessen Impulse in Lichtsignale umgesetzt wurden (d. h. entweder leuchtete ein rotes Lämpchen oder ein grünes auf). Versuchspersonen hatten die Aufgabe, diese Lichtsignale durch Gedankenkraft zu beeinflussen (z. B. das grüne Lämpchen solle häufiger aufleuchten als das rote). Und tatsächlich zeigte sich eine immer wiederholende Abweichung.

Eine 2006 durchgeführte Metaanalyse, in der 380 Studien über Psychokinese ausgewertet wurden, kam zu dem Schluss, dass Psychokinese nicht erwiesen ist. Der Effekt der Psychokinese war – umgekehrt proportional – sehr stark abhängig vom jeweiligen Versuchsumfang und zudem extrem heterogen. Das heißt, Psychokinese konnte nur bei kleinen Stichproben und nur gelegentlich beobachtet werden. Mit durchgeführten Monte-Carlo-Simulationsrechnungen kommen die Autoren zu dem Schluss, dass die Beziehung zwischen jeweiligem Versuchsumfang, beobachtetem Effekt sowie der (sehr geringen) Größe des Effektes das Ergebnis eines Publikationsbias ist.

Telekinese (oder Psychokinese) findet sich häufig als eine psychische Kraft in Filmen, im Fernsehen, in Computerspielen, in der Literatur, in Comics und anderen Formen der Unterhaltung. In der Fernsehserie "Mein Onkel vom Mars" aus dem Jahre 1963 beherrscht der außerirdische Protagonist das Bewegen von Dingen, indem er auf sie zeigt. In dem Film "Carrie (1976)", der auf der gleichnamigen Novelle von Stephen King beruht, stellte Sissy Spacek eine verstörte Schülerin mit telekinetischen Kräften dar. Für diese Rolle wurde sie für einen Oscar als beste Hauptdarstellerin nominiert. Im englisch-französischen Film "Der Schrecken der Medusa" von 1978 mit Richard Burton und Lino Ventura in den Hauptrollen geht es um einen Mann, der mit der Macht seiner Gedanken Katastrophen herbeiführen kann. In den Krieg-der-Sterne-Filmen und darauf beruhenden Kurzgeschichten und Computerspielen haben die Jedi-Ritter die Fähigkeit, Gegenstände mental durch "Die Macht" zu kontrollieren. Verschiedene psychokinetische Fähigkeiten finden sich bei fiktiven Charakteren wie Jean Grey (X-Men), Andros (Power Rangers), Piccolo (Dragon Ball), einigen Pokémon, The Doctor (Doctor Who), Gucky (Perry Rhodan), Prue Halliwell und Christopher Chris Perry Halliwell ("Charmed – Zauberhafte Hexen").






</doc>
<doc id="5121" url="https://de.wikipedia.org/wiki?curid=5121" title="Thomas Jonathan Jackson">
Thomas Jonathan Jackson

Thomas Jonathan Jackson (genannt „Stonewall“; * 21. Januar 1824 in Clarksburg, Virginia (heute West Virginia); † 10. Mai 1863 in Guinea Station, Spotsylvania County, Virginia) war Major des US-Heeres, Lehrer am Virginia Military Institute (VMI) in Lexington, Virginia, und General im Heer der Konföderierten Staaten von Amerika im Amerikanischen Bürgerkrieg. Bekannt ist er vor allem durch den erfolgreichen Shenandoah-Feldzug und den Flankenangriff bei Chancellorsville, die ihm den Ruf einbrachten, "General Robert E. Lees fähigster Untergebener" zu sein.

Jackson wurde als Kind eines Anwalts geboren. Sein Vater und seine ältere Schwester starben 1826 an Typhus. Nach dem Tod des Vaters blieben der Witwe hohe Schulden und die Familie verarmte. Nachdem seine Mutter 1830 wieder geheiratet hatte, wurde Jackson zu einem unverheirateten Onkel aufs Land geschickt. Dort musste er die landwirtschaftlichen Tätigkeiten auf dem Hof seines Onkels erledigen. In seiner freien Zeit nutzte Jackson jede Gelegenheit, zur Schule zu gehen. Er war ein überdurchschnittlich guter und sportlicher Schüler, erhielt aber keinen höheren Abschluss.

Jackson wurde 1842 an die Militärakademie in West Point, New York berufen, allerdings nicht als erste Wahl seines vorschlagenden Kongressabgeordneten. Wegen seiner mangelhaften Schulbildung hatte er besonders im ersten Jahr erhebliche Schwierigkeiten, mit seinen Klassenkameraden mitzuhalten, die ihn nannten. Zu diesen gehörten unter anderen die späteren Generale beider Seiten George B. McClellan, Jesse L. Reno, Darius N. Couch, Ambrose P. Hill und George Edward Pickett.

Seine Defizite auf allen Gebieten glich er durch häufiges, nächtelanges Lernen aus. Jackson schloss die Militärakademie 1846 als 17. seiner Klasse ab. Zum Leutnant befördert, wurde er zur Artillerie versetzt und nahm während des Mexikanisch-Amerikanischen Krieges an General Scotts Feldzug von Vera Cruz bis Mexiko-Stadt teil. Sein Batteriechef lobte ihn als hingebungsvollen, eifrigen, talentierten und tapferen Soldaten. Eigenständiges und mutiges Handeln zeichneten ihn bereits damals aus. In Folge wurde er mit zwei Brevet-Beförderungen ausgezeichnet. Für seinen Mut bei der Erstürmung Chapultepecs wurde er zum Brevet-Major befördert. Nach dem Krieg wurde er zunächst an Lees ehemaliger Wirkungsstätte, Ft. Hamilton im New Yorker Hafen, verwendet und anschließend nach Ft. Meade, Florida versetzt.

Jackson erhielt 1851 einen Lehrstuhl am Virginia Military Institute. Er trat aus dem US-Heer aus, verblieb jedoch als Major in der Miliz Virginias. Im November 1859 führte Jackson die Artillerie des Kadettenkorps, das die Hinrichtung John Browns in Harpers Ferry, Virginia (heute West Virginia) sicherte.

Jackson unterrichtete Artilleriewesen und Physik (Artillery Tactics and Natural Philosophy). Er war bei seinen Schülern unbeliebt, so nannten ihn einige , und 1856 beantragten ehemalige Schüler, ihn aus dem Lehrkörper zu entfernen. Der Dekan lehnte den Antrag mit der Begründung ab, als Lehrer der allgemeinen Physik hätte Jackson zwar keinen Erfolg, zudem ließe er den notwendigen Takt gegenüber den Schülern vermissen, aber als Lehrer der Kriegswissenschaften sei er ein Genie. Diese pädagogische Unfähigkeit gepaart mit seinem humorlosen Auftreten ließen ihn zum Opfer vieler derber Späße der Kadetten werden; einer von ihnen, James Alexander Walker, forderte ihn sogar zum Duell. Jackson trug ihm das jedoch nicht nach. Walker diente während des Bürgerkrieges in der "Stonewall"-Brigade, deren Kommandeur er auf Vorschlag Jacksons 1863 wurde.

Am 4. August 1853 heiratete Jackson Eleanor Junkin, die bei der Totgeburt des ersten Kindes starb. Am 16. Juli 1857 heiratete er Mary Anna Morrison, mit der er zwei Kinder hatte, von denen nur eins das Erwachsenenalter erreichte.

Jackson war bereits zu Lebzeiten für viele Skurrilitäten bekannt, die später als Anekdoten von zahlreichen Autoren weiter erzählt wurden. So lutschte er angeblich genußvoll an Zitronen, aß jedoch keinen Pfeffer. Vieles hiervon lässt sich aufgrund von Jacksons Krankengeschichte erklären. Jackson litt vor dem Bürgerkrieg oft an Verdauungsstörungen und an chronischer Verstopfung, weswegen er sehr viel Wasser trank und oft im Stehen aß, da er sich von einer „Streckung des Verdauungsapparates“ Linderung für seine Beschwerden erhoffte. Daneben plagten ihm vor dem Krieg auch andere Leiden (u. a. war sein Gehör und sein Sehvermögen bei Zwielicht beeinträchtigt), sodass er mehrmals Heilbäder besuchte; sein angeblicher Zitronenkonsum könnte darin begründet liegen, dass er damit seinen Gesundheitszustand verbessern wollte.

Jackson besuchte 1860 Neuengland. Dort hörte er erstmals von Gerüchten, die eine Sezession voraussagten. Seine Befürchtungen um die Einheit der Nation stiegen. Er trat immer dafür ein, die Meinungsverschiedenheiten der Staaten innerhalb der Union zu lösen, nicht zuletzt weil er die militärische Unterlegenheit des Südens kannte. Als jedoch die abolitionistischen Strömungen in Washington immer stärker wurden und sich die Absicht der US-Regierung, in die Rechte der Einzelstaaten einzugreifen, immer deutlicher abzeichnete, sah auch er keinen anderen Ausweg, als durch den Austritt aus der Union die Rechte der Südstaaten zu bewahren.

Am 21. April 1861, vier Tage nach der Sezession Virginias, wurden die Kadetten des VMI unter Jacksons Kommando als Ausbilder nach Richmond, Virginia beordert. Er selbst wurde zum Oberst befördert und am 27. April nach Harpers Ferry, zu der Zeit noch zu Virginia gehörig, versetzt, um als Brigadekommandeur die sich dort versammelnden Regimenter der Miliz zu einer schlagkräftigen Brigade zu formen. Diese Brigade erhielt seinen Namen und später nach seinem Tod auch seinen Spitznamen „Stonewall“, den die Soldaten als Auszeichnung verstanden.

Jackson unterstand Brigadegeneral Joseph E. Johnstons Shenandoah-Armee. Beim ersten Gefecht um Harpers Ferry zeichnete er sich durch Tapferkeit aus und wurde deshalb am 17. Juni zum Brigadegeneral befördert. Jacksons Brigade wurde danach vom 2. Juli bis zum 15. Juli in den Gefechten am Hoke Run gegen Generalmajor Patterson eingesetzt und anschließend mit der Eisenbahn in den Raum um Manassas, Virginia verlegt.

Dort wurde Jackson am Henry Hill eingesetzt. Als während der ersten Schlacht am Bull Run am 21. Juli 1861 die Brigade Brigadegeneral Barnard Elliott Bees vor den Unionstruppen fluchtartig auswich, rief dieser seinen Soldaten zu: 

Bis heute ist nicht geklärt, wie diese Äußerung gemeint war, weil Bee kurz darauf tödlich verwundet wurde. Meist wird angenommen, dass er die Worte respektvoll meinte, weil Jacksons Männer nicht flohen und Bee daher seine Soldaten sammeln konnte. Möglicherweise sagte er es aber auch aus Wut darüber, dass Jackson keinen Entlastungsangriff unternahm. Fest steht nur, dass Jacksons Brigade zu diesem Zeitpunkt nicht im Feuerkampf stand und dass die Flucht der Konföderierten aufgehalten wurde. In dieser Schlacht erhielt Jackson seinen Spitznamen „Stonewall“, der später als Ehrenname auch seiner Brigade verliehen wurde.

Jackson wurde mit seiner Brigade nach der Schlacht zurück ins Shenandoahtal beordert. Bis zum 6. Oktober unterstand er der konföderierten Potomac-Armee, am darauffolgenden Tag wurde er zum Generalmajor befördert und am 22. Oktober zum Kommandeur des Wehrbezirks Shenandoahtal ernannt. Ein winterlicher Vorstoß nach Romney, heute West Virginia, blieb nicht zuletzt wegen der Witterungsbedingungen erfolglos. Wegen der seiner Meinung nach ungerechtfertigten Kritik Jefferson Davis’ an diesem Misserfolg wollte er zunächst sein Offizierspatent zurückgeben, sah jedoch später davon ab.

Am 23. März 1862 begann Jackson mit zunächst 10.000 Mann (erst später kam eine weitere Division als Verstärkung hinzu) den Shenandoah-Feldzug. Auch wenn dieser mit einer Niederlage wegen mangelhafter Aufklärung bei Kernstown, Virginia begann, gelang es Jackson im Frühjahr 1862, mit diesen zahlenmäßig weit unterlegenen Großverbänden durch fünf Siege ungefähr 100.000 Unionssoldaten im Shenandoahtal zu binden, die Generalmajor McClellan für dessen Halbinsel-Feldzug fehlten. Jacksons Feldzug war gekennzeichnet durch schnelle Bewegungen, seine berüchtigten Gewaltmärsche, die seinen Truppen den Spitznamen „Fuß-Kavallerie“ einbrachten, aggressives Zuschlagen, bevor der Gegner seine Kräfte jeweils vereinigen konnte, und systematische Verschleierung seiner Absichten und Marschwege. Dieses ging so weit, dass er selbst unterstellten Offizieren die nächsten beabsichtigten Schritte verschwieg – aus Angst, die überall vorhandenen Spione des Gegners könnten Wind davon bekommen. Jackson kam dabei zugute, dass er als Einheimischer das Tal genauestens kannte und zusätzlich erkunden ließ. Er orientierte sich anhand einer 3 m langen Karte. Der führende Kartograph war Hauptmann Jedediah Hotchkiss. Jacksons brillanter Feldzug verschaffte ihm nicht nur bei den unterstellten Offizieren und im konföderierten Heer den Nimbus des Siegers, sondern wurde im späten 19. Jahrhundert in vielen Kriegsakademien – und wird bis heute im US-Heer – als Paradebeispiel für eine erfolgreiche Taktik angesichts eines vielfach überlegenen Gegners gelehrt. Jackson selbst äußerte sich nur selten zu den von ihm bevorzugten Taktiken. Zu General Imboden sagte er 1861:

Diese Grundsätze wendete Jackson immer an, wenn es ihm möglich erschien. Nach dem Sieg bei Port Republic waren die Infanteriedivisionen erschöpft und zur Verfolgung des ausweichenden Gegners nicht fähig. Er wies deshalb die Kavallerie an, die ausweichenden Unionssoldaten ständig zu bedrängen:

Am Abend des 17. Juni 1862 beginnend verließ Jackson mit etwa 16.000 Mann das Shenandoahtal, um General Lee, der als Nachfolger des verwundeten Johnston gerade den Oberbefehl der Nord-Virginia-Armee übernommen hatte, bei dessen gewagtem Plan für den Entsatz des belagerten Richmonds zu unterstützen. Daraus entwickelte sich die Sieben-Tage-Schlacht, bei der Lee durch ständige und verlustreiche Angriffe McClellan bis auf den Malvern Hill zurückdrängte und somit zum Abbruch der Belagerung zwang. Während dieser Schlacht führte Jackson sein Korps in den Augen vieler späterer Militärhistoriker und einiger konföderierter Generale, die nach dem Shenandoah-Feldzug andere Erwartungen an ihn gehegt hatten, zögerlich und ohne Nachdruck. Es ging sogar das (unberechtigte) Gerücht um, er habe einen ganzen Tag aus Erschöpfung verschlafen. Eine fairere Beurteilung ist, dass sich die Unionssoldaten in dem unwegsamen Gelände zäh verteidigten und ein umsichtiger General wie Jackson erst seine Kräfte zusammenfasste und nach Umgehungsmöglichkeiten suchte, bevor er eine starke gegnerische Stellung angriff. Während der ganzen Schlacht gab es bei den konföderierten Generalen immer wieder Orientierungsschwierigkeiten (es gab nur ganz einfache Karten und kaum ortskundige Führer) und Mängel in der Kommunikation (letztlich ein Fehler von Lees Stab). Der gesamte Verlauf der Kampfhandlungen zeigt deutlich, dass sich die Divisionen der Nord-Virginia-Armee erst aufeinander und auf den Führungsstil General Lees einspielen mussten. Lee machte folglich Jackson in seinem offiziellen Bericht keinerlei Vorwürfe. Nichtsdestoweniger bleibt die Beurteilung der Sieben-Tage-Schlacht der umstrittenste Punkt in Jacksons Karriere. Interessanterweise wurde Jackson dennoch nie ein „Opfer“ des Lost Cause – im Gegenteil versteiften sich viele südstaatliche Autoren nach dem Krieg eher darauf, dem Nichtvirginier James Longstreet seine angeblichen Fehler bei Gettysburg anzukreiden, und verloren über Jackson und die Sieben-Tage-Schlacht wenig bis gar keine Worte.

Nach dem strategischen Sieg Lees über McClellan in der Sieben-Tage-Schlacht gliederte Lee die Nord-Virginia-Armee um. Jackson wurde Kommandeur des linken Flügels. Ihm unterstanden drei Divisionen: Winders und Ewells, die Jackson schon im Shenandoah-Feldzug geführt hatte, und die „Light Division“ Generalmajor A. P. Hills, die sich während der Sieben-Tage-Schlacht mehrfach ausgezeichnet hatte.

Mitte Juli beabsichtigte Lee, zunächst Generalmajor John Pope und anschließend McClellan zu schlagen. Er schickte Jackson den Truppen Popes entgegen, um diesen zunächst am weiteren Vorgehen nach Süden zu hindern. Nördlich von Orange, Virginia kam es am 9. August zur Schlacht am Cedar Mountain. Die Schlacht wurde von den Konföderierten nachlässig geschlagen. Jackson hatte nicht für ausreichende Aufklärung gesorgt, die Befehle an die Divisionen, außer der vordersten – unter Brigadegeneral Winders –, bei der sich Jackson aufhielt, waren verworren und erreichten sie verspätet. Erst das Eintreffen von A. P. Hills „Light Division“ am frühen Abend konnte die Schlacht zu Jacksons Gunsten beenden. Während der Schlacht zeigte Jackson zum einen überragenden persönlichen Mut und Führungskraft, als er eine zurückflutende Brigade, ausgerechnet die "Stonewall Brigade", mit gezogenem Säbel aufhielt und zum Gegenangriff führte, zum anderen Detailversessenheit, als er zusammen mit General Winder Kanonen selbst bediente und sich am „feinsten Artillerieduell des Krieges“ als Artillerist erfreute.

Am 25. August 1862 führte Jackson den linken Flügel der Nord-Virginia-Armee, von Pope unerkannt, nach Westen über die Blue Ridge Mountains um dessen eigene Armee herum und zerstörte nach einem Marsch von 51 Meilen zwei Tage später die Versorgungsbasis der Virginia-Armee bei Manassas Junction, Virginia. Danach verschanzte er sich hinter einer unfertigen Eisenbahntrasse bei Groveton. Durch ständiges Verlagern des Schwerpunktes und unter dem Einsatz der letzten Reserven widerstand Jackson den Angriffen Popes zwei Tage lang, bis der konföderierte Generalmajor James Longstreet die Virginia-Armee der Union in einem vernichtenden Angriff am 30. August schlug.

Im anschließenden Maryland-Feldzug erhielt Jackson den Auftrag, mit sechs Divisionen die Bedrohung im Rücken der Nord-Virginia-Armee durch die Garnison von Harpers Ferry auszuschalten. Vom 12. bis 14. September platzierte er seine Divisionen auf den drei die Stadt umgebenden Höhen und zwang so die Garnison, sich am 15. September nahezu kampflos zu ergeben. Am nächsten Tag marschierte er unter Zurücklassung der Division A. P. Hills nach Sharpsburg, Maryland und vereinigte sich mit dem Rest der Nord-Virginia-Armee. Während der Schlacht am Antietam wehrte er Angriffe von Hookers, Mansfields und Sumners Korps ab. Jacksons letzter Division, A. P. Hills „Light Division“, die das Schlachtfeld am späten Nachmittag aus Harpers Ferry kommend erreichte, gelang es, einen Sieg der Union zu verhindern; die Schlacht endete unentschieden.

Nach dem Rückzug aus Maryland wurde Jackson am 10. Oktober 1862 zum Generalleutnant befördert und gleichzeitig zum Kommandierenden General des II. Korps, seines vorherigen Kommandos, ernannt. Bei der für die Konföderation siegreichen Schlacht von Fredericksburg am 13. Dezember führte er sein Korps umsichtig, obwohl ihm bei der Geländebeurteilung ein Fehler unterlief, der beinahe zum Durchbruch der Union geführt hätte. Nachdem er durch den Einsatz seiner Reserve die eigenen Stellungen zurückerobern konnte, wollte er die "Left Grand Division" der Union unverzüglich angreifen, um den kleinen Vorteil auszunutzen. Das wurde ihm jedoch von General Lee untersagt.

Nach der Überwinterung der Nord-Virginia-Armee südlich des Rappahannock griff der neue Oberbefehlshaber der Potomac-Armee, Generalmajor Joseph Hooker, erneut die Nord-Virginia-Armee an. In der Schlacht bei Chancellorsville bildete Jackson mit dem II. Korps den rechten Flügel der Armee. Er schlug Lee einen gewagten Plan vor, den dieser akzeptierte. Am 2. Mai 1863 löste sich Jackson morgens unbemerkt von den angreifenden Korps der Union und umging in Gewaltmärschen die gesamte Front der Potomac-Armee. Am Nachmittag griff er überraschend das XI. Korps auf dem rechten Flügel der Potomac-Armee in dessen Rücken an. Die Angegriffenen erlitten schwere Verluste und es breitete sich Panik aus. Dies war die entscheidende Wendung der Schlacht. Am 5. Mai wich Hooker schließlich über den Rappahannock aus, und die Schlacht war für die Konföderation gewonnen.

Bereits in der Nacht vom 2. auf den 3. Mai erkundete Jackson mit seinem Stab das Gelände, um das weitere Vorgehen planen zu können. Bei der Rückkehr wurde er vom Feuer der eigenen Truppen, die nicht von dieser Erkundung unterrichtet waren, überrascht und angeschossen. Sein linker Arm musste amputiert werden. Während der Rekonvaleszenz starb Jackson am 10. Mai 1863 an den Folgen einer Lungenentzündung. Er wurde am 15. Mai in Lexington beigesetzt.

Was Jacksons Haltung zur Sklaverei angeht, sagte seine Frau in ihrer Biographie:

Jackson selbst unterrichtete gemeinsam mit seiner Frau erfolgreich jahrelang neben seinem Beruf und auf eigene Kosten Sklaven von Freunden in der Sonntagsschule. Als Angehöriger der virginischen Oberschicht hatte auch Jackson Sklaven. Er führte den Haushalt patriarchalisch und pedantisch und behandelte die Sklaven wie Diener. Jackson persönlich bildete die Sklaven in den von ihm als wesentlich erachteten Tugenden – Höflichkeit, Pünktlichkeit und Moral – aus.

Jackson wird als einer der großen Helden der Konföderation während des Bürgerkrieges verehrt. Einige Theoretiker behaupten, mit Jackson an der Spitze des II. Korps hätten der Pennsylvania-Feldzug des Sommers 1863 und die Schlacht von Gettysburg einen anderen Verlauf genommen. Er gilt als einer der größten Taktiker des 19. Jahrhunderts.

Jackson hatte zeitlebens den Ruf, keinem Laster zu frönen und streng moralisch zu leben. In Lexington war er Diakon der Presbyterianischen Kirche. Er verabscheute es, sonntags zu kämpfen, ließ sich aber nicht davon abhalten, wenn es notwendig war – allerdings holte er den Gottesdienst dann an einem anderen Tag nach. Seine Frau berichtet, dass er sonntags nicht nur keine Briefe schrieb, sondern nach Möglichkeit auch keine las und sogar seine Post so einrichtete, dass sie nicht an einem Sonntag befördert wurde. An anderer Stelle schrieb er ihr: . In einem Gespräch mit einem seiner Stabsoffiziere äußerte er sich sogar dahingehend, militärische Handlungsanweisungen direkt aus dem Alten Testament zu übernehmen – sein dabei zitiertes Vorbild war der Kampf Josuas mit den Amalekitern, die dieser vernichtend schlug und dem daraufhin der Bibel nach von Gott befohlen wurde, diese vollständig zu vernichten. Seine tiefe Religiosität und sein sprödes Wesen führten immer wieder dazu, dass er andere vor den Kopf stieß. Trotz seiner Schrullen vertrauten ihm seine Soldaten und kämpften unter seiner Führung hervorragend.

Im Kampf kannte Jackson keine Gnade mit dem Gegner und akzeptierte kein Fehlverhalten eigener Soldaten. Als ein Soldat auf einem Marsch seinem Befehl, keine Häuser der Zivilbevölkerung zu betreten, zuwiderhandelte, ließ er ihn nach einem der im Bürgerkrieg typischen Kriegsgerichtsverfahren aburteilen und innerhalb von 20 Minuten nach Verkündung des Urteils erschießen. Jackson bestätigte stets die Todesurteile der Kriegsgerichte über Deserteure. Besonders erbittert war er über die Plünderungen der Unionsarmee bei Fredericksburg. , schrieb er an seine Frau.

Nach einem Gefecht wurde Jackson von einem Oberst auf die außerordentliche Tapferkeit der gefallenen Unionssoldaten hingewiesen. Der Oberst zeigte sein Bedauern über den Tod der feindlichen Soldaten, und sagte, dass sie wegen ihrer Tapferkeit hätten überleben sollen. Jackson antwortete: 

Dabei ging es Jackson weniger um das Schicksal der einzelnen Soldaten, sondern um die Erkenntnis, dass mittelalterliche Höflichkeit auf den Schlachtfeldern von 1862 keine Daseinsberechtigung mehr hatte.

Jackson war ein Befürworter beweglich geführter Operationen, bei denen er die Initiative erringen und behalten konnte. Kampf in und um Feldbefestigungen lehnte Jackson ab. Dafür war er bereit, durch bewegliche Kriegsführung verursachte Schäden in Kauf zu nehmen, da nur so der Krieg zu einem schnellen Ende geführt werden könne.

Diesen Gedanken eines Krieges „verbrannter Erde“ setze er jedoch nie um, da er nicht im Feindesland eingesetzt war und die Zerstörung gegnerischer Ressourcen nicht das Ziel der Nord-Virginia-Armee war. Generalmajor Philip Sheridan führte dagegen 1864 ausgerechnet in Jacksons heimatlichen Shenandoahtal diese Art der Kriegsführung durch.

Jackson hatte ein Gespür für die in der jeweiligen Situation notwendigen und durchführbaren Entscheidungen. Um erfolgreich handeln zu können, bedurfte er der Führung am langen Zügel. Hatte er die Möglichkeit, die zum Erreichen des Ziels notwendigen Schritte weitgehend selbst bestimmen zu können, so hatte er fast immer großen Erfolg. General Lee ermöglichte ihm das. Kurz vor Jacksons Tod sagte dieser gleichzeitig mit dem Befehl schnellstmöglich zu genesen: 

Jackson selbst handelte entgegengesetzt: er befahl seinen Untergebenen detailliert, wie sie vorgehen sollten, weil er befürchtete, seine Gedanken würden sonst nicht richtig umgesetzt. Das führte zu einer komplizierten und komplexen Befehlsgebung, die ohne mündliche Erläuterungen immer wieder zu fehlerhafter Ausführung führte, z. B. bei der Schlacht am Cedar Mountain. Er hatte deswegen ständig Reibereien mit A. P. Hill, der sich wegen seiner früher selbst errungenen Erfolge nicht in diesem Maße gängeln lassen wollte. Die anderen ihm geraume Zeit Unterstellten waren andererseits nicht gewohnt, selbstständig zu handeln, was bei seinem Nachfolger, General Ewell, während der Schlacht von Gettysburg dazu führte, dass entscheidende Aktionen nicht durchgeführt wurden.

Er war ein Meister der schnellen Bewegungen und der überraschenden Taktiken, aber er hielt seine Absichten manchmal so geheim, dass die ihm unterstellten Offiziere seine Pläne bis kurz vor ihrem Einsatz nicht kannten und daher mitunter nicht optimal ausführen konnten.

Eine der Maximen Jacksons war die Überlegung, unabhängig von einer eventuellen Unterlegenheit immer die Initiative zu behalten, sich Handlungsmöglichkeiten offenzuhalten und sie sich vor allem aktiv zu schaffen, niemals Zeit zu verschwenden und dem Gegner zu keiner Zeit Ruhe zu gönnen. Jackson führte den Shenandoah-Feldzug nach diesen Grundsätzen, was ihm auch in Europa die Bewunderung führender Militärtheoretiker des 19. Jahrhunderts, wie die des Briten George Henderson in Sandhurst oder des preußischen Generalfeldmarschall von Moltke einbrachte, dessen Meinung von der strategischen Durchführung der Feldzüge des Amerikanischen Bürgerkriegs ansonsten nicht sehr hoch war.

Das VMI errichtete Jackson ein Denkmal, das vor einem nach ihm benannten Eingang des Unterkunftgebäudes steht, und benannte ein repräsentatives Gebäude nach ihrem ehemaligen Lehrer, das eine Aula beherbergt.

Viele seiner Zeitgenossen sahen Jacksons Schicksal eng mit dem der Konföderation verknüpft. Schon zu Lebzeiten wurde ihm in den Südstaaten eine nachgerade religiöse Verehrung zuteil. So schrieb etwa im Juni 1862 der "Daily Appeal", eine Tageszeitung aus Memphis, er sei 

Und während des Shenandoah-Feldzuges 1862 sagte Jackson selbst: , was tatsächlich ein halbes Jahr nach der Eroberung des Tals durch Sheridan eintrat.

Während der Einsegnung eines Friedhofes für gefallene Angehörige der Nord-Virginia-Armee aus Louisiana in New Orleans betete der ehemalige Militärgeistliche Father D. Hubert bei der Enthüllung eines Denkmals für Jackson 1881:

Jacksons Todesumstände trugen dazu bei, dass er in der Geschichtsschreibung wie im kollektiven Bewusstsein bis heute als tragischer Held gilt. Sein Tod wurde zum Gegenstand zahlreicher Gedichte selbst in den Nordstaaten; so überhöhte Herman Melville ihn in seinem Gedicht "Stonewall Jackson (Ascribed to a Virginian)" zu fast mythischer Größe. Bereits kurz nach Jacksons Tod erschienen zudem zahlreiche recht pathetische Biographien, die sein Bild bis heute prägen.

Jacksons letzte Worte wählte Ernest Hemingway als Titel seines Buches „Across the River and into the Trees“ (1950), dessen Held ein alternder Oberst des US-Heeres vom selben Schlag wie Jackson ist.

Jackson wurde in zahlreichen Städten des Südens mit Denkmälern geehrt. 1875 wurde eine erste Statue in Richmond errichtet, 1881 wohnten mehr als 12.000 Menschen der Einweihung des Denkmals in New Orleans bei. Im 20. Jahrhundert wurde er gemeinsam mit Robert E. Lee und Jefferson Davis auf dem größten Flachrelief der Welt im Stone Mountain bei Atlanta verewigt. Die Geburtstage Jacksons und General Lees werden seit 1904 in Virginia jedes Jahr am Montag nach dem dritten Wochenende im Januar mit dem Lee-Jackson-Tag gefeiert.

Mit der Weiterentwicklung der Panzerwaffe nach dem Ersten Weltkrieg wurde es im US-Heer üblich, Panzer nach Generalen zu benennen. Zwar wurde kein Kampfpanzer nach Jackson benannt, er erhielt jedoch die Ehre, Namensgeber für den Jagdpanzer M36 Jackson zu werden. Der Panzer wurde während des Zweiten Weltkrieges ab 1944 eingesetzt.

Die US-Marine benannte zwei Schiffe, die Marine der Konföderierten ein Panzerschiff nach Jackson. Dabei handelte es sich um die "CSS Stonewall", die nach dem Sezessionskrieg an Japan verkauft wurde, einen Liberty-Frachter mit dem Namen "SS T.J. Jackson", der 1942 bis 1960 im Dienst stand und das kernkraftgetriebene ballistische U-Boot mit der Kennung "SSBN-634", das von 1964 bis 1995 im Dienst stand.




</doc>
<doc id="5123" url="https://de.wikipedia.org/wiki?curid=5123" title="Tiberius">
Tiberius

Tiberius Iulius Caesar Augustus (vor der Adoption durch Augustus: "Tiberius Claudius Nero"; * 16. November 42 v. Chr. in Rom; † 16. März 37 n. Chr. am Kap Misenum) war römischer Kaiser von 14 bis 37 n. Chr. Nach seinem Stiefvater Augustus war Tiberius der zweite Kaiser des Römischen Reiches und gehört wie dieser der julisch-claudischen Dynastie an. Seine Regierungszeit war eine der längsten Alleinherrschaften eines römischen Kaisers.

Tiberius konnte besonders vor seinem Herrschaftsantritt bedeutende militärische Erfolge erzielen. Seine militärischen Aktivitäten in Pannonien, Illyricum, Raetien und Germanien legten die nördliche Grenze des römischen Imperiums fest. In der Verwaltung der Provinzen sowie der Finanzen war der Kaiser erfolgreich. Palastintrigen, die Verschwörung des ehrgeizigen Seianus, Hinrichtungen dissidenter römischer Aristokraten und Tiberius’ Rückzug aus der Hauptstadt verursachten das negative Werturteil der späteren antiken Historiographen. Gegen Ende seines Lebens wurde der Interessenkonflikt zwischen dem in seiner politischen Funktion reduzierten Senat und dem nun institutionalisierten Amt des Kaisers erstmals deutlich.

Tiberius entstammte dem patrizischen Geschlecht der Claudier. Seine Eltern waren Tiberius Claudius Nero, Prätor 42 v. Chr., und Livia Drusilla, deren claudischer Familienzweig durch Adoption in das plebejische Geschlecht der Livier übergegangen war. Im Jahre 41 v. Chr. flohen seine Eltern mit ihm nach Sizilien und Griechenland, um den Proskriptionen zu entgehen, da sein Vater als überzeugter Republikaner und Anhänger der Caesarmörder den Lucius Antonius unterstützte und sich somit gegen Octavian gestellt hatte. Octavian, der spätere Kaiser Augustus, erzwang nach ihrer Rückkehr im Jahr 39 v. Chr. Livias Scheidung vom älteren Tiberius Claudius Nero, um sie selbst heiraten zu können. Drei Monate nach der Heirat am 17. Januar 38 v. Chr. brachte Livia Tiberius’ Bruder Drusus zur Welt, dessen leiblicher Vater allerdings Tiberius Claudius Nero war. Da Octavian den Neugeborenen seinem Vater überstellte, dürfte auch der junge Tiberius zu dieser Zeit bei seinem Vater gewesen sein und nicht bei seiner Mutter und dem Stiefvater Octavian. Sueton berichtet, dass Tiberius nach der Rückkehr nach Rom von einem Senator Marcus Gallius testamentarisch adoptiert wurde, dessen Namen aber nicht führte, weil Gallius als Gegner Octavians galt. Nach dem Tod seines Vaters, wohl im Jahr 33 v. Chr., hielt der neunjährige Tiberius ihm die Trauerrede, was ihn im öffentlichen Leben der römischen Aristokratie positionierte, und gelangte dann zusammen mit seinem Bruder in die Vormundschaft seines Stiefvaters. Drusus wurde von Octavian gegenüber seinem älteren Bruder bevorzugt.

Bereits in jungen Jahren wurde Tiberius in das politische Leben eingeführt. Vom 13. bis 15. August 29 v. Chr. wurde er in den Triumphzug Octavians für den Sieg bei Actium einbezogen. Bereits 23 v. Chr. wurde ihm als Quästor mit dem Zuständigkeitsbereich der Getreideversorgung das erste politische Amt und damit der Senatorenstatus übertragen, weit vor dem hierfür vorgeschriebenen Mindestalter von 25 Jahren.

Tiberius unternahm unter der Herrschaft des Augustus mehrere erfolgreiche Feldzüge. Bereits in den Jahren 26–24 v. Chr. nahm er als Militärtribun an Kämpfen des Augustus in Spanien teil. Im Jahre 20 v. Chr. führte er einen Feldzug gegen das armenische Königreich an, durch den er Tigranes III. auf den armenischen Thron brachte. Er gewann im selben Jahr durch Diplomatie die römischen Feldzeichen zurück, die Marcus Licinius Crassus, Lucius Decidius Saxa und Marcus Antonius in teils verheerenden Niederlagen an die Parther verloren hatten. Im Jahr 16 v. Chr. war er Prätor und bereitete gemeinsam mit Augustus in Gallien die Neuordnung der Provinz vor.

Gemeinsam mit seinem jüngeren Bruder Drusus brachte Tiberius in den Jahren 15–13 v. Chr. Raetien und das im Norden befindliche Vindelicien unter römische Herrschaft. Von 12 bis 9 v. Chr. leitete er die Eroberung Pannoniens. Er überführte 9 v. Chr. den Leichnam seines Bruders Drusus, der infolge eines Reitunfalls verstorben war, von Germanien nach Rom und erhielt als dessen Nachfolger für die folgenden beiden Jahre den Oberbefehl in Germanien. Im Jahr darauf beendete er erfolgreich die von seinem Bruder begonnenen Drusus-Feldzüge. Um den germanischen Druck auf den Mittelrhein zu vermindern, wurden unter seiner Befehlsgewalt etwa 40.000 Sugambrer und Sueben in linksrheinisches Gebiet umgesiedelt.

Tiberius war von 16 bis 12 v. Chr. mit Vipsania Agrippina verheiratet, der Tochter von Octavians engem Vertrauten und Feldherrn Marcus Vipsanius Agrippa. Aus dieser Ehe stammte sein um 15 v. Chr. geborener Sohn Tiberius Drusus Iulius Caesar (auch „der jüngere Drusus“). Im Jahr 12 v. Chr. musste sich Tiberius auf Anordnung seines Stiefvaters von Vipsania Agrippina scheiden lassen und seine Stiefschwester Iulia heiraten, die Tochter des Augustus. Diese Verbindung sollte die Einheit des regierenden Hauses stärken. Iulia dürfte allerdings eher ihren Kindern die Nachfolge gewünscht haben. Auch fühlte sie sich nach drei ihr von Augustus aufgebürdeten Zwangsehen zu einem ausschweifenden Leben hingezogen, so dass die Ehe für den als menschenscheu geltenden Tiberius im Unterschied zu dessen erster Ehe nicht glücklich war. Nachdem Tiberius bereits im Jahr 13 v. Chr. Konsul geworden war, erhielt er 6 v. Chr. die "tribunicia potestas" auf fünf Jahre; somit konnte er als Nachfolger des Princeps gelten, da er außerdem der Schwiegersohn des Augustus war.

Die schnell zerrüttete Ehe und die auffällige Förderung der von Augustus adoptierten Söhne Iulias, Gaius und Lucius Caesar, brachten Tiberius jedoch dazu, seine Laufbahn zu unterbrechen und sich für sieben Jahre in ein zuerst freiwilliges Exil nach Rhodos zurückzuziehen. Tiberius selbst soll später erklärt haben, er habe sich zurückgezogen, um den Caesares nicht im Wege zu stehen. Tiberius fühlte sich wohl wegen der Beliebtheit des Gaius Caesar und dessen Bevorzugung in seiner eigenen dignitas zurückgesetzt.

Da die Insel Rhodos auf der römischen Haupthandelslinie lag, dürfte Tiberius jedoch keineswegs vom politischen Leben ausgeschlossen gewesen sein. Während seines Aufenthaltes auf Rhodos schickte Augustus 2 v. Chr. seine Tochter Iulia wegen ihres Lebenswandels und politischer Intrigen in die Verbannung. Tiberius setzte sich zwar in mehreren Briefen vergeblich für seine Gattin ein, ließ sich jedoch auf Betreiben von Augustus schließlich von ihr scheiden. Im Jahr 2 n. Chr. bewilligte Augustus die Rückkehr des Tiberius nach Rom, gestand ihm aber zunächst keine politische Funktion zu.

Erst der kurz aufeinander folgende Tod der designierten Nachfolger des Augustus, seiner Enkelkinder und Adoptivsöhne Gaius und Lucius Caesar (4 bzw. 2 n. Chr.), brachte Tiberius in die Position des einzigen möglichen Nachfolgers. Mit der Adoption durch Augustus am 26. Juni 4 n. Chr. wurde Tiberius (mit dem Namen "Tiberius Iulius Caesar") in das Geschlecht der Julier aufgenommen. Die nachfolgenden Kaiser bis hin zu Nero gehörten in unterschiedlichen Graden beiden Familien an und waren so Mitglieder einer Doppeldynastie. Neben Tiberius adoptierte Augustus Agrippa Postumus, der allerdings später in die Verbannung geschickt wurde. Tiberius selbst musste Germanicus adoptieren, den Sohn seines Bruders Drusus. Außerdem erhielt er die beiden zur Nachfolge in der Herrschaft berechtigenden Amtsgewalten, das "imperium proconsulare maius" und die " tribunicia potestas."

Tiberius übernahm 4 n. Chr. im Zuge des "immensum bellum" erneut den Oberbefehl in Germanien und zog im folgenden Jahr von Gallien aus bis ins Mündungsgebiet des Rheins ("Rhenus"). In seinem Gefolge befand sich der Historiker Velleius Paterculus, der die Position eines "praefectus equitum" innehatte. Tiberius drang bis zur Weser ("Visurgis") vor und errichtete an den Quellen der Lippe ("Lippia") ein Winterlager. Dies war das erste Mal, dass eine große römische Armee in Germanien überwinterte. Im Frühjahr des Jahres 5 n. Chr. besiegte er zusammen mit der römischen Flotte die Langobarden an der Unterelbe. Er zog daraufhin weiter elbaufwärts und gelangte an der mittleren Elbe ("Fluvius Albis") zu den Semnonen und schließlich zu den Hermunduren, wo er ein Lager aufschlug und germanische Gesandte empfing. Der Feldzugteilnehmer Velleius Paterculus beschrieb die Situation zu diesem Zeitpunkt folgendermaßen: „Nichts blieb mehr in Germanien, das hätte besiegt werden können, außer dem Stamm der Markomannen“.

Im Jahr 6 rüstete Tiberius gegen Marbod, den König der Markomannen. Es wurden insgesamt zwölf Legionen mit Hilfstruppen aufgestellt, was die Hälfte des gesamten Militärpotentials der Römer zu der Zeit darstellte. Kurz nach Beginn des Feldzugs im Frühjahr des Jahres 6 brach Tiberius ihn wieder ab, als er die Nachricht vom Pannonischen Aufstand erhielt. Allerdings schloss Tiberius noch einen Freundschaftsvertrag mit Marbod, um sich vollkommen auf die schwere Aufgabe in Pannonien zu konzentrieren.

Von 6 bis 9 n. Chr. warf er mit größten Anstrengungen, unter Aufbietung einer Armee von 15 Legionen, den Aufstand in Pannonien und Illyrien nieder. Kurz nach dem Sieg erhielt Augustus die Nachricht, dass Varus in Germanien mit drei Legionen und ebenso vielen Reiterabteilungen sowie sechs Kohorten gefallen war. Dieser Verlust war eine der größten Niederlagen, die das Römische Reich je erlitt; ernsthafte Expansionsbestrebungen nach Germanien wurden in den kommenden Jahrhunderten nicht mehr unternommen. In Rom herrschte drei Tage Staatstrauer, und Tiberius, der eben erst siegreich heimgekehrt war, verzichtete auf einen Triumph.

Nach der schmachvollen Niederlage des Varus wurde Tiberius aufgrund seiner großen militärischen Erfahrung in Germanien wieder mit dem "imperium proconsulare" ausgestattet. Im ersten Jahr seines militärischen Kommandos 10 n. Chr. sah er davon ab, den Rhein zu überqueren. Laut Sueton handelte Tiberius mit äußerster Vorsicht und Zurückhaltung und nur in Absprache mit seinem Beraterkreis, wodurch angedeutet sein mag, dass Tiberius bereits anfänglich nicht eine Rückeroberung des Raumes zwischen Elbe und Rhein plante, sondern sich auf Strafexpeditionen beschränken wollte. Bezüglich anschließender militärischer Erfolge sind die Quellendarstellungen widersprüchlich. Velleius Paterculus, der allgemein die Leistungen des Tiberius verherrlicht, berichtet, dass Tiberius den Rhein überschritt und erfolgreich bis tief in das Landesinnere vordrang, um germanische Siedlungen zu brandschatzen und Felder zu verwüsten. Nach Cassius Dio, der sein Geschichtswerk Anfang des 3. Jahrhunderts abfasste, kam es zu keinen nennenswerten militärischen Auseinandersetzungen. Archäologische Untersuchungen haben bislang keine Spuren von Militärwegen oder Anzeichen von Holzkohleschichten nachweisen können, die man bei einem großflächigen Abbrennen von Siedlungen erwarten würde.

Anfang 13 n. Chr. kehrte Tiberius nach Rom zurück und hielt den verschobenen Triumph für die Niederschlagung des Pannonischen Aufstands ab. Seine Amtsgewalten, die "tribunicia potestas" und das "imperium proconsulare maius", wurden auf weitere zehn Jahre verlängert. Als Augustus am 19. August 14 starb, hatte Tiberius somit alle Rechte inne, auf denen der Prinzipat beruhte.

Mit dem Tod des Augustus war der 55 Jahre alte Tiberius praktisch zum Nachfolger designiert. Auch seine militärischen Erfahrungen ließen ihn konkurrenzlos erscheinen. Am 18. September 14 n. Chr. ließ er den Senat einberufen, um die Leichenfeier und die Divinisierung für Augustus beschließen zu lassen. In dieser Senatssitzung wurde das private Testament des Augustus eröffnet. Tiberius und Livia waren als Haupterben eingesetzt, wobei Tiberius zwei Drittel und Livia ein Drittel der Erbschaft erhielten. Durch das Testament wurde Livia adoptiert und zur "Iulia Augusta" erhoben. Livia, die bereits unter Augustus öffentlich als Teilhaberin am Prinzipat aufgetreten war und in der offiziellen Propaganda – etwa auf Münzen – als solche dargestellt wurde, konnte somit in ihrer neuen Stellung als Kaisermutter höchsten Einfluss ausüben. Bis zu ihrem Tod im Jahr 29 gelang es ihr in dieser Rolle, die zunehmenden Anfeindungen innerhalb der Kaiserfamilie, besonders angesichts der Nachfolgefrage, zu kontrollieren. Allerdings bestand ein Konkurrenzverhältnis zwischen der herrschsüchtigen Mutter und dem Sohn.

Trotz des eindeutigen Testaments des Augustus wartete Tiberius demonstrativ das ausdrückliche Ersuchen des Senats ab, die Kaiserwürde anzunehmen. Diese zögernde Haltung "(recusatio imperii)" kann damit erklärt werden, dass Tiberius allgemein als zurückhaltender Mensch galt; wahrscheinlicher ist jedoch, dass er bewusst den Rückhalt und die verbindliche Festlegung des Senats auf seine Person suchte, um als ehemals umstrittener Nachfolgekandidat seine Position zu stärken. Eine solche eher taktisch motivierte Zurückhaltung spiegelt sich auch darin, dass Tiberius in späteren Jahren häufig Rücktrittsgedanken äußerte. Außerdem akzeptierte Tiberius zwar den Ehrenbeinamen Augustus, den an Augustus verliehenen Titel "pater patriae" lehnte er jedoch ab. Erst ab dem 10. März 15 bekleidete er das Amt des "pontifex maximus". Da es sich um die historisch erste Übertragung der an Augustus persönlich verliehenen Amtsgewalten handelte, war es noch nicht endgültig entschieden, dass die Institution des Prinzipats eine dauerhafte werden sollte. Der Senat akzeptierte jedoch widerspruchslos die Amtsstellung des Kaisers und fügte sich zunehmend in dessen Autorität.

Unmittelbar zu Beginn der Kaiserherrschaft des Tiberius wurde Agrippa Postumus ermordet. Bereits in der Antike wurde spekuliert, ob Tiberius für die Ermordung verantwortlich war, ob Augustus angeordnet hatte, Agrippa Postumus nach seinem Tod beseitigen zu lassen, oder ob Livia die Herrschaft für ihren Sohn sichern wollte. Tacitus legt eine Mitschuld des Tiberius nahe. Tiberius bestritt jedoch die Verantwortung für den Mord. Noch 14 n. Chr. machte Tiberius dem kappadokischen König Archelaos, von dem er sich während der schwierigen Zeit in Rhodos nicht genug beachtet fühlte, den Prozess.

Unmittelbar nach Tiberius’ Herrschaftsantritt kam es zu einer Meuterei der in Pannonien und Germanien stationierten Legionen. Gründe für den Aufstand waren die Härte des Dienstes, die Länge der Dienstzeit und der geringe Sold. Diese Missstände gingen zurück auf die Politik des verstorbenen Augustus und dessen strenge Reaktionen auf den Pannonischen Aufstand und die Varusniederlage. Während Tiberius’ Sohn Drusus die Lage in Pannonien ohne größere Komplikationen beruhigen konnte, hatte Germanicus zunächst große Mühe, die ihm in Germanien unterstellten Legionen wieder unter Kontrolle zu bringen, die ihn statt Tiberius zum neuen Princeps ausrufen wollten. Die Legio XIV "Gemina" verweigerte den Treueeid, und in einem Sommerlager schlossen sich die zusammengezogenen vier Legionen des niedergermanischen Heeres dem Beispiel an. Germanicus blieb Tiberius gegenüber loyal und weigerte sich, den auf einen Staatsstreich gerichteten Forderungen nachzukommen. Schließlich beendete er die Meuterei mit zahlreichen Zugeständnissen im Namen des Princeps, ohne sich jedoch zuvor bei Tiberius rückversichert zu haben. So sagte er beschleunigte Dienstentlassungen und Geldgeschenke an die Soldaten zu. Um ein mögliches Wiederaufleben der Meuterei zu verhindern und zugleich eine Strafexpedition für die Varusniederlage durchzuführen, initiierte er im Herbst des Jahres 14 einen Feldzug gegen die Marser. In diesem Feldzug erlitten seine Legionen nur geringe Verluste.

Tiberius reagierte ambivalent. Einerseits betrachtete er den Sieg über die Marser als Erfolg, denn es war Germanicus gelungen, das Heer zu disziplinieren. Andererseits lehnte er das eigenmächtige Vorgehen des Germanicus ab, zumal dessen neu gewonnener Ruhm die Position des Tiberius im Heer schwächte.

Unter Augustus und zu Beginn der Herrschaft des Tiberius wollte Rom die "clades Variana" korrigieren, zumindest aber die aufrührerischen Germanenstämme formell unterwerfen und die Deserteure bestrafen, allein schon zur Abschreckung künftiger Aufrührer. Diese Ziele wurden jedoch nicht erreicht. Die Römer hatten Glück, dass die anderen Fronten während dieser Zeit ruhig blieben, denn das römische Heer war nicht groß genug, um auf Dauer acht Legionen an der Germanenfront bereitzuhalten. Die Katastrophe des Varus, der im Jahr 13 v. Chr. zusammen mit Tiberius das Konsulat innegehabt hatte, und das von Germanicus im Jahre 14 vorgefundene Problem der Militärrevolten ließen Tiberius von der Grenzverschiebung in Richtung Weser und Elbe endgültig Abstand nehmen. Der illusionslose Germanienkenner Tiberius ging im Gegensatz zu Germanicus zu einer defensiven Grenzpolitik über, die die Germanen ihrem inneren Streit überließ und sich auf die Behauptung eines der Grenze vorgelagerten Gebietes beschränkte. Tiberius erkannte, dass Rom die germanische Arminius-Koalition allein schon aufgrund der logistischen und topographischen Gegebenheiten nicht ohne beträchtliche Mittelaufstockung besiegen konnte. Die römischen Truppen konnten sich bei einem Vormarsch nicht aus dem Lande ernähren, und der Landkriegsführung standen durch die weiten Wege und Transporte bei den kurzen Feldzugszeiten nahezu unüberwindbare Schwierigkeiten und Risiken entgegen.

Tiberius gebot den zum Teil verlustreichen Unternehmungen des Germanicus in den Jahren 15 und 16 Einhalt und rief ihn nach Rom zurück. Er berief sich dabei angeblich auf den Rat des Augustus, das Reich in seinen gegenwärtigen Grenzen zu belassen "(consilium coercendi intra terminos imperii)". Die Historizität des "consilium coercendi" wird allerdings in der modernen Forschung angezweifelt, unter anderem, weil die offizielle Darstellung des Augustus gegenüber dem Senat in den "Res Gestae Divi Augusti" einen derart weiten Entscheidungsspielraum des Kaisers auszuschließen scheint. Auch ist unsicher, ob mit "intra terminos" die West- oder die Ostgrenze des Reichs gemeint sei und ob es sich im ersteren Fall um die Elbgrenze oder die Rheingrenze handele.

Tiberius bewilligte dem Germanicus einen aufwändigen Triumph über die Germanen, den dieser am 26. Mai 17 in Rom abhielt. Tiberius wollte damit einerseits Germanicus eine feierliche Anerkennung seiner Gesamtleistungen zuteilwerden lassen, andererseits den faktischen Abbruch der Offensive als außenpolitischen Erfolg darstellen. Paradoxerweise erwies gerade die Katastrophe der Varusschlacht die Beständigkeit der römischen Grenze am Rhein, um derentwillen die Eroberung Germaniens begonnen worden war. Durch die Abberufung des Germanicus (16 n. Chr.) setzte sich die neue außenpolitische Linie des Tiberius durch, die in der "Tabula Siarensis" (19 n. Chr.) ihren Niederschlag finden sollte: Befriedung Galliens, Vergeltung für die Varusniederlage, Rückgewinnung der Feldzeichen, jedoch nicht mehr die Eroberung des rechtsrheinischen Germanien. Diese Politik fand mit dem Tod des Tiberius (37 n. Chr.) ihr Ende, sein Nachfolger Caligula unternahm wieder (erfolglose) Expeditionen in das germanische Kerngebiet.

Nach seinem Triumph reiste Germanicus im Auftrag des Tiberius in den Osten des Reiches, um die politischen Verhältnisse aus römischer Sicht zu ordnen. Kappadokien wurde zur römischen Provinz. Germanicus erhielt ein spezielles "imperium," das zwar über dem aller anderen Prokonsuln stand, aber unter dem des Tiberius. Über Griechenland und Kleinasien gelangte er nach Syrien, von dort nach Ägypten, zum großen Missfallen des Tiberius, da es keinem Senator erlaubt war, die für die Getreideversorgung Roms wichtige Provinz Aegyptus zu betreten, die als persönliches Eigentum des Kaisers betrachtet wurde. Nach der Rückkehr nach Syrien erkrankte Germanicus in Antiochia und starb dort im Jahr 19. Schnell kamen zahlreiche Gerüchte auf, wie es zum Tod des Germanicus gekommen sei.

Aufgrund eines Konkurrenzverhältnisses zu Germanicus wurde insbesondere der Statthalter der Provinz Syria, Gnaeus Calpurnius Piso, beschuldigt, Germanicus vergiftet zu haben. Giftmordanklagen waren im kaiserzeitlichen Rom häufig und wegen der eingeschränkten Untersuchungsmethoden letztlich nicht nachweisbar. Sentius Saturninus beschuldigte Martina, eine Freundin der Gattin des Piso, des Giftmordes an Germanicus. Aufgrund der Entsendung des Germanicus und der Ernennung Pisos vermutete man in Rom ein Komplott, da vor allem Tiberius und Livia daran interessiert gewesen seien, den populären Germanicus zu beseitigen, um Tiberius’ Sohn Drusus die Nachfolge zu sichern. Tiberius verhielt sich zuerst zurückhaltend, worauf seine Kritiker Gerüchte verbreiteten, er habe die Nachricht über den Tod des Germanicus innerlich mit Freude und Genugtuung aufgenommen. Deshalb ließ Tiberius eine Erklärung veröffentlichen, in der er erläuterte, dass viele erlauchte Römer für den Staat gestorben seien; diese seien sterblich, ewig sei nur das Gemeinwesen "(principes mortales – rem publicam aeternam)". Jedoch ließen die Gerüchte und Forderungen nach Bestrafung des Schuldigen nicht nach, vor allem, weil die als „Giftmischerin“ beschuldigte Martina auf ihrem Weg von Syrien nach Rom in Brundisium selbst an Gift gestorben war und in ihrem Haar verstecktes Gift gefunden wurde.

Angesichts dieser Indizien, auch mit Blick auf die Gerüchte um sein eigenes mutmaßliches Motiv (sein Sohn Drusus war mit Germanicus’ Tod unangefochtener Nachfolger geworden), sah sich Tiberius schließlich veranlasst, Anklage gegen Piso zu erheben. Tiberius forderte in diesem Prozess die Senatoren auf, unparteiisch zu sein. Piso fand jedoch weder vor dem Senat noch bei seinen engsten Freunden Rückhalt und wurde noch vor Prozessende tot aufgefunden. Die Umstände sind unklar. Die früher nur literarisch bekannten Einzelheiten des Prozesses sind durch einen Inschriftenfund um 1990 ergänzt worden. Die in Spanien gefundene Inschriftentafel enthält einen Senatsbeschluss im Anschluss an den Piso-Prozess. Der Giftmordvorwurf ist im Senatsbeschluss angedeutet; der offizielle Vorwurf gegen Piso war allerdings bewaffneter Aufruhr. Die Berufung des Tiberius auf sein Gerechtigkeitsempfinden "(aequitas)" ist deutlich hervorgehoben. Kopien des Senatsbeschlusses wurden in allen Legionslagern und Provinzhauptstädten des Reiches aufgestellt.

Tiberius bemühte sich zu Beginn seiner Regierung um Legitimation und ein gutes Verhältnis zu Senat und Ritterstand, dessen Privilegien (Tragen des Goldringes, bevorzugte Sitze bei Spielen) bewahrt blieben. Er übertrug dem Senat das Wahlrecht von Amtsträgern, das bis dahin nominell von der stadtrömischen Bürgerschaft ausgeübt worden, unter Augustus aber faktisch ein Privileg des Kaisers geworden war. Auch vermied es Tiberius, lediglich den Senatsausschuss zu befassen, mit dem Augustus vorher anstelle des gesamten Gremiums verhandelt hatte. Der Versuch, stattdessen dem Senatsplenum größere Entscheidungsmöglichkeiten einzuräumen, scheiterte jedoch am Ungleichgewicht der Macht und am Kampf der verschiedenen Gruppen um Einfluss, vor allem in der Frage der Nachfolge. Es bildeten sich Parteiungen gegenüber einzelnen Mitgliedern der Kaiserfamilie oder anderen einflussreichen Persönlichkeiten, wie Seianus, heraus, die zu gegenseitigen Unterstellungen und Anfeindungen führten. Bereits im Jahr 16 wurde Libo Drusus, ein Urenkel des Pompeius, einer Verschwörung gegen die Kaiserfamilie verdächtigt und zum Selbstmord gezwungen. Im selben Jahr ließ Tiberius den Sklaven Clemens, der sich für Agrippa Postumus ausgegeben und in Italien eine beachtliche Schar Anhänger um sich gesammelt hatte, beseitigen.

Tiberius setzte den konservativen Kurs des Augustus in der Religionspolitik fort. Magier und Astrologen ließ er im Jahr 16 aus Italien ausweisen, obwohl er selbst Astrologie praktiziert haben soll und bei Entscheidungen häufig den Rat des Philosophen und Astrologen Thrasyllos einholte, mit dem er befreundet war. Des Weiteren ging Tiberius im Jahr 19 scharf gegen den Isiskult und das Judentum vor, nachdem es zu angeblich religionsbedingten Unruhen und Störungen der öffentlichen Ordnung gekommen war. 4.000 jüdische Freigelassene wurden nach Sardinien gebracht, um dort gegen sardische Räuber militärisch eingesetzt zu werden. Die restlichen Juden wurden gezwungen, ihrem Glauben abzuschwören oder Italien zu verlassen. Jedoch gelang es Tiberius nicht, den jüdischen Glauben in Rom und Italien langfristig zu unterbinden.

Tiberius war in der Verwaltung des Reiches erfolgreich. Er setzte den von Augustus am Ende seiner Herrschaft eingeschlagenen konservativen, auf die Bewahrung des Bestehenden ausgerichteten Kurs fort. Tiberius berief sich ebenso wie Augustus auf die Herrschertugenden "virtus", "clementia", "iustitia" und "pietas" („Exzellenz“, „Milde“, „Gerechtigkeit“ und „Ehrerbietung“). Jedoch war die Propaganda in Inschriften und auf Münzen zusätzlich durch Schlagwörter wie "salus" und "moderatio" („Wohlergehen“ und „Zurückhaltung“) gekennzeichnet, die als Leitbilder seiner Regierung moderne Verwaltungsziele widerspiegeln, etwa eine ausgewogene, dezentrale Wirtschaftspolitik.

Statthalter wurden weit über die übliche einjährige Amtszeit hinaus auf ihren jeweiligen Posten belassen, wodurch eine größere Kontinuität in der Provinzverwaltung erreicht wurde. So war beispielsweise Lucius Aelius Lamia neun Jahre lang Statthalter von Syrien. Er verwaltete dabei die Provinz von Rom aus.

Neben dem im Jahr 17 annektierten Kappadokien wurde Kommagene vorübergehend zur römischen Provinz, bis sie unter Vespasian endgültig in das Imperium eingegliedert wurde. Außerdem sorgte seit demselben Jahr der Numider Tacfarinas, der aus einer römischen Hilfstruppe desertiert war, für Aufruhr im afrikanischen Teil des römischen Reichs. Er wurde zwar von römischen Truppen im offenen Kampf geschlagen, jedoch erholten sich die Aufständischen wieder und führten fortan verheerende Kleinkriege gegen die römische Besatzungsmacht. Forderungen und Verhandlungen unter der Führung des Tacfarinas nach Land für sich und sein Heer lehnte Tiberius ab. Stattdessen schickte er eine weitere Legion, die Legio IX "Hispana", mit dem Befehl nach Afrika, Tacfarinas zu vernichten. Erst sieben Jahre nach ihrem Beginn konnten die von Tacfarinas angeführten Revolten unter Publius Cornelius Dolabella endgültig niedergeschlagen werden. Tacfarinas fiel im Kampf, sein Sohn geriet in Gefangenschaft.

Die Lebensmittelversorgung, die Steuerbelastungen sowie die Arroganz und Grausamkeit der römischen Statthalter sorgten in Gallien für Unruhen, die zum Aufstand des Häduers Iulius Sacrovir und des Treverers Iulius Florus im Jahre 21 führten. Dieser Aufstand wurde jedoch in kürzester Zeit niedergeschlagen. In den Jahren 22 bis 25 wurden rebellische thrakische Stämme mit Erfolg bekämpft. Bemerkenswert ist die militärstrategische Zurückhaltung des Tiberius, denn mit Ausnahme der Feldzüge gegen Aufständische gab es keinerlei große Militäraktionen während seiner Herrschaft.

In Armenien, wo sich römische und parthische Interessen kreuzten, wurde mit Artaxias III. um das Jahr 18 ein neuer König eingesetzt. Rom wollte die Parther in einer ständigen Bedrohungssituation belassen, um ihnen den Anreiz eines Einfalles in Kleinasien, Syrien oder Palästina zu nehmen, was bis zum Tod des Artaxias im Jahre 34 oder 35 gelang. Erst in der sich anschließenden Nachfolgefrage sollte der Partherkönig Artabanos II. seinen Sohn Arsaces auf den armenischen Thron setzen und Gebietsabtretungen der Römer in Kleinasien fordern. Durch das diplomatische Eingreifen des Lucius Vitellius, Statthalter von Syrien, konnte ein Gebietsverlust jedoch abgewendet werden. Lucius Vitellius griff in den Jahren 35/36 auch in die parthischen Thronwirren ein und konnte Tiridates III. vorübergehend als König der Parther einsetzen.

Die Haushaltspolitik des Tiberius war durch ein rigoroses Sparprogramm geprägt, in dem keine größeren Bauprojekte vorgesehen waren. Einige wenige Ausnahmen waren Tempel, die zur Demonstration der "pietas" dienten, sowie der Bau von Straßen für militärische Zwecke in Nordafrika, Spanien, Gallien, Dalmatien und Moesien.

Tiberius’ Sparsamkeit und seine Abkehr vom Luxus hatten sich bereits in dem gegen Kleidungsluxus gerichteten Senatsbeschluss des Jahres 16 gezeigt, der das Tragen von durchsichtigen Seidengewändern verbot, sowie in einem Gesetz aus dem Jahre 22, das sich gegen den Tafelluxus richtete. Tiberius sah davon ab, seine Popularität durch aufwändige Spiele zu erhöhen, und zeigte sich allgemein bei Spielen gegenüber der stadtrömischen Bürgerschaft desinteressiert.

Allerdings war er bei großen Notlagen so spendabel wie kaum ein Politiker vor ihm. Bei den Großbränden in der Stadt Rom in den Jahren 27 und 36 und bei einer Tiberüberschwemmung, die ebenfalls im Jahre 36 eintrat, sowie bei Getreideteuerungen spendete Tiberius Millionen von Sesterzen. Seine Großzügigkeit in Notsituationen bekamen auch die Provinzen zu spüren: Als ein Erdbeben 17 n. Chr. zwölf asiatische Städte vernichtete, darunter Sardes, spendete er zehn Millionen Sesterzen und gewährte einen fünfjährigen Steuererlass. Diese Fürsorge des Tiberius wurde in der Münzprägung "civitatibus Asiae restitutis" („für den Wiederaufbau der Städte Asiens“) proklamiert.

Von seinem Alterssitz auf Capri aus griff Tiberius im Jahr 33 in eine Finanzkrise in Rom ein, die vor dem Hintergrund seiner restriktiven Geldpolitik durch illegale Zinserhöhung der Geldverleiher ausgelöst worden war, die zugleich immer weniger Kredite gewährten. Da der Senat die Finanzkrise nicht mit eigenen Mitteln bewältigen konnte, stellte Tiberius Kreditvermittlern 100 Millionen Sesterzen zur Vergabe von zinslosen Krediten auf drei Jahre zur Verfügung, mit der Bedingung, dass ihre Schuldner dem römischen Staat Grundstücke von doppeltem Wert als Sicherheiten überschreiben mussten. Die Finanzkrise konnte so behoben werden.

Aufgrund des rigorosen Sparkurses von Tiberius fand sein Nachfolger Caligula 2,7 Milliarden Sesterzen in der Staatskasse vor, die dieser allerdings schnell verschwendete. Tiberius konnte auch daraus finanziellen Gewinn ziehen, dass wegen Majestätsverbrechen verurteilte Senatoren ihr Erbe an den Kaiser abtreten mussten.

Die unter Augustus noch seltenen Anklagen wegen Majestätsbeleidigung nahmen merklich zu. Auf Grundlage der noch von Augustus eingeführten "lex Iulia de maiestate" konnten nicht nur Lebensbedrohungen, sondern auch Schmähungen der Person des Princeps bestraft werden. In den Jahren 14–20 hatte Tiberius sich zunächst noch entschieden gegen die Verfolgung solcher Schmähungen gewandt.

Die ersten von Tiberius gebilligten Prozesse wurden vermutlich maßgeblich vom Senat initiiert, dem ein Teil des Gerichtswesens institutionell unterlag. Seit dem Jahr 24 wurden Majestätsprozesse häufiger eingeleitet, obwohl Tiberius das Majestätsgesetz nicht verschärfte. Insgesamt gab es unter seiner Herrschaft etwa 60 Majestätsprozesse. Ihre Anzahl hatte deshalb so sprunghaft zugenommen, weil der unbestimmte Rechtsbegriff der "laesa maiestas" so weit ausgelegt wurde, dass schon das Mitsichführen einer Kaisermünze auf dem sanitären Abtritt oder im Bordell Gegenstand einer Anklage werden konnte. Wahrscheinlich handelte es sich dabei eher um einen von vielen Anklagepunkten in einer Reihe von jeweils zur Last gelegten Vergehen. Besonders dissidente literarische Anspielungen konnten strengstens bestraft werden. So war der Historiker Cremutius Cordus gezwungen, sich durch Nahrungsverweigerung das Leben zu nehmen, da man ihm vorwarf, in seinem Geschichtswerk vorteilhaft auf die Caesarmörder Brutus und Cassius eingegangen zu sein. Brutus hatte er gelobt, Cassius soll er den „letzten Römer“ genannt haben. Die meisten Exemplare des Werks wurden auf Senatsbeschluss verbrannt, später wurde es aber wieder herausgegeben. Nachdem sich Gaius Asinius Gallus, der Ehemann von Tiberius’ erster Frau Vipsania Agrippina, nach dem Sturz von Agrippina der Älteren dem Sejan zugewandt hatte, wurde er im Jahr 30 inhaftiert und nach drei Jahren ebenfalls durch Nahrungsentzug getötet.

Tacitus beschreibt die Majestätsprozesse als willkürliches Handeln eines Tyrannen, und diese Deutung ist vor allem in der älteren Forschung weitgehend übernommen worden. Die neuere Forschung dagegen hat sie zunehmend relativiert, da die Darstellung des Tacitus einseitig die institutionelle Verantwortung des Princeps betone und mit Rücksicht auf sein senatorisches Publikum das interne Ränkespiel senatorischer Familien herunterspiele. Es bildete sich erstmals das Phänomen senatorischen Denunziantentums heraus, das die Beziehung von Kaiser und Senat bis zum Ende des 1. Jahrhunderts erheblich belasten sollte. Die kurz zuvor von Augustus geschaffene Stellung des Princeps war institutionell noch nicht so weit gefestigt, dass Tiberius eine repressive Politik gänzlich ohne Unterstützung zumindest eines Teils des Senates hätte durchsetzen können. Erst die spätere Unterwürfigkeit des Senats ermöglichte die autokratische Gewaltherrschaft eines Caligula, Nero oder Domitian.

Anlässlich des frühen Todes von Germanicus, des designierten Nachfolgers von Tiberius, im Jahr 19 stellte sich erneut die Nachfolgefrage. Das Verhältnis zwischen Tiberius und Germanicus’ Witwe Agrippina der Älteren war gespannt, da sie als Enkelin des Augustus ihre Söhne als potenzielle Nachfolger des Tiberius sah.

In dieser Zeit begann der Einfluss des Prätorianerpräfekten Lucius Aelius Seianus zu wachsen. Er baute die von ihm kommandierte Prätorianergarde zu einem persönlichen Machtfaktor aus, indem er sie in einem einzigen Lager, den Castra praetoria, auf dem Viminal vor der Stadtmauer stationierte. Tacitus zufolge vertraute Tiberius Seianus blind, seitdem dieser sich beim Einsturz einer Höhle schützend über Tiberius geworfen hatte. Das Seianus-Bild bei Tacitus ist allerdings, wie bei Sueton, äußerst negativ und steht damit im Gegensatz zu der positiven Charakterisierung des Seianus durch seinen Zeitgenossen Velleius Paterculus, der 30 n. Chr. schrieb.

Seianus plante vermutlich, durch systematische Ausschaltung der natürlichen Erben des Tiberius und Einheirat in dessen Familie selbst Nachfolger des Princeps Tiberius zu werden. Angeblich verleitete er Livilla, die Frau von Tiberius’ Sohn Drusus, zum Ehebruch. Im Jahr 23 starb der Thronfolger Drusus an einer Krankheit, wie man allgemein annahm. Im Jahr 31 sagte Apicata, die verstoßene Ehefrau des Seianus, aus, dass dieser Drusus habe vergiften lassen, indem er sich den Lieblingseunuchen des Drusus, Eudamus, hörig machte und mit der Verabreichung des Giftes beauftragte, wie auch einige zeitgenössische Autoren berichteten. Apicata wurde allerdings bei dieser Aussage stark unter Druck gesetzt, da sie nicht nur um ihr eigenes Leben, sondern auch um das ihrer Kinder fürchten musste. In der Forschung wird die Beteiligung des Seianus am Tod des Drusus sowie gelegentlich auch das Verhältnis zu Livilla bezweifelt.

Seianus versuchte im Jahr 25, Livilla zu heiraten, wodurch er Mitglied der kaiserlichen Familie geworden wäre. Tiberius lehnte die Heirat jedoch mit Rücksicht auf Vorbehalte in der Kaiserfamilie ab, die eine Verschwägerung mit dem aus dem Ritterstand stammenden Seianus als unstandesgemäß empfand.

Nachdem seine Heiratspläne vereitelt worden waren, stellte Seianus Tiberius in öffentlichen Reden die Vorteile des ländlichen Lebens außerhalb der Hauptstadt vor Augen. Dem Princeps war die Anwesenheit in Rom mit ihren Intrigen und Streitereien zwischen seinen Familienangehörigen zuwider, vor allem die problematischen Beziehungen zu seiner Mutter Livia und zu Agrippina, der Witwe des Germanicus. Hinzu kamen Angst um seine persönliche Sicherheit und menschenscheues Verhalten. Bereits seit dem Jahr 22 hatte er sich wiederholt in Kampanien aufgehalten und Drusus die "tribunicia potestas" verliehen. Seianus hatte ein entschiedenes Interesse am Rückzug des Kaisers, da er dadurch – praktisch in Stellvertreterfunktion – die Übernahme der Macht vorbereiten konnte. Im Jahr 26 zog sich Tiberius tatsächlich auf die abgelegene Insel Capri zurück. Seianus kontrollierte von nun an den Zugang zu Tiberius, da seine Prätorianer verantwortlich für die Übermittlung der kaiserlichen Korrespondenz waren.

Seianus brachte schließlich seinen Anspruch auf die Thronfolge offen zum Ausdruck, indem er seinen Geburtstag zum römischen Feiertag erklären und sich öffentlich durch Aufstellen von Statuen mit seinem Konterfei ehren ließ. Dadurch stellte er den Kult um seine Person dem des Kaisers gleich.

Durchaus in Übereinstimmung mit den Interessen des Tiberius war Seianus wahrscheinlich an Intrigen gegen Agrippina und ihre Parteigänger entscheidend beteiligt. Angeblich ließ er ihren ältesten Sohn und Nachfolgekandidaten Nero Caesar bespitzeln und durch Mittelsmänner zu unbedachten Äußerungen gegen Tiberius verleiten. Als Folge wurden Nero und Agrippina im Jahre 29 auf die Insel Pandataria verbannt, wo beide in den Tod gedrängt wurden. Ihr zweiter Sohn Drusus Caesar verhungerte ein Jahr später im Kerker. Einige Forscher sehen jedoch die Beteiligung des Seianus an den nicht genau bekannten Vorwürfen gegen die Familie des Germanicus als allenfalls gering an.

Antonia Minor, die Witwe von Tiberius’ Bruder Drusus, denunzierte schließlich Seianus bei Tiberius mit dem Vorwurf, dieser wolle Gaius, den späteren Kaiser Caligula, beseitigen lassen, um sich als einzigen Nachfolger zu positionieren. Als Reaktion ließ Tiberius im Jahr 31 von Capri aus einen Brief an den Senat schicken, wobei er Seianus, der unlängst zum Consul ernannt worden war, in den Glauben setzte, dass dieser Brief die Übertragung der Amtsgewalten an dessen Person enthielt. Der in Anwesenheit des Seianus verlesene Brief begann mit dessen Verdiensten, endete aber mit Vorwürfen und der Verurteilung des Seianus. Seianus wurde verhaftet und zusammen mit seinen Kindern durch Strangulierung hingerichtet. Sein Leichnam wurde auf die Gemonische Treppe geworfen, dort vom Mob zerstückelt und anschließend an einem Haken zum Tiber geschleift, da nach altrömischer Jenseitsvorstellung den im Meer treibenden Toten der Zugang zur Unterwelt verwehrt war. Es ist unklar, ob Seianus tatsächlich die Ermordung Caligulas plante oder einer Hofintrige bzw. seinen eigenen Machtansprüchen, die ihm Neid und Missgunst einbrachten, zum Opfer fiel. In den Jahren 31 bis 37 wurden zahlreiche Senatoren und Ritter unter dem Verdacht, die Pläne des Seianus unterstützt zu haben, hingerichtet oder zum Selbstmord gezwungen. Tacitus beschreibt im sechsten Buch der "Annalen" eine Atmosphäre voller Terror und Intrigen, bei der es unklar gewesen sei, „ob es bejammernswerter sei, der Freundschaft wegen angeklagt zu werden oder den Freund selbst anzuklagen“.

Nachfolger des Seianus als Prätorianerpräfekt wurde Naevius Sutorius Macro.

Die antiken Historiographen (Cassius Dio, Sueton und Tacitus) stellten den Kaiser in seinen letzten Lebensjahren als unansehnlichen, durch Hautgeschwüre entstellten Lustgreis dar, der sich auf Capri pädophilen und sadistischen Neigungen hingebe und die Öffentlichkeit scheue. Insbesondere der Kaiserbiograph Sueton charakterisierte Tiberius in dieser Hinsicht sehr ausführlich, bediente allerdings damit die Erwartung eines senatorischen Publikums im frühen 2. Jahrhundert. So soll Tiberius männliche Minderjährige in den kaiserlichen Thermalbecken zu homosexueller Unterwasser-Fellatio missbraucht und in diesem Zusammenhang seine „Fischlein“ genannt haben. Angeblich wurde auch der spätere Kaiser Vitellius von Tiberius hierzu sexuell missbraucht.

Die moderne Forschung löst sich von diesen tendenziell stereotypen Überlieferungsformen, die sich dadurch begründen lassen, dass zum Ende der Regierungszeit des Tiberius erstmals die politische Ohnmacht und der Autoritätsverlust des Senats vor Augen traten. Dies äußerte sich in den andauernden Majestätsprozessen und in der mangelnden Möglichkeit, auf Entscheidungen im fernen Capri Einfluss zu nehmen. Nach antikem Verständnis war es üblich, in biographischen Abhandlungen die allgemeine politische Richtung eines Kaisers mit dessen charakterlichen Anlagen und Privatinteressen in engen, teils fiktiven Zusammenhang zu bringen. Die Residenz des Tiberius auf Capri, die Villa Jovis, ist als Ruine erhalten. Sie war grundsätzlich darauf ausgelegt, Regierungsgeschäfte zu erledigen, wurde aber von keinem späteren Kaiser mehr bewohnt.

Als Tiberius am 16. März 37 in Misenum am Golf von Neapel starb, hatte er sich nicht nur beim Senat unbeliebt gemacht, sondern auch bei der stadtrömischen Bürgerschaft, die seinen Leichnam wie den eines Verbrechers in den Tiber werfen "(Tiberium in Tiberim)" oder im Theater von Atella anrösten wollte. Die Anfeindungen in der Bevölkerung resultierten aus den zahlreichen Hinrichtungen der letzten Regierungsjahre, denen jährlich mehrere hundert Bürger der Hauptstadt zum Opfer fielen. Ihre Leichname wurden zur Abschreckung auf den Gemonischen Treppen ausgestellt. In der öffentlichen Darstellung wurde diese Politik mit notwendiger Verbrechensbekämpfung und erforderlicher Eindämmung unsittlichen Verhaltens begründet.

Tiberius’ Leichnam wurde nach Rom eskortiert und öffentlich verbrannt. Seine Asche wurde im Augustusmausoleum beigesetzt. Eine Divinisierung erfolgte zunächst nicht. Allerdings wurde Tiberius in der Lex de imperio Vespasiani des Jahres 69 zu den Kaisern gezählt, deren Regierungsbeschlüsse noch gültig waren. Der vollständige Name des Tiberius zum Zeitpunkt seines Todes lautete gewöhnlich "Tiberius Caesar Divi Augusti filius Augustus, Pontifex maximus, Tribunicia potestate XXXVIII, Imperator VIII, Consul V" („Tiberius Caesar Augustus, Sohn des vergöttlichten Augustus, höchster Priester, im 38. Jahr Inhaber der tribunizischen Vollmacht, achtmal zum Imperator ausgerufen, fünfmaliger Konsul“).

Es ist überliefert, dass Tiberius in der Nachfolgeregelung unschlüssig gewesen sei. Einen Nachfolger außerhalb seiner Familie zu suchen, wagte Tiberius nicht, um das mit der Autorität des Augustus verbundene dynastische Prinzip nicht zu verletzen. Es blieben daher nur Germanicus’ Sohn Gaius, der spätere Kaiser Caligula, oder Tiberius Gemellus, Enkel des Tiberius, als Kandidaten übrig. Im Jahr 31 ließ Tiberius Gaius zu sich nach Capri kommen. Dort gelang es Gaius offenbar, das Vertrauen des Kaisers zu gewinnen. Sueton gibt an, dass dieses Vertrauensverhältnis auf dem gemeinsamen Interesse an Folterungen und sexuellen Ausschweifungen beruht habe. Tiberius soll zu Gaius gesagt haben: „Du wirst diesen [Gemellus] ermorden, dich ein anderer.“ Tatsächlich ließ Caligula, kurz nachdem er Kaiser geworden war, Tiberius Gemellus Ende des Jahres 37 oder Anfang des Jahres 38 töten, weil dieser verdächtigt wurde, eine schwere Krankheit Caligulas ausgenutzt zu haben, um sich gegen ihn zu verschwören. Möglicherweise wurde Tiberius selbst auch von Gaius umgebracht, wobei die Quellenaussagen nicht eindeutig sind und ungeklärte Todesfälle von Herrschern oft unbestätigte Mordgerüchte nach sich zogen. Es wurde auch spekuliert, dass der Prätorianerpräfekt Macro den Tod des Tiberius herbeigeführt habe.

Während Tiberius’ Regierungszeit wirkte Jesus von Nazareth. In dessen Predigten und Gleichnissen gibt es mehrfach Bezüge zu "Caesar" (bzw. dem "Kaiser" in einigen Übersetzungen), ohne jedoch den Namen Tiberius zu erwähnen, wie wahrscheinlich im Falle der Steuermünze in den Evangelien des Matthäus und Markus . Im Neuen Testament wird Tiberius nur einmal namentlich erwähnt, im Lukasevangelium im Rahmen des sogenannten lukanischen Datums, das auf das Jahr 28 hinweist und als einziges eine sichere Datierung der neutestamentlichen Ereignisse erlaubt:
In der Ära des Tiberius löste die Kreuzigung Jesu (wahrscheinlich im Jahr 30) weder besondere Aufmerksamkeit in Rom noch irgendeinen Aufstand aus. Judäa galt damals als ruhige Region. Der christliche Historiker Eusebius von Caesarea berichtet, dass der Senat die Anerkennung des Christengottes seitens des römischen Staates formal abgelehnt, Tiberius selbst allerdings keine Verfolgungen gegen Christen in Erwägung gezogen habe, was die Verbreitung des Frühchristentums begünstigt habe. Zu Ehren des Kaisers erhielt die Stadt Tiberias an der Westküste des See Genezareth ihren Namen vom Tetrarchen Herodes Antipas.

Auch Tacitus erwähnt in seiner Schilderung von Tiberius’ Herrschaft in den ersten sechs, zum großen Teil erhaltenen Büchern der "Annalen" Christus mit keinem Wort. Die Kreuzigung Jesu wird bei Tacitus nur nebenbei erwähnt, als er sich zur Hinrichtung von Christen in Rom unter Kaiser Nero äußert:

Tiberius war – verglichen etwa mit den Herrschern Caesar oder Nero – nur relativ selten Gegenstand künstlerischer Bearbeitung. Gerhart Hauptmann schrieb 1884 in Rom das Drama "Das Erbe des Tiberius", Julius Grosse verfasste 1876 ein Drama namens "Tiberius". Zahlreiche historische Romane befassen sich seit Franz Horn mit dem zweiten Kaiser, wenn auch in vielen Fällen nur als Nebenfigur wie im Roman "Ich, Claudius, Kaiser und Gott" (1934) von Robert von Ranke-Graves, der auch als TV-Serie verfilmt wurde.

Da das Kreuzigungsgeschehen in seine Regierungszeit fällt, wird Tiberius vor allem in belletristischen Werken und Monumentalfilmen mit neutestamentlichen Bezügen wie etwa "Das Gewand" oder "Ben Hur" (Triumphszene, Begnadigung von Ben Hur) beiläufig dargestellt. In Tinto Brass’ berüchtigtem "Caligula" (1979) nach einem Drehbuch von Gore Vidal wurde Tiberius von Peter O’Toole als grausamer Lustgreis dargestellt. Ähnlich zeichnete Anthony Burgess den Kaiser in seinem Roman "The Kingdom of the Wicked", der als Mini-TV-Serie unter dem Titel "Anno Domini" (1984) verfilmt wurde.

Unter den literarischen Bearbeitungen nach dem Zweiten Weltkrieg sind die Romane von Josef Toman (1963) und Hubertus Prinz zu Löwenstein-Wertheim-Freudenberg aus dem Jahr 1977 zu nennen. Einen belletristischen Rehabilitierungsversuch unternahm Gerhard Prause (1966).

Der spanische Psychologe Gregorio Marañón beschäftigte sich 1939 mit der Erforschung der Persönlichkeit des Tiberius und analysierte eine mögliche Geisteskrankheit, das sogenannte Ressentiment-Syndrom, bei dem die Selbstwahrnehmung und der Eindruck, den die Personen tatsächlich in ihrer Umgebung hinterlassen, gestört seien. Eine solche gestörte Eigenwahrnehmung resultiere oft aus Misserfolgen.

Die antiken Historiographen Sueton, Cassius Dio und besonders Tacitus stellen Tiberius als lethargisch und tyrannisch dar. Die negative Charakterisierung des Tiberius war aber bereits in früheren, heute verlorenen Geschichtswerken erfolgt, auf die sich die genannten Autoren stützten. In der Forschung konnte durch Quellenanalysen bewiesen werden, dass Dio und Tacitus teils eine gemeinsame Quelle herangezogen haben, wenngleich keiner immer nur einer Quelle folgte. Jedoch findet Velleius Paterculus, der im Gegensatz zu den anderen Historiographen ein Zeitgenosse des Tiberius war, lobende Worte, die allerdings als panegyrische Verherrlichung des Tiberius ausgelegt werden müssen. 

Radikale moderne Rehabilitierungsversuche bis hin zu der Vorstellung, in Tiberius eine starke Führungsperson zu sehen, sind den politischen Projektionen des 19. Jahrhunderts zuzuschreiben. Die 1960 postum veröffentlichte Tiberius-Biographie von Ernst Kornemann gehört ebenfalls den energischen Rehabilitierungsversuchen an und stellt den Tod des Kaisers in einen weltgeschichtlichen Zusammenhang zum Kreuzigungsgeschehen.

Die moderne Forschung bemüht sich um ein ausgewogeneres Urteil. Nach Zvi Yavetz sprechen gegen die Deutung des Tiberius als Tyrannen, dass er kein Usurpator war (denn die Legitimität seiner Herrschaft war durch die Adoption des Augustus unbestritten), keine göttliche Verehrung anstrebte und keine Eroberungskriege führte, um von innenpolitischen Schwierigkeiten abzulenken. Yavetz nannte seine Tiberiusbiographie "Der traurige Kaiser" und deutete damit Tiberius auch psychologisch, indem er den Tiberius verliehenen inoffiziellen Beinamen "tristissimus hominum" („der Traurigste unter den Menschen“) sowie seine düstere und menschenscheue Persönlichkeit auf die problematischen Ereignisse in der Jugend des Tiberius zurückführte. Auch Michael Grant sah Tiberius für das Erbe des Prinzipats als charakterlich nicht hinreichend geeignet an.

Barbara Levick begründet das ungünstige Urteil der antiken Historiographie aus der Institutionalisierung des Prinzipats nach dem Tod des Augustus, den materiellen Interessen der Senatsaristokratie und der damit kontrastierenden Amtsmüdigkeit des Kaisers, der darin versagte, den Hofintrigen anders als durch Gewalt Einhalt zu gebieten, jedoch in der Provinzverwaltung eine glückliche Hand besaß. Robin Seager erklärt in ähnlicher Weise das Geschichtsbild aus einem gemeinsamen Versagen von Kaiser und Senat sowie aufgrund von Erzählmustern der antiken Historiographie, die eine in Phasen verlaufende Wandlung des Kaisers zum Scheusal beschreiben. David C. A. Shotter erkennt Schwächen in der Amtsführung des Tiberius, vor allem im Umgang mit dem Senat, weist ihm jedoch das Verdienst zu, nach Augustus das Reich dauerhaft in eine dynastische Monarchie umgeformt zu haben.





</doc>
<doc id="5127" url="https://de.wikipedia.org/wiki?curid=5127" title="Trebonianus Gallus">
Trebonianus Gallus

Gaius Vibius Trebonianus Gallus (* 206 in Perusia; † August 253) war zwischen 251 und 253 gemeinsam mit seinem Sohn Volusianus römischer Kaiser.

Trebonianus Gallus wurde in Italien in eine Familie mit weithin geachteten Vorfahren und senatorischem Hintergrund geboren. Er hatte zwei Kinder aus seiner Ehe mit Afinia Gemina Baebiana, den späteren Kaiser Gaius Vibius Volusianus und eine Tochter, Vibia Galla. In den vierziger Jahren war er Suffektkonsul und 250 Statthalter der Provinz "Moesia" (Mösien), woraus ersichtlich ist, dass der Kaiser Decius ihm vertraute. In "Moesia" war Gallus eine Schlüsselfigur bei der Abwehr der häufigen Invasionen der Goten über die Donau und wurde dadurch bei der Armee populär.

Anfang Juni 251 starben Kaiser Decius und sein älterer Sohn und Mitkaiser Herennius Etruscus in der Schlacht von Abrittus bei einem Feldzug gegen die Goten (zu den Hintergründen siehe auch "Reichskrise des 3. Jahrhunderts"). Daraufhin proklamierten die Soldaten der Donauarmee Gallus zum Kaiser, obwohl der in Rom verbliebene jüngere Sohn des Decius, Hostilian, der den Titel "Caesar" trug, einen Anspruch auf die Nachfolge hatte. Der Senat erhob Hostilian zum neuen Kaiser. Um einen Bürgerkrieg zu vermeiden, akzeptierte Gallus Hostilian als Mitkaiser und adoptierte ihn. Hostilians Mutter Herennia Etruscilla behielt den Titel "Augusta", während die Frau des Gallus vorerst auf diesen Titel verzichten musste. Gallus verheiratete seinen Sohn mit der Schwester Hostilians. 

Im November 251 starb Hostilian in Viminatium an der Pest. Jetzt im Besitz der alleinigen Macht, ernannte Gallus seinen Sohn Volusianus zum Mitkaiser.

Begierig darauf, Kompetenz zu zeigen und Popularität in der Stadt zu gewinnen, engagierte sich Gallus schnell im Kampf gegen die Seuche und organisierte die Beisetzung der Opfer. Gallus wird oft zu den Christenverfolgern gezählt, aber das einzige Indiz dafür ist die angebliche Einkerkerung des römischen Bischofs Cornelius im Jahr 252.

Wie seine Vorgänger hatte auch Gallus keine einfache Regierungszeit. Im Osten marschierte der persische König Schapur I. ein, eroberte die Provinz "Syria" (Syrien), ohne auf römischen Widerstand zu treffen. An der Donau überfielen die gotischen Stämme trotz des Friedensvertrags von 251 erneut das Land. Die Armee war mit dem Kaiser nicht zufrieden, und als Aemilianus, der Statthalter der Provinzen "Moesia superior" (Obermösien) und "Pannonia" (Pannonien), die Initiative ergriff, die Goten angriff und schlug, wurde er von seinen Soldaten zum Kaiser proklamiert.

Gallus bereitete sich auf den Kampf vor. Er rief mehrere Legionen und andere Verstärkungen von der Rheingrenze zurück; unter den loyalen Heerführern war dabei auch der spätere Kaiser Valerian. Trotz dieser Maßnahmen marschierte Aemilianus nach Italien, um seinen Anspruch durchzusetzen. Gallus bekam nicht die Gelegenheit, sich zu verteidigen: Er wurde von seinen eigenen Truppen im August 253 ermordet. Sein Sohn Volusianus teilte sein Schicksal.



</doc>
