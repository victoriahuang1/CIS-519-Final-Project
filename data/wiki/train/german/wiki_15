<doc id="1646" url="https://de.wikipedia.org/wiki?curid=1646" title="Februar">
Februar

Der Februar ( „reinigen“) ist der zweite Monat des Jahres im gregorianischen Kalender. Schon seit 153 v. Chr. war er auch der zweite Monat des römischen Kalenders. Er wurde nach dem römischen Reinigungsfest Februa benannt. In Österreich sowie Teilen Südtirols wird er auch Feber genannt, insbesondere in der Amtssprache.

Der Monat umfasst in Gemeinjahren 28 Tage und in Schaltjahren 29 Tage. Der eigentliche Schalttag ist der 24. Februar, d. h. in Schaltjahren wird nach dem 23. Februar ein Tag eingeschoben, was jedoch nur für die kirchlichen Feiertage und Namenstage von Bedeutung ist, die sich vom 24. Februar und den folgenden Tagen in Schaltjahren auf den 25. Februar etc. verschieben. Dies erklärt, weshalb das Schaltjahr bspw. im Französischen "année bissextile" heißt: In der Antike wurde der 24. Februar (der sechstletzte Tag vom 29. aus gerechnet, lat. "sex") doppelt (lat. "bis") gerechnet.

Im römischen Kalender war der Februarius ursprünglich der letzte Monat. Aus diesem Grund erhielt genau dieser Monat damals überzählige Schalttage angehängt, ein Brauch, der sich durch die julianische und gregorianische Kalenderreform hindurch erhalten hat.

Der Februar beginnt in Nicht-Schaltjahren mit dem gleichen Wochentag wie der März (28 geteilt durch 7 ist 4, daraus folgt, dass der Februar exakt vier Wochen lang ist und der Folgemonat mit dem gleichen Wochentag beginnt) und der November, in Schaltjahren wie der August.

Der Februar beginnt immer mit dem gleichen Wochentag wie der Juni des Vorjahres, weil niemals ein Schalttag (29. Februar) zwischen beiden Monaten liegt.

Banktechnisch hat der Februar wie jeder andere Rechnungsmonat (nach deutscher Zinsberechnungsmethode) 30 Zinstage, so dass Zinsabrechnungen zum 30. Februar durchaus sinnvoll sind.

Unter Kaiser Commodus wurde der Monat in "Invictus" umbenannt, nach dem Tod des Kaisers erhielt er allerdings seinen alten Namen zurück.
Der alte deutsche Name für den Februar ist "Hornung", weil der reife Rothirsch in diesem Monat die Stangen seines Geweihes abwirft und beginnt, ein neues Geweih zu schieben. Eine andere Theorie geht davon aus, dass Hornung „der im Winkel/Geheimen gezeugte Bastard“ bedeutet, da er in der Anzahl der Tage zu kurz kommt. Im Elsass wird dieser Monat auch heute noch so bezeichnet. Auch im Pennsylvaniadeutsch ist der alte Monatsname als "Hanning" erhalten geblieben.

Weitere gebräuchliche Namen waren "Schmelzmond" und "Sporkel" oder "Spörkel". Bei Gärtnern war früher die Bezeichnung "Taumonat (Taumond)" üblich.

Die Bezeichnung "Narrenmond" für den Februar rührt daher, dass in dieser Zeit die alten Vorfrühlings- und Fruchtbarkeitsrituale abgehalten wurden, um die Dämonen des Winters zu vertreiben. Unter dem Einfluss der Christianisierung wurden diese ausgelassenen Feierlichkeiten als Fastnacht (Fassenacht, Fasnet) oder Fasching auf die Tage vor dem Aschermittwoch beschränkt, so dass diese Narrenzeit (meistens) im Februar endet.




</doc>
<doc id="1647" url="https://de.wikipedia.org/wiki?curid=1647" title="Florenz">
Florenz

Florenz ( ) ist eine italienische Großstadt mit Einwohnern (Stand ). In der Metropolregion leben 1,5 Millionen Menschen. Florenz ist Hauptstadt sowie größte Stadt der Toskana und der Metropolitanstadt Florenz. In Italien ist Florenz die nach Einwohnern achtgrößte Stadt.

Florenz ist für seine Geschichte berühmt. Als Zentrum des spätmittelalterlichen europäischen Handels- und Finanzwesens war es eine der reichsten Städte des 15. und 16. Jahrhunderts. Florenz gilt als die Wiege der Renaissance. Aufgrund seiner kulturellen Bedeutung – insbesondere für die bildende Kunst – wird es schon seit dem 19. Jahrhundert auch als das „italienische Athen“ bezeichnet.

Durch die mächtige Dynastie der Familie Medici stieg Florenz in der Renaissance zu einer der florierendsten Metropolen Europas auf. Zahlreiche Kunstschaffende und Geistliche waren hier beheimatet: Leonardo da Vinci verbrachte große Teile seiner Jugend in Florenz, Michelangelo fand Unterschlupf in der Kirche der Medici, Galileo Galilei wohnte als Hofmathematiker in den Palästen der Medici. Von 1865 bis 1870 war die Stadt die Hauptstadt des neu gegründeten Königreichs Italien.

Das historische Zentrum von Florenz zieht Jahr für Jahr Millionen von Touristen an. Euromonitor International platziert die Stadt mit fast 4,2 Millionen Besuchern im Jahr 2015 weltweit an 40. Stelle unter den meist besuchten Städten. Die historische Innenstadt wurde von der UNESCO im Jahre 1982 zum Weltkulturerbe erklärt. Aufgrund des künstlerischen und architektonischen Erbes hat das Forbes Magazine Florenz als eine der schönsten Städte der Welt ausgewählt. Hingewiesen wird vor allem auf den Reichtum an Museen, Palästen und Denkmälern.

Florenz liegt am Arno, der durch die Altstadt fließt, und am Mugnone, der von Norden kommend westlich der Altstadt in den Arno mündet. Von Süden kommend tritt der Ema dem Greve bei Galluzzo zu, zusammen münden sie danach im Stadtgebiet von Florenz im Arno. Der Arno war ebenso wichtig für die Versorgung der Menschen durch den Handel, sorgte allerdings durch Überflutungen auch für Zerstörung und Leid. Nördlich von Florenz erstreckt sich der Höhenzug des toskanisch-emilianischen Apennins, im Süden grenzen die Hügel des Chianti an die Stadt.

Der Aufstieg der Stadt von einem Armeelager zu einer Hochburg der Renaissance vollzog sich langsam. 1330 zählte die Stadt ungefähr 30.000 Einwohner. Bis zum Jahr 1348 wuchs die Zahl der Einwohner auf bis zu 100.000 an. Die Pestpandemie traf Florenz besonders hart und forderte in Florenz geschätzte 70.000 Tote, nur knapp ein Fünftel der Bevölkerung überlebte.

Mitte des 19. Jahrhunderts war wieder ein kontinuierlicher Anstieg zu verzeichnen, die Stadt zählte 150.000 Einwohner. In den 1980er Jahren waren starke Abwanderungsströme und Geburtenrückgänge zu erkennen, weshalb seitdem die Einwohnerzahl in Florenz rückläufig ist.

Florenz befindet sich noch in der gemäßigten Klimazone mit sehr warmen Sommern und kalten und feuchten Wintern. Aufgrund seiner Lage und des damit verbundenen Mangels an Ventilation ist es in Florenz im Sommer spürbar wärmer als an der Küste.

Die höchste gemessene Temperatur lag bei 44 °C im Juli 1983. Die tiefste festgestellte Temperatur war −23 °C im Januar 1985.

Oberbürgermeister (ital. Sindaco) von Florenz ist seit 26. Mai 2014 Dario Nardella, Mitglied der PD (Partito Democratico).

Im Mittelalter war Florenz in vier Stadtviertel "(Quartieri)" eingeteilt, welche nach den Stadttoren benannt waren: San Piero, Duomo oder Vescovo, San Pancrazio und Santa Maria. Später wurden daraus sechs, so dass man von Sestieri sprach: San Piero, Duomo, San Pancrazio, San Piero a Scheraggio, Borgo, Oltrarno. Hinzu kommen die Vororte westlich und östlich der Ausfallstraßen und der markanten Hügel San Miniato, Belvedere und Bellosguardo im Süden sowie Careggi, Montughi, Fiesole und Settignano im Norden.

Die moderne Verwaltungsgliederung in fünf Stadtviertel ab 1990 orientiert sich im Außenbereich an den Grenzen der traditionellen Stadtviertel, wie auf den Karten zu sehen ist:

Die fünf modernen Verwaltungseinheiten im Überblick, mit zugehörigen Stadtteilen:

Die Geschichte von Florenz ist heute u. a. deshalb so bekannt, weil sie um das Jahr 1520 von Niccolò Machiavelli (1469–1527) erstmals aufgeschrieben wurde. Machiavelli schrieb seine "Istorie fiorentine" im Auftrag der Medici und überreichte das umfangreiche Werk im Jahre 1525 Giulio de’ Medici, der sich als Papst Clemens VII. nannte. Machiavelli begann schon in seiner Jugendzeit, die Geschichte seiner Heimatstadt aufzuschreiben und nannte sein erstes Buch "Decannale". Später knüpfte er daran an und wurde einer der ersten Historiker der Neuzeit.

Florenz wurde nach 59 v. Chr. von Julius Cäsar als Colonia mit dem Namen "Florentia" (nach der römischen Göttin der Blumen und des Pflanzenwachstums) im fruchtbaren, aber noch teilweise sumpfigen Arnotal errichtet. Die Colonia bestand erstens aus einem Militärlager, dem Castrum, dessen quadratische Anlage sich auch heute noch im Straßenverlauf widerspiegelt (Via Tornabuoni, Via Cerretani, Via del Proconsolo und Piazza della Signoria). Das Forum befand sich am heutigen Platz der Republik. Florentia verfügte auch über Thermalbäder und ein Amphitheater. Zur Colonia gehörten auch die Ansiedlungen der Veteranen der Garnison außerhalb des Castrum, die gemäß der Lex Julia nach der Entlassung aus dem Militärdienst eine Landparzelle zur Bebauung zugewiesen erhielten, die aufgrund der Vergabepraxis in Form einer Verlosung "partes" genannt wurde. Die verkehrstechnisch günstige Lage am Kreuzungspunkt der nach Rom führenden Via Cassia, der von Volterra kommenden Etruskerstraße (Volterana) und der ebenfalls etruskischen Pisana, die über Pisa ans Meer führte, begünstigte das rasche Aufblühen der Stadt auf Basis von Handel und Handwerksbetrieben. Die älteren etruskischen Ansiedlungen, vor allem das auf einem Hügel nördlich der neuen Stadt gelegene bedeutende Fiesole (Gründung 7. Jahrhundert vor Christus) gerieten dadurch rasch ins Hintertreffen. Nachdem man neben Fiesole auch den Etruskerstädten Volterra und Chiusi sowie den römischen Coloniae Pistoia und Lucca den Rang abgelaufen hatte, ernannte Kaiser Diokletian Florenz zur Hauptstadt der Siebenten Region (Toskana und Umbrien).

Im Zuge der byzantinischen Rückeroberungskriege wurde die Stadt fast vollständig zerstört und nahm erst wieder unter den Langobarden einen Aufschwung. Da die Langobardenherzöge jedoch in Lucca bzw. Pisa residierten, konnte Florenz bis ins 12. Jahrhundert nicht an die Bedeutung vor der Völkerwanderungszeit anschließen. Entscheidend für den Wiederaufstieg wurde die um 1000 erfolgte Verlegung des Amtssitzes des von den Karolingern eingesetzten Markgrafen Hugo nach Florenz. Mit dem Aufkommen des Feudalismus expandierte die Stadt im 12. Jahrhundert und wurde schließlich autonom. Die Bürgerschaft gewann an Macht, es kam zu erbitterten Streitereien zwischen den kaisertreuen Ghibellinen und den später siegreichen Anhängern des Papstes, den Guelfen.

Im 14. und 15. Jahrhundert blühte die Stadt auf und setzte die Maßstäbe in der europäischen Kunst und Kultur. Viele Künstler und Gelehrte siedelten sich an, darunter Donatello, Botticelli; später Michelangelo, Machiavelli, Leonardo da Vinci und Galileo Galilei. Es entwickelte sich die kulturgeschichtliche Epoche der Renaissance (italienisch "Rinascimento").

Zugleich wurde Florenz zum Handels- und Finanzzentrum. Die reiche Familie der Medici stieg im 15. und 16. Jahrhundert zu einer Großmacht auf und prägte die Stadt wie keine andere Familie. Der erste bedeutende Medici war Cosimo I., der sich die Stadt nach und nach untertan machte. Cosimo lebte kurze Zeit im Exil, als die Medici durch gegnerische Familien gestürzt worden waren. Da jedoch die Wirtschaft aufgrund der Abwesenheit der Medici zum Erliegen kam, kehrte Cosimo aus seinem Exil zurück und übernahm 1537 als Herzog die Regentschaft. Durch geschicktes Agieren und eine präzise ausgewählte Kundschaft schuf sich Cosimo ein Netzwerk aus bedeutenden Politikern, Handelsleuten und bis in die höchsten Ränge der katholischen Kirche. Die Tatsache, dass die Medici als die privaten Bankiers des Papstes fungierten, machte sie schnell zu einer angesehen Bankiersfamilie. Doch hinter den Kulissen wurde die Politik jener Zeit von Intrigen und Skandalen erschüttert. Der Einfluss der Medici, ihr Geschick und ihr ausgeprägter Geschäftssinn ließen Florenz prosperieren und zur Kulturhochburg zweier Jahrhunderte in Europa aufsteigen. Stellvertretend steht hierfür unter anderem die Fertigstellung der Kuppel der Santa Maria del Fiore, die als technische Meisterleistung gilt.

Die kulturelle Bedeutung von Florenz schwand im 17. Jahrhundert. Die Medici, die lange Zeit die Stadt geprägt hatten, starben aus, und als Franz I. Stephan, der Ehemann von Maria Theresia, ihr Nachfolger und als "Franz II." Großherzog der Toskana (1737–1765) wurde, gelangte Florenz in den Besitz der Habsburger. Von 1801 bis 1807 war Florenz Hauptstadt des Königreichs Etrurien, ehe es von Frankreich besetzt und bis 1814 Hauptstadt des Départements Arno wurde.

Erst im 19. Jahrhundert begann ein neuer wirtschaftlicher Aufschwung. Florenz wurde das Ziel von Bildungsreisen, den Grands Tours, und ein Teil Österreichs. 1859 verloren die Österreicher aber gegen Frankreich und das Königreich von Sardinien-Piemont, Florenz wurde 1861 Teil des Vereinigten Italiens. Die Stadt folgte Turin 1865 als italienische Hauptstadt nach und beherbergte so das erste Parlament des neuen Staates, verlor die Würde aber bereits 1871 an Rom.

Nachdem die Stadtbevölkerung sich im 19. Jahrhundert verdoppelt hatte, verdreifachte sie sich im 20. Jahrhundert und profitierte stark von den neuen Wirtschaftszweigen des Tourismus und der Industrie, während Fernhandel und Finanzwirtschaft wieder aufblühten.

Nach der nationalsozialistischen Machtergreifung in Deutschland siedelten sich viele deutsche Intellektuelle in und um Florenz an. Nicht alle von ihnen waren Emigranten im klassischen Sinne, sondern verließen Deutschland nur, weil ihnen das politische und kulturelle Klima in der Heimat nicht behagte. Das gilt etwa für den Kreis um Hans Purrmann, der ab 1935 die Villa Romana in Florenz leitete. Politisch und rassistisch Verfolgte fanden sich dagegen eher in den Kreisen um den Verleger Kurt Wolff, die Schriftsteller Alfred Neumann und Karl Wolfskehl oder am Landschulheim Florenz. Nach der Verabschiedung der italienischen Rassengesetze von 1938 waren auch in Florenz und Umgebung viele jüdische Emigranten zur abermaligen Flucht gezwungen oder hatten diesen Schritt, wie etwa Karl Wolfskehl, schon nach dem Hitlerbesuch in Italien im Frühjahr 1938 vollzogen. Noch prekärer wurde die Situation nach der Besetzung Florenz durch die deutschen Truppen in den Jahren 1943 bis 1945, in deren Folge es zu Razzien und anschließenden Deportationen nach Auschwitz kam.

Bei einer Volksabstimmung von 1946 stimmten die Florentiner gegen den Erhalt des Königreichs und für die Republik Italien. Von 1946 bis 1950 regierte eine Koalition aus Sozialisten und Kommunisten die Stadt. Es vollzog sich ein rascher wirtschaftlicher und sozialer Wandel und Aufschwung. Die Jahre bis 1964 waren durch den christlich-sozialen Politiker Giorgio La Pira geprägt, der Bürgermeister von 1950 bis 1956 und wieder von 1960 bis 1964 war. Die Überschwemmung in Florenz 1966 beschädigte viele Kunstschätze und forderte 34 Menschenleben, wobei die genauen Angaben von den Behörden jahrzehntelang unter Verschluss gehalten wurden.

Im Jahr 1786 endeten mit Abschaffung von Todesstrafe und Folter durch Peter Leopold (1765 bis 1790 Großherzog der Toskana) diese Methoden auch in Florenz.

Florenz hat ein großes und bedeutendes künstlerisches Erbe. Cimabue und Giotto, die „Väter“ der italienischen Malerei, lebten in Florenz sowie Arnolfo und Andrea Pisano. Weitere bedeutende Pioniere in Architektur und Skulptur waren Brunelleschi, Donatello und Masaccio, allesamt verbrachten sie große Zeit ihres künstlerischen Lebens in Florenz. Auch der Universalgelehrte Leonardo da Vinci gilt als einer der herausragendsten Denker und Erfinder seiner Zeit. Er verbrachte einen großen Teil seines Lebens in der Stadt.

Die Kunst vieler Maler und Bildhauer wird in den zahlreichen Museen in Florenz ausgestellt, die vor allem in den Sommermonaten ausverkauft sind oder sich Schlangen mit stundenlangen Wartezeiten bilden. Die bekanntesten Museen sind die Uffizien und der Palazzo Pitti, mit einer herausragenden Sammlung.
In Florenz wird Florentinisch (fiorentino) gesprochen. 
Florentinisch ist ein toskanischer Dialekt, der in vielen Teilen identisch mit dem Standarditalienischen ist, in der Aussprache aber Besonderheiten aufweist.

Die Bevölkerung ist zu etwa 99 % römisch-katholisch, bedingt durch den wichtigen Sitz des Erzbischofs und der Bischofskirche Santa Maria del Fiore. Es gibt jedoch mehrere Kirchen anderer christlicher Glaubensgemeinschaften sowie eine Synagoge.

Die historische Altstadt von Florenz spiegelt die überragenden Leistungen der Stadt auf dem Gebiet der Architektur wider. Hierbei sind insbesondere zahllose Bauten von der Zeit der Protorenaissance bis zur Herrschaft der Medici im 15. und 16. Jahrhundert entstanden, die die enorme wirtschaftliche und kulturelle Bedeutung der Stadt zu dieser Zeit belegen. Die Entstehung vieler Bauten der Stadt wurde dabei durch die Bankiers und Kaufleute der Stadt gefördert. Die florentinische Architektur ist insbesondere durch die zu Beginn des 15. Jahrhunderts durch Brunelleschi, Donatello und Masaccio formulierten Prinzipien der Renaissancearchitektur geprägt, die weit über die Stadt hinaus Bedeutung erlangt haben. Die historische Altstadt von Florenz wurde 1982 in das UNESCO-Welterbe aufgenommen, wobei es hierzu im Antrag heißt, dass „jede Rechtfertigung hierfür lächerlich und unverfroren“ sei, da sich hier die „weltgrößte Anhäufung universell bekannter Kunstwerke“ befinde.

Zentrum der historischen Altstadt ist die Piazza della Signoria. Hier sandten die Florentiner Dante 1301 ins Exil, hier verbrannten sie 1497 auf Aufforderung des Girolamo Savonarola im „Fegefeuer der Eitelkeiten“ Schmuck, Kosmetika, Spiegel, Musikinstrumente und Ähnliches und im darauffolgenden Jahr nach päpstlichem Urteil Savonarola selbst. Auf dem Platz befand sich ursprünglich Michelangelos Statue David an der Frontseite des Palazzo Vecchio. Die Statue wurde jedoch mittlerweile durch eine Kopie ersetzt, das Original befindet sich in der Accademia di Belle Arti. Auf dem Platz befindet sich zudem Bartolomeo Ammanatis marmorner Neptunbrunnen. Er bildet den Endpunkt eines noch funktionsfähigen Aquädukts aus der Antike. Außer dem Palazzo Vecchio liegt die Loggia dei Lanzi an diesem wichtigsten Platz der Stadt.

An der Stelle des römischen Zentrums liegt der Platz mit dem Triumphbogen. Er wurde geplant, als Florenz ab 1865 italienische Hauptstadt war und vor allem um 1890 historistisch gestaltet.

Die einzige Brücke, die den Zweiten Weltkrieg unbeschadet überstand, ist der Ponte Vecchio. Die das erste Mal von den Etruskern gebaute Brücke verbindet die Uffizien mit dem Palast der Medici. Sie zeichnet sich heute vor allem durch entlang ihrer beiden Brüstungsverläufe erbaute Schmuckläden aus, deren Baulichkeiten teils über die Brücke hinausragen.

Zentrum der Florentiner Kirchen ist die romanisch-gotische Kathedrale Santa Maria del Fiore mit ihrer eindrucksvollen Kuppel von Filippo Brunelleschi. Die vom 12. bis 14. Jahrhundert gebaute Kirche steht Touristen offen. Zum Domkomplex gehören weiter der Campanile des Giotto südlich an der Kathedrale und das westlich vor der Kirche gelegene Baptisterium San Giovanni mit Paradiespforte. Wichtige Skulpturen aus der Kirche wie die Pietà Palestrina des Michelangelo sind im Dommuseum zu besichtigen.

Die Basilica di San Lorenzo stammt in ihrer ersten Version von 390 (von Ambrosius geweiht) und wurde ab 1421 von Brunelleschi in den Formen der Frührenaissance umgebaut. Auf Grund zwischenzeitlichen Geldmangels ruhten die Bauarbeiten mehrfach. Die Ausführung der Pläne Brunelleschis konnte so erst nach seinem Tode vollendet werden, dennoch blieb die Fassade trotz eines spektakulären Entwurfs Michelangelos von 1518 bis heute unvollendet. An ihren Chor schließt sich zwischen den beiden Sakristeien des Brunelleschi und des Michelangelo die Medici-Kapelle an, die wie diese Grablegen der Familie Medici beherbergt. An einem Kreuzgang südlich der Kirche liegt die Biblioteca Medicea Laurenziana, gleichfalls nach Plänen des Michelangelo geschaffen.


Der Palazzo Pitti, gegenüber der Piazza della Signoria jenseits des Arno gelegen, beherbergt heute die ehemalige Privatsammlung der Medici. Angeschlossen an den Palast ist der Boboli-Garten mit eindrucksvoller Landschaftsgestaltung und vielen Skulpturen, dahinter der Belvedere, der einen Blick über die Stadt erlaubt.

Unter den mittelalterlichen Palästen erwähnenswert sind ferner:


Sehenswerte Renaissancepaläste sind:



Der Hauptwirtschaftszweig von Florenz ist der Fremdenverkehr. In den Sommermonaten liegt die Zahl der Touristen deutlich über der der Florentiner. Die großen Museen der Stadt sind regelmäßig ausverkauft.

Florenz beherbergt das Hauptquartier der Haute-couture-Firma Gucci, das damit eines der wenigen italienischen Modehäuser ist, das nicht in Mailand ansässig ist. Bedeutende Zweigstellen in Florenz oder der näheren Umgebung betreiben darüber hinaus auch Prada, Pucci, Ferragamo und Roberto Cavalli.

Im Jahr 2008 stand die Stadt auf Platz 17 bezüglich des Durchschnittseinkommens in Italien.

Als Handelsstadt profitiert Florenz als größte Stadt der Toskana und kann so einen umfangreichen Weinhandel beherbergen.

Kulinarisch ist Florenz auch für die Produktion von Cantuccini bekannt.

Im Nordwesten von Florenz liegt der kleine internationale Flughafen Amerigo Vespucci, der unter anderem von Alitalia und Lufthansa angeflogen wird. Busse verbinden ihn mit dem Zentrum. So verkehrt ein Pendelbus der ATAF zwischen Flughafen und Hauptbahnhof, die Fahrzeit beträgt rund 15 Minuten.

Florenz liegt an den Autobahnen E45–A1 (Mailand–Rom) und A11 (Pisa–Florenz). Hinzu kommen verschiedene Schnellstraßen.

Außerdem ist Florenz seit 1928 Knotenpunkt für Staatsstraßen: die von Rom kommende und endende SS2, die nach Bologna führende SS65, die nach Piteglio-La Lima führende SS66 und die die Stadt durchquerende SS67 Pisa–Porto Corsini.

In der historischen Altstadt herrscht für auswärtige PKW und Mietwagen – außer für Anwohner und an Feiertagen – ein striktes Einfahrverbot (Zone mit beschränktem Verkehr, "zona a traffico limitato", kurz ZTL). An den Einfahrten in die Verkehrszone überprüfen Überwachungskameras – ähnlich wie in London – in Echtzeit anhand des Kennzeichens, ob eine Einfahrtsgenehmigung vorliegt oder nicht. Einfahrten ohne Genehmigung werden sofort mit hohen Geldstrafen geahndet.

Durch Florenz verläuft die wichtigste Nord-Süd-Eisenbahnverbindung Italiens von Norditalien nach Rom und Neapel (Schnellfahrstrecke Bologna–Florenz und Direttissima Florenz–Rom) und damit auch die TEN-Achse Nr. 1 Berlin–Palermo. Nebst dem Hauptbahnhof Firenze S.M.N. gibt es noch zwei weitere Fernbahnhöfe auf Stadtgebiet, Campo di Marte und Rifredi. Es ist zudem geplant, mittelfristig einen neuen Hochgeschwindigkeitsbahnhof (Firenze Belfiore) zu bauen.

Die erste Linie der Straßenbahn Florenz verbindet den Hauptbahnhof Firenze S.M.N. mit der Nachbarstadt Scandicci. Sie wurde am 14. Februar 2010 in Betrieb genommen und hat auf einer Länge von 7,8 Kilometern 14 Stationen. Die Stadt rechnete vor der Inbetriebnahme mit etwa 9,8 Millionen Fahrgästen im Jahr. Sie wird im Rahmen einer nach einer Ausschreibung zugeteilten Konzession mit einer Laufzeit von 30 Jahren von "RATP Dev", einer Filiale des Betreibers der Pariser Metro RATP betrieben und gewartet. Zwei weitere Linien (Linie 2 und Linie 3) sind derzeit (Stand: 2016) in Bau.

Florenz beheimatet den bekannten Serie-A-Verein AC Florenz. Eine besondere Tradition ist das Calcio Storico, eine Art Mischung aus Fußball, Rugby und Kampfsport, das seine Ursprünge im 15. Jahrhundert hat.

Die 1321 gegründete Universität Florenz ist zentral, das Europäische Hochschulinstitut außerhalb gelegen. Die Accademia di Belle Arti ist eine der ältesten europäischen Kunsthochschulen.

Bekannte Persönlichkeiten der Stadt sind in der "Liste von Persönlichkeiten der Stadt Florenz" aufgeführt.

Florenz unterhält mit folgenden Städten Partnerschaften:




</doc>
<doc id="1648" url="https://de.wikipedia.org/wiki?curid=1648" title="Francis William Aston">
Francis William Aston

Francis William Aston (* 1. September 1877 in Harborne / seit 1891 zu Birmingham; † 20. November 1945 in Cambridge) war ein englischer Chemiker und Physiker sowie Nobelpreisträger (Chemie 1922). 

Francis William Aston studierte nach Abschluss seiner Schullaufbahn zunächst Chemie. Die damaligen Entwicklungen in der Physik bewogen ihn, über ein Stipendium 1903 ein weiteres Studium der Physik an der Universität von Birmingham nahe seinem Geburtsort Harborne aufzunehmen, nach dessen Abschluss er sich auf die Physik der Gasentladungsröhre konzentrierte. Bei diesen Arbeiten entdeckte er während einer Glimmentladung direkt an der Kathode vor dem ersten Kathodenlichtsaum eine hauchfeine, dunkle Schicht, die nach ihm der „Astonsche Dunkelraum“ („Aston Dark Space“) benannt wurde.

1909 folgte er einer Einladung von Sir Joseph John Thomson an das Cavendish-Laboratorium in Cambridge und befasste sich dort mit der Identifizierung der Neonisotope. Dazu hielt er Vorlesungen am Trinity College. Seine Arbeiten wurden durch den Ersten Weltkrieg unterbrochen, nach dessen Ende er 1919 wieder an seine Arbeiten zurückkehrte. Er entwickelte während seiner Forschung 1901 eine Methode der elektromagnetischen Fokussierung von Partikelstrahlen (elektromagnetischer Massenspektrograph), die zur Entwicklung des ersten Massenspektrometers (1918) führte. Mit dessen Hilfe identifizierte er mehr als 200 der 287 natürlich vorkommenden Isotope. Bereits 1919 postulierte er die extrem energiereiche Fusion von Wasserstoff zu Helium. 1922 erhielt er den Nobelpreis in Chemie „für seine Entdeckung von Isotopen, darunter weitgehend die nicht-radioaktiver Elemente unter Zuhilfenahme seines Massenspektrographen und für seine Formulierung der ‚Regel der Ganzzahligkeit‘.“ Diese Regel (Whole Number Rule - Ganzzahlregel), nach ihm auch die „Astonsche Regel“ oder „(Astonsche) Isotopenregel“ benannt, besagt: Chemische Elemente mit ungerader Ordnungszahl haben nie mehr als zwei stabile Isotope, solche mit gerader Ordnungszahl besitzen hingegen oft bedeutend mehr. Francis William Aston machte dies am Sauerstoffisotop O fest, indem er formulierte: „Bei definierter Masse des Sauerstoffisotops [O] haben alle anderen Isotope [des Sauerstoffs] Massen, die ziemlich nahe ganzer Zahlen liegen.“

Bereits vor seiner Nobelpreisverleihung wurde er 1921 in die Royal Society aufgenommen. Herausragend unter seinen Veröffentlichungen sind die Werke "Isotopen" (Isotopes, 1922) und "Massenspektren und Isotopen" (Mass-Spectra and Isotopes, 1933). 1938 wurde ihm die Royal Medal der Royal Society verliehen. Zu seinen Ehren wurde der Mondkrater „Aston“ sowie die Version 1.0 der Software OpenChrom benannt.



</doc>
<doc id="1652" url="https://de.wikipedia.org/wiki?curid=1652" title="Fourier-Analysis">
Fourier-Analysis

Die Fourier-Analysis (Aussprache: ), die auch als Fourier-Analyse oder klassische harmonische Analyse bekannt ist, ist die Theorie der Fourierreihen und Fourier-Integrale. Ihre Ursprünge reichen in das 18. Jahrhundert zurück. Benannt sind die Fourier-Analysis, die Fourier-Reihe und die Fourier-Integrale nach dem französischen Mathematiker Jean Baptiste Joseph Fourier, der im Jahr 1822 in seiner "Théorie analytique de la chaleur" Fourier-Reihen untersuchte.

Die Fourier-Analysis ist in vielen Wissenschafts- und Technikzweigen von außerordentlicher praktischer Bedeutung. Die Anwendungen reichen von der Physik (Akustik, Optik, Gezeiten, Astrophysik) über viele Teilgebiete der Mathematik (Zahlentheorie, Statistik, Kombinatorik und Wahrscheinlichkeitstheorie), die Signalverarbeitung und Kryptographie bis zu Ozeanographie und Wirtschaftswissenschaften. Je nach Anwendungszweig erfährt die Zerlegung vielerlei Interpretationen. In der Akustik ist sie beispielsweise die Frequenz-Transformation des Schalls in Oberschwingungen.

Aus Sicht der abstrakten harmonischen Analyse sind sowohl die Fourier-Reihen und die Fourier-Integrale als auch die Laplace-Transformation, die Mellin-Transformation oder auch die Walsh-Transformation (dabei werden die trigonometrischen Funktionen durch die Walsh-Funktionen ersetzt) Spezialfälle einer allgemeineren (Fourier-)Transformation.

Die verschiedenen Begriffe in diesem Zusammenhang werden leider in der Literatur nicht einheitlich gebraucht und es existieren mehrere Namen für den gleichen Vorgang. So nutzt man Fourier-Transformation sehr oft als Synonym der kontinuierlichen Fourier-Transformation, und mit Fourier-Analyse wird oft die Zerlegung in eine Fourier-Reihe gemeint, manchmal aber auch die kontinuierliche Transformation.

Je nach den Eigenschaften der zu untersuchenden Funktion gibt es vier Varianten, wie in nebenstehender Abbildung dargestellt:


Man erhält bei allen Transformationen ein Frequenzspektrum, das je nach Variante diskret (unendlich scharfe Linien) oder kontinuierlich ist:

Jede stetig differenzierbare Funktion, die auf dem Intervall formula_1 definiert ist, lässt sich in eine Fourierreihe entwickeln, das heißt, beide Seiten der Transformation existieren. Mit der Grundfrequenz formula_2 und den Kreisfrequenzen formula_3 gilt:

Es können allgemeinere Typen von Funktionen in eine Fourier-Reihe entwickelt werden, so abschnittsweise stetige, beschränkte Funktionen oder allgemeiner messbare quadratintegrable Funktionen.

Bei einem periodischen Polygonzug formula_5 (Punkte durch gerade Linien verbunden) liefern die Knick- und eventuell vorhandene Sprungstellen die Beiträge zu den Fourierkoeffizienten
Mit diesen und dem Mittelwert einer Periode
lässt sich die Ausgangsfunktion als die harmonische Summe
synthetisieren.
Die Abszissen formula_10 der formula_11 Stützwerte formula_12 (bei Sprüngen: Stützwertpaare formula_13 und formula_14) müssen in derselben Periode liegen, aufsteigend geordnet sein und formula_15 erfüllen.

Die Wertsprünge
an den formula_17 Sprungstellen werden jeweils als Differenz ihres rechts- und linksseitigen Grenzwerts formula_14 bzw. formula_19 berechnet, die Ableitungssprünge
an den formula_21 Knickstellen analog als Differenz der rechts- und linksseitigen ersten Ableitung.

Die Koeffizienten formula_22 betragen das formula_23-fache der formula_24-Werte; bei dieser Eichung der Fourierkoeffizienten sind die Amplituden der Harmonischen "gleich" den Beträgen von formula_22.

Die kontinuierliche Fourier-Transformation ist definiert durch

Die Rücktransformation lautet dazu:

In der Literatur findet man auch andere Definitionen, die als Vorfaktor statt formula_28 nur formula_29 oder 1 haben. Dies hängt von den jeweils verwendeten Normierungskonventionen ab. Die hier verwendete Variante hat den ästhetischen Vorteil, dass der Vorfaktor bei Hin- und Rücktransformation gleich ist. Außerdem vereinfacht sie die Darstellung des Satzes von Parseval:

Diese Bedingung ist zum Beispiel in der Physik wichtig für die Energieerhaltung durch die Fourier-Transformation. Mathematisch gesehen bedeutet die Gleichung, dass die Fourier-Transformation eine unitäre Abbildung ist, was unter anderem in der Quantenmechanik fundamental ist.

Manchmal, zum Beispiel in der Signaltheorie, bevorzugt man die – ebenfalls energieerhaltende – Version der Fourier-Transformation, bei der die – auch "Spektralfunktion" genannte – Fourier-Transformierte von der Frequenz statt der Winkelgeschwindigkeit abhängt:
Die Beziehung zwischen beiden Arten der Fourier-Transformation wird durch formula_32 vermittelt.

Die Rücktransformation lautet dann
Da hier über die Variable formula_34 statt formula_35 integriert wird, entfällt in dieser Darstellungsform der Vorfaktor.

Es gibt keine Einschränkungen in der Anwendung der Transformation und der Entwicklungsformel. Sind formula_36 positive Zahlen mit formula_37, und sind formula_38 beliebige ganzzahlige Verschiebungen, so kann eine allgemeinere Variante der Transformationsformeln angegeben werden. Mit formula_39 und formula_3 gilt
und

Zur Berechnung der diskreten Fourier-Transformation wird oft die schnelle Fourier-Transformation (FFT) verwendet, ein Algorithmus, bei dem die Anzahl der Rechenschritte zur Berechnung der Fourier-Koeffizienten wesentlich kleiner ist als bei einer direkten Implementation der Integration.

Alle Transformationen, die in der Fourier-Analysis betrachtet werden, haben die Eigenschaft, dass eine entsprechende inverse Transformation existiert. In den Ingenieurwissenschaften, der Physik und der numerischen Mathematik nennt man das Zerlegen einer Funktion in ihr Spektrum ebenfalls Fourier-Analyse. Der Begriff beschreibt also nicht nur dieses Teilgebiet der Funktionalanalysis, sondern auch den Prozess der Zerlegung einer Funktion. Das Darstellen der Ausgangsfunktion mit Hilfe des Spektrums aus der Fourier-Analyse wird als Fourier-Synthese bezeichnet. Da diese Begriffsbildung besonders in den angewandten Wissenschaften üblich ist, tritt diese auch eher im Zusammenhang mit der diskreten Fourier-Transformation und der schnellen Fourier-Transformation auf.

Die Fouriertransformation besitzt vor allem in den Ingenieurwissenschaften, wie der Signalverarbeitung und in der Physik, bedeutende Anwendungsbereiche. Dabei werden auch spezielle Begriffe und Nomenklaturen verwendet:




In technisch motivierten Anwendungen wird der Bezug zwischen dem Zeitbereich mit der Originalfunktion formula_5 und dem Frequenzbereich mit der Bildfunktion formula_44 auch mit folgender Symbolik dargestellt:

In der Physik stellt die Fouriertransformation in der Wellenmechanik die Verknüpfung zwischen Zeitbereich und Frequenzraum dar. Werden statt Zeitsignale Signale als Funktion des Ortes betrachtet, stellt die Fouriertransformation eine Verknüpfung zwischen dem Ortsraum und den im Frequenzraum vorhandenen Ortsfrequenzen bzw. Wellenzahlen dar. In mehreren Dimensionen werden die Wellenzahlen in Form von Wellenvektoren beschrieben. In der Kristallographie heißt der zum Ortsraum reziproke Frequenzraum reziproker Raum.

In der Quantenmechanik entsprechen, bis auf einen Proportionalitätsfaktor, die Wellenzahlen dem Impuls des Teilchens, woraus sich ein Zusammenhang mit der Heisenbergsche Unschärferelation ergibt. Da Orts- und Impulsraum durch die Fouriertransformation verknüpft sind, führt die Verknüpfung der Ausdehnungen zu einer Unschärfe. Analog ergibt sich auch die Energie-Zeit-Unschärfe aus der Fouriertransformation, wobei hier die Frequenz bis auf den Proportionalitätsfaktor der Energie entspricht und somit eine Verknüpfung von Energie und Zeit durch die Fouriertransformation gegeben ist, die zu einer Unschärfe führt.

Schon ab 1740 diskutierten Mathematiker wie Bernoulli und d’Alembert die Möglichkeit, periodische Funktionen als trigonometrische Reihen darzustellen. Die heute bekannte Reihenentwicklung für periodische Funktionen geht auf den französischen Mathematiker Fourier zurück. Zu Beginn des 19. Jahrhunderts veröffentlichte er sein Werk "Théorie analytique de la chaleur", in dem er davon ausgeht, dass jede Funktion in eine trigonometrische Reihe entwickelt werden könne. Er benutzte diese Reihen insbesondere zum Lösen der Wärmeleitungsgleichung. In diesem Werk führte er auch die kontinuierliche Fourier-Transformation in Form einer Kosinus-Transformation ein. Mit dieser versuchte er die Wärmeleitungsgleichung auf unbeschränkten Mengen insbesondere auf der reellen Achse zu lösen.

Peter Gustav Lejeune Dirichlet untersuchte diese trigonometrischen Reihen, die heute Fourier-Reihen heißen, weiter und konnte erste Konvergenzeigenschaften beweisen. So konnte er 1829 zeigen, dass die Fourier-Reihe punktweise konvergiert, wenn die Ausgangsfunktion lipschitz-stetig ist. Zur exakten Berechnung der Fourier-Koeffizienten führte Bernhard Riemann dann seinen Integralbegriff ein und entdeckte 1853 das Lokalisationsprinzip. Das besagt, dass die Konvergenz beziehungsweise Divergenz sowie gegebenenfalls der Wert der Fourier-Reihe einer Funktion formula_46 bei formula_47 durch das Verhalten von formula_46 in einer beliebig kleinen Umgebung von formula_47 eindeutig bestimmt ist.

Erst 1876 fand Paul Du Bois-Reymond eine stetige Funktion, deren Fourier-Reihe nicht punktweise konvergiert. In seinem Satz konnte Fejér 1904 jedoch zeigen, dass die Fourier-Reihe für jede stetige Funktion im arithmetischen Mittel konvergiert. Im Jahr 1915 warf Nikolai Nikolajewitsch Lusin die Frage auf, ob die Fourier-Reihe für jede Funktion formula_50 konvergiert. Dies konnte erst 1968 von Lennart Carleson positiv beantwortet werden und Hunt verallgemeinerte 1968 das Ergebnis auf Funktionen formula_51 mit formula_52. Die Voraussetzung formula_52 ist allerdings wesentlich, wie das Beispiel einer integrierbaren Funktion mit überall divergenter Fourier-Reihe, das Kolmogorow 1926 fand, zeigt.

Da die Fourier-Transformation auch außerhalb der Mathematik einen großen Anwendungsbereich hat, ist man an einem Algorithmus interessiert, mit dem ein Computer die Fourier-Koeffizienten mit möglichst wenig Aufwand berechnen kann. Solche Verfahren nennt man Schnelle Fourier-Transformation. Der bekannteste Algorithmus stammt von James Cooley und John W. Tukey, die ihn 1965 veröffentlichten. Jedoch wurde ein Algorithmus schon 1805 von Carl Friedrich Gauß entwickelt. Er benutzte ihn zur Berechnung der Flugbahnen der Asteroiden (2) Pallas und (3) Juno. Zum ersten Male wurde eine Variante des Algorithmus von Carl Runge im Jahre 1903 beziehungsweise 1905 veröffentlicht. Darüber hinaus wurden vor Cooley und Tukey schon eingeschränkte Varianten der schnellen Fourier-Transformation veröffentlicht. So hat zum Beispiel Irving John Good 1960 ebenfalls einen solchen Algorithmus veröffentlicht.

Wir betrachten stetige, von der Zeit "t" reell abhängige Funktionen bzw. Vorgänge (z. B. als vektorwertige Funktionen) "f(t)", die sich nach einer Zeit formula_54 wiederholen, also periodisch mit Periode "T" sind, "f(t+T)=f(t)".
Joseph Fourier postulierte in seiner Arbeit, dass sich "f" aus periodischen, harmonischen Schwingungen, also Sinus- oder Kosinusfunktionen, verschiedener Phase und Amplitude und genau definierter Frequenz zusammensetzen lässt. Betrachten wir eine solche zusammengesetzte Funktion mit "(N+1)" Summanden:

Die einzelnen Schwingungen haben die Kreisfrequenz formula_56, also die Frequenz formula_57. Damit hat die erste Schwingung (Grundschwingung) die Frequenz formula_58, die nächsten formula_59, formula_60, …

Weil ein Sinus nur ein phasenverschobener Kosinus ist, konnte die Reihendarstellung auf Kosinus-Funktionen beschränkt werden. Wir erhalten sofort auch die Sinusterme, wenn wir die Additionstheoreme benutzen:

Zusammen mit formula_62 erhalten wir eine phasenfreie Darstellung

Im nächsten Schritt soll die Summe mit Hilfe komplexer Zahlen umgeschrieben werden. Es sind dann komplexe Koeffizienten erlaubt, und die Reihe wird komplexwertig. Sofern reelle Funktionen betrachtet werden, kann diese als Realteil der Summe zurückgewonnen werden. Aus der Euler-Formel oder auch nach der Definition der trigonometrischen Funktionen mit der Exponentialfunktion folgt

somit

Mit den komplexen Koeffizienten formula_67, formula_68 und formula_69 für "n>0" erhalten wir eine Summe mit auch negativen Indizes

Wir kennen jetzt also die trigonometrische Summe in verschiedenen Darstellungen. Es war aber gefragt, eine periodische stetige Funktion mittels solch einer Summe zu approximieren. Dazu stellen wir fest, dass die komplexen Koeffizienten formula_71, und damit auch die der anderen Darstellungen, sich aus der Summenfunktion zurückgewinnen lassen.

Dazu wird die obige Gleichung mit formula_72 multipliziert und sodann auf beiden Seiten über dem Intervall formula_1, d. h. über eine Periode integriert. Mit Umformungen erreicht man folgende Aussage:
Daraus folgt

Für das formula_11-te Integral auf der rechten Seite gilt:

Es liefert also nur der Summand für n=0 einen Beitrag, es vereinfacht sich das Integral also zu

Wir können nun versuchen, die trigonometrische Summe durch eine beliebige stetige periodische Funktion "f" zu ersetzen, die Koeffizienten nach obigen Formeln zu bestimmen und die mit diesen Koeffizienten gebildeten trigonometrischen Summen mit der
Ausgangsfunktion vergleichen:

Mit dem Dirichlet-Kern

Voraussetzung für die hergeleitete Fourier-Reihe ist die Periodizität von formula_82 über dem Zeitintervall formula_54. Selbstverständlich gibt es auch nichtperiodische Funktionen, die diese Voraussetzung für kein endliches Zeitintervall erfüllen.
Wie schon gezeigt, hat die formula_11-te Oberschwingung die Frequenz formula_85.
Die Differenz der formula_11-ten Oberfrequenz von der vorherigen ist formula_87, das heißt, die Oberfrequenzen haben den Abstand formula_58. Für formula_54 gegen unendlich geht ihr Abstand gegen Null – die Summe wird im Grenzfall zum Riemann-Integral.

Das Fourier-Integral, die kontinuierliche Fourier-Transformation, ist also gegeben durch

mit

Aus der Folge formula_92 ist nun das kontinuierliche Spektrum formula_93 geworden. Man bezeichnet genau genommen die zweite Transformation als Fourier-Transformation, die erste, deren inverse, ist die Fourier-Synthese.

Die zweite Gleichung kann analog wie für die Reihe hergeleitet werden.

Das angegebene Beziehungspaar gilt u. a. erneut für quadratintegrierbare Funktionen.

Die Fourier-Transformation wird oft eingesetzt, um Differentialgleichungen zu lösen. Denn die formula_94 bzw. die formula_95 sind Eigenfunktionen der Differentiation, und die Transformation wandelt lineare Differentialgleichungen mit konstanten Koeffizienten in normale algebraische Gleichungen um.

So ist zum Beispiel in einem linearen zeitinvarianten physikalischen System die Frequenz eine Erhaltungsgröße, und das Verhalten kann für jede Frequenz einzeln gelöst werden. Die Anwendung der Fourier-Transformation auf die Differentialgleichung ergibt den Frequenzgang des Systems.

Die abstrakte harmonische Analyse ist die Weiterentwicklung der Fourier-Analysis auf lokalkompakte topologische Gruppen. Auf diesen Gruppen kann man mit Hilfe des Haar-Maßes, das das Lebesgue-Maß als Spezialfall umfasst, ein Integral definieren. Zentral in der abstrakten harmonischen Analyse ist der Begriff der Charakters, der von Lew Semjonowitsch Pontrjagin eingeführt wurde. Das ist ein stetiger Gruppenhomomorphismus formula_96 von der lokalkompakten, abelschen Gruppe formula_97 in die Sphäre. In Analogie zu linearen Funktionalen und den Dualräumen bilden ihre Gesamtheit die Dualgruppe formula_98. Der Begriff Dualgruppe wird durch den Dualitätssatz von Pontrjagin gerechtfertigt. Aus Sicht der abstrakten harmonischen Analyse versteht man dann unter der Abbildung
die Fourier-Transformation. Wählt man formula_100 und formula_101 so ist formula_102 und man erhält die klassische kontinuierliche Fourier-Transformation. In der abstrakten harmonischen Analyse gibt es genauso wie in der klassischen Fourier-Analysis für diese Transformation auch eine Rücktransformation. Außerdem umfasst diese abstrakte Fourier-Transformation auch die Fourier-Reihe sowie die Laplace-Transformation, die Mellin-Transformation und andere Transformationen als Spezialfälle.





</doc>
<doc id="1653" url="https://de.wikipedia.org/wiki?curid=1653" title="Funktion (Mathematik)">
Funktion (Mathematik)

In der Mathematik ist eine Funktion () oder Abbildung eine Beziehung (Relation) zwischen zwei Mengen, die jedem Element der einen Menge (Funktionsargument, unabhängige Variable, formula_1-Wert) genau ein Element der anderen Menge (Funktionswert, abhängige Variable, formula_2-Wert) zuordnet. Der Funktionsbegriff wird in der Literatur unterschiedlich definiert, jedoch geht man generell von der Vorstellung aus, dass Funktionen mathematischen Objekten mathematische Objekte zuordnen, zum Beispiel jeder reellen Zahl deren Quadrat. Das Konzept der Funktion oder Abbildung nimmt in der modernen Mathematik eine zentrale Stellung ein; es enthält als Spezialfälle unter anderem parametrische Kurven, Skalar- und Vektorfelder, Transformationen, Operationen, Operatoren und vieles mehr.

Erste Ansätze zu einer impliziten Verwendung des Funktionsbegriffs in Tabellenform (Schattenlänge abhängig von der Tageszeit, Sehnenlängen abhängig vom Zentriwinkel etc) sind bereits in der Antike zu erkennen. Den ersten Beleg einer expliziten Definition des Funktionsbegriffs findet man bei Nikolaus von Oresme, der im 14. Jahrhundert Abhängigkeiten sich ändernder Größen (Wärme, Bewegung etc) graphisch durch senkrecht aufeinander stehende Strecken (longitudo, latitudo) darstellte. Am Beginn des Prozesses zur Entwicklung des Funktionsbegriffs stehen Descartes und Fermat, die mit Hilfe der von Vieta eingeführten Variablen die analytische Methode der Einführung von Funktionen entwickelten. Funktionale Abhängigkeiten sollten durch Gleichungen wie zum Beispiel formula_3 dargestellt werden. In der Schulmathematik wurde dieser naive Funktionsbegriff bis weit in die zweite Hälfte des 20. Jahrhunderts beibehalten. Die erste Umschreibung des Funktionsbegriffs nach dieser Idee stammt von Gregory in seinem 1667 erschienenen Buch "Vera circuli et hyperbolae quadratura." Der Begriff "Funktion" kommt wohl erstmals 1673 in einem Manuskript von Leibniz auf, der in seiner Abhandlung von 1692 "De linea ex lineis numero infinitis ordinatim ductis" auch die Begriffe „Konstante“, „Variable“, „Ordinate“ und „Abszisse“ benutzt. Im Schriftwechsel zwischen Leibniz und Johann Bernoulli wird der Funktionsbegriff von der Geometrie losgelöst und in die Algebra übertragen. In Beiträgen von 1706, 1708 und 1718 stellt Bernoulli diese Entwicklung dar. 1748 präzisiert Euler, ein Schüler Johann Bernoullis, in seinem Buch "Introductio in analysin infinitorum" den Funktionsbegriff weiter.

Bei Euler findet man zwei verschiedene Erklärungen des Funktionsbegriffs: Zum einen stellt jeder „analytische Ausdruck“ in formula_1 eine Funktion dar, zum anderen wird formula_5 im Koordinatensystem durch eine freihändig gezeichnete Kurve definiert. 1755 formuliert er diese Vorstellungen ohne Verwendung des Terminus „analytischer Ausdruck“ um. Außerdem führte er bereits 1734 die Schreibweise formula_6 ein. Er unterscheidet zwischen eindeutigen und mehrdeutigen Funktionen. Bei Euler ist damit auch die Umkehrung der Normalparabel, bei der jeder nicht-negativen reellen Zahl sowohl ihre positive als auch ihre negative Wurzel zugeordnet wird, als Funktion zugelassen. Für Lagrange sind nur Funktionen zulässig, die durch Potenzreihen definiert sind, wie er 1797 in seiner "Théorie des fonctions analytiques" festlegt. Eine fruchtbare Auseinandersetzung über das Bewegungsgesetz einer schwingenden Saite, zu dem d’Alembert 1747, Euler 1748 und Daniel Bernoulli 1753 unterschiedliche Lösungen vorstellten, führte zur Entdeckung der "Definitionsmenge" und einem weiter präzisierten Funktionsbegriff, in dem schon so etwas wie eindeutige Zuordnung umschrieben wird, durch Fourier in seinem 1822 erschienenen Buch "Théorie analytique de la chaleur." Ähnliches formuliert Cauchy 1823 in "Résumé des leçons … sur le calcul infinitésimal."

Als die Analysis im 19. Jahrhundert mit einem exakten Grenzwertbegriff auf eine neue Grundlage gestellt wurde, wurden Eigenschaften, die bisher als für Funktionen konstituierend aufgefasst wurden, in einem Exaktifizierungsprozess als selbständige Begriffe eingeführt und vom Funktionsbegriffs losgelöst. Dirichlet, ein Schüler Fouriers, formulierte diese neue Sicht: „Ideen an die Stelle von Rechnungen“ und stellte 1837 seine Ideen dar. Stokes führte in Arbeiten 1848 und 1849 ähnliche Ansichten aus. So verfuhr Riemann, Schüler von Dirichlet, 1851 in "Grundlagen für eine allgemeine Theorie der Functionen einer veränderlichen complexen Größe" mit der Stetigkeit, später folgten Integrierbarkeit und Differenzierbarkeit. Eine Zusammenfassung dieser Entwicklung macht Hankel 1870 in "Untersuchungen über die unendlich oft oscillierenden und unstetigen Functionen." Auch hier wird noch nicht zwischen der Funktion formula_7 und dem Funktionswert formula_6 an der Stelle formula_1 unterschieden.

Weierstraß, Dedekind und andere entdeckten, dass Grenzwerte unendlicher Folgen „klassischer“ Funktionen sprunghaft sein können und sich nicht immer durch „geschlossene“ Formeln, d. h. mit endlich vielen Rechenoperationen, ausdrücken lassen. Das erzwang eine schrittweise Ausweitung des Funktionsbegriffs.

Davon unabhängig wurde im 19. Jahrhundert die Gruppentheorie begründet, mit der man systematisch untersuchen kann, wie sich algebraische Gleichungen unter der Wirkung aufeinanderfolgender Transformationen verändern. Bei der Anwendung dieser Theorie auf geometrische Probleme wurden gleichbedeutend mit "Transformation" auch die Begriffe "Bewegung" und "Abbildung" gebraucht.

Als Anfang des 20. Jahrhunderts die Grundlagen der Mathematik einheitlich in der Sprache der Mengenlehre formuliert wurden, stellten sich die mathematischen Begriffe "Funktion" und "Abbildung" als deckungsgleich heraus. Im Sprachgebrauch wirken die unterschiedlichen Traditionen jedoch fort. In der Analysis spricht man heute häufig noch von Funktionen, während man in der Algebra und in der Geometrie von Abbildungen spricht. Einige Mathematiker unterscheiden auch heute noch streng zwischen einer Abbildung und einer Funktion. Diese verstehen unter einer Funktion eine Abbildung in den reellen oder komplexen Zahlenkörper (formula_10 bzw. formula_11) oder auch Potenzen davon (formula_12 bzw. formula_13), andererseits ist es in der Booleschen Algebra gebräuchlich, von Booleschen Funktionen zu sprechen.

Weitere Synonyme für "Funktion" in spezielleren Zusammenhängen sind unter anderem Operator in der Analysis, Operation, Verknüpfung und (etwas verallgemeinert) Morphismus in der Algebra.

Heute sehen manche Autoren den Funktionsbegriff (genauso wie den Relationsbegriff) nicht unbedingt als auf Mengen beschränkt an, sondern lassen jede aus geordneten Paaren bestehende Klasse, die keine verschiedenen Elemente mit gleicher linker Komponente enthält, als Funktion gelten. Mengentheoretisch ausgedrückt werden Funktionen also als "rechtseindeutige Relationen" definiert.

Eine Funktion formula_7 ordnet "jedem" Element formula_1 einer Definitionsmenge formula_16 "genau ein" Element formula_2 einer Zielmenge formula_18 zu.

Schreibweise:

Für das dem Element formula_21 zugeordnete Element der Zielmenge schreibt man im Allgemeinen formula_6.

Anmerkungen:

Mengentheoretisch ist eine Funktion eine spezielle Relation:

Die letzten beiden Eigenschaften lassen sich auch wie folgt zusammenfassen:

Oft möchte man aber auch die Zielmenge explizit zu einem Teil der Funktion machen, zum Beispiel um Aussagen zur Surjektivität (als eine Eigenschaft der betrachten Funktion selbst) anstellen zu können:

formula_70 wird dann auch der Graph der Funktion formula_7 genannt. Die Definitionsmenge formula_16 der Funktion ist dabei durch ihren Graphen eindeutig bestimmt und besteht aus den ersten Komponenten aller Elemente des Graphen. Stimmen zwei Funktionen in ihren Graphen überein, so sagt man auch, sie seien im Wesentlichen gleich. Insbesondere ist jede Funktion formula_74 im Wesentlichen gleich mit der surjektiven Funktion formula_75 mit der Bildmenge formula_76.

Oft empfiehlt es sich auch noch die Definitionsmenge hinzunehmen und eine Funktion entsprechend als ein Tripel formula_77 zu definieren. Diese Definition stimmt dann überein mit der entsprechenden ausführlichen Definition bei Relationen, so dass auch Multifunktionen und partielle Funktionen auf gleiche Weise erfasst sind.

Eine Zuordnung kann unter anderem in einer der folgenden Formen beschrieben werden:



Für die Zuordnung eines Funktionswertes formula_2 zu einem Argument formula_1 gibt es eine Reihe verschiedener Sprech- oder ausführlicher Schreibweisen, die alle mehr oder weniger gleichwertig sind und vor allem in Abhängigkeit von dem, was vordergründig ausgedrückt werden soll, vom jeweiligen Kontext, der benutzten Symbolik und auch vom Geschmack des Sprechers (Schreibers) gewählt werden. Hier einige Beispiele:

Davon zu unterscheiden ist die Sprech- und Schreibweise: "„formula_2 ist eine Funktion von formula_1“," die vor allem in der Physik sehr nahestehenden Bereichen der Mathematik auftaucht. Sie ist die ältere und ursprüngliche Sprech- und Schreibweise und beschreibt die Abhängigkeit einer Variablen formula_2 von einer anderen Variablen formula_1, im Gegensatz dazu, dass mit Hilfe der Variablen formula_1 und formula_2 (stellvertretend) die Zuordnung bestimmter Elemente von Mengen beschrieben wird. Die "„physikalische“" Sprechweise stammt von dem Vorgehen, zunächst zwei veränderlichen Größen (der physikalischen Realität) Symbole, nämlich die Variablen formula_1 und formula_2, zuzuordnen und "danach" deren Abhängigkeit festzustellen. Steht beispielsweise formula_2 für die Raumtemperatur und formula_1 für die Zeit, so wird man feststellen können, dass sich die Raumtemperatur in Abhängigkeit von der Zeit ändert und somit "„die Raumtemperatur eine Funktion der Zeit ist“" oder stellvertretend "„formula_2 eine Funktion von formula_1 ist.“"

Statt "Definitionsmenge" formula_16 wird auch "Definitionsbereich, Urbildmenge" oder schlicht "Urbild" gesagt. Die Elemente von formula_16 heißen "Funktionsargumente, Funktionsstellen" oder "Urbilder," salopp auch "formula_1-Werte." Die Zielmenge formula_18 wird auch "Wertemenge" oder "Wertebereich" genannt, die Elemente von formula_18 heißen "Zielwerte" oder "Zielelemente," salopp auch "formula_2-Werte." Diejenigen Elemente von formula_18, die tatsächlich auch als Bild eines Arguments auftreten, heißen "Funktionswerte, Bildelemente" oder schlicht "Bilder."

Eine Funktion formula_119, kann man visualisieren, indem man ihren Graphen in ein (zweidimensionales) Koordinatensystem zeichnet. Der Funktionsgraph einer Funktion formula_7 kann mathematisch definiert werden als die Menge aller Elementepaare formula_121, für die formula_122 ist. Der Graph einer stetigen Funktion auf einem zusammenhängenden Intervall bildet eine zusammenhängende Kurve (genauer: die Menge der Punkte der Kurve, aufgefasst als Unterraum des topologischen Raumes formula_123 ist zusammenhängend).

Analog kann man Funktionen formula_124, und formula_125, visualisieren, indem man sie in ein dreidimensionales Koordinatensystem zeichnet. Ist formula_7 stetig, so ergibt sich eine Kurve (die auch Ecken haben kann), die sich durch das Koordinatensystem „schlängelt“. Ist formula_127 stetig, so ergibt sich eine Fläche als Bild, typischerweise in Form einer „Gebirgslandschaft“.

Computerprogramme zur Darstellung von Funktionen heißen Funktionenplotter. Funktionsprogramme gehören auch zum Funktionsumfang von Computeralgebrasystemen (CAS), matrizenfähigen Programmierumgebungen wie MATLAB, Scilab, GNU Octave und anderen Systemen. Die wesentlichen Fähigkeiten eines Funktionenplotters sind auch auf einem graphikfähigen Taschenrechner verfügbar. Es gibt auch Web-gestützte Angebote, die nur einen aktuellen Browser benötigen.

Das Bild eines Elements formula_1 der Definitionsmenge ist einfach der Funktionswert formula_6. Das Bild einer Funktion ist die Menge der Bilder aller Elemente der Definitionsmenge formula_16, also

Das Bild einer Funktion ist folglich eine Teilmenge der Zielmenge und wird Bildmenge genannt. Ist allgemeiner formula_132 eine Teilmenge von formula_16, dann ist

das Bild von formula_132 unter der Funktion formula_7.

Das Urbild eines Elements formula_2 der Zielmenge formula_18 ist die Menge aller Elemente der Definitionsmenge, deren Bild formula_2 ist. Es ist

(formula_141 ist im Allgemeinen keine eindeutige Funktion ist, sondern eine Multifunktion, zu Schreibweise formula_142 siehe dort, sowie bei Relation §Relationen und Funktionen und Korrespondenz (Mathematik)).

Oft werden diese "Fasern" einfach mit formula_143 bezeichnet, was aber im Fall (eindeutig) umkehrbarer Funktionen einerseits "x", andererseits {"x"} bezeichnet.

Das Urbild einer Teilmenge formula_144 der Zielmenge ist die Menge aller Elemente der Definitionsmenge, deren Bild Element dieser Teilmenge ist:


Eine Funktion formula_151, deren Definitionsmenge formula_16 eine Produktmenge formula_153 ist, heißt oft "zweistellig." Den Wert von formula_7, der bei Anwendung von formula_7 auf das Paar formula_156 erhalten wird, bezeichnet man mit formula_157.

Analoges gilt für höhere Stelligkeiten. Eine Funktion formula_158 bezeichnet man üblicherweise als "dreistellig." Eine Funktion, deren Definitionsmenge keine Produktmenge ist (oder bei der die innere Struktur der Definitionsmenge keine Rolle spielt) bezeichnet man als "einstellig." Unter einer nullstelligen Funktion versteht man eine Funktion, deren Definitionsmenge das leere Produkt formula_159 ist, bei einem beliebigen Funktionswert. Daher können nullstellige Funktionen als Konstanten aufgefasst werden, was bei algebraischen Strukturen (wie auch bei heterogenen Algebren) Anwendung findet.

Statt nullstellig, einstellig, zweistellig, dreistellig sagt man auch oft unär, binär, ternär; Stelligkeit wird daher auch als „Arität“ (englisch: arity) bezeichnet.

Mit formula_160 oder formula_161 wird die Menge aller Abbildungen von formula_16 nach formula_18 bezeichnet:
Für die Mächtigkeit gilt:

Die Einschränkung einer Funktion formula_166 auf eine Teilmenge formula_167 der Definitionsmenge formula_168 ist die Funktion formula_169, deren Graph durch

gegeben ist.

Zu jeder bijektiven Funktion formula_166 gibt es eine Umkehrfunktion

sodass formula_143 das eindeutig bestimmte Element formula_174 ist, für das formula_68 gilt. Die Umkehrfunktion erfüllt damit für alle formula_174

Bijektive Funktionen werden daher auch als eindeutig umkehrbare Funktionen bezeichnet.

Zwei Funktionen formula_166 und formula_179, bei denen der Wertebereich der ersten Funktion mit dem Definitionsbereich der zweiten Funktion übereinstimmt (oder als Teilmenge enthalten ist), können verkettet werden. Die Verkettung oder Hintereinanderausführung dieser beiden Funktionen ist dann eine neue Funktion, die durch

gegeben ist. In dieser Notation steht meist die zuerst angewandte Abbildung rechts, das heißt bei formula_181 wird zuerst die Funktion formula_7 angewandt und dann die Funktion formula_127. Gelegentlich wird in der Literatur allerdings auch die umgekehrte Reihung verwendet und formula_184 geschrieben.

Ist auf der Zielmenge formula_185 eine innere zweistellige Verknüpfung formula_186 gegeben, so lässt sich auch für Funktionen formula_187 eine innere zweistellige Verknüpfung definieren:

Beispiele hierfür sind die punktweise Addition und Multiplikation von Funktionen. Weiter lässt sich mit Hilfe einer äußeren zweistelligen Verknüpfung der Form formula_189 auch die Verknüpfung einer Funktion mit einem Element aus formula_167 definieren:

Beispiel hierfür ist die punktweise Multiplikation einer Funktion mit einem Skalar. Analog lässt sich so auch eine äußere Verknüpfung der Form formula_192 definieren. Sind Verknüpfungen der gleichen Art sowohl auf der Definitionsmenge, als auch auf der Zielmenge gegeben, dann heißt eine Funktion verträglich mit diesen Verknüpfungen, wenn sich die Bilder bezüglich der einen Verknüpfung genauso verhalten wie die Urbilder bezüglich der anderen Verknüpfung.




Ein fundamentales Konzept in der Mathematik stellen Strukturen dar, die dadurch entstehen, dass Mengen in Verbindung mit dazugehörigen Abbildungen gesehen werden. Derartige Strukturen bilden die Grundlage praktisch aller mathematischen Disziplinen, sobald sie über elementare Mengenlehre, kombinatorische Probleme oder grundlegende mathematisch-philosophische Fragestellungen hinausgehen.

Mengen können beispielsweise durch sogenannte Verknüpfungen strukturiert werden. Der wichtigste Spezialfall ist die innere zweistellige Verknüpfung, dabei handelt es sich um eine Abbildung der Form formula_210. Beispiele für innere zweistellige Verknüpfungen sind Rechenoperationen, wie die Addition oder Multiplikation auf Zahlenmengen. Dementsprechend wird das Bild formula_211 eines Paares formula_42 unter einer Verknüpfung formula_213 üblicherweise in der Form formula_214 geschrieben.

Weitere wichtige Beispiele solcher Strukturen sind algebraische, geometrische und topologische Strukturen, wie beispielsweise Skalarprodukte, Normen und Metriken.

Eine Multifunktion (auch mehrwertige Funktion oder Korrespondenz genannt) ist eine linkstotale Relation. Das heißt, die Elemente der Definitionsmenge formula_215 können auf mehrere Elemente der Zielmenge formula_216 abgebildet werden. Man schreibt auch formula_217.

Wenn formula_216 eine Menge ist, dann kann man jede Multifunktion formula_217 auch als eine Funktion formula_220 darstellen, die in die Potenzmenge von formula_216 geht: formula_222. 

Im Fall formula_223 stellt eine mehrwertige Funktion formula_7 eine Transitionsrelation dar, und formula_220 ist die zugehörige Transitionsfunktion.

Die Verkettung von Multifunktionen lässt sich genauso definieren wie für (eindeutige) Funktionen, mengentheoretisch ist dies äquivalent einer Verkettung zweier zweistelliger Relationen.

Ein Beispiel für Multifunktionen sind die Umkehrfunktionen (Umkehrungen) von nicht injektiven Funktionen. Wenn formula_226 surjektiv ist, gilt automatisch: formula_227 ist eine Multifunktion. Die Darstellung der Umkehrfunktion in die Potenzmenge von formula_215 liefert mit formula_229 die Fasern von formula_7 (siehe oben). 

Die Verkettung einer Funktion mit ihrer (allgemein nicht eindeutigen) Umkehrung in der Form formula_231 ist eine Äquivalenzrelation, die durch formula_7 "induzierte Äquivalenzrelation". Zwei Elemente aus dem Definitionsbereich sind genau dann äquivalent, wenn sie denselben Funktionswert haben.

Wohl zu unterscheiden vom Begriff der Funktion ist der Begriff der partiellen Funktion, man spricht auch von einer „nicht überall definierten Funktion“ oder „funktionalen Relation“. Hier darf es Elemente der Quellmenge (formula_1-Werte) geben, denen kein Wert der Zielmenge (formula_2-Wert) zugeordnet ist. Hier ist dann die Nennung der Quellmenge in der obigen Tripelschreibweise tatsächlich notwendig. Allerdings darf es auch dort für einen formula_1-Wert nicht mehr als einen formula_2-Wert geben. Um partielle Funktionen von Funktionen zu unterscheiden, bezeichnet man Letztere auch als totale oder überall definierte Funktionen.

Die Menge formula_237 der partiellen Abbildungen von formula_16 nach formula_18 ist die Vereinigung der totalen Abbildungen von Teilmengen von formula_16 nach formula_18:
Sind die Mengen endlich, so gilt für Ihre Kardinalzahlen
schließlich kann man jede partielle Abbildung auf D umkehrbar eindeutig zu einer totalen Abbildung fortsetzen, indem man einen beliebigen festen Funktionswert formula_244 festschreibt, der nicht in formula_18 enthalten ist; und diese Operation stellt eine bijektive Abbildung auf formula_246 dar.

Jede partielle Funktion formula_247 ist im Wesentlichen gleich mit der (totalen) Funktion formula_248 mit der Urbildmenge formula_249.

Häufig liegen die Werte einer Funktion nicht in einer Zielmenge, sondern lediglich in einer echten Klasse, beispielsweise sind Mengenfolgen „Funktionen“ mit Definitionsmenge formula_250 und Werten in der Allklasse. Um die mengentheoretischen Probleme, die sich daraus ergeben, zu vermeiden, betrachtet man nur noch den Graph der entsprechenden Funktion, genauer: Ein "funktionsartiger Graph" ist eine Menge formula_70 von Paaren formula_42, so dass keine zwei Paare im ersten Eintrag übereinstimmen:
Definitions- und Wertemenge sind tatsächlich Mengen, aber es ist nicht nötig, sich von vornherein auf eine Ziel"menge" festzulegen, solange die Funktionen im Wesentlichen gleich sind.

Bei partiellen Funktionen gilt gleiches für den Ziel- "und" Quellbereich. Beide können einzeln oder zusammen echte Klassen sein; mengentheoretische Probleme entstehen nicht, solange der Graph eine Menge bleibt.

Für Funktionen gibt es etliche symbolische Schreibweisen, die jeweils einige spezielle Eigenschaften der Funktion ausdrücken. Im Folgenden werden einige wichtige genannt.

Die Symbole können auch, wo sinnvoll, miteinander kombiniert werden.




</doc>
<doc id="1654" url="https://de.wikipedia.org/wiki?curid=1654" title="Beurteilung eines binären Klassifikators">
Beurteilung eines binären Klassifikators

Bei einer Klassifizierung werden Objekte anhand von bestimmten Merkmalen durch einen Klassifikator in verschiedene Klassen eingeordnet. Der Klassifikator macht dabei im Allgemeinen Fehler, ordnet also in manchen Fällen ein Objekt einer falschen Klasse zu. Aus der relativen Häufigkeit dieser Fehler lassen sich quantitative Maße zur Beurteilung eines Klassifikators ableiten.

Häufig ist die Klassifikation binärer Natur, d. h., es gibt nur zwei mögliche Klassen. Die hier diskutierten Gütemaße beziehen sich ausschließlich auf diesen Fall. Solche binäre Klassifikationen werden häufig in Form einer Ja/Nein-Frage formuliert: Leidet ein Patient an einer bestimmten Krankheit oder nicht? Ist ein Feuer ausgebrochen oder nicht? Nähert sich ein feindliches Flugzeug oder nicht? Bei Klassifikationen dieser Art gibt es zwei mögliche Arten von Fehlern: Ein Objekt wird der ersten Klasse zugeordnet, obwohl es der zweiten angehört, oder umgekehrt. Die hier beschriebenen Kennwerte bieten dann eine Möglichkeit, die Zuverlässigkeit des zugehörigen Klassifikators (Diagnoseverfahren, Feuermelder, Fliegerradar) zu beurteilen.

Ja-Nein-Klassifikationen weisen Ähnlichkeiten zu statistischen Tests auf, bei denen zwischen einer Nullhypothese und einer Alternativhypothese entschieden wird.

Um einen Klassifikator zu bewerten, muss man ihn in einer Reihe von Fällen anwenden, bei denen man zumindest im Nachhinein Kenntnis über die „wahre“ Klasse der jeweiligen Objekte hat. Ein Beispiel für so einen Fall ist ein medizinischer Labortest, mit dem festgestellt werden soll, ob eine Person eine bestimmte Krankheit hat. Später wird durch aufwändigere Untersuchungen festgestellt, ob die Person tatsächlich an dieser Krankheit leidet. Der Test stellt einen Klassifikator dar, der die Personen in die Kategorien „krank“ und „gesund“ einordnet. Da es sich um eine Ja/Nein-Frage handelt, sagt man auch, der Test fällt "positiv" (Einordnung „krank“) oder "negativ" (Einordnung „gesund“) aus. Um zu beurteilen, wie gut geeignet der Labortest für die Diagnose der Krankheit ist, wird nun bei jedem Patienten dessen tatsächlicher Gesundheitszustand mit dem Ergebnis des Tests verglichen. Dabei können vier mögliche Fälle auftreten:

Im ersten und letzten Fall war die Diagnose also richtig, in den anderen beiden Fällen liegt ein Fehler vor. Die vier Fälle werden in verschiedenen Kontexten auch anders benannt. So sind auch die englischen Begriffe "true positive", "false positive", "false negative" und "true negative" gebräuchlich. Im Rahmen der Signalentdeckungstheorie werden richtig positive Fälle auch als "hit", falsch negative Fälle als "miss" und richtig negative Fälle als "correct rejection" bezeichnet.

Es wird nun gezählt, wie häufig jede der vier möglichen Kombinationen von Testergebnis (ermittelte Klasse) und Gesundheitszustand (tatsächliche Klasse) vorgekommen ist. Diese Häufigkeiten werden in eine sogenannte "Wahrheitsmatrix" (auch Konfusionsmatrix genannt) eingetragen:
Diese Matrix ist ein einfacher Spezialfall einer Kontingenztafel mit zwei binären nominalen Variablen – dem Urteil des Klassifikators und der tatsächlichen Klasse. Sie kann auch für Klassifikationen mit mehr als zwei Klassen eingesetzt werden, dann wird bei N Klassen aus einer 2×2-Matrix eine N×N-Matrix.

Durch Berechnung verschiedener "relativer" Häufigkeiten können aus den Werten der Wahrheitsmatrix nun Kenngrößen zur Beurteilung des Klassifikators berechnet werden. Diese können auch als Schätzungen der bedingten Wahrscheinlichkeit für das Eintreten des entsprechenden Ereignisses interpretiert werden. Die Maße unterscheiden sich hinsichtlich der Grundgesamtheit, auf die sich die relativen Häufigkeiten beziehen: So können etwa nur alle die Fälle in Betracht gezogen werden, in denen die positive bzw. negative Kategorie "tatsächlich" vorliegt, oder man betrachtet die Menge aller Objekte, die als positiv bzw. negativ "klassifiziert" werden (Summe über die Einträge einer "Zeile" der Wahrheitsmatrix). Diese Wahl hat gravierende Auswirkungen auf die berechneten Werte, insbesondere dann, wenn eine der beiden Klassen insgesamt viel häufiger vorkommt als die andere.

Die Sensitivität (auch Richtig-positiv-Rate, Empfindlichkeit oder Trefferquote; englisch "sensitivity", "true positive rate", "recall" oder "hit rate") gibt den Anteil der korrekt als positiv klassifizierten Objekte an der Gesamtheit der tatsächlich positiven Objekte an. Beispielsweise entspricht Sensitivität bei einer medizinischen Diagnose dem Anteil an tatsächlich Kranken, bei denen die Krankheit auch erkannt wurde.

Die Sensitivität entspricht der geschätzten bedingten Wahrscheinlichkeit

Entsprechend gibt die Falsch-negativ-Rate (englisch "false negative rate" oder "miss rate") den Anteil der fälschlich als negativ klassifizierten Objekte an der Gesamtheit der tatsächlich positiven Objekte an. Also im Beispiel die tatsächlich Kranken, die aber als gesund diagnostiziert werden.

Die Falsch-negativ-Rate entspricht der geschätzten bedingten Wahrscheinlichkeit

Da sich beide Maße auf den Fall beziehen, dass in Wirklichkeit die positive Kategorie vorliegt (erste Spalte der Wahrheitsmatrix), addieren sich die Sensitivität und die Falsch-negativ-Rate zu 1 bzw. 100 %.

Die Spezifität (auch Richtig-negativ-Rate oder kennzeichnende Eigenschaft; englisch: "specificity", "true negative rate" oder "correct rejection rate") gibt den Anteil der korrekt als negativ klassifizierten Objekte an der Gesamtheit der in Wirklichkeit negativen Objekte an. Beispielsweise gibt die Spezifität bei einer medizinischen Diagnose den Anteil der Gesunden an, bei denen auch festgestellt wurde, dass keine Krankheit vorliegt.

Die Spezifität entspricht der geschätzten bedingten Wahrscheinlichkeit

Entsprechend gibt die Falsch-positiv-Rate (auch Ausfallrate; englisch "fallout" oder "false positive rate") den Anteil der fälschlich als positiv klassifizierten Objekte an, die in Wirklichkeit negativ sind. Im Beispiel würde dann ein tatsächlich Gesunder zu Unrecht als krank diagnostiziert. Es wird also die Wahrscheinlichkeit für einen Fehlalarm angegeben.

Die Falsch-positiv-Rate entspricht der geschätzten bedingten Wahrscheinlichkeit

Da sich beide Maße auf den Fall beziehen, dass in Wirklichkeit die negative Kategorie vorliegt (zweite Spalte der Wahrheitsmatrix), addieren sich die Spezifität und die Falsch-positiv-Rate zu 1 bzw. 100 %.

Während Sensitivität und Spezifität eines medizinischen Tests epidemiologisch und gesundheitspolitisch relevante Kenngrößen sind (beispielsweise bei der Frage, ob ein Einsatz im Screening zur Früherkennung von Krankheiten sinnvoll ist), ist im konkreten Fall für Patient und Arzt der Vorhersagewert entscheidend. Nur er beantwortet einem positiv/negativ Getesteten die Frage, mit welcher Wahrscheinlichkeit er denn nun wirklich krank/gesund ist.

Der positive Vorhersagewert (auch Relevanz, Wirksamkeit, Genauigkeit, positiver prädiktiver Wert; englisch: "precision" oder "positive predictive value"; Abkürzung: PPV) gibt den Anteil der korrekt als positiv klassifizierten Ergebnisse an der Gesamtheit der als positiv klassifizierten Ergebnisse an (erste Zeile der Wahrheitsmatrix). Beispielsweise gibt der positive Vorhersagewert eines medizinischen Tests an, welcher Anteil der Personen mit positivem Testergebnis auch tatsächlich krank ist.

Der positive Vorhersagewert entspricht der geschätzten bedingten Wahrscheinlichkeit

Entsprechend gibt der negative Vorhersagewert (auch Segreganz oder Trennfähigkeit; englisch: "negative predictive value"; Abkürzung: NPV) den Anteil der korrekt als negativ klassifizierten Ergebnisse an der Gesamtheit der als negativ klassifizierten Ergebnisse an (zweite Zeile der Wahrheitsmatrix). Im Beispiel entspricht das dem Anteil der Personen mit negativem Testergebnis, der auch tatsächlich gesund ist.

Der negative Vorhersagewert entspricht der geschätzten bedingten Wahrscheinlichkeit

Anders als die anderen Paare von Gütemaßen addieren sich der negative und der positive Vorhersagewert "nicht" zu 1 bzw. 100 %, da jeweils von unterschiedlichen Fällen ausgegangen wird (tatsächlich positiv bzw. tatsächlich negativ, d. h. unterschiedliche Spalten der Wahrheitsmatrix). Die Vorhersagewerte können aus Sensitivität formula_7 und Spezifität formula_8 berechnet werden, dazu muss aber die Prätestwahrscheinlichkeit formula_9 (entspricht bei Krankheiten der Prävalenz in der untersuchten Population) bekannt sein oder geschätzt werden. Der positive Vorhersagewert profitiert von einer hohen Prätestwahrscheinlichkeit, der negative Vorhersagewert von einer niedrigen Prätestwahrscheinlichkeit. Ein positives medizinisches Testergebnis hat also eine viel höhere Aussagekraft, wenn der Test auf Verdacht durchgeführt wurde, als wenn er allein dem Screening diente.

Die für ein Kollektiv ermittelten positiven und negativen Vorhersagewerte sind auf andere Kollektive nur dann übertragbar, wenn die relative Häufigkeit der positiven Fälle dort dieselbe ist. Beispiel: Wurden zur Bestimmung des positiven Vorhersagewerts 100 HIV-Patienten und 100 gesunde Kontrollpatienten untersucht, so ist der Anteil an HIV-Patienten in dieser Gruppe (50 %) weit von der HIV-Prävalenz in der BRD (0,08 %) entfernt (siehe dazu auch das unten genannte Zahlenbeispiel). Die Vorhersagewerte wären also völlig andere, wenn derselbe Test an einem zufällig ausgewählten Menschen durchgeführt wird. Ein Maß, das ohne die Prätestwahrscheinlichkeit auskommt, ist die likelihood ratio (LR) (nicht zu verwechseln mit dem Likelihood-Quotienten-Test):

Die "Korrektklassifikationsrate" (auch Vertrauenswahrscheinlichkeit oder Treffergenauigkeit; englisch: "accuracy") gibt den Anteil aller Objekte an, die korrekt klassifiziert werden. Der restliche Anteil entspricht der Falschklassifikationsrate (auch Größe des Klassifikationsfehlers). Im Beispiel der Diagnose wäre die Korrektklassifikationsrate der Anteil an richtig positiven und richtig negativen Diagnosen an der Gesamtzahl der Diagnosen, die Falschklassifikationsrate hingegen der Anteil der falsch positiven und falsch negativen Diagnosen.

Die Korrektklassifikationsrate entspricht der geschätzten Wahrscheinlichkeit

und die Falschklassifikationsrate der geschätzten Wahrscheinlichkeit

Die Korrekt- und die Falschklassifikationsrate addieren sich entsprechend zu 1 oder 100 %.
Da sich die verschiedenen Gütemaße gegenseitig beeinflussen (siehe Abschnitt Probleme), wurden verschiedene kombinierte Maße vorgeschlagen, die eine Beurteilung der Güte mit einer einzigen Kennzahl erlauben. Die im Folgenden vorgestellten Maße wurden im Kontext des Information Retrieval entwickelt (siehe Anwendung im Information Retrieval).

Das "F-Maß" kombiniert Genauigkeit (precision) und Trefferquote (recall) mittels des gewichteten harmonischen Mittels:

Neben diesem auch als formula_15 bezeichneten Maß, bei dem Genauigkeit und Trefferquote gleich gewichtet sind, gibt es auch andere Gewichtungen. Der Allgemeinfall ist das Maß formula_16 (für positive Werte von formula_17):

Beispielsweise gewichtet formula_19 die Trefferquote viermal so hoch wie die Genauigkeit und formula_20 die Genauigkeit viermal so hoch wie die Trefferquote.

Das "Effektivitätsmaß" formula_21 entspricht ebenfalls dem gewichteten harmonischen Mittel. Es wurde 1979 von van Rijsbergen eingeführt. Die Effektivität liegt zwischen 0 (beste Effektivität) und 1 (schlechte Effektivität). Für einen Parameterwert von formula_22 ist formula_21 äquivalent zur Trefferquote, für einen Parameterwert von formula_24 äquivalent zur Genauigkeit.

Es ist nicht möglich, alle Gütekriterien unabhängig voneinander zu optimieren. Insbesondere sind die Sensitivität und die Spezifität negativ miteinander korreliert. Zur Veranschaulichung dieser Zusammenhänge ist es hilfreich, die Extremfälle zu betrachten:


Wie konservativ oder liberal ein Klassifikator optimalerweise sein sollte, hängt vom konkreten Anwendungsfall ab. Aus diesem leitet sich beispielsweise ab, welche der Fehlklassifikationen die schwererwiegenden Folgen hat. Bei der Diagnose einer schlimmen Krankheit oder sicherheitsrelevanten Anwendungen wie einem Feueralarm ist es wichtig, dass kein Fall unentdeckt bleibt. Bei einer Recherche durch eine Suchmaschine hingegen kann es wichtiger sein, möglichst wenige Resultate zu bekommen, die für die Suche irrelevant sind, also falsch-positive Resultate darstellen. Die Risiken der verschiedenen Fehlklassifikationen lassen sich zur Bewertung eines Klassifikators in einer Kostenmatrix angeben, mit der die Wahrheitsmatrix gewichtet wird. Eine weitere Möglichkeit besteht in der Verwendung kombinierter Maße, bei denen sich eine entsprechende Gewichtung einstellen lässt.

Um die Auswirkungen verschieden konservativer Tests für ein konkretes Anwendungsbeispiel darzustellen, können Receiver-Operating-Characteristic-Kurven (ROC-Kurven) erstellt werden, in denen die Sensitivität für verschiedene Tests gegen die Falsch-positiv-Rate aufgetragen wird. Im Rahmen der Signalentdeckungstheorie spricht man auch von einem verschieden konservativ gesetzten "Kriterium".

Darüber hinaus wird auch ein extremes Ungleichgewicht zwischen tatsächlich positiv und negativen Fällen die Kenngrößen verfälschen, wie es etwa bei seltenen Krankheiten der Fall ist. Ist beispielsweise die Anzahl der an einem Test teilnehmenden Kranken erheblich geringer als die der Gesunden, so führt dies im Allgemeinen zu einem geringen Wert im positiven Vorhersagewert (siehe dazu das unten angeführte Zahlenbeispiel). Daher sollte in diesem Fall alternativ zu den Vorhersagewerten die likelihood ratio angegeben werden.

Dieser Zusammenhang ist bei verschiedenen Labortests zu bedenken: Preiswerte Screening-Tests werden so justiert, dass eine möglichst kleine Anzahl falsch negativer Ergebnisse vorliegt. Die produzierten falsch positiven Testergebnisse werden anschließend durch einen (teureren) Bestätigungstest identifiziert. Für schwerwiegende Erkrankungen sollte immer ein Bestätigungstest durchgeführt werden. Dieses Vorgehen ist für die Bestimmung von HIV sogar gefordert.

Ein weiteres Problem bei der Beurteilung eines Klassifikators besteht darin, dass häufig nicht die gesamte Wahrheitsmatrix ausgefüllt werden kann. Insbesondere ist oft die Falsch-negativ-Rate nicht bekannt, etwa wenn bei Patienten, die eine negative Diagnose erhalten, keine weiteren Tests durchgeführt werden und eine Krankheit unerkannt bleibt, oder wenn ein eigentlich relevantes Dokument bei einer Recherche nicht gefunden wird, weil es nicht als relevant klassifiziert wurde. In diesem Fall können nur die als positiv klassifizierten Ergebnisse ausgewertet werden, d. h. es kann nur der positive Vorhersagewert berechnet werden (siehe dazu auch das unten angeführte Zahlenbeispiel). Mögliche Lösungen für dieses Problem werden im Abschnitt Anwendung im Information Retrieval besprochen.

Mit Hilfe der Klassifikationsbewertung kann die Qualität eines statistischen Test beurteilt werden:


Man kann statistische Tests einsetzen, um zu überprüfen, ob eine Klassifikation statistisch signifikant ist, d. h., ob bzgl. der Grundgesamtheit die Einschätzung des Klassifikators unabhängig von den tatsächlichen Klassen ist (Nullhypothese) oder ob er signifikant mit ihnen korreliert (Alternativhypothese).

Im Fall von mehreren Klassen kann dafür der Chi-Quadrat-Unabhängigkeitstest verwendet werden. Dabei wird geprüft, ob die Einschätzung des Klassifikators unabhängig von den tatsächlichen Klassen ist oder signifikant mit ihnen korreliert. Die Stärke der Korrelation wird durch Kontingenzkoeffizienten abgeschätzt.

Im Fall einer binären Klassifikation wird der Vierfeldertest verwendet, ein Spezialfall des Chi-Quadrat-Unabhängigkeitstests. Hat man nur wenige Beobachtungswerte, sollte der Exakte Fisher-Test verwendet werden. Die Stärke der Korrelation kann mit dem Phi-Koeffizient abgeschätzt werden.

Lehnt der Test die Nullhypothese ab, bedeutet es jedoch nicht, dass der Klassifikator gut ist. Es bedeutet nur, dass er besser ist als (zufälliges) Raten. Ein guter Klassifikator sollte auch eine möglichst hohe Korrelation aufweisen.

In Diettrich (1998) werden fünf Tests untersucht zum direkten Vergleich von Missklassifikationsraten von zwei unterschiedlichen Klassifikatoren:

ein einfacher Zweistichproben-t-Test für unabhängige Stichproben, ein Zweistichproben-t-Test für verbundene Stichproben, ein Zweistichproben-t-Test für verbundene Stichproben mit 10-fach-Kreuzvalidierung, der McNemar-Test und ein Zweistichproben-t-Test für verbundene Stichproben mit 5-fach-Kreuzvalidierung und modifizierter Varianzberechnung (5x2cv). Als Ergebnis der Untersuchung von Güte und Fehler 1. Art der fünf Tests ergibt sich, dass sich der 5x2cv-Test am besten verhält, jedoch sehr rechenaufwendig ist. Der McNemar-Test ist etwas schlechter als der 5x2cv-Test, jedoch deutlich weniger rechenaufwendig.

Ein spezieller Anwendungsfall der hier beschriebenen Maße ist die Beurteilung der Güte von Treffermengen einer Recherche beim Information Retrieval. Dabei geht es um die Beurteilung, ob ein gefundenes Dokument, etwa beim Webmining durch Suchmaschinen, entsprechend einem definierten Kriterium relevant ist. In diesem Zusammenhang sind die oben definierten Bezeichnungen "Trefferquote" (engl. „recall“), "Genauigkeit" (engl. „precision“) und "Ausfallquote" (engl. „fallout“) gebräuchlich. Die Trefferquote gibt den Anteil der bei einer Suche gefundenen relevanten Dokumente und damit die Vollständigkeit eines Suchergebnisses an. Die Genauigkeit beschreibt mit dem Anteil relevanter Dokumente an der Ergebnismenge die Genauigkeit eines Suchergebnisses. Der (weniger gebräuchliche) Ausfall bezeichnet den Anteil gefundener irrelevanter Dokumente an der Gesamtmenge aller irrelevanten Dokumente, er gibt also in negativer Weise an, wie gut irrelevante Dokumente im Suchergebnis vermieden werden. Statt als Maß können Trefferquote, Genauigkeit und Ausfall auch als Wahrscheinlichkeit interpretiert werden:


Eine gute Recherche sollte möglichst alle relevanten Dokumente finden (richtig positiv) und die nicht relevanten Dokumente nicht finden (richtig negativ). Wie oben beschrieben, hängen die verschiedenen Maße jedoch voneinander ab. Im Allgemeinen sinkt mit steigender Trefferrate die Genauigkeit (mehr irrelevante Ergebnisse). Umgekehrt sinkt mit steigender Genauigkeit (weniger irrelevante Ergebnisse) die Trefferrate (mehr relevante Dokumente, die nicht gefunden werden). Je nach Anwendungsfall sind die unterschiedlichen Maße zur Beurteilung mehr oder weniger relevant. Bei einer Patentrecherche ist es beispielsweise wichtig, dass keine relevanten Patente unentdeckt bleiben – also sollte der Negative Vorhersagewert möglichst hoch sein. Bei anderen Recherchen ist es wichtiger, dass die Treffermenge wenige irrelevante Dokumente enthält, d. h., der Positive Vorhersagewert sollte möglichst hoch sein.

Im Kontext des Information Retrieval wurden auch die oben beschriebenen kombinierten Maße wie der F-Wert und die Effektivität eingeführt.

Zur Einschätzung eines Retrieval-Verfahrens werden meist Trefferquote und Genauigkeit gemeinsam betrachtet. Dazu werden im sogenannten "Precision-Recall-Diagramm" (PR-Diagramm) für verschieden große Treffermengen zwischen den beiden Extremen Genauigkeit auf der y-Achse und Trefferquote auf der x-Achse eingetragen. Dies ist vor allem leicht bei Verfahren möglich, deren Treffermenge durch einen Parameter gesteuert werden kann. Dieses Diagramm erfüllt einen ähnlichen Zweck wie die oben beschriebene ROC-Kurve, die man in diesem Zusammenhang auch als Trefferquote-Fallout-Diagramm bezeichnet.

Der (höchste) Wert im Diagramm, an dem der Precision-Wert gleich dem Treffer-Wert ist – also der Schnittpunkt des Genauigkeit-Trefferquote-Diagramms mit der Identitätsfunktion – wird der Genauigkeit-Trefferquote-Breakeven-Punkt genannt. Da beide Werte voneinander abhängen, wird auch oft der eine bei fixiertem anderen Wert genannt. Eine Interpolation zwischen den Punkten ist allerdings nicht zulässig, es handelt sich um diskrete Punkte, deren Zwischenräume nicht definiert sind.

In einer Datenbank mit 36 Dokumenten sind zu einer Suchanfrage 20 Dokumente relevant und 16 nicht relevant. Eine Suche liefert 12 Dokumente, von denen tatsächlich 8 relevant sind.

Trefferquote und Genauigkeit für die konkrete Suche ergeben sich aus den Werten der Konfusionsmatrix.

Ein Problem bei der Berechnung der Trefferquote ist die Tatsache, dass man nur selten weiß, wie viele relevante Dokumente insgesamt existieren und nicht gefunden wurden (Problem der unvollständigen Wahrheitsmatrix). Bei größeren Datenbanken, bei denen die Berechnung der absoluten Trefferquote besonders schwierig ist, wird deswegen mit der "relativen Trefferquote" gearbeitet. Dabei wird die gleiche Suche mit mehreren Suchmaschinen durchgeführt, und die jeweils neuen relevanten Treffer werden zu den nicht gefundenen relevanten Dokumenten addiert. Mit der Rückfangmethode kann abgeschätzt werden, wie viele relevante Dokumente insgesamt existieren.

Problematisch ist auch, dass zur Bestimmung von Trefferquote und Genauigkeit die Relevanz eines Dokumentes als Wahrheitswert (ja/nein) bekannt sein muss. In der Praxis ist jedoch oft die Subjektive Relevanz von Bedeutung. Auch für in einer Rangordnung angeordnete Treffermengen ist die Angabe von Trefferquote und Genauigkeit oft nicht ausreichend, da es nicht nur darauf ankommt, ob ein relevantes Dokument gefunden wird, sondern auch, ob es im Vergleich zu nicht relevanten Dokumenten genügend hoch in der Rangfolge eingeordnet wird. Bei sehr unterschiedlich großen Treffermengen kann die Angabe durchschnittlicher Werte für Trefferquote und Genauigkeit irreführend sein.

Das Ziel eines HIV-Tests sollte die möglichst sichere Erkennung eines Infizierten sein. Aber welche Konsequenzen ein falsch positiver Test haben kann, zeigt das Beispiel eines Menschen, der sich auf HIV testen lässt und dann aufgrund eines falsch-positiven Ergebnisses Suizid begeht.

Bei einer angenommenen Genauigkeit von 99,9 % des nicht-kombinierten HIV-Tests sowohl für positive als auch negative Ergebnisse (Sensitivität und Spezifität = 0,999) und der aktuellen Verbreitung von HIV (Stand 2009) in der deutschen Bevölkerung (82.000.000 Einwohner, davon 67.000 HIV-positiv) wäre ein allgemeiner HIV-Test verheerend: bei nicht-kombiniertem HIV-Test würden nämlich von 67.000 tatsächlich Erkrankten lediglich 67 HIV-Infizierte fälschlicherweise nicht erkannt, aber ca. 82.000 Personen würden fälschlicherweise als HIV-positiv diagnostiziert. Von 148.866 positiven Ergebnissen wären etwa 55 % falsch positiv, also mehr als die Hälfte der positiv Getesteten. Somit liegt die Wahrscheinlichkeit, dass jemand, der nur mit dem ELISA-Test positiv getestet würde, auch wirklich HIV-positiv wäre, bei nur 45 % (positiver Vorhersagewert). Dieser angesichts der sehr geringen Fehlerrate von 0,1 % niedrige Wert liegt darin begründet, dass HIV nur bei etwa 0,08 % der Bundesbürger auftritt.

In den USA werden pro Jahr etwa vier Millionen Frauen und Männer wegen Schmerzen in der Brust unter der Verdachtsdiagnose Herzinfarkt in eine Klinik eingewiesen. Im Verlauf der aufwendigen und teuren Diagnostik stellt sich dann heraus, dass von diesen Patienten nur etwa 32 % tatsächlich einen Infarkt erlitten haben. Bei 68 % war die Diagnose Infarkt nicht korrekt (falsch positive Verdachtsdiagnose). Andererseits werden in jedem Jahr etwa 34.000 Patienten aus dem Krankenhaus entlassen, ohne dass ein tatsächlich vorhandener Herzinfarkt erkannt wurde (ca. 0,8 % falsch negative Diagnose).

Auch in diesem Beispiel ist die Sensitivität der Untersuchung ähnlich hoch, nämlich 99,8 %. Die Spezifität lässt sich nicht ermitteln, weil die falsch-positiven Ergebnisse der Untersuchung nicht bekannt sind. Bekannt sind nur die falsch-positiven Eingangsdiagnosen, die auf der Angabe „Herzschmerz“ fußen. Betrachtet man ausschließlich diese Eingangsdiagnose, dann ist die Angabe der 34.000 Patienten, die fälschlich entlassen werden, wertlos, denn sie haben hiermit nichts zu tun. Man benötigt nämlich die Zahl der Falsch-Negativen, also jener Personen mit Herzinfarkt, die nicht eingewiesen wurden, weil sie keinen Herzschmerz hatten.






</doc>
<doc id="1655" url="https://de.wikipedia.org/wiki?curid=1655" title="Fehler 1. und 2. Art">
Fehler 1. und 2. Art

Die Fehler 1. und 2. Art, auch α-Fehler (Alpha-Fehler) und β-Fehler (Beta-Fehler) genannt, bezeichnen eine statistische Fehlentscheidung. Sie beziehen sich auf eine Methode der mathematischen Statistik, den sogenannten Hypothesentest. Beim Test einer Hypothese liegt ein Fehler 1. Art vor, wenn die Nullhypothese zurückgewiesen wird, obwohl sie in Wirklichkeit wahr ist (beruhend auf falsch positiven Ergebnissen). Dagegen bedeutet ein Fehler 2. Art, dass der Test die Nullhypothese fälschlicherweise bestätigt, obwohl die Alternativhypothese korrekt ist. Fehler 1. und 2. Art werden in der "statistischen Qualitätskontrolle" (siehe Prüflos) häufig "Produzentenrisiko" und "Konsumentenrisiko" genannt. In der "Prozesskontrolle" durch Qualitätsregelkarten verwendet man dafür die Begriffe "blinder Alarm" und "unterlassener Alarm".

"Hinweis": Sowohl Beta (wie auch Alpha) repräsentieren bedingte Wahrscheinlichkeiten:

wobei A den Ablehnbereich und T die für den Test benutzte Teststatistik bezeichnet.

Beim Test einer Hypothese liegt ein Fehler 1. Art vor, wenn die Nullhypothese zurückgewiesen wird, obwohl sie in Wirklichkeit wahr ist (beruhend auf falsch positiven Ergebnissen).

Die Ausgangshypothese formula_3 (Nullhypothese) ist hierbei die Annahme, die Testsituation befinde sich im „Normalzustand“. Wird also dieser „Normalzustand“ nicht erkannt, obwohl er tatsächlich vorliegt, ergibt sich ein Fehler 1. Art. Beispiele für einen Fehler 1. Art sind:


Als "Signifikanzniveau" oder "Irrtumswahrscheinlichkeit" bezeichnet man die vor einem Hypothesentest festgelegte maximale Wahrscheinlichkeit dafür, dass die Nullhypothese aufgrund der Testergebnisse abgelehnt wird, obwohl die Nullhypothese wahr ist. In der Regel wählt man ein Signifikanzniveau von 5 % (signifikant) oder 1 % (sehr signifikant).

Die andere mögliche Fehlentscheidung, nämlich die Alternativhypothese formula_4 zurückzuweisen, obwohl sie wahr ist, heißt Fehler 2. Art.


Im Gegensatz zum Fehler 1. Art bedeutet ein Fehler 2. Art, dass der Test die Nullhypothese fälschlicherweise bestätigt, obwohl die Alternativhypothese korrekt ist.

Im Gegensatz zum Risiko 1. Art, die gegebene Null-Hypothese, obwohl sie in Wirklichkeit zutrifft, irrtümlicherweise abzulehnen, lässt sich das Risiko 2. Art, also die Wahrscheinlichkeit eines Fehlers 2. Art meist nicht vorab bestimmen. Grund dessen ist die Art und Weise der Festlegung von Hypothesen statistischer Tests: Während die Null-Hypothese stets eine dezidierte Aussage wie beispielsweise formula_3: „Mittelwert“ formula_6 darstellt, ist die Alternativhypothese, da sie im Grunde "alle" übrigen Möglichkeiten erfasst, damit i. d. R. auch nur recht unbestimmter bzw. globaler Natur (bspw. formula_4: „Mittelwert formula_8“).

Die rechtsstehende Grafik illustriert diese Abhängigkeit der Wahrscheinlichkeit eines Fehlers 2. Art formula_9; (rot) vom unbekannten Mittelwert formula_10, wenn als „Signifikanzniveau“, d. h. maximales Risiko 1. Art, formula_11; (blau) in beiden Fällen derselbe Wert gewählt wird. Wie zu sehen, ergibt sich dabei überdies die paradoxe Situation, dass die Wahrscheinlichkeit eines Fehlers 2. Art umso größer wird, je näher der wahre Wert formula_10 an dem von der Nullhypothese behaupteten Wert formula_13 liegt, bis hin dazu, dass für formula_14 das Risiko 2. Art formula_9; den Grenzwert formula_16; annimmt. Anders gesagt: Je kleiner die Abweichung des tatsächlichen vom behaupteten Wert formula_17, desto größer paradoxerweise die Wahrscheinlichkeit, einen "Fehler" zu machen, wenn man aufgrund des Testergebnisses weiterhin dem behaupteten Wertformula_13 Glauben schenkt (obwohl die Abweichung beider Werte voneinander möglicherweise aufgrund ihrer Geringfügigkeit "praktisch" gar keine Rolle mehr spielt). Wie dieser Widerspruch zeigt, kann ein rein formal-logischer Umgang mit der Problematik des Fehlers 2. Art leicht Grundlage von Fehlentscheidungen sein.
Bei biometrischen und medizinstatistischen Anwendungen heißt die Wahrscheinlichkeit, eine Entscheidung für H zu treffen, falls H richtig ist, "Spezifität". Die Wahrscheinlichkeit, eine Entscheidung für H zu treffen, falls H richtig ist, wird "Sensitivität" genannt. Wünschenswert ist, dass ein Testverfahren hohe Sensitivität und hohe Spezifität und damit kleine Wahrscheinlichkeiten für die Fehler erster und zweiter Art hat.



In manchen Quellen wird für den Fehler 2. Art und die Teststärke die genau entgegengesetzte Notation verwendet. Dort wird also die Wahrscheinlichkeit, einen Fehler 2. Art zu begehen, mit dem Wert 1-β bezeichnet, die Teststärke oder Power dagegen mit β.




</doc>
<doc id="1661" url="https://de.wikipedia.org/wiki?curid=1661" title="Ferdinand de Saussure">
Ferdinand de Saussure

Ferdinand de Saussure (* 26. November 1857 in Genf; † 22. Februar 1913 auf Schloss Vufflens, Kanton Waadt, Schweiz) war ein Schweizer Sprachwissenschaftler. Er hat den sprachwissenschaftlichen Strukturalismus und die Entwicklung der Indogermanistik und der Semiotik im 20. Jahrhundert nachhaltig geprägt.

Saussure war der Sohn des Naturwissenschaftlers Henri de Saussure und von Louise Elisabeth de Pourtalès, Enkel von Nicolas Theodore de Saussure und Urenkel von Horace Bénédict de Saussure. 1876 bis 1880 studierte er in Leipzig Indogermanistik, 1878/1879 auch ein Semester in Berlin bei Heinrich Zimmer. 1882 heiratete er Marie Faesch (1867–1950), Tochter des Schweizer Ingenieurs Jules Faesch (1833–1895). Durch seine Frau gelangte das Schloss Vufflens in den Besitz von Ferdinand de Saussure und seiner Nachkommen. 

Nach seiner Promotion in Leipzig unterrichtete Saussure von 1881 bis 1891 an der École pratique des hautes études in Paris. Von 1891 bis zu seinem Tod war er Professor für vergleichende Sprachwissenschaft (Indogermanistik) an der Universität Genf. In dieser Zeit widmete er sich zunehmend Studien zur germanischen Heldensage und zur lateinischen Versdichtung, in der er – ohne Erfolg – die Präsenz von Anagrammen nachzuweisen suchte. In drei Vorlesungen über allgemeine Sprachwissenschaft, die zwischen 1906 und 1911 gehalten wurden, stellte er seine Grundideen vor, wie er sie vor allem in seiner Pariser Zeit entwickelt hatte. 

Sein Sohn Raymond de Saussure wurde Psychoanalytiker und war einer der wichtigsten Organisatoren der Psychoanalyse in der Westschweiz.

Zu Lebzeiten trat Saussure ausschließlich mit indogermanistischen Arbeiten zur vergleichenden Sprachwissenschaft hervor. 

In seinem "Mémoire sur le système primitif des voyelles dans les langues indo-européennes" (1879) rekonstruierte Saussure das indogermanischen Vokalsystem. Er versuchte zu zeigen, dass die späturindogermanischen Laute "*a", "*ā", "*o" und "*ō" in vielen Fällen aus einem "*e" in Kombination mit zwei – wie Saussure es nannte – „sonantischen Koeffizienten“ ("coefficients sonantiques") entstanden sind. Über die lautliche Eigenschaften dieser postulierten Koeffiozienten machte er keine weiteren Angaben.

Der dänische Sprachforscher Hermann Møller vermutete, dass es sich bei diesen Koeffizienten um Laryngale handle. Der polnische Sprachwissenschaftler Jerzy Kuryłowicz wies im Jahr 1929 nach, dass das erst 1917, vier Jahre nach Saussures Tod, entzifferte Hethitische einen der postulierten Laute aufwies. Im 
Lauf des 20. Jahrhunderts hat sich die Laryngaltheorie allgemein durchgesetzt.

Saussure gilt als Begründer der modernen Linguistik und des sprachwissenschaftlichen Strukturalismus. Seine Schüler Charles Bally und Albert Sechehaye veröffentlichten drei Jahre nach Saussures Tod den "Cours de linguistique générale" (zu Deutsch "Grundfragen der allgemeinen Sprachwissenschaft"). Der "Cours" entwickelt eine allgemeine Theorie der Sprache als Zeichensystem.

Saussure unterscheidet bei der Sprache drei Aspekte, die er mit drei unterschiedlichen Ausdrücken bezeichnet:

Der Begriff "langage" bezeichnet die menschliche Sprache als vortheoretischen Phänomenbereich, also so, wie sie den Sprechern in der Sprechtätigkeit begegnet. Demgegenüber ist die "langue" als theoretischer Sprachbegriff zu verstehen. Die "langue" kann also begriffen werden als sprachwissenschaftliche Perspektive, unter der die "langage" betrachtet wird.

"Langue" hat eine soziale und eine individuelle Dimension: In ihrer sozialen Dimension "(fait social)" ist "langue" eine intersubjektiv geltende gesellschaftliche Institution, ein sozial erzeugtes und in den Köpfen der Sprecher aufgehobenes, konventionelles System sprachlicher Gewohnheiten. In ihrer individuellen Dimension ist sie mentales "„depôt“", bzw. "„magasin“" (etwa: Lager) einer subjektiv internalisierten Einzelsprache.

Auch der Begriff der "parole" hat eine soziale und eine individuelle Seite. Er meint einmal den konkreten Sprechakt, also die individuelle Realisierung der "langue" durch den je einzelnen Sprecher "(hic et nunc)" gebundene, raum-zeitliche Realisierung des Systems. Zugleich ist die "parole" aber in ihrer sozialen Dimension der Ort der Genesis und Veränderung der "langue".

"Langue" und "parole" stehen also in einem Verhältnis der wechselseitigen Bedingtheit: Auf der einen Seite gibt es nichts in der "langue", das nicht durch die "parole" zuvor in sie gelangt wäre. Andererseits ist die "parole" nur möglich aufgrund jenes sozialen Produktes, das "langue" heißt.

Die beiden Herausgeber hielten sich an Mitschriften aus Saussures Vorlesungen. Allerdings hatten sie nicht selbst an jenen Vorlesungen teilgenommen. Textkritische Untersuchungen haben gezeigt, dass der Wortlaut zentraler Thesen des "Cours" sich in den Nachschriften nicht findet, sondern von den Herausgebern hinzugefügt wurde. Dazu gehört etwa der oft zitierte Satz, Sprache sei „eine Form, keine Substanz“. Erst in den 1950er Jahren entwickelte sich eine quellenkritische Forschung, die sich seither darum bemüht, Saussures fragmentarischen Nachlass zu erschließen.

Eine vom "Cours de linguistique générale" stark abweichende Darstellung der Lehren Saussures vertritt der deutsche Sprachwissenschaftler Ludwig Jäger mit seiner „transzendental-hermeneutischen“ Lesart. Jäger rekonstruiert Saussures Ansichten nicht anhand des "Cours" sondern aufgrund nachgelassener Manuskripte, in denen nach seiner Auffassung „der authentische Saussure“ zu finden sei. In der internationalen Saussure-Forschung stellt Jägers Auffassung eine einzelne Interpretation neben anderen dar, die nicht als allgemein akzeptiert gelten kann.

Während im "Cours" noch der Begriff des "signe" (‚Zeichen‘) Verwendung findet und (in Kongruenz mit der frühromantischen Diskussionen hierüber, insbesondere mit Novalis) die mentale und lautliche Seite sprachlicher Zeichen als "Signifikat" („signifié“ = Bezeichnetes, Zeicheninhalt) und "Signifikant" („signifiant“ = Bezeichnendes, Bezeichnung, äußere Zeichenform) unterschieden werden, verwendet Saussure diese Begriffe in den von Jäger herangezogenen Manuskripten nicht. Hier prägt er für das Ganze des Zeichens den Begriff des "Sème", für die lautliche Hülle des "Sème" den des "Aposème" sowie den des "Parasème" für den mentalen Zeichenaspekt. 

Der Begriff des "Sème" meint dabei stets das „Ganze des Zeichens, Zeichen und Bedeutung in einer Art Persönlichkeit vereint“ und soll die Vorherrschaft entweder der lautlichen oder der gedanklichen Seite beseitigen. Auch die Begriffe "Parasème" und "Aposème" bezeichnen nicht die Teile eines "Sème", sondern Aspekte desselben. Diese Aspekte sind keine dem "Sème" logisch vorausliegenden, unterscheidbaren Einheiten, die dann lediglich während des Sprechens zusammengesetzt werden. D. h., es werden nicht lediglich bereits mental vorhandene Bedeutungen mit ebenfalls vorhandenen Lauten verknüpft. Sprache bildet nicht Gedanken ab. Sie erschafft sie vielmehr: Erst im Akt des Sprechens, der Artikulation, vollzieht sich die Verbindung "(Synthese)" eines vorsprachlichen und daher chaotischen und gleichsam spurlos vorüberziehenden Denkens mit der lautlichen Substanz. Dieser Vorgang vollzieht sich in der Zeit, also "linear": Worte werden nacheinander geäußert. 

Lautlicher und gedanklicher Aspekt des Zeichens lassen sich so immer nur im Nachhinein ihrer Entstehung, der "Zeichensynthese", unterscheiden. Das dort erzeugte Ganze des Zeichens, das "Sème" ist notwendige Bedingung seiner beiden Seiten. "Aposème" und "Parasème" sind keine autonomen Bestandteile des "Sème", sondern lediglich Gesichtspunkte, unter denen dieses von Sprachwissenschaftlern betrachtet werden kann. Sie sind für Saussure vergleichbar mit einem Blatt Papier: das Denken ist die Vorderseite, der Laut die Rückseite. So wenig wie man die Vorderseite zerschneiden kann, ohne zugleich die Rückseite zu zerschneiden, so wenig kann der Gedanke vom Laut getrennt werden.

Bedeutung ist für Saussure nichts der Zeichensynthese logisch Vorausgehendes, sondern wird konkret im sozialen Austausch, in der Zeichensynthese erzeugt. Welche Bedeutung einem Zeichen zukommt, verdankt sie dabei nicht etwa einer wie auch immer gearteten inneren Verbindung zwischen Zeichen und Bezeichnetem. Es gibt keine im Zeichen selbst liegende Qualität, die eine bestimmte Bedeutung rechtfertigen könnte. Dieses von Saussure sogenannte Prinzip der "Arbitrarität" sprachlicher Zeichen wird im Deutschen unglücklich mit "Beliebigkeit" bzw. "Willkür" übersetzt. Das Arbitraritätsprinzip meint aber gerade nicht eine freie Wählbarkeit des Zeichens im Hinblick auf eine bestimmte bezeichnende Funktion. Gemeint ist die "Freiheit des Zeichens", das durch keine in ihm selbst liegende und der Zeichensynthese vorausliegende Eigenschaft an eine bestimmte Bedeutung gebunden ist. Dies lässt sich sowohl an dem Umstand ablesen, dass verschiedene Sprachen verschiedene Zeichen für gleiche Bedeutungen verwenden, als auch daran, dass sich die Bedeutung von Zeichen mit der Zeit verändert.

Bedeutung ist keine (ontologische) Eigenschaft von Zeichen, sondern ein Effekt ihrer Verwendung durch die Sprachgemeinschaft, insofern die "Parole" der ausschließliche Ort der Hervorbringung sprachlichen Sinnes ist. Zugleich verdankt sie sich dem Umstand, dass Sprachzeichen Teile eines Systems (der "langue") sind, innerhalb dessen jedes Zeichen von allen anderen Zeichen unterscheidbar ist. Die sprachliche Form gewinnt erst dadurch Bedeutung, dass sie in systematischer Korrelation zu anderen Formen steht. Ein Zeichen wird also in seiner Bedeutung nicht aus sich heraus und damit positiv, sondern durch seine Differenz zu anderen Zeichen bestimmt. Bedeutung kommt mit Saussure „immer von der Seite“, also durch die Opposition zu anderen Zeichen. Er spricht daher von der Wertlosigkeit des – in sich bedeutungslosen – Zeichens an sich („nullité du sème en soi“). Diesen systemischen Aspekt der differenzlogischen Bestimmung von Bedeutung bezeichnet Saussure als "valeur", als systemischen "Wert" des Zeichens.

Voraussetzung dieser Zeichenbestimmung ist neben dem "Prinzip der Arbitrarität" die "Linearität" der Lautsubstanz, bzw. der Artikulation. Erst das zeitlich differentielle Nacheinander, die Zergliederung des Gedankens in der Artikulation schafft die Voraussetzung für die Abgrenzbarkeit und Unterscheidbarkeit sprachlicher Einheiten. Und damit auch die Voraussetzung für ihre Identifizierbarkeit.

Der gleichermaßen individuelle wie soziale Charakter der "langue" als subjektiver Sprachschatz auf der einen und überindividuelles System sprachlicher Gewohnheiten auf der anderen Seite und ihre Verankerung in der "parole" als Ort der dialogischen Sinngenese sind es, aus denen die von Saussure bestimmten Prinzipien des Lebens der Sprache in der Zeit resultieren. Diese Prinzipien muten zunächst widersprüchlich an: Charaktereigenschaft der Sprache nämlich ist so sehr ihre "Kontinuität in der Zeit", wie ihre "fortwährende Transformation".

Während die Kontinuität der Sprache, ihr Ist-Zustand als bestimmtes Sprachstadium zu einer bestimmten Zeit als "synchronische" Ebene bezeichnet wird, nimmt die "diachrone" Ebene die Veränderung der Sprache in der Zeit in den Blick. Methodisch sind diese beiden Ebenen in der sprachwissenschaftlichen Praxis strikt voneinander zu trennen. Tatsächlich aber sind beide dicht ineinander verwoben: Der Aspekt der Kontinuität der Sprache adressiert Sprache zum einen als soziale und historische Tatsache. Die – in der Philosophie oft gestellte – Frage nach dem Sprachursprung, also nach einem Prozess der ursprünglichen Benennung von Welt, stellt sich für Saussure nicht, denn die Idee einer ursprünglichen Aushandlung von Bezeichnungen setzt eine begrifflich erschlossene Welt und damit die Existenz von Sprache immer schon voraus.

Zum anderen ist die Kontinuität der Sprache Möglichkeitsbedingung der Verständigung überhaupt, die stets an – in Synchronie befangene – Sprecherbewusstseine, an zu einem bestimmten Zeitpunkt intersubjektiv geteilte Sinnhorizonte und Bedeutungszuschreibungen geknüpft ist. Die Kontinuität der Sprache ist also Grundlage ihres sozialen Charakters. Eben jener soziale Charakter, also der Umstand, dass Sprecher fortwährend und gemeinsam mit Sprache umgehen aber ist es, dem sich zugleich die permanente Verwandlung der Sprache verdankt. Die Bewegung der Sprache – systemisch gesprochen: die fortwährende Neujustierung des relationalen Systems "langue" – ist unstillbar und unausgesetzt. Sie wird jedoch in aller Regel von den Sprechern nicht wahrgenommen. Das Wesen der Sprache ist daher – mit einem Wort des Sprachwissenschaftlers Christian Stetters – das der "Fluktuanz": das einer „nicht seienden sondern beständig werdenden und insofern sich kontinuierlich verändernden Substanz.“





</doc>
<doc id="1664" url="https://de.wikipedia.org/wiki?curid=1664" title="Friedrich Dürrenmatt">
Friedrich Dürrenmatt

Friedrich Reinhold Dürrenmatt (* 5. Januar 1921 in Konolfingen; † 14. Dezember 1990 in Neuenburg; heimatberechtigt in Guggisberg) war ein Schweizer Schriftsteller, Dramatiker und Maler.
Friedrich Dürrenmatt kam 1921 in Stalden im Emmental, seit 1933 politische Gemeinde Konolfingen, Kanton Bern, als erstes Kind von Reinhold (1881–1965) und Hulda Dürrenmatt (1886–1975), geborene Zimmermann, zur Welt. Sein Vater war reformierter Pfarrer des Dorfes, sein Großvater Ulrich Dürrenmatt war Politiker und Dichter. 1924 wurde seine Schwester Verena geboren. Im Oktober 1935 zog die Familie nach Bern um, wo der Vater Pfarrer am Diakonissenhaus wurde. Die Weltwirtschaftskrise machte sich zu diesem Zeitpunkt auch in der Schweiz bemerkbar, und das mittelständische Bürgertum wurde ärmer. Friedrich Dürrenmatt besuchte zunächst das Freie Gymnasium Bern, später das Humboldtianum, an dem er 1941 die Matura ablegte. Er war kein besonders guter Schüler (Gesamtnote: „knapp ausreichend“) und bezeichnete seine Schulzeit selbst als die „übelste Zeit“ seines Lebens. Die Schule wechselte er, weil ihm die Art des Unterrichts nicht gefiel, weil er schlechte Noten hatte und weil er durch sein Verhalten bei den Lehrern aneckte. Kurzzeitig war Dürrenmatt 1941 Mitglied einer Fröntler-Vereinigung, um sich von seinem Vater abzugrenzen, wie er später einräumte.

Noch in Konolfingen begann er zu malen und zu zeichnen, eine Neigung, die er sein Leben lang verspüren sollte. Er illustrierte später manches seiner eigenen Werke, verfasste Skizzen, zum Teil ganze Bühnenbilder. Seine Bilder wurden 1976 und 1985 in Neuenburg, 1978 in Zürich ausgestellt. Eigentlich wollte er eine Ausbildung zum Kunstmaler machen, studierte aber dann ab 1941 Philosophie, Naturwissenschaften und Germanistik an der Universität Bern, dazwischen 1942/43 an der Universität Zürich. In Bern wohnte er bei seinen Eltern in einer Mansarde, die er mit großen Wandbildern ausstattete, die später übertüncht und erst Anfang der neunziger Jahre entdeckt, freigelegt und restauriert wurden (siehe Dürrenmatt-Mansarde). 1946 beendete er das Studium, ohne seine geplante Dissertation zu Søren Kierkegaard auch nur anzufangen, entschlossen, Schriftsteller zu werden.

Am 11. Oktober 1946 heiratete er die Schauspielerin Lotti Geißler; darauf zogen sie zunächst nach Basel, wo 1947 ihr Sohn Peter geboren wurde, dann 1948 nach Schernelz am Bielersee. Dort entstand 1950 der Kriminalroman "Der Richter und sein Henker" mit offenem Bezug auf angrenzende Lokalitäten wie Lamboing. In dessen Verfilmung im Jahr 1975 tauchte er als "Friedrich" auf.
Max Frisch hatte vom Theaterverleger Kurt Reiss das Manuskript von Dürrenmatts erstem Bühnenwerk "Es steht geschrieben" erhalten und nach der Lektüre mit einem Brief den Kontakt zu Dürrenmatt eröffnet. Die an das Täuferreich von Münster anknüpfende Komödie wurde im April 1947 am Schauspielhaus Zürich uraufgeführt und verursachte einen Theaterskandal; nachdem es nicht den erhofften Anklang gefunden hatte, zog der Autor es im folgenden Jahr wieder zurück. 1948 folgte sein zweites Stück, "Der Blinde"; auch dieses Drama fand kaum Beachtung. 1949 kam sein drittes Stück, die Komödie "Romulus der Große", auf die Bühne, anstelle des nicht zu Ende geschriebenen und vom Autor vernichteten Werks "Der Turmbau zu Babel".

Die ersten Jahre als freier Schriftsteller waren wirtschaftlich schwierig für Dürrenmatt und seine bald fünfköpfige Familie. Dann besserte sich die finanzielle Situation allmählich, besonders aufgrund von Hörspiel-Aufträgen deutscher Rundfunkanstalten. Außerdem wurde zu dieser Zeit der Arche Verlag zu seinem Stammverlag. Seine beiden Krimis ("Der Richter und sein Henker" und "Der Verdacht") wurden ab 1950 zuerst als Fortsetzungsgeschichten im Schweizerischen Beobachter veröffentlicht. Die Dürrenmatts bezogen 1952 ihren dauerhaften Wohnsitz im neu gebauten Haus oberhalb von Neuenburg.

1950 entstand die Komödie "Die Ehe des Herrn Mississippi", mit der er 1952 seinen ersten großen Erfolg auf den bundesdeutschen Bühnen verzeichnen konnte, nachdem sie von den Schweizer Bühnen zuvor abgelehnt worden war. Weltweiten Ruhm erzielte er 1956 mit seiner Tragikomödie "Der Besuch der alten Dame"; der überragende Erfolg dieses Werks begründete zudem seine finanzielle Unabhängigkeit. Auf den Misserfolg mit der „musikalischen Komödie“ "Frank der Fünfte" (1960) folgte 1962 der zweite Welterfolg mit "Die Physiker". Das zum Theaterstück umgearbeitete Hörspiel "Herkules und der Stall des Augias" (1963) kam beim Publikum wiederum nicht an. Mit "Der Meteor", seinem persönlichsten Stück, konnte er 1966 den dritten und letzten Welterfolg als Dramatiker feiern.

Für sein Schaffen erhielt er viele Auszeichnungen, so 1948 den Welti-Preis für "Es steht geschrieben", 1959 den Schillerpreis der Stadt Mannheim, 1960 den Grossen Schillerpreis und 1977 die Buber-Rosenzweig-Medaille. 1969 wurde ihm die Ehrendoktorwürde der Temple University in Philadelphia verliehen, und er erhielt weitere Ehrendoktortitel in Jerusalem und Nizza. In den 1960ern stand Dürrenmatt mit seinen Theaterwerken auf dem Höhepunkt seines Öffentlichkeitserfolges. Zu großem Ruhm verhalf Dürrenmatt zudem sein Drehbuch zu dem Heinz-Rühmann-Film "Es geschah am hellichten Tag" (1958), nach dessen Vorbild er auch seinen Roman "Das Versprechen" schrieb. Der Film gilt noch heutzutage als einer der größten deutschen Kriminalfilme.

Ab 1967 widmete er sich auch der praktischen Theaterarbeit, erst an Basler Bühnen, nach einem Herzinfarkt im Oktober 1969 in der Neuen Schauspiel AG in Zürich, schließlich in Düsseldorf. Dort fanden zwei seiner Uraufführungen statt, "Porträt eines Planeten" und "Titus Andronicus". Er inszenierte mehrere spektakuläre Wiederaufführungen seiner eigenen Stücke, so 1978 in Wien "Der Meteor" (1964/65).

Dürrenmatt nahm als gesellschaftskritischer Autor in Essays, Vorträgen und Festreden Stellung zur internationalen Politik, etwa mit "Sätze aus Amerika" (1970), dem Pressetext "Ich stelle mich hinter Israel" (1973) und einem Vortrag zum 100. Geburtstag von Albert Einstein an der ETH Zürich (1979). Im Februar 1987 nahm er an der von Michail Gorbatschow einberufenen Friedenskonferenz in Moskau teil. 1990 hielt er zwei Reden zu Václav Havel und Michail Gorbatschow, die unter dem Titel "Kants Hoffnung" erschienen.

Für die 29-bändige Werkausgabe, die 1980 im Arche Verlag als gebundene Ausgabe und im Diogenes Verlag als Taschenbuch erschien, hatte Dürrenmatt von den meisten seiner Werke Neufassungen hergestellt. In dieser Zeit setzte er sich intensiv mit seiner eigenen Arbeitsweise und seinen von ihm erschaffenen Figuren und Orten auseinander, mündend in den beiden Bänden "Labyrinth. Stoffe I–III" (1981) und "Turmbau. Stoffe IV–IX" (1990). Aus Typoskripten wurde 1992 postum unter dem Titel "Gedankenfuge" eine Fortsetzung der "Stoffe" veröffentlicht.

In den 1980ern erhielt er wieder eine Reihe von Auszeichnungen, so 1983 den Österreichischen Staatspreis für Europäische Literatur und 1986 den Georg-Büchner-Preis. Im Jahre 1985 erhielt er den Bayrischen Literaturpreis (Jean-Paul-Preis) zur Würdigung des literarischen Gesamtwerks.

Am 16. Januar 1983 starb seine Frau Lotti. Dürrenmatt heiratete am 8. Mai 1984 die Schauspielerin und Filmemacherin Charlotte Kerr. Zusammen brachten sie den Film "Porträt eines Planeten" und das Theaterstück "Rollenspiele" heraus. Am 14. Dezember 1990 starb Friedrich Dürrenmatt in Neuenburg im Alter von 69 Jahren an Herzversagen. Charlotte Kerr hat ihre Erinnerungen an die gemeinsame Zeit in ihrem Buch "Die Frau im roten Mantel" verarbeitet. Postum wurde Dürrenmatt mit Einverständnis seiner Witwe in die Lord Jim Loge aufgenommen. Im September 2000 wurde in seinem Wohnhaus das Centre Dürrenmatt eröffnet, wo seither Ausstellungen und Veranstaltungen zu seinem Schaffen stattfinden.

Am 26. Juli 2000 wurde der Asteroid (14041) Dürrenmatt nach ihm benannt.

Ähnlich wie Bertolt Brecht (1898–1956), dessen Theorien zum epischen Theater Dürrenmatt studierte und neben dem er als „originellster Theoretiker“ angesehen wird, wollte er beim Zuschauer Distanz zum Geschehen auf der Bühne erzeugen. Der Zuschauer soll nicht weiter die Rolle eines passiven Konsumenten innehaben. Er soll zum eigenständigen Nachdenken angeregt werden.

Dazu bevorzugte Dürrenmatt das Stilmittel der Verfremdung, z. B. allgemein Anerkanntes wird hinterfragt und die Widersprüchlichkeit gesellschaftlicher Strukturen offenbart. Ebenso charakteristisch sind tragisch-groteske Elemente, also eine Verbindung von scheinbar Unvereinbarem. Im Gegensatz zu Brecht präsentierte Dürrenmatt aber keine Weltanschauung (bei Brecht: Marxismus).

Dürrenmatt schuf so seinen eigenen Typus der Tragikomödie, einer Mischform aus Tragödie und Komödie, seiner Meinung nach "„die einzig mögliche dramatische Form, heute das Tragische auszusagen“." Denn die Tragödie setzt, wie Dürrenmatt in seinem Text "Theaterprobleme" von 1955 sagt, „Schuld, Not, Maß, Übersicht, Verantwortung“ voraus, um ihr Ziel, die Läuterung des Einzelnen, zu erreichen. In der Unübersichtlichkeit der modernen Welt, so Dürrenmatt, werde Schuld verwischt und abgeschoben, der Moderne komme nur die Groteske bei.

Von Marcel Reich-Ranicki werden drei Werke Dürrenmatts hervorgehoben, welche seine Epoche für spätere Generationen greifbar mache: „seine tragische Komödie von der Käuflichkeit des Menschen und von der korrumpierenden Wirkung des Wohlstands“ (Der Besuch der alten Dame, 1956), „die Parabel von der Bedrohung der Menschheit durch die Zivilisation“ (Die Physiker, 1962) „und schließlich die von der deutschen Kritik gänzlich unterschätzte Parabel von der Schuld des Individuums“ (Die Panne, 1956).
Anmerkung: Viele seiner Romane und Erzählungen wurden auch als Hörspiel vertont. Von beinahe allen Werken existieren unterschiedliche Fassungen.

Von 1980 bis 1986 ist das dramatische Werk in 17 und das Prosawerk in 12 Einzelbänden erschienen, herausgegeben von Daniel Keel in Zusammenarbeit mit dem Autor, gleichzeitig als Hardcover im Arche Verlag und als Taschenbuch im Diogenes Verlag. Band 30 mit Zeugnissen über Friedrich Dürrenmatt ist hier unter Literatur angeführt.

1998 hat der Diogenes Verlag die auf 37 Bände erweiterte Taschenbuch-Neuausgabe veröffentlicht:










 Über Dürrenmatt


</doc>
<doc id="1666" url="https://de.wikipedia.org/wiki?curid=1666" title="Flughafen Berlin-Tempelhof">
Flughafen Berlin-Tempelhof

Der Flughafen Berlin-Tempelhof war einer der ersten Verkehrsflughäfen Deutschlands und nahm 1923 den Linienverkehr auf. Er war bis zu seiner Schließung am 30. Oktober 2008 neben Berlin-Tegel und Berlin-Schönefeld einer von drei internationalen Verkehrsflughäfen im Großraum Berlin und trug die Bezeichnung "Zentralflughafen". Im Jahr 2007 wurden dort rund 350.000 Fluggäste abgefertigt.

Seit 2010 wird das ehemalige Flughafengelände vom Land Berlin und seinen Unternehmen mit dem Projektnamen "Tempelhofer Freiheit" bezeichnet und ist für die Öffentlichkeit zugänglich. In den Medien wird dagegen meist vom "Tempelhofer Feld" gesprochen.

Das Gelände des ehemaligen Flughafens Tempelhof liegt im Innenstadtbereich Berlins innerhalb des S-Bahn-Ringes, vier Kilometer südlich des Stadtkerns und 51 Meter über dem Meeresspiegel. Das Flughafengebäude und der größte Teil des Flugfeldes befinden sich im Ortsteil Tempelhof, das Flugfeld erstreckt sich östlich aber bis in den Ortsteil Neukölln.

Auf der Straße ist der einstige Flughafen Berlin-Tempelhof über die Anschlussstelle 20 der A 100 (Stadtautobahn) sowie den Abschnitt Tempelhofer Damm der Bundesstraße 96 zu erreichen. Ebenfalls zum Flughafen führen der Mehring- und der Columbiadamm sowie als Zufahrtsstraßen die Manfred-von-Richthofen- und die Dudenstraße. Diese Straßen enden am Platz der Luftbrücke, wo sich der Haupteingang zum Flughafengebäude befindet. An die öffentlichen Verkehrsmittel ist der ehemalige Flughafen durch die Linie U6 der Berliner U-Bahn mit dem Bahnhof Platz der Luftbrücke angebunden, durch die u. a. der Regionalbahnhof Friedrichstraße erreicht werden kann; ebenfalls am ehemaligen Flughafengelände bzw. am U-Bahnhof halten die Buslinien 104 und 248.

Die Fläche, auf der der Flughafen Tempelhof gebaut wurde – das Tempelhofer Feld – war ehemals ein Exerzierplatz. Der erste Motorflug auf dem Tempelhofer Feld fand bereits 1909 statt. Am 28. Januar begann der Franzose Armand Zipfel (1883–1954) hier mit seinen öffentlichen Vorführungen. Er flog auf Einladung des "Berliner Lokal-Anzeigers" unter großem öffentlichen Interesse bis Mitte Februar 1909 mit seinem Voisin-Doppeldecker. Vom 4. bis 20. September 1909 führte auch Orville Wright auf dem Feld Demonstrationsflüge durch, bei denen er unter anderem einen Höhenweltrekord von 172 Metern aufstellte und erstmals einen Passagierflug von 1:35 h Dauer absolvierte. Im Oktober führte Hubert Latham (1883–1912) den ersten Überlandflug über einer Stadt vom Tempelhofer Feld über Rixdorf und Britz zum Flugplatz Johannisthal durch.

Nach dem Ersten Weltkrieg stimmten im Jahr 1919 die Gemeindevertretungen Neuköllns und Tempelhofs, auf deren Gebiet sich das Tempelhofer Feld befand, gegen eine Bebauung des Feldes. Erst nach einer Initiative des Reichsverkehrsministeriums im Dezember 1921 vollzog sich im Laufe des Jahres 1922 ein Schwenk in den betroffenen Gemeinden und Berlins hin zum Bau eines Flughafens, allerdings verbunden mit dem Willen zur gleichzeitigen Schaffung eines Volksparks am Nordrand des Tempelhofer Feldes und eines Sportparks auf seiner östlichen Seite. Den Beschluss zum Flughafenbau fasste der Magistrat von Groß-Berlin nach einer Vorlage des Berliner Verkehrsstadtrates Leonhard Adler am 21. Februar 1923. Anfang März 1923 demonstrierte die Junkers Luftverkehrsgesellschaft die Tauglichkeit des Tempelhofer Feldes mit Sonderflügen von fünf Junkers F 13 zum Flughafen Leipzig-Mockau. Unter den Passagieren befanden sich Reichspräsident Friedrich Ebert und der Direktor des Reichsluftamtes, Traugott Bredow. Im April 1923 wurden für Berliner Persönlichkeiten aus Politik und Wirtschaft auch einige Rundflüge vom Tempelhofer Feld aus veranstaltet. Dabei kam es zu einem Flugzeugabsturz über der Hasenheide, bei dem auch ein Berliner Stadtverordneter starb. Ungeachtet dieses Unglücks stimmten am 3. Mai 1923 die Berliner Stadtverordneten für den Bau des Flughafens.

Auf Kosten der Junkers Luftverkehr AG und der Deutschen Aero Lloyd wurde ab Juni 1923 am Nordrand des Tempelhofer Feldes ein Stück Land planiert und zwei hölzerne Flugzeughallen mit je 1000 m² Grundfläche und ein Stationsgebäude errichtet. Die Anlage sollte später in den Besitz der Stadt Berlin übergehen. Der Flugbetrieb begann am 8. Oktober 1923 mit einer vorläufigen Konzession des Reichsverkehrsministeriums. Mehrere Hundert Zuschauer verfolgten an diesem Tag die Starts zweier Flüge, einer führte nach München, der andere nach Danzig.

Die noch heute bestehende Berliner Flughafen-Gesellschaft mbH (BFG) wurde am 19. Mai 1924 gegründet, ihr erster Aufsichtsratsvorsitzender wurde Leonhard Adler. Aufgabe der Gesellschaft war der „Ausbau und Betrieb des Flughafens auf dem Tempelhofer Feld und anderer Luftverkehrseinrichtungen in Berlin“. Gesellschafter waren zunächst der Berliner Magistrat und ab 27. September 1924 das Deutsche Reich. 1925 beteiligte sich auch der Freistaat Preußen an der Gesellschaft. Planungen, auf einem Teilstück des Tempelhofer Feldes auch einen Standort für Messeanlagen zu schaffen, wurden im Verlauf des Jahres 1924 zugunsten des Charlottenburger Messegeländes aufgegeben.

Mit dem nun zur Verfügung stehenden Kapital konnte der Ausbau des Flughafens beginnen. Es wurde ein ca. 1,5 Millionen m² großes Areal im Zentrum des Tempelhofer Feldes planiert, wobei der Aushub der gerade in Bau befindlichen Verlängerung der Nord-Süd-U-Bahn (heutige Linie U6) verwendet wurde. Allerdings reichte der Aushub nicht, weshalb man zusätzlich 18.000 Fuhren Müll zur Verfüllung benutzte.

Ende 1924 wurde mit dem Bau der großen Flugzeughallen begonnen. Es entstanden die drei westlichen Hallen mit einer Grundfläche von 64 Meter × 25 Meter und einer Höhe von sechs Metern. Diese Dimensionen erwiesen sich aber schnell als zu klein, weshalb die drei östlichen Hallen mit einer Grundfläche von 80 Meter × 30 Meter und einer Höhe von acht Metern gebaut wurden. Neben den Hallen entstanden ein Scheinwerferturm sowie eine Funkstation und das Abfertigungsgebäude. Der erste Bauabschnitt war im Jahr 1927 fertig und konnte über den damals ebenfalls neu eröffneten "U-Bahnhof Flughafen" (heute: U-Bahnhof Paradestraße) erreicht werden. Eine Flughafenanbindung durch eine U-Bahn war seinerzeit weltweit einzigartig.

Der erste planmäßige Luftverkehr führte nach München mit Anschluss in die Schweiz bzw. nach Österreich und weiter auf den Balkan, sowie nach Königsberg mit Anschluss an die von London über Berlin-Staaken nach Moskau beflogene Strecke. 1923 wurden insgesamt 100 Starts und Landungen mit 150 Passagieren und 1300 kg Fracht durchgeführt.

Die am 6. Januar 1926 aus der Vereinigung der Junkers Luftverkehr AG und Deutscher Aero Lloyd entstandene "Deutsche Luft Hansa A.G." machte Tempelhof zu ihrem Heimatflughafen (siehe auch: Geschichte der Lufthansa). Von dort aus erfolgte am Tag der Betriebsaufnahme, dem 6. April 1926 – im Winter hatte der Flugverkehr noch geruht – auch der erste planmäßige Flug nach Dübendorf (Zürich).

In einem zweiten Bauabschnitt wurde das Abfertigungsgebäude erweitert. Es entstand ein großer, mit Klinkern verkleideter Bau. Es gab hier ein von der Mitropa betriebenes Flughafenrestaurant, eine Besucherterrasse und ein Flughafenhotel. Doch schon lange vor der Eröffnung dieses Abschnittes im Frühjahr 1929 forderte die BFG, das Flugfeld nach Süden, wo sich Kleingartenkolonien befanden, zu erweitern. Sie begründete ihre Forderung mit dem starken Anstieg des Luftverkehrs in Tempelhof einerseits und der Verringerung der Rollfläche durch eine zunehmende Betonierung der Abstellbereiche für die Flugzeuge andererseits. Nach dem Protest der betroffenen Kleingärtner und den Auswirkungen der Weltwirtschaftskrise ab 1930 wurde dieses Vorhaben vorerst nicht weiter verfolgt.

In den 1930er Jahren stand der alte Flughafen Tempelhof mit seinem Verkehrsaufkommen noch vor Paris, Amsterdam und London an der Spitze des europäischen Flugverkehrs. Die Grenzen der technischen Möglichkeiten waren bald erreicht, und im Januar 1934 begannen – noch unter dem BFG-Hausarchitekten Heinrich Kosina – die ersten Planungsarbeiten für einen Neubau zu einem Großflughafen auf dem Tempelhofer Feld. Im Juli 1935 erhielt der Architekt Ernst Sagebiel vom Reichsluftfahrtministerium den Planungsauftrag für den Neubau, der sowohl den neuen städtebaulichen Vorstellungen und der monumentalen Architektur im Nationalsozialismus entsprach als auch die Entwicklung der Luftfahrt für einen längeren Zeitraum vorwegnehmen musste. Der Flughafen war für bis zu sechs Millionen Passagiere pro Jahr geplant. Die Anlage sollte aber nicht allein dem Luftverkehr dienen, sondern auch für Veranstaltungen wie den Reichsflugtag genutzt werden und möglichst vielen luftfahrtbezogenen Dienststellen und Institutionen einen Sitz bieten. Dieser Neubau erfüllte auch alle Voraussetzungen eines Militärflugplatzes der damaligen Zeit.

Das ab 1936 entstandene Flughafengebäude war nach seiner Fertigstellung 1941 mit einer Bruttogeschossfläche von 307.000 m² für zwei Jahre das flächengrößte Gebäude der Welt, ehe es vom Pentagon in Arlington abgelöst wurde. Die Gesamtlänge des bogenförmigen Teils des Gebäudes (siehe auch Architektur weiter unten) beträgt etwa 1,2 Kilometer – es ist damit eines der längsten Gebäude Europas. Das Flugfeld wurde als ovaler Rasenplatz mit annähernd zwei Kilometern Durchmesser angelegt, sodass die zu diesem Zeitpunkt noch relativ leichten Flugzeuge, unter anderem die Ju 52, jeweils exakt gegen den Wind starten und landen konnten. Durch Einbeziehung des Volksparks und der um den alten Flughafen liegenden Sportplätze und Kleingartenflächen und durch Hinzunahme eines Teils des alten Garnisonsfriedhofs konnte das Flughafengelände auf über 4,5 Millionen m² erweitert werden. Auf diesem Gelände wurde die neue Flughafenanlage konstruiert – um den alten Flughafen herum – ohne dass es während der Bauarbeiten zu einer Beeinträchtigung des Flugbetriebes kam. Die Reste des alten Flughafens wurden erst in den 1950er Jahren von Notstandsarbeitern entfernt. Der U-Bahn-Zugang verschob sich mit dem neuen Gebäude zum Bahnhof Kreuzberg, der daraufhin in "Flughafen" (heute: Platz der Luftbrücke) umbenannt wurde.

Anfang Oktober 1939 bis Anfang März 1940 diente der Flugplatz Rangsdorf als Ersatz für den zivilen Luftverkehr in Tempelhof, weil das NS-Regime zu dieser Zeit eine Bombardierung des innerstädtischen Flugplatzes fürchtete. Busse transportierten die Passagiere zwischen Berliner Zentrum und Rangsdorf.

Das direkt am Neubau gelegene, am 27. Dezember 1934 eröffnete frühe nationalsozialistische Konzentrationslager KZ Columbia wurde aufgrund des Neubaus geschlossen. Es war bis zum 5. November 1936 in Betrieb und wurde 1938 abgerissen. An die Existenz des KZ Columbia erinnert seit 1994 ein von Georg Seibert entworfenes Mahnmal sowie der "Förderverein für ein Gedenken an die Nazi-Verbrechen auf dem und um das Tempelhofer Flugfeld e. V." mit Veranstaltungen, Führungen und Ausstellungen.

Im Dezember 1939 verfügte Hermann Göring, Teile der Produktion des Weserflug-Werkes Lemwerder nach Tempelhof zu verlagern. Aus der Baustelle "Neuer Flughafen" wurde eines der größten Endmontagewerke für Bomber weltweit. Als Lizenzbau stellte „Weserflug“ dort nahezu 2000 Ju 87 und rund 170 Fw 190 her. Produziert wurde im Wesentlichen in den Hangars 3 bis 7, der Flugsteighalle (die deshalb eine hölzerne Außenfassade erhielt), der 5000 m² großen Empfangshalle, der darunter befindlichen Frachthalle und mit dem Beginn der Fw 190-Herstellung seit 1943 auch im Eisenbahntunnel. Rund die Hälfte der 4150 Weserflug-Beschäftigten in Tempelhof (1944) waren Zwangsarbeiter.

Die Lufthansa nutzte ab 1940 ebenfalls den Flughafen-Neubau zu Produktionszwecken. In Hangar 2 reparierte ihre Dural-Werkstatt Beschussschäden an Flugzeugen der Luftwaffe und im Hangar 1 wurden die von Telefunken entwickelten „Würzburg“-Radargeräte montiert. In Tempelhof und später auch an anderen Standorten hat die Lufthansa bis Kriegsende eine geschätzte Zahl von 4000 dieser Geräte, die in der Luftverteidigung zum Einsatz kamen, hergestellt. Die Lufthansa beschäftigte während dieser Zeit auch Zwangsarbeiter, die in Baracken auf dem Flugfeld untergebracht waren.

Nach der Annexion Tschechiens im März 1939 wurden tschechische Frauen und Männer aus dem „Protektorat Böhmen und Mähren“ zur Arbeit ins Reich verpflichtet und im Weserflug-Werk Tempelhof eingesetzt. Im Verlauf des Zweiten Weltkriegs kamen zusätzlich Menschen aus nahezu allen anderen besetzten Ländern Europas dazu.

Ab 1941 wurden sämtliche Männer zur Wehrmacht einberufen. Sie wurden durch „Ostarbeiter“ ersetzt – verschleppte Familien aus Osteuropa, vor allem der Sowjetunion. Die ersten Lager hatte das Reichsluftfahrtministerium (als Bauherr des Flughafens) für reichsdeutsche Arbeiter errichten lassen. Diese Baracken wurden als Unterkünfte für Zwangsarbeiter und (französische) Kriegsgefangene mitgenutzt. Weser-Flugzeugbau und die Lufthansa ließen weitere Lager errichten. Die Lager und Unterkünfte waren auf dem Flugfeld in der Nähe des Columbiadamms, des Tempelhofer Damms sowie beim alten Flughafengebäude. Am Columbiadamm befand sich auch ein noch nicht weiter erforschtes „Russenlager“, das dreifach umzäunt und schwer bewacht war. Die Bauarbeiten liefen auch nach Kriegsbeginn weiter; bei Kriegsende 1945 war der neue Flughafen noch nicht vollständig fertiggestellt. Der Flugverkehr wurde weiterhin über die alte Flughafenanlage abgewickelt, die aber während des Krieges durch die Luftangriffe der Alliierten mehr und mehr beschädigt wurde. Der restliche zivile Flugverkehr wurde kurz vor Kriegsende – auch aus Mangel an Treibstoff – ganz eingestellt. Der alte Flughafen wurde 1939 in den Status eines Fliegerhorstes der Luftwaffe erhoben und diente zur Erprobung und Auslieferung der bei Weserflug gebauten Maschinen. Am 22. April 1945 verließ die letzte Maschine der Lufthansa Tempelhof in Richtung Warnemünde (siehe auch Geschichte der Lufthansa).

Im Zuge der Schlacht um Berlin eroberte die Rote Armee den Flughafen Tempelhof und befreite auch die verbliebenen Zwangsarbeiter, die hier buchstäblich bis zur letzten Minute arbeiten mussten.

Als sich die Front Ende April 1945 näherte, sollte der Flughafen verteidigt werden. Der damalige Flughafenkommandant Oberst Rudolf Böttger und einige leitende Lufthansa-Angestellte umgingen jedoch diesen Befehl, indem sie die bereitgestellten Waffen beiseiteschaffen ließen und ein Feldlazarett einrichteten. Dadurch kam es nicht zu einer Verteidigung des Flughafens, die möglicherweise zu einer völligen Zerstörung geführt hätte. Böttger entzog sich dem Vernichtungsbefehl Adolf Hitlers, die gesamte Anlage zu sprengen, durch Selbstmord. Nach anderen Quellen wurde er wegen Befehlsverweigerung von einem Offizier der Waffen-SS erschossen. Tatsächlich wurde der Betonboden der Haupthalle gesprengt, sodass dieser auf die darunter liegende Gepäckebene stürzte und die Haupthalle unbenutzbar wurde. Am 28./29. April 1945 besetzten Truppen der Roten Armee den Bezirk Tempelhof und den Flughafen.

Die neuen Gebäude blieben weitgehend von Zerstörungen verschont, jedoch kam es zu mehreren Bränden, die auch die Stahlkonstruktion der Hallenbauten schwer beschädigten. Die Gebäude des alten Flughafens waren restlos zerstört und das Flugfeld von Einschlägen übersät. Auch der unterirdische Bunker mit dem Filmarchiv brannte komplett aus und alle Filme wurden dabei zerstört.

Bereits kurz nach Ende der Kampfhandlungen richteten ehemalige Lufthansa- und Weserflug-Mitarbeiter die "Hansa-Werkstätten", eine Fahrzeugreparaturwerkstatt, im Flughafengebäude ein. Der Betrieb sammelte mit Genehmigung der Tempelhofer Bezirksverwaltung die in den Straßen herumstehenden Autowracks ein und baute aus noch brauchbaren Teilen wieder fahrbereite Autos zusammen.

Am 2. Juli 1945 verließ die Rote Armee den Flugplatz, damit dieser von den US-Amerikanern (473rd Air Services Group) noch vor ihrem offiziellen Eintreffen am 4. Juli übernommen werden konnte. Am 2. Juli 1945 wurde "Tempelhof Central Airport" (TCA), der die alliierte Code-Bezeichnung "Airfield R.95" erhielt, eingerichtet, am folgenden Tag begannen die Aufräumarbeiten. Dabei wurden alle vorgefundenen Akten, Personalpapiere und auch fast alle Baupläne des noch unfertigen Baus vernichtet. Der Flugbetrieb wurde im August 1945 aufgenommen, um Passagiere zur Potsdamer Konferenz zu bringen. Die US Army Air Forces (USAAF, ab 1947 US Air Force) stationierten im August 1945 das 301 Troop Carrier Squadron mit Douglas C-47 Skytrain, das im Januar 1946 durch das aus München verlegte 306 Troop Carrier Squadron abgelöst wurde.

Im Jahr 1946 wurde der im US-amerikanischen Sektor liegende Flughafen Tempelhof zum Militärstützpunkt, den überwiegend die USAAF nutzte. Er bekam den Namen "Tempelhof Air Base". Die erste Aufgabe war die Instandsetzung der Hallen 1 und 2, die dringend für die Wartung und Unterstellung der Flugzeuge gebraucht wurden. Außerdem musste eine befestigte Start- und Landebahn angelegt werden, damit auch schwerere Flugzeuge landen konnten. Dies geschah zuerst mit Hilfe von Lochplatten-Elementen der Pionier-Einheiten. Am 18. Mai 1946 landete auf dieser Bahn auch die erste zivile Maschine, eine DC-4 der American Overseas Airlines, die einmal wöchentlich die Strecke New York – Frankfurt – Berlin bediente.

Parallel wurde aber bereits der Bau des bis zuletzt genutzten befestigten Rollbahnsystems in der Hauptwindrichtung Ost-West begonnen. Während der Luftbrücke wurde von der französischen Militärverwaltung zur dringend benötigten Entlastung von Tempelhof auch die erste Start- und Landebahn in Tegel angelegt, die dadurch den Ursprung des heutigen Flughafens Tegel bildete.

Die US Army stationierte ab 1951 in Tempelhof eine Heeresfliegereinheit mit zunächst 3 Hubschraubern vom Typ Hiller H-23A Raven als Teil der 6. Infantry Brigade. Im Laufe der Jahre wurde es als das Berlin Brigade BBDE Avn.Det. bekannt. Die Hiller H-23A wurden bald durch Bell OH-13 Sioux ersetzt. Es folgten ab 1958 Sikorsky H-19 Chikasaw, ab 1964 Sikorsky H-34 Choctaw, ab 1966 Bell UH-1B und schließlich ab März 1971 bis zur Auflösung im August 1994 Bell UH-1H.

Zu den Starrflüglern zählten unter anderem Cessna O-1 Bird dog (bis 1975), de Havilland Canada U-6 Beaver (bis 1979), Cessna O-2A (1975–1979),Pilatus UV-20A Chiricahua (1979–1991), Beechcraft U-8D Seminole, Beechcraft U-21 (bis 1986 und 1991–1994), sowie Beechcraft C-12C (1986–1991).

Der zivile Luftverkehr wuchs nun stetig. Die BEA flog bereits seit 1946 den Flughafen Gatow an und am 5. Januar 1950 nahm die Air France den Berlin-Verkehr nach Tempelhof auf. Der Flughafen bekam 1948 eine neue Bedeutung: Zusammen mit dem Flugfeld Gatow, und später auch dem Flughafen Tegel, diente er während der Blockade West-Berlins dem Transport von Verpflegung und Gütern für Berlin per Flugzeug. Ein großer Teil der Ladung bestand aus Brennstoffen. Die lebensnotwendige Versorgung durch die Berliner Luftbrücke zwischen verschiedenen westdeutschen Städten und Berlin dauerte vom 26. Juni 1948 bis 12. Mai 1949. In Tempelhof starteten und landeten die Flugzeuge zeitweise im 90-Sekunden-Takt. Der amerikanische Pilot Gail Halvorsen machte das Abwerfen von Süßigkeiten während des Anfluges auf Tempelhof mit Fallschirmen aus Taschentüchern aus den Cockpit-Fenstern populär, was von weiteren Piloten übernommen wurde und den Flugzeugen den legendären Namen "Rosinenbomber" einbrachte. Für den reibungslosen Betrieb der Luftbrücke wurde die südliche Start- und Landebahn gebaut. Diese unterbricht seitdem die Oderstraße in Neukölln.

Das auf dem Platz vor dem Flughafen gelegene Denkmal erinnert an die historischen Versorgungsflüge und die dabei umgekommenen Menschen. Im Berliner Volksmund wird es aufgrund seines Aussehens als "Hungerharke" oder "Hungerkralle" bezeichnet. Weitere Denkmäler baugleicher Art befinden sich beim Flughafen Frankfurt und in etwas kleinerer Ausführung beim Heeresflugplatz Celle. Anlässlich des 50. Jahrestages der Luftbrücke feierte die Bundeswehr am 27. Juni 1998 auf dem Flughafen Tempelhof einen Großen Zapfenstreich.

Nach der Blockade bat man deshalb von West-Berliner Seite die Amerikaner, einen Teil der Anlagen für die zivile Nutzung freizugeben. Am 1. Juli 1950 übertrug der amerikanische Hohe Kommissar dem Senat von Berlin das Recht, einen Teil des Flughafens Tempelhof zur zivilen Nutzung zu übernehmen. Daraufhin wurde am südlichen Teil mit Zugang vom Tempelhofer Damm auf kleinstem Raum eine Abfertigungsanlage gebaut, die für eine Kapazität von 20.000 Passagieren monatlich ausgelegt war. Die Haupthalle, die später als Abfertigungsanlage diente, war damals noch im Rohbau und schwer beschädigt. Am 9. Juli 1951 konnte die neue Anlage dem Verkehr übergeben werden. Damit konnte die 1936 begonnene Anlage zum ersten Mal ihre offizielle Funktion übernehmen. Die drei westalliierten Fluggesellschaften Pan Am, BEA und Air France flogen nun gemeinsam Tempelhof an.

Der Passagier-Luftverkehr entwickelte sich nun rascher als erwartet, war dies doch die einzige Möglichkeit, ohne Kontrollen durch die DDR von West-Berlin nach Westdeutschland zu gelangen. Einen erheblichen Anteil daran hatten auch die Flüchtlinge, die West-Berlin nicht auf dem Landweg verlassen konnten. Bereits Ende 1951 wurden 320.000 Passagiere befördert. 1954 hatte der Flughafen Tempelhof schon mehr als 650.000 Fluggäste, die weitgehend von den westalliierten Fluggesellschaften BEA, später British Airways, Air France (nur bis 1960) und Pan Am befördert wurden.

Von den während der Blockadezeit entstandenen drei Start- und Landebahnen wurde die mittlere in den Jahren 1957/1958 entfernt. Die beiden anderen wurden im Laufe der 1950er Jahre von Grund auf erneuert. Man hatte während der Blockade zunächst Lochbleche verlegt und diese später mit einer Asphaltschicht überzogen, die zunächst entfernt werden musste. 1954 entstand so die nördliche Bahn mit 2093 Metern Länge und die südliche mit 2116 Metern Länge.

Zum Ende der 1950er Jahre konnten die zur Verfügung stehenden Anlagen das Passagieraufkommen (1960 waren es bereits 1,5 Millionen) nicht mehr bewältigen. Durch Verhandlungen wurde 1959 erreicht, dass die US Air Force weitere bisher militärisch genutzte Bereiche für die zivile Nutzung freigab. Hierbei handelte es sich um den Vorplatz (auch als "Ehrenhof" bezeichnet), das Bürogebäude mit der Eingangshalle (auch als "Ehrenhalle" bezeichnet) und das Abfertigungsgebäude mit der großen Haupthalle, die durch die BFG wieder hergerichtet bzw. fertiggestellt wurden. Der südliche Teil am Tempelhofer Damm wurde nun für den zivilen Luftverkehr genutzt, während der nördliche Teil am Columbiadamm weiterhin von den Amerikanern militärisch genutzt wurde. Am 2. Juli 1962 konnten die neuen Abfertigungseinrichtungen, die für 200.000 bis 250.000 Fluggäste pro Monat ausgelegt sind, dem Verkehr übergeben werden.

Die Gebäude wurden überwiegend in Stahlbeton- oder Backsteinbauweise ausgeführt und an den Sichtflächen mit Natursteinplatten verkleidet. Die der Haupthalle quer vorgelagerte 90 Meter breite, 9 Meter tiefe und 15 Meter hohe Eingangshalle war bei Kriegsende bereits fertiggestellt. Um Baumaterial für die Sichtflächen der stark beschädigte Haupthalle gewinnen zu können, wurde die Eingangshalle durch den Einbau einer Beton-Zwischendecke knapp unterhalb der 21 großen Hallenfenster geteilt und so in der Raumhöhe deutlich reduziert. Die unterhalb der Zwischendecke entstandene Eingangszone wirkt dadurch relativ unscheinbar. Der oberhalb der Zwischendecke verbliebene, rund zehn Meter hohe Rest der ursprünglichen Eingangshalle wird nicht genutzt – er kann bei Führungen besichtigt werden. In der Haupthalle ist die ursprünglich in 19 Metern Höhe hängende stark beschädigte Stuckdecke durch eine auf 15 Meter abgehängte Kassettendecke ersetzt worden. In den elf 5,60 Meter × 22,50 Meter großen Kassetten ist die Deckenstrahlungsheizung untergebracht. Diese Decke ist begehbar, um die Heizung und die Beleuchtung warten zu können.

Acht Jahre nach Inbetriebnahme der großen Abfertigungshalle wurde 1970 erneut die Kapazitätsgrenze erreicht, obwohl Air France mit Einführung der Caravelle bereits 1960 zum Flughafen Tegel umgezogen war. 1968 verlegte man daher zunächst den Charter- und Pauschalreiseverkehr nach Tegel. 1971 konnte die Kapazität durch etliche Umbauten und Verbesserungen noch einmal gesteigert werden, aber man entschloss sich trotzdem, den verbliebenen Linienverkehr in Tempelhof einzustellen und nach Tegel zu verlagern. Von 1970 bis 1974 war der durch die Berliner Luftbrücke bekannt gewordene „Candy-Pilot“ Gail Halvorsen Kommandant des Flughafens Tempelhof.

Im Sommer 1975 wurde Tempelhof für den zivilen Luftverkehr geschlossen und durch den neu errichteten Flughafen Tegel (auf dem Gelände des französischen Militärflugplatzes, nach Plänen der Hamburger Architekten Gerkan, Marg und Partner) ersetzt. Flughafenhalter und -betreiber war nun ausschließlich das US Army Aviation Detachment mit der Einheit 7350th ABG (Air Base Group). Es wurden verschiedene Hubschrauber- und Flugzeugtypen betrieben, zuletzt sechs Hubschrauber Bell UH-1H sowie ein Flugzeug Beechcraft C-12 C und zwei Maschinen des Typs Pilatus UV-20 A.

Am 30. August 1978 wurde eine Maschine der LOT bei ihrem Flug von Danzig nach Berlin-Schönefeld entführt und zur Landung in Tempelhof gezwungen. Da das Motiv eine Flucht aus der DDR war, kam es mitten im Kalten Krieg zu diplomatischen Verwerfungen zwischen den beiden Blöcken.

Im Jahr 1981 wurde Tempelhof für den Zivilluftverkehr, das heißt für den Geschäftsreiseverkehr, der seitdem ein Schwerpunkt des Flughafens war, und für Fluggesellschaften mit kleinerem Flugmaterial, wiedereröffnet. Als eine der ersten Fluggesellschaften nahm die US-amerikanische Regionallinie Tempelhof Airways 1981 mit einer Nord 262 ihren Shuttle-Dienst zwischen Tempelhof und Paderborn im Auftrag der Computerfirma Nixdorf auf, deren Hauptbetriebe und -büros sich in Paderborn und West-Berlin befanden. 1990 wurden wieder mehr als 400.000 Fluggäste gezählt. Auch noch bis kurze Zeit nach der politischen Wende lief die Abfertigung der Fluggäste zunächst nicht über die zu früheren Zeiten genutzte Haupthalle, sondern über einen relativ kleinen Bereich, dem späteren GAT (Abfertigungsbereich für allgemeine Luftfahrt), südwestlich der Haupthalle. Die Haupthalle selbst wurde aufgrund der rapide steigenden Passagierzahlen am 16. Dezember 1990 durch den Flughafenbetreiber etwas überraschend wiedereröffnet. Erst zu Beginn des Jahres 1992 war der Service dort vollständig einem gewissen Standard angepasst: Eine Hallenbar wurde errichtet, das neue Restaurant oberhalb der Haupthalle mit Blick auf das Vorfeld öffnete, neue Anzeigetafeln für Abflüge und Ankünfte wurden installiert, und ein neues Gepäckausgabeband für Inlandsflüge in der Haupthalle ging in Betrieb.

Die U.S. Air Force übergab den Flughafen 1993 bei ihrem Abzug aus Berlin wieder komplett an die BFG. Auf Grund der mit nur 2116 Metern relativ kurzen Start- und Landebahn war die Größe der Flugzeuge für den Linienverkehr auf die gängigen Schmalrumpfflugzeuge begrenzt, so dass er als ziviler Verkehrsflughafen vorwiegend für innerdeutsche und innereuropäische Ziele genutzt wurde. Die U.S. Air Force hatte auf dem Flughafen große Transportflugzeuge wie die Lockheed C-5 Galaxy nur unter eingeschränkten Bedingungen nutzen können. Zweimal landete eine Boeing 747 der Pan American in Tempelhof. Am 18. September 1976 landete eine Boeing 747 SP, aus Amsterdam kommend, anlässlich des Tages der offenen Tür und am 12. Juni 1987 eine Boeing 747-121 von/nach Frankfurt am Main mit 300 Journalisten anlässlich des Besuches von US-Präsident Ronald Reagan.

Am 24. Mai 2001 stürzte ein auf Tempelhof anfliegendes einmotoriges Reiseflugzeug vom Typ Beechcraft B36TC Bonanza nach einem Triebwerksausfall ab. Beim Versuch einer Außenlandung prallte das Flugzeug auf die Giebelwand eines Wohngebäudes im Berliner Ortsteil Neukölln, nachdem es zuvor noch einen Baum gestreift hatte. Die beiden Flugzeuginsassen kamen bei dem Absturz mit nachfolgendem Aufschlagbrand ums Leben. Die Unfallursache lag laut der Bundesstelle für Flugunfalluntersuchung neben dem Triebwerksausfall, der das Erreichen der Landebahn verhinderte, in dem für Notlandungen ungeeigneten Gelände. Dies war entgegen aller Kritik bezüglich der Innenstadtlage des Flughafens seit der Berliner Luftbrücke der einzige Flugunfall mit Todesfolge, der sich am Flughafen Tempelhof ereignete.

Am 27. Mai 2006 war der Flughafen Austragungsort des Red Bull Air Race. Seit 2007 war die – unter anderen von der Zeppelin-Stiftung getragene – Zeppelin University mit einem Standort im Flughafenfoyer vertreten. Am 8. September 2007 landete anlässlich der Veranstaltung „Reisemarkt“, veranstaltet von der Essener Luftfahrtagentur "airevents.de", ausnahmsweise ein Großraumflugzeug Airbus A330-200 der LTU in Tempelhof, der aufgrund des hohen Leistungsüberschusses moderner Antriebe sowie der geringen Beladung einen problemlosen Umgang mit der kurzen Startbahn sowie mehrere Durchstartmanöver mit Passagieren an Bord demonstrierte. Es handelte sich dabei um die Landung des größten Passagierflugzeugs auf einem kommerziell buchbaren Flug in der Geschichte des Flughafens (soweit in den 1970er und 1980er Jahren Großraumflugzeuge auf Tempelhof landeten, handelte es sich in der Regel um Maschinen der U.S. Air Force oder um Zivilmaschinen im Auftrag der U.S. Administration). In den Jahren 2007 und 2008 gab es zahlreiche von Luftfahrt-Verbänden und Vereinen organisierte sogenannte Fly-ins von Privatmaschinen, die bis zu 180 kleinere Flugzeuge gleichzeitig nach Tempelhof brachten.

Die "Bürgerinitiative flugfreies Tempelhof" (BIFT) setzte sich seit 2001 für die Schließung des Flughafens ein. Sie hatte im Wesentlichen drei Vorgängerbündnisse: die 1986 gegründete "Bürgerinitiative Flughafen Tempelhof," die 1996 gegründete "Bürger für die Schließung des Flughafens Tempelhof" sowie die 2001 initiierte "Bürgergruppe Herrfurthstraße/Oderstraße."

Gegen die Schließung des Flughafens hatte sich die 1995 gegründete "Interessengemeinschaft City-Airport Tempelhof" (ICAT) mit 1250 Mitgliedern gewandt. Sie initiierte 2006 erfolgreich ein Volksbegehren, das in einen Volksentscheid 2008 mündete. Dieses wurde auch durch das "Aktionsbündnis be-4-tempelhof," die "SPD-Wähler für den Flughafen Tempelhof" und andere Initiativen unterstützt. Bei dem Volksentscheid "Tempelhof bleibt Verkehrsflughafen!" am 27. April 2008 stimmten zwar 60,1 % der Abstimmenden, aber nur 21,7 % der Stimmberechtigten für den Weiterbetrieb des Flughafens. Damit wurde das notwendige Quorum zur Annahme des Beschlusses nicht erreicht.

Das Aktionsbündnis "be-4-tempelhof.de" initiierte im Bezirk Tempelhof-Schöneberg ein Bürgerbegehren mit dem Titel "Das Denkmal Flughafen Tempelhof erhalten – als Weltkulturerbe schützen." Der Bürgerentscheid am 7. Juni 2009 ergab bei 37,9 % Wahlbeteiligung 65,2 % Zustimmung. Da auch das hier notwendige Quorum von 15 % Abstimmungsbeteiligung erreicht wurde, hat der erfolgreiche Bürgerentscheid die Rechtskraft eines Beschlusses der Bezirksverordnetenversammlung.

Für die Nachnutzung des Flughafens Berlin-Tempelhof formierte sich 2007 die "Bürgerinitiative Nachnutzung des Flughafens Tempelhof" (NANU THF) und für eine Öffnung des umzäunten Flughafens setzt sich die Bürgerinitiative "Tempelhof für alle" ein und am 20. Juni 2009 wurde eine von der Plattform "Squat Tempelhof" initiierte Öffnung des ehemaligen Flughafengeländes durch 5000 Demonstranten versucht.

Bereits der erste Flächennutzungsplan des wiedervereinigten Berlins aus dem Jahr 1994 sah im Gegensatz zum Flughafen Tegel eine Umwidmung des Flughafengeländes mit zukünftiger Nutzung als Gewerbe-, Wohn-, Park-, Sport- und Sonderfläche vor. Im sogenannten „Konsensbeschluss“ einigten sich 1996 Bundesverkehrsminister Matthias Wissmann (CDU), Berlins Regierender Bürgermeister Eberhard Diepgen (CDU) und Brandenburgs Ministerpräsident Manfred Stolpe (SPD) auf den Neubau eines Großflughafens Berlin Brandenburg, in dessen Folge auch die Schließung der innerstädtischen Flughäfen Tempelhof und Tegel vereinbart wurde. Der Berliner Senat erließ nach erfolgtem Planfeststellungsbeschluss für den Flughafen Berlin Brandenburg 2003 den Bescheid, der die BFG von der Betriebspflicht des Flughafens befreite. Zu diesem Zeitpunkt war der Flugbetrieb laut Betreibergesellschaft defizitär, für das Jahr 2003 wurde der daraus entstehende Verlust mit 15,3 Millionen Euro angegeben. Gegen diesen Bescheid klagten einige Fluggesellschaften. In einem vorläufigen Rechtsschutzverfahren entschied das Oberverwaltungsgericht Berlin am 23. September 2004, dass die Klagen eine aufschiebende Wirkung haben und der Flugbetrieb bis zur Entscheidung in der Hauptsache aufrechterhalten werden muss. Das Gericht stellte eine Entscheidung im Sinne der Kläger in der Hauptsache in Aussicht. Der Senat zog daraufhin den Bescheid zurück und bereitete einen fundierteren Bescheid zur Betriebseinstellung vor, der im August 2006 erlassen wurde und ein Ende der Betriebspflicht zum 31. Oktober 2007 vorsah.

Die Klage der Fluggesellschaften gegen den neuen Bescheid wurde am 19. und 21. Dezember 2006 vor dem OVG in Berlin verhandelt. Ein vom OVG vorgeschlagener Vergleich zur Anerkennung eines auf Oktober 2008 neu datierten Bescheides scheiterte an der fehlenden Zustimmung der meisten klagenden Luftfahrtunternehmen. Der Berliner Senat griff den Vergleich des OVG auf und änderte nochmals den "Bescheid zum Widerruf der Betriebserlaubnis für den Flughafen Tempelhof", der nun als Datum für die Schließung den 31. Oktober 2008 vorsah. Das Oberverwaltungsgericht Berlin-Brandenburg und das Bundesverwaltungsgericht haben die Senatsentscheidung schließlich bestätigt.

Um die Schließung des Flughafens doch noch zu verhindern, wurde von der "Interessengemeinschaft City-Airport Tempelhof" (kurz: "ICAT") ein Volksentscheid angestrebt.

Dazu wurden zunächst seit Ende November 2006 Unterschriften für die Unterstützung eines Volksbegehrens gesammelt. Am 8. Mai 2007 bestätigte der Berliner Senat die Sammlung von knapp 30.000 gültigen Unterschriften. Damit wurde der nach der Verfassung von Berlin erforderliche Nachweis von mindestens 20.000 Unterstützern für die Einleitung eines Volksbegehrens erbracht. In der Zeit vom 15. Oktober 2007 bis zum 14. Februar 2008 konnte jeder wahlberechtigte Berliner per Unterschrift in einem der Berliner Bürgerämter das Volksbegehren unterstützen. Bereits am 30. Januar 2008 wurde das nötige Quorum von 170.000 Unterschriften erreicht. Insgesamt wurden gut 208.000 Zustimmungserklärungen abgegeben. Der anschließende Volksentscheid fand am 27. April 2008 statt. Er wurde abgelehnt, da bei einer Wahlbeteiligung von 36,1 % zwar 60,1 % der Teilnehmer dafür stimmten, jedoch bezogen auf alle Wahlberechtigten sich damit nur eine Zustimmung von 21,7 % ergab; notwendig wäre ein Viertel der Abstimmungsberechtigten gewesen. Die Kosten für die Durchführung des Volksentscheides betrugen rund 2,5 Millionen Euro. Gegen das festgestellte Ergebnis des Volksentscheids wurde von der ICAT Verfassungsbeschwerde beim Verfassungsgerichtshof eingelegt. Am 27. Oktober 2008 entschied dieser, dass der Volksentscheid nicht wiederholt werden muss.

Die Senatsverwaltung für Stadtentwicklung hatte am 7. Juni 2007 den Bescheid zur Entwidmung des Flughafengeländes zum 31. Oktober 2008 verkündet. Gegen diesen Bescheid wurden zwei Klagen beim Oberverwaltungsgericht eingereicht. Dieses wies am 17. Dezember 2008 die Klage der ICAT als unbegründet zurück, die eines Privatmannes erklärte sie für unzulässig. Beide Kläger seien in ihren eigenen Rechten nicht verletzt worden. Eine Revision wurde nicht zugelassen. Auf die Einstellung des Flugbetriebes hatte das Verfahren keine Auswirkung.

Der letzte Charterflug und gleichzeitig der letzte Start eines Jets von Berlin-Tempelhof erfolgte am 30. Oktober 2008 um 22:12 Uhr mit der Boeing 737-700 D-ABAB der Air Berlin unter Flugnummer AB1001 mit den Kapitänen Funke und Altenscheidt im Cockpit, der in Zusammenarbeit mit dem Essener Sonderflugveranstalter Airevents durchgeführt wurde. Der Flug landete nach nur 22 Minuten um 22:34 Uhr in Berlin-Tegel und beendete damit die Geschichte der Jetfliegerei ab Tempelhof. Nur fünf Minuten später startete um 22:17 Uhr eine Dornier 328 der Cirrus Airlines mit dem Kennzeichen D-CIRP als letzter Linienflug in Richtung Mannheim. Cirrus Airlines und einige ihrer Piloten hatten eine besondere Bindung zum Flughafen Tempelhof, und so verabschiedete sich der letzte Abflug dieser Airline aus Tempelhof bei Tageslicht gegen 16:45 Uhr mit dem Flugzeug D-COSA mit einer Ehrenrunde über dem Südteil der Stadt und einem nochmaligen tiefen Überflug über die Piste 27L vom Flughafen. Die letzten Flugzeuge, die in Tempelhof offiziell starteten, waren eine Douglas DC-3 "(Rosinenbomber)" und die Junkers Ju 52/3m „Berlin-Tempelhof“ der "Deutschen Lufthansa Berlin-Stiftung", die um 23:55 Uhr parallel von den beiden Startbahnen abhoben, mit den Flügeln winkten und nach Südwesten, Richtung Schönefeld wegdrehten.

Die letzte offizielle Landung eines Flugzeuges in Berlin-Tempelhof machte die Piper PA31T1 Cheyenne I mit der Registrierung D-ILCE. Sie landete am 30. Oktober 2008 nach 22 Uhr auf einem Ambulanzflug und verließ den Flughafen nach einem kurzen Aufenthalt am GAT-Bereich wieder.

Drei unter Sichtflug (Visual Flight Rules, VFR) betriebene Kleinflugzeuge mussten am 30. Oktober 2008 wegen schlechter Witterungsbedingungen weiterhin am Flughafen verbleiben. Sie konnten erst nach einer behördlichen Außenstartgenehmigung am 24. November 2008 als nunmehr allerletzte Starts den Flughafen verlassen. Dieses waren die Antonow An-2 Doppeldecker D-FBAW der Fluggesellschaft LTS MiniHansa und D-FWJC der Fluggesellschaft Air Tempelhof, die am 24. November 2008 um 12:11 Uhr sowie 12:12 Uhr kurz hintereinander in Richtung Strausberg und Finow starteten; gefolgt von der Beechcraft F33A Bonanza D-EDBS, die um 12:15 Uhr den Flughafen Tempelhof in Flugrichtung Schönhagen verließ.

Die derzeit letzte Flugbewegung gab es auf dem Flughafen Tempelhof am 26. Juni 2010. Die vom Flughafen Tegel kommende Socata TB 10 Tobago mit dem Kennzeichen D-EGKJ befand sich auf einem Rundflug über der Stadt. Aufgrund eines Leistungsverlustes des Triebwerks entschied sich der Pilot zu einer Notlandung auf der Piste 27L des mittlerweile geschlossenen Flughafens Tempelhof, um kein weiteres Risiko einer Außenlandung mitten im Stadtgebiet einzugehen. Der Wiederstart der Maschine von Tempelhof wäre theoretisch möglich gewesen. Die Genehmigung dazu wurde vom Senat allerdings nicht erteilt, und so musste das Flugzeug teilweise demontiert und letztendlich am 30. Juni 2010 auf einem Tieflader vom Gelände gebracht werden.

Das Flughafengelände gehörte als früheres Reichsvermögen ursprünglich dem Bund, seit 2005 der Bundesanstalt für Immobilienaufgaben (BImA) sowie dem Land Berlin als Miteigentümer. Im Jahr 2009 verkaufte die BImA dem Land Berlin ihren Anteil zu einem Preis von 35 Millionen Euro. Der Umstand, dass Berlin nunmehr alleiniger Eigentümer des denkmalgeschützten Gebäudekomplexes und der großen Freiflächen ist, erleichtert die Planung und Umsetzung von Entwicklungskonzepten.

Das Land Berlin hatte nach der Wiedervereinigung Ansprüche auf ehemaliges Reichsvermögen geltend gemacht, darunter auch auf die damals bundeseigenen Flächen des Flughafens Tempelhof; der Bund lehnte die Ansprüche ab. Ein Normenkontrollantrag des Landes vor dem Bundesverfassungsgericht hatte keinen Erfolg. Ob die Voraussetzungen für einen Rückfallanspruch Berlins nach dem Reichsvermögen-Gesetz auf die Bundesflächen des Flughafens vorlagen, steht nicht fest, da das Land die maßgebliche Frist versäumt hatte. Mittlerweile versucht Berlin auf dem Verwaltungsrechtsweg, seine Ansprüche weiterzuverfolgen, und ist dabei in zweiter Instanz unterlegen.

Verschiedene Nachnutzungskonzepte wurden diskutiert und teilweise wieder verworfen. So bestand eine Planung, dass im Jahr 2017 auf dem Gelände die Internationale Gartenschau (IGA) stattfinden sollte. Im Juli 2012 hat der Berliner Senat diese Pläne wieder verworfen, da sich die Parknutzung durch die Bürger besser als erwartet entwickelte und somit eine Steigerung der Attraktivität des Geländes zu diesem Zweck nicht mehr nötig erschien. In diesem Zusammenhang gab es im Vorfeld Proteste gegen die kostenpflichtige IGA, die die Nutzung des Tempelhofer Feldes für viele Besucher einschränken würde. Für das Jahr 2020 war geplant, einen Teil der Internationalen Bauausstellung (IBA) auf dem Gelände auszurichten.

Anfang August 2013 wurde ein bis dahin unter Verschluss gehaltenes Gutachten bekannt, das die Kosten für die notwendige Sanierung des Gebäudes mit 478 Millionen Euro beziffert. Zum reinen Substanzerhalt seien 144 Millionen Euro notwendig.

Die Berliner Senatsverwaltung für Stadtentwicklung hat am 5. März 2008 als Folgenutzungskonzept für das Flughafengelände das städtebauliche Projekt "Tempelhofer Freiheit" vorgestellt. Die Grundlage bildete das 1998/1999 erarbeitete Planungskonzept "Vom Flughafen zum Park der Luftbrücke." Darin vorgesehen ist die Einrichtung eines "Tempelhof Forum THF" für Kultur-, Medien- und Kreativwirtschaft im denkmalgeschützten ehemaligen Flughafengebäude und den südlich anschließenden befestigten Vorfeldflächen. An den Rändern des ehemaligen Flugfeldes sollen neue Wohnanlagen der Stadtquartiere Tempelhof (westlich bis südlich), Neukölln (östlich) und dem neuen nordöstlichen Columbiaquartier entstehen. Dazwischen soll die rund 220 Hektar große unbebaute Grünfläche des ehemaligen Flugfeldes als Parklandschaft mit zahlreichen Freizeitnutzungen erschlossen werden. Das überwiegend offengehaltene Wiesengelände soll dann auch weiterhin dem Temperaturausgleich des Stadtklimas dienen.

Seit dem 8. Mai 2010 ist der Tempelhofer Park, der sich auf dem ehemaligen Flugfeld befindet, für die Öffentlichkeit zugänglich. Das Betreten des Geländes ist tagsüber durch zehn Eingänge möglich, die am Tempelhofer Damm, am Columbiadamm und an der Oderstraße liegen.

Eine Volksinitiative wendet sich gegen den Namen "Tempelhofer Freiheit", da damit die NS-Geschichte dieses historischen Ortes verharmlost werde.

Seit der Schließung am 30. Oktober 2008 haben rund 26.000 Besucher (Stand: September 2010) das denkmalgeschützte Flughafengebäude besichtigt.

Nach dem gescheiterten Volksentscheid zur Rücknahme des Schließungsbeschlusses des Berliner Senats erneuerte das Filmstudio Babelsberg das Angebot, im Tempelhofer Flughafengebäude in mehrere Filmateliers sowie Europas größten Requisiten- und Kostümfundus investieren zu wollen.

Am 29. Januar 2009 unterzeichnete die für den Flughafen Tempelhof zuständige Berliner Immobilienmanagement GmbH (BIM) einen zehn Jahre laufenden Nutzungsvertrag mit der Modemesse "Bread & Butter." Die Modemesse wird zweimal jährlich für jeweils einen Monat sämtliche Hangars, das Vorfeld sowie die Haupthalle des ehemaligen Flughafens Tempelhof anmieten.

Seit 2009 findet zweimal im Jahr die Messe "Berlin Vital", die zum Rahmenprogramm des alljährlichen Berliner Halbmarathons im Frühjahr sowie des Berlin-Marathons im Herbst gehört, im Gebäude des ehemaligen Flughafens statt. Die Messe ist nach Angaben des Veranstalters die größte deutsche Sport- und Gesundheitsmesse.

Die Jugendmesse "YOU" sowie die internationale Messe für Umwelttechnologie "Clean Tech World" fanden zum ersten Mal im September 2010 in Tempelhof statt.

Anfang August 2009 beschloss der Berliner Senat in Zusammenarbeit mit dem Berliner Eissportverband und der Eishockeymannschaft des "ECC Preussen", dass im ehemaligen Hangar 3 eine Eisfläche installiert werden soll. Diese Eisfläche wurde gebaut, da der Verein aufgrund der Schließung der Deutschlandhalle eine Ersatzfläche für seine knapp 800 Eissportler braucht. Zuerst ohne Tribünen und nur für den Trainingsbetrieb geplant, entstanden zur Eishockey-Saison 2010/2011 drei kleine Tribünen, die insgesamt durch 199 Zuschauer genutzt werden können.

Mehrere Hangars des Flughafens wurden Ende September / Anfang Oktober 2009 zur Austragung eines hochdotierten nationalen Reitturniers genutzt, das als "Hauptstadtturnier" bezeichnet wird. Ebenfalls im Oktober 2009 fand das Funsport-Event "Swatch freestyle.berlin" statt. Im November 2009 wurde auf dem Gelände der "17. Kondius Berliner Marathon-Staffel-Wettbewerb" ausgetragen.

Am 4. Oktober 2009 hat die "Turngemeinde in Berlin 1848 e. V." (TiB) die Freiluft-Sportanlagen auf dem Gelände des ehemaligen Flughafens in Berlin-Tempelhof wieder in Betrieb genommen. Die TiB übernahm beide Softball-Felder, das östliche wurde für den Baseballbetrieb der Berlin Rangers umgebaut. Zur Anlage gehören noch zwei Tennisfelder, sowie ein Sandplatz für Speed-Badminton, Beachvolleyball und Beachsoccer.

Die FIA-Formel-E-Meisterschaft, eine Serie von ausschließlich mit Elektroantrieb betriebenen Rennwagen, trug in der Saison 2014/15 auf einer temporären Rennstrecke auf dem ehemaligen Vorfeld des Flughafens den Berlin ePrix 2015 aus.

Der asphaltierte Rundkurs ist vor allem bei Läufern sehr beliebt. Die Streckenlänge beträgt 6218 Meter und ist läuferisch wenig anspruchsvoll, da der Rundkurs mit nur 53 Höhenmetern keine nennenswerten Steigungen aufweist. Startpunkt ist der Haupteingang am Columbiadamm und man folgt der mit lilafarbenen Punkten markierten Strecke im Uhrzeigersinn.

Im Zusammenhang mit der Flüchtlingskrise in Deutschland ab 2015 werden Hangars des Flughafens seit Ende Oktober 2015 zeitweise als Notunterkünfte für Flüchtlinge genutzt. Im Februar 2017 wurde die Baugenehmigung für ein Containerdorf im Randbereich des Flugfeldes erteilt, die Bauarbeiten begannen noch im selben Monat. Die sogenannten Tempohomes sollen Platz für über 1000 Geflüchtete bieten und längstens bis 2020 genutzt werden.

Aus Protest gegen die Nachnutzungspläne versuchten mehrere tausend Aktivisten, die sich in dem Bündnis "Squat Tempelhof" zusammengeschlossen hatten, am 20. Juni 2009 das Gelände zu besetzen. Dazu aufgerufen hatten neben Mieterbündnissen auch die Grünen. Die Demonstranten kritisierten, dass die Fläche nicht für die Öffentlichkeit freigegeben wurde und befürchteten neben einer zunehmenden Privatisierung und Kommerzialisierung einen vorangetriebenen Gentrifizierungsprozess. Die Besetzung wurde jedoch von der Polizei verhindert, die mit etwa 1500 Beamten im Einsatz war. 102 Demonstranten wurden festgenommen.

Im September 2011 gründete sich im östlich an die Parkfläche angrenzenden Schillerkiez unter dem Titel "100 % Tempelhofer Feld" eine Bürgerinitiative mit dem erfolgreichen Ziel, die Nachnutzungspläne des Senats im Wege eines Berlin-weiten Volksentscheides zu kippen und eine Bebauung des Geländes zu verhindern. Nach Vorstellung der Initiative solle die Freifläche weder mit einem Neubau der Landesbibliothek, Wohn- und Gewerbeimmobilien, noch der Internationalen Gartenausstellung versehen und für Parkbesucher in ihrem natürlichen Zustand belassen werden. Die Unterschriftensammlung für das Volksbegehren gegen die Bebauung des Tempelhofer Feldes lief bis zum 13. Januar 2014 und brachte rund 185.000 Unterschriften. Der Volksentscheid über den Erhalt des Tempelhofer Feldes fand am 25. Mai 2014 statt: 64 % der abgegebenen Stimmen waren für den Volksentscheid, 36 % dagegen. Das notwendige Abstimmungsquorum von mindestens 25 % wurde mit 30 % überboten.

Das Gelände des ehemaligen Flughafens erstreckt sich auf eine Fläche von vier Millionen Quadratmetern, wovon das Vorfeld 486.000 m² einnimmt; auf diesem befanden sich 60 Flugzeugabstellpositionen, wovon 40 der Allgemeinen Luftfahrt zustanden. Zur Wartung standen sieben Hangars zur Verfügung, deren Bruttogrundfläche insgesamt 52.250 m² beträgt. 19.200 m² davon sind die offenen Abfertigungsflächen A1 und A2. Der Flughafen verfügte über zwei Start- und Landebahnen, deren Oberfläche jeweils aus Asphalt besteht. "09R/27L" ist 1840 Meter lang und 42,5 Meter breit; sie war für Anflüge in beiden Richtungen für das Instrumentenlandesystem (ILS) in der Kategorie I sowie für Nichtpräzisions-Instrumentenanflüge (NDB/DME) zugelassen. "09L/27R" ist 2094 Meter lang und ebenfalls 42,5 Meter breit; sie konnte für Nichtpräzisions-Instrumentenanflüge (VOR/DME) und unter Sichtflugbedingungen benutzt werden. Instrumentenabflüge waren von beiden Bahnen in alle Richtungen möglich.

Mit dem neoklassizistischen Neubau des Flughafens Tempelhof ab 1934 durch den Architekten Ernst Sagebiel wurden erstmals alle Anforderungen eines modernen Großflughafens in einer architektonischen Gesamtform mit getrennten Funktionsebenen für Ankunft, Abflug, Post- und Frachtverkehr organisiert. Die in der Gebäudeanlage verwirklichte funktionale Komplexität (Ebenentrennung sowie zahlreiche – erst heute allgemein übliche – Sekundärfunktionen wie Hotels, Kongresszentrum, Großrestaurants, Lufthansa-Verwaltungen) war zum Zeitpunkt der Entstehung als Flughafen einzigartig und ist in zahlreichen Bestandteilen Vorbild für moderne Flughafenanlagen geworden. Der britische Architekt Lord Norman Foster bezeichnete den Flughafen daher im Jahr 2004 als „die Mutter aller Flughäfen“. Diese Metapher bekräftigte er 2009 und fügte hinzu: „Tempelhof müsste eine Sache des nationalen Gewissens sein – es ist viel zu bedeutend, um auf dem Altar kommerzieller Immobilienentwicklung geopfert zu werden.“ Wegen seiner besonderen ingenieurtechnischen Bedeutung wurde das Bauwerk am 1. Juni 2011 von der Bundesingenieurkammer mit dem Titel "Historisches Wahrzeichen der Ingenieurbaukunst in Deutschland" ausgezeichnet.

Der Flughafen teilt sich in die mehr als 1200 Meter lange Flughalle mit Hangar und die Empfangs- und Verwaltungsgebäude. Das Empfangsgebäude befindet sich axial dem Hallenbogen angeschlossen, umschließt einen Vorplatz dreiseitig und schafft einen Übergang zu dem dahinter liegenden heutigen Platz der Luftbrücke. Dieser Platz war als Rundplatz konzipiert und sollte einen Durchmesser von 250 Metern haben. Die am Platz liegenden viergeschossigen Bauten sollten einen Dreiviertelkreis um den Platz legen und Dienste wie Luftpostamt und Frachthof aufnehmen. Die vorgesehene Bebauung ist allerdings nur auf der Ostseite des Platzes verwirklicht. Die Außengebäude sind, ähnlich wie viele andere Bauten aus der Zeit des Nationalsozialismus, mit Natursteinplatten aus Muschelkalk verkleidet. Die Gesamtanlage steht unter Denkmalschutz. Seit Dezember 2007 liegt dem UNESCO-Welterbe-Komitee ein Antrag auf Ernennung zum Weltkulturerbe vor.

Vom letzten freien Viertel des Rundplatzes, das sich gegenüber dem Empfangsgebäude geöffnet hätte, sollte eine Wasserkaskade bis zum naheliegenden Kreuzberg reichen.

Diese Wassertreppe wurde allerdings nicht verwirklicht. Die damit durch die Haupthalle verlaufende Achse der Flughafen-Anlage ist in ihrer Richtung auf das Kreuzbergdenkmal von Karl Friedrich Schinkel orientiert. Der Flughafen sollte, den Wünschen Adolf Hitlers entsprechend, seine monumentale Wirkung östlich der geplanten Nord-Süd-Achse entfalten.

Die Anlage des Flugfeldes entsprach den zum Planungszeitpunkt gültigen Bedingungen, indem sie für den Betrieb kleiner Flugzeuge als Rasenfläche mit vier betonierten Start-Taschen ausgelegt wurde. Hierdurch war ein Starten und Landen der noch relativ leichten Fluggeräte exakt gegen den Wind möglich. Die Gesamtform als Oval erfüllte neben der idealen windrichtungsneutralen Form zugleich die Anforderungen als Luftstadion für die von Hermann Göring vorgesehenen Flugschauen.

Die Passagierhalle teilt das Gebäude in zwei Hälften und ist hundert Meter lang und fünfzig Meter breit. Daran schließen sich unmittelbar zu beiden Seiten die Hangars an. Diese – alle Funktionen eines Flughafens integrierende Anordnung – die heute wegen der damit verbundenen geringeren Flexibilität unüblich ist, war wesentlicher Konzeptbestandteil mit dem Ziel, Zusammenhang und Größe zu demonstrieren.

Eine technische Meisterleistung ist die über 40 Meter weit auskragende stählerne Dachkonstruktion entlang des Flugsteigs. Flugzeuge bis zu einer Höhe von fast zwölf Metern können unter das Dach des Flugsteigs rollen, um dort abgefertigt zu werden. Das Flughallendach war ursprünglich auch als Tribünenbereich für mehr als 100.000 Zuschauer gedacht, wie bei Flugschauen zu den Reichsflugtagen. Eine weitere Besonderheit ist, dass die gesamte Dachanlage nicht nur im Bezug auf ihr eigenes Gewicht freitragend ist, sondern auch Schneemassen von mehreren Metern Höhe problemlos aufnehmen kann. Die Stadtseite der gebogenen Hangar- und Hallenanlage wird durch die sich in gleichen Abständen befindenden Treppentürme zur Erschließung der von Hermann Göring auf dem Dach vorgesehenen Zuschauer-Tribünen gegliedert. Die Treppentürme waren so ausgelegt, dass 100.000 Zuschauer in weniger als 30 Minuten die Dachtribünen hätten erreichen können, für die damalige Zeit eine ausgeklügelte logistische Meisterleistung. Diese – seit der Bauzeit im Rohzustand belassenen und für die Öffentlichkeit nie genutzten – unzugänglichen Treppenhäuser bestimmen die dominante Erscheinungsweise des Gebäudes; allein hierdurch wird der Zeitbezug zur Architektur des Nationalsozialismus deutlich.

Der aktuelle Betreiber, die Tempelhof Projekt GmbH, bietet Führungen an, bei denen die ansonsten nicht zugänglichen Bereiche besichtigt werden können. Hierzu zählt auch der als Ballsaal gedachte Raum über der Abfertigungshalle, der in seiner Funktion nie fertiggestellt wurde. Während der Nutzung durch die amerikanischen Streitkräfte wurde hier eine Basketball-Halle errichtet, die noch immer so erhalten ist. Im Nebenraum befindet sich eine Bar, die als Entertainment-Bereich mit Billard-Tischen und Bowling-Bahnen genutzt wurde.

Berlins Regierender Bürgermeister Michael Müller erklärte am 12. November 2015, dass aufgrund anhaltend hoher Flüchtlingszahlen bis auf weiteres die Hangars und die überdachte Haupthalle für die Flüchtlingsregistrierung und -unterbringung benötigt und damit andere Nutzungen ausgeschlossen würden.

Der ehemalige Flughafen Berlin-Tempelhof hat außerdem umfangreiche unterirdische Anlagen, die über drei Etagen hinab in die Tiefe reichen. Mit der Aufgabe des Ausbaus 1942 wurden diese sowie auch einige oberirdische Elemente nicht weitergebaut. Unterirdisch wurden beispielsweise Fertigungsanlagen für Flugzeuge (im Zweiten Weltkrieg), Filmarchive, Kraftwerke und die spätere Kommandozentrale der US Army untergebracht. Dabei wird die Größe des „Tunnellabyrinths“ legendenhaft überschätzt. Die von Fotos her bekannte Endmontage von Jagdflugzeugen fand erst 1945 an der Endstation des Eisenbahntunnels am Hauptgebäude statt, und zwar in einer Halle, die zu einem tief gelegenen Innenhof hin offen ist. Im Zweiten Weltkrieg wurden die unterirdischen Räume auch für die Bevölkerung unverzichtbar als Luftschutzbunker genutzt, wobei Überreste von „Wandmalereien“ nach Motiven von Wilhelm Busch erhalten geblieben sind. Sie wurden auch während der Nutzung der Räume durch die amerikanische Luftwaffe bis 1993 nicht entfernt. Die Wände der Räume wurden zwar mehrfach weiß gestrichen, doch es wurde um die Gemälde sorgsam herumgestrichen, sodass die Wandmalereien nicht beschädigt wurden.

Eine weitere Besonderheit ist eine in die unterirdische Ebene hinein verlaufende Straße zur Versorgung des Flughafens und Anlieferung von Gütern sowie ein Eisenbahntunnel. Der Tunnel wurde über einen im Westen und Süden am Flughafenrand verlaufenden Gleisanschluss zum Güterbahnhof Hermannstraße, an dem auch die Neukölln-Mittenwalder Eisenbahn beginnt, an das Eisenbahnnetz der Deutschen Reichsbahn angebunden.

Im südöstlichen Anschluss an das Gebäudeteil Columbiadamm 1–9 befindet sich in fünf Meter Tiefe ein zweigeschossiger Bunkerbau, der sogenannte „Filmbunker“. Seine untere Fußbodensohle ist mit 12,50 Meter das tiefstgelegene Stockwerk des gesamten Flughafenbaus. Der Filmbunker diente der Hansa Luftbild und der Luftwaffe zur Lagerung von Kartenmaterial und Luftbildaufnahmen auf Zelluloid, wofür auch eine aufwendige Lüftungsanlage eingebaut wurde. War bislang angenommen worden, dass der Zugang zum Bunker im April 1945 durch sowjetische Truppen aufgesprengt und sein Inhalt durch den dadurch ausgelösten Brand vollständig vernichtet worden war, ist inzwischen erwiesen, dass das über 1200 °C heiße mehrtägige Feuer nicht durch äußere Explosion entstanden sein konnte. „Also bleibt eigentlich nur die Möglichkeit, dass die Deutschen den Inhalt des Bunkers selbst und mit voller Absicht vernichtet haben, um ihn nicht dem Feind in die Hände fallen zu lassen.“ Die Spuren des Feuers sind heute noch sichtbar; Rohrleitungen, Überdruckventile und Aktivkohlefilter-Reinigungsanlagen der Lüftung sind ebenfalls erhalten.

Der markante und über 71 Meter hohe Turm der RRP 117-Radaranlage östlich des Flughafengebäudes wurde 1982 so konstruiert und errichtet, dass sich die durch den Wind verursachten Turmbewegungen kaum auf die Qualität des Radarbildes auswirken. Es wurde bewusst eine dem monumentalen Baustil des Flughafens entgegengesetzte filigrane und moderne Bauform gewählt.

Bis zu Beginn der 1990er Jahre, als der Flughafen noch von der US Air Force betrieben wurde, gab es einige weitere Navigationsanlagen am Flughafen. Sie wurden mit dem Abzug der amerikanischen Streitkräfte abgebaut, da es sich größtenteils um rein militärisch nutzbare Anlagen handelte. So existierte südlich der südlichen Start- und Landebahn auf Höhe der Bahnmitte ein Präzisionsanflugradar (PAR), das für die Südbahn genutzt wurde. Auf dem Dach des Gebäudes in Höhe des GAT befand sich ein Flughafenrundsichtradar (ASR). Die Radaranlage selbst ist abgebaut, allerdings ist die Trägerkonstruktion immer noch erhalten. Bereits im Oktober 1984 wurde ein auf dem Dach des Gebäudes befindlicher Funkhöhenmesser abgebaut.

Zuletzt haben lediglich vier Fluggesellschaften den Flughafen Berlin-Tempelhof im Linienbetrieb angeflogen. Diese waren unter anderem Brussels Airlines, InterSky sowie Cirrus Airlines. Daneben gab es mehrere Fluggesellschaften wie die am Flughafen ansässige Windrose Air, die mit ihren Maschinen Flüge der Allgemeinen Luftfahrt durchführten. Die sogenannte ‚Executive-Fliegerei‘ nutzte für Flüge nach Berlin in großem Maße den Flughafen Tempelhof, weil er aufgrund der Lage eine einzigartig schnelle Anbindung an das Stadtzentrum bot. Darüber hinaus wurden von Tempelhof aus vom Air Service Berlin Rundflüge mit einem restaurierten ‚Rosinenbomber‘ vom Typ Douglas DC-3 angeboten. Die Luftschiffgeneration Zeppelin NT benutzte den Flughafen als Ausgangspunkt ihrer Fahrten. Außerdem gab es nördlich der Start- und Landebahnen noch mehrere Hubschrauber-Bahnen im Grasgelände, die später allerdings nicht mehr genutzt wurden.

Frequenzen

Funkfeuer

Landehilfen

Wichtige Navigationspunkte

Über die Geschichte und Architektur des Flughafens Berlin-Tempelhofs wurde unter anderem auch eine detaillierte Dokumentation für das ARD-Fernsehen unter dem Titel "Geheimnisvolle Orte 2/7: Die Katakomben von Tempelhof" gedreht.

In den folgenden Filmen diente der Flughafen als Kulisse:

Der Flughafen war ebenfalls Kulisse in mehreren Folgen der Sat.1-Telenovela "Schmetterlinge im Bauch", der ARD-Vorabendserie "Berlin, Berlin" sowie der Sat.1-Serie "HeliCops – Einsatz über Berlin" (später wurde die Kulisse im brandenburgischen Briest nachgebaut).

In einigen Filmen, in denen der Flughafen auftaucht, handelt es sich jedoch nur um eine Studiokulisse oder einen anderen Flughafen, der als Kulisse dient. Bekannte Filme aus dieser Kategorie sind beispielsweise "Indiana Jones und der letzte Kreuzzug" von Steven Spielberg oder "The Good German – In den Ruinen von Berlin" von Steven Soderbergh.

Für einige Musikvideos ist der Flughafen Berlin-Tempelhof ebenfalls als Drehort ausgewählt worden: So sind in dem 1999 erschienenen Video zum Lied "1, 2, 3 Rhymes Galore (From New York to Germany)" von DJ Tomekk einige Aufnahmen während des laufenden Flugbetriebes in der Haupthalle und in angrenzenden Räumen entstanden. Im Jahr 2011 diente die Haupthalle des mittlerweile stillgelegten Flughafens als Kulisse zum Musikvideo zu "Hollywood Hills" der finnischen Band Sunrise Avenue.

In Folge 8 der 2. Staffel der Dokufiktion-Serie "Zukunft ohne Menschen" ("Chaos am Himmel", USA 2010) dient der Flughafen als Beispiel für den Verfall von Flughafenanlagen nach einem fiktiven Verschwinden der Menschheit.

Der Flughafen spielt eine hervorgehobene Rolle im Spiel "TwinKomplex", als Sitz einer mutmaßlichen Geheimorganisation.

Im Mai 2014 diente das Flughafengebäude als Kulisse für Dreharbeiten zum dritten Teil der Verfilmung der Romanreihe "Die Tribute von Panem".

Am ehemaligen Flughafen gab es ein Heizkraftwerk sowie ein Wasserwerk zur Versorgung des Flughafens. Die Ressourcen reichten auch für die Versorgung des damaligen Bezirks Tempelhof, was insbesondere zur Zeit der Luftbrücke von großer Bedeutung war. Wichtig für die militärische Luftraumüberwachung der NATO war während des Kalten Krieges das Radar am nordöstlichen Ende des Hauptgebäudes. Das 100 m² große Areal wird bis heute von der Bundeswehr genutzt.

Bei den Zahlen handelt es sich bis 1972 um Summen der Flughäfen Berlin-Tempelhof und Berlin-Tegel, 1973 zusätzlich mit Flughafen Berlin-Schönefeld. Von 1974 bis 1991 sind keine Zahlen verfügbar.





</doc>
<doc id="1667" url="https://de.wikipedia.org/wiki?curid=1667" title="Freiburg">
Freiburg

Freiburg steht als Ort für:
Freiburg steht als Kanton für:
und als Verwaltungseinheit für:
Freiburg steht für:
Siehe auch:


</doc>
<doc id="1670" url="https://de.wikipedia.org/wiki?curid=1670" title="Fuge (Musik)">
Fuge (Musik)

Die Fuge (von lateinisch "fuga" „Flucht“) ist ein musikalisches Kompositionsprinzip polyphoner Mehrstimmigkeit. Kennzeichnend für die Fuge ist eine besondere Anordnung von Imitationen zu Beginn der Komposition: Ein musikalisches Thema wird in verschiedenen Stimmen zeitlich versetzt wiederholt, wobei es jeweils auf unterschiedlichen Tonhöhen einsetzt (in der Regel abwechselnd auf dem Grundton und der Quinte).

Eine Fuge kann eine eigenständige Komposition sein. Fugen wurden oft zusammen mit einem vorangehenden Präludium komponiert. Fugen und fugenartige Strukturen werden aber auch innerhalb von Werken anderer Formen verwendet, z. B. in Kantaten, Messen, Konzerten, Symphonien oder Ouvertüren.

Der Begriff "Fuga" wurde bereits im 14. Jahrhundert für den Kanon verwendet, später auch allgemein für Imitationen. Noch bei den Komponisten der franko-flämischen Schule bezeichnet "Fuga" oder "ad fugam" kanonische Kompositionen, obwohl in der Polyphonie des 16. Jahrhunderts bereits die ersten im späteren Sinne der Fuge angelegten Strukturen auftauchen. Erst im Laufe des 17. Jahrhunderts werden solche Stücke als "Fugen" bezeichnet.

Besonderes Kennzeichen der Fuge ist ihre komplexe Themenverarbeitung. Eine Fuge beginnt mit der "Exposition" der Stimmen: Die erste Stimme trägt das – meist kurze und prägnante – Thema vor. Dieser Themeneinsatz wird auch als "Dux" (lat. "dux" „Führer“) bezeichnet. Hierzu gesellt sich in der Folge eine zweite Stimme, die das Thema nun als "Comes" (lat. "comes" „Gefährte“) meist auf die Oberquinte (bzw. Unterquarte) versetzt vorträgt.

Wenn im Themenkopf des Dux der Quintton über dem Grundton exponiert erscheint, wird dieser im "Comes" meist zur Quarte abgewandelt (tonale Beantwortung), um die Identität der Tonart zu gewährleisten. Diese Technik geht auf die Anordnung der Modi zurück. Andernfalls wird das Thema intervallgetreu („real“) transponiert.

Weitere Stimmen können nach diesem Prinzip hinzukommen, bis die volle Stimmenzahl (meistens 3 oder 4, seltener 5 oder mehr) erreicht ist.

Bringt die erste Stimme während des zweiten Themeneinsatzes motivisch oder thematisch bedeutsames Material, das später wieder aufgegriffen wird (in manchen Fällen sogar als neues Thema), so spricht man von einem Kontrasubjekt. Das Kontrasubjekt muss mit dem Thema einen doppelten Kontrapunkt bilden, um sowohl über als auch unter dem Thema erscheinen zu können, ohne die Stimmführungsregeln zu verletzen.

Alle Abschnitte, in denen das Thema – in verschiedenen Stimmen – vorgetragen wird, heißen "Durchführungen" (nicht zu verwechseln mit der Durchführung des Sonatensatzes) oder "Thema-Phasen", wobei der Beginn der Fuge, also die "Exposition" bereits die erste "Durchführung" darstellt. Die weiteren Themeneinsätze bzw. "Durchführungen" können u. a. auch in der Paralleltonart der Grundtonart sowie der Ober- und Unterquinttonart stehen. Ab dem 19. Jahrhundert erscheint das Thema auch in noch entfernteren Tonarten.

Es gibt verschiedene Fugentypen. In den meisten Fällen sind die Themeneinsätze durch "Zwischenspiele" miteinander verbunden, die im Allgemeinen der Modulation dienen und oft aus Sequenzen bestehen. Andere Fugen besitzen überhaupt keine "Zwischenspiele" (z. B. C-Dur, WK I, BWV 846). Einen besonderen Fall stellt hier die Fuge in cis-Moll von J. S. Bach (WK I, BWV 849) dar, die drei Themen beinhaltet. Diese werden der Reihe nach eingeführt und im weiteren Verlauf ständig miteinander enggeführt, sodass neben fehlenden "Zwischenspielen" auch kaum Raum für themenfremdes Material überhaupt bleibt. Für die formale Gliederung ist in solchen Fällen weniger die Tonart eines jeden Einsatzes als vielmehr die zugrundeliegende Kadenzordnung entscheidend – sprich: welche Stufen der Grundtonart werden durch eine erkennbare Kadenz erreicht?

In den "Thema-Phasen" können neben Engführungen des Themas auch Umkehrungen, Augmentationen (Vergrößerung der Notenwerte), Diminutionen (Verkleinerung) etc. von Thema oder Kontrasubjekt auftreten.

Vor dem Ende einer Fuge wird manchmal ein Orgelpunkt – auf der Dominante oder der Tonika – eingefügt, sei es als Signal für den kommenden Schluss oder bereits als Ausgestaltung desselben. Ein bekanntes Beispiel dafür ist die hier zitierte Fuge c-Moll (WK I) oder die g-Moll-Fuge aus der Sonate für Violine solo (BWV 1001) von J. S. Bach.

"Das Wohltemperierte Klavier", Teil I, Fuga Nr. 2 in c-Moll   

Diese dreistimmige Fuge von Johann Sebastian Bach beginnt mit einer typischen Exposition, die sich bis zum Anfang von Takt 9 erstreckt. Es beginnt zunächst die Altstimme, es folgen der Sopran in Takt 3 und der Bass in Takt 7.

Das "Thema" hat eine Ausdehnung von zwei Takten. Es erscheint, wie bei Fugen üblich, zu Beginn allein, um sich vorzustellen, und zwar in der Grundtonart c-Moll.

Die "Beantwortung des Themas" stellt eine genaue Transposition des Themas auf die Oberquint-Tonart g-Moll dar, mit einer Ausnahme: die vierte Note ist c, nicht d, wie eigentlich zu erwarten wäre. Diese kleine Veränderung ist notwendig, um die Grundtonart noch über den 2. Themeneinsatz hinaus beibehalten zu können. Man spricht in diesem Falle von "tonaler Beantwortung" (im Gegensatz zur "realen Beantwortung", bei der ein Thema ohne Veränderung in der Oberquint-Tonart erscheint).

In Takt 5 haben die beiden Stimmen die Oberquint-Tonart g-Moll endgültig erreicht. Damit die dritte Stimme mit dem Thema einsetzen kann, muss jedoch zur Originaltonart c-Moll zurückmoduliert werden. Dies geschieht in der zweitaktigen "Codetta" der Takte 5 und 6. Der Komponist macht hier im Sopran Gebrauch von dem charakteristischen Anfangsmotiv des Themas, während der Alt das von ihm in Takt 3 eingeführte "Kontrasubjekt" (oder "Kontrapunkt") verwendet. Jedoch erscheinen die für dieses Kontrasubjekt typischen Tonschritte umgekehrt, d. h., nicht absteigend, sondern aufsteigend. Außerdem erfolgt der Aufstieg dreimal hintereinander auf der jeweils nächsthöheren Tonstufe: es handelt sich um eine Sequenz. In Takt 7 ist die Grundtonart c-Moll wieder erreicht, und der Bass kann mit dem Thema einsetzen.

Während der Bass das Thema durchführt, ist im Sopran das Kontrasubjekt zu hören. Der Alt führt ein zweites Kontrasubjekt ein, das im weiteren Verlauf der Fuge noch einige Male in verschiedenen Stimmen auftauchen wird und den dreifachen Kontrapunkt begründet.

Durch ihre einfache, fast homophone Führung übernehmen Sopran und Alt ab Takt 8 Begleitfunktionen. An dieser Stelle wird der kammermusikalische, weniger komplex-polyphone Charakter dieser Fuge besonders deutlich.

Zu Beginn von Takt 9 ist der Themeneinsatz im Bass abgeschlossen, und somit auch die Exposition: Jede der drei Stimmen hat das Thema vollständig durchgeführt.

Das Prinzip der Imitation zwischen verschiedenen Stimmen eines Musikstücks ist seit dem ausgehenden Mittelalter bekannt. Als Vorstufe der Fuge wurde zunächst der Kanon gepflegt. Um 1600 bezeichnen die Begriffe Fantasia, Canzona, Capriccio, Ricercar und Tiento ähnliche Formen von Instrumentalstücken (meist für Tasteninstrumente), die als Vorläufer der Fuge gelten dürfen. Auch in der Motette hält das Fugenprinzip nach und nach Einzug.

Im Hochbarock folgt die Emanzipation der Fuge als selbständige (Teil-)Form. Lautenisten und Gitarristen, etwa der Spanier Gaspar Sanz, komponierten im 17. Jahrhundert ebenfalls Fugen. In der Französischen Ouvertüre ist der zweite Teil eine Fuge, in der Norddeutschen Orgelschule wird die Fuge zum abschließenden Gegenstück eines vorangehenden Präludiums, einer Toccata oder anderer Formen.

Der wohl bekannteste Komponist von Fugen war Johann Sebastian Bach; in seinen Werken (z. B. "Wohltemperiertes Klavier", "Die Kunst der Fuge") erprobte er sämtliche Möglichkeiten der Fuge, sodass viele spätere Komponisten sich beim Thema Fuge auch mit Bach auseinandersetzten. 1753/54, einige Jahre nach Bachs Tod, erschien Friedrich Wilhelm Marpurgs "Abhandlung von der Fuge", die bis weit ins 19. Jahrhundert als musiktheoretische Anleitung zum Erlernen der Fugentechnik Verwendung fand.

Nach dem Barock galt die Fuge zwar als historische und damit veraltete Form, sie wurde aber nie aufgegeben. Spätere Komponisten setzten sich immer wieder mit ihren Prinzipien auseinander, wobei jeweils klar war, dass die Ergebnisse stets einen Verweis auf die Vergangenheit bedeuteten. Das Schreiben einer Fuge galt zudem als Nachweis besonderer kompositorischer Fähigkeiten.

Komponisten, die sich nach dem Barockzeitalter der Fuge widmeten, waren unter anderem:

Astor Piazzolla vermischte klassische Fugentechnik und argentinischen Tango zu einer neuen Einheit.
Im Jazz sind ebenfalls Fugen zu finden, z. B. in "Love Me or Leave Me" von Nina Simone oder "Passacaglia & Fugue" von Don Ellis.

Von einer Permutationsfuge spricht man, wenn zum Thema immer mehrere, stets gleichbleibende Kontrapunktthemen treten. Der Komponist tauscht dann in der jeweils nächsten Thema-Phase nur die Stimmen gegeneinander aus. Dies ist beliebt in Vokalsätzen; Beispiel: Eingangschor der Kantate Himmelskönig, sei willkommen von J. S. Bach.

Eine Doppelfuge ist eine Fuge mit zwei Themen sowie einem oder zwei Kontrasubjekten, die nacheinander oder gleichzeitig vorgestellt und verarbeitet werden können. Beispiele: Johann Sebastian Bach: Wohltemperiertes Klavier II. Teil, gis-Moll-Fuge; Contrapunctus IX und X aus der Kunst der Fuge.

Ein Spezialfall ist der Gebrauch des Begriffs Doppelfuge durch Johann Mattheson. In seiner 1739 erschienenen Schrift „Der vollkommene Capellmeister“ nennt er Doppelfugen alle Fugen, in denen doppelter Kontrapunkt angewendet wird. Dabei stellt er die Forderung nach „Doppelfugen mit dreyen Subjecten“ auf, einer Fugenart, die Bach nicht nur in der Kunst der Fuge, sondern schon in früheren Werken verwendete. Beispiele dafür sind die Fuge zur Passacaglia c-Moll BWV 582, in der dem Thema (Subjekt) zwei Kontrasubjekte beigegeben werden, und die dreistimmige Sinfonia f-Moll BWV 895. Wenn drei Themen im doppelten Kontrapunkt behandelt werden, spricht man in moderner Terminologie von sechsfachem Kontrapunkt.

Die Tripelfuge ist eine Fuge mit drei Themen. Diese werden wiederum in getrennten Expositionen aufgestellt und anschließend miteinander kombiniert. Beispiele: J. S. Bach, Wohltemperiertes Klavier, Teil II, Fuge fis-Moll, Kunst der Fuge, Contrapunctus 8 und 11, die den Dritten Theil der Clavierübung beschließende Orgelfuge Es-Dur BWV 552.

Die Quadrupelfuge ist eine Fuge mit vier Themen. Als Beispiel wird oft die fragmentarisch überlieferte Schlussfuge von Bachs Zyklus „Die Kunst der Fuge“ genannt, die aber nach der Einführung des dritten Themas und dessen Kombination mit den Vorhergehenden abbricht. Da das Grundthema des Werks ebenfalls noch hinzupassen würde, ist eine geplante Quadrupelfuge wahrscheinlich, in dieser Form aber nicht überliefert.

Dies ist eine Fuge, in der das Thema im Comes zuerst zur Quinte geht, dann aber der Dux nicht wieder auf der Tonika folgt, sondern erneut eine Quinte ansteigt. Diese Technik entwickelte sich mit dem Modulationsbedürfnis der Romantik. Beispiel: Johannes Brahms, „Warum ist das Licht gegeben den Mühseligen?“, aus: Zwei Motetten, op. 74. Hier wird das Fugenthema, welches in d-Moll beginnt, in a-Moll real beantwortet. Diese Beantwortung wird wieder real beantwortet in e-Moll. Diese wiederum in h-Moll und jene ein letztes Mal in fis-Moll. Das Fugenthema steigt in dieser Motette demnach gleich viermal hintereinander um eine Quinte an.
Ebenfalls in Fächer- oder Pyramidenform gestaltet ist der erste Satz aus Béla Bartóks „Musik für Saiteninstrumente, Schlagzeug und Celesta“. Der erste Auftritt des Themas wird zunächst in der Oberquinte, dann in der Unterquinte beantwortet, es folgt die zweite Oberquinte, die zweite Unterquinte usw. Im ganzen Stück kommen somit Transpositionen des Themas auf jeder chromatischen Tonstufe vor. Nach sechs Einsätzen erklingt das Thema im Tritonus des Ausgangstons, d. h. in einem bei Bartók konstruktiv wichtigen Intervall. Dieser Einsatz ist gleichzeitig der dynamische Höhepunkt des Stücks.

In einer Spiegelfuge ist der gesamte kontrapunktische Satz spiegelbildlich umkehrbar. Dabei werden alle Abwärts- zu Aufwärtsbewegungen, die höchste Stimme zur tiefsten usw. Fugen dieser Art sind äußerst selten; Bach bringt drei Beispiele in der "Kunst der Fuge" (Contrapunctus 16, 17, 18), in denen jeweils der gesamte Satz in (tonaler, also nicht hundertprozentig 'exakter') Spiegelung wiederholt wird.

Um eine Gegenfuge handelt es sich, wenn der "Comes" die Umkehrung des "Dux" ist und zwar meist so, dass Tonika und Dominante einander entsprechen. Gegenfugen finden sich beispielsweise in J. S. Bachs "Kunst der Fuge", Contrapunctus 5, 6, 7 und 14.

Die Fughetta oder Fugette ist eine Fuge von kleinerem Umfang, ohne eine breite Durchführung und schon im Thema von leichterer, graziöserer Haltung.

Ein Fugato ist ein fugenähnlicher Abschnitt in einer Sonate, einer Symphonie, einem Konzert etc. Dabei geht es nicht darum, das Thema durch alle Stimmen zu führen, es soll lediglich wirken wie eine Fuge. Oft sind diese Fugati nur wenige Takte lang. Beispiele sind die meisten Schlusssätze in den Cembalo-Suiten und Partiten oder in den Brandenburgischen Konzerten Nr. 2 und 5 sowie die schnellen Mittelteile von Bachs französischen Ouvertüren in den ersten Sätzen der Orchestersuiten.
Händel bedient sich im Hallelujah-Chorus seines "Messias" gekonnt der Fugato-Technik.
Mozart entwickelt u. a. im letzten Satz seiner "Jupiter-Sinfonie" ein äußerst effektvolles Fugato.
Auch in der 9. Sinfonie Beethovens und der 5. Sinfonie Bruckners sind bekannte Fugati enthalten. In der 4. Sinfonie von Schostakowitsch bildet ein Fugato den Höhepunkt des ersten Satzes.





</doc>
<doc id="1671" url="https://de.wikipedia.org/wiki?curid=1671" title="Fuge">
Fuge

Fuge steht für:

Personen:
Siehe auch:


</doc>
<doc id="1672" url="https://de.wikipedia.org/wiki?curid=1672" title="Feuerbohne">
Feuerbohne

Die Feuerbohne, in Österreich auch Käferbohne genannt, ("Phaseolus coccineus") ist eine Pflanzenart aus der Gattung "Phaseolus" in der Unterfamilie der Schmetterlingsblütler (Faboideae) innerhalb der Familie der Hülsenfrüchtler (Fabaceae oder Leguminosae). Die leuchtend hellrote Blüte ist namensgebend für die Feuerbohne. Weitere Trivialnamen sind Prunkbohne, Blumenbohne, Schminkbohne, Türkische Bohne, Arabische Bohne oder die griechischen Gigantes. Diese Nutzpflanze ist nahe verwandt mit einer Reihe anderer „Bohnen“ genannter Feldfrüchte.

Die Feuerbohne wächst als linkswindende, meist einjährige, jedoch in frostfreien Gebieten auch zwei- und mehrjährige krautige Schlingpflanze. Die Feuerbohne ist eine Langtagpflanze. Die Keimblätter bleiben im Boden, ergrünen also nicht: hypogäische Keimung. Die Wurzel verdickt sich bei mehrjährigen Pflanzen zu einer im Durchmesser 2 bis 3 Zentimeter dicken, spindelförmigen Knolle. Der meist 2 bis 4, selten bis zu 7 Meter lange, im unteren Bereich runde und im oberen Bereich sechskantige Stängel ist wie bei der Gartenbohne stets linkswindend. Der Stängel ist anfangs schwach und kurz behaart und später verkahlend. 

Die wechselständig und schraubig am Stängel verteilt angeordneten Laubblätter sind in Blattstiel und Blattspreite gegliedert. Der sechskantige Blattstiel besitzt oben eine Rinne. Der Blattstiel und die Fiederstiele besitzen Gelenke, welche über Turgor-Veränderungen funktionieren. Die Laubblätter führen ausgeprägte nyktinastische Bewegungen aus, bei Eintritt der Dunkelheit nehmen sie eine Schlafstellung ein. Die unpaarig gefiederte Blattspreite besteht aus drei Fiederblättern. Die relativ großen Fiederblätter sind breit-eiförmig. Von den relativ rauhen Blattflächen ist die Oberseite deutlich behaart sowie glänzend dunkelgrün, und die Unterseite heller grün; Netznerven sind deutlich erkennbar. Der Blattrand ist glatt oder seltener schwach geschweift. Die auf der Blattunterseite vorhandenen Drüsenhaare geben ein kaliumkarbonathaltiges Sekret ab, das hygroskopisch wirkt, dies ermöglicht die Aufnahme von Wasser aus der Luft. Sowohl die Nebenblätter (Stipeln) als auch die Nebenblättchen (Stipellen) der Fiederblätter sind relativ klein sowie kurz-lanzettlich.

Die Blütezeit reicht von Juni bis September. Die Blütenstände sind bei einer Länge von 25 bis 35 Zentimeter meist länger als die Laubblätter. Die Blütenstände enthalten sechs bis zehn in den Achseln kleiner eiförmiger Tragblätter stehende Blütenpaare. Der Blütenstiel ist relativ lang. Die zwittrigen Blüten sind bei einer Höhe von 1,5 bis 3,0 Zentimeter leicht asymmetrisch zygomorph und fünfzählig mit doppelter Blütenhülle. Der Kelch besteht aus zwei Lippen und die oberen Kelchzähne sind deutlich kürzer als die anderen. Die kurze Fahne ist zurückgeschlagen. Die relativ großen Flügel sind breit. Schiffchen und Fruchtknoten sind schraubig eingerollt. Der relativ kurze Griffel ist dick. Blütenökologisch handelt es sich bei der Feuerbohne um Pollen-Schmetterlingsblumen mit Bürstenmechanismus, so dass der Bestäubungsmechanismus nur von großen Apidae ausgelöst werden kann. Die Blüten sind selbststeril.

Die Hülsenfrüchte sind bis zu 25 cm lang. Die nierenförmigen Samen sind bis 2,5 cm lang und meistens braun, rot, schwarz und violett gescheckt oder vollständig weiß. Bei den Kulturformen bleiben die Hülsenfrüchte meist geschlossen, die Wildformen verbreiten sich als Austrocknungsstreuer. Die nierenförmigen Samen der Feuerbohne enthalten 18,4 % Rohprotein, 1,8 bis 2,9 % Rohfett, 4,4 % N-freie Extraktstoffe, 6,8 % Rohfaser, 3,8 % Asche sowie 15,0 % Wasser.

Die Chromosomenzahl beträgt 2n = 22.

Die Feuerbohne stammt aus Südamerika und wurde im 17. Jahrhundert nach Europa gebracht.
Da die Feuerbohne Kälte besser toleriert als die Gartenbohne, ist sie heute von Nord- bis Südeuropa anzutreffen und wird auch in höheren Lagen in Österreich kultiviert.

In Mitteleuropa wird die Feuerbohne als einjährige Pflanze kultiviert; sie kann in Ländern mit milderem Klima mehrjährig sein. In Europa werden Feuerbohnen vielfach als Zierpflanzen gepflanzt. Zur Nahrungserzeugung kultiviert man die Feuerbohne wegen ihrer Wuchshöhe meist an 4 bis 5 Meter langen Stangen, die zur besseren Stabilität zeltförmig gegeneinander gestellt und miteinander verbunden werden. Manchmal werden die Bohnen auch mit Mais gemeinsam angebaut, wobei die Maispflanzen die Stangen ersetzen. Diese Methode ist mit weniger Aufwand verbunden, da die Ernte mit einem Mähdrescher vollzogen werden kann. Danach muss die Ernte jedoch sortiert werden.

Die Blüten, die jungen Hülsenfrüchte und die getrockneten Samen werden gegessen. Die rohen Bohnen enthalten rund 1,2 % gesundheitsschädliche Lektine und sind daher giftig. Durch Erhitzen auf mindestens 75 °C wird die Struktur dieses Giftes zerstört, so dass gekochte Bohnen bedenkenlos verzehrt werden können.

Als Spezialität gilt in der österreichischen Steiermark der Käferbohnensalat aus den gekochten Samen mit frischen Zwiebelscheiben, Essig und steirischem Kürbiskernöl. Auch sonst wird die Käferbohne in der Steiermark traditionell gerne verwendet und findet sich auf jedem Bauernmarkt. Im Jahr 2016 wurde die "Steirische Käferbohne" auch von der EU als Geschützte Herkunftsbezeichnung anerkannt.

Die „Fasolia Gigantes“ () sind weiß blühende griechische Sorten der Feuerbohne mit geschützter geographischer Bezeichnung. Die reifen Bohnen sind weiß bis hellbraun und bis zu 2,5 Zentimeter lang. Sie wird im Norden Griechenlands in den Regionen Kato Nevrokopi, Florina und Kastoria angebaut. Aus Griechenland und Nordafrika kommen schon früh im Jahr die frischen flachen Hülsen als „grüne Bohnen“ oder „breite Bohnen“ auf den Markt, die sich anhand der Größe und der raueren Haut von den Hülsen der Gartenbohne unterscheiden lassen. In der griechischen Küche spielt sie eine wichtige Rolle, dort kennt man vielfache Zubereitungsarten der jungen grünen Hülsen und der getrockneten Bohnensamen.





</doc>
<doc id="1674" url="https://de.wikipedia.org/wiki?curid=1674" title="Helmbohne">
Helmbohne

Die Helmbohne ("Lablab purpureus"), auch Indische Bohne oder Ägyptische Bohne, Hyazinth-Bohne, früher Faselbohne genannt, ist einzige Pflanzenart der Gattung Lablab in der Unterfamilie Schmetterlingsblütler (Faboideae) innerhalb der Familie der Hülsenfrüchtler (Fabaceae oder Leguminosae). Diese Nutzpflanze ist nahe verwandt mit einer Reihe anderer, Bohnen genannter Feldfrüchte.

Die Helmbohne hat mit großer Wahrscheinlichkeit ihren Ursprung im (süd-)östlichen Afrika, weil nur dort Wildpflanzen der Art vorkommen. In Indien ist andererseits die größte morphologische Vielfalt der Nutzpflanze zu beobachten.
Als tropische Pflanze benötigt sie hohe Temperaturen (>20 °C), aber relativ wenig Wasser; insbesondere verträgt sie keine Staunässe.

Die Helmbohne ist eine stark wuchernde, halbaufrechte bis kletternde krautige Pflanze, die bis zu 10 m weit (in gemäßigtem Klima meist um 2 m) rankt. Sie ist ausdauernd, wird aber meist als einjährige Pflanze kultiviert, da sie wie die meisten Bohnen keinen Frost verträgt. Sie bildet eine starke, bis zu 2 m tiefe Pfahlwurzel. Die Stängel sind oft stark behaart. Die wechselständigen Laubblätter sind gestielt und dreiteilig. Die Nebenblätter sind zurückgebogen.

An einem achselständigen, bis 20 cm langen Stiel stehen traubigen Blütenstände. Die angenehm duftenden Blüten sind zygomorph und zwittrig. Die Kelchblätter sind verwachsen. Der Kelch ist zweilippig; die obere Kelchlippe ist nicht geteilt, die untere ist dreilappig. Die Kronblätter sind rosa bis violett oder weiß. Das einzelne Fruchtblatt enthält einige Samenanlagen. Die Blüte beginnt in Europa ab Juni.

Die purpurroten Hülsenfrüchte der Ziersorten sind knapp 20 cm lang und enthalten viele Samen. Die eiförmigen Samen sind gut 1 cm lang und 0,5 cm dick. Die gefleckten, marmorierten oder einfarbigen Samen sind weiß über rotbraun bis schwarz. Das Tausendkorngewicht liegt zwischen 140 und 600 Gramm. Die typischen in Indien angebauten buschigen frühen Sorten sind weißblühend und haben eher helle Samenfarben (weiß, beige, hellbraun).

Samen und Hülsen vieler Sorten sind im rohen Zustand giftig, da sie cyanogene Glykoside enthalten. Das Gift wird durch Kochen zerstört. Allerdings gibt es große Sortenunterschiede.

Die Chromosomenzahl beträgt 2n = 22.

Die Verwendungsmöglichkeiten der Faselbohne sind vielfältig: Man kann die unreifen Hülsen und Samen sowie die reifen Samen gekocht essen. Die Pflanze wird auch als Bodendecker und Gründüngung zur Bodenverbesserung genutzt. In Europa und Nordamerika wird sie wegen ihrer duftenden, violetten Blüten als Zierpflanze zum Beranken von Zäunen oder als Sichtschutz u. ä. genutzt. Blätter und Stängel werden in den Tropen als Viehfutter verwendet. Sowohl in Afrika als auch in Ostasien hat sie zudem Bedeutung als Medizinalpflanze.

In Kenia ist die 'Njahi' genannte Helmbohne im ganzen Land sehr beliebt, besonders bei den Kikuyu. Sie hat den Ruf, die Milchproduktion anzuregen und ist daher traditionell eine Hauptmahlzeit stillender Mütter. Die Bohnen werden gekocht und mit gemusten reifen und/oder halbreifen Bananen vermischt, was dem Gericht einen süßen Geschmack verleiht. Heutzutage geht die Produktion der Helmbohne im östlichen Afrika zugunsten von Bohnen ("Phaseolus vulgaris") und Augenbohnen ("Vigna unguiculata") zurück. Dieser Rückgang wird z. T. jedoch auch darauf zurückgeführt, dass kenianische Bauern in der Kolonialzeit gezwungen wurden, ihre traditionellen (Helm-)Bohnen für die Erzeugung von trockenen Bohnen ("Phaseolus vulgaris") aufzugeben, die für den Export bestimmt waren.

Die Gattung "Lablab" gehört zur Subtribus Phaseolinae der Tribus Phaseoleae in der Unterfamilie Schmetterlingsblütler (Faboideae) innerhalb der Familie der Hülsenfrüchtler (Fabaceae).

Der Gattungsname "Lablab" wurde 1763 von Michel Adanson in "Familles des plantes", 2:325 veröffentlicht. Die Erstbeschreibung der Art erfolgte 1753 unter dem Namen "Dolichos lablab" durch Carl von Linné in "Sp. Pl.", 725. Der britische Biologe und Taxonom Bernard Verdcourt unterzog die Art 1970 einer Revision, woraufhin nun viele der früheren Namen als Synonyme zu gelten haben. Trotzdem hält sich der Name "Dolichos lablab" noch immer hartnäckig in wissenschaftlichen und populärwissenschaftlichen Veröffentlichungen.

Synonyme von "Lablab purpureus" sind: "Dolichos lablab" , "Lablab niger" , "Lablab lablab" , "Vigna aristata" , "Lablab vulgaris" .

Laut Verdcourt gibt es von "Lablab purpureus" zwei kultivierte Unterarten:

Dazu eine wilde Unterart:
von der eine spezielle Variante mit gelappten Blättern nur in Namibia vorkommt:




</doc>
<doc id="1675" url="https://de.wikipedia.org/wiki?curid=1675" title="DR 877">
DR 877

Der Verbrennungstriebwagen 877 (später DB-Baureihe VT 04.0) war der erste Dieselschnelltriebwagen der Deutschen Reichsbahn (DR) und zugleich der erste Stromlinienzug in planmäßigem Einsatz. Mit ihm wurde ab 1933 zwischen Berlin und Hamburg die damals weltweit schnellste Zugverbindung hergestellt, die Höchstgeschwindigkeit lag bei 160 km/h. Er war als Fliegender Hamburger bekannt.

Der aus zwei zusammengekuppelten Wagen bestehende Triebzug mit der damaligen Betriebsnummer "877a/b" wurde im Februar 1932 von der DR bei der Waggon- und Maschinenbau AG Görlitz (WUMAG) bestellt. Ausgeliefert wurde er Ende 1932 und abgenommen im Februar 1933.

Eine Probefahrt am 19. Dezember 1932 zwischen dem Lehrter Bahnhof und dem Hamburger Hauptbahnhof legte der Schnelltriebwagen mit einem Geschwindigkeitsrekord zurück. In 142 Minuten hatte der Zug die Strecke von 286 km bewältigt.
Neu am Fliegenden Hamburger waren die Stromlinienform (wobei dies aber der einzige Triebzug mit tiefgezogenem Frontdach blieb), die in Windkanalversuchen entwickelt wurde, die Leichtbauweise und der dieselelektrische Antrieb. Jeder der beiden Wagen hatte einen Maybach-Zwölfzylinder-Viertakt-Dieselmotor GO 5 mit daran angeschlossenem Gleichstrom-Generator und elektrischen Tatzlager-Fahrmotoren. Mit einer Leistung von 2 × 420 PS (2 × 302 kW) wurde bei Versuchsfahrten eine Höchstgeschwindigkeit von 175 km/h erreicht; für den planmäßigen Einsatz wurde eine Höchstgeschwindigkeit von 160 km/h festgelegt. Der Maybach-GO-5-Motor bereitete anfangs eine Reihe von Problemen, teils durch die viel zu starre Motoraufhängung im Triebdrehgestell, teils durch das zu schwach dimensionierte Kurbelgehäuse. Diese Probleme wurden mit der Weiterentwicklung zum Maybach GO6 weitestgehend beseitigt. Franz Kruckenberg berücksichtigte dies bereits bei der Konstruktion seines Schnelltriebwagens DR 137 155 (nicht zu verwechseln mit dem ebenfalls von ihm konstruierten Schienenzeppelin) und setzte den Motor in eine Rahmenaufhängung statt in das bisher verwendete Triebdrehgestell. Der Maybach-Motor ist in seiner letzten Ausbaustufe als GTO 6 noch heute in diversen Loks der DB-Baureihe V 60 eingesetzt.

Der Zug war mit einer Knorr-Druckluftbremse und einer Magnetschienenbremse ausgerüstet, mit denen er aus einer Geschwindigkeit von 160 km/h innerhalb von 800 Metern zum Halten gebracht werden konnte. 

Der Triebzug hatte 98 Sitzplätze in zwei Großraumwagen-Abteilen und ein viersitziges Büffet. Als Zeichen seiner Exklusivität wurde er wie die Wagen des „Rheingold-Zuges“ cremefarben und violett lackiert.

Anfangs war das cremefarbene Fensterband auch um die Stirnseiten herumgezogen, auf späteren Abbildungen sieht man, dass der Bereich um die Stirnfenster bis zu einer viertelkreisförmigen Farbtrennkante ebenfalls in violett lackiert wurde. Dies geschah zum einen, um das Erscheinungsbild an die übrigen Schnelltriebwagen vom Typ Hamburg, Leipzig und Köln anzupassen, zum anderen litt die cremefarbene Stirnseite sehr schnell unter Verschmutzungen durch den Fahrbetrieb.

Der DR 877 war Prototyp für weitere Schnelltriebwagen:


Die Erfolge dieser Schnelltriebwagen führten dazu, dass 1935 in Kassel von Henschel & Sohn zusammen mit der Waggonfabrik Wegmann & Co. der stromlinienverkleidete, aber dampflokbetriebene „Henschel-Wegmann-Zug“ mit vergleichbaren Leistungen entwickelt und im Fernschnellverkehr zwischen Berlin und Dresden eingesetzt wurde.

Ab 15. Mai 1933 verkehrte der Triebzug planmäßig zwischen Berlin Lehrter Bahnhof und Hamburg Hauptbahnhof. Für die 286 km lange Strecke benötigte er 138 Minuten, eine Zeit, die erst 64 Jahre später, im Juni 1997 von einem ICE-Zug der Deutschen Bahn AG mit 132 Minuten unterboten wurde. Aktuell (2015) bewältigen die schnellsten Züge die Strecke in 98 Minuten. Im Zweiten Weltkrieg wurde der Triebwagen abgestellt. Ab 1945 wurde er von der französischen Besatzungsmacht als Reisezug eingesetzt und 1949 an die Deutsche Bundesbahn zurückgegeben, die ihn 1951 modernisierte und als VT04 000 a/b in purpurroter Farbgebung einreihte. Zur Modernisierung gehörte auch der Einbau von Scharfenbergkupplungen an beiden Enden, um ihn zusammen mit weiteren VT 04 in Doppel- oder Dreifachtraktion einsetzen zu können. Der Triebwagen war 1955/1956 in Hamburg stationiert und wurde dort gelegentlich als Verstärkungstriebwagen des Kopenhagen-Express zwischen Hamburg und Großenbrode Kai eingesetzt. Er wurde 1957 abgestellt.

Nach seiner Abstellung wurde das Fahrzeug dem Verkehrsmuseum Nürnberg übergeben, dort wurde der Triebwagen getrennt.
Die vordere Triebwagenhälfte a wurde wegen Platzmangels nochmals in der Mitte zerschnitten, der Torso mit Führerstand ist heute im Verkehrsmuseum Nürnberg ausgestellt. Die Sektion b wurde 1961 im AW Nürnberg mangels Interessenten ebenso verschrottet wie die restliche Hälfte der Sektion a.

Der Wagen zeigte zum ersten Mal die wegweisende Konstruktion der Schnelltriebwagen, die nach ihm von den Fahrzeugen der Bauarten Hamburg, Leipzig, Köln und Berlin vor dem Zweiten Weltkrieg realisiert wurde.

Die Doppelfahrzeuge waren in Leichtbauweise weitgehend in Schweißkonstruktion hergestellt worden. Sie stützten sich über ein gemeinsames Jakobs-Drehgestell und zwei Endgestelle ab. Auffällig bei dem Fahrzeug gegenüber den anderen Schnelltriebwagen der Deutschen Reichsbahn waren die heruntergezogene Dachfront und die kleinen Stirnfenster, die als Folge von Windkanaluntersuchungen entstanden waren. Aus diesen Untersuchungen resultierten ebenfalls die seitlichen Schürzen sowie der Verzicht auf eine reguläre Zug- und Stoßeinrichtung. Statt derer erhielt der Fliegende Hamburger lediglich einen Nothaken sowie seitliche Gummipuffer. Die Wagenkästen waren zum ersten Mal in der folgend im Triebwagenbau dominierenden Spantenbauart mit senkrechten Säulen aus gewalzten Profilen, einem durchgehenden Obergurt aus Stahlblech sowie Dachspriegeln aufgebaut. Die Fahrgasträume mit der Sitzplatzanordnung 1 + 3 waren als Großraumabteile mit Mittelgang ausgebildet. Der Sitzkomfort auf der Dreierbank wurde bald als unzureichend empfunden und bei den nachfolgenden SVT in die Anordnung 1+2 geändert. Der Wagen "a" enthielt neben dem Maschinenraum das Gepäckabteil mit einer Grundfläche von 7,4 m², einen schmalen Vorraum, den Fahrgastgroßraum mit 42 Sitzplätzen sowie den beiden Aborten incl. Wascheinrichtung und einen weiteren Vorraum, der auch eine Heizungsnische besaß. Der Wagen "b" begann vom Kurzkuppelende ebenfalls mit einem kurzen Vorraum mit Erfrischungsraum inkl. vier Sitzplätzen, dem Großraumabteil mit 56 Sitzplätzen. Ihm schloss sich ein weiterer Vorraum sowie der Maschinenraum an. Beide Maschinenräume waren auch die Führerstände des Fahrzeuges.

Die Drehgestelle waren ebenfalls eine Schweißkonstruktion aus Profilen und Blechen der Bauart Görlitz. Die Wagenkästen stützten sich am Drehgestell über eine Wiege ab. Bei dem mittleren Jakobs-Gestell war die Federung auf Grund der höheren Belastung doppelt ausgeführt. Die Fahrzeuge waren mit der Druckluftbremse Bauart Knorr ausgestattet, die als Außentrommelbremse mit einem Durchmesser von 780 mm ausgebildet war. Die Bremstrommeln waren bei den Außendrehgestellen innen, bei dem Innendrehgestell außen an den Radkörpern angeschraubt. Die Bremstrommeln waren mit einem Asbestbelag belegt, sie wurden von Einzelbremszylindern mit einem Durchmesser von 70 mm bei einem Hub von 60 mm angepreßt.

Die Maschinenanlage war bei diesem Fahrzeug mit den beiden Dieselmotoren Maybach GO 5 und den angeflanschten Generatorsätzen in den Außengestellen sowie den elektrischen Fahrmotoren, gelagert als Tatzlager-Fahrmotoren im Jakobs-Drehgestell, ausgeführt. Die Motoren waren in einem Hilfsrahmen gelagert, dieses war in drei Punkten im Maschinendrehgestell gelagert. Am Drehgestellrahmen war eine Blechhaube für die Diesel-/Generatoreinheit angeschraubt. Da diese bei Bogenfahrten die Drehbewegung mitmachte, war sie noch von einem am Maschinenrahmen befestigten klappbaren Holzrahmen überdeckt. Mit dem zur Verfügung stehenden Dieselkraftstoff von 2 × 990 l erreichte der Triebwagen einen Aktionsradius von 1.000 km. Unter dem Langträger waren auf beiden Seiten Füllstutzen zur Betankung angebracht. Die dieselelektrische Leistungsübertragung wurde von dem Dieselmotor in Drehzahlregelung in sieben Fahrstufen betrieben, und zwar von der Fahrstufe "0" mit 800 U/min bis zur Fahrstufe "6" mit 1.400 U/min. Zusätzlich gab es noch eine Stellung "*" für besonders große Zugkräfte, die nur zum Anfahren bis zu einer Geschwindigkeit von 25 km/h benutzt werden durfte, bei größeren Geschwindigkeiten musste auf eine geringere Fahrstufe zurückgeschaltet werden.

Das Kühlwasser der beiden Dieselmotoren wurde bei jedem Maschinengestell unterflur in je einem Rippenkühler mit acht Elementen rückgekühlt. Diese Rippenkühler wurden von zwei Ventilatoren zwangsbelüftet. Eine vom Dieselmotor über Zahnräder angetriebene Kühlwasserumwälzpumpe sorgte für den Kreislauf des Kühlwassers im Motor. Über elektrische Heizstäbe konnte dieses im Ausgleichbehälter vorgewärmt werden. Beheizt wurden beide Wagen des Triebwagens von einer koksgefeuerten Warmwasserheizung. Die Abgase wurden nach oben geführt und gaben mit der am Kurzkuppelende befindlichen Abgashutze das charakteristische Abbild des Triebwagens. Ausgerüstet zur Versorgung der Druckluftanlage war der Doppelwagen mit einem zweistufigen Luftverdichter der Bauart Knorr. Angetrieben wurde dieser elektrisch unmittelbar von dem Hauptgenerator. Bei einer Spannung unter 380 V konnte der Verdichter nicht anlaufen. Um trotzdem bei längeren Fahrten mit Leerlauf, wie bei Rangierfahrten, Luft zu pumpen, gab es zwei Möglichkeiten; durch einen sogenannten "Pumpenschalter" konnte die Erregung des Generators gestärkt werden und die Spannung auf 600 V erhöht werden, oder es konnte mit einem batteriegespeisten Hilfsluftverdichter Luft gepumpt werden. Der Triebwagen besaß ein Bordnetz von 48 V, das durch eine unterflur angeordnete Lichtmaschine oder die Batterie gespeist wurde. Bei Stillstand der Dieselmotoren erfolgte selbsttätig die Umschaltung der Speisung auf Batteriebetrieb.




</doc>
<doc id="1676" url="https://de.wikipedia.org/wiki?curid=1676" title="Foxtrott">
Foxtrott

Der Foxtrott (englische Schreibweise "Foxtrot" ‚Fuchsgang‘) ist ein Gesellschaftstanz, der paarweise getanzt wird und zu den Standardtänzen des Welttanzprogramms gehört.

Entstanden ist der Foxtrott zwischen 1910 und 1915 in Nordamerika. Sowohl die tänzerischen Wurzeln als auch die Herkunft des Namens sind nicht eindeutig zu bestimmen, da sich hier zahlreiche Quellen deutlich widersprechen. 

Der Foxtrott nahm Elemente des "Ragtime, Onestepp, Twostep" sowie des von Vernon und Irene Castle choreografierten "Castle Walk" auf. Der Name Foxtrott geht möglicherweise auf den Schauspieler Harry Fox zurück, der für sein damals populäres Varieté „Harry Fox & the Zigfeld Follies“ Schritte aus "Onestep" und "Castle Walk" übernahm. Fox verbreitete so diesen Tanz in der Öffentlichkeit. Der Foxtrott wurde zum Synonym für eine Reihe von Geh- und Schreittänzen, von denen die meisten nicht mehr existieren.

Nach Europa kam der Foxtrott erst nach dem Ersten Weltkrieg. 1920 wurde das vorhandene Schrittmaterial auf einer Konferenz in England zum ersten Mal geordnet. Seit 1924 unterscheidet man zwischen der langsamen Variante, dem "Slowfox" sowie dem schnelleren "Quickstepp". Ins Welttanzprogramm wurde der Foxtrott 1963 mit aufgenommen, als Turniertanz wurde er in Europa jedoch nie verwendet.

Während Slowfox und Quickstepp technisch sehr anspruchsvoll sind, ist der Foxtrott recht unkompliziert. Die Schritte werden normal gesetzt, besondere Körperhaltungen, Posen oder schwierige Figuren sind nicht vorgesehen; einzig das „Auf-und-ab-Hüpfen“ – vor allem des Kopfes – bei den schnellen Seitschritten gilt es zu vermeiden.

Der Foxtrott wird auf Musik im 4/4-Takt getanzt, wobei ein kompletter Grundschritt sechs Schläge und damit anderthalb Takte umfasst. Dadurch wird der Grundschritt auf den Takt bezogen zeitlich versetzt, wie es auch beim Abkömmling Discofox der Fall ist. Die Geschwindigkeit ist in einem weiten Rahmen möglich. 

Der Foxtrott wird traditionell auf Popmusik getanzt, ist aber in Tanzschulen besonders deswegen beliebt, weil er sich auch gut auf Hip-Hop-Musik tanzen lässt.

 Takt: 1 2 3 4 | 1 2 3 4 | 1 2 3 4 |

Legende: X = (Vollzogener) Schritt, < … | …> = ein Grundschritt.

Herrenschritte:

Damenschritte:

Den „Seit-Schluss“-Teil führt man allgemein doppelt so schnell aus wie die restlichen Schritte.



</doc>
<doc id="1677" url="https://de.wikipedia.org/wiki?curid=1677" title="Frühgeschichte">
Frühgeschichte

Die Frühgeschichte ist ein Teilgebiet der archäologischen Disziplin „Ur- und Frühgeschichte“ und bezeichnet eine Periode der menschlichen Geschichte: Sie befasst sich mit jenen Kulturen der Menschheit, über die erste schriftliche Aufzeichnungen (teils aus anderen Kulturen) bekannt sind, ein Teil der Erkenntnisse aber auch durch archäologische Grabungen gewonnen wird. Sie beginnt regional sehr unterschiedlich mit dem ersten Auftreten von Schriftzeugnissen und reicht bis in die historische Zeit der Geschichte im engeren Sinne. 

Die vorangehende Epoche ist die Urgeschichte, welche bis zurück vor etwa 2,5 Millionen Jahren in die Zeit des Auftretens erster Steinwerkzeuge in der Menschheitsgeschichte reicht; die nachfolgende Epoche ist die Geschichte im engeren Sinne, in der historische Entwicklungen wesentlich durch Auswertung schriftlicher Quellen erkannt werden und die materielle Kultur oft parallel archäologisch erschlossen wird.

In den Regionen archäologischer und historischer Forschung setzt die Schriftkultur zu unterschiedlichen Zeiten ein. Deshalb lässt sich Frühgeschichte nur regional definieren. Entwicklungen im Fernen Osten, in Nordamerika, in Afrika und in Australien werden in eigenen Disziplinen behandelt. Der Nahe Osten, der Mittlere Osten, Nordafrika und der Mittelmeerraum sind dagegen jene Gebiete, für welche eine frühgeschichtliche Phase üblicherweise bestimmt werden kann und behandelt wird. 

In Südeuropa beginnt die Frühgeschichte mit der minoischen Kultur und dem Einsetzen der Archanesschrift um 2000 v. Chr. in der Stufe "Mittelminoisch I". Abgelöst wurde sie um 1450 v. Chr. von der mykenischen Kultur während der Stufe Späthelladisch II. Mit den schriftführenden Kulturen der Griechen und Römer endet die Frühgeschichte zu Beginn der Archaik, mit der in Südeuropa die historische Zeit einsetzt. Mit der materiellen Kultur befassen sich hier die Fächer Klassische Archäologie und Provinzialrömische Archäologie.

Der Übergang von der Urgeschichte zur Frühgeschichte lässt sich für Mitteleuropa nicht exakt definieren. Üblicherweise gilt das Einsetzen römischer Schriftzeugnisse über Germanen und Kelten außerhalb des Römischen Reiches (zu nennen sind vor allem Werke von Caesar und Tacitus) als Beginn der Frühgeschichte. Die römisch beherrschten Gebiete Mitteleuropas sind dem Fachgebiet provinzialrömische Archäologie zugeordnet, hier setzt die Frühgeschichte als archäologische Spezialdisziplin erst mit dem Ende der Antike ein. Daher wird gelegentlich auch die römische Kaiserzeit im "Barbaricum" nicht als frühgeschichtlich, sondern als eigener Zeitabschnitt zwischen Vorgeschichte und eigentlicher Frühgeschichte bewertet. Gegenstand der Forschung und Diskussionen ist seit längerem unter anderem die Problematik kultureller und politischer Kontinuität bzw. Diskontinuität im Übergang von der Spätantike zum Frühmittelalter.

In der Archäologie Mitteleuropas wird die Frühgeschichte unterteilt in 

In der Archäologie Nordeuropas gelten auch die Vendelzeit 550–800 n. Chr. und die anschließende Wikingerzeit bis 1050 n. Chr. als frühgeschichtliche Perioden.





</doc>
<doc id="1680" url="https://de.wikipedia.org/wiki?curid=1680" title="Fluchtgeschwindigkeit">
Fluchtgeschwindigkeit

Fluchtgeschwindigkeit steht für



</doc>
<doc id="1681" url="https://de.wikipedia.org/wiki?curid=1681" title="Fußball-Weltmeisterschaft">
Fußball-Weltmeisterschaft

Die Fußball-Weltmeisterschaft der Männer, offiziell "FIFA World Cup" oder "FIFA Fussball-Weltmeisterschaft", ist ein Fußballturnier für Nationalmannschaften, bei dem alle vier Jahre der Fußball-Weltmeister ermittelt wird. Veranstalter ist der Weltfußballverband FIFA. Die Endrunde – eine rund vierwöchige Veranstaltung – gilt nach den Olympischen Spielen als das bedeutendste Sportereignis der Welt. 

Die bislang letzte Endrunde fand 2014 in Brasilien statt, amtierender Weltmeister ist Deutschland. Die Endrunde der nächsten Fußball-Weltmeisterschaft wird 2018 in Russland ausgetragen.

Die Zeit des organisierten Fußballs begann 1863 mit der Gründung der englischen Football Association in London, die sich in ihren Regeln für den Association Football erstmals in der Geschichte verbindlich vom Rugby Football abgrenzte und so zum Beispiel das kontrovers diskutierte Handspiel verbot, was zu Austritten aus dem neuen Verband und zum Rückzug des Schatzmeisters führte. Am 9. Januar 1864 fand mit ausgewählten Spielern das erste Fußballspiel der Welt nach den Regeln der FA statt. Zu diesem Zeitpunkt war das britische Empire die einflussreichste Macht der Welt, es hatte auf der gesamten Welt seine Stützpunkte und britische Schiffe waren in jedem Hafen zu finden. Diese historische Besonderheit war die Grundlage für die weltweite Verbreitung der englischen Fußballregeln innerhalb einer Generation. Die ersten Spiele außerhalb der Britischen Inseln wurden unter anderem in Seehäfen von britischen Matrosen organisiert.

Während des ausgehenden 19. Jahrhunderts wurden in Europa und Amerika viele Nationalverbände gegründet, was erstmals die Organisation internationaler Begegnungen ermöglichte. Das erste Spiel zwischen Vertretern nationaler Verbände fand am 30. November 1872 auf dem Hamilton Crescent, im heutigen Glasgower Stadtteil Partick, zwischen Schottland und England statt, die Begegnung endete torlos.

Der 21. Mai 1904 war ein weiterer Meilenstein der Fußballgeschichte. An diesem Tag wurde von Robert Guérin, dem Sekretär der Fußballabteilung der Union des Sociétés Françaises de Sports Athlétiques, und von Carl Anton Wilhelm Hirschmann, dem Sekretär des Nederlandse Voetbal Bond, in Paris die Gründung der FIFA initiiert und damit ein rein nationales Denken der Verbände verhindert. Dennoch sollte es viele Jahrzehnte dauern, bis die FIFA sich gegen die Vormacht der englischen FA behaupten konnte und bis die amerikanischen Verbände einen bedeutenden Einfluss auf die von den europäischen Verbänden geprägte Politik der FIFA nehmen konnten.

Im Juli 1905 fand der zweite FIFA-Kongress statt, und Vizepräsident Carl Anton Wilhelm Hirschmann machte den Vorschlag für ein Welt-Turnier. Für diese rein europäische Veranstaltung hatte er bereits einen Spielplan erstellt, Austragungsland sollte die Schweiz sein. Die Kongressteilnehmer waren begeistert, aber vielen Worten folgten wegen ausbleibenden Interessenten keine Taten.

Bis zur ersten Fußball-WM 1930 in Uruguay hatten die Olympia-Turniere quasi den Stellenwert einer Weltmeisterschaft. Aus Sicht der Olympia-Verantwortlichen war Fußball für die Spiele ungeeignet, da es sich nicht um eine Wettkampfsportart, sondern nur um ein Spiel handelte, und sie betrachteten diese Sportart als Showeinlage. 1896 war Fußball nicht im olympischen Programm, und vier Jahre später in Paris waren nur drei Vereinsmannschaften aus Frankreich, Belgien und Großbritannien für einen Demonstrationswettbewerb anwesend. 1904 in St. Louis traten drei nordamerikanische Mannschaften gegeneinander an.

Ein Glücksfall für die Zukunft des internationalen Fußballs war die Vergabe der Spiele an London 1908. Im Heimatland des Fußballs konnte man eine professionelle Organisation durch die FA erwarten. Außerdem wurde die FIFA mittlerweile von dem Briten Daniel Burley Woolfall angeführt. Neben Großbritannien stellten die Verbände aus Dänemark, Schweden und den Niederlanden eine Mannschaft auf. Frankreich schickte sogar zwei Teams in die britische Hauptstadt. Sieger wurden überzeugend die Engländer, die im Finale Dänemark, die damals stärkste Mannschaft Kontinentaleuropas, besiegten. 1912 nahmen bereits 11 Mannschaften am olympischen Fußballturnier teil. Die Finalbegegnung wiederholte sich, mit einem 4:2 konnten die Engländer erneut die Goldmedaille erringen.

1920 war Antwerpen der Mittelpunkt der Fußballwelt, und 14 Mannschaften kämpften um den Olympiasieg. Im Finale standen sich Belgien und die Tschechoslowakei gegenüber. Während des Spiels fühlten sich die Tschechoslowaken vom Schiedsrichter benachteiligt und verließen das Spielfeld, Belgien wurde zum Sieger erklärt. Die Olympischen Spiele 1924 wurden zum ersten Weltturnier des Fußballs. Neben den Europäern schickte Ägypten ein Team. Ebenfalls dabei war eine US-amerikanische Auswahl, die allerdings zum Großteil aus europäischen Einwanderern bestand, sowie das Team aus Uruguay.

Die unerwartet überlegene Vorstellung des südamerikanischen Fußballs vier Jahre zuvor führte dazu, dass vor dem olympischen Turnier von 1928 viele Mannschaften aus Südamerika zu Gastspielen in Europa eingeladen wurden. Die Olympiateilnehmer mussten Amateure sein, was zur Absage einiger wichtiger Länder führte. Der FIFA war zunehmend klar, dass die Amateurregel des IOC ein Problem darstellte. Deshalb entschied sie sich am 28. Mai 1929 für die Organisation einer eigenständigen Weltmeisterschaft, nachdem FIFA-Präsident Jules Rimet und der uruguayische Mäzen Enrique Buero schon seit 1924 darauf hingearbeitet hatten. Neben Uruguay wollten auch einige europäische Länder diese Veranstaltung ermöglichen. Deren Gruppe wurde rasch kleiner, und am Ende waren nur noch Italien, Ungarn und Uruguay übrig. Der argentinische Delegierte Adrian Beccar Varela hielt eine Rede für sein Nachbarland, was die beiden europäischen Mitbewerber überzeugte. Somit wurde Montevideo zum Austragungsort der ersten Fußball-Weltmeisterschaft bestimmt.

Die offizielle deutschsprachige Schreibweise der Fußball-Weltmeisterschaft ist "FIFA Fussball-Weltmeisterschaft". Dabei entspricht zwar die Schreibweise des Bestandteils "Fussball" der amtlichen Regelung der deutschen Rechtschreibung (§ 25 E2, der Weltfußballverband FIFA hat seinen Hauptsitz in Zürich, Schweiz), nicht aber das Leerzeichen hinter "FIFA" (s. § 44, Abs. 1).

Über den Austragungsort einer Fußball-Weltmeisterschaft entscheidet der Exekutiv-Ausschuss der FIFA. Bei Stimmengleichheit zählt die Stimme des FIFA-Präsidenten doppelt. Seit dem Jahr 1958 fanden alle Fußball-Weltmeisterschaften immer abwechselnd in Europa und einem anderen Kontinent statt.

Im Jahr 2000 beschloss die FIFA ein so genanntes Rotationsverfahren, demzufolge Weltmeisterschaften ab 2010 im regelmäßigen Wechsel zwischen den sechs Kontinentalverbänden stattfinden werden. Dieses Verfahren wurde 2007 durch das Exekutivkomitee wieder abgeschafft. Ausgeschlossen sind nur die Kontinentalverbände, in welchen die letzten beiden Weltmeisterschaften stattgefunden haben. Für die Fußball-Weltmeisterschaft 2018 bedeutete dies, dass Länder aus dem Afrikanischen Fußballverband und dem Südamerikanischen Fußballverband als Gastgeber ausgeschlossen waren. Am 19. Dezember 2008 beschloss das FIFA-Exekutivkomitee auf seiner Sitzung in Tokio, die WM 2018 und die WM 2022 gleichzeitig zu vergeben.

Um an der Endrunde der Fußball-Weltmeisterschaft teilnehmen zu dürfen, müssen sich die Mannschaften in der Regel in der Qualifikationsrunde durchsetzen. Nur das Gastgeberland ist automatisch bei der Endrunde startberechtigt. Bei den Endrunden von 1938 bis einschließlich 2002 war neben dem Gastgeberland auch der amtierende Weltmeister automatisch qualifiziert.

Die Qualifikation wird innerhalb der einzelnen Kontinentalverbände ausgetragen. Jedem Kontinentalverband steht eine festgelegte Zahl an Endrunden-Teilnehmern zu, wobei es auch „halbe“ Startplätze gibt, die sich in einer interkontinentalen Relegation durchsetzen müssen.

Der Modus in den Qualifikationsturnieren ist von Kontinent zu Kontinent unterschiedlich. So spielen in der südamerikanischen Zone alle zehn Nationalmannschaften in einer Gruppe. Die vier besten Teams der Gruppe sind für die Endrunde qualifiziert, während die fünftplatzierte Nationalmannschaft in Relegationsspielen gegen einen nordamerikanischen Vertreter um einen weiteren Startplatz spielt. In den anderen Kontinentalverbänden werden die Teilnehmer auch in Gruppenspielen oder im K.-o.-System ermittelt.

Die qualifizierten Mannschaften spielen mit dem vorher bestimmten Gastgeberland in einem ca. vier Wochen dauernden Wettstreit um den Titel des Weltmeisters, welcher alle vier Jahre vergeben wird. Der Modus der Endrunde wurde im Lauf der Geschichte mehrfach verändert. Frühere Modi sind weiter unten beschrieben. Der aktuell gültige Modus ist seit 1998 im Einsatz.

In der ersten Turnierphase (Gruppenphase) sind die Mannschaften nach dem Zufallsprinzip in mehrere Gruppen mit jeweils vier Mannschaften unterteilt, wobei einige Mannschaften nach gewissen Kriterien (Gastgeber, Weltmeister, FIFA-Rangliste) gesetzt und die anderen Mannschaften aus vorwiegend regional orientierten Lostöpfen gezogen werden. Dadurch soll verhindert werden, dass in der Gruppenphase bereits die Turnierfavoriten aufeinandertreffen oder eine Gruppe nur aus Nationalmannschaften eines Kontinents besteht.

Jedes Team hat in der Gruppenphase drei Spiele gegen seine Gruppengegner zu bestreiten. Wie im Fußball weltweit Standard, bringt ein Sieg drei Punkte (seit 1994, vorher zwei), ein Unentschieden einen Punkt und eine Niederlage keinen Punkt. Die beiden letztplatzierten Mannschaften jeder Gruppe scheiden nach den drei Spielen der Gruppenphase aus. Bei Punktgleichheit von zwei oder mehr Mannschaften wird die Rangfolge in der Gruppe gemäß Art. 42 Ziffer 5 der FIFA-Regeln für die WM 2014 folgendermaßen ermittelt: Erstes Kriterium ist die Tordifferenz aus allen Gruppenspielen. Sollte diese gleich sein, zählt die höhere Zahl der in allen Gruppenspielen erzielten Tore. Sollten zwei oder mehr Mannschaften in allen diesen Kriterien übereinstimmen, entscheidet der direkte Vergleich dieser Mannschaften (wieder in der Reihenfolge Punkte, Tordifferenz und Anzahl der geschossenen Tore aus den Spielen dieser Mannschaften untereinander) und letztlich das Los.

In den kommenden Runden gilt das K.-o.-System, d. h. nur der Sieger kommt in die jeweils nächste Runde. Steht es nach Ablauf der regulären 90-minütigen Spielzeit unentschieden, geht das Spiel in die Verlängerung. Für die Entscheidung in der Verlängerung galt zwischenzeitlich die Golden-Goal-Regel. Seit der WM 2006 findet die Verlängerung wieder in klassischer Form statt: Nach einer Pause von fünf Minuten wird ohne weitere Pause (nur mit Seitenwechsel) zwei Mal 15 Minuten gespielt. Die Mannschaft, die in der Verlängerung mehr Tore erzielt, hat gewonnen. Sollte nach der Verlängerung immer noch kein Sieger feststehen, entscheidet ein Elfmeterschießen.

Nachdem in der Gruppenphase die Hälfte der Mannschaften ausgeschieden sind, verbleiben 16 Teams, die in den Achtelfinalspielen um ein Weiterkommen kämpfen. Dabei spielt jeder Gruppenerste gegen den Gruppenzweiten einer anderen Gruppe. Die Sieger der Achtelfinals bestreiten eines von vier Spielen, die als Viertelfinale bezeichnet werden. Die vier Sieger dieser Partien dürfen in eines von zwei Halbfinalen einziehen.

Die beiden Verlierer der Halbfinalspiele bestreiten das Spiel um den dritten Platz der WM, welches am Vorabend des Finalspiels stattfindet und auch als „Kleines Finale“ bezeichnet wird. Das Finale der Fußball-Weltmeisterschaft ist eines der prestigeträchtigsten und beliebtesten sportlichen Ereignisse, die ein Fußballspieler erleben kann. Das Siegerteam des Finalspiels bekommt den Pokal und darf sich für vier Jahre Weltmeister nennen.

Der Austragungsmodus der Fußballweltmeisterschaften wurde mehrmals geändert. Das erste Turnier 1930 sollte eigentlich komplett im K.-o.-System durchgeführt werden. Da aber nur 13 Mannschaften angereist waren, entschloss man sich, vor dem Start zunächst eine Gruppenphase mit drei Gruppen à drei und einer Gruppe à vier Mannschaften durchzuführen. Dies sollte für die langwierig per Schiff angereisten vier europäischen Teams auch garantieren, dass sie nicht unmittelbar die Rückreise antreten mussten. Die Zusammensetzung der Gruppen wurde nach Ankunft aller Teilnehmer kurz vor dem Turnier gelost. Die Sieger der vier Gruppen spielten im Halbfinale gegeneinander, die beiden Sieger bestritten das Finale. Zum einzigen Mal in der WM-Geschichte wird das Spiel um Platz 3 noch nicht ausgetragen.

1934 und 1938 wurde das Turnier, beginnend mit einem Achtelfinale, komplett im K.-o.-System durchgeführt, wobei alle Partien einer Runde zeitgleich stattfanden. Bei einem Unentschieden nach Verlängerung gab es einen Tag (1934) bzw. zwei bis fünf Tage (1938) später ein Wiederholungsspiel. Danach hätte ggf. das Los entschieden. 1934 musste sich der Gastgeber Italien erst sportlich qualifizieren, der Titelverteidiger verzichtete aus Protest gegen ein Turnier in Europa; 1938 fällt durch den Anschluss Österreichs eine Mannschaft weg und wird stattdessen Teil der deutschen.

Nach dem Zweiten Weltkrieg kehrte man 1950 zum Gruppenmodus in der Vorrunde zurück. Da drei qualifizierte Mannschaften auf die Teilnahme verzichteten, gab es zwei Gruppen mit vier, eine Gruppe mit drei und eine mit lediglich zwei Teams, also einer einzigen Partie. Dies stieß in der nächsten Runde auf Kritik, da die uruguayische Mannschaft damit nur ein Spiel absolviert hatte, während es bei der brasilianischen drei Spiele waren. Die vier Gruppensieger spielten anschließend in einer weiteren Gruppenrunde den Weltmeister aus, so dass es kein offizielles Endspiel gab. Jedoch ergab es sich, dass im dritten Spiel die beiden bestplatzierten Mannschaften aufeinandertrafen. Den bis heute einmaligen Modus hatte zur damaligen Zeit noch der Ausrichter des Turniers bestimmt.

1954 wurde die Vorrunde in einem sehr ungewöhnlichen Gruppenmodus mit vier Gruppen durchgeführt: Pro Gruppe waren zwei Teams gesetzt, die gar nicht gegeneinander spielen mussten. Endeten Spiele in der Gruppenphase remis, wurden sie um zweimal 15 Minuten verlängert, bevor das Endergebnis zählte. Bei Punktgleichheit des Zweiten und Dritten gab es ein Entscheidungsspiel, zwischen dem Ersten und Zweiten einen Losentscheid. Das Torverhältnis spielte keine Rolle. Der Versuch, favorisierte Mannschaften durch den Setzmodus in der Vorrunde zu schonen, führte jedoch nur zu geringen Punkteausbeuten, die insgesamt je zwei Entscheidungsspiele und Losentscheide notwendig machten. Anschließend fand eine K.-o.-Runde statt, bei der die teils gelosten Gruppensieger gegen die Zweiten spielten. Erstmals trugen die Mannschaften feste Rückennummern.

1958 wurde die Vorrunde ebenfalls im Gruppenmodus, aber ohne gesetzte Teams gespielt, bei Punktgleichheit gab es aber weiterhin direkt Entscheidungsspiele. Die K.-o.-Runde wurde wieder im Überkreuzvergleich (Erster gegen Zweiter einer anderen Gruppe) durchgeführt.

1962 bis 1970 wurde für die Ermittlung der Gruppensieger und -zweiten bei Punktgleichheit erstmals das Torverhältnis (Quotient) herangezogen, seit 1974 ist es die Tordifferenz, so wie heute noch üblich. 1970 wurden die Gelbe und die Rote Karte sowie die Möglichkeit zu zwei Auswechslungen eingeführt.

1974 und 1978 folgte nach der Vorrunde mit 16 Mannschaften eine Zwischenrunde, in der je zwei Gruppensieger und Gruppenzweite in zwei Gruppen wieder jeder gegen jeden die Endspielteilnehmer ausspielten. Die beiden Zwischenrundenzweiten spielten den dritten Platz aus. Es gab also keine Halbfinalspiele.

1982 wurde erstmals ein Turnier mit 24 Mannschaften durchgeführt. Nach der Vorrunde im nun üblichen Gruppenmodus erfolgte eine Zwischenrunde mit vier Gruppen à drei Mannschaften. Die Gruppensieger spielten im Halbfinale gegeneinander die beiden Finalisten aus. Bei diesem Turnier wurde auch erstmals ein Elfmeterschießen durchgeführt, wenn ein Spiel nach Verlängerung noch remis stand.

1986 bis 1994 qualifizierten sich neben den sechs Gruppensiegern und Gruppenzweiten noch die vier besten Gruppendritten für das erstmals seit 1938 ausgetragene Achtelfinale.

Seit 1998 wird das Turnier mit 32 Mannschaften durchgeführt. Für das Achtelfinale qualifizieren sich die acht Gruppensieger und -zweiten, wobei zwei Mannschaften aus derselben Gruppe erst wieder im Finale bzw. im Spiel um den dritten Platz aufeinandertreffen können. 2002 jedoch sollte verhindert werden, dass die beiden Veranstalter (Japan und Südkorea) zu früh aufeinandertreffen können, wodurch zwei Mannschaften aus der gleichen Gruppe (Brasilien und Türkei) im Halbfinale erneut gegeneinander spielten. Außerdem gab es 1998 und 2002 das Golden Goal, was bedeutete, dass eine Verlängerung durch das erste erzielte Tor automatisch vor Spielende entschieden wurde.

Seit 2006 ist der amtierende Weltmeister nicht mehr automatisch qualifiziert, sondern nur der Gastgeber. 

Am 10. Januar 2017 beschloss die FIFA, dass 48 Mannschaften in insgesamt 16 Gruppen zu je drei Mannschaften teilnehmen werden. Die Dauer der Vorrunde bleibt damit gleich, es kommt im K.-o.-System ein Sechzehntelfinale hinzu.

Bei der ersten Fußball-Weltmeisterschaft 1930 wurde bekannt gegeben, dass derjenige Verband, dessen Auswahl den Weltpokal dreimal gewinnt, diesen behalten dürfe. Durch den dritten WM-Gewinn der brasilianischen Nationalmannschaft 1970 ging die Trophäe, welche 1946 nach dem FIFA-Präsidenten Coupe Jules Rimet benannt worden war, in den Besitz des Brasilianischen Fußballverbandes über. Das Original wurde 1983 gestohlen und vermutlich eingeschmolzen.

Aus 53 Entwürfen wurde der von dem Italiener Silvio Gazzaniga entworfene FIFA-WM-Pokal ausgewählt, der seit 1974 an den Turniersieger vergeben wird. Der Wanderpokal ist 36,8 cm hoch, wiegt 6175 g und besteht aus 18-karätigem Gold sowie zwei Ringen aus Malachit. Zunächst durfte der amtierende Fußball-Weltmeister den Pokal bis zur nächsten WM behalten. Nun muss der Original-Pokal auf Verlangen der FIFA spätestens bei der Abreise aus dem Gastgeberland der Endrunde der FIFA zurückgegeben werden. Der Weltmeister erhält eine vergoldete Replik. Auch die Replik bleibt Eigentum der FIFA und muss dieser auf Verlangen zurückgegeben werden. Seit 2006 wird der Pokal vor jeder Endrunde im Rahmen der „FIFA World Cup Trophy Tour“ auf eine mehrmonatige Weltreise geschickt und anschließend im Gastgeberland präsentiert.

Die Mannschaften auf dem ersten, zweiten und dritten Platz bekommen Medaillen aus Gold, Silber oder Bronze.

Insgesamt sind in der FIFA 209 nationale Fußballverbände registriert. (Stand: November 2013.) Bis einschließlich der WM 2014 waren 77 dieser Verbände bei einer Weltmeisterschafts-Endrunde mit einer eigenen Auswahl vertreten. Die folgende Liste gibt einen Überblick der WM-Premieren aller bisherigen Teilnehmer einschließlich der zum jeweiligen Zeitpunkt gültigen Bezeichnung ihres Staates bzw. Teilstaates.


Seit einigen Jahren wird die Anzahl der bisher erworbenen Weltmeistertitel durch Sterne dargestellt, die meist oberhalb der Logos des Fußballverbands auf dem Trikot der Nationalmannschaften angebracht sind. Als erste Mannschaft trug Brasilien 1971 drei Sterne, heute sind es fünf (siehe auch Meisterstern).

Am Ende einer jeden Fußball-Weltmeisterschaft werden mehrere Auszeichnungen an die besten Spieler und das fairste Team verliehen. Bis zur WM 1966 wurden keine offiziellen Auszeichnungen vergeben. Aktuell gibt es fünf verschiedene Auszeichnungen:

Darüber hinaus werden per Internet-Abstimmung gewählt:


Nachträglich ermittelte die FIFA, per Internet-Abstimmung, auch den Besten Jungen Spieler für die Weltmeisterschaften 1958 bis 2002.

Folgende Fußballer wurden bisher im Rahmen von Fußballweltmeisterschaften des Dopings überführt:


Alternative Konzepte zur Fußball-Weltmeisterschaft der FIFA sind z. B.




</doc>
<doc id="1683" url="https://de.wikipedia.org/wiki?curid=1683" title="Französische Euromünzen">
Französische Euromünzen

Die französischen Euromünzen sind die in Frankreich in Umlauf gebrachten Euromünzen der gemeinsamen europäischen Währung Euro. Am 1. Januar 1999 trat Frankreich der Eurozone bei, womit die Einführung des Euros als zukünftiges Zahlungsmittel gültig wurde.

Sie haben für jede der drei Münzreihen ein eigenes Motiv. Die kleinste Reihe wurde von Fabienne Courtiade entworfen, die mittlere von Laurent Jorio und Oscar Roty sowie die 1- und 2-Euro-Münzen von Joaquim Jimenez. Alle Entwürfe zeigen die zwölf Sterne der EU und das Prägejahr sowie die Buchstaben "RF" für "République Française" (Französische Republik). Die französischen Euromünzen zeigen als Jahreszahl nicht das Ausgabe-, sondern das Prägedatum, sodass die früheste Jahreszahl 1999 ist. Geprägt werden sie in der französischen Münzprägestätte Établissement Monétaire in Pessac mit dem "Füllhorn" als Zeichen. Außerdem findet sich auf den französischen Euromünzen auch das Zeichen des Münzmeisters:


Die drei Motive der französischen Euromünzen sind:


Wie die meisten Euroländer prägt Frankreich bereits seit 2007 seine Euromünzen mit der neu gestalteten Vorderseite (neue Europakarte).

→ "Hauptartikel:" 2-Euro-Gedenkmünzen

Frankreich hat bis heute folgende 2-Euro-Gedenkmünzen ausgegeben:

zukünftige Ausgaben




</doc>
<doc id="1684" url="https://de.wikipedia.org/wiki?curid=1684" title="Finnische Euromünzen">
Finnische Euromünzen

Die finnischen Euromünzen sind die in Finnland in Umlauf gebrachten Euromünzen der gemeinsamen europäischen Währung Euro. Am 1. Januar 1999 trat Finnland der Eurozone bei, womit die Einführung des Euros als zukünftiges Zahlungsmittel gültig wurde.
Die 1- und 2-Cent-Münzen werden nur in sehr geringer Auflage geprägt und nur aufgrund der von der EZB aufgelegten Pflicht, diese prägen zu müssen. Sie sind im normalen Zahlungsverkehr nicht im Umlauf. Hauptgrund dafür ist die Tradition, keine kleinen Münzen zu verwenden, sowie die Rundung kleiner Beträge in den nordeuropäischen Ländern bei Barzahlung. Der Staatssekretär im finnischen Finanzministerium erklärte sogar, dass diese kleinen Münzen oftmals weggeworfen würden, da sie praktisch keinen Wert hätten und auch von Banken nur gegen hohe Gebühren eingetauscht würden. 

Nachdem 2002 die Ausgabe der 1- und 2-Cent-Münzen noch bei der Zentralbank in Helsinki praktiziert wurde, entwickelte sich eine hohe Nachfrage am öffentlichen Schalter der Zentralbank und eine Schlange von mehreren Kilometern. Die Polizei verbot daraufhin den Verkauf der Münzen. Seitdem werden die Münzen nur noch an Händler zum Nominalwert verkauft, die die Münzen zu einem beliebigen Preis weiterverkaufen dürfen. Für eine Rolle 1-Cent-Münzen muss in Finnland mit einem Preis von mindestens 20 Euro gerechnet werden, 2-Cent-Münzen sind teurer und die gemischten Rollen in Bezug auf das Prägungsjahr billiger als die, die nur Münzen aus einem Jahr beinhalten.

Ein- und Zwei-Cent-Münzen zählen als gesetzliches Zahlungsmittel und müssen daher auch in Finnland von Geschäften angenommen werden, etwa wenn Touristen sie aus anderen Staaten der Euro-Zone mitbringen. Dies ändert jedoch nichts daran, dass bei Barzahlung der Endbetrag laut Gesetz immer auf 5 Cent gerundet wird. In der Praxis werden Ein- und Zwei-Cent-Münzen trotz der gesetzlichen Verpflichtung nicht immer angenommen.

Alle Münzen werden in der finnischen Münzprägestätte in Helsinki geprägt.

Die Münzen der ersten Prägeserie haben drei Motive, zwei davon auf nur je einer Münze. Das Design für die sechs kleinsten Münzen stammt von Heikki Häiväoja, der Entwurf für die 1-Euro-Münze von Pertti Mäkinen und die nationale Seite der 2-Euro-Münze von Raimo Heino. Alle Designs enthalten die zwölf Sterne der EU und das Prägejahr sowie das Münzzeichen "M", das Initial des finnischen Münzmeisters Raimo Makkonen.

Die drei Motive der finnischen Euromünzen sind:

2007 begann Finnland mit der von der EU geforderten Neugestaltung der Münzen. Gleichzeitig wurden diese Münzen, wie in den meisten Euroländern, mit der neu gestalteten Vorderseite mit erweiterter Europakarte geprägt. Die Motive der Münzen wurden dabei nicht geändert, nur wenige Details waren von der Umgestaltung betroffen. Das Münzmeisterzeichen "M" entfiel, dafür wurden die Länderkennung "FI" und zwischen dem 8- und dem 9-Uhr-Stern das Logo der finnischen Münzprägestätte ergänzt.

2008 wurde das Münzzeichen nach innen verschoben, sodass es sich nun nicht mehr auf dem äußeren Ring befindet. 

Mitte 2010 erhielt die Prägestätte ein neues Logo. Auf den Kursmünzen wird dieses seit 2011 verwendet.

→ "Hauptartikel:" 2-Euro-Gedenkmünzen

Finnland hat bis heute folgende 2-Euro-Gedenkmünzen ausgegeben:


zukünftige Ausgaben

Material: 925er Silber – Münzdurchmesser: 38,6 mm – Gewicht: 27,4 g (bis 2004); 25,5 g (ab 2005)

Material: Bimetall, Ring: 925er Silber, Kern: 750er Gold – Münzdurchmesser: 27,25 mm – Gewicht: 12,8 g




</doc>
<doc id="1685" url="https://de.wikipedia.org/wiki?curid=1685" title="Fennek">
Fennek

Der Fennek oder Wüstenfuchs ("Vulpes zerda") ist eine Fuchsart aus der Gattung "Vulpes". Er ist der kleinste aller Wildhunde und bewohnt die Sandwüsten Nordafrikas. Die Art zeigt zahlreiche Anpassungen an das Wüstenklima, etwa die geringe Körpergröße, behaarte Sohlen und große Ohren, die der Wärmeregulation dienen. Der Fennek ist nacht- und dämmerungsaktiv und frisst als Allesfresser sowohl Wirbellose und kleine Wirbeltiere als auch Früchte und Knollen.

Fenneks leben für gewöhnlich in Paaren; die meist zwei bis fünf Jungen pro Wurf kommen zwischen März und April zur Welt. Während der Trage- und Säugezeit versorgt und beschützt das Männchen das Weibchen und den Wurf. Der Erdbau des Fenneks ist im Regelfall einfach und wird meist in lockeren Sand gegraben, nur in festerem Untergrund nimmt er komplexere Formen an. Der nächste Verwandte des Fenneks ist der Afghanfuchs ("Vulpes cana"), der auf der Arabischen Halbinsel, im Iran und in Afghanistan lebt. Obwohl Fenneks regelmäßig wegen ihres Fells oder für touristische Schauvorführungen gefangen werden, gilt der Bestand nicht als bedroht. Die IUCN klassifiziert die Art als "Least Concern" (nicht gefährdet). Der Fennek wird seit der Jungsteinzeit von den Menschen Nordafrikas als Nahrungs- und Felllieferant genutzt und seit dem 20. Jahrhundert vor allem in Nordamerika auch als Haustier gehalten.

Der Fennek ist die kleinste aller Hundearten und verfügt über sehr große Ohren. Seine Kopf-Rumpf-Länge beträgt 333–395 mm, der Schwanz wird 125–250 mm lang. Sein Geburtsgewicht beträgt zwischen 80 und 187 g, das Gewicht adulter Tiere 1,0 bis 1,5 kg. Die Ohren machen 20 % der Körperoberfläche aus und werden 86–104 mm lang. Damit sind sie proportional größer als bei allen anderen Hunden. Schnauze und Beine sind schlank und zierlich. Der Schädel entspricht in den Proportionen dem anderer "Vulpes"-Arten, besitzt aber sehr große Paukenhöhlen, ein typisches Merkmal von Wüstenbewohnern. Die Zahnformel lautet I 3/3 – C 1/1 – P 4/4 – M 2/3, der Fennek hat also insgesamt 42 Zähne. Sie sind kleiner und schmaler als bei anderen Arten der Gattung. Der Penisknochen (Baculum) ist 3 mm breit und mit 31–36 mm vergleichsweise lang. 
Das Fell ist sandbraun mit einer beigen, rötlichen oder grauen Tönung. Die Körperunterseite ist heller gefärbt als die Oberseite. Die Ohren besitzen eine dunkle Rückseite, ihre Innenseite und ihre Ränder sind weiß befellt. Die Augen sind verhältnismäßig groß und dunkel, vom Innenwinkel zieht sich eine dunkle Linie hinunter zur Schnauze und umrahmt sie. Ein kürzerer Strich verläuft vom Außenwinkel der Augen in Richtung der Wangen. Die Schenkel sind bei Individuen aus dem nördlichen Teil des Verbreitungsgebietes rötlich gefärbt. Bei Tieren aus dem Süden besitzen sie eine weiße Färbung. Das Fell ist sehr dicht und lang. Die Behaarung der Zehen reicht bis über die Sohlen hinaus und bildet so ein isolierendes Polster für die Füße. Der Schwanz ist dicht behaart, seine Spitze und der Bereich um die Violdrüse sind dunkel gefärbt. Die Weibchen verfügen über drei Zitzenpaare. Der Fennek wechselt sein Fell vom Sommer zum Winter, wobei das Sommerfell etwas kürzer und heller als das Winterfell ist. Jungtiere zeigen eine ähnliche Fellzeichnung wie adulte, sind aber heller und besitzen wenig bis keine Rotanteile im Pelz. Die dunkle Gesichtszeichnung ist bei ihnen nur schwach ausgeprägt. 

Die Nieren des Fenneks sind darauf ausgelegt, hochkonzentrierten Urin zu filtern und dabei so wenig Wasser wie möglich zu verbrauchen. Die Metabolismusrate des Fenneks ist sehr niedrig und liegt 33 % unter dem Wert, den Tiere seiner Größe gewöhnlicherweise aufweisen. Sein Herz ist 40 % kleiner, als es für seine Körpergröße zu erwarten wäre. Unterhalb von 35 °C Außentemperatur atmet der Fennek mit 23 Zügen pro Minute. Wird dieser Wert jedoch überschritten, kann sich die Atemfrequenz auf bis zu 690 Atemzüge pro Minute erhöhen. Die Blutgefäße in den Ohren und Fußsohlen werden bei Hitze erweitert, um möglichst viel Wärme nach außen abzugeben.  Der Fennek hat 2n = 46 Chromosomen.

Die Stimme des Fenneks ist hoch und ähnelt der kleiner Haushunde. Sein Rufrepertoire ist umfangreich und mitunter melodiös. Schwaches Gebell dient als Warnruf vor Fressfeinden, an Hauskatzen erinnerndes Schnurren als Ausdruck des Wohlbefindens. Als Drohgebärde stößt der Fennek ein hohes Kläffen aus. Partner, Eltern oder andere Individuen, zu denen die Tiere einen positiven Bezug haben, werden mit Quieken begrüßt. 

Das Verbreitungsgebiet des Fenneks umfasst die gesamte Sahara und wird durch Gebiete mit gemäßigtem beziehungsweise humiderem Klima begrenzt. Die nordwestliche Verbreitungsgrenze bilden die südlichen Ausläufer des Atlas, während das Artareal in Tripolitanien fast bis an die Küste reicht. In Ägypten wird es in etwa vom Nil begrenzt, reicht aber im Norden bis auf die nordwestliche Sinai-Halbinsel. Im Sudan umfasst das Verbreitungsgebiet auch weiter östlich gelegene Gebiete als in Ägypten, wie etwa die Nubische Wüste. Insgesamt fehlt der Fennek aber entlang der Küstenregion zum Roten Meer. In Mauretanien und Marokko kommt der Fennek bis knapp an die Atlantikküste vor. Die Südgrenze des Verbreitungsgebiets markiert die nördliche Sahelzone, wo der Fennek etwa bis 14° N vorkommt.

Fraglich ist, ob es auf der Arabischen Halbinsel Vorkommen des Fenneks gibt oder gab. Zwar wurden von dort mehrere Sichtungen gemeldet, teils handelte es sich aber nur um Fußspuren im Sand oder um Rüppellfüchse ("V. rueppelli"), die für Fenneks gehalten wurden. Die IUCN geht nicht davon aus, dass die Art östlich des Sinai vorkommt, andere Autoren halten es zumindest für möglich.

Das Habitat des Fenneks besteht vorwiegend aus hyperariden Sandwüsten (Erg), wo er im flachen Boden oder in statischen Dünen seine Baue anlegt. Nahe der marokkanischen Atlantikküste nutzt der Fennek aber auch moderat bewachsene Dünen für seinen Bau. Da der Fennek auf weichen Untergrund angewiesen ist, um seinen Bau zu graben, fehlt er in Gebieten ohne Sand. Der jährliche Niederschlag an der Nordgrenze des Verbreitungsgebiets beträgt rund 100 mm, in der Sahelregion sind es 300 mm. Süßgräser der Gattung "Aristida" und der Meerträubel "Ephedra alata" auf Großdünen sowie die Rispenhirse "Panicum turgidum" und Jochblätter ("Zygophyllum" spp.) auf kleineren Dünen bilden oft die einzige Vegetation im Lebensraum des Fenneks. Selten finden sich auch Akazien ("Acacia" spp.) darunter. Der Fennek ist offenbar nicht auf einen direkten Zugang zu Wasseransammlungen angewiesen.

Die Nahrung des Fenneks ist vielfältig. Sie umfasst vor allem Insekten, kleine Nagetiere wie Wüstenspringmäuse ("Jaculus" spp.), Echte Rennmäuse ("Gerbillus" spp.) oder Rennratten ("Meriones" spp.), Eidechsen, Skinke, Geckos sowie Eier und kleine Vögel wie Steinlerchen ("Ammomanes deserti") oder Flughühner. Daneben verzehrt der Fennek auch Früchte und einige Pflanzenknollen.

Fenneks gehen während der Dämmerung und nachts auf Nahrungssuche und meiden die Hitze des Tages. Im Winter reicht die Aktivitätsphase auch bis in den Morgen hinein. Der für andere "Vulpes"-Arten typische Mäusesprung wurde bei Fenneks nicht beobachtet. Fenneks graben regelmäßig im Sand nach Insekten und kleinen Wirbeltieren. Die vergrößerten Paukenhöhlen ermöglichen es ihnen, auch sehr tiefe Geräusche wahrzunehmen und damit Bewegungen im Sand zu hören. Überzähliges Futter vergraben sie. Menschliche Siedlungen und Lager werden nachts häufig zur Nahrungssuche aufgesucht. Fenneks müssen in freier Wildbahn nicht trinken, in Gefangenschaft nehmen sie jedoch bereitwillig Wasser und andere Flüssigkeiten zu sich. Das für ihren Organismus nötige Wasser gewinnen sie wahrscheinlich aus den flüssigen Komponenten ihrer Nahrung oder durch Oxidation von in ihr enthaltenem Wasserstoff.

Fenneks leben in kleineren Familienverbänden, die das Elternpaar und die Jungtiere des letzten Wurfes umfassen. Größere soziale Verbände bilden sie nur auf engem Raum in Gefangenschaft, in freier Wildbahn wurde ein solches Verhalten bisher nicht beobachtet. Sowohl Jungtiere als auch ausgewachsene Fenneks spielen häufig. In Gefangenschaft zeigen sie ein hohes Maß an sozialer Bindung und schlafen für gewöhnlich dicht nebeneinander. Kot wird in Gefangenschaft in der Regel vergraben.

Der Bau wird etwa 1 m tief im Sand angelegt, nach Möglichkeit im Schutz von Vegetation. Je fester der Untergrund, desto komplexer ist in der Regel das Gangsystem: Während der Bau in losem Sand oft nur aus einem einzelnen Eingang, einem 1–2,5 m langen Gang und einer Hauptkammer besteht, wurden in kompakterem Boden Baue mit einer Fläche von 120 m² und 15 Eingängen gefunden, teils mit 10 m langen Gängen. Einzelbaue können nahe beieinander liegen und sogar untereinander verbunden sein.

Der Sexualzyklus der Art umfasst einen Proöstrus von etwa sechs Tagen und einen lediglich ein- bis zweitägigen Östrus. Die Paarung findet im Januar und Februar statt und dauert für ein Säugetier ungewöhnlich lange, bis zu 2 Stunden und 45 Minuten. Sie wird vom Weibchen eingeleitet, indem es den Schwanz zur Seite streckt und sich dem Männchen zur Besteigung anbietet. Die Tragezeit beträgt 50–52 Tage, der Wurf erfolgt also im März oder April. In Gefangenschaft wurden aber auch 62- und 63-tägige Trächtigkeiten beobachtet, Fenneks werfen hier das ganze Jahr über. Der Wurf besteht aus ein bis sechs, meist zwei bis fünf Welpen. Stirbt der erste Wurf, kann es auch zu einem zweiten oder sogar dritten Wurf kommen. Während der Brunft-, Trag- und Säugezeit sind Männchen sehr aggressiv und verteidigen das Weibchen und den Wurf gegen Eindringlinge und Fressfeinde. Das Männchen übernimmt zudem die Nahrungsversorgung während der Zeit, in der das Weibchen dazu nicht in der Lage ist.

Die Jungen werden blind und vollständig behaart geboren. Sie öffnen die Augen nach 8–11 Tagen und bewegen sich mit zwei Wochen erstmals selbstständig fort. Die Zähne brechen etwa zur gleichen Zeit durch. Ab der dritten Lebenswoche fressen die Welpen erstmals Fleisch, sie werden aber 61–70 Tage lang von der Mutter gesäugt. Spielerisches Jagdverhalten zeigen sie ab der siebten Woche nach der Geburt. Die Geschlechtsreife wird mit 9–11 Monaten erreicht. Die Jungen verbleiben rund ein Jahr bei den Eltern, bis die nächste Wurfzeit einsetzt.

Dem kleinen Mitglied der Familie der Füchse werden Lebenserwartungen von 6 bis über 10 Jahren nachgesagt. So beträgt das bisher höchste aufgezeichnete Alter gefangen lebender Tiere 14 Jahre bei einem Rüden und 13 Jahre bei einer Fähe. 

Ein Wüstenfuchs in der Wildnis steht verschiedenen Umweltfaktoren gegenüber. Entsprechend kann sicher eine durchschnittlich deutlich geringere Lebenserwartung der Art in Freiheit gefolgert werden. In seinem Lebensraum gibt es etliche andere Wüstenbewohner, die dem Fennek wegen seiner geringen Körpergröße als potentieller Fressfeind konkurrieren. Von Streifenhyänen ("Hyaena hyaena") und Goldschakalen ("Canis aureus"), aber auch von Haushunde geht dabei die Hauptbedrohung aus. Ob dies auch auf den Wüstenuhu ("Bubo ascalaphus") zutrifft, ist aufgrund lückenhafter Informationen nicht eindeutig.

Die enorme Beweglichkeit des Wüstenfuchses stellt wahrscheinlich seinen effektivsten Mechanismus zur Verteidigung gegen potentielle Fressfeinde dar. Deutlich wird dies besonders in den geringen Jagderfolgen, sogar wenn flinke Windhunde gezielt zum Einsatz gebracht werden.

Innerhalb der Art besteht nur während der Ranz zwischen den Rüden ein verstärkter Konkurrenzkampf. Deshalb enden in diesem Zeitraum Auseinandersetzungen zwischen ihnen immer wieder tödlich. In Gefangenschaft des Menschen sind die Tiere erhöhtem Stress ausgesetzt. Vermehrte Sterblichkeit gerade bei Neugeborenen ist dafür ein deutliches Symptom. 

Neben diesen offensichtlichen Faktoren in seiner Umwelt gibt es eine Mehrzahl diverser Parasiten, die den Fennek als Wirt nutzen. Der Befall durch verschiedene Arten von Band- und Fadenwürmer, aber auch Saug- und "Hakenwürmer" wurde nachgewiesen. Dies gilt ebenfalls für die Infektion mit den parasitären Einzellern der Kokzidie. 

Die gegenwärtige Hauptursache des Populationsrückgangs macht vermutlich der zusätzliche Druck auf die Art des Wüstenfuchses durch Mensch und Bejagen aus, dem diese nicht gewachsen ist.

Erstbeschreiber des Taxons "Vulpes zerda" ist Eberhard August Wilhelm von Zimmermann. Er beschrieb die Art 1780 in seinem Werk "Geographische Geschichte des Menschen und der vierfüßigen Tiere", allerdings noch als "Canis zerda". Das Artepitheton leitete er von einem berberischen Namen des Fenneks ab.  Aufgrund seiner geringen Größe und anderer morphologischer Besonderheiten stellten ihn viele Autoren in eine eigene Gattung "Fennecus". Ab den 1990er Jahren wurde er aber zunehmend der Gattung "Vulpes" zugerechnet, was auch durch DNA-Studien bestätigt wurde. Eine frühere Beschreibung von Anders Fredrik Skjöldebrand aus dem Jahr 1777 hat keine Gültigkeit, da dieser mit „"Vulpes minimus Saarensis"“ kein Binomen als Bezeichnung wählte. Zwar versuchten einige spätere Autoren, diesen Namen als „"Vulpes minimus"“ in das Linnésche System zu integrieren. Er wurde jedoch auf Basis eines 1976 eingereichten Antrags von der International Commission on Zoological Nomenclature 1980 endgültig unterdrückt und für ungültig erklärt, um die Gültigkeit der Gattung "Vulpes" mit dem Rotfuchs ("V. vulpes") als Nominotypisches Taxon sicherzustellen.

Der Fennek repräsentiert einen eher basalen Vertreter der Gattung "Vulpes". Seine Schwesterart ist der Afghanfuchs ("V. cana"), der vor allem aride Gebirgslandschaften und Geröllwüsten entlang des Roten Meeres, im Süden der arabischen Halbinsel und im Mittleren Osten bewohnt. Beide Arten trennten sich DNA-Analysen zufolge vor 3–4,5 Millionen Jahren im Pliozän, als sich in Afrika und im Mittleren Osten die bis heute bestehenden Wüstengebiete herausbildeten. Die ältesten Fossilfunde des Fenneks stammen aus dem Spätpleistozän. Der Fennek ist monotypisch, das heißt, er hat keine Unterarten.

Für den Fennek fehlen verlässliche Bestandsschätzungen. Da die Art in Nordafrika immer noch regelmäßig gefangen und verkauft wird, ist davon auszugehen, dass der Bestand zumindest nicht zurückgeht. Die Hauptgefahr für den Bestand stellt nach wie vor die kommerzielle Jagd dar. Um die Jagd und den Verkauf des Fenneks als Haustier zu beschränken, wurde er 2000 im Anhang II des Washingtoner Artenschutzübereinkommens gelistet; dort ist er aber mittlerweile nicht mehr aufgeführt. In Marokko, Tunesien, Algerien und Ägypten steht der Fennek unter Schutz. Die IUCN stuft den Fennek trotz unzureichender Informationen über den Bestand als ungefährdet ein. Die Canid Specialist Group der IUCN erklärte den Fennek 2007 zu einer Art mit hoher Forschungspriorität, um damit die Forschung in freier Wildbahn voranzutreiben.

Die wirtschaftliche Nutzung und kulturelle Rezeption des Fenneks reichen weit in die Menschheitsgeschichte zurück. In der neolithischen Fundstätte Regenfeld nahe Dachla wurden rund 7000 Jahre alte Fennekknochen gefunden, die eine Nutzung als Nahrungsmittel belegen. Bereits in vordynastischer Zeit findet sich der Fennek auf einer Elfenbeintafel aus dem Grab Skorpions I., der in der Naqada-III-Periode (ca. 3200 v. Chr.) das Alte Ägypten regierte. Eine bisweilen als Fennek interpretierte Abbildung eines Caniden auf der Grabkapelle des Nefermaat ist dagegen wohl ein Streifenschakal ("Canis adustus"). Schon in altägyptischer Zeit wurde wahrscheinlich versucht, den Fennek zu domestizieren, um ihn als Fleisch- und Felllieferanten zu nutzen; die Hieroglyphe "ms" (F31) zeigt drei zusammengebundene Fennekfelle. Später wurde er von arabischen Jägern an die Bevölkerung von Oasen verkauft, die ihn in ähnlicher Weise nutzten.

Das ursprünglich wohl persische Wort "fanak" oder "fanaǧ" wurde von den Arabern als auf zahlreiche Pelztiere und deren Fell angewandt und als „Fennek“ zur modernen Bezeichnung für den Wüstenfuchs. Das Epitheton "zerda" kann vom persischen "zarde" abgeleitet werden, das mit der Bedeutung „gelb-blonde Farbe“ oder „Safran“ der Fellfärbung des Tieres entspricht. Die wirtschaftliche und kulturelle Bedeutung war unter der arabischen Bevölkerung Nordafrikas allerdings weit geringer als unter den Nomadenstämmen der Sahara. Während der Fennek in arabischen Gedichten und naturgeschichtlichen Werken kaum auftaucht, existieren allein im Tuareg-Dialekt Tamahaq sechs verschiedene Bezeichnungen für die Art. Diese sehr unterschiedliche Wahrnehmung lässt sich auf die Abwesenheit des Fenneks in den kulturellen Zentren des Arabischen, auf sein unauffälliges Äußeres sowie seine nachtaktive Lebensweise zurückführen. In Nordafrika wird der Fennek auch heute noch verzehrt und seines Fells wegen gejagt. In der Westsahara werden meist Welpen gefangen, gemästet und gegessen, wohingegen der Fennek in Marokko als ungenießbar angesehen wird. Anders als das Fleisch aller anderen Hundearten gilt das des Fenneks als halāl, er wurde von den islamischen Rechtsgelehrten also traditionell nicht als Hundeverwandter betrachtet.

Mit dem aufkommenden Interesse der europäischen Gesellschaften für den Orient rückte der Fennek auch in das Bewusstsein europäischer Künstler. Maler wie Paul Leroy und Étienne Dinet porträtierten ihn vor allem als charakteristisches Haustier der nordafrikanischen Landbevölkerung. Der im 20. Jahrhundert einsetzende Massentourismus in Nordafrika führte dazu, dass Fenneks verstärkt gefangen wurden, um sie zu fotografieren, sie für Geld zur Schau zu stellen oder an Reisende auf Märkten zu verkaufen. Auf diese Weise gelangten Fenneks wahrscheinlich auch in die USA, wo sie heute als Haustiere verbreitet sind. Als solche sind sie vor allem wegen ihrer exotischen Herkunft, ihrer Anhänglichkeit und ihres ausgeprägten Spieltriebs beliebt. Junge Zuchtpaare erzielen hier Preise von bis zu 1500 USD.




</doc>
<doc id="1687" url="https://de.wikipedia.org/wiki?curid=1687" title="Familie (Begriffsklärung)">
Familie (Begriffsklärung)

Familie steht für:

FAMILIE steht für:
Siehe auch:


</doc>
<doc id="1688" url="https://de.wikipedia.org/wiki?curid=1688" title="Fermion">
Fermion

Fermionen (benannt nach Enrico Fermi) sind im physikalischen Sinne alle Teilchen, die der Fermi-Dirac-Statistik genügen. Nach dem Spin-Statistik-Theorem besitzen sie einen halbzahligen Spin, also formula_1, formula_2 etc. Anschaulich gesprochen sind Fermionen diejenigen Teilchen, aus denen die Materie besteht.

Fermionen unterscheiden sich von den Bosonen, die der Bose-Einstein-Statistik genügen und nach dem Spin-Statistik-Theorem einen ganzzahligen Spin besitzen. Ein Elementarteilchen in drei Raumdimensionen ist immer entweder ein Fermion oder ein Boson. In sehr dünnen Schichten, also zweidimensionalen Systemen, gibt es außer Bosonen und Fermionen die sogenannten Anyonen, die einer eigenen Quantenstatistik mit beliebigem (englisch 'any') Spin genügen.

Von der mathematischen Theorie her sind drei Typen von Fermionen möglich:

Zu den Fermionen gehören:

Fermionen gehorchen dem Pauli’schen Ausschlussprinzip, welches besagt, dass zwei Fermionen nicht gleichzeitig an demselben Ort einen identischen Quantenzustand annehmen können. Allgemein gilt, dass die quantenmechanische Wellenfunktion zweier oder mehrerer gleichartiger Fermionen bei Vertauschung zweier Fermionen vollkommen antisymmetrisch sein muss, das heißt, das Vorzeichen ändert sich (Phasenfaktor −1).

Auf die Elektronen in einem Atom angewendet erklärt das Pauli-Prinzip, dass nicht alle Elektronen in denselben Grundzustand fallen können, sondern paarweise die verschiedenen Atomorbitale eines Atoms auffüllen. Erst durch diese Eigenschaft erklärt sich der systematische Aufbau des Periodensystems der chemischen Elemente.

Im Standardmodell der Teilchenphysik gibt es keine elementaren Fermionen mit einem Spin größer als 1/2. Eine Eigenschaft von Fermionen mit dem Spin 1/2 ist, dass ihre quantenmechanische Wellenfunktion nach einer Rotation um 360° das Vorzeichen ändert; erst nach einer Rotation um 720° (also zweimal komplett gedreht) ist der Ausgangszustand wiederhergestellt. Das lässt sich anschaulich mit einer Uhr vergleichen: erst nach einer Drehung des Stundenzeigers um 720° hat man wieder die gleiche Tageszeit.

Im um die Supersymmetrie erweiterten Modell der Elementarteilchen existieren weitere elementare Fermionen. Auf jedes Boson kommt rechnerisch ein Fermion als supersymmetrisches Partnerteilchen, ein so genanntes "Bosino", so dass sich der Spin jeweils um ±1/2 unterscheidet. Die Superpartner der Bosonen werden durch die Endung "-ino" im Namen gekennzeichnet, so heißt z. B. das entsprechende Fermion zum (hypothetischen) Graviton dann "Gravitino".

Genau genommen wird zunächst im Wechselwirkungsbild jedem bosonischen Feld ein fermionisches Feld als Superpartner zugeordnet. Im Massebild ergeben sich die beobachtbaren oder vorhergesagten Teilchen jeweils als Linearkombinationen dieser Felder. Dabei muss die Zahl und der relative Anteil der zu den Mischungen beitragenden Komponenten auf der Seite der fermionischen Superpartner nicht mit den Verhältnissen auf der ursprünglichen bosonischen Seite übereinstimmen. Im einfachsten Fall (ohne oder mit nur geringer Mischung) kann jedoch einem Boson (wie dem oben erwähnten Graviton) ein bestimmtes Fermion oder Bosino (wie das Gravitino) zugeordnet werden.

Bisher wurde keines der postulierten supersymmetrischen Partnerteilchen experimentell nachgewiesen. Sie müssen demnach eine so hohe Masse haben, dass sie unter normalen Bedingungen nicht entstehen. Man hofft, dass die neue Generation der Teilchenbeschleuniger zumindest einige dieser Fermionen direkt oder indirekt nachweisen kann. Mit dem leichtesten supersymmetrischen Teilchen (LSP) hofft man, einen Kandidaten für die Dunkle Materie des Universums zu finden.



</doc>
<doc id="1689" url="https://de.wikipedia.org/wiki?curid=1689" title="Färöische Sprache">
Färöische Sprache

Färöisch [] (färöisch "føroyskt" [], ; daraus abgeleitet die deutsche Bezeichnung "Färöisch" neben (seltenerem) "Färingisch") bildet zusammen mit dem Isländischen die inselnordischen Sprachen im Gegensatz zu den skandinavischen Sprachen Norwegisch, Schwedisch und Dänisch.
Eine ältere Einordnung spricht von Westnordgermanisch und platziert dort Färöisch, Isländisch, westnorwegische Dialekte sowie das ausgestorbene Norn.
Färöisch wird von mindestens 44.000 Menschen auf den politisch zu Dänemark gehörenden und weitreichende Autonomierechte besitzenden Färöern sowie weiteren Färingern im Ausland gesprochen.

Die Gesamtzahl der Muttersprachler auf der Welt ist unklar. Ältere Schätzungen reichen von 60.000 bis zu 100.000, je nachdem, wie gut die Nachkommen von Muttersprachlern außerhalb der Färöer die Sprache noch beherrschen. Die weitaus größte Anzahl von Färöisch sprechenden Menschen außerhalb der Färöer lebt in Dänemark und hier insbesondere in Kopenhagen. Im Jahr 2007 ermittelte die Nordatlantische Gruppe im Folketing erstmals die Gesamtzahl von Färingern der ersten Generation, d. h. mit färöischen Geburtsort und Wohnsitz in Dänemark. Es wurden 7.737 Personen gefunden. Seit 2008 ist jedoch eine stetige Zunahme in der Anzahl dieser Gruppe verzeichnet worden. Ende 2013 lebten laut "Danmarks Statistik" insgesamt 11.696 Menschen in Dänemark, deren Geburtsort auf den Färöern liegt, 4.877 Männer und 6.819 Frauen. Es kann davon ausgegangen werden, dass diese Personengruppe (die erste Generation) die färöische Sprache als Muttersprache beherrscht. Hinzu kommen noch Menschen, die in Dänemark geboren wurden und bei Färöisch sprechenden Eltern bzw. Elternteilen aufgewachsen sind, die zweite Generation, sowie in Teilen auch noch die dritte Generation. Neuere Schätzungen gehen sogar von einer Gesamtzahl von 30.000 Färingern in Dänemark aus, wovon die Hälfte, also 15.000 Personen, im Großraum Kopenhagen leben soll. Unklar ist hier jedoch, wie viele davon die Sprache noch aktiv sprechen können.

Färöisch gehört damit zu den kleineren germanischen Sprachen (indogermanische Sprachfamilie).

In färöischer Sprache werden viele Bücher herausgegeben. Von 1822 bis 2002 erschienen 4306 Titel, wobei das Jahr 2000 mit 170 Titeln (darunter 66 Übersetzungen aus anderen Sprachen) der bisherige Rekord ist, ein Buchtitel auf etwa 325 Einwohner.

Nicht zuletzt durch ihren Status als Amtssprache auf den Färöern und durch die reichhaltige färöische Literatur gilt sie heute als nicht mehr gefährdet gegenüber der Dominanz des Dänischen bis in das 20. Jahrhundert hinein.

Färöisch und Isländisch sind gegenseitig in der "Schriftsprache" verständlich. Beide modernen Sprachformen stehen in grammatischer Hinsicht noch dem Altwestnordischen nahe. Die gegenseitige Verständlichkeit der "gesprochenen" Sprachen Färöisch und Isländisch ist hingegen eingeschränkt. Hammershaimb (1891) spricht von gegenseitiger Verständlichkeit zwischen Färöisch und westnorwegischen Dialekten, mit denen es größere Übereinstimmungen im Vokabular aufweise. Wie weit das heute noch gegeben ist, ist fraglich, denn es spielt auch die Zweisprachigkeit bei den Färingern eine wichtige Rolle, sie lernen Dänisch bis auf annähernd muttersprachliches Niveau und können auch deshalb Norwegisch gut verstehen.

Das nordische Dialektkontinuum wird heute nur noch für die festlandskandinavischen Dialekte in Norwegen, Schweden und Dänemark angenommen, trotzdem soll die färöische Schriftsprache vielen Norwegern relativ leicht verständlich erscheinen.

Die alte Kolonialsprache Dänisch hingegen ist mit Färöisch weder in Schrift noch Aussprache gegenseitig verständlich, obwohl sie von der gemeinsamen urnordischen Vorläufersprache abstammt. Dänen können ohne weitere Färöischkenntnisse in der Regel nur einen Teil geschriebener Texte entziffern und von der gesprochenen Sprache nur einzelne Wörter erahnen. Färinger hingegen lernen Dänisch ab der 3. Klasse in der Schule und beherrschen es (in der Schriftsprache) oft auf muttersprachlichem Niveau. Den färöischen Akzent – "gøtudanskt" genannt – hört man aber meist heraus.

Obwohl Isländisch und Färöisch von allen skandinavischen Sprachen dem Altwestnordischen phonologisch und grammatisch am nächsten sind, müssen Isländer und Färinger gleichermaßen üben, um es zu verstehen. Generell lässt sich sagen, dass sich Färöisch mehr vom Ursprung entfernt hat als Isländisch. Dies zeigt sich besonders bei der Flexion der Substantive und Verben, die einfacher ausfallen als im Altnordischen, aber weitaus komplexer als im Dänischen.

Trotz der relativ geringen Bevölkerung und Fläche der Färöer gibt es aufgrund der geographischen Situation große Dialektunterschiede (im Gegensatz zum viel weitläufigeren Island). Die wichtigste Isoglosse läuft entlang dem Skopunarfjørður als Wasserstraße zwischen Sandoy und Streymoy (auf der Abbildung rot markiert: „short ó“). Sie teilt das Färöische in die Hauptgruppen:

Die Trennung der beiden Hauptdialekte fand im 15. Jahrhundert statt. Typische Merkmale sind:

Die Dialektgruppe "nordfjords" zerfällt in:
Diese können auch in zwei Gruppen zusammengefasst werden: Tórshavn-Vágar und Eysturoy-Nordinseln (durch die grüne Isoglosse auf der Abbildung getrennt).

Die Dialektgruppe "südfjords" zerfällt in:

Als „standardsprachlich“ gelten die Dialekte von Vágar oder Tórshavn. Sprecher sowohl des Nordinseln- als auch des Suðuroy-Dialekts kann man am deutlichsten davon unterscheiden. Daher erscheint es sinnvoll, von drei Hauptgruppen zu sprechen:
Hierbei bilden 1. und 2. wiederum eine Gruppe, die deutlich von 3. unterschieden werden kann. Der Skopunarfjørður hat daher also eine ähnliche Bedeutung für das Färöische, wie die Benrather Linie für das Deutsche.

Bereits Jens Christian Svabo berichtete Ende des 18. Jahrhunderts in seinem Vorwort zum "Dictionarium Færoense" von diesen drei Hauptdialekten. Den Nordinseln-Dialekt und den Südinseln-Dialekt sah er als das „reinste“ Färöisch an, während er das Tórshavnerisch als „verdorben“ bezeichnete. Die „Korrumpiertheit“ des Tórshavner Dialekts führt Svabo vermutlich auf den dortigen Einfluss der Kolonialsprache Dänisch zurück.

Auch wenn es bis heute keine Standardaussprache des Färöischen gibt, orientieren sich Ausspracheangaben in etwa am Dialekt von Tórshavn/Südstreymoy, welcher auch die höchste Sprecherzahl hat.

Das heutige Färöisch ähnelt im Schriftbild dem Altnordischen, aber es gab Lautverschiebungen, und zwar so, dass es heute zwei Hauptvarietäten (Nord und Süd) gibt.

Das Altwestnordische "(Altnorwegisch)" kam im 9. Jahrhundert in der Wikingerzeit auf die Färöer. Die meisten Siedler stammten aus dem südwestlichen Norwegen. Gälische Sprachreste belegen, dass ein Teil der nordischen Einwanderer über die britischen Inseln kam.

Durch die Christianisierung der Färöer um 1000 fielen die Inseln an Norwegen, was den sprachlichen Einfluss weiter verfestigte. Lautstand, Formenbau, Wortschatz und Satzbildung des Norwegischen finden sich auch im Färöischen wieder.

Der älteste bekannte Runenstein, der auf den Färöern gefunden wurde, ist der Kirkjubøstein von ca. 1000. Der Sandavágsstein stammt aus dem 12. Jahrhundert, und der Fámjinsstein aus dem 16. Jahrhundert. Letzterer belegt die (teilweise) Verwendung der Runenschrift bis in die Zeit nach der Reformation.

Bis ins 13. Jahrhundert unterschied sich die westnordische Sprache auf den Färöern kaum von den Sprachformen in Island und Norwegen.

Erstes färöisches Dokument in lateinischer Schrift ist der "Schafsbrief" („Seyðabrævið“) von 1289. Hier zeigen sich bereits vereinzelte Abweichungen vom Norwegischen (Altnordischen), z. B. "girða" statt "gærda" („einzäunen“).

Der Schwarze Tod um 1350 halbierte die färöische Bevölkerung, sodass neue Einwanderer aus Norwegen kamen und der Þ-Laut allmählich verschwand, wie er in den Húsavíkbriefen noch vorkam.

1380 gerieten die Färöer zusammen mit Island in die dänisch-norwegische Personalunion und damit faktisch unter dänische Herrschaft, gleichwohl die nordatlantischen Inseln als norwegische Kolonien betrachtet wurden.

Erst ab dem 15. Jahrhundert bildete sich eine eigenständige färöische Varietät der nordischen Sprache, das Altfäröische im Gegensatz zum Altnordischen, Isländischen oder Norwegischen. Im färöischen Standardlehrbuch "Mállæra" 1997 wird diese Sprachstufe auch „Mittelalterfäröisch“ "(miðaldarføroyskt)" genannt.

Linguistisch entscheidend sind hierfür die Húsavík-Briefe („Húsavíkarbrøvini“), die von 1403 bis 1405 datieren. Anhand von Schreibfehlern des Altnordischen kann nachgewiesen werden, inwieweit sich die färöische Aussprache von diesem unterschied. So steht dort an einer Stelle "hrentadi" statt des korrekten "rentaði" („rentierte“), was nach Jakobsen und Matras ein Hinweis darauf ist, dass im Färöischen kein /h/ mehr vor dem /r/ vorkam, wodurch der verunsicherte Schreiber es vor ein Wort setzte, wo es auch im Altnordischen nicht hingehört hätte. Ein anderes Beispiel ist "huast" statt "kvask" („selbst gesagt“). Hier wäre /kv/ die etymologisch korrekte Aussprache, aber da im Färöischen /hv/ zu /kv/ wurde, konnte der Schreiber auch hier nicht mehr unterscheiden.

Beispiel mit dem Schreibfehler „hrentadi“. Auffallend ist die große Ähnlichkeit des altnordischen/altfäröischen Textes mit der heutigen Grammatik:
Altfäröisch: "en so mykid j Hiatlande ad segs skillingar ok xl hrentadi leigan a huerium tolf manadum ..."
Neufäröisch: "og so mikið í Hetlandi, at seks og fjøruti skillingar rentaði leigan á hvørjum tólf mánaðum ..."
Übersetzung: „und so viel in Shetland, dass für den Kredit alle zwölf Monate sechsundvierzig Schillinge Zinsen anfielen ...“

Die Reformation auf den Färöern 1538 bewirkte, dass Dänisch alleinige Schriftsprache wurde und sich endgültig durchsetzte. Ab ca. 1600 spricht man von der neufäröischen Sprache, die sich in drei Hauptdialekte auffächert. Die Periode bis 1750 wird auch als älteres Neufäröisch bezeichnet.

Das Färöische teilte nach der Reformation ein ähnliches Schicksal wie das Norwegische: Dänisch als Kirchensprache, Rechtssprache und Unterrichtssprache, dänische Lehrbücher und dänische Unterhaltungsliteratur. Die Isländer hingegen wachten über ihre alte Sprache und entwickelten sie in dieser Zeit weiter auf Grundlage des Altnordischen (bis heute). Das Isländische bestand als Literatursprache weiter fort und konnte das ganze Volk unter einer Standardsprache einen, während sich Färöisch und Norwegisch in viele Dialekte aufspalteten.

Eine färöische Schriftsprache gab es ab der Reformation nicht mehr. Es konnte aber – anders als in Norwegen – in den alten Balladen und der überall gesprochenen Alltagssprache überleben. Bis Ende des 18. Jahrhunderts liegen nur sporadische Schriftzeugnisse vor. Zum Beispiel existiert ein Dokument von 1532, das eine Sammlung norwegischer Gesetzestexte beinhaltet und Jógvan Heinason (1541–1602) gehörte.

Die meisten Dokumente bezüglich der Färöer wurden nach der Reformation auf Dänisch geschrieben, aber dort finden sich auch einzelne färöische Wörter, insbesondere Orts- und Personennamen. Die wichtigsten Quellen hierfür sind die "jarðabøkur" (Grundbücher seit 1584 erhalten) und "tingbøkur" (Gerichtsprotokolle seit 1615 erhalten). Hier lässt sich z. B. nachweisen, dass der Ð-Laut nicht mehr ausgesprochen wurde.

Im ersten Buch über die Färöer, "Færoæ & Færoa Reserata" schreibt Lucas Debes 1673:

Mit anderen Worten empfand man zu Debes' Zeiten die färöische Landessprache oft noch als eine Art Norwegisch. Hammershaimb weist in seiner "Færøsk Anthologi" 1891 nach, dass Debes eine Festrede zitiert, in der, trotz dänischem Duktus, altnordische Wendungen erkennbar sind. Debes verwendet auch andernorts in seiner Reisebeschreibung typisch färöische Begriffe.

In den alten Tanzballaden haben zum Teil veraltete Wörter und Flexionen überlebt, aber es ist meist unmöglich, sie zeitlich zu bestimmen. Diese Wörter und Formen sind im heutigen "Føroysk orðabók" erfasst und entsprechend gekennzeichnet, was die Verständlichkeit des alten Balladenstoffs erleichtert.

Die ersten schriftlichen Fragmente färöischer Balladen finden sich 1639 beim dänischen Altertumsforscher Ole Worm.

Der erste Pionier des geschriebenen Färöisch war der Gelehrte Jens Christian Svabo (1746–1824). Im Rahmen seiner "Indberetninger fra en Reise i Færø 1781–82" sammelte er alte färöische Balladen und schrieb sie als erster nieder. Allerdings gelangten sie erst lange nach seinem Tode zum Druck. Svabos Orthographie orientierte sich am Dialekt von Vágar, versuchte aber bereits eine Standardisierung. Sein "Dictionarium Færoense" (um 1773) ist das erste färöische Wörterbuch. Es existiert in sieben bekannten Manuskripten und wurde 1966 herausgebracht. Es ist ein Wörterbuch Färöisch-Dänisch-Latein. Svabo schrieb das Wörterbuch in der Annahme, dass Färöisch aussterben würde, aber noch für die Nachwelt dokumentiert werden sollte.

Ein Beispiel für Svabos lautnahe und bemerkenswert konsistente Orthographie:
Svabos Schreibweise des Vágar-Dialekts Ende des 18. Jahrhunderts zeigt, dass das Färöische sich seitdem kaum in der Aussprache geändert hat. Dass er /ó/ als /eu/ schreibt, spiegelt die dialektale Aussprache nördlich der Linie Suðuroy-Tórshavn wider (violette Isoglosse auf der Karte oben) als [œu] anstelle von [ɔu].

Das erste gedruckte Buch auf Färöisch trägt den dänischen Titel "Færøiske Qvæder om Sigurd Fofnersbane og hans Æt" und wurde 1822 vom dänischen Pfarrer Hans Christian Lyngbye (1782–1837) verfasst, dokumentierte die Sigurdlieder, die von seinem färöischen Kollegen Johan Henrik Schrøter (1771–1851) gesammelt wurden.

Ein Beispiel von Schrøters Orthographie in dem Buch von 1822, die sehr der von Svabo ähnelt. Auch hier ist die Schreibweise viel näher an der tatsächlichen (Standard-)Aussprache als die heutige Orthographie:

Ein anderer Pionier jener Jahre war Jóannes í Króki (Johannes Clemensen oder Klemensen, 1794–1869), der in der bekannten "Sandoyarbók" (1821–1831) ebenfalls färöische Balladen sammelte. Es ist mit 93 färöischen Balladen das umfangreichste Werk seiner Art, das je von einem Einzelnen zusammen getragen wurde. Seine Schreibweise widerspiegelte den Dialekt von Sandoy. Auch seine Orthographie zeigt bemerkenswerte Ähnlichkeiten mit der heutigen Aussprache. Allerdings ist es keine Lautschrift im Sinne der Svaboschen Orthographie.


Johan Henrik Schrøter besorgte auch die erste Übersetzung des Matthäusevangeliums ("Evangelium Sankta Matthæussa aa Førisk o Dansk" 1823) aus dem Dänischen.

Obwohl das Buch in jeden der rund 1200 färöischen Haushalte gelangte, konnte es sich aber in der Kirche nicht durchsetzen, wo weiterhin Dänisch gepredigt wurde. Es herrschte damals die mehrheitliche Auffassung im Volk, dass das Wort Gottes und die dänische Sprache zusammengehören. Außerdem kamen Beschwerden über bestimmte Wortformen. Søren Sørensen, ein Pfarrer von den Nordinseln, fügte in einem Schreiben an die dänische Bibelgesellschaft sogar die Übersetzung einer kurzen Passage in den Nordinseln-Dialekt hinzu, um dies zu illustrieren.

Schrøter schrieb das Matthäusevangelium im Dialekt von Suðuroy. Im Wesentlichen verwendete Schrøter hierbei die gleiche Orthographie wie bei den Sigurdliedern zuvor. Allerdings schwächte er die Konsonanten /p,t,k/ nach langen Vokalen zu /b,d,g/ ab, wie es für den Südinselndialekt typisch ist, zum Beispiel "leiba" statt "leypa" („laufen“), "foudur" statt "fótur" („Fuß“) und "ruigje" [] statt "ríki" [] („Reich“).

Die Zusammenstellung der Färingersaga "(Færeyínga saga eller Færøboernes Historie)" aus altisländischen Quellen durch den dänischen Altertumsforscher Carl Christian Rafn (1795–1864) war ein weiterer Meilenstein. Bei der Herausgabe 1833 wurde eine färöische Übersetzung mitgeliefert, die auch von Schrøter stammte, diesmal aber im Dialekt von Südstreymoy verfasst war. Hierbei bekam Schrøter Hilfe von seinen Landsleuten Jákup Nolsøe (1775–1869) und Jens Davidson (1803–1878), die Schüler von Svabo waren. Nolsøe war übrigens der erste Färinger, der eine am Altnordischen ausgerichtete etymologische Schreibweise bevorzugte. Er schrieb 1829 auch die erste färöische Grammatik, die aber nie veröffentlicht wurde.

In der Färingersaga machte sich der Einfluss des dänischen Philologen Rasmus Rask (1787–1832) bemerkbar, der Schrøter zu einer verbesserten Orthographie bewegen konnte. Offenbar war Rask von Rafn als Berater herangezogen worden, vermutlich, um die Kritik zu vermeiden, die Schrøters Matthäusevangelium zuvor erntete, und um eine gewisse Standardisierung des Färöischen zu erreichen.

Bereinigt von einigen Inkonsistenzen sieht die Tabelle der verwendeten Vokalzeichen in den ersten neufäröischen Schriften wie folgt aus:

Der dänische Skandinavist Niels Matthias Petersen (1791–1862) polemisierte 1845 gegen die phonetische Orthographie in dem Artikel "Det færøske Sprog", der in "Færdrelandet" erschien. Er argumentierte, dass bisher nicht die Rede von einer färöischen Schriftsprache sein kann, da alles bisher veröffentlichte Material immer nur einen bestimmten Dialekt wiedergab. Eine Schriftsprache müsse aber „die dialektale Harmonie sein, basierend auf der simplen, edlen und ursprünglichen Form der Sprache“. Gleichzeitig betrachtete er die bisherigen Orthographieversuche als hässlich, besonders was die Schreibung der Vokale betrifft. Zudem fehlten ihm Konsonanten als „Stützpfeiler“ der Sprache. Als Beispiel nannte er aus Schröters Färingersaga: "E haldi tä råvuliast", was für ihn aus Sicht der Skandinavistik keinen Sinn habe, sondern "eg haldi täd råduligast" geschrieben werden müsse, damit der Leser überhaupt die Wörter erkennt. Die heutige Schreibweise ist ähnlich: "eg haldi tað ráðuligast" („ich halte das für am ratsamsten“) und wird [] ausgesprochen, also etwa so, wie Schrøter schrieb.

Dabei war Petersens Ansatz ähnlich wie der von Svabo, nämlich „vor dem Untergang retten, was vom Altfäröischen noch gerettet werden kann, und es der Welt in einer Form geben, die entgegenkommend und verständlich ist“. Aber seine Methode unterschied sich, denn Petersen interessierte sich nicht für das gesprochene Färöisch, das nur für Linguisten von Interesse wäre. Petersens Kritik erwies sich als wegweisend für die weitere Entwicklung, die ihm am Herzen lag: „Mit anderen Worten: Es muss eine färöische Schriftsprache geschaffen werden!“

Petersen haben wir die Forderung zu verdanken, dass Färöisch sich an der isländischen Schriftsprache orientieren und für alle lesbar sein soll, die Isländisch oder Altnordisch verstehen. Auch wenn das bedeutete, dass die Färinger dann erst lernen müssten, ihre eigene Sprache zu lesen, so sei die Situation in Dänemark nicht anders, wo man auch von keinem gesprochenen Dialekt ohne weiteres auf die Schriftsprache schließen kann.

Eigentlich wollten V. U. Hammershaimb (1819–1909) und Svend Grundtvig (1824–1883) eine Replik schreiben, und Schrøter tat es auch in der "Berlingske Tidende", aber da der norwegische Historiker Peter Andreas Munch (1810–1863, Onkel von Edvard Munch) Petersens Argumentation in einem Artikel über eine künftige norwegische Schriftsprache zustimmte, verzichteten Hammershaimb und Grundtvig darauf.

Im Sommer 1845 schickte der dänische Gouverneur auf den Färöern, Christian Pløyen (1803–1867), die vom Lehrer Ole Jespersen gesammelten "Zaubersprüche" an C.C. Rafn. Sie waren nach Svabos Orthographie verfasst. Neben dem färöischen Originaltext lieferte er eine dänische Übersetzung mit, bei der ihm wohl Schrøter und Jens Davidsen halfen. Rafn hielt diese Schreibweise aber für nicht geeignet, um sie zu veröffentlichen, und beauftragte den isländischen Philologen und Nationalisten Jón Sigurðsson (1811–1879) mit einer Überarbeitung, einer „Isländifizierung“. Das Ergebnis schickte er an N. M. Petersen mit der Bitte um Kommentare. Als Rafn die Kommentare von Petersen vorliegen hatte, wurde das Ganze an Hammershaimb geschickt, denn Petersen meinte, die letzte Entscheidung müsse ein Färinger treffen.

V. U. Hammershaimb (1819–1909) gilt als der eigentliche Vater der modernen färöischen Schriftsprache. Zunächst war er, wie schon Svabo und Schrøter, ein Anhänger einer lautnahen Schreibung. Erst durch Petersens und Sigurðssons Einfluss kam es hier zum Umdenken.

1844 schrieb er einen Artikel in der dänischen Zeitung "Københavnsposten", wo er einen Regierungsvorschlag über das Schulwesen auf den Färöern kritisierte, in dem Färöisch als „Dialekt“ bezeichnet wurde. Hammershaimb berief sich auf die alten Balladen und Schrøters Übersetzung der Färingersaga als Beleg dafür, dass Färöisch eine Einzelsprache ist, die „Merkmale des Altnordischen bewahrt hat“.

1845 sprang ihm Svend Grundtvig (1824–1883) mit der Streitschrift "Dansken paa Færøerne, et Sidestykke til Tysken i Slesvig" zur Seite. Er argumentierte, dass das Verhältnis zwischen Färöisch und Dänisch mit demjenigen zwischen Dänisch und Deutsch im Herzogtum Schleswig vergleichbar sei, wo die Dänen damals für das Recht auf ihre Sprache kämpften. Grundtvig forderte die Regierung auf, deshalb Färöisch als Nationalsprache anzuerkennen und entsprechend an den Schulen, in der Kirche usw. einzuführen.

1846 erschienen Hammershaimbs ersten Volksmärchen in Rafns wissenschaftlicher Zeitschrift "Annaler for nordisk Oldkyndighed" zusammen mit den o. g. Zaubersprüchen und einigen Kommentaren zur Aussprache.

Das ursprüngliche Manuskript von 1845 hierzu war noch an der letzten Version der Schrøterschen Orthographie orientiert:

Übereinstimmungen sind zum Beispiel:

Neuerungen sind jedoch:

Was 1846 in den Druck gelangte, sah nach dem Einfluss von Sigurðsson und Petersen dann so aus:

Damit war die Grundlage für die heutige färöische Schriftsprache gelegt. Nur noch Kleinigkeiten wurden geändert:

1854 erschien Hammershaimbs "Færøsk sproglære" (Färöische Sprachlehre) ebenfalls in dieser Zeitschrift.

Hierüber schreibt er:
Als Beispiel nennt Hammershaimb den altnordischen Buchstaben ó der in den verschiedenen Dialekten als "ou" oder "ow" (Suðuroy), "eu" oder "öv" (Nordinseln), oder kurz vor zwei Konsonanten "ö" (im Norden vor <gv> "e" oder "æ" (siehe färöische Verschärfung)) geschrieben wurde. Er machte daraus wieder einen Buchstaben, und definierte stattdessen die besonderen Ausspracheregeln hierfür. Damit wurden die altnordische Wörter im Schriftbild leichter erkennbar.

1891 wurde Hammershaimbs Sprachlehre in seiner "Færøsk Anthologi" vollständig überarbeitet und hat bis heute nur wenig an Gültigkeit verloren. Hammershaimbs jüngerer Kollege Jakob Jakobsen trug hierzu maßgeblich bei. Sein Verdienst bei diesem Standardwerk war nicht nur die phonetisch exakte Umschrift und Gegenüberstellung der Dialekte anhand ausführlicher Leseproben, sondern vor allem auch ein Wörterbuch Färöisch-Dänisch mit 10.000 Stichwörtern und durchgängigen Ausspracheangaben. Es bildet den zweiten Band der "Anthologi". Abgesehen von der Unterscheidung zwischen den Buchstaben ø und ö und der Verwendung des x entspricht es weitgehend der heutigen Rechtschreibung.

Jakobsen war zugleich der erste färöische Gelehrte, der neue Begriffe schuf und so das Färöische zu einer modernen Bildungssprache ausbaute. Seine reformierte lautnahe Broyting-Rechtschreibung setzte sich allerdings nicht durch, weswegen Färöisch heute noch sehr dem isländischen und altnordischen Schriftbild ähnelt. Als Beispiel sei hier der Buchstabe ð genannt, der im Färöischen stumm oder ein Gleitvokal ist und daher immer wieder zu Schreibfehlern führt.

Hammershaimbs Freund Svend Grundtvig reiste zusammen mit Jørgen Bloch auf die Färöer, um bei der Sammlung vieler alter Sprachdenkmäler zu helfen. Grundtvig und Bloch verwendeten konsequenterweise Hammershaimbs Orthographie in seiner Sammlung "Føroyja kvæði". Sie schrieben auch das Wörterbuch "Lexicon Færoense" (1887–1888), welches zwar unveröffentlicht blieb, aber die Grundlage für alle weiteren färöischen Wörterbücher bildete. Es hat 15.000 Stichwörter und übertrug u. a. Svabos "Dictionarium Færoense" in die Normalrechtschreibung.

Hammershaimbs Verdienst war es, die färöische Sprache in eine Schriftform gegossen zu haben, die keinen der färöischen Dialekte bevorzugt und gleichzeitig für Kenner des Altnordischen ein Höchstmaß an Lesbarkeit garantiert – allerdings auf Kosten der Nähe zur Aussprache.

Das Neufäröische wurde auf dem Weihnachtstreffen der Färöer 1888 von der sich bildenden Nationalbewegung als künftige Hauptsprache proklamiert. Aber erst mit der Gründung der Unabhängigkeitspartei Sjálvstýrisflokkurin 1906 trat das geschriebene Färöisch als „ernstzunehmende Konkurrentin“ des Dänischen auf.

Der färöische Sprachenstreit in der ersten Hälfte des 20. Jahrhunderts war ein besonders deutlicher Ausdruck des Kulturkampfs für die eigene Nationalsprache. Protagonisten waren Pädagogen wie Símun av Skarði (1872–1942), Jákup Dahl (1878–1944) und A. C. Evensen (1874–1917). Von Dahl stammt die erste Grammatik, die "Føroysk Mállæra". Sein Freund A. C. Evensen konnte die Arbeit am "Føroysk orðabók" („Färöisches Wörterbuch“) nicht vollenden, so dass es nur von A-F reicht.

1927–1928 erschien das erste „richtige“ färöische Wörterbuch von Christian Matras (1900–1988) und Mads Andreas Jacobsen (1891–1944). Es war das "Føroysk-donsk orðabók" ein färöisch-dänisches Wörterbuch, das 1961 in überarbeiteter Ausgabe erschien und mit Ergänzungsband bis heute (2007) maßgeblich ist.

Erst 1937 wurde Färöisch als Schulsprache anerkannt, 1938 als Kirchensprache, und seit der Autonomie der Färöer von 1948 ist es Hauptsprache "(høvuðsmál)" auf der Inselgruppe.

1961 schließlich kam die erste "offizielle" färöische Bibel von Jákup Dahl heraus (vorher gab es schon eine baptistische Ausgabe); das Färöische wurde aber bereits vorher von der Kanzel gepredigt.

Die Gründung der Universität der Färöer 1965 unterstrich den Anspruch, Färöisch als Wissenschaftssprache zu etablieren. Erster Professor für Färöisch war Christian Matras. Er sorgte für die Veröffentlichung der färöischen Balladen ("Føroya kvæði: corpus carminum Færoensium" in 7 Bänden 1941–96) als wichtigstes nationales Sprachdenkmal. Mit dem "Føroyamálsdeildin" gibt es hier zudem das einzige Faroistik-Institut weltweit.

Es sollte bis 1998 dauern, bis die Färinger ihr erstes muttersprachliches Wörterbuch bekamen, das "Føroysk orðabók" von Jóhan Hendrik Winther Poulsen (* 1934) und anderen. Poulsen prägte die heutige färöische Sprachpolitik, die sich in ihrem Purismus (Vermeidung von Fremdwörtern) am Isländischen orientiert. Dadurch ist gewährleistet, dass Färöisch auch heute noch einen relativ eigentümlich anmutenden nordischen Wortschatz aufweist. Beispielsweise wurde aus einem "helikoptari" eine "tyrla", und ein "komputari" heißt inzwischen nur noch "telda".

Dänisch ist offizielle Zweitsprache auf den Färöern, verliert aber im 21. Jahrhundert zunehmend an praktischer Bedeutung gegenüber dem Englischen als Geschäftssprache. Beispielsweise sind die Website und der Briefkopf der Landesregierung der Färöer nur auf Färöisch und Englisch, nicht aber auf Dänisch, während färöische Gesetzestexte immer noch ins Dänische übersetzt werden müssen.

Die meisten Hinweisschilder auf den Färöern sind heute einsprachig auf Färöisch. Dort wo Zweisprachigkeit vonnöten scheint, wird grundsätzlich Englisch verwendet. Dänische Schilder sieht man nur noch an dänischen Einrichtungen.

Genetische Untersuchungen haben ergeben, dass 80 % der männlichen Gene der Färinger skandinavischen (norwegischen) Ursprungs sind und 20 % britischer Herkunft. Bei den Frauen ist dieses Verhältnis genau umgekehrt. Zu 90 % stammen ihre Gene von den Kelten und nur zu 10 % von den Wikingern. Das ist dadurch erklärbar, dass die Wikinger Keltinnen als Frauen und Sklavinnen hatten. Ob sie direkten sprachlichen Einfluss hatten, ist nicht abschließend geklärt. Aber es finden sich einige typische keltische Wörter im Färöischen, wie "dunna" („Ente“), "drunnur" („Rumpf“ bei Schafen und Rindern), "korki" (eine auf den Färöern dominierende Flechte, aus der ein Purpurfarbstoff und Lackmus hergestellt wird) und Ortsnamen wie "Dímun". Auch Redewendungen wie "tað er ótti á mær" („ich habe Angst“, wörtlich „da ist Furcht auf mir“) haben eine keltische, aber keine skandinavische Entsprechung.

Durch die dänische Kolonialsprache, insbesondere seit der Reformation, gelangten viele dänische Lehnwörter ins Färöische. Diese findet man noch heute mehr in der gesprochenen als in der Schriftsprache.

Daneben gibt es auch charakteristische alte englische Lehnwörter, wie zum Beispiel "trupulleiki" (< trouble) „Problem“ und "fittur" (< fit) „fit; nett, süß; ziemlich viel oder gut“. Wenngleich die heutige färöische Sprachpolitik sehr puristisch ist, dringen immer wieder Anglizismen ins Färöische, insbesondere in die gesprochene Sprache.

Das färöische Alphabet hat 29 Buchstaben, die wie folgt klingen können:

Anmerkungen:


Die Buchstaben <ð> und <g> verhalten sich zwischen Vokalen identisch. Sie werden zu einem Gleitvokal /j, v, w,/ je nach Umgebung oder sind stumm. Diese Regeln gelten auch, wenn zwei Vokale in der Schrift aufeinanderstoßen.


In der färöischen Grammatik "Mállæra" 1997 wird nicht zwischen /v/ und /w/ unterschieden.

Das Färöische ist im Gegensatz zu anderen germanischen Sprachen wie Dänisch oder Englisch reicher an Formen. Zum Beispiel ist das Genus-System dem Deutschen sehr ähnlich, es wird also bei Substantive, Pronomina, Adjektiven etc. zwischen drei Geschlechtern unterschieden. Auffallend – und unter den germanischen Sprachen alleine stehend – ist im Färöischen die Pluralform des Zahlworts und unbestimmten Artikels ein, der genauso geschrieben, gesprochen und (im Singular) verwendet wird wie im Deutschen, aber anders gebeugt wird. Hinzu kommen die distributiven Zahlwörter der färöischen Sprache für "zwei" und "drei" "(siehe dort)".

Charakteristisch für die nominal flektierten Wörter im Färöischen ist deren häufige Endung "-ur". Dabei ist das (aus dem Kontext gerissen) keineswegs ein Indikator für eine bestimmte Wortart, noch für ein Geschlecht oder einen Numerus oder Kasus. Ebenso verhält es sich mit den typischen Endungen "-ir" und "-ar". Wie oben bereits erwähnt, können unbetonte Silben (und das sind im Färöischen allgemein die Endsilben) keine anderen, als diese drei Vokale a, i, u tragen. Damit ist es freilich komplizierter als im Deutschen (und anderen Sprachen), wo in diesem Fall meist das e verwendet wird, falls eine Flexionsendung einen Vokal trägt. Dieses System ist auch für Muttersprachler manchmal schwer durchschaubar, zumal erschwerend hinzukommt, dass die "gesprochene Sprache" bestimmte Endungsvokale anders realisiert und manchmal auch in der Rechtschreibung zwei Varianten einer Form zulässig sind.

Andererseits kann gesagt werden, dass sich sowohl bestimmte Paradigmen in der gesprochenen Sprache kaum oder gar nicht von dem altnordischen Ursprung entfernt haben als auch selbst unregelmäßige Formen in bestimmten Fällen Parallelen zum Deutschen aufweisen.

Die färöischen Substantive (Hauptwörter) werden dem Geschlecht (Genus) nach, wie im Deutschen, in drei Gruppen eingeteilt:

Stellvertretend für die drei Geschlechter seien hier zur Veranschaulichung drei häufige Klassen genannt, deren Stammvokale sich "nicht" ändern.

Anmerkungen:

Allgemein unterscheiden sich die skandinavischen Sprachen von den anderen germanischen Sprachen dadurch, dass der bestimmte Artikel dem Substantiv "angehängt" wird, also ein Suffix ist. Dies ist im Färöischen nicht anders, und es bildet in dieser Hinsicht eine Gemeinsamkeit mit dem Norwegischen und Schwedischen, indem es in attributiven Stellungen eine "doppelte Determination" gibt – im Gegensatz zum Dänischen und Isländischen. Das heißt: Wenn ein determiniertes Substantiv durch ein Adjektiv näher beschrieben wird, taucht in dem Satz nicht nur der Artikel als einzelnes Lexem auf, sondern "zusätzlich" noch als Suffix an dem betreffenden Nomen.

Beispiel:
Anmerkung:

Grundsätzlich gilt, dass die Nominativform des angehängten bestimmten Artikels bei männlichen und weiblichen Nomen immer -(i)n und bei sächlichen -(i)ð ist, wobei sich das in den anderen Kasus anders darstellt. Als Faustregel kann gelten, dass sich die oben aufgeführten Nominalflexionen auch im Neutrum (wie in den anderen beiden Genera) so verhalten, dass ein "n" zwischen Stamm und Flexionsendung tritt, und dass die Dativendung -um in diesem Fall nicht nur im Plural, sondern auch im Singular auftritt (als -num).
Der unbestimmte Artikel ein verhält sich wie folgt (identisch mit dem Zahlwort):

Anmerkungen:

Wie im Deutschen gibt es bei Adjektiven (Eigenschaftswörtern) eine starke und eine schwache Beugung. Erstere wird bei unbestimmten Artikeln (ein, kein, einige etc.) verwendet, oder wenn das Hauptwort alleine steht. In diesem Fall trägt das Hauptwort auch keinen angehängten bestimmten Artikel. Adjektive werden nach Genus, Kasus und Numerus gebeugt. Im Wörterbuch steht stets die männliche Nominativform der starken Beugung (erkennbar an der Endung -ur, die in einigen Fällen aber auch zum Wortstamm gehören kann).


In dieser Tabelle sind auch die dazugehörigen Fragewörter angegeben (hvør? = wer?, hvat? = was? usw.).


Färöisch als Fremdsprache wird nur von Ausländern auf den Färöern und einigen Skandinavisten und Färöerfreunden im Ausland beherrscht.

Außerhalb der Färöer wird es lediglich an der Universität Kopenhagen und seit Januar 2011 auch am Nordkolleg Rendsburg unterrichtet. Die Universität der Färöer ist die einzige Bildungseinrichtung mit Färöisch als Hauptstudiengang innerhalb der Skandinavistik.

Das bedeutet auch, dass Kinder von Färingern im Ausland nirgends einen färöischen Schulunterricht bekommen können, außer bei ihren Eltern und der Volkshochschule der Färöer, die seit 2007 einen Sommerkurs für diese Kinder anbietet.

Die Universität der Färöer bietet für erwachsene ausländische Interessenten ebenfalls einen intensiven Sommerkurs in Färöisch an. Dieser findet in der Regel jedes Jahr statt und dauert eine Woche.

Gelehrte im deutschen Sprachraum für Färöisch waren Ernst Krenn (1897–1954) an der Universität Wien und Otmar Werner († 1997) an der Universität Freiburg.

Beispiel aus: W.B. Lockwood, "An Introduction to Modern Faroese". Lockwood verwendet hier eine neufäröische Version der Färingersaga und zitiert den Abschnitt, wo Sigmundur Brestisson vom norwegischen König beauftragt wird, die Färöer zu christianisieren. Die Forschung geht davon aus, dass sich das entsprechende Ting im Jahre 999 auf Tinganes versammelte.

Quelle: Pressemitteilung der Färöischen Landesregierung vom 26. September 2005 (tinganes.fo). Die neue Smyril ist eine hochmoderne Autofähre, die die Fahrtzeit von Suðuroy nach Tórshavn erheblich verkürzt und insbesondere für die Bewohner der Südinsel von immenser Bedeutung ist.



In den folgenden Artikeln werden einzelne färöische Begriffe erklärt:

Es gibt in der deutschen Sprache zwei echte Lehnwörter aus dem Färöischen: Grindwal und Skua (Raubmöwe).


Einen Überblick in deutscher Sprache gibt:
Eine ältere Einführung der färöischen Sigurdlieder für das historisch-vergleichende Studium:


Nur auf Färöisch sind z. B.:

Das Standardwörterbuch ist seit 1998 das einsprachige "Føroysk orðabók", das seit 2007 auch im Internet verfügbar ist (siehe Weblinks). Es wurde unter der Leitung von Prof. Jóhan Hendrik Winther Poulsen erstellt.

Das erste Färöisch-Deutsche Wörterbuch sollte 2008 erscheinen, bisher blieb es jedoch bei der Ankündigung dieses Titels:

Die beiden hier aufgeführten Titel sind färöisch-dänische bzw. dänisch-färöische Wörterbücher. Das "Føroysk-Donsk Orðabók" erschließt einen großen Teil des färöischen Wortschatzes, während das "Donsk-Føroysk Orðabók" wichtige Rückschlüsse auf den färöischen Umgang mit Internationalismen, Anglizismen und niederdeutschen Lehnwörtern gestattet, die im Dänischen häufig sind und in der färöischen Schriftsprache meist vermieden werden.

Das zweibändige Wörterbuch Färöisch-Englisch/Englisch-Färöisch von 2008 ist das größte färöische Wörterbuch bisher:


Auf Färöisch:



</doc>
<doc id="1692" url="https://de.wikipedia.org/wiki?curid=1692" title="Freitag">
Freitag

Der Freitag ist gemäß der Europäischen Norm EN 28601 und dem internationalen Standard ISO 8601 der fünfte Tag der Woche, nach jüdischer, christlicher und islamischer Zählung – in der die Woche mit dem Sonntag beginnt – der sechste.

Der Name geht auf den römischen Tagesnamen "dies Veneris", also Tag der (Liebesgöttin) Venus, und dieser wiederum auf den babylonischen Wochentagsnamen zurück. Als die südlichen Germanen die Siebentagewoche von den Römern übernahmen, übersetzten sie ihn mit ihrer als ähnlich wahrgenommenen Göttin Frija, die im Norden Frigg hieß (vgl. althochdeutsch "frîatac", altenglisch "frīgedeag"). Sie war in der isländischen Edda eher Schutzherrin der Ehe und Mutterschaft. Danach würde man eher die nordgermanische Liebesgöttin Freya an dieser Stelle erwarten, die deshalb auch oft als Namensgeberin des Freitags genannt wird. Allerdings kann ihr Name, der urnordisch "*fraujōn" (Herrin) gelautet hätte, nicht zu "frîatag" geführt haben. Eindeutig geklärt ist die Zuweisung jedoch nicht. Im Altnordischen gab es sowohl die Bezeichnungen "Freyjudagr" als auch "Frjádagr" als Namen für den Freitag, einmal auf Freya und das andere Mal auf Frigg verweisend. Vermutlich war Frijas Rolle ursprünglich der Venus ähnlicher als später in der isländischen Literatur des Mittelalters. In Skandinavien wurde der Name allerdings nicht nach der dortigen Namensform "Frigg" gebildet, sondern nur der südgermanische Name übernommen (vgl. schwedisch fredag).

Die romanischen Namen für Freitag (franz. ', ital. ', span. "") gehen ebenfalls auf die lateinische Bezeichnung "dies Veneris" beziehungsweise "Veneris dies" zurück.

Im Judentum ist der Freitag, hebräisch יום שישי (jom schischi, der sechste Tag) der Rüsttag und Vorabend des Sabbats, der am Freitagabend bei Einbruch der Dunkelheit beginnt. 

Im Christentum gedenken die Gläubigen freitags in besonderer Weise des Leidens und der Kreuzigung Christi. Nach alter Tradition verzichten Christen freitags auf Fleisch (siehe auch Freitagsopfer). Der Karfreitag im Triduum Sacrum gehört zu den höchsten Feiertagen des Kirchenjahres.

Im Islam ist der Freitag der wöchentliche Feiertag, an dem das Mittagsgebet (Salat) in der Gemeinschaft verrichtet wird und der Prediger (Chatib) eine Predigt (Chutba) hält (vgl. Freitagsgebet).

Der Spruch "„Freitag nach eins macht jeder seins.“" bezieht sich auf den besonders in Behörden verbreiteten frühen Feierabend am letzten Arbeitstag der Woche. Das im Englischen existierende "„Thank God it's Friday“" drückt in ähnlicher Weise die Vorfreude auf das in der Regel arbeitsfreie Wochenende aus.

In den letzten 20 Jahren wurde der Freitag bei einem Teil der arbeitenden Bevölkerung immer öfter zum zusätzlichen arbeitsfreien Tag. Zu einem besonders hohen Prozentsatz nehmen dies die Teilzeitbeschäftigten in Anspruch, in manchen Branchen, etwa dem Bauwesen, auch bis zur Hälfte der Vollzeitbeschäftigten. Eine Untersuchung aus der Schweiz, wo der Anteil der Teilzeitarbeit relativ hoch ist, bezeichnet diesen Effekt als „neuen Samstag“.




</doc>
<doc id="1693" url="https://de.wikipedia.org/wiki?curid=1693" title="Freya">
Freya

Freya, auch Freia oder Freyja (altnordisch „Herrin“), ist der Name der nordischen Wanengöttin der Liebe und der Ehe. Sie gilt als zweite Göttin des nordischen Pantheons nach Frigg, mit der sie in neuzeitlichen Rezeptionen oft gleichgesetzt oder verwechselt wird. Sie ähnelt der Venus des römischen Götterhimmels.

Aus der Skalden-Dichtung sind einige Beschreibungen bekannt, die als Freya-Kenningar aufgefasst werden. Dies sind Mardöll, Menglada, Hörn, Gefn, Sýr und Vanadís.
Aufgrund ihres Beinamens Gefn, wird sie (eher spekulativ) auch mit der Göttin Gefjon in Zusammenhang gebracht. Die südgermanische Frija (althochdeutsch Friia, Frea) bezieht sich auf die Asengöttin Frigg.

Freya gehört zu den Wanen, einem der beiden Göttergeschlechter der nordischen Mythologie. Ihr Bruder ist Frey (aisl. Freyr), ihr Vater der Meergott Njörd, als Mutter wird Skadi, Tochter des Riesen Thiazi genannt. Ihr Gatte ist in der eddischen Mythologie der Gott Óðr. Mit ihm hatte sie die Töchter Hnoss und Gersimi (beide Namen sind Synonyme und bedeuten „Kostbarkeit“). Freya gilt als die „berühmteste von den Göttinnen“ (Gylfaginning, Kap. 23).

Sie gilt als die Göttin der Fruchtbarkeit und des Frühlings, des Glücks und der Liebe, sowie als Lehrerin des Zaubers (seiðr).

Freya besitzt ein von Zwergen geschmiedetes Halsband, Brisingamen, einen von Waldkatzen gezogenen Wagen und ein Falkengewand, mit dem man wie ein Falke durch die Lüfte gleiten kann. Nach dem Gedicht "Hyndluljóð" reitet sie auch auf dem Eber Hilisvini. Auch in der Gylfaginning tritt Freya auf. Danach weint sie goldene Tränen, als Oðr fortfährt. Nach der Grímnismál heißt ihr Hof Fólkvangr. Ihr Saal heißt Sessrúmnir. Nach der "Ynglinga saga" Snorris lehrte sie die Asen den Zauber.
Aber ihre Hauptaufgabe liegt darin, dass sie als Anführerin der Walküren auf den Schlachtfeldern daheim ist und die Hälfte der gefallenen Recken beanspruchen darf, während Odin (der oberste Gott, Gott des Krieges) die andere Hälfte zusteht.

Der Wochentag Freitag (ahd. frîatac, ae. frīgedeag) ist genau genommen nicht vom nordgermanischen „Freya“ abgeleitet, sondern von „Frija“, der südgermanischen Namensform der germanischen Göttin Frigg, welche je nach Lesart der (spärlichen!) Quellen von jener zu unterscheiden ist.

Freya spielt in den eddischen Texten "Hyndluljóð, Lokasenna" und "Þrymskviða" eine bedeutende Rolle. In "Grímnismál" erscheint sie als Todesgöttin und in der "Völuspá" schimmert sie durch den Gesang "Ods Braut" (Óðs mey). Auch die Zauberinnen Gullveig und Heid, die in den Strophen davor den Krieg zwischen Asen und Wanen entfachen, werden für Hypostasen der Göttin Freya gehalten. Nach Snorris "Gylfagynning" erhält sie immer, wenn sie einem Kampf beiwohnt, die Hälfte der Gefallenen, die andere Hälfte fällt Odin zu. 

Da es keine südgermanischen (z. B. deutschen oder englischen) Überlieferungen zu Freya gibt und die Südgermanen den Tag der Venus (Freitag) noch mit Frija/Frigg verbanden, wird angenommen, dass Freya eine wikingerzeitliche Loslösung der Aspekte Liebe, Liebesmagie und Promiskuität der Frigg bildet. Dazu sind in der "Edda" und dem "Gylfaginning" folgende Episoden beschrieben: Den Halsschmuck der Freya, der Brisingenschmuck, hatten die Zwerge Alfrigg, Dvalin, Berling und Grervier (Gerr) gefertigt, der Preis des Erwerbs war, dass die Göttin vier aufeinanderfolgende Nächte mit jeweils einem der Zwerge verbrachte – zum Unwillen Odins, der Freya zur Strafe zwang, unter den Menschen einen Krieg anzuzetteln. Eine weitere Berichterstattung besagte, dass Loki beim von Ägir ausgerichteten Trinkgelage alle Anwesenden beschimpft und der Freya vorwirft, sie habe mit allen Asen und Alben im Saal Liebschaften gehabt. Hinzuzufügen bleibt, dass Loki in unerwiderter Liebe zu Freya schmachtete. Die literarischen Ausgestaltungen Freyas während der isländischen Renaissance des 13. und 14. Jahrhunderts sind allerdings keine authentischen Quellen zur heidnischen Gestalt der Göttin. In der Neuzeit hat sie die Göttin Frigg in der isländischen Verarbeitung der alten Sagen vollkommen verdrängt. In einer Illumination in einer Papierhandschrift des 17. Jahrhunderts erscheint sie allerdings nur noch als treusorgende Familienmutter.
Besonders bekannte Quellen über Freya sind zwei Gedichte der Lieder-Edda. In der "Lokasenna" („Schmähreden des Loki“) wirft ihr der Gott Loki vor, mit jedem Gott und jeder mythologischen Gestalt Verkehr gehabt zu haben. In der "Þrymskviða" („Das Lied von Thrym“) hat sie einen Wutausbruch, als die Forderung des Riesen Thrymr (aisl. Þrymr) lautet, ihn heiraten zu sollen, um den Hammer Thors von den Riesen auszulösen, der wichtig für den Fortbestand der Götterwelt ist. Auch in der Gylfaginning und im Grímnismál tritt Freya auf.

Dänische wie schwedische Ortsnamen gehen auf die Göttin zurück. So ist z. B. Fröjel auf Gotland ein wikingerzeitlicher Hafen und Kultplatz der Freya (schwed. Fröja), an dem noch eine Fornborg und eine Trojaburg (nord. Trojeborg) auf die alte Funktion des Ortes verweisen, der auch Thingplatz war. In Dänemark sind in Jütland Frøslev, auf Seeland ebenfalls Frøslev und auf Lolland Frejlev solche Orte.




</doc>
<doc id="1695" url="https://de.wikipedia.org/wiki?curid=1695" title="Fritz Walter">
Fritz Walter

Friedrich „Fritz“ Walter (* 31. Oktober 1920 in Kaiserslautern; † 17. Juni 2002 in Enkenbach-Alsenborn) war ein deutscher Fußballspieler.

Fritz Walter gehört zu den herausragenden Persönlichkeiten des deutschen Fußballsports. Mit ihm als Kapitän gewann die Nationalmannschaft die Weltmeisterschaft 1954. Auch bei der Weltmeisterschaft 1958 war er Stammspieler der deutschen Mannschaft.

Auf Vereinsebene hielt Walter dem 1. FC Kaiserslautern über 30 Jahre lang die Treue und gewann mit ihm zwei deutsche Meisterschaften (1951 und 1953). Für seine fußballerischen und sozialen Verdienste wurde er vielfach geehrt und als damals erster Spieler zum Ehrenspielführer der Nationalelf ernannt.

Friedrich Walter wurde 1920 als ältestes von fünf Kindern in Kaiserslautern geboren. Er hatte zwei Schwestern, Gisela und Sonja, und zwei Brüder, Ludwig und Ottmar, die beide ebenfalls beim 1. FC Kaiserslautern spielten. Mit Ottmar spielte er später gemeinsam in der Nationalmannschaft und gewann mit seinem Bruder den Weltmeistertitel 1954.
Als Sohn des Vereinswirts des 1. FC Kaiserslautern kam der junge Fritz schon in frühester Jugend mit dem Fußball in Kontakt. Seine ersten Schritte auf dem Fußballplatz machte er als Siebenjähriger in der Schülermannschaft des FCK. Zunächst spielte er auf der Position des rechten Verteidigers, schon bald war das Ausnahmetalent ein stadtbekannter Fußballer.

Nach der Schule machte er eine Ausbildung zum Bankkaufmann, bevor er sich 17-jährig 1938 als Mittelläufer des FCK ganz dem Fußball verschrieb. Allerdings benötigte er wegen seines Alters eine Sondergenehmigung. Schnell war Walter der Star der Mannschaft, die in der Gauliga Südwest (ab 1941: Gauliga Westmark) zu den stärksten der Region gehörte. Bereits in der Saison 1939/40 erzielte er in 15 Spielen 30 Treffer.

Wie vielen anderen Fußballern auch, raubte der Zweite Weltkrieg Fritz Walter seine besten Jahre als Sportler. Obwohl Reichstrainer Sepp Herberger für seine Nationalspieler (Walter war seit 1940 Auswahlspieler) Privilegien durchsetzte, wurde Walter 1940 in die Wehrmacht einberufen und als Infanterist nach Frankreich versetzt. Am 15. März 1942 erzielte er im Gauliga-Spiel gegen den FK Pirmasens beim 26:0 dreizehn Tore. Im Achtelfinale der deutschen Meisterschaft scheiterte er mit dem 1. FC Kaiserslautern am späteren Meister FC Schalke 04. Während seiner Zeit als Infanterist im lothringischen Diedenhofen spielte er 1943 zeitweise für die TSG Diedenhofen, für die Soldatenelf „Rote Jäger“ und im Juni 1943 kurzzeitig für die TSG Saargemünd. Später wurde er auf Sardinien, Korsika und Elba eingesetzt.
Nach Kriegsende geriet er in der Ukraine in sowjetische Kriegsgefangenschaft. Das „Spiel seines Lebens“, wie er später jedoch betonte, war nicht das WM-Finale 1954, sondern ein Spiel, das er im Kriegsgefangenenlager bei Máramarossziget in Rumänien machte. Geschwächt von einem Malaria-Anfall spielte er mit den ungarischen und slowakischen Wachsoldaten Fußball. Sie erkannten den deutschen Nationalspieler und stellten ihn dem sowjetischen Lagerkommandanten Major Schukow vor. Angeblich bewahrte Schukow Walter und dessen jüngeren Bruder Ludwig vor dem sibirischen Gulag. Bereits am 28. Oktober 1945 kehrten die Brüder nach Kaiserslautern zurück.

Nach seiner Rückkehr aus der Gefangenschaft spielte Walter wieder für „seinen“ FCK und wirkte bei der Reorganisation des Vereins mit. Als Regisseur auf dem Feld führte er die "Roten Teufel" in die bedeutendste Phase ihrer Clubgeschichte. Zwischen 1945 und 1949 trainierte er auch den 1. FCK. Der Verein entwickelte sich zum erfolgreichsten der frühen Nachkriegszeit. Zwischen 1948 und 1954 wurde er sechsmal Meister der Oberliga Südwest, in der ab 1948 erstmals in Deutschland das Vertragsspielerstatut eingeführt worden war. 1951 gewann Walter mit seiner Mannschaft erstmals die deutsche Meisterschaft (2:1-Sieg über Preußen Münster), 1953 wurde der VfB Stuttgart im Finale mit 4:1 deklassiert. 1948, 1954 und 1955 scheiterte Kaiserslautern im Endspiel.

Walter galt als der beste Fußballer Deutschlands und erhielt Angebote von großen europäischen Spitzenvereinen. 1951 bot Atlético Madrid für einen Zweijahresvertrag 500.000 DM Handgeld, dazu Gehalt, Prämien, Auto, mietfreies Wohnen – damals enorme Summen und Privilegien. „Dehäm is dehäm“ sagte er lapidar zu seiner Entscheidung in der Pfalz zu bleiben. Auch Angebote von Inter Mailand, dem FC Nancy und Racing Paris lehnte der bodenständige Walter ab. Hierzu schrieb er später einmal in einer Kolumne: „‚Schätzche, was mache mer?‘ hab ich meine Frau Italia gefragt. ‚Brauchst du mich doch gar nicht erst zu fragen‘ hat sie mir geantwortet, ‚da oben dein Betzenberg, der Chef, dein FCK, die Nationalmannschaft ……‘“. Herberger hatte zur Unterstützung den adidas-Gründer Adi Dassler davon überzeugt, ihm eine repräsentative Funktion im Unternehmen anzubieten. Mit dem FCK wurde er 1955 bis 57 drei weitere Mal Oberligameister. Man sprach respektvoll von der "Walter-Elf".
In einem Freundschaftsspiel mit dem FCK erzielte er 1956 sein legendäres Hackentor von Leipzig im Spiel gegen den SC Wismut Karl-Marx-Stadt. Es wird als eines der besten Tore aller Zeiten bezeichnet: Walter hatte sich nach vorne fallen lassen und den Ball dann mit der rechten Hacke über den eigenen Kopf ins rechte Eck geschossen. Der DDR-Sportreporter Wolfgang Hempel bezeichnete es als „Tor des Jahrhunderts“.

In seiner Zeit beim 1. FC Kaiserslautern erzielte Walter in 384 Spielen 327 Tore. Sensationell ist diese Quote vor allem deshalb, weil er kein Stürmer, sondern Mittelfeldspieler auf der Halbposition war. Er trug die Rückennummer 8. Am 20. Juni 1959 streifte er sich das letzte Mal das rote Trikot des FCK über und beendete seine Karriere im Alter von 38 Jahren.

Schnell rückte Walter auch ins Blickfeld von Reichstrainer Sepp Herberger, der ihn 1940 in die großdeutsche Nationalmannschaft berief. Am 14. Juli 1940 bestritt der 19-jährige Walter sein erstes Länderspiel und erzielte beim 9:3-Erfolg über Rumänien gleich drei Tore. Einige Wochen später folgte ein 13:0 gegen Finnland, wobei er sich mit zwei Toren beweisen konnte. Mehr als seine Torjägerqualitäten bewunderten die Fachleute jedoch sein spielerisches und taktisches Vermögen, mit dem er die Angriffe seiner Mannschaft lenkte. Durch ständige Positionswechsel – auch in die Abwehr – verkörperte er einen völlig neuen Typ Stürmer und wurde als kommender Superstar gefeiert. Doch der Zweite Weltkrieg unterbrach die internationale Karriere Walters; acht Jahre lang (von 1942 bis 1951) bestritt er kein Länderspiel für Deutschland.

Da der DFB nach Ende des Nationalsozialismus fünf Jahre lang keine Länderspiele bestreiten durfte, spielte Walter für die Auswahl "Pfalz". Dieser Mannschaft, in der neben ihm noch sieben weitere Kaiserslauterer Spieler standen, bescheinigte Bundestrainer Herberger „Länderspielformat“, und ab 1951 sollten diese Spieler dann das Gerüst der Nationalmannschaft bilden. Sepp Herberger bedachte Fritz Walter mit der Kapitänsbinde, die Walter erstmals am 15. April 1951 beim 3:2-Sieg über die Schweiz trug. Er wurde der verlängerte Arm des Bundestrainers auf dem Feld, zudem verband beide ein inniges Vater-Sohn-Verhältnis. Drei Jahre später führte Walter die Nationalmannschaft als Kapitän zur Weltmeisterschaft 1954. Mit Fritz Walter, seinem Bruder Ottmar, Werner Kohlmeyer, Horst Eckel und Werner Liebrich stellte der FCK den Kern des von Herberger trainierten und aufgestellten Kaders für die WM 1954 in der Schweiz. Das Vater-Sohn-Verhältnis zwischen Herberger und seinem Kapitän erwies sich als Glücksfall für den deutschen Fußball: Walter setzte als Kopf und Ideengeber der Elf die taktischen Anweisungen des Trainers perfekt auf dem Rasen um. Nach zwei souveränen Siegen in der Vorrunde gegen die Türkei (4:1 und 7:2) und der „taktischen“ Niederlage mit einer Reservemannschaft gegen den hohen Favoriten Ungarn (3:8), führte ein überragender Walter seine Mitspieler über das Viertelfinale gegen Jugoslawien (2:0) ins Halbfinale. Dort wurde das Nachbarland Österreich mit 6:1 deklassiert, wobei Walter mit zwei Toren vom Elfmeterpunkt und einer Weltklasseleistung seinen Status untermauerte. Im Finalspiel gegen Ungarn am 4. Juli 1954 lag die Mannschaft im Berner Wankdorfstadion nach acht Minuten mit 0:2 zurück, glich jedoch noch vor der Pause aus (das 2:2 hatte Walter mit einer perfekten Ecke vorbereitet). Das 3:2 durch Helmut Rahn sechs Minuten vor Spielende machte den Außenseiter zum Weltmeister und die Spieler zu Nationalhelden: „Wir sind wieder wer“, lautete neun Jahre nach Kriegsende der Tenor in Deutschland. Noch heute wird die Mannschaft auch als "Walter-Elf" bezeichnet. Fritz Walter hat sich durch dieses Turnier in die Riege der Ausnahmespieler wie Ferenc Puskás, Sándor Kocsis oder Juan Schiaffino eingereiht.

Nach dem WM-Titel kämpfte Fritz Walter mit Verletzungen. Er bestritt von 1956 bis 1958 nur vier Länderspiele und wollte seine Karriere in der Nationalelf eigentlich beenden. Doch Mentor Herberger überredete seinen Lieblingsspieler zu einer erneuten WM-Teilnahme 1958 in Schweden. Walters Comeback war umstritten, weil man dem 37-Jährigen nicht mehr zutraute, solch eine dominierende Rolle wie beim Titelgewinn spielen zu können. Doch Walter zählte wiederum zu den stärksten Spielern Deutschlands, auch wenn er nicht mehr Kapitän war, und führte die Mannschaft zum Gruppensieg und schließlich ins Halbfinale gegen Schweden. Dort unterlag Deutschland mit 1:3, Fritz Walter musste nach einem harten Foulspiel von Parling in der 75. Minute verletzt ausscheiden. Das Halbfinale am 24. Juni 1958 sollte sein letztes Länderspiel sein, denn im Spiel um den dritten Platz gegen Frankreich konnte er nicht mehr auflaufen. Nach der WM erklärte er seinen Rücktritt vom internationalen Fußball.

Damit gehört Fritz Walter zu den vier Spielern, die mehr als 15 Jahre in der Nationalmannschaft gespielt haben. (Übertroffen wurde er dabei nur von Lothar Matthäus.) Mit 33 Toren in 61 Länderspielen (davon 30 als Kapitän) war Walter bis zum 23. Juni 1966 Rekordtorschütze der Nationalmannschaft, bis er hierin von Uwe Seeler abgelöst wurde. Derzeit ist er der zehntbeste Torschütze der Nationalmannschaft.

Vor der WM 1962 in Chile – Walter war schon 42 Jahre alt, hatte seine Karriere ja 1959 schon beendet – versuchte Herberger noch einmal, seinen Kapitän zu überreden. „Fritz, Sie können mich doch nicht im Stich lassen“, flehte der Bundestrainer angeblich, doch Walter lehnte ab.

Fritz Walter war ein genialer Spielmacher, hochgradig sensibel, mit Charisma und Autorität ausgestattet sowie mit der Fähigkeit, ein Spiel „lesen“ zu können. Sein Aktionsradius reichte vom eigenen Strafraum bis vor des Gegners Tor. Er half in der eigenen Abwehr aus und war zudem torgefährlich, ein begnadeter Techniker und ein großer Stratege. Er wusste immer eine Antwort auf die taktischen Finessen des Gegners. Deshalb wollte auch Herberger seinen Zögling zu seinem Nachfolger machen. Walter sollte Bundestrainer werden. Doch den Schritt ins Trainergeschäft wagte er nie. Fritz Walter galt als sehr ehrlich und gestand: „Jahrelang war ich vor jedem Spiel so aufgeregt, dass mir schlecht wurde. Ich saß dann oft bis kurz vor Anpfiff auf dem Klo.“ „Bei ihm“, so hat Herberger einmal gesagt, „war ich mehr Psychologe als Trainer.“ Nach schlechten Spielen war Walter tagelang für niemanden zu sprechen.

Nach ihm ist das "Fritz-Walter-Wetter" benannt. Damit ist regnerisches Wetter gemeint, das er zum Spielen vorzog. Er hatte sich im Zweiten Weltkrieg mit Malaria angesteckt, deshalb fiel es ihm schwer, bei Hitze zu spielen. Außerdem spielte er bei schwerem, nassem Boden seine Technik aus (so auch während des Endspiels der WM 1954, bei dem es ausdauernd regnete). „Fritz, Ihr Wetter.“ – „Chef, ich hab’ nichts dagegen.“ (Fritz Walter vor dem Endspiel zu Herberger)

Der gelernte Bankkaufmann war Repräsentant bei adidas, kommentierte Fußball für Rundfunksender, vertrat die Sepp-Herberger-Stiftung, die sich unter anderem um Strafgefangene kümmert, und wurde so zum einzigen der 54er Weltmeister, der seinen Ruhm vermarkten konnte, und das, obwohl der DFB nur 2.350 Mark WM-Prämie zahlte. Äußeres Zeichen seines Wohlstandes war der Bungalow mit Schwimmbad auf einer 5.000-m²-Fläche in Alsenborn.
Für den Historiker Joachim Fest gab es drei Gründungsväter der Bundesrepublik Deutschland: politisch war es Konrad Adenauer, wirtschaftlich war es Ludwig Erhard und mental Fritz Walter. Eigentlich sei der 4. Juli 1954, der Tag des Endspiels in Bern, das Gründungsdatum der Bundesrepublik gewesen.

Seit Oktober 1948 war Fritz Walter mit Italia Bortoluzzi (* 6. Dezember 1921; † 14. Dezember 2001) verheiratet (Sepp Herberger war Trauzeuge). Nach dem Ende seiner Karriere als Fußballspieler war Walter zunächst Werbeträger und Berater beim SV Alsenborn, Inhaber des Fritz-Walter-Kinos ("Universum") und einer Wäscherei; er schrieb Sportbücher und engagierte sich für die Sepp-Herberger-Stiftung. Der Fußballspieler engagierte sich für die Augsburger Benefiz-Fußballelf Datschiburger Kickers, die Spenden für wohltätige Zwecke sammelt. Fritz Walter war bis zu seinem Tod über viele Jahre Schirmherr der Schlappekicker-Aktion der Frankfurter Rundschau, die unter anderem in Not geratene Sportler unterstützt.

In seinen letzten Lebensjahren ging Fritz Walter kaum noch in das nach ihm benannte Stadion auf dem Betzenberg in Kaiserslautern: Ein Fußballspiel anzusehen war für den nervösen und hochsensiblen Walter einfach zu aufregend. Bei Länderspielen der deutschen Nationalmannschaft saß angeblich seine Ehefrau Italia vor dem Fernseher und meldete Tore, Fouls und andere Ereignisse ins Schlafzimmer, in das sich Fritz Walter zurückgezogen hatte.

Fritz Walter starb 2002 in Alsenborn, weniger als ein Jahr nach dem Tod seiner langjährigen Ehefrau Italia. Beim Viertelfinalspiel der Fußball-Weltmeisterschaft 2002 gegen die Fußballnationalmannschaft der Vereinigten Staaten spielten die deutschen Spieler ihm zu Ehren mit Trauerflor. „Seine“ Fußball-WM in Kaiserslautern konnte er nicht mehr miterleben. Walter äußerte sich angeblich einmal derart, dass er mit dem Verlauf seines Lebens zufrieden wäre, wenn er die WM 2006 in Kaiserslautern noch erlebte. Walter wurde auf dem Kaiserslauterer Hauptfriedhof in einem Ehrengrab beigesetzt. Tausende Fußballfans erwiesen ihm die letzte Ehre.

Obwohl er die WM selbst nicht mehr erleben durfte, hatte er wohl maßgeblichen Anteil daran, dass Kaiserslautern – noch vor Bremen – zur WM-Stadt 2006 gekürt wurde. Er beteiligte sich aktiv (als offizieller WM-Botschafter) an der Kampagne "5 Weltmeister für Kaiserslautern" (mit Horst Eckel, Ottmar Walter, dem damaligen FCK-Trainer Andreas Brehme und dem damaligen Spieler Youri Djorkaeff). Andererseits wurde auch vielfach der „Fritz-Walter-Bonus“ beschworen.

Die Fritz-Walter-Stiftung trägt seinen Namen. Walter war der einzige Fußballweltmeister, dem schon zu Lebzeiten ein Denkmal gesetzt wurde: 1985 wurde das Stadion Betzenberg in "Fritz-Walter-Stadion" umbenannt.

Der Deutsche Fußball-Bund verleiht seit 2005 den Nachwuchsspielern des Jahres die Fritz-Walter-Medaille in Gold, Silber und Bronze. Mit dieser Auszeichnung sollen besondere Leistungen jeweils in den drei Altersklassen U-17, U-18, und U-19 geehrt werden. Mit der Namensgebung möchte der DFB an den 2002 verstorbenen Ehrenspielführer der deutschen Nationalmannschaft erinnern, der, wie Gerhard Mayer-Vorfelder anlässlich der Verleihung 2005 sagte, seit dem Gewinn der Weltmeisterschaft 1954 sowohl sportlich als auch menschlich ein Vorbild gewesen sei.

Die Band Sportfreunde Stiller ehrte Fritz Walter auf ihrer Fußball-CD "You have to win Zweikampf" anlässlich der WM 2006 mit ihrem Lied "Dem Fritz sein Wetter." Eine Punkband nannte sich in Erinnerung an die legendäre Weltmeisterelf von 1954 "Walter Elf".





Datenbanken

Über Fritz Walter


</doc>
<doc id="1696" url="https://de.wikipedia.org/wiki?curid=1696" title="FIFA">
FIFA

Die Fédération Internationale de Football Association (), kurz FIFA oder "Fifa", ist ein privater Verband, der „die Kontrolle des Association Football in all seinen Formen“ zum Zweck hat. Der Weltfußballverband ist ein gemeinnütziger Verein im Sinne der Artikel 60 ff. des Schweizerischen Zivilgesetzbuches mit Sitz in Zürich und im Handelsregister eingetragen. Die FIFA muss als nicht steuerbefreiter Verein im Kanton Zürich eine reduzierte Gewinnsteuer von 4 % entrichten.

Die FIFA erwirtschaftet in ihrer aktuellen Vierjahresertragsperiode 5,66 Milliarden Dollar, die zu 89 % aus der Vermarktung der von ihr organisierten Männer-Fußball-WM stammen. Darüber hinaus organisiert sie auch die Frauen-Fußball-WM und zahlreiche weitere Turniere. Ihr Präsident ist Gianni Infantino.

Die beiden letzten Wörter im ausgeschriebenen Namen der FIFA, „Football Association“, stehen als Eigenname für die englische Bezeichnung des Fußballsports, "Association Football". Diese Bezeichnung dient zur Unterscheidung von Sportarten, die ebenfalls die Bezeichnung "football" führen, so zum Beispiel "Rugby Football" oder "American Football". Der französische Name der FIFA übersetzt sich daher als „Internationaler Verband des Association Footballs“ oder schlicht als „Internationaler Zusammenschluss des Verbandsfußballs“.

Die FIFA wurde am 21. Mai 1904 in Paris von dem Niederländer Carl Anton Wilhelm Hirschmann und dem Franzosen Robert Guérin gegründet. Dem vorausgegangen war ein Treffen anlässlich des ersten Länderspiels Belgien gegen Frankreich am 1. Mai 1904 im Stadion "Ganzenvijver/Vivier d'Oie" in Uccle, bei dem der Vereinssekretär des damals in Belgien führenden Vereins "Racing Club de Bruxelles" Louis Muhlinghaus die Gründung mit den französischen Kollegen vereinbarte, und dann auch erster FIFA-Generalsekretär wurde. 

Gründungsmitglieder waren die nationalen Fußballverbände der Schweiz, Dänemarks, Frankreichs, der Niederlande, Belgiens und Schwedens, wobei die Gründungsmitglieder in einigen Fällen nicht den heute existierenden Verbänden entsprachen, sowie Spanien, allerdings nicht durch einen Verband, sondern vom "Madrid Football Club" vertreten. Der Deutsche Fußball-Bund trat der FIFA noch am Gründungstag telegrafisch bei. In den nächsten Jahren kamen weitere nationale Verbände hinzu. Der erste große internationale Fußballwettbewerb fand an den Olympischen Sommerspielen 1908 in London statt. Auch im Rahmen der Olympischen Sommerspiele 1912 wurde ein Fußballwettbewerb ausgetragen. Während des Ersten Weltkriegs geriet die Entwicklung ins Stocken; es konnten keine Spiele mehr ausgetragen werden und mehrere Verbände (z. B. England) traten aus der FIFA aus.

Nach dem Ersten Weltkrieg und dem Tod von Präsident Daniel Burley Woolfall war es der Niederländer Hirschmann, der durch seine ehrenamtliche Arbeit als Sekretär und als Interimspräsident der FIFA den Bestand sichern konnte. Der große Aufschwung begann mit der Wahl des neuen Präsidenten Jules Rimet, der ab 1924 – gemeinsam mit dem wohlhabenden Uruguayer und Sportmäzen Enrique Buero – ein Fußball-Weltturnier plante. 1930 wurde die erste WM veranstaltet. Als Rimet 1954 zurücktrat, fand bereits die fünfte Weltmeisterschaft statt und die FIFA zählte 85 Mitglieder. Die Mitgliederzahl wuchs in den Folgejahren von Jahr zu Jahr. Vor allem in Kriegszeiten stellten der Fußball und somit auch die FIFA eine wichtige Verbindung zwischen den Nationen dar.

Nach einer Statistik der FIFA von 1972 nahmen weltweit 16 Millionen Menschen, darunter 42.220 Berufsspieler am aktiven Fußballsport teil und organisierten sich in ca. 300.000 Vereinen. Die Zahl der Schiedsrichter wurde mit 243.596 angegeben.
Der nächste große Schritt war die Erweiterung des Teilnehmerfeldes bei Weltmeisterschaften von 16 auf 24 (zur WM 1982) und später auf 32 Teams (zur WM 1998).

Der FIFA gehören aktuell 211 Nationalverbände an. Diese müssen gleichzeitig Mitglied eines von sechs Kontinentalverbänden sein, jedoch sind einige Mitglieder der Kontinentalverbände derzeit nur assoziiert [AFC (1), CAF (1), OFC (3)] bzw. zwar Vollmitglied des Kontinentalverbandes aber noch kein FIFA-Mitglied [CAF (1), CONCACAF (6)].

Neben dem Weltverband FIFA existieren die folgenden sechs Kontinentalverbände:

Ausnahmen bilden beispielsweise Aruba, Curaçao, Guyana, Suriname und Trinidad und Tobago, die trotz ihrer geografischen Lage in Südamerika Mitglied der CONCACAF sind. Die asiatischen Staaten Armenien, Aserbaidschan, Georgien, Republik Zypern und Israel sind in der UEFA organisiert, ebenso die Türkei, Russland und Kasachstan, die Landesteile in Europa und Asien haben. Weitere UEFA-Mitglieder mit außereuropäischen Landesteilen sind Frankreich, Spanien, die Niederlande, Portugal und Dänemark. Indonesien als Mitglied der AFC hat Landesteile auf dem australischen Kontinent (Neuguinea), die USA als Mitglied der CONCACAF mit Hawaii in Ozeanien und Ägypten als Mitglied der CAF in Asien (Sinai-Halbinsel).

Australien wechselte 2006 vom Ozeanien-Verband OFC in den asiatischen (AFC), um in Qualifikationsspielen gleichwertige Gegner für seine Nationalmannschaft zu bekommen.

Bis heute (Stand: 12. Mai 2016) haben sich der FIFA 211 Nationalverbände angeschlossen, zuletzt die Verbände von Gibraltar, des Kosovo und des Südsudan, Montenegro, Osttimor und den Komoren. Allein zwischen 1975 und 2002 wurden 60 Verbände als Mitglieder aufgenommen.

Die Nationalverbände werden finanziell und logistisch über verschiedene Programme der FIFA unterstützt. Sie räumt ihnen eine Anzahl attraktiver Rechte und Privilegien ein. Allerdings ergeben sich aus der Mitgliedschaft auch Verpflichtungen: Als FIFA-Repräsentanten in ihrem Land müssen die Nationalverbände die Statuten, Ziele und Ideale der FIFA respektieren und den Sport dementsprechend bewerben und führen.

Als Alternative für National- und Regionalverbände, die nicht von der FIFA aufgenommen werden, wurde das NF-Board ins Leben gerufen.

Die FIFA organisiert u. a. folgende Wettbewerbe:

Im August 1993 wurde für Männerfußballnationalmannschaften und 2003 für Frauenfußballnationalmannschaften eine Weltrangliste eingeführt. Diese dienen teilweise dazu, die Mannschaften bei den Wettbewerbsauslosungen einzelnen Lostöpfen zuzuordnen.

Die FIFA veranstaltet im Rahmen der World XI in unregelmäßigen Abständen Benefizspiele mit der "Fußballweltauswahl", gegen die bereits öfter die "Europäische Fußballauswahl" angetreten ist, zuletzt 2005 und 2007.

Die beiden wichtigsten Gremien der FIFA sind der Kongress und der FIFA-Rat, dem der Präsident der FIFA vorsitzt. Der Präsident hatte bis ins Jahr 2016 weitreichende Machtbefugnisse und Management-Kompetenzen, wurde nach dem Rücktritt von Sepp Blatter und durch vom FIFA-Kongress beschlossene Reformen aber auf die Rolle eines Aufsichtsratsvorsitzenden beschränkt. Stattdessen wird das operative Geschäft seitdem maßgeblich durch den Generalsekretär bestimmt. Weitere Gremien der FIFA sind


Der Kongress ist das höchste Entscheidungsorgan des internationalen Fußballverbands. Bis 1998 kam er alle zwei Jahre zusammen, seit 1998 findet dieses Treffen jährlich statt. Dieser neue Zyklus erlaubt es dem Kongress, Entscheidungen über eine ständig wachsende Anzahl an Themen zu treffen.

Der Kongress trifft Entscheidungen bezüglich der Statuten und der Methoden, mit denen sie eingesetzt und angewendet werden. Der Kongress segnet auch den jährlichen Bericht ab, entscheidet über die Aufnahme neuer Nationalverbände und hält Wahlen ab, vor allem die der FIFA-Präsidentschaft. Jeder Nationalverband wird durch einen Delegierten vertreten und hat eine Stimme. Mitglieder des FIFA-Rats (vor 2016 FIFA-Exekutivkomitees) dürfen nicht als Delegierte am Kongress teilnehmen.

Der FIFA-Rat umfasst 37 Mitglieder und setzt sich aus
zusammen.

Den FIFA-Rat gibt es seit Februar 2016. Zuvor gab es das FIFA-Exekutivkomitee.

Es gibt 25 ständige Ausschüsse (Kommissionen) und mit den Disziplinar- und Berufungsausschüssen zwei operative Organe. Die Ausschüsse spielen eine wichtige Rolle, indem sie Entscheidungen bezüglich der Organisation von Turnieren und der Entwicklung des Fußballs im Allgemeinen treffen. Die von den Ausschüssen getroffenen Entscheidungen werden vom Exekutiv-Ausschuss ratifiziert.

Ausschüsse und juristische Institutionen (Stand: 3. Juni 2015):


Weitere Institutionen unterstützen die FIFA bei der Erfüllung ihrer Aufgaben (Stand Juni 2015):

Das Generalsekretariat, welches in Zürich rund 310 Mitarbeiter beschäftigt, ist für die Verwaltung der FIFA zuständig. An der Spitze steht der Generalsekretär, der dafür verantwortlich ist, dass die Entscheidungen des Exekutiv-Ausschusses umgesetzt werden. Weitere Aufgabenbereiche des Generalsekretariats sind die Belange der Finanzen, die Pflege internationaler Beziehungen, die Organisation des FIFA Weltpokals und die Organisation weiterer FIFA Fußball-Wettbewerbe. Das Generalsekretariat setzt sich aus verschiedenen Bereichen zusammen, die sich mit den Themen Business, Entwicklung, Finanzen, Fußball-Verwaltung, Kommunikation, Personal, Services und Wettbewerbe befassen.

Offizielle Sprachen der FIFA sind Deutsch, Englisch, Französisch und Spanisch. In diesen Sprachen werden sämtliche Satzungen, Vorschriften, Entscheidungen und Ähnliches erstellt. Englisch dient darüber hinaus als offizielle Sprache für Protokolle und Korrespondenz. Für den Kongress gelten zusätzlich die drei Sprachen Arabisch, Portugiesisch und Russisch als offiziell.

Die FIFA plant ihr Geschäft in Anlehnung an den Zyklus der Fußball-Weltmeisterschaft der Männer in Vierjahresperioden, die mit dem Kalenderjahr der Austragung der Endrunde enden. Derzeit befindet sich die FIFA in der „Geschäftsperiode 2015–2018“. Die FIFA selbst verbucht in ihrem Finanzbericht 2016 vertragliche Sicherung von derzeit 76 % des Vierjahresertragsbudgets von geplanten 5,66 Milliarden Dollar als einen Höhepunkt. Dieses Ertragsbudget basiert weitgehend auf der Vermarktung der Weltmeisterschaft der Männer und besteht zu

Von den Einnahmen aus Werbeverträgen und Fernsehausstrahlungslizenzen werden jährlich hohe Teilbeträge an die Mitgliedsverbände weitergereicht. Allein durch die weltweiten Fernsehrechte an den Herren-Weltmeisterschaften 2002 und 2006 nahm man 1,81 Milliarden Euro ein. Die FIFA forderte für die Ausrichtung der WM in Deutschland eine vollständige Steuerbefreiung, die ihr auch gewährt wurde.

Von 2003 bis 2006 erzielte die FIFA bei Erträgen von 3,328 Milliarden Franken einen Gewinn von 816 Millionen Franken. Allein 2006 wies sie einen Gewinn von 303 Millionen Franken aus und bezahlte dafür nur 1,06 Millionen Franken an Steuern, da sie als nicht gewinnorientierte Organisation gilt und wie ein Verein besteuert wird. Von 2011 bis 2014 nahm die FIFA 5,718 Milliarden Dollar ein, wovon 338 Millionen Dollar Gewinn verblieben. Sie verfügt im Jahr 2014 über ein Kapital von 1,523 Milliarden Dollar. Etwa 70 Prozent der Einnahmen fließen in verschiedener Form wieder an den Fußball zurück.

Nach der WM 2014 schieden die Fluggesellschaft Emirates und der Elektronikkonzern Sony aus dem Sponsorenkreis der FIFA aus. Zum Jahresende 2014 schieden Continental, Castrol sowie Johnson & Johnson aus.

Die FIFA ist in der Schweiz von der direkten Bundessteuer befreit, weil nach schweizerischem Recht juristische Personen, die öffentliche oder gemeinnützige Zwecke verfolgen, von der direkten Bundessteuer befreit werden können. Die FIFA bezahlt pro Jahr 3 Millionen Franken Steuern, weil sie als gemeinnütziger Verein gilt und somit von einer Sonderbesteuerung profitiert. Eine Gesetzesinitiative zu einer künftigen gesetzlich verpflichtenden Steuerpflicht scheiterte im Schweizerischen Parlament.

Vor jedem von der FIFA organisierten Spiel ertönt beim Einlaufen der Schiedsrichter und Mannschaften auf das Spielfeld die von Franz Lambert komponierte "FIFA-Hymne". Sie wird seit der Fußball-Weltmeisterschaft 1994 gespielt.

Das Motto des Verbandes lautet seit 2007 „For the Game. For the World.“ (dt. „Für das Spiel. Für die Welt.“).

Im Jahr 1932 zog der Internationale Weltfußballverband FIFA von Paris nach Zürich und hat seitdem dort seinen Hauptsitz. Im Mai 2004, zum 100-jährigen Bestehen der FIFA, wurde die Grundsteinlegung zum Um- und Neubau gefeiert. Der Grundstein birgt in seinem Inneren einen stählernen Fußball mit 1,3 Metern Durchmesser, der mit 204 Säckchen Erde aus jedem FIFA-Mitgliedsland gefüllt ist, weshalb die FIFA Wert auf die Feststellung legt, dass ihr Haus „auf dem Boden aller Mitgliedsländer“ steht. Ende Oktober 2005 wurde dann Richtfest gefeiert. Vor dem eigentlichen Baubeginn wurde das alte Gebäude zuerst abgerissen.

Am 29. Mai 2007 wurde in Zürich-Hottingen der neue Hauptsitz der FIFA eingeweiht. Der neue FIFA-Hauptsitz – „Home of FIFA“ (Haus oder auch „Heimat“ der FIFA) genannt – umfasst 270 Büroarbeitsplätze, einen Hörsaal für 200 Personen, 240 Tiefgaragenstellplätze, Lager- und Archivräume. Im Außenbereich ist ein komplettes Fußballfeld nach internationalem Standard mit unterirdischen Umkleide- und Besprechungsräumen angelegt. Das Gebäude besteht aus neun Etagen (Erdgeschoss eingeschlossen), wovon sechs Etagen sich aus städtebaulichen Gründen unterhalb der Erdoberfläche befinden und fast 20 m tief reichen. Durch den Einsatz energieeffizienter Gebäudetechnik konnte auf Energie aus fossilen Brennstoffen verzichtet werden, wodurch auch keine CO- Emissionen von dem Gebäude ausgehen.

Der Bau kostete 240 Millionen Franken (ca. 180 Millionen Euro) und wurde von der Architektin Tilla Theus entworfen und von der Schweizer Totalunternehmerin HRS Real Estate AG realisiert.

Gegenüber der FIFA wird Kritik geäußert, dass diese ihre Monopolstellung ausnutze; wie in den meisten anderen Sportarten, gibt es im Fußball einen Weltverband.

Die Kommerzialisierung des Fußballs durch die FIFA und ihre Sponsoren sorgt für Kritik, da der Verband die von ihm eingeforderten Vermarktungsprivilegien u. a. mit hartem gerichtlichen Vorgehen in Einzelfällen durchzusetzen bestrebt ist.

Das rigorose Vorgehen der FIFA wird insbesondere dann deutlich, wenn Grundregeln des Verbandes durch Vereine oder Landesverbände in Frage gestellt werden. So drohte die FIFA bei einer Auseinandersetzung mit dem Grazer AK mit dem Ausschluss Österreichs von der EM 2008 im eigenen Land. Im Juli 2006 wurde der griechische Verband kurzzeitig aus der FIFA ausgeschlossen.

Die Nationalmannschaft von Kamerun erschien zum African Cup of Nations 2004 in einem neu entworfenen, körperbetonenden Einteiler (UniQT), den der ausrichtende afrikanische Verband auch genehmigte. Die FIFA sah dies jedoch als Verstoß gegen die eigenen Regeln an, wonach die Sportkleidung aus einem Trikot und einer Hose bestehen muss.
Gegen das Team von Kamerun wurde eine Strafe von 200.000 Franken verhängt, und für die Qualifikation zur WM 2006 zog man ihm sechs Punkte ab. Der Punktabzug wurde jedoch nach erfolgreicher Klage seitens Ausrüster Puma von der FIFA wieder zurückgenommen.

Wegen dieses Vorgehens haben Zeitungen und Experten folgende Kritiken geäußert:

Im Juni 2007 kam es zu einer außergerichtlichen Einigung zwischen der FIFA und ihrem ehemaligen Sponsor Mastercard, wonach die FIFA 90 Millionen US-Dollar an das Kreditkartenunternehmen zahlte. Hintergrund war neben einem Streit um die Verwendung des FIFA-Logos auch die Feststellung durch ein US-Gericht, dass die FIFA entgegen ihren vertraglichen Verpflichtungen Mastercard bei den Neuverhandlungen über die Sponsorenvergabe im Kreditkartenbereich im Jahr zuvor zugunsten von VISA übergangen habe. Damit hat die FIFA die Hälfte der Einnahmen aus dem Neuvertrag mit VISA für die Auseinandersetzung mit Mastercard verwendet. Der damalige Verhandlungsführer der FIFA, Jérôme Valcke wurde daraufhin zunächst entlassen, bevor er am 27. Juni 2007 Generalsekretär der FIFA wurde.

Gegen Ende der WM 2010 in Südafrika wurde von Medienseite bemängelt, dass die FIFA weiterhin zu ihrer Rolle während des Apartheidregimes schweige.
Kritik erntete die FIFA außerdem wegen der Vergabe der Weltmeisterschaften 2018 an Russland sowie 2022 an das Wüstenemirat Katar. Der Zürcher Tagesanzeiger meinte dazu, dass Russland die Wahl der Macht und Katar die Wahl des Geldes gewesen sei.

Weiter wird die FIFA kritisiert, ihre in den letzten Jahren stark angestiegenen Einnahmen für prestigeträchtige Neubauten und überhöhte Betriebskosten (insbesondere in Form von Personalkosten) verwendet zu haben. Der Umsatz der FIFA stieg zwischen 1990 und 2009 von 10 auf 778 Millionen Euro. Von ihrem Reingewinn zahlt die FIFA nach Schweizer und Zürcher Recht 4,25 Prozent Steuern.

Mit dem Negativpreis "Verschlossene Auster" hat die "Journalistenvereinigung Netzwerk Recherche" den Weltfußballverband 2012 ausgezeichnet. Die FIFA habe bisher «alle Versuche kritischer Journalisten, über Korruption und Ungereimtheiten bei der Postenvergabe zu recherchieren, abgeblockt», erklärte der Vorsitzende des Netzwerks Recherche, Oliver Schröm. Die Laudatio hielt der Sportmanager Roland Büchel, ehemaliger FIFA-Mitarbeiter und Mitglied des Schweizer Nationalrates. Das System von Löhnen, Aufwandsentschädigungen und Boni bei der FIFA sei „völlig intransparent“, sagte Büchel und wies darauf hin, dass die FIFA im vergangenen Jahr 96,8 Millionen Dollar an Löhnen, Zahlungen an Ehrenamtliche und Boni ausgeschüttet habe. Jedoch seien kritische Medienanfragen zu dem Thema nicht beantwortet worden. Der Europarat sei Ende April in 124 Punkten zu einem „vernichtenden Urteil“ über die Fußballweltorganisation gekommen und habe daran erinnert, dass Autonomie für die Interessen des Sports da sei und „nicht für die Interessen von skrupellosen Individuen“. Die FIFA schickte keinen Vertreter zur Preisverleihung.

Im Mai 2006 beschrieb der britische Enthüllungsjournalist Andrew Jennings in seinem Buch "Foul!" ein angeblich umfangreiches System der Korruption unter der Ägide von João Havelange und Sepp Blatter, das im Zuge des Zusammenbruchs des FIFA-Marketing-Partners ISL ans Licht kam. Kurz nach Veröffentlichung des Buches sendete die BBC am 11. Juni 2006 einen vierstündigen kritischen Beitrag, in dem der angebliche Schmiergeldskandal im Detail beleuchtet wurde. In Summe soll ISL rund 100 Millionen US-Dollar Schmiergeld gezahlt haben um Entscheidungen der FIFA zu beeinflussen. Der BBC liegt eine Liste von 175 geheimen Zahlungen vor. Der zufolge sollen auch drei Mitglieder des FIFA-Exekutivkomitees, das über die Auswahl des Ausrichters von Weltmeisterschaften entscheidet, Zahlungen erhalten haben. So sollen demnach Nicolás Leoz, Präsident der südamerikanischen Fußball-Konföderation CONMEBOL, 1998 und 1999 600.000 US-Dollar, Issa Hayatou, Präsident der Confédération Africaine de Football, 1995 20.000 US-Dollar und Ricardo Teixeira, Präsident des brasilianischen Fußball-Nationalverbands Confederação Brasileira de Futebol, 9,5 Millionen US-Dollar erhalten haben.

Im Juni 2010 verfügte die Staatsanwaltschaft in Zug die Einstellung des auf Zeugenaussagen der ISMM/ISL-Gruppe beruhenden Verfahrens gegen eine bis auf zwei Funktionäre nicht namentlich genannte Führungsgruppe der FIFA gegen einen Betrag von 5,5 Millionen Schweizer Franken. Davon musste die FIFA 2,5 Millionen Schweizer Franken selbst bezahlen. Die FIFA wehrte sich gegen die Veröffentlichung eines 41-seitigen Papiers der Staatsanwaltschaft, welches das Korruptionssystem rund um die FIFA, den ehemaligen FIFA-Präsidenten João Havelange und seinen früheren Schwiegersohn Ricardo Teixeira beschreibt, die laut Dokument Schmiergelder in Millionenhöhe kassiert haben sollen. In dem Dokument ersichtlich sind die internationalen Geldflüsse und der Umgang der FIFA-Spitze mit dem Schmiergeldsystem. In der Einstellungsverfügung wird Bezug auf den damaligen FIFA-Präsident Sepp Blatter genommen (ohne ihn namentlich zu nennen), der zumindest von den Schmiergeldzahlungen gewusst haben müsste. In einem Urteil vom 3. Juli 2012 vom Schweizer Bundesgericht wird festgestellt, dass großes „öffentliches und weltweites Interesse“ an den Inhalten des Dokuments besteht. Den Medien wird hier eine Kontrollfunktion zugestanden.

Vor dem in Zürich tagenden 66. FIFA-Kongress fanden am 27. Mai 2015 unabhängig voneinander Festnahmen einiger FIFA-Funktionäre und eine Durchsuchung aufgrund einer Strafanzeige im FIFA-Hauptquartier statt.

Am Morgen des 27. Mai 2015 wurden sechs Fußballfunktionäre durch die Kantonspolizei Zürich im Auftrag des Bundesamts für Justiz aufgrund eines US-Verhaftungsersuchens im Hotel Baur au Lac festgenommen. Das Gesuch ist gemäß der Sprecherin des Bundesamts auf den 21. Mai 2015 datiert. Ausgestellt wurde es durch das Office for International Affairs des Justizministeriums der Vereinigten Staaten. Den Funktionären wird Korruption vorgeworfen. In Auslieferungshaft gesetzt wurden gemäß dem US-Justizministerium dabei die Funktionäre Jeffrey Webb, Eduardo Li Sánchez, Julio Rocha, Costas Takkas, Eugenio Figueredo, Rafael Esquivel sowie José Maria Marin. Am Abend des 27. Mai 2015 haben die Behörden von Trinidad und Tobago einen Haftbefehl für den früheren FIFA-Vizepräsidenten Jack Austin Warner erhalten.

Unabhängig davon hat die FIFA am 18. November 2014 eine Strafanzeige gegen Unbekannt gestellt, worauf in Folge ein Strafverfahren eingeleitet worden ist. Daraufhin wurde im Auftrag der Bundesanwaltschaft ebenfalls am Morgen des 27. Mai 2015 das FIFA-Hauptquartier durchsucht. Hierbei geht es um die Vergaben der WM an Russland und Katar.

Vier Tage nach seiner Wiederwahl durch den FIFA-Kongress kündigte Sepp Blatter am 2. Juni 2015 auf einer kurzfristig einberufenen Pressekonferenz seinen Rücktritt an.

Am 8. Oktober 2015 gab die Ethikkommission der FIFA bekannt, sowohl FIFA-Präsident Sepp Blatter als auch seinen Vertreter Michel Platini für 90 Tage zu sperren. Präsidentschaftskandidat Chung Mong Joon wurde für sechs Jahre gesperrt und erhielt eine Geldstrafe von 100.000 Schweizer Franken. Am 21. Dezember 2015 wurde Sepp Blatter vom FIFA-Ethik-Komitee für acht Jahre von allen Ämtern ausgeschlossen; eine Strafe, die in der Berufung auf sechs Jahre reduziert wurde.

Am 26. Februar 2016 wurde UEFA-Generalsekretär Gianni Infantino auf einem außerordentlichen Verbandskongress in Zürich zum Nachfolger Blatters gewählt. Er setzte sich im zweiten Wahlgang gegen den zuvor als Favorit geltenden ACF-Präsidenten Salman bin Ibrahim Al Chalifa durch.

Bei der FIFA-Vollversammlung im Mai 2016 in Mexiko-Stadt wurde auf Infantinos Vorschlag beschlossen, dass der Council bis zum kommenden Jahr alle Mitglieder der Audit- und Compliance-Kommission, der Ethikkommission, der Disziplinarkommission und der neuen Governance-Kommission selbst bestimmen und entlassen kann. Daraufhin trat Domenico Scala als Leiter des "Audit & Compliance Committees" der FIFA noch am gleichen Tag von seinem Amt zurück und begründete diesen Schritt wie folgt: "Ich bin über diesen Entscheid konsterniert, da damit eine zentrale Säule der Good Governance der Fifa untergraben und eine wesentliche Errungenschaft der Reformen zunichte gemacht wird."

Am 2. Juni 2016 wurde die Zentrale der FIFA in Zürich erneut von Vertretern der Ermittlungsbehörden durchsucht. Am 3. Juni teilten zwei Vertreter der von der FIFA seit Juni 2015 zur Vertretung ihrer Interessen beauftragten Anwaltskanzlei Quinn Emanuel mit, dass Blatter, Valcke sowie der ehemalige Finanzchef und Interims-Generalsekretär Kattner in den vergangenen fünf Jahren mindestens 79 Millionen Schweizer Franken auf fragwürdiger Grundlage erhalten hatten.

Medien berichteten im Februar 2017 über Bestrebungen von Präsident Infantino, beim FIFA-Kongress im Mai in Bahrain die beiden Chefs der Ethikkommission auszuwechseln und sich von der US-Anwaltskanzlei Quinn Emmanuel zu trennen. Quinn Emmanuel untersucht im Auftrag der amerikanischen Justiz interne Vorgänge bei der Fifa. Strafrechtsexperten haben gewarnt, dass die FIFA durch dieses Vorgehen in den USA aufgrund des Racketeer Influenced and Corrupt Organizations Act unter Mafia-Verdacht gestellt und zu hohen Strafzahlungen verurteilt werden könnte. Parallel hat der Europarat eine eigene Untersuchung der FIFA angekündigt. DFB-Präsident Reinhard Grindel warnte Infantino vor einer Absetzung der FIFA-Ethikkommissare.

Der stellvertretende Generalsekretär, der Kroate Zvonimir Boban, gilt als engste Bezugsperson von Präsident Gianni Infantino.






</doc>
<doc id="1697" url="https://de.wikipedia.org/wiki?curid=1697" title="Föhn">
Föhn

Der Föhn oder Föhnwind ist ein warmer, trockener Fallwind, der häufig auf der der Windrichtung abgewendeten Leeseite von größeren Gebirgen auftritt. Er entsteht meist großräumig als Wetterlage und kann stetig wehen, aber auch böig sein.

Die Bezeichnung "Föhn" stammt aus dem deutschsprachigen Alpenraum und hat sich als meteorologischer Begriff für entsprechende Windereignisse durchgesetzt. Sowohl für den "Alpenföhn" als auch entsprechende Wetterphänomen an anderen Orten der Welt gibt es zahlreiche regional unterschiedliche Namen.

Zu unterscheiden ist der echte Föhn von der ähnlich warm-trockenen „föhnigen“ Höhenströmung und anderen, etwa durch Druckgradienten bei Sturmtiefs induzierten föhnähnlichen Fallwinden.

Der Föhn entsteht aus einer Windströmung (oder einem horizontalen Druckgradienten) über dem Gebirge und ist auf dessen dem Wind zugewandten Luvseite mit Steigungsregen verbunden, die zu relativ warmer Höhenluft führen. Charakteristisch ist die deutliche Erwärmung und Trocknung der herabströmenden Luft, die zu gesundheitlichen Beschwerden (Föhnkrankheit) führen kann, sowie die ausgeprägte Fernsicht aufgrund der aerosolarmen (schwebeteilarmen) Luftmassen. 

Neben diesem warmen Föhn durch feuchtadiabatisch aufsteigende Luft vor dem Gebirge und trockenadiabatisch absteigende Luft nach dem Gebirge gibt es aber noch andere Ursachen. Weniger warme Föhnwinde treten als physikalisches Wetterphänomen zumindest in den Ostalpen je nach Schichtung der Luftmassen auch ohne das Ausregnen auf, welches die zusätzliche Wärme generiert.

Föhn und Bora sind die typbestimmenden warmen bzw. kalten Fallwinde, die so oder ähnlich auch weltweit beobachtet werden können. Durch divergente bioklimatische Wirkung und gegensätzliche landschaftsprägende Folgen ist eine Separierung von föhn- und boragenen Typen zwangsläufig sinnvoll. Phänomenologisch lassen sie sich einfach unterscheiden:
Die Definition der Weltorganisation für Meteorologie (WMO) lautet:
Die Bezeichnung Föhn ging vom lateinischen "favonius" „lauer Westwind“, wohl über das Rätoromanische ("favuogn," dialektal auch "fuogn"), in das Althochdeutsche "(phōnno)" ein.

Daneben sind Bezeichnungen für regionale Föhnlagen entstanden:

Weitere Beispiele sind:

Dagegen keine warmen Föhnwinde, sondern katabatische Fallwinde sind z. B.

Die in Lehrbüchern – auch heute noch – am weitesten verbreitete Erklärung des Föhns ist mit der Darstellung von Ficker & De Rudder aus dem Jahr 1943 verbunden, wird gern "thermodynamisch" genannt und irrtümlich Julius Hann zugeschrieben. Diese Theorie ist nach heutigem Verständnis nur noch von historischer Bedeutung, obwohl sie wichtige Erscheinungen richtig erklärt. Ihre Charakteristika sind ein Niederschlag im Luv, der als alleinige Erklärung der relativ hohen Temperaturen auf der Lee- im Vergleich zur Luvseite herangezogen wird, sowie eine dem Hangprofil folgende Störung auf beiden Seiten. Dies trifft jedoch in vielen Fällen nicht zu.

Ein Föhn entsteht nach der thermodynamischen Föhntheorie wie alle Winde durch die Wirkung einer Druckgradientkraft mit tieferem Druck auf der Lee-Seite eines Gebirges. Beim Aufsteigen der relativ feuchten Luft an der Luv-Seite des Gebirges kühlt sich diese zunächst so lange trockenadiabatisch mit 1,0 °C pro 100 m Höhenanstieg ab, bis die relative Luftfeuchte 100 % beträgt. Dies liegt daran, dass die Wasserdampfkapazität der Luft mit der sinkenden Temperatur sinkt, sodass sie beim Erreichen des Taupunktes mit Dampf gesättigt ist und Wassertröpfchen bildet. Steigt die Luft weiter, so kühlt sie sich nur noch feuchtadiabatisch mit etwa 0,6 °C/100 m ab. Dabei bleibt die relative Luftfeuchte mit 100 % konstant: Die Luft kann ihren (unsichtbar) enthaltenen Wasserdampf nicht mehr behalten, und es kommt zu laufender Kondensation und Wolkenbildung. Diese dauert an, bis die Luft am Bergkamm angekommen ist, und führt fast immer zum sogenannten Steigungsregen, der in großen Höhen auch in Schneefall übergehen kann.

Vom Kamm aus beginnt die abgekühlte Luft auf der anderen Seite des Berges hangabwärts zu sinken. Der Föhn entsteht also – trotz einer stabilen Atmosphärenschichtung – nach der thermodynamischen Föhntheorie zuerst als katabatischer Wind. Die Ursachen für das Absinken liegen sowohl in der niedrigen Temperatur als auch in der Hangneigung des Geländes und werden verstärkt, wenn der Wind auf der Leeseite des Gebirges durch ein Tiefdruckgebiet „angesaugt“ wird. Die absinkende Luft erwärmt sich wieder trockenadiabatisch mit durchgehend 1 °C/100 m – also viel schneller, als sie während des „Aufstiegs“ (in der feuchtadiabatischen Phase) abkühlte: Es fehlt ihr die beim Aufsteigen abgeregnete Wassermenge, die gleichzeitig ihre Kondensationswärme an diese Luft abgab. Die abgeregnete Wassermenge in Verbindung mit dem raschen Wärmerwerden der Luft auf der Leeseite ist die Ursache für die relative Trockenheit und hohe Temperatur des Föhnwindes. Im Tiefland angekommen ist der Föhn deshalb kein katabatischer Wind mehr, sondern ein warmer Fallwind.

Die thermodynamische Theorie als Erklärung des Föhns basiert auf dem unterschiedlichen Temperaturverhalten der Luft bei vertikalen Bewegungen und ist wegen der didaktischen Klarheit insbesondere in Lehrbüchern weit verbreitet: In vielen Lehrbüchern wurde der Kondensationseffekt als „der thermodynamische Föhneffekt“ hervorgekehrt, als ob sonst keine Gründe für die Temperaturerhöhung bei Föhn vorlägen. Dieser Effekt ist lange Zeit zu sehr betont worden, wohl auch wegen seiner didaktischen Vorzüge. Zwei Beobachtungen zeigen, dass er nicht essentiell zum Föhn gehört:

Dass eine absteigende Warmluft dem archimedischen Prinzip zuwiderläuft, ist aber problematisch, dynamische Kriterien fehlen dieser Theorie und weder die Beobachtungen des "hydraulic jump" noch die "mountain waves" oder die Rotoren – auf welche im Folgenden eingegangen wird – können mit der Theorie erklärt werden.

Obwohl die Atmosphäre aus Gasen aufgebaut ist, verhält sie sich in vielen Fällen wie eine Flüssigkeit. Daher treten viele atmosphärische Turbulenzen als Wellen auf. Atmosphärische Wellenstörungen resultieren aus der Interaktion verschiedener Kräfte, darunter Druckgradientkraft, Corioliskraft, Gravitation und Reibung. Lange war die obige "thermodynamische Annahme" bestimmende Theorie eines Föhnprinzips. Heute stehen allgemeine "strömungsdynamische Gesetze" bei Prinzipien der Entstehung von Fallwinden im Vordergrund, die zum "mountain-wave"-Konzept führen.

Am geeignetsten, um Fallwinde in einem dreidimensionalen System zu erklären, sind hydrologische Modelle, da sie auch für Bewegungsmuster in einem stark reliefierten Gelände mit Tälern und Pässen geeignet sind. Heute wird den topografischen Gegebenheiten noch mit der auf Englisch "gap flow dynamic" genannten Hypothese Rechnung getragen. Hiernach ist die vertikale Einengung (am Pass) und eine laterale Kontraktion (in einer Lücke – "gap") der Luftströmung für Fallwinde wie Föhn und Bora unabdingbar.

Hydraulische Begriffe wie "fließendes Wasser", "schießendes Wasser", mit "kritischer Geschwindigkeit" strömendes Wasser und die Froude-Zahl formula_1 (ähnlich der Mach-Zahl) werden heute in der Föhntheorie benutzt.
Analog der Einteilung der Gasdynamik in Strömungen mit "Unter-" und "Überschallgeschwindigkeit" ist die Hydraulik der Strömungen mit freier Oberfläche in Wasserströmung mit Unter- und solche mit Übergrundwellengeschwindigkeit eingeteilt. Wasser, das mit einer Geschwindigkeit strömt, die kleiner ist als die Grundwellengeschwindigkeit, heißt in der Hydraulik fließendes Wasser, Wasser mit einer Strömungsgeschwindigkeit größer als die Grundwellengeschwindigkeit heißt schießendes Wasser. Strömt Wasser genau mit Grundwellengeschwindigkeit, so nennt man es „mit kritischer Geschwindigkeit strömendes Wasser“. Die Froudsche Zahl formula_1 drückt letztlich das Verhältnis zwischen kinetischer Energie (abhängig von der Windgeschwindigkeit) und potenzieller Energie (Stabilität, Gebirgshöhe) aus.


Das Problem bei der Erklärung ist, das verschiedenartige Verhalten bei Modellversuchen von fließendem und schießendem Wasser beim Überströmen eines Bodenhindernisses analog beim Föhn anzuwenden. Wenn Wasser über ein Hindernis strömt, so wirken im Wesentlichen zwei Kräfte: die Schwerkraft und die Trägheitskraft. Man kann nun zwischen zwei Regimen unterscheiden:


Wenn über dem Hindernis eine genügend starke Beschleunigung erreicht wird und eine genügend große Abnahme der Dicke der Wasserschicht erfolgt (bei großen Hindernissen möglich), kann ein Übergang von subkritischem zu superkritischem Fließen geschehen. Da nun das Wasser am Lee-Hang superkritisch ist, beschleunigt es sich und stürzt den Hang hinunter. Weil auf der ganzen Strecke über dem Hindernis potenzielle Energie in kinetische verwandelt wird, werden starke Fallwinde im Lee produziert. Die Flüssigkeit passt sich auf der Leeseite durch einen hydraulischen Sprung (engl. "hydraulic jump") wieder der Umgebung an und wechselt dadurch wieder zu subkritischem Fließen. Hier besteht eine Analogie zur Gasdynamik: Wie dort der Übergang einer Strömung mit Unterschallgeschwindigkeit zu einer mit Überschallgeschwindigkeit stetig erfolgt, der umgekehrte dagegen meist unstetig auf dem Wege über eine riemannsche Stoßwelle, geht eine fließende Wasserströmung stetig in eine schießende über, eine schießende in eine fließende dagegen meist unstetig auf dem Wege über einen Wassersprung. Damit ist die durch Turbulenzen beim Wassersprung erzeugte Wärme für den hydraulischen Prozess verloren, beim gasdynamischen Prozess bleibt diese aber als innere Energie erhalten, der Luftsprung entspricht damit nicht gänzlich dem Wassersprung. Dass beim Föhn eine Luftströmung mit überkritischer Geschwindigkeit existiert (schießend strömende Luft), wird durch die außergewöhnliche Turbulenz der Rotoren beim Emporschießen bodennaher Luft im Lee unterstrichen.

Zu einem wesentlichen Element der Föhn-Hypothese gehört die "gap dynamic". Der Grundgedanke besteht darin, dass eine orthogonale Strömung, die gegen eine Gebirgsbarriere fließt, zuerst ein zweidimensionales Problem darstellt, dass aber, wenn so genannte "gaps" (Täler, Pässe) vorhanden sind, die Dimensionalität des Problems verändert wird. Dies gilt insbesondere dann, wenn die Froude-Zahl der Luft an einer Gebirgsbarriere niedriger ist und diese einen Weg durch Schluchten, Täler und Pässe anstelle einer Passage über das Hindernis nimmt. Dadurch, dass viele Gebirge bestimmte Windgassen aufweisen, wird diese Idee bestärkt. Beispiele sind die „Stampede Gap“ in der Kaskadenkette in Washington ("Cascade Windstorm"), die Trockentäler des Himalaya, das Wipptal am Brenner zwischen Inn und Etsch (Föhn), der Vratnik-Pass über Senj im Velebit (Bora) oder der Einschnitt der Bucht von Kotor in Montenegro als Korridor der Risaner Bora.

Folgendes Bild für den Mechanismus des Föhns ergibt sich heute: Im Ausgangszustand lagert über einem Gebirgsrelief und seiner weiteren Umgebung eine ausgedehnte, nahezu horizontale Temperaturinversion, in den Gebirgstälern und vielleicht auch im Vorland eine stagnierende kalte Luftschicht. Ein heranziehendes Tief beginnt die Kaltluft durch den Kanal zwischen Erdoberfläche und der über dem Gebirge gelegenen Inversionsgrenzschicht abzusaugen. Die Strömungsgeschwindigkeit in diesem Kanal nimmt ständig zu. Bei genügend starker Absaugwirkung des Tiefs wird irgendwann längs einer zunächst schmalen Teilstrecke des Gebirgszuges die Strömung kritisch, und zwar vorzugsweise auf einem Pass, weil dort wegen der Düsenwirkung die Strömungsgeschwindigkeit besonders gesteigert wird. Längs dieser Strecke ist damit die maximale Förderleistung des Kanals erreicht. Die Inversion wird im Lee dieser Teilstrecke herabgezogen und schreitet in Richtung der Grundströmung weiter fort, während darunter die Strömung überkritisch wird. Der Föhn hat am Pass begonnen und setzt sich in das Tal hinein fort, wobei er auch die Kaltluft am Boden des Kanals mit einbezieht. Während dieses Vorgangs kann die Luft zu beiden Seiten der Gebirgsteilstrecke noch ungehindert nachströmen, da dort die kritische Geschwindigkeit noch nicht erreicht ist. Das ansaugende Tief fordert aber weiteren Luftnachschub, so dass auch seitlich der Strecke die Strömungsgeschwindigkeiten weiterhin zunehmen müssen, bis nach und nach längs des ganzen Gebirgsrückens überall die kritischen Werte überschritten sind. Am gesamten Gebirgszug hat damit der Föhn eingesetzt.

Verschiedene Missdeutungen bei der Temperaturerhöhung gerade des Südföhns verlangen eine genaue Analyse. Grundsätzlich hängt die adiabatische Erwärmung der Luft davon ab, dass die Atmosphäre zwischen der Talstation und dem Gebirgsgrat stabil stratifiziert ist. Vor allem an Sommertagen mit einer tiefen und gut durchmischten Grenzschicht und superadiabatischen Gradienten in der Nähe des Bodens ist der Föhn kühler als die Luft, die er verdrängt. Daher wird die grundsätzliche Erwärmung und Trocknung der Föhnluft aufgrund des Abstiegs auf der Lee-Seite eines Gebirges mit der Tatsache verwechselt, dass Föhnluft wärmer und trockener als die Luftmasse ist, die dieser auswechselt. Dies belegen Statistiken, die bei Südföhn in Innsbruck einen deutlichen erhöhten Trend der Temperaturmaxima in den Sommermonaten belegen. Für die Alpensüdseite ist der Effekt von Nordföhn aber durch die Kaltluftadvektion überschattet. Dagegen ist die Südströmung bei Südföhnlagen für den Bereich der Ostalpen im Raum von Tirol mit der Wirkung des Föhns als Südwind immer durch eine entsprechende Erhöhung der Temperaturmaxima charakterisiert.

Typisch für die Föhnlage ist eine markante Wolkenwand – die "Föhnmauer" – vor fast blauem Himmel, dem "Föhnfenster". Die Föhnmauer steht als Wolkenwand über dem Kamm, an dem der Fallwind dann herunterströmt. Das Föhnfenster ist die durch Trocknung ausgeblasene Schönwetterzone.

Bei hohen Windgeschwindigkeiten des Föhnwindes spricht man vom "Föhnsturm". Dabei kann die Föhnmauer auf die Leeseite hereinbrechen und dort zu Niederschlägen führen. 

Am Ende der Föhnwirkung steht eine zweite Föhnmauer an der Kaltfront des auslösenden Tiefdruckgebietes. Ihr Vorrücken wird durch den Gegenwind des Föhns aufgehalten. Bricht der Föhn zusammen, rückt diese zweite Föhnmauer rasch vor und bringt das Föhnfenster zum Verschwinden.

Dass implizierte Stauniederschläge kein Muss bei Föhn sind, geht aus der Statistik von Fliri (1984) eindeutig hervor. Bei Südföhn ist nur ca. 70 % Niederschlagswahrscheinlichkeit am östlichen Alpensüdrand, 80 % im westlichen Teil mit Maxima von 90 % im Tessin, wo die Niederschlagsintensitäten auch größer sind. Dass der Fall aber nicht ganz einfach ist und ein thermodynamischer Effekt mit Aufsteigen von Bodenluft aus dem Po-Becken unter Umständen eine Rolle spielt, wenn auch lokal beschränkt, konnte in einem partiellen Widerspruch zu bisherigen Ergebnissen gezeigt werden. Für Teile der Westalpen kann daher die feuchtadiabatische Komponente eine Rolle spielen. Während des ALPEX-Programms wurde die Existenz eines Kaltluft-Pools an der Alpensüdseite bestätigt. Damit setzte sich die nicht ganz neue Theorie von Hann (1866) gegenüber der von Ficker und De Rudder (1943) durch. Hier ist die Luft der unteren Schichten im Pool gefangen und tritt nicht über den Alpenhauptkamm. Diese Luft wird daher auch Totluft genannt.

Auf der Leeseite des Gebirges gerät die strömende Luft in Schwingungen. Diese Leewellen werden bei ausreichender Luftfeuchtigkeit durch die Bildung von charakteristischen Wolken, den "Föhnlinsen" ("Altocumulus lenticularis", kurz "Ac lent"), sichtbar. In den Leewellen können Segelflugzeuge auf über 10.000 m steigen.

So gleichen die atmosphärischen Wellenstörungen, die durch orografische Hindernisse gebildet werden, den Schwerewellen der Wasseroberfläche. Während sich nun eine Meereswelle weiterbewegt und das Wasser still steht, ist es mit "mountain waves" genau umgekehrt: Während die Welle im Wesentlichen stationär bleibt, bewegt sich die Luft durch sie hindurch. "Mountain waves" können überall dort auftreten, wo eine starke Strömung in einer stabilen Atmosphäre auf eine Barriere trifft.

Praktisch genutzt werden die Wellen im Segelflug. Im Aufwindbereich können große Höhen ohne Motorkraft erreicht werden. Die damit einhergehende Turbulenz stellt jedoch für Luftfahrzeuge in geringerer Höhe, z. B. Gleitschirme und Drachen, eine ernstzunehmende Gefahr dar.

Weniger bekannt, in der Praxis aber recht verbreitet, sind schwächere Föhneffekte im Lee von niedrigeren Geländestufen und Mittelgebirgszügen. Typischerweise treten solche Effekte bei starker Warmluftadvektion in den Wintermonaten auf. Die warme Luftmasse kann sich mangels Sonneneinstrahlung und aufgrund von Nebel/Hochnebelbildung nicht bis in die tiefen Lagen durchsetzen, es kommt zur Ausbildung einer starken, aber nur wenige hundert Meter flachen Temperaturinversion. Ist die großräumige Luftströmung von einer Hochfläche oder einem Mittelgebirgszug in Richtung Tiefebene gerichtet, so wandert die bodennahe Kaltluftschicht in Richtung Tiefland ab und wird durch die wärmere und trockenere Luft aus höheren Luftschichten ersetzt. Hier kommt es zur Auflösung tiefer Wolkenschichten, bei deutlich verbesserter Sicht und höheren Temperaturen. Diese Effekte treten großräumiger auf, sind nicht auf einzelne Täler begrenzt und können sich noch relativ weit von der Geländeschwelle entfernt bemerkbar machen. Die Windgeschwindigkeit nimmt dabei nur unwesentlich zu.

Typische Regionen mit Föhneffekten sind:

in Deutschland





</doc>
<doc id="1701" url="https://de.wikipedia.org/wiki?curid=1701" title="Fichtelgebirge">
Fichtelgebirge

Das Fichtelgebirge (tschechisch: "Smrčiny") ist ein bis zu 1051 Meter hohes Mittelgebirge im Nordosten Bayerns.

Im Jahre 1971 wurde auf einer Fläche von 1020 km² der Naturpark Fichtelgebirge geschaffen. Kleinere Teile davon befinden sich im Přirodní park Smrčiny (deutsch: "Naturpark Fichtelgebirge") im Nordwesten Tschechiens.
Der südliche Bereich des Naturraumes Fichtelgebirge, der Steinwald, liegt im Naturpark Steinwald.

Das Fichtelgebirge bedeckt eine Fläche von rund 1600 Quadratkilometern. Der weit überwiegende Teil erstreckt sich auf den Osten des bayerischen Regierungsbezirks Oberfranken (Landkreise Wunsiedel, Hof und Bayreuth) und im Südosten hat es Anteil am bayerischen Regierungsbezirk Oberpfalz (Landkreis Tirschenreuth). Zusätzlich reichen seine nord- sowie südöstlichen Teile auf tschechisches Territorium (zur Lage im Bezug auf umliegende Gebirge siehe Naturräumliche Gliederung).

Im nordwestlichen Schenkel des Fichtelgebirgshufeisens liegen dessen höchster Berg, der Schneeberg (1051 m), des Weiteren das Waldsteinmassiv mit dem Großen Waldstein (877 m) und dem markanten Epprechtstein (798 m) sowie der Große Kornberg (827 m). Der Selber Forst mit dem Wartberg (688 m) und der Liebensteiner Forst (heute: Blatenská vrchovina) mit dem Kühbühl (661 m) bildeten bis 1945 noch einen abschließenden Nordostschenkel. Im südöstlichen Schenkel liegen der Steinwald mit der Platte (946 m), der Reichsforst mit dem Steinberg (705 m) und der Kohlwald mit dem Výhledy (656 m). Im südwestlichen Teil zwischen den beiden Schenkeln befinden sich der Ochsenkopf (1024 m), die plateauartige Königsheide mit dem Hohberg (863 m) und die Kösseine (939 m) (für weitere Berge siehe Berge im Hohen Fichtelgebirge und Berge auf der Selb-Wunsiedler Hochfläche).

Zusammen mit Thüringer Wald, Thüringer Schiefergebirge und Frankenwald bildet das Fichtelgebirge die naturräumliche Haupteinheitengruppe Thüringisch-Fränkisches Mittelgebirge (Haupteinheitengruppe Nr. 39). Dabei ist das im Grundriss hufeisenförmige "Fichtelgebirge im engeren Sinne" die Haupteinheit Hohes Fichtelgebirge (Haupteinheit Nr. 394), das die Selb-Wunsiedler Hochfläche (Haupteinheit Nr. 395) mit dem darauf gelegenen Selber Forst von Nordwesten, Südwesten und Südosten umgibt. Seit September 2010 existiert ein Neuentwurf der Naturräume Nordostbayerns, in dem unter anderem das Hohe Fichtelgebirge in mehrere eigenständige Naturräume zerfällt.

Am Nordostrand des Fichtelgebirges schließt sich das Erzgebirge (mit dem Elstergebirge am Übergang) und am Südostrand der Oberpfälzer Wald an. Nach Nordwesten und Norden lassen sich der Frankenwald und das Vogtland geologisch klar abgrenzen. Gleiches gilt für das im Südwesten angrenzende Fränkische Bruchschollenland. Traditionell wird zumindest der südöstliche Teil der Münchberger Hochfläche dem Fichtelgebirge zugeschlagen, jedoch ist diese geologisch anders aufgebaut als das Fichtelgebirge und wird daher als eigenständige naturräumliche Einheit ausgehalten. Somit grenzte der Frankenwald nicht unmittelbar an das Fichtelgebirge.

In der geomorphologischen Gliederung des Nachbarlandes Tschechien, in der kein Elstergebirge definiert ist, werden stattdessen Ašská vrchovina (deutsch: "Ascher Bergland"), Hazlovská pahorkatina (deutsch: "Haslauer Hügelland") sowie Chebská pahorkatina (deutsch: "Egerer Hügelland") dem Fichtelgebirge als Haupteinheit Smrčiny (I3A-1) zugeordnet. Darüber hinaus wird es zusammen mit dem Erzgebirge dem Gebiet Krušnohorská hornatina (Erzgebirge i. w. S.) und zusammen mit dem Egergraben der Subprovinz Krušnohorská subprovincie (Erzgebirgs-Subprovinz) zugeordnet. Weitere übergeordnete Einheiten (in aufsteigender Rangfolge) sind die Provinz Böhmische Masse (Česká vysočina), das Untersystem "Herzynisches Gebirge" (in etwa vergleichbar mit der Mittelgebirgsschwelle zuzüglich der Südwestdeutschen Tafel) und das System Herzynisches System (umfasst zudem Regionen über begrabenem Varistikum nördlich der Mittelgebirgsschwelle).

Zu den bedeutendsten Ortschaften im Fichtelgebirge gehört Wunsiedel, die Hauptstadt des gleichnamigen Landkreises, der faktisch vollständig im Fichtelgebirge liegt und auch den größten Flächenanteil daran hat. Die mit deutlich über 10.000 Einwohnern größten Städte sind jedoch Marktredwitz und Selb (für weitere Ortschaften siehe Städte und Gemeinden). Größere Städte in unmittelbarer Umgebung sind Hof im Norden, Bayreuth im Westen, Cheb (dt. Eger) im Osten und Weiden im Süden.

Mit den Autobahnen A 72 im Norden, A 9 (Abschnitt Hof–Bayreuth) im Westen und A 93 (Abschnitt Hof–Weiden) im Osten tangieren bzw. kreuzen drei bedeutende Verkehrsadern das Fichtelgebirge. Die wichtigste Ost-West-Achse ist die B 303 (E 48). Sie führt über Marktredwitz und verbindet die A 9 mit der A 93. Dieser Abschnitt der B 303 wird auch Fichtelgebirgsstraße genannt. Ab Schirnding führt sie als Staatsstraße 6 über Cheb weiter nach Nordosten.

Ein wichtiger Eisenbahnknotenpunkt im Fichtelgebirge ist der Bahnhof Marktredwitz mit Anbindung an Hof, Bayreuth und Cheb sowie Direktverbindungen nach Regensburg, Nürnberg und München. Über Selb-Plößberg im Nordosten des Fichtelgebirges führt die Bahnstrecke Cheb–Oberkotzau. Daneben ist mit der Bahnstrecke Bayreuth–Warmensteinach noch eine von ehemals sieben Stichstrecken ins Fichtelgebirge in Betrieb, jedoch nur bis Weidenberg.

Mit dem Verkehrslandeplatz Hof-Plauen befindet sich nahe dem Fichtelgebirge auch ein kleiner Regionalflughafen.

Folgende eigenständige Gemeinden begrenzen das physische Fichtelgebirge von außen im Gegenuhrzeigersinn, beginnend im Norden: 
Im "Inneren" des Fichtelgebirges liegen die folgenden Gemeinden , darunter der gesamte Landkreis Wunsiedel im Fichtelgebirge (WUN):

Ortschaften in Tschechien im und am Fichtelgebirge (alle im Okres Cheb):
„Nabel Deutschlands“ oder „Herzbrunnen Europas“ nannte man in früherer Zeit das Fichtelgebirge, denn dort entspringen vier bedeutende Flüsse, die in vier Himmelsrichtungen abfließen:


Viele Teiche und Weiher, die für die Fischzucht oder für die Wasserversorgung der ehemaligen Hammerwerke und Mühlen angelegt wurden, sind noch vorhanden. Künstliche Stauseen, teilweise für Erholungszwecke geschaffen, sind

Größere Teich- bzw. Weiheranlagen sind der

Zahlreiche Moore und Sümpfe, die unter Naturschutz stehen, sind wertvolle Wassersammler. Über das Mittelgebirge verläuft die Europäische Hauptwasserscheide zwischen Nordsee und Schwarzem Meer.

Ausreichende Quellen versorgen die Einwohner mit gutem Trinkwasser. Weiter entfernte Städte wie Hof/Saale, Bayreuth oder Eger (Cheb) beziehen Trinkwasser aus dem Fichtelgebirge.

An größeren Hochmooren sind noch vorhanden:
Die Moorgebiete wurden früher wirtschaftlich für die Gewinnung von Torf für Brennzwecke genutzt, sie sind heute Naturschutzgebiete.

Geologisch besteht der Gebirgsstock im Wesentlichen aus Granit. Die Geschichte seiner Orogenese beginnt im Präkambrium etwa vor 750–800 Millionen Jahren – fast 20 % der Erdgeschichte, was nur auf wenige der noch bestehenden Rumpfgebirge zutrifft.

Damals war das Gebiet von Meer bedeckt und Flüsse transportierten die Sedimente vom heute nicht mehr vorhandenen Gebirge vor die Küsten, wo es sich in Ton- und Sandschichten, teilweise auch als Kalkstein ablagerte.
Am Beginn des Kambriums (vor rund 570 Millionen Jahren) wurden die Schichten gefaltet und als neues Gebirge aus dem Meer herausgehoben. Hohe Temperaturen und Druckkräfte während dieser bis ins Oberkarbon andauernden Gebirgsbildung machten aus den Gesteinen Metamorphite, das heißt, sie wurden in Zusammensetzung und Struktur verändert: aus Ton entstand Phyllit und Glimmerschiefer, aus Sanden Quarzite und aus den Kalken der Wunsiedler Marmor. Durch heftige Erosion (das „junge“ Gebirge mag einige Kilometer hoch gewesen sein) sank es bald wieder unter den Meeresspiegel ab.

Im Silur, Devon und Unterkarbon erfuhren jene Bereiche der Erdkruste, die unter anderem durch das heutige Fichtelgebirge und den Frankenwald repräsentiert sind, die Ablagerung mächtiger Tiefsee-Sedimente sowie Tiefseevulkanismus (mit Erzbildung). Diese Ablagerungen und Vulkanite sind in ihrer annähernd ursprünglichen Ausprägung, einschließlich gut zur Datierung heranziehbarer Fossilien, besonders gut im Frankenwald erhalten, da sie dort keiner oder einer nur sehr niedriggradigen Metamorphose (Anchimetamorphose) unterlagen. Im Oberkarbon vor 285 Millionen Jahren setzte die Endphase der Variszischen Gebirgsbildung ein und die Sedimente und Vulkanite wurden gefaltet. Diese Orogenese ist nach Hofs lateinischem Namen (und dem Volk der Varisker?) "Curia variscorum" benannt. Nachfolgend drangen in mehreren Schüben glutflüssige Schmelzen in die gefalteten Gesteine ein, wo sie tief unter der damaligen Erdoberfläche zu den heutigen Graniten erstarrten. Durch die Platznahme der Granite wurde das Nebengestein meist nur gering kontaktmetamorph überprägt. Aus den Restschmelzen mit deren erzhaltigen Fluiden entstanden die Pegmatite, die Sammlern und Wissenschaftlern reiche Mineralvorkommen bescherten, sowie Erz- und Mineralgänge, die Basis für den Bergbau im Mittelalter und in der Frühphase der Industrialisierung.

Nach Ende der Orogenese, noch während des Oberkarbons sowie im Unteren Perm (Rotliegend) lagerten sich große Mengen Gesteinsschutt in intramontanen Becken und im Vorland des Gebirges ab. Die Becken waren durch eine Dehnungstektonik entstanden, die von einem intermediären bis sauren Vulkanismus begleitet wurde. Die Sedimente des Rotliegenden sind nur an wenigen Stellen aufgeschlossen, können jedoch durch Bohrungen unter dem mesozoischen Deckgebirge südwestlich der Fränkischen Linie weiträumig nachgewiesen werden. Die postvariszischen Vulkanite bilden im Fichtelgebirge Quarzporphyrgänge.

Im Neogen (Jungtertiär, Beginn vor 26 Millionen Jahren) nahm die Tektonik wieder zu, gerade als die alpidische Gebirgsbildung (Alpen, Karpaten usw.) langsam zu Ende ging. In dieser Zeit gerieten Teile dieses und anderer alter Gebirge (siehe Böhmisch-Mährische Höhe oder die Böhmische Masse im Alpenvorland) teilweise unter jüngere Gesteine. Im oberen Miozän, vor zehn Millionen Jahren, brachen im Zuge der Bildung des Egergrabens Basaltschmelzen in der nördlichen Oberpfalz durch. Durch Erosion freipräparierte Überreste ehemaliger Förderschlote sind z. B. am Rauhen Kulm oder am Parkstein bei Weiden vorhanden. Basaltische Decken, also flächenhafte Lavaergüsse dünnflüssiger Lava, sind beispielsweise am Teichelberg bei Pechbrunn zu beobachten. Diese basaltischen Decken sind jedoch nicht mit tektonischen Deckenbildungen zu verwechseln.

Das Bild der heutigen Landschaft entstand im jüngeren Pliozän vor etwa 5 Millionen Jahren: eine schon früh entstandene fränkische Verwerfungslinie kam wieder unter Druck und an ihr entlang hoben sich Fichtelgebirge, Frankenwald, die Münchberger Gneismasse und der nördliche Oberpfälzer Wald. Diese letzte Hebung unterlag erneut der Erosion und die Flüsse schnitten sich tief in das schon früher fast eingeebnete Gebirge ein. So wurde aus einer Hochfläche die heutige Struktur: ein von allen Seiten angenagtes Mittelgebirge mit langer, wechselhafter Geschichte. Es stellt ein, allerdings oft schwierig deutbares Eldorado für Geowissenschafter der verschiedenen Disziplinen dar.
Der Granit (lat. granum für Körnung) und seine Abkömmlinge
machen etwa 40 % der Gebirgsfläche aus. Dieses so feste, aber dennoch wasserhaltige Gestein baute die höchsten Erhebungen auf. Sein ernster Charakter und die früh entwickelte Industrie prägen Landschaft und Leute.

Es gibt nachstehende Granitarten:

Bereits seit dem frühen Mittelalter betrieb man im Fichtelgebirge Erzbergbau. Abgebaut wurden vor allem Gold, Zinn, Eisen, Minerale, Erden und Steine (Basalt, Braunkohle, Diabas, Granit, Lehm, Marmor, Speckstein, Ton, Torf). In jüngerer Zeit entdeckte man Uranerzlagerstätten. In Hammerwerken (siehe Ortsnamensendungen mit -hammer) an den Fichtelgebirgsflüssen, in Schmelzöfen und Schmiedebetrieben erfolgte die Weiterverarbeitung der Metalle. Die Wälder des Fichtelgebirges lieferten das erforderliche Holz für die Herstellung von Holzkohle. Im Dreißigjährigen Krieg lag der Bergbau darnieder, die Erzlagerstätten waren weitgehend ausgebeutet. Alexander von Humboldt versuchte im 18. Jahrhundert, den Bergbau nochmals zu beleben. Viele Städte und Orte (z. B. Wunsiedel, Weißenstadt, Arzberg, Fichtelberg-Neubau, Goldkronach) verdanken ihre Entstehung dem Bergbau.

Einen Einblick in die Bergbaugeschichte des Fichtelgebirges vermitteln

Von den Hugenotten wurde die Osterdekoration der Brunnen ("Osterbrunnen") in Form einer Lilie (Emblem der Bourbonen-Könige) eingeführt (so ein Artikel im April 2007 in der "Fränkischen Post"). Das Wunsiedler Brunnenfest, das größte Heimatfest in der Kreisstadt, hat mit den Osterbrunnen nichts gemeinsam, es hat eine andere Entstehungsgeschichte. Die traditionell auf der Freilichtbühne der Luisenburg bei Wunsiedel stattfindenden Luisenburg-Festspiele gehen bis in das 17. Jahrhundert zurück. In vielen Städten des Fichtelgebirges finden jährlich so genannte Wiesenfeste statt, die von den Schulen durchgeführt werden mit themenorientierten Umzügen, Volkstänzen und Spielen.

Quer durch das Fichtelgebirge verläuft von Nordosten nach Südwesten die Dialektgrenze zwischen dem (Ost-)Fränkischen Dialekt im Norden und Westen sowie dem (nord-)bairischen beziehungsweise Oberpfälzer Dialekt im Osten und Süden. Die Dialektgrenze stimmt nicht mit der Grenze der Regierungsbezirke Oberfranken und Oberpfalz überein, sondern es wird auch z. B. im oberfränkischen Kreis Wunsiedel zum Teil bairisch gesprochen.
Nachkommen Vertriebener, die nach dem Zweiten Weltkrieg aus Böhmen, Mähren, Schlesien und Ostpreußen ins Fichtelgebirge kamen, haben einen bedeutenden Anteil an der Bevölkerung.

Während der Bergbau nur noch von historischem Interesse ist, werden an zahlreichen Orten im Fichtelgebirge noch Glaswaren erzeugt, die man dort auch günstig kaufen kann. International bekannt und deutschlandweit führend ist die Porzellanindustrie, deren Zentrum die Stadt Selb ist. Firmen wie Rosenthal oder Hutschenreuther genießen Weltgeltung. Weitere Unternehmen widmen sich der Kunststoffherstellung, dem Maschinenbau und der Metallerzeugung, der Textilverarbeitung und gehören zum Ernährungsgewerbe. Steinbearbeitungsbetriebe verarbeiten einheimischen und ausländischen Granit. Hochinnovative Unternehmen sind in den Bereichen Green-Tech und Neue Materialien vorhanden.

Der Tourismus stellt heute für viele Gemeinden im Fichtelgebirge die Haupteinnahmequelle dar. In einigen Orten wie beispielsweise Bischofsgrün hat der Tourismus eine lange Tradition seit den 1920er-Jahren; nach dem Zweiten Weltkrieg nahm der Zustrom der Urlaubsreisenden sowohl im Sommer zum Wandern als auch im Winter für den Wintersport stark zu. Das Fichtelgebirge entwickelte sich zu einem der „Hausgebirge“ der West-Berliner, die über die seinerzeit als Transitstrecke fungierende A 9 anreisen konnten. Dies hat sich mit der Wiedervereinigung und einem veränderten Angebot an Mittelgebirgs-Ferienlandschaften verändert.

Im Winter hat das Fichtelgebirge eine auch überregionale Bedeutung als Wintersportgebiet. Mehrere Lifte, zwei Sessellifte am Ochsenkopf und gespurte Loipen bilden die Grundlage hierfür.

Kur- und Rehabilitationseinrichtungen befinden sich in Bad Berneck (Kneippheilbad), Bischofsgrün (Heilklimatischer Kurort), Bad Alexandersbad (Mineral- und Moorbad) und Weißenstadt (Kurhotel mit Radonbad). Mineralquellen gibt es in Bad Alexandersbad, Kothigenbibersbach (Gemeinde Thiersheim), Blumenthal bei Selb, Hohenberg an der Eger, König-Otto-Bad (Markt Wiesau) und Kondrau (Stadt Waldsassen).

Objekte von geotouristischem Interesse und Wanderziele sind unter anderem das Luisenburg-Felsenlabyrinth oder der Teufelstisch am Roten Schloss auf dem Großen Waldstein.

Der Siebenstern ist die Symbolpflanze des Fichtelgebirges.
Am 30. Dezember 2011 erbrachte eine Kamerafalle am Schneeberg den Beweis für die Anwesenheit eines Wolfes im Fichtelgebirge.

Bis in das 19. Jahrhundert wurden Schneeberg, Ochsenkopf mit Königsheide und Kösseine als "Centralgruppe" bezeichnet, während die Nordwest- und Nordostflanke aus Waldstein, Kornberg, Selber Forst und Liebensteiner Forst als "Waldsteiner Kette" und die Südostflanke aus Steinwald, Reichsforst und Kohlwald als "Weißensteiner Kette" bezeichnet wurden.

Johann Wolfgang von Goethe schrieb in einem Brief an Charlotte von Stein „Der Granit lässt mich nicht los!“ Der Dichter und Naturwissenschaftler unternahm drei Reisen in das Fichtelgebirge, bei denen er sich ernsthaft mit naturwissenschaftlichen Problemen auseinandersetzte. Zwei seiner Reisen verband er mit Fahrten von Weimar nach Karlsbad, die letzte unternahm er eigens von Eger aus ins Fichtelgebirge.

Begleitet wurde er von Karl Ludwig von Knebel und Friedrich Gottlieb Dietrich. Am 30. Juni 1785 führte die Reise von Hof über Marktleuthen nach Wunsiedel, noch am gleichen Tag wurden der Katharinenberg und Alexandersbad besucht. Bei einer Fußtour ging es am 1. Juli von Wunsiedel über Leupoldsdorf zum Seehaus (damals Zechenhaus genannt), nach Karches und zur Weißmainquelle (damals Fürstenbrunnen genannt), dann zum Gipfel des Ochsenkopfes, wo unterwegs die seltene Pflanze Sonnentau bewundert wurde. Der Rückweg ging über den Seehügel hinüber zum Nußhardt und zum Weißen Fels, dann nach Vordorfermühle und Vordorf (jetzt zur Gemeinde Tröstau gehörend) nach Wunsiedel zurück. Goethe fertigte dabei einige Zeichnungen von Felsformationen an und trieb geologische Studien. Der 2. Juli war ein Regentag, weshalb nur einige Besichtigungen in Wunsiedel stattfanden. Am 3. Juli waren der Luisenburg (damals noch Luxburg genannt) und dem Burgsteinfelsen gewidmet, wobei wieder einige Zeichnungen von der Granitverwitterung entstanden. Die Weiterreise am 4. Juli führte über Holenbrunn, Göpfersgrün, Thiersheim, Schirnding und Mühlbach nach Eger. Goethe zeigte lebhaftes Interesse an den „geologischen Merkwürdigkeiten“ Marmor, Speckstein und Basalt, die am Reiseweg vorkamen.

Als 71-Jähriger befand er sich wieder auf einer Fahrt in die westböhmischen Bäder, ein Abstecher brachte ihn am 25. April nach Alexandersbad, wo er im "Alten Schloss" logierte. Nach dem Mittagessen begab er sich auf die Luisenburg, die nun durch Wege weitgehend erschlossen war. Er erklärte die Entstehung des Felsenlabyrinths als einen ganz langsam ablaufenden Verwitterungsprozess. Am 26. April folgte die Weiterreise nach Karlsbad.

Am 13. August kam Goethe über Eger, Waldsassen und Mitterteich nach Marktredwitz, um die berühmte Chemische Fabrik von Wolfgang Kaspar Fikentscher zu besichtigen; begleitet wurde er von Joseph Sebastian Grüner, Magistrat- und Polizeirat in Eger. Bis zum 18. August wurde die Quecksilberherstellung begutachtet und die Glashütte bei Brand aufgesucht, wo 17 Arbeiter große Fenstertafeln herstellten; es folgten chemische und pyrotechnische Versuche. Es hat den Anschein, dass es dem 73-jährigen Goethe wegen der Fikentscher-Töchter in Marktredwitz besonders gut gefallen hat.

Der Universalgelehrte Alexander von Humboldt wurde als 22-Jähriger im Jahr 1792 in die damals preußisch gewordenen Fürstentümer Ansbach und Bayreuth entsandt, um den Bergbau auf Vordermann zu bringen. Bis 1795 wirkte er in Arzberg, Goldkronach und Bad Steben, wo es ihm gelang, in kurzer Zeit den Bergbau wieder aufzunehmen, den Grubenbau zu erneuern und moderne Abbaumethoden einzuführen. Bergbauschulen gründete er in Arzberg, Goldkronach und Bad Steben und er richtete eine Bergbau-Hilfskasse für verunglückte Bergleute ein.












</doc>
<doc id="1702" url="https://de.wikipedia.org/wiki?curid=1702" title="Flörsheim am Main">
Flörsheim am Main

Flörsheim am Main ist eine Stadt im Main-Taunus-Kreis in Hessen und liegt zentral im Rhein-Main-Gebiet zwischen Frankfurt am Main und Mainz.

Flörsheim liegt, wie der gesamte Main-Taunus-Kreis, rechts des Untermains. Aus nordöstlicher Richtung von Frankfurt her fließt der Main am Hattersheimer Ortsteil Eddersheim vorbei, wo der – im Ardelgraben in den Main mündende – Weilbach den Beginn der Flörsheimer Gemarkung markiert.

Im Weiteren erstreckt sich die Flörsheimer Altstadt entlang des Maines. Ihr gegenüber liegen, links des Maines, die Städte Raunheim und Rüsselsheim am Main des Kreises Groß-Gerau.

Diesseits von Rüsselsheim beenden Überflutungswiesen, die – nach ihre Vorgängerin "Opelbrücke" genannte – Mainbrücke und ein kleiner Industriehafen die ufernahe Wohnbebauung.

Um den Hafen nimmt der Main eine Rechtsbiegung, bis sich im Mündungsbereich des Wickerbachs der Flörsheimer Ortsteil Keramag/Falkenberg anschließt, der weiter westlich an die Nachbargemeinde Hochheim grenzt.

Parallel zum Main verlaufend trennt die Wiesbaden und Frankfurt anbindende Bahnstrecke die dem Main zugewandte Altstadt von später bebauten Gebieten.

Neben dem Neuzubau hat Flörsheim durch die Zusammenlegung zum Jahreswechsel 1971/1972 mit den vormaligen Nachbargemeinden Weilbach im Norden und Wicker nordwestlich seine heutigen Ausmaße gewonnen.

Heute sind es die Ränder des Stadtteils Weilbach, die die Grenze im Nordosten nach Hattersheim und im Norden nach Hofheim bilden; während Wicker nach Westen an Hochheim und dessen Stadtteil Massenheim grenzt.

Während der Stadtkern Flörsheims in der Mainebene auf liegt, liegt Weilbach auf und Wicker mit deutlich höher. So begründen natürliche Hanglagen die Wickerer Weinanbautradition als "Tor zum Rheingau" und den heute gern bemühten Begriff der "Flörsheimer Schweiz".

Über Weilbach hat Flörsheim im Norden direkten Anschluss an die Wiesbaden und Frankfurt verbindende Autobahn A 66. Während die Autobahn A 3 das Flörsheimer Stadtgebiet ohne eigene Zufahrt in Ost-West-Richtung schneidet. Im Besonderen trennt die A 3 Weilbach von dessen kleineren Teil Bad Weilbach. Dort entspringen eine Natron-Lithion- und in einem kleinen Parkgelände eine Schwefelquelle.

Im Stadtgebiet gab es mehrere Kalksteinbrüche und Gruben, die später teils als Mülldeponien genutzt wurden. Heute befindet sich im Bereich zwischen Wicker und Hochheim der Rhein-Main-Deponiepark. In jüngster Vergangenheit wurden Anstrengungen zur Renaturierung und Schaffung von Naherholung gemacht.
Die Bewohner Flörsheims sind der Belastung von Fluglärm und Wirbelschleppen durch den östlich, jenseits des Maines gelegenen Flughafen Frankfurt am Main ausgesetzt.
Teile des Flughafengeländes befanden sich bis 1980 als Wald in Flörsheimer Eigentum. Heute führen die An- oder Abflugschneisen von drei der vier Startbahnen über bewohntes Flörsheimer Stadtgebiet.

Neben der Belastung profitiert Flörsheim von seiner zentralen Lage nahe dem Flughafen, zwischen den großen Städten des Rhein-Main-Gebiets: Frankfurt am Main, Wiesbaden, Mainz und Darmstadt.

Ein am heutigen Flörsheim vorbeiführender frühgeschichtlicher Wanderungsweg wurde von den Römern zur Straße ausgebaut. Diese führte von Kastel über Hochheim, Flörsheim, Okriftel und Höchst in die Wetterau und weiter ins heutige Mitteldeutschland. Eine weitere Römerstraße zweigte zwischen Flörsheim und Weilbach nach Limburg an der Lahn ab. Das Straßenpflaster aus Kalkstein stammte aus Flörsheimer Steinbrüchen.

Die heutigen Stadtteile Flörsheim, Wicker und Weilbach entstanden aus Siedlungen der westgermanischen Volksgruppe der Franken.
Flörsheim wurde im Jahr 828 erstmals urkundlich als "Flaritesheim" erwähnt. Der Ortsname könnte auf einen Franken namens „Flarido“ zurückgehen. Eine Schenkungsurkunde befindet sich im Hessischen Staatsarchiv Marburg. Erzbischof Hermann I. von Köln bestätigte im Jahr 922 seine Besitzungen im fränkischen Maingau. Er bezeichnete Flörsheim als "Flaradesheim" und Wicker als "Weleron". Wicker wurde urkundlich erstmals im Jahr 910 und Weilbach im Jahr 1112 erwähnt.

Im Jahr 1270 wurde Flörsheim für 1050 Mark an das Mainzer Domkapitel verkauft. Um den Wasserverkehr auf dem Main zu kontrollieren, wurde Flörsheim im Verlauf des Mittelalters stark befestigt.

Während des Dreißigjährigen Krieges wurde Flörsheim verwüstet, nachdem der schwedische König Gustav Adolf seinen Vormarsch auf Mainz 1631 vor Flörsheims Befestigungen unterbrechen musste. Nach achttägiger Einschließung durch die Schweden ergab sich Flörsheim und blieb bis 1636 besetzt.
Auch die Kriege Friedrich des Großen brachten Unheil über den Ort – aber auch die Industrialisierung. Im Jahr 1765 eröffnete der Mainzer Georg Ludwig Müller in Flörsheim eine Fayence-Fabrik mit etwa 80 Arbeitern. Das darin hergestellte Porzellan trägt als Marke drei große „F“ für „Flörsheimer Fayence-Fabrik“, die noch heute im Stadtwappen zu sehen sind. Die Fabrik bestand bis ins Jahr 1914.

Lange Zeit bestanden enge Bindungen zu Mainz. Das änderte sich erst zu Beginn des 19. Jahrhunderts während der Herrschaft Napoleons, als Flörsheim im Jahr 1803 dem Fürstentum Nassau-Weilburg – kurz danach – dem Herzogtum Nassau zugeschlagen wurde.
Im Jahr 1839 wurde zwischen Wiesbaden und Frankfurt die Taunus-Eisenbahn als erste hessische Eisenbahn erbaut. Nach der Planung sollten auch Anschlussgleise nach Darmstadt führen.

Der mit der Taunusbahn 1839 errichtete Bahnhof stammt vom Architekten Ignaz Opfermann. Er lag damals noch außerhalb der Altstadt und zählt zu den ältesten erhaltenen Bahnhöfen Deutschlands. 1875 wurde das Obergeschoss als Wohnung für den Bahnhofsvorsteher angebaut.

1865 wurde die Freiwillige Feuerwehr Flörsheim gegründet. Nach dem Deutschen Krieg von 1866 kam Flörsheim zum Königreich Preußen, welches das Herzogtum Nassau annektiert hatte.

Im Jahr 1900 wurden in Flörsheim die ersten Telefonanschlüsse installiert, am 25. August 1914 erhielt der Ort elektrisches Licht. Im Ersten Weltkrieg hatte Flörsheim 104 Gefallene und 7 Vermisste zu beklagen. Nach dem Krieg besetzten französische Truppen am 1. Dezember 1918 den Ort. Die Franzosen hielten Flörsheim im Zuge der Alliierten Rheinlandbesetzung bis in die späten 1920er Jahre besetzt.

Gab es zuvor nur eine Fährverbindung nach Raunheim, so schuf die am 26. August 1928 eingeweihte „Opelbrücke“ eine Straßenverbindung zur anderen Mainseite nach Rüsselsheim. Diese Brücke wurde 1979 abgerissen und etwas weiter mainaufwärts durch eine größere Brücke mit vierspuriger Fahrbahn ersetzt.

In der Nacht vom 18. auf den 19. Juli 1938 wurde der jüdische Friedhof von Nationalsozialisten zerstört. Am 10. November 1938 wurde in der Reichskristallnacht auch die 1718 errichtete Flörsheimer Synagoge zerstört. Im Zweiten Weltkrieg gingen in der Nacht vom 8. zum 9. September 1942 auf den Ort und die Gemarkung Flörsheim 29 Sprengbomben nieder. Durch den schweren Bombenangriff entstanden 26 Brände und 11 Gebäude – davon 9 Wohnhäuser – wurden völlig zerstört sowie 81 Gebäude, fast nur Wohnhäuser, schwer beschädigt. Fünf Menschen starben. Am 23. März 1945 sprengten deutsche Truppen die von Rüsselsheim über den Main führende Opelbrücke, um den Vormarsch amerikanischer Truppen aufzuhalten. Die Amerikaner marschierten dennoch am nächsten Tag in Flörsheim ein.

Nach dem Zweiten Weltkrieg und der Auflösung des Freistaats Preußen durch die Alliierten im Jahr 1945 kam Flörsheim zum neu gebildeten Bundesland Hessen.

Im Jahr 1953 erhielt Flörsheim das Stadtrecht.
Am 31. Dezember 1971 schlossen sich Flörsheim, Weilbach und Wicker im Vorgriff auf die Gebietsreform in Hessen zusammen.

Am 1. Januar 1978 wurde der Name der Stadt amtlich in „Flörsheim am Main“ geändert.

Die Hexenprozesse in Flörsheim dauerten von 1595 bis 1630. In Flörsheim, Weilbach und Wicker fielen über 71 Frauen, Männer und Kinder dem Hexenwahn zum Opfer. Zur „Bestreitung der Unkosten der wegen Ausrottung und Bestrafung des eingerissenen Lasters der Zauberei und Hexerei befohlenen Inquisition“ nahm die Gemeinde 1618 beim St.-Clara-Kloster in Mainz ein Darlehen auf, konnte aber keine Rückzahlungen leisten. Noch hundert Jahre später hatte die Stadt an der Schuldenlast zu tragen.

Die Namensendung auf „-heim“ deutet auf einen fränkischen Ursprung hin, während sich der erste Namensteil möglicherweise auf einen germanischen Personennamen wie „Flarid“ oder „Flarad“ zurückführen lässt.

Die Zuordnung einer urkundlichen Erwähnung in einem Kartular des Klosters Fulda aus dem Jahr 828: „Tradidit Reginpraht ad Flaritesheim mancipia II“, deutsch: "Es übertrug Reginpraht zu Flörsheim zwei Hörige". zu Flörsheim am Main ist spekulativ.

Urkundlich zweifelsfrei auf die Ortschaft am Main bezieht sich eine Benennung vom 11. August 922 durch Hermann I. von Köln. In der Urkunde werden als Besitzungen im „pago Moinacense“ – Gau am Main – „Flaradesheim“ – Flörsheim – und „Wikeron“ – Wicker – genannt.

1171 erschien im Lehnsbuch der Herren von Eppstein der Eintrag "dorff in Vlersheim".

1270 in der Beurkundung des Dorfverkaufs an das Domkapitel des Erzbistums Mainz zum 1. April wird das Dorf als "villam nostram Flersheim" bezeichnet.

Seit 1. Januar 1978 heißt die Stadt amtlich Flörsheim am Main, nachdem zuvor schon abkürzende Schreibweisen wie Flörsheim/M, Flörsheim/Main oder Flörsheim a. M. gebräuchlich waren.

Im örtlichen Dialekt heißt die Stadt „Flerschem“.

Die folgende Liste zeigt die Territorien bzw. Verwaltungseinheiten denen Flörsheim unterstand im Überblick:

Jedes Jahr am Fastnachtssonntag beginnt um 13.31 Uhr der Flörsheimer Fastnachtsumzug oder „Fassenachtszuuch“, zum Teil mit über 3500 Teilnehmern und um die 160 Zugnummern. Regelmäßig übersteigt die Zahl der Gäste die der Einwohner. Im Jahr 2007 berichtete der Hessische Rundfunk sogar von 80.000 Besuchern.

Der Fastnachts- oder Narrenruf „Hall die Gail“ entstammt der Zeit, als im Fastnachtszug noch viele Wagen mit Pferdegespannen fuhren. Er war die Aufforderung an einen Zugwagenlenker inne zu halten bzw. die vor der ausgelassenen Menschenmenge scheuenden Pferde im Zaum zu halten. So übersetzt sich „Hall die Gail“ mit „Halte die Pferde/Gäule!“

Seit den 1970er Jahren gibt es an einem Juli-Wochenende das „Flörsheimer Open Air“, ein kleines Rock-Musikfestival mit freiem Eintritt auf den Wiesen unter der Mainbrücke nach Rüsselsheim.
Das Festival wird vom örtlichen Verein "Old Company" nur durch ehrenamtliche Helfer ausgerichtet und fand 2015 bereits zum 40. Mal statt.

Jedes Jahr am letzten Montag im August feiert die Stadt den „Verlobten Tag“. Dieser hat seinen Ursprung im Jahr 1666, als in Flörsheim die Pest wütete. Nachdem innerhalb kürzester Zeit mehr als 200 Einwohner gestorben waren und der kleinen Gemeinde von etwa 700 Einwohnern die völlige Ausrottung drohte, beteten der Überlieferung nach die Überlebenden in höchster Not um Rettung.

Als die Pest dann tatsächlich endete, gelobten die Flörsheimer zusammen mit dem Initiator Pfarrer Johannes Laurentius Münch „solange in Flörsheim Stein auf Stein steht, eine Dankprozession zum Lobpreis des Allerhöchsten alljährlich durchzuführen“. Dieses Gelöbnis wurde bisher strikt eingehalten; auch in Kriegszeiten und trotz zeitweisem Verbot der Veranstaltung. Am 29. August 2016 wurde der „Verlobte Tag“ zum 350. Mal gefeiert.

Verwurzelt in dem Fest zur Weihe der St.-Gallus-Kirche wird am 16. Oktober, dem Tag des Namenspatrons St. Gallus, beziehungsweise am darauffolgenden Wochenende die Flörsheimer „Kerb“ abgehalten. Seit über hundert Jahren wird alljährlich am Mainufer ein Jahrmarkt errichtet. Während dort ein Rummel mit Buden und Fahrgeschäften betrieben wird, organisieren die Kerweborsch (Kerbeburschen) Tanzveranstaltungen – pflegen Brauchtum und Geselligkeit: Traditionell wird am Samstag ein Baum errichtet, der mit Kerwebobb (Kerbe-Puppe) und Bluns (Blutwurst ohne Grieben) ausgestattet ist. Ein Umzug findet statt. Die Flörsheimer Besonderheit der „Nachkerb“ am nachfolgenden Wochenende stand im Jahr 2014 zur Disposition.
Künftig findet der traditionelle Abschluss der Kerb mit Beerdigung der Kerbe-Puppe und Feuerwerk schon am Nachkerbesonntag statt wie bislang montags statt.

Seit 1980 finden im vierten Quartal eines Kalenderjahres die Gallus-Konzerte statt, eine musikkulturelle Reihe, deren konzertante Aufführungen teilweise als Veranstaltungen des Hessischen Rundfunks geführt werden.
Der Verwaltungsaufbau der Stadt Flörsheim am Main richtet sich nach der Hessischen Gemeindeordnung und der Hauptsatzung der Stadt in der Fassung vom 8. November 2012.

Danach fungiert die Stadtverordnetenversammlung, aus von den Bürgern der Stadt gewählten Stadtverordneten, als oberstes Organ der kommunalen Selbstverwaltung. Der Magistrat als ausführendes Organ besorgt die laufende Verwaltung der Stadt. Er besteht aus elf ehrenamtlichen Stadträten, sowie dem hauptamtlichen Bürgermeister und dem ebenfalls hauptamtlichen Ersten Stadtrat als seinem Vertreter.

Die Hauptsatzung regelt die Einteilung der Stadt in vier Ortsbezirke, und legt die Größe der Ortsbeiräte auf jeweils neun Mitglieder, sowie für den Ortsbeirat Keramag/Falkenberg auf fünf Mitglieder fest. Zudem wird ein Ausländerbeirat mit elf Mitgliedern eingerichtet.

Die Stadt Flörsheim unterliegt nach der Hessischen Gemeindeordnung der Kommunalaufsicht durch das Regierungspräsidium Darmstadt.

Der Bürgermeister wird direkt vom Volk gewählt.

Die Stadtverordnetenversammlung ist das oberste Organ der Stadt. Ihre politische Zusammensetzung wird alle fünf Jahre in der Kommunalwahl durch die Wahlbevölkerung der Stadt bestimmt. Wählen darf, wer das 18. Lebensjahr vollendet hat und Deutscher Staatsbürger im Sinne des Grundgesetzes oder Staatsangehöriger eines der übrigen Mitgliedstaaten der Europäischen Union ist. Für alle gilt, dass sie seit mindestens drei Monaten in der Stadt gemeldet sein müssen.

Die Kommunalwahl am 6. März 2016 lieferte folgendes Ergebnis: in Vergleich gesetzt zu früheren Kommunalwahlen:

Es waren 37 Stadtverordnete sowie die Ortsbeiräte der Stadt für die Legislaturperiode vom 1. April 2016 bis 31. März 2021 zu wählen. Von 15.943 Wahlberechtigten gingen 8136 zur Wahl. Somit stieg die Wahlbeteiligung von 47,5 Prozent im Jahr 2011 auf 51 Prozent im Jahr 2016.

Der seit 1. November 2006 amtierende Bürgermeister Michael Antenbrink (SPD) wurde am 17. September 2006 in einer Stichwahl mit 56,1 Prozent der Stimmen gewählt. Die Wahlbeteiligung betrug 47,5 Prozent. Für eine zweite sechsjährige Amtszeit wurde er am 17. Juni 2012 wiedergewählt, wiederum in einer Stichwahl, mit 61,6 Prozent der Stimmen bei 46,1 Prozent Wahlbeteiligung.

Antenbrink ist Nachfolger von Ulrich Krebs (CDU), der am 18. März 2001 zum Bürgermeister gewählt wurde und am 8. Mai 2006 aus dem Amt ausschied, um im Hochtaunuskreis als Landrat eingeführt zu werden.

Seit Einführung der Möglichkeit zu Bürgerentscheiden in Hessen am 1. April 1993 hat Flörsheim zweimal – am 6. Mai 2007 und am 13. Februar 2011 – über das Betreiben der Planfeststellung zum Bau einer Ortsumgehungsstraße entschieden. Beide Male hat sich die Bevölkerung mit knappen Mehrheiten für die Abstimmungsfrage ausgesprochen, die sich jeweils gegen die Planung einer Ortsumfahrung der Bundesstraßen B 40/519 wanden. Die Beteiligungsquote an den Bürgerentscheiden lag jeweils über 60 Prozent.

Das Wappenmotiv ist hervorgegangen aus dem seit 1816 verwendeten Sinnbild für das noch bis 1868 verkehrende Flörsheimer Marktschiff, der "Flörsheimer Yacht". Seit 1930 ist das Großsegel mit den drei „F“ versehen. Diese Beschriftung erinnert an die 1765 gegründete Flörsheimer Fayence-Fabrik.

Das Rad der Heckflagge verweist auf die lange historische Zugehörigkeit zum Mainzer Domkapitel zwischen 1270 und 1803.
So wurde das Mainzer Rad im 18. Jahrhundert auf Grenzsteinen und in amtlichen Siegel benutzt. Ältere Gerichtssiegel verweisen, in der bildlichen Darstellung eines thronenden Bischofs im 17. Jahrhundert oder des Mainzer Landespatron St. Martin im 15. Jahrhundert, ebenso auf die Domstadt.

Die Farben Flörsheims sind Blau und Orange. In städtischer „Beflaggung“ wird meist das Stadtwappen auf blauer Fahne gezeigt.

Im Oktober 1952 wurde der Gemeinde Flörsheim am Main durch den Hessischen Minister des Innern die Führung einer Flagge genehmigt.


Am Mainufer verlaufen mehrere Radwanderwege:



Anrufsammeltaxis und Anschlusssammeltaxi

Die S-Bahn-Linie S1 verbindet den Flörsheimer Bahnhof auf der Route Wiesbaden – Mainz-Kastel – Frankfurt – Rödermark-Ober-Roden.

Für den Personenverkehr gibt es am Konrad-Adenauer-Ufer eine Bedarfsanlegestelle für Schiffe, für den Güterumschlag eine weitere Anlegestelle an der Hafenstraße.

Die "Flörsheimer Warte" nahe dem Ortsteil Wicker ist ein 1996 im Stile eines früher an gleicher Stelle stehenden Wartturms errichteter 30 Meter hoher Rundturm. Er steht an der Regionalparkroute Rhein-Main, ist mit dem angrenzenden Restaurant ein beliebtes Ausflugsziel und kann für private Veranstaltungen gemietet werden. Die oberste Ebene bietet durch zwanzig schmale Fenster, zwischen denen jeweils Orientierungstafeln angebracht sind, eine gute Aussicht in die Umgebung.

Der Eisenbaum westlich von Flörsheim, ebenfalls Teil des Regionalparks Rhein-Main, ist mit seiner ausgefallenen Form sowohl eine Skulptur als auch ein Aussichtsturm. Der stählerne 18 Meter hohe Baum besitzt zehn künstliche Äste und bietet eine 9 Meter hohe Aussichtsplattform. Eine solarbetriebene Tonanlage an der Plattform spricht und macht Geräusche.

Die katholischen Gemeinden St. Gallus und St. Josef in Flörsheim, St. Katharina in Wicker und Maria Himmelfahrt in Weilbach befinden sich im Prozess der Bildung eines gemeinsamen Pastoralen Raumes Flörsheim. Dieser soll ab Januar 2015 unter dem Namen Pfarrgemeinde St. Gallus firmieren. Die Gemeinden St. Josef, Maria Himmelfahrt und St. Katharina sollen als Ortskirchen weiterbestehen.

Am 24. Juni 2013 wurde von Mirza Masrur Ahmad – dem Kalifen der Ahmadiyya Muslim Jamaat  – die Ata-Moschee in der Flörsheimer Altkönigstraße eröffnet. („Ata“ bedeutet „Gottesgeschenk, von Gott gegeben“.) Anwesend waren neben dem Bundesvorsitzenden der Gemeinschaft Abdullah Uwe Wagishauser eine Reihe Kommunal- und Landespolitiker.

Zur Moschee wurde seit dem 4. Oktober 2012 ein ehemaliger Lebensmittel-Discounter umgebaut. Der in blau-weiß gehaltene, mit Kalligraphien geschmückte Gebäudekomplex umfasst einen 380 Quadratmeter großen Gebetsraum mit Gebetsnische, eine separate Küche, einen 80 Quadratmeter großen Anbau mit Veranstaltungsraum und Bibliothekszimmer, sowie Büros und einen weiteren Seminarraum im Obergeschoss. Den Moscheecharakter unterstreichen zwei ins Dach eingefügte Kuppeln, sowie ein etwa 10 Meter hohes symbolisches Minarett am Eingang.

Die Ahmadiyya Muslim Jamaat oder Ahmadiyya Muslim-Gemeinschaft ist eine 1889 im indischen Qadian entstandene islamische Reformgemeinde. Das erste Mitglieder der seit 1995 eigenständigen Gemeinde Flörsheim/Hochheim kam 1988 nach Flörsheim. Zur Eröffnung umfasst die Gemeinde 140 Mitglieder. Ihr Präsident ist Muhammad Munawar Abid.



Liste der Kulturdenkmäler in Flörsheim am Main



</doc>
<doc id="1703" url="https://de.wikipedia.org/wiki?curid=1703" title="FreeDOS">
FreeDOS

FreeDOS ist ein Betriebssystem für Computer aus der Gruppe der DOS-Betriebssysteme.

Die Entwicklung von FreeDOS findet innerhalb des FreeDOS-Projekts statt, in dem sich mehrere Einzelprojekte zusammengefunden haben, um eine freie und kompatible Alternative zum Betriebssystem MS-DOS zu schaffen, dessen Weiterentwicklung von seinem Hersteller Microsoft eingestellt wurde.
Viele der Einzelprojekte verfolgen oder verfolgten ursprünglich das Ziel, Bestandteile wie beispielsweise den DOS-Kernel, Treiber- und Dienstprogramme von MS-DOS oder anderen DOS-Betriebssystemen durch Eigenentwicklungen mit vergleichbarer oder auch erweiterter Funktionalität zu ersetzen oder zu ergänzen.
Das Gesamtprojekt hat dabei den Anspruch, zeitgemäße Erweiterungen und Anpassungen vorzunehmen und dabei trotzdem den Charakter von FreeDOS als einem MS-DOS-kompatiblen Betriebssystem zu erhalten.

Am 3. September 2006 wurde die Version 1.0 fertiggestellt. Die für April 2008 geplante Version 1.1 erschien schließlich am 2. Januar 2012. Version 1.2 enthält vor allem Detailverbesserungen wie neuere Versionen und zusätzliche Programme.

FreeDOS ist ein quelloffenes und freies Betriebssystem, das der GPL-Lizenz unterliegt und aktiv weiterentwickelt wird. Darüber hinaus bietet es aber auch technische Vorteile gegenüber anderen DOS-Betriebssystemen. So unterstützt es unter anderem:


FreeDOS wurde als Alternative zu MS-DOS geschaffen. Das Projekt wurde 1994 gestartet, als Microsoft bekanntgab, dass der Vertrieb und die Produktunterstützung für MS-DOS eingestellt werden würden. Die Entwicklung startete fast von null, nur auf zwei schon vorhandene Projekte konnten die Entwickler aufbauen: DOS-C, dessen Kernel schließlich von FreeDOS übernommen wurde, und einen sehr primitiven Speichermanager, der nach aufwendiger Überarbeitung zu EMM386.EXE wurde. Die Entwicklung von FreeDOS verlief unabhängig von DR DOS, das 1996 als „OpenDOS“ ebenfalls unter einer quelloffenen Lizenz, jedoch eingeschränkt auf nicht-kommerziellen, privaten Gebrauch, veröffentlicht wurde. Diese ist jedoch nicht mit der für FreeDOS verwendeten GNU General Public License vereinbar, weswegen die Übertragung von Quelltext ausgeschlossen ist.

Ab der Version Beta 5 und 6 wurde FreeDOS zunehmend als hinreichend ausgereift bewertet und wurde diversen Computerzeitschriften, meist auf CD-ROM, beigelegt. Mit den der Beta 9 Ende 2003 wurden die ersten PCs mit FreeDOS ausgeliefert, etwa von Dell und HP. Es gilt als moderneres DOS, da es bereits größere Festplatten und FAT32 unterstützt, was den letzten Versionen von MS-DOS fehlte (ohne Windows, also vor Windows 95b/MS-DOS 7.10).

FreeDOS umfasst eigene Treiber für XMS (HIMEM.EXE) und EMS (EMM386.EXE). EMM386 unterstützt mittlerweile auch die Speicher-Schnittstelle VCPI und funktioniert somit mit DOS-Extendern und DPMI-Programmen zur Erweiterung des unter MS-DOS-Kompatiblen auf 1 MiB beschränkten, konventionellen Speicherraums. Statt HIMEM und EMM386 kann man auch die Alternativen HIMEMX (Ersatz für und Verbesserungen gegenüber dem originalen HIMEM), JEMM386 (leistungsfähiger Ersatz für EMM386) oder JEMMEX (kombiniert die Funktionalität von HIMEM und EMM386 in einem einzigen Programm) benutzen, die auf den beiden offiziellen FreeDOS-Treibern aufbauen. In der FreeDOS-Distribution sind auch Ultra-DMA-Treiber und das Programm „LBAcache“ enthalten, das ähnlich wie „SmartDrv“ von Microsoft Festplattendaten im XMS-Speicher puffert (siehe auch Festplattencache). Durch Einsatz solcher Treiber und Programme kann teilweise ein schnellerer Festplattenzugriff erzielt werden als unter modernen 32-Bit-Betriebssystemen wie Microsoft Windows oder Linux.

Der FreeCOM-Befehlszeileninterpreter sowie Teile des Kernels, Puffer, Treiber und TSRs lassen sich ähnlich wie in späten MS-DOS-Versionen in den UMB- beziehungsweise HMA-Speicher laden, wodurch bis zu 620 KiB des konventionellen DOS-Speichers (der 640 KiB umfasst) verfügbar gemacht werden können. Das ist zum Beispiel für alte Spiele und Anwendungen wichtig, da diese oft viel des knappen konventionellen Speichers benötigen.

Eine native Unterstützung für NTFS ist nicht geplant, allerdings gibt es Shareware-Treiber, die diese Aufgabe erfüllen.

Microsoft Windows ist überhaupt nicht (ab Windows 95), nur eingeschränkt (Windows 3.x) oder nur in sehr alten Versionen (Windows 1.x oder 2.x) nutzbar. Ähnliche Probleme wie mit neueren Windows-Versionen treten auch mit anderen Programmen auf, die viele undokumentierte Schnittstellen in MS-DOS benutzen. Außerdem befinden sich einige Programme in FreeDOS noch in der Beta-Phase, sind also nicht immer ausreichend auf Fehler geprüft und versagen möglicherweise den Dienst.

Das System wird vornehmlich genutzt, damit Komplettsysteme nominell nicht ohne Betriebssystem ausgeliefert werden, so etwa von Dell für seine "n-Serie". Außerdem wird FreeDOS gerne für bootbare Disketten verwendet, z. B. um Testprogramme mit vollem Hardwarezugriff zu starten.

Neben neuen für FreeDOS entwickelten Programmen laufen fast alle Programme, die für MS-DOS geschrieben wurden, problemlos auch unter FreeDOS. Ausnahmen sind einzelne Programme, die eine MS-DOS-Versionsüberprüfung durchführen oder die von nicht standardisierten Verhaltensweisen oder undokumentierten Merkmalen von MS-DOS abhängen. Grundsätzlich unterstützt werden:

Mit Hilfe des HX DOS Extender besteht zudem die Möglichkeit, einige für Windows (32-Bit) geschriebene PE-EXE-Dateien unter FreeDOS auszuführen.

Für MS-DOS geschriebene grafische Benutzeroberflächen (kurz „GUI“) sollten grundsätzlich auch auf FreeDOS lauffähig sein. Auch hier gilt, falls das betreffende GUI von standardisierten Verhaltensweisen abweicht oder undokumentierte Merkmale von MS-DOS verwendet, treten Probleme auf. Das betrifft beispielsweise Windows-3.x-Versionen (siehe unten).

Sehr gute Kompatibilität weist OpenGEM auf, eine grafische Benutzeroberfläche für MS-DOS-kompatible Betriebssysteme, die unter einer freien Lizenz steht. OpenGEM ist eine Weiterentwicklung der Mitte der 1980er Jahre populären Benutzeroberfläche GEM von Digital Research, die unter anderem durch den Atari ST weite Verbreitung fand und bereits damals in einer Version für den IBM-PC verfügbar war.

Weitere mit FreeDOS kompatible grafische Benutzeroberflächen sind unter anderem ct-FRAME, PC/GEOS, oZone und SEAL.

Die Windows-Versionen 1.0 bis 2.x stellen noch keine eigene Speicherverwaltung und keine eigenen Treiber für den Datenträgerzugriff bereit und lassen sich somit problemlos unter FreeDOS benutzen. Windows 3.x und Windows for Workgroups 3.x laufen bisher nur im "Standard Mode". Zur Verwendung des "Enhanced Mode" ist ein neuerer FreeDOS-Kernel notwendig, der sich noch in der Test-Phase befindet.

Abgesehen von der theoretischen Möglichkeit, Windows 4.0 (die grafische Bedienoberfläche von Windows 95) direkt unter FreeDOS zu starten, beinhalten alle DOS-basierten Windows-Versionen als vollwertige Betriebssysteme einen angepassten DOS-Unterbau in Form von MS-DOS 7.0/7.1 (Windows 95/98) bzw. MS-DOS 8.0 (Windows Me).

Da diese Windows-Versionen auf viele undokumentierte Funktionen des mitgelieferten MS-DOS zugreifen, sind sie nicht von FreeDOS aus startbar.

Ab Windows 95 ist ein eigenes, angepasstes MS-DOS im Lieferumfang. Um FreeDOS neben Windows 95 und allen Nachfolgeversionen betreiben zu können, ist daher ein Mechanismus erforderlich, der sich „Dualboot“ oder „Multiboot“ nennt. Windows 95 bringt generell bereits alle Voraussetzungen dazu mit – wenn es zum Beispiel auf einer Partition mit bereits vorhandenem DOS installiert werden soll, konfiguriert es automatisch ein geeignetes Bootmenü zur Auswahl des zu startenden Betriebssystems. Dieser Mechanismus funktioniert jedoch nur zusammen mit MS-DOS und PC-DOS.

Daher bietet die FreeDOS-Distribution das Programm "MetaKern", das für DOS-basierte Windows-Versionen (Windows 95 bis Windows Me) ebenfalls ein Bootmenü zur Verfügung stellt.

Mit Windows-Versionen, die von Windows NT abstammen und daher NTLDR verwenden, wird FreeDOS als „unbekanntes Betriebssystem“ erkannt und kann auch gestartet werden, im Fall von Windows NT bis einschließlich Version 4.0 jedoch nur, wenn FreeDOS auf einer FAT16-Partition installiert ist. Alternativ kann man die Datei BOOT.INI, bei ReactOS FREELDR.INI, manuell anpassen.

Mit Windows Vista wurde ein neues Gebilde mit dem Namen „“ eingeführt (siehe auch "Boot Configuration Data"), das nur über die Befehlszeilenanwendung BCDEDIT.EXE geändert werden kann.

Ab Version 1.0 gibt es eine offizielle FreeDOS-Distribution auf CD, die als ISO-Abbild aus dem Internet heruntergeladen werden kann. Mit der bootfähigen Live-CD, mit der man ohne Installation FreeDOS einfach ausprobieren kann, ist auch eine Installation auf die Festplatte möglich. Enthalten sind neben den Systemdateien von FreeDOS und der grafischen Benutzeroberfläche OpenGEM auch eine Reihe von nützlichen Programmen, von denen einige hier aufgeführt sind:


Da die Distributions-CD nicht ständig auf dem aktuellen Stand gehalten wird, kann man sich aktualisierte Versionen der einzelnen Programme auch separat herunterladen. Links dazu finden sich jeweils auf der FreeDOS-Website.




</doc>
<doc id="1704" url="https://de.wikipedia.org/wiki?curid=1704" title="Familie (Biologie)">
Familie (Biologie)

Die Familie () ist eine hierarchische Ebene der biologischen Systematik.

Sie steht zwischen den Hauptrangstufen Ordnung und Gattung. Direkt über der Familie kann als Ableitung die Überfamilie (lat. "superfamilia") stehen, unter ihr die Unterfamilie (lat. "subfamilia"). In der Zoologie kommt zur speziellen Familien-Rangstufe noch die aus weiteren Rangstufen bestehende Familien-Gruppe.

In der Zoologie endet die Familienbezeichnung stets auf "-idae" (zum Beispiel Hunde: Canidae, Katzen: Felidae), die Überfamilienbezeichnung teilweise auf "-oidea" (Beispiel Hundeartige: Canoidea, alternativ aber auch Caniformia) und die Unterfamilienbezeichnung stets auf "-inae" (Beispiel Kleinkatzen: Felinae).
Wenn die Mitglieder einer Familie gemeint sind, wird im deutschen dazu oft die Endung "-iden" benutzt (zum Beispiel Hunde: Caniden, Katzen: Feliden), bei Mitgliedern einer Unterfamilie wird die Endung "-inen" verwendet (Beispiel Kleinkatzen: Felinen).

In der Botanik endet die Familienbezeichnung im Grundsatz auf "-aceae" (zum Beispiel Korbblütler: Asteraceae, Liliengewächse: Liliaceae), Unterfamilien auf "-oideae" (zum Beispiel Lilioideae) und leitet sich stets vom Gattungsnamen einer festgelegten Typusart ab (z. B. "Aster", "Lilium"). Historisch waren in der Botanik jedoch auch Benennungen nach morphologischen Besonderheiten üblich. Artikel 18.5 des ICBN legt fest, dass acht solche abweichende Familiennamen als gültig publiziert anzusehen sind, nämlich Palmae/Arecaceae, Gramineae/Poaceae, Cruciferae/Brassicaceae, Leguminosae/Fabaceae, Guttiferae/Clusiaceae, Umbelliferae/Apiaceae, Labiatae/Lamiaceae und Compositae/Asteraceae. In allen anderen Fällen gilt ausschließlich der vom Typus abgeleitete und auf "-aceae" endende Name als gültig.

Der Begriff geht auf Pierre Magnol zurück, der ihn 1689 in die Botanik einführte. Linné verwandte den Begriff noch nicht. Michel Adanson gebrauchte ihn dann 1764 in seinem Werk "Familles des Plants" und definierte dort die ersten 58 Pflanzenfamilien. Auch bei Antoine-Laurent de Jussieu kommt er nicht vor, vergleichbaren Rang nehmen dort die "ordines naturales" („natürliche Ordnungen“) ein, die konzeptionell den Familien entsprachen.

Erst zur Mitte des 19. Jahrhunderts begann sich die Rangstufe dann – auch außerhalb der Botanik – durchzusetzen.


</doc>
<doc id="1705" url="https://de.wikipedia.org/wiki?curid=1705" title="Feldschlange">
Feldschlange

Die Feldschlange, auch Kolubrine (von – „schlangenartig“; , , türk. Kolomborna) oder Kalverine, war ein Kanonentyp des späten Mittelalters und der Frühen Neuzeit.

Der Name "Feldschlange" kommt in Deutschland erstmals um 1440 vor und stammt vermutlich von der anfangs als Schlangen- oder Drachenkopf gestalteten Mündung. Möglich ist aber auch, dass der Begriff auf die Machart der Feldschlange anspielt, deren Rohr häufig mit einem korkenzieherförmigen Eisenband umschmiedet war (vgl. Schrumpfringe bei heutigen Kanonen).

Feldschlangen hatten ein im Vergleich zu den Kartaunen genannten Belagerungsgeschützen ein relativ kleines Geschosskaliber, zwischen 13 cm ("ganze Feldschlangen") und ca. 5 cm ("Falkonetts") bzw. 3,5 cm ("Serpentinell"). Der Lauf war dagegen mit normalerweise zwischen 30 und 40 Kaliberlängen länger als die Rohre der Kartaunen, die meist nur 17 Kaliber, bei der Viertel-Kartaune auch 24 und bei der Falkaune (sofern als Kartaune eingeteilt, siehe unten) auch 27 Kaliber zählten. Das längere Rohr erhöhte die Treffsicherheit, Reichweite und Durchschlagswirkung der Geschosse, da die Kugeln nachhaltiger dem Explosionsdruck der Treibladung ausgesetzt waren. Geschütze mit noch größerer Kaliberlänge bezeichnete man auch als "Bastard-Feldschlangen" (von ).

Die Entwicklung des Kanonengusses im 16. Jahrhundert beruhte auf der Kombination mehrerer Durchbrüche in den beteiligten Handwerken:

Die verschossenen Eisenkugeln variierten im Gewicht zwischen etwa 20 Pfund bei den größten Geschützen und einem Pfund bei den kleinsten. Feldschlangen waren gewöhnlich auf einer zweirädrigen Lafette montiert, die von einem Pferd gezogen werden konnte.

Die Einteilung der Feldschlangen-Typen unterlag je nach Region oder Autor gewissen Varianten hinsichtlich der Namensgebung und der zugehörigen Kaliber- und Geschossmaße. Die Feldschlangen wurden in der Regel eingeteilt in "Ganze Feldschlange" (Geschossgewicht: etwa 18 Pfund), "Notschlange" (16-Pfünder), "Halbe Feldschlange" (9-Pfünder) und "Quartierschlange" bzw. "Falkaune" (7-Pfünder, Michael Mieth teilt die Falkaune im Jahr 1684 jedoch als 6-Pfünder-Kartaune ein!) und "Falkon" (2-Pfünder). 

Dem gezielten Einzelschuss auf feindliche Offiziere oder Geschützbedienungen dienten "Falkonett" (auch "Achtel-Schlange", 1-Pfünder) und "Serpentinell" (auch "Schmirgel" oder "(Feld-)Schlängelein". Geschossgewicht: 16 Lot bzw. 1/2 Pfund). Giovanni dalle Bande Nere kostete ein Falkonetttreffer zunächst ein Bein, die infizierte Wunde dann sein Leben, ebenso Marschall Guébriant. Götz von Berlichingen verlor seine rechte Hand durch eine Feldschlange.

Dieser Kanonentyp ging später in der Feldkanone auf.

Kuriosum: Die Rohre ausgedienter Feldschlangen wurden gelegentlich an belebten Straßenecken zum Schutz der Hauskanten als Prellstein eingemauert (so beschrieben von Wilhelm Raabe in "Die Chronik der Sperlingsgasse").



</doc>
<doc id="1706" url="https://de.wikipedia.org/wiki?curid=1706" title="Frequenz">
Frequenz

Die Frequenz (von lat. "frequentia", Häufigkeit) ist in Physik und Technik ein Maß dafür, wie schnell bei einem periodischen Vorgang die Wiederholungen aufeinander folgen, z. B. bei einer fortdauernden Schwingung. Die Frequenz ist der Kehrwert der Periodendauer.

Die Einheit der Frequenz ist die abgeleitete SI-Einheit mit dem besonderen Namen Hertz (Einheitenzeichen Hz), wobei 1 Hz = s ist. Gelegentlich werden aber auch andere Einheiten verwendet, wie z. B. min oder h. Bei der Frequenzangabe aus Zahlenwert und Einheit sagt demnach der Zahlenwert aus, wie viele Perioden innerhalb der gewählten Zeiteinheit stattfinden.

Bei manchen Vorgängen werden auch die Bezeichnungen Folgefrequenz, Impulsfolgefrequenz oder Hubfrequenz verwendet, bei Drehbewegungen Drehzahl.

Die Frequenz formula_1 eines sich regelmäßig wiederholenden Vorgangs ist definiert als der Kehrwert der Periodendauer formula_2:

Da eine Anzahl formula_4 der sich periodisch wiederholenden Vorgänge das Zeitintervall formula_5 benötigt, gilt ebenso:
Dies wird gelegentlich auch als Definition der Frequenz angegeben. Die Frequenz ist ihrer Natur nach eine beliebig fein veränderbare, kontinuierliche Größe.

Bei Wellen ist die Frequenz über die Phasengeschwindigkeit formula_7 mit ihrer Wellenlänge formula_8 verknüpft:

Bei elektromagnetischen Wellen ist formula_10 und formula_11. Dabei ist formula_12 die Naturkonstante Lichtgeschwindigkeit, formula_13 die Wellenlänge im Vakuum und formula_14 der Brechungsindex des Mediums. Bei einer Welle, die während ihrer Ausbreitung das Medium wechselt, ändern sich die Ausbreitungsgeschwindigkeit und die Wellenlänge. Ihre Frequenz bleibt dagegen gleich.

Für jeden periodischen Vorgang in der Natur und im Alltag kann eine Frequenz angegeben werden. Der Tag-Nacht-Wechsel wiederholt sich beispielsweise mit einer Frequenz von formula_15.
Das menschliche Herz hat im ruhenden Körper eine Pulsfrequenz von ca. 50–90 min (das entspricht 0,83–1,5 Hz), die Atemfrequenz beträgt, je nach Alter beim Menschen 12 bis 50 Atemzüge pro Minute. In der Musik ist der Standard-Kammerton mit einer Frequenz von 440 Hz bekannt. Die empfundene Tonhöhe eines Tons ist hauptsächlich durch die Frequenz seiner Grundschwingung bestimmt. Das menschliche Ohr nimmt Schallwellen mit Frequenzen zwischen 20 Hz und höchstens 20.000 Hz wahr; mit zunehmendem Lebensalter sinkt die Obergrenze im Allgemeinen bis auf 10.000 Hz und weniger.

Die mit elektronischen Mitteln herstellbaren Frequenzen elektromagnetischer Wellen werden im Bereich zwischen ca. 100 kHz und einigen GHz für die Zwecke der drahtlosen Kommunikation in Frequenzbänder aufgeteilt (Langwelle, Mittelwelle, UKW, ...). Das für Menschen wahrnehmbare Licht liegt im Bereich zwischen 400 THz und 750 THz.

Eine Reihe unterschiedlicher Messgeräte werden unter Frequenzmesser aufgeführt. Die Frequenz gilt in der digitalen Messtechnik als sehr einfach zu messende Größe, da lediglich deren Schwingungen oder Impulse während einer geeigneten Zeit gezählt werden müssen, so dass diese Messgeräte dann als "Frequenzzähler" bezeichnet werden.

Die relative Fehlergrenze der Frequenzmessung ergibt sich unmittelbar aus der relativen Fehlergrenze der Zeitbegrenzung. Dazu werden Zeitdauern aus einer Anzahl von Periodendauern eines möglichst genauen Frequenzgenerators gebildet, etwa eines Schwingquarzes. Selbst als Konsumartikel haben Schwingquarze relative Fehlergrenzen in der Größenordnung 0,001 %.

Derartig kleine Fehlergrenzen sind sonst in der Messtechnik nur mit extremem Aufwand oder gar nicht erreichbar.

Reale, nicht diskrete Schwingungen bestehen immer aus mehreren überlagerten Schwingungen mit unterschiedlichen Frequenzen, da in der Natur keine perfekt sinusförmigen Schwingungen existieren. Das lässt sich unter anderem dadurch begründen, dass reale Schwingungen eine endliche Länge haben und somit durch einen Aus- und Einschwingvorgang begrenzt sind. Auch können schwingende Systeme von außen gestört werden, was mit dem Einbringen weiterer Frequenzen in die Schwingung verbunden ist. Eine mathematisch exakte Sinusschwingung ist hingegen zeitlich unbegrenzt und ungestört. Die Gesamtheit der in einer Schwingung vertretenen Frequenzen mit ihren jeweiligen Amplituden heißt "Frequenzspektrum". Die Bestimmung des Frequenzspektrums einer gegebenen Schwingung heißt "Fourieranalyse".

Auch bei weiteren Größen, die zwar die Dimension einer Rate, d. h. die SI-Einheit s, haben, aber keine Frequenz darstellen, etwa die radioaktive Zerfallsrate, ist die Einheit Hertz "nicht" zu verwenden.





</doc>
<doc id="1707" url="https://de.wikipedia.org/wiki?curid=1707" title="Franz Werfel">
Franz Werfel

In den 1920er und 1930er Jahren waren seine Bücher Bestseller. Seine Popularität beruht vor allem auf seinen erzählenden Werken und Theaterstücken, über die aber Werfel selbst seine Lyrik setzte. Mit seinem Roman "Verdi. Roman der Oper" (1924) wurde Werfel zu einem Protagonisten der Verdi-Renaissance in Deutschland. Besonders bekannt wurden sein zweibändiger historischer Roman "Die vierzig Tage des Musa Dagh" 1933/47 und "Das Lied von Bernadette" aus dem Jahr 1941.

Franz Werfel wurde am 10. September 1890 in Prag als Sohn des wohlhabenden Handschuhfabrikanten Rudolf Werfel und dessen Frau Albine, geb. Kussi, geboren. Die Familie gehörte dem deutsch-böhmischen Judentum an. Die Frömmigkeit seiner tschechischen Kinderfrau, der Besuch der Privatvolksschule der Piaristen und die barocke Katholizität seiner Heimatstadt prägten den jungen Werfel. Seine Reifeprüfung legte Werfel 1909 am Deutschen Gymnasium Stefansgasse in Prag ab. Schon während seiner Schulzeit veröffentlichte er Gedichte.

Mit den Schriftstellern Willy Haas, Max Brod und Franz Kafka sowie dem Schauspieler Ernst Deutsch und dem Literaturagenten Ernst Polak, seinem ehemaligen Mitschüler, war Werfel ein Leben lang befreundet.

Seine Schwester Marianne Rieser wurde als Schauspielerin bekannt.

1910 absolvierte Werfel ein Volontariat bei einer Hamburger Speditionsfirma. 1911 / 1912 leistete er als Einjährig-Freiwilliger Militärdienst auf dem Prager Hradschin. Von 1912 bis 1915 war er Lektor beim Kurt Wolff Verlag in Leipzig. Unter seiner Mitverantwortung erschien die expressionistische Schriftenreihe "Der jüngste Tag".

Werfel begegnete Rainer Maria Rilke und schloss Freundschaft mit Walter Hasenclever und Karl Kraus, mit dem er sich später überwarf. Er publizierte u. a. auch in der ungarischen deutschsprachigen Zeitung "Pester Lloyd".

1915 bis 1917 diente Werfel an der ostgalizischen Front. 1917 wurde er ins k.u.k. Kriegspressequartier in Wien versetzt.

Werfel lebte die folgenden zwei Jahrzehnte in Wien und schloss hier Freundschaft mit Alma Mahler, Witwe Gustav Mahlers und Ehefrau von Walter Gropius. Unter Almas Einfluss zog er sich weitgehend aus dem öffentlichen Leben zurück, ging aber oft auf Reisen, so z. B. nach Breitenstein am Semmering, Santa Margherita Ligure und nach Venedig. Während seiner zweiten Nahostreise Anfang 1930 traf er in einem Waisenhaus in Syrien Überlebende des Völkermordes an den Armeniern während des Ersten Weltkrieges. Diese Begegnung inspirierte ihn zu seinem Roman "Die vierzig Tage des Musa Dagh", in dem das Schicksal von etwa 5000 Armeniern geschildert wird, die sich vor der osmanischen Armee auf den Berg Musa Dağı (Mosesberg) geflüchtet hatten.

1918 brachte Alma, noch während ihrer Ehe mit Walter Gropius, Werfels mutmaßlichen Sohn Martin Carl Johannes zur Welt, der 1919 verstarb.

Am 7. August 1929 heiratete Werfel Alma Mahler, die 1920 von Gropius geschieden worden war. Friedrich Torberg beschrieb sie in "Die Erben der Tante Jolesch" als „Frau von gewaltigem Kunstverstand und Kunstinstinkt. Wenn sie von jemandes Talent überzeugt war, ließ sie für dessen Inhaber – mit einer oft an Brutalität grenzenden Energie – gar keinen anderen Weg mehr offen als den der Erfüllung.“

Die Preußische Akademie der Künste führte Werfel als Mitglied in der Sektion Dichtkunst. Auf Betreiben von Gottfried Benn wurde Werfel im Frühjahr 1933 ausgeschlossen.

Auf dem Höhepunkt seiner amerikanischen Bestsellererfolge sagte Franz Werfel zu seinem Freund Friedrich Torberg: „Wenn ich die Alma nicht getroffen hätte – ich hätte noch hundert Gedichte geschrieben und wäre selig verkommen …“ Laut Torberg hatte Werfel „oft und oft davon gesprochen, wie unvorstellbar ein Leben ohne Alma für ihn gewesen wäre“.

1935 starb seine an Kinderlähmung erkrankte Stieftochter Manon Gropius; Alban Berg komponierte für sie sein Konzert für Violine und Orchester "Dem Andenken eines Engels".

Nach dem „Anschluss“ Österreichs, 1938, ließ sich Werfel, der sich schon im Winter 1937/1938 mit seiner Frau im Ausland aufgehalten hatte und nach dem Anschluss nicht mehr zurückkehrte, mit Alma in Sanary-sur-Mer in Südfrankreich nieder, wo auch andere Emigranten lebten. 1940, als die Wehrmacht große Teile Frankreichs besetzte, fand er Zuflucht in Lourdes und Werfel gelobte, falls er gerettet würde, ein Buch über die heilige Bernadette zu schreiben.

Zu Fuß überquerte er mit seiner Frau Alma sowie Heinrich, Nelly und Golo Mann die Pyrenäen nach Spanien. Das Ehepaar erreichte von dort Portugal und emigrierte im Oktober 1940 an Bord des griechischen Dampfers "Nea Hellas" in die USA, nach Beverly Hills und Santa Barbara in Kalifornien.

Werfel erhielt 1941 die amerikanische Staatsbürgerschaft. 1943 wurde sein Roman "Das Lied von Bernadette" mit Jennifer Jones in der Titelrolle mit großem Erfolg verfilmt.

1943 verschlimmerte sich Werfels Angina pectoris, und er erlitt zwei Herzanfälle. Am 26. August 1945 starb Werfel im Alter von 54 Jahren an einem Herzinfarkt. Er wurde in Beverly Hills auf dem Rosedale Cemetery begraben.

1947 wurde ihm von Theodor Körner, damals Bürgermeister der Stadt Wien, später Bundespräsident, ein Ehrengrab auf dem Wiener Zentralfriedhof "reserviert", die Grabstelle in Beverly Hills zu einem Ehrengrab aufgewertet. Auf Basis einer vom Kulturamt der Stadt Wien und der Österreichischen Gesellschaft für Literatur 1974 gefassten Initiative wurden Werfels sterbliche Überreste 1975 nach Wien überführt und am 21. Juli 1975 auf dem Wiener Zentralfriedhof beigesetzt (Ehrengrab Gruppe 32 C, Nummer 39). Posthum erhielt Werfel im Jahr 2006 die armenische Staatsbürgerschaft verliehen.

Zu Ehren Werfels wurde sein Name nach seinem Tod verwendet:

Das Zentrum gegen Vertreibungen vergibt den Franz-Werfel-Menschenrechtspreis.

Die Österreichische Austauschdienst-Gesellschaft vergibt das Franz-Werfel-Stipendium für junge Universitätslehrende, die sich schwerpunktmäßig mit österreichischer Literatur beschäftigen.


Verzeichnis aller Werke siehe 














</doc>
<doc id="1709" url="https://de.wikipedia.org/wiki?curid=1709" title="Farkas Wolfgang Bolyai">
Farkas Wolfgang Bolyai

Farkas Bolyai (* 9. Februar 1775 in Bólya, Siebenbürgen; † 20. November 1856 in Marosvásárhely), deutsch Wolfgang Bolyai, war ein ungarischer Mathematiker.

Bolyai studierte an den Universitäten Klausenburg, Jena und Göttingen und wurde dort ein enger Freund von Carl Friedrich Gauß. Im Jahr 1802 wurde er Professor für Mathematik, Physik und Chemie am reformierten Kolleg in Marosvásárhely, wo er bis 1849 tätig war.

Er untersuchte, ob sich das Parallelenaxiom aus den anderen vier Axiomen der euklidischen Geometrie herleiten lässt. Hierbei fand er acht äquivalente Aussagen, die in seinem Hauptwerk "Tentamen" (1832) enthalten sind. Unter anderem bewies er die logische Äquivalenz der Aussage „Durch drei nicht auf einer Geraden liegende Punkte gibt es einen Kreis“ zum Parallelenaxiom.

Farkas Bolyai war der Vater des Mathematikers János Bolyai.





</doc>
<doc id="1710" url="https://de.wikipedia.org/wiki?curid=1710" title="Freiwirtschaft">
Freiwirtschaft

Die Freiwirtschaft ist ein Wirtschaftsmodell, das von Silvio Gesell, einem deutsch-argentinischen Kaufmann, Landwirt und volkswirtschaftlichen Autodidakten, im Wesentlichen zwischen 1891 und 1916 entwickelt worden ist. Anlass seiner drei ersten Schriften, die sich noch ausschließlich mit einer Geldreform beschäftigten, war eine argentinische Wirtschaftskrise um 1890. Anfang des 20. Jahrhunderts forderte Gesell neben einer Währungsreform auch eine Bodenreform. Im Titel seines 1916 erschienenen Hauptwerks heißt es deshalb: " Die natürliche Wirtschaftsordnung durch Freiland und Freigeld."

Unter "Freiland" wird in der Freiwirtschaft der friedlich in öffentliches Eigentum überführte Boden verstanden. Die Nutzung des "Freilandes" bleibt jedoch gegen Zahlung einer Pacht in privater oder genossenschaftlicher Regie. Aus der Pacht sollen zunächst die ehemaligen Eigentümer angemessen entschädigt werden. Ist das geschehen, fließt die Pacht – gewissermaßen als abgeschöpfte Bodenrente – der Allgemeinheit zu. 

Mit "Freigeld" bezeichnet die "Natürliche Wirtschaftsordnung" ein Zahlungs"mittel", das (wie die Ware) einem Wertverfall unterworfen ist und damit unter Umlaufzwang steht. Der Besitzer von "Freigeld" kann jedoch der Entwertung entgehen, wenn er die Hortung des Zahlungsmittels vermeidet, es also entweder gegen Ware eintauscht, verleiht oder seinem Bankkonto gutschreiben lässt. Man bezeichnet das "Feigeld", das nach Auffassung Gesells zu sinkenden Zinsen, eventuell sogar zu Negativzinsen führt, auch als "rostende Banknoten", "Fließ-" oder "Schwundgeld". Freiwirtschaftliche Geldexperimente, auf die sich die modernen Komplementärwährungen berufen, fanden Ende der 1920er / Anfang der 1930er Jahre in Deutschland, Österreich und in den Vereinigten Staaten statt. Auch gab es eine Reihe von Versuchen, die Gesellschen "Freiland"-Ideen umzusetzen. Träger dieser Experimente waren vor allem verschiedene genossenschaftlich organisierte Siedlungsprojekte. 

Ideengeschichtliche Beziehungen der "Natürlichen Wirtschaftsordnung" bestehen zur Physiokratie François Quesnays (1694–1774), zur sogenannten „Eigennutzethik“ Max Stirners (1806–1856), zum solidarischen Anarchismus Pierre-Joseph Proudhons (1809–1865) sowie zu den Bodenreformern des 19. und 20. Jahrhunderts. Unter Letzteren ist besonders Michael Flürscheim zu nennen.

Seit Beginn des 21. Jahrhunderts findet die "Natürliche Wirtschaftsordnung" neue Aufmerksamkeit. Gründe dafür sind unter anderem die Entstehung von Regionalwährungen, die Weltwirtschaftskrise ab 2007, die Eurokrise ab 2010 sowie die Nullzinspolitik der Europäischen Zentralbank.

Der Begriff "Freiwirtschaft" geht auf Silvio Gesell zurück. Er bezeichnete damit eine Art Vorstufe seiner "Natürlichen Wirtschaftsordnung". Das eigentliche Ziel war die Errichtung einer Physiokratie (="Naturherrschaft"). Damit verwiesen Gesell sowie seine frühen Anhänger Georg Blumenthal und Hans Timm auf François Quesnay, verbanden dessen Ideen jedoch zu Anfang des 20. Jahrhunderts mit anarchistischem und freiwirtschaftlichem Gedankengut. Anhänger Gesells bezeichneten sich in der ersten Phase der Freiwirtschaftsbewegung als "Physiokraten" (auch "Fysiokraten", "Fisiokraten"). Martin Hoffmann, ein junger Theologe und ebenfalls früher Anhänger Gesells, unterschied Mitte der 1920er Jahre mit den genannten Begriffen zwei Strömungen innerhalb der Gesellschen Bewegung: die bürgerlichen Freiwirtschaftler auf der einen und die proletarischen Physiokraten auf der anderen Seite. Seit den 1930er Jahren bezeichnen sich Vertreter der Gesellschen Ideen als "Freiwirtschaftler", "Freiwirte" und/oder "Gesellianer". Neuerdings taucht auch der Begriff Humanwirtschaft als Alternativbezeichnung auf.

Die Anfänge der Freiwirtschaftslehre liegen im letzten Jahrzehnt des 19. Jahrhunderts. Im Jahr 1891 veröffentlichte Silvio Gesell in Buenos Aires / Argentinien eine Broschüre mit dem Titel "Die Reformation im Münzwesen als Brücke zum sozialen Staat". Diese Schrift „war die Keimzelle einer eigenständigen sozialen Bewegung, die später den Namen Freiwirtschaftsbewegung bekam.“ In ihr spiegeln sich die Erfahrungen, die Gesell als Kaufmann im krisengeschüttelten Argentinien machte. Sein Nachdenken über die Ursachen von Wirtschaftskrisen führten ihn in Widerspruch zum Marxismus. Die menschliche Ausbeutung – so Gesell – habe ihre Ursachen nicht im Privateigentum von Produktionsmitteln, sondern in einem fehlerhaften Währungssystem. In seiner zweiten, ebenfalls 1891 erschienen Schrift "Nervus rerum" führte er diesen Gedanken weiter aus.

Neben einer radikalen Währungsreform forderte Gesell ab 1904 auch eine ebenso tiefgreifende Bodenreform. Angeregt dazu wurde er durch eine ganze Reihe von „gelehrten und ungelehrten Theoretikern [...], die der Bodenfrage als Brennpunkt des ganzen gesellschaftlichen Zusammenlebens ihre Aufmerksamkeit geschenkt“ hatten. Zu nennen ist hier Theodor Stamm (1822–1892), Mitglied der Sozialdemokratischen Arbeiterpartei, der als einer der Ersten in seiner 1871 erschienenen Schrift "Erlösung der darbenden Menschheit" die Forderung aufstellte, privates Grundeigentum durch ein „gerechtes Expropriationsverfahren“ zu beseitigen und 1874 (erfolglos) beantragte, sie in das Programm der Arbeiterpartei aufzunehmen.

Im Jahr 1890 erregte der Österreicher Theodor Hertzka (1845–1924) mit seinem in Romanform verfassten Buch "Freiland" große Resonanz. Es verwendet nicht nur erstmals den Begriff, sondern entwirft auch die Konzepte für Freihandel und Freigeld als grundlegende Prinzipien seines Wirtschaftsmodells. Die Ideen des Buches fanden viele Anhänger in Deutschland und Österreich und führten zu Siedlungsprojekten, Vereinen und politischen Strömungen in verschiedenen Ländern. Weitere zeitgenössische Vertreter von Bodenreformideen, durch die Gesell inspiriert wurde, waren der Amerikaner Henry George (1839–1897), der Badener Michael Flürscheim (1844–1912) und der Preuße Adolf Damaschke (1865–1935). Während George und Damaschke es beim privaten Bodeneigentum belassen und nur den Wertzuwachs zugunsten der Gesellschaft besteuern wollten, folgte Silvio Gesell der Forderung Flürscheims, das Eigentum an Grund und Boden in die Hände des Staates zu überführen, dabei aber die ehemaligen Privateigentümer zu entschädigen. Ein Schwager Michael Flürscheims, der Emder Hausarzt Max Sternberg, kam ebenfalls aus der Bodenreformbewegung und wandte sich nach 1922 der Freiwirtschaft zu. Er sorgte für die Ausbreitung der Gesellschen Lehren im Nordwesten Deutschlands.
Im Jahr 1909 trat der gelernte Tischler Georg Blumenthal in den damals kleinen Kreis der Gesellianer. Er kam aus der Gewerkschaftsbewegung und war während seiner Wanderjahre Anarchisten und unabhängigen Sozialisten begegnet. Die Arbeiterschule, die er später besuchte, machte ihn bekannt mit Benedikt Friedländer und über diesen mit Adolf Damaschke und dem Bund deutscher Bodenreformer. Dort hörte er von Gesell, der in dieser Zeit wieder in Argentinien lebte, las dessen Schriften und referierte über seine neu gewonnenen Erkenntnisse in anarchistischen sowie anarchosyndikalistischen Kreisen. Nur kurze Zeit später gründete er in Berlin den "Verein für physiokratische Politik", dem Gesell von Südamerika aus beitrat. 1910 folgte die Gründung des "Physiokratischen Verlages" und zwei Jahre später die der Zeitschrift "Der Physiokrat", deren erste Ausgabe im Mai 1912 erschien. 1913 erweiterte Blumenthal den von ihm gegründeten Verein zur "Physiokratischen Vereinigung". 

Ein weiterer für die Verbreitung der Gesellschen Lehre wichtige Multiplikator war der ehemalige römisch-katholische Landpfarrer und Damaschke-Anhänger Paulus Klüpfel (1876–1918). Er begegnete 1914 zunächst Blumenthal und dann Gesell, für den er bald als Privatsekretär arbeitete. Bereits ein Jahr später gründete Klüpfel den "Freiland-Freigeld-Bund" mit Sitz in Berlin-Steglitz. Anders als Gesell und Blumenthal war er, obwohl er sich von der Kirche getrennt hatte, stark von der christlichen Ethik geprägt. „In gewisser Hinsicht“, so Günter Bartsch, „war Klüpfel der freiwirtschaftliche Franz von Assisi“. Er setzte sich kritisch mit der "Physiokratischen Vereinigung" auseinander, gründete Mitte 1915 den "Freiland-Freigeld-Bund" (FFB) und bewirkte unter anderem, dass einige Gesellianer Blumenthals Vereinigung verließen und FFB-Mitglieder wurden. Klüpfel führte im Zusammenhang der Gesellschen Lehren unter anderem einen Briefwechsel mit Walther Rathenau. Einen vereinbarten Gesprächstermin mit Rathenau konnte er nicht mehr wahrnehmen; er starb am 29. Juli 1918 nach einer längeren Fastenzeit „für die Beendigung des Krieges“. 
Seine Programmschrift "Die natürliche Wirtschaftsordnung durch Freiland und Freigeld" (NWO), „das Standardwerk der Freiwirtschaftslehre“ gab Silvio Gesell 1916 im Selbstverlag heraus. Er hielt sich während des Ersten Weltkrieges in Les Hauts-Geneveys (Französische Schweiz) auf, wo er eine Landwirtschaft betrieb. Das Vorwort zur zweiten Auflage, die kurze Zeit später erschien, schrieb der bereits erwähnte Paulus Klüpfel. Zu Lebzeiten Gesells erschienen sechs Auflagen der NWO. Postum 1930 gab der "Stirn-Verlag Leipzig" eine siebente Auflage heraus, eine achte wurde während der Zeit des Dritten Reiches im schweizerischen "Genossenschaft-Verlag freiwirtschaftlicher Schriften" veröffentlicht und schließlich erschien im August 1949 eine neunte, von Karl Walker bearbeitete Nachkriegsauflage beim "Rudolf Zitzmann Verlag" in Nürnberg.

Im Jahre 1949 fand in der Schweiz eine Volksinitiative „zur Sicherstellung der Kaufkraft und Vollbeschäftigung (Freigeldinitiative)“ statt. Diese Initiative wurde durch die Volksabstimmung vom 15. April 1951 jedoch mit 87,6 % Nein-Stimmen abgelehnt, und erhielt weniger Ja-Stimmen als Unterschriften zum Einreichen der Volksinitiative gesammelt wurden. Angenommen wurde in der Volksabstimmung hingegen der Gegenentwurf der Bundesversammlung, mit 69,0 % und in 22 (19 6/2) Ständen. Thema der Abstimmung war allerdings nicht die Einführung einer Umlaufsicherung selbst, sondern die teilweise Aufgabe der Golddeckung, um die Währungsstabilität sicherzustellen. Mit dem Zusammenbruch des Bretton-Woods-Systems wurde diese Golddeckung später aufgehoben.

Hauptziel der Freiwirtschaft ist eine stabile, sozial gerechte Marktwirtschaft. In einem freiwirtschaftlich organisierten Wirtschaftssystem sollen Produktion und Konsum über den Markt vermittelt werden (Marktwirtschaft). Private oder öffentliche Unternehmen tragen das geschäftliche Risiko und erwirtschaften mit dem Kapitaleinsatz eine gewinnabhängige Rendite. Das Geldvermögen ist mit einem Negativzins belegt, wodurch es als „umlaufgesichert“ gilt. Damit soll die Umlaufgeschwindigkeit des Freigelds erhöht werden, wodurch genügend Mittel für Investitionen bereitstünden. Mit dem Freigeld würde sogar ein Absinken des allgemeinen Marktzinsniveaus auf 0 % (oder gar darunter) erlaubt. Gleichzeitig sollen mittels der Freilandreform die gegenleistungslosen Einkommen, die durch Landbesitz entstehen und sich systemisch nicht eliminieren lassen, an die Allgemeinheit abgeführt und vergesellschaftet werden.

Die Reformforderungen der vor allem in den 1920er Jahren im deutschsprachigen Raum großgewordenen Freiwirtschaftsbewegung werden oft mit „F.F.F.“ zusammengefasst: Freigeld, Freiland, Festwährung.

Hauptforderungen dieser Geldpolitik sind:

Silvio Gesell forderte die Abschaffung der bis dahin weltweit verbreiteten Golddeckung, weil nur eine begrenzte Menge Gold für den Geldkreislauf zur Verfügung stehe, während eine Wirtschaft beinahe unbegrenzt wachsen könne. Goldmangel könne deflationäre Zustände verursachen, Goldüberschuss könne destabilisierende Inflation zur Folge haben.

In der freiwirtschaftlichen Theorie ist das grundsätzliche Problem des Geldes das der fehlenden Lagerkosten. Alles in der Natur unterliege dem rhythmischen Wechsel von Werden und Vergehen, nur das Geld scheine der Vergänglichkeit alles Irdischen entzogen.

Zwei Ansätze gibt es, um dies zu verdeutlichen: Der Gesellsche Ansatz basiert auf der Analyse von Pierre-Joseph Proudhon, welche besagt, dass der Geldbesitzer gegenüber dem Besitzer bzw. Anbieter von Waren, Produkten, Dienstleistungen sowie Arbeitskraft einen entscheidenden Vorteil besitzen würde: Durch das Lagern von Waren, Produkten und Dienstleistungen entstünden laufende Kosten, bei Geld aber nicht. Dadurch würde der Geldbesitzer (die Nachfrage) einen systemischen Vorteil gegenüber dem Angebot erhalten, was dazu führen würde, dass Geld teurer verkauft würde als Waren. Diesen zusätzlichen Wert definierte Gesell als den „Urzins“, dessen Höhe er auf jährlich 4–5 Prozent schätzte.

Investitionen würden seiner Meinung nach nicht getätigt, läge der allgemeine Marktzins unter drei Prozent. Stattdessen würde es als liquides Mittel gehalten und gemäß Gesell zu Spekulationszwecken verwendet. Aus Perspektive der Anleger entstünde der Anlagenotstand, aus Perspektive der Unternehmer entstünde der Eindruck der Kapitalknappheit. Deflation und Spekulationsblasen wären erfahrungsgemäß die Folgen solcher Situationen.

Als Gegenmittel dazu bietet Gesell die Umlaufsicherung an, welche sicherstellen soll, dass weiterhin das mit negativem Zins belegte Geld investiert würde. Die Umlaufsicherung soll sich deshalb wie eine Steuer auf Liquidität auswirken, um die Umlaufgeschwindigkeit zu steuern. Dadurch soll – nach freiwirtschaftlicher Annahme – Vollbeschäftigung, vergleichbar mit einer permanenten Hochkonjunktur eintreten, wodurch die Löhne stiegen, während gleichzeitig die Preise real fallen würden.

Ein derartiges „Freigeld“ erfüllt nicht die Wertaufbewahrungsfunktion des Geldes. Manchmal wird auch der von Otto Heyn geprägte Begriff "Schwundgeld" genannt, der von Kritikern gelegentlich abwertend benutzt wird.

Ein weiterer Kritikpunkt der Freiwirtschaft an der bestehenden Verteilung der Produktionsgüter und Mittel ist das private Eigentum am Boden. Es verschafft seinen Eigentümern generell eine Bodenrente, die ihnen als leistungsloses Einkommen zufließt, sowohl bei Selbstnutzung der Grundstücke wie auch beim Verpachten und Vermieten. Nach freiwirtschaftlicher Auffassung soll die Bodenrente nicht in private Verfügung gelangen, sondern der Allgemeinheit zukommen, weil Boden ein Produkt der Natur und kein vom Menschen geschaffenes Gut ist, und der Wert, und damit die Bodenrente, nur durch die Allgemeinheit entsteht.

Durch eine Bodenreform will die Freiwirtschaft öffentliches Eigentum am Boden mit dessen privater Nutzung verbinden. Dazu fordert sie, allen Boden gegen volle Entschädigung seiner bisherigen Eigentümer in öffentliches Eigentum zu überführen, zum Beispiel in Eigentum der Gemeinden. Die bisherigen Eigentümer behalten dabei das Nutzungsrecht an ihren Grundstücken gegen Entrichtung einer regelmäßig wiederkehrenden Nutzungsabgabe an die öffentliche Hand. Boden in bis dahin öffentlichem Eigentum, der nicht ausdrücklich für öffentliche Zwecke gebraucht wird, soll an die Meistbietenden zur Nutzung vergeben werden.

Im Unterschied zum Boden dürfen und sollen darauf befindliche oder künftig zu errichtende Einrichtungen wie Gebäude oder gewerbliche Anlagen weiterhin Privateigentum sein und können privat genutzt werden, weil sie aus menschlicher Arbeit hervorgegangen sind. Die Rechte zum Vermieten oder Verpachten solcher Einrichtungen bleiben nach freiwirtschaftlicher Vorstellung gewährleistet, nicht jedoch das private Verpachten der Bodennutzung.

Wer Boden benötigt und nutzen möchte – sowohl Privatpersonen wie juristische Personen, sowohl bisherige Eigentümer wie neue Nutzer –, soll der zuständigen Bodenverwaltungsbehörde für die Nutzung des Bodens regelmäßig wiederkehrend eine Nutzungsabgabe entrichten, welche in ihrer Höhe ungefähr der Bodenrente entspricht. Die Höhe der Abgabe sollte je nach Begehrtheit des betreffenden Grundstücks bemessen sein und kann zum Beispiel in einer Versteigerung von Nutzungsrechten als Höchstgebot ermittelt werden. Damit wäre die Höhe der Nutzungsabgabe entsprechend marktwirtschaftlichen Prinzipien durch Angebot und Nachfrage bestimmt.

Diese Bodenreform bedingt die Schaffung einer rechtlichen Trennung zwischen Boden und darauf befindlichen Einrichtungen, wogegen das bestehende Recht nicht zwischen Boden und Bauten unterscheidet, sondern beides zusammen als "Grundstück" bezeichnet und rechtlich als Ganzes behandelt. Mit der neuen Ordnung wären Handel und Spekulation mit Boden nicht mehr möglich, nach wie vor jedoch Kauf und Verkauf der privaten Einrichtungen. Beim Verkauf eines Bauwerks müsste der Käufer vom Verkäufer auch den Bodennutzungsvertrag mit der betreffenden Behörde übernehmen.

Mit der Bodennutzungsabgabe wird die Bodenrente der Allgemeinheit zufließen. Gesell selbst plante, das durch die Vergesellschaftung der Bodenrente gewonnene Geld als "Mutterrente", eine Art hohes Kindergeld, an die Mütter zu verteilen, um diese wirtschaftlich unabhängig von Männern zu machen.

Eine Bodenreform nach freiwirtschaftlichem Modell wäre notwendig, um zu verhindern, dass Großgeldbesitzer, deren leistungslose Einkommen aus Zinsen nach der Einführung von Freigeld beschnitten sein würden, auf den Aufkauf von Grundstücken ausweichen. Dadurch würden die Grundstückspreise in unermessliche Höhen klettern und damit auch die Bodenrente in privater Hand, sehr zum Nachteil aller Übrigen, weil jeder Mensch zum Leben und Arbeiten auf Boden angewiesen ist.

Gesell bezieht sich dabei auf die Landreform-Theorie von Henry George. Diese sieht für Land eine Eigentumssteuer in einer Höhe vor, die die Grundrente angemessen neutralisiert. Gesell hält dabei aber Freiland für die systemisch überlegene Lösung.

Ein weiterer Aspekt, der zur Freiwirtschaft gehört, ist der Freihandel. Damit ist die Abschaffung nationaler Wirtschaftsgrenzen gemeint. Da Freihandel von praktisch allen Ökonomen gefordert und befürwortet wird, ist Freihandel der einzige Freiwirtschaftliche Aspekt, der sich soweit global durchzusetzen scheint. Organisationen wie die WTO üben international großen Druck auf Staaten aus, Zoll- und Importbarrieren zu reduzieren und Exportsubventionen abzuschaffen, in der mit der ursprünglichen Freiwirtschaftsbewegung übereinstimmenden Überzeugung, dass intensive Handelsbeziehungen und -verflechtungen einen langfristigen Frieden zwischen den Ländern der Welt sicherstellen.

Auf die Anregung von Theodor Hertzkas Buch "Freiland" gehen zahlreiche Konsum-, Produktiv- und Baugenossenschaften, sowie verschiedene Siedlungsprojekte zurück, darunter das Projekt Eden, der spätere Wohnort Gesells.

Zu den ersten Versuchen, die freiwirtschaftliche Freigeld-Theorie in der Praxis zu erproben, gehörte das sogenannte WÄRA-Experiment. Es wurde Ende der 1920er Jahre an vielen Orten Deutschlands durchgeführt. Initiiert wurde dieser Versuch von den Gesell-Anhängern Hans Timm und Helmut Rödiger im Jahr 1926.
Der Bergwerksingenieur Max Hebecker führte in Zusammenarbeit mit Hans Timm und Helmut Rödiger nach 1929 das "Schwanenkirchener Freigeldexperiment" durch. In der Folgezeit erlebte die Region um Schwanenkirchen einen in der Öffentlichkeit sehr beachteten wirtschaftlichen Aufschwung.

Über die Grenzen Europas hinaus erlangte das sogenannte "Wunder von Wörgl" Bekanntheit. Der Wörgler Bürgermeister Michael Unterguggenberger arbeitete im Zusammenhang der Weltwirtschaftskrise 1929 ein Nothilfe-Programm aus, das sich an der Gesellschen Freiwirtschaftslehre orientierte und dazu führte, dass umlaufgesichertes Freigeld als Komplementärwährung für die Region Wörgl ausgegeben wurde.

Auch in den Vereinigten Staaten kam es Anfang der 1930er Jahre an vielen Orten zur Durchführung eines freiwirtschaftlichen Geldexperiments. Unter der Bezeichnung "stamp scrip", gewann das Experiment so sehr an Popularität, dass der Nationalökonom Irving Fisher darüber eine wissenschaftliche Untersuchung veröffentlichte.

Als Fortsetzung dieser historischen Freigeldexperimente gilt das sogenannte Regiogeld, das heute an vielen Orten unter unterschiedlichen Bezeichnungen als Komplementärwährung in Umlauf ist.

Am 1. Mai 1933 kam es aufgrund einer Initiative Wilhelm Radeckes zur Gründung des Rolandbundes, eines „nationalen Bundes zur Sicherung der Markthoheit des Reiches“. Das neue politische System – so Radecke im "Sammelruf" des Rolandbundes – solle nicht gestürzt, sondern unterstützt werden, mehr noch: „der "Roland" wolle es vollenden“. Der "Rolandbund" hatte mindestens 1500 Mitglieder. Er wurde – wahrscheinlich auf Veranlassung von Hjalmar Schacht – nach dem sogenannten Röhm-Putsch am 30. Juni 1934 aufgelöst.

1950 entstand die Partei "Frei-Soziale Union (FSU)". Nach 1968 wurde für den Parteinamen die Zusatzbezeichnung "Demokratische Mitte" beschlossen. Ab 2001 nannte sie sich Humanwirtschaftspartei. Sie spielt aufgrund der geringen Mitgliederzahl gegenwärtig keine wesentliche Rolle in der deutschen Politik. Nach Ansicht des Bundeswahlausschusses fehlen inzwischen die Voraussetzungen für die Anerkennung der Parteieigenschaft. Im September 2010 ließ sich die Partei ins Vereinsregister eintragen.
Weitere Organisationen, die sich mit der Freiwirtschaft befassen und sich dafür einsetzen, sind:


Folgende private Bildungseinrichtungen versuchen durch Kurse, Tagungen und die Herausgabe von Zeitschriften freiwirtschaftliche Gedanken zu verbreiten:

Unter anderem auch freiwirtschaftliche Positionen vertreten:

Sammlungen freiwirtschaftlicher Literatur befinden sich unter anderem

John Maynard Keynes kam in seinem 1936 erschienenen Hauptwerk "Allgemeine Theorie der Beschäftigung, des Zinses und des Geldes" ("General Theory of Employment, Interest and Money") zu folgender Einschätzung der Gesellschen Lehre: „Ich glaube, daß die Zukunft mehr vom Geiste Gesells als von jenem von Marx lernen wird.“ Der US-amerikanische Ökonom Irving Fisher setzte sich, angeregt durch einen Modellversuch in Wörgl, dafür ein, „Freigeld“ in Form von „stamp scrips“ in den USA einzuführen.

Der spätere Wirtschaftsnobelpreisträger Maurice Allais skizzierte in seinem 1947 erschienenen Hauptwerk „Économie et Intérêt“ („Wirtschaft und Zins“) einen „socialisme concurrentiel“, oder „planisme concurrentiel“, der als zentrale Elemente die Verstaatlichung des Bodeneigentums und die „kontinuierliche Entwertung des umlaufenden Geldes“ enthält. Allais sah beides als Bedingungen für maximale wirtschaftliche Effizienz an. Er verwies dabei auf die Nähe seines Konzeptes zu dem von Gesell. Ähnlich wie dieser plädierte er für eine „systematische Organisation des Wettbewerbs“, die alle Vorrechte und Monopole beseitigt.

In den gängigen wirtschaftswissenschaftlichen Lehrbüchern und Zeitschriften wurde die Freiwirtschaft selten diskutiert. Jedoch hat Dieter Suhr, von 1975 bis 1990 Professor für Öffentliches Recht an der Universität Augsburg, in seinen Büchern grundsätzliche verfassungsrechtliche Kritik an der heutigen Geldordnung geübt und wesentliche, sowohl theoretische wie auch praktische Anstöße für eine Weiterentwicklung der Freiwirtschaft gegeben.

Bernd Senf, Professor für Volkswirtschaftslehre an der Fachhochschule für Wirtschaft Berlin, präsentierte in seinem erstmals 2001 veröffentlichten Buch "Die blinden Flecken der Ökonomie" die Freiwirtschaftslehre als eine von sieben historisch bedeutsamen Schulen der Volkswirtschaftslehre (neben Physiokratie, klassischer Ökonomie, Marxismus, Neoklassik, Keynesianismus und Monetarismus).

2003 promovierte Roland Wirth bei dem Wirtschaftsethiker Peter Ulrich an der Universität St. Gallen mit einer Dissertation zum Thema "Marktwirtschaft ohne Kapitalismus. Eine Neubewertung der Freiwirtschaftslehre aus wirtschaftsethischer Sicht". Nach Rezensionen von Jost W. Kramer, Professor für Allgemeine Betriebswirtschaftslehre an der Hochschule Wismar, und von Dr. Stephan Märkt, Bologna-Berater der HRK an der Leuphana Universität Lüneburg, resümierte der Berliner Professor Hermann Kendel, Wirths Doktorarbeit bringe „die Ideen von Silvio Gesell wieder in die allgemeine Fachdiskussion zurück.“

Mit Beginn der Weltwirtschaftskrise ab 2007 wurde die Idee des umlaufgesicherten Geldes an verschiedenen Stellen erneut aufgegriffen. So verwiesen Gregory Mankiw oder Willem Buiter auf Silvio Gesell.

EZB-Direktoriumsmitglied Benoît Cœuré hielt am 9. März 2014 vor der Geldmarkt-Kontaktgruppe der EZB die Rede "Life below zero: Learning about negative interest rates" (Leben unter null: Über negative Zinsen lernen). Darin erklärte er, dass die Idee negativer Zinsen oder der „Besteuerung des Geldes“ auf das 19. Jahrhundert, auf Silvio Gesell zurückgehe, den deutschen Begründer der Freiwirtschaft, der von Irving Fisher unterstützt und von John Maynard Keynes „ein seltsamer, zu Unrecht übersehener Prophet“ genannt wurde.

Auch die griechische Finanzkrise 2015 veranlasste Fachleute, darunter der britische Wirtschaftshistoriker und Keynes-Biograph Robert Skidelsky, der US-Wirtschaftsprofessor Miles Kimball, der britische Journalist und Universitätsdozent George Monbiot und die Capital International Group, auf Gesells Freigeld als Lösungsmöglichkeit hinzuweisen. Stanley Fischer, Vizepräsident der US-amerikanischen Zentralbank FED, erwähnte in seiner Rede "Monetary Policy, Financial Stability, and the Zero Lower Bound" am 3. Januar 2016 Silvio Gesell als einen der Vordenker negativer Zinsen.

Die liberale Gesellschaftsordnung beruht größtenteils auf dem Eigentumsrecht. Durch die Geldumlaufsicherungsgebühr werde das Verfügungsrecht des Geldbesitzers, das nach liberaler Auffassung auch das Recht auf Geldhortung umfasst, eingeschränkt. Der Zins entspricht nach neoklassischer Auffassung (Eugen von Böhm-Bawerk) der Zeitpräferenzrate des Geldbesitzers und somit auch den menschlichen Bedürfnissen. Auch die Zinskosten entsprechen nach neoklassischer Auffassung den gesellschaftlichen Präferenzen. Jeder Konsument habe die freie Wahl zwischen Zahlung der Zinskosten oder Konsumverzicht.

Die Umlaufsicherungsgebühr für Bargeld bildet die Kernidee der freiwirtschaftlichen Geldreform.
Kritisiert wird unter anderem die freiwirtschaftliche Prämisse, dass Geld durch die Umlaufsicherung auf den Konsum- oder Kreditmarkt gedrängt würde. Das umlaufgesicherte Geld würde von den Bürgern „stattdessen“ durch Devisen und Edelmetalle substituiert, welche keinem Wertverfall unterliegen.

Das Greshamsche Gesetz beschreibt den Effekt, dass „schlechtes Geld gutes Geld im Umlauf verdrängt“. Wenn ein gesättigter Markt vorliegt, wird jeder Konsument, der vor der Wahl steht, Ausgaben mit umlaufgesichertem Geld oder anderem Geld zu begleichen, die Zahlung mit umlaufgesichertem Geld vornehmen. Das andere Geld wird dadurch "das Land verlassen oder durch Hortung aus dem Umlauf verschwinden".

Laut der Quantitätsgleichung formula_1 erhöht eine Umlaufsicherung die Umlaufgeschwindigkeit formula_2. Dies hat prinzipiell denselben Effekt wie die Erhöhung der Geldmenge formula_3.

Nicht berücksichtigt wird allerdings, dass das Handelsvolumen formula_4 durch die erhöhte Güternachfrage in der Freiwirtschaft auch steigt.

Auch kann eine einfache Erhöhung der Geldmenge formula_3 zu einer gleichzeitigen Senkung der Umlaufgeschwindigkeit führen, wenn Geld von der Geldbasis formula_6 und formula_7, welches eine hohe Umlaufgeschwindigkeit formula_8 aufweist, zurückgehalten oder angespart und dadurch zur Geldmenge formula_9 oder gar formula_10 wird, welche geringere Umlaufgeschwindigkeiten formula_11 aufweisen. Diese Verlagerung auf Geldmengen mit geringerer (bzw. keiner) Umlaufgeschwindigkeit entsteht, wenn Menschen
Den beiden ersten Effekten wird beim Freigeld durch die Umlaufsicherung entgegengewirkt, denn hier entsteht die Erhöhung der Umlaufgeschwindigkeit durch die Verlagerung der lang- bis mittelfristig angelegten Geldmengen formula_10 und formula_9 auf die rasch zirkulierenden Geldmengen formula_7 und formula_6.

Marxisten wie der Ökonom Elmar Altvater bezeichnen die Freiwirtschaft als „sozialdarwinistisches Konzept“, und lehnen sie deshalb ab.

Werner Onken legt in seiner Antwort auf diesen Vorwurf dar, dass die Evolutionslehre damals neu, und vor allem auch im Kontrast zu den Dogmen der Kirchen, – auch in der Arbeiterbewegung – „en vogue“ war, und Gesell keineswegs einen „Kampf des Stärkeren gegen den Schwächeren“ vertreten hat, sondern dafür eintrat, „mit einer gerechten Rahmenordnung des Wirtschaftens Voraussetzungen für eine gerechte Verteilung der Einkommen und Vermögen [zu] schaffen“.

Der Vorwurf Altvaters, dass viele Anhänger Gesells mit den Nationalsozialisten paktiert und ihre Nähe gesucht haben, „lässt sich leider nicht bestreiten: Im historischen Kontext erscheint sie jedoch in einem differenzierteren Licht.“ Gesells Anhänger hätten Politikern der demokratischen Parteien und den Gewerkschaften immer wieder Vorschläge zur Stabilisierung der wirtschaftlichen Konjunktur unterbreitet. Sie seien jedoch nicht beachtet und ignoriert worden.




Ein bis zum Jahr 1986 fast vollständiges Verzeichnis freiwirtschaftlicher Schriften bietet der von der "Freiwirtschaftliche Bibliothek" herausgegebene und von Werner Onken redigierte "Katalog der Bücher, Broschüren und Zeitschriften mit zahlreichen Leseproben und dokumentarischen Abbildungen". Die folgenden ausgewählten Literaturangaben sind innerhalb der verschiedenen Unterabschnitte chronologisch geordnet.






</doc>
<doc id="1715" url="https://de.wikipedia.org/wiki?curid=1715" title="Forderung">
Forderung

Unter Forderung wird im Allgemeinen eine Aufforderung, ein Befehl, eine Anweisung, die Einforderung eines Rechtes oder das Geltendmachen eines Anspruches verstanden.

Forderungen sind als Vermögensgegenstand Bestandteil der Aktiva einer Bilanz und können durch eine Kreditversicherung abgesichert werden. Der Gesetzgeber hat den Forderungen eine so große Bedeutung beigemessen, dass er ihnen aus Gründen der Bilanzklarheit eine eigene Bilanzposition zugewiesen hat. Sie sind gemäß Abs. 2 B II HGB als "Forderungen aus Lieferungen und Leistungen", "Forderungen gegen verbundene Unternehmen", "Forderungen gegen Unternehmen mit einem Beteiligungsverhältnis" oder "sonstige Vermögensgegenstände" im Umlaufvermögen des Jahresabschlusses auszuweisen. Forderungen entstehen insbesondere durch eine Lieferung oder Leistung, bei der der Gefahrenübergang auf den Kunden erfolgt ist und dieser nicht unmittelbar bezahlt hat. Grund für die nicht sofortige Bezahlung kann ein vereinbarter Zielverkauf, aber auch ein Zahlungsverzug sein. Diese Forderungen bilden bei den meisten Unternehmen den wichtigsten oder wesentlichen Vermögensgegenstand des Umlaufvermögens in der Bilanz. Ein Forderungsmanagement soll dafür sorgen, dass die unbezahlten Lieferungen im Hinblick auf die Bonität der Abnehmer und die Fälligkeit überwacht werden. Dieses Debitorenrisiko besteht in der Gefahr, dass die Abnehmer zu spät, nicht oder nicht vollständig bezahlen oder gar insolvent werden. Es kann gemindert oder ausgeschaltet werden durch die Lieferung unter Eigentumsvorbehalt. Dieser ist eine originäre Kreditsicherheit, die der Lieferant mit dem Abnehmer vereinbart und bei Nichtbezahlung der Forderung dazu führt, dass der Lieferant die gelieferten Waren vom Abnehmer herausverlangen kann. Verwirklicht sich das Debitorenrisiko, verwandeln sich die intakten Forderungen in zweifelhafte Forderungen.

In der deutschen Rechtswissenschaft bezeichnet der Begriff „Forderung“ einen schuldrechtlichen Anspruch, der in den § ff. BGB geregelt ist. Bisweilen wird auch das Synonym „Schuldverhältnis im engeren Sinne“ benutzt. Für die Forderung spezifisch ist, dass sie auf einem Schuldverhältnis (im weiteren Sinne) beruht. Dies unterscheidet sie von den dinglichen Ansprüchen, die auf einem absoluten Herrschaftsrecht beruhen. Forderungen gründen sich auf Personenbeziehungen, dingliche Ansprüche sind hingegen sachbezogen.

So handelt es sich etwa bei einem Anspruch des Eigentümers auf Herausgabe seiner Sache gegen den Dieb um einen sachenrechtlichen Anspruch, der auf der Rechtsbeziehung des Eigentümers zu dieser Sache beruht. Forderungen sind dagegen beispielsweise der Anspruch des Verkäufers auf Kaufpreiszahlung gegen den Käufer aus dem Kaufvertrag oder der Anspruch des Unfallopfers auf Schadensersatzzahlung gegen den Verursacher, denn sie basieren auf einer Rechtsverbindung zwischen den beteiligten Personen, die entweder von diesen gewollt (Vertrag) oder gesetzlich angeordnet (gesetzliches Schuldverhältnis) sein kann.

Auch öffentlich-rechtliche Beziehungen können Gegenstand von Forderungen werden, z. B. Steuerforderungen, Bußgelder, Rückforderungen zu Unrecht erhaltener Sozialleistungen.

Die Forderung ist ein Zahlungs- oder sonstiger Leistungsanspruch gegen einen Forderungsschuldner, der sich aus Gesetz oder aus einem Vertrag ergibt (§ 241 BGB). Eine Forderung aus einem Vertrag ist zu bilanzieren, wenn an den Kunden geleistet und die Gegenleistung noch nicht erfüllt wurde. Forderungen sind ein Aktivposten der Bilanz und gehören zum Umlaufvermögen (nach HGB) oder zu den kurzfristigen Vermögenswerten (nach IAS/IFRS). Zu den Forderungen innerhalb der kurzfristigen Vermögenswerte zählen:


Grundlagen für die Bilanzierung von Forderungen im IFRS sind IAS 39 (Finanzinstrumente: Ansatz und Bewertung), IAS 32 (Finanzinstrumente: Darstellung), IFRS 7 (Finanzinstrumente: Angaben), sowie F49a, F53 – F59, F89 – 90.

Unterschiede zur gesetzlichen Regelung auf nationaler Ebene lassen sich insbesondere bei der Bewertung von Forderungen feststellen. Nach HGB entfällt die nach den IFRS bekannte Möglichkeit, Forderungen und Ausleihungen zum Fair Value zu bewerten. Forderungen und Ausleihungen werden nach HGB grundsätzlich zum Rückzahlungsbetrag bilanziert, sofern nicht aufgrund des Vorsichtsprinzips auf den niedrigeren beizulegenden Wert abzuwerten ist.

Eine Forderung ist jeder vertragliche Anspruch, Zahlungsmittel oder andere finanzielle Vermögenswerte zu erhalten. Forderungen sind finanzielle Vermögenswerte und zählen zu den Finanzinstrumenten.

Ein Vermögenswert ist eine Ressource, die auf Grund von Ereignissen in der Vergangenheit in der Verfügungsmacht des Unternehmens steht, und von der erwartet wird, dass dem Unternehmen aus ihr künftiger wirtschaftlicher Nutzen zufließt.

Ein Finanzinstrument ist ein Vertrag, der gleichzeitig bei dem einen Unternehmen zu einem finanziellen Vermögenswert und bei dem anderen zu einer finanziellen Verbindlichkeit oder einem Eigenkapitalinstrument führt. Gängige Beispiele für Finanzinstrumente sind unter anderem Wertpapiere und Forderungen.

Fair Value ist der Wert, zu dem ein Vermögenswert zwischen sachverständigen, vertragswilligen und voneinander unabhängigen Geschäftspartnern getauscht oder eine Verpflichtung beglichen werden kann. Er wird nach folgender Hierarchie bestimmt:

Ein Vermögenswert ist als kurzfristig einzustufen, wenn er mindestens eines der nachfolgenden Kriterien erfüllt:

Alle anderen Vermögenswerte sind als langfristig einzustufen.

Forderungen aus Lieferungen und Leistungen sind gemäß der obigen Abgrenzung erst dann zu aktivieren, wenn der Umsatz realisiert wurde, das heißt, das Produkt muss ausgeliefert oder die Dienstleistung gegenüber dem Kunden erbracht worden sein. Bei Lieferungen ist grundsätzlich erst dann eine Forderung zu aktivieren, wenn das Risiko des Untergangs auf den Käufer übergegangen ist.

Das Ausbuchen aus der Bilanz erfolgt, wenn das Unternehmen das Recht auf die Vorteile verliert, die im Vertrag festgelegt sind, wenn die Rechte auslaufen oder wenn das Unternehmen die Verfügungsmacht über die vertraglichen Rechte des Finanzinstruments verliert. Durch die Zuordnung aller Finanzinstrumente in einer der folgenden Kategorien im Rahmen der erstmaligen Erfassung wird bestimmt, wie die betreffenden finanziellen Vermögenswerte in der Bilanz anzusetzen und zu bewerten sind.

Bei erstmaliger Erfassung eines finanziellen Vermögenswertes ist dieser mit dem beizulegenden Zeitwert (fair value) unter Einschluss der Transaktionskosten zu bewerten.
Boni (trade discounts), Skonti (cash discounts) und Einzelwertberichtigungen sind vom beizulegenden Zeitwert abzuziehen. Wertberichtigungen sind immer aktivisch abzusetzen. Die Folgebewertung geschieht zu fortgeführten Anschaffungskosten (amortized costs).

Aus Wesentlichkeitsgesichtspunkten sind Forderungen nicht abzuzinsen, wenn sie innerhalb eines Jahres fällig werden. Bei Forderungen, die nicht innerhalb eines Jahres fällig werden, sind die fortgeführten Anschaffungskosten mit Hilfe der Effektivzinsmethode zu ermitteln, sofern mit dem Kunden keine gesonderte Vereinbarung über die Berechnung von marktüblichen Zinsen getroffen wurde. Liegt eine getroffene Zinsvereinbarung unter dem marktüblichen Zinssatz, so ist für die Ermittlung des Abzinsungsbetrages die Differenz zwischen dem marktüblichen und dem mit dem Kunden vereinbarten Zinssatz zu Grunde zu legen.

Nach IFRS sind Forderungen einzeln zu bewerten, die Bildung von Pauschalwertberichtigungen zur Abdeckung des allgemeinen Kreditrisikos ist damit unzulässig. Zulässig sind jedoch so genannte pauschalierte Einzelwertberichtigungen, wobei individuelle Einzelwertberichtigungen grundsätzlich Vorrang haben. Gemäß IAS 39, AG 87 sind pauschalierte Einzelwertberichtigungen auf Basis einer Gruppierung der Forderungen nach Maßgabe der Bonitätseinschätzungen der jeweiligen Schuldner vorzunehmen. Sobald spezifische Informationen über einen individuellen Einzelwertberichtigungsbedarf einer Forderung innerhalb einer gebildeten Gruppe von Forderungen vorliegen, muss diese Forderung aus der Gruppe ausgesondert und die entsprechende Wertminderung als individuelle Einzelwertberichtigung ausgewiesen werden. Eine Wertberichtigung auf Forderungen ist zwingend vorgeschrieben, wenn der Betrag der Wertberichtigung hinreichend genau ermittelt werden kann und das Ereignis, das die Abwertung verursacht, wahrscheinlich eintreten wird.

Einzelwertberichtigungen sind wegen bestrittener Forderungen (Mangel oder angeblicher Mangel auf Seiten des Lieferanten) und wegen Delkredere (bekannte oder vermutete Bonitätsrisiken auf Seiten des Kunden) vorzunehmen.

Eine Forderung ist aus der Bilanz auszubuchen, wenn das Unternehmen das Recht auf die Vorteile verliert, die im Vertrag festgelegt sind, wenn die Rechte auslaufen oder wenn das Unternehmen die Verfügungsmacht über die vertraglichen Rechte des Finanzinstruments verliert. Veräußerungsgewinne und -verluste sind erfolgswirksam anzusetzen. Der Veräußerungserfolg ist die Differenz zwischen dem Erlös und dem Buchwert des Finanzinstruments.

Eine Aufrechnung von Forderungen und Verbindlichkeiten ist auch bei Identität von Schuldner und Gläubiger und annähernd gleicher Fälligkeit nicht zulässig.

Ein vollständiger Abschluss beinhaltet unter anderem eine Bilanz und eine Gewinn- und Verlustrechnung.

In der Bilanz sind unter anderem anzugeben:

Kurzfristige und langfristige Vermögenswerte sind als getrennte Gliederungsgruppen in der Bilanz darzustellen, sofern eine Darstellung nach Liquidität nicht zuverlässig und relevanter ist.

Die Angabepflichten gemäß IFRS 7 umfassen auf Ebene der Einzelklassen ähnlicher Finanzinstrumente Informationen über die Bedeutung der Finanzinstrumente und Informationen über Art und Ausmaß der mit den Finanzinstrumenten verbundenen Risiken.

Im Einzelnen sind in der Bilanz und Anhang anzugeben:

Reklassifizierungen (IFRS 7.12) müssen ebenso wie Ausbuchungen (IFRS 7.13) offengelegt werden.

Folgende Posten sind in der Gewinn- und Verlustrechnung auszuweisen:



</doc>
<doc id="1716" url="https://de.wikipedia.org/wiki?curid=1716" title="Flöhe">
Flöhe

Flöhe (Siphonaptera) bilden eine Ordnung in der Klasse der Insekten und gehören zur Gruppe der holometabolen Insekten. Von den etwa 1600 Arten der Flöhe sind etwa 80 Arten in Mitteleuropa nachgewiesen. Die Tiere zählen zu den Parasiten. Sie erreichen eine Länge von 1 bis 4 Millimetern. Die größte Art ist der Maulwurfsfloh ("Hystrichopsylla talpae" Curtis, 1826), der auf dem Europäischen Maulwurf ("Talpa europaea" Linnaeus, 1758) parasitiert.

Flöhe besitzen keine Flügel. Dies erklärt den zweiten Teil des wissenschaftlichen Namens, der sich aus altgriechisch "síphōn" ‚Röhre, Heber, Spritze‘ sowie "ápteros" ‚ungeflügelt‘ zusammensetzt. Stattdessen haben sie aber zur schnellen Fortbewegung kräftige Hinterbeine, die ihnen weite Sprünge von fast einem Meter erlauben. Die Schnellbewegung der Sprungbeine gilt als eine der schnellsten Bewegungen im gesamten Tierreich. Um diese zu erreichen, würde die Kontraktionsgeschwindigkeit der Muskeln nicht ausreichen. Daher besitzen Flöhe in ihren Beinen sogenannte Resilinpolster: Resilin ist ein elastisches Protein, welches vor dem Sprung wie ein Bogen gespannt werden kann und dem Floh auf diese Weise sehr weite und hohe Sprünge ermöglicht. Der Sprung eines Flohs ist ungerichtet.

Charakteristisch für Flöhe ist ihr seitlich abgeplatteter Körper, der es ihnen erleichtert, sich im Fell zwischen den Haaren fortzubewegen. Flöhe besitzen keine Facettenaugen, sondern ein Paar einlinsige Punktaugen. Die Mundwerkzeuge sind zu einem kombinierten Stech- und Saugrüssel umfunktioniert (daher der erste Teil des wissenschaftlichen Namens dieser Ordnung: siphon, griech. „Rohr, Röhre“). Beim Saugen führt der Floh einen regelrechten Kopfstand aus.

Flöhe besitzen einen sehr harten Chitinpanzer, der es sehr schwer macht, sie zu zerdrücken. Ein Zerreiben ist hingegen eher möglich, man kann sie aber mit dem Fingernagel zerknacken. Am Körper und an den Beinen haben sie nach hinten gerichtete Borsten und Zahnkämme (Ctenidien), die es – zusammen mit den Krallen an den Beinen – schwer machen, Flöhe aus den Haaren zu kämmen.

Flöhe sind Parasiten, die von warmblütigen Tieren leben, wobei 94 Prozent aller Arten auf Säugetieren parasitieren und etwa 6 Prozent auf Vögeln. Flöhe haben zwar Vorlieben für bestimmte Wirtstiere, sind aber nicht ausschließlich auf diese angewiesen. Vielmehr scheinen Flöhe eine größere Bindung zu ihren Nestern (Tiernester, aber auch Polster, s. u.) zu haben als zu ihren Wirten.

Somit wird der Mensch auch von anderen Floharten als dem Menschenfloh ("Pulex irritans" Linnaeus, 1758) befallen. Haustierbesitzer sollten auch um ihrer eigenen Gesundheit willen darauf achten, dass ihre Tiere frei von Flöhen sind.

Flöhe werden durch das Kohlenstoffdioxid der Atemluft, Wärme und Bewegung von Tieren angelockt. Nach einer üppigen Mahlzeit kommen Flöhe bis zu zwei Monate ohne Nahrung aus.

In Wohnungen fühlen sich Flöhe in Teppichen und Polstermöbeln wohl, wo sie auch die meiste Zeit verbringen. Nur zum Blutsaugen suchen sie den Menschen auf.

Ein Floh kann maximal 1½ Jahre alt werden. Die Lebensdauer des ausgewachsenen Rattenflohs beträgt fünf bis sechs Wochen. Die Larvenentwicklung dauert je nach Temperatur acht Tage (warme Zimmertemperatur) bis zu einem Jahr. Es gibt drei Larvenstadien und ein ruhendes Puppenstadium.

Nach ihrem Verhalten werden die Flöhe in zwei Gruppen eingeteilt: Nestflöhe und Pelzflöhe. Die Nestflöhe bleiben stationär in der Nähe des Schlafplatzes ihres Wirtes in dunkler und trockener Umgebung. Sie kommen des Nachts aus ihrem Versteck, befallen den Wirt und verschwinden wieder im Versteck, wo sie ihre Eier legen. Sie sind extrem lichtscheu und lieben keine Ortsveränderung. Man findet sie daher nur sehr selten auf Kleidung, die in Gebrauch ist. Kennzeichnend ist, dass der Wirt wahllos über den ganzen Körper von Bissen befallen ist. Bekanntester Vertreter ist der Menschenfloh, der sich tagsüber an den dunklen Stellen des Bettes aufhält. Die Pelzflöhe hingegen bleiben auf ihrem Wirt sitzen und wandern mit ihm mit. Sie vertragen daher Licht ohne weiteres sehr gut, springen auch Menschen an und setzen sich in deren Kleidung fest. Aber Menschenblut nehmen sie nur ausnahmsweise, wenn keine Ratten mehr zur Verfügung stehen.

Die Larven der Flöhe ernähren sich meist von zerfallenden organischen Stoffen in der Nähe ihrer späteren Wirte. Zur Nahrung kann deshalb auch der Kot der erwachsenen Flöhe zählen.

Die Fortpflanzung setzt einen bestimmten Temperaturbereich voraus. Fällt die Temperatur auf 5 °C und darunter, wird die Fortpflanzung eingestellt, bereits unter 10 °C nimmt sie signifikant ab. Das bedeutet aber nicht, dass sich Flöhe in den gemäßigten und nördlichen Breiten im Winter nicht vermehren. Sie pflanzen sich dort in Wohnungen und Ställen das ganze Jahr über fort.

Die Männchen besitzen spezielle Klammerorgane, die sie bei der Kopulation einsetzen. Das Weibchen legt die relativ großen Eier in Eipaketen zu etwa 10 Stück ab und muss zwischendurch immer wieder neue Nahrung zu sich nehmen. Während ihres Lebens können Weibchen etwa 400 Eier legen. Die Larven besitzen weder Beine noch Augen und sind mit Borsten bedeckt. Die Entwicklung verläuft im Nest des Wirtes und dauert etwa zwei bis vier Wochen. Dabei ernähren sich die Larven von den Ausscheidungen der erwachsenen Tiere. Da es sich hierbei um eingetrocknetes Blut handelt, lässt sich anhand dieses Flohkotes ein Befall effektiv nachweisen. Hierzu werden die mittels eines Flohkammes ausgekämmten Bestandteile auf eine weiße saugfähige Unterlage (Zellstoff, Kissenbezug oder Ähnliches) gegeben und leicht befeuchtet. Durch seinen Blutgehalt wischt die Ausscheidung des Parasiten rötlich aus.

Weibliche Flöhe haben eine Samentasche, in die das Männchen sein Ejakulat mit Druck einspritzt. Dort bleibt es so lange gespeichert, bis das Weibchen geeignete Bedingungen für die Eiablage vorfindet. Erst dann fließt die Samenflüssigkeit durch Kapillarwirkung aus der Samentasche.

Springt ein Vertreter dieser Arten auf den Menschen über, so verursacht er dort durch seinen Stich eine kleine Wunde mit einem mehr oder minder intensiven und großflächigen Juckreiz, welcher in der Regel dazu führt, dass die Menschen nachts unbemerkt daran kratzen. Das Ergebnis sind offene Stellen in der Haut, die sich auch entzünden können. Charakteristisch ist, dass die Stiche fast immer in Reihen liegen, weil die Flöhe leicht irritiert werden bzw. Probestiche vornehmen.

Durch Flohstiche können Bakterien (z. B. Streptokokken und Staphylokokken) übertragen werden, welche möglicherweise verstärkt durch das Kratzen bei Juckreiz zu Entzündungen an der Stichstelle führen.<ref name="Parasiten-Flöhe/Flöhe als Krankheitsüberträger">Parasiten-Floh</ref>

Der Menschenfloh ("Pulex irritans") kann in seltenen Fällen durch seinen Stich/Biss die Pest auf mechanischem Wege übertragen. Speziell der Rattenfloh ("Xenopsylla cheopis"), der Pestfloh, ist durch seinen Stich/Biss schon lange als biologischer Überträger der Pest bekannt (siehe auch Infektionsweg). Hunde- und Katzenflöhe bleiben in der Regel auf ihren üblichen Wirten, doch bei engerem Zusammenleben gehen sie auch gerne auf den Menschen über.

Von tropischen Floharten können die Erreger von Pest, Tularämie und murinem bzw. endemischem Fleckfieber (Erreger: Bakterium "Rickettsia mooseri", Vektor: in erster Linie Ratten- und flohähnliche Mäuseflöhe ("Leptinus testaceus") Mueller) übertragen werden. Eine direkte Übertragung von Mensch zu Mensch ist bei diesen Flöhen nicht möglich.

Gegen adulte Flöhe bei Tieren gibt es zahlreiche Wirkstoffe, die entweder zur äußeren (Spray, Spot-on, Puder, Halsband) oder zur inneren Anwendung bestimmt sind. Äußerlich werden Insektizide wie Fipronil, Imidacloprid, Metaflumizon, Nitenpyram, Selamectin angewendet. Zur inneren Anwendung in Tablettenform sind Wirkstoffe wie Fluralaner oder Spinosad geeignet. Zur Verhinderung der Larvenentwicklung eignen sich Chitininhibitoren wie Lufenuron.

Darüber hinaus sollte eine Behandlung der Umgebung des Tieres, vor allem des Liegeplatzes und bevorzugter Aufenthaltsorte, erfolgen, da sich Flöhe nicht permanent auf dem Tier aufhalten und die Wirksamkeit der am Tier angewendeten Wirkstoffe auf diesen Teil der Flohpopulation begrenzt ist. Die Umgebungsbehandlung erfolgt durch regelmäßiges Wischen, Staubsaugen und Waschen von Decken und Teppichen, unterstützt durch eine chemische Flohbekämpfung mit Chlorpyrifos, Permethrin, Propoxur, Fenoxycarb, Methopren bzw. Kombinationen dieser Wirkstoffe.

Noch in der Mitte des 20. Jahrhunderts waren Flohzirkusse eine große Attraktion. Gewöhnlich wurden Menschenflöhe ("Pulex irritans") als „Artisten“ eingesetzt. Weibliche Tiere wurden bevorzugt, da sie größer und sowohl für das Publikum als auch den Dompteur besser sichtbar sind. Der Marburger Gelehrte Otto Philipp Zaunschliffer schrieb humoristische Werke über Flöhe. Ebenso hat der Orientalist Enno Littmann durch seine kleine Sammlung von Geschichten und Liedern über den Floh (Vom morgenländischen Floh. Dichtung und Wahrheit über den Floh bei Hebräern, Syriern, Arabern, Abessiniern und Türken, Leipzig 1925) dem Tier eine amüsante Schrift gewidmet.

Die in Deutschland vorkommenden Arten der Flöhe werden sechs Familien in vier Überfamilien zugeordnet:

Flöhe


Der älteste fossile Beleg ist ein etwa zwei Zentimeter langer Floh aus dem Jura Chinas. Die kräftigen Mundwerkzeuge deuten auf einen Wirt mit einer relativ dicken Haut. Fossile Flöhe des Mesozoikums sind überdies aus der Unterkreide Australiens bekannt. Darüber hinaus wurden Einschlüsse in Bernstein verschiedener tertiärer Lagerstätten beschrieben. Während einige morphologische Merkmale der mesozoischen Flöhe sich noch deutlich von denen ihrer rezenten Verwandten unterscheiden, sind die wenigen (Stand 2015: 6 Exemplare) Flöhe aus dem eozänen Baltischen Bernstein und dem etwas jüngeren Bitterfelder Bernstein (sämtlich zur Gattung "Palaeopsylla" gestellt) den heutigen Vertretern ihrer Gattung sehr ähnlich. Als deren Wirte werden die im Tertiär weit verbreiteten kleinen Insektenfresser, wie Spitzmäuse oder Maulwürfe, angesehen. Weitere drei Exemplare sind in dem etwas jüngeren Dominikanischen Bernstein gefunden worden.

Die über lange Zeiten große Nähe der Menschen zu diesen kleinen Quälgeistern führte zu zahlreichen Sprichwörtern, Sprachbildern und Ausdrücken:





</doc>
<doc id="1717" url="https://de.wikipedia.org/wiki?curid=1717" title="Floh">
Floh

Floh bezeichnet:

Siehe auch:



</doc>
<doc id="1718" url="https://de.wikipedia.org/wiki?curid=1718" title="Filderstadt">
Filderstadt

Filderstadt ist eine Stadt in der Mitte Baden-Württembergs, direkt südlich der Landeshauptstadt Stuttgart gelegen. Die erst 1975 im Rahmen der Gemeindereform entstandene Stadt hatte bereits bei ihrer Gründung mehr als 20.000 Einwohner und wurde daher mit Wirkung vom 1. Juli 1976 zur Großen Kreisstadt erklärt. Heute ist sie nach Esslingen am Neckar die zweitgrößte Stadt des Landkreises Esslingen und gehört zum Mittelbereich Stuttgart innerhalb des gleichnamigen Oberzentrums. Filderstadt gehört zur Region Stuttgart (bis 1992 "Region Mittlerer Neckar") und zur europäischen Metropolregion Stuttgart.

Filderstadt liegt auf der inneren Filderhochfläche auf 327 bis 474 Meter Höhe. Die Landschaft, die wortverwandt mit "Gefilde" ist, gab der Stadt ihren Namen. Am Westrand, beim Stadtteil Plattenhardt, beginnt der Naturpark Schönbuch. Die Schwäbische Alb liegt in Sichtweite der Stadt.

Folgende Städte und Gemeinden grenzen an die Stadt Filderstadt. Sie werden im Uhrzeigersinn, beginnend im Norden, genannt:
Stuttgart (Stadtkreis), Neuhausen auf den Fildern, Wolfschlugen und Aichtal (alle Landkreis Esslingen), Waldenbuch (Landkreis Böblingen) sowie Leinfelden-Echterdingen (Landkreis Esslingen).

Das Stadtgebiet Filderstadts besteht aus den 5 Stadtteilen Bernhausen (13.216 Einwohner), Bonlanden (10.296 Einwohner), Plattenhardt (8.482 Einwohner), Sielmingen (7.566 Einwohner) und Harthausen (4.094 Einwohner). Die Stadtteile sind identisch mit den ehemaligen Gemeinden desselben Namens. Die offizielle Bezeichnung der Stadtteile erfolgt durch vorangestellten Namen der Stadt und durch Bindestrich verbunden nachgestellt der Name der Stadtteile.

Nach Daten des Statistischen Landesamtes, Stand 2014.

Die Stadt Filderstadt entstand am 1. Januar 1975 durch Zusammenschluss der ehemals selbständigen Gemeinden Bernhausen, Bonlanden, Harthausen, Plattenhardt und Sielmingen zunächst unter dem Namen „Gemeinde Filderlinden“. Am 25. Juli desselben Jahres wurde der Name in „Filderstadt“ geändert. Mit Wirkung vom 1. Januar 1976 erhielt die neue Gemeinde das Stadtrecht und ein halbes Jahr später, am 1. Juli 1976, wurde sie auf Antrag der Stadt von der baden-württembergischen Landesregierung zur Großen Kreisstadt erklärt. Die fünf ehemaligen Gemeinden haben jedoch eine lange Geschichte.

Bernhausen wurde 1089 als „Berinhusen“ (als frühschwäbische Bezeichnung für „Wohnstätten des Bero“) erstmals erwähnt. Einige adelige Familien der Herren von Bernhausen hatten die Rechte über den Ort, doch fiel er in der ersten Hälfte des 14. Jahrhunderts an Württemberg. Die Gemeinde gehörte zum Amt bzw. Amtsoberamt Stuttgart und kam 1938 zum Landkreis Esslingen.

Bonlanden wurde Anfang des 12. Jahrhunderts als „Bonlandum“, was so viel wie „baumbestandene Lande“ bedeuten dürfte, erstmals erwähnt. Der Ort gehörte zunächst den Herren von Bernhausen, später deren von Stöffeln, von Stammheim und von Sachsenheim. Württemberg tauschte den Ort Zug um Zug. Um 1400 war ganz Bonlanden württembergisch. 1820 wurde die Gemarkung um ein großes Waldgebiet des Schönbuchs vergrößert. Die Gemeinde gehörte zum Amt bzw. Amtsoberamt Stuttgart und kam 1938 zum Landkreis Esslingen.

Harthausen wurde 1304 als „Harthusen“ erstmals erwähnt. Der Name bedeutet so viel wie „Häuser am Hart“, also Weidewald. Auch hier hatten die Herren von Bernhausen ihre Besitzungen. Über verschiedene Herren gelangte auch Harthausen ebenfalls an Württemberg, doch hatten die Herren von Stammheim und Thumb von Neuburg noch bis ins 16. Jahrhundert kleinere Rechte. Die Gemeinde gehörte zum Amt bzw. Amtsoberamt Stuttgart und kam 1938 zum Landkreis Esslingen.
Plattenhardt wurde 1269 als „Blatinhart“ erstmals erwähnt und bedeutet wohl platte = eben und Hart = Weidwald. Neben den Herren von Bernhausen hatten auch die Herren von Urslingen Rechte am Ort, der aber bald mit Waldenbuch an Württemberg gelangte. 1833 wurde die zum Amt bzw. Amtsoberamt Stuttgart gehörige Gemeinde um einige Waldflächen vergrößert. 1938 kam Plattenhardt zum Landkreis Esslingen.
Sielmingen wurde 1275 als „Sygehelmingen“ (wahrscheinlich abgeleitet vom Eigennamen „Sighelm“ bzw. „Sigehelm“) erstmals erwähnt. Schon damals wurde zwischen Ober- und Untersielmingen unterschieden. Obersielmingen gehörte den Herren von Bernhausen und kam mit Waldenbuch 1363 von den Herren von Urslingen an Württemberg. Untersielmingen gehörte verschiedenen Herren und kam dann teilweise an Württemberg. Das Spital Nürtingen behielt aber bis 1806 einen Teil des Ortes, bevor auch dieser an Württemberg gelangte. Bis 1850 waren beide Orte als Gemeindeverband organisiert, dann wurden sie zu selbständigen Gemeinden erklärt, 1923 jedoch unter dem Namen Sielmingen zu einer Gemeinde vereinigt. Beide Orte bzw. die Gemeinde Sielmingen gehörte zum Amt bzw. Amtsoberamt Stuttgart und kam 1938 zum Landkreis Esslingen.
Die Bevölkerung der fünf ehemaligen Gemeinden der heutigen Stadt Filderstadt gehörten ursprünglich zum Bistum Konstanz. Da die Orte politisch schon früh zu Württemberg gehörten, wurde auch hier ab 1535 durch Herzog Ulrich die Reformation eingeführt, daher waren sie über Jahrhunderte überwiegend protestantisch. In den Orten gibt es daher auch jeweils eine evangelische Kirchengemeinde mit einer Kirche. In Bernhausen wurde infolge des starken Zuzugs 1965 eine weitere Kirche, die Johanneskirche, erbaut. Später folgte die Petruskirche. Die drei Kirchengemeinden bilden aber weiterhin die Gesamtkirchengemeinde Bernhausen. Die Kirchengemeinde Harthausen war lange Zeit eine Filiale von Bernhausen, später von Plattenhardt, dann von Untersielmingen und schließlich ab 1838 von Bonlanden. 1838 erhielt der Ort seine eigene Kirche und 1959 wurde auch eine eigene Pfarrei errichtet. Alle Kirchengemeinden Filderstadts gehörten früher zum Dekanat bzw. Kirchenbezirk Degerloch. 1981 wurde die Jakobuskirche Bernhausen Sitz eines eigenen Dekanats bzw. Kirchenbezirks innerhalb der Evangelischen Landeskirche in Württemberg, zu dem alle Kirchengemeinden im Stadtgebiet Filderstadts gehören. In Bernhausen sind auch die Altpietistische Gemeinschaft und Hahn’sche Gemeinschaft und in Sielmingen die Landeskirchliche Gemeinschaft vertreten.

Katholiken gibt es in Filderstadt erst wieder seit dem 20. Jahrhundert. In Bernhausen entstand 1968 die Kirche St. Stephanus. Zur Kirchengemeinde gehört auch Sielmingen, doch gibt es dort seit 1963 eine eigene Kirche: St. Michael. In Bonlanden wurde 1958 die katholische Kirche „Zu Unserer Lieben Frau“ gebaut, eine Pfarrei gibt es dort seit 1961. Die Kirchengemeinde umfasst auch Plattenhardt. In Harthausen wurde 1968 eine katholische Kirche erbaut, die zur Pfarrei der Nachbargemeinde Grötzingen (Stadt Aichtal) gehört. Alle Kirchengemeinden gehören zum Dekanat Esslingen-Nürtingen des Bistums Rottenburg-Stuttgart und bilden die Seelsorgeeinheit 2 des Dekanats. Leitender Pfarrer ist Andreas Marquardt aus Bernhausen.

Neben den beiden großen Kirchen gibt es in Filderstadt auch Freikirchen und Gemeinden, darunter die Evangelisch-methodistische Kirche (Bonlanden) und die Evangelisch-Freikirchliche Gemeinde Esslingen-Fildern in Sielmingen. In Bernhausen befinden sich das "Glory Life Zentrum" und das Gospel Forum Fildern. Auch die Neuapostolische Kirche, die Christengemeinschaft und die Zeugen Jehovas sind in Filderstadt vertreten.

Außer den christlichen Gemeinschaften gibt es mehrere islamische Gemeinschaften und die Christlich-Islamische Gesellschaft für die Begegnung und den Dialog zwischen Christen, Muslimen und anderen Religionen.

Die Zahlen sind Volkszählungsergebnisse (¹) oder amtliche Fortschreibungen der jeweiligen Statistischen Ämter (nur Hauptwohnsitze). Die Zahlen der Jahre 1961 und 1970 ergeben sich aus der Addition der Einwohnerzahlen der fünf Vorläufergemeinden.

¹ Volkszählungsergebnis

Der Gemeinderat in Filderstadt hat 32 Mitglieder. Die Kommunalwahl am 25. Mai 2014 führte zu folgendem amtlichen Endergebnis: Der Gemeinderat besteht aus den gewählten ehrenamtlichen Gemeinderäten und dem Oberbürgermeister als Vorsitzendem. Der Oberbürgermeister ist im Gemeinderat stimmberechtigt.

An der Spitze der Stadt steht der von der Bevölkerung auf acht Jahre gewählte Oberbürgermeister. Er ist auch Vorsitzender des ebenfalls von der Bevölkerung auf fünf Jahre gewählten Gemeinderats. Er hat als allgemeinen Stellvertreter einen 1. Beigeordneten mit der Amtsbezeichnung „Erster Bürgermeister“ und einen weiteren Beigeordneten mit der Amtsbezeichnung „Bürgermeister“.

Stadtoberhäupter seit Bildung der Stadt 1975:

Am 5. Juli 2015 wurde der CDU-Mann Christoph Traub für die nächste Amtsperiode zum Oberbürgermeister gewählt. Er trat am 3. Oktober 2015 sein Amt an. Zuvor stellte er den Fraktionsvorsitz der Fraktionsgemeinschaft CDU/FDP im Gemeinderat von Filderstadt.

Der Jugendgemeinderat der Großen Kreisstadt Filderstadt wurde im Oktober 1987 gegründet.

Das Wappen der Stadt Filderstadt zeigt einen „von Gold und Grün fünf mal geteilten“ Schild. Die Stadtflagge ist gelb-grün. Wappen und Flagge wurden durch das Regierungspräsidium Stuttgart am 10. August 1977 verliehen. Das Wappen ist das Wappen der Edelfreien von Bernhausen, die in allen heutigen Stadtteilen eine historische Rolle spielten.

Die damalige Gemeinde Bernhausen schloss 1972 Partnerschaften mit Dombasle-sur-Meurthe und La Souterraine in Frankreich. 1988 ging Filderstadt gemeinsam mit den Nachbarstädten Ostfildern und Leinfelden-Echterdingen eine Partnerschaft mit Poltawa in der Ukraine ein. Weitere Partnerstädte sind seit 1990 Oschatz in Sachsen und seit 2002 Selby in Großbritannien.





Im ehemaligen Bonländer Rathaus befindet sich das Gottlob-Häussler-Heimatmuseum. Gezeigt wird das frühere Alltagsleben auf den Fildern mit Landwirtschaft, Handwerk (Schuster-, Schreiner- und Bürstenbinderwerkstätten), Küche und einem „Tante-Emma-Laden“.


Die größten Arbeitgeber Filderstadts sind der Etikettenhersteller Herma, das Klimatechnik-Unternehmen Modine und der TÜV Süd mit seinem zweitgrößten Standort. Im Luftfrachtzentrum des Stuttgarter Flughafens, das sich im Stadtteil Bernhausen befindet und eine Fläche von rund 150.000 m² umfasst, sind mehr als 70 Unternehmen der Logistikbranche ansässig. Im produzierenden Gewerbe, das etwa 30 Prozent der Arbeitsplätze in Filderstadt stellt, sind überwiegend mittelständische Automobilzulieferer tätig.

Im Gewerbegebiet Affelter in Bonlanden begann 2012 die Hugo Boss AG auf einer Fläche von 23.400 m² mit dem Bau eines Hochregallagers. Es wurde im Sommer 2014 eingeweiht. Außerdem soll dort bis Herbst 2012 mit der "Hall of Soccer" eine Fußballhalle entstehen.

Die Filder mit ihren fruchtbaren Lössböden war schon immer ein wichtiges Landwirtschaftsgebiet. Der ehemalige „Gemüsegarten Stuttgarts“ ist mittlerweile zwar durch Siedlungs- und Infrastrukturprojekte etwas eingeschränkt, doch die Landwirtschaft lebt immer noch in allen Stadtteilen, vor allem in Bernhausen und Sielmingen, die die Hauptorte des Krautanbaus in Filderstadt sind. Zwar ging durch den Strukturwandel in der Landwirtschaft die Zahl der landwirtschaftlichen Betriebe zurück, doch heute gibt es immer noch ca. 70 Stück.

Vor allem steht hier der Kraut- und Gemüseanbau im Vordergrund, die Viehhaltung ist eher selten anzutreffen.
Auf den Hofläden und Wochenmärkten lassen sich heute Produkte direkt vom Bauer erwerben, unter anderem Obst, Gemüse, Fleisch, Wurst und Brot.

Der Anteil der Siedlungsfläche an der Gesamtfläche der Stadt stieg zwischen 2000 und 2010 von 29,5 auf 33,8 Prozent. Im gleichen Zeitraum ging der Anteil landwirtschaftlicher Fläche um 4,5 Prozentpunkte auf 45,8 Prozent zurück.

Das traditionelle Filderkraut wurde erstmals 1772 vom Pfarrer Wilhelm Bischoff erwähnt. Vermutlich hatte es seinen Anfang in den Klostergärten des Klosters Denkendorf. Mit der Industrialisierung gewann es immer mehr an Bedeutung. Heute hat es immer noch einen hohen Stellenwert, vor allem in Echterdingen, Bernhausen und Sielmingen, die als Zentrum des Krautanbaus gelten. Mittlerweile wird allerdings immer öfter der leichter zu bearbeitende Rundkohl angebaut.

Da die Filder keine Vorrangregion für Milch- bzw. Fleischwirtschaft, wie das Allgäu oder der Schwarzwald war, wurde das Vieh nur zur Selbstversorgung gehalten. Das Ortsbild vor hundert Jahren war noch sehr von der Viehwirtschaft geprägt, Schweine, Schafe oder Ziegen, Kleinvieh wie Hasen, Hühner oder Enten gehörten zu Haushalt und Ortsbild. Im Farrenstall war der Farren untergebracht, für dessen Haltung die Gemeinde verpflichtet war. Heute ist die Zahl der Tiere gesunken, da durch bessere Einkaufsmöglichkeiten die Viehhaltung überflüssig geworden ist. Heute sind lediglich die alten Haltungseinrichtungen zu sehen. Die Funktion von z. B. Pferden hat sich verändert. Heute gibt es fünfmal so viele Pferde wie vor 30 Jahren. Im Gegensatz zu der damaligen Nutzung als Zug- und Arbeitstiere werden sie heute als Hobbytiere zum Reiten gehalten. Die Zahl der Milchkühe reduzierte sich in den letzten 30 Jahren um 85 %, die Menge der gehaltenen Schweine um 95 %. Dies ist kein für Filderstadt besonderer Prozess, er fand fast überall in der Landwirtschaft statt.

Streuobstwiesen sind in Filderstadt noch in sehr großer Zahl vertreten. Mit Aktionen wie den Streuobst-GUIDS und der „Mobilen Moste“ versucht man, diese Naturräume zu erhalten. Das alljährliche Apfelfest des Fildergartenmarkt Briems ist immer ein beliebter Zulauf für Streuobst- Fans. Der Museumsobstgarten beim Bildungszentrum Seefelle ist mit alten Sorten bestückt.

Der Biologische Landbau ist in Filderstadt vor allem durch den Bioland Gemüsehof Hörz in Bonlanden präsent.

Der Stuttgarter Flughafen liegt unmittelbar nördlich von Filderstadt. Die Start- und Landebahn befindet sich auf Filderstädter Gemarkung, ebenso der Tower, der in Bernhausen am Rande der Wohnbebauung steht.

An der nördlichen Stadtgrenze Filderstadts führt die Bundesautobahn 8 (Karlsruhe–Ulm) vorbei. Über die Anschlussstelle Stuttgart-Flughafen ist die Stadt direkt angebunden. Ferner führen die vierspurige Bundesstraße 27 (Stuttgart–Tübingen) und die Bundesstraße 312 (Flughafen–Reutlingen) durch das Stadtgebiet.

Den öffentlichen Personennahverkehr bedient seit Herbst 2001 vor allem die Linie S2 (Filderstadt–Schorndorf über Stuttgart-Flughafen und Stuttgart Hauptbahnhof) der S-Bahn Stuttgart. Der S-Bahnhof Filderstadt befindet sich im Stadtteil Bernhausen. Dieser ist auch der Knotenpunkt für neun von zehn Buslinien, die innerhalb des Stadtgebiets verkehren. Die Linien sind zu einheitlichen Preisen innerhalb des Verkehrs- und Tarifverbunds Stuttgart (VVS) zu benutzen;
eine Ausnahme ist die Linie X3, die zwischen Pfullingen/Reutlingen und Stuttgart-Flughafen verkehrt und dem Verkehrsverbund Neckar-Alb-Donau (Naldo) angehört.

Über das Tagesgeschehen Filderstadts berichtet die Filder-Zeitung, die den beiden Tageszeitungen Stuttgarter Zeitung und Stuttgarter Nachrichten beiliegt.
Außerdem gibt es noch die kostenlose Zeitung „Filder Wochenblatt“

Filderstadt hat ein Notariat.

Im Stadtteil Bernhausen befindet sich der Sitz des Kirchenbezirks Bernhausen der Evangelischen Landeskirche in Württemberg.

Im Stadtteil Bonlanden befindet sich das Gemeinschaftskrankenhaus Filderklinik, das zur Grund- und Regelversorgung gehört.

Im Stadtteil Plattenhardt befindet sich seit 2012 ein Wohnverbund der Diakonie Stetten e. V. für 36 Erwachsene mit geistiger Behinderung, davon zwölf Plätze in Apartmentwohnungen.

In Filderstadt gibt es alle allgemein bildenden Schularten. In Bernhausen besteht eine Grundschule (Bruckenackerschule), eine Grund- und Gemeinschaftsschule (Gotthard-Müller-Schule), die Fleinsbach-Realschule und das Eduard-Spranger-Gymnasium. Außerdem ist hier die Musikschule Filderstadt angesiedelt. Bonlanden hat eine Grundschule (mit den beiden Standorten Uhlbergschule und Schillerschule) sowie eine Werkreal- und Realschule im Bildungszentrum Seefälle. In Harthausen gibt es eine Grund- und Werkrealschule (Jahnschule mit der Lindenschule). Plattenhardt hat neben der Grundschule (Weilerhauschule) noch die Volkshochschule & Kunstschule Filderstadt. In Sielmingen gibt es eine Grundschule (Wielandschule), das Dietrich-Bonhoeffer-Gymnasium und eine Förderschule (Pestalozzischule). Eine Privatschule ist die Waldorfschule „Gutenhalde“.

Die Stadt ist Mitglied im Zweckverband Filderwasserversorgung. Die Stadtteile Harthausen und Sielmingen sowie die nördlichen Teile von Bonlanden erhalten Filderwasser aus der zentralen Enthärtungsanlage des Wasserwerks Neckartailfingen. Die Stadtteile Bernhausen und Plattenhardt sowie die südlichen Teile von Bonlanden erhalten Trinkwasser vom Zweckverband Bodensee-Wasserversorgung.

Die Strom- und Erdgasnetze in der Stadt werden von der EnBW Regional AG betrieben.

Zur Reinigung des Abwassers werden die beiden Kläranlagen Bombach und Fleinsbach betrieben.

Die Abfallentsorgung wird vom Abfallwirtschaftsbetrieb Esslingen organisiert, einem Eigenbetrieb des Landkreises Esslingen.




dito , , , und 


</doc>
<doc id="1719" url="https://de.wikipedia.org/wiki?curid=1719" title="Faz">
Faz

faz steht für:

FAZ steht für:

Siehe auch:


</doc>
<doc id="1720" url="https://de.wikipedia.org/wiki?curid=1720" title="File Transfer Protocol">
File Transfer Protocol

Das File Transfer Protocol [] (FTP, für "Dateiübertragungsprotokoll") ist ein im RFC 959 von 1985 spezifiziertes zustandsbehaftetes Netzwerkprotokoll zur Übertragung von Dateien über IP-Netzwerke. FTP ist in der Anwendungsschicht (Schicht 7) des OSI-Schichtenmodells angesiedelt. Es wird benutzt, um Dateien vom Server zum Client (Herunterladen), vom Client zum Server (Hochladen) oder clientgesteuert zwischen zwei FTP-Servern zu übertragen (File Exchange Protocol). Außerdem können mit FTP Verzeichnisse angelegt und ausgelesen sowie Verzeichnisse und Dateien umbenannt oder gelöscht werden.

Das FTP verwendet für die Steuerung und Datenübertragung jeweils separate Verbindungen: Eine FTP-Sitzung beginnt, indem vom Client zum "Control Port" des Servers (der Standard-Port dafür ist Port 21) eine TCP-Verbindung aufgebaut wird. Über diese Verbindung werden Befehle zum Server gesendet. Der Server antwortet auf jeden Befehl mit einem Statuscode, oft mit einem angehängten, erklärenden Text. Die meisten Befehle sind allerdings erst nach einer erfolgreichen Authentifizierung zulässig.

Zum Senden und Empfangen von Dateien sowie zur Übertragung von Verzeichnislisten (der Standard-Port dafür ist Port 21) wird pro Vorgang jeweils eine separate TCP-Verbindung verwendet. FTP kennt für den Aufbau solcher Verbindungen zwei Modi:

Beim "aktiven FTP" (auch „Active Mode“) öffnet der Client einen zufälligen Port und teilt dem Server diesen sowie die eigene IP-Adresse mittels des PORT- oder des EPRT-Kommandos mit. Dies ist typischerweise ein Port des Clients, der jenseits von 1023 liegt, kann aber auch ein anderer Server sein, der seinerseits in den "Passive Mode" geschaltet wurde, also auf eine Verbindung wartet (so genanntes FXP). Heutzutage ist FXP jedoch bei den meisten FTP-Servern aus Sicherheitsgründen standardmäßig deaktiviert. 
Die Datenübertragung auf der Server-Seite erfolgt dabei über Port 20. Die Kommunikation mit Befehlen erfolgt ausschließlich auf dem Control Port. Man spricht auch von der Steuerung „Out of Band“. Somit bleibt es möglich, dass während der Datenübertragung die Partner noch immer miteinander kommunizieren können.

Beim "passiven FTP" (auch „Passive Mode“) sendet der Client ein PASV- oder ein EPSV-Kommando, der Server öffnet einen Port und übermittelt diesen mitsamt IP-Adresse an den Client. Hier wird auf der Client-Seite ein Port jenseits 1023 verwendet und auf der Server-Seite der vorher an den Client übermittelte Port. Diese Technik wird eingesetzt, wenn der Server keine Verbindung zum Client aufbauen kann. Dies ist beispielsweise der Fall, wenn der Client sich hinter einem Router befindet, der die Adresse des Clients mittels NAT umschreibt, oder wenn eine Firewall das Netzwerk des Clients vor Zugriffen von außen abschirmt.

Viele FTP-Server, vor allem Server von Universitäten, Fachhochschulen und Mirrors, bieten sogenanntes "Anonymous FTP" an. Solche FTP-Server werden auch als "Pub" (v. engl. ‚öffentlich‘) bezeichnet. Hier ist zum Einloggen neben den realen Benutzerkonten ein spezielles Benutzerkonto, typischerweise „anonymous“ und/oder „ftp“, vorgesehen, für das kein (oder ein beliebiges) Passwort angegeben werden muss. Früher gehörte es zum „guten Ton“, bei anonymem FTP seine eigene, gültige E-Mail-Adresse als Passwort anzugeben. Die meisten Webbrowser tun dies heute nicht mehr, da es aus Spamschutz-Gründen nicht zu empfehlen ist.

Für das Datenübertragungsverfahren wird ein FTP-Client benötigt. In vielen aktuellen Browsern ist ein FTP-Client meist bereits integriert. Ein Beispiel für die Syntax einer FTP-Adressierung im Browser ist:

Der Client baut die TCP-Verbindung zum Control Port eines Servers auf. Über diese Verbindung wird über FTP-Kommandos der Datenaustausch zwischen Client und Server gesteuert. Davon zu unterscheiden sind die Kommandos für den zum Betriebssystem gehörenden Terminal-Client „ftp“, siehe auch FTP-Terminal-Client.

Daneben ist WebFTP ein von Webservern angebotener Dienst, der den Zugriff auf FTP-Server auch über HTTP ermöglicht. Die Darstellung erfolgt dabei innerhalb eines Webbrowsers. Eine Installation von Client-Software auf einem lokalen Rechner entfällt dadurch.

Eine Free/Libre Open Source Software zur Dateiübertragung mittels FTP ist FileZilla.

Auch der kostenfreie Dateimanager Total Commander bietet ein einfaches FTP Interface, genauso wie der Windows Explorer.

PureFTPd und ProFTPD sind kostenfreie FTP Server Implementationen.

Um Verschlüsselung und Authentifizierung zu nutzen, kann Transport Layer Security eingesetzt werden (FTP über SSL, kurz FTPS). Nach der Authentifizierung des Hosts und der Verschlüsselung durch TLS kann FTP die Authentifizierung des Client mittels Benutzername und Kennwort durchführen, wenn der Client sich nicht bereits mit einem Zertifikat über TLS authentifiziert hat.

Außerdem existiert mit dem SSH File Transfer Protocol (SFTP) eine auf SSH aufbauende Alternative zu FTP für Dateiverwaltung und -übertragung, bei dem nur der schon laufende codice_1-Daemon genutzt und somit keine weitere Software auf Serverseite benötigt wird.



</doc>
<doc id="1722" url="https://de.wikipedia.org/wiki?curid=1722" title="Fledermaus (Begriffsklärung)">
Fledermaus (Begriffsklärung)

Fledermaus steht für

Siehe auch:


</doc>
<doc id="1723" url="https://de.wikipedia.org/wiki?curid=1723" title="Fledermäuse">
Fledermäuse

Die Fledermäuse (Microchiroptera) sind eine Säugetiergruppe, die zusammen mit den Flughunden (Megachiroptera) die Ordnung der Fledertiere (Chiroptera) bilden. Zu dieser Ordnung gehören die einzigen Säugetiere und neben den Vögeln die einzigen Wirbeltiere, die aktiv fliegen können. Weltweit gibt es rund 900 Fledermausarten.

Der Name bedeutet eigentlich „Flattermaus“ (, zu ahd. "fledarōn" „flattern“).

Fledermäuse sind nahezu weltweit verbreitet, sie kommen auf allen Kontinenten der Erde mit Ausnahme der Antarktis vor. Auch in anderen polaren Regionen sowie auf entlegenen Inseln fehlen sie. Auf manchen Inseln (zum Beispiel Neuseeland) waren sie dagegen bis zur Ankunft des Menschen die einzigen Säugetiere. Die Fledermausgattung der Mausohren ("Myotis") ist die ohne menschlichen Einfluss am weitesten verbreitete Säugergattung überhaupt, ebenfalls sehr weit verbreitet sind die Bulldoggfledermäuse (Molossidae) und die Glattnasen-Freischwänze (Emballonuridae).

In Europa sind etwa 40 Arten verbreitet, davon knapp 30 auch in Mitteleuropa. Eine Liste findet sich im Abschnitt Systematik.

Fledermäuse sind im Durchschnitt etwas kleiner als Flughunde. Als größte Fledermausart gilt die Australische Gespenstfledermaus ("Macroderma gigas"), die eine Kopfrumpflänge von 14 Zentimetern, eine Spannweite von 60 Zentimetern und ein Gewicht von 200 Gramm erreichen kann. Die kleinste Fledermaus ist die Schweinsnasenfledermaus ("Craseonycteris thonglongyai"), auch bekannt als Hummelfledermaus, mit einer Kopfrumpflänge von drei Zentimetern und einem Gewicht von zwei Gramm. Sie gilt neben der Etruskerspitzmaus als kleinstes Säugetier überhaupt.

Die Skelettelemente sind meistens sehr dünn, und zart ausgebildet, um das Gewicht möglichst gering zu halten.

Fledermäuse besitzen ein dichtes, oft seidiges Fell, das meistens grau bis braun oder schwärzlich gefärbt ist und keinen Haarstrich aufweist. Es gibt aber auch weiße und gemusterte Arten, bei fast allen Arten ist zudem die Bauchseite heller als der Rücken. Anders als andere Säugetiere besitzen sie kein Wollhaar, die Fellhaare sind arttypisch aufgebaut und besitzen kleine Schuppen, sie können zur Bestimmung der Arten dienen.

Auffälligstes Merkmal der Fledermäuse ist, wie bei den Flughunden, die Flughaut, die sie zum aktiven Fliegen befähigt. Die Flughaut besteht aus zwei Hautschichten und erstreckt sich von den Handgelenken bis zu den Fußgelenken (Plagiopatagium). Weitere Häute erstrecken sich von den Handgelenken zu den Schultern (Propatagium), zwischen den Fingern (Dactylopatagium) sowie den Beinen. Die Unterste wird Uropatagium (Schwanzflughaut) genannt, sie bindet den Schwanz – sofern vorhanden – mit ein und dient oft zum Einkeschern der Beute. In der Flughaut befinden sich Muskelstränge zur Stabilisation und zum Einschlagen der Flügel sowie Nervenfasern und Blutgefäße zur Versorgung der Flughaut.

Der Daumen ist kurz – bei den Stummeldaumen (Furipteridae) fehlt er – und trägt eine Kralle; die vier übrigen Finger sind stark verlängert und spannen die Flughaut. Ebenfalls verlängert sind der Ober- und der Unterarm, der nur noch aus einem Knochen, der Speiche (Radius), besteht, während die Elle (Ulna) im mittleren Teil reduziert ist. Im Gegensatz zu den meisten Flughundarten fehlt bei den Fledermäusen die Kralle am zweiten Finger; dieser besteht bei ihnen nur aus einem langen Fingerglied. Ein Dorn am Fußgelenk, Calcar genannt, dient zum Aufspannen der Schwanzflughaut, dieser ist bei einigen Arten noch durch einen steifen Hautlappen, das Epiblema, ergänzt.

Die Hinterbeine der Fledermäuse sind im Gegensatz zu den meisten anderen Säugetieren durch eine Drehung des Beines im Hüftgelenk nach hinten gerichtet, sie enden in fünf bekrallten Zehen. Diese dienen in der Ruhephase zum Aufhängen im Quartier, wobei eine besondere Konstruktion der Krallensehnen ein passives Festhalten ohne Muskelanspannung ermöglicht – dadurch bleiben auch tote Tiere hängen.

Die Köpfe der verschiedenen Fledermausarten unterscheiden sich beträchtlich. Während manche an Gesichter anderer Tiere erinnern – zum Beispiel an Mäuse, darum auch der Name dieser Gruppe –, haben andere besondere Strukturen entwickelt. Viele Arten haben Nasenblätter oder andere Gesichtsstrukturen, die zum Aussenden oder Verstärken der Ultraschall­laute dienen. Die Ohren, die bei manchen Arten drastisch vergrößert sind, sind oft mit Rillen oder Furchen versehen, darüber hinaus haben sie einen Tragus, einen Ohrdeckel, der der Verbesserung der Echoortung dient. Fledermäuse können schwarz-weiß sehen, und wie aufgrund jüngster Untersuchungen festgestellt wurde, können einige Arten auch UV-Licht sehen, das von einigen Blüten verstärkt reflektiert wird, die sie dann zur Nektaraufnahme anfliegen. Zusätzlich verfügen Fledermäuse über einen Magnetsinn. Bei Langstreckenflügen orientieren sie sich an den Linien des Erdmagnetfeldes, ähnlich wie Zugvögel und viele andere Tierarten. Es gibt Hinweise darauf, dass der Magnetsinn durch Magnetit entsteht.

Fledermäuse besitzen im Normalfall ein Gebiss aus 32 bis 38 Zähnen, wobei besonders die Eckzähne stark ausgeprägt sind. Diese dienen den meisten Arten zum Aufbrechen des Chitin­panzers ihrer Beuteinsekten und den frugivoren zum Festhalten der Früchte. Die sanguinivoren (blutleckenden) Arten verwenden zum Anritzen des Wirts entgegen dem weit verbreiteten Glauben die unteren Schneidezähne. In Anpassung an die unterschiedlichen Ernährungsweisen variiert der Aufbau des Gebisses allerdings erheblich, sodass sich aus der ursprünglichen Zahnformel 2133/3133 = 38 insgesamt über 50 verschiedene Varianten entwickelt haben. Besonders wenige Zähne weist der Gemeine Vampir ("Desmodus rotundus") mit einer Zahnformel von 1111/2121 = 20 auf.

Die Augen sind meistens sehr klein, schwarz und besitzen wimpernlose Augenlider. Im Mundbereich und bei einigen Arten auch im Bereich der Nase besitzen die Tiere Vibrissen, also empfindliche Sinneshaare. Durch Drüsen im Mundbereich sezernieren die Tiere ein öliges Sekret, welches zur Pflege der Flughäute eingesetzt wird und wahrscheinlich auch arttypische Geruchsstoffe enthält. Weitere Duftdrüsen sitzen je nach Art an weiteren Stellen des Gesichts, an den Schultern oder an anderen Körperstellen.

Fledermäuse besitzen keine auffälligen Geschlechtsunterschiede. Die ausgewachsenen Weibchen sind in der Regel zwar etwas größer als die Männchen, dies kann jedoch nur durch genaue Messungen festgestellt werden. Erst bei der genauen Betrachtung der Genitalregion ist der Penis der Männchen erkennbar. Dieser wird durch einen kleinen Penisknochen (Baculum) stabilisiert. Der Penis ist, wie auch beim Menschen, freihängend (Penis pendulum). Dies ist im Tierreich recht ungewöhnlich. Bei einigen Arten treten besonders zur Paarungszeit auch die Hoden und Nebenhoden deutlich hervor.

Bei säugenden Weibchen erkennt man außerdem die gut ausgebildeten Brustdrüsen, die nahe den Achselhöhlen liegen. Bei den meisten Arten sind nur zwei Zitzen ausgebildet, manche Arten besitzen jedoch auch vier. Bei einigen Familien sind außerdem paarige Haftzitzen ohne Milchabgabe im Bereich der Leiste ausgebildet, an denen sich die Jungtiere festklammern können.

Die perfekte Anpassung der Fledermäuse an die Luft als Lebensraum prägt auch ihre Lebensweise.

Die meisten Fledermausarten ernähren sich von Insekten (Gliederfüßer), die sie teilweise im Flug erbeuten. In den Tropen und Subtropen gibt es viele vegetarisch lebende Arten, die Früchte fressen oder Nektar trinken. Diese Arten spielen eine wichtige Rolle für die Pflanzen, deren Blüten sie bestäuben (Chiropterophilie) und deren Samen sie verbreiten (Chiropterochorie).

Größere Arten der Gattungen Megadermatidae, Nycteridae und Phyllostomidae fressen auch kleinere Säugetiere wie Nagetiere und andere Fledermäuse, kleinere Vögel, Frösche und Fische. Die größten Arten wie Vampyrum spectrum fressen Vögel bis zur Größe von Tauben. Unter anderem dienen die von der Beute ausgestoßenen Laute wie auch deren Geruch zur Identifikation.
Die drei Arten der Vampirfledermäuse (Desmodontinae) ernähren sich vom Blut anderer Tiere.

Die Hauptfortbewegungsart der Fledermäuse ist das Fliegen, zu dem sie durch den Besitz der Flughäute und verschiedene weitere Anpassungen befähigt sind. Dabei handelt es sich bei schmalflügeligen Arten meistens um schnelle Flieger, die vor allem in offenem Gelände leben, bei breitflügeligen Arten um Langsamflieger in strukturreichen Lebensräumen; manche Fledermäuse beherrschen den Rüttelflug, um Ausschau nach Beute halten zu können, etwa das Braune Langohr. Beim Flug werden die Flügel in einer Rotationsbewegung geschlagen, wobei der kräftige Abschlag vor dem Kopf geschieht und die Flügel dann im hinteren Bereich des Körpers wieder hochgezogen werden. Die Schwanzflughaut dient dabei als Manövrierhilfe und zum Abbremsen.

Die anatomischen und physiologischen Anpassungen an diese Fortbewegung sind vielfältig. So besitzen die Fledermäuse einen sehr voluminösen Brustkorb mit einem Brustbein, das in Konvergenz zu dem der Vögel einen Kiel als erweiterte Ansatzstelle für die Flugmuskulatur aufweist, außerdem ist die Wirbelsäule im Brustbereich stark vorgebogen. Während des Fluges werden die Atem- und die Herzschlagfrequenz stark erhöht, um den Sauerstoffbedarf zu decken. Das Herz ist zudem stark vergrößert und hat etwa das dreifache Volumen zu dem anderer Säugetiere gleicher Größe, außerdem ist die Anzahl der roten Blutkörperchen (Erythrozyten) sowie der Hämoglobin­anteil stark erhöht, sodass etwa doppelt so viel Sauerstoff im Blut gebunden werden kann wie bei vergleichbaren Tieren. Zur Abkühlung dienen temperaturabhängig erweiterte Blutgefäße in den Flughäuten, in denen das Blut durch die umströmende Luft abgekühlt wird.

Neben dem Fliegen können sich Fledermäuse auch auf dem Boden fortbewegen. Manche Arten – etwa die Vampirfledermäuse oder die Neuseelandfledermäuse – sind dabei sehr geschickt und erstaunlich schnell, andere Arten hingegen sind am Boden plump und ungeschickt. Einige Arten können außerdem ihre Flughäute zum Schwimmen benutzen und sogar von der Wasseroberfläche zum Flug starten.

Fledermäuse sind in der Regel nachtaktive Tiere. Zum Schlafen ziehen sie sich in Höhlen, Felsspalten, Baumhöhlen oder menschengemachte Unterschlüpfe (Dachböden, Ruinen, Minen und andere) zurück. Neben Arten, die in großen Gruppen zusammenleben, gibt es auch solche, die als Einzelgänger leben. In den kühleren Regionen ihres Verbreitungsgebietes halten sie Winterschlaf, manchmal ziehen sie auch während der Wintermonate in wärmere Regionen.

Alle europäischen Fledermäuse haben einen vom Klima bestimmten Jahresablauf. Daher benötigen sie Quartiere, die ihnen Schutz vor schlechter Witterung und vor Feinden bieten. Es lassen sich Sommer- von Winterquartieren unterscheiden.
Im Spätsommer, etwa ab Ende August, suchen die meisten europäischen Fledermausarten nach geeigneten Winterquartieren, die ihnen für die kalten Monate ausreichend Schutz bieten. In Europa sind Fledermäuse Winterschläfer und entsprechend während des Winters abhängig von Unterschlupfmöglichkeiten, wo sie gleichmäßige Witterungsbedingungen vorfinden und gleichzeitig für ihre Feinde nicht gut erreichbar sind. Perfekte Winterquartiere stellen für sie als Höhlentiere Höhlen­systeme dar, aber auch Stollen und Festungs­anlagen werden gerne angenommen. So ist das größte bekannte Winterquartier das etwa 50 Meter unter der Erde liegende Bunkersystem des Ostwalles aus dem Zweiten Weltkrieg in Westpolen in Nietoperek bei Międzyrzecz. Hier überwintern jährlich bis zu 30.000 Fledermäuse, die zu zwölf verschiedenen Arten gehören. Weitere wichtige Quartiere sind die Kalkberghöhle in Bad Segeberg und die Zitadelle Spandau, eine Festungsanlage in Berlin. Häufiger sind jedoch Quartiere, die nur eine relativ geringe Anzahl der Tiere beherbergen.
Für den Winterschlaf legen die Fledermäuse spezielle Fettvorräte an, deren alleiniger Zweck es ist, während des Aufwachens die notwendige Energie zu liefern, mit der wieder die normale Körpertemperatur erreicht werden kann. Während des Winterschlafes sinkt die Körpertemperatur bis auf wenige Zehntel Grad über der Umgebungstemperatur, aber nicht tiefer als die Temperatur, bei der das Blut nicht mehr in der Lage ist, Sauerstoff zu transportieren.

Fledermäuse haben eine auffallend niedrige Fortpflanzungsrate. Die meisten Arten bringen nur einmal im Jahr ein einzelnes Jungtier zur Welt. Dies wird durch eine für Säugetiere ihrer Größe hohe Lebenserwartung kompensiert; so können manche Arten unter günstigen Umständen ein Alter von 20 bis 30 Jahren erreichen. Ein weiteres Merkmal dieser Tiere ist die verzögerte Befruchtung: Der Samen der Männchen kann mehrere Monate im Fortpflanzungstrakt der Weibchen aufbewahrt werden, erst bei günstiger Witterung beginnt der Fötus in der Gebärmutter zu wachsen.
In Europa findet die Paarung häufig in den Winterquartieren statt. Dabei suchen die brünstigen Männchen die Weibchen unter den meist in Gruppen hängenden Tieren auf, umklammern sie mit den Flügeln und beißen sie in den Nacken. Durch diese Behandlung wacht das Weibchen auf und wird, sobald es erwacht ist, vom Männchen begattet. Die Männchen sind bei der Verpaarung voll aktiv, während die Weibchen meist noch in der Aufwachphase sind. Eine Werbung um die lethargischen Weibchen findet nicht statt. Nach dem Geschlechtsakt suchen sich beide Tiere wieder einen Schlafplatz. Im Laufe des Winterschlafes kann ein Weibchen mehrfach von verschiedenen Männchen begattet werden. Die Befruchtung der Eizelle erfolgt jedoch nicht im Anschluss an die Paarung, sondern erst nach Beendigung des Winterschlafes. So wird verhindert, dass das Weibchen durch die Schwangerschaft zu viel Energie verliert und die Jungtiere in der kalten Jahreszeit geboren werden.

Nach Beendigung des Winterschlafes, etwa Ende März, wandern die Fledermäuse in ihre Sommerquartiere. Dabei suchen sich die Männchen meist Tagesquartiere, die als Ausgangspunkt für die Jagd dienen. Die Weibchen finden sich zu Wochenstuben zusammen, in denen die Jungtiere geboren und gemeinsam aufgezogen werden. Die Tragzeit der mitteleuropäischen Arten ist vom Nahrungsangebot abhängig. Sollte es für das trächtige Weibchen wenig zu fressen geben, so „regelt“ es Kreislauf und Stoffwechsel herunter. Die Tragzeit kann dadurch zwischen 40 und 70 Tagen variieren. Diese Wochenstuben umfassen meistens 20 bis 50 Muttertiere, die sich alljährlich wieder zusammenfinden. Dabei lassen sie die Jungtiere im Quartier zurück, wo sie gemeinsam mit anderen verlassenen Jungtieren regelrechte Fledermaustrauben bilden. Nach dem Jagdflug erkennt jede Mutter ihr Junges und setzt es an ihren Zitzen zum Säugen an. Ab Ende August werden die Jungen dann von ihren Müttern verlassen und finden sich selbständig in den Winterquartieren ein.

Fledermäuse sind hochsoziale Tiere, die die meiste Zeit des Jahres in Gruppen zusammenleben. In ihren Quartieren suchen sie meist engen Körperkontakt mit anderen Tieren, wodurch sich Fledermauspulke bilden (Schlafverband). Dies hat den Vorteil, dass die einzelnen Tiere wenig Energie für die Körperaufwärmung aufwenden müssen und verbrauchen. Sowohl in den Wochenstuben als auch in den Winterquartieren kommt es zudem zu einer Durchmischung verschiedener Arten. Dabei findet man meistens zwei oder drei verschiedene Arten in einem Quartier, wobei die einzelnen Arten sowohl in eigenen Clustern beieinanderhängen als auch eine echte Durchmischung vorkommt. In einer Kolonie können mehrere Millionen Tiere leben. So beherbergt die Bracken-Höhle bei Austin in Texas etwa 20 Millionen Tiere der Guano-Fledermaus "Tadarida brasiliensis".

Eine Rangordnung innerhalb von Fledermauskolonien wurde bislang nicht beschrieben, allerdings vertreiben männliche Fledermäuse ihre Konkurrenten aus den Paarungsrevieren. Kommt es zu Störungen innerhalb der Quartiere, ist ein Drohen mit aufgerissenem Maul und Zetern die Antwort, und nach kurzer Zeit kehrt wieder Ruhe ein. Einige Arten reagieren bei leichten Störungen mit einer Schreckstellung, bei der sie sich auf den Boden pressen, bei intensiveren Bedrohungen stellen sich diese Arten tot (Schreckstarre).

Wie bei vielen anderen sozialen Tieren gibt es auch bei Fledermäusen ein Schwarmverhalten, bei dem die Aktionen einzelner zu einer Beteiligung anderer Tiere führen. So folgt im Regelfall nach dem Abflug eines Tieres auch ein Start weiterer, und auch das Putzen einzelner Tiere führt dazu, dass andere damit beginnen. Beim Putzen gibt es allerdings bei den meisten Arten keine gegenseitige Fellpflege, stattdessen konzentriert sich jedes Tier auf sich selbst. Nur die Jungtiere werden in den ersten Lebenstagen noch vom Muttertier geputzt. Bei verschiedenen Arten, vor allem bei Hufeisennasen, wurde ein gegenseitiges Belecken des Gesichts beobachtet, allerdings geht man davon aus, dass es sich dabei nicht um Reinigungsverhalten, sondern um Kommunikationsgesten handelt.

Natürliche Feinde der Fledermäuse sind vor allem tag- und nachtaktive Raubtiere, vor allem Katzen sowie Greifvögel und Eulen. Außerdem gibt es eine Reihe von großen, fleischfressenden Fledermausarten, die neben anderen Beutetieren auch kleinere Fledermäuse jagen.

Mit ihrem Echoortungssystem (oder auch "Ultraschallortung") haben die Fledermäuse eine sehr komplizierte und effektive Methode entwickelt, die es ihnen ermöglicht, sich im Dunkeln zurechtzufinden und Insekten zu jagen, ohne ihre Augen einzusetzen. Dabei stoßen sie Ultraschall­wellen aus, die von Objekten als Reflexionen zurückgeworfen werden. Die einzelnen Echos werden von der Fledermaus aufgenommen und in die richtige Abfolge gebracht. Durch die Zeit­unterschiede kann das Gehirn die Umgebung erfassen und somit orten, wie weit ein Baum oder Insekt entfernt ist und sogar mit welcher Geschwindigkeit und Richtung sich ein Beutetier bewegt. Beim Großen Hasenmaul ("Noctilio leporinus") erreicht die Lautstärke des Rufes bis zu 140 Dezibel.

Lange Zeit nahm man an, dass Fledermäuse über extrem gute Augen verfügten, da sie sich in absoluter Dunkelheit zurechtfinden. Im 18. Jahrhundert unternahm der italienische Wissenschaftler Lazzaro Spallanzani erste Versuche mit Fledermäusen und Eulen, in denen er die Tiere in dunklen Räumen fliegen ließ. Während alle Eulen scheiterten, fanden sich Fledermäuse gut zurecht. Einige Zeit später führte er weitere Versuche durch, diesmal mit Fledermäusen, denen er die Augen ausgestochen hatte. Auch diese Tiere konnten ohne Probleme fliegen, während Exemplare mit versiegelten Ohren zu Boden fielen.

Als sich Hiram Maxim, der Erfinder des Maschinengewehrs, im Jahre 1913 mit Sonar­systemen zur Navigation auf See und zur Ortung der gesunkenen Titanic beschäftigte, glaubte er auf dem richtigen Weg zu sein, doch er irrte sich, denn er nahm an, dass Fledermäuse niederfrequente Töne mit dem Schlagen ihrer Flügel erzeugen würden. Erst als George W. Pierce kurz vor dem Zweiten Weltkrieg einen Schalldetektor für Hochfrequenztöne entwickelte, wurde die wahre Beschaffenheit des Fledermaussonars erkannt.

Damit das Echoortungssystem richtig funktionieren kann und alle Möglichkeiten optimal ausgeschöpft werden, ist eine spezielle Anpassung der verschiedenen Organe notwendig. So sind bei den Fledermäusen viele Körperteile genau auf den Gebrauch der Echoortung ausgelegt. Allerdings gibt es auch Fledermäuse, die kein Echoortungssystem haben. Innerhalb der Familie der Flughunde haben nur die Rosettenflughunde ein Echoortungssystem. Die übrigend Arten kompensieren, die fehlende Echoortung mit sehr großen, lichtempfindlichen Augen. 

Der Ruf besteht meistens aus einer Serie von fünf oder mehr verschiedenen Tönen, die eine Dauer von weniger als einer Sekunde bis zum Hundertstel einer Sekunde haben können, siehe auch Chirp. Fledermäuse können Frequenzen zwischen 9 kHz und 200 kHz ausstoßen. Erwachsene Menschen nehmen Frequenzen meist nur in einem Bereich zwischen 16 Hz und höchstens 18 kHz wahr. Mit Hilfe eines Fledermausdetektors können Ultraschallrufe auch für Menschen hörbar gemacht werden. Dieser wandelt die Rufe in Schallwellen niedrigerer Frequenz um, die in den Hörbereich des Menschen fallen.

Zur Jagd könnten die Fledertiere theoretisch sowohl niedrige als auch höhere Frequenzen einsetzen, allerdings haben hochfrequente Rufe viele Vorteile, wie kleinere Wellenlängen, die eine genauere räumliche Trennschärfe ermöglichen und die klarere Abgrenzung des Widerhalls von Hintergrundgeräuschen. Tiefere Frequenzen, die größere Wellenlängen besitzen, umspülen gleichsam kleine Objekte und senden daher kaum Echos zurück.

In Baumnähe rufen die Jäger nur leise, um ein Überschneiden mehrerer Echos zu verhindern (Echosalat), während sie im offenen Gelände laute Schreie ausstoßen. Eine Fledermaus passt ihren Ruf (innerhalb ihrer arttypischen Möglichkeiten und Grundstruktur) ständig an die Situation an. In offenem Gelände sind die Rufe länger, lauter und weniger frequenzmoduliert, in der Nähe von Hintergründen und beim Fang eines Insekts werden sie kürzer und stärker frequenzmoduliert.
Ein typischer Fledermausruf besteht aus zwei Komponenten, nämlich aus der Komponente mit konstanter Frequenz (CF) und einer Komponente, deren Frequenz mit der Zeit abnimmt (FM). Jedoch unterscheiden die Rufe sich stark zwischen den Arten und Gruppen. Hufeisennasen besitzen z. B. einen sehr langen (viele ms), konstantfrequenten Ruf, dessen Anfang und Ende sehr schwach frequenzmoduliert ist. Andere Arten nutzen sehr kurze, nur frequenzmodulierte Rufe, andere dagegen etwas längere mit einem ausführlicheren konstantfrequenten Teil. Zusätzlich unterscheiden sich die Rufe noch in der Anzahl der Harmonischen.

Die CF-Komponente des Rufs hat eine konstante Frequenz (CF = „constant frequency“), vergleichbar mit der einer Stimmgabel.
Sie hat eine hohe Reichweite und liefert der Fledermaus ein einfarbiges, lang andauerndes Echo. Nur wenige Fledermäuse (z. B. die Hufeisennasen) verwenden vor allem CF-Rufe (mit einem kleinen FM-Teil am Anfang und/oder Ende). Andere Arten verwenden als Suchlaute im offenen Luftraum sogenannte quasi-konstant-frequente Rufe, die nur schwach frequenzmoduliert sind (also quasi-konstant-frequent).

Die FM-Komponente der Fledermausrufe hat eine mit der Zeit abnehmende Frequenz (FM = „frequency modulated“). Sie hat eine geringere Reichweite als die CF-Komponente, liefert dafür aber ein Echo, mit welchem auch Oberflächenstrukturen erkannt werden. FM-Rufe werden meist bei der Verfolgung von Beutetieren verwendet. Die meisten Fledermäuse verwenden ausschließlich FM-Rufe mit unterschiedlich starker Frequenzmodulation.

Der Ruf wird von den Fledermäusen, wie bei Säugetieren üblich, im Kehlkopf erzeugt, wo Luft zwischen zwei Membranen (den Stimmbändern) hindurchgepresst wird und diese dadurch in Schwingungen geraten. Durch das Anspannen der Muskeln, die die Membranen halten, können unterschiedliche Tonhöhen erzeugt werden.

Bevor die Schallwellen aus dem Mund oder aus der Nase austreten, werden sie im Kehl- und Rachenraum verstärkt und gefiltert. Fledermäuse, die durch die Nase rufen, haben oft komplizierte Nasenaufsätze, welche die Schallwellen stark bündeln und in die richtigen Richtungen lenken. Fledermäuse mit solchen Aufsätzen, wie z. B. die Hufeisennasen, haben oft kleinere Ohren.

Die trichterförmigen Ohren der Fledermäuse sind sowohl gegenüber der Richtung der Echos als auch gegenüber der Klangqualität sehr empfindlich. Sie können die Ohren drehen und neigen, um bestimmte Schallquellen genauer zu orten. Jedes Ohr empfängt unabhängig von dem anderen.

Die Hörschnecke, welche besonders an die Jagdfrequenz angepasst ist, besitzt sehr viele Windungen, wodurch sie eine differenziertere Frequenzanalyse besitzen als andere Säugetiere, wie zum Beispiel Menschen. Nur Hufeisennasen besitzen in dem schmalen, wenige Kilohertz umfassenden Frequenzbereich, in dem sie auch rufen, eine hochdifferenzierte Frequenzanalyse. Ihre Gehörschnecke deckt diesen Bereich fein ab, wodurch eine sogenannte „akustische Fovea“, vergleichbar der Fovea (Gelber Fleck) in unserem Auge, entsteht.

Nachdem die Echos in den Ohren aufgenommen wurden, wird diese Information an das Gehirn weitergeleitet, wo die verschiedenen Echos anhand ihrer Frequenzen in die richtige Reihenfolge gebracht und dann analysiert werden. Je länger ein Echo benötigt, um nach dem Ruf wieder das Ohr zu erreichen, desto weiter ist der Reflektor entfernt. Ein Zeitabstand von einer Millisekunde entspricht etwa einer Objektentfernung von 17 Zentimeter (zurückgelegter Schallweg zum Objekt hin und zurück also 34 cm). Da die Abstandswahrnehmung von der Schallgeschwindigkeit und damit von der Temperatur der Luft abhängt, entwickelten die Fledermäuse auch ein fein ausgeprägtes Temperaturempfinden, welches in die Abstandswahrnehmung mit einfließt. Fledermäuse können Laufzeiten bis zu ca. 0,1 Millisekunden erkennen. Da beide Ohren die Ultraschallechos empfangen, kann das Gehirn beide Bilder zu einem 3D-Bild zusammenfügen, das einem Vergleich mit unserem Augenbild mehr als standhält.

Neben der Größe und Form eines Objekts kann auch die Oberflächenstruktur und damit das Material erkannt werden. Die Objektgröße wird über die Lautstärke des Echos bestimmt. Da die gleiche Lautstärke allerdings entweder von einem kleinen, nahen oder einem großen, weit entfernten Objekt stammen kann, wird erst die Entfernung bestimmt, dann kann die tatsächliche Größe ermittelt werden.

Die Erkennung der Objektform beruht auf der Auswertung der Lautstärke und des zeitlichen Verlaufs des Echos. Ein Echo entsteht an mehreren Echofronten, die auf die Form eines Gegenstandes hinweisen. Materialien und Oberflächenstrukturen werden über die Klangfarbe des Schalls unterschieden. Die Klangfarbe eines Objekts entsteht aus objekttypischen Interferenzen (Überlagerungen) der Schallwellen, wodurch bestimmte Frequenzen verstärkt und andere abgeschwächt werden.

Damit die Fledermaus weiß, ob sich ein Objekt links oder rechts von ihrer aktuellen Position befindet, wertet sie, wie zahlreiche andere Tierarten, die Zeitunterschiede beim Eintreffen des Schalls in beiden Ohren aus. Erreicht das Echo des gleichen Objekts das linke Ohr später als das rechte, so befindet sich der Gegenstand rechts von ihr. Wie die Tiere erkennen, ob das Objekt über oder unter ihnen ist, konnte bis heute noch nicht zweifelsfrei geklärt werden. Man geht davon aus, dass sie das Interferenzmuster der Schallwellen auswerten, wie Menschen es ebenfalls machen.

Der Doppler-Effekt, also eine Verschiebung der Frequenz, tritt auf, sobald Schallwellen auf sich bewegende Objekte treffen. Wenn sich ein Objekt auf die Fledermaus zubewegt, oder die Fledermaus auf ein Objekt, nimmt die Frequenz zu und der Ton wird höher, während ein Entfernen das Gegenteil bewirkt. Fledermäuse (Hufeisennasen?) können Unterschiede von nur 6 Hz erkennen und dadurch die Bewegungsgeschwindigkeit ermitteln. Hufeisennasenfledermäuse sind in der Lage, die durch die Flügelschläge von Insekten (insbesondere Nachtfalter) erzeugten Doppler-Verschiebungen zu analysieren und über die Lautstärke des Echos die Größe des Insektes und über die Häufigkeit der Dopplerverschiebungen pro Sekunde die Flügelschlagfrequenz zu bestimmen. Dadurch können sie verschiedene Insektenarten unterscheiden.

Die Zwergfledermaus erkennt Drähte von 0,28 Millimeter aus mehr als einem Meter Entfernung und jagt am Tag etwa 500 bis 1200 Taufliegen ("Drosophila"), die ungefähr drei Millimeter lang sind. Andere Fledermausarten wie die Mittelmeer-Hufeisennase können sogar einen Weg zwischen 0,05 Millimeter dicken Drähten finden. Experimente haben gezeigt, dass die vom Fledermausohr aufgenommenen und im Gehirn verrechneten Signale es ermöglichen, Ziele zu unterscheiden, welche nur 10 Millimeter auseinander liegen, auch wenn die Objekte völlig verschiedene Größendimensionen haben.

Das älteste Fledermausfossil wird auf 50 Millionen Jahre datiert. Daher wird die Entwicklung der Fledertiere im Eozän gesehen (das Eozän begann vor etwa 56 Millionen Jahren und endete vor etwa 33,9 Millionen Jahren).

Je nach Schädelform haben sich die Fledermäuse auf einen kleinen Kreis von Nahrungsquellen spezialisiert. So besitzen etwa nektartrinkende Fledermäuse lange schmale Schnauzen, mit denen sie optimal in Blüten hineinreichen, wohingegen Fledermäuse, die sich vorwiegend von harten Früchten ernähren, ein kurzes, „mopsähnliches“ Gesicht haben. Blattnasenfledermäuse leben dagegen von Insekten, Nektar, Früchten, Fröschen, Eidechsen und sogar Blut. Die Entwicklung einer breiteren Schädelform hat vor 15 Millionen Jahren bei Blattnasenfledermäusen zu einer größeren Beißkraft geführt. So konnten sie sich neue Nahrungsquellen erschließen. Diese „Schlüsseltechnologie“ öffnete den Blattnasenfledermäusen den Zugang zu neuen Ressourcen wie zum Beispiel den Früchten. Dies ermöglichte eine schnelle und vielfältige Aufteilung in verschiedenste neue Fledermausarten. Ein interessanter Nebeneffekt ist, dass Samen vieler Pflanzenarten nun von Fledermäusen ausgebreitet werden.

In den 1970er-Jahren tauchte die Frage auf, ob Fledertiere tatsächlich monophyletisch sind, das heißt ob Fledermäuse und Flughunde von einem gemeinsamen Vorfahren abstammen oder sich lediglich konvergent entwickelt haben. Zahlreiche Untersuchungen wurden zu dieser Frage durchgeführt, wobei heute die meisten Forscher von der Monophylie der Fledertiere ausgehen (Näheres siehe Systematik der Fledertiere). Mittlerweile wurde diese Ansicht neben morphologischen Vergleichen auch durch biochemische, parasitologische und molekularbiologische Analysen bestätigt.

Als nächste Verwandte der Fledermäuse neben den Flughunden innerhalb der Säugetiere galten lange Zeit die Riesengleiter und darüber hinaus ein gemeinsames Taxon bestehend aus den Fledertieren, Riesengleitern, Spitzhörnchen und Primaten. Jüngere molekulargenetische Untersuchungen stellen die Fledertiere jedoch in eine ganz andere Gruppe, nämlich die Laurasiatheria, zu denen unter anderem Insektenfresser, Paarhufer, Wale und Raubtiere gehören.

Die Fledermäuse werden in rund 17 Familien unterteilt, die in sieben Überfamilien zusammengefasst werden können.


Die verwandtschaftlichen Verhältnisse lassen sich in folgendem Diagramm darstellen.
Die phylogenetischen Beziehungen innerhalb der Fledermäuse sind relativ unumstritten. Zu den diskutierten Punkten zählen unter anderem:

Eine in jüngster Zeit aufgetauchte Diskussion betrifft die Monophylie der Fledermäuse, das heißt einige Fledermausarten könnten näher mit den Flughunden als mit anderen Fledermäusen verwandt sein. So platzieren Emma Teeling und Mark Springer die Hufeisennasenartigen (Rhinolophoidea) und die Flughunde (Pteropodidae) in eine eigene Klade, Yinpterochiroptera, und stellen diese allen anderen Fledertierarten gegenüber. Vor allem molekularbiologische Untersuchungen sprechen für diese Theorie, sodass die Fledermäuse eine paraphyletische Gruppe wären.

In Mitteleuropa sind annähernd 30 Arten verbreitet, die allesamt zu den Hufeisennasen (Rhinolophidae) oder Glattnasen (Vespertilionidae) gehören. Die folgende Liste ist alphabetisch und nicht systematisch:


Eine Reihe weiterer Arten findet sich unter anderem in Südeuropa, manche davon gelegentlich als Irrgäste in Mitteleuropa. Dazu zählen:

Die Entwicklungsgeschichte der Fledermäuse ist durch Fossilienfunde nur sehr spärlich dokumentiert. Zu den ältesten bisher gefundenen Gattungen zählen "Onychonycteris finneyi" und "Icaronycteris index" aus dem frühen Eozän der Green-River-Formation Wyomings sowie "Archaeonycteris", "Palaeochiropteryx", "Hassianycteris" und "Tachypteron franzeni" aus dem mittleren Eozän der Grube Messel in Deutschland. Diese frühen Vertreter ähneln in ihrem Körperbau bereits sehr stark den heutigen Fledermäusen, Unterschiede bestehen lediglich in Details wie beispielsweise dem Vorhandensein von Fingerklauen und einem langen, freien Schwanz (der sich allerdings auch bei den heutigen Mausschwanzfledermäusen findet). Auch die eozänen Gattungen dürften bereits zur Echolokation fähig gewesen sein.

Im Gegensatz zu anderen schwierig einzuordnenden Säugetiertaxa, etwa den Walen, liefert der Fossilienbefund bisher keinerlei Hinweise auf Übergangsformen. Folglich sind die Bedingungen, die zur Evolution des Schlagflugs bei Fledermäusen führten, unklar. John Speakman, Lehrstuhlinhaber für Zoologie an der Universität Aberdeen, rekonstruiert die Evolution der Fledermäuse dahingehend, dass diese Tiere zunächst tagaktiv waren und sich erst unter dem Druck durch Greifvögel zunehmend auf nächtlichen Beutefang verlegten. Parallel dazu habe sich die Echoortung entwickelt.

Fledermäuse erlangten offenbar bereits im Eozän weltweite Verbreitung – aus dieser Epoche sind Funde in Europa, Nordamerika und Australien belegt. Da für etliche Familien fossile Belege fehlen, ist über die Entwicklungsgeschichte der Gruppe kaum etwas bekannt.

Fledermäuse gelten in Teilen Afrikas und Asiens als Delikatesse. Strabo ("Geographika" 16,1,7) berichtet, dass die Einwohner des mesopotamischen Borsippa die dort sehr zahlreichen und auffällig großen Fledermäuse fingen und als Nahrung einsalzten. Der Inka-Herrscher Atahualpa besaß einen grauen Mantel aus Fledermauswolle.

In China gilt die Fledermaus als Symbol für Glück und Gewinn. Dies spiegelt sich in dem chinesischen Wort "fú" (蝠) wider, welches zugleich „Glück“ und „Fledermaus“ bedeutet. Als fünf Fledermäuse ("wǔ fú"; 五蝠) wurden Fledermäuse häufig als Stickerei auf Kleidungsstücken oder als runder Talisman um einen Lebensbaum angeordnet, wo sie außerdem für ein langes Leben, Reichtum, Gesundheit und einen leichten Tod standen. In Mittelamerika fand man Abbilder einer Fledermausgottheit der Maya auf Steinsäulen und Tongefäßen, die etwa 2000 Jahre alt waren. Diese Gottheit besaß einen Fledermauskopf und ausgebreitete Flügel und findet sich auch in der Bilderschrift des Volkes wieder.

Auf manchen ostindonesischen Inseln werden Fledermäuse wegen ihres unheilbringenden Wesens gefürchtet. Sie sollen ein schlechtes Omen verbreiten und gelten als Verkörperung von Vampiren. Bei den Toraja auf der Insel Sulawesi wird den großen Flughunden, Kalong, die magische Bedeutung der Fledermäuse zugeschrieben. Die Kalong leben in den Höhlen, in denen die Toraja die Gebeine ihrer verehrten Ahnen aufgestellt haben. Fledermäuse spielen in den traditionellen Glaubensvorstellungen in Ostindonesien ferner eine Rolle als Totemtier und in Australien kommen sie in einigen Ursprungsmythen vor. Auf der obersten Terrasse des Candi Ceto, eines ostjavanischen Tempels auf dem Berg Lawu aus dem 15. Jahrhundert, befindet die Darstellung einer am Boden liegenden Fledermaus, die auf ihrem Rücken eine Schildkröte trägt. Das Motiv der Fledermaus auf Java dürfte chinesischen Ursprungs sein, die kultisch-religiöse Bedeutung an diesem Tempel ist jedoch unklar.
In Europa ist die Fledermaus seit der Antike ebenfalls überwiegend negativ besetzt. So erzählt Ovid in seinen "Metamorphosen" (IV, 1–34), dass die Töchter des Königs von Böotien zur Strafe in Fledermäuse verwandelt wurden, weil sie es vorgezogen hatten, am Webstuhl zu arbeiten und sich Geschichten aus der Mythologie zu erzählen, statt an den Festlichkeiten zu Ehren Bacchus’ teilzunehmen. Auch die Bibel schreibt Fledermäusen negative Eigenschaften zu, zählt sie zu den unreinen Tieren (genauer zu den Vögeln) und bringt sie in Verbindung mit heidnischen Götzenbildern (Deuteronomium 14,16 und Jesaja, 2,20). Der Kirchenlehrer Basilius von Caesarea ("Homilie" 8) nannte die Fledermäuse dagegen Gottes nächtliche Geschöpfe und beschrieb ihre Lebensweise. Dass sie sich gegenseitig stützen, nannte er dem Menschen als Vorbild.

Dämonische und teuflische Wesen – auch Satan (der Teufel) selbst – werden in der Bildenden Kunst häufig mit Fledermausflügeln dargestellt und unterscheiden sich dadurch von Engeln.
Auf Albrecht Dürers bekanntem grafischen Blatt "Melancholie" aus dem Jahre 1514 hält ein an eine Fledermaus erinnerndes Wesen zwischen Tag und Nacht den Schriftzug "Melencolia I". Der spanische Maler Francisco de Goya verwendete Fledermäuse neben Eulen als Symbole des Bedrohlichen. Ein alter Aberglaube besagt, dass sich Fledermäuse gerne in Frauenhaare wickeln. Dieser entstand vermutlich aus der christlichen Vorstellung heraus, dass die Haare von Frauen Dämonen bzw. allgemein „das Böse“ anziehen (weshalb in vielen Glaubensvorstellungen Frauen ihre Haare bedeckt halten müssen). Bei der Landbevölkerung Mexikos gelten die Vampirfledermäuse zum Teil auch heute noch als Hexen, die den schlafenden Menschen das Blut aussaugen.

Fledermäuse werden außerdem mit der Seele und deshalb mit dem Tod assoziiert, auf einigen Darstellungen aus dem 14. Jahrhundert verlassen die Seelen beim Sterben den Körper in Form einer Fledermaus. Daraus könnten auch die europäischen Vampirsagen entstanden sein, die es bereits gab, bevor die mittelamerikanischen Vampirfledermäuse bekannt waren. Dieser Vampirglaube hat sich bis heute in der Populärkultur gehalten und spiegelt sich vor allem in der Phantasie von Buchautoren und Filmemachern. Figuren wie Graf Dracula oder auch Der kleine Vampir fliegen nächtens als Fledermäuse herum und suchen ihre Opfer, auch andere Vampirfilme, wie etwa der "Tanz der Vampire", nutzen dieses Motiv. Ebenfalls durch die nächtliche Lebensweise inspiriert ist die Schöpfung der Comic- und Filmfigur Batman – ein Superheld, der in Fledermausverkleidung nachts auf Verbrecherjagd geht.

Cesare Ripa ordnet in seinem Werk "Iconologia" unter dem Stichwort "Ignoranca" die Fledermaus der Personifikation der Unwissenheit zu, da das Tier lieber im Dunkeln bleibt, statt sich dem Licht der Wahrheit zu nähern. Auch in der klassischen persischen Literatur ist die Fledermaus ein Symbol für die Ablehnung von Wissen und Güte (also Licht) und wird von der Sonne (als Symbol eines gerechten Herrschers) vertrieben.
Das Wappen der Gemeinde Fiefbergen zeigt eine silberne fliegende Waldfledermaus (Großer Abendsegler: Nyctalus noctula) in Frontalansicht.

Auch in der Volksmedizin fanden Fledermäuse international Einzug. Ganze Fledermäuse oder auch Teile von ihnen sind bei verschiedenen Naturvölkern in Afrika und Asien Bestandteil von Schutzamuletten. In den arabischen Ländern und auch in Europa gab es vor allem im Mittelalter viele Rezepte, in denen Fledermausteile gegen verschiedenste Krankheiten und Beschwerden verwendet wurden. So empfahl etwa Albertus Magnus im 13. Jahrhundert, dass man sich das Gesicht mit Fledermausblut einreiben solle, wenn man auch in der Nacht klar sehen möchte. Als dämonisches Tier verwendete man die Fledermaus homöopathisch zur Abwehr von Dämonen, in christlicher Zeit auch von Hexen und Teufel.

Neben Flughunden findet man Fledermäuse heute noch lebend auf indischen Basaren: Ihnen wird die Haut abgezogen, die zur Wundheilung frisch auf betroffene Körperteile gelegt wird.

Zu den weltweiten Hauptbedrohungen der Fledermäuse zählen der Verlust des Lebensraumes sowie in geringerem Ausmaß die Bejagung durch den Menschen. Insbesondere die auf kleinen Inseln endemischen Arten sind dabei gefährdet. Die IUCN listet vier Arten als ausgestorben, rund 20 gelten als stark bedroht, zahlreiche weitere als bedroht oder gefährdet.

17 der deutschen Arten werden in den Gefährdungskategorien der Roten Liste Deutschlands geführt.

Nach dem Anhang IV der FFH-Richtlinie gelten alle auf dem Gebiet der Europäischen Union heimischen Fledermaus-Arten als streng geschützte Tierarten von gemeinschaftlichem Interesse. 13 ausgewählte Fledermausarten sind auch im Anhang II der FFH-Richtlinie geführt. Für diese Arten müssen EU-weit spezielle Schutzgebiete ausgewiesen werden.

Die Europäische Fledermausnacht ist ein jährlich stattfindendes Ereignis, bei dem auf die Bedrohung dieser Tiere aufmerksam gemacht werden soll.

Das bisher einzige Fledermaus-Museum Deutschlands informiert Besucher über den Schutz der Fledermäuse und ihrer Umwelt. Es dokumentiert das Leben der Tiere und zeigt die Entwicklung ihrer Erforschung. Das Museum arbeitet eng mit Wissenschaftlern und Fledermausforschern zusammen.

Höhlen und Stollen sind ein Winterquartier. Diese dürfen laut § 39 Abs. 6 Bundesnaturschutzgesetz in der Zeit vom 1. Oktober bis 31. März nicht betreten werden. Die Ethikrichtline des Höhlenschutzes unterstützt hierbei den Schutz der Fledermäuse.

Fledermäuse zählen zu den Kulturfolgern, da sie z. T. in menschlichen Behausungen nisten und in der Abenddämmerung zum Teil im Schein von Straßenlaternen, manchmal sogar bei geöffneten Fenstern in Wohnräumen im Schein einer Lampe nachtaktive Fluginsekten aus der Luft fangen. Ihre Gefährdung geht vor allem von der Zerstörung ihrer Lebensräume aus, etwa durch die Sanierung von Altbauten und die Versiegelung von potentiellen Schlafplätzen, durch die Vernichtung von Insekten-Lebensräumen, durch die Zerstörung von Totholzbeständen und die Vergiftung mit Insektenschutzmitteln und Holzschutz­farben. Nicht mehr ganz so selten sind Großes Mausohr ("Myotis myotis", siehe Foto oben), Zwergfledermaus ("Pipistrellus pipistrellus"), Großer Abendsegler ("Nyctalus noctula") und Wasserfledermaus ("Myotis daubentonii"). Mausohrfledermaus-Weibchen bilden im Sommer große Wochenstuben auf Dachböden, wo sie gemeinsam ihre Kinder gebären und aufziehen. Diese Wochenstuben und auch andere Fledermaus-Quartiere (Bäume mit Höhlungen, Spaltenquartiere, Höhlen und Stollen und Fledermauskästen) gilt es wie auch die anderen Lebensräume zu erhalten. Nur mit zweiter Priorität ist die Schaffung von Ersatzquartieren in Form von Fledermauskästen zu verfolgen, die neben dem Schutz der Fledermausarten auch der biologischen Schädlingsbekämpfung dienen.

Da sich gebäudebewohnende Fledermausarten sowohl Siedlungen als auch Städte erschlossen haben, sind sie wesentliche Elemente der Stadtnatur. Jedoch sind sie durch Sanierungen oder moderne Bauweisen gefährdet. Daher müssen sie bei Baumaßnahmen berücksichtigt werden. Der Landesbund für Vogelschutz in München setzt sich mit seinem Projekt „Artenschutz an Gebäuden“ für den Erhalt gebäudebewohnender Fledermaus- sowie Wildvogelarten ein.

Auch an Windkraftanlagen verunglücken Fledermäuse. Zuerst in den USA und in Australien beobachtet, erforscht man inzwischen auch in Europa Umfang und Hintergründe der Todesfälle. Untersuchungen ergaben 2008, dass kein direkter Kontakt zwischen Fledermaus und Windkraftanlage als Todesursache notwendig ist, sondern viele Tiere ein Barotrauma erleiden, das durch Druckunterschiede, vor allem an den Rotorblattenden, ausgelöst wird. In Deutschland sind bislang 13 Fledermausarten (Stand November 2005) mit mehreren hundert Individuen an den Anlagen verunglückt; die Dunkelziffer dürfte groß sein, da nur eine verschwindend kleine Anzahl der Anlagen kontrolliert wird.

Offenbar gibt es verschiedene Gründe für Unfälle, die sich teilweise überlagern und verstärken:

Die Problematik der Schlagopfer an Windkraftanlagen zeigt, dass noch erheblicher Forschungsbedarf besteht. Einige bisher als sicher geltende Erkenntnisse werden in Frage gestellt. So fanden sich Arten, bei welchen man Flughöhen bis max. 20 m annahm, als Opfer unter Windkraftanlagen. Die seit über 50 Jahren nördlich der Alpen nicht mehr nachgewiesene Alpenfledermaus fand man als Schlagopfer an einem Windrad in Brandenburg.

"Siehe auch" Windkraftanlage#Vogel- und Fledermausschlag.

Die Vampirfledermäuse und andere Arten können den Menschen und andere Tiere gefährden, da sie durch ihre Bisse und Kot verschiedene Krankheiten übertragen können. 

Die erste tollwütige Fledermaus wurde 1954 in Hamburg entdeckt. Bis 1985 wurden in Europa nur sehr wenige infizierte Fledermäuse gefunden. Seitdem hat sich die Fledermaustollwut stark ausgebreitet. Zwei Drittel aller tollwütigen Fledermäuse wurden in Dänemark und den Niederlanden registriert. Ungefähr 20 Prozent der in Europa infizierten Tiere wurden in Deutschland erfasst. Die Fledermaustollwut – welche nicht mit der Fuchstollwut identisch ist – wird vom Europäischen Fledermausvirus ("European Bat Lyssavirus", EBLV, Typ I u. II) ausgelöst und wurde 2003 insgesamt 13 mal in Deutschland festgestellt (Berlin 3, Bremen 1, Niedersachsen 3, Sachsen-Anhalt 1, Schleswig-Holstein 5). Bayern gilt bislang als frei von Fledermaustollwut. Allerdings sind die relativ geringen Untersuchungszahlen nicht sehr aussagekräftig.

In Europa gab es bis jetzt nur vier bestätigte Tollwuterkrankungen bei Menschen:
Am häufigsten ist die Breitflügelfledermaus ("Eptesicus serotinus") infiziert.

Bei Fledermäusen und Nagern wird ein Reservoir von Paramyxovirusarten vermutet. Hierbei wurden bis jetzt 86 Fledermaus- und 33 Nagerarten untersucht, hauptsächlich tropische Arten. Das Mumps-Virus ist laut einer Untersuchung von Fledermäusen auf den Menschen übergegangen. Bei dieser Studie wurden nur Fledermäuse und Nager untersucht, keine Tiere der Nahrungskette davor und danach, eine Prüfung, ob die Tiere die Viren über die Nahrung aufgenommen haben (und damit nur Zwischenwirte wären) erfolgte nicht, auch andere Überträger (die nicht untersucht wurden, etwa Insekten) wären als Überträger möglich.

Fledermäuse scheiden im Gegensatz zu den meisten anderen Säugetieren, aber ebenso wie Vögel und Reptilien, Stickstoffverbindungen als Guanin aus. Guanin ist zwar energiereicher als Harnstoff, benötigt aber kaum Wasser zur Ausscheidung, sodass die Tiere nicht so viel Trinkwasser wie Säugetiere benötigen und das Wasser im Körper nicht mitgeführt werden muss. Diese Ersparnis an zu bewegender Masse unterstützt die Flugfähigkeit.

Höhlenablagerungen aus Fledermauskot können als sogenannter "Höhlenguano" abbauwürdige Mächtigkeiten erreichen. Höhlenguano wird ebenso wie "Inselguano", der aus Seevogelausscheidungen besteht, als phosphatreiches Düngemittel eingesetzt.




</doc>
<doc id="1724" url="https://de.wikipedia.org/wiki?curid=1724" title="Fledertiere">
Fledertiere

Die Fledertiere (Chiroptera, auch Flattertiere) sind eine Ordnung der Säugetiere. Mit rund 1100 Arten sind die Fledertiere nach den Nagetieren die artenreichste Ordnung innerhalb der Säugetiere. Die Fähigkeit zum Schlagflug haben sie als stammesgeschichtlich jüngste Gruppe der Wirbeltiere erworben – nach den ausgestorbenen Flugsauriern und den Vögeln.

Die Ordnung der Fledertiere wird in zwei Unterordnungen aufgeteilt: Flughunde (Megachiroptera) und Fledermäuse (Microchiroptera). Das Schwestergruppenverhältnis dieser beiden Gruppen, also die Monophylie des Taxons der Fledertiere, gilt zwar mittlerweile als recht wahrscheinlich, ist jedoch umstritten.

Der wissenschaftliche Name "Chiroptera" leitet sich aus und "pteron" πτερόν ‚Flügel‘ ab, bedeutet also „Handflügler“.

Fledertiere sind nahezu weltweit verbreitet, sie fehlen lediglich in den Polarregionen sowie auf entlegenen Inseln. Auf manchen Inseln (beispielsweise Neuseeland) waren sie bis zur Ankunft des Menschen die einzigen Säugetiere.

Fledertiere sind die einzigen Säugetiere und neben den Vögeln die einzigen Wirbeltiere, die aktiv fliegen können. Einige Säugetiergruppen (wie die Gleithörnchen, die Dornschwanzhörnchen, die Riesengleiter und die Gleitbeutler) haben zwar eine Gleitmembran (Flughaut) zwischen den Gliedmaßen, können aber nur von höheren Punkten aus Gleitflüge machen. Im Gegensatz dazu können Fledertiere beim Fliegen auch Höhe gewinnen. 
Die Flugmembran besteht aus zwei Hautschichten und erstreckt sich von den Handgelenken bis zu den Fußgelenken. Weitere Membranen erstrecken sich von den Handgelenken zu den Schultern und zwischen den Beinen. Letztere wird Uropatagium (Schwanzflughaut) genannt, sie bindet den Schwanz – sofern vorhanden – mit ein und dient oft zum Einkeschern der Beute. Der Daumen ist kurz – nur bei den Stummeldaumen (Furipteridae) fehlt er – und trägt eine Kralle, die vier übrigen Finger sind stark verlängert und spannen die Flughaut. Während Flughunde meist am zweiten Finger ebenfalls eine Kralle haben, fehlt diese bei den Fledermäusen. Ein Dorn am Fußgelenk, Calcar genannt, dient zum Aufspannen der Schwanzflughaut. Die Hinterbeine der Fledertiere sind im Gegensatz zu den meisten anderen Säugetieren nach hinten gerichtet, sie enden in fünf bekrallten Zehen.

Das dichte, seidige Fell der Fledertiere ist meistens grau bis braun gefärbt, es gibt aber auch weiße und gemusterte Arten.

Die Größe dieser Tiere variiert erheblich, wobei die Schweinsnasenfledermaus mit 3 cm Länge und 2 Gramm Gewicht als das kleinste Säugetier überhaupt gilt, während der Kalong bis zu 1,7 Meter Flügelspannweite und 1,5 Kilogramm Gewicht erreichen kann.

Die meisten Fledertiere – mit Ausnahme einiger Flughunde – sind nachtaktive Tiere, die tagsüber in einem Versteck schlafen. Sie hängen dabei meist kopfüber an den Füßen, wodurch im Gefahrenfall eine schnelle Flucht durch einfaches Fallenlassen ermöglicht wird. Sie brauchen keine Kraft, um sich festzuklammern, da die Krallen durch das Gewicht der Fledermaus gekrümmt werden. Deshalb fallen selbst tote Fledertiere nicht herab. Die meisten Fledermäuse orientieren sich während des Fluges durch Echoortung: Mit dem Mund oder der Nase stoßen sie Laute ab, die im Ultraschallbereich liegen, also jenseits der menschlichen Hörgrenze. Manche Arten, insbesondere die Großblattnasen (Megadermatidae) und die Blattnasen (Phyllostomidae) haben auffällige Auswüchse an den Nasen, sogenannte Nasenblätter, die zur Verstärkung dieser Laute dienen. Die Ohren sind gut entwickelt und oftmals sehr groß, ein Tragus (Ohrdeckel) ist bei vielen Arten vorhanden und dient zum besseren Empfang der zurückgesandten Signale. Im Gegensatz dazu verwenden Flughunde mit Ausnahme der Rosettenflughunde keine Echoortung. Fledertiere sind nicht blind, sondern haben gut entwickelte Augen, auch wenn – wie bei vielen nachtaktiven Tieren – die Stäbchen in der Netzhaut überwiegen. Insbesondere Flughunde haben einen gut entwickelten Gesichtssinn. Auch der Geruchssinn ist bei den meisten Arten gut entwickelt.

Fledertiere verbringen den Tag in Höhlen, Felsspalten, Baumhöhlen oder in menschengemachten Behausungen wie Minen, Ruinen und Gebäuden; Flughunde schlafen eher auf Bäumen als Fledermäuse. Viele Arten leben in großen Kolonien, oft aus Tausenden von Tieren, andere sind Einzelgänger.

In kühleren Regionen halten sie oft Winterschlaf oder ziehen während des Winters in wärmere Regionen. Auch während des Tagesschlafs sinkt ihr Stoffwechsel in stärkerem Ausmaß als bei anderen Säugetieren.

Fledertiere nehmen je nach Art unterschiedlichste Nahrung zu sich. Man kann sie anhand der bevorzugten Nahrung in mehrere Gruppen aufteilen, diese Einteilung ist jedoch nicht systematisch:

Generell sind Fledertiere durch eine niedrige Fortpflanzungsrate gekennzeichnet. In den meisten Fällen kommt nur ein Jungtier im Jahr zur Welt. Bei den meisten Arten haben die Weibchen zwei Zitzen im Brustbereich, wegen dieses Merkmals wurden sie früher (unter anderem bei Carl von Linné) zu den Primaten gezählt. Als Ausgleich für die niedrige Fortpflanzungsrate sind Fledertiere verglichen mit anderen Säugetieren ähnlicher Größe sehr langlebig, manche Tiere werden über 20, manchmal über 30 Jahre alt.

Viele Fledertierarten sind heute bedroht. Die Gründe dafür liegen meist im Verlust des Lebensraumes, sowohl in den Tropen durch Waldrodungen als auch in Industrieländern durch den Einsatz von Pestiziden und Pflanzenschutzmitteln und die Versiegelung von Schlafplätzen durch Altbausanierungen. 12 Arten sind laut IUCN ausgestorben, 75 weitere gelten als bedroht oder stark bedroht.

Seit den 1970er-Jahren wird intensiv die Frage diskutiert, ob Fledertiere tatsächlich monophyletisch sind, das heißt von einem gemeinsamen Vorfahren abstammen. Mehrfach wurde die Theorie aufgestellt, Fledermäuse und Flughunde hätten sich unabhängig voneinander entwickelt, die Ähnlichkeiten im Körperbau seien lediglich auf konvergente Evolution zurückzuführen. Viele Studien wurden mit biochemischen, molekularen oder morphologischen Daten durchgeführt, um die Frage der Monophylie der Fledertiere zu klären. Während manche Untersuchungen anhand des Aufbaus des Nervensystems und des Penis sowie gewisser DNA-Sequenzen eher auf konvergente Evolution beider Gruppen hindeuten sollen, sprechen sich die meisten Forschungsergebnisse anhand morphologischer Studien, Untersuchungen des Fortpflanzungssystems und DNA-Vergleichen für die Monophylie beider Gruppen aus.

Es ist schwierig, die Stellung der Fledertiere im Stammbaum der Säugetiere festzulegen. Vielfach gelten sie als enge Verwandte der Riesengleiter und Primaten, jüngere Untersuchungsergebnisse stellen sie jedoch in die Überordnung der Laurasiatheria in die nähere Verwandtschaft der Cetartiodactyla (Paarhufer und Wale), Unpaarhufer (Perissodactyla) und Raubtiere (Carnivora).


</doc>
<doc id="1726" url="https://de.wikipedia.org/wiki?curid=1726" title="Frankfurter Allgemeine Zeitung">
Frankfurter Allgemeine Zeitung

Die Frankfurter Allgemeine Zeitung (Eigenschreibweise: "Frankfurter Allgemeine. Zeitung für Deutschland"; kurz F.A.Z. oder FAZ) ist eine deutsche überregionale Abonnement-Tageszeitung. Sie gehört mehrheitlich (zu 93,7 %) der Fazit-Stiftung und wird von der Frankfurter Allgemeine Zeitung GmbH verlegt.

Die Linie der Zeitung wird nicht von einem Chefredakteur, sondern von den Herausgebern bestimmt.

Die FAZ verfügt mit 41 Auslandskorrespondenten über eines der größten Korrespondentennetze der Welt. In größeren Metropolen gibt es mehrere spezialisierte Auslandskorrespondenten für Politik, Wirtschaft und Feuilleton, so in Brüssel (4), London (4), Madrid (2), Moskau (2), New York (3), Paris (2), Peking (2), Rom (2), Washington (2), Wien (2). Seit 2001 leitet Klaus-Dieter Frankenberger das Ressort Außenpolitik. Im Inland unterhält die FAZ (neben der Redaktion der "Rhein-Main-Zeitung") Redaktionsbüros in Berlin, Bonn, Dresden, Düsseldorf, Hamburg, Hannover, Kassel, Leipzig, München, Stuttgart und Wiesbaden.

Die FAZ verkaufte im Zuge der Konzentration auf die Kernkompetenz im September 2005 ihre Buchverlage Kösel-Verlag und Deutsche Verlags-Anstalt mit dem Manesse Verlag an die Verlagsgruppe Random House. 2006 stieß die "FAZ Buch- und Zeitschriftenverlag" auch den Kunstbuchverlag Prestel ab. Nach wie vor erscheinen FAZ-Bücher im so genannten FAZ-Institut.

Die FAZ gilt als bürgerlich-konservatives Medium. Laut einer Untersuchung von "Literaturkritik.at" erschienen im Jahr 2014 in der FAZ 447 Belletristik-Rezensionen mit einer Länge von über 500 Wörtern, was ihren Sonderstatus als „Flaggschiff des deutschen Rezensionsfeuilletons“ bestätige, das trotz eines Rückgangs in den vorangegangenen Jahren „noch immer mit Abstand die meisten Besprechungstexte überhaupt veröffentlicht“.

Die "Frankfurter Allgemeine Zeitung" wird unter Journalisten seit langem als eines der deutschsprachigen Leitmedien eingestuft, denen die Funktion zukommt, gesellschaftliche Kommunikation und Öffentlichkeit zu gestalten und zu prägen.

Die "Frankfurter Allgemeine Zeitung" hat in den vergangenen Jahren erheblich an Auflage eingebüßt. Sie beträgt gegenwärtig Das entspricht einem Rückgang von Stück. Der Anteil der Abonnements an der verkauften Auflage liegt bei %.
Die Gründung der FAZ im Jahr 1949 geht auf einen Beschluss der Wirtschaftspolitischen Gesellschaft (Wipog) zurück, eines zwei Jahre zuvor gegründeten Vereins von Unternehmern, die ihre Interessen in der Öffentlichkeit stärker vertreten sehen wollten. Gründungsherausgeber der FAZ waren Hans Baumgarten, Erich Dombrowski, Karl Korn, Paul Sethe und Erich Welter. Einige Redakteure der FAZ arbeiteten zuvor schon bei der 1943 verbotenen "Frankfurter Zeitung" und bei der "Allgemeinen Zeitung" in Mainz. Die erste Ausgabe der Zeitung erschien am 1. November 1949. Auf der Titelseite dieser Ausgabe hieß es unter der Überschrift „Zeitung für Deutschland“: „Unsere Leser haben heute die erste Nummer der ‚Frankfurter Allgemeinen Zeitung‘ vor sich. Dieses Blatt setzt die journalistische Arbeit fort, die in Mainz mit der ‚Allgemeinen Zeitung‘ begonnen worden ist. Aber es knüpft zugleich den Anfang zu einem neuen Werk.“

Laut eigener Darstellung sieht sich die Zeitung nicht als direkte Nachfolgerin der "Frankfurter Zeitung". So konnte man in der ersten Ausgabe lesen: „Aus der Tatsache, daß einige unserer Mitarbeiter früher der Redaktion der ‚Frankfurter Zeitung‘ angehört haben, ist vielfach geschlossen worden, hier werde der Versuch gemacht, die Nachfolgeschaft dieses Blattes anzutreten. Eine solche Annahme verkennt unsere Absichten. Wie jeder, so haben auch wir die hohen Qualitäten dieses Blattes bewundert […] Aber der Respekt vor einer hervorragenden Leistung bedeutet noch nicht den Wunsch, sie zu kopieren.“ Der Titel "Frankfurter Zeitung" wurde jedoch von der FAZ für sich markenrechtlich geschützt. Jahre später wurde die Marke FAZ geschützt.

Bis zum 30. September 1950 wurde die FAZ in Mainz gedruckt. Eine erste Anfrage, die FAZ in der von der "Frankfurter Rundschau" gepachteten Societäts-Druckerei herstellen zu lassen, gab es 1949, doch lehnte der in seine Rechte als Miteigentümer der Druckerei und der "Frankfurter Zeitung" wiedereingesetzte Kurt Simon dies ab mit der Begründung, die Herausgeber Erich Welter und Paul Sethe seien im Sinne nationalsozialistischer Zielsetzung zu stark engagiert gewesen. Später konnte man sich doch noch einigen und ab Herbst 1950 wurde die FAZ in der Societäts-Druckerei gedruckt. Im Jahr 1987 wurde in der Hellerhofstraße ein neues Redaktionsgebäude fertiggestellt, das der Architekt A. C. Walter geplant hatte. 1989 übernahm die Fazit-Stiftung die Mehrheit der Societäts-Druckerei.

Neben integren Verlagsgründern und leitenden Mitarbeitern waren die 1950er Jahre auch durch die einige NS-belastete leitende Mitarbeiter geprägt. So traten die Verlagsmanager Viktor Muckel, ehemaliger NS-Gauamtsleiter in Düsseldorf und Erwin Finkenzeller, im Zweiten Weltkrieg Propagandist der SS-Standarte Kurt Eggers, in die Führungsebene der FAZ ein. Während Finkenzeller für das Anzeigengeschäft zuständig war, übernahm Muckel die Bereiche Vertrieb und Werbung, zunächst als „selbständiger Verlagsberater“, dann als einer der Verlagsdirektoren. Von ihm stammt der bis heute gängige FAZ-Werbeslogan „Dahinter steckt immer ein kluger Kopf“.

Die Macher der FAZ (und viele Leser) wehrten sich lange Zeit gegen eine Überarbeitung des eher schlichten, ruhigen Erscheinungsbildes. Titelbilder in der FAZ blieben traditionell die Ausnahme und die Einführung farbiger Informationsgrafiken und Fotografien wurde kontrovers diskutiert. Seit dem 5. Oktober 2007 erscheint die Zeitung in einer optisch überarbeiteten, moderneren Aufmachung: Dabei entfielen unter anderem die Fraktur-Überschriften über den Kommentaren sowie die Linien zwischen den einzelnen Spalten. Die erste Seite erhielt ein farbiges Titelbild, wie auch die Abbildungen im Innenteil der Zeitung nach Möglichkeit farbig gehalten sind. Kästen mit zunehmend kürzeren Erläuterungen zu einzelnen Stichwörtern werden häufiger eingesetzt. Damit reagierte das Herausgebergremium auf anhaltende Auflagenverluste.

Seit dem 20. April 2011 ist die FAZ auch als ePaper auf dem iPad verfügbar.

Im Geschäftsjahr 2012 machte die Verlagsgesellschaft durch den weiteren Rückgang der Anzeigenerlöse einen Verlust von 4,3 Millionen Euro, nachdem im Vorjahr durch den Verkauf von Vermögen noch ein Ertrag von 19,3 Millionen Euro erwirtschaftet worden war. 2013 stieg das Defizit weiter an, auch der Umsatz ging zurück. Zum Ausgleich wurde Anfang 2014 die Seitenzahl der Zeitung reduziert, damit verbunden waren Personaleinsparungen in der Redaktion.

Am 16. September 2014 kündigte die FAZ an, bis 2017 jährlich 20 Millionen Euro einzusparen und bis zu 200 von 900 Stellen zu streichen.

Die FAZ spielt in vielen gesellschaftspolitischen Diskussionen eine meinungsbildende Rolle und löste sie häufig aus. So veröffentlichte sie etwa wesentliche Debattenbeiträge des Historikerstreits der 1980er Jahre, unter anderem von Ernst Nolte und Michael Stürmer, zuerst. Der Mitherausgeber Frank Schirrmacher stieß 2002 die Debatte über Martin Walsers Roman "Tod eines Kritikers" an, als er den – gewissermaßen traditionellen – Vorabdruck des neuen Walser-Romans verweigerte und in einem offenen Brief ausführlich begründete, was der Rezension eines noch nicht veröffentlichten Buchs gleichkam. Mit seinem 2004 erschienenen Buch "Das Methusalem-Komplott" und einer Reihe von Artikeln beteiligte sich Schirrmacher an der Diskussion über die Überalterung der deutschen Gesellschaft (siehe auch Demographie Deutschlands) und die damit einhergehenden sozialen, wirtschaftlichen, politischen und städtebaulichen Folgen. 2006 erregte ein Interview größeres Aufsehen, das Günter Grass der FAZ bereitwillig gegeben hatte und in dem er kurz vor der Veröffentlichung seiner Memoiren "Beim Häuten der Zwiebel" erstmals öffentlich von seiner Waffen-SS-Mitgliedschaft berichtete.

In der Diskussion über die Rechtschreibreform von 1996 spielten Beiträge von FAZ-Redakteuren und Gastautoren eine wichtige Rolle. Die Zeitung berichtete nicht nur über die Entwicklungen, sondern griff auch aktiv in die Debatte zugunsten der alten Rechtschreibung ein. Nach einer anfänglichen Umstellung zum 1. August 1999 auf die reformierte Rechtschreibung kehrte die Redaktion nach einem Jahr (zum 1. August 2000) wieder zur bisherigen Rechtschreibung zurück. Nach den Überarbeitungen des Regelwerkes durch den Rat für deutsche Rechtschreibung übernahm die FAZ Teile der Reform und druckt seit 1. Januar 2007 nach einer Hausorthographie, basierend auf der neuen deutschen Rechtschreibung, jedoch mit einigen Modifikationen. Durch das zwischenzeitliche Beharren auf der „bewährten“ Schreibweise (der sich 2005 auch "Der Spiegel", der Axel-Springer-Verlag und die "Süddeutsche Zeitung" vorübergehend anschlossen) wollte die Redaktion unter anderem Druck auf den Rat für deutsche Rechtschreibung ausüben, die in ihren Augen groben Fehler der Reform zu korrigieren.

Eine Sonderstellung für die gesellschaftspolitische Bedeutung der FAZ nimmt die Leserbriefseite der Zeitung ein, auf der sich oft prominente Diskussionsteilnehmer zu Wort melden.

Ehemalige Herausgeber
In der Geschichte der FAZ kam es zu zwei Entlassungen von Herausgebern, der von Jürgen Tern im Jahr 1970 und der von Hugo Müller-Vogg im Jahr 2001. Bei beiden gab es nur vage beziehungsweise gar keine offiziellen Begründungen.

Theodor-Wolff-Preis:
Die Artikelreihe "Frankfurter Anthologie" ist eine Sammlung deutschsprachiger Gedichte mit Interpretationen, die von Marcel Reich-Ranicki im Jahr 1974 begründet wurde und bis heute im Feuilleton der Samstagsausgabe erscheint.

Bis Ende 2001 war "Bilder und Zeiten" die Tiefdruckbeilage zur Samstagsausgabe der "FAZ". Sie zeichnete sich durch längere Artikel des Ressorts Feuilleton (insbesondere Literatur) aus. Die Beilage war großformatig schwarz-weiß bebildert. Zu erinnern ist insbesondere an die Fotos von Barbara Klemm, die hier regelmäßig erschienen. Im November 2006 wurde "Bilder und Zeiten" zumindest als Name wiederbelebt: die neue Samstagsbeilage erschien allerdings in gewöhnlichem Zeitungsdruck und modernisiert gestaltet. Verantwortlicher Redakteur ist Andreas Platthaus. "Bilder und Zeiten" wurde Ende 2012 als Beilage eingestellt; die bisher dort erschienenen Rubriken wurden in das Feuilleton aufgenommen. Im Internet werden die bisher in der Beilage erschienenen Beiträge noch unter altem Namen bereitgestellt.

Die "Berliner Seiten" waren eine in Berlin produzierte, in der Regel sechsseitige feuilletonistische Beilage der FAZ. Die Redaktion wurde von Florian Illies geleitet. Die "Berliner Seiten" erschienen erstmals am 1. September 1999 und wurden im Sommer 2002 wieder eingestellt, nachdem sich die Erwartung der FAZ, mit der Beilage die Zahl der Berliner Abonnenten nennenswert zu steigern, nicht erfüllt hatte.

Das "FAZ-Magazin" erschien vom 7. März 1980 bis zum 25. Juni 1999 freitags als wöchentliches farbiges Beilagenheft – dem "Zeit-Magazin" ähnlich – mit vorzugsweise kulturellen und biographischen Themen in insgesamt 1008 Ausgaben. Als eigenständiges Verlagsprodukt wurde es zuletzt von einer etwa zwanzigköpfigen Redaktion unter Thomas Schröder als Chefredakteur hergestellt. Regelmäßig schrieb Johannes Gross eine Kolumne.

Seit 23. Februar 2013 erscheint wieder ein "FAZ-Magazin", das aus dem bisher gemeinsam mit der "Neuen Zürcher Zeitung" herausgegebenen Mode- und Lifestylemagazin "Z" hervorgegangen ist. Es erscheint zwölfmal im Jahr, jeweils am zweiten Samstag des Monats und behandelt auf 80 Seiten die Themen Mode, Design, Reise, Beauty, Kunstmarkt und Kulinarik. Im Editorial zur Ausgabe vom 23. Februar 2013 heißt es: „Bei all dem Zuspruch lässt sich unser Supplement, das in diesem Jahr acht Mal der Zeitung beiliegt, schon von Erscheinungsweise, Format und Themenspektrum her nicht mit dem im Jahr 1999 eingestellten Vorläufer gleichsetzen. Die Zeiten ändern sich, die Zeitschriften auch. Mit Themen rund um Lebensstil, Populärkultur und Gesellschaft werden wir neue Seiten aufschlagen.“ Das großformatige (278 mm × 400 mm) Hochglanzheft legt anders als das Vorgängermagazin einen Schwerpunkt auf Lifestyle und Luxus und dient damit als Werbefläche für Produkte aus diesen Bereichen.

Der "Hochschulanzeiger" ist eine Zeitschrift, die viermal jährlich im Verlag der Frankfurter Allgemeinen Zeitung erscheint. Er wendet sich speziell an Studenten, Hochschulabsolventen und Berufseinsteiger, die sich über Branchen und Unternehmen informieren wollen, ihren zukünftigen Arbeitgeber suchen oder Tipps für die Bewerbung wünschen. Er kann einzeln oder zusammen mit einem Studentenabonnement der "FAZ" abonniert werden. Außerdem ist er am Kiosk erhältlich. Zwei Wochen nach Erscheinungstermin wird er kostenlos an vielen Hochschulen in Deutschland und Österreich verteilt bzw. dort ausgelegt. Die verbreitete Auflage des "Hochschulanzeigers" beträgt 216.839 Exemplare, davon 99.839 verkauft (IVW 4/2009).

Seit 2008 legt die FAZ monatlich das geheftete "Chrismon"-Magazin der evangelischen Kirche bei.

Seit Januar 2001 ist die FAZ mit einem eigenständigen redaktionellen Nachrichtenportal im Internet vertreten. 2006 hat FAZ.NET erstmals an der Erhebung der Arbeitsgemeinschaft Online-Forschung (AGOF) teilgenommen und verzeichnet die größte Reichweite deutscher Qualitätszeitungen bei Internetnutzern: 1,32 Millionen/Monat. 65 % der Nutzer sind männlich, die Hälfte hat Abitur. Ab dem 17. November 2007 erhielt die Website der "FAZ" ein verändertes Seitenlayout.

Im Oktober 2011 kam es zu einer weiteren Überarbeitung des Layouts von FAZ.NET. Nach dieser Überarbeitung ähnelt die Website dem Aussehen der Printausgabe. So wich das eigene, moderner gestaltete Logo von FAZ.NET dem bekannten Frakturschrift-Kopf der gedruckten Zeitung, dem seit seinem ersten Erscheinen etablierten Markenzeichen des Organs. Dabei wurde auch die Darstellung der Leserkommentare überarbeitet. Diese waren vor der Umstellung unter dem Artikel und konnten positiv wie negativ bewertet werden; nach der Umstellung befanden sich die Kommentare in einem separaten Reiter, und es war nicht mehr möglich, Leserkommentare negativ zu bewerten. Leserkommentare werden vor Veröffentlichung durch einen Moderator überprüft.

Im Juni 2015 verzeichnete FAZ.NET laut den Ergebnissen der Studie "AGOF digital facts" 6,55 Mio. Besucher pro Monat. Im Januar 2018 verzeichnete die Seite 10,29 Mio. Besucher.

Seit 2013 verantwortet ein Chefredakteur alle digitalen Produkte der F.A.Z.

Die "Frankfurter Allgemeine Sonntagszeitung" (FAS), erstmals erschienen am 30. September 2001, ist die Sonntagszeitung der FAZ. Trotz gemeinsamer Nutzung redaktioneller Ressourcen und Autoren tritt sie eigenständig auf und verfügt über 50 Redakteure.

Die "FAZ Weekly" war die englischsprachige Wochenzeitung der FAZ. Sie fasste hauptsächlich Leitartikel der Tageszeitung zusammen und lag jeweils freitags der International Herald Tribune bei. Sie erschien von Sommer 2002 bis zur Jahresmitte 2005. Vom 3. April 2000 bis zum 29. Juni 2002 hatte es sogar eine tägliche erscheinende Beilage "FAZ English Edition" gegeben.

"FAZ Audio-Dossiers" bündeln Berichte der FAZ oder der Sonntagszeitung zu einem Thema. Sie erscheinen monatlich und haben durch ihre thematische Dichte und die Qualität der Texte den Charakter von Hörbüchern. Die Laufzeit beträgt jeweils etwa zwei Stunden. Auszüge aus dem aktuellen Audio-Dossiers werden gleichzeitig als kostenlose Podcasts veröffentlicht.

Die Audioausgabe der "Frankfurter Allgemeinen Zeitung" für das Hören via (Mobil-)Telephon erscheint werktäglich mit den wichtigsten Kommentaren der FAZ. Sie ermöglicht auch Blinden und Sehbehinderten einen leichten Zugang. Diese Hörzeitung ist 30 bis 40 Minuten lang hörbar. Die Navigation erfolgt über die Tastatur.

In Verbindung mit "FAZ Audio-Dossiers" und der Audioausgabe erscheinen seit Mai 2006 in regelmäßigen Abständen Podcasts der "Frankfurter Allgemeinen Zeitung".

Seit April 2016 erscheint wöchentlich jeweils am Freitag die "Frankfurter Allgemeine Woche". Das Magazin hat das Format 26,5 × 20,3 cm, wird im 4-Farb-Offsetdruck gedruckt und einen Umfang von circa 80 Seiten. Eine jeweils wechselnde Titelgeschichte wird ausführlicher behandelt. Verantwortlicher Redakteur ist Nikolas Busse.

Das vierteljährliche Magazin "Frankfurter Allgemeine Quarterly" erschien erstmal im November 2016. Bei einer Startauflage von 75.000 Exemplaren, einem Format von 28,5 × 21 cm, einem Umfang von bis zu 210 Seiten und einem Heftpreis von 10 Euro soll es nach Eigenaussage „die kreative Elite“ des Landes ansprechen. Verantwortlicher Redakteur ist seit Herbst 2016 Rainer Schmidt. 

Im November 2017 erschien FAZ Einspruch als Digitalprodukt speziell für Juristen. Wöchentlich erscheinen sechs neue Ausgaben, Mittwochs wird das FAZ Einspruch-Magazin veröffentlicht, das exklusiv für FAZ Einspruch verfasste Inhalte enthält. Dazu wird ein Podcast veröffentlicht, der einmal wöchentlich erscheint.

Der Verlag diversifiziert seine Aktivitäten, um aus intern vorhandenen Kompetenzen zusätzliche Erlöse zu generieren.

Das Archiv der FAZ ist mit über 45 Millionen Artikeln eines der umfangreichsten Pressearchive der Welt. Seine Dokumentare verfügen über eine große Pressedatenbank mit Dokumenten aus mehr als 200 Quellen sowie über spezialisierte Wissensdatenbanken. Das Archiv ist das Informationszentrum der Zeitung, dessen vorrangige Aufgabe darin besteht, die Redaktion mit Fakten und Hintergrundinformationen zu versorgen. Daneben bietet es Informationen und -dienstleistungen für externe Kunden an (u. a. Online-Archiv mit Artikeln ab 1993, Jahrgangs-, Länder- und Themen-CD-ROMs, Audio-Dossiers, Vermarktung von Nachdruck- und Nutzungsrechten, Bereitstellung des Online-Archivs für Bibliotheken und Unternehmen, Termindienste).

Im "FAZ Stellenmarkt" werden Samstags und Sonntags Stellenanzeigen in den Printausgaben veröffentlicht Die überwiegende Anzahl der Print-Anzeigen werden ebenfalls Online im zugehörigen Jobportal veröffentlicht. Von 2006 bis 2016 war der Online Stellenmarkt unter der Domain fazjob.net zu erreichen. Die Domain wurde auf stellenmarkt.faz.net geändert. 

Der "FAZ Immobilienmarkt" ist das digitale Immobilienportal der FAZ. Der Relaunch des Marktes erfolgte Anfang 2018. Es werden Immobilien innerhalb Deutschland und Auslandsimmobilien in Europa im höheren Preissegment angeboten.

In den Jahren 2005 (beginnend mit "Superman") und 2006 (abschließend mit "Lucky Luke") veröffentlichte die FAZ in Zusammenarbeit mit "Panini Comics" 20 Bände bekannter Comicserien. Sie wurden redaktionell durch den Journalisten und Autor Andreas Platthaus betreut.

Die Verlagsgruppe veranstaltet Fachkongresse, bei denen neben externen Referenten auch redaktionelle Mitarbeiter der Zeitung ihr Fachwissen für die Teilnehmer aufbereiten. Das FAZ-Forum wurde zum 31. Dezember 2017 geschlossen. Die Geschäfte werden von der Convent Kongresse GmbH übernommen.

Unter dem Titel "Frankfurter Allgemeine Business School" wird berufliche Weiterbildung im Bereich Wirtschaft und Management angeboten.

Wichtigste überregionale deutsche Konkurrenzblätter sind die "Süddeutsche Zeitung" und "Die Welt". Die "Frankfurter Rundschau" war traditionell der regionale Wettbewerber, wurde aber im Zuge der Insolvenz durch die FAZ übernommen und wird heute unter dem Dach des Verlages weitergeführt. Ebenfalls zum Konzern gehört die "Frankfurter Neue Presse", die im Umland von Frankfurt unter verschiedenen lokalen Kopfblättern erscheint.

Der Bundesnachrichtendienst wurde 1968 von der Niederschlagung des „Prager Frühlings“ überrascht. Mit einem „Deal“ sorgte der Geheimdienst dafür, dass die Presse dieses Versagen verschwieg: „Grundsätzlich hat sich den letzten Tagen gezeigt, dass unsere PrSV [Pressesonderverbindung] gegen Überlassung guter Informationen stets bereit sind, für unser Haus einzutreten“, bilanzierte das Pressereferat am 28. August 1968. Außer der FAZ wurden auch die "Welt", der "Münchner Merkur", die "Rheinzeitung" und "Bild" genannt.

Eine Studie der gewerkschaftsnahen Otto-Brenner-Stiftung von Hans-Jürgen Arlt und Wolfgang Storz von März 2010 beleuchtete die Zeitungen "Handelsblatt", "die tageszeitung", "Süddeutsche Zeitung", FAZ und "Financial Times Deutschland", sowie die ARD-Formate "Tagesschau" und "Tagesthemen", sowie die Nachrichtenagentur DPA zum Thema „Wirtschaftsjournalismus in der Krise – Zum massenmedialen Umgang mit Finanzmarktpolitik“. Die Studie kommt zu dem Schluss, dass der tagesaktuelle deutsche Wirtschaftsjournalismus als Beobachter, Berichterstatter und Kommentator des Finanzmarktes und der Finanzmarktpolitik bis zum offenen Ausbruch der globalen Finanzmarktkrise – mit Ausnahme der "taz" – schlecht gearbeitet habe.





</doc>
<doc id="1727" url="https://de.wikipedia.org/wiki?curid=1727" title="Frédéric Chopin">
Frédéric Chopin

Fryderyk Franciszek Chopin (auch Szopen, "Szopę" und Choppen) oder Frédéric François Chopin (* 22. Februar oder 1. März 1810 in Żelazowa Wola, im damaligen Herzogtum Warschau; † 17. Oktober 1849 in Paris) war ein polnischer Komponist, Pianist und Klavierpädagoge. Er wuchs in Warschau als Sohn einer Polin und eines Franzosen auf. Chopin verbrachte die ersten 20 Jahre seines Lebens bis zum 2. November 1830 in Polen und die letzten 18 Jahre ab Oktober 1831 überwiegend in Frankreich. Er besaß die polnische und ab 1835 auch die französische Staatsbürgerschaft. Chopin schuf vorwiegend Klavierwerke. Schon zu Lebzeiten galt er als einer der führenden Musiker seiner Zeit. Sein Klavierspiel wurde wegen der Erweiterung der technischen und klanglichen Möglichkeiten des Instrumentes, der Sensibilität des Anschlages, der Neuerungen im Gebrauch beider Pedale und im Fingersatz als außergewöhnlich angesehen. Der als Wunderkind geltende Chopin erhielt seine musikalische Ausbildung in Warschau, wo er auch seine ersten Stücke komponierte. Chopins Leben war geprägt von Krankheit. Er starb 1849 im Alter von 39 Jahren in Paris, höchstwahrscheinlich an einer Perikarditis (Herzbeutelentzündung) als Folge einer Tuberkulose.

Chopins Kompositionsstil ist beeinflusst von der polnischen Volksmusik, der klassischen Tradition Bachs, Mozarts, Webers, Hummels und Schuberts, besonders aber vom Stil des Belcanto () der zeitgenössischen italienischen Oper (Vincenzo Bellini, 1801–1835). Von prägendem Einfluss war die Atmosphäre der Pariser Salons, in denen er häufig verkehrte. Hier entfaltete er seine Fähigkeiten in freien Improvisationen am Klavier, die oft zur Grundlage seiner Kompositionen wurden. Seine Neuerungen in allen Elementen der Komposition (Melodik, Rhythmik, Harmonik, Formen) und das Einbeziehen der polnischen Musiktradition mit ihrer Betonung des nationalen Charakters waren für die Entwicklung der europäischen Musik wichtig.

Chopins Eltern waren der aus Lothringen stammende Sprachlehrer Nicolas Chopin und die Polin Tekla Justyna Chopin, geborene Krzyżanowska. In der Zeit von deren Eltern, also der Großeltern von Fryderyk Chopin, François Chopin
(1738–1814) und Marguerite, geborene Deflin (1736–1794), wurde Lothringen von König Stanisław Bogusław Leszczyński (1677–1766) regiert, dem Schwiegervater von Ludwig XV. (1710–1774), der das Herzogtum 1737 als Entschädigung für den Verlust des polnischen Thrones erhalten hatte. Viele seiner polnischen Unterstützer und Höflinge hatten dort eine neue Heimat gefunden. Laut Erzählung von Chopins Vater gehörte hierzu auch dessen Vater, der ursprünglich aus Polen stammte und Fryderyk Choppen geheißen hat. Der Eintrag in der Taufurkunde lautet entsprechend. Er sei gehalten gewesen, seinen Namen ins französische „Chopin“ umzuwandeln. Er selbst sei nunmehr in die polnische Heimat zurückgekehrt. Trotz aller Unabhängigkeit war Lothringen politisch ein Satellitenstaat Frankreichs. Nicolas Chopin verdingte sich als Bürokraft und Hilfsarbeiter. Nach dem Untergang des Königreiches Polen durch die Dritte Teilung 1795 verdiente er seinen Unterhalt als Hauslehrer für Französisch beim polnischen Adel (Szlachta). Ludwika verhalf Nicolas Chopin über Samuel Linde zu einer Stelle als Französischlehrer am "Liceum Warszawskie." Ab 1810 zunächst als Collaborator und ab 1814 als Gymnasialprofessor blieb er dort bis zur Schließung der Schule im Jahre 1833.

Die Eltern Chopins verband die Leidenschaft zur Musik: Nicolas spielte Geige und Flöte, Tekla Justyna spielte Klavier und sang. Die Eheschließung fand am 2. April 1804 statt. Sie hatten vier Kinder.

Chopins Vater Nicolas war Ende 1787, vor den Teilungen Polens (1793, 1795), siebzehnjährig aus Lothringen in das Herzogtum Warschau (1807–1815, , ) gezogen. Er hielt keinerlei Kontakt zu seiner französischen Familie. Im Hause Chopins wurde es vermieden, über den französischen Teil der Familie zu sprechen. Er verbot seiner Familie, zu Hause französisch zu sprechen. Seine beiden Schwestern hatten das nicht unerhebliche Erbe von François Chopin nach seinem Tod 1814 unter sich aufgeteilt, ohne den Bruder Nicolas zu berücksichtigen.

Nicolas nahm die polnische Staatsbürgerschaft an und benutzte als Vornamen die polnische Form „Mikołaj“ []. Er kämpfte im Russisch-Polnischen Krieg 1792 und im Kościuszko-Aufstand 1794 für die polnische Unabhängigkeit auf polnischer Seite. Die Mutter stammte von dem verarmten Kujawski-Adel ab, deren Familie mit den Skarbeks verwandt war.

Der Stammbaum der Familie Chopin ist väterlicherseits bis zu den Ururgroßeltern nachzuverfolgen.

Chopin kam in Żelazowa Wola zur Welt, einem Dorf in der Gemeinde Brochów, Bezirk Sochaczew, Departement Warschau, im damaligen Herzogtum Warschau. Das Herzogtum stand seit 1807 unter der Herrschaft von Napoleons Gnaden, König Friedrich August I. von Sachsen (1750–1827), gleichzeitig bis 1815 Herzog von Warschau. 52 Kilometer westlich von Warschau gelegen, war dieses Dorf seit 1800 im Besitz der Landadelsfamilie Skarbek. Geburt und Taufe Chopins wurden zu Ostern, am 23. April 1810 in Brochów registriert, zwei Monate nach der Geburt. Die Einträge wurden erst 43 Jahre nach Chopins Tod, im Jahre 1892 entdeckt.
Die beiden Urkunden geben als Geburtsdatum den 22. Februar 1810 an, aber nach Chopins eigener Angabe – lange vor der Entdeckung der originalen Geburtsurkunde – sei sein Geburtstag der 1. März 1810. Die letzten Biographien übernahmen dieses Datum und betrachten den „22. Februar“ als Irrtum Nicolas Chopins am 23. April 1810. In den älteren Biographien (vor der Entdeckung der Einträge) finden sich andere Daten.

Auch Chopins Mutter gab den 1. März als Geburtstag an (Brief vom Februar 1837). In der Familie wurde Chopins Geburtstag immer am 1. März gefeiert. Vier Gedenkstätten verzeichnen den 22. Februar als Geburtstag: die Gedenktafeln am Geburtshaus in Żelazowa Wola, in der Taufkirche von Brochów, am Sterbehaus in Paris (Place Vendôme 12) und die Urne mit Chopins Herz in der Heiligkreuzkirche in Warschau.

Die polnischsprachige Geburtsurkunde verzeichnet Chopin als "Fryderyk Franciszek."

Chopin wurde am 23. April (Ostermontag) 1810 in der Kirche "Świętego Rocha i Jana Chrzciciela" () von Brochów getauft. Der lateinische Eintrag im Kirchenbuch () vermerkt als Namen "Fridericus Franciscus" und als Geburtsdatum den 22. Februar 1810. Eingetragen sind Chopins Vater als "Nicolai Choppen Gali" (), seine Mutter als "Justyna de Krzyżanowska" sowie "Franciscus Grembecki" und "Anna Skarbkówna" als Taufpaten.

Der Vermerk im Taufeintrag, , bedeutet, dass vor der zeremoniellen Taufe eine Nottaufe stattgefunden hatte, wahrscheinlich bei den Chopins in Żelazowa Wola; aber sie wurde nicht registriert. Auch die jüngste Schwester Emilia wurde am 15. Dezember 1812 notgetauft und am 14. Juni 1815 mit traditionellen Zeremonien getauft.
Franciszek, der zweite Vorname, war der ins Polnische übersetzte Vorname (François) des Großvaters Nicolas. Chopins Unterschrift war immer "FF Chopin."

Im September/Oktober 1810 zog die Familie nach Warschau in das Sächsische Palais, wo sich das Warschauer Lyceum befand und Nikolaus als Französischlehrer eingestellt wurde. Chopin und seine drei Schwestern erhielten eine gründliche Erziehung, die von Herzlichkeit und Toleranz geprägt war. Auf Wunsch seines Vaters erhielt Chopin bis zu seinem 13. Lebensjahr Hausunterricht. Seine ältere Schwester Ludwika erteilte ihm Polnisch- und Französischunterricht, ersten Klavierunterricht, anfangs auf einem Clavichord und nahm die Rolle einer zweiten Mutter ein. Sie selbst war Schülerin von Wojciech Żywny, einem aus Böhmen stammenden Pianisten und Klavierlehrer. Die Geschwister verband lebenslang eine innige Geschwisterliebe. 

Von 1816 bis 1822 war Żywny in Warschau der erste Klavierlehrer Fryderyk Chopins. Żywny legte die technischen Grundlage, leitete das sechsjährige Kind zu seinen ersten Kompositionen an und bereitete ihn auf seine ersten öffentlichen Auftritte vor. Später nahm auch seine jüngere Schwester Izabela bei Żywny Klavierunterricht.

1818 wurde der österreichische Hofkomponist Adalbert Gyrowetz (1763–1850) auf Chopin aufmerksam. Er führte ihn in die Kreise des österreichischen und polnischen Adels ein. In diesem Jahr spielte der Achtjährige anlässlich einer Wohltätigkeitsveranstaltung ein Konzert von Gyrowetz; ab diesem Zeitpunkt trat er in den Salons des polnischen Hochadels auf.

Chopins musikalisches Talent zeigte sich früh, er galt als Wunderkind und komponierte schon im Alter von sieben Jahren. Seine ersten Polonaisen B-Dur und g-Moll sind auf 1817 datiert und lassen eine außergewöhnliche improvisatorische Begabung erkennen.

1822 entließ Żywny den 12-jährigen Chopin aus seinem Unterricht mit dem Hinweis, „dass er ihm nichts mehr beibringen könne“.

Ab 1822 nahm Chopin Privatunterricht in Musiktheorie und Komposition bei dem aus Schlesien stammenden Deutschen Joseph Elsner (1769–1854), einem wichtigen Vertreter der polnischen Musik der Aufklärung und Frühromantik. Als Komponist, Dirigent, Musiktheoretiker, Publizist und Pädagoge nimmt Elsner als Vorläufer der polnischen Nationalbewegung eine bedeutende Stellung in der Musikgeschichte ein. Elsner war der Begründer des Warschauer Konservatoriums.

Anschließend besuchte Chopin bis 1826 das "Königlich-Preußische Lyzeum zu Warschau," gefolgt vom Studium an der Musikhochschule, die heute seinen Namen trägt, wo er von Elsner in Kontrapunkt, Generalbass und Komposition weiter unterrichtet wurde. Er komponierte eifrig und legte die Ergebnisse Elsner vor, der dazu feststellte: „Er meidet die ausgetretenen Pfade und gewöhnlichen Methoden, aber auch sein Talent ist ungewöhnlich.“

1827 fand der Umzug der Familie Chopin in den Pałac Czapskich () in Warschau statt.

Als Chopins Lehrer für Klavier und Orgel folgte Wilhelm Würfel (1790–1832), Professor an der Warschauer Musikhochschule und ab 1826 Kapellmeister der Wiener Oper. Er überredete Chopin nach seiner Abreise aus Polen dort ein öffentliches Konzert zu geben.

Ein Jahr später spielte Chopin öffentlich ein Konzert von Ferdinand Ries (1784–1838). Es entstanden unter Elsners Anleitung 1825 das Rondo in c-Moll Opus 1, 1826 das Rondo à la Mazur in F-Dur Opus 5, 1828 das Rondo für zwei Klaviere in C-Dur, und das Rondo à la Krakowiak in F-Dur Op. 14 für Klavier und Orchester. Chopins Interessen umfassten während seines Musikstudiums auch Geschichte, Politik, Folklore, Literaturgeschichte, Kunstgeschichte, Ökonomie, Philosophie, Literatur, Biologie und Medizin, Studienfächer, die er bei namhaften Professoren belegt hatte.

Zu Chopins Zuhörern und Förderern gehörten die reichsten polnischen Familien, wie Radziwiłł, Komar, Potocki , Czartoryski u. a., die später in Paris als Emigranten eine große Rolle in Chopins Laufbahn spielen sollten.

Ohne selbst zum hohen Adel zu zählen, hatte Chopin seit seiner Kindheit aufgrund seines musikalischen Talentes Umgang mit Adelsfamilien. Dies hatte neben seiner familiären Sozialisation einen wichtigen Einfluss auf seine Persönlichkeitsentwicklung. Zeit seines Lebens war ihm wichtig, sich in hohen Kreisen angemessen bewegen zu können, angesehen und geachtet zu sein.

Im Juli 1829 hatte Chopin sein Studium beendet. In Elsners Beurteilung heißt es: „Szopen Friderik. Besondere Begabung, musikalisches Genie“ ().

Chopins Opus 2, Variationen über das Duett „Là ci darem la mano“ () aus Mozarts Don Giovanni für Klavier und Orchester, entstand 1827/28 und wurde am 11. August 1829 von Chopin selbst im Wiener K. und K. Hoftheater nächst dem Kärntnerthore uraufgeführt. Die Leipziger "Allgemeine musikalische Zeitung" (AmZ) schrieb darüber:

Über die im Wiener Verlag Tobias Haslinger erschienene Notenausgabe brachte die AmZ vom 7. Dezember 1831 unter dem Titel "Ein Opus II." eine huldigende Rezension von Robert Schumann, die mit dem Ausruf „Hut ab, Ihr Herren, ein Genie“ eingeleitet wurde. Und weiter: „Chopin kann nichts schreiben, wo nicht spätestens nach dem siebten, achten Takt ausgerufen werden muss: Das ist Chopin!“ An anderer Stelle: „Chopins Werke sind wie unter Blumen verborgene Kanonen“, der später in abgewandelter Form zum Buchtitel „Unter Blumen eingesenkte Kanonen“ wurde, in dem Reinhard Piechocki Chopins Musik in dunkler Zeit (1933–1945) beschreibt.

Chopin war bereits in Polen ein gefeierter Musiker. Ein Teil seiner Etüden, einige Mazurkas und Polonaisen sowie seine beiden Klavierkonzerte entstanden in Polen, noch vor seinem 20. Lebensjahr.

Sein letztes Konzert in Polen gab er am 11. Oktober 1830 im Nationaltheater Warschau mit der Wiedergabe seines Klavierkonzertes e-Moll (Opus 11) und der "Grande Fantaisie sur des Airs Nationaux polonais pour le Pianoforté avec accompagnement d’Orchestre" () A-Dur (Opus 13) unter der Leitung des italienischen Komponisten Schweizer Herkunft Carlo Evasio Soliva (1791–1853). 1821 war Soliva zum Direktor des Institutes für Musik und Deklamation nach Warschau berufen worden, wo er den jungen Chopin kennengelernt hat. Er verblieb auch später noch in Paris mit Chopin und Sand in freundschaftlicher Verbundenheit.

In seiner Jugend war Tytus Woyciechowski (1808–1879) ein Schul- beziehungsweise Studienkollege Chopins am Warschauer Lyceum, darüber hinaus häufiger Gast der Familie Chopin. Viele seiner Jugendfreunde wie Tytus Woyciekowski, Jan Biafobłocki, Jan Matuszyński, Dominik Dziewanowski und Julian Fontana blieben ihm lebenslang verbunden. Woyciechowski hatte wie Chopin bei Vojtěch Živný Klavierunterricht. und studierte dann Jura an der Universität Warschau. Chopin widmete ihm sein Opus 2, die Variationen über Mozarts Duett "Là ci darem la mano." Im Jahre 1830 besuchte Chopin Woyciechowski auf dessen Anwesen in Poturzyn.

Chopins Freund Woyciechowski fungierte als Vertrauter während Chopins Liebesbeziehung zu der Sängerin Konstancja Gładkowska (1810–1889), die am Warschauer Konservatorium ausgebildet wurde. Im Jahr 1829, während eines Konzerts von Solisten der Universität, traf sie Fryderyk Chopin, dessen erste Liebe und Inspiration sie wurde. Als Chopin im Herbst 1830 das Land verließ, sang sie bei seiner Abschiedszeremonie. Die Korrespondenz zwischen den Liebenden endete nach einem Jahr.

Schon in seiner Jugend war Chopin viel gereist. Reisen waren bis an sein Lebensende Bestandteil seines Lebens. Seine Interessen waren breit gestreut. Er besuchte Museen, Ausstellungen, Konzerte und Opern, Bibliotheken, Universitäten und bewunderte Bauwerke und deren Architektur.

Chopin wusste, dass die wirklich großen Musiker nicht in Warschau und auch nicht mehr in Wien, sondern in Paris, der Hochburg für Künstler aus aller Welt im 19. Jahrhundert, zu finden waren. Die Größe eines Pianisten wurde damals am Erfolg in dieser Metropole gemessen. Erstmals schickten ihn seine Eltern und sein Lehrer 1829 für drei Wochen nach Wien, um seine künstlerischen Erfahrungen zu erweitern. Nach Angaben von Oskar Kohlberg nahm er bereits 1822 Deutschunterricht bei Pastor Jerzy Tetzner. Im November 1830 kam er voller Optimismus ein zweites Mal nach Wien.

Chopin verließ Polen am 2. November 1830 im Alter von 20 Jahren – auch auf Drängen seines Vaters vor der drohenden Revolte – und reiste über Kalisz, Breslau, Prag und Dresden nach Wien, wo er am 23. November 1830 ankam. Die Freunde überreichten ihm am letzten Abend einen Silberpokal mit polnischer Erde und sangen ihm am Stadtrand noch ein Abschiedslied, das folgenden Refrain enthielt:

Chopin kam nach einem viertägigen Aufenthalt in Breslau (mit einem Konzert am 8. November 1830) und einer Woche in Dresden mit seinem Freund Tytus Woyciechowski am 23. November 1830 in Wien an. „Wir haben auf dem Kohlmarkt, an der Hauptstraße, drei Zimmer gemietet, allerdings im dritten Stock, aber hübsch und vornehm und elegant möbliert“, bemerkte er in einem seiner Briefe. Die Monatsmiete war mit 25 Gulden günstig. Chopin versuchte vergeblich, den Musikverleger Carl Haslinger (1816–1868), der ihn freundlich empfing, zu bewegen, seine Kompositionen (Sonate, Variationen) herauszugeben. Der Wiener Musikgeschmack hatte sich geändert, sodass er während seines achtmonatigen Aufenthalts – im Gegensatz zu seinem ersten Aufenthalt in Wien – nur ein öffentliches Konzert am 11. Juni 1831 gab. Es fand im Kärntnertortheater im Rahmen der sogenannten Akademien statt. Chopin spielte in diesem Benefizkonzert ohne Honorar sein e-Moll Klavierkonzert. Die Presse lobte zwar sein Klavierspiel, aber nicht die Komposition.

Anfang Dezember 1830 erreichte Chopin in Wien die Nachricht, dass am Abend des 29. November 1830 die später sogenannte Novemberrevolution gegen die russische Herrschaft in Warschau ausgebrochen war. Woyciechowski verließ Wien, um am Aufstand teilzunehmen und hinterließ einen einsamen, von Heimweh geplagten Chopin. Nach einem Aufenthalt von über sieben Monaten, den Chopin als enttäuschend empfand, weil er zwar als Pianist Anerkennung fand, nicht jedoch als Komponist, und er von Sorge über das ungewisse Schicksal Polens geprägt war, verließ Chopin am 20. Juli 1831 Wien. Die "Große Emigration" () war eine Emigration polnischer politischer Eliten, die zeitgleich begann und bis 1870 andauerte. Diese "Große Emigration" aus Polen ging größtenteils nach Frankreich, vorwiegend nach Paris, und umfasste 5472 Emigranten. Fryderyk Chopins Musik, die sich von Volksquellen inspirieren ließ, spielte eine große Rolle in der Entwicklung des Nationalgeistes. Die Synthese der polnischen Geschichte, entwickelt von Joachim Lelewel (1768–1861), hatte großen Einfluss auf die Ideologie des polnischen demokratischen Lagers und auf die spätere Geschichtsschreibung. Die "Polnische Literarische Gesellschaft" wurde durch die Emigranten gegründet und zum politischen Zentrum der Exilpolen.

Die komplizierten Ausreiseformalitäten – Chopin war Pole und damit Untertan des russischen Zaren – brachten es mit sich, dass Chopin, trotz seines erstrebten Reisezieles Paris, auf Anraten eines Freundes einen Antrag auf einen Pass nach England stellte, weil er für die Einreise nach Paris weder von den österreichischen noch von den russischen Behörden Unterstützung erhoffen konnte. Sein Gesuch wurde von der russischen Botschaft in Wien abgelehnt. Es gelang ihm aber, ein Visum nach Frankreich zu erhalten. Sein Reisepass trug den Vermerk: „passant par Paris à Londres“ (). Er gab dies an, nachdem er von einem in diplomatischen Gepflogenheiten erfahrenen Freundes als endgültiges Reiseziel London – über Paris – angeben hat. Chopin sagte später in Paris öfter scherzhaft, er halte sich hier nur „en passant“ – auf der Durchreise – auf. Chopin hatte jedoch die Absicht, wenigstens drei Jahre in Paris zu bleiben. Er fuhr über Salzburg, München und Stuttgart, das er Anfang September 1831 erreichte und wo er von der Niederschlagung des polnischen Aufstandes und der am 8. September 1831 erfolgten Kapitulation Warschaus erfuhr. Er setzte die Reise über Straßburg nach Paris fort, wo er als ein völlig Unbekannter am 5. Oktober 1831 ankam. Er hatte lediglich ein Empfehlungsschreiben an die in Paris wirkenden Komponisten Luigi Cherubini (1760–1842) und Ferdinando Paër (1771–1839).

Paris sollte bis zu seinem Tod Mittelpunkt seines Lebens und Schaffens bleiben.

Der italienische Komponist und Hofkapellmeister Ferdinando Paër setzte sich bei den Behörden für Chopin ein, um eine Aufenthaltsgenehmigung zu erlangen. Chopin war von Paris fasziniert. „Die schönste aller Welten“, schrieb er in einem Brief nach Polen. Hier lernte er Friedrich Kalkbrenner (1785–1849) kennen, den er als Pianisten schätzte und der das Angebot machte, ihn drei Jahre lang zu unterrichten. Damit hätte sich Chopin auch verpflichtet, für diesen Zeitraum auf Auftritte zu verzichten. Kalkbrenner hatte das außergewöhnliche Talent Chopins erkannt und wollte im Musikbetrieb womöglich Konkurrenz vermeiden. Chopin lehnte den Vorschlag ab, in der Sorge, seine persönliche Art des Klavierspiels zu verlieren. Selbstbewusst stellte er fest, nichts werde „imstande sein, einen vielleicht allzu kühnen, aber edlen Willen und Plan, sich eine neue Welt zu schaffen, zu verwischen“. Chopins Briefen kann entnommen werden, dass er den Vermutungen seiner Freunde und seines Lehrers Elsner entgegentrat, Kalkbrenner habe es nur darauf abgesehen, sich damit zu schmücken, der Lehrer Chopins zu sein.

Bei Chopins Ankunft in Paris Anfang Oktober 1831 herrschte eine Zeit der wirtschaftlichen Krise, die immer wieder zu Demonstrationen führte. Unruhe, Not und Verbitterung kennzeichneten die Stimmung der Arbeiterklasse. Chopin war in einer schlechten körperlichen und seelischen Verfassung. In einem Brief an Titus Woyciechowski vom 25. Dezember 1831 beschrieb er seine Lage:

In Paris hatte Chopin bald nach seiner Ankunft am 5. Oktober 1831 erste Kontakte mit polnischen Emigrantenkreisen, die im Laufe der Zeit immer enger wurden. Er lernte Valentin Radziwiłł kennen, den Sohn des Fürsten Anton Radziwiłł (1775–1833), der ihn zu einer Gesellschaft im Hause Rothschild einlud, wo sich alles traf, was in Paris Rang und Namen hatte und er durch sein Vorspiel begeisterte. Auf dem Höhepunkt der Romantik arrangierten Marie und Camille Pleyel (1788–1855) berühmte „Salons“. Marie Moke-Pleyel (1811–1875), Konzertpianistin und durch ihre Affairen bekannte Ehefrau Camilles bis 1835, war Chopins erste Gastgeberin in ihren Salons in der "Rue Cadet Nr. 9." Hier fand am 25. Februar 1832 das erste Konzert Chopins in Paris statt. Es legte nach einem großen Erfolg den Grundstein für die erfolgreiche Karriere Chopins als Komponist, Pianist und vor allem als gesuchter Klavierlehrer von Angehörigen der Aristokratie. Das gedruckte Programm dieses „Grand Concert Vocal et Instrumental, donné par M. Frédéric Chopin, de Varsovie“ ist erhalten. Chopin spielte sein Klavierkonzert in e-Moll (nicht das in f-Moll, wie man lange Zeit glaubte), seine „Grandes Variations brillantes sur un thème de Mozart“ (die Variationen opus 2) und gemeinsam mit Kalkbrenner, Mendelssohn-Bartholdy, Hiller, Osborn und Sowenski, eine Polonaise für sechs Klaviere von Kalkbrenner. 

In den 18 Jahren, die Chopin von 1831 bis zu seinem Tode im Jahr 1849 im Wesentlichen in Paris verbrachte, wohnte er in neun verschiedenen Wohnungen:
Als Chopin nach Paris kam, bestand die musikalische Elite aus wenigen älteren Größen wie Luigi Cherubini, dem Leiter des Konservatoriums, Ferdinando Paër, Jean-François Lesueur, berühmten Opernkomponisten wie Daniel-François-Esprit Auber und Ferdinand Hérold und vor allem Gioachino Rossini (1792–1868) und Giacomo Meyerbeer. Beethoven, Weber und Schubert waren schon tot und die nächste Generation der künftigen großen Komponisten, Felix Mendelssohn Bartholdy, Robert Schumann, Franz Liszt, Giuseppe Verdi und Richard Wagner standen am Anfang ihres Schaffens.

Chopin bestritt seinen Lebensunterhalt in erster Linie mit Klavierunterricht. Zu Chopins Zeit war das Klavier ein weitverbreitetes Instrument, das vorwiegend von Frauen erlernt wurde. Seine große Beliebtheit seit Beginn des 19. Jahrhunderts, die von manchen Beobachtern wie Heinrich Heine in Paris oder Eduard Hanslick in Wien sehr kritisch beurteilt wurde, hat mehrere Gründe. Der Sozialphilosoph Max Weber sagt, dass das Klavier seinem „ganzen musikalischen Wesen nach ein bürgerliches Hausinstrument“ sei. Es eröffnet durch seine, aus der Sicht des Benutzers, einfache Tonerzeugung einen unmittelbaren Zugang, auch für Laien, zu verschiedenen Arten von Musik, vom einfachen Kinderlied bis zur virtuosen Konzertliteratur. Durch seinen frühzeitigen Verkehr in den Pariser Salons der Aristokratie und auch der Welt der Politik und Finanzen, die Protektion der polnischen adeligen Emigranten und nicht zuletzt aufgrund des durchschlagenden Erfolges seines ersten Konzertes in Paris (25. Februar 1832) war Chopin bald ein gesuchter, gut bezahlter Klavierlehrer, dessen Schülerinnen und Schüler vorwiegend aus den Kreisen des Adels und den einflussreichen Milieus von Politik und Finanzen stammten. Zu seinen Schülerinnen gehörten unter anderem die Töchter des Comte Charles-Joseph de Flahaut – Diplomat und Mitglied der Chambre des Pairs und berühmter Liebhaber Delfina Potockas, weiterhin die Comtesse Thérèse Apponyi – Ehefrau des österreichischen Botschafters, die Comtesse Élise de Perthuis – Ehefrau vom Adjutanten des Königs Louis-Philippe I., die Töchter des Duc Paul de Noailles, aber auch Baron Nathaniel Stockhausen und seine Frau.

Chopin hatte ab 1833 ein geregeltes Einkommen, das er durch Honorare für Konzerte und Kompositionen, die er manchmal gleichzeitig Verlegern in Frankreich, England und Deutschland anbot, zusätzlich aufstocken konnte.
Von der Entlohnung und dem Umgang mit seinen Kompositionen war er sehr enttäuscht, was aus seinen Briefen an seine intimsten Freunde folgt:
Chopin konnte sich eine private Kutsche und Bedienstete leisten und legte Wert auf teure Kleidung. Infolge seines aufwendigen Lebensstils sah er sich bald genötigt, statt vier nun täglich fünf Stunden zu unterrichten. Das Unterrichtshonorar betrug 20 Francs. (Zur Kaufkraft: Eine Kutschenfahrt durch Paris kostete 1 Franc). Bei Hausbesuchen verlangte er 30 Francs pro Stunde, was einem heutigen Wert von etwa 200 € entspricht. Eine Unterrichtsstunde dauerte 45 Minuten, die er jedoch bei seinen begabten Schülern verlängerte. Der Unterricht bei Chopin wurde zu einem Statussymbol. Er hatte in Paris etwa 150 Schüler. Chopins Einkünfte betrugen während seiner Berufstätigkeit 1833–1847 etwa 14.000 Francs pro Jahr, was im Jahre 2018 etwa 100.000 € entspräche. Damit konnte er seine Ausgaben gerade decken.

Insgesamt hatte Chopin etwa 30 öffentliche Auftritte. davon fünf in Warschau, zwei in Bad Reinerz, einen in Breslau, drei in Wien, einen in München, drei in London, je einen in Rouen, Manchester, Glasgow und Edinburgh. Er zog dabei in Paris, wo er zwölf Konzerte gab – im Gegensatz zu Liszt – die intime Atmosphäre der Pariser Salons den großen Konzertsälen vor. Chopin war sich bewusst, dass seine Innovationen es schwer haben würden, vor der breiten Masse zu bestehen. Von den Kreisen, die in den Salons verkehrten, wusste er, dass er den klassischen Kanon verlassen und mit traditionellen Hörgewohnheiten brechen konnte, weil diese offen für seinen Kompositionsstil waren.

Chopin wurde 1832 Mitglied der 1832 in Paris von den polnischen Emigranten Adam Jerzy Czartoryski (1770–1861) und Alexandre Colonna-Walewski (1810–1868) gegründeten "Société littéraire polonaise" (), unter der damaligen Präsidentschaft Graf Cezary Plater (1810–1869). 1854 wurde die Gesellschaft in Société historique et littéraire polonaise () umbenannt. Sie hat bis heute ihren Sitz in Paris, 6 Quai d’Orléans.

Zu Chopins Zeit wurden in Paris etwa 850 Salons geführt, halb private, in großen Häusern übliche Zusammenkünfte von Freunden und Kunstsinnigen, die sich mit gewisser Regelmäßigkeit, wöchentlich oder monatlich, zum Abendessen, Gesprächen und Musik trafen. Wer in diesen Zirkeln der Pariser Großbürger verkehrte, der hatte es zu gesellschaftlicher Reputation gebracht. Am wohlsten dürfte sich Chopin in den Künstlersalons gefühlt haben, wo er unter seinesgleichen verkehrte und Musizieren und Gedankenaustausch intellektuelles Niveau sicherten. Durch George Sand lernte er den Philosophen und Verfasser politischer Schriften Hugues Félicité Robert de Lamennais kennen, den er, ebenso wie die übrigen polnischen Immigranten, wegen seiner Haltung zur prekären Lage Polens schätzte.

Ein Zeichen für die gesellschaftliche Anerkennung, die Chopin in Paris genoss, ist die Einladung, der königlichen Familie, im Palast in den Tuilerien zu spielen. Er erhielt jedes Mal ein Geschenk, mit der eingravierten Inschrift „Louis-Philippe, Roi des Français, à Frédéric Chopin“ ().

Zu Chopins Freundeskreis zählten unter anderem die Dichter Alfred de Musset (1810–1857), Honoré de Balzac (1799–1850), Heinrich Heine (1797–1856) und Adam Mickiewicz (1798–1855), der Maler Eugène Delacroix (1798–1863), die Musiker Franz Liszt (1811–1886), Ferdinand von Hiller (1811–1885), der Cellist Auguste-Joseph Franchomme (1808–1884). Heinrich Heine schrieb im Jahre 1838 in seinem "Pariser Kunstbrief:" „Polen gab ihm seinen chevaleresken Sinn und den geschichtlichen Schmerz, Frankreich gab ihm seine Anmut, seine Grazie und Deutschland gab ihm den romantischen Tiefsinn.“
Von besonderer Bedeutung für Chopin war der gleichaltrige Julian Fontana (1810–1869), mit dem ihm seit der Kindheit eine lebenslange Freundschaft verband. Fontana schloss sich dem polnischen Novemberaufstand an und musste 1831 das Land verlassen. Er blieb zunächst in Hamburg und ließ sich 1832 in Paris als Pianist und Klavierlehrer nieder. Bis zu seiner Emigration in die Vereinigten Staaten (1841) war er für Chopin unentbehrlich als Kopist, Arrangeur, Sekretär und Impresario, der auch mit den Verlegern verhandelte und sich um die Alltagsgeschäfte seines Freundes kümmerte. Nach Chopins Tod veröffentlichte er – gegen den früher geäußerten Willen des Komponisten, aber mit Zustimmung der Familie – einige nachgelassene Werke mit den Opuszahlen 66–73 (erschienen 1855) und 74 (erschienen 1859). 

Im Mai 1834 reiste Chopin nach Aachen zum Niederrheinischen Musikfest. Er besuchte Köln, Koblenz und Düsseldorf, wo er Felix Mendelssohn Bartholdy begegnete. In der Folge konzertierte Chopin immer häufiger. Im Sommer reiste er nach Karlsbad, wo er seine Eltern traf. Nach seiner Weiterreise nach Dresden lernte er Maria Wodzińska (1819–1896) kennen. Er traf sie und ihre Familie 1836 in Marienbad wieder, wo sie zur Kur weilten und es – trotz des Protestes ihres Onkels – zur Verlobung von Chopin und Wodzińska kam. Marias Mutter bestand aber darauf, dass diese bis zum Sommer des darauffolgenden Jahres geheimgehalten wurde. 

1835 machte Chopin in Leipzig, vermittelt durch Felix Mendelssohn Bartholdy (1809–1847), Bekanntschaft mit Clara (1809–1896) und Robert Schumann sowie 1836 mit Adolph von Henselt (1814–1889) in Karlsbad. Nur ein Jahr später wurde die Verlobung mit Maria Wodzińska – wohl auf Drängen ihrer Eltern bezüglich des angeschlagenen Gesundheitszustands Chopins – wieder aufgelöst.

Trotz seiner Erfolge und starken Verwurzelung im kulturellen Leben von Paris, sowie eines großen Freundeskreises, der die polnischen Emigranten einschloss, sehnte sich Chopin nach Polen und seiner Familie und litt, wie aus seinen Briefen und Aussagen hervorgeht, unter ständigem Heimweh. Zeitlebens bestand Chopin auf der polnischen Aussprache seines französischen Nachnamens: . Sein Heimatgefühl und seinen Nationalstolz drückte er besonders in den 43 zu seinen Lebzeiten veröffentlichten Mazurken aus. Der Ausdruck der Sehnsucht, Nostalgie und Schwermut (polnisch "”żal”") wurde neben der Betonung des Polentums () zum wichtigsten Merkmal seiner Musik und machte ihn zu einem der am meisten gespielten Komponisten der Musikgeschichte. Als glühender polnischer Patriot stand er ganz auf der Seite des Widerstands gegen das zaristische Russland, das das sogenannte Kongresspolen besetzt hielt. Wenn vor Weihnachten ein polnischer Wohltätigkeitsbasar stattfand, half Chopin bei dessen Organisation. Sein Patriotismus und seine Sehnsucht nach Polen blieben die wichtigste Inspirationsquelle für die meisten seiner Kompositionen. Inspiriert durch den Aufstand entstand seine Revolutionsetüde (Opus 10 Nr. 12). Sie führten jedoch nicht zu politischer Aktivität. Er fühlte sich als Emigrant, aber in dem Sinne, wie sich alle Künstler der Romantik selbst sahen: Seine wahre Heimat war das ferne Arkadien. Der polnische Musikwissenschaftler weist darauf hin, dass Chopin an den Etüden Opus 10 vorwiegend in Wien gearbeitet habe und dass die Grundidee zur sogenannten Revolutionsetüde Opus 10/12 schon vor dem Stuttgarter Aufenthalt existiert habe. Zudem passe der Ausdruck von Kampf und Heroismus, den die Etüde ausstrahlt, nicht zu den Gefühlen, die eine Niederlage und Kapitulation auslösen.

Chopin fühlte sich zutiefst mit dem Christentum verbunden. In vielen Briefen an seine in Polen verbliebene Familie brachte er seine Sehnsucht nach den in polnisch-katholischer Tradition gefeierten Festen etwa zu Weihnachten oder Ostern zum Ausdruck – Traditionen, die den Franzosen völlig fremd waren, beispielsweise Bräuchen wie Pasterka am Heiligen Abend und dem Weihnachtsessen () mit polnischen Weihnachtsoblaten und polnischen Weihnachtsliedern (). Dabei werden die Oblaten im Familienkreis gegenseitig gebrochen, wobei man sich Glück und Segen für das kommende Jahr wünscht. Oder die Osterspeisensegnung, () am Karsamstag, bei dem die "Święconki" zur katholischen Pfarrkirche gebracht werden und dort gesegnet und mit Weihwasser besprengt werden, bevor man sie traditionell beim Osterfrühstück am Ostersonntag im Kreis der Familie verzehrt.

Obwohl Chopin Teile der Heiligen Schrift auswendig kannte, hat er seinen Glauben nicht mit Worten offenbart. Der Musikwissenschaftler Bohdan Pociej (1933–2011) interpretiert jedoch das Prélude E-Dur Opus 28 Nr. 9 als einen Ausdruck seiner religiösen Gefühle.

Chopin hatte durch seinen französischstämmigen Vater einen Anspruch auf die französische Staatsbürgerschaft, die er vier Jahre nach seiner Ankunft in Frankreich zusätzlich erhielt. Der Anspruch leitete sich vom Code Napoléon aus dem Jahre 1804 ab, in dem es in Artikel 10 hieß: „Jedes im Ausland geborene Kind eines Franzosen ist Franzose.“ (). In Artikel 12 hieß es ferner, dass „der Status einer Ausländerin, die einen Franzosen heiratet, dem Status ihres Ehemannes folge“ (). Durch diesen Umstand konnte es Chopin vermeiden, mit einem russischen Pass den Status eines politischen Flüchtlings zu erlangen, denn er war nach dem in Polen geltenden Territorialitätsprinzip Pole mit einem durch den russischen Zaren ausgestellten Pass. Dies hätte auch große verwaltungstechnische Probleme ergeben, Auslandsvisa von der russischen Botschaft zu erlangen. Sein erster französischer Pass wurde am 1. August 1835 ausgestellt.

Juristisch gesehen, besaß der Komponist zwei Staatsbürgerschaften. Nach dem Code civil war er durch den Vater automatisch Franzose, gleichzeitig als Bürger des Herzogtums Warschau auch Pole. Durch Kumulation beider Rechtstitel blieb der Status der doppelten Staatsbürgerschaft zeitlebens wirksam. Insofern war Chopin in Frankreich kein Emigrant wie viele seiner Freunde – auch wenn er sich selbst stets mit der Emigration identifizierte, denn seine persönliche Präferenz war unzweideutig. Als Bürger und Patriot war und blieb er Pole, der am tragischen Schicksal seines Volkes leidenschaftlich Anteil nahm.

Aus Anlass einer Reise von Chopin nach London erhielt dieser am 7. Juli 1837 einen von den französischen Behörden ausgestellten Reisepass. Es ist dort sowohl vermerkt, dass er „grau-blaue Augen“ hat (was nicht mit Delacroix Porträt des Komponisten übereinstimmt), als auch, dass Chopin „von französischen Eltern“ abstammt.

1837 erhielt Chopin über Graf Carlo Andrea Pozzo di Borgo (1764–1842) das Angebot, Hofpianist beziehungsweise Hofkomponist des russischen Zaren Nikolaus I. (1796–1855) zu werden. Hintergrund war ein Konzert, das Chopin im Mai 1825 auf einem Aeolomelodicum (einer Orgelvariante) vor seinem Vorgänger, Zar Alexander I. (1777–1825) noch in Warschau in der Dreifaltigkeitskirche gegeben hatte. Der Zar hatte ihn seinerzeit mit einem kostbaren Brillantring belohnt. Chopin habe nichts zu befürchten, versicherte Graf Borgo. Er gelte nicht als politischer Emigrant, da er das Land schon vor dem Novemberaufstand verlassen habe. Dass er es versäumt habe, sein Visum in die Heimat zu verlängern, würde kein Problem darstellen. Chopins wies das Angebot zurück und antwortete, er habe zwar nicht aktiv am Novemberaufstand teilgenommen, was er sehr bedaure. Aus der Ferne aber habe er immer die Partei der Aufständischen ergriffen und nur ihnen den Sieg gewünscht. Bis heute fühle er sich mit ihnen vereint in der Trauer über die Niederlage durch die „Moskaler“ (Russen). Zudem würde er es den Franzosen nie verzeihen, dass Frankreich Polen während des Novemberaufstands nicht zu Hilfe geeilt war. „Und die furchtbarsten Qualen mögen die Franzosen heimsuchen, die uns nicht zu Hilfe gekommen sind!“, schrieb er in sein Tagebuch.

Durch die Absage war ihm jedoch dauerhaft eine Rückkehr in das Kongresspolen verwehrt. Zudem verkaufte er den zaristischen Brillantring.

Chopin lernte die erfolgreiche Schriftstellerin "Amandine Aurore Lucile Dupin de Francueil" alias George Sand (1804–1876) im Hause Franz Liszts kennen. Seine erste Reaktion auf diese in Männerkleidung auftretende, Zigarren rauchende Frau war pure Ablehnung: „Was für eine unsympathische Frau sie doch ist! Ist sie denn wirklich eine Frau? Ich möchte es fast bezweifeln.“ „Sagen Sie, dieser Chopin, ist das ein Mädchen?“, antwortet die Schriftstellerin an einer anderen Stelle. Der 27-jährige Chopin 1837 war wegen einer unglücklichen Liebe zu der damals 18-jährigen Maria Wodzińska in eine Lebenskrise geraten. Maria Wodzińska und die 33-jährige George Sand waren jedoch grundverschieden. Wodzińska war ein femininer Typ, George Sand eine selbstbewusste, provozierende und widersprüchliche Persönlichkeit. Ihr neunjähriges Verhältnis mit Chopin, eine Liebesbeziehung, geprägt von Vertrauen, gegenseitiger Wertschätzung, Zärtlichkeit aber auch von Eifersucht, Hass und Misstrauen, lässt viele Fragen offen.

George Sand war eine leidenschaftliche Frau, der eine ganze Reihe zumeist jüngerer Männer regelrecht verfielen. Ob das Leidenschaftliche auch auf Chopin zutraf, lässt sich nicht sicher beantworten. George Sand hat nachträglich zahlreiche an sie gerichtete Briefe vernichtet, sodass hierfür keine eindeutigen Belege überliefert sind. Deutliche Hinweise gibt jedoch ein zweiunddreißig Seiten langer Brief George Sands an Chopins Freund Wojciech Grzymała (1793–1871) von Ende Mai 1838, in dem sie ihn um Rat bat. Sie befand sich in einem Zwiespalt, weil sie noch eine Beziehung zu dem Schriftsteller Félicien Mallefille unterhielt aber andererseits eine Zuneigung zu Chopin gefasst hatte über dessen Gefühle zu ihr sie im Unklaren war. Es muss aber auf jeden Fall zu einer näheren Begegnung der beiden gekommen sein.

Im November 1838 machte George Sand mit ihren Kindern Maurice und Solange eine Reise nach Mallorca. Der Entschluss hierzu beruhte auf ärztlichem Rat, denn man erhoffte eine Verbesserung des Gesundheitszustands von Maurice, der an Rheumatismus erkrankt war. Da Chopin an Tuberkulose litt und sich eine Besserung durch ein milderes Klima erhoffte, schloss er sich der Familie an. Während Maurice sich erholte, stand für Chopin der Aufenthalt in der Kartause von Valldemossa in der Serra de Tramuntana unter keinem guten Stern. Die Räumlichkeiten waren kalt und feucht, das Wetter sehr schlecht. Hinzu kam die ablehnende Haltung der Mallorquiner gegenüber dem nicht verheirateten Paar. Schon bald zeigten sich bei Chopin alle Anzeichen einer Lungenentzündung, wie George Sand später schriftlich beklagte. Am 13. Februar 1839, nach dreieinhalb Monaten, verließen sie und Chopin die Insel. Trotz der relativen Kürze des Aufenthaltes, hatte er sowohl Chopin als auch George Sand stark mitgenommen. Aber anders als George Sand, die ihre zum Teil negativen Erfahrungen in dem 1842 erschienenen Bericht "Un hiver à Majorque" (deutsch "Ein Winter auf Mallorca") aufarbeitete, reagierte Chopin weniger nachtragend. Der oft zitierte Brief vom 3. Dezember 1838 über die ärztliche Kunst der Mallorquiner ist möglicherweise weniger boshaft gemeint als vielmehr Zeugnis seiner Selbstironie, deren Chopin sich oft bediente, um mit seiner chronischen Erkrankung umzugehen.

Auf Mallorca wurden die 24 Préludes Opus 28 fertiggestellt, zu denen das sogenannte Regentropfen-Prélude zählt. Er hatte sich extra einen Pleyel-Flügel nach Mallorca liefern lassen, der im Januar 1839 eintraf. Im Kontext dieser Musikstücke wird gern darauf verwiesen, wie unwohl Chopin sich in der unbehaglichen Umgebung des Klosters gefühlt hat. Ein Brief vom 28. Dezember 1838 belegt diese Annahme. Chopin schrieb an Julian Fontana:

Nach Aussagen von George Sand litt Chopin in jener Zeit oft unter Halluzinationen. Einer seiner Biografen, der Musikwissenschaftler Bernard Gavoty (1908–1981), berichtet, wie Chopin im August 1848 im britischen Manchester ein Konzert abbrach und regelrecht floh, weil er um sich seltsame Geschöpfe sah. Chopin selbst schrieb in einem Brief an Sands Tochter über diesen Zwischenfall: „Das Allegro und das Scherzo hatte ich mehr oder weniger korrekt vorgespielt, und als ich gerade mit dem Marsch beginnen wollte, sah ich plötzlich aus dem halb geöffneten Piano diese verfluchten Kreaturen, die mir auch in dem düsteren Kartäuser-Kloster erschienen waren.“ Spanische Neurologen kommen zu dem Schluss, dass sich die heftigen Visionen am besten mit der sogenannten Schläfenlappen-Epilepsie erklären lassen.

Nach der Rückkehr von Mallorca nahm Chopins Leben einen geregelten Verlauf. Die Winter waren dem Unterrichten, den gesellschaftlichen Veranstaltungen, dem Kulturleben, den Salons und den wenigen eigenen Auftritten gewidmet, die mehrmonatigen Sommeraufenthalte verbrachte das Paar bis einschließlich 1846 meist auf George Sands ererbtem Landsitz in Nohant-Vic. Chopin verbrachte insgesamt sieben Sommer in Nohant-Vic: 1839 und 1841 bis 1846. Dort fand Chopin Zeit und Ruhe fürs Komponieren. Er empfing Freunde und debattierte etwa in Gesprächen mit Delacroix ästhetische Fragen. Er studierte dort das Belcanto-Repertoire des 18. Jahrhunderts und Luigi Cherubinis (1760–1842) "Cours de contrepoint et de fugue" (). Eine große Anzahl von Werken entstand in dieser letzten mit George Sand verbrachten Zeit.

Jedes Jahr finden in Nohant „Les fêtes romantiques de Nohant“ (deutsch „das Festival der Romantik von Nohant“) und „Le Nohant festival Chopin“ (deutsch „Das Chopin Festival Nohant“) statt.

Die Beziehung zwischen Chopin und George Sand endete 1847. Am 28. Juli 1847 schrieb George Sand ihren letzten Brief an Chopin. Er endet mit den Worten:
Der Grund für die Trennung ist nicht eindeutig geklärt. Weder Chopin noch George Sand haben dazu Stellung bezogen. Bekannt ist, dass George Sand zu dieser Zeit sehr konfliktfreudig auftrat. Dass ihre Tochter Solange sich dem mittellosen Bildhauer Auguste Clésinger (1814–1883) zugewandt hatte, wollte George Sand keinesfalls akzeptieren. Auch Chopin waren Details zu Clésingers unstetem Leben zu Ohren gekommen, er riet Solange ebenso eindringlich ab – aber letztlich hielt er an seiner Freundschaft zu Solange fest, akzeptierte ihren unbedingten Entschluss, Clésinger zu heiraten und zur Not mit der herrischen Mutter zu brechen. Das war der Auslöser für Familienstreitigkeiten, bei denen es zu Handgreiflichkeiten zwischen dem Sohn Maurice und Clésinger beziehungsweise der dem Sohn beispringenden Mutter kam. Was im Einzelnen vorfiel, ist nicht gesichert, weil es hierüber von George Sand und Solange unterschiedliche Berichte gibt. Chopin, von der Nachricht brüskiert, dass Solange sich heimlich verlobt hatte, hielt gleichwohl seine Freundschaft zu ihr aufrecht.

Chopin stellte Solange seine Kutsche für ihre vorzeitige Abreise aus Nohant in das 300 km entfernte Paris zur Verfügung, als ihre Mutter sie des Hauses verwies. Solange war mittellos und von George Sands Geld abhängig. Die Hilfe Chopins für Solange war für George Sand eine ungeheure Provokation.

George Sand und Chopin sahen sich noch einmal zufällig am 4. März 1848 bei Charlotte Marliani. Beim Verlassen des Hauses traf Chopin auf George Sand. Er teilte ihr mit, dass ihre Tochter vier Tage zuvor Mutter geworden war.

In der "Geschichte meines Lebens" schreibt George Sand:

Im Laufe des Jahres 1847 verschlechterte sich Chopins Gesundheitszustand ernstlich. Zielführende Therapieverfahren gegen die Tuberkulose waren seinerzeit noch unbekannt. Chopins Schülerin Jane Stirling (1804–1859), die bis zum Zerwürfnis Chopins mit George Sand eher im Hintergrund für Chopin gewirkt hatte, nahm sich nach der Trennung des Paares der Anliegen Chopins an und versuchte dessen immer größer werdende materielle Not zu lindern.

Am 16. Februar 1848 gab Chopin in der Salle Pleyel in der "Rue Rochechouart" (heute: "Rue de Rochechouart") Nr. 20 sein letztes Konzert in Paris. Der wichtigste Teil dieses Konzertes war die Barcarolle.

Der französischen Februarrevolution 1848 entging Chopin durch einen sieben Monate dauernden Aufenthalt in Großbritannien, den Jane Stirling, die dem schottischem Adel entstammte, organisiert hatte. Die Strapazen dieser Reise führten später dazu, dass den Schwestern Stirling von weiten Kreisen der Chopin-Verehrer eine Mitschuld an seinem frühen Ende angelastet wurde, da die Stirlings ihn geradezu durch ihre sehr ausgedehnte schottische Verwandtschaft auf Besuche jagten. Er trat vor Queen Victoria (1819–1901) und Prince Albert (1819–1861) auf und reiste weiter nach Schottland, wo er in Edinburgh und Glasgow Konzerte auf Broadwood-Flügeln gab.

In London, wo Chopin im Saal von Broadway spielte, musste er eine Treppe heraufgetragen werden, da er bereits zu schwach zum Treppensteigen war. Sein letztes Konzert in Britannien war am 16. November in der Londoner Guildhall, wo er spielte, obschon er sehr krank war.
Auf der Reise, die er nach Schottland per Eisenbahn unternehmen konnte, traf er auf abendlichen Diners die berühmte schwedische Opernsängerin Jenny Lind (1820–1887). Chopin hatte sie zuvor in Paris kennengelernt. Nach Chopins Tod ging sie auf Tour quer durch das von Russland besetzte Polen, wo sie mit italienischen Texten versehene Mazurkas sang. Sie nannte es "Folio von Mazurkas von Chopin." Die erste, die Mazurka Nr. 16 Opus 24 Nr. 3 As-Dur, enthält die Zeilen: „Mio povero cuore, Dimentica il dolore … Rimani fedele al tuo amore, il fedele ama che non muore mai!“ ().

Am 23. November kehrte er nach Paris zurück und nahm seine Unterrichtstätigkeit wieder auf, was ihm wegen seiner nachlassenden Kräfte, aber auch wegen nachlassender Nachfrage aufgrund der Unruhen allerdings nur sehr unregelmäßig gelang. Chopin zog aus der Wohnungsnachbarschaft von George Sand am Square d’Orléans aus und wohnte eine Weile in der damals mehr ländlichen Umgebung des Palais de Chaillot.
Die Pariser Freunde und Jane Stirling, wahrscheinlich mit Jenny Linds Unterstützung, verschafften ihm dann seine letzte Wohnung am Place Vendôme 12, in der er am 17. Oktober 1849 starb. Sie haben auch dafür gesorgt, dass Chopin in seinen letzten Lebensmonaten keinen materiellen Mangel litt, zumal er wegen seines Gesundheitszustandes weder unterrichten noch komponieren konnte und deshalb fast mittellos war.

Die große Wohnung in der Nähe des Louvre war zuvor die Residenz des Zarenbotschafters gewesen.
Anfang Oktober 1849 verfasste Chopin sein Testament. Er wollte, dass alle unvollendeten und noch nicht veröffentlichten Partituren verbrannt werden sollten.

Bei einer Körpergröße von 1,70 m wog er nur 45 kg. Der Gedanke an den Tod begleitete ihn Zeit seines Lebens. Sein Vater, seine jüngste Schwester und zwei engste Freunde verstarben alle an Tuberkulose, derjenigen Krankheit, die auch sein Ende bedeuten sollte.

Wenige Tage vor Chopins Tod am 17. Oktober 1849 kaufte Jane Stirling seinen Pleyel-Flügel. Chopin starb völlig mittellos im Alter von 39 Jahren, wahrscheinlich an Tuberkulose. Wissenschaftler untersuchten 2017 das in Cognac eingelegte Herz von Chopin und stellten fest, dass Chopin an einer Herzbeutelentzündung (Perikarditis) litt, die infolge einer Tuberkulose entstand. Daneben wird ärztlicherseits über weitere mögliche Todesursachen spekuliert. Am 15. September empfing er die Sterbesakramente.

Zum Zeitpunkt seines Todes gegen zwei Uhr morgens wachten enge Freunde, unter anderem auch George Sands Tochter Solange Clésinger, an seinem Bett. Am darauffolgenden Morgen nahm Auguste Clésinger Chopin die Totenmaske ab und fertigte einen Abguss von dessen linker Hand an. Jane Stirling bezahlte alle Kosten seines Begräbnisses, alle Reisekosten von Chopins Schwester Ludwika und ihrer Tochter Magdalena, und kam für die Kosten auf, um sein Klavier nach Warschau zu bringen. Sie kaufte alle restlichen Möbel und Wertgegenstände Chopins, einschließlich seiner Totenmaske.

Zu Chopins Totenmesse am 30. Oktober um 11 Uhr in der Kirche La Madeleine kamen etwa 3000 Trauergäste. Als der Sarg von der Krypta in die Oberkirche getragen wurde, spielte das Orchester der "Société des Concerts du Conservatoire" () unter der Leitung von Narcisse Girard (1798–1860) eine von Napoléon-Henri Reber (1807–1880) hergestellte Orchesterfassung des Trauermarsches aus Chopins Klaviersonate in b-Moll Opus 35. Weiterhin erklangen auf der Orgel, gespielt von Louis James Alfred Lefébure-Wély (1817–1869) die Préludes Nr. 4 in e-Moll und Nr. 6 in h-Moll aus Opus 28. Den Abschluss bildete Mozarts Requiem, ein Wunsch Chopins. Die Bestattung erfolgte auf dem Pariser Friedhof Père Lachaise. Liszt schreibt in seinem Chopinbuch, Chopin habe ihm gegenüber geäußert, er wollte wie zu einem Konzertauftritt bekleidet neben dem Grab seines engen Freundes Vincenzo Bellini bestattet werden, dessen Musik er sehr geschätzt hat. Chopins Schwester Ludwika übergab Jane Stirling den Silberpokal mit der polnischen Erde, den er bei seiner Ausreise aus Polen zum Abschied geschenkt bekommen hatte, worauf Jane die Erde auf dem Grab verstreute. Diese Sitte wird oft bei Polen begangen, die im Ausland begraben werden. Chopin hatte Jane Stirling erzählt, dass sie der einzige Mensch sei, der seinen richtigen Geburtstag kenne. Sie schrieb ihn auf und platzierte ihn in einer Schachtel, die mit ihm begraben wurde.
Auf Chopins ausdrücklichen Wunsch wurde sein Herz von seiner Schwester Ludwika heimlich in die polnische Heimat gebracht, wo sie es in Warschau in ihrer Wohnung aufbewahrte. (Zum weiteren Schicksal von Chopins Herz: ).

Am Jahrestag seines Todes, dem 17. Oktober 1850, enthüllte Auguste Clésinger das von ihm gestaltete Grabmal mit dem Medaillon von Fryderyk Chopin.

Chopin vereinigte in sich Talente als Komponist, Pianist, Improvisateur, Virtuose und Klavierpädagoge. Chopin war vielseitig begabt. Bekannt war vor allem sein schauspielerisches, komödiantisches Talent, bekannte Personen zu imitieren – eine Fähigkeit, mit der er Freunde oft unterhielt, gespeist aus einer außergewöhnlichen Beobachtungsgabe. Chopins Schauspielertalent blieb eine seiner gesellschaftlichen Domänen. 1829 parodierte er in Wien gerne das Auftreten und Benehmen österreichischer Generäle und hatte damit den gleichen Erfolg wie als Pianist. Er nahm auch Zeichenunterricht bei Zygmunt Vogel (1764–1826) – und nutzte das Zeichnen nicht nur für die Anfertigungen von Karikaturen.

Alle Kompositionen Chopins schließen das Klavier ein. Die meisten sind Klaviersoli, obwohl er auch zwei Klavierkonzerte, Kammermusik und Vertonungen polnischer Lieder komponierte. Zu den von ihm bevorzugten Formen gehören Mazurken, Walzer, Nocturnes, Polonaisen, Etüden, Impromptus, Scherzi, und Sonaten, wobei einige erst nach seinem Tod veröffentlicht wurden. Die Originalpartituren sind weltweit verstreut. Das polnische Chopin-Institut hat sie als Faksimiles gesammelt, um sie einheitlich vorzustellen.

Als "Xiao Bang" ( beziehungsweise "siu bong" (蕭 邦)) wird er in China gefeiert, als "Syo-Paeng" (쇼 팽) in Korea, als "Shopan" (ショパン) in Japan, als "šubān" (شُوبَان)‎‎ in arabischen Ländern, "Šopén" (Шопе́н) in Russland, "Schopen" (Σοπέν) in Griechenland, Szopen {შოპენი} in Indien und "Shopen" (שאפען) in Israel.

Chopins Kompositionen entwickelten sich häufig aus Improvisationen. George Sand beschreibt, wie heftig und oft verzweifelt Chopin darum kämpfte, seine auf dem Klavier schon vollständig ausgeführte Idee auf dem Papier festzuhalten. Das Improvisieren hatte zu Chopins Zeiten einen viel höheren Stellenwert als heute, sowohl in der Ausbildung als auch im Konzertgeschehen. Das Fantasieren auf dem Klavier war früher Gegenstand höchster Bewunderung. Chopin gehörte zu den besten Improvisatoren seiner Zeit. In seinen Konzerten lagen Improvisationen als umjubelter Höhepunkt immer am Ende.

Sein Spiel galt als technisch anspruchsvoll und von einer hohen Individualität geprägt; seine eigenen Auftritte waren bekannt für Nuancierung und Feingefühl. Chopin schätzte vor allem die Interpretation seiner Werke durch Liszt, der ein hervorragender Blattspieler war. Lediglich bei Chopins Etüden stieß Liszt an seine Grenzen. Chopins Etüden waren seit Jahren die ersten Klavierstücke, die der hoch trainierte junge Liszt nicht auf Anhieb spielen konnte. Die unterschiedlichen Spielweisen derselben Musik waren ein Quell der Freude für beide Pianisten und ihren Freundeskreis – solange die Freundschaft zu Liszt bestand.

Sie endete, als Liszt in einer Urlaubsabwesenheit den Schlüssel zu Chopins Wohnung hatte und diese Wohnung für eine Begegnung mit Marie Moke-Pleyel benutzte. Chopin war empört über dieses Verhalten seines Freundes, da er das Ehepaar Pleyel als seine Freunde betrachtete.

Seine wenigen Kunstlieder waren nicht für die Veröffentlichung bestimmt und erlangten keine Bedeutung. Hingegen hatte er einen Sinn für die Klangfarbe des Violoncellos. Ihm widmete er vier Werke: die "Introduction et polonaise brillante" Opus 3, das Klaviertrio Opus 8 und die "Sonate für Violoncello und Klavier" Opus 65; mit Auguste-Joseph Franchomme (1808–1884) schrieb er das "Grand Duo" über Themen aus Giacomo Meyerbeers (1791–1864) Oper Robert le diable (, ohne Werknummer).

Schon Elsner hatte ihm die Oper nahegebracht. Carl Maria von Webers "Der Freischütz" begeisterte ihn. Mit Vincenzo Bellini befreundet, liebte Chopin vor allem die italienische Oper. Liedformen und singbare Melodien sowie die Verzierungskunst des Belcanto spielten daher auch in seinen Instrumentalwerken eine große Rolle. Typisch für ihn wurde eine ausgeschmückte Melodik, die mit ihrer relativ freien rhythmischen Entfaltung deutlich vom Vokalen mitgeprägt worden ist. Die feingliedrigen und chromatischen Fiorituren (Verzierungen) seines Klaviersatzes sind vom Gesang beeinflusst.

Markant in seinem Klavierwerk sind neben den Fiorituren die auseinander- und wieder zusammenlaufenden Rhythmen. Dies war ein musikalisches Konstrukt, das zwar Chopin nicht erfunden hatte, das er aber am Klavier äußerst populär machte. Die „souplesse“, die Leichtigkeit des Spieles, die er als Klavierlehrer forderte, zeigt sich im Ergebnis des Trainings gerade in der Gleichmäßigkeit solcher rhythmisch-harmonischer Zierden. Die Musik, der Takt läuft – im ersten Moment als fehlerhaft wahrgenommen – auseinander, wird dann aber sofort wieder geschickt zusammengeführt.-->

Chopin übernahm – und überhöhte – die brillante Virtuosenliteratur. Der Einfluss von Ignaz Moscheles (1794–1870), Friedrich Kalkbrenner (1785–1849), Carl Maria von Weber, Johann Nepomuk Hummel (1778–1837) und (der ebenfalls von Elsner ausgebildeten) Maria Szymanowska (1789–1831) ist deutlich. Von Elsner in konzentrierter und akribischer Arbeit unterwiesen, feilte Chopin manchmal jahrelang an Kompositionsentwürfen. „Er […] wiederholte und änderte einen Takt hundertmal, schrieb ihn nieder und strich ihn ebenso oft wieder aus, um am nächsten Tag seine Arbeit mit der gleichen minutiösen, verzweifelten Beharrlichkeit fortzusetzen.“

Zur Melodik und zum virtuosen Klaviersatz seiner Kompositionen kommt eine hochexpressive Harmonik, die souverän mit Chromatik, Enharmonik und alterierten Akkorden umgeht und neuartige Wirkungen hervorruft. Sein Lehrer Elsner bestärkte Chopin in der Hinwendung zu polnischen Volkstänzen und Volksliedern. Ihre Elemente finden sich nicht nur in den Polonaisen, Mazurkas und Krakowiaks, sondern auch in anderen Werken ohne namentlichen Hinweis. Chopins Leitbilder waren Johann Sebastian Bach (1685–1750) und Wolfgang Amadeus Mozart (1756–1791).
Elsner hielt ihm vor, dass er keine Opern schreiben würde. Chopin entgegnete, dass Komponisten Jahre darauf warten müssten, bis ihre Opern aufgeführt würden. Wäre er in Polen geblieben, hätte er sich vermehrt den Kompositionen für Gesang gewidmet.

Zeitgenossen Chopins beschreiben sein Spiel, beziehungsweise seine Interpretation als veränderlich, niemals fixiert, sondern spontan. „Das gleiche Stück von Chopin zweimal zu hören, war sozusagen zwei verschiedene Stücke zu hören“. Fürstin Maria Anna Czartoryska (1768–1854) beschrieb es so:

Chopin unterrichtete zwar vorwiegend Schülerinnen und Schüler, die aus Kreisen des wohlhabenden Adels kamen, achtete aber auch bei der Auswahl auf deren Talent. Nur wenige von Chopins Schülern wurden später Konzertpianisten. Einer seiner besten, vielversprechendsten Schüler, Carl Filtsch (1830–1845), starb schon als Jugendlicher. Franz Liszt unterrichtete ihn eine Zeit lang in Vertretung von Chopin. Von ihm ist später folgender Ausspruch überliefert: „Wenn der Kleine auf Reisen geht, mach’ ich die Bude zu“. Chopin selbst äußerte sich nach dem Vortrag eines seiner Klavierkonzerte: „Mein Gott, welch ein Kind! Kein Mensch hat mich jemals so verstanden …“. Erfolgreich wurde Marie Moke-Pleyel, die – fast gleichaltrig – zwar nicht direkt als Chopins Schülerin, aber als Kennerin seiner Musik noch in hohem Alter als Professorin am Königlichen Konservatorium Brüssel lehrte.

Chopin brachte seinen Schülern seine sehr persönliche Auffassung von Musik bei. Die folgende Aussage, Jean-Jacques Eigeldinger (* 1940) nennt sie eine „profession de foi esthétique“ (deutsch: ästhetisches Glaubensbekenntnis), machte Chopin anlässlich eines Gespräches über ein Konzert, das Liszt am 20. April 1840 bei Érard gab.

Chopin hinterließ nur Skizzen zu einer Lehrmethode, die erst spät veröffentlicht wurden, zuerst von Alfred Cortot (1877–1962) und in jüngster Zeit von Jean-Jacques Eigeldinger, der auch in seinem Werk "Chopin vu par ses élèves" () alle die mit diesem Thema zusammenhängenden Themen behandelt.

Chopin bestand auf einem nach zeitgenössischen Maßstäben niedrigen Klavierschemel, sodass sich die Ellbogen auf gleicher Höhe mit den weißen Tasten befanden. Der Pianist sollte alle Tasten an den beiden Enden der Klaviatur erreichen können, ohne sich zur Seite zu beugen oder seine Ellbogen bewegen zu müssen. Seine Schüler berichteten über die von Chopin empfohlenen Übungen. Demnach hatte Chopin seine „Normallage“ der Finger auf dem Klavier beschrieben. Hierzu gehört der Daumen der rechten Hand auf „e“, der zweite Finger auf „fis“, der dritte auf „gis“, der vierte auf „ais“ (=„b“) und der fünfte Finger auf „h“. Chopin machte, ohne seine Handposition zu ändern – also aus seiner Referenzposition heraus – Übungen, um die Gleichheit und Unabhängigkeit der Finger zu vermitteln.

Oft gebrauchte er die Wendung „dire un morceau de musique“ (), ganz im Sinne des Konzeptes der „Klangrede“ der historischen Aufführungspraxis nach Nikolaus Harnoncourt (1929–2016). Voraussetzung dafür war Chopins unkonventionelle Schulung der Finger. Chopin versuchte nicht, die natürliche Ungleichheit der Finger zu beheben, sondern erkannte die Eigenheit eines jeden Fingers als Quelle immenser Klangvielfalt. So schätzte er den Daumen als „stärksten und freiesten Finger“, den Zeigefinger als „wichtigste Stütze“, den Mittelfinger als „großen Sänger“ und den Ringfinger als „seinen schlimmsten Feind“. Da der Ringfinger wie ein „siamesischer Zwilling“ an den Mittelfinger gebunden ist, versuchte er die Fingerfolge 3–4–3 in schnellen Passagen möglichst zu vermeiden.

Die im Sinne eines gefühlvollen Anschlages notwendige lockere Handhaltung erklärt Chopins Vorliebe für schwarze Tasten. Sie ermöglicht den längeren Mittelfingern eine angenehme Position als Voraussetzung für ein ebenso virtuoses wie expressives Spiel. Diese Charakteristik etablierte selbst die Etüde im Konzertsaal.

Er lehnte jegliche Manierismen und pathetischen Bewegungen ab. Ein Pianist solle nicht sich und seine Gefühle den Zuhörern präsentieren und sich damit in den Vordergrund stellen, sondern das Werk. Dabei muss das Gefühl immer in die Interpretation einfließen.

"In dieser" [normalen Handlage] "mussten seine Schüler zunächst Übungen zur gleichmäßigen Ausbildung und zur Unabhängigkeit der Finger ausführen. Dann ließ er staccato spielen, um die Leichtigkeit des Spiels zu erreichen; hierauf staccato-legato, schließlich betont legato. Er lehrte eine eigene Methode, um die Hand im Augenblicke des Untersetzens des Daumens bei Tonleitern und Arpeggienpassagen in möglichst gleicher, ruhiger Haltung zu bewahren. Diese äußerst ruhige Hand erschien ihm vornehmlich erstrebenswert und das einzige Mittel, ein gleichmäßiges und ruhiges Spiel zu erzielen, selbst dann, wenn es sich darum handelte, beim Daumenuntersatz den Daumen unter den vierten oder den fünften Finger unterzusetzen."

Chopin empfahl seinen Schülern, die Finger frei und leicht fallen zu lassen, die Hände in der Luft und ohne Schwere zu halten, dann Tonleitern zu spielen und dabei jede dritte oder vierte Note betonen. Er war mehr als hartnäckig mit denen, die sich darin nicht wohl fühlten. Chopin gebrauchte oft den Begriff „souplesse“, eine Geschmeidigkeit, die es unablässig zu trainieren galt. Ebenso regte er seine Schüler an, die Stücke zu singen. Wenn sie nicht verstanden, was er damit meinte, schickte er sie in die Oper, um sich das italienische Belcanto anzuhören. Er empfahl, nicht mehr als drei Stunden pro Tag zu üben. Dabei sollte Bach nie fehlen. Wenn man ein Stück auswendig spielen konnte, hielt er die Schüler an, es bei absoluter Dunkelheit zu üben, um durch nichts vom Klang abgelenkt zu werden.

Im Gegensatz zur Chopininterpretation des ausgehenden neunzehnten und der 1. Hälfte des 20. Jahrhunderts, die weitgehend von der Intuition und dem persönlichen musikalischen Geschmack der Interpreten abhing, hat man sich gleichzeitig mit der Erarbeitung von zuverlässigen Urtexten auch bemüht, grundlegende Elemente der Aufführungspraxis auf eine wissenschaftliche Grundlage zu stellen. Durch das Erforschen der historischen und soziokulturellen Gegebenheiten ist so auch die Aufführungspraxis objektiver geworden, zumal auch die Kenntnis der alten Instrumente, ihres Baues und ihres von den heutigen Instrumenten verschiedenen Klanges, mit einbezogen wird.

Vom Komponisten selbst mit Bezug auf einen bestimmten Notenwert wie „Halbe“, „Viertel“ oder „Achtel“ angegebene Metronomzahlen sind für den Interpreten wertvoll als Richtschnur für das von ihm zu wählende Tempo. Von Frédéric Chopin sind nicht viele eigenschriftliche Metronomzahlen überliefert. Chopin schwankte gelegentlich zwischen metrischer und mathematischer Schreibweise der Metronomzahlen. Chopin hat Walzer und Polonaisen geschrieben, die beide im 3/4-Takt stehen. Zum Beispiel ist das Tempo der Polonaise Opus 40, Nr. 2 mit "Allegro maestoso" angegeben, das des Walzers op. 69, Nr. 1 mit "Lento." Die Kombination aus Tempoangabe und Taktart für sich betrachtet würde bedeuten, dass die Polonaise deutlich schneller gehen müsste als der Walzer. Doch das Gegenteil ist der Fall: die Polonaise wird üblicherweise langsamer gespielt als der Walzer. Dies rührt daher, dass das standardmäßige Grundtempo () eines Walzers erheblich schneller ist als das einer Polonaise. Aus diesem Beispiel geht hervor, dass der Typus des betreffenden Stücks für die korrekte Interpretation der Tempobezeichnung eine entscheidende Rolle spielt. Hinzu kommen die Vortragsbezeichnungen, die meist in italienischer Sprache gehalten sind und in der Liste musikalischer Vortragsbezeichnungen verzeichnet sind.

Um das "tempo rubato" (, meist abgekürzt "rubato") zu erklären, sagte Chopin, dass die linke Hand der Kapellmeister () sei, während die rechte Hand "ad libitum" () spielen dürfe. Er meinte damit das seit dem 17./18. Jahrhundert auch von Mozart beschriebene, sogenannte "gebundene rubato:" „die Modifizierung einzelner Notenwerte bei gleichbleibender Grundbewegung der Begleitung.“. Um dies zu gewährleisten stand auf Chopins Klavier immer ein Metronom bereit, das erst 20 Jahre zuvor von Johann Nepomuk Mälzel (1772–1838) erfunden worden war. Diese Technik, bei der die Melodiestimme vorauseilt oder zurückbleibt, also nicht synchron mit der Begleitung läuft, ist besonders mit Chopins Namen verbunden. Die andere Form des rubato, das sogenannte "freie rubato" ist eine Veränderung des Tempos im Ganzen (Melodie und Begleitung zusammen) und wird bei Chopin durch die Bezeichnungen ritardando (allmähliche Verlangsamung des Tempos) und rallentando (Nachlassen des Tempos) angezeigt. Carl Czerny beschreibt es in seiner Pianoforte-Schule als ein bewusstes Langsamerwerden und Beschleunigen in beiden Händen. Wenn das Rubato übertrieben wird, besteht die Gefahr, dass die Spielweise unnatürlich wirkt und ins Kitschige oder Sentimentale abgleitet. Dies gilt allgemein auch für die Behandlung der Dynamik (Veränderung der Lautstärke) und Agogik (Veränderung des Tempos).

Die Verzierungen in Chopins Klavierwerken werden häufig falsch ausgeführt, weil die Zeichen falsch interpretiert werden oder man die musikwissenschaftlichen Forschungsergebnisse nicht zur Kenntnis nimmt. Auch zahlreiche handschriftliche Eintragungen in die Exemplare seiner Schüler, die früheren Pianistengenerationen nicht zur Verfügung standen, haben geholfen Chopins Intentionen zu verstehen. In einigen Verzierungen lehnt sich Chopin an die barocke Tradition an. Es gibt bei Chopin im Wesentlichen folgende Verzierungen:

Bei einem Arpeggio () verband Chopin den Beginn mittels einer gestrichelten Linie zur Note der anderen Hand, wodurch der Einsatz des Arpeggios im Takt erfolgte.

Beim Spiel seiner eigenen Stücken war Chopin streng. Er erlaubte anderen normalerweise keine Abweichung von seinem Notensatz. Es ist jedoch bekannt (Beispiele: Nocturne Opus 9 Nr. 2, Berceuse Opus 57), dass Chopin seinen Schülern erlaubte, Varianten in seiner Musik zu spielen. So ist eine Variante zu dem Nocturne Nr. 9 Nr. 2 überliefert, die zum Zeitpunkt ihrer Komposition um 1828/29 noch gar nicht hätte gespielt werden können, da das hier verwendete hohe „As“ zum Einstieg in den Abwärtslauf auf den Klaviaturen von 1831 noch gar nicht vorhanden war und erst Ende der 1830er Jahre in Erweiterung der Skala vom hohen „G“ auf das hohe „A“ oder „C“ auf die Flügel kam. Als der junge Norweger Thomas Tellefsen (1823–1874) seine Variante 1840 spielte, hatte Chopin nichts dagegen einzuwenden. Chopin lehnte es ab, dass seine persönliche Art des Spiels nachgeahmt wurde. Er versuchet vielmehr bei seinen Schülern stets den Sinn für eine mitschöpferische Interpretation zu wecken. „Legen Sie doch Ihre ganze Seele hinein“, lautete eine seiner häufigsten Unterrichtsanweisungen, wobei er Wert darauf legte, dass seine Schüler zuvor eine formale Analyse der Komposition vollzogen.

In der Geschichte der Klaviermusik gab es keinen Komponisten, der dem Pedalgebrauch soviel Aufmerksamkeit gewidmet hat wie Chopin und viele seiner Werke genau mit Pedalzeichen versehen hat. Die Sorgfalt, mit der Chopin vorging, zeigt, dass das Pedal für ihn ein wesentliches Element der Klanggestaltung war. „Das rechte Klavierpedal [aber] war für ihn integrierender Teil der Interpretation.“ Umso erstaunlicher ist es, dass dieses Thema weder in der Literatur über aufführungspraktische Fragen des Chopinspiels, noch im Unterricht ausreichend behandelt wird. Der Beginn des Einsatzes des Forte-Pedals wird durch und das Ende durch notiert.

Chopins Pedalisierung dient als wichtiger Hinweis für die klangliche Gestaltung des Werkes. Nicht ein dichter, durch ständiges „Nachtreten“ gewährleisteter, lückenloser Pedalgebrauch schwebte Chopin vor, sondern ein punktueller, harmonie- und taktbezogener Pedaleinsatz. Im Gegensatz zur starken Wirkung der Dämpfer des heutigen Klaviers, bei dem der Ton nach Loslassen der Taste oder des Pedals vollständig abgedämpft wird, hatten die Töne des Klaviers der Chopinzeit einen Nachklang, sodass es bei beim Aufheben des Pedals vor der neuen Harmonie nicht zu einer störenden größeren klanglichen Lücke kam. Es ist außerdem zu beachten, das aus Chopins Pedalisierung hervorgeht, dass er in manchen Fällen Mischklänge beabsichtigte, die auch beim damaligen Klavier Mischklänge waren und keineswegs mit dem Argument vermieden werden dürfen, das Klavier habe sich seit der Chopinzeit stark verändert. In dieser Hinsicht verstoßen Herausgeber einiger Chopinausgaben, die die klangliche Sauberkeit in den Vordergrund stellen, manchmal gegen die Absicht des Komponisten.
Wiederholungen hat Chopin oft nicht erneut pedalisiert. Wenn ganze Passagen unbezeichnet bleiben, muss das nicht heißen, dass das Pedal nicht verwendet wird.

Viele moderne Pianisten ignorieren die oft subtilen und präzisen Pedalangaben Chopins oder halten sie für nicht verbindlich. Chopin sagte seinen Schülern: „die richtige Anwendung desselben [des Pedals] bleibt ein Studium für das Leben.“. Die Klaviere um 1846 waren weniger resonant und der Spieler konnte das Pedal für eine ganze Phrase gedrückt halten, um der Musik einen schwebenden Klang zu geben. Dies hat sich durch den modernen Klavierbau verändert. Im Jahr 1844 wurde auf der Pariser Ausstellung ein neues Pedal von Xavier Boisselot (1811–1893) vorgestellt, das im Gegensatz zum rechten Pedal nicht alle Dämpfer abhebt. Dieses Pedal wurde „Sostenuto-Pedal“ () oder Tonhaltepedal genannt und ermöglicht es, ausgewählte Töne (meistens als Orgelpunkte im Bass) zu halten, während andere davon unbeeinflusst bleiben. Im Klavierwerk Chopins spielt dieses Pedal keine Rolle. Chopin setzte auch das „Una-corda-Pedal“ („Leise-Pedal“) ein, ohne es jedoch in seinen Manuskripten anzugeben.

Vor seiner Pariser Zeit kannte Chopin nur Flügel mit der „Wiener Mechanik“ (Prellzungenmechanik) und der entsprechenden leichten Spielart. Die Flügel, die er in Paris antraf, hatten die „englische“ Stoßzungen­mechanik, die im Prinzip der Mechanik Bartolomeo Cristoforis (1655–1731) entsprach und seit den Anfängen des Klavierbaus im Einsatz war. Die Flügel von Pleyel schätzte Chopin wegen ihrer leichtgängigen Mechanik und sie kamen mit ihrem, wie Liszt es ausdrückte, „silbrigen, ein wenig verschleierten Ton“ seinem Klangideal am nächsten.

Chopin lehnte das auf große und laute Show-Effekte zielende Bühnengeschehen nach Art Niccolò Paganinis (1782–1842) und Franz Liszts für sich selbst ab. Ein entscheidender Fortschritt war die Erfindung einer Repetitionsmechanik () durch Sébastien Érard (1752–1831) im Jahr 1821, die ein schnelles Repetieren (wiederholtes Anschlagen) von Tönen auch im forte () () ermöglicht. Diese Erfindung, die für die Weiterentwicklung des Klavierspiels von großer Bedeutung werden sollte, war für das Spiel Chopins unerheblich, weil die schnelle Repetition im mittleren dynamischen Bereich () den Chopin in seinem Spiel bevorzugte, durch die Mechanik der Flügel von Pleyel gewährleistet war. Im Gegensatz zu den Instrumenten von Érard, wurde bei Pleyel die doppelte Auslösung erst nach 1863 eingeführt.

Trotz seines großen Ansehens sah sich Chopin zu seinen Lebzeiten auch negativer Kritik ausgesetzt.

In Deutschland griff Ludwig Rellstab (1799–1860), Chopins Werke an. Die Variationen über "Là ci darum la mano" brandmarkte er als „slawischen Vandalismus“. Nach der Veröffentlichung der Mazurken Opus 7 schrieb Rellstab in seiner Zeitschrift "Iris" vom 12. Juli 1833 beispielsweise über Chopin:
François-Joseph Fétis (1784–1871) schrieb über Chopins Pariser Début in der Revue Musical vom 3. März 1832 eine Rezension, in der er nicht mit Kritik an Chopins eigener Wiedergabe seines e-Moll Klavierkonzerts sparte:

Robert Schumann, wenngleich ein großer Verehrer Chopins, schrieb 1840 über die b-Moll-Sonate Opus 35 (Sonate mit dem Trauermarsch), dass sie überhaupt keine Musik sei: „So fängt nur Chopin an und so schließt nur er: mit Dissonanzen durch Dissonanzen in Dissonanzen. […] Dass Chopin es Sonate nannte, möchte man eher eine Caprice heißen, wenn nicht einen Übermut, dass er gerade vier seiner tollsten [Anm.: im Sinne von „wahnsinnigen“] Kinder zusammenkoppelte.“ Chopin komponierte den Trauermarsch, nachdem seine Verlobung mit Maria Wodzińska gelöst war. Chopin fiel darauf in eine tiefe Lebenskrise.

Und Claude Debussy (1862–1918), ebenfalls ein Enthusiast Chopins, schrieb ein halbes Jahrhundert später über die Sonate in h-Moll, dass diese nur aus „Skizzen“ bestünde. Dabei war Debussy ein Bewunderer Chopins und widmete ihm seine zwölf Etüden.

Bei Liszt taucht der Verdacht des Künstlerneids auf, wenn er über Chopin schreibt: „Il a craché sur l’assiette pour en dégoûter les autres“ ().

Hector Berlioz (1803–1869), der Virtuose des Orchesters, kritisierte: „Bei Chopin konzentriert sich das ganze Interesse auf den Klavierpart; das Orchester ist in seinen Klavierkonzerten nichts anderes als eine kalte, fast überflüssige Begleitung.“ Als Chopin im Wiener Theater am Kärntnertor gastierte, wurde das Ungleichgewicht zwischen Klavier und Orchester auch optisch deutlich. Die Bühne war allein für den Solisten reserviert, das Orchester spielte – wie bei einer Opernaufführung – unten im Orchestergraben. Man kann heute fragen, ob es im Sinne einer historisch orientierten Aufführungspraxis der Musik Chopins gerecht wird, wenn sie in großen Sälen vor einem nach Tausenden zählenden Publikum aufgeführt wird.

Chopin wurde auch als Pianist kritisiert. Weil sich sein Spiel vorwiegend im mittleren Bereich der Dynamik bewegte, warfen ihm Zeitgenossen, die ihn in einem seiner wenigen Konzerte in größeren Sälen erlebt hatten vor, er würde zu leise spielen. Chopin trat meistens vor einer kleineren Zuhörerschaft in den Salons auf. Sein mehr zurückhaltendes, aber nuancenreiches, dem emotionalen Gehalt der Musik nachspürendes Spiel, stand im Gegensatz zu dem auf äußere Wirkung angelegten Spiel anderer Künstler, wie zum Beispiel Liszt, der die Effekte, die Paganini auf der Geige erzielte, auf das Klavier übertrug. Chopin versagte diesen Künstlern nicht seine Bewunderung, ging aber seinen eigenen Weg des verinnerlichten, auf Effekte verzichtenden Spiels.

Chopin spielte nicht gern vor einem großen anonymen Publikum, das ihn ängstigte. Er befürchtete, dass die breite Masse – im Gegensatz zum aufgeschlossenen Publikum in den Salons – seine Musik verurteilen würde. Hinzu kommt, dass zu seiner Zeit die Konzertflügel noch nicht die Klangfülle moderner Instrumente hatten und den Pianisten, um gehört zu werden, zu einem Spiel zwangen, das seinem Naturell und auch dem Geist des dargestellten Werkes (etwa Chopins "Berceuse") widersprach. In den 18 Jahren seiner Pariser Zeit gab er nur insgesamt zehn Konzerte.

Normalerweise war Chopin sehr beherrscht, bei einem weniger begabten Schüler konnte er einen Wutausbruch haben, bei dem auch ein Stuhl zu Bruch gehen konnte oder er mit den Füßen zu trampeln anfing. Solche Unterrichtsstunden nannte seine Schülerin Zofia Rosengardt (1824–1868), die heimlich in Chopin verliebt war, „leçons orageuses“ (). Später war Chopin ihr Trauzeuge bei ihrer Eheschließung mit Józef Bohdan Zaleski (1802–1886). Zofia nahm ab November 1843 regelmäßig wöchentlichen Klavierunterricht. Sie beschreibt in ihrem Tagebuch die Persönlichkeit und das Verhalten ihres Lehrers in alltäglichen Situationen aus der Perspektive einer Schülerin gegenüber dem von ihr verehrten Meister. Indem sie ein farbenfrohes Porträt von Chopin nachzeichnet, bringt sie seine Sensibilität und auch seine Stimmungsschwankungen und sein stürmisches Temperament zum Ausdruck.

Bronisław von Poźniak (1887–1953) verfasste seine Schriften zum Klavier- beziehungsweise Chopinspiel in der 1. Hälfte des 20. Jahrhunderts. Er betont die Wichtigkeit der Entspannung und das Vermeiden unnötiger Bewegungen. Poźniak sieht sich als Bewahrer der Tradition des polnischen Chopinspiels, wie es von Karol von Mikuli (1819/1821–1897), einem Schüler Chopins, in Lwów (Lemberg) gelehrt wurde.

Poźniak wendet sich gegen die übermäßige Betonung der technischen Seite des Klavierwerks Chopins, wie sie vor allem in den übertriebenen Tempi mancher Chopinspieler zum Ausdruck kommt. Dieses Zurschaustellen der technischen Fertigkeiten, wie es besonders bei der Interpretation der Etüden beobachtet wird, sei eine Verfälschung des Geistes der Chopinschen Musik, die sich nach Poźniak durch Noblesse, Poesie, Natürlichkeit, Fehlen jeglicher Sentimentalität und tief empfundener Liebe und Verbundenheit zur polnischen Heimat und dem polnischen Volk auszeichnet.

Mikuli gilt als Gründer der Lemberger Klavierschule. Chopin hat Mikuli unter seinen Schülern ausgezeichnet, indem er ihn mit der Redigierung seiner Werke beauftragt hatte. Mikuli hat zu Lebzeiten von Chopin gedruckte Klavierwerke aufbewahrt, nach denen er bei ihm 1844–1847 in Paris studierte. Chopin hat eigenhändig die Druckfehler beseitigt und mehrfach auch Korrekturen am Notentext vorgenommen oder sie seinem Schüler, mit dem ihn eine feste Freundschaft verband, diktiert. Bei seinen Schülern strebte er die Organisiertheit des Rhythmus an, verwarf jegliche rhythmische Schlampigkeit. Er wollte den Schülern ein melodisches Spiel („cantabile“, ) beibringen, das einen gellenden „klopfenden“ Ton ausschloß. Härte und Grobheit im Spiel nervten Mikuli. Nach Worten von Mikuli „sang in Chopins Spiel die musikalische Phrase mit solcher Klarheit, dass jede Note zur Silbe wurde, jeder Takt zum Wort, jede Phrase zum Gedanken, eine Sprache ohne Schwulst, einfach und gleichmäßig“.

Aus Chopins Schriftverkehr sind Streitereien mit Verlegern in Frankreich, England und Deutschland überliefert, wie sich seine Kompositionen im Detail erster Drucksätze unterscheiden – ein umfangreiches Forschungsgebiet für Chopin-Spezialisten. Chopin las normalerweise die Vordruck-Abzüge akribisch und korrigierte umfangreich, und änderte nicht nur das von den Notenstechern nach seiner teils recht flüchtigen Notenschrift Gestochene, sondern auch seine eigene Musik teils noch nachträglich, was zu einigem Ärger der Verleger führte.

„Urtext“-Ausgaben sind „textkritische Werkausgaben“. Frühere Herausgeber hatten im 19. Jahrhundert ein breites Musikpublikum zu erziehen. Sie vollführten mancherorts Änderungen in Kompositionen, wodurch oft zu viel des Guten getan und Werke regelrecht korrumpiert worden sind. Chopins Werken ging es da nicht anders. Andererseits waren Notentexte aber auch „gebrauchsfertig“ zu machen, denn auch die schriftliche Fixierung ist einem Wandel unterworfen. Hinzu kommt, dass „Schreibfehler“ – subtil – zu korrigieren sind, die auch großen Komponisten oder Notenstechern unterliefen und dabei herauszufinden ist, was der Komponist tatsächlich ausdrücken wollte.

Die Paderewski-Ausgabe
Die Chopin-Edition Paderewskis „Complete works“ von 1953 bis 1964 hat heute vor allem noch historischen Wert. Sie wurde durch die modernen Urtextausgaben (Henle, PWM (Jan Ekier) Peters) abgelöst.

Die Cortot-Ausgabe

Die Ausgabe der Klavierwerke Chopins von Alfred Cortot in einer „Edition de travail avec commentaires D’Alfred Cortot“ ist textlich durch die modernen Urtext-Ausgaben überholt. Sie war aber mit ihren ausführlichen Kommentaren eine bei Pianisten beliebte und weit verbreitete Ausgabe. Sie wird heute aber von der Klavierpädagogik und Musikwissenschaft wegen ihrer Subjektivität kritisch beurteilt.

Die Poźniak-Ausgabe

Die alte Chopinausgabe von Hermann Scholz der Edition Peters, Leipzig wurde 1949 aus Anlass des 100. Todesjahres Chopins von Bronisław von Poźniak neu herausgegeben. Es fand keine größere Revision des Textes statt. Pożniak versah die Ausgabe mit einem aus der Erfahrung des konzertierenden Pianisten und Pädagogen gewonnenen neuen Fingersatzes, der in bewusster Einfachheit zu manchen Spielerleichterungen führt. Er verzichtet konsequent auf den Fingerwechsel bei repetierten Noten und Verzierungen, wie das schon Ferruccio Busoni gefordert hatte. Poźniaks sparsame Pedalisierung, die nicht selten im Gegensatz zu Chopins eigenen Angaben steht, hat als Richtlinie die Klarheit in der Harmonik und Linienführung, die nicht verwischt werden soll. Dabei verkennt er jedoch, dass Klangmischungen von nichtverwandten Akkorden von Chopin manchmal beabsichtigt sind und dies auch in der originalen Pedalisierung zum Ausdruck kommt. Pożniak verfolgte mit seiner Ausgabe, wie auch in seinen Schriften, das Ziel, das Chopinsche Klavierwerk einem möglichst großen Kreis von Spielern, auch dem Laienspieler, näher zu bringen. Seine Vorgehensweise entspricht ganz dem Chopinschen Ideal der „simplicité“(deutsch Einfachheit) und der von ihm oft im Unterricht gebrauchten Spielanweisung „facilement“ (deutsch mit Leichtigkeit, ungezwungen), wie sie von seinen Schülern überliefert wurde. ( s. im Literaturverzeichnis die Werke von Jean-Jacques Eigeldinger).

Die Askenase-Ausgabe

In den Jahren 1946 bis 1969 gab Stefan Askenase (1896–1985) ein Reihe von Klavierwerken Chopins bei der Edition Heuwerkemeijer, Amsterdam heraus:


Von Chopin sind etwa 230 Werke überliefert.

Die Ballade bezeichnete ursprünglich eine Gattung des Tanzliedes. In der deutschsprachigen Literatur wird seit dem 18. Jahrhundert ein mehrstrophiges, erzählendes Gedicht als Ballade bezeichnet. Als Erster übertrug Chopin die epische Form der Ballade auf die Klaviermusik. Als neue Gattung kennzeichnet sie die Verknüpfung kontrastierender, erzählender Melodien nach musikalischer Gesetzmäßigkeit, die Sonatensatzformen nicht ausschließt. Dass Gedichte von Adam Mickiewicz und Juliusz Słowacki (1809–1849) Chopin zu den vier Balladen angeregt haben, wird vermutet, ist aber nicht erwiesen.

Als „Barkarolen“, (von ), bezeichnete man ursprünglich Gesänge venezianischer Gondolieri. Die Themen in Chopins Werk erinnern an Gondoliere-Melodien; sie werden von einer gleichmäßig fließenden Begleitung getragen.

Erhaltene Skizzen seiner Berceuse () geben einen seltenen Einblick in Chopins Schaffensweise. Neben dem Basso ostinato kennzeichnet eine persönliche Besonderheit Chopins Wiegenlied in Des-Dur Opus 57 (1844): Etwa die Hälfte der Werke Chopins tragen Widmungen. Mit Ausnahme der Berceuse und eines Walzers hatte Chopin jeweils einem Menschen stets nur ein einziges Stück gewidmet. Die Berceuse und der Walzer sind "Mademoiselle Elise Gavard" gewidmet, einem 1842 neugeborenen Kind, das mit seiner Mutter, einer Freundin George Sands, und Chopin im Sommerurlaub in Nohant war. Die kleine Elise Gavard ist der einzige Mensch, dem zwei Stücke Chopins gewidmet sind – darunter ihr eigenes Wiegenlied. Chopin spielte das luftig-zarte Stück bei all seinen (wenigen) öffentlichen Konzerten.

Alle 27 Etüden (12 Etüden Opus 10, 12 Etüden Opus 25, 3 Etüden „Méthode des Méthodes“) sind mit einer Spieldauer von zwei bis vier Minuten kurze Stücke.
Die Etüde opus 10/12, die sogenannte Revolutionsetüde, zählt zu den bekanntesten Werken Chopins. Seine Etüden sind jedoch, genau wie die Etüden von Franz Liszt, im Gegensatz zu denen anderer Komponisten, wie Carl Czerny (1791–1857) – Konzertetüden. Problematische Nachschöpfungen sind die Studien über die Etüden Fryderyk Chopins von Leopold Godowsky (1870–1938), weil sie durch die Betonung des rein Technischen der Intention Chopins widersprechen.

Schuberts und Chopins Impromptus () sind wir so wenig Stegreifstücke wie ihre Walzer. Bekannt wurde vor allem das Fantaisie-Impromptu (komponiert 1834, erschienen 1855 als opus 66). Chopin soll es nicht zur Veröffentlichung freigegeben haben, weil er nach dem Entstehen des Stücks erkannt habe, dass das Hauptthema des ersten Teiles eine große Ähnlichkeit mit dem Thema des Vivace aus dem Impromptus Opus 89 von Ignaz Moscheles aufwies.

Musikalisch und pianistisch reicher sind die Impromptus Fis-Dur Opus 36 (1840) und Ges-dur Opus 51 (1843). Das Impromptu As-Dur Opus 29 (1837/38) mit seinem reich verzierten Mittelteil in f-Moll bleibt im Rahmen virtuoser Salonmusik.

In seinen beiden Klavierkonzerten verwendet Chopin typisch polnische Elemente und stilisiert in den Schlusssätzen die Tänze Krakowiak (e-Moll-Konzert), Mazurka und Oberek (f-Moll-Konzert; Oberek von ). Beide Konzerte sind Jugendwerke, Chopin komponierte sie kurz hintereinander in den Jahren 1829 und 1830, wobei das heute als Nr. 2 bezeichnete Konzert in f-moll Opus 21 das zuerst komponierte ist. Es wurde aber nach dem e-Moll-Konzert veröffentlicht und gilt somit als das zweite Klavierkonzert Chopins.

Das Konzertrondo für Klavier und Orchester Opus 14 in F-Dur (1828) und der Schlusssatz des e-Moll-Konzerts sind Krakowiaks, polnische Volkstänze, die aus der Region um Krakau stammen.

Chopin vertonte im Laufe von knapp zwei Jahrzehnten 19 damals aktuelle, romantische polnische Gedichte. 17 davon wurden aus dem Nachlass 1859 von Julian Fontana (1810–1869) als Opus 74 herausgegeben. 2 Lieder tragen keine Opuszahl. Die Spannweite der Lieder reicht vom launigen Gesellschaftslied bis zur Rhapsodie, von der balladenartigen Dumka bis zur lyrischen Romanze.

Die Mazurka (; ) war, anders als die Polonaise, Anfang des 19. Jahrhunderts eine recht neue Gattung der Klaviermusik, die sich aber schnell in ganz Europa etablierte. Chopin kannte sie als Folklore – "Kujawiak" ist die langsame, "Oberek" die schnellere Variante des Mazurek – von seinen Sommeraufenthalten auf dem polnischen Land. Der Begriff leitet sich von der polnischen Landschaft Masowien () ab. Mit 15 Jahren schrieb er seine erste Mazurka (B-Dur K. 891–895). Stilistische Merkmale seiner Mazurkas sind Chromatik, modale Wendungen und zuweilen ein Bass mit Quint-Bordun (tiefer Halteton zur Begleitung einer Melodie). Chopin veröffentlichte 43 Mazurkas, die größtenteils in Gruppen zusammengefasst sind (Opus 6, 7, 17, 24, 30, 33, 41, 50, 56, 59, 63, dazu die Mazurken a-Moll „Gaillard“ und a-Moll „France Musicale“). (Die Ausgabe des Henle Verlages, München, verzeichnet insgesamt mit den nachgelassenen 57 Mazurken). In der Regel bildet das letzte Stück einen größeren Abschluss. Der Mittelteil der fis-Moll-Polonaise und der Schlusssatz des f-Moll-Konzerts haben den Charakter von Mazurken. Die zahlreichen Mazurken verkörpern eine Art musikalisches Tagebuch des Komponisten.

Eine andere von Chopin weiterentwickelte Form sind die 21 Nocturnes (). Er baut mit ihnen auf den Nocturnes des Iren John Field (1782–1832) auf, der großen Einfluss auf ihn hatte. Chopins Werke weisen dabei einen größeren harmonischen Gehalt, abwechslungsreichere Rhythmik und eine geschmeidigere Melodik auf. Die Melodien orientieren sich am Stil des Belcanto Gioachino Rossinis (1792–1868) und Vincenzo Bellinis. Ab Opus 27 veröffentlichte Chopin die Nocturnes durchweg paarweise. Sie sind miteinander durch ihren antithetischen (gegensätzlichen) Charakter verbunden.

(Anfangstakte des Nocturne Opus 9 Nr. 2):

Chopin schuf insgesamt 17 Polonaisen (von ). Zunächst orientierte er sich an den Polonaisen Michał Ogińskis (1765–1833), Josef Elsners, Johann Nepomuk Hummels und Carl Maria von Webers.
Die Polonaise (; , ) ist ein polnischer Nationaltanz, bei dem Tanzpaare im Reigen und moderaten Tempo nach bestimmten Figuren würdevoll und majestätisch zu einer Musik im Polonaise-Rhythmus durch den Saal schreiten. Zum Tempo schreibt Bronisław von Poźniak: „Ich weiß positiv, daß Chopin seinen Schülern beim Studium der Polonaisen ausdrücklich das Zählen des Dreivierteltaktes in der Sechsteiligkeit empfahl. Damit bewies er, daß er das Tempo auf keinen Fall anders haben wollte, als man es beim Tanzen nahm.“ Chopins Polonaisen waren nicht zum Tanzen gedacht. Sein frühestes, als Druckwerk erhaltene Stück ist eine Polonaise in g-Moll (K. 889) von 1817. Einige Polonaisen ohne Opuszahl sind Jugendwerke, die er später nicht veröffentlichen wollte, weil sie ihm zu schlicht waren. Seine späteren, in Paris entstandenen Werke dieser Gattung machen sich von den Vorbildern frei. Die Polonaise As-Dur (Opus 53, "Héroïque") gilt als „heimliche Nationalhymne“ Polens.

Die 24 Préludes Opus 28 entstanden 1839 und früher. Keßlers Etüden Opus 31 sind Frédéric Chopin gewidmet, der ihm zunächst im Gegenzug seine Préludes () Opus 28 widmen wollte. Im März 1839 schrieb jedoch Chopin in einem Brief an seinen Freund Julian Fontana, das Werk solle Camille Pleyel gewidmet werden. Für die deutsche Erstausgabe, die bei Breitkopf & Härtel erschien, kam diese Nachricht jedoch zu spät, sodass diese eine Widmung an Joseph Christoph Kessler (1800–1872) enthält. Nur die französische Erstausgabe ist Pleyel zugeeignet. Wie im Wohltemperierten Klavier durchlaufen die Préludes alle Dur- und Moll-Tonarten, aber nicht in chromatischer Reihenfolge, sondern im Quintenzirkel, wobei bei Bach nach einer Durtonart die gleichnamige Molltonart kommt (C-Dur/c-Moll), bei Chopin die parallele Molltonart (C-Dur/a-Moll).
Sie sind nicht nacheinander entstanden, sondern (auf Mallorca) nach langem Erproben nachträglich in den Ablauf der Quintenfolge gebracht worden. Erstaunlich an diesen „Adlern ohne Flügel“ ist, dass der "„rein mechanischen Ordnung eine geistige, stimmungsmäßige entspricht: die 24 Stücke kann man hintereinander spielen, als habe man ein geschlossenes Gesamtwerk vor sich“."

Chopin schrieb fünf Rondos:
Rondo in c-Moll, Opus 1, Rondo à la mazur in F-Dur, Opus 5, Rondo in Es-Dur, Opus 16 (auch "Introduction et Rondeau" genannt), Rondo in C-Dur, Opus posth. 73 (Versionen für Piano solo und zwei Pianos) und Rondo à la Krakowiak, Opus 14. Robert Schumann hörte 1836 zum ersten Mal das Rondo à la Mazur und er nannte es „lieblich, enthusiastisch und voller Anmut. Wer Chopin noch nicht kennt, sollte am besten mit diesem Stück mit ihm Bekanntschaft machen“.

Die vier Scherzi () Chopins gehören zu seinen bedeutendsten Klavierwerken. Mit ihnen schuf er eine leidenschaftliche, virtuose Musik, mit zahlreichen pianistischen Herausforderungen.

Nach der frühen Klaviersonate (von ) in c-moll Opus 4 (1827 entstanden, aber erst nach dem Tode des Komponisten veröffentlicht), und der b-moll-Sonate Opus 35 (Entstehung: 1837–1839), konzentrierte sich Chopin auf die Komposition seiner dritten Klaviersonate in h-Moll Opus 58.

Als Pole hat Chopin – wie seine Landsleute Karol Kurpiński (1785–1857) und Maria Szymanowska – den heimatlichen Tänzen Polonaise und Mazurka ein Denkmal gesetzt. Als Charakterstücke sind sie wie die Walzer nicht zum Tanzen bestimmt. Sie sind stilisierte Tänze für den konzertanten Vortrag.

Das konzertante Opus 19 ist ein Bolero. Trotz des vordergründig spanischen Geschmacks des Stückes wurde es als verdeckte Polonaise oder als "Boléro à la Polonaise" beschrieben, da seine Rhythmen eher an den Nationaltanz von Chopins Heimat erinnern als an alles Spanische. Der Bolero wurde 1838, fünf Jahre vor dem ersten Besuch von Chopin in Spanien, geschrieben.

Frédéric Chopin schrieb seine zwei Bourrées, ursprünglich barocke Hoftänze, 1846 in A-Dur und G-Dur. Sie wurden erst 1968 veröffentlicht, tragen keine Opusnummern und werden nach den Chopin Werkverzeichnissen (s. Literaturverzeichnis) nummeriert.

Chopin komponierte drei Écossaises (), Opus 72 Nr. 3/1–3 ursprünglich schottische Rundtänze im 3/2- oder 3/4-Takt, die mit dem Dudelsack begleitet wurden. Es handelt sich um einen in Hofgesellschaften getanzten Kontratanz von lebhafter Bewegung im 2/4-Takt.

Die Tarantella ist ein aus Süditalien stammender Volkstanz. Sie zeichnet sich durch ein schnelles Tempo im 3/8- oder 6/8-Takt aus. Chopin komponierte die Tarantella Opus 43 As-Dur im Juni 1841 und veröffentlichte sie im Oktober 1841.

Chopin beschäftigte sich immer wieder mit dieser Gattung und schuf ein breites Spektrum an Formen, von virtuosen Paradestücken – den "Grandes Valses Brillantes" – bis zu tief melancholischen Stimmungsbildern. Sie waren nicht, wie etwa die Walzer von Franz Schubert, zum Tanzen bestimmt. Die überwiegend raschen Walzer sind Salonmusik. Chopin hat diese Stücke mit wenigen Ausnahmen in Dur-Tonarten setzte, stehen diese doch nach dem abendländischen Harmonieverständnis für eine freudvollere Stimmung als die Moll-Tonarten.

Der sogenannte „Minutenwalzer“ (Opus 64 Nr. 1, ursprünglich "Valse du petit chien," ) ist nicht darauf angelegt, möglichst in einer Minute gespielt zu werden. „George Sand besaß einen kleinen Hund, der die Gewohnheit hatte, sich rund umher zu drehen, um seinen Schwanz zu erfassen. Eines Abends, als derselbe gerade damit beschäftigt war, sagte sie zu Chopin: „Wenn ich Ihr Talent hätte, so würde ich für diesen Hund ein Clavierstück schreiben“. Chopin setzte sich ans Klavier und improvisierte den Walzer in Des-dur.

„Walzer nennen sie hier Werke! Und Strauss und Lanner, die ihnen zum Tanz aufspielen, Kapellmeister“, schrieb Chopin empört aus Wien an Elsner. „Von den zahlreichen Wiener Belustigungen sind die Abende in den Gasthäusern besonders berühmt, wo zum Nachtmahl Strauss oder Lanner […] Walzer spielen“, erklärte er seiner Familie. Für Chopin waren Walzer Impressionen aus dem zeitgenössischen Salon: abendliche Feste, chevalereske Gesten, wirbelnde Paare – alles in der für Chopin typischen vornehmen Distanz und Bändigung des Gefühls.

Chopin komponierte viele Klavierstücke, die verschiedenen Gattungen zuzuordnen sind: Allegro de Concert Opus 46, Andante Spianato, B 88, Andantino, B 117, Cellosonate g-Moll, Opus 65, Fuge a-Moll, B 144, Kanon f-Moll, B 129(B), Klaviertrio g-Moll, Opus 8, Largo Es-Dur, B 109 und diverse Variationen, beispielsweise die ‚Variations Brillantes‘, Opus 12, die ‚Variations sur un air national allemand‘, B 14, die Variations für Flöte und Piano in E-Dur ‚Non piu Mesta‘, B 9, die Variations in A-Dur ‚Souvenir de Paganini‘, B 37, die Variations on ‚La Ci Darem la Mano‘ Opus 2 oder die ‚Variations sur un air national de Moore‘, B 12a für Klavier vierhändig.
Die letzte Opus-Zahl, die Chopin verwendete, war 65, die der Cello-Sonate in g-Moll zugeteilt ist. Mit der Erlaubnis der Mutter und der Schwestern des Komponisten, aber gegen seinen Willen, wählte Julian Fontana weitere unveröffentlichte Klavierstücke und Lieder aus und gruppierte sie in 9 Opusnummern (Opus 66–74). Diese Arbeiten wurden 1855 (opus 66–73) und 1859 (opus 74) veröffentlicht.
Die Werke sind mit den Nummern der Kataloge von Maurice J. E. Brown (B (1972)), Krystyna Kobylańska (KK (1979)), and Józef Michał Chomiński/Teresa Dalila Turło (Cho (1990)) gekennzeichnet.

Die Studien über die Etüden von Frédéric Chopin sind Bearbeitungen der Etüden Chopins von Leopold Godowsky (1870–1938), die vor allem dem Ausloten und der Erweiterung der klaviertechnischen Möglichkeiten dienen. Die einseitige Betonung des Technischen bei Godowsky ist jedoch eine Verkehrung der Absichten Chopins, der in den Etüden das technische Element nicht als Selbstzweck behandelt, sondern immer in den Dienst der musikalischen Aussage stellt. Zu den Verfahren Godowskys gehören unter anderem die Vertauschung des Partes von linker und rechter Hand (beispielsweise in der Terzenetüde). Dies stellt durch die neuen, ungewohnten Aufgaben ein Höchstmaß an Anforderungen an den Spielapparat, besonders die linke Hand, was nicht selten an die Grenze der Belastbarkeit führt. Ein weiteres Verfahren ist das Zusammenführen zweier Etüden (beispielsweise Opus 10 Nr. 5 mit Opus 25 Nr. 9) zu einem neuen Stück. Dies führt neben den technischen Problemen zu neuen Klangergebnissen, die mit Chopins Intentionen nichts mehr zu tun haben und in reine Artistik ausarten. Die technischen Schwierigkeiten sind groß und stellen eine Steigerung gegenüber denen der Etüden Chopins dar.

"Les Sylphides" (oder "Chopiniana") ist ein kurzes, nicht-narratives Ballet Blanc. Die Originalchoreografie stammt vom russisch-amerikanischen Choreografen Michel Fokine (1880–1942), der als Musik Klavierstücke von Frédéric Chopin auswählte. Diese wurden vom russischen Komponisten Alexander Glasunow (1865–1936) orchestriert.
Die erste Version des Balletts, die vier Stücke von Chopin von Alexander Glasunow verwendet, hieß "Chopiniana, Opus 46," die 1893 unter der musikalischen Leitung des russischen Komponisten Rimski-Korsakow (1844–1908) erstmals aufgeführt wurde. Die Stücke waren Polonaise, Nocturne, Mazurka und Tarantella. Fokine, der Choreograf, überredete Glasunow, einen zusätzlichen Walzer hinzuzufügen, weil er mindestens einen Tanz auf Zehen und in den langen Röcken der Tagiioni-Periode schaffen wollte. Sie wurde bei einer Wohltätigkeitsgala im Mariinski-Theater in Sankt Petersburg im Dezember 1906 als "Chopiniana" erstmals aufgeführt.

Auf seinen ausdrücklichen Wunsch hin wurde Chopins Herz von seiner Schwester Ludwika heimlich in die polnische Heimat gebracht, wo sie es in Warschau in ihrer Wohnung in der "Ul. Podwale" in der Altstadt aufbewahrte. Nach einigen Wochen wurde das Herz den Priestern der Heiligen-Kreuz-Kirche in der Ulica Krakowskie Przedmieście anvertraut, die zuerst in der Sakristei und dann in der Krypta der Unterkirche aufgebahrt wurde. Während des Warschauer Aufstands in der Nähe der Kirche wurden schwere Kämpfe ausgetragen. Der Kaplan der deutschen Truppen, Pfarrer Schulz, überredete den Priester Niedziela, den Deutschen die Urne zu übergeben, um sie vor der Zerstörung zu bewahren. Am 4. September übergaben die Deutschen die Reliquie dem Erzbischof Antoni Władysław Szlagowski und filmten dieses Ereignis zu Propagandazwecken. Die Urne mit Chopins Herz wurde in Milanówek aufbewahrt, wo die Warschauer Bischöfe interniert waren. Sie stand auf dem Klavier in der Salonkapelle im ersten Stock des Presbyteriums der Heiligen-Jadwiga-Kirche bis zum 17. Oktober 1945. Nach Beendigung des Krieges, am Jahrestag von Chopins Tod, brachten der Pfarrer der Heiligen-Kreuz-Kirche, Priester Leopold Petrzyk (1890–1960), der Komponist Bolesław Woytowicz (1899–1980) und der Musikwissenschaftler Bronisław Sydow (1886–1951) die Urne nach Żelazowa Wola. Von dort kam es zu einer festlichen Rückkehr der Urne, begleitet vom polnischen Staatspräsidenten Bolesław Bierut (1892–1956) von der Geburtsstätte Chopins zurück zur Heiligen-Kreuz-Kirche in Warschau. Dort enthält die Säule mit dem Herz Chopins die Inschrift: . (Matthäus 6.21,).

1926/1928 und nochmals 1929 wurde durch den Marschall Józef Piłsudski (1867–1935) der Versuch unternommen, die Gebeine Chopins von Frankreich nach Polen überführen zu lassen und sie in der Wawel-Kathedrale von Krakau an jener Stelle beisetzen zu lassen, wo Polens Könige und Freiheitskämpfer ruhen. Die damaligen – und auch späteren – politischen Verhältnisse haben dies jedoch nicht zugelassen.

Die Liste der Chopin-Interpreten enthält bekannte Pianisten, die sich überwiegend mit Chopin-Werken befasst oder sich durch besondere Interpretation ausgezeichnet haben.

Der Internationale Chopin-Wettbewerb () ist einer der ältesten und angesehensten Musikwettbewerbe der Welt. Außerdem gehört er zu den Klavierwettbewerben, die dem Werk eines einzigen Komponisten gewidmet sind. Der Wettbewerb wurde 1927 begründet und findet seit 1955 alle fünf Jahre in Warschau statt, zuletzt 2015.

Ab 1934 wünschte sich Adolf Hitler eine Versöhnung mit Polen mit dem Ziel einer außenpolitische Stärkung. Propagandaminister Joseph Goebbels unterzeichnet ein deutsch-polnisches Medienabkommen. Danach soll „eine freundschaftliche Atmosphäre geschaffen und die Aussöhnung vorangetrieben werden“. Musikalisch muss dafür Fryderyk Chopin herhalten: Seine Werke werden in den deutschen Rundfunksendern gespielt. In den deutschen Opernhäusern tanzt man Ballette zu Chopin, Deutschland unterstützt Polen finanziell beim Erwerb kostbarer Chopin-Handschriften. Mit der britisch-französischen Garantieerklärung vom 31. März 1939 an Polen, welche die Unabhängigkeit Polens zum Gegenstand hatte, kippt die Stimmung. Die Nationalsozialisten unterstellten Chopins Musik revolutionäre Gedanken. Seitdem war es verboten, Musikwerke aufzuführen, die mit der polnischen Nationaltradition zusammenhingen.

Dies galt auch im Warschauer Ghetto, von dem der Kritiker Marcel Reich-Ranicki (1920–2013) in seiner Autobiographie berichtet, dass manches Mal ein Pianist ein unbekannteres Werk Chopins als Zugabe spielte und auf die Frage eines Aufsehers, wessen Stück er spiele, dieser zynisch auf Schumann verwies.

Hans Michael Frank (1900–1946), nationalsozialistischer Generalgouverneur von Polen, der von Zeitgenossen der „Schlächter von Polen“ oder der „Judenschlächter von Krakau“ genannt wurde, hat Chopin während der Eröffnung einer Chopinausstellung in Krakau am 27. Oktober 1943 zu germanisieren versucht: „Friedrich Schopping war ein Genie, also konnte er nicht polnisch sein. Dies ist der größte Komponist, den der deutsche Boden hervorgebracht hat.“ Zwar wollte er den „slawischen Barbaren“ Kultur bringen, hatte aber selbst auch eine seltsame Affinität zur Kultur Polens.

Am 25. September 1939, um 8 Uhr, fand eine Liveübertragung eines Klavierkonzerts im Polnischen Radio statt. Władysław Szpilman (1911–2000) spielte gerade Chopins Nocturne cis-Moll, als die ersten deutschen Bomben auf Warschau fielen und der polnische Rundfunk seine Sendung wegen des Angriffs deutscher Truppen auf Warschau unterbrach. Mit genau demselben Stück nahm der polnische Rundfunk seine Sendungen nach dem Zweiten Weltkrieg wieder auf.

Das Chopin-Denkmal in Warschau war 1907 von Wacław Szymanowski (1859–1930) entworfen worden und sollte ursprünglich zur Wiederkehr Chopins 100. Geburtstag 1910 eingeweiht werden. Durch Kontroversen über das Design und durch den Ersten Weltkrieg bedingt, wurde es erst 1926 im Łazienki-Park errichtet. Es zeigt den sitzenden Chopin unter einer stilisierten Pianistenhand, die in den Adlerkopf des Wappen Polens übergeht. Nach dem Überfall auf Polen sprengte die deutsche Wehrmacht dieses Denkmal am 31. Mai 1940. Nachdem die Gussform den Zweiten Weltkrieg überstand, konnte ein Replikat des Denkmals nach dem Krieg angefertigt werden, das 1958 am ursprünglichen Ort wieder aufgestellt wurde.

Originale, noch spielbare „Chopin-Flügel“ von Érard oder Pleyel aus den 1830er und 1840er Jahren sind eine Seltenheit.

Hammerflügel von Pleyel zählten zu ihrer Zeit zusammen mit den Instrumenten seines Konkurrenten Sébastien Érard zu den Spitzenprodukten des Tasteninstrumentenbaus, waren zusammen mit zwei Londoner Firmen (Broadwood, Collard & Collard) anerkannte Weltklasse und waren (im Fall Erard) auch die Vorlage des frühen Flügelbaues bei Steinway & Sons.

Heutzutage sind drei Konzertflügel („Pantaleones“) von Pleyel bekannt, von denen verbürgt ist, dass sie von Chopin in seiner jeweiligen Wohnung benutzt wurden. Einer befindet sich nach Restaurierung beim Hammerflügel-Experten Edwin Beunk, Enschede, Niederlande, nun in deutschem Privatbesitz. Ein Flügel ist original spielbereit im Süden Großbritanniens nahe der Hurstwood Farm, ein Nachbar des Klavierbaubetriebs „Phoenix Pianos“. Der dritte Pleyel-Flügel, sein letzter, den Jane Stirling kaufte und Chopins Schwester mitgab, steht ausgestellt, jedoch in unspielbarem Zustand in Warschau. Sodann existiert das Pleyel-Klavier in Valldemossa.

Nach anderen Angaben existieren sieben Pleyel-Klaviere oder -Flügel, von denen als erwiesen gilt, dass Chopin auf ihnen spielte. Die Instrumente sind in Museen auf Mallorca, Paris, Stockholm, Krakau und Nürnberg.

In Polen stellen nach Art. 1 Abs. 1 des Gesetzes vom 3. Februar 2001 über den Schutz des Erbes von Fryderyk Chopin seine Werke und damit zusammenhängenden Gegenstände ein nationales Gut dar, das einem besonderen Schutz unterliegt. Das Gesetz betrifft die Verwendung von Chopins Bild und Nachnamen in Marken, während es jedoch nicht für seine Werke gilt, die öffentlich zugänglich sind.
Das Nationale Fryderyk-Chopin-Institut (NIFC) befasst sich mit dem Schutz des Erbes des Komponisten, unterstützt vom Patentamt der Republik Polen. Unternehmen, die eine Marke einschließlich des Namens oder der Abbildung von Fryderyk Chopin registrieren möchten, müssen zuvor die Genehmigung des NIFC einholen. Das Institut setzt voraus, dass Produkte, die das Bild oder den Namen eines Komponisten tragen, von hoher Qualität sind und mit Polen assoziiert werden. Um die Verwendung einer solchen Marke für kommerzielle Zwecke zu akzeptieren, erhebt das Institut eine jährliche Gebühr und einen Prozentsatz des erzielten Gewinns.


Es gibt fast 300 Titel in der größten Internet-Filmdatenbank, Internet Movie Database (IMDb), unter „Frédéric Chopin“, ein weiteres Dutzend lässt sich durch Links finden. Nur wenige polnische Filme werden aufgeführt, obwohl es etwa 50 solcher abendfüllender Spielfilme gibt.

„Die meisten Portraitisten malten Chopin ein face, um die übergroße Hakennase Chopins zu kaschieren. Portraitierten sie ihn jedoch von der Seite, so gingen sie sehr schonend und diskret mit seiner Nase um, denn das Ebenbild des Menschen sollte auch ein Ebenbild seiner Kunst sein, deren Formvollendung und Ebenmaß Laien und Künstler zu entzücken hatte“, analysiert Ludwig Kusche die Gemälde von Chopin. Das beste Porträt Chopins sei das Ölbild von Delacroix, das im Louvre in Paris hängt und den Kopf halb von vorn und halb von der Seite wiedergibt. Das gemeinsame Porträt, das Delacroix von dem Künstlerpaar anfertigte, wurde 1874 von einem Unbekannten zerschnitten. Heute hängt Chopin allein im Louvre, seine einstige Geliebte im Ordrupgaard Museum im dänischen Charlottenlund.











</doc>
<doc id="1731" url="https://de.wikipedia.org/wiki?curid=1731" title="Föhr">
Föhr

Die Insel Föhr (nordfriesisch "Feer", dänisch "Før") gehört zu den Nordfriesischen Inseln und zum Kreis Nordfriesland in Schleswig-Holstein. Föhr ist die größte und bevölkerungsreichste deutsche Insel ohne Landverbindung. 

Der Name Föhr und das friesische Pendant "Feer" sind vielfältig interpretiert worden. Die aktuelle etymologische Forschung geht davon aus, dass der Name Föhr einen maritimen Hintergrund hat. Eine weitere Deutung bezieht sich auf friesisch "feer" „unfruchtbar“.

Föhr liegt südöstlich von Sylt, östlich von Amrum und nördlich der Halligen. Sie ist die fünftgrößte deutsche Insel und zweitgrößte deutsche Nordseeinsel. Unter den deutschen Inseln ohne Straßen- oder Bahnverbindung zum Festland ist Föhr die flächenmäßig größte Insel mit der höchsten Bevölkerungszahl.

Föhr wird „die grüne Insel“ genannt, da sie durch ihre Lage im Windschatten von Amrum und Sylt vor den stürmischen Einflüssen der Nordsee relativ geschützt ist und sich daher die Vegetation gut entwickeln kann. Sie ist in Nord-Süd-Richtung bis zu 8,5 Kilometer breit und in Ost-West-Richtung 12,5 Kilometer lang und hat eine Fläche von 82,82 Quadratkilometern. Der Norden der Insel besteht aus Marschland, im Süden Föhrs befindet sich die höher gelegene Geest. Die höchste Erhebung liegt 13,2 Meter über Normalnull auf dem Geestrücken zwischen Nieblum und Midlum. Die Geest macht etwa zwei Fünftel der Gesamtfläche aus. Die meisten Ortschaften liegen dort. In der Marsch befinden sich zahlreiche Aussiedlerhöfe.

Bis zur ersten Groten Mandränke 1362 war Föhr noch keine Insel, sondern Teil des Festlands. Mit der Nordsee war es durch tiefe Ströme verbunden. Südlich von Föhr verläuft heute die Norderaue; das Amrumtief liegt westlich, die Föhrer Ley östlich Föhrs.

Föhr ist, wie auch die benachbarten Inseln, ein beliebtes Urlaubsziel. Vom Fährhafen Wyk zieht sich am Südrand bis etwa zur Mitte der Westküste ein 15 Kilometer langer Sandstrand. Nördlich und nordwestlich der Insel befindet sich die Schutzzone I des Nationalparks Schleswig-Holsteinisches Wattenmeer.

Föhr gehört zum Kreis Nordfriesland und hat 8.248 Einwohner (Stand: 1. Quartal 2018).
Im Südosten der Insel liegt als einzige Stadt der Hauptort Wyk (Fering: "bi a Wik"), der ein staatlich anerkanntes Nordseeheilbad ist. Die 16 Inseldörfer verteilen sich auf elf Gemeinden. Wyk und alle Föhrer Gemeinden gehören zum Amt Föhr-Amrum.

Auf Föhr herrscht Seeklima. Die Durchschnittstemperaturen betragen im August zwischen 14 und 19 °C, im Januar und Februar zwischen −1 und 3 °C. Föhr hat rund 4,6 Sonnenstunden pro Tag. Monatlich gibt es im Mittel zehn Regentage. Die durchschnittliche Niederschlagsmenge liegt bei etwa 800 Millimetern.

Auf Föhr herrscht aufgrund der salzhaltigen Luft und der relativ starken Winde Reizklima.

Die höhergelegenen Geestkerne der nordfriesischen Inseln inmitten weiter Marschflächen lockten Menschen an, als zu Beginn der Jungsteinzeit der Wasserspiegel der Nordsee stieg. Auch auf Föhr zeugen Steingräber und zahlreiche Kleinfunde davon. In Wyk gibt es Besiedlungsspuren aus dem zweiten bis fünften Jahrhundert nach Christus. 

Als die Friesen im 7. Jahrhundert das heutige Nordfriesland besiedelten, befanden sich archäologischen Funden zufolge ihre ersten Niederlassungen auf Föhr. Die zuvor wenig besiedelte Insel erlebte einen schnellen Bevölkerungszuwachs. Die recht große Anzahl skandinavischer Schmuckteile in Gräbern verraten, dass gleichzeitig enge Beziehungen zu Nordeuropa bestanden. Aus der Wikingerzeit sind mehrere Kreiswälle, darunter die sogenannte "Lembecksburg", erhalten.

Das 1231 verfasste Erdbuch des dänischen Königs Waldemar berichtet von zwei Föhrer Harden, Westerharde, zu der Westerland Föhr und Amrum gehörten, und Osterland Föhr. 1368 wechselte die Westerharde unter dem Ritter Klaus Lembeck, Amtmann von Ripen, zu den Holsteiner Grafen über. Im Januar 1400 ergab sich die Harde Königin Margarethe I. und blieb beim Amt Ripen. Bis 1864 war die Westerharde Teil der königlichen Enklaven und dem Königreich Dänemark direkt unterstellt, während Osterland Föhr mit Wyk zum Herzogtum Schleswig gehörte, seit es in den 1420er Jahren vom König abgefallen war. Gemeinsam mit der Wiedingharde, der Bökingharde, Strand und Sylt schloss Osterlandföhr 1426 mit Herzog Heinrich IV. von Schleswig die Siebenhardenbeliebung, die besagte, dass sie ihre Rechtsautonomie behalten durften.

Das Marschland im Norden der Insel wurde 1523 als 22 Hektar großer "Föhrer Marschkoog" eingedeicht.

Von 1526 an wurde die Reformation evangelisch-lutherischer Konfession auf Föhr eingeführt, die 1530 abgeschlossen war.

Mit dem Walfang brach für Föhr ein „goldenes“ Zeitalter an. Im 17. und 18. Jahrhundert wurden die holländischen und englischen Grönlandfahrer meistens mit Inselfriesen bemannt. Auf Föhr entstanden mehrere private Seefahrerschulen, in denen Pastoren und ehemalige Commandeure für geringe Gebühren im Winterhalbjahr Unterricht gaben. Ende des 18. Jahrhunderts lebten 1000 Seefahrer, darunter 150 Schiffsführer, auf der Insel. Noch heute sind kostbar ausgestattete Häuser der Commandeure in Nieblum und Süderende zu sehen. Die sogenannten „sprechenden Grabsteine“ auf den Friedhöfen der drei ältesten Föhrer Kirchen berichten ihre Lebensgeschichten. Doch mit dem Rückgang der Walbestände fuhren, wie überall in der Region, immer weniger Männer zur See. Die Bevölkerung wandte sich wieder der Landwirtschaft zu. Der Ort Wyk wurde im Jahr 1706 aus der Harde Osterlandföhr herausgelöst und erhielt den Status eines Fleckens. 

Ab 1842, als der dänische König Christian VIII. den Sommer auf Föhr verbrachte, kam die Insel als Kurort in Mode.

Während des Deutsch-Dänischen Krieges 1864 war der dänische Seeoffizier Otto Christian Hammer in Wyk Befehlshaber einer dänischen Flottille auf den Nordfriesischen Inseln. Es gelang ihm zunächst erfolgreich, überlegene preußisch-österreichische Marineverbände abzuwehren. Im Laufe des Krieges wurde er jedoch in Wyk von dem preußischen Leutnant Ernst von Prittwitz und Gaffron gefangen genommen, dem Wyk auf Föhr daraufhin die Ehrenbürgerwürde verlieh. 1867 wurden nach der Auflösung der Harden die Ämter Westerlandföhr und Osterlandföhr gebildet.

Bei der Volksabstimmung in Schleswig im Jahr 1920 stimmten die drei Gemeinden Goting, Utersum und Hedehusum auf Westerland Föhr als einzige Gemeinden in der sogenannten Zone II mehrheitlich für einen Wechsel zum Staatsgebiet von Dänemark. Jedoch sprach sich in der Zone II insgesamt eine deutliche Mehrheit für den Verbleib bei Deutschland aus. Da die drei Gemeinden nicht direkt an der Grenze zu Dänemark lagen, blieben sie bei Deutschland.

1970 wurden die Ämter Wester- und Osterlandföhr zum Amt Föhr-Land vereinigt. Zum 1. Januar 2007 wurde das Amt Föhr-Land mit der Stadt Wyk auf Föhr und dem Amt Amrum zum Amt Föhr-Amrum vereinigt.

Auf Föhr wird von etwa 2.000 Einwohnern, insbesondere der Dörfer in Westerland Föhr, ein Dialekt der nordfriesischen Sprache gesprochen. Dieser Dialekt wird nach dem Namen der Insel Fering genannt. Damit bilden die Fering-Sprecher die größte Gruppe von Sprechern der nordfriesischen Sprache. Auf Osterland Föhr, besonders in Nieblum, wird seit dem 19. Jahrhundert eher Niederdeutsch, in Wyk nach Gründung der Stadt vor allem Niederdeutsch und heute Hochdeutsch gesprochen. Der ehemalige eigene Wyker Dialekt des Nordfriesischen, das "Wyker Friesisch", ist ausgestorben. Darüber hinaus gibt es auf Föhr auch eine Dänisch sprechende Minderheit.

Die Friesentracht wird von vielen Frauen, besonders in Westerland Föhr, zu besonderen Anlässen getragen. Auf Föhr werden verschiedene Volksbräuche gepflegt wie das Biikebrennen am 21. Februar und das "Tamsen" (auch "Thamsen", nach dem Apostel Thomas), bei dem an jedem 21. Dezember junge Leute im Scherz Dinge verstecken, die sich drehen können. In der Weihnachtszeit gibt es, wie auf anderen nordfriesischen Inseln auch, einen speziellen Weihnachtsbaum, Kenkenbuum genannt. Am Silvesterabend gehen verkleidete Föhrer von Haus zu Haus. Auf Fering heißt dieser Brauch "ütj tu kenknin", in Wyk "Rummelrotje" ("siehe auch": Hulken).

In den Jahrhunderten, als viele Föhrer Männer Walfänger waren, verbrachten sie den Winter auf Föhr. Die ledigen Seefahrer trafen sich dann am Nachmittag im Halbdunkeln, auf Fering: "Hualewjonken". Heute ist das "Hualewjonken" ein gemütliches Beisammensein Gleichgesinnter.

Mehrere Schriftsteller schrieben auf Fering, etwa die Wykerin Stine Andresen (1849–1927), deren Lyrik oft auf Föhr bezogen ist. Die Föhrerin Ellin Nickelsen schrieb in den 1980er Jahren die Erzählung "Jonk Bradlep" (deutsch: „Dunkle Hochzeit“). 

"Siehe auch": Nordfriesische Literatur

Die beiden Föhrer Museen haben kulturelle Schwerpunkte (siehe Sehenswürdigkeiten).

Die international erfolgreiche Musikband Stanfour hat auf der Insel Föhr ihren Ursprung und unterhält dort ein eigenes Studio. Die Föhrer Folkband Kalüün wurde für ihre Lieder mit Preisen ausgezeichnet.

Föhr ist vor allem vom Tourismus abhängig. Das Beherbergungsgewerbe wird durch zahlreiche Gewerbebetriebe mit Dienstleistungsfunktion wie Fahrradverleihstationen und Käsereien ergänzt. Daneben gibt es dort zahlreiche landwirtschaftliche Betriebe, die teilweise ebenfalls Unterkünfte bieten. Diese Diversifizierung wird durch Mittel aus dem ELER-Programm gefördert. Auf der Insel sind zahlreiche Handwerks- und Einzelhandelsbetriebe angesiedelt; im Wyker Hafen haben sechs Miesmuschelfischerboote und drei Krabbenkutter ihren Heimathafen. Föhr verfügt über niedergelassene Zahnärzte sowie Arztpraxen verschiedener Fachrichtungen. Seit 1893 gibt es in Wyk ein Krankenhaus, das an der medizinischen Grundversorgung von Föhr und Amrum mitwirkt. In Utersum befindet sich eine Rehabilitationsklinik, in Wyk das "Nordseesanatorium Marienhof" des Diakonie-Hilfswerkes Schleswig-Holstein.

Auf Föhr gibt es sechs Kindergärten, davon vier in Wyk sowie je einen in Süderende und Midlum. Einzige Schule mit gymnasialer Oberstufe für die Inseln Föhr und Amrum ist die „Eilun Feer Skuul – Gymnasium & Regionalschule Insel Föhr“ (deutsch: „Insel-Föhr-Schule“) in Wyk. Dort befinden sich außerdem eine Grundschule mit Förderzentrum und eine Dänische Schule, die als Gemeinschaftsschule bis zur achten Klasse führt. Eine weitere Grundschule gibt es in Süderende mit Außenstelle in Midlum.

In Wyk befinden sich ferner eine Volkshochschule und eine Musikschule, die eine Bezirksstelle der Kreismusikschule Nordfriesland ist.

Vom Fährhafen Wyk aus verkehren mehrmals am Tag unabhängig von der Tide Fähren zum Festlandshafen Dagebüll und nach Wittdün auf der Nachbarinsel Amrum. Betreiber der Fährlinie ist die Wyker Dampfschiffs-Reederei Föhr-Amrum GmbH (W.D.R.) mit Sitz in Wyk auf Föhr.

Während der Sommersaison werden Ausflugsfahrten zu den Halligen Langeneß und Hooge sowie zur Insel Sylt (Hafen Hörnum) angeboten.

Von Wyk aus bestehen Busverbindungen als Ringlinie mit oder gegen den Uhrzeigersinn in alle Dörfer der Insel Föhr. Die Insel ist über den Verkehrslandeplatz Wyk per Flugzeug zu erreichen. Von diesem Flugplatz aus starten wetterabhängig täglich mehrere Rundflüge über das Wattenmeer, die Nachbarinseln und das nordfriesische Festland.

Auf der Insel befinden sich drei mittelalterliche, seit der Reformation evangelische Kirchen aus dem 12. und 13. Jahrhundert – in Wyk-Boldixum die Kirche St. Nicolai, in Nieblum die Kirche St. Johannis und in Süderende die Kirche St. Laurentii. Auf den dazugehörigen Friedhöfen finden sich die sogenannten Sprechenden Grabsteine, die ganze Lebensgeschichten erzählen und teilweise bebildert sind.

Mehrere Hügelgräber zeugen von einer Besiedelung der Insel während der Bronzezeit. Heute lassen sich noch 17 dieser alten Grabmonumente besichtigen; sie liegen vor allem im Südwesten der Insel. 

Bei Borgsum befindet sich zudem die Lembecksburg, ein Ringwall aus der Zeit der Völkerwanderung mit 95 Metern Durchmesser und acht Metern Ringhöhe. Der Sage nach soll hier im Mittelalter der Ritter Klaus Lembeck als Statthalter des dänischen Königs residiert haben.

In Wyk liegt das Friesenmuseum (eigentlich "Dr.-Carl-Häberlin-Museum"), das sich der Wahrung und Vermittlung friesischer Kulturgeschichte widmet, es wurde 1908 eröffnet. In Alkersum befindet sich das 2009 eröffnete Museum Kunst der Westküste, das in wechselnden Ausstellungen internationale klassische und zeitgenössische Kunst zum Thema „Meer und Küste“ präsentiert. Ein kleines Heimatmuseum in Oevenum widmete sich ab 1993 der Geschichte der Landwirtschaft und dem Leben auf der Insel, ist aber seit 2011 aus Altersgründen geschlossen. Die Sammlung ist jedoch erhalten.

Auf Föhr befinden sich des Weiteren fünf Windmühlen, davon zwei in Wyk (die Galerieholländerwindmühle "Venti Amica" von 1879 im Stadtgebiet und eine Bockwindmühle von der Hallig Langeneß im Außenbereich des Friesenmuseums), dazu jeweils eine in Wrixum ("Osterwindmühle", achtkantiger Erdholländer, 1850–1960 in Betrieb), Borgsum ("Borigsem", achtkantiger Galerieholländer von 1992 nach Brand des Vorgängerbaus) und Oldsum (achtkantiger Galerieholländer von 1901).

Bis auf die Bockwindmühle und die Mühle in Wrixum (Museum und Restaurant) befinden sich die Mühlen in Privatbesitz.

Sechs Vogelkojen findet man in der Marsch im Norden der Insel. Zu ihnen zählen die neue sowie die alte Oevenumer Vogelkoje, die zu Midlum gehörende Ackerumer Vogelkoje, die Borgsumer, die Oldsumer und die Boldixumer Vogelkoje. Letztere kann man besichtigen.

Auch das gesamte Wattenmeer (als Nationalpark Schleswig-Holsteinisches Wattenmeer seit 2009 UNESCO-Weltnaturerbe) gilt als Sehenswürdigkeit.

Vor allem das Vorland nördlich des Inseldeiches, aber auch die übrigen Wattflächen bieten Rast- und Futterplätze für viele Arten von Seevögeln. So findet man dort zahlreiche Austernfischer, Eiderenten und Brandgänse. Während des Vogelzuges fallen außerdem große Schwärme von Zugvögeln auf Föhr und den umliegenden Inseln ein. Gelegentlich, insbesondere nach schweren Winterstürmen, können Seehunde am Strand angetroffen werden.

Der Südstrand der Insel zwischen Wyk und Utersum ist ein beliebter Badestrand. Von den Fremdenverkehrsämtern werden geführte Wattwanderungen, zum Beispiel zur Nachbarinsel Amrum, angeboten.

Als weitere Wyker Sehenswürdigkeiten gelten der Glockenturm (erbaut 1886) sowie die Seepromenade "Sandwall".





</doc>
<doc id="1732" url="https://de.wikipedia.org/wiki?curid=1732" title="Formale Sprache">
Formale Sprache

Eine formale Sprache ist eine abstrakte Sprache, bei der im Unterschied zu konkreten Sprachen oft nicht die Kommunikation im Vordergrund steht, sondern die mathematische Verwendung. Eine formale Sprache besteht aus einer bestimmten Menge von Symbolketten (im Allgemeinen Zeichenketten) („Worte“ der Sprache), die aus einem Zeichen-/Symbolvorrat („Alphabet“, Grundsymbole) zusammengesetzt werden können. Anwendung finden formale Sprachen in der Linguistik, der Logik und der theoretischen Informatik.

Formale Sprachen eignen sich zur (mathematisch) präzisen Beschreibung des Umgangs mit Zeichenketten. So können zum Beispiel Datenformate oder ganze Programmiersprachen spezifiziert werden. Zusammen mit einer formalen Semantik erhalten die definierten Zeichenketten eine (mathematische) Bedeutung. Bei einer Programmiersprache kann damit einer Programmieranweisung (als Teil der formalen Sprache) ein eindeutiges Maschinenverhalten (als Teil der Semantik) zugeordnet werden.

Aufbauend auf formalen Sprachen können aber auch Logikkalküle definiert werden, mit denen man mathematische Schlüsse ziehen kann. In Verbindung mit formal definierten Programmiersprachen können Kalküle helfen, Programme auf ihre Korrektheit zu überprüfen.

Eine formale Sprache formula_1 über einem Alphabet formula_2 ist eine Teilmenge der Kleeneschen Hülle des Alphabets: formula_3.

Ein Alphabet formula_2 legt die Zeichen fest, aus denen ein „Wort“ der Sprache gebildet werden kann. Zum Beispiel kann man die Dezimaldarstellung jeder natürlichen Zahl aus dem Alphabet formula_5 bilden.

Alle aus einem gegebenen Alphabet formula_2 beliebig bildbaren Wörter mit endlicher Länge (Länge 0 oder länger), deren jeder einzelne Buchstabe Element von formula_2 ist, diese größtmögliche Wortmenge zum Alphabet formula_2, nennt man die "Kleenesche Hülle" des Alphabetes formula_2, kurz formula_10. Eine formale Sprache über einem Alphabet formula_2 ist also eine bestimmte Teilmenge der Kleeneschen Hülle ihres Alphabets – im Allgemeinen ist also "nicht" jede beliebige Zeichenkombination ein gültiges Wort der Sprache.

Formale Sprachen können leer, endlich oder unendlich sein; maximal können sie die gesamte Kleenesche Hülle ihres Alphabetes umfassen. Sie können über eine mathematische Bedingung an ihre Wörter definiert sein: „Die Sprache … ist die Menge aller Wörter, für die gilt …“.

Die in der theoretischen Informatik auftretenden Sprachen sind jedoch meistens spezieller durch ein bestimmtes Ersetzungsverfahren definiert – Regeln, wie die Alphabet-Zeichen kombiniert sein/werden dürfen. Von den Ersetzungsverfahren gibt es verschiedene Typen: Semi-Thue-Systeme, Chomsky-Grammatiken, Lindenmayer-Systeme u.a. Bei solchen Ersetzungsverfahren geht man beispielsweise von einer spezifischen Start-Zeichenkette aus, die man durch wiederholte („rekursive“) Anwendung der Regeln (Text-Ersetzungen) schrittweise in Wortgebilde überführt, die dann als ganzes, oder nur ein vorgegebener Abschnitt davon, als Wörter der Sprache gelten. Man redet hier auch von "generativen Grammatiken", weil die Wörter einer Sprache über solche Textsubstitutionen schrittweise "erzeugt" werden.
Umgekehrt kann man Sprachen auch definieren als die Menge aller Wörter, aus denen (über das Ersetzungsverfahren der Sprache) ein bestimmtes vorgegebenes Wort oder eines von mehreren vorgegebenen Wörtern erzeugbar ist. („Es gehört alles zur Sprache, was sich über die Regeln auf … zurückführen lässt.“)

Mit Hilfe formaler Sprachen können auch natürliche Sprachen modelliert werden, vor allem deren Syntax.
Beim Vergleich formaler Sprachen mit natürlichen Sprachen ist aber zu beachten, dass natürliche Sprachen oberhalb der elementaren "Laut-Zeichen" mindestens die zwei übereinander liegenden Hierarchieebenen des "Wortes" und des "Satzes" besitzen. Die Regeln für deren Aufbau trennt man gewöhnlich in Morphologie zum einen und in Syntax zum anderen. In formalen Sprachen dagegen liegt über dem elementaren Alphabet-Zeichen oft nur die eine Hierarchieebene des formalen "Wortes", man redet im Hinblick auf den Bau der Wörter formalsprachlich von Syntax. Wenn eine natürliche Sprache mittels einer formalen modelliert wird, dann werden also die Sätze der natürlichen Sprache in formalsprachlicher Betrachtung "Wörter" genannt.

Außerdem haben Äußerungen in natürlicher Sprache eine natürliche Bedeutung, während die Bedeutung formaler Sprachen stets auf ebenfalls formalem Weg definiert werden muss.



</doc>
<doc id="1733" url="https://de.wikipedia.org/wiki?curid=1733" title="Farbe">
Farbe

Farbe ist ein durch das Auge und Gehirn vermittelter Sinneseindruck, der durch Licht hervorgerufen wird, genauer durch die Wahrnehmung elektromagnetischer Strahlung der Wellenlänge zwischen 380 und 760 Nanometer. Es ist der Sinneseindruck, durch den sich zwei aneinandergrenzende, strukturlose Teile des Gesichtsfeldes bei einäugiger Beobachtung mit unbewegtem Auge allein unterscheiden lassen.

In der Alltagssprache werden Farbmittel (farbgebende Substanzen) ebenfalls als Farbe bezeichnet, also stoffliche Mittel, mit denen die Farbe von Gegenständen verändert werden kann, so bei Malerfarben.

Die Farbwahrnehmung ist eine subjektive Empfindung, welche nicht nur durch die Art der einfallenden Lichtstrahlung, sondern auch durch die Beschaffenheit der Augen, Empfindlichkeit der Rezeptoren und den Wahrnehmungsapparat bestimmt wird. Andere optische Wahrnehmungsphänomene wie Struktur (Licht-Schatten-Wirkungen), Glanz oder Rauheit sowie psychische Effekte, wie Umstimmung oder Adaptation, sind vom Farbbegriff zu unterscheiden.

"Farbe" hat mehrere Wortbedeutungen.

In anderen Sprachen wird stärker zwischen dem Effekt Farbe („farbig“) und der Ursache für Farbe („färben“) unterschieden, so im Englischen "colour" und "dye (stuff)" (oder "pigment"), oder in den romanischen Sprachen (spanisch: "color" und "teñir").

In diesem Artikel wird nicht das Entstehen von Farben erläutert und die ergänzenden Begriffe zur Farbe werden unter Grundfarbe behandelt.

Farbe ist das Wahrgenommene. Sie entsteht durch den visuellen Reiz in Farbrezeptoren als Antwort auf eine Farbvalenz, so wie ein mechanischer Reiz durch Druck oder Rauheit hervorgerufen wird. Farbe ist nicht die Eigenschaft eines betrachteten Objekts oder gesehenen Lichtes, sondern sie ist subjektives Empfinden, dessen physikalische Ursache die Intensitätsverteilung elektromagnetischer Wellen zwischen 380 nm und 780 nm ist. Unterschiedliche Intensitäten im sichtbaren Licht lösen Nervenreize aus, die unterschiedliche Qualitäten der Farbwahrnehmung bilden, deren Miteinander als Farbe wahrgenommen wird.

Das optische Phänomen der Farbwahrnehmung ist ein Forschungsgebiet von umfassender Komplexität. Es sind physikalische (Spektrum), wahrnehmungsphysiologische (Farbreiz) und wahrnehmungspsychologische (Farbvalenz) sowie sprachlich-konventionelle Aspekte verflochten. Die visuelle Wahrnehmung des Menschen erfolgt durch Rezeptoren, die sich auf der Netzhaut befinden: Stäbchen für Hell-/Dunkel-Kontrast, die Zapfen (nicht Zäpfchen!) für die Farbwahrnehmung.

Zapfen sind in drei Ausprägungen vorhanden, die ihr Empfindlichkeitsmaximum je in einem der Spektralbereiche „Rot“, „Grün“ und „Blau“ haben. Farbe lässt sich aufgrund der drei Arten von Farbrezeptoren beim Menschen als dreidimensionale Eigenschaft darstellen. Jede Kombination von Anregungen der drei Zapfenarten durch (Licht-)Strahlung, die auf die Netzhaut trifft, bewirkt einen spezifischen Farbeindruck. Somit sind auch Schwarz (keinerlei Erregung), Neutralgrau (gleiche Erregung) und Weiß (volle Erregung aller drei Zapfensorten) ebenfalls Farben, die klassifizierend als unbunte Farben benannt werden.

Als Licht sichtbar ist elektromagnetische Strahlung der Wellenlänge zwischen von 380 nm und 780 nm (sichtbarer Teil des elektromagnetischen Spektrums). Spektralfarben, wie sie bei der Brechung weißen Lichts hinter einem Prisma auftreten, sind Spektren, in denen nur ein Wellenlängenbereich sichtbaren Lichts ohne Fremdanteile vorkommt.

Grundsätzlich unterscheiden sich Licht- und Körperfarben. Bei ersten sendet eine Beleuchtungsquelle (Sonne, Leuchten, Bildschirmpixel) farbiges Licht in unsere Augen. Für den Gesamteindruck mehrerer farbiger Beleuchtungsquellen gelten die Gesetze der additiven Farbmischung (Rote Lampe + Grüne Lampe = Gelbes Licht). Körperfarben entstehen, wenn einfallendes Licht auf einer Körperoberfläche teilweise absorbiert und anderenteils ins Auge reflektiert wird. Für Körperfarben und deren Farbmittel gelten die Gesetze der subtraktiven Farbmischung (Magenta + Gelb = Rot). Körperfarben hängen stark von der Beleuchtungsquelle ab, beispielsweise erscheint ein grünes Blatt, wenn es mit rein-rotem Licht beleuchtet wird, schwarz, denn es reflektiert keine roten Anteile. 

Innerhalb eines Oberbegriffes Farbe (Farbigkeit) ist Farbe auch Ausdruck für die Unterscheidungskriterien dieser Qualität. Gras hat die Farbe Grün, Blut hat die Farbe Rot, eine Zitrone hat die Farbe Gelb. Klares Glas ist farblos (ohne eigene Farbe). Diese Wahrnehmung einer Qualität eines visuellen Eindruckes entsteht vor der Benennung durch Worte.

Worte beschreiben Eindrücke: Blau, Tiefblau, Blassblau, Himmelblau, Rotblau. Farbunterschiede können benannt werden und so ist es möglich Wahrnehmungen auszutauschen. Neben dem Zeigen von materiellen Proben kann deshalb auch durch Worte von und über Farben geredet werden (zweites Signalsystem). Dem liegt die konventionelle Übereinkunft zugrunde, von Generationen geprägt und in der Kindheit erlernt. Bei verschiedenen Menschen kann die individuelle Wahrnehmung (objektiv) gleich benannter Farben durchaus unterschiedlich sein. Diese Individualitäten gehen bis zum teilweisen oder vollständigen Ausfall von Rezeptoren, bis zur Farbenfehlsichtigkeit.

Farbnamen dienen zum gemeinsamen Verständnis der Umwelt. Hinzu kommen weitere nichtverbale Konventionen: Rot ist an der Ampel oben und Grün ist bei der Ampel unten. Darüber hinaus beeinflussen die Farbwirkung und den Eindruck auch Farbstimmungen, die zeitliche und räumliche Vorwirkung, individuelle Erfahrung und Training der Wahrnehmung. () (sortiert nach Häufigkeit der Nennung)

Im Sinne von „Farbe“ im allgemeinen Sprachgebrauch bestehen Gruppenbezeichnungen für Klassen des Sinneseindrucks, die beispielsweise als „Körperfarbe bei Tageslicht“ eine Objekteigenschaft beschreibt. Solche gebräuchliche, festgelegte Farbnamen finden sich unter

In allen modernen Sprachen gibt es eine große Zahl nuancierender Wörter für einzelne Farben. Unser Bedürfnis, Farben zu benennen, wird mit der Zeit immer stärker. Bedingt durch die Einflüsse der Umwelt kennen nach einer Studie aus den 2010er Jahren Vierjährige so viele Farbbezeichnungen wie vor 100 Jahren Achtjährige.

Mitunter „fehlen“ in einer Sprache Farbnamen, die andere haben. Lücken dieser Art können durch Entlehnung aus anderen Sprachen oder durch Umfunktionierung bereits vorhandener Gegenstandsnamen gefūllt werden. Beispiele dafür sind das späte Auftreten von Orange, Rosa, Türkis oder Magenta im Deutschen. 

Die Wortbedeutungen unterliegen oft einem von sozialen und kulturellen Faktoren bestimmten Wandel. Im Deutschen bedeutete "braun" im 17. Jahrhundert sowohl „braun“ als auch „dunkelviolett bis dunkelblau“. So heißt es im Kirchenlied "Hernieder ist der Sonnen Schein / die braune Nacht bricht stark herein." Schwierig war aus frūheren Zeiten der begriffliche Unterschied zwischen "Purpur", "Violett" und "Lila". Wenn verschiedene Sprachen das Farbenspektrum anders aufteilen, wie in asiatischen Sprachen, kann es zu Irritationen bei Übersetzungen führen. Beispiele dafūr finden sich beim Diskussionspunkt der blauen und grünen Töne. Es kann in einzelnen Sprachen eigene (objektgebundene) Farbbezeichnungen für bestimmte Einsatzzwecke geben: beispielsweise gilt blond im Deutschen nur für menschliches, dagegen falb nur für tierisches Haar.

Seit 1969 beschäftigten sich vor allem angelsächsische Linguisten mit der Frage, ob Farb-Grundwörter („basic color terms“) in einer sprachuniversalen Implikationshierarchie stehen. In der einflussreichen 98 Sprachen umfassenden Untersuchung "Basic Color Terms" schlugen Brent Berlin und Paul Kay vor, dass alle Sprachen der Welt eine minimale Besetzung von zwei Farbkategorien in ihrem Wortschatz (d.h. Farbtermini für Weiß/Hell und Schwarz/Dunkel) haben. Dazu treten als dritte Kategorie Rot, als vierte Gelb oder Grün und weiter bis maximal elf Farb-Grundwörtern. Berlin und Kay interpretierten ihren Befund nicht nur synchron als sprachtypologische Erscheinung, sondern auch als historisches Entwicklungsmodell mit sieben Sprachstadien (Stages I - VII). Diese Hypothese wird seit 2002 an der Universität Konstanz neben vielen anderen sprachtypologischen Arbeitshypothesen im Rahmen des Projekts "The Universals Archive" getestet. Berlin und Kays Ansichten stießen bei Ethnologen und Sprachrelativisten auf Kritik und wurden daraufhin von Kay und anderen Sprachuniversalisten modifiziert. Kritisiert wurden die Ausklammerung kulturspezifischer Faktoren, der anglozentrische Ansatz und die arbiträren, teils widersprüchlichen Kriterien für die Identifizierung der Grundwörter. Aspekte des Berlin/Kayschen Modells (der Begriff eines begrenzten Inventars von Grundfarbennamen) wurden häufig von germanistischen Linguisten akzeptiert, typischerweise aber mit signifikanten Modifikationen, so beispielsweise bei Caroline Kaufmann. Aufgrund von zwölf dem deutschen Sprachsystem eigens zugeschnittenen Kriterien identifizierte Kaufmann ein Inventar von lediglich acht Grundfarbadjektiven ("blau, braun, gelb, grau, grün, rot, schwarz, weiß"), daneben acht Zwischenfarbadjektive ("rosa, pink, orange, türkis, lila, violett, purpur, beige").

Die emotionale Wirkung von Farbnamen nutzt die Werbung für kommerzielle Produkte, da hier Verknüpfungen zu „ansprechenden“, allgemein bekannten Gegenständen oder Situationen nutzbar sind. Die Bezeichnung "Sahara" als Oberflächenfarbe von Autos steht symbolisch für Sehnsucht oder Weite, und "Ferrari-Rot" soll Gedanken an Leistung und Geschwindigkeit wecken. Zweifellos ist durch Kulturkreis, Psyche und Erziehung eine Symbolik der Farben vorhanden, was sich mitunter in Sprichwörter und Bewertungen ausdrückt. In diesem Sinne stehen Farbnamen auch für Gefühle und umgekehrt. 

Zur Dokumentation deutscher Farbbezeichnungen (einschließlich Farbmittelnamen) in allen Sprachperioden bietet das historische Lexikon von William Jervis Jones eine Sammlung von Farbnamen und Ableitungen mit Textbelegen. Das Werk besteht aus Band I: Quellen und Literatur, Althochdeutsch, Mittelhochdeutsch, und den Bänden II bis V für Frühneuhochdeutsch bis Neuhochdeutsch.

Für die Farbdarstellung auf technischen Systemen existieren verschiedene nationale und internationale Standards und Quasi-Standards, beispielsweise die „Webfarben“ als Teil der vom World Wide Web Consortium herausgegebenen CSS-3-Spezifikation. Farbkataloge mit Farbdarstellungen bieten eine Verbindung zwischen Farbbezeichnungen und flächiger Farbdarstellung, wie das HKS-Farbsystem oder für den deutschsprachigen Raum der RAL-Farbkatalog. In Deutschland nicht so verbreitet aber dennoch gebräuchlich ist das Pantone-Farbsystem.

Wie im Abschnitt Wahrnehmung beschrieben, kann eine Farbe als dreidimensionale Eigenschaft dargestellt werden. Daher werden technische Farbangaben meist als 3-Tupel in einem Farbraum angegeben; dementsprechend gibt es oft drei Grundfarben oder Primärfarben, auf denen der jeweilige Farbraum aufgebaut ist. Angaben solcher Farbkoordinaten, als Farbort, sind wenig anschaulich, für technische Anwendungen (beispielsweise Toleranzangaben in Verträgen) notwendig und unumgänglich. Nur so lässt sich „Farbe“ umrechnen und Farbmanagement wird erst möglich.

Die Angabe von drei Farbkoordinaten allein besagt nichts, wenn nicht das zugehörige Farbsystem angegeben ist, um verständliche Aussagen zu machen. Speziell im Falle eines Gerätefarbraums, also für das spezielle (individuelle) Gerät, ist diese Beziehung zu beachten. Am gleichen Bildschirm sehen die drei Balken gleich aus, so scheint der Farbton (Rot, Grün, Blau)= {#800080} für ein Purpur im RGB-System ausreichend definiert. Beim Betrachten des so erzeugten Farbreizes an verschiedenen (nebeneinander stehenden) Monitoren erscheinen die Balken allerdings unterschiedlich, insbesondere wenn die Monitore "unkalibriert" sind. Für die Prüfung des zur Betrachtung dieses Artikels genutzten Monitors und dessen Einstellung kann die unten angezeigte Grafik dienen. An LC-Bildschirmen wirkt oft sogar der Betrachtungswinkel verändernd auf den wahrgenommenen Farbeindruck.

Damit Farbe wahrgenommen werden kann, ist Licht nötig. Dieses entsteht durch Wärmebewegung von Molekülen bzw. Atomen oder durch Änderungen in den Energieniveaus der Elektronenhülle von Atomen.

Körperfarbe ist jene visuelle Wahrnehmung von Gegenständen, die durch spezifische Änderungen des remittierten Spektrums wegen Absorption stoffspezifischer Wellenlängen der optischen Strahlung oder durch Streuung von der Oberfläche reflektiert wird. In der Malerei wird der Begriff Gegenstandsfarbe genutzt und im Speziellen Falle Lokalfarbe als Gegensatz zu Gesamtton. Dabei kann auch durch die Struktur der Oberfläche eine physikalisch begründete Färbung (Strukturfarben), etwa die schillernden Flecken auf den Flügeln eines Schmetterlings, entstehen.

Reizt Licht eines bestimmten Lichtspektrums das Auge, hat das außer der einfachen Sinnesempfindung (wie „kirschrot“, „himmelblau“) komplexere und farbspezifische psychische Wirkungen im Zentralnervensystem.

Bei Menschen desselben Kulturkreises bestehen durch Tradition und Erziehung viele Gemeinsamkeiten, aber es bestehen auch individuelle Unterschiede. Solche seelischen Wirkungen der Farbwahrnehmung werden – intuitiv oder bewusst – für Effekte bei der künstlerischen Gestaltung sowie in der Mode- und Werbebranche genutzt. Dabei helfen psychologische Farbtests eine angestrebte Wirkung zu erreichen. Farbempfindung wirkt genauso wie andere Eindrücke auf die Psyche ein. Unübliche Färbung kann Details hervorheben oder verbergen und dadurch irritieren.

Psychologischen Farbtests wie dem Lüscher-Farbtest wird zugeschrieben, von der Bevorzugung bestimmter Farben und Farbkombinationen auf die Persönlichkeit der Testperson schließen zu können. Allgemeiner sollen Farbtests Auskunft geben, wie eine Persönlichkeit auf welche Farben reagieren. Psychische Farbwirkungen werden in vielen Kulturen angenommen, was sich in Sprichwörtern und Redewendungen niederschlägt. Erkenntnisse hiervon werden in der Werbung gezielt eingesetzt.

Durch die Erfahrung ergeben sich die einfachsten Beziehungen zu den Farben, wie dies für das Temperaturempfinden gilt.
Diese Beziehung darf nicht mit der physikalisch definierten Farbtemperatur von Lichtquellen verwechselt werden. Zudem unterliegt sie individuellen und kulturellen Unterschieden der Farbwahrnehmung. So gilt Blau meist als kalte Farbe, wurde im Mittelalter aber als warm eingestuft und beispielsweise mit der Gottesmutter Maria assoziiert.

Die Wirkungen und symbolischen Bedeutungen von Farben, auch bezogen auf verschiedene Kulturkreise, sind in den entsprechenden Artikeln zu den Farbtönen und Unbuntfarben zu finden.

Die Arbeitsweise des visuellen Systems im Zentralnervensystem und besonders im Gehirn im Zusammenspiel mit dem Gefühlszentrum ist noch unerforscht. Andererseits ist die Wahrnehmung unterschiedlicher Wellenlängen in den Zapfen und Stäbchen der Netzhaut nicht allein für die Entstehung des wahrgenommen Bildes verantwortlich. Der Sehvorgang von Farbe und Form eines Objektes ist auch dadurch geprägt, dass das Großhirn einen Sinneseindruck mit einer dazugehörenden Erinnerung verbindet. Die empfundene Farbe eines Objektes ist nicht immer mit der messtechnischen (da physikalischen) vergleichbar. Vielmehr ist das wahrgenommene Bild der momentan aufgenommenen Informationen überdeckt, vom Wissen zu diesem Objekt.

In der Psychologie ist der Begriff "Gedächtnisfarben" eingebürgert, wenn es um Farbwahrnehmung geht. Objekte mit einem typischen Farbton werden also unter Rückgriff auf den im Gedächtnis gespeicherten prototypischen Farbton wahrgenommen. So werden Tomaten in einem intensiveren Rot wahrgenommen als es ihrer tatsächlichen Erscheinung entspricht. Eine Wiese erscheint selbst in der Dämmerung noch grün. Auch der blaue Himmel ist solch eine Ausbildung, für die Römer war der Himmel „licht“, im Sinne von hell.

In der Farbmetrik kann diese Individualisierung zu Schwierigkeiten führen, da zwei physikalisch gleiche Farben von verschiedenen Personen nicht zwangsläufig auch gleich beurteilt werden.

Die Wahrnehmung von Farben wirkt psychologisch auf zweierlei Art.

Assoziationen und Gefühle infolge von Farbwahrnehmung, gehen in die Traditionen der Kultur im jeweiligen Volksbereich ein.
Nach der „Empiristischen Theorie der Gefühlswirkung von Farben“ werden Farbgefühle individuell und implizit (unbewusst, nicht erinnerbar) gelernt: Das sind vor allem Gefühle, die der Mensch auf Grund ererbter Triebstruktur und Daseinsthematik ursprünglich gegenüber bestimmten überall vorkommenden „Universalobjekten“ oder „Universalsituationen“ entwickelt.


Weil die Erfahrung und die Erziehung diesen gefühlsbesetzten Dinge eine (vom Kulturkreis) bestimmte Farbe beigibt, entwickelt der Mensch Gefühle schon dann, wenn er die Farbe allein wahrnimmt. Die Reaktion auf die Farbe ist sodann bereits eingeprägt: Rot alarmiert, auch wenn das vermeintlich dazugehörende Feuer fehlt und nur die Wand des Raumes grell rot gestrichen ist. Das entspricht dem erlernten bedingter Reflexe bei Pawlows Hunden durch klassische Konditionierung.

Farbe ist eine auffällige Stoffeigenschaft. Bereits dem Steinzeitmenschen war diese visuelle Qualität bekannt, die allen Primaten eigen ist. Beleg für eine aktive Wahrnehmung sind die steinzeitlichen Höhlenzeichnungen, in denen Menschen die ›gesehene‹ Farbe der Natur in eigener Schöpfung mit andersartigen Farbstoffen reproduziert haben.

Handwerkliche Tätigkeit erfordert die Nachbildung von Farbvorlagen, religiöse Ansichten zur Natur führten zu philosophischen Betrachtungen über diese Stoffeigenschaft und Lichterscheinungen. Erste Anmerkungen dieser Art finden sich im klassischen China, im alten Vorderasien und besonders dann in der Antike. Das glänzende Gelb des Materials Gold, der Substanz der Götter, der Abglanz der Sonne führten zum Wunsch dies nachzugestalten. Versuche der Metallhandwerker und philosophische Ansätze zur Stoffwandlung auf Basis der Theorien der Elemente förderten den Wunsch teure Pigmente anders und billiger in gleicher „Farbe“ herzustellen. Insbesondere das „schöne“, aber teure Gold gemäß seiner „sehbaren“ Eigenschaft – der Farbe – „nachzubauen“ wurde zur Grundlage und Triebkraft der Alchemie, der hermetischen Kunst.

Theorien und Lehren zur Farbe entwickelten sich wie jede Art von Wissenschaft im Widerstreit. Für Demokrit waren rote Teilchen spitz und die grünen rund.

Im deutschen Sprachraum wirkten am stärksten die Untersuchungen und Ansichten von Johann Wolfgang von Goethe, unterstützt durch Philipp Otto Runge in seiner Gegenansicht zu Isaac Newton. Zu nennen sind Hermann von Helmholtz, Ewald Hering, Wilhelm Ostwald und auch Johannes Itten oder Harald Küppers. Bei allen Aufgeführten ist der pädagogische Aspekt des „Ratgebens zur Farbanwendung“ vorhanden.

Grundlage für Farben, im Sinne von Farbstoff, zur Farbgestaltung waren anfangs die Naturstoffe. Blau wurde aus sehr teurem (da seltenem) Lapislazuli-Pulver gewonnen. Der Blaufärbung von Stoffen diente die Küpe mit Indigo. Purpur aus dem Sekret der Purpurschnecke war der Farbstoff für Kaiser und Könige. Rot stammte aus der Cochenille-Schildlaus. Für Braun-, Gelb- und Rottöne wurden Erden eingesetzt. Stellvertretend sind Umbra und die Terra di Siena (Sienaerde) aus Italien zu nennen. Weiß wurde als Bleiweiß aus Blei gewonnen. Für Schwarz eignete sich Ruß als Pigment, für die schwierige Schwarzfärbung von Stoffen gab es ein besonderes Handwerk: die Zunft der Schwarzfärber. Gold hatte in der byzantinischen Malerei als Himmelsfarbe eine metaphysische Bedeutung.

Im 19. Jahrhundert wurde die Farbpalette durch neue anorganische Farbstoffe und Pigmente erweitert. Berliner oder Preußisch Blau, Rinmans Grün, Schweinfurter Grün. Durch Imitation seltener natürlicher Farbstoffe in großen Mengen, durch industrielle Verfahren oder neu geschaffene Innovationen wurden die Färbemöglichkeiten erweitert.

Durch die organischen Anilin-Farben (Teerfarben) wurde die Anzahl der verfügbaren Färbemittel erheblich erweitert. Die natürlichen Pigmente und Farbstoffe konnten durch synthetische Farben für den wachsenden Bedarf in Kunst und Wirtschaft ersetzt werden. Die alten Namen mit regionalen Bezügen blieben teilweise noch erhalten. Neapel-Gelb, Venezianer-Rot, Veroneser Grün sind Beispiele dafür.

Im 20. Jahrhundert wurden durch Farbfotografie und Farbdruck die Möglichkeiten der Wiedergabe von Naturvorlagen über das „Farbvolumen“ von Gemälden oder künstlerischen Grafiken (Handkoloration) hinaus erweitert. So wurde seither nach den Gesetzen der farbexakten Wiedergabe geforscht. Die Entwicklung im Farbfernsehen und Digitalfotografie erlaubten wiederum verbesserte Farbwiedergaben der Naturfarben, aber die Sehgewohnheiten änderten sich ebenfalls und erforderten bessere Farbnachstellungen. Probleme bei der Umsetzung der Farben einer Vorlage vom Scanner zum Großformat für Reklamezwecke werden durch „Farbtraining“ in der Breite der Bevölkerung neu wahrgenommen.

Durch die entstehenden höheren Ansprüche der Verbraucher an die Farbwiedergabe, die neuen technischen Möglichkeiten und die Forschungsergebnisse entwickelte sich die „Messung“ der physiologischen Größe Farbe zur Farbmetrik.

Die Internationale Vereinigung für die Farbe besteht seit 1967.

Es wurden verschiedene Farbmodelle entwickelt, in denen Farben "quantitativ" (mit Hilfe von Zahlen) beschrieben sind, ohne dass notwendigerweise eine Verständlichkeit der Zahlentripel mit Empfindungen vorliegt. Die Angabe (L = 75, a = 5, b = 33) ruft nicht explizit eine Wahrnehmung einer Farbe hervor. Im Farbmodell wird jede enthaltene Farbe als Punkt innerhalb eines (oft) dreidimensionalen Farbraumes dargestellt – dessen maximaler Umfang sich nach der "Reinheit" der jeweiligen Grundkomponenten richtet. Die Modelle sind durch den Anwendungsfall bedingt und begrenzt, deren Farbraum sollte alle in der jeweiligen Technik möglichen Farben umfassen. Für den Fall, dass in einem Farb-Workflow unterschiedliche Techniken der Farbreproduktion verwendet werden, können diese nur bedingt ineinander umgerechnet werden. Teilweise sind nicht-lineare Beziehungen möglich, meist handelt es sich aber um Matrizen mit Stützstellen, zwischen denen dann linear interpoliert werden muss. Unterschiedliche Farbräume sind nicht deckungsgleich – die Farben können deshalb oft nur relativ zueinander, nicht jedoch absolut gleich reproduziert werden. Der wichtigste Fall ist die Abbildung des RGB-Farbraumes (Farben am Monitor designt) auf den CMYK-Farbraum der Druckfarben.

Anders das CIE-Lab-Modell, das auf Untersuchungen der menschlichen Farbwahrnehmung basiert, so dass darin alle vom Menschen wahrnehmbaren Farben enthalten sind. Deshalb wird „Lab“ oft in der Farbreproduktion als Referenzfarbraum verwendet, über den die anderen Farbräume definiert werden.


Neben diesen mathematisch definierten (stetigen) Farbräumen gibt es Mustersammlungen, in denen materielle Proben von definierten Farbtönen enthalten sind. Diese werden je nach Branche als Mappen, Einzelmuster oder Farbfächer ausgegeben. Beispiele sind:


In einer neutralen Farbdefinition (wie CIELAB, sRGB) können Farbwerte und -kataloge rechnerisch miteinander verglichen werden. Hierbei ist zu beachten, dass der Farbumfang (Gamut) des Modells ausreichend groß ist, ansonsten müssen Out-Of-Gamut Farbtöne auf diesen projiziert werden. Da der CIELAB-Farbraum keinen eingeschränkten Gamut aufweist, sondern alle möglichen Farben eindeutig definiert enthält, sind Farbvergleiche in CIELAB am sinnvollsten. Aufgrund der wahrnehmungsgerechten Definition von CIELAB sind die hiermit berechneten Farbabstände (Delta E) auch aussagekräftiger als bei RGB-Berechnungen.

Um die Änderung von Farben bewerten zu können werden in verschiedenen Industriebranchen genormte Graumaßstäbe eingesetzt.

Soll eine große Anzahl verschiedener Farben erzeugt werden, so wird die gewünschte Farbe meist aus einer geringen Anzahl Grundfarben gemischt. Oft genügen dazu die drei Grundfarben, die jedoch im realen Praxisfall (als Farbstoff oder auch Licht) meist nicht zur Verfügung stehen.







Diese Unterscheidung ist begründet in der Farbwahrnehmung.

Anzumerken bleibt, dass die Zapfen und Stäbchen entwicklungshistorisch auf die gleichen lichtreagierenden Ausgangszellen zurückgehen. Diese Entwicklung führte dazu, dass das Wahrnehmungsspektrum anderer Tierarten vom menschlichen abweicht. Bienen sind im Ultravioletten besser ausgerüstet, ihre Sehzellen nehmen kurzwelligere Strahlung (energiereichere Photonen) wahr als der Mensch. Bei Vögeln hat sich die Kontrastwahrnehmung zwischen roten Früchten und grünem Laub als wichtiger erwiesen. Für Fische ist die bessere Wahrnehmung von kurzwelliger Strahlung nötig, da langwelligere Anteile des Sonnenlichtes durch Wasser absorbiert werden.

Von "Farbe" zu sprechen ist bezüglich des Sehens der Tiere nur in dem Sinne möglich, dass Licht in Abhängigkeit von der Wellenlänge unterschiedlich registriert wird.

Die komplexe Natur des Phänomens Farbe ist schließlich auch Grundlage für unterschiedliche Abstraktionsebenen und scheinbar widersprüchlichen Aussagen. Ein Beispiel hierzu findet sich unter Purpurlinie.






</doc>
<doc id="1734" url="https://de.wikipedia.org/wiki?curid=1734" title="File">
File

file ist ein traditionelles Unix-Kommando zur Erkennung des Typs oder MIME-Typs einer Datei.

Die erste Version von "file" datiert zurück bis 1973, "Unix Research Version 4". System V beinhaltete schon eine wesentlich verbesserte Version von "file", seit dieser Version wurden die Informationen über die Dateitypen nicht mehr direkt in die Programmdatei kompiliert, sondern von einer externen Textdatei ("mime magic file") zur Laufzeit eingelesen.

Die heutzutage verbreiteten Unix-Derivate, das heißt vor allem BSD und Linux, verwenden eine freie Open-Source-Implementierung, die von Ian Darwin neu geschrieben wurde. Diese Implementierung wurde 1989 von Geoff Collyer weiterentwickelt und erhielt seitdem verschiedenste Verbesserungen, unter anderem von berühmten Open-Source-Hackern wie Guy Harris, Chris Lowth und Eric Fischer. Der aktuelle Betreuer ist Christos Zoulas.

Die Single UNIX Specification (SUS) sieht vor, dass eine Implementierung des Programms "file" eine fest definierte Reihe von Tests mit der auf der Kommandozeile angegebenen Datei durchführen muss, um damit ihren Typ festzustellen:

In zeitgemäßen Implementierungen von "file" werden in den Tests, in denen Teile der Datei eingelesen werden, Vergleiche mit einer Textdatenbank angestellt, die magische Zahlen enthält. Damit unterscheidet sich "file" von wesentlich primitiveren Dateityperkennungen, z. B. anhand Dateiendungen oder MIME-Typ-Angaben.

In den meisten Implementierungen benutzt "file" eine Datenbank, mit der es die ersten Bytes einer Datei abgleicht. Diese Datenbank wird üblicherweise in einer sogenannten "magic"-Datei (engl., Magisch) gespeichert, welche typischerweise im Dateisystem unter /etc/magic, /usr/share/file/magic o. ä. gespeichert wird. Der Umfang dieser Datei ist meist ausschlaggebend für die Güte der "file"-Tests zur Bestimmung auch exotischer Dateitypen.

"file" lässt sich, wie die meisten Unix-Kommandos, quasi intuitiv benutzen. Ein Aufruf läuft nach dem Schema

Eine der Single UNIX Specification konforme Implementierung von "file" muss mindestens die folgenden Argumente verarbeiten können:

Die folgenden Beispiele zeigen die typischen Ausgaben von "file", wenn man das Programm mit diversen Dateitypen aufruft. Die fiktiven Dateinamen sollen dabei dem eigenen Dateityp entsprechen. Das Doppelkreuz "#" soll andeuten, dass diese Zeile in einer Shell eingegeben werden muss.




</doc>
<doc id="1735" url="https://de.wikipedia.org/wiki?curid=1735" title="File Allocation Table">
File Allocation Table

File Allocation Table (kurz FAT [], für "Dateizuordnungstabelle") bezeichnet eine ursprünglich 1977 von Microsoft entwickelte, weit verbreitete Familie von Dateisystemen, die zum Industriestandard erhoben wurde und bis heute auch über Betriebssystemgrenzen hinweg als fast universelles Austauschformat dient. Wesentliche Erweiterungen wurden auch von Seattle Computer Products, Compaq, Digital Research und Novell eingebracht. Als proprietäre Nachfolger entwickelte Microsoft NTFS und exFAT.

Das FAT-Dateisystem wurde ursprünglich 1977 in einer 8-Bit-Variante von Marc McDonald für Microsofts Standalone Disk BASIC-80 für 8080-Prozessoren entwickelt, 1978 auf einer DEC PDP-10 unter Zuhilfenahme eines 8086-Simulators für Standalone Disk BASIC-86 portiert, und 1979 für Microsofts Betriebssystem MDOS/MIDAS adaptiert.

Ebenfalls 1979 wurde Standalone Disk BASIC-86 von Bob O'Rear auf eine von Seattle Computer Products (SCP) entwickelte S-100-Bus-Hardware-Plattform angepasst. Bei dieser Gelegenheit wurde Tim Paterson auf das Dateisystem aufmerksam, das er 1980 als konzeptionelle Grundlage seines 12-Bit-Dateisystems für SCPs Betriebssystem QDOS wählte, welches, umbenannt in 86-DOS, von Microsoft zunächst lizenziert, aufgekauft und daraufhin 1981 die Ausgangsbasis für MS-DOS und PC DOS 1.0 wurde.

Zu der Familie der FAT-Dateisysteme gehören:


Mit der 1980 erschienenen ersten Version von QDOS bzw. 86-DOS wurde FAT12 als Dateisystem für 8,0″- und 5,25″-Disketten eingeführt. Erst ab 86-DOS 0.42 von Februar 1981 wiesen die internen Ordnungsstrukturen jedoch ein Format auf, das dem späteren FAT12-Format in MS-DOS und PC DOS in allen wesentlichen Punkten glich. Aufgrund abweichender logischer Geometrien und der Tatsache, dass der BIOS Parameter Block (BPB) erst mit DOS 2 eingeführt wurde, können jedoch (mit Ausnahme von SCP MS-DOS 1.25) weder MS-DOS noch PC DOS auf unter 86-DOS formatierte Medien zugreifen.

Anfangs wurden keine Unterverzeichnisse verwaltet. Das änderte sich mit MS-DOS Version 2.0.

FAT12 wird nur auf Datenträgern bzw. Partitionen bis zu einer Größe von 16 MiB eingesetzt; es ist bis heute auf allen FAT-formatierten 3,5″-Disketten im Einsatz.

Merkmale:


FAT16 ist ein Dateisystem, das 1983 zu "FAT12" dazukam. Durch die zunehmende Größe der eingesetzten Festplatten wurde eine Erweiterung des Adressraumes notwendig. Nun waren selbst mit 512-Byte-Clustern zumindest theoretisch insgesamt 32 MiB große Platten verwaltbar.

Die ursprüngliche FAT16-Implementierung verwendete auf partitionierten Medien in der Regel (abhängig vom jeweiligen DOS-OEM) den Partitiontyp 04h und einen noch vergleichsweise kurzen BIOS Parameter Block (BPB) im Bootsektor. Dessen genauer Aufbau und Inhalt hing insbesondere bei DOS 2.x noch stark von der verwendeten DOS-Version ab, er enthielt jedoch in allen Fällen nur einen 16-Bit breiten Eintrag für die Sektorenanzahl, was die Größe von FAT16-Laufwerken auf 32 MiB bis 512 MiB beschränkte (je nach Betriebssystemversion). Mit OS/2 Release 1 wurde ein Enhanced BIOS Parameter Block (EBPB) eingeführt, erkennbar am Signaturbyte 28h (für DOS-BPB-Version 4.0) an Offset +26h. Mit Einführung von DOS 3.31 wurde dieser durch den nochmals erweiterten, heute allgemein für FAT12 und FAT16 verwendeten "Extended BIOS Parameter Block" (XBPB) mit Signatur 29h (für DOS-BPB-Version 4.1) an Offset +26h ersetzt. EBPB und XBPB zeichnen sich u. a. dadurch aus, dass der Eintrag für die Zahl der Sektoren auf 32 Bit Breite wuchs, womit erstmals FAT16-Laufwerke mit bis zu 2 GiB, später 4 GiB, möglich wurden, auch wenn die damaligen Betriebssysteme davon noch keinen Gebrauch machen konnten. Diese größere Variante von FAT16 wurde in Entwicklerkreisen „BigDOS“ genannt, daher stammt auch ihr offizieller Name "FAT16B." Da ältere Betriebssysteme mit diesem neuen Typ nicht arbeiten konnten, wurde für die Verwendung auf partitionierten Medien auch ein neuer Partitionstyp (06h) dafür definiert. Die alte FAT16-Variante wird zwar nach wie vor unterstützt, findet aber (bis auf die forcierte Erzeugung von sehr kleinen FAT16-Partitionen mit dem Partitionstyp 04h) in der Praxis keine Verwendung mehr, da spätestens seit DOS 5 bei der Erzeugung von FAT12- und FAT16-Partitionen gleichermaßen nur noch Bootsektoren mit XBPB geschrieben werden, um einige neue Betriebssystemfunktionen optimal zu unterstützen. Die Tatsache, dass es eigentlich zwei FAT16-Typen gibt, ist in der Allgemeinheit nicht mehr präsent, mehr noch, da "FAT12" fast nur noch für Disketten verwendet wird, wird heute "FAT" oft fälschlicherweise nur mit "FAT16" (und das auch nur in der beschriebenen "FAT16B"-Variante) gleichgesetzt, obwohl darunter eigentlich mehrere FAT12- und FAT16-Typen zu verstehen wären. Allerdings benötigt das Server-Betriebssystem Novell-Netware bis zur Version 4.0 noch eine bis zu 16 MiB große „DOS“-Bootpartition, die (automatisch) mit FAT12 erzeugt wurde.

Erfolgt der Zugriff über LBA (Logical block addressing), wird eine FAT16-Partition auch als "FAT16X" bezeichnet.

FAT16 hat folgende Merkmale:

Eine Weiterentwicklung erfolgte mit "FAT32".

FAT32 ist ein von Microsoft entwickeltes Dateisystem, das im Sommer 1996 mit Windows 95B eingeführt wurde und die Vorgängerversion "FAT16" ergänzt.

Partitionen kleiner als 512 MiB werden nach wie vor mit FAT16 erzeugt, von 512 MiB bis 2 GiB hat man die Wahl, ab 2 GiB wird FAT32 benutzt. Die Adressierung arbeitet mit 32 Bit, wovon 4 Bit reserviert sind, so dass 2 = 268.435.456 Cluster adressiert werden können.

FAT32 kann außerdem mit allen Windows-Versionen seit Windows 95B sowie – anders als NTFS – problemlos auch mit FreeDOS und Enhanced DR-DOS verwendet werden. Da Windows je nach Version von Haus aus nur wenige Dateisysteme unterstützt, wird FAT32 trotz seiner Beschränkungen zum Datenaustausch sowohl mit anderen Windows-Systemen als auch mit Nicht-Windows-Systemen (z. B. macOS, Linux) eingesetzt, z. B. auf USB-Speichersticks und mobilen Festplatten.

Spielekonsolen wie beispielsweise die PlayStation 3 oder digitale Satellitenreceiver setzen bei extern angeschlossenen Festplatten häufig FAT32 als Dateisystem voraus.

Ein Nachteil eines standardkonformen FAT32-Dateisystems ist, dass nur Dateien erstellt werden können, die kleiner als 4 GiB sind. Mit der rückwärtskompatiblen Erweiterung FAT32+ sind zwar auch Dateien bis zu 256 GiB möglich, diese Erweiterung wird aber nur von wenigen Systemen unterstützt. Ein weiterer Nachteil ist, dass Windows ab Version 2000 mit dem eigenen Formatierungswerkzeug nur 32 GB formatieren kann.

Da bis zu einer Partitionsgröße von 8 GiB ein Cluster nur 4 KiB groß ist (bei der Standardformatierung), werden diese „kleinen und alten“ Platten verhältnismäßig besser ausgenutzt als mit FAT16, wo ein Cluster bis zu 32 KiB belegt (unter Windows NT oder Windows 2000 FAT16-Clustergröße maximal 64 KiB).

Erfolgt der Zugriff über LBA (Logical block addressing), wird eine FAT32-Partition auch als FAT32X bezeichnet.

FAT32 hat folgende Merkmale:

Da auch in aktuellen Windows-Installationen FAT32 und NTFS koexistieren können, ist zu beachten, dass bei der Übertragung von Dateien von NTFS auf FAT32 sowohl NTFS-Streams als auch die Berechtigungen verloren gehen, was je nach Anwendungszweck sinnvoll oder störend sein kann.

VFAT ("Virtual File Allocation Table") ist eine Erweiterung des FAT-Formats zur Verwendung langer Dateinamen, die auf FAT12, FAT16 und seit dessen Einführung im Jahr 1997 auch auf FAT32 angewendet werden kann. Gelegentlich wird im Sprachgebrauch auch fälschlich "VFAT" mit "FAT32" gleichgesetzt.

Die Designer von Windows 95 hatten das Ziel, die Nutzung von langen Dateinamen zu ermöglichen, obwohl die auf MS-DOS aufbauenden Versionen das unter der NT-Serie dafür vorgesehene Nachfolge-Dateisystem NTFS nicht unterstützen. Das wird durch einen Trick im Layout des Dateisystems erreicht. Die Datei wird wie bisher als 8.3-Dateiname gespeichert, bei längeren Namen wird jedoch ein Alias in der Form xxxxxx~1.xxx verwendet, wobei die Nummer hochgezählt wird. Der lange Name wird dann über mehrere Verzeichniseinträge verteilt, die ältere Systeme als ungültig ansehen. Während bisher ein Eintrag auf eine Datei verwies, kann jetzt eine Datei mehrere Einträge mit je 32 Byte belegen. Das endgültige Format erlaubt bis zu 255 Zeichen lange Dateinamen (wobei der Name inklusive Speicherpfad bis zu 260 Zeichen enthalten kann) und nutzt Unicode als Zeichensatz mit der Kodierung UCS-2.

In bisher von Microsoft-Systemen nicht genutzten Bereichen des Eintrages mit dem 8.3-Dateinamen werden nun auch das Erstelldatum und das Datum des letzten Zugriffes gespeichert.

Auch um lange Dateinamen auf FAT12-Disketten einsetzen zu können, nutzt Windows die VFAT-Erweiterung. Mehrere zusätzliche Verzeichniseinträge liegen vor dem eigentlichen Verzeichniseintrag im FAT12-Format zur Speicherung des langen Dateinamens. Ältere Systeme (z. B. DOS) ignorieren diese Verzeichniseinträge in der Regel, da sie durch eine spezielle Kombination von Attributen markiert sind, u. a. als „Volume“ und „Hidden“. Allerdings kann es durch die Verwendung des „Volume“-Attributes zur Kennzeichnung derartiger Einträge dazu kommen, dass ältere MS-DOS (vor 7.1) im dir-Befehl solche Einträge als Volumenamen interpretieren, speziell wenn der tatsächliche Volumename im Verzeichnis nicht an erster Stelle steht oder ganz fehlt.

"Windows for Workgroups 3.11" unterstützt "VFAT" optional, jedoch nur für Festplatten und ohne die Möglichkeit langer Dateinamen.

"VFAT" wird in "Windows 95" und höher und in "Windows NT 3.5" und höher unterstützt.

Unter Linux wird die "VFAT"-Erweiterung vollständig unterstützt.

In den frühen 1990er Jahren wurde von vielen "Linux"-Distributionen die UMSDOS-Erweiterung für "FAT16" eingesetzt, um "Linux" zu installieren, ohne das Festplattenlaufwerk neu partitionieren und formatieren zu müssen. "UMSDOS" fügt zu einem "FAT"-Dateisystem eine darüberliegende "Unix"-kompatible Schicht hinzu. Diese verwaltet Dateien, die den Namen --linux-.--- tragen. Darin werden Benutzerrechte und auch lange Dateinamen gespeichert.

In "Linux 2.6.11" wurde "UMSDOS" aus dem Kernel entfernt, da es nicht mehr weiterentwickelt wird. Es gibt als Ersatz ein "POSIX-Overlay"-Dateisystem, das "FUSE" verwendet und über einem normalen "FAT"-Dateisystem „eingeblendet“ werden kann.

UVFAT existierte nur für eine kurze Zeit und hat die "VFAT"-Erweiterung zur Speicherung langer Dateinamen genutzt, während der "UMSDOS"-Mechanismus für die unter allen "FAT"-Versionen fehlenden Benutzerrechte verwendet wurde. So waren unter "Linux" angelegte lange Dateinamen auch unter modernen "Windows"-Versionen lesbar und umgekehrt. Die Entwicklung wurde bereits vor derjenigen der "UMSDOS"-Erweiterung wieder eingestellt.

Es gibt folgende Derivate:
exFAT ("Extended File Allocation Table") ist ein speziell für Flash-Speicher entwickeltes Dateisystem. Eingeführt wurde es 2006 mit Windows CE 6.0. exFAT wird dort eingesetzt, wo NTFS nur schwer oder gar nicht implementierbar ist. Windows 7 unterstützt exFAT nativ, Windows Vista erst ab Service Pack 1. Für Windows XP ab SP2 hat Microsoft ein Aktualisierungspaket bereitgestellt und beschrieben. Ab Mac-OS-X-Version 10.6.5 wird exFAT auf Apple-Computern vollständig unterstützt.

Die Vorteile gegenüber vorherigen Versionen sind:

Nachteile:


TFAT ("Transaction-safe File Allocation Table") bietet insbesondere für mobile Geräte mit fest eingebautem Flash-Speicher Schutz vor Beschädigungen des Dateisystems, zum Beispiel wenn während einer Schreiboperation die Stromversorgung des Gerätes ausfällt.

Dafür wird die FAT doppelt geführt: einmal als FAT1 mit den aktuellen Dateizuordnungen und einmal als FAT0 mit dem letzten als konsistent bekannten Stand des Dateisystems. FAT0 wird erst nach erfolgreichem Abschluss einer Transaktion aktualisiert, indem FAT1 nach FAT0 kopiert wird. Eine Transaktion ist beispielsweise das Anlegen einer neuen Datei.

Während des Ablaufs einer Transaktion werden Änderungen am Dateisystem in neu angelegten Clustern gespeichert und FAT1 wird entsprechend angepasst. So kann im Fehlerfall eine unvollständig ausgeführte Transaktion durch Kopieren von FAT0 nach FAT1 rückgängig gemacht und das Dateisystem auf den Stand von vor Beginn der Transaktion zurückversetzt werden.

Das rechnerische Limit für TFAT-Partitionen liegt bei einer Sektorgröße von 512 Byte bei bis zu 2 TiB.

TFAT ist zwar explizit für nicht entfernbaren Speicher gedacht, kann jedoch auch mit Wechselspeichermedien verwendet werden. Allerdings kann es zu Problemen kommen, wenn ein TFAT-Medium in einem anderen Gerät ohne Unterstützung für TFAT verwendet wird. Prinzipiell ist es möglich, von dem Medium zu lesen, doch wird es dann wie ein normales FAT-Medium angesehen werden. Schreibvorgänge werden also nicht transaktionssicher geschrieben. Auch können mit TFAT erstellte Verzeichnisse nicht von FAT-Systemen gelöscht werden.

TFAT wird üblicherweise nicht von Desktopsystemen unterstützt. Unterstützt wird es von Microsoft für Mobilgeräte seit Windows Mobile 6.5 und Windows CE ab Version 6.0.

Ein FAT-Dateisystem gliedert sich in fünf Bereiche:

Alle Mehrbyte-Werte (16/32 Bit) sind im Little Endian gespeichert, d. h. niederwertigste Bytes zuerst.

Der Bootsektor enthält teilweise ausführbaren x86-Maschinencode, der das Betriebssystem laden soll. An anderen Stellen enthält er Informationen über das FAT-Dateisystem.

Anschließend unterscheiden sich die Daten je nach FAT-Variante. Bei FAT12 und FAT16 folgt diese Datenstruktur:

FAT32 benutzt eine davon abweichende Struktur ab Offset 24:

Zwischen Bootsektor und der ersten FAT können Sektoren reserviert werden, die vom Dateisystem nicht benutzt werden. Dieser Bereich kann von einem Bootmanager oder für betriebssystemspezifische Erweiterungen genutzt werden. Auf den meisten FAT12- oder FAT16-Dateisystemen existieren – außer dem Bootsektor – keine weiteren reservierten Sektoren. Die FAT folgt somit direkt im Anschluss an den Bootsektor. FAT32-Dateisysteme enthalten in der Regel noch einige Erweiterungen zum Bootsektor sowie eine komplette Sicherungskopie des Bootsektors und der Erweiterungen.

Die FAT ist eine Art Tabelle fester Größe, in der über die belegten und freien "Cluster" eines FAT-Dateisystems Buch geführt wird. Ein Cluster ist die aus einem oder mehreren Sektoren bestehende Zuordnungseinheit, die von einer Datei belegt werden kann. Der Datenbereich ist in eine feste Anzahl von Clustern eingeteilt. Zu jedem dieser Cluster existiert ein Eintrag in der FAT, der Folgendes angeben kann:


Die Größe (in Bit) und der Wertebereich der Tabelleneinträge unterscheiden sich zw. FAT12, FAT16 und FAT32 wie folgt:

Die Lage der belegten Cluster einer Datei können aus den Adressen der zugehörigen FAT-Einträge berechnet werden. Die FAT-Einträge bilden eine einfach verkettete Liste.

Wegen ihrer grundlegenden Bedeutung für das Dateisystem existieren in der Regel zwei Kopien der FAT, um bei Datenverlust noch immer eine funktionsfähige zweite FAT zu haben. Mit diversen Programmen ist so eine Datenwiederherstellung in vielen Fällen möglich.

Auf Installationsdisketten oder mit Spezialprogrammen formatierten Medien findet man manchmal keine zweite FAT, wodurch der verfügbare Speicherplatz etwas größer wird. Theoretisch ist es auch möglich, ein Dateisystem mit mehr als zwei FAT-Kopien zu formatieren. Diese Dateisysteme können zwar in der Regel von jedem Betriebssystem gelesen werden, jedoch wird die dritte (und jede weitere FAT-Kopie) bei Schreibzugriffen meist nicht aktualisiert, so dass bei Beschädigung der ersten beiden FATs oft keine Reparatur unter Zuhilfenahme der weiteren Kopien möglich ist.

Das Stammverzeichnis (englisch "root directory"), auch Wurzelverzeichnis oder Hauptverzeichnis genannt, ist eine Tabelle von Verzeichniseinträgen. Jede Datei oder Unterverzeichnis wird in der Regel durch je einen Verzeichniseintrag repräsentiert. Die bei Windows 95 eingeführte Erweiterung um „lange Dateinamen“ benutzt jedoch ggf. mehrere Verzeichniseinträge pro Datei bzw. Verzeichnis, um die langen Dateinamen unterzubringen.

Das Stammverzeichnis folgt bei FAT12 und FAT16 direkt der FAT und hat eine feste Größe und damit eine Maximalanzahl an Verzeichniseinträgen. Diese wird beim Formatieren des Dateisystems festgelegt und kann später – außer mit Spezialsoftware – nicht mehr geändert werden.

Bei FAT32 hat das Stammverzeichnis eine variable Größe und kann an einer beliebigen Position des Datenbereichs beginnen.

Je nach Medientyp gibt es unterschiedliche Vorgabegrößen für das Stammverzeichnis. Mit speziellen Formatierungsprogrammen lässt sich jedoch die Größe des Stammverzeichnisses frei wählen. So besitzen beispielsweise Installationsdisketten, die nur sehr wenige Archivdateien enthalten, oft ein minimales Stammverzeichnis, das nur einen Sektor groß ist und somit nur Platz für 16 Verzeichniseinträge bietet.

Ein Verzeichniseintrag besteht aus 32 Bytes.

Zusammenspiel:
Soll nun eine Datei gelesen werden, wird der zugehörige Verzeichniseintrag herausgesucht. Neben den Attributen kann hier nun der Startcluster selektiert werden. Die weiteren Cluster werden dann über die FAT herausgesucht. Am Ende terminiert die Weitersuche jener FAT-Tabelleneintrag, welcher den Wert FFFFFFh enthält.

Ein Unterverzeichnis wird als normale Datei angelegt, außer dass der Eintrag im übergeordneten Verzeichnis mit dem entsprechenden Bit markiert ist. Der Aufbau der Einträge ist mit jenen des Hauptverzeichnisses identisch. Da die Cluster der Unterverzeichnisse über die FAT verknüpft werden, können sie beliebig wachsen und haben keine Begrenzung in der Zahl der verwaltbaren Dateien.

Der Atari ST benutzt für Disketten eine Variante des FAT12-Dateisystems und kann daher unter MS-DOS formatierte und beschriebene Disketten lesen und schreiben. Ursprünglich konnten auf dem Atari formatierte Disketten nicht unter MS-DOS benutzt werden, wohl aber unter MS-DOS formatierte und auf dem Atari beschriebene Disketten. Diese Inkompatibilitäten wurden in späteren GEMDOS-Versionen behoben. Die Unterschiede der Atari-Implementierung im einzelnen:





</doc>
<doc id="1736" url="https://de.wikipedia.org/wiki?curid=1736" title="Fessan">
Fessan

Der Fessan (aus tamazight ⴼⴻⵣⵣⴰⵏ "Fezzan", ) ist eine Landschaft in Libyen, die zur Sahara gehört. Er ist eine der drei historischen Großprovinzen Libyens und früheren Gouvernements, neben Tripolitanien im Norden und der Kyrenaika im Osten.

Der Fessan ist 551.170 km² groß (nach anderen Angaben 684.280 km²), bei einer Bevölkerung von 413.005 Einwohnern (Stand 2003). Im Westen wird er von Algerien, im Süden von Niger und vom Tschad begrenzt. Die bedeutendsten Orte sind Murzuk und Sabha. Letzteres ist das Verwaltungszentrum für den Fessan und hat in dieser Funktion Murzuk abgelöst. Weitere wichtige Orte sind Ghadames und Ghat.

Das Land wird im Wesentlichen von Sand-, Kies- und Felswüsten bedeckt; es gibt jedoch bewohnte Oasen. Die libysche Regierung ist bemüht, die Region durch den Ausbau der Infrastruktur und die Einrichtung von Bewässerungsanlagen zu entwickeln. Die Gefahr der Versalzung der Böden ist dabei groß.

Auf dem Gebiet der früheren Großprovinz Fessan lagen bis 2007 sechs der 32 Munizipien Libyens:

Nach anderen Quellen wird Ghadames (Nr. 18 auf der Karte) noch zum Fessan gerechnet.

Seit dem Altertum wird die Landschaft von Berbervölkern bewohnt. Mit dem 5. Jahrhundert v. Chr. wurden den Griechen die Garamanten bekannt. Zwar eroberten die Römer nicht den Fessan, doch unternahmen sie Expeditionen in die Sahara und haben wohl unter Maternus um 100 n. Chr. die Gebiete am Tschadsee erreicht.

Mit dem Vordringen des Islam und der Einführung des Kamels kam es zu einem Aufschwung des Transsaharahandels, wobei sich Murzuk als bedeutendes Handelszentrum in Fessan etablierte. Nach der Einwanderung der arabischen Banu Sulaym kam es zu einer Vermischung der arabischen Bevölkerungsgruppen mit den Berbern.

Nachdem im 13. Jahrhundert Fessan zeitweise der Herrschaft von Kanem-Bornu unterstanden hatte, geriet das Land im 16. Jahrhundert unter die lockere Oberherrschaft der Osmanen und der Qaramanli. Als Italien Libyen eroberte, unterwarf es 1930 die Stämme des Fessan. Seit 1951 bildet Fessan – gemeinsam mit Tripolitanien und der Kyrenaika – das unabhängige Libyen.




</doc>
<doc id="1737" url="https://de.wikipedia.org/wiki?curid=1737" title="Fructose">
Fructose

Fructose (oft auch "Fruktose", von „Frucht“, veraltet "Lävulose", umgangssprachlich Fruchtzucker) ist eine natürlich vorkommende chemische Verbindung. Fructose gehört als Monosaccharid ("Einfachzucker") zu den Kohlenhydraten. Sie kommt in mehreren isomeren (anomeren) Formen vor. In diesem Artikel betreffen die Angaben zur Physiologie allein die -Fructose. -Fructose ist praktisch bedeutungslos.

Fructose ist eine farb- und geruchlose, leicht wasserlösliche, sehr süß schmeckende Verbindung, die prismen- oder nadelförmige, stark hygroskopische Kristalle bildet. Bei 60 % Luftfeuchtigkeit nimmt sie innerhalb einer Stunde 0,28 % Wasser auf, innerhalb von 9 Tagen 0,6 %. Das Monosaccharid ist optisch aktiv und kommt in zwei spiegelbildlichen Isomeren, den sogenannten "Enantiomeren" vor. Fructose gehört wegen ihrer sechs Kohlenstoffatome zur Gruppe der Hexosen und wegen der Ketogruppe zu den Ketosen (Ketohexosen). In kristalliner Form liegt sie als Sechsring ("Fructopyranose") vor, gelöst teilweise als Fünfring ("Fructofuranose"). Fructose hat einen Brennwert von 3,75 Kilokalorien pro Gramm. Fructose ist ein reduzierender Zucker. Sie neigt daher zur Reaktion mit Aminogruppen (Glykation).

Die α- und β-Anomere der jeweiligen Ringformen können in wässriger Lösung ineinander umgewandelt werden und stehen untereinander in einem Gleichgewicht. Bei 20 °C liegt in Wasser gelöste -Fructose zu 76 % in der β-Pyranoseform, zu 4 % in der α-Furanoseform und zu 20 % in der β-Furanoseform vor.

Fructose kommt in der Natur vor allem in Früchten wie Kernobst (Äpfeln und Birnen zu je etwa 6 g/100 g), Beeren (beispielsweise Weintrauben 7,5 g/100 g) sowie in manchen exotischen Früchten (Granatapfel und Kaki) und im Honig (35,9–42,1 g/100 g) vor. Haushaltszucker (Saccharose, auch Rohrzucker wenn aus Zuckerrohr oder Rübenzucker wenn aus Zuckerrüben hergestellt) enthält Fructose in gebundener Form; er ist ein Zweifachzucker, der sich aus je einem Molekül Glucose (Traubenzucker) und Fructose zusammensetzt. Ein bedeutsamer Anteil bei der Zuckeraufnahme kommt aus industriell gefertigten Nahrungsmitteln, die Fructose-Glucose-Sirup ("high-fructose corn syrup", HFCS) enthalten.

Aus ökonomischen und logistischen Gründen ist, v. a. aufgrund günstiger Transportmöglichkeiten in Tankwagen und einer gegenüber gewöhnlichem Zucker (Kristall- / Tafel- / Haushaltszucker oder Saccharose) 20 % höheren Süßkraft, eine zunehmende Verdrängung anderer Süßstoffe durch Fructose zu beobachten.

Lange Zeit – bis Anfang der 2000er-Jahre – wurde Fruchtzucker zum Süßen diätetischer Lebensmittel empfohlen. Bezogen auf Haushaltszucker hat eine 10-prozentige -Fructoselösung eine Süßkraft von 114 Prozent. Die Angaben variieren zwischen 1,14 (gelöste Form) und 1,8 (kristalline Form). Die Süßkraft von Fructose wirkt synergistisch mit anderen Süßstoffen. Die Pyranoseform der Fructose wirkt süßer als Saccharose, während die Furanoseform etwa gleich süß wirkt. Im kristallinen Zustand liegt nur die süßer wirkende Pyranoseform der Fructose vor. Erwärmen von Fructoselösungen begünstigt die Furanoseform. Fructose ist hygroskopischer als andere Zucker und besitzt eine höhere Löslichkeit in Wasser. Daher sind Zuckermischungen mit Fructose weicher als andere Zuckermischungen, was in einem angenehmeren Mundgefühl resultiert. Allerdings führt sie im Vergleich zu anderen Zuckermischungen zu einer stärkeren Gefrierpunktserniedrigung, was bei tiefgekühlten Nahrungsmitteln unerwünscht sein kann, weil sie weicher werden.

In den USA stieg die kommerzielle Verwendung von Fructose in den 1970er-Jahren drastisch an – der Verzehr von "High Fructose Corn Syrup" (HFCS), einer besonders fructosereichen Version des Maissirups, von 0,23 kg pro Person im Jahr 1970 auf 28,4 kg pro Person im Jahr 1997. HFCS wird in den USA vor allem in Softdrinks eingesetzt, wobei der Fructosegehalt auf bis zu 55 % (HFCS-55) gesteigert wird. Dieser Süßstoff ist für den Hersteller besonders kostengünstig, da in den USA die Maisproduktion subventioniert wird, wohingegen der Zuckerimport verzollt werden muss. Diese signifikante Änderung in der Zusammensetzung der Zuckerzusätze zu Lebensmitteln wurde vorgenommen, ohne dass die möglichen Wirkungen auf den menschlichen Stoffwechsel zuvor umfassend untersucht wurden.

Das Bundesinstitut für Risikobewertung (BfR) kam jedoch bei der Auswertung vorliegender Studien zum Schluss, dass die Verwendung von Fructose als Zuckeraustauschstoff in Diabetiker-Lebensmitteln nicht sinnvoll ist, da sich eine erhöhte Fructoseaufnahme ungünstig auf den Stoffwechsel auswirke und die Entwicklung von Fettleibigkeit sowie des metabolischen Syndroms begünstigt werde. Außerdem kann die erhöhte Zufuhr von Fructose das Risiko für Bluthochdruck steigern.

Fructose wird industriell aus pflanzlichen Stärken wie beispielsweise Maisstärke gewonnen. Durch Zugabe der Enzyme Amylase und Glucoseisomerase wird aus gelöster Maisstärke High-fructose corn syrup erzeugt, z. B. HFCS-42 (mit 42 % Fructose) und HFCS-55 (mit 55 % Fructose, zweite Generation HFCS ab 1976). Seit etwa 1972 werden die Enzyme immobilisiert, wodurch die Produktionskosten von HFCS in den USA unter die Importkosten von Saccharose fielen. Gleichzeitig war dies auch die erste großtechnische Anwendung der Immobilisierung von Enzymen. Daneben wird per Chromatographie noch HFCS-90 mit 90 % Fructoseanteil erzeugt, das zur Herstellung von HFCS-55 aus HFCS-42 verwendet wird. Die meisten Softdrinks verwenden HFCS-55, während die meisten anderen HFCS-gesüßten Lebensmittel HFCS-42 verwenden.

Im Körper wird Fructose über den Polyolweg aus Glucose hergestellt (nicht aber in der Leber – dort fehlt dieser Stoffwechselweg), bei dem Glucose zusammen mit dem Cosubstrat NADPH zu Sorbitol reduziert wird, das dann durch die Sorbitoldehydrogenase zu Fructose oxidiert wird, wobei sich NAD zu NADH reduziert. Fructose wird beispielsweise in der Samenblase beim Mann als Nährstoff für die Spermatozoen gebildet. Netto führt dies zu einer Umwandlung von NADPH zu NADH, was für einen Teil der Langzeitfolgen eines chronisch erhöhten Blutzuckerspiegels (z. B. bei Diabetes) verantwortlich gemacht wird. NADPH wird von der Zelle auch zur Entgiftung gefährlicher Sauerstoffverbindungen benötigt. Weil bei erhöhtem Glucosespiegel im Blut jedoch mehr Glucose über den Polyolweg zu Fructose umgewandelt wird, steigt auch der NADPH-Verbrauch. Zudem sammeln sich Fructose und Sorbitol in den Zellen an, was zum einen die Zelle osmotisch schädigt, zum anderen können bestimmte Zell-Enzyme durch hohe Konzentrationen dieser beiden Zucker gehemmt werden. Fructose wird über die Fructolyse abgebaut, einer Variante der Glycolyse. Die Fructolyse wird durch Insulin verstärkt und durch cAMP gemindert. Daneben kann Fructose-6-Phosphat durch die Glucose-6-Phosphat-Isomerase aus Glucose-6-Phosphat erzeugt werden (und umgekehrt), das zum Aufbau von Hexosaminen verwendet werden kann.

Im Dünndarm wird Fructose von Menschen unterschiedlich gut, vor allem langsamer als Glucose resorbiert. Dies liegt am passiven Transport der Fructose durch spezielle Proteine. zum einen durch das so genannte GLUT5 (Fructose-Transporter, apikal, d. h. an der dem Darmlumen zugewandten Zelloberfläche), das der Fructose Zutritt zu den Darmzellen (Enterocyten) gewährt, und zum anderen durch GLUT2 (Fructose- und Glucose-Transporter, basolateral, d. h. dem Blutkreislauf zugewandt), das der Fructose erlaubt, von den Darmzellen ins Blut zu gelangen. Daneben werden GLUT5 und GLUT2 auch von Nierenzellen gebildet, wodurch diese Zellen ebenfalls Fructose aufnehmen können. Die Michaelis-Menten-Konstante für die Aufnahme von Fructose liegt für GLUT5 bei etwa 6 mM und für GLUT2 bei etwa 11 mM.

Glucose und Galactose hingegen werden schneller sekundär-aktiv (SGLT1, apikal), also unter Energieverbrauch, in die Zelle gepumpt. Dies geschieht reguliert über eine rückgekoppelte Hemmung. Im Gegensatz dazu fließt Fructose unreguliert ohne Energieaufwand entlang ihres Konzentrationsgradienten. Dies führt dazu, dass Fructose niemals vollständig aus der Nahrung aufgenommen wird. Vor allem bei Kleinkindern besteht daher die Gefahr, dass es bei zu hohen Fructosemengen in der Nahrung zu osmotischer Diarrhoe kommt. Neben Fructose werden unter den Monosacchariden nur noch Glucose und Galactose direkt in den Blutkreislauf aufgenommen. Niedrige Dosen an Fructose unter 1 g/kg Körpergewicht werden vollständig im Dünndarm aufgenommen und dort verstoffwechselt. Nach Einnahme größerer Mengen von Fructose nimmt die Konzentration dennoch im Blut kaum zu, da die Fructose vollständig von der Leber aufgenommen wird. Ohne körperliche Betätigung wird Fructose in Glucose und Fettsäuren umgewandelt. Die Glucose wird in Glykogen gespeichert, in Fettsäuren und dann in Fette umgewandelt und auch an den Blutkreislaufs zur Aufrechterhaltung des Blutzuckerspiegels abgegeben.

-Fructose wird bei der Fructolyse in Zellen der Leber durch das Enzym Ketohexokinase C in -Fructose-1-phosphat umgewandelt – so kann sie die Zelle nicht mehr verlassen. Andere Zelltypen besitzen als mögliche Transporter GLUT1, GLUT3 und GLUT4, die nur eine geringe Affinität für Fructose aufweisen – ebenso wie die Hexokinase in diesen Zellen. Der Vorrat an energiereichen Phosphaten wird durch die Ketohexokinase verbraucht: ATP → ADP → AMP und die AMP-Desaminase hochreguliert. Es fällt IMP an, das über den Purinabbau die Konzentration der Harnsäure ansteigen lässt. Fructose-1-phosphat wird durch die Fructose-1-phosphat-Aldolase (Aldolase B) in Glycerinaldehyd und Dihydroxyacetonphosphat gespalten. Nach Phosphorylierung kann Glycerinaldehyd (dann als Glycerinaldehyd-3-phosphat) in die Glycolyse eintreten. Bedeutsamer ist der Abfluss der Zerfallsprodukte in die Triacylglyceridsynthese. Triacylglyceride lagern sich als Depotfett an, aber auch als Fetttröpfchen zwischen den Myofibrillen der Muskulatur. Im Fettgewebe kann Fructose auch als Fructose-6-phosphat in die Glycolyse eintreten, wenn die Glycogenreserven erschöpft sind. Weiterhin wird Fructose von ChREBP gebunden, wodurch Enzyme für die Lipogenese (Fettbildung) und die Gluconeogenese induziert werden.

Fructose bindet beim Menschen an den Rezeptor für den Süßgeschmack auf der Zunge, dessen Aktivierung allgemein mit positiven Stimmungsveränderungen (Affekten) assoziiert ist. Hohe Dosen an Fructose verzögern den Eintritt der Sättigung. Fructose wird im Kraftsport gleichzeitig mit Glucose eingenommen, um eine schnellere Regeneration des Blutzuckerspiegels durch die Bildung von Laktat zu erreichen.

Beim Menschen führen Störungen der Fructose-Aufnahme im Darm oder des Fructose-Stoffwechsels in der Leber zu Krankheitssymptomen. Verschiedene Gendefekte des Fructosestoffwechsels wurden beschrieben: die benigne Fructosurie aufgrund einer Fructokinase-Defizienz, die hereditäre Fructoseintoleranz und die Fructose-1,6-bisphosphatase-Defizienz. Klinische Bedeutung haben die häufige Fructosemalabsorption (auch "intestinale Fructoseintoleranz" genannt), bei der ein gestörter Fruchtzucker-Transport durch die Darmzellen angenommen wird, und die seltene, aber zu ernsten Symptomen führende hereditäre Fructoseintoleranz ("HFI"), die durch eine erbliche Störung des Fructosestoffwechsels in der Leber bedingt ist und bei der Fructose nicht oder nicht in ausreichenden Mengen abgebaut werden kann. Bei der hereditären Fructoseintoleranz wird in der Leber anstatt der Aldolase B die Aldolase A gebildet, die Fructose langsamer umsetzt. Durch die Anhäufung von Fructose-6-Phosphat und Fructose-1,6-Bisphosphat wird die Fructose-1,6-bisphosphatase und die Aldolase A gehemmt, wodurch die Glykolyse und die Gluconeogenese gehemmt wird. Daher folgt bei der hereditären Fructoseintoleranz eine Unterzuckerung auf den Konsum Fructose-haltiger Nahrung.

Bei der benignen Fructosurie (1:130.000, autosomal-rezessiv) liegt ein Mangel der Fructokinase vor. Fructose wird dabei vermehrt mit dem Urin ausgeschieden.

Geschätzte 30–40 % der Mitteleuropäer weisen die Fructosemalabsorption auf, wobei etwa die Hälfte Symptome zeigt. Die Störung tritt vorwiegend im Kindesalter auf. Nichtresorbierter Fruchtzucker wird von den Bakterien der Darmflora vorwiegend anaerob zu Kohlenstoffdioxid, Wasserstoff und kurzkettigen Fettsäuren abgebaut. Diese erzeugen Reizdarmsymptome wie Blähungen, Bauchschmerzen, breiigen, teils übelriechenden Stuhl und Durchfall. Die hereditäre Fructoseintoleranz ist sehr viel seltener; auf etwa 130.000 gesunde Menschen kommt ein von der HFI Betroffener. Diese Form der Fructoseintoleranz bewirkt über eine Störung des Glucosestoffwechsels eine gefährliche Unterzuckerung (Hypoglykämie).

Eine übermäßige Zufuhr von Kalorien in Form von Fructose führt zum metabolischen Syndrom, zu Übergewicht und teilweise auch zu Diabetes mellitus Typ II, nicht aber der Konsum von Fructose innerhalb einer normalen Kalorienzufuhr. Weiterhin kann bei übermäßigem Konsum von Fructose eine nichtalkoholische Fettleberhepatitis entstehen. Fructose wird vom Körper schneller in Körperfett umgewandelt als Glucose. Zudem scheint die Verwendung von Fructose zu einem geringeren Sättigungsgefühl zu führen, da diese keine Insulin-Ausschüttung induziert und Insulin auch zu den Sättigungshormonen gehört. Der Anstieg des Fructosekonsums wird mit der Zunahme des metabolischen Syndroms in Zusammenhang gebracht, eines Risikofaktors für koronare Herzkrankheiten.

Geringe Mengen Fructose verbessern sowohl bei gesunden Menschen als auch bei Patienten mit Diabetes mellitus Typ 2 die Glucose-Toleranz und die glykämische Antwort ohne gesteigerte Insulinsekretion. Die Datenlage ist momentan nicht ausreichend (Stand 2017), um den Konsum von Fructose eindeutig mit einer Häufung von Diabetes mellitus Typ II im Menschen zu assoziieren. Fructose führt im Vergleich zu Glucose oder Saccharose zu einem geringeren Anstieg der Insulin- und Triglycerid-Spiegel im Blut.

Der übermäßige Konsum von fructosehaltigen Getränken wie Limonaden und anderen gesüßten Softdrinks können zu Schädigungen der Leber bis hin zur Fettleber (Steatosis hepatis) mit einhergehender krankhafter Vermehrung des Bindegewebes (Fibrose) führen. Der in den letzten Jahren rapide ansteigende Fructosekonsum spielt damit nicht nur eine wichtige Rolle bei der Entstehung des metabolischen Syndroms, sondern stellt nach neueren Untersuchungen einen eigenständigen Risikofaktor für nicht alkoholbedingte Fettlebererkrankungen ("nonalcoholic fatty liver disease") dar.

Der übermäßige Konsum von Fructose wird mit einem erhöhten Risiko für Gicht (Urikopathie) assoziiert. Durch die vermehrte Synthese von ATP wird auch vermehrt AMP zu Harnsäure abgebaut, welche wenig löslich ist und bei Kristallisation in den Gelenken zu Gicht führen kann. Auch fructosereiche Früchte und Fruchtsäfte scheinen das Risiko zu erhöhen, an Gicht zu erkranken, während von Diätlimonaden diesbezüglich keine Gefahr ausgeht.

 der Verordnung über diätetische Lebensmittel (sogenannte Diätverordnung) regelte einst die Zusammensetzung von speziellen Produkten für Diabetiker. Seit dem 1. Oktober 2010 ist dieser Artikel gestrichen, da der Forschungsstand zu Diabetikerdiäten und Zuckerersatzstoffen zeigt, dass diese Patienten keine derartigen Produkte benötigen und dass ein erhöhter Fructosekonsum sogar schädliche Einflüsse auf die Gesundheit haben kann (siehe Text). Fructose ist die gesetzlich geschützte Bezeichnung einer Zuckerart.

Fructose in kohlensäurehaltigen Getränken kann per HPLC getrennt und nachgewiesen werden.

Als α-Hydroxyketon wirkt Fructose reduzierend, daneben kann sie im Zuge der Fehling-Reaktion im alkalischen Milieu in Mannose und Glucose umgewandelt werden (siehe Ketol-Endiol-Tautomerie), so dass ein Gleichgewicht zwischen all diesen Isomeren vorliegt.

Die Seliwanow-Reaktion ist ein Nachweis für Ketohexosen in der Furanose-Ringform. Da sie im sauren Milieu abläuft, kommt es nicht zur Ketol-Endiol-Tautomerie. Mit Glucose fällt die Probe deshalb negativ aus.

Zunächst wird die Fructose mit Salzsäure erhitzt. Dadurch entsteht das 5-Hydroxymethylfurfural. Dieses reagiert dann mit Resorcin zu einem roten Niederschlag.



</doc>
<doc id="1742" url="https://de.wikipedia.org/wiki?curid=1742" title="Fixstern">
Fixstern

Fixstern (von lateinisch "stellae fixae" „fest stehende Sterne“) ist eine aus der Antike stammende Bezeichnung für die scheinbar unverrückbar am Nachthimmel stehenden (also "fixen") und stets dieselbe Stellung zueinander einnehmenden Sterne, die zusammen mit der Himmelssphäre den Sternenhimmel bilden. Durch ihre gegenseitigen Positionen, die freiäugig als unveränderlich erscheinen, bilden sie die uns bekannten Sternbilder und Konstellationen. Die beobachtbare scheinbare Bewegung dieser „Fixsterne“ im Verlaufe einer Nacht (oder eines Jahres) von Osten nach Westen über das von der Erde aus sichtbare Firmament entsteht durch die Erdrotation bzw. durch den Umlauf der Erde um die Sonne.

Im antiken und mittelalterlichen Weltbild, das sich am Augenschein orientiert, drehen sich die Fixsterne und die Kugelschale des Himmelsgewölbes mit gleichförmiger Winkelgeschwindigkeit um die Weltachse. Der Radius dieser Kugelschale ist nach Ptolemäus (150 n. Chr.) gegenüber der Erde unfassbar groß, sodass die Richtung zu einem Fixstern von allen Punkten der Erdoberfläche als parallel gelten kann. Über die mögliche Entfernung der Fixsterne und ihre Natur ließ sich bis ins 18. Jahrhundert nur spekulieren.

Früher verstand man als Gegensatz zu den "Fixsternen" die "Wandelsterne" (wie z. B. Planeten oder Monde), die innerhalb kurzer Zeiträume ihre Position am Himmel merklich verändern. Ihre Entfernung musste wesentlich kleiner sein, insbesondere beim Erdmond, dessen genaue Stellung vor dem Sternhintergrund von der eigenen Position abhängt.

Tatsächlich besitzen Fixsterne entgegen ihrem Namen ebenfalls eine Eigenbewegung, wie James Bradley 1728 erkannte. Die Bezeichnung "Fixsterne" ist deswegen aus heutiger Sicht unpräzise und wird zunehmend durch "Sterne" ersetzt.


Mit bloßem Auge können am gesamten Himmel etwa 3.000 bis 6.000 Fixsterne wahrgenommen werden, davon aber nur rund die Hälfte "gleichzeitig" von einem irdischen Standort. Sie alle sind Sterne der Milchstraße und befinden sich in sehr unterschiedlichen Entfernungen von uns. Die meisten der heute geschätzten 100 Milliarden Sterne der Milchstraße sind jedoch mit bloßem Auge nicht sichtbar, da sie entweder zu lichtschwach, zu weit entfernt oder von anderen astronomischen Objekten verdeckt sind.

Das dem Sonnensystem nächstgelegene Sternsystem ist das Alpha-Centauri-System, welches aus zwei (bzw. drei) (Fix-)Sternen besteht.



</doc>
<doc id="1748" url="https://de.wikipedia.org/wiki?curid=1748" title="Froschlöffelgewächse">
Froschlöffelgewächse

Die Froschlöffelgewächse (Alismataceae) sind eine Familie in der Ordnung der Froschlöffelartigen (Alismatales) innerhalb der Bedecktsamigen Pflanzen (Magnoliopsida). Die bis zu 100 Arten gedeihen an nassen Standorten oder im Wasser.

Die Vertreter der Froschlöffelgewächse sind selten einjährige oder meist ausdauernde krautige Sumpf- oder Wasserpflanzen. Sie bilden manchmal Rhizome mit Endodermis und manchmal Stolonen. Die Pflanzen enthalten Milchsaft. Pflanzenteile sind unbehaart oder mit einfachen, einzelligen bis sternförmigen Trichomen besetzt.

Die Stängel sind nicht chlorophyllhaltig, kurz, aufrecht und kormusartig. Sie verzweigen sympodial. Entlang der Stängel finden sich oft Reste der Gefäßbündel verwelkter Blattstiele. Oftmals werden Rhizome gebildet, die gelegentlich in Knollen enden. Die Wurzeln befinden sich an der Basis der Stängel oder an den unteren Knoten.

Die Laubblätter schwimmen auf dem Wasser oder stehen untergetaucht aufrecht. Sie sind grundständig, aufsitzend oder gestielt und stehen zweireihig, spiralartig zweireihig, spiralförmig oder oftmals auch in basalen Rosetten. Die Blattstiele besitzen einen drehrunden bis dreieckigen Querschnitt und weisen an der Basis eine Blattscheide ohne Öhrchen auf. Die Blattspreite ist linealisch, lanzettlich, eiförmig oder rhombisch und kann durchscheinende Punkte oder Linien aufweisen. Der Blattrand ist ganzrandig oder gewellt, die Spitze stumpf, spitz oder zugespitzt oder andersförmig abgeschnitten. Die Basis der Blattspreite ist entweder ohne Lappen spitz zulaufend oder mit abgeschnittenen Lappen versehen, pfeil- oder speerförmig. Die Aderung besteht aus parallelen Hauptadern und netzartigen Nebenadern.

Die über einem Blütenstandsschaft meist aufrecht stehenden oder selten auch schwimmenden Blütenstände sind traubig oder durch quirlförmige Verzweigung rispig, selten sind sie auch doldig. Sie enthalten quirlig angeordnete Tragblätter, die linealisch, ganzrandig und nach vorn stumpf bis spitz sind.

Die Blüten sind zwittrig oder eingeschlechtig, gelegentlich auch beides an einer Pflanze (Subdiözie). Wenn die Blüten eingeschlechtig sind, dann können die Arten einhäusig (monözisch) oder zweihäusig (diözisch) getrenntgeschlechtig sein. Die Blütenstiele sind sehr kurz bis lang.

Die radiärsymmetrischen Blüten sind dreizählig mit doppelter Blütenhülle. Die drei grünen und haltbaren Kelchblätter umschließen Blüte und Frucht oder stehen ausgebreitet bis zurückgebogen. Die drei weißen bis rosafarbenen, oder manchmal gelblichen Kronblätter sind zart und werden früh abgeworfen. Die Nektarproduktion kann an der Basis der Kronblätter, an Staubblättern oder aus Staminodien erfolgen.

Es sind ein oder zwei Kreise mit jeweils drei oder mehr untereinander freien Staubblätter vorhanden, die zentrifugal oder zentripetal gebildet werden. Die äußeren Staubblätter können zu Staminodien reduziert sein. Die Staubfäden sind relativ lang. Die an der Basis fixierten oder freistehenden Staubbeutel sind nach außen gewendet und öffnen sich durch Längsschlitze. Die Pollenkörner sind meist pantoporat und stachelig. Es werden drei sechs bis viele freie oder an ihrer Basis verwachsene Fruchtblätter gebildet, die in einem Kreis, spiralig oder unregelmäßig angeordnet sind. Jedes Fruchtblatt enthält eine (selten zwei) anatrope, an der Basis befindliche Samenanlagen, nur in der Gattung "Damasonium" werden zwei bis mehrere Samenanlagen mit marginaler Plazentation gebildet. Der endständig oder seitlich stehende Griffel endet in einer linealischen Narbe.

Die in Gruppen oder einem Kreis zusammenstehenden Früchte sind meist Nüsschen (Achänen), selten Steinfrüchte oder Balgfrüchte, die einen bis einige Samen enthalten. Die Fruchtschale besitzt oft Drüsenhaare. Die U-förmigen Samen besitzen einen hufeisenförmigen Embryo und, wenn sie ausgereift sind, kein Endosperm.

Die Chromosomen sind 2,4 bis 14,4 µm lang. Als Chromosomengrundzahlen werden x = 5–13 angegeben, wovon 7, 8 und 11 am häufigsten vorkommen.

Die Familie der Alismataceae wurde 1799 durch Étienne Pierre Ventenat in "Tableau du Regne Vegetal", 2, S. 157 aufgestellt. Typusgattung ist "Alisma" Die Gattungen der früher eigenständigen Familie Damasoniaceae und Wassermohngewächse (Limnocharitaceae ex ) werden jetzt entsprechend APG III den Alismataceae zugeordnet.

Die Familie der Alismataceae ist fast weltweit verbreitet, besonders aber auf der Nordhalbkugel, hauptsächlich in tropischen und subtropischen Gebieten.

Die Familie der Froschlöffelgewächse enthält 11 bis 16 Gattungen mit 81 bis 100 Arten:



</doc>
<doc id="1750" url="https://de.wikipedia.org/wiki?curid=1750" title="Internationale Friedensfahrt">
Internationale Friedensfahrt

Die Internationale Friedensfahrt auch Internationale Fernfahrt für den Frieden, (poln. Wyścig Pokoju sowie tschech. Závod Míru bzw. international üblich franz. Course de la Paix) war ein Etappenrennen in Mitteleuropa und bis zum politischen Umbruch in den ehemaligen Ostblockstaaten 1989 das international bedeutendste Amateurradrennen. Bis auf wenige Ausnahmen waren Berlin, Prag und Warschau jährlich abwechselnd Start-, Etappen- oder Zielort. Das bisher letzte Rennen wurde 2006 durch Deutschland, Österreich und Tschechien ausgetragen, nachdem es 2005 nicht in die damals neue UCI Protour aufgenommen wurde und auf Grund finanzieller sowie organisatorischer Probleme erstmals seit der Erstaustragung nicht stattgefunden hatte.

Für das Jahr 2014 war vom 1. bis 6. Mai eine Neuauflage des Rennens geplant. Die Friedensfahrt wurde im internationalen Rennkalender der UCI unter der Kategorie 2.2 eingestuft, der Plan wurde jedoch durch den Organisator, den ehemaligen tschechoslowakischen Rennfahrer Jozef Regec, aufgegeben. Stattdessen wurden vier Eintagesrennen im Rennkalender der UCI Europe Tour 2014 registriert.

Die Friedensfahrt wurde 1948 erstmals ausgetragen und fand zunächst zwischen Warschau und Prag statt. Veranstalter waren die Tageszeitungen Rudé právo aus Prag und Trybuna Ludu aus Warschau. Ab 1952 wurde das Rennen auch nach Ost-Berlin geführt und verband danach in wechselnder Streckenführung jeweils im Mai die Hauptstädte der drei teilnehmenden Staaten Polen, Tschechoslowakei und DDR. Für die DDR war die Tageszeitung Neues Deutschland Veranstalter. Offizielles Symbol für die Friedensfahrt wurde Pablo Picassos weiße Friedenstaube.

Wegen der politischen Situation in der Tschechoslowakei wurde die Friedensfahrt 1969 nur auf dem Gebiet Polens und der DDR ausgetragen.

Der spätere Straßenradweltmeister Täve Schur wurde 1955 der erste Gesamtsieger für die DDR. Ein Jahr später trat erstmals ein Team aus Westdeutschland an. Die erste Etappe für die Bundesrepublik gewann der spätere Bundestrainer Peter Weibel 1976.

Die Friedensfahrt galt bis zur Wende und friedlichen Revolution 1989 als die „Tour de France des Ostens“ und war dort ähnlich populär wie diese in Westeuropa.

Die Friedensfahrt wurde weitgehend von den Staatsamateuren der mittel- und osteuropäischen Länder dominiert. Die ebenfalls teilnehmenden westeuropäischen Nationalmannschaften konnten nur mit Nachwuchsfahrern, die keinen Profistatus hatten, starten.

Die Friedensfahrt 1986 startete in Kiew. Die Stadt ist nur 100 km vom Kernkraftwerk bei Prypjat, wo sich kurz zuvor die Nuklearkatastrophe von Tschernobyl ereignet hatte, entfernt. Von 19 gemeldeten Mannschaften sagten 9, darunter fast alle gemeldeten westlichen, die Teilnahme ab. DDR-Sportler, darunter der spätere Gewinner Olaf Ludwig, wurden gezwungen teilzunehmen.

Einen entscheidenden Einschnitt für die Rundfahrt stellte das Jahr 1989 dar. Der Amateurstatus verlor innerhalb kürzester Zeit seine Bedeutung und wurde schließlich ganz abgeschafft. Die Friedensfahrt geriet in die Krise. Mitte der 1990er Jahre wurde sie zu einem Profirennen umgestaltet und hatte sich im Kalender des Radsportweltverbands UCI als Rennen der mittleren Kategorie 2.2 etabliert. Sie führte weiterhin durch die klassischen Teilnehmerländer Polen, Tschechien bzw. Slowakei und Deutschland, berührte deren Hauptstädte jedoch nur noch selten.

Der erfolgreichste Teilnehmer ist Steffen Wesemann, der die Friedensfahrt zwischen 1992 und 2003 fünf Mal gewinnen konnte. Je vier Erfolge errungen haben Uwe Ampler (dreimal für die DDR, einmal für das polnische Team „Mroz“) und der Pole Ryszard Szurkowski. Der zweimalige Gewinner Gustav-Adolf Schur, genannt „Täve“, wurde nach 1989 mit großem Abstand zum populärsten Sportler der DDR gewählt.

Seit 2004 hat der tschechische Radsportverband die Rechte am Namen „Course de la Paix“, somit ist dieser auch hauptverantwortlich für die Durchführung des Rennens. Mit der Nichtaufnahme des Rennens in die neu geschaffene höchste Radsportklasse UCI ProTour 2005 verschlechterte sich die Stellung der Veranstaltung. Finanzielle und organisatorische Probleme – insbesondere die Trennung zwischen dem tschechischen Hauptorganisator Pavel Doležel und seinen deutschen Marketing-Partnern und dem daraus folgenden Verlust wichtiger deutscher Sponsoren – führten im Frühjahr 2005 dazu, dass die Friedensfahrt zunächst verschoben und schließlich ganz abgesagt wurde. Eine Wiederaufnahme des Rennens für 2006 erfolgte mit insgesamt acht Etappen, welche auf den Territorien der Länder Österreich (Start), Tschechische Republik und Deutschland (Ziel) vom 13. bis 20. Mai ausgefahren wurden. Zum ersten Mal war damit Österreich Veranstalterland.

Die 59. Auflage der Friedensfahrt im Jahr 2007 fiel aus. Hauptgrund war der Rückzug des Hauptsponsors Škoda Auto, der zunächst eine Finanzierungssicherung von 500.000 Euro gegeben, diese dann aber im November 2006 zurückgezogen hatte. Daraufhin gab der tschechische Verband bekannt, keinen neuen Partner gefunden zu haben. Seitdem fand keine Friedensfahrt statt.

Seit ihrem Debüt im Jahr 1948 wurden bei der Internationalen Friedensfahrt das Gelbe Trikot für den führenden Fahrer der Gesamteinzelwertung und das Blaue Trikot für die beste Mannschaft vergeben. Im Laufe der Zeit wurden weitere Kategorien eingeführt, die durch verschiedene Trikots repräsentiert wurden. Voraussetzung für den Gesamtsieg in jeder dieser Wertungen war die vorschriftsmäßige Absolvierung der gesamten Rundfahrt. Wenn ein Fahrer in mehreren Wertungen gleichzeitig in Führung lag, galt für die Trikotwahl folgende Rangfolge:


Als Kriterium für die Gesamteinzelwertung gilt die Summe aller Zeiten aus den einzelnen Etappen und dem Prolog (außer Mannschaftszeitfahren), der Fahrer mit der niedrigsten Gesamtzeit führt dabei die Wertung an. Bei Gleichheit entscheidet die niedrigere Summe der Platzierungen bei den bisher absolvierten Etappen (bis 1986 identisch mit der Wertung des "Punktbesten Fahrers"). Gibt es auch hier keinen Unterschied, ist die größere Anzahl der besseren Plätze – verglichen vom ersten Platz an – ausschlaggebend. Falls auch hier Gleichheit herrscht, entscheidet die bessere Platzierung auf der zuletzt beendeten Etappe.

Die Gesamtzeit setzt sich aus folgenden Bestandteilen zusammen:

Steffen Wesemann (Deutschland) trug insgesamt fünfmal das Gelbe Trikot am Ende der Rundfahrt, womit er alleiniger Rekordhalter ist. Mit 49 Etappen hatte der vierfache Gesamtsieger Ryszard Szurkowski (POL) das Gelbe Trikot am längsten in seinem Besitz.

Die Kategorie der "Besten Mannschaft" existiert von Beginn an. Gab es anfangs keine Trikots, bekamen die Sieger im Jahr 1951 weiße Trikots verliehen. Die darauf folgenden 38 Jahre kennzeichnete die Farbe Blau das führende Team in der Mannschaftswertung. Seit 1990 werden die Trikots nur noch symbolisch zum Ende jeder Friedensfahrt-Austragung an die Siegermannschaft überreicht.

Als Kriterium gilt die Summe der Etappen-Mannschaftszeiten, die Mannschaft mit der niedrigsten Gesamtzeit führt dabei die Wertung an. Bei Gleichheit entscheidet bei den betroffenen Mannschaften die niedrigere Summe der Plätze der in der Gesamteinzelwertung drei bestplatzierten Fahrer. Gibt es auch hier keinen Unterschied, gibt der in der Gesamteinzelwertung bestplatzierte Fahrer aller betroffenen Mannschaften den Ausschlag.

Die Gesamtzeit setzt sich aus folgenden Bestandteilen zusammen:

Mit insgesamt 20 Gesamterfolgen ist die Auswahl der UdSSR unangefochtener Rekordsieger in dieser Kategorie, die zudem mit 218 Etappen am längsten die Spitzenposition innehatte. Seit der Zulassung von Profi-Rennställen im Jahre 1996 konnte das Team T-Mobile mit insgesamt vier Gesamtsiegen am häufigsten triumphieren.

Die Wertung für den "Besten Bergfahrer" wurde 1956 eingeführt, zunächst ohne Trikotvergabe. Ab 1969 bekam der Bestplatzierte in dieser Kategorie das Rosa Trikot verliehen. Ab 1972 wurde die Trikotfarbe in Grün geändert und die nächsten 25 Jahre beibehalten. Mit der Umstellung der Kategorien und der Einführung des Grünen Trikots für den besten Sprinter im Jahr 1998 wird für den besten Kletterer fortan das Gepunktete Trikot vergeben.

Als Kriterium für diese Kategorie gilt die Summe aller Punkte aus Bergwertungen, der Fahrer mit der höchsten Punktzahl führt dabei die Wertung an. Bei Punktgleichheit entscheidet die bessere Platzierung in der Gesamteinzelwertung.

Die Punktevergabe setzt sich aus folgenden Bestandteilen zusammen:

Drei Fahrer konnten sich am Ende der Rundfahrt drei Mal den Sieg in der Kategorie "Bester Bergfahrer" sichern. Sergei Suchorutschenkow (URS) stellte 1984 die Rekordmarke auf, die anschließend von Uwe Ampler (DDR) und Jaroslav Bílek (ČSSR) egalisiert wurde. Mit 21 Etappen hatten Ryszard Szurkowski (POL) und Uwe Ampler am häufigsten die Spitzenposition der Bergwertung inne.

Die Wertung für den "Aktivsten Fahrer" wurde 1962 eingeführt und durch das Violette Trikot repräsentiert. Mit der 1998 erfolgten Umstellung wurde die Kategorie in "Bester Sprinter" und die Trikotfarbe in Grün geändert.

Als Kriterium gilt die Summe aller Punkte aus Prämienspurts und Vorstößen, der Fahrer mit der höchsten Punktzahl führt dabei die Wertung an. Bei Punktgleichheit entscheidet die bessere Platzierung in der Gesamteinzelwertung.

Die Punktevergabe setzt sich aus folgenden Bestandteilen zusammen:

Rekordsieger dieser Kategorie ist Olaf Ludwig, der, ausschließlich für die DDR startend, am Ende von acht Rundfahrten das Violette Trikot des "Aktivsten Fahrers" sein Eigen nennen konnte. Mit 55 Etappen hatte der gebürtige Geraer das Trikot auch am längsten in seinem Besitz.

Die Wertung für den "Besten Nachwuchsfahrer" wurde 1989 eingeführt. Während im Premierenjahr ein schwarz-weiß gestreiftes Trikot gestiftet wurde, erhält der Führende in dieser Wertung ab 1990 das Weiße Trikot verliehen. Als Kriterium für diese Kategorie galt die Platzierung der Fahrer unter 21 Jahren in der Gesamteinzelwertung. 1998 wurde die Altersgrenze auf 23 Jahre angehoben, seit 2003 gelten 25 Jahre als Höchstgrenze.

Torsten Hiekmann (Deutschland) trug das Trikot des besten Nachwuchsfahrers mit zehn Etappen am längsten.

Die Wertung für den "Punktbesten Fahrer" wurde 1978 eingeführt und bis 1989 durch das Weiße Trikot repräsentiert. Ab 1990 trug der Führende dieser Kategorie ein weißes Trikot mit roten Punkten, da das bisherige Trikot fortan dem "Besten Nachwuchsfahrer" vorbehalten war. 1998 wurde die Kategorie des punktbesten Fahrers abgeschafft und das Gepunktete Trikot an die Wertung des "Besten Bergfahrers" übertragen.

Als Kriterium galt die Summe aller Punkte aus den Etappen-Einzelwertungen. Bis 1986 entsprachen die Punkte dabei der jeweiligen Etappenplatzierung, der Fahrer mit der niedrigsten Punktzahl führte die Wertung an. Ab 1987 wurde die Punktevergabe dem Reglement der "Internationalen Amateurradsport-Föderation" FIAC angepasst, wodurch fortan der Fahrer mit der höchsten Punktzahl die Wertung anführte. Bei Punktgleichheit entschied die bessere Platzierung in der Gesamteinzelwertung.

Die Punktevergabe setzte sich aus folgenden Bestandteilen zusammen:

Rekordsieger dieser Kategorie ist Olaf Ludwig, der, ausschließlich für die DDR startend, insgesamt sechsmal die Abschlusswertung für den "Punktbesten Fahrers" gewinnen konnte. Mit 47 Etappen hatte Ludwig das Trikot auch am längsten in seinem Besitz.

Das Rosa Trikot für den "Vielseitigsten Fahrer" wurde von 1980 bis 1995 vergeben. Als Kriterium galt die Punktsumme aus den drei Kategorien des "Aktivsten Fahrers", des "Besten Bergfahrers" und des "Punktbesten Fahrers", der Fahrer mit der höchsten Punktzahl führte dabei die Wertung an. Bei Punktgleichheit entschied die bessere Platzierung in der Gesamteinzelwertung.

Die Punktevergabe setzte sich aus folgenden Bestandteilen zusammen:

Rekordsieger dieser Kategorie ist Olaf Ludwig, der, ausschließlich für die DDR startend, insgesamt achtmal die Abschlusswertung des "Vielseitigsten Fahrers" gewinnen konnte. Mit 75 Etappen hatte Ludwig das Trikot auch am längsten in seinem Besitz.

Anfang der 1950er Jahre suchte der DDR-Rundfunk eine geeignete Fanfare für die Friedensfahrt-Berichterstattung und wählte die Rundfunkproduktion des Komponisten Paul Noack-Ihlenfeld. Die Fanfare wurde jeweils zu Beginn der Rundfunkübertragung sowie zu allen Siegerehrungen gespielt und etablierte sich schon bald als markante Erkennungsmelodie der Friedensfahrt. Später wurde sie in der DDR zum Symbol des Radsports allgemein und war wesentlicher Bestandteil bei Massensportbewegungen („Kleine Friedensfahrt“, „Kinder- und Jugendspartakiade“). Die Friedensfahrtfanfare wurde auch mit den Erfolgen des mehrfachen Friedensfahrtsiegers und Sportidols Täve Schur in Verbindung gebracht und war wohl die bekannteste und beliebteste Fanfare der DDR.

In der Bördegemeinde Kleinmühlingen bei Calbe (Saale) befindet sich das einzige Friedensfahrt-Museum, das Radsportmuseum Course de la Paix. Initiator dieser Einrichtung ist Horst Schäfer. Die Grundsteinlegung für das neue Museum wurde am 21. Mai 2005 vollzogen, denn die Räume in denen es untergebracht war, boten nicht mehr genug Stellfläche für die vielen Exponate. Der Trägerverein wird von ehemaligen Radsportgrößen, unter anderen Täve Schur und Klaus Ampler, unterstützt. Am 24. November 2007 öffnete das Friedensfahrt-Museum seine Türen für die Öffentlichkeit.

In einigen Jahren wurden kurze Prolog- und Epilog-Etappen durchgeführt (P und E, Spalte "Etappen")

Die U23-Austragung lief bis 2016 unter dem Namen "Course de la Paix U23 / Závod Míru U23". 2017 läuft die Veranstaltung unter "Grand Prix Priessnitz spa."


Die Juniorenaustragung läuft unter dem Namen "Course de la Paix Junior".



Statistik


</doc>
<doc id="1751" url="https://de.wikipedia.org/wiki?curid=1751" title="Frankenwald">
Frankenwald

Der Frankenwald ist ein 300 bis hohes und 925 km² großes deutsches Mittelgebirge im Nordosten Frankens (nördliches Bayern). Kleine Teile gehören zu Thüringen und bilden die südöstliche Fortsetzung des Thüringer Waldes.

Der Frankenwald ist der mittlere Teil des " Thüringisch-Fränkischen Mittelgebirges". Dieser 200 km lange Höhenzug aus Thüringer Wald und Thüringer Schiefergebirge, Frankenwald und Fichtelgebirge verläuft von Nordwest nach Südost bis zur tschechischen Grenze.

Der Frankenwald liegt zwischen dem Thüringer Schiefergebirge (im engeren Sinne) im Nordwesten, dem Hofer Land (Bayerisches Vogtland) im Osten, dem Fichtelgebirge im Südosten und dem Obermainischen Hügelland im Süden; der Übergang zum Thüringer Schiefergebirge ist fließend, der zum Fichtelgebirge verläuft über die Münchberger Hochfläche. Einige Gemeinden im südöstlichen Thüringen zählen zum Frankenwald, der aus geologischer Sicht zusammen mit dem Thüringer Schiefergebirge und dem Vogtländischen Schiefergebirge das Saalische Schiefergebirge bildet.

Als Frankenwald wird unter Berücksichtigung morphographischer Werte das Gebiet vom Südwestrand des Saalischen Schiefergebirges bis zu den Kammhöhen bezeichnet. Das heißt insbesondere, dass der Frankenwald nach Nordosten nur knapp über die Main-Saale-Wasserscheide hinaus reicht und fast ausschließlich zum Main entwässert.

Naturräumlich ist der Frankenwald Teil des Thüringer Schiefergebirges, einer Haupteinheit innerhalb der Haupteinheitengruppe Thüringisch-Fränkisches Mittelgebirge. Da der Frankenwald aber im touristischen Sinne aus historischen Gründen als ein vom Thüringer Wald, zu dem das Thüringer Schiefergebirge meist hinzugerechnet wird, getrenntes (Teil-)Mittelgebirge aufgefasst wird, versteht man bis heute unter "Frankenwald" in der Regel genau den Teil des Gebirgskamms, der südöstlich der sogenannten Steinacher Flexur längs der Linie Mengersgereuth-Hämmern – Steinach – Spechtsbrunn – Gräfenthal liegt, wobei die ihrer Rodung wegen auch auf Satellitenbildern gut erkennbare Flexur die Flusstäler der Steinach und ihrer Nebenflüsse schneidet und nicht etwa einem ihrer Täler folgt.

Zu den Bergen des Frankenwalds gehören − geordnet nach Höhe in Meter (m) über Normalhöhennull (NHN):

Den Charakter des Frankenwalds beschreibt der folgende – nur auf den ersten Blick widersprüchliche – Satz: „Im Frankenwald gibt es keine Berge – da gibt es Täler“. Eine große Zahl an schmalen, zuweilen parallel verlaufenden V-Tälern zwischen Werra, Itz und Steinach im Nordwesten und den Quellästen des Weißen Mains im Südosten greift in die Hochebene ein und gestaltet so ein Mittelgebirge.

Der Frankenwald ist ein waldreiches Gebiet. Früher dominierten Rotbuche und Tanne. Nach der fast vollständigen Abholzung um die Wende vom 19. zum 20. Jahrhundert wurde überwiegend mit schnellwachsenden Fichten-Monokulturen wieder aufgeforstet, die heute noch das Bild des Frankenwaldes prägen.

Die Geologie des Frankenwalds besteht zu großen Teilen aus Grauwacke und Tonschiefer des Unterkarbons. An der Fränkischen Linie, einer Verwerfungszone, grenzt er an den Muschelkalk des Obermainlands. Wissenschaftlich wird unterschieden zwischen dem Frankenwald im engeren Sinn (westlich von Selbitz) und dem Frankenwald (Überbegriff für die drei Gebiete Frankenwald im engeren Sinn, Münchberger Hochfläche und Bayerisches Vogtland).

Am westlichen Rand des Frankenwalds, zwischen Gundelsdorf im Süden und Rothenkirchen im Norden liegt das dreigeteilte Stockheimer Becken, eines der wenigen Rotliegend-Becken in Bayern. In ihm finden sich u. a. saure Vulkanite, vulkanogene und lakustrine Sedimente des Perms (vorwiegend Schiefer, Sandsteine und verschiedene Konglomerate) sowie einige geringmächtige Steinkohleflöze, die bei Stockheim und Neuhaus-Schierschnitz bis in die 1960er Jahre unter Tage abgebaut wurden.

Der erwähnte Schiefer gestaltete die Häuser – noch heute wird zur Dacheindeckung das „blaue Gold“ verwendet – und prägt die Frankenwalddörfer.

Viele Orte wie Schwarzenbach am Wald oder Bad Steben sind aufgrund ihrer Höhenlage und des Reizklimas staatlich anerkannte Luftkurorte und steuern somit einen großen Teil zum Einkommen der Bevölkerung bei.

Die Frankenwäldler sind eng mit ihrem Wald verbunden. Er war Grundlage für ihren Lebensunterhalt in Glas- und Porzellanindustrie, Flößerei, Köhlerei und den zahlreichen Schneidmühlen. Bis nach Amsterdam brachten die Flößer auf Main und Rhein Frankenwaldtannen. Noch heute wird die Flößerei auf der Wilden Rodach bei Wallenfels touristisch betrieben.

Die Besiedlung des Frankenwaldes, des früheren Nortwaldes, begann im 13. Jahrhundert zunächst auf den bewaldeten Hochflächen. In Rodungsinseln entstanden die ersten Siedlungen mit den heute noch erkennbaren Siedlungsformen Waldhufen- und Rundangerdorf. Musterbeispiel für ein guterhaltenes Rundangerdorf ist die Ortschaft Effelter im Landkreis Kronach, die heute ein Ortsteil von Wilhelmsthal ist.
Erst später fand die Besiedlung der Täler statt und es entstanden die typischen Wiesentäler.

Deswegen wird der Frankenwald von drei Landschaftselementen geprägt:
Im Osten, in der Gegend um Naila und Schwarzenbach am Wald, herrscht eine eher sanft gewellte Hochplateaulandschaft vor. Im Westen dagegen, im Landkreis Kronach, wechseln sich enge Wiesentäler, bewaldete Hänge und gerodete Hochflächen ab.

Durch den Frankenwald bzw. an seinem Rand verlaufen die Bahnlinien München – Berlin, Lichtenfels – Kulmbach – Hof, Saalfeld – Blankenstein, Münchberg – Helmbrechts, Hof – Naila – Bad Steben, die Bundesautobahn 9 und die Bundesstraßen 2, 85, 89, 173, 289 und 303.




Folgende Gemeinden liegen im Frankenwald oder an seinen Grenzen. Die Liste ist alphabetisch sortiert.

Der Frankenwald liegt zwischen dem Main im Südwesten und der (sächsischen) Saale im Nordosten. Dem Main zu fließt die Rodach mit ihren Nebenflüssen Haßlach und Kronach sowie die Schorgast mit der Unteren Steinach, wobei die beiden letztgenannten Flüsse der Münchberger Hochfläche entspringen und nur die Untere Steinach den Frankenwald durchquert, während ihr Vorfluter westlich von Wirsberg die Südgrenze bildet.

Die Selbitz im östlichen Frankenwald und die Loquitz im Norden münden in die Saale. Zwischen den Zuflüssen zu Saale und Main verläuft im Frankenwald die Europäische Wasserscheide zwischen Elbe und Rhein.

Den Naturpark Frankenwald bilden Teile des Landkreises Kronach und der Nachbarkreise Hof und Kulmbach. Im Naturpark liegt die Ködeltalsperre, die größte Trinkwassertalsperre Bayerns, die mit ihren 21 Millionen Kubikmeter Fassungsvermögen fast die gesamte oberfränkische Bevölkerung mit Rohwasser versorgt.

Der Frankenwaldverein ist ein Heimat- und Wanderverein. Er pflegt Brauchtum und Geschichte im Frankenwald und unterhält ein dichtes Netz von Wanderwegen. Der Verein wurde in Naila gegründet und setzt Technologien wie GPS für Wanderungen ein.

Der Frankenwald war wie der Schwarzwald in vergangenen Jahrhunderten ein Waldrodungsgebiet. Mittels Flößerei wurden die Stämme bis in die Niederlande verschifft. Während das Schwarzwaldholz in Rotterdam verbaut wurde, bildete Frankenwaldholz das Fundament für Amsterdam.







</doc>
<doc id="1753" url="https://de.wikipedia.org/wiki?curid=1753" title="Fluid">
Fluid

Das Fluid (vom lateinischen "" für „fließend“) ist eine gemeinsame Bezeichnung für Gase und Flüssigkeiten. Viele physikalische Gesetze gelten für Gase und Flüssigkeiten gleichermaßen, denn diese Stoffe unterscheiden sich in manchen Eigenschaften nur quantitativ, also in ihren Größenordnungen, aber nicht qualitativ. 

Die Strömungslehre bezeichnet als Fluid jede Substanz, die einer genügend langsamen Scherung keinen Widerstand entgegensetzt (endliche Viskosität). 

Reale Fluide werden eingeteilt in 


</doc>
<doc id="1756" url="https://de.wikipedia.org/wiki?curid=1756" title="Fachliteratur">
Fachliteratur

Die Fachliteratur, je nach Definition auch Fachprosa genannt, ist ein Teilgebiet der nichtbelletristischen Literatur. Sie zählt somit – neben der Sachliteratur, zu deren Untermenge die Fachliteratur zunehmend gerechnet wird – zur literarischen Gattung der Non-Fiction. Im Unterschied zur Sachliteratur, die bestimmte Sachthemen – oft populärwissenschaftlich aufbereitet und von Fachjargon befreit – für ein Laien­publikum darstellt, richtet sich die Fachliteratur an „ein Fach­publikum meist mit Blick auf die professionelle Anwendung oder die Gewinnung neuer wissenschaftlicher Erkenntnisse.“

Ein Teilgebiet der Fachliteratur wiederum ist die wissenschaftliche Literatur, mit den sogenannten Standardwerken, die sich an wissenschaftlich gebildete Personen richtet bzw. deren Ausbildung dient.

Zur Fachliteratur zählen insbesondere:


Die Digitale Revolution hat es mit sich gebracht, dass heute auch im Bereich der Fachliteratur zunehmend auf elektronischen bzw. digitalen Medien publiziert wird, vor allem auf CD-ROM oder DVD sowie auf speziellen Websites. Im Bereich der wissenschaftlichen Fachartikel sind dies meist die eigens hierfür eingerichteten Online-Plattformen der die jeweiligen Fachzeitschriften herausgebenden Verlage.
Zu den bekanntesten dieser Portale gehören "ScienceDirect" des Elsevier-Verlages und "SpringerLink" des Verlags Springer science+business media.
Es werden aber auch von öffentlichen Einrichtungen Plattformen betrieben, die eine weitgehend freie Veröffentlichung und Nutzung ermöglichen, zum Beispiel der Preprint-Server "arXiv".

Fachliteratur entsteht in all jenen Sprachen, in denen sie benötigt wird; seit der zweiten Hälfte des 20. Jahrhunderts erscheint sie jedoch immer häufiger auf Englisch. Dadurch hat die englische Sprache immer mehr die Rolle der wissenschaftlichen "Lingua franca" eingenommen, die im 19. Jahrhundert in Westeuropa das Deutsche und teilweise auch das Französische innehatten.

Noch weiter in der Vergangenheit waren in Europa sowie dem gesamten Mittelmeerraum seit dem Ende der Antike Latein und Griechisch, sowie teils (Mittelmeer) die arabische Sprache die führenden Sprachen der Wissenschaft.




</doc>
<doc id="1760" url="https://de.wikipedia.org/wiki?curid=1760" title="Fuchsschwanzgewächse">
Fuchsschwanzgewächse

Die Fuchsschwanzgewächse (Amaranthaceae) sind eine Familie in der Ordnung der Nelkenartigen (Caryophyllales) innerhalb der Bedecktsamigen Pflanzen (Magnoliopsida). Hier ist auch die oft separat geführte Familie der Gänsefußgewächse (Chenopodiaceae) eingegliedert. Nicht verwandt mit dieser Gruppe sind die Fuchsschwanzgräser.

Die meisten Arten sind einjährige oder ausdauernde krautige Pflanzen oder Halbsträucher; es gibt auch einige Sträucher; wenige Arten sind Lianen oder Bäume. Viele Arten sind sukkulent. Bei vielen Arten sind an den Sprossachsen die Knoten (Nodien) verdickt. Das Holz der mehrjährigen Sprossachsenteile weist ein für die Familie typisches „anomales“ Dickenwachstum auf, welches nur den Polycnemoideae fehlt.

Die Laubblätter sind meist wechselständig, gelegentlich auch gegenständig. Nebenblätter sind keine vorhanden. Die Gestalt der Blätter ist äußerst variabel, die Blattränder sind ganzrandig oder gezähnt, ihr Querschnitt ist flächig bis stielrund, bei einigen Arten sind die Blätter auch zu winzigen Schuppen reduziert.

Die Vorblätter und Tragblätter sind entweder krautig oder trockenhäutig. Die Blütenhülle ist mehr oder weniger krautig oder auch trockenhäutig und besteht aus (selten eines bis) meist fünf (selten bis acht) Tepalen. Die meist in gleicher Anzahl vorhandenen Staubblätter stehen entweder vor den Tepalen oder dazwischen. Sie entspringen am Blütengrund einem Diskus, welcher bei einigen Arten Anhängsel (Pseudostaminodien) trägt. Die Staubbeutel besitzen zwei oder vier Pollensäcke. Bei den "Caroxyloneae" kommen blasenförmige Staubbeutelanhängsel vor. Die Pollenkörner sind rund mit zahlreichen Öffnungen (pantoporat), wobei die Porenzahl von wenigen bis zu 250 (bei "Froelichia") reichen kann. Die meist ein bis drei (selten bis sechs) Fruchtblätter sind zu einem oberständigen Fruchtknoten verwachsen. Im Fruchtknoten befindet sich eine (selten zwei) basale Samenanlage.

Als Ausbreitungseinheit (Diasporen) dienen entweder die Samen, oft sind aber die Blütenhüllblätter auch noch bei der reifen Frucht vorhanden und erfahren Umgestaltungen, die der Ausbreitung dienen. Gelegentlich werden auch die Trag- und Vorblätter in die Diaspore einbezogen. Seltener kommen Kapselfrüchte oder Beeren vor. Der Same ist horizontal oder anders ausgerichtet, oft mit verdickter und verholzter Samenschale. Der Embryo ist grün oder weiß, spiralig (dann ohne Nährgewebe) oder ringförmig (selten gerade).

Die Chromosomengrundzahl ist (selten sechs) meist acht oder neun (selten 17).

Weitverbreitet bei den Fuchsschwanzgewächsen ist das Vorkommen von Betalainen. Die früheren Chenopodiaceae enthalten oft Isoflavonoide.

Bei phytochemischen Untersuchungen wurden zudem Methylendioxyflavonole, Saponine, Triterpene, Ecdysteroide sowie in den Wurzeln spezielle Kohlenhydrate gefunden.

Mit etwa 800 C-Arten sind die Fuchsschwanzgewächse die größte Gruppe mit diesem Photosyntheseweg innerhalb der Eudikotyledonen (circa 1600 C-Arten). Innerhalb der Familie gibt es verschiedene Typen von C-Photosynthese und etwa 17 verschiedene Typen der Blattanatomie. Daher wird angenommen, dass diese Eigenschaft wahrscheinlich etwa 15-mal unabhängig voneinander in der Evolution dieser Familie erworben wurde, davon 2/3 bei den ehemaligen Chenopodiaceae. Das erste Mal trat C-Photosynthese im frühen Miozän vor etwa 24 Millionen Jahren auf. Bei einigen Gruppen entstand dieser Photosyntheseweg aber erst wesentlich später, vor sechs (oder weniger) Millionen Jahren.

Die mehrfache Entwicklung von C-Photosynthese bei den Amaranthaceae wird als Anpassung an zunehmende Wasserknappheit und höhere Temperaturen angesehen. Diese Arten waren durch ihre größere Effizienz im Wasserverbrauch in trockenen Lebensräumen im Vorteil und konnten sich dort ausbreiten.

Einige Arten, wie etwa der Spinat ("Spinacia oleracea") oder Kulturformen der Rübe ("Beta vulgaris") (z. B. Rote Rübe, Mangold), werden als Gemüsepflanzen genutzt. Weitere Formen von "Beta vulgaris" sind die Futterrübe und die Zuckerrübe. Die Samen mehrerer "Amaranthus"-Arten und der Quinoa ("Chenopodium quinoa"), selten auch Reismelde genannt, werden ähnlich wie Getreide (Pseudogetreide) verwendet.

Mexikanischer Drüsengänsefuß ("Dysphania ambrosioides") und Wurmsamen-Drüsengänsefuß ("Dysphania anthelmintica") sind Heilpflanzen.

Aus mehreren Arten wird Soda gewonnen.

Als Zierpflanzen werden beispielsweise Garten-Fuchsschwanz, Brandschopf und Iresine verwendet.

Die Familie Amaranthaceae ist weltweit in den gemäßigten Zonen sowie den Subtropen und Tropen verbreitet. Viele Arten sind an Böden mit relativ hohem Salzgehalt angepasst oder kommen in trockenen Steppen- und Halbwüstengebieten vor.

Eine Gruppe von Gattungen, die mehr als die Hälfte der Arten umfasst, wurde traditionell als eigene Familie Gänsefußgewächse (Chenopodiaceae) abgetrennt. Molekularbiologische Untersuchungen haben aber eine enge Verwandtschaft der beiden traditionell unterschiedenen Familien ergeben und nahegelegt, dass die Gänsefußgewächse paraphyletisch sind und nur bei einer Vereinigung mit den Amaranthaceae im engeren Sinn ein monophyletisches Taxon ergeben. Aktuelle Veröffentlichungen verwenden weiterhin den Familiennamen Chenopodiaceae .

Die Familie Amaranthaceae wurde 1789 durch Antoine Laurent de Jussieu in "Genera Plantarum", S. 87–88 aufgestellt. Die Erstveröffentlichung der Familie Chenopodiaceae erfolgte 1799 durch Étienne Pierre Ventenat in "Tableau du Regne Vegetal", 2, S. 253. Der älteste und nach der Prioritätsregel gültige wissenschaftliche Name des erweiterten Taxons ist Amaranthaceae.

Aus dem Kladogramm wird deutlich, dass die Einstufung der Chenopodiaceae entscheidend von der Unterfamilie Polycnemoideae abhängt: Wird sie so wie bisher als Teil der Familie betrachtet, müssen auch die Amaranthaceae im engeren Sinn dazugehören, und der Name der erweiterten Familie lautet nach der Prioritätsregel Amaranthaceae. Würden die Polycnemoideae jedoch als eigene Familie abgetrennt, dann wären Chenopodiaceae und Amaranthaceae zwei jeweils monophyletische Verwandtschaftsgruppen, die als separate Familien betrachtet werden könnten.

In der Familie Amaranthaceae im neuen Umfang sind die Gattungen der früheren Familien: Achyranthaceae , Atriplicaceae , Betaceae , Blitaceae , Celosiaceae , Chenopodiaceae nom. cons., Corispermaceae , Deeringiaceae , Dysphaniaceae nom. cons., Gomphrenaceae , Polycnemaceae , Salicorniaceae , Salsolaceae , Spinaciaceae enthalten.

Die Systematik der Familie Amaranthaceae wird seit einigen Jahren intensiv erforscht. Molekularbiologische Studien haben gezeigt, dass die bisherige Einteilung, die auf morphologischen und anatomischen Merkmalen beruhte, nicht die verwandtschaftlichen Beziehungen widerspiegelte.
Die früher den Gänsefußgewächsen (Chenopodiaceae) zugerechneten Arten werden derzeit (2011) in etwa acht Unterfamilien eingeordnet (die Bearbeitung ist noch nicht abgeschlossen): die Polycnemoideae, welche als ursprünglich angesehen werden, sowie die Betoideae, Camphorosmoideae, Chenopodioideae, Corispermoideae, Salicornioideae, Salsoloideae und Suaedoideae.
Innerhalb der Amaranthaceae s. str. (im engeren Sinne) erwiesen sich die Unterfamilie Amaranthoideae sowie manche Gattungen innerhalb der Gomphrenoideae als polyphyletisch, so dass hier in den nächsten Jahren weitere taxonomische Änderungen zu erwarten sind.

Die Familie Amaranthaceae s. l. wird in der vorläufigen Systematik in zehn Unterfamilien gegliedert und enthält etwa 176 Gattungen mit etwa 2050 bis 2500 Arten:














</doc>
<doc id="1763" url="https://de.wikipedia.org/wiki?curid=1763" title="Filmgenre">
Filmgenre

Unter einem Filmgenre [] wird eine Gruppe von Filmen verstanden, die unter einem spezifischen Aspekt Gemeinsamkeiten aufweisen. Diese Gemeinsamkeiten können insbesondere in einer bestimmten Erzählform (Filmkomödie, Drama) oder Grundstimmung (Liebesfilm, Thriller), hinsichtlich des Themas der Handlung (Kriminalfilm, Fantasyfilm) oder in historischen oder räumlichen Bezügen (Historienfilm) bestehen. Filme, die den sogenannten Kerngenres wie Science-Fiction, Fantasy, Horror, Action, Thriller, Dark Drama, Mystery zuzuordnen sind, werden als Genrefilme bezeichnet. Von Genrefilm spricht man, „wenn der Begriff des Genres eine aktivere Rolle in der Produktion und im Konsum spielt“.

Bestandsaufnahmen haben ergeben, dass im Laufe der Zeit mindestens für eine hohe dreistellige Zahl verschiedener Filmgruppen eigene Genrebezeichnungen kreiert worden sind. Dieses Ergebnis ist zu großen Teilen damit zu erklären, dass Filmkritik und Kinowerbung sich häufig auf andere Filme beziehen, und dieses Bedürfnis immer wieder neue Genrebezeichnungen generiert. Eine Tendenz, die dadurch begünstigt wird, dass Filme häufig die Merkmale mehrerer Genres (siehe Genresynkretismus) in sich tragen und die jeweiligen Kombinationen gern als neue Genres ausgerufen werden. Diese Vorgehensweise wird nicht von der filmwissenschaftlichen Genretheorie gestützt. Diese definiert einzelne Genres insbesondere über enge Produktionszusammenhänge, ein Repertoire konventionalisierter Formen und ein stabiles Verständnis, das sowohl seitens der Produzenten als auch beim Publikum vorhanden ist.

Wie strittig Definitionsansätze sein können, illustriert das Beispiel des Film noir, bei dem sich die Filmwissenschaftler nicht einig sind, ob von einem Filmgenre oder einer Stilrichtung gesprochen werden sollte.

Die Herausbildung des Begriffs Filmgenre ging in den ersten Jahrzehnten des 20. Jahrhunderts einher mit der zunehmenden Bedeutung des Films als Wirtschaftsfaktor. Angelehnt an Genredefinitionen, die im 19. Jahrhundert für einzelne Sparten massenhaft produzierter Unterhaltungsliteratur (s. Trivialliteratur) entwickelt worden waren, ging die Filmindustrie zunehmend dazu über, Handlungen, Sujets, Stimmungen, Erzählformen und andere Einflussfaktoren zu schematisieren. Ähnlich gelagerte Produktionen wurden mit Genrebezeichnungen etikettiert, deren vorrangige Funktion darin bestand, Marketingbotschaften an die Erwartungshaltungen des Publikums zu senden. Dies insbesondere dann, wenn sich ein vorheriger Film als kommerziell einträglich erwiesen hatte und mit weiteren Produktionen nach dem entsprechenden Strickmuster an diesen Erfolg angeknüpft werden sollte. Zum einen entwickelten sich Filmgenres damit auch zu mehr oder minder verlässlichen Kalkulationsfaktoren. Insbesondere im Studiosystem des damals bereits führenden Filmlandes USA bildeten sich in den 1920er und 1930er Jahren außerdem "Production Units" heraus, die jeweils auf die Herstellung von Filmen eines bestimmten Genres spezialisiert waren. Hauptsächlich repräsentierten Western, Komödien, Gangsterfilme und Horrorfilme in dieser Zeit die ersten abgegrenzten Filmgenres. Zu nennen sind in diesem Zusammenhang aber auch Musikfilme, die zu Beginn der Tonfilmära ein erfolgreiches eigenständiges Genre bildeten, sowie Produktionen, deren Sujet eine Liebesbeziehung war und die unbedingt mit einem Happy End ausgehen mussten. Als feste Größe etablierte sich der Genrefilm spätestens im Zeitraum von 1930 bis 1950. Im US-Studiosystem manifestierte er sich unter anderem in Gestalt der B-Filme, die jeweils ein bestimmtes Genre bedienten, mit dem das Publikum klar umrissene Erwartungen verband.

Trotz aller Definitions- und Abgrenzungsschwierigkeiten ist zumindest weitgehend unstrittig, dass der Genrebegriff nicht auf die „Großgattungen“ des Films angewendet wird. Dazu gehören insbesondere die Gattungen Spielfilm, Dokumentarfilm, Experimentalfilm, Nachrichtenfilm, Kulturfilm, Lehrfilm, Werbefilm/Propagandafilm und Wirtschaftsfilm.

Im engeren Sinne zählen dazu auch nicht die Gattungen, die sich durch spezifische technische Merkmale auszeichnen (zum Beispiel Stummfilm, Schwarzweißfilm, 3D-Film und Trick-/Animationsfilm).

Obwohl teilweise auch im Zusammenhang mit bestimmten Produktionsbedingungen (zum Beispiel Independentfilm) oder mit einer bestimmten Länge von Filmen (zum Beispiel Kurzfilm) von eigenständigen Filmgenres gesprochen wird, handelt es sich dabei im engeren Sinne nicht um solche. Dies gilt auch im Zusammenhang mit Zielgruppen, an die sich Filme vorrangig richten (zum Beispiel Kinderfilm und Jugendfilm).

Vergleichsweise schwierig gestaltet sich die Abgrenzung gegenüber bestimmten Stilrichtungen und Bewegungen. Obwohl Strömungen wie die Nouvelle Vague oder der Italienische Neorealismus von großer filmgeschichtlicher Bedeutung sind, werden sie mehrheitlich nicht als Genres aufgefasst. Und zwar deshalb, weil sich die einzelnen Produktionen u. a. in ästhetischer Hinsicht zu unterschiedlich darstellen.

In der praktischen Terminologie der Filmkritik erkennt man auch oft die Nähe zur Literaturwissenschaft (siehe auch Text).

In ihrer Gesamtheit sind Filmgenres bisher nicht systematisiert worden, auch wegen des Bedeutungswandels, den Filmgenres häufig im Laufe der Zeit durchgemacht haben. Aber auch, weil Genrebezeichnungen in verschiedenen kulturellen oder sprachlichen Zusammenhängen unterschiedlich verstanden werden können. So wird zum Beispiel im englischsprachigen Raum unter einem Filmdrama weitgehend ein Film verstanden, der sich durch eine ausgeprägte Darstellung einzelner Persönlichkeiten auszeichnet, während das Merkmal dieser Filmgattung nach dem Verständnis im deutschsprachigen Raum in einer Handlung im Sinne des klassischen Dramas oder in einem besonders erregenden bzw. tragischen Verlauf der Handlung besteht.

Unter Berücksichtigung des eingangs erwähnten Gruppierungsaspekts lassen sich beispielsweise folgende Filmgenres unterscheiden:




</doc>
<doc id="1764" url="https://de.wikipedia.org/wiki?curid=1764" title="Filmregisseur">
Filmregisseur

Ein Filmregisseur ist ein Regisseur (veraltet "Spielleiter"), der eine komplette Filmproduktion kreativ leitet. Im Gegensatz dazu leitet der Produzent (englisch: "Producer") die Filmproduktion administrativ.

Bei kleinen Produktionen erstreckt sich diese Tätigkeit von der Stoffentwicklung über die Erarbeitung von Drehbüchern, die Planung des Ablaufs der Produktion einschließlich der Kosten bis zur Postproduction. In professionellen Produktionszusammenhängen ist die Kernaufgabe des Regisseurs die Inszenierung, das heißt, die Auflösung der Szenen eines Drehbuches in einzelne Kameraeinstellungen und die Anleitung der Darsteller.

Der Begriff „Regie“ ist beim Kino-Spielfilm klar definiert. Beim Fernsehen kann er vielerlei bedeuten: von der Studio-Regie, der Ablauf-Regie über die Bild-Regie (Kamera) bis hin zur Spielfilm-Regie gleichen Regie, vor allem im fiktionalen Bereich (Fernsehspiel, auch in Form von Reihen und Serien, TV-Movie etc.).

Der Filmregisseur ist der Haupturheber eines Filmwerks, der dieses persönlich und eigenschöpferisch prägt unter Verwendung und Bearbeitung vorbestehender Werke (z. B. vom Drehbuchautor und vom Filmkomponisten) und im Zusammenwirken mit weiteren Mit-Urhebern (z. B. Bildgestalter und Filmeditor).

Der Begriff leitet sich von Französisch "régisseur" „Verwalter“ ab. Im Französischen wird ein Regisseur allerdings als "réalisateur" (wörtlich „Verwirklicher“) bezeichnet. Während mit dem Begriff des Regisseurs im Französischen die Aufnahmeleitung, also die Betriebsleitung bezeichnet wird.

In den 1910er- und 1920er-Jahren hatten in den USA prominente Filmregisseure wie David W. Griffith, Charlie Chaplin, Rex Ingram, Cecil B. DeMille, King Vidor oder Erich von Stroheim eine große Entscheidungsfreiheit und Machtfülle bei den von ihnen inszenierten Filmen. Ihre Popularität und Werbewirksamkeit überstrahlte teilweise sogar die der in den Filmen eingesetzten Schauspieler.

Mitte der 1920er-Jahre begannen die Produzenten des Studiosystems, die wirtschaftliche und zum großen Teil auch künstlerische Kontrolle über die Filmherstellung zurückzugewinnen, die sie in den Anfangstagen des Films innehatten. Filmregisseure gerieten in Abhängigkeit von Produzentenentscheidungen und wurden oft nur als Koordinatoren und ausführende Spielleiter eingesetzt. Um sich ihre künstlerische Freiheit zu bewahren, entschlossen sich einige Regisseure, ihre eigenen Produktionsfirmen zu gründen, etwa Frank Capra, George Stevens und William Wyler mit ihrer gemeinsamen Firma Liberty Films. Auch Regisseure wie Robert Aldrich, Otto Preminger, Samuel Fuller und Sam Peckinpah agierten zeitweise als “Produzenten-Regisseure”. Später versuchten auch Filmemacher wie Robert Altman, Sydney Pollack, George Lucas oder Steven Spielberg, auf diese Weise die Kontrolle über ihre Filme zu behalten.

In Europa war der Konflikt zwischen geldgebenden Produzenten und künstlerisch arbeitenden Regisseuren nicht so stark ausgebildet wie in den USA. Das Problem, Ökonomie und Anspruch zusammenzubringen, wurde oft eher kooperativ gelöst, jedoch waren die Regisseure oft in ihrer künstlerischen Freiheit beschnitten. Die Auteur-Theorie begann ab den 1940ern und verstärkt zur Zeit der Nouvelle Vague, zwischen dem "Realisateur", dem zwar begabten, aber Zwängen unterworfenen „Handwerker“, und dem "Auteur", der seine Arbeit als individuelle, künstlerisch freie Aufarbeitung der eigenen Weltvorstellung sieht, zu unterscheiden. Dieses Verständnis des Filmregisseurs als ganzheitlicher Künstler, dem in seiner Arbeit auch Schwächen und Fehler zugestanden werden müssen, um ihn frei agieren zu lassen, wurden von den Regisseuren des Neuen Deutschen Films übernommen.


Filmregisseure leiten während der Produktion eine ganze Reihe von Mitarbeitern an:

Die Ausbildung zum Regisseur ist nicht einheitlich geregelt. Ein grundständiges Studium im Regiefach wird an staatlichen und privaten Filmhochschulen angeboten. Bei der Aufnahmeprüfung muss eine filmspezifische künstlerische Befähigung nachgewiesen werden. Zur formalen Voraussetzung gehört in der Regel die allgemeine Hochschulreife oder zumindest die Fachhochschulreife. Üblich ist die praktische Aneignung der erforderlichen Kenntnisse und Fähigkeiten über eine Tätigkeit als Regieassistent bei einer Filmproduktion.

Voraussetzung für die Regietätigkeit ist eine Kombination aus vielen verschiedenen Fähigkeiten. Die Fähigkeit, künstlerische und technische Mitarbeiter zu motivieren, zu leiten und koordinieren zählt ebenso dazu, wie dramaturgische, darstellerische, sprachliche, musikalische und visuelle Elemente zu einem Filmwerk zusammenzufügen. Regisseure müssen über Psychologie und Menschenkenntnis verfügen, um auch evtl. entstehende Konflikte innerhalb des Gesamtteams zu lösen. 





</doc>
<doc id="1765" url="https://de.wikipedia.org/wiki?curid=1765" title="Flüssigkeit">
Flüssigkeit

Eine Flüssigkeit ist Materie im "flüssigen Aggregatzustand". Nach einer makroskopischen Definition handelt es sich um einen Stoff, der einer Formänderung so gut wie keinen, einer Volumenänderung hingegen einen recht großen Widerstand entgegensetzt (der Stoff ist nahezu inkompressibel). Nach einer mikroskopischen Definition ist eine Flüssigkeit ein Stoff, dessen Teilchen sich ständig nichtperiodisch bewegen sowie keiner Fernordnung, jedoch einer Nahordnung unterliegen und deren mittlere freie Weglänge in der Größenordnung des Teilchendurchmessers liegt. 

Flüssigkeiten sind also volumenbeständig, formunbeständig und unterliegen einer ständigen Brownschen Bewegung. Der flüssige Zustand ist nicht allein stoffspezifisch, sondern hängt auch von äußeren Faktoren wie der Temperatur und dem Druck ab. Wechselt eine solche Flüssigkeit ihren Aggregatzustand, so spricht man von einer Phasenumwandlung, wobei der Begriff der Phase selbst einen Überbegriff zum Aggregatzustand darstellt.

Mit den Gasen werden die Flüssigkeiten zu den Fluiden zusammengefasst.

Die temperaturabhängige Volumenausdehnung einer Flüssigkeit wird durch deren Volumenausdehnungskoeffizienten quantifiziert. Der Kompressionsmodul ist ein Maß für die adiabatische Volumenelastizität, das heißt für die „Zusammendrückbarkeit“ einer Flüssigkeit. In der Schwerelosigkeit beziehungsweise bei einer Abwesenheit äußerer Kräfte nehmen Flüssigkeiten aufgrund ihrer Oberflächenspannung eine kugelförmige Gestalt an, da diese Form die Oberfläche minimiert.
Flüssigkeiten üben auf die Wand des Gefäßes, in dem sie sich befinden, einen hydrostatischen Druck aus, zum Beispiel den Wasserdruck. Ruhende Flüssigkeiten sind physikalisch hauptsächlich durch diesen Druck gekennzeichnet. Übt man von außen Druck auf Flüssigkeiten aus, so verteilt sich der Druck gleichmäßig in der ganzen Flüssigkeit. Je tiefer man einen Körper in eine Flüssigkeit taucht, desto größer wird der hydrostatische Druck auf den Körper. Dieser hängt allerdings nicht nur von der Tauchtiefe, sondern auch von der Dichte der Flüssigkeit ab. In strömenden Flüssigkeiten treten zusätzliche Größen auf, die durch die Fluiddynamik, ein Teilgebiet der Kontinuumsmechanik, beschrieben werden. Der Widerstand gegen Formänderung, genauer die Viskosität, kann allerdings beliebig groß sein. Zwischen Flüssigkeit und Festkörper gibt es insofern keine klare Grenze.

Aufgrund der im Vergleich zum Festkörper fehlenden Translationsperiodizität und der ständigen Teilchenbewegung müssen Flüssigkeiten mit den Mitteln der statistischen Mechanik (z. B. klassische Dichtefunktionaltheorie) beschrieben werden. Wichtig sind hier die atomaren Verteilungsfunktionen. Viele Eigenschaften der Volumenphase von Flüssigkeiten lassen sich mittels Molekulardynamik- oder Monte-Carlo-Simulation berechnen.




</doc>
<doc id="1767" url="https://de.wikipedia.org/wiki?curid=1767" title="Finanzkrise">
Finanzkrise

Finanzkrisen sind größere Verwerfungen im Finanzsystem, die durch plötzlich sinkende Vermögenswerte (z. B. bei Unternehmensbeteiligungen – siehe Börsenkrach) und die Zahlungsunfähigkeit zahlreicher Unternehmen der Finanzwirtschaft und anderer Branchen gekennzeichnet sind und die die ökonomische Aktivität in einem oder mehreren Ländern beeinträchtigen. Die Gesellschaft für deutsche Sprache kürte das Wort 2008 zum Wort des Jahres.

Prinzipiell wird nach ihrer äußeren Erscheinungsform unterschieden zwischen Bankenkrisen, Währungskrisen, Finanzsystemkrisen und Krisen, in denen ein Land oder einzelne Länder ihre Auslandsschulden nicht mehr bedienen können (Verschuldungskrisen).

Gemäß der monetären Überinvestitionstheorie nach Friedrich August von Hayek und Knut Wicksell kommt es zu einem Anstieg der internen Verzinsung der Unternehmen, also des „natürlichen Zinssatzes“, etwa durch technischen Fortschritt, über den bestehenden Geldzinssatz. Auf dem Kapitalmarkt steigt die Nachfrage nach Krediten, um neue Investitionen zu finanzieren. Zunächst nährt die zusätzliche Liquidität den Aufschwung, in dessen Verlauf auch Investitionsprojekte mit niedrigeren (erwarteten) Renditen finanziert werden.

Nach Hayek führt die größere Nachfrage nicht zu einem Anstieg der Zinssätze, weil die Banken die allgemeine Wirtschaftsbelebung als Anreiz verstehen, das Kreditangebot mit der Nachfrage auszuweiten. Erst mit zeitlicher Verzögerung passt sich der Geldzinssatz an den natürlichen Zinssatz an. Dann können sich Sachinvestitionen als überdimensioniert herausstellen. Investitionsprojekte, die zum bisherigen Geldzinssatz noch rentabel waren, werden abgebrochen. Die Strukturbereinigung zieht Unternehmen, Konsumenten und Finanzinstitute in den Strudel der Krise. Nach Wicksell müsste die Zentralbank rechtzeitig den Leitzins anheben, um der Überinvestitionskrise vorzubeugen. Auch Hayek empfiehlt eine rechtzeitige Anhebung des Leitzinssatzes durch die Zentralbank, ohne dass aber dadurch die Finanzkrisen völlig vermieden werden können. „Was die Krisenbewältigung betrifft, so gelingt diese, ganz grob gesprochen, nur durch einen Abbau der Überkapazitäten, also deren Liquidation. Die Handlungsempfehlung ist einfach: Nichtstun.“

Die monetäre Überinvestitionstheorie war die dominierende Vorstellung in der Zeit um 1929. Der amerikanische Präsident Herbert Hoover folgte dieser Theorie in der Weltwirtschaftskrise der 1930er Jahre weitgehend („Hoover-Economics“). Irving Fisher verglich diese mit einem Arzt, der bei einer Lungenentzündung „die Heilung der Natur überlassen“ würde. Nach dem Platzen der Dotcom-Blase erlebte die zwischenzeitlich in Vergessenheit geratene monetäre Überinvestitionstheorie eine Renaissance.

Eine Theorie zur Erklärung von gesamtwirtschaftlichen Finanzkrisen geht auf Milton Friedman und Anna J. Schwartz zurück. Diese erklärt die Great Depression in den Vereinigten Staaten mit einer verfehlten Politik der Zentralbank. Die Reduzierung der Geldmenge in den USA um 30 % zwischen den Jahren 1929 und 1933 betrachten sie als entscheidend für den Verlauf der Weltwirtschaftskrise in den 1930er Jahren.

Die Schuldendeflation als Erklärung für bestimmte Finanz- und Wirtschaftskrisen stellt Irving Fisher 1933 auf. Die Theorie wurde 1983 von Ben Bernanke erweitert und gehört seitdem zum volkswirtschaftlichen Mainstream. Eine Schuldendeflation liegt vor, wenn ein Preisverfall (Deflation) zu sinkenden Nominaleinkommen führt. Da die nominale Höhe der Schulden und der geschuldeten Zinsen unverändert bleibt, führt die Schuldendeflation zu einer Erhöhung der realen Schuldenlast. Dies kann zu einer Deflationsspirale führen: die Erhöhung der realen Schuldenlast verursacht die Insolvenz einiger Schuldner. Dies führt zu einer Verringerung der gesamtwirtschaftlichen Nachfrage und somit zu einer weiteren Verringerung der Preise (Verschärfung der Deflation). Dies wiederum führt zu noch weiter fallenden Nominaleinkommen und damit zu einer noch stärkeren Erhöhung der realen Schuldenlast. Dies führt zu weiteren Insolvenzen und so weiter.

Die Einschätzung von einigen Experten, so etwa die Mehrheitsauffassung der Financial Crisis Inquiry Commission, führte die Finanzkrise ab 2007 unter anderem auf die relativ laxe Finanzregulierung der 1980er und 1990er zurück. Selbst vorherige Verfechter dieser Politik, wie Alan Greenspan, rückten nach der Krise von der Markteffizienzhypothese ab. In der Folge kam es zu einem neuen Interesse an keynesianischen oder postkeynesianischen Erklärungsmodellen.

Ein auf den Postkeynesianer Hyman P. Minsky und Charles P. Kindleberger zurückgehender Ansatz erklärt Finanzkrisen als Ergebnis exzessiver Spekulation in einer boomenden Konjunktur. In der Theorie von Minsky verfolgen die Investoren nach einer Krise zunächst eine abgesicherte Finanzierung („hedging“). Die Einnahmen, die den Investitionen folgen, reichen aus, um die Kredite mit Zinsen zurückzuzahlen. Erweist sich das wirtschaftliche Wachstum als stabil, erscheint eine „spekulative Finanzierung“ eingehbar. Die Einnahmen reichen jetzt nur noch aus, um die Zinsen der aufgenommenen Kredite zu bedienen. Die Kredite selbst werden durch neu aufgenommene Kredite abgelöst. Erweist sich auch dies als stabil, gehen die Investoren schließlich zur „Ponzi-Finanzierung“ über, benannt nach Charles Ponzi. Sogar um die Zinslast finanzieren zu können, werden jetzt zusätzliche Kredite aufgenommen. Die Investoren erwarten aber weiterhin, dass ganz zum Schluss die Einnahmen aus der Investition ausreichen, um allen aufgelaufenen Verpflichtungen genügen zu können. Insgesamt ist aber die Wirtschaft immer labiler geworden und in einer Krise kommt es zu Insolvenzen und zu einer Bilanzbereinigung bei den Investoren. Nach der Krise beginnt mit der jetzt zunächst wieder abgesicherten Finanzierung (hedging) ein neuer Zyklus.

Minsky vertrat die Auffassung, dass die Finanzierungsprozesse einer kapitalistischen Ökonomie endogene destabilisierende Kräfte entwickeln. Er hielt die Finanzinstitutionen des Kapitalismus für „von sich aus ruinös“. Deshalb riet er dazu, zu akzeptieren, dass das Gebiet effizienter und wünschenswerter freier Märkte begrenzt ist.

George A. Akerlof und Robert J. Shiller wollen in ihrer Diagnose der Ursachen von Finanzkrisen wieder an die bei John Maynard Keynes präsente Vorstellung der „Animal Spirits“ anknüpfen. Diese sei im Keynesianismus zugunsten einer Synthese mit dem neoklassischen Mainstream vernachlässigt worden. Stärker als von rationalen Erwartungen sei die Entwicklung der Konjunktur abhängig von Vertrauen, Gerechtigkeitsvorstellungen, phasenweiser Korrumpierung ethischer Standards, Geldillusion und kollektiven Narrativen oder „Erzählungen“, die den Marktteilnehmern Orientierung geben können.

siehe auch: Herdenverhalten.

Unter anderem wird als Maßnahme gegen Finanzkrisen oder zu deren Dämpfung Makroprudentielle Aufsicht empfohlen. d. h. Aufsichtsbehörden sollen nicht nur mikroprudentiell vorgehen, sondern makroprudentiell auch den Systemzusammenhang insgesamt im Auge behalten.

Midas erkannte, dass er angesichts des begrenzten Vorrats an Metallen für die Münzproduktion die Geldmenge durch die Senkung des Metallgehalts pro Münze erhöhen konnte. Die Folge war eine Trennung der Geld- und Kreditpolitik und eine Globalisierung des Zahlungsmittels. Sparer, die in Midas „Leichtgeld“ ihr Vermögen anlegten, büßten durch diesen Geldüberhang und den nun fälligen Währungsschnitt ihre Kaufkraft ein. Sinnbildlich wird die Finanzierungstechnik Midas’ durch die Redewendung symbolisiert, dass alles, was Midas anfasste, sich in Gold verwandelte, sogar Wasser. Nach der Erzählung von Herodot starb Midas, weil er am zum Gold verwandelten Wasser erstickte.

Der Anwalt und Senator Marcus Tullius Cicero beschrieb die Krise 66 v. Chr.:

Tiefgreifende Schwierigkeiten bereitete eine globale Finanzkrise im 15. Jahrhundert, die Europa und Asien gleichermaßen betraf. Ausgelöst wurde die Krise durch eine Reihe von Faktoren: übersättigte Märkte, fallende Preise und unausgeglichene Zahlungsbilanzen, die außer Kontrolle gerieten. Selbst bei der wachsenden Nachfrage nach Seide und anderen Luxusartikel gab es nur ein bestimmt Menge, die China in Europa absetzen konnte. Vor allem hatte Europa kaum etwas zu bieten für Stoffe, Porzellan und Gewürze, die so teuer bezahlt wurden. Da China Anfang des 15. Jahrhunderts de facto mehr herstellte, als es im Ausland verkaufen konnte, waren die Folgen absehbar, sobald die Fähigkeit, weiterhin Waren zu kaufen, abnahm. Das Ergebnis war ein «Großer Hunger nach Edelmetall» (engl. "Great Bullion Famine"), wie man es häufig nannte. Aus heutiger Sicht handelte es sich um eine Deflation in Folge fallender Preise aufgrund eines Überangebots. Diese Deflation führte zum Horten von Silber- und Goldmünzen. Der gleichzeitige Rückgang von Abbaumengen in zahlreichen europäischen Gold- und Silberminen verschlechterte die Situation zusätzlich. Dies führte schließlich zu einer Liquiditätskrise von Korea bis Japan, von Vietnam bis Java, von Indien bis zum Osmanischen Reich. Kaufleute auf der Malaiischen Halbinsel nahmen die Angelegenheit selbst in die Hand und prägten eine seltsame neue Währung aus Zinn, das vor Ort reichlich vorhanden war. 

Der Liquiditätsengpass führte aber in Europa unmittelbar zu neuen Innovationen und zu gewagten Expeditionen auf der Suche nach neuen Silber- und Goldvorkommen. Zu den wichtigsten Innovationen zur Bekämpfung der europäischen Geldknappheit zählte die Lösung der Grundwasser-Problematik im Silberbergbau durch Martin Claus aus Gotha sowie die Seigerung bei der Silbergewinnung. Das Prinzip der Seigerung basiert darauf, dass sich Silber im Schmelzprozess wesentlich besser in Blei als in Kupfer löst. Fortan konnten große Mengen an Silber aus silberhaltigem Schwarzkupfer gewonnen werden. In den 1490ern etablierte Jakob Fugger die Saigerung in Schwaz in Tirol von wo bald knapp die Hälfte des europäischen Silbers kam sowie in der Fuggerau in Kärnten (das Blei kam aus Bleiberg) und kurz darauf auch in Neusohl. Zu den ersten "Edelmetallexpeditionen" jener Zeit zählten die Entdeckungsfahrten der Portugiesen Richtung Westafrika auf der Suche nach dem sagenumwobenen Songhaireich, das für seine hohen Goldvorkommen und Reichtümer seit der Zeit des Königs Mansa Musa bekannt war. Aber letztlich erst durch die großen Silber- und Goldmengen aus der Neuen Welt konnte die europäisch-asiatische Liquiditätskrise des 15. Jahrhunderts endgültig gelöst werden.




Grenzüberschreitende Finanzkrisen nach dem Ende des Bretton-Woods-Systems waren u. a. die





</doc>
<doc id="1768" url="https://de.wikipedia.org/wiki?curid=1768" title="Fränkisches Reich">
Fränkisches Reich

Das Fränkische Reich oder Frankenreich, das zwischen dem 5. und 9. Jahrhundert bestand und sich im Wesentlichen aus dem römischen Gallien und angrenzenden rechtsrheinisch-germanischen Siedlungsgebieten gebildet hatte, war der bedeutendste Nachfolgestaat des 476 untergegangenen Weströmischen Reiches und die historisch wichtigste Reichsbildung in Europa seit der Antike.

Das Reich der Franken ging auf mehrere westgermanische Kriegerverbände der Völkerwanderungszeit zurück. Nach dem Untergang Westroms stieg es im Frühmittelalter unter den Dynastien der Merowinger und der Karolinger in drei Jahrhunderten zu einer Großmacht auf, die weite Teile West-, Mittel- und Südeuropas beherrschte. Als Hausmeier der merowingischen Könige übten die Karolinger bereits seit dem späten 7. Jahrhundert die tatsächliche politische Macht aus, bevor sie im Jahr 751 selbst die Königswürde übernahmen. Den Höhepunkt seiner Macht und Ausdehnung erreichte das Frankenreich unter der Herrschaft Karls des Großen (768–814). Nachdem es im 9. Jahrhundert geteilt worden war, entwickelten sich aus der östlichen Reichshälfte das mittelalterliche deutsche Reich, aus der westlichen das spätere Königreich Frankreich.

Seit dem 4. Jahrhundert siedelten auf dem Gebiet des Römischen Reiches germanische Gruppen als Foederaten. Bei ihnen handelte es sich um Krieger, die unter eigenen Anführern im Dienste der Kaiser kämpften und dafür Anspruch auf Versorgung durch den römischen Staat hatten. Am nordöstlichen Ende Galliens siedelten dabei die Franken, die als "Franci" in römischen Quellen das erste Mal in den 50er Jahren des 3. Jahrhunderts erwähnt werden und seit dem späten 4. Jahrhundert als "foederati" für die Verteidigung der Rheingrenze gegen Plünderer zuständig waren. Umstritten ist, wie und wann sich aus diesen meist germanischen Söldnern im Laufe der Zeit ein Volk mit eigener Identität ausgebildet hat (siehe Ethnogenese).

Die Erstnennung des Stammes bzw. Verbandes der Salfranken findet sich beim römischen Historiker Ammianus Marcellinus, welcher vom Kampf des römischen "Caesar" (Unterkaisers) Julian gegen die Franken im Jahr 358 berichtete:

Nachdem Gallien spätestens seit dem Tod des machtbewussten Heermeisters Aëtius 454 der weströmischen Kontrolle mehr und mehr entglitten war, nutzten die Franken den Zusammenbruch des von Bürgerkriegen zerrütteten Weströmischen Reiches (um 476), um das entstandene Machtvakuum zu füllen und ihr Gebiet eigenmächtig zu vergrößern, ähnlich wie die Westgoten im Süden. Im Norden Galliens hatte sich ein römisches Restreich unter dem römischen Kommandeur Syagrius, dem Sohn des Heermeisters Aegidius, im Gebiet um Soissons halten können, welches vom Rest des Imperiums abgeschnitten war (seit 464, siehe auch Paulus). Mit den Gallo-Römern möglicherweise verbündet, eventuell aber auch in Konkurrenz zu ihnen stehend, war der salfränkische "rex" Childerich von Tournai.

486/487 besiegte Childerichs Sohn Chlodwig I. Syagrius, eroberte dessen Herrschaftsgebiet und übernahm das Kommando über die verbliebenen römischen Truppen. Dadurch verschob sich die Grenze des merowingischen Machtbereiches bis an die Loire. Chlodwig, der vorher nur einer von mehreren fränkischen "warlords" war, nutzte danach die Chance, die übrigen Teilreiche zu beseitigen und ein germanisch-romanisches Reich zu gründen. Er beseitigte nacheinander unter anderem den "rex" Sigibert von Köln sowie Ragnachar und führte 496/506 erfolgreiche Kriege gegen die Alamannen. 507 schlug Chlodwig die Westgoten in der Schlacht von Vouillé (oder bei Voulon), nach der er sie fast ganz aus Gallien verdrängte.

Der Besitz jener römischen Grundherren, die während der fränkischen Eroberungskriege getötet oder vertrieben wurden, gelangte in den Besitz des Herrschers. Dadurch finanzierte Chlodwig seine weiteren Feldzüge und stärkte seine Macht. Er wurde nach und nach größter Grundbesitzer. Durch Landschenkungen brachte er andere Adlige in direkte Abhängigkeit, woraus sich nach Ansicht der älteren Forschung vielleicht das Lehnswesen entwickelte – eine heute allerdings sehr umstrittene Hypothese. Im Laufe der Zeit verwandelte sich die Stellung des fränkischen "rex" immer mehr in die eines regelrechten Königs.

Chlodwig, dem es um die Versorgung seiner Krieger gehen musste, übernahm, soweit möglich, den funktionsfähigen spätantiken römischen Verwaltungs- und Finanzapparat (dessen Kern vor allem im Süden die "civitates" waren). Dabei spielte die Macht der örtlichen Bischöfe, die oft Verwaltungsaufgaben in den "civitates" übernommen hatten, eine wichtige Rolle, so dass sich die Kirche zu einer weiteren Machtstütze des Herrschers entwickeln sollte, dem es gelang, die Bischöfe weitgehend unter seine Kontrolle zu bringen. Angeblich unter dem Einfluss der Burgunderin Chrodechild trat Chlodwig, der zuvor entweder Heide oder Arianer gewesen war, zum katholischen Christentum über. Mit seiner Taufe (vielleicht 496/98 oder 508; das Datum ist umstritten) sicherte er sich die Unterstützung durch die römischen Christen und bereitete so einem Miteinander von fränkischen Kriegern und gallo-römischer Zivilbevölkerung den Weg. Um die Mitte des 6. Jahrhunderts ging dann die spätantike Übergangszeit in Gallien vorüber, das Frühmittelalter nahm langsam Gestalt an. Die lokalen Autoritäten (Grafen und Bischöfe) waren dazu bestimmt, Chlodwigs Anordnungen durchzusetzen. Daneben setzte Chlodwig 511 auf dem ersten fränkischen Reichskonzil einen maßgeblichen Einfluss fränkischer Könige auf die Bischofsinvestitur durch und versuchte, eine einheitliche kirchliche Gesetzgebung für das Frankenreich zu schaffen. Im frühen 6. Jahrhundert (nach 507) entstand mit der "Lex Salica" eine Sammlung des Rechts der Franken, das von der modernen Forschung allerdings nicht mehr auf altes germanisches Stammesrecht, sondern auf spätrömisches Soldatenrecht zurückgeführt wird.

Nach dem Tode Chlodwigs (511) wurde die Herrschaft nach dem Vorbild des spätrömischen Kaisertums (und nicht etwa, wie man früher glaubte, aufgrund germanischer Tradition) unter seine vier Söhne aufgeteilt. Allerdings konnte die formal nie aufgehobene Reichseinheit durch Chlodwigs Nachfolger immer wieder hergestellt werden (wobei vor allem Theudebert I. von Bedeutung ist, der eine expansive Politik in Italien betrieb). Tatsächlich gelang es von 558 bis 561 Chlothar I. die Einheit wieder herzustellen, vererbte nach seinem Tod das Reich aber wiederum an seine vier zu diesem Zeitpunkt noch lebenden Söhne.
Ab spätestens 623 begann im östlichen Reichsteil, der nun als Austrasien bezeichnet wurde eine Emanzipationsbewegung des Adels die von Chlothar II. einen eigenen Unterkönig in Person seines Sohnes Dagobert I. verlangte. Dieser wurde der letzte bedeutende Merowingerkönig. Die wahre Macht lag aber fortan beim Hausmeier Aega und der Witwe Dagoberts.

Die Hausmeier strebten nun auch nach der gesamten Macht im Reich. Ob die Merowingerkönige nach Dagobert allerdings durchgängig wirklich so schwach waren, wie es die späteren pro-karolingischen Quellen schildern, ist nicht eindeutig. In jüngerer Zeit äußern Historiker wie Ian N. Wood, Bernhard Jussen oder Johannes Fried zumindest vermehrt Zweifel an der Zuverlässigkeit der diesbezüglich parteiischen Berichten aus der Karolingerzeit.

Ein Intermezzo brachten die Jahre 657–662, in denen der Sohn des Hausmeiers Grimoald, der unter dem Namen Childebertus adoptivus in die Geschichte einging, von dem Merowinger Sigibert III. adoptiert wurde und in diesen Jahren auf dem Thron saß. In der Schlacht bei Tertry (687) schließlich besiegte der austrasische Hausmeier Pippin II. den rechtmäßigen Herrscher des fränkischen Gesamtreiches und schuf so die Voraussetzung für den weiteren Aufstieg der Arnulfinger und Pippiniden und später den der Karolinger. Pippin wagte es aber nach dem im Endeffekt missglückten „Staatsstreich“ Grimoalds noch nicht, sich selbst zum König zu erheben, weil das dynastische Denken zu stark ausgeprägt war, das in spätantiker Tradition nur einer einzigen Familie das Recht auf die Herrschaft zusprach.

714, nach dem Tode Pippins, entbrannten Machtkämpfe, in denen sich 719 sein unehelicher Sohn Karl Martell durchsetzte. Der für seine Härte und sein Durchsetzungsvermögen bekannte Karl stand vor schwierigen innen- und außenpolitischen Problemen. Immer wieder versuchten einige Führer der "alten" Reichsadelsgeschlechter im Frankenreich, sich gegen seine Herrschaft aufzulehnen. Einen Wendepunkt stellte das Jahr 732 dar. In der Schlacht bei Tours und Poitiers besiegte Karl, gemeinsam mit seinem ehemaligen Feind Eudo von Aquitanien und unterstützt von den Langobarden, die muslimischen Araber. Hierfür wurde er als Retter des Abendlandes gefeiert. Auch die Kämpfe gegen Friesen, Sachsen, Bajuwaren und Alamannen festigten seine Herrschaft. Daneben unterstützte er die Missionsarbeit des Bischofs Bonifatius in diesen Gebieten. Ab 737 herrschte er nach dem Tode des merowingischen Königs Theuderich IV. allein über das Frankenreich, wie schon sein Vater ohne Königstitel. Nach fränkischer Tradition teilte Karl Martell das Reich kurz vor seinem Tode unter seinen Söhnen Karlmann und Pippin III. auf.

Pippin III. wurde Alleinherrscher, nachdem sein Bruder Karlmann ins Kloster gegangen war. 751 setzte er nach Absprache mit Papst Zacharias den letzten merowingischen König, Childerich III., ab und ließ sich dann nach alttestamentlichem Vorbild zum König salben. Drei Jahre später salbte ihn Papst Stephan II. ein zweites Mal. Im Vertrag von Quierzy (754) versprach Pippin, das ehemalige oströmische Exarchat von Ravenna dem Papst als weltliche Herrschaft zu übertragen (Pippinische Schenkung); im Gegenzug legitimierte der Papst die Karolinger als Könige des Frankenreichs. Schon 755 ereilte den fränkischen König die Bitte, dem Vertrag nachzukommen. Bis zu seinem Tode führte Pippin zwei erfolgreiche Feldzüge gegen die Langobarden und schenkte dem Papst die eroberten Gebiete. Pippin III. gilt so als Begründer des Kirchenstaates. Bei seinem Tode 768 hinterließ er seinen Söhnen Karl und Karlmann ein Reich, das politisch wie wirtschaftlich im Aufbau begriffen war.

Kurze Zeit später (771) starb Karlmann, und Karl der Große wurde dadurch Alleinherrscher. Durch den von seinem Vater geschlossenen Vertrag mit dem Papst war Karl diesem verpflichtet. Da die Langobarden die Schenkungen Pippins nicht anerkannten, führte Karl weiter gegen sie Krieg und eroberte ihr Reich im Jahre 774. Neben den Langobardenfeldzügen schritt die Missionierung im Osten voran. Besonders die Kriege gegen die Sachsen bestimmten die Politik Karls bis 785, als sich Widukind schließlich dem fränkischen König unterwarf. Die Sachsenkriege dauerten noch bis 804 fort (letzter Feldzug der Franken nach Nordelbien). 811 wurde die Eider als Grenze zwischen dem fränkischen und dem dänischen Reich festgelegt; damit war die Nordexpansion der Franken abgeschlossen.

Die zahlreichen Kriege bewirkten eine fortschreitende Feudalisierung, eine Stärkung der Reichen und einen Anstieg der feudalabhängigen Bauern. Im Ergebnis dieser Entwicklung wuchsen Besitz und Macht der Lehnsherren, insbesondere des Königs (und späteren Kaisers) und der Herzöge. Auch die Kirche konnte ihre Macht festigen. Karl konsolidierte die Staatsmacht nach außen durch die Errichtung von Grenzmarken. Diese waren Bollwerke für die Reichsverteidigung und Aufmarschgebiete für Angriffskriege. Zur Verwaltung setzte er Markgrafen ein, die mit besonderen Rechten ausgestattet waren, da die Marken nicht direkt Teil des Reiches waren und somit auch außerhalb der Reichsverfassung standen. In den Marken wurden Burgen errichtet und eine wehrhafte Bauernbevölkerung angesiedelt. Besonders wichtig waren hierbei die Marken im Osten des Reiches, die Awarenmark (siehe auch Marcha Orientalis) und die Mark Karantanien, aus denen später Österreich hervorging (siehe auch Ostarrîchi).

Zur Festigung seiner Herrschaft nach innen zentralisierte Karl die Königsherrschaft um 793 durch eine Verwaltungsreform. Die Königsherrschaft gründete sich auf den königlichen Hof, das Pfalzgericht und die Kanzlei. Im Reich verwalteten Grafen die Königsgüter (Pfalzen). Pfalz- und Markgrafen wurden durch Königsboten "(missi dominici)" kontrolliert und sprachen königliches Recht. Aachen wurde unter Karl zur Kaiserpfalz und zum Zentrum des Frankenreiches.

Den Höhepunkt seiner Macht erreichte Karl am 25. Dezember 800 mit der Krönung zum römischen Kaiser: Damit war das Frankenreich – neben dem Byzantinischen Kaiserreich und dem Kalifat der Abbasiden – nun endgültig eine anerkannte Großmacht.

Nach 46-jähriger Herrschaft starb Karl 814 in Aachen. Sein Sohn Ludwig der Fromme wurde Kaiser. Dieser versuchte, entgegen der fränkischen Tradition, welche die Aufteilung des Erbes vorsah und wie es auch Karl der Große in der Divisio Regnorum von 806 bestimmt hatte, die Reichseinheit zu wahren und erließ 817 ein Reichsteilungs- oder besser Reichseinheitsgesetz (Ordinatio imperii). Schließlich galt auch die Kaiserwürde als unteilbar. Deswegen bestimmte Ludwig seinen Sohn Lothar zum Mitkaiser. Das Gesetz sah vor, dass immer der älteste Sohn des Kaisers den Titel des römischen Kaisers erben sollte. Ludwig entschied sich für den Reichseinheitsgedanken, wenn auch unter kirchlichem Einfluss, der die Einheit des Reiches als Pendant zur Einheit der Kirche sah. Daher spielten die Bischöfe auch eine besondere politische Rolle: Sie stellten sich gegen die Söhne des Kaisers, die für die Aufteilung des Reiches waren. Seit 829 führten diese Spannungen zu militärischen Auseinandersetzungen zwischen dem Kaiser und seinen Söhnen.

Als Ludwig 840 starb, wurde Lothar I. zwar Kaiser, doch einigten sich die Söhne 843 im Vertrag von Verdun, das Frankenreich aufzuteilen. Später wurde das Reich durch die Prümer Teilung (855) und die Verträge von Mersen (870) und Ribemont (880) weiter aufgeteilt. Die Reichseinheit wurde, außer kurzzeitig unter Karl III. (885–887), nicht wiederhergestellt. Die einzelnen Teile entwickelten unterschiedliche Sitten, Bräuche, Sprachen und wurden so zu eigenständigen Staaten. Einige Zeit darauf sprach man von einem West- und Ostfränkischen Reich, bis dieser Hinweis auf die gemeinsame Herkunft ein Jahrhundert später verschwand. Vom alten Frankenreich sollte nur der westliche Teil den Namen "„Frankreich“" übernehmen. Das aus dem Ostfrankenreich entstehende Heilige Römische Reich, aus dem später Deutschland hervorging, führte die Tradition des römischen Kaisertums fort. Ein Herzogtum Franken konnte sich dort im Frühmittelalter nicht durchsetzen und wurde aufgeteilt. Jedoch hat der fränkische Name in der Region Franken, die jeweils einen kleinen oder größeren Teil der Länder Baden-Württemberg, Bayern, Thüringen und Hessen ausmacht, bis in die moderne Zeit überlebt, ebenso wie der Gebrauch des Wortes "Franken" in einigen Dialektgruppen: Niederfränkisch, Mittelfränkisch, Rheinfränkisch, Südfränkisch und Ostfränkisch.

Das Testament Karls des Großen sah die Aufteilung unter seinen Söhnen Pippin, Ludwig dem Frommen und Karl dem Jüngeren vor. Da jedoch Pippin und Karl der Jüngere bereits 810 bzw. 811 und damit vor ihrem Vater verstarben, wurde dieser Plan aufgegeben und Ludwig stattdessen 813 zum Mitkaiser erhoben, der so nun nach dem Tod seines Vaters 814 im Besitz aller kaiserlichen Rechte seine Nachfolge antreten konnte.

Die Aufteilung des Fränkischen Reichs ging auf den teils kriegerischen Erbfolgestreit zurück, den Kaiser Ludwig I., "der Fromme," mit seinen Söhnen führte. Nach einer Palastrevolution und Gefangennahme wurde Kaiser Ludwig I. Anfang der 830er Jahre von seinen Söhnen entmachtet. Ab 831/832 verselbständigten die Söhne zunehmend ihre Herrschaftsbereiche im Reichsverband und beließen ihren Vater in der Funktion eines "Titularkaisers". Drei Jahre nach dem Tod ihres Vaters leiteten Kaiser Lothar I., König Karl der Kahle und König Ludwig der Deutsche 843 im Vertrag von Verdun die Teilung und damit das Ende des Fränkischen Reiches ein; die Reichseinheit war nicht mehr zu gewährleisten und endete faktisch mit dem Vertrag von Verdun.

Durch die Teilung entstanden drei neue Reiche:


855 veranlasste Lothar I. in der Prümer Teilung die Aufteilung des Mittelreiches unter seinen Söhnen.

Nach dem Tod der Söhne Lothars I. wurde das einstige Mittelreich unter Karl dem Kahlen und Ludwig dem Deutschen im Vertrag von Meersen aufgeteilt.

Nach vergeblichen Versuchen Karls des Kahlen, das ganze Mittelreich zu erobern (Erste Schlacht bei Andernach 876), erhielt der ostfränkische König Ludwig III. durch den Vertrag von Ribemont die Westhälfte Lotharingiens. Damit war die Aufteilung des Frankenreiches vorläufig abgeschlossen, die Grenze zwischen dem West- und Ostteil blieb das ganze Mittelalter über nahezu unverändert.

Nach dem Tod der Könige Ludwig III. (882) und Karlmann (884) wurde der ostfränkische König Karl III. bis 888 noch letzter Kaiser des Gesamtreiches (außer Niederburgund).

Im Frankenreich war der Großteil der Bevölkerung Bauern oder bäuerliches Gesinde. In vielen Gegenden gab es keine Städte, da Gallien bereits in der Antike zu den weniger stark urbanisierten Teilen des "Imperium Romanum" gezählt hatte. Vor allem im Süden bestanden aber verkleinerte römische Anlagen fort, die als Verwaltungsmittelpunkte von Civitates unter Bischöfen oder "comites" („Grafen“) weiter existierten. Im Süden des Frankenreichs stellten die Gallorömer die große Mehrheit der Bevölkerung, weshalb sich die germanischen Dialekte der fränkischen Kriegerschicht hier nie durchsetzten. Im Norden setzten sich hingegen fränkische Sprache und Lebensweise stärker durch. Hier war das Leben insgesamt primitiver als im Süden. Über dem niederen Volk befand sich eine dünne Schicht von Adligen, in der damaligen Zeit meist „die Großen“ genannt.

Die materielle Kultur war nach dem Zerfall der antiken Strukturen nun erheblich einfacher als in römischer Zeit, und anders als in der Kaiserzeit konnte nun auch nur noch ein Bruchteil der Menschen lesen und schreiben. Der Großteil der Menschen verbrachte sein ganzes Leben in demselben Dorf. Täglich wurde von Sonnenaufgang bis Sonnenuntergang gearbeitet, außer am Sonntag und an kirchlichen Festtagen. War man alt genug, heiratete man und bekam beinahe jährlich ein Kind; die meisten Kinder starben jung. Allgemein war die Lebenserwartung wesentlich niedriger als heute, mit 50 Jahren galt eine Bäuerin oder ein Bauer als Greis. Die meisten Menschen kannten nebst ihrem Dorf nur den Weg zur nächsten Kirche und umliegende Ortschaften. Von dem Geschehen in größerer Entfernung hatte der Großteil keine Ahnung. Ein zusätzliches Hindernis war das Fehlen von befestigten Straßen außer denjenigen, die von den Römern angelegt worden waren. Arbeiten auf dem Land wurden von den Bauern in der gleichen Weise verrichtet, wie es einst ihre Väter vor ihnen taten.

Genaue Zahlen über die damalige Bevölkerung sind nicht bekannt, so dass die Historiker auf Schätzungen angewiesen sind. Diese ergaben eine ungefähre Anzahl von 2 Millionen Einwohnern im nördlichen, „deutsch“-sprachigen Teil des Frankenreichs. Für das ganze Reich nimmt man eine durchschnittliche Bevölkerungsdichte von etwa 8 Einwohnern/Quadratkilometer an, für die fränkischen Sprachgebiete hingegen nur eine durchschnittliche Anzahl von 4 bis 5 Einwohnern/Quadratkilometer.

Die Krieger des fränkischen "rex" übernahmen nach dem Kollaps des weströmischen Reiches vielfach die Herrenhöfe gallo-römischer Vorgänger, während andere Latifundien nicht den Besitzer wechselten. Wie die anschließende Transformation der spätrömischen Wirtschaft und Gesellschaft genau ablief, ist unklar; der Prozess war jedenfalls weitaus komplexer, als es die Forschung lange annahm. Details kennt man erst für die karolingische Zeit: Die Knechte und Mägde, die neben dem Herrenhof wohnten, kümmerten sich nun um das Land des Herren. Sie bekamen kein Geld, aber dafür Verpflegung und Unterkunft. Die Handwerker unter ihnen stellten die Kleidung und Waffen her und pflegten diese. Die Ärmeren wurden zu Heeresdienst gezwungen. Die anderen, die Abgaben leisten konnten, wurden nach Hause entlassen.

Die Bauern als der vorherrschende Teil der Landbevölkerung im Mittelalter wurden genau nach ihrem Rechtsstatus unterschieden. Es gab Freie, Halbfreie und Unfreie, später wurde noch zwischen Leibeigenen und Hörigen unterschieden. Auch die Adligen waren anfangs nur Großbauern mit besonders umfangreichem Besitz an Land, Allod genannt, und an Menschen. Über diese Angehörigen seines Hauses übte der Adlige ein weitreichendes Herrenrecht aus. Zum Haus zählten dabei in weiterem Sinne auch abhängige Familien. Eine ähnliche Stellung nahmen zuvor in der spätrömischen Gesellschaft die Großgrundbesitzer ein, denen ein umfangreicher Besitz an Latifundien gehörte, in dessen Zentrum ein luxuriöser Herrenhof stand, der von zahlreichen abhängigen Bauern bewirtschaftet wurde. Daneben gehörten noch Handwerker zu dessen Besitz, so dass man nahezu von Selbstversorgung ausgehen kann. Diese Bauern waren an ihr Stück Land gebunden und durften nicht wegziehen, um sich an einem anderen Ort einen anderen Herren oder gar einen anderen Beruf zu suchen. Aus diesen beiden Wurzeln entstand in einer langen Entwicklung die neue Gesellschaftsordnung der heutzutage so genannten Grundherrschaft im Frankenreich.

Die Grundherrschaft setzte sich im ganzen Reich durch. Sie breitete sich rasch auch in den Gebieten aus, die erst um 800 in fränkischen Besitz gelangten. Grundherren waren Adlige, Klöster, Bischöfe und der König, der damals der größte Grundeigentümer war. Die Bauern, die unter eine solche Herrschaft fielen, wirtschafteten den größten Teil der Zeit nicht selbstständig, sondern mussten gleichzeitig auf den Feldern des Eigentümers mithelfen. Die Grundherrschaft wurde zum „Grundbaustein“ des damaligen Gesellschaftsbaus und spätestens in karolingischer Zeit zum üblichen landwirtschaftlichen Betrieb, ähnlich wie heute der Bauernhof der übliche landwirtschaftliche Betrieb ist.

Die Grundherren waren in karolingischer Zeit alle Adligen (Bischöfe, Äbte). Der hörige Bauer des Mittelalters durfte ohne die Erlaubnis seines Grundherren nicht aus der Grundherrschaft ausscheiden. Die Hörigen mussten Dienste für ihren Herrn verrichten und ihm dabei regelmäßig Abgaben zahlen, meist in Form von Anteilen an der Ernte. Aber auch der Eigentümer hatte Pflichten, die es zu erfüllen galt. Er musste seinem Untergebenen „Schutz und Schirm“ bieten, das heißt ihn schützen und unterstützen, beispielsweise bei Krankheiten, einem Brand oder einer starken Missernte. Er musste ihn sowohl vor Angreifern verteidigen, als auch in seinem Namen Rache üben, falls er umgebracht werden sollte. Innerhalb seiner eigenen Grundherrschaft war er der Hüter des Friedens, so sprang er auch bei Streitereien als Vermittler und Richter ein und konnte im Streitfall den Friedensbrecher bestrafen.

Die Grundherrschaft gliederte sich dabei in verschiedene Bereiche. Es gab je nach Größe des Hofes eine Kirche, verschiedene Werkstätten (Lederwerkstatt, Schmiede, Wagnerei, Schneiderei, Tuchfärberei, Schuhmacher), eine Brauerei, eine Mühle und eine Kelterei. Dazu gab es natürlich eine Vielzahl von Feldern, von denen der Großteil den Hörigen zur Verfügung gestellt wurde. Ein Teil der Felder war jedoch noch im Besitz des Grundherrn. Und so gehörte es nebst den Abgaben ebenfalls zu den Aufgaben der Bauern, täglich eine bestimmte Zeit auf diesen Feldern zu arbeiten, bevor sie sich um die Bestellung ihrer eigenen Flächen kümmern konnten.

Nebst den Hörigen gab es auch das so genannte Gesinde. Mit diesem Begriff bezeichnet man die Knechte und Mägde des Grundherrn, deren einzige Aufgabe darin bestand, auf den Feldern ihres Eigentümers Frondienst zu leisten. Sie wohnten zumeist im Fronhof oder unmittelbar daneben.

Nebst den zahlenmäßig größten Schichten der Bevölkerung, dem hörigen Bauern und dem grundherrlichen Gesinde, gab es im Frankenreich noch zwei weitere bäuerliche Schichten: die Zinsbauern und die Königsfreien. Bei den Zinsbauern handelt es sich um solche Landwirte, die keiner Arbeit auf dem Fronhof oder dem Herrenacker verpflichtet waren, dem Grundherren jedoch eine bestimmte Abgabe zahlten, damit dieser sie vor allfälligen Gefahren schützt. Im Laufe der Zeit wurden sie den Hörigen langsam angepasst und gegen Ende des Frankenreichs (etwa um 900) unterschieden sie sich praktisch nicht mehr von ihnen.

Die Königsbauern waren Bauern, die außer dem König keinen Menschen über sich hatten. Meist gehörten sie dem fränkischen Stamm an. Sie waren zur Heerfolge verpflichtet, wenn der König seine Armee aufbot und dienten dort als Fußkrieger. Die Frankenkönige hatten seit dem Einbrechen der Franken in Gallien die Königsbauern zumeist auf herrenloses Land gesetzt. Karl der Große siedelte vor allem in Sachsen diese Bauern an, die er vermutlich aus den Hörigen der Königsgüter, über die er Grundherr war, hatte auswählen lassen. Sie sollten damit gleichzeitig die fränkische Herrschaft über Sachsen sichern.

Es kam nicht selten vor, dass Könige ein vormals an einen Königsfreien vergebenes Land wieder an eine neue Person verschenkten, beispielsweise als Landgeschenk an ein Kloster oder wenn sie einen Vasallen mit Grund ausstatten wollten. In diesem Fall wurde das Land mitsamt dem Königsfreien verschenkt. Dieser blieb zwar theoretisch gesehen ein freier Mann, war aber gleichzeitig seinem neuen Eigentümer untertan. Zuerst verlor er das Recht, von seinem Besitz wegzuziehen und wurde Schritt für Schritt zum Hörigen gemacht.

Es gab aber auch Fälle, in denen sich ein Königsfreier freiwillig einem Grundherren untertan machte. Dies konnte verschiedene Gründe haben: Verarmung und die Unfähigkeit, selber weiter zu wirtschaften, eine große Anzahl Schulden an einen Grundherren, die nicht mehr zurückgezahlt werden konnten oder weil er sich nicht mehr für das Heer aufbieten lassen wollte. Ohne dass es ein genaues Gesetz gab, bürgerte es sich mit der Zeit ein, dass hörige Bauern nicht mehr dazu verpflichtet waren, in Kriegen zu kämpfen.

Gegen Ende des Frühmittelalters wurde in den verschiedensten Gegenden Frankreichs und Deutschlands beschlossen, dass kein Landbewohner frei sein könne. Das heißt, jeder Bauer musste einen Grundherren über sich haben und gehörte damit entweder zum Gesinde eines Herrn oder zu dessen hörigen Bauern.

Im Laufe der Jahrhunderte nahm die Anzahl der Klöster im Reich stark zu. Seit dem ersten Karolingerkönig und seit Bischof Bonifatius nahmen mehr und mehr solcher Einrichtungen die 530 verfasste Regel des heiligen Benedikt an. Benedikt von Nursia hatte hiermit das Zusammenleben und Verhalten der Mönche in seinem Kloster auf dem Montecassino bei Neapel festgelegt. Es wurde in der darauf folgenden Zeit zur Mustereinrichtung für das gesamte europäische Klosterwesen.

Mönche und Nonnen wurden hauptsächlich jene, die sich von der restlichen Welt mit ihren Freunden oder Bindungen zurückziehen wollten, um ihr Leben in den Dienst Gottes zu stellen. Es gab jedoch noch weitere Beweggründe für einen Eintritt, so wurden Klosterbrüder und -schwestern wirtschaftlich hinreichend versorgt. Fünfmal am Tag und zweimal in der Nacht versammelten sich die Mönche in ihrer Kirche zu Gebeten und zum Psalmensingen. Bei den Mahlzeiten las immer abwechselnd ein Mönch seinen Brüdern aus den Schriften von Heiligen vor. Aufgrund der drei Gelübde, die Mönche bei ihrem Eintritt ablegen mussten, durften sie weder eine Ehe führen noch Kinder haben. Sie sollten mittellos sein und waren dem jeweiligen Abt zu Gehorsam verpflichtet. Dies alles sollte dazu dienen, dass ein Mönch sein Leben nur auf Gott ausrichten konnte.

Da Untätigkeit als eine Sünde galt, schrieb das Reglement vor, dass die Mönche mehrere Stunden pro Tag arbeiten und mehrere Stunden lesen sollten. Alles, was man zum Leben brauchte, wurde in der Klosteranlage hergestellt. Ein Teil der Mönche verrichtete seine Arbeit auf den Feldern, ein Teil seine im Klostergarten. Wieder andere verrichteten ihren Dienst als Abschreiber, indem sie Pergamentschreiben oder Bücher aus den Klosterbibliotheken kopierten. Nebst vorwiegend christlichen Schriften wurden auch Bücher „weltlicher“ Autoren übernommen, beispielsweise die Schriften von Titus, Caesar und Vergil. Ab dem 6. Jahrhundert entstanden zusätzlich zu den Mönchsklöstern auch Frauenklöster für Nonnen. Nonnen verrichteten keine Feldarbeit, arbeiteten jedoch oftmals im Garten.

Im Frankenreich wurden Klöster vielfältig mit Ländereien beschenkt und konnten sich auf diese Weise zu reichen Grundherren entwickeln. Die großen Klöster beschäftigten unter anderem auch Knechte, die als Handwerker in gewissen Werkstätten arbeiteten. Von Adligen wurden die Klöster nicht selten auch als Versorgungsstätten für ihre Söhne und Töchter verwendet, die sie nicht hatten verheiraten können. Hier konnten sie zwar kein adeliges Leben führen, allerdings ohne wirtschaftliche Not leben. Überdies waren die einem Kloster vorstehenden Äbte und Äbtissinnen in vielen Fällen von adeliger Herkunft.

"Siehe auch:" Kloster, Klosteralltag (Zisterzienser)

Der König stand seit karolingischer Zeit nicht nur über den gewöhnlichen Bauern und den Adligen, sondern auch über den Äbten und Bischöfen in seinem Reich. Er war bei weitem der größte Grundherr im Land. In einer Vielzahl von Gebieten hatte er Adlige zu Grafen gemacht; mit diesem Titel führten sie dort die Aufsicht über die in der Nähe gelegenen Königsgüter und einzelne Fronhöfe, wirkten beim Heeresaufgebot mit und zogen die dem König zustehenden Abgaben aus dem Land (Grenz-, Schifffahrts- und Wegzölle, Münzenprägungs- und Marktabgaben) ein. In einigen seiner Gutshöfe ließ der König ab karolingischer Zeit größere, steinerne Gebäude errichten, die sogenannten Pfalzen (von lat. "palatium", „Palast“). Alle Königsgüter hatten ihre Überschüsse an die nächstgelegene solche Einrichtung zu entrichten. Jeder Pfalz stand ein Pfalzgraf vor.

Der König hatte keine feste Hauptstadt, sondern zog mit seinem Hofgefolge von Pfalz zu Pfalz. Zum einen war sein Gefolge auf diese Weise leichter zu versorgen, zum anderen konnte er so Präsenz im Reich zeigen – da mit dem Ende des weströmischen Reiches auch die antike Infrastruktur und Verwaltung zerfallen waren, war dies unumgänglich, um Kontrolle auszuüben. Zum Gefolge zählten ein Kämmerer, dessen Aufgabe darin bestand, den Königsschatz und die Einkünfte des Königs zu verwalten, und der Marschall, der die berittenen Krieger der Königswache befehligte. Ein Geistlicher war ebenfalls anwesend und leitete die Kanzlei. Er las dem König die Briefe anderer Herrscher oder von Bischöfen vor, verfasste die Antwortschreiben und ließ durch die ihm unterstehenden Hofgeistlichen die Schenkungs- und andere königliche Urkunden verfassen. Der Herrscher selbst konnte nur in den wenigsten Fällen lesen und schreiben. Auch Karl der Große hatte dieses Problem: Anstelle seiner Unterschrift zeichnete er auf eine Urkunde oder ein Schreiben einen kleinen Strich und vervollständigte so sein Monogramm, um die Urkunde für gültig zu erklären.


Monographien/Sammelbände

Artikel in Fachlexika

Monographien/Sammelbände

Artikel in Fachlexika

Monographien/Sammelbände

Artikel in Fachlexika



</doc>
<doc id="1770" url="https://de.wikipedia.org/wiki?curid=1770" title="FSF">
FSF

Die Abkürzung FSF steht für:


</doc>
<doc id="1771" url="https://de.wikipedia.org/wiki?curid=1771" title="Fakultät (Mathematik)">
Fakultät (Mathematik)

Die Fakultät (manchmal, besonders in Österreich, auch Faktorielle genannt) ist in der Mathematik eine Funktion, die einer natürlichen Zahl das Produkt aller natürlichen Zahlen (ohne Null) kleiner und gleich dieser Zahl zuordnet. Sie wird durch ein dem Argument nachgestelltes Ausrufezeichen („!“) abgekürzt. Diese Notation wurde erstmals 1808 von dem elsässischen Mathematiker Christian Kramp (1760–1826) verwendet, der um 1798 auch die Bezeichnung "faculté" „Fähigkeit“ dafür einführte.

Für alle natürlichen Zahlen formula_1 ist
als das Produkt der natürlichen Zahlen von 1 bis formula_1 definiert. Da das leere Produkt stets 1 ist, gilt 

Die Fakultät lässt sich auch rekursiv definieren:

Fakultäten für negative oder nicht ganze Zahlen sind nicht definiert.

Die Werte der Fakultäten bilden die .

In der abzählenden Kombinatorik spielen Fakultäten eine wichtige Rolle, weil formula_7 die Anzahl der Möglichkeiten ist, formula_1 unterscheidbare Gegenstände in einer Reihe anzuordnen. Falls formula_9 eine formula_1-elementige Menge ist, so ist formula_7 auch die Anzahl der bijektiven Abbildungen formula_12 (die Anzahl der Permutationen). Dies gilt insbesondere auch für den Fall formula_13, da es genau eine Möglichkeit gibt, die leere Menge auf sich selbst abzubilden.

Beispielsweise gibt es bei einem Autorennen mit sechs Fahrern formula_14 verschiedene Möglichkeiten für die Reihenfolge beim Zieleinlauf, wenn alle Fahrer das Ziel erreichen. Für den ersten Platz kommen alle sechs Fahrer in Frage. Ist der erste Fahrer angekommen, können nur noch fünf Fahrer um den zweiten Platz konkurrieren. Für die Belegung des zweiten Platzes ist es maßgeblich, welcher der sechs Fahrer nicht berücksichtigt werden muss (da er bereits auf Rang 1 platziert ist). Daher muss für jede Belegungsmöglichkeit von Platz 1 gesondert gezählt werden, wie viele Belegungsmöglichkeiten für Platz 2 bestehen. Für die Belegung der Plätze 1 und 2 ergeben sich bei sechs Fahrern daher formula_15 Möglichkeiten. Ist auch der zweite Platz vergeben, kommen für den dritten Platz nur noch vier Fahrer in Frage, woraus sich für die ersten drei Plätze und sechs Fahrer formula_16 Belegungsmöglichkeiten ergeben, usw. Letztlich gibt es also

verschiedene Ranglisten für den Zieleinlauf.

Ein Begriff, der in der abzählenden Kombinatorik eine ähnlich zentrale Stellung wie die Fakultät einnimmt, ist der Binomialkoeffizient
Er gibt die Anzahl der Möglichkeiten an, eine formula_19-elementige Teilmenge aus einer formula_1-elementigen Menge auszuwählen. Umgekehrt gilt
Hier ist das beliebteste Beispiel, das Zahlenlotto 6 aus 49 mit
Möglichkeiten. 

Eine prominente Stelle, an der Fakultäten vorkommen, sind die Taylorreihen vieler Funktionen wie zum Beispiel der Sinusfunktion und der Exponentialfunktion.

Die eulersche Zahl formula_23 lässt sich als Summe der Kehrwerte der Fakultäten definieren:

Der numerische Wert für formula_7 kann gut rekursiv oder iterativ berechnet werden, falls formula_1 nicht zu groß ist.

Die größte Fakultät, die von den meisten handelsüblichen Taschenrechnern berechnet werden kann, ist formula_27 da formula_28 außerhalb des üblicherweise verfügbaren Zahlenbereiches liegt.
Die größte als Gleitkommazahl im Format "double precision" des IEEE-754-Standards darstellbare Fakultät ist formula_29.

Umsetzung der Fakultätberechnung in ein Pythonprogramm (in der Programmiersprache Python kann mit beliebig großen ganzen Zahlen gerechnet werden, Grenzen setzt lediglich der verfügbare Speicher).

Auf einem Intel Pentium 4 benötigt zum Beispiel die Berechnung von 10000! nur wenige Sekunden. Die Zahl hat 35660 Stellen in der Dezimaldarstellung, wobei die letzten 2499 Stellen nur aus der Ziffer "Null" bestehen.
n = int(input('Fakultaet von n = '))
f = 1
for i in range(1, n + 1):
print(n,'! = ',f)

n = int(raw_input('Fakultaet von n = '))
f = 1
for i in range(1, n + 1):
print n,'! = ',f

public static int factorial(int n) {
Rekursive Lösung
public int factorial(int n) {

Wenn formula_1 groß ist, bekommt man eine gute Näherung für formula_7 mit Hilfe der Stirling-Formel:
Dabei bedeutet formula_33, dass der Quotient aus linker und rechter Seite für formula_34 gegen formula_35 konvergiert.

Es gibt eine Reihe weiterer Folgen und Funktionen, die in ihrer Definition oder ihren Eigenschaften ähnlich aussehen wie die Fakultät:

Die Gammafunktion formula_36 verallgemeinert die Fakultät um ihren Definitionsbereich von den natürlichen bis hin zu den komplexen Zahlen:

Eine kombinatorische Verallgemeinerung stellen die steigenden und fallenden Faktoriellen formula_39 und formula_40 dar, denn formula_41.

Die Primfakultät einer Zahl ist das Produkt der Primzahlen kleiner oder gleich der Zahl:

Die vor allem in der Kombinatorik auftretende Subfakultät

bezeichnet die Anzahl aller fixpunktfreien Permutationen von formula_1 Elementen.

Die seltener verwendete "Doppelfakultät" oder "doppelte Fakultät" ist für gerade formula_1 das Produkt aller geraden Zahlen kleiner gleich formula_1. Für ungerade formula_1 ist es das Produkt aller ungeraden Zahlen kleiner gleich formula_1.

Sie ist definiert als:

Häufig werden anstelle der Doppelfakultät Ausdrücke mit der gewöhnlichen Fakultät verwendet. Es gilt

Werden nicht ganzzahlige Funktionswerte zugelassen, dann gibt es genau eine Erweiterung auf negative ungerade Zahlen, so dass formula_52 für alle ungeraden ganzen Zahlen formula_1 gilt. Man erhält die Formel formula_54 für ungerade formula_55.

Die Werte der Doppelfakultäten bilden die .



Analog zur doppelten Fakultät wird eine dreifache (formula_74), vierfache (formula_75), …, formula_19-fache Fakultät (formula_77) rekursiv definiert als

Der Begriff "Superfakultät" formula_79 wird für (wenigstens) zwei unterschiedliche Funktionen verwendet; die eine ist definiert als das Produkt der ersten Fakultäten:

mit der Barnes’schen Funktion formula_81, die andere als mehrfache Potenz einer Fakultät


</doc>
<doc id="1772" url="https://de.wikipedia.org/wiki?curid=1772" title="Frank Herbert">
Frank Herbert

Frank Patrick Herbert (* 8. Oktober 1920 in Tacoma, Washington; † 11. Februar 1986 in Madison, Wisconsin) war ein US-amerikanischer Fantasy- und Science-Fiction-Autor. Als sein wichtigstes Werk gilt der Romanzyklus "Dune", der sich über zwölf Millionen Mal verkaufte und der bereits mehrfach verfilmt wurde.

Nach eigener Aussage hegte Herbert bereits zu seinem achten Geburtstag den Wunsch, Schriftsteller werden zu wollen. Da seine Familie jedoch in Armut lebte, boten sich ihm kaum Perspektiven, diesen Traum in die Wirklichkeit umsetzen zu können. Im Alter von 18 Jahren zog er schließlich zu Verwandten nach Salem, wo er die Schule beendete und als freier Journalist zu arbeiten begann. Um an Aufträge zu gelangen, fälschte er unter anderem seine Dokumente, um älter zu erscheinen.

Nach Ausbruch des Zweiten Weltkrieges wurde Herbert in die Marine eingezogen, für die er als Fotograf zum Einsatz kam. Nach seiner Entlassung heiratete er 1940 seine erste Frau, Flora Parkinson. Die Ehe hielt jedoch nur fünf Jahre und blieb kinderlos.

1946 lernte Herbert während des Studiums an der Universität von Washington in einem Seminar für kreatives Schreiben seine zweite Frau, Beverly Ann Stuart, kennen. Mit ihr sollte er später zwei Söhne haben. Brian, der 1947 geboren wurde, ist ebenfalls schriftstellerisch tätig. Bruce, der 1951 zur Welt kam und 1993 an HIV verstarb, war Aktivist im Kampf für die Rechte von Schwulen und Lesben.

Sein Studium brach Herbert bald wieder ab und begann in Seattle erneut für unterschiedliche Tageszeitungen als Journalist zu arbeiten. Nebenbei schrieb er erste Kurzgeschichten, die unter anderem im "Esquire" sowie unterschiedlichen Pulpmagazinen veröffentlicht wurden.

Nach sechs Jahren der Recherche und des Schreibens versuchte Herbert zuerst erfolglos, einen Verleger für das erste Buch seines Romanzyklus "Dune" zu finden. Zwanzig Absagen später erschien es endlich 1965, im hauptsächlich auf Ratgeberpublikationen spezialisierten Verlagshaus "Chilton", und leitete den Beginn seiner literarischen Karriere ein. Unter anderem erhielt das Werk im selben Jahr den begehrten Nebula Award und 1966 den renommierten Hugo Award. In dem Science-Fiction-Roman verknüpft Herbert Probleme der Ökologie mit philosophischen, politischen und sozialen Fragestellungen. Den spezifischen Stil, aus der Perspektive verschiedener Handlungsträger die Erzählung zu verknüpfen, nutzte er auch in seinen späteren Veröffentlichungen.

Ab 1970 unterrichtete Herbert selbst als Dozent an der Universität von Washington. 1972 war er schließlich Vollzeitschriftsteller geworden und hatte seit etwa 1980 neben seinem Wohnsitz im Bundesstaat Washington auch ein Haus auf Hawaii. Bis in die 1980er Jahre hinein war Herbert höchst produktiv. Es entstanden viele seiner bekanntesten Werke, darunter auch einige in Zusammenarbeit mit Bill Ransom. Nachdem seine Frau Beverly 1984 gestorben war, heiratete er Ende 1985 seine dritte Frau, Theresa Shackleford. Doch nur wenige Monate später starb Herbert im Alter von 65 Jahren an den Folgen eines Bauchspeicheldrüsenkrebses in Madison. 2006 wurde er postum in die Science Fiction Hall of Fame aufgenommen.

Herberts bekanntestes Werk ist der in viele Sprachen übersetzte und aus sechs Büchern bestehende Romanzyklus "Dune" (dt. "Der Wüstenplanet"). Der erste Band wurde mit zahlreichen wichtigen Preisen ausgezeichnet und erstmals 1984 von David Lynch für die Kinoleinwand verfilmt. 2000 folgte ein Remake von John Harrison fürs Fernsehen. Die Teile des Romanzyklus sind:

Herbert arbeitete am siebten und letzten Band des Romanzyklus, als er verstarb. Aufzeichnungen zu diesem Roman und weitere Fragmente haben bereits als Vorlagen für eine Reihe von in der Vorgeschichte angesiedelten Romanen gedient, die von Herberts Sohn Brian Herbert in Zusammenarbeit mit Kevin J. Anderson geschrieben wurden. Die Vollendung des Romanzyklus haben jene beiden Autoren 2007 abgeschlossen. Der siebte Band wurde zweigeteilt publiziert:

Diese Romane stellen jedoch nach Ansicht vieler Fans eine Abkehr von Herberts eigener Darstellung komplexer Ideen und der Auseinandersetzung mit dem menschlichen Leben dar. Auch der Stil der neuen Bücher ist weniger dicht und intensiv; es finden sich vermehrt reine Abenteuerelemente. Unabhängig davon erschien 1985 von Herbert die Kurzgeschichte "The Road to Dune" (1985 dt. "Auf dem Wüstenplaneten"), ein Auszug aus dem fiktiven „Imperiumsführer“, einer Art Touristenführer. Der siebzehnseitige Text erschien 1990 exklusiv im Sammelband "Auge" mit Illustrationen von Jim Burns.

Der Caleban-Zyklus Herberts wird in zwei Kurzgeschichten und zwei Romanen behandelt.










</doc>
<doc id="1773" url="https://de.wikipedia.org/wiki?curid=1773" title="Leonardo Fibonacci">
Leonardo Fibonacci

Leonardo da Pisa, auch Fibonacci genannt (* um 1170 in Pisa; † nach 1240 ebenda), war Rechenmeister in Pisa und gilt als einer der bedeutendsten Mathematiker des Mittelalters. 

Auf seinen Reisen nach Afrika, Byzanz und Syrien machte er sich mit der arabischen Mathematik vertraut und verfasste mit den dabei gewonnenen Erkenntnissen das Rechenbuch "Liber ab(b)aci" im Jahre 1202 (Überarbeitung 1228). Bekannt ist daraus heute vor allem die nach ihm benannte Fibonacci-Folge, die im Zusammenhang mit dem Goldenen Schnitt steht.

Leonardo wird in den Handschriften als "Leonardus Pisanus", "Leonardus filius Bonacij", "Leonardus Pisanus de filiis Bonaccij" und "Leonardus Bigollus" bezeichnet. Bonaccio (von lat. "bonatius" „gütig, günstig, angenehm“) war der Großvatername, den Leonardos Vater Guglielmo wie auch dessen Brüder Alberto und Matteo als Patronym führten und der sich in Leonardos eigener Generation bereits zum Familiennamen verstetigt hatte. Aus "filius Bonacii" bzw. "figlio di Bonaccio" („Sohn des Bonaccio“) wurde im Italienischen dann durch Kontraktion die in Leonardos eigener Zeit noch nicht bezeugte Zunamensform "Fibonacci", unter der Leonardo vor allem wegen der seit Édouard Lucas nach ihm benannten Fibonacci-Folge heute noch am besten bekannt ist. Der Beiname "Bigollus", jeweils nur im Genitiv in der Form "Leonardi Bigolli" belegt und wohl darum in der Literatur zuweilen irrtümlich als Patronym "Leonardo Bigolli" wiedergegeben, ist in seiner Deutung nicht sicher, wird aber meist im Sinne von „der Weitgereiste“ interpretiert.

Über die Biographie Leonardos ist nur wenig bekannt, die meisten Angaben gehen zurück auf den Widmungsprolog seines Rechenbuchs "Liber abbaci" und auf ein Dokument der Kommune von Siena.

Leonardo wurde in der zweiten Hälfte des 12. Jahrhunderts als einer von mindestens zwei Söhnen des Guglielmo Bonacci in Pisa geboren, wo sich die Familie bis auf den Urgroßvater Leonardos, einen Anfang des 12. Jahrhunderts verstorbenen Bonito, zurückverfolgen lässt. Als der Vater von der Stadt als Notar in die Niederlassung der Pisaner Kaufmannschaft im algerischen Bougie, dem heutigen Bejaia, entsandt wurde – wofür man als Datum um 1192 annimmt –, ließ er auch Leonardo zu sich kommen, um ihn dort im Rechnen unterrichten zu lassen. Leonardo lernte dort das Rechnen mit den "novem figurae indorum" („neun Ziffern der Inder“), unseren heutigen (indo-arabischen) Ziffern, die den arabischen Mathematikern in Bagdad seit der zweiten Hälfte des 8. Jahrhunderts aus Indien bekannt geworden waren und im 12. Jahrhundert von Spanien (Toledo) aus durch lateinische Übersetzungen aus den arabischen Schriften des Al-Chwarizmi auch im Westen allmählich verbreitet wurden.

Leonardo war in den neunziger Jahren des 12. Jahrhunderts folglich nicht der erste Lateiner, der das Rechnen mit den neuen Ziffern erlernte, aber er erwarb in Bougie offenbar mathematische Grundlagen, die er höher schätzte als alles, was er bei weiteren Studien an Handelsorten „in Ägypten, Syrien, Griechenland, Sizilien und Südfrankreich“ noch erlernte. Als von ihm vergleichsweise gering, „gleichsam als Irrtum“ eingeschätzte Methoden nennt er besonders den „Algorismus“, worunter das elementare Ziffernrechnen nach Al-Chwarizmi verstanden wurde, von dem sich Leonardos eigene Mathematik eigentlich nur durch die anspruchsvollere Anwendung der Verfahren unterschied, sowie eine von ihm als „Bögen des Pythagoras“ umschriebene Methode: gemeint ist das abazistische Rechnen auf dem im 10. bis 12. Jahrhundert gebräuchlich gewesenen, zu Leonardos Zeit wieder weitgehend außer Gebrauch gekommenen Gerbertschen Abakus, der als Erfindung des Pythagoras galt und auf dem im Unterschied zu den späteren mittelalterlichen Rechenbrettern mit bezifferten Rechensteinen (beziffert mit arabischen Ghubar-Ziffern 1-9) gerechnet wurde.

Seine Reisen scheinen ihn gegen Ende des 12. Jahrhunderts auch nach Konstantinopel geführt zu haben, da er von einer der Aufgaben in seinem "Liber abbaci" angibt, dass sie ihm in Konstantinopel von einem dorther stammenden, hochgelehrten Meister namens „Muscus“ ("a peritissimo magistro musco constantinopolitano", ed. Boncompagni, vol. I, p. 249) vorgelegt worden sei. Ein Mathematiker dieses Namens, vermutlich Μόσκος, ist anderweitig nicht bekannt.

Nachdem Leonardo, wie er im Widmungsprolog ausführt, seine Kenntnisse weiter vertieft hatte, teils durch eigene Beobachtungen und teils durch Studium der Geometrie Euklids, legte er schließlich die „summa“ seiner mathematischen Kenntnisse in seinem Hauptwerk, dem "Liber abbaci" nieder. Der Titel ist am besten mit „Buch der Rechenkunst“ zu übersetzen, da die ursprüngliche, an das Rechenbrett gebundene Bedeutung von "ab(b)acus" sich in Italien erweitert hatte und zu Leonardos Zeit die allgemeine Bedeutung „Rechenkunst“ angenommen hatte. Die erste, heute nicht mehr erhaltene Fassung dieses Werks soll bereits 1202 (oder 1201?) entstanden sein, allerdings ist dieses Datum nur aus dem Kolophon einer Handschrift der zweiten, einzigen erhaltenen Fassung bekannt. Zudem besteht bei den expliziten Datierungen von Leonardos Schriften generell die Schwierigkeit, dass das Jahr nach dem "mos pisanus" am 25. März des – aus Sicht gewöhnlicher Jahreszählung – vorausgegangenen Jahres begann, so dass von solchen Jahresangaben ein Jahr abzuziehen ist, sofern die Datierung nicht im letzten Jahresviertel (von Januar bis 24. März) erfolgte.

Von Leonardo sind noch einige weitere Werke erhalten: eine "Practica geometriae" von 1220 (1219?), gewidmet einem Freund und Lehrer Dominicus, die im 15. Jahrhundert von Cristoforo Gherardo di Dino auch ins Italienische übertragen wurde; ein "Liber quadratorum" von 1225 (1224?), der Friedrich II. gewidmet ist und erwähnt, dass dieser bereits ein Buch Leonardos gelesen habe, was man auf den "Liber abbaci" zu beziehen pflegt; ferner eine nicht datierte Schrift "Flos super solutionibus quarumdam questionum ad numerum et ad geometriam uel ad utrumque pertinentium", welche dem Kardinal Raniero Capocci von Viterbo gewidmet ist und Fragen behandelt, die Leonardo im Beisein Friedrichs II. von einem Magister Johannes aus Palermo vorgelegt worden sein sollen; und schließlich ein Brief an einen Magister Theodorus. Aus Leonardos Schriften geht hervor, dass er auch noch zwei weitere, heute nicht mehr erhaltene Schriften verfasste, ein kürzeres Rechenbuch und einen Kommentar zum zehnten Buch der Elemente Euklids.

Die zweite Fassung des "Liber abbaci" entstand dem Widmungsprolog zufolge für Michael Scotus († um 1236), nachdem dieser von Leonardo eine Abschrift des Werkes erbeten und Leonardo aus diesem Anlass einige Ergänzungen und Kürzungen vorgenommen hatte. Da Michael Scotus ab Herbst 1227 am Hof Friedrichs II. bezeugt ist, hat man 1227 auch als Entstehungsdatum für die erhaltene zweite Fassung des "Liber abbaci" angenommen, tatsächlich kann sie aber auch früher oder später entstanden sein, jedoch nicht vor 1220 (1219?), da sie bereits auf die "Practica geometriae" verweist.

Die letzte Erwähnung Leonardos findet sich in einem Dekret der Kommune von Pisa, das ihn als geachteten Magister Leonardus Bigollus für seine Verdienste als Steuerschätzer und Rechenmeister der Stadt würdigt und ihm für künftige Dienste dieser Art ein Jahresgehalt von zwanzig Pfund Pfennigen zuzüglich der bei solchen Beamten üblichen Naturalien gewährt. Der Herausgeber Bonaiini hatte das im Text nicht datierte Dokument auf 1241 datiert, allerdings ohne Angabe von Gründen. Falls die Datierung zutrifft, starb Leonardo nicht vor 1241 (wegen der Divergenz des "mos pisanus" in der Forschung manchmal auch „nicht vor 1240“ angegeben), so dass er, wenn man das Geburtsjahr um 1180 ansetzt, ein für die Zeit nicht unbeachtliches Alter von mindestens sechzig Jahren erreicht hätte und auch in diesem Alter von der Kommune noch für weitere Dienste vorgesehen gewesen wäre.

Der "Liber abbaci" legt den Schwerpunkt ausdrücklich mehr auf die Theorie als die Praxis ("magis ad theoricam spectat quam ad practicam") und geht tatsächlich in seinen Ansprüchen weit über alles hinaus, was dem lateinischen Mittelalter bis dahin bekannt geworden war oder bis zum 16. Jahrhundert noch bekannt wurde. Die Besonderheit liegt dabei nicht so sehr in der Schwierigkeit der Aufgaben, sondern in der mathematischen Intelligenz des Autors, seiner Durchdringung der Materie und dem besonderen Wert, den er darauf legt, Lösungen und Regeln nicht nur vorzuführen, sondern auch mathematisch zu beweisen. Der "Liber abbaci" ist in 15 capitula unterteilt:


Aus dem Widmungsprolog des "Liber abbaci", ed. B. Boncompagni, vol. I, Rom 1857, S. 1:
Aus dem "Constitutum usus pisanae civitatis", Zitat und Übersetzung nach H. Lüneburg: "Leonardo Pisanos Liber abbaci". In: "Der Mathematik-Unterricht" 42,3 (1996), S. 31–42, S. 31:
In Pisa befindet sich im Kreuzgang des historischen Friedhofes Camposanto eine Statue Leonardos, welche die Inschrift: "A Leonardo Fibonacci Insigne Matematico Pisano del Secolo XII" trägt. Als Porträt ist die Darstellung ein Produkt künstlerischer Phantasie, da aus Leonardos eigener Zeit keine Abbildungen und keine Überlieferung über dessen Aussehen existiert.

Die Statue geht zurück auf die Initiative von zwei Mitgliedern der provisorischen Regierung des ehemaligen Großherzogtums Toskana, Bettino Ricasoli und Cosimo Ridolfi, die am 23. September 1859 ein Dekret zur Finanzierung der Statue herbeiführten. Beauftragt wurde der Florentiner Bildhauer Giovanni Paganucci, der das Werk 1863 vollendete. Die Statue wurde in Pisa auf dem Campo Santo aufgestellt, wo Grabmonumente Pisaner Bürger zusammen mit antiken Sarkophagen und neu hinzugefügten Kunstwerken seit dem Mittelalter ein einzigartiges Grab- und Gedenkensemble bilden.

Zur Zeit des Faschismus entschieden die Behörden in Pisa, die Statue Leonardos 1926 ebenso wie zwei Statuen anderer namhafter Bürger Pisas aus der sakralen Abgeschiedenheit des Campo Santo heraus an öffentlich besser sichtbare Standorte zu versetzen. Die Statue Leonardos wurde am südlichen Ende des Ponte di Mezzo aufgestellt. Während des Zweiten Weltkrieges wurde 1944 bei den Kämpfen um Pisa die Brücke zerstört und auch die Statue beschädigt, die zunächst an ihrem Standort verblieb, dann in einem Lager verwahrt wurde und zeitweise in Vergessenheit geriet. In den 1950er Jahren wurde sie wiederentdeckt, notdürftig restauriert und im Park Giardino Scotto am östlichen Eingang der Altstadt aufgestellt. Erst in den 1990er Jahren entschloss sich die pisanische Stadtverwaltung die Statue zu restaurieren und sie wieder an ihrem ursprünglichen Platz im Campo Santo aufstellen zu lassen.





</doc>
<doc id="1774" url="https://de.wikipedia.org/wiki?curid=1774" title="Fibonacci-Folge">
Fibonacci-Folge

Die Fibonacci-Folge ist die unendliche Folge von natürlichen Zahlen, die (ursprünglich) mit zweimal der Zahl 1 beginnt oder (häufig, in moderner Schreibweise) zusätzlich mit einer führenden Zahl 0 versehen ist. Im Anschluss ergibt jeweils die Summe zweier aufeinanderfolgender Zahlen die unmittelbar danach folgende Zahl:

Die darin enthaltenen Zahlen heißen Fibonacci-Zahlen. Benannt ist die Folge nach Leonardo Fibonacci, der damit im Jahr 1202 das Wachstum einer Kaninchenpopulation beschrieb. Die Folge war aber schon in der Antike sowohl den Griechen als auch den Indern bekannt.

Weitere Untersuchungen zeigten, dass die Fibonacci-Folge auch noch zahlreiche andere Wachstumsvorgänge der Pflanzen beschreibt. Es scheint, als sei sie eine Art Wachstumsmuster in der Natur.

Die Fibonacci-Zahlen weisen einige bemerkenswerte mathematische Besonderheiten auf:

Die Fibonacci-Folge formula_1 ist durch das rekursive Bildungsgesetz

mit den Anfangswerten

definiert. Das bedeutet in Worten:


Daraus ergibt sich:

Aus der Forderung, dass die Rekursion

auch für ganze Zahlen formula_6 gelten soll, erhält man eine eindeutige Fortsetzung auf den Index 0 und auf negative Indizes. Es gilt:

Die so erweiterte Fibonacci-Folge lautet dann

Darüber hinaus ist eine Verallgemeinerung der Fibonacci-Zahlen auf komplexe Zahlen, proendliche Zahlen und auf Vektorräume möglich.

Identitäten:

Teilbarkeit:

Reihen:

Es gibt noch zahlreiche weitere derartige Formeln.

Wie von Johannes Kepler festgestellt wurde, nähert sich der Quotient zweier aufeinander folgender Fibonacci-Zahlen dem Goldenen Schnitt formula_41 an. Dies folgt unmittelbar aus der Näherungsformel für große formula_42

Diese Quotienten zweier aufeinanderfolgender Fibonacci-Zahlen haben eine bemerkenswerte Kettenbruchdarstellung:

Da diese Quotienten im Grenzwert gegen den goldenen Schnitt konvergieren, lässt sich dieser als der unendliche Kettenbruch
darstellen.

Die Zahl formula_41 ist irrational. Das bedeutet, dass sie sich nicht durch ein Verhältnis zweier ganzer Zahlen darstellen lässt. Am besten lässt sich formula_41 durch Quotienten zweier aufeinanderfolgender Fibonacci-Zahlen approximieren. Dies gilt auch für verallgemeinerte Fibonaccifolgen, bei denen formula_48 und formula_49 beliebige natürliche Zahlen annehmen.

Das nach Edouard Zeckendorf benannte Zeckendorf-Theorem besagt, dass jede natürliche Zahl formula_9 eindeutig als Summe voneinander verschiedener, nicht direkt aufeinanderfolgender Fibonacci-Zahlen geschrieben werden kann. Das heißt, es gibt für jedes formula_51 eine eindeutige Darstellung der Form

Die entstehende Folge formula_56 von Nullen und Einsen wird Zeckendorf-Sequenz genannt. Da aufeinanderfolgende Fibonacci-Zahlen ausgeschlossen sind, können keine zwei Einsen in einer Zeckendorf-Sequenz unmittelbar hintereinander stehen.

Allgemeiner ist die verwandte Aussage, dass sich jede "ganze" Zahl "z" eindeutig als Summe verschiedener, nicht direkt aufeinanderfolgender "negaFibonacci"-Zahlen (formula_57 mit formula_58) darstellen lässt:
So wäre zum Beispiel formula_63 als Binärsequenz codice_1 darstellbar.

Das explizite Bildungsgesetz für die Glieder der Fibonacci-Folge wurde unabhängig voneinander von den französischen Mathematikern Abraham de Moivre im Jahr 1718 und Jacques Philippe Marie Binet im Jahr 1843 entdeckt. Dazwischen war sie aber auch den Mathematikern Leonhard Euler und Daniel Bernoulli bekannt, Letzterer lieferte 1728 auch den vermutlich ersten Beweis.

Die Fibonacci-Zahlen lassen sich direkt mittels
berechnen, wobei formula_65 die beiden Lösungen der charakteristischen Gleichung formula_66 sind und somit auch formula_67 und formula_68 gilt. Setzt man
ein, erhält man die explizite Formel von Moivre-Binet:

Bemerkenswert ist das Zusammenspiel zweier irrationaler Zahlen "φ" und "ψ," das zu einem ganzzahligen Ergebnis führt. Die Abbildung zeigt die beiden Teilfolgen mit "φ" und "ψ" sowie deren Differenz. Der Einfluss von "ψ" geht rasch gegen Null. Das kann man verwenden, um die Berechnung zu beschleunigen, indem man den Term ignoriert und das Ergebnis zur nächstgelegenen natürlichen Zahl rundet.

Einer der einfachsten Beweise gelingt induktiv. Wegen formula_72 und formula_73 ist der Induktionsanfang erfüllt. Angenommen die Formel gelte für alle Werte bis "n." Wir zeigen nun, dass sie dann notwendigerweise auch für "n"+1 gelten muss:
Dabei haben wir benutzt, dass formula_75 und formula_76 der charakteristischen Gleichung formula_77 bzw. formula_78 genügen.

Nach dem Prinzip der vollständigen Induktion muss nun die Formel für alle "n" gelten.

Die Formel von Binet kann mit Matrizenrechnung und dem Eigenwertproblem in der linearen Algebra hergeleitet werden mittels folgendem Ansatz:

Nun transformiert man die Matrix formula_80 in eine Diagonalmatrix formula_81 durch Betrachtung als Eigenwertproblem.

Es gilt formula_82, wobei formula_83 die Matrix der Eigenvektoren und formula_81 die Diagonalmatrix mit den Eigenwerten ist. Damit folgt:

formula_85

Eine andere Herleitungsmöglichkeit folgt aus der Theorie der linearen Differenzengleichungen:

Sei formula_86 eine geometrische Folge, so ergibt sich:

Wenn also formula_88 so gewählt wird, dass die charakteristische Gleichung formula_66 erfüllt ist (also formula_90 oder formula_91), wird formula_92, d. h., formula_93 erfüllt die Fibonacci-Rekursion mit dem Rekursionsanfang formula_94 und formula_95.

Die rekursive Folge formula_96, formula_97, formula_98 hat die explizite Darstellung formula_99. Ebenso formula_100, formula_101, formula_102.

Mit formula_103 und formula_104 genügt wegen der Superpositionseigenschaft auch jede Linearkombination formula_105 der Fibonacci-Rekursion formula_106. Mit Hilfe eines linearen Gleichungssystems ergibt sich formula_107 und formula_108, damit formula_109 und formula_110. Folglich ergibt sich explizit formula_111.

Für formula_112 ergibt sich formula_113 und formula_114, d. h. die klassische Lucas-Folge mit explizit formula_115.

Die erzeugende Funktion der Fibonacci-Zahlen ist
Die auf der linken Seite stehende Potenzreihe konvergiert für formula_117. Über die Partialbruchzerlegung erhält man wiederum die Formel von Moivre-Binet.

Durch Entwicklung der obigen Erzeugenden Funktion formula_118 in eine Potenzreihe um formula_119 ergibt sich durch Koeffizientenvergleich ein Zusammenhang zwischen den Fibonacci-Zahlen und den Binomialkoeffizienten. Dies gelingt durch Einsetzen des Polynoms formula_120 in die Potenzreihe für formula_121 mit formula_122 und somit formula_123.

Nach Multiplikation mit "z" ergibt sich formula_124, nach Umformen dieser Summe zu einer Binomialreihe.

Die letzte Summe kann mittels Umbenennung der Summationsindizes vereinfacht werden zu formula_125.

Koeffizientenvergleich liefert schließlich formula_126.

Alternativ ergibt sich über die Definition formula_127 die Darstellung

Die Fibonacci-Zahlen tauchen auch als Einträge der Potenzen der Matrix formula_129 auf:
Aus der Relation formula_131 ergibt sich beispielsweise die erste oben angegebene Formel für formula_132. formula_133 beschreibt zugleich die Summationsvorschrift der Fibonacci-Folge, denn ihr Produkt mit einem Paar aufeinanderfolgender Fibonacci-Zahlen (als Spaltenmatrix geschrieben) ergibt das nächste Paar; entsprechend erzeugt formula_134 das formula_25-te Paar aus dem Startpaar formula_136. Dies und die Tatsache, dass die Eigenwerte von formula_133 gerade der Goldene Schnitt und dessen Kehrwert (letzterer mit negativem Vorzeichen) sind, führen wieder auf die oben genannte Formel von Binet.

Für große Werte von "n" wird formula_138 in der Formel von Binet immer kleiner, da der Ausdruck in der Klammer vom Betrag kleiner als 1 ist. Deshalb erhält man die Näherungsformel

Der Absolutbetrag des Quotienten formula_140 ist für alle n kleiner als 0,5. Demnach beschreibt die Näherungsformel das exakte Ergebnis mit einem Fehler von weniger als 0,5. Durch Runden kommt man daher wieder zu einer exakten Formel:

mit der Gaußklammer formula_142.

Die klassische („kanonische“) Fibonacci-Folge ist durch drei Kriterien charakterisiert:

Jedes dieser Kriterien erlaubt eine Verallgemeinerung:




Viele Pflanzen weisen in der Anordnung ihrer Blätter (Phyllotaxis) und anderer Teile Spiralen auf, deren Anzahlen durch Fibonacci-Zahlen gegeben sind, wie beispielsweise bei den Früchten in Fruchtständen. Das ist dann der Fall, wenn der Winkel zwischen architektonisch benachbarten Blättern oder Früchten bezüglich der Pflanzenachse der Goldene Winkel ist. Hintergrund ist der Umstand, dass die rationalen Zahlen, die den zugrunde liegenden Goldenen Schnitt am besten approximieren, Brüche von aufeinanderfolgenden Fibonacci-Zahlen sind. Die Spiralen werden daher von Pflanzenelementen gebildet, deren Platznummern sich durch die Fibonacci-Zahl im Nenner unterscheiden und damit fast in die gleiche Richtung weisen. Durch diese spiralförmige Anordnung der Blätter um die Sprossachse erzielt die Pflanze die beste Lichtausbeute. Der Versatz der Blätter um das irrationale Verhältnis des Goldenen Winkels sorgt dafür, dass nie Perioden auftauchen, wie es z. B. bei 1/4 der Fall wäre (0° 90° 180° 270° | 0° 90° …). Dadurch wird der denkbar ungünstigste Fall vermieden, dass ein Blatt genau senkrecht über dem anderen steht und so die Blätter maximalen Schatten auf darunterliegenden Blättern erzeugen oder maximale ‚Lichtlücken‘ entstehen.

Beispielsweise tragen die Körbe der Silberdistel "(Carlina acaulis)" hunderte gleichgestaltiger Blüten, die in kleineren Körben in einer 21-zu-55-Stellung, in größeren Körben in 34-zu-89- und 55-zu-144-Stellung in den Korbboden eingefügt sind. Auch die Schuppen von Fichtenzapfen wie auch von Ananasfrüchten bilden im und gegen den Uhrzeigersinn Spiralen, deren Schuppenanzahl durch zwei aufeinanderfolgende Fibonaccizahlen gegeben ist.

Wissenschaftshistorisch sei hier auf das Buch "On Growth and Form" von D’Arcy Wentworth Thompson (1917) verwiesen.

Ein weiterer interessanter Aspekt ist, dass die Fibonacci-Folge die Ahnenmenge einer männlichen ("n" = 1) Honigbiene (Apis mellifera) beschreibt. Das erklärt sich dadurch, dass Bienendrohnen sich aus unbefruchteten Eiern entwickeln, die in ihrem Genom dem Erbgut der Mutter ("n" = 2) entsprechen, die wiederum zwei Eltern besitzt ("n" = 3) usw.

Die Anzahl der unverzweigten Fettsäuren (aliphatischen Monocarbonsäuren) mit verschieden vielen Doppelbindungen an verschiedenen Positionen als Funktion der Kettenlänge gehorcht der Fibonacci-Folge. Das folgt unter anderem daraus, dass (bis auf seltene Ausnahmen) bei Fettsäuren keine benachbarten Doppelbindungen auftreten. Speziell gibt es nur eine aliphatische Monocarbonsäure mit einem C-Atom: Ameisensäure, eine mit zwei C-Atomen: Essigsäure, zwei mit dreien: Propionsäure und Acrylsäure, usw. Bei 18 C-Atomen ergeben sich 2.584 Varianten (wovon Stearinsäure, Ölsäure, Linolsäure und Linolensäure vier Beispiele sind).

Ihre früheste Erwähnung findet sich unter dem Namen "maatraameru" („Berg der Kadenz“) in der "Chhandah-shāstra" („Kunst der Prosodie“) des Sanskrit-Grammatikers Pingala (um 450 v. Chr. oder nach anderer Datierung um 200 v. Chr.). In ausführlicherer Form behandelten später auch Virahanka (6. Jh.) und besonders dann Acharya Hemachandra (1089–1172) diese Zahlenfolge, um die rechnerische Möglichkeit der Bildung von Metren durch regelmäßige Verteilung kurzer und langer Silben zu beschreiben.

In der westlichen Welt war diese Reihe ebenfalls schon in der Antike Nikomachos von Gerasa (um 100 n. Chr.) bekannt. Sie ist aber mit dem Namen des italienischen Mathematikers Leonardo da Pisa, genannt Fibonacci ("„figlio di Bonacci“," Sohn des Bonacci), verbunden, der in seinem "Liber abbaci" („Buch der Rechenkunst“, Erstfassung von 1202 nicht erhalten, zweite Fassung von ca. 1227) diese Zahlenfolge mit dem Beispiel eines Kaninchenzüchters beschrieb, der herausfinden will, wie viele Kaninchenpaare innerhalb eines Jahres aus einem einzigen Paar entstehen, wenn jedes Paar ab dem zweiten Lebensmonat ein weiteres Paar pro Monat zur Welt bringt:
Fibonacci illustrierte diese Folge durch die einfache mathematische Modellierung des Wachstums einer Population von Kaninchen nach folgenden Regeln:


Fibonacci begann die Reihe, nicht ganz konsequent, nicht mit einem neugeborenen, sondern mit einem trächtigen Paar, das seinen Nachwuchs bereits im ersten Monat wirft, sodass im ersten Monat bereits 2 Paare zu zählen sind. In jedem Folgemonat kommt dann zu der Anzahl der Paare, die im Vormonat gelebt haben, eine Anzahl von neugeborenen Paaren hinzu, die gleich der Anzahl derjenigen Paare ist, die bereits im vorvergangenen Monat gelebt hatten, da der Nachwuchs des Vormonats noch zu jung ist, um jetzt schon seinerseits Nachwuchs zu werfen. Fibonacci führte den Sachverhalt für die zwölf Monate eines Jahres vor (2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377) und wies auf das Bildungsgesetz der Reihe durch Summierung jeweils zweier aufeinanderfolgender Reihenglieder (2+3=5, 3+5=8, 5+8=13 usw.) hin. Er merkte außerdem an, dass die Reihe sich nach diesem Prinzip für eine unendliche Zahl von Monaten fortsetzen lässt, was dann allerdings unsterbliche Kaninchen voraussetzt: "„et sic posses facere per ordinem de infinitis numeris mensibus.“" Weitere Beachtung hatte er dem Prinzip in seinen erhaltenen Werken nicht geschenkt.

Eine gerade erschienene mathematisch-historische Analyse zum Leben des Leonardo von Pisa, insbesondere zu seinem Aufenthalt in der nordafrikanischen Hafenstadt Bejaia (im heutigen Algerien), kam zu dem Schluss, dass der Hintergrund der Fibonacci-Folge gar nicht bei einem Modell der Vermehrung von Kaninchen zu suchen ist (was schon länger vermutet wurde), sondern vielmehr bei den Bienenzüchtern von Bejaia und ihrer Kenntnis des Bienenstammbaums zu finden ist. Zu Leonardos Zeit war Bejaia ein wichtiger Exporteur von Bienenwachs, worauf noch heute der französische Name der Stadt (Bougie, wie das frz. Wort für Kerze) hinweist.

Nachdem spätere Mathematiker wie Gabriel Lamé (1795–1870) die Entdeckung dieser Zahlenfolge für sich beansprucht hatten, brachten Édouard Lucas (1842–1891) und andere wieder in Erinnerung, dass der zu dieser Zeit älteste bekannte Beleg von Leonardo da Pisa stammte, und unter dem Namen „Fibonacci-Folge“ („suite de Fibonacci“, „Fibonacci sequence“, „successione di Fibonacci“) ist sie seither in den meisten westlichen Sprachen geläufig.


Die Fibonacci-Folge ist namensgebend für folgende Datenstrukturen, bei deren mathematischer Analyse sie auftritt.




</doc>
<doc id="1775" url="https://de.wikipedia.org/wiki?curid=1775" title="Faradayscher Käfig">
Faradayscher Käfig

Der faradaysche Käfig (auch Faradaykäfig) ist eine allseitig geschlossene Hülle aus einem elektrischen Leiter (z. B. Drahtgeflecht oder Blech), die als elektrische Abschirmung wirkt. Bei äußeren statischen oder quasistatischen elektrischen Feldern bleibt der innere Bereich infolge der Influenz feldfrei. Bei zeitlich veränderlichen Vorgängen wie elektromagnetischen Wellen beruht die Abschirmwirkung auf den sich in der leitfähigen Hülle ausbildenden Wirbelströmen, die dem äußeren elektromagnetischen Feld entgegenwirken. Statische oder langsam variierende Magnetfelder (wie das Erdmagnetfeld) werden durch einen faradayschen Käfig nicht abgeschirmt.

Der Begriff geht auf den englischen Physiker Michael Faraday (1791–1867) zurück. Die Quantität der Schirmwirkung wird über die Schirmdämpfung (zum Beispiel einer Abschirmung) erfasst.

Ein faradayscher Käfig führt unter anderem zu folgenden Effekten:

Die Abschirmung von elektrostatischen bzw. quasistationären elektrischen Feldern beruht auf der Wirkung der Influenz. Wird eine elektrisch leitende Hülle, beispielsweise eine Hohlkugel, in ein von außen aufgebrachtes elektrostatisches Feld "E" gebracht, kommt es aufgrund der Kraftwirkung formula_1 auf die in der Hülle frei beweglichen Ladungen "Q" zu räumlichen Umverteilung der Ladungen an der Oberfläche, bis die tangential auf der Oberfläche stehende elektrische äußere Feldkomponente null wird und damit ein Ausgleich gefunden ist. Dadurch entspringt bzw. endet im statischen Fall der elektrische Fluss an der Oberfläche der Hülle, womit das Innere der Hülle feldfrei bleibt. Diese Schirmwirkung ist nicht an eine bestimmte Form der Hülle gebunden und tritt bei beliebig geformten Hohlkörpern auf, sofern sie elektrisch leitfähig sind.

Die Dämpfung ist bei einer komplett geschlossenen leitenden Hülle im statischen Fall ideal und unendlich groß, bei quasistationären Feldern ist dies mit guter Näherung erfüllt. Mit Hilfe des gaußschen Gesetzes lässt sich für die Normalkomponenten des elektrischen Feldes im leeren Außenraum unmittelbar über der Hülle:

und im Innenraum zu

bestimmen, mit formula_4 der Flächenladungsdichte und formula_5 der Dielektrizitätskonstante.

Die leitfähige Hülle ist eine Äquipotentialfläche, die im Sprachgebrauch elektrische Wand genannt wird. Wesentlich ist, dass die Schirmwirkung nur gegen äußere elektrische Felder wirkt. Ein elektrischer Fluss, der durch eine von der Hülle isolierte Ladungsansammlung im Inneren der Hülle entspringt, die davon getrennte Ladung mit umgekehrtem Vorzeichen befindet sich im Außenbereich, führt so auch im Außenraum zu einem elektrischen Feld. Besteht hingegen eine elektrische Verbindung zwischen den ladungstragenden Innenbereichen und der Hülle, werden die elektrische Ladungen zur Oberfläche verschoben und der innere Bereich bleibt feldfrei. Dieses Prinzip der Ladungsverschiebung wird bei manchen Hochspannungsgeneratoren wie dem Van-de-Graaff-Generator zur Ladungsspeicherung und zur Erzeugung von hohen elektrischen Spannungen genutzt.

Bei nicht zu hochfrequenten Wechselfeldern kann ein faradayscher Käfig statt aus einer geschlossenen Leiter-Wand auch aus einem Käfig aus Leiterstäben, -drähten oder aus einem Blech mit kleinen Öffnungen bestehen. Die Schirmdämpfung hängt mit der Maschenweite zusammen, die etwa 1/10 der Wellenlänge nicht überschreiten sollte.

Ein idealer faradayscher Käfig schirmt auch hochfrequente Wechselfelder ab, weil auf der Oberfläche des Käfigs Wirbelströme induziert werden, die dem äußeren Feld nach der Lenzschen Regel entgegenwirken. Die Schirmwirkung ist in diesem Fall aber nicht ideal, sondern durch endliche Schirmdämpfungen und Eindringtiefen in den Schirm gekennzeichnet.

Faradaysche Käfige aus nicht-ferromagnetischem Metall schirmen aufgrund ihrer endlichen Leitfähigkeit dann hochfrequente Wechselfelder ab, wenn die Metallschicht deutlich stärker als die Eindringtiefe der induzierten Ströme ist. 

Schlitze führen zur Unterbrechung der Induktionsströme im Schirm. Elektromagnetische Wellen durchdringen den Schirm vergleichsweise gut, wenn Schlitze im Schirm parallel zur Magnetfeldkomponente der Welle liegen. Die Schirmdämpfung lässt mit zunehmender Apertur nach und wird gering, wenn die Wellenlänge der ankommenden elektromagnetischen Welle in der Größenordnung der Schlitzabmessungen liegt.

Faradaysche Käfige werden häufig dort angewandt, wo Einflüsse von äußeren elektrischen oder elektromagnetischen Feldern die Funktionsweise eines Gerätes negativ beeinflussen können oder wo innere elektromagnetische Felder nicht nach außen gelangen sollen. Beispielsweise wird er zur Abschirmung von Messinstrumenten, elektrischen Leitungen oder Messräumen, z. B. vor Sendern, verwendet. Der faradaysche Käfig ist dann z. B. das Gehäuse aus einem leitenden Material oder eine dünne metallische Folie, mit welcher der zu schützende Raum umhüllt ist.

Die Abschirmung kann ganze Räume umfassen, zum Beispiel geschirmte Räume als elektromagnetisch beruhigte Prüfumgebung in EMV-Laboren (Absorberhalle).

Das Prinzip des faradayschen Käfigs findet auch Anwendung beim Blitzschutz für Gebäude. Hier ist er durch eine grobe Struktur aus Blitzableitern und geerdeten Gebäudeteilen angenähert.

Auch Autos und Flugzeuge mit einer leitfähigen Hülle wirken wie faradaysche Käfige. Elektromagnetische Felder, deren Wellenlänge im Vergleich zu den elektrisch offenen Fugen und Spalten der Karosserie klein sind, werden allerdings nicht effizient geschirmt. Dies erklärt, warum im Auto Mobilfunk-Empfang möglich ist.

Kleine, oft aus Weißblech gefertigte Abschirmkäfige findet man um die Hochfrequenz-Baugruppen in elektronischen Geräten (Mobiltelefone, Radio- und Fernseh-Tuner, drahtlose Babyfone usw.).

Der Mikrowellenherd ist ein Beispiel für einen faradayschen Käfig, bei dem gewissermaßen Innen und Außen vertauscht sind. Der metallene Garraum schirmt die Umgebung von der starken Mikrowellenstrahlung innerhalb des Ofens ab. An der Tür befindet sich meist eine Resonanzdichtung, die nur für eine ganz bestimmte Wellenlänge wirksam ist.

Das metallische Gehäuse eines Magnetrons sorgt dafür, dass das hochenergetische elektromagnetische Feld im Inneren des Magnetrons bleibt. Ein geringer Teil des Feldes wird durch den Antennenanschluss nach außen geleitet.

Die vereinfachte, zweidimensionale Ausführung eines faradayschen Käfigs wird als Koronaring bezeichnet und wird im Hochspannungsbereich beispielsweise bei Isolatoren und Überspannungsableitern (Varistoren) eingesetzt. Im Ringinneren ist die Feldstärke sehr gering, deshalb kann dort auch an Ecken und Spitzen wie dem Montagegeschirr keine verlustbringende Feldemission auftreten.


</doc>
<doc id="1777" url="https://de.wikipedia.org/wiki?curid=1777" title="Flora (Begriffsklärung)">
Flora (Begriffsklärung)

Mit Flora (von lateinisch "flos" = „Blüte“) werden bezeichnet:


Zeitschriften:

Gelände und Gebäude:

Berge:

Orte:

in den Vereinigten Staaten:

Personen:

Sonstiges:

Siehe auch:


</doc>
<doc id="1778" url="https://de.wikipedia.org/wiki?curid=1778" title="Fieber">
Fieber

Das Fieber ist ein Zustand erhöhter Körperkerntemperatur, der meistens als Begleiterscheinung der Abwehr gegen eindringende Viren, lebende Mikroorganismen oder andere als fremd erkannte Stoffe auftritt, sowie seltener im Rahmen anders verursachter Entzündungsvorgänge, Traumata oder als Begleiterscheinung bei manchen Tumoren vorkommt. Die hiermit verbundenen Vorgänge beruhen auf komplexen physiologischen Reaktionen, zu denen unter anderem eine pyrogenvermittelte, vom Organismus aktiv herbeigeführte, geregelte und begrenzte Erhöhung der Körperkerntemperatur gehört. Letztere entsteht infolge einer Temperatursollwertänderung im hypothalamischen Wärmeregulationszentrum. Fieber ist damit ein Beispiel für eine regulierte Änderung der Homöostase.

Das heutige Wort „Fieber“ geht auf das mittelhochdeutsche ' zurück, dies von althochdeutsch ', nachweisbar seit dem 9. Jahrhundert und entlehnt aus lateinisch "," eigentlich „Hitze“; auch die "Pyrexie" von altgriechisch , "," „Fieber haben“, von griechisch , "," „brennende Hitze“, „Fieber“; vergleiche "," „Feuer“.

Entgegen einem häufig vorkommenden Missverständnis ist Fieber in den meisten Fällen nicht Ursache von Krankheit, sondern Teil der Antwort des Organismus auf Krankheit. Die häufige Praxis, Fieber ab einer bestimmten Höhe symptomatisch zu senken, um vermeintlichen Schaden vom Kranken abzuwenden, entspricht oft nicht dem Forschungsstand der Fieberphysiologie. Anstelle einer routinemäßigen Senkung des Fiebers ab einer bestimmten Temperatur wird empfohlen, eine symptomatische Therapie an der Befindlichkeit und an sekundären Risiken des Fiebers für bestimmte Patientengruppen zu orientieren.

Fieber unterscheidet sich grundsätzlich von ungeregelten Zuständen der Hyperthermie. Bei diesen sind keine Pyrogene beteiligt, weshalb eine medikamentöse antipyretische Therapie auch wirkungslos bleibt. Die Temperatur bleibt dabei erhöht, obwohl der Organismus an der Grenze seiner gegenregulatorischen Möglichkeiten versucht, seine Temperatur zu senken. Solche Überhitzung kann bei überstarker Erwärmung durch die Umgebung und/oder im Rahmen kräftiger körperlicher Bewegung vorkommen, ferner selten bei einer gestörten Temperaturregulation im Rahmen neurologischer Krankheiten oder bei der malignen Hyperthermie.

Fieber ist einer der häufigsten Beratungsanlässe in einer allgemeinmedizinischen oder pädiatrischen Praxis.

Die Fähigkeit mehrzelliger Organismen, fieberartige Reaktionen im Rahmen der angeborenen Immunantwort zu bilden, ist wahrscheinlich etwa 600 Millionen Jahre alt, in der Evolution hochkonserviert und überwiegend erfolgreich: Sie kommt bei Säugetieren, Reptilien, Amphibien, Fischen wie auch bei einigen Invertebraten (Wirbellose) bis hin zu den Insekten vor und führt in der Regel zu verbessertem Überleben oder Ausheilen verschiedener Infektionen. Gleich- und wechselwarme Tiere ändern im Rahmen einer Fieberreaktion ihr Verhalten, um die von der Fieberreaktion geforderte höhere Körpertemperatur zu erreichen (Aufsuchen wärmerer Umgebung etc.), gleichwarme Tiere haben darüber hinaus effizientere physiologische Möglichkeiten, ihre Körpertemperatur zu erhöhen. Dieselben Antipyretika, die bei gleichwarmen Tieren die physiologische Fieberreaktion hemmen, unterdrücken bei wechselwarmen Tieren z. B. das gezielte Aufsuchen eines wärmeren Ortes im Falle einer Infektion.

Das oberste thermoregulatorische Zentrum ist die Regio praeoptica des Hypothalamus: Hier laufen afferente Signale z. B. von Wärme- und Kälterezeptoren aus der Haut des ganzen Körpers zusammen. Die Temperaturinformationen aus der Peripherie werden mit den zentralen Temperaturinformationen verglichen und integriert; es resultiert eine von hier gesteuerte thermoregulatorische Antwort mit einem der beiden folgenden Ziele:

Ferner wird im Hypothalamus das Verhalten über die Wahrnehmung der Eigenwärme beeinflusst (Wechseln der Kleidung, Aufsuchen einer anderen Umgebung etc.). Bei einer normalen pyrogeninduzierten Fieberreaktion laufen diese Regulationsmechanismen genauso ab, sie sind also ebenfalls nur mit einer intakten Regio praeoptica des Hypothalamus möglich. Daher friert man bei fieberhaft ansteigender Temperatur und fühlt sich an Händen und Füßen kalt an. Demgegenüber ist einem warm bis hin zum Schwitzen, wenn die Temperatur nach dem Fieber (oder bei Gabe eines fiebersenkenden Medikamentes) wieder sinkt.

In der Regio praeoptica des Hypothalamus finden sich verschiedene Neurone: Etwa 30 % sind wärmesensitiv (das heißt, sie feuern schneller, wenn die Temperatur steigt), über 60 % reagieren nicht auf Temperaturänderungen und weniger als fünf Prozent sind kältesensitiv. Es wird vermutet, dass der sogenannte Temperatursollwert durch einen Vergleich der Neuronenaktivität der temperaturinsensitiven Neurone mit den wärmesensitiven Neuronen entsteht. Insbesondere die Aktivität der kältesensitiven Neurone ist stark abhängig von excitatorischem und inhibitorischem Input benachbarter Neurone, während die wärmesensitiven Neurone vor allem Input aus der Peripherie bekommen. Die wärmesensitiven Neurone werden also ab einer bestimmten Temperatur aktiver und lösen im Endeffekt eine Regulation aus, die den Körper zu mehr Wärmeabgabe bringt.

Diese wärmesensitiven Neurone können durch sogenannte Pyrogene gehemmt werden, wodurch dann das normale regulatorische Gleichgewicht im Thermoregulationszentrum verschoben wird. Diese Pyrogene gehören teilweise zu den Akute-Phase-Proteinen, die im Rahmen einer Entzündung vorkommen. Eine Vorstellung über die Wirkungszusammenhänge der verschiedenen Pyrogene gewann man vor allem durch tierexperimentelle Fiebererzeugung vor allem mit gespritzten Lipopolysacchariden (Bestandteile aus der Wand gramnegativer Bakterien). Dieses exogene Pyrogen führt vor allem in Monozyten, vermittelt unter anderem durch den CD14-Rezeptor, zu einer vermehrten Bildung von endogenen Pyrogenen, und zwar beginnend für Tumornekrosefaktor (TNF), Interleukin-8 und Spuren von Interleukin-1 und etwas später für deutliche Mengen von Interleukin-6. Letzteres korreliert am besten mit dem Fieberverlauf selbst. Diese Bildung endogener Pyrogene in durch Lipopolysaccharide angeregten Monozyten läuft bei 42 °C (also einer Temperatur, die knapp über der natürlichen Fiebergrenze liegt) etwas langsamer (und für TNF und Interleukin-8 zeitlich begrenzter) als bei 37 °C. Tumornekrosefaktor kann je nach Kontext auch eine fieberbegrenzende Eigenschaft haben. Wenn im Experiment Lipopolysaccharide als exogenes oder Interleukin-1β als endogenes Pyrogen gespritzt werden, resultiert ein uniformer, zweigipfliger Fieberanstieg. Ein erster Fiebergipfel beginnt rasch und dauert 30–60 Minuten. Er wird dadurch hervorgerufen, dass das Interleukin-1β über seinen Interleukin-1-Rezeptor die Neutrale Sphingomyelinase aktiviert, welche die Bildung des löslichen C2-Ceramides katalysiert. Ceradmid hemmt die wärmesensitiven Neurone. Es gab auch die Hypothese, dass dieser erste Fieberanstieg durch den Vagusnerv vermittelt werde, diesbezügliche Versuche erbrachten aber uneinheitliche Ergebnisse.

Gleichzeitig regt das Interleukin-1β die vermehrte Transkription der Cyclooxygenase-2 zunächst in den Makrophagen an, diese bildet vermehrt Prostaglandine, vor allem auch Prostaglandin E2, welches über die zirkumventrikulären Organe in den Hypothalamus gelangt und den Beginn des zweiten Fieberanstieges bewirkt. Dann wird die Cyclooxygenase-2 in den Endothelzellen des Hypothalamus selbst angeregt, welche zentral zu einer erhöhten Prostaglandin-E-Bildung führt. Das entstehende Prostaglandin-E kann in das Gehirn gelangen und induziert über seinen EP3-Rezeptor dann letztlich einen längerdauernden Fieberanstieg mit einem Maximum ungefähr drei Stunden nach dem Auftreten des Interleukin-1β, ebenfalls über die Hemmung wärmesensitiver Neurone. Hierdurch werden wärmeabgebende Prozesse (periphere Gefäßerweiterung, Schwitzen etc.) gehemmt und ferner die Hemmung der wärmesensitiven Neurone auf die kältesensitiven Neurone aufgehoben. Dies führt dann zur Wärmebildung bis hin zum Schüttelfrost. Alles in allem resultiert ein stereotyper und reproduzierbarer zweigipfliger Fieberanstieg, bis jeweils das neue regulatorische Gleichgewicht hergestellt ist. Fieber ist also insgesamt das Ergebnis einer fein abgestimmten Kommunikation des Immunsystems des Organismus mit seinem Nervensystem.

Bei einer akuten Fieberreaktion steigt die menschliche Körpertemperatur (insbesondere bei Kindern) schnell bis zu Werten zwischen 40 und 41,4 °C an, jedoch fast nie darüber hinaus, unabhängig von der Fieberursache oder dem Ort der Temperaturmessung. Der Körper muss also unter normalen Bedingungen in der Lage sein, eine Fieberreaktion regulatorisch wirksam zu begrenzen, bevor sie durch sich selbst gefährlich wird. Wenn dies nicht der Fall wäre, hätte sich das Phänomen der Fieberreaktion nicht evolutionär durchsetzen können. Allerdings sind die Vorgänge der Fieberentstehung viel länger erforscht und daher ist über sie mehr bekannt als über die Vorgänge der Fieberbegrenzung durch den Organismus selbst.

Der Körper kann mit Hilfe einer Reihe endogener Antipyrogene seine Fieberreaktion begrenzen. Hierzu gehören:

Regulatoren auf Zytokinebene

Prostaglandinderivate

Neurotransmitter

Hormone

Vor einer Denaturierung von Zellproteinen, z. B. bei erhöhter Temperatur, schützen sich Zellen durch die Hitzeschock-Antwort. Diese ist ein evolutionär uralter und hochkonservierter Prozess, der in allen Lebewesen bis hin zu den Bakterien vorkommt. Die dabei gebildeten Hitzeschockproteine haben vielfältige Funktionen, eine der Hauptaufgaben besteht dabei in der Erleichterung der korrekten Faltung denaturierter Proteine. Diese Funktion trägt wesentlich zum Zellüberleben unter Stressbedingungen bei. Die Gene für die Hitzeschockproteine haben sich die ganze Evolution hindurch erhalten, obwohl neue Möglichkeiten für die höherentwickelten Organismen hinzugekommen sind, mit Stressoren durch die Umwelt umzugehen. Die Beziehung zwischen der evolutionär alten Hitzeschock-Antwort und der evolutionär jüngeren Fieberreaktion kann als ein Beispiel dafür angesehen werden, wie neuere Prozesse früher entwickelte Prozesse benutzen. Beispiele für die komplexen Zusammenhänge zwischen Fieber und Hitzeschockantwort sind:


Viele Funktionen der neutrophilen Granulozyten, der Makrophagen und der Lymphozyten, die für die Infektabwehr wichtig sind, wie z. B. Beweglichkeit, Phagozytosefähigkeit, Radikalbildung, Vermehrung, Antikörperbildung usw. sind bei Temperaturen von 38 bis 41 °C verstärkt beobachtbar und nehmen bei Temperaturen über 41 °C wieder ab.

Für die meisten Infekte – vom einfachen Schnupfen bis hin zur lebensgefährlichen Sepsis – zeigt sich, dass fiebersenkende Maßnahmen den Krankheitsverlauf meistens komplikationsreicher machen und verlängern können. Dies gilt sowohl innerhalb klinischer Studien als auch in (tier-)experimentellen Settings, für virale, bakterielle und parasitäre Erkrankungen. Einige Beispiele sind in der nachfolgenden Tabelle aufgeführt:

Es gibt auch Studien, die keinen krankheitsverlängernden Effekt fiebersenkender Maßnahmen bei Infektionskrankheiten feststellen konnten. Aber verkürzend auf eine Infektionserkrankung wirkt sich eine Fiebersenkung in der Regel nicht aus. Eine Fiebersenkung kann bei einigen Patientengruppen aber sekundäre Probleme abmildern. Solche Ergebnisse und klinische Erfahrungen sowie die zunehmenden Kenntnisse über die Fieberphysiologie stellen den routinemäßigen Gebrauch von Antipyretika bei Fieber z. B. auf Intensivstationen in Frage. Gefordert wird heute vielmehr eine an den individuellen Behandlungszielen orientierte Therapie; Temperatursenkung als Selbstzweck ist bei Fieber kein unbedingtes Behandlungsziel.

Fieberkrämpfe treten bei (1 %)–6 %–(14 %) (je nach Bevölkerungsgruppe) aller ein- bis fünfjährigen Kinder auf; die Mechanismen, warum sie auftreten, sind kaum bekannt. Man vermutet, dass betroffene Kinder eine komplex vererbte Anlage für Fieberkrämpfe haben. Eine zurzeit diesbezüglich verfolgte Hypothese ist, dass es sich bei dieser Anlage um Mutationen eines anfallshemmenden GABA-Rezeptors handeln könnte, der temperaturabhängige Eigenschaften aufweist. Im Gegensatz zu einer auch in Lehrbüchern oft geäußerten Vermutung verhindern Antipyretika nicht signifikant ein Fieberkrampfrezidiv. Endogene Pyrogene können die Krampfschwelle des Gehirnes senken. Dies sind zum Beispiel Tumornekrosefaktor-alpha, Interleukin-1 beta und Interleukin-6, die über die Stimulierung der Cyclooxygenase-2 mit nachfolgender Prostaglandin-E2-Erhöhung zu Fieber führen. Eine Fiebersenkung hemmt nur die Cyclooxygenase-2, nicht aber die Ausschüttung dieser Pyrogene. Eine erhöhte Temperatur selber wiederum kann aber die Ausschüttung dieser Pyrogene hemmen. Eventuell kann auch hierdurch begründet sein, warum Fiebersenkung Fieberkrämpfe nicht verhindert.

Patienten mit Epilepsie müssen von solchen mit Fieberkrämpfen unterschieden werden. Da es viele verschiedene Epilepsien gibt, ist der Einfluss von Fieber und erhöhter Temperatur auf die Anfallsaktivität unterschiedlich: Sie kann erhöht werden oder gleich bleiben. In manchen Fällen kann die Anfallsaktivität durch Fieber aber auch vorübergehend abnehmen.

Wiederholte Fieberepisoden im ersten Lebensjahr (die zumeist aufgrund von Luftwegsinfekten auftreten) gehen mit einer höheren Prävalenz von früh begonnenem, nichtallergischem Asthma einher. Allerdings treten allergische Sensibilisierungen und später begonnenes Asthma nach häufigeren Fieberepisoden im ersten Lebensjahr seltener auf. Wichtig scheint zu sein, dass die fieberhaften Episoden auftreten, bevor eine allergische Sensibilisierung eingetreten ist. Es scheinen nur Fieberepisoden zwischen dem siebenten und zwölften Lebensmonat vor atopischer Veranlagung zu schützen, wichtig ist ferner eine ausreichende Fieberhöhe > 39 °C. Luftwegsinfekte im ersten Lebensjahr im Allgemeinen scheinen dagegen die Asthmahäufigkeit eher zu erhöhen (siehe z. B.). In diesen Studien wurde aber zumeist nicht der Einfluss von Antibiotika und antipyretischen Maßnahmen z. B. durch Paracetamol berücksichtigt; letzteres hat einen asthmabegünstigenden Effekt. Kinder aus Familien mit anthroposophischem Lebensstil erhalten unter anderem weniger Antibiotika und Antipyretika und haben seltener Asthma und Allergien.

Seit Krebsdiagnostik und -behandlung im 19. Jahrhundert eine Wissenschaft wurde, wurden immer wieder seltene Fälle mit „unerklärlichen“ Spontanheilungen berichtet. Vielen dieser Fälle ist eine hochfieberhafte Erkrankung vorausgegangen. Dies wurde vor der Chemotherapieära erfolgreich therapeutisch genutzt, z. B. mit der Fiebererzeugung durch ein injiziertes Bakterienextrakt. Während man in der Chemotherapie- und Bestrahlungsära ab den 1950er Jahren der Meinung war, dass der Körper keine eigenen Mittel habe, gegen Krebszellen zu kämpfen, wird der Zusammenhang zwischen Fieber und Krebsheilung seit den 1990er Jahren wieder systematischer untersucht. Unterdessen ist es unstrittig, dass Fieber, insbesondere wenn es hoch ist, unter Umständen das Immunsystem zu einer besseren Krebsabwehr bringen kann. In der praktischen Onkologie müssen solche Überlegungen mit dem Ziel verbunden werden, unangenehme Situationen für den Patienten zu lindern.

Da Krebserkrankungen eine länger schlummernde Erkrankung sind, ist dies auch im Vorfeld einer manifesten Krebserkrankung möglich, also präventiv. So erklärt sich, dass in der Vorgeschichte von Krebspatienten seltener Episoden mit fieberhaften Infekten zu finden sind. Dies konnte zum Beispiel deutlich für das Melanomrisiko gezeigt werden.

Fieber tritt immer im Rahmen einer komplexen körperlichen Entzündungsreaktion auf, die unterschiedlich ausgeprägt sein kann. Die Gesamtsymptomatik ist immer von der Grunderkrankung mitgeprägt, daher fällt es schwer, einzelne Symptome in jedem Fall dem Fieber zuzurechnen. Häufig kommen jedoch folgende Symptome zusammen mit fieberhaften Erkrankungen vor:

Der Verlauf der Fieberkurve (graphische Darstellung der Fiebertemperatur in Abhängigkeit von der Zeit) kann Hinweise auf die Fieberursache (z. B. Krankheitserreger) geben, allerdings kann man sich für eine Diagnose nicht alleine darauf verlassen. Traditionell wurden folgende Fiebermuster in diagnostisch brauchbare Gruppen zusammengefasst (nach):


Mit der Hand kann man die Temperatur von Stirn und Rumpf grob abschätzen. Zudem kann man durch Fühlen an Händen und Füßen mitbeurteilen, ob der Patient friert (Wärmekonzentration beim Temperaturanstieg) oder ob ihm warm ist (die Wärme wird vom Körper wieder verteilt, die Temperatur wird dann nicht mehr schnell steigen). 

Eltern können durch das Fühlen der Temperatur recht sicher (höheres) Fieber bei ihren Kindern ausschließen. Wenn sie den Verdacht auf Fieber haben, sollten sie die Temperatur dennoch messen.

Die Körpertemperatur kann mit verschiedenen Messgeräten und an verschiedenen Stellen gemessen werden.

Traditionell wurde mit Quecksilberthermometern gemessen. Wegen des enthaltenen Quecksilbers und der Glasbauweise geht von beschädigten Thermometern jedoch eine Gesundheitsgefahr aus. Seit April 2009 ist der Vertrieb von Quecksilberthermometern mit Ausnahme des wissenschaftlichen und medizinischen Bereichs innerhalb der EU verboten. Zunehmend wird Quecksilber durch nicht-toxisches Gallium ersetzt. Es handelt sich um Spitzenwert-Thermometer, das heißt, der im Verlaufe der Messung höchste Wert verbleibt in der Anzeige. Vor erneuter Messung ist die Metallsäule deshalb herunterzuschütteln.

Solche analogen Thermometer besitzen gegenüber modernen digitalen Thermometern den Vorteil, ohne elektrischen Strom auszukommen. Digitalthermometer weisen dafür eine höhere Bruchfestigkeit auf, ermöglichen eine schnellere Messung und bieten häufig eine Speicherfunktion zur Anzeige früherer Messergebnisse. Durch ein akustisches Signal am Ende des Messvorgangs und die einfache Ablesbarkeit sind sie zudem einfacher zu benutzen.
Zunehmende Verbreitung findet die pyrometrische Messung der Infrarotabstrahlung, meist mit Ohr-Thermometern. Diese ist wegen der hohen Messgeschwindigkeit vor allem für die Messung bei Kindern beliebt, findet aber auch zunehmend generelle Verwendung in Arztpraxen und Krankenhäusern. Moderne Digitalthermometer brauchen oft nur noch 60 Sekunden und signalisieren, dass der Messvorgang abgeschlossen ist.
Digitale Ohrthermometer brauchen sogar oft nur wenige Sekunden, um die Messung durchzuführen.

Preislich liegen analoge und digitale Thermometer mit kleineren Abweichungen ungefähr gleichauf. Ohrthermometer sind je nach Modell um den Faktor 10 bis 40 teurer. Ein Kostenfaktor, der bei Ohrthermometern zusätzlich zu berücksichtigen ist, sind die auswechselbaren Kunststoffschalen, die den direkten Hautkontakt mit dem Gerät vermeiden sollen.

Die Körpertemperatur kann sublingual (im Mund), rektal (im After), aurikular (im Ohr), vaginal (in der Scheide), inguinal (in der Leiste) oder axillar (in der Achselhöhle) gemessen werden, wobei der rektal gemessene Wert der Körperkerntemperatur am nächsten ist. Orientierend ist eine Messung auch an der Stirn möglich. Mittels Infrarotmessgeräten ist das, z. B. in der Seuchenkontrolle, auch über Distanz möglich. Die rektale Messung ist – insbesondere bei Säuglingen und Kleinkindern bis vier Jahren – am zuverlässigsten, dabei ist die gemessene Temperatur im Vergleich am höchsten. Die Temperatur unter der Zunge liegt etwa 0,3–0,5 °C niedriger, die unter den Achseln um etwa 0,5 °C und ist relativ unzuverlässig.

Bei der Messung im Ohr wird pyrometrisch, d. h. anhand der temperaturabhängigen Infrarotabstrahlung, die Temperatur des Trommelfelles gemessen. Diese Messmethode ist schnell und prinzipiell genau, liefert jedoch bei Fehlbedienung durch falsche Winkelung und Verlegung des Gehörganges durch Cerumen falsch-niedrige Werte. Modernere Geräte bieten technische Möglichkeiten, die dies erkennen sollen.

Um die Messung nicht durch Abkühlung zu verfälschen, sollte das Messgerät vorher auf annähernd Körpertemperatur erwärmt werden. Bei hochwertigen Ohrthermometern wird die Spitze vor der Messung elektrisch auf 37 Grad erwärmt. Bei Messung im Mund sollte man innerhalb von 15 Minuten keine kühlen Speisen oder Getränke eingenommen haben.

In der Intensivmedizin wird die Temperatur häufig über einen Blasenkatheter mit Thermistor oder über einen Thermistor-Katheter in einer Arterie (der außerdem zur Messung des Herzminutenvolumens dient) gemessen. Mund und Achseln sind zu unzuverlässig.

Bei Fieber ist der Flüssigkeitsbedarf gesteigert, deshalb ist hier besonders auf eine ausreichende Flüssigkeitszufuhr zu achten. In der ersten Phase (siehe Symptome), in der vielfach auch Schüttelfrost empfunden wird, sollte Wärmeverlust des Körpers vermieden werden. Fiebersenkung durch Wärmeableitung, z. B. Wadenwickel, ist i. d. R. nur sinnvoll bei zusätzlicher Senkung des Sollwertes durch geeignete Medikamente. Kühlende Maßnahmen sind zudem sinnvoll bei extrem hohen Temperaturen, dann werden z. B. Eisbeutel in den Leisten platziert. Ein Mensch mit Fieber muss nicht unbedingt Bettruhe einhalten, da es bislang keinen Nachweis eines positiven Effektes der Bettruhe gibt. Körperliche Schonung, also Vermeidung von körperlichen und geistigen Überanstrengungen, ist empfehlenswert. Sollte Schwindel auftreten, ist die Verkehrstüchtigkeit eingeschränkt.

Unter „fiebersenkender Therapie“ versteht man Behandlungen zur Senkung fiebriger Körpertemperaturen. Es gibt verschiedene Indikationen für eine fiebersenkende Therapie. Vor allem ein reduziertes subjektives Wohlbefinden bei Fieber spricht für den Einsatz einer fiebersenkenden Therapie, wobei fiebersenkende Arzneimittel oft zusätzlich auch analgetisch wirken. Aber auch die Vermeidung unerwünschter metabolischer Effekte bei Fieber, wie z. B. Dehydratation oder auch unerwünschter kardiovaskulärer Effekte bei Fieber, z. B. Tachykardie, sind Indikationen. Speziell Kinder und ältere Menschen sind empfindlich gegenüber hohem Fieber; bei Kleinkindern können Fieberkrämpfe auftreten, insbesondere nach schnellem Fieberanstieg.

Bevor man eine fiebersenkende Therapie einsetzt, sollte man allerdings auch Argumente bedenken, die gegen den Einsatz einer fiebersenkenden Therapie sprechen. So verliert man das Fieber als diagnostischen Parameter, wodurch eine Verzögerung von therapeutischen Entscheidungen theoretisch denkbar ist.

Fiebersenkende Medikamente (Antipyretika) sind z. B. Acetylsalicylsäure, Ibuprofen, Paracetamol oder Metamizol. Die naturheilkundlich verwendete Weidenrinde enthält Salicin, das im Körper zu Salicylsäure verstoffwechselt wird und ähnlich wie Acetylsalicylsäure wirkt. Behandlung durch Ableitung von Körperwärme, wie z. B. Wadenwickel, Rumpf-Reibebad, absteigendes Wannenbad oder Irrigator (Einläufe) werden komplementärmedizinisch verwendet. Auch intensivmedizinisch wird im Bedarfsfall durch Wärmeableitung behandelt, dann meist mit Hilfe von mit Eiswasser gefüllten Beuteln, die z. B. in der Leiste platziert werden. Dabei findet im Gegensatz zur medikamentösen Fiebersenkung keine Normalisierung des Temperatursollwertes statt, so dass der Körper versucht, der externen Kühlung entgegenzusteuern, was mit einem hohen Energieverbrauch einhergeht. Deshalb sind diese Maßnahmen nur sinnvoll, wenn auch medikamentös behandelt wird.

Nach Meinung von Anhängern komplementärer Verfahren eignet sich auch eine Erhöhung der Temperatur zur Fieberbekämpfung. Dabei werden vor allem ansteigende Fußbäder, Tees und Sauna empfohlen. Einen Wirksamkeitsnachweis für diese Maßnahmen gibt es nicht; insbesondere beim Saunieren besteht die Gefahr eines lebensbedrohlichen Temperaturanstiegs.

Bei bekanntem (oder wahrscheinlichem) Erreger kann das Fieber ursächlich behandelt werden:
Eine Behandlung mit Antibiotika erfolgt bei einem bakteriell bedingten Fieber. Wird das Fieber von Pilzen verursacht, helfen Antimykotika; bei manchen Virusinfektionen können Virostatika eingesetzt werden.




</doc>
<doc id="1780" url="https://de.wikipedia.org/wiki?curid=1780" title="Flüchtigkeit">
Flüchtigkeit

Flüchtigkeit (auch Volatilität oder Verdunstungszahl) ist eine dimensionslose relative Kennzahl, die 
die Verdunstung eines Lösungsmittels beschreibt.

Per definitionem wird die Flüchtigkeit angegeben als Verhältnis des Dampfdrucks des betrachteten Stoffs zum Dampfdruck des leicht flüchtigen Bezugsstoffs Diethylether (dieser bei 20 °C und 65 ±5 % relativer Luftfeuchtigkeit):

In Deutschland wird die Verdunstungszahl (VD) nach DIN 53170 bestimmt. Dabei wird die Zeit, in der ein Stoff komplett verdunstet (Verdunstungszeit = VDZ) mit der Zeit in Relation gesetzt, die Diethylether zum Verdunsten benötigt. 

Eine hohe Verdunstungszahl bedeutet relativ langsames Verdunsten, also eine geringe Flüchtigkeit.
Eine kleine Verdunstungszahl bedeutet schnelleres Verdunsten, also eine relativ hohe Flüchtigkeit.

In den USA wird die evaporation rate (E) über die Zeit und in Bezug auf Butylacetat bestimmt.

mit formula_4 = Zeit, bis zu der 90 % der Probe verdunstet ist.



</doc>
<doc id="1782" url="https://de.wikipedia.org/wiki?curid=1782" title="Fremdwort">
Fremdwort

Fremdwörter sind Wörter, die aus anderen Sprachen vor so wenig Zeit übernommen wurden, dass sie hinsichtlich Lautstand, Betonung, Flexion, Wortbildung oder Schreibung der Zielsprache noch so unangepasst sind, dass sie (im Gegensatz zum integrierteren Lehnwort) als „fremd“ empfunden werden können.

In der modernen Sprachwissenschaft ist die Unterscheidung zwischen „Fremd-“ und „Lehnwörtern“ unüblich, da es viele Zweifelsfälle gibt. Wie auch in vielen anderen Sprachen – vgl. frz. ' und engl. ' – wird allgemein nur von „Entlehnungen“ bzw. „Lehnwörtern“ gesprochen.

Die Quantitative Linguistik modelliert den Prozess der Übernahme von Fremd- und Lehnwörtern mit Hilfe des Sprachwandelgesetzes (Piotrowski-Gesetzes). Die Entlehnung geschieht, wie sich immer wieder zeigt, im Sinne bestimmter Gesetze. Dasselbe gilt für das Fremdwortspektrum, das eine Übersicht gibt, aus welchen Sprachen wie viele Wörter übernommen wurden.

Latein verbreitete sich durch Lehnwörter wie "Straße", "Frucht", "Sichel", "Koch" erstmals im germanischen Sprachbereich, als das römische Reich zwischen dem 1. Jahrhundert v. Chr. und dem 6. Jahrhundert n. Chr. große Teile Europas beherrschte. Die Begriffe drangen vor der zweiten Lautverschiebung in die deutsche Sprache ein und wurden von ihr erfasst und umgeformt (z. B. "Ziegel" aus "tēgula", "Pfeffer" aus "piper").

Auch nach dem Zusammenbruch des römischen Imperiums und nach der zweiten Lautverschiebung kamen lateinische Ausdrücke, jetzt schon stärker als Fremdwörter (Latinismen) empfunden, ins Deutsche:

Seit dem Ende der Antike war Latein die Sprache der Wissenschaft. Griechisch begann erst mit der Renaissance wieder eine Rolle zu spielen.

In der Zeit der Entstehung der großen Handelsgesellschaften wurden im deutschsprachigen Raum kaufmännische Ausdrücke aus dem Italienischen eingebürgert (Konto, Saldo). Das Italienische prägte auch Kunst (Torso, Fresko) und Musik (forte, Tempobezeichnungen wie "andante").

Zur Zeit des Barocks und der Aufklärung war in Deutschland das Französische die Sprache der oberen Gesellschaftsschichten. Die Sprachpuristen Philipp von Zesen und Johann Heinrich Campe versuchten dem durch gekonnte Verdeutschungen entgegenzuwirken (z. B. Abstand [Distanz], Anschrift [Adresse], Augenblick [Moment], Beistrich [Komma], Bücherei [Bibliothek], Gesichtskreis [Horizont], Leidenschaft [Passion], Mundart [Dialekt], Nachruf [Nekrolog], Rechtschreibung [Orthographie], altertümlich [antik], herkömmlich [konventionell], Erdgeschoss [Parterre], Lehrgang [Kursus], Stelldichein [Rendezvous], tatsächlich [faktisch], Voraussage [Prophezeiung], Wust [Chaos]).

Viele derartige Neuschöpfungen haben sich, nicht zuletzt durch den Nationalismus des 19. Jahrhunderts, in der deutschen Alltagssprache durchsetzen können. Post und Bahn deutschten systematisch Wörter aus ihren Fachbereichen ein (Bahnsteig [Perron]; Umschlag [Kuvert], Einschreiben [recommandé]). Andere Länder sind damit noch weiter gegangen (z. B. die Türkei, in der so viele arabische Begriffe durch neugeschaffene türkische ersetzt wurden, dass die heutigen Türken die Osmanische Sprache nicht mehr verstehen). Neuere Versuche von Verdeutschungen (Nuance > Abschattung) sind wenig erfolgreich geblieben.

Bis heute ist ein Anteil der deutschen Fremdwörter französischen Ursprungs. Erst mit dem technischen und industriellen Siegeszug der USA, und seit im 20. Jahrhundert das Englische das Französische auch als Sprache der Diplomatie abzulösen begonnen hatte, ist der Strom französischer Ausdrücke ins Deutsche versiegt. Heute überwiegt die Übernahme von Wörtern aus dem Englischen, besonders dem amerikanischen (Meeting [Treffen], Computer [Rechner]).

Von den rund 140.000 Begriffen des heutigen Duden hat etwa jedes vierte fremdsprachliche Wurzeln. Jeweils etwa 3,5 Prozent stammen aus dem Englischen und dem Französischen. Jeweils etwa fünf bis sechs Prozent stammen aus dem Lateinischen und Griechischen. Ein fortlaufender Zeitungstext erreicht beispielsweise etwa 8 bis 9 Prozent Fremdwörter; werden nur Substantive, Adjektive und Verben gezählt, steigt der Anteil auf etwa 16 bis 17 Prozent. In Fachtexten mit vielen Termini technici liegt der Anteil meist wesentlich höher.

Auch deutsche Wörter werden in andere Sprachen übernommen und sind dort dann Fremdwörter.
Sprachwissenschaftliche Forschungen ergaben, dass bis zu 2500 Wörter der polnischen Sprache einen Ursprung in deutschen oder mittelhochdeutschen Wörtern haben könnten. Eine Auflistung aller bisher bekannten Lehnwörter findet sich auf der Homepage der Universität Oldenburg.

Für eine Ausschreibung mit dem Titel „Wörterwanderung“ sammelten im Sommer 2006 über 1600 Menschen aus 57 Ländern „ausgewanderte Wörter“ mit persönlichen Erlebnissen und Erläuterungen zu Bedeutungsverschiebungen in anderen Sprachen. Der Deutsche Sprachrat hat einige Ergebnisse inzwischen veröffentlicht (vgl. Limbach 2007).

Das deutsche „Hinterland“ steht beispielsweise in England für das Gebiet hinter einem Frachtschiffhafen, in Italien für die dicht besiedelte Gegend um Mailand und in Australien für Gebiete, die in einem größeren Abstand von der Küste liegen, jedoch im Gegensatz zu den riesigen Flächen im Landesinneren („Outback“).

Das dänische „habengut“ für Dinge, die man besitzt und mit sich tragen kann, kam mit deutschen Wandergesellen. Ein Teilnehmer aus der Schweiz berichtete von „schubladisieren“, abgeleitet von „Schublade“, in der französischsprachigen Schweiz im Sinne von zu den Akten legen, auf die lange Bank schieben bzw. nicht behandeln wollen. In der englischen Jugendsprache hat sich das Wort „uber“ – „über“ ohne Umlaut – als Steigerungsform von „super“ oder „mega“ herausgebildet. Das deutsche Wort „Zeitgeist“ wird dort sogar als Adjektiv „zeitgeisty“ verwendet. In Italien, so ein Einsender, hat sich das Wort „Realpolitik“ in der Zeit des Eisernen Vorhangs verbreitet, mit Willy Brandt assoziiert, heute zunehmend als „wahre, sinnvolle, lebensnahe Politik“ verstanden.

Die meisten Zusendungen nannten ins Englische, Russische, Ungarische und Polnische ausgewanderte Wörter. Auch Vietnamesisch, Koreanisch, Chinesisch, Japanisch, Arabisch, Persisch, Hebräisch, Brasilianisch, Spanisch, Finnisch, Estnisch, Afrikaans, Swahili, Wolof und Kirundi kommen vor.

Spitzenreiter ist nach wie vor das französische „vasistas“ für „Oberlicht“ oder „Kippfenster“, abgeleitet vom deutschen „Was ist das?“. An zweiter Stelle steht der „kindergarten“, den es im englischen, französischen, spanischen und japanischen Sprachgebrauch gibt, gefolgt vom russischen „butterbrot“, das ein belegtes Brot, allerdings auch ohne Butter, bezeichnet und dem Wort „kaputt“ im Englischen, Spanischen, Französischen und Russischen.

Immanuel Kant schrieb in "Kritik der reinen Vernunft" (B 402 Fußnote):

Ludwig Reiners erzählt eine Geschichte vom falschen Umgang mit Fremdwörtern:

Goethe gegen jene, die jeden Gebrauch eines Fremdworts ablehnen:
Wenn ein fremdes Volk einem Gebiet seine Kultur so flächendeckend aufzwingt, dass seine Sprache ganz in ihm zu herrschen beginnt, nehmen die verbleibenden örtlichen Ausdrücke den Charakter von Fremdwörtern an. Beispiele im Amerikanischen sind "toboggan" (Rutschschlitten) und "canoe" aus dem Indianischen oder "adobe" (an der Sonne getrockneter Lehmziegel), "lasso", "sierra", "desperado" aus der Zeit der spanischen Kolonisation.





</doc>
<doc id="1783" url="https://de.wikipedia.org/wiki?curid=1783" title="Felsit">
Felsit

Felsite sind allgemein helle magmatische oder metamorphe Gesteine, die hauptsächlich aus Quarz und Feldspat, also felsischen Mineralen, bestehen und eine Dichte kleiner als 3 g/cm³ haben.

Der Begriff "Felsit" ist eine Zusammenfassung der Wörter "Feldspat" und "Silikat", wobei mit Silikat hier Quarz gemeint ist. Das entsprechende Adjektiv ist felsisch. Da Quarz aus Siliziumdioxid (SiO) – chemisch inkorrekt oft als Kieselsäure bezeichnet – besteht, wird für Felsite nicht selten auch der Ausdruck saure Gesteine genutzt. Allerdings sind beide Bezeichnungen nicht vollsynonym, da sich "felsisch" auf den Mineralbestand und "sauer" auf die chemische Zusammensetzung, insbesondere des Magmas bzw. der Lava, aus dem das Gestein hervorgegangen ist, bezieht. Daher werden ausschließlich unmetamorphe magmatische Gesteine als "sauer" bezeichnet.

Das Adjektiv felsitisch steht darüber hinaus für ein feinkörniges bis dichtes und ohne besondere morphologische Kornausbildung gekennzeichnetes Gefüge felsischer Gesteine.

Felsische Glase, wie z. B. Obsidian, waren in Kulturen, in denen die Metallverarbeitung nicht bekannt war, bedeutende Rohstoffe für Werkzeuge und Waffen.



</doc>
<doc id="1784" url="https://de.wikipedia.org/wiki?curid=1784" title="Französische Sprache">
Französische Sprache

Französisch bzw. die französische Sprache (französisch ' [], ' []) gehört zu der romanischen Gruppe des italischen Zweigs der indogermanischen Sprachen. Damit ist diese Sprache unter anderem mit dem Italienischen, Rätoromanischen, Spanischen, Katalanischen, Portugiesischen und Rumänischen näher verwandt.

Französisch wird von etwa 80 Millionen Menschen als Muttersprache gesprochen und gilt als Weltsprache, da es von rund 274 Millionen Sprechern auf allen Kontinenten in über 50 Ländern gesprochen und weltweit oft als Fremdsprache gelernt wird. Französisch ist unter anderem Amtssprache in Frankreich und seinen Überseegebieten, in Kanada, Belgien, der Schweiz, in Luxemburg, im Aostatal, in Monaco, zahlreichen Ländern West- und Zentralafrikas sowie in Haiti, während es im arabischsprachigen Nordafrika und in Südostasien als Nebensprache weit verbreitet ist. Zudem ist es Amtssprache der Afrikanischen Union und der Organisation Amerikanischer Staaten, eine der Amtssprachen der Europäischen Union und eine der sechs Amtssprachen sowie neben Englisch Arbeitssprache der Vereinten Nationen, weiterhin Amtssprache des Weltpostvereins.
Auf die französische Sprache wirken normierend ein die "Académie française," die sogenannte "Loi Toubon" (ein Gesetz zum Schutz der französischen Sprache in Frankreich), das "Office québécois de la langue française" (eine Behörde in Québec), der "Service de la langue française" (eine belgische Institution zur Pflege der französischen Sprache) sowie die "Délégation générale à la langue française et aux langues de France".

Französisch wird in Europa vor allem in Frankreich selbst, aber auch in weiten Teilen Belgiens und Luxemburgs sowie in der Westschweiz und im Aostatal (Italien) gesprochen. In Monaco ist es zudem Amtssprache.

Nach der Eurostat-Studie „Die Europäer und ihre Sprachen“ "(Europeans and Languages)," die von Mai bis Juni 2005 in den damaligen 25 Mitgliedstaaten der Europäischen Union durchgeführt und im September 2005 veröffentlicht wurde, sprechen 11 % der EU-Bürger Französisch als Fremdsprache. Somit ist Französisch die am dritthäufigsten gelernte Fremdsprache Europas nach Englisch (34 %) und Deutsch (12 %). Französische Muttersprachler sind nach der Studie 12 % der EU-Bürger.

Neben Deutsch und Englisch ist Französisch die wichtigste Amts- und Arbeitssprache der Europäischen Union. Dies liegt unter anderem daran, dass Frankreich ein Gründungsmitglied der Organisation ist und sich viele EU-Institutionen in den hauptsächlich französischsprachigen Städten Brüssel, Straßburg und Luxemburg befinden. Französisch ist ebenfalls die traditionelle interne Arbeitssprache des Europäischen Gerichtshofs, des judikativen Organs der EU, und des Europarats. Allerdings schwindet innerhalb der EU aufgrund der wachsenden Relevanz des Englischen der Einfluss des Französischen auf die Arbeitswelt insgesamt stetig.

Die französische Sprache gilt als Weltsprache, sie wird auf allen Kontinenten der Erde verwendet und ist Amtssprache zahlreicher wichtiger internationaler Organisationen. Französisch gilt auch im globalisierten Zeitalter, in dem viele gesellschaftliche Bereiche von der englischen Sprache dominiert werden, immer noch als zweite Sprache der Diplomatie.

Französisch ist Amts- bzw. Verkehrssprache der Vereinten Nationen, der Afrikanischen Union, der Organisation Amerikanischer Staaten, des Weltpostvereins (UPU), von Interpol, des Internationalen Olympischen Komitees, der FIFA, der UEFA, der Lateinischen Union, von "Reporter ohne Grenzen", von "Ärzte ohne Grenzen", der Welthandelsorganisation, der Frankophonie und von vielen weiteren Institutionen und Organisationen.

Außer in den Ländern, in denen Französisch als Amtssprache gilt, wie z. B. in den Überseegebieten Frankreichs und Staaten Afrikas, der Antillen und Ozeaniens, wird es in vielen ehemaligen Kolonien Frankreichs und Belgiens als Verkehrs- und Kultursprache gesprochen. In den Staaten des Maghreb ist Französisch als Unterrichts- und Kultursprache erhalten geblieben.

In den Vereinigten Staaten gibt es französischsprachige Minderheiten vor allem in Maine und Louisiana, in geringerem Maße auch in New Hampshire und Vermont. Siehe auch: Französische Sprache in den Vereinigten Staaten.

In der kanadischen Provinz Québec spricht die überwiegende Mehrheit der Menschen Französisch als Muttersprache. Das Quebecer Französisch unterscheidet sich in Bezug auf Grammatik, Aussprache und Vokabular nur in geringem Maße vom Standardfranzösischen. Kleinere französischsprachige Minderheiten gibt es in Ontario, in Alberta, im Süden von Manitoba, im Norden und Südosten von New Brunswick/Nouveau-Brunswick (Neubraunschweig) und im Südwesten Nova Scotias (Neuschottland). Über 20 Prozent der Kanadier sind französische Muttersprachler, und Französisch ist neben dem Englischen gleichberechtigte Amtssprache (siehe auch: Frankophone Kanadier, Französisch in Kanada).

In Mauritius, Mauretanien, Laos, Kambodscha, Vietnam, dem Libanon, auf den Kanalinseln und in Andorra wird die französische Sprache in unterschiedlichem Maße als Bildungs- und Verwaltungssprache verwendet.

Französisch ist eine indogermanische Sprache und gehört zu den galloromanischen Sprachen, die in zwei Gruppen unterteilt werden: "Langues d’oïl" im nördlichen Frankreich und Belgien und "Langues d’oc" im Süden Frankreichs.

Hierbei ist der Status, was dabei Dialekt und was eigenständige Sprache ist, umstritten. Meistens spricht man von zwei Sprachen und deren jeweiligen Patois, den französischen Dialekten. Das Französische wird den "Langues d’oïl" zugeordnet und geht auf eine Mundart aus der Île de France zurück, der weiteren Umgebung der Hauptstadt Paris.

Sie grenzen sich von den "Langues d’oc" ab, die südlich des Flusses Loire verbreitet sind und eine eigene Sprache darstellen. Die Unterscheidung bezieht sich auf die Verwendung des Wortes "Ja" – "Oc" im Süden und "Oïl" im Norden. Zudem ist bei den "Langues d’oc", die zusammenfassend auch als Okzitanisch bezeichnet werden, der romanische Charakter stärker ausgeprägt, während bei den "Langues d’oïl" der Einfluss des fränkischen Adstrats zu erkennen ist.

Daneben gibt es das Franko-Provenzalische, das mitunter als selbständig gegenüber den anderen beiden gallo-romanischen Sprachen eingestuft wird. Da es allerdings keine Hochsprache entwickelt hat, wird es auch als Dialekt der "Langues d’oc" angesehen.

Der Gruppe der Oïl-Sprachen zugerechnet wird in der Regel auch das Jèrriais, eine Varietät auf der Kanalinsel Jersey, die sich durch die isolierte geographische Lage strukturell von den Festlandvarietäten unterscheidet.

In vielen afrikanischen Ländern wird Französisch als Zweitsprache verwendet. In diesen Ländern ist die Sprache häufig durch einen Akzent gefärbt.

Aus dem Französischen haben sich außerdem in den ehemaligen (vor allem karibischen) Kolonialgebieten verschiedene Französisch geprägte Kreolsprachen herausgebildet. Diese werden wegen ihrer vom Standardfranzösischen stark abweichenden Struktur jedoch meist als eigene Sprachgruppe und nicht als französische Varietät angesehen, wie z. B. Haitianisch.

Der Kreis der galloromanischen Sprachen:


In Gallien gab es drei große Völker mit eigenen Sprachen: die Kelten (die von den Römern Gallier genannt wurden), die Aquitanier im Südwesten und die Belger im Norden. Die Romanisierung erfolgte in zwei Schritten. Die lateinische Sprache gelangte mit der Einrichtung der römischen Provinz Gallia Narbonensis nach Südfrankreich, beginnend mit der Gründung der Festung "Aquae Sextiae" (120 v. Chr., heute Aix-en-Provence) und der Siedlung "Colonia Narbo Martius" (118 v. Chr., heute Narbonne). Ab 58 v. Chr. eroberte Gaius Iulius Caesar Nordgallien im Gallischen Krieg. Anschließend verbreitete sich das Lateinische im ganzen Land.

Innerhalb eines Zeitraums von vier Jahrhunderten setzte sich das Lateinische gegenüber den einheimischen festlandkeltischen (gallischen) Dialekten durch. Die Romanisierung geschah zunächst in Städten, Schulen und Verwaltungen, erst später in den abgelegenen Gebieten Galliens. Die keltischen Sprachen verschwanden nicht spurlos, sondern fanden mit schätzungsweise deutlich über 240 Wortstämmen Eingang in das gesprochene Vulgärlatein. Infolge der späteren Durchsetzung des Lateinischen in den ländlichen Regionen Galliens blieben vor allem Begriffe keltischer Herkunft aus der Landwirtschaft im Vulgärlatein erhalten, die auch im heutigen Französisch weiter verwendet werden, z. B. "aller" ‚gehen‘ (vgl. korn. "ello" ‚er gehe‘), "craindre" ‚fürchten‘ (vgl. bret. "kren" ‚Zittern‘), "mouton" ‚Schaf‘ (vgl. wal. "mollt" ‚Schafbock‘), "soc" ‚Pflugschar‘ (vgl. ir. "soc" ‚Schar, Saugrüssel‘) usw. Aber auch die Zählweise im Zwanziger-System (Vigesimalsystem), die das Standardfranzösische bis heute teilweise beibehält, wird häufig keltischen Einflüssen zugeschrieben (z. B. "soixante et onze": sechzig und elf = 71, "quatre-vingts": vier(mal)-zwanzig = 80). Einen solchen Einfluss einer untergehenden Sprache auf die sich durchsetzende Sprache nennt man Substrat.

Die gallorömische Bevölkerung im Norden Galliens kam mit germanischen Stämmen hauptsächlich durch Handelsbeziehungen in Kontakt, aber auch durch Söldnerdienste der Germanen in der römischen Armee. Bereits durch diese Kontakte fanden neben dem keltischen Substrat etliche Wörter germanischen Ursprungs Eingang in die französische Sprache. Ein solcher Vorgang einer friedlichen Beeinflussung durch nachbarschaftliche Beziehungen wird Adstrat genannt.

Einen stärkeren Einfluss übte später der westgermanische Stamm der Franken aus. Die Franken eroberten nach dem endgültigen Sieg über eine römische Restprovinz 486 n. Chr. durch Chlodwig I das Gebiet Galliens und prägten den französischen Wortschatz entscheidend mit. Um die 700 Wortstämme wurden von den Franken übernommen (z. B. "alise" ‚Mehl- oder Elsbeere‘ [vgl. nl. "els" ‚Erle‘, entsprechend dt. "Erle"], "blanc" ‚weiß‘, "danser" ‚tanzen‘ [vgl. ahd. "dansōn" ‚ziehen, dehnen‘], "écran" ‚Schirm‘ [vgl. dt. "Schrank"], "gris" ‚grau‘, "guerre" ‚Krieg‘ [vgl. mnl. "werre" ‚Ärgernis, Verwirrung‘, entsprech. dt. "wirr"], "jardin" ‚Garten‘, "lécher" ‚lecken‘, "saule" ‚Salweide‘), außerdem sind jene Ortsnamen in Nordfrankreich, die auf "-court, -ville" und "-vic" enden, meist germanisch-fränkischer Herkunft. Hierbei vollzog sich der geschichtlich bemerkenswerte Vorgang, dass sich die Franken sprachlich dem Vulgärlatein der besiegten gallo-romanischen Bevölkerung bis auf wenige verbleibende fränkische Einflüsse anpassten. Den Verbleib einiger Wörter aus der Sprache der Sieger in der sich durchsetzenden Sprache der Besiegten nennt man Superstrat.

Dieser Vorgang zog sich vom 5. bis zum 9. Jahrhundert hin. Noch Karl der Große (Krönung 800 n. Chr.) sprach als Muttersprache Fränkisch. Nur ganz im Norden Galliens konnte durch die fränkische Eroberung die germanische Sprachgrenze in das heutige Belgien hinein verschoben werden, die heute das Land in Flandern und Wallonien teilt. Die ungebrochene Dominanz des Vulgärlateinischen erklärt sich unter anderem aus dem nach wie vor hohen Prestige des Lateinischen, sowie aus der weitgehenden Übernahme der römischen Verwaltung. Auch die fränkische Lex Salica, in der sich römisches Rechtsdenken mit germanischen Zügen verbunden hat, begünstigte diese Entwicklung.
Die fränkischen Einflüsse schlugen sich nicht nur im Wortschatz nieder, sondern auch im Lautsystem (etwa das sogenannte "h aspiré", das „behauchte h“, das im Anlaut nicht gebunden wird), sowie in der Wortstellung (z. B. Voranstellung einiger Adjektive vor Nomen: "une grande maison" – „ein großes Haus“).

Zur Zeit Karls des Großen wich die Aussprache des Vulgärlateins erheblich von der Schreibweise ab. Auf Grund dessen veranlasste er – angeregt durch Alkuin – die karolingische Bildungsreform, wodurch Latein mit dem Ziel einer klassischen Aussprache erlernt wurde. Somit sollte die Missionierung der germanischen Bevölkerungsteile erleichtert werden, die vor allem von irischen Mönchen ausging, für die Latein eine Fremdsprache war. Darüber hinaus sollten eingetretene Unsicherheiten in der Aussprache bereinigt werden. Diese sich herausbildende Zweisprachigkeit führte zu erheblichen Schwierigkeiten bei der Verständigung des lateinisch sprechenden Klerus mit dem Volk. Auf dem Konzil von Tours 813 legte man eine einheitliche, dem Volk verständliche Sprache für Predigten in Kirchen fest. Latein blieb als Schriftsprache erhalten. Das Konzil von Tours erscheint als Geburtsstunde eines Bewusstseins davon, dass die gesprochene Sprache eine andere war als Latein.

Es bildeten sich verschiedene Dialekte heraus, die als Langues d’oïl zusammengefasst werden, in Angrenzung zu den südlichen Langues d'oc, benannt nach dem jeweiligen Wort für „Ja“ (im heutigen Französisch "oui"). Die ersten Dokumente, die der französischen Sprache zugeordnet werden, sind die Straßburger Eide, die 842 sowohl auf Altfranzösisch als auch auf Althochdeutsch verfasst wurden. Damit war auch die herkömmliche Diglossie, lateinisch zu schreiben, aber romanisch zu sprechen, zerstört. Im offiziellen Gebrauch blieb Latein aber noch jahrhundertelang dominant.

Unter den Kapetingern kristallisierte sich Paris und die Ile-de-France allmählich als politisches Zentrum Frankreichs heraus, wodurch der dortige Dialekt, das Franzische, zur Hochsprache reifte. Aufgrund der zunehmend zentralistischen Politik wurden die anderen Dialekte in den folgenden Jahrhunderten stark zurückgedrängt. Nachdem Wilhelm der Eroberer im Jahr 1066 den englischen Thron bestiegen hatte, wurde das normannische Französisch für zwei Jahrhunderte die Sprache des englischen Adels. In dieser Zeit wurde die englische Sprache sehr stark vom Französischen beeinflusst, das Französische aber auch vom Normannischen, was Wörter wie "crevette, quai" sowie die Himmelsrichtungen "sud, nord" usw. bezeugen.
Mit den Albigenserkreuzzügen im 13. Jahrhundert weitete Frankreich sein Territorium nach Süden aus (später folgte noch Korsika), die Kultur und Sprache des siegreichen Nordens wurden dem Süden oktroyiert. Das Okzitanische wurde zunächst aus dem offiziellen, im Laufe des 19. und 20. Jahrhunderts auch aus dem privaten Sprachgebrauch verdrängt; eine ähnliche Entwicklung widerfuhr dem Niederdeutschen (mit dem Hochdeutschen) in Norddeutschland. Dadurch schwand die Bedeutung der Langues d’oc (siehe oben) und des Frankoprovenzalischen, die vorher prestigeträchtige Kultur- und Literatursprachen waren.

Am 15. August 1539 erließ Franz I., der zweite französische König des Renaissancezeitalters, das Edikt von Villers-Cotterêts, mit der das Französische das Latein als Kanzleisprache ersetzt. Seither ist das Französische Amtssprache in Frankreich.

Sprachgeschichtlich spricht man im Zeitraum von 842 bis etwa 1340 von Altfranzösisch, "l’ancien français", und von 1340 bis etwa 1610 von Mittelfranzösisch, "le moyen français".

Im Jahre 1635 gründete Kardinal Richelieu die bis heute bestehende Académie française, die sich mit der „Vereinheitlichung und Pflege der französischen Sprache“ beschäftigt. Ab dem 17. Jahrhundert wird Französisch die "Lingua franca" des europäischen Adels, zunächst in Mitteleuropa, im 18. und 19. Jahrhundert auch in Osteuropa (Polen, Russland, Rumänien); zahlreiche Gallizismen gelangen in die Sprachen Europas. Jahrhundertelang wurde das Französische vom Adel und den Intellektuellen Europas gesprochen und galt als Sprache des Hofes und der Gebildeten. Auch heute noch zeugen Wörter wie Manieren, Noblesse, Kavalier, Etikette oder Konversation von der starken Anlehnung an französische Sitten und Gebräuche. In dieser Zeit entwickelte sich Frankreich zu einer Kolonialmacht und legte damit den Grundstein für die heutige Verbreitung der französischen Sprache außerhalb Europas und der französischen Kreolsprachen. Das 1830 aus den Vereinigten Niederlanden hervorgegangene Belgien erwarb ebenfalls eine Kolonie (Belgisch-Kongo) und führte dort die französische Sprache ein.

Im 18. Jahrhundert übernahm das Französische als Sprache des Adels die Domäne der internationalen Beziehungen und der Diplomatie (zuvor: Latein). Nach der Französischen Revolution und dem Scheitern der napoleonischen Großmachtspolitik, die Nationalismus und Freiheitsbewegungen der unterworfenen Völker hervorbrachte, ging die Verwendung des Französischen stark zurück; das aufstrebende Bürgertum etwa in Deutschland dachte national und sprach deutsch.

Durch den Aufstieg des englischsprachigen Vereinigten Königreichs im 19. Jahrhundert zur vorherrschenden Kolonialmacht und der englischsprachigen Vereinigten Staaten von Amerika im 20. Jahrhundert zur Supermacht entwickelte sich Englisch zur De-facto-Welthauptsprache und verdrängte das Französische aus weiten Teilen der Diplomatie, der Politik und des Handels. Dies zeigt sich etwa darin, dass der Friedensvertrag von Versailles von 1919 nicht mehr allein auf Französisch, sondern auch auf Englisch verfasst wurde.
Als Gegengewicht zum britischen Commonwealth baute Präsident Charles de Gaulle, dem an der Fortführung der Weltgeltung des Landes gelegen war, seit Beginn der Fünften Republik ein System von kulturellen Beziehungen zwischen Mutterland und ehemaligen Kolonien auf, unter anderem die "Organisation internationale de la Francophonie," den Weltverbund aller französischsprachiger Staaten.

Im Jahr 1977 erhielt in Kanada das Gesetz 101 Rechtskraft, das Französisch als einzige Amtssprache der Provinz Québec festlegt.

Mit der Dezentralisierung in den 1980er Jahren wurde den Regionalsprachen sowie den Dialekten in Frankreich mehr Freiraum zugestanden, wodurch diese ein Wiederaufleben erfuhren. 1994 wurde in Frankreich das nach dem Kulturminister benannte Loi Toubon erlassen: Ein Gesetz, das den Schutz der französischen Sprache sichern soll. Danach sollen Anglizismen im offiziellen Sprachgebrauch bewusst vermieden werden: Entsprechend heißt zum Beispiel der Computer "l'ordinateur" und der Walkman "le baladeur".

Laut einer demographischen Analyse der kanadischen Université Laval und der "Agence universitaire de la Francophonie" wird sich die Anzahl der französischsprachigen Menschen im Jahr 2025 auf 500 Millionen und im Jahr 2050 auf 650 Millionen belaufen. 2050 würde dies sieben Prozent der Weltbevölkerung ausmachen. Grund für diesen starken Anstieg ist hauptsächlich der rasche Bevölkerungszuwachs in arabischen und afrikanischen Staaten.

Aussprache und Sprachmelodie der französischen Sprache stellen viele Deutschsprachige vor Probleme, da das Französische mehrere Laute enthält, die im Deutschen unbekannt sind. Dazu zählen vor allem die Nasallaute.

Weitere Schwierigkeiten treten beim Erlernen der Schriftsprache auf, weil sich Schriftbild und die korrekte Aussprache seit Jahrhunderten auseinanderentwickelt haben, wobei allerdings die Zuordnung häufig recht einfachen Regeln folgt.

Das Französische kennt – je nach Zählung – 11 bis 16 Vokalphoneme; alle sind Monophthonge:
Die Oppositionen // – // und // – // sind im Verschwinden begriffen bzw. werden bereits von der Mehrzahl der Sprecher nicht mehr beachtet, in der Regel zugunsten des jeweils letztgenannten Phonems. Dadurch werden frühere Minimalpaare für Sprecher, die eines der beiden Phoneme nicht besitzen, zu Homophonen.

Die Nasalvokale tauchen immer dann auf, wenn nach dem Vokal ein „m“ oder „n“ und danach ein anderer Konsonant oder das Wortende folgt. In diesen Fällen dient das „m“ oder „n“ nur zur Anzeige der nasalen Aussprache des davor stehenden Vokals. Im Folgenden wird die nasale Aussprache durch die Tilde [  ̃] verdeutlicht:


Folgt dem „m“ bzw. „n“ derselbe Konsonant oder ein Vokal, dann tritt keine Nasalierung ein:

Ausnahmen: Bei den Präfixen "em-" und "en-" bleibt die Nasalisierung erhalten (z. B.: "emmancher, emménager, emmerder, emmitoufler, emmener, ennoblir, ennuyer"), bei "im-" gilt es nur selten "(immangeable immanquable)". Importe aus dem Englischen auf "-ing" "(faire du shopping)" und aus der Wissenschaftssprache auf "-um" (sprich ausnahmsweise: , z. B.: "uranium") nasalieren nicht.

Das Französische kennt 20 bis 21 Konsonantenphoneme, je nachdem ob das Phonem // gezählt wird. (Dies kommt fast ausschließlich in Fremdwörtern aus dem Englischen vor; von einigen Franzosen wird es als [] realisiert.):


Das Phonem // kommt fast ausschließlich in Fremdwörtern aus dem Englischen vor; von einigen Franzosen wird es als [] realisiert.

Aufgrund ihrer Geschichte, in der sich die Aussprache teilweise deutlich, die Schreibweise aber gar nicht geändert hat, hat die französische Sprache einen sehr großen Anteil stummer Zeichen. Insbesondere am Wortende können ganze Zeichengruppen stumm bleiben.

Ein "h" am Wortbeginn bleibt stumm. Es wird jedoch – vor allem aus sprachgeschichtlichen Gründen – zwischen zwei verschiedenen "h" unterschieden: Neben dem ursprünglich aus der lateinischen Schreibtradition stammenden "h" gibt es das "h aspiré" („gehauchtes "h"“), das erst im 16. Jahrhundert in der Aussprache verstummt ist. Dieses "h aspiré" hat bis heute indirekte Auswirkungen auf die Aussprache:


Ist der Konsonant am Wortende ein "-t" (außer nach "s"), ein grammatisch bedingtes "-s" oder "-x," einer dieser beiden Buchstaben in Ortsnamen, die Endung "-d" in den Verben auf "-dre," die finite Verbendung "-nt" oder ein deutsches "-g" in Ortsnamen, so wird er nicht ausgesprochen, und vor ihm werden auch alle etwa noch davorstehenden "p, t, c/k, b, d, " nicht ausgesprochen.


Ferner haben ein stummes "r"

Weiterhin haben "assez „genug“, "chez „bei“ und die Verbformen auf "-ez (2. P. Pl.) stummes "z". Die Adjektive auf (im Femininum) "-ille" haben im Maskulinum stummes "l" ("gentil [], gentille [] „freundlich“); bei der Liasion wird dieses wie doppeltes "l," also der Eselsbrücke zufolge wie das Femininum ausgesprochen ("gentilhomme" [] „Gentleman“).

Unregelmäßig fällt der Konsonant aus bei

In gewissen Wortverbindungen wird ein sonst stummer Endkonsonant ausgesprochen, wenn das nächste Wort mit Vokal beginnt (sog. Liaison). Dazu gehören verpflichtend unter anderem folgende Verbindungen:

Grundsätzlich kann außer vor Satzzeichen immer Liaison gemacht werden, aber nicht nach Infinitiven auf "-er" und wohl auch nicht nach Standesbezeichnungen auf "-er".

Auch ein "e" am Wortende ist zumeist stumm. Der in der Schrift davor stehende Konsonant ist zu artikulieren.


Die Apostrophierung (s. u.) ist ein durchaus ähnlicher Vorgang, erscheint aber im Schriftbild; beim weiblichen Artikel kann dort auch ein "a" ausfallen. Wo ein "h aspiré" die Apostrophierung verhindert, kann das "e" auch in der Aussprache nicht ausfallen, zumindest in der Hochsprache:


Bei den seltenen Konsonantenhäufungen ist oftmals auch der eine oder andere Buchstabe nur noch ein stummes Überbleibsel der Etymologie, weil er dem Wohlklang im Wege stand:


Bisweilen aber tauchen stumme Konsonanten am Wortende in der Aussprache wieder auf, wenn das folgende Wort mit einem Vokal beginnt. Es wird dann eine so genannte Liaison vorgenommen, also beide Wörter werden zusammenhängend ausgesprochen.


Da das "h" im Französischen nicht gesprochen wird, wird also auch bei vielen Wörtern, die mit "h" beginnen, eine Liaison vorgenommen.


Jedoch wird nicht immer eine Liaison durchgeführt. In manchen Fällen ist beides möglich.

Zudem gibt es eine ganze Reihe von Wörtern, die mit einem „aspirierten (gehauchten) h“ "(h aspiré)" beginnen. Dieses "h" bleibt zwar ebenso stumm, aber durch seine Existenz wird gewissermaßen die Autonomie des Wortes bewahrt, also keine Liaison vorgenommen.


Zur Aussprache gewisser Buchstaben bzw. Buchstabengruppen lassen sich zumeist schnell Regeln finden, die auch in den meisten Fällen Gültigkeit haben.

Französisch erhält seinen Klang nicht nur durch den Wegfall der Aussprache (Elision) „unnötiger“ Konsonanten, sondern auch durch das Auslassen von Vokalen, vor allem des , damit es zu keiner Häufung (Hiat) kommt; siehe oben. In bestimmten grammatischen Gegebenheiten wird dies auch von der Rechtschreibung nachvollzogen und durch einen Apostroph gekennzeichnet.


Außer wird in jeweils einem Fall auch bzw. weggelassen:

In der Umgangssprache wird auch das in "tu" gerne weggelassen (so bei "t’as" statt "tu as").

Vor einem "h aspiré" (siehe oben) kann nicht gekürzt werden.

Im Regelfall sind Homographe im Französischen auch Homophone, wobei es Ausnahmen gibt:

Französisch ist eine romanische Sprache, d. h., sie ist aus dem antiken Latein entstanden. Wie auch in vielen anderen Sprachen dieses Sprachzweigs, wie Spanisch oder Italienisch, zeichnet sich die französische Grammatik dadurch aus, dass die Deklinationen der Ursprungssprache getilgt wurden. An grammatischen Geschlechtern kennt das Französische zwei: Maskulinum und Femininum. Die Artikel, die verwendet werden, haben sich aus den lateinischen Demonstrativpronomen entwickelt. Außerdem hat sich die Flexion der Verben in mehreren Zeiten geändert, die nun mit Hilfsverb und Partizip konstruiert werden.

Der Sprachbau im Französischen ist wie folgt: Subjekt – Verb – Objekt. Diese Regel wird nur gebrochen, wenn das Objekt ein Pronomen ist. In diesem Fall lautet die Satzstellung: Subjekt – Objekt – Verb. Einige Archaismen, die ebenfalls typisch für romanische Sprachen sind, weichen von dieser Regel ab, vor allem im Nebensatz.

Allgemeine Erklärung der Menschenrechte:

Mit den typischen Fehlern, die beim Erlernen und Übersetzen der französischen Sprache auftreten können, beschäftigen sich folgende Artikel:





</doc>
<doc id="1785" url="https://de.wikipedia.org/wiki?curid=1785" title="Flut">
Flut

Als Flut wird das Steigen des Wasserstandes infolge der Gezeiten (Tide) bezeichnet. Dieser Zeitraum reicht von einem Niedrigwasser bis zum folgenden Hochwasser. An der Küste wird auch der Ausdruck auflaufendes Wasser zur Unterscheidung von binnenländischen Hochwässern oder Überflutungen benutzt. Das darauf folgende Sinken des Meeresspiegels wird Ebbe ("ablaufendes Wasser") genannt. Die Flut ist nicht mit dem Hochwasser zu verwechseln. Flut zeigt eine Bewegungsrichtung an, während Hochwasser den höchsten Stand des Wassers markiert.

Der "Flutstrom" kann in den Prielen des Wattenmeers beträchtliche Geschwindigkeiten (bis über 20 km/h) erreichen. Daher ist bei Wanderungen im Watt besondere Vorsicht geboten.

Die Höhe der Flut über dem Meeresspiegel ist nicht überall gleich. In der von den Ozeanen relativ abgeschnittenen Ostsee liegt sie bei 10 cm, auf der offenen Nordsee meist bei 100 cm. Der Tidenhub des Atlantiks liegt im Gebiet des mittelatlantischen Rückens bei nur 50 cm. An Küsten, Buchten und an Ästuaren, an denen der Wasserberg Engstellen passieren muss, liegt er weitaus höher. In den Ästuaren der Flüsse, beispielsweise der Elbe und Weser, werden bis zu 4 m, bei Sturmfluten bis zu 10 m erreicht. Der Tidenhub ist an Flüssen auch noch im Landesinneren zu spüren, sofern keine Sperrwerke bestehen und der Höhenunterschied gering ist (Tidefluss), z. B. Amazonas, Themse, Elbe, Weser, Wümme, Ems. Der Tidenhub am Ärmelkanal beträgt bis zu 12 m, an der Bay of Fundy von 15 bis zu 21 m. 

In Sturmfluten wird der Wasserstand durch die Kraft des Windes über das Normalmaß hinaus erhöht. Dadurch können Wasserstände erreicht werden, die 3 bis 5 Meter über dem normalen mittleren Tidehochwasser (MTHW) liegen. In der Vergangenheit haben Sturmfluten insbesondere an den Küsten der Nordsee beträchtliche Opfer gefordert, so z. B. 1962 in Hamburg.


</doc>
<doc id="1786" url="https://de.wikipedia.org/wiki?curid=1786" title="Abu-Nidal-Organisation">
Abu-Nidal-Organisation

Die Abu-Nidal-Organisation (ANO, auch bekannt unter dem Namen Fatah-Revolutionsrat) ist eine von Abu Nidal 1974 gegründete Abspaltung von der PLO, die sich für ein selbständiges Palästina einsetzt. Sie wurde zuerst von Saddam Hussein, dann von Hafiz al-Assad, dann von Muammar al-Gaddafi und vom Iran unterstützt.

Ihr werden zahlreiche Anschläge zur Last gelegt. Unter anderem wird die Gruppe für Anschläge auf die Flughäfen von Rom und Wien im Jahre 1985, bei denen 18 Menschen ums Leben kamen, und auf eine griechische Fähre bei Athen im Sommer 1988, wobei neun Menschen starben und etliche verletzt wurden, sowie einen Angriff auf Synagogen in Paris und Wien (Stadttempel) verantwortlich gemacht. Zudem ist sie für die Ermordung des Wiener Politikers Heinz Nittel verantwortlich. Die EU und die USA führen die Organisation auf ihrer Liste der Terrororganisationen. Darüber hinaus beging die Gruppe Auftragsmorde und tötete Fatah-Politiker, die für Verhandlungen mit Israel eintraten wie z. B. 1983 den Arafat-Vertrauten Issam Sartawi. Sie wurde aber, anders als andere palästinensische Organisationen, niemals zum Ziel israelischer Vergeltungsschläge. Dies und ihre offensichtliche Arbeit gegen die Interessen der PLO führte zu Spekulationen, die Gruppe sei zumindest in Teilen von israelischen Geheimdiensten unterwandert.

Im Jahr 2000 versuchte die Frau des Abu-Nidal-Finanzreferenten Samir N., die Ägypterin mit dem Spitznamen „Die Sanfte“, Geld von dessen Bankkonto abzuheben. Sie wurde wegen Terrorismus angeklagt, konnte aber nach Libyen entkommen. Die acht Millionen US-Dollar, die sich bereits seit Jahren auf jenem Wiener Bankkonto befinden, sind seither Gegenstand mehrerer Gerichtsprozesse, die beinahe zur Überweisung des Geldes an ehemalige Mitglieder geführt hätten. 2009 wurde ein entsprechendes Urteil jedoch vom Wiener Oberlandesgericht aufgehoben. Ein neuer Prozess soll klären, was mit dem Geld geschehen soll.



</doc>
<doc id="1787" url="https://de.wikipedia.org/wiki?curid=1787" title="Formant">
Formant

Formant von lateinisch "formare" = formen (eines Vokals): Damit bezeichnet man in der Akustik und Phonetik die Konzentration akustischer Energie in einem fixen (unveränderlichen) Frequenzbereich (Hz), unabhängig von der Frequenz des erzeugten Grundtons.<br>
Aufgrund der Resonanz- und Inteferenzeigenschaften eines Resonanzkörpers (Artikulationsraums) werden diese Frequenzbereiche gegenüber den übrigen verstärkt.

Ein Partial, oder einen zusammenhängenden Abschnitt von Partialen, die durch Resonanzverstärkung im Pegel angehoben werden, bezeichnet man als Formanten. - Hingegen bezeichnet man den Frequenzbereich, der für einen Vokal charakteristisch ist, als einen Formantbereich (auch: "Formantstrecke").

Im Kehlkopf oder z. B. im Mundstück eines Blasinstrumentes wird zunächst ein Grundton mit zahlreichen Obertönen produziert. Erst im Klangkörper eines Musikinstrumentes bzw. auf dem Weg zwischen Kehlkopf und Mundöffnung wird aus diesem Spektrum ein Teil der Harmonischen, also Partial- bzw. Teiltöne oder Obertöne und Rauschanteile, gedämpft, ein anderer Teil durch Resonanz relativ gegenüber der Grundfrequenz und gegenüber anderen Obertönen verstärkt. Die Bereiche, bei denen eine maximale relative Verstärkung stattfindet, sind die Formanten. Stimmen und Instrumente besitzen oft mehrere Formantregionen, die nicht direkt aneinander anschließen. 

Die Lage und Ausprägung der Formanten prägen maßgeblich die Klangfarbe (Timbre) eines Musikinstruments oder einer Stimme. Durch sie lassen sich Stimmen und auch Musikinstrumente voneinander unterscheiden – etwa die Stimmen zweier Frauen oder eine Geige von einer anderen. 

Die Lage der Formanten hängt ab:

Bei der menschlichen Sprache charakterisiert die Lage der Formanten die Bedeutung bestimmter Laute. Anhand der ersten beiden Formanten im Vokaldreieck beziehungsweise im Vokaltrapez lassen sich alle Vokale eines Lautsystems voneinander unterscheiden. Die Vokal-Formantlagen unterscheiden sich von Mensch zu Mensch, besonders zwischen Männern, Frauen und Kindern. Hier folgt eine Tabelle der gemittelten Formantlagen aus dem genannten Vokaldreieck.

Tabelle 1: Gemittelte Formantlagen aus dem Vokaldreieck
Die ersten beiden Formanten "f" und "f" sind für die Verständlichkeit der Vokale wichtig. Ihre Lage charakterisiert den gesprochenen Vokal, der dritte und der vierte Formant "f" und "f" sind für das Sprachverständnis nicht mehr wesentlich. Sie charakterisieren eher die Anatomie des Sprechers und dessen Artikulations-Eigenarten sowie das Timbre seiner Sprache und variieren je nach Sprecher. Darüber hinaus wird der Charakter einer Stimme noch durch die Grundfrequenz 100 bis 250 Hz und Artikulationseigenarten bestimmt. Die mittlere Sprechstimmlage liegt beim Mann etwa bei 130 Hz und bei der Frau etwa bei 240 Hz .

Formanten, die zwischen 1500 und 2000 Hz liegen, bringen die Wirkung des Näseleffekts hervor, was darum Näselformant genannt wird.
Wird das Velum geöffnet, treten ein, oft auch zwei Nasalformanten hinzu. Hierzu liegen diverse Untersuchungen vor, die unterschiedliche Nasalformanten ergeben haben. Der erste Nasalformant wird mit Werten zwischen 200 und 250 Hz angegeben, der zweite Nasalformant sehr unterschiedlich mit Werten zwischen 1000, 1200, 2000 und 2200 Hz.

Tabelle 2: Typische spektrale Anhebung (Quint- bis Oktavbreite),<br>die bei der Tonaufnahme von Gesang und Instrumenten gezielt eingesetzt wird.

Grundsätzlich gilt für den Gesang das gleiche wie für die Sprache. Die o. g. Formanten lassen sich besonders gut für tiefe Töne, z. B. gesungen im Schnarrregister zeigen. Aber bereits im höheren Bereich einer Sopranstimme liegt die Grundfrequenz oberhalb der in Tabelle 1 genannten 1. Formantfrequenzen. Bei Frequenzen von z. B. 700 Hz müssten demnach die Vokale u, e und i unverständlich sein und wegen der starken Dämpfung zwischen den Formanten nur schwache, nicht tragfähige Töne bilden. Allerdings sind nach Sundberg die Formanten "nicht" unabhängig vom Grundton. Diese unabhängige Variation der Formanten wird beispielsweise beim Obertongesang praktiziert. Wenn der Grundton in den Bereich des 1. Formanten fällt oder darüber liegt, dann steigt mit steigendem Grundton auch der 1. Formant. Dieses erzielt die Sängerin, indem sie den Mund weiter öffnet. Diese Anpassung des ersten Formanten bezeichnet man als "Formanttuning". Es führt beim i, u, e zu einem Anstieg des 1. Formanten, er liegt bei einer Grundfrequenz von 700 Hz ebenfalls bei etwa 700 Hz. Beim a bleibt er weitgehend konstant. Der 2. Formant sinkt dagegen beim e und i und steigt beim u. Der Anstieg des 1. Formanten geht aber nicht „unendlich“ weiter, im Bereich um h2 und darüber kann man mit weiterem Öffnen des Mundes nichts mehr bewirken. Die Vokale sind bei sehr hohen Tönen nicht mehr unterscheidbar, weil nunmehr die Grundfrequenz immer oberhalb des ersten Formanten liegt und somit der Klangeindruck dieses Formanten verschwindet.

Frequenzen um 3 kHz spielen eine entscheidende Rolle für die Tragfähigkeit einer Stimme. Deshalb nennt man diesen Frequenzbereich Sängerformant. Der Sängerformant ist gut ausgeprägt, wenn in einem gesungenen Ton die Frequenzen in einem breiten Band zwischen 2800 und 3400 eine „relative Stärke“ haben, unabhängig vom Grundton.

Der Begriff "Formant" wurde 1890 erstmals von Ludimar Hermann in seiner Akustischen Phonetik verwendet, aber erst 1929 von Erich Schumann in seiner Habilitationsschrift in Berlin technisch beschrieben und bildet heute ein breites Forschungsfeld sowohl in analytischen, nachrichtentechnischen wie klangsynthetischen Domänen.





</doc>
<doc id="1788" url="https://de.wikipedia.org/wiki?curid=1788" title="Fastenzeit">
Fastenzeit

Als Fastenzeit wird in der Westkirche der vierzigtägige Zeitraum des Fastens und Betens zur Vorbereitung auf das Hochfest Ostern bezeichnet. In den reformatorischen Kirchen ist der Begriff „Passionszeit“ gebräuchlich, der der Fastenzeit unbekannt. In der römisch-katholischen Kirche wird seit dem Zweiten Vatikanischen Konzil auch die Bezeichnung „österliche Bußzeit“ verwendet. Die orthodoxen Kirchen nennen sie die "heilige und große Fastenzeit", kennen daneben aber noch drei weitere längere Fastenzeiten.

Historische Begriffe im deutschen Sprachraum sind „die große Faste“ und „die lange Faste“. Die wichtigste lateinische Bezeichnung ist Quadragesima.

Zur Vorbereitung auf Weihnachten kennt die Westkirche eine zweite, ursprünglich ebenfalls vierzigtägige Bußzeit, den Advent.

Seit dem 2. Jahrhundert ist ein zweitägiges Trauerfasten an Karfreitag und Karsamstag bezeugt, das im 3. Jahrhundert mancherorts auf die ganze Karwoche ausgedehnt wurde. Im 3. Jahrhundert gab es in Rom eine dreiwöchige Fastenzeit, doch „seit dem 4. Jh. ist auf vielfältige Weise eine vierzigtägige Vorbereitungszeit auf das Osterfest bezeugt.“ Diese Periode galt als Bußzeit für öffentliche Sünder und gleichzeitig als Vorbereitungszeit der Katechumenen (Taufbewerber) auf die Taufe, die damals nur in der Osternacht gespendet wurde.

Biblischer Hintergrund für die Festsetzung der Fastenzeit auf 40 Tage und Nächte ist das ebenfalls vierzigtägige Fasten Jesu in der Wüste . Die Zahl 40 erinnert aber auch an die 40 Tage der Sintflut , an die 40 Jahre, die das Volk Israel durch die Wüste zog , an die 40 Tage, die Mose auf dem Berg Sinai in der Gegenwart Gottes verbrachte , und an die Frist von 40 Tagen, die der Prophet Jona der Stadt Ninive verkündete, die durch ein Fasten und Büßen Gott bewegte, den Untergang von ihr abzuwenden .

Die Dauer von „vierzig Tagen“ ist eher als symbolische und weniger als mathematische Größe verstanden worden. Ursprünglich – so etwa in Rom gegen Ende des 4. Jahrhunderts – scheint das Fasten am 6. Sonntag vor Ostern (Invocavit) begonnen zu haben, es endete am 40. Tag, dem Gründonnerstag, an dem die Büßer wieder zum Empfang der Kommunion zugelassen wurden. Ab dem 5. Jahrhundert wurden die Sonntage (als „kleine“ Auferstehungstage) vom Fasten ausgenommen. Um auf eine vierzigtägige Fastenzeit zu kommen, wurde daher der Beginn des Fastens "(caput ieiunii)" auf den Aschermittwoch vorgezogen und auch die beiden Tage des Trauerfastens (Karfreitag und Karsamstag) noch mitgerechnet.

Nach einer anderen Zählweise, welche die Sonntage einschließt, beginnt die Fastenzeit am Aschermittwoch und geht bis Palmsonntag. Mit dem Palmsonntag beginnt die heilige Woche, die dann als gesonderter Abschnitt gerechnet wird.

Auch die adventliche Fastenzeit umfasste ursprünglich 40 Tage und begann nach dem 11. November, dem Martinstag. Die Sitte, an diesem Abend noch eine Martinsgans zu essen, ist ebenso wie der Beginn der Karnevalssession am 11. November in Parallele zu den Fastnachtsbräuchen vor Aschermittwoch zu sehen.

Mit dem Auslaufen der öffentlichen Kirchenbuße gegen Ende des ersten Jahrtausends erhielt sich der Ritus der Bestreuung mit Asche als Zeichen der Buße und wurde an allen Gläubigen vorgenommen. Der Ritus der Auflegung der Asche fand Eingang in die Liturgie des Aschermittwochs. Auf der Synode von Benevent (1091) empfahl Papst Urban II. diesen Brauch allen Kirchen.

Die mittelalterlichen Fastenregeln erlaubten nur eine Mahlzeit am Tag, in der Regel am Abend. Der Verzehr von Fleisch, Milchprodukten, Alkohol und Eiern war verboten. Darauf geht die Tradition zurück, in den Fastnachtstagen Backwerk mit Zutaten wie Milch, Eiern, Zucker oder Schmalz herzustellen, wie etwa Krapfen, um solche Vorräte vor der Fastenzeit aufzubrauchen. Der Fastnachtsdienstag wird im französischsprachigen Raum dementsprechend "Mardi Gras" („fetter Dienstag“), im englischsprachigen "Pancake Tuesday" („Pfannkuchendienstag“) genannt. 1486 erlaubte Papst Innozenz VIII. auch den Verzehr von Laktizinien in der Fastenzeit. Gegen Zahlung des sogenannten „Butterpfennigs“ konnte bis dahin von dem Verbot, Butter und andere Milchspeisen zu verzehren, Dispens erteilt werden.

Die vierzigtägige Fastenzeit der römisch-katholischen Kirche ist als „österliche Bußzeit“ bestimmt und „dient der Vorbereitung auf die Feier des Todes und der Auferstehung Christi. Katechumenen und Gläubige bereitet die Liturgie der vierzig Tage zur Feier des Ostergeheimnisses; die einen durch die verschiedenen Stufen der Aufnahme in die Kirche, die anderen durch Taufgedächtnis und tätige Buße“. „Die Fastenzeit dauert von Aschermittwoch bis zum Beginn der Messe vom letzten Abendmahl am Gründonnerstag.“ Ab Karfreitag bis zur Osternachtfeier schließt sich das Osterfasten an, als Trauerfasten zum Gedächtnis der Passion und der Grabesruhe Christi und zur Vorbereitung der Taufe oder Erneuerung der Taufversprechen in der Osternacht. Die Fastenzeit gilt als geschlossene oder „gebundene“ Zeit.

Die Anforderungen der katholischen Kirche an die Fastenpraxis sind detailliert in der apostolischen Konstitution "Paenitemini" Papst Pauls VI. aus dem Jahr 1966 geregelt. Neben der Beachtung besonderer Speisegebote werden auch andere Formen der Askese und Buße empfohlen. Die Gläubigen sind angehalten, das Gebet intensiver zu pflegen und vermehrt an Gottesdiensten und Andachten (etwa der Kreuzwegandacht) teilzunehmen. Ebenso sollen sie mehr Werke der Nächstenliebe verrichten und Almosen geben. Ein solches Bußwerk wird, wie auch eine spürbare finanzielle Spende, die in der Fastenzeit gegeben wird, "Fastenopfer" genannt.

An den Fastensonntagen und Hochfesten, die in die Fastenzeit fallen (etwa dem Josefstag oder an Mariä Verkündigung) wird nicht gefastet.

Viele katholische Pfarrgemeinden kennen die Tradition des „Fastenessens“. Unter diesem Begriff versteht man ein Solidaritätsessen zugunsten von Projekten in der Dritten Welt, für die auf den üblichen Sonntagsbraten verzichtet wird. Stattdessen wird oft ein einfacher Eintopf oder ein für das Projektland typisches Gericht verkauft oder gegen eine Spende gereicht.

Die Liturgiereform in der Folge des Zweiten Vatikanischen Konzils überließ die Ausgestaltung der Bestimmungen zum Fasten und der Lage der Quatembertage weitgehend den einzelnen Bischofskonferenzen.

Die sechs Sonntage der Fastenzeit werden nach den Anfängen der liturgischen Messfeiern benannt, den lateinischen Antiphonen zum Introitus bzw. nach dem Ritus der Palmweihe am Palmsonntag (Palmarum).

In der Liturgie der Fastenzeit wird kein Halleluja gesungen, das Gloria nur an Hochfesten. Nach dem Gloria der Messe vom letzten Abendmahl am Gründonnerstag bis zum Gloria in der Osternacht werden keine Glocken geläutet, sondern stattdessen Ratschen verwendet. Auch die Orgel schweigt traditionell während des folgenden Triduum Sacrum. Ebenso gibt es bis auf den Sonntag Laetare in der Fastenzeit keinen Blumenschmuck in der Kirche.

Ab dem 5. Sonntag der Fastenzeit („Passionssonntag“) werden Kreuze und Standbilder durch violette Tücher verhüllt. Die Retabel von Triptychen und Flügelaltären sind in der Fastenzeit häufig zugeklappt und zeigen die einfacher gestaltete Rückseite der Flügel. Teilweise verhüllen Fastentücher den ganzen Chorraum.

Bis zum Zweiten Vatikanischen Konzil galt das Fastengebot auch noch viermal im Jahr an den Quatembertagen. Daneben bestand das Fasten- bzw. Abstinenzgebot am Vortag verschiedener Hochfeste und Heiligenfeste (Vigilfasten), etwa am Heiligen Abend und vor Pfingsten.

Bis in die 1960er-Jahre war Katholiken auch der Verzicht auf Fleisch an allen Freitagen, auf die kein Hochfest fällt, verbindlich vorgeschrieben (Codex des Kanonischen Rechtes). Nach Maßgabe der Bischofskonferenzen einiger Länder kann dieser Verzicht durch einen anderen Akt der Buße und des Verzichts ersetzt werden. Manche Gläubige fasten aus persönlicher Frömmigkeit außer freitags zusätzlich auch mittwochs oder auch samstags. Zu den Verpflichtungen der Mitglieder einiger Skapulierbruderschaften, etwa der Unserer Lieben Frau auf dem Berge Karmel, gehört die Abstinenz von Fleischspeisen mittwoches, freitags und samstags.
In der orthodoxen Kirche gibt es vier mehrtägige Fastenzeiten:

Je nach Tradition gibt es verschiedene Fastenstufen. Während der Fastenzeiten sollte sowohl die Anzahl der täglichen Mahlzeiten wie auch deren Gehalt eingeschränkt werden. An Samstagen und Sonntagen wird das Fasten jeweils um eine „Stufe“ gelockert.

Nach der in den orthodoxen Kirchen verbreiteten Ansicht gilt jedoch das Beten sowie die strengstmögliche Enthaltung von Sünden als der wichtigere Teil des Fastens, wichtiger als der Nahrungsverzicht im engeren Sinne. Jeder Gläubige sollte seine Fastenregeln mit Gott, sich selbst und seinem Priester oder Beichtvater abklären. Fasten „auf eigene Faust“ wird nicht empfohlen. Die genaue Beachtung der Speiseregeln wird heute nur noch von einer kleinen Minderheit von Gläubigen vollständig eingehalten, in der Karwoche jedoch ist das Fasten weiterhin verbreitet üblich.

Bezüglich der Speisegebote kennen die orthodoxen Kirchen grundsätzlich drei Stufen des Fastens:

Diese Fastenstufen können von Kirche zu Kirche verschieden gehandhabt werden. Sie können auch durch den Priester für den einzelnen Gläubigen an dessen Möglichkeiten angepasst werden.
In Klöstern gibt es noch eine zusätzliche Form des Fastens, die "Xerophagia", die sich durch kompletten Nahrungsverzicht bis zur neunten Stunde (15 Uhr) auszeichnet und danach nur Brot, Früchte und Wasser erlaubt. Diese Form ist für die große Fastenzeit vor Ostern vorgesehen und wird von Laien bisweilen am „Reinen Montag“ (dem ersten Fastentag) und am Karfreitag eingehalten.

Außer in den Wochen direkt nach Ostern und Pfingsten (Oktav) und in den zwei Wochen nach Weihnachten soll an jedem Mittwoch und Freitag streng gefastet werden.

Für orthodoxe Mönche gelten weitere Regeln. Allgemein fasten sie zusätzlich an jedem Montag. Die weitere Ausgestaltung ist jedoch von Kloster zu Kloster verschieden. In den strengsten Klöstern kann ein einziges gekochtes Ei pro Jahr, am Ostersonntag, das maximal Erlaubte an tierischen Lebensmitteln sein.

„Im evangelischen Bereich heißen die Vierzig Tage Passionszeit – Zeichen dafür, dass das Motiv der Passion Jesu die gesamte Vorbereitungszeit auf Ostern bestimmt. Ursprünglich war solche Prägung auf die Karwoche beschränkt.“

Die Reformatoren standen in der spätmittelalterlichen Tradition einer verinnerlichten Frömmigkeit: nicht die quantifizierbaren äußeren Akte seien wichtig, sondern die Gesinnung. In diesem Sinn äußert sich Martin Luther in seinem "Sermon von den guten Werken":

Deutlich wird aus diesem Zitat, dass Luther das Fasten als eine Art individuelles Trainingsprogramm versteht. Daher kann nicht das gleiche Verzichtsverhalten allen gleichermaßen empfohlen oder gar verordnet werden.

Zweck des Fastens ist nach den lutherischen Bekenntnisschriften „den alten Adam zu zähmen“; das Fasten wird insbesondere zur Vorbereitung auf das Abendmahl empfohlen: „Fasten und leiblich sich bereiten ist wohl eine feine äußerliche Zucht“. Jedoch wird die Festschreibung des Fastens in kirchenrechtlichen Kategorien durchweg abgelehnt und „Freiheit in äußerlichen Ceremonien“ gefordert, programmatisch z. B. in der Augsburgischen Konfession, § 26 „Von Unterschied der Speis“: „Und wird also nicht das Fasten verworfen, sondern daß man einen notigen Dienst daraus auf bestimbte Tag und Speise, zu Verwirrung der Gewissen, gemacht hat.“

Auch Luther formulierte: „Kein Christ ist zu den Werken, die Gott nicht geboten hat, verpflichtet. Er darf also zu jeder Zeit jegliche Speise essen.“ Seine theologische Pointe lag dabei in seiner Rechtfertigungslehre, weil Luther die Gefahr sah, dass der Mensch mit seinem Handeln Gott gefallen wolle.

Im traditionellen Luthertum wird am Karfreitag bis zur Todesstunde Jesu um 15 Uhr strikt gefastet. Das Evangelische Gottesdienstbuch, das für die VELKD und die UEK, also für fast alle evangelischen Landeskirchen in Deutschland, verbindlich ist, sieht vor, dass ab dem Beginn der Vorpassionszeit, also ab Septuagesimae, „das Halleluja entfällt. Von Aschermittwoch bis Karsamstag entfällt auch das Ehre sei Gott in der Höhe (Ausnahme Gründonnerstag).“ Schließlich entfallen „von Palmsonntag bis Karsamstag […] ‚Ehre sei dem Vater‘, ‚Halleluja‘ und ‚Ehre sei Gott in der Höhe‘ (Ausnahme: Gründonnerstag).“

Am anderen Ende des evangelischen Spektrums, z. B. bei Pfingstlern oder Evangelikalen, aber auch bei vielen reformierten Christen werden geschichtlich gewachsene Traditionen wie die Fastenzeit eher skeptisch gesehen, manchmal provokativ durchbrochen wie beim Zürcher Wurstessen an Invokavit 1522.

Wo in den evangelischen Kirchen die Fastenzeit neu entdeckt wird, geht es generell nicht um eine Rückkehr zu überlieferten Speiseregeln, sondern um das Aufbrechen eigener Gewohnheiten, um dem Heiligen Geist Raum zu geben. Seit rund 25 Jahren verbinden evangelische Christen diese geistliche Praxis auch wieder mit einer körperlichen: dem Verzicht auf liebgewonnene Gewohnheiten wie gut essen, rauchen, Alkohol trinken oder fernsehen. Kennzeichen für diese Entwicklung ist die Fastenaktion "7 Wochen Ohne" der Evangelischen Kirche. Inzwischen nehmen jedes Jahr viele Millionen Menschen an dieser Aktion teil, die sich 1983 aus einer Stammtischidee des Hamburger Pressepastors Hinrich Westphal entwickelte.

Auch andere Religionen wie das Judentum und der Islam kennen Zeiten des Fastens, in der sich die Gläubigen von morgens bis abends Speise und Trank enthalten. Das Judentum kennt Fastentage wie den Jom Kippur und Tischa beAv. Im Islam ist der Fastenmonat der Ramadan. Im Alevitentum fastet man im Muharrem-Monat, 20 Tage nach dem islamischen Opferfest. Im Februar findet noch das Hizir-Fasten statt, das dem Propheten al-Chidr gewidmet ist. Im Bahaitum beginnt die Fastenzeit Anfang März und endet 19 Tage darauf unmittelbar vor dem astronomischen Frühlingsanfang, wenn die Bahai das Nouruz-Fest begehen.




</doc>
<doc id="1789" url="https://de.wikipedia.org/wiki?curid=1789" title="Freistaat (Republik)">
Freistaat (Republik)

Freistaat ist die im 19. Jahrhundert entstandene deutsche Bezeichnung für einen von keinem Monarchen regierten freien Staat, das heißt für eine Republik. In der Weimarer Republik war der Begriff des Freistaats – neben Volksstaat – die amtliche Bezeichnung der meisten deutschen Flächenländer. Es ist heute die amtliche Bezeichnung für die Länder Bayern (seit 1945), Sachsen (seit 1990) und Thüringen (seit 1993) und wurde von 1945 bis 1952 auch für das Land Baden verwendet.

Bereits im Mittelalter gab es die Bezeichnung "frei" für Stände, Reichsstädte oder Hansestädte. Dies stand für die Gewährung bestimmter Rechte, der Steuerfreiheit oder der eigenen Gerichtshoheit.

In der Neuzeit wird das Wort "Freistaat" im Sinn von Republik verwendet, nämlich als die Übersetzung der lateinischen Bezeichnung für die römische Republik ( ‚freier Staat‘, während oft nur allgemein ‚Staat‘ bedeutet).
Im 18. Jahrhundert ist die Bezeichnung "Freistaat" ein von Sprachpuristen eingeführtes deutsches Synonym für Republik (lat. , ). Sie bezeichnet einen Staat, in dem die Staatsgewalt vom Volk ausgeht und insbesondere – im Gegensatz zur Monarchie – das Staatsoberhaupt direkt oder indirekt vom Volk gewählt wird.

Als Synonym für Republik verwendet dieses Wort auch die Weimarer Reichsverfassung (1919), wenn sie in Art. 17 bestimmt: „Jedes Land muss eine freistaatliche Verfassung haben“. Der Freistaat ist heute üblicherweise als parlamentarische Demokratie organisiert; die Bezeichnung ist aber zum Beispiel auch von der Münchner Räterepublik gebraucht worden. Der Schweizer Kanton Obwalden bezeichnet sich in seiner Verfassung als „demokratischer Freistaat und im Rahmen der Bundesverfassung souveräner Stand und Bundesglied der Schweizerischen Eidgenossenschaft“.

Am Ende des Ersten Weltkriegs rief in der Nacht vom 7. zum 8. November 1918 der Sozialist Kurt Eisner in München den "Freistaat Bayern" aus und wurde wenig später von den Arbeiter- und Soldatenräten zum Ministerpräsidenten bestimmt. Nach der Ausrufung der Republik in Deutschland am 9. November 1918 in Berlin übernahmen neben Bayern viele der neuen deutschen Republiken – entsprechend dem Artikel 17 der Weimarer Reichsverfassung: „Jedes Land muss eine freistaatliche Verfassung haben“ – den Begriff Freistaat als offizielle Bezeichnung für Republik: Preußen, Sachsen, Braunschweig, Anhalt, Oldenburg, Mecklenburg-Schwerin, Mecklenburg-Strelitz, Waldeck, Lippe, Schaumburg-Lippe sowie die thüringischen Kleinstaaten mit Ausnahme von Reuß. 

Andere deutsche Gliedstaaten bezeichneten sich als "Republik" oder "Volksstaat", wie etwa der „freie“ Volksstaat Württemberg. 1919 wurde die Gründung einer "Nordwestdeutschen Republik" erwogen, die aus zehn sozialistischen Freistaaten bestehen sollte. 1920 schloss sich der Freistaat Coburg an Bayern an. Verschiedene thüringische Staaten gingen im neu gegründeten Land Thüringen auf, welches die Bezeichnung Freistaat (damals) nicht benutzte. 1929 schloss sich Waldeck an Preußen an, die Nationalsozialisten vereinigten 1934 die beiden mecklenburgischen Staaten zwangsweise zum Land Mecklenburg.

Die Besatzungssituation nach dem Ersten Weltkrieg ließ am Rhein einen schmalen Landstreifen nordwestlich von Lorch (Rheingau) frei, der jedoch vom übrigen unbesetzten Deutschland faktisch isoliert und damit zur Selbstverwaltung gezwungen war. Er bestand bis 1923 und bezeichnete sich ironisch als Freistaat Flaschenhals.

1947 wurde der Staat Preußen durch das Kontrollratsgesetz Nr. 46 förmlich aufgelöst. Braunschweig, Oldenburg und Schaumburg-Lippe wurden 1946 Teile des neu gegründeten Landes Niedersachsen, Lippe kam 1947 zu Nordrhein-Westfalen, Anhalt 1945/1947 zu Sachsen-Anhalt. 

Nachdem im Jahre 1952 Sachsen zusammen mit den anderen Ländern der Deutschen Demokratischen Republik faktisch aufgelöst und in die Bezirke Dresden, Chemnitz (später "Karl-Marx-Stadt") und Leipzig aufgeteilt worden war, blieb von allen Ländern, die sich als Freistaaten bezeichnet hatten, allein Bayern übrig. Erst am Tage der Deutschen Einheit entstand der Freistaat Sachsen erneut, und etwa drei Jahre später beschloss die Landesregierung Thüringens, die Bezeichnung für ihr Land erstmals einzuführen.

Auch in der Struktur der Bundesrepublik Deutschland mit ihrem föderalen System hat die Bezeichnung "Freistaat" keine rechtliche Bedeutung, da alle Länder der Bundesrepublik die gleiche verfassungsrechtliche Stellung besitzen. Daher ergeben sich für die Bundesländer, welche sie – wie etwa der Freistaat Bayern vornehmlich aus historischen Gründen – verwenden, auch keinerlei Sonderstellungen. Auch die Existenz der Regionalpartei CSU (anstelle eines Landesverbandes der CDU) begründet keine Ausnahme in Bezug auf den Föderalismus, sondern steht lediglich in der Tradition, dass der politische Katholizismus in Bayern vom Anfang der Parteienbildung an eigenständig organisiert war (statt "Zentrum" im Kaiserreich, "Bayerische Patriotenpartei" im Königreich und in der Weimarer Republik "Bayerische Volkspartei").

Vergleichbare Bezeichnungen mit historischem Hintergrund führen die "Freie und Hansestadt Hamburg" und die "Freie Hansestadt Bremen". Im Fall von Bremen ist die Bezeichnung darüber hinaus geeignet, das Land Bremen, zu dem auch die Stadt Bremerhaven gehört, von der Stadt Bremen zu unterscheiden. "Freistaat" und "Freie Stadt" unterscheiden sich in ihrem historischen Hintergrund.



</doc>
<doc id="1790" url="https://de.wikipedia.org/wiki?curid=1790" title="Geographie">
Geographie

Die Geographie (oder Geografie, , zusammengesetzt aus γῆ "gē" ‚Erde‘ und γράφειν "gráphein" ‚(be-)schreiben‘) oder Erdkunde ist die sich mit der Erdoberfläche befassende Wissenschaft, sowohl in ihrer physischen Beschaffenheit wie auch als Raum und Ort des menschlichen Lebens und Handelns. Sie bewegt sich dabei an der Schnittstelle zwischen den Naturwissenschaften, Geistes- und Sozialwissenschaften.

Gegenstand der Geographie ist die Erfassung, Beschreibung und Erklärung der Strukturen, Prozesse und Wechselwirkungen in der Geosphäre. Die physikalische, chemische und biologische Erforschung ihrer Einzelerscheinungen ist jedoch Gegenstand anderer Geowissenschaften.

Bis zur amtlichen Neuregelung der deutschen Rechtschreibung war ausschließlich die Schreibweise "Geographie" richtig. Ab 1996 war auch "Geografie" zulässig, wobei "Geographie" zunächst noch bevorzugt an erster Stelle stand. Seit der überarbeiteten Fassung 2004 des Wörterverzeichnises ist nunmehr "Geografie" die primär angeführte Schreibweise. Der Duden erlaubt mindestens seit 2006 (24. Auflage) beide Schreibweisen und kennzeichnete die Variante "Geografie" als "Dudenempfehlung". Traditionell wird in wissenschaftlichen Texten und unter Fachleuten weiterhin häufig die alte Schreibweise genutzt. So empfahl das Präsidium der Deutschen Gesellschaft für Geographie im Jahr 2003 einstimmig, die Schreibweise "Geographie" beizubehalten.

Die Bedeutung geographischen Wissens wurde, soweit historisch überliefert, erstmals in der Antike von den Griechen erkannt. Vom Naturphilosophen Anaximander aus Milet wird berichtet, dass er als erster um 550 v. Chr. eine Karte der Erde und der Meere skizzierte. Herodot von Halikarnassos (484–424 v. Chr.) verfasste eine Vielzahl geographischer Berichte. Die Eroberungen Alexander des Großen öffneten den Blick der griechischen Gelehrten bis weit nach Asien hinein. Es entstanden Itinerarien, also Beschreibungen der Straßen und Verzeichnisse der Stationen auf Reisen, sowie Periploi, praktische Reisehandbücher für Seefahrer und Kaufleute, die oft auf persischen oder parthischen Quellen fußten. 

Mit zunehmender Fernreisetätigkeit nahmen auch die Versuche der Erkundung der Gesamtgestalt der Welt zu. Neben der physikalischen Geographie und der Kulturgeographie entwickelten sich Anfänge einer mathematischen Geographie. Eine Berechnung des Erdumfangs gelang erstmals Eratosthenes (ca. 273–194 v. Chr.), während der um die Zeitenwende lebende Strabon eines der heute am besten erhaltenen geographischen Werke der Antike verfasste. Der Astronom Claudius Ptolemäus (ca. 100 bis 170) sammelte topografisches Wissen von Seefahrern und gab Anleitungen für das Zeichnen von Landkarten. Die Erkenntnisse der Griechen nutzten die Römer weiter. Während des Mittelalters geriet die Geographie, wie andere Wissenschaftszweige auch, in Europa weitgehend in Vergessenheit. Neue Impulse kamen jedoch aus dem Kaiserreich China und der aufstrebenden Geographie und Kartographie im mittelalterlichen Islam.

Frühe theoretische Ansätze lieferte Albertus Magnus: In seiner Abhandlung „De natura locorum“ beschrieb er die Abhängigkeit der Eigenschaften eines Ortes von seiner geographischen Lage. Im Anschluss daran führte der Wiener Astronom Georg Tannstetter die physikalische Geographie in den Kreis der universitären Lehrgegenstände ein (1514).

Die neuzeitliche Geographie wurde von Bartholomäus Keckermann (1572–1608) und Bernhard Varenius (1622–1650) begründet. Sie entwickelten ein Begriffssystem, unterschieden „Allgemeine Geographie“ "(geographia generalis)" und die „Regionale Geographie“ beziehungsweise Länderkunde "(geographia specialis)". Sie sahen Völker, Staaten und Orte in einem räumlichen, historischen und auch religiösen Kontext. Zu Beginn des 18. Jahrhunderts beförderten in Deutschland vor allem Johann Hübner (1668–1731) und Johann Gottfried Gregorii alias MELISSANTES (1685–1770) durch ihre Lehrbücher, thematischen Lexika und Atlanten die Verbreitung der Geographie in weite Teile der bildungsnahen Bevölkerung.

Das Zeitalter der Aufklärung förderte Erklärungsversuche von Naturerscheinungen durch Wissenschaftler wie Johann Gottfried Herder (1744–1803) und Georg Forster (1754–1794). Anton Friedrich Büsching (1724–1793) verfasste die elfbändige "Neue Erdbeschreibung" mit Beschreibungen der Länder und deren Wirtschaft. 

Alexander von Humboldt (1769–1859) und Carl Ritter (1779–1859) begründeten schließlich die moderne wissenschaftliche Geographie, deren ursprüngliches länder- und landschaftskundliches Forschungsprogramm auf Herders Kulturtheorie basiert. Im Laufe des 19. Jahrhunderts gründeten sich zunächst vielerorts „geographische Gesellschaften“, während die universitäre Institutionalisierung des Fachs vor allem mit der Gründung des Deutschen Reichs vorangetrieben wurde.

Ferdinand von Richthofen (1833–1905) definierte die Geographie zu jener Zeit als "„Wissenschaft von der Erdoberfläche und den mit ihr in ursächlichem Zusammenhang stehenden Dingen und Erscheinungen“". Dieser geodeterministische Betrachtung standen das von Paul Vidal de la Blache (1845–1918) geprägte Konzept des Possibilismus sowie die von Alfred Hettner (1859–1941) formulierte Chorologie gegenüber. Einzelne Fachvertreter wie Élisée Reclus (1830–1905) knüpften früh Verbindungen zur aufkommenden Soziologie. Auch belegt etwa das Entstehen der ersten Nationalparks, dass der prägende Einfluss des Menschen auf seine Umwelt nicht nur bekannt, sondern auch von politischer Bedeutung war.

Insbesondere die deutsche Geographie war aber letztendlich von sozialdarwinistisch und völkisch argumentierenden Vertretern wie Alfred Kirchhoff (1838–1907), dem als Begründer der Humangeographie geltenden Friedrich Ratzel (1844–1904) und dem Geomorphologen Albrecht Penck (1859–1945) bestimmt. Anwendung fanden diese Ansichten schließlich vor allem durch die Geopolitik, wie sie insbesondere durch Halford Mackinder (1861–1947) und Karl Haushofer (1869–1946) formuliert worden war.

Nach dem Zweiten Weltkrieg wandte sich die geographische Forschung im deutschsprachigen Raum zunächst Themengebieten von relativ geringer politischer Brisanz zu. Carl Troll (1899–1975), Karlheinz Paffen (1914–1983), Ernst Neef (1908–1984) und Josef Schmithüsen (1909–1984) entwickelten die Landschaftsökologie, Hans Bobek (1903–1990) und Wolfgang Hartke (1908–1997) die Sozialgeographie weiter. Eine stärker an den Erfordernissen der Raumplanung orientierte, nicht zuletzt auf den Werken von Walter Christaller (1893–1969) aufbauende Geographie wurde dagegen zunächst in Schweden durch Torsten Hägerstrand (1916–2004) und im anglo-amerikanischen Raum etabliert. 

Seit Ende der 1960er Jahre („Quantitative Revolution“) versteht sich auch die deutschsprachige Geographie zunehmend als angewandte Wissenschaft und sucht ihre Themen im Zusammenhang mit Städtebau, Entwicklung des ländlichen Raumes, Raumplanung oder dem Umweltschutz. Gleichzeitig trägt die Entstehung einer sich als kritisch verstehenden Geographie dieser neuerlich übernommenen gesellschaftspolitischen Verantwortung Rechnung. Durch die wachsende Spezialisierung im 20. Jahrhundert entstand die Vielfalt der heutigen Teildisziplinen und die Aufteilung zwischen Physischer Geographie und Humangeographie.
Es existieren verschiedene Versuche, die Geographie schematisch zu ordnen. Die im heutigen Wissenschaftsbetrieb bedeutsamste ist die Einteilung in die beiden großen Teilgebiete der "Physischen Geographie" und der "Humangeographie" nebst einem interdisziplinären Bereich als dritter „Säule“. Es lassen sich jeweils diverse Unterdisziplinen identifizieren, wobei die Teilbereiche der physischen Geographie insgesamt relativ stark in die übergeordneten naturwissenschaftlichen Disziplinen integriert sind, während diejenigen der Humangeographie wiederum untereinander eng vernetzt sind.

Die "Physische Geographie" (oder "Physiogeographie") beschäftigt sich in erster Linie mit den natürlichen Bestandteilen und Strukturen der Erdoberfläche. Dabei wird die Tätigkeit des Menschen zur Erklärung der Landschaftsgenese auch behandelt.

Teilgebiete der Physischen Geographie sind unter anderem:

Die "Humangeographie" (auch "Anthropogeographie", selten "Kulturgeographie") beschäftigt sich sowohl mit dem Einfluss des Menschen auf den geographischen Raum, als auch mit dem Einfluss des Raums auf den Menschen − beispielsweise im Zusammenhang mit der räumlichen Verteilung von Bevölkerung oder Wirtschaftsgütern. Ehemals als Teil der Geisteswissenschaften aufgefasst, hat sie sich insbesondere seit den 1980er Jahren („spatial turn“) den Gesellschaftswissenschaften angenähert. Hartmut Leser (2001) definiert die Humangeographie als denjenigen „Teilbereich der Allgemeinen Geographie, der sich mit der Raumwirksamkeit des Menschen und mit der von ihm gestalteten Kulturlandschaft und ihren Elementen in ihrer räumlichen Differenzierung und Entwicklung befasst.“
Die Sozialgeographie und die Kulturgeographie gelten dabei als „Kerngebiete“ der Humangeographie, da sie alle weiteren Subdisziplinen berühren. Teilweise werden diese Begriffe auch als Synonym für die Humangeographie im Ganzen verwendet. Auch die politische Geographie, zumal in ihrer damaligen Anwendung als Geopolitik und Militärgeographie, ist eng in die Gründungsgeschichte der Humangeographie verwoben, bildet heute aber eine eigenständige Fachrichtung. Weitere sozialwissenschaftlich orientierte Bereiche der Geographie stellen die Bevölkerungsgeographie, die Bildungsgeographie und die Religionsgeographie dar. Einige andere Unterdisziplinen, die diesem Fächerspektrum zugerechnet werden können, werden im deutschen Sprachraum allerdings nur in geringem Maß oder als Teil anderer sozialwissenschaftlicher Fachrichtungen betrieben. Dazu gehören unter anderem die Kriminalgeographie, die Sprachgeographie mit der Dialektgeographie und die Wahlgeographie.

Zu den klassischen Teilgebieten der Humangeographie zählen jene Unterdisziplinen, die sich mit der vom Mensch errichteten gebauten Umwelt befassen, also die Siedlungsgeographie, die Geographie des ländlichen Raumes, die Stadtgeographie und die Verkehrsgeographie. Letztere wird teilweise auch zur Wirtschaftsgeographie gerechnet, die außerdem die Geographie des primären (Agrargeographie), sekundären (Industriegeographie) und tertiären Wirtschaftssektors (Handelsgeographie, Tourismusgeographie) umfasst.

Eine Sonderstellung nimmt die Historische Geographie ein. Ursprünglich vor allem mit genetischer Siedlungsforschung beschäftigt und damit humangeographisch orientiert, ist das Fach inzwischen relativ stark interdisziplinär integriert und insbesondere eng mit der Umweltgeschichte verbunden. Klassische Anwendungsbereiche sind die Kulturlandschaftsforschung, Waldgeschichte, Wüstenbildungsforschung oder Flusslaufdokumentation. Die raum-zeitliche Ausbreitung von Phänomenen ist Gegenstand der geographischen Diffusionsforschung.

Auch wenn sich natur- und geistes- bzw- sozialwissenschaftlich orientierte Geographie inzwischen in ihrer methodischen Vorgehensweise stark voneinander unterscheiden, ergeben sich hinsichtlich der Fragestellungen weiterhin Überschneidungen. Da diese vor allem die Folgen menschlichen Handelns auf die Natur und deren Rückwirkung auf die Gesellschaft betreffen, wurde dieser der Humanökologie nahestehende Teilbereich teilweise als "physische Anthropogeographie" bezeichnet, ein Begriff von allgemeiner Verwendung existiert jedoch nicht. Eng eingebunden ist die Geographie auch in die interdisziplinäre Erforschung von spezifischen Mensch-Umwelt-Systemen wie die Gebirgs-, die Küsten-, die Polar-, die Tropen- und die Wüstenforschung.

Eine traditionelle Einteilung hingegen ist jene in die "Allgemeine Geographie" und die "Regionale Geographie", wie sie etwa im länderkundlichen Schema von Alfred Hettner modellhaft dargestellt wurde. Die "Allgemeine Geographie" ist demnach der Teil der Geographie, welcher sich nomothetisch mit den Geofaktoren der Erdoberfläche (Geosphäre) beschäftigt. Im Mittelpunkt stehen zumeist ein Geofaktor (z. B. Wasser, Boden, Klima etc.) und dessen Wechselwirkungen mit anderen Geofaktoren. Die allgemeine Geographie beschäftigt sich somit mit allgemeinen Gesetzmäßigkeiten in der gesamten Geosphäre. Physische Geographie und Humangeographie sind dann lediglich Teile der Allgemeinen Geographie.

Unter "Regionale Geographie (Spezielle Geographie)" wird gemäß dieser Unterteilung jener Teil der Geographie verstanden, welcher sich idiographisch oder typologisch mit bestimmten Teilgebieten der Erdoberfläche (Geosphäre) beschäftigt. Im Mittelpunkt steht somit eine Region, z. B. ein Land oder eine Landschaft, deren räumliche Elemente, Strukturen, Prozesse und Funktionsweisen (Wechselwirkungen zwischen den Geofaktoren) erfasst, klassiert und erklärt werden. Die Regionale Geographie lässt sich demnach unterteilen in die Länderkunde, also die idiographische Untersuchung von Raumindividuen, und die Landschaftskunde, die typologische Untersuchung von Raumtypen.

Bis weit ins 20. Jahrhundert hinein galten Länder- und Landschaftskunde als der eigentliche „Kern“ der Geographie, der dem Fach eine gewisse Identität gab. Zwar werden Werke mit entsprechender Thematik weiterhin produziert, ihnen wird inzwischen aber kein wissenschaftlicher Charakter mehr attestiert. Die "Regionale Geographie" erfuhr einen Bedeutungswandel und beschäftigt sich, statt Regionen als Forschungsgegenstand vorauszusetzen, mit dem Regionalisierungsvorgang an sich. Damit ist sie heute Teil von Sozial- und Wirtschaftsgeographie sowie des interdisziplinären Felds der Regionalwissenschaft.

Die "Angewandte Geographie", die in der zweiten Hälfte des 20. Jahrhunderts in Abgrenzung zur "Theoretischen Geographie" entstand, stellt eine normative Form der geographischen Forschung dar, die sich in allen ihren Fachgebieten wiederfindet. Gegenstand der Angewandten Geographie ist die Analyse und Planung räumlicher Strukturen und Prozesse, sowie die Lösung raumbezogener Probleme. Praktische Anwendungsgebiete sind die Raumplanung oder der Umweltschutz. Insbesondere einige Forschungsbereiche der physischen Anthropogeographie sind normativ etwa auf die Paradigmen der Nachhaltigkeit und der Gesundheit hin ausgerichtet. Beispiele hierfür sind die Geographische Entwicklungsforschung, die Geographische Risikoforschung und die Medizinische Geographie.

Unter "Schulgeographie" versteht man das Schulfach Geographie, auch "Erdkunde" genannt (in Österreich "Geographie und Wirtschaftskunde"), und die dazugehörige Ausbildung für das Lehramt. Zentrales Anliegen dieses Zweiges ist – wie in jeder Disziplin – Wissenschaftsdidaktik in ihrer speziellen Ausprägung als Geographiedidaktik. Daher umfasst die Schulgeographie auch die Methodologie der systematischen Reduzierung, Paradigmenbildung und didaktischen Aufbau des Fachgebiets in den verschiedenen Schultypen (Erstellung von Lehrplänen und Lerninhalten). Im weiteren Sinne kann sie damit auch in die hochschulische Lehre selbst eingreifen und auch Schulkartografie, Weiterbildung, Beratung und Information umfassen, und so zum Tätigkeitsfeld eines angewandten Geographen werden (Erstellung etwa von Lehrbüchern, Lehrsendungen, geographischen Dokumentationen, Kartenwerken, bzw. Fachberatung bei denselben und Öffentlichkeitsarbeit).
Als „Brückenfach“ zwischen natur-, geistes- und gesellschaftswissenschaftlichen Disziplinen besteht in der Geographie generell eine große methodische Vielfalt, die die Bandbreite an möglichen Forschungsobjekten reflektiert. Während die Erstellung von Karten und die Nutzung geographischer Informationssysteme (GIS) als wichtige Darstellungs- und Forschungsmethoden in allen Teilbereichen zu finden sind, kommen außerdem den jeweiligen Nachbardisziplinen entlehnte Verfahren zur Anwendung.

Die "Vergleichende Geographie" wurde schon im 19. Jahrhundert von Carl Ritter und Oskar Peschel begründet. Sie ist eine Vorgehensweise, die zwei typologische Kategorien in Bezug setzt.

Ein aktueller methodischer Teilbereich, der zunehmend Bedeutung in der Geographie erlangt und auch der Mathematischen Geographie zugerechnet werden kann, ist die "Geoinformatik". Sie verwendet Methoden der Informatik bei der Bearbeitung geographischer Fragestellungen. Aufgabenfelder der Geoinformatik sind:

Der kritische Geograph Gerhard Hard argumentierte nach 1968, dass der Landschaftsgeographie, die seit Alexander von Humboldt den Kern der klassischen Geographie bildet, Wahrnehmungsmuster zugrunde liegen, die aus der Landschaftsmalerei stammen. Daher bestimmten jene Forschungsrichtungen, die sich auf Landschaft beziehen wie z. B. die Landschaftsökologie, ihren Gegenstand primär auf ästhetischer Weise, der erst sekundär mit einem szientistischen Methodendesign versehen werde. Dieses führe wiederum dazu, dass die ästhetischen Implikationen innerhalb der Profession nicht bewusst reflektiert werden.

Obwohl sich die Geographie immer wieder neu verstanden und ausgerichtet hat, sieht Gábor Paál ein kontinuierliches Merkmal in der ästhetischen Grundlage, die der Wissenschaft zugrunde liegt. Demnach ist es immer ein zentrales Motiv von Geographen gewesen, räumliche Muster zu erkunden und zu verstehen, und zwar insbesondere solche Muster, die sich in ihrer Größenordnung innerhalb des menschlichen Aktionsradius bewegen: Sie befasst sich mit Mustern „von der Größenordnung dessen, was das menschliche Augen ohne große Anstrengung noch erkennen kann bis zur gesamten Erdoberfläche.“ Ansätze, die sich explizit mit Umweltwahrnehmungen auseinandersetzen, werden unter der Wahrnehmungsgeographie gefasst.






</doc>
<doc id="1795" url="https://de.wikipedia.org/wiki?curid=1795" title="Gesundheit">
Gesundheit

Gesundheit wird, auf den einzelnen Menschen bezogen, als Zustand des körperlichen und/oder geistigen subjektiven Wohlbefindens aufgefasst. Auf eine Population bezogen steht Gesundheit für ein möglichst geringes Ausmaß an Krankheitslast. Gesundheit hat mit dem Erleben eine subjektive Seite, und erscheint andererseits auch objektiv feststellbar über das Nicht-Vorliegen von Krankheit, bei Fehlen einer medizinischen Diagnose.

Gesundheit ist ein in kultureller und historischer Hinsicht vielschichtiger Begriff. Je nach wissenschaftlicher Disziplin wird er unterschiedlich verstanden, und auch der subjektive Gesundheitsbegriff jedes Einzelnen variiert stark, z. B. abhängig von Alter, Geschlecht, Bildung und kulturellem Hintergrund. Einem naturwissenschaftlich verstandenen engen Begriff von Gesundheit nach dem bio-medizinischen Modell steht in der heutigen Zeit ein ganzheitlicher Begriff von Gesundheit gegenüber. Gesundheit kann sich auf den einzelnen Menschen beziehen, und als Zustand des körperlichen wie geistigen Wohlbefindens, oder der physischen und psychischen Funktions- und Leistungsfähigkeit begriffen werden. Gesundheit kann auch als Gegenbegriff zu Krankheit gefasst werden, und beschreibt dann den wünschenswerten „Normal“-Zustand als Abwesenheit von Krankheit. Gesundheit kann auch auf ein Kollektiv, z. B. die Bevölkerung, bezogen werden, und beschreibt dann das Ausmaß einer geringen Krankheitslast in einer Population.

Es gibt eine Vielzahl von Gesundheitsdefinitionen, die sich hinsichtlich ihrer grundlegenden Annahmen unterscheiden lassen. Die nachfolgende Aufzählung stellt einige davon vor:


Sozialepidemiologische Untersuchungen belegen, dass Menschen aus sozioökonomisch besser gestellten Schichten in Deutschland gesünder sind und eine längere Lebenserwartung haben als Menschen, die über geringere Bildung, Einkommen und Berufsstatus verfügen. Es zeigen sich schichtspezifische Unterschiede beim Gesundheits- und Krankheitsverhalten, z. B. Ernährung oder Rauchen, was zu einer "gesundheitlichen Ungleichheit", zu Unterschieden in der Mortalität und Morbidität führt. Die Gründe dafür liegen nach Mielck in

Die Frage nach einem gesunden Leben ist aus der Perspektive der Ungleichheitsforschung nicht nur eine gesundheits-, sondern stets auch eine sozialpolitische Frage.





</doc>
