<doc id="10268" url="https://de.wikipedia.org/wiki?curid=10268" title="Internationale Raumstation">
Internationale Raumstation

Die Internationale Raumstation (, kurz ISS, , ) ist eine bemannte Raumstation, die in internationaler Kooperation betrieben und ausgebaut wird.

Erste Pläne für eine große internationale Raumstation gab es in den 1980er Jahren unter den Namen "Freedom" oder "Alpha". Seit 1998 befindet sich die ISS im Bau. Zurzeit ist sie das größte künstliche Objekt im Erdorbit. Sie kreist in rund 400 km Höhe mit einer Bahnneigung von 51,6° in östlicher Richtung binnen etwa 92 min einmal um die Erde und hat eine räumliche Ausdehnung von etwa 110 m × 100 m × 30 m erreicht. Seit dem 2. November 2000 ist die ISS dauerhaft von Astronauten bewohnt.

Die ISS ist ein gemeinsames Projekt der US-amerikanischen NASA, der russischen Raumfahrtagentur Roskosmos, der europäischen Raumfahrtagentur ESA, sowie der Raumfahrtagenturen Kanadas CSA und Japans JAXA. In Europa sind die Länder Belgien, Dänemark, Deutschland, Frankreich, Italien, die Niederlande, Norwegen, Schweden, die Schweiz und Spanien beteiligt. Im Jahre 1998 wurde dazu ein entsprechendes Abkommen für den Bau der Raumstation unterschrieben.

Brasilien hat mit den USA ein separates Abkommen über die Nutzung der ISS. Die Volksrepublik China hat ihren Wunsch einer Beteiligung an der ISS ausgesprochen, ist aber bisher am Veto der USA gescheitert, weshalb China aktuell an einer eigenen Raumstation arbeitet. Die Raumfahrtagenturen Indiens und Südkoreas haben ebenso eine mögliche Beteiligung an der ISS angekündigt.

Erste Ideen für eine dauerhaft bewohnte Station im Weltall kamen bei der NASA schon sehr früh auf. Zu Beginn der 1960er Jahre, also noch lange vor der ersten Mondlandung, dachte man an eine Raumstation, die von etwa zehn bis zwanzig Personen bewohnt sein sollte. Nach dem Abschluss des Apollo-Programms wandte man sich konkreter dem Bau von Raumstationen zu, um den Anschluss an die Sowjetunion nicht zu verlieren, die 1971 mit Saljut 1 ihre erste Raumstation gestartet hatte. So wurde im Jahre 1973 die US-amerikanische Station Skylab gestartet, die insgesamt 171 Tage bewohnt war. Danach wandten sich die US-Amerikaner jedoch der Entwicklung des Space Shuttles zu, während die Sowjetunion sechs weitere Saljut-Stationen und vor allem die modulare Raumstation Mir in die Umlaufbahn brachte und umfangreiche Erfahrung mit Langzeitflügen sammeln konnte.

Nach dem Erstflug des Space Shuttles im Jahre 1981 rückte das Konzept einer Raumstation wieder in den Blickpunkt, weil diese nach Ansicht der NASA-Strategen der nächste logische Schritt in der Raumfahrt sei. Im Mai 1982 wurde im NASA-Hauptquartier die "Space Station Task Force" geschaffen. Im Januar 1984 kündigte der damalige US-Präsident Ronald Reagan in Anlehnung an den Aufruf Kennedys zur Mondlandung an, es sei das nationale Ziel, eine ständig bemannte Raumstation innerhalb eines Jahrzehnts zu bauen. Die Kosten für eine solche Station wurden damals auf acht Milliarden US-Dollar geschätzt. Ein Jahr später wurde entschieden, die Station zusammen mit internationalen Partnern zu bauen. Daraufhin schlossen sich die ESA sowie Kanada und Japan dem Projekt an. Im Jahre 1988 wurde die geplante Station von Reagan auf den Namen "Freedom" (Freiheit) getauft.

Nach dem Ende des Kalten Krieges wurde eine engere Zusammenarbeit der NASA mit Russland möglich. Das ursprüngliche Freedom-Projekt wurde gekürzt, weil die Kosten der geplanten Raumstation explodierten, und in "Space Station Alpha" umbenannt. 1993 unterzeichneten Russland und die USA ein Abkommen über zehn Shuttle-Flüge zur russischen Raumstation Mir sowie über Langzeitaufenthalte einiger US-Astronauten auf der Mir, später bekannt als das Shuttle-Mir-Programm. Die NASA zahlte dafür 400 Millionen US-Dollar. Dies markierte die erste Zusammenarbeit der beiden Raumfahrtmächte seit dem Apollo-Sojus-Test-Projekt im Jahre 1975.

Unter US-Präsident Bill Clinton wurde dann das Projekt einer großen Raumstation im November 1993 zusammen mit Russland neu aufgelegt – Russland steuerte die Pläne der geplanten Mir-2-Station bei. Auf US-amerikanischer Seite wurde der Name "Alpha" vorgeschlagen, der jedoch von Russland abgelehnt wurde, da die Mir-Station die erste Raumstation war – Alpha ist der erste Buchstabe des griechischen Alphabets. Bis 1998 schlossen sich 13 weitere Länder dem Projekt an: 11 der ESA-Staaten (Großbritannien war Mitunterzeichner des Vertrages, stieg jedoch später aus), Japan und Kanada. Zudem unterzeichnete Brasilien im Oktober 1997 mit den USA einen separaten Vertrag über die Nutzung der Raumstation, die nun den Namen "International Space Station (ISS)" trägt. Im Jahr darauf begann mit dem Start des russischen Fracht- und Antriebmoduls Sarja (Sonnenaufgang) der Aufbau der Station.

Wie die russische Raumstation Mir ist die ISS modular aufgebaut. Einzelne Baugruppen wurden von Trägerraketen und Raumfähren in die Umlaufbahn gebracht und dort zusammengesetzt. Dazu waren rund 40 Aufbauflüge nötig. Insgesamt 37 Shuttleflüge wurden bis zur Ausmusterung der Raumfähren Mitte 2011 durchgeführt. Der amerikanische Teil der Station ist fertig aufgebaut und geht in den Routinebetrieb über. Der Rest wurde und wird von den unbemannten russischen Trägerraketen Proton und Sojus durchgeführt.

Die ISS hat zurzeit eine Masse von 450 Tonnen bei einer Länge der Gitterstruktur von 109 Metern und einer Breite der Solarmodule von 73 Metern. Die endgültige Spannweite ist seit der Installation der ersten Solarzellen bereits erreicht. Damit ist sie die größte Raumstation, die bisher gebaut wurde.

Das erste ISS-Bauteil im All war das von Russland gebaute Fracht- und Antriebsmodul Sarja. Es wurde am 20. November 1998 von einer Proton-Schwerlastrakete in die vorgesehene Umlaufbahn gebracht. Zwei Wochen später kam mit der Space-Shuttle-Mission STS-88 der erste Verbindungsknoten Unity (Node 1) ins All und wurde mit Sarja verbunden. Dieser Knoten verbindet den US-amerikanischen mit dem russischen Teil der Station. Als Nächstes folgten mit STS-96 und STS-101 zwei logistische Shuttle-Flüge, die dem Transport von Ausrüstung zur Station dienten. Zudem wurden weitere Arbeiten am Äußeren des Komplexes ausgeführt.

Als nächstes Modul startete im Sommer 2000 das russische Wohnmodul Swesda. Es wurde ebenfalls von einer Proton-Rakete gestartet und dockte automatisch am Sarja-Modul an. Bei einem weiteren Logistikflug (STS-106) wurden Lebensmittel, Kleidung, Wasser und sonstige Alltagsgegenstände für die erste Stammbesatzung zur Station gebracht. Zudem wurde das für die Aufbereitung der Atemluft zuständige "Elektron"-System installiert. Im Oktober 2000 wurde mit der Mission STS-92 das erste Gittersegment, genannt Integrated Truss Structure Z1, zur Station gebracht. Es sollte vorübergehend als Verbindungsstück zwischen einem Solarzellenträger und dem bewohnten Teil der ISS dienen. Außerdem beherbergt es Apparaturen zur Lageregelung und am Zenit-Dockingport einen kleinen Stauraum. Danach konnte am 2. November 2000 die erste Langzeitbesatzung, ISS-Expedition 1, auf der Station einziehen. Sie startete mit Sojus TM-31 zur Station.

Als nächstes Modul wurde mit der Shuttle-Mission STS-97 das erste von vier großen Solarmodulen zur Station gebracht. Der P6-Kollektor wurde im Dezember 2000 zunächst auf Z1 installiert und lieferte in der Anfangsphase nahezu die gesamte Energie zum Betrieb der Station. Erst im Oktober 2007 wurde das Modul an das Backbordende der ISS umgesetzt. Mit der Mission STS-98 wurde das US-amerikanische Labormodul Destiny zur Station gebracht und an Unity angedockt. Nach einem weiteren Logistikflug wurde mit STS-100 der erste Roboterarm der Station, Canadarm2, sowie mit STS-104 die US-Luftschleuse Quest angeliefert. Dies versetzte die Raumfahrer in die Lage, ohne die Hilfe des Shuttles Weltraumausstiege durchzuführen und zum Aufbau der Station beizutragen.

Am 14. September 2001 startete das russische Kopplungsmodul Pirs, das sowohl zum Andocken von Sojus- und Progress-Raumschiffen als auch für Ausstiege in russischen Raumanzügen genutzt wurde. Für den Start dieses Moduls wurde zum ersten Mal eine Sojus-Rakete und eine modifizierte Progress verwendet. Bis zum Start von Poisk im Jahr 2009 blieb es lange Zeit das einzige Modul, das auf diese Weise gestartet wurde.

Darauf wurden drei weitere Elemente der Gitterstruktur der Station gestartet. Die Elemente S0, S1 und P1 bildeten das Gerüst, an dem später die weiteren Ausleger mit den zugehörigen Solarzellen befestigt wurden.

In den folgenden Missionen wurden das Gerüst und die Stromversorgung weiter ausgebaut. Zunächst wurden von STS-115 im September 2006 auf der Backbordseite ein Stück Gitterstruktur und ein großes Solarmodul (P3/P4) angebaut und drei Monate später um das Gitterelement P5 verlängert (STS-116). Im Juni 2007 folgten auf der Steuerbordseite mit der Mission STS-117 ein weiteres Gitterelement mitsamt einem Solarmodul (S3/S4) und zwei Monate später die Verlängerung S5 (STS-118).

Im Oktober 2007 wurde mit STS-120 der Verbindungsknoten Harmony (Node 2) zur ISS gebracht. Außerdem versetzte die STS-120-Mannschaft das Solarmodul P6 an seinen endgültigen Platz am linken Ende des Gerüsts. Nachdem die Discovery die ISS verlassen hatte, wurde durch die 16. Langzeitbesatzung der Shuttle-Andockadapter (PMA-2) von Destiny auf Harmony umgesetzt und die Baugruppe Harmony/PMA-2 auf der endgültigen Position an der Stirnseite von Destiny angedockt. Nach über sechs Jahren Pause war dies die erste Erweiterung des von den ISS-Besatzungen nutzbaren Lebensraumes auf der ISS.

Das europäische Forschungsmodul Columbus wurde am 11. Februar 2008 an der ISS installiert. Am 3. Juni 2008 wurde die Installation des japanischen Hauptmoduls von Kibō abgeschlossen. Durch STS-119 wurde im März 2009 das vierte und letzte Solarmodul S6 installiert. Im Mai 2009 wurde die Besatzung der ISS auf sechs Raumfahrer aufgestockt. Das letzte Bauteil des Kibō-Moduls wurde Mitte Juli durch STS-127 installiert. Im November 2009 erreichte das russische Kopplungsmodul Poisk die Station. Im Februar 2010 wurde der Verbindungsknoten Tranquility (Node 3) mit der Aussichtskuppel Cupola installiert. Im Mai 2010 folgte das russische Modul Rasswet, das PMM Leonardo im März 2011. Am 23. Oktober 2010 löste die ISS mit 3644 Tagen die Mir als das Raumfahrzeug, das am längsten dauerhaft mit Menschen besetzt war, ab. Dieser Rekord wurde bis heute () auf Tage ausgedehnt. Das AMS-Experiment wurde im Mai 2011 mit dem vorletzten Shuttleflug installiert. Im März 2019 soll die Station mit dem russischen Labormodul Naúka (MLM) weiter komplettiert werden.

Nachdem die ISS-Partner den Betrieb der Raumstation bis mindestens 2024 vereinbarten, plant Russland den Anbau dreier weiterer Module, die einem neuen Konzept entspringen. 2019 soll zunächst das kugelförmige Kopplungsmodul Pritschal am unteren Ende des MLM Naúka angebracht werden. Hier sollen ab 2021 zwei große Forschungs- und Energiemodule (NEM 1 und 2) angekoppelt werden.

Eine Liste aller ISS-Module geordnet nach dem Zeitpunkt des Starts ist unter Liste der ISS-Module zu finden.
Sollte die Station nicht mehr weiter betrieben werden, ist ein gezielter Wiedereintritt in die Erdatmosphäre über dem Südpazifik geplant. Damit soll unter anderem Weltraumschrott vermieden werden, es soll aber auch sichergestellt werden, dass die Reste der Station über unbewohntem Gebiet niedergehen.

Am 8. Januar 2014 gab die NASA bekannt, dass die Station nach Absprache mit den internationalen Partnern bis mindestens 2024 weiter betrieben werden soll. Wegen des sich entwickelnden Konfliktes in der Ostukraine stellte sie im Mai 2014 die Kooperation mit Roskosmos zum Teil ein, für den ISS-Betrieb waren jedoch keine Abstriche geplant. Daraufhin erklärte Russlands Vizeregierungschef Dmitri Rogosin am 13. Mai 2014: „Wir wollen die Ressourcen auf andere perspektivische kosmische Projekte richten.“ Das russische ISS-Segment könne nach 2020 allein betrieben werden, „aber das amerikanische nicht unabhängig vom russischen“. Ohne Russland müssten die Amerikaner ihre Astronauten „mit dem Trampolin zur ISS bringen“.

Am 24. Februar 2015 gab Roskosmos bekannt, bis ca. 2024 die ISS weiterzubetreiben und danach mit den bestehenden russischen Modulen eine eigene Raumstation aufbauen zu wollen.
Technisch wäre ein Betrieb der ISS bis 2028 denkbar.

Die ISS befindet sich in einer annähernd kreisförmigen niedrigen Erdumlaufbahn (LEO) mit einer Bahnneigung von etwa 51,6° gegen den Äquator und umrundet die Erde etwa alle eineinhalb Stunden in östlicher Richtung. Durch die geringe Exzentrizität der Bahnellipse schwankt die Höhe während eines Umlaufs zwischen Perigäum und Apogäum um maximal 20 Kilometer. Die mittlere Bahnhöhe nimmt durch den Luftwiderstand der Station um 50 bis 150 m pro Tag ab. Diesem Höhenverlust wird je nach Erfordernissen des Stationsbetriebs in unregelmäßigen Abständen durch Triebwerkszündungen von Sojus, Progress, ATV oder dem Swesda-Modul unter Aufwendung von etwa 7.000 Kilogramm Treibstoff pro Jahr entgegengewirkt. Das Heben der abgesunkenen ISS erfolgt durch Beschleunigungen in Flugrichtung der Station. Auf diese Weise wurde die mittlere Höhe der Station zunächst zwischen etwa 330 und 400 Kilometern gehalten. In der Vergangenheit hat auch das Shuttle einen großen Anteil zum Ausgleich dieses Höhenverlustes beigetragen. Seit Juni 2011 wurden mehrfach größere Bahnanhebungen durchgeführt, um die mittlere Höhe zunächst auf etwa 380 km und ab Ende 2012 auf mehr als 400 km zu bringen. Dadurch reduziert sich der Einfluss der oberen Atmosphäre und damit auch der tägliche Höhenverlust. Außerdem dient diese Anhebung einer Anpassung der Umlaufzeit und Bahn an die Anforderungen eines schnelleren Anfluges für die bemannten Sojus-Raumschiffe. Die mittlere Bahnhöhe, als Differenz von großer Halbachse der Bahnellipse und Erdradius, berechnet sich aus der mittleren Bewegung. Dieser Parameter gibt die Umläufe pro Tag an und ist in regelmäßig veröffentlichten TLE-Datensätzen der Satellitenbahnelemente enthalten (siehe Weblinks: Heavens-Above).

Die Lage der Bahn relativ zur Sonne bestimmt die Länge der Orbitalen Nacht. Übersteigt der Winkel (Beta) zwischen Bahnebene und Sonnenrichtung Werte von 60°, wird die Nachtphase so kurz, dass die Station speziell ausgerichtet werden muss, um nicht zu viel Wärme aufzunehmen. Space-Shuttle-Besuche fanden in solchen Zeiten nicht statt, da angedockte Shuttles überhitzt worden wären. Diese Phase wird deshalb "beta-angle cutout" oder einfach "beta cutout" genannt.

Die Modulachsen der ISS sind parallel zur Erdoberfläche orientiert. Wie der Mond wendet sie der Erde also stets dieselbe „Unter“-Seite zu. Einem Beobachter, der sie nachts bei passender Sicht 10° über dem Horizont auftauchen sehen kann, zeigt sie jedoch erst ihren „Bug“ (schräg von unten), zuletzt ihr „Heck“.

Die Sonnenpaddel werden als am Korpus drehbare Teile entsprechend der Sonne nachgeführt. Dies gilt nicht während des Überfliegens der Nachtseite der Erde, dann werden die Sonnenpaddel so ausgerichtet, dass sie der oberen Atmosphäre möglichst wenig Widerstand bieten. Bewegungen der Sonnenpaddel, die sich symmetrisch nicht ausgleichen, werden durch Gyroskope aufgenommen, ebenso wie der Impuls eines sich innerhalb der ISS abstoßenden Astronauten (und sein Abfangen).

Die Versorgung der Besatzung mit Lebensmitteln, Frischwasser, Kleidung, Sauerstoff sowie Ersatzteilen und wissenschaftlichen Experimenten wurde bis März 2008 ausschließlich durch russische Progress-Frachter und US-amerikanische Space Shuttles sichergestellt. Von April 2008 bis August 2014 stand hierfür zusätzlich das europäische Automated Transfer Vehicle (ATV) zur Verfügung. Im September 2009 erfolgte der Erstflug des japanischen Versorgungsschiffes H-2 Transfer Vehicle (HTV) zur ISS, 2012 der des Frachters Dragon und 2013 der des Frachters Cygnus.

Die russischen Progress-Transportraumschiffe stellen die Grundversorgung für die Station sicher. Die von dem Sojus-Raumschiff abgeleiteten unbemannten Transporter sind in der Lage, bei durchschnittlich vier Flügen pro Jahr die ISS allein zu versorgen, sofern sie nur von zwei Personen bewohnt wird. Dies musste während des Flugverbots der Shuttle-Flotte nach dem Columbia-Absturz 2003 durchgeführt werden. Bei höherer Startfrequenz können auch größere Besatzungen versorgt werden.

Die Raumschiffe sind nicht wiederverwendbar. Nach dem Andocken an einem Port am russischen Teil der Station werden die rund 2,5 Tonnen Fracht und Treibstoff zur Station transferiert. Anschließend wird Progress mit Müll gefüllt, nach mehreren Monaten wieder abgekoppelt und in der Erdatmosphäre zum Verglühen gebracht.

Ein Nachteil der Progress-Raumschiffe ist der kleine Durchmesser der Verbindungsluken, weshalb sperrige Nutzlasten und Ersatzteile (wie z. B. Gyroskope) nicht von Progress angeliefert werden können. Russland setzt für Transporte zur ISS die Progress-Versionen "Progress M", "Progress M1" und "Progress M1M" ein. Die ersten beiden Versionen wurden bereits zur Versorgung der Raumstation Mir verwendet und unterscheiden sich im Wesentlichen lediglich im Anteil des Treibstoffes, der mitgenommen werden kann. "Progress M1M" wurde erstmals am 26. November 2008 eingesetzt und hat eine deutlich höhere Nutzlastkapazität.

Das Multi-Purpose Logistics Module (MPLM) war ein bei Alenia Spazio in Italien gebautes Versorgungsmodul, welches in der Nutzlastbucht des Space Shuttles zur Raumstation gebracht wurde. Die Nutzlastkapazität war mit ca. 9,1 Tonnen höher als die der Progress-Raumschiffe. Die Module sollten maximal 25-mal verwendbar sein und Ausrüstungsgegenstände zur Station oder Resultate von Experimenten zurück zur Erde zu bringen. Nach dem Andocken des Shuttles wurde das Modul von dem Roboterarm des Shuttles aus der Ladebucht der Raumfähre gehievt und anschließend mit dem Canadarm2 an einem Kopplungsstutzen der Raumstation angedockt. Nach dem Transfer der Fracht zur ISS wurde das MPLM mit den Ergebnissen abgeschlossener Experimente, aber auch Müll, beladen und vom Shuttle wieder zur Erde zurückgebracht. Insgesamt kamen zwischen 2001 und 2011 zwei der Module bei zwölf Shuttle-Missionen zum Einsatz. Eines der Module wird heute nach einer Modifikation als permanentes Modul der ISS genutzt.

Von 2008 bis 2014 leistete auch die ESA einen Beitrag zur Versorgung der Station. Dies geschah mit dem ATV (Automated Transfer Vehicle), das wie die russischen Progress-Schiffe Fracht transportierte. Die Nutzlast eines ATV beträgt mit 7,5 Tonnen in etwa das Dreifache eines Progress-Transporters. Davon können etwa 4,5 Tonnen Treibstoff sein, der genutzt wird, um die Bahn der ISS anzuheben. Dies ist regelmäßig erforderlich, da sie durch die Reibung an der Restatmosphäre zwischen 50 und 150 Meter pro Tag an Höhe verliert.

Das erste ATV wurde am 9. März 2008 unter dem Namen „Jules Verne“ von einer Ariane-5-Rakete gestartet und dockte am 3. April erfolgreich an der Raumstation an, am 21. und 25. April hob es die Umlaufbahn der Station um insgesamt 6,4 km an und am 29. September 2008 verglühte „Jules Verne“ mit 6,3 Tonnen Müll der Station planmäßig über dem Pazifik. Der Vertrag der ESA umfasst insgesamt fünf ATV-Flüge. Ab 2010 war bis einschließlich 2013 jedes Jahr ein weiterer Einsatz geplant. Aufgrund einer guten Versorgungslage und Verzögerungen im Shuttle-Programm kam es jedoch zu Verschiebungen. Das ATV-2 „Johannes Kepler“ startete im Februar 2011 zur Station, ATV-3 „Edoardo Amaldi“ dockte am 29. März 2012 an der ISS an. Am 15. Juni 2013 dockte ATV-4 „Albert Einstein“ an die ISS an und am 12. August 2014 das letzte ATV-5 „Georges Lemaître“.

Für die Kopplung wurde ein lasergestütztes automatisches System genutzt, mit dem das ATV am hinteren Andockstutzen des russischen Swesda-Moduls anlegen kann. Dort befinden sich die benötigten Andockhilfen (Antennen und Laser-Reflektoren).

Ein ähnliches Transportfahrzeug wurde auch von der japanischen Weltraumagentur JAXA entwickelt und nach der verwendeten Trägerrakete H-IIB auf den Namen H-2 Transfer Vehicle (HTV) getauft. Mittlerweile wurde der Name Kounotori (dt. Weißstorch) für die Frachtraumschiffe ausgewählt. Die Größe des HTV entspricht in etwa der eines Busses; die Nutzlast beträgt rund sechs Tonnen. Im Gegensatz zum ATV ist der japanische Transporter nicht in der Lage, ein automatisches Andockmanöver durchzuführen, sondern wird vom Roboterarm der Station eingefangen und an einem freien Kopplungsstutzen im US-Teil der Station befestigt. Der Erstflug des HTV wurde am 10. September 2009 gestartet. Es wurde erfolgreich am 17. September an das ISS-Modul Harmony angedockt.

Um nach der Beendigung des Space-Shuttle-Programms Mitte 2011 auch weiterhin die Station unter US-amerikanischer Leitung versorgen zu können, hat die NASA das COTS-Programm aufgelegt. Dadurch soll die Versorgung mit Material und Besatzung sichergestellt werden. Nach einem ersten Wettbewerb wurden im August 2006 die beiden privaten Unternehmen SpaceX und Rocketplane Kistler beauftragt, entsprechende Raketen sowie Besatzungs- und Logistik-Module zu entwickeln. Nachdem Rocketplane Kistler die Zusagen bezüglich der Einwerbung von Drittmitteln nicht hatte einhalten können, wurde die Beteiligung der Firma seitens der NASA im Oktober 2007 aufgekündigt. In einem zweiten Wettbewerb wurde im Februar 2008 das Unternehmen Orbital Sciences Corporation beauftragt.

Seit Mai 2012 führt SpaceX Materialtransportflüge zur ISS durch und kann im Gegensatz zu HTV und ATV mit dem Dragon-Raumschiff Material und Forschungsergebnisse auch wieder zur Erde zurückbringen. Der Transport von Menschen ist derzeit noch nicht möglich, ein entsprechendes Raumfahrzeug mit der Bezeichnung Dragon V2 ist aber in der Entwicklungsphase und soll voraussichtlich im August 2018 seinen Erstflug antreten. Entsprechende Anpassungen durch die Vorbereitung zur Montage eines "International Docking Adapter" (IDA) wurden bei Außenbordarbeiten während Expedition 42 getroffen.

Seit September 2013 führt Orbital Sciences mit dem Cygnus-Raumtransporter Materialtransportflüge zur ISS durch.

Die Raumstation ist seit dem 2. November 2000 permanent besetzt. Die jeweiligen Langzeitbesatzungen tragen die Bezeichnung „ISS-Expedition“ und eine fortlaufende Zahl. Zunächst starteten jeweils drei Raumfahrer (Kommandant und zwei Bordingenieure) gemeinsam zur ISS, um für sechs bis sieben Monate dort zu bleiben. Die Langzeitbesatzungen wurden anfangs jeweils durch Shuttle-Missionen ausgetauscht. Nach dem Unglück des Space Shuttles Columbia am 1. Februar 2003 standen die Space Shuttles längere Zeit nicht mehr für die Versorgung der Station zur Verfügung. Die Besatzungsgröße wurde deshalb ab der ISS-Expedition 7 auf zwei Personen reduziert und der Besatzungsaustausch wurde auf Sojus-Raumschiffe umgestellt. Mit der Shuttle-Mission STS-121 wurde der Deutsche Thomas Reiter im Juli 2006 als erster ESA-Raumfahrer zu einem Langzeitaufenthalt auf die ISS gebracht. Damit hatte die Station wieder drei Besatzungsmitglieder. Seitdem wurden zwei Raumfahrer durch Sojus-Raumschiffe ausgewechselt, der Dritte wurde jeweils per Space Shuttle zur Station bzw. zurück zur Erde gebracht. Seit der Rückkehr von Nicole Stott mit STS-129 wird der Mannschaftsaustausch ausschließlich über Sojus-Raumschiffe abgewickelt.

Mit der Ankunft von Sojus TMA-15 am 29. Mai 2009 begann die ISS-Expedition 20. Damit befanden sich erstmals sechs Besatzungsmitglieder dauerhaft auf der ISS und es standen entsprechend zwei Sojus-Raumschiffe für eine eventuelle Evakuierung der Station zur Verfügung. Die NASA schätzt die Wahrscheinlichkeit für eine Evakuierung innerhalb eines Zeitraumes von sechs Monaten mit 1:124 ab (2008). Eine Übersicht über alle Langzeitbesatzungen gibt die Liste der ISS-Expeditionen.

Die ersten zwölf Expeditionen bestanden ausschließlich aus russischen und US-amerikanischen Raumfahrern. Seit ISS-Expedition 13 absolvierten regelmäßig auch einzelne Astronauten der ESA, JAXA und CSA einen Langzeitaufenthalt auf der ISS. Neben den Langzeitbesatzungen haben bereits zahlreiche andere Raumfahrer aus den verschiedenen Nationen die ISS besucht. Während ihr Sojus-Raumschiff bzw. das Space Shuttle an der ISS angekoppelt war, arbeiteten deren Besatzungen für etwa ein bis zwei Wochen auf der ISS und kehrten anschließend zurück.

Insgesamt haben bereits 230 Personen die ISS besucht, davon absolvierten (bzw. absolvieren) 108 einen oder mehrere Langzeitaufenthalte. Sieben Besucher waren Weltraumtouristen, die sich für je etwa zwanzig Millionen US-Dollar einen Flug mit einem Sojus-Raumschiff gekauft haben und sich jeweils ungefähr eine Woche auf der Station aufhielten, einer davon, Charles Simonyi, sogar bereits zwei Mal. Eine alphabetische Übersicht gibt die Liste der Raumfahrer auf der Internationalen Raumstation, eine chronologische Übersicht bietet die Liste bemannter Missionen zur Internationalen Raumstation.

Die längste Mission war die ISS-Expedition 14 mit 215 Tagen, 8 Stunden und 22 Minuten und 48 Sekunden. Sie bedeutete den US-Rekord für Michael López-Alegría.

Am 29. März 2013 flog die Besatzung der Mission Sojus TMA-08M das erste Mal in der Rekordzeit von knapp sechs Stunden zur ISS, bislang waren dafür zwei Tage nötig.

Anlässlich seines Rückflugs zur Erde wurden am 12. Mai 2013 im Internet eine vom kanadischen ISS-Kommandanten Chris Hadfield eingesungene Coverversion von David Bowies "Space Oddity" und ein auf der Raumstation gedrehtes Musikvideo veröffentlicht. Innerhalb von vier Tagen wurde dieser Clip über zwölf Millionen Mal angesehen.

Seit 2008 befindet sich ein Geocache auf der Raumstation, welcher vom Weltraumtourist Richard Garriott während seines Aufenthaltes dort gelegt wurde.
Grundsätzlich unterscheidet man unter Druck stehende und nicht unter Druck stehende Module. Sämtliche Module, die von den Astronauten zum Wohnen, Schlafen und zur Arbeit benutzt werden, stehen unter Druck, da Menschen im Vakuum nicht überleben können. Das Lebenserhaltungssystem an Bord sorgt für eine Atmosphäre, die der irdischen entspricht (21 Prozent Sauerstoff, 78 Prozent Stickstoff, 1014 Hektopascal Druck). Zu den unter Druck stehenden Modulen zählen zum Beispiel das US-amerikanische Destiny-Labor oder das russische Modul Sarja. Solarzellen oder Gitterstrukturen stehen nicht unter Druck.

Sarja ( für „Morgenröte“) war das erste Modul der ISS. Es wurde von Russland gebaut und gestartet, aber von der NASA finanziert. In der ersten Ausbaustufe stellte es Strom sowie die Möglichkeiten zur Navigation zur Verfügung. Heute wird es als Frachtmodul für die Zwischenlagerung von Ausrüstungsteilen verwendet. Seit August 2012 dient der kugelförmige Kopplungsknoten Sarjas als Stützpunkt für den russischen Kran Strela-2.

Der Pressurized Mating Adapter 1 ist der ständig unter Druck stehende Adapter zwischen Sarja und dem Unity-Verbindungsknoten. Außerdem wird PMA-1 als Stauraum genutzt.

Der Unity-Verbindungsknoten (Node 1) (engl. für "Einigkeit", "Eintracht") verbindet den russischen Teil über einen Adapter mit dem Rest der Station und verfügt über insgesamt sechs Kopplungsstutzen. Teilweise wird der Knoten auch als Stauraum für Nahrungsmittel genutzt, wenn kurz nach der Ankunft von Progress-Frachtern im Sarja-Modul nicht ausreichend Platz ist.

Swesda (russisch für „Stern“) oder DOS-8 ist das russische Wohn- und Servicemodul der Station. Es beinhaltet Steuereinrichtungen, Lebenserhaltungssysteme, hygienische Einrichtungen, Küche, Trainingsgeräte und mehrere Wohnkabinen. Am hinteren Kopplungsstutzen von Swesda docken Sojus-Raumschiffe und Progress-Frachter, sowie auch das europäische ATV an.

Das Destiny-Modul (engl. für "Schicksal", "Vorsehung") ist das US-amerikanische Labormodul der ISS. Es bietet insgesamt Platz für 24 Racks, die für Experimente, Steuerungseinheiten oder als Stauraum genutzt werden können. Im Labor werden Experimente auf den Gebieten Mikrogravitation, Lebenswissenschaften, Biologie, Ökologie, Erderkundung, Weltraumforschung und Technologie durchgeführt.
Quest (engl. für "Streben", "Suche") ist die US-amerikanische Luftschleuse der ISS. Sie ermöglicht das Verlassen der Station in US-amerikanischen Raumanzügen für Wartungs- und Reparaturarbeiten außerhalb der ISS. In der Luftschleuse werden auch die US-amerikanischen Raumanzüge sowie Werkzeuge für den Außenbordeinsatz gelagert.
Pirs (russisch für Pier) oder Stykowoi Otsek 1 (SO 1) ist die russische Luftschleuse. Sie wird für Ausstiege in russischen Orlan-Anzügen benutzt. Im Gegensatz zu Quest kann Pirs jedoch auch als Kopplungsadapter für anfliegende Sojus-Raumschiffe oder Progress-Frachter genutzt werden.

Harmony (Node 2) (engl. für "Harmonie", "Eintracht") ist ein Verbindungsknoten, der am Destiny-Modul angedockt ist. Er bietet weitere Anschlussmöglichkeiten für das Kibō-Modul, das Columbus-Modul sowie für MPLM-Module bzw. HTV-Transporter. Es verfügt über acht Racks, die zur Versorgung der Station mit Luft, Elektrizität und Wasser dienen sowie andere lebensnotwendige Systeme enthalten oder als Stauraum fungieren.

Columbus ist das europäische Labormodul der ISS. Es enthält Platz für insgesamt zehn Racks, die unter anderem für Experimente der Material- und Biowissenschaften sowie der Flüssigkeitsforschung genutzt werden sollen.

Der japanische Beitrag zur ISS heißt Kibō (japanisch für „Hoffnung“). Das System besteht aus vier Modulen, die mit den Missionen STS-123, STS-124 und STS-127 ins All gebracht wurden.

Seit Mitte 2017 wird in Kibō die Kamera-Drohne "Int-Ball" erprobt. Sie soll die Astronauten von Fotografiearbeiten entlasten sowie in Kooperation mit Bodenpersonal die Durchführung von Experimenten verbessern.

Im November 2009 wurde das russische Kopplungsmodul Poisk (russisch für „Suche“, auch Maly Issledowatelski Modul 2, kurz MIM 2 oder MRM-2) mit einer Sojus-Rakete zur ISS gebracht. Poisk ist nahezu baugleich mit der Luftschleuse Pirs und wird diese ergänzen und voraussichtlich ab 2014 ersetzen. Zusätzlich wird Poisk auch für externe wissenschaftliche Experimente verwendet. Das Modul ist am Zenitdockingport von Swesda angekoppelt. Seit Februar 2012 ist Poisk der Stützpunkt für den russischen Kran Strela-1.

Tranquility (engl. für "Ruhe") ist ein Verbindungsknoten, der am Unity-Verbindungsknoten angedockt ist. Er enthält Systeme zur Wasser- und Luftaufbereitung, zusätzlichen Stauraum sowie Koppelungsstutzen zum Andocken von weiteren Modulen. Tranquility wurde zusammen mit der Aussichtsplattform Cupola im Februar 2010 mit der Shuttle-Mission STS-130 zur ISS gebracht.

Cupola (ital. für "Kuppel") ist ein mehrteiliges Aussichtsfenster mit einem Durchmesser von knapp 3 Metern und einer Höhe von 1,5 Metern. Cupola hat 6 große seitliche Fenster sowie ein großes Mittelfenster mit 80 Zentimetern Durchmesser. Cupola wurde im Februar 2010 zur ISS gebracht und am Nadir-Dockingport Tranquilitys befestigt.

Rasswet (russisch für „Morgendämmerung“, auch Docking Cargo Module oder Maly Issledowatelski Modul 1 – MIM 1) wurde im Mai 2010 mit der Shuttle-Mission STS-132 zur ISS gebracht und an das Sarja-Modul angedockt. Dort stellt es einen Andockplatz für Sojus- und Progress-Schiffe bereit, um die seit 2009 steigende Anzahl dieser Schiffe bedienen zu können.

Mit der Mission STS-133 wurde im Februar 2011 neben ELC-4 das modifizierte MPLM Leonardo zur ISS gebracht und bleibt nun dauerhaft an der ISS.

Die NASA und die Firma Bigelow Aerospace vereinbarten Bau und Test des aufblasbaren Testmoduls BEAM (Bigelow Expandable Activity Module) für die Internationale Raumstation. Das Modul mit etwa 16 m³ Rauminhalt (im verpackten Zustand 3,6 m³) wurde im April 2016 mit der Mission CRS-8 im drucklosen Teil des Dragon-Raumfrachters zur ISS gestartet und an den Achtern-Port des Tranquility-Moduls angedockt. Im Mai 2016 wurde das Modul aufgeblasen, der Druck in dem Modul soll für die nächsten zwei Jahre gehalten werden, um das Modul auf seine Eignung zu testen.

Die Pressurized Mating Adapter 2 und 3 stehen nach Ankopplung eines Raumschiffs vollständig unter Druck. Die Stationsseite der PMAs kann außerhalb von Kopplungen separat unter Druck gesetzt werden und wird dann als Stauraum genutzt.

Der International Docking Adapter 2 ist ein an PMA-2 installierter Kopplungsadapter gemäß dem International Docking System Standard. IDA-2 startete am 18. Juli 2016 mit der Mission CRS-9 als Außenlast des Dragon-Raumfrachters und wurde am 19. August 2016 während eines Außenbordeinsatzes an der ISS befestigt.

Das eigentliche Gerüst der Station wird Integrated Truss Structure genannt. Es ist senkrecht zur Flugrichtung ausgerichtet und besteht aus elf Elementen. Die Elemente P1, P3/P4, P5 und P6 sind in Flugrichtung links angeordnet (von engl. ‚Backbord‘). Auf der rechten Seite („S“ wie engl. ‚Steuerbord‘) werden die Elemente S1, S3/S4, S5 und S6 genannt. Das Element S0 liegt in der Mitte und ist über das Destiny Labor mit dem bewohnten Teil der Station verbunden. Das P6-Element war das erste der vier großen US-amerikanischen Solarmodule und wurde zunächst oberhalb des Z1-Elements angebracht. Im Rahmen der STS-120-Mission wurde es an seiner endgültigen Position am P5-Element befestigt. Die Elemente P2 und S2 waren ursprünglich als Antriebselemente gedacht, wurden aber durch die russische Beteiligung an der Station überflüssig.

Neben den kleineren Solarzellen an den russischen Modulen, die vor allem zu Baubeginn genutzt wurden, hat die ISS vier große Solarelemente. Diese sind an den Elementen P6 und P4 auf der linken bzw. S6 und S4 auf der rechten Seite angebracht. Die Elemente können um zwei Achsen gedreht werden, um immer optimal auf die Sonne ausgerichtet zu sein.

Überschüssige Wärme wird über Abstrahler abgeführt. Dreireihige Abstrahler finden sich auf den zentralen Truss-Elementen S1 und P1. Zusätzlich gehört zu jedem Solarmodul ein kleinerer Abstrahler. Die Radiatoren bilden die logischen Gegenstücke zu den Solarpanelen, die der Station Energie zuführen, und verhindern damit einen Hitzestau in der Station.

Der Roboterarm der Station wird (in Anlehnung an den Canadarm des Shuttles) Canadarm2 oder SSRMS (Space Station Remote Manipulator) genannt. Der Arm kann eine Masse von bis zu 100 Tonnen bewegen und wird vom Innern des Destiny-Labors aus gesteuert. Dazu stehen vier Kameras zur Verfügung – direkter Blickkontakt ist also nicht notwendig. Seit der Installation Cupolas kann der Roboterarm auch von dort aus bedient werden. Der Arm ist nicht an einer festen Stelle der Station montiert, sondern kann mit einem von mehreren Konnektoren, die über die ganze Station verteilt sind, befestigt werden. Dazu hat der Arm an beiden Enden eine Greifmechanik. Zudem kann der Arm auf den Mobilen Transporter gesetzt und so auf Schienen die Gitterstruktur entlanggefahren werden.

Dextre ist der Spitzname der „Roboterhand“, deren technische Bezeichnung Special Purpose Dexterous Manipulator (SPDM) lautet. Das mit zwei Armen und Händen ausgestattete Element kann als Endstück für den Roboterarm der Station genutzt werden, ist aber auch davon unabhängig einsetzbar. Dextre verfügt über sehr viele Gelenke und Vorrichtungen, zum Beispiel ausfahrbare Inbusschlüssel. Damit können auch komplexere Arbeiten außerhalb der Station ohne die Hilfe der Astronauten vorgenommen werden.

Strela bezeichnet zwei Kräne russischer Bauart, die im Rahmen von Außenbordeinsätzen für Materialtransporte und zum Transport von Raumfahrern benutzt werden. Anfangs waren beide Kräne am Modul Pirs befestigt, im Jahr 2012 wurden Strela-1 zum Modul Poisk und Strela-2 zum Lagermodul Sarja versetzt. Mit rund 18 Metern Reichweite ist Strela in der Lage, einen Großteil des russischen Segmentes der Station zu erreichen.

Eine Plattform für Experimente im freien Weltraum. Sie gehört zum japanischen System Kibō, ist an der Stirnseite des "Pressurized Module" befestigt und kann mit einer recht großen Zahl von Experimenten bestückt werden. Die Plattform wurde im Juli 2009 mit der Shuttle-Mission STS-127 zur Station gebracht.

Die EXPRESS Logistics Carrier (ELC) bieten zusätzliche Experimentierfläche im luftleeren Raum. Die Module ELC-1 und ELC-2 wurden mit der Shuttle-Mission STS-129 im November 2009 und ELC-4 mit STS-133 Ende Februar 2011 an der ISS installiert. ELC-3 wurde im Mai 2011 mit der Mission STS-134 angebracht. ELC-5 wurde zu Gunsten des MRM1 abgesagt.

Das Alpha-Magnet-Spektrometer-Experiment (AMS) ist die Bezeichnung für einen modernen Teilchendetektor zur Untersuchung der kosmischen Höhenstrahlung, der am 19. Mai 2011 mit STS-134 an der ISS angebracht wurde.

Der Ausleger des Orbiter Boom Sensor Systems der Endeavour wurde bei der Mission STS-134 permanent auf der ISS deponiert. Dazu mussten einige Modifikationen am OBSS vorgenommen werden u. a. bei einer Greifkupplung, um sie zum Roboterarm der Station kompatibel zu machen. Die Nützlichkeit des Verlängerungsarms hat sich z. B. bei der Reparatur des P6-Sonnenkollektors während der Mission STS-120 erwiesen.

Der "Neutron star Interior Composition ExploreR" ist im Juni 2017 mit einer Dragon-Kapsel zur ISS gebracht und dort installiert worden. Es besteht aus 56 einzelnen Röntgendetektoren und soll Spektraldaten von Neutronensternen erfassen, um deren exotische Materie besser zu verstehen.

Im August 2018 soll an das Kopplungsmodul PMA-3 ein weiterer Adapter nach dem International-Docking-Standard angebaut werden. Dafür wurde im März 2017 PMA-3 von Tranquility (Node 3) auf den Zenit-Port von Harmony (Node 2) am Bug der Station verlegt. Damit stünden dann zwei Kopplungsstutzen für anfliegende Raumschiffe US-amerikanischer Bauart (Dragon-Raumschiff/CST-100/Dream Chaser) bereit.

Das russische Labormodul Naúka (MLM, russisch für Mehrzweck-Labor-Modul) soll am 21. März 2019 (ursprünglich geplant Ende 2011) mit einer Proton-M-Rakete zusammen mit dem European Robotic Arm zur ISS gebracht werden. Das Modul soll sowohl Platz für wissenschaftliche Experimente bieten, als auch Lagerräume und Räume für die Mannschaft enthalten. Es soll außerdem über Triebwerksysteme verfügen, die zur Lagekorrektur der Station eingesetzt werden können. An der Außenseite werden das ESA-Manipulatorsystem European Robotic Arm (ERA), ein Radiator und eine Experimentierschleuse montiert.

Der European Robotic Arm ist ähnlich wie Canadarm2 ein Roboterarm. Er verfügt im Gegensatz zum Canadarm2 jedoch über Greifmechanismen, die für den russischen Teil der ISS ausgelegt sind. Der Arm hat eine Länge von über 11 m und kann bei einer Eigenmasse von 630 kg mit einer Genauigkeit von unter 5 mm etwa 8 Tonnen Nutzlast positionieren. Der European Robotic Arm soll die Einsatzzeit bei Außenarbeiten (EVA) verringern und verschiedene Aufgaben halb- und vollautomatisch durchführen.

Aufgrund der vertraglichen Verlängerung der Betriebsdauer der Internationalen Raumstation bis mindestens 2024 plant Russland die Erweiterung seines Segments um zwei oder drei weitere Module, die ursprünglich für die nächste Generation von Raumstationen entwickelt werden sollten. Im Januar 2011 wurden Bau und Start eines kugelförmigen Verbindungsmoduls genehmigt. Das Uslowoi Modul (UM) ist kugelförmig, bietet einen Rauminhalt von etwa 14 Kubikmetern und hat eine Masse von 4 Tonnen. Es ist mit sechs Kopplungsstutzen rundum ausgestattet und soll am Nadir-Dockingport von Naúka angedockt werden. Hier stehen dann fünf Kopplungsstellen für zusätzliche Module sowie unbemannte oder bemannte Raumschiffe zur Verfügung.

Das technische Konzept für ein freifliegendes Labor für Mikrogravitationsforschung wurde Ende 2012 beauftragt. Die Realisierung war bis Ende 2018 vorgesehen. Dabei handelt es sich um ein knapp 8 t schweres Raumfahrzeug, in dem regelmäßig betreute Experimente z. B. zur Nanotechnologie, Nanoelektronik oder Molekularstrahlepitaxie unter besonders guter Mikrogravitation, besser als 1 µg (Mikro-g) sowie hinter einem Schild besonders guten Vakuumbedingungen absolviert werden können. Autonom soll OKA-T 90 bis 180 Tage operieren und nach Abschluss der Experimente und Fixierung der Proben an der Internationalen Raumstation ankoppeln und neu bestückt werden.

Im Dezember 2012 wurde der Auftrag für den Bau eines Wissenschafts- und Energiemoduls (NEM) an Energija vergeben. Das Modul soll eine Masse von etwa 21 Tonnen besitzen und am Kopfende mit nachführbaren Solarzellenpaneelen ausgerüstet sein. Diese sollen eine Leistung von 18 kW zur Verfügung stellen. Ein druckbeaufschlagter zylindrischer Teil von etwa 5,8 Metern Länge bei 4,30 m Durchmesser soll Raum für wissenschaftliches Arbeiten bieten. NEM 1 soll seitlich am Kopplungsmodul UM angebracht werden. Eventuell folgt diesem ein zweites, ähnliches Modul. Die neuen Module inklusive Naúka könnten nach 2024 auch von der ISS abgekoppelt und als eigenständige Station weiter genutzt werden.

Das Habitation Module sollte ein etwa zehn Meter langes Modul sein, das nur zum Wohnen gedacht war. Zu ihm gehörten vier Schlafecken, eine Dusche sowie eine Küchennische.

Die Forschungsmodule sollten einen großen Teil des russischen Labortraktes ausmachen. Zu den Forschungsgebieten gehörten Geowissenschaft, Astronomie, Biologie und Medizin. In den ersten Planungen war von drei Modulen die Rede, 1998 gab es nur noch zwei Module, die jedoch in den Plänen von September 2001 ebenfalls fehlten. Mittlerweile sollen neben zwei Miniforschungsmodulen (MIM 1 Rasswet, 2010 und MIM 2 Poisk, 2009) sowie dem umgebauten MLM Naúka (2019) ein bis zwei große Forschungsmodule einer neuen Generation gebaut und ab 2021 Teil der ISS werden.

Die Science Power Platform (SPP) sollte Strom für die russischen Komponenten liefern. Zusätzlich sollte sie mit Steuerdüsen ausgestattet werden, die die Umlaufbahn der ISS korrigieren sollten. Das russische System sollte mit der Mission STS-138 an der ISS andocken. Es wurde gestrichen, da weitere Module ebenfalls nicht realisiert werden sollten und somit die Energie der großen US-amerikanischen Solarzellenflächen völlig ausreicht. Der druckbeaufschlagte Teil wurde später zum Miniforschungsmodul Rasswet umgebaut und gelangte 2010 zur Station. Mittlerweile sollen ab 2021 ein bis zwei weitere Module angekoppelt werden, die über größere nachführbare Solarzellen verfügen und jeweils etwa 18 kW Leistung liefern können.

Das Centrifuge Accommodations Module (CAM) sollte regelbare Schwerkraft für Experimente zur Verfügung stellen. Das Modul hätte zum US-amerikanischen Segment der Station gehört, wurde jedoch von Japan im Gegenzug für den Transport des Kibō-Moduls zur ISS gebaut. Wegen fehlender Mittel wird dieses Modul von der NASA aber nicht mehr zur ISS gebracht.

Die X-38 ist ein flügelloser Lifting Body (Auftriebskörper), der im Notfall die Evakuierung der Internationalen Raumstation ermöglichen sollte. Der Gleiter bietet Platz für sieben Personen und ist mit einer Antriebseinheit zum Verlassen der Umlaufbahn ausgestattet. Es war geplant, dass ständig ein solches Crew Return Vehicle (zu deutsch: Mannschafts-Rückkehrfahrzeug) an der ISS angedockt ist. Wegen zu hoher Kosten wurde die Entwicklung des X-38 jedoch 2002 eingestellt. Die Evakuierungsmöglichkeit wird zum jetzigen Zeitpunkt durch die Sojus-Raumschiffe sichergestellt. Nach dem Erhöhen der Besatzung auf sechs Personen sind es zwei solcher Raumschiffe. Weil eine Sojus-Landekapsel maximal drei Personen befördern kann, wird die ISS die ursprünglich geplante Besatzungsstärke von sieben Raumfahrern nicht erreichen können. Die offizielle Bezeichnung für den Prototyp des Fahrzeuges, der mehrmals in der Atmosphäre geflogen ist, lautet zwar X-38, oft spricht man jedoch einfach von dem „Crew Return Vehicle“, obwohl diese Bezeichnung auch allgemein für Rettungsfahrzeuge dieser Art verwendet wird.

Die Stromversorgung der Raumstation geschieht ausschließlich über Sonnenenergie. Der US-amerikanische Teil der ISS verfügt über 16 Solarpaneele, die durch photovoltaische Stromerzeugung elektrische Energie für die Station bereitstellen. Diese sind in acht sogenannten Photovoltaic Modules (PVMs) zu je zwei Elementen zusammengefasst, die durch Rotationsgelenke auf die Sonne ausgerichtet werden. An beiden Enden des „Rückgrats“ der ISS befinden sich jeweils zwei Module; auf der Backbordseite sind es die mit P4 und P6 bezeichneten Elemente und an Steuerbord S4 und S6.

Die acht Solarelemente arbeiten unabhängig voneinander. Während ein Teil des Stroms zur Speicherung in die Akkumulatoren (Nickel-Wasserstoff-Zellen) geleitet wird, geht der andere Teil direkt zu den zahlreichen Verbrauchern. Dazu wird der Strom über vier MBSU-Verteiler (Main Bus Switching Units) geleitet. Um eine gleichmäßige Energieversorgung auf der gesamten Station zu gewährleisten, kann eine MBSU über Kreuzschaltungen mit jeder anderen MBSU verbunden werden.

Zwei Paneele speisen einen Verteiler, der die Stromleitungen splittet und vier Leitungen ausgibt, die die Energie in DDCU-Gleichstromrichtern (Direct current–to–Direct Current Converter Units) herunterregeln. Anschließend wird die elektrische Energie durch ein verzweigtes Leitungsnetz an jedes Element des US-amerikanisch basierten Teils der ISS verteilt. Die Photovoltaik-Module erzeugen eine Spannung von 160 Volt (Primary Power), die Verbraucher auf dem US-Teil der Station arbeiten jedoch mit 124 Volt Gleichspannung (Secondary Power) und einige Geräte auch mit 28 Volt.
Der russische Teil der Station verfügt über mehrere Solarpaneele, die klassisch direkt an den größeren Modulen befestigt sind. Sie sind nur um eine Achse drehbar. Die Sonnenenergie des russischen Teils der Raumstation wird in Nickel-Cadmium-Akkus gespeichert, wobei alle Geräte mit 28 Volt Gleichspannung arbeiten. Über Konverter kann elektrische Energie zwischen den US-amerikanischen und russischen Systemen ausgetauscht werden.

Die Ausrichtung der Solarelemente hat einen relativ hohen Einfluss auf den Luftwiderstand der Station. Durch den Nachtgleitmodus kann der Widerstand im Mittel um 30 % reduziert werden und pro Jahr etwa 1000 kg Treibstoff eingespart werden.

Überschüssige Wärmeleistung von bis zu 106,8 kW kann über das Kühlsystem in den Weltraum abgegeben werden. Dazu dienen zwei Arten von Radiatorengruppen:

Beide Typen wurden bei Lockheed-Martin hergestellt und zusammengefaltet mit dem Space Shuttle in den Weltraum gebracht. Als Kältemittel dient flüssiges Ammoniak.

Bei russischen Modulen sind Wärmetauscher und Radiatoren überwiegend in die Modulstruktur integriert.

Um auf medizinische Notfälle vorbereitet zu sein, haben bestimmte Crew-Mitglieder ein Notfallmedizin-Programm durchlaufen. Des Weiteren ist eine beinahe unterbrechungsfreie Funkverbindung mit der Bodenstation vorhanden. Als Notfallausrüstung ist folgendes an Bord: Defibrillator, Ultraschallgerät, Krankentrage mit Fixierungen und ein umfangreiches Erste-Hilfe-Set. Bei schweren medizinischen Notfällen ist eine schnelle Rückkehr zur Erde innerhalb von 6 Stunden möglich.

Die Datenübertragung und der Sprechfunkverkehr mit dem Kontrollzentrum erfolgen für den US-basierten Teil der Station über das TDRS-Netz über S-Band (192 kbps) und Ku-Band (bis 300 Mbps). 2014 gelangt auch ein experimentelles Laserkommunikationssystem auf die Station. Die Kommunikation mit Astronauten während Außenbordeinsätzen sowie dem Shuttle wird über ein UHF-System hergestellt.

Der russische Teil der Station benutzt überwiegend direkte Funkverbindungen zu Bodenstationen oder Systeme des US-amerikanischen Segments, um mit dem russischen Kontrollzentrum in Moskau zu kommunizieren. 2012 und 2013 wurde auch ein experimentelles Lasersystem verwendet. In Zukunft soll das dem TDRS ähnliche Lutsch-Netz wieder installiert werden. Die Starts der ersten beiden Satelliten erfolgten 2011 und 2012, ein dritter ist für die nächste Zeit geplant.

Im Sommer 2008 konnten Internetnutzer aus Polen, Deutschland, Österreich und Kanada über den polnischen Instantmessenger Gadu-Gadu erstmals in Kontakt mit den Astronauten auf der ISS treten. Damit entstand erstmals eine öffentliche Verbindung über das Internet ins Weltall. Die Aktion war zum 30. Jahrestag des ersten Weltraumflugs eines Polen, des Kosmonauten Mirosław Hermaszewski, initiiert worden.

Auf der ISS selbst läuft Software unter Windows XP, Linux und OSX.

Das ARISS-Projekt ( für "Amateurfunk auf der Internationalen Raumstation") dient zur Realisierung von Kontakten mit Amateurfunkstellen auf der Erde, vor allem zwischen Schulen und Astronauten auf der ISS über Amateurfunk. Die erste Phase von ARISS fand bereits im ersten Modul der ISS Sarja statt, sodass bereits zwei Jahre nach dessen Start der erste Schulkontakt durch den Astronauten William Shepherd am 21. Dezember 2000 durchgeführt werden konnte. Auf diesem befindet sich auch der APRS-Digipeater. Im Rahmen der ARISS Phase 2 wurden während verschiedener Außenbordeinsätze am Swesda-Modul mehrere Antennen für Kurzwelle, VHF, UHF sowie das L-Band installiert. Für die Amateurfunkstelle im Columbus-Modul wurden im Oktober 2007 an dessen Mikrometeoritenschutzschild Antennen für das S- und L-Band installiert.

Wie viel das Projekt insgesamt kosten wird, ist umstritten. Nachdem die NASA beim Anfangsbetrag von 40 Milliarden US-Dollar diverse Korrekturen nach oben vornehmen musste, gibt sie heute keine neuen Kostenschätzungen mehr heraus. Nach Angaben der ESA werden sich die Gesamtkosten auf etwa 100 Milliarden Euro belaufen. Darin enthalten sind Entwicklung, Aufbau und die ersten zehn Jahre der Nutzung. 8 Milliarden Euro davon entfallen auf die Länder der ESA. 41 Prozent der europäischen Kosten werden von Deutschland getragen. Die Schweiz trägt 2,5 Prozent und Österreich weniger als 0,4 Prozent.

Das NASA-Budget für 2007 vermerkt Kosten für die ISS (exklusive der Shuttle-Kosten, die einen separaten Posten bilden) in Höhe von 25,6 Milliarden Dollar für die Jahre 1994 bis 2005. Für 2005 und 2006 wurden 1,7 respektive 1,8 Milliarden Dollar bereitgestellt. Die jährlichen NASA-Kosten stiegen bis ins Jahr 2014 auf 3 Milliarden Dollar.

Die 3 Milliarden Dollar des Budgets von 2015 verteilen sich wie folgt:


Wenn die Projektionen der NASA über jährlich ca. 2,5 Milliarden Dollar zwischen 2014 und 2019 zutreffen und 2020 wie geplant der Betrieb eingestellt werden würde, würden sich die Kosten seit dem Beginn des Programms 1993 auf 60 Milliarden Dollar aufsummiert haben. Die 33 Shuttle-Flüge für die Konstruktion und die Versorgung der Raumstation werden weitere 35 Milliarden Dollar gekostet haben. Zusammen mit den Vorarbeiten der NASA beim Design für die geplanten, aber nie realisierten Vorläuferstationen der ISS kann davon ausgegangen werden, dass allein die NASA näherungsweise 100 Milliarden Dollar für die Internationale Raumstation ausgegeben haben wird.

Die ESA kalkuliert ihren Beitrag über die 30-jährige Gesamtdauer des Projekts mit 8 Milliarden Euro. Die Kosten für die Entwicklung des Columbus-Moduls betrugen knapp 1 Milliarde (in dieser Höhe zum Teil hervorgerufen durch viele Änderungen und aufgezwungene Managementstrukturen). Der weitaus größere Teil der Kosten wird für die operative Phase benötigt (Betrieb des europäischen Bodenzentrums, Fertigung/Lagerhaltung für Ersatzteile, Mietkosten für Datenübertragungsstrecken usw).

Die Entwicklung des ATV kostete inklusive des ersten Starts von Jules Verne 1,35 Milliarden Euro. Die vier weiteren Flugexemplare sind mit 875 Millionen Euro günstiger, da die Entwicklungskosten weggefallen sind.
Da jeder Flug einer Ariane-5-Rakete wenigstens 125 Millionen Euro kostet, sind für ATV-Flüge Kosten in Höhe von 2,85 Milliarden Euro zu erwarten.

ATV-Kosten für die Flüge werden zum Teil mit der NASA, für die durch Columbus anfallenden Nutzungskosten der Stationsressourcen, verrechnet.

Das Kibō-Laboratorium hat bereits 2,81 Milliarden Dollar gekostet. Hinzu kommen die jährlichen Betriebsausgaben des Moduls im Bereich zwischen 350 und 400 Millionen Dollar.

Ein erheblicher Betrag des Budgets der russischen Weltraumbehörde Roskosmos wird für die ISS aufgewendet. Seit 1998 führte Roskosmos mehr als 30 Sojus- und mehr als 50 Progress-Flüge durch. Die Gesamtkosten sind schwierig abzuschätzen. Die bereits in der Umlaufbahn befindlichen russischen Module sind Nachkömmlinge des Mir-Designs, so dass die Entwicklungskosten hierfür immerhin sehr viel niedriger als bei vielen anderen Bestandteilen des Projektes sind. Kosten für neu beauftragte Komponenten sind mittlerweile aber nachzulesen.

Kanada, dessen Hauptbeitrag zur Internationalen Raumstation das Modul Canadarm2 ist, beziffert seine Kosten für das Projekt über die vergangenen 20 Jahre mit 1,4 Milliarden Kanadischen Dollar.
Neben dem Canadarm2 hat die kanadische Raumfahrtagentur (CSA) auch das Special Purpose Dexterous Manipulator (SPDM, dt. geschickte Arbeitsvorrichtung für Sonderzwecke) als weiteren Beitrag zur Internationalen Raumstation entwickeln lassen. Das SPDM wurde am 18. März 2008 an der ISS montiert.

Der Funkname lautete lange Zeit "Station". Während der ISS-Expedition 14 begann jedoch der Astronaut Lopez-Alegria mit der Verwendung des Namens "Alpha" (in Anlehnung an die US-amerikanische Bezeichnung der Station während der frühen Planungsphase), was dann von Houston und anderen Astronauten übernommen wurde. Nach seinem Aufenthalt auf der Station kehrte man aber zum alten Rufnamen "Station" zurück, unter anderem auch, weil für die russische Seite die ISS nicht die erste Raumstation ist. Mittlerweile entscheidet der jeweilige ISS-Kommandant über den zu nutzenden Funknamen am Anfang einer Expedition (zumeist "Station").

Im Gegensatz zu zeitlich begrenzten Raumflügen, auf denen die Zeit gemäß Mission Elapsed Time (MET) gemessen wird, werden für die Raumstation alle Zeiten in Koordinierter Weltzeit (UTC) angegeben. Zur Anpassung an die Hauptarbeitszeiten in den Kontrollzentren wird der Tagesablauf aber häufig dagegen verschoben.
Für die Öffentlichkeitsarbeit in Zusammenhang mit der ISS verwendet die NASA eine Mischung aus Zeitangaben in Pacific (PST/PDT), Central (CST/CDT) und Eastern Time (EST/EDT).

Die ISS erreicht eine scheinbare Helligkeit von bis zu etwa −5 mag, das heißt, sie erscheint bei günstiger Phase, und wenn sie nahe am Zenit vorbeizieht, von der Erde aus etwa 25-mal so hell wie der hellste Stern namens Sirius mit −1,44 mag (zum Vergleich: die Venus, der hellste Planet, kann bis zu −4,7 mag hell werden).

Mit den weiteren Modulen, die in Zukunft noch angedockt werden, erhöht sich die reflektierende Fläche der Station, so dass die ISS noch etwas höhere Helligkeitsklassen erreicht.

Die ISS ist jeweils periodisch zu bestimmten Zeiten im Jahr von Mitteleuropa aus am Himmel zu sehen: zunächst während zwei bis drei Wochen nahezu täglich in der Morgendämmerung, dann, nach einigen Tagen (hier abhängig von der Jahreszeit) Pause, zwei bis drei Wochen in der Abenddämmerung. Nach knapp zwei Monaten wiederholt sich diese Abfolge. Die genauen Zeitpunkte der Überflüge und die Zugbahnen, abhängig vom Beobachtungsstandort, sind online abrufbar. → siehe Weblinks: Spot The Station, Heavens-Above, calsky oder Orbitron

Unter optimalen Sichtbedingungen ist die noch mehrere tausend Kilometer entfernte ISS bereits zu Beginn eines Überfluges am westlichen Horizont sichtbar. Beim Überflug ist die nur wenige hundert Kilometer entfernte ISS mit bloßem Auge als zügig vorbeiziehender sehr heller Punkt auszumachen. Durch die fehlenden Positionslichter, ihre Helligkeit und den Charakter ihrer Bewegung kann sie nicht mit Flugzeugen oder anderen Satelliten verwechselt werden. Der Überflug kann bis zu sechs Minuten lang dauern, bis die ISS, wiederum mehrere tausend Kilometer entfernt, am östlichen Horizont untergeht bzw. in den Erdschatten eintaucht.

Die Beobachtung mit einem Teleskop ist ausgesprochen schwierig. Die Achsklemmungen der Montierung müssen gelöst sein und das Teleskop muss per Hand nachgeführt werden. Zur Beobachtung empfiehlt sich eine geringe Vergrößerung (großes Gesichtsfeld) sowie ein Überflug der ISS im Zenit (geringste Entfernung zum Teleskop).

Besonders spektakulär sind die Vorbeiflüge und Querungen des Mondes oder die Durchquerung der Sonne, ebenso die Beobachtungen bei Versorgungsflügen, wenn ein helles Objekt (ISS) und ein dunkleres (Transportraumschiff) mit nahezu gleicher Geschwindigkeit neben- oder hintereinander herfliegen.






</doc>
<doc id="10271" url="https://de.wikipedia.org/wiki?curid=10271" title="Beutelwolf">
Beutelwolf

Der Beutelwolf ("Thylacinus cynocephalus"), auch Tasmanischer Wolf, Beuteltiger oder Tasmanischer Tiger genannt, war das größte räuberisch lebende Beuteltier, das in geschichtlicher Zeit auf dem australischen Kontinent lebte. Das letzte bekannte Exemplar („Endling“), ein „Benjamin“ genanntes Weibchen, starb 1936 im Zoo von Hobart auf Tasmanien.

Beutelwölfe erreichten eine Kopfrumpflänge von 85 bis 130 Zentimetern, eine Schwanzlänge von 38 bis 65 Zentimetern und ein Gewicht von 15 bis 30 Kilogramm. Ihre Schulterhöhe betrug rund 60 Zentimeter. Ihr Fell war kurz und rau, grau oder gelbgrau gefärbt. Auffällig waren die 13 bis 19 schwarzbraunen Querstreifen am hinteren Teil des Körpers und an der Schwanzwurzel, denen er auch seinen Namen „Beuteltiger“ verdankt und die der Tarnung dienten. Im Gesicht hatte er weiße Zeichnungen um die Augen und Ohren. Der Beutelwolf wies im Körperbau verblüffende Ähnlichkeiten mit einigen Raubtieren aus der Familie der Hunde (Canidae) auf und stellt so ein Paradebeispiel für konvergente Evolution dar. Der Schädel war etwas breiter gebaut, die Zahnformel lautete 4/3-1/1-3/3-4/4 x2, insgesamt also 46 Zähne. Ähnlich wie bei Hunden waren die Eckzähne lang und die Backenzähne scharf. Bemerkenswert ist, dass die Tiere ihren Unterkiefer sehr weit aufklappen konnten, nach manchen Angaben bis zu 90 Grad. Die Gliedmaßen waren eher kurz, die Beine endeten jeweils in fünf Zehen. Die Tiere waren Zehengänger und erreichten wohl eine Geschwindigkeit von bis zu 40 km/h.

Nicht nur dem Namen nach gibt es Ähnlichkeiten zwischen Wolf und Beutelwolf. Obwohl die Vorfahren beider Tiere sich stammesgeschichtlich sehr früh in der Kreidezeit teilten, entwickelte sich in der Gruppe der Beuteltiere und der Höheren Säugetiere jeweils ein Raubtier mit verblüffenden Übereinstimmungen.
Generell überwiegen beim Vergleich deutlich die Ähnlichkeiten in Ausbildung und Proportionen, so dass man in diesem Fall von einem Paradebeispiel für Konvergenz sprechen kann. Beide besitzen ein Raubtiergebiss mit sehr kleinen Schneidezähnen und großen, gebogenen Eckzähnen. Die Vorbackenzähne sind einhöckrig und die Backenzähne besitzen mehrere Höcker. Die Zahnformeln lauten:

Vergleicht man die Schädel dieser Tiere, fällt nicht nur Ungeübten die Unterscheidung sehr schwer. Nebenstehende Abbildung zeigt den Schädel von Beutelwolf (rote Markierung) und Wolf (grüne Markierung) in verschiedenen Ansichten. Die deutlichsten Unterschiede im Vergleich zum Wolf sind:

Zur Zeit der Ankunft der Europäer in Australien lebte der Beutelwolf vermutlich nur noch in Tasmanien. Auf dem australischen Festland und auf Neuguinea verschwand er bereits vorher. Sein ursprünglicher Lebensraum waren offene Waldgebiete und Grasländer, in den letzten Jahrzehnten seiner Existenz wurde er aber durch den Menschen in dichte Wälder abgedrängt.

Beutelwölfe waren in der Regel nachtaktiv, konnten aber beim Sonnenbaden beobachtet werden. Über die Jagdtechnik gibt es unterschiedliche Berichte. Nach manchen Berichten verfolgte er seine Beute, bis sie ermüdet war und er sie überwältigen konnte, nach anderen Berichten schlich er sich an seine Opfer an und überrumpelte sie. Dabei half ihm sein kräftiger Kiefer – einem Bericht zufolge zermalmte er den Schädel eines Hundes mit einem einzigen Biss. Neuere Forschungen eines Teams um Marie Attard von der Universität von New South Wales in Sydney mit Computermodellen und Gebissvergleichen mit anderen Raubtieren widerlegen das aber und bescheinigen dem Beutelwolf eher geringe Bisskräfte. Den Analysen zufolge scheint der Beutelwolf vor allem kleinere Tiere, wie etwa Wallabys und Beuteldachse, erlegt zu haben. Selbst Schafe seien demzufolge als Beute zu groß gewesen, der Vernichtungsfeldzug gegen den Beutelwolf als angeblichen Schafkiller war nach heutigen Fakten ungerechtfertigt. Auf alle Fälle war er kein allzu schneller, sondern ein ausdauernder Läufer. Manchmal richtete er sich auch känguruartig auf seine Hinterbeine auf, wobei der Schwanz als Stütze diente. Er lebte vorwiegend allein, manchmal jagte er aber auch in Paaren oder kleinen Gruppen. Zu den bekannten Lauten zählten ein dumpfes Bellen während der Jagd, ein Knurren, wenn er verärgert war, und ein Jaulen, das vermutlich der Kommunikation mit Artgenossen diente.

Generell wurden Beutelwölfe als eher scheue und im Vergleich zum Beutelteufel als eher wenig aggressive Tiere beschrieben. Es existieren sehr wenige Berichte über Angriffe auf Menschen, auch Tiere in Gefangenschaft sollen sich sehr zahm benommen haben.

Man vermutet, dass Beutelwölfe vorwiegend von Säugetieren wie Australischen Nasenbeutlern, Possums, Wallabys und anderen kleinen Kängurus lebten, daneben nahmen sie auch andere Säugetiere (darunter Wildkaninchen und eventuell auch Ameisenigel) und Vögel zu sich. In welchem Ausmaß er nach Ankunft der Europäer Schafe und andere Weidetiere jagte, ist umstritten, da viele dem Beutelwolf zugeschriebene Risse von Schafen tatsächlich auf verwilderte Hunde zurückgingen. Zudem nehmen Forscher der Universität von New South Wales, die eine Simulation mit einem 3D-Modell vom Kiefer des Beutelwolfs durchführten, an, dass er zu schwach war, um Schafe zu reißen.

Weibliche Beutelwölfe hatten einen nach hinten geöffneten Beutel, der vier Zitzen enthielt. Die meisten Jungtiere kamen im Sommer (Dezember bis März) zur Welt, die Wurfgröße betrug zwei bis vier Junge. Nach drei Monaten verließen die Jungtiere den Beutel, blieben aber bei der Mutter, bis sie knapp ein Jahr alt waren. Die Lebenserwartung wird auf maximal zwölf bis vierzehn Jahre geschätzt.

Als die ersten Menschen den australischen Kontinent besiedelten, waren Beutelwölfe in weiten Teilen Australiens und Neuguineas verbreitet, wovon auch Felszeichnungen der Aborigines Zeugnis ablegen. Aus unbekannten Gründen starben Beutelwölfe jedoch auf Neuguinea und dem australischen Festland aus, die jüngsten Fossilfunde vom Festland (aus dem Northern Territory) datieren auf 3000 v. Chr. Oft wird vermutet, dass der Dingo, der vor 5.000 Jahren von Austronesiern in Australien eingeführt wurde, den Beutelwolf durch Erhöhung des Konkurrenzdrucks verdrängt habe. Gestützt wird diese These durch die Tatsache, dass der Beutelwolf auf Tasmanien, wo Dingos nie auftauchten, bis ins 20. Jahrhundert überlebte.

Eine weitere Theorie zieht in Betracht, dass das Aussterben durch eine Zunahme der menschlichen Bevölkerung verursacht wurde. Es gibt Hinweise auf dramatische Veränderungen der menschlichen Population in vielen Gebieten Australiens, welche aber nie Tasmanien erreichten. Diese Veränderungen beinhalteten eine Vielfalt an Neuerungen von Jagdwerkzeugen, Populationsanstieg und Sesshaftwerdung in mehreren Gebieten, eine Intensivierung der Nutzung von Ressourcen und eine Besiedlung neuer Gebiete bis in die Wüsten hinein. So zeigen Funde, dass vor ca. 3000 Jahren praktisch alle Hauptgebiete des australischen Kontinents von Menschen genutzt wurden. Einerseits könnte das Aussterben durch direkten Jagddruck bewirkt worden sein (Felszeichnungen aus Nordaustralien zeigen, wie Beutelwölfe als Beute weggetragen wurden). Dieser Ansatz wird durch Grabfunde mit Schmuck aus Beutelwolfzähnen sowie die Tatsache unterstützt, dass Ureinwohner Tasmaniens Beutelwölfe gejagt und gegessen hatten. Andererseits könnte es zur Verringerung vieler Beutearten und somit zur Verdrängung des Beutelwolfs gekommen sein. Ein Beispiel sei mit dem Pfuhlhuhn genannt: Da das Verbreitungsgebiet des Pfuhlhuhns womöglich schon vor der Ankunft der Dingos auf dem australischen Kontinent stark geschrumpft war, könnte die Intensivierung der Jagd zusätzlich zum Aussterben des Beutelwolfs geführt haben. Folglich könnte damit erklärt werden, weshalb der Tasmanische Teufel auf dem Festland soviel länger als der Beutelwolf überleben konnte, da der Tasmanische Teufel aufgrund seiner geringeren Größe weniger große Beute gebraucht hätte und daher wesentlich weniger anfällig auf den erhöhten Konkurrenzdruck gewesen wäre.

Die Intensivierung, die Ankunft des Dingos und das Aussterben des Beutelwolfs fallen ebenso mit einer Klimaveränderung hin zu kurzzeitig trockenerem Klima zusammen. Eine Klimaveränderung wird aber nicht als Hauptgrund für das Aussterben angesehen, da die Trockenheit verhältnismäßig mild war und Tasmanien ebenso beeinflusste. Es ist aber auch möglich, dass diese Veränderung die Auswirkungen der Intensivierung und des Dingos noch beschleunigte. Wahrscheinlich ist auch, dass die Auswirkungen der Intensivierung und des Dingos miteinander verbunden waren und der Dingo einer der Gründe für die Intensivierung war (neue Jagdwerkzeuge tauchten bereits vorher auf). Inwieweit das aber zusammenhängt, ist nicht klar, da man nicht weiß, wie schnell die Dingos wilde Populationen gebildet hatten bzw. wie stark sie an die Ureinwohner gebunden waren.

Wann dieses Aussterben letztlich wirklich stattfand, ist umstritten; es gibt Behauptungen, wonach eine kleine Population im nördlichen Australien bis nach der Ankunft der Europäer überlebt haben könnte. Gelegentlich gibt es Behauptungen über Sichtungen auf dem Festland, dafür gibt es jedoch keine Belege.

In Tasmanien, wo es nie Dingos gab, war die Art jedoch noch zu Beginn des 19. Jahrhunderts weit verbreitet und häufig. Nach Einführung von Schafen auf der Insel bekam der Beutelwolf den Ruf eines blutrünstigen Jägers, obwohl in Wirklichkeit die meisten Schafe von verwilderten Haushunden getötet wurden. 1830 setzte die Regierung ein Kopfgeld von einem Pfund auf jeden erlegten Beutelwolf aus. In den 1860er-Jahren war die Art auf die unzugänglicheren Bergregionen im Südwesten der Insel beschränkt, die Jagd mit Fallen und Hunden ging jedoch unvermindert weiter. Um das Jahr 1910 galt die Art als selten. Zoos auf der ganzen Welt machten sich auf die Suche nach diesen Tieren.

Obwohl die Art in verschiedenen Tiergärten gehalten wurde, kam es in ihrer Haltungsgeschichte nur zu einem einzigen Wurf in Gefangenschaft; der fiel 1899 im Zoo von Melbourne. Die letzte bekannte Tötung eines Tieres in der Natur war im Jahr 1930; das bis heute letzte bekannte Exemplar – ein Weibchen namens Benjamin, das zeitlebens für ein Männchen gehalten wurde – starb in der Nacht vom 6. auf den 7. September 1936 im inzwischen geschlossenen "Beaumaris Zoo" von Hobart in Tasmanien. Es war am 19. Februar 1924 mit einem weiteren Beutelwolf, der bereits am 14. April 1930 starb, in den Zoo gekommen. Benjamin, der mit 12 Jahren und 4 Monaten am längsten in menschlicher Obhut lebende Beutelwolf, wurde nach seinem Tod präpariert und befindet sich heute in der Art Gallery des Museums in Hobart.

Es gibt auch Vermutungen, dass das Aussterben des Beutelwolfs durch eine Krankheit gefördert wurde. Hinweise darauf sind ein plötzlicher Rückgang der geschossenen Tiere um 1906, ein zeitgleiches Aussterben über Tasmanien verteilt und Augenzeugen, die von einer der Hundestaupe ähnlichen Erkrankung sprachen. Wie bei den anderen Vermutungen bleibt der Beweis für eine Epizootie als Ursache des Aussterbens auch hier aus; neuere Modelluntersuchungen kommen zum Schluss, dass ein derartiges Ereignis für sich alleine wohl nicht für das Aussterben verantwortlich gewesen sein kann. DNA-Untersuchungen an Museumspräparaten lieferten Hinweise darauf, dass die auf Tasmanien lebende Population stark ingezüchtet war, so dass auch der Mangel an genetischer Diversität mit zum Aussterben beigetragen haben könnte.

Beutelwölfe besaßen keinen hohen Schauwert beim Publikum, lediglich während der Fütterung, Paarung, Aufzucht von Jungtieren oder bei seltsamem Verhalten wie dem Wutgähnen, das meist nicht als Drohgebärde verstanden wurde, erhielten sie Aufmerksamkeit. Zwischen 1850 und 1936 lebten nachweislich 68 Beutelwölfe in Zoos, 18 von ihnen wurden während dieser Zeit in andere Zoos exportiert.

Die Schutzmaßnahmen, die zum Erhalt der Art ergriffen wurden, kamen zu spät. 1936 wurden Beutelwölfe gesetzlich geschützt, kurz bevor der letzte Beutelwolf in Gefangenschaft starb. Mehrere Expeditionen in den nachfolgenden Jahrzehnten fanden keine Anhaltspunkte mehr, die auf ein Überleben der Art hindeuten könnten. 1966 errichtete die tasmanische Regierung ein 647.000 Hektar großes Schutzgebiet im Südwesten der Insel für den Fall, dass sich manche Tiere noch in Rückzugsgebieten halten konnten.

Mit an Sicherheit grenzender Wahrscheinlichkeit ist der Beutelwolf ausgestorben. Dennoch wird immer wieder von Sichtungen lebender Tiere aus Tasmanien berichtet, eindeutige Fotografien oder Videoaufzeichnungen davon existieren jedoch nicht. Zuletzt sorgten zwei voneinander unabhängige angebliche Sichtungen auf der Kap-York-Halbinsel im Norden Queenslands im März 2017 für Aufsehen. Am 22. März 2005 setzte die australische Zeitschrift "The Bulletin" eine Belohnung von umgerechnet 750.000 Euro für den Beweis eines lebenden und unverletzten Tieres aus. 

Im Jahr 2000 begannen Wissenschaftler mit der Erforschung der DNA des Tieres, auch um die ausgestorbene Art vielleicht erneut züchten zu können. Fünf Jahre später gaben sie den Versuch auf: Das vorliegende Genmaterial sei zu sehr zerstört, um es zu rekonstruieren. Die Forscher hatten unter anderem mit der DNA eines Fötus experimentiert, der 1886 in Alkohol eingelegt worden war. Bereits drei Monate später teilte Mike Archer von der University of New South Wales allerdings mit, dass das Projekt von einer anderen Gruppe weitergeführt wird.

Im Jahr 2007 wollten australische Zoologen vom "Australian Centre for Ancient DNA" der University of Adelaide mit der DNA-Analyse von Kotproben beginnen, die während der 1950er- und 60er-Jahre gesammelt wurden und vom Beutelwolf stammen könnten. Das könnte helfen, die Frage zu klären, ob der Beutelwolf in freier Wildbahn möglicherweise erheblich länger überlebt hat als bisher angenommen.

2008 gelang es Forschern der University of Melbourne und der University of Texas, das aus in Ethanol konserviertem Gewebe isolierte Gen "Col2A1 enhancer" des Beutelwolfs in eine transgene Maus einzuschleusen, wo es in den Knorpelzellen der Maus die Funktion des orthologen Mausgens erfüllen konnte. 2009 sequenzierte eine andere Gruppe aus Proben von zwei Museumsexponaten das mitochondriale Genom des Beutelwolfs. 

2017 gelang einer Gruppe australischer Wissenschaftler unter Leitung von Andrew J. Pask von der Universität Melbourne die vermutlich vollständige Entschlüsselung des Genoms des Beutelwolfes. Zu diesem Zweck extrahierten sie die DNA eines zum Zeitpunkt seines Todes noch im Beutel befindlichen Jungtiers, das 1909 im Museum Victoria in Australien in Alkohol eingelegt worden war. Dabei erhielten sie DNA Fragmente von 300 bis 600 Basenpaaren, die isoliert und sequenziert wurden. Durch Vergleich der überlappenden Sequenzen erhielten sie eine Gesamtsequenz von 188 Giga-Basenpaaren. Diese wurde mit den Datenbanken für mikrobielle und fungale DNA-Sequenzen verglichen. Nach Abzug dieser Verunreinigungen blieb eine Gesamtfrequenz von 155 Giga-Basenpaaren übrig, die vermutlich dem einigermaßen vollständigen Genom des Beutelwolfs entspricht. Unterstützt wird diese Annahme durch den Vergleich des Sequenzumfangs des Genoms noch lebender Beuteltierarten, wie dem Beutelteufel ("Sarcophilus harrisii"), mit dem der Beutelwolf ("Thylacinus cynocephalus") rund 89,3 % des Genoms gemein hat.

Die Genomanalyse beantwortet auch die phylogenetische Stellung des Beutelwolfs, der, wie der Numbat, zu den basalen Dasyuromorphia gehört. Mit dem Beutelteufel, der zu den Dasyuridae gehört, ist der Beutelwolf nur entfernt verwandt.

Der Beutelwolf war der einzige überlebende Vertreter der Familie der Beutelwölfe (Thylacinidae), die zur Ordnung der Raubbeutlerartigen (Dasyuromorphia) gerechnet wird. Die Familie selbst ist seit dem Oligozän belegt und mit zahlreichen ausgestorbenen Gattungen bekannt. Es folgt eine kurze Auswahl von Arten:

Die International Thylacine Specimen Database führt Buch über alle weltweit erhaltenen Präparate von "Thylacinus cynocephalus." Die meisten Präparate befinden sich wegen ihres schlechten Erhaltungszustands oder der wenig lebensnahen Ausführung lediglich in Magazinen. Exemplare, die gut erhalten sind, haben heute einen hohen Schauwert bei den Besuchern.

Zu besichtigen gibt es Beutelwolfpräparate in:
Weitere Präparate werden in Frankreich, Italien, England, Russland, Australien und den USA ausgestellt.

Der 2008 veröffentlichte australische Horrorthriller "Dying Breed" greift den Mythos des ausgestorben geglaubten Beutelwolfs auf.

Im australischen Filmdrama "The Hunter" von 2011, der auf dem gleichnamigen Roman von Julia Leigh ("Sleeping Beauty") basiert, jagt Willem Dafoe in der Hauptrolle den letzten lebenden Tasmanischen Tiger in den Wäldern Tasmaniens.




</doc>
<doc id="10280" url="https://de.wikipedia.org/wiki?curid=10280" title="Sozialistische Einheitspartei Deutschlands">
Sozialistische Einheitspartei Deutschlands

Die Sozialistische Einheitspartei Deutschlands (SED) war eine in der sowjetischen Besatzungszone Deutschlands und der Viersektorenstadt Berlin aus der Zwangsvereinigung von SPD und KPD zur SED 1946 hervorgegangene politische Partei. Der Zusammenschluss zur Einheitspartei und die anschließende Entwicklung zur marxistisch-leninistischen Kader- und Staatspartei der 1949 gegründeten DDR erfolgten unter Einflussnahme der sowjetischen Besatzungsmacht. Aufgrund des seit 1968 in der Verfassung der DDR festgeschriebenen Führungsanspruchs der SED und der umfassenden Durchdringung der Organe aller drei Gewalten (Legislative, Exekutive und Judikative) mit SED-Nomenklaturkadern war das politische System der DDR eine de-facto-Ein-Parteien-Herrschaft.

Im Zuge der Wende und friedlichen Revolution in der DDR 1989/90 verlor die SED ihre Stellung als herrschende Staatspartei, gab sich ein neues Programm und benannte sich im Dezember 1989 zunächst in "Sozialistische Einheitspartei Deutschlands – Partei des Demokratischen Sozialismus (SED-PDS)", am 4. Februar 1990 dann in "Partei des Demokratischen Sozialismus" (PDS) um. Aus ihr entstand 2007 durch Verschmelzung mit der WASG die Partei Die Linke.

Die SED sah sich in Tradition der KPD über die VKPD, die USPD, den Spartakusbund, die SPD, die SDAP, den ADAV bis hin zur deutschen Arbeiterbewegung.
Nach den zwölf Jahren der Diktatur des Nationalsozialismus war die Parteienlandschaft Deutschlands gründlich zerstört, was einen demokratischen Neuanfang stark erschwerte. Also galt es für die Besatzungsmächte, die Grundlagen für das gesellschaftliche Leben zu schaffen. Als erstes reagierte die Sowjetunion. Mit dem "Befehl Nummer zwei" der Sowjetischen Militäradministration in Deutschland (SMAD) vom 10. Juni 1945 initiierte sie die politische Betätigung in ihrer Zone. Danach sollte die Tätigkeit antifaschistisch-demokratischer Parteien und freier Gewerkschaften gestattet sein.

Das Zentralkomitee (ZK) der KPdSU ließ dazu deutsche Kommunisten und Widerstandskämpfer, die den Zweiten Weltkrieg überlebt hatten, nach umfassender Schulung in Moskau zurück nach Berlin verbringen. Vorerst drei Initiativgruppen "Ulbricht", "Ackermann" und "Sobottka", die in Berlin, Sachsen und Mecklenburg tätig wurden, hatten die Aufgabe, die Verwaltung aufzubauen und den sowjetischen Weisungen einen demokratischen Anschein zu geben. Einer dieser Kader war der später in die Bundesrepublik geflüchtete Wolfgang Leonhard, der als Mitglied der "Gruppe Ulbricht" in die sowjetische Besatzungszone kam.

Schon am 11. Juni 1945 trat das ZK der KPD zum ersten Mal mit seinem Gründungsaufruf an die Öffentlichkeit. Ermöglicht wurde diese schnelle Reaktion durch die Tätigkeit der oben genannten Gruppen. Kurze Zeit später veröffentlichte die SPD am 15. Juni ihren Gründungsaufruf.

Unter dem massiven Druck der sowjetischen Besatzungsmacht und der KPD-Führung sowie mit der Unterstützung führender Sozialdemokraten und nicht weniger SPD- und KPD-Mitglieder bildeten sich auf allen Ebenen der beiden Parteien Arbeitsgemeinschaften und Ausschüsse, deren erklärtes Ziel die organisatorische Vereinigung war. Teile der sozialdemokratischen Seite gingen dabei weiter als die Führung der KPD, die anfänglich eher zurückhaltend hinsichtlich der Vereinigung war und noch ein Vereinigungsangebot des Berliner Zentralausschusses der SPD unter Führung von Otto Grotewohl im Juni 1945 ablehnte. Getrieben von der Besatzungsmacht und unter nun veränderter Taktik der KPD-Führung veranstalteten der ZA der SPD und das ZK der KPD im Dezember 1945 eine Konferenz, auf der jeweils dreißig führende Vertreter beider Parteien anwesend waren, die die Verschmelzung beider Parteien beschlossen. Grundlegende Motivation waren die Erfahrungen mit der Spaltung der linken Hitler-Gegner im Parlament der späten Weimarer Republik, die als eine der wesentlichen Ursachen für die Machtübertragung an die NSDAP betrachtet wurde, was unter anderem im deklamatorischen Charakter des "Schwurs von Buchenwald" und in den Ideen der Einheits- und Volksfront zum Ausdruck kam. Eine weitere Motivation für die Kommunisten war das unerwartet schlechte Abschneiden der österreichischen Kommunisten bei der Nationalratswahl in Österreich 1945.

Besonders innerhalb der SPD tobten um die avisierte Vereinigung heftige Kontroversen. Der faktische Vorsitzende in Westdeutschland, Kurt Schumacher, sprach sich vehement gegen diesen Schritt aus. Der Zentralausschuss unter dem Vorsitz von Grotewohl, das selbsternannte Leitungsgremium der SPD in der SBZ, konnte bei mehreren Sitzungen zu keiner Einigung kommen. Er willigte erst ein, als der sächsische SPD-Landesvorsitzende Otto Buchwitz drohte, die Vereinigung mit seinem Landesverband zu starten. Insbesondere in den Regional- und Lokalgliederungen der SPD hatte die sowjetische Besatzungsmacht die Möglichkeit, unter anderem auch mit Repressionen und Verhaftungen auf die SPD-Mitglieder einzuwirken. Aber auch Teile der KPD-Führung mussten von ihren Vorstellungen abrücken, die eigene Partei aufzubauen, Regierungspolitik zu betreiben und die in ihren Augen diskreditierte Sozialdemokratie abzulösen. Dies war sowohl auf den zunehmenden Führungsanspruch der Sozialdemokratie als auch auf mangelnden Rückhalt in der Bevölkerung zurückzuführen.

Bezüglich einer Vereinigung waren lokal große Unterschiede festzustellen. So vereinigten sich bereits am 23. Februar 1946 die Kreisorganisationen der KPD und der SPD in Neuruppin zur "Sozialistischen Einheitspartei Deutschlands". Dagegen sprachen sich bei einer Urabstimmung unter SPD-Mitgliedern, die nur in den Westsektoren in West-Berlin stattfinden konnte, am 31. März 1946 etwa 82 % der Teilnehmer gegen eine sofortige Vereinigung, aber immerhin 62 % für „gemeinsame Arbeit“ mit der KPD aus. Im sowjetischen Sektor von Berlin und in der Sowjetischen Besatzungszone hatte die Besatzungsmacht eine Urabstimmung der SPD verhindert. In Berlin, wo die SPD auch im Ostteil der Stadt bis 1961 weiter existierte, behielten ungefähr zwei Drittel der Mitglieder ihr sozialdemokratisches Parteibuch, etwa ein Drittel trat in die SED ein.

Hauptströmungen der kontroversen Diskussionen der Mitglieder in den deutschen Ländern waren dabei:


Am 21. und 22. April 1946 versammelten sich im Ost-Berliner Admiralspalast in der Berliner Friedrichstraße Delegierte von KPD und SPD, Ehrengäste und Zuschauer zum gemeinsamen Parteitag von KPD und Teilen der SPD. Seitens der SPD nahmen 548 Delegierte (darunter 103 aus den westlichen Besatzungszonen) teil und von der KPD 507 Delegierte (darunter 127 westliche). Diese vertraten rund 680.000 sozialdemokratische und rund 620.000 kommunistische Parteimitglieder der Sowjetischen Besatzungszone. Eröffnet wurde die Veranstaltung mit der Fidelio-Ouvertüre Beethovens. Anschließend betraten Wilhelm Pieck und Otto Grotewohl von verschiedenen Seiten die Bühne und reichten sich die Hände. Diese symbolische Geste wurde im Emblem der SED nachempfunden.

Auch in den übrigen Besatzungszonen gab es verschiedene Formen der Zusammenarbeit und Annäherungsbestrebungen zwischen Sozialdemokraten und Kommunisten. So beschlossen am 24. Juli 1945 in Hamburg und am 8. August 1945 in München Vertreter der SPD und der KPD ein gemeinsames Aktionsprogramm. In Frankfurt am Main entstand am 3. Oktober 1945 ein Arbeitsausschuss von Sozialdemokraten und Kommunisten, und am 1. Oktober 1945 rief der Einheitsausschuss von SPD und KPD in Wiesbaden zur Vereinigung beider lokaler Parteien auf. Darüber hinaus arbeiteten in einer Reihe von Städten Sozialdemokraten und Kommunisten auf kommunaler Ebene zusammen.

Sowohl in den amerikanischen, britischen und französischen Besatzungszonen als auch in der sowjetischen Besatzungszone, wurde auf diese Prozesse seitens der Besatzungsmächte Einfluss genommen. Die Vereinigung in der sowjetischen Besatzungszone kam maßgeblich durch sowjetischen Druck zustande.
Zu dieser Sicht äußert sich u. a. der Zeitzeuge und damalige Mitverantwortliche Wolfgang Leonhard, der in seinen Büchern die Koordinierung durch das ZK der KPdSU belegt.

2001 räumten die Bundestagsabgeordneten Gabi Zimmer und Petra Pau (beide PDS) ein, dass Mitglieder der SED sowohl im Prozess der Vereinigung Täuschungen, Zwänge und Repressionen zuließen, als auch Fehler begangen hätten. Am 6. Mai 2001 schloss sich der Parteivorstand dieser Erklärung an.

Zum Zeitpunkt ihrer Gründung hatte die SED etwa 1,3 Millionen Mitglieder, die zu fast gleichen Teilen aus KPD und SPD kamen. Das Parteiprogramm war anfangs an antifaschistisch-demokratischen Grundzügen orientiert.

Bei den Landtagswahlen 1946 verfehlten die vereinigten Arbeiterparteien eindeutig ihr Wahlziel: Trotz massiver Unterstützung durch die Besatzungsbehörden erzielte die SED in keinem Land die absolute Mehrheit. In Mecklenburg und in Thüringen verfehlten sie diese knapp, in Sachsen-Anhalt und in Brandenburg wären bürgerliche Koalitionen von CDU und LDP möglich gewesen. Noch enttäuschender war das Ergebnis in Groß-Berlin. Bei der Wahl der Stadtverordnetenversammlung von Groß-Berlin im Oktober 1946, bei der neben der SED auch die SPD antrat (→ Sonderfall Berlin), errang die SPD einen Stimmenanteil von 48,7 % gegenüber der SED mit 19,8 %, (CDU 22,2 % und LDP 9,3 %). Dies war die einzige freie Wahl in Gesamtberlin (vor 1990).

Frauen, die die Nachkriegsgesellschaft rein zahlenmäßig dominierten, waren in der SED deutlich unterrepräsentiert: 1947 waren weniger als 24 % der Mitglieder der SED Frauen. Zudem arbeiteten in den Berufen mit besonders hohem Mitgliederanteil vorwiegend Männer. Mitte 1948 war die Zahl der Mitglieder auf zwei Millionen angewachsen, was einem Bevölkerungsanteil von sechzehn Prozent entsprach.

Das erste Parteiprogramm der SED war an das "Erfurter Programm" der SPD von 1891 angelehnt, um ehemaligen Sozialdemokraten die Zustimmung zu erleichtern. So vermied das ursprüngliche Programm der SED noch jeden Bezug auf den Leninismus und sprach vom demokratischen Weg zum Sozialismus. Im Parteistatut wurden noch keine weltanschaulichen Einschränkungen erhoben. Vielmehr stand die SED allen offen, die den Nationalsozialismus ablehnten. Es gab noch keine Kandidatenzeit, keine Überprüfungen, kein Politbüro und keinen Generalsekretär. Ämter wurden streng paritätisch von Kommunisten und Sozialdemokraten besetzt. So gab es zu dieser Zeit auch zwei Parteivorsitzende: den Sozialdemokraten Otto Grotewohl und den Kommunisten Wilhelm Pieck. Die paritätische Besetzung von Parteiämtern schützte die Sozialdemokraten nicht vor ihrer Vereinnahmung. Unmittelbar nach der Vereinigung setzte die «Marginalisierung der Sozialdemokraten», die «schleichende Stalinisierung» und die Zentralisierung der Partei ein. Bereits im Mai 1946 wurden gemeinsame Schulungen für alle Parteimitglieder beschlossen:

Immer offener distanzierte sich die SED von den Grundsätzen der Vereinigung. Der im Herbst 1946 eingeleitete organisatorische Umbau der SED zielte bewusst auf das Zurückdrängen des sozialdemokratischen Einflusses, die Entmachtung der unteren Parteiebenen und eine Machtkonzentration an der Parteispitze. Untermauert wurde dieser Umbau durch die am 24. Dezember 1946 vom Zentralsekretariat beschlossenen "Richtlinien für den organisatorischen Aufbau der SED". Auf dem 2. Parteitag im September 1947 wurde der Beschluss gefasst, ein neues Parteiprogramm zu erstellen. Die Sozialdemokraten sollten ab 1949 kaum noch eine Rolle spielen. Die paritätische Besetzung von Gremien wurde abgeschafft. Offiziell wurde dies zum einen mit dem „ideologischen Zusammenschluss der Parteimitglieder“ und zum anderen mit der großen Zahl junger Kader begründet, die weder der SPD noch der KPD angehört hatten, so dass diese bei Beibehaltung der Parität nicht in leitende Funktionen hätten gewählt werden können. Auf dem III. Parteitag im Juli 1950 wurde das Vereinigungsprogramm «Grundsätze und Ziele der SED» endgültig außer Kraft gesetzt. Die Formulierung eines neuen Programmes ließ aber bis zum VI. Parteitag 1963 auf sich warten. In diesem Programm bekannte sich die SED zum Ziel des Kommunismus, der als eine Gesellschaft definiert wurde, „in der jeder Werktätige seine Fähigkeiten mit dem größten Nutzen für das Volk anwendet“, ganz nach dem marxschen Prinzip „Jeder nach seinen Fähigkeiten, jedem nach seinen Bedürfnissen“. An diesem Ziel hielt die SED auch bei der Neuformulierung ihres Programms im Jahr 1976 fest, in dem sich die SED als „freiwilliger Kampfbund gleichgesinnter Kommunisten“ definierte.

Einschneidende Veränderungen setzten nach der Ersten Parteikonferenz im Januar 1949 ein. Ohne einen Parteitag einzuberufen und die Zustimmung der Delegierten abzuwarten, begann die stalinistische Umorientierung der Partei einschließlich der Kriminalisierung sozialdemokratischer Positionen («Sozialdemokratismus»). Zuvor waren auf der 13. Tagung des Parteivorstandes im Herbst 1948 die Bildung einer Zentralen Parteikontrollkommission und im Januar 1949 die Einführung der Kandidatenzeit und die Umwandlung des Zentralsekretariats zum Politbüro beschlossen worden. Das Politbüro übernahm die Kontrolle von Partei und der zu bildenden Regierung. Welche Rolle ihm zukam, verdeutlicht ein Beschluss des Sekretariats des Politbüros vom 17. Oktober 1949:

Speziell die Westarbeit und dabei die Option auf ein sozialistisch wiederzuvereinigendes Deutschland prägte die Parteiarbeit der ersten Jahre. Es gelang der SED aber nicht, die angestrebten Ziele zu verwirklichen. Dass die SED deutschlandpolitisch so erfolglos war, lag vor allem an ihrer Parteiführung, die nicht erkennen wollte, dass sie mit ihren Extrempositionen bezüglich der Umgestaltung Deutschlands in den anderen Besatzungszonen keine Gesprächspartner (nicht einmal bei der SPD) fand. Selbst die KPD in den Westzonen war nur bedingt zu Gesprächen bereit bzw. löste sich sogar im Januar 1949 organisatorisch von der SED und arbeitete als formal selbstständige Partei weiter. Auch die Versuche, die Parteiarbeit auf den Westen Deutschlands auszudehnen, misslangen.

Im Dezember 1947 tagte erstmals der auf Initiative der SED einberufene "Erste Deutsche Volkskongress für Einheit und gerechten Frieden" in Berlin. Er verstand sich als gesamtdeutsches Gremium gegen die, so in der Parteisprache der damaligen Zeit, "„Spalterpolitik der imperialistischen Westmächte“". Allerdings nahmen aus den westlichen Besatzungszonen nur 664 Delegierte und Gäste teil, darunter Parteikader der KPD (242 Delegierte) und der SPD (91 Delegierte). Trotz massiven Drucks entschied sich der Vorstand der CDU der Sowjetischen Besatzungszone, nicht teilzunehmen, stellte aber die Teilnahme von CDU-Mitgliedern als Einzelpersonen frei.

Einer der Hauptagendapunkte der 1. Parteikonferenz am 25.-28. Januar 1949 im Haus der Deutschen Wirtschaftskommission in Berlin betraf die Entwicklung der SED zu einer Partei neuen Typus. Dies ist nach eigenem Verständnis eine Partei auf der Basis des Marxismus-Leninismus und des demokratischen Zentralismus, mit straffer Parteidisziplin als Organisationsprinzip, die sich als Avantgarde des Proletariats versteht.

Als Massenpartei spiegelte die SED alle Strömungen der Gesellschaft wider. Dies entsprach nicht den Vorstellungen einflussreicher Teile der ehemaligen KPD und der sowjetischen Besatzungsmacht. So wurde, bedingt durch die zunehmende Führerschaft ehemaliger kommunistischer Mitglieder, ein neues, grundlegendes Demokratieverständnis verhindert. Zudem konnten wesentliche Vorbehalte, die schon in den 1930er Jahren gegen eine gemeinsame Politik von SPD und KPD sprachen, nicht ausgeräumt werden. Dazu gehörte in erster Linie das Abrücken von den stalinistischen Repressionen, denen auch deutsche Antifaschisten zum Opfer fielen. Verbot sich doch jeder Ansatz einer kritischen Bewertung dieser Politik allein schon aus der Anwesenheit der Besatzungsmacht heraus. Als unheilvoll erwies sich auch die starke Bindung deutscher Kommunisten an die KPdSU und die damit verbundene Einflussnahme seitens der Sowjetunion auf alle Bereiche des parteilichen Lebens. Dies gipfelte darin, dass nationale Interessen bedingungslos sowjetischen Bestrebungen untergeordnet wurden. Die Bevorzugung ehemaliger kommunistischer Funktionäre durch die Besatzungsmacht und die Art und Weise, in der diese es auch für sich nutzten, verbunden mit politischen Diffamierungen, führten zu Spannungen und Beschädigungen innerhalb der SED.


In Deutschland zeichnete sich die Bildung zweier Staaten ab, die unterschiedlichen Blöcken angehören würden. Damit wurde die Konfrontationspolitik des Kalten Krieges unmittelbar in die verschiedenen Besatzungszonen hineingetragen. Heftige Auseinandersetzungen zwischen LDPD, CDU und SED hinsichtlich der Entwicklungstendenz der Wirtschaft, Widerstände gegen Bodenreform und Verstaatlichung, sowie Widersprüche zwischen Markt- und Zentralverwaltungswirtschaft kennzeichneten die Situation in der sowjetischen Besatzungszone. Hinzu kamen verschiedene Formen der Wirtschaftskriminalität und der Sabotage. Nicht übersehen werden sollte dabei, dass die SED ‚Wirtschaftsdelikte‘ gezielt als Instrument der Kriminalisierung der Privatwirtschaft einsetzte. Dazu war im Mai 1948 die Zentrale Kommission für Staatliche Kontrolle (ZKK) gegründet worden:


Um die politische Macht zu stabilisieren und unter den Einflüssen der KPdSU schien es den führenden Kreisen der SED notwendig, die Partei zu reformieren. Auf der I. Parteikonferenz im Januar 1949 wurde zudem deutlich, dass sich die stalinistischen Kräfte erfolgreich in der SED durchgesetzt hatten. Sie wurde streng nach dem Muster der KPdSU umgebildet, dem das Prinzip des stalinischen „demokratischen Zentralismus“ zugrunde lag. Dazu gehörte die Aufgabe der weltanschaulichen Neutralität zugunsten eines strengen Materialismus, die alleinige Orientierung am vom Stalin geprägten Marxismus-Leninismus als „wissenschaftliche Weltanschauung“ und die Bekämpfung aller sozialdemokratischen Tendenzen. Etwa 150.000 Mitglieder wurden ausgeschlossen.

Begleitet wurden diese Prozesse von Verfolgungen, Verhaftungen, Anklagen und Verurteilungen von ehemaligen Sozialdemokraten, Arbeiterfunktionären, ehemaligen Mitgliedern von KPO und SAP und Westemigranten der KPD unter direkter Mitwirkung der Parteikontrollkommission und später von Organen der DDR (Ministerium für Staatssicherheit, Volkspolizei, Justizapparat) sicherten den stalinistischen Kräften in der SED die Vorherrschaft. Damit wurde die SED zur Staatspartei der DDR, neben der die anderen Blockparteien nur eine untergeordnete Rolle spielten.

Nachdem die Stalin-Noten vom März 1952 von den Westmächten zurückgewiesen worden waren und somit absehbar war, dass es mittelfristig keine Wiedervereinigung Deutschlands geben würde, beschloss die II. Parteikonferenz der SED, die vom 9. bis zum 12. Juli 1952 tagte, den "Aufbau des Sozialismus" in der DDR:


Die revolutionären Ereignisse im Herbst 1989 beendeten die Vormachtstellung der Partei. Am 1. Dezember 1989 strich die Volkskammer den Führungsanspruch der SED aus der Verfassung. Auf dem Außerordentlichen Parteitag vom 8./9. und 16./17. Dezember 1989 in Ost-Berlin wurde die Umbenennung in "Sozialistische Einheitspartei Deutschlands – Partei des Demokratischen Sozialismus" (SED-PDS) und der „unwiderrufliche Bruch mit dem Stalinismus als System“ beschlossen. In dieser Zeit veränderte sich die Partei deutlich in personeller, organisatorischer und inhaltlicher Sicht. Am 4. Februar 1990 trennte sich die SED-PDS vom Namensbestandteil SED, der neue Name lautete nun "Partei des Demokratischen Sozialismus" (PDS).

Am 17. Juli 2005 wurde die PDS umbenannt in "Die Linkspartei.PDS". Nach der Vereinigung mit der WASG gab sich die Partei den Namen "Die Linke". Es handelte sich rechtlich um eine Verschmelzung nach dem Umwandlungsgesetz, die Partei selbst bezeichnet den Vorgang als Neugründung. In einem Prozess vor der Pressekammer des Berliner Landgerichts 2009 erklärte Bundesschatzmeister Karl Holluba, die Partei "Die Linke" sei jedoch nach wie vor „rechtsidentisch“ mit der SED.

Die SED organisierte sich hauptsächlich in den Betrieben und Einrichtungen der DDR. Damit unterlag faktisch jeder Bereich des öffentlichen Lebens ihrem Einfluss. Die Anforderungen, die sich daraus für jedes Mitglied ergeben sollten, drückt die Losung "„Wo ein Genosse ist, da ist die Partei“" aus.
Damit erhielten die Grundorganisationen in den Volkseigenen Betrieben (VEB), Maschinen-Traktoren-Stationen (MTS), Volkseigenen Gütern (VEG) und Landwirtschaftlichen Produktionsgenossenschaften (LPG) ausdrückliches Kontrollrecht über die Tätigkeit der Betriebsleitungen.

Die "Parteigruppe" bildete die kleinste Organisationszelle der Partei. In ihr wählten die Mitglieder den "Parteigruppenorganisator" (PGO) als Verantwortlichen für die Parteiarbeit, einen Kassierer, Agitator und, je nach Größe, noch beigeordnete Mitglieder in die Leitung. Waren mehrere Parteigruppen vorhanden, so wurden sie in der "Abteilungsparteiorganisation" (APO) zusammengefasst, die wiederum eine gesonderte Leitung um den Abteilungsparteisekretär bildete. Die regelmäßig stattfindenden Parteiversammlungen dienten der politischen Diskussion und Schulung.
Mehrere APOs oder, in kleineren Einrichtungen, oftmals nur eine Parteigruppe bildeten die "Grundorganisation" (GO), die von einem "Parteisekretär" geleitet wurden. In den Wohngebieten gab es für nicht Berufstätige (Hausfrauen, Rentner) die weniger bedeutende "Wohnparteiorganisation" (WPO) mit analogem Aufbau.

Der Parteitag der SED war das höchste Parteiorgan.

Parteitage wurden zunehmend stabsplanmäßig vorbereitet, entbehrten nicht einer starken Inszenierung und sollten immer auch als gesamtgesellschaftliche Ereignisse verstanden werden. Damit gingen sie über den bloßen Charakter von politischen Veranstaltungen weit hinaus. Die Delegierten des Parteitages wurden nach einem vom Zentralkomitee der SED bestimmten Schlüssel in den Grundorganisationen gewählt. Dabei wurde darauf geachtet, dass das Verhältnis von Frauen und Jugendlichen, Mitgliedern staatlicher Massenorganisationen sowie von vorbildlichen Arbeitern gewahrt wurde. Da der Vorschlag für eine Delegierung von Seiten der übergeordneten Leitung an die Grundorganisation herangetragen wurde, fand eine tatsächliche, demokratische Wahl nicht statt. Eingeleitet wurde der Parteitag durch die Begrüßung der zahlreichen Gäste ausländischer kommunistischer sowie inländischer Blockparteien, den Vertretern von Befreiungsbewegungen und befreundeter Staaten. Im Mittelpunkt stand ein Grundsatzreferat des jeweiligen Generalsekretärs bzw. Ersten Sekretärs. Im Anschluss fand die Diskussion statt, in der längere ergänzende Reden von zuständigen Mitgliedern des Parteiapparates und kürzere Beiträge von ausgewählten Delegierten gehalten wurden. Alle Diskussionsbeiträge wurden langfristig vorbereitet, mehrfach zur Prüfung an übergeordnete Organe eingereicht und immer wieder verändert, sodass sie letztendlich nur noch wenig mit der Meinung des Vortragenden gemein hatten. Diese Reden wurden als Auszeichnung betrachtet und sollten an typischen Beispielen die Umsetzung der Forderungen der Partei verdeutlichen oder nachahmenswerte Initiativen aufzeigen. Während des Parteitages kam immer der Generalsekretär der KPdSU als erster zu Wort, weitere Vertreter der anwesenden Parteien folgten, darüber hinaus wurden Grußadressen verlesen. Auftretende Junge Pioniere, FDJler und Soldaten der NVA, die betont feierlich mit Fahnen einmarschierten, Meldungen an die Delegierten vollzogen und Verpflichtungen übergaben, schufen eine stark emotional geprägte Atmosphäre. Jeder Delegierte fand auf seinem Platz ein kleines Geschenk wie etwa einen Taschenrechner, ein Kofferradio o. Ä. Die Berichterstattung dominierte die gesamte Medienlandschaft der DDR. Neben den ausführlichen Live-Übertragungen wurden in der "Aktuellen Kamera" Zusammenfassungen gesendet. Das Neue Deutschland druckte als Zentralorgan die Reden des Generalsekretärs der SED sowie der KPdSU, in Zusammenfassung die anderer Gäste und ausgewählte Diskussionsbeiträge. In den Bezirkszeitungen wurde ähnlich verfahren, wobei der Umfang der gedruckten Reden geringer war, dafür aber Stimmen, Verpflichtungserklärungen und Meinungen aus der Bevölkerung breiten Raum einnahmen. Der Dietz-Verlag gab zusätzlich Broschüren mit dem vollen Inhalt der Reden heraus. Während und nach dem Parteitag wurden über die Reden und deren Bedeutung für das gesellschaftliche Leben der DDR in den Grundorganisationen diskutiert.

Im April 1946 wurde am Gründungsparteitag der SED ein jährlicher Turnus der Parteitage festgelegt. Der 2. Parteitag fand tatsächlich 1947 statt, der dritte dann erst 1950. Danach wurden die Parteitage alle vier Jahre, ab 1971 alle fünf Jahre abgehalten. Nach dem 11. Parteitag 1986 hätte die 12. Tagung turnusmäßig 1991 stattfinden sollen. Dieses Parteitagsdatum wurde jedoch im Jahre 1989 auf 1990 vorverlegt. Bedingt durch die Wende und friedlichen Revolution wurde Anfang Dezember 1989 ein kurzfristig anberaumter Sonderparteitag gehalten.

Parteisekretäre wirkten zum größten Teil ehrenamtlich neben ihrer täglichen Arbeit. Ab einer bestimmten Größe der Grundorganisation, die immer auch viele Abteilungsorganisationen und zwischengeordnete Gremien bedingte, wurden hauptamtliche Parteisekretäre gewählt.
Parteisekretäre in sehr großen Kombinaten oder in volkswirtschaftlich bedeutsamen Unternehmen waren gleichzeitig Mitglied in übergeordneten Führungsorganen, bis hin zum Zentralkomitee. Die Aufgabe des Parteisekretärs war die Organisation der politischen Arbeit. Er bereitete die Parteiversammlungen und politischen Schulungen gemeinsam mit der Parteileitung vor, kontrollierte die Einhaltung der Parteibeschlüsse, sorgte für deren Umsetzung, meldete weiter und leitete an. Dazu gehörte auch ein monatlich abzugebender Bericht über „Stimmungen und Meinungen“, in dem das Meinungsbild der Bevölkerung widergespiegelt werden sollte. Da übergeordnete Leitungen darin mitunter eine Kritik ihrer Arbeit fanden, wurden diese vielfältig abgewandelt weitergegeben. Diese Tatsache macht die zunehmende Bürokratisierung des Parteiapparates und das Vorhandensein stalinistischer Tendenzen deutlich. Parteisekretäre wurden monatlich politisch besonders qualifiziert und von Vertretern der übergeordneten Parteigremien, den Instrukteuren angeleitet und kontrolliert. Sie waren auch Mitglieder der staatlichen Leitung und sicherten so die Führungsansprüche der SED in den Betrieben und Verwaltungen ab. Entscheidungen der Leitung wurden in den Parteigremien besprochen und letztendlich beschlossen. Dies bedeutete, dass der staatliche Leiter, sofern er Mitglied der SED war, an die Umsetzung des Beschlusses gebunden wurde.

Die Wahl des Parteisekretärs erfolgte scheinbar demokratisch durch Abstimmung der Mitglieder oder Delegierte, tatsächlich war der Ausgang durch die Benennung geeigneter Kandidaten schon vorbestimmt. Der geringe Handlungsspielraum, der Parteisekretären zur Verfügung stand, verbunden mit Desillusionierung angesichts der erlebten Widersprüche der gesellschaftlichen Entwicklung führte dazu, dass besonders die ehrenamtliche Funktion oft nur unter erheblichem moralischen Druck seitens der übergeordneten Leitungen angenommen wurde.

Die Grundorganisationen eines Kreises waren der SED-Kreisleitung unterstellt. Insgesamt gab es 262 Kreisleitungen, davon zwanzig in zentralen Einrichtungen wie Freie Deutsche Jugend (FDJ), Freier Deutscher Gewerkschaftsbund (FDGB), Außenministerium, Ministerium für Außenhandel, Deutsche Reichsbahn und den militärischen Organen Ministerium des Innern (MdI), Ministerium für Staatssicherheit (MfS) und Nationale Volksarmee (NVA), die jeweils eine eigene politische Verwaltung hatten.

Die Kreisleitung als Gremium war ein gewähltes, ehrenamtlich agierendes Organ. Daneben bestand die Verwaltungsinstitution Kreisleitung, die angestellte Mitarbeiter hatte, die aber nicht zwangsläufig Mitglieder des Gremiums Kreisleitung waren, sondern den Parteiapparat verwalteten. Deren "1. Sekretär der SED-Kreisleitung" wurde unterstützt vom 2. Kreissekretär, den Sekretären für Wirtschaft, Landwirtschaft, Agitation und Propaganda und dem Vorsitzenden der Kreisparteikontrollkommission. Dieses "Sekretariat der Kreisleitung" führte die eigentlichen Geschäfte. Weitere Mitglieder des Sekretariats waren in der Regel der Vorsitzende des Rats des Kreises bzw. Rat der Stadt, der Vorsitzende der Kreisplankommission, der Vorsitzende des FDGB-Kreisvorstandes und der 1. FDJ-Kreissekretär. Sie nahmen direkt Einfluss auf die Arbeit der staatlichen Organe, beispielsweise den Rat des Kreises. Grundsätzlich konnten die Parteigremien den staatlichen Organen „nur“ Empfehlungen in der operativen Arbeit geben, waren allerdings in Kaderfragen (Personalentscheidungen) zustimmungspflichtig. Mitglied der SED-Kreisleitung war stets der Leiter der Kreisdienststelle des MfS. Der 1. Kreissekretär war auch Leiter der Kreiseinsatzleitung, für die Führung des Kreises im militärischen Verteidigungszustand verantwortlich.

Als Kontrollorgane fungierten die Kreisrevisionskommission, die Finanzen und Einhaltung der Beschlüsse kontrollierte, und die Kreisparteikontrollkommission, die innerparteiliche Abläufe prüfte und direkt dem Sekretariat unterstand. Das Zusammentreten der Kreisdelegiertenkonferenz, an der gewählte Vertreter der Grundorganisationen (Parteisekretär und, entsprechend der Größe, mehrere Mitglieder) teilnahmen, war Anlass, Rechenschaft abzulegen, Beschlüsse zu fassen, die Arbeit des Sekretariates und der Kreisleitung zu bestätigen und eine neue Kreisleitung zu wählen. In größeren Orten war eine Ortsleitung und eine Ortsdelegiertenkonferenz zwischen Kreisleitung und Grundorganisationen installiert, um auch Parteimitglieder, die nicht in betrieblichen Grundorganisationen erfasst wurden (Rentner, kleinere Handwerksbetriebe, Freiberufler etc.), zu organisieren. Der Kreisleitung war die Kreisparteischule zugeordnet. Ein Bild der Arbeit einer Kreisleitung und ihres 1. Sekretärs zeichnete der thüringische Schriftsteller Landolf Scherzer in seinem Buch "Der Erste". In kreisfreien Städten gab es die Stadtleitung der SED mit nachgegliederten Stadtbezirksleitungen mit Parteigremien in den Betrieben des Territoriums bzw. Wohnparteileitungen (WPO).

Diese Struktur setzte sich über die 15 Bezirke mit der Bezirksleitung (BL) und deren Sekretariat sowie den oben genannten Kommissionen fort. Die BL als Gremium war ein gewähltes, ehrenamtlich agierendes Organ. Daneben bestand die Verwaltungsinstitution Bezirksleitung, die angestellte Mitarbeiter hatte, die aber selten Mitglieder des Gremiums BL waren, sondern den Parteiapparat verwalteten. Deren 1. Sekretär wurde unterstützt vom 2. Sekretär und dem Sekretariat mit Verantwortlichen für Agitation und Propaganda, Wirtschaft, Wissenschaft, Kultur und Landwirtschaft. Diesem "Sekretariat" gehörten analog der Kreisleitung die Bezirkschefs von FDJ, FDGB, Bezirksplankommission etc. an. Der erste Sekretär der Bezirksleitung verfügte über eine beträchtliche Machtfülle im Bezirk, war Mitglied des Zentralkomitees der SED und seltener sogar Kandidat oder Mitglied des Politbüros des ZK der SED (immer der Bezirkssekretär für die Hauptstadt Berlin). Er war zugleich Vorsitzender der jeweiligen Bezirkseinsatzleitung (BEL), die für die Leitung des Bezirks im Verteidigungsfall als Organ des Nationalen Verteidigungsrates zuständig war. Sitz der BEL war in Friedenszeiten in der Regel das Wehrbezirkskommando. Für den Verteidigungsfall standen gedeckt vorbereitete Ausweichführungsstellen (AFüSt) zur Verfügung. Mitglied der BEL war unter anderem immer der jeweilige Leiter der Bezirksverwaltung für Sicherheit (BfS) des MfS und der Bezirksbehörde der Volkspolizei (BDVP). Dies bedeutete, dass der Leiter der BfS formal dem SED-Bezirkschef unterstellt war, aber in allen operativen Fragen eigene Befehlsgewalt hatte. Der Bezirksleitung war als Bildungsstätte die Bezirksparteischule zugeordnet. Ebenso unterstand der BL eine Tageszeitung mit zahlreichen Lokalredaktionen, die zum Parteibetrieb VOB Zentrag gehörte. Die 1. Sekretäre der SED-Kreis- und Bezirksleitungen waren jeweils schon Nomenklaturkader, das heißt, sie mussten vor ihrer Wahl in diese Parteifunktion vom ZK der SED bestätigt werden.

Das Zentralkomitee (ZK) war das höchste Organ in der Parteistruktur zwischen den Parteitagen. Das Machtzentrum lag dabei beim "Sekretariat des Komitees", dem ein Generalsekretär (von 1953 bis 1976 "Erster Sekretär") vorstand. Dieser führte wiederum den Vorsitz im Politbüro. In der politischen Rangfolge standen die Mitglieder des ZK über den Ministern, die ZK-Sekretäre und Abteilungsleiter waren gegenüber den staatlichen Ministern weisungsbefugt. Diese Führungsrolle ergibt sich aus der Verfassung von 1968, in der die Führungsrolle der SED festgeschrieben wurde.

Die Delegierten des III. Parteitags der SED wählten 1950 ein Zentralkomitee nach sowjetischem Vorbild, das an die Stelle des bis dahin paritätischen Parteivorstands trat. Auffallend war im ZK die Dominanz ehemaliger KPD-Mitglieder (62,5 %) über die ehemaligen SPD-Mitglieder (24 %). Von der anfänglichen Parität innerhalb der SED war vier Jahre nach der Vereinigung der Arbeiterparteien wenig übrig geblieben.

1989 bestand das ZK aus 165 Mitgliedern und 57 Kandidaten. Alle hochrangigen Partei- und Staatsfunktionäre der DDR waren – sofern Mitglied der SED – im ZK vertreten. Von Institutsdirektoren über Generaldirektoren wichtiger Kombinate, dem Präsidenten des Schriftstellerverbandes, Generälen bis hin zu verdienten Parteiveteranen waren alle wichtigen Funktionsträger vertreten. Das ZK war – wie die gesamte obere Machthierarchie der DDR – männlich dominiert, der Frauenanteil stieg seit 1950 nie über 15 Prozent.

Die Generalsekretäre bzw. Ersten Sekretäre des ZK der SED waren:

Den etwa zehn ZK-Sekretären waren die insgesamt 40 verschiedenen Abteilungen des ZK mit hauptamtlichen Mitarbeitern zugeordnet. Gab es 1970 noch 1.000 Mitarbeiter, waren es 1987 schon 2.000 Mitarbeiter. Eine Abteilung wurde jeweils durch einen Abteilungsleiter und seinen Stellvertreter geleitet, ebenfalls einflussreiche Positionen im DDR-Machtapparat. Jede Abteilung war wiederum in Sektoren gegliedert mit Sektorenleitern, Mitarbeitern und Instrukteuren.

ZK-Mitglieder und Mitarbeiter hatten mit ihren Dienstausweisen freien Zugang zu allen staatlichen und Parteieinrichtungen, eigene Ferienheime und andere Privilegien.

Das ZK der SED hatte überwiegend seinen Sitz im "ZK-Gebäude", dem Haus am Werderschen Markt in Berlin-Mitte.

Das Zentralkomitee wurde oft als „kleiner Parteitag“ bezeichnet, da es zwischen den eigentlichen Parteitagen mehrmals im Jahr zusammentrat und die Arbeit des Politbüros absegnete. Während unter dem 1. Sekretär Ulbricht noch lebhafte Diskussionen im ZK stattfanden, tagte unter seinem Nachfolger Honecker dieses Gremium nur noch sehr förmlich zweimal im Jahr. Die Tagesarbeit übernahm stattdessen das Politbüro, ein kleiner Zirkel der Sekretäre des ZK und anderer hochrangiger Parteifunktionäre.

Egon Krenz und Erich Mielke führten am Abend des 16. Oktober 1989 Vorgespräche für die Absetzung Honeckers. In der Sitzung des Politbüros vom 17. Oktober 1989 schlug Willi Stoph als ersten Punkt der Tagesordnung vor: „Entbindung des Genossen Honecker von seiner Funktion als Generalsekretär und Wahl von Egon Krenz zum Generalsekretär“. Günter Schabowski erweiterte den Antrag und forderte die Absetzung Honeckers auch als Staatsratsvorsitzenden und Vorsitzenden des Nationalen Verteidigungsrates. Alfred Neumann wiederum forderte darüber hinaus die Ablösung von Günter Mittag und Joachim Herrmann. Es kam zu einem einstimmigen Beschluss des Politbüros. Dem ZK der SED wurde vorgeschlagen, Honecker, Mittag und Hermann von ihren Funktionen zu entbinden. Bei der folgenden ZK-Sitzung waren 206 Mitglieder und Kandidaten anwesend. Das ZK folgte der Empfehlung des Politbüros. Öffentlich hieß es: „Das ZK hat der Bitte Erich Honeckers entsprochen, ihn aus gesundheitlichen Gründen von der Funktion des Generalsekretärs, vom Amt des Staatsratsvorsitzenden und von der Funktion des Vorsitzenden des Nationalen Verteidigungsrates der DDR zu entbinden.“ Egon Krenz wurde per Akklamation einstimmig zum neuen Generalsekretär der SED gewählt. Am 20. Oktober 1989 musste auch Margot Honecker von ihren Ämtern zurücktreten. Die letzte Sitzung des Zentralkomitees der SED fand am 3. Dezember 1989 statt, auf der Hans Albrecht, Erich Honecker, Günther Kleiber, Werner Krolikowski, Erich Mielke, Gerhard Müller, Alexander Schalck-Golodkowski, Horst Sindermann, Willi Stoph, Harry Tisch, Herbert Ziegenhahn und Dieter Müller aus der Partei ausgeschlossen wurden. Danach traten das Politbüro und das gesamte ZK zurück.

Die wichtige Tagesarbeit übernahm das Politbüro, ein kleiner Zirkel hochrangiger Parteifunktionäre, bestehend aus 15 bis 25 Mitgliedern und etwa zehn Kandidaten (ohne Stimmrecht), darunter die etwa zehn Sekretäre des ZK. Der Generalsekretär des ZK der SED führte zugleich den Vorsitz im Politbüro. Die offizielle Regierung, der Ministerrat der DDR, hatte die Beschlüsse des Politbüros nur noch über die Ministerien nach unten umzusetzen. Dabei wurde der Ministerrat ständig von den Parteigremien kontrolliert, wodurch diese die laut DDR-Verfassung „führende Rolle der Partei“ sicherstellten. Die Vorsitzenden des Ministerrates und der Präsident der Volkskammer waren, sofern SED-Mitglieder, auch Mitglieder des Politbüros.

In der Praxis wurden nur noch die umfangreichen, vom Sekretariat und den Abteilungen des ZK erarbeiteten Vorlagen von den Mitgliedern meist einstimmig beschlossen, die den Mitgliedern zuvor per Kurier zum Aktenstudium zugestellt worden waren. Dabei verließ man sich meist auf die Beschlussempfehlung des für das jeweilige Fachgebiet zuständigen Politbüromitglieds, ohne anderen in ihr Fachgebiet hinein zu reden – dies vor allem dann, wenn der Generalsekretär auf der Vorlage bereits vorab sein Einverständnis notiert hatte. Übergreifend konnte nur er eingreifen. Kontroverse Diskussionen gab es kaum, der Generalsekretär behielt sich das Letztentscheidungsrecht vor. Insbesondere Abstimmungen zu Sicherheitsfragen waren tabu, diese wurden direkt zwischen dem jeweiligen Minister und dem Generalsekretär streng vertraulich geregelt.

Zu speziellen Themen wurden leitende Kader wie Generaldirektoren, Institutsdirektoren, Minister oder Staatssekretäre zur Verteidigung ihrer Entscheidungsvorlage vorgeladen. Das Politbüro tagte jede Woche dienstags ab 10 Uhr für etwa zwei Stunden in der zweiten Etage des Zentralkomitee-Gebäudes, eröffnet und geschlossen wurden die Sitzungen, die nach Günter Schabowski in einer „Klassenzimmeratmosphäre“ stattfanden, vom Generalsekretär. Außerhalb der Sitzungen und in der Urlaubszeit kam es auch zu Beschlüssen im Umlaufverfahren, das heißt, eine Unterschriftenmappe wurde von den Mitgliedern zustimmend abgezeichnet.

Kommissionen und Arbeitsgruppen beim SED-Politbüro und deren Leiter:

Für die unterstützende administrative Arbeit gab es ein "Sekretariat des Politbüros", seine Leiter waren:

Das Sekretariat des ZK tagte jeweils am Mittwoch, um als Planungsstab die am Vortag getroffenen Entscheidungen des Politbüros umzusetzen und dessen nächste wöchentliche Sitzung vorzubereiten. Es bestand aus den Sekretären des ZK der SED. Entscheidende Bedeutung hatte das Sekretariat bei der Auswahl der ZK-Nomenklaturkader, dies waren die etwa 300 höchsten Positionen in Partei und Staat, die vor ihrer Neubesetzung durch das ZK-Sekretariat zustimmungspflichtig waren.

Die praktische Arbeit wurde von den diversen Abteilungsleitern und ihren Mitarbeitern geleistet. Dem ZK-Sekretär für Agitation und Propaganda waren beispielsweise die drei Abteilungen Agitation, Propaganda und Befreundete Parteien unterstellt. Die Abteilung Agitation war für die Organisation und Lenkung der Massenmedien verantwortlich, sowie wichtigste Zensurbehörde der DDR.

Anders als andere kommunistische Parteien, die erst nach dem stalinistischen Modell errichtet worden sind – Stalin hatte sein Amt, das des Generalsekretärs, nach dem Tod des Vorsitzenden Lenin zum Führungsamt ausgebaut –, kannte die SED grundsätzlich auch die Funktion eines Vorsitzenden. Doch lag die tatsächliche Macht von Anfang an auch hier beim Generalsekretär; 1954 wurde das Amt ersatzlos abgeschafft. 1971 wurde es als machtloses, symbolisches Amt für Walter Ulbricht neu geschaffen. Immerhin waren mit ihm aber die Mitgliedschaft im Politbüro sowie bedeutende Funktionen im Staat verbunden:


Das erklärte politische Ziel der SED, die Errichtung und Erhaltung der Diktatur des Proletariats konnte aus ihrer Sicht nur dadurch sichergestellt werden, dass alle gesellschaftlichen Bereiche ständiger Kontrolle und Einflussnahme unterlagen. Mit der Doktrin der Führungsrolle der Partei sollte es gelingen, die Fäden des politischen, geistigen und wirtschaftlichen Lebens in den parteilichen Machtzentren zusammenlaufen zu lassen. Abgeleitet aus dem Kommunistischen Manifest von Marx und Engels wurde dieser Führungsanspruch letztlich seit 1968 in der Verfassung der DDR (Abschnitt I, Kapitel 1, Artikel 1) verankert:

Die Außenpolitik der SED verfolgte in den Anfangsjahren vor allem das Ziel einer Anerkennung der DDR als souveräner Staat, später traten wirtschaftliche Ziele in den Vordergrund. Die SED verfolgte dabei innerhalb des Kommunistischen Parteienspektrums Westeuropas eine durchaus eigenständige Außenpolitik mit eigenen Beziehungen zu den "Bruderparteien", anders als etwa die Italienische oder Französische Kommunistische Partei erlaubte sich die SED keinerlei Kritik an der Moskauer Außenpolitik. So wurde etwa von der Italienischen KP der Einmarsch des Warschauer Paktes in die CSSR 1968 und die Niederschlagung des Prager Frühling heftig kritisiert, während die DDR den Einmarsch logistisch unterstützte. Darunter litten die Beziehungen der SED zu den Italienischen Kommunisten zunächst, aus ökonomischen Gründen und wegen des Werbens um Anerkennung in Westeuropa wurden die engen Beziehungen jedoch beibehalten. 

Zum Zeitpunkt des Vereinigungsparteitags gab es laut den offiziellen Statistiken 679.159 SPD-Mitglieder und 619.256 KPD-Mitglieder, so dass die Partei 1.298.415 angab. Diese Zahlen wurden von Beginn an angezweifelt, insbesondere weil rund 200.000 ehemalige SPD-Mitglieder nicht in die SED eintraten. Viele stillschweigend durch Nichtzahlung des Beitrags wodurch sie weiter in der Statistik mitgezählt wurden. Bis September stieg die Zahl der Mitglieder stetig bis auf 1.766.198. Ab Oktober 1947 wurde begonnen die Statistik um Karteileichen zu bereinigen und dadurch bedingt verringerte sich die Mitgliederzahl innerhalb des nächsten Jahres trotz über 70.000 Neumitgliedern um 20.000. Innerhalb des nächsten Jahres sank die Mitgliederzahl im Saldo um weitere 169.944.

In der Parteiführung war man auf der einen Seite besorgt über den Mitgliederrückgang während man auf der anderen Seite auch kein unkontrolliertes Anwachsen wünschte. Ausdruck dessen war die 1949 eingeführte Kandidatenzeit von zwei Jahren. Politisch gewollt war es, den Einfluss alter Parteikader aus SPD und KPD zu verringern. Tatsächlich waren dann auch schon Ende 1951 nur noch weniger als 16 % der Mitglieder schon vor 1933 in einer der Vorgängerparteien oder deren Jugendorganisationen politisch in der Arbeiterbewegung organisiert.

Die SED war im Nachkriegsdeutschland die erste Partei, die sich ehemaligen Nationalsozialisten öffnete. Am 15. Juni 1946 fasste nach einer entsprechenden Einführung von Wilhelm Pieck das SED-Zentralsekretariat den neuen grundlegenden Beschluss zur Aufnahme der ehemaligen Mitglieder der NSDAP, soweit sie bei der Entnazifizierung als „Mitläufer“ eingestuft waren, in die SED und hob damit einen entsprechenden Unvereinbarkeitsbeschluss auf. Mit dem Rückgang der Mitglieder aus der Arbeiterbewegung stieg der Anteil derer, die in der NSDAP oder einer ihrer Gliederungen Mitglied waren. Damals waren 8,6 % der Mitglieder und 9,3 % der Kandidaten ehemalige NSDAP-Mitglieder mit einem Spitzenwert von 15,4 % im Bezirk Erfurt. Dort hatten unter Einbeziehung aller ehemaligen NS-Organisationen 35,8 % der SED-Mitglieder eine NS-Vergangenheit.

Zu Beginn der 1950er Jahre sank die Zahl der Mitglieder weiter mit jährlichen Verlusten im zweistelligen Prozentbereich. Die meisten wurden aus der Parteiliste gestrichen weil sie den Beitrag nicht zahlten. Dies war eine beliebte Möglichkeit stillschweigend auszutreten, da man dadurch inquisitorische Fragen nach den Gründen vermeiden konnte. Der absolute Tiefstand wurde 1952 mit 1.125.691 Mitgliedern erreicht.

Die soziale Zusammensetzung der Mitglieder unterlag von Anfang an einem starken Wandel. Ab 1946 nahm der Anteil der Arbeiter unter den Mitgliedern, der 1946 noch fast 55   % betragen hatte, beträchtlich ab. 1959 war der Anteil der Angestellten mit ebenfalls rund einem Drittel fast genauso hoch wie der der Arbeiter. Obwohl die Mitgliederwerbung unter Arbeitern weiter intensiv betrieben wurde zeigt sich darin die Funktion der SED als dominierende Staats- und Verwaltungspartei. Für diese war es wichtig das möglichst alle Funktionen in der Verwaltung und der Wirtschaft politisch von ihr beherrscht wurden. Um äußerlich den Anschein einer Arbeiterpartei zu erhalten wurden aufgrund eines Sekretariatsbeschlußsses ab 1962 hauptamtliche Funktionäre der Partei und ihrer Organisationen und auch bewaffneter Organe als in der Statistik als Arbeiter aufgeführt. Somit ist diese für die Folgejahre wenig aussagefähig. Es gelang der Partei nie, eine breitere Verankerung in der Arbeiterschaft zu erreichen.

Der Frauenanteil in der Partei lag, bedingt durch die deutsche geschichtliche Entwicklung, in der nur wenige Frauen in Parteien organisiert waren, 1950 bei 21,5 % und konnte bis 1960 trotz aller Versuche der Parteiführung ihn zu erhöhen nur unwesentlich auf 23,5 % erhöht werden. Die SED war in ihren Anfangsjahren, wie schon ihre Vorgängerparteien, in Relation zur Gesamtbevölkerung überaltert. Gegründet wurden die meisten Parteien von Altmitgliedern aus der Zeit vor 1933 und insgesamt war die Bereitschaft jüngerer Männer, sich nach Krieg und oft Gefangenschaft politisch zu betätigen gering, so dass 1946 nur 8,8 % der Mitglieder jünger als 30 Jahre war. Nachdem sich dieser Wert, bedingt durch intensive Anwerbung jüngerer Mitglieder, bis 1948 auf 16,7 % erhöht hatte, sank die relative Zahl jüngerer Mitglieder bis 1960 auf 9,3 % der bis 25-jährigen unter Berücksichtigung des von 21 auf 18 vorverlegten Eintrittsdatums. Im weiteren Bestehen gelang es der SED verstärkt jüngere Mitglieder aufzunehmen. 1970 waren 19,4 % und 1986 23,6 % der Mitglieder jünger als 30 Jahre. Zurückzuführen ist das darauf, dass Parteimitglieder bessere gesellschaftliche und berufliche Aufstiegschancen hatten. besonders Parteifunktionäre, die als Staats- und Wirtschaftskader als politische Bürokraten agierten, genossen materielle und immaterielle Vorteile zu denen die Mehrheit der Bevölkerung keinen Zugang hatte.

Im Juni 1971 hatte die Partei 1.909.859 Mitglieder. Insbesondere vor Parteitagen wurde in den Folgejahren die Mitgliederwerbung intensiviert und 1975 waren es erstmals über zwei Millionen Mitglieder und Kandidaten. 1987 erreichte der Mitgliederstand seinen Höchstwert mit 2.328.331. dass entsprach ungefähr jedem sechsten DDR-Bürger über 18 Jahren.

1989 begann sich der Abwärtstrend schon im ersten Halbjahr abzuzeichnen, in dem schon Tausende ihre Mitgliedschaft kündigten. Im Sommer verstärkte sich dieser Trend mit ungefähr 100.000 Austritten zwischen August und Oktober. In einer zweiten Austrittswelle in den Monaten Oktober/November folgten weitere 220.000 bevor eine regelrechte Flucht aus der Partei begann, in der bis Ende Januar 1990 insgesamt 907.480 die SED verließen.

Klaus Schroeder bezeichnet die DDR als Land der „kleinen Leute“, da Personen bürgerlicher Herkunft kaum Aufstiegschancen hatten, und deshalb insbesondere in der Führungsebene ehemalige „kleine Leute“ regierten. Diese sicherten nach ihrem Aufstieg für sich und ihre Klasse Privilegien.

Die SED hatte zuletzt etwa 2,3 Millionen Mitglieder. Dies war ein sehr hoher Anteil bei etwa 8 Millionen Erwerbstätigen und 16,8 Millionen Menschen Gesamtbevölkerung in der DDR. Damit führte die SED ihren eigenen Anspruch, als „Avantgarde der Arbeiterklasse“ zu gelten, "ad absurdum". Allein 339.000 Mitglieder, also 15 Prozent, waren 1981 Nomenklaturkader, das heißt hohe leitende Partei- oder Wirtschaftsfunktionäre.

In der DDR war der Begriff "Die Partei" als Synonym für die SED gebräuchlich und wurde dort zum geflügelten Wort.

In den späten 1980er Jahren der DDR wurde es, bedingt durch zunehmende Widersprüche zwischen der erlebten gesellschaftlichen Wirklichkeit und der verkündeten Theorie, immer schwieriger, insbesondere junge Menschen zum Parteieintritt zu bewegen. Während einige den beruflichen Aufstieg durch eine Parteimitgliedschaft fördern wollten oder damit gedrängt wurden – so wurde es Meisteranwärtern nahegelegt, in die SED einzutreten –, war es gerade für die Verantwortlichen schwierig, die geforderte Anzahl Arbeiter zu werben. In den Kreisen der künstlerischen Intelligenz und in der Ärzteschaft galt es traditionell eher als befremdlich, „Genosse“ zu sein, aber Spitzenpositionen waren auch dort an ein „Bekenntnis zur Partei“ gekoppelt.

Für die SED arbeiteten etwa 44.000 hauptamtliche Mitarbeiter und 300.000 nebenamtliche Mitarbeiter, darunter 100.000 Parteisekretäre, wobei zumindest die einfachen Mitarbeiter lediglich knapp durchschnittlich zu einem vergleichbaren Wirtschaftskader bezahlt wurden.

Die Aufnahme in die SED erfolgte ab dem vollendeten 18. Lebensjahr. Es bedurfte eines schriftlichen begründeten Antrags auf Mitgliedschaft als „Kandidat der SED“, der von zwei Bürgen unterstützt werden musste, die langjährige Mitglieder der SED waren und den Antragsteller kannten. Die Kandidatenzeit dauerte für „Angehörige der Arbeiterklasse“ ein Jahr und für andere länger.

In dieser Zeit hatte der Kandidat die Pflicht und das Recht, an allen Parteiversammlungen der zuständigen Grundorganisation ohne Stimmrecht teilzunehmen. Es erfolgte eine spezielle Kandidatenschulung, und oftmals wurden Kandidatenaufträge vergeben. Sie hatten zum Beispiel folgende Form:

Nach Ablauf der Kandidatenzeit wurde in der Parteigruppe abgestimmt, ob die Aufnahme als Mitglied erfolgen sollte, wobei es auch zu Ablehnungen oder Verlängerung der Kandidatenzeit kam. Allerdings war dies sehr selten und häufig mit Kritik an der Grundorganisation seitens übergeordneter Leitungen verbunden. Der betreffende Kandidat musste mit Benachteiligungen und Anfeindungen im Berufsleben rechnen.

Für die Aufnahme war die Angehörigkeit zu sozialen Schichten oder Klassen durchaus maßgebend. Es bestanden festgeschriebene Mitgliederverhältnisse von Arbeitern, Angestellten, Genossenschaftsbauern, Mitgliedern der sozialistischen Intelligenz, Handwerkern und Freiberuflern. Während Arbeiter und Genossenschaftsbauern praktisch ohne Beschränkung in die „Arbeiterpartei“ SED eintreten durften, ja sogar gezielte Werbeaktionen durchgeführt wurden, war es unter Umständen für einen Angehörigen der Intelligenz (insbesondere Lehrer) besonders dann schwer in die SED aufgenommen zu werden, wenn sich gerade die Mitgliederverhältnisse nicht in der gewünschten Übereinstimmung befanden. Teilweise mussten sich diese weniger gewünschten Schichten jahrelang mit dem Kandidatenstatus begnügen. 1986 wurden 58,2 % aller Mitglieder als „Arbeiter“ eingestuft, tatsächlich Produktionsarbeiter waren aber nur 37,9 %. Angehörige der Intelligenz waren offiziell nur 22,4 % und Rentner 14 % aller Mitglieder.

In der Praxis kam es zu den abenteuerlichsten Verbiegungen, um noch als gewünschter Arbeiter zu gelten. So galt der Generaldirektor, wenn er vor 40 Jahren seine Karriere als Arbeiter begonnen hatte, zeitlebens als Arbeiter.

Bei erfolgreicher Aufnahme wurden dem neuen Genossen die Dokumente, das heißt Mitgliedsausweis, Parteiprogramm und Parteistatut (zwei kleine rote Büchlein, Format etwa DIN A6) feierlich übergeben. Der Verlust des Mitgliedsausweises „Parteidokument“ galt als grobe Verfehlung, da er ja dem „Klassenfeind“ in die Hände fallen konnte, und wurde mindestens mit einer Rüge geahndet. In den Anfangsjahren mussten die Genossen den Ausweis ständig bei sich tragen. In den harten Zeiten des Kalten Krieges der 1950er Jahre wurde noch wesentlich stärker auf Parteidisziplin geachtet, und der Ausschluss des betreffenden Genossen wäre sicher gewesen.

Beschlüsse wurden nach Diskussion meist einstimmig gefasst, Stimmenthaltung war laut Parteistatut nicht vorgesehen. Die Diskussionen wurden auch von unten nach oben immer einsilbiger, bis es auf den Parteitagen nur noch zur Verlesung vorher schriftlich eingereichter und genehmigter „Diskussionsbeiträge“ kam.

Die Mitgliedschaft in der SED endete durch "Ausschluss, Austritt (Streichung) oder Tod". Ein Austritt war jedoch faktisch nicht möglich, da der betreffende abtrünnige Genosse einfach vorher ausgeschlossen wurde. Dies wurde dann als "Streichung" bezeichnet. Parteistrafen wie "Rüge", "Strenge Rüge" und "Ausschluss" wurden durch die Parteikontrollkommissionen auf allen Parteiebenen verhängt, die über die „Einheit und Reinheit“ der Partei streng zu wachen hatten.

Vorsitzende der "Zentralen Parteikontrollkommission" (ZPKK) beim ZK der SED:

Mit Rügen wurden auch „moralische Verfehlungen“ wie Ehebruch, der eines Parteimitgliedes im öffentlichen und persönlichen Leben nicht würdig war, geahndet. Eine strafrechtliche Verurteilung führte zum Parteiausschluss.

Eine Sonderform, seine Parteimitgliedschaft wieder zu verlieren, war der etwa alle zehn bis fünfzehn Jahre stattfindende sogenannte "Umtausch der Parteidokumente", das heißt, es wurde ein neuer Mitgliedsausweis ausgegeben. Dies war mit einer umfassenden innerparteilichen Diskussion und „Reinigung“ verbunden, in der „unzuverlässige“ Genossen nicht wieder in die Partei kamen, es erfolgte sozusagen ein „kalter Ausschluss“ mit der Streichung von der Mitgliederliste. So wurden zum Beispiel zwischen Januar und Juli 1951 ca. 22 % der Mitglieder wegen ‚ideologischer Unreife‘ ausgeschlossen. Der letzte Umtausch war im Herbst 1989 kurz vor dem Ende der DDR geplant. Er ging einher mit persönlichen Gesprächen in den Grundorganisationen. Die Herbstereignisse ließen den Umtausch platzen, und es wurden keine neuen Parteidokumente mehr ausgegeben. Sie waren jedoch bereits in den Kreisleitungen vorhanden und ausgestellt.

Als Mitglied der SED nahm man an den Parteigruppenversammlungen beziehungsweise Mitgliederversammlungen der Betriebsparteiorganisationen (BPO) oder bei nicht Erwerbstätigen/Rentnern der Wohngebietsparteiorganisationen (WPO) teil. Man konnte gewählt werden und wählen. Kandidaten hatten nur beratende Stimme. In den Versammlungen gab es eine Tagesordnung und ein Versammlungsprotokoll.

Der Information der etwa 100.000 Parteisekretäre diente das parteiinterne und weitestgehend vertrauliche Mitteilungsblatt "Parteiinformation". In den Versammlungen wurden häufig Argumentationen zu aktuellen Geschehnissen daraus vorgetragen.

Die Parteiversammlung fand monatlich in allen Betrieben immer montags nach Arbeitsschluss, also ab etwa 17:00 Uhr statt und dauerte ein bis zwei Stunden. Sie war nur Genossen und Kandidaten zugänglich. In Ausnahmefällen wurden öffentliche Versammlungen durchgeführt.
Neben den Sitzungen der Grundorganisation wurden monatliche Zusammenkünfte der Abteilungsparteiorganisation (APO) und das Parteilehrjahr durchgeführt.

Das "Parteilehrjahr" diente der politisch-ideologischen Schulung der Mitglieder und wurde monatlich durchgeführt. Geleitet wurde es von einem Mitglied der Parteileitung der Grundorganisation beziehungsweise einem geschulten Propagandisten. Es wurde zentral mit Veranstaltungen für die Seminarleiter begonnen. An den Seminaren nahmen auch Nichtmitglieder teil, wenn sie besondere Führungspositionen einnahmen. Für Lehrer existierte ein Beschluss der Gewerkschaft, in der die Teilnahme für Parteilose verpflichtend war. Aus einem Themenangebot wählte die Parteileitung das für die Grundorganisation bedeutsame aus. In hohen Auflagen wurden Broschüren zur Unterstützung der Arbeit im Dietz-Verlag herausgegeben. Dieses Material wurde von den Teilnehmern des Lehrjahres für den Preis von 1,60 Mark käuflich erworben.

Themenbeispiele:

Zusätzlich zum Parteilehrjahr gab es in den Betrieben in den 1980er Jahren das "Argument der Woche", kurze politische Schulungen für die Mitarbeiter durch ein dazu beauftragtes Mitglied der SED.

Die SED-Parteischulen waren ebenfalls hierarchisch organisiert. Am unteren Ende standen die Kreisparteischulen (KPS) mit Abendkursen, danach kam die Delegation zu den Bezirksparteischulen (BPS, 1 Jahr Direktstudium), und an der Spitze war die Parteihochschule Karl Marx (PHS, 1 und 3 Jahre Studium) in Berlin.

In den 1980er-Jahren bildeten 255 SED-Kreis- und 478 Betriebsschulen die Basis des Schulungssystems. Dort wurden die Kurse neben dem Beruf absolviert. An den 15 Bezirksparteischulen - so etwa in Schwerin, Rostock und Neubrandenburg - gab es dreimonatige oder einjährige Vollzeit-Lehrgänge. An der Bezirksparteischule in Ballenstedt beispielsweise absolvierten von 1956 bis 1989 - also in einer Zeitspanne von 33 Jahren - mehr als 16.000 SED-Parteimitglieder aus den DDR-Bezirken Halle (bis 1989) und Magdeburg (bis 1975) einjährige Lehrgänge. Während der Zeit des Studiums bekamen die Kursteilnehmer 80 Prozent ihres vorigen Nettogehalts als Stipendium. 

Üblicherweise konnte die nächste Stufe nur absolvieren, wer zuvor die vorhergehende Schule erfolgreich absolviert hatte. Bezirks- und Parteihochschule waren auch im Fernstudium möglich. Der Abschluss an der Parteihochschule war Diplom-Gesellschaftswissenschaftler. Rektorin der Parteihochschule war von 1950 bis 1983 die als besonders orthodox bekannte Hanna Wolf, mit sehr engen persönlichen Kontakten zum Generalsekretär.

Weitere Einrichtungen auf zentraler Ebene waren das Institut für Marxismus-Leninismus (IML) und die Akademie für Gesellschaftswissenschaften beim ZK der SED. Deren theoretisches Organ war die Monatszeitschrift "Die Einheit". Als Material für die aktuelle Parteiarbeit gab das ZK der SED die Monatsschrift "Neuer Weg" heraus.

Alternativ war eine Delegierung zum Besuch der Parteihochschule der KPdSU in Moskau möglich. Hier studierten im Ein- oder Dreijahresstudium viele Kader aus allen sozialistischen Ländern und Volksdemokratien. Die Diskussionen waren von einer wesentlich offeneren globalen Perspektive geprägt. Aufgrund dieses Moskauaufenthaltes sprachen viele leitende Parteikader (ab 1. Kreissekretär aufwärts) exzellent Russisch. Absolvent als Diplom-Gesellschaftswissenschaftler mit Staatsexamen war zum Beispiel Egon Krenz.

Ohne den Besuch einer Parteihochschule war es in der DDR praktisch unmöglich, eine staatliche oder innerparteiliche Spitzenposition zu erreichen, da fachliche und gesellschaftliche Qualifikation für den „sozialistischen Leiter“ eine Einheit darstellten.
Die SED verfügte über umfangreiches Vermögen, insbesondere Infrastruktureinrichtungen wie Parteigebäude, Druckereien, Zeitungsverlage, aber auch Erholungseinrichtungen und anderes. Weiterhin bestand ein Auslandsvermögen, das unter anderem zur Unterstützung von Schwesterparteien im Westen und der Dritten Welt, aber auch zu geheimdienstlichen Zwecken eingesetzt wurde, sowie ca. 160 eingetragene Betriebe.

Mit dem 1. Juni 1990 ging das bis August 1989 bestehende Vermögen der SED zur Prüfung und treuhänderischen Verwaltung in die Hände der Unabhängigen Kommission zur Überprüfung des Vermögens der Parteien und Massenorganisationen (UKPV) und der Treuhandanstalt über.

In verschiedenen Organisationen, insbesondere in der SED, aber auch in den anderen Parteien sowie den teilweise in Auflösung befindlichen Massenorganisationen versuchten Funktionäre auf verschiedenen Ebenen, die Geldbestände am Gesetz vorbei zu „sichern“ oder für private Zwecke zu veruntreuen. Alleine das nach der Wende sichergestellte Vermögen der SED beläuft sich auf rund 1,16 Milliarden Euro. Dazu zählen nach einem – noch nicht rechtskräftigen – Urteil des Obergerichts des Kantons Zürich vom 25. März 2010 128.355.788 Euro, welche 1992 spurlos von Konten der ehemaligen DDR-Handelsgesellschaft Novum und deren Tochtergesellschaft Transcarbon verschwunden waren. Alleinige Gesellschafterin der beiden Unternehmen war die Österreicherin Rudolfine Steindling, genannt „Rote Fini“. Sie hat sich das Geld 1991 von der Bank Austria bar auszahlen lassen. Die Unicredit Bank Austria muss, als Rechtsnachfolger, der Bundesrepublik Deutschland den Schaden ersetzen.

Ein weiteres Beispiel ist der als Putnik-Deal bekanntgewordene Versuch der PDS, ehemaliges SED-Vermögen ins Ausland zu verschieben.





</doc>
<doc id="10283" url="https://de.wikipedia.org/wiki?curid=10283" title="4. Buch Mose">
4. Buch Mose

Das 4. Buch Mose, auf , Bemidbar oder , Bamidbar, auf genannt, ist das vierte Buch des Tanachs wie auch des Alten Testaments und damit das vierte Buch der verschiedenen Bibelkanons. Es handelt vom Volk Israel in der Wüste und wurde in 36 Kapitel unterteilt, wie es sich seit dem Mittelalter etabliert hat. Zu Beginn werden auch die Zwölf Stämme Israels in ihren Zahlen nach männlichen Erwachsenen und in ihrer Ordnung angegeben.

Das Buch heißt im Hebräischen nach den ersten Worten des Buches בַּמִּדְבָּר "Bamidbar" oder "Bemidbar" („in der Wüste“). Die Benennung nach direkten oder bedeutendsten Anfangsworten ist mit ihrer Verwendung als "Parascha" oder "Sidra" („Wochenabschnitt“) für die Lesung der Tora („Weisung, Lehre“) in der Synagoge im Judentum verknüpft. Im Lateinischen heißt es "Numeri", nach dem Griechischen , „Zahlen“. Die Bezeichnung ist darauf zurückzuführen, dass im ersten Teil viele Zahlenangaben enthalten sind.

Die deutsche Bezeichnung "4. Buch Mose" geht vor allem auf die Bibelübersetzung Martin Luthers zurück und folgt dem sonstigen traditionellen jüdischen und kirchlichen Sprachgebrauch, der Mose als Autor benennt.

Das 4. Buch Mose ist im Original in hebräischer Sprache geschrieben und ist Teil der Tora, die hebräisch auch Chumasch, oder auf griechisch als Pentateuch bezeichnet wird. Im Deutschen spricht man auch von den „fünf Büchern Mose“. Sie bilden den ersten Teil des Tanachs und des Alten Testaments.

Die Lutherbibel bietet folgende Inhaltsübersicht:

Im 4. Buch Mose und auch im übrigen Pentateuch wird kein Verfasser genannt. Die deutsche Bezeichnung als die „fünf Bücher Mose“ verweist auf Mose als Autor des gesamten Pentateuchs. Diese Sichtweise wird nach wie vor vom orthodoxen Judentum sowie einem Teil der Christen vertreten.


Zu Beginn des Buches werden die Stämme der Israeliten aufgezählt und eine Volkszählung beschrieben, in der alle Männer ab 20 Jahren aufgeführt werden – es sind 603.550 Männer. Die Leviten werden nicht dazugezählt, da sie als Träger und Hüter des Heiligen Zeltes und der Bundeslade für Verteidigung und Kriegsführung nicht zur Verfügung stehen. Ihre Aufgabe wird in Kapitel 3 ausführlich beschrieben. Die Lager- und Marschordnung werden ebenfalls festgeschrieben.

Im weiteren Verlauf des Buches werden verschiedene Gesetze beschrieben: Es wird beschrieben, was Aussatz ist, und dass Aussätzige das Lager zu verlassen haben. Es wird beschrieben, wie bei Diebstahl und Verdacht auf Ehebruch gehandelt werden soll. Vorschriften, wie Priester und andere Menschen sich dem Dienst Gottes weihen können, werden beschrieben, wie auch der priesterliche Segen.

Nun kehrt das Buch von den gesetzlichen Vorschriften zu der Handlung um Mose und das Volk Israel zurück. Es werden die Einweihung des Heiligtums sowie die Geschenke zur Einweihung (Gold, Silber, Opfertiere) beschrieben. Das Licht im Heiligtum wird beschrieben und die Weihung der Leviten zum Dienst, sowie weitere Vorschriften zum Pessachfest.

Gott lässt Signaltrompeten herstellen und schreibt ihre Verwendung vor, die Marschordnung wird beschrieben, und das Volk macht sich auf den Weg. Nach einiger Zeit fängt es an zu klagen, dass es kein Fleisch bekäme. Gott schickt ihnen Wachteln, an denen jedoch viele Israeliten sterben. Das Volk zieht weiter. Mirjam, Moses Schwester, lehnt sich gegen ihren Bruder auf, da er eine Ägypterin geheiratet hat. Dafür wird sie mit Aussatz bestraft, der jedoch nach einer Woche abheilt. Danach erst wandert das Volk weiter.

Kundschafter werden nach Kanaan ausgesandt. Sie berichten von einem reichen Land, das jedoch von einem starken Volk bewohnt wird. Das Volk Israel weigert sich weiterzuziehen, und Gott will sie dafür strafen. Nur durch Moses Intervention wird das Volk verschont, doch werden die Menschen des Volkes das Gelobte Land nicht sehen, sondern erst ihre Nachkommen. So zieht das Volk vierzig Jahre lang durch die Wüste, und diejenigen, die schon vorher nach Kanaan wollen, werden von den dortigen Bewohnern verjagt.

Im 15. Kapitel werden die Opfervorschriften für das Land Kanaan ergänzt, und die Menschen werden noch einmal ermahnt, Gottes Gebote zu beachten. Eine versehentliche Nichteinhaltung der Opfervorschriften kann durch Darbringung weiterer Opfer das Versehen entschuldigt werden (). Bei vorsätzlicher Nichteinhaltung hingegen soll der Mensch ausgemerzt werden (). Als Beispiel wird in von einem Mann erzählt, der am Sabbat Holz gesammelt hatte. Die Israeliten fragten Mose, was wegen des Verstoßes gegen das Sabbatgebot unternommen werden soll. Gott befahl Mose die Steinigung des Mannes, die von den Israeliten daraufhin ausgeführt wurde.

Korach, einer der Leviten, bringt das Volk auf seine Seite und fragt Mose, warum nur er und nicht alle heilig seien. Auch andere Männer zweifeln Moses Herrscherposition an. Mose fordert sie auf, ein Opfer zu bringen. Gott hat vor, die Israeliten für ihren Aufstand zu töten, doch wieder interveniert Mose. So lässt Gott nur eine Spalte im Erdboden öffnen, und Korach und seine Anhänger stürzen hinein.

Der Rest des Volkes opfert vor Angst vor dieser Strafe, doch dann werfen sie Aaron und Mose vor, die Bestraften umgebracht zu haben. Aaron und Mose versöhnen das Volk mit einem Rauchopfer, doch 250 Männer sterben unter Gottes Zorn. Mit einem Zeichen bestätigt Gott Aarons Priesteramt.

Noch einmal betont Gott Aaron gegenüber die Bedeutung seines Priesteramtes und erläutert noch einmal den Lohn, den die Priester und Leviten bei jedem Opfer erhalten und der ihr Überleben sichert. Die Herstellung des Reinigungswassers wird erläutert, das genutzt wird, um Menschen wieder rein zu machen, die durch Berührung eines Toten unrein geworden sind.

Aaron und Mose klagen, weil der Herr sie in eine Wüste geführt hat, in der sie noch nicht einmal Wasser finden. Gott ist enttäuscht von Mose und Aaron, lässt aber Wasser aus einem Stein sprudeln. Doch Gott straft Aaron für seine Zweifel und lässt ihn sterben, sein Nachfolger wird Eleasar.

Den Israeliten wird versagt, durch das Land der Edomiter zu ziehen. Der König von Arad greift sie sogar an, als sie in sein Gebiet kommen, seine Armee und seine Städte werden jedoch von den Israeliten zerstört. Bei der weiteren Wanderung durch die Wüste klagen die Menschen wieder und werden von Schlangen gestraft, die Gott ihnen schickt.

Auch der Amoriterkönig lässt die Israeliten nicht durch sein Land ziehen, sondern greift sie an. Die Israeliten besiegen sie bei einer Schlacht und nehmen die Städte ein. Auch Og, den König von Baschan, tritt ihnen mit seinem Heer entgegen und wird besiegt.

Die Moabiter und Midianiter verbünden sich unter Balak, um die Israeliten aufzuhalten. Doch Gott befiehlt Bileam, der Israel im Auftrag der beiden Völker verfluchen soll, es nicht zu verfluchen, und hält seine Eselin auf. Bileam opfert Gott, doch seine Verbündeten verlangen weiterhin, dass er die Israeliten verflucht, doch stattdessen segnet er sie drei Mal.

Viele der Israeliten wurden von den Moabitern zu den Opferfesten ihrer Götter eingeladen. Das Volk fiel vor ihren Göttern nieder, u. a. vor Baal-Peor. Es heißt, das habe den Zorn des Gottes Israels erregt, und er habe zur Tötung der Anführer des Volkes aufgerufen. Mose befahl, alle Verehrer Baal-Peors zu töten. Als ein Israelit eine Midianiterin mitbrachte und der Priester Pinchas beide tötete, soll er dadurch den Zorn des Gottes Israels abgewendet haben. Dann erst war die Seuche beendet, an der 24.000 Israeliten starben. Der Gott Israels soll mit Pinchas einen besonderen Bund geschlossen haben und zur Tötung der Midianiter aufgerufen haben.

Gott befiehlt eine zweite Volkszählung, bei der 601.730 Männer ab 20 Jahren gezählt werden. Außerdem gibt es 23.000 männliche Leviten. Bei der Volkszählung fällt auf, dass außer Mose nur noch Kaleb und Josua leben, die auch bei der ersten Zählung aufgekommen waren.

Nachdem die Töchter Zelofhads zu Mose kamen, legte Gott eine Erbreihenfolge fest: Sind keine Söhne vorhanden, so erben die Töchter, ansonsten die Onkel oder anderen leibliche Verwandte. Da auch Mose nicht nach Kanaan darf, wird Josua als sein Nachfolger bestimmt und geweiht. Es werden noch einmal die Opferregelungen beschrieben. Die Gelübde von Frauen sind ebenso gültig wie die der Männer, so ihr Vater oder Mann keinen Einspruch erhebt.

Gott gibt Mose die Anweisung, Rache an den Midianitern zu üben. Die Midianiter werden angegriffen und geschlagen. Danach befiehlt Mose, alle zu töten, lediglich Jungfrauen werden gefangen genommen. Die Beute der Schlacht wird auf die Stämme verteilt, und die Heerführer opfern Gott zum Dank für diesen Sieg, bei dem kein Israelit ums Leben gekommen ist. Danach enthält es rituelle Vorschriften über die Reinigung von Waffen und Gerät nach einem Völkermord.

Die Stämme Ruben und Gad wollen im gerade eroberten Ostjordanland bleiben, doch sie versprechen, gemeinsam mit dem Volk Israel um weitere Gebiete zu kämpfen.

Das Volk zieht weiter durch die Wüste. Auf dieser Reise stirbt Aaron auf dem Berg Hor. Gott befiehlt den Israeliten, das Volk der Kanaaniter zu vertreiben und ihre Götterstatuen zu zerstören. Die Ausdehnung des Landes wird genau beschrieben, und per Los sollen die Gebiete aufgeteilt werden. In einigen der Städte, die die Leviten bekommen, soll Menschen, die unabsichtlich jemanden getötet haben, Unterschlupf gewährt werden, bis ihr Fall vor Gericht entschieden wird. Jeder andere Mord soll mit dem Todesurteil bestraft werden. Am Ende des 4. Buches Mose wird festgelegt, dass Grundstücke nur innerhalb eines Stammes vererbt werden dürfen.


Allgemein
Forschungsberichte

Kommentare

Einzelstudien



</doc>
<doc id="10284" url="https://de.wikipedia.org/wiki?curid=10284" title="5. Buch Mose">
5. Buch Mose

Das 5. Buch Mose, auf "(dbārīm)" Debarim oder auch Devarim („Worte“), auf Deuteronomion, latinisiert Deuteronomium („zweites Gesetz“) genannt, ist das fünfte Buch des jüdischen Tanach wie auch des christlichen Alten Testaments und damit das fünfte Buch der verschiedenen Bibelkanons. In der rabbinischen Literatur wird das Buch auch "Mischne Tora" („Wiederholung der Weisung“) genannt. Hinter dem griechischen Namen stehen (christliche) theologische Vermutungen, die das 5. Buch Mose als die zweite nach einer ersten von Exodus 19 bis Numeri 10 berichteten Gesetzgebung verstehen.

Das im Deutschen gewöhnlich "5. Buch Mose" oder "Deuteronomium" genannte Buch heißt im Hebräischen nach den ersten Worten des Buches "Eleh ha-Devarim" („Dies sind die Worte…“). Sein hebräischer Name "Devarim" () bedeutet „Worte, Aussprüche“. Die Benennung nach direkten oder bedeutendsten Anfangsworten ist mit ihrer Verwendung als "Parascha" oder "Sidra" („Wochenabschnitt“) für die Lesung der Tora („Weisung, Lehre“) in der Synagoge im Judentum verknüpft.

Das Buch heißt im lateinischen "Deuteronomium", nach dem Griechischen Δευτερονόμιον, „zweites Gesetz“. Diese Bezeichnung entstammt der Septuaginta in der latinisierten Fassung der Vulgata. Sie basiert auf der Phrase "wə-chatav lo et mischne ha-Tora ha-sot" ( – Kapitel 17, Vers 18), übersetzt „er soll ihm eine Wiederholung der Weisung schreiben“, welche die Septuaginta als τὸ Δευτερονόμιον τοῦτο, „diese Wiederholung des Gesetzes“, wiedergibt.

Die deutsche Bezeichnung "5. Buch Mose" geht vor allem auf die Bibelübersetzung Martin Luthers zurück und folgt dem sonstigen traditionellen jüdischen und kirchlichen Sprachgebrauch, der Mose als Autor benennt.

Das 5. Buch Mose ist im Original in hebräischer Sprache geschrieben und ist Teil der jüdischen Tora, die hebräisch auch Chumasch, oder im christlichen Umfeld auf griechisch als Pentateuch bezeichnet wird. Im Deutschen spricht man von den „Fünf Büchern Mose“. Sie bilden jeweils den ersten Teil des Tanach (Jüdische Bibel) und des Alten Testaments (Christliche Bibel).

Das 5. Buch Mose besteht im Wesentlichen aus drei Reden, die Mose kurz vor seinem Tode an die Israeliten richtete.
Ort der Handlung ist die Ebene von Moab, Zeit der Handlung ist der elfte Monat im letzten Jahr der Wanderung der Israeliten durch die Wüste. Inhaltlich ist das Buch eine Fortsetzung des 2., 3. und 4. Buches Moses.

Die erste Rede (Kapitel 1–4) blickt auf die bedeutendsten Ereignisse der letzten 40 Jahre der Wüstenwanderung zurück.
Der Gehorsam gegenüber den Geboten Gottes wird als wichtig herausgestellt, und vor den Gefahren, JHWH, den Gott der Väter zu verlassen, wird gewarnt.

Die zweite Rede (Kapitel 5–26) stellt den Hauptteil des Buches dar und wird manchmal in zwei Teile (Kapitel 5–11 sowie Kapitel 12–26) unterteilt.
Der erste Teil enthält eine Wiederholung der Zehn Gebote (mit leichten Änderungen am Text), der zweite Teil befasst sich mit Regeln, die das Leben im verheißenen Land Kanaan betreffen. Kapitel 20 enthält die Kriegsgesetze. Der Aufbau ist teilweise verwirrend und viele Aussagen, wie die Verpflichtung, nur den einen Gott zu verehren, werden sehr oft wiederholt.

Die abschließende Rede (Kapitel 27–30) befasst sich mit den Konsequenzen, die aus dem Übertreten der Gebote folgen sowie dem Lohn des Gehorsams.
Mit einer Erneuerung des Bundes zwischen Gott und den Israeliten sowie der Benennung Josuas zu seinem Nachfolger schließt das Buch.

Es folgen drei kurze Anhänge:

Im Buch Josua wird die Geschichte des Volkes Israel nach der Überquerung des Jordan weitergeführt.

Das Deuteronomium hat im Wesentlichen zwei Ziele:


Das Buch beginnt mit einer sehr genauen Beschreibung von Ort und Zeit, zu der Mose das Gesetz niedergeschrieben und seinem Volk vorgetragen hat: Im vierzigsten Jahr seit dem Auszug aus Ägypten, im elften Monat, am ersten Tag des Monats, jenseits des Jordan, in der Wüste Araba.

Dann erzählt Mose, wie Gott das Volk aufgefordert hatte, nun den Jordan zu überschreiten und das Land Kanaan, das Gott seinem Volk als Besitz versprochen hat, zu erobern und zu bevölkern. Er erwähnt noch einmal eine der Grundlagen des Gesetzes, das durch ihn vermittelt wurde: Die Ältesten und Richter unter dem Volk sollen ihre Entscheidungen ohne Ansehen der Person fällen, sowohl für Israeliten als auch für Fremde.

Weil aber das Volk Gott nicht vertrauen wollte und vor den Amurritern, deren Land sie erobern sollten, Angst hatte, wurde Gott zornig und schwor: „Kein einziger von diesen Männern, von dieser verdorbenen Generation, soll das prächtige Land sehen, von dem ihr wisst: Ich habe geschworen, es euren Vätern zu geben.“ So sollte das Volk Israel vierzig Jahre durch die Wüste ziehen, bis von der Generation, die damals zusammen mit Mose aus Ägypten ausgezogen war, keiner mehr lebte, außer Kaleb und Josua. Auch Mose sollte das gelobte Land nicht mehr betreten können.

Es folgt ein Rückblick auf die Reise des Volkes durch die Wüste, an deren Ende die Eroberung des Ostjordanlandes folgt. Dabei werden die Heere von Sihon, dem König von Hesbon und von Og, dem König des Baschan geschlagen. Die unterworfenen Völker werden auf Geheiß Gottes dem Untergang geweiht: „Damals eroberten wir alle seine Städte. Wir weihten die ganze männliche Bevölkerung, die Frauen, die Kinder und die Greise der Vernichtung; keinen ließen wir überleben.“ 

Es folgen Anweisungen zur Eroberung des Westjordanlandes, des heutigen Israel. Mose darf vom Gipfel des Berges Nebo ins gelobte Land hinübersehen. Er selbst wird es nicht mehr betreten dürfen, Josua wird das Volk im Krieg führen.

Als Abschluss der Rede des Mose folgt im vierten Kapitel eine erneute Mahnung, die Rechtsvorschriften des Gesetzes zu halten. Dazu gehört ganz besonders, keine Götter von den besiegten Völkern anzubeten oder sich sonstige Götzenbilder zu machen. Diese Warnung, zusammen mit der Aufforderung, Gottes Gebot zu achten, wird im ganzen Buch vielfach wiederholt. Mose trägt dem Volk auf, die Zehn Gebote, die ihm der Herr übergeben hat, an die nachfolgenden Generationen weiterzugeben. Sollte das Volk die Vorschriften übertreten, droht der Herr mit schweren Strafen bis hin zur Vertreibung aus dem Land Israel.

Der erste Teil des Buches endet mit der Liste der Asylstädte im Ostjordanland.

Der zweite Teil des Buches enthält nun konkrete Rechtsvorschriften, die Mose dem Volk vorgelegt hat. Die Form der Verkündigung ist die eines Bundesschlusses, das heißt einer freiwilligen Verpflichtung auf das Gesetz durch das Volk. Damit soll das Gesetz ein Vertrag zwischen Gott und seinem Volk werden und nicht nur eine von Gott bestimmte weltfremde Vorschrift.

Zunächst folgt eine Wiederholung der Zehn Gebote . Dieser Abschnitt ist, bis auf eine etwas andere Formulierung beim Sabbatgebot, weitgehend identisch mit . Es folgt ein Einschub, der erzählt, wie das Volk Mose als seinen Mittler bei Gott einsetzt, da es sich am Horeb, wie der Berg Sinai im 5. Buch Mose genannt wird, davor gefürchtet hatte, selbst Gott gegenüberzutreten. So soll Mose den Israeliten die Gesetze, das der Herr ihm auf dem Horeb gibt, verkünden.

Die eigentliche Verkündigung der Vorschriften beginnt mit einem Abschnitt, der verlangt, das Gesetz "auf dem Herzen geschrieben" und "um das Handgelenk gebunden" zu haben. JHWH wird danach erneut ganz deutlich als der einzige Gott Israels herausgehoben, wenn an die Zeichen erinnert wird, die er in Ägypten geschehen ließ, weil der Pharao Mose nicht glauben wollte.

Kapitel 7 trägt in der Einheitsübersetzung die Überschrift „Israel und die Völker des Landes“. Darin wird dem Volk Israel deutlich gemacht, dass die Völker, die der Herr vor ihm vertreiben wird, ausgemerzt und vernichtet werden müssen. Es ist verboten, sich mit den geschlagenen Völkern einzulassen oder gar ihre Söhne und Töchter den eigenen zu geben. Indirekt wird das Verbot damit begründet, dass das Risiko groß ist, dass Israel auch die Brauchtümer und den Polytheismus der Fremden annehmen könnte. Weil Israel das Gebot nicht sehr genau nehmen wird, wird der Götzendienst später, zur Zeit der Könige von Israel, auch wieder Einzug nehmen.

Es folgt ein weiterer Rückblick auf die Verkündigung der Zehn Gebote am Horeb. Gott ist nicht bestechlich, kennt kein Ansehen der Person und verschafft auch Fremden ihr Recht; „– auch ihr sollt die Fremden lieben, denn ihr seid Fremde in Ägypten gewesen.“ 

Um nicht der Versuchung der fremden Götter zu verfallen, ist es auch notwendig, die Altäre und Kultstätten dieser Gottheiten zu zerstören. Für den Gott der Israeliten wird es nur eine Kultstätte geben, die Er bestimmen wird. Dies wird zunächst noch das Zelt sein, das das Volk auf der Reise begleitet hat, später wird der Tempel des Herrn auf dem Zion in Jerusalem erbaut werden. Nur dort dürfen dem Herrn Schlachtopfer dargebracht werden. Das Schlachten und Verzehren von Tieren ist jedoch überall gestattet, verboten ist hingegen der Verzehr des Blutes getöteter Tiere – damals vermutete man im Blut die Lebenskraft und damit die Seele der Tiere, weshalb andere Kulturen ebendieses Blut während der Opferung tranken. Schlacht- und Brandopfer und die restlichen Abgaben, die den Zehnten ausmachen, sowie die Erstlinge von allem Vieh, sollen zum Zelt des Herrn gebracht werden.

Anstiftung zum Abfall von Gott und zur Anbetung von fremden Gottheiten wird mit Steinigen des Verführers bestraft. Sollte eine ganze Stadt vom Herrn abfallen, wird sie gnadenlos vernichtet.

Danach lesen wir über Speisevorschriften, besonders darüber, welche Tiere verzehrt werden dürfen und welche nicht. Die Kategorisierung erfolgt einer heute nicht mehr direkt nachvollziehbaren Logik, wonach nur Tiere gegessen werden dürfen, die gespaltene Klauen haben und Wiederkäuer sind, wobei sich letzteres Kriterium auf reine Beobachtung stützt und der heutigen wissenschaftlichen Betrachtung nicht standhält. Fische und Vögel dürfen im Allgemeinen auch verspeist werden, die meisten fleischfressenden Vögel jedoch nicht. Der Verzehr von Aas und von Aasfressern ist auf jeden Fall verboten.

Der Zehnte Teil der Ernte des Jahres gehört Gott und den Leviten, die den Dienst am Altar verrichten. Auch sollen Arme mit Pfandleihen oder Almosen unterstützt werden, wenn es nötig ist.

Nach den Bestimmungen für das Schawuot (Wochenfest) und das Sukkot (Laubhüttenfest) folgen Vorschriften zum gerechten Gerichtsverfahren. So soll jemand nur zum Tod verurteilt werden können, wenn mindestens zwei Zeugen gegen ihn auftreten. Weitere Gesetze finden sich fast unverändert auch in modernen Rechtsstaaten: Grenzverrückung und die Verwendung von zweierlei Gewichten ist verboten, genauso wie eine falsche Aussage vor Gericht und Menschenraub.

Kapitel 20 enthält die sogenannten Kriegsgesetze. Der Abschnitt beginnt erneut mit der Bekräftigung, dass der Herr mit seinem Volk in den Krieg ziehen wird und sich dieses daher nicht vor größeren und stärkeren Feinden fürchten soll. Das Aufgebot zum Krieg gilt grundsätzlich allen Männern des Volkes; ausgenommen sind Männer, die gerade ein Haus gebaut, einen Weinberg angelegt, oder sich gerade verlobt, aber noch nicht geheiratet haben. Diese dürfen nach Hause zurückkehren. Nicht zum Kampf antreten soll auch einer, der sich fürchtet. Wieder wird das Volk ermahnt, die aktuellen Einwohner des Landes Kanaan keinesfalls zu verschonen, sondern der Vernichtung zu weihen. Die Einwohner von weiter entfernten Städten dürfen hingegen versklavt und ihre Frauen geheiratet werden.

Die folgenden Abschnitte enthalten in kurzer Form wieder Gesetze des täglichen Lebens: Gefundenes Gut soll zurückgegeben werden; hatte der Bruder einen Unfall mit dem Ochsenkarren, soll ihm beigestanden werden; Männer sollen keine Frauenkleider tragen und umgekehrt; an Dachterrassen sollen Geländer angebracht werden; am Gewand sollen Quasten getragen werden.

Das Deuteronomium enthält einige sehr detaillierte Gesetze zum Ehebruch. Grundsätzlich wird dieser mit dem Tod beider Beteiligter durch Steinigung bestraft. Wenn ein Mann eine verlobte Frau vergewaltigt, soll er sterben, sie darf am Leben bleiben, wenn nicht nachgewiesen werden kann, dass sie hätte um Hilfe rufen können. Beschuldigt einer seine Frau, nicht jungfräulich in die Ehe gekommen zu sein, sollen die Eltern der Frau als Beweisstück für das Gegenteil ihr Hochzeitskleid vorlegen. Anderenfalls sei sie zu steinigen. Es war wohl Brauch, dieses Kleid nach der Hochzeitsnacht den Eltern der Braut mit den Blutspuren zu übergeben.

Weitere Gesetze bestimmen die Bedingungen für die Aufnahme in die Versammlung des Herrn, die Reinheit des Heerlagers, ein Verbot zur Auslieferung von Flüchtlingen und der sakralen Prostitution. Dazu ein Verbot, von Brüdern Zinsen zu verlangen oder gewisse lebenswichtige Dinge wie Mühlsteine als Pfand zu nehmen. Der Lohn eines Tagelöhners soll noch vor dem Sonnenuntergang bezahlt werden. Die sogenannte Sippenhaft ist verboten und an Acker und Weinberg soll keine Nachlese gehalten werden – diese Früchte sind für die Armen bestimmt.

In einer gebetsförmigen Überleitung werden die wichtigsten Gesetze im Kapitel 27 noch einmal zusammengefasst. Kapitel 28 enthält dann Fluch und Segen für Gehorsam beziehungsweise Ungehorsam gegenüber dem Gebot Gottes.

Zum Fluch folgt auch eine lange Liste von Verwünschungen, die dem Volk widerfahren werden, wenn es sich nicht an die Gesetze hält. Auffallend ist, dass dieser Abschnitt viermal so lang ist, wie der Abschnitt mit den Segenswünschen.

Der letzte Teil des Buches enthält noch einmal einen kurzen geschichtlichen Rückblick auf die Reise des Volkes Israel. Noch einmal wird der Bund mit Gott bekräftigt und die Strafen erwähnt. Beim Abfall wird es dem Land gleich ergehen wie Sodom und Gomorra und das Volk wird aus dem Land vertrieben werden, wie es später bei babylonischen Exil geschehen wird. Nach der Androhung dieser schweren Strafen folgt allerdings gleich auch die Verheißung, wieder nach Hause zurückkehren zu können, wenn die Fehler bereut werden.

Im Lied des Mose (Kapitel 32) findet sich eine versartige Zusammenfassung der Ereignisse in den fünf Büchern Mose. Von der Verkündigung eines neuen Namens für JHWH – „Fels“ – und vom störrischen Volk Israel wird berichtet – wie es immer wieder Gott auf die Probe gestellt und dann zurückgekehrt ist. So endet das Lied auch mit blutigen Bildern von der Vernichtung der Feinde und vom Ende der Schlacht.

Das Buch schließt mit dem Segen Mose über die zwölf Stämme Israels, jedem Stamm wird eine persönliche Segnung zuteil. Schließlich steigt Mose auf den Berg Nebo, gegenüber von Jericho, und stirbt dort. Josua, der Sohn Nuns, wird das Volk über den Jordan führen.

Das 5. Buch Mose setzt sich mit Ausnahme des Schlusses in Stil, Methode und Ausdrucksweise derart von den übrigen Büchern der Tora ab, dass sein Ursprung einer eigenständigen Schule zugeschrieben wird.
Insbesondere die Tatsache, dass im Buch selbst von einem eigenständigen Gesetz gesprochen wird (Kapitel , Kapitel , Kapitel , Kapitel ), spricht für eine Entstehung, die separat von den vier vorhergehenden Büchern anzusetzen ist.

Daneben sind auch eine Reihe von inhaltlichen Unterschieden zwischen diesem und den drei vorhergehenden Büchern (2.–4. Buch Mose) zu beobachten: Die Gesetze zeigen einige Unterschiede, und die Rolle der Priesterschaft (Aaroniten) gegenüber der des Stammes Levi (Leviten) wird abweichend dargestellt.

Der Talmud behandelt die dargestellten Ungereimtheiten unter der Annahme, dass der ganze Pentateuch aus der Feder Moses entstanden sei, und kommt zu dem Schluss, dass einiges (etwa der Bericht von Moses Tod und Beisetzung) wahrscheinlich später von Moses Nachfolger Josua hinzugefügt sei.

Die Autorschaft Moses wird von der traditionellen Lehrmeinung folgendermaßen begründet:


Seit dem Mittelalter wurde dann auch die Möglichkeit diskutiert (z. B. von Isaak Abrabanel), dass das 5. Buch Mose einen anderen Autoren als die anderen Bücher des Pentateuch habe, und später entstanden sei.

Die spätere Entstehung wird nach biblischen Quellen folgendermaßen begründet:
Am Ende des 2. Buch der Könige wird von religiösen Reformen unter König Josia berichtet. Während dieser Periode findet der Hohepriester Hilkia bei Umbauarbeiten im Tempel eine Schriftrolle der Tora. Insbesondere die zentrale Rolle Jerusalems im jüdischen Kultus, die von Josias Reformen betont wurde, ist im Pentateuch nur im 5. Buch Mose zu finden (nicht namentlich, sondern als „der Ort, den der Herr erwählen wird“). Die sonst unbekannte Prophetin Hulda bestätigt die Authentizität des Buches. Hiernach wird Jerusalem Zentrum des Kultus, und die Lesung des Buches durch den König (ebenfalls nur im 5. Buch Mose zu finden) Teil der Pilgerfahrt am Laubhüttenfest.

Während die traditionelle Lehrmeinung diese verlorene Schriftrolle mit einem von Mose verfassten Text oder mit dem gesamten Pentateuch identifiziert, der nur während der Herrschaft der vorhergegangenen Jahwe-feindlichen Könige in Vergessenheit geraten war, sehen modernere Ansichten eine spätere Entstehung zur Untermauerung der politischen und religiösen Reformen als wahrscheinlicher an. Demnach wäre sie unter Federführung einer königstreuen, in religiösen Dingen der Staatsräson zuneigenden Partei der Priesterschaft unter Berücksichtigung existierender Traditionen entstanden (und von den Schreibern auch nicht als „Fälschung“, sondern als Formalisierung ihres Ritus verstanden worden).

Unabhängig von den Glaubenspostulaten in den verschiedenen Strömungen der jüdisch(-orthodoxen), christlich(-fundamentalen) oder islamisch(-fundamenten) Religionen, legen religionsgeschichtlich bzw. religionswissenschaftliche Untersuchungen die Hypothese nahe, dass Mose das Deuteronomium nicht verfasst habe oder hat. 

Zur genauen Entstehung findet man verschiedene Hypothesen, welche die Entstehung des gesamten Pentateuch behandeln. 
Etwa die Fragmentenhypothese, die eine Verbindung von ursprünglich selbstständigen Überlieferungsblöcken frühestens seit der späten Königszeit (so im „Münsteraner Pentateuchmodell“ nach 650 v. Chr.) oder aus exilischer Zeit oder in persischer Zeit annimmt.

Insbesondere wird heute aus der Bedeutungsverwandtschaft zwischen einzelnen Abschnitten, z. B. , und Abschnitten aus den Vasallenverträgen Asarhaddons mit medischen Fürsten geschlossen, dass eine Urfassung des Buches in der Zeit König Joschijas von Juda abgefasst worden sein müsse (vgl. 2. Kön. 22,8); denn es handele sich um eine förmliche Aufkündigung der Treue zum assyrischen König nach dem Tode Assurbanipals durch den Eid auf Jahwe (Eckart Otto).

Aus dem Vergleich mit prophetischen Büchern des Tanach schließen andere Forscher (Gustav Hölscher), das 5. Buch Mose sei in frühnachexilischer Zeit verfasst worden. Die Quellen, die die Schreiber bei der Verfassung der uns heute bekannten Form des Buches verwendet haben, sind jedoch zweifellos sehr viel älter.

Seit Martin Noth wird das Deuteronomium auch als Bestandteil des Deuteronomistischen Geschichtswerks angesehen.








</doc>
<doc id="10285" url="https://de.wikipedia.org/wiki?curid=10285" title="Jainismus">
Jainismus

Der Jainismus, auch Jinismus, (Sanskrit, जैन, m., Jaina, „Anhänger des Jina“) ist eine in Indien beheimatete Religion, die etwa im 6./5. Jahrhundert v. Chr. entstanden ist. Ein historisch fassbarer Gründer ist Mahavira (um 599–527 v. Chr). Dem Jainismus gehörten 2001/2002 etwa 4,4 Millionen Gläubige an, davon etwa 4,2 Millionen in Indien.

Die geistigen Führer des Jainismus werden als Tirthankaras („Furtbereiter“) bezeichnet, um ihre Funktion als Mittler zwischen der materiellen und der spirituellen Welt zu verdeutlichen. Von dem für ihren historisch fassbaren Begründer Mahavira verwendeten Ehrentitel "Jina" („Sieger“) erhielt die Religion ihren Namen. Im tamilischen Kulturkreis werden die Jains als "samanar" (von Sanskrit श्रमण, śramaṇa) bezeichnet, was so viel bedeutet wie „Asket“, „Einsiedler“, „Mönch“ etc.

Das "Kalpa-Sutra", eine heilige Schrift der Jainas, verzeichnet 24 Tirthankaras. Die Geschichten von Rishabha, dem ersten Tirthankara, sowie von Neminatha, Parshvanata und Mahavira, den 22.–24. Tirthankaras, sind in dieser Schrift ausführlicher geschildert. Nur die letzten beiden gelten als historische Persönlichkeiten. Mahavira (Sanskrit „der große Held“) begründete den Jainismus im 6. Jh. v. Chr., während sein Vorgänger Parshvanata ca. 350 Jahre vorher gelebt haben soll.

Nach der dualistisch orientierten Vorstellung des Jainismus wechseln sich Zeitalter (Kalpa), in denen die menschlichen Tugenden und spirituellen Fähigkeiten wachsen, und solche des Niedergangs auf ewig ab. In jedem Zeitalter erscheinen 24 Tirthankaras. Das gegenwärtige Äon gilt als ein Zeitalter des Verfalls.

Nach Parshvanata soll der Berg Parasnath benannt sein, auf welchem er der Legende nach sein Nirwana erreichte. Mit seinen 24 Tempeln, die die 24 Tirthankaras symbolisieren, ist der Berg ein bedeutender Pilgerort.

Andere bekannte Jain-Heiligtümer sind

Aber auch in nahezu jeder größeren Stadt Indiens gibt es einen oder mehrere Jain-Tempel.

Der Jainismus hat wie der Buddhismus seine Wurzeln im Brahmanismus, der Vorgängerreligion des Hinduismus. Nach der Überlieferung der Gemeinde war der erste Tirthankara Rishabha oder Adinath (um 1500 v. Chr.), ein Asket in der Stadt Pithunda, die Mahapadma Nanda später zerstörte. Aus der mythologischen Kette der 24 jainistischen Propheten lassen sich die letzten beiden, Parshvanata und Mahavira, vielleicht sogar historisch belegen.

Parshvanata oder Parsnath, der 23. Tirthankara (um 870 v. Chr.) war der Sohn eines Königs von Benares. Er sagte dem Reichtum ab, wurde Asket und erhielt ein absolutes Wissen. Er gründete acht Gemeinden, woraus möglicherweise auch Mahavira hervorging, und soll im Alter von 100 Jahren gestorben sein.

Vardhamana Mahavira, Sohn des Königs Siddhartha, wurde in Kundalpur im Königreich Vaishali (heute Bihar) geboren. Einige Quellen datieren seine Geburt auf 599 v. Chr., also vor Buddha (ca. 560 v. Chr.), andere gehen davon aus, dass Mahavira jünger als Buddha sei und 539 oder 549 v. Chr. geboren worden sei. Mahaviras Mutter "Trishala" war im Traum die messianische Mission Mahaviras vorhergesagt worden – eine deutliche Parallele zum Traum Mayas, der Mutter Buddhas. Ähnlich wie Buddha verließ Mahavira im Alter von 28 bis 30 Jahren seine Familie sowie das Königreich, ließ alles zurück und wurde Asket. Zwölf Jahre lebte er zurückgezogen in Wald- und Bergregionen und führte ein Leben in mönchischer Existenz, bis er in die Gesellschaft zurückkehrte, um seine Lehren zu verkünden.

Im Gegensatz zum Buddhismus richtet sich der Jainismus nicht als Reaktion gegen den Adel der brahmanischen Gesellschaft, sondern sieht sich eingebettet in die traditionellen philosophischen Überzeugungen. Mahavira war einerseits der Begründer einer neuen eigenständigen Lehre, suchte andererseits Reformen des bestehenden Systems. Der Hinduismus sah in der neuen Lehre aufgrund ihres Rigorismus keine Konkurrenz.

Der erste König des Maurya-Reichs im 4. Jahrhundert v. Chr., Chandragupta Maurya, soll im Alter seinen Thron verlassen haben und jainistischer Asket geworden sein. Nach dieser Zeit verbreitete sich der Jainismus in Südindien, wohin ein großer Teil der Gemeinde auswanderte. Viele indische Könige bekehrten sich zum Jainismus und unterstützten ihn. Auch im Osten Indiens in Andhra Pradesh und Orissa, dem Wirkungsbereich Mahaviras, blühte der Jainismus. Im westlichen Indien etablierte er sich in Gujarat unter der Herrschaft Kumarpals.

Die islamische Invasion im 13. Jahrhundert behinderte die Ausbreitung des Jainismus, führte aber nicht zu seinem Verschwinden, da eine hohe Selbstdisziplin und mönchisches Engagement für Resistenz sorgten. Eine Angleichung an den Hinduismus war im Mittelalter die Übernahme von Kastenregeln in abgeschwächter Form.

Der Jainismus geht davon aus, dass sich in der Welt zwei Prinzipien gegenüberstehen: Geistiges und Ungeistiges. Das Geistige beruht auf einer unendlichen Anzahl individueller Seelen ("Jiva"). Das Ungeistige umfasst die fünf Kategorien: Bewegung, Ruhe, Raum, Stoff und Zeit. Alles Stoffliche ist beseelt, nicht nur Menschen und Tiere, sondern auch Pflanzen oder Wasser.

Die ursprüngliche Reinheit und Allwissenheit der Seele ("Jiva") wird jedoch durch feinstoffliche Substanzen, die als Folge von Karma eindringen, getrübt. Der Jiva lässt sich nach dem jeweiligen Reinheitsgrad durch farbliche, olfaktorische, haptische sowie geschmackliche Abstufungen kategorisieren, wobei z. B. das mögliche Farbspektrum des Jiva von Schwarz, Dunkelblau über Taubengrau, Feuerrot, Gelb bis Weiß reicht. So attestiert eine gelbe Geistesmonade dem Träger ausgeglichene Wesenszüge. Jedwede karmische Tat, ob intentionell oder nicht, zwingt zum Verbleib im Kreislauf der Wiedergeburten (Samsara), bis alles Karma getilgt ist.

Eine Reinigung der Seele wird im Jainismus durch sittliche Lebensweise und strenge Askese erreicht. Ist eine Seele von allen Verunreinigungen befreit, so steigt sie in den höchsten Himmel auf, um dort in ruhiger Seligkeit zu verharren. Dieses Stadium erreichen jedoch nicht alle Seelen. Die sogenannten "abhavya jivas" („unfähige Seelen“) können aufgrund ihrer natürlichen Veranlagung nie aus dem Samsara befreit werden.

Die drei universellen ethischen Grundprinzipien, bezeichnenderweise auch als die Kleinen Gelübde (Anuvratas) der Laienanhänger des Jainismus genannt, sind Ahimsa (Gewaltlosigkeit gegenüber allen immanent beseelten Existenzformen), Aparigraha (Unabhängigkeit von unnötigem Besitz) und Satya (Wahrhaftigkeit).

Jain-Nonnen und -Mönche nehmen bei ihrer Ordination die folgenden fünf Großen Gelübde (Mahavratas) auf sich:

Wegen des Ideals der Nichtverletzung von Lebewesen ernähren sich Jainas so, dass keine Tiere dafür leiden oder sterben müssen und Pflanzen nur im unvermeidlichen Maß geschädigt werden. Sie ernähren sich üblicherweise (lakto-)vegetarisch, manche auch vegan. Die indische Stadt Palitana wurde zur vegetarischen Stadt erklärt, da dort viele Jains leben.

Bedingt durch diese Prinzipien üben Anhänger des Jainismus nicht jeden Beruf aus, weshalb sie beispielsweise oft im Handel und im Bankgewerbe (z.B. Anshu Jain), d. h. in den Städten arbeiten. Wegen der Strenge der Lebensführung war die Jaina-Gemeinde nie sehr groß. Die Laien konnten wegen des Gewaltlosigkeitgebots weder in der Landwirtschaft arbeiten (beim Pflügen könnten Lebewesen verletzt werden), noch durften sie sich dem Kriegshandwerk widmen.

Dieser ethische Rigorismus, der zugleich auch schon einen starken soteriologischen Charakter in sich trägt, führt zuweilen bei älteren durch Tapas-Übungen (Kasteiungen und meditative Praktiken) geläuterten Jain-Mönchen im Extremfall so weit, dass sie sich durch "Samlekhama" (Hungerfasten und körperlicher Passivität) gänzlich der Welt entäußern, da nur so der Jiva von neuerlichen karmischen Verunreinigungen (ob positiver oder negativer Natur) bewahrt bleibt.

Jainas bilden nach ihrer Religionsauffassung zwei Sekten, die Digambaras, „Luftgewandeten“ in den südlichen Regionen des indischen Subkontinents, deren Mönche den Abbildungen ihres Stifters Mahavira entsprechend traditionell in gänzlicher Nacktheit leben, und die Shvetambaras, die „Weißgekleideten“ mehrheitlich in den nördlichen indischen Bundesstaaten.

Die ersichtlichen Differenzen liegen vor allem im doktrinären Traditionsverständnis, das sich aus der jeweiligen Interpretation, Auslegung sowie des erhobenen Autoritätsanspruches des Schrifttums ergibt. So vertritt größtenteils nur die Sekte der Shvetambaras den Standpunkt, dass der Kanon, d. h. die Sutren und Agamas, in den Geltungsbereich eines heiligen Schriftkorpus anzusiedeln sei.

Nach der Ansicht einiger Anhänger des Jainismus gehen die Ursprünge auf die nichtarische Zeit, die sogenannte dravidische Periode im 3. oder 4. Jahrtausend v. Chr. zurück. Mahavira stellte demnach nur den letzten einer langen Reihe von Jaina-Lehrern dar. Wie auch im Hinduismus schätzen die Anhänger des Jainismus die eigene Religion somit als wesentlich älter als Religionswissenschaftler und Indologen ein.

Die heterodoxe Religion (da sie die Veden nicht anerkennt) wurde von den Brahmanen zwar immer bekämpft, konnte sich aber nach einer Blütezeit im Mittelalter bis heute halten.





</doc>
<doc id="10291" url="https://de.wikipedia.org/wiki?curid=10291" title="Digambara">
Digambara

Ein Digambara (Sanskrit, m., दिगम्बर, digambara, übersetzt: „im Luftkleid“, „im Himmelskleid“ oder „in die Weltweite gekleidet“) ist ein Angehöriger einer überwiegend aus Mönchen bestehenden religiösen Gruppe, die dem Jainismus angehört.

Angehörige der Digambara-Sekte legen die Gebote des Jainismus strenger aus als die Shvetambaras, die ebenfalls gläubige Jainas sind. Digambaras sind jedoch strengere Asketen und Verfechter des uneingeschränkten Existenzrechtes eines jeden Lebewesens. Sie praktizieren die Gewaltlosigkeit ("ahimsa") deshalb sehr konsequent und versuchen, auch ein versehentliches Töten oder Verletzen anderer Lebewesen, auch von Insekten, zu vermeiden. Dies geschieht durch Bewegungslosigkeit, Tragen eines Mundschutzes und/oder durch mitgeführte Wedel, mit denen − vor dem Betreten − der Boden gefegt wird.

Digambaras nehmen nicht am Berufs- oder Wirtschaftsleben teil und lehnen materiellen Besitz ab. Sie leben teilweise oder vollständig nackt; daher die Bezeichnung "Digambara" – „Luftgekleideter“.

Im Zentrum des Heiligtums von Shravanabelagola bei Mysore ist der nach Digambara-Sitte völlig unbekleidete Jaina-Asket Bahubali/Gomateshvara dargestellt − das Idealbild vieler Jainas. Seine bewegungslose Meditation geht sogar so weit, dass sich an seinem Körper Ranken emporwinden.




</doc>
<doc id="10292" url="https://de.wikipedia.org/wiki?curid=10292" title="Jean Dubuffet">
Jean Dubuffet

Jean Philippe Arthur Dubuffet (* 31. Juli 1901 in Le Havre; † 12. Mai 1985 in Paris) war ein französischer Maler, Bildhauer, Collage- und Aktionskünstler. Dubuffet war ein Hauptvertreter der Art brut und zählt zu den prominentesten Vertretern der französischen Nachkriegskunst.

Jean Dubuffet wurde als Sohn einer großbürgerlichen Familie von Weingroßhändlern in Le Havre geboren. Als Schüler belegte er 1916 Abendkurse im Zeichnen an der École des Beaux-Arts in Le Havre; nach dem Abitur 1918 begab er sich nach Paris, um Literatur, Sprache und Musik an der Académie Julian zu studieren. Hier lernte er 1919 Max Jacob kennen. In den zwanziger Jahren malte er im Umkreis der Pariser Surrealisten gegenständliche Kompositionen, gab die Kunst aber bald auf. Nach langer Schaffenspause, in der er als Weinhändler arbeitete, setzte er 1942 erneut mit naiven Gemälden ein; seine erste Einzelausstellung fand 1944 in der Pariser Galerie René Drouin statt. In der frühen Nachkriegszeit erregte er mit seinen „primitiven“ Materialbildern einen Skandal, erlangte aber bald internationale Bekanntheit, insbesondere in den USA. Dort stellte er in der Galerie Pierre Matisse in New York bereits 1947 aus.

Dubuffet entwickelte das Konzept einer antiintellektuellen Kunst, die er mit Art brut bezeichnete. Diese verteidigte er auch kunsttheoretisch in Texten und Vorträgen. 1949 veröffentlichte er sein Manifest "L'Art brut préféré aux arts culturels". Seine frühen Gemälde sind vom Bildvokabular von Kindern, Naiven und Geisteskranken inspiriert, die für ihn die Künstler der Art brut sind.
Angeregt durch die Graffiti-Fotografien von Brassaï setzte sich Dubuffet mit dem Thema Mauer und den darin eingeritzten Graffiti auseinander. Ihm war hierbei der „körperlich-materiale Herstellungsvorgang“ der Wand und der Graffiti wichtig. Deshalb versuchte er den Entstehungsprozess der Mauer auf der Leinwand nachzuempfinden, indem er viele Farbschichten dick auftrug und ihnen Zeit zum Reagieren gab. Graffiti vollzog er sogar technisch als Einritzungen in die Ölfarbe auf der Leinwand nach, womit er Trivial- und Hochkunst verband, woraus sich eine positive Neubewertung von Graffiti ergibt, die viele Parallelen mit der Art brut aufweisen.

Er experimentierte parallel intensiv mit Druckgrafik: Holzschnitt ("Ler dla campane", 1948) und Lithografie ("Les murs", 1945). Die Lithografien erarbeitete er zuerst in der Werkstatt Fernand Mourlot in Paris ("Matière et mémoire", 1945), richtete sich 1958 ein eigenes Atelier ein; herausragend ist sein umfangreicher Zyklus "Les Phénomènes" (1958/1959). Nach 1962 entwickelte Dubuffet seine Serie "Hourloupe", zellenartige Strukturen, die sich auf die Farben Rot, Weiß, Schwarz und Blau beschränken. Ende der 1960er Jahre übertrug er die grafischen Elemente der "Hourloupe"-Serie in die Skulptur. Es entstanden bemalte felsartige Gebilde aus Polyester, großformatige Freiplastiken und teilweise begehbare Labyrinthe wie "Jardin d’Email" (1972/1973) im Kröller-Müller Museum im niederländischen Otterlo. Im Jahr 1959 war Jean Dubuffet Teilnehmer der documenta 2. Auch an der documenta 3 (1964) und der 4. documenta (1968) in Kassel nahm er Teil.

Mit "Coucou Bazar" schuf Dubuffet 1972 ein Gesamtkunstwerk aus Malerei, Skulptur, Theater, Tanz und Musik. Dabei agieren mehrere kostümierte Figuren miteinander ebenso wie mit den Bühnenelementen. Dieses Spektakel wurde nur dreimal produziert: 1973 in New York und Paris sowie 1978 in Turin. Die letzte Inszenierung wurde in einem Film festgehalten. "Coucou Bazar" kann heute aus konservatorischen Gründen jedoch nicht mehr als Ganzes aufgeführt werden. Zwei Kostümfiguren dürfen noch bewegt werden und waren 2016 in der Ausstellung der Fondation Beyeler zu sehen.

1984 entstand eine Werkreihe auf schwarzem Hintergrund und im letzten Lebensjahr schrieb er eine Autobiographie.

Nach seinem Tod 1985 wurden auch seine musikalischen Experimente – mit Asger Jorn – bekannt, ebenso sein schriftstellerisches Werk. Er unterhielt mit zahlreichen Autoren regelmäßig Korrespondenzen: unter anderem mit Claude Simon, Jean Paulhan, Witold Gombrowicz und Valère Novarina. Er gehörte seit 1954 dem Collège de 'Pataphysique an. 

Seine Werke sind in zahlreichen internationalen Museen vertreten; große Werkkomplexe stiftete Dubuffet zu Lebzeiten dem Musée des Arts décoratifs in Paris und dem Stedelijk Museum in Amsterdam. Sein Nachlass wird von der Fondation Dubuffet in Paris verwaltet, wo man sein ehemaliges Atelier in 137, rue de Sèvres besuchen kann, im zweiten Sitz der Stiftung in Périgny-sur-Yerres ist u. a. Dubuffets begehbare Großskulptur "Closerie Falbala" (1.610 m²) zu besichtigen.

Neben seiner Kunst war Dubuffet einflussreich wegen seines Engagements für Art Brut: die Schöpfungen von Geisteskranken, gesellschaftlichen Außenseitern und Sonderlingen, die er sammelte und förderte. Vor dem Hintergrund dieses Interesses besuchte er auch die umfangreiche Sammlung Hans Prinzhorns von Bildwerken psychisch Kranker in Heidelberg. Dubuffets Art-Brut-Sammlung wird heute in der Collection de l’Art Brut in Lausanne verwahrt.







</doc>
<doc id="10293" url="https://de.wikipedia.org/wiki?curid=10293" title="Marsden Hartley">
Marsden Hartley

Marsden Hartley (eigentlich "Edmund Hartley"; * 4. Januar 1877 in Lewiston, Maine; † 2. September 1943 in Ellsworth, Maine) war ein US-amerikanischer Maler. Er gilt als einer der profiliertesten Maler der klassischen Moderne in den Vereinigten Staaten.

Edmund Hartley stammte aus einer Kleinstadt in dem Neuenglandstaat Maine. Er war der einzige Junge einer neunköpfigen Familie. Mit 13 Jahren malte er Objekte aus der Natur ab, als er einem ortsansässigen Naturforscher aushalf, die einheimischen Schmetterlinge, Insekten und Blumen der Umgebung zu dokumentieren. 1896 begann er einen Kunstkurs in Cleveland, schrieb sich im selben Jahr an der Cleveland School of Arts ein und erhielt 1899 ein Stipendium für ein fünfjähriges Kunststudium in New York, wo er an der Chase School und an der National Academy of Design studierte. An der National Academy of Design besuchte er die "Meisterklasse" bei William Merritt Chase. In dieser Zeit studierte er eine Technik, die „Segantini stitch“ (Segantini-Masche) hieß, wobei reine Farbe nebeneinander in langen, breiten Strichen auf die Leinwand gebracht wurde. 1906, wieder zurück in seiner Heimatstadt Lewiston, übernahm er den Geburtsnamen seiner Stiefmutter „Marsden“ als Vornamen. 1909 traf er Alfred Stieglitz, der noch im selben Jahr Hartleys erste Einzelausstellung in dessen New Yorker Galerie 291 eröffnete. Als sich ihm durch die Großzügigkeit von Stieglitz die Chance bot, querte er im April 1912 den Atlantik und blieb einige Jahre in Europa.

Zunächst ging er nach Paris, wo er im Kreis seiner Mäzenin Gertrude Stein verkehrte. Hier lernte er den Bildhauer Arnold Rönnebeck und dessen Cousin, den deutschen Offizier Karl von Freyburg, kennen und, nach einem kurzen Besuch im Januar 1913, entschied er sich, etwas länger in Berlin zu bleiben, zog im Mai 1913 mit Freyburg in die Metropole und lebte dort bis zum Dezember 1915. Hartley wandte sich von seinem bisher gepflegten Stil der Landschafts- und Stillleben-Malerei ab, er knüpfte Kontakte zur deutschen Avantgarde und pflegte besonders intensiven Austausch mit Wassily Kandinsky und Franz Marc, deren künstlerisches Schaffen, neben Kubismus und Orphismus, für Hartleys Arbeit bestimmend wurde.

Es entstand eine Reihe von Gemälden, die zuerst von Hartleys Förderer Alfred Stieglitz in seiner New Yorker Galerie 291 gezeigt wurde und heute als "Ikonen der amerikanischen Avantgarde" gelten. In ihnen malte Hartley sowohl figurative ("The Warriors." 1913) wie zunehmend abstrakte Darstellungen des preußischen Militärs, das er als Ausdruck kraftvoller Maskulinität tief bewunderte. Georgia O’Keeffe hingegen fand, die Bilder seien in Komposition und Farben viel zu laut, "wie eine Blaskapelle in einem kleinen Wandschrank". Den Kriegstod seines Freundes Karl von Freyburg am 7. Oktober 1914, mit dem er eine erotische Beziehung hatte, verarbeitete Hartley in einer Reihe von zwölf symbolischen Gemälden.

Er wurde durch die Kriegsereignisse zur Rückkehr in die Vereinigten Staaten gezwungen und ging in seine Heimatstadt zurück, um dort die „Regionalgröße“ unter den Bildenden Künstlern in Maine zu werden und eine eigenständige originär "US-amerikanische Malerei" hervorzubringen. Das Spätwerk zeichnet sich vor allem durch Landschaften, Seestücke und Genrebilder aus, denen eine expressiv-konturierte Farbigkeit zu eigen ist.

Marsden Hartleys Dichtung und Malerei wurden von der Kunstgeschichte vor allem als Teil der Avantgarde und als modernistisch verstanden, in letzter Zeit betonte Donna M. Cassidy den Zusammenhang von Hartleys Werk mit dem amerikanischen "Regionalismus" (Grant Wood, Thomas Benton).

2014 fand erstmals eine Ausstellung "Marsden Hartley: The German Paintings" mit 30 Gemälden aus seiner Berliner Zeit in der Berliner Neuen Nationalgalerie statt.






</doc>
<doc id="10294" url="https://de.wikipedia.org/wiki?curid=10294" title="Shvetambaras">
Shvetambaras

Die Shvetambaras (Sanskrit, m., श्वेताम्बर, śvetāmbara, Weißgekleideter) sind eine Gruppe innerhalb des Jainismus.
Obwohl es auch unter den Shvetambaras Mönche gibt, bilden sie doch eher die große Gruppe der Laien innerhalb der Jaina-Gemeinde. Im Vergleich zu den Digambaras vertreten sie eher gemäßigtere Standpunkte. Doch auch die Shvetambaras leben prinzipiell nach dem Gebot der "ahimsa", der Gewaltlosigkeit und dem Respekt gegenüber allen Lebewesen. Um nicht versehentlich ein Insekt zu töten tragen sie häufig einen weißen Mundschutz oder fegen den Boden bevor sie darauf treten. 

Im Zentrum des Heiligtums von Shravanabelagola bei Mysore ist der − nach Digambara-Sitte − völlig unbekleidete Jaina-Asket Bahubali/Gomateshvara dargestellt − das Idealbild vieler Jainas, auch der Shvetambaras. Seine bewegungslose Meditation geht sogar so weit, dass sich an seinem Körper Ranken emporwinden.

Die Postulate von Gewalt- und Bewegungslosigkeit haben dazu geführt, dass Jainas meist in 'sitzenden', aber exklusiven Berufen wie Händler, Juweliere u. ä. tätig waren bzw. sind. Diese Tatsache − verbunden mit einer weitgehend asketischen Lebensführung − wiederum bedeutete, dass viele Shvetambara-Familien durchaus wohlhabend wurden und mit großen Geldmitteln aufwendig gestaltete Tempelbauten bzw. deren Restaurierung (z. B. in Mount Abu, Ranakpur oder Jaisalmer) finanzieren konnten, die auch von Digambaras besucht werden.




</doc>
<doc id="10295" url="https://de.wikipedia.org/wiki?curid=10295" title="Arshile Gorky">
Arshile Gorky

Vosdanig Manoug Adoian (, * 15. April 1904 in Khorkom, Vari Hayoz Dzor, Vilâyet Van, Osmanisches Reich; † 21. Juli 1948 in Sherman, Connecticut, Vereinigte Staaten), besser bekannt unter dem Pseudonym Arshile Gorky, war ein armenischstämmiger Zeichner und Maler, der 1939 die amerikanische Staatsangehörigkeit annahm. Er war, obwohl er selbst sich der Gruppe der Surrealisten nicht zugehörig fühlte, der letzte in diese Gruppe aufgenommene Künstler. Sein Werk war wegbereitend für den Abstrakten Expressionismus. Es inspirierte die Künstler der New Yorker Schule.

Unter seinem aus der kaukasischen Form des armenischen Vornamens Arschak oder Arsakes (von persisch: "kleiner Bär") und dem russischen Nachnamen Gorky ("bitter") zusammengesetzten Pseudonym schuf der heimatvertriebene Künstler sich ab 1924 eine neue Identität. Er schilderte sein früheres Leben auf unterschiedliche, nicht immer wahrheitsgetreue Weise. Er nannte beispielsweise Tiflis als Geburtsort, behauptete, in Paris studiert zu haben und gab sich als Mitglied der Pariser Künstlergruppe Abstraction-Création (1931–1937) aus, sowie als Angehörigen von Maxim Gorki, ohne dabei zu berücksichtigen, dass dieser ebenfalls ein Pseudonym angenommen hatte. Des Weiteren legte Gorkys Neffe Karlen Mooradian Ende der 1960er und Anfang der 1970er Jahre englische Übersetzungen von Briefen vor, die Gorky in armenischer Sprache an seine Schwestern geschrieben haben soll und deren Authentizität heute in Frage gestellt wird. Da sowohl Gorkys Aussagen, als auch die vermutlich gefälschten Briefe in viele Biografien einflossen, ist vor allem der Schilderung von Gorkys erstem Lebensabschnitt mit entsprechender Skepsis zu begegnen.

Der spätere Künstler wurde in einfachen Verhältnissen in dem Dorf Khorkom am Vansee (heute "Dilkaya" im türkischen Landkreis Edremit) als Sohn des armenischen Bauern Sedrak Adoyan und seiner Ehefrau Shushan, Tochter des armenisch-apostolischen Priesters Sarkis Der Marodorosian geboren. Das Kind wurde nach dem Geburtsort seiner Mutter, deren Vorfahren seit Jahrhunderten in der kleinen Klosteranlage Charahan Surp Nischan in Vostan ansässig gewesen waren, auf den Namen Vostanik getauft, etwa ab seinem vierten Lebensjahr im Familienkreis aber nach seinem Großvater aus der väterlichen Linie Manuk (englisch "Manoog") genannt.

In den Zeiten der Verfolgung und des Völkermordes an den Armeniern hatten Vosdanigs Eltern nach dem Verlust des jeweils ersten Ehepartners eine Vernunftehe geschlossen, Shushans Vater war 1898 ermordet worden, ihr sechzehnjähriger Bruder Nishan im Jahr 1903. In dieser gefährlichen Lage ließ Sedrak Adoyan seine Frau mit vier Kindern unter der Obhut seines Bruders in Khorkom zurück, als er – um sich der Einberufung in die türkische Armee zu entziehen – in den Jahren von etwa 1906 bis 1910 in die Vereinigten Staaten auswanderte. Vosdanig wuchs also im Kreis seiner Schwestern auf: der ältesten Halbschwester Akabi, aus Shushans erster Ehe, Satenik und Yartoosh. Der Knabe zeigte früh künstlerische Begabung und begann im Jahr 1908, sich mit Holzschnitzarbeiten zu beschäftigen. Vorbilder dafür fand er möglicherweise in den 40 kunstvoll bemeisselten Grabmälern seiner Ahnen in der Klosterkirche Charahan Surp Nischan. Im selben Jahr trat er in die armenisch-apostolische Dorfschule ein, wo er unter anderem Zeichenunterricht erhielt. Mit der Mutter und zwei seiner Schwestern zog er im Jahr 1910 nach Aikesdan, einem Vorort von Van. Die Stadt wurde im Ersten Weltkrieg dem Erdboden gleichgemacht, während in Khorkom Vosdanigs Verwandte dem Genozid (1915) zum Opfer fielen. Dies veranlasste Vosdanigs Mutter, mit ihren Kindern einen rund 200 Kilometer langen Gewaltmarsch anzutreten und in Jerewan Zuflucht zu suchen. Nachdem seine beiden ältesten Schwestern ebenfalls in die Vereinigten Staaten ausgewandert waren (1916) und die durch Flucht und Entbehrungen gezeichnete Mutter an Auszehrung gestorben war (1919), gelang es dem jungen Halbwaisen, sich mit seiner jüngeren Schwester Yartoosh, die er später oft in seinen Werken darstellte, bis nach Ellis Island durchzuschlagen. Als das Geschwisterpaar im April 1920 in New York eintraf, vollendete der Immigrant (wenn das Geburtsjahr 1904 zugrunde gelegt wird), gerade sein 16. Lebensjahr.

Das Geschwisterpaar fand bei der Halbschwester Akabi in Watertown, Massachusetts Aufnahme. Vosdanig reiste bald nach Providence weiter, um vorübergehend bei seinem Vater zu wohnen, an den er sich kaum zu erinnern vermochte. Er konnte keine engere Beziehung mehr zu ihm aufbauen und erhielt auch von seinem späteren Tod (1947) keine Kenntnis. Bis zum Frühjahr 1921 besuchte er die "Providence’s Technical High School", dann die New School of Design in Boston (1922–1924) später die National Academy of Design und die Grand Central School of Art, beide in New York. Nach seinem Abschluss lehrte er vermutlich an der letztgenannten Schule. In New York nahm er das Pseudonym Arshile Gorky an (1924), mietete ein Atelier in Manhattan (36 Union Square ) und debütierte im Museum of Modern Art in der Gruppenausstellung "Exhibition of work of 46 painters and sculptors under 25 years" (1930).
Er fand in New York Kontakt zu anderen jungen Künstlern. Im Jahr 1927 lernte er die Malerin Ethel Schwabacher (1903–1984), seine spätere Förderin und Biografin kennen, mit der ihn eine lebenslange Freundschaft verbinden sollte. Er befreundete sich unter anderem mit den beiden Kubisten Iwan Dabrowsky alias John D. Graham (1886–1961) und Stuart Davis (1894–1964), sowie mit dem 1926 aus Österreich eingewanderten Bühnenbildner und Raumgestalter Friedrich Kiesler (1890–1965). Nach 1933 unterstützte er den Niederländer Willem de Kooning (1904–1997) mit dem er gemeinsam ein Atelier anmietete und der zeit seines Lebens einer seiner engsten Freunde blieb.

Gorkys erste Einzelausstellung, der weitere folgten (siehe unten), fand in den Mellon Galleries in Philadelphia statt (1934). 1935 erhielt er Unterstützung durch die kurz zuvor zur Linderung der durch die Great Depression verursachten Not gegründete Works Progress Administration (später Works Projects Administration, kurz WPA). Die Behörde, die Arbeitsbeschaffungsmassnahmen für arbeitslose Arbeiter und Handwerker, aber auch Intellektuelle und Künstler durchführte, beauftragte Gorky im Rahmen des "Federal Art Projects" (FAP) mit der Ausführung einer großflächigen Wanddekoration für den 1928 eröffneten Newark Airport in Newark, New Jersey. Die Arbeit wurde im Jahr 1936 im Rahmen einer WPA-Ausstellung im Museum of Modern Art in New York gezeigt und kam nie an den vorgesehenen Platz, da der Flughafen ab Beginn des Zweiten Weltkrieges der US Army als Stützpunkt diente.

Offizielle künstlerische Anerkennung wurde Gorky im Jahr 1937 zuteil, als das Whitney Museum im Anschluss an eine dort organisierte Ausstellung sein Werk "Painting" (1936/37) ankaufte, sowie durch die Teilnahme an der Weltausstellung in New York (1939) anlässlich welcher er seine Wanddekorationen im Aviation Pavilion zeigen konnte. 1941 widmete das Museum of Art in San Francisco ihm eine Retrospektive.

Die Begegnung im Jahr 1942 mit dem Surrealisten Roberto Matta (1911–2002) und jene zwei Jahre später mit dem infolge der Besetzung Frankreichs durch deutsche Truppen nach New York übergesiedelten André Breton (1896–1966) beeinflusste seinen Werdegang nachhaltig. In New York vertrat der Galerist und Kunsthändler Julien Levy (1906–1981) die Interessen der Surrealisten, seitdem er gegen Ende der 20er Jahre in den Kreisen der Pariser Avantgarde verkehrt hatte. Julien Levy nahm später die "Entdeckung" Gorkys für sich in Anspruch. Eine Einzelausstellung widmete er ihm in seiner renommierten Galerie allerdings erst im Jahr 1945.

Damals begann der Künstler, in Sherman, Connecticut, mit Hilfe des befreundeten, dort ansässigen Architekten Henry Hebblen eine Scheune zum Atelier umzubauen, in der 1946 zahlreiche seiner Gemälde und Zeichnungen sowie ein großer Teil seiner Bücher einer Feuersbrunst zum Opfer fielen. Schließlich verlegte er seinen Hauptwohnsitz nach Sherman (1947) und unterhielt in New York nur noch sein Atelier.

Nach der Diagnose einer Darmkrebserkrankung und der darauffolgenden Operation litt Gorky unter einer tiefen Depression. 1948 zog er sich in einem gemeinsam mit Julien Levy erlittenen Autounfall einen Nackenbruch zu. Folgeerscheinungen waren die Lähmung des rechten Armes, unerträgliche Kopfschmerzen und Schlafstörungen. Unter dem Einfluss von Alkohol stieß Gorky in einem Tobsuchtsanfall seine Frau Agnes, geborene Magruder, die er 1941 geheiratet hatte, eine Treppe hinunter, worauf sie ihn mit den beiden gemeinsamen kleinen Töchtern verließ.

Arshile Gorky erhängte sich im Juli 1948 im Alter von 44 Jahren in seinem Atelier in Sherman. Er ruht dort auf dem North Cemetery.

Seine älteste Tochter, die Malerin Maro Gorky, heiratete Matthew Spender (Sohn des britischen Schriftstellers Stephen Spender), der eine Schrift über Gorkys ersten Lebensabschnitt in Khorkom verfasste.


Postum:

Der talentierte und intuitive Künstler ergriff schon als Kind jede Gelegenheit, um zu zeichnen und bereitete zeit seines Lebens seine Gemälde durch sorgfältige Vorzeichnungen vor. Er bildete sich hauptsächlich als Autodidakt, besuchte Ausstellungen und las Kunstbücher. Er studierte und kopierte, im Einklang mit der traditionellen akademischen Methode, die Techniken großer Meister von der Antike bis in die Gegenwart und eignete sich nicht nur künstlerische Fertigkeiten, sondern, wie Kollegen und Studenten hervorhoben, auch erstaunlich umfassende Kenntnisse zu dem Œuvre von Joan Miró und jenem von Pablo Picasso (und anderen Künstlern wie Fernand Léger) an. Entsprechend vielseitig sind die Inspirationsquellen, die sein Werk nährten.

Das Frühwerk ist hauptsächlich geprägt durch Gorkys Auseinandersetzung mit den Werken Paul Cézannes ("Self portrait at the age of nine") und Pablo Picassos. Der in bestimmten seiner Zeichnungen deutlich erkennbare Einfluss des synthetischen Kubismus geht unter anderem auch auf einen künstlerischen Austausch mit John D. Graham zurück, der in Paris gelebt und dort sowohl mit den Kubisten, als auch mit den Surrealisten Umgang gepflegt hatte. Diese Zeichnungen trugen Gorky den Beinamen "„Picasso des Washington Square“" ein. Andere Zeichnungen, wie das Porträt der Schwester des Künstlers, sind von Picassos "ingresker" Periode beeinflusst. Des Weiteren inspirierten ihn Picassos Atelierbilder aus den Jahren 1927/28, wobei allerdings Gorkys viel lockere, weichere und dynamischere Pinselführung im Gegensatz zu den strengen, harten Konturen des katalanischen Künstlers steht ("The artist and his mother").

In den 1930er Jahren löste der Maler sich allmählich von diesen (und anderen) Vorbildern. Einerseits setzte er sich in seinem Werk fortan (und bis zu seinem Lebensende) mehr und mehr mit seiner armenischen Herkunft und Kindheit auseinander, andererseits begann er, sich der Freilichtmalerei zu widmen. Die Arbeit in der Natur begleitete eine grundlegende Veränderung der Arbeitsweise, des Stils und des Bildinhaltes. Merkmale dafür sind unter anderem eine scheinbar explosionsartig befreite, deutlich schnellere Gestik, ein flüssigerer Farbauftrag und leuchtendere Farbtöne sowie die bis zum Beginn der 1940er Jahre zunehmend in die Gemälde einfliessenden subtilen, nicht selten zweideutigen Anspielungen auf organische oder anatomische Formen "(Garden in Sochi)".

Gorky wandte sich anschließend dem Surrealismus zu, wobei er sich besonders mit Joan Miró und Roberto Matta auseinandersetzte. Er übernahm Mirós kryptische Liniensprache, die ihm als optimale Symbiose von Menschen, Tieren und Pflanzen erschien. Von Matta übernahm er die automatische Schreibweise. Aus den Versatzstücken von Miró und Matta fand er zu einer persönlichen Bildsprache, die Traumbilder als amorphen Fluss protokolliert.

Während seiner Lehrtätigkeit an der New Yorker „Grand Central School of Art“ vermittelte er den amerikanischen Studenten die europäische Tradition und war ein Wegbereiter des abstrakten Expressionismus.






</doc>
<doc id="10296" url="https://de.wikipedia.org/wiki?curid=10296" title="Robert Motherwell">
Robert Motherwell

Robert Motherwell (* 24. Januar 1915 in Aberdeen, Washington; † 16. Juli 1991 in Provincetown, Massachusetts) war ein US-amerikanischer Maler des Surrealismus und Abstrakten Expressionismus.

Motherwell studierte in den Jahren von 1932 bis 1938 zuerst an der California School of Fine Arts und danach an der Stanford Universität Philosophie, wo er den Bachelorabschluss machte. Des Weiteren studierte er Philosophie und französische Literatur an der Harvard Universität. Nach einem zweijährigen Aufenthalt von 1938 bis 1939 in Paris, wo er sich unter anderem mit den späteren europäischen Exilkünstlern Piet Mondrian und Fernand Léger anfreundete, studierte Motherwell in New York an der Columbia Universität bei Meyer Schapiro und Kurt Seligmann Kunstgeschichte. 1940 lernte er Robert Matta kennen, mit dem er noch im selben Jahr eine Reise nach Mexiko unternahm, wo er den österreichischen Surrealisten Wolfgang Paalen kennenlernte. Nach mehreren Monaten bei Paalen kehrte er 1941 nach New York zurück, wo er Paalen half, seine gegen-surrealistischen Ideen zu propagieren und bei dessen Kunstmagazin "DYN" mitarbeitete. 1945 lehrte er am Black Mountain College, North Carolina. Zwischen 1951 und 1958 hatte Motherwell einen Lehrauftrag am Hunter College in New York inne.

Seine Zeichnungen und großformatigen Malereien sind durch dominante schwarze Zeichensetzungen geprägt. Ab den 1960er Jahren fand eine Annäherung an das "Color-Field-Painting" von Morris Louis statt. Motherwell war einer der wichtigsten Vertreter des amerikanischen Abstrakten Expressionismus. Meist wird er dem Action Painting zugeordnet, er gilt aber als das eher „intellektuelle Gegenstück“ zu Malern wie Jackson Pollock. Er gründete 1947/1948 zusammen mit William Baziotes, Mark Rothko und Barnett Newman die Schule „Subjects of the Artists“.

Von 1958 bis 1971 war er mit der Malerin Helen Frankenthaler verheiratet. 1972 heiratete er die deutsche Fotografin Renate Ponsold, mit der er bis zu seinem Tod liiert blieb.







</doc>
<doc id="10297" url="https://de.wikipedia.org/wiki?curid=10297" title="Peggy Guggenheim">
Peggy Guggenheim

Peggy Guggenheim, eigentlich "Marguerite Guggenheim" (* 26. August 1898 in New York, USA; † 23. Dezember 1979 in Camposampiero bei Padua, Italien) war als Autodidaktin eine amerikanische Kunstmäzenin, Sammlerin und Galeristin der Kunst des 20. Jahrhunderts.

Peggy Guggenheim war eine von drei Töchtern des New Yorker Geschäftsmanns Benjamin Guggenheim und dessen Frau Florette Seligman (1870–1937). Ihr Vater entstammte einer der wohlhabendsten Industriellenfamilien Amerikas; er kam 1912 beim Untergang der "Titanic" ums Leben. Ihr Onkel war der amerikanische Industrielle und Kunstsammler Solomon R. Guggenheim, Gründer der Solomon R. Guggenheim Foundation.

Als Peggy Guggenheim im August 1919 volljährig wurde, erhielt sie ein Erbe von 450.000 Dollar, das sie von ihrer Familie unabhängig machte. Im Herbst 1920 trat sie ein Volontariat in der Buchhandlung „Sunwise Turn“ in New York an, wo sie viele Intellektuelle und Künstler kennenlernte. Im Dezember des Jahres ließ sie ihre Nase operieren, doch da die plastische Chirurgie noch in den Kinderschuhen steckte, misslang die Operation. 

Im Jahr 1921 zog Guggenheim nach Paris, genoss das Leben der Bohème und lernte viele Künstler und Schriftsteller kennen, mit denen sie Freundschaft schloss, unter ihnen beispielsweise Djuna Barnes, Marcel Duchamp und Man Ray, der 1924 eine Porträtserie von ihr schuf. 1922 heiratete sie den französischen Maler und Bildhauer Laurence Vail; aus dieser Verbindung entstammen ihre beiden Kinder Sindbad (1923–1986) und Pegeen Vail (1926–1967). Nach acht Jahren wurde die Ehe geschieden. Vail neigte alkoholisiert zu Gewalttätigkeiten, und sie hatte sich in den britischen Schriftsteller John Holms (* 1897) verliebt, der, alkoholkrank, bereits im Jahr 1934 verstarb.

Guggenheim begann sich auf den Ratschlag von Samuel Beckett, mit dem sie ab Dezember 1937 eine kurze Affäre hatte, mit zeitgenössischer Kunst zu beschäftigen und kaufte Werke der Avantgarde, unter anderem von Constantin Brâncuși, Georges Braque, Marc Chagall, Salvador Dalí, Marcel Duchamp, Wassily Kandinsky, Piet Mondrian, Wolfgang Paalen und Pablo Picasso. Duchamp beriet sie bei der Eröffnung ihrer Galerie Guggenheim Jeune, 30 Cork Street, London, die am 24. Januar 1938 mit einer Jean-Cocteau-Ausstellung stattfand. Es bedurfte vorher eines kompletten Einführungkurses in die moderne Kunst durch Duchamp, denn Guggenheim hatte, wie sie bekannte, vorher keine Kenntnisse darüber: „Ich konnte nicht ein modernes Werk vom anderen unterscheiden“. Als Nächstes folgte eine Kandinsky-Ausstellung, und im Juni 1938 stellte sie Werke von Yves Tanguy aus, mit dem sie, sehr zum Missvergnügen von Tanguys damaliger Ehefrau, Jeanette, eine Affäre hatte. Als sie einmal auf Kandinskys Bitte ihrem Onkel Solomon R. Guggenheim ein Bild des Malers, das sich ihr Onkel früher gewünscht hatte, für sein mit Hilla von Rebay 1939 eröffnetes kleines Museum, das Museum of Non-Objective Painting, in Manhattan anbot, erhielt sie ein brüskes Ablehnungsschreiben Rebays, wonach kommerzielle Angebote nicht erwünscht seien. Im Jahr 1939 schloss Guggenheim die Galerie wieder, da diese – trotz großer Medienaufmerksamkeit, die ihre Ausstellungen begleitete – keinen Gewinn abwarf. Guggenheim kehrte nach Paris zurück. Dort erweiterte sie zu Beginn des Zweiten Weltkriegs ihre Sammlung täglich, da viele Künstler die Stadt verlassen und ihre Gemälde verkaufen wollten. Unter Anleitung von Marcel Duchamp und Howard Putzel, einem jungen Kunsthändler aus Kalifornien, kaufte sie für weniger als 40.000 Dollar den Grundstock ihrer großen Sammlung moderner Kunst, darunter Braque, Max Ernst, Giacometti, Kandinsky, Paul Klee und Mirò. Sie habe keine Ahnung gehabt, dass sie Kunst zu Schleuderpreisen erworben habe, sagte sie später. „Ich habe einfach bezahlt, was man mir sagte.“

Der amerikanische Journalist Varian Fry leitete in Marseille ein Hilfskomitee, das Emergency Rescue Committee, um Flüchtlingen die Ausreise aus dem Vichy-Regime Frankreichs zu ermöglichen. Guggenheim unterstützte das Komitee im Dezember 1940 mit einer Summe von 500.000 Franc. Unter den Emigranten waren Künstler wie Marc Chagall und Jacques Lipchitz. Guggenheim finanzierte beispielsweise die Ausreise von Max Ernst, dessen Werk als „Entartete Kunst“ diffamiert wurde, sowie die des surrealistischen Schriftstellers André Breton mit Familie. Doch auch Guggenheim, die jüdischer Abstammung war, musste mit ihrer Sammlung Frankreich verlassen und flog im Juli 1941 mit Max Ernst, mit dem sie befreundet war, von Estoril nach New York. Ihre Kunstsammlung hatte sie gesondert verschickt. Im Dezember 1941, kurz nach Weihnachten, fand die Heirat mit Max Ernst statt.

In New York eröffnete Guggenheim im Jahr 1942 erneut eine Galerie, Art of This Century in der 30 West 57th Street, die zugleich Museum war, und förderte aus Europa emigrierte sowie neue US-amerikanische Künstler – unter anderem Jackson Pollock. Im Januar 1943 fand dort die Ausstellung „Exhibition by 31 Women“ statt, bei deren Vorbereitung sich Max Ernst in die Malerin Dorothea Tanning verliebte, was zum Bruch der ehelichen Beziehung führte und 1946 zur Scheidung. Die Galerie, nach Plänen des Architekten Friedrich Kiesler ausgestattet, bestand bis zum 31. Mai 1947. In diesem Jahr kehrte Peggy Guggenheim nach Europa zurück und zog nach Venedig.

Im Jahr 1948 erhielt Guggenheim die Einladung, ihre Kunstsammlung auf der Biennale von Venedig auszustellen. Sie wurde im griechischen Pavillon, der wegen des Bürgerkriegs leerstand, präsentiert. Im selben Jahr hatte sie den unvollendeten Palazzo Venier dei Leoni am Canal Grande mit Garten aus dem 18. Jahrhundert erworben und umbauen lassen. Seit 1949 nutzte sie ihn zugleich als Wohnung und als gelegentlichen Ausstellungsraum ihrer Sammlung, der bereits ab 1951 in den Sommermonaten der Öffentlichkeit zugänglich war. 

Die Tate Gallery in London stellte von Januar bis März 1965 den größten Teil von Guggenheims Sammlung aus und ehrte sie mit einem Festbankett. 1969 wurde sie vom Solomon R. Guggenheim Museum, New York, eingeladen, ihre Sammlung dort zu zeigen. Zu diesem Zeitpunkt entschloss sie sich, ihre Kunstsammlung sowie den Palast der Solomon R. Guggenheim Foundation zu vermachen. 

Peggy Guggenheim verstarb 1979. Ihr Grab und das Grab ihrer geliebten Hunde, Lhasa-Dogs, befinden sich auf dem Gelände des Museumgartens (später Nasher Sculpture Garden genannt) in Venedig. In den Räumen des Palazzo ist seit 1980 das Museum Peggy Guggenheim Collection untergebracht, das weiterhin ihre Sammlung ausstellt. 

Ihr bewegtes Leben schrieb Guggenheim erstmals 1946 in der Autobiografie "Out of This Century" nieder. 1960 erschien das um private Details gekürzte und um kunstbezogene Ergänzungen erweiterte Werk erneut unter dem Titel "Confessions of an Art Addict". Eine Ausgabe letzter Hand erschien postum 1980.

Viele der von ihr gesammelten Werke sind heute in Museen zugänglich; außer der bereits genannten Peggy Guggenheim Collection in Venedig ist es das Solomon R. Guggenheim Museum in New York sowie das Guggenheim-Museum Bilbao in Bilbao.

Peggy Guggenheim war die Schwiegermutter des französischen Malers Jean Hélion, der mit ihrer Tochter Pegeen von 1946 bis 1958 verheiratet war.

Guggenheim sah sich als „arme Guggenheim“, was aufgrund des relativ geringen Erbes nicht ganz falsch war, genoss aber weiterhin, „in Opposition zur obersten Schicht der Gesellschaft, in die sie hineingeboren war“, deren Privilegien. Im Gegensatz zu „anderen Guggenheims, die wohltätige Einrichtungen mit Hilfe des Familienvermögens gründeten“, nahm Peggy Guggenheim „nicht die Form einer Institution an und war zudem überaus persönlich.“ Sie distanzierte sich von Anfang an von bestehenden Normen, und ihr Interesse an der Person des Künstlers ging meist ihrer Beschäftigung mit dem Kunstwerk voraus. Aufgrund der Missachtung jeglicher Konventionen galt sie als Rebellin, wurde zum „"arbiter elegantiarum"“ (Sachverständiger in Angelegenheiten des Geschmacks) und „galt in ihrer italienischen Wahlheimat schließlich als "l’ultima dogaressa"“ (die letzte Dogaressa).

In dem Film "Pollock", eine Biografie des amerikanischen Malers Jackson Pollock aus dem Jahr 2000, spielt Guggenheim eine wichtige Rolle, sie wird dargestellt von Amy Madigan. Regie führte der Hauptdarsteller Ed Harris.

"Peggy Guggenheim: Art Addict" ist ein Dokumentarfilm über Peggy Guggenheim; Regie führte Lisa Immordino Vreeland. Der Film hatte am 20. April 2015 auf dem Tribeca Film Festival seine Premiere.





</doc>
<doc id="10299" url="https://de.wikipedia.org/wiki?curid=10299" title="Joseph Cornell">
Joseph Cornell

Joseph Cornell (* 24. Dezember 1903 in Nyack, New York; † 29. Dezember 1972 in New York) war ein US-amerikanischer Bildhauer, Maler und Experimentalfilmer.
Beeinflusst vom Surrealismus komponierte er seit 1931 Collagen und Assemblagen. Er freundete sich mit einigen Surrealisten an, die vor dem Zweiten Weltkrieg in die USA geflohen waren. Cornell lebte den größten Teil seines Lebens im New Yorker Stadtteil Queens zusammen mit seiner Mutter und seinem behinderten Bruder Robert. Als Künstler war er Autodidakt und wurde vor allem durch seine "Boxes" berühmt, die er „constructions“ nannte: Assemblagen in Kästen, oft mit einer Glaswand versehen, in denen er poetische Sammlungen von Fotografien, Sternkarten, Kugeln oder viktorianischem Spielzeug nach eigener Symbolik verband. 

Positiv gesinnte Kritiker attestierten ihm, die formale Klarheit des Konstruktivismus mit der lebhaften Fantasie des Surrealismus zu kombinieren. Im Gegensatz zu vielen Surrealisten fand er seine Objekte zwar auch im Alltag, war aber nicht vom Negativen oder Verworfenen fasziniert, sondern von Fragmenten des einst Schönen, die er zu hintergründigen, humorvollen, teilweise erotischen Kompositionen zusammensetzte. Er war Teilnehmer der 4. documenta in Kassel im Jahr 1968 und auch auf der Documenta 5 im Jahr 1972 als Künstler vertreten. 

Joseph Cornell war mit seiner Kunst, insbesondere mit seinen "Boxes", unter anderem Vorbild für Tony Curtis, der Cornell über einen langen Zeitraum hinweg nicht nur finanziell unterstützte.




 


</doc>
<doc id="10300" url="https://de.wikipedia.org/wiki?curid=10300" title="Buch der Richter">
Buch der Richter

Das Buch der Richter (Abkürzung: Ri; hebr.: "Sefer Schoftim" ספר שופטים) ist ein Teil des Tanach und somit des Alten Testaments. Seit dem Mittelalter wird es in 21 Kapitel unterteilt.

Geschildert wird die Zeit nach der Landnahme (Buch Josua) bis kurz vor Beginn der Königszeit unter Saul (ca. 1050 v. Chr.).

In dieser Zeit war Israel ein Judikat, d. h., es wurde durch Richter regiert. Die bekanntesten sind die Richterin Debora und die Richter Gideon, Simson (Samson) und Samuel, unter dem die Richterzeit endete und die Königszeit begann.

Das hebräische Wort („Richter“) beinhaltet anders als im Deutschen nicht nur eine juristische, sondern auch eine politisch-militärische Komponente (vgl. phönizisch-punisch Sufet). Im Richterbuch herrscht die politisch-militärische Komponente vor. Die Richterin Debora erobert mit Hazor die Metropole des Nordens (abweichend von dieser Darstellung tut dies bereits Josua), während einzelne der sogenannten "kleinen Richter" (Tola, Schamgar, Jaïr, Ibzan, Elon und Abdon) eine überwiegend juristische Aufgabe hatten. Von juristischen Aufgaben im eigentlichen Sinne, also von Rechtsprechung, berichtet das Buch jedoch nicht. Auch ist die Bezeichnung der Personen als „Richter Israels“ irreführend, da sie eigentlich nur jeweils "einer" Stadt oder "einem" der Zwölf Stämme Israels vorstanden. Die verschiedenen Kapitel des Richterbuches handeln in verschiedenen Teilen des Siedlungsraumes der Stämme.

Die Erzählungen der sogenannten "großen Richter" Otniël, Ehud, Barak, Gideon, Jiftach und Simson (alternative Schreibweise: Samson) folgen dem immer gleichen Kreislauf:


Die Betonung der Rettung Israels nur durch ihren Gott ist ein starker Hinweis auf einen Deuteronomisten als Redaktor des Buches. In der fragmentarisch erhaltenen Handschrift 4Q559 werden die Richter Israels ebenfalls beschrieben; offenbar als Teil einer fortlaufenden Chronologie und ohne einen deuteronomistischen Rahmen.

Das Buch beginnt mit der Fortführung der geschichtlichen Erzählung über die Landnahme Israels, die direkt an die Erzählungen im Buch Josua anschließt. Die Stämme Juda, Simeon und Benjamin erobern die Gebiete westlich des Toten Meeres, darunter die Städte Jerusalem und Hebron. Einige der Völker in den eroberten Gebieten können jedoch nicht ganz vernichtet werden. Das Gebiet von Gaza bleibt von den Philistern besetzt .

Auch die Siedlungsgebiete der Stämme Manasse, Efraim, Sebulon, Ascher und Naftali werden erobert. Allerdings gelingt es auch hier nicht, sämtliche Einwohner der eroberten Gebiete zu vertreiben. Teilweise sind die Israeliten jedoch stark genug, die Bewohner zur Fronarbeit zu zwingen .

Das Kapitel 2 beginnt mit einer Drohung durch den Engel Gottes, da die Israeliten nicht, wie von JHWH gefordert, die Bewohner des Landes vertrieben oder umbrachten und die Altäre der fremden Gottheiten niederrissen: „Deshalb sage ich euch jetzt: Ich werde [die fremden Völker] nicht vor euren Augen vertreiben, sondern sie sollen euch Widerstand leisten, und ihre Götter sollen euch zu Fall bringen.“ 

Der folgende Abschnitt über Josuas Tod gehört chronologisch an den Anfang des Buches, vor die Landnahme der einzelnen Stämme. Josua, der Sohn Nuns, starb im Alter von hundertzehn Jahren, er wurde in Timnat-Heres auf dem Gebiet seines Stammes Efraim begraben. Nachdem die ganze Generation Josuas, die mit ihm über den Jordan geschritten war, gestorben war, erinnerte sich Israel nicht mehr an die Taten JHWHs und diente anderen Göttern .

In folgt dann eine erklärende Zusammenfassung zu den folgenden Abschnitten der einzelnen Richter. Wegen der Verfehlungen des Volkes wird es große Not leiden müssen, dann wird Gott einen Richter schicken, um das Volk zu erlösen. Zeit seines Lebens wird dann Friede herrschen, danach verfällt das Volk wieder zu bösem Treiben. „Schlimmer als ihre Väter“ trieben sie es und „ließen nicht ab von ihrem bösen Treiben und ihrem störrischen Verhalten.“ Es folgt eine kurze Liste der Völker, die nach der Landnahme weiterhin unter den Israeliten wohnten.

Es folgen die Erzählungen der vierzehn wichtigsten Richter. Die Erzählungen halten sich, wo sie ausführlich genug sind, ziemlich genau an das vorher aufgezeigte Schema: Abfall – Elend – Berufung eines Richters – Errettung – Friede – Abfall.


Der Schlussteil des Buches enthält noch einige geschichtliche Erzählungen, die mit den Richtern nichts zu tun haben. Die Daniter ziehen nach Lajisch (später Dan genannt), schlagen die Einwohner mit scharfem Schwert und zerstören die Stadt. Unterwegs hatten sie das Gottesbild des Efraimiters Micha und dessen Priester mitgenommen und stellen das Bildnis bei sich auf. Es soll bis zur Verschleppung in die Babylonische Gefangenschaft dort gestanden haben .

Im Kapitel 19 steht eine Erzählung, die stark an die Ereignisse in erinnert. Die Nebenfrau eines Leviten wird auf übelste Weise vergewaltigt und umgebracht, als er in Gibea im Siedlungsgebiet von Benjamin übernachtete. Als Warnung zerteilt er sie in zwölf Teile und schickt sie an alle Stämme Israels . Die Israeliten versammeln sich daraufhin in Mizpa, um gegen Gibea wegen des Verbrechens vorzugehen. Benjamin stellt jedoch eine starke Streitmacht auf, statt die Übeltäter wie gefordert herauszugeben. Die ersten zwei Angriffe auf die Stadt werden zurückgeschlagen, und die Israeliten erleiden starke Verluste. Am dritten Tag gelingt den Israeliten mittels eines Hinterhaltes dann doch ein Angriff auf die Stadt Gibea. Sie stecken die Stadt in Brand und vernichten das ausgezogene Heer fast vollständig. 25.000 aus dem Stamm Benjamin fallen an diesem Tag .

Sofort nach dem Ende der Schlacht bereuen die Israeliten, dass nun praktisch der ganze Stamm Benjamins ausgerottet ist. Sie können dem verbleibenden Rest aber keine Frauen aus den eigenen Reihen geben, da sie geschworen hatten, das nicht zu tun. Nun jedoch finden sie, dass Jabesch-Gilead niemanden an die Versammlung geschickt hatte, also nicht an diese Verpflichtung gebunden war. Dafür hatte man geschworen, jeden zu vernichten, der der Versammlung ferngeblieben war. Die Israeliten zogen also aus, vernichteten Jabesch-Gilead und brachten alle Bewohner um, außer den Jungfrauen, die sie finden konnten. Diese gab man den Benjaminitern. Weil es aber zu wenige Frauen waren, raubten die Benjaminiter die Frauen von Schilo während eines Festes .

Der letzte Satz des Buches fasst gleichsam als Parabel die Geschehnisse nochmals zusammen und weist auf die kommenden Ereignisse in den Büchern des Propheten Samuel hin: „In jenen Tagen gab es noch keinen König in Israel; jeder tat, was ihm gefiel“ .

Im Neuen Testament wird relativ selten Bezug auf das Buch der Richter genommen. Die meist indirekten Verweise konzentrieren sich auf die als Glaubenshelden wahrgenommenen Personen. Johannes der Täufer wird in als Samson-artiger Nasiräer dargestellt (ohne dass dort der Name Samson fällt). stellt anlässlich der Geburt Jesu einen ähnlichen Bezug her. Wie Jaël, die Frau, die Sisera tötete, im Deboralied wird Maria in als „mehr gesegnet als alle anderen Frauen“ bezeichnet.

Eine direkte Erwähnung von Personen des Richterbuches findet sich in , wo Gideon, Barak, Samson und Jiftach als Glaubenshelden neben Henoch, Noach, Abraham, Isaak, Jakob, Mose, Rahab, David, Samuel und den Propheten genannt werden. Die sehr von der alttestamentlichen Vorlage abweichende Charakterisierung der Personen im Hebräerbrief erklärt sich aus der homiletischen Zielsetzung 11. Kapitel des Hebräerbriefs. Dieses Kapitel ist keine Exegese alttestamentlicher Texte, sondern eine Predigt über den Glauben.

Allgemein

Forschungsberichte

Kommentare

Einzelstudien



</doc>
<doc id="10301" url="https://de.wikipedia.org/wiki?curid=10301" title="Buch Rut">
Buch Rut

ֹּDas Buch Rut oder Ruth, , ist ein Buch des Tanach und des christlichen Alten Testaments. Seit dem Mittelalter wird es in vier Kapitel unterteilt. Das Buch Rut umfasst als eine Novelle in der hebräischen Bibel insgesamt 85 Verse. Hier steht das Buch unter den „fünf Festrollen“ (Rut, Hoheslied, Kohelet, Klagelieder, Ester). In der griech.-latein. Überlieferung wird es als Anhang des Buches der Richter betrachtet und demzufolge vor den Büchern Samuels eingeordnet. Das „Fremdvölkermotiv“ (Rut, die Moabiterin) lässt jedoch viele Ausleger eine Abfassungszeit in nachexilischer Zeit vermuten (nicht vor der zweiten Hälfte des 6. Jahrhunderts v. Chr.). Im Judentum zählt das Buch Rut zu den fünf Megillot, den Festrollen, und wird in der Festtagsliturgie des jüdischen Wochenfestes gelesen. Das Buch handelt um ca. 1000 v. Chr., zur Zeit der Richter in Israel. Obed, der Sohn Ruts, ist der Großvater Davids.

Das Buch Rut erzählt vom Schicksal einer jüdischen Familie, die einer Hungersnot wegen aus Bethlehem in Juda ins benachbarte Moab auswandern muss. Noomi (eine der Hauptgestalten der Novelle) und Elimelech ziehen mit ihren beiden Söhnen Machlon und Kiljon in die Fremde, wo bald danach Elimelech stirbt. Die Söhne heiraten zwei moabitische Frauen, Rut und Orpa , bleiben aber kinderlos. Nachdem auch die Söhne gestorben sind, bleibt Noomi als verwitwete Frau mit ihren nun ebenfalls verwitweten Schwiegertöchtern allein zurück .

Orpa bleibt daraufhin in Moab, Rut jedoch besteht darauf, mit ihrer Schwiegermutter nach Israel zu ziehen, obwohl sie dort als Moabiterin mit Zurückweisung zu rechnen hat. Rut antwortete: „Dränge mich nicht, dich zu verlassen und umzukehren. Wohin du gehst, dahin gehe auch ich, und wo du bleibst, da bleibe auch ich. Dein Volk ist mein Volk und dein Gott ist mein Gott. Wo du stirbst, da sterbe auch ich, da will ich begraben sein. Der Herr soll mir dies und das antun – nur der Tod wird mich von dir scheiden.“ 

In Israel arbeitet Rut als Ährenleserin bei Boas, einem Verwandten von Noomi. Boas bemerkt Rut, erkennt ihr außergewöhnliches Engagement für ihre Familie an (2,11ff.) und begünstigt sie. Daraufhin bekommt Rut von Noomi den Rat, sich nachts nach der Feldarbeit zu Boas zu legen. Boas verspricht Rut, sie zu heiraten. Es gibt jedoch noch einen anderen Verwandten, der gemäß dem Leviratsgesetz ebenfalls das Recht und die Pflicht hat, Rut zu heiraten. Da dieser ablehnt, löst Boas Rut aus und nimmt sie zur Frau. Rut gebiert ihm einen Sohn, den Obed, den Vater Isais und Großvater Davids. Rut ist somit auch mit Jesus verwandt (vgl. Stammbaum Jesu bei Matthäus und Lukas )





Bibelkommentare: 
Roman-Adaptionen: 



</doc>
<doc id="10303" url="https://de.wikipedia.org/wiki?curid=10303" title="1. Buch Samuel">
1. Buch Samuel

Das 1. Buch Samuel (abgekürzt 1 Sam) ist ein biblisches Buch des (jüdischen) Tanach und des (christlichen) Alten Testaments. Ursprünglich bildete 1 Sam zusammen mit dem 2. Buch Samuel eine Einheit. Der Name geht darauf zurück, dass es nach jüdischer Tradition von Samuel verfasst wurde. In der Septuaginta (und infolgedessen auch in den Ostkirchen) heißt es 1. Buch der Königreiche. Die Septuaginta-Fassung dieses Buches ist an manchen Stellen wesentlich kürzer als die heutige hebräische Fassung, was dafür spricht, dass der hebräische Text erst spät seine endgültige Form erlangte. Seit dem Mittelalter wird das 1. Samuelbuch in 31 Kapitel unterteilt.
Das 1. Buch Samuel erzählt die Geschichte Israels von der Bitte der kinderlosen Hanna um einen männlichen Nachkommen, über die Geburt des Propheten Samuel bis zum Selbstmord Sauls und dem Tod seiner Söhne im Kampf gegen die Philister. Zum letzten Kapitel findet sich eine Parallele im 1. Buch der Chronik (1 Chr 10,1–12).

Neben den Erzählungen findet sich auch ein Psalm, der Lobgesang der Hanna (1 Sam ).

Ein inhaltlicher Schwerpunkt ist die Entstehung des Königtums und die Ambivalenz gegenüber diesem (1 Sam 8–12). Besonders in (1 Sam ) werden deutlich die Nachteile des Königtums benannt, in (1 Sam ) wird der Wunsch des Volkes Israel nach einem König als Abfall von Gott gedeutet. In 1 Sam 11 wird Saul dann als König gewählt, und in 1 Sam 13–31 wird die Herrschaft dieses ersten Königs geschildert. Die Schilderungen sind nach einigen Anfangserfolgen Sauls geprägt von der Konkurrenz Sauls mit seinem Gegenspieler David, der von Gott begünstigt wird. Auch die eigenen Familienangehörigen Sauls ergreifen für David Partei. Sauls Tochter Michal liebt David (1 Sam 18,28), und Sauls Sohn Jonathan greift zugunsten Davids ein und warnt diesen vor seinem Vater (1 Sam 19,2–3).






</doc>
<doc id="10304" url="https://de.wikipedia.org/wiki?curid=10304" title="2. Buch Samuel">
2. Buch Samuel

Das 2. Buch Samuel ist ein biblisches Buch im Tanach. Es wird seit dem Mittelalter in 24 Kapitel unterteilt. In den Ostkirchen heißt es 2. Buch der Königreiche.

Der Prophet Samuel erscheint nur im 1. Buch Samuel; die beiden Bücher Samuel waren einst ein einziges Buch, und so behielten die Teile den Namen bei, nachdem sie aus praktischen Gründen (handhabbare Größe einer Schriftrolle) voneinander getrennt wurden. Hauptfigur dieses Buches ist vielmehr David. Das Buch weist viele Parallelen zum 1. Buch der Chronik auf. Im Gegensatz zu diesem ist es aber merklich kritischer und legt den Schwerpunkt mehr auf die politischen Ereignisse als auf den Kultus. Neben den Erzählungen finden sich auch Psalmen (2. Sam 1,19–27: Davids Klagelied über Saul und Jonatan; 2. Sam 22: Davids Danklied (= Ps 18, 1–51); 2. Sam 23: Davids letzte Worte).

Das Buch schildert zunächst den Aufstieg Davids als König über Juda und ganz Israel nach Siegen über Rafaiten und Philister. In 2 Sam () erhält David durch den Propheten Natan die Zusage Gottes, dass seine Dynastie für immer erhalten bliebe. Die positive Sicht Davids schlägt in 2 Sam 11 um, wo geschildert wird, wie David mit der verheirateten Batseba Ehebruch begeht und deren Ehemann Urija in den Tod schickt.

Dafür wird David von Gott durch Natan zur Rechenschaft gezogen. Es wird angekündigt, dass die Nachkommen Davids durch Gewalt umkommen werden (2 Sam ). Es folgt eine Geschichte von kriegerischen Geschehnissen, Aufständen und Gewalt: so z. B. 2 Sam 13 die Vergewaltigung von Davids Tochter Tamar durch ihren Halbbruder, den Davidssohn Amnon oder den Aufstand des Sohnes Abschalom gegen seinen Vater und das Ende Absaloms durch Joab.

Im letzten Kapitel (2 Sam 24) bringt David Gott mit einer Volkszählung, die er gegen den Rat Joabs vollzieht, gegen sich auf. Infolgedessen wird das Volk mit einer Pest bestraft, die endet als David auf dem späteren Tempelplatz opfert. Das Buch schließt mit Nachträgen und Davids Vermächtnis.

Das 1. Buch der Könige stellt eine Fortsetzung des Buches Samuel dar.





</doc>
<doc id="10305" url="https://de.wikipedia.org/wiki?curid=10305" title="Chlorophylle">
Chlorophylle

Das Chlorophyll (von altgriechisch "chlōrós" „hellgrün, frisch“ und "phýllon" „Blatt“) oder Blattgrün bezeichnet eine Klasse natürlicher Farbstoffe, die von Organismen gebildet werden, die Photosynthese betreiben. Insbesondere Pflanzen erlangen ihre grüne Farbe durch Chlorophyll.

Pflanzen, Algen und Cyanobakterien besitzen verschiedene Chlorophylltypen, photosynthesetreibende Bakterien verschiedene Typen von Bacteriochlorophyll.

Chlorophylle sind Chelat-Komplexe genannte Molekularstrukturen, bestehend aus einem derivatisierten Porphyrin-Ring und Mg als Zentralion. Im Unterschied zum Porphyrin enthält das Grundgerüst der Chlorophylle einen weiteren, fünften Ring an Ring III (Nummerierung nach Fischer). Je nach Art des Chlorophylls sind an den Grundkörper verschiedene Seitenketten angehängt. So ist beispielsweise Chlorophyll "a" mit Phytol verestert (vgl. Tabelle). Chlorophyllide sind Chlorophylle ohne Seitenketten.

Strukturell sind die Chlorophylle mit den Hämen verwandt, welche als Bestandteil des Blutfarbstoffs (Hämoglobin), des Myoglobins und der Cytochrome auftreten, als Zentralion jedoch nicht Magnesium, sondern Eisen enthalten. Chlorophylle sind gut löslich in Ethanol und Aceton, sowie ähnlichen Lösungsmitteln. Läuft die Photosynthese bei Lebewesen ab, die Sauerstoff freisetzen (oxygene Phototrophe), spricht man allgemein von "Chlorophyll". Anoxygene Phototrophe erzeugen jedoch nicht Sauerstoff als Reaktionsprodukt bei der Photosynthese, bei diesen Organismen bezeichnet man das Chlorophyll als "Bakteriochlorophyll".

Hans Fischer ermittelte 1940 die Molekülstruktur von Chlorophyll, die absolute Konfiguration wurde 1967 von Ian Fleming aufgeklärt.

Die Absorptionsspektren von in Lösungsmitteln gelösten Chlorophyllen besitzen immer zwei ausgeprägte Absorptionsmaxima, eines zwischen 600 und 800 nm, das als Q-Bande bezeichnet wird, und eines um 400 nm, das Soret-Bande genannt wird. Die Abbildung rechts zeigt diese Absorptionsmaxima für Chlorophyll "a" und "b". Zusätzlich existiert die Q-Bande um 580 nm, die senkrecht zu Q polarisiert ist und in der Regel sehr schwach absorbiert. Für Chlorophyll "a" ist sie in der Abbildung noch zu erkennen, für Chlorophyll "b" verschwindet sie im Untergrund. Der zwischen den Banden liegende Bereich wird als Grünlücke bezeichnet.

Anhand der Spektren in der Abbildung kann man leicht verstehen, warum Blätter – diese enthalten Chlorophyll "a" und "b" – grün sind. Zusammen absorbieren Chlorophyll "a" und "b" hauptsächlich im blauen Spektralbereich (400–500 nm) sowie im roten Spektralbereich (600–700 nm). Im grünen Bereich hingegen findet keine Absorption statt, so dass grünes Licht gestreut wird, was Blätter grün erscheinen lässt.

Die Absorption ist abhängig vom Lösungsmittel und dementsprechend kann die Lage der Absorptionsmaxima je nach Art des Lösungsmittels um einige wenige Nanometer variieren. In der natürlichen Umgebung von Chlorophyllen, also der Proteinumgebung, sieht das anders aus. Hier hängt die Lage der Absorptionsmaxima von zwei Faktoren ab: (1) Je nach Partialladung der umgebenden Aminosäuren und Verbiegung der Seitengruppen der Chlorophyllmoleküle können die Absorptionsmaxima bei stark unterschiedlichen Wellenlängen liegen. (2) In Proteinen kommen sich Chlorophylle sehr nahe, sodass sie eine Wechselwirkung aufeinander ausüben (Dipol-Dipol-Wechselwirkung; bei sehr geringen Abständen auch Austauschwechselwirkung). Diese Wechselwirkung führt zu einer Absenkung der Energieniveaus und damit zu einer Rotverschiebung der Absorptionsmaxima. Dies kann man besonders eindrucksvoll am Beispiel des Antennenkomplexes LH2 von Purpurbakterien sehen. Der LH2-Komplex besteht aus zwei ringförmig angeordneten Gruppen von Bacteriochlorophyllmolekülen (siehe Abbildung links). Der obere Ring (B850) enthält 18 BChl "a"-Moleküle, die in sehr geringen Abständen voneinander liegen, also stark gekoppelt sind. Der untere Ring (B800) besteht aus 9 BChl "a"-Molekülen, die deutlich weiter voneinander entfernt liegen und somit viel schwächer gekoppelt sind.

Durch die starke Kopplung wird die Absorption von BChl "a" im B850-Ring zu Rot verschoben. Die Absorptionsbande liegt bei 850 nm. Die schwachgekoppelten BChl "a" des B800-Rings absorbieren hingegen bei 800 nm, also ungefähr im gleichen Bereich wie in Lösungsmittel gelöste BChl "a"-Moleküle. Im Absorptionsspektrum (Abbildung rechts) des LH2-Komplexes sind die Absorptionsbanden der B800- und der B850-BChl-"a"-Moleküle deutlich getrennt. Zusätzlich werden Banden dargestellt, die von Carotinoidmolekülen stammen, diese sind in der Struktur nicht eingezeichnet.

Es gibt verschiedene Typen von Chlorophyll, die sich in den Seitengruppen des Porphyrins unterscheiden. Sie besitzen verschiedene Absorptionsspektren und kommen bei verschiedenen phototrophen Organismen vor:

Chlorophyll wird bei Eukaryoten in den Chloroplasten synthetisiert, bei Prokaryoten im Cytoplasma. Bei vielen Phototrophen wird die Chlorophyll-Bildung durch Licht induziert und bleibt ohne Belichtung aus. Die Biosynthese besteht aus einer Reihe zahlreicher Schritte mit einer entsprechenden Anzahl spezifischer Enzyme.

Die Synthese dieses und anderer Tetrapyrrole ist ein mehrstufiger Prozess, der auch verschiedene Verzweigungspunkte aufweist. Die Biosynthese geht von -Glutamat aus und endet in einem Sirohäm-, einem Häm- und einem Chlorophyll-Zweig.

Nach mehreren Schritten wird aus -Glutamat Uroporphyrinogen III gebildet, dem ersten Verzweigungspunkt, aus dem Sirohäm gebildet werden kann. Uroporphyrinogen III wird dann in drei Schritten zu Protoporphyrin IX umgesetzt, was den zweiten Verzweigungspunkt zu den Hämen darstellt. In Protoporphyrin IX wird bei einer ATP-abhängigen Reaktion das Magnesiumion eingeführt, was eine Magnesium-Chelatase () katalysiert. Das hierbei gebildete Mg-Protoporphyrin IX wird über Mg-Protoporphyrin IX-Monoethylester zu Dinvinyl-Protochlorophyllid "a" umgesetzt. Jenen Schritt katalysiert eine Cyclase, die den fünften Ring in Chlorophyll einführt. In Pflanzen ist dieses Enzym O-abhängig, während es bei Prokaryonten sowohl O-abhängige als auch -unabhängige Cyclasen gibt.

Im nächsten Schritt wird der D-Ring des Protochloropylls durch eine Oxidoreduktase () zu Divinyl-Chlorophylid "a" reduziert. In Angiospermen ist diese Reaktion absolut lichtabhängig. Daher bilden Keimlinge erst dann Chlorophyll, wenn sie dem Licht ausgesetzt sind. Andere Pflanzen (einige Gymnospermen), Algen aber auch Cyanobakterien haben sowohl eine lichtabhängige als auch lichtunabhängige Oxidoreduktase. Infolgedessen können diese Organismen Chlorophyll auch im Dunkeln synthetisieren. Divinyl-Chlorophylid "a" wird durch eine Reduktase zu Monovinyl-Chlorophylid "a" reduziert, bevor dieses in einem letzten Schritt mittels Phytolphosphat zu Chlorophyll "a" verestert wird. Diesen terminalen Schritt katalysiert eine Chlorophyll-Synthase, eine Prenyltransferase ().

Aus Chlorophyll "a" kann auch Chlorophyll "b" oder umgekehrt gebildet werden.

Der Abbau des Chlorophylls in Laubbäumen erzeugt im Herbst eine charakteristische Färbung der Blätter. Chlorophyll wird durch die Chlorophyllase zu Chlorophyllid verstoffwechselt. Anschließend erfolgt ein Ionenaustausch durch die Mg-Dechelatase zu Phäophorbid. Phäophorbid wird durch die Phäophorbid-A-Oxygenase mit dem Cofaktor Ferredoxin oxidiert, wodurch die Grünfärbung verschwindet und zuerst verschiedene fluoreszente Abbauprodukte (FCC, von engl. "fluorescent chlorophyll catabolites") und im weiteren Abbau nichtfluoreszente Stoffe (NCC) entstehen. In Spitzahorn wird Chlorophyll über einen anderen Abbauweg zu Dioxobilan abgebaut.

Chlorophylle haben innerhalb der Photosynthese im Photosystem I, sowie im Photosystem II mehrere Aufgaben. Der mit Abstand größte Anteil dient der Lichtabsorption und der Weiterleitung der absorbierten Energie. Sie wirken also als Photosensibilisatoren. Hierzu sind die Chlorophyllmoleküle in Lichtsammelkomplexen organisiert, die so angeordnet sind, dass einerseits eine möglichst große absorbierende Fläche gebildet wird und andererseits ein energetischer Trichter entsteht, der die absorbierte Energie zum sogenannten Reaktionszentrum leitet. Im Reaktionszentrum dienen zwei Chlorophylle als Akzeptor dieser Energie. Sie sind so speziell angeordnet, dass ihre Anregung zu einer Ladungstrennung führt, die als erster Schritt der eigentlichen Photosynthese betrachtet werden kann. Dieses Chlorophyllpaar wird im Englischen als "special pair" bezeichnet.

Bei den sehr verschiedenen photosynthesebetreibenden Organismen gibt es vielfältige Unterschiede in der Struktur der Lichtsammelkomplexe, das Reaktionszentrum hingegen ist immer nahezu gleich strukturiert. Das "special pair" wird bei Pflanzen, Algen und Cyanobakterien immer von Chlorophyll "a", bei Bakterien von verschiedenen Bakteriochlorophyllen gebildet.

Der Chlorophyllgehalt ist vor allem in grünem Gemüse hoch. Der Chlorophyll "a"- und "b"-Gehalt von Gemüse und Obst je 100 g Frischsubstanz ist in folgender Tabelle geordnet nach absteigendem Chlorophyll "a"-Gehalt aufgeführt:

Erste Beschreibungen eines „Farbstoffes“, der durch Ethanol („Weingeist“) extrahiert werden kann und unter Lichteinfluss zersetzt wird, finden sich bei Heinrich Friedrich Link in seinem Buch „Grundlehren der Anatomie und Physiologie der Pflanzen“, Göttingen 1807. Ebenso findet man uneindeutige Nachweise, dass Joseph Louis Proust den grünen Farbstoff als „Fécule“ beschrieben hat. Pierre Joseph Pelletier und Joseph Bienaimé Caventou extrahierten den Stoff erneut und nannten ihn "Chlorophyll". Erste Studien über die chemische Struktur des Chlorophylls stammen von Richard Willstätter (1913). Der Chemiker Hans Fischer nahm Willstätters Forschungen in den 1930er Jahren wieder auf, 1940 konnte er die Struktur des Moleküls aufklären. Fischers Forschungsergebnisse wurden 1960 durch Robert B. Woodwards Chlorophyllsynthese bestätigt.

Eine wichtige Eigenschaft des Chlorophylls ist die Chlorophyllfluoreszenz. Sie wird vor allem zum Bestimmen des Chlorophyllgehalts und dessen Aktivität sowie für andere wissenschaftliche Analysen genutzt.

Wegen seiner geruchsneutralisierenden Wirkung ist Chlorophyll auch in Drageeform in der Apotheke erhältlich, als Mittel gegen Mund- und Körpergeruch. Als Lebensmittelzusatzstoff erhält Chlorophyll die Kennnummer E 140.





</doc>
<doc id="10306" url="https://de.wikipedia.org/wiki?curid=10306" title="Chlamys (Muschel)">
Chlamys (Muschel)

Chlamys ist eine Gattung der Kammmuscheln (Pectinidae) in der Ordnung der Pectinida innerhalb der Klasse der Muscheln (Bivalvia). Sie leben bzw. lebten ausschließlich im Meer. Die ältesten Vertreter der Gattung sind aus der Trias bekannt. Viele Arten werden intensiv befischt und sind von hoher kommerzieller Bedeutung.

Die Gehäuse sind gewöhnlich höher als lang. Beiden Klappen sind konvex gewölbt; gewöhnlich ist die linke Klappe etwas stärker gewölbt. Das vordere Ohr ist größer als das hintere Ohr. Unterhalb des vorderen Ohrs der rechten Klappe befindet sich ein großes Byssusloch. Die Außenseite ist mit zahlreichen, bedornten Rippen oder Wulsten besetzt, wobei die Wulste wiederum von feineren radialen Rippen besetzt sind. Diese radialen Elemente können von konzentrischen Anwachsrippen und -wulsten gekreuzt werden. Der innere Rand weist feine radiale Rippen auf. Die Cruren, kleine Fortsätze am Schloss sind schwach entwickelt bis fehlend. Die Schalen sind bei zahlreichen Arten auffallend bunt gefärbt. Die Färbung kann orange, gelb, rosa, purpurn, braun oder weiß sein.

Auffallend am Weichkörper sind die in Reihen angeordneten Augen, die am lebenden Tier als schwarze Pigmentflecken in der Mantelfalte erkennbar sind. Die Tiere nutzen die Augen zur Erkennung sich nähernder Fressfeinde, aber vermutlich auch zur Orientierung beim Schwimmverhalten.

"Chlamys"-Arten sind getrennt-geschlechtlich, das Mengenverhältnis Männchen zu Weibchen ist 1:1 oder nahe daran.

Die Entwicklung ist an verschiedenen Arten untersucht worden, beispielsweise bei "Chlamys hastata". Aus dem etwa 70 Mikrometer großen, befruchteten Ei schlüpft ein frei schwimmendes Larvenstadium, die Trochophora. Diese beginnt aus zwei dorsalen Schalenfeldern nach etwa 45 Stunden Entwicklung Schalenmaterial abzusondern. Nach etwa 50 Stunden ist die Umwandlung zur ebenfalls freischwimmenden, planktonischen Veliger-Larve abgeschlossen. Diese hat ihrem Namen nach dem Velum, einem ovalen, lappenförmigen, mit Zilien besetzten Organ, das sowohl zur Fortbewegung wie zur Nahrungsbeschaffung eingesetzt wird. Nach etwa 34 Tagen ist der Fuß entwickelt, die Larven kriechen jetzt oft auf der Substratoberfläche umher, dabei werden sowohl Muskeln wie auch Zilien eingesetzt. Die Larvalentwicklung ist nach etwa 40 Tagen abgeschlossen, die Schalenlänge beträgt dann etwa 240 Mikrometer. In einer raschen Metamorphose entwickeln sich aus kleinen Kiemenanlagen die funktionsfähigen Kiemen, Mundöffnung und Fuß wandern in die imaginale Lage. 

Für eine kommerzielle Ernte ausreichende Größe (etwa 6 Zentimeter) wird nach 5 bis 6 Jahren erreicht. Die Tiere können aber ein Lebensalter von 28 bis 30 Jahren erreichen, maximal 35 Jahre Sie sind dann etwa 8 Zentimeter groß.

"Chlamys"-Arten leben am Meeresgrund auf Hartsubstraten, oft auch auf Sandgrund mit einzelnen Steinen, an denen sie sich mit Byssusfäden verankern. Sie können sich im Falle von ungünstigen Bedingungen von der Verankerung lösen. Wie viele Pectinidae sind sie schwimmfähig, schwimmen aber nicht so oft und aktiv wie andere Arten der Familie (meist mit glatten Schalen). Beim Schwimmen wird Atemwasser beiderseits des Schlosses ausgepresst, so dass das Tier mit dem Schloss nach hinten schwimmt. Die Tiere kommen von der Brandungszone bis maximal in etwa 2.000 Meter Meerestiefe, meist aber nur bis etwa 120 bis 200 Meter Tiefe, vor. 

Die alte umfassende Gattung "Chlamys" wurde in zahlreiche Untergattungen aufgeteilt, die jetzt überwiegend als eigenständige Gattungen aufgefasst werden. Die frühere Gattung wurde nach molekularen Untersuchungen als paraphyletisch bestätigt. 

Die Gattung im modernen Sinn umfasst nur noch die frühere Untergattung "Chlamys" s. str. mit folgenden lebenden (rezenten) Arten:


Die Arten "Zygochlamys subantarctica" Hedley, 1916, und "Zygochlamys delicatula" Hutton, 1873 (syn. "Chlamys campbellicus", "Chlamys instar") werden von manchen Autoren noch in der Gattung "Chlamys" geführt. Die Artnamen "Chlamys russata" (Reeve, 1853) (vermutlich ein Synonym von "Pinna exquisita" Dall, Bartsch & Rehder, 1938) und "Chlamys reticulata" (Reeve, 1853) sind in ihrer Zuordnung unklar (nomen dubium, species inquirenda).

Die zahlreichen anderen Arten, die früher zeitweise in der Gattung geführt worden waren werden aktuell anderen Gattungen zugerechnet.

Die Gattung "Chlamys" im hier dargestellten, modernen Sinn ist auf den Nordpazifik und Nordatlantik beschränkt, sie ist in borealen bis arktischen Gewässern verbreitet. Die Gattung ist weit verbreitet und zirkumpolar, die einzelnen Arten besitzen aber deutlich kleinere Verbreitungsgebiete. Sie sind regional häufig, aber in vielen flacheren Gewässern sind die Bestände durch Überfischung heute deutlich seltener geworden.



</doc>
<doc id="10307" url="https://de.wikipedia.org/wiki?curid=10307" title="Muschel">
Muschel

Muschel bezeichnet:
Muschel ist der Familienname folgender Personen:
Siehe auch:


</doc>
<doc id="10308" url="https://de.wikipedia.org/wiki?curid=10308" title="Isländische Kammmuschel">
Isländische Kammmuschel

Die Isländische Kammmuschel ("Chlamys islandica") oder auch Nördliche Kammmuschel ist eine Muschelart aus der Familie der Kammmuscheln (Pectinidae) und die Typusart der Gattung "Chlamys". Früher lautete die wissenschaftliche Bezeichnung "Pecten islandicus".

Das Gehäuse weist 50 bis 132 feine Rippen auf und wird 60 bis 116 mm lang. Die Rippen werden von konzentrischen Anwachslinien gekreuzt; auf den Kreuzungspunkten können feine Schuppen sitzen. Sehr variabel sind Gehäuseformen und die Gehäusefarben, die alle Schattierungen von weiß über gelb und rot bis zu schwarz abdecken. Die Oberflächen der Gehäuse sind häufig von Seepocken der Gattung "Balanus" besiedelt.

"Chlamys islandica" lebt in Tiefen von 8 bis 1300 m auf Fels- und Kiesgrund, an den sie sich mit Byssusfäden fest anheftet. Sie braucht Wassertemperaturen von unter 10 °C und erträgt noch Temperaturen geringfügig unter 0 °C.
Diese Art kommt rezent im nördlichen Atlantik vor, im Westatlantik südlich bis Cape Cod, in Europa mit Nachweisen in Island, auf den Shetlandinseln sowie den norwegischen Inseln Spitzbergen, Lofoten und Vesterålen und Jan Mayen verbreitet. Sie kommt auch vereinzelt in der Nordsee bis Helgoland und auch auf den Azoren vor.

Die Vermehrung erfolgt durch die Abgabe von Eiern und Spermien ins freie Wasser, wo dann die Befruchtung stattfindet. Aus den befruchteten Eiern entwickeln sich planktonisch-lebende Veliger-Larven. Sie kann bis 23 Jahre alt werden.

Beim Schleppnetzfang im westlichen Mittelmeer werden regelmäßig subfossile Muschelschalen aus der letzten Eiszeit (vor mehr als 11.000 Jahren) gefunden. Hell gefärbte Exemplare aus dem Zeitraum des Klimawechsels gegen Ende dieser Eiszeit kann man z. B. an der Mündung des Clyde in Schottland finden. Im Mittelmeer finden sich noch ältere, durch die Fossilisationsbedingungen schwarzgefärbte Exemplare.

Die Art wird seit 1985 in Norwegen intensiv kommerziell befischt, in Island sogar schon seit 1969. Im Jahr 1986 wurde in Island das Maximum mit 12700 Tonnen angelandet. Später stabilisierte sich die jährliche Fangmenge auf etwa 8000 bis 9000 t. Seit 2000 sind die Bestände jedoch stark rückläufig. 2003 lag die angelandete Menge nur noch bei 800 t. Der Rückgang ist jedoch nicht auf Überfischung zurückzuführen, da der größte Rückgang in einem Gebiet zu beobachten war, wo die Bestände gar nicht befischt wurden. Die Ursachen sind in den ständig steigenden Meerestemperaturen zu suchen.




</doc>
<doc id="10311" url="https://de.wikipedia.org/wiki?curid=10311" title="Ernst Ulrich von Weizsäcker">
Ernst Ulrich von Weizsäcker

Ernst Ulrich Michael Freiherr von Weizsäcker (* 25. Juni 1939 in Zürich) ist ein deutscher Naturwissenschaftler und Politiker (SPD). 1998 bis 2005 war er Mitglied des Deutschen Bundestages. Seit 2012 ist er Ko-Präsident des Club of Rome.

Ernst Ulrich von Weizsäcker entstammt dem pfälzisch-württembergischen Geschlecht Weizsäcker. Er ist der Sohn des Physikers und Philosophen Carl Friedrich von Weizsäcker, Bruder des Wirtschaftswissenschaftlers Carl Christian von Weizsäcker und Neffe des ehemaligen Bundespräsidenten Richard von Weizsäcker. Er ist seit 1969 mit der Biologin Christine von Weizsäcker (geb. Radtke) verheiratet und hat fünf Kinder.

Nach dem Abitur 1958 in Göttingen absolvierte Weizsäcker ein Studium der Chemie und Physik an der Universität Hamburg, das er 1966 als Diplom-Physiker beendete. 1968 wurde er an der Universität Freiburg bei Bernhard Hassenstein mit einer Arbeit zum "Formensehen der Bienen" zum Dr. rer. nat. promoviert.

Von 1969 bis 1972 war Weizsäcker wissenschaftlicher Referent bei der Forschungsstätte der Evangelischen Studiengemeinschaft in Heidelberg. 1972 nahm er einen Ruf der Universität-Gesamthochschule Essen auf einen Lehrstuhl für Biologie an. 1975 bis 1980 war er Präsident der Universität Kassel. 1981 wechselte er als Direktor an das UNO-Zentrum für Wissenschaft und Technologie in New York, 1984 bis 1991 war er Direktor des Instituts für Europäische Umweltpolitik. 1991 bis 2000 war er Präsident des Wuppertal Instituts für Klima, Umwelt, Energie.

Von Januar 2006 bis Dezember 2008 war er Dekan der Bren School of Environmental Science and Management an der University of California, Santa Barbara. Seitdem ist er freiberuflich in Emmendingen tätig und seit 2012 Honorarprofessor an der Universität Freiburg.

Seit 1966 ist Weizsäcker Mitglied der SPD. 1966 bis 1968 war er Vorsitzender der Jungsozialisten in Freiburg im Breisgau. 1968 bis 1972 und 1999 bis 2001 gehörte er dem Landesvorstand der SPD Baden-Württemberg an. 1998 bis 2005 war er Mitglied des Deutschen Bundestages, in den er 1998 über die Landesliste Baden-Württemberg einzog. 2002 wurde er im Wahlkreis Stuttgart I direkt gewählt. Von März 2000 bis Oktober 2002 war er Vorsitzender der Enquête-Kommission "Globalisierung der Weltwirtschaft – Herausforderung und Antworten". Ab November 2002 war er Vorsitzender des Ausschusses für Umwelt, Naturschutz und Reaktorsicherheit. Zur Bundestagswahl 2005 trat er nicht mehr an.








</doc>
<doc id="10312" url="https://de.wikipedia.org/wiki?curid=10312" title="Daseinsvorsorge">
Daseinsvorsorge

Daseinsvorsorge (in der Schweiz öffentliche Dienstleistungen, Service public und öffentliche Infrastruktur) ist in Deutschland ein verwaltungsrechtlicher Begriff, der auch in der politischen und sozialwissenschaftlichen Diskussion eine wichtige Rolle spielt. Er umschreibt die staatliche Aufgabe zur Bereitstellung der für ein menschliches Dasein als notwendig erachteten Güter und Dienstleistungen − die Grundversorgung. Dazu zählt als Teil der Leistungsverwaltung die Bereitstellung von öffentlichen Einrichtungen für die Allgemeinheit, also Verkehrs- und Beförderungswesen, Gas-, Wasser- und Elektrizitätsversorgung, Müllabfuhr, Abwasserbeseitigung, Bildungs- und Kultureinrichtungen, Krankenhäuser, Friedhöfe, Schwimmbäder, Feuerwehr usw. (Infrastruktur). Dabei handelt es sich größtenteils um Betätigungen, die heute von kommunalwirtschaftlichen Betrieben wahrgenommen werden.

Der Begriff wurde von Ernst Forsthoff im Anschluss an Karl Jaspers in die staats- und verwaltungsrechtliche Diskussion eingebracht. Die ursprüngliche Verwaltungsrechtsdogmatik kannte nur die Eingriffsverwaltung. Forsthoff erweiterte diese Dogmatik in seiner 1938 in Königsberg erschienenen Schrift "Die Verwaltung als Leistungsträger" um das Konzept der Leistungsverwaltung, mit dem das Verhältnis des Einzelnen zum leistungsgewährenden Staat bestimmt werden sollte. Er sah die Notwendigkeit, dass dem Einzelnen Teilhaberechte an Leistungen der Daseinsvorsorge zustehen müssen. Die in Erfüllung der sozialen Verantwortung erfolgende leistungsgewährende Betätigung des Staates bezeichnete er als Daseinsvorsorge. Forsthoff definierte den Begriff Daseinsvorsorge in eigenen Worten als „diejenigen Veranstaltungen, die zur Befriedigung des Appropriationsbedürfnisses getroffen wurden“.

Forsthoff begründete die Notwendigkeit der Daseinsfürsorge in "Die Verwaltung als Leistungsträger" wie folgt:
Dieser Aufgabe, "die Grundversorgung mit lebenswichtigen Gütern und Dienstleistungen" „für alle zu sozialstaatlich angemessenen Bedingungen zur Verfügung zu halten“, entsprach die Übernahme der Daseinsvorsorge durch öffentliche Leistungsträger etwa durch eine staatliche Bahn oder Post oder kommunale Versorgungsbetriebe für Wasser und Strom. Inzwischen hat man die Daseinsvorsorge aber weitgehend privatisiert. Hierdurch sollte sie „der Auslesefunktion des Wettbewerbs ausgesetzt werden und dadurch möglichst effizient, flexibel und unbürokratisch funktionieren“. Hierbei bleibt aber nach der Ansicht von Zippelius der Sozialstaat „gefordert, regelnd einzugreifen, wenn die notwendige Grundversorgung … nicht erreicht wird“, z.B. auf Grund von Streiks, auf welche die betroffenen Bürger keinen nennenswerten Einfluss haben. In solchen Fällen entspräche es dem ursprünglichen Gedanken staatlicher Daseinsvorsorge, den Interessenausgleich zwischen Arbeitgebern und Arbeitnehmern in die Hand staatlicher oder kommunaler (also demokratischer) Gesamtverantwortung zu legen, auf deren Seite sowohl die Arbeitgeber als auch die Arbeitnehmer repräsentiert sind.

Der in der öffentlichen Verwaltungspraxis häufig verwendete Begriff der Daseinsvorsorge ist juristisch ein unbestimmter Rechtsbegriff. Er wird in Gesetzen häufig verwendet, ohne dass dort sein Inhalt näher definiert wird. Im Vertrag zur Gründung der Europäischen Gemeinschaft wird in Anlehnung an den französischen Begriff der „services publics“ in Art. 86 Abs. 2 EGV von „Dienstleistungen von allgemeinem wirtschaftlichen Interesse“ gesprochen. Diese werden vage definiert als „marktbezogene Tätigkeiten, die im Interesse der Allgemeinheit erbracht und daher von den Mitgliedstaaten mit besonderen Gemeinwohlverpflichtungen verbunden werden.“ Darunter werden überwiegend die Bereiche der Daseinsvorsorge verstanden. Allerdings sind die Begriffe inhaltlich nicht vollkommen deckungsgleich. Auch die EU-Kommission hat den unbestimmten Rechtsbegriff in ihr Vokabular übernommen und definiert ihn als „marktbezogene oder nichtmarktbezogene Tätigkeiten, die im Interesse der Allgemeinheit erbracht und daher von den Behörden mit spezifischen Gemeinwohlverpflichtungen verknüpft werden“. Vertraglich verankert wurde die Daseinsvorsorge auf europäischer Ebene mit dem Vertrag von Lissabon in den in Art. 14 AEUV geregelten „Diensten von allgemeinem wirtschaftlichen Interesse“.

Rechtliche Grundlage der Daseinsvorsorge ist in Deutschland die Garantie der kommunalen Selbstverwaltung nach Abs. 2 Grundgesetz. Das GG vermeidet den Begriff Daseinsvorsorge, sondern umschreibt ihn als „alle Angelegenheiten der örtlichen Gemeinschaft.“ Darunter versteht das BVerfG diejenigen „Bedürfnisse und Interessen, die in der örtlichen Gemeinschaft wurzeln oder auf sie einen spezifischen Bezug haben“. Was letztlich zum Inhalt der Daseinsvorsorge wird, muss jede Kommune im Rahmen der Selbstverwaltung für sich entscheiden. Während eine Kommune Messestandort ist, sind viele andere Kommunen hingegen kein Messestandort. Bei der einen Kommune gehört das Messe- und Ausstellungswesen somit zur Daseinsvorsorge, bei den anderen nicht. Daseinsvorsorge ist also keineswegs bundeseinheitlich regelbar. In Abs. 2 Zi. 1 Raumordnungsgesetz wird bestimmt, dass in Deutschland ausgeglichene soziale, infrastrukturelle, wirtschaftliche, ökologische und kulturelle Verhältnisse anzustreben sind. Hierbei ist die „nachhaltige Daseinsvorsorge zu sichern“.

Unter Daseinsvorsorge versteht man verwaltungsrechtlich alle Dienstleistungen der Kommune, an deren Erbringung ein allgemeines öffentliches Interesse besteht. Für das BVerfG ist die Daseinsvorsorge eine Leistung, „derer der Bürger zur Sicherung einer menschenwürdigen Existenz unumgänglich bedarf.“ Nach deutschem Verständnis kann die Gestaltung der Daseinsvorsorge wirtschaftlich oder nichtwirtschaftlich, im Wettbewerb oder als Monopol, gewinnbringend, kostendeckend oder zuschussbedürftig sein. Ihre Bandbreite reicht von der Energie- und Wasserversorgung über Abwasser- und Abfallentsorgung, Polizei, Feuerwehr, Krankenhäuser, Friedhöfe, sozialem Wohnungsbau und ÖPNV bis zu kulturellen, sportlichen und sozialen Angeboten. Trotz des Wandels gehört die kommunale Daseinsvorsorge weiterhin zum faktischen Kernbereich der Selbstverwaltung.

Juristisch ungeklärt und heftig umstritten ist die rechtliche Relevanz des Begriffes Daseinsvorsorge. In der Verwaltungsrechtswissenschaft gibt es kaum einen Terminus, der eine größere Faszination ausgelöst hat, aber andererseits auch mehr Ärgernis erregt hat als der Begriff der Daseinsvorsorge. In der verwaltungsrechtlichen Diskussion wird er einerseits häufig verwendet und als Argumentationsstütze herangezogen. Andererseits wird darauf hingewiesen, dass er mehr ein soziologischer Begriff mit vorrangig „problemverdeutlichender, weniger problemlösender Funktion“ sei. Selbst Forsthoff musste 1959 anmahnen, dass der Begriff zu einem „Allerweltsbegriff“ wurde, „mit dem man alles und deshalb nichts beweisen kann“. In seinem Buch „Der Staat der Industriegesellschaft“ räumte Forsthoff ein, es handele sich um einen Begriff der Staatswissenschaften „wie sie im 18. Jahrhundert verstanden wurden“ (S. 77).

Einige Gemeindeordnungen der Länder verwenden den Begriff Daseinsvorsorge: In Baden-Württemberg (§ 102 Abs. 1 Nr. 3 GemO), Bayern (Art. 87 Abs. 1 Nr. 4 BayGO) und Thüringen (§ 71 Abs. 2 Nr. 4 KO) gilt die kommunalwirtschaftliche Subsidiaritätsklausel nur „außerhalb der kommunalen Daseinsvorsorge“. Dies wird jedoch wegen der juristischen Unschärfe des Begriffs Daseinsvorsorge als problematische Regelung angesehen.

Im Rahmen einer Debatte über Privatisierungen wird der Begriff teilweise polarisierend aufgefasst. Wer eher etatistisch denkend den Staat in erster Linie als „Gewährleistungsstaat“ ansieht, neigt dazu, dem Begriff eine besondere und wichtige Rolle einzuräumen. Liberale Politiker halten das Ende der Daseinsvorsorge für gekommen. Jedenfalls ist zu beobachten, dass viele ehemals von Staats- bzw. Gemeindemonopolen wahrgenommene Betätigungen der Daseinsvorsorge heute mit privaten Anbietern konkurrieren müssen bzw., dass die traditionellen Leistungen der Daseinsvorsorge heute auch von Privaten wahrgenommen werden. Auch im Zuge der fortschreitenden Europäisierung des Wirtschaftsrechts, die zunehmend die öffentliche Ausschreibung bisheriger kommunaler Aufgaben vorsieht, sehen selbst die Kommunen und Vertreter der Kommunalwirtschaft die Aufgabe der Kommunalwirtschaft schrumpfen. Staatliche Daseinsvorsorge kann jedoch auch privatwirtschaftlich organisiert werden. In großer Analogie zum „starken Staat“ im Ordnungssystem der Sozialen Marktwirtschaft beschränkt sich der Gewährleistungsstaat in diesem Fall auf die Setzung von Rahmenbedingungen, hier Vertragszielen, und überlässt die Umsetzung der privaten Initiative.

Dahingegen hat es aber auch ab etwa den 2000er Jahren eine teilweise durch Bürgerbegehren getragene Gegentendenz von Rekommunalisierungen (beispielsweise Wasserversorgung in Berlin, Energienetze in Hamburg, etc) gegeben.

Am 23. Juni 2017, dem internationalen Tag des öffentlichen Dienstes, fand erstmals ein Tag der Daseinsvorsorge statt.





</doc>
<doc id="10314" url="https://de.wikipedia.org/wiki?curid=10314" title="Margaret Thatcher">
Margaret Thatcher

Margaret Hilda Thatcher, Baroness Thatcher (* 13. Oktober 1925 als "Margaret Hilda Roberts" in Grantham, Lincolnshire; † 8. April 2013 in London) war eine britische Politikerin.

Während ihrer Ausbildung zur Chemikerin entschied sich Thatcher 1945/1946, politisch tätig zu werden, und kandidierte erstmals 1950 für das Unterhaus. 1959 wurde sie für die Konservative Partei als Unterhaus-Abgeordnete gewählt. 1970 bis 1974 war sie Ministerin für Bildung und Wissenschaft in der Regierung von Edward Heath. In einer Kampfabstimmung um das Amt des Parteivorsitzenden besiegte sie ihn 1975 und blieb bis 1990 Parteivorsitzende.

Nachdem die Konservative Partei die Unterhauswahlen 1979 gewonnen hatte, war Thatcher vom 4. Mai 1979 bis zum 28. November 1990 Premierministerin des Vereinigten Königreichs. Sie war die erste Frau in diesem Amt und übte es ohne Unterbrechung länger als jeder andere britische Premierminister des 20. Jahrhunderts aus. Der Sieg des britischen Militärs im Falklandkrieg (1982) zementierte ihren Ruf als „Eiserne Lady“ und war eine entscheidende Basis für nachfolgende Wahlsiege der Konservativen. Außenpolitisch lehnte Thatcher sich eng an die USA an und unterstützte deren antikommunistischen Kurs. Dagegen stand sie nach anfänglicher Sympathie dem fortschreitenden europäischen Einigungsprozess zunehmend feindselig gegenüber. Unter ihrer Ägide wurden eine umfassende Deregulierung vor allem des Finanzsektors und eine Flexibilisierung der Arbeitsmarktgesetze durchgesetzt, Staatsunternehmen in großem Umfang privatisiert und der Einfluss der britischen Gewerkschaften gebrochen.

Thatcher gilt als eine der umstrittensten politischen Persönlichkeiten der Nachkriegszeit. Von Ihren Anhängern verehrt und ikonisiert, wird sie von ihren Gegnern gleichermaßen verachtet und geschmäht. Sie wurde namensgebend für den Thatcherismus und wird in vielen Songs, Filmen, Büchern und Theaterstücken dargestellt.

Margaret Thatcher wurde als Margaret Hilda Roberts am 13. Oktober 1925 als jüngere von zwei Töchtern geboren. Ihre Eltern entstammten der unteren Mittelschicht. Ihr Vater Alfred Roberts aus Northamptonshire war Kolonialwarenhändler sowie Bürgermeister ihrer Geburtsstadt Grantham und betätigte sich als methodistischer Laienprediger. Ihre Mutter Beatrice Ethel Roberts geb. Stephenson aus Lincolnshire war eine gelernte Hausschneiderin. Während Thatcher auch in späteren Jahren ihren Vater gern als ein von ihr bewundertes, frühes Vorbild anführte und idealisierte, zeigte sie niemals öffentlich Zuneigung zu ihrer Mutter. Ihre Schwester Muriel beschrieb ihre Mutter später als eine „bigotte Methodistin“, zu der sie und Margaret keine enge Beziehung gehabt hätten. „Mutter existierte nicht in Margarets Kopf.“ Die Familie lebte in einer Wohnung über dem Ladengeschäft des Vaters, in dem Margaret und ihre Schwester aushalfen. In späteren Jahren berief sie sich oft auf den Laden ihres Vaters, in dem sie früh ein Verständnis für die Regeln des freien Unternehmertums gewonnen habe. Auch der ihr von ihrem Vater vermittelte christliche Glaube spielte in Thatchers späterem Leben eine große Rolle; als Politikerin benutzte sie oft religiöse Metaphern und gab sich ostentativ als praktizierende Christin. Zeitweise nahm ihre Familie ein jüdisches Kind auf, das aus dem Deutschen Reich geflohen war. Später erlebte sie während des Zweiten Weltkriegs die Angriffe der deutschen Luftwaffe auf ihre Heimatstadt.

Nachdem sie durch ein Stipendium die Volksschule in Kesteven und die Mädchenoberschule in Grantham besucht hatte, studierte Margaret Roberts ab 1943 Chemie am Somerville College in Oxford. Dort nahm sie wenig am Gesellschaftsleben teil, trat jedoch der Oxford University Conservative Association (OUCA) bei. 1947 erwarb sie ihren Bachelor-Abschluss in Chemie, wobei sie im letzten Jahr bei der späteren Nobelpreisträgerin Dorothy Hodgkin eine Abschlussarbeit über Röntgenkristallographie eines Antibiotikums (Gramicidin) anfertigte. Sie arbeitete vier Jahre lang als Chemikerin in der Industrie und hatte ihre erste Anstellung bei British Xylonite Plastics. Im Jahr 1950 wechselte sie zum Nahrungsmittelkonzern J. Lyons & Co., da ihr politisches Zuhause in Dartford (Kent) lag. Dort war sie verschiedenen Anekdoten zufolge auch an der Entwicklung von Softeis beteiligt. Gesichert ist, dass sie an einer Verbesserung der Konsistenz und Qualität von Kuchen und Speiseeis arbeitete.

Nachdem Margaret Roberts etwa um 1945/1946 entschieden hatte, sich politisch zu betätigen, kandidierte sie bei den Wahlen 1950 als konservative Kandidatin für den Wahlkreis Dartford erstmals für das Unterhaus, verlor jedoch in der Labour-Hochburg klar. Dennoch wurde sie als jüngste weibliche Kandidatin des Landes in einer weiteren Öffentlichkeit wahrgenommen. Sie erwartete, einen sicheren Wahlkreis für die nächste Wahl zu bekommen, das Partei-Establishment zog ihr allerdings weniger befähigte Kandidaten vor, wie Richard Aldous 2009 konstatierte.

Im Dezember 1951 heiratete sie den wohlhabenden, geschiedenen Unternehmer Denis Thatcher. Nicht mehr auf eigenes Einkommen angewiesen, begann Margaret Thatcher bald nach ihrer Heirat ein erneutes Studium, diesmal der Rechtswissenschaften. Im Anschluss arbeitete sie kurzzeitig als Anwältin für Steuerrecht. Aus der Ehe mit Denis Thatcher stammen die Zwillinge Carol und Mark, die sie am 15. August 1953 zur Welt brachte. Durch den Einfluss ihres Mannes begann Thatcher, sich dem Anglikanismus zuzuwenden und konvertierte später. Bei den Unterhauswahlen 1955 trat sie nicht an, um sich auf ihre Familie zu konzentrieren.

Danach jedoch begann sie, sich nach einem aussichtsreicheren Parlamentssitz umzusehen. Bei der Wahl 1959 gelangte Thatcher durch einen knappen Sieg für den Wahlkreis Finchley im nördlichen Londoner Stadtbezirk Barnet ins Unterhaus. Ihre erste dortige Rede hielt sie am 5. Februar 1960. 1961 wurde Thatcher von Premierminister Harold Macmillan in die Position einer Parlamentarischen Staatssekretärin im Ministerium für Sozialversicherungen berufen, eine Beförderung, die vor allem in Macmillans Ziel begründet war, mindestens drei Frauen in verantwortlicher Position in seiner Regierung zu haben. In dieser Zeit unterstützte Thatcher Macmillans politischen Kurs und bezeichnete ihn auch 1979 noch als den Politiker des 20. Jahrhunderts, den sie am meisten bewundere. 

In den 1960ern befürwortete sie die Legalisierung von Homosexualität und Abtreibung, war jedoch gegen die Abschaffung der Todesstrafe und äußerte Sympathien für Law and Order-Methoden. Sie unterstützte zudem die erfolglosen britischen Beitrittsgesuche zur Europäischen Wirtschaftsgemeinschaft.
Nachdem die Konservativen 1964 eine knappe Wahlniederlage erlitten hatten, wurde Thatcher in der Opposition zunächst mit dem gleichen Aufgabengebiet betraut, um von April 1966 an als Stellvertreterin für den Schattenkanzler Ian McLeod zu fungieren. Schließlich wurde Thatcher 1967 vom neuen Parteiführer Edward Heath auch in sein Schattenkabinett berufen. Eine sechswöchige Reise durch die USA im selben Jahr weckte Thatchers dauerhafte Begeisterung für das Land. Die USA wurden für Thatcher zum bewunderten Idealbild einer freien Gesellschaft und der freien Marktwirtschaft. Zudem begann sie, sich nun offen für marktliberale Ideen zu interessieren, wie sie vom Institute of Economic Affairs propagiert wurden; umgekehrt wurde sie von anderen Anhängern der Ökonomie des freies Marktes (wie Geoffrey Howe) bis in die 1970er Jahre noch nicht als „eine der ihren“ angesehen. Thatcher nur schrittweise erfolgte Konvertierung hin zu den wirtschaftsfreundlichen Ideen des Neoliberalismus räumte sie später selbst ein.

1970 wurde Thatcher Bildungsministerin im Kabinett von Edward Heath. In dieser Funktion schaffte sie unter anderem die Gratismilch an Grundschulen ab, was ihr mit dem Wortspiel "Milk Snatcher" den Ruf der „Milchdiebin“ einbrachte. Im Jahr 1972 setzte sie sich mit großer Energie für den britischen Beitritt zur Europäischen Wirtschaftsgemeinschaft ein. Die Regierung Heath wurde neben den allgemeinen Auswirkungen der Ölkrise zusätzlich von einer Reihe schwerer Streiks erschüttert und war gezwungen, zeitweise eine Dreitagewoche einzuführen. Um Energie zu sparen, kam es zu Stromabschaltungen. In der Folge beschrieben mehrere Kommentatoren Großbritannien als den „kranken Mann Europas“. Premierminister Heath rief deshalb Wahlen mit dem Wahlkampfslogan „Wer regiert Britannien?“ aus, um sich bestätigen zu lassen. Bei der Unterhauswahl am 28. Februar 1974 erlitten Heaths Konservative jedoch eine Niederlage; es gab (zum ersten Mal seit 1929) ein hung parliament – keine Partei hatte die absolute Mehrheit erreicht. Die Labour Party bildete eine Minderheitsregierung unter Premierminister Harold Wilson und kam zu einem Kompromiss mit den Gewerkschaften. Für Oktober 1974 rief Wilson Neuwahlen aus, bei denen Labour eine knappe Mehrheit der Unterhaussitze erhielt.

Nach der erneuten Niederlage machte sich besonders innerhalb der Parlamentsfraktion der Konservativen Partei eine zunehmende Desillusion und Unzufriedenheit über ihren Parteiführer breit, der nunmehr drei von vier Wahlen verloren hatte. Heath zeigte sich zudem beratungsresistent und unfähig, eigene Fehler anzuerkennen. Der einflussreiche Vorsitzende des 1922-Komitees, Edward DuCann, forderte im Namen der konservativen Hinterbänkler Heath am 13. Oktober auf, sich einer innerparteilichen Neuwahl zu stellen. Nachdem Heath sich zunächst der Forderung widersetzt und eine Machtprobe mit den Abgeordneten des Komitees gesucht hatte, musste er sich im November schließlich jedoch beugen und einer Neuwahl zustimmen. 

Ende November verkündete Thatcher ihre eigene Kandidatur, nachdem der führende Vertreter der Parteirechten, Keith Joseph, sich gegen eine eigene Kandidatur entschieden hatte. Obwohl sie in der Presse als talentierte Politikerin gelobt und ihre Kandidatur in der Sunday Times offen unterstützt wurde, galt sie dennoch als Außenseiterin. Am 4. Februar 1975 trat sie gegen Edward Heath als Parteiführer der Konservativen an und gewann zunächst die erste Runde einer Kampfabstimmung mit 130 zu 119 Stimmen gegen Heath, der daraufhin vom Parteivorsitz zurücktrat. In der zweiten Runde am 11. Februar 1975 schlug sie unter anderem den als favorisiert geltenden William Whitelaw, der aus Loyalität zum Parteiführer Heath in der ersten Runde noch auf eine eigene Kandidatur verzichtet hatte. Thatcher konnte bei ihren als überraschend wahrgenommenen Erfolgen vor allem von den Stimmen des 1922-Komitees profitieren. Nach ihrem Sieg ernannte sie Whitelaw sofort zu ihrem Stellvertreter, der in den kommenden Jahren zu Thatchers loyalstem Unterstützer wurde. Der geschlagene Heath dagegen entwickelte sich zu einem unversöhnlichen persönlichen Gegner Thatchers, der, über die Jahre zunehmend isoliert, bei jeder Gelegenheit gegen Thatchers Politik opponierte.

Als Oppositionsführerin schmetterte Thatcher bald innerparteiliche Vorschläge ab, weiterhin für den sogenannten „middle way“, der vor allem von ihren konservativen Vorgängern Macmillan und Anthony Eden vertreten worden war, einzutreten und bewarb stattdessen innerparteilich die Ideen des Ökonomen Friedrich Hayek. Zudem scharte sie überzeugte Monetaristen um sich, die sich ebenfalls für ein Umdenken in der Wirtschaftspolitik stark machten. Es gelang ihr jedoch nur graduell, diese auf prominente Posten zu befördern; ihr Schattenkabinett bestand weiterhin zu einem großen Teil aus traditionellen Tories, die eher mit ihrem Vorgänger Heath sympathisierten. 

Durch die desolate wirtschaftliche Situation Großbritanniens in den späten 1970er-Jahren und insbesondere durch den Winter of Discontent verlor die Regierung von Labour-Premierminister James Callaghan immer weiter an Popularität; gleichzeitig war Thatcher zunehmend entschlossen, eine völlige Abkehr von der bisherigen Konsenspolitik des „middle ways“ zu betreiben, die sie verantwortlich machte für den britischen Niedergang. Die Sterlingkrise 1976 und die nachfolgende Inanspruchnahme eines Kredits durch den Internationalen Währungsfonds empfand sie als eine nationale Demütigung für Großbritannien. Dazu betonte sie Viktorianischen Werte und deklarierte die ökonomische Krise als Ausdruck einer grundliegenden geistigen Krise der Nation. 

Bei ihren Reden imitierte sie oft ganz bewusst die Rhetorik Winston Churchills. Sie hielt, in Kontrast zu ihren Vorgängern, ein enges Verhältnis zu den Hinterbänklern der Partei, die zusätzlich von ihrer aggressiven und teils populistischen Rhetorik angetan waren. Der von ihr selbst geliebte Spitzname „Eiserne Lady“ (Iron Lady) stammt aus einem Kommentar von "Radio Moskau" im Jahre 1976, nachdem sie in der sogenannten Kensington-Ansprache die „bolschewistische Sowjetunion“ scharf attackiert und dem sowjetischen Politbüro vorgeworfen hatte, nach globaler militärischer Dominanz zu streben.

Bei der Unterhauswahl vom 3. Mai 1979 erhielt die konservative Partei mit 43,9 Prozent der Wählerstimmen 339 von 635 Sitzen. Thatcher wurde tags darauf von Elisabeth II. im Buckingham Palace als Nachfolgerin Callaghans zur Premierministerin ernannt. Bei ihrem Eintreffen in der Downing Street zitierte sie vor der Presse das Gebet des heiligen Franziskus.

Von Anfang an war Thatcher fest entschlossen, ihre Regierung von denen ihrer Vorgänger abzusetzen. Aus machtpolitischer Rücksichtnahme bildete sie ihr erstes Kabinett – ebenso wie vorher ihr Schattenkabinett – nicht ausschließlich aus Getreuen, sondern auch aus vielen One-Nation-Konservativen und Anhängern Heaths. Unter Thatcher änderte sich der Stil der internen Kabinettsdiskussionen substantiell; weg vom erprobten Asquithschen Modell einer moderierenden Führung bevorzugte Thatcher es, die Diskussionen aggressiv von vorne zu führen und führte einen kämpferischen, teils rüden Umgangston ein.

Im weiter andauernden Nordirlandkonflikt setzte sie in weiten Teilen die Politik der vorherigen Regierungen fort und erklärte öffentlich, Nordirland sei und bleibe Teil Großbritanniens, solange eine Mehrheit der dortigen Bevölkerung dies wünsche. Die IRA dagegen führte im Sommer 1979 eine Reihe von blutigen Bombenanschlägen aus.

Im Mai 1980 beendete Thatcher erfolgreich die Geiselnahme in der iranischen Botschaft in London durch irakische Terroristen, indem sie Innenminister Whitelaw eine gewaltsame Befreiungsaktion durch den SAS erlaubte. Die Aktion, live von Fernsehkameras übertragen, brachte dem SAS ein großes mediales Echo und Thatcher erstmals eine Reputation für kühles, entschlossenes Handeln in einer Krisensituation. Auf dem Parteitag der Konservativen im Oktober 1980 adressierte Thatcher Zweifel innerhalb der Partei an ihrer eingeleiteten Wirtschaftspolitik und äußerte in einer ihrer bekanntesten Reden, andere könnten eine Kehrtwende vollziehen, sie selbst stehe nicht bereit für Kehrtwenden.

In mehreren Städten Englands kam es im Frühjahr 1981 zu Unruhen; die sogenannten England Riots 1981 zeigten deutliche Rassenspannungen und die Folgen des Niedergangs und der Vernachlässigung der „innercities“ (vor allem von ethnischen Minderheiten bewohnte innerstädtische Viertel), insbesondere in London, Birmingham, Leeds und Bristol. Thatcher verurteilte die Ausbrüche von Gewalt und die Plünderungen und betonte im Kabinett die Notwendigkeit, die Polizei mit neuer Ausrüstung aufzurüsten. Gleichzeitig lehnte sie es ab, mehr Gelder für die Förderung der innerstädtischen Viertel bereitzustellen und äußerte, mehr Geld könne weder Vertrauen noch Harmonie zwischen den Rassen erkaufen. 

Im Sommer 1981 sah sich Thatcher im Kabinett einer „Revolte“ gegenüber, nachdem die Beliebtheit der Regierung und auch die von Thatcher selbst laut Umfragen an einem Tiefpunkt angekommen war und ihr Schatzkanzler Geoffrey Howe trotz der herrschenden Rezession erneut ein inflationshemmendes Budget vorgelegt hatte. Die Loyalität ihres Stellvertreters William Whitelaw und des Außenministers Lord Carrington bewahrte sie jedoch vor einem Sturz. Als Gegenreaktion bildete Thatcher nach dem Ende der parlamentarischen Sommerpause ihr Kabinett um: sie entließ Christopher Soames, Ian Gilmour und Mark Carlisle und Arbeitsminister Jim Prior musste aus seinem Ressort auf den Posten des Ministers für Nordirland wechseln. Alle waren Anhänger des One-Nation-Konservatismus, der sozialpolitischen Richtung der Tories, und wurden von der Presse als „wets“ betitelt – im Gegensatz zu den „dries“ Nigel Lawson, Norman Tebbit und Cecil Parkinson, die Thatchers wirtschaftspolitische Ideale teilten und nun auf Kabinettsposten rückten.
Ab dem 3. Quartal 1981 zeigte die Wirtschaft deutliche Anzeichen einer Erholung, die Arbeitslosigkeit blieb allerdings auf einem Stand von 3 Millionen, eine ungekannte Höhe seit der Weltwirtschaftskrise der 1930er Jahre. Skeptiker hielten der Regierung Thatchers zudem entgegen, dass die wirtschaftliche Erholung regional gesehen auf den Süden Englands beschränkt blieb, während die alten Industriezentren im Norden Englands, in Süd-Wales und Schottland dauerhaft geschädigt blieben. Zudem hatten nur bestimmte Sektoren wie die Finanzbranche und der Dienstleistungsektor profitiert, der Industrielle Sektor hatte dagegen keinen Anteil an der wirtschaftlichen Erholung. 

Der siegreiche Falklandkrieg 1982 gegen Argentinien brachte Thatcher, der noch ein Jahr zuvor kaum Chancen auf eine Wiederwahl eingeräumt worden waren, einen großen Popularitätsschub ein. Die Unterhauswahlen 1983 wurden der größte Erfolg der Conservative Party und gleichzeitig der einer Partei überhaupt seit den Wahlen von 1945. Die Tories profitierten dabei nicht nur vom radikal sozialistischen Kurs des Labour-Führers Michael Foot, der sich für eine unilaterale Abrüstung, für die Abschaffung des House of Lords, erhebliche Steuererhöhungen und weitere Verstaatlichungen großer Banken und Wirtschaftsbetriebe aussprach. Auch die neu gegründete Social Democratic Party, die in einer Allianz mit der Liberal Party 15 % der Stimmen errang, zersplitterte die Stimmen der Linken.

Nach ihrem Erfolg beförderte sie viele ihrer engsten Anhänger. So avancierten Nicholas Ridley, Cecil Parkinson und Leon Brittan zu Kabinettsmitgliedern. Nigel Lawson, der als einer der wenigen Thatcher intern regelmäßig widersprach, wurde Schatzkanzler und blieb bis zu seinem Rücktritt ein Schlüsselmitglied in ihrem Kabinett. Die letzten prominenten „wets“ – Jim Prior und Francis Pym – wurden dagegen bis 1984 aus dem Kabinett entfernt.
Am 12. Oktober 1984 verübte während des Parteitags der Konservativen in Brighton die IRA einen Bombenanschlag auf das Grand Hotel mit dem Ziel, Thatcher zu töten. Fünf Personen starben; Handels- und Industrieminister Norman Tebbit wurde verletzt, seine Frau erlitt eine Querschnittslähmung. Thatcher und ihr Mann blieben unverletzt. Sie hielt am nächsten Tag äußerlich unbeeindruckt die vorgesehene Rede, was zu ihrem "harten" Image beitrug und ihr Bewunderung einbrachte. Im folgenden Jahr unterzeichneten Thatcher und der irische Ministerpräsident Garret FitzGerald in Hillsborough Castle eine Vereinbarung, die erstmals der Irischen Regierung eine beratende Rolle im Nordirlandkonflikt einräumte und gleichzeitig bestätigte, dass der verfassungsrechtliche Status Nordirlands nicht ohne den Willen der nordirischen Bevölkerungsmehrheit verändert werden würde.

Im Februar 1985 verweigerte ihr die University of Oxford die Ehrendoktorwürde (mit der normalerweise jeder Premierminister ausgezeichnet wird) aus Protest gegen Kürzungen im Bildungsetat. 

Thatchers abschätziger Umgang mit Kabinettskollegen zeigte sich auch in der Westland-Affäre. Beim Streit um die Rettung des einzigen britischen Hubschrauberherstellers Westland Helicopters kam es zum Rücktritt von Verteidigungsminister Michael Heseltine, der danach von einem Zusammenbruch der gemeinschaftlichen Kabinettsverantwortung sprach. Heseltine hätte eine Kooperation mit einem europäischen Konsortium unter Führung der italienischen Agusta bevorzugt, während das (darin von Thatcher unterstützte) Management sich mit der Sikorsky Aircraft Corporation zusammentun wollte. Zurücktreten musste auch Thatchers Gefolgsmann Leon Brittan vom Posten des Industrieministers, nachdem bekannt geworden war, dass er ein kritisches offizielles Dossier, welches Heseltines Position unterminieren sollte, der Presse zugespielt hatte. Die Westland-Affäre fügte Thatcher schweren politischen Schaden zu, die zum ersten Mal seit 1982 politisch angreifbar geworden war und eine kritische Unterhausdebatte überstehen musste. Zudem attackierten die Medien Thatchers autoritären Regierungsstil, der in hartem Gegensatz zum Idealbild der kollektiven Verantwortung früherer Kabinette stand. Während Brittans politische Karriere endete, wurde der ambitionierte und flamboyante Heseltine zum Herausforderer in Wartestellung.

Im April 1986 erlebte Thatchers Regierung ihre einzige Abstimmungsniederlage im Unterhaus, als sie per eingebrachtem Gesetz Einzelhändlern Verkaufsoffene Sonntage erlauben wollte. Nicht nur die Opposition stimmte gegen das Gesetz, auch 72 christlich-konservative Hinterbänkler ihrer eigenen Partei brachten mit ihrem Votum das Gesetz zu Fall.

Bei der Unterhauswahl vom 11. Juni 1987 verteidigten die Konservativen erneut ihre komfortable Mehrheit und verloren nur einige Sitze. Als Ergebnis von Thatchers Reformen kam es auch bei den Unterhauswahlen zu einer zunehmenden Polarisierung; während die Tories im wohlhabenden Südosten Englands weitere Sitze hinzugewinnen konnten, mussten sie im strukturschwachen Norden Englands starke Verluste hinnehmen und verloren sogar die Hälfte ihrer Sitze in Schottland. Norman Tebbit, lange als möglicher Nachfolger Thatchers gehandelt, schied nach der Unterhauswahl aus privaten Gründen aus dem Kabinett aus.

In Thatchers dritter Amtszeit kam es zu einem beschleunigten Prozess der Privatisierung und viele größere Unternehmen wurden zugunsten einer niedrigeren Staatsquote privatisiert. In einem Interview mit dem Magazin "Woman's Own" im September 1987 prägte sie den Satz: „So etwas wie eine Gesellschaft gibt es nicht.“ Der Satz sorgte sofort weithin für Empörung; Thatcher wiederholte ihn, leicht abgewandelt, jedoch 1988 und appellierte erneut an die Eigenverantwortung der Menschen, anstatt Gesellschaft und Regierung die Schuld zu geben. Bereits 1985 hatte sie geäußert: „Die Gesellschaft, das ist niemand. Du bist selbst für dich verantwortlich.“

Im Januar 1988 trat ihr Deputy William Whitelaw aus Altersgründen zurück. Ihre Popularitätskurve begann zu sinken, als sie 1989 eine als ungerecht empfundene personenbezogene Steuer einführte, die "community charge", besser bekannt als "poll tax" („Kopfsteuer“). Dies führte zu heftiger Kritik und zu teils gewalttätigen Demonstrationen sogar in ausgesprochen konservativ geprägten Landesteilen. Besonders stark waren die Proteste zunächst in Schottland, wo die "poll tax" bereits 1988 probeweise eingeführt worden war.

Ihre zunehmend europafeindliche Rhetorik entfremdete Thatcher von Geoffrey Howe und Nigel Lawson, den verbliebenen beiden Schlüsselmitgliedern in ihrem Kabinett. Beide wollten einen britischen Beitritt zum Europäischen Währungssystem (EWS) erzwingen. 
Thatcher lehnte, darin von ihrem Wirtschaftsberater Sir Alan Walters bestärkt, einen Beitritt Großbritanniens zum Europäischen Währungssystem (EWS) strikt ab. Im Juli 1989 nahm sie deshalb eine weitere Kabinettsumbildung vor und berief John Major zum Außenminister anstelle von Geoffrey Howe, den sie stattdessen Leader of the House of Commons und Lord President of the Council machte.
Walters und Finanzminister Nigel Lawson stritten sich im Jahresverlauf 1989 weiter über den britischen Beitritt zum EWS; Lawson forderte Thatcher schließlich unter Androhung seines Rücktritts auf, Walters zu entlassen. Thatcher, die sich zunehmend auf ihre eigenen Berater stützte, weigerte sich Walters zu entlassen und Lawson reichte seinen Rücktritt ein. Auch Walters, dessen Position unhaltbar geworden war, demissionierte wenige Tage später. Thatcher sah sich erneut gezwungen, ihr Kabinett umzubilden und schob Major nun ins Schatzamt, während Douglas Hurd Außenminister wurde. Am 7. Oktober 1990 schloss Großbritannien sich dem EWS an und führte damit für das Britische Pfund einen engen Wechselkurskorridor (± 2,25 Prozent) zu den übrigen EWS-Mitgliedswährungen ein.
Dies erwies sich knapp zwei Jahre später als ein Fehler: Nach dem Schwarzen Mittwoch war Großbritannien gezwungen, aus dem EWS wieder auszutreten und das Britische Pfund verlor mehr als 25 % an Wert gegenüber dem amerikanischen Dollar.

Im Juli 1990 sah sich auch der Thatcher-Loyalist Nicholas Ridley gegen den erfolglosen Widerstand Thatchers von den Hinterbänklern des 1922-Komitees zum Rücktritt gezwungen, nachdem er dem Spectator ein kontroverses Interview gegeben hatte, in dem er die Europäische Wirtschafts- und Währungsunion als eine Masche Deutschlands bezeichnete, um die Herrschaft über Europa zu erringen. Mitte November 1990 wurde Thatcher als Parteiführerin der Tories von Michael Heseltine herausgefordert, nachdem der kurz zuvor von seinen Ämtern zurückgetretene Geoffrey Howe ihren Kurs offen kritisiert und seine Parteifreunde aufgefordert hatte, ihre Konsequenzen zu ziehen. Viele konservative Abgeordnete befürchteten, mit Thatcher an der Spitze die nächste Unterhauswahl (April 1992) zu verlieren. Besonders die Kopfsteuer hatte sie bei vielen Wählern unbeliebt gemacht; ihre Beliebheitswerte waren kontinuierlich hinter ihrer eigenen Partei zurückgeblieben. Daneben wurden die Steuersenkungen im Staatshaushalt 1988 kritisiert.

Als Thatcher im ersten Wahlgang in Abwesenheit (sie nahm am 19. November 1990 am KSZE-Gipfel in Paris teil) das notwendige Quorum (mindestens 15 Prozent mehr als Heseltine) zur Bestätigung in der Parteiführung knapp verfehlte, erklärte sie zunächst, weiterkämpfen zu wollen und zeigte sich überzeugt, im zweiten Wahlgang zu gewinnen. Eine Befragung aller Kabinettsmitglieder in Einzelgesprächen ergab jedoch eine mangelnde Unterstützung innerhalb des Kabinetts. Am 28. November 1990 erklärte sie ihren Rücktritt. Thatchers Amtszeit von elf Jahren und 209 Tagen als Premierministerin war die längste seit Lord Salisbury und die längste in einem Zug seit Lord Liverpool.

Fest entschlossen, Heseltine als ihren Nachfolger zu verhindern, setzte sie sich für den als Kompromisskandidat auftretenden John Major ein, der ihre Nachfolge als Parteiführer der Tories und Premierminister Großbritanniens antrat. Mit ihrem plötzlichen Sturz konnte sich Thatcher zeitlebens nicht abfinden; verbittert betrachtete sie ihren Sturz rückblickend als einen Verrat ihrer Kabinettskollegen.

Die von Thatcher vertretene Wirtschaftspolitik (Thatcherismus), unterstrichen durch die von ihr immer wieder verwendete Formulierung , hatte im Hinblick auf Inflationsbekämpfung und Deregulierung zahlreiche Gemeinsamkeiten mit der von Ronald Reagan (Reaganomics) in den USA, unterschied sich aber auch in mancher Hinsicht. Weder erhöhte sie wie Reagan exzessiv die Staatsausgaben noch senkte sie zumindest bis 1987 die Steuern wesentlich.

Vor Thatchers Amtsantritt war Anfang 1977 der britische Schatzkanzler Denis Healey gezwungen gewesen, zur Vermeidung eines finanziellen Ruins seines Landes harte wirtschaftspolitische Einschränkungen anzukündigen. Die darauffolgenden Streiks wie eine parteiinterne Kontroverse legten im Winter of Discontent Land wie Regierung über Monate lahm und führten mit zum Wahlsieg Thatchers.

In Thatchers erster Legislaturperiode stand dennoch die Inflationsbekämpfung im Vordergrund (Monetarismus). Thatcher sah sich in den ersten Jahren einer andauernden Rezession gegenüber, die von stark ansteigenden Arbeitslosenzahlen und von hoher Inflation geprägt war. Thatcher und ihr Schatzkanzler Geoffrey Howe senkten direkte Steuern wie die Einkommenssteuer ab, erhöhten indirekte Steuern und nahmen Zinserhöhungen vor, um die Inflation zu bekämpfen. Howe senkte in seinem ersten Budget die Standardhöhe der Einkommenssteuer von 33 auf 30 Prozent und den Spitzensatz von 83 auf 60 Prozent herab. Die öffentlichen Ausgaben wurden um insgesamt 3 Prozent verringert. Besonders betroffen von den Kürzungen waren der Bildungsetat und der Wohnungsbau.

In ihrer zweiten Legislaturperiode ging es der Regierung vor allem darum, den Einfluss des Staates und der Gewerkschaften auf die Wirtschaft zurückzudrängen. Entgegen der britischen Tradition, dass die Regierung und die Verwaltung vor Entscheidungen die Gewerkschaften zu konsultieren pflegten, wenn diese sich auf die Arbeitswelt und die Beschäftigten auswirkten, ließ Thatcher die Gewerkschaften von allen Beratungen ausschließen. 

Mit der Privatisierung vieler Staatsunternehmen (etwa der British Telecom, British Petroleum (BP), British Airways) und lokaler Versorgungsunternehmen (Trinkwasserversorgung, Elektrizitätsunternehmen) fand die seit Ende des Zweiten Weltkriegs bestehende Mischwirtschaft ein Ende. Der Einfluss des Staates und die Staatsquote wurden deutlich reduziert. Am Ende der Ära Thatcher waren 40 Firmen mit insgesamt 600.000 Angestellten privatisiert worden. Zudem wurde in großem Umfang Wohnraum privatisiert; war Großbritannien 1979 noch der größte Grundbesitzer Westeuropas gewesen, wurden in den 1980ern mehr als eine Million Sozialwohnungen (oft zu reduzierten Preisen an die Bewohner) verkauft. Als Resultat stieg die Eigennutzung von Immobilien binnen 10 Jahren von 55 Prozent auf 67 Prozent, während das Schatzamt einen Reinerlös von 28 Milliarden Pfund erzielte. Durch die erzielten Erlöse aus Privatisierungen von Firmen und Wohnraum war die Regierung Thatcher in der Lage, die Staatsschulden um 12,5 % zu verringern. Betrug die Staatsverschuldung Großbritanniens 1980 noch 54,1 % des Bruttoinlandsprodukts, so sank diese bis 1990 auf 34,7 %.

Zur lang erwarteten Kraftprobe zwischen Regierung und Gewerkschaften geriet 1984/85 der Streik der britischen Bergarbeiter, der ein Jahr lang dauerte. Da der radikalsozialistische Gewerkschaftsführer Arthur Scargill sich innerhalb der Gewerkschaft National Union of Mineworkers (NUM) in früheren Jahren nie mit seinen Streikforderungen hatte durchsetzen können, initiierte er stattdessen lokale Streiks in den Regionen mit höherem Organisationsgrad und Streikbereitschaft, wie Yorkshire und Schottland, wo er auf viele Unterstützer zählen konnte. Die Bergarbeiter in Nottinghamshire und Süd-Wales beteiligten sich dagegen nicht am Streik. Ebenso stellten sich andere Gewerkschaften wie die der Dock- und Stahlarbeiter gegen Scargill. Scargill setzte durch, dass Streikgelder nur an Bergarbeiter ausgezahlt würden, die sich – erfolglos – an gewaltsamen Ausschreitungen gegen arbeitswillige Bergarbeiter beteiligten, was den Streikenden weitere Sympathien im Land entzog.

Thatchers Regierung profitierte im Streikverlauf einerseits von der bereits lange zuvor betriebenen Kohle-Vorratsbildung. Zum anderen zeigten sich nun auch die Auswirkungen der britischen Nordseeöl-Förderung, welche die Abhängigkeit von der Kohleförderung weiter gemindert hatte. Die Streikenden hatte bald ihre Streikkasse aufgebraucht und konnten dann keine Streikgelder mehr erhalten. In der Folge kehrten die meisten zu ihrer Arbeit zurück. Am 3. März 1985 stimmte eine Delegiertenkonferenz der NUM schließlich für das Ende des Arbeitskampfes. Durch den Erfolg Thatchers und die Privatisierung vieler Unternehmen sowie die Zerstrittenheit der Gewerkschaften sank deren Einfluss dauerhaft. Der Weg für weitere Reformen wie die Abschaffung des Closed Shop (gesetzlich vorgeschriebene Pflichtmitgliedschaft in Gewerkschaften für Arbeiter zahlreicher Unternehmen) und das Verbot der sogenannten "flying pickets" (Streikposten, die nicht dem bestreikten Betrieb angehören) war frei. In den folgenden Jahren nahmen die Mitgliederzahlen der Gewerkschaften erheblich ab. Thatchers teils konfrontative Rhetorik – so bezeichnete sie im Juli 1984 die Bergarbeiter als „den Feind im Inneren“ – sorgte jedoch für heftigen Widerspruch auch innerhalb des eigenen Lagers und einem zwischenzeitlichen Abfall ihrer Popularität in der Bevölkerung.

Am 27. Oktober 1986 wurde im "Financial Services Act 1986" der Londoner Finanzmarkt dereguliert, der Unterschied zwischen Market-Makern und Börsenmaklern aufgehoben, der Ausschluss von Ausländern von der Stock-Exchange-Mitgliedschaft aufgehoben und die Mitgliedschaft von Unternehmen erlaubt. Nachfolgend als Big Bang-Event bekanntgeworden, führte dies zu einem allgemeinen Boom der Finanzindustrie, stärkte den zwischenzeitlich hinter den New Yorker Finanzmarkt deutlich zurückgefallenen Londoner Finanzmarkt erheblich und machte ihn erneut zum bedeutendsten Finanzplatz der Welt.

Ausdrücklich ausgenommen von tiefgreifenden Reformen, die den Nachkriegskonsensus in Frage gestellt bzw. abgewickelt hätten, blieb dagegen der National Health Service (NHS), zu dem Thatcher 1982 nachdrücklich erklärte: „Der NHS ist in unseren Händen sicher.“ Thatcher lehnte jede tiefgreifende Reformierung des NHS in Richtung einer Privatisierung unter dem Hinweis ab, es gäbe dafür keine Anhängerschaft. In Wahlkampfauftritten 1987 führte sie regelmäßig an, dass ihre Regierung 1986 mit 15 Milliarden Pfund fast doppelt so viel Geld für den Gesundheitssektor ausgegeben habe wie die letzte Labourregierung mit nur 8 Milliarden Pfund.

Im Jahr 1988 nahm Schatzkanzler Lawson eine abschließende Rationalisierung der Steuerstruktur vor, indem er nun eine aus zwei Steuersätzen bestehende Einkommenssteuer (25 % Standardrate und 40 % Toprate) einführte. Direkte Steuern wurden von Lawson systematisch abgesenkt, als Anreiz für unternehmerisches Handeln. Dagegen wurden indirekte Steuern wie die Mehrwertsteuer weiter angehoben. Familienbeihilfen, Wohngeld und Arbeitslosenunterstützung wurden gekürzt. Dies verstärkte den Trend zu einer größeren Ungleichheit in der Gesellschaft.

Thatchers erste außenpolitische Handlung war das Lancaster-House-Abkommen, durch das der rhodesische Kolonialkrieg zu einem Ende kam und die Schaffung des unabhängigen Staates Simbabwe anstelle des dysfunktionalen Rhodesiens ermöglicht wurde. Während es ihr gleich zu Beginn ihrer Amtszeit gelang, die „special relationship“ mit den USA wiederzubeleben, sah sie sich innerhalb der Europäischen Gemeinschaft vom bestimmenden deutsch-französischen Tandem Valéry Giscard d’Estaing und Helmut Schmidt isoliert. Sie lehnte Sanktionen gegen das Apartheidsregime Südafrikas durch den Commonwealth und die Europäische Gemeinschaft ab und setzte sich für weitere Wirtschaftsbeziehungen mit Südafrika ein, mit dem Großbritannien aufgrund seiner kolonialen Vergangenheit wirtschaftlich eng verflochten war. Südafrikas Präsident Pieter Willem Botha bezeichnete sie als Freund und lud ihn gegen erhebliche Proteste 1984 nach Großbritannien ein, während sie den African National Congress als eine Terrororganisation diffamierte.

Die kurz nach ihrem Amtsantritt erfolgte Sowjetische Intervention in Afghanistan verurteilte Thatcher scharf und erklärte den Bankrott der Entspannungspolitik. Sie versuchte, weitgehend erfolglos, die britischen Athleten zum Boykott der Olympische Sommerspiele 1980 in Moskau zu überreden. Dagegen wandte sie sich, mit Rücksicht auf Großbritanniens schwache ökonomische Situation, gegen Wirtschaftssanktionen der USA unter Präsident Jimmy Carter. Thatcher unterstützte mit Nachdruck den NATO-Doppelbeschluss und die zugehörigen Stationierungen von Mittelstreckenraketen auf britischen Territorium, die den bestehenden Vorteil der sowjetischen SS-20 Raketen ausgleichen sollten. 

Die Friedensbewegung und deren Wunsch nach bedingungsloser unilateraler Abrüstung verspottete sie als reines Wunschdenken. Im Unterhaus verkündete sie im Juni 1980: „Jedwede Politik der unilateralen Abrüstung ist eine Politik der unilateralen Kapitulation.“ Im Gegenteil zeigte sie sich über die sowjetische Aufrüstung besorgt und warb in Gesprächen mit Bundeskanzler Helmut Schmidt und Carter für eine Aufrüstung der NATO-Mitglieder.

Ihre Regierung unterstützte die kambodschanische Regierung der Roten Khmer bei ihrem Bestreben, in der UN zu bleiben. Im September 1982 besuchte sie die Volksrepublik China, um mit dem maßgebenden KPCh-Funktionär Deng Xiaoping Verhandlungen über den weiteren Umgang mit Hongkong zu beginnen. Sie setzte sich vergeblich für eine Weiterführung der britischen Verwaltung ein. 1984 unterzeichnete sie schließlich einen Vertrag mit China über die Rückgabe der Kronkolonie Hongkong bis 1999.

Ihrem Außenministerium misstrauend, holte sich Thatcher in außenpolitischen Fragen – besonders nach dem Falklandkrieg – vielfach Rat von unabhängigen Experten aus dem akademischen Bereich; so konsultierte sie unter anderem Hugh Thomas, Robert Conquest und Timothy Garton Ash und installierte Charles Powell als ihren Privatsekretär für außenpolitische Fragen.

Neben den Gemeinsamkeiten in der Wirtschaftspolitik teilte Thatcher mit US-Präsident Ronald Reagan ein tiefes Misstrauen gegenüber dem Kommunismus. Beide lehnten die Entspannungspolitik ab und suchten keine friedliche Koexistenz, sondern den Kalten Krieg zu gewinnen. Ebenso wie Reagan gab Thatcher auch einer harten Rhetorik gegenüber der Sowjetunion den Vorzug. Thatcher hielt am NATO-Doppelbeschluss fest, der vorsah, dass ein Drittel aller Cruise-Missiles auf britischem Boden stationiert werden sollten. Dies stärkte ihre Verbindung zu US-Präsident Ronald Reagan, führte allerdings auch zu heftigen Protesten und Demonstrationen der Friedensbewegung. Die Vorteile der engen britischen Kooperation mit den USA zeigten sich bei der Erneuerung des britischen Nuklearwaffenarsenals, welches seit den 1960er Jahren und der Vereinbarung von Nassau auf den flottengestützten Polarisraketen basiert hatte. Mit dem Tridentprogramm stärkte Thatcher die Zusammenarbeit beider Länder im Rüstungssektor. Der Kauf und die Kooperation mit den USA verdreifachten das britische Atomarsenal. Es war mit damaligen Kosten von £12 Milliarden (1996–1997) eines der teuersten Regierungsprogramme der Regierung Thatcher überhaupt. Dazu gestattete Großbritannien den USA die Nutzung der Insel Diego Garcia im Indischen Ozean für militärische Zwecke.

Dagegen wandte Thatcher sich in Einvernehmen mit ihren europäischen Partnern gegen die Wirtschaftssanktionen, mit denen Reagan die Sowjetunion ökonomisch ruinieren wollte.
Obwohl Reagan ideologisch verbunden, zeigte sie sich entsetzt über die 1983 durchgeführte US-Invasion im Commonwealth-Mitglied Grenada. Da Reagan ihr kurz vorher noch versichert hatte, eine solche Invasion würde nicht stattfinden, war das Vertrauen Thatchers zu Reagan zunächst gestört.

Reagans SDI-Programm stand Thatcher ebenfalls distanziert gegenüber; einerseits die Vorteile sehend, war sie andererseits eine ausgesprochene Befürworterin der atomaren Abschreckung. In einer umjubelten Rede vor dem amerikanischen Kongress im Februar 1985 sprach sie sich für das Prinzip der atomaren Abschreckung aus und wandte ein, Atomwaffen hätten auch konventionelle Kriege unwahrscheinlicher gemacht.

In anderen außenpolitischen Fragen verfolgte Thatcher eine gemeinsame Linie mit den USA, sowohl bei G7-Gipfeln, bei den gemeinsamen Forderungen nach erhöhten Verteidigungsausgaben innerhalb der NATO, sowie in der Haltung zum libyschen Machthaber Muammar al-Gaddafi. Thatcher stellte den USA 1986 auch britische Luftstützpunkte zur Verfügung, als diese Tripolis und Bengasi bombardierten.

Im Februar 1984 nahm Thatcher an der Beerdigung von KPdSU-Generalsekretär Juri Andropow teil. Während sie sich vom designierten Nachfolger Konstantin Tschernenko unbeeindruckt zeigte, gewann sie vom Politbüro-Mitglied Michail Gorbatschow einen positiven ersten Eindruck und lud ihn sofort nach London ein. Nach Gorbatschows Aufstieg zum Generalsekretär fungierte Thatcher mehr als einmal als eine informelle Unterhändlerin zwischen ihm und Reagan.

Thatcher verurteilte bei Beginn der irakischen Invasion Kuwaits sofort Saddam Husseins Aggression und ermunterte den neuen Präsidenten George H. W. Bush zu einem militärischen Eingreifen.

Im Gegensatz zur Labour-Regierung wie auch zur US-Regierung unter Jimmy Carter, die Augusto Pinochets Militärdiktatur in Chile scharf verurteilten und verschiedene Sanktionen und Embargos, unter anderen gegen Waffenexporte nach Chile, erließen, hob die Regierung Thatcher bereits im Juni 1979 die Beschränkungen der betreffenden Exportgarantien des staatlichen Export Credit Guarantee Department auf. Margaret Thatcher begründete diese Schritte offiziell mit der Behauptung, die Problematik der Menschenrechtsverletzungen in Chile habe sich verbessert. Die UN, Amnesty International und andere Organisationen vertraten allerdings eine gegenteilige Einschätzung. Großbritannien hatte sich Chile zuvor in dessen Konflikt mit Argentinien um den Beagle-Kanal angenähert. Die britische Vermittlungsrolle beim Schiedsgericht im Beagle-Konflikt hatte Chiles Regierung unter Salvador Allende angenommen, Argentinien jedoch nicht (vgl. Operation Soberanía).

Später lobte Thatcher die enge Kooperation mit Chile, die sich auch während des Falklandkrieges ausgezahlt habe. Sie traf sich mehrmals mit dem ehemaligen Diktator Augusto Pinochet, im Besonderen, als dieser in Großbritannien von 1998 bis 2000 wegen Auslieferungsanträgen mehrerer europäischer Länder, mit denen Auslieferungsabkommen bestanden, aufgrund von Anklagen wegen Völkermord, Staatsterrorismus und Folter inhaftiert wurde. Thatcher nutzte ihren erheblichen politischen Einfluss zur Verhinderung einer Auslieferung sowie für eine Aufhebung der Haft in einer politischen Kampagne, in der sie Pinochet als „politischen Gefangenen“ darstellte „dessen Rechte verletzt würden.“ Dies führte auch in Großbritannien selbst zu erheblichen Kontroversen.

Am 2. April 1982 befahl die argentinische Junta die Invasion und Besetzung der britisch bevölkerten Falklandinseln und Südgeorgiens. In der Folge kam es zum Falklandkrieg. Außenminister Carrington übernahm die Verantwortung für frühere Fehler im Außenministerium und trat – gegen den Widerstand Thatchers, die ihn zum Bleiben zu überreden versuchte – zurück, da er aus prinzipiellen Gründen und einem Loyalitätsgefühl für Thatchers Regierung heraus meinte, jemand müsse der Öffentlichkeit und dem aufgebrachten Unterhaus als Sündenbock für den überraschenden Angriff Argentiniens dienen. Thatcher berief Francis Pym an seiner Stelle. 

Auf den Rat des früheren Premiers Harold Macmillan hin richtete Thatcher sofort ein kleines, täglich konferierendes Kriegskabinett ein und schloss – eingedenk des britischen Debakels in der Sueskrise – den Schatzkanzler Geoffrey Howe von diesem aus. Nachdem alle Vermittlungsversuche (vor allem von Seiten der USA) gescheitert waren, kam es ab Mitte April zur Rückeroberung der besetzten Gebiete durch eine britische Task Force. Der Sieg im Falklandkrieg brachte Thatcher einen enormen Popularitätsschub. In der Folge rief sie für den 9. Juni 1983 Unterhauswahlen aus und konnte ihren Popularitätszuwachs in einen Wahlsieg ummünzen, wobei sie auch von der Spaltung der Labour Party profitierte.

Unter dem Motto „I want my money back“ erreichte sie 1984 den bis heute gültigen Britenrabatt auf Großbritanniens Beitragszahlungen an die damalige EG. Dies veranlasste den Bundeskanzler Helmut Kohl zu dem Satz, er fürchte Margaret Thatcher „wie der Teufel das Weihwasser“.

Thatcher war eine enge Kooperation der europäischen Staaten zwar wichtig, allerdings warnte sie stets vor einem europäischen Superstaat. Die europäische Einigkeit sah sie vor allem als wichtig unter den Bedingungen des Kalten Krieges an. Insbesondere zu EG-Kommissionspräsident Jacques Delors hatte sie ein schwieriges Verhältnis. Während die Mehrheit der europäischen Partner unter Führung Delors versuchte, die Integration der EG voranzubringen, sah Thatcher in der EG immer nur eine Wirtschaftsgemeinschaft. Bei der Durchsetzung des Delors-Pakets, welches eine Reform der Agrarpolitik, Schaffung eines Finanzsystems und den Ausbau der Strukturfonds für ärmere Mitgliedsstaaten vorsah, arbeiteten beide noch eng zusammen. Delors und Thatcher setzten sich auch für mehr Haushaltsdisziplin und die Eindämmung der Agrarüberschüsse ein.

Die erste große Auseinandersetzung zwischen der Premierministerin und dem Kommissionspräsidenten wurde ausgelöst, als Delors bei einem Besuch in Großbritannien sagte, dass 80 % der wirtschaftlichen und sozialen Entscheidungen in der EG innerhalb von zehn Jahren auf europäischer Ebene geregelt werden würden. Daraufhin hielt Thatcher am 20. September 1988 eine vielbeachtete Rede vor dem Europa-Kolleg in Brügge. Darin legte sie ihre Forderung nach einer auf Wirtschaft und Handelsbeziehungen ausgelegten Gemeinschaft dar und betonte, dass sie kein Interesse an einer stärkeren politischen Integration Europas habe – dieses Vorhaben nannte Thatcher „remodelling of Europe“. Thatcher führte aus, ihre Regierung habe nicht die Rolle des Staates in Großbritannien zurückgefahren, um im Gegenzug einen europäischen Superstaat zu akzeptieren, der von Brüssel aus seine Mitgliedsstaaten dominiere. 
Auch der Delors-Bericht zur Europäischen Wirtschafts- und Währungsunion (EWU) wurde von Thatcher strikt abgelehnt; sie wollte unter allen Umständen am britischen Pfund festhalten.

Während sie anfangs vom CDU-Politiker Helmut Kohl einen äußerst positiven Eindruck hatte und die CDU als deutsches Pendant der britischen Konservativen betrachtete, stand sie ihm in späteren Jahren eher feindselig gegenüber. Sie lehnte sowohl Kohls Enthusiasmus für die europäische als auch für die deutsche Einigung strikt ab. Im Prozess der deutschen Wiedervereinigung 1989/90 reagierte sie zunächst mit Befürchtungen und ablehnend. Thatcher sah die Gefahr eines Deutschlands, welches Profit aus dem Zusammenbruch des Ostblocks ziehen und Europa als Hegemon dominieren würde. Gegenüber Präsident Bush betonte sie, Deutschlands Schicksal sei nicht nur eine Frage der Selbstbestimmung, sondern hätte weit größere Implikationen. So sei das Schicksal Gorbatschows, des Warschauer Pakts und Osteuropas eng mit den deutschen Frage verknüpft. Gemeinsam mit François Mitterrand suchte sie nach Wegen, die Entwicklungen aufzuhalten. Im März 1990 ließ sie auf ihrem Landsitz eine Tagung mit Deutschland-Experten durchführen. Die Veröffentlichung eines Memorandums über diese Tagung, die ihre auch durch den deutschen Nationalsozialismus geprägten Ansichten über schlechte Eigenschaften im Nationalcharakter der Deutschen offenbarten, löste im Sommer 1990 die Chequers-Affäre aus. Sie bestand schließlich, nach Rat von Fritz Stern, auf der Anerkennung der Nachkriegsgrenzen durch Deutschland, was schließlich im Zwei-plus-Vier-Vertrag festgelegt wurde. Gegenüber Bundespräsident Richard von Weizsäcker erklärte sie, ihr Deutschlandbild habe sich im Wesentlichen bis 1942 gebildet und seitdem wenig geändert.

In ihrer Regierungszeit befasste sich Thatcher bereits früh mit Themen des Umweltschutzes und der Globalen Erwärmung. Während sie auf der einen Seite Organisationen wie Greenpeace in Interviews als naiv und rückwartsgewandt verspottete, setzte sie sich andererseits für den Umweltschutz ein und brachte das Thema ins Bewusstsein der britischen Öffentlichkeit. Im Juni 1984 nutzte sie ihren Vorsitz beim G7-Gipfel in London, um eine Verpflichtung zu mehr Forschung zu erreichen, die die Umweltverschmutzung und insbesondere das Problem des Sauren Regens angehen sollten. 

Den Treibhauseffekt anerkennend, sah sie Kohle und andere fossile Brennstoffe als „dreckige“ Energieträger an und befürwortete stattdessen die Nuklearenergie. Die Risiken und Probleme der Nuklearenergie (wie radioaktive Abfälle) tat sie dagegen ab und erklärte: „Die Probleme, die die Wissenschaft geschaffen hat, können durch die Wissenschaft gelöst werden.“ Sie zeigte sich zuversichtlich, dass binnen der nächsten 50 Jahre eine Lösung für das Problem der Atommülllagerung gefunden werden könne. 

Der Entwicklung erneuerbarer Energien schenkte sie wenig Beachtung. Für das Problem der kontinuierlich wachsenden Müllmenge machte sie eine individuelle Verantwortung aus und sagte der Londoner Times in einem Interview, jeder Einzelne habe eine Verantwortung für die Umwelt. Im September 1988 warnte sie in einer Rede vor der Royal Society vor den Gefahren des Ozonlochs, ein Thema, das sie in der Folge auch bei einer Rede vor der Generalversammlung der Vereinten Nationen aufgriff. Zudem setzte sie sich für den verringerten Ausstoß von Kohlenstoffdioxid in die Atmosphäre ein, sah sich in dieser Frage jedoch der Opposition der USA gegenüber. Wiederholt setzte sie sich bei der Bush-Regierung für eine internationale Vereinbarung ein, die Umweltfragen auf einer globalen Ebene diskutieren sollte.

Margaret Thatcher wurde 1970 in den Privy Council der Königin berufen. Seit 1983 Mitglied der Royal Society (FRS), wurde sie im Juni 1990 in den Order of Merit aufgenommen. 1995 erhielt sie den höchsten Orden Englands, den Hosenbandorden. Weiter war sie Ehren- und einziges weibliches Vollmitglied des renommierten Carlton Clubs. Seit Februar 2007 befindet sich im Foyer des britischen Parlaments, dem Palace of Westminster, eine vom Bildhauer Antony Dufort geschaffene überlebensgroße Bronzestatue Thatchers.

Auf den Falkland-Inseln wird der 10. Januar als Thatchertag begangen.

Die American Philosophical Society verlieh ihr 1987 ihre Benjamin Franklin Medal for Distinguished Public Service. 1991 überreichte US-Präsident George H. W. Bush Thatcher die Freiheitsmedaille („The Presidential Medal of Freedom“), die höchste zivile Auszeichnung in den USA. Die Stadt Danzig verlieh Thatcher 2000 die Ehrenbürgerwürde.

Kurz nach ihrem Rücktritt erwarben Margaret und ihr Ehemann Denis Thatcher ein Stadthaus am Chester Square im Londoner Stadtteil Belgravia.
Thatcher, immer eine ruhelose Workaholic mit wenig Interessen außerhalb der Politik, fand sich schnell zunehmend desillusioniert über ihren Nachfolger John Major.

Bei zwei Reden in den USA warnte sie im Juni 1991, dass die Versuche, eine einheitliche EG-Außenpolitik zu etablieren, die NATO unterminieren und schwächen würde. Die in ihren Augen protektionistische Handelspolitik der EG verurteilte sie und warb stattdessen erneut für eine Freihandelszone, die die nordamerikanische NAFTA, die EG sowie Osteuropa umfassen solle. Im Herbst 1991 hielt sie eine Rede über den Zusammenbruch Jugoslawiens, in der sie sich gegen die Passivität des Westens wandte, der zusehe, während die jugoslawische Armee Kroatien zerstöre und kroatische Zivilisten ermorde. In den Medien kritisierte sie nun wiederholt, teils verklausiert, teils offen, die Arbeit ihres Nachfolgers als zu pro-europäisch. Auch den 1992 unterzeichneten Vertrag von Maastricht lehnte sie ab. Für Major erwies sich Thatchers wiederholte Kritik als schwere Hypothek; seine Regierung wurde in der Folge von den konstanten Streitigkeiten über die Europa-Frage stark in Mitleidenschaft gezogen.

Bei den Unterhauswahlen 1992 unterstützte sie die Regierung ihres Nachfolgers noch mit mehreren Wahlkampfauftritten; sie selbst verzichtete darauf, zur Wiederwahl für das Unterhaus anzutreten. Daraufhin wurde sie, wie bei pensionierten Premierministern üblich, im gleichen Jahr nobilitiert. Als "Life Peer" („Peer auf Lebenszeit“) zog sie am 30. Juni als "Baroness Thatcher of Kesteven in the County of Lincolnshire" ins House of Lords („Oberhaus“) ein. Denis Thatcher war im Jahr zuvor der erbliche Titel "Baronet of Scotney in the County of Kent" verliehen worden (womit seine Ehefrau bereits die Höflichkeitsanrede „Lady“ führte).

Thatcher schrieb ab 1992 ihre Memoiren und veröffentlichte diese 1993 und 1995 in zwei Bänden; zudem reiste sie für verschiedene britische Firmen als inoffizielle Botschafterin und Lobbyistin durch die Welt. Nach der Wahlniederlage der Tories 1997 unterstützte sie William Hague bei seiner Kandidatur für den Vorsitz der Partei.

2000 und 2001 erlitt Lady Thatcher mehrere Schlaganfälle, die auch zu dauerhaften Gedächtnisstörungen führten. Im März 2002 erklärte sie daraufhin ihren Rücktritt aus dem öffentlichen Leben. 2003 wurde ihr letztes Buch veröffentlicht, "Statecraft: Strategies for a Changing World", in dem sie sich zu aktuellen Themen der Weltpolitik äußerte. Erneut hatte sie das Buch, ebenso wie ihre Memoiren, wieder mit Hilfe ihres Redenschreibers Robin Harris verfasst. Im Juni 2003 erlag Denis Thatcher einem Krebsleiden.

Nach dem Tod von Ronald Reagan reiste sie 2004 nochmals in die USA, um am 11. Juni in Washington an der Trauerfeier teilzunehmen. Sie war eine von vier Personen, die Reagan persönlich darum gebeten hatte, anlässlich seiner Beerdigung zu sprechen. Wegen ihres schlechten Gesundheitszustandes war die Grabrede geraume Zeit vorher aufgezeichnet worden und wurde bei der Trauerfeier über Bildschirme eingespielt.

Mitte 2008 wurde bekannt, dass Lady Thatcher unter fortgeschrittener Demenz litt. Ihre Tochter Carol Thatcher thematisierte die Erkrankung ihrer Mutter 2008 in einem Buch. In der britischen Presse wurde 2008 die Frage, ob Lady Thatcher nach ihrem Ableben ein Staatsbegräbnis erhalten solle, kontrovers diskutiert. Am 19. Juli 2010 wohnte sie zum letzten Mal einer Sitzung des Oberhauses bei. Im Dezember 2012 zog sie in eine Suite im Londoner Hotel Ritz. Dort verstarb sie am 8. April 2013 an den Folgen eines weiteren Schlaganfalls.

Anlässlich ihres Todes im April 2013 erschienen zahlreiche Nachrufe und Betrachtungen zu ihrer Regierungszeit.

Sowohl der amtierende Premierminister David Cameron als auch seine überlebenden Vorgänger spendeten Margaret Thatcher höchstes Lob. Im Allgemeinen äußerten sich auch politische Gegner Thatchers respektvoll über sie und ihr Wirken. Der Vorsitzende der Labour-Party, Ed Miliband, verurteilte jeden Jubel über Thatchers Tod und würdigte sie als „riesige Figur in der britischen Politik und auf der Weltbühne“. Der ehemalige Parteichef der Liberaldemokraten Paddy Ashdown nannte Thatcher „zweifellos den größten Premierminister unserer Zeit“.
Barack Obama, Präsident der USA, bezeichnete die Verstorbene als „eine der großen Verfechterinnen der Freiheit und wahre Freundin Amerikas“.

In Brixton, Glasgow, Leeds, Cardiff und den alten Bergbaustädten feierten und tanzten anlässlich von Thatchers Tod etwa 200 – meist junge – Menschen auf offener Straße, wobei es zu Zusammenstößen mit der Polizei und mehreren Verhaftungen kam. Nach einer Kampagne in sozialen Netzwerken wurde ab dem 8. April 2013 das 1939 entstandene Lied "Ding-Dong! The Witch Is Dead" massenhaft für Klingeltöne und iTunes abgerufen. Die rasante Verbreitung wird auf eine länger vorbereitete Social-Media-Kampagne zurückgeführt. Kurze Zeit später gelang es Anhängern Thatchers, das 1979 entstandene "Im in love with Margaret Thatcher" der Punkband The Notsensibles ebenso über Social Media in die UK Singles Chart zu positionieren.

Die am 17. April 2013 abgehaltene Trauerfeier stellte kein Staatsbegräbnis im streng protokollarischen Sinn dar, kostete den britischen Staat aber dennoch 3,2 Millionen Pfund. Nach einem Trauerzug durch London, bei dem u. a. 700 Soldaten aus beim Falkland-Krieg aktiven Regimentern das Geleit gaben, fand ein Gottesdienst in der St Paul’s Cathedral mit mehr als 2000 Gästen statt. Es waren 11 Premierminister und 17 Außenminister angereist. Aus den USA waren die früheren Außenminister Henry Kissinger, George Shultz und James Baker vertreten, ebenso wie der frühere US-Vizepräsident Dick Cheney. Deutschland wurde von Außenminister Guido Westerwelle repräsentiert. Der Leichnam Thatchers wurde danach im engsten Familienkreis im Mortlake-Krematorium in Kew eingeäschert. Die Urne wurde neben der ihres Mannes Denis auf dem Gelände des Royal Hospital Chelsea in London beigesetzt. Während der Beisetzung war die Königin anwesend und das Viertelsgeläut des Big Ben wurde abgeschaltet, eine besondere Ehrung, die zuletzt dem 1965 verstorbenen britischen Premierminister Winston Churchill zuteil geworden war.

Der Begriff des Thatcherismus wurde 1979 erstmals von der kommunistischen Zeitschrift Marxism Today verwendet und zunächst als Kampfbegriff der politischen Linken verwendet. Thatcher und ihre Anhänger adaptierten den Begriff jedoch schnell für den eigenen Sprachgebrauch. Thatcher gründete 1974 zusammen mit Sir Keith Joseph und Alfred Sherman die britische Denkfabrik Centre for Policy Studies. Diese hatte eine wesentliche Rolle bei der Verbreitung von Positionen des Monetarismus und eine Rücknahme staatlicher Aktivitäten zugunsten des Freien Markts. Das Zentrum selbst hält Thatchers Eintreten für den Monetarismus im Sinne Milton Friedmans für wichtiger als die Aufnahme von Thesen Friedrich August von Hayeks im Sinne der Österreichischen Schule. Zwar habe Hayeks intellektuelle Ablehnung des Sozialismus sicher Thatcher, Keith Joseph und weitere politische Weggefährten beeinflusst, beim "Thatcherismus" spiele der Hayeksche volkswirtschaftliche und makroökonomische Ansatz aber eine deutlich geringere Rolle als Friedmans Monetarismus. Hayek habe in einer im freundschaftlichen Ton gehaltenen Korrespondenz mit Thatcher die Forderung nach einer deutlich schnelleren Einschränkung der Gewerkschaften erhoben und den Einfluss der Monetaristen eher beklagt als begrüßt. Thatcher habe dies wie die Hinweise Hayeks auf das "Wunder von Chile" insoweit zurückgewiesen, als dies unter den Bedingungen einer Demokratie nicht durchzusetzen sei.

Der Thatcherismus vereint sowohl konservative als auch liberale Elemente. Außerdem werden im Thatcherismus traditionelle Werte bzw. im britischen Kontext Viktorianische Werte betont, die in Kontrast zur permissiven Gesellschaft stehen. Er dient – in den Worten von Nigel Lawson – als politische Plattform für eine starke Betonung des freien Marktes, beschränkte Staatsausgaben und Steuersenkungen, gepaart mit britischem Nationalismus. Nigel Lawsons Definition: „Freie Märkte, Finanzdisziplin, strenge Kontrolle über die öffentlichen Ausgaben, Steuersenkungen, Nationalismus, „Viktorianische Werte“ (im Sinne einer Samuel Smiles Hilf dir selbst-Variante), Privatisierung und ein Schuss Populismus.“

Richard Vinen unterscheidet beim Thatcherismus zudem einerseits zwischen Thatchers persönlicher Rolle und den von ihrer Regierung in Gang gebrachten Reformen. Andererseits zieht er auch eine Trennungslinie zwischen Anhängern, die, wie Howe und Lawson, eher den Kernideen des Thatcherismus verpflichtet waren als der Person Thatcher selber, und denen, die sich dagegen als Thatcheristen im Sinne einer unbedingten Loyalität zur Politikerin Margaret Thatcher definierten. Dominik Geppert urteilt über Thatcher: „Erst ihr Führungswille, ihr Populismus, ihr missionarischer Eifer, andere von der Richtigkeit ihrer eigenen Einstellungen zu überzeugen, verliehen dem Thatcherismus seine politische Durchschlagskraft.“ Ferner hebt er die Gegensätzlichkeit zentraler Facetten des Thatcherismus hervor, die aus dem konfliktreichen Verhältnis konservativer und liberaler Elemente resultiert habe.

Der Thatcherismus löste den britischen Nachkriegskonsens ab und verschob den politischen Mittelgrund nach rechts. Die wirtschaftspolitischen Reformen des Thatcherismus wurden ab 1997 auch von New Labour unter dem neuen Premierminister Tony Blair beibehalten, der sich zu Thatchers Erbe bekannte; 2002 erklärte Peter Mandelson, ein führender Vertreter von New Labour, sogar: „Wir sind jetzt alle Thatcheristen“. Vereinzelt wird diese Fortführung von Thatchers Wirtschaftspolitik durch Blairs Labourregierung unter dem Schlagwort „Blatcherism“ beschrieben.

Thatchers Politik wie ihre Person polarisieren auch noch nach ihrer aktiven Zeit. 2002 und 2003 erreichte sie in zwei Umfragen sowohl den 16. Platz unter den 100 größten Briten aller Zeiten als auch den 3. Platz unter den 100 schlechtesten. In einer Umfrage des BBC Newsnight-Programms im September 2008, bei der die Abstimmenden den besten Premierminister nach 1945 wählen sollten, belegte Thatcher den dritten Rang hinter Churchill und Clement Attlee. Bei einer gleichlautenden Umfrage der University of Leeds im Jahr 2010 belegte Thatcher den zweiten Rang; diese Umfrage fand unter 106 Akademikern statt, die sich auf britische Geschichte und britische Politik spezialisiert haben.

Richard Vinen sieht Thatcher, die bei allen Unterhauswahlen eine eigene Mehrheit in den anderen Landesteilen jeweils verfehlte, als ein rein englisches Phänomen. Eric Evans attestiert, auch Jahre nach Thatchers Fall bleibe sie in der britischen Gesellschaft umstritten.

Ihre Anhänger heben ihre Wirtschafts- und Sozialpolitik hervor, die zu mehr Wohlstand für das Land und viele Bürger geführt habe. Auch ihre Rolle in der Beendigung des Kalten Krieges wird von ihren Anhängern betont. Zudem habe sie Großbritannien, ehemals als kranker Mann Europas betitelt, wieder als Großmacht etabliert. Kritiker werfen ihr die Zerstörung eines gesellschaftlichen Gemeinschaftsgefühls durch die Zerschlagung der Gewerkschaften, den Ruin des öffentlichen Sektors durch Privatisierung sowie Ignoranz gegenüber immateriellen gesellschaftlichen Werten vor. Zudem habe sich die Armutsrate nahezu verdoppelt. Qualitätsprobleme traten bei den unter Thatcher privatisierten englischen Trinkwasserversorgern auf. Die Wasserpreise stiegen in zehn Jahren um 46 Prozent an, die betreibenden Unternehmen investierten trotzdem nicht ausreichend in das Leitungsnetz. In Thatchers Ära fiel auch die Verabschiedung der umstrittenen Clause 28, die Kommunalbehörden eine vorsätzliche Förderung von Homosexualität untersagte.

Thatchers autoritärer Regierungsstil wird ebenfalls regelmäßig als Kritikpunkt angeführt; in ihrer Regierungszeit habe die gemeinsame Kabinettsverantwortung gelitten; anstelle gemeinsam getroffener Kabinettsentscheidungen habe sie politische Sachfragen meist mit Ministern in Vieraugengesprächen ausgehandelt. Auch habe sie statt dem Kabinett viel eher einem kleinen Kreis persönlicher Berater (wie Bernard Ingham und Charles Powell) vertraut. Zudem habe sie das Amt des Premierministers zu einem präsidialen Amt umgedeutet – ein Vorwurf, der später auch regelmäßig gegen Tony Blair erhoben wurde.

In Schottland konnte sich der Thatcherismus nie durchsetzen und traf mit seinen Maßnahmen auf entschiedenen Widerstand in der Bevölkerung, die sich auch in den Unterhauswahlen zunehmend von den Konservativen abwandte. Der schottische First Minister Alex Salmond führte die Unabhängigkeitsbestrebungen der Schotten mittelbar auf Thatcher und die insbesondere in Schottland regelrecht verhasste Polltax zurück.
Auch in Wales fand durch Thatchers Regierung eine Polarisierung statt; hatten sich einer Studie zufolge 1979 nur 57 % eher als walisisch denn als britisch definiert, sagten dies 1981 bereits 69 % der Befragten.

Umstritten ist bis heute die Bedeutung der Wirtschaftspolitik Thatchers. Mit der kontraktiven Geldpolitik Anfang der 1980er Jahre gelang es ihr, die Inflation zu senken, allerdings um den Preis eines starken Anstiegs der Arbeitslosigkeit in der Spitze auf drei Millionen (rund 12,5 Prozent in 1983). Die monetaristische Geldpolitik Thatchers wird von vielen Ökonomen, einschließlich Milton Friedman, als eher misslungen angesehen. Die gesamte Regierungszeit war von sozialen Unruhen und hoher Arbeitslosigkeit geprägt. Die Produktivitätssteigerung in Großbritannien von durchschnittlich 1,1 % in den 1970er Jahren auf durchschnittlich 2,2 % in den 1980er Jahren wird von einigen Ökonomen auf ihre Politik der Privatisierung, Deregulierung und der Zurückdrängung des Gewerkschaftseinflusses zurückgeführt. Andere führen den Produktivitätszuwachs auf den Niedergang des (im internationalen Vergleich eher niedrigproduktiven britischen) industriellen Sektors und das Wachstum des Dienstleistungssektors zurück. Positiv wurde vermerkt, dass die Dynamik der britischen Wirtschaft seit den 1980er Jahren nicht mehr hinter der Dynamik der deutschen und französischen Wirtschaft zurückblieb. Das Wirtschaftswachstum war in den 1980er Jahren mit durchschnittlich 2,7 % etwas höher als in den 1970er Jahren (2,5 %).

Die im Zuge des sogenannten "Big Bang" durchgeführte Deregulierung im britischen Bankwesen wird als mitursächlich sowohl für den späteren Erfolg Londons als Finanzplatz, aber auch für den Kasinokapitalismus gesehen, der zur Finanzkrise ab 2007 führte.

Beginnend mit ihrer Streichung der Gratismilch an Grundschulen 1971 wurde Thatcher Gegenstand unzähliger Witze und satirischer Darstellungen. Das satirische Hörspiel "The Iron Lady" wurde im Jahr 1979 veröffentlicht. Ab Mitte der 1980er Jahre avancierte Thatcher zu einem der bekanntesten Menschen weltweit, die im Ausland weit populärer war als in Großbritannien selbst. Bei Gegnern und Anhängern gleichermaßen als „Maggie“ bekannt, wurde Thatcher auch vom einflussreichen britischen Kunstkritiker Michael Billington als prägend für Theater und die Künste eingestuft.

In den 1980ern wurde sie zum Gegenstand von zahlreichen Protestliedern. Billy Bragg und Paul Weller bildeten dafür eigens das Red Wedge Kollektiv. In dem Album The Final Cut von Pink Floyd wird Margaret Thatcher mehrfach erwähnt. Kritisiert wird sie unter anderem im Zusammenhang mit dem Falklandkrieg.

John Wells nahm Thatcher in verschiedenen Medienformaten satirisch aufs Korn. Mit Richard Ingrams wurden die angeblichen "Dear Bill"-Briefe im Austausch mit Denis Thatcher als Kolumne im "Private Eye" veröffentlicht und als Theaterstück im West End als "Anyone for Denis?" aufgeführt. "Anyone for Denis?" kam 1982 ins Fernsehen. Bei Spitting Image, einer satirischen britischen TV-Serie, war Thatcher ebenso ein beliebtes Feindbild; Steve Nallon verlieh ihr dabei seine Stimme.

Margaret Thatcher wurde zudem in verschiedenen Fernsehprogrammen, Dokumentationen, Filmen und Theaterstücken abgebildet. Im James Bond-Film "In tödlicher Mission" wurde sie von der Imitatorin Janet Brown dargestellt. Patricia Hodge spielte sie in Ian Curteiss "The Falklands Play" (2002) und Andrea Riseborough im Film "The Long Walk to Finchley" (2008). Der Fernsehfilm "Thatcher: The Final Days" von 1991 zeigte die letzten Tage als Premierministerin und wurde von Richard Maher verfasst. Sylvia Syms spielte Thatcher. Sie ist ebenso Titelcharakter im Film "Margaret" von 2009, gespielt von Lindsay Duncan. Meryl Streep spielte sie 2011 in "Die Eiserne Lady" (Originaltitel: "The Iron Lady").

In Alan Hollinghursts Buch "Die Schönheitslinie", 2004 mit dem Man Booker Prize ausgezeichnet, hat Thatcher einen Nebenaufritt.

Im Juni 2015 übergaben die Erben Margaret Thatchers ihre persönlichen Aufzeichnungen und Papiere an eine Einrichtung des für Kultur und Medien zuständigen Ministeriums. Es wurde ihnen hierfür ein Rabatt von einer Million britischen Pfund auf die zu erwartende Erbschaftssteuer in Höhe 4,7 Millionen britischen Pfund gewährt. Sie schlugen damit die Möglichkeit aus, sie in den USA zu verkaufen. Die Papiere werden auf Wunsch Thatchers im öffentlichen Archiv des Churchill College der University of Cambridge aufbewahrt und sollen auch online einsehbar sein.






</doc>
<doc id="10316" url="https://de.wikipedia.org/wiki?curid=10316" title="Öffentlich-private Partnerschaft">
Öffentlich-private Partnerschaft

Eine öffentlich-private Partnerschaft (ÖPP, oder ) ist eine vertraglich geregelte Zusammenarbeit zwischen öffentlicher Hand und Unternehmen der Privatwirtschaft in einer "Zweckgesellschaft". Ziel von ÖPP ist die Arbeitsteilung, wobei der private Partner die Verantwortung zur effizienten Erstellung der Leistung übernimmt, während die öffentliche Hand dafür Sorge trägt, dass gemeinwohlorientierte Ziele beachtet werden. Die öffentliche Hand erwartet von der Partnerschaft mit der privaten Wirtschaft die Entlastung der angespannten öffentlichen Haushalte, da der private Unternehmer die Finanzierung ganz oder teilweise selbst besorgt und daher auf die Wirtschaftlichkeit des Projektes achten muss. ÖPP ist in der Regel einem Miet- oder Pachtvertragsverhältnis ähnlich.

Aufgrund der Vielgestaltigkeit der Anwendungsfelder gibt es noch keine allgemein anerkannte Definition. Der wirtschaftliche Sprachgebrauch hat mittlerweile übernommen, dass ÖPP sowohl vom Sinn als auch vom Begriffsgehalt nur dann vorliegt, wenn die Partner ihre unterschiedlichen Stärken bündeln. Reine Finanzierungsgeschäfte, also auch Sale and Lease Back, gehören deshalb nicht zum Begriff. ÖPP ist somit nach heutigem, funktionalem Begriffsverständnis die vertraglich meist langfristig geregelte Zusammenarbeit zwischen öffentlicher Hand und Privatwirtschaft, bei der die notwendigen Ressourcen (zum Beispiel Know-how, Betriebsmittel, Kapital, Personal usw.) von den Partnern zum gegenseitigen Nutzen in einem gemeinsamen Organisationszusammenhang eingebracht und vorhandene Projektrisiken entsprechend der Risikomanagementkompetenz der Projektpartner verteilt werden. Privatisierungsrechtlich stehen öffentlich-private Partnerschaften zwischen Aufgabenprivatisierungen (materielle Privatisierung) und Organisationsprivatisierungen (formelle Privatisierung). Im letztgenannten Fall verwendet der öffentlich-rechtliche Verwaltungsträger lediglich eine privatrechtliche Gesellschaftsform, im erstgenannten Fall wird die bisher hoheitliche Aufgabe vollständig oder teilweise dem Markt übertragen, denn die staatliche Aufsicht bleibt in der Regel bestehen.

Der Anstieg der öffentlichen Schulden mit der Folge knapper finanzieller Ressourcen und gleichzeitig anstehende öffentliche Investitionen veranlassten die öffentliche Hand, nach neuen Finanzierungsmöglichkeiten zu suchen. Sieht man von Konzessionierungen zur Entwicklung von Wasser-, Gas- und Elektrizitätsinfrastrukturprojekten ab (die es bereits im 19. Jhdt. gab), waren erst ab 1987 öffentliche Stellen nicht mehr strikt gegen privates Kapital als Finanzierungsgrundlage öffentlicher Projekte. Ein frühes Beispiel ist das Projekt Neues Frankfurt zwischen 1925 und 1930, wo sich Stadt und private Investoren je zur Hälfte an den Kosten beteiligten.

Die Beteiligung der Europäischen Investitionsbank an ÖPP-Vorhaben reicht bis zu den Darlehen zurück, die im Entstehungsland Großbritannien nach Gründung des Eurotunnel-Projekts (Frankreich/Großbritannien) im Juli 1987 gewährt wurden. Die britische "Private Finance Initiative" (PFI) vom Dezember 2001 gilt als das erste systematische, von einer Regierung konzipierte Projekt eines Staates zur Nutzung von privatem Kapital für öffentliche Vorhaben.

Die weitaus meisten ÖPP-Projekte werden in Großbritannien realisiert. 2002 startete das Prestigeprojekt für die Sanierung und den Betrieb der Londoner U-Bahn. London sollte innerhalb von 30 Jahren insgesamt 45 Mrd. Euro an Mieten an die Investoren zahlen. Doch bereits 2007 gingen die Investoren in die Insolvenz. London musste die Verpflichtungen der Investoren übernehmen und unter eigener Regie von vorn beginnen. Bei Schulprojekten stellten sich bauliche Mängel heraus, bei Krankenhäusern und Gefängnissen wird so an Personal gespart, dass häufig die Qualität der Versorgung, der Sicherheit und des Essens gefährdet wird. Oft verkaufen die Erstinvestoren die Verträge an andere Investoren weiter, die auf höhere Renditen setzen. Ein Ausschuss des englischen Parlaments kam 2011 zu dem Schluss, dass keine Belege für die Vorteilhaftigkeit des ÖPP-Verfahrens gefunden werden konnten. Die lange Laufzeit mache die Verträge inflexibel, die Auftragsvergabe sei teuer. Die langfristig vereinbarten Mieten seien in Wirklichkeit eine verdeckte Kreditaufnahme, die im öffentlichen Haushalt aber nicht ausgewiesen werden.

Die EU-Kommission hat erstmals im März 2003 „Leitlinien für erfolgreiche ÖPP-Projekte“ herausgegeben, die dem Projektmanager helfen sollten, die Ziele des öffentlichen und privaten Sektors in Einklang zu bringen.

Die während der Griechenlandkrise begonnene und bis heute (Mitte 2017) fortgesetzte Niedrigzinspolitik der EZB hat die Rahmenbedingungen für ÖPP massiv verändert. Staatsanleihen der Bundesrepublik Deutschland notierten zeitweise sogar unter null Prozent. Gleichwohl befürwortet der Verkehrsminister im Kabinett Merkel III, Alexander Dobrindt (CSU), Teilprivatisierungen.

Seither wurden ÖPP von Staaten und supranationalen Institutionen als eine weichere Alternative zur Privatisierung genutzt. Ende 2007 bestand ein Volumen von € 73,8 Mrd. ÖPP-Projekten, von denen € 54,7 Mrd. zwischen 2005 und 2007 entstanden waren. Größter ÖPP-Markt ist Großbritannien mit einem Anteil von € 42,2 Mrd. (57 %), gefolgt von Italien (€ 29,8 Mrd; 40 %), Deutschland (€ 9,5 Mrd.; 13 %) oder Griechenland mit einem Anteil von € 6,3 Mrd. In Deutschland entfielen im Jahre 2010 etwa 66 % Marktanteil bei der Finanzierung von ÖPP auf die Sparkassenorganisation und 22 % auf die sonstige Kreditwirtschaft.

Die Kreditgewährung an eine Projektgesellschaft stellt ein konstitutives Element einer ÖPP-Struktur dar. Die meist privatrechtlich organisierte Projektgesellschaft fungiert als Kreditnehmerin. Diese verkauft (forfaitiert) oder tritt ihre Forderungen gegen die Kommune an eine Bank ab, die Kommune spricht gleichzeitig einen vollständigen Einredeverzicht gegenüber der Bank aus.

Inzwischen wurden in den meisten Staaten auch die rechtlichen Voraussetzungen geschaffen oder durch die ÖPP-Partner Vertragsgestaltungen entwickelt, die eine Kreditaufnahme des privaten Sektors innerhalb von ÖPP-Projekten zu besseren Kommunalkredit-Konditionen ermöglichen. Generell ist das statthaft, wenn die Forderungen einer privatrechtlich organisierten Projektgesellschaft gegen die öffentliche Hand im Rahmen einer "echten Forfaitierung" an Banken verkauft/abgetreten werden und gleichzeitig der öffentliche Schuldner mindestens in Höhe der Kreditbedienung auf sämtliche Einreden verzichtet. Wegen des Einredeverzichts ist die Forderung durch die öffentliche Hand selbst bei Nichtleistung der Projektgesellschaft noch zu erfüllen, so dass hierdurch Kreditinstitute so gestellt werden, als ob sie einen Kreditvertrag direkt mit dem öffentlichen Schuldner geschlossen hätten; denn die Kreditbedienung wird durch etwaige Leistungsstörungen innerhalb der Vertragsbeziehung zwischen Kommune und Projektgesellschaft nicht beeinträchtigt.

ÖPP steht landläufig für eine besondere Art der funktionalen Privatisierung. Im Unterschied zur materiellen Privatisierung lässt der Staat eine bislang öffentlich wahrgenommene Aufgabe also nur teilweise los und zieht private Wirtschaftssubjekte lediglich hinzu. Daher wird oft auch von Teilprivatisierung gesprochen. Die hoheitliche Erfüllungsverantwortung bleibt unangetastet. Vertragliche Konstruktionen können in den unterschiedlichsten Formen gestaltet sein. Aufgrund dessen ist eine Einordnung von ÖPP-Konstruktionen in definierte Modelle erschwert, da eine klare Abgrenzung selten gelingt. Jedoch unterscheidet die Europäische Kommission zwischen ÖPP auf Vertragsbasis und institutionalisierten ÖPP. Bei vertraglichen ÖPP-Projekten ist das Kooperationsverhältnis zwischen öffentlichem und privatem Partner rein vertraglich geregelt, während bei institutionalisierten ÖPP eine Unternehmensneugründung stattfindet, die durch gemischtes Kapital von öffentlichen und privaten Investoren finanziert wird.

Dennoch soll unter anderem nach den umfangreichen Informationen der PPP-Task-Force im BMVBS oder des Gutachtens „PPP im Öffentlichen Hochbau“ eine Auflistung der heute üblichen ÖPP-Vertragsmodelle erfolgen.

Das Betreibermodell sieht in der Regel vor, dass der private Unternehmer ein Infrastrukturprojekt auf eigenes Risiko plant, errichtet, finanziert und betreibt; er hat die Bauherreneigenschaft und trägt das wirtschaftliche Risiko. Für diese Vorhaben wird meist eine Einzweckgesellschaft gegründet. Die Betriebskosten und der Kapitaldienst werden durch Gebühren aufgebracht, die die Nutzer für die Inanspruchnahme der Einrichtung zu entrichten haben. Der private Betreiber erbringt seine Leistungen entweder im Namen und auf Rechnung der Gemeinde oder als Konzessionär in eigenem Namen. Grundlage ist stets ein Betreiber- oder Konzessionsvertrag, in dem sich die Kommune Kontroll- und Zugriffsrechte sichert.

Unter der Bezeichnung BOT (Build, Operate, Transfer; deutsch: Bauen, Betreiben, Übertragen) ist ein Betreibermodell geläufig, das die schlüsselfertige Erstellung von Anlagen einschließlich Finanzierung der Vorlaufkosten und umfassendem Projektmanagement sowie die Betriebsübernahme für die Anlaufphase vorsieht. Nach Ende der Projektlaufzeit wird das Projekt an den Endnutzer übertragen. BOTs mit Laufzeiten bis zu 30 Jahren und mehr, insbesondere beim Bau von Infrastrukturanlagen wie Kraftwerken oder Flughäfen, sind üblich. Der Bau der britischen Botschaft in Berlin wurde nach den Maßstäben der britischen Private Finance Initiative (PFI) umgesetzt.

Der private Auftragnehmer übernimmt auf einem in seinem Eigentum stehenden Grundstück Planung, Bau, Finanzierung und den Betrieb z. B. einer Immobilie, die von der öffentlichen Hand genutzt wird. Zum Vertragsende geht das Eigentum an Grundstück und Gebäude auf den öffentlichen Auftraggeber über. Das Entgelt besteht in einer regelmäßigen Zahlung an den Auftragnehmer; es wird bei Vertragsabschluss festgesetzt und enthält Komponenten für Planung, Bau, Betrieb, Finanzierung und Erwerb der Immobilie inkl. Grundstück, einschließlich möglicher Zuschläge für den betriebswirtschaftlichen Gewinn, der auch die Risikoübertragung abdeckt. Die Laufzeit des Vertrages beträgt in der Regel 20 bis 30 Jahre.

Der private Auftragnehmer übernimmt Planung, Bau, Finanzierung und den Betrieb z. B. einer Immobilie oder Straße, die von der öffentlichen Hand genutzt wird und in ihrem Eigentum steht. Das Entgelt besteht in einer regelmäßigen Zahlung an den Auftragnehmer; es wird bei Vertragsabschluss festgesetzt und enthält Komponenten für Planung, Bau, Betrieb und Finanzierung einschließlich möglicher Zuschläge für den betriebswirtschaftlichen Gewinn, der auch die Risikoübertragung abdeckt.

Der private Auftragnehmer übernimmt Planung, Bau, Finanzierung, Betrieb und optional die Verwertung einer Immobilie. Anders als beim ÖPP-Erwerbermodell besteht jedoch keine Verpflichtung zur Übertragung des Gebäudeeigentums am Ende der Vertragslaufzeit. Der Auftragnehmer hat vielmehr ein Optionsrecht, die Immobilie entweder zurückzugeben oder zu einem vorab vereinbarten Restwert zu übernehmen. Neben der Kaufoption sind auch Mietverlängerungsoptionen oder Verwertungsabreden möglich. Als Nutzungsentgelt zahlt der Auftraggeber Leasingraten. Bestandteile der Raten sind Entgelte für die (Teil-)Amortisation der Planungs-, Bau- und Finanzierungskosten sowie den Betrieb (Facility Management) einschließlich Risikozuschlag.

Das Mietmodell entspricht weitgehend dem Leasingmodell, jedoch ohne Kaufoption. Das Gebäude kann zum im Zeitpunkt des Vertragsablaufs zu ermittelnden Verkehrswert erworben werden. Der Auftraggeber zahlt regelmäßige Raten an den Auftragnehmer in feststehender Höhe; Bestandteile dieser Raten sind das Entgelt für die Gebrauchsüberlassung und den Betrieb (Facility Management).

Der private Auftragnehmer verpflichtet sich, Einrichtungen für die öffentliche Hand zu planen, zu errichten und zu betreiben (Baukonzession) und bestimmte Dienstleistungen gegenüber den Nutzern zu erbringen (Dienstleistungskonzession). Der private Partner finanziert sich unmittelbar bei den Nutzern über Eintrittsgebühren, Maut, Parkgebühren. Überschätzt der private Partner das Nutzungsaufkommen, ist ihm keine Möglichkeit gegeben das Projekt durch Entgelterhebung zu refinanzieren oder Gewinne zu erwirtschaften. Um diese Modelle dennoch zu fördern, können von der öffentlichen Hand Zahlungen erfolgen (z. B. Anschubfinanzierung oder Abschlusszahlungen).
Konzessionsmodelle finden häufig Anwendung bei Projekten der Verkehrsinfrastruktur, bei denen wiederum zwischen A- und F-Modellen unterschieden wird. Bei A-Modellen entrichtet der Nutzer das Entgelt an die öffentliche Hand, die es an den privaten Partner weiterleitet. Bei F-Modellen ist der private Partner ermächtigt, die Gebühr direkt bei den Nutzern einzufordern.

Die intensivste Form des ÖPP findet im Rahmen der so genannten gemischt-wirtschaftlichen Unternehmen statt, die sowohl öffentliche als auch private Anteilseigner haben: teilweise als Modifikation der Betreibermodelle, teilweise sind private Anteilseigner lediglich finanziell beteiligt.

Bei dem Gesellschaftsmodell oder Kooperationsmodell errichten und betreiben öffentliche Hand und private Partner eine Einrichtung über eine gemeinsame Gesellschaft. Entsprechend der oben angegebenen Definition sind aber nur solche gemischtwirtschaftlichen Unternehmen als ÖPP zu verstehen, bei denen beteiligte Private nicht nur ein Finanzierungsgeschäft wollen, sondern die Partner ihre unterschiedlichen Kompetenzen in das Unternehmen einbringen.

Bei dem Betriebsführungsmodell bleibt die öffentliche Hand selbst Eigentümerin der Einrichtung. Es ist lediglich vorgesehen, dass der private Betriebsführer gegen Entgelt die Einrichtung im Namen des öffentlichen Aufgabenträgers betreibt. Typischerweise umfasst Betriebsführung den Betrieb, die Wartung und die Instandhaltung sowie die technische und kaufmännische Verwaltung.

Als Zwischenform zwischen dem Betreibermodell und dem Betriebsführungsmodell gilt das sog. "Betriebsüberlassungsmodell". Die öffentliche Hand zieht sich mehr aus dem laufenden Betrieb der Anlage zurück. Der private Betriebsführer hat einen weitergehenden Gestaltungsraum, darf zum Beispiel oft außenwirksam handeln.

Grundsätzlich muss zwischen ÖPP-Projekten im öffentlichen Hochbau und solchen im Verkehrssektor unterschieden werden.
Im öffentlichen Hochbau sind grundsätzlich alle Modelle anwendbar, etabliert haben sich insbesondere die oben beschriebenen Modelle wie etwa:


In der Verkehrsinfrastruktur können grundsätzlich drei Modelltypen unterschieden werden:


Die Erwartung eines wirtschaftlichen Vorteils für die öffentlichen Haushalte ist üblicherweise der zentrale Beweggrund für ÖPP. Zitiert werden im Schnitt zehn bis fünfzehn Prozent Kostenersparnis. Der wirtschaftliche Vorteil wird über Vergleichsrechnungen ermittelt, die die konventionelle Realisierung (Public Sector Comparator, PSC) der über ÖPP gegenüberstellen. Allein die Berechnung des PSC stellt einen Bruch mit tradierten Methoden der öffentlichen Finanzwirtschaft dar, da hier möglichst alle mit einer Maßnahme verbundenen Kosten einbezogen werden („ganzheitliche“ Betrachtung, zum Beispiel Einbeziehung der Reparaturkosten über die gesamte Nutzungsdauer und nicht nur die reine Bauinvestition) und die Kosten meist über mehrere Jahrzehnte betrachtet werden; häufig über den gesamten Lebenszyklus. Ist die Vorteilhaftigkeit durch entsprechende Kostenanalysen nachgewiesen und politisch gewollt (siehe Abschnitt Kritik), ist auch bei der sich anschließenden Ausschreibung des ÖPP-Projektes der Preis das in nahezu allen Fällen am stärksten gewichtete Kriterium bei der Anbieterauswahl. Üblicherweise ist der Angebotsbarwert ausschlaggebend. Dies ist der Nettobarwert der vom Auslober zu zahlenden, jährlichen, üblicherweise stetigen Entgelte für Betrieb und Schuldendienst über die Vertragslaufzeit. Der Abzinsungsfaktor wird hierbei vom Auslober vorgegeben.

Ein Vorzieheffekt bei ÖPP-Investitionen kann für die oft stark verschuldete öffentliche Hand insoweit eintreten, da eine oft langwierige Haushaltsplanung für eine eigene (Neu-)Kreditaufnahme entfällt. Hinzu kommt ein Zeitgewinn bei ÖPP-Projekten durch eine schnellere, termin- und budgettreue Fertigstellung sowie eine Effizienzsteigerung durch das rein betriebswirtschaftliche Management der Privaten bei Wartung und Betrieb der Anlagen.

Gemäß der Maxime, wonach der Staat und die Privatwirtschaft sich auf ihre jeweiligen Stärken und Kernkompetenzen konzentrieren sollen, wird somit der Service für die Nutzer und die Gesamteffizienz bei der Leistungserstellung optimiert. Die privaten Unternehmen haben bei bestimmten Projekttypen, insbesondere auch im Hochbau, bereits langjährige Erfahrungen zur optimalen Gestaltung und können daher die vorhandenen Projekt- und Betriebsrisiken und -chancen besser einschätzen, sodass durch ÖPP eine wirtschaftlichere Leistungserbringung im Interesse aller erreicht werden kann.

Die privaten Unternehmen versprechen sich von der Beteiligung an ÖPP-Vorhaben neue profitable Geschäftsfelder. Die Finanzwirtschaft verspricht sich vom ÖPP-Geschäft in Deutschland im Kredit- und Eigenmittelmarkt das Aufkommen einer neuen „Asset“-Kategorie, der insoweit Jahrzehnte hinter der Entwicklung in anderen Ländern, wie Großbritannien zurückgeblieben ist.

Der Staat macht sich auch in höherem Maße von den Privaten abhängig. Dem stehen aber der potentielle Effizienzgewinn gegenüber und die Möglichkeit für die öffentliche Hand neuverschuldungsfrei investieren zu können.

Potentiell besteht die Gefahr, dass bei einem nicht ausreichend überwachten und konzessionierten Vorhaben die Kontrolle durch die Behörden verloren geht. Ein Negativbeispiel lieferte etwa das Konsortium Toll Collect, das die Lkw-Maut in Deutschland gegenüber dem vertraglich vorgesehenen Termin erst mit über einem Jahr Verspätung einführen konnte. Die Verträge dieses ÖPP-Modells sind selbst für Abgeordnete des Bundestags nicht frei zugänglich. Eine öffentliche Kontrolle ist dadurch massiv erschwert.

Haushaltstechnisch wirkt ÖPP nur dann wie eine Neukreditaufnahme der öffentlichen Hand, wenn keine oder nur unzureichende Risiken und Chancen auf den Privaten übertragen wurden (zum Beispiel Forfaitierungsmodell). Nach den in der gesamten EU geltenden Regeln von Eurostat ist ein ÖPP-Vorhaben dann nicht der öffentlichen Verschuldung zuzurechnen, wenn der Bau und das Marktrisiko dem Privaten übertragen wurden.

Die öffentliche Hand ist nicht vollständig von der Nützlichkeit von ÖPP als alternative Beschaffungsmethode überzeugt. Auch sind derzeit nicht alle Konzepte ausgereift. Von daher sind viele Entscheidungsträger, Gremien und Beamte angesichts unerprobter Verwaltungsverfahren bei ÖPP eher geneigt, die Planung und Beschaffung wie bisher in Eigenregie durchzuführen. In weiten Bereichen besteht in Deutschland auch noch eine nicht zu unterschätzende rechts- und verwaltungsverfahrensmäßige Unsicherheit. Generell besteht das Risiko, dass ÖPP-Projekte teurer werden als ihre möglichen rein öffentlichen Alternativen.

Kritisiert wird die Vorstellung einer Win-win-Situation und die Ausweitung auf den Bereich der Daseinsvorsorge. Es besteht ein Zielkonflikt: Die Politik ist am Gemeinwohl orientiert und hat daher bei der Zuordnung von Ressourcen die Interessen jener Menschen wahrzunehmen, die ihre Bedürfnisse nicht oder nur unzureichend durch ihre Kaufkraft nachfragen können. Das Hauptziel eines Unternehmens dagegen ist die Gewinnmaximierung für seine Eigentümer. Dadurch besteht die Gefahr der Verschlechterung des Leistungsangebotes aufgrund der meist monopolartigen Exklusivverträge.

Für die Organisation Attac stellt die oft geübte Praxis der Geheimhaltung von Privatisierungsverträgen den größten Kritikpunkt an ÖPP dar. Es ist daher oft auch nicht möglich, Aussagen über die Rentabilität von ÖPP-Projekten zu treffen. Dabei besteht gemäß dem Prinzipal-Agent-Problem das Problem der asymmetrischen Informationsverteilung.

Gemäß Art. 20 Abs. 2 GG geht jede Staatsgewalt vom Volke aus. Jede Entscheidung des Verwaltungsträgers muss sich daher bis zum Volkssouverän zurückverfolgen lassen. Sind aber öffentliche Ressourcen in einem gemischt-wirtschaftlichen Unternehmen gebunden, hat die Verwaltung unter Umständen einen zu geringen Einfluss auf die Entscheidungsfindung zur Verwendung der öffentlichen Ressourcen und das Leistungsangebot. Im Gegenteil: Verfassungsrechtlich nicht legitimierte Private treffen Entscheidungen, die das Gemeinwohl betreffen. Dies führt unter Umständen dazu, dass öffentliche Mittel nicht ausreichend dem Gemeinwohl, sondern in erster Linie dem privaten Partner zugutekommen.

Der Grünen-Fraktionsvorsitzende Anton Hofreiter sieht die Gefahr verdeckter Staatsverschuldung oder kommunaler Schattenverschuldung. Ähnlich der Kommentar von Harald Schumann: .

Der Publizist Werner Rügemer hat auf der Grundlage des Verlaufs bisheriger ÖPP-Projekte und Recherchen vor Ort eine „Spur des Scheiterns“ diagnostiziert. Verschiedene Formen des Scheiterns seien festzustellen: 
Diese vielfältigen Formen des Scheiterns führt Rügemer auf Strukturelemente des ÖPP-Verfahrens zurück: Geheimhaltung der Verträge, private Schiedsgerichtsbarkeit, Forfaitierung mit Einredeverzicht (Verkauf der Mietforderungen an eine Bank), hohe Transaktions- und Beraterkosten, Zugehörigkeit der einschlägigen Berater zur organisierten ÖPP-Lobby, Alleinbestimmungsrecht des Investors bei den Subunternehmen u.a. Auch in Wirtschaftskreisen wird ÖPP inzwischen heftig kritisiert: „Bei ÖPP verdienen Konzerne, Banken und Berater das große Geld. Gemeinsam mit der öffentlichen Hand haben sie ein intransparentes System geschaffen ‒ zulasten von Mittelstand und Steuerzahlern.“

Der Englische Publizist George Monbiot hat anhand des ÖPP-Vorzeigeprojekts Skye Bridge das Scheitern des Prinzips ÖPP detailliert dokumentiert. Um dem Projekt den Schein des Erfolgs zu garantieren, hatte die Britische Regierung substanzielle finanzielle Vorleistungen getätigt, obwohl gemäß der Idee von ÖPP die Finanzierung eigentlich privat erfolgen soll. Außerdem hatte der Staat die privaten Bauherren für Kostenüberschreitungen kompensiert und damit die behaupteten Vorteile von ÖPP wie Risikotransfer und effizientes Kostenmanagement gleich selber widerlegt. Am Ende kostete die Brücke die Öffentlichkeit (Autofahrer, Steuerzahler) rund 93 Millionen Pfund Sterling. Hätte der Staat die Brücke selber gebaut, hätte sie höchstens 15 Millionen Pfund gekostet.

Die NDR-Fernsehdokumentation „Der geplünderte Staat“ (2013) von Stefan Aust und Thomas Ammann zeigt detailliert die Nachteile von ÖPP-Projekten auf: Geheimhaltung der Verträge, keine parlamentarische Kontrolle, Anfälligkeit für Korruption und mangelnde Wirtschaftlichkeit werden dabei im Detail belegt. Als Beispiele dienen den Autoren der Ausbau der Autobahn A1 zwischen Hamburg und Bremen, der Neubau eines Gefängnisses in Rostock sowie die Elbphilharmonie Hamburg. Neben vielen Interview-Partnern kommt Dieter Engels, Präsident des Bundesrechnungshofs zu Wort. Er verweist darauf, dass die beteiligten Unternehmen anders als der Staat Gewinne erzielen müssen, dass umgekehrt aber ihre Kreditkosten höher sind als die des Staates. Allein dieser Zusammenhang mache ÖPP in der Regel unwirtschaftlich. Ausführlich dokumentieren die Autoren die Möglichkeit der Umgehung der Schuldenbremse durch ÖPP-Projekte.

In Deutschland wird die ÖPP Deutschland AG kritisiert, da Banken, Berater und Baukonzerne Anteile an der "ÖPP Deutschland AG" halten und gleichzeitig von öffentlich-privaten Partnerschaften profitieren. Ulrich Müller, Vorsitzender der Organisation Lobbycontrol, forderte eine Auflösung der "ÖPP Deutschland AG", da sie eine Einladung zu Lobbyismus zulasten der Bürger sei. Die Vorsitzende von Transparency International Deutschland, Edda Müller, äußerte, dass „klare Auftraggeber- und Auftragnehmerbeziehungen öffentlich-privater Partnerschaften aus Sicht der Korruptionsprävention eindeutig vorzuziehen“ seien. Dies ist u.a. auch Thema bei "Mario Barth deckt auf!" gewesen.

Bis 2014 sind nach einem Gutachten des Bundesrechnungshofs 5 der 6 ÖPP-Autobahnprojekte (auch als Privatautobahn bezeichnet) teurer geworden, als dies bei konventioneller Umsetzung der Fall gewesen wäre. Eine wesentliche Motivation zur Nutzung von ÖPP sei die Vorfinanzierung der Baukosten durch Private und damit die Möglichkeit der Umgehung der Schuldenbremse.

Das bisher größte und zugleich umstrittenste ÖPP-Projekt bildete der jahrelange A1-Umbau zwischen Hamburg und Bremen. Telekom und Daimler (Toll Collect-Konsortium) sind über die Erhebung der Lkw-Maut am „Ertrag“ der Autobahn beteiligt. Der Betrieb eines 72,5  Kilometer langen Stücks der A 1 zwischen Bremen und Hamburg im Gegenzug für die LKW-Mauteinnahmen durch das Konsortium A1 mobil stellte sich 2017 als nicht wirtschaftlich heraus. Deshalb erhebt das Konsortium gegenüber dem Bund Forderungen in einer Größenordnung von 640 bis 787 Millionen Euro, um eine Insolvenz zu verhindern. Nach einem Bericht der Berliner Zeitung kannte die Regierung diese Probleme, hielt sie jedoch geheim, während weitere ÖPP-Projekte forciert wurden.

ÖPP (öffentlich-private Partnerschaft), auch bezeichnet als Public-private-Partnership (PPP), ist eine neue Beschaffungsform öffentlicher Auftraggeber, die immer (nur) dann zum Einsatz kommen soll, wenn sie in einer konkreten Projektsituation in der Lage ist, den gesetzlichen Vorgaben von Sparsamkeit und Wirtschaftlichkeit eher zu entsprechen als andere verfügbare Beschaffungsvarianten.

Spezifisches Kennzeichen ist dabei der Lebenszyklusphasen übergreifende, aus Sicht des Auftragnehmers möglichst viele, mindestens vier der Wertschöpfungsstufen Planen, Bauen, Finanzieren, Erhalten und Betreiben umfassende Aufgabentransfer vom öffentlichen Auftraggeber auf einen privaten Anbieter solcher integrierter Dienstleistungen.

Aus der Definition von ÖPP ergibt sich eine große Vielfalt möglicher Anwendungsgebiete, wie etwa der Verkehr, Ver- und Entsorgungsbereich sowie der öffentliche Hochbau. Folgende Abbildung illustriert und ergänzt dies mit konkreten Beispielen.

Seit seiner Entstehung wurde der Begriff ÖPP in Deutschland undifferenziert angewendet und unscharf wahrgenommen. Es wurde damit eine Vielzahl von Aktivitäten und Vorstellungen beschrieben, die mit der ursprünglichen Idee von öffentlich-privater Partnerschaft nur sehr entfernt zu tun haben:


Seit Ende der 1990er Jahre existieren öffentlich-private Partnerschaften in Deutschland. Es folgt ein historischer Überblick über die Entstehung:

Weitere Aspekte wie etwa der Standardisierung, des Deal Flows sowie der Entwicklungen in der EU können der angegebenen Quelle entnommen werden.

Allgemein wird Public Private Partnership auch in jenen Bereichen angewendet, die mit Daseinsvorsorge eher ungenau umschrieben sind.

Geht man von einer weiten Definition des Public-Private-Partnership aus, so können auch Projekte einiger internationaler Gesundheitsschutzorganisationen, die sowohl von öffentlichen als auch von privaten Organisationen finanziert werden, als ÖPP gelten. Beispiele dafür sind verschiedene WHO-Projekte, da die WHO auch durch die Industrie und durch Stiftungen finanziert wird. Zu den größten zählen:


ÖPP gibt es in den unterschiedlichsten Bereichen, wobei die Ausgestaltung auch von den Fachgesetzen der jeweiligen Sachgebiete abhängt. Hier, wie auch im Hochbau allgemein, wird Public Private Partnership als eine Projektrealisierung öffentlicher Infrastrukturmaßnahmen unter privatem Gewinnstreben verstanden, die möglichst den gesamten Lebenszyklus eines Bauprojektes (nicht identisch mit dem herkömmlichen Produktlebenszyklus), beispielsweise eines Gebäudes (siehe nebenstehende Grafik) umfasst.


Am 9. Juli 2008 wurde in Berlin im Beisein des Bundesfinanzministers Peer Steinbrück und des Bundesbauministers Wolfgang Tiefensee die Rahmenvereinbarung zur Gründung der neuen vom Bund initiierten Beratungsgesellschaft "Partnerschaften Deutschland" unterzeichnet. Sie soll Bund, Länder und Kommunen bei Grundlagenthemen von ÖPP-Projekten beraten. Die deutsche Industrie ist über eine private Beteiligungsgesellschaft beteiligt. Inwieweit Einfluss von dieser Seite genommen wird, ist noch nicht deutlich geworden. Der Vorstand besteht aus einer Doppelspitze mit einem Vertreter des Finanzministeriums und einem Vertreter der Industrie. Mit Beginn des Jahres 2009 hat die ÖPP Deutschland AG (Partnerschaften Deutschland) ihre operative Tätigkeit aufgenommen.

Der Bundesrechnungshof und die Rechnungshöfe aller Bundesländer haben in einer gemeinsamen Auswertung festgestellt, dass die Wirtschaftlichkeit von ÖPP-Projekte nicht nachgewiesen und in vielen Fällen nicht gegeben sei.

Das IT-Projekt Herkules der Bundeswehr gilt als das derzeit größte ÖPP-Projekt Europas.

Ein umstrittenes Projekt im öffentlichen Hochbau ist der Neuaufbau des Berliner Stadtschlosses, der nach der Planung des ehemaligen Bundesministers Manfred Stolpe im Rahmen einer partnerschaftlichen öffentlich-privaten Finanzierung möglich sein sollte.
Zunehmend kommt ÖPP auch bei Gebietskörperschaften zur Anwendung, deren Verschuldungssituation nach Auffassung der staatlichen Aufsichtsbehörden eine kreditfinanzierte Sanierung von Gebäuden nicht mehr zulässt. Im öffentlichen Hochbau sind bisher vor allem Schulneubau- und Schulsanierungsmaßnahmen Treiber dieser Beschaffungsvariante. Schulgebäude sind insbesondere in Hessen im Rahmen von Erbbauverträgen langfristig an private Gesellschaften abgegeben worden, nur um sie sogleich wieder anzumieten. Die privaten Gesellschaften verpflichten sich zur Sanierung der Gebäude und erhalten dafür über Zeiträume von 20 bis 40 Jahren Mietzahlungen der zuständigen Gebietskörperschaft. Diese Mietzahlungen liegen in der Regel über den bei einer kreditfinanzierten Sanierung fällig werdenden Kapitalmarktzinsen; zudem haben die beteiligten Gebietskörperschaften „Nebenkosten“, zum Beispiel für Beratung und Geschäftsbesorgung, in zum Teil erheblicher Höhe zu tragen.

Die Hamburger Elbphilharmonie ist ein Großprojekt der ÖPP. Nach zehnjähriger Bauzeit verzehnfachten sich die Fertigstellungskosten. Die JVA Schwerin wurde in ÖPP erbaut und hierbei ergaben sich Hinweise auf „privat“-private Partnerschaft.

Mittlerweile gibt es mit der Justizvollzugsanstalt Hünfeld in Hessen auch das erste Gefängnis in Deutschland, das als ÖPP betrieben wird.

Die Kommune Plauen beschäftigt einen privaten Sicherheitsdienst für die Umsetzung der lokalen Polizeiverordnung.

Begünstigt durch das deutsche Kreislaufwirtschafts- und Abfallgesetz sind in Deutschland auch im Bereich der Abfallentsorgung zahlreiche ÖPP-Projekte entstanden. So eröffnet Abs. 1 KrW-/AbfG den entsorgungspflichtigen Körperschaften ausdrücklich die Möglichkeit, sich zur Erledigung der Entsorgungspflicht Dritter zu bedienen, während die Erfüllungsverantwortung bei den Körperschaften bleibt.

Auch in Satz 3 Wasserhaushaltsgesetz (WHG) ist die Möglichkeit der Hinzuziehung Dritter bei der Abwasserbeseitigung ausdrücklich vorgesehen.

Die Wasserversorgung von Berlin war in Kooperation mit dem französischen Konzern Veolia Environnement privatisiert worden. Die Kosten für den Berliner Bürger wurden hierdurch 20-30 % teurer.


Ein Beispiel für ÖPP-Modelle in der Informationstechnologie ist das 2004 gegründete Unternehmen WIVERTIS zwischen Siemens (Siemens Business Services) und der Landeshauptstadt Wiesbaden.

Mit der Privatisierung der Deutschen Bundespost wurde das deutsche Sendernetz weitgehend von Telekom und Media Broadcast übernommen. Ende der 1990er Jahre wurden daraufhin mit Hilfe von TRANSRADIO SenderSysteme Berlin AG viele Stationen mit neuen Sendenormen digitalisiert und das LW- und MW-Netz danach stark dezimiert.


Ein Schwerpunkt ist das Verkehrswesen, wo ÖPP-Modelle neben der LKW-Maut auch größere Infrastrukturprojekte wie den Warnowtunnel in Rostock und den Herrentunnel in Lübeck ausführen. Mit der Inbetriebnahme der Nordverlegung der Bundesautobahn 4 bei Eisenach wurde 2010 das erste ÖPP-Pilotprojekt im Autobahnbau fertig gestellt. Inzwischen (Stand: August 2017) sind sieben solcher ÖPP-Vorhaben in Betrieb und weitere in Bau oder Planung.

Hinsichtlich der Überlegungen der Bundesregierung zur Privatisierung des Bundesfernstraßennetzes hat der Bundesrechnungshof am 30. November 2016 ein Gutachten vorgelegt. Er weist darin auf mehrere Problemkreise hin.
Bei der Lkw-Maut („Toll Collect“) zeigte sich die schwache Stellung der öffentlichen Hand auch bei Projekten des Bundes. Weil die Investoren Daimler, Telekom und cofiroute die Installationen auf den Autobahnen und in den Lkws erst mit einer Verzögerung von knapp zwei Jahren funktionsfähig machen konnten, entstand dem Staat ein Einnahmeausfall von gut 4 Milliarden Euro. Die 2004 von der Bundesregierung beim privaten Schiedsgericht eingereichte Schadenersatzklage – die Höhe des inzwischen aufgelaufenen Betrags mit Zinsen und Konventionalstrafen beläuft sich auf etwa 7 Milliarden Euro – wurde bis heute nicht entschieden; die Bundesregierung zeigte sich bereit (Stand Oktober 2013), auf mindestens 4,5 Milliarden Euro zu verzichten.

Eines der bekanntesten Projekte ist die Errichtung und der Betrieb der Nord Autobahn durch das Konsortium "Bonaventura". Die Bauzeit soll mit drei Jahren relativ kurz werden. Die Erlöse der privaten Partner richten sich nach der Autobahnmaut.

In einem anderen Projekt wird ab 2010 ein Teilstück einer ehemaligen Bundesstraße neu errichtet, bzw. erweitert und ergänzt.

Auf dem ehemaligen Zeughausareal in Burgdorf, Kanton Bern, ist seit Frühling 2012 das kantonale Verwaltungszentrum "Neumatt" in Betrieb, das neben 450 Arbeitsplätzen der Verwaltung einen Werkhof sowie ein Regionalgefängnis mit 110 Haftplätzen umfasst. 
Neumatt" wurde als ÖPP-Pilotprojekt für die Schweiz nach internationalen Standards realisiert.





</doc>
<doc id="10318" url="https://de.wikipedia.org/wiki?curid=10318" title="Säkularismus">
Säkularismus

Säkularismus bezeichnet eine Weltanschauung, die sich auf die Immanenz und Verweltlichung der Gesellschaft beschränkt und auf darüber hinausgehende, religiöse Fragen verzichtet. Sie erwächst aus zwei Prozessen: zum einen aus der Säkularisierung, also dem mentalen Prozess der Entflechtung oder Trennung zwischen Religion und Staat, zum anderen aus der Säkularisation, dem konkreten Prozess der Ablösung der weltlichen Macht religiöser Institutionen. Der Begriff wurde von dem Theologen Friedrich Gogarten (1887–1967) geprägt und unter anderem eingeführt, um eine Aussöhnung der christlichen Kirchen mit der Säkularisierung zu ermöglichen. Die religiöse Seite betrachtet die dem Begriff des Säkularismus zugrunde liegenden Weltanschauungen meist als ideologisch – was Kritiker ihr wiederum als ebensolche Ideologie vorwerfen.

In Auseinandersetzung mit europäischen Ideen hat sich im frühen 20. Jahrhundert auch in einigen islamischen Ländern ein säkularistisches Denken entwickelt. In der Türkei legte Mustafa Kemal Atatürk nach dem Sieg im Befreiungskrieg (1919–1922) ein säkularistisches Modernisierungsprogramm auf, das anderen politischen Führern in der islamischen Welt als Vorbild diente. Einer der prominentesten säkularistischen Denker der islamischen Welt war ʿAlī ʿAbd ar-Rāziq, der 1925 sein Buch „Der Islam und die Grundlagen der Herrschaft“ ("al-Islām wa-uṣūl al-ḥukm") veröffentlichte, in dem er die These vertrat, dass die Muslime ihr Herrschaftssystem frei wählen dürften, da Mohammed kein solches System festgelegt habe und auch Koran und Sunna dazu keine Vorgaben machten.




</doc>
<doc id="10319" url="https://de.wikipedia.org/wiki?curid=10319" title="1. Buch der Könige">
1. Buch der Könige

Das 1. Buch der Könige (abgekürzt 1 Kön) ist ein Buch des (jüdischen) Tanach und des (christlichen) Alten Testamentes. In den Ostkirchen heißt es 3. Buch der Königreiche. Ursprünglich, in der wechselvollen Geschichte seiner Entstehung mit seinen mehrfachen Überarbeitungen, bilden das 1. und das 2. Buch der Könige (2 Kön) eine "Einheit", also nur ein biblisches Buch. Bei der Beschreibung der Entstehungsgeschichte und seiner theologischen Inhalte ist es daher sinnvoll, die beiden Bücher zusammen zu betrachten.

Das Buch erzählt die Geschichte vom betagten König David und seinem Sohn Salomo, der ihm auf den Thron Israels folgt, als weiser Richter „salomonische Urteile“ fällt, dem Reich Wohlergehen und eine lange, 40-jährige Friedenszeit beschert (Schalom – Salomo / Frieden) und für Israel den ersten Tempel auf dem Berg Moria in Jerusalem bauen lässt. Nach dem Tode Salomos zerfällt das seit David bestehende Reich in ein Nordreich (Israel) und ein Südreich (Juda). Könige kommen und gehen, die Propheten Elija und Elischa treten auf. Das erste Buch der Könige endet – etwas abrupt – damit, dass Ahasja, der Sohn Ahabs, König über Israel wird und wie schon sein Vater dem Gott Baal und nicht JHWH dient.

Der Schluss von 2 Kön () legt nahe, dass die beiden Bücher der Könige nur ein Buch darstellen. Dies belegt auch die Zäsur (hinter ) am Ende vom 1. Buch, die vom Erzählverlauf nicht gerechtfertigt ist, da hier die Geschichte Ahasjas von Israel in zwei Teile (1 Kön und ) unterbrochen wird.

Erstmals findet sich diese Aufteilung des Königsbuches im 3./2. vorchristlichen Jahrhundert bei den Übersetzern der Septuaginta (LXX), wo sie, wie bei dem Buch Samuel, vom Umfang der Buchrollen motiviert war. Dass die Königsbücher ursprünglich eine Einheit bildeten, belegen die Angaben über die Zahl der biblischen Bücher bei Flavius Josephus (Ap. 1,8) und im baylonischen Talmud (BB 14b). Die Aufteilung der Septuaginta wurde später in die Vulgata und im 15./16. Jahrhundert in die hebräische Bibel übernommen.

In der LXX werden die Samuel- und die Königsbücher (1 Sam, 2 Sam, 1 Kön und 2 Kön) als die "vier Bücher der Königsherrschaften" (bzw. Königreiche) (1. bis 4. Buch) bezeichnet. Dieser Name wurde von den christlichen Ostkirchen und auch der Vulgata übernommen.

Der hebräische Tanach zählt die Bücher der Könige zu den Prophetenbüchern (Nevi’im), während es im christlichen Kanon des Alten Testaments in die Bücher der Geschichte eingeordnet wird. Der Tanach unterscheidet die „vorderen“ und die „hinteren“ Propheten. Zu den vorderen Propheten zählt er die Bücher Josua, Richter, Samuel und Könige, die hinteren Propheten bilden die Bücher Jesaja, Jeremia und Ezechiel sowie die Propheten des Dodekaprophetons.

Zunächst geht es im Josuabuch um die Landnahme der Zwölf Stämme Israels. Darauf folgt die Richterzeit und dann die Königszeit, die für Israel bzw. Juda im Jahre 587 v. Chr. mit dem Babylonischen Exil in der Katastrophe endet. Die Zeit der Monarchie in Israel bzw. Juda, die in den Samuel- und Königsbüchern beschrieben wird, dauert also etwa 400 Jahre, angefangen bei den Königen Saul (um 1020 v. Chr.), David und Salomo. Im Jahr 926 v. Chr. erfolgt die Reichsteilung in Nord- und Südreich (Israel und Juda), und 722 v. Chr. geht das Nordreich unter. Das Königreich Juda besteht bis zum König Jojachin, der im Jahr 587 v. Chr. samt Oberschicht ins Exil gehen muss.

Die Bücher der Könige beginnen im ersten Teil mit dem betagten König David, dessen Sohn Salomo ihm auf dem Thron folgt. Nach Salomos Tod erzählt der zweite Hauptteil die Geschichte der getrennten Reiche. Im dritten Teil wird die Geschichte der Könige Juda (Südreich mit Jerusalem) behandelt, die (in ) mit der Begnadigung Jojachins endet.

Jeder der drei Hauptteile enthält eine "Rahmung" sowie "Leitwörter" bzw. "Leitmotive", die das Buch gliedern.

Die sich auf das ungeteilte Reich und auf das Reich Juda beziehenden Teile weisen starke Parallelen zur ersten Hälfte des 2. Chronikbuches auf, inhaltlich sind sie aber merklich kritischer.

Die Darstellung der israelitischen und judäischen Könige weist einen stereotypen Rahmen auf, der ein Charakteristikum für die Art der Geschichtsschreibung in den Königsbüchern ist. Dieser Rahmen ist als Erzählgerüst um die Beschreibungen der individuellen Taten der Könige gelegt. Weder bei König Saul noch bei König David gibt es bereits Elemente eines solchen Darstellungsrahmens, aber bei Salomo (1 Kön ) ist der Schluss gerahmt. Wo ausführlichere Erzählungen aus dem Leben von Königen vorliegen (Jerobeam I, Jehu), können Elemente der Erzählstruktur fehlen. Bei der judäischen Königin Atalja fehlt die Rahmenstruktur komplett, wodurch zum Ausdruck gebracht wird, dass ihr die Rechtmäßigkeit ihrer Herrschaft verweigert wird.

Die unterschiedlichen Propheten im Königsbuch sind die von JHWH gesandten Mahner, die den Königen den Untergang ihrer Herrschaft und des Landes ankündigen. Die Darstellung ihres Auftretens bzw. ihrer Wirkung unterliegen einer gewissen Stereotypie, deren vier gestalterische Elemente Wortereignisformel/Botenformel (1), Begründung (2), Drohung (3) und Erfüllung (4) sind. Mit dem Auftreten der Propheten wird theologisch (s.u. Schwerpunkte der Theologie) das Funktionieren des göttlichen Wortes in der Geschichte aufgezeigt.

Neben Elija und Elischa (s.u.) werden in den Königbüchern die folgenden Propheten erwähnt:

Erwähnung im Königsbuch: 1 Kön ; und ; darüber hinaus in anderen biblischen Büchern (siehe Artikel: Elija).

Der Nordreichprophet Elija ist während der Zeit der Könige Ahab und Ahasja tätig gewesen, also etwa zwischen 870 und 850 v. Chr. Er gehört zu den Wanderpropheten, die weder mit einem Heiligtum verbunden sind, noch in einer Prophetengemeinschaft lebte. Es gibt vier Erzählungen mit geschichtlichem Hintergrund:
Dass Elia mit seinen Ansichten beim Königshaus nicht durchgedrungen ist, zeigt die Erzählung von der Orakelbefragung.



Überlieferung im Königsbuch: 1 Kön , ; ; – und ; zu berücksichtigen ist auch – Revolution Jehus.

Der Nordreichprophet Elischa hat im Unterschied zu Elija eine Prophetengemeinschaft um sich geschart, mit der er überwiegend an einem Ort wohnte. Er stand dem König sehr nahe und besaß politischen Einfluss, den er beispielsweise zur Hilfe für Notleidende geltend machen konnte.

Es gibt zahlreiche Hinweise darauf, dass das Buch der Könige unterschiedliche Entstehungsstadien durchlief. Die christlichen Exegeten sind sich aber uneins, wie die Bildung des Königsbuches tatsächlich vonstattenging.

Manche Forscher plädieren für ein Schichtenmodell, wonach das Buch in mehreren, zeitlich voneinander entfernten Schichten überarbeitet worden ist. Andere bevorzugen ein Blockmodell, das im Bibeltext verschiedene Redaktionsblöcke ausmachen will. Wieder andere versuchen beide Modelle zu kombinieren oder lehnen beide Modelle ab.

Eine zeitliche Einordnung scheint schwierig. Jahreszahlen für eine erste, zweite und dritte Redaktion des Buches oder Teilen davon werden beispielsweise mit 580 (nach 586), 550 und 500 v. Chr. angegeben. Je nach Entstehungsthese variieren die angenommenen Zeiten.

Eine grobe Einordnung, die als zeitlicher Rahmen für die Entstehung des Königsbuches angegeben werden kann, ist die Zeit des Exils und die Jahrzehnte danach.

Die Geschichten, Erzählungen etc. des 1. Buches der Könige sind "historisch" in etwa zwischen den Jahren 960 v. Chr. und 840 v. Chr. einzuordnen. Dabei ist zu bedenken, dass den Historikern als Quelle etwa für die Datierung der Regierungszeiten der Könige selten außerbiblisches Vergleichsmaterial zur Verfügung steht. "Einziges Quellenmaterial ist oftmals die Bibel." Den Redaktoren des Königsbuches, dessen Entstehung um etwa 550 v. Chr. anzunehmen ist, ging es dabei, dies ist zu beachten, in erster Linie um religiöse Botschaften und wenig um die Niederlegung historischer Wahrheiten. Zahlenangaben über das Alter und die Regierungsdaten von Königen sind deshalb kritisch zu betrachten.


"Omriden":


Im Königsbuch geht es theologisch um die Einheit und Reinheit des JHWH-Glaubens. Alle nichtjahwistischen Einflüsse sind dem JHWH-Kult fernzuhalten, und der Gott JHWH darf allein im Jerusalemer Tempel verehrt werden. Dies ist für die deuronomistischen Redaktoren des Königbuches auch der Maßstab für die Könige Israels und Judas. Da diese sich neben JHWH auch anderen Gottheiten (als Chiffre dafür stehen die Namen Baal und Aschera) zuwenden, werden sie zumeist verworfen.

Sowohl das Nordreich Israel mit seinen Heiligtümern in Bet El und Dan (die „Sünde Jerobeams“), als auch das Südreich Juda, das neben Jerusalem noch Kultorte an den Höhenheiligtümern kennt, sind dem Untergang geweiht.

Über beide Reiche bricht folgerichtig das Gericht herein, und sie gehen unter. Für das Südreich gibt es jedoch Hoffnung, die sich auf das Verhalten der Ideal-Könige David, Hiskija und Joschija gründet. Diese konnten zwar das Gericht für Juda nicht abwenden, jedoch durch ihre Treue zu Jerusalem als einzigem Kultort den endgültigen Untergang abwenden.

Die Propheten treten als von JHWH gesandte Mahner auf, die König und Volk den rechten Weg weisen. Sie besitzen Wunderkräfte, und ihr Wort bewahrheitet sich, selbst, als sie mit dem Untergang von Königtum und Staat Israel und Juda die Katastrophe schlechthin voraussagen.









</doc>
<doc id="10320" url="https://de.wikipedia.org/wiki?curid=10320" title="2. Buch der Könige">
2. Buch der Könige

Das 2. Buch der Könige ist ein Buch des jüdischen Tanach bzw. des christlichen Alten Testaments. Seit dem Mittelalter wird es in 25 Kapitel unterteilt. In der Septuaginta (und infolgedessen in den christlichen Ostkirchen) heißt es das 4. Buch der Königreiche.

Ursprünglich bildeten beide Bücher der Könige nur ein Buch, vergleiche die Schlussmasora nach .

Die Teilung der Bücher nach – mitten in der Geschichte Ahasjas von Israel – ist sachlich nicht gerechtfertigt. Die Teilung in zwei Bücher stammt aus der Tradition der Septuaginta, wo sie wahrscheinlich durch die handhabbare Länge einer Schriftrolle bedingt war – griechische Texte nehmen bedingt durch den Aufbau der griechischen Sprache (lange Wörter) und Schrift (viele Vokale) wesentlich mehr Platz ein als hebräische Texte (kurze Wörter, keine Vokale) desselben Inhalts. Sie wurde in der Vulgata tradiert und im späten Mittelalter auch zurück in die Hebräische Bibel übernommen.

Das 2. Buch der Könige setzt die Geschichte der getrennten Reiche Israel und Juda (israelitischen Reichsteilung 926 v. Chr.) bis zum Untergang Samarias in 2. Kön 17 fort. Danach folgt die Geschichte Judas bis zum Fall Jerusalems und der späteren Begnadigung Jojachins.




siehe 1. Buch der Könige#Literatur



</doc>
<doc id="10322" url="https://de.wikipedia.org/wiki?curid=10322" title="1. Buch der Chronik">
1. Buch der Chronik

Das 1. Buch der Chronik, auf Diwrei hajjamim („Ereignisse der Tage“, 1 und 2 Chr), ist ein Buch des Tanach, der hebräischen Bibel bzw. des christlichen Alten Testaments. Seit dem Mittelalter wird es in 29 Kapitel unterteilt. In den Ostkirchen heißt es 1. Buch der Auslassungen (oder "der ausgelassenen Dinge", griech. "Paralipomenon"), weil es viele in den Samuel- und Königsbüchern fehlende Details enthält. Als Entstehungszeit wird die vorhellenistische Epoche angenommen, da Ereignisse vor 516 v. Chr. in der Chronik enthalten sind, griechische Einflüsse jedoch nicht festgestellt werden konnten.

Das Buch besteht aus zwei Teilen. Im kürzeren ersten Teil werden umfangreiche Abstammungs- und Geschlechterlisten der Israeliten und einiger Nachbarvölker gegeben. Der größere zweite Teil des Buches zeigt inhaltlich Parallelen zum 2. Buch Samuel, stellt die Ereignisse aber aus einem etwas anderen Blickwinkel dar; vor allem wird weniger Wert auf die politischen Ereignisse, dafür mehr Wert auf den Kultus und den Aufbau der israelitischen Gesellschaft des geschilderten Zeitraums gelegt. Die Sicht auf die Führungspersonen ist merklich positiver und unkritischer als in den Samuelbüchern. Wegen der vielen Verweise auf den Tempel wird vermutet, dass der Autor selbst dem Tempelkult nahestand und evtl. einer der Tempelsänger war.

Das 2. Buch der Chronik ist eine direkte Fortsetzung, die wohl nur wegen der Unhandlichkeit allzu langer Schriftrollen vom ersten Buch abgetrennt wurde.

Inhalt:





</doc>
<doc id="10323" url="https://de.wikipedia.org/wiki?curid=10323" title="Stylesheet-Sprache">
Stylesheet-Sprache

Stylesheet-Sprachen [] sind formale Sprachen in der Informationstechnik, um das Erscheinungsbild von Dokumenten bzw. Benutzeroberflächen festzulegen.

Ein Stylesheet ist am ehesten mit einer Formatvorlage zu vergleichen. Grundidee hierbei ist die Trennung von Information (Daten) und Darstellung. Das Programm, das das Stylesheet auswertet, interpretiert die zugewiesenen Daten (Text, Tabellen, Grafiken etc.) und formatiert sie (z. B. für die Bildschirmausgabe) entsprechend den vorgegebenen Regeln. 

Beispiele für Stylesheetsprachen sind CSS, XSL und DSSSL.

Stylesheets umfassen alle Bereiche der Interpretation (bildliche, hörbare oder fühlbare Darstellung). Stylesheets interpretieren Inhalte abhängig vom Ausgabegerät (z. B. Braille-Lesegeräte für Blinde). Dabei darf der Inhalt nicht verändert werden.




</doc>
<doc id="10324" url="https://de.wikipedia.org/wiki?curid=10324" title="2. Buch der Chronik">
2. Buch der Chronik

Das 2. Buch der Chronik, auf Diwrei hajjamim („Ereignisse der Tage“, 1 und 2 Chr), ist ein Buch aus dem Tanach und bildet die direkte Fortsetzung des 1. Buches der Chronik, das wohl nur der Unhandlichkeit allzu langer Schriftrollen wegen vom ersten getrennt wurde. Seit dem Mittelalter wird es in 36 Kapitel unterteilt. In den Ostkirchen heißt es 2. Buch der Auslassungen.

Die Handlung des Buches ist größtenteils parallel zum 1. und 2. Buch der Könige, das Geschehen wird jedoch aus anderem Blickwinkel betrachtet. Vor allem auf den Kultus und die israelitische Gesellschaft wird mehr Wert gelegt, auf politische Vorgänge dafür weniger. Im Gegensatz zu den Königsbüchern beschränkt sich die Chronik nach der Reichsteilung auf die Vorgänge im Südreich Juda und lässt das Nordreich Israel außer Acht. Die Sicht auf das Königtum ist in der Chronik insgesamt positiver als in den sehr kritischen Büchern der Könige.

Der Aufbau des Buches besteht vor allem aus folgenden Themen:





</doc>
<doc id="10326" url="https://de.wikipedia.org/wiki?curid=10326" title="Buch Esra">
Buch Esra

Das Buch Esra ist ein Buch des jüdischen Tanach bzw. des christlichen Alten Testaments der Bibel. Seit dem Mittelalter wird es in zehn Kapitel unterteilt. Es bildet zusammen mit dem Buch Nehemia eine Einheit. Daher wird in der Septuaginta und der Vulgata das Buch Nehemia als 2. Buch Esra bezeichnet ("Esdras β" bzw. "II Ezrae").

Das 3., 4., 5. und 6. Buch Esra und die Esra-Apokalypse sind apokryphe jüdische oder christliche Schriften seit dem 1. Jahrhundert n. Chr., die sich auf den biblischen Esra beziehen.

Das Buch lässt sich grob in zwei Teile gliedern:

Die einzelnen Teile behandeln dabei:


Der Haupttext des Buches ist auf Hebräisch geschrieben. Esra 4,8 – 6,18 und 7,12–26 sind dagegen in aramäischer Sprache geschrieben. Das Aramäisch des Esra-Buchs unterscheidet sich von dem des Buchs Daniel. So lautet z. B. die Form des Personalpronomens der 2. Person Singular maskulin in Esra , während in Daniel der Konsonantentext die Form aufweist.

In der frühen jüdischen und griechischen Tradition wurden die Bücher Esra und Nehemia als Einheit gesehen, wie sich aus Angaben zum Kanon und der Handschriftentradition ersehen lässt. So vermerkt z. B. die Massora im Codex Leningradensis die Buchmitte nach der Anzahl der Verse bei Nehemia 3,32. Ebenso fehlt ein Kolophon am Ende von Esra.

Dieser Zusammenhang ist auch sachlich gegeben. Beide Bücher behandeln die Ereignisse vom Beginn der Perserzeit über den Wiederaufbau des Tempels, die Errichtung der Stadtmauer um Jerusalem und die Konstituierung der judäischen bzw. jüdischen Kultgemeinschaft. In Neh 8 tritt Esra erneut auf, Neh 8,9 und 12,26 nennen Esra und Nehemia nebeneinander, so dass der Eindruck gleichzeitigen Wirkens entsteht. Hinzu kommen literarische Makrostrukturen, die auf einen planvollen Aufbau des Esra-Nehemia-Buches schließen lassen: So steht das Bußgebet Esras (Esr 9) in Verbindung mit dem Bußgebet Nehemias (Neh 1) und dem Bußgebet des Volkes (Neh 9). Sowohl das Handeln Esras als auch Nehemias steht in engem Kontakt zum Persischen Großkönig und wird durch königliche Erlasse legitimiert (Esr 1; 7; Neh 2).

Die Abtrennung eines eigenen Buches Nehemia ist motiviert durch die Einleitung Neh 1,1: „Worte Nehemias, des Sohnes Chachaljas...“ und findet sich erstmals bei Origenes.

Das Buch Esra-Nehemia weist weiterhin starke sachliche und theologische Bezüge zu den Büchern der Chronik auf. So wiederholt Esr 1,1–3 wörtlich den Schluss . Esra-Nehemia kann also als Fortsetzung von 1/2 Chr gelesen werden. Auffällig ist dabei, dass die Worte, die sich inhaltlich mit der Verkündigung Deuterojesajas berühren, als Prophetie Jeremias eingeführt werden.

Gemeinsam ist Esra-Nehemia und 1/2 Chr weiterhin das Interesse an Stammtafeln, am Kult und am Kultpersonal, an Festen und Gebeten. Ähnlichkeiten ergeben sich auch auf kompositioneller Ebene im Wechsel von Erzählungen und Listen. Diese Beobachtungen führten zur These eines "Chronistischen Geschichtswerkes".

In neuerer Zeit wird diese These teilweise bestritten. Die chronologische Reihenfolge 1/2 Chr – Esr/Neh wird nur in den wenigsten Handschriften geboten. Zudem gibt es auch eine Zahl sachlicher Unterschiede. Die Stellung des davidischen Königshauses spielt in Esra-Nehemia keine Rolle, während sie für 1/2 Chr bedeutsam ist.

Für die Verhältnisbestimmung von Esra-Nehemia und 1/2 Chr ergeben sich demnach mehrere Möglichkeiten:

Im Neuen Testament wird Esra nicht zitiert.






</doc>
<doc id="10327" url="https://de.wikipedia.org/wiki?curid=10327" title="Buch Nehemia">
Buch Nehemia

Das Buch Nehemia (auch 2. Buch Esra) ist ein Buch im jüdischen Tanach und im christlichen Alten Testament der Bibel.

Seit dem Mittelalter wird das Buch Nehemia in 13 Kapitel unterteilt.


Das Thema des Buches ist der Wiederaufbau der Mauer und der Stadt Jerusalems. Laut umstrittenen Interpretationen stellt dies den Startpunkt für das Kommen des Messias dar. So soll 445 v. Chr. im Monat Nissan (März/April) der Beginn der 69 Jahrwochen nach Daniel gewesen sein.

Das Buch Nehemia wurde historisch teilweise als „Zweites Buch Esra“ bezeichnet oder bildete sogar zusammen mit dem Buch Esra ein einziges Buch, wie wir bei Josephus, im Talmud und bei Hieronymus lesen. Dadurch konnte die Zahl der kanonischen Bücher auf die Zahl der Buchstaben im hebräischen Alphabet (22) beschränkt werden, was symbolisch wichtig war für die Abgrenzung des Kanons gegenüber nichtkanonischen Büchern. Protestantische und modernhebräische Bibeln enthalten zwei Bücher, benannt nach ihren Hauptpersonen: Esra und Nehemia. Auf jeden Fall hängen beide Bücher eng zusammen. Zu den verschiedenen Zählweisen der mit dem Namen Esra verbundenen Bücher, siehe Liste biblischer Bücher.

Laut einigen Autoren ist die Reihenfolge der Ereignisse in den Büchern Esra und Nehemiah teilweise durcheinandergekommen; auch könnte mit dem „ich“ der beiden Bücher an einigen Stellen der jeweils andere der beiden gemeint sein.

Die moderne historisch-kritische Forschung rechnet beide Bücher (Esra/Nehemia) zum „chronistischen Geschichtswerk“, das wohl nach 400 v. Chr. verfasst wurde; umstritten dabei ist, ob es vor oder nach den Feldzügen Alexanders des Großen entstand. Vermutet wird, dass der Autor bzw. die Autoren oder Endredakteure dabei auf umfangreiche und zuverlässige Quellenschriften, z. B. die in erwähnte sog. Nehemiaquelle oder -denkschrift und die sog. Esraquelle (Neh 8–10) zurückgegreifen konnten und es getan haben.


Die Zeit Esras und Nehemias war eine Zeit gewaltiger philosophischer Strömungen und Umbrüche, die bekannte Denker, Philosophen und Religionsstifter hervorbrachte. Bekannte ungefähre Zeitgenossen waren: Buddha, Konfuzius, Sokrates, Plato, Aristoteles. Esra als Erneuerer und teilweise sogar als Schöpfer des Judentums, wie wir es heute kennen, passt gut in diese Reihe hinein.

Nehemia (; in der Septuaginta: Neemia) war ein babylonischer Jude.
444 v. Chr. wurde Nehemia zum Statthalter von Juda ernannt. Nehemia sorgte dafür, dass die Stadtmauern von Jerusalem wieder aufgebaut wurden und entwarf eine Reform der religiösen Vorschriften. Für die Durchsetzung der Reformen sorgte der Priester Esra. Zentrale Aspekte seiner Reform waren die Einhaltung des Sabbat, das Verbot, „fremde“ Frauen zu heiraten, und die Erhebung des Zehnten.





</doc>
<doc id="10328" url="https://de.wikipedia.org/wiki?curid=10328" title="Buch Ester">
Buch Ester

Das Buch Ester (auch: "Esther") ist ein Buch des jüdischen Tanach, gehört dort zu den "Ketuvim" (Schriften) und wird als eine der fünf Festrollen (Megillot) beim Purimfest gelesen. Im christlichen Alten Testament gehört das Buch zu den Geschichtsbüchern. 


Der Verfasser und seine Lebenszeit sind nicht genau festzustellen.

Aus dem Buch Ester selbst geht nur hervor, dass Achaschwerosch bei seiner Abfassung bereits gestorben war. Nach der jüdischen Überlieferung wurde das Buch um 400 v. Chr. verfasst. Auch im christlichen Bereich gab es eine Frühdatierung in die Zeit noch vor dem Untergang des Perserreiches vor Alexander den Großen (um 330 v. Chr.).

Da sich bei genauer Analyse zeigt (siehe dazu den folgenden Abschnitt), dass die Kenntnis persischer Verhältnisse im Buch Ester keineswegs so gut ist, wie es zunächst scheint, wird in der heutigen Wissenschaft eine Datierung des Buches Ester in das 3. Jahrhundert v. Chr. vertreten. Dafür spricht außerdem, dass das Thema Judenverfolgungen in der Zeit der Diadochenkämpfe nach dem Tod Alexanders des Großen aktuell war.

Das Esterbuch in der Septuaginta hat erhebliche Veränderungen und Zusätze zum hebräischen Text, die wohl erst einige Zeit später geschrieben wurden (1. Jahrhundert vor Christus). In der Lutherbibel stehen die Zusätze als „Stücke zu Ester“ unter den Apokryphen.

Der im Buch Ester genannte persische König Ahasveros bzw. Ahaschverosch wird üblicherweise mit Xerxes I. gleichgesetzt, worauf einige der nachfolgend genannten Argumente beruhen; daneben hat es auch andere, weniger verbreitete Identifikationsversuche gegeben.

Vertreter der historischen Glaubwürdigkeit des Buches Ester weisen darauf hin, dass sich manche im Buch beschriebenen Einzelheiten gut in unser historisches Bild vom achämenidischen Hof fügen, so etwa der Luxus am Hof, der königliche Wein und das Charakterbild von Achaschwerosch bzw. Xerxes als eigensinnig und leicht beeinflussbar durch Frauen und Günstlinge. Ferner beschreibt der griechische Geschichtsschreiber Herodot weitere persische Bräuche, die dem Verfasser des Esterbuches offensichtlich auch bekannt waren, wie etwa die sieben fürstlichen Ratgeber (vgl. Herodot, Historien III 83f.). Zudem enthält das Buch Ester etliche persische Namen und Wörter. Allerdings hätte dieses „Perserreich-Kolorit“ (E. Zenger) auch dann von einem gut informierten Autor in das Esterbuch eingebaut werden können, wenn es sich dabei um eine fiktive Erzählung handelt; damit alleine lässt sich also der historische Charakter nicht beweisen.

Vertreter der historischen Unglaubwürdigkeit des Buches Ester stellen u. a. folgende Punkte heraus:


Nach dem Urteil der heutigen historisch-kritischen Forschung besteht „äußerste Skepsis“, ob das Buch Ester einen tatsächlichen historischen Hintergrund hat: „Primär handelt es sich um ein literarisches Kunstwerk, um Dichtung, nicht um einen historischen Bericht“ (Esther Brünenberg). Es wird auch angenommen, dass das Buch Ester wohl erst nachträglich die Legende zum Purimfest geworden ist, welches vorgegeben war und wohl „als eine Art Neujahrsfest im persischen oder mesopotamischen Raum vom Judentum übernommen“ wurde.


Heute besteht allgemeiner Konsens über Zugehörigkeit des Buches Ester zum biblischen Kanon. Die Kanonizität des Buches war jedoch sowohl unter Juden als auch unter Christen historisch umstritten. Einige Rabbiner des ersten christlichen Jahrhunderts wollten es ausgeschlossen sehen, einige Kirchenväter sahen das Buch als zweitrangig an, Luther lehnte es als zu jüdisch bzw. „heidnisch“ ab.

Bildende Kunst

Literatur

Musik

Film





</doc>
<doc id="10333" url="https://de.wikipedia.org/wiki?curid=10333" title="Esther">
Esther

Esther oder Ester ist ein weiblicher Vorname.

Der etymologische Ursprung des Namens Esther ist unklar. Möglicherweise ist er altpersischen Ursprungs und bedeutet „Stern“. Eine Verwandtschaft mit dem alt-irakischen "Ischtar" (und damit dem Namen der syrischen/kanaanäischen Göttin "Astarte") erscheint wenig plausibel, da die Geschichte des Buchs nicht im Irak, sondern in Persien spielt (genauer: in der persischen Hauptstadt Susa). Im Buch Esther im Tanach ist dies der persische Name der Jüdin Hadassa, die zur Gemahlin des Perserkönigs Xerxes I. (hebräisch: אחשורוש, Achaschwerosch) wird. Esther ist eine historisch nicht nachgewiesene Gestalt der jüdischen Überlieferung, die die Juden während ihrer Zeit der Diaspora im Perserreich durch eine kluge Tat vor der Vernichtung bewahrt haben soll.

24. Mai (katholisch)


Königin Ester, Gattin des persischen Königs Achaschwerosch (Xerxes I.), Hauptperson des biblischen "Buches Ester"






</doc>
<doc id="10335" url="https://de.wikipedia.org/wiki?curid=10335" title="Hiob">
Hiob

Hiob bezeichnet:

Hiob ist der Name folgender Personen:
HIOB ist die Abkürzung für:


</doc>
<doc id="10337" url="https://de.wikipedia.org/wiki?curid=10337" title="Kote">
Kote

Kote steht für:


Siehe auch:


</doc>
<doc id="10338" url="https://de.wikipedia.org/wiki?curid=10338" title="Buch der Psalmen">
Buch der Psalmen

Das Buch der Psalmen, auch der Psalter genannt, ( "sefer tehillim") ist ein Buch des Tanachs, die erste der Ketuvim („Schriften“). Im Alten Testament gehört es zur Weisheitsliteratur und steht dort an zweiter Stelle. Es ist eine Sammlung von 150 Psalmen, also Gebeten und Liedern, die in fünf Bücher eingeteilt sind. Die Psalmen spielen in der Liturgie des Judentums wie auch des Christentums eine bedeutende Rolle und wurden vor allem in Musik und Literatur vielfach aufgegriffen. In der griechischen Übersetzung der Septuaginta und daraus abgeleitet in allen orthodoxen Psaltern gehört noch Psalm 151 zum Buch der Psalmen.

Die in der christlichen Tradition übliche Bezeichnung "Buch der Psalmen" oder "Psalmen" geht über den lateinischen Titel "liber psalmorum" oder kurz "psalmi" der Vulgata zurück auf das griechische ψαλμός ("psalmós", Plural "psalmoi"), vom Verb ψάλλειν ("psallein", „die Saiten spielen“).<ref name="Zenger2008/350"></ref> Es wird in den meisten griechischen Handschriften der Psalmen und auch in neutestamentlichen Anführungen (z. B. ) gebraucht.

Die Bezeichnung "Psalter" lässt sich über das lateinische "Psalterium" auf das griechische ψαλτήριον "(Psalterion)" zurückführen, das in der Septuaginta des Codex Alexandrinus aus dem 5. Jahrhundert verwendet wird. Es bezeichnet sowohl ein großes Saiteninstrument (Psalterium) wie auch eine Sammlung von Liedern, die zu dessen Begleitung gesungen werden.
Beide Bezeichnungen sind vermutlich eine Entsprechung für das nur im Buch der Psalmen vorkommende hebräische מִזְמור ("mizmor", umschreibbar als „kantilierender Sprechgesang mit Saitenspielbegleitung“), mit dem 57 der 150 Psalmen überschrieben sind.

Eine hebräische Bezeichnung für die Psalmen, auf die die griechische zurückgehen könnte, ist nicht bekannt, auch wenn der Gebrauch der Pluralform "mizmorot" im palästinischen Schrifttum als Bezeichnung für die Gesamtheit der Psalmen belegt ist. In der rabbinischen Literatur durchgesetzt hat sich dagegen die Bezeichnung סֵפֶר תְּהִלִּים ("Sefer tehillim", „Buch der Lobpreisungen“) oder kurz "Tillim" (aramäisch "Tillin"), die im Judentum seither verwendet werden, obwohl nur ein Teil der Psalmen Lobgesänge sind. Der unregelmäßige männliche Plural geht auf die weibliche Singularform "tehillah" („Lobgesang“) von הלל (hll, „preisen“) zurück, mit der jedoch allein Psalm 145 überschrieben ist. Zur Wahl der Bezeichnung "Tehillim" für die gesamte Textsammlung hat möglicherweise der vom selben Wortstamm abgeleitete populäre liturgische Kehrvers Halleluja, „preiset den Herrn“, beigetragen.

Die einzelnen Psalmen des Psalters haben ihre je eigene Entstehungsgeschichte. Grundfassungen einzelner Psalmen – vor allem Königspsalmen und Zionshymnen – sind wahrscheinlich vor dem Babylonischen Exil in der israelitischen Königszeit entstanden.
Die meisten Psalmen stammen jedoch aus nachexilischer Zeit, also frühestens aus dem späten 6. Jahrhundert v. Chr.

Das Psalmenbuch besteht aus ursprünglich selbständigen Teilsammlungen aus dem 6. bis 3. Jahrhundert v. Chr., die in mehreren Phasen zusammengestellt wurden. Wann die Sammlung abgeschlossen wurde, ist zwar unsicher, in der Forschung werden aber tendenziell die Jahre zwischen 200 und 150 v. Chr. angegeben. Dafür spricht die Nähe zur späten Weisheitsliteratur, die bei den jüngsten redaktionellen Bearbeitungen des Psalters erkennbar wird.

Außerdem war eine Sammlung von Psalmen bereits in der Gemeinde von Qumran eine feste Größe. Die große Psalmenrolle aus Qumran (11QPs) aus dem 1. Jahrhundert v. Chr. umfasst 40 Psalmen von Psalm 101 bis 150, dazu Psalm 151, der sonst nur in den griechischen Septuaginta-Handschriften enthalten ist, die Psalmen 154 und 155 und außerdem fünf weitere sonst nicht bekannte Texte. Die Reihenfolge der Psalmen unterscheidet sich dabei von der späteren Zusammenstellung. Ob dies ein Hinweis auf den noch grundsätzlich unabgeschlossenen Prozess der Zusammenstellung des Psalmenbuches ist oder lediglich eine für Qumran spezifische individuelle Abweichung darstellt, ist unsicher.

Der älteste schriftliche Beleg für die abgeschlossene Buchgestalt des Psalters ist eine Handschrift aus der zweiten Hälfte des 2. Jahrhunderts v. Chr.

In der hebräischen Bibel wird das Psalmenbuch an die Spitze des dritten und letzten Teils, der „Schriften“ (Ketuvim) gestellt. So ist die Reihenfolge auch in der griechischen Septuaginta. Die christliche Tradition ordnet die Psalmen dagegen übereinstimmend vor den „Propheten“ bei den Weisheits- bzw. Lehrbüchern an zweiter Stelle hinter das Buch Ijob ein.

Das Psalmenbuch in der heutigen Form ist eine redaktionelle Zusammenstellung von fünf ursprünglich eigenständigen Büchern mit einer je eigenen Entstehungsgeschichte. Der 1. Psalm steht dem Buch wie ein Motto vor. Er lautet nach der Einheitsübersetzung:

Bei der Kombination der fünf Teilsammlungen erhielt jede von ihnen einen eigenen neuen Abschluss in Form einer Doxologie. Diese Preisungen Gottes münden zum Schluss in die fünf Halleluja-Psalmen, das sogenannte „Schluss-Hallel“ (Psalmen 146–150). Durch diesen Aufbau erhält der Psalter eine Strukturierung, die ihn formal der fünfteiligen Tora zuordnet. Im späteren rabbinischen Midrasch "Tehillim" (spätestens aus dem 11. Jahrhundert) heißt es dazu: „Mose gab den Israeliten die fünf Bücher der Tora, und David gab den Israeliten die fünf Bücher der Psalmen.“

Die vollständige Liste der Psalmen findet sich im Artikel Psalmenüberschriften.

Im Psalmenbuch lassen sich Gruppierungen und Verwandtschaften unter den Psalmen ausmachen, die Rückschlüsse auf ihre Entstehung, ihren Sitz im Leben und spirituellen Gehalt zulassen:


Während es im Tanach an verschiedenen Stellen Psalmen als Lieder, Hymnen und Klagen gibt (z. B. Lied des Mose , Lied der Hannah und Psalm des Jona ), so findet sich jedoch im Buch der Psalmen bei weitem der größte Bestand.

Inhaltlich befassen die Psalmen sich vor allem mit folgenden Themen:

Die meisten Psalmen sind in der hebräischen Gedichtform geschrieben, die durch den Parallelismus membrorum (lateinisch: „Parallelität der Versglieder“) charakterisiert ist: Zwei (oder drei) aufeinanderfolgende Verse oder Vershälften zeigen einen besonderen inhaltlichen Bezug, indem sie Gleiches unterschiedlich ausdrücken (synonymer Parallelismus), sich ergänzen (synthetischer Parallelmus) oder einen Gegensatz bilden (antithetischer Parallelismus).

Beispiel für synonyme Parallelismen:

Beispiel für synthetische Parallelismen:

Beispiele für den antithetischen Parallelismus:

Im Hebräischen sind die meisten Psalmen mit Überschriften versehen, die von kurzen Verfasserangaben über heute kaum mehr verständliche musikalische Angaben bis zu mehrere Sätze langen Situationsschilderungen reichen.
Das nachexilische Judentum schrieb fast die Hälfte der Psalmen dem König David zu. Bei etwa 20 der 72 Psalmen Davids liefert die Überschrift zusätzliche Angaben zur Verbindung des Psalms mit Situationen aus seinem Leben. Zwar könnte eine Autorschaft Davids dadurch historisch plausibel erscheinen, dass im Tanach auch außerhalb des Psalters von David als „Leierspieler“ und „Dichter“ gesprochen wird. Bei der Zuschreibung seiner Autorschaft handelt es sich jedoch nicht um eine Aussage zur generellen Entstehungsgeschichte der (Davids-)Psalmen, sondern zu ihrer Bedeutung für das jüdische Volk, die durch die Figur des Königs David betont wird. In diesem Sinne spricht man auch von einer „Davidisierung“ der Psalmen. Dabei kann die hebräische Überschrift „ldawid“ einerseits verstanden werden als „von David“, womit ihre geistliche Dignität ausgedrückt wird, andererseits als „für David“, womit das Volk Israel seine Hoffnung auf messianische Vollendung im Beten der Psalmen ausdrückt. Auch für die als Psalmendichter genannten Mose und Salomo unterstreicht deren Autorität die Bedeutung der Texte und reiht sie ein in die Tradition Israels.

Bei den "Asaf-" und "Korachpsalmen" handelt es sich um Texte, die aus diesen beiden Jerusalemer levitischen Sängergilden stammen und möglicherweise Teil des Tempelkultes waren.

Die griechische Übersetzung der Septuaginta fügt weitere Überschriften hinzu, die wohl aus einer anderen hebräischen Textquelle stammen. Somit haben in der Septuaginta und in den aus dieser abgeleiteten Übersetzungen alle Psalmen eine Überschrift, mit Ausnahme der beiden ersten. Bereits damals wurden die musikalischen Angaben des hebräischen Textes in großen Teilen nicht mehr verstanden; deren entsprechend kryptische griechische Übertragungen boten später Anlass zu vielfältiger symbolischer und mystischer Interpretation.

Die deutschen Übersetzungen fügen weitere Überschriften hinzu. Sie stehen nicht im hebräischen Urtext, sondern wurden erst von den Übersetzern zum besseren Auffinden und zur Orientierung hinzugefügt.

Im Psalmenbuch folgt die Kapiteleinteilung den einzelnen Psalmen und ist daher ursprünglich. Darin unterscheidet sich das Buch von allen anderen Büchern der Bibel, wo die Einteilung in Kapitel erst im Mittelalter erfolgte. Die Nummerierung der Verse kam mit dem Buchdruck im Gefolge von Robert Estienne auf, folgt aber größtenteils der natürlichen Verseinteilung der poetischen Texte wie sie schon von den Masoreten vorgenommen wurde. Bei einer Reihe von Psalmen (Psalm 9, 10, 25, 34, 37, 111, 112, 119 und 145) folgen die Versanfänge dem hebräischen Alphabet.

Die Nummerierung der Psalmen unterscheidet sich geringfügig zwischen dem hebräischen Text in der masoretischen Textfassung einerseits und den Übersetzungen der griechischen Septuaginta und der lateinischen Vulgata andererseits, da der in der Liturgie verwendete lateinische Text der Psalmen auf der Septuaginta beruht – anders als die anderen alttestamentlichen Texte der Vulgata, die Hieronymus direkt aus dem Hebräischen übersetzt hat. Evangelische Bibeln zählen wie der Urtext, den Martin Luther für seine Übersetzung verwendete. Ältere katholische Bibeln verwendeten die Zählung der Septuaginta bzw. Vulgata. Die in der katholischen Kirche jetzt verwendete lateinische Bibelausgabe, die 1979 herausgegebene "Nova Vulgata," folgt der Nummerierung des masoretischen Texts. Daher muss man bei Verweisen auf Psalmen darauf achten, auf welche der beiden Nummerierungen sich ein Verweis bezieht. Oft werden die Psalmnummern in der Form "Ps 51(50)" angegeben. Die höhere Nummer bezieht sich dabei auf die vorlaufende hebräische Zählung.

Der griechische Text der Septuaginta kennt einen zusätzlichen Psalm 151, der jedoch in seinem Titel als „außerhalb der Nummerierung“ bezeichnet wird. Bei den orthodoxen Kirchen blieb dieser Psalm hingegen im Kanon. Die hebräische Fassung dieses apokryphen Psalms ist in einer Qumran-Handschrift belegt.

Bei der Nummerierung der Verse eines Psalms unterscheiden sich englischsprachige Bibeln vom hebräischen Urtext und von deutschen Übersetzungen dadurch, dass sie den Überschriften im Urtext keine Versnummer zuteilen. Ist die Überschrift mindestens einen ganzen Vers lang, bleibt so die Versnummer in der englischen Bibel um 1 oder 2 hinter der anderen Nummerierung zurück. Betroffen sind 62 Psalmen, drei davon (51, 52, 60) mit einer Differenz von 2.

Das Buch der Psalmen ist das Gebetbuch der Juden und der frühen Christen. Im Islam wird das Buch der Psalmen, Zabur (arabisch زبور, DMG Zabūr) genannt, zu den heiligen Büchern gezählt und im Koran in den Suren 4,163, 17,55 und 21,105 erwähnt.

Die Psalmen waren nicht das Gesangbuch des Zweiten Tempels, auch wenn einzelne Psalmen dort von Tempelmusikern mit Instrumentenbegleitung vorgetragen wurden (z. B. die Wallfahrtspsalmen). Die Lieder und Gebete des Buches Tehillim stellen bis heute einen unverzichtbaren Bestandteil der traditionellen jüdischen Liturgie dar. Dabei kommt den Psalmen 113 bis 118, dem sogenannten "Hallel", eine besondere Bedeutung zu. Er wird an den Feiertagen und an Rosch Chodesch jeweils nach Abschluss des Schacharit, d.h. vor dem Ausheben des Sefer Tora, gesungen. Die Psalmen sind auch ein Buch der privaten Frömmigkeit und sind dies (als Frauengebetbuch, neben dem Siddur) im Judentum bis heute. Dazu wird das Psalmbuch in 30 Abschnitte geteilt, die den Tagen eines Monats gemäß dem jüdischen Kalender zugeordnet sind. Die Psalmen werden, anders als in der christlichen Tradition, mit ihren Überschriften, aber ohne rahmende Verse (Antiphonen) gebetet.

Erst spät wurden Psalmen zu einem Teil des Synagogengottesdienstes.

Das Stundengebet der römisch-katholischen, orthodoxen, lutherischen und anglikanischen Kirche besteht vorwiegend aus Psalmen und den zugehörigen Antiphonen. Psalmen werden in der Heiligen Messe, bei der Spendung von Sakramenten und Sakramentalien, bei Prozessionen und Wallfahrten, beim Begräbnis gesungen. Einzelne oder mehrere Psalmverse sind Bestandteile sowohl des Graduales wie auch des Introitus. Auch die christliche Ikonographie geht häufig auf Motive aus den Psalmen zurück.

Bei der Übersetzung ins Lateinische (Vulgata) hat Hieronymus dreimal die Psalmen bearbeitet:

Ein Grund für das Vorgehen war, dass er nicht ohne Not in die bekannten Texte der Liturgie eingreifen wollte. Die Version „iuxta Hebraeos“ war eher für Gelehrte gedacht und wurde in der Liturgie nicht verwendet.

Martin Luther nannte die Psalmen die „kleine Biblia“ und weist damit auf den umfassenden religiösen Reichtum des Psalters hin. Johannes Calvin schrieb in der Einleitung seiner Auslegung der Psalmen: „Mit gutem Grund nenne ich gewöhnlich das [Psalm]buch eine Aufgliederung [die Anatomie] aller Teile der Seele“. Papst Benedikt XVI. bezeichnete die Psalmen als Geschenk Gottes an Israel und die Kirche und als „Schule des Gebets“, insofern das Wort Gottes zum Wort des Betenden werde.

Unter "liturgischem Psalter" versteht man in der Liturgiewissenschaft das Verteilungssystem der Psalmen bzw. der Psalmantiphonen auf die Tagzeiten (Horen) im Stundengebet. Als Verteilungssystem stellt der liturgische Psalter zugleich ein „Psalmpensum“ dar, das heißt, das vorgeschriebene Gebet eines Quantums an Psalmen innerhalb eines bestimmten Zeitraumes.

Viele Psalmen sind als Psalmodien, Kirchenlieder und liturgische Gesänge vertont. Dazu wurden ihre Texte häufig in eine Reim- und Strophenform überführt. Künstler befassen sich bis heute oft mit Psalmen in Nachdichtungen oder Vertonungen. Der Psalter hat auch einem Musikinstrument, dem Psalterium, den Namen gegeben.






Texte

Darstellungen

Bearbeitungen

Nummerierung


</doc>
<doc id="10339" url="https://de.wikipedia.org/wiki?curid=10339" title="Psalter">
Psalter

Psalter (kirchenlat. "psalterium" zu altgriechisch ψαλτήριον "psaltḗrion", zu "Psalm") ist:



</doc>
<doc id="10341" url="https://de.wikipedia.org/wiki?curid=10341" title="Psalm">
Psalm

Ein Psalm (Plural "Psalmen") (von gr. "psalmós" „Saitenspiel, Lied“) ist im Judentum und Christentum ein poetischer religiöser Text, oft mit liturgischer Funktion. Die Bezeichnung wird vor allem verwendet für die 150 Gedichte, Lieder und Gebete des Buches der Psalmen der hebräischen Bibel bzw. des Alten Testaments (auch "Psalter" genannt). Daneben existieren weitere Texte in der biblischen wie in der außerbiblischen Literatur, in Überlieferung und Gebetspraxis, die als Psalmen bezeichnet werden.

Der griechische Name ψαλμός ("psalmós") stammt vom Verb ψάλλειν ("psallein") = „die Saiten schlagen“. Er bezeichnet einen Gesang mit Saitenbegleitung und kann wörtlich übersetzt werden als „gezupftes Lied“. Die griechische Bezeichnung gibt das hebräische Wort ("mizmor") wieder, was als „kantilierender Sprechgesang mit Saitenbegleitung“ umschrieben wird.

Die Psalmen haben Vorbilder in der altorientalischen Literatur, sind jedoch in ihrer Dramatik und persönlich-geschichtlichen Aussage ohne Parallele. Herkunft, Entstehungszeit und „Sitz im Leben“ der einzelnen Psalmen sind je nach Anlass sehr unterschiedlich. Die ältesten Psalmen der Bibel stammen wohl aus der Zeit vor dem babylonischen Exil und aus der israelitischen Königszeit.

Die Psalmen zeigen die typische Technik der hebräischen Versdichtung, den "parallelismus membrorum" („parallel gestaltete Glieder“). Dabei werden zwei (oder selten drei) aufeinander folgende Zeilen als zusammengehörig gestaltet, indem die Aussage der ersten Verszeile in den nachfolgenden unter anderer Perspektive dargestellt wird. Dies kann als Wiederholung („synonymer Parallelismus“), als Gegensatz („antithetischer Parallelismus“) oder als Weiterführung („synthetischer Parallelismus“) der Aussage geschehen. 

Ihrem Inhalt und ihrer Form nach werden Psalmen in verschiedene Gattungen unterteilt. Diese Kategorisierung geht zurück auf die gattungsgeschichtlichen Untersuchungen Hermann Gunkels und Joachim Begrichs, wobei Übergänge zwischen den Formen häufig sind und jeder Psalm „eine spezifische Gestalt und eine individuelle Biografie“ hat, die ihn als Gebet einzigartig macht:

Etwa die Hälfte der Psalmen innerhalb des Psalters verweisen in ihrer Überschrift auf König David und werden daher Davidpsalmen genannt, einzelne verweisen auf einen anderen Urheber, etwa Asaf oder Korach.

Klage-, Dank- und Bittpsalmen werden weiterhin unterschieden nach der Zahl der Betenden in Psalmen des Einzelnen (z. B. ) oder des Volkes (z. B. ). 

Die Klage führt nicht selten zu einem „Wendepunkt“, mit dem sich das Gebet nach göttlichem Rettungshandeln in Lob und Dank wandelt.

Die meisten Psalmen finden sich im Buch der Psalmen, aber es finden sich einzelne Psalmen auch außerhalb dieses Buches. In der Tora sind etwa das Siegeslied am Schilfmeer oder das Lied des Mose zu nennen. Hymnen und Danklieder sind das Deboralied und das „Magnificat der Hanna“ . Dazu kommen Psalmen aus dem Hohenlied, dem Buch Ijob und den Prophetenbüchern (z. B. , ). Besonders bekannt ist auch der Psalm des Jona aus dem Bauch des Walfisches . Auch die Klagelieder Jeremias kann man zu den Psalmen rechnen. Daneben zu nennen sind auch Davids Gebete im 2. Buch Samuel (2Sam 1,7; 22 = Ps 18; 2Sam 23,1ff).

Unter den Schriftrollen vom Toten Meer der Gemeinde von Qumran finden sich 120 Psalmen, die in den Höhlen 1, 4 und 11 gefunden wurden, die teilweise mit den in der hebräischen Bibel kanonisierten übereinstimmen.

Nicht Bestandteil eines biblischen Kanons ist die als Psalmen Salomos bezeichnete Sammlung von 18 Dichtungen vermutlich aus dem 1. vorchristlichen Jahrhundert, die König Salomo zugeschrieben wurden. Die Septuaginta hat einen 151. Psalm, der nicht im hebräischen Psalmenbuch vorhanden ist.

Diskutiert werden kann die Einordnung der Gattung als ein Danklied des/der Einzelnen oder als Hymnus.

Die Bezeichnung "Magnifikat der Hanna" legt sich nahe, da Lk 1,46-55 (Magnifikat der Maria) 1Sam 2,1-10 zu rezipieren scheint. Belege hierfür wären einige übereinstimmende Schlüselbegriffe (σωτηρία/σωτήρ, δυνατος, θρόνος, ...).

Häufige Wortfelder in 1Sam 2,1-10 sind einerseits hoch sein/erhöhen und andererseits fallen/erniedrigen. Es scheint sich eine konzentrische Struktur um V.6f (JHWH – Herr über Tod + Leben) zu bilden, worin auch die theologische Kernaussage zu besteht. Schlüsselthemen sind darüber hinaus:


Einige Texte aus dem Neuen Testament werden der Gattung „Psalm“ zugeordnet, da sie diese Texttradition voraussetzen und aufnehmen oder sogar auf jüdische Vorlagen zurückgehen. Daher werden das Magnificat , das Benedictus und das Nunc dimittis manchmal auch explizit als Psalmen bezeichnet (meist als Cantica). Auch der Philipperhymnus gehört in diese Reihe.

Nach den Passionsberichten der Evangelien stammen zwei der von Jesus während seines Todeskampfes am Kreuz gesprochenen Sieben Letzten Worte aus den Psalmen ( und ).

Das aus dem Judentum entstehende Christentum übernahm die Psalmen – insbesondere das vollständige Buch der Psalmen des Alten Testaments – als Grundstock der eigenen Gebetssprache. Dabei wurden viele Psalmen so gedeutet, dass sie auf Jesus Christus verweisen bzw. dieser selbst in ihnen spreche. Als einer der bekanntesten Psalmen gilt der Psalm 23 mit dem Titel „Der Herr ist mein Hirte“. Dieser thematisiert den Schutz und die Sicherheit im „Haus des Herrn“.

In den christlichen Kirchen gehen die meisten liturgischen Gesangsformen auf die Psalmen zurück. Das Singen von Psalmen auf verschiedene melodische Modelle wird Psalmodie genannt. Vor allem bilden die (gesungenen oder gesprochenen) Psalmen den Hauptinhalt des Stundengebets. Dort werden sie regelmäßig mit der trinitarischen Doxologie "Gloria Patri" abgeschlossen. Daneben nimmt seit altkirchlicher Zeit der Gesang von frei gedichteten Hymnen in allen Liturgietraditionen breiten Raum ein. Die deutsche Reformation schuf die Gattung des volkssprachlichen Kirchenlieds, für das häufig Psalmen in eine Reim- und Strophenform gebracht wurden. In der reformierten Tradition galt das Psalmlied im Anschluss an Calvin lange als einzig legitimer gottesdienstlicher Gesang (Genfer Psalter). Nahezu alle geistlichen Dichtungen sind bis heute geprägt von Psalmenmotiven und Psalmensprache.





</doc>
<doc id="10347" url="https://de.wikipedia.org/wiki?curid=10347" title="Buch Josua">
Buch Josua

Das Buch Josua, auch Jehoschua oder Joschua genannt von (hebr. יְהוֹשֻׁעַ, "Jehoschua") ist das sechste Buch des Tanach und des Alten Testaments der christlichen Bibel. Es beschreibt die Eroberung und frühe Besiedlung Kanaans durch die israelitischen Stämme von der Zeit nach dem Tod Moses bis zum Tod Josuas. Seit dem Mittelalter wird es in 24 Kapitel unterteilt.

Das Buch Josua ist benannt nach dem Ephraimiter Josua, dem Sohn des Nun. Josua wird dargestellt als Diener des Mose, der später zu seinem Nachfolger und zum Heerführer ernannt wurde (; ; ). Der Verfasser ist namentlich unbekannt, steht aber in enger Verbindung zur Tora. Die Tora wird ausdrücklich erwähnt in , , und deren theologische Konzeption weitergeführt. Die Verbindung ist so eng, dass einige Forscher Tora und Josuabuch zusammenfassen zum Hexateuch. Das Josuabuch schließt direkt an die Erzählung der Tora an und berichtet den Einzug in das Gelobte Land, das Ende der Wüstenwanderung und die Aufteilung des Landes auf die Stämme. Das Buch deutet sogar die Fortsetzung der Tora durch Josua an in .

Das Buch Josua besteht aus drei Hauptteilen.

Die Kapitel 1–12 beschreiben die Überquerung des Jordans und Eroberung des Westjordanlandes durch die Israeliten. In diesen Kapiteln sind mehrere ätiologische Sagen enthalten. Sie sind an der Schlussformulierung „bis auf diesen Tag“ erkennbar.

In erfolgt eine Aufzählung der eroberten Gebiete und in Kapitel 12 eine Aufzählung der geschlagenen Könige.

Die Kapitel 13–21 beschreiben detailliert die Verteilung des Landes auf die zwölf Stämme Israels. Die vielfältigen Angaben lassen sich anhand weiterer Belege als historisch zuverlässige Beschreibung der Siedlungsgebiete der einzelnen Stämme erkennen, die jedoch teilweise aus späterer Zeit sind. Die Wüstenwanderung hat somit ihr Ziel erreicht mit dem „Land, darin Milch und Honig fließen“. Alle Stämme, Sippen und Familien bekommen ihren Teil an dem Land, auch die Leviten, die keinen eigenen Landbesitz haben, bekommen ihre Wohnstätte zugewiesen.

Den Schluss bilden in Kapitel die Rückkehr der Männer der Oststämme zu ihren Stammesgebieten. In und finden sich ausführliche Reden Josuas und die Erneuerung des Bundes zu Sichem.

In der Septuaginta, der griechischen Übersetzung der hebräischen Bibel, wird der Name Jehoschua von aramäisch Jeschua/Jeschu als Jesus (Ἰησοῦς, Iesous) transliteriert.


Einführung

Kommentare

Einzelstudien



</doc>
<doc id="10348" url="https://de.wikipedia.org/wiki?curid=10348" title="Buch der Sprichwörter">
Buch der Sprichwörter

Das Buch der Sprichwörter (Buch der Sprüche oder Sprüche Salomos, , "Mischle [Schelomo]") ist ein Buch des Tanach und gehört dort zu den Ketuvim (Schriften), also zum dritten Teil des jüdischen Bibelkanons. Im christlichen Alten Testament gehört es zur Dichtung und Weisheitsliteratur, die hier vor die Prophetenbücher gerückt sind.

Die einleitenden Verse des Buches werden traditionell als Angabe zur Urheberschaft Salomos gedeutet. Diese Annahme geht auch auf eine Aussage im 1. Buch der Könige (Kap. 5, Vers 12) zurück, nach der Salomo Dreitausend Sprüche aufgeschrieben habe. Das Buch selbst nennt in Kap. 30 und 31 weitere Quellen (Agur und Lemuel). Ausdrücklich als Verfasser genannt wird Salomo für die Stellen 10,1–22,16 und 25,1–29,27.

Nach jüdischer Tradition geht das gesamte Buch auf "Hiskija, den König von Juda," zurück. (nach dem babylonischen Talmud, Traktat Bava Bathra 15a)

Die gegenwärtige Forschung nimmt eine längere Entstehungszeit der biblischen Sprichwortsammlung an, die von der Zeit des Königs Hiskia bis in das vierte, evtl. sogar dritte Jahrhundert vor Christus reicht. Die ältesten Teile sind vermutlich die dritte und die vierte Sammlung; die erste Sammlung gilt als die jüngste.

Im Neuen Testament der Bibel finden sich 35 Zitate oder Bezüge auf das "Buch der Sprichwörter".


Die Spruchsammlung behandelt eine Vielzahl von Themen; es geht um allgemeine Lebensweisheit (Gesunder Menschenverstand), die sich hier ausspricht. Einiges ist von solcher überzeitlicher Gültigkeit, dass manches auch als deutsches Sprichwort dient, z. B. „Wer dem andern eine Grube gräbt, fällt selbst hinein.“, cf. 26,27.

Einen Schwerpunkt der Sprüche bildet das Thema Erziehung, beziehungsweise Züchtigung, cf.13,24: „Wer seine Rute schont, der hasst seinen Sohn; wer ihn aber lieb hat, der züchtigt ihn beizeiten.“

Der Tun-Ergehen-Zusammenhang kann als eine Art „Grundgesetz“ der Weisheit gelten. Dabei geht es um die „Verlässlichkeit der Welt“ (Markus Witte), die sich in der Überzeugung ausdrückt, dass gute Taten ein gutes Ergehen zur Folge haben und böse ein schlechtes.
11,31: „Siehe, dem Gerechten wird vergolten auf Erden, wieviel mehr dem Gottlosen und Sünder!“
Dabei gilt Gott als Garant dieses Zusammenhanges, cf. 10,3: „Der HERR läßt den Gerechten nicht Hunger leiden; aber die Gier der Gottlosen stößt er zurück.“

Einzelne Sprüche jedoch stellen angesichts gegenteiliger Erfahrungen (cf. Psalm 49; 73; Buch Ijob) die Unverfügbarkeit des Handelns Gottes heraus, z. B.16,9 „Des Menschen Herz erdenkt sich seinen Weg; aber der HERR allein lenkt seinen Schritt.“

In der vorliegenden Fassung des Buches ist die Weisheit theologisch gedeutet, wie das das Buchmotto in 1,7 deutlich macht: „Die Furcht des HERRN ist der Anfang der Erkenntnis.“ Die personifizierte Weisheit ist Mittlerin zwischen Gott und Mensch (vgl. Kapitel 1, Weisheit in der Rolle einer Prophetin und Kapitel 8, Weisheit als Schöpfungsmittlerin).




</doc>
<doc id="10350" url="https://de.wikipedia.org/wiki?curid=10350" title="Hoheslied">
Hoheslied

Als Hoheslied (auch: Hohelied Salomos, seltener: Hohes Lied) bezeichnet man ein Buch des Tanachs, wo es zu den fünf Megillot zählt, bzw. des Alten Testaments. Es handelt sich um eine Sammlung von zärtlichen, teilweise explizit erotischen Liebesliedern, in denen das Suchen und Finden, das Sehnen und gegenseitige Lobpreisen zweier Liebender geschildert wird.

Der Buchtitel lautet . Er bedeutet wörtlich „Das Lied der Lieder“ und drückt den hebräischen Superlativ aus (sinngemäß: „Das schönste aller Lieder“). Dem entspricht auch weitgehend der Titel in der griechischen Septuaginta ("ásma asmáton") und in der lateinischen Vulgata "Canticum Canticorum".

Die Bezeichnung „Hoheslied“ geht auf die Bibelübersetzung Martin Luthers zurück, der das Buch „Das Hohelied Salomonis“ nannte.

Im Deutschen werden heute geringfügig unterschiedliche Schreibweisen verwendet. In der Fachliteratur und im religiösen christlichen Sprachgebrauch herrscht die Schreibweise „Hoheslied“ vor (seltener „Hohes Lied“). Der Duden empfiehlt hingegen die Form „Hohelied“ ohne Flexion des Adjektivs (also z. B. „des Hoheliedes“). In der Fachsprache wird der Begriff überwiegend in beiden Wortbestandteilen gebeugt (also „des Hohenliedes“). Die Wikipedia folgt gemäß ihrer der Fachsprache.

Konsens herrscht mittlerweile hinsichtlich des Befundes, dass es sich bei dem Hohenlied um eine Sammlung ursprünglich selbstständiger Liebeslieder handelt. Umstritten ist, ob die Lieder nach einem übergreifenden Konzept angeordnet wurden. Dabei lassen sich grundsätzlich drei Auffassungen unterscheiden: Eine deutet das Hohelied als eine fortschreitende Geschichte (u. a. André Robert, 1963), eine zweite liest es als Drama (u. a. Origenes, 244; Christoph Uehlinger, 2001), während eine dritte es als eher lose Zusammenstellung betrachtet (u. a. Keel, 1992; Zakovitch, 2004). Die Deutung des Hohenliedes als lockere Zusammenstellung kann als "common sense" betrachtet werden, wobei die Verwendung einiger refrainartiger Elemente (z. B. Beschwörung der Töchter Jerusalems: 2,7; 3,5; 8,4; Zusammengehörigkeitsformel: 2,16, 6,3; 7,11) und wiederkehrende Motive (z. B. das Garten-Motiv: 4,12.15.16; 5,1; 6,2.11; 8,13) der Sammlung einen gewissen strukturellen Zusammenhang verschaffen.

Im Hohenlied treten wechselweise ein Mann, eine Frau und eine Art Chor als Sprecher auf. Der Mann wurde traditionell oft mit Salomo identifiziert (die Zuschreibung im Gedicht ist unklar; dort, wo der Name „Salomo“ fällt, muss dies nicht der männliche Sprecher sein); mitunter wurde auch ein Liebesdrama zwischen drei Personen (Frau, einem einfachen Hirten und König Salomo als dessen Nebenbuhler) angenommen. Der Name der Frau wurde aufgrund der Nennung in Hld 7,1 meist mit Sulamith wiedergegeben. Dabei ist jedoch zu beachten, dass dem Sammlungscharakter des Hohenlieds entsprechend hier ursprünglich unterschiedliche Frauen- und Männerfiguren gesprochen und gehandelt haben.

Seit dem Mittelalter wird das Hohelied in acht Kapitel unterteilt.

Die Entstehungszeit des Hohenliedes ist stark umstritten. Die Nennung Salomos zu Beginn des Hohenliedes wird allgemein nicht als ausreichendes Indiz für eine Urheberschaft Salomos gedeutet. Dennoch schließen einige Theologen eine (Teil-)Urheberschaft Salomos nicht aus oder ordnen die Entstehung des Hohenliedes zumindest dem salomonischen Umfeld zu. Ein Argument für das mögliche hohe Alter der Dichtung ist seine Nähe zu ägyptischer Lyrik des Neuen Reichs.

Andererseits werden aramaisierende Sprachformen, ein persisches Lehnwort ("pardes"; Park in Hld 4,13) sowie verschiedene Bezeichnungen für exotische Würz- und Duftstoffe angeführt, die darauf hindeuten, dass das Hohelied seine abschließende Form erst nach 500 v. Chr. erhalten hat.

Parallelen zur griechischen Poesie und diverse griechische Bräuche (z. B. königliche Prachtsänfte in Hld 3,9 – 10; Bräutigamsbekränzung in Hld 3,11) im Hohenlied weisen wiederum auf die hellenistische Periode, d. h. das 3. Jh. v. Chr, hin.

Die erhaltenen Textzeugen aus den Höhlen von Qumran zeigen zudem Varianten im Textbestand, was darauf hinweist, dass dieser im 2. Jh. v. Chr. noch nicht endgültig feststand.

Der Religionsphilosoph Carl Gebhardt hat sich 1930 in Übersetzung und Kommentaren mit Datierung und Deutung befasst. Ungeachtet älterer anzunehmender Urideen und Textteilen datiert er das Werk in die Zeit des Hellenismus (300 v. Chr.). Er stellte die Motivübereinstimmungen mit der amöbäischen Dichtung Theokrits dar, nachdem bereits den Humanisten des 17. und 18. Jahrhunderts aufgefallen war, dass sich hier Parallelen zur griechischen Dichtung finden. Darauf haben auch Hugo Grotius und Johann Theophil Lessing, ein Bruder von Gotthold Ephraim Lessing, bereits hingewiesen.

Eine kultisch-mythologische Theorie betont die Übereinstimmungen mit sumerischen und akkadischen Texten über die heilige Hochzeit, insbesondere die Verbindung von Dumuzi bzw. Tammuz und der Göttin Inanna/Ištar. Gegen diese Theorie wird angeführt, dass sich das Alte Testament ansonsten deutlich gegen kanaanitische Fruchtbarkeitskulte wendet.

Das Hohelied hat sehnsuchtsvolle bis schwärmerische Äußerungen über die menschliche Liebe und Erotik zum Inhalt. Mann und Frau besingen abwechselnd ihre Liebe zueinander, ihr Verlangen nach dem/der anderen und preisen die Schönheit der geliebten Person. Eine fortschreitende Handlung ist kaum auszumachen, vielmehr geht es um das wechselvolle Zusammenspiel von Begehren und Erfüllung, von Trennung und Vereinigung.

Dabei fällt auf, dass die weibliche Sprecherin wesentlich häufiger zu Wort kommt als ihr männliches Pendant. Auch strukturell stehen ihre Äußerungen an exponierter Stelle, da das Hohelied mit ihrem Sehnsuchtslied (Hld 1,2–4) beginnt und mit der Aufforderung an ihren Geliebten, zu ihr zu eilen (Hld 8,14), schließt. Ebenfalls inhaltlich präsentiert sich die Sprecherin als auffallend aktiv, stark und handlungsmächtig.
Die herausgehobene Stellung der Frau im Hohenlied ist bereits 1857 von Ginsberg festgestellt worden und von der feministischen Theologin Brenner als offener „Gynozentrismus“ bezeichnet worden.

Kennzeichnend für das Hohelied ist eine mehrdeutige, ausgesprochen bildhafte Sprache. Die Schönheit des/der Geliebten (z. B. Augen wie Tauben, Hld 4,1) oder der Liebesakt (z. B. Gang in den Garten, 4,12–5,1) werden in Metaphern gekleidet besungen, die in der Sprache und Kultur Israels, Ägyptens und des Vorderen Orients verankert sind.

Als Verfasser des Hohenliedes wurde in der Antike der biblische König Salomo angenommen. Dies geht vermutlich darauf zurück, dass im Text Salomo selbst genannt wird (1,5; 3,7ff.; 8,11f.) und Salomo als Autor von 1005 Gedichten galt . Diese Verfasserzuschreibung wurde auch vom Mittelalter übernommen und hat bis heute Anhänger.

Gemäß der allegorischen Auslegungsmethode wurde in Antike und Mittelalter von Juden und Christen die erotische Annäherung, von der das Gedicht handelt, als Beschreibung der Liebe zwischen Gott und seinem auserwählten Volk (im Judentum) bzw. zwischen Christus und der Kirche als Braut Christi (im Christentum) interpretiert.

Die älteste Nachricht liefert der Talmud. Im Mischna-Traktat "Jadajim" (III-5) wird berichtet, dass die Synode von Jamnia (um 90 n. u. Z.) zu entscheiden hatte, ob das Lied der Lieder in den Kanon der heiligen Schriften aufgenommen werden sollte. Der Anspruch der Kanonizität wurde von der Schule Hillels trotz des Widerspruchs von Schammai anerkannt.
Diese Interpretation wurde innerhalb des Judentums besonders entschieden von Rabbi Akiba im 2. Jahrhundert betrieben. Er interpretierte das Lied als eine Darstellung der Beziehung zwischen Gott und dem Volk Israel. Folglich verurteilte er entschieden eine weltliche, erotische Auslegung und einen entsprechenden gesanglichen Vortrag des Liedes. Diese Interpretation Akibas war über Jahrhunderte hinweg dominant. In ähnlicher Weise deuteten ihn auch der Targum zum Hohenlied zwischen 700 und 900 nach Christus sowie spätere mittelalterliche Rabbiner wie Saadia Gaon, Schlomo ben Jizchak oder Abraham ibn Esra.

Der Interpretationsstrang wurde vom Christentum fortgesetzt. Dabei handelte es sich beim Bräutigam meist um Christus und bei der Braut um die Kirche (so bei Hippolyt), um die Einzelseele (Origenes) oder um die Jungfrau Maria (Ambrosius von Mailand).

Da auch im christlichen Mittelalter Sulamith häufig als Repräsentation von Maria angesehen wurde, spielte das Hohelied eine herausgehobene Rolle in der Marienfrömmigkeit der christlichen Mystiker. In der Bildenden Kunst ist es häufig der "Hortus conclusus", der als Bildmotiv auf das Hohelied anspielt und zu den marianischen Symbolen zählt. Das Motiv bezieht sich dabei auf die Textstelle "Ein verschlossener Garten ist meine Schwester Braut, ein verschlossener Garten, ein versiegelter Quell" ().

Diese Deutung befand sich seit dem 18. Jahrhundert im Zuge der Aufklärung zunehmend in der Defensive. Vom Beginn des 18. bis in das 19. Jahrhundert lässt sich die „Dramatische Hypothese“ verfolgen, die erstmals den Szenen- und Sprecherwechsel zwischen Frauen- und Männerstimme, Dialogen beider und chorischen Wir-Stücken in den Mittelpunkt rückte. Dabei blieb die genaue Abgrenzung der Einzelelemente jedoch immer kontrovers. Während Georg Wachter das Hohelied 1722 als ein szenisch abgeteiltes Singspiel in fünf Akten sah, interpretierte es Heinrich Ewald 1826 als Hirtenstück.

Gegen die traditionellen religiösen Deutungen und gegen ein rein weltliches Verständnis, wie es seit Herder und Goethe vorherrschte, nahm der jüdische Religionsphilosoph Franz Rosenzweig das Hohelied in Schutz: „Nicht obwohl, sondern weil das Hohe Lied ein ‚echtes‘, will sagen: ein ‚weltliches‘ Liebeslied war, gerade darum war es ein echtes ‚geistliches‘ Lied der Liebe Gottes zum Menschen. Der Mensch liebt, weil und wie Gott liebt. Seine menschliche Seele ist die von Gott erweckte und geliebte Seele.“

Während das Hohelied im Mittelalter sehr häufig kommentiert und als Predigtstoff verwendet wurde – herausragend hierfür sei Bernhard von Clairvaux genannt – spielt es in der heutigen Frömmigkeitspraxis der Großkirchen kaum noch eine Rolle.









</doc>
<doc id="10351" url="https://de.wikipedia.org/wiki?curid=10351" title="Jesaja">
Jesaja

Jesaja (hebr. "Jeschajahu" ) war der erste große Schriftprophet des Tanach. 

Er wirkte zwischen 740 und 701 v. Chr. im damaligen Südreich Juda und verkündete diesem wie auch dem Nordreich Israel und dem anrückenden Großreich Assyrien JHWHs Gericht. Er verhieß den Israeliten aber auch eine endzeitliche Wende zu universalem Frieden, Gerechtigkeit und Heil und erstmals einen zukünftigen Messias als gerechten Richter und Retter der Armen.

Das gleichnamige Buch der Bibel überliefert seine Prophetie in den Kapiteln 1–39. Diese bezeichnet man seit 1892 als Protojesaja.

Im Unterschied dazu werden die Buchteile Deuterojesaja (Jes 40–55) und Tritojesaja (Jes 56–66) auf spätere, exilisch-nachexilische Propheten und deren Tradenten zurückgeführt, die ihre Stoffe dem historischen Jesaja aus der Assyrerzeit zuschrieben. 

Das einheitliche Jesajabuch wurde um 200 v. Chr. bei Jesus Sirach vorausgesetzt; seine älteste bekannte vollständige hebräische Handschrift, die große Jesajarolle, wurde bis spätestens 150 v. Chr. erstellt. Es spielt im rabbinischen Judentum (Talmud) und im Urchristentum (Neues Testament) eine herausragende Rolle. Es eröffnet im jüdischen Bibelkanon die Reihe der „hinteren“, im christlichen Kanon die der „großen“ Propheten.

Der erste Teil (Jes 1–39 oder „Protojesaja“) ist durch die jeweiligen Einleitungssätze gegliedert:

Die ersten 12 Kapitel durchzieht eine vierfache Abfolge von Sündenaufweis, Ankündigung des Gerichts (einer historischen Katastrophe) und Wiederherstellung durch JHWH und/oder einen künftigen messianischen König:

Die mit „Ausspruch für…“ eingeleiteten Abschnitte sind in Gruppen zusammengestellt:
Kapitel 24–27 bilden das Ziel der Fremdvölkersprüche, nun bezogen auf die ganze Erde, und eine thematische Einheit: Laut Jes 24 bewirkt JHWH die Verwüstung der ganzen Erde, laut Jes 25–27 gewährt er inmitten dieser universalen Verwüstung Rettung (25,9; 26,1), nämlich am „Berg“ (25,6–10) bzw. „Berg Zion“ (24,23; 27,13). 

Kapitel 28–35 sind durch den Schrei der Totenklage („Wehe…“) mit wechselnden Adressaten und darin eingestreute Gnaden- und Heilsworte gegliedert:

Die Kapitel 36–39 bieten Erzählungen über Jesaja und den vorexilischen König Hiskija, die großenteils auch in überliefert sind. Diese Fremdberichte kontrastieren die Fremd- und Ich-Berichte in Jes 7–8 und kündigen in Jes 39,1–6 zuletzt das über 150 Jahre später erfolgte babylonische Exil (586–539 v. Chr.) an. Damit wurde der erste (1–39) mit dem zweiten Buchteil (40–66) verknüpft, der das Ende jenes Exils verheißt.

 schreibt das folgende „Gesicht“ einem „Jesaja ben Amoz“ zu, der „zur Zeit des Usija, Jotam, Ahas und Hiskia, der Könige von Juda“ gewirkt habe. Jes 7–8 spielen auf den Untergang des Nordreichs Israel (722 v. Chr.) an. Jes 36–39 und 2 Kön 18–20 bestätigen Jesajas Auftreten unter König Hiskija. Außerbiblische Chroniken bestätigen die dort geschilderte Belagerung Jerusalems beim Feldzug des assyrischen Herrschers Sanherib (703-701 v. Chr.). Daher gilt als gesichert, dass dieser Jesaja ein historischer jüdischer Prophet war, der mindestens zwischen 734 und 701 in Jerusalem und Juda auftrat.

, die Autoren der griechischen Septuaginta und die Kirchenväter betrachteten diesen Propheten als Autor des ganzen nach ihm benannten Buchs. Der Talmud dagegen schrieb es einem Schreiberkollektiv Hiskijas, also mehreren Autoren zu. Ein rabbinischer Traktat aus dem 5. Jahrhundert erklärt das Präsens („Gott sagt“) in Jes 40,1 damit, dass die folgende Prophetie auch nach dem Abtreten des Propheten erging. Der jüdische Kommentator Abraham ibn Esra stellte 1145 fest, dass der Name „Jesaja“ ab Kapitel 40 fehlt: Daher müsse dieser Buchteil analog zum Samuelbuch nach dem Tod des Propheten verfasst worden sein. 

Die historisch-kritische Methode entwickelte sich während der Aufklärung besonders aus dem offenkundigen Widerspruch im Jesajabuch: Ein Prophet, der seit etwa 740 v. Chr. in Jerusalem auftrat, hätte über 200 Jahre alt werden müssen, um das ab Jes 40 angekündigte Ende des babylonischen Exils zu erleben. Er hätte den Perserkönig Kyros II., den Jes 44,28; 45,1 namentlich nennt, nicht voraussagen können. So erklärte der evangelische Alttestamentler Johann Christoph Döderlein 1775 erstmals: Weil der zuvor angekündigte Messias (Jes 9; 11) nicht mit Kyros gleichzusetzen sei, habe wahrscheinlich ein anderer, namenloser Prophet am Ende des babylonischen Exils den Teil Jes 40ff. verfasst. Bernhard Duhm verhalf dieser These 1892 zum Durchbruch in der AT-Forschung. Er nannte den Autor von Jes 40–55 „Deuterojesaja“ und schrieb Jes 56–66 einem weiteren anonymen Propheten zu, den er „Tritojesaja“ nannte. Seitdem wurden mindestens drei verschiedene Propheten angenommen, deren Verkündigung später zu diesem Buch zusammengestellt wurde. 

Während die Zweiteilung des Buchs bis heute anerkannt ist, sind die Dreiteilung und einheitliche Autorschaft der Unterteile seit den 1980er Jahren umstritten. Oft wird Jes 40–66 als kontinuierliche Fortschreibung verschiedener nachexilischer Redaktionen erklärt. Dabei widmet die Forschung den kompositorischen Querbezügen durch das ganze Buch und den Aussageabsichten einer vermuteten Endredaktion (synchrone Analyse) gegenüber den weiter anerkannten zeitgeschichtlichen und theologischen Unterschieden (diachrone Analyse) stärkere Aufmerksamkeit. Diesem Forschungsstand widersprechen einige Exegeten, die den größten Anteil des Buchs weiterhin einem historischen Jesaja des 8. Jahrhunderts v. Chr. zuschreiben, also Jes 40–66 als echte, vorexilische Prophetie ansehen. Für die meisten historisch-kritischen Forscher ist diese Ansicht unhaltbar. Jedoch erkennen sie viele sprachlinguistische, strukturelle und inhaltliche Argumente für eine einheitliche Konzeption des ganzen Buchs an.

Welche Texte des ersten Teils vom historischen Jesaja ben Amoz stammen, ist stark umstritten. Uwe Becker (1997) hielt nur die Zeichenhandlung 8,1.3.16. und den Berufungsbericht (6) ohne Verstockungsmotiv für authentisch. Aus diesem Kern sei das heutige Buch gewachsen. Mit Ulrich Berges, Martin Sweeney und Erhard Blum halten viele Forscher heute einen größeren Textbestand für jesajanisch, den sie mehreren Phasen seines Wirkens zuordnen:
Möglicherweise schrieb Jesaja seine Worte selbst auf, wie es und nahelegen, und/oder ein Schülerkreis () sammelte und überlieferte sie. Als älteste Sammlungen gelten folgende Texte:
Hermann Barth weist Texte, die Assyriens späteren Niedergang voraussetzen, einer hypothetischen Assur-Redaktion aus der Zeit des judäischen Königs Joschija (~640–609 v. Chr.) zu. Diese habe die schon verschrifteten älteren Textblöcke durch Überleitungen und neue Kapitel ergänzt, verknüpft und eventuell bereits zu einem Buch zusammengestellt. Dazu zählt er die Texte Jes 7,1–4.10.18f.21–25; 15,2b; 16,13f.; 20; 23,1a.15–18; 27; 30,19–33; 32,1–8.15–20; 36–37 (übernommen aus 1 Kön 18–19). Analog zu und habe also ein geschichtlicher Anhang dieses Buch abgeschlossen.

Nach dem babylonischen Exil wurden in das vermutete Jesajabuch der Joschijazeit weitere Texte eingefügt, die im Exil entstanden und darauf vorausweisen. Dazu zählt man mindestens 13,1.19; 14,4.22; 21,9; 38–39. Die Kapitel 40–66 werden entweder als unabhängig entstandene Bücher, die mehrere Redaktoren stufenweise mit Protojesaja verknüpften, oder als dessen kontinuierliche Fortschreibung erklärt. Ulrich Berges datiert die Endredaktion für Gesamtjesaja auf die Zeit nach dem Tempelneubau (um 500 v. Chr.), Odil Hannes Steck dagegen auf die Zeit Alexanders (um 300 v. Chr.).

Für Jesaja ist die Abweichung seines Volkes Israel vom rechten Weg zu JHWH und die gewaltsame Korrektur durch die Assyrer ein zentrales Anliegen. Seine in seiner Prophetie entworfene Gottesvorstellung zeigen das (religiöse) Versagen der Bevölkerung im Königtum Juda und die göttliche Bestrafung über sie. So betrachtet Jesaja die assyrischen Heere als JHWHs Zuchtrute.

Die gottlose Nation sind die Menschen im Königtum Juda, deren Vernichtung beschlossen wurde:
Jesaja ben Amoz trat ab etwa 740 öffentlich in Jerusalem auf und reagierte auf die damalige Verarmung großer Bevölkerungsteile mit einer scharfen Sozialkritik, die „Recht und Gerechtigkeit“ für die Armen einklagte und Israels Überleben davon abhängig sah (1,21–26; 5,1—10; 10,1–3). Ab 734 wollte das Nordreich Israel mit dem Südreich Juda eine Allianz gegen das expandierende Assyrien bilden. Dagegen riet Jesaja Ahas, dem damaligen König Judas, allein auf JHWH zu vertrauen, den Gott Gesamtisraels. Diese grundsätzliche, am ersten Gebot orientierte Kritik an jeder auf militärische Sicherheit gerichteten Politik behielt er bis ans Ende seines Wirkens bei. Der Fall des Nordreichs (722 v. Chr.), der Jesajas Warnungen Recht gab, kann sich in Jes 28,1–4 spiegeln. Ab 705 stellte Judas König Hiskija Tribute an Assur ein und provozierte damit dessen Herrscher Sanherib, Judas Vasallenstatus mit einem Krieg wiederherzustellen. Dazu rückte er mit seinem Heer gegen Jerusalem vor und belagerte es (2 Kön 18,7.13). Erneut warb Jesaja in dieser Lage für Vertrauen auf JHWH (28,12.16f.; 30,15). Tatsächlich entging Jerusalem damals noch einmal der Eroberung und Zerstörung. 

Jesaja nennt JHWH den „Heiligen Israels“: Gottes Heiligkeit, seine absolute Überlegenheit über alle Weltläufe, nötigt ihn zugleich, Gottes leidenschaftlichen Zorn und sein Gericht über das Unrecht an den Armen anzukündigen. Diese Gerichtsansagen nennen die brutale Unterdrückung ebenso radikal beim Namen wie die früherer Propheten (Amos, Micha). Sie sollen dem erwählten Volk Israel eine neue Lebenschance eröffnen. Darum spricht Jesaja von einem „Rest“, der verschont bleibe (1,8f.; 30,17). Weil er selbst Sündenvergebung erfuhr (6,7), widersprechen Aussagen zur „Verstockung“ (6,8f.) und Jerusalems endgültiger Schuld (22,14) nicht anderen Aussagen, die Gottes Gericht als Läuterung auffassen (1,21ff.) und ein alternatives Verhalten andeuten, das das Gericht aufhalten kann. Erst nach dem Untergang beider Königreiche wurde jene Verstockung wohl als nicht revidierbarer prophetischer Auftrag verstanden und formuliert. Gottes Heiligkeit entspricht auch Jesajas kontinuierliche Kritik am menschlichen Hochmut und Selbstbehauptungswillen, vor allem der Herrscher: Je mehr sie sich selbst verteidigen und retten wollen, umso mehr verfallen sie jenen Mächten, vor denen sie sich mal rebellierend, mal sich unterwerfend abzusichern suchen. Wirklichen Frieden („Ruhe“) gebe es nur im alleinigen Vertrauen auf den Gott, der Israel erwählt und gerettet habe und wieder retten werde. Daraus könne ein Mensch angstfrei für andere handeln, Erschöpften Ruhe verschaffen (28,12) und Armen zu ihrem Recht verhelfen. Weil sich die städtische Oberschicht (1,21), das Nordreich und die Vertreter Judas (5,7) diesem Vertrauen verweigerten, falle ihre Schuld auf das ganze Volk und mache es krank (1,4–6). So verknüpfte Jesaja innenpolitische Sozialkritik mit Kritik an Militär- und Außenpolitik. 

Spätere Texte sprechen von JHWHs Gnade, Aufhebung der unheilbaren Krankheit und Schuld am Berg Zion (30,18.26; 33,24). Dort ist JHWH für Jesaja gegenwärtig, auch in einer persönlichen Krise (8,17). Die Bedrohung des Zion von innen wie außen war daher seine Hauptsorge. Nur durch die Garantie von Recht für die Armen könne Jerusalem sich retten und wieder „Stadt der Gerechtigkeit“ heißen (1,26f.). Dann würden die Völker dorthin pilgern, um JHWHs Rechtswillen zu erfahren, und freiwillig abrüsten (2,2–4). Von dort aus herrsche JHWH als wahrer König über alle Herrscher der Welt; dort werde er seinen künftigen davidischen Mandatar einsetzen, der seine Gerechtigkeit verwirklichen werde (9; 11). Dort werde Gott den Völkern das Festmahl des Schalom bereiten (25,6f.). An diese originären Heilszusagen knüpften die exilisch-nachexilischen Buchteile sprachlich und inhaltlich an. Wie Jesajas Worte auf seine Zeitgenossen wirkten, ist nicht überliefert; die jahrhundertelange Fortschreibung seiner Prophetie zeigt jedoch die Autorität, die er seit seinem Auftreten genoss.



Einführung

Kommentare

Einzelstudien



</doc>
<doc id="10353" url="https://de.wikipedia.org/wiki?curid=10353" title="Wahlkreis">
Wahlkreis

Ein Wahlkreis ist der – in der Regel geographisch zusammenhängende – Teilraum eines Wahlgebietes, in dem Wahlberechtigte über die Besetzung eines oder mehrerer Mandate abstimmen. Die zu wählende Versammlung kann das nationale Parlament oder das eines Gliedstaates sein.

Das unterscheidet den Wahlkreis begrifflich vom "Wahlbezirk (Wahlsprengel)", der nur eine organisatorische Einheit der Stimmauszählung ist. Wahlkreise sind spezielle Wahlbezirke.

Der Wahlkreis ist ein frühes Konstrukt der Demokratie. Als die Römische Republik sämtliche italischen Gebiete unterworfen und zu Bundesgenossen gemacht hatte, wurden diese in Wahlbezirke (sogenannte "Tribus") eingeteilt, um auf diese Art in Rom vertreten zu sein.

Wahlkreise können nach der Anzahl der im Wahlkreis zu vergebenden Mandate sowie nach der Art des verwendeten Wahlverfahrens unterschieden werden.

Wenn pro Wahlkreis genau ein Sitz vergeben wird, spricht man von Einerwahlkreisen (bzw. Einpersonenwahlkreisen), in ihnen gewinnt der Bewerber mit der relativen oder absoluten Mehrheit. Daneben gibt es Wahlsysteme mit Mehrmandatswahlkreisen (bzw. Mehrpersonenwahlkreisen), d. h. dass in ihnen mehr als ein Mandat zu gewinnen ist. Die Vergabe von nur einem Sitz pro Wahlkreis ist das ältere Verfahren, und dementsprechend weltweit stärker verbreitet. Mehrmandatswahlkreise gibt es seit vielen Jahrzehnten in Irland, seit einiger Zeit auch bei den Wahlen zum schottischen Regionalparlament, sowie bei den Wahlen zur Hamburgischen Bürgerschaft. Beispiele für Wahlsysteme mit Mehrmandatswahlkreisen sind das in Chile und Indonesien verwendete Binomiale Wahlsystem und das unter anderem in Japan gebräuchliche System mit nicht übertragbarer Einzelstimmgebung.

Weiterhin unterscheidet man Wahlkreise nach den in ihnen zum Tragen kommenden Wahlverfahren. Entsprechend sind eine ganze Reihe möglicher Wahlkreistypologien denkbar. So können sowohl Einerwahlkreise als auch Mehrmandatswahlkreise mit verschiedensten Wahlverfahren kombiniert werden.

Das älteste und bis heute verbreitetste Verfahren ist die relative Mehrheitswahl. Dies ist beispielsweise bei der Wahl zum britischen Unterhaus, zum US-Repräsentantenhaus, zum indischen Unterhaus sowie bei der Wahl der Direktkandidaten des Deutschen Bundestags der Fall.

Bei den Wahlen zur französischen Nationalversammlung wird nach dem romanischen Mehrheitswahlrecht gewählt. In denjenigen Wahlkreisen, in denen kein Bewerber mindestens die Hälfte der gültig abgegebenen Stimmen auf sich vereinigen konnte, kommt es zu einer Stichwahl in einem zweiten Wahlgang. An der Stichwahl nehmen die zwei stärksten Kandidaten teil. Weitere Kandidaten nehmen teil, sofern sie die Stimmen von mehr als 12,5 % der Wahl"berechtigten" erhalten haben.

Bei Wahlen zum australischen Unterhaus wird ebenfalls in Einerwahlkreisen, allerdings nach dem Instant-Runoff-Voting-Verfahren gewählt.

In den Mehrmandatswahlkreisen in Irland (bei denen je nach Größe drei, vier bzw. fünf Mandate zu erringen sind) wird nach dem Prinzip der Übertragbaren Einzelstimmgebung gewählt.

Im Bundesland Hamburg findet die Vergabe der Sitze in den Mehrmandatswahlkreisen durch Wahlkreislisten statt, bei denen kumuliert und panaschiert werden kann.

In den modernen Demokratien ist die Einteilung der Wahlkreise oftmals ein Politikum, da bei der Wahlkreiseinteilung verschiedene widersprüchliche Aspekte Berücksichtigung finden müssen.

Zunächst ist das Prinzip der Gleichheit der Wahl "(One Man – One Vote)" zu beachten. Dieser wesentliche Wahlgrundsatz erfordert im Idealfall, dass alle Wahlkreise die gleiche Anzahl von Wahlberechtigten enthalten. In der Praxis ist dies nicht ohne weiteres möglich. Umfassen die Wahlkreise deutlich unterschiedliche Anzahl von Wahlberechtigten, ist das Stimmgewicht des einzelnen Wahlbürgers je nach Wahlkreiszugehörigkeit unterschiedlich. In Deutschland haben die Landesverfassungsgerichte der Länder mehrfach Wahlkreiseinteilungen für verfassungswidrig erklärt, weil die Größe einiger Wahlkreise zu stark von der mittleren Größe der Wahlkreise abwichen.

Aus organisatorischen Gründen ist es sinnvoll, sich bei der Wahlkreiseinteilung an bestehenden administrativen Einheiten (Gemeinden, Landkreise oder ähnlichem) zu orientieren.

Die Wahlkreise sollen sich vielfach an gewachsenen geographischen Gebieten, ethnischen Siedlungsgebieten oder Sprachräumen (wie zum Beispiel bei Wahlen zur Belgischen Abgeordnetenkammer) orientieren.

Insbesondere bei "Einer-Wahlkreisen" besteht die Möglichkeit der manipulativen Wahlkreiseinteilung, welche in den Vereinigten Staaten als "Gerrymandering" bezeichnet wird. Hierbei werden Wahlkreise so geschnitten, dass in einigen wenigen Wahlkreisen sehr hohe Ergebnisse einer Partei erzielt werden und in vielen Wahlkreisen knappe Mehrheiten für die andere Partei entstehen. Um dies zu vermeiden, müssen die Wahlkreise möglichst gleichartig strukturiert sein, also eine annähernd gleiche Zahl von Einwohnern, Staatsbürgern oder Wahlberechtigten pro zu vergebendem Mandat haben (je nach Gebietsgröße Zehn- bis Hunderttausende). Zudem wird oft auch darauf geachtet, dass sie eine ähnliche soziologische Struktur aufweisen. Vor allem aber ist die Aufteilung anhand klarer einheitlicher Prinzipien vorzunehmen.

In Deutschland gibt es seit der Bundestagswahl 2002 299 Wahlkreise (auch: Bundestagswahlkreise) bei Wahlen zum Deutschen Bundestag ( zum BWahlG), welche sich wiederum in Wahlbezirke unterteilen. In den Fällen, in denen nach Verhältniswahl gewählt wird (zum Beispiel Europawahl, Bundestagswahl, Landtagswahl, Bürgerschaftswahl), sind die Wahlkreise zugleich Stimmkreise für die Abgabe derjenigen Stimmen, die über die Verteilung der Mandate nach Landeslisten entscheiden.

Die Wahlkreise sollen so eingeteilt sein, dass jeder Wahlkreis die ungefähr gleiche Zahl der deutschen Bevölkerung umfasst. Die Zahl der Deutschen in einem Wahlkreis soll vom Durchschnitt nicht mehr als 15 % nach oben oder unten abweichen. Ab einer Abweichung von mehr als 25 % muss der Wahlkreis neu zugeschnitten werden (siehe z. B. Abs. 1 Nr. 3 BWahlG), was jeweils auch Veränderungen benachbarter Wahlkreise nach sich zieht. Ein Wahlkreis darf sich nur innerhalb eines Bundeslandes befinden, sonstige Gebietskörperschaften (beispielsweise Bezirke, Kreise, Kommunen) sollen so weit wie möglich nicht zerschnitten werden (siehe z. B. Abs. 1 Nr. 1 und 5 BWahlG). Größere Verschiebungen der Bevölkerungszahlen der einzelnen Bundesländer können dazu führen, dass sich die Zahl der Wahlkreise einzelner Bundesländer verändert, was ebenfalls einen Neuzuschnitt von Wahlkreisen zur Folge hat. Eine unabhängige Wahlkreiskommission macht Vorschläge für die Verteilung der Wahlkreise auf die Länder und ihren Zuschnitt ( Abs. 3 BWahlG); die endgültige Einteilung wird vom Gesetzgeber im Bundeswahlgesetz festgelegt.

Die Mandate derjenigen Abgeordneten, die einen Wahlkreis gewonnen haben, nennt man Direktmandate. Bei Wahlen zum Deutschen Bundestag wird neben den Direktmandaten eine gleiche Anzahl (seit 2002: 299) Mandate an Listenkandidaten vergeben, so dass sonst zu Lasten kleinerer Parteien auftretende Verzerrungen ausgeglichen werden. Entscheidend für die Sitzverteilung im Bundestag ist demnach nicht die Anzahl der gewonnenen Direktmandate, sondern das prozentuale Gesamtergebnis der Parteien. Beispielsweise erhielt die FDP bei der Bundestagswahl 2009 14,6 % der gültig abgegebenen Stimmen, jedoch kam keiner der 299 erfolgreichen Direktkandidaten aus ihren Reihen. Die der Partei zustehenden etwa 15 % der Sitze im Deutschen Bundestag wurden also ausschließlich über die Landeslisten bestimmt.

Auch bei den Landtagswahlen ist das Wahlgebiet in Wahlkreise eingeteilt. Einen Sonderfall bildet Bayern, wo es eine zweifache Unterteilung gibt: zunächst nach den bayerischen Bezirken, die als Wahlkreise bezeichnet werden, und dann weiter nach Stimmkreisen, die also in Bayern dieselbe Bedeutung haben wie in anderen Ländern die Wahlkreise.

Auch im Kaiserreich gab es bei den Wahlen zum Reichstag Wahlkreise. Im Kaiserreich galt das Mehrheitswahlrecht in Einerwahlkreisen, wie es etwa noch heute im Vereinigten Königreich üblich ist: Wer in einem Wahlkreis die meisten Stimmen auf sich vereinigen konnte, erhielt das Mandat, gegebenenfalls nach Stichwahl. Einen Ausgleich für die unterlegenen Parteien wie etwa in Form einer Landesliste gab es nicht. Insgesamt gab es 397 Wahlkreise; bei der ersten Reichstagswahl 1871, die in Elsass-Lothringen nicht stattfand, waren es 382.

In der Weimarer Republik gab es ebenfalls Wahlkreise, diese waren jedoch weitaus größer als die Wahlkreise der Kaiserzeit und erfüllten eine andere Funktion: In jedem Wahlkreis wurde auf Grundlage des Verhältniswahlrechts eine größere Zahl von Abgeordneten gewählt (siehe Wahlrecht und Wahlsystem der Weimarer Republik). Je nach Zahl der Wahlberechtigten war diese Zahl von Wahlkreis zu Wahlkreis unterschiedlich. 1918 wurde die Zahl der Wahlkreise auf 38 festgelegt; da Elsass-Lothringen bei den Wahlen zur Nationalversammlung 1919 bereits wieder französisch war, gab es bei jener Wahl nur 37 Wahlkreise, durch den Verlust der Wahlkreise (und Provinzen) Posen und Westpreußen bei der Reichstagswahl 1920 nur noch 35. Bei dieser Zahl blieb es bis zur letzten Reichstagswahl 1933.

"Für die einzelnen Artikel über Wahlkreise siehe:"

"Historische deutsche Wahlkreise:"

Zu den Wahlen des Nationalrats ist das Wahlgebiet entsprechend der bundesstaatlichen Gliederung in 9 "Landeswahlkreise (die den 9 Bundesländern entsprechen)" und 39 "Regionalwahlkreise" aufgeteilt. (vgl. Nationalratswahlordnung). Jedem Landeswahlkreis werden vor der Wahl so viele der insgesamt 183 Mandate zugeordnet, wie sich Einwohner nach der letzten Volkszählung dort ergeben und zwar nach dem Quotenverfahren nach größten Bruchteilen "(nach Hare)". Diese Mandate werden entsprechend an die Regionalwahlkreise unterverteilt.

Jeder der 26 Kantone bildet einen Wahlkreis. Jeder Wahlkreis hat unabhängig von seiner Bevölkerungszahl Anrecht auf mindestens einen Abgeordnetensitz im Nationalrat. Die restlichen 174 Sitze werden proportional auf die Wahlkreise (= die Kantone) verteilt. Maßgeblich für die Zuteilung ist jeweils die gesamte Wohnbevölkerung der Kantone gemäß den Ergebnissen der letzten Volkszählung. Der Wahlkreis mit den meisten Nationalräten ist der Kanton Zürich.

Jeder Kanton ist im Ständerat mit je zwei Abgeordneten (Die Halbkantone mit je einem Abgeordneten) vertreten. So hat der Kanton Zürich mit Einwohner gleich viele Sitze wie der Kanton Uri mit Einwohner.

Da jeder Wahlkreis einem Kanton entspricht, ist das Wort "Wahlkreis" kaum gebräuchlich. Gebräuchlich ist das Wort "Wahlkreis" im Kanton St. Gallen, der bis Ende 2002 in 14 Bezirke aufgeteilt war. Zum 1. Januar 2003 wurden die 14 Bezirke durch 8 Wahlkreise abgelöst. Per 1. Januar 2013 wird die administrative Gliederung des Kantons Luzern insofern geändert, als die bisherigen fünf Ämter durch sechs Wahlkreise ersetzt werden.

Im Fürstentum Liechtenstein bezeichnet der Begriff "Wahlkreis" die zwei Regionen "Oberland" und "Unterland"

Die Wahlen zur belgischen Abgeordnetenkammer werden in elf Wahlkreisen abgehalten. Für die Wahlen auf regionaler Ebene und die Wahlen zu den Provinzialräten existieren anders zugeschnittene Wahlkreise.

Nicht zu verwechseln sind die Wahlkreise in Belgien mit den Wahlkantonen, die eine Anzahl von Gemeinden unter einem gemeinsamen Wahlauswertungsbüro gliedern.

Für die Wahl des US-Repräsentantenhaus werden die Bundesstaaten der USA in 435 Kongresswahlbezirke unterteilt. Dabei werden alle 10 Jahre nach dem Census jedem Bundesstaat proportional zu seiner Bevölkerung Mandate enthält. In den meisten Bundesstaaten entscheidet die (Bundes-)Staatslegislative über den Zuschnitt der Wahlkreise.

Die Verfassung Namibias legt fest, dass es in jeder Region des Landes zwischen sechs und zwölf Wahlkreise geben soll, die jeweils ein Ratsmitglied in den Regionalrat entsenden. Jeweils eines dieser Ratsmitglieder wird als Vertreter für den Nationalrat gewählt. Insgesamt gibt es in Namibia derzeit 121 Wahlkreise.



</doc>
<doc id="10354" url="https://de.wikipedia.org/wiki?curid=10354" title="Genesis (Band)">
Genesis (Band)

Genesis ist eine 1967 gegründete, einflussreiche britische Progressive-Rock-Band, die mit weltweit über 150 Millionen verkaufter Alben bis heute zu den kommerziell erfolgreichsten zählt. Gekennzeichnet durch ihre sehr eigenständigen Mitglieder, durchlief die Band zwei sich deutlich voneinander unterscheidende musikalische Epochen.

Die anfängliche Kombination aus komplexen Songstrukturen, anspruchsvollen Instrumentierungen und Arrangements sowie theatralischen Live-Auftritten machte die ursprünglich fünfköpfige Formation bereits zu einem relativ frühen Zeitpunkt ihrer Karriere neben King Crimson, Emerson, Lake & Palmer und Yes zu einem der wichtigsten und beliebtesten Vertreter des Progressive Rock der 1970er Jahre.

Nach dem Ausstieg des Gründungsmitglieds und Frontmanns Peter Gabriel 1975 und des Gitarristen Steve Hackett 1977 machte das verbliebene Trio, bestehend aus Tony Banks, Phil Collins und Mike Rutherford, ab den späten 1970ern eine signifikante stilistische Wandlung durch. Mit ihrem nun zumeist radiotauglichen Mainstream-Rock wurde Genesis zu einer der kommerziell erfolgreichsten Musikgruppen der 1980er und frühen 1990er Jahre.

Nach Collins’ vorläufigem Abschied von der Band wurde 1997 der Sänger Ray Wilson für ein Album samt nachfolgender Tournee engagiert. Anschließend trat die Band mit Anthologien ihrer bisherigen Stücke, Veröffentlichung von bislang nicht offiziell erhältlichem Archivmaterial und neuen SACD-Abmischungen ihrer Alben in Erscheinung. Im Sommer 2007 ging Genesis in Europa und Nordamerika wieder mit Phil Collins auf Tournee. Im März 2010 wurde Genesis als wichtige und einflussreiche Band in die Rock and Roll Hall of Fame aufgenommen.

Die Wurzeln von Genesis sind an der Charterhouse School in Godalming (Surrey) zu finden. 1963 traten zunächst Peter Gabriel und Tony Banks in die traditionsreiche, elitäre Privatschule ein. Beide waren frustriert von den damals sehr strengen und repressiven Regeln einer englischen Public School und nutzten ihre knappe Freizeit, um gemeinsam zu musizieren. Tony Banks spielte bereits seit seiner frühen Kindheit Klavier. Auch Peter Gabriel bekam in seiner Jugend Klavierunterricht, interessierte sich bald aber mehr für das Schlagzeug. Da beiden in der Schule nur ein Klavier zur Verfügung stand, einigte man sich darauf, dass Banks dieses spielte, während Gabriel dazu sang. So spielten beide zunächst bekannte Rock- und Popsongs ihrer Zeit nach, komponierten aber auch schnell erste eigene Stücke.

1964, ein Jahr nach Banks und Gabriel, kam Mike Rutherford an die Schule. Er spielte seit seinem siebten Lebensjahr Gitarre. Er freundete sich mit einem anderen Gitarristen, Anthony Phillips, an und musizierte in der Folge gemeinsam mit ihm. Zusammen mit ihren Mitschülern Richard Macphail, Rivers Jobe († 1979) und Rob Tyrrell gründeten die beiden 1965 ihre eigene Band Anon. Phillips war Leadgitarrist der Gruppe, während Rutherford die Rhythmusgitarre übernahm. Macphail (später Roadmanager und Tonmischer der frühen Genesis bis April 1973) steuerte den Leadgesang bei. Anon beschränkte sich zunächst auf das Nachspielen von Titeln der Rolling Stones oder anderer bekannter Rock- und Popgrößen ihrer Zeit. Eine Zeitlang wurde Rutherford durch Mick Colman († 2010) ersetzt, da er mit dem Schlagzeuger Chris Stewart auch ein anderes Bandprojekt namens Climax verfolgte.

Etwa zur selben Zeit traten Banks und Gabriel der Schulband The Garden Wall des Trompeters Johnny Trapman bei. Als Schlagzeuger stieß Chris Stewart hinzu, während Rivers Job auch hier den Part des Bassisten übernahm. Im Sommer 1966 traten die Bands Anon, The Garden Wall und Climax anlässlich eines Charterhouse-Schulkonzertes gemeinsam auf, wobei der Mangel an Mitgliedern sie teilweise fusionieren ließ. Wer genau mit wem spielte, ist unklar, da die späteren Genesis-Mitglieder zu unterschiedlichen Zeiten unterschiedliche Auskünfte darüber gaben. Das Konzert stellte für alle Beteiligten ein wichtiges Ereignis dar, obwohl es von der Schulleitung kurz vor Ende abgebrochen wurde: Rebell Richard Macphail hatte es trotz ausdrücklichen Verbots gewagt, den letzten Song anzusagen.

Kurze Zeit später löste sich Anon auf und Mike Rutherford und Anthony Phillips zogen sich zurück, um gemeinsam Songs zu schreiben. Als sie 1967 einige ihrer Stücke aufnehmen wollten, baten sie Tony Banks um musikalische Unterstützung am Klavier. Banks überzeugte Phillips davon, Peter Gabriel als Sänger dazuzunehmen. Rutherford wechselte seinerseits von der Rhythmusgitarre zum Bass, da Rivers Job mittlerweile die Schule hinter sich gebracht und sich der Bluesrock-Band Savoy Brown angeschlossen hatte. In dieser Besetzung nahmen sie in den Osterferien bei einem Freund die Phillips/Rutherford-Kompositionen "Don’t Want You Back, Try a Little Sadness, That’s Me, Listen on Five" und "Patricia" sowie das Banks/Gabriel-Stück "She Is Beautiful" auf. Im Anschluss wurde Chris Stewart als Schlagzeuger verpflichtet, der die Erstbesetzung der Band komplettierte.

Als im selben Jahr der ehemalige Charterhouse-Schüler Jonathan King, mittlerweile ein relativ erfolgreicher Musikproduzent, seine einstige Lehranstalt besuchen kam, ließ die Band ihm ihr Demoband zukommen. King war von den Aufnahmen begeistert und nahm die junge Band, nachdem sie noch ein weiteres Demo für ihn produziert hatte, bei seiner Plattenfirma Jonjo Music unter Vertrag. Er hatte genaue Vorstellungen davon, wie die Gruppe zu klingen habe, und bestand auf einfachen Arrangements mit ruhiger Instrumentierung aus akustischer Gitarre und Klavier.

In diesem Stil nahmen sie ihre erste Single "Where the Sour Turns to Sweet" auf, die allerdings nicht veröffentlicht wurde. Im Hintergrund komponierte die Band bereits längere und komplexere Stücke, was King allerdings missfiel. So schrieben sie den einfach gestrickten Titel "The Silent Sun," mit dem sie ihn wieder von sich überzeugten. Den Song produzierte King im Dezember 1967 prompt mit ihnen als Single, die am 2. Februar 1968 beim Decca-Label auf den Markt kam. Für die Veröffentlichung brauchte die Band, die bis dahin „halbherzig“ als New Anon firmiert hatte, einen zündenden Namen. Nach verschiedenen gleichermaßen schlechten Ideen wie Champagne Meadow oder Gabriel’s Angels schlug Jonathan King schließlich den Namen Genesis vor, der den Anfang von etwas Neuem suggerieren sollte und der allen Mitgliedern zusagte. Anschließend veröffentlichte man mit "A Winter’s Tale" eine weitere Single, die allerdings ebenso wie die vorhergehende erfolglos blieb. Danach wurde Schlagzeuger Chris Stewart auf Kings Geheiß durch John Silver ersetzt.

Mit Silver nahm Genesis im September 1968 in den Regent Studios in London in nur eineinhalb Tagen das erste Album auf. Es erschien im März 1969 ohne explizite Nennung des Bandnamens, da zu der Zeit bereits eine US-Band existierte, die ebenfalls den Namen "Genesis" trug. Für eine Weile nannte sich die Band deshalb "Revelation", und erst nach Auflösung besagter US-Formation wechselte man wieder zum Bandnamen "Genesis". Der Titel des Albums, "From Genesis to Revelation," nahm indirekt Bezug auf die Probleme der Namensgebung, veranlasste die Plattenläden jedoch dazu, das Album irrtümlich der Kategorie „religiöse Musik“ zuzuordnen – mit der Folge, dass es mit nur etwa 600 verkauften Exemplaren vollkommen unterging. Auch die Singleauskopplung des Stücks "Where the Sour Turns to Sweet" im Juni 1969 konnte die Verkaufszahlen nicht steigern. Die ausnahmslos kurzen und eingängigen Stücke der Platte entsprachen noch nicht dem musikalischen Potential von Genesis, sondern waren eher an den Geschmack ihres Produzenten Jonathan King angepasst. Dessen nachträglich hinzugefügte Streicher- und Bläserpassagen stießen bei der Band – insbesondere Anthony Phillips – auf wenig Gegenliebe, und aufgrund der immer größer werdenden künstlerischen Differenzen trennte man sich schließlich von King. Mittlerweile hatten alle Mitglieder ihren Schulabschluss und befanden sich in einer Findungsphase, was ihre zukünftige Entwicklung anging.

Nach einer mehrmonatigen Pause traf die Band im Sommer 1969 wieder zusammen. Gabriel, Phillips, Banks und Rutherford entdeckten schnell ihre Freude an der Musik wieder und entschieden sich dazu, professionelle Musiker zu werden. John Silver, der die Band verlassen hatte, um in den USA zu studieren, wurde durch den neuen Schlagzeuger John Mayhew ersetzt. Am 20. August nahm die Gruppe ein Demoband mit den neuen Songs "White Mountain, Family" (eine frühe Version des Titels "Dusk", welcher 1970 auf "Trespass" erschien), "Going Out to Get You" und "Pacidy" auf. In dieser Phase kauften sich die Bandmitglieder mit geliehenem Geld allesamt ihre ersten professionellen Instrumente und steigerten ihre instrumentalen Fähigkeiten weiter.

Von Oktober 1969 bis April 1970 bezog die Band ein abgeschiedenes Wochenendhaus, das Christmas Cottage der Eltern ihres Freundes Richard Macphail, um erstmals über einen langen Zeitraum intensiv an ihrer Musik zu arbeiten.
Trotz einiger Differenzen zwischen den Bandmitgliedern machten die gemeinschaftlichen musikalischen Bemühungen hier einen Riesenschritt nach vorn. Während dieser Zeit nutzten Genesis zudem jede Gelegenheit, um die Titel live und vor Publikum zu testen, wodurch die erste kleine, aber treue Fangemeinde entstand. Der erste ordentliche Live-Auftritt der Band fand am 1. November 1969 in der Brunel University in Uxbridge statt, und die Setlist der frühesten Konzerte pendelte sich bald auf die Stücke "In the Beginning, The Serpent" (beides "From-Genesis-to-Revelation"-Überbleibsel), "Pacidy, Key to Love" (Bluesbreakers-Cover), "Visions of Angels, Going Out to Get You, Stagnation, Little Leaf" (unveröffentlichte Phillips-Komposition, zu hören heute als "Old Wive’s Tale" auf zwei verschiedenen Phillips-CDs und am Anfang von "Resignation" auf dem Box-Set "Genesis 1970–1975") und "The Knife" ein.

Auch zwei Aufnahme-Sessions fallen in diese Phase: Am 9. Januar 1970 nahm die Band vier Stücke für eine nie gesendete BBC-Fernsehdokumentation um den Maler Mick Jackson auf. Die von Paul Samwell-Smith produzierten, größtenteils instrumentalen Titel "Provocation, Frustration, Manipulation" und "Resignation" sind in Fankreisen als "Jackson-Tapes" bekannt. Am 22. Februar spielte Genesis live in den BBC-Maida-Vale-Studios die Titel "Shepherd, Pacidy, Let Us Now Make Love, Stagnation, Looking for Someone" und "Dusk" für die BBC-Radiosendung "Nightride" ein.

Auf der Suche nach einer geeigneten Plattenfirma sympathisierte die Band anfangs mit Island, Chrysalis und dem Threshold-Label der Moody Blues. Das Problem erledigte sich dann jedoch von selbst, als Genesis als Vorgruppe für Rare Bird spielte und daraufhin von deren Keyboarder Graham Field Tony Stratton-Smith empfohlen wurde. Als dieser einem ihrer Auftritte beiwohnte, war er vom Stück "Visions of Angels" so angetan, dass er die Band sofort bei seinem Label Charisma Records unter Vertrag nahm. Für Charisma nahm Genesis im Juni und Juli ihr zweites Album auf.

"Trespass" wurde am 23. Oktober 1970 veröffentlicht und wird heute von vielen Fans als das erste „richtige“, unverfälschte Album der Gruppe angesehen. Im Vergleich zu ihrem ersten Album hatte sich die Musik von Genesis deutlich weiterentwickelt: An Stelle der kurzen Popsongs traten bis zu neun Minuten lange Titel mit ausgedehnten Instrumentalteilen. "Trespass" ist insgesamt eher akustisch gehalten und von zwölfsaitigen Gitarren, Orgel und Klavier dominiert. Einzig der frühe Live-Favorit "The Knife" ist als dynamische Rocknummer angelegt und durch aggressives E-Gitarren-Spiel gekennzeichnet. Dieser Titel erschien – in zwei Teile geteilt – im Mai des darauffolgenden Jahres auch als Single. Trotz einiger guter Kritiken war das Album kommerziell wenig erfolgreich.

Kurz nach den Aufnahmen zu "Trespass" kam es noch im Juli zu einem personellen Umbruch in der Band: Wegen künstlerischer Differenzen und aus Krankheitsgründen verließ Gitarrist Anthony Phillips die Gruppe. Er litt unter Lampenfieber, war von den mittlerweile zahlreichen Auftritten geschwächt und in musikalischen Fragen oft anderer Meinung als die anderen Bandmitglieder. Dieser Austritt stellte für Genesis einen großen Verlust dar, da sie neben ihrem Gitarristen auch einen wichtigen Songschreiber und die eigentliche frühe Schlüsselfigur der Band verlor. Die Folgezeit wird von den verbliebenen Mitgliedern noch heute als größte Krise der Bandgeschichte beschrieben. Im Zuge von Phillips’ Abschied trennte sich Genesis auch von Schlagzeuger John Mayhew, der das mittlerweile hohe musikalische Niveau der Band nicht mehr halten konnte. Nach einer kurzen Phase der Ratlosigkeit, in der sogar das Ende der Band zur Diskussion stand, entschied man sich schließlich dazu, weiterzumachen und per Anzeige im "Melody Maker" nach einem neuen 12-Saiten-Gitarristen und einem fähigen Schlagzeuger zu suchen.

Auf die Anzeige meldete sich Phil Collins, der seit früher Kindheit Schlagzeug gespielt und schon als Jugendlicher durch eine Rolle im Musical "Oliver!" Bühnenerfahrungen gesammelt hatte. Zudem hatte er in einigen Film- und Fernsehproduktionen mitgewirkt, unter anderem als Statist im Beatles-Film "Yeah Yeah Yeah (A Hard Day’s Night)". Zusammen mit seinem Freund Ronnie Caryl spielte er in der relativ unbekannten Band Flaming Youth, die 1969 das Album "Ark 2" veröffentlicht hatte. Er sah sich gerade nach einer neuen musikalischen Herausforderung um, als er davon erfuhr, dass Genesis nach neuen Musikern suchte. So meldete er sich im August 1970 zusammen mit Gitarrist Caryl auf die Anzeige, und sie wurden ins Haus von Peter Gabriels Eltern zum Vorspielen eingeladen. Dabei wurde schnell klar, dass Collins den Job als Schlagzeuger bekommen würde. Er spielte die Genesis-Stücke nicht nur überzeugend, sondern passte auch menschlich zur Band.

Die Suche nach einem passenden Gitarristen gestaltete sich in der Folge schwieriger, da Genesis nicht nur einen Instrumentalisten suchte, sondern auch einen Songschreiber, der zu der Band passte. Zudem waren die vor allem von Mike Rutherford gestellten Anforderungen an das neue Bandmitglied sehr hoch. So kam es, dass die Rolle des Gitarristen vorerst unbesetzt blieb, da auch Ronnie Caryl bei der gemeinsamen Vorstellung mit Collins den Zuschlag nicht erhalten hatte. Daher spielte Genesis einige Monate als Quartett und Tony Banks übernahm die Gitarrenteile auf seinen Keyboards. Für kurze Zeit stieß der Gitarrist Mick Barnard zur Band, der allerdings das Niveau der restlichen Bandmitglieder nicht erreichen konnte.

Im Dezember 1970 entdeckte Peter Gabriel im "Melody Maker" eine Musiker-Sucht-Band-Anzeige des Gitarristen Steve Hackett, der sich als "A Able Accordionist" vorstellte, was seiner Annonce den obersten Platz in der alphabetisch sortierten Anzeigenliste garantierte. Hackett spielte seit Mitte der 1960er Jahre elektrische und akustische Gitarre. Bereits im Alter von 16 Jahren hatte er die Schule verlassen und danach in verschiedenen Bands mitgewirkt. Dabei wurde er von den Blues-Gitarristen seiner Zeit wie beispielsweise Eric Clapton beeinflusst, ebenso von experimentierfreudigeren Gitarrenkünstlern wie Jeff Beck und später Robert Fripp. Bei seinem Spiel kam es ihm weniger auf Geschwindigkeit an, sondern vielmehr darauf, mit seiner Gitarre in neue melodische und harmonische Bereiche zu gelangen. Gabriel rief ihn an und riet ihm, sich das Stück "Stagnation" von "Trespass" anzuhören und sich wieder zu melden, wenn es ihm zusagte. Nach einem Freikonzert der Band im Londoner Lyceum, dem Hackett beiwohnte, wurde er zum Vorspielen in Tony Banks’ Wohnung eingeladen und bekam den Job. Mit ihrem ersten gemeinsamen Auftritt am 14. Januar 1971 war so die „klassische“ Besetzung von Genesis komplett.

Die ersten Monate des Jahres 1971 waren geprägt durch die "Charisma-Package"-Tour, die aufgrund der geringen Ticket-Preise auch als "Six-Bob"-Tour bekannt wurde (six bob = sechs britische Schilling). Label-Boss Tony Stratton-Smith ließ seine drei vielversprechendsten Bands gemeinsam touren und Genesis eröffnete die Konzerte für Van der Graaf Generator und Lindisfarne. Zwischendrin hatten Genesis im belgischen Woluwe-Saint-Lambert im März ihren ersten Auftritt außerhalb Großbritanniens.

Das erste Album mit den beiden neuen Bandmitgliedern, "Nursery Cryme," wurde im August 1971 aufgenommen und im November veröffentlicht. Es enthielt das Klassik-beeinflusste "The Fountain of Salmacis" und mit "The Musical Box" einen der größten Genesis-Klassiker, an dessen Entstehungsprozess auch Hacketts Vorgänger Phillips und Barnard Anteil gehabt hatten. Collins bereicherte den Gruppen-Sound mit seinem bisweilen jazzigen Stil und war beim kurzen Stück "For Absent Friends" erstmals auch als Leadsänger zu hören. Hackett fügte Aggression einerseits und eine größere atmosphärische Bandbreite andererseits hinzu.

Nach Erfolgen in Belgien ("Trespass" an der Charts-Spitze) und Italien ("Nursery Cryme" auf Nr. 4) verschlug es Genesis Anfang 1972 auf den Kontinent: nach einem Auftritt in Brüssel im Januar spielte die Band im April gleich dreizehn Konzerte in Italien und gab auf dem Rückweg im Frankfurter Sinkkasten ihr Deutschland-Debüt. Die Single "Happy the Man" ging im Mai 1972 zwar noch sang- und klanglos unter, aber das im Oktober veröffentlichte Album "Foxtrot" mit dem epischen "Supper’s Ready" und dem von Arthur C. Clarke inspirierten "Watcher of the Skies" brachte der Band auch den kommerziellen Durchbruch im eigenen Land (Platz 12). In Italien war "Foxtrot" monatelang auf Platz 1 der LP-Charts.

War die Band bis dahin zumeist als Vorgruppe anderer Acts bzw. als Bestandteil von Festival-Programmen in Erscheinung getreten, so stellte die auf dem Album "Genesis Live" dokumentierte "Foxtrot"-Tour von 1972/73 ihre erste Tournee als Hauptattraktion dar. So trat die Band auch im Pariser Bataclan auf. Zu dieser Zeit begann Gabriel mit diversen Verkleidungen und Masken zu experimentieren, um die oft surrealistischen Texte der Band visuell zu unterstreichen. Seine exzentrische Bühnenshow sowie generell die Verknüpfung von Musik und Optik in den Konzerten verhalfen Genesis zu großer Popularität. Bis dahin von Tony Stratton-Smith und sich selbst mehr schlecht als recht gemanagt, verpflichtete die Band mit Tony Smith 1973 erstmals einen professionellen Manager, der fortan sämtliche Genesis-Werke vermarktete (ab 1977 mit seiner Firma Hit & Run Music Publishing).

"Selling England by the Pound" (seinerzeit ein Wahlkampfslogan der Labour Party) zeigte die Band Ende 1973 mit wesentlich diesseitigeren Texten, feiner nuanciertem Klang und noch größerer Filigranität und Virtuosität an den Instrumenten. Das Album beinhaltete Klassiker wie "Firth of Fifth, The Cinema Show" und "I Know What I Like (In Your Wardrobe)," die fortan zum festen Live-Repertoire der Band gehörten. Steve Hackett war damals einer der ersten Gitarristen, der die Spieltechnik des Tapping und des Sweep Picking einführte, was oft fälschlicherweise Eddie Van Halen bzw. Yngwie Malmsteen zugeschrieben wird. Beide Techniken sind im Song "Dancing with the Moonlit Knight" zu hören. Die Auskopplung "I Know What I Like" wurde Anfang 1974 zum ersten kleineren Single-Hit der Band.

Das Konzept-Doppelalbum "The Lamb Lies Down on Broadway" und die anschließende Tour stellen nach Meinung vieler Fans den künstlerischen Höhepunkt der Schaffensperiode mit Peter Gabriel dar. Das Album wurde am 18. November 1974 veröffentlicht und handelt von der fantastischen und surrealen Reise des puerto-ricanischen Punks Rael in New York, der in einem Paralleluniversum seinen Bruder John retten muss. Insbesondere die erste Platte des Doppelalbums ist von kürzeren Stücken dominiert, was eine deutliche Abkehr von den eher längeren und ausgedehnten Songs bisheriger Alben darstellt. Der Gebrauch verzerrter Instrumente, neuer elektronischer Keyboardsounds und anderer synthetischer Klänge (wie etwa die Effekte auf Gabriels Stimme beim Song "The Grand Parade of Lifeless Packaging") war merklich in den Vordergrund gerückt. Dies stand im auffälligen Kontrast zu den vorhergehenden Alben, was „alten“ Genesis-Fans nicht unbedingt gefiel, jedoch neue Hörerschichten erschloss. Auf "The Lamb Lies Down on Broadway" praktizierte die Band eine Art Arbeitsteilung: Gabriel schrieb die Story und die Songtexte (mit Ausnahme des Textes zu "The Light Dies Down on Broadway," bei dem er Unterstützung von Banks und Rutherford erhielt), die anderen Bandmitglieder komponierten die Musik (mit Ausnahme von "Counting out Time" und "Carpet Crawlers," an denen Gabriel beteiligt war).

Am 12. November begab sich Genesis mit ihrem Werk auf Welttournee, und da "The Lamb..." ein Konzeptalbum war, wurde es komplett aufgeführt. Dabei machte die Gruppe extensiven Gebrauch von Licht- und Lasereffekten; die meisten der damals benutzten Effektgeräte waren Sonderanfertigungen des Niederländers Theo Botschuijver. Ein spezieller Handlaser erlaubte es Peter Gabriel, das Publikum mit verschiedenen Lichteffekten zu behelligen, während sein Slipperman-Kostüm den nicht von allen goutierten Höhepunkt seiner Maskeraden darstellte. Collins erinnerte sich später: „Er steckte in diesem ‚Slipperman‘-Kostüm und versuchte, das Mikrofon irgendwie in die Nähe seines Munds zu bekommen, verwickelte sich und geriet dabei völlig außer Atem. Gegen Ende fand ich, dass der Gesang nicht wirklich zu hören war.“ Bereits gegen Anfang der Tour, im Dezember 1974, hatte Peter Gabriel seinen Bandkollegen verkündet, dass er sie verlassen werde.

Die Gründe für Peter Gabriels Genesis-Ausstieg waren vielschichtig: Die Band wurde in der Öffentlichkeit immer mehr als „Gabriel und seine Mitspieler“ wahrgenommen, was zu internen Spannungen geführt hatte. Diese verstärkten sich noch, als der Frontmann mitten im Schreibprozess zu "The Lamb" einem Angebot des Regisseurs William Friedkin für ein gemeinsames Filmprojekt nachkommen wollte. Als es Ende Juli, kurz vor den Albumaufnahmen, dann noch zu Komplikationen bei der Geburt von Gabriels erster Tochter kam, war die gegenseitige Entfremdung perfekt: Die anderen (kinderlosen) Bandmitglieder zeigten wenig Verständnis für Gabriels Wunsch, sich verstärkt um Frau und Kind zu kümmern, anstatt all seine Zeit in den Dienst der Band zu stellen, deren Durchbruch in den USA mit Händen zu greifen war. Laut späterer Aussage des Sängers fühlte er sich durch die damaligen Umstände „entmenschlicht“.

Gabriels Abschied erfolgte schließlich am 22. Mai 1975 mit dem letzten Konzert der "The-Lamb-Lies-Down-on-Broadway"-Tour im französischen Besançon, wurde aber erst im August publik gemacht. Ursprünglich wollte der Musiker dem Rock-Geschäft für immer Lebewohl sagen, aber noch im selben Jahr nahm er schon wieder erste Demos mit Solomaterial auf. Im Frühjahr 1976 fand in den Londoner Trident Studios eine Session statt, bei der Gabriel zusammen mit Anthony Phillips, Mike Rutherford, Phil Collins und John Goodsall von Brand X unter anderem frühe Versionen seiner Stücke "Here Comes the Flood", "Slowburn" und "Flotsam and Jetsam" aufnahm. Der Song "Solsbury Hill" von seinem ersten Solo-Album "Peter Gabriel" (1977) war eine Allegorie über seinen Abschied von Genesis, in der er seine Ex-Kollegen mit Zeilen wie "„no-one taught them etiquette“" bedachte. Trotz der damals harten zwischenmenschlichen Konflikte sind sich Gabriel und Genesis bis heute in Freundschaft verbunden geblieben – in späteren Jahren äußerte die Band nachträglich volles Verständnis für seine Entscheidung, der Familie den Vorrang zu geben.

Auf der Suche nach einem Nachfolger für Peter Gabriel probierten die verbliebenen Bandmitglieder zahlreiche Sänger aus, bevor sie erkannten, dass der passende Mann für den Job sich bereits in ihren eigenen Reihen befand: Der Schlagzeuger Phil Collins, der schon von Anfang an auch als Background-Sänger der Band überzeugt hatte, übernahm schließlich die Position des Lead-Sängers. Das von David Hentschel (vormals Toningenieur des Albums "Nursery Cryme") produzierte erste Album der Nach-Gabriel-Ära, "A Trick of the Tail," wurde 1976 von Fans und Kritikern freundlich aufgenommen und verkaufte sich besser als alle bisherigen Genesis-Alben. Am Ende des (fast) instrumentalen Stücks "Los Endos" war ein auf Peter Gabriel gemünztes Selbstzitat aus der Suite "Supper’s Ready" zu hören: "„There’s an angel standing in the sun …freed to get back home“". Nach Meinung vieler klang Collins’ Stimme „mehr nach Gabriel als Gabriel selber“. Bei den Liveauftritten der "Trick"-Tour übernahm der ehemalige Yes/King-Crimson-Schlagzeuger Bill Bruford den Posten von Collins, damit dieser sich auf das Singen konzentrieren konnte. Gleichwohl führte Collins gemeinsam mit Bruford bereits die ersten Drum-Duette ein, die später zum Markenzeichen von Collins' Soloauftritten werden sollten. Sein Ansatz als Frontmann bei Live-Auftritten unterschied sich nicht nur durch seine Schlagzeugeinlagen von Gabriels theaterinspirierten Auftritten, seine Interpretationen der Gabriel-Stücke klangen beschwingter. Jahre später, beim Milton-Keynes-Reunion-Konzert von 1982, offenbarte Gabriel Collins, dass er die Lieder "besser" als er selbst sänge, jedoch nie "wie" er.

Im Dezember 1976 wurde das Album "Wind & Wuthering" in Großbritannien veröffentlicht, im Januar 1977 auch weltweit. Es war das erste von zwei in den Hilvarenbeeker Relight Studios aufgenommenen Genesis-Alben. Der Albentitel war Emily Brontës Roman "Sturmhöhe" (engl. "Wuthering Heights") entlehnt, dessen letzte Zeilen "„how anyone could ever imagine unquiet slumbers for the sleepers in that quiet earth“" auch die Titel des siebten und achten Stücks des Albums inspirierte. Das Album beinhaltete u. a. die komplexe mehrteilige Suite "One for the Vine". Bei den Live-Auftritten sitzt seit 1977 der Jazz-Fusion-Musiker Chester Thompson am Schlagzeug, der zuvor unter anderem bei Weather Report und Frank Zappa gespielt hatte. Im Studio und bei längeren Live-Instrumentalparts spielte Collins bis zur letzten Aufnahme 2007 zusätzlich zu Thompson Schlagzeug.

Die beiden unter der Viererbesetzung entstandenen Prog-Alben "A Trick of the Tail" und "Wind & Wuthering" trugen zum Image von Genesis als „Bombastrocker“ bei. Besonders der extrem voluminöse Klang des legendären Moog-Taurus-Basspedals durch Mike Rutherford trug maßgeblich zum unverwechselbaren, kraftvollen Sound von Genesis bei. Die zunehmende Popularität des Punk wird nicht selten als Gegenbewegung dazu angesehen.

Der Gitarrist Steve Hackett fühlte sich in seiner künstlerischen Freiheit in der Band vor allem durch Tony Banks und eine zunehmende Keyboard-Orientierung des Genesis-Sounds stark eingeschränkt. Hackett war auch das erste Bandmitglied, das mit "Voyage of the Acolyte" 1975 ein Soloalbum veröffentlicht hatte, mit dem er respektable Erfolge erzielen konnte. Bei den Aufnahmen zu "Wind & Wuthering" wollte er ein Viertel des Albums zugestanden haben, um sein Songmaterial unterbringen zu können, was laut Collins allerdings „eine blöde Art und Weise war, in einem Band-Kontext zu arbeiten“. Banks, Collins und Rutherford versuchten ihn zu beschwichtigen, indem sie ihm bei den beiden Instrumentalstücken "Unquiet Slumbers for the Sleepers…" / "…In That Quiet Earth" (ursprünglich ein einzelner Song) zusätzlichen kompositorischen Spielraum überließen. Hacketts eigene Komposition "Please Don’t Touch" fand jedoch bei den Kollegen keinen Gefallen und wurde auf dem Album durch einen anderen Instrumentalsong, "Wot Gorilla?," ersetzt, während das von Hackett gemeinsam mit Phil Collins geschriebene "Blood on the Rooftops" nie bei den Live-Auftritten der Band gespielt wurde. Nach der Veröffentlichung der "Spot the Pigeon"-EP (1977), die aus weiteren Stücken der "Wind & Wuthering"-Sessions bestand, verließ Hackett schließlich die Band, als sie gerade dabei war, das Live-Album "Seconds Out" abzumischen.

Die Gruppe entschied sich, als Trio weiterzumachen, was durch den Titel ihres 1978er Albums "… And Then There Were Three …" reflektiert wurde. Mike Rutherford übernahm ab hier das Gitarrenspiel bei den Studioaufnahmen, um sich bei Live-Auftritten mit Daryl Stuermer an Gitarre und Bass abzuwechseln. Mit dem ersten Album in Trio-Besetzung begann auch eine Neuorientierung weg von zehnminütigen Prog-Epen hin zu kürzeren, radiofreundlicheren Songs. Mit "Follow You, Follow Me" landete die Band in den USA ihren ersten Hit, was entscheidend dazu beitrug, dass "And Then There Were Three" in den Vereinigten Staaten „vergoldet“ wurde.

1979 kam es nach Aussage der Band zur größten Gefährdung des Fortbestehens von Genesis seit dem Weggang von Anthony Phillips neun Jahre zuvor: Phil Collins zog ins kanadische Vancouver, um seine in die Brüche gehende Ehe zu retten. Zwei Monate und eine Scheidung später kehrte er jedoch nach Großbritannien zurück und verarbeitete seine Erfahrungen im Album "Duke" (1980). Collins äußerte sich später, dass die gescheiterte Ehe seine Entwicklung als Songschreiber beschleunigt habe. "Duke" war tatsächlich das erste Genesis-Album, auf dem Banks, Collins und Rutherford gleichen Kompositionsanteil hatten. Während sie auf "And Then There Were Three" bemüht waren, kürzere und prägnantere Lieder zu schreiben, stellte "Duke" den eigentlichen Übergang Genesis’ vom Progressive Rock in Richtung des massenkompatiblen und überaus erfolgreichen Poprock der 1980er Jahre dar. Ihr progressiver Sound blieb nur noch in marginalen Ansätzen vorhanden; vollständig ignoriert wurde er aber nie, sondern höchstens dem moderneren Sound der Achtziger angepasst. Die Nutzung eines Drumcomputers war ein gleichbleibendes Merkmal künftiger Genesis- und Collins-Soloalben. Die kommerzieller gestaltete Musik erhielt bei den Massenmedien gute Kritiken. "Duke" war für Genesis der erste Nummer-eins-Erfolg in den BBC-Album-Charts, und die Auskopplungen "Turn It On Again" und "Misunderstanding" waren zwei von der Band gern und häufig gespielte Songs.

Anfang der 1980er Jahre verfügte die Band erstmals in ihrer Geschichte über größere finanzielle Mittel und konnte so das eigene Tonstudio "The Farm" in Surrey aufbauen, in dem sämtliche weiteren Alben aufgenommen wurden. Den Anfang machte 1981 das minimalistisch anmutende Album "Abacab," mit dem die Band versuchte, einen Großteil ihres Bombasts abzuwerfen und neue Wege bei den Arrangements zu beschreiten. Für den Song "No Reply at All" wurde die als Phenix Horns auftretende Bläsersektion der Gruppe Earth, Wind and Fire engagiert. Bezeichnend für "Abacab" war der Einsatz des Collins-typischen "gated-reverb"-Drumsounds, der von Hall-, Lautstärke- und Kompressionseffekten gekennzeichnet ist und Anfang desselben Jahres bereits maßgeblich zum Erfolg von Collins’ Welthit "In the Air Tonight" sowie seines Debütalbums "Face Value" beigetragen hatte. Entwickelt wurde dieser besondere Sound ursprünglich von Peter Gabriel, dem Koproduzenten Hugh Padgham und Collins bei den Aufnahmen zu "Intruder," dem ersten Song auf Gabriels 1980er Album. Der "gated"-Drumsound sollte auch zu "dem" Markenzeichen sämtlicher zukünftiger Genesis- und Collins-Alben schlechthin werden.

1982 veröffentlichte die Band das Live-Doppelalbum "Three Sides Live". Die US-Version dieses Albums bestand aus drei (Schallplatten-)Seiten Live-Material (daher der Albumtitel) plus einer Seite mit Studioaufnahmen, darunter der Song "Paperlate," auf dem erneut die „Earth,-Wind-and-Fire“-Bläser zu hören sind. In Großbritannien waren drei der unveröffentlichten Titel der Studio-Seite bereits mit der EP "3 × 3" auf den Markt gekommen. Daher enthielt die britische Version von "Three Sides Live" weiteres Livematerial, das allerdings älter war und von früheren Tourneen stammte.

Am 2. Oktober 1982 fand in Milton Keynes unter dem Namen "Six of the Best" ein einmaliges Reunion-Konzert statt, an dem sowohl Peter Gabriel als auch (bei den Zugaben) Steve Hackett teilnahmen. Die Organisation fand unter großem Zeitdruck statt; die Konzerteinnahmen sollten dem finanziell angeschlagenen WOMAD-Projekt Gabriels zugutekommen. Zum Leidwesen der Fans existieren von diesem Auftritt keine offiziellen Aufnahmen.

Das Album "Genesis", in Fankreisen auch als "Shapes" oder "Mama-Album" bekannt, war 1983 das dritte Nummer-eins-Album in Großbritannien. Es enthielt radiofreundliche Titel wie "Mama" und "That’s All". Mit "Home by the Sea," das aufgrund seiner Pentatonik in Asien besonders beliebt war, erfolgte eine Reminiszenz an die Zeiten langer und epischer Songs. Das Stück "Just a Job to Do" wurde zur Titelmelodie der ABC-Detektivserie "The Insiders" (1985). Zu dieser Zeit hatte sich das Interesse der Bandmitglieder mehr auf ihre jeweiligen Solokarrieren verlagert, was auch dadurch verdeutlicht wird, dass aus den damaligen Album-Sessions untypischerweise keinerlei zusätzliches Material in Form von Outtakes oder Single-B-Seiten hervorging.

1986, als die Popularität des Solokünstlers Phil Collins ihren Höhepunkt erreicht hatte, veröffentlichten Genesis ihr meistverkauftes Album "Invisible Touch". Das Album brachte fünf US-Top-5-Singles hervor: "Invisible Touch", "In Too Deep", "Land of Confusion", "Tonight, Tonight, Tonight" und "Throwing It All Away". Trotz eines eher mageren Platz 15 in den britischen Charts erreichte der Titelsong als einziger Genesis-Titel überhaupt Platz eins in den US-amerikanischen Billboard-Charts (Hot 100). Anfang des Jahres hatte Collins eine Verulkung seiner Person auf "Spitting Image," einer britischen Satiresendung, gesehen und war so davon beeindruckt, dass die Macher der Sendung mit der Produktion des Musikvideos zu "Land of Confusion" beauftragt wurden. Das Video wurde ein beißend-sarkastischer Kommentar zum Kalten Krieg, in dem Banks, Collins und Rutherford und u. a. auch der als "Superman" verkleidete Ronald Reagan als Gummipuppen dargestellt wurden. Der Clip wurde für den "MTV Video Music Award" nominiert, der dann allerdings an Gabriels "Sledgehammer" ging. Anheuser-Busch nutzte "Tonight, Tonight, Tonight" (ebenso wie Collins’ "In the Air Tonight") für ihre Bierwerbung, während "In Too Deep" im Film "Mona Lisa" Eingang fand. Das Instrumentalstück "The Brazilian" wurde im Zeichentrickfilm "Wenn der Wind weht" verwendet. Auf der Tour zum Album war Genesis 1987 die erste Band, die im Wembley-Stadion vier Abende in Folge vor ausverkauftem Haus spielte. Genesis war damals ebenfalls die erste Band, die "Vari*Lite"-Lichteffekte, "JumboTron"-Videoschirme und das "Prisma"-Soundsystem zum Einsatz brachte, die heutzutage zum Standard bei Rockkonzerten in großen Arenen gehören.

Beim "Prince’s-Trust"-Konzert in der Royal Albert Hall 1988 spielten Phil Collins und Peter Gabriel zum ersten und bislang letzten Mal seit 1982 wieder live zusammen. Collins war an diesem Abend Schlagzeuger der Hausband, die dann auch Gabriel zu seinem Hit "Sledgehammer" begleitete.
Nach einer von Soloaktivitäten ausgefüllten längeren Auszeit – neben Collins war seit Mitte der 1980er Jahre auch Mike Rutherford mit seinem Zweitprojekt Mike & the Mechanics erfolgreich – fand sich die Gruppe 1991 wieder zusammen, um "We Can’t Dance" zu veröffentlichen, Collins’ bislang letztes Studioalbum mit Genesis. Es beinhaltete zumeist erfolgreiche Singles wie "No Son of Mine", "I Can’t Dance", "Hold on My Heart", "Jesus He Knows Me", "Tell Me Why" und "Never a Time", sowie längere Stücke wie "Driving the Last Spike" und "Fading Lights". Den Song "Since I Lost You" schrieb Collins anlässlich des Todes von Eric Claptons Sohn Conor. Für das Album arbeitete die Band erstmals mit Nick Davis zusammen, der seither alle neuen Veröffentlichungen der Band produziert sowie das ältere Material geremastert und geremixt hat. Zuvor hatte er 1988 das Mike-&-the Mechanics-Album "Living Years" als Toningenieur betreut. Der Albenveröffentlichung folgte eine Tournee mit mittlerweile gewohnt gigantischen Ausmaßen. Sie wurde durch zwei "The Way We Walk" betitelte Live-Alben dokumentiert.

Im März 1996 gab Phil Collins seinen Abschied von der Band bekannt:

Rutherford und Banks beschlossen weiterzumachen, benötigten nun aber mehr als nur ein neues Mitglied. Tatsächlich hatte Genesis nicht nur Phil Collins verloren, sondern auch die Live-Musiker Daryl Stuermer und Chester Thompson. Die Band fragte bei Stuermer an, der sich jedoch bereits zu einer Tournee mit Collins verpflichtet hatte. Thompson interessierte sich für die freie Position am Schlagzeug, allerdings machte er sein Engagement von einer Vollmitgliedschaft in der Band abhängig, was Banks und Rutherford ihm nicht einräumen wollten. Schließlich wurden gleich zwei Schlagzeuger verpflichtet, die sich dann die Arbeit auf dem neuen Album teilten: Nir Zidkyahu, ein israelischer Session-Schlagzeuger, der bei der Band Hidden Persuaders gespielt hatte, und Nick D’Virgilio von Spock’s Beard. Die beiden Schlagzeuger hatten durchaus unterschiedliche Spielweisen, D’Virgilio bevorzugte weichere, subtile Rhythmen im Gegensatz zu Zidkyahus dynamischen und Bombast-artigen Spiel.

Als neuen Lead-Sänger engagierten Banks und Rutherford nach wilden Spekulationen der Fans (über Paul Carrack von Rutherfords Nebenband Mike & the Mechanics, den Ex-Marillion-Sänger Fish, mit dem Banks bereits zusammengearbeitet hatte, und sogar eine Rückkehr Peter Gabriels) den früheren Stiltskin-Sänger Ray Wilson. Dem Produzenten Nick Davis zufolge war der einzige andere ernsthaft in Erwägung gezogene Anwärter David Longdon (heute Sänger der Band Big Big Train) gewesen. Kevin Gilbert wurde zum Vorsingen eingeladen, kam jedoch kurz davor auf tragische Weise ums Leben. Ebenfalls beworben hatten sich Francis Dunnery (It Bites) und Nick van Eede (Cutting Crew).

Das Album "… Calling All Stations …" (1997) verkaufte sich in Europa ordentlich, die erfolgreichste Single-Auskopplung "Congo" kam in den britischen Charts auf Platz 29. Bei den Live-Konzerten übernahm Nir Zidkyahu das Schlagzeug, außerdem wurde Anthony Drennan, der bei Paul Brady und den Corrs tätig gewesen war, als Session-Gitarrist angeheuert. In den USA war das Album mit Wilson ein kommerzieller Misserfolg und erreichte nicht einmal die Top 50 der "Billboard"-Charts. Die geplante US-Tournee musste von Genesis aufgrund fehlender Nachfrage storniert werden. Weitere geplante Alben mit Ray Wilson wurden nicht mehr verwirklicht.

Zwischen der Europatour 1998 und dem Jahr 2006 war die Band bis auf Archiv-Veröffentlichungen und diverse Soloprojekte nicht mehr aktiv. In mehr oder weniger regelmäßigen Abständen tauchten immer wieder Gerüchte einer Reunion auf, die sich jedoch immer als falsch erwiesen. Mitte 1998 versammelten sich sämtliche verfügbaren Bandmitglieder der frühen Jahre (die „klassischen 5“ plus Anthony Phillips und John Silver), um anlässlich der Veröffentlichung von "Archive I – 1967–1975" Interviews zu geben und für Pressefotos zu posieren. Im Oktober 1999 beinhaltete die Zusammenstellung "Turn It On Again – The Hits" eine von Trevor Horn produzierte Neuaufnahme von "Carpet Crawlers," die zwar von der gesamten Originalbesetzung des Stückes, jedoch getrennt eingespielt worden war. Im Jahr 2000 gab das Trio Banks/Collins/Rutherford im Londoner Hilton-Hotel ein Privatkonzert für Bandmanager Tony Smith in Form eines kurzen Akustiksets.

Nach zahlreichen Spekulationen über eine Wiedervereinigung wurde im Oktober 2006 in der Presse verlautbart, dass für 2007 tatsächlich eine Tour durch Europa und die USA in der Besetzung Banks/Collins/Rutherford geplant sei. Der ursprüngliche Plan war gewesen, "The Lamb Lies Down on Broadway" mit Peter Gabriel und Steve Hackett erneut auf die Bühne zu bringen, jedoch stand Gabriel aufgrund eigener Aktivitäten für eine Neuauflage von Genesis in Fünferbesetzung vorerst nicht zur Verfügung. Da die Viererversion der Band 1976/77 nur eine kurze Übergangsphase gewesen war, entschieden sich Banks/Collins/Rutherford dazu, stattdessen als Trio aufzutreten. In einer kurzen Notiz auf seiner Webseite zeigte Steve Hackett Verständnis dafür und übermittelte seine besten Wünsche für die Reunion-Tournee.

Am 7. November 2006 wurde "Turn it on Again – The Tour" auf einer Pressekonferenz in London offiziell angekündigt, um am 11. Juni 2007, ziemlich genau vierzig Jahre nach Gründung der Band, in Helsinki zu starten. Die Tour umfasste insgesamt 22 Konzerte in Europa, neun davon in deutschen Stadien (Hamburg, Hannover, 2x Düsseldorf, Stuttgart, Berlin, Leipzig, Frankfurt und München). Innerhalb von neun Stunden wurden allein in Deutschland 200.000 Konzertkarten verkauft. Der Abschluss des Europaabschnitts der Tour erfolgte am 14. Juli in Rom, wo die Band im Circus Maximus bei freiem Eintritt von etwa einer halben Million Zuschauer gesehen wurde. Vom 7. September (Toronto) bis 13. Oktober (Los Angeles) ging es für 24 Konzerte nach Kanada und in die USA. Verstärkt wurde die Band wieder durch ihre alten Begleiter Daryl Stuermer und Chester Thompson. Die Setlist umfasste Stücke aus der Zeit von 1973 bis 1991. Das zweite der beiden Konzerte in der LTU-Arena in Düsseldorf wurde am 27. Juni 2007 live in Kinos in Großbritannien, Schweden und Spanien übertragen. Alle Konzerte wurden live mitgeschnitten und auf CD veröffentlicht. Aus diesem Material der Tour wurde das Live-Album Live over Europe 2007 zusammengestellt und zusammen mit der Live-DVD "When in Rome" die Tour dokumentiert.

2007 brachte die Band zudem zwei Boxsets mit digital remasterten und neu abgemischten Original-Alben heraus. Die erste Box umfasst die Schaffensperiode "1976–1982" und enthält die Alben "A Trick of the Tail, Wind & Wuthering, … And Then There Were Three …, Duke" und "Abacab," die zweite Box deckt die Jahre "1983–1998" ab und enthält die Alben "Genesis, Invisible Touch, We Can’t Dance" und "… Calling All Stations …".

Als Besonderheit wurden die Aufnahmen auf Hybrid-SACD und DVD-Video veröffentlicht und liegen auf der DVD im 5.1-DTS- und Dolby-Digital-Sound vor. Die DVD enthält zusätzlich noch die Musik-Videos der entsprechenden Alben und dazugehörige Live-Auftritte der Gruppe. Weiterhin ist in beiden Boxsets jeweils eine Bonus-Hybrid-SACD und Bonus-DVD mit den Non-Album-Tracks der jeweiligen Periode, seltenen Videoaufnahmen, sowie aktuellen Interviews enthalten.

Ende 2008 folgte in der gleichen umfangreichen Ausstattung das Boxset "1970–1975", das die Alben "Trespass" bis "The Lamb Lies Down on Broadway" abdeckt. Als „Sahnehäubchen“ enthalten sind unter anderem die "Jackson-Tapes" von 1970, in denen spätere Stücke der Band bereits embryonal enthalten waren, sowie auf DVD alle Original-Dias, die 1974/75 bei den "The-Lamb"-Shows zu sehen waren. Die Box verkaufte sich von allen am besten und belegte in den deutschen Charts einen beachtlichen 22. Platz.

Im September 2009 erschien das vierte Boxset "1973–2007 Live", das die geremixten Live-Alben von Genesis inklusive Bonus-Material enthält (minus "Live over Europe 2007"). Ein fünftes Boxset, "1981–2007: The Movie Box", folgte im November.

Am 26. März 2009 starb der "Trespass"-Schlagzeuger John Mayhew 61-jährig an einem Herzinfarkt. Phillips, Banks und Hackett gedachten seiner in kurzen Nachrufen auf ihren jeweiligen Webseiten.

Im April 2009 musste sich Phil Collins einer Halswirbeloperation unterziehen. Seitdem hat er Taubheitsgefühle in den Händen, so dass er nur noch eingeschränkt Schlagzeug spielen kann.

Im Dezember desselben Jahres wurde die Aufnahme von Genesis in die "Rock and Roll Hall of Fame" bekanntgegeben. Die Prozedur fand im März 2010 unter Anwesenheit von Banks, Collins, Rutherford und Hackett statt. Gabriel entschuldigte sein Fernbleiben damit, seine Live-Tournee vorbereiten zu müssen.

Im März 2011 wurde ein Interview mit Collins von den Medien zunächst als das Ende seiner musikalischen Karriere gedeutet. Damit schien eine Fortsetzung von Genesis in der langjährigen Formation unwahrscheinlich geworden. Collins relativierte jedoch seine diesbezüglichen Äußerungen kurz darauf und nannte die Kommentare der Medien hierzu eine Fehlinterpretation.

In einem Interview mit dem "Rolling Stone" sagte Peter Gabriel im September 2011, dass ein Wiedersehen mit der klassischen Besetzung immer noch eine – allerdings sehr unwahrscheinliche – Möglichkeit sei, und erklärte: „"I won’t say never ever, but it’s in the outside department of the betting shop...if you stick with the stuff that nourishes you the most then you’ll probably be the happiest"“.

In einem Interview mit "BBC Breakfast" am 4. Mai 2012 sagte Banks, dass es wahrscheinlich kein Comeback von Genesis mehr geben werde, und erklärte: „"I think we probably won’t do it. Phil, particularly, has sort of moved on somewhat. We did do that last tour three or four years ago as a sort of goodbye. That was the idea of it."“

Steve Hackett ist seit April 2013 mit der Musik seiner Ex-Band auf Welttournee. Bei den Stücken "The Carpet Crawlers", "I Know What I Like" und "Firth of Fifth" wurde er dabei gelegentlich von Ray Wilson gesanglich unterstützt. Die Tour ist so erfolgreich, dass noch bis November 2014 weitere Konzerte angekündigt wurden.

Bei einem Interview im Rahmen der Premiere seines Musicals "Tarzan" in Stuttgart deutete Phil Collins im November 2013 überraschend an, bald wieder Solo-Material veröffentlichen oder sogar Genesis wiederbeleben zu wollen: „"I have started thinking about doing new stuff, some shows again, even with Genesis. Everything is possible. We could tour in Australia and South America. We haven’t been there yet."“

Mike Rutherford veröffentlichte 2014 mit "Rhythmen des Lebens – Die erste Genesis-Autobiografie" (Originaltitel "The Living Years") als erstes Bandmitglied von Genesis eine Autobiographie, die in weiten Teilen die Entwicklung der Gruppe aus seiner Perspektive und Erinnerung beschreibt.

Im Herbst 2014 ist eine 3-CD-Kollektion mit dem Titel "R-Kive" erschienen. Diese enthält neben Genesis-Titeln auch ausgewählte Musikstücke aus den Repertoires von Phil Collins, Peter Gabriel, Tony Banks, Steve Hackett und Mike Rutherford.

Genesis waren durch ein breites Musikspektrum von der klassischen Musik bis hin zum Mainstream-Rock und Jazz beeinflusst. Die Arrangements ihres ersten Albums "From Genesis to Revelation" orientierten sich an The Moody Blues und dem Family-Debütalbum "Music In A Doll’s House" (1968). Im darauffolgenden Jahr war die gesamte damalige Band von King Crimsons Debütalbum "In the Court of the Crimson King" (1969) fasziniert, das deutliche Spuren in ihrer Musik hinterließ. Als weitere wichtige frühe Einflüsse wurden von den Musikern Bands mit klassischen Anklängen wie Procol Harum und The Nice genannt, aber auch die Folkrock-Band Fairport Convention.

Banks bezeichnete Alan Price von den Animals als „die erste Person, die mich der Orgel im Rock-Kontext bewusst werden ließ“. Zu seinen Einflüssen aus der Klassik zählt der Pianist Rachmaninow, die Komponisten Ravel, Mahler und Schostakowitsch. Collins war Buddy Rich und dem jazzigen Mahavishnu Orchestra zugetan, die Eingang in seinen Schlagzeugstil fanden. Gabriel ließ sich gesanglich von persönlichen Favoriten wie Nina Simone, Otis Redding und Familys Roger Chapman inspirieren. Alle Mitglieder der Fünferbesetzung waren zudem Fans der Beatles, auch wenn deren Einfluss eher selten zu erahnen ist (etwa bei "I Know What I Like").

Die meisten (Ex-)Mitglieder der Band haben bei ihren Solo-Konzerten auch Genesis-Material im Programm. Steve Hackett begann 2013 eine ganze Tournee mit Genesis-Stücken der 1970er Jahre. Zu Gabriels Live-Repertoire gehörten zu Beginn seiner Solokarriere die Titel "The Lamb Lies Down on Broadway" und "Back in NYC". Collins spielte seine Neuinterpretation von "Behind the Lines", sowie später auch "I Can’t Dance", "Turn It On Again", "Misunderstanding" und "Invisible Touch". Mike & the Mechanics spielten u. a. "Follow You Follow Me" und "I Can’t Dance". Etliche Genesis-Songs wurden von Ray Wilson live interpretiert und sind auf verschiedenen Live-Alben dokumentiert. Seit 2009 tourt Wilson in Sachen Genesis regelmäßig mit dem Berlin Symphony Ensemble, zu hören auf "Genesis Klassik – Live in Berlin" und "Genesis Classic – Live in Poznan".

Der erste Künstler, der einen Genesis-Song im Studio coverte, war Phil Collins mit "Behind the Lines" auf seinem Debütalbum "Face Value". 1992 spielte die deutsche Band Mekong Delta eine Thrash-Metal-Version von "Dance on a Volcano" für ihr Album "Kaleidoscope" ein. 1993 versuchte sich Fish auf seinem Fremdkompositionen vorbehaltenen Werk "Songs from the Mirror" an "I Know What I Like". Im selben Jahr war "Carpet Crawlers" in der Interpretation der deutschen Band M. Walking on the Water auf deren EP "Pictures of an Exhibitionist" zu hören. Das 1998 postum veröffentlichte Album "Sketches for My Sweetheart the Drunk" von Jeff Buckley enthielt eine Coverversion von "Back in NYC". Jordan Rudess von Dream Theater nahm 2007 für sein Tribut-Album "The Road Home" ein Rearrangement von "Dance on a Volcano" mit Sänger Neal Morse (Spock’s Beard) auf, zu dem es positives Feedback von Tony Banks gab; ferner baute Rudess im Stück "JR Piano Medley" Teile von "Supper’s Ready" ein. Zum 40-jährigen Jubiläum von Genesis coverte Simon Collins 2007 den Song "Keep it Dark" und stellte ihn zum freien Download ins Internet. 2009 sampelte der kanadische Rapper Classified "No Reply at All" für seine Single "Anybody Listening".

Besonderes Interesse genießt das Stück "Land of Confusion": Die schwedische Death-Metal-Band In Flames coverte es 2003 auf ihrer EP "Trigger," ebenso Disturbed 2005 auf ihrem Album "Ten Thousand Fists". Zudem nutzte die schwedische Discopop-Gruppe Alcázar den Refrain des Songs für ihren Hit "This is the World We Live In" von 2004. Auch die Version der norwegischen Folk-Rock-Band Katzenjammer vom Album "A Kiss Before You Go" (2011) erreichte einige Bekanntheit.

Es existieren auch ganze Tribute-Alben, auf denen diverse, zumeist unbekanntere Musiker Genesis-Stücke coverten. Die bekanntesten dieser Kompilationen sind "The River of Constant Change" (1995, unter anderem mit Galahad und der deutschen Tributband Seconds Out), "Supper’s Ready" (1995, mit Annie Haslam, Kevin Gilbert, Richard Sinclair) und "The Fox Lies Down" (1998, mit John Wetton, Daevid Allen, The Flower Kings).

Auch Steve Hackett zollte 1996 auf seinem Album "Genesis Revisited" (US-Titel: "Watcher of the Skies") mit den Gästen John Wetton, Bill Bruford, Ian McDonald, Paul Carrack, Chester Thompson, Tony Levin, Colin Blunstone und dem Royal Philharmonic Orchestra seiner ehemaligen Band Tribut. 2012 ließ er "Genesis Revisited II" folgen, bei dem u. a. Steven Wilson, Nik Kershaw, Francis Dunnery, Simon Collins, Steve Rothery, Mikael Åkerfeldt, Roine Stolt, Neal Morse und abermals Wetton mitwirkten. 2013 nahm Hackett zudem mit Ray Wilson eine Version von "The Carpet Crawlers" auf.

Des Weiteren wurden den Genesis-Werken Interpretationen von Klassik über Jazz bis zu (Pseudo-)Gregorianischem Gesang zuteil. Auf Phil Collins’ Live-Album "A Hot Night In Paris" von 1999 sind die Genesis-Stücke "That’s All, Invisible Touch, Hold on My Heart" und "Los Endos", benannt als "The Los Endos Suite", im Big-Band-Gewand zu hören. Eine ebenfalls rein instrumentale Angelegenheit war das 2000 von Daryl Stuermer präsentierte Werk "Another Side of Genesis" mit Smooth-Jazz-Versionen einiger Hits der Band.

Der vor allem mit der Band Spock’s Beard in Erscheinung tretende kurzzeitige Session-Drummer von Genesis, Nick D’Virgilio, wagte sich 2008 in Zusammenarbeit mit Produzent Mark Hornsby an eine Neuinterpretation des kompletten Doppelalbums "The Lamb Lies Down on Broadway". Das "Rewiring Genesis: A Tribute to The Lamb Lies Down on Broadway" genannte Werk wurde von ausgesuchten Musikern aus Nashville mit starken Jazz-Anklängen eingespielt.

Martin Levac, Ex-Schlagzeuger von The Musical Box, veröffentlichte die Alben "A Visible Jazz Touch of Genesis" (2011) und "A Visible Jazz Touch Of Genesis... Live" (2013), letzteres mit vollständig anderen Songs.

Aus der Klassik-Abteilung können lediglich das von David Palmer (mittlerweile Dee Palmer) mit dem London Symphony Orchestra und Gastmusiker Steve Hackett eingespielte Album "We Know What We Like" (1987) sowie das ebenfalls von Hackett unterstützte zweiteilige Projekt "Genesis for two Grand Pianos" (2002/05) der Pianisten Yngve Guddal und Roger T. Matte überzeugen.

Tolga Kashif präsentierte 2010 mit dem London Symphony Orchestra das durch Genesis-Kompositionen inspirierte Werk "The Genesis Suite". Die verwendeten Stücke von Genesis (1. "Land of Confusion / Tonight, Tonight, Tonight", 2. "Ripples", 3. "Mad Man Moon", 4. "Follow You Follow Me", 5. "Fading Lights", 6. "Entangled", 7. "Undertow / Blood on the Rooftops") wurden nicht für Orchester umgeschrieben, sondern neu komponiert und beinhalten nur Spuren der Originale. Das Werk ist eher eine Anlehnung an die "Genesis Suite" von Nathaniel Shilkret aus dem Jahr 1945.

Als Vorreiter des Progressive-Rock-Genres werden Genesis von zahlreichen der seit den frühen 1980er Jahren aufgetauchten Neo-Progrock-Gruppen als Einfluss genannt: Marillion, IQ, Dream Theater, echolyn, Spock’s Beard, The Flower Kings, Änglagård, Phish, Pendragon und Opeth, ebenso von älteren Bands wie Ange, Camel, Rush, Goblin, Kansas und Saga.

Tribute-Bands wie The Musical Box, ReGenesis oder Duke führen regelmäßig meist älteres Genesis-Material aus der Peter-Gabriel-Ära auf. Angelehnt an diese Ära, wenn auch mit eigenen Kompositionen, spielt auch die italienische Retro-Prog-Band The Watch, deren Sänger zudem eine große stimmliche Ähnlichkeit mit Gabriel verbindet.

Die Alben-Cover von Genesis reflektieren die Musikthemen des jeweiligen Albums und sind meist aufwändig und komplex gestaltet. Das erste Album hatte ein ganz in schwarz gehaltenes Cover mit dem Schriftzug "From Genesis to Revelation" in goldener gebrochener Schriftart in der oberen linken Ecke. Der Name der Band wurde ansonsten nicht erwähnt. Das Cover dieses Albums änderte sich mit nahezu jeder der zahlreichen Wiederveröffentlichungen.

Die Cover der drei folgenden Alben stammten alle von Charisma-Records-Grafiker Paul Whitehead: Das "Trespass"-Cover basiert auf einer Illustration von Willy Pogány aus dem Jahr 1911 für das Buch „Tannhäuser: A Dramatic Poem“, das Cover von "Nursery Cryme" war durch die Geschichte rund um den Song "The Musical Box" beeinflusst, das von "Foxtrot" zeigt eine weibliche Figur in einem roten Kleid mit dem Kopf eines Fuchses. Whitehead gab in einem Interview an, dass der Jimi-Hendrix-Song "Foxy Lady" ihn zu dieser Darstellung inspiriert hatte, die wiederum Gabriel zu einer seiner ersten Kostümierungen inspirierte.

Nachdem Whitehead nach Los Angeles gezogen war, verwendeten Genesis für das nächste Album "Selling England by the Pound" eine bereits bestehende Zeichnung von Betty Swanwick, zu der die Künstlerin lediglich noch den Rasenmäher hinzuzeichnete. Später engagierte die Band die renommierte Designer-Firma Hipgnosis, deren Künstler bereits die Cover für "The Dark Side of the Moon" von Pink Floyd und "Houses of the Holy" von Led Zeppelin entworfen hatten. Das erste Hipgnosis-Album-Cover für Genesis wurde für "The Lamb Lies Down on Broadway" erstellt. Hier war zum ersten Mal auf einem Genesis-Album auch eine reale Person abgebildet, die laut dem Covertext den schlichten Namen Omar trug und den Protagonisten Rael darstellte.

Die übrigen Genesis-Alben-Cover der 1970er Jahre wurden von verschiedenen Hipgnosis-Künstlern, allen voran Colin Elgie, gestaltet. Auf dem Cover von "A Trick of the Tail" waren einige der Song-Charaktere abgebildet: Der Räuber von "Robbery, Assault and Battery," der "Squonk," das Untier vom Titelsong und von "Ripples" ein metaphorisches Bild eines alten Menschen, der in Erinnerungen an die Jugendzeit schwelgt. "Duke" wurde mit Karikaturen von Lionel Koechlin aus dessen Kinderbuch "L’alphabet d’Albert" illustriert. "Abacab" und "Genesis" gestaltete das Bill Smith Studio. Für das Cover des meistverkauften Genesis-Albums "Invisible Touch" zeichneten Assorted Images verantwortlich, die zuvor Cover für Duran Duran und Culture Club erstellt hatten. Das an "Wind & Wuthering" erinnernde "We-Can’t-Dance"-Aquarell stammt von Felicity Bowers. Die Cover von "Calling All Stations" und der Kompilation "Turn it on Again: The Hits" wurden von Wherefore Art? entworfen.

Aufgrund ihrer „Progressive-Rock“-Wurzeln und ihres Public-School-Hintergrunds unterschieden sich Genesis von anderen Rock-Musikern ihrer Zeit. Die meiste Kritik, der sich die Band in den frühen 1970er Jahren ausgesetzt sah, richtete sich dabei gegen den Progressive Rock im Allgemeinen, den viele als zu verkopft und zu komplex ablehnten. Anhänger konventionellerer Rockmusik und sogar Genesis-Fans waren zudem von den zunehmend theatralischen Auftritten und den Maskeraden Gabriels befremdet. Als 1976 der Siegeszug des Punk begann, galten Genesis mitunter als kraftlos und langweilig: 1977 beschrieb ein Artikel des "Q"-Magazins eine Ray-Lowry-Karikatur, in der Fans einem Auftritt der Band "GENESNOOZE" (engl. "snooze" = Nickerchen) „entweder schlafend, sterbend [oder] komatös“ beiwohnten.

Aber auch mit ihrem Wechsel von längeren und komplexeren Stücken zu kompakteren und zugänglicheren Popsongs konnten Genesis es nach dem Ausscheiden von Gabriel und Hackett vielen früheren Fans und insbesondere zahlreichen Kritikern nicht recht machen. Indem sich die Band immer mehr dem gängigen Pop-Sound annäherte, feierte sie zwar viel größere kommerzielle Erfolge als zuvor, doch musste sie sich zugleich mit dem Vorwurf des künstlerischen Ausverkaufs auseinandersetzen. Eine vernichtende Plattenkritik im "Rolling Stone" zu "And Then There Were Three" äußerte sich folgendermaßen: „Kurz gesagt ist dieses verachtenswerte Werk nichts weiter als der bleiche Schatten früherer Leistungen der Gruppe. Der Schaden ist nicht nur unabänderlich, er wurde auch weithin bekräftigt: "And Then There Were Three" ist Genesis’ erste Goldene Schallplatte in den USA.“ Allerdings verließ die Band die Pfade des epischen, ausgedehnten Rocks nie vollständig; auf jedem ihrer Studioalben finden sich Songs von mehr als sechs Minuten Länge.

Vor allem Collins wurde häufig für Genesis’ Wandel von einer Progrock-Gruppe zu einer Mainstream-Poprock-Band, deren Musik sich kaum von der des Solokünstlers Collins unterscheide, kritisiert. „Ich denke nicht, dass wir uns selber verfälscht haben“, sagte hingegen Collins 1990 in einem "Music-Express"-Interview. „Irgendwann mal werde ich die Schuld für die Veränderung auf mich nehmen, ich denke aber nur, dass wir älter geworden sind und uns anderen musikalischen Dingen zugewendet haben.“ Tatsächlich zeichneten alle drei Bandmitglieder seit 1978 gemeinsam für den Sound und die graduelle musikalische Weiterentwicklung verantwortlich, so dass die sich allein auf Collins richtende Kritik nur in Teilen zutrifft. Die oft geäußerte Vermutung, erst Gabriels Ausscheiden habe den Wandel von Genesis ermöglicht, ist fragwürdig, weil auch Gabriel als Solokünstler bald konventionellere Songstrukturen verwendete.











</doc>
<doc id="10356" url="https://de.wikipedia.org/wiki?curid=10356" title="Falklandinseln">
Falklandinseln

Die Falklandinseln (), auch Malwinen (, ), sind eine Inselgruppe im südlichen Atlantik. Sie gehören geographisch zu Südamerika und liegen 395 km östlich von Südargentinien und Feuerland. Die Falklandinseln sind ein britisches Überseegebiet mit innerer Autonomie. Das Vereinigte Königreich übernimmt Verteidigung und Außenpolitik. Seit 1833 werden sie von Argentinien beansprucht.

Die Falklandinseln waren vor etwa 400 Millionen Jahren Teil des Urkontinents Gondwana. Ursprünglich vor der heutigen Ostküste Südafrikas gelegen, wurde ein kleines Krustenfragment, aus dem heute die Inseln bestehen, isoliert und driftete Richtung Westen. Während des Jura, vor etwa 170 Millionen Jahren, drehten sich die Landstücke, die heute Ost- und Westfalkland bilden, um ca. 120°.

Die Falklandinseln bestehen aus etwa 200 Inseln, deren wichtigste Westfalkland und Ostfalkland mit je etwa 6.000 km² sind (140 km × ca. 50 km). Die nördlichen Teile der beiden Hauptinseln sind von Hügelketten überzogen. Sie verlaufen in West-Ost-Richtung und erreichen im Mount Usborne auf Ostfalkland 708 m Höhe. Der zweithöchste Berg heißt Mount Adam und befindet sich auf Westfalkland.

Zwischen Ost- und Westfalkland verläuft der breite Falklandsund, an dem Port Howard liegt. Auch die Ostinsel selbst wird von einem langen Fjord (bei Darwin) beinahe in zwei Hälften geteilt; an ihrer zum Atlantik blickenden Ostküste liegt die Hauptstadt Stanley mit rund 2000 Einwohnern. Von den übrigen 200 Inseln sind nur etwa fünf größer als 10 km².

Die heutige Landschaft der Falklandinseln wurde durch die wiederholten Vergletscherungen im Eiszeitalter geformt. Dabei bildete sich vor allem eine glaziale Abtragungslandschaft. Fjorde, Rundhöcker und durch das Eis geformte Seen sind typisch. In der Nacheiszeit sind viele Landstriche aufgrund des feuchtkalten Klimas vermoort.


Die Zwergstrauchheiden der Falkland-Inseln werden aufgrund ihres Erscheinungsbildes zum Teil als Tundra bezeichnet, obwohl das mildere Klima und die fehlenden Permafrostböden deutlich vom typischen Tundrenklima abweichen. Die Zuordnung der Vegetation ist in der Literatur uneinheitlich.

Insgesamt verzeichnet die Flora der Falklandinseln 278 Arten. Die Inseln sind überzogen von zahlreichen Gräsern – meist Seggen- und Rispengräserarten – sowie verschiedenen Kleearten. Eine Besonderheit ist die ansonsten nur in Südamerika heimische "Arachnitis uniflora". Bäume kommen ursprünglich nicht auf den Inseln vor. Es gibt heute einige wenige angepflanzte Bäume, zumeist Koniferen.

Es gab auf den Falklandinseln nur ein heimisches Landsäugetier, den Falklandfuchs, der im 19. Jahrhundert ausgerottet wurde. Daneben gibt es 63 heimische Vogelarten, darunter Albatrosse, Versicolorenten, die Falklanddrossel, den endemischen Falklandpieper, den Falkland- und den Schopfkarakara. An den Küsten brüten Pinguinkolonien, die mehrere Millionen Tiere umfassen. Außerdem findet man an den Küsten Kolonien von Mähnenrobben, Südamerikanischen Seebären und von Südlichen See-Elefanten. Heute gibt es auf den Inseln neben den sehr häufigen Schafen zahlreiche eingeschleppte Tiere, wie etwa Ratten, Mäuse, Kaninchen und Katzen.

Das Klima ist kalt, windig und regenreich. Die jährliche Durchschnittstemperatur liegt bei nur 5 °C. Verglichen mit London oder Köln, die auf derselben (nördlichen) Breite liegen, ist das ein Unterschied von fast 5 °C. Das hängt vor allem mit der Landverteilung Nord-Süd sowie dem das Klima der Nordhalbkugel beeinflussenden Golfstrom zusammen. Nur im Hochsommer (Dezember, Januar und Februar) steigt die Temperatur an wenigen Tagen auf annähernd 20 °C. Sonst liegt die durchschnittliche Tagestemperatur auch zwischen Oktober und April bei 8 °C bis 12 °C. Verglichen mit europäischen klimatischen Verhältnissen herrschen auf den Falklandinseln selbst in den Frühlings- und Sommermonaten spätherbstliche Temperaturen. Zwischen Mai und September besteht oft Frost. Tagsüber steigt in diesen Monaten die Temperatur selten auf über 1 °C bis 3 °C. Auf Grund des ozeanisch geprägten Klimas sind strenge Fröste von unter −15 °C die Ausnahme. Es regnet oder schneit an durchschnittlich 200 Tagen im Jahr.

Insgesamt ähnelt das Klima eher dem der Shetland- oder Färöer-Inseln im Nordatlantik, wobei die Jahreszeiten auf Falkland noch maritimer, sprich die Sommer kühler und die Winter milder sind.

Vor der Ankunft europäischer Siedler waren die Falklandinseln unbewohnt. 1592 wurden sie vom englischen Seefahrer John Davis entdeckt, der sie jedoch nur sichtete. Er hatte sich von Puerto Deseado aus auf die Suche nach den anderen drei Schiffen unter dem Kommando von Thomas Cavendish gemacht, war jedoch in einen Sturm geraten, der ihn nach Falkland führte. Es dauerte weitere 98 Jahre, bis die Inseln erstmals 1690 von John Strong betreten wurden. Er gab der Meeresenge zwischen den beiden Hauptinseln, zu Ehren des „Schatzmeisters der Marine“ und britischen Politikers Anthony Cary, 5. Viscount Falkland, den Namen "Falkland Channel". Der Name „Falkland“ ging später auf die gesamte Inselgruppe über.

Die erste Siedlung, Port-Louis auf Ostfalkland, wurde 1764 unter französischer Herrschaft von Louis Antoine de Bougainville gegründet; 1766 etablierten die Briten auf Westfalkland die Siedlung Port Egmont, zogen dort allerdings acht Jahre später wieder ab. Der argentinische Name "Islas Malvinas" geht auf die französische Bezeichnung der Inselgruppe – „"Îles Malouines"“ – zurück, der sich auf die Seeleute und Fischer aus der bretonischen Hafenstadt Saint-Malo bezieht, die die ersten bekannten Siedler der Inselgruppe waren.

Port-Louis wurde schon 1766 an Spanien übergeben. 1811 stellte Spanien den Unterhalt der Kolonie ein, verzichtete aber nicht auf die Souveränität über die Inseln. Seitdem sind die Falklandinseln Gegenstand von Territorialstreitigkeiten, anfangs zwischen Großbritannien und Spanien, danach bis heute zwischen Großbritannien und Argentinien. 1820 wurde die Inselgruppe von Argentinien physisch in Besitz genommen, die argentinische Siedlung in Port Louis zählte bis zu 100 Einwohner.

Das Vereinigte Königreich behauptete seine Ansprüche, indem es 1833 einen Flottenstützpunkt auf der Insel errichtete und die argentinische Verwaltung zum Abzug zwang. 1837 wurde eine Kolonialverwaltung eingerichtet.

Im Ersten Weltkrieg fand zwischen deutschen Kreuzern und einem überlegenen britischen Flottenverband das Seegefecht bei den Falklandinseln statt. Das deutsche Ostasiengeschwader unter Vizeadmiral Maximilian Graf von Spee wollte in den Atlantik in Richtung Deutschland durchbrechen und wurde am 8. Dezember 1914 von den Briten unter Vizeadmiral Sir Frederik Doveton Sturdee fast vollständig vernichtet.
Die militärische Besetzung der Inseln durch Argentinien am 2. April 1982 löste den Falklandkrieg aus: Großbritannien reagierte und landete sieben Wochen später mit Truppen auf den Inseln. Nach kurzen, aber blutigen Kämpfen konnten die britischen Truppen Argentinien am 14. Juni 1982 zur Aufgabe bewegen. Es fielen ca. 900 Soldaten, davon 649 Argentinier.

Insgesamt kostete der Falklandkrieg mehr als 1.000 Menschen das Leben. Seitdem ist eine größere Zahl von Soldaten auf den Inseln stationiert, im Jahr 2012 nach Angaben des britischen Verteidigungsministeriums 1.350 Mann unter dem Kommando des „Commander of the British Forces South Atlantic Islands (CBFSAI)“. Es handelt sich überwiegend um Infanteristen, Pioniere und Funker. Daneben sind verschiedene britische Kriegsschiffe dauerhaft im Südatlantik stationiert, zur Zeit u. a. die HMS "Clyde" und die HMS "Portland", sowie mutmaßlich U-Boote der "Trafalgar"-Klasse mit atomarer Bewaffnung. Im letzten Jahrzehnt hatte sich der latente Konflikt zwar in der allgemeinen Wahrnehmung etwas entspannt. Seitdem hier 60 Milliarden Barrel Öl vermutet werden, haben sich aber viele lateinamerikanische Regierungen mit Argentinien solidarisiert. Die politische Führung des Landes erneuert jedes Jahr den argentinischen Anspruch auf die Inseln, so auch die ehemalige Präsidentin Cristina Fernández de Kirchner.

Im Zusammenhang mit den Territorialstreitigkeiten mit Argentinien kündigte die Regierung der Falklandinseln Anfang Juni 2012 für die erste Jahreshälfte 2013 eine Volksabstimmung über den politischen Status an. Die Regierung trug ihr Anliegen außerdem vor den UN-Ausschuss für Entkolonialisierung, wo Kirchner den Anspruch ihres Landes dadurch begründete, man könne keine Inselgruppe „als britisches Territorium erklären, wenn es 14.000 Kilometer von Großbritannien entfernt“ sei. Die Inseln seien „Teil des Südatlantiks und Argentiniens.“ Der Versuch des Vertreters der Falklandinseln, Mike Summers, der argentinischen Staatschefin nach ihrer Rede einen Brief zu übergeben, in dem er Gespräche mit der Inselregierung anbot, schlug fehl, als sich der argentinische Außenminister Héctor Timerman weigerte, den Brief an Kirchners Stelle anzunehmen. Er wies Summers Ansinnen mit den Worten zurück, er solle das Schreiben zur argentinischen Botschaft schicken.

Anfang Januar 2013 forderte Kirchner den britischen Premierminister David Cameron in einem offenen Brief auf, die Falklandinseln an Argentinien zu übergeben.

Seit 1946 steht das Territorium auf der UN-Liste der Hoheitsgebiete ohne Selbstregierung. Am 10. und 11. März 2013 wurde ein Referendum über den zukünftigen politischen Status der Inselgruppe abgehalten. 99,8 Prozent der Bewohner sprachen sich für einen Verbleib bei Großbritannien aus, nur drei Bewohner stimmten dagegen. Stimmberechtigt waren 1672 Menschen, die Wahlbeteiligung lag bei ca. 92 Prozent. Die argentinische Präsidentin Kirchner hatte allerdings schon im Vorfeld angekündigt, das Ergebnis des Referendums nicht anerkennen zu wollen. Nachdem sich die große Mehrheit der Inselbewohner für eine weitere Zugehörigkeit zu Großbritannien entschieden hatte, bezeichnete Kirchner das Referendum am 12. März 2013 als „Parodie“. Der britische Premierminister David Cameron erklärte, dass Argentinien das Referendum anerkennen müsse, und die britische Regierung gab bekannt, dass sie alles tun werde, um die Inseln zu verteidigen.

Die UN-Commission on the Limits of the Continental Shelf entschied im März 2016, dass die Gewässer Argentiniens die Falklandinseln mit einschließen, da die Wasserfläche des Landes gemäß einem Bericht Argentiniens aus dem Jahr 2009 um 1,7 Millionen Quadratkilometer ausgedehnt wurde und zwischen 320 km und 560 km von der Küste endet. Die Regierung der Falklandinseln erklärte, dass die UN-Kommission nicht über umstrittene Gebiete entscheiden dürfte und die Auswirkungen der Entscheidung blieben zunächst unklar.

Die Bevölkerung stammt überwiegend von Einwanderern von den Britischen Inseln ab, die in den 1830er Jahren auf die Inseln kamen. Sie waren durchweg nordenglischen und schottischen Ursprungs. In den 1840er Jahren wanderten auch einige Menschen aus St. Helena und Chile ein. Nach dem Falklandkrieg kam es zu einer erneuten, teilweise aus Neuseeland herrührenden Einwanderung, die die Einwohnerzahl vergleichsweise stark erhöhte.

Zwei Drittel der rund 3.000 Einwohner (ohne das in Mount Pleasant konzentrierte Militär) wohnen in der Hauptstadt Stanley, die auch zugleich Hauptort von Ost-Falkland ist. Der Hauptort von West-Falkland, Port Howard, der über eine eigene asphaltierte Landebahn verfügt, hat nur 22 Einwohner (Census: 2012). Von den übrigen Siedlungen auf den beiden Inseln haben weniger als zehn mehr als 50 Einwohner. Die restlichen Siedlungen verteilen sich über eine große Fläche und sind sogenannte „camp settlements“, vergleichbar mit Weilern, bisweilen sogar nur „camps“, also Einzelhöfe.

Die Falkländer, die sich selbst auch als „Kelpers“ ("kelp:" englisch für Tang, also etwa „die vom Tang Lebenden“) bezeichnen, sprechen falkländisches Englisch, eine Sprachvarietät des britischen Englisch mit einem Akzent, der unter anderem an das Schottisch- und das Norfolk-Englisch erinnert. Des Weiteren gibt es viele Lehnwörter, die aus dem Spanischen kommen, besonders die Viehhaltung und den Umgang mit Pferden betreffend (Gaucho-Tradition).

Die Religionszugehörigkeit ist überwiegend protestantisch. In Port Stanley gibt es die anglikanische "Christchurch Cathedral" – der dortige Pfarrer ist direkt dem Erzbischof von Canterbury zugeordnet – und eine katholische Kirche und Gemeinde, die eine eigene Apostolische Präfektur bildet, die Apostolische Präfektur Falklandinseln oder Malwinen.

In Stanley gibt es in einem 1981 ursprünglich für die argentinische Fluglinie Líneas Aéreas del Estado (LADE) erbauten Haus ein Museum, das Gegenstände und Dokumente zur Geschichte der Inseln zeigt. Im Hafen von Stanley gibt es einen Lehrpfad entlang einer Reihe von Schiffswracks, die dort teilweise seit der ersten Hälfte des 19. Jahrhunderts liegen.

Nationalfeiertag ist der 14. Juni als Befreiungstag von der argentinischen Besetzung.

Seit 1985 hat Falkland eine eigene Verfassung, die 2008 durch eine neue, am 1. Januar 2009 in Kraft getretene Verfassung ersetzt wurde. Das Parlament "(Legislative Council)" besteht aus dem Gouverneur, dem Chief Executive sowie acht auf vier Jahre gewählten Mitgliedern. Da auf Falkland Parteien keine Bedeutung haben, handelt es sich um Unabhängige. Gouverneur ist seit April 2014 Colin Roberts. Südgeorgien und die Südlichen Sandwichinseln werden vom Gouverneur in Personalunion als Commissioner mitverwaltet. Die Regierung "(Executive Council)" setzt sich zusammen aus dem Gouverneur, dem Chief Executive, dem Financial Secretary und drei Mitgliedern des Parlaments. Letztgenannte werden jeweils für ein Jahr vom Parlament gewählt.

Infolge des Falklandkrieges, an dessen Anfang die wenigen bis dahin auf den Falklandinseln stationierten britischen Soldaten den argentinischen Truppen chancenlos unterlegen waren, wurde die Präsenz der britischen Streitkräfte deutlich verstärkt. Im Jahr 2012 waren noch etwa 1350 Soldaten aller drei Teilstreitkräfte auf den Inseln stationiert. Der zentrale Stützpunkt ist RAF Mount Pleasant. Die British Army hat dort Infanterie-, Pionier- und Kommandoeinheiten stationiert. Neben der Überwachung der Inseln sind sie vorrangig für das Räumen von Minen und Munition aus Zeiten des Falklandkrieges zuständig, die noch heute Teile der Inseln zu Sperrgebieten machen.

Die Royal Air Force hat in Mount Pleasant ein Vickers VC10-Tankflugzeug, vier Eurofighter "Typhoon" FGR4-Kampfflugzeuge, ein Hercules-Transportflugzeug sowie mehrere Transport- und SAR-Hubschrauber stationiert. Der Stützpunkt dient zudem der zivilen Versorgung der Inseln im Überseeverkehr.

Bei Port Pleasant hatte die Royal Navy eine Korvette der "Castle"-Klasse sowie einen Lenkwaffenzerstörer (seit 2014 die HMS Portland) oder eine Fregatte stationiert. Seit 2007 soll als Ersatz für die "Castle"-Klasse-Schiffe HMS Dumbarton Castle und HMS Leeds Castle mindestens bis 2018 das Patrouillenboot HMS Clyde der "River"-Klasse im Südatlantik bleiben. Die HMS Protector, ein weiteres Patrouillenboot, ist in den Antarktis-nahen Gewässern jeweils im Winterhalbjahr zur Überprüfung des Eisgangs unterwegs. Darüber hinaus kreuzen regelmäßig britische Atom-U-Boote im Südatlantik, deren Fahrten jedoch geheim gehalten werden. Im März 2010 soll nach Presseberichten ein Angriffs-U-Boot der "Swiftsure"-Klasse Richtung Falkland-Inseln in Marsch gesetzt worden sein, seit Februar 2012 wird über ein Boot der "Trafalgar"-Klasse spekuliert. In Notfällen konnte früher das Antarktispatrouillenschiff HMS Endurance hinzugezogen werden. In Mount Pleasant ist außerdem eine Abordnung der Royal Marines stationiert. Die britischen Streitkräfte können im Ernstfall von der "Falkland Islands Defence Force" unterstützt werden. Die setzt sich aus Bewohnern der Inseln zusammen und ist im Stil einer militärischen Reserveeinheit organisiert.

Falkland hat eine eigene Währung, das Falkland-Pfund. Dieses ist 1:1 an das britische Pfund gebunden. Das Außenhandelsdefizit macht etwa die Hälfte des Bruttoinlandsprodukts aus, die Inseln sind also völlig von Großbritannien abhängig. Das Bruttoinlandsprodukt pro Kopf liegt bei etwa 20.800 Euro (2003). Die Arbeitslosigkeit liegt mit 6 % unter dem Durchschnitt des Vereinigten Königreichs.

Produkte der verbreiteten Schafzucht sind neben Häuten und Talg das traditionelle Exportgut Wolle; Handelspartner ist hauptsächlich Großbritannien. Daneben erlangten seit Mitte der 1980er Jahre die Fischerei und die Fischverarbeitung wachsende Bedeutung. Bei der Zerlegung der Wale werden Fischbein und Walöl hergestellt. Die Fischindustrie trägt heute über 50 % zum Bruttoinlandsprodukt der Inseln bei. Über weitere Industrie bzw. industrielle Produktion verfügen die Inseln nicht.

Ein weiteres wirtschaftliches Standbein ist die Vergabe von Fischfanglizenzen an ausländische Unternehmen. Dies führt manchmal zu Konflikten mit dem Nachbarland Argentinien, das die Inseln beansprucht und in diesem Fall den Standpunkt vertritt, dass die exzessive Fischerei in dieser Region zu ökologischen Schäden, auch im argentinischen Teil des Südatlantiks, führe.

Jedes Jahr besuchen rund 60.000 Touristen die Insel. Der überwiegende Teil davon sind jedoch lediglich Tagesausflügler, die im Rahmen von Kreuzfahrten hier Station machen. Die Zahl der jährlich per Flugzeug anreisenden Touristen wird mit rund 1600 angegeben. Der Tourismus steuert rund 4 Mio. Pfund zum Bruttoinlandsprodukt bei und hat damit nach der Fischindustrie den zweitgrößten Anteil.

Die Entdeckung von großen Ölfeldern vor den Inseln führte in den späten 1990er Jahren zu erneuten politischen Spannungen zwischen Großbritannien und Argentinien. Seitdem werden diese Felder von verschiedenen Firmen, unter anderem "Falkland Oil & Gas", erkundet. Die britische Firma Desire Petroleum begann am 22. Februar 2010 mit Bohrungen nach Erdöl und Erdgas in den Gewässern der Falklandinseln. Das erste Öl wurde im Mai 2010 gefunden.

Die Falklandinseln können von Großbritannien aus mit der britischen Luftwaffe (RAF) erreicht werden. Die RAF fliegt bis zu drei Mal wöchentlich zwischen Brize Norton in Oxfordshire und Mount Pleasant (IATA-Code: MPN) auf den Falklandinseln. Von Mount Pleasant gibt es auch Flugverbindungen nach Chile.

Der Inlandsverkehr wird von der "Falkland Island Government Airlines System" (FIGAS) mit einer Flotte von sechs Britten-Norman BN-2 Islandern gewährleistet, die ihre Flugpläne täglich auf Vorbestellung nach Bedarf zusammenstellt. Die Flugpläne werden am Vorabend per Radio bekannt gegeben. Der Inlandsverkehr nutzt den Flughafen Port Stanley als Ausgangsbasis. Bei den über die Inseln verstreuten Siedlungen bestehen Landeplätze – oft nur Rasenstreifen oder ein geeigneter Strand.

Es gibt eine Fährverbindung zwischen der Ost- und Westinsel (New Haven – Port Howard). Schiffsverkehr zwischen den anderen Inseln besteht nur für den Warentransport.

Die einzige ausgebaute Straße außerhalb der Ortschaften besteht zwischen Port Stanley und dem Militärstützpunkt Mount Pleasant (rund 50 km).

Im Hafenbereich von Port Stanley gab es eine Eisenbahn zum Gütertransport, die aber schon seit Jahrzehnten stillgelegt ist.

Seit Dezember 2005 gibt es ein auf dem GSM-Standard basierendes Mobiltelefonnetz. Im Wesentlichen deckt es die Gebiete um Port Stanley und Mount Pleasant ab. Betrieben wird das Netz von Sure (ehemals Cable & Wireless) Falkland Island.

Die Postleitzahl "FIQQ 1ZZ" gilt für das gesamte Territorium der Falklandinseln. Aufgrund der geringen Bevölkerungsdichte ist eine weitergehende Differenzierung dieser Leitzahl nicht vonnöten.

Die Falklandinseln geben eigene Briefmarken heraus. Die Zuständigkeit dafür liegt beim staatlichen Falkland Islands Philatelic Bureau.





</doc>
<doc id="10357" url="https://de.wikipedia.org/wiki?curid=10357" title="Martinique">
Martinique

Martinique [] (Martinique-Kreolisch Matinik oder Matnik) ist eine Insel in der Karibik und gehört zu den kleinen Antillen – genauer gesagt zu den Inseln über dem Winde. Sie ist ein Überseedépartement und eine Region Frankreichs.

In der Sprache der Ureinwohner wurde die Insel Madinina (Blumeninsel) genannt, diese Bezeichnung wird auch heute noch oft von den Einheimischen verwendet.

Martinique ist ein vollintegrierter Teil des französischen Staates und damit auch Teil der Europäischen Union.

Martinique liegt zwischen dem karibischen Meer und dem Atlantischen Ozean 25 km südlich von Dominica und 37 km nördlich von St. Lucia. Sie liegt ungefähr 6.850 km von Paris und 3.150 km von New York entfernt sowie 440 km vor der Küste Venezuelas.

Die Insel hat eine Länge von 73 km und eine Breite von 39 km. Die Küstenlinie ist rund 350 km lang. Die Insel ist bergig. Im Norden der Insel liegt der Vulkan Montagne Pelée, der eine Höhe von 1.397 m hat.

9,4 % der Landfläche der Insel ist verstädtert. Landwirtschaft wird auf 11,3 % der Fläche betrieben.

Das Klima ist tropisch und die Regenzeit dauert von Juni bis Oktober. Der Norden ist feucht mit einer üppigen Vegetation. Im Süden ist das Klima trockener, dort befinden sich auch die meisten touristischen Ziele. Die mittleren Lufttemperaturen liegen im Januar und Februar zwischen min. 21 °C und max. 27 °C, im August und September zwischen min. 24 °C und max. 30 °C. Die Monate Juni bis November zeichnen sich durch hohe Luftfeuchtigkeit aus. Der Februar hat im Mittel 12 Regentage, der Juli 22.

Die Wassertemperatur kann im Juli bis Oktober 28 °C überschreiten und liegt auch im Februar nicht unter 26 °C.

Zwischen Juni und November können Wirbelstürme auftreten.

Die Bevölkerung ist zu ca. 80 % afrikanischer Herkunft. 15 % der Bewohner sind indischer oder afro-indischer Herkunft (in Martinique „coolies“ genannt), überwiegend im Osten der Insel. Etwa 5 % der Einwohner Martiniques sind europäischer Abstammung. Zu dieser Gruppe gehören die auf Martinique geborenen Weißen, die von der kolonialen Oberschicht abstammen und Béké genannt werden. Sie lassen sich auf etwa 30 Familien zurückführen. Alle auf Martinique geborenen Menschen, sowohl Weiße als auch Schwarze, werden Kreolen genannt. Daneben leben europäische Zuwanderer aus der Metropole (Frankreich) und nach Martinique entsandte französische Staatsbeamte auf der Insel. Aufgrund des im regionalen Vergleich sehr hohen Lebensstandards zieht Martinique – wie die anderen französischen Départements Guadeloupe und Französisch-Guayana – auch Zuwanderer aus der Region an, vor allem aus Haiti.

85 % der Bevölkerung sind römisch-katholisch, 10,5 % protestantisch (hauptsächlich Adventisten). Je 0,5 % bekennen sich zum Islam und zum Hinduismus.

Die offizielle Sprache ist Französisch. Die Muttersprache der Mehrheit der Bevölkerung ist allerdings Martinique-Kreolisch, eine französische Kreolsprache.

Quelle: UN

Erste Besiedlungen können bis 4000 v. Chr. nachgewiesen werden. Etwa um 100 v. Chr. besiedelten die Arawak vom Orinokogebiet in Venezuela ausgehend die Insel. Im 10. Jahrhundert folgten die Kariben. Als erster Europäer entdeckte Christoph Kolumbus Martinique am 15. Juni 1502 auf seiner vierten Reise für Europa. Er ging bei der heutigen Gemeinde Carbet an Land. Die Insel wurde 1635 von Frankreich durch Pierre Belain d’Esnambuc im Namen der von Richelieu gegründeten "Compagnie des îles d'Amérique" kolonialisiert und blieb seitdem bis auf drei kurze Perioden fremder Besatzung in französischem Besitz. Im Jahre 1648 ging die "Compagnie des îles d'Amérique" in Konkurs, daraufhin wurde die Insel an Jaques Dyel du Parquet, Neffe von Pierre Belain d’Esnambuc verkauft. Er gründete Fort-de-France und ließ zum ersten Mal Zuckerrohr anpflanzen, was zu einem ersten wirtschaftlichen Aufschwung führte. Um 1660 war fast die gesamte einheimische Bevölkerung ausgerottet.

Durch die Gründung der Französischen Ostindienkompanie durch Jean-Baptiste Colbert im Jahr 1664 wurde Martinique Besitz der französischen Krone. Während des Zweiten Englisch-Niederländischen Krieges war Frankreich mit den Niederlanden verbündet – eine englische Flotte griff wiederholt französische Siedlungen auf Martinique an und besiegte am 6. Juli bei Saint-Pierre ein französisches Geschwader. Im Dritten Englisch-Niederländischen Krieg, in dem Frankreich nun mit England gegen die Niederlande kämpfte, wurde Martinique am 16. Juli 1674 durch die Flotte des holländischen Admirals Michiel de Ruyter angegriffen.

1685 wurde der sogenannte Code Noir verabschiedet, der die Sklaverei in den französischen Kolonien bestätigte.
Im Jahr 1694 traf der Dominikaner Père Labat ein. Er war Missionar, Ethnologe und Schriftsteller; er führte die Windmühlen ein und verbesserte die Rumdestillation.

Dank der Patronage von Madame de Pompadour wurde der Ökonom und Physiokrat Pierre-Paul Le Mercier de La Rivière zum Intendanten oder Gouverneur von Martinique bestimmt, während der Amtszeit von 1759 bis 1764 hatte er dort große wirtschaftliche Erfolge. Während der kriegerischen Auseinandersetzungen mit den Briten wurde er verwundet und gelangte in Gefangenschaft.
Von 1762 bis 1763 war Martinique durch die Briten besetzt. Am 23. Juni 1763 wurde Joséphine, geb. de Tascher de la Pagerie, die spätere Gattin Napoleons, in Trois-Îlets bei Fort-de-France auf Martinique geboren. Ihre Eltern betrieben dort eine Zuckerrohrplantage, die noch heute als Museum zu besichtigen ist. Auf dem Zentralplatz von Fort-de-France steht eine kleine Statue von Joséphine, allerdings seit 1991 ohne Kopf, da sie bei der Bevölkerung wegen der erneuten Einführung der Sklaverei auf Martinique unbeliebt ist.

Im Jahr 1783 gab es ca. 60.000 Sklaven. Von 1787 bis 1802 entflammte ein Bürgerkrieg wegen Konflikten zwischen Plantagenbesitzern und Händlern, es gab einen Sklavenaufstand. 1794 stimmte die französische Konvention im Geiste der französischen Revolution für die Abschaffung der Sklaverei. Dieser Beschluss hielt aber nicht lange, denn Napoleon führte 1802 die Sklaverei wieder ein. Am 22. Mai 1848 wurde die Sklaverei endgültig aufgehoben. Victor Schoelcher spielte hierbei eine wichtige Rolle. Wegen Knappheit an Arbeitskräften auf den Plantagen wurden ab dieser Zeit Inder und Chinesen dort beschäftigt.

Der Martinique-Hurrikan von 1891 verwüstete im August jenes Jahres die Insel, und rund 700 Personen verloren ihr Leben, doch ein Jahrzehnt später traf die Insel eine noch schwerere Naturkatastrophe: Am 8. Mai 1902 brach der Vulkan Mt. Pelée aus. Ein pyroklastischer Strom hatte mehr als 30.000 Tote zur Folge. In Saint-Pierre überlebten lediglich ein Schuhmacher und ein Gefängnisinsasse. Die Stadt war damals wegen der guten Reede die wirtschaftlich bedeutendste von Martinique. Im Jahr 1946 wurde Martinique zu einem der französischen Überseedépartements ("Départements d’Outre-Mer"/"DOM"), die politisch als Teil des Mutterlandes gelten. Martinique erhielt vier Abgeordnete und zwei Senatoren. 1972 wurde Martinique eine Région, ein Parallelstatus zum DOM. 1983 wurde durch die Dezentralisation der Regionalrat eingeführt. 1958 gab es Autonomiebewegungen. Im Jahr 1999 wurde die Banane aus Martinique Anlass eines „Handelskriegs“ zwischen den USA und Europa. 2003 wurde der Doppelstatus als Region und Department (DOM) bestätigt.

Wie auf Guadeloupe kam es 2009 auch auf Martinique zu einem Generalstreik. Er begann am 5. Februar und ging im März zu Ende. Auslöser waren die hohen Lebenshaltungskosten. Gegner der Streikenden waren die „békés“, die Nachfahren der früheren weißen Sklavenhalter, die die Inseln ökonomisch noch immer weitgehend dominieren. Die Streikenden konnten höhere Löhne durchsetzen. Die Zusagen wurden allerdings zum Teil nicht eingehalten.

Bei einer vom französischen Staat initiierten Volksabstimmung über mehr Autonomie des Départements vom 10. Januar 2010 stimmten 79 % der Abstimmenden dagegen.

Auf der Insel herrscht eine starke Tanz- und Musiktradition. Getanzt werden die Tänze Biguine, Zouk, Quadrille und Gwo Ka, die typische kreolisch sind. Besonders zur Zeit des Karnevals der Insel wird viel bei geschmückten Umzügen über die Insel getanzt.

Ein weiterer kultureller Höhepunkt Martiniques ist die Regatta Tour des Yoles, bei dem vermehrt mit kleinen Bootstypen gefahren wird.

Martinique ist eine französische Überseeregion und ein französisches Überseedépartement mit der Départementnummer 972.

Region und Département sind als Gebietskörperschaften für dasselbe Territorium zuständig, haben jedoch getrennte Institutionen – den Regionalrat ("conseil régional") bzw. den Generalrat ("conseil général") des Départements mit 45 Abgeordneten –, die ihre jeweiligen Kompetenzen unabhängig voneinander wahrnehmen.

Als Vertreter der Zentralregierung fungiert der Präfekt.
Martinique entsendet vier Vertreter in die französische Nationalversammlung und zwei in den Senat.

Als vollintegrierter Teil des französischen Staates ist Martinique auch Teil der Europäischen Union. Der Euro ist wie im französischen Kernland das gesetzliche Zahlungsmittel.

"Siehe auch: Liste der Präsidenten des Regionalrates von Martinique seit 1983"

Martinique gliedert sich in vier Arrondissements und 34 Gemeinden. Bis 2015 untergliederte sich Martinique zudem in 45 Kantone, diese Gliederungsebene wurde 2015 abgeschafft.


Die Insel verfügt über einen Flughafen, den Aéroport International Martinique Aimé Césaire in Lamentin (IATA-Flughafencode: FDF). Die Flugdauer von Paris-Orly nach Martinique beträgt hin ca. 8 Stunden 30 Minuten und zurück ca. 8 Stunden. Weitere Direktflugverbindungen gibt es von bzw. nach San Juan (Puerto Rico, American Eagle), Santo Domingo (Dominikanische Republik), St. Lucia, Guadeloupe, Cayenne (Franz. Guyana) und saisonal nach Montreal (Kanada), Isla Magarita (Venezuela), Panama, Havanna (Kuba) und Marseille sowie New York, Boston und Baltimore (USA).

Das Straßennetz ist hervorragend und zum Teil vierspurig ausgebaut. Einige Nebenstraßen sind sehr kurvig mit teilweise starken Steigungen, so dass die erreichbaren Durchschnittsgeschwindigkeiten relativ niedrig sind, zumal regelmäßig auch Verkehrsstaus auftreten.

Auf Martinique gibt es keine Eisenbahn.

Regelmäßige Fähren verbinden Martinique mit St. Lucia, Dominica und Guadeloupe.

Für das Jahr 2009 weist INSEE 402.499 Einwohner und Eurostat ein Bruttoinlandsprodukt von 7,753 Mrd. € für Martinique aus. Dies entspricht 16.900
 € (Kaufkraftstandard) pro Einwohner.

Das Bruttoinlandsprodukt (BIP) von Martinique betrug 1995 4,48 Mrd. € und damit 11.990 € pro Einwohner (Frankreich 19.360 €). Damit hat Martinique das höchste BIP aller fünf französischen Überseedepartements und aller karibischen Staaten. Im Vergleich mit dem BIP der EU ausgedrückt in Kaufkraftstandards erreicht Martinique einen Index von 73,4 (EU-25:100) (2003).

7,6 % der Beschäftigten sind im primären Bereich, 17,5 % im sekundären und 74,9 % im tertiären Bereich beschäftigt.

Bananen tragen zu 40 % der Exporterlöse bei und sind damit das wichtigste Exportgut. 80 % der in der Landwirtschaft Beschäftigten sind im Anbau von Bananen tätig. Rohrzucker, Rum und Ananas sind weitere wichtige landwirtschaftliche Produkte.

Der sekundäre Bereich wird hauptsächlich durch zwei Unternehmen abgedeckt, den französischen Stromkonzern Electricité de France und die Société Anonyme de la Raffinerie des Antilles.

Der tertiäre Bereich besteht hauptsächlich aus Handel und Tourismusindustrie. Der Tourismus trägt zu 7 % des BIP bei. Circa 80,1 % der Touristen kommen aus Frankreich, 5,0 % aus Europa (ohne Frankreich), 10,4 % aus der Karibik, 3,1 % aus den USA und 1,4 % aus dem Rest der Welt.




</doc>
<doc id="10358" url="https://de.wikipedia.org/wiki?curid=10358" title="Überwachungskamera">
Überwachungskamera

Eine Überwachungskamera ist eine fest montierte, oft durch einen Antrieb schwenkbare Videokamera, die dazu dient, ein Objekt oder einen Bereich dauerhaft zu überwachen. Das Bild der Überwachungskamera wird meist live auf einem Monitor angezeigt sowie zur späteren Auswertung aufgezeichnet. Zudem existieren Überwachungskameras, die Standbilder erzeugen, wenn ein Grenzwert überschritten wird. Ein sehr bekannter Einsatz dieser Kameras erfolgt zur Ermittlung von Verstößen im Straßenverkehr, wie dem Fahren mit überhöhter Geschwindigkeit.

Die Überwachungskamera im Gehäuse für den Außeneinsatz und Wandhalterung ist zudem Symbol für Überwachungsmaßnahmen aller Art geworden.

Überwachungskameras sollen beispielsweise in Banken oder Supermärkten zur Prävention von Ladendiebstählen dienen und werden an wichtigen Gebäuden wie Botschaften zur Überwachung eingesetzt. Andere typische Anwendungsgebiete sind Bahnhöfe (v. a. der U-Bahn) und Flughäfen oder die Verkehrsüberwachung, z. B. an stark frequentierten Kreuzungen. In der Regel werden im öffentlichen Nahverkehr Dome-Kameras eingesetzt.

Neben der Abschreckung, Aufklärung von Straftaten und Stellung der Täter findet Videoüberwachung auch in anderen Gebieten Anwendung. Eine weitere Anwendung ist die Früherkennung von Waldbränden, wofür in brandgefährdeten Gebieten Kameras auf Türmen, welche auch als Aussichts- oder Funkturm genutzt werden können, installiert werden. Hierbei werden auch Wärmebildkameras eingesetzt, da diese einen eventuellen Brand schneller detektieren können.

Babyphones werden zusehends mit einer Videomöglichkeit ausgestattet oder durch Videokameras ersetzt. Diese Art von Innenraumüberwachung wird zudem bei der Haustierbeobachtung oder bei der Versorgung von pflegebedürftigen Personen angewendet. Die zu betreuenden Personen oder Haustiere können beobachtet werden, ohne dass Eltern, Haustierbesitzer oder Pflegepersonal im selben Raum anwesend sein müssen. Auf demselben Prinzip basiert die Wildtierbeobachtung, bei der Tiere in ihrer natürlichen Umgebung beobachtet werden können, ohne sichtbar in ihr Leben einzudringen. Zur Tierbeobachtung werden auch Wärmebildkameras verwendet.

Innerhalb der Forschung wird Videoüberwachung ebenfalls genutzt. Durch Funktionen wie Bewegungserkennung oder durch die Nutzung von Langzeitrekordern sind Videoüberwachungen über einen langen Zeitraum möglich. Bei der Bewegungserkennung wird nur dann aufgezeichnet, wenn ein Ereignis eintritt. Diese Funktion spart während der Bildauswertung viel Zeit beim Finden von relevantem Geschehen und reduziert den zur Speicherung der Aufnahmen benötigten Speicherplatz.

Neben der typischen Überwachung von Menschen und Tieren werden Überwachungskameras zur Kontrolle und Beobachtung von industriellen Abläufen und Experimenten eingesetzt, um schwer zugängliche Bereiche sichtbar zu machen (z. B. innerhalb einer Maschine) oder Vorgänge unter für Menschen schädlichen Bedingungen zu kontrollieren.

Bei automatisierten Prozessen in Betrieben werden zur Überprüfung des Geschehens Videokameras eingesetzt. Sie zeichnen je nach Bedarf bis zu 24 Stunden am Tag auf. Bei Prozesstopp oder aufgetretenen Fehlern kann so schnell der Prozesshergang zurückverfolgt und die Ursachen gefunden werden. In Fabriken werden Überwachungskameras für den Außenbereich eingesetzt, sodass sie vor Nässe und mechanischer Beanspruchung optimal geschützt sind.

Die meisten Überwachungskameras weltweit sind in Großbritannien installiert. Insbesondere aufgrund des Falles James Bulger ist das Land gegenüber der Videoüberwachung teilweise positiv eingestellt. In den britischen Medien wurde fälschlicherweise behauptet, dass Videoaufnahmen zur Aufklärung der Tat geführt haben.

In Österreich ist die Zahl der Überwachungskameras seit 2006, wo laut ORF über 160.000 Überwachungskameras auf öffentlichen Plätzen und in Einkaufszentren gemeldet waren, bis 2013 auf eine Million gestiegen.

In Deutschland wurde 2014 eine Statistik vom EHI Retail Institute durchgeführt, wo nach der Verwendung von CCTV im Einzelhandel gefragt wurde. Nur 9,4 % der befragten Händler gaben an keine Videoüberwachung zu nutzen oder zu planen.

Zu den Kontroversen rund um den Einsatz von Überwachungskameras im öffentlichen Raum siehe auch:
Die Diskussion um Videoüberwachung hat auch zur Aufnahme von Überwachungskameras in Kunstobjekte, die sich mit dem Thema auseinandersetzen, geführt.

Überwachungskameras bestehen in der Regel aus den folgenden (Bau-)Teilen:

Monitore und Rekorder dienen der Signalverarbeitung. Überwachungskameras sind nur selten mit Bewegungssensoren gekoppelt; häufiger nutzen entsprechende Rekorder (bzw. Software) die Signale der Kameras selbst als Bewegungssensor.

Die Qualität des erzeugten Bildes wird von dem verwendeten CCD- oder CMOS-Chip und dem Objektiv bestimmt, wobei je nach Einsatzgebiet unterschiedliche Objektive an eine Kamera montiert werden können. Neue Modelle von Überwachungskameras nutzen HD-SDI und stellen Bilder in 720p oder 1080p da. Sie werden auf einen HD-SDI-Rekorder geleitet. Videokabel können bis zu 150 Meter lang sein.

Schwarzweiß- und Farbkameras werden je nach Bedarf eingesetzt: Schwarzweiß-Kameras sind lichtempfindlicher und besser für den Nachteinsatz geeignet, Farbkameras dagegen bieten dem menschlichen Betrachter ein erheblich schneller erfassbares Bild. Manche Farbkameras sind in der Lage, bei Dunkelheit auf Schwarzweiß-Betrieb umzuschalten. Der Endverbraucher kann über den Großhandel bereits Kameras mit einer Empfindlichkeit von 0,01 Lux erwerben.

Die Gehäuse von Kameras, die im Innenbereich eingesetzt werden, sind oft bewusst auffällig gestaltet, da Videoüberwachung meist der Verhinderung von vorsätzlichen Straftaten dienen soll. Oft verbergen undurchsichtige Kuppeln (sogenannte „Domes“) dem menschlichen Betrachter die Ausrichtung der Kamera. Dies entspricht dem Einsatzprinzip von Einwegspiegeln in Supermärkten. Der Dome dient dabei ebenfalls dem physikalischen Schutz der Kamera. 

Vorsicht ist hingegen bei einer heimlichen Videoüberwachung geboten. Gerade an öffentlich zugänglichen Orten und Plätzen, aber auch im privaten Rahmen ist dies nicht oder nur unter bestimmten Voraussetzungen mit dem Datenschutz vereinbar. Sobald nämlich eine Überwachungsanlage Bildmaterial aufzeichnet und somit Daten identifizierbarer Personen verarbeitet, liegt eine meldepflichtige Datenanwendung vor.

Einsatzgebiete und Aufgaben entscheiden über die Bauform der Überwachungskamera. Sollen öffentliche Plätze oder ein offenes Firmengelände beobachtet werden, bieten sich sogenannte offensichtliche, also sichtbare Kameras an. Zwei Bauformarten sind in der Öffentlichkeit vorherrschend: zum einen die Kamera mit Wandarm, zum anderen die Dome-Kamera. Diese können entweder fest oder mechanisch beweglich (PTZ) sein. Für detektivische Maßnahmen eignen sich dagegen getarnte (Mini-)Kameras.

Diese Kameras finden sich zumeist an öffentlichen Plätzen, in Parkanlagen und an Gebäuden von beispielsweise Kaufhausketten. Sie gehören zu den offensichtlichen Kameras und dienen neben der zeitnahen Entdeckung von Straftaten ebenso als Abschreckung für Gelegenheitstäter. Aufgrund ihrer zumeist kubischen Form ist leicht zu erkennen, wohin die fest montierte Kamera zeigt bzw. welcher Bereich von ihr überwacht wird. Der Bereich, den sie gerade nicht scannt, ist ungeschützt bzw. benötigt eine weitere Kamera.

Dome-Kameras lassen sich am halbrunden Gehäuse erkennen. Zu finden sind sie an Eingängen von Parkhäusern, im Supermarkt oder im öffentlichen Personennahverkehr. Sie sind meistens an der Decke befestigt und mit getöntem Glas versehen. Aufgrund ihrer kreisförmigen Bauform und den dunkel getönten Scheiben ist nicht auf Anhieb zu erkennen, welcher Bereich von der Kamera überwacht wird. Damit bietet sie einen höheren Abschreckungsfaktor als die Kamera mit Wandhalterung. Daher sind Domekameras auch an sozialen Brennpunkten im Außenbereich im Einsatz. Für diese Aufgabe erhalten sie ein wetterfestes Außengehäuse, das in der Regel aus Aluminium besteht. Neben den festinstallierten Domekameras gibt es auch sogenannte Speed-Dome-Kameras. Bei diesen kann die eigentliche Kamera im Inneren aus der Ferne geschwenkt und geneigt werden und somit einen weitaus größeren Bereich überwachen.

Steuerbare Kameras können sich nach oben und unten sowie seitlich bewegen. Diese Funktion nennt man PTZ, wobei das „P“ für engl. "pan" ‚schwenken‘ und das „T“ für "tilt" ‚neigen‘ steht. Das „Z“ zeigt an, dass diese Kameras ebenso eine Zoomfunktion haben. Sie können stehende oder sich bewegende Objekte erfassen und zur besseren Identifizierung Bildausschnitte vergrößern. Kameras dieser Bauform, die in der höheren Preisklasse angesiedelt sind, verfügen über die Funktion Autotracking. Damit wird eine Person erfasst und, solange wie eben möglich, verfolgt. 
PTZ-Kameras werden bei Live-Überwachung eingesetzt. An Flughäfen oder in Stadien können Straftaten schnell erkannt werden, so dass das Wachpersonal zeitnah einschreiten kann.
Aus der PTZ-Funktion ergeben sich Vor- und Nachteile: Durch ihre Schwenk- und Neigetechnik können sie einen großen Bereich abtasten. Andererseits ist der Bereich, den sie gerade nicht prüfen, ungeschützt.

Minikameras sind sehr kleine Kameras, die mit dem bloßen Auge nicht leicht zu erkennen sind. Sie gehören zu den nicht offensichtlichen Typen und dienen in erster Linie der verdeckten Videoüberwachung. Sie können freistehend eingesetzt oder in anderen Gegenständen platziert werden wie zum Beispiel in Rauchmeldern, Kugelschreibern oder Weckern.

Bei der getarnten Kamera ist die Kamera fest mit ihrem Gegenstand verbaut. Das Gehäuse, wie zum Beispiel eine Wanduhr, kann dennoch über ihre eigentliche Funktion (hier: die Zeitanzeige) verfügen. Getarnte Überwachungskameras werden meist mit Bewegungsmeldern ausgestattet, sodass sie erst aktiviert werden, wenn ein Gegenstand in ihren Erfassungsbereich eindringt.

IP-Kameras gibt es in LAN- und WLAN-Varianten. Das bedeutet, dass sie die Kamerasignale entweder über ein Netzwerkkabel oder drahtlos über das WLAN in das Netzwerk senden können. IP-Kameras haben den Vorteil, dass sie nicht extra an einen Computer angeschlossen werden müssen. Das Bildmaterial kann stattdessen von den entsprechend eingerichteten Endgeräten, von beliebig vielen Nutzern, abgerufen werden. Einige Modelle verfügen außerdem über eine Bewegungserkennung und einer somit zusätzlichen Alarmfunktion, durch die der Nutzer bei Veränderungen im Kamerabild z. B. über eine E-Mail benachrichtigt wird. Weiters wird noch zwischen Outdoor- und Indoor-IP-Kameras unterschieden, wobei erstere wetterfest sind.

Nachtsichtkameras leuchten den zu überwachenden Bereich mit Restlichtverstärker aus oder zeichnen das Geschehen in Wärmebildern auf. 

Die meisten Nachtsicht- oder Infrarot-Kameras verwenden sogenanntes aktives Infrarot, um Nachtsicht zu erzeugen. Die Kamera ist dabei für Nah-IR, welches von Menschen nicht wahrgenommen wird, empfindlich. Ein IR-Scheinwerfer oder an der Kamera selbst angebrachte LEDs dienen als Beleuchtung. Das Bild der Kamera ist am Monitor auf den ersten Blick nicht von dem einer Schwarzweiß-Kamera und einem Scheinwerfer zu unterscheiden.

Bei völliger Dunkelheit können IR-Nachtsichtkameras noch einen Bereich von 4 bis 100 Metern erfassen, sofern die entsprechende Ausleuchtung gewährleistet wird.

Die Qualität einer solchen Kamera ist von mehreren Faktoren abhängig. Einige verfügen über eine geringe Restlichtstärke und eignen sich nur für den Nahbereich von bis zu 3 Metern. Zudem kann es beim Übergang von Tag- und Nachtbeleuchtung zu Farbrauschen und Farbverfälschungen kommen. Schwarze Kleidung kann am Tag zum Beispiel hell erscheinen, wenn der Stoff Nah-IR reflektiert. Andere Modelle weisen eine separate Nachtsichttechnik auf. Sie wechselt automatisch vom Tag- in den Nachtbetrieb. Ein Farbrauschen kann nicht entstehen, da der Nachtbetrieb auf den Farbmodus verzichtet. Durch IR-korrigierte Objektive wird zudem zwischen Tag- und Nachtfunktion die abweichende Wellenlänge ausgeglichen, sodass das Entstehen unscharfer Bilder kaum vorkommt.

Während eine IR-Kamera im Nachtbetrieb Schwarzweiß-Bilder produziert, nutzt die Wärmebildkamera die Strahlung der Körperwärme, die jedes Objekt auf der Welt besitzt, um das Überwachungsbild (Thermobild) zu erzeugen. Ein Wärmebild besteht aus vielen Graustufen, die für das menschliche Auge kaum unterscheidbar sind. Aus diesem Grunde wird zur Erstellung der Thermobilder die sogenannte Falschfarben-Methode angewendet. Aus den unterschiedlichen Graustufen werden von der bildverarbeitenden Software gelbe, rote, blaue und grüne Flächen errechnet. Dabei steht Rot für hohe Körperwärme und Gelb für geringere; Blau und Grün geben die geringste Körperwärme an. Schwarze Bereiche strahlen keine zu erfassende Körperwärme aus.

Wärmebildkameras sind exzellent dazu geeignet, um das Entstehen möglicher Brandherde ausfindig zu machen, weshalb sie sehr gut zur Früherkennung von Waldbränden geeignet sind.

Wärmebildkameras kommen an Plätzen zum Einsatz, in denen völlige Dunkelheit oder sehr schwierige Lichtverhältnisse vorherrschen. Da sie nur Wärmebilder erzeugen, können sie zur Identifizierung von Personen nicht verwendet werden. Jedoch wird ein Geschehen als solches bei einer bemannten Videoüberwachung mit Wärmebildkameras erkannt. Täter können durch die Ausstrahlung ihrer eigenen Körperwärme zügig gefunden und vom Wachpersonal zeitnah gefasst werden.

Aus verschiedenen Gründen werden für Überwachungszwecke in der Regel keine Wärmebildkameras oder Restlichtverstärker eingesetzt.

Wärmebildkameras dürfen hierbei nicht mit herkömmlichen Schwarzweiß-Kameras verwechselt werden, deren CCD-Chips generell für nahes Infrarot empfindlich sind (Farbkameras bzw. deren Objektive müssen diesen Bereich filtern, um Verfälschungen zu vermeiden). Infrarot-LEDs und Scheinwerfer mit entsprechenden Filtern können für jede CCD-Schwarzweiß-Kamera als Lichtquelle dienen und ermöglichen so Nachtsicht. Um eine Blendung der Kamera zu vermeiden, werden IR-Scheinwerfer meist getrennt von der Kamera montiert. 

Ähnlich wie im militärischen Bereich haben Überwachungsinstallationen mit IR-Scheinwerfern den Nachteil, dass sie von Dritten mit einem beliebigen (Nah-)Infrarot-Sichtgerät ebenfalls gesehen werden können. Spezielle Sichtgeräte sind hier in der Regel nicht nötig – auch viele günstige Digitalkameras (wie die in Handys) verfügen über keinen Infrarotfilter.

Einen echten Nutzen hat IR-Beleuchtung nur in Fällen, in denen der Betreiber der Videoüberwachung mit einem Ausfall der herkömmlichen Beleuchtung rechnen muss, oder gezwungen ist, auf die Beleuchtung eines Areals zu verzichten. Außerhalb der klassischen Überwachung wird diese Technik vor allem zur Beobachtung nachtaktiver Tiere eingesetzt.

Für Überwachungskameras (und deren Gehäuse) gültige Normen bzw. Vorschriften sind innerhalb Deutschlands die Schutzart und die Unfallverhütungsvorschriften für Kassen, die definieren, ob eine Kamera für den Innen- oder Außeneinsatz oder den Einsatz in Banken vorgesehen werden kann.

Bei der Installation einer Überwachungskamera oder Webcam, welche auf einen öffentlich zugänglichen Ort gerichtet ist, ist in Deutschland Bundesdatenschutzgesetz (BDSG) zu beachten. Dieser regelt im Wesentlichen, dass keine Bild- und Tonaufnahmen gemacht werden dürfen, auf denen Personen identifiziert werden können. Dies gilt auch für Merkmale wie Kfz-Kennzeichen, welche eine Identifizierung ermöglichen. Verstöße gegen das BDSG können je nach Schwere auch mit Freiheitsstrafe geahndet werden.

Im privaten Bereich ist eine Videoüberwachung und -speicherung (z. B. durch Überwachungskameras an und in Wohnhäusern) nur dann zulässig, wenn der davon unmittelbar betroffene Personenkreis (z. B. "alle" Mieter) dieser Maßnahme zugestimmt haben. Andernfalls stellt dies eine Verletzung des allgemeinen Persönlichkeitsrechts des Betroffenen dar, was stets einen zivilrechtlichen Unterlassungsanspruch und in Einzelfällen sogar Schmerzensgeld- und Schadenersatzansprüche begründen kann (, BGB).




</doc>
<doc id="10359" url="https://de.wikipedia.org/wiki?curid=10359" title="Mosambik">
Mosambik

Mosambik [] ( []) ist ein Staat in Südostafrika. Die Hauptstadt ist Maputo, weitere bedeutende Städte sind Matola, Beira und Nampula. Mosambik ist seit dem 12. November 1995 Mitglied des Commonwealth of Nations. Nationalfeiertag ist der 25. Juni, Tag der Unabhängigkeit (1975).

Mosambik liegt am Indischen Ozean zwischen dem 10. und dem 27. südlichen Breitengrad. Der Staat grenzt an Tansania, Malawi, Sambia, Simbabwe, Südafrika und Swasiland. Die Straße von Mosambik trennt den Inselstaat Madagaskar vom afrikanischen Festland.

Nach einem jahrelangen Bürgerkrieg ist es eines der ärmsten Länder der Welt. 2016 belegte es Platz 181 von 188 Ländern im Index der menschlichen Entwicklung. In den letzten Jahren erlebte das Land einen Aufschwung.

Entlang der 2800 km langen Küste befindet sich ein breites Küstentiefland. Es bedeckt den größten Teil des Südens, doch wird es von der Sambesimündung nach Norden hin schmaler. Hinter der Küste steigt das Land stufenförmig bis zum zirka 1000 m hohen Tafelland des Hochfelds an. Der höchste Berg ist der Monte Binga in der Provinz Manica (an der Grenze zu Simbabwe) mit 2436 m.

Die zahlreichen Flüsse des Landes fließen aus den Hochländern nach Osten in die Straße von Mosambik. Der größte Fluss ist der Sambesi (2.574 km), der im Westen Mosambiks durch den Cahora Bassa-Damm aufgestaut wird. Weitere große Flüsse sind der Rovuma, der Grenzfluss zu Tansania, sowie Save und der Limpopo. Der Malawisee bildet einen Teil der Grenze mit Malawi; sein Abfluss ist der Shire, der in den Sambesi mündet.

Mit einer Landesfläche von 801.590 km² nimmt Mosambik den Weltrang 34 ein. 18 % der Landesfläche sind Wald- und Buschland, 4 % Ackerland, 55 % Wiesen und Weiden.

Die Ausdehnung des Landes beträgt in Nord-Süd-Richtung 2000 km, in der West-Ost-Richtung 50 bis 600 km. Die Küste am Indischen Ozean ist 2.470 km lang.

Mosambik hat 4.571 km Landesgrenzen, davon zu Malawi 1.569 km, zu Südafrika 491 km, zu Swasiland 105 km, zu Tansania 756 km, zu Sambia 419 km und zu Simbabwe 1.231 km.

Die vorherrschende Vegetation ist die Trockensavanne mit trockenem Grasland und einigen Trockenwäldern. Die Bäume in der Savanne werfen teilweise ihr Laub in der Trockenzeit ab und ergrünen im Laufe der Regenzeit. Typische Bäume der Trockensavanne sind Schirmakazien und Affenbrotbäume. Das Gras ist in der Trockenzeit braun und verdorrt, wird aber während der Regenzeit bis zu 2 Meter hoch.

Savannenklima mit einer feuchten und einer trockenen Jahreszeit herrscht vor. In der Regenzeit, die von November bis April geht, fallen rund 80 % der Jahresniederschläge. Diese schwanken je nach Region zwischen 700 und 1500 mm pro Jahr. Während die Temperaturen während der Regenzeit schwül-heiß (tropisch) sind, ist die Trockenzeit vor allem durch deutlich kühlere Nächte gekennzeichnet. Das ganze Jahr liegen die Tagestemperaturen zwischen 25 und 30 °C, im Inland auch bis 35 °C. Die Nächte sind mit rund 15 bis 25 °C besonders an der Küste teilweise sehr schwül.

In einigen Jahren, etwa 2007/2008 kam es zu ungewöhnlich hohen Niederschlägen, die Todesopfer forderten und Ernten bedrohten. Insgesamt erfährt das Land eine hohe Klimavariabilität und häufige extreme Wetterereignisse (insbesondere Dürren, Überschwemmungen, tropische Zyklone). Dürren sind die häufigsten Katastrophen, treten etwa alle drei bis vier Jahre auf und erschweren massiv die Entwicklung des Landes. In Bezug auf die Folgen der Globalen Erwärmung wird davon ausgegangen, dass Zyklone zwar weniger häufig auftreten könnten, aber sich ihre Intensität und damit die Niederschläge wahrscheinlich vergrößern. Diese können auch zu einer erhöhten Erosion im Küstenbereich führen. Da ein Großteil der Bevölkerung und insbesondere viele arme Menschen im ländlichen Raum vom Regenfeldbau leben, sind sie gegenüber Veränderungen der Niederschlagsmuster besonders anfällig.

Die durchschnittliche Lebenserwartung bei der Geburt wird im Zeitraum von 2010 bis 2015 mit 56,1 Jahren angegeben. 43 % der Bevölkerung sind unter 15 Jahre alt und nur 3 % über 65. Die zusammengefasste Fruchtbarkeitsziffer liegt bei 5,4 Kindern pro Frau. Dies liegt unter anderem auch daran, dass nur 12 % der verheirateten Frauen moderne Verhütungsmethoden zur Verfügung stehen (Stand 2008). Das Land hat eine der höchsten HIV-Prävalenzen der Welt (12,3 %), was das Bevölkerungswachstum bremst.

Bevölkerungsentwicklung
Quelle: UN

Der Großteil der Gesamtbevölkerung gehört Bantuvölkern an. Das größte Volk bilden mit etwa 40 % Bevölkerungsanteil die Makua, daneben sind mit 21 % auch die Tsonga eine einflussreiche Gruppe. Die Yao, welche auch in Malawi leben, bilden 12 % der Bevölkerung, daneben sind mit 11 % auch die Makonde im Nordosten eine starke Minderheit. Die Volksgruppe der ostafrikanischen Swahili lebt im Küstengebiet und macht 7 % der Bevölkerung aus. Zudem leben noch mit einem Anteil von 4 % an der Bevölkerung die Chewa im Land – ihr Hauptsiedlungsgebiet ist Malawi. Die kleinere Minderheit der 3 % Shona im Westen bildet ihrerseits wiederum die Bevölkerungsmehrheit in Simbabwe.

Ferner leben in Mosambik viele Personen mit Migrationshintergrund (Inder, Pakistani, Chinesen), Europäer (vor allem Portugiesen) und Südafrikaner. Die Rückwanderung von fast fünf Millionen Binnenflüchtlingen in ihre Heimatorte und die Rückkehr von 1,7 Millionen Flüchtlingen aus den Nachbarländern nach Beendigung des mosambikanischen Bürgerkrieges sowie von rund 15.000 Mosambikanern aus der ehemaligen Deutschen Demokratischen Republik, sogenannten Madgermanes, stellen das Land vor große Herausforderungen.

Insgesamt werden über 40 Sprachen im Land gesprochen. Die einheimischen Landessprachen zählen zur Sprachgruppe der Bantusprachen. Portugiesisch, die einzige Amtssprache, wird laut Volkszählung von 2007 inzwischen von etwa 12 % (vornehmlich in Städten) der Gesamtbevölkerung als Muttersprache gesprochen, in Maputo jedoch etwa 25 %. Gut 50 % beherrschen Portugiesisch als Zweitsprache neben ihrer einheimischen Sprache. Die meisten Mosambikaner sprechen mehr als eine einheimische Sprache. Zu den wichtigsten Sprachen gehören neben der Amtssprache Portugiesisch unter anderem (sortiert nach Sprecheranteil):

Bei den ausländischen Sprachen sind diejenigen hervorzuheben, die von den chinesischen, indischen und pakistanischen Einwanderern gesprochen werden.

Gemäß einer Erhebung von 2007 sind insgesamt 28,4 % der Einwohner römisch-katholisch (hauptsächlich im Süden und Südwesten) und 17,9 % muslimisch (hauptsächlich Sunniten, vor allem im Norden und an den Küstenregionen). 15,5 % sind zionistische Christen. Protestanten machen 12,2 % der Einwohner aus, davon sind 10,9 % Pfingstler und 1,3 % Anglikaner. Der Rest der Bevölkerung (6,7 %) gehört anderen Religionen, zumeist traditionellen Religionen an. Keiner Religion gehören 18,7 % an und 0,7 % sind nicht erfasst.

Laut UNICEF gibt es 1,5 Millionen Waisen in Mosambik, (davon 470 000 Aidswaisen). Die Kinderarbeit ist aufgrund der Armut ein großes Problem, da viele Familien auf das Geld, das die Kinder verdienen, angewiesen sind. Nur 6 % der unter Fünfjährigen haben eine Geburtsurkunde. Millionen Kinder, die über kein Dokument verfügen, sind Missbrauch, Kinderarbeit, Zwangsverheiratung und dem Dienst an der Waffe ausgesetzt. Ohne Geburtsurkunde gibt es keinen staatlichen Schutz. Ca. 32 % der Kinder arbeiten auf Feldern, Märkten, als Schuhputzer oder als Bettler. Die Situation älterer Menschen ist prekär. Die staatliche Rente beträgt umgerechnet nur fünf US-Dollar.

In Mosambik können fast 40 % der Erwachsenen nicht lesen und schreiben. 55 % der Frauen sind Analphabeten. Seit dem Ende des Krieges 1992 hat Mosambik große Anstrengungen für den Grundschulunterricht unternommen. Mittlerweile gehen 80 % der Kinder 5 Jahre lang zur Schule, während 30 % die Schule bis zur 6. oder 7. Klasse weiterbesuchen. Die durchschnittliche Klassengröße beträgt 74 Kinder, in den ländlichen Gebieten sind es noch mehr. Mosambik hat trotz Fortschritten zu wenige Klassenzimmer, Schulmöbel und Schulbücher. Zahlreiche Lehrer nehmen an der landesweiten Kampagne zur Verbesserung der Unterrichtsqualität an den Grundschulen teil.



AIDS ist in Mosambik ein großes Problem: 12,3 % der Erwachsenen (15 bis 49 Jahre) sind HIV-positiv (Stand: 2016). Das sind etwa 1,5 Millionen Menschen. AIDS stellt eine große Gefahr für alle dar, die Infektionsrisiken eingehen: Ungeschützte Sexualkontakte, unsaubere Spritzen oder Kanülen und Bluttransfusionen können ein erhebliches Risiko bergen.

Hochwasserkatastrophen, vor allem entlang des Sambesi, fördern die Ausbreitung von Cholera. Ab Ende 2003 breitete sich in Mosambik, insbesondere in der Maputo-Provinz, eine schwere Cholera-Epidemie aus. Eine gültige Gelbfieberimpfung wird bei Einreise aus einem Gelbfiebergebiet verlangt. Gelegentlich wird sie an der Grenze auch bei Einreise aus nichtendemischen Gebieten verlangt.

Die medizinische Versorgung im Lande ist vielfach technisch, apparativ und/oder hygienisch problematisch. Häufig fehlen auch gut ausgebildete Ärzte.

Nur 48 % der Geburten können medizinisch betreut werden. Die Säuglingssterblichkeit liegt bei 55 von 1000 Lebendgeburten (Stand 2015), die Kindersterblichkeit liegt bei 81 von 1000 Lebendgeburten (Stand 2015), die Müttersterblichkeit bei 489 von 100.000 Lebendgeburten (Stand 2015).

Die Trinkwasserversorgung im Land ist sehr schlecht. Zugang zu sauberem Trinkwasser, seit 2010 ein Menschenrecht der UNO, besitzt laut WHO und UNICEF nicht einmal jeder zweite Mensch in Mosambik.

Die Rate der an Unterernährung leidenden Bevölkerung konnte von 40,3 % im Jahr 2000 auf 26,6 % im Jahr 2015 gesenkt werden.

Entwicklung der Lebenserwartung in Mosambik

Quelle: UN

Vor den großen Erkundungsfahrten der Europäer herrschten seit Jahrhunderten Araber an der Küste vor Afrika. Sie betrieben Handel zwischen Afrika, dem Orient und Indien mit Gold, Elfenbein und afrikanischen Sklaven. Als erster Portugiese landete 1497 Pedro da Covilhã, der im Auftrag des portugiesischen Königs den Seeweg von Arabien nach Ostafrika erkundete, in Sofala. 1498 erreichte Vasco da Gama auf dem Weg nach Indien Mosambik: Auf der Insel von Mosambik traf er mit dem Scheich Moussa Ben Mbiki zusammen, von dem sich der Name Mosambik ableitet. Darauf bemächtigten sich die Portugiesen dieser Handelsplätze und drangen auf der Suche nach Gold entlang des Sambesi ins Landesinnere vor. Jahrhundertelang begnügten sich die Portugiesen mit dem Handel von Sklaven und kümmerten sich nicht groß um die Bevölkerung. Ihre Herrschaft dauerte bis ins 20. Jahrhundert, und durch Zwangsarbeit, ausbeuterische Arbeitsverträge und rücksichtslose Behandlung verschlechterten sich die Lebensbedingungen in den Kolonien erheblich. Bis 1898 war die Stadt Ilha de Moçambique Hauptstadt des Landes. Sie gab dem Land auch seinen Namen.

1890 musste Portugal britischem Druck nachgeben und auf die Verbindung Angolas und Mosambiks zu einem geschlossenen südafrikanischen Kolonialreich verzichten. Stattdessen nahm in den portugiesischen Kolonien der Einfluss britischen Kapitals beträchtlich zu. Verhandlungen über ein britisch-deutsches Bündnis führten aber schon 1898 zum Angola-Vertrag: Für den Fall, dass Portugal Geld brauchen sollte, vereinbarten Deutschland und Großbritannien eine gemeinsame Anleihe, für die die portugiesischen Kolonien als Pfand vorgesehen waren. Im Falle der erwarteten Zahlungsunfähigkeit Portugals sollten Angola und Nordmosambik an Deutschland, Südmosambik an Großbritannien fallen. Deutschland verzichtete dafür auf die Unterstützung der Buren in deren Kampf gegen Großbritannien. Das Abkommen wurde am 30. August 1898 geschlossen, aber niemals umgesetzt und schon 1899 durch die Verlängerung der britischen Schutzgarantie (Windsorvertrag) für Portugal und all seine Besitzungen unterlaufen. Obwohl das britisch-deutsche Bündnis nie zustande kam, bemühte sich Großbritannien 1912–1914 nochmals, den endgültigen Bruch mit dem Kaiserreich aufzuschieben. Bei einem Besuch des britischen Königs in Berlin wurde 1913 der Vertrag von 1898 aus den Archiven geholt und sogar noch zugunsten Deutschlands modifiziert. Tatsächlich aber zögerte Großbritannien die Unterzeichnung bis Juli 1914 heraus, dann machten das Attentat von Sarajevo und der Ausbruch des Ersten Weltkrieges seine Umsetzung ohnehin unmöglich. So blieben Angola und Mosambik zunächst im Besitz Portugals. Während des Krieges jedoch erklärte Südafrika 1915 ganz Mosambik zum Eroberungsziel, und ab 1917 zogen sich die deutschen Kolonialtruppen aus Deutsch-Ostafrika kämpfend nach Mosambik zurück und besetzten bis 1918 tatsächlich weite Teile der Nordhälfte. Als Entschädigung erhielt Portugiesisch-Ostafrika beim Frieden von Versailles 1919 das Kionga-Dreieck.

1962 wurde die Freiheitsbewegung FRELIMO gegründet. Je stärker die Portugiesen an ihrem Kolonialbesitz festhielten, umso radikaler wurde der Widerstandswille der FRELIMO. 1964 gingen die Widerstandskämpfer in den bewaffneten Kampf über, der im Norden sehr erfolgreich endete. Doch erst nach der Nelkenrevolution und dem Sturz des diktatorischen Regimes in Portugal erlangte Mosambik am 25. Juni 1975, nach knapp 500 Jahren als Kolonie, die Unabhängigkeit als Volksrepublik Mosambik. Samora Machel wurde der erste Staatspräsident, jedoch nicht durch allgemeine Wahlen. 1986 starb der FRELIMO-Präsident bei einem Flugzeugabsturz. In den FRELIMO setzten sich die marxistischen Kräfte durch. Da sie den Staat unter Kontrolle hatten, waren auch alle wichtigen Posten durch ihre Männer besetzt. Sie verstaatlichten die Industrie und gründeten landwirtschaftliche Produktionsgenossenschaften. Doch die Abwanderung europäischer Fachkräfte schwächte die Wirtschaft des Landes empfindlich. Mitte der siebziger Jahre entstand eine neue Widerstandsbewegung, die durch Südafrika und Rhodesien unterstützt wurde- die RENAMO. Im Gegensatz z. B. zur angolanischen UNITA hatte die erst nach der Unabhängigkeit entstandene RENAMO niemals gegen die portugiesische Kolonialmacht gekämpft und daher wenig moralischen Rückhalt in der mosambikanischen Opposition.

Das Land verfiel 1976 dennoch in einen 16-jährigen Bürgerkrieg zwischen FRELIMO und RENAMO, der zu einem völligen wirtschaftlichen Zusammenbruch führte. Mosambik erhielt Unterstützung z. B. nach 1980 von Simbabwe (ehemals Rhodesien), das 10.000 Soldaten zur Sicherung des Beira-Korridors entsandte. Im Land befanden sich 1983 außerdem 750 Militärberater und Ausbilder aus Kuba, 600 aus der Sowjetunion und 100 aus der DDR. Doch erst nach der Unterzeichnung des Friedensvertrages, des Allgemeinen Friedensabkommens von Rom, und mit der Hilfe von UN-Friedenstruppen konnte das Land stabilisiert und die erste Oppositionspartei gegründet werden. Seit 1995 ist Mosambik neben Kamerun das einzige Mitglied des Commonwealth of Nations, das nicht ehemals britische Kolonie gewesen ist. Die Auswanderung der Weißen in großem Ausmaß, die wirtschaftliche Abhängigkeit von Südafrika, eine anhaltende Dürre und der langgezogene Bürgerkrieg behinderte die wirtschaftliche Entwicklung des Landes. Seit der Abkehr vom Marxismus-Leninismus und der Einparteienherrschaft der FRELIMO hat sich die Renamo als politische Partei etabliert und stellt seit 1994 die parlamentarische Opposition im Lande. Die ersten demokratischen Wahlen wurden unter der Aufsicht von ONUMOZ im Oktober 1994 gehalten. Aus ihr ging die Festigung der alten Regierung hervor, und RENAMO akzeptierte, nachdem Druck von Anrainer-Staaten ausgeübt wurde, die Sitze im Parlament, womit sie die Opposition formte.

Die Demokratisierung des Landes war das Verdienst des nach Samora Machels an die Macht gekommenen Staatspräsidenten Joaquim Alberto Chissanó. Chissanos Verdienste um die Demokratie, die Ausarbeitung einer Verfassung mit einem Mehrparteiensystem, die Normalisierung der Beziehungen zum Nachbarstaat Südafrika und insbesondere die Tatsache, dass er nach zwei Amtszeiten auf eine weitere Kandidatur als Präsident verzichtete und den Weg für einen Nachfolger freigab, brachten ihm im Oktober 2007 nach dem Ende seiner Präsidentschaft den Preis der "Mo Ibrahim Foundation" für gute Regierungsführung.

Im Februar 2000 führten schwere Regenfälle zu einer Flutkatastrophe, die zahlreiche Menschenleben forderte.

Im Oktober 2013 nährten Berichte über zunehmende Kämpfe zwischen den ehemaligen Bürgerkriegsparteien die Furcht vor einer Aufkündigung des Friedensabkommens von 1992 – zumindest kündigte ein Sprecher der RENAMO dies als mögliche Konsequenz der Einnahme des RENAMO-Hauptquartiers nahe Gorongosa durch Regierungstruppen an.

Die herrschende Frelimo-Regierung sagte sich 1989 offiziell vom Marxismus los. Die im folgenden Jahr aufgestellte Verfassung garantierte freie Wahlen in einem Mehrparteiensystem und die freie Marktwirtschaft. Die seither stattgefundenen Wahlen wurden von auswärtigen Beobachtern begleitet und als überwiegend fair eingeschätzt, wenn auch FRELIMO alle Möglichkeiten einer Regierungspartei zur Wahlbeeinflussung nutzte. Es hat sich seither ein Quasi-Zweiparteiensystem herausgebildet, das von der Dauer-Regierungspartei FRELIMO und der bisher größten Oppositionspartei RENAMO beherrscht wird. Keiner der übrigen Parteien Mosambiks ist es bisher gelungen, irgendeine erwähnenswerte Rolle in diesem System zu spielen. Zu den Wahlen 2009 trat allerdings die RENAMO-Abspaltung Movimento Democrático de Moçambique (MDM) an und errang einen Achtungserfolg.

Die wichtigsten Organe des Staates sind:

Am 28. Oktober 2009 fanden die vierten Parlaments- und Präsidentschaftswahlen seit der Beendigung des Bürgerkriegs 1992 statt, die erwartungsgemäß vom amtierenden Präsidenten Armando Guebuza und FRELIMO gewonnen wurden. Zeitgleich wurden erstmals auch Wahlen zu den Provinzvertretungen abgehalten.

Bei der Präsidentschaftswahl in Mosambik 2014 wurde der frühere Verteidigungsminister Filipe Nyusi (FRELIMO) zum Präsidenten gewählt. Er ernannte im Januar 2015 Carlos Agostinho do Rosário zum Premierminister von Mosambik.

Die Haftbedingungen sind ausgesprochen hart und haben bereits zu mehreren Todesfällen geführt. Die Gerichte sind unterbesetzt, und die unzureichend ausgebildeten Richter arbeiten ineffizient und sind von der regierenden Partei beeinflusst. Die Polizei ging, laut Amnesty International, bei Demonstrationen und bei der Festnahme von Straftatverdächtigen mit exzessiver Gewalt vor. 13 Häftlinge erstickten dabei im Polizeigewahrsam in einer überfüllten Gefängniszelle. Zwei Polizeibeamte mussten sich in diesem Zusammenhang vor Gericht verantworten. Für eine im Jahre 2007 begangene außergerichtliche Hinrichtung wurde ein hochrangiger Polizeibeamter wegen Mordes verurteilt.

Es wurden auch 2009 Fälle schwerer Menschenrechtsverletzungen gemeldet: Die Pressefreiheit ist stark eingeschränkt und unabhängige Medien werden behindert. Gesellschaftliche Probleme wie häusliche Gewalt, Diskriminierung von Frauen, Missbrauch, Ausbeutung, Zwangsarbeit von Kindern und Diskriminierung von sexuellen Minderheiten und Menschen mit HIV/AIDS sind nach wie vor weitverbreitet, so der Human Rights Report 2009 des US-amerikanischen Außenministeriums. Auch kommt es immer wieder zu Übergriffen, Diskriminierungen und Gewalthandlungen aufgrund der sexuellen Orientierung von Menschen. Homosexualität wird seit 2015 nicht mehr als Straftat angesehen.

Im Länderbericht Freedom in the World 2017 der US-amerikanischen Nichtregierungsorganisation Freedom House wird das politische System des Landes als „teilweise frei“ bewertet. In der Kategorie „politische Rechte“ erhält Mosambik die Note 4, bei der Wahrung der Bürgerrechte erhält das Land ebenfalls die Note 4 (die Note 1 ist die beste und die 7 die schlechteste). Mosambik zählt, aufgrund der verbreiteten politischen Korruption, noch nicht zu den Wahldemokratien.

2016 kam es, laut Berichten, bei erneuten Kämpfen zwischen Regierungstruppen und der RENAMO zu Menschenrechtsverletzungen.

Mosambik ist in zehn Flächen-Provinzen und die Hauptstadtprovinz gegliedert, darunter folgen 141 Distrikte, die ihrerseits gegliedert sind in 415 Postos administrativos (Verwaltungsbezirke) mit 1024 Localidades (Orte), die jeweils noch meist mehrere Ortschaften (Povoações) und Dörfer (Aldeias) umfassen.

Die elf Provinzen Mosambiks:

Die größten Städte sind die Hauptstadt Maputo mit 1.101.170 Einwohnern, Matola mit 1.616.267 Einwohnern, Nampula mit 743.125 und Beira mit 533.825 Einwohnern (2017). Die Metropolregion von Maputo hatte im selben Jahr 2,717.437 Millionen Einwohner.

Mosambiks Wirtschaft basiert vorwiegend auf Landwirtschaft. In den 1980er Jahren wurde die Wirtschaft durch den Bürgerkrieg, die Abwanderung portugiesischer Fachkräfte und mehrere Dürreperioden geschwächt. Zu dieser Zeit waren die meisten Plantagen und Industriebetriebe im Besitz des Staates. Erst 1990 führte die Regierung die freie Marktwirtschaft ein.

Die Währung von Mosambik ist der Metical. 1 Metical = 100 Centavos. Bis 2006 entsprach 1 Euro ungefähr 34.500 Metical, 1 Schweizer Franken 22.300 Metical. Am 1. Juli 2006 wurden der Währung drei Nullen gestrichen. Umrechnung neu: 1 Euro entspricht ungefähr 42,5 Metical, 1 Schweizer Franken 35 Metical.

Im Global Competitiveness Index, der die Wettbewerbsfähigkeit eines Landes misst, belegte Mosambik Platz 136 von 137 Ländern (Stand 2017–18). Im Index der Wirtschaftlichen Freiheit belegte das Land 2017 Platz 158 von 180 Ländern.

Obwohl über 80 % der Erwerbstätigen in der Landwirtschaft tätig sind, produzieren sie nur 24 % des Bruttoinlandsprodukts (BIP). Die wichtigsten landwirtschaftlichen Erzeugnisse sind Cashewnüsse, Zuckerrohr, Baumwolle und Tee. Angebaut werden außerdem auch Bananen, Tabak, Zitrusfrüchte, Sisal und Ölpalmen. Der Versuch, die aus Zentralamerika stammende und als ökologisch anspruchslos geltende Jatropha-Pflanze zur Gewinnung von Pflanzenöl in Mosambik großflächig zu kultivieren, scheiterte. Eine Projektplantage des deutschen Unternehmens Elaion AG wurde 2011 nach fünf Jahren aufgegeben, da die erwarteten wirtschaftlichen Gewinne ausblieben.

Der Großteil des jährlichen Holzeinschlages wird als Brennstoff verwendet.
Die Küstenfischerei hat sich in den letzten Jahren zu einem wichtigen Wirtschaftsfaktor entwickelt. Gefischt werden hauptsächlich Thunfisch und Garnelen.

Für die Forschung und Entwicklung im mosambikanischen Baumwollanbau gibt es ein Institut, das "Instituto do Algodão de Moçambique" (IAM). Sein Sitz befindet sich in Maputo. Es unterhält Außenstellen in Montepuez, Nampula, Beira und Maxixe.

Seit 2008 wird im Norden Mosambiks unter Federführung eines brasilianisch-japanischen Konsortiums ein Großprojekt zur grundsätzlichen Umstrukturierung des Agrarsektors verfolgt. Das Vorhaben unter der Bezeichnung "ProSavana" ist Teil eines agrarwirtschaftlichen Projektes im sogenannten Nacala-Entwicklungs-Korridor, einem Gebiet von etwa 14 Millionen Hektar Fläche. Die im Projekt "ProSavana" vorgesehene Fläche umfasst etwa sechs Millionen Hektar. Davon betroffen sind die drei Provinzen Niassa, Nampula und Zambezia sowie angrenzende Areale in den Nachbarprovinzen Manica und Cabo Delgado. Statt der heute dort vorherrschenden kleinbäuerlichen Landwirtschaft auf kommunalen Flächen sollen künftig agrarindustrielle Großbetriebe dafür sorgen, dass dieser Sektor durch die Produktion von Nahrungsmitteln und anderen Agrarrohstoffen für den Binnenmarkt, vor allem aber für den Export, maßgeblich zum Wirtschaftswachstum des Landes beiträgt.

Wesentliche Komponente von "ProSavana" ist die Steigerung der Produktivität durch Technologietransfer und ausländische Investitionen. Ähnlich wie in den tropischen Savannengebieten Brasiliens, dem Cerrado, sollen in Mosambik in großem Stil Sojabohnen, Sonnenblumen und Baumwolle wie auch andere Rohstoffe für den weltweiten Export angebaut werden. Das trilaterale Vorhaben wird mit japanischem Kapital sowie brasilianischer Technik und Know-how umgesetzt. Laut der japanischen Agentur für Internationale Zusammenarbeit ("Japan International Cooperation Agency" / JICA) handelt es sich dabei um „eines der weltweit größten dreiseitigen Kooperationsprojekte“. Umweltverträglichkeitsprüfungen oder gesellschaftliche Folgeabschätzungen sind bisher nicht bekannt.

Innerhalb mosambikanischer Kleinbauernverbände und in Kreisen von Beratern der internationalen Entwicklungszusammenarbeit wird befürchtet, dass Brasilien mit seinem Agrarmodell auch die sozialen Widersprüche des Landes nach Afrika exportieren könnte.

Im November 2012 ging Mosambiks Kleinbauernverband UNAC ("União Nacional de Camponeses" / "National Peasants' Union") gemeinsam mit Via Campesina und GRAIN, bedeutende Internationale Nichtregierungsorganisationen für eine nachhaltige und menschenzentrierte ländliche Entwicklung, mit einer Erklärung zu "ProSavana" an die Öffentlichkeit. Darin äußern die Organisationen die Sorge, dass ansässige Bauernfamilien im Zuge des Vorhabens ihr Land verlieren werden und sich zukünftig in der Agrarindustrie als Landarbeiter verdingen müssten. Gefordert wird u. a. Transparenz und Zugang zu den Planungsunterlagen. Bis zu jenem Zeitpunkt waren innerhalb Mosambiks kaum Informationen zu diesem Vorhaben zugänglich.

Anfang April 2013 unterzeichneten Vertreter der drei beteiligten Staaten Japan, Brasilien und Mosambik eine Vereinbarung zur Umsetzung des gemeinsamen Agrarprojektes. Ende April gelangte der auf März 2013 datierte "ProSavana"-Masterplan an die Öffentlichkeit.

Mosambik verfügt über einige mineralische Rohstofflagerstätten. Es gibt Vorkommen an Diamanten und anderen Edelsteinen sowie Gold und Kupfer, Nutzgesteine wie Gabbros, Granite und Marmore, Industrieminerale wie Bauxit, Beryll, Korund, Glimmer, Graphit, ferner Lagerstätten mit ökonomisch interessanten Gehalten an Zinn, Seltenerdmetallen (Davidit), Niob und Tantal sowie Schwermineralsande. Weiterhin existieren Lagerstätten an Energierohstoffen wie Erdgas und Steinkohle.

Im Nordwesten des Landes werden die möglicherweise größten Steinkohlevorkommen der Welt vermutet. 23 Milliarden Tonnen sollen in der Provinz Tete nahe der Grenze zu Malawi lagern. Wegen logistischer Probleme konnten diese Vorkommen bisher nicht genutzt werden. Geplant ist eine 525 Kilometer lange Eisenbahnverbindung, mit der die Kohle an die Küste der Provinz Zambezia des südostafrikanischen Landes transportiert werden soll. Dort sind neue Hafenanlagen vorgesehen, die eine Kapazität zur Verladung von 20 Millionen Tonnen Kohle pro Jahr erlangen sollen.

Die 1998 errichtete Aluminium-Hütte Mozal verarbeitet importiertes Bauxit zu Aluminium, dem mittlerweile wichtigsten Exportgut Mosambiks. Der Betrieb der Schmelze trägt mit 7 % maßgeblich zum Bruttoinlandsprodukt Mosambiks bei und hat das Außenhandelsdefizit Mosambiks halbiert.

Andere Rohstoffe des Landes werden wenig genutzt. Die Industrie Mosambiks beschränkt sich vor allem auf die Verarbeitung der landwirtschaftlichen Erzeugnisse.

Die Handelsbilanz Mosambiks ist noch immer stark negativ. Exportiert werden hauptsächlich Cashewnüsse, Krustentiere, Baumwolle und Zucker. Seit einigen Jahren ist Aluminium das wichtigste Exportprodukt. Importiert werden Maschinen, elektronische Geräte, Erdöl, Nahrungsmittel und Konsumgüter. China ist der wichtigste Handelspartner.

Der Staatshaushalt umfasste 2016 Ausgaben von umgerechnet 3,6 Mrd. US-Dollar, dem standen Einnahmen von umgerechnet 2,5 Mrd. US-Dollar gegenüber. Daraus ergibt sich ein Haushaltsdefizit in Höhe von 9,3 % des BIP.
Die Staatsverschuldung betrug 2016 88,6 % des BIP.

2006 bzw. 2009 betrug der Anteil der Staatsausgaben (in % des BIP) folgender Bereiche:

Der Bundesrat der Schweiz gewährte zugunsten der Republik Mosambik eine Budgethilfe im Umfang von 24 Millionen Schweizer Franken für die Periode 2007–2009. Die jährlichen Auszahlungen sind an die Erreichung von wichtigen Reformfortschritten gebunden. Die finanzielle Hilfe soll Mosambik bei der Umsetzung der Armutsbekämpfungsstrategie unterstützen sowie die Rahmenbedingungen für das wirtschaftliche Wachstum weiterverbessern.

Bedeutende Seehäfen befinden sich in allen größeren Küstenstädten, wie Maputo im Süden, Beira, Quelimane, Lumbo und Nacala bis Pemba im Norden.

Internationale Flughäfen befinden sich u. a. in Maputo (MPM), in Beira (BEW) und in Nampula (APL).

Der Tourismus ist wenig entwickelt. Unterkünfte sind rar, ein Ausbau der touristischen Infrastruktur ist geplant.

Die älteste portugiesische Handelsniederlassung wurde 1507 auf der Ilha de Moçambique gegründet. Vom späten 16. Jahrhundert bis zur Fertigstellung der Eisenbahnverbindung Transvaal – Delagoa-Bucht 1898 lag hier die Hauptstadt von Portugiesisch-Ostafrika. Seit 1991 ist die kleine Insel mit ihrer gut erhaltenen Kolonialarchitektur das einzige UNESCO-Welterbe auf mosambikanischen Territorium.

Der erste Nationalpark Mozambiks, der Nationalpark Gorongosa wurde 1960 gegründet und liegt in der Provinz Sofala. Er ist 150 km von der Stadt Beira entfernt.
Östlich davon, vor der Küste Mozambiks befindet sich auf dem Bazaruto-Archipel der 1971 gegründete Bazaruto National Park. An der Grenze zum südafrikanischen Krüger-Nationalpark findet sich der 2001 gegründete Nationalpark Limpopo. Im Südosten in der Nähe der Hauptstadt Maputo ist auf der Machangulo-Halbinsel das Machangulo Private Naturreservat und das Maputo-Reservat.

In der traditionellen Unterhaltungsmusik werden annähernd äquiheptatonisch gestimmte Xylophone ("valimba, manguilo, timbila") und Brettzithern ("bangwe") gespielt. Zithern, Lamellophone ("shitata") und einsaitige Röhrenspießgeigen ("mugole, tagare, chikwèsa") dienen zur Liedbegleitung. Gruppentänze werden von Chorgesängen und mit den Händen oder mit dünnen Schlägeln geschlagenen einfelligen Röhrentrommeln begleitet. "Marrabenta" ist eine aus der portugiesischen Kolonialzeit stammende Tanzmusik. Zu den international bekanntesten Musikgruppen des Landes, die mit E-Gitarre, Bass und Schlagzeug populäre Tanzmusik spielen, gehören Mabulu, Eyuphuro, Mc Roger, Ghorwane und Kapa Dech.

Bei der Rangliste der Pressefreiheit 2017, welche von Reporter ohne Grenzen herausgegeben wird, belegte Mosambik Platz 93 von 180 Ländern. Obwohl die Pressefreiheit in Mosambik Verfassungsrang genießt, gibt es bei der Situation der Pressefreiheit im Land laut der Nichtregierungsorganisation "erkennbare Probleme".

Rundfunk:
Rádio Moçambique (staatliches Radio) sendet in portugiesischer und verschiedenen lokalen Sprachen.

Fernsehen:
Televisão de Moçambique (staatliches Fernsehen, ein Kanal, sendet ab Nachmittag), Soico TV (privat), TV Miramar (privat)

Tageszeitungen:
Notícias (Maputo), O País (Maputo), Diário de Moçambique (Beira) sowie die Faxzeitungen Mediafax, Imparcial und Vertical

Wochenzeitungen:
@Verdade, Domingo, Zambeze, Savana, Demos, Jornal da Tard

Nachrichtenagentur:
Agência de Informação de Moçambique (AIM)

2016 hatten 6,4 % der Bevölkerung Zugang zum Internet.




</doc>
<doc id="10361" url="https://de.wikipedia.org/wiki?curid=10361" title="Gabun">
Gabun

Gabun [] ist ein Staat in Zentralafrika. Er grenzt an Kamerun, Äquatorialguinea und die Republik Kongo sowie an den Golf von Guinea. Durch das Land verläuft der Äquator. Gabun hat rund zwei Millionen Einwohner (Stand 2017). Im Jahr 2016 belegte es im Index der menschlichen Entwicklung Rang 109 von 188 Ländern. Dank seiner Ölvorkommen zählt es zu den wohlhabenderen Ländern Afrikas.

Gabun liegt an der westlichen Atlantikküste Zentralafrikas, von wo aus es sich in östliche Richtung bis kurz vor das Kongobecken erstreckt.
Die Küstenlänge beträgt 885 km. Das westliche Küstentiefland steigt nach etwa 200 Kilometern stufenförmig bis zur Niederguineaschwelle im Osten an.

Größter Fluss des Landes ist der Ogooué, der sich mit seinen zahlreichen Nebenflüssen tief in das Gelände des Hochlands eingeschnitten hat.
Der höchste Berg Gabuns ist bisher nicht festgelegt. Es existieren verschiedene (fehlerhafte) Angaben, die bis zu 500 Höhenmeter voneinander abweichen. Die höchsten Erhebungen im Nordosten und Süden reichen bis knapp über 1.000 m ü. d. M.

In einigen Regionen Gabuns findet sich sehr altes Gestein, das bis auf das Proterozoikum (rund 2 Milliarden Jahre vor heute) datiert werden kann. In den entsprechenden Formationen wurden unter anderem Gabonionta, frühe Formen mehrzelligen Lebens, und insgesamt 17 natürliche Kernreaktoren gefunden, deren bekanntester der Naturreaktor Oklo ist.

Gabun gehört zu den am dünnsten besiedelten Ländern Afrikas. Es hat etwa 75 % der Fläche Deutschlands, aber nur knapp doppelt so viele Einwohner wie Köln. Etwa die Hälfte der Bevölkerung lebt in und um die drei größten Städte: Libreville mit 703.939, Port-Gentil mit 136.462 und Franceville mit 110.568 Einwohnern. Die Landesmitte und der Norden sind weitgehend menschenleer. Der jährliche Bevölkerungszuwachs mit 1,8 % ist für afrikanische Verhältnisse vergleichsweise niedrig.

Die zusammengefasste Fruchtbarkeitsziffer liegt bei 4,43 (Stand 2016) und somit weit unter dem afrikanischen Durchschnitt. Frauen haben eine Lebenserwartung von 64,1 Jahren und Männer eine von 63,2 Jahren (Stand 2010–2015). 42 % der Bevölkerung sind unter 15 Jahre alt und 3,7 % über 65 Jahre. 87 % der Bevölkerung lebt in den Städten.

Gabun hatte 2016 den vierthöchsten Index der menschlichen Entwicklung Subsahara-Afrikas (hinter Mauritius, Seychellen und Botswana).

Bevölkerungsentwicklung

Quelle: UN

Auf dem Staatsgebiet von Gabun leben etwa 40 verschiedene Völker bzw. ethnische Gruppen; die Mehrheit der Bevölkerung sind Angehörige von Bantu-Völkern. Davon sind die mit Abstand größte und politisch einflussreichste Volksgruppe die Mpongwe-Fang, die etwa ein Drittel der Gabuner stellen (Mpongwe 31 %, Fang 7 %). Kleinere Gruppen sind die Mbete (15,5 %), die Bapunu (15 %, mit der Sprache Punu), die Tsabatis (14 %), die Batazis (9,5 %) und die Bateke (4 %). Außerdem gibt es 1,5 % Pygmäen – die im Nordosten und Süden lebenden Ureinwohner – sowie ungefähr 60.000 Franzosen, diese zumeist in den Städten, in Gabun. Ausländer – viele davon Angestellte eines multinationalen Erdölkonzerns – spielen eine große Rolle im Bildungswesen und in der Wirtschaft.

Die Amtssprache Französisch wird von rund 80 % der Gesamtbevölkerung beherrscht, wobei es ein Drittel der Einwohner der Hauptstadt Libreville als Muttersprache spricht. Im Alltag werden überwiegend Bantusprachen gesprochen. Die wichtigste Bantusprache ist das Fang, daneben haben auch das Mbere, das Punu, das Teke und das Njebi Bedeutung. Insgesamt werden 42 verschiedene Sprachen und Idiome gesprochen.

Etwa 65 % der Einwohner bezeichnen sich als Christen (rund 60 % als Katholiken und ca. 5 % als Anhänger verschiedener protestantischer Kirchen). Viele von ihnen pflegen jedoch auch weiterhin bestimmte Formen afrikanischer Religiosität. Ein großer Teil der übrigen Bevölkerung hängt zumeist den traditionellen Volksreligionen, vor allem dem Bwiti, an. Eine Minderheit von rund 12 % bekennt sich zum Islam, darunter Präsident Bongo und zahlreiche Ausländer.

Es besteht offiziell eine zehnjährige allgemeine Schulpflicht.
Etwa die Hälfte der Schulen des Landes Gabun sind in konfessioneller oder privater Trägerschaft.

Die Analphabetenquote beträgt allerdings weiterhin etwa 29 %.

Die Kindersterblichkeit liegt bei 44 pro 1.000 Geburten und die Müttersterblichkeit bei 291 pro 100.000 Geburten (Stand 2017). 86 % der Geburten können medizinisch betreut werden (Stand 2008).
Die AIDS-Rate wird je nach Quelle auf zwischen 8,0 % und 5,9 % geschätzt ("siehe auch: HIV/AIDS in Afrika"). Die medizinische Versorgung ist oft unzureichend. 2015 waren 7 % der Bevölkerung unterernährt was eine der niedrigsten Raten in Afrika ist.

Lambaréné in Gabun beherbergt das von Albert Schweitzer begründete und bis zu seinem Tod 1965 von ihm geleitete Urwaldkrankenhaus.

Quelle: UN

Während des 15. Jahrhunderts wurde auf dem Gebiet des heutigen Gabun der Bantu-Staat Loango gegründet.

Der Begriff Gabun stammt von den portugiesischen Seefahrern, die Mitte des 15. Jahrhunderts begannen, einen Seeweg nach Indien zu suchen und dabei Jahr für Jahr an der afrikanischen Westküste weiter nach Süden vordrangen. Im Bereich des heutigen Gabun trafen sie auf dichten Seenebel, der sich wie ein Mantel (portugiesisch „gabão“) um alles legt.

Nach der Besiedlung des Gebietes erlangten die französischen Siedler 1839 eine erste Hoheit über das Gebiet. 1854 wurde Gabun mit Gorée und anderen französischen Siedlungen vereinigt, Gorée 1858 in den Senegal wiedereingegliedert. 1888 wurde Gabun Teil von Französisch-Kongo und 1910 als selbständiger Teil von Französisch-Äquatorialafrika wieder ausgegliedert. Als sich Französisch-Äquatorialafrika 1958 auflöste, erlangte Gabun als Gabunische Republik die Autonomie.

Am 17. August 1960 erlangte Gabun die Unabhängigkeit von Frankreich unter Präsident Léon M’ba, dem 1967 nach dessen Tod Omar Bongo nachfolgte. Die Gründung der "Parti Démocratique Gabonais (PDG)" erfolgte am 12. März 1968. Mit dieser Einheitspartei regierte er das Land lange Zeit mit harter Hand. Gabun führte in den 1990er Jahren ein Mehrparteiensystem ein und verabschiedete eine neue Verfassung, die eine Reform der Regierungsorganisationen und transparentere Wahlen ermöglichte. Die relativ kleine Bevölkerung, die enormen Rohstoffvorkommen und Hilfe von außen machten Gabun im Laufe der Zeit zu einem der wenigen florierenden Staaten Afrikas.

Staatspräsident Omar Bongo war der am längsten herrschende Staatschef in Afrika; er starb am 8. Juni 2009 in Barcelona an Herzstillstand.

Die Senatspräsidentin Rose Francine Rogombé wurde zur Übergangspräsidentin gewählt mit dem Auftrag, innerhalb von 45 Tagen Neuwahlen zu organisieren.

Am 30. August 2009 gewann der Verteidigungsminister Ali Bongo die Wahlen und wurde damit Nachfolger seines Vaters als Staatspräsident. Er erreichte mit 140.000 Stimmen 41,73 % der abgegebenen Stimmen bei 800.000 Wahlberechtigten. Auf den früheren Innenminister André Mba Obamé und auf einen weiteren Oppositionskandidaten entfielen je etwa 87.000 Stimmen. Am Wahltag kam es in der Hafenstadt Port-Gentil, einer Hochburg der Opposition, lokal zu Krawallen durch Anhänger des unterlegenen Kandidaten, in die etwa 600 Personen, vorwiegend männliche Jugendliche, verwickelt waren. Es wurde ein Polizeiposten und ein Gefängnis gestürmt und 300 Gefangene befreit. Die Gelegenheit wurde genutzt, um zahlreiche Geschäfte, vorwiegend die von libanesischen Immigranten, zu plündern. Die von den unterlegenen Kandidaten verlangte Neuauszählung der Stimmen ergab keine Veränderung des Wahlergebnisses. Daher wird das Ergebnis von diesen noch immer nicht anerkannt. Da aber sowohl europäische als auch Wahlbeobachter der Afrikanischen Union die Rechtmäßigkeit und Richtigkeit dieser Wahlen bestätigt haben, kam es am 17. Oktober 2009 zur Angelobung Ali Bongos.

Nach der Verfassung vom 28. März 1991 ist Gabun eine präsidiale Republik mit einem Mehrparteiensystem. Der Präsident ist Staatsoberhaupt und Oberbefehlshaber der Streitkräfte und wird für 7 Jahre vom Volk direkt gewählt und kann nach einer Verfassungsänderung von 2003 unbegrenzt wiedergewählt werden. Vollziehendes Organ ist die Regierung unter Vorsitz des Premierministers (wird vom Präsidenten ernannt). Der Präsident übt gemeinsam mit ihm und dem Regierungskabinett, das dem Präsidenten verantwortlich ist, die Exekutivgewalt aus. Die Legislative hingegen liegt beim Zweikammerparlament, das aus dem Senat (mit 91 Mitgliedern, die von den Regional- und Gemeinderäten auf 6 Jahre gewählt werden) und der Nationalversammlung besteht. Die Nationalversammlung hat 120 Abgeordnete, die für 5 Jahre gewählt werden.

Im Demokratieindex 2016 der britischen Zeitschrift "The Economist" belegt Gabun Platz 123 von 167 Ländern und gehört damit zu den autoritär regierten Staaten. Im Länderbericht Freedom in the World 2017 der US-amerikanischen Nichtregierungsorganisation Freedom House wird das politische System des Landes als „nicht frei“ bewertet.

Das Rechtssystem umfasst Recht französischen kolonialen Ursprungs sowie auch traditionelles Stammesrecht.

Einflussreichste Parteien:

Die Gefängnisse sind überfüllt und die Haftbedingungen sehr hart. Lebensmittel, hygienische Bedingungen und Belüftung sind mangelhaft. Medizinische Versorgung ist so gut wie nicht vorhanden.

In Gabun arbeiten viele Kinder, die von Menschenhändlern aus ihrer Heimat verschleppt wurden, vor allem Mädchen von 8 bis 15 Jahren aus Togo, Benin und Nigeria.

Homosexualität ist in Gabun legal, jedoch wird diese in der Öffentlichkeit tabuisiert, vielfach wird sie als Krankheit betrachtet. „Offen vorgetragene Bekenntnisse zur Homosexualität“ werden von größeren Bevölkerungsteilen als „Verstoß gegen die guten Sitten“ betrachtet und würden nicht verstanden, so das Auswärtige Amt der Bundesrepublik Deutschland. In Gabun entwickelt sich zunehmend eine Zivilgesellschaft. Federführend war unter anderem das Engagement des Aktivisten Marc Ona, welcher 2009 den Goldman Environmental Prize erhielt. Nach den Angaben der international tätigen Nichtregierungsorganisation, Reporter ohne Grenzen kommt es im Land sehr häufig zu Polizeigewalt gegen Journalisten; so werde häufig eine Selbstzensur unternommen. 

Im Korruptionswahrnehmungsindex (CPI) der Transparency International belegte das Land gemeinsam mit Peru, Philippinen, Niger, Trinidad und Tobago, Thailand und Osttimor Platz 101 von 176 Ländern (Stand 2016). 

2010/11 war das Land über einen nicht-ständigen Sitz im Sicherheitsrat der Vereinten Nationen in New York und Genf und bei der UNESCO in Paris vertreten. Weiterhin wurden in der nichtafrikanischen Welt Botschaften in Frankreich, Großbritannien, Italien, USA, Russland, Belgien (Brüssel), Brasilien, Kanada, Saudi-Arabien, China, Libanon, Südkorea und Japan eingerichtet.

Gabun ist bei der Bundesrepublik Deutschland in Berlin durch den außerordentlichen und bevollmächtigten Botschafter, S.E. Jean Marie Maguena, akkreditiert. Honorarkonsul der Gabunischen Republik in Offenbach am Main ist Olaf Meister.

Deutschland wiederum hat in der Hauptstadt Libreville eine Botschaft eingerichtet, die zugleich für São Tomé und Príncipe zuständig ist, jedoch nicht für Rechts- und Konsularaufgaben. Außerordentlicher und bevollmächtigter Botschafter ist Burkhard Ducoffre.

Gabun ist Mitglied der International Cocoa Organization.

Die Streitkräfte Gabuns gliedern sich in Armee, Luftwaffe und Marine und verfügen über 5.000 Mann.

Der Staat gliedert sich in neun Provinzen, diese wiederum in 37 Departements.
Die größten Städte sind (Stand 2013): Libreville 703.939 Einwohner, Port-Gentil 136.462 Einwohner, Franceville 110.568 Einwohner, Owendo 79.300 Einwohner, Oyem 60.685 Einwohner und Moanda 59.154 Einwohner.

Quelle: Direction Générale des Statistiques du Gabon

Die einzige Eisenbahn­strecke des Landes verbindet die Hauptstadt Libreville mit der Stadt Franceville im Landesinneren.

Daneben ist das Land von einem Fernstraßen­netz durchzogen, dessen Straßen drei Kategorien zugeordnet werden, nämlich den Nationalstraßen, den Regionalstraßen und den Lokalstraßen.
Reiche Naturschätze sowie eine liberale Wirtschaftspolitik begünstigten die wirtschaftliche Entwicklung Gabuns. Das Bruttoinlandsprodukt betrug 2016 19.056 Dollar (KKP) je Einwohner, was vergleichbar mit dem Einkommensniveau von Argentinien war. Gabun ist somit eines der reichsten Länder Subsahara-Afrikas. Dennoch leben etwa 80 Prozent der Bevölkerung unterhalb der Armutsgrenze. Etwa ein Drittel der Bevölkerung lebt in extremer Armut und beim Index der menschlichen Entwicklung rangierte das Land 2016 auf Platz 109 von 188 Ländern. Über 90 % des Bruttoinlandsprodukts wird von nur 10 % der Bevölkerung verbraucht.

Die wichtigsten Handelspartner sind die Vereinigten Staaten, China und Frankreich. Es sind nach Angaben des neuen Präsidenten Ali Bongo konkrete Projekte zum Ausbau des öffentlichen Verkehrswesens, des überregionalen Straßennetzes und zur nachhaltigen Landwirtschaft vorhanden und teilweise bereits in Ausführung.

Im Global Competitiveness Index, der die Wettbewerbsfähigkeit eines Landes misst, belegte Gabun Platz 108 von 138 Ländern (Stand 2016–17). Im Index der Wirtschaftlichen Freiheit belegte Gabun 2017 Platz 103 von 180 Ländern. 

Gabun ist einer der rohstoffreichsten Staaten Afrikas, mit erheblichen Erdölreserven vor der Küste. Dementsprechend zählen zu seinen Hauptexportgütern Rohöl und Erdölprodukte, auf die zirka 82 Prozent seiner Export­einnahmen entfallen. Im Landesinneren werden Mangan, Uran, Eisenerze und Gold gefördert. Mangan ist nach Erdöl und Holz das drittwichtigste Exportgut.

Die ehemals großen Uranvorräte bei Franceville sind weitestgehend erschöpft. Es ist das erklärte Ziel des neuen Präsidenten, die vorhandenen Einnahmen aus Rohstoffverkäufen verstärkt für die Verbesserung der nationalen Infrastruktur zu verwenden.

Weiterhin gehört Gabun zu den größten Tropenholz-Exportländern Afrikas – der ausgedehnte Waldbestand erlaubt die extensive Nutzung zahlreicher Hölzer. Ca. zwei Drittel der Landesfläche sind noch von tropischem Regenwald bedeckt; für das Edelholz Okoumé hat Gabun das internationale Weltmonopol. Die nationale Gesetzgebung verlangt allerdings eine nachhaltige Bewirtschaftung des Waldes, und der Export unbehandelter Hölzer unterliegt Restriktionen. 11 Prozent des Staatsgebietes sind bereits als Reservate ausgewiesen und werden mit Unterstützung Frankreichs, der EU und neuerdings auch der USA betreut. Für den Export werden Kaffee, Kakao, Kautschuk (zur Gummiherstellung), Palmöl und Zucker angebaut. Es werden etwa 25.000 Tonnen Zucker produziert, von denen der größte Teil im Land selbst bleibt. Der Anbau von Grundnahrungsmitteln dient vor allem dem Eigenbedarf, kann diesen jedoch nicht vollständig decken.

Gabuns Industrie besteht zum größten Teil aus Holz- und Papierindustrie sowie Textil- und Nahrungsmittelindustrie. Drei agrarindustrielle Betriebe wurden bereits privatisiert. Einen Teil der Energie bezieht das Land durch die Wasserkraft, hauptsächlich im Süden des Landes. 1997 wurde der gabunische Wasser- und Stromversorger SEEG in private Hand übergeben.

Der Staatshaushalt umfasste 2016 Ausgaben von umgerechnet 3,464 Mrd. US-Dollar, dem standen Einnahmen von umgerechnet 2,917 Mrd. US-Dollar gegenüber. Daraus ergibt sich ein Haushaltsdefizit in Höhe von 3,8 % des BIP.
Die nationale Staatsverschuldung betrug 2016 62,0 % des BIP.

2006 betrug der Anteil der Staatsausgaben (in % des BIP) folgender Bereiche:

Seit 2012 gibt Gabun jährlich die Sammler- und Anlagemünze Silberunze Afrikanischer Springbock zum Nennwert von 1.000 Francs CFA heraus.

Bei der Rangliste der Pressefreiheit 2017, welche von Reporter ohne Grenzen herausgegeben wird, belegte Gabun Platz 108 von 180 Ländern. Bei der Situation der Pressefreiheit im Land gibt es laut der Nichtregierungsorganisation „erkennbare Probleme“.

In Gabun befindet sich der Standort des ältesten panafrikanischen Rundfunksenders – Radio Africa No. 1. Der Sender ist auch für die Infrastruktur des Landes von großer Bedeutung, er ermöglicht den Schulbetrieb, unterstützt die Verwaltung der durch Regenwälder und schlechte Straßenverbindungen oft über Monate unzugänglichen Gebiete.

Das Internet wurde 2016 von 10,3 % der Bevölkerung genutzt.

Die beliebtesten Sportarten in Gabun sind Basketball und Fußball. Gabun trug 2012 (gemeinsam mit Äquatorialguinea) und 2017 die Fußball-Afrikameisterschaft aus. Eine der bekanntesten Personen Gabuns ist der Fußballspieler Pierre-Emerick Aubameyang, der zurzeit beim FC Arsenal unter Vertrag steht. 

Gabun nimmt seit 1972 an den Olympischen Spielen teil. Der einzige olympische Medaillenträger aus Gabun ist Anthony Obame, der bei den Olympischen Sommerspielen 2012 in London Silber im Taekwondo gewann.

Einige Kulturen Gabuns sind bekannt für ihre Schnitzkunst, besonders die Fang, die Kota, die Punu und die Tsogo. Aus dem Gebiet der Kota im Osten des Landes stammt ein spezieller Typ von Reliquiarfiguren, die den Urahn des jeweiligen Klans versinnbildlichen; sie bestehen zumeist aus einem Holzkern, aus dem ein ovales Gesicht, teilweise ohne Mund, skulpiert und dann mit Folie und Lamellen aus Edelmetallen (meist Kupferfolie) beschlagen wird. Über dem Kopf befindet sich oft ein mondsichelförmiger Aufsatz, der Hals ruht auf einem hochkant gestellten Rechteck.

Diese Reliquiarfiguren waren Vorbilder für den Maler Pablo Picasso. Er bediente sich des Öfteren dieser Figuren für seine Werke. So malte er 1907 eine Reihe von Variationen dieses Motivs.



</doc>
<doc id="10366" url="https://de.wikipedia.org/wiki?curid=10366" title="Geometrische Optik">
Geometrische Optik

Die geometrische Optik oder Strahlenoptik bedient sich des "Strahlenmodells" des Lichtes und behandelt damit auf einfache, rein geometrische Weise den Weg des Lichtes auf Linien.

Einem auf eine Linie begrenzten Lichtstrahl kommt keine physikalische Realität zu, und man kann ihn folglich auch nicht experimentell realisieren. Dennoch lässt sich mit Hilfe der Strahlenoptik die Funktion der optischen Abbildung, die die Hauptaufgabe der technischen Optik ist, oft mit ausreichender Genauigkeit beschreiben.

Beschränkt man die geometrische Optik auf Strahlen, die die optische Achse sehr flach schneiden, liegt die sogenannte paraxiale Optik vor. Dafür lassen sich geschlossene mathematische Ausdrücke für Abbildungsgleichungen finden. Man wendet diese Methode aber hauptsächlich nur dann an, wenn man sich einen schnellen grundsätzlichen Überblick verschaffen will, bevor man umfangreiche Ermittlungen genauer durchführt.

Die geometrische Optik lässt sich mathematisch als Grenzfall der Wellenoptik für verschwindend kleine Wellenlänge des Lichts auffassen. Sie versagt aber auch in diesem Fall, wenn die Verhältnisse für Strahlen mit hoher Energiedichte oder nahe an der Grenze zum Schatten (kein Licht) untersucht werden sollen.

Als allgemeinste Grundlage der Strahlenoptik lässt sich das Fermatsche Prinzip ansehen. Es führt auf die beiden ersten der folgenden Axiome.

Hauptanwendungsgebiet der Strahlenoptik ist die Behandlung der Abbildung durch optische Elemente, Geräte und Systeme, wie Linsen, Brillen, Objektive, Fernrohre und Mikroskope.

Auch das Raytracing-Verfahren in der 3D-Computergrafik beruht auf den Gesetzen der geometrischen Optik.

Die Luftspiegelungen durch eine heiße Luftschicht über sonnenbeschienenem Asphalt und andere Naturphänomene können auch durch Anwendung dieses Prinzips erklärt werden.

Effekte, die von der geometrischen Optik nicht beschrieben werden können, sind unter anderem:

Einige Methoden der geometrischen Optik, insbesondere die Matrizenoptik, übertragen sich jedoch auf das Konzept der Gaußstrahlen, welches die Effekte der Wellenoptik teilweise mit berücksichtigt.



</doc>
<doc id="10367" url="https://de.wikipedia.org/wiki?curid=10367" title="Jeremia">
Jeremia

Jeremia ( "Yirməyāhū", Jirmejahu oder "Yirməyā(h)", Jirmeja; dt. „Gott erhöht“ oder „JHWH gründet“) ist einer der drei großen Schriftpropheten des Tanach (hebräische Bibel) und damit des Alten Testaments. Das nach ihm benannte Buch gehört im jüdischen Bibelkanon zu den „hinteren“ Nevi’im und steht dort nach Jesaja und vor Ezechiel an zweiter Stelle. Seit dem Mittelalter wird das Buch in 52 Kapitel unterteilt. Traditionell gilt Jeremia auch als Verfasser der Klagelieder Jeremias.

Laut den Angaben zu Beginn des Jeremiabuches wurde der Prophet von Gott im 13. Regierungsjahr eines Königs Joschija (siehe ) berufen, was etwa dem Jahr 626 oder 627 v. Chr. entspricht. Die Datierung ist von den verwendeten Modellen abhängig. Es wird über sein Wirken zur Zeit der Könige Joschija, Joahas, Jojakim, Jojachin und Zedekia in Jerusalem berichtet, was vermutlich bis 585 v. Chr. dauerte. Er predigte dem Volk Israel Bekehrung und Umkehr zu JHWH und prophezeite jahrelang den Untergang Jerusalems und des Tempels, der im Jahr 586 v. Chr. durch den babylonischen König Nebukadnezar II tatsächlich eintrat.

Das Buch ist eine wichtige Quelle für die Geschichte des ausgehenden Königtums im Südreich Juda. Es zeichnet ein detailliertes Bild der damaligen politischen und sozialen Verhältnisse. Viele der darin erwähnten Völker des Nordens finden sich auch in assyrischen und griechischen Quellen (Aschkenas, Gomer, Minni, Ararat (Urarṭu), Meder und Perser). Piotrovski versuchte Jeremia auch für die Geschichte von Urarṭu heranzuziehen und setzte auf Grund von (Feldzug von Ararat, Minni und Aschkenas – gewöhnlich als Skythen gedeutet – gegen Babel) das Ende von Urarṭu 590 oder 585 an. Diese Interpretation wird jedoch überwiegend abgelehnt, die meisten Forscher gehen davon aus, dass das Reich bereits Ende des 7. Jh. v. Chr. sein Ende fand.

Der Verfasser des Buches Jeremia bezeichnet den Propheten als Sohn des Priesters Hilkija , der möglicherweise von Abjatar, dem von David nach Anatot (nach eine der Städte, die den Nachkommen des Priesters Aaron gegeben worden waren) verbannten Priester , abstammt. Ob dieser mit dem im 2. Buch der Könige genannten Priester Hilkija identisch ist, ist höchst zweifelhaft. Jeremia stammt aus Anatot, dessen Bewohner ihm das Auftreten als Prophet ausreden wollen .

Eine priesterliche Prägung der Botschaft Jeremias, wie etwa beim Propheten Ezechiel, ist nicht erkennbar. Auch seine Stellung gegenüber der religiösen Reform ( und ) durch König Joschija, die auf das Jahr 622 v. Chr. datiert wird und hauptsächlich den jüdischen Gottesdienst im Jerusalemer Tempel sowie die Wiedereinführung des Pessachfest betraf, bleibt völlig unklar, da Jeremiaworte aus den Jahren zwischen der Reform und dem Tod von Joschija nicht überliefert sind.

Im biblischen Jeremiabuch ist die letzte Nachricht seine Verschleppung nach Ägypten. Spätere nicht-kanonische Schriften erzählen von seinem Leben dort und seiner Steinigung ca. 580 v. Chr.

Verschiedene Teile des Buches von Jeremia lassen sich der Form nach klar unterscheiden. Zum einen handelt es sich um Prophetenworte Jeremias, zumeist formuliert aus der Perspektive Jeremias, davon sind einzelne Sprüche in Reimform, dann gibt es psalmenartige Abschnitte und zum anderen gibt es eingeschobene Erzählungen und Berichte über Jeremia und sein Auftreten, formuliert in der dritten Person.


Das erste Kapitel kann als Programmtext des gesamten Buches gelesen werden. Dieses Kapitel legt vielfältige Spuren ins Buch hinein:


Theologische und ethische Analysen gehen im Buch ineinander über, ebenso die Kritik. Ein Grundgedanke ist, dass – wenn Israel anderen Göttern folgt – JHWH gegen sein auserwähltes Volk prozessiert und mit dem Verlust des Landes droht.
"Šeqer" (Hebr. = Lug, Trug, Verlogenheit) gilt als Schlüsselwort: Nicht mehr das Recht JHWHs bestimmt eine auf Solidarität gründende Gemeinschaft, sondern Täuschung, Betrug und Gewinn prägen die Gesellschaft. Daher trifft die Kritik v. a. die Propheten, Priester und Könige.

In manchen Texten scheint das Gericht als unausweichlich, dann wieder gibt es doch konkrete Heilserwartungen – vermutlich verstärkt durch spätere Zusätze. Heil und Unheil lassen sich nicht immer säuberlich scheiden. Heil liegt darin, dass die Zeit des Unheils begrenzt ist, dass Gott auf Bestrafung verzichtet und Jerusalem zurückkehren darf zu JHWH.

Die "Konfessionen Jeremias" sind einzelne abschließende Abschnitte in den Kapiteln 11-20. Sie thematisieren die inneren und äußeren Konflikte des Propheten, sie sind im Stil von Klagepsalmen gehalten und unterscheiden sich der Form nach von den Prophetensprüchen.
Diese Konfessionen waren der Grund, dass die Klagelieder Jeremia zugeordnet wurden und führten auch zu dem Begriff Jeremiade.

Im Gesamtkontext des Buches wendet sich jedoch das Geschick Jeremias: In Kap. 37ff gehört Jeremia zu den Geretteten, während seine Gegner ihre Strafe erfahren. Deren Überlegenheit und Erfolg waren also nur vorläufig. Man könnte sagen, die Person und das Geschick Jeremias boten sich als „Folie“ für die Spannung zwischen realen Verhältnissen und Gerechtigkeit Gottes, die zwar noch aussteht, sich aber letztendlich durchsetzen wird. In späteren Schriften war es dann kein großer Schritt mehr in Richtung Apokalyptik. Die Verbindung von Gefährdung und Bewahrung eines Propheten gibt es in der Form nur bei Jeremia.

Das Jeremiabuch ist in zwei verschiedenen Fassungen überliefert. Die kurze Version des Jeremiabuches in der griechischen Septuaginta (LXX) weicht von der längeren Version im masoretischen Text (MT) in vielerlei Hinsicht ab. In den übereinstimmenden Passagen stellt die griechische Version offensichtlich eine getreue Übersetzung der hebräischen Vorlage dar. Insgesamt ist aber der hebräische Text um etwa ein Siebtel länger. Außerdem unterscheiden sich beide Versionen im Aufbau erheblich. So folgt der griechische Text dem „dreigliedrigen eschatologischen Schema“ (Unheilssprüche gegen Israel – Unheilssprüche gegen die Völker – Heilsansagen für Israel), während in der hebräischen Fassung die Völkersprüche (Kap. 46–51) nach den Heilsansagen für Israel folgen, die zudem in die Erzählungen über Jeremia eingebettet sind (siehe nebenstehende Tabelle).

Wie die Funde von Qumran nahelegen, geht die griechische Fassung auf eine vom masoretischen Text unterschiedene hebräische Vorlage zurück. Welche der beiden Fassungen die ältere ist, ist umstritten. Jedenfalls kann man von einer längeren parallelen Überlieferungsgeschichte ausgehen.

Als Verfasser gilt in der biblischen Tradition der gleichnamige Prophet, der etwa von 627 bis 587 v. Chr. in Jerusalem wirkte.

Die wissenschaftliche Diskussion des 20. Jahrhunderts war lange bestimmt vom Kommentar Bernhard Duhms (1901). Er sah den ältesten Bestandteil des Buches in den „Gedichten Jeremias“ in den Kapiteln 1 bis 25. Ein zweiter Block bestand seiner Meinung nach im „Buch Baruchs“ (Kapitel 26-45). Spätere Ergänzungen fänden sich in allen Buchteilen. Auf den historischen Jeremia seien nach Duhm nur etwa 280 Verse zurückzuführen, d. h. weniger als ein Viertel des Buches.

Einen anderen Weg schlug Sigmund Mowinckel (1914) ein. Er unterschied bei der Buchentstehung vier Quellen: Worte Jeremias, Erzählungen über Jeremia, stilistisch deuteronomistische Reden (z. B. c. 7 und 25) sowie die Heilsworte in Jer 30f. Allerdings ist der Charakter der Prosareden nicht quellenhaft, sondern redaktionell, d. h., sie setzen ihren Kontext bereits voraus, wie Winfried Thiel nachweisen konnte. Thiel unterschied daher lediglich zwischen jeremianischen Texten, einer deuteronomistischen Redaktion und nachdeuteronomistischen Ergänzungen.

Allerdings ist in den so genannten deuteronomistischen Texten zu unterscheiden zwischen sprachlichen und sachlichen Deuteronomismen. Die Entstehung des Jeremiabuches ist daher vermutlich weit komplexer vorzustellen, als es sich in diesen vereinfachenden Modellen darstellen lässt. Das Buch Jeremia ist durchzogen von Hinweisen auf eine bestehende Schriftkultur: Nicht nur Baruch trägt den Titel ‚Schreiber‘ (36,26), sondern der Titel ist auch sonst Funktionsbezeichnung (36,12; 37,15.20; 52,25). Von Tafel (17,3), Tinte (36,18) und Schreibermesser (36,23) ist die Rede. Jeremia schreibt einen Brief an die Exilierten in Kapitel 29,1. Die wörtlich zitierte Unheilsdrohung Michas (26,17f) und Anspielungen auf zahlreiche frühere Propheten setzen schriftliche Dokumentation dieser früher entstandenen Prophetensprüche voraus.










</doc>
<doc id="10368" url="https://de.wikipedia.org/wiki?curid=10368" title="Klagelieder Jeremias">
Klagelieder Jeremias

Die Klagelieder Jeremias, , in der Septuaginta θρῆνοι "Thrē̂noi", in der Vulgata "Lamentationes", lateinisch auch "Thrēnī" genannt, bisweilen auch als "Jeremiaden" bezeichnet (abgekürzt "Klgl"); sind ein Buch des Tanach, das aus fünf Gedichten besteht. Dort sind sie im dritten Teil des Tanach, nach Tora (Weisung) und Nevi’im (Propheten), unter den Festrollen (Megillot) eingeordnet, im Alten Testament der Bibel sind sie in der Ordnung vorverlegt, schon nach dem Propheten Jeremia.

In den Klageliedern wird die Zerstörung Jerusalems und des Tempels von 586 v. Chr. beklagt. Die Fakten des Geschehens sind in und beschrieben. Von diesem Inhalt her bietet sich eine Entstehung zwischen 586 und 530 an. Die tiefe Erschütterung in den ersten vier Kapiteln lässt vermuten, dass sie aus dem unmittelbaren Erleben heraus kurz nach dem Fall Jerusalems geschrieben wurden. Kapitel 5 betont mehr das Leid des Exils.

Die Klagelieder sind anonym, sie enthalten nichts, was auf den Verfasser schließen lässt. Nach jüdischer Tradition aus vorchristlicher Zeit (Targum, Septuaginta) gilt der Prophet Jeremia als Verfasser. In der Sekundärliteratur gehen die Meinungen darüber auseinander. Im Hauptstrom der heutigen theologischen Welt wird Jeremia als Verfasser kaum noch vertreten. In Stil und Ausdrucksweise gibt es jedoch Ähnlichkeiten zwischen dem prophetischen Buch Jeremia und den Klageliedern. Es ist anzunehmen, dass der Verfasser Augenzeuge der Zerstörung Jerusalems im Jahr 586 v. Chr. war und damit ein Zeitgenosse Jeremias. Einige Autoren gehen davon aus, dass Jeremia nach dem Exil eine Zeit in Juda blieb, um sich um die Zurückgebliebenen zu kümmern. In dieser Zeit seien die Klagelieder entstanden.

Die Klagelieder sind Beispiele von hochstehender hebräischer Dichtkunst. Sie sind im Versmaß der jüdischen Totenklage ("Qina") abgefasst, die ersten vier als Abecedarius (alphabetisches Lied). Dieses Akrostichon hat nicht nur den praktischen Zweck der Gedächtnisstütze, sondern ist auch Ausdruck der Grenzenlosigkeit der alles einschließenden Trauer – vergleiche im Deutschen den Ausdruck „von A bis Z“ für „alles“. Das Akrostichon beweist, dass die Lieder von Anfang an schriftliche Literatur waren und nicht eine erst später niedergeschriebene mündliche Überlieferung darstellen.

Die ersten beiden Lieder enthalten je 22 Verse mit drei Zeilen. Die ersten Worte jedes Verses beginnen der Reihe nach mit den 22 Buchstaben des hebräischen Alphabets. Das vierte Lied ist ebenso gestaltet, jedoch kommen auf jeden Vers zwei Zeilen. Das dritte Lied hat 66 Verse, unterteilt in 22 Einheiten zu je drei Versen. Jeder dieser Verse beginnt mit dem entsprechenden gleichen Buchstaben. Eine Besonderheit besteht darin, dass im zweiten bis vierten Lied der Pe-Vers entgegen der heute üblichen alphabetischen Reihenfolge vor dem Ajin-Vers steht. Diese Folge ist jedoch ebenfalls in alten Alphabettafeln belegt. Das fünfte Lied hat 22 Verse zu je einer Zeile, aber ohne spezifische Buchstabenfolge. Die Klagelieder verwenden eine reiche Zahl von Bildern, um das Leid und die Trauer plastisch darzustellen.

Auffälligstes Merkmal ist die Personifikation Jerusalems als „Tochter Zion“, klagende Mutter, vergewaltigte und entehrte Geliebte und verlassene Witwe. Diese Elemente weisen darauf hin, dass möglicherweise eine Gattung altorientalischer "Stadtklage" Vorbild für die Abfassung dieser Texte war. 
Es finden sich folgende Klageelemente:

Orthodoxe Juden lesen die Klagelieder wöchentlich an der Klagemauer in Jerusalem. Tischa beAv ist ein jährlicher jüdischer Gedenk- und Fastentag zur Erinnerung an die Zerstörung des Jerusalemer Tempels (Bajith Rishon) durch die Babylonier und an die Zerstörung des zweiten Tempels in Jerusalem (Bajith Sheni) durch die Römer, an dem die Klagelieder rezitiert werden. Die Klagelieder gehören zusammen mit Ijob und Jeremia zu den einzigen Teilen der Schrift, die fromme Juden in der Trauerzeit nach dem Tod eines Angehörigen lesen.

In der Liturgie der römisch-katholischen Kirche werden die Klagelieder im Triduum Sacrum der Karwoche in den frühmorgendlichen Karmetten als Lesungen gesungen. Allioli gibt in seiner Einführung zu den Klageliedern verschiedene Motive und Absichten der Kirche für diese Wahl an . In der Karmette des römischen Stundenbuches werden die Klagelieder als erste Lesung in der Karwoche vorgetragen, das fünfte Klagelied, die Oratio Jeremiae, wird dort außerdem als drittes Canticum in der Matutin der sechs Fastensonntage, den Karfreitag und den Karsamstag gesungen. Der Gesang der Klagelieder wird mit "Incipit Lamentatione Jeremiae Prophetae" eingeleitet und jeweils mit dem lateinischen Ruf "Jerusalem, Jerusalem, convertere ad Dominum Deum tuum" („Jerusalem, Jerusalem, bekehre dich zu deinem Herrn und Gott“) abgeschlossen.
Es gibt in der Geschichte der Kirchenmusik eine große Anzahl an Vertonungen, entweder nur der Klagelieder oder auch der Responsorien. Zu den letzteren gehören Werke von Carlo Gesualdo und Marc-Antoine Charpentier. Der Text der Klagelieder wird unterschiedlich auf die jeweiligen Tage bzw. Nokturnen verteilt:

In der gegenwärtigen evangelischen Perikopenordnung ist lediglich der Abschnitt Klagelieder 3,22-26.31-32 vertreten und als Lesung aus dem Alten Testament (Predigtreihe III) dem 16. Sonntag nach Trinitatis zugeordnet. Matthias Weckmann schuf im August 1663 ein Geistliches Konzert aus Versen des ersten Kapitels mit dem Titel "Wie liegt die Stadt so wüste" zum 10. Sonntag nach Trinitatis, an dem der Zerstörung der Stadt Jerusalem gedacht wurde. Rudolf Mauersberger vertonte die Verse 1,1.4.9.13; 2,15; 5,17.20-21 in seiner Motette "Wie liegt die Stadt so wüst" aus dem Zyklus Dresden am Karsamstag 1945 als Reaktion auf die Zerstörung Dresdens. Klaus Miehling schrieb einen vollständigen Zyklus von neun Lamentationen (op. 15, 1985) sowie Einzelstücke: für Chor und Streicher (op. 20, 1987), Sopran und Blockflötenquartett (op. 78, 1999), vier Stimmen ATTB (op. 84, 2001).



</doc>
<doc id="10369" url="https://de.wikipedia.org/wiki?curid=10369" title="Lichtquelle">
Lichtquelle

Eine Lichtquelle ist der Ort, von dem Licht ausgeht. Primäre globale Lichtquelle ist die Sonne.

Charakteristisches Merkmal aller Lichtquellen ist die Wellenlängenverteilung nach Frequenz und Intensität.

Die Vielfalt von Lichtquellen lässt sich nach weiteren Kriterien einteilen: nach den Merkmalen messbarer Strahlung, nach der Geometrie des Strahlengangs oder nach einzelnen physikalischen Kennzeichen wie der Quantenenergie. Nach der räumlichen Ausdehnung der strahlenden Quelle unterscheiden sich Punktlichtquellen und diffuse Lichtquellen, nach der jeweiligen Abstrahlcharakteristik als rundum oder gerichtet strahlend.

Physikalisch werden "natürliche" lokal begrenzte Lichtquellen (Glühwürmchen, Polarlicht, Blitz) und vom Menschen geschaffene "künstliche" technische Lichtquellen (Öllampe, Leuchtmittel, Laser, Bildröhre, Leuchtdiode) unterschieden.

Eine selbstleuchtende Lichtquelle, auch als „aktive Lichtquelle“ oder Lichtquelle 1. Ordnung erzeugt das abgestrahlte Licht in der Lichtquelle. Zu diesen Selbstleuchtern gehören die Sonne, Sterne, Glühwürmchen, Feuer oder Lampen.

Alle anderen Körper, die nicht selbst leuchten, werden als „passive Lichtquellen“, auch Lichtquellen 2. oder höherer Ordnung, bezeichnet. Sie können erst durch Beleuchtung (Anstrahlung) mit anderen Lichtquellen Licht

Thermische Strahler liefern eine kontinuierliche Strahlung, mit steigender Temperatur verschiebt sich das Strahlungs-Maximum vom infraroten über rotes, hin zu blauem und ultraviolettem Licht (siehe Plancksches Strahlungsgesetz). Je heißer ein Strahler ist, desto blauer erscheint er. Dabei spielt die Energieform, die in Wärme umgesetzt wird und zur Strahlung führt, keine Rolle.

Im Gegensatz zum thermischen Strahler können Moleküle und Atome durch Zufuhr von Energie unterschiedlicher Provenienz in einen angeregten Zustand versetzt werden. Geht dann der angeregt wieder in den Grundzustand (Rekombination) so wird die Differenz der Energie wieder freigesetzt. Für die praktische Nutzung ist es von besonderer Bedeutung, dass diese als Strahlung mit Wellenlängen im sichtbaren Spektralbereich abgegeben wird. Der optische Anteil der so entstehenden Strahlung ist Lumineszenz. Bei der Lumineszenz werden zwei Formen nach der Zeit zwischen Anregung und Abstrahlung unterschieden. Fluoreszenz tritt nur während der Anregung auf, Phosphoreszenz dagegen auch, nachdem die äußere Anregung bereits erloschen ist. Beides sind Formen der Lumineszenz. Die Phosphoreszenz (Nachleuchten nach dem Beleuchten) wird bei Sicherheitsschildern, Zifferblättern oder als Dekoration verwendet. Im Gegensatz zum kontinuierlichen Spektrum des thermischen Strahlers entstehen auf Grund der Prozessabläufe diskontinuierliche Spektrallinien oder -banden. Gasentladungen in verdünnten Gasen zeigen sehr scharfe Spektrallinien, bei Gasen unter Druck (Hochdruck-Metalldampflampen) verbreitern sich die Linien.

Die anregende Energie kann auf unterschiedlichen Energieformen zur Lichtquelle führen. Bei Glühwürmchen oder dem Leuchtstab führt die chemische Reaktion zur Reaktion und der Lichtabgabe. Leuchtdioden, Gasentladungslampen und EL-Folien erhalten mittels Gasentladung oder Elektrolumineszenz die Funktion als Lichtquelle durch elektrischen Strom. Durch Elektronenbeschuss, auch Betastrahlung aus einem fluoreszierenden Leuchtstoff, werden Bildröhren, Fluoreszenzanzeigen zum Leuchten angeregt, hier sind auch Kathodolumineszenz und Tritiumlicht zu nennen.

Eine andere Kategorie ist die Wandlung von (vorzugsweise) UV-Licht durch Fluoreszenz mittels Leuchtstoff en in sichtbares Licht, diese Vorgänge der Umwandlung von kürzeren (energiereicheren) Wellenlänge zum (längerwelligen) sichtbaren Licht sind grundlegend für Leuchtstoffröhren und bei den weißen Leuchtdioden. Kürzerwellige Strahlung zur Erzeugung sichtbaren Lichtes ist bei Leuchtschirmen älterer Geräte die Röntgenstrahlung und die Gammastrahlung für „radioaktive“ Leuchtfarbe. Synchrotronstrahlung und Tscherenkowstrahlung haben dagegen keine Bedeutung als künstliche Lichtquellen.

Laser werden durch elektrischen Strom, Strahlung kürzerer Wellenlängen oder chemische Energie angeregt und werden nur selten als Lichtquelle verwendet. Beispiele für den praktischen Einsatz von Lasern als Lichtquelle sind Infrarot-Zielbeleuchtung, Blendlaser oder rote Laserpointer. Das Licht grüner Laserpointer wird durch Frequenzverdopplung aus einem infraroten Laserstrahl erzeugt.

Die in den 2010er Jahren langsam aussterbende Glühlampe ist mit rund 10 lm/W der Halogenlampe mit etwa 20 lm/W unterlegen. Als einziges bezüglich der Lichtausbeute noch entwicklungsfähiges haushaltsübliches Leuchtmittel überholt die LED im gleichen Jahrzehnt bei etwa 100 lm/W die (Kompakt-) Leuchtstofflampe.

Neben der Lichtausbeute ist auch bei vielen weißen Strahlern der Farbwiedergabeindex von Bedeutung.

 


</doc>
<doc id="10371" url="https://de.wikipedia.org/wiki?curid=10371" title="Greenwich Mean Time">
Greenwich Mean Time

Die Greenwich Mean Time war von 1884 bis 1928 Weltzeit, in dieser Funktion wurde sie 1972 von der "Koordinierten Weltzeit" (UTC) abgelöst.

Der Ausdruck Greenwich Mean Time (GMT) wird heute eigentlich nur noch in Großbritannien und Westafrika offiziell für die Zeitzone "Westeuropäische Zeit" (WEZ/WET, UTC+0) verwendet. Seit 1925 wird die Bezeichnung von unterschiedlichen Stellen für verschiedene Zeitnormale genutzt. Daher wird empfohlen, wenn man genaue Zeiterfassung erreichen möchte, diese Bezeichnung nicht zu verwenden.

Im Mittel überquert die Sonne um 12:00 GMT den Mittagskreis (Meridiandurchgang) von Greenwich und hat dabei annähernd ihren höchsten Stand am Himmel (obere Kulmination). Aufgrund der ungleichmäßigen Geschwindigkeit der Erde auf ihrer elliptischen Umlaufbahn und der Neigung der Erdachse weicht der tatsächliche Mittagsdurchgang um bis zu 16 Minuten davon ab (siehe Zeitgleichung), was sich jedoch über das Jahr ausgleicht. GMT folgt also einer gedachten "mittleren Sonne", die sich mit konstanter Geschwindigkeit im Laufe eines Jahres entlang des Äquators (statt wie in Wirklichkeit entlang der Ekliptik) bewegt.

Eine genauere Methode der astronomischen Zeitmessung ist es, die Zeitintervalle zwischen den Meridiandurchgängen eines Fixsterns zu messen (siderische Zeit).

Zum Zwecke der astronomischen Navigation auf See wurde von Nevil Maskelyne im Jahre 1767 erstmals der Nautical Almanac veröffentlicht, dessen astronomische Tabellen für die wahre Ortszeit des Observatoriums Greenwich ausgelegt waren. Navigatoren, die ihre astronomischen Beobachtungen mit Hilfe dieses Jahrbuches auswerteten, erhielten automatisch eine auf den Meridian von Greenwich bezogene Position, während es früher üblich gewesen war, die geographische Länge bezüglich des Ausgangs- oder Zielpunktes anzugeben. Seekarten begannen daher auch zunehmend, Greenwich als Standardmeridian für ihre Koordinatennetze zu übernehmen. Als die Internationale Meridiankonferenz im Jahre 1884 einen Nullmeridian international verbindlich festlegte, fiel die Wahl auf den bereits überwiegend gebräuchlichen Greenwich-Meridian. Für Zwecke, die einheitliche Zeitangaben für unterschiedliche Orte erfordern, sei die mittlere Ortszeit von Greenwich zu verwenden. Diese Zeit war 1880 unter dem Namen "Greenwich Mean Time" als gesetzliche Standardzeit in Großbritannien eingeführt worden.

Zur weltweiten Koordination der Zeitmessung wurde das Bureau International de l’Heure (BIH) in Paris gegründet, das 1920 von der neu gegründeten International Astronomical Union (IAU) übernommen wurde. Bald darauf änderte die IAU die Definition von GMT. Bisher war es bei den hauptsächlich des Nachts arbeitenden Astronomen üblich gewesen, den Tag mittags beginnen zu lassen, um nicht ständig um Mitternacht, mitten unter der Arbeit, das Datum wechseln zu müssen ("astronomischer Tag", so wie das bei der Julianischen Datumsskala der Astronomie noch heute üblich ist). Entsprechend war GMT ursprünglich „die mittlere Sonnenzeit auf dem Meridian von Greenwich, gerechnet ab dem mittleren Mittag“. Die IAU führte mit dem 1. Januar 1925 eine neue Zeitskala ein, deren Tage bürgerlichem Brauch folgend um Mitternacht begannen und nannte die neue Skala wieder GMT, während die bisherige Skala in "Greenwich Mean Astronomical Time (GMAT)" umbenannt wurde. Die daraus folgende Verwirrung bewog die IAU, im Jahre 1928 die neue GMT in Universal Time (UT) umzubenennen. UT war damit (und ist im Wesentlichen bis heute) die mittlere Sonnenzeit auf dem Meridian von Greenwich, gerechnet ab Mitternacht.

Da UT von der Erdrotation abgeleitet wird, welche aber kurzfristigen Fluktuationen und einer langfristigen Verlangsamung unterliegt, ist sie keine streng gleichmäßig verlaufende Zeitskala und für viele wissenschaftliche und manche technische Zwecke nicht brauchbar. Daher wurde 1952 zunächst die von den gleichmäßigeren Planetenbewegungen abgeleitete "Ephemeridenzeit" (ET) eingeführt, welche am 1. Januar 1972 wiederum von der Koordinierten Weltzeit (UTC) abgelöst wurde. UTC beruht auf der strikt gleichmäßigen von Atomuhren erzeugten Atomsekunde; Schaltsekunden sorgen gegebenenfalls dafür, dass UTC nicht mehr als 0,9 s von der unregelmäßigen UT abweicht.

Heutzutage wird UTC im Vereinigten Königreich und in Westafrika immer noch als GMT bezeichnet, obwohl es von der eigentlichen GMT (der heutigen UT) um bis zu 0,9 s abweichen kann. Aufgrund dieser Begriffsverwirrung empfiehlt es sich, die Bezeichnung "Greenwich Mean Time" abseits dieser Regionalbezeichnungen der örtlichen Zonenzeit nicht mehr zu verwenden.


In Greenwich selbst gilt in sieben von zwölf Monaten die Britische Sommerzeit, außerdem wurde der Nullmeridian beim Royal Greenwich Observatory 1984 um etwa 100 Meter verschoben (WGS84-Koordinaten).

In der Britischen Seefahrt war der Ausdruck "Greenwich Civil Time" (GCT) vom "HM Nautical Almanac Office" vorgeschrieben, was aber nach 1924/25 offenließ, ob nautisch Uhrzeitwechsel ‚astronomisch‘ zu Mittag oder ‚bürgerlich‘ zu Mitternacht vorzunehmen sei, das "United States Naval Observatory" verwendete den Ausdruck "Greenwich Civil Time" für die neue Regelung, GMT für den Mittagswechsel. Erst 1952 übernahmen die britische und US-Marine die allgemeine Weltzeit.


</doc>
<doc id="10374" url="https://de.wikipedia.org/wiki?curid=10374" title="Indischer Ozean">
Indischer Ozean

Der Indische Ozean ist mit 74,9 Millionen km² Fläche (ca. 14,7 % der Erdoberfläche) der drittgrößte Ozean der Erde. Er fasst ein Volumen von ca. 291,9 Mio km³, die maximale Meerestiefe beträgt 8.047 Meter. Der Indische Ozean liegt zum größten Teil auf der Südhalbkugel. Er grenzt an die Kontinente Afrika, Asien und Australien sowie an den Atlantischen Ozean, den Pazifischen Ozean und entlang des südlichen 30°-Breitenkreises an den Antarktischen Ozean.

Die analog zu "Atlantik" und "Pazifik" gebildete Kurzbezeichnung Indik (aus ) wird selten verwendet.

Innerhalb des Indischen Ozeans bzw. auf dessen Meeresboden befinden sich niedrigere Schwellen und ein hoher, langgestreckter mittelozeanischer Rücken: der Zentralindische Rücken, der sich ungefähr in der Mitte von Nord nach Süd durch den Ozean zieht.

Weiterhin befinden sich im Indischen Ozean auch Tiefseebecken sowie Tiefseerinnen und verschiedene Meerestiefs. Zu den Tiefseerinnen gehört der bis 7.455 m tiefe Sundagraben. Das Diamantinatief ist mit 8.047 m unter dem Meeresspiegel die tiefste Stelle des Indischen Ozeans.

Drei Kontinentalplatten haben einen größeren Anteil am Meeresboden des Indischen Ozeans: die Afrikanische Platte im Westen, die Australische Platte im Osten und die Antarktische Platte im Süden. Dazu kommen im Norden Teile der Arabischen Platte, der Indischen Platte und der Eurasischen Platte (siehe dazu die Karte bei Plattentektonik).

Zu den Randmeeren, Golfen und Meerengen des Indischen Ozeans zählen (im Uhrzeigersinn von Westen über Norden nach Osten und Südosten):

Vom Süden nach Norden sind das:

Südafrika, Mosambik, Tansania, Kenia, Somalia, Dschibuti, Eritrea, Sudan und Ägypten.

Im Uhrzeigersinn von Westen über Norden nach Osten und Südosten:

Saudi-Arabien, Jemen, Oman, Vereinigte Arabische Emirate, Katar, Kuwait, Irak, Iran, Pakistan, Indien, Bangladesch, Myanmar, Thailand, Malaysia, Indonesien und Osttimor.

Israel und Jordanien liegen jeweils mit einem kleinen Küstenabschnitt am Golf von Akaba und sind indirekt über das Rote Meer mit dem Indischen Ozean verbunden. Sie können deshalb ebenfalls zu den Anrainerstaaten gerechnet werden.

Australien

 

Innerhalb des Indischen Ozeans liegen die politisch eigenständigen Inselstaaten Indonesien, Madagaskar und Sri Lanka. Eigenständige Inselgruppen sind die Komoren (mit dem französischen Überseedepartement Mayotte), die Seychellen, und die Malediven. Zum Inselstaat Mauritius gehören neben der Hauptinsel, der Insel Rodrigues und den beiden Agalega-Inseln weitere, jedoch unbewohnte Inseln wie die Cargados-Carajos-Inseln. Die Inselgruppe der Maskarenen umfasst die meisten Inseln von Mauritius (nicht die Agalegas) sowie das französische Überseedepartement La Réunion.

Die Inselgruppe Sokotra gehört zur Republik Jemen. Das Sansibar-Archipel gehört zu Tansania. Das indische Unionsterritorium Andamanen und Nikobaren bilden die gleichnamigen Inselgruppen Andamanen und Nikobaren. Die Inselgruppen Lakkadiven und Amindiven sowie die Insel Minicoy bilden zusammen das indische Unionsterritorium Lakshadweep.

Der Chagos-Archipel mit der Hauptinsel Diego Garcia ist das letzte britische Territorium im Indischen Ozean. Die Insel Ko Phuket gehört zu Thailand.

Zu Australien gehören die Weihnachtsinsel, die Kokosinseln, Heard und die McDonaldinseln und die Ashmore- und Cartier-Inseln.

Weitere zum Indischen Ozean gehörende Inseln sind die zu den Französischen Süd- und Antarktisgebieten zählenden Kerguelen.



Verheerende Auswirkungen hatte ein Erdbeben im Indischen Ozean, das sich am 26. Dezember 2004 ereignete. Es hatte die Stärke von 9,2 auf der Richterskala. Das Epizentrum lag im Meer, nahe der Nordwestspitze von Sumatra. Der von dem Beben ausgelöste riesige Tsunami verursachte mehr als 300.000 Todesfälle. Hauptsächlich betroffene Länder waren Indonesien, Thailand, Indien und Sri Lanka. Die Wellen erreichten aber sogar noch das 5.200 km entfernte Somalia.





</doc>
<doc id="10375" url="https://de.wikipedia.org/wiki?curid=10375" title="Ozean">
Ozean

Als Ozean (Plural die Ozeane, von „der die Erdscheibe umfließende Weltstrom“, personifiziert als antiker Gott Okeanos) bezeichnet man die größten Meere der Erde. Synonym und als Übertragung wird im Deutschen auch die Bezeichnung Weltmeer verwandt.

Verallgemeinert werden auch große Wassermengen auf anderen Himmelskörpern „Ozeane“ genannt.

Insgesamt sind 71 Prozent der Erdoberfläche von Meeren (den Ozeanen und deren Nebenmeeren) bedeckt. Sie konzentrieren sich auf der Wasserhemisphäre, deren Zentrum im riesigen Pazifik nahe Neuseeland liegt. Auf der gegenüberliegenden Landhemisphäre befinden sich nur der Atlantik, der Arktische Ozean und Teile des Südlichen Ozeans sowie des Indischen Ozeans.

Die fünf Ozeane der Erde sind:


Im Unterschied zur Fachsprache unterscheidet man in der Alltagssprache meist nur zwischen drei Ozeanen: "Atlantischer", "Pazifischer " und "Indischer Ozean". Bei dieser Sichtweise ohne die Polarmeere wird der Arktische Ozean als Teil des Atlantiks betrachtet und der Südliche oder Antarktische Ozean zum Atlantik, Pazifik und Indik gezählt.

Historisch spricht man von den „Sieben Weltmeeren“, die neben Pazifik, Atlantik und Indik auch das Karibische Meer, das Mittelmeer, das Gelbe Meer und die Nordsee umfassen (oder auch andere Meere, die als Nebenmeere der Ozeane gelten, wie das Schwarze Meer oder die Ostsee).

Eine alternative Betrachtung unterteilt die zwei größten Ozeane der Erde entsprechend ihrer Zugehörigkeit zur Nord- bzw. Südhalbkugel in Nord- und Südatlantik sowie Nord- und Südpazifik, betrachtet jeweils auch das Nord- und das Südpolarmeer als Ozean und zählt zusammen mit dem Indik sieben Ozeane. Dies korrespondiert mit einer Zählweise von sieben Kontinenten (Nordamerika, Südamerika, Europa, Afrika, Asien, Ozeanien (Australien und Ozeanien), Antarktika).

Die einzelnen Ozeane, die zwischen den Kontinenten liegen, unterscheiden sich unter anderem durch Volumen, Salzgehalt, ein eigenes Gezeiten-System, Wellen (Seegang) und Meeresströmungen sowie erdgeschichtlich von den anderen Teilen des Weltmeeres.

Innerhalb der Ozeane und ihren Nebenmeeren bzw. auf dem Ozeanboden befinden sich teils sehr hohe und langgestreckte mittelozeanische Rücken, teils sehr viele und niedrigere Schwellen, große und kleine Tiefseebecken, Tiefseerinnen und verschiedene Meerestiefs sowie im Pazifik der Pazifische Feuerring. Außerdem ragen zahlreiche Inseln, Inselgruppen und Archipele aus diesen Meeren heraus und Halbinseln in diese hinein. Nord- und Südpolarmeer sind teils oder ganz von Pack- und Treibeis bedeckt.

Der Boden eines Ozeans ist die Oberseite eines Stücks ozeanischer Erdkruste. Seine Gestalt wird durch die Theorie der Plattentektonik erklärt. Danach entsteht neuer Ozeanboden an den mittelozeanischen Rücken und fließt weg bis er in einer Tiefseerinne (Subduktionszonen) ins Erdinnere eintaucht. Dies bedeutet, dass ein Ozean größer oder kleiner werden, neu entstehen und auch verschwinden kann. So wird angenommen, dass der Atlantische Ozean etwa 150 Millionen Jahre alt ist. Frühere Ozeane sind beispielsweise der Mirovia, der Panthalassa, der Rheische Ozean, der Iapetus oder die Tethys mit dem „europäischen“ Randmeer Paratethys.

Der Küsten­verlauf hängt nicht nur von der Form und Lage der Kontinente ab, sondern auch vom Volumen des Meerwassers. So gibt es bei niedrigen Temperaturen weniger Meerwasser, da große Wassermengen als Eisschilde und Gletscher auf den Kontinenten gespeichert sind, bei steigenden Temperaturen hingegen kommt es aufgrund der Wärmeausdehnung und dem Abschmelzen der Eismassen zu einem Meeresspiegelanstieg (Transgression). Weitere Faktoren sind Hebungen und Senkungen des Ozeanbodens aufgrund geologischer Ereignisse.

Das Volumen der Ozeane wurde 2009 auf 1,33·10 km geschätzt, entsprechend einer durchschnittlichen Tiefe von 3680 m – exakt vermessen waren nicht einmal 10 %.

Der Wasserkörper eines Ozeans ist nicht einheitlich, sondern ändert sich mit der Tiefe. Es gibt große, stabile Wasserbewegungen, die Meeresströmungen. Am bedeutendsten ist das sogenannte Globale Förderband, eine Kombination von Meeresströmungen, die vier der fünf Ozeane miteinander verbinden und bei dem Oberflächenströmungen und Tiefenströmungen einen globalen Wasserkreislauf bilden. Dabei kann es zur Bildung von großen Wasserwirbeln oder Eddies in einer Tiefe von mehreren 1000 m kommen. Auch Mittelozeanische Rücken können zur Verwirbelung führen. Große Wasserwirbel von 50 km bis 200 km Durchmesser, die sich mehrere Wochen halten und kaltes, nährstoffreiches Tiefenwasser an die Meeresoberfläche befördern, werden ebenfalls beobachtet. Ebenfalls kann es sogenannte interne Wellen im Wasserkörper geben. Die größten untermeerischen Wellen von mehr als 200 Metern Höhe wurden in der 320 km breiten Luzonstraße im südchinesischen Meer gemessen. In dieser Meerenge staut eine Tiefenströmung vor Unterseeklippen große Mengen von schwerem, kaltem Tiefenwasser, das irgendwann überschwappt und anschließend wieder auf die alte Tiefe absackt, wodurch eine interne Welle ausgelöst wird. Derartige interne Wellen können tausende von Kilometern im Ozean wandern.

An der Meeresoberfläche zeigen sich Wasserwellen. Es können vom Wind erzeugte unregelmäßige Wasserbewegungen sein, die durch eine Seegangs­skala quantifizierbar sind. Einzelne Wellen oder Wellengruppen, die sogenannten „Monsterwellen“, sind besonders gefährliche Wellen, die durch Überlagerung mehrerer Wellen entstehen und dabei Höhen von mehr als 25 m erreichen können. Die Tsunamis sind durch Seebeben und Vulkanausbrüche verursachte Wellen, die sich erst in Küstennähe zu gefährlichen Höhen auftürmen.

Die im Verlaufe des Tages durch die Gezeiten verursachten Meeresspiegelschwankungen sind dagegen regelmäßig und werden in ihrer Ausprägung durch die jeweilige geometrische Form der Küsten beeinflusst.

Der Wind erzeugt im Ozean einen Wassertransport. Unter Berücksichtigung der Corioliskraft kommt es in den oberen Wasserschichten (bis etwa 50 m) zu einer Korkenzieherströmung.

"Siehe dazu: Halokline, Thermokline, Chemokline, Pyknokline, Salinität sowie Versauerung der Meere"

Durch Serpentinisierung werden pro Jahr 60 Kubikkilometer Meerwasser chemisch im Ozeanboden gebunden. Hinzu kommt noch die Sättigung der Sedimente am Meeresboden mit Wasser. In den Subduktionszonen wird dieses Wasser wieder frei.

Der Sauerstoffgehalt des Meerwassers nahe der Meeresoberfläche ist bestimmt durch den Übergang von Sauerstoff aus der Luft ins Wasser und der biologischen Produktion von Sauerstoff aus Kohlenstoffdioxid (CO) durch das marine Phytoplankton. Deshalb kann es besonders in den Tropen zeitweise zur Übersättigung (Sauerstoffsättigung > 100 Prozent) des Oberflächenwassers kommen, so dass Sauerstoff verstärkt in die Luft abgegeben wird. Das Phytoplankton verbraucht allerdings in der Dunkelheit selbst einen Teil des erzeugten Sauerstoffs.

Mit zunehmender Wassertiefe und der damit verbundenen Abnahme des Sonnenlichtes nimmt die Sauerstoffsättigung des Meerwassers ab. Neben dem Veratmen des Sauerstoffs durch das Zooplankton und einen Teil des Bakterioplanktons trägt auch der zunehmende biologische Abbau von Biomasse zur Verringerung des Sauerstoffgehaltes bei. Im Ozean kommt es nicht zum Umkippen des Tiefseewassers, da in der Labradorsee, in der Grönlandsee und im Weddell-Meer sauerstoffreiches Oberflächenwasser entsteht, das in die Tiefsee herabsinkt und über die Tiefenströmung des Globalen Förderbandes weltweit verteilt wird. Die Sauerstoffverteilung in der Tiefsee ist nicht gleichmäßig; es existieren sogenannte Sauerstoff-Minimum-Zonen, wo es beispielsweise zur anaeroben Ammoniak-Oxidation und zur Denitrifikation kommt (durch anaerobe Atmung von Bakterien entsteht molekularer Stickstoff, der aus dem Wasser in die Luft entweicht). Diese Gebiete finden sich häufig in den Tropen, so gibt es im Arabischen Meer eine bedeutende Sauerstoff-Minimum-Zone in einer Tiefe von 200 m bis 1150 m.

Der Sauerstoffgehalt der Meere weltweit hat laut Forschern des Geomar Helmholtz-Zentrums für Ozeanforschung Kiel seit 1960 um ca. 2 % abgenommen, mit großen Folgen z. B. für Fische oder andere Organismen in bereits sauerstoffarmen Meeresregionen. Dafür verantwortlich seien steigende Wassertemperaturen, da wärmeres Oberflächenwasser weniger Sauerstoff aufnehme als kälteres Wasser und außerdem wärmeres Wasser die Temperaturschichtung des Meerwassers manifestiere, sodass dessen Umwälzung reduziert und damit weniger Sauerstoff von der Meeresoberfläche in große Meerestiefeen transportiert werde.

Für das Ökosystem Ozean ist das mit zunehmender Tiefe abnehmende Sonnenlicht von großer Bedeutung. Im obersten, vom Sonnenlicht erfüllten Teil des Ozeans, der Euphotischen Zone, nutzen Pflanzen die Photosynthese zur Aufnahme von Energie. Es schließt sich darunter die Dysphotische Zone an, wo Sonnenlicht nur noch zum Sehen ausreichend vorhanden ist. In der darunter liegenden Schicht, der Aphotischen Zone, ist kein Sonnenlicht mehr vorhanden.

Ein weiteres wichtiges Kennzeichen der Ozeane ist, dass sich das Meereswasser bei unterschiedlichen Tiefen chemisch unterschiedlich verhält. Meereslebewesen, wie beispielsweise Muscheln, Korallen, Kalkalgen und Kieselalgen nutzen Calciumcarbonat und Siliciumdioxid durch Biomineralisation zum Bau von Schalen und Skeletten. Diese Biominerale können allerdings chemisch durch das Meerwasser abgebaut werden. So gibt es für die Calciumcarbonate Aragonit und Calcit in den Ozeanen eine untere Tiefe, ab der sie sich auflösen, die Calcit- und Aragonit-Kompensationstiefe.

Der Tiefenverlauf eines Ozeans wird in mehrere Stufen unterteilt. Er beginnt mit dem bis in 200 Meter Tiefe herabreichenden Schelfbereich. Daran schließt sich der Kontinentalhang an, der in 2000 bis 4000 m Tiefe in den flacheren Kontinentalfuß übergeht. Es folgen das Abyssal mit einer Maximaltiefe von 6000 m und darunter das Hadal.

Die sehr seltenen, meistens saisonalen Auftriebsgebiete sind sehr nährstoffreich. In ihnen steigt kalte Tiefenströmung nach oben und ersetzt das nährstoffarme warme Oberflächenwasser.

Der Offene Ozean umfasst etwa 80 Prozent der Fläche des Weltmeeres, aber nur 1 Prozent der Biomasse wird dort produziert. In diesem oligotrophen Gebiet begrenzt hauptsächlich der Mangel an Stickstoff und Phosphor im Meerwasser das Wachstum der Meerespflanzen (Phytoplankton). Aber auch der Mangel an wichtigen Metallen, wie beispielsweise Eisen, wirkt wachstumshemmend, weshalb mit Eisendüngung von HNLC-Gebieten experimentiert wird. Wichtig ist im relativ nährstoffarmen offenen Ozean die Bedeutung der Viren in den oberen Wasserschichten, da eine Infektion der Bakterien, z. B. der Blaualgen (Cyanobakterien), dazu führt, dass diese aufplatzen und damit ihren Inhalt als Nährstoff zur Verfügung stellen.

An der Oberfläche des Meerwassers ist das Neuston zu finden.

Große Wasserwirbel, bei denen kaltes, nährstoffreiches Meerwasser aus der Tiefe an die Meeresoberfläche gefördert wird, wirken wie ein kurzzeitig bestehendes Auftriebsgebiet und führen zu einer explosionsartigen Vermehrung des Phytoplanktons. Denselben Effekt haben tropische Wirbelstürme.

Bedeutend sind große Erhebungen des Meeresbodens, die manchmal bis zur Wasseroberfläche hinauf reichen, wie einzelne Unterwasserberge (Seamounts und Guyots) und große untermeerische Gebirge. Diese Erhebungen beeinflussen die Meeresströmung, so dass dort über große Entfernungen transportiertes, nährstoffreiches Tiefenwasser in geringere Tiefen aufsteigen und somit in einem sonst nährstoffarmen Teil eines Ozeans eine Oase des Lebens entstehen kann.

Der Übergang zwischen dem Festland und der Tiefsee wird durch den bis zu 200 Meter Wassertiefe herabreichenden Schelf, den anschließenden Kontinentalhang und den Kontinentalfuß gebildet.

Die Schelfgebiete der Ozeane sind sehr nährstoffreich und wirtschaftlich von großer Bedeutung für die angrenzenden Staaten. Insofern wurde das rechtliche Konstrukt einer Ausschließlichen Wirtschaftszone geschaffen, um die heute meist überfischten Fischgründe und eventuelle Lagerstätten an Erdöl und Erdgas der nationalen Hoheit zu unterstellen. In der Europäischen Union gilt die Gemeinsame Fischereipolitik.
Tangwälder wachsen auf meist ruhigen, felsigen, 15 m bis 40 m tiefen Schelfgebieten. Der namensgebende Seetang ist eine mehrzellige Alge, die auf dem Meeresboden wurzelt.

Auf weichem Boden im Flachmeer- oder im Wattbereich bilden Pflanzen aus der Familie der Seegrasgewächse teilweise ausgedehnte Seegraswiesen. Neben ihrer großen ökologischen Bedeutung sind sie auch für den Küstenschutz wichtig.

Die Tiefsee ist ein bisher nur wenig erforschtes Gebiet der Ozeane. Mit bemannten Tiefsee-U-Booten für mittlere und große Tiefen sowie mit unbemannten autonomen und ferngesteuerten Tauchfahrzeugen werden seit dem 20. Jahrhundert vor Ort Bilder aufgenommen und Proben gesammelt. Bis dahin konnten nur mit Netzen, beispielsweise auf der Challenger-Expedition (1872–1876) aus bis zu 8000 m Tiefe oder der Valdivia-Expedition (1898–1899) aus etwa 4600 m Tiefe, mehr oder weniger zermatschte Lebewesen aus der Tiefsee gefangen werden.

Im Gegensatz zum durchlichteten oberen Bereich des Ozeans erreicht die Tiefsee zu wenig oder überhaupt kein Sonnenlicht mehr, so dass dort keine Photosynthese möglich ist. Die meisten Tiefseetiere wandern bei Sonnenuntergang aus der Schwachlichtzone nach oben in den tagsüber durchlichteten Bereich, um sich dort zu ernähren, und tauchen bei Sonnenaufgang wieder ab. Bei dieser Wanderung treffen sie auf lauernde Räuber. Die häufigsten Wanderer sind Ruderfußkrebse, Quallen und Krill. Überlebenswichtig für die hier lebenden Tiere ist es, dass sie sich gegenüber dem von oben kommenden schwachen, blauen Licht nicht farblich abheben. Wichtige Tarntechniken sind Durchsichtigkeit und Gegenbeleuchtung, indem an der Körperunterseite vorhandene Leuchtorgane je nach Lichtverhältnissen unterschiedlich stark blau leuchten. Diese Biolumineszenz gewinnt in der von Sonnenlicht freien Zone der Tiefsee noch mehr an Bedeutung. So gibt es dort Tiefseefische, die mit Leuchtsignalen Beutetiere oder Partner anlocken.

Der Ozeanboden ist auf der Erde der flächengrößte Lebensraum und umfasst die Böden der Küsten, der Schelfe, der Kontinentalhänge, der großen Tiefseeebenen und der Tiefseegräben.

Der Ozeanboden an einem Kontinentalhang besteht in der Regel aus Sand und Kies, in den Gezeitenzonen auch aus Schlick und Schlamm. Von den Kontinenten weiter entfernt besteht er vorwiegend aus Tonen und Resten von Mikroorganismen, die in Form des sogenannten Meeresschnees von der Oberfläche zum Grund eines Ozeans langsam herabsinken. Auf diese Weise entsteht eine im Durchschnitt 800 m dicke Schicht von Tiefsee-Sedimenten, die ein wichtiger Teil der tiefen Biosphäre ist.

Die Organismen im Ozeanboden ernähren sich von den herab fallenden Überresten von Pflanzen und Tieren, gelegentlich auch von gelösten vulkanischen Gasen. Denkbar ist auch, dass durch Radiolyse erzeugter Wasserstoff von Bakterien als Energiequelle genutzt wird. In der obersten noch mit Sauerstoff angereicherten Sedimentschicht leben Bakterien und wenige Archaeen, während darunter nur noch Archaeen zu finden sind. Im offenen Ozean des Südpazifik, in einem Gebiet wo jährlich nur wenig Meeresschnee anfällt, konnte im Sediment in Tiefen von bis zu acht Metern viel Sauerstoff gemessen werden, während Kohlenstoff wiederum kaum verfügbar war. Dort fanden sich wenige, aber sehr aktive auf Sauerstoff angewiesene Bakterien. Kleinere Tiere in der oberen Sedimentschicht sind beispielsweise Würmer, Schnecken und Muscheln.

Auf dem Ozeanboden wachsen in bis zu 50 m Tiefe tropische Korallenriffe und an den Kontinentalhängen bis in Tiefen von 1000 Metern die durch die Grundschleppnetzfischerei stark gefährdeten Kaltwasserriffe. Weitere typische auf den Meeresböden lebende Meerestiere sind Seeanemonen, Röhrenwürmer, Schwämme, Seeigel, Seegurken, Seesterne, Schlangensterne und bodenbewohnende Fische, wie beispielsweise Knurrhähne, Plattfische oder Netzaugenfische.

An einigen untermeerischen Gebirgen, den mittelozeanischen Rücken, gibt es "heiße Quellen". Diese lagern Erzschlämme ab und bilden die Grundlage für das von Sonnenlicht vollständig unabhängige Ökosystem der Black Smoker (siehe auch Lost City). In der Nähe von Tiefseerinnen und an Stellen wo Methanhydrate infolge von Erdrutschen instabil wird, finden sich "kalte Quellen", die sogenannten Cold seeps, auch Methanquellen genannt. Sie entstehen dadurch, dass aus dem Meeresboden Wasser, angereichert beispielsweise mit Methan und Schwefelwasserstoff, ausströmt. An den heißen und kalten Quellen finden sich Bartwürmer, die in Symbiose mit Bakterien leben. An den heißen Quellen gibt es eine vielseitige und biomassereiche Fauna, die beispielsweise aus Yeti-Krabben sowie bestimmten Arten von Muscheln, Schnecken und Garnelen besteht. Das Ökosystem der kalten Quellen ähnelt dem der heißen Quellen, nur fehlt dort die erhöhte Temperatur des Meerwassers, es ist dauerhafter und der Übergang zur nicht spezialisierten Fauna ist einfacher. Ein weiteres wichtiges Ökosystem sind die Kadaver großer Lebewesen, beispielsweise Wale, die auf den Ozeanboden sinken und dort für Monate bis Jahrzehnte verschiedenen Lebewesen als Nahrungsquelle dienen. Dies sind beispielsweise Haie, Schleimaale und knochenfressende Würmer.

"→ Siehe auch Atommüll#Legale Entsorgung in Meergewässern, Müllstrudel, Plastikmüll in den Ozeanen, Schiffsabwasser (MARPOL) Unterwasserlärm, Verklappung von Dünnsäure"

Wahrscheinlich existiert, unter einer mächtigen Eiskruste verborgen, ein Ozean auf dem Jupitermond Europa, vielleicht auch auf den anderen Monden Ganymed und Kallisto. Auf dem Saturnmond Enceladus ist ein solcher Ozean sehr wahrscheinlich. Viele Hinweise deuten darauf hin, dass der Mars in der Frühzeit seiner Entwicklung offene Wasserflächen enthielt. Kleinere Ozeane oder auch nur Seen aus Kohlenwasserstoffen (Methan, Ethan) könnten auf dem Saturnmond Titan ganzjährig oder nur zeitweise existieren. Darüber, ob die Gasplaneten Jupiter, Saturn, Uranus und Neptun vielleicht Schichten flüssiger Phasen, eventuell aus Helium oder Wasserstoff, beherbergen, kann nur spekuliert werden. Zur Herkunft der Ozeane siehe Herkunft des irdischen Wassers.

Das einzige Mondmeer, das die Bezeichnung «Ozean» trägt, ist der Oceanus Procellarum, der "Ozean der Stürme".

Es gibt große Aquarien, die verschiedene Ökosysteme der Ozeane nachbilden. Dazu gehören beispielsweise das Oceanário de Lisboa und das Ozeaneum Stralsund.












</doc>
<doc id="10377" url="https://de.wikipedia.org/wiki?curid=10377" title="Blitz">
Blitz

Ein Blitz ist in der Natur eine Funkenentladung oder ein kurzzeitiger Lichtbogen zwischen Wolken oder zwischen Wolken und der Erde. In aller Regel tritt ein Blitz während eines Gewitters infolge einer elektrostatischen Aufladung der wolkenbildenden Wassertröpfchen oder der Regentropfen auf. Er wird dabei vom Donner begleitet und gehört zu den Elektrometeoren. Dabei werden elektrische Ladungen (Elektronen oder Gas-Ionen) ausgetauscht, d. h. es fließen elektrische Ströme. Blitze können, je nach Polarität der elektrostatischen Aufladung, auch von der Erde ausgehen.

Künstlich im Labor mit Hochspannungsimpulsen erzeugte Blitze dienen deren Studium oder der Überprüfung von Einrichtungen des Stromnetzes hinsichtlich der Effekte von Blitzeinschlägen und der Wirksamkeit von Schutzmaßnahmen.

Eine Blitzentladung ist deutlich komplexer als eine reine Funkenentladung. Die der natürlichen Blitzentstehung zugrunde liegenden physikalischen Gesetzmäßigkeiten sind bis heute nicht abschließend erforscht.

Benjamin Franklin bewies am 15. Juni 1752 die Hypothese, dass bei Gewittern eine elektrische Spannung zwischen Wolken und der Erde besteht, indem er einen Drachen in aufziehende Gewitterwolken aufsteigen ließ und so eine Funkenentladung auslöste. Das war der Beginn der neuzeitlichen Blitzforschung. Bis heute sind allerdings nicht alle Erscheinungsformen von Blitzen sowie die damit verbundenen Effekte umfassend und unumstritten wissenschaftlich erklärt, insbesondere wie die Ladungsunterschiede entstehen, die zum Blitz führen.

Heute haben sich verschiedene Verfahren zur Untersuchung von Blitzen etabliert, die auch darauf achten, das Risiko für die Forscher möglichst gering zu halten (im Gegensatz zur Methode Franklins). Häufig werden Raketen abgeschossen, die einen metallischen Draht hinter sich herziehen (Blitztriggerung). Der Blitz gelangt durch den Draht zur Messstation, wo er analysiert werden kann. Andere Verfahren stützen sich auf Wetterballons oder Messungen durch Flugzeuge.

Lange Zeit war das Forschungsinteresse an natürlichen Blitzen gering, da man glaubte, sie wie Funkenentladungen behandeln zu können, wie sie ohne Weiteres im Labor erzeugbar sind. Erst seit Ende der 1990er Jahre hat sich das geändert, da Ungereimtheiten auftraten, die durch das einfache Modell nicht erklärt werden konnten. Es stellte sich als unmöglich heraus, mit den heutigen Mitteln Blitze zur Energiegewinnung auszunutzen.

Einige der jüngsten Forschungsprojekte sind:

Am häufigsten beobachtet man Blitze zwischen speziellen Wolkentypen wie Cumulonimbus und Erde, in den Tropen fast täglich, in gemäßigten Breiten vorwiegend während der Sommermonate. Sehr zahlreiche Blitze werden auch bei Vulkanausbrüchen beobachtet, bei denen aufsteigende Feuchtigkeit wohl nicht als Ursache in Frage kommt. In beiden Fällen konnte bisher nicht lückenlos aufgeklärt werden, wodurch es zu der gewaltigen Ladungstrennung kommt, die vorher stattgefunden haben muss. Rätselhaft ist der offensichtliche Unterschied zu Laborexperimenten mit Gasen, wo es wegen der guten Beweglichkeit der Moleküle schwierig ist, Ladungstrennung ohne metallische Leiter und Isolatoren zu erzeugen und längere Zeit aufrechtzuerhalten.

Grundvoraussetzung für die Entstehung von Blitzen ist die Ladungstrennung. Nach heutigem Wissensstand können eine Reihe von Mechanismen innerhalb der Gewitterwolken dazu beitragen. Man unterscheidet dabei zwischen Aufladungsmechanismen, die "mit" Influenz und "ohne" Influenz wirken können, wobei letztere die weitaus wichtigere Kategorie darstellen.

Grundvoraussetzung für die Trennung von elektrischer Ladung ist die Reibung durch kräftige Aufwinde innerhalb einer Cumulonimbuswolke, die 5–20 m/s und mehr erreichen können. In der Wolke kondensiert übersättigter Wasserdampf zu kleinen, aber ständig wachsenden Wassertröpfchen. Die Kondensation setzt Wärme frei. Dadurch bekommt die Luft eine höhere Temperatur als sie in gleicher Höhe ohne Kondensation hätte. Das erhöht ihren Auftrieb im Vergleich zur Luft außerhalb der Wolke. Der Aufstieg beschleunigt sich. Beim Aufstieg kühlt sich die Luft durch den mit der Höhe sinkenden Druck adiabatisch ab, was die Kondensation verstärkt und den Aufstieg weiter beschleunigt. In einigen Kilometern Höhe wird die Nullgradgrenze unterschritten, und die Wassertropfen gefrieren zu Eispartikeln, die durch Resublimation weiter anwachsen. Mit der Zeit werden die Graupelteilchen schwer genug, dass sie entgegen der Richtung der Aufwinde zum Erdboden fallen.

Vermutlich kollidieren in diesem Stadium kleinere, noch leichte Eiskristalle mit den Graupelteilchen und geben dabei Elektronen an die Graupelteilchen ab. Diese nehmen eine negative Ladung an und sinken so geladen weiter in den unteren Teil der Wolke. Die leichten, jetzt positiv geladenen Eiskristalle werden von den Aufwinden weiter nach oben getragen. Bei ausreichend hoher Steiggeschwindigkeit kommt es zu einer Ladungstrennung, und es entstehen beachtliche Raumladungen. In der Tropical Rainfall Measurement Mission (TRMM) wurde festgestellt, dass die Stärke der Raumladungen direkt vom Eisgehalt der Wolke abhängt. Das bedeutet eine starke Korrelation zwischen der Eismenge in einer Wolke und der Blitzhäufigkeit.

In Wolkenbereichen mit hohem Graupelanteil werden Luftmassen durch die nach unten fallenden Graupelteilchen mit nach unten gerissen, und es entstehen Abwindkanäle in der Gewitterwolke. In ihnen gelangen die negativ geladenen Graupelteilchen zunächst in den unteren Teil der Wolke. Der nun negativ geladene untere Teil der Wolke bewirkt durch Influenz, dass sich der unter der Wolke befindliche Erdboden positiv auflädt, es kommt zur klassischen Ladungsverteilung in einer Gewitterwolke. Dazu kommt, dass im unteren Teil der Gewitterwolke die Graupelteilchen wieder schmelzen und sich dabei positiv aufladen. Die gängige Erklärung lautet, dass sich beim Anwachsen des Graupelteilchens in der Höhe Lufteinschlüsse bilden, die beim späteren Auftauen den Wassertropfen verlassen und dabei an der Oberfläche befindliche negative Ladung mit sich nehmen. Auf diese Weise wird der unter der Wolke ausfallende Niederschlag elektrisch neutral oder – wie man beobachtet hat – sogar positiv geladen, während die negative Ladung im unteren Teil der Wolke verbleibt. Die teilweise extrem starken Turbulenzen innerhalb von Gewitterwolken machen eine experimentelle Überprüfung dieser Vermutungen sehr schwierig.

Man kann sich weitere Prozesse vorstellen, welche diese Ladungsverteilung unterstützen: Die durch Resublimation anwachsenden Graupelteilchen können sich positiv aufladen und diese ihre Ladung bei Kollisionen an leichtere Eiskristalle abgeben, bevor oder während sie in Richtung Erdboden fallen. Der umgekehrte Effekt, also die negative Aufladung von sublimierendem Eis, käme dann in den Abwindkanälen zum Tragen.

In der bereits geladenen Gewitterwolke können weitere Ladungstrennungsmechanismen hinzukommen: Der Nobelpreisträger Charles Thomson Rees Wilson schlug im Jahre 1929 vor, dass durch die anwesende Raumladung dipolartig geladene und entsprechend ausgerichtete Niederschlagspartikel in der Luft befindliche Ionen je nach Polarität entweder einfangen oder abstoßen (unabhängig von ihrem Aggregatzustand).

In der Praxis kann man mit Elektrofeldmetern messen, dass die oben dargestellte Ladungsverteilung im Gewitter häufig zutrifft, dass es aber auch abhängig von der Art des Gewitters (Frontengewitter, Wärmegewitter) und des Reifestadiums starke Abweichungen geben kann, wie zum Beispiel weit in den unteren Teil der Wolke reichende positive Raumladungen, negative Areale am Boden oder positive Wolkenuntergrenze im Spätstadium eines Gewitters. Eine Klärung aller Zusammenhänge steht bis heute aus.
Ein Blitz ist ein Potentialausgleich innerhalb der Wolke "(Wolkenblitz)" oder zwischen dem Erdboden und dem unteren Teil der Wolke "(Erdblitz)". Für Blitze zwischen der Wolke und der Erde muss der Potentialunterschied (die Spannung) einige zehn Millionen Volt betragen. In der Luft kommt es erst zu einer elektrischen Funkenentladung bei einer elektrischen Feldstärke von ca. drei Millionen Volt pro Meter (der so genannten Durchbruchfeldstärke); dieser Wert sinkt jedoch stark mit zunehmender Luftfeuchtigkeit. Allerdings wurden solche Feldstärken in einer Gewitterwolke noch nie gemessen. Messungen ergeben nur extrem selten Feldstärken von über 200.000 V/m, was deutlich unter dem Wert für den Durchbruch liegt. Daher wird heute davon ausgegangen, dass die Luft zuerst durch Ionisation leitfähig gemacht werden muss, damit es zu einer Blitzentladung kommen kann.

Einige Forscher, als erster Wilson im Jahre 1925, gehen davon aus, dass durch kosmische Strahlung angeregte Elektronen den Anfang einer Blitzentstehung bilden. Trifft ein solches Elektron auf ein Luftmolekül einer Gewitterwolke, werden weitere hochenergetische Elektronen freigesetzt. Es kommt zu einer Kettenreaktion, in deren Folge eine Elektronenlawine entsteht ("Runaway-Elektronen" genannt, der genaue Mechanismus findet sich im Artikel Runaway-Breakdown erklärt).

Einer Blitzentladung geht eine Serie von "Vorentladungen" voraus, die gegen die Erdoberfläche gerichtet sind. Dabei wird ein Blitzkanal "(Leitblitz)" geschaffen, d. h., ein elektrisch leitender Kanal wird durch Stoßionisation der Luftmoleküle durch die Runaway-Elektronen gebildet. Der ionisierte Blitzkanal baut sich stufenweise auf (daher engl. "stepped leader"), bis er zwischen Erdoberfläche und Wolke hergestellt ist. Die Vorentladungen sind zwar zum Erdboden hin gerichtet, variieren aber innerhalb weniger Meter leicht ihre Richtung und können sich stellenweise aufspalten. Dadurch kommen die Zick-Zack-Form und die Verästelungen des Blitzes zustande. Der Leitblitz emittiert – wie neue Forschungen zeigen – auch Röntgenstrahlung mit einer Energie von 250.000 Elektronenvolt (siehe dazu die Literaturhinweise). Forscher der Universität Florida haben 2004 nachgewiesen, dass die gemessenen Ausbrüche von Röntgenstrahlen zusammen mit der Bildung der einzelnen Stufen des Leitblitzes auftreten. Dabei nimmt die Intensität der Strahlung mit der Anzahl der Stufen zu, je länger also der Blitzkanal wird. Während der Hauptentladungen wurden keine Röntgenstrahlen gemessen. Noch ist nicht bekannt, wodurch die Elektronen im Leitblitz so stark beschleunigt werden. Der Vorgang des Runaway-Breakdown allein reicht für die gemessene Strahlung nicht aus (siehe dazu auch in den Weblinks).

Kurz bevor die Vorentladungen den Erdboden erreichen, gehen vom Boden eine oder mehrere "Fangentladungen" aus, welche bläulich und sehr lichtschwach sind. Eine Fangentladung tritt meistens bei spitzen Gegenständen (wie Bäumen, Masten oder Kirchtürmen) aus, welche sich in ihrer Höhe von der Umgebung abheben. Meist – aber nicht immer – trifft eine der Fangentladungen mit den Vorentladungen zusammen und bildet einen geschlossenen Blitzkanal zwischen Wolke und Erdboden. Der Blitzkanal weist maximal 12 mm im Durchmesser auf. Durch diesen Kanal erfolgt dann die "Hauptentladung", welche sehr hell ist und als eigentlicher Blitz wahrgenommen wird. Das Leuchten des Blitzes wird durch die Bildung von Plasma verursacht.

Im Durchschnitt bilden vier bis fünf Hauptentladungen einen Blitz. Die Vorentladungen benötigen zusammengenommen etwa 0,01 Sekunden, die Hauptentladung dauert nur 30 µs (0,00003 s). Nach einer Erholungspause zwischen 0,03 s und 0,05 s erfolgt eine neue Entladung. Es wurden schon bis zu 42 aufeinanderfolgende Entladungen beobachtet. Dadurch kommt das Flackern eines Blitzes zustande.

Durch die ruckartigen verschiedenen Stufen der Entladung kann der Blitz als kurzfristiger, pulsierender Gleichstrom interpretiert werden.

Die Stromstärke einer Hauptentladung beträgt im Durchschnitt etwa 20.000 Ampere, wodurch ein starkes Magnetfeld den Blitzkanal umgibt. Die Kombination aus Strom und Magnetfeld bewirkt eine Kompression des leitfähigen Plasmakanals (Pinch-Effekt), der einen Durchmesser von nur wenigen Zentimetern besitzt.

Meistens fließt die negative Ladung von der Wolkenunterseite zum Boden, man spricht vom "Negativblitz". Seltener wird positive Ladung der Erdoberfläche zugeführt "(Positivblitz)". Meistens handelt es sich dabei um eine besonders intensive Entladung, deren Hauptentladung auch deutlich länger anhält als beim Negativblitz. Der Positivblitz besteht in aller Regel auch nur aus einer Hauptentladung. Die Stromstärke einer Hauptentladung bei Positivblitzen wird mit bis zu 400.000 Ampere angegeben. Sie sind daher weitaus gefährlicher als Negativblitze, machen allerdings nur etwa 5 % aller Erdblitze aus. Positivblitze entstammen oft dem oberen, positiv geladenen Teil der Gewitterwolke oder dem Wolkenschirm. Sie können auch aus der Wolke austreten und durch den wolkenfreien Raum ihren Weg zu einem Einschlagsziel am Boden nehmen. Die Einschlagstelle kann dabei durchaus einige Kilometer von der Gewitterzelle entfernt liegen. Positivblitze treten auch in den rückwärtigen, stratiformen Bereichen des Gewitters sowie in deren Auflösungsphase auf. Außerdem haben Wintergewitter, in denen der Niederschlag in gefrorener Form fällt, einen hohen Positivblitzanteil.

Die Anstiegsgeschwindigkeit eines Blitzstroms beträgt durchschnittlich 7000 Ampere pro Mikrosekunde. Demzufolge steigt auch die Stärke des dazugehörigen Magnetfelds entsprechend an. Dadurch ist ein Blitz in der Lage, selbst in mehreren Kilometern Entfernung erhebliche elektrische Spannungen zu induzieren.

Anschließend zum Hauptblitz kann durch den ionisierten Blitzkanal ein Ladungsausgleich erfolgen, der 10 bis einige 100 ms anhält. Dabei fließt ein annähernd konstanter Strom von 10 bis 1000 A. Dieser Langzeitstrom tritt häufig nach positiven Blitzen auf und wird auch als „Stromschwanz“ bezeichnet.

Aufgrund der bei einem Blitz auftretenden hochenergetischen Photonen werden auch Kernreaktionen in der Atmosphäre ausgelöst. Das wurde schon von Charles T. R. Wilson Anfang des 20. Jahrhunderts vermutet und 2017 durch Wissenschaftler der Universität Tokio schlüssig nachgewiesen. Sie konnten Gammastrahlen mit einer Energie von 511 keV, der Annihilationsenergie eines Elektrons und Positrons, mit Blitzen korrelieren. In einem photonuklearen Prozess schlugen Photonen von mehr als 10 MeV ein Neutron aus einem Stickstoff-14-Kern, der danach in einen Kohlenstoff-13-Kern zerfiel unter Betazerfall, wobei auch ein Positron entstand. Da dabei somit auch Kohlenstoffkerne entstehen, hat das Auswirkungen auf die C14-Datierungsmethode. Vorher war auch über Fusionsprozesse bei Blitzen spekuliert worden, was aber mit diesen Beobachtungen ausgeschlossen wurde.

Die durchschnittliche Länge eines Erdblitzes (Negativblitz) beträgt in mittleren Breiten 1 bis 2 km, in den Tropen aufgrund der höheren Luftfeuchtigkeit 2 bis 3 km. Positivblitze reichen nicht selten von den oberen Regionen der Gewitterwolke bis zum Erdboden und kommen daher auf Längen von deutlich über 10 km. Ein Wolkenblitz ist ca. fünf bis sieben Kilometer lang. Blitze können jedoch auch enorme Längen entwickeln, der bisher längste Blitz wurde 2007 über Oklahoma mit einer horizontalen Länge von 321 km aufgezeichnet.

Im Blitzkanal wird die Luft schlagartig auf bis zu 30.000 °C erhitzt. Das den Blitzkanal schlauchförmig umhüllende Magnetfeld verhindert dabei die Ausdehnung der ionisierten und damit magnetisch beeinflussbaren Luftmoleküle. Die Folge ist ein extrem hoher Druck. Mit dem Ende des Leitblitzes und damit des Stroms bricht auch das Magnetfeld zusammen, und die heiße Luft dehnt sich explosionsartig aus, wodurch der Knall des Donners hervorgerufen wird. Das Grollen des Donners kommt durch Echo-Effekte, durch unterschiedliche Distanzen zum Blitzkanal und durch Dispersion (Abhängigkeit der Schallausbreitung von der Wellenlänge) zustande. Der Blitz selbst erreicht etwa ein Zehntel bis ein Drittel der Lichtgeschwindigkeit, wobei die für das Auge nicht wahrnehmbare Vorentladung nur mit einem Tausendstel der Lichtgeschwindigkeit verläuft, also mit 300 Kilometer pro Sekunde. Blitzentladungen innerhalb der Wolke werden gewöhnlich von einem länger anhaltenden und weniger scharf polternden Geräusch begleitet. Das hängt zum einen mit der gewöhnlich größeren Distanz zusammen, ist aber vor allem auf die verschiedene Orientierung und Struktur von Erdblitz und Wolkenblitz zurückzuführen.

An der Stelle, wo der Blitz in den Boden geht (oder aus ihm heraus), bildet sich ein starkes Spannungsfeld (hohes Potential), das von der Stelle des Einschlags nach außen hin kreisförmig abnimmt und sich in das Erdreich kegelförmig spitz fortsetzt, daher der Name. Fläche, Tiefe und Potential des Kegels sind z. B. abhängig von der Stärke des Blitzes, der Bodenbeschaffenheit und Feuchtigkeit. Im Zentrum des Kegels kann es zu Gesteinsaufschmelzung kommen. Dann entsteht ein Fulgurit.

Mit „Blitzschlag“ ist nicht nur der direkte Treffer gemeint, sondern auch Schädigungen durch den Spannungskegel. Steht z. B. ein Blitzopfer mit beiden Beinen auf dem Boden, befindet sich jedes Bein auf einem etwas anderen Potential. Die Potentialdifferenz im Körper, die sogenannte Schrittspannung, führt zu Schäden an Organen. Diese sind nicht tödlich, falls die Differenz gering ist, z. B. wenn das Opfer im Moment des Einschlags beide Füße dicht nebeneinander hat und die Spannungsdifferenz minimiert ist. Bei jemandem, der mit Kopf oder Füßen in Richtung Einschlagstelle liegt, ist die Spannungsdifferenz u. U. aber sehr groß. Dann kann auch ein Einschlag, der weiter entfernt ist, zu schweren Schäden führen. Aus diesem Grund sind vierbeinige Tiere (z. B. Kühe auf der Weide) besonders gefährdet. Stärke und Form des Spannungskegels sind in der Regel nicht vorhersehbar.

„Blue Jets“ (engl., „blauer Strahl“) sind bläulich leuchtende Lichtfontänen, die sich oberhalb von Gewitterzellen mit ca. 100 km/s bis 50 km hoch ausbreiten.

Ein Elmsfeuer ist eine Funkenentladung gegen die umgebende Luft. Physikalisch betrachtet ist sie eine Vorentladung aufgrund großer Feldstärke. Sie tritt meistens an hohen Gegenständen wie Antennenmasten, Schiffsmasten, Flugzeugen (beim Fliegen in Gewitternähe oder einer mit Aschepartikeln durchtränkten Luftschicht) oder Gipfelkreuzen auf. Elmsfeuer können eine Blitzentladung einleiten. Bergsteiger berichten oft, dass diese sog. Spitzenentladung auch am Pickel auftritt, den man daher bei Gewittern nicht in der Hand tragen soll.

Bei „Elfen“ (engl. "elves") handelt es sich um Blitzentladungen, welche die Gase in der Ionosphäre in Schwingung versetzen , so dass sie kurz ringförmig leuchten. Sie treten über großen Gewitterwolken als farbiger Ring in etwa 90 km Höhe auf und werden vermutlich durch Wolkenblitze induziert.

Blitzentladungen können auch durch einen Vulkanausbruch ausgelöst werden.

Ein Flächenblitz zeigt zahlreiche Verzweigungen vom Hauptblitzkanal.

Kugelblitze sind seltene, kugelförmige Leuchterscheinungen, die bei Gewittern beobachtet wurden. Die meist auf Augenzeugenberichten basierenden Fälle können physikalisch nur unzureichend erklärt werden.

Ein Linienblitz hat keine Verzweigungen. Er sucht sich jedoch nicht immer den direkten Weg zum Erdboden, sondern kann auch Bögen beschreiben, die aus einer bestimmten Perspektive als Knoten und kreisförmige Verschlingungen gesehen werden können. Der Linienblitz ist häufiger zu sehen als andere Blitze.

Der Perlschnurblitz ist eine Blitzart, bei der der Blitz nicht durch einen zusammenhängenden Blitzkanal gekennzeichnet ist, sondern in einzelne, meistens nur wenige Meter lange Segmente zerfällt. Diese einzelnen Segmente leuchten heller und meistens auch etwas länger als ein „normaler“ Linienblitz. Von weitem betrachtet sehen die kurzen, leuchtenden Segmente des Blitzes wie eine Perlenschnur aus.

Perlschnurblitze sind wie Kugelblitze sehr seltene Blitzphänomene. In Laboren ist es bereits gelungen, Perlschnurblitze künstlich zu erzeugen. Dennoch hat man ihre Bildung noch nicht restlos verstanden: Als Ursache könnten Instabilitäten im Plasma des Blitzkanals in Frage kommen.

Ein positiver oder "Megablitz" ist ein Blitz, bei dem die Blitzentladung aus dem oberen, positiv geladenen Teil der Wolke (Amboss) zum Boden erfolgt. Diese Blitze sind um einiges stärker als negative Blitze und können kilometerweit vom eigentlichen Gewitter entfernt einschlagen. Sie dauern länger als ein negativer Blitz, haben demzufolge eine größere Energie und können somit einen weit größeren Schaden anrichten. Der Donner ist durch den länger anhaltenden Potentialausgleich lauter, einem Knall ähnlich und wird von einem niederfrequenten Poltern oder Rumpeln begleitet.

„Red Sprites“ (engl., „Rote Kobolde“) sind kurze, (ca. 5 ms), bis zu 100 km hoch reichende, Polarlichtern ähnelnde Entladungserscheinungen in der Mesosphäre oberhalb von großen Gewittern. Sie stehen im Zusammenhang mit Blitzen und sind hauptsächlich aus Flugzeugen beobachtbar, aus weiterer Entfernung (ca. 200 km) bei entsprechenden Sichtverhältnissen auch vom Boden. Sie erscheinen meist rötlich - die rote Farbe entsteht durch die Fluoreszenz von Stickstoff, der durch Blitze des darunterliegenden Gewitters angeregt wurde - und haben unterschiedliche Formen von pilzartig bis lattenzaunähnlich.

Unter „Wetterleuchten“ (mittelhochdeutsch "weterleichen" zu „weter“ (Wetter) + „leichen“ (tanzen, hüpfen), volksetymologisch angelehnt an das nicht verwandte "leuchten") wird meistens der Widerschein von Blitzen verstanden, wenn man sie selbst nicht sehen kann. Es tritt bei weiter entfernten Gewittern oder bei Blitzen in Erscheinung, die sich innerhalb von Wolken entladen. Den dazugehörenden Donner hört man wegen der großen Distanzen meistens nicht oder nur schwach.

Eine Entladung wird als "Blitzschlag" (engl. stroke) bezeichnet. Zu statistischen Zwecken fasst man mehrere Teilblitze (strokes), die innerhalb einer oder 1,5 Sekunden am gleichen Ort gemessen werden, zu einem Blitzereignis, ‚Blitz‘ (engl. "flash") zusammen. Nach der Datenbank CATS "(Computer Aided Thunderstorm Surveillance System)" der EUCLID (European Cooperation for Lightning Detection) ist ein Verhältnis von 100 Mio. Teilblitzen zu 65 Mio. Blitzen festzustellen, also etwa 3:2.

Um die "Blitzhäufigkeit" (Anzahl der Blitzereignisse) vergleichbar zu erfassen und die Blitzgefahr abzuschätzen, ermittelt man die "Blitzdichte" "N" in Ereignissen (Blitz) je Quadratkilometer. Seit Entwicklung der elektromagnetischen Blitzortung ist die Blitzdichte heute exakt messbar, früher wurde sie aus dem "keraunischen Pegel der Gewitterhäufigkeit" abgeschätzt. Als gemitteltes Datum ist dieser Wert von der zugrunde gelegten Flächeneinheit (im Allgemeinen 1 km × 1 km) abhängig, für die Abschätzung am Einzelobjekt legt man die "lokale Blitzdichte" (etwa EN 62305-2 "Blitzschutz – Risikomanagement") zugrunde.

Blitze rufen starke elektromagnetische Störungen im Funkverkehr hervor (Atmosphärische Störungen). Auf unbenutzten Radiofrequenzen der Lang- und Mittelwelle machen sich Blitze durch deutliches Knacken oder Kratzen bemerkbar. Dieses Phänomen wird zur automatischen Ortung von Blitzeinschlägen genutzt. Dazu werden nach der heute üblichen Technik der Blitzortungssysteme mittels mindestens dreier Sensoren die Laufzeitunterschiede gemessen, und daraus die Position bestimmt ("Time of arrival"-Systeme, TOA, ähnlich der Funktion der GPS-Peilung) – die Technik der magnetischen Richtungspeilung hat sich nicht durchgesetzt. Die Ergebnisse sind auf diversen Internetseiten als Blitzkarten erhältlich, wie sie zum Beispiel BLIDS von der Siemens AG oder das österreichische System ALDIS und andere Mitglieder von EUCLID "(European Cooperation for Lightning Detection)", oder NALDN "(North American Lightning Detection Network)" anbieten.

Eine andere Methode sind die satellitengestützten globalen Blitzortungen, die auf optischen oder elektromagnetischen Messmethoden beruhen: Zu den wichtigen Blitzortungssatelliten und -systemen gehören: MicroLab-1 "Optical Transient Detector (OTD)"; TRMM "Lightning Imaging Sensor (LIS)"; GOES-R "Geostationary Lightning Mapper (GLM)", "Lightning Mapper Sensor (LMS)"; auch die dritte Generation "Meteosat" ab 2015 soll ein Ortungssystem tragen.

Daneben ist auch Ortung über die Schumann-Resonanz möglich.

Um bei einem Gewitter ohne Messmittel eine ungefähre Entfernungsangabe zu erhalten, kann die Zeit zwischen Blitz und Donner gemessen (gezählt) werden. Dabei wird die Laufzeit des Lichtes als geringfügig vernachlässigt. Diese Zeit in Sekunden, multipliziert mit der Schallgeschwindigkeit (343 m/s), ergibt die Entfernung in Metern. Näherungsweise kann auch die Zeit in Sekunden geteilt durch drei für die ungefähre Entfernung in Kilometern gerechnet werden. Zur Bestimmung des Donnerzeitpunktes ist dabei stets das erste wahrnehmbare Schallsignal zu verwenden, welches vom Blitz auf kürzestem Weg zum Beobachter gelangt und somit die Entfernung zu diesem Abschnitt des Blitzkanals relativ genau wiedergibt. Je nach Art des Blitzes ist dieser Blitzkanalabschnitt im Allgemeinen entweder der am nächsten zum Beobachter liegende Teil eines Wolkenblitzes oder der etwas oberhalb des Bodens liegende eines Bodenblitzes. Die Schallsignale von weiter entfernten Abschnitten des Blitzkanals bilden zusammen mit durch Reflexionen und Beugungen verzögerten Bestandteilen das Donnergrollen, welches wesentlich lauter als das Primärereignis sein kann.

Weltweit gibt es zu jedem beliebigen Zeitpunkt 2000 bis 3000 Gewitter, was auf der gesamten Erde täglich 10 bis 30 Millionen Blitze ergibt (andere Schätzungen gehen nur von 4 Millionen aus). Das sind über 100 Blitze in jeder Sekunde. Doch nur 10 % aller Blitze schlagen in den Boden ein.

In der Bundesrepublik Deutschland gab es 2003 über 2 Millionen Blitze. In Österreich schwankt die seit 1992 registrierte Zahl zwischen 100.000 und 222.000, davon allerdings 70 % in der südöstlichen Landeshälfte und nur 10 % im alpinen Tirol. Die Regel, dass im Gebirge mehr Blitze auftreten, hat sich an Messdaten nicht bestätigt.

Die allgemeine Blitzhäufigkeit in Deutschland liegt zwischen 0,5 und zehn Einschlägen pro Quadratkilometer und Jahr. Der Schnitt Bayerns liegt bei weniger als einem Blitz pro km² jährlich, in Österreich und Norditalien bei 1–2, in Slowenien bei 3. Fast überall gibt es kleinere Bereiche, in denen die Blitzhäufigkeit zwei- bis dreimal so hoch wie in der Umgebung ist und umgekehrt. Vor allem aber hängt die Blitzhäufigkeit sehr stark von der Jahreszeit ab. Im Juli und August kommt es zu vielen Blitzschlägen, im Januar gibt es fast keine. Zudem gibt es in Großstädten mehr Blitze, was vermutlich mit der Luftverschmutzung und der Lufttemperatur (Stadtklima) zusammenhängt. Am häufigsten blitzt es in Deutschland im Schwarzwald, dicht gefolgt von der Rhein-Main-Gegend und dem Rhein-Neckar-Dreieck, in Österreich und Italien an den Südlichen Kalkalpen.

Forschungen der NASA (z. B. LIS) haben ergeben, dass die weltweit größte Blitzhäufigkeit im Kongobecken, speziell im Lee, d. h. westlich der Zentralafrikanischen Schwelle, zu finden ist. Weitere Zentren sind der Norden Kolumbiens bis hin zum Maracaibo-See in Venezuela (siehe Catatumbo-Gewitter), der äußerste Norden der von den Hochgebirgen umgebenen Indus-Ebene in Pakistan, die Straße von Malakka einschließlich des südlichen Teils der Malaiischen Halbinsel, Paraguay und Nordargentinien etwa entlang des Río Paraná sowie die Südstaaten der USA (namentlich Florida) und die vorgelagerten Karibikinseln.

Während es im Kongobecken mit geringen Verschiebungen ganzjährig blitzt, fällt in den anderen genannten Gebieten das Blitzmaximum signifikant mit dem Sommer der jeweiligen Hemisphäre oder dem Auftreten des Monsuns zusammen. Der Grund, dass speziell in diesen Gebieten so häufig intensive Gewitter auftreten, ist fast immer orografischer Natur, d. h., die vorherrschende Windrichtung zwingt die Luftmassen zum Aufsteigen an Gebirgsketten und das ist der Auslöser für die Entstehung gewittriger Niederschläge.

Blitze/km² über der Zeit (1992–2010) für Österreich mit Bundesländern

Quelle: ALDIS (Jahresdurchschnitte und Flächenmittelwerte berechnet) Der Anbieter ergänzt seine Veröffentlichungen um den folgenden Hinweis:

Im Juni 2017 veröffentlichte der ORF eine Landkarte mit der bezirksweisen Blitzdichte (pro Jahr und km) gemittelt über die Jahre 2010–2016.

Blitze richten in Deutschland jährlich Schäden in Höhe von mehreren Millionen Euro an. 2014 verursachten Blitze versicherte Schäden in Höhe von 340 Millionen Euro. Durch Blitzeinschlag können Haus- und Waldbrände entstehen, zunehmend werden jedoch elektrische Geräte beschädigt. Zum Schutz werden daher viele Gebäude mit einem Blitzschutzsystem versehen. Von Versicherungsgesellschaften wird der Blitzschutz privater Gebäude jedoch nicht ausdrücklich verlangt.

Schäden entstehen jedoch nicht nur durch direkten Einschlag, sondern auch durch Potentialunterschiede elektrischer Anlagen oder des Bodens sowie durch elektromagnetische Induktion in längeren Kabelstrecken. Überspannungsschutzsteckdosen für elektronische Geräte wie Computer sind daher recht unzureichende Glieder einer Kette von Maßnahmen des Blitzschutzes. Werden sie allein eingesetzt, schützen sie insbesondere dann kaum, wenn an den Geräten weitere Leitungen angeschlossen sind (Telefonleitung, Antennenanlage, Kabelfernsehen). Wirksamer ist es, alle Leitungen (Strom, Gas, Wasser, Telefon, Antenne, Kabelfernsehen) bei Gebäudeeintritt auf eine gemeinsame Potentialausgleichsschiene zu führen. Zusätzlich sollten die Strom- und Signalleitungen mit Überspannungsableitern (Grob- und Feinschutz) versehen sein. Bei Antennenanlagen gilt weiterhin die alte Regel, den Antennenstecker vor einem Gewitter vom Gerät abzuziehen.

Ein besonders spektakulärer Blitzschaden ereignete sich 1970 am Langwellensender Orlunda in Schweden. Damals zerstörte ein Blitzschlag den Fußpunktisolator des 250 Meter hohen Zentralmasts des Langwellensenders und brachte diesen dabei zum Einsturz.

Während eines Gewitters ist man im Freien – vor allem auf erhöhten Standpunkten – der Gefahr des Blitzschlags ausgesetzt.
Die Effekte eines direkten Blitzschlages entsprechen in etwa denen eines Stromunfalls mit den für Hochspannungsunfälle typischen Verletzungen wie Verbrennungen, aber auch Auswirkungen auf das Nervensystem (wie Gehirn, Rückenmark), Muskulatur einschließlich des Herzens und anderer Organe sowie (bleibende) Schädigungen sind möglich, die u. a. zur Bewusstlosigkeit (Koma), Lähmungen und tödlichem Herz-, Kreislauf- und Atemstillstand führen können. Dabei ist innerhalb einer Stunde nach dem Unfall die Ausbildung von Hautverletzungen in Form einer Lichtenberg-Figur möglich. Direkte Blitzeinschläge in Menschen verlaufen oft tödlich, vor allem bei stärkeren Blitzen.

Bei etwa 50 % der Blitzopfer, die überleben, treten nach Monaten bis Jahren neurologische Folgeschäden auf.

Zusätzlich zu den direkten Auswirkungen des elektrischen Stroms stellt auch die durch den Blitz resultierende Druckwelle eine Gefahr dar. Diese kann je nach Stärke des Blitzes einer Sprengwirkung von ungefähr 30 kg TNT entsprechen und noch in einiger Entfernung Folgeverletzungen wie Gehörschäden, zum Beispiel Hörsturz, Tinnitus oder Risse im Trommelfell, aber auch unter Umständen lebensbedrohliche Risse der Lunge oder Verletzungen innerer Organe sowie Frakturen verursachen.

Je nach Situation können weitere indirekte Wirkungen bestehen, beispielsweise durch das Erschrecken oder die Blendwirkung, welche zu Folgeunfällen führen können. Personen, die sich in der Nähe eines Blitzschlags befunden haben, haben in der Folgezeit zum Teil physiologische oder psychische Störungen oder Veränderungen, die sich sogar dauerhaft in einer Persönlichkeitsveränderung auswirken können.

Tödlicher Blitzschlag ist in Deutschland selten geworden; die durchschnittlich drei bis sieben Todesopfer pro Jahr ließen sich durch weitere Vorsichtsmaßnahmen noch weiter reduzieren. Im 19. Jahrhundert wurden in Deutschland noch an die 300 Personen jährlich vom Blitz getötet, da wesentlich mehr Menschen auf freiem Feld in der Landwirtschaft arbeiteten und sich nicht in geschützte Objekte wie Autos, Traktoren oder Mähdrescher zurückziehen konnten.

Zah­len aus den USA, wo die Be­rech­nun­gen sehr weit zu­rück­rei­chen, zei­gen, dass das Ri­si­ko, vom Blitz er­schla­gen zu wer­den, zu Be­ginn des 20. Jahr­hun­derts 40-mal hö­her war als heu­te, von rund vier Op­fern pro ei­ner Mil­li­on Ein­woh­ner pro Jahr auf un­ter 0,1 pro Mil­li­on. Für Ge­samt­deutsch­land lie­gen ver­gleich­ba­re Da­ten erst ab 1980 vor, doch auch in die­ser jün­ge­ren Ver­gan­gen­heit ist der Rück­gang deut­lich zu er­ken­nen. Der Golf­sport, eine an­sons­ten eher ri­si­ko­lo­se Sportart, bleibt blitz­ge­fähr­det. 2012 er­schlug ein Blitz vier Frau­en auf ei­nem Golf­platz in Nord­hes­sen. In den USA kommt im Schnitt je­des Jahr ein Gol­fer durch Blitz­schlag ums Le­ben.

Der beste Schutz besteht darin, unterwegs die kurzfristige Wetterentwicklung zu beobachten und bei Gewitterneigung erreichbare Zufluchtsorte zu identifizieren. Wetterprognosen sind heute noch zu ungenau, um den genauen Ort und Zeitpunkt eines Gewitters vorauszusagen. Kurzfristige Unwetterwarnungen per Handy-App können durchaus hilfreich sein, ersetzen aber dennoch nicht die konkreten Entscheidungen, die je nach Situation getroffen werden müssen.

Nach der 30/30-Regel geht man davon aus, dass die Gefahr, von einem Blitz getroffen zu werden, hoch ist, sobald bei Heraufziehen eines Gewitters zwischen Blitz und Donner weniger als 30 Sekunden liegen bis zu dem Zeitpunkt, wo 30 Minuten nach dem letzten Blitz oder Donner vergangen sind. Innerhalb dieser Zeit soll ein sicherer Ort aufgesucht und nicht wieder verlassen werden.


Wenn kein Schutz in Gebäuden oder Fahrzeugen gefunden werden kann, gelten folgende Regeln:


Die anderen Gefahren von Gewittern müssen auch berücksichtigt werden. An Bächen und Flüssen kann eine Sturzflut entstehen und insbesondere im Gebirge kann die Temperatur sehr rasch und stark absinken. Ebenso können Wege nass und rutschig werden, oder von Hagelkörnern bedeckt sein.

In Deutschland ist vom Gesetzgeber ein Blitzableiter an Wohngebäuden grundsätzlich nicht zwingend vorgeschrieben. In den baurechtlichen Vorschriften der anhängigen Musterbauordnung heißt es unter § 46 Blitzschutzanlagen lediglich knapp:

Jedes Bauvorhaben erfordert damit eine Einzelfallprüfung hinsichtlich der Blitzschlagwahrscheinlichkeit (zum Beispiel anhand der Lage und Ausdehnung des Gebäudes) und einer Folgenabschätzung (zum Beispiel Personenschaden).

Der entsprechende Wortlaut im österreichischen Baurecht lautet: „Bauwerke sind mit Blitzschutzanlagen auszustatten, wenn sie wegen ihrer Lage, Größe oder Bauweise durch Blitzschlag gefährdet sind oder wenn der Verwendungszweck oder die kulturhistorische Bedeutung des Bauwerks dies erfordern“.

Der Gesetzgeber benennt keine technische Regel, nach der diese Prüfung durchgeführt werden soll. Im Prinzip ist daher der Bauherr/Architekt in der Nachweisführung frei, soweit alle im Gesetzestext genannten Einflussgrößen (Lage, Bauart, Nutzung, Folgen) detailliert betrachtet werden.

In der Praxis erweist sich das als gar nicht so einfach, weil in der Regel die erforderlichen Abschätzungen eine entsprechende Erfahrung voraussetzen. Welcher Arbeitsaufwand hinter einer fachgerechten Risikobeurteilung stecken kann, lässt sich anhand der EN 62305-11 Teil 2 (Deutschland: VDE 0185-305) ablesen. Diese Norm erfüllt vom Umfang die gesetzlichen Mindestanforderungen, die Anwendung ist also baurechtlich zulässig. Andererseits ist der Aufwand für die Datenerfassung und Berechnung für viele Bauvorhaben unangemessen hoch. Besonders problematisch ist jedoch, dass in Einzelfällen die Berechnungsergebnisse nicht mit dem geltenden Baurecht in Einklang stehen. Der Gesetzgeber oder die Rechtsprechung haben für bestimmte Gebäudetypen/Nutzergruppen andere Festlegungen getroffen. Weichen die Berechnungsergebnisse der Risikoermittlung von den gesetzlichen Forderungen ab, so sind grundsätzlich die höheren Anforderungen umzusetzen.

Die Risikoermittlung wird immer nur der erste Schritt bei der Planung einer Blitzschutzanlage sein, in einem weiteren Schritt sind die baurechtlichen Besonderheiten zu berücksichtigen, und anschließend sind die in der Risikoermittlung getroffenen Annahmen (ausgewählte Reduktionsfaktoren, Schadenfaktoren usw.) umzusetzen. Auch für die anschließende Planung des Blitzschutzes einer baulichen Anlage werden in der EN 62305-11 Teil 1 bis 4 weiterführende Aussagen getroffen.

In der Bibel werden Blitze (und Donner) zum Beispiel für den Zorn Gottes verwendet (; ; ; ), für das Strafgericht Gottes (), für Gottes Offenbarung an die Menschen (; ), für das Kommen des Menschensohnes (; ), für das Fallen des Satans () und für das Wesen der Engel und Auferstandenen (; ; ).

In der griechischen Antike waren die Blitze dem Zeus als Blitzschleuderer zugeordnet, bei den Römern dem Jupiter. Ein Blitzbündel in der Hand als Attribut des Blitzewerfers findet sich in literarischen Quellen (bspw. bei Homer) und auf Darstellungen seither. Die Etrusker sahen in Blitzen Orakel, durch die sie die Gegenwart und Zukunft deuten konnten. Nur die Priester (Haruspices) waren zur Deutung der Blitze gemäß der Blitzlehre befugt. Schon zu dieser Zeit (zwischen 800 und 600 v. Chr.) wurden Blitze kategorisiert und beobachtet.

Die Germanen deuteten den Blitz als sichtbares Zeichen dafür, dass Thor (Donar) seinen Hammer zur Erde geschleudert hatte. Bei den baltischen Völkern war es der Gewittergott Perkūnas.

Auch auf anderen Planeten unseres Sonnensystems, zum Beispiel auf der Venus oder dem Jupiter, treten Blitze auf. Voraussetzung dafür ist eine dichte Atmosphäre.





</doc>
<doc id="10378" url="https://de.wikipedia.org/wiki?curid=10378" title="Dreieck">
Dreieck

Ein Dreieck (veraltet auch Triangel, lateinisch: triangulum) ist ein Polygon und eine geometrische Figur. Es handelt sich innerhalb der euklidischen Geometrie um die einfachste Figur in der Ebene, die von geraden Linien begrenzt wird. Seine Begrenzungslinien bezeichnet man als "Seiten". In seinem Inneren spannen sich drei Winkel, die sogenannten Innenwinkel auf. Die Scheitel dieser Winkel bezeichnet man als "Eckpunkte" des Dreiecks. Auch eine Verallgemeinerung des Dreiecksbegriffes auf nichteuklidische Geometrien ist möglich; in diesem Fall müssen die Begrenzungslinien Geodäten sein.

In der Trigonometrie, einem Teilgebiet der Mathematik, spielen Dreiecke die wesentliche Rolle. Siehe dazu insbesondere Dreiecksgeometrie.



Spitz- und stumpfwinklige Dreiecke werden auch unter dem Namen "schiefwinkliges Dreieck" zusammengefasst.

Ein Dreieck wird durch drei Punkte definiert, die nicht auf einer Geraden liegen. Sie werden "Ecken" des Dreiecks genannt. Die Verbindungsstrecken zwischen je zwei Ecken heißen "Seiten" des Dreiecks. Das Dreieck unterteilt die Ebene in zwei Bereiche, das "Äußere" und das "Innere" des Dreiecks. Der von je zwei an einem Eckpunkt zusammentreffenden Seiten gebildete Winkel ist eine wichtige Größe zur Charakterisierung des Dreiecks.

In der Geometrie werden die Eckpunkte des Dreiecks in der Regel mit formula_1, formula_2 und formula_3 bezeichnet, üblicherweise so wie abgebildet, gegen den Uhrzeigersinn. Die Seite, die einer Ecke gegenüberliegt, wird analog formula_4, formula_5 bzw. formula_6 genannt. Damit liegt z. B. die Seite formula_4 dem Eckpunkt formula_1 gegenüber, verbindet also die Punkte formula_2 und formula_3. Häufig wird mit formula_4, formula_5 und formula_6 auch stattdessen die Länge der jeweiligen Seite formula_14, formula_15 oder formula_16 bezeichnet.
Die Winkel werden formula_17, formula_18 und formula_19 genannt; formula_17 ist der Winkel am Eckpunkt formula_1, formula_18 liegt am Eckpunkt formula_2 und formula_19 liegt am Eckpunkt formula_3

Diese intuitiv einsichtigen Eigenschaften ebener Dreiecke folgen aus den Axiomen der euklidischen Geometrie.

Jedes Dreieck besitzt einen Umkreis, das heißt einen Kreis, der durch seine drei Eckpunkte verläuft. Der Mittelpunkt des Umkreises ist der Schnittpunkt der drei Mittelsenkrechten; das sind die Lotgeraden durch die Mittelpunkte der Seiten.

Die Winkelhalbierenden der drei Innenwinkel schneiden sich ebenfalls in einem gemeinsamen Punkt, nämlich im Mittelpunkt des Inkreises. Dieser berührt die drei Seiten von innen. Die drei Kreise, die jeweils eine Seite von außen und die Verlängerungen der beiden anderen Seiten berühren, heißen Ankreise des Dreiecks.

Der Schwerpunkt eines Dreiecks ist der gemeinsame Schnittpunkt der drei Seitenhalbierenden, also der jeweiligen Verbindungsstrecken der Eckpunkte mit dem Mittelpunkt der gegenüberliegenden Seite. Der Schwerpunkt teilt dabei die Seitenhalbierenden im Verhältnis 2:1.

Auch die drei Höhen, also die Lote der Eckpunkte auf die jeweils gegenüberliegende Seite, schneiden sich in einem gemeinsamen Punkt, dem Höhenschnittpunkt. Mit Hilfe der Höhen kann der Flächeninhalt eines Dreiecks berechnet werden (siehe Dreiecksfläche).

Ein weiterer bekannter Kreis am Dreieck ist der Feuerbachkreis. Er wird auch "Neunpunktekreis" genannt, da er durch die drei Seitenmittelpunkte, die drei Fußpunkte der Höhen und die drei Mittelpunkte der oberen Höhenabschnitte verläuft. Sein Mittelpunkt liegt wie der Schwerpunkt, der Umkreismittelpunkt und der Höhenschnittpunkt auf der eulerschen Geraden.

Ein Dreieck besitzt drei Seiten und drei Innenwinkel. Liegen drei Angaben zur Größe dieser Seiten oder Winkel vor, kann man daraus die jeweils fehlenden übrigen Seiten oder Winkel berechnen, es sei denn es sind nur die drei Winkel gegeben.

Je nachdem, welche Kombination bekannter Seiten und/oder Winkel dabei im Einzelnen gegeben ist, ist das Ergebnis entweder ein- oder mehrdeutig (siehe nebenstehende Abb.).

So liefern die Kongruenzsätze zunächst einmal drei stets eindeutig lösbare Konstellationen, die man symbolisch mit "SSS", "SWS" und "WSW" bezeichnet, wobei "S" für eine bekannte Seite und "W" für einen bekannten Winkel steht.

Der "SSW- oder WSS-Fall" dagegen ist nur dann eindeutig, wenn der bekannte Winkel der "größeren" der beiden gegebenen Seiten gegenüberliegt (SsW-Fall) – liegt er der "kleineren" Seite gegenüber (sSW-Fall), gibt es meist zwei verschiedene Dreiecke, die die Ausgangsbedingungen erfüllen. Dies allerdings muss nicht immer so sein, wie der Sonderfall mit dem Seitenverhältnis 1 : 2 und dem Winkel 30° zeigt, bei dem es genau dann gleichwohl nur ein so bestimmtes Dreieck gibt, wenn der Winkel gegenüber der "längeren" Seite 90° beträgt. Zu erwähnen ist schließlich die rein rechnerisch mögliche Situation, dass gar kein Dreieck die Ausgangsbedingungen erfüllt, nämlich dann, wenn sich für den Sinus des der "längeren" Seite gegenüberliegenden Winkels ein Wert > 1 ergibt (bei real existierenden Dreiecken allerdings ist dieser Fall naturgemäß ausgeschlossen).

Der "WWS- oder SWW-Fall" kann (wie nebenstehender Abbildung zu entnehmen) auf zweierlei Weise gelöst werden: Entweder man berechnet mittels des Sinussatzes zunächst einmal eine der beiden noch fehlenden Seiten und rechnet dann weiter wie im "SSW-Fall", oder aber man bestimmt, was wesentlich bequemer ist, mittels der Winkelsumme im Dreieck den noch fehlenden dritten Winkel und verfährt dann weiter wie im "WSW-Fall".

Wenn die größte der drei Seiten kleiner als die Summe der beiden anderen Seiten ist, dann ist das Dreieck (bis auf Kongruenz) eindeutig bestimmt. Ansonsten gibt es kein Dreieck mit den vorgegebenen drei Seiten. Die Innenwinkel des Dreiecks lassen sich z. B. mit dem Kosinussatz berechnen.

Der "WWW-Fall" ist bei ebenen Dreiecken überhaupt nicht eindeutig lösbar, weil in diesem Fall in Wirklichkeit nur zwei voneinander unabhängige Angaben vorliegen, die Größe des dritten Winkels dagegen stets zwangsläufig aus der Größe der beiden anderen resultiert. Ohne eine gegebene Seite ist zwar die "Form" des gesuchten Dreiecks gegeben, seine "Größe" aber bleibt unbestimmt.

Die wichtigsten Werkzeuge für die Berechnung eines beliebigen Dreiecks sind neben der Winkelsumme im Dreieck der Sinus- und der Kosinussatz, denen gegenüber die weiteren Dreieckssätze wie der Projektionssatz und Tangentensatz sowie die Halbwinkelsätze nur eine untergeordnete Rolle spielen.

Das rechenaufwändigste, aber auch leistungsfähigste der drei Werkzeuge ist dabei der Kosinussatz, da man mit ihm als einzigem für ein Dreieck ohne alle Winkelangaben einen ersten Winkel berechnen (und sich anschließend mit dem einfacheren Sinussatz sowie der Winkelsumme im Dreieck weiterhelfen) kann. Dementsprechend verwendet man den Kosinussatz im hier diskutierten Zusammenhang nur zu Beginn der Berechnung eines Dreiecks vom Typ "SSS" oder "SWS", während alles übrige einfacher und schneller per Sinussatz und Winkelsumme erledigt wird.

Wie nachfolgend zu sehen, beginnt der Kosinussatz genauso wie der Satz des Pythagoras, und in der Tat kann man diesen als einen Sonderfall des Kosinussatzes auffassen:

Wird nämlich der von zwei gegebenen Seiten eines Dreiecks eingeschlossene Winkel ein rechter, wird damit sein Kosinus gleich Null, und was dann von dem betreffenden Kosinussatz übrigbleibt, ist nichts anderes als eine weitere Version des „Pythagoras“.

Kennt man von einem Dreieck nur seine drei Seiten formula_4, formula_5 und formula_6, lassen sich seine Innenwinkel unter Zuhilfenahme der Arkuskosinusfunktion (arccos) wie folgt bestimmen:

Den Sinussatz gibt es in drei Varianten, die sich wie folgt zusammenfassen lassen:

Wie zu sehen, ist der Sinussatz rechnerisch wesentlich unkomplizierter: Kennt man einen der drei Brüche, kennt man damit automatisch auch alle übrigen. Dafür allerdings muss hier stets wenigstens einer der drei Innenwinkel schon bekannt sein, und, wenn nicht, zunächst einmal auf den Kosinussatz zurückgegriffen werden (s. o.).

Ein Dreieck, bei dem alle drei Seiten gleich lang sind, wird gleichseitiges Dreieck genannt. Alle drei Innenwinkel sind gleich groß und betragen folglich 60° (es ist folglich ein spitzwinkliges Dreieck). Damit gehören die gleichseitigen Dreiecke zu den regelmäßigen Polygonen.

Alle gleichseitigen Dreiecke sind zueinander ähnlich und genau dann kongruent, wenn ihre Seitenlängen gleich sind. Mittelsenkrechte, Seitenhalbierende und Höhe zu einer Seite sowie Winkelhalbierende des gegenüberliegenden Winkels fallen bei einem gleichseitigen Dreieck jeweils aufeinander. Entsprechendes gilt für den Umkreismittelpunkt, den Inkreismittelpunkt, den Schwerpunkt und den Höhenschnittpunkt des gleichseitigen Dreiecks, sodass dieser Punkt häufig einfach "Mittelpunkt" genannt wird.

Für ein gleichseitiges Dreieck mit der Seitenlänge formula_4 gilt:

Ein gleichschenkliges Dreieck ist nach moderner Auffassung ein Dreieck, bei dem "mindestens" zwei Seiten gleich lang sind. Diese Seiten werden als "Schenkel" bezeichnet, die dritte Seite heißt "Basis" des gleichschenkligen Dreiecks. Die beiden Winkel an der Basis ("Basiswinkel") sind gleich groß. Der Punkt, an dem beide "Schenkel" zusammentreffen, wird "Spitze" genannt, der dortige Winkel ist der "Winkel an der Spitze".

Bei einem Geodreieck handelt es sich um ein Lineal in Form eines rechtwinkligen gleichschenkligen Dreiecks.

In einem gleichschenkligen Dreieck fallen die Mittelsenkrechte der Basis, die Seitenhalbierende der Basis und die Höhe auf der Basis sowie die Winkelhalbierende des Spitzenwinkels aufeinander.
Man kann die Länge dieser Strecke, also insbesondere die Höhe formula_37, bestimmen, indem man den Satz des Pythagoras auf eine Hälfte des Dreiecks anwendet. Es ergibt sich formula_38.

Ein rechtwinkliges Dreieck ist ein Dreieck, das einen 90°-Winkel, also einen rechten Winkel besitzt. Die dem rechten Winkel gegenüberliegende Seite ist die längste Seite des Dreiecks und wird "Hypotenuse" genannt. Die beiden anderen Seiten heißen "Katheten". In Bezug auf einen der spitzen Winkel des Dreiecks bezeichnet man die dem Winkel anliegende Kathete als "Ankathete" und die dem Winkel gegenüberliegende Kathete als "Gegenkathete".

Die Längen der drei Seiten eines rechtwinkligen Dreiecks werden durch den Satz des Pythagoras in Beziehung gebracht:
Das Quadrat der Länge der Hypotenuse (in der Grafik als formula_6 bezeichnet) ist gleich der Summe der Quadrate der Längen der Katheten (formula_4 und formula_5). Umgekehrt ist ein Dreieck, bei dem die Seitenlängen in der Beziehung formula_42 zueinander stehen, ein rechtwinkliges Dreieck mit Hypotenuse formula_6.

Die Höhe formula_44 eines rechtwinkligen Dreiecks teilt die Hypotenuse in zwei Teile formula_45 und formula_46, sodass die beiden Teildreiecke mit den Seiten formula_45, formula_4, formula_49 und formula_46, formula_49, formula_5 wiederum rechtwinklig sind.
Bei Kenntnis zweier der sechs Angaben (formula_4, formula_5, formula_6, formula_45, formula_46 und formula_49) lassen sich die fehlenden vier anderen Werte aus den in folgender Tabelle aufgeführten Formeln berechnen.
Durch das Verhältnis zwischen Katheten und Hypotenuse lassen sich auch die beiden spitzen Winkel des rechtwinkligen Dreiecks eindeutig bestimmen.
Die folgenden sechs Funktionen werden "Winkelfunktionen" oder trigonometrische Funktionen genannt.
Aus den obigen können die folgenden durch Kehrwertbildung dargestellt werden.
Die Umkehrfunktionen der genannten Winkelfunktionen werden Arkussinus, Arkuskosinus, Arkustangens usw. genannt – ihre Hauptanwendung ist es dementsprechend, zu gegebenen Sinus-, Kosinus- oder Tangenswerten die dazugehörigen Winkel zu liefern.


→ "Hauptartikel: Kugeldreieck"

Dreiecke auf einer Kugel, deren drei Seiten Teile von Großkreisen sind, nennt man sphärische Dreiecke oder Kugeldreiecke. Ihre Seitenlängen werden nicht in der Dimension einer Länge angegeben (Meter, Zentimeter o. ä.), sondern als zugehöriger Winkel im Kugelmittelpunkt.

Ein sphärisches Dreieck hat eine Winkelsumme größer als 180°. Der „Überschuss“ wird sphärischer Exzess genannt und in Formeln meist mit formula_59 bezeichnet:

Der maximale Exzess von 360° tritt bei einem „Dreieck“ mit drei auf 180° gestreckten Winkeln auf. Dieses zum Großkreis entartete Dreieck hat die Winkelsumme 540° (drei mal 180°) und formula_61.

Der Exzess hängt direkt mit dem Flächeninhalt formula_62 des Dreiecks zusammen:

wobei formula_65 den Kugelradius und formula_66 die Kreiszahl 3,14159… bedeutet.

Sphärische Dreiecke können analog den ebenen Dreiecken berechnet werden, wofür es in der Geodäsie z. B. den sphärischen Sinussatz, den Kosinussatz, den Projektionssatz und verschiedene Halbwinkelsätze gibt – siehe Sphärische Trigonometrie.

Zur nichteuklidischen Geometrie – in der das Parallelenaxiom nicht gilt – zählen auch Dreiecke auf einer Sattelfläche. Während eine Kugel überall konvex gekrümmt ist, haben Sattel- und andere hyperbolische Flächen sowohl konvexe als auch konkave Krümmung (ihr Produkt, das Krümmungsmaß, ist "negativ").

Entsprechend ist auch der Exzess negativ – d. h. die Winkelsumme eines Dreiecks auf einer Sattelfläche ist "kleiner" als 180°. Die Kongruenzsätze machen Aussagen über die Dreiecksgrößen (Seitenlänge, Winkel), die notwendig sind, um ein Dreieck eindeutig zu bestimmen.


Das Dreieck wird als Symbol verwendet, zum Beispiel in der Theologie, als ideologisches Symbol, als mathematisches Symbol und auch in Schildern.





</doc>
<doc id="10379" url="https://de.wikipedia.org/wiki?curid=10379" title="GMT">
GMT

GMT steht für:



</doc>
<doc id="10383" url="https://de.wikipedia.org/wiki?curid=10383" title="Tora">
Tora

Die Tora (auch Thora, Torah; Betonung auf „a“, auf Jiddisch "Tojre", auch "Tauroh;" von ‚Gebot‘, ‚Weisung‘, ‚Belehrung‘, von "jarah" ‚unterweisen‘) ist der erste Teil des Tanach, der hebräischen Bibel. Sie besteht aus fünf Büchern, weshalb sie im Judentum auch "chamischa chumsche tora" ‚Die fünf Fünftel der Tora‘ genannt wird. Die griechische Bezeichnung ist "(Pentáteuchos)," lateinisch "Pentateuchus", auch "Pentateuchum", deutsch Pentateuch. In den deutschen christlichen Bibelübersetzungen sind dies die fünf Bücher Mose.

Das hebräische Wort "Tora" bedeutet "Weisung," jedoch wird der Begriff Tora in vielen Bedeutungen gebraucht. Die engste bezeichnet die fünf Bücher Mose, die das Volk Israel nach der Darstellung der Tora am Berg Sinai erhalten hat.

Mit dem Begriff "Tora" wird auch die Torarolle bezeichnet. Dies ist eine handgeschriebene Rolle aus Pergament mit dem unpunktierten hebräischen Text der fünf Bücher Mose. Aus einer Torarolle wird in jüdischen Gottesdiensten gelesen, wobei dieses Lesen eher ein Singen nach einer bestimmten Kantillation ist.

Eine Torarolle für den Gottesdienstgebrauch wird grundsätzlich per Hand von einem Sofer, einem speziell dafür ausgebildeten Schreiber, geschrieben. Eine Torarolle gehört zur Grundausstattung jeder Synagoge und wird nach dem Gebrauch im Toraschrein aufbewahrt. Da eine solche Rolle den Gottesnamen enthält, wird sie vor allen fremden Blicken geschützt. Zum Toraschmuck gehören Torawimpel, Toramantel, Toraschild, Zeigestab und Torakrone oder zwei kleine Krönchen (Rimonim).

Bei guter Aufbewahrung kann eine Torarolle mehrere hundert Jahre rituell brauchbar bleiben. Die älteste existierende Torarolle stammt von etwa 900 n. Chr. Torarollen, die mechanisch, durch Abnutzung oder hohes Alter (Materialermüdung) beschädigt und somit unbrauchbar geworden sind, werden aus Respekt nicht einfach weggeworfen oder verbrannt, sondern in einer Geniza aufbewahrt oder auf einem jüdischen Friedhof begraben.

Nicht alle Toraformen sind Rollen. Eine kommentierte Tora in Buchform und mit einer Übersetzung in der Landessprache heißt Chumasch.

Laut jüdischer Tradition erhielt Israel über Mose nicht nur die schriftliche Tora, sondern auch deren mündlich überlieferte Auslegung, die die schriftliche Tora jeweils aktualisiert. Unter Rabbi Jehuda ha-Nassi wurde das in einzelnen Sammlungen erhaltene, aber kaum überschaubare Material in ein System von sechs Ordnungen gebracht und um das Jahr 200 n. Chr. schriftlich fixiert. Diese erste schriftliche Fixierung der mündlichen Tora, die Mischna, wurde zum Standardkanon, der in seinem Bestand nicht ergänzt, wohl aber kommentiert wurde. Die Mischna wird ausführlich im Talmud diskutiert und erklärt. Talmud ist die Bezeichnung für das gesamte Werk, das aus Mischna und deren Diskussion (Gemara) besteht. Die Gemara wurde bis zum 6. Jahrhundert schriftlich fixiert. Während in der Tora neben den erzählenden Teilen 613 Ge- und Verbote aufgelistet werden, werden in der Mischna und der Gemara diese Vorschriften konkretisiert und teilweise faktisch verändert.

In einer weiteren Bedeutung bezeichnet „Tora“ pars pro toto den gesamten Tanach, also sowohl die Tora (Weisung) im engeren Sinne als auch die Nevi’im (Prophetenbücher) und die Ketuvim (Schriften).

Die Bezeichnung Pentateuch () ist die griechische Bezeichnung für die fünf Bücher Mose. Sie leitet sich her von und , also ‚Fünfgefäß‘. Der Begriff stammt von den Krügen, in denen Schriftrollen aufbewahrt wurden. Deren Umfang bestimmte auch seine Einteilung in fünf ‚Bücher‘ (). Der griechische Begriff wird auch im Lateinischen "(Pentateuchus)" übernommen und ist bis heute in der Wissenschaft gebräuchlich.

In den deutschen christlichen Übersetzungen bildet die Tora als "fünf Bücher Mose" den ersten Teil des Alten Testaments. Der Name leitet sich von Mose ab, der traditionell lange Zeit als Autor der Schrift galt.

Die Tora bzw. der Pentateuch ist im Hebräischen und im Griechischen in fünf Bücher eingeteilt. Diese Einteilung stammt aus der begrenzten Größe der antiken Schriftrollen aus Papyrus oder Pergament. Diese werden im Hebräischen nach den ersten hebräischen Worten des jeweiligen Textes, in der griechischen Septuaginta nach ihren zentralen Themen benannt; im Deutschen wird nach dem traditionellen Verfasser von 1. bis 5. Mose nummeriert.

Die Tora macht einen großen erzählerischen Bogen. Es beginnt mit der Schöpfung und der Urzeit über die Erzväter Abraham, Isaak und Jakob, geht weiter über den Auszug aus Ägypten und den Bundesschluss am Berg Sinai mit der Bekanntgabe der Gesetze bis hin zur Wanderung durch die Wüste bis zur Ansiedlung im Gelobten Land Kanaan (heute Israel/Palästina) als Heilsgeschichte JHWHs. Von der Landnahme selbst berichtet die Tora nicht mehr; das folgt erst im Buch Josua, das die Geschichte weiterführt. In dieser Erzählung werden die vielen Bestimmungen, die nach der Tora Gott den Israeliten am Berg Sinai gegeben hat, ausführlich behandelt. Weil die Tora über weite Strecken ein reines Gesetzeskorpus darstellt, wurde sie zur Grundlage der religionsgesetzlichen Ausformung des rabbinischen Judentums und erhält von dorther ihre Bedeutung im Judentum bis heute. Nach traditioneller jüdischer Auffassung beinhaltet die Tora 613 Vorschriften, 248 Ge- und 365 Verbote.
Die Tora ist thematisch in drei Hauptteile gegliedert:

Diese drei Hauptteile durchziehen sieben große Themenkreise, die als eigenständige Komplexe ursprünglich mündlich überliefert wurden. Sie wurden schon in sehr frühen Glaubensbekenntnissen Gesamtisraels als Stationen einer Heilsgeschichte im sogenannten "kleinen geschichtlichen Credo" aneinandergereiht:

Diese Reihung umgreift eine Geschichtsperiode von gut 500 Jahren von den nomadischen Anfängen Israels bis zur Besiedelung des fruchtbaren Landes Kanaan. Ihr entspricht die Verknüpfung der

Die Themenkomplexe des Sinaibundes [6] und der Urgeschichte [7] fehlen noch in den alten Credoformeln Israels, da ihr Einbau in den Pentateuch relativ spät erfolgte. Kristallisationskern und ordnendes Zentrum der Überlieferung ist das Thema der Befreiung aus der Sklaverei, mit der JHWH sich erstmals unter seinem Namen offenbart und Israel zu seinem Bundesvolk „erwählt“ (Ex 3).
Erst in der Begegnung mit den orientalischen Großmächten und ihrer kosmogonischen Mythologie stellte Israel sein Werden in den größeren Rahmen der Erschaffung der Welt. Die Urgeschichte am Anfang der Bibel ist also der letzte Themenkomplex, der dem Pentateuch zugewachsen ist. Diesen durchzieht ein Spannungsbogen von der Verheißung zur Erfüllung, bezogen besonders auf das Stichwort des „Landes“, das Gott durch Unterscheidung von Himmel und Urflut schuf (Gen 1,1–12), um es Mose kurz vor seinem Tod als Erbe Israels zum Segen für alle Völker (Gen 12,3) zu zeigen (Dtn 34,1–4).

Das 1. Buch Mose, Genesis, enthält

Das 2. Buch Mose, Exodus, enthält

Das 3. Buch Mose, Leviticus, enthält

Das 4. Buch Mose, Numeri, enthält
In ihm sind weitere heterogene Kult- und Sozialgesetze verstreut, die man zum Priestergesetz zählt, das die Bücher 2 bis 4 durchzieht: darunter die Kapitel Num 15, 19, 27–31, 33 und 34, 35 und 36.

Das 5. Buch Mose, Deuteronomium enthält

Zu den in der Tora enthaltenen und in sich geschlossenen Gesetzeskorpora zählt man
Besondere Bedeutung als tägliches Gebet im Judentum hat das Schma Israel:

Die Verschriftlichung der Tora erfolgte in einem langen Überlieferungsprozess, in dem unterschiedliche Quellen und verschiedene redaktionelle Bearbeitungen Eingang gefunden haben. Der Pentateuch wurde spätestens etwa 440 v. Chr. zur Zeit Esras fertiggestellt und ab etwa 250 v. Chr. aus dem Althebräischen in die griechische Septuaginta und in aramäische Targume übersetzt (siehe Bibelübersetzung).

Die Tora war der erste Teil des Tanach, dem eine besondere Bedeutung als Heilige Schrift zuerkannt wurde und der somit zuerst kanonisiert war. Trotz der frühen Kanonisierung der Tora wurde das religionsgesetzliche Material der Tora im Frühjudentum diskutiert und weiterentwickelt und in einem langen, meist mündlichen Auslegungsprozess fortgeführt. Diese Auseinandersetzung der Rabbiner mit der Tora fand ihren Niederschlag in der Mischna und später in der Gemara, die zusammen den Talmud bilden, und war das Fundament des sich auf das Religionsgesetz, der Halacha, gründenden Judentums. Diese Fundierung war im Mittelalter selbstverständlich, wurde von der jüdischen Aufklärung an vor allem im aschkenasischen Judentum teilweise kritisiert und findet bis heute vor allem im orthodoxen Judentum seinen Ausdruck.

Der jüdische Talmud und das christliche Neue Testament schreiben diese fünf Bücher dem Mose zu und betrachten die Ereignisse von der Schöpfung bis zur Landverteilung in Kanaan (Dtn 33) als direkte Offenbarung Gottes an ihn. Das 5. Buch Mose endet mit dem Kapitel über seinen Tod (Dtn 34), das der Talmud demgemäß seinem Nachfolger Josua zuschreibt. Mose habe diese Offenbarung zuvor schriftlich festgehalten. Sie sei dann bis auf unwesentliche Kopierfehler wortgetreu überliefert worden: Diese Ansicht vertreten heute noch das orthodoxe Judentum und teilweise evangelikale Christen und verschiedene Gruppen des fundamentalistischen Christentums.

Die Autorschaft des Mose wurde schon im Mittelalter angezweifelt. Der jüdische Gelehrte Ibn Esra bemerkte, dass die Schriften die Ereignisse ohne Ich-Erzähler darstellen und zwischen der Zeit des Mose und der Zeit des Erzählers oder der Erzähler unterscheiden. Er sah Widersprüche, die Mose als Schriftautor ausschließen: So blickt z. B. Gen 12,6 auf die Zeit zurück, als Kanaanäer das Land noch bewohnten, weist also auf eine Aufzeichnung nach der Ansiedelung Israels in Kanaan hin. Ferner hielt Mose die Reden des 5. Buches nach Dtn 1,1 bis zu seinem Tod mündlich, so dass sie bereits ein anderer aufgezeichnet haben müsse.

Im 16. Jahrhundert bestritten Reformatoren wie Andreas Karlstadt die Autorschaft des Mose und sahen den Priester und Torakundigen Esra (etwa 440 v. Chr.) als Redaktor, der die fünf Bücher aus älteren Teilen der Tora zusammengestellt habe . Er erscheint auch im Talmud als Bearbeiter der Tora.

Thomas Hobbes stellte zahlreiche Aussagen aus dem Pentateuch zusammen, aber er sammelte nicht nur die Fakten, sondern zog auch den Schluss daraus, dass Mose nicht der alleinige Autor habe sein können.

Ebenfalls im 17. Jahrhundert veröffentlichte Baruch Spinoza die Beobachtungen Ibn Esras und leitete damit die historische Pentateuchkritik ein. Im Zuge der Aufklärung wurden dann verschiedene Theorien zur Entstehung des Pentateuch aufgestellt, auf denen die heutige Forschung aufbaut. Auf der Basis einer immer differenzierteren Textanalyse und neuerer archäologischer und altorientalistischer Forschungsergebnisse nehmen heute die meisten Forscher an, dass der Pentateuch seine redaktionelle Endgestalt erst nach dem babylonischen Exil im 5. Jahrhundert v. Chr. gewann. Sie wird auf die Priester in Israel, vor allem am Jerusalemer Tempel, zurückgeführt. Seine ältesten, lange Zeit mündlich überlieferten Stoffe reichen jedoch bis 1500 v. Chr. zurück.

Um ca. 440 v. Chr. wurde der Pentateuch als Tora kanonisiert und bildet seitdem den Hauptteil des Tanach mit normativem Charakter für die jüdische Religion. Eine Motivation dafür sieht die Forschung darin, einen Zusammenhalt der Volksstämme in Israel durch eine „definitive“ Religion sicherzustellen und Widersprüche in älteren heterogenen Überlieferungen auszugleichen.

Mit der Aufklärung begann in Europa die historisch-kritische Erforschung der Bibel. Seit dem 18. Jahrhundert wurde die Bibel nicht mehr nur in ihrer Funktion als geoffenbartes Wort Gottes rezipiert, sondern auch in ihrer Gestalt als historisch gewachsenes Buch wahrgenommen und untersucht. Die historisch-kritische Forschung räumte ab dem 18. Jahrhundert auf mit der über Jahrhunderte geltenden Vorstellung, Mose sei der Autor des Pentateuch. Die Autorenschaft des Mose wurde u. a. deshalb bestritten, da Mose nicht über Dinge hätte berichten können, die vor (Weltschöpfung in Gen 1 f.) oder nach ihm (Tod des Mose in Dtn 34) geschehen waren.

Die frühe Forschung beobachtete im gesamten Pentateuch verschiedene Unstimmigkeiten und Dopplungen, so zum Beispiel:

Bereits 1711 schloss der Hildesheimer Pfarrer Henning Bernward Witter daraus auf zwei verschiedene Autoren der Schöpfungsberichte in Gen 1,1 – 2,4 und Gen 2,5 – 3,24. Der erste dieser Autoren benutzte in Gen 1,1 – 2,4a den Gottestitel „Elohim“, der zweite in Gen 2,4b – 3,24 den Gottesnamen „JHWH“. Witters Beobachtungen wurden jedoch lange nicht rezipiert.

Erst der Franzose Jean Astruc, welcher der Leibarzt des französischen Königs Ludwig XV. war, baute die These Witters 1753 aus und stieß damit die kritische Forschung am Alten Testament an. Er rekonstruierte aus den Mehrfachüberlieferungen innerhalb des Pentateuchs, vor allem der Genesis, zwei durchlaufende und zwei weitere kürzere, ehedem selbständige Quellenschriften, die dem jetzigen Text zugrunde liegen. Diese Quellenschriften hätten je eigene Erzählungen der Frühzeit Israels enthalten und seien von Mose in vier Kolumnen (Astruc nennt diese Quellenschriften A, B, C und D) zusammengestellt worden. Ein späterer, nachmosaischer Redaktor habe die vier Quellen ineinandergearbeitet („redigiert“).

In Deutschland weitete Johann Gottfried Eichhorn 1781 die These Astrucs auf den Textkomplex Gen 1 – Ex 2 aus und schied die Quellen in einen vormosaischen "Elohist" (benannt nach der Verwendung des Gottestitels „Elohim“) und einen nachmosaischen "Jehowist" (benannt nach der Verwendung des Gottesnamens „JHWH“). Die Schreibung „Jehowist“ entspricht der damaligen Lesung des Gottesnamens „JHWH“, der bis ins 19. Jahrhundert als „Jehova(h)“ gelesen wurde.

Karl David Ilgen baute die These Eichhorns weiter aus, indem er noch einen zweiten Elohisten annahm und daher insgesamt drei Quellen unterschied. Forschungsgeschichtlich wurde diese Theorie unter der Bezeichnung Ältere Urkundenhypothese (auch: "Quellenhypothese") bekannt, da sie von mehreren (von der Schöpfung bis zur Landnahme reichenden) durchlaufenden Quellenschriften ausging, aus denen der heutige Textbestand des Pentateuchs zusammengearbeitet wurde.

Im 19. Jahrhundert entwickelten sich Gegentheorien, die die Entstehung des Pentateuchs anders zu rekonstruieren versuchten.

Die so genannte Fragmentenhypothese ging von zahlreichen, ehedem selbständigen "Erzählkränzen" aus, die erst sukzessive zu einer Gesamterzählung zusammengearbeitet wurden. Unter einem Erzählkranz versteht die Forschung eine in sich geschlossene Gruppe von Episoden zu einem bestimmten Thema oder einer bestimmten Person, wie etwa die Erzählungen um den Stammvater Abraham oder die Sintflut. Vertreter der Fragmentenhypothese waren der englische Pastor Alexander Geddes sowie der deutsche Forscher Johann Severin Vater.

Als eine Art Verbindung aus Urkunden- und Fragmentenhypothese entwickelte sich die Ergänzungshypothese (auch: "Grundschrifthypothese"), deren wichtigster Vertreter Wilhelm Martin Leberecht de Wette war. Nach seiner Rekonstruktion bestand die Genesis zunächst aus einer einzigen Grundschrift oder Quelle (nach de Wette: elohistisch), in die ein jehowistischer Redaktor nach und nach einzelne, im Umlauf befindliche Erzählkränze einarbeitete. De Wette beobachtete außerdem die Doppelung vieler Gesetze in Ex 20–23 und Dtn 12–26. Er interpretierte diesen Befund als einen weiteren Hinweis auf verschiedene Autoren und Redaktoren innerhalb der ersten vier Bücher Mose („Tetrateuch“) und des „Deuteronomiums“.

Über viele Jahre bestimmend wurde die so genannte Neuere Urkundenhypothese, die im ausgehenden 19. Jahrhundert von den Alttestamentlern Karl Heinrich Graf, Abraham Kuenen und vor allem von Julius Wellhausen entwickelt wurde.
Wellhausen formulierte in seinen "Prolegomena zur Geschichte Israels" (1886) die These, die Tora und das Buch Josua, die zusammen den sogenannten „Hexateuch“ bilden, seien aus mehreren fortlaufenden literarischen Quellen zusammengesetzt. Diese ließen sich anhand verschiedener Merkmale, wie etwa der Wahl der Gottesbezeichnung, bestimmten Vorzugsvokabulars oder der theologischen Ausrichtung, unterscheiden.

Wellhausen unterscheidet vier Quellen:

In die jahwistische Quellenschrift (J) arbeitete ein Redaktor (R) aus der Zeit unmittelbar nach dem Untergang des Nordreiches Israel im Jahre 722 v. Chr. die elohistische Quelle (E) ein und schuf so das „Jehowistische Geschichtswerk“ (JE). Dieses wurde dann in nachexilischer Zeit wiederum in die Priesterschrift eingearbeitet. Schließlich wurde von einem weiteren Redaktor (nach Wellhausen möglicherweise Esra) das Deuteronomium als eigene Größe hinzugefügt und so entstand der Pentateuch in seiner heutigen Gestalt. Wegen der vier von Wellhausen herausgearbeiteten Quellen wurde die Neuere Urkundenhypothese manchmal auch als „Vierquellentheorie“ bezeichnet. Obwohl viele Schlussfolgerungen Wellhausens heute nicht mehr vertreten werden, bleibt seine These ein Meilenstein der alttestamentlichen Forschung.

Martin Noth baute die These Wellhausens zu Beginn des 20. Jahrhunderts weiter aus und verhalf ihr durch seine "Überlieferungsgeschichtlichen Studien" (1948) zu langjähriger Geltung und breiter Rezeption in der alttestamentlichen Forschung.

Den Forschungsstand zur Mitte des 20. Jahrhunderts fasste der Alttestamentler Gerhard von Rad folgendermaßen zusammen:
Seit Beginn der 1970er Jahre wird die Neuere Urkundenhypothese zunehmend in Frage gestellt. Erst wurde die Existenz einer elohistischen Quellenschrift, dann die einer jahwistischen Quellenschrift in Frage gestellt (erstmals von Hans Heinrich Schmid). Bei J und E handelt es sich nach Ansicht der neueren Forschung insofern nicht um Quellen, als sie die Kriterien einer eigenständigen Quelle (sinnvoller Anfang, sinnvolles Ende, durchlaufender Erzählfaden und erkennbare Gesamtkonzeption) nicht erfüllen.

Daher geht die aktuelle Forschung meist nur noch von einer wirklichen "Quelle" innerhalb des Pentateuch aus, der "Priesterschrift". Allein die Priesterschrift besitzt einen von der Erschaffung der Welt bis zur Landnahme reichenden, durchgehenden Erzählfaden. Sie zeichnet sich durch eine klar erkennbare theologische Linie und wiederkehrende Formulierungen aus.

Alle anderen Texte, die zuvor J oder E zugewiesen wurden, werden heute in der Regel zu jüngeren Redaktionen gerechnet oder als ältere Einzeltraditionen angesehen, die keinen gesamten Geschichtsverlauf erzählen. Die Mehrzahl der neueren exegetischen Entwürfe – etwa von Reinhard Gregor Kratz, Erhard Blum, Eckart Otto, Erich Zenger, Jan Christian Gertz, Konrad Schmid, Markus Witte – spricht bei diesen Texten daher einfach von "vor-" oder "nicht-priesterschriftlichen Texten".

Auch das Deuteronomium kann streng genommen nicht als Quelle betrachtet werden, da es keinen gesamten Geschichtsverlauf erzählt. Es ist und bleibt in der Forschung stets eine Größe "sui generis". Es nimmt sowohl für die Entstehungsgeschichte des Pentateuch wie für die Entstehungsgeschichte des sogenannten Deuteronomistischen Geschichtswerkes eine Schlüsselstellung ein. Über seine genaue Verortung (Abschluss des Pentateuch oder Beginn des Deuteronomistischen Geschichtswerkes?) ist die Wissenschaft uneins.

Die alttestamentliche Einleitungswissenschaft durchläuft momentan einen Paradigmenwechsel, da die jahrelang geltenden Datierungs- und Entstehungsmodelle nicht mehr tragen. Auch inhaltlich vollzieht sich ein Wandel im Verständnis des Pentateuch. So wurde besonders die Figur des Mose als weithin redaktionelles Konstrukt „destruiert“, welches sekundär ganz verschiedene, ursprünglich selbstständig überlieferte Traditionskomplexe miteinander verbinden sollte: den Exodus Israels aus Ägypten, den Zug durch die Wüste, die Sinaioffenbarung und den Beginn der Landnahme.

Die lange für die Quellentheorie als beispielhaft und impulsgebend verstandene Josefsgeschichte verlor diese Rolle, seit "H. Schweizer" (1991) gezeigt hat, dass sich "ein" intakter, durchlaufender Erzählstrang "literarkritisch" gewinnen lässt, der aber durch massenhafte punktuelle redaktionelle Ergänzungen – darunter mit Gen 38.49 zwei komplette Kapitel – entstellt worden war. Die Vorstellung von „Quellen“ versagt hierbei komplett. Die ursprüngliche und künstlerisch hochstehende Erzählung ist durch Textmaterial in gleichem Umfang aufgebläht und verunstaltet worden.

Große Verbreitung hat in den letzten Jahren das sogenannte "Münsteraner Pentateuchmodell" erfahren; es stellt jedoch keinen Konsens der aktuellen Forschung dar. Das Modell geht auf Erich Zenger zurück. Zenger geht von drei Quellenschriften aus:
Die Texte, die in diesen Quellen vereint sind, sind verschieden alt und haben eine komplizierte Entstehungsgeschichte. Die endgültige Redaktion des Pentateuchs wird auf spätestens 400 v. Chr. geschätzt, da sich zu dieser Zeit die Samaritaner vom Jerusalemer Zentralheiligtum abspalteten und für sich nur die Tora, also den Pentateuch als Korpus heiliger Schriften anerkannten (siehe Samaritanischer Pentateuch). Somit muss die Entstehung des Pentateuchs zu dieser Zeit im Großen und Ganzen abgeschlossen gewesen sein.

Innerhalb des Judentums ist die herausragende Bedeutung der Tora unstrittig, da sie zur Grundlage für die religionsgesetzliche (halachische) Auslegung des rabbinischen Judentums wurde. Allerdings darf nicht übersehen werden, dass im weiteren Verlauf der jüdischen Geschichte nicht die Tora im Mittelpunkt des rabbinischen Interesses lag, sondern die religionsgesetzliche Diskussion, wie sie im Talmud zum Prinzip geworden ist. Zwar entstanden zum Text der Tora Midraschim, die im weitesten Sinn eine Auslegung der Tora darstellen, doch waren die rabbinischen Autoritäten an der halachischen Diskussion und später an der Festlegung halachischer Standards interessiert. Der Torakommentar von Raschi (1040–1105) geht in der Regel vom "Peschat" aus, das heißt der „einfachen“, wörtlichen Textbedeutung (siehe unten), und ist bis heute für das Studium der Tora von wegweisender Bedeutung.

Im orthodoxen Verständnis hat die Tora zwei Dimensionen – eine offenbarte und eine verborgene. Die offenbarte Dimension enthält die Gesetze der Tora, die ein Ausdruck des Willens Gottes sind. Im Hebräischen heißt dieser Aspekt "Gufej Tora" („Körper der Tora“) oder "Nigleh," die „offenbarte Dimension“. Neben dem „Körper“ der Tora gibt es auch die „Seele“ der Tora – die mystische Dimension. Sie birgt Einsichten über die göttliche Existenz und ihre Offenbarung, den Schöpfungsprozess und das Wesen der menschlichen Seele. Im Hebräischen wird dieser Aspekt auch "Sitrej Tora" genannt, die „Geheimnisse der Tora“, oder "Nistar," die „verborgene Dimension“.

Die unterschiedlichen Bedeutungsebenen der Tora werden in der orthodoxen Auffassung in 4 allgemeine Kategorien geteilt:

Aber auch innerhalb dieser vier Ebenen gibt es verschiedene Interpretationen der Tora. Auf der Ebene des "Peschat" etwa kennt das Judentum nicht eine, sondern mehrere Autoritäten (Raschi, Ibn Esra, Raschbam u.v.m.). Und trotz einheitlicher Grundausrichtung auf die wörtliche Interpretation kommen sie zu unterschiedlichen Lehrmeinungen über die einzelnen Verse und Ereignisse.

Der grundlegende Unterschied zwischen orthodoxem Judentum und den nicht-orthodoxen Strömungen (Reformjudentum und konservatives Judentum) ist das Verständnis der Offenbarung. Die orthodoxe Tradition innerhalb des Judentums betrachtet die Tora als "Gotteswort," das Mose am Berg Sinai von Gott selbst gegeben wurde. Es wird in einigen orthodoxen Kreisen durchaus eingeräumt, dass sich in der Tradierung des Gotteswortes hier und da einige Schreibfehler eingeschlichen haben könnten, das fechte die Tatsache, dass die Tora das Wort Gottes sei, jedoch nicht an. So ist dem orthodoxen Standpunkt ein Satz wie „Da erschuf Gott den Menschen in seinem Ebenbilde …“ (Gen 1,28) eine Tatsache, da das Wort Gottes per definitionem die Wahrheit selbst ist. Dies impliziert auch, dass jedes Wort der Tora einen Sinn haben muss, da kein Buchstabe Gottes Wortes überflüssig sein könne. Wo die modernen Wissenschaften mit dem Tanach in Widerspruch stünden, würde sich einmal zeigen, dass sie sich irrten.

Das liberale oder Reformjudentum sieht die Offenbarung als einen fortschreitenden Dialog des Volkes Gottes mit seinem Gott. Im nicht-orthodoxen Judentum wird die Tora heute mit Hilfe erkenntnistheoretischer Kriterien gedeutet. Das Gewissen, die Vernunft, ethische Überlegungen, Erkenntnisse der Natur-, Geistes- und Sozialwissenschaften beschränken die Bedeutung und die Auswirkung der Gebote und Verbote der Tora.

Die jüdische progressive Zivilisation ist in der Zeit von Menschenrechten, demokratischen Entscheidungen und Naturwissenschaften vor allem um die Einhaltung der Moralgesetze bemüht. Sie glaubt nicht, dass der Tanach, die Tora das unabänderliche Wort Gottes ist, aber dass diese im Kern göttlich inspiriert sind. Die Offenbarung ist ein fortschreitender Prozess. Gott offenbart die Inhalte seines Willens und seiner Gebote jeder Generation neu. Diese Haltung macht es möglich, die tradierte jüdische Rechtspraxis dort zu ändern, wo sie nach liberaler Auffassung den ethischen Normen des Judentums nicht mehr entspricht. Dazu zählen bestimmte Regeln in Bezug auf Scheidung, Mamser (d. h. ein aus einer inzestuösen oder ehebrecherischen Beziehung stammendes Kind), Kohanim (Priester), Homosexuelle usw. und vor allem die volle religiöse Gleichberechtigung von Frauen. Die Ausführung der Mitzwot wird in die verantwortliche Entscheidung des Einzelnen gestellt.

Das Reformjudentum bestimmt für sich Teile der Tradition, die immerwährende Bedeutung haben, getrennt von solchen, die zeitbedingt und relativ sind. Wertelemente der jüdischen Tradition und des Judentums von Dauer sind der Schabbat, das Streben nach Gerechtigkeit und die Heiligkeit des Lebens. Zeitbezügliche, relative Wertelemente sind zum Beispiel das Tempelopfer und die unbedingte Macht des Mannes über seine Frau (als juristische Sache).

Das Alte Testament (AT) ist dreigegliedert wie der Tanach. Der Pentateuch eröffnet die christliche Bibel. Dabei bildet die Tora jedoch keine eigene Einheit, sondern ist meist mit den "vorderen Propheten" (Josua, Richter, Samuel, Könige) und den Büchern Ruth, Chronik, Esra, Nehemia und Ester als Gruppe der "Geschichtsbücher" sortiert. Die katholische Kirche zählt zu den Geschichtsbüchern noch die Bücher "Tobit" und "Judith," die nicht Teil der hebräischen Bibel sind.

In anderer Reihenfolge bezüglich des Tanach folgen im AT die "Schriften" (Ketuvim) und erst dann die hinteren "Propheten" (Nevi’im). Mit der abweichenden Sortierung gehen im Christentum Abweichungen des Verständnisses des Pentateuchs einher. Die "fünf Bücher Mose" werden nicht mehr als Lehre, Gesetz gelesen, sondern als "Geschichtsbücher". Es stehen im Christentum nicht mehr die Lehren und Gesetze im Vordergrund, sondern die Verheißungen – besonders die Abraham-Verheißung – und die Erzählungen von Gottes geschichtlichem Handeln.

Da die christliche Kirche das Alte Testament (und damit auch die Tora) in ihren Kanon aufgenommen hatte, wurden inhaltliche Schwerpunkte der Tora wie Schöpfung oder Nächstenliebe zum Allgemeingut der westlich-christlichen Kultur.

In der frühchristlichen Theologie des Paulus erscheint allerdings als Gegenteil von Gnade auch das Gesetz (). Gemeint sind damit die Lehren und Traditionen des Judentums im Allgemeinen und im engeren Sinn die Tora. In diesem Zusammenhang erscheint Gnade als Proprium des Christentums, während vom Gesetz zumeist in abfälliger oder zumindest ablehnender Weise die Rede ist: Der Mensch könne durch das Gesetz nur einen Anschein von Rechtfertigung erlangen (Vorwurf des Versuchs der Selbsterlösung), während es wahrhafte Rechtfertigung nur (vermittels des Glaubens) durch die freie Gnade Gottes gebe.

Daraus entwickelte sich ein hegemonistischer Diskurs der Mehrheits- über die Minderheitsreligion, wobei Christen stärker als Juden den legalistischen, kasuistischen Charakter der Tora betonten. Weitere Vorurteile waren „Lohnmoral“, „Formalismus“, „Leiden unter dem Gesetz“ oder „Unerfüllbarkeit“ aller Einzelforderungen. Teils heute noch vielmals zitiert wird das „Auge-um-Auge-Prinzip“, das nach allgemeiner Auffassung den Rachegedanken bediene, während eine genauere Analyse (auch mithilfe rabbinischer Klärungen) die Begrenzung von Schadenersatzforderungen beinhaltet.

Im 19. Jahrhundert wurde die Einschätzung des Judentums als Religion des Gesetzes auf die nachexilische Zeit verschoben. Nach Julius Wellhausen sei dann jüdische Identität alleine definiert worden durch Befolgung – heteronom und willkürlich von Gott gesetzter – Vorschriften, nicht mehr durch die Erwählung Israels. Ed Parish Sanders brachte beides wieder zusammen und begründete eine "Neue Perspektive auf Paulus" mit. Heil werde auch nach jüdischer Vorstellung nicht durch Gesetzeserfüllung erreicht, sondern sei im von Gott ausgehenden Bund begründet. Dieser verlange Gehorsam dem Gesetz gegenüber, aber auch bei Übertretungen sei es durch in der Tora vorgesehene Sühnemittel möglich, im Bund zu verbleiben. Heute wird in der christlichen Theologie ein früheres Zerrbild vom Mosegesetz weithin kritisiert, und jüdische Interpretationen der Tora werden stärker beachtet.

In seiner Grundhaltung und Weltanschauung verweist der Islam auf das Erbe der Propheten und auf den klaren Monotheismus Abrahams (Ibrahim). Judentum und Christentum gelten dem Islam als Religionen, die auch einen Anteil an der göttlichen Offenbarung haben. Aus verschiedenen Suren des Korans (3:3, 3:50, 3:65, 5:43 ff., 5:66 ff., 5:110, 7:157, 9:111, 48:29, 61:6, 62:5) ist den gläubigen Muslimen geläufig, dass der Qurʾān (Koran) Wurzeln in der Tora (, auch als "tawrah", "tawrat" oder "taurat" transkribiert) hat.

Einige Bestimmungen der Tora werden im Qur'an zitiert, so das Prinzip „Auge um Auge“, welches aber relativiert wird:

Gemäß dem Koran wird auch das Auftreten des Propheten Mohammed (Muhammad) in der Tora prophezeit:

Nach geläufiger muslimischer Auffassung bezieht sich das auf .

Obwohl die Tora wie auch das Evangelium im Koran als heilige Schriften erwähnt werden, werden sie von Muslimen jedoch kaum studiert, da nach islamischer Auffassung die Originale von Tora und Evangelium (Indschil) verloren gegangen seien. So gelten die heutigen Versionen als verfälscht.

Aus muslimischer Sicht ist der Grund für die Ähnlichkeiten zwischen Qur'an und Tora, dass in der Tora trotz Veränderungen im Laufe der Zeit durch menschlichen Einfluss immer noch Elemente der ursprünglichen göttlichen Offenbarung enthalten und somit in der letzten Offenbarung Gottes (Allah), dem Qur'an, wiederzufinden sind.







</doc>
<doc id="10386" url="https://de.wikipedia.org/wiki?curid=10386" title="Thora (Begriffsklärung)">
Thora (Begriffsklärung)

Thora steht für:

Tora steht für:

TORA steht für:

Þóra steht für:

Siehe auch:



</doc>
<doc id="10388" url="https://de.wikipedia.org/wiki?curid=10388" title="Märkische Schweiz">
Märkische Schweiz

Die Märkische Schweiz ist ein Hügelland im Landkreis Märkisch-Oderland im Bundesland Brandenburg in (Deutschland).

Die Märkische Schweiz liegt knapp 30 km nordöstlich von Berlin auf der Hochfläche des Barnim. Das Landschaftsrelief wurde in den Eiszeiten geformt.
Die Märkische Schweiz ist teilweise als rund 205 km² großer Naturpark Märkische Schweiz ausgewiesen, wobei dessen Fläche nicht die gesamte Märkische Schweiz darstellt. Der Naturpark umfasst vor allem die südlich gelegenen Bereiche um Buckow, nicht jedoch die zentralen und nördlichen Bereiche um Bad Freienwalde (Oder). Im Gebiet des Naturparks gibt es mehrere Landschaftsschutz- und Naturschutzgebiete. Im Norden, bei Bad Freienwalde (Oder) und Falkenberg, grenzt die Märkische Schweiz direkt an das Biosphärenreservat Schorfheide-Chorin sowie an das Oderbruch, den größten Binnenpolder Deutschlands.

Die höchste Erhebung des hügeligen und waldreichen Gebietes ist der Semmelberg () bei Bad Freienwalde (Oder). Für brandenburgische Verhältnisse extrem reliefreich sind die dort liegenden saalezeitlichen Stauchungsgebiete. Mit Höhenunterschieden von deutlich mehr als 100 Meter auf weniger als 1 km Horizontalentfernung ist das Gebiet unmittelbar südlich von Bad Freienwalde das reliefstärkste in Brandenburg. Verstärkend für das Relief wirkte dort die Bildung von Trockentälern am Ende der Weichseleiszeit.

Geschichtlich werden die nördlichen Quellen der Märkischen Schweiz bereits im 17. Jahrhundert unter dem Großen Kurfürsten erwähnt, der wegen ihrer großen Heilkraft in Bad Freienwalde (Oder), damals noch Freienwalde, den Beginn der Bäderzeit einleitete. Auch heute noch lässt sich dies anhand der Bäderarchitektur des Ortes deutlich erkennen.

Seit den 1920er Jahren wurde Bad Freienwalde (Oder) zu einem beliebten Wintersportort der Berliner Bevölkerung.

Das zentrale Fließgewässer im Süden der Märkischen Schweiz ist der Stobber. Der Bach entspringt auf der Nordsee-Ostsee-Wasserscheide, sodass er zwei Fließrichtungen und Mündungen hat. Sein Scheitelbereich mit der Pseudobifurkation liegt in im Niedermoorgebiet Rotes Luch. Der kürzere südwestliche Teil vereinigt sich nach rund 6 Kilometern zwischen dem Maxsee und dem Liebenberger See mit dem aus dem Maxsee kommenden "Mühlenfließ" zur Löcknitz, die über den Flakensee und Dämeritzsee in die Spree und damit über die Havel und Elbe in die Nordsee entwässert. Dieser kürzere Teil des Stobber wird zur Unterscheidung heute zumeist als Stobberbach oder Stöbberbach bezeichnet; bis in das 19. Jahrhundert hieß dieser Wasserlauf "Köpernitz". Der 25 Kilometer lange nordöstliche Hauptteil fließt vom Roten Luch durch Buckow zum Oderbruch. Er vereinigt sich bei Altfriedland mit dem "Quappendorfer Kanal" zum Friedländer Strom, dessen Wasser über die Alte Oder, die Hohensaaten-Friedrichsthaler Wasserstraße und die Oder im Stettiner Haff der Ostsee zugeführt wird. Die Alte Oder ist auch jener Fluss, welcher die Märkische Schweiz im Osten und Norden abgrenzt. In sie münden die zahlreichen klaren Bäche des Hohen Barnim, welche in den zentralen und nördlichen Bereichen der Märkischen Schweiz entspringen.

Als touristischer Mittelpunkt im Süden der Märkischen Schweiz gilt traditionell die zentral innerhalb des Naturparks gelegene Stadt Buckow, ein Kneippkurort. Im Norden ist es die Stadt Bad Freienwalde (Oder), zugleich der älteste Kurort der Mark Brandenburg und Moorheilbad.

In der Märkischen Schweiz besteht heute der nördlichste Trainingsstandort des Deutschen Skiverbandes. Entlang der Trockentäler befindet sich auch die einst längste Naturrodelbahn des Norddeutschen Tieflandes. Auf einer Länge von 870 m werden etwa 80 Höhenmeter überwunden.

Theodor Fontane beschrieb die Region in Wanderungen durch die Mark Brandenburg wie folgt:

"Wo liegt denn nun aber die wirkliche Märkische Schweiz? Wir werden uns einen Dualismus, wie auch sonst wohl, gefallen lassen müssen. Freienwalde ist immerhin eine Dame, Buckow ist eine ländliche Schönheit, die mit nacktem Fuß in den See tritt und unter Weidenzweigen ihr Haar flicht. Nun wähle jeder nach seinem Sinn" (Theodor Fontane, Wanderungen durch die Mark Brandenburg II, Das Oderland, Das Oderbruch und seine Umgebungen, 1892).

Der Große Brockhaus in seiner Ausgabe von 1929 (15. Auflage) verdeutlicht mit seinem Kartenmaterial die Lage der Märksichen Schweiz (vgl. Abb.).




</doc>
<doc id="10389" url="https://de.wikipedia.org/wiki?curid=10389" title="Herrschaft Ruppin">
Herrschaft Ruppin

Das Herrschaft Ruppin (auch "Land Ruppin", "Grafschaft Ruppin") war von etwa 1214 bis 1524 ein Territorium innerhalb des Heiligen Römischen Reiches im Besitz der Grafen von Lindow-Ruppin. In ihrer Anfangszeit war sie vermutlich reichsunmittelbar. Später wurde die Herrschaft um Lehen der Markgrafen von Brandenburg erweitert und kam im weiteren Verlauf wahrscheinlich vollends unter die Oberhoheit der Markgrafen. Nach dem Erlöschen des Adelsgeschlechts Lindow-Ruppin fiel die Herrschaft an die Mark Brandenburg und bildete fortan den Kreis Ruppin. Das ehemalige Gebiet der Herrschaft bildet als Ruppiner Land eine historische Landschaft in Brandenburg.

Das Gebiet der späteren Herrschaft Ruppin war seit dem 1. Jahrhundert nur schwach besiedelt. Vermutlich ab dem 6. Jahrhundert wanderten slawische Stämme aus dem Osten ein. Seit spätestens 948 bewohnte der elbslawische Stamm der Zamzizi das Gebiet. Ihr politisches Zentrum war vermutlich die Slawenburg Ruppin auf einer Insel im Ruppiner See. Daneben bildete der Burgwall Altfriesack am Nordufer des Bützsees vermutlich einen weiteren kultischen Mittelpunkt. Am Westufer des Ruppiner Sees lag der Burgwall Treskow. In der zweiten Hälfte des 12. Jahrhunderts kam das Gebiet nach dem Wendenkreuzzug 1147 unter deutsche Oberhoheit und die deutsche Ostsiedlung setzte in dem Gebiet ein.

Um 1214 gelangte die Gegend zwischen den Flüssen Temnitz und Rhin als vermutlich reichsunmittelbare Herrschaft Ruppin in den Besitz des edelfreien Grafen Gebhard von Arnstein (* 1180/1209; † um 1256), eines Urenkels Albrechts des Bären. Er ist der erste historisch belegte Herr zu Ruppin und Stammvater der Grafen von Lindow-Ruppin, die eine Nebenlinie der Grafen von Arnstein bildeten und bis 1524 im Besitz der Herrschaft blieben. Der Name Lindow-Ruppin bezieht sich neben der Herrschaft Ruppin auf die Herrschaft Lindau (auch "Herrschaft Lindow") in Anhalt, die ebenfalls im Besitz des Adelsgeschlechts war.

Aufgrund des Grafentitels derer von Lindow-Ruppin wurde die Herrschaft Ruppin seit dem Ende des 13. Jahrhunderts auch als "Grafschaft Ruppin" bezeichnet. Trotzdem war Ruppin eine Herrschaft, keine Grafschaft. Das Wappen der Herrschaft Ruppin zeigte ähnlich dem der Grafen von Lindow-Ruppin in Rot einen silbernen Adler goldbewehrt.

Kurz nach 1220 hatte Gebhard das Gebiet seiner Herrschaft nach Osten bis an die Grenzen der Länder Gransee und Löwenberg erweitert. Er baute die Burg Ruppin (auch "Planenburg") zu Alt Ruppin in unmittelbarer Nähe der ehemaligen Slawenburg Ruppin als politisches Zentrum der Herrschaft aus. Die Burg Wildberg war vermutlich ebenfalls in seinem Besitz. Fünf Kilometer südwestlich der Burg Ruppin gründete Gebhart die Siedlung Neuruppin als wirtschaftliches Zentrum der Herrschaft Ruppin; sie wurde 1238 erstmals schriftlich erwähnt. Zwischen 1230 und 1240 stiftete Gebhart das Zisterziensernonnenkloster Lindow. Im Jahr 1240 nahm er seinen ständigen Wohnsitz in der Burg Ruppin. 1246 gründete Gebhards Bruder Wichmann von Arnstein (* um 1185; † 1270) das Dominikanerkloster Neuruppin und wurde dessen erster Prior.

Die Siedlung Neuruppin erhielt 1256 unter Gebhards Sohn Günther I. von Lindow (* um 1230; † um 1284) das Stadtrecht. Im Verlauf des 13. Jahrhunderts wurde das Gebiet der Herrschaft Ruppin nach Norden bis zur Linie Goldbeck–Rheinsberg–Menz erweitert. Um 1300 wurde die Burg Goldbeck angelegt. 1349 kamen die Länder Wusterhausen und Gransee als Lehen des Markgrafen von Brandenburg hinzu, nachdem sie seit 1317 bereits in Pfandbesitz der Grafen von Lindow-Ruppin waren. 1407 wurde Neustadt Teil der Herrschaft Ruppin.

Trotz der zu diesem Zeitpunkt vermutlich bereits bestehenden Oberhoheit der Markgrafen von Brandenburg wurde die Herrschaft Ruppin als Territorium des 1512 geschaffenen Obersächsischen Reichskreises geführt. Gemäß der Reichsmatrikel von 1521 hatte die Herrschaft Ruppin drei Soldaten zu Pferd, zwölf Soldaten zu Fuß und 42 Gulden für die Reichsarmee zu stellen.

1524 erlosch das Adelsgeschlecht Lindow-Ruppin mit dem Tod des Grafen Wichmann. Die Herrschaft Ruppin wurde daraufhin vollständig durch Kurfürst Joachim I. von Brandenburg eingezogen und mit der Mark Brandenburg vereinigt. Sie blieb als ständische und steuerliche Einheit erhalten und bildete fortan den Kreis Ruppin der Mittelmark. Verwandte des verstorbenen Grafen Wichmann klagten 1541 vor dem Reichskammergericht gegen die Einziehung der Herrschaft durch den Kurfürsten. Die Klage wurde 1562 abgewiesen.



</doc>
<doc id="10390" url="https://de.wikipedia.org/wiki?curid=10390" title="Bill Mollison">
Bill Mollison

Bruce Charles „Bill“ Mollison (* 4. Mai 1928 in Tasmanien, Australien; † 24. September 2016 in Sisters Beach, Tasmanien) galt, gemeinsam mit David Holmgren, als „Vater der Permakultur“. 1978 gründete er das Institut für Permakultur (Permaculture Institute), das sich der Verbreitung der Permakultur in Bildung, Forschung und durch konkrete Umsetzung widmet. 1981 wurde er mit dem Right Livelihood Award ausgezeichnet.




</doc>
<doc id="10393" url="https://de.wikipedia.org/wiki?curid=10393" title="Ford">
Ford

Die Ford Motor Company mit Sitz im US-amerikanischen Dearborn ist nach Toyota, Volkswagen, General Motors und Hyundai der fünftgrößte Autohersteller weltweit (Stand 2014). Mit einem Umsatz von 151,8 Milliarden US-Dollar, bei einem Gewinn von 4,9 Milliarden US-Dollar, steht Ford laut den Forbes Global 2000 auf Platz 64 der weltgrößten Unternehmen (Stand 2017). Das Unternehmen kam Anfang 2017 auf eine Marktkapitalisierung von 44,7 Mrd. USD.

Ursprung des Konzerns ist eine von Henry Ford in Detroit 1903 gegründete Fabrik. Mit der Einführung der Fließbandproduktion im Jahr 1913 brachte Ford einen radikalen Umbruch in der neu entstehenden Autoindustrie.

Die Ford Motor Company war Henry Fords zweiter Start in die Unabhängigkeit. 1899 hatte er die Detroit Automobile Company gegründet. Sie war nicht erfolgreich und wurde bereits 1901 unter der Bezeichnung Henry Ford Company reorganisiert. Im März 1902 kam es auch hier zu Unstimmigkeiten im Management. Ford war auf der Suche nach einem Auto für eine breite Kundschaft, die Geldgeber, vor allem William Murphy und Lemuel Bowen, wollten vielmehr teure, lukrative Fahrzeuge bauen. Ford verließ die erste Firma, die seinen Namen trug. Im August 1902 übernahm Henry M. Leland, der spätere Mitbegründer von Lincoln, die Geschäfte und benannte die Firma in Cadillac um.

Am 16. Juni 1903 gründete Henry Ford mit einem Kapital von 28.000 US-Dollar in Detroit (Michigan) mit der "Ford Motor Company" erneut ein eigenes Unternehmen. Er benannte seine Fahrzeuge zunächst nach dem Alphabet und produzierte täglich nur wenige Autos in seinem Werk an der Mack Avenue, wo Gruppen von zwei bis drei Männern zugelieferte Teile zusammenbauten. In den ersten beiden Jahren wurden von den Typen Modell A, C und AC nur ca. 1700 Stück hergestellt.

Nach dem anfänglich geringen Erfolg ließ er 1904 in Detroit die "Piquette Avenue Plant" bauen, wo ab 1908 das als „Tin Lizzy“ bekannte Ford Modell T produziert wurde, das schnell zum Verkaufserfolg wurde. Um die vom Markt geforderten Zahlen herzustellen, zog das Unternehmen bereits 1910 in die "Highland Park Ford Plant", wo bis 1913 die neue Technik der Fließbandproduktion perfektioniert wurde. Henry Ford übernahm das damals schon über 100 Jahre alte Konzept des Austauschbaus von Eli Whitney, der auch die erste Fertigungsstraße entworfen hatte. Mit größtenteils angelernten Kräften konnten so die Wagen günstiger und schneller hergestellt werden. Die Montagezeit eines Autochassis verringerte sich von über zwölf auf zuletzt nur noch 1,5 Stunden. Im Jahre 1918 war die Hälfte aller Autos in den USA ein „Modell T“. Zu dem Wagen bemerkte Ford in seinen Lebenserinnerungen, seine Kunden könnten ihn in jeder Farbe der Welt bekommen – solange sie schwarz sei. (Original: „Any customer can have a car painted any colour that he wants so long as it is black.“ Mein Leben und Werk, 1922) Als die Produktion 1927 eingestellt wurde, hatte das Unternehmen über 15 Millionen „Tin Lizzy“ hergestellt. Diese Zahl wurde erst Anfang 1972 vom VW Käfer übertroffen.

Am 1. Januar 1919 folgte Edsel Ford seinem Vater an die Spitze des Konzerns, dieser behielt aber trotzdem Einfluss auf das Management. In den 1920er Jahren verlor die Firma Marktanteile. Ihr erklärtes Ziel war, ein günstiges Auto zu bauen, das sich jeder Arbeiter leisten konnte. Um die Preise gering zu halten, bot man keine Zusatzausstattung an. General Motors und andere Firmen hatten schon begonnen, Autos auch in anderen Farben anzubieten, teilweise besser ausgestattet und auch luxuriöser. Diese Firmen hoben auch den Kreditrahmen der Kunden an, sodass sie sich die teureren Autos leisten konnten. Ford beklagte damals, die Kredite schädigten die Wirtschaft, aber aufgrund von Marktzwängen fügte sich Ford schließlich in die Rolle des „zweiten Siegers“.

Mit der Produktion von Traktoren der Marke Fordson (Henry Ford and Son) erschloss der Konzern ab 1917 einen zusätzlichen Markt. Die "Fordson"-Traktoren wurden ab 1964 unter dem Namen "Ford" weiter produziert. Das Landmaschinengeschäft erweiterte die Firma durch den Aufkauf von "New Holland" 1986 beträchtlich; weiterhin wurde 1987 der kanadische Landmaschinenhersteller "Versatile" übernommen. Bereits 1991 wurde die Landmaschinensparte – und damit New Holland und Versatile – an Fiat verkauft. Mit diesem Verkauf wurde Fiat auch zugesichert, Traktoren unter der Marke Ford bis zum Jahr 2000 verkaufen zu können.

Zur Produktion von Bombenflugzeugen des Typs B-24 Liberator eröffnete Ford in der Nähe von Ypsilanti (Michigan) Anfang der 1940er Jahre die "Willow Run Factory". Dort wurden mit Lizenz der Consolidated Aircraft über 8600 Maschinen hergestellt. Nach Einstellung der Flugzeugproduktion 1945 übernahm der Autohersteller Kaiser Motors das Werk.

1951 gründete Ford ein wissenschaftliches Labor in Dearborn (Michigan) zur Grundlagenforschung. Dies führte zu einer für Ford bemerkenswerten Mitwirkung in der Supraleiter-Forschung. 1964 landete Ford Research Lab einen fundamentalen Durchbruch mit der Erfindung der supraleitenden Quanteninterferenzeinheit SQUID.

Im Jahre 1955 wurde Ford eine Aktiengesellschaft.

Zunächst basierend auf dem Ford T-Modell wurden auch Nutzfahrzeuge hergestellt, die sich bald zu eigenständigen Modellen weiterentwickelten und bis in mittlere Nutzlastklassen reichten. In Deutschland wurde die Produktion von Lastwagen oberhalb des 1953 vorgestellten Kleintransporters Transit 1961 zunächst eingestellt.

1961 erwarb man Philco, einen Hersteller von Fernsehgeräten, Radios und weiteren Elektrogeräten.

1973 stellte Ford erneut zwei Lastwagenmodelle für den europäischen Markt vor, 1975 folgte der Schwerlastwagen-Typ Transcontinental. Die leichteren Modelle wurden 1981 durch einen einheitlichen Nachfolger ersetzt, der Ende der 1980er Jahre ersatzlos eingestellt wurde. Seitdem ist Ford im Lastwagensektor in Europa nicht mehr vertreten. In den USA wurde 1997 die bis dahin stets durchgehende Lkw-Produktpalette bis auf zwei Serien von kompakten Hauben-Lkw aufgegeben und die Sparte der schweren Lkw (Heavy-Truck-Division) an Freightliner verkauft.

1989 übernahm Ford die Firma Jaguar, weitere zehn Jahre später, 1999, die Pkw-Produktion und die zugehörigen Markenrechte von Volvo.

1990 verkaufte Ford das Tochterunternehmen "Ford Aerospace" an die Loral Corporation, wo dieses heute als Space Systems/Loral firmiert. Im selben Jahr erwarb Ford eine Beteiligung in Höhe von 10,8 % an Cummins Engine.

Ab dem Jahr 2000 geriet Ford durch eine falsche Modellpolitik auf dem Heimatmarkt in eine schwere Krise. Der Konzern hatte sich auf die renditestarken SUVs (Ford Explorer) und Pick-ups (Ford F-Serie) gestützt und den Markt für kompakte Pkw gegenüber ausländischen Herstellern vernachlässigt. Der damit einhergehende Verlust an Marktanteilen wurde lange ignoriert. Nachdem SUVs, Pickups und andere große Wagen wegen gestiegener Benzinpreise schwieriger abzusetzen waren, sah sich Ford wegen anhaltender Auslastungsprobleme in seinen Werken einer Rabattschlacht ähnlich wie General Motors und Chrysler ausgesetzt.

Der von 2006 bis Mitte 2014 amtierende Chef des Ford-Konzerns, Alan Mulally, hatte deswegen ein drastisches Sanierungsprogramm beschlossen, das ca. 11 Milliarden US-Dollar kostete und in dessen Rahmen 44.000 Arbeitsplätze abgebaut werden sollten. Bis zu 16 Produktionsstandorten drohte in diesem Zusammenhang die Schließung. Mit einem sukzessiv neu zu entwickelnden Modellprogramm sollte die Wende zu sparsameren Fahrzeugen geschafft werden. Dabei gehe der Trend verstärkt zu kompakten Fahrzeugen sowohl im Mittelklassesegment als auch im Segment der SUV, wo der Trend weg von schweren Geländewagen hin zu leichteren sogenannten Crossover-Modellen wie den Modellen Edge und Freestyle gehe.

Im Juni 2007 berichtete die Financial Times, dass Ford die britischen Tochtergesellschaften Jaguar und Land Rover über die Investmentbanken Goldman Sachs, Morgan Stanley und HSBC verkaufen wolle. Analysten zufolge sollten beide Sparten im Paket rund 10 Milliarden US-Dollar wert sein. Der indische Konzern Tata Motors übernahm im März 2008 beide Firmen.

Auf dem US-Automarkt wurde Ford 2007 bei den Absatzzahlen von Toyota überholt und steht damit in den Vereinigten Staaten hinter General Motors und Toyota auf Rang 3. Im Januar 2008 informierte Ford über ein neues Abfindungsprogramm, um sich nochmals von 13.000 Beschäftigten zu trennen.
Nach einem schlechten Geschäftsjahr 2009, der Umstrukturierung des Konzerns und einer Fokussierung auf Kleinwagen konnte im ersten Quartal 2010 ein Überschuss von 2,1 Milliarden US-Dollar erwirtschaftet werden. Das Vorjahresergebnis des Vergleichszeitraums lag noch bei einem Verlust von 1,4 Milliarden US-Dollar. Gleichzeitig steigert Ford seinen Marktanteil in den USA um 2,7 Prozentpunkte auf 16,6 Prozent und lag somit vor dem insolventen General Motors-Konzern.

Am 9. Dezember 2011 gab Ford bekannt, im kommenden März nach fünf Jahren zum ersten Mal wieder Dividende ausschütten zu wollen. Gründe seien die gute wirtschaftliche Entwicklung des Unternehmens sowie die Hoffnung auf Rückgewinnung des Vertrauens von Investoren.

Am 31. August 2012 baute Ford, nach 109-jähriger Unternehmensgeschichte, das 350-millionste Auto. Es handelt sich um einen roten Ford Focus, der in der thailändischen Fabrik in Rayong vom Band rollte.

Als deutsches Tochterunternehmen wurde 1925 in Berlin die "Ford Motor Company Aktiengesellschaft" gegründet. Nach Verlegung des Unternehmenssitzes nach Köln im Jahr 1930 wurde die Firma 1939 in "Ford-Werke AG" geändert. Nach einem Ausschluss von Minderheitsaktionären („squeeze-out“) im Jahre 2002, bei dem die "Ford Deutschland Holding GmbH" über 95 % der Anteile der deutschen Ford-Werke-AG-Aktien erwarb, folgte im November 2004 die Umwandlung der Rechtsform in "Ford-Werke GmbH".

Neben der Marke "Ford" gehören die Automobilmarken Lincoln und Troller zum Konzern. Die 1989 bzw. 2000 übernommenen Marken Jaguar bzw. Land Rover wurden im März 2008 an die Tata-Gruppe verkauft. Die Marke Mercury wurde 2010 eingestellt. Von 1979 bis 2015 war die "Ford Motor Company" an Mazda beteiligt. Unter der Marke Motorcraft werden Ersatzteile vertrieben. Weitere Marken, die nicht direkt mit Automobilherstellung und dem Ersatzteilgeschäft zu tun haben, veräußerte Ford in den vergangenen Jahren wegen der Konzentration auf das Kerngeschäft, so etwa die Autovermietung Hertz, oder stellte sie ein, wie die Discount-Werkstättenkette Kwik-Fit. Am 23. Dezember 2009 wurde bekannt, dass Ford im ersten Quartal 2010 die angeschlagene schwedische Automobilmarke Volvo für zwei Milliarden US-Dollar an den chinesischen Automobilhersteller Geely verkaufen will.









Ford stellte seit 1908 auch Nutzfahrzeuge her, die zunächst aus dem Ford T-Modell abgeleitet waren und sich bald eigenständig weiterentwickelten. Ford Nutzfahrzeuge wurden neben den USA beispielsweise in Argentinien, Australien, Brasilien, Deutschland, Frankreich, Großbritannien, Indien, Kanada, den Niederlanden, den Philippinen, Spanien sowie der Türkei produziert, vertrieben oder in Lizenz hergestellt, darunter in Kanada auch unter der Marke Mercury, in Großbritannien auch als Fordson und Ford Thames sowie in Spanien in Lizenz unter der Marke Ebro.

Die meisten dieser Produktions- und Vertriebszweige sind mittlerweile erloschen. Die US-Aktivitäten oberhalb der Leichtlastwagen wurden 1997 an die Daimler-Tochter Freightliner verkauft, die sie unter dem Markennamen Sterling Trucks weiterführt. In Deutschland wurde die LKW-Fertigung oberhalb des Kleintransporters Transit 1961 aufgegeben, erlebte seit 1973 eine Wiederbelebung und endete Ende der 1980er Jahre erneut, als die noch vorhandenen Fertigungsstätten an Iveco verkauft wurden. Ford ist in Europa seit 1953 mit dem Kleintransporter Ford Transit erfolgreich im Markt vertreten, der gegenwärtig in der sechsten Generation gefertigt wird.






</doc>
<doc id="10396" url="https://de.wikipedia.org/wiki?curid=10396" title="Wasserstoffantrieb">
Wasserstoffantrieb

Als Wasserstoffantrieb wird umgangssprachlich eine Antriebsart bezeichnet, welche Wasserstoff als Treibstoff oder Kraftstoff nutzt. Außer beim Raketenantrieb und der Strahlturbine, die tatsächlich die Kraft des ausströmenden, verbrannten Wasserstoffes als Antriebsenergie direkt nutzen, wird im Regelfall der Wasserstoff lediglich als Energieträger für ein nachgeordnetes Antriebssystem eingesetzt.

Im Wesentlichen lassen sich folgende Konzepte unterscheiden:

Der als Treibstoff dienende Wasserstoff ist keine Primärenergie, sondern muss analog zur Stromerzeugung, aus Primärenergie hergestellt werden. Zu seiner Herstellung ist Energie erforderlich. Diese wird bei der chemischen Reaktion in einem Wasserstoffverbrennungsmotor oder in der Brennstoffzelle teilweise wieder freigesetzt. Wasserstoffgas enthält aufgrund seiner geringen Dichte massebezogen mehr Energie pro Gewichtseinheit als jeder andere chemische Brennstoff. Allerdings ist die Energiedichte volumenbezogen sehr gering. Daher muss Wasserstoff als Treibstoff entweder stark komprimiert (bis etwa 700 bar) oder verflüssigt (−253 °C) werden. Beides ist mit zusätzlichem Energieeinsatz verbunden.

Die Abgase einer Brennstoffzelle bestehen aus reinem Wasserdampf.

Bei der Verbrennung von Wasserstoff in Verbindung mit Luft (in einer Gasturbine) enthalten die Abgase zusätzlich Stickoxide, die bei den hohen Temperaturen im Brennraum aus dem Luftstickstoff entstehen. Bei hohem Luftüberschuss (λ»1) entstehen weniger Stickoxide, allerdings sinkt dann auch der Wirkungsgrad. Bei Kolbenmotoren gelangen weiterhin Spuren von CO und CH in das Abgas. Sie stammen vom Schmieröl zwischen Zylinderwand und Kolben und von der Kurbelgehäuseentlüftung.

Die wesentlichen Verfahren zur Wasserstofferzeugung sind 

Die technischen Probleme bei der Speicherung von Wasserstoff gelten heute als gelöst. Verfahren wie Druck- und Flüssigwasserstoffspeicherung und die Speicherung in Metallhydriden befinden sich im kommerziellen Einsatz. Daneben existieren weitere Verfahren wie die Speicherung in Nanoröhren oder als chemische Verbindung ("N"-Ethylcarbazol), die sich noch im Stadium der Entwicklung oder in der Grundlagenforschung befinden.

Als Voraussetzung für die breite Anwendung von Wasserstoffantrieben gilt die Herstellung der Versorgungsinfrastruktur. Um in Deutschland ein flächendeckendes Netz zu erhalten, sind ca. 1000 Wasserstofftankstellen erforderlich.

Weltweit existieren ca. 274 Wasserstofftankstellen (Stand Mai 2017). In Deutschland sind es ca. 30, davon werden nur 7 öffentlich betrieben. Der Daimler Konzern wird in Zusammenarbeit mit der Linde AG weitere 20 Wasserstofftankstellen bauen, um zunächst durchgängige Verbindungen auf der Nord-Süd- und der Ost-West-Achse zu gewährleisten. → "Siehe auch : Hydrogen highway"

Eine Wasserstofftankstelle kostet ca. 1 bis 1,5 Mio. Euro.

 Wasserstoff/Sauerstoff-Gemische werden als Treibstoff von Raketentriebwerken verwendet, so z.B. in den Saturn-Raketen. Die Außentanks des Space Shuttle waren im Gegensatz zu den Rocket Boostern mit flüssigem Wasserstoff (−253 °C) und flüssigem Sauerstoff (−190 °C) gefüllt. Im Außentank war ein größerer Wasserstofftank im unteren Teil sowie ein kleinerer Sauerstofftank im oberen Teil. An der Außenseite des Tanks verliefen Leitungen, die den Wasserstoff und den Sauerstoff in den Orbiter leiteten, wo die Flüssigkeiten dann in den Haupttriebwerken des Shuttles verbrannt wurden. Der Wasserstofftank bestand aus verstärktem Aluminium.

Auf der Hamburger Alster verkehrte von 2007 bis 2013 ein Fahrgastschiff für 100 Passagiere, das durch Strom (ca. 100 kW) aus Brennstoffzellen angetrieben wird. Die Kosten der Brennstoffzellen betrugen 3 Mio. Euro, das komplette Schiff kostete 5 Mio. Euro. Es wurde im Rahmen des Projektes Zemships entwickelt. Die Stilllegung erfolgte wegen Außerbetriebnahme der H-Tankstelle wegen Unwirtschaftlichkeit.

Als wasserstoffbetriebenes Hochseeschiff befindet sich die norwegische Viking Lady im Einsatz. Sie ist ein Versorgungsschiff für Bohrplattformen, das 2009 zusätzlich zum dieselelektrischen Antrieb mit einer Brennstoffzelle ausgerüstet wurde. Diese wird wie der konventionelle Antrieb mit LNG (verflüssigtem Erdgas) betrieben.

Bei der U-Boot-Klasse 212 A und den neueren Booten der Dolphin-Klasse werden Brennstoffzellenantriebe eingesetzt. Die neun wassergekühlten Polymer-Elektrolyt-Membran-Brennstoffzellenmodule leisten insgesamt 306 kW. Sie werden mit Sauerstoff aus Drucktanks und Wasserstoff aus Metallhydridspeichern versorgt. Das anfallende Wasser wird als Brauchwasser genutzt. Das aus den Brennstoffzellen kommende Kühlwasser erwärmt den Metallhydridspeicher, um den Wasserstoff auszutreiben.

Das DeepC (in englischer Aussprache: Tiefsee) ist ein wasserstoffbetriebenes, unbemanntes Unterwasserfahrzeug. Es wurde 2004 in Betrieb genommen. Inzwischen ist das Projekt beendet.

Heutzutage wird Wasserstoff noch aus fossilen Energien hergestellt und weist somit gegenüber der direkten Verbrennung fossiler Energieträger keine Umweltvorteile auf. Im Rahmen der weltweiten stattfindenden Transformation hin zu nachhaltigen Energiesystemen mittels Erneuerbaren Energien, der sog. Energiewende, ist vorgesehen, Wasserstoff entweder direkt durch Künstliche Photosynthese oder indirekt mittels Elektrolyse aus erneuerbaren Energien, insbesondere Windenergie, Solarenergie und Wasserkraft herzustellen. Dieser Wasserstoff kann dann emissionsfrei in Wasserstoffantrieben genutzt werden.

Wasserstoffantriebe werden mit anderen Antriebsformen konkurrieren, in Zukunft im motorisierten Individualverkehr vorwiegend mit Elektroautos. Hierbei ist jedoch zu berücksichtigen, dass mit regenerativ erzeugten Wasserstoff betriebene Autos zwar einerseits effizienter und sauberer sind als fossil betriebene Fahrzeuge, Elektrofahrzeuge aber andererseits wieder deutlich effizienter als Wasserstofffahrzeuge. Aus Sicht der Energieeffizienz sind batteriebetriebene Elektrofahrzeuge demnach sinnvoller als Wasserstofffahrzeuge, da sie deutlich weniger Strom benötigen als beim Umweg über Wasserstoff. Allerdings ist Wasserstoff für Anwendungen notwendig, in denen batteriebetriebene Fahrzeuge nicht sinnvoll eingesetzt werden können, beispielsweise im Schwerlastverkehr, Flugverkehr oder Schiffsverkehr. Da sowohl die Wasserstoffherstellung als auch die Rückverstromung in den Brennstoffzellen des Wasserstofffahrzeugs verlustintensiv sind, benötigen Wasserstofffahrzeuge für dieselbe Strecke etwa 2,2-mal so viel elektrische Energie wie batteriebetriebene Elektroautos. 

Mazda verleast seit März 2006 den Wasserstoff RX-8 und ist somit der erste Autohersteller, der ein Fahrzeug mit Wasserstoffverbrennungsmotor anbietet.

BMW ist der zweite Hersteller, der einen Wasserstoffverbrennungsmotor für PKWs zur Serienreife gebracht hat. Der Motor kann sowohl mit Wasserstoff als auch mit Benzin betrieben werden. BMW hat auf der Auto-Show 2006 in Los Angeles das ab November 2007 erhältliche Modell 760h „Hydrogen 7“ vorgestellt. Es basiert auf dem 760i der BMW-7er-Reihe und kann von BMW geleast werden (ein Verkauf ist derzeit nicht vorgesehen). Der herkömmliche 12-Zylinder Verbrennungsmotor der 7er Reihe wurde dabei für die Verbrennung von Wasserstoff und Benzin modifiziert. Die Speicherung erfolgt als Flüssigwasserstoff. Für die Wasserstoffverflüssigung (−253 °C) wird allerdings sehr viel Energie benötigt. Außerdem verflüchtigt sich durch unvermeidbare Isolationsverluste ein Teil des Wasserstoffes bei der Lagerung, wenn kein kontinuierlicher Verbrauch gesichert ist. So beginnt die Ausgasung beim BMW Hydrogen 7 nach 17 Stunden Standzeit, nach 9 Tagen ist ein halbvoller Tank verdampft.

In Berlin waren zur Fußball-Weltmeisterschaft 2006 zwei Busse mit Wasserstoffverbrennungsmotor im Dauereinsatz. Sie legten dort 8.500 Kilometer zurück und hatten im Lauf des Jahres 2006 in Berlin-Spandau den Linienbetrieb aufgenommen. 2009 teilte der Hersteller MAN mit, wegen vermehrter Defekte das Projekt aufzugeben.

Das österreichische Hydrogen Center Austria stellte Ende 2009 unter dem Namen HyCar1 ein Konzeptfahrzeug (Mercedes W211) mit Verbrennungsmotor vor, welches multivalent sowohl mit Benzin, Wasserstoff, Erdgas oder Gasgemischen betrieben werden kann.

BMW hat Ende 2009 bekanntgegeben, dass die Weiterentwicklung von Wasserstoffverbrennungsmotoren eingestellt wird. Der Feldversuch mit Luxuslimousinen, die mit Wasserstoff betrieben werden, wird nicht weitergeführt. „Es wird vorerst keine neue Wasserstoff-Testflotte geben“, sagte der BMW-Entwicklungsvorstand im Dezember 2009. 2010 wurde von BMW der 1er mit Brennstoffzellenantrieb vorgestellt.

HCNG (oder H2CNG) ist eine Mischung aus komprimiertem Erdgas (CNG) und Wasserstoff. Der Wasserstoffanteil liegt bei bis zu 50 Volumenprozent. Dieser Treibstoff kann prinzipiell mit jedem Erdgasmotor verbrannt werden und verringert den Aufwand für konstruktive Änderungen herkömmlicher Verbrennungsmotoren.

Schon um 1995 beschäftigten sich Autobauer intensiv mit Brennstoffzellen-Pkw. Daimler-Benz stellte mit dem Necar II (New Electric Car) ein Forschungsfahrzeug vor und rühmte es als das „mit Abstand umweltfreundlichstes Auto der Welt“ Wird demgegenüber auch die Herstellung des Wasserstoffs als Vorkette bis zur Betankung (Well-to-Tank) in die Betrachtung einbezogen (Well-to-Wheel-Betrachtung), verschlechtert sich dessen Ökobilanz drastisch, wird es gar als „Eines der klimafeindlichsten Autos überhaupt“ bezeichnet. Eine neuere Ökobilanz von 2015 zeigt nun auf, unter welchen Rahmenbedingungen Brennstoffzellenfahrzeuge ökologisch konkurrenzfähig werden im Vergleich zu batteriebetriebenen Elektrofahrzeugen und konventionellen Benzinautos.

Die in der Schweiz ansässige Firma ESORO stellte 2008 unter dem Namen „HyCar“ ein Konzeptfahrzeug vor.

Die Fahrzeughersteller Toyota, Nissan und Honda haben angegeben, die Produktionskosten für wasserstoffgetriebene Fahrzeuge inzwischen stark reduziert zu haben. Es sei beabsichtigt, in Japan ab 2015 Großserien zu fertigen und zahlreiche Wasserstofftankstellen in den japanischen Metropolregionen zu errichten.

2013 nahm Hyundai in Korea als erster Hersteller die Serienfertigung des Brennstoffzellen-Pkw Hyundai ix35 FCEV in Kleinserie auf; Hauptzielmarkt ist Europa. Seit 2015 findet sich der Wagen unter der Bezeichnung ix35 fuel cell im offiziellen Vertriebsprogramm von Hyundai Deutschland. 

2015 bringt Toyota den seriell gefertigten Brennstoffzellen-Pkw unter dem Namen Mirai auf den internationalen Markt.

Daimler wollte 2014 mit der Großserienfertigung von Wasserstofffahrzeugen beginnen. Um die Alltagstauglichkeit des Wasserstoffantriebes nachzuweisen, startete Daimler eine Weltumrundung mit mehreren Brennstoffzellenfahrzeugen der Mercedes-Benz B-Klasse. Bereits 200 Serienfahrzeuge dieses Typs wurden 2010 auf Leasingbasis an Kunden ausgeliefert. Ende 2012 wurde bekannt, dass sich die Serienproduktion bezahlbarer BSZ-PKW bei Daimler um mehrere Jahre verschiebt.

Opel hatte im April 2011 angekündigt, ab 2015 erste Serienmodelle mit Brennstoffzellenantrieb in Serie zu fertigen und den Aufbau einer flächendeckenden Infrastruktur für Wasserstofftankstellen parallel zur Markteinführung voranzutreiben. Im Zusammenhang mit dem Kernkraftausstieg würde erwogen, überschüssige Energie aus Wind- und Solarkraftwerken zur ökologischen Wasserstofferzeugung zu verwenden. Ein erstes Pilotprojekt sei mit dem Windkrafterzeuger Enertrag geplant. Ende 2012 wurde bekannt, dass die Brennstoffzellenentwicklung bei Opel aufgegeben wurde.

Im November 2014 kündigte Toyota die Serienfertigung des Brennstoffzellenautos ("Mirai") an, das seit Dezember in Japan erhältlich ist. Seit 2015 wird dieses Auto auch in Deutschland verkauft.

Im Rahmen der IAA 2017 wurde ein Vorserienmodell des Mercedes-Benz GLC F-Cell vorgestellt. Das Fahrzeug soll als Serienmodell ab 2018 im Leasing erhältlich sein.

Der auf der CES im Januar 2018 präsentierte Hyundai mit dem Nexo das Nachfolgemodell des ix35 fuel cell.

Eine Kleinserie wasserstoffbetriebener Stadtbusse wurde vom Daimler-Tochterunternehmen EvoBus gebaut und zur weltweiten Erprobung in Großstädten zur Verfügung gestellt. Da es sich hierbei um Stadtbusse handelt, entfällt das Problem des fehlenden Tankstellennetzes. In der Stadt ist nur eine Tankstelle auf dem Betriebshof des Busbetreibers nötig. 2004 wurden wasserstoffgetriebene Busse in einem gemeinsamen Projekt von DaimlerChrysler, Shell und dem isländischen Umweltministerium in Reykjavík erprobt.

In Hamburg sind seit 2004 drei durch Brennstoffzellen und Elektromotoren angetriebene Busse in der praktischen Erprobung, sechs weitere seit April 2006. Das Projekt der Hamburger Hochbahn AG und Vattenfall Europe heißt HH2. Allerdings ist der Gesamtwirkungsgrad (Well-to-Wheel) der mit Wasserstoff aus ÖkoStrom betriebenen Fahrzeuge umstritten, da zur Wasserstoffherstellung und Speicherung enorme Strommengen benötigt werden. Der Energieverbrauch der Wasserstoffbusse entsprach daher etwa einem Dieselverbrauch von 100 Liter auf 100 Kilometer. Diese zweite weiterentwickelte Generation war bis 2010 im Einsatz. Seit 2011 kommt die dritte, deutlich verbesserte Version zum Einsatz. Es handelt sich um serielle Hybridbusse, deren Brennstoffzelle mit bis zu 60 % Wirkungsgrad arbeitet und die den Strom in Lithium-Ionen-Batterien speichert. Dadurch sind rein elektrisches Fahren und Rekuperation möglich. Die zwei Radnabenmotoren besitzen je 60 kW Dauerleistung und können kurzzeitig bis 240 kW leisten. Der Wasserstoffverbrauch konnte um bis zu 50 % verringert werden, so dass sich der Gesamtwirkungsgrad deutlich verbesserte.

Auf der Hannover Messe 2017 wurde ein neues Elektrobusmodell mit Brennstoffzelle des polnischen Herstellers Ursus vorgestellt. Der Stadtbus Ursus City Smile erreicht durch den Range Extender eine Reichweite von 450 km und kann in etwa 8 Minuten voll aufgetankt werden. Der Bus ist 12 m lang, bietet Platz für 76 Passagiere, fährt maximal 85 km/h und hat laut Hersteller einen Wasserstoffverbrauch von ca. 7 kg H pro 100 km. Die elektrischen Radnabenantriebe "ZAwheel" von Ziehl-Abegg erreichen einen Wirkungsgrad von 90 % und eine maximale Leistung von 364 kW. Die Brennstoffzelle mit einer maximalen Leistung von 60 kW liefert das niederländische Unternehmen HyMove. Die Batterie kommt vom deutschen Hersteller BMZ.

Der Brennstoffzellenbus Sora des japanischen Herstellers Toyota wurde 2017 auf der Tokyo Motor Show vorgestellt. 2018 erhielt der Bus die Zulassung für den Einsatz in Japan. Bis zum Jahr 2020 möchte Toyota - anlässlich der Olympischen Spiele - im Großraum Tokio 200 Fahrzeuge zum Einsatz bringen. Verwendet wird die auch bei dem PKW Toyota Mirai eingesetzte Technik, allerdings mit zwei Elektromotoren.

Mit Brennstoffzellen angetriebene Fahrräder und Motorroller befinden sich derzeit in der Entwicklungsphase. Als erstes Brennstoffzellen-Zweirad überhaupt erhielt der Suzuki Burgman Fuell-Cell-Scooter 2011 die EU-Typgenehmigung zur Straßenzulassung. Nun soll der Roller in England auf seine Alltagstauglichkeit hin getestet werden. Herzstück des Fahrzeugs ist eine luftgekühlte Brennstoffzelle sowie ein in den Rahmen integrierter Wasserstofftank.

Antriebe, die fossile Treibstoffe nutzen, waren im Jahr 2011 im Gegensatz günstiger als Fahrzeuge mit Wasserstoffantrieb. Wasserstoff aus erneuerbaren Energien wird vom Verbraucher nur genutzt, wenn er für eine Übergangszeit durch staatliche Maßnahmen wirtschaftlich gemacht wird (Förderung der erneuerbaren Energien/Besteuerung der fossilen Energien).

Die Wirtschaftlichkeit von Wasserstofffahrzeugen ist von mehreren Faktoren abhängig (siehe Tabelle). Neben den Kosten der Wasserstofffahrzeuge verglichen mit herkömmlichen Antrieben ist der relative Preis der fossilen Primärenergieträger zum Wasserstoff ein wichtiger Faktor für die Wirtschaftlichkeit. 

In einer Studie der DENA, die im Auftrag des Bundesverkehrsministeriums im Jahr 2009 durchgeführt wurde, sind Preise zwischen 85 $/Barrel und 130 $/Barrel als Gewinnschwelle zur Wirtschaftlichkeit von Brennstoffzellenfahrzeugen genannt, sofern die Preise für ein Brennstoffzellenfahrzeug im Bereich eines Dieselfahrzeugs liegen. Nach der Einschätzung namhafter Automobilhersteller sollte dies etwa ab 2014 erreicht sein. Allerdings wird der Serienstart der Brennstoffzellenfahrzeuge auch von führenden Autoherstellern immer wieder verschoben.

Beispiel
Damit ist das Brennstoffzellenfahrzeug in Bezug auf den Treibstoffverbrauch wirtschaftlicher als das Fahrzeug mit Ottomotor. Dies gilt für die Kraftstoffpreise, die der Kunde an der Tankstelle zu zahlen hat. Anzumerken ist, dass Mineralöl und Wasserstoff steuerlich unterschiedlich behandelt werden. Derzeit wird auf Wasserstoff keine Energiesteuer erhoben.

Ein Problem bei der Wirtschaftlichkeit des Brennstoffzellenantriebes sind die Kosten für den Katalysator. Benötigt ein Katalysator 60 g Platin, so belaufen sich die Kosten auf knapp 2.400 Euro allein für das Platin (zum Vergleich: Der Katalysator eines benzingetriebenen Fahrzeugs benötigt nur ca. 20 g Platin). Mit weniger Platin auskommende Brennstoffzellen befinden sich derzeit in der Entwicklung.

→ "Siehe auch : Sicherheitshinweise"

Mit Wasserstoff betriebene Pkw sind nicht gefährlicher als mit Benzin oder Gas betriebene Fahrzeuge. Wasserstoff ist wegen der geringen Dichte ein sehr flüchtiges Gas. Im Freien verflüchtigt es sich sehr schnell. In geschlossenen Räumen ist für eine ausreichende Belüftung zu sorgen, da es in einem weiten Bereich von 4–75 Vol.-% entzündlich ist (Benzin: 0,6–8 Vol.-%). Sauerstoff/Wasserstoffgemische mit einem Anteil von unter 10,5 Volumenprozent Wasserstoff sind schwerer als Luft und sinken zu Boden. Die Entmischung erfolgt nicht unmittelbar, so dass bis zur Unterschreitung der 4-Volumenprozent-Grenze die Zündfähigkeit erhalten bleibt. Beim Umgang mit Wasserstoff müssen Sicherheitsvorschriften und Entlüftungsanlagen dieses Verhalten berücksichtigen.

Benzin ist eine Flüssigkeit, die langsam verdampft. Die entzündlichen Benzindämpfe sind schwerer als Luft und verbleiben länger am Boden und der Zeitraum, in dem es sich entzünden kann, ist länger.

Wenn Wasserstoff in geschlossenen Räumen freigesetzt wird, besteht erhöhte Explosionsgefahr, z.B. in Garagen oder Tunneln. Hier ist für eine erhöhte Belüftung und eventuell für zusätzliche Sicherheitsmaßnahmen zu sorgen.

Die Detonationsgrenze von Wasserstoff liegt bei einer Konzentration ab 18 %. Benzin explodiert wesentlich früher, nämlich schon bei einer Konzentration von 1,1 %. Damit es überhaupt zu einer Explosion oder zum Brand kommt, muss in beiden Fällen ein entstandenes Kraftstoff-Luft-Gemisch erst einmal entzündet werden. Im Fall von Wasserstoff ist dafür eine geringere Energie von 0,02 mJ nötig als bei Benzin (Benzin: 0,24 mJ), in der Praxis spielt das aber keine Rolle, denn bereits die Energie eines elektrischen Funkens reicht aus, um auch Benzindämpfe zu entzünden.

Benzin hat eine deutlich geringere Zündtemperatur (220–280 °C) als Wasserstoff (585 °C), so dass es sich leichter an heißen Oberflächen wie dem Auspuffkrümmer oder dem Katalysator entzünden kann.

Nach einer Entzündung brennt Wasserstoff mit einer höheren Verbrennungsgeschwindigkeit ab als Benzin. Die Flamme bewegt sich dabei mit geringem Durchmesser steil nach oben, wenn sich das Leck an der Tankoberseite befindet.

Eine Wasserstoff-Flamme hat eine geringere Wärmestrahlung als eine Benzinflamme. Neben einer Wasserstoff-Flamme wird es deshalb weniger heiß als neben einer Benzinflamme – der Vorteil ist, dass benachbarte Gegenstände wie z.B. Autositze nicht so leicht Feuer fangen. Auch für Personen, die sich in der Nähe der Flamme aufhalten ist die Gefahr geringer, Verbrennungen zu erleiden. Allerdings ist die Wasserstoff-Flamme kaum sichtbar. Daher besteht die Gefahr, unabsichtlich hineinzugeraten.

Die heute verwendeten Drucktanks halten (im Gegensatz zu Benzintanks) auch schwere Unfälle unbeschadet aus. Wasserstofffahrzeuge mit Drucktanks können problemlos in Parkhäusern und Tiefgaragen geparkt werden. Es existiert keine gesetzliche Bestimmung, die das einschränkt. Im Gegensatz dazu dürfen Fahrzeuge mit Flüssigwasserstoff nicht in geschlossenen Räumen abgestellt werden, da sich durch das Ausgasen explosive Gasansammlungen bilden können.

Ein Beispiel für das Verhalten von Wasserstoff zeigte sich bei mehreren Unfällen von Tankwagen, die mit Flüssigwasserstoff beladen waren. Hier kam es jeweils zur Explosion bzw. zum Abbrennen des Wasserstoffes: Es gab keine oder nur leicht Verletzte, niemand kam bisher ums Leben.

Das Hauptproblem bei der Wasserstofflagerung sind Lecks. Wasserstofftanks und Rohrleitungen müssen aufgrund des gegenüber z.B. Erdgas bzw. Propan/Butan geringeren Moleküldurchmessers wesentlich besser abgedichtet sein. Manche Materialien sind ungeeignet, da sie für Wasserstoff durchlässig sind. Lecks führen nicht nur zu hohen Transportverlusten, sondern bilden ein Sicherheitsrisiko, wenn sich Gas ansammelt und sich ein Wasserstoff-Luft-Gemisch bildet. Deshalb sind Wasserstofftanks und Leitungen aus besonderen Kunststoffen, die eine Diffusion weitgehend verhindern. Solche Systeme müssen vom TÜV abgenommen werden. Von Vorteil ist, dass Wasserstoff wegen seiner geringen Dichte nach oben entweicht und sich nicht, im Gegensatz zu Benzindämpfen, Propan oder Butan, in Vertiefungen sammelt.





</doc>
<doc id="10400" url="https://de.wikipedia.org/wiki?curid=10400" title="Rohstoff">
Rohstoff

Primärrohstoffe sind natürliche Ressourcen, die bis auf die Lösung aus ihrer natürlichen Quelle noch keine Bearbeitung erfahren haben. Sie werden aufgrund ihres Gebrauchswertes aus der Natur gewonnen und entweder direkt konsumiert oder als Arbeitsmittel und Ausgangsmaterialien für weitere Verarbeitungsstufen in der Produktion, im Bauwesen oder als Energieträger verwendet.

Als Sekundärrohstoffe werden in Abgrenzung von den aus natürlichen Quellen stammenden primären Rohstoffen die durch Wiederverwertung (Recycling) gewonnenen Rohstoffe bezeichnet. Die Gewinnung und Nutzung beider Rohstoffarten ist Thema der Rohstoffwirtschaft und der jeweils relevanten, materialbezogenen Fachgebiete.

Für die Klassifikation von Rohstoffen gibt es unterschiedliche Systeme. Häufig genutzte Kriterien zur systematischen Einteilung sind ihre natürlichen Eigenschaften, der Grad der Verarbeitung und der Regenerierbarkeit, die Herkunft und der Verwendungszweck.

Nach ihren natürlichen Eigenschaften werden organische und anorganische Rohstoffe unterschieden. Erstere stammen aus der belebten Natur. Zu ihnen zählen pflanzliche und tierische Stoffe einschließlich der Mikroorganismen. Die Quelle für anorganische Rohstoffe sind Ressourcen der unbelebten Natur einschließlich des Wassers und der Luft.

Nach dem Grad der Regenerierbarkeit werden die Rohstoffe in erneuerbare und nichterneuerbare eingeteilt. Erneuerbar sind nachwachsende Rohstoffe aus dem Tier- und Pflanzenreich, aber auch anorganische Stoffe wie Wasser, Luft und Sonne. Als nicht durch menschliche Einwirkung erneuerbar gelten mineralische und fossile Rohstoffe, die sich in geologischen oder astronomischen Zeiträumen gebildet haben (zum Beispiel Erdöl und Metalle).

Rohstoffe entstammen den unterschiedlichen Bereichen der Erdsphären. Aus der Biosphäre werden die pflanzlichen und tierischen Stoffe, aus der Hydrosphäre das Wasser und die Fische, aus der Erdatmosphäre der Sauerstoff und aus der Lithosphäre die mineralischen Rohstoffe gewonnen. Orte der Erdoberfläche, an denen sich Rohstoffe in abbauwürdiger Form angereichert haben, werden als Lagerstätten bezeichnet. Die Bauwürdigkeit wird durch Faktoren wie die Menge, Qualität oder Lage des Rohstoffes bestimmt.

Nach der Art ihrer Gewinnung und dem Verwendungszweck werden Agrar- und Industrierohstoffe unterschieden.

Agrarrohstoffe werden von der Land-, Forst- und Fischereiwirtschaft geliefert. Sie können tierischen oder pflanzlichen Ursprungs sein. Rohstoffe wie Getreide, Fleisch, Fisch und organische Öle werden zu Nahrungs-, Genuss- und Futtermitteln weiterverarbeitet. Organische Abfälle können als Ausgangsstoff zur Biogas­produktion genutzt werden.

Erzeugnisse der landwirtschaftlichen Produktion, die als Grundstoffe für technische Verwertungszwecke dienen, wie Holz, Kautschuk, Baumwolle, Industrieobst, Heilpflanzen oder Raps, werden als industrielle pflanzliche Rohstoffe bezeichnet.

Industrierohstoffe aus anorganischen und fossilen Ressourcen werden vor allem als Bodenschätze im Bergbau gefördert. Sie werden in vier Gruppen eingeteilt:

Rohstoffe wurden vom Menschen schon immer gewonnen, genutzt und gehandelt. Ganze Epochen der Ur- und Frühgeschichte wie die Steinzeit, die Bronzezeit oder die Eisenzeit sind nach Rohstoffen benannt, die diese geprägt haben.

Die Nachfrage nach Rohstoffen wird wesentlich vom jeweiligen technologischen Entwicklungsstand einer Zivilisation bestimmt. Im Zuge technologischer Wandlungsprozesse ändert sich stets auch die Rohstoffnachfrage: bisher nachgefragte Rohstoffe werden obsolet und es entsteht eine Nachfrage nach Rohstoffen, die bisher nicht benötigt wurden bzw. mangels verfügbarer Technologie nicht ausgebeutet werden konnten.

In der Neuzeit steigen seit Beginn der industriellen Revolution der Bedarf und die Ansprüche an Rohstoffe. Mit wachsenden Kenntnissen in der Geologie, Chemie und Werkstofftechnik werden immer mehr Rohstoffe und Rohstoffvorkommen entdeckt und neue Nutzungsmöglichkeiten gefunden.

Seit Publikation der Studie Die Grenzen des Wachstums 1972 und der anschließenden Ölkrise, die wirtschaftliche Stagnation und Zwangseinschränkungen für die Bevölkerung zur Folge hatte (zum Beispiel Sonntagsfahrverbot), ist auch der Öffentlichkeit vieler Industrieländer bewusst geworden, dass kein Rohstoff unbegrenzt verfügbar ist.

Heute werden mit 70 Milliarden Tonnen pro Jahr doppelt so viel Rohstoffe gewonnen wie Ende der 1970er-Jahre. Der Pro-Kopf-Verbrauch ist in Europa 4-mal höher als in Asien und 5-mal so hoch wie in Afrika. Deutschland liegt mit einem Rohstoffverbrauch von 200 kg pro Kopf und Tag weltweit mit an der Spitze.

Rohstoffe stellen mehr als ein Drittel aller Güter im Welthandel dar. Der globale Handel wird über organisierte Warenterminbörsen abgewickelt. Die Preisbildung wird dabei von oligopolartigen Marktstrukturen mitbeeinflusst. Viele Rohstoffe können nur unter Einsatz von erheblichen Investitionen gewonnen werden. Insbesondere die Ausbeutung von mineralischen und fossilen Stoffen konzentriert sich oft auf wenige multinationale Konzerne.

Anbau und Förderung sowie Weiterverarbeitung von Rohstoffen finden dabei häufig in unterschiedlichen Ländern statt. Dabei traten in den vergangenen Jahren verstärkt schnell wachsende Tigerstaaten wie Indien, Brasilien oder China als Käufer von Rohstoffen auf. Insbesondere die Nachfrage nach Eisenerz steigt von Seiten dieser Staaten an. Der Gegensatz zwischen exportierenden und importierenden Ländern, der sich seit Beginn des 20. Jahrhunderts herausgebildet hatte, ließ den Rohstoffhandel zum Gegenstand nationaler politischer Interessen werden. Grundzüge einer internationalen Rohstoffpolitik wurden bereits 1927 auf der Weltwirtschaftskonferenz in Genf festgelegt.

Insbesondere die rohstoffabhängigen Volkswirtschaften (Industriestaaten) benötigen einen freien Marktzugang zu den Ressourcen. Dies gilt vor allem für Buntmetalle, aber auch allgemein für wenig transparente Märkte wie beispielsweise den Recyclingmarkt. Hier werden in vielen Fällen wertvolle Rohstoffe wieder exportiert, obwohl sie im Inland gebraucht würden. Darüber hinaus verzerren einige rohstoffimportierenden Schwellenländer den Markt, da sie nur auf den Preis achten und nicht auf ethische, soziale und ökologische Kriterien in den Abbauländern. Dieser Versuchung, der durch die marktwirtschaftlichen Zwänge natürlich jederzeit auch Firmen aus den Industrieländern erliegen können, möchte die internationale Politik (EU, G7, UN u. a.) durch reglementierte, diskriminierungsfreie Exportmärkte verhindern.

Konflikte im Rohstoffhandel entstehen aus gegensätzlichen privatwirtschaftlichen und nationalen Interessen, besonders zwischen den Industrie- und den Entwicklungsländern. Die Notwendigkeit globaler Übereinkommen, die den steigenden Rohstoffbedarf einerseits und den Umweltschutz und die Ressourcenschonung andererseits berücksichtigen, führte zu einer Reihe internationaler Abkommen und Organisationen. Die wichtigsten von ihnen sind die UNCTAD als Interessensvertretung der Entwicklungsländer, die Welthandelsorganisation (WTO), das UN-Seerechtsübereinkommen, das die Ausbeutung der Meeresressourcen reguliert, der Antarktisvertrag und die OPEC als Vereinigung erdölexportierender Länder.

Die weltgrößte Warenterminbörse ist die New York Mercantile Exchange (NYMEX). An dieser Börse werden Metalle, Energie­produkte, Agrarrohstoffe und andere Produkte gehandelt. Die Chicago Board of Trade (CBOT), gegründet 1848, ist die weltälteste Terminbörse und Teil der CME Group. Mehr als fünfzig verschiedene Termingeschäfte werden durch über 3.600 CBOT-Mitglieder sowohl durch Parketthandel als auch elektronisch abgewickelt. Eine weitere Börse ist die Chicago Mercantile Exchange (CME). An der CME werden vor allem Futures und Optionen auf unterschiedliche Waren gehandelt.

Für Industriemetalle, wie Aluminium, Blei, Kupfer, Nickel, Zink und Zinn, ist die London Metal Exchange (LME) zuständig. Außer bei Kupfer und Aluminium, die auch an der NYMEX in New York gehandelt werden, verfügt die LME bei allen anderen Metallen nahezu über eine Monopolstellung. Die ICE Futures (früher „International Petroleum Exchange“, IPE) ist Handelsplattform für die in Europa führende Ölsorte Brent. Sie ist die größte Terminbörse für Optionen und Futures auf Erdöl, Erdgas und Elektrizität in Europa.

Der London Bullion Market ist der wichtigste außerbörsliche Handelsplatz (englisch: Over-The-Counter, OTC) für Gold und Silber sowie einer der global bedeutenden Rohstoffhandelsplätze in London. Hier wird seit 1919 der Weltmarktpreis für Gold und seit 1897 der Weltmarktpreis für Silber festgestellt. Den Handel koordiniert die London Bullion Market Association (LBMA). Die Preisbildung für die Edelmetalle Platin und Palladium findet am London Platinum and Palladium Market (LPPM) statt. Der LPPM stellt wie der London Bullion Market die Ausnahme unter den Rohstoffmärkten dar: er ist keine Börse, sondern ein OTC-Markt.

Die Preisentwicklung von 19 für den Welthandel relevanten Rohstoffen misst der Thomson Reuters/Jefferies CRB Index. Er wurde erstmals 1958 vom Commodity Research Bureau (CRB) in den USA berechnet. Der Index gilt als übergeordneter Indikator für den gesamten Rohstoffsektor. Der heutige Rohstoffindex, der den Namen CRB Index trägt, ist nicht mit dem historischen CRB Index vergleichbar. Er wurde 2005 grundlegend überarbeitet, als seine traditionelle Berechnungsmethode nicht mehr aktuell war. Der ursprüngliche CRB Index läuft seitdem unter dem Namen Continuous Commodity Index („Old CRB Index“) weiter.

Weitere Rohstoffindizes sind der Dow Jones-UBS Commodity Index (früher Dow Jones-AIG Commodity Index), der Rogers International Commodity Index (RICI) und der S&P GSCI (früher Goldman Sachs Commodity Index). Ein Nahrungsmittel-Preisindex der Ernährungs- und Landwirtschaftsorganisation (FAO) der Vereinten Nationen ist der FAO Food Price Index (FFPI). Er erfasst die Entwicklung der Weltmarktpreise von verschiedenen Agrarrohstoffen und Nahrungsmitteln. Der HWWI-Rohstoffpreisindex ist ein umfassender Rohstoffindex.

Im Gegensatz zu Rohstoffindizes spiegeln Rohstoffaktienindizes nicht die Wertentwicklung der Rohstoffe, sondern die der Aktiengesellschaften wider. Beispiele sind der NYSE Arca Gold BUGS Index (HUI), ein Aktienindex von internationalen Goldproduzenten und hauptsächlich Gold fördernden Bergbau­unternehmen, und der Philadelphia Gold and Silver Index (XAU), in dem internationale Gold- und Silberproduzenten gelistet sind.

Über 90 % des Welthandels, fast 95 % des Außenhandels der Europäischen Union und nahezu 70 % des deutschen Im- und Exports werden über den Seeweg abgewickelt. Ein wichtiges Stimmungsbarometer für den Welthandel und damit auch für die Weltkonjunktur ist der Baltic Dry Index (BDI). Der BDI ist ein Preisindex für das weltweite Verschiffen von Hauptfrachtgütern (hauptsächlich Kohle, Eisenerze und Getreide) auf Standardrouten. Er wird seit 1985 täglich von der Baltic Exchange in London veröffentlicht.

Rohstoffe stellen eine eigene Anlageklasse dar. Aufgrund der hohen Volatilität ist diese Anlageklasse häufig auch Gegenstand spekulativer Investments. Eine Investition in Rohstoffe (Commodities) erfolgt meist nicht in physische Bestände, sondern in Termingeschäfte auf Rohstoffe oder börsengehandelte Exchange-traded Commodities. Grundsätzlich werden bei Rohstoffinvestments vier große Gruppen unterschieden: Agrarrohstoffe, Edelmetalle, Industriemetalle und Energierohstoffe. Insbesondere die Geldanlage in Agrarrohstoffen ist ethisch umstritten. Mit Abstand populärstes Anlageprodukt sind Edelmetalle mit Gold an der Spitze. Gold wird häufig als Sicherung gegen Inflation und Krisensituationen angesehen.

Die Rohstoffgewinnung im großen Maßstab kann zu erheblichen Umweltproblemen führen. Beispiele sind Schadstofffreisetzungen im Coltan- und Urantagebau, Ölunfälle, großflächige Rodungen und Überweidung für Holzgewinnung und Energiepflanzen­anbau und die Zerstörung von Landschaften und Ökosystemen beim Braunkohletagebau. Um diese Gefahren zu minimieren, werden Verhaltenskodexe von Bergbauunternehmen, nationalen Regierungen und internationalen Organisationen erarbeitet. Überdies entwickelt die Internationale Gemeinschaft transparente Standards für ökologisch und sozial nachhaltige Praktiken in Bergbau, Rohstoffhandel und -verarbeitung. Jedoch ist deren Umsetzung in vielen Ländern häufig nicht oder nur eingeschränkt gewährleistet und überprüfbar, so dass es weiterhin zu erheblichen Schäden an Mensch und Umwelt kommt, die zum Teil irreversible Konsequenzen haben.

Aus ökonomischer Sicht begrenzt in einer geschlossenen integrierten Volkswirtschaft bei gegebener Produktionstechnologie der knappe Produktionsfaktor das Wirtschaftswachstum. Sofern dieser knappe Faktor endlich oder nur beschränkt regenerierbar ist, ist nur dann ein weiteres Wirtschaftswachstum möglich, wenn grundsätzlich andere Produktionstechnologien eingesetzt werden, die diesen Faktor überflüssig machen. Sofern die Innovations­anstrengungen erst kurz vor der Erschöpfung des Rohstoffes in Angriff genommen werden, vollzieht sich der Übergang hin zu den neuen Produktionstechnologien krisenhaft. Wenn bereits lange vor der Erschöpfung Substitutionsversuche einsetzen und Prozessinnovationen erzielt werden, ist es naheliegend, dass alte und neue Techniken lange Zeit nebeneinander existieren, da die Einführung und Verbreitung letzterer zeitaufwändige Lernprozesse erfordert. Anschließend verschwinden die alten Verfahren und die von ihnen benötigten Ressourcen werden, sofern noch vorhanden, entwertet. 

In einer offenen Volkswirtschaft, in der Import aus anderen Staaten durchführbar und somit eine Abmilderung der nationalen Auswirkungen des Ressourcenmangels möglich sind, kann sich ein Ressourcenmangel von einem Nachteil zu einem Vorteil entwickeln, wenn eine neue Produktionstechnik die alte in wichtigen Marktsegmenten überflüssig macht. Der nötige Import eines knappen Rohstoffes kann dann durch einen Export von durch neue Technologien erschlossenen Gütern abgelöst werden, wodurch der alte Rohstoff sowohl im eigenen Land als auch in anderen Staaten ökonomisch entwertet wird.

Die Statische Reichweite eines nicht-erneuerbaren Rohstoffs gibt die Zeitspanne in Jahren an, für die bei aktuellem Verbrauch die weltweit bekannten und förderwürdigen Vorkommen noch reichen werden. Da einerseits die weltweite Nachfrage nach Rohstoffen steigt, andererseits nach wie vor neue Lagerstätten gefunden werden, stellt diese nur ein grobes Maß für die langfristige Verfügbarkeit eines Rohstoffes dar. Die heute bekannten hochgradigen Rohstoffvorkommen haben eine begrenzte Reichweite von oft weniger als einhundert Jahren. Konflikte um Rohstoffe können zum Anlass globaler Machtpolitik werden. Es gibt Projekte für Tiefseebergbau z. B. um den Abbau von Manganknollen zu erforschen und auch theoretische Überlegungen für Asteroidenbergbau.

Bei mangelnder Verfügbarkeit steigen zunächst die Preise. Dies beeinflusst die Wirtschaftlichkeit aller von diesem Rohstoff abhängigen Verfahren und Produkte, fördert aber mittel- und langfristig auch die Erschließung von weniger ergiebigen Lagerstätten, die Entwicklung von Substituten (z. B. Photovoltaik statt Kohleverstromung), effizienteren Technologien und Recyclingverfahren. 

Oft finden sich potentielle Rohstoffe von Natur aus oder nutzungsbedingt so fein in der Umwelt verteilt, dass eine wirtschaftliche Anreicherung auf absehbare Zeit nicht wirtschaftlich ist. Dies gilt etwa für die Gewinnung seltener Metalle aus dem Meerwasser, das z. B. einige Millionen Tonnen Gold enthält. Auch häufigere Metalle wie etwa Zink von verzinkten Eisenteilen werden durch Umwelteinflüsse allmählich in feinster Form zerstreut, analog zu Platin, das aus Fahrzeugkatalysatoren als Nanopartikel an die Umgebung abgegeben wird (vgl. Zunahme der Entropie).

In den letzten Jahren kam es daher vermehrt zu Diskussionen über die Reichweite der technologisch kaum ersetzbarer Metalle wie z. B. Indium. Von diesen sind oft nur wenige, lokal eng begrenzte Vorkommen verfügbar. Auch werden sie im Regelfall nur in so kleinen Mengen verwendet, dass sie derzeit praktisch nicht rückgewinnbar sind. Wegen ihrer hohen Bedeutung für elektronische Bauelemente und andere Zukunftstechnologien werden hier zum Teil kurzfristig Engpässe erwartet.





</doc>
<doc id="10401" url="https://de.wikipedia.org/wiki?curid=10401" title="Grillen">
Grillen

Grillen oder Grillieren (Verb, ins Deutsche übertragen von und , abgeleitet von für „Flechtwerk, kleiner Rost“) ist das Braten in Wärmestrahlung.

Grillen beziehungsweise das Braten über dem offenen Feuer ist eine ursprüngliche Methode des Garens von Lebensmitteln – sie verlangt nur die Beherrschung des Feuers und benötigt kein Kochgeschirr. Grillen ist eine der weltweit beliebtesten sozialen Freizeitbeschäftigungen. Gegrillt wird in Privatgärten, auf Balkonen sowie auf öffentlichen oder vereinseigenen Grillplätzen. Grillgeräte und Holzkohle können in Deutschland nach DIN EN 1860 genormt werden. Eines der gängigsten Zeichen auf dem Markt ist das DIN-Geprüft oder DINplus.

Beim Grillen wird das Gargut im Wesentlichen durch Wärmestrahlung gegart und an der Oberfläche geröstet. Dazu wird es entweder mithilfe eines Fleischspießes oder auf einem Grillrost über, neben oder unter einer strahlenden Wärmequelle gehalten. Als Hitzequelle dienen Holzfeuer oder Holzglut, Gas, durch Gas erhitzte Steine oder elektrische Heizschleifen. Die beim Grillen entstehenden Röststoffe (siehe Maillard-Reaktion) führen zum typischen Geschmack des Gargutes. Anders als oft behauptet wird, entstehen beim Grillen mit hochwertiger Holzkohle keine zusätzlichen Aromastoffe. In der stationären und mobilen Gastronomie westlicher Länder werden wegen der besseren Steuerbarkeit der Hitze fast ausschließlich elektrische oder gasbetriebene Grills verwendet. "Kontaktgrills", die in der Gastronomie ebenfalls verbreitet sind, sind keine Grills im eigentlichen Sinn, da sie vor allem durch Wärmeleitung garen.

Beim direkten Grillen wird das Grillgut über der Hitzequelle platziert. Die hohen Temperaturen (bis zu 260 °C) an der Oberfläche führen zur Bildung einer Kruste. Bei richtigem Grillen bleibt der größte Teil des Saftes im Gargut erhalten. Zur Verhinderung des Austrocknens an den Oberflächen des Grillgutes kann dieses mit Fett (zum Beispiel Speiseöl) oder mit einer Marinade bestrichen werden. Dadurch werden im Bereich der Oberfläche des Gargutes höhere Temperaturen erreicht, allerdings werden durch den Einsatz von Fett gesundheitsschädliche Stoffe produziert, sofern diese bei Kontakt mit der Hitzequelle verrauchen und nicht abgeleitet werden.

Eine besondere Art des direkten Grillens stellt das "Sizzeling" dar. Hierbei wird ein Fleischstück kurz (weniger als eine Minute pro Seite) über extremer Hitze sehr heiß angegrillt um danach bei moderater Hitze fertig gegart zu werden. Besonders einige moderne Gasgrill-Stationen haben speziell für diese Zubereitungsart eine extra Brennerzone, in der ein Keramikbrenner verbaut ist, der Temperaturen von mehr als 800 Grad Celsius erreicht. Der Vorteil des "Sizzelings" ist das schnelle Entstehen von Röstaromen an der Oberfläche ohne das eigentliche Garen im Inneren des Fleischstückes.

Beim indirekten Grillen wird das Grillgut bei mittlerer bis hoher Temperatur (ca. 130 bis 220 °C) in einem geschlossenen Grill (oft ein Kugelgrill) gegart. Das Grillgut befindet sich dabei entweder neben der Hitzequelle oder seitlich versetzt oberhalb der Hitzequelle. Die Hitze erreicht das Grillgut daher nicht direkt. Sie wird vielmehr an der Innenseite des Grills reflektiert. Die heiße Luft umströmt das Gargut gleichmäßig. Der Garprozess ist mit dem in einem Heißluft- oder Umluftofen vergleichbar. Unterhalb des Grillgutes kann eine Schale platziert werden, die herabtropfendes Fett, Fleischsaft oder herunterlaufende Marinade auffängt, die die Zubereitung einer Soße mittels Zugabe von Flüssigkeit (Wasser, Bier, Wein), Wurzelgemüsen und Gewürzen erlauben.

Beim indirekten Grillen kann auch voluminöseres Gargut gleichmäßig gegart werden, weil dabei die Hitze ausreichend Zeit hat, in dessen Inneres vorzudringen, ohne dessen äußere Schicht zu verbrennen. Außerdem bleibt der Bratensaft erhalten, und das Wenden des Gargutes entfällt. Der Nachteil besteht in einer längeren Zubereitungszeit, welche sich durch die Größe des Grillgutes ergibt. Durch Zugabe von Holzstücken zur Grillkohle kann der Geschmack beeinflusst werden.

Speziell beim indirekten Grillen ist es verbreitet, Fleisch vor dem Grillen längere Zeit in einer Marinade einzulegen, um Aromen die Möglichkeit zu geben, tief in das Fleisch einzudringen. Weiterhin können Fleischstücke, die generell durchgegart werden (wie Schweinefleisch oder Geflügel) vor dem Würzen in eine Salzlake („Brine“) eingelegt werden. Dem Fleisch wird dadurch eine gewisse Menge an Feuchtigkeit entzogen, die das Grillgut mürber machen soll (siehe Nasspökeln).

Eine besondere Form des indirekten Grillens stellt das Plankengrillen dar. Hierfür wird ein Holzbrett für mehrere Stunden gewässert und dann mit einem Tuch nur oberflächlich abgetrocknet. Das Brett wird auf einer Seite eingeölt und mit der geölten Seite nach oben in einem Kugelgrill über der Glut, in einem Gasgrill über der Flamme platziert. Nach Schließen des Deckels fängt das Brett nach ungefähr fünf bis zehn Minuten auf der Unterseite an zu glühen und zu rauchen. Jetzt wird das Grillgut auf die geölte Seite der Planke gelegt und das Brett auf die indirekte Seite des Grills geschoben. Dort glüht und raucht das Brett langsam auf der Unterseite weiter, und das Grillgut wird indirekt im heißen Rauch gegart. Diese Zubereitungsart eignet sich besonders für Fisch.

In einem Barbecue-Smoker wird das Grillgut bei Niedrigtemperatur (90 bis maximal 130 °C) in heißem Rauch gegart. Obwohl dieses Verfahren sich stark vom Grillen unterscheidet, werden die Wörter Barbecue und Grillen oft synonym verwendet. Klassische Barbecue-Smoker haben einen Behälter für das Brennmaterial (Holz, Holzkohle oder Pellets) und daran angeschlossen eine Garkammer für das Gargut.

Holz, Holzkohle oder Briketts aus Holzkohle und Braunkohle sind Brennstoffe, die nicht leicht entzündlich sind. Sie müssen daher für eine saubere Verbrennung über einen längeren Zeitraum stark erhitzt werden. Außerdem ist eine gute Luftzufuhr erforderlich, da der Verbrennungsprozess Sauerstoff benötigt. Für eine gleichmäßige Glut und die Verminderung von Rauch sollten die Brennstoffe trocken gelagert werden. Es gibt unterschiedliche Hilfsmittel und Vorgehensweisen des Anfeuerns. Grillanzünder werden in Deutschland nach DIN EN 1860-3 zertifiziert und sind mit dem DIN-Geprüft gekennzeichnet. Dies ist nur gültig mit einer Register-Nummer und wird von der Firma DIN CERTCO vergeben.

Der Anzündkamin ermöglicht durch den Kamineffekt das einfache, zuverlässige und relativ schnelle Entzünden des Brennstoffs.

Elektrische Grillanzünder bestehen aus einer Heizschlange, die unter den Brennstoff gelegt wird und diesen entzündet. Sie sind emissionsfrei und beeinträchtigen nicht den Geschmack des Grillguts. Ihr Nachteil besteht lediglich in der Abhängigkeit von einer Stromquelle.

Chemische Grillanzünder sind leicht entzündlich und brennen lange genug, um den eigentlichen Brennstoff anzuzünden. Sie sind vor dem Entzünden des Grills aufzubringen. Es gibt sie in flüssiger Form zum Tränken des Brennstoffs, in gelartiger, dickflüssiger Form – in der Regel aus Kerosin, Petroleum oder N-Paraffin – sowie in fester Form, zum Beispiel aus gewachster Holzwolle oder Holzfasern. Chemische Grillanzünder werden zweckmäßig leicht erhöht platziert, anschließend mit locker geschichtetem Brennstoff umgeben und dann entzündet. Damit kann das unterstützende Feuerentfachen, zum Beispiel mit einem Blasebalg, fast immer entfallen. Chemische Grillanzünder können den Geschmack des Grillguts beeinträchtigen. Darum sollte dieses erst aufgelegt werden, wenn die Anzünder vollständig abgebrannt sind.

Mit einem Heißluftgebläse oder einer Lötlampe lässt sich der Brennstoff gleichmäßig und sehr schnell entzünden.

"Yakitori" ist die japanische Variante gegrillter Fisch-, Fleisch- und Gemüsespießchen. In japanischen Städten findet man oftmals "Streetfood"-Stände und Restaurants, die über einen Kohlegrill verfügen und diese gegrillten Hühnerspieße anbieten. "Yakiniku" ist eine weitere Variante des Grillens, wobei Fleisch und Gemüsestücke direkt über einem kleinen Kohle- oder Gasgrill bei hohen Temperaturen gegart werden; eine Methode, die sich über Japan und weite Teile Asiens verbreitet hat. Eine weitere Grillspezialität findet man in Malaysien, Singapur, Indonesien und Thailand mit dem "Satay". Dabei handelt es sich um mariniertes Fleisch auf einem Bambusspieß, das über einem Kohlegrill gegart wird und mit Erdnusssoße serviert wird. In Korea wird dünn geschnittenes Rindfleisch mariniert und an speziellen Tischen gerillt, in denen (in der klassischen Variante) ein Holzkohlegrill in der Mitte eingelassen ist um den die Esser sitzen. Modernere Varianten nutzen Gasflammen oder Strom. Das gegarte Fleisch wird dann mit (meist scharfen) Saucen und anderen Zutaten wie Knoblauch, Paprika, Peperon, Zwiebeln etc. in ein Salat- oder Sesamblatt geschlagen und gegessen.

In Argentinien und Uruguay werden "Asado" und "Steak a la Parrilla" als Nationalgerichte betrachtet. Beides sind Varianten von gegrilltem Fleisch. Bei Asado handelt es sich um über offenem Feuer gegrilltes Rindfleisch, Steak a la Parrilla ist ebenfalls ein Rindersteak, das auf einen traditionellen Grill gegart wird.

In Großbritannien, Irland und dem Commonwealth of Nations beschreibt der Begriff grillen "(grilling)" üblicherweise das Garen unter einer Quelle direkter, trockener Hitze. Der Grill ist dabei ein eigener Teil eines Ofens, in dem die Speisen direkt unter dem Grill-Element eingeführt werden können. In Nordamerika wird diese Praxis "Broiling" genannt. In Australien versteht man unter dem Begriff das Garen unter einer direkten Hitzeeinwirkung von oben, wobei hier manchmal auch die Hitze von unterhalb des Gargutes kommen kann.

Beim Grillen in elektrischen Öfen wird das Gargut direkt unterhalb der oberen Heizstäbe platziert, und die unteren Heizelemente werden abgeschaltet. Die Ofentür wird leicht geöffnet. Diese Form des Grillens verursacht oftmals eine starke Rauchentwicklung. Sowohl Gas- als auch Elektroöfen besitzen zum Teil eigene Kompartimente, die für das Grillen gedacht sind.

Die US-amerikanische Grillkultur wird Barbecue genannt, womit sowohl das direkte und das indirekte Grillen, als auch das Garen im Barbecue-Smoker bezeichnet werden. In den USA kommt beim Grillen die Hitze stets von unten. Das Gargut wird dabei typischerweise auf einem Gitter platziert, das auf dem Gargut erkennbare Grillmuster hinterlässt. Gegrillt wird üblicherweise im Freien mit Kohle- oder Gasgrills. Eine neuere Entwicklung in den USA ist das Grillen mit Infrarotstrahlung. Eine weitere Form des Grillens kann mit Griddleplatten durchgeführt werden, oder mit elektrischen Grills für Innenräume.

Bei Kohlegrillen ist das Hinzufügen von Holzchips aus Hickory oder Mesquite in den USA gängige Praxis. Die Holzstücke glimmen unter Einfluss der Hitze der Kohlen und geben dem Gargut einen für die Holzsorte jeweils typischen Geschmack. Das "Smoking" ist eine Variation dieser Grillform, bei der die Holzchips unter dem Gargut bei niedriger Hitze verraucht werden. Auch Harthölzer wie Pekan, Ahornholz, Apfelbaumholz oder Eichenholz können in Form von Chips den Kohlen hinzugefügt werden.

"Kabob" (US-Begriff für Kebab) ist eine Modifikation des Kebabs mit persischem Ursprung, bei der Fleischstücke am Spieß (oder Drehspieß) gegrillt werden. Das Produkt ähnelt dem Satay der asiatischen Küche und dem mexikanisch-yucatanischen Alambre.

In Schweden erfolgt das Grillen üblicherweise direkt über glühenden Kohlen. Als Fleisch kommt vorwiegend mariniertes Schweinefleisch zum Einsatz. Es ist auch üblich, Fleisch- und Gemüsestücke gemeinsam am Spieß zu grillen, was "Grillspett" genannt wird.

In Spanien grillt man traditionell „a la Plancha“. Die Plancha ist eine, meist gusseiserne, Grillplatte, die mit Gas oder elektrisch beheizt wird. Das Grillen mit der Plancha zählt zu den indirekten Grillmethoden.

Beim Grillen wird kein oder kaum Fett hinzugegeben, und aus dem Grillgut austretendes Fett kann durch Abtropfen entfernt werden. Gegrillte Lebensmittel sind fettärmer als in der Pfanne gebraten, selbst wenn der Boden der Pfanne eine strukturierte Oberfläche aufweist die das austretende Fett sammelt. Ein Krebsrisiko besteht, wenn das Grillgut zu stark erhitzt oder falsch gegrillt wird. Beim Grillen bilden sich verschiedene Stoffe, die von der Weltgesundheitsorganisation (WHO) als krebserregend eingestuft werden. Dazu zählen heterozyklische Amine, die beim scharfen und langen Anbraten von Fleisch bei hohen Temperaturen entstehen. Man müsste jedoch etwa 50 kg von verkohltem Grillfleisch essen, damit etwa gleich viele dieser Giftstoffe aufgenommen werden wie beim Rauchen einer einzigen Zigarette. Eine neue Studie der kanadischen "Food Research Division" belegt, dass die heterozyklischen Amine beim Grillen zwar entstehen, widerlegt jedoch, dass diese im menschlichen Körper ihre kanzerogene Wirkung auch entfalten. Laut der Studie wirke das verkohlte Grillfleisch als Aktivkohle, welche die aromatischen Kohlenwasserstoffe an sich dockt, so dass diese den Verdauungstrakt passieren, ohne oxidativen Schaden anzurichten. Eine Möglichkeit den Anteil an Aminen zu reduzieren, ist das Fleisch vorzugaren (beispielsweise in der Mikrowelle), wodurch sich die Zeit, in der das Fleisch großer Hitze ausgesetzt ist, minimieren lässt.

Beim direkten Grillen mit Holzkohle können gesundheitsschädliche Stoffe aus der Glut und dem hinein getropften Fett ins Grillgut übergehen. Die entstehenden polyzyklischen aromatischen Kohlenwasserstoffe wie Benzo["a"]pyren gelten als krebserregend. Beim indirekten Grillen ist diese Gefahr nicht gegeben, da das Fett nicht aus dem Grillgut in die Glut tropfen kann.

Es gibt Belege dafür, dass typische Grillgewürze wie Senf, Thymian, Oregano, Rosmarin und Salbei, ebenfalls Bier, die Aufnahme dieser Kohlenwasserstoffe weitgehend verhindern, beispielsweise indem sich die in ihnen enthaltenen Flavonoide fest an die Kohlenwasserstoffe binden. Diese werden aus dem Körper unverändert wieder ausgeschieden.

Chinesische Forscher haben zudem herausgefunden, dass das Grillen von Fisch dessen Quecksilbergehalt senken soll. Die hohen Temperaturen sollen die Bioverfügbarkeit des Schwermetalls modifizieren.

Beim Grillen erfolgt zumeist der Umgang mit Glut und so ist zunächst ein dafür geeigneter Grillplatz auszuwählen. Auch das geeignete Werkzeug wie Wahl von Grillanzünder und dessen Anwendung, sichere Handhabung des Grillguts durch Grillzangen oder andere Dinge sind Voraussetzung zur Vermeidung von Gefahren und Gefährdungen. In Deutschland ereignen sich jährlich bis zu 4000 Grillunfälle, davon 500 mit schweren Verbrennungen. Die meisten davon entstehen durch die Verwendung von ungeeigneten Brandbeschleunigern, wie Benzin oder Alkohol (Spiritus) als Anzünder. Es können hohe Stichflammen und großräumige Verpuffungen entstehen. Häufig entzündet sich der Behälter mit dem Brandbeschleuniger und Personen im weiten Umkreis um den Grill können schwere Verbrennungen erleiden.

Auch reguläre flüssige Grillanzünder können zu explosionsartigen Verpuffungen führen, wenn sie auf bereits glühende Kohle geschüttet werden. Da flüssige Grillanzünder bei Kindern zu Vergiftungen führen können, empfiehlt der Berufsverband der Kinder- und Jugendärzte (BVKJ) den Gebrauch von elektrischen Grillanzündern oder Anzündern in fester Form.

Tod durch Kohlenstoffmonoxidintoxikation ist die Folge, den auch bereits abgekühlten Grill in geschlossene Räume zu bringen oder ihn dort zu betreiben. Das darin entstehende Gas Kohlenstoffmonoxid sammelt sich in geschlossenen Räumen, ist geruchlos und wird nicht bemerkt.

Wie bei allen Geräten birgt auch der Einsatz von nicht geeignetem Material Gefahren. So hat die Stiftung Warentest bei einzelnen, getesteten Elektrogrills festgestellt, dass Glasdeckel durch die Hitzeeinwirkung des Grills zerspringen und durch die Splitter eine entsprechende Verletzungsgefahr entsteht.

Grillen im Garten oder auf dem Balkon ist im deutschsprachigen Raum ein häufiger Grund für Nachbarschaftsstreit, der die Gerichte beschäftigt. Eine klare gesetzliche Regelung existiert (außer in Brandenburg) nicht, sondern hängt von Ortsüblichkeit und Ermessen ab. Dabei kommt es nicht zuletzt darauf an, ob es sich um einen Holz- oder Kohlengrill oder um einen emissionsarmen Gas- oder Elektrogrill handelt. Grundstücks- oder Wohnungseigentümern kann das Grillen allgemein schwerer verwehrt werden als Mietern und Pächtern. Mitunter ist ein Grillverbot Gegenstand von Hausordnungen in Gebäuden oder Festlegungen für Parkanlagen.





</doc>
<doc id="10403" url="https://de.wikipedia.org/wiki?curid=10403" title="Wurst">
Wurst

Wurst ist ein Nahrungsmittel, das meist aus zerkleinertem Fleisch, Speck, Salz und Gewürzen, bei bestimmten Sorten auch unter Verwendung von Blut und Innereien zubereitet wird. Die vorbereitete Masse, das Brät, wird in Därme, Blasen oder Mägen gefüllt, durch Abbinden mit Wurstgarn oder Abklammern mit rostfreien Metall<nowiki>klammern</nowiki> in einzelne Würste unterteilt und je nach Sorte durch Kochen oder Backen gegart oder durch Trocknen mit oder ohne zusätzliches Räuchern konserviert. Bei der Wurstherstellung werden auch Kunstdärme, Gläser und Konservendosen verwendet.

Zur Herstellung von Wurst wird Fleisch (vor allem vom Schwein, Rind und Kalb, daneben auch von Lamm, Geflügel (Geflügelwurst), Pferd und Wild) und Speck mit dem Fleischwolf zerkleinert und mit den Gewürzen versetzt. Für feine Würste wird die Masse zusätzlich mit dem Kutter, unter Beifügen von Eis, zu einem homogenen Teig verarbeitet.

Nach den Herstellungsverfahren werden Wurstsorten in drei Gruppen unterteilt:




Einzelne Spezialitäten werden auch mit anderen Zutaten angereichert wie bestimmte Salamisorten mit Nüssen (auch die französische Saucisson aux noisettes), Pfälzer Saumagen mit Kartoffeln, und in neuerer Zeit Käseknacker mit Käse sowie eine Vielzahl von Aufschnittsorten mit Gemüse oder mit Pilzen, meist Champignons. In Mittelmeerländern wird statt Zwiebeln auch Knoblauch verwendet. Weitere Zutaten können regionale Spezialitäten sein, in Italien Pistazien und Grappa, in Frankreich Edelkastanien oder im Schwarzwald Kirschwasser. Französische Andouille und Andouillette werden ausschließlich aus Innereien hergestellt.

Verwandt mit der Wurst ist die "Terrine", eine teiglose Variante der Pastete.

Würste und Würstchen gibt es in vielen Längen, Stückgewichten und Kalibern. Zu den größten Würsten zählt beispielsweise die italienische Mortadella mit bis zu 100 kg Gewicht und Durchmessern bis zu 300 mm. Zu den kleinsten Würstchen zählen u. a. Cocktailwürstchen, sie wiegen nur ca. 30 Gramm oder Nürnberger Rostbratwurst, welche nur 7 bis 9 Zentimeter lang sind.

Technisch, chemisch oder mikrobiell verursachte, qualitätsmindernde Eigenschaften von Würsten und Wurstwaren, die nicht notwendigerweise mit Verderb in Beziehung stehen, bezeichnet man als Wurstfehler. Hierzu zählen:


Häufige Wurstfehler von Rohwürsten sind grauer oder trockener Rand, grauer Kern, Rissbildung, unklares Schnittbild und Verschimmeln. Auch Brühwürste können grau gefärbt sein, können aufplatzen oder ungeräucherte Sattelstellen (Knicke nahe den Wurstenden) aufweisen. Bei Kochwürsten treten ein noch blutiger Kern, saurer Geschmack, Fettabsatz und unzureichende Bindung auf.

Die Wurst war und ist auch heute noch das Produkt des Wunsches nach möglichst weitgehender Verwertung eines (geschlachteten) Tieres. Durch die Verarbeitung zu Wurst kann Fleisch länger haltbar gemacht werden. Die ersten Würste, wenn auch nicht im heutigen Sinne, wurden vermutlich bereits in früher Zeit hergestellt, siehe dazu Haggis. Eine erste chinesische Erwähnung zu einer Wurst findet sich um das Jahr 589 v. Chr. Bei dieser wurden Lamm- und Ziegenfleisch verwendet.

Homer erwähnt in seiner Odyssee eine Art von Blutwurst. Diese blutgefüllten Tierdärme wurden von den griechischen Kriegern mit in die Schlacht genommen, um göttlichen Beistand zu erhalten. Diese Geschichte gehört möglicherweise zu den Legenden. Die antiken Griechen und Römer kannten bereits die Herstellung von Wurst, so zum Beispiel die Lucanicae, zudem ein Beispiel für einen lateinischen Lebensmittelbegriff, der sogar in die griechische Sprache eingegangen ist. Aus der Antike verbreitete sich die Wurstfertigung schließlich über ganz Europa. Die Lagerung von Wurst brachte spezielle Möbel hervor, z. B. die Wurstkrone.

Rohrman et al. veröffentlichten im März 2013 eine Analyse der EPIC-Daten, die den Zusammenhang zwischen dem Konsum von unter anderem verarbeitetem Fleisch und dem Risiko für einen frühen Tod untersuchte. Die Forscher werteten die Daten von insgesamt 448568 Männern und Frauen aus, die zu Studienbeginn noch nicht an Krebs erkrankt waren und auch keinen Schlaganfall oder Herzinfarkt gehabt hatten. Bei allen Teilnehmern war bekannt, wie sie sich ernährten, wie viel sie sich bewegten, ob sie rauchten und wie ihr Body-Mass-Index war. Am Anfang der Studie waren alle Teilnehmer zwischen 35 und 69 Jahre alt. Sie stammten aus zehn europäischen Ländern und wurden im Durchschnitt 12,7 Jahre lang begleitet. 26344 Teilnehmer starben in diesem Zeitraum. Die Analyse zeigte, dass der Konsum von verarbeitetem Fleisch statistisch signifikant mit einer höheren Sterblichkeit korreliert: Jene Teilnehmer, die täglich mehr als 160 Gramm verarbeitetes Fleisch aßen, hatten ein 44 Prozent höheres Risiko, in der Zeit der Studie zu sterben, als Teilnehmer, die nur rund 20 Gramm pro Tag verzehrten. Die Wissenschaftler erklärten sich dieses Analyseergebnis damit, dass verarbeitetes Fleisch häufig einen viel höheren Fettanteil als unverarbeitetes Fleisch hat und mit Speisesalz und anderen potentiell gesundheitsschädlichen Stoffen behandelt wird.

Eine Reihe von Redewendungen bezieht sich auf die Herstellung oder das Aussehen von Würsten. , oder wird Otto von Bismarck zugeschrieben. Das Bonmot geht auf den amerikanischen Dichter John Godfrey Saxe (1816–1887) zurück und wird seit den 1930er Jahren mit Bismarck in Verbindung gebracht.
Eine häufige Redewendung lautet „Ist mir Wurst“ oder „Ist mir Wurscht“ im Sinne von „Ist mir gleichgültig“. Laut Walther Mitzka stammt die Wendung aus der Studentensprache; ihre Bedeutung ist ungeklärt. Er vermutet, dass es sich um eine Verkürzung von "ist mir Wurst wie Pelle" handeln könne und eine Analogiebildung zu "Jacke wie Hose". Hans-Martin Gauger hält eine vulgäre Assoziation mit "scheißegal" nicht für ausgeschlossen, Wolfgang Seidel sieht die Wurst im Hinblick auf das mit ihr verbundene alltägliche Wurstbrot als „Inbegriff des Alltagseinerleis“. Weitere gängige Redewendungen sind „Es geht um die Wurst“ (= „Jetzt kommt es zur letzten Entscheidung“) und „Alles hat ein Ende, nur die Wurst hat zwei“.




</doc>
<doc id="10405" url="https://de.wikipedia.org/wiki?curid=10405" title="Südkorea">
Südkorea

Die Republik Korea (kor. , , [], "Daehan Minguk"), meist Südkorea genannt, liegt in Ostasien und nimmt den südlichen Teil der Koreanischen Halbinsel ein. Als einzige Landgrenze, mit 243 km Länge, besteht faktisch nur die Grenze zum nördlichen Nachbarn Nordkorea. Die beiden Nachfolgestaaten Chōsens wurden 1948 im aufkommenden Kalten Krieg gegründet; der folgende Koreakrieg zementierte die Teilung Koreas. Der Norden wurde sozialistisch und autokratisch, während im kapitalistischen, diplomatisch nach Westen orientierten Südkorea mit der Zeit eine parlamentarische Demokratie etabliert werden konnte. Im Westen grenzt Südkorea an das Gelbe (in Südkorea: Westmeer), im Süden an das Ostchinesische und im Osten an das Japanische Meer (in Südkorea: Ostmeer).

Mit rund 51,5 Millionen Einwohnern zählt Südkorea zu den dicht besiedelten Staaten und zu den 30 bevölkerungsreichsten Staaten der Erde. Etwa die Hälfte der Einwohner lebt im Großraum der Hauptstadt Seoul, einer Weltstadt mit der viertgrößten Wirtschaft weltweit. Über zwei Millionen Menschen leben jeweils in den Städten Busan, Incheon und Daegu.

„Das Wunder am Han-Fluss“, wie die Zeit des rapiden Wirtschaftsaufschwungs ab 1962 genannt wird, machte Südkorea schnell von einem armen Agrarland zu einem modernen Industriestaat. Man spricht auch von einem Tigerstaat. In der Produktion von Schiffen und elektronischen Produkten wie Halbleitern, Mikrochips, Flachbildschirmen und Computern hat die südkoreanische Industrie eine marktbeherrschende Stellung erreicht. Auch dadurch nimmt die kulturelle Bedeutung des Landes zu, was etwa in der "Koreanischen Welle" Ausdruck findet. Das Land ist Mitgliedsstaat der Vereinten Nationen, der G20, der OECD, der APEC und ASEAN+3.

Der offizielle deutsche Staatsname lautet "Republik Korea"; umgangssprachlich spricht man jedoch meist von "Südkorea". Auf Koreanisch heißt das Land offiziell "Daehan Minguk" (, ; dt. „Republik Groß-Korea“). Allgemein wird es in Südkorea in seiner Kurzform "Hanguk" (, , „Staat Korea“) oder "Namhan" (, , „Südkorea“) genannt, in Abgrenzung zu "Bukhan" (, , „Nordkorea“). Da in Nordkorea „Korea“ nicht als "Han", sondern als "Chosŏn" bezeichnet wird, heißt „Südkorea“ dort entsprechend "Nam-Chosŏn" (, ).

Das Wort "Han" (, ) geht auf den historischen Reichsbund Samhan (, ; „Drei Koreas“) zurück, der aus den Reichen Mahan, Jinhan und Byeonhan gebildet war und im Zeitraum vom ersten bis vierten Jahrhundert n. Chr. bestand. Dieser Name wurde in der Bezeichnung des im Jahr 1897 gegründeten Kaiserreichs "Daehan Jeguk" (Kaiserreich Groß-Korea) wieder aufgegriffen.

Der Name in den westlichen Sprachen hat seinen Ursprung in "Cauly", wie Marco Polo die Halbinsel während seiner Reisen im späten 13. Jahrhundert nannte. Dies beruht vermutlich auf der chinesischen Aussprache des koreanischen Königreichs Goryeo (chinesisch "Gāolì"). In europäischen Aufzeichnungen tauchen bis ins 20. Jahrhundert hinein die beiden Schreibweisen "Corea" und "Korea" auf. Im englischen und deutschen Sprachraum setzte sich schließlich die Schreibweise mit "K", in romanischen Sprachen die Schreibung mit "C" durch.

Südkoreas Fläche beträgt 100.284 Quadratkilometer. Davon entfallen 290 Quadratkilometer auf Wasserflächen; es gibt keine größeren natürlichen Seen.

Südkorea umfasst den südlichen Teil der Koreanischen Halbinsel und vorgelagerte Inseln. Nahe der Westküste und im Südosten liegt ebenes, aber fast überall mit Hügeln durchsetztes Land, das höchstens ein Drittel des Staatsgebiets ausmacht, aber die große Mehrheit der Einwohner beherbergt. Der große Rest des Landes ist gebirgig; außer auf einem schmalen Streifen an der Ostküste und in kleinen Talgründen gibt es keine Tiefebenen. Sowohl die Gebirge als auch die Hügel der Ebenen sind meist bewaldet; sie erreichen zwar selten große Höhen, haben aber oft ein steiles Relief.

Etwa 70 % Südkoreas sind gebirgig. Höchster Berg ist der Vulkan Hallasan mit 1950 Metern auf der Insel Jeju, auf dem südkoreanischen Festland sind am höchsten der Jirisan im Süden mit 1915 Metern und der Seoraksan im Nordosten mit 1708 Metern. Südkorea wird von fünf größeren Gebirgen durchzogen, das größte ist das Taebaek-Gebirge. Er beginnt im südöstlichen Nordkorea und zieht sich dann fast die gesamte Ostküste Südkoreas entlang. Vom Taebaek zweigt der zweitgrößte, Sobaek genannte Gebirgszug in südwestlicher Richtung ab; er zieht sich durch das Zentrum des Landes. Kleiner sind das Gwangju-, das Charyeong- und das Noryang-Gebirge. Die aus Nordkorea über den Seoraksan bis zum Jirisan verlaufende Hauptwasserscheide heißt Baekdudaegan (; ).

Vier größere Flüsse durchziehen Südkorea. Der längste von ihnen heißt Nakdonggang und hat eine Länge von 525 Kilometern. Er entspringt am Berg Taebaek, fließt von dort, anders als die meisten Flüsse des Landes, nach Süden und mündet bei Busan ins Ostmeer. Zweitlängster Fluss ist der Hangang, dessen Nordarm eine Länge von 497,5 Kilometern hat und in Nordkorea entspringt. Sein Südarm entspringt ebenfalls am Berg Taebaek. Beide Han-Flüsse vereinigen sich etwa 35 Kilometer vor Seoul, bevor sie vereint die Hauptstadt mittig durchfliessen und kurz danach als Grenzfluss zu Nordkorea in das Gelbe Meer münden. Relativ kurz sind der Geumgang (401 Kilometer) und der Seomjingang (212 Kilometer).

Südkorea stößt an drei Seiten ans Meer:

Die Küsten im Westen und Süden weisen als Ria viele Buchten und Halbinseln auf, denen rund 4400 mittelgroße und kleinere Inseln vorgelagert sind. Davon sind weniger als 500 bewohnt. An der Westküste liegt auch das zweitgrößte Wattenmeer der Erde mit dem Namen Saemangeum. Der buchtenarmen und vielerorts steilen Ostküste sind nur wenige und sehr kleine Inseln und Felsen vorgelagert.

Die mit Abstand größte Insel heißt Jejudo. Sie liegt rund 150 Kilometer südlich der Südwestküste des Festlands, ist 1845,6 Quadratkilometer groß und bildet mit einigen kleinen Inseln die Provinz Jeju-do.

Etwa zwei Drittel des Landes sind bewaldet. Die ursprünglichen Mischwälder mit Eichen, Ahorn, Buchen, Ulmen, Pappeln, Fichten und Espen sind an vielen Stellen einem Sekundärwald gewichen, da sehr viel Wald dem Brennholzbedarf und dem Brandrodungsfeldbau zum Opfer gefallen ist. In höheren Lagen schließt Nadelwald mit Fichten und Lärchen an. Die Pflanzenwelt Südkoreas ist beträchtlich artenreicher als die Mitteleuropas. Allein die leicht sichtbaren höheren Pflanzen sind mit etwa 3400 Arten und Unterarten in 880 Gattungen vertreten. So reicht Koreas Pflanzenpalette von alpinen Latschen und Rhododendren oberhalb der Baumgrenze im Nordgebirge bis zum subtropischen Bambus, Lorbeer und Kamelien an der warmen Südküste und auf Jejudo.

Große Säugetiere wie Tiger, Leoparden und Bären waren auf der gesamten Koreanischen Halbinsel verbreitet; durch Abholzung und Wilderei sind sie aber praktisch aus Südkorea verschwunden. In den Wäldern leben Luchse und Bengalkatzen, an den Küsten gibt es Seehunde. Bemerkenswerte Vogelarten sind Mandarinente, Weißbauch-Schwarzspecht, Mandschurenkranich und Halsring-Zwergohreule. Etwa 3,9 % der Staatsfläche Südkoreas stehen unter Naturschutz.

Südkorea liegt in der gemäßigten Klimazone, man unterscheidet dort vier verschiedene Jahreszeiten. Ausgenommen hiervon sind einige subtropische Täler an der Südküste von Jejudo sowie einige Höhenregionen über 1700 Meter.

Der Frühling beginnt meist zwischen Ende März und Anfang April und ist mild und recht sonnig. Die Winde tragen dann oft feinen gelben Wüstenstaub aus der Wüste Gobi nach Südkorea. Im Sommer führen Südwinde heiße, feuchte Luft von den Philippinen herbei. Die sommerliche Monsunzeit, in Südkorea "Jangma" () genannt, beginnt meist Ende Juni oder Anfang Juli. Ein Großteil der jährlichen Niederschläge geht in dieser Zeit auf Südkorea nieder. Regen wechselt dabei mit klaren Tagen. Dem folgt ein sehr heißer Mittsommer, der vor allem durch die hohe Luftfeuchtigkeit nur schwer erträglich ist. Die Tageshöchsttemperatur übersteigt dann oft 30 °C, begleitet von einer Luftfeuchtigkeit von 80 bis 95 %.

Mitte September setzt der Herbst ein, wenn die Winde wieder aus Nordwest wehen. Die trockene Kontinentalluft sorgt für viel Sonne, während die Temperatur langsam zu sinken beginnt. Der Winter ist in Südkorea sehr kalt und trocken. Die Winde aus Sibirien bringen selten Schnee. Ab Januar sorgt eine besondere Klimakonstellation für ein eigentümliches Temperaturschema, bei dem sich drei kalte Tage mit vier etwas milderen abwechseln.

Die Durchschnittsdaten einzelner Regionen weichen teilweise deutlich von den genannten ab. In den nördlichen und zentralen Regionen muss mit höheren Temperaturdifferenzen übers Jahr gerechnet werden als in den südlichen Küstengebieten. An der Ostküste ist es meist etwas wärmer als an der Westküste, da das Taebaek-Gebirge am Einfallen kalter Winde aus Sibirien hindert.

Anders als das benachbarte Japan ist Südkorea kaum von Naturkatastrophen betroffen. So ereignen sich in Südkorea nur durchschnittlich 20 Erdbeben pro Jahr. Davon liegen im Mittel 9,2 Erdbeben jährlich über dem Wert 3,0 auf der Richterskala (entspricht der „Wahrnehmungsschwelle“ eines Erdbebens). Im langjährigen Trend hat die Anzahl der Beben allerdings seit 1992 wieder zugenommen. Im Jahr 2006 ereigneten sich insgesamt 50 Erdbeben, im Jahr 2007 waren es insgesamt 42 und im Jahr 2008 insgesamt 46. In Japan hingegen werden im Jahr rund 1200 Erdbeben mit Intensitäten größer 3,0 auf der Richterskala gezählt. In Südkorea gibt es allerdings keine aktiven Vulkane.

Vor allem in der Zeit zwischen Ende Juli und Anfang September können Taifune auftreten, die meist aber ihre Kraft schon verlieren, bevor sie Südkorea erreichen. Von März bis Mai ist die Luft bisweilen mit feinem gelbem Wüstensand (kor. "hwangsa") gefüllt, der aus China oder der Mongolei zusammen mit Schadstoffen herüberweht und sich wie eine Nebelglocke über das Land legt.

Größte Stadt ist mit 10.103.233 Einwohnern die Hauptstadt Seoul im Nordwesten. Zusammen mit den umliegenden Städten bildet sie die Sudogwon genannte Metropolregion, mit etwa 25 Millionen Einwohnern nach Tokio den zweitgrößten Ballungsraum der Welt. Im äußersten Südosten der Halbinsel liegt Südkoreas zweitgrößte Stadt Busan (3.519.401 Einwohner); sie besitzt einen der umschlagstärksten Häfen der Welt. Danach folgen die vor den Toren Seouls an der Westküste gelegene Hafenstadt Incheon (2.902.608 Einwohner) sowie das im südöstlichen Landesinneren befindliche Daegu mit 2.493.264 Einwohnern. Fünftgrößte Stadt ist das zentral gelegene Daejeon mit 1.531.809 Einwohnern, sechstgrößte Gwangju mit 1.475.884 Einwohnern im Südwesten. Anders als die zuvor genannten Städte sind Suwon (1.174.228 Einwohner), Goyang (1.006.154 Einwohner) und Seongnam (974.608 Einwohner) keine politisch einer Provinz gleichgestellten Gebilde, sondern gehören zur Provinz Gyeonggi-do. Sie liegen wie Incheon so nahe bei Seoul, dass sie inzwischen an dessen U-Bahn-Netz angeschlossen wurden. Achtgrößte Stadt ist das am südlichen Teil der Ostküste gelegene Ulsan mit 1.166.377 Einwohnern.

Das schnelle Wirtschaftswachstum Südkoreas führte zu zahlreichen Nebenwirkungen auf die Umwelt. Emissionen aus Industrie und Verkehr erzeugen eine hohe Luftbelastung und lassen sauren Regen entstehen. Pro Kopf werden in Südkorea jährlich 9,5 Tonnen Kohlenstoffdioxid (Schätzung für 2002) ausgestoßen. Südkorea hatte 2015 die neunt-höchsten CO- Emissionen. Südkorea ist trotz seiner relativ kleinen Bevölkerung der weltweit zweitgrößte Konsument von FCKW. Ein weiteres großes Problem stellen die Verschmutzung der Gewässer durch Abwässer aus Wohngebieten und Industrie sowie die rasch wachsenden Müllberge dar, die teilweise durch die verschwenderische Verpackung von Konsumgütern ausgelöst wird. Das Problem der grenzüberschreitenden Umweltverschmutzung versucht das Umweltministerium Südkoreas zusammen mit den zuständigen Stellen Japans und der Volksrepublik Chinas zu lösen.

In der Asienkrise wurde sichtbar, dass die südkoreanische Wirtschaft sehr stark von Energieimporten abhängig ist. Südkorea hat sich deshalb für das 21. Jahrhundert die Förderung von erneuerbaren Energien zum Ziel gesetzt. Seit 2008 existiert das Regierungsprogramm: „Low Carbon, Green Growth“. Es beinhaltet langfristige Strategien zur Förderung grüner Umwelttechnologien. Im Januar 2009 wurde im Zuge der Weltwirtschaftskrise ein weiteres grünes Konjunkturprogramm in Höhe von 50 Billionen Won aufgelegt.
Zusätzlich folgte im Juli 2009 ein Fünfjahresplan für grünes Wachstum, der 107 Billionen Won beinhaltet und ebenfalls nachhaltiges Wirtschaften fördern soll. Insgesamt zielen die Programme auf den Ausbau regenerativer Energien, der Revitalisierung verschmutzter Flüsse, einer umweltverträglichen Verkehrsinfrastruktur und Energiersparmaßnahmen. Außerdem sollen 1,8 Millionen neue Arbeitsplätze im Umweltsektor damit geschaffen werden.

Südkorea hatte (Stand Oktober 2015) rund 51,501 Millionen Einwohner und wies zu der Zeit eine Bevölkerungsdichte von etwa 513 Personen pro Quadratkilometer auf. Rund 92 % aller Südkoreaner leben in Städten. Das Bevölkerungswachstum lag 2015 bei jährlich 0,25 %. Prognosen sagen ab dem Jahr 2028 eine Schrumpfung der Bevölkerungszahl voraus. Am 30. September 2010 wurde der 50-millionste Einwohner bei den Behörden registriert. In der offiziellen Mitteilung des „Ministry of Public Administration & Security“ (MOPAS) waren davon 25.034.736 männlich und 24.942.224 weiblich (was in Summe nicht exakt der ebenfalls in der offiziellen Mitteilung genannten Gesamtzahl entspricht). Man geht davon aus, dass es rund 466.000 nichtregistrierte Einwohner gibt.

Die Südkoreaner haben eine sehr hohe Lebenserwartung, sie lag 2015 bei insgesamt 82,4 bei 79,3 Jahren für Männer und 85,8 für Frauen. Die Lebenserwartung in Südkorea ist in den letzten Jahrzehnten enorm angestiegen, im Jahre 1955 betrug sie laut Zahlen der UN noch 47 Jahre. Dies trägt zu einer schnellen Alterung der Bevölkerung bei. Waren etwa 2000 nur 7,2 % der Bevölkerung 65 Jahre oder älter, so erreichte der Anteil dieser Altersgruppe im Jahre 2015 schon 13,1 %. Das Medianalter beträgt 40,8 Jahre. Die Fertilitätsrate ist eine der niedrigsten der Welt und liegt bei nur 1,25 Kinder pro Frau. Wenn die Geburtenrate nicht gesteigert wird droht Südkorea eine regelrechte "Vergreisung".

Die Gesamtbevölkerung der Koreanischen Halbinsel, also die der heutigen Staaten Nord- und Südkoreas zusammen, ist in ethnischer Hinsicht weitgehend homogen. Da der Vorgängerstaat Korea seit der Vereinigung durch das Silla-Reich im Jahre 668 bis zur Teilung nach dem Zweiten Weltkrieg 1945 fast immer eine politische Einheit war, entwickelte sich auch eine weitgehend einheitliche Kultur mit nur geringen regionalen Unterschieden. Nach dem Ende des Koreakriegs setzte in Südkorea eine Landflucht von den ländlichen Gebieten in die Städte, und hier insbesondere nach Seoul ein. Seit 1990 sind aber zunehmend die Vororte von Seoul Siedlungsziel, wo mit großangelegten Bauprogrammen ganze Satellitenstädte hochgezogen wurden.

Während der Nachkriegsära wurden die Chinesen diskriminiert, da die Regierung eine ethnisch möglichst homogene Bevölkerung anstrebte. In den 1960er Jahren gab es gesetzliche Regelungen, die die Größe des Besitzes von Ausländern regelte, dies betraf vor allem die Chinesen. Die Staatsbürgerschaft Südkoreas zu erlangen war kompliziert. Die Chinesen in Südkorea wurden als Staatsbürger der Republik China angesehen, die auch die chinesischsprachigen Schulen in Südkorea finanzierten. Da Südkorea neben Japan die Asienkrise im Jahre 1997 am besten überstanden hat, ist eine große Zahl von Arbeitern aus anderen Teilen Asiens (Thailand, Philippinen und Indien) und sogar aus Afrika nach Südkorea eingewandert, um in den großen Fabriken Arbeit zu finden. Viele hiervon befinden sich illegal im Land. Durch die Beziehungen zu den USA seit der Nachkriegszeit haben sich mittlerweile auch viele US-Amerikaner angesiedelt, im Stadtteil Itaewon von Seoul prägen sie das Bild. Hier befindet sich unter anderem auch das „UN-Dorf“ nebst vielen Botschaften und ausländischen Unternehmen. Von 2004 bis 2014 stieg die Anzahl an registrierten Ausländern in Südkorea von etwa 469.000 auf 1,1 Millionen.

Die Zahl der sich in Südkorea aufhaltenden Volksrepublik-Chinesen belief sich Ende November 2010 auf 0,61 Mio., darunter 0,4 Mio. Koreaner mit chinesischer Staatsangehörigkeit der Volksrepublik. Diese Chinesen stellen somit gefolgt von Amerikanern (128 Tsd.), Vietnamesen (120 Tsd.), Philippinern (47 Tsd.), Japanern (41 Tsd.), Thailändern (40 Tsd.), Mongolen (30 Tsd.) und Indonesiern (29 Tsd.) die größte ausländische Bevölkerungsgruppe in Südkorea dar.

Auf der anderen Seite wohnen viele ethnische Koreaner im Ausland, insbesondere in den Vereinigten Staaten und der Volksrepublik China, wo jeweils rund zwei Millionen Koreaner leben. Etwa 660.000 leben in Japan, etwa eine halbe Million lebt in Russland und den übrigen ehemaligen Sowjetrepubliken.

Statistiken zeigen, dass die Selbsttötungsrate in Südkorea unter allen OECD-Staaten am höchsten ist. Die Rate liegt 2012 bei 29,1 Selbsttötungen pro 100.000 Personen. Selbsttötung gilt als großes Problem in Südkorea und sorgt für viel Aufmerksamkeit aufgrund einiger Selbsttötungen von Prominenten. Es ist die Haupttodesursache unter Personen zwischen 10 und 39 Jahren.

Quelle: UN, Zahlen für 2030 und 2050 sind Prognosen

Die Religionsfreiheit wird durch die Verfassung garantiert. Eine offizielle Staatsreligion gibt es entsprechend nicht. Daher weist die Religionslandschaft in Südkorea eine Vielfalt auf. Dennoch verfügen einige bestimmte Religionen über die Mehrheit der Bevölkerung. Um 2011 waren 31 % der Südkoreaner als religionslos bekannt, 31 % waren Christen (23,8 % der Bevölkerung evangelisch), 23,7 % Buddhisten und 7 % Angehörige der koreanischen Schamanenreligion.

Der Schamanismus ist das ursprüngliche Glaubenssystem Koreas. Er ähnelt in vieler Hinsicht den schamanischen Bräuchen der benachbarten Länder und gründet auf den Glauben an Geister, die es zu beschwichtigen und von denen es Schutz zu erbitten gilt.

Der Buddhismus erreichte Nord- und Südkorea von Indien aus über China und wurde im Jahre 372 in Goguryeo, 384 in Baekje und 528 n. Chr. in Silla Staatsreligion. Seine Blütezeit hatte er, als Silla beinahe die gesamte Koreanische Halbinsel erobert hatte. Während der Joseon-Dynastie galt er als Wurzel der Korruption und wurde unterdrückt. Die Mönche zogen sich meist in die Berge zurück, und der Buddhismus verlor an Einfluss, verschwand aber nie ganz. Buddhistische Schulen koreanischer Herkunft gibt es heute teilweise auch in den USA und in Europa.

Ab etwa 600 n. Chr. erlangte der Konfuzianismus in Korea zunehmende Bedeutung. Weniger eine echte Religion als vielmehr eine Gesellschaftsordnung, prägt diese Philosophie bis heute die südkoreanische Gesellschaft wesentlich. Da er aber erst seit 1995 offiziell als Religion anerkannt wird, gibt ihn heute kaum ein Südkoreaner als seine Religion an. Das ist vermutlich der Hauptgrund für die vergleichsweise hohe Religionslosigkeit in Südkorea.

Das Christentum in Korea breitete sich ab dem Jahr 1784 durch koreanische Intellektuelle aus, die bei Bildungsreisen in China mit der Religion in Kontakt gekommen waren. Chinesische Großstädte bildeten damals Anlaufstellen westlicher Kulturen und europäische Missionare gründeten Schulen und Kirchen. Die sich in Korea langsam und meist heimlich vermehrenden Christen wurden von der konfuzianistisch geprägten Monarchie unterdrückt, bis im Jahr 1882 die Religionsfreiheit gewährt wurde. Seit den 1960er Jahren erlebte das Christentum mit dem Wirtschaftsaufschwung und der damit verknüpften Ausbreitung der Bildung einen beispiellosen Aufstieg. Südkorea ist nach den Philippinen und Osttimor das ostasiatische Land mit dem höchsten Bevölkerungsanteil bekennender Christen. Von den christlichen Konfessionen stellen mit Abstand die evangelischen Kirchen, insbesondere die presbyterianischen Kirchen unter anderen reformierten Kirchen, den größten Anteil dar. Dies erklärt neben dem starken angloamerikanischen theologischen Einfluss die recht große Wirksamkeit und Bekanntheit deutschsprachiger Theologen wie z. B. Karl Barth, Dietrich Bonhoeffer und Emil Brunner im Land.

Der zunehmende Einfluss des christlichen Fundamentalismus und die Verknüpfung zwischen der Kirche und Politik prägen neuerdings die reformierte Kirche und die Gesellschaft Südkoreas. Beispielsweise wurde innerhalb des staatlichen "Korea Advanced Institute of Science and Technology", eines der führenden Forschungsinstitute des Landes, eine Arbeitsgruppe für die Kreationismus-Forschung eingerichtet. Pläne zur Streichung von Passagen zur Evolutionstheorie aus Schulbüchern, die dem Kreationismus widersprechen, wurden nach öffentlichen Protesten von Wissenschaftlern allerdings verworfen.

Mehrere neue religiöse Bewegungen entstanden ebenfalls in Korea, inklusive Daesoon Jinrihoe und Siegesaltar.

Die koreanische Sprache ist in Südkorea offizielle Amts- und Schriftsprache. Anerkannte Minderheitensprachen gibt es nicht. Die koreanische Sprache wird von einigen Sprachwissenschaftlern zu den Altaisprachen gezählt, von anderen als isolierte Sprache angesehen. Möglicherweise ist sie mit dem Japanisch-Ryūkyū näher verwandt. Koreanisch sprechen weltweit etwa 78 Millionen Menschen. Die Unterschiede zwischen den regionalen Dialekten sind marginal, mit Ausnahme des auf Jejudo gesprochenen Dialekts. Für viele Begriffe hat die Sprache sowohl ein rein koreanisches als auch ein dem Chinesischen entlehntes sogenanntes sinokoreanisches Wort. Darüber hinaus werden heute viele englische Wörter in die koreanische Sprache übernommen.

Englisch wird als erste Fremdsprache von der Grundschule an unterrichtet. In den oberen Stufen kommt eine zweite Fremdsprache hinzu. Die traditionellen Sprachen seit der Nachkriegszeit waren bisher Deutsch, Französisch oder Japanisch, in seltenen Fällen Spanisch. Die Bedeutung der europäischen Sprachen ist seit den 1990er Jahren zurückgegangen. Insgesamt ist das Interesse für eine zweite Fremdsprache kleiner geworden, während die Betonung auf den Englischunterricht zunehmend stärker geworden ist. Ein neues Phänomen ist die in letzter Zeit steigende Anfrage nach Chinesisch, was auf die wachsende Rolle der Volksrepublik China für Korea zurückzuführen ist.
Die koreanische Schrift Hangeul ist eine Alphabetschrift mit 24 Buchstaben, 10 Vokalen und 14 Konsonanten. Diese Buchstaben werden silbenweise zu Blöcken kombiniert, wodurch der Eindruck entstehen kann, sie sei ähnlich komplex wie die chinesische Schrift. Tatsächlich ist die Schrift sehr logisch aufgebaut. Die chinesische Schrift, in Nord- und Südkorea Hanja genannt, war auf der Koreanischen Halbinsel bis zum Ende der japanischen Kolonialzeit im Jahre 1945 Amtsschrift, trotz der Einführung der Hangeul-Schrift durch Großkönig Sejong im 14. Jahrhundert. Chinesische Zeichen haben im heutigen Alltagsgebrauch eine deutlich geringere Bedeutung als in Japan. In südkoreanischen Veröffentlichungen werden zum Teil Wörter in Hangeul durch ihre in Klammern gesetzten Entsprechungen in Hanja ergänzt, um besonders bei Homonymen die Bedeutung zu verdeutlichen. Veröffentlichungen, die ausschließlich Hanja verwenden, sind aber die Ausnahme. An südkoreanischen Schulen lernen die Schüler heute rund 1800 Hanja-Zeichen, auf Universitäten kommen weitere Zeichen aus den eingeschlagenen Fachrichtungen dazu. Allgemein geht der Gebrauch von Hanja aber zurück. Dies hängt auch mit der allgemeinen Bewegung zusammen, die Rolle der koreanischen Sprache sowohl in der schriftlichen als auch in der mündlichen Praxis zu stärken. Auch seitens der Sprachwissenschaft und den Medien gibt es Bemühungen, die koreanische Sprache zu pflegen.

Es gibt einen kleinen Flüchtlingsstrom von Nordkorea nach Südkorea über Drittstaaten. Das Entkommen aus dem diktatorischen Regime Nordkoreas ist generell mit großen Schwierigkeiten verbunden. Um die Flüchtlinge an die Lebensweise in einer Demokratie zu gewöhnen, existiert das Umerziehungslager Hanawon, in dem Stand Januar 2014 etwa 160 Nordkoreaner auf eine schlussendliche „Einbürgerung“ warten. Bis Ende 2015 siedelten etwa 29.000 Menschen aus Nordkorea nach Südkorea aus.

"Die Geschichte vor dem Zweiten Weltkrieg ist unter Geschichte Koreas zu finden."

Nachdem 1945 durch die Kapitulation Japans der Zweite Weltkrieg sein Ende genommen hatte, wurde die Provinz Chōsen, die dem Gebiet des seit 1910 in das Japanische Kaiserreich eingegliederten und kolonisierten Koreas entsprach, von den Siegermächten entlang des 38. Breitengrads in zwei Besatzungszonen aufgeteilt. Dies entsprach der Konferenz von Jalta der Alliierten im Februar 1945. (Zuvor hatten die Alliierten 1943 auf der Konferenz von Kairo beschlossen, Korea solle zu gegebener Zeit seine staatliche Unabhängigkeit erhalten.) Der südliche Teil Chōsens wurde von US-amerikanischen Truppen besetzt, der nördliche Teil kam unter Kontrolle der Roten Armee. Die Alliierten beaufsichtigten die Entwaffnung und den Abzug der japanischen Soldaten aus Chōsen.

Ursprünglich sollte die Verwaltung des Landes bis zur Bildung einer gesamtkoreanischen Regierung von den USA und der Sowjetunion übernommen werden. Diese wurde allerdings nie erreicht. Stattdessen errichteten die Sowjetunion im Norden und die USA im Süden Besatzungszonen mit Militärregierungen. Als im Jahre 1947 die Generalversammlung der Vereinten Nationen auf Antrag der USA beschloss, in den beiden Landesteilen Wahlen abzuhalten, lehnte dies die Sowjetunion ab. Daher fand die Wahl am 10. Mai 1948 nur im Süden statt. Am 15. August 1948 kam es dann zur Staatsgründung der "Republik Korea". Die USA übergaben offiziell die Macht an die gewählte Regierung, beließen aber ihre Truppen im Land. Der Norden beantwortete die einseitige Staatsgründung im Süden mit Gründung der Demokratischen Volksrepublik Korea am 9. September 1948 in Pjöngjang. Beide Staaten sahen sich als einzige rechtmäßige Regierung der gesamten Koreanischen Halbinsel und kündigten an, darum auch kämpfen zu wollen.

Bereits unter Verwaltung der US-Militärregierung (USAMGIK) begannen ab April 1948 genozidähnliche Massaker von antikommunistischen Polizeieinheiten und südkoreanischen Truppen an vermeintlichen Unterstützern von Sozialrebellen, wie das Jeju-Massaker. Auf der Insel Jeju wurde mindestens jeder zehnte Einwohner getötet. Weitere Massaker in Südkorea wurden während des Koreakrieges verübt. Die Massaker wurden von Offizieren der US-Streitkräfte begleitet und teilweise fotografiert.

Mitte des Jahres 1949 waren die Truppen der Sowjetunion vertragsgemäß aus Nordkorea abgezogen. Nordkorea konnte mit Hilfe der Sowjetunion und Chinas seine Industrie schneller aufbauen als Südkorea. Dies lag daran, dass die Schwerindustrie von den Japanern während ihrer Kolonialzeit vor allem im rohstoffreicheren Norden angesiedelt worden war. Im landwirtschaftlich fruchtbareren Süden dagegen wurde von ihnen die Landwirtschaft gefördert und ausgebaut. Daher und dank der Hilfe der Sowjetunion war Nordkorea auch schneller in der Lage, sich wirtschaftlich zu erholen und eine schlagkräftige Armee aufzubauen.

Am 25. Juni 1950 überschritt die Nordkoreanische Volksarmee die Grenze am 38. Breitengrad und leitete damit den Koreakrieg ein. Der amerikanische Präsident Harry S. Truman hatte bereits wieder einige Truppen nach Südkorea geschickt, die keinesfalls stark genug waren, die materielle Überlegenheit der nordkoreanischen Truppen über die südkoreanische Armee auszugleichen. Die Hauptstadt Seoul fiel bereits nach drei Tagen, etwa einen Monat später kontrollierten die Nordkoreaner bereits die gesamte Koreanische Halbinsel bis auf einige Inseln und einen schmalen Streifen um Busan im Südosten. Erst hier gelang es den Südkoreanern, die Lage zu stabilisieren.

Mit der Landung bei Incheon Mitte September 1950 gelang es den UN-Truppen, den Vormarsch der Nordkoreaner zu beenden. Am 30. September überschritten die Truppen Südkoreas den 38. Breitengrad, um die Koreanische Halbinsel unter ihrer Flagge wieder zu vereinigen. Im November erreichte man erste Abschnitte des Grenzflusses Yalu zu China. Die Chinesen wollten ein vereinigtes Korea unter US-amerikanischem Einfluss nicht dulden und griffen mit einer zunächst 300.000 Soldaten umfassenden „Freiwilligenarmee“ in Nordkorea ein. Die UN-Truppen wurden schließlich bis südlich des 38. Breitengrades zurückgedrängt, wo die Front erstarrte.

Der Waffenstillstand wurde am 27. Juli 1953 vereinbart, unterzeichnet von der UNO, Nordkorea und China. Rhee Syng-man, der Präsident Südkoreas, weigerte sich, den Vertrag zu unterzeichnen. Man verfügte die Einrichtung einer demilitarisierten Zone etwa entlang des 38. Breitengrades. Die demilitarisierte Zone ist auch heute noch die Grenze zwischen beiden koreanischen Staaten. Ein Friedensvertrag wurde bis heute nicht unterzeichnet, obwohl die Absicht dazu mehrfach bekundet wurde.
Die Folgen des Koreakriegs waren dramatisch. Die Schätzungen der Anzahl getöteter Koreaner schwanken zwischen einer und drei Millionen; weit mehr noch waren vertrieben worden. Die koreanische Infrastruktur lag zum größten Teil in Schutt und Asche. Mindestens genauso schlimm waren die psychologischen Folgen. Die Angst vor einer erneuten Invasion beeinträchtigt die Politik beider Staaten bis heute, wenn auch zusehends weniger.

Nach dem Koreakrieg ging es trotz westlicher Entwicklungshilfe wirtschaftlich mit Südkorea kaum aufwärts. Als Land ohne größere Bodenschätze war Südkorea auf Importe angewiesen, auch waren die wenigen Industrieanlagen und die gesamte Infrastruktur zerstört. Dass es zunächst nur schleppend voranging, wurde vorwiegend der Misswirtschaft des Präsidenten Rhee Syng-man angelastet. Er sicherte sich bei den folgenden Wahlen durch Verhaftungen von Oppositionellen und mehreren Verfassungsänderungen seine Wiederwahl. Die wirtschaftliche Entwicklung blieb danach enttäuschend, die Korruption war eklatant, und der Regierungsstil von Rhee wurde immer autokratischer. Im Jahre 1960 kam es monatelang und landesweit zu Studenten-Demonstrationen gegen ihn; sie fanden immer mehr Unterstützung in der Bevölkerung. Am 26. April 1960 trat Rhee schließlich zurück.

Als auch eine parlamentarisch basierte Regierung die Probleme des Landes nicht in den Griff bekam, putschte sich am 16. Mai 1961 das Militär unter der Führung von General Park Chung-hee an die Macht. Man ließ in der Folgezeit zwar Wahlen zu, diese blieben aber praktisch folgenlos. Wesentliche demokratische Rechte wie Meinungs- und Pressefreiheit blieben den Südkoreanern versagt. Unter Park Chung-hee entwickelte sich eine Militärdiktatur, Oppositionelle wurden gefoltert und ermordet.

Währenddessen machte Südkorea wesentliche wirtschaftliche Fortschritte. Eine enge Verbindung zwischen Politik und Wirtschaft ließ Großindustrien entstehen. Südkorea wandelte sich in dieser Zeit zu einem modernen, exportorientierten Industriestaat. Dadurch verbesserte sich auch der Lebensstandard der Südkoreaner. Das Bildungswesen wurde verbessert und breiteren Bevölkerungsschichten zugänglich gemacht, das sogenannte Saemaul-Programm hob die Lage der Landbevölkerung. Park gilt daher heute gemeinhin als Architekt des wirtschaftlichen Aufschwungs.

1968 und 1975 versuchten nordkoreanische Agenten, Park zu ermorden; dem zweiten Attentat fiel seine Frau zum Opfer. Sein Ende kam unerwartet am 26. Oktober 1979, als Park vom eigenen Geheimdienstchef Kim Chae-kyu erschossen wurde.

Der Premierminister Choi Kyu-ha wurde zunächst Interimspräsident und ging aus der Wahl durch ein Wahlgremium am 6. Dezember 1979 als Sieger hervor. Doch schon am 12. Dezember putschte das Militär unter Führung von General Chun Doo-hwan erneut gegen die Regierung. Große Unsicherheit bestimmte das Jahr 1980. Menschen aus allen Gesellschaftsschichten forderten echte Demokratie, Demonstrationen erfassten das ganze Land. Das Militär fürchtete aufgrund der unruhigen Lage eine Invasion des Nordens und griff deshalb besonders hart durch. In einer der Protesthochburgen, in Gwangju, wurde im Mai 1980 ein Exempel statuiert und der Aufstand brutal niedergeschlagen. Laut einer Untersuchung Ende der 1990er Jahre über den heute als Gwangju-Aufstand oder in Südkorea als "18.-Mai-Gwangju-Demokratiebewegung" bekannten Vorfall starben 207 Zivilisten, mehrere Tausend wurden verletzt. Andere Quellen belegen bis zu 2.300 Todesopfer (s. Hauptartikel).

Allmählich gelang es Chun, die Lage zu beruhigen. Die wirtschaftliche Entwicklung nahm erneut Fahrt auf, und die Lebensqualität der Südkoreaner stieg deutlich an. Trotzdem wurden die Forderungen nach Demokratie immer lauter. Es kam oft zu Demonstrationen und Streiks, die teilweise unterdrückt wurden. Chun ermöglichte den ersten friedlichen Machtwechsel seit der Gründung Südkoreas, indem er am Ende seiner Amtszeit 1988 zurücktrat.

Bei einem Bombenanschlag im Norden von Rangun in Myanmar wurden am 9. Oktober 1983 19 Personen getötet, darunter vier Kabinettsmitglieder der Regierung Chun: Kim Jae-ik, Suh Sook-joon, Hahn Pyong-choon und Außenminister Lee Bum-suk. Chun Doo-hwan entging dem Attentat, da er verspätet am Ort des Anschlags eintraf. Nach einer Untersuchung beschuldigte man Nordkorea offiziell des Anschlags.

Chuns potenzieller Nachfolger, der Ex-General Roh Tae-woo, bot im Sommer 1987 überraschend an, die Verfassung zugunsten echter demokratischer Reformen zu ändern. So wurde der Präsident im November 1987 zum ersten Mal seit 1961 wieder direkt durch die Bevölkerung gewählt und seine Amtszeit auf fünf Jahre verkürzt. Die beiden Oppositionsführer Kim Young-sam und Kim Dae-jung konnten sich nicht auf einen gemeinsamen Kandidaten einigen und kandidierten gegeneinander. Weil die Opposition damit gespalten war, genügten Roh 37 % der Stimmen, um die Wahl zu gewinnen.

Während der Amtszeit Rohs machte die Demokratie in Südkorea deutliche Fortschritte, es wurden viele Reformen beschlossen. 1988 war Südkorea Gastgeber der Olympischen Sommerspiele. Südkorea nahm mit ehemaligen Ostblockstaaten diplomatische Beziehungen auf. Zusammen mit Nordkorea trat das Land 1991 den Vereinten Nationen bei. Nach dem Abzug von etwa einhundert amerikanischen taktischen Atomwaffen im September 1991 schlossen am 13. Dezember 1991, 38 Jahre nach dem vorläufigen Ende des Koreakriegs durch den Waffenstillstand, Nord- und Südkorea einen Nichtangriffspakt.

Weil seine Partei mit der Partei Roh Tae-woos ein konservatives Bündnis gründete, konnte sich Kim Young-sam bei der Wahl im Jahr 1992 gegen Kim Dae-jung durchsetzen. Ein Schwerpunkt seiner Politik war der Kampf gegen die Korruption und die Aufklärung staatlichen Fehlverhaltens. Dabei wurden die ehemaligen Präsidenten Chun Doo-hwan und Roh Tae-woo wegen des Staatsstreichs und des Gwangju-Massakers im Jahr 1980 verurteilt, Chun sogar zum Tode. Beide wurden später begnadigt.

Im November 1997 erfasste die Asienkrise Südkorea. Nachdem das Land wirtschaftlich lange Zeit mit zweistelligen Zuwachsraten geglänzt hatte, schrumpfte das Bruttoinlandsprodukt im Jahre 1998 um 6,7 % und die Landeswährung, der Won, verlor stark an Wert. Mit Hilfe eines Kredites des IWF konnte die Krise überwunden werden, schon im Jahre 1999 wuchs das BIP wieder um mehr als 10 %.

Im Jahr 2002 richtete Südkorea zusammen mit Japan die 17. Fußball-Weltmeisterschaft aus. Es war das erste Mal, dass zwei Länder gemeinsam Gastgeber dieser Sportveranstaltung wurden, angesichts der gespannten Beziehungen zu Japan umso bedeutsamer. Der Erfolg der südkoreanischen Fußballnationalmannschaft war eine der großen Überraschungen dieses Turniers, sie belegte den vierten Platz.

Bei der Wahl am 18. Dezember 1997 konnte sich Kim Dae-jung durchsetzen. Der Hauptpunkt seiner Politik war die Aussöhnung mit Nordkorea, die sogenannte Sonnenscheinpolitik. Man stellte zwei während des Koreakriegs unterbrochene Eisenbahnstrecken wieder her; die erste Testfahrt fand erst am 17. Mai 2007 statt. Darüber hinaus wurde ein gemeinsames Industriegebiet in Kaesŏng gegründet. Der Höhepunkt dieser Politik war ein Treffen Kim Dae-jungs mit dem nordkoreanischen Führer Kim Jong-il in Pjöngjang im Juni 2000. Für diese Politik wurde Kim Dae-jung noch im selben Jahr mit dem Friedensnobelpreis ausgezeichnet.

Aus der Präsidentschaftswahl am 19. Dezember 2002 ging der, derselben Partei wie Kim Dae-jung angehörende, Roh Moo-hyun als Sieger hervor. Er versuchte, die Politik Kim Dae-jungs gegenüber Nordkorea fortzuführen. 

Auch Roh Moo-hyun reiste kurz vor dem Ende seiner Amtszeit vom 2. bis zum 4. Oktober 2007 zu einem Staatsbesuch nach Nordkorea. Dabei unterzeichnete er zusammen mit dem nordkoreanischen Staatschef Kim Jong-il eine Absichtserklärung, Verhandlungen über einen Friedensvertrag aufnehmen zu wollen. Dieser soll das Waffenstillstandsabkommen zur Beendigung des Koreakriegs von 1953 ersetzen. Darüber hinaus sollte es öfter zu Gipfeltreffen kommen.

Unter dem bis 2012 amtierenden südkoreanischen Präsidenten Lee Myung-bak kühlte sich das Verhältnis zwischen beiden Staaten jedoch merklich ab. Lee hatte bereits im Wahlkampf angekündigt, eine härtere außenpolitische Linie gegenüber Pjöngjang zu verfolgen. Nordkorea kündigte schließlich an, seine Grenzen zum Süden ab 1. Dezember 2008 zu schließen. Von dieser Maßnahme sind vor allem Reisen von Südkoreanern in die grenznahen Tourismusgebiete Nordkoreas betroffen. Erst im August 2009 kam es zum ersten Mal nach knapp zwei Jahren wieder zu Gesprächen zwischen hochrangigen Vertretern der beiden Regierungen. Der nordkoreanische Geheimdienstchef Kim Yang Kon erörterte mit dem südkoreanischen Wiedervereinigungsminister Hyun In Taek bilaterale Themen in Seoul.

Im Frühjahr 2013 erreichten die Beziehungen beider Länder durch die Nordkorea-Krise 2013 einen erneuten Tiefpunkt.

Nach der Amtsenthebung von Park Geun-hye folgte ihr im Mai 2017 Moon Jae-in ins Präsidentenamt. Dieser zeigte von Anfang an Dialogbereitschaft mit dem nordkoreanischen Machthaber Kim Jong-un, der im Dezember 2017 nach mehreren Raketentests und einem Atombombentest verkündet hatte, dass Nordkorea die Entwicklung zur Atommacht abgeschlossen habe. Nachdem sich der Konflikt gefährlich zugespitzt hatte, ging Kim Jong-un am 1. Januar 2018 überraschend auf das Angebot Südkoreas ein, sein Land im Februar 2018 an den Olympischen Winterspielen in Pyeongchang teilnehmen zu lassen. Vertreter beider Staaten einigten sich bei Gesprächen in der demilitarisierten Zone in Panmunjom anderthalb Wochen später auf eine Drei-Punkte-Abschlusserklärung. Danach darf Nordkorea eine Delegation zu den Olympischen Winterspielen entsenden, für eine Entspannung sollen zwischen beiden Staaten Militärgespräche wiederaufgenommen werden und hochrangige Treffen sollen fortgesetzt werden, um den Austausch in verschiedenen Bereichen wiederzubeleben. Medien spekulierten darüber, dass Kim Jong-un auf eine Rücknahme von UN-Sanktionen hoffe oder die Beziehungen zwischen Südkorea und den USA unter Präsident Donald Trump schwächen wolle.

Im Demokratieindex 2016 belegt Südkorea Platz 25 von 167 Ländern, womit das Land als eine „unvollständige Demokratie“ gilt.
Südkorea ist auf der höchsten Unterebene politisch gegliedert
in eine "Besondere Stadt":
in eine "Besondere autonome Stadt":
in sechs selbstständige "Großstädte":
in acht "Provinzen":
sowie in eine "Besondere autonome Provinz":

Am 17. Juli 1948 wurde die erste Verfassung Südkoreas beschlossen. Im Zuge der politischen Umwälzungen wurde sie insgesamt neun Mal überarbeitet, zuletzt am 29. Oktober 1987. Diese Überarbeitung war ein wichtiger Schritt zur Demokratisierung des Landes. Unter anderem wurden dabei die Macht des Präsidenten beschränkt und die Befugnisse der Legislative erweitert. Auch die Menschenrechte waren danach besser geschützt als zuvor.

Die derzeit gültige Verfassung umfasst eine Präambel, 130 Artikel und sechs Zusatzbestimmungen. Sie ist in zehn Kapitel unterteilt: „Allgemeine Bestimmungen“, „Rechte und Pflichten der Bürger“, „Nationalversammlung“, „Exekutive“, „Rechtswesen“, „Verfassungsgericht“, „Wahlen“, „Kommunalverwaltung“, „Wirtschaft“ sowie „Verfassungsänderungen“. Sie sichert die Souveränität des Volkes, verfügt die Gewaltentrennung, bekundet Ziele wie die friedliche und demokratische Wiedervereinigung mit Nordkorea, fordert das Streben nach Frieden und zur Zusammenarbeit auf internationaler Ebene ebenso wie die Verpflichtung des Staates, für das Gemeinwohl zu sorgen. Eine Verfassungsänderung erfordert eine Zweidrittelmehrheit in der Nationalversammlung und muss außerdem durch eine einfache Mehrheit einer Volksabstimmung bestätigt werden.

Das Staatsoberhaupt der Republik Korea ist der direkt vom Volk gewählte Präsident. Der Präsident wird für jeweils fünf Jahre gewählt und kann nicht wiedergewählt werden. Er ist der höchste Vertreter der Republik und vertritt diese nach innen und außen. So empfängt er ausländische Diplomaten, verleiht Orden und kann Begnadigungen aussprechen. Er steht auch an der Spitze der Verwaltung und setzt in dieser Funktion von der Nationalversammlung beschlossene Gesetze in Kraft. Er ist Befehlshaber der Armee und kann den Krieg erklären. 

Der Premierminister wird vom Präsidenten ernannt. Er leitet die Regierung. Das Kabinett besteht aus mindestens 15 und höchstens 30 Mitgliedern, es wird ebenfalls vom Präsidenten zusammengestellt. Sowohl Premierminister als auch Kabinettsmitglieder müssen vom Parlament bestätigt werden. Das südkoreanische Parlament hat nur eine Kammer und wird "Gukhoe" (Nationalversammlung) genannt. Die Parlamentarier werden für vier Jahre gewählt. Das Parlament besteht aus 299 Abgeordneten, von denen 243 direkt gewählt werden. Die übrigen 56 Sitze werden unter denjenigen Parteien verteilt, die mindestens 3 % der Stimmen erhalten haben. Hierdurch soll sichergestellt werden, dass die Mitglieder des Parlaments eher nationale als regionale Interessen vertreten. letzte Parlamentswahl fand am 13. April 2016 statt. Die regierende Saenuri-Partei erreichte nur noch 122 von 300 Sitzen, während die oppositionelle Minju-Partei 123 Sitze erhielt.

Das dritte wichtige Organ im System Südkoreas ist das Verfassungsgericht. Es überwacht die Arbeit der Regierung und entscheidet im Falle von Misstrauensanträgen und Ähnlichem. Das Gericht besteht aus neun Obersten Richtern. Der Präsident persönlich ernennt drei Richter für den obersten Gerichtshof. Das Parlament bestimmt weitere drei Richter, muss diese aber vom Präsidenten bestätigen lassen. Die letzten drei Richter werden vom Vorsitzenden des Obersten Gerichtshofs ernannt.

Die Politik und auch das Leben in Südkorea wurden in der Vergangenheit in großem Maße von der Angst vor einer neuen Invasion durch Nordkorea bestimmt. In den letzten Jahren nahm die Angst deutlich ab. Trotzdem ist es Südkoreanern durch das "Nationale Sicherheitsgesetz" (, , "gukga boanbeop") verboten, Kontakt nach Nordkorea aufzunehmen. Auch darf Nordkorea in der Öffentlichkeit nicht gelobt oder für dieses geworben werden. Das Gesetz wurde am 1. Dezember 1948 beschlossen, 1963 und 1980 geändert und ist bis heute in Kraft. Es wurde vor der Demokratisierung als „Gummiparagraph“ zur Unterdrückung politischer Opposition missbraucht, denn es ist inhaltlich sehr unbestimmt, und sieht auch schon für regierungsfeindliche Äußerungen, Besitz und Weitergabe regierungsfeindlichen Materials, Mitgliedschaft in regierungsfeindlichen Organisationen und Nichtanzeige derartiger Straftatbestände Strafen bis hin zur Todesstrafe vor. Das Verfassungsgericht hat das Gesetz im August 2004 überprüft und für verfassungskonform erklärt, die Nationale Menschenrechtskommission im September desselben Jahres hingegen deren Abschaffung empfohlen. Präsident Roh sprach sich gleichfalls für seine Abschaffung aus. Der deutsche Staatsbürger und Exilkoreaner Song Du-yul wurde im März 2004 auf Grund des Gesetzes zu sieben Jahren Haft verurteilt, die in der nächsten Instanz in eine Bewährungsstrafe umgewandelt wurde. Nach Informationen von Amnesty International waren im Dezember 2004 mindestens neun Personen auf Grund dieses Gesetzes inhaftiert, sechs von ihnen Mitglieder der verbotenen pro-nordkoreanischen Studentenorganisation Hanchongnyeon.

Wie in den meisten ostasiatischen Ländern gibt es auch in Südkorea die Todesstrafe. Im Jahr 2006 wurde eine Person zum Tode verurteilt, nach Angaben von Amnesty International saßen im Juni 2006 63 zum Tode verurteilte Gefangene in südkoreanischen Gefängnissen ein. Seit 1998 hält man ein inoffizielles Hinrichtungsmoratorium ein, weswegen keine Todesstrafen mehr vollstreckt werden. Auch gibt es zunehmende Bestrebungen, die Todesstrafe abzuschaffen. Zwar wird die Abschaffung von der Bevölkerung mehrheitlich abgelehnt, jedoch haben im Dezember 2004 175 der 299 Mitglieder des Parlaments einen Gesetzesvorschlag gegen die Todesstrafe unterschrieben. Anfang 2006 gab das Justizministerium bekannt, eine Studie über die Folgen der Abschaffung vornehmen zu wollen. Der oberste Gerichtshof entschied, dass die Todesstrafe mit der Verfassung vereinbar sei, ihre Abschaffung fällt aber in die Zuständigkeit der Legislative.

Jedes Jahr leisten mehrere Hundert dem Einberufungsbefehl nicht Folge und werden daraufhin zu mindestens 18 Monaten Haft verurteilt. Von 1950 bis 2013 waren deshalb allein 17.840 Zeugen Jehovas mindestens 18 Monate im Gefängnis. Das Verfassungsgericht hatte erst 2011 die Vorschläge für einen alternativen Ersatzdienst abgelehnt und die allgemeine Wehrpflicht für verfassungskonform erklärt. Wenngleich offenbar eine Tendenz kürzerer Haftstrafen zu beobachten war, erhielten Kriegsdienstverweigerer aus Gewissensgründen weiterhin einen Eintrag ins Vorstrafenregister, was ihre Chancen auf dem Arbeitsmarkt minderte. Sechs Bezirksrichter, die bei ihren Entscheidungen Bedenken hatten, legten mehrere Fälle, in denen es um Wehrdienstverweigerer aus Gewissensgründen geht, erneut dem Verfassungsgericht vor.

Leitlinie der südkoreanischen Außenpolitik ist die strategische Partnerschaft zu den Vereinigten Staaten, wegen der gemeinsamen Wahrnehmung Nordkoreas als Bedrohung. Die Vereinigten Staaten sehen Südkorea als einen ihrer wichtigsten Verbündeten überhaupt und vergeben dorthin große Beträge an sogenannter „militärischer Entwicklungshilfe“. Die USA haben in Südkorea auch große Truppenkontingente stationiert. Seit der Aufnahme diplomatischer Beziehungen zur Volksrepublik China im Jahre 1992 entwickeln sich insbesondere die Wirtschaftsbeziehungen dynamisch. China ist mit Abstand Südkoreas größter Handelspartner, der bedeutendste Absatzmarkt und ein wichtiger ausländischer Produktionsstandort.

Daneben prägt die Außenpolitik Südkoreas ein sehr ambivalentes Verhältnis zu Japan. Die als belastend empfundenen Erinnerungen an die Vergangenheit (japanische Kolonialzeit 1910–1945, Koreakrieg 1950–1953) erschweren die Beziehungen zu Japan.

Die Beziehungen zu Nordkorea haben sich, nach einer Zeit der Entspannung um das Jahr 2000, in den letzten Jahren wieder deutlich verschlechtert.

Nach dem Ende des Koreakrieges war die Angst vor einer erneuten Invasion des Nordens sehr groß. Noch in den 1980er Jahren wurden regelmäßig Probealarme exerziert, die das gesamte öffentliche Leben miteinbezogen. Vor dem Hintergrund der terroristischen Aktivitäten des Nordens war dies nachvollziehbar. Im Oktober 1983 verübten nordkoreanische Agenten ein Attentat auf eine südkoreanische Regierungsdelegation in der damaligen burmesischen Hauptstadt Rangun. Präsident Chun Doo-hwan überlebte, der Außenminister und 16 andere Südkoreaner wurden getötet. 1988 platzierte der nordkoreanische Geheimdienst eine Bombe in einem südkoreanischen Passagierflugzeug, das daraufhin über dem Indischen Ozean explodierte. 115 Menschen wurden dabei getötet. Dass ein erneuter Krieg nicht unwahrscheinlich war, zeigen auch Tunnel von mehreren Kilometern Länge, die von Nordkorea aus unter der Demilitarisierten Zone hindurch getrieben wurden. Diese auf südkoreanischer Seite noch verdeckten Tunnel sollten es im Kriegsfall ermöglichen, rasch und unbemerkt Infanterie in das südkoreanische Hinterland einzuschleusen. Bis heute wurden insgesamt vier Tunnel entdeckt, die Existenz noch weiterer wird vermutet. Mit dem Ende der Militärdiktatur im Jahre 1988 und mit dem wirtschaftlichen Abstieg Nordkoreas ließ die Angst vor einer erneuten Invasion aber mehr und mehr nach. Da nach dem Koreakrieg nur ein Waffenstillstandsabkommen geschlossen wurde, befinden sich beide Staaten aber offiziell auch heute noch im Kriegszustand miteinander.

Kim Dae-jung gelang es, einige gemeinsame Projekte mit dem Norden zu begründen. So gibt es heute das Industriegebiet Kaesŏng auf nordkoreanischer Seite, in dem südkoreanische Firmen mit nordkoreanischen Arbeitskräften produzieren. Auch die Gyeongui-Linie, eine Eisenbahnstrecke von Seoul über Pjöngjang nach Sinŭiju an der chinesischen Grenze, wurde wiederhergestellt, sie verkehrt allerdings vorerst nur von Seoul bis zur innerkoreanischen Grenze. Im Jahr 2000 kam es zu einem historischen Treffen zwischen dem damaligen südkoreanischen Präsidenten Kim Dae-jung und dem nordkoreanischen Machthaber Kim Jong-il in Pjöngjang. Doch musste Kim Dae-jung im Jahr 2002 eingestehen, im Vorfeld des Treffens rund 100 Millionen Dollar an die nordkoreanische Regierung gezahlt zu haben.

Die Wiedervereinigung mit dem Norden bleibt politisch ein aktuelles Thema; die Erfahrungen der deutschen Wiedervereinigung haben Befürchtungen geweckt, dass Südkorea die Kosten nicht würde tragen können, selbst wenn das nominale Bruttoinlandsprodukt Südkoreas mittlerweile das dreizehntgrößte der Welt ist. In Nordkorea leben 22.912.177 Einwohner auf einer Fläche von 122.762 km², im Süden sind es 48.640.671 Einwohner auf einer Fläche von 99.392 km². Wegen des vergleichsweise viel stärkeren Gewichts des anderen Staates, nach Fläche wie nach Bevölkerungszahl, wären voraussichtlich noch höhere Transferzahlungen zu leisten als nach der Wiedervereinigung Deutschlands.

Zu Beginn seiner Amtszeit äußerte Präsident Roh Moo-hyun, er könne eher mit einem atomar bewaffneten Nordkorea leben als mit einem kollabierenden Norden. Diese Aussage musste er zwar als politische Inkorrektheit zurücknehmen, aber er dürfte damit die Einstellung vieler Südkoreaner wiedergegeben haben. Zudem gibt es Zweifel, ob die beiden Staaten nicht schon zu lange voneinander getrennt sind. Während im geteilten Deutschland immerhin noch zum Teil gegenseitige Besuche, Briefkontakte und Telefongespräche stattfanden, sind die beiden koreanischen Staaten praktisch vollständig voneinander isoliert. Abgesehen von einigen wenigen Familientreffen in den letzten Jahren gab es keinerlei Kontakte; die meisten Familien wissen nicht einmal, ob ihre im anderen Staat wohnenden Verwandten überhaupt noch leben.

Die Beziehungen zwischen den beiden Ländern kühlten allerdings nach der Wahl des ehemaligen Präsidenten Lee Myung-baks wieder ab. Nach dem Untergang des Kriegsschiffes Cheonan im März 2010, für dessen Versenkung Nordkorea verantwortlich gemacht wurde, stellte Südkorea den Handel mit dem nördlichen Nachbarn ein und erklärte, dass es den UN-Sicherheitsrat anrufen werde. Nordkorea brach daraufhin alle Beziehungen ab, versetzte seine Truppen in Kampfbereitschaft und kündigte ein Sicherheitsabkommen, das bewaffnete Auseinandersetzungen verhindern sollte. Zudem sollten alle Südkoreaner aus der Industrieregion Kaesŏng ausgewiesen werden.

Die Spannung auf der Koreanischen Halbinsel erreichte durch einen Artilleriebeschuss der Insel Yeonpyeong nahe der inoffiziellen Seegrenze durch nordkoreanische Einheiten am 23. November 2010 einen vorläufigen Höhepunkt. Für erneute Spannung sorgte ein nordkoreanischer Atomwaffentest im Februar 2013, der die Verhängung von UN-Sanktionen gegen das Land zur Folge hatte. Als Reaktion auf die Sanktionen kündigte Nordkorea am 8. März 2013 den Nichtangriffspakt auf, was die Wahrscheinlichkeit eines Krieges wieder in den Vordergrund rücken lässt.

Auch nach über 70 Jahren nach der Unabhängigkeit von Japan sind die Beziehungen noch immer belastet. Antijapanische Ressentiments sind weit verbreitet, manche Südkoreaner lehnen zumindest alles offensichtlich Japanische ab. Hauptgrund sind die schmerzhaften Erinnerungen an die Kolonialzeit, die zudem in Japan als zu wenig aufgearbeitet angesehen werden. Offizielle Geschichtsbücher in Japan stellen die Eingliederung Koreas in das Japanische Kaiserreich noch immer sehr einseitig dar, so werden vor allem die Verbesserungen der Infrastruktur und Industrie betont, während die Unterdrückung der Koreaner und ihrer Kultur verschwiegen wird. Viele Japaner sind sich daher der Geschehnisse der Vergangenheit kaum bewusst und verstehen die Gründe für die Anfeindungen aus Südkorea nicht.

Proteste in Südkorea wurden in der Vergangenheit vor allem dann laut, wenn Japan seine Ansprüche auf die auch von Südkorea beanspruchten Liancourt-Felsen bekräftigte oder wenn hohe Regierungsmitglieder Japans auch wiederholt den Yasukuni-Schrein besuchten, wo auch verurteilte Kriegsverbrecher und japanische Soldaten koreanischer Abstammung geehrt werden.

Viele ehemalige sogenannte Trostfrauen (ein euphemistischer Begriff für Mädchen und Frauen, die in der Kaiserlich Japanischen Armee bis 1945 in Kriegsbordellen als Zwangsprostituierte dienen mussten) meldeten sich ab Ende der 1980er Jahre in der Öffentlichkeit zu Wort und begannen 1992 jeden Mittwoch vor der japanischen Botschaft in Seoul mit den Worten zu protestieren: „Es ist die japanische Regierung, die sich schämen muss, nicht wir!“ Sie forderten eine Entschuldigung Japans und auch Entschädigungen. Neun große Sammelklagen gegen die jap. Regierung scheiterten. Nach Äußerungen des seinerzeit neugewählten Premierministers Shinzō Abe vom 1. März 2007: „Es gibt keinen Beweis dafür, dass Zwang auf Frauen ausgeübt wurde, wie es zunächst geheißen hatte.“ gab es nach Kontroversen eine Entschuldigung des Japanischen Parlaments vom 27. März 2007 bei den bis zu 200.000 Opfern, von denen nur ein Drittel überlebt haben soll. Da Japan die Demokratische Volksrepublik Korea (Nordkorea) nicht anerkennt, ist nicht bekannt, ob es sich bei dieser Zahl um – alle – "Trostfrauen" der ehemaligen Kolonie Chōsen handelt oder nur aus Südkorea. 
Am 28. Dezember 2015 schlossen Japan und Südkorea ein Abkommen, mit dem beide Staaten den Streit um die Trostfrauen beilegen wollen. Das Abkommen sieht eine erneute öffentliche Entschuldigung Japans vor und die Zahlung von einer Milliarde Yen (7,56 Millionen Euro) zu einem Fonds unter südkoreanischer Verwaltung, der den Opfern der Zwangsprostitution zukommen soll. Die Thematik wurde und wird in Japan diskutiert. Zur Zeit des Abkommens lebten in Südkorea noch 46 der damaligen Trostfrauen.
Am 10. August 2010 entschuldigte sich der japanische Ministerpräsident Naoto Kan bei Südkorea für die Kolonialherrschaft seines Landes von 1910 bis 1945. Damit sei auch die Hoffnung verbunden auf eine Verbesserung der südkoreanisch-japanischen Beziehungen.

Die ersten bilateralen Beziehungen auf einer formalen Ebene wurden mit der Unterzeichnung des Deutsch-Koreanischen Handels-, Schiffahrts- und Freundschaftsvertrag am 26. November 1883 gelegt. Mit der Zweiten Japanisch-Koreanischen Übereinkunft 1905 wurde Japan die Auslandsvertretung und -repräsentation für Korea übertragen; die diplomatischen Geschäfte der zwischenzeitlich in Korea eingerichteten deutschen Ministerresidentur gingen an die Deutsche Gesandtschaft in Tokyo über, wodurch die diplomatischen Beziehungen zwischen Deutschland und Korea endeten. Nach Ende des Zweiten Weltkrieges waren Deutschland durch das Besatzungsstatut der Siegermächte rechtliche Schranken gesetzt. Durch die Pariser Verträge und ihre Ratifizierung am 5. Mai 1955 erhielt Deutschland seine staatliche Souveränität wieder. Damit war auch der Weg für die Aufnahme der diplomatischen Beziehungen mit dem 1948 gegründeten Südkorea frei und der Austausch zwischen den beiden Staaten wurde auch auf staatlicher Ebene aufgenommen.

Im Jahr 1961 belief sich die deutsche Entwicklungshilfe für Südkorea auf insgesamt 75 Millionen DM. Mit rund 35 Millionen DM sollte ein Großteil der Entwicklungshilfe für den Ausbau des Fernsprechwesens finanziert werden. Etwa 20,72 Millionen DM sollte in den Ausbau der staatlichen Kohlengruben investiert werden. Neben der monetären Unterstützung sah die Bundesrepublik einen weiteren Beitrag zur Entwicklungshilfe in Südkorea vor. Eine Vereinbarung über ein „Programm zur vorübergehenden Beschäftigung [süd]koreanischer Bergarbeiter“ trat durch einen Notenwechsel zwischen der Bundesrepublik und der Republik Korea am 16. Dezember 1963 in Kraft. So wurde die Bundesregierung allmählich von der Idee überzeugt, südkoreanische Bergarbeiter unter dem Deckmantel der „technischen Entwicklungshilfe“ nach Deutschland anzuwerben. Die Anwerbepolitik richtete sich eigentlich gezielt auf südeuropäische und damit kulturell nahe „Gastarbeiter“ aus dem Mittelmeerraum. Am 21. Dezember bestiegen 247 südkoreanische Männer in westlichen Anzügen ein Flugzeug am Flughafen Gimpo, das sie nach Deutschland brachte. Es war die erste südkoreanische Delegation, die in deutschen Bergwerken arbeitete. Die Zahl der von 1962 bis 1977 ausgewanderten Gastarbeiter südkoreanischer Nationalität betrug etwa 8.000, weitere 10.000 Frauen wanderten in derselben Zeit nach Deutschland aus, um in Krankenhäusern zu arbeiten.

Die Streitkräfte der Republik Korea verfügen über knapp 685.000 Männer und Frauen in vier Teilstreitkräften und zwei paramilitärischen Organisationen, deren strategisches Kernstück das Heer ist. Im Jahre 2005 betrug das Verteidigungsbudget umgerechnet ungefähr 21 Mrd. US-Dollar. Damit leistet sich das Land das fünft- bis siebtgrößte Militär der Welt. Auch die anderen Staaten Ostasiens haben „starke“ Streitkräfte, gemessen an der Zahl der Soldaten (Volksrepublik China, Nordkorea), ihrem Verhältnis zur Bevölkerungszahl (Nordkorea, Republik China) oder an der Größe des Verteidigungshaushaltes (Japan, Nordkorea, Volksrepublik China). In Südkorea sieht man sich am meisten durch Nordkorea bedroht.

Das Oberkommando (OPCON, "operational control") über die südkoreanischen Streitkräfte wurde beim Ausbruch des Koreakrieges 1950 an die USA übergeben. 1978 wurde die Befehlsgewalt an die "Combined Forces Command" (CFC) übertragen. Seit 1994 liegt die Befehlsgewalt in friedlichen Zeiten beim "Republic of Korea Joint Chiefs of Staff (ROK JCS)". Im Kriegsfall ("wartime OPCON") liegt diese bei den USA. Nach einem ursprünglichen Beschluss vom Februar 2007 sollte es aber auch im Kriegsfall ab dem 17. April 2012 an Südkorea fallen. Der Zeitpunkt der Übergabe war jedoch fortlaufender Diskussionsgegenstand. Während des G20-Gipfels in Toronto im Juni 2010 kamen der damalige südkoreanische Staatspräsident Lee Myung-bak sowie der damalige US-Präsident Barack Obama überein, den Zeitpunkt der Übergabe auf den 1. Dezember 2015 zu verschieben. Als Hauptgrund wurde die in jüngster Zeit ansteigende Bedrohungslage durch Nordkorea angeführt, hauptsächlich untermauert durch den Atombombentest im Mai 2009 sowie den mutmaßlichen Angriff auf das Kriegsschiff Cheonan im März 2010. Bei einem Treffen im Oktober 2014 im Pentagon wurde die Übergabe erneut vertagt. Eine Übergabe wird um 2020 erwartet.

In Südkorea herrscht eine Wehrpflicht für Männer mit einer Dienstzeit von 24 bis 28 Monaten.

Die südkoreanischen Streitkräfte kooperieren eng mit den amerikanischen Streitkräften. Im Februar 2010 waren rund 28.500 Mann der US-Truppen in Korea stationiert, mit denen jedes Jahr eine gemeinsame Militärübung abgehalten wird.

Seit einigen Jahren engagieren sich die Streitkräfte auch in Auslandsmissionen. Der erste Einsatz im Ausland begann 2004, als etwa 3600 Soldaten für etwa vier Jahre humanitäre und Wiederaufbauhilfe im Irak unterstützten. Zwischen 2002 und 2007 waren rund 200 Soldaten (Sanitätsdienst und Pionierwesen) im Rahmen der Operation Enduring Freedom in Afghanistan stationiert. Im Juli 2009 wurden, auf Bitten der Vereinten Nationen, 350 Soldaten zur Friedenssicherung in den Süden des Libanon entsandt. Im Februar 2010 wurde eine 240 Mann starke Einheit zur Friedenssicherung in das vom Erdbeben betroffene Haiti verlegt. Neue Pläne sahen zudem vor, im Juli 2010 etwa 350 Soldaten erneut nach Afghanistan zu schicken, um den Wiederaufbau zu unterstützen.

Südkorea gilt als einer der vier ostasiatischen Tigerstaaten: Seit den 1960er Jahren hat sich das Land in rasantem Tempo zu einer der bedeutendsten Volkswirtschaften der Welt entwickelt, das in einigen Technologiebranchen die weltweite Führerschaft übernommen hat. Dies wurde in Zusammenarbeit zwischen Regierung und Wirtschaft durch ein Maßnahmenpaket erreicht, das gerichtete Kredite, Importrestriktionen, Exportförderung, Sponsoring von bestimmten Wirtschaftssektoren und Industrien sowie einen enormen Arbeitskräfteaufwand beinhaltete.

Die Asienkrise des Jahres 1997 hat die Schwachstellen dieses Wirtschaftswundermodells offenbart: unter anderem hohe Schulden/Eigenkapital-Verhältnisse, eine massive Überschuldung und Vernachlässigungen im Finanzsektor. Zur Überwindung der Asienkrise hat Südkorea Hilfe des IWF bekommen, allerdings unter der Auflage, sein Finanzsystem zu reformieren und zu stärken. Inwiefern die geforderten Reformen vollständig umgesetzt wurden, ist Gegenstand von Diskussionen. Im Jahre 2001 hat Südkorea seine Schulden beim IWF vollständig zurückgezahlt.

Heute stellt Südkorea die elftgrößte Volkswirtschaft in der Welt dar. In den 1990er Jahren war es eine der zehn größten, bis es von den einwohnerreichen BRICS-Staaten überholt wurde. Das Pro-Kopf-Bruttoinlandsprodukt Südkoreas entspricht mittlerweile dem eines durchschnittlichen EU-Landes. Die Wachstumsraten sind noch immer wesentlich höher als in Europa oder den USA. Nach Angaben der WAZ lag das Bruttoeinkommen 2006 bei rund 21.000 US$, 2016 lag es bei rund 27.539 US$. Zum Vergleich: Anfang der 1960er betrug es 100 US$. Im Korruptionswahrnehmungsindex 2016 von Transparency International wurde Südkorea auf Platz 52 von 176 eingeordnet und erreichte auf der Skala von 0 (sehr viel wahrgenommene Korruption) bis 100 (kaum wahrgenommene Korruption) einen Wert von 53. Seit Anfang 2010 gehört Südkorea, als erstes ehemaliges Nehmerland, zu den Geberländern des OECD-Entwicklungsausschusses.

Im Global Competitiveness Index, der die Wettbewerbsfähigkeit eines Landes misst, belegt Südkorea Platz 26 von 137 Ländern (Stand 2017). Im Index der Wirtschaftlichen Freiheit belegt das Land 2017 Platz 23 von 180 Ländern.

Die Bedeutung der Landwirtschaft für die Wirtschaft Südkoreas ist in den vergangenen Jahrzehnten ständig zurückgegangen. Im Jahr 2003 betrug der Anteil der Landwirtschaft am Bruttoinlandsprodukt des Landes etwa 3,2 %. Trotzdem beschäftigt die Landwirtschaft etwa 10 % der Arbeitskräfte. Das wichtigste landwirtschaftliche Produkt ist der Reis, der in etwa 80 % aller Betriebe angebaut wird. Die Selbstversorgung mit Reis ist eine der Prioritäten in der Wirtschaftspolitik Südkoreas – obwohl der Reisanbau in Südkorea relativ teuer ist und etwa 70 % aller Reisfelder künstlich bewässert werden müssen. Weitere landwirtschaftliche Produkte sind Roggen, Weizen, Sojabohnen, Kartoffeln, Gemüse und Obst, wobei der Anbau dieser Produkte ständig sinkt und durch Importe ersetzt wird. Aufgrund von fallenden Preisen für landwirtschaftliche Produkte, die vor allem durch Importe verursacht werden, kommt es immer wieder zu politischen und gesellschaftlichen Auseinandersetzungen.
Die Viehzucht hat mit dem steigenden Wohlstand der Bevölkerung an Bedeutung gewonnen und ist nun der zweitwichtigste landwirtschaftliche Sektor.

Im Moment befindet sich die koreanische Landwirtschaft in einem Strukturwandel, durch den von einzelnen Ehepaaren geführte landwirtschaftliche Betriebe langsam verdrängt werden und durch großflächigere, hochmechanisierte Betriebe ersetzt werden. Auch in der Viehzucht geht der Trend in Richtung Großbetriebe.

Die Forstwirtschaft hat in Südkorea eine sehr geringe Bedeutung. In der ersten Hälfte des 20. Jahrhunderts wurden die dichten Wälder der Koreanischen Halbinsel durch unkontrollierte Abholzung und die kriegerischen Auseinandersetzungen weitgehend zerstört. Nach dem Koreakrieg wurde mit Erfolg begonnen, die Wälder wieder aufzuforsten. Die Wälder Südkoreas haben heute ein Durchschnittsalter von weniger als 30 Jahren. Der Holzbedarf des Landes wird deshalb fast ausschließlich durch Importe gedeckt.
Die Fischerei und Fischverarbeitung erwirtschaftete im Jahr 2000 einen Umsatz von etwa 3,6 Milliarden US-Dollar. Südkorea verfügt über fast 100.000 Fischereischiffe, und 140.000 Personen sind in der Fischverarbeitung beschäftigt. Umsatz und Beschäftigung in der Fischerei sinken seit den 1980er Jahren beständig. Die Küstengewässer Südkoreas sind weitgehend leergefischt, was die Regierung im Jahr 1997 veranlasste, die Küsten- und Tiefseefischerei zu regulieren.

Die Industrie trägt fast 35 % zum Bruttoinlandsprodukt bei und beschäftigt etwa 20 % aller Arbeitskräfte. In Südkorea werden vor allem Elektronik wie Computer, Telekommunikationsausrüstungen, Unterhaltungselektronik und Halbleiter hergestellt; daneben Fahrzeuge, Schiffe, Produkte der chemischen Industrie, Stahl und Produkte der Leichtindustrie wie Textilien, Schuhe oder Lebensmittel. In der Produktion von Halbleitern, Flachbildschirmen und Schiffen sind südkoreanische Unternehmen weltweit führend. Nach wie vor kann die südkoreanische Industrieproduktion hohe Wachstumsraten vorweisen.

Der großindustrielle Sektor erreichte in den 1970er Jahren seine größte Ausdehnung. Daneben gewann in den 1980er Jahren die Klein- und Mittelindustrie Beschäftigungsanteile hinzu. Kleine und mittlere Unternehmen erhöhten ihren Gesamtanteil an den Beschäftigten von 35 % im Jahr 1970 auf etwa 58 % im Jahr 1998. Seitdem ist Südkoreas Wirtschaft durch diese duale Wirtschaftsstruktur gekennzeichnet; eine oligopolistische Großindustrie existiert neben einem bedeutenden Wettbewerbssektor von Klein- und Mittelunternehmen.

Charakteristisch für die südkoreanische Wirtschaft ist die dominante Position der Jaebeols. Das sind große Industriekonglomerate, die aus rechtlich unabhängigen Einzelunternehmen bestehen. Die einzelnen Unternehmen sind durch Netzwerke auf der Ebene des Top-Managements verflochten, die wiederum durch autokratische Entscheidungssysteme von einem Familienclan kontrolliert werden. Die Jaebols sind des Weiteren über Interessenkonstellationen mit Staats- und Bankenwesen gesellschaftlich verankert. Die bekanntesten Jaebols sind Hyundai, Samsung, Daewoo, und LG. Sie sind meist sehr stark diversifiziert, auch wenn außerhalb Südkoreas nur kleine Teile der Jaebols bekannt sind. Samsung beispielsweise ist in Südkorea auch im Versicherungs-, Maschinen-, Großhandels- und Immobiliensektor aktiv.

Die Asienkrise 1997/98 hat die Schwächen in diesem System aufgezeigt. Die mangelhafte Wettbewerbsfähigkeit des südkoreanischen Wirtschaftsmodells führte bei vielen Jaebols zu Finanzierungsproblemen, die sich in steigenden Schuldenquoten widerspiegelten und gegen Ende der 1990er Jahre das ganze System der Jaebols unter Veränderungsdruck brachte. Besonders die Automobilindustrie war von der Krise betroffen. Ein gravierender Fall war der Zusammenbruch des Mutterkonzerns Daewoo (1999) unter der Last von etwa 80 Milliarden US-Dollar an Schulden, der mit dem Konkurs von Daewoo Motors im Jahr 2000 den Niedergang des zweitgrößten südkoreanischen Automobilherstellers nach sich zog.

Diese schwierige Situation führte zu einer Zunahme staatlicher Interventionen, nach einer Phase liberaler Zurückhaltung in den 1990er Jahren. Im Zuge ihres Reformprogramms zur Bewältigung der Krise traf die Regierung auch Maßnahmen zur Zerschlagung einiger dieser Jaebols. Ziel war es, die Unternehmen zu zwingen, sich auf ihr Kerngeschäft zu konzentrieren und unprofitable Geschäftsbereiche zu veräußern. Durch die Entflechtung des Jaebol-Systems und die Übernahme von Eigentumsanteilen durch ausländische Investoren ist heute nahezu die gesamte südkoreanische Automobilindustrie durch internationale Beteiligungen abgesichert. An der Grundstruktur, der Kontrolle durch Familienclans, hat sich jedoch trotz massiver Veränderungen auf vielen Gebieten wenig geändert.

Der Dienstleistungssektor erwirtschaftet etwa 62 % des südkoreanischen Bruttoinlandsproduktes. Gleichzeitig beschäftigt er etwa 63 % aller Arbeitskräfte. Die wichtigsten Branchen sind Finanzdienstleistungen, Einzelhandel, Transport und Tourismus.

Der Tourismus wuchs seit den 1970er Jahren beständig. Im Jahr 1970 besuchten etwa 170.000 Personen Südkorea. Im Jahr 2002, dem Jahr der Fußballweltmeisterschaft in Japan und Südkorea, kamen 5,3 Millionen Besucher ins Land. Davon waren etwa 43 % Japaner; die zweitgrößte Gruppe der Besucher kam aus der Volksrepublik China. Bereits im Jahr 2008 betrug die Anzahl der Besucher 6.890.841 und im Jahr 2009 7.817.533. Ein kurzer Aufenthalt in Südkorea ist für Besucher aus vielen Staaten ohne Visum möglich. Präsident der Nationalen Tourismusbehörde Südkoreas war von August 2009 bis November 2013 der in Deutschland geborene Lee Charm.

Laut der Korea Electric Power Corporation (KEPCO) betrug die installierte Leistung der Kraftwerke in Südkorea am Ende des Jahres 2012 81.805 MW, davon entfielen auf kalorische Kraftwerke 52.305 MW (63,9 %), auf Kernkraftwerke 20.716 MW (25,3 %) und auf Wasserkraftwerke 6.446 MW (7,8 %). Die installierte Leistung der Wärmekraftwerke verteilte sich wie folgt: Kohle 24.533 MW, Erdgas 20.566 MW sowie Öl 7.206 MW. Insgesamt wurden im Jahre 2012 509,574 Mrd. kWh produziert, davon 180,752 Mrd. durch Kohlekraftwerke (35,5 %), 150,327 Mrd. durch Kernkraftwerke (29,5 %), 113,984 Mrd. durch Gaskraftwerke (22,4 %), 28,244 Mrd. durch Ölkraftwerke (5,5 %) und 7,695 Mrd. (1,5 %) durch Wasserkraftwerke.

Laut dem Korea Energy Economics Institute (KEEI) wiesen die verschiedenen Kraftwerkstypen folgende Erzeugungskosten auf (angegeben in ₩ je kWh):

Ähnliche Werte findet man für das Jahr 2008 bei dieser Quelle: Atomstrom 39,02 ₩/kWh (0,0247 €/kWh), Strom aus Kohle 51,1 ₩/kWh (0,0324 €/kWh), Wasserkraft 135,6 ₩/kWh (0,0861 €/kWh), Strom aus Erdgas 143,6 ₩/kWh (0,0912 €/kWh), Strom aus Erdöl 191,5 ₩/kWh (0,1216 €/kWh), Windenergie 126,7 ₩/kWh (0,080 €/kWh) und Solarstrom 646,9 ₩/kWh (0,411 €/kWh).

Die Spitzenlast wurde am 26. Dezember 2012 mit 75.987 MW erreicht. Im Jahre 2012 lag Südkorea bzgl. der jährlichen Erzeugung mit 494,7 Mrd. kWh an Stelle 11 und bzgl. der installierten Leistung mit 84.870 MW an Stelle 14 in der Welt.

Die Kernenergie wurde in Südkorea massiv ausgebaut (siehe Liste der Kernkraftwerke in Asien#Südkorea; 1977 ging der erste Reaktor in Betrieb). 2006 lag der Anteil des Atomstroms um 39 %. Alle Anlagen werden vom Staatsunternehmen und Monopolisten "Korea Hydro & Nuclear Power" (KHNP) betrieben und vom Subunternehmen "Korea Power Engineering Company" (KPEC) gebaut. Korea sieht es als Vorteil, dass man – wenn man genügend Uran(brennstäbe) importiert – autark ist. Das "Korea-US Atomic Energy Agreement" aus den 1970er Jahren verbietet Korea die Urananreicherung und Wiederaufarbeitung. Korea ist hier auf Importe angewiesen.

Für die Brennstoffbeschaffung ist die "KEPCO Nuclear Fuel Company" (KNFC) verantwortlich, die zusammen mit KEPCO, Hanwha und KHNP in Kanada, Südafrika, Niger und Südamerika in Minenprojekte bzw. Uranbergbau involviert ist. Zur Anreicherung wurde Mitte 2007 ein 10-Jahresvertrag mit Areva NP unterzeichnet, und 2009 ein 2,5-Anteil an der Anreicherungsanlage Georges Besse II erworben. Das erste Kraftwerk Kori-1 wurde 1977 ans Netz genommen, im Jahr 1980 waren acht Reaktoren im Bau. Anfangs wurde im Kernkraftwerk Kori ein Design von Westinghouse verwendet, die Reaktoren im Kernkraftwerk Hanbit basieren auf der CP-Serie von Framatome. In Wolsong wurden kanadische CANDU-Anlagen verbaut. Die erste Eigenentwicklung war der OPR-1000 mit 1000 MWe; er ging ab 1998 in Betrieb. Daraus wurde der APR-1400 entwickelt, der mit erhöhter Redundanz und gesteigerter Blockleistung von etwa 1400 MWe ab 2008 gebaut wird und erstmals auch Exporterfolge in den Vereinigten Arabischen Emiraten verzeichnet. im Februar 2012 waren drei Reaktoren im Bau und sechs weitere in Planung, 23 Anlagen waren am Netz. Der Atomstromanteil soll dadurch langfristig auf über 50 % ansteigen.

Zur Entsorgung nuklearer Abfälle wurde 2009 die "Korea Radioactive Waste Management Co. Ltd" (KRWM) gegründet. KHNP zahlt dafür eine Entsorgungsabgabe von 900.000 Won (571 Euro) pro Kilogramm abgebrannter Brennelemente an KRWM, was je nach Anlagentyp etwa 0,15 bis 0,2 ct/kWh entspricht und im internationalen Vergleich recht hoch ist. Für die Entsorgung von schwach- und mittelradioaktiven Abfällen wurden im Jahr 2000 Gemeinden gebeten sich freiwillig als Standort zu melden, woraufhin sieben Anträge einreichten, aber in keiner die notwendige Bevölkerungsmehrheit zustande kam. Das Ministry of Knowledge Economy (MKE) wählte 2003 daraufhin vier Standorte aus, der Gewinner sollte 300 Mrd. Won (etwa 190 Mio. Euro) bekommen. Im November 2005 erhielt Gyeongju den Zuschlag nachdem sich dort 89,5 % der Wähler dafür entschieden, während an anderen Standorten die Zustimmung bei „nur“ 67,5 bis 84,4 % lag. Der Bau des Endlagers Wolsong begann im Juli 2008; es soll bis zu 281.600 m³ Abfälle aufnehmen. Über die Entsorgung von hochradioaktiven Abfällen sollte die bis 2014 einen Bericht erstellen und danach entschieden werden, wenn das 'Korea-US Atomic Energy Agreement' ausläuft. Dann soll festgelegt werden, ob eine direkte Endlagerung durchgeführt wird oder ob ein Einstieg in die Wiederaufarbeitungstechnologie erfolgt. Letztere Lösung wurde 2009 aus global-wirtschaftlichen und politischen Gründen favorisiert. Der Bericht der stand bis Stand November 2015 aus.

Südkorea ist Mitglied im Generation IV International Forum und arbeitet auch an der Entwicklung der Kernfusion (ITER). Der "Korea Superconducting Tokamak Advanced Research" (KSTAR) mit supraleitenden Spulen wurde dazu 2008 in Betrieb genommen.

Südkorea ist nach Japan der zweitgrößte Kohleimporteur der Welt. Etwa zwei Drittel des verbrauchten Stroms wurde um 2001 in Kohlekraftwerken produziert.

Südkorea importierte 2008 fast 64 Mio. t Kohle allein für die Stromerzeugung. Die wichtigsten Lieferländer waren Indonesien mit 26 und Australien mit 22 Mio. t. Im Jahre 2013 wurden 101 Mio. t Kohle für die Stromerzeugung importiert und es gibt Schätzungen, dass die Importe bis 2030 auf 140 Mio. t ansteigen werden. Kohle aus Indonesien oder Australien kostete im April 2014 etwa 105 USD je Tonne.

Südkorea hat kaum eigene Energieressourcen; weniger als 3 % des Energiebedarfs können aus eigenen Ressourcen gedeckt werden.
Das Land liegt in Hinblick auf den Energieverbrauch pro Kopf weltweit auf dem 19. Platz. Südkorea war 2001 der fünftgrößte Ölimporteur der Welt, es verbrauchte etwa 2,1 Millionen Fass Öl täglich. Mit Erdöl wurde um 2001 etwa 45 % des Primärenergiebedarfs gedeckt. Der Höchstwert von 66 % war Mitte der 1990er Jahre erreicht und fällt seitdem. Um den kontinuierlichen Nachschub an Erdöl zu sichern, wurde die "Korea National Oil Corporation" (KNOC) gegründet deren Aufgabe es ist, eine strategische Ölreserve zu halten und sich weltweit an Lagerstättenerkundungen und Förderprojekten zu beteiligen.

Südkorea hat das Kyoto-Protokoll unterzeichnet; Maßnahmen zur Verringerung des Kohlendioxidausstoßes sind vorgesehen. So liegt der Anteil der Wasserkraft seit Jahren konstant bei etwa 1,3 % und soll durch den Bau von Gezeitenkraftwerken wie Sihwa-ho und größeren Anlagen deutlich gesteigert werden. Im Rahmen des "Jeju Smart Grid Demonstration Project" wird die Insel Jeju unter Leitung des "Korea Smart Grid Institute" (KSGI) mit einem Intelligenten Stromnetz ausgestattet. Dafür sollen bis zur Fertigstellung im Jahr 2030 rund 2,75 Billionen Won (1,75 Mrd. Euro) investiert werden.

Der Arbeitsmarkt Südkoreas umfasst im Jahr 2016 etwa 25,4 Millionen Personen. Die Arbeitslosenrate liegt gleichzeitig bei etwa 3,7 %.

Etwa die Hälfte der südkoreanischen Frauen im arbeitsfähigen Alter sind beruflich aktiv. Im Januar 2016 wurde die Zahl der berufstätigen Frauen mit 11 Millionen angegeben. Die Anzahl der arbeitslosen Frauen betrage etwa 408.000.

In Südkorea gilt ein Mindestlohn, der jährlich angepasst wird. Im Jahr 2016 beträgt dieser 6.030 Won pro Stunde (etwa 4,5 Euro). 2017 wird der Mindestlohn auf 6.470 Won angehoben. Das Ministerium für Gesundheit und Wohlfahrt schätzt, dass sich etwa 1,4 Millionen Personen unterhalb der Armutsgrenze befinden und weitere 3,2 Millionen in potenzieller extremer Armut leben.

Im Jahr 2003 gab es in Südkorea mehr als 6.500 Gewerkschaften, die etwa 11 % aller Arbeitskräfte vertraten. Die meisten dieser Gewerkschaften existieren auf Firmenebene, einige davon sind auf nationaler Ebene in zwei nationalen Föderationen vereinigt. Im gleichen Jahr gab es 319 Streiks, bei denen insgesamt 1,3 Millionen Arbeitstage verloren gingen. Die Regierung wurde wiederholt dafür kritisiert, Gewerkschaften im öffentlichen Sektor nicht anzuerkennen und Gewerkschafter, die sich bei Streiks engagieren, verhaften zu lassen. Gemäß OECD-Daten aus dem Jahre 2004 beträgt die Arbeitsleistung koreanischer Arbeiter 2390 Stunden pro Jahr. Das seien 400 Stunden mehr als in Polen mit der zweitgrößten Stundenzahl und 34 % mehr als in den Vereinigten Staaten. Nach Angaben der südkoreanischen Regierung sank die Zahl der Arbeitsstunden geringfügig auf 2316 im Jahre 2007.

Die internationalen Wirtschaftsbeziehungen, insbesondere der Export, sind einer der zentralen Punkte der Außenpolitik Südkoreas. Seit 1995 ist das Land Mitglied der WTO. Die Exporte haben sich seit den 1970er Jahren rasant entwickelt. Während sie in den frühen 1970er Jahren etwa 10 % des BIP ausmachten, lag dieser Prozentsatz im Jahr 2014 bei 50,6 %. Die wichtigsten Exportgüter sind Elektronik, Fahrzeuge, Unterhaltungselektronik, Nukleartechnik und Maschinen, Stahl, Schiffe sowie Produkte der chemischen Industrie. Die wichtigsten Absatzmärkte für südkoreanische Güter sind Volksrepublik China und die USA. Danach folgen Hongkong, Vietnam und Japan. Die wichtigsten Importgüter sind Rohöl, Lebensmittel, Maschinen und Fahrzeuge, Chemikalien und Metalle. Die meisten Importe stammen aus der Volksrepublik China, den USA, Japan, Deutschland und Australien.

Die gesamten Exporte des Jahres 2015 beliefen sich auf etwa 527 Mrd. US-Dollar, die Importe lagen bei 436 Milliarden. Dies führte zu einem Außenhandelsüberschuss von 91 Milliarden US-Dollar.

Ausländische Firmen investierten in Südkorea im Jahr 2016 nahezu 184 Mrd. US-Dollar. Der größte Investor mit etwa 36 % sind die Staaten der Europäischen Union, danach folgen Singapur, die USA, Hongkong und Japan. Während sich die amerikanischen Investitionen auf den Servicesektor konzentrieren, investieren die japanischen Firmen größtenteils in Industrieunternehmen. Die ausländischen Investitionen werden durch Bedenken über Korruption, politische Instabilität und unfaire Handelspraktiken gebremst.

Die wichtigen Wirtschaftskennzahlen Bruttoinlandsprodukt, Inflation, Haushaltssaldo und Außenhandel entwickelten sich in den letzten Jahren folgendermaßen:

Die OECD prognostizierte für Südkorea 2017 ein Wirtschaftswachstum von 2,8 %. Im Schlussquartal 2008 lag es bedingt durch die Weltwirtschaftskrise bei −5,6 %. 2009 erholte sich der Wert auf 0,2 %.

Der Staatshaushalt umfasste 2016 Ausgaben von umgerechnet 321,0 Mrd. US-Dollar; dem standen Einnahmen von umgerechnet 304,3 Mrd. US-Dollar gegenüber. Daraus ergibt sich ein Haushaltsdefizit in Höhe von 1,2 % des BIP.
Die Staatsverschuldung betrug 2016 550 Mrd. US-Dollar oder 39,0 % des BIP.

2006 betrug der Anteil der Staatsausgaben (in % des BIP) folgender Bereiche:

Die erste Eisenbahnverbindung in Korea war ein Teilstück der Gyeongin-Linie, die Seoul mit dem nahen Incheon verbindet und am 18. September 1899 eröffnet wurde. Die Gyeongbu-Linie von Seoul nach Busan wurde am 1. Januar 1905 eröffnet, diese ist noch heute die wichtigste Strecke Südkoreas. Das Streckennetz umfasst heute 78 Routen und weist eine Gesamtlänge von 3.389 Kilometern auf. Die staatliche Eisenbahngesellschaft KORAIL besaß im Juli 2005 3.935 Lokomotiven, darunter auch 920 Lokomotiven für den Hochgeschwindigkeitsbetrieb sowie 15.062 Waggons. 1.192 davon sind Personenwagen, bei nahezu allen übrigen handelt es sich um Güterwaggons.

Beim Schienenpersonenverkehr gibt es vier Kategorien. Der Nahverkehr wird durch die sogenannte "Tonggeun" (, ; "Pendelzug") bedient. Die nächsthöhere Kategorie stellt die sogenannten "Mugunghwa" (, ; "Sharonrose") dar, die beliebteste Klasse. Noch seltener halten die "Saemaeul"-Züge (, ; "Neue Gemeinde"), die mehr Komfort bieten.

Seit 2004 gibt es außerdem einen auf dem französischen TGV basierenden Hochgeschwindigkeitszug namens Korea Train Express (KTX), der die Strecken Seoul–Busan und Seoul–Mokpo (Honam-Linie) bedient. Bis Cheonan laufen beide Strecken gemeinsam. Vor allem wegen der Hochgeschwindigkeitstrassen von Seoul bis Daegu konnte die Reisezeit auf der Strecke nach Busan von vorher viereinhalb Stunden auf zwei Stunden und 40 Minuten reduziert werden. Diese Zeit sank mit der Eröffnung der Hochgeschwindigkeitsstrecke zwischen Daegu und Busan 2010 auf zwei Stunden und 10 Minuten. Eine Neubaustrecke nach Gwangju mit Verlängerung nach Mokpo befindet sich in einem frühen Planungsstadium, eine Eröffnung ist für 2017 angepeilt. Nach der Eröffnung blieb die Zahl der Fahrgäste zunächst weit hinter den Erwartungen zurück, erst im Dezember 2005 überstieg die Anzahl der täglichen Benutzer die 100.000-Marke.
In den sechs größten Städten Südkoreas werden heute U-Bahn-Systeme betrieben. Diese stellen einen wichtigen Eckpfeiler im Nahverkehr der Großstädte dar und werden noch laufend erweitert. Das erste und größte U-Bahn-Netz Südkoreas ist das der Hauptstadt Seoul. Das Netz der U-Bahn Seouls wurde 1974 eröffnet und umfasst heute acht Linien mit einer Gesamtlänge von 287 Kilometern und 263 Stationen. Es verbindet die Stadt mit den zahlreichen Satellitenstädten im Umland und wird täglich von durchschnittlich 5,6 Millionen Passagieren benutzt. Die U-Bahn Busan wurde 1985 eröffnet. Heute umfasst das Streckennetz drei Linien mit einer Gesamtlänge von 88,8 Kilometern und 90 Stationen, die tägliche Transportleistung liegt bei über 706.000 Passagieren.

1997 ging die erste Linie der U-Bahn Daegu in Betrieb, eine zweite Linie wurde 2005 eröffnet. Das Netz umfasst seitdem 57,3 Kilometer mit 56 Stationen. Bei einem durch einen psychisch Erkrankten ausgelösten Brand am 18. Februar 2003 kamen fast 200 Personen ums Leben, das Unglück gilt weltweit als eines der schwersten in der Geschichte der U-Bahnen.
Die 1999 eröffnete U-Bahn Incheon umfasst eine Linie mit 24,6 Kilometer Länge und 22 Stationen; es ist außerdem mit dem Netz der U-Bahn Seouls verbunden. Die erste Linie der U-Bahn Gwangju wurde 2004 eröffnet und umfasst bisher 14 Stationen bei einer Länge von 12 Kilometern. Der neueste Betrieb ist der der U-Bahn Daejeon, die im März 2006 eröffnete Linie umfasst bisher 12 Stationen auf 12,4 Kilometern Länge.

Das Straßennetz Südkoreas umfasst eine Gesamtlänge von 97.252 Kilometern, von denen 74.641 Kilometer asphaltiert sind. Das Autobahnnetz, in Südkorea "Express Way" genannt, wurde mit der 1968 eröffneten, 24 Kilometer langen Autobahn von Seoul nach Incheon in Betrieb genommen. Die mit 425,5 Kilometern deutlich längere Autobahn von Seoul nach Busan wurde zwei Jahre später eröffnet. Ende 2005 umfasste das Express-Way-Netz 24 Autobahnen mit einer Gesamtlänge von 2.968 Kilometern, die größtenteils mautpflichtig sind.
Neben den in der Regel gut ausgebauten Stadtbusnetzen verfügt Südkorea auch über ein gut ausgebautes überregionales Busnetz. Intercity-Busse verbinden die meisten Städte des Landes miteinander. Viele Linien machen mehrere Zwischenhalte, andere fahren Nonstop zum Zielort. Etwas teurer sind die Express-Busse, die das nationale Autobahnnetz – meist mit eigener Busspur – nutzen. Rund die Hälfte der Linien beginnt oder endet in Seoul, rund 70 weitere Städte sind an das Netz angebunden. Die meistbefahrenen Linien werden alle 5 bis 10 Minuten bedient, wobei alle Busse ihr Ziel direkt anfahren.

Mit dem wirtschaftlichen Aufschwung des Landes hat der Automobilverkehr einen dramatischen Anstieg erfahren. So stieg die Anzahl der registrierten Fahrzeuge zwischen 1980 und 2006 von 527.729 auf 15.493.681. Dies entspricht einem Anstieg von 14 % jährlich. Noch deutlicher ist die Steigerung, wenn man nur die Klasse der Personenwagen betrachtet. Deren Zahl stieg von 249.102 (1980) auf 11.224.016 im Jahr 2006, das entspricht einem Zuwachs um das 45-fache. Dies führte vor allem in Großstädten zu den üblichen Problemen. Neben der Überlastung der Straßen ist der Straßenverkehr eine schwere Belastung für die Umwelt. So hat Seoul die stärkste Luftverschmutzung aller Städte in den Mitgliedsstaaten der OECD zu ertragen.

Um der ebenfalls stark gestiegen Bedeutung des Luftverkehrs gerecht zu werden, wurde 2001 auf der Insel Yeongjongdo, 52 Kilometer westlich von Seoul, der Incheon International Airport in Betrieb genommen. Er löste als Drehscheibe für internationale Flüge den überlasteten Flughafen Gimpo ab, von dem hauptsächlich nationale Ziele angeflogen werden.

Vom Incheon International Airport bieten die beiden südkoreanischen Fluggesellschaften Korean Air und Asiana Airlines pro Woche mehr als 1700 internationale Direktverbindungen in die wichtigsten Städte Asiens, Nordamerikas, Europas und des Mittleren Ostens an.

Nationale Flüge werden zwischen Seoul, Busan, Jeju, Daegu, Gwangju, Jinju, Wonju, Cheongju, Yeosu, Ulsan, Yangyang und Pohang angeboten. 2003 wurden zwischen diesen Städten 21,3 Millionen Passagiere befördert.

Durch seine Lage auf der Koreanischen Halbinsel mit hunderten von bewohnten Inseln sowie der Situation als Exportnation spielt die Schifffahrt für Südkorea eine bedeutende Rolle. Die wichtigsten Seehäfen sind Incheon und Gunsan an der Westküste, Mokpo, Jinhae und Masan an der Südküste, sowie Busan, Donghae, Ulsan und Pohang an der Ostküste. Der jährliche Güterumschlag der südkoreanischen Häfen betrug 2003 596 Millionen Tonnen, im Gegensatz zu 9 Millionen Tonnen im Jahre 1961. Die südkoreanische Handelsmarine umfasste 2005 650 Schiffe mit mehr als 1000 Bruttoregistertonnen.

Internationale Fähren fahren von Incheon nach Weihai, Yantai, Qingdao, Shanghai, Tianjin, Dalian und Dandong in der Volksrepublik China. Von Busan werden Routen nach Shimonoseki, Tsushima und Hakata in Japan sowie Yantai in China angeboten. Ebenfalls in China liegt Lianyungang, das von Mokpo angefahren wird. Außerdem Sokcho wird eine Route nach Zarubino in Russland angeboten. Nationale Fähren fahren zu den zahlreichen Inseln. Durch den Jeju International Airport auf der Insel Jeju verlieren die Fährlinien dorthin aber zunehmend an Bedeutung.

Während sich die Zahl der Festnetzanschlüsse in Südkorea in den letzten Jahren praktisch nicht verändert hat, ist die Zahl der Mobiltelefone stark angestiegen. 2004 gab es in Südkorea 26,6 Millionen Festnetzanschlüsse und 36,6 Millionen Mobiltelefone bei einer Bevölkerungszahl von 48,8 Millionen Menschen. Die Anzahl der Breitband-Internetzugänge betrug 12,2 Millionen, womit das Land weltweit lange die meisten Breitbandanschlüsse pro Einwohner hatte, bis es 2006 von Island überholt wurde. Die Anzahl der PCs betrug 26,2 Millionen Geräte, die Anzahl der Internet-Benutzer 43,2 Millionen. Südkorea hatte 2017 das schnellste Internet der Welt. Dies zeigt die hohe Technisierung des Landes.

In Südkorea werden pornografische Webinhalte, nordkoreanische Webseiten sowie Onlinedienste, die nach Ansicht der Behörden die „öffentliche Ordnung“ stören könnten, blockiert.

Südkorea gab im Jahr 2014 4,3 % des BIP für Forschung und Entwicklung aus und damit prozentual mehr als jedes andere Land. 2006 implementierte die südkoreanische Regierung ein Regelwerk, durch das Autoren von Fachartikeln in wichtigen Zeitschriften wie "Science", "Nature" und "Cell" 3 Millionen Won erhalten. Um die Forschung weiter zu stärken, wurde das Institute for Basic Science gegründet, vergleichbar mit RIKEN in Japan und der Max-Planck-Gesellschaft in Deutschland.
Nach Japan, den USA und Deutschland verfügt Südkorea über den weltweit vierthöchsten Bestand von Industrierobotern. Das Wachstum betrug von 2011 auf 2014 etwa 59 % und weist eine Menge von 150.505 Robotern auf. In der Servicerobotik ist Südkorea neben Japan führend.

2005 entwickelten Forscher des Korea Advanced Institute of Science and Technology (KAIST) den weltweit zweiten, laufenden humanoiden Roboter, HUBO. Ein Team des Korea Institute of Industrial Technology entwickelte den ersten koreanischen Androiden, Ever-1 im Mai 2006.

Südkorea hat innerhalb der OECD die höchste Rate von Absolventen in Naturwissenschaften und Ingenieurswesen. Außerdem führt das Land den "Bloomberg Innovation Index" an. Des Weiteren weist Südkorea nur geringe Grenzen für neue Technologien auf und wird deshalb als Testmarket, gerade für Smartphone-Technik, genutzt. Zahlreiche Inventionen neuer Medien und Apps sowie 4G- und 5G-Infrastrukturen werden in Südkorea umgesetzt.

Südkorea brachte 10 Satelliten seit 1992 ins All, Arirang-1 (1999) und Arirang-2 (2006) durch eine Partnerschaft mit Russland. Arirang-1 ging 2008, nach neun Jahren Nutzungszeit, im All verloren.

Im April 2008 flog Yi So-yeon als erste koreanische Astronautin an Bord einer russischen Soyus TMA-12 ins All. Im Juni 2009 wurde Südkoreas erster Weltraumbahnhof, das Naro Space Center, in Goheung (Jeollanam-do) in Betrieb genommen. Der Start der Rakete Naro-1 im August 2009 scheiterte. Auch der zweite Versuch im Juni 2010 war nicht erfolgreich. Der dritte Start im Januar 2013 war schließlich erfolgreich.

Südkoreas Anstrengungen eine eigene Trägerrakete zu entwickeln stoßen auf politischen Druck ausgehend von den USA, die über mehrere Jahrzehnte Südkoreas Ambitionen behinderten. Die USA befürchteten, dass es sich um geheime, militärische Programme handeln könnte. Südkorea suchte eine Zusammenarbeit mit weiteren Staaten, wie Russland, um eine einheimische Raketentechnologie zu entwickeln.

Durch den großen Einfluss des Konfuzianismus wird der Bildung in Korea traditionell ein sehr hoher Wert beigemessen. Auch heute ist das spürbar, wo die Ausbildung wesentlich den späteren sozialen Status bestimmt. Moderne Schulen wurden in Korea in den 1880er Jahren eingeführt. Mit der Gründung Südkoreas begann die Regierung, ein modernes Schulsystem nach westlichem Vorbild zu errichten. Heute weist Südkorea eine der höchsten Alphabetisierungsraten weltweit auf, und die gut ausgebildete Bevölkerung wird als einer der wesentlichen Gründe für den starken wirtschaftlichen Aufschwung in der Vergangenheit angesehen. Das südkoreanische Bildungssystem ist stark zentralisiert. Die für das Bildungssystem verantwortliche Institution ist das „Ministerium für Bildung und die Entwicklung von Humanressourcen“.

Das südkoreanische Bildungssystem ist in den letzten Jahren aber auch zunehmend in die Kritik geraten. Insbesondere wird der große Leistungsdruck in der High School kritisiert. So ist es für Schüler dieser Schulen (ähnlich wie in Japan) nicht unüblich, dass sie einen 12-Stunden-Tag haben und mehrere "Hagwon" genannte Paukschulen besuchen. Die Abschlussprüfung ist entscheidend dafür, welche Universität man besuchen kann. Diese wiederum ist maßgeblich für die späteren Berufschancen und den sozialen Status. Am Tag der Prüfung fahren viele Menschen später zur Arbeit, um die Schüler nicht im Berufsverkehr stecken bleiben zu lassen; sogar Flugzeugstarts müssen zu bestimmten Zeitpunkten unterbleiben.

Die Vorschulausbildung hat in den letzten Jahren an Bedeutung gewonnen. Gab es im Jahre 1980 landesweit nur 901 Vorschulen, so stieg deren Zahl bis 2003 auf 8.292. Seit 1999 werden Kindergartenplätze für Kinder aus sozial schwachen Familien vom Staat bezuschusst. 2002 wurde das Programm erweitert, um 20 % der fünfjährigen Kindergartenkinder komplett von den Gebühren zu befreien.

Das Schulsystem gliedert sich in eine sechsjährige Grundschule (, , "chodeunghakgyo"), eine dreijährige Mittelschule (, , "junghakgyo") sowie eine dreijährige High School (, , "godeunghakgyo"). Der Besuch der Grundschule und seit 2002 auch der Mittelschule ist verpflichtend, nahezu alle Schüler wechseln anschließend auf die High School (99,7 % aller Schüler im Jahr 2004). In Grundschulklassen gibt es im Durchschnitt 26,2 Schüler pro Lehrer (Stand: 2002). An der Mittelschule unterrichtet ein Lehrer im Durchschnitt 19 Schüler (Stand: 2004). Die durchschnittliche Klassengröße insgesamt stand 2003 bei 34,5 Schülern.

Es gibt zwei Arten von High Schools, eine allgemeinbildende, auf ein Hochschulstudium vorbereitende (, , "inmun-gye godeunghakgyo" genannt), sowie eine berufsvorbereitende High School (, , "sireobgye godeunghakgyo"), von der wiederum vier Unterarten existieren, die speziell auf die Themen Landwirtschaft, Ingenieurs- und Wirtschaftswissenschaften sowie Meereskunde vorbereiten. Der Lehrplan an diesen Schulen enthält zwischen 40 und 60 % Fächer aus diesen Gebieten, der Rest gilt der Allgemeinbildung. Auch einige der allgemeinbildenden High Schools haben sich auf bestimmte Fächer wie Kunst, Sport, Wissenschaft oder Fremdsprachen (wie die HAFS) spezialisiert. 2004 gab es 729 berufsvorbereitende High Schools mit 514.550 Schülern und 1.351 allgemeinbildende High Schools mit 1,23 Millionen Schülern. Rund 97 % eines Jahrgangs schließen die High School erfolgreich ab; mit diesem Wert liegt Südkorea weltweit an der Spitze.

Südkorea kennt ein differenziertes Hochschulsystem. Universitäten und Colleges bieten vierjährige Bachelor-Studiengänge an (sechsjährig für Medizin und Zahnmedizin). Dem können weiterführende Studiengänge zur Promotion folgen. An eigenen Hochschulen (vierjährig) findet die Lehrerbildung statt, daneben existieren berufsvorbereitende Colleges (zwei- oder vierjährig), Fernuniversitäten, sowie mehrere Schulen mit Universitätsstatus, die zwei- oder vierjährige Studiengänge anbieten. 2004 gab es in Südkorea insgesamt 411 Institutionen der höheren Bildung mit zusammen 3,56 Millionen Studenten und rund 64.000 Lehrkräften. Gab es 1960 lediglich 52 Universitäten im Land, lag 2013 ihre Anzahl mit 345 um ein Vielfaches höher. 71 % aller Oberschüler, die die Hochschulzulassung erreicht haben, gehen zur Universität, wovon zwischen 600.000 bis 700.000 Studenten jährlich ihre Universität mit einem Abschluss verlassen. Eine besondere Herausforderung für den Südkoreanischen Arbeitsmarkt.

Eine Besonderheit im südkoreanischen Bildungssystem stellen spezielle Universitäten nur für Frauen dar. Diese stammen aus der Zeit, als die anderen Universitäten allein den männlichen Studenten zugänglich waren, sie wurden teilweise von christlichen Missionaren gegründet. Universitäten exklusiv für Männer gibt es heute aber keine mehr. Ein Teil der Hochschulen sind Staatsgründungen, andere private. Die bekannteste staatliche ist die Seoul National University, von den privaten sind die Yonsei University und die Korea University hoch angesehen.

Südkorea teilt die traditionelle Kultur mit Nordkorea. Die Differenzen zwischen Nord- und Südkorea haben jedoch dazu geführt, dass sich die gegenwärtige südkoreanische Kultur von der des Nordens unterscheidet. Seit den 1990er Jahren erfreuen sich südkoreanische Filme, Fernsehserien und Musik zunehmend weltweiter Beliebtheit. Dieses Phänomen wird als Koreanische Welle ("Hallyu") bezeichnet.

Um Westen wurde der Autor Kim Chi-ha bekannt, da er in seinen Werken der Auflehnung gegen die Diktatur von Park Chung-hee Ausdruck verlieh. Aufgrund dessen wurde er 1974 zum Tode verurteilt. Dies löste international einen Skandal aus und es folgten Proteste von westlichen Intellektuellen, wie Jean-Paul Sartre, Heinrich Böll und Noam Chomsky, bis eine Amnestie erfolgte. Eines der bekanntesten südkoreanischen Werke im deutschsprachigen Raum ist wohl der Roman "Als Mutter verschwand" von Sin Kyong-suk. Drei Themen bestimmen auffallend die Gegenwartsliteratur in Südkorea: Die Teilung Koreas sowie der Koreakrieg und die Industrialisierung des Landes seit den 1960er Jahren. Außerdem spielt die Entfremdung des Individuums in einer kapitalistischen und verstädterten Gesellschaft, die mit ihren traditionellen Werten ringt. Die Autorengeneration nach 1945 wird auch als Hangeul-Generation bezeichnet, da diese nicht mehr in der japanischen Sprache schrieben.

In Südkorea füllen sich bei Literaturlesungen teilweise Stadien. Auf der Frankfurter Buchmesse 2005 war Südkorea Gastland. Bedeutende zeitgenössische Autoren aus Südkorea sind Park Kyung-ni, Ko Un, Yi Mun-yol, Hwang Sok-yong und Pak Wanso. Hwang Sok-yong hat den Koreakrieg selbst erlebt und war im Vietnamkrieg als Soldat im Einsatz. Ein zentrales Thema seiner Werke stellt der Konflikt zwischen Tradition und Moderne dar.

Die Autorin Han Kang wurde 2016 mit dem wichtigsten britischen Literaturpreis, dem Man Booker Prize, für ihr Werk "Die Vegetarierin" bedacht. Das Buch wurde auch ins Deutsche übersetzt. Wie viele Autoren der jüngeren Generation setzt sich auch Han mit dem Modernisierungsschub auseinander. Dabei ist auch Globalisierungskritik und Fortschrittsskeptik zu erkennen. Der Schriftsteller Kim Young-ha hingegen ist ein Modernisierungsbejaher. Ijoma Mangold von der "Süddeutschen Zeitung" bezeichnet seine Erzählung "Klingende Weihnachtsgrüße" als „eine psychologische Erzählung von hoher Raffinesse und sehr zeitgenössischem Charakter“. Des Weiteren sind die Romane der Autorinnen Kim Ryŏ-ryŏng und Gong Ji-young populär. Von ihren Werken wurden einige erfolgreich verfilmt.

Comics aus Südkorea werden Manhwa genannt und finden auch in Deutschland zunehmend Interessenten. Es gibt in Südkorea zahlreiche sogenannte Manhwabangs, in denen Manhwas gelesen und ausgeliehen werden können. Durch Webtoons und Apps wie Daum Webtoon und Line Webtoon bekommen Comics aus Südkorea international zunehmend Aufmerksamkeit. Bekannte Autoren sind Jeon Geuk-jin, Yoon Tae-ho, Yang Yeong-soon, Chon Kye-young, Horang, Kang Full und Soonkki.

Westliche Musik erreichte Korea gegen Ende des 19. Jahrhunderts in Form christlicher Hymnen der Missionare. Die Verbreitung westlicher Musik wurde zur Zeit des Koreanischen Kaiserreichs vor allem durch die Militärkapelle vorangetrieben. Der deutsche Dirigent Franz Eckert wurde 1901 beauftragt, diese zu gründen und zu leiten. 1915 wurde während der Zeit, als Korea eine Kolonie Japans war (1910–1945), die oben genannte Militärkapelle aufgelöst. Anstelle von traditioneller Musik wurde im staatlichen Schulsystem ausschließlich westliche und japanische Musik gelehrt. Somit nahm diese Musik eine feste Stellung in Korea ein. Koreanische Musiker die in Japan westliche Musik studierten, wie Hyeon Che-myeong (1902–1960) oder Choi Dong-seon (1901–1953), kehrten in den 1930er Jahren nach Korea zurück und versuchten, die Qualität der musikalischen Ausbildung dort zu verbessern. Gleichzeitig erlebte der Musikkonsum durch den Bau von neuen Theatern und Konzertsälen, sowie durch die Schallplattenindustrie ein starkes Wachstum.

Mit Beginn des Zweiten Chinesisch-Japanischen Krieg im Jahr 1937 leitete der damalige General Generalgouverneur der koreanischen Kolonie, Minami Jirō, offiziell eine Angleichungspolitik ein. Pro-Japan-orientierte Musiker, unter anderem Hong Nan-pa (jap. Morikawa Jun, 1897–1941) und Hyeon Che-myeong (jap. Kuroyama) stellten daraufhin Leitfiguren der koreanischen Musikszene dar. Nach dem Zweiten Weltkrieg und dem Koreakrieg war das schöpferische Klima zunächst belastet.

Die Komponisten der späten 1960er Jahre, wie Kang Suk-hi (geb. 1934), Paik Pyong-dong (geb. 1936) und Kim Chong-gil (geb. 1934), glaubten, dass sie so schnell wie möglich die westlichen Kompositionstechniken des 20. Jahrhunderts übernehmen müssten, wenn sie das kreative Leben Südkoreas aus seiner historisch bedingten Rückständigkeit erlösen wollten. Diese führenden Komponisten der zweiten Generation studierten in Hannover beim koreanisch-deutschen Komponisten Yun I-sang Dieser gilt als erster Künstler, der die Formen und Klänge der traditionellen koreanischen Musik mit der zeitgenössischen europäischen Musik verbunden hatte.

Die Komponisten der Dritten Generation moderner Musiker, drängten darauf, die musikalischen Grundsätze ihrer Vorgänger zu überwinden. In den 1980er Jahren bildeten sie eine Bewegung zur Entwicklung einer „koreanischen“ Musiktheorie. Eine Reihe von Musikern, darunter Yi Keon-yong (geb. 1947), vertraten die Auffassung, „echte koreanische Musik“ sei unmöglich, wenn man sich ausschließlich an westlichen Techniken orientierte. Im beginnenden 21. Jahrhundert erscheint der Dissens weitgehend beigelegt. Die Musiker versuchen nun, das künstlerische Erbe Koreas mit einer angemessenen Akzeptanz der westlichen Musik schöpferisch zu nutzen.

Im Zuge der koreanischen Welle wurde K-Pop in ganz Asien und auch weltweit sehr populär.

Bis in die 1990er waren Trot und Balladen das vorherrschende Genre in Südkorea. Das Aufkommen der Rap-Pop-Gruppe Seo Taiji and Boys 1992 markiert einen Wendepunkt im koreanischen Musikmarkt und Popmusik mit vielen Boy und Girlgroups, aber auch Solosängern, wurde beliebt. 2007 trat Girls’ Generation eine weitere Girlgroup-Welle los, die aktuell etwas abflacht. Insbesondere Psy wurde durch seinen Hit "Gangnam Style" (2012) weltweit bekannt. Weitere aktuell sehr beliebte Künstler sind Big Bang, IU, Jang Yoon-jung, Sistar, Lim Chang-jung, EXO, Bangtan Boys und AOA.

Karaoke ist in Südkorea eine beliebte Freizeitbeschäftigung. Die sogenannenten Noraebangs sind an vielen Ecken aufzufinden und beliebt bei jungen, aber auch bei vielen älteren Leuten. Die koreanischen Karaokeräume sind mit den japanischen Karaokeboxen zu vergleichen.

Gemessen an Kinobesuchen ist Südkorea mit über 200 Millionen verkauften Karten jährlich der viertgrößte Filmmarkt der Welt. Zudem finden mit dem Busan International Film Festival jährlich die größten Filmfestspiele Asiens statt. Eine der größten Kinoketten der Welt ist CJ CGV mit Sitz in Südkorea. Zwei weitere große Ketten sind Lotte Cinema und Megabox. Erstere hält mit dem "Super Plex G" im Lotte World Tower den Weltrekord für die größte Kinoleinwand der Welt. Auch der vorherige Rekordhalter befindet sich in Seoul: Das Starium von CGV.

Seit den 1990er Jahren gewann der südkoreanische Film international an Bedeutung. Der 1999 veröffentlichte Spielfilm Shiri stellt dabei den ersten großen kommerziellen Erfolg dar. Allein in Seoul hatte der Film über 2 Millionen Zuschauer. Auch auf den größten europäischen Filmfestivals waren südkoreanische Filme erfolgreich. 2002 gewann Lee Chang-dongs Film "Oasis" den Silbernen Löwen von Venedig. 2004 wurde Kim Ki-duk auf der Berlinale für die beste Regie für "Samaria" ausgezeichnet und im gleichen Jahr wurde in Cannes "Oldboy" mit dem Großen Preis der Jury ausgezeichnet. 2010 wurde Lee Chang-dong in Cannes für das beste Drehbuch für "Poetry" ausgezeichnet. Kim Ki-duks Film "Pieta" erhielt 2012 den Goldenen Löwen der Filmfestspiele von Venedig und Hong Sang-soos "Right Now, Wrong Then" 2015 den Goldenen Leoparden von Locarno. Die wichtigsten nationalen Auszeichnungen sind der Blue Dragon Award und der Grand Bell Award.

In der zeitgenössischen südkoreanischen Kunst tritt die traditionelle koreanische Formensprache in einen Dialog mit der westlichen Moderne. Seit einigen Jahren findet Gegenwartskunst aus Südkorea stetig zunehmende Beachtung und erzielt auch in den großen Kunstauktionen hohe Preise, nachdem sie lange im Schatten chinesischer Kunst stand. Bedeutende Maler und Bildende Künstler sind unter anderem Junggeun Oh sowie Tschoon Su Kim und Suh Yongsun.

In der Videokunst gilt Nam June Paik als weltweit bedeutendster Pionier. Er wird als „Vater der Videokunst“ bezeichnet.

Online-Spiele und das traditionelle Brettspiel Baduk (japanisch: Go) entwickelten sich zu einem wichtigen Teil der südkoreanischen Kultur. So werden Baduk-Partien im Fernsehen übertragen und für sachliche Analysen wiederholt.

Südkorea gilt als „Mekka des E-Sports“. Lange Zeit war das PC-Strategiespiel StarCraft: Brood War das mit Abstand am meisten im Fernsehen übertragene Spiel in Südkorea. Die Spiele werden oftmals von Sendern wie MBCGame und OnGameNet ausgestrahlt, können aber auch in Internet auf Seiten wie GOMtv mitverfolgt werden. Turniere werden in der Regel Live übertragen und haben hohe Zuschauerzahlen. Professionelle Starcraft-Spieler können durch das Spielen in Südkorea viel Geld verdienen und werden teilweise auch als Prominente angesehen, wie z. B. Lim Yo-hwan („Boxer“), Lee Jae-dong („Jaedong“) und Lee Young-ho („Flash“). Seit etwa 2011 hat das Spiel "League of Legends" eine ähnliche Popularität erreicht wie es "" in den 2000er Jahren hatte.

Computer-Spiele werden normalerweise in sogenannten "PC Bangs", die Ähnlichkeit mit Internetcafés haben, aber nur zum Spielen von LAN-Titeln genutzt werden können, wie "MapleStory", "World of Warcraft", "Mabinogi", "Lineage". Wenngleich es vor allem eine Freizeitbeschäftigung für Studenten ist, finden sich hier dennoch Menschen jeden Alters unabhängig vom Geschlecht zusammen.

Bei der Rangliste der Pressefreiheit 2017, welche von Reporter ohne Grenzen herausgegeben wird, belegte Südkorea Platz 63 von 180 Ländern. Trotz der generellen Pressefreiheit gibt es laut der Nichtregierungsorganisation „erkennbare Probleme“, da einige autoritäre Gesetzte aus der Zeit der Diktatur noch existieren.

Als wichtigste Tageszeitungen gelten die Chosun Ilbo, JoongAng Ilbo und Dong-a Ilbo, die als konservativ eingeschätzt werden und häufig unter dem Begriff "Chojoongdong" () zusammengefasst werden. Die Hankyoreh ist eine politisch eher linksgerichtete Zeitung. Die wichtigsten Fernsehsendeanstalten sind KBS, MBC und SBS.

Das südkoreanische Nationalgericht ist Kimchi, ein überwiegend scharf eingelegtes Gemüse. Unter den südkoreanischen Hauptspeisen nimmt Bulgogi (gebratene Rindfleischstreifen) eine Sonderstellung ein. Die in einer Mischung aus Sojasauce, Sesam, und Gewürzen marinierten Fleischstreifen werden über einem Holzkohlenfeuer gebraten. Galbi heißen zarte Rippenstücke, die wie Bulgogi mariniert und gebraten oder gegrillt werden. Aber nicht das Fleisch, sondern immer noch der Reis gilt in Südkorea als wichtiger Bestandteil des Essens.

Zu einer echten südkoreanischen Mahlzeit gehört auch eine Suppe, die als eine der frühesten kulinarischen Errungenschaften des Landes gilt. Berühmt ist beispielsweise die "Doenjangguk", eine Suppe aus fermentierten Sojabohnen ("doenjang") mit Gemüse und oft auch Muscheln. Gern gegessen werden auch die aus "Myeolchi"-Pulver (getrockneten, fermentierten, gemahlenen Sardellen) gekochte leichte Brühe sowie Gemüsesuppen, zubereitet aus Trockenspinat, Rettichscheiben oder aus frischen oder getrockneten Algen ("miyeokguk"). Gekühltes Obst, in Stücke zerkleinert, ist das übliche Dessert: Je nach Jahreszeit sind dies verschiedene Melonen, Erdbeeren, Äpfel oder Nashi-Birnen. Bei festlichen Anlässen wird auch "Tteok" (Reiskuchen) serviert. Sein Verzehr hat rituelle Gründe.


Links zu Webseiten in Deutschland

Links zu Webseiten in Südkorea

Links zu anderen Webseiten


</doc>
<doc id="10406" url="https://de.wikipedia.org/wiki?curid=10406" title="Lieferkette">
Lieferkette

Mit Lieferkette (engl. "supply chain" []) wird das Netzwerk von Organisationen bezeichnet, die über vor- und nachgelagerte Verbindungen an den verschiedenen Prozessen und Tätigkeiten der Wertschöpfung in Form von Produkten und Dienstleistungen für den Endkunden beteiligt sind. Das Konzept der Lieferkette gehört zum Standardrepertoire der Wirtschaftswissenschaften. Insbesondere ist es Gegenstand des Supply-Chain-Managements (Lieferkettenmanagement). Abzugrenzen ist die Lieferkette von der Wertkette und der Transportkette.

In einer weit verbreiteten Definition bezeichnet Christopher (1998) eine Lieferkette als das Netzwerk von Organisationen, die über vor- und nachgelagerte Verbindungen an den verschiedenen Prozessen und Tätigkeiten der Wertschöpfung in Form von Produkten und Dienstleistungen für den Endkunden beteiligt sind. Die Lieferkette berücksichtigt somit ein Unternehmen, dessen Zulieferer, die Zulieferer der Zulieferer usw. sowie dessen Kunden, die Kunden der Kunden usw. Zu beachten ist dabei insbesondere, dass auch der Endkunde Teil der Lieferkette ist. In einer engen Auffassung wird die Lieferkette als Triade aus direkten Lieferanten, eigenem Unternehmen und direkten Kunden verstanden; dieser Auffassung fehlt die ganzheitliche, integrierende Betrachtung von den Rohstofflieferanten bis zu den Endkunden.

Die Begriffe „Supply Chain“ und „Lieferkette“ sind irreführend: Einerseits deckt eine "Liefer"kette nicht nur die "Lieferanten"seite "(supply)" ab, sondern auch die Kundenseite und führt somit vom Rohstofflieferanten bis zum Endkunden; andererseits handelt es sich bei ihr nicht um eine „Kette“ ("chain"), sondern vielmehr um ein „Netzwerk“. Es wird daher auch vorgeschlagen statt Lieferkette den treffenderen Begriff Liefernetz "(supply network)" zu verwenden. Im Deutschen ist auch der Begriff Zuliefernetzwerk (Zulieferpyramide) gebräuchlich, wobei hierbei häufig nur die vorgelagerten Stufen der Wertschöpfung gemeint sind, insbesondere jedoch der Endkunde nicht als dessen Bestandteil angesehen wird.

In einer anderen Definition wird unterschieden zwischen Lieferkette und Liefernetz. Die Lieferkette umfasst demnach Lieferanten, Lieferanten von Lieferanten, die Firma, ihre Kunden und die Kunden der Kunden. Ein Liefernetz berücksichtigt, dass einer der Lieferanten der Lieferanten zugleich ein Lieferant für einen der Kunden oder sogar für den Endkunden ist.

Bei komplexen Produkten mit einem internationalen weltweiten Produktionsverbund – wie in der Automobil- und der Luftfahrtindustrie – muss der weltweite Beschaffungs-, Produktions- und Vertriebsverbund frühzeitig und integrativ geplant, gesteuert und überwacht werden. Die Produktions-, Transport- und Lagerstrecken werden als direkt aufeinanderfolgende Intervalle beschrieben, wodurch die gesamte Lieferkette bis zum Kunden einheitlich abgebildet wird. Der Beginn jedes Intervalls wird jeweils durch einen Zählpunkt (Logistik) eindeutig abgegrenzt. Alternative Produktions- oder Transportstrecken werden als parallele Intervalle abgebildet. An den Zählpunkten wird der gesamte Materialfluss geplant, gesteuert und permanent überwacht. Durch die Ermittlung der jeweiligen Durchlaufzeit für jedes Intervall kann sukzessiv die jeweilige Gesamtdurchlaufzeit des benötigten Materials, der Teile, Baugruppen und Erzeugnisse in der Lieferkette ermittelt werden.

Mit der Zunahme internationaler Kooperationen und vertikaler Integration sowie der Fokussierung auf Kernkompetenzen haben Unternehmen akzeptiert, dass sie Elemente vernetzter Lieferketten sind. Scharfer Wettbewerb in globalen Märkten, kurze Lebensdauern bei der Produkteinführung und hohe Kundenerwartungen haben Lieferketten ins Zentrum betriebswirtschaftlicher Entscheidungen gerückt. Die Feststellung im modernen Management, dass Lieferketten im Wettbewerb stehen und nicht individuelle Geschäftseinheiten hat das Supply-Chain-Managements (SCM; Lieferkettenmanagement) hervorgebracht. Durch Emergenz stellen sich bei Betrachtung des Systems „Lieferkette“ im Supply-Chain-Management ganz neuartige Fragestellungen, die im System „Unternehmen“ in der Betriebswirtschaftslehre so nicht auftraten, Insbesondere ist das SCM geeignet, den in Lieferketten auftretenden Peitscheneffekt (bullwhip effect) zu verringern und mithilfe der Aufschubstrategie ("postponement") Fertigungs- und Logistikentscheidungen näher an den Endkunden zu verlagern. Aufgrund ihrer besonderen Systemeigenschaften wird die Lieferkette von einigen Autoren auch als komplexes adaptives System aufgefasst, was Auswirkungen auf ihr Management hat.

In Lieferketten werden häufig Waren- (und Dienstleistungs-), Informations- und Finanzflüsse unterschieden: Waren und Dienstleistungen fließen in der Lieferkette vom Hersteller zum Verbraucher. Geld fließt in der Lieferkette in der Gegenrichtung: vom Verbraucher zum Hersteller. Die zu dieser Kette gehörenden Informationen fließen zuerst vom Verbraucher zum Hersteller (z. B. Bestellung eines Buches im Geschäft. Dieses bestellt es dann beim Verlag, der wiederum für die Produktion seine Mittel bestellt usw.). Die warenbegleitenden Informationen fließen entweder mit ihnen (z. B. Lieferschein) oder gehen diesen voraus (z. B. Lieferavis).

Wird die Lieferkette vom Rohstoff bis zum Verbraucher verfolgt, so lässt sich erkennen, in welchem Maße und wofür der Rohstoff gebraucht wird. Außerdem wird deutlich, wie weitreichende Konsequenzen Preisveränderungen des Rohstoffs haben können. Wird die Lieferkette vom Verbraucher zum Rohstoff zurückverfolgt, so lässt sich erkennen, was alles für die Erzeugung eines Endprodukts verbraucht wurde. Damit lassen sich auch Auswirkungen von Nachfrageänderungen abschätzen.

Vorfälle wie der Gebäudeeinsturz in Sabhar (2013), der mehr als 1000 Menschenleben gefordert hat, haben die Rolle der Lieferkette als Gestaltungsobjekt von Corporate Social Responsibility (CSR) stärker in den Vordergrund gerückt. Ansätze des Supply-Chain-Managements werden infolgedessen vermehrt zur Stärkung von CSR eingesetzt. Wieland und Handfield (2013) schlagen drei Maßnahmenkomplexe vor, um CSR entlang der Lieferkette sicherzustellen:

Man betrachte einen Rohstoff, zum Beispiel Erz (s. a. Stahlerzeugung):




</doc>
