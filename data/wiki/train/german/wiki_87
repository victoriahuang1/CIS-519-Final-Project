<doc id="12886" url="https://de.wikipedia.org/wiki?curid=12886" title="Strukturelle Gewalt">
Strukturelle Gewalt

Strukturelle Gewalt bezeichnet die Vorstellung, dass Gewaltförmigkeit auch staatlichen bzw. gesellschaftlichen Strukturen inhärent sei - in Ergänzung zum klassischen Gewaltbegriff, der einen unmittelbaren personalen Akteur annimmt. In besonderer Weise formulierte der norwegischen Friedensforscher Johan Galtung ab 1971 eine solche Theorie. 

Johan Galtung ergänzte den traditionellen Begriff der Gewalt, der vorsätzlich destruktives Handeln eines Täters oder einer Tätergruppe bezeichnet, um die strukturelle Dimension:

Diesem erweiterten Gewaltbegriff zufolge ist das Zurückbleiben der aktuellen Selbstverwirklichung hinter der in einer Gesellschaft möglichen Selbstverwirklichung eine Form von Gewalt. Wenn Menschen im Mittelalter an Tuberkulose stürben, wäre dies nicht unbedingt Gewalt, weil die Medizin noch nicht weit genug entwickelt war. Wenn heute Menschen an Tuberkulose sterben, könne dies hingegen auf strukturelle Gewalt zurückgeführt werden. 

Unter "Strukturelle Gewalt" fallen alle Formen der Diskriminierung, die ungleiche Verteilung von Einkommen, Bildungschancen und Lebenserwartungen, sowie das Wohlstandsgefälle zwischen der ersten und der Dritten Welt. Auch eingeschränkte Lebenschancen auf Grund von Umweltverschmutzung oder die Behinderung emanzipatorischer Bestrebungen werden hierunter subsumiert. Gewalt kann in dieser umfassenden Definition, die allein die Effekte benennt, nicht mehr konkreten, personalen Akteuren zugerechnet werden. Sie basiere nurmehr auf Strukturen einer bestehenden Gesellschaftsformation, insbesondere auf gesellschaftlichen Strukturen wie Werten, Normen, Institutionen oder Diskursen sowie Macht­verhältnissen.

Diese Begriffsbestimmung verzichtet auf die Voraussetzung, dass, um von Gewalt sprechen zu können, eine Person oder Gruppe subjektiv Gewalt empfinden muss. Strukturelle Gewalt werde von den Opfern oft nicht einmal wahrgenommen, da die eingeschränkten Lebensnormen bereits internalisiert seien.

Galtung stellte sein Verständnis von „struktureller Gewalt“ erstmals 1971 in einem längeren Aufsatz vor. 1975 erschien ein Buch zum Thema. 1996 fügte er die strukturelle Gewalt als neben personaler und kultureller Gewalt als einen der drei Pole in sein Konzept eines interdependenten Gewaltdreiecks ein.

Vor und nach Galtung gab es weitere Autoren, die eine Gewaltförmigkeit staatlicher bzw. gesellschaftlicher Strukturen beschrieben.
Bertolt Brecht interpretierte den im 5. Jahrhundert vor Christus lebenden chinesischen Philosophen Me-Ti:

Der Gedanke, dass Gewalt auch in den gesellschaftlichen Verhältnissen selbst begründet sein kann, findet sich auch bei Karl Marx. So schreiben die Postmarxisten Michael Hardt und Antonio Negri:

Ähnlich die Kritische Theorie, vor allem Herbert Marcuse und sein 1964 erschienenes Werk "Der eindimensionale Mensch". Hier werden die pluralistischen Demokratien der westlichen Welt als repressive, ja „totalitäre“ Gesellschaften beschrieben, die sich auf Indoktrination, Manipulation, Ausbeutung und Krieg gründeten. Kritik bleibe fruchtlos, da sie in das „eindimensionale“ System von Politik, Wirtschaft und Kulturindustrie integriert würde. 

Der französische Philosoph und Historiker Michel Foucault, dessen Anfang der 1970er Jahre entstandene Diskurs-Theorie strukturalistisch und apersonal geprägt ist, entwickelte in seinem Werk Überwachen und Strafen (1975) ebenfalls sozialkritische Gedanken, die auf strukturelle Gewalt abzielen. Auf Foucaults Theorie der Gouvernementalität beziehen sich heute zahlreiche Philosophen, so auch Giorgio Agamben.

Schon vor Galtung wurde die Vorstellung von den gesellschaftlichen Strukturen inhärenter Gewalt zur Legitimation von Widerstand und Gegengewalt herangezogen.

Herbert Marcuse betonte, dass es für unterdrückte Minderheiten ein Naturrecht auf Widerstand gebe: Wenn diese Minderheiten Gewalt anwendeten, so begönnen sie keine neue Kette von Gewalttaten, sondern zerbrächen die etablierte. Dabei ist er der Ansicht, dass eine Überwindung der entsprechenden Zustände im Wege der Reform nicht möglich sei. Wenn die strukturelle Gewalt den kritisierten Gesellschaftsformen wesenshaft inhärent ist, so bedarf es eines revolutionären Prozesses, um sie aufzubrechen.

Der Vordenker der Studentenbewegung Rudi Dutschke erklärte nach der Erschießung von Benno Ohnesorg bei der Demonstration am 2. Juni 1967 in West-Berlin:

Die RAF rechtfertigte revolutionäre Gewalttaten mit der vorgängigen „Gewalt des Systems“. Ulrike Meinhof schrieb im Gründungsmanifest der RAF, „Das Konzept Stadtguerilla“ 1971:

Albert Fuchs, Mitglied des Instituts für Friedensarbeit und gewaltfreie Konfliktaustragung, schrieb:

Galtungs Ansatz wurde in der wissenschaftlichen Literatur vielfach rezipiert. In den 1970er und 1980er Jahren wurde er verschiedentlich herangezogen, etwa zur Analyse des Imperialismus und des Nord-Süd-Konflikts. Viele Richtungen der Soziologie und Politikwissenschaft zögerten allerdings, den Begriff zu übernehmen, einerseits wegen des Verdachts seiner ideologischen Verwendung, andererseits fürchtete man, dass er von dem eingeführten und wohldefinierten Begriff „Herrschaft“ fast ununterscheidbar sei.

Der Staatsrechtler Josef Isensee sah in der „Lehre von struktureller Gewalt, die von der neomarxistischen Richtung der sog. Friedensforschung vertreten wird“, ein „Legitimationsschema zum Bürgerkrieg gegen das ‚kapitalistische‘ System“:

Gustav Däniker, ehemaliger Stellvertretender Chef des Generalstabs der Schweizer Armee, schrieb in einer Analyse des Terrorismus im Jahrbuch für internationale Sicherheitspolitik:

Auch heute werden laut dem Soziologen Helmut Willems linksextremistisch motivierte Gewalttaten mit Verweis auf eine „strukturelle Gewalt des Systems“ gerechtfertigt.

Der Politikwissenschaftler Dieter Nohlen kritisiert, dass der Begriff schwammig bleibe, da Galtung sich dagegen gewehrt habe, ihn präzise zu explizieren. Seine Inhalte blieben daher fließend. Mehr als dass strukturelle Gewalt schlecht sei, bewusst gemacht und so überwunden werden müsse, sage der Begriff letztlich nicht aus.




</doc>
<doc id="12890" url="https://de.wikipedia.org/wiki?curid=12890" title="Bundesverband zur Förderung der Schwimmausbildung">
Bundesverband zur Förderung der Schwimmausbildung

Der Bundesverband zur Förderung der Schwimmausbildung (BFS) ist ein Zusammenschluss von Verbänden, die in der Schwimmausbildung aktiv sind. Hervorgegangen ist der BFS aus den so genannten "befreundeten Verbänden", die seit 1977/78 zusammen mit der Kultusministerkonferenz die Prüfungsbedingungen (Deutsche Prüfungsordnung) für die Schwimmabzeichen ("Seepferdchen", "Deutsches Jugendschwimmabzeichen" und "Deutsches Schwimmabzeichen") festlegen. Die Geschäftsstelle des BFS ist in der Bundesgeschäftsstelle des DSV in Kassel beheimatet und ihr Vorstandsvorsitzender ist der ehemalige Leiter Ausbildung der DLRG, Helmut Stöhr.

Gegründet wurde der rechtsfähige Verein Kraft staatlicher Verleihung gemäß § 22 BGB am 24. August 1998 durch die Bezirksregierung Hannover mit dem Zweck:





</doc>
<doc id="12892" url="https://de.wikipedia.org/wiki?curid=12892" title="Hestia">
Hestia

Hestia (, ionisch „Herd“) ist in der griechischen Mythologie die Göttin des Familien- und Staatsherdes, des Herd- und Opferfeuers und eine der zwölf olympischen Götter. 

Die bei den Römern der Hestia gleichgesetzte Göttin ist Vesta. 

Sie war die älteste Tochter des Kronos und der Rhea und Schwester des Zeus. Sie wurde von ihrem Vater verschlungen, aber durch die List ihrer Mutter gerettet.

Sie war eine jungfräuliche Göttin und wie Athene und Artemis nicht der Macht der Aphrodite unterworfen. Als Poseidon und Apollon um sie warben, schwor sie beim Haupt des Zeus, ewig Jungfrau zu bleiben. Zeus gewährte ihr auf diesen Wunsch hin immerwährende Jungfräulichkeit und wies ihr einen ehrenvollen Platz als Hüterin und Opferempfängerin „mitten im Haus“ an.

Ovid erzählt, dass Rhea die Götter zu einem Fest geladen hatte. Nachdem alle reichlich Wein genossen hatten und die meisten in den Schlaf gesunken waren, versuchte der lüsterne Gott Priapos die schlafende Hestia zu vergewaltigen. Das Geschrei eines Esels bewirkte, dass Hestia aufwachte, alles lief hinzu und Priapos musste durch die aufgebrachte Menge fliehen (sein Kult auf Lampsakos wird mit einem Eselsopfer begangen).

Hestia bewahrte den Frieden nicht nur am häuslichen Herd: Als Dionysos zum Gott ernannt wurde, gab Hestia ihren olympischen Thron preis um einen Krieg zu verhindern.

Über Kultstätten und Tempel der Hestia ist relativ wenig überliefert. Die Ursache mag sein, dass der Herd eines jeden Hauses und der Herd des Prytaneions, also sowohl im privaten als auch im öffentlichen Bereich das jeweilige sakrale Zentrum der Gemeinschaft, der Hestia geweiht waren. Ihr gebührte das erste Opfer. Pausanias vermerkt, dass ihr in Olympia noch vor Zeus geopfert wurde. Platon leitet ihren Namen etwas gewagt von (altattisch : „wahrhaftes Sein“, „Wirklichkeit“) her und begründet damit, dass ihr als Erste geopfert wird, denn die Essenz des Seins stehe natürlich an erster Stelle. Genau genommen gebührte ihr das erste und das letzte Opfer, was auch damit in Beziehung gesetzt wurde, dass sie die „Erste und die Letzte“ war, als erstes der Kinder des Kronos war sie auch als Erste von ihm verschlungen worden, von ihm wieder ausgespien wurde sie aber als Letztes.

Der häusliche Herd, ursprünglich in der Mitte des Hauptraums, war der Ort des häuslichen Kultes, hier wurde bei der Amphidromia das Neugeborene in die Hausgemeinschaft aufgenommen, hier konnte ein Schutzflehender Asyl finden und man konnte beim Herd schwören. Sie war nicht nur die Schutzherrin aller Häuslichkeit, nach Diodor soll sie auch den Hausbau erfunden haben.

Die Göttin des privaten Herdfeuers war auch Göttin des Herdfeuers der Gemeinschaft, der "koine hestia" als Symbol der Gemeinschaft der Polis. Deshalb war in den griechischen Stadtstaaten das Prytaneion der Hestia geweiht, und sie hatte dort einen Altar, auf dem ihr zu Ehren ein ewiges Feuer unterhalten wurde. Von diesem Altar nahmen die in die Ferne ziehenden Kolonisten Feuer mit für den Herd ihrer künftigen Niederlassung. Bei Gründung einer neuen Stadt sollte (jedenfalls nach der Idealvorstellung von Platon) als erstes der Hestia, Zeus und Athene (in dieser Reihenfolge) ein heiliger Bezirk auf der Akropolis zugewiesen werden. 

Ausdrücklich von Pausanias in der "Beschreibung Griechenlands" erwähnte Kultstätten der Hestia sind:

Außerdem wird der Kult der Hestia in Larissa von Bakchylides und auf Tenedos von Pindar erwähnt.

Im Kult erscheint sie häufig zusammen mit Hera, aber auch mit Hermes, so in Oropos und in Olympia. Der Homerische Hymnos XXIX ist beiden Göttern gleichermaßen gewidmet. Sie werden angerufen und eingeladen im Haus zu weilen und es zu segnen. Ohne das Weinopfer für Hestia zu Beginn und Ende des Mahles kann keine gesittete Gastlichkeit sein.

Wie oben erwähnt, war der Kult der Hestia sowohl im privaten als auch im öffentlichen Bereich an zentraler Stelle repräsentiert, was immer wieder als Begründung dafür herangezogen wird, dass es kaum ausgewiesene Tempel oder Heiligtümer der Hestia gibt: Wer überall den vornehmsten Ehrenplatz bereits innehat, bedarf keiner weiteren kultischen Ehrung durch Tempel und Statuen. Dennoch hat das sehr weitgehende Fehlen von Inschriften, die z. B. eine Priesterschaft der Hestia bezeugen, Verwunderung erregt. 

In Athen beispielsweise gibt es keine einzige gesicherte Inschrift, die einen Kult der Hestia belegen würde. Eine sich auf „Hestia, Livia und Julia“ beziehende Inschrift gilt wohl nicht der griechischen Hestia, sondern dem in der Kaiserzeit in Athen eingeführten Kult der römischen Vesta. Priester der Hestia sind nur aus Delos, Stratonikeia in Karien und Chalkis bekannt. Schließlich sind in Kameiros auf Rhodos noch Personen bezeugt, die "damiurgoi" der Hestia genannt wurden, und in Sparta ist im 2. Jahrhundert mehrfach der Titel "hestia poleos" („Hestia der Stadt“) als weiblicher Ehrentitel belegt. Ob damit ein Amt oder eine öffentliche Funktion verbunden war, ist unklar aber eher unwahrscheinlich. Insgesamt ist das für eine der ranghöchsten unter den olympischen Göttern bemerkenswert wenig.

Demgegenüber ist der öffentliche Kult der "Hestia Prytaneia" im Prytaneion, dem Sitz der Stadtregierung, und der "Hestia Boulaia" im Buleuterion, dem Sitz des Stadtrates, gut und vielfach bezeugt, woraus geschlossen werden könnte, dass die Kultobliegenheiten der Hestia zu besorgen, Teil eines öffentlichen Amtes war, wofür es auch entsprechende Belege bei Dionysios von Halikarnassos und Aristoteles gibt.

Dem reinen und keuschen Wesen der Göttin entsprechend, pflegte man sie sitzend oder ruhig dastehend mit ernstem Gesichtsausdruck und stets völlig bekleidet darzustellen. Im ganzen gab es im Altertum nur wenige Statuen der Hestia, die berühmteste war die des Skopas. In erhaltenen Statuen ist Hestia noch nicht sicher nachgewiesen; man bezieht auf sie gewöhnlich die sogenannte „Hestia Giustiniani“ im Museo Torlonia in Rom, eine weibliche Gewandstatue strengen Stils, etwa aus der Zeit der Giebelfiguren des Zeustempels in Olympia und diesen formenverwandt. Auf römischen Münzen erscheint sie mit dem Palladion und Simpulum.

Da Hestia in Darstellungen nicht durch ein für sie spezifisches Attribut (wie etwa der Dreizack des Poseidon oder der Hammer des Hephaistos) ausgewiesen wird, ist eine Zuordnung meist nur dann sicher, wenn die Dargestellte (etwa in der Vasenmalerei) durch einen Schriftzug mit ihrem Namen eindeutig identifiziert wird. Die Zuordnung wird außerdem dadurch schwierig, dass Hestia offenbar auch geflügelt dargestellt wurde, was eine Unterscheidung zwischen Hestia und der geflügelten Iris erschwert.

In der Kosmologie der Pythagoräer (z. B. bei Philolaos) ist die Hestia das (unsichtbare) Zentralfeuer, um das in einem Heptachord die Planeten kreisen (zu denen auch die Sonne zählt), die durch diese Kreisbewegung die Sphärenharmonie erzeugen. Nun ist natürlich nicht ohne weiteres gesagt, dass bei diesen kosmologischen Spekulationen auch die Göttin assoziiert wurde und nicht nur das Abstraktum Feuer. Dass die Verbindung tatsächlich hergestellt wurde, belegen zwei Epigramme der Claudia Trophime, 92 n. Chr. Prytanis von Ephesos. Das erste lautet:

Schon erwähnt wurde die von Platon stammende Herleitung des Namens der Hestia von und die damit begründete Gleichsetzung Hestias mit der Essenz des Seins, der wahren Wirklichkeit. Die gleiche Entsprechung findet sich später bei Plotin, wo die Gleichsetzung zu Einheit (Monade) = Sein = Hestia ausgebaut wird.

Die von den Pythagoräern ausgegangene Spekulation treibt Blüten bis in den deutschen Idealismus. Bei Schelling versucht sie sich zurückzuwinden zur naturwissenschaftlichen Wurzel:

Die Göttin Hestia ist eine der Hauptfiguren in der Roman-, Manga- und Anime-Serie "Dungeon ni Deai o Motomeru no wa Machigatteiru Darō ka". Sie wird dort als zierliche, junge Frau dargestellt und ist eine der Götter, die aus Neugier in die Menschenwelt herabgestiegen sind.




</doc>
<doc id="12901" url="https://de.wikipedia.org/wiki?curid=12901" title="Versicherung">
Versicherung

Versicherung steht für:

Siehe auch:


</doc>
<doc id="12902" url="https://de.wikipedia.org/wiki?curid=12902" title="Kapelle">
Kapelle

Kapelle (von lat. capa, ,Mantel‘, urpr. Aufbewahrungsort des Mantels des Hl. Martin) steht für:

Kapelle ist Ortsname von
Kapelle ist Familienname von
"Siehe auch:"



</doc>
<doc id="12903" url="https://de.wikipedia.org/wiki?curid=12903" title="Turtur">
Turtur

Turtur bezeichnet:


Die literarische Figur von Michael Ende wird Tur Tur geschrieben, siehe "Scheinriese" 
Turtur ist der Familienname folgender Personen:



</doc>
<doc id="12907" url="https://de.wikipedia.org/wiki?curid=12907" title="Online">
Online

Online (von englisch "on" ‚auf‘ und "line" ‚Leitung‘, deutsch etwa ‚im Netz‘) bezeichnet meist eine aktive Verbindung mit einem Kommunikationsnetzwerk, insbesondere dem Internet. Ist eine Verbindung inaktiv, so bezeichnet man dies als "offline", Geräte ganz ohne Netzanbindung auch mit "stand-alone".

Gelegentlich wird der Begriff „Online-Verarbeitung“ auch als Synonym für "Dialogverarbeitung" bzw. als Gegenteil von "Stapelverarbeitung" benutzt. Beides ist jedoch nur bedingt korrekt: Denn einerseits kann z. B. auch ein automatisches Übertragen von Daten (-Stapeln) mit Speicherung zur späteren Weiterverarbeitung „online“ erfolgen, auch das Drucken an entfernten Druckern wäre Online-Stapelverarbeitung; andererseits werden klassische Vertreter der Dialogverarbeitung, z. B. Computerspiele und Tabellenkalkulation auch an „stand-alone“-Rechnern, also nicht „on line“ betrieben.


Online angebotene Dienste stellen, sehr oft kostenfrei, Informationen über das Internet zur Verfügung oder erlauben deren Bearbeitung.

In verschiedenen gesellschaftlichen Bereichen gibt es Übertragungen bisheriger „Offline-Tätigkeiten“ in das Internet, unter anderem:


</doc>
<doc id="12909" url="https://de.wikipedia.org/wiki?curid=12909" title="Else von Hollander-Lossow">
Else von Hollander-Lossow

Else von Hollander-Lossow (* 23. März 1884 in Stralsund; † unbekannt) war eine deutsche Übersetzerin und Erzählerin.

Else von Hollander-Lossow, geb. Glawe, heiratete 1914 in Quedlinburg Walter von Hollander. Sie kam frühzeitig nach Berlin, wo sie als Journalistin und besonders als Übersetzerin tätig war. Zudem schrieb sie Romane. 1924 heiratete sie in zweiter Ehe den Schriftsteller und Theaterspielleiter Rudolf von Lossow. 

Bekannt sind Übersetzungen aus dem Schwedischen (zum Beispiel von Ernst Didring und Astrid Lindgren), Norwegischen, Dänischen, Englischen, Niederländischen ("Tschip" von Willem Elsschot) und Französischen (beispielsweise Werke von Voltaire und Honoré de Balzac).





</doc>
<doc id="12911" url="https://de.wikipedia.org/wiki?curid=12911" title="Wilhelm Furtwängler">
Wilhelm Furtwängler

Gustav Heinrich Ernst Martin Wilhelm Furtwängler (* 25. Januar 1886 in Schöneberg; † 30. November 1954 in Ebersteinburg bei Baden-Baden; beigesetzt auf dem Bergfriedhof in Heidelberg) war ein deutscher Dirigent und Komponist. Er gilt als einer der bedeutendsten Dirigenten des 20. Jahrhunderts.

Wilhelm Furtwängler wurde 1886 als Sohn des Professors für Klassische Archäologie Adolf Furtwängler und dessen Frau Adelheid (geborene Wendt) am Nollendorfplatz in Berlin geboren.

Er verbrachte seine Jugend in München, wo sein Vater an der Universität unterrichtete, und besuchte das humanistische Gymnasium. Frühzeitig begeisterte er sich für Musik. Ab 1899 erhielt er Privatunterricht in Tonsatz, Komposition und Klavier. Seine Ausbildung zum Pianisten übernahmen Joseph Rheinberger, Max von Schillings und Conrad Ansorge.

1900 führte, wie Karl Alexander von Müller berichtet, der Münchner Orchesterverein ein Klavierquartett und eine Ouvertüre des jungen Furtwängler auf, von denen er letztere selbst dirigierte. Im Jahr darauf wurde im Haus des Bildhauers Adolf von Hildebrand ein Streichsextett aus seiner Feder gespielt, das „wahrhaftig Schuberts würdig“ gewesen sein soll.

Seine ersten Engagements führten ihn 1906 als 2. Repetitor nach Berlin, 1907 über Breslau als Chorleiter nach Zürich und anschließend wieder nach München. 1910 engagierte ihn Hans Pfitzner als 3. Kapellmeister nach Straßburg. 1911 ging er als Nachfolger von Hermann Abendroth nach Lübeck und dirigierte dort das Orchester des Vereins der Musikfreunde. Als Träger des der Oper zur Verfügung gestellten Konzertorchesters setzte der Verein bereits durch, dass der Direktor des Theaters Hermann Abendroth auch als dessen Dirigenten zu beschäftigen hatte. Die ständige lübeckische Kritik, Intrigen, vielerlei Hickhack und das defizitäre Theater griffen die Gesundheit derart an, dass der Direktor nach drei Jahren zurücktrat und kurz darauf verstarb. Als Stanislaus Fuchs als sein Nachfolger ins Amt berufen wurde, behielt man diese Praktik bei. Furtwängler, der nahezu zeitgleich Abendroths Nachfolger im Verein wurde, war als Dirigent der Oper des ohne ihn schon defizitären Theaters zu beschäftigen.

Bereits 1915 verließ Furtwängler die Stadt, in der er seine erste Chefposition erhielt, und wurde Operndirektor in Mannheim, von 1919 bis 1921 fungierte er als Chefdirigent des Wiener Tonkünstler-Orchesters, 1920 übernahm er als Nachfolger von Richard Strauss die Konzerte der Berliner Staatsoper. Von 1921 bis 1927 hatte er (gemeinsam mit Leopold Reichwein) die Stelle des Konzertdirektors der Gesellschaft der Musikfreunde in Wien inne und dirigierte in dieser Funktion das 1921 neu konstituierte Wiener Sinfonieorchester (seit 1933: Wiener Symphoniker). Ab 1922 arbeitete er als Chefdirigent des Berliner Philharmonischen Orchesters und dirigierte außerdem bis 1928 das Gewandhausorchester in Leipzig als Gewandhauskapellmeister. Für das Jahr 1931 hatte er die Gesamtleitung der Richard-Wagner-Festspiele in Bayreuth.

Die Nationalsozialisten hofierten Furtwängler wegen seiner internationalen Reputation als kulturelles Aushängeschild. Für 1933 ist nachgewiesen, dass er sich für einige Juden (wie seinen Konzertmeister Szymon Goldberg) einsetzte. Der Ministerialdirektor im Kultusministerium, Georg Gerullis, hielt am 20. Juli 1933 in einem Dienstschreiben an Reichskulturverwalter Hans Hinkel diesbezüglich verärgert fest: "„Können Sie mir einen Juden nennen, für den Furtwängler nicht eintritt?“"

Im Vorfeld eines gemeinsamen Konzerts mit den Berliner Philharmonikern im April 1933 in Mannheim kam es zu Protesten gegen die Mitwirkung jüdischer Musiker. Furtwängler sagte das Konzert daraufhin kurzerhand ab und kündigte an, in dieser Stadt nicht mehr zu gastieren, solange „bei Ihnen solche Gesinnung herrscht“. In einem offenen Brief an Joseph Goebbels kritisierte Furtwängler am 11. April 1933 die Diskriminierung jüdischer Musiker: „Nur einen Trennungsstrich erkenne ich letzten Endes an: den zwischen guter und schlechter Kunst.“ Wohl habe der Kampf Berechtigung gegen jene, die „wurzellos und destruktiv, durch Kitsch und trockene Könnerschaft“ zu wirken suchten. Wenn sich dieser Kampf jedoch gegen wirkliche Künstler richte, so sei das nicht im Interesse des Kulturlebens. Es müsse klar ausgesprochen werden, dass Männer wie Walter, Klemperer und Reinhardt auch in Zukunft mit ihrer Kunst in Deutschland zu Wort kommen müssten. Der Reichsminister für Volksaufklärung und Propaganda antwortete umgehend: „Lediglich eine Kunst, die aus dem vollen Volkstum selbst schöpft, kann am Ende gut sein und dem Volke, für das sie geschaffen wird, etwas bedeuten […] Gut muß die Kunst sein; darüber hinaus aber auch verantwortungsbewußt, gekonnt, volksnahe und kämpferisch.“ Der Briefwechsel zwischen Furtwängler und Goebbels erschien im Berliner Tageblatt am 11. und 12. April 1933; liberal und sozialdemokratisch geprägte Blätter des Auslands (Neue Freie Presse, Prager Tagblatt) druckten den Protest auf der Titelseite. Letztendlich konnte Furtwängler erreichen, dass der „Arierparagraph“ auf die Berliner Philharmoniker zunächst nicht angewandt wurde. Er lud auch jüdische Solisten ein (die dann allerdings absagten).

Im Juni 1933 wurde er von Göring zum Ersten Kapellmeister, im Januar 1934 zum Direktor der Berliner Staatsoper ernannt. Nebenbei gastierte er am Deutschen Opernhaus Berlin-Charlottenburg. Im Juli 1933 ernannte Göring ihn zum Preußischen Staatsrat. Außerdem kam er den neuen Machthabern im Herbst 1933 insoweit entgegen, als er sich dazu bereitfand, sich zum Vizepräsidenten der Reichsmusikkammer ernennen zu lassen, die Goebbels’ Reichsministerium für Volksaufklärung und Propaganda unterstand. Furtwängler war, laut seinen Einlassungen nach 1945, dem NS-Regime gegenüber jedoch ablehnend eingestellt. Er habe sich von dieser Position erhofft, im Sinne einer taktischen Zusammenarbeit auf das kulturpolitische Geschehen Einfluss nehmen und damit das Schlimmste verhindern, „die Kunst von allem ‚Niederen‘ freihalten“ zu können. In Wirklichkeit bewirkte er zusammen mit Richard Strauss, dem Präsidenten der Reichsmusikkammer, den Ausschluss der meisten Juden und sogenannter „Kulturbolschewisten“ aus der Kammer, was einem Berufs- und Aufführungsverbot gleichkam.

Gleichwohl führte er im Februar 1934 drei Stücke aus dem „Sommernachtstraum“ des bereits geächteten Mendelssohn auf und ehrte diesen somit demonstrativ zu dessen 125. Geburtstag. Am 11. und 12. März desselben Jahres dirigierte er die Uraufführung der Sinfonie „Mathis der Maler“ des später als „entartet“ verpönten Komponisten Paul Hindemith. Obwohl diese Sinfonie ein überwältigender Publikumserfolg war und weitere Aufführungen und Rundfunksendungen erlebte, genehmigte Hitler im Herbst nicht die geplante Aufführung der gleichnamigen Oper. Furtwängler, der durch seine Unterschrift unter den Aufruf der Kulturschaffenden vom 19. August 1934 öffentlich bekundet hatte, dass er "zu des Führers Gefolgschaft" gehörte, drohte daraufhin mit Rücktritt und setzte sich in einem aufsehenerregenden Zeitungsbeitrag für Hindemith ein. Da das erhoffte Einlenken der NS-Führung ausblieb und sie ihn vor die Alternative Rücktritt oder Entlassung stellte, sah er sich am 4. Dezember 1934 genötigt, seine Ämter als Staatsoperndirektor, Leiter des Berliner Philharmonischen Orchesters und Vizepräsident der Reichsmusikkammer aufzugeben.
Am 28. Februar 1935 ließ er sich allerdings von Goebbels empfangen und erklärte, es habe ihm völlig ferngelegen, mit dem Hindemith-Artikel „in die Leitung der Reichskunstpolitik einzugreifen“; diese werde „auch nach seiner Auffassung selbstverständlich allein vom Führer und Reichskanzler und dem von ihm beauftragten Fachminister bestimmt“. So konnte er – nach weiteren Gesprächen mit Rosenberg und Hitler – seine öffentliche Tätigkeit im April 1935 wiederaufnehmen, allerdings nur beim Berliner Philharmonischen Orchester, weil für die Staatsoper bereits Clemens Krauss vorgesehen war. Er dirigierte 1935 und 1938 am Vorabend der Reichsparteitage in Nürnberg, war 1936, 1937 und 1943 Hauptdirigent der propagandistisch genutzten Bayreuther Festspiele und repräsentierte Deutschland 1937 bei der Pariser Weltausstellung. Er ließ sich in Goebbels’ Reichskultursenat berufen und unterstützte Wahlaufrufe zur Reichstagswahl 1936 und zur Volksabstimmung über den „Anschluss“ Österreichs. Im Juni 1939 wurde er mit der Leitung der Wiener Philharmoniker betraut und im Dezember desselben Jahres von Gauleiter Josef Bürckel zum Bevollmächtigten für das gesamte Musikwesen der Stadt Wien ernannt. Neben Konzerten zu Hitlers Geburtstag und Weihnachtsempfang, für Goebbels’ Propagandaministerium und für die Hitlerjugend dirigierte er in Prag im November 1940 ein Konzert zur Neueröffnung des „Deutschen Theaters“ und erneut im März 1944 zum fünften Jahrestag des Protektorats Böhmen und Mähren.

1936 bot sich Furtwängler die Gelegenheit, Deutschland zu verlassen und als Nachfolger Toscaninis ohne anderweitiges festes Engagement die New Yorker Philharmoniker zu übernehmen. Doch er zog es vor, mit Göring einen Vertrag abzuschließen, wonach er in der Spielzeit 1936/1937 mindestens zehn Gastdirigate an der Berliner Staatsoper geben sollte. Das führte zu Missverständnissen und zur Absage an New York. Seit 1944 wohnte er mit Billigung des NS-Regimes überwiegend in Luzern (Schweiz), drei Monate vor der Besetzung Berlins durch sowjetische Truppen floh er endgültig dorthin. Von der Teilnahme am Kriegseinsatz wurde er verschont, da er nicht nur auf der Gottbegnadeten-Liste, sondern auch auf der Sonderliste der drei wichtigsten Musiker der Gottbegnadeten-Liste stand.

Furtwänglers Verhalten während der Zeit des Nationalsozialismus wird unterschiedlich beurteilt. Während Fred K. Prieberg und Herbert Haffner ihn als rein künstlerisch Interessierten eher zu entlasten suchen, stellt ihn unter anderen Eberhard Straub als ausgeprägten Opportunisten dar.

1945 erhielt Furtwängler von den amerikanischen Besatzungsbehörden zunächst Dirigierverbot. Verheerender noch war für ihn seine internationale Ächtung und seine Brandmarkung als Sündenbock: Man titulierte ihn als „Hitlers gehätschelten Maestro“, „musikalischen Handlanger der nazistischen Blutjustiz“ und „eine der verhängnisvollsten Figuren des Nazireiches“.

Die emigrierten Künstler hingegen verübelten Furtwängler vor allem seine Prominenz im Dritten Reich. Dabei wurde vergessen, dass er bereits zu Zeiten der Weimarer Republik ein Stardirigent war. Fred K. Prieberg vermutet denn auch, dass die Ablehnung, die Furtwängler aus Emigrantenkreisen entgegenschlug, sich letztlich auf die Enttäuschung gründete, dass er nicht emigriert war:

Wenn man Furtwängler Kollaboration mit und Propaganda für den NS-Staat vorwarf, so unterschätzte man dabei nicht zuletzt auch eklatant die Zwänge, denen man auch als Prominenter „in einem Terrorregime wie diesem, dessen Grausamkeit doch auch sonst jeglicher Vergleichbarkeit entzogen wird, ausgesetzt war“. Ronald Harwood schrieb 1995 das Bühnenstück „Taking Sides“, das von István Szabó im Jahre 2001 unter demselben Titel (deutscher Untertitel: "Der Fall Furtwängler") verfilmt wurde.

Der Fürsprache der „entarteten“ Musiker Paul Hindemith, Yehudi Menuhin, Szymon Goldberg sowie seiner langjährigen jüdischen Sekretärin Berta Geissmar verdankte es Furtwängler, dass er 1947 freigesprochen wurde. Am 25. Mai 1947 dirigierte er erstmals wieder in einem öffentlichen Konzert die Berliner Philharmoniker. Es dauerte jedoch noch weitere fünf Jahre, bis er 1952 wieder zum Chefdirigenten der Berliner Philharmoniker ernannt wurde, diesmal auf Lebenszeit.

Furtwängler, Mitglied der weitverzweigten Familie Furtwängler, war zweimal verheiratet. 1923 heiratete er die Dänin Zitla Lund. Zu diesem Zeitpunkt hatte er bereits vier außereheliche Kinder. Die Ehe selbst blieb kinderlos. 1931 erfolgte die offizielle Trennung des Paars, die Scheidung jedoch erst 1943. Im selben Jahr heiratete er Elisabeth Ackermann (* 20. Dezember 1910; † 5. März 2013), geborene Albert, deren erster Mann, Hans Ackermann, im Zweiten Weltkrieg gefallen war. Aus dieser Ehe ging der einzige eheliche Sohn, Andreas E. Furtwängler (* 11. November 1944), hervor. Befreundet war er mit der Geigerin Melanie Michaelis.

Furtwängler war Stiefvater der Schauspielerin Kathrin Ackermann, die mit Bernhard Furtwängler verheiratet war, einem Sohn von Wilhelms Bruder Walter Furtwängler. Deren Tochter Maria Furtwängler ist ebenfalls als Schauspielerin bekannt.

Sein Grab auf dem Heidelberger Bergfriedhof wird von einer Steinplatte mit dem Vers aus 1. Kor. 13,13 bedeckt: "Nun aber bleibt Glaube, Liebe, Hoffnung, diese drei. Aber die Liebe ist die Größte unter ihnen." Neben ihm ruhen seine Mutter und seine Schwester Märit Furtwängler-Scheler, die von 1912 bis 1924 mit Max Scheler verheiratet war.

Furtwängler war ein Dirigent, dessen Selbstverständnis der Mythos von der Erlösungsfunktion der Musik ist. Seine Subjektivität äußerte sich in einer Dirigierhaltung, die häufig als unerschöpfliches Sich-Hineinsteigern in Formen und Elemente der Musik gedeutet wurde, die dabei aber auch, gerade was Accelerandi und Temporückungen betrifft, in hohem Maße kalkuliert war. Diese Haltung und Interpretationsweise hat ihren Ursprung im 19. Jahrhundert.

Viele Kommentatoren und Kritiker, wie beispielsweise Joachim Kaiser, sehen Furtwängler als größten Dirigenten der Geschichte.

Furtwänglers Dirigierkunst wird als Synthese und Gipfelpunkt der sogenannten „Germanischen Schule des Dirigierens“ angesehen, die von Richard Wagner initiiert wurde. Im Gegensatz zu Mendelssohns Dirigierstil zur selben Zeit, der „charakterisiert war durch schnelle, gleichmäßige Tempi und angefüllt war mit dem, was viele als vorbildliche Logik und Präzision ansahen“, war „Wagners Art […] breit, hyperromantisch und umfasste die Vorstellung von Tempo-Modulation“. Wagner betrachtete eine Interpretation als eine Neuschöpfung und betonte mehr Phrase als Takt. Das Tempo zu variieren war nichts Neues, denn nachgewiesenermaßen interpretierte Beethoven selbst seine eigene Musik sehr freizügig. Beethoven schrieb in einigen seiner Briefe: „Meine Tempi gelten nur für die ersten Takte, da Gefühl und Ausdruck ihr eigenes Tempo benötigen“, oder „Weshalb ärgern sie mich, indem sie nach meinen Tempi fragen? Entweder sind sie gute Musiker und sollten wissen wie meine Musik gespielt werden sollte, oder sie sind schlechte Musiker und in dem Fall wären meine Hinweise nutzlos“. Beethovens Schüler, wie etwa Anton Schindler, bezeugten, dass der Komponist kontinuierlich das Tempo variierte, wenn er seine Werke dirigierte. Es waren die ersten beiden festangestellten Dirigenten der Berliner Philharmoniker, die Wagners Tradition folgten. Hans von Bülow unterstrich mehr die einheitliche Struktur der symphonischen Werke, während Arthur Nikisch mehr die Großartigkeit der Töne betonte. Die Stile dieser beiden Dirigenten wurden von Furtwängler zusammengeführt. Furtwängler war der Schüler von Felix Mottl, einem Schüler von Wagner, als Furtwängler 1907–1909 in München weilte. Darüber hinaus sah Furtwängler stets Arthur Nikisch als sein Vorbild an. Wie John Ardoin darlegte, führte der subjektive Dirigierstil von Wagner zu Furtwängler, der objektive Dirigierstil von Mendelssohn zu Toscanini.

Zusätzlich wurde Furtwänglers Kunst stark durch den jüdischen Musiktheoretiker Heinrich Schenker beeinflusst, mit dem er von 1920 bis zu Schenkers Tod 1935 zusammenarbeitete. Schenker war der Begründer der Musikanalyse und betonte darunterliegende weitreichende harmonische Spannungen und Auflösungen eines Musikstücks. Furtwängler las 1911 Schenkers Monographie über Beethovens 9. Sinfonie. Seitdem versuchte er, alle seine Bücher aufzufinden und zu lesen. Er traf Schenker erstmals 1920, und seitdem arbeiteten sie kontinuierlich gemeinsam an den musikalischen Werken, die Furtwängler dirigierte. Da seine Ideen zu modern für ihre Zeit waren, konnte Schenker nie in eine akademische Position in Österreich und Deutschland gelangen, trotz Furtwänglers Bemühungen, ihn dabei zu unterstützen. Schenker lebte dank einiger Mäzene einschließlich Furtwängler. Furtwänglers zweite Ehefrau bestätigte viel später, dass Schenker einen immensen Einfluss auf ihren Mann hatte. Schenker sah Furtwängler als den größten Dirigenten der Welt an und als den „einzigen Dirigenten, der Beethoven wirklich verstand“.

Furtwängler modifizierte die sogenannte Amerikanische Orchesteraufstellung, indem er die Bratschen rechts außen setzte (erste und zweite Geigen links, Violoncelli halbrechts und Bratschen rechts, Bässe rechts). Jedoch soll Serge Kussewitzky diese Aufstellung fast zeitgleich und angeblich unabhängig von Furtwängler praktiziert haben – mit der Variante, dass die Bässe links blieben. Allerdings sind viele Bilddokumente zu sehen, bei denen Furtwängler auch die alte deutsche Aufstellung dirigiert (zweite Geige rechts, Bässe links). Seine Orchesteraufstellung erfreut sich – als Kompromiss zwischen Amerikanischer und Deutscher Aufstellung – großer Beliebtheit.

Furtwänglers Aufnahmen sind auch durch einen „außergewöhnlichen Klangreichtum“ charakterisiert, mit besonderer Betonung auf Celli, Kontrabässen, Schlagzeug und Holzblasinstrumenten. Furtwängler zufolge lernte er von Arthur Nikisch, wie dieser Klang zu erreichen sei. Dieser Klangreichtum rührt teilweise von seinem „vagen“ Takt her, der häufig sein „fließender Takt“ genannt wird. Dieser fließende Takt erzeugte eine geringfügige Taktverschiebung zwischen den Musikern, was dem Zuhörer erlaubte, alle Orchesterinstrumente klar zu unterscheiden, sogar in den Tutti. Deshalb sagte Vladimir Ashkenazy einst: „Ich hörte niemals solch schöne Fortissimi wie bei Furtwängler.“ Yehudi Menuhin erklärte bei vielen Gelegenheiten, dass Furtwänglers fließender Takt schwieriger, jedoch Toscaninis sehr präzisem Takt überlegen gewesen sei. Außerdem versuchte Furtwängler im Gegensatz zu Otto Klemperer nicht, Emotionen zu unterdrücken, die seinen Interpretationen einen hyperromantischen Aspekt gaben, deren emotionale Intensität in den Aufnahmen aus der Zeit des Zweiten Weltkriegs an die Grenzen künstlerischer Erlebnisfähigkeit gehen.

Die Interpretation der 9. Sinfonie von Beethoven im März 1942 mit den Berliner Philharmonikern wird von manchen seiner Bewunderer als „Jahrtausendinterpretation“ angesehen. Joachim Kaiser schreibt dazu: „Die nach wie vor gewaltigste und tiefgründigste Deutung der Symphonie Nr. 9 [von Beethoven] stammt von Wilhelm Furtwängler. Es ist der Mitschnitt eines Konzerts mit den Berliner Philharmonikern aus dem Jahr 1942.“ Dieser Interpretation steht eine Interpretation der großen C-Dur Symphonie von Schubert im Dezember des gleichen Jahres in nichts nach. Joachim Kaiser äußerte sich wie folgt (wenn auch nicht auf diese spezielle Aufnahme bezogen): „Wilhelm Furtwängler – darüber gibt es unter den Schubertianern der Alten und Neuen Welt wohl keinen Zweifel mehr – hat Schuberts ‚große‘ C-Dur-Symphonie faszinierender, glühender und visionärer zu dirigieren vermocht als jeder andere.“

Furtwängler wollte stets einen Aspekt von Improvisation und Unerwartetem in seinen Konzerten bewahren, so dass sich jede Interpretation als Neuschöpfung entwarf, wie bei Richard Wagner. Jedoch gingen bei Furtwängler weder die melodische Linie noch die globale Einheit jemals verloren, nicht einmal in den dramatischsten Interpretationen, zum Teil durch den Einfluss von Heinrich Schenker, und weil Furtwängler auch Komponist war, der lebenslang Komposition studiert hatte.

Zu den Musikern, die die höchste Meinung über Furtwängler zum Ausdruck brachten, gehören einige der prominentesten des 20. Jahrhunderts, wie Arnold Schönberg, Paul Hindemith oder Arthur Honegger. Solisten wie Dietrich Fischer-Dieskau, Yehudi Menuhin und Elisabeth Schwarzkopf, die mit fast allen großen Dirigenten des 20. Jahrhunderts musizierten, erklärten bei mehreren Gelegenheiten, dass für sie Furtwängler der wichtigste war. John Ardoin berichtete die folgende Diskussion, die er mit Maria Callas im August 1968 hatte, nachdem sie Beethovens Achte mit dem Cleveland Orchestra unter George Szell angehört hatten:

Weniger bekannt ist, dass Furtwängler auch komponierte. Er sah sich selbst sogar primär als Komponist an und litt daher zeitlebens unter dem Spannungsverhältnis, dass er zwar als Dirigent bewundert wurde, aber in seiner Rolle als Komponist viel zu wenig Beachtung fand. So schrieb er beispielsweise zu Beginn seiner Dirigentenkarriere: „Morgen gehe ich in meine Verbannung als Kapellmeister nach Straßburg. Ich kann mir nicht helfen. Ich habe dabei die Empfindung, als ob ich mir untreu würde damit.“ Eine ähnliche Äußerung lautete wie folgt:

An seinen Privatlehrer Ludwig Curtius schrieb er:

Seine zweite Frau Elisabeth erzählte, dass sie einmal zu Furtwängler gesagt habe, dass es doch eigentlich schade sei, dass sein Vater gar nicht erlebt habe, dass er Dirigent der Berliner Philharmoniker geworden sei. Darauf habe Furtwängler geantwortet, dass sein Vater darüber sehr enttäuscht gewesen wäre, denn dieser habe gewusst, dass er Komponist sei. Gegen Ende seines Lebens konnte der Komponist Furtwängler mit dem Dirigenten Furtwängler insofern wenigstens ansatzweise versöhnt werden, als es ihm vergönnt war, seine 2. Sinfonie in e-Moll bei zahlreichen Gelegenheiten aufzuführen.

Seine bedeutendsten Werke, so auch die zweite Sinfonie, schrieb er nach 1935. Das meiste, was er davor komponiert hatte, stammt aus den Jahren bis zum Ersten Weltkrieg. In den zwei Jahrzehnten dazwischen konzentrierte er sich fast ausschließlich auf seine Dirigentenkarriere und vollendete kein einziges Werk. Furtwänglers schmales Œuvre umfasst drei Sinfonien (frühe Werke teilweise verschollen), einige Orchesterstücke, ein Klavierkonzert, etwas Kammermusik, Chorstücke (sämtlich Jugendwerke) und frühe Klavierkompositionen sowie Lieder. Die zweite Sinfonie ist das am meisten aufgeführte und daher auch bekannteste unter seinen Werken. Die Sätze seiner dritten Sinfonie in cis-Moll, an der er bis zu seinem Tode arbeitete, sind mit den folgenden programmatischen Bezeichnungen versehen: 1. „Das Verhängnis“, 2. „Im Zwang zum Leben“, 3. „Jenseits“, 4. „Der Kampf geht weiter“.

Unter seiner Kammermusik ragt besonders die 2. Violinsonate in D-Dur mit ihrem elegisch-meditativen langsamen Satz hervor. Die reifen Kompositionen zeichnen sich besonders durch riesenhafte Ausmaße (sein dreisätziges Klavierquintett dauert 80 Minuten) sowie ein hohes Maß an motivisch-thematischer Arbeit aus. Im Großen und Ganzen ist sein Stil dem Erbe Anton Bruckners, Johannes Brahms’ und Max Regers verpflichtet, allerdings führt Furtwängler deren Traditionen auf originelle Weise weiter, sodass man den Komponisten nicht als Epigonen verurteilen darf, was oft geschieht. Zu sehr hat Furtwängler seine eigene, persönliche Tonsprache entwickelt. Die Stimmung seiner Werke lässt sich oft als grüblerisch oder tragisch bezeichnen. Dazu erschwert der hohe intellektuelle Anspruch seiner Musik das Verständnis, was zusammen mit den enormen spieltechnischen Ansprüchen wohl der Grund dafür ist, dass sie sich bisher nicht im Konzertbetrieb etablieren konnte. In jüngerer Zeit haben sich vor allem die Dirigenten Wolfgang Sawallisch, George Alexander Albrecht und Daniel Barenboim um eine Pflege der Musik Furtwänglers bemüht. Eine Gesamtausgabe der Werke und der Direktionen des Komponisten ist 2011 bei Documents erschienen.

„Der Musiker und sein Publikum“ ist das Manuskript für einen Vortrag, der in der Bayerischen Akademie der Schönen Künste gehalten werden sollte, aber durch die Erkrankung und den Tod Furtwänglers nicht zustande kam. Furtwängler hatte dem Verleger Martin Hürlimann gegenüber vorab einer Veröffentlichung zugestimmt. Der Autor ergreift darin leidenschaftlich Partei für eine Kompositionsweise, bei der die Musik das Publikum, auch das laienhafte („Menschen des einfachen, klaren Lebens“), unmittelbar anspricht. Im Gegensatz dazu sieht er Musik, die in erster Linie für Theoretiker, Fachleute und Kritiker geschrieben werde und eines ideologischen Unterbaus bedürfe. Als Beispiel nennt er die Zwölftonmusik Arnold Schönbergs.

„Gespräche über Musik“ umfasst die Mitschriften von sechs Gesprächen zwischen dem Dirigenten und dem Herausgeber Walter Abendroth, einen von Furtwängler verfassten Text („Siebentes Gespräch“) sowie ein ebenfalls von ihm stammendes Nachwort. Auch in diesen Texten verwendet er sich intensiv für die klassische, tonale Musik, insbesondere für die Werke Beethovens.


Seit 1990 wurde im Rahmen der Veranstaltung „Gala d’Europe Baden-Baden“ in unregelmäßigem Turnus der Wilhelm-Furtwängler-Preis zur Auszeichnung international renommierter Sängerinnen, Sänger und Dirigenten für besonders herausragende Leistungen auf dem Gebiet der klassischen Musik vergeben. Initiiert wurde der Preis von Elisabeth Furtwängler, der Ehefrau Wilhelm Furtwänglers, und Ermano Sens-Grosholz.

Erstmals wurde der Preis an Plácido Domingo verliehen. Seit 2008 wird er während des Beethovenfestes in Bonn an herausragende Solisten, Orchester, Dirigenten und Ensembles des klassischen Musiklebens verliehen.

Liste der Preisträger (unvollständig):

Dies ist eine unvollständige Liste der Aufnahmen Furtwänglers. Aufgrund der Entstehungszeit handelt es sich ausschließlich um Mono-Aufnahmen und größtenteils um Live-Mitschnitte.






































Solostimme und Klavier

Duett für hohe und tiefe Stimme und Klavier











</doc>
<doc id="12912" url="https://de.wikipedia.org/wiki?curid=12912" title="Apartheid">
Apartheid

Als Apartheid wird eine geschichtliche Periode der staatlich festgelegten und organisierten so genannten Rassentrennung in Südafrika bezeichnet. Sie war vor allem durch die autoritäre, selbsterklärte Vorherrschaft der „weißen“, europäischstämmigen Bevölkerungsgruppe über alle anderen gekennzeichnet. Bereits Anfang des 20. Jahrhunderts begonnen, hatte sie ihre Hochphase von den 1940er bis zu den 1980er Jahren und endete 1994 nach einer Phase der Verständigung mit einem demokratischen Regierungswechsel, bei dem Nelson Mandela der erste schwarze Präsident des Landes wurde. Heute wird der Begriff manchmal auch als Synonym für rassistische Segregation im Allgemeinen verwendet, zudem wurde das politische Handeln mit solchen Bestrebungen als Straftatbestand ins internationale Recht aufgenommen (→ Apartheid (Recht)).

"Apartheid" bedeutet ‚Getrenntheit‘, gebildet aus dem Afrikaans- oder niederländischen Adjektiv "apart" für ‚getrennt, einzeln, besonders, anders‘, was ursprünglich aus dem Lateinischen stammt: "pars" ‚der Teil‘, "ad partem" ‚(nur) zu einem Teil‘. In weiteren Sprachen:

Bei der Entwicklung von Theorie und Praxis der Apartheid waren viele historische, gesellschaftlich-soziologische, religiöse und psychologische Faktoren wirksam. Die Relevanz und Bedeutung der einzelnen Komponenten wird von der Forschung kontrovers diskutiert. Im engeren Sinne wird nur die seit 1948 praktizierte gesetzlich verankerte Politik der Rassentrennung als Apartheid bezeichnet. In Südafrika wird der Apartheidsbegriff von offiziellen Stellen bereits für die politisch-legislativen Maßnahmen zur Rassentrennung vor 1948 verwendet, da die Grundlagen der Apartheid bereits ab 1908 schrittweise entstanden. Mit dem Sieg der Nationalen Partei bei den Parlamentswahlen 1948 und der sich anschließenden Regierungsbildung unter Führung von Daniel François Malan erreichte die Ideologie der Apartheid eine Dynamik hin zu einer noch strengeren und autoritären Ausprägung als die Rassentrennungspolitik vorangegangener Regierungen. Die Geschichte der Apartheid in Südafrika wurde vor allem durch die Konflikte zwischen zugewanderten Bevölkerungsgruppen der Bantu, niederländischstämmigen Buren, Briten und später auch den als Coloured bezeichneten Mischlingen sowie Indischstämmigen geprägt. Dementsprechend war die demographische Struktur Südafrikas eine Basis zur Herausbildung des Apartheidsystems.

Ursprünglich war die Region südlich des Sambesi von den San besiedelt. Im 16. und 17. Jahrhundert stießen bantusprachige Gruppen aus dem Norden in deren Siedlungsgebiet und verdrängten die indigene Bevölkerung teilweise. Mitte des 16. Jahrhunderts errichteten portugiesische Seefahrer als erste Europäer kleine Niederlassungen an der Küste. 1652 gründete Jan van Riebeeck am Kap der Guten Hoffnung im Namen der Niederländischen Ostindien-Kompanie eine Station zur Versorgung von Schiffen mit Lebensmitteln, aus der in der Folge Kapstadt entstand. Die Niederländer, ab dem 18. Jahrhundert als Buren bekannt, betrieben Landwirtschaft und begannen mit den Einheimischen Handel zu treiben. Die Briten erlangten die Kontrolle über die Kapprovinz. Bei ihrem Vordringen Richtung Osten stießen sie auf die Xhosa; von 1779 bis 1879 kam es zu neun Kriegen (Xhosa- oder Kap-Grenzkriege), bei denen die Xhosa den weißen Truppen unterlagen.

Die niederländischstämmigen Buren waren durch den Calvinismus geprägt, der Johannes Calvins Prädestinationslehre weiterentwickelte. In der neo-calvinistischen Nederduitse Gereformeerde Kerk (NGK) auf dem Gebiet des heutigen Südafrikas, der auch heute noch die Mehrzahl aller weißen Afrikaaner angehören, war es bis 1857 selbstverständlich, dass Weiße und Nichtweiße gemeinsam beteten und kommunizierten. Erst 1857 beschloss diese, dass Nichtweiße „ihre christlichen Privilegien in einem separaten Gebäude oder Institute genießen“ sollten. Zur religiösen Legitimation der Apartheid wurden Stellen aus dem Alten Testament wie dem 5. Buch Mose Kapitel 7 und 23 "(In die Versammlung des Herrn darf kein Bastard aufgenommen werden; auch in der zehnten Generation dürfen seine Nachkommen nicht in die Versammlung des Herrn aufgenommen werden)", oder herangezogen. Mit zentralen Aussagen Calvins, für den eine Unterscheidung zwischen arm und reich, Freien und Sklaven, Frauen und Männern sowie Rassen bzw. Nationalitäten in der Kirche undenkbar war (siehe ), ist eine theologische Rechtfertigung der Apartheid wie etwa durch die NGK nicht vereinbar. Wiederholt wurde in der Forschung (beispielsweise F. A. van Jaarsfeld, Edward A. Tiryakian und T. Dunbar Moodie) ab den 1950er Jahren die Meinung vertreten, dass einige Aspekte des Calvinismus eine wichtige Rolle bei der Ausbildung des Apartheidssystems gespielt hätten. Diesen Sichtweisen wurde ab den 1980er Jahren (beispielsweise von André du Toit oder Norman Etherington) vermehrt widersprochen.

Unter der britischen Herrschaft zu Beginn des 20. Jahrhunderts bildeten sich die ersten umfassend geplanten Apartheidsstrukturen in Südafrika heraus.

Von 1903 bis 1905 sollte die South African Native Affairs Commission (SANAC) eine gemeinsame Ethnienpolitik für alle vier südafrikanischen Provinzen (Natal, Kapkolonie, Oranje-Freistaat und Transvaal) festlegen. Die Kommission schlug die Errichtung im Sinne der in Natal herrschenden Praxis der Native Administration vor. Diese separate Zuständigkeit einer mächtigen Verwaltungsbehörde wurde ab 1958 in Form der "Bantu Administration" das organisatorische Zentrum im Apartheidregime.

1910 wurde die Südafrikanische Union durch den Zusammenschluss der vier Provinzen gegründet. Die Union war von Anfang an unter Kontrolle der Weißen. Schwarze wie auch Farbige und Asiaten erhielten kein Wahlrecht, obwohl es Bemühungen dieser Art durch den Missionar James Stewart gegeben hatte. Nur an den Provinzregierungen durften sie partizipieren. Des Weiteren war jeglicher sexueller Kontakt zwischen den unterschiedlichen als „Rassen“ bezeichneten Bevölkerungsgruppen verboten. Die Segregationspolitik wurde durch die weißen Machthaber mit einer wachsenden Zahl von Gesetzen untermauert.

Der Mines and Works Act legte 1911 die ungleiche Behandlung der Weißen und Schwarzen in der Wirtschaft fest. Das wohl wesentlichste Gesetz der räumlichen Trennung, der Natives Land Act, wurde 1913 in Kraft gesetzt. In der Folge durfte die schwarze Bevölkerung nur noch in den ihnen zugewiesenen Reservaten Land erwerben. Diese Areale umfassten rund 7,3 Prozent des südafrikanischen Territoriums. Zehn Jahre später vollzog der Natives Urban Areas Act die räumliche Trennung auch in städtischen Gebieten. Gegen die wachsende Ungleichheit der Bevölkerungsgruppen erklärte sich im Jahre 1923 eine interkirchliche Missionskonferenz, die sich unter der Leitung von Johannes Du Plessis mit einem diesbezüglichen Forderungspapier an die damalige Regierung Südafrikas wandte.

Im Jahr 1924 schränkte der "Industrial Conciliation Act" das Zusammenwirken der möglichen Tarifpartner ein. Mit diesem Gesetz schuf man so genannte Industrieräte "(Industrial Councils)", um die bisherigen Auseinandersetzungen zwischen Arbeiterkommandos und dem Militär zu verhindern. Diese Industrieräte arbeiteten ähnlich wie Tarifkommissionen und hatten Beschlussfassungskompetenz, die jedoch im Einzelnen durch den Arbeitsminister bestätigt werden mussten. Von der Seite der Arbeiter konnten nur Personen mit dem vom Gesetz definierten Status als "employees" (Arbeitnehmer) daran mitwirken. Schwarze Arbeitnehmer waren jedoch davon ausgeschlossen und galten demzufolge auch nicht als tariffähig. Die Regierung des 1924 gewählten Bündnisses zwischen der National Party und der South African Labour Party unter dem gemeinsamen Ministerpräsidenten James Barry Munnick Hertzog entwickelte eine "Civilized Labour Policy" (zivilisierte Arbeitspolitik), nach der alle öffentlichen Arbeitgeber nur noch weiße Arbeitskräfte einzustellen hatten. Demnach verloren beispielsweise im staatlichen Eisenbahnbereich tausende schwarze Arbeitnehmer ihren Arbeitsplatz. Der damalige sozialdemokratische Arbeitsminister Frederic Creswell definierte „unzivilisierte Arbeit“ als eine Tätigkeit von Personen, die sich auf einen Lebensstil mit den nur allernötigsten Verpflichtungen beschränken, wie es unter „barbarischen und unentwickelten Menschen“ üblich sei.

Weitere gesetzliche Maßnahmen, die zu Einschränkungen für die nichtweiße Bevölkerung führten, gab es in den 1930er und 1940er Jahren. Im Jahr 1948 gewann die Nationale Partei die Parlamentswahlen. Sie blieb danach bis 1994 an der Macht.

Aus dieser Tradition heraus wurde die Rassentrennung gerechtfertigt, mit Empfehlungen aus einer mit Wissenschaftlern besetzten Kommission unterstützt und schließlich mit Gesetzen und einer speziellen Behörde institutionalisiert. In den Gesetzestexten wurde die Apartheid dabei mit dem Euphemismus „Getrennte Entwicklung“ (afrikaans: "Afsonderlike Ontwikkeling") bezeichnet.

Der Sieg der burischen Nationalisten war eng verknüpft mit dem Zweiten Weltkrieg. Unter dem zuvor amtierenden Premierminister Jan Christiaan Smuts beteiligte sich Südafrika an der Seite der Briten an militärischen Auseinandersetzungen. Die Nationalisten hingegen waren gegen eine Einmischung in das kriegerische Geschehen und sympathisierten offen mit dem deutschen nationalsozialistischen Regime. Das wahlberechtigte Volk stimmte mehrheitlich mit den Nationalisten überein.

Der Regierungswechsel stellte für viele Buren, die zuvor unter britischer Herrschaft kaum Anschluss an die führende Spitze des Landes gefunden hatten, den Ausstieg aus der Armut dar. Viele zogen in urbane Gebiete und fanden dort in der aufstrebenden Wirtschaft Arbeit. Die Nationalisten, die sich im Übrigen von den Briten abzugrenzen versuchten, lenkten nun auch die Rassenpolitik in neue Bahnen. Dabei verfolgten sie drei Ziele: Erstens wollten sie die politische Macht konsolidieren, zweitens ihre Vision der Rassenbeziehungen umsetzen und drittens sollte der Bildungsstand und wirtschaftliche Status der Buren angehoben werden.

Vor 1948 waren die Schwarzen schrittweise von der selbstbestimmten politischen Teilhabe und hohen Positionen in der Wirtschaft ausgeschlossen. Die Rassentrennung war zum Teil durch das Gesetz und zum Teil durch den inoffiziellen Brauch gegeben. Die Ordnung war jedoch nicht sehr strikt. Es gab durchaus Farbige, die neben Weißen wohnten, indische Geschäftsleute, welche im Stadtzentrum ihren Aufgaben nachgingen oder Schwarze, die außerhalb ihrer Reservate ihre Farmen bewirtschafteten.

Diese „Löcher“ in der Rassentrennung schlossen die Nationalisten mit diversen Maßnahmen. Als erstes teilten sie die ganze südafrikanische Bevölkerung in vier ethnisch differenzierte Klassen ein: "Weiße", "Farbige", "Asiaten" und "Schwarze" bzw. auf Englisch "White", "Coloured", "Asiatic" oder "Indian" und "Native" oder später "Bantu" und "African." ("Siehe auch:" Bevölkerung Südafrikas). Die Zuordnung zu einer dieser Gruppen geschah nach bestimmten Kriterien. Die Interpretation der Testergebnisse lag oft im Ermessen des Versuchsleiters. Dies betraf besonders die Einteilung in Schwarze und Farbige. Es kamen dabei verschiedene Tests zum Einsatz, wie zum Beispiel, ob ein in die Haare gesteckter Stift herunterfällt, wenn der Proband den Kopf schüttelt. Fiel der Stift heraus, so galt der Proband als Farbiger, blieb der Stift stecken, galt er als Schwarzer. Dies hatte zur Folge, dass Kurzhaarfrisuren populär wurden. Ein anderer dieser Tests bestand darin, dass der Testleiter mit Kraft eine Fingerkuppe der zu testenden Person zusammendrückte. Aus der Farbe des nach dem Loslassen verfärbten – weil blutleeren – Fingernagelbetts wurde auf die Rassenzugehörigkeit geschlossen.

Die Rassenordnung bestimmte fortan das gesamte Leben. An öffentlichen Orten war eine strikte Trennung von Weißen und Nicht-Weißen vorgeschrieben. Mischehen waren verboten. Mit dem "Group Areas Act" vom 13. Juni 1950 wurde die Trennung der Wohngebiete festgeschrieben. In städtischen Gebieten wurden getrennte Wohnbereiche für die verschiedenen Rassen geschaffen; die Ausbildung richtete sich ebenfalls nach der entsprechenden Rasse. Schwarze mussten außerhalb ihrer Reservate einen Pass tragen. Damit sollten in städtischen Gebieten nur jene Schwarzen geduldet werden, die dafür eine Arbeitserlaubnis vorweisen konnten. Alle übrigen Schwarzen wurden als Ausländer angesehen. Die in den Städten arbeitenden Schwarzen wurden als Gastarbeiter akzeptiert. Sie lebten überwiegend in so genannten Townships am Stadtrand. Nichtstädtische Schwarze durften sich gemäß dem Native Laws Amendment Act von 1952 ohne Genehmigung nur 72 Stunden in Städten aufhalten. Damit war die Apartheid legalistisch vollständig. Dennoch war der Lebensstandard, die Bildungsmöglichkeiten in Schulen und den wenigen für sie zugelassenen Universitäten sowie die medizinische Versorgung und somit die Lebenserwartung der Schwarzen höher als in allen anderen afrikanischen Ländern, weswegen Südafrika auch während der Apartheid mit illegaler Einwanderung aus den nördlichen Anrainerstaaten konfrontiert war.

1953 wurde der Bantu Education Act verabschiedet, der am 1. April 1955 die Kontrolle über die Bildung der Schwarzen vom Bildungsministerium auf das Native Affairs Department übertrug. Hintergrund war es, die Afrikaner zu körperlicher Arbeit auszubilden; anstelle von Mathematik und Englisch sollte Landwirtschaft gelehrt werden. Gleichzeitig sollten alle afrikanischen Grund- und Oberschulen, die von Kirchen und Missionen betrieben wurden, von der Regierung übernommen werden, ansonsten würden diese Schulen keine staatlichen Mittel mehr als Unterstützung erhalten. Aus Protest rief der ANC einen einwöchigen Schulboykott aus, der am 1. April 1955 beginnen sollte. Daraufhin wurde das Gesetz dahingehend geändert, dass die Erziehung für alle gleich sein solle.

Die Politik in Südafrika schuf eine Reihe von verschiedenen Gesetzen, Verordnungen und administrativen Strukturen, welche den Regierungen weitgehende Vollmachten ermöglichten, die Benachteiligung großer Bevölkerungsgruppen durchzusetzen und die Macht der Weißen über die anderen Gruppen zu untermauern.

Nach dem Ende des Zweiten Burenkriegs beauftragte der Gouverneur der Kapkolonie Lord Milner 1903 eine Kommission ("South African Native Affairs Commission") mit der Untersuchung aller Lebensverhältnisse in der Eingeborenenbevölkerung von den vier „Südafrikanischen Kolonien“, also in der Kapkolonie einschließlich Natal, in Transvaal sowie in der Oranjefluss-Kolonie.

Diese von 1903 bis 1905 tätige Kommission war auf Grund ihrer personellen Zusammensetzung von europäischen Interessen geprägt und stand unter der Leitung von Sir Godfrey Lagden. In der Öffentlichkeit trug die Kommission und deren Report seinen Namen. Der so genannte "Lagden-Report" und die aus seinen Empfehlungen folgende Gesetzgebung wird heute als Reaktion auf die Minderheitssituation der weißen Bevölkerung mit ihren fortschreitenden wirtschaftlichen Problemen interpretiert.
Der zunehmende Landbesitz (treuhänderisch oder Gewohnheitsrecht) unter der einheimischen Bevölkerung, eine damalige zentrale Frage, sollte nach den Empfehlungen des Reports so gestaltet werden, dass er von den Gebieten der weißen Bevölkerung sowohl räumlich als auch strikt rechtlich abgetrennt war. Die weiße Bevölkerung begann sich mit Landbesitz zu bevorraten. Die dadurch eintretende Landverknappung minderte den sozialen Aufstieg der schwarzen Bevölkerung durch eigene landwirtschaftliche Betätigung und hemmte auf diese Weise nicht nur deren Gesamtentwicklung, sondern erzeugte eine Bevölkerungswanderung in Südafrika mit Konzentration an neuen Orten. Diese institutionelle Benachteiligung der einheimischen Bevölkerung zu Ungunsten ihrer Erwerbsgrundlagen in den Heimatgebieten schuf eine wachsende Zahl von Wanderarbeitern, die sich zunehmend in den Bergbauzentren konzentrierten oder sie in einem Abhängigkeitssystem zu Lohnarbeit auf "weißen" Farmen zwang.

Mit dem Natives Land Act (Act No. 27) von 1913 wurde versucht, den Landerwerb durch die schwarze Bevölkerung außerhalb jener Gebiete zu stoppen, die von der Regierung für ihre Ansiedlung vorgesehen waren. Somit betrieb man eine Konzentration der einheimischen afrikanischen Bevölkerung in den "African Reserves" genannten neuen Siedlungsarealen, indem man sie dort durch Grundstückskäufe und Pachtverträge gezielt zu binden versuchte. Auf diese Weise waren die Bewohner jener Areale als niedrigentlohnter Arbeitskräftepool zu Gunsten der Farmen und den Industrien der Weißen in den Städten gesteuert verfügbar gehalten. An dieser damaligen Strukturentwicklungspolitik wird der ökonomische Charakter des Apartheidkonzeptes erkennbar. Der "Natives Land Act" wird demzufolge als erster legislativer Meilenstein für die gesamte Apartheidpolitik angesehen. Auf seiner Grundlage schuf man 1916 die "Beaumont-Kommission" ("Beaumont Commission"), deren Aufgabe war, eine nähere räumliche Definition für die neuen "schwarzen" Siedlungsgebiete festzulegen. Sie erhielt ihren Namen nach William Henry Beaumont, einem ehemaligen Administrator von Natal.

Der Vertreibungsprozess der schwarzen Bevölkerung aus den Städten in die "African Reserves" begann in Transvaal, wo die "Transvaal Local Government Commission" (Stallard Commission) nach der neuen Ansiedlungspolitik zielstrebig vorging. Sie argumentierte dabei mit ihrer grundsätzlichen Auffassung, wonach die Städte von der weißen Bevölkerung angelegt wurden und deshalb der schwarzen Bevölkerung darin nur ein zeitweiliger Aufenthalt erlaubt wäre.

Der Native (Urban Area) Act (Act No 21) von 1923 stellt den zweiten Meilenstein in der frühen Apartheidsphase dar. Diesem Gesetz folgte 1945 in der Sache der "Native (Urban Areas) Consolidation Act" ("Act No 25"), der 1986 wiederum durch den "Abolition of Influx Control Act" ("Act No 68") aufgehoben wurde.

Im Jahr 1927 beschloss das Südafrikanische Parlament den Native Administration Act (Act No 38). Dieses Gesetz gestaltete alle Fragen der einheimischen Bevölkerung in der Weise neu, dass die Zuständigkeit von der parlamentarischen Ebene der Südafrikanischen Union in die Verantwortung der Regierung und ihre regionalen Verwaltungen verschoben wurde. Damit festigte man mittels der Gesetzgebung ein Zweiklassen-Staatsbürgerrecht, das die Grundlage für das 1951 in Kraft getretene Gesetz Bantu Authorities Act bildete, mit dem später eine Selbstverwaltung unter weißer Oberaufsicht geschaffen wurde.

Während der weltwirtschaftlichen Depression in den 1930er Jahren verstärkte sich auf dem Gebiet der Südafrikanischen Union die Überweidung landwirtschaftlicher Flächen und es entstand eine Überbevölkerung in den betroffenen Regionen des Landes, was eine fortschreitende Bodenerosion und sinkende Nahrungsmittelproduktion verursachte. Die naturräumlichen Veränderungen nutzte man zu weiteren reglementierenden Eingriffen in den Grundstücksverkehr. Dazu beschloss das Parlament 1936 auf Empfehlung der "Beaumont-Kommission" den Development Trust and Land Act (Act No 18). Das Gesetz stellte eine Reaktion auf die zunehmenden Konflikte zwischen "illegalem" Landbesitz durch schwarze Farmer und den gesetzlich begünstigten weißen Farmern dar. Mittels dieser Rechtsvorschrift schuf die Südafrikanische Union ein System zur Registrierung der Farmwirtschaft sowie eine Kontrolle der Viehhaltung und Zuteilung der Landverpachtung an Schwarze. Zudem verbot man für die schwarze Bevölkerung den Grundbesitz und dessen Erwerb außerhalb der angewiesenen Siedlungsgebiete. Im Jahr 1936 wurde mit dem Representation of Natives Act das Wahlrecht der schwarzen Bevölkerung für eine Parlamentsvertretung stark eingeschränkt.

Der "Natives Laws Amendment Act" ("Act No 46 / 1937") von 1937 reduzierte die Rechte von schwarzen Arbeitnehmern. Arbeitssuchende aus ländlichen Gebieten hatten nun in den Städten nur noch ein Aufenthaltsrecht für 14 Tage einschließlich ihrer Rückkehr zum Heimatort. Der industrielle Aufschwung im Verlauf des Zweiten Weltkriegs beförderte im Parlament und in der Regierung Haltungen, diese Einschränkungen wieder zu lockern. Jedoch griff 1948 die Regierung der burischen Nasionalen Party den Stand von 1937 auf und machte ihn zur Grundlage weiterer Restriktionen in ihrer Apartheidpolitik.

Für die administrative Umsetzung der erdachten Kontrollsysteme errichtete man eine staatliche Verwaltungsstruktur, den "South African Native Trust (SANT)". Mit diesem Instrument wurde in den ländlichen Arealen eine restriktive Umverteilungspolitik von Landvermögen unter Nutzung verfügbarer staatlicher Planungs- und Siedlungspolitik begonnen. In deren Folge setzte eine Vertreibung nicht registrierter Landwirte ein, sofern sie nicht offiziell auf den weißen Farmen als Arbeiter angemeldet waren. Die Enteignung eines erheblichen Teiles der dort lebenden einheimischen Bevölkerung war die beabsichtigte ökonomische Wirkung dieser parlamentarischen Reformbestrebungen. Man bezeichnete das als „Besserungsplanung“ ("Betterment planning") und setzte diese Vorgaben in den späten 1930er und 1940er Jahren strikt um. Das führte zu einer Ausweitung der Befugnisse von den damit befassten Regierungsbeamten, den "Native Commissioners" und "Agricultural Officers".

Noch im selben Jahr ihres Sieges bei den Parlamentswahlen 1948 begann die Nationale Partei (Nasionale Party) Gesetze zu verabschieden, die die Segregation verschiedener Bevölkerungsgruppen schärfer definieren und weiter durchsetzen sollten. Mit der Verabschiedung dieser Gesetze wurde die Rassendiskriminierung in Südafrika, die Apartheid, auf systematische Art und Weise institutionalisiert und gesetzlich festgeschrieben.

Ideologische Voraussetzung dieser Gesetzgebung war die klare Einteilung und daraus folgende Trennung der Bevölkerung nach Zugehörigkeit zu einer „Rasse“ und zwecks Errichtung von unabhängigen "Bantustaaten" zu einer melderechtlichen Nationalitäteneinheit "(National Unit)".

Die Gesetze (englisch: Acts) zur systematischen Umsetzung des Apartheidskonzeptes wurden nach der Wahl 1948 und der anschließenden Erklärung der „Grand Apartheid“ in Kraft gesetzt. Wichtige Beispiele von Rechtsvorschriften zur Durchsetzung der Apartheid waren folgende:





Die Auswirkungen der Apartheidpolitik werden von manchen Forschern in zwei Aspekte eingeteilt: die "kleine Apartheid", auch "Petty Apartheid" genannt, und die "große Apartheid" oder "Grand Apartheid". Die "große Apartheid" ist die räumliche Trennung im großen Maßstab gemeint, die eigentliche Segregations- oder Homeland-Politik. Andere wissenschaftliche Darstellungen greifen diese Zweiteilung nicht auf, da das System systematischer Benachteiligungen miteinander sehr komplex verknüpft war.

Im Alltag der Nicht-Weißen waren die Formen der "kleinen Apartheid" unmittelbar spürbar. Sie beinhaltete die rassistisch motivierte Trennung im Dienstleistungsbereich wie auch etwa das Verbot des Betretens von öffentlichen Parks für Schwarze, separate Abteile in öffentlichen Verkehrsmitteln oder eigene Schulen. Unmissverständliche Regelungen und Verbote zur Trennung im öffentlichen Raum wurden durch Schilder erreicht. So hatten Krankenhäuser, Postgebäude, Rathäuser, Banken und Toiletten meist zwei, durch Schilder gekennzeichnete Eingänge. Andere Lebensbereiche waren weniger klar definiert. Durch Mundpropaganda wurden Restaurants und Bars unter Nicht-Weißen genannt, in denen man nicht bedient wurde bzw. nicht erwünscht war. Manche Nicht-Weiße testeten die Grenzen der Akzeptanz durch die Weißen. Andere scheuten sich, ihren sicheren Bereich zu verlassen. Dadurch lebten sie ruhiger und setzten sich der Diskriminierung in geringerem Umfang aus.

Manche dieser Trennungsmaßnahmen besaßen eine unmittelbare Wirkung, erzeugten aber weniger langfristige Auswirkungen für die von der Segregationpolitik betroffenen Bevölkerungsgruppen.

Der Ausschluss aller Nicht-Weißen, vorrangig jedoch der Schwarzen, vom aktiven und passiven Wahlrecht in den Landesteilen außerhalb der Reservate bzw. späteren Homelands wirkte bis in den kommunalen Bereich. Damit schufen die politischen Entscheidungsträger im parlamentarischen Vertretungssystem Südafrikas bewusst ein absolutes Defizit demokratischer Rechte für eine Bevölkerungsmehrheit. Mit der Verfassungsreform von 1984 unter Pieter Willem Botha sollte diese Lücke mit einem Dreikammersystem wieder relativiert werden, ohne der schwarzen Bevölkerungsmehrheit dabei die politische Willensbildung und Mitgestaltung in Südafrika einzuräumen. Damit konnten aus ihrem Kreis keine demokratisch legitimierten Korrekturen oder Entwicklungen in der südafrikanischen Gesellschaft angestoßen werden.

Der historische Verlauf des Stimmrechtsabbaus für die nichteuropäischstämmige Bevölkerung vollzog sich seit der Gründung der Südafrikanischen Union über mehrere Jahrzehnte und nach gruppenspezifischen (Coloured, Inder, Schwarze) Handlungsmustern. Eine wirkungsvolle Gestaltung gesellschaftlicher Fragen über die verfassungsgemäßen Strukturen der parlamentarischen und kommunalen Wahlkörperschaften war nur den europäischstämmigen Bürgern gewährt. Politische Mitgestaltung für Nichtweiße organisierte der Apartheidstaat ausschließlich aus der eigenen Herrschaftsperspektive. Raum boten dafür die Regierungen der Homelands oder weitgehend unwirksame Gremien, da sie nicht mit ausreichend Kompetenzen ausgestattet waren. Zu den letzteren gehörten vorbestimmte Institutionen mit Beratungscharakter, wie das "Coloured Persons’ Representative Council" und das "South African Indian Council".

Die Freizügigkeit war durch mehrere gesetzliche Regelungen eingeschränkt. Mit dem "Natives Laws Amendment Act (Act No 54 / 1952)" von 1952, einem Änderungsgesetz für den "Native Labour Regulation Act" von 1911 und den "Natives Consolidation Act (Act No 25 / 1945)" schränkte die Apartheidsregierung die bereits begrenzten Wohn- und Aufenthaltsrechte der schwarzen Bevölkerung weiter ein. Von besonderer Bedeutung sind dabei die Regelungen in "section 10" (deutsch sinngemäß: Paragraph 10) dieses Gesetzes, die existenziell bedeutende Ausnahmen vom 72-Stunden-Aufenthaltsrecht außerhalb der zugewiesenen Wohngebiete in den Reservaten oder Homelands definierten. Kein Schwarzer durfte sich länger als 72 Stunden in den "prescribed areas" der Weißen aufhalten. Unter die "Sektion-10-Rechte" fielen Aufenthaltsgenehmigungen für schwarze Arbeitnehmer in den „weißen“ Regionen. Sie wurden für einen zugewiesenen Arbeitsplatz mit regionaler Beschreibung definiert und entfielen bei Verlust der Arbeit. In den stets mitzuführenden Passbüchern war diese Genehmigung und eine sich monatlich wiederholende Bestätigung des Arbeitgebers eingetragen. Bei Kontrollen konnte der legale Aufenthalt dadurch sofort festgestellt werden. Besonders Frauen und die Kinder von männlichen Wanderarbeitern waren von diesen Einschränkungen massiv betroffen, da es für sie keine familiären Zuzugsrechte gab. Der Minister für Bantu-Verwaltung, Hendrik Frensch Verwoerd, erklärte 1955 in Anlehnung an die Ergebnisse der "Stallard-Kommission", dass sich die schwarzen Arbeitnehmer nur „auf Geheiß und durch die Gunst der Weißen“ und nicht durch gesetzlich garantierte eigene Rechte in den „weißen Gebieten“ nutzbringende Arbeiten erfüllten, weshalb sie „höchstens Besucher“ seien. Das wirtschaftspolitische Ziel dieser Regelungen bestand darin, alle schwarzen Beschäftigten in die Rolle von Kontrakt-Wanderarbeitern zu bringen und deren Sesshaftigkeit am Arbeitsort zu verhindern.

Durch die Einordnung der Bevölkerung in „rassisch“ definierte Gruppen entstand eine Klassifizierung, die eine perfekte Unterscheidung im gesamten gesellschaftlichen Leben für jede Person von Anderen ermöglichte. Die „Rassenkategorie“ wurde in die Ausweisdokumente durch Buchstabencodes, zum Beispiel "-C-" für Coloureds, eingetragen. Die schwarze Bevölkerung erhielt ein besonderes Ausweisdokument, das "reference book". Der "Population Registration Act (Act No 30 / 1950)" teilte die Bevölkerung Südafrikas in drei Hauptgruppen ein:
Zur Umsetzung dieser Maßgaben schuf man ein „Amt für Rassenklassifizierung“ "(Race Classification Board)". Alle Südafrikaner wurden von dieser Behörde erfasst und waren zur Einsendung eines Passbildes verpflichtet. Auf dieser Grundlage entstand ein zentrales „Rassenregister“.
Seit 1951 war der Begriff "Bantu" als Terminus für die einheimische schwarze Bevölkerung bei der Regierung üblich und seit 1962 offizieller Begriff. Im Jahr 1978 führte man als offizielle Bezeichnung für Personen das Wort "Black" ein. Mit dem Jahr 1973 war in den Personaldokumenten der Schwarzen eine ethnische Untergruppe (National unit) vermerkt. Ein Ergänzungsgesetz von 1982, der "Population Registration Amendment Act (Act No 101 / 1982)" bewirkte eine Vereinheitlichung der Personalausweise für alle Bevölkerungsgruppen, die nun die Möglichkeit zur Aufnahme biometrischer Merkmale vorsahen. Alle Personendaten wurden in einem zentralen Computersystem des Staates gespeichert.

Die Wohngebiete der weißen Bevölkerung, auch "Europeans" genannt, lagen durchweg in den geographisch und strukturell vorteilhaftesten Arealen der Siedlungsgebiete. Wurden die festgelegten Bereiche für die Weißen zu eng, mussten andere Bevölkerungsgruppen Teile ihrer Wohngebiete räumen und in neu zugewiesene Bereiche umsiedeln. Ein bekanntes Beispiel war die Räumung des District Six im Zentrum von Kapstadt und die Zwangsumsiedlung von etwa 60.000 Menschen in das etwa 30 Kilometer entfernte, sandige Khayelitsha. Die schwarze Bevölkerung war in ihrem abgelegenen Wohngebiet so weit außerhalb der Gemeinden, oft hinter natürlichen oder künstlichen Hügeln sowie Müllkippen verbannt, dass sie nicht als Teil der Gemeinde angesehen werden konnte.

Mit der Konzipierung der Homelands versuchten die Apartheidsideologen eine hauptsächlich ökonomisch begründete Raumordnungspolitik umzusetzen.

Zwischen 1960 und 1980 mussten etwa 3,4 Millionen Menschen im Zuge der Homelandpolitik ihre bisherigen Wohnstätten in urbanen und ländlichen Regionen zwangsweise aufgeben. Darunter befanden sich etwa 2,8 Millionen Schwarze, 600.000 Coloureds und Inder sowie 16.000 Weiße. Auf diese Weise zerstörte man das traditionelle "labour tenant system", was den Landarbeiterfamilien ein unbestrittenes Wohnrecht auf den „weißen“ Farmen garantierte, wenn sich ihr Familienoberhaupt dort für eine jährliche Mindestzeit (90 Tage in Transval, 180 Tage in Natal) zur bezahlten Arbeit verpflichtete. Den Rest des Jahres konnten sie anderen Beschäftigungen nachgehen. Dies erfolgte nicht ohne Proteste, die zu unzähligen Verhaftungen führten. Auf die Zwangsumsiedlungen, besonders auf deren Ausmaß und die Leiden der Bevölkerung machten die Bürgerrechtsorganisation Black Sash, der Südafrikanische Kirchenrat und das "Surplus Peoples Project" aufmerksam.

Die Regierungen zerstörten ganze Siedlungen in den Townships, um so die Schwarzen zur Umsiedlung, welche beispielsweise auf dem Native Resettlement Act von 1952 basierte, zu zwingen. Lediglich vorübergehende Aufenthalte der genehmigten Arbeitskräfte in den Unterkünften der Townships waren gewollt und geduldet. Nach Auffassung der herrschenden Politik waren diese Personen nur Gäste in den „weißen“ Gebieten mit einer patriarchalisch gewährten Arbeitserlaubnis. Dahingehend orientierte die Bantu Administration 1967 in einer Direktive die Lokalbehörden darauf, dass keine „größere, bessere, attraktivere und luxuriöse Bedingung“ zu schaffen sei. Es müsse „bedacht werden, dass ein städtisches Bantu-Wohngebiet kein Heimatland, sondern Teil eines weißen Gebietes ist. Wenn diese Bedingungen zur Folge haben, den Bantu nicht nur an einen fremden Geschmack zu gewöhnen, sondern ihm auch einen Luxus aufzwingen, den sein Heimatland nicht bieten kann, und ihn so von dem entfremdet, was das Seinige ist“.

Besonders die städtischen Ballungsräume waren von Zwangsumsiedlungen ("urban relocation") betroffen. Nach im Jahre 1977 veröffentlichten Forschungsergebnissen gab es fünf Phasen der mit staatlichen Maßnahmen betriebenen Aussiedlung der schwarzen Bevölkerung aus den Städten. Der "Natives (Urban Areas) Act" von 1923 beförderte die Auflösung von Slums und sah die vollständige Aussiedlung der schwarzen Bevölkerung aus den „weißen“ Gebieten vor. In diesem Zusammenhang wurde dafür das „Prinzip der Unbeständigkeit“ proklamiert. Eine weitere Phase bildete das Compound-System im Bergwerkssektor und für die Zuckerrohrplantagen in der Provinz Natal. Die dritte Phase entwickelte sich nach dem Erlass des "Group Areas Act" von 1950, wodurch eine forcierte Umsiedlung und Slumauflösung im Umfeld der städtischen Ballungsräume betrieben wurde. Die nächste Phase ereignete sich in den 1960er Jahren. In diesem Zeitraum baute die Regierung kleine Siedlungshäuser in den Homelands. In den „weißen“ Gebieten sollte durch einen limitierten und separaten Hausbau für Schwarze die Anwesenheit einer schwarzen Arbeitsbevölkerung gezielt reguliert werden. Im Sprachgebrauch der Bantu Administration als „unproduktiv“ angesehene Personen, wie Ältere, Witwen u. a., waren ab 1967 in die vorgesehenen Schwarzengebiete zu deportieren. Im Verlauf der fünften und letzten Phase in den 1970er Jahren begann die Urbanisierung der Homelands unter der Kontrolle des "South African Bantu Trust", die sich im Gleichschritt mit der Entwicklung von Industriestandorten in denselben Regionen vollzog.

Die auch inhaltlich unterschiedlichen Schulsysteme, mit jeweils abgestufter Ausstattung und Qualifikation des Lehrkörpers, waren mitverantwortlich für ungleiche Zukunftschancen in Beruf, Kultur und sozialen Zusammenhängen. Das Gesetz Bantu Education Act von 1953 setzte die Rahmenbedingungen für eine einheitlich staatlich kontrollierte und geringwertige Schulbildung. Die für eine Hochschulausbildung erforderlichen Voraussetzungen erreichte nur eine ganz geringe Zahl nichtweißer Personen. Das Ziel der so genannten „Bantubildung“ bestand in der systematisch geplanten und statisch verankerten Entwicklung einer großen, wenig gebildeten Bevölkerungsschicht, die als Niedriglohnkräfte der weißen privilegierten Minderheitsbevölkerung Südafrikas im Arbeitsmarkt nicht zur Konkurrenz erwachsen konnten. Die freien Schulen der zumeist kirchlichen Träger, einst die alternative Chance zu einer besseren Bildung für Schwarze und Farbige, wurden mit dem "Bantu Education Act" in dieser Eigenschaft liquidiert und einer staatlichen Aufsichtsverwaltung unterstellt.

Schon vor dem Ende der Apartheid formierten sich im Land Positionen und Aktivitäten zu einer bildungspolitischen und pädagogischen Alternative zum herrschenden und repressiv kontrollierten Staats-Bildungssystem. Die sich auf diesem Feld abzeichnenden Veränderungen gingen mit dem Erstarken der Black-Consciousness-Bewegung einher. Als 1977 der Pädagoge Es’kia Mphahlele aus dem Exil nach Südafrika zurückkehrte, befasste dieser sich mit dem Konzept der "alternative education". Seine an der Witwatersrand-Universität aufgenommene Lehrtätigkeit ließ ihm dazu den erforderlichen Spielraum. Dabei bezog er sich beispielsweise auf Arbeiten von Paulo Freire. Im Jahre 1981 formulierte Mphahlele im Verlauf eines Interviews eine kritische Bestandsaufnahme des staatlichen Bildungssystems:

Damit wurde der neue Ansatz einer Befreiungs-Pädagogik in den politischen Diskurs um die „getrennte Entwicklung“ innerhalb Südafrikas Bildungssystem eingebracht, die dabei als zentrales Ziel den Abbau des „Kolonialismus in den Köpfen“ verfolgte.

Auf einem Kongress des "National Education Crisis Committee" (NECC) in Durban am 29. März 1986 verbreitete sich die Sichtweise von Mphahlele weiter. Zwelakhe Sisulu erklärte: „Wir fordern nicht mehr die gleiche Erziehung, wie sie die Weißen haben; denn das ist Erziehung zur Herrschaft. 'People’s education' dient dem Volke als ganzen, ist Erziehung, die befreit, ist Erziehung, die das Volk in die Lage versetzt, sein Leben selbst in die Hände zu nehmen. [...] Wir sind nicht willens, irgendeine Alternative zur 'Bantu Education' zu akzeptieren, die dem Volke von oben auferlegt wird. [...] Alternativen, [...] die sicher stellen sollen, daß die Ausbeutung durch ausländische Monopole weitergeht.“

Das Bildungssystem für die schwarze Bevölkerung (für Coloureds und Inder gab es gesonderte Regelungen) sah keine einheitliche Pädagogenausbildung vor. Im Jahr 1985 beschäftigte das staatliche (Bantu-)Schulsystem 45.059 Lehrer, von ihnen waren 42.000 unterqualifiziert. Nur 3,6 Prozent verfügten über ein fachbezogenen Universitätsabschluss und 70 Prozent hatten nicht einmal einen eigenen Schulabschluss auf Standard 10 oder höher (Gymnasium umfasst "Grade 8" bis "Grade 12"). Die Quote für unterqualifizierte Lehrer an Schulen für weiße Schüler lag überwiegend im einstelligen Prozentbereich.

Der Spro-cas-Bericht von 1971 fasste die politisch in Kauf genommenen Schwächen des staatlichen Bildungssystems für die schwarze Bevölkerung am Beispiel des Homelands Bophuthatswana mittels markanter Punkte zusammen:

Die starken Einschränkungen eines freien Hochschulzuganges für Schwarze führten im Rahmen eines Sonderweges schließlich zu einer mit internationalen Hilfsmitteln und Lehrkräften seit 1978 arbeitenden Bildungseinrichtung des ANC in Tansania, die Studiengänge mit international anerkannten Abschlüssen anbot.Im Jahre 1983 begann die Vista University in verschiedenen südafrikanischen Städten ihre akademische Ausbildungstätigkeit für Schwarze, jedoch als eine Einrichtung der rassenpolitisch konzipierten Bildungspolitik im Apartheidsstaat. Für die indischstämmige Bevölkerungsgruppe gab es in Durban seit 1962 das "University College for Indians" und später die daraus entstandene Universität von Durban-Westville. Das Hochschulstudium für Coloureds war seit 1959 am "University College of the Western Cape" möglich.

Die Apartheidpolitik war hauptsächlich ein Mittel zur Sicherung wirtschaftlichen Interessen der weißen Bevölkerungsminderheit. Gesetzliche Einschränkungen und im Lande verteilte Arbeitsagenturen erzielten eine wirkungsvolle Lenkungswirkung, die den Interessen der Industrie diente. Die weitgehend ohne grundhafte Berufsausbildung mit Zertifikat abgeschlossene versehene schwarze Bevölkerung war in ein komplexes System der Wanderarbeit eingebunden, das ihnen ein Leben auf nur geringsten Standards ermöglichte. Gesetzlich ausgeschlossene Streik- und Tarifverhandlungsrechte machten sie zu einer beliebig verfügbaren und im Sinne der Arbeitgeber effizient einsetzbaren Masse von Billiglohnempfängern. Die Bildung von Gewerkschaften war zwar nicht verboten, aber in der Praxis unterlagen solche Aktivitäten starken Repressionen. Im Jahr 1972 wandte sich der "South African Congress of Trade Unions" (SACTU) mit einem umfassenden Themenkatalog an die internationale Gewerkschaftsbewegung, ihn bei seinen Bemühungen um Herstellung grundlegender Arbeitnehmerrechte zu unterstützen. Aktive Mitglieder des SACTU erlitten Verfolgung mit allen Repressionsmitteln des Apartheidsstaates. Auf der Grundlage des "Industrial Conciliation Amendment Act (Act No 94 / 1979)" ließ die Apartheidsregierung 1979 erstmals Lehrlingsausbildungsgänge für Schwarze zu. Zudem erhielten nun schwarze Arbeiter den Status von Angestellten, was ihnen zugleich Arbeitnehmerrechte verlieh. Ausgenommen davon waren Wanderarbeiter und ausländische Arbeitsmigranten, die vorrangig aus Mosambik kamen.

Um die Ziele der Apartheid umsetzen zu können, war ein riesiger Verwaltungsapparat notwendig. Dieser ging aus der "Native Administration" der ehemaligen Staatsverwaltung nach britischem Muster hervor und erlangte als Bantu Administration zeitweilig einen großen Einfluss. Diese Eingeborenenverwaltung bildete eine weitgehend autarke Parallelstruktur zu allen anderen öffentlichen Verwaltungen.

Das Justizsystem von Südafrika wurde in der Apartheidsperiode mit Handlungsmöglichkeiten versehen, die rechtsstaatlich fragwürdig sind. Beispielsweise ermöglichte eine so genannte Sobukwe-Klausel aus dem Jahre 1963 die Haftfortsetzung auf alleinige ministerielle Anordnung hin, ohne eine erneute richterliche Entscheidung einholen zu müssen. Im Jahr 1976 reaktivierte man dieses Instrument mit verschärften Möglichkeiten, wodurch auf der Grundlage des "Internal Security Amendment Act (Act No 79 / 1976)" die zeitlich unbegrenzte Ingewahrsamnahme "(preventive detention)" ohne Richterentscheidung nun nicht nur bei Häftlingen, sondern auch bei jeder anderen Person möglich wurde, falls sie nach subjektiver Sicht des Justizministers eine „Gefahr“ für die Sicherheit und öffentliche Ordnung darstellte. Die Unterrichtung der Betroffenen über die Gründe ihrer Vorbeugehaft war hierbei nicht zwingend vorgeschrieben. Ein mit dem Gesetz geschaffenes "Review-Committee" konnte Empfehlungen auf Entlassung aus dieser Internierung aussprechen, die es aber nur in wenigen Fällen formulierte. Zur Anwendung der präventiven Ingewahrsamnahme kam es im Juli 1976 in Transvaal und im August im gesamten Staat, so dass im Oktober desselben Jahres bereits 123 Apartheidkritiker präventiv in Gefängnissen interniert waren. Einige setzte man später unter die Bannungsverfügung und andere verurteilte man auf der Basis des "Terrorism Act" "(General Laws Amendment Act, Act No 83 / 1967)" und weiterer Sicherheitsgesetze zu Haftstrafen.

Die "Security Branch" genannte Sonderpolizei war Teil der South African Police; ihre einzelnen Dienststellen wurden bedarfsweise bis in die zivilen Gemeindestrukturen aufgegliedert. Zur Ausweitung der repressiven Sicherungsmaßnahmen der Apartheidsdoktrin in der südafrikanischen Innen- und Außenpolitik entwickelte sich unter dem 1972 geschaffenen State Security Council (deutsch etwa: Staatssicherheitsrat) ein sich immer weiter verzweigendes System von Substrukturen, die im National Security Management System (NSMS) zusammengefasst waren. Neben der geheimdienstlich organisierten Beobachtung von Antiapartheidsaktivitäten in zivilen und paramilitärischen Zusammenhängen sowie der Sammlung von Informationen über ihre Netzwerke, ergriffen die damit verbundenen Dienststellen und Einsatzgruppen viele operative Maßnahmen, teilweise mit dem Ziel einer Strategie der Spannung. Als spektakuläre Fälle können beispielsweise Mordanschläge im Ausland auf prominente Aktivisten der Antiapartheidsbewegung gelten, wie in den Fällen von Albie Sachs oder Ruth First sowie die systematische Bedrohung von Familienangehörigen und Personen aus dem Umfeld der Zielpersonen. Die dafür häufig genutzte Organisationsstruktur war die Sondereinheit C1, die nach ihrem Sitz als "Vlakplaas" bekannt wurde und unter der Führung des Offiziers Eugene de Kock stand. Das Civil Cooperation Bureau war seitens des Militärs mit verdeckten Destabilisierungsaktionen befasst. Dabei induzierten geheime „Sicherheitskräfte“ Konflikte zwischen organisierten Bevölkerungsgruppen. Personelle und operative Kompetenz konnte dabei auch aus der Eingliederung ehemaliger Rhodesier aus den Selous Scouts in südafrikanische Strukturen gewonnen werden.Eine permanent angespannte Lage unter der schwarzen Bevölkerung in den Ballungszentren kam durch undifferenzierte Großaktionen der Polizei zustande, die mit taktischen „Bürgerkriegsübungen“, vorzugsweise in der Nacht und unter Einsatz von hunderten bis über tausend Polizisten, ganze Stadtviertel abriegelten und rasterartig Hausdurchsuchungen praktizierten.

Infolge der zunehmenden Militarisierung der gesamten Gesellschaft Südafrikas und den zunehmenden Kriegsaktivitäten im benachbarten Ausland gründete sich nach jahrelangen informellen Aktivitäten kleinerer Gruppen 1984 eine offizielle Vereinigung zur Abschaffung der Wehrpflicht. Diese "End Conscription Campaign" fasste das Apartheidregime im Widerspruch zu seiner "total strategy" der 1980er Jahre als eine feindliche Organisation auf und bannte sie im August 1988.

Zur Ausdehnung des rechtsfreien Raumes innerhalb der Apartheidpolitik nahm man mehrere einschränkende Eingriffe in die Pressefreiheit vor. Das 1959 erlassene Gefängnis-Gesetz (Prison Act, Act No 8 / 1959) und das Änderungs-Polizeigesetz "(Police Amendment Act, Act No 64 / 1979)" von 1979 untersagten eine unabhängige Berichterstattung, sofern sie nicht von den betroffenen Behörden selbst bestätigt wurden. Die Steyn-Kommission erarbeitete Vorschläge zur „Neuordnung“ des Mediensektors und leistete damit einen fundamentalen Beitrag zur Einschränkung der Pressefreiheit. Auf diesem Wege war nun eine unzensierte öffentliche Wahrnehmung des polizeilichen Handelns schrittweise erschwert, letztendlich unmöglich geworden. Mit dem Zweiten Änderungsgesetz zum Polizeigesetz "(Second Police Amendment Act)" im Jahr 1980 wurde sogar jegliche Berichterstattung über die als „terroristisch“ eingestuften Handlungen verboten. Darunter fielen auch die Namen der Inhaftierten. Vorgänge von Misshandlungen, Folter oder Mord konnten nun kaum noch von der Presse aufgegriffen werden und der ungeklärte Verbleib zahlreicher Personen nahm zu. Zugleich konnte niemand mehr den Umfang widerrechtlicher Ingewahrsamnahmen durch die Behörden abschätzen. John Dugard kritisierte bereits 1980 als Professor an der Witwatersrand-Universität diese Rechtspraxis, in dem er auf die dadurch geschaffenen Verhältnisse verwies, die beispielsweise eine Aufklärung der Todesumstände von Steve Biko unmöglich machen könnten. Der damalige Anwalt am Supreme Court of South Africa, Albie Sachs, war selbst über fünf Monate das Opfer eines dieser repressiven Gesetze, wonach ein Inhaftierter bis zu einer Dauer von 90 Tagen (definiert in Sektion 17 des "General Laws Amendment Act, Act No 37 / 1963") ohne richterliche Entscheidung im Gewahrsam der Sicherheitspolizei und dabei deren unkontrollierten Folterungen ausgesetzt sein konnte. Über die Misshandlungen und Folterungen von Gefangenen in Südafrika informierte ein UN-Bericht aus dem Jahre 1973.

Das 1929 gegründete South African Institute of Race Relations untersucht und dokumentiert die Entwicklung des südafrikanischen Rassismus und der institutionellen Apartheid mit vielen Einzelpublikationen und Periodika. An der Arbeit des Instituts beteiligten sich zahlreiche Apartheidskritiker.

Mehrere Kommissionen erarbeiteten im Auftrag der südafrikanischen Regierungen in den Jahren der Apartheidsperiode Empfehlungen und Konzepte, die zu konkreten Ausgestaltung der Kabinettspolitik genutzt wurden. Dazu zählten die Tomlinson-Kommission, die "Native Laws Commission" und weitere Gremien.

Die Gegenbewegungen an der Basis der Bevölkerung zum politischen motivierten Rassismus und den Apartheidsverhältnissen in Südafrika entstanden nicht erst mit der Machtübernahme der Nationalen Partei im Jahre 1948. Sie waren zu diesem Zeitpunkt bereits in vielfacher Ausprägung existent, weil die seit Jahrzehnten praktizierte staatliche Ausgrenzung der schwarzen, indischstämmigen und farbigen Bevölkerungsgruppe spürbare nachteilige Wirkungen auf diese ausübte.

Im Wesentlichen hatten die gesellschaftskritischen Positionen im politischen Emanzipationsprozess des ausgehenden 19. Jahrhunderts ihre Ursprünge an verschiedenen Missionsschulen, besonders im Wirkungsbereich der Anglikanischen Kirche. Diese Entwicklung leitet sich aus den aufklärerischen Impulsen hier tätiger Theologen und Missionare ab, wie James Stewart und Jane Elizabeth Waterston, sowie in dem daraus erwachsenen politischen Selbstverständnis führender schwarzer und indischstämmiger Persönlichkeiten. Internationale Einflüsse und Vorbilder wirkten als verstärkende Faktoren auf die Emanzipationsentwicklung innerhalb der schwarzen Bevölkerung, zu denen das US-amerikanische Tuskegee Institute zählte. Diese Einrichtung übte auf die Missionare in der damaligen Kapkolonie bei der Weiterentwicklung der Bildungskonzepte für die „nichtweißen“ Bevölkerungsgruppen eine Vorbildwirkung aus.

In den ausgehenden 1920er und den 1930er Jahren formierte sich durch die Wahrnehmung wachsender sozialer Differenzierungsprozesse innerhalb der südafrikanischen Gesellschaft unter manchen Theologen und Sozialwissenschaftlern die Bereitschaft zur kritischen Systemanalyse. Die Gründung des South African Institute of Race Relations im Jahre 1929 war ein Resultat dieser sich wandelnden Lage. Im zweiten Drittel des 20. Jahrhunderts etablierten sich in der schwarzen und indischstämmigen Bevölkerung selbstorganisierte Proteststrukturen. Das wird an der Gründung neuer politischer Organisationen, vermehrten Forderungen nach Angleichung der Bürgerrechte an die Standards der europäischstämmigen Oberschicht und in der wachsenden Bedeutung eigener Zeitungen erkennbar. Der ehemalige ANC-Präsident Zaccheus Richard Mahabane wandte sich in den 1930er Jahren gegen die zunehmende Gesetzgebung der Rassentrennung und setzte sich dazu für den gemeinsamen politischen Weg verschiedener Oppositionsgruppierungen ein. Die südafrikanische Regierung verschärfte in den 1930er und 1940er Jahren ihre rassistische Repressionspolitik. 1938 gründete sich in Johannesburg die "Non-European United Front", zu deren führenden Mitgliedern Yusuf Dadoo gehörte. Er organisierte Massenproteste gegen die zunehmende Ausgrenzung „nichtweißer“ Bevölkerungsteile.

In der Folge dieser wachsenden innenpolitischen Spannung kam es 1949 zu einem folgenreichen Wechsel an der Spitze des ANC. Junge Mitglieder erzwangen den Rücktritt des Vorsitzenden Alfred Bitini Xuma zugunsten von James Moroka und beeinflussten damit die politische Wirkung ihrer Organisation. Trotzdem galt immer noch das Primat des gewaltfreien Widerstandes, das sich noch einmal mit dem nächsten Vorsitzenden Albert Luthuli manifestierte.

Inzwischen hatte sich in Natal der Einfluss des sich an Gandhis Prinzipien orientierende South African Indian Congress (SAIC) ausbauen können und war zu einer mächtigen Kraft in Südafrika angewachsen. Die Regierung von Jan Christiaan Smuts wollte das Wahl- und Grundstücksrecht für die Inder einschränkend regeln und erregte daraufhin heftigen Widerspruch. Eine Delegation des SAIC reiste deshalb zur indischen Regierung und erreichte dort Sanktionen gegen Südafrika. Zwischen 1946 und 1948 machte die "Indian Passive Resistance Campaign" auf die ungerechten Lebensverhältnisse der indischstämmigen Bevölkerung aufmerksam.

Die Defiance Campaign zwischen 1952 und 1953 war eine von ANC, SAIC und Coloureds gemeinsam angelegte Aktion zur Einforderung von Bürgerrechten und rechtlicher Gleichbehandlung. Es folgte 1956 der international beachtete Protestmarsch von 20.000 Frauen auf die Regierungszentrale in Pretoria wegen der unbeliebten Pass-Gesetze und der sich aus weiterer Zuspitzung "(Anti-Pass Campaigns)" entwickelnde Protest im Jahre 1960 nach Vorbild von Mahatma Gandhi in Sharpeville, der durch bewaffneten Eingriff von Polizeikräften jedoch als Massaker von Sharpeville in die südafrikanische Geschichte einging.

Die Politik des gewaltfreien Widerstandes wurde während der gesamten Apartheidsperiode von den Betroffenen nicht aufgegeben, konnte jedoch im Inland nur noch sehr eingeschränkt ausgeübt werden und verlagerte sich auf Aktionen im Rahmen der internationalen Öffentlichkeit.

Bereits 1912, zwei Jahre nach der Errichtung der Südafrikanischen Union, gründeten der Anwalt Pixley Seme, die Geistlichen John L. Dube, Walter B. Rubusana sowie der Autor Sol Plaatje den Afrikanischen Nationalkongress (ANC). Obwohl von Männern aus der elitären Gesellschaft gegründet, verstand sich der ANC durchaus nicht als elitäre Organisation. Er stand grundsätzlich allen offen, egal welcher Hautfarbe, und akzeptierte sowohl das Christentum wie auch die englische Sprache. Der ANC verstand sich als schwarze Widerstandspartei, die volle Bürgerrechte forderte. Lange Zeit opponierte er friedfertig durch Boykotte und Streiks. So organisierte er in den 1920er Jahren Streiks der Minenarbeiter, um die schlechten Arbeitsbedingungen der Schwarzen zu verbessern.

Der ANC wurde immer mehr zur Massenorganisation. Hunderttausende befolgten die Aufrufe zu Demonstrationen oder Streiks. Beispielsweise im Jahre 1946, zwei Jahre vor dem Beginn der Apartheid, streikten rund 70.000 schwarze Minenarbeiter. Insbesondere gegen Passgesetze, wonach die städtischen Schwarzen jederzeit ein persönliches Dokument mit sich tragen mussten, um sich als Arbeitnehmer ausweisen zu können, protestierte der ANC durch Demonstrationen und durch das Verbrennen der umstrittenen Personaldokumente. Trotzdem standen keineswegs alle Nicht-Weißen, nicht einmal alle Schwarzen, hinter dem ANC. Etliche Schwarze sahen die Homeland-Politik der Regierung als Chance, den Rassismus endlich zu beenden und ihre Traditionen wieder zu leben.

In späteren Jahren sollten diese Meinungsverschiedenheiten insbesondere zwischen städtischen und ländlichen Schwarzen zu bewaffneten Auseinandersetzungen führen. So forderten Unruhen bei Pietermaritzburg zwischen 1987 und 1990 rund 4000 Todesopfer. Bei diesem Konflikt handelte es sich um Streitigkeiten innerhalb der Zulu. Städtische Zulu vertraten andere Ansichten als die in der Inkatha Freedom Party vereinten ländlichen Zulu. In den frühen 1990er Jahren, also bereits nach dem offiziellen Ende der Apartheid, wendeten sich die Inkatha-Anhänger dann im Besonderen gegen die Xhosa. Menschen beider Seiten verloren dabei ihr Leben.

Die Regierung versuchte, die Menschenrechtsaktivisten des ANC und anderer Gruppen immer wieder an ihrer Arbeit zu hindern, indem sie diese bannten. Gebannte waren eingeschränkt in ihrer Bewegungsfreiheit, sie durften ein genau definiertes Territorium nicht verlassen. Des Weiteren löste die Regierung häufig Treffen des ANC auf. Das geschah auf der Grundlage mehrerer Gesetze, im Zentrum dieser Jurisdiktion der Suppression of Communism Act von 1950.

Einigen Mitgliedern gingen die meist friedlichen Aktionen des ANC nicht weit genug. Sie gründeten 1959 eine weitere Widerstandsorganisation, den Pan Africanist Congress (PAC). Im Gegensatz zum ANC verwarf der PAC die offene Haltung gegenüber allen Rassen. Er positionierte sich als reine Schwarzen-Organisation und lehnte jegliche Zusammenarbeit mit den Weißen ab. Später gründete auch der ANC einen bewaffneten Flügel. Nelson Mandela selbst leitete diesen Flügel mit dem Namen Umkhonto we Sizwe, was übersetzt so viel wie "Speer der Nation" bedeutet. Umkhonto we Sizwe tat sich in den folgenden Jahren insbesondere durch Sabotageakte hervor.

Ein Jahr vor der Gründung des bewaffneten Flügels des ANC endete eine vom PAC organisierte Demonstration im Township Sharpeville in einem Blutbad, das die in Panik geratenen Polizisten anrichteten. 69 Afrikaner fanden dabei den Tod. Dieses Ereignis löste nationale Unruhen aus, welche die südafrikanische Regierung mit eiserner Faust bekämpfte. Rund 20.000 Demonstranten wurden verhaftet. In der Folge wurden sowohl der PAC als auch der ANC verboten. Beide Organisationen operierten fortan aus dem Untergrund. Führende opponierende Köpfe wie Nelson Mandela oder Walter Sisulu wurden 1964 im so genannten Rivonia-Prozess zu lebenslanger Haft verurteilt. Das Gericht warf ihnen vor allem Beteiligung an Sabotageakten vor.

In den späten 1960er Jahren entstand in Kirchen und Schulen, beeinflusst durch die Black-Power-Bewegung in den USA, die so genannte Black-Consciousness-Bewegung. Steve Biko gilt als Begründer dieser Bewegung. Hervorgerufen durch das neue Selbstbewusstsein der Schwarzen sahen sie die Kultur der Weißen nicht mehr als übermächtig. Vielmehr lehnten sie die weiße Kultur nun ab; ihre eigenen Werte hingegen hoben sie heraus. Künstler wie Miriam Makeba engagierten sich für einen weltweiten Boykott des Apartheidregimes.

Die Folgen des neuen Bewusstseins waren zum Teil heftige Studentenunruhen. Am 16. Juni 1976 boykottierten Schüler in Soweto den Unterricht. Dies stand im Zusammenhang mit der versuchten, zwangsweise durchgeführten Einführung der bei Schwarzen verhassten Sprache Afrikaans. Mit dem Boykott begann der Aufstand in Soweto. Durch brutale Polizeieinsätze verloren in wenigen Tagen 500 bis 1000 Schwarze ihr Leben und viele Kinder und Jugendliche wurden inhaftiert. Weltbekannt ist das Foto des sterbenden 12-jährigen Hector Pieterson in den Armen eines Mitschülers. Danach nahm der bewaffnete Widerstand sprunghaft zu. Die in den nächsten zwei Jahren folgenden Unruhen verunsicherten das Land. Hunderte von Schwarzen wurden von der Polizei getötet. Die Schüler und Studenten fanden Unterstützung bei Hunderttausenden von schwarzen Arbeitern. Für die südafrikanische Wirtschaft nahm dies verheerende Ausmaße an. Einige unbedeutendere Gesetze der Apartheid wurden gelockert, um dem Unmut der Schwarzen zu begegnen.

Einige Länder unterstützten das Apartheidregime in bestimmten Teilbereichen. Beispielsweise setzten die USA 21 Mal im Sicherheitsrat ihr Veto ein, um Resolutionen gegen Südafrika zu verhindern, die zumeist eine totale Wirtschaftsblockade gegen das Land zum Inhalt hatten, das waren 13 Prozent der Gesamtanzahl ihrer Vetos. Allerdings waren die USA aber auch die treibende Kraft hinter der Verabschiedung des ersten Waffenembargos gegen Südafrika durch die UN im Jahr 1963.
Auch Firmen wie IBM haben mit logistischen und technologischen Mitteln das Regime unterstützt. Die Bedeutung Südafrikas für die USA lag unter anderem in den Uranvorkommen des Landes.

Auch die Bundesrepublik unterhielt während der Apartheid Wirtschaftskontakte zu Südafrika. Der damalige Außenminister Willy Brandt, in dessen Partei die Beziehungen zu Südafrika höchst umstritten waren, begründete dies damit, „daß man Handel und Politik nicht ohne Not koppeln soll“. Einer der führenden deutschen Politiker, der durch seine Nähe zur südafrikanischen Regierung in der Zeit der Apartheid auffiel, war Franz-Josef Strauß. Er befürwortete die Apartheid und soll bei einem Besuch in Südafrika gesagt haben: „Die Politik der Apartheid beruht auf einem positiven religiösen Verantwortungsbewußtsein für die Entwicklung der nichtweißen Bevölkerungsschichten. Es ist deshalb falsch, von der Unterdrückung der Nicht-Weißen durch eine weiße Herrenrasse zu sprechen.“ Deutschen Konzernen wird vorgeworfen, sich an der Apartheid in Südafrika beteiligt zu haben. In einem seit 2002 bei Bundesgerichten in den USA anhängigen Prozess, der von Apartheid-Opfern angestoßen und u. a. von Desmond Tutu unterstützt wurde, wurden 50 internationale Konzerne, darunter auch die Daimler AG und mehrere deutsche Banken, beschuldigt, durch ihre Geschäfte die Verbrechen des Apartheid-Regimes unterstützt zu haben. Die Kläger beriefen sich auf ein Gesetz von 1789, nach dem ausländische Bürger in den USA Klagen einreichen können, wenn internationales Recht verletzt wurde. General Motors einigte sich 2012 mit den Klägern auf einen Vergleich ohne Schuldeingeständnis. Ein Berufungsgericht verwarf die Klage im August 2013 einstimmig mit einer Berufung auf eine Entscheidung des Obersten Gerichtshofs der Vereinigten Staaten, nach der das Gesetz in dem Fall nicht anwendbar sei. Die Verteidigung kann nun die Einstellung des Verfahrens beantragen.

Eine Studie von 1999 kam zu dem Ergebnis, dass Deutschland mit 27,3 Prozent aller Auslandsschulden des öffentlichen Sektors der wichtigste Direktfinanzier des Apartheidregimes war und „[…] in herausragender Weise den Apartheidstaat direkt, ebenso wie die strategisch wichtigen Staatskonzerne der Apartheid mit Finanzkapital bedient hat“.

Die tatsächlichen Apartheidsverhältnisse in Südafrika waren in Deutschland bekannt und in Teilen der Bevölkerung ein Diskussionsthema, wie nach Unterstützungsnoten aus dem Kreis der Evangelischen Frauenarbeit und dem damit verbundenen Früchteboykott zu schließen ist. Andererseits fand Südafrika in Mitteleuropa auch Unterstützer seiner Politik. Eine 1974 in deutscher Sprache herausgegebene Schrift des Informationsministeriums in Pretoria wandte sich an deutschsprachige Leser und setzte sich rechtfertigend mit der internationalen und inneren Kritik an der Apartheid auseinander. Darin wurden die „Anti-Apartheid-Bewegung“ und die „Vertreter der Terroristenorganisationen und der Weltkirchenrat“ zu Staatsfeinden erklärt. Dem Weltkirchenrat bescheinigt die Propagandaschrift, „den terroristischen Bewegungen in Afrika sowohl geistige Unterstützung als auch Gelder“ zu liefern. Ferner meinten die ungenannten Autoren unter den Apartheid-Kritikern „bornierte Geister“ zu finden und dass „viele selbsternannte Experten“ prophezeiten, „dass die südafrikanische Regierungspolitik in einer Katastrophe enden würde“. Gleichzeitig gaben sie einen Einblick in ihre Auffassung von Pressefreiheit, indem sie in Hinblick auf kritische Berichterstattungen „von den alten Dickschädeln, die in Presse, Rundfunk und Fernsehen immer wieder das gleiche tun“ sprachen.

Positive Haltungen zu den Apartheidsverhältnissen, insbesondere zu den damit beabsichtigt herbeigeführten sozio-ökonomischen Segregationsprozessen, drangen bis in wissenschaftliche Arbeiten Deutschlands ein und wurden als „räumliche Auswirkungen einer politischen Idee“ gekennzeichnet. Das geschah in der Weise, dass beispielsweise die Etablierung der Homelands als „Hinführung zur innenpolitischen Autonomie“ bezeichnet wurde oder die dort geplanten Ortsgründungen als „[…] eingerichtet als Ansatzpunkte städtischer Entwicklung (s. Smit and Boysen 1977)“, um „im Laufe der Zeit eine solche Attraktivität zu entwickeln, dass aus den weißen Gebieten eine Rückwanderung in diese neuen Städte einsetzt, sowie als Ansatzpunkte einer industriellen Entwicklung innerhalb der Homelands zu dienen“.

Die Folgen dieser Siedlungspolitik, beispielsweise das Fehlen von Anschlüssen vieler privater Haushalte an die nach 1994 erheblich verbesserte Trinkwasserversorgung, die ungenügende Ausstattung mit medizinischen und schulischen Einrichtungen in vielen Townships (wie z. B. Mdantsane) und im ländlichen Bereich sowie die bis heute (2009) anhaltende Situation massiver Wanderarbeiteranteile unter der schwarzen Bevölkerung, führen noch nach über einem Jahrzehnt des Endes der Apartheid zu innenpolitischen Spannungen und einem bedrohlich anwachsenden Gewaltpotenzial.

Auch in Großbritannien fand das Apartheidregime Unterstützung für seine Politik. Margaret Thatcher bezeichnete den ANC in einer Pressekonferenz auf der Commonwealth-Konferenz in Vancouver im Jahre 1987 als „terroristische Organisation“ und bediente im selben Statement antikommunistische Stereotype des Kalten Kriegs. Im selben Jahr erschienen Mitglieder der "Young Conservatives", der Jugendorganisation der Conservative Party, auf einem Parteitag mit "Hang Nelson Mandela!"-Abzeichen (deutsch: „Erhängt Nelson Mandela!“).

Schweizer Banken und Industrieunternehmen ignorierten wiederholt und massiv die UN-Sanktionen und verlängerten dadurch die Existenz des Apartheidregimes. Die Schweizer Regierung äußerte, wenn überhaupt, nur halbherzig Kritik. Dagegen gab es sogar enge Kontakte auf diplomatischer Ebene. Seit 1980 hatte der südafrikanische Militärattaché seinen Dienstsitz in Bern, zuvor noch in Rom, Köln und Wien; bereits zu dieser Zeit verweigerten andere Staaten dessen Akkreditierung.

Die Beziehungen Israels zu Südafrika verstärkten sich insbesondere, als Israel nach dem Sechstagekrieg international zunehmend in Isolation geriet. Vor allem auf militärischem Gebiet entwickelte sich eine enge Zusammenarbeit. Dazu gehörten neben konventionellen Waffenlieferungen auch lange geheim gehaltene Kooperationsprojekte zu Atomwaffen.

In vielen Ländern gab es Unterstützung für die Bevölkerungsmehrheit Südafrikas im Kampf gegen die Apartheid. Sowohl der ANC, die "Black Consciousness Movement" als auch kirchliche Organisationen hatten viele Kontakte, zum Beispiel zum Weltkirchenrat, den Vereinten Nationen und kleineren Organisation wie der Anti-Apartheid-Bewegung in Deutschland und der Evangelischen Frauenarbeit in Deutschland. Dazu kamen viele lokale Gruppierungen, die oft mit Dritte-Welt-Läden zusammenarbeiteten. Unterstützt wurden diese Gruppen auch aus der SPD. So forderten die Bundestagsabgeordneten Lenelotte von Bothmer und Hans-Jürgen Wischnewski zum Beispiel 1973 eine Einschränkung der wirtschaftlichen Beziehungen Deutschlands zu Südafrika.

Um auf die Situation in Südafrika aufmerksam zu machen, wurde insbesondere zum Boykott südafrikanischer Produkte aufgerufen. Die in Großbritannien sehr aktive "Anti-Apartheid Movement", woran auch Ambrose Reeves und Trevor Huddleston maßgeblich beteiligt waren, erzielte damit erhebliche Erfolge. Deren Wirkungen waren so deutlich, dass der britische Premierminister Harold Macmillan in seiner so genannten "Wind-of-Change-Rede" vor beiden Kammern des südafrikanischen Parlaments am 3. Februar 1960 in Kapstadt darauf hinwies. Zur Unterstützung von politisch Verfolgten und ihren Familien entstanden bereits 1956 finanzielle Hilfsstrukturen zwischen Südafrika und dem Vereinigten Königreich, die sich später mit dem International Defence and Aid Fund for Southern Africa weltweit ausbreiteten.

Im Zuge dieser internationalen Protestentwicklung entstanden viele kleinere Aktionen unter anderem auf den Deutschen Evangelischen Kirchentagen. Der Früchteboykott wurde von Südafrikanern angeregt und dann von den lokalen Gruppen in ihren jeweiligen Ländern propagiert. Neben dem Boykott der Früchte aus Südafrika wurde auch gegen die die Apartheid unterstützenden Geschäfte deutscher Großbanken protestiert.

Die Bemühungen des ANC im Ausland zur Verdeutlichung der Apartheidsverhältnisse im damaligen Südafrika bewirkten an vielen Orten der Welt Reaktionen von der Gewährung seiner Aktivitäten auf fremden Territorien bis zur aktiven Unterstützung konkreter Projekte. Beispielsweise unterhielt der ANC in London seine wichtigste Auslandsvertretung und sammelte auf diese Weise politische, wissenschaftliche, logistische und finanzielle Unterstützung für zahlreiche Vorhaben. Eines dieser Projekte bestand in einer umfangreich gegliederten Bildungseinrichtung auf dem Staatsgebiet von Tansania. Zwischen 1978 und 1992 wurde dort im Solomon Mahlangu Freedom College eine Schul- und Hochschulbildung durch einen international zusammengesetzten Lehrkörper für ausgewählte Südafrikaner gewährleistet.

Die von der indischstämmigen und farbigen Bevölkerungsgruppe Südafrikas initiierten Antiapartheidsbestrebungen ermöglichten ihrerseits weitere Unterstützeraktivitäten, wie beispielsweise Studiermöglichkeiten in Indien durch direkte Protektion der Staatspräsidentin Indira Gandhi oder neue Schulprojekte in Slumsiedlungen der damaligen Provinz Natal. Eine zentrale Rolle spielte innerhalb der Organisation dieses politischen Prozesses die südafrikanische Soziologieprofessorin Fatima Meer.

Der Iran versah die Reisepässe seiner Bürger mit einem Stempel, welcher die Einreise iranischer Bürger in Südafrika untersagte. Länder wie Tansania untersagten die Einreise, wenn im Pass ersichtlich war, dass der Inhaber sich in Südafrika aufgehalten hatte.

Die Vereinten Nationen haben seit ihrer Gründung die Apartheid als gravierendes Beispiel einer systematischen Rassentrennung verurteilt. Die Mehrheiten in den Organen der Vereinten Nationen haben sich vor allem durch das Wachstum der Vereinten Nationen durch den Beitritt vieler Staaten der Dritten Welt auf der XV. Sitzung der Generalversammlung der UN (1959) zuungunsten der Politik der Apartheid verschoben. Die Veränderung der Mehrheitsverhältnisse beeinflusste auch die Haltung der westlichen Staaten, inklusive der Bundesrepublik, die ab den 1970er Jahren vermehrt Resolutionen der Generalversammlung gegen die Apartheid unterstützten, sofern diese nicht zu Gewalt aufriefen oder Anti-Apartheidsorganisationen erwähnten, die als marxistisch eingeschätzt wurden.

Zu den wichtigsten Reaktionen zählt die "Resolution 1761" aus der XVII. Sitzung der UN-Generalversammlung vom 6. November 1962 unter Leitung von Muhammad Zafrullah Khan bezüglich der Apartheidpolitik der Südafrikanischen Regierung, die mit dieser Erklärung unter Aufruf zu Sanktionen verurteilt wurde.

Von den Vereinten Nationen wurde die Entwicklung der Apartheidpolitik kontinuierlich beobachtet. Auf dem "6. Kongress der Vereinten Nationen für Verbrechensverhütung und die Behandlung Straffälliger" zwischen dem 25. August und 5. September 1980 in Caracas wurde über den Fortschritt der am 18. Juli 1976 in Kraft getretenen "Internationale Konvention über die Bekämpfung und Bestrafung des Verbrechens der Apartheid" berichtet. Bis zum 1. Mai 1980 hatten sie 56 Staaten ratifiziert oder waren ihr beigetreten. Die UN-Menschenrechtskommission forderte die "UN-Sonderkommission gegen die Apartheid" "(Special Committee on the Policies of Apartheid of the Government of the Republic of South Africa)" auf, zusammen mit aus Südafrika stammenden Experten eine Liste zu erstellen, worin Personen, Institutionen, Organisationen und offizielle Repräsentanten der Republik Südafrika erfasst werden sollten, die für Verbrechen nach Artikel 2 der internationalen Konvention als verantwortlich angesehen wurden.

Initiiert durch die Vereinten Nationen, gab es einen weitgehenden Boykott kulturellen Austauschs mit Südafrika. Paul Simon machte mit seinem 1986 erschienenen Album Graceland, an dem zahlreiche südafrikanische Musiker mitwirkten, auf die Apartheid aufmerksam. Er wurde aber gleichzeitig kritisiert, weil er dem Boykott nicht gefolgt war.

Die Europäische Gemeinschaft (EG) hatte sich 1985 im Rahmen der europäischen politischen Zusammenarbeit auf eine abgestimmte Haltung zu Südafrika festgelegt und ein Sonderprogramm zugunsten von Opfern der Apartheidpolitik entwickelt, das man ab 1986 praktizierte. Am 16. September 1986 beschlossen die Außenminister der EG gemeinsame Sanktionen, die unter anderem Investitionen in Südafrika sowie den Import von südafrikanischem Stahl, Eisen und Goldmünzen (Krugerrand) verboten. Das im Entwurf vorgesehene Verbot des Imports von Kohle – zu jenem Zeitpunkt gingen zwei Drittel der Kohleexporte Südafrikas in EG-Länder – wurde auf Betreiben der deutschen und unterstützt von der portugiesischen Regierung nicht in den beschlossenen Text aufgenommen.

Die Proteste der Schwarzen sowie andere Faktoren ließen die Apartheid ab 1974 immer mehr bröckeln. Die Vollversammlung der UN nahm im Dezember 1973 die „Konvention zur Bekämpfung und Ahndung des Verbrechens der Apartheid“ an, die 1976 in Kraft trat. Die Präambel dieser Konvention betonte, dass Apartheid als Verbrechen gegen die Menschlichkeit einzustufen ist. Straftatbestände wurden benannt, so dass mit dieser Konvention eine Strafbarkeit nach internationalem Völkerrecht begründet wurde. Die burische Regierung näherte sich in langsamen Schritten den schwarzen Vorstellungen an. Die schwarze Opposition wurde immer stärker, obwohl ihre bekanntesten Führer im Gefängnis saßen. Höhepunkte des Widerstandes in den 1970er Jahren waren Streiks in Natal (1973) sowie der Aufstand in Soweto 1976. Dem schwarzen Widerstand begegnete die Regierung mit Notmaßnahmen, die allerdings die staatlichen Kapazitäten sprengten. Die Kosten der Apartheid waren nicht mehr länger tragbar.

Der ANC wurde vom Westen während des Kalten Krieges als revolutionär und prokommunistisch angesehen. Trotz gewisser Sanktionen stützten die USA und Westeuropa das weiße Apartheidregime als Bollwerk gegen den Kommunismus, auch weil Südafrika bedeutende Uranvorkommen hat. Nachdem die portugiesischen Kolonien Moçambique und Angola unabhängig und zum Schauplatz blutiger Kriege wurden, erschien die Unterstützung Südafrikas noch wichtiger. Nach dem Kalten Krieg verlor dieses Element freilich seine Bedeutung, und das alte Regime Südafrikas wurde vom Westen fallen gelassen.

Weiteres Ungemach erfasste Südafrika 1983 mit Beginn des Verfalls des Goldpreises auf dem Weltmarkt. Die schon durch die europäischen und amerikanischen Sanktionen geschwächte ökonomische Situation verschärfte sich damit weiter.

Die zunehmend verbesserte Organisation der nicht-weißen Opposition, die in den 1980er Jahren faktisch die Verwaltung der Townships übernahm, führte zum permanenten Ausnahmezustand von 1985 bis 1990. Angestoßen durch die Dakar-Konferenz im Juli 1987, bei der sich Vertreter des ANC im Exil mit einer Gruppe weißer Oppositioneller aus Südafrika über Möglichkeiten einer friedlichen Überwindung der Apartheid ausgetauscht hatten, begann ein teilweise geheimer Dialog mit den Führern des ANC im Exil über die Zukunft Südafrikas nach der Apartheid.

1989 trat Frederik Willem de Klerk die Nachfolge von Pieter Willem Botha als südafrikanischer Staatspräsident an. De Klerk nahm sogleich Verhandlungen mit dem noch immer inhaftierten ANC-Führer Mandela auf. Er stellte Mandela die sofortige Freilassung in Aussicht, wenn dieser gewisse Konditionen, wie beispielsweise die Abkehr vom bewaffneten Widerstand, annähme, worauf Mandela jedoch nicht einging. De Klerk ließ Mandela aufgrund des steigenden Druckes zusammen mit den übrigen politischen Gefangenen im Jahre 1990 frei. Die beiden Widerstandsparteien ANC und PAC wurden wieder legalisiert.

Aufgrund dieser in ihrer Summe bedeutsamen Faktoren, also des Widerstandes der Schwarzen, des internationalen Druckes, der ökonomischen Krise, des Wechsels der Regierungsführung von Botha zu de Klerk sowie der Standhaftigkeit Mandelas bei den Verhandlungen mit de Klerk, brach die weiße Autorität in den frühen 1990er Jahren Schritt für Schritt zusammen. Bei einem Referendum im März 1992 sprachen sich 68,7 Prozent der Weißen für die Abschaffung der Rassentrennung aus.

Der Reformierte Weltbund schloss die niederländisch-reformierte Kirche Südafrikas aus und erhöhte so den moralischen Druck auf einen Wandel.

De Klerk hob wesentliche Gesetze auf, die als Pfeiler der Apartheid galten. Darunter waren der Population Registration Act, der Group Areas Act und der Land Act. Die Homelands existierten allerdings weiter; diesbezüglich änderte sich nur wenig.

Die Übergangsphase von der Apartheid zur rechtlichen Gleichstellung dauerte von 1990 bis 1994. Während dieser Zeit wurden die verbliebenen Gesetze der Rassentrennung beseitigt. Alle in Südafrika wohnhaften Menschen konnten sich frei und ohne Restriktionen bewegen. Viele Schwarze nutzten diese Chance und zogen in Städte. Des Weiteren war die Übergangsphase geprägt durch blutige Unruhen zwischen der Inkatha-Partei Mangosuthu Buthelezis und dem ANC. Buthelezi, Führer des Homelands KwaZulu, sah durch das neue Staatssystem seine Macht bedroht. Die Unruhen dauerten von 1989 bis 1994 und forderten insgesamt etwa 7.000 Tote. Nebst Buthelezi standen auch Lucas Mangope und Oupa Gqozo, die Führer der Homelands Bophuthatswana und Ciskei, dem neuen System negativ gegenüber. Andere Homeland-Verantwortliche kooperierten mit den Plänen des ANC und versuchten, opportunistisch eine gute Position in den neuen Machtverhältnissen zu ergattern.

Die neue Verfassung sollte 1994 in Kraft treten. Danach würden alle fünf Jahre Regierungswahlen stattfinden. Dazu sollte das Land in neun statt in vier Provinzen unterteilt werden.

Im letzten Moment schwenkte Buthelezi ein, nachdem ihm eine wichtige Position in der neuen Regierung zugesagt worden war. So kam es 1994 zu den ersten allgemeinen Wahlen Südafrikas. Der ANC gewann mit 62,6 Prozent überragend, es folgte die Nationale Partei (NP) mit 20,4 Prozent und die Inkatha Freedom Party mit 10,5 Prozent. Mandela wurde zum ersten Präsidenten im neuen System ernannt. Ihm zur Seite standen zwei populäre Vizepräsidenten, de Klerk von der NP und Thabo Mbeki vom ANC. Buthelezi wurde Premier der Provinz Kwazulu-Natal, er konnte seine Macht also über die bisherige Homeland-Grenze ausdehnen.

Die vorausgegangenen Unruhen hatten Südafrika in eine ökonomische Krise gestürzt. Diese brachte eine hohe Staatsverschuldung mit sich. Im Weiteren sollten die Ungleichheiten zwischen den Rassen beseitigt werden. Dies würde unter anderem bessere Schulen und eine bessere Gesundheitsversorgung für Schwarze bedeuten. Beides war jedoch mit hohen Kosten verbunden. Unterschiedlichste Interessen führten zu verschiedenen Landstreitigkeiten. Schwarze, die während der Apartheid ihr Land aufgeben mussten und gezwungen worden waren, in die Homelands zu ziehen, forderten ihr Land zurück. Die nun dort ansässigen Weißen oder Industriebetriebe machten ihre jüngeren Rechte geltend.

1999 stieg Mbeki vom Vizepräsidenten zum Präsidenten auf. Er intensivierte in der Folge die Privatisierung von Staatsbetrieben. Dies führte zu Stellenabbau und zu teureren Strom- und Wassertarifen. Immer mehr schwarze Arbeiter, die vor allem unter diesen Maßnahmen zu leiden haben, werden zunehmend unzufrieden mit der Politik des ANC. Sie werfen ihm vor, dass der ANC zwar von der linken Arbeiterklasse gewählt worden sei, jedoch im Interesse der rechten Bourgeoisie regiere.

Mandela und de Klerk erhielten 1993 den Friedensnobelpreis.

In Anlehnung an das südafrikanische Regime wird heute eine systematische Rassendiskriminierung, insbesondere durch einen Regierungsapparat, als Apartheid bezeichnet.

Die Wahrheits- und Versöhnungskommission (Truth and Reconciliation Commission (TRC)) wurde eingerichtet, um politisch motivierte Verbrechen zu verhandeln, die während der Zeit der Apartheid begangen worden waren. Sie hatte die Rettig-Kommission von 1991 in Chile zum Vorbild. Sie geht in ihrer Entstehung zurück auf eine Initiative des ANC und des damaligen Justizministers Abdullah Omar im Jahr 1994 und wurde im Januar 1996 durch Präsident Nelson Mandela eingesetzt. Vorsitzender war Desmond Tutu. Die Wahrheits- und Versöhnungskommission bestand aus drei Ausschüssen, die jeweils unterschiedliche Aufgaben übernahmen:

Die Kommission wurde für 18 Monate einberufen und ihre Arbeit konnte um ein halbes Jahr verlängert werden. Der relativ kurze Zeitraum ihres Wirkens war bereits zur Einberufung umstritten, da die Fülle der zu behandelnden Fälle in dieser Zeit kaum zu bearbeiten schien. Allerdings galt es auch, die Folgen des Apartheidsystems schnell öffentlich zu machen, sowohl um gegebenenfalls Entschädigungen nicht erst nach vielen Jahren zu zahlen, als auch, um den schmerzhaften Prozess der Aufklärung nicht unnötig in die Länge zu ziehen.
Ihr Ziel war es, Opfer und Täter in einen „Dialog“ zu bringen und somit eine Grundlage für die Versöhnung der zerstrittenen Bevölkerungsgruppen zu schaffen. Vorrangig hierbei war die Anhörung beziehungsweise die Wahrnehmung des Erlebens des jeweils anderen.
Den Angeklagten wurde Amnestie zugesagt, wenn sie ihre Taten zugaben, den Opfern wurde finanzielle Hilfe versprochen. Ziel war die Versöhnung mit den Tätern sowie ein möglichst vollständiges Bild von den Verbrechen, die während der Apartheid verübt worden waren, zu bekommen. Sämtliche Anhörungen waren deshalb öffentlich. Am 29. Oktober 1998 präsentierte die Wahrheits- und Versöhnungskommission ihren Abschlussbericht. Vor allem von Seiten der Schwarzen wurde kritisiert, dass die Gedanken der Versöhnung und Amnestie Vorrang vor der Gerechtigkeitsfindung hatten.

Die mit der Apartheid verbundenen Diskriminierungen und Menschenrechtsverstöße sind mittlerweile auch im internationalen Recht – losgelöst von der mittlerweile überwundenen Apartheid in Südafrika – als "Verbrechen gegen die Menschlichkeit" definiert. Durch das Römische Statut über die Schaffung eines Internationalen Strafgerichtshofs wurde die Apartheid der Zuständigkeit dieses Gerichtshofs unterworfen. Das Statut wurde auf einer Staatenkonferenz in Rom im Jahre 1998 angenommen und seither von 139 Staaten unterzeichnet und von 114 Staaten ratifiziert. Es ist seit dem Jahre 2002 in Kraft. Somit können derartige Vorgänge mittlerweile international strafrechtlich verfolgt werden. Diese Entwicklung wurde maßgeblich dadurch motiviert, dass es früher keine derartige Rechtsgrundlage gab, so dass die Apartheid in Südafrika bzw. die Verantwortlichen juristisch praktisch nicht belangt werden konnten.

Adriaan Vlok war der erste Minister des früheren Apartheidregimes, der sich in einem Prozess gegen frühere Mitglieder der Sicherheitsbehörden vor einem Gericht für Verbrechen, die er während seiner Amtszeit begangen hatte, verantworten musste und dafür rechtskräftig verurteilt wurde.








</doc>
<doc id="12913" url="https://de.wikipedia.org/wiki?curid=12913" title="Wende">
Wende

Wende (von althochdeutsch: "wendi" wenden) steht für:


Politik:


Personen:


Geografie:



</doc>
<doc id="12914" url="https://de.wikipedia.org/wiki?curid=12914" title="Panzer (Begriffsklärung)">
Panzer (Begriffsklärung)

Panzer steht für:



Panzer ist der Familienname folgender Personen:




Siehe auch:


</doc>
<doc id="12915" url="https://de.wikipedia.org/wiki?curid=12915" title="Athene">
Athene

Athene oder Athena (Ehrentitel: "Pallas Athene") ist eine Göttin der griechischen Mythologie. Sie ist die Göttin der Weisheit, der Strategie und des Kampfes, der Kunst, des Handwerks und der Handarbeit sowie Schutzgöttin und Namensgeberin der griechischen Stadt Athen. Sie gehört zu den zwölf olympischen Gottheiten, den Olympioi. Ihr entspricht die römische Göttin Minerva.

Ihr bedeutendstes Heiligtum war der Parthenon in Athen. Auf der Akropolis standen mehrere Statuen der Athene aus der Hand des Bildhauers Phidias. Die größte Statue verkörperte die Athena Promachos (die „vorauskämpfende Athene“) in voller Rüstung. Ebenso berühmt war die chryselephantine Kolossalstatue der Athena Parthenos (der „Jungfrau Athene“) im Parthenon.

Um eine Frühform des Namens könnte es sich beim mykenischen "Atana Potinija" handeln. Im Altgriechischen existierten mehrere dialektale Varianten des Namens, darunter das attische ("Athēnã") oder ("Athēnaía"), das ionische ("Athḗnē"), dorisch ("Athānā") sowie das ("Athēnaíē") der epischen Dichtersprache. 

Aus der attischen Namensform gingen das lateinische "Athena" und neugriechisch ("Athiná") hervor. Im Deutschen ist neben der attischen Lautung ("Athena") auch die vom Ionischen abgeleitete Form "Athene" gebräuchlich.

Der Name "Athena" konnte bisher nicht auf eine indogermanische Wurzel zurückgeführt werden und gilt daher als vorgriechisch. Die Bedeutung des Namens ist unklar. Ein aus Knossos stammendes Tontäfelchen mit Linearschrift B aus mykenischer Zeit nach 1500 v. Chr. nennt "(a-ta-na-po-ti-ni-ja)", wobei es sich bei "a-ta-na" um ein Theonym oder ein Toponym handeln könnte. Der Wortbestandteil "po-ti-ni-ja" wird mit dem altgriechischen πότνια ("pótnia") identifiziert und bedeutet „Herrin, Gebieterin“ oder auch „Beherrscherin“. Der Ausdruck "a-ta-na-po-ti-ni-ja" wurde lange Zeit als „Herrin Atana“ übersetzt, und es wurde angenommen, dass „Atana“ eine an mehreren Orten verehrte Burggöttin war. Eine alternative Übersetzung ist „Herrin von Athen“, was bedeuten würde, dass Athen der Herkunftsort der Göttin ist und sie schon in dieser Zeit eng mit der Stadt verbunden war.

Bekannte Beinamen der Athena im Griechischen sind:

Athena ist Schutzgöttin und Namensgeberin Athens. Sie gilt als Göttin der Städte, der Weisheit und des Kampfes, so auch der Kriegstaktik und der Strategie; sie fungierte als Palast- und Schutzgöttin der mykenischen Herrscher. Athena war Schirmherrin der Künste und der Wissenschaften; als Hüterin des Wissens beschützte sie auch Spinner, Weber und andere Handwerker. Sie wurde aber auch in anderen Städten verehrt, so zum Beispiel in römischer Zeit im pamphylischen Side, wo sie auch die Schutzgöttin des städtischen Rates war. Dies dokumentiert eine Bronzemünze, auf der Athene einen Stimmstein in eine Wahlurne wirft.

In den zwei größten Epen Griechenlands, der Ilias und der Odyssee von Homer, ist Athena die Schutzgöttin des Odysseus. Im Trojanischen Krieg „kämpft“ Athena auf Seiten der Griechen. Anschließend begleitet sie Odysseus bei seinen gefahrvollen Abenteuern.

Athena führt Perseus bei der Enthauptung der Medusa.

Laut der "Theogonie" Hesiods, der ältesten und verbreitetsten Mythosversion von Abstammung und Geburt der Athena, war sie eine Tochter des Zeus und der Metis. Zeus hatte die von ihm mit zwei Kindern schwangere Metis verschlungen, da ihm von Uranos und Gaia prophezeit worden war, eine Tochter sei Zeus ebenbürtig, ein Sohn werde ihn jedoch stürzen. Als er danach unter großen Kopfschmerzen litt, zerschlug Hephaistos auf Zeus’ Befehl hin dessen Haupt (was er als Göttervater überstand). Daraus entsprang in voller Rüstung Athena. Sie wurde daher als eine Verkörperung des Geistes (da aus dem Kopf des Zeus = Kopfgeburt; siehe Namensherleitung) und damit der Weisheit und Intelligenz angesehen. Der Bruder der Athena blieb in Metis (beziehungsweise in Zeus) ungeboren und unbenannt. Die Hephaistos-Episode ist nicht in allen Versionen vorhanden.

In einer besonderen Version des Mythos entsprang Athena in Rüstung dem Mund des Zeus und zwang ihn, ihre verschlungenen Geschwister freizugeben. Als Schutzgöttin der Stadt Athen wurde sie daher auch oft in voller Kriegsrüstung dargestellt.

Von ihrem Vater erhielt sie seine Aigis als Leihgabe, die das Haupt der später Medusa genannten Gorgo, das Gorgoneion, zierte. Dieses Antlitz schmückte auch ihren Schild. Ihr Ziehvater war der Meeresgott Triton, mit dessen Tochter Pallas sie aufwuchs. Athena tötete diese versehentlich während eines Kampfspiels mit Wurfspeeren. Zum Andenken schuf Athena eine Statue, das Palladion, und übernahm den Namen der Getöteten: – "Pallas Athēnâ".

Wie viele griechische Gottheiten war Athena überaus leicht zu kränken: So verwandelte sie Arachne, die behauptete, die Göttin in der Webkunst zu übertreffen, in eine Spinne. Der Maler Diego Velázquez hat den Wettstreit zwischen Athena und Arachne in seinem monumentalen Gemälde "Die Spinnerinnen" dargestellt.

Sie ging niemals eine Liebesbeziehung ein, daher auch der Beiname "Parthenos" „die Jungfräuliche“ (vergleiche auch Artemis). Doch hauchte sie auf Bitten ihres Freundes, des Titanen Prometheus, den Menschen Wissen und Weisheit ein.

Nach dem Mythos stritten Poseidon und Athena um die Schirmherrschaft einer Stadt. So hielten sie einen Wettstreit ab: Wer der Stadt das nützlichere Geschenk mache, habe gewonnen. Poseidon gab einen Brunnen (oder auch eine Quelle), der jedoch nur Salzwasser spendete oder in anderen Versionen das Pferd; Athenas Gabe war der Olivenbaum und damit dessen Holz und Früchte. So wurde Athena die Schutzgöttin der Stadt, die seitdem ihren Namen trägt: – Athen. Der heilige Ölbaum stand lange Zeit exponiert auf dem Areal der Akropolis und soll laut Legende nach der Zerstörung des Tempels während der Invasion des Xerxes neu ausgeschlagen haben.

Laut Homer ist Athena "glaukōpis", was meistens mit „eulenäugig“ übersetzt wird ( „Eule“, „Auge“). Für das Attribut "glaukōpis" gibt es mehrere Deutungen.

Es wurde argumentiert, dass Homer, wenn er auf große Augen hinweisen wollte, er Athene – wie Hera – wenigstens ab und zu auch „kuhäugig“ hätte nennen können. So nennt er aber immer nur Hera und nie Athene. Danach wäre zu fragen, warum Homer für die beiden Göttinnen verschiedene Attribute verwendet hat, wenn die Bedeutung jeweils nur „großäugig“ gewesen sein soll. Diese Überlegung stützt die alternativen Deutungen „scharfsichtig“ und „helläugig“.

Jedenfalls war die Eule Athena symbolisch zugeordnet und erschien auch auf den athenischen Münzen – daher die seit der Antike bekannte Redensart "Eulen nach Athen tragen" für „etwas Überflüssiges tun“. Auch heute ist ein Teil dieser athenischen Münze auf der griechischen 1-Euro-Münze zu sehen.

Als Sinnbild der Athena und als Vogel der Weisheit galt insbesondere der Steinkauz. Sein wissenschaftlicher Name ist "Athene noctua", „nächtliche Athene“.

Im klassischen Jahrhundert der deutschen Literatur (etwa bei Friedrich Schiller) wurde für „Athena“ oft der damals geläufigere lateinische Name „Minerva“ benutzt, so auch in Hegels berühmtem Zitat zu der Tatsache, dass die Erkenntnis gesellschaftlicher Verhältnisse den Ereignissen oft erst folge: „[…] die Eule der Minerva beginnt erst mit der einbrechenden Dämmerung ihren Flug.“ (Vgl. Grundlinien der Philosophie des Rechts.)

Die Nationale und Kapodistrias-Universität Athen, die Max-Planck-Gesellschaft, die Universität der Bundeswehr München und die Technische Universität Darmstadt führen den Kopf der Athena in ihrem Signet.

Die deutsch-griechische Athene-Grundschule in Berlin (Europaschule) trägt diesen Namen seit 2002.

Eine 5,5 Meter hohe Statue der Pallas Athena steht vor dem österreichischen Parlamentsgebäude in Wien. Auf dem Ehrenhof des Campus Süd des Karlsruher Instituts für Technologie (ehem. Universität Karlsruhe) steht ebenfalls eine Statue der Athena mit gesenkter Speerspitze, mit der die Universität an ihre im Krieg Gefallenen erinnert. Seit 1957 steht eine solche Statue auch vor dem altsprachlich orientierten Wilhelm-Dörpfeld-Gymnasium in Wuppertal.




</doc>
<doc id="12916" url="https://de.wikipedia.org/wiki?curid=12916" title="Inselbegabung">
Inselbegabung

Inselbegabung (auch Savant-Syndrom ([]) oder Teilleistungsstärke) bezeichnet das Phänomen, dass Menschen, die z. B. eine kognitive Behinderung oder eine anderweitige (häufig tiefgreifende) Entwicklungsstörung aufweisen, sehr spezielle außergewöhnliche Leistungen in kleinen Teilbereichen („Inseln“) vollbringen können.

50 Prozent der bekannten Inselbegabten sind Autisten. Sechs von sieben Inselbegabten sind männlich.

Es gibt allerdings keine zuverlässigen Untersuchungen darüber, wie häufig das Savant-Syndrom auftritt. Der Autismus-Forscher Darold Treffert schlug 1989 eine Unterscheidung in „erstaunliche“ und „talentierte“ Inselbegabte vor. Während „erstaunliche“ Inselbegabte wirklich herausragende Fähigkeiten besäßen, wiesen die „talentierten“ höchstens durchschnittliche Leistungen auf, die jedoch in Anbetracht ihrer Behinderung bemerkenswert seien. Zurzeit sind weltweit etwa 100 Menschen bekannt, die man nach dieser Unterteilung als „erstaunliche Inselbegabte“ bezeichnen könnte. Der Intelligenzquotient dieser Personen liegt meist unter 70, kann aber auch durchschnittlich, in einigen Fällen auch überdurchschnittlich sein. Die Fähigkeiten sind dabei sehr unterschiedlich ausgeprägt. Durch den Film "Rain Man" wurde das Savant-Syndrom in der Öffentlichkeit etwas bekannter.

Der 1887 von dem englischen Neurologen John Langdon-Down in einer Vorlesungsreihe vor der Londoner Medical Society eingeführte Begriff „idiot savant“ (gedacht als „beschränkt Wissender“) ist irreführend und nach heutigen Maßstäben diskriminierend.

Aktuell spricht man von "Inselbegabten" oder "Savants". Besonders herausragende Inselbegabte werden von dem amerikanischen Psychiater und Forscher Darold Treffert als "prodigious savants" bezeichnet, abgeleitet von prodigy (Wunderkind, Talent). Autistisch veranlagte Inselbegabte werden auch „Autistic Savant“ oder „Savant Autistique“ genannt. Auch der Begriff „Savant“ ist irreführend, da das Substantiv „Savant“ in der französischen und in der englischen Sprache in einem umfassenden Sinn „Wissender“ oder „Gelehrter“ bedeutet.

Der Begriff „Inselbegabung“ trifft den Kern des Phänomens am ehesten, da er ausdrückt, dass bei insgesamt schwacher Begabung in einem abgegrenzten einzelnen Fach, einer Insel, eine herausragende Leistungsfähigkeit vorliegen kann, die in bizarrem Gegensatz zur übrigen Persönlichkeit steht. Es handelt sich um „eine isolierte Gabe inmitten von Defekten“ (Douwe Draaisma, 2006).

Die Ursachen von Inselbegabungen sind noch nicht genau bekannt. Die Fallbeschreibungen in der Literatur enthalten die unterschiedlichsten Charakterisierungen. Einige musikalische Savants sind blind. Derzeit geht man davon aus, dass den Savants eine wichtige Filterfunktion fehlt, die unwichtige Daten ausblendet.

Inselfertigkeiten sind fast immer angeboren, können jedoch auch später aus einer Hirnschädigung entstanden sein. Bei den meisten Inselbegabten ist die Sprache deutlich unterentwickelt; es gibt aber auch solche, die in kürzester Zeit eine Fremdsprache aufnehmen. Zu jeder Regel können genügend Ausnahmen belegt werden. Generalisierungen sind nicht möglich, und dementsprechend differieren auch die Deutungen der Ursachen.

Bei der Suche nach Erklärungen ist zu unterscheiden zwischen dem prüfbaren Können der Inselbegabten und der Frage, warum sie das können. Zuerst geht es um mögliche Strategien, die Inselbegabte anwenden, und darum, ob diese Leistungen auf erkennbaren Gedächtnisstützen, Rechenkünsten oder geschickten Faustregeln beruhen. Von Rechenkünstlern unter den Inselbegabten weiß man, dass sie nicht tatsächlich rechnen, sondern aus einem in ihrem Gedächtnis gespeicherten nahezu unendlichen Fundus von Zahlenketten und „Rohbausteinen“ die erforderlichen Elemente abrufen und zu neuen Zahlenketten kombinieren, die dann ebenfalls gespeichert werden und bei erneutem Abfragen der gleichen Aufgabe – und sei es 20 Jahre später – schnell verfügbar sind. Manchmal werden dabei auch ursprüngliche Fehler und deren anschließende Korrektur stereotyp wiederholt, was diese Gedächtnistheorie stützt. Zeichenkünstler wie Stephen Wiltshire haben meist ein fotografisches Gedächtnis, wobei das Gesamtbild mit allen, auch kleinsten Details in einem Akt in das Gedächtnis aufgenommen wird. Inselbegabte behalten, wie schon von Langdon Down beschrieben, die oberflächlichen Fakten, aber nicht die Zusammenhänge und nicht die dahinter liegenden Theorien.

Die zweite Frage lautet, warum Inselbegabte solche Strategien entwickeln können und andere nicht. Eine einheitliche Theorie ist noch nicht in Sicht. Gerade wegen der Vielfalt der Erscheinungsformen haben die meisten Hypothesen, die aus einzelnen Phänomenen abgeleitet wurden, nur einen begrenzten Aussagewert.

Die älteste Theorie vermutete in den Inselbegabten verunglückte Genies, bei denen durch einen Geburtsschaden alle Begabungen außer einer einzigen irreparabel beschädigt wurden. Nach heutigem Kenntnisstand ist diese Hypothese nicht haltbar. Eine andere Überlegung sucht die Erklärung des Phänomens in der Kompensation. Inselbegabte haben, bedingt durch eine sinnliche Störung oder durch autistische Anlagen, kompensatorisch eine Neigung zur Beschäftigung mit trivialen und bizarren Tätigkeiten und lassen sich durch nichts von dieser "one track mind" abbringen. Nach Douwe Draaisma ist der Inselbegabte das Produkt aus Konzentration, Einseitigkeit und endloser Wiederholung.

Eine Hypothese der Harvard-Neurologen Norman Geschwind und Albert Galaburda beruht auf Erkenntnissen der Hirnforschung, wonach zwischen der zehnten und der achtzehnten Woche der embryonalen Phase ein beschleunigtes Wachstum des Gehirns eintritt. Störungen dieser explosionsartig beschleunigten Neuronenverbindungen führen zu massiven Gehirnschäden. Einer der möglichen Störfaktoren ist das männliche Hormon Testosteron, das im Körper zirkuliert, während die Hoden des Embryos angelegt werden. Ein hoher Testosteronspiegel wirkt hemmend auf das Wachstum der Hirnrinde. Diese Theorie könnte die männliche Überrepräsentanz unter den Inselbegabten erklären.

Auch der Hirnforscher Michael Fitzgerald vom Trinity College (Dublin) sieht die herausragende Kreativität der Inselbegabten als Folge der bei den Autisten bestehenden neuronalen Fehlschaltungen. Seiner Meinung nach waren bei vielen Genies wie Albert Einstein, Isaac Newton und Mozart mehr oder minder starke Ausprägungen von Autismus vorhanden. Allan Snyder von der Universität Sydney geht davon aus, dass man bestimmte Gehirnareale ausschalten muss, um die Reserven der anderen Bereiche freisetzen zu können. Seine Versuchsergebnisse mit starken Magnetfeldern (rTMS) und die daraus abgeleiteten Thesen sind jedoch umstritten.

Eine weitere gängige Theorie besagt, dass bei Inselbegabten die Filtermechanismen des Gehirns gestört seien. Dadurch würden nur ausgewählte Informationen des Unbewussten und nur einzelne, für relevant gehaltene, Informationen des Gedächtnisses dem bewussten Bereich des Gehirns zugeführt, um dessen Überforderung zu verhindern und den Menschen im Alltag schneller und intuitiver entscheiden zu lassen. Manche Wissenschaftler gehen davon aus, dass jeder Mensch ausnahmslos alle Sinneseindrücke in seinem Gedächtnis speichert, aber nur Zugriff auf die wichtigen hat, während ein Savant in einem Teilbereich auf jede Information zugreifen kann, unabhängig von ihrer Relevanz oder emotionalen Bedeutung.

Neuere Forschungen (2012) an Taufliegen zur Gedächtnisbildung deuten auch auf mögliche Ursachen im Zusammenhang mit Dopamin und Savants hin. Dies würde solchen Theorien entgegenkommen. Es konnte gezeigt werden, dass ein Dopamin-Rezeptor (DAMB-Receptor) beim Prozess des „Vergessens“ eine wichtige Rolle spielt.

Wichtig ist, sich vor Augen zu führen, dass es nicht den einen Savant gibt, sondern ein breites Spektrum von Inselbegabten mit sehr unterschiedlichen Hirnstörungen und Teilbegabungen. Deshalb ist es auch schwierig, den Savant-Zustand zu „simulieren“ und normal begabte Menschen vorübergehend in „autistische Genies“ zu verwandeln, wie es der australische Forscher Allan Snyder versucht.











</doc>
<doc id="12917" url="https://de.wikipedia.org/wiki?curid=12917" title="Rudolf Augstein">
Rudolf Augstein

Rudolf Karl Augstein (* 5. November 1923 in Hannover; † 7. November 2002 in Hamburg; Pseudonyme unter anderem "Moritz Pfeil" oder "Jens Daniel") war ein deutscher Journalist, Verleger, Publizist und der Gründer des Nachrichtenmagazins "Der Spiegel", dessen Herausgeber er bis zu seinem Tode blieb.

Augstein wurde in Hannover geboren. Seine Mutter war Gertrude Maria Augstein und sein Vater Friedrich Augstein, ein ehemaliger Kamerafabrikant und Fotokaufmann ("Photo Augstein"). Rudolf wuchs in einer bürgerlichen katholischen Familie auf und war das jüngste von sieben Kindern (fünf Schwestern, ein Bruder – Josef Augstein, später Rechtsanwalt in Hannover). Als Neunjähriger erlebte er die Machtübernahme der Nationalsozialisten. Seine Eltern sandten ihn 1933 zunächst quer durch die Stadt auf das Kaiserin-Auguste-Viktoria-Gymnasium (die heutige Helene-Lange-Schule) in den Arbeiterstadtteil Linden, da diese als wenig nationalsozialistisch beeinflusst galt. Dort lernte er als Mitschüler Uri Avneri kennen. Als das Gymnasium 1939 zur Mädchenschule wurde, wechselte er zum Ratsgymnasium Hannover, das er 1941 mit dem Abitur verließ. Anschließend absolvierte er ein Volontariat beim "Hannoverschen Anzeiger", der späteren "Hannoverschen Allgemeinen Zeitung" (HAZ). Ab 1942 war Rudolf Augstein im Kriegsdienst als Kanonier und Funker, u.a. im russischen Woronesch. Gegen Ende des Zweiten Weltkriegs wurde er als Artilleriebeobachter zum Leutnant der Reserve befördert. Er wurde während seiner Dienstzeit mit dem Eisernen Kreuz und dem silbernen Verwundetenabzeichen ausgezeichnet.
1955 oder 1956 trat er in die FDP ein. 1972 errang er ein Bundestagsmandat für die FDP, welches er nach drei Monaten niederlegte.

Nach Ende des Krieges war Augstein zunächst Redakteur des "Hannoverschen Nachrichtenblatts". 1946 wurde er von den britischen Presseoffizieren John Seymour Chaloner, Harry Bohrer und Henry Ormond als Redakteur für ihre Wochenzeitschrift "Diese Woche" rekrutiert, die sich als Lizenzzeitung am Vorbild der britischen "News Review" und des amerikanischen "Time"-Magazins orientieren sollte. Nach nur sechs Ausgaben ordnete das britische Foreign Office aber wegen der Kritik, die im Magazin auch an den Besatzungsmächten geübt wurde, die sofortige Einstellung an. Chaloner erlangte zumindest die Erlaubnis, die Zeitschrift in deutsche Hände zu übergeben. So erwarb Augstein gemeinsam mit dem Fotografen Roman Stempka und dem Redakteur Gerhard R. Barsch in Hannover die Verlegerlizenz. Augstein wurde Chefredakteur und Herausgeber und brachte am 4. Januar 1947 die Erstausgabe des Nachrichtenmagazins unter dem neuen Titel "DER SPIEGEL" im Verlagshaus des Anzeiger-Hochhauses in Hannover heraus.

Im Januar 1949 wurde Augstein erstmals für eine Meldung im "Spiegel" angeklagt, nachdem das Magazin berichtet hatte, dass bei einer Hausdurchsuchung beim Kieler Ex-Agrarminister Erich Arp Fleischbüchsen gefunden worden waren. Augstein wurde vor Gericht freigesprochen. 

1952 kam eine Affäre um Hans-Konrad Schmeißer bei der eine bereits ausgelieferte „Spiegel“-Ausgabe bundesweit gerichtlich beschlagnahmt worden war. 2007 wurde bekannt, dass Augstein in diesem Zusammenhang in den 1950ern den Staatsrechtler Carl Schmitt, der aufgrund seines Einsatzes für den Nationalsozialismus als „Kronjurist des Dritten Reiches“ bezeichnet wurde, um juristischen Rat für eine Verfassungsbeschwerde ersuchte und auch eine Zeit lang eine briefliche Korrespondenz mit ihm unterhielt. Das Verfahren endete im September 1955 mit einem Vergleich.

Als der "Spiegel" in Ausgabe 41/1962 unter dem Titel „Bedingt abwehrbereit“ einen Artikel veröffentlichte, der, gestützt auf vertrauliche Berichte zum NATO-Manöver Fallex 62, das Verteidigungskonzept der Bundeswehr in Frage stellte, besetzte die Polizei – auf Betreiben von Verteidigungsminister Franz Josef Strauß – am 26. Oktober 1962 die Redaktionsräume und nahm in der Folge Augstein und sieben andere Mitarbeiter unter Verdacht des Landesverrats fest (siehe Spiegel-Affäre). Die Festnahmen lösten eine Welle von Protesten aus. Nach 103 Tagen Untersuchungshaft wurde Augstein im Februar 1963 entlassen. Bereits am 30. November 1962 wurde Strauß wegen der Affäre zum Rücktritt vom Amt des Verteidigungsministers gezwungen und zog sich daraufhin zeitweise in die bayerische Landespolitik zurück. Man sprach vom „Anfang des Endes“ der Ära Adenauer, der ebenfalls noch im selben Jahr zurücktrat. Kurz vor seinem Tod empfing Adenauer Augstein noch für ein Gespräch.

In den 1960er Jahren gründete Augstein die Rudolf Augstein Stiftung, die seinen Nachlass verwalten und sich unter anderem für wohltätige Zwecke einsetzen soll.

In den darauffolgenden Jahren veröffentlichte Augstein mehrere Bücher. 1972 und 1973 saß er für die FDP im Bundestag. 1974 schenkte Augstein 50 Prozent des Unternehmens den Mitarbeitern des "Spiegels". 1988 führte er mit dem damaligen Parteichef der KPdSU, Michail Gorbatschow, ein Gespräch über dessen Politik der Perestroika.

Im Herbst 1989 schrieb der damalige "Spiegel"-Chefredakteur Erich Böhme zehn Tage vor der Maueröffnung einen Kommentar mit dem Kernsatz „Ich möchte nicht wiedervereinigt werden“, in dem er seine Vorbehalte gegen eine Wiedervereinigung formulierte. Augstein, der als Kämpfer für die Wiedervereinigung galt, stellte in der darauf folgenden Ausgabe klar, dass er persönlich die Meinung seines Chefredakteurs nicht teilt. In seinem Artikel erklärte er: „Erich Kuby hat mich kürzlich einen Nationalisten genannt, und das bin ich auch. […] Lieber allerdings lasse ich mich als Patrioten bezeichnen, diesen Begriff habe ich in aller Subtilität vor 40 Jahren von Carlo Schmid geerbt.“ In einem Kommentar Anfang 1990 forderte Augstein: „Bitte keinen Friedensvertrag!“ und begründete dies mit der Befürchtung, dass in den Verhandlungen Reparationszahlungen gefordert werden würden und diese wiederum zu nationalistischen Protesten führten: 

1998 kündigte Augstein an, dass er sich 2003 komplett aus dem "Spiegel" zurückziehen wolle. Am 26. August 2002 schrieb er seinen letzten Kommentar im "Spiegel" unter dem Titel „Die Präventiv-Kriegstreiber“ über die Irak-Politik von George W. Bush.

Augstein wuchs katholisch auf, trat jedoch 1968 aus Protest gegen die Enzyklika Humanae Vitae aus der katholischen Kirche aus, wollte keiner Kirche mehr angehören und blieb zeitlebens ein überzeugter Atheist und scharfer Kirchenkritiker. Augstein „wolle nicht mehr zu einer Kirche gehören, die im Namen Gottes die Pille verbiete, die gegen die Ehescheidung polemisiere und die Wahlen durch Hirtenbriefe beeinflussen wolle“. Der Institution Kirche könne er nur Misstrauen entgegenbringen, da er davon ausging, dass der Schaden, den sie anrichtet, größer wäre als ihr sozialer Nutzen.

Rudolf Augstein starb am 7. November 2002, zwei Tage nach seinem 79. Geburtstag, in Hamburg an den Folgen einer Lungenentzündung. Die Beisetzung fand am 19. November 2002 auf dem Friedhof der evangelisch-lutherischen Severin-Kirche in Keitum statt, eine Trauerfeier folgte am 25. November in der Hauptkirche Sankt Michaelis (Hamburg). Von Konfessionslosen, Freidenkern und Atheisten wurde dies scharf kritisiert und von einer nachträglichen Vereinnahmung Augsteins durch die Kirche gesprochen, die nicht im Sinne des Toten gewesen wäre.

Augstein war fünfmal verheiratet und hatte drei leibliche Kinder und ein gesetzlich anerkanntes.
Rudolf Augstein heiratete am 13. Oktober 2000 in Tondern seine langjährige Lebensgefährtin, die Hamburger Galeristin Anna Maria Hürtgen.

Schon in den 1960er Jahren hatte Rudolf Augstein die Idee, sein Vermögen in eine Stiftung einzubringen. So wurde die Rudolf Augstein Stiftung gegründet, die sich für Menschen in Krankheit und Not sowie für Journalismus und Kunst engagiert. Es handelt sich um eine Stiftung, deren Vorstand ausschließlich Mitglieder der Familie Augstein bilden.






</doc>
<doc id="12918" url="https://de.wikipedia.org/wiki?curid=12918" title="Äther">
Äther

Äther oder Aether (von altgriechisch [zu "aithḗr" und lat. ""], zu dt. „[blauer] Himmel“) steht für:


sowie:

ätherisch steht insbesondere auch in Bezug zu:

Siehe auch:


</doc>
<doc id="12919" url="https://de.wikipedia.org/wiki?curid=12919" title="Der Spiegel">
Der Spiegel

Der Spiegel (Eigenschreibweise: DER SPIEGEL) ist ein deutsches Nachrichtenmagazin, das im "Spiegel-Verlag" in Hamburg erscheint und weltweit vertrieben wird. 

Die Redaktion kooperiert mit "Spiegel Online", das ebenfalls zum Spiegel-Verlag gehört, aber redaktionell und unternehmerisch vom Magazin getrennt ist. Es gab Überlegungen und Bestrebungen, beide Redaktionen zusammenzulegen oder die Mitarbeiter von Spiegel Online gleichwertig zu stellen.

Aufgrund seines Einflusses auf die öffentliche Meinungsbildung wird das Blatt oft als ein Leitmedium in Deutschland bezeichnet. In der bundesdeutschen Pressegeschichte nehmen "Der Spiegel" und sein Gründer Rudolf Augstein eine wichtige Rolle ein. Das 1947 gegründete Blatt erlangte seine Bedeutung im Kampf für die Pressefreiheit (siehe "Spiegel-Affäre") und durch die Enthüllung politischer Affären. Es ist Gründungsmitglied der 2016 initiierten European Investigative Collaboration (EIC).

"Der Spiegel" erscheint seit dem 10. Januar 2015 (Ausgabe 3/2015) offiziell jeweils samstags, ist vielerorts aber schon am Freitag erhältlich (online freitags ab 18 Uhr). Seit der Gründung des Magazins hat sich der Erscheinungstag immer wieder geändert, von anfänglich Samstag (bis 1949), dann auf Donnerstag, anschließend auf Mittwoch und bis einschließlich zur Ausgabe 2/2015 war der Montag für mehrere Jahrzehnte „Spiegel-Tag“.

Das Blatt wird unter Journalisten seit langem als eines der deutschsprachigen Leitmedien eingestuft, denen die Funktion zukommt, gesellschaftliche Kommunikation und Öffentlichkeit zu gestalten und zu prägen.
"Der Spiegel" hat wie seine direkten Konkurrenten "Focus" und "Stern" in den vergangenen Jahren an Auflage eingebüßt. Sie beträgt gegenwärtig Das entspricht einem Rückgang von Stück. Der Anteil der Abonnements an der verkauften Auflage liegt bei Prozent. Die Digitalauflage des "Spiegel" ist mit rund 56.000 Exemplaren die höchste eines Magazins in Deutschland.

Bereits vor dem Ersten Weltkrieg wurde von Lion Feuchtwanger in München eine Zeitschrift unter dem Namen "Der Spiegel" herausgegeben. Diese fusionierte im November 1908 mit Siegfried Jacobsohns "Schaubühne", steht allerdings nicht in Verbindung mit dem heutigen Nachrichtenmagazin "Der Spiegel".

Die erste Ausgabe des Blattes erschien am 4. Januar 1947, einem Samstag, in Hannover. Unter dem Titel "Diese Woche" war bereits seit November 1946 in Hannover ein Vorläufer erschienen, der amerikanischen und britischen "news magazines" nachempfunden war und zunächst unter der Ägide der britischen Militärverwaltung stand. Die drei verantwortlichen Presseoffiziere waren John Seymour Chaloner, Henry Ormond und Harry Bohrer, letzterer als kommissarischer Chefredakteur. Mit der siebten Ausgabe wurde das Blatt in deutsche Hände übergeben.

Rudolf Augstein, der das Deutschland-Referat bei "Diese Woche" geleitet hatte, erhielt die Verlegerlizenz und übernahm das Magazin, das er alsbald "Der Spiegel" nannte, als Herausgeber und Chefredakteur. Die erste Ausgabe erschien im Januar 1947, wurde im hannoverschen Anzeiger-Hochhaus erstellt und erreichte eine Auflage von 15.000 Exemplaren – die Papierrationierungen der Briten verhinderten zunächst höhere Auflagen.

1949 beschloss die Redaktion das "Spiegel-Statut":

1949 schrieb der SPIEGEL „in allgemein beleidigendem Ton“ über den Thronwechsel der niederländischen Königin Wilhelmina zu Königin Juliana. Die britische Besatzungsmacht verbot den SPIEGEL für zwei Wochen, als die niederländische Regierung sich beschwerte.

1950 deckte das Blatt auf, dass Bundestagsabgeordnete bei der Wahl der Bundeshauptstadt bestochen worden waren, damit sie für Bonn statt Frankfurt am Main stimmten. Augstein wurde im sogenannten "Spiegel-Ausschuss" als Zeuge vernommen, gab jedoch die Quellen für die Geschichte nicht preis und berief sich auf die journalistische Schweigepflicht.

1952 folgte die "Schmeißer-Affäre". Hans-Konrad Schmeißer, ehemaliger Agent im französischen Geheimdienst, hatte behauptet, Bundeskanzler Adenauer, Ministerialdirektor Blankenhorn und Generalkonsul Reifferscheid seien für den französischen Geheimdienst tätig gewesen und hätten einen französischen Agenten mit geheimen Nachrichten versorgt. 1958 begann im "Spiegel" die Debatte um die Notstandsgesetze, aus denen später (1960, 1963, 1965) verschiedene Gesetzesentwürfe des Innenministers Gerhard Schröder wurden.

Schon in seiner Anfangszeit erlangte "Der Spiegel" große Bedeutung. Die Auflage stieg massiv: 1961 betrug sie 437.000 Exemplare. Mit dem wirtschaftlichen Erfolg stiegen auch die publizistische Macht und der politische Einfluss.

Am 10. Oktober 1962 erschien im "Spiegel" der Artikel "Bedingt abwehrbereit", in dem der verantwortliche Redakteur Conrad Ahlers interne Dokumente der Bundeswehr zitierte und zu dem Schluss kam, die NATO und die Bundesrepublik könnten einem sowjetischen Angriff nicht standhalten. Am 26. Oktober 1962 wurden das "Spiegel"-Verlagsgebäude in Hamburg und die Redaktion in Bonn durchsucht. Es wurden Haftbefehle mit dem Vorwurf auf Verdacht des Landesverrats, landesverräterischer Fälschung und aktiver Bestechung ausgestellt. Bundesverteidigungsminister Franz Josef Strauß ließ "Spiegel"-Redakteur Conrad Ahlers in Spanien mit falschen Behauptungen durch die Polizei verhaften und nach Deutschland transferieren. Zwei Tage später stellte sich Rudolf Augstein der Polizei und wurde in Untersuchungshaft genommen. Weite Teile der Öffentlichkeit solidarisierten sich mit dem Nachrichtenmagazin, Studenten gingen für Augstein auf die Straße. Bundeskanzler Konrad Adenauer sagte im Bundestag unter heftigem Protest aus den Reihen der SPD und auch der FDP und unter Beifall der CDU, beim "Spiegel" habe sich ein „Abgrund von Landesverrat“ geöffnet. Nach 103 Tagen wurde Rudolf Augstein aus der Haft entlassen. 1963 sagte Strauß über das Blatt:

Strauß musste im Anschluss an die Affäre zurücktreten. Er hatte derart vielfältig deutsches und internationales Recht gebrochen, insbesondere bei der Veranlassung der Verhaftung von Conrad Ahlers in Spanien, dass er politisch nicht zu halten war. Bundeskanzler Adenauer überstand die Affäre trotz seines „Abgrundes an Landesverrat“ verhältnismäßig unbeschädigt, insbesondere auch deshalb, weil sein Verteidigungsminister ihn in erheblichem Umfang falsch informiert hatte und der Bundeskanzler sich darauf berief, er hätte seinem eigenen Minister wohl kaum misstrauen müssen.

Am 13. Mai 1965 lehnte der Bundesgerichtshof aus Mangel an Beweisen die Eröffnung des Hauptverfahrens gegen Ahlers und Augstein ab.

Die Affäre führte dazu, dass weite Kreise, besonders Angehörige der jungen Generation und der kritischen Intelligenz, sich für das Wochenmagazin als Garant der Meinungsfreiheit engagierten, und begründete den Mythos des Blattes.

1966 übte Karl Jaspers in seinem Buch "Wohin treibt die Bundesrepublik" scharfe Kritik an den Notstandsgesetzen, die der Bevölkerung im Falle eines "äußeren Notstandes" keine Wahl ließen, sich Gewalt und Macht zu verweigern. Ein "innerer Notstand" könne überhaupt nicht eintreten, weil das dem Gedanken eines demokratischen Staats zuwiderlaufe: „Das Notstandsgesetz raubt dem Volk die ihm verbliebenen legitimen, dann aber nicht mehr legalen Mittel des Widerstands.“ Am 5. August 1966 scheiterte eine Verfassungsbeschwerde des "Spiegels" vor dem Bundesverfassungsgericht. 1968 wurden die Notstandsgesetze Teil des Grundgesetzes. 1969 betrug die "Spiegel"-Auflage 953.000 verkaufte Exemplare.

Das Blatt hatte Anfang der 1970er Jahre knapp 900 Beschäftigte, davon rund 400 in der Redaktion, 100 in der Dokumentation sowie knapp 400 in den kaufmännischen und technischen Abteilungen. 1970 wurde das "Manager Magazin" gegründet, das von einer Tochtergesellschaft der "Spiegel-Gruppe" herausgegeben wird. 1971/72 wurde ein Mitbestimmungsmodell und mehr Demokratie innerhalb der Redaktion beschlossen; außerdem eine Gewinnbeteiligung. Einnahmen aus Anzeigen sanken. 1971 betrug die Anzahl der Leser rund sechs Millionen – das entsprach rund zwölf Prozent aller in der Bundesrepublik lebenden Menschen über 14 Jahre. Der Anteil der Auslandsauflage an der Gesamtauflage betrug 10 bis 15 Prozent – "Der Spiegel" ist seitdem eine Publikation mit intensiver Rezeption im Ausland. Die Auflage betrug 923.000 verkaufte Exemplare.

1974 nannte Willy Brandt das Magazin ein „Scheißblatt“. 1975 wurden "Spiegel"-Korrespondenten aus der DDR wegen „böswilliger Verletzung ihrer Rechtsvorschriften“ ausgewiesen. Im Januar 1978 schloss die DDR die "Spiegel"-Büros in der DDR, auch das in Ost-Berlin, nach einer kritischen Berichterstattung über Zwangsadoptionen und der Veröffentlichung des zweiten Teils des Manifests des Bundes Demokratischer Kommunisten Deutschlands, einem Dokument einer angeblichen Opposition innerhalb der SED. Die DDR wertete diese Veröffentlichungen als Einmischung in die inneren Angelegenheiten der DDR.

Das Blatt publizierte Vorabdrucke von und über den Dissidenten Rudolf Bahro, "Die Alternative" (EVA) und "Elemente einer neuen Politik" (Olle & Wolter), "Antworten auf Bahro" (Olle & Wolter) und machte damit seinen systemkritischen Ansatz einem größeren Publikum bekannt.

Das Blatt deckte diverse deutsche Staats- und Wirtschaftsaffären auf, zum Beispiel 1982 die "Flick-" und "Neue-Heimat-Affäre" und 1987 die Barschel-Affäre. Die Behandlung der "Barschel-Affäre" durch den "Spiegel" ist nicht unumstritten. 1988 deckte er die "co-op-Affäre" auf.

1990 überschritt das Blatt mit 1.050.000 verkauften Exemplaren erstmals die Millionengrenze. 1992 sagte Antje Vollmer: „Am Ende der Ära Augstein hat "Der Spiegel" an Bedeutung verloren und an Macht gewonnen“.

Am 18. Januar 1993 erschien die erste Ausgabe des "Focus", nach Aussage des Chefredakteurs Helmut Markwort als „Konkurrenz-, nicht Gegenmedium zum "Spiegel"“. Danach kam es zu deutlich wahrnehmbaren Veränderungen. "Focus" wurde bewusst als Gegenpol und Alternative zum "Spiegel" konzipiert; nachweisbar ist das insbesondere an der politischen Linie und dem vergleichsweise schonenden Umgang mit den Anzeigenkunden. Uli Baur, neben Markwort Chefredakteur des "Focus", fasste die redaktionelle Linie des "Focus" unter Bezugnahme auf das bekannte Augstein-Zitat („[…] im Zweifelsfalle links“) deutlich zusammen: „Wenn "Der Spiegel" im Zweifel links ist, sind wir im Zweifel rechts.“

Das Blatt erlitt einen Auflagenverlust von mehr als zehn Prozent und einen Rückgang der verkauften Anzeigenseiten um mehr als zwölf Prozent. 1995 lag die Anzahl der Leser bei über sieben Millionen. Es entstanden "Spiegel TV" und "Spiegel Special", die ein Fünftel des "Spiegel"-Umsatzes von 542 Millionen D-Mark (1996) generierten. "Der Spiegel" war im ersten Halbjahr 1996 „die deutsche Zeitschrift mit den höchsten Einnahmen aus Vertrieb und Anzeigen.“ Erzielt wurden Bruttoeinnahmen von 330,7 Millionen D-Mark, das war knapp eine Million mehr als der "Stern" (Platz 2) erzielen konnte und lag noch vor "Bild am Sonntag" (Platz 3) und "Focus". Im Januar 1997 feierte "Der Spiegel" 50. Geburtstag. Bis dahin waren 2.649 Ausgaben erschienen. Man aktualisierte das Layout, das seitdem durchgehend farbig ist.

Ab Ende der 1990er Jahre, unter dem Chefredakteur Stefan Aust und möglicherweise auch unter dem Eindruck der Konkurrenz, wurde von Beobachtern eine Hinwendung des "Spiegels" zu liberalen Standpunkten verzeichnet.
Als mit der Bundestagswahl 1998 Helmut Kohl abgewählt wurde, kam es zur ersten rot-grünen Koalition auf Bundesebene. Vieles in Politik und Gesellschaft änderte sich. Das Internet gewann an Bedeutung und die Dotcom-Blase bildete sich.
Kritiker hielten dem Blatt vor, boulevardesker geworden zu sein und an analytischer Tiefe verloren zu haben. Die Artikel wurden aber nicht kürzer oder weniger aktuell. Im Vorfeld der Bundestagswahl 2005 wurde dem Blatt „Wahlhilfe“ für das bürgerliche Lager um Angela Merkel attestiert. Auf die Frage, mit welcher Partei sie sympathisieren, antworteten 2005 die befragten "Spiegel"-Leser zu 36 Prozent CDU/CSU, zu 28 Prozent SPD, zu 18 Prozent Die Grünen, zu 7 Prozent FDP und zu 5 Prozent Linkspartei.PDS.

Laut einer Umfrage unter 1536 deutschen Journalisten im Frühjahr 2005 soll sich der Einfluss des Magazins verringert haben. 33,8 Prozent der Befragten bezeichneten das Blatt weiterhin als ihr Leitmedium, während für die "Süddeutsche Zeitung" 34,6 Prozent votierten. 1993 hatten noch zwei Drittel der befragten Journalisten für den "Spiegel" als Leitmedium gestimmt.

Seit 1996 veranstaltet das Magazin den jährlichen "Spiegel-Wettbewerb" für Schülerzeitungen.

Im Jahr 2002 wurde der "Spiegel-Shop" gegründet, dessen Geschäftszweck die Vermarktung von Nebenprodukten des "Spiegel"-Verlags und weiterer Medien ist.

Seit dem 24. Oktober 2002 gibt es das Blatt auch als digitale Ausgabe im "Portable Document Format".

Am 7. November 2002 starb Herausgeber Rudolf Augstein. Er wird auch postum als offizieller Herausgeber genannt.

Am 6. August 2004 verkündete der Verlag, gemeinsam mit der Axel Springer AG, zur traditionellen deutschen Rechtschreibung zurückkehren zu wollen. Dieses Vorhaben wurde aber nicht umgesetzt; am 2. Januar 2006 wurde die reformierte Rechtschreibung entsprechend den Empfehlungen des Rates für deutsche Rechtschreibung weitgehend übernommen.

Am 25. Juni 2007 erschien das Blatt in der Schweiz testweise und vorerst einmalig mit einer eingehefteten Split-Beilage.

Mit Spiegel Wissen startete der Verlag im Februar 2008 in Kooperation mit der Wissen Media Group eine Internetplattform, die Inhalte des Nachrichtenmagazins "Der Spiegel", von Spiegel Online, der Wikipedia und Bertelsmann-Lexika und -Wörterbücher zusammenfasste. Dort wurden außerdem kostenlos fast alle seit 1947 veröffentlichten "Spiegel"-Artikel bis auf jene der beiden aktuellen Ausgaben angeboten. Seit 2009 wurde der Großteil des Angebots von Spiegel Wissen, insbesondere das Heftarchiv, in den Auftritt von Spiegel Online integriert. Im November 2013 konnten die Spiegel-Artikel im Archiv bis auf die vergangenen zwölf Monate kostenlos gelesen werden.

Am 5. Februar 2008 endete die Ära Aust. Sein Vertrag lief bis zum 31. Dezember 2008; die Gesellschafter beurlaubten ihn und verlängerten seinen Vertrag nicht. Ihm folgten Mathias Müller von Blumencron, bis Ende Mai 2008 Chef von Spiegel Online, und Georg Mascolo, Leiter des Hauptstadtbüros.

Im September 2009 startete Dein Spiegel, ein Kindermagazin und 2010 "Legal Tribune Online", ein Portal in Kooperation mit dem niederländischen Wolters Kluwer-Verlag mit Stellungnahmen zu aktuellen Rechtsfragen. Im Februar 2011 wurden die Zuständigkeiten innerhalb der doppelköpfigen Chefredaktion neu verteilt: Mascolo übernahm die Alleinverantwortung für das Nachrichtenmagazin "Der Spiegel" und Blumencron die Verantwortung aller digitalen Aktivitäten, einschließlich von "Spiegel Online". Nach der im März 2012 veröffentlichten Studie „Medienmarken als Arbeitgeber 2012“ der Fachzeitung "Horizont" gilt "Der Spiegel" unter den Beschäftigten der Medienbranche als bester Arbeitgeber unter allen deutschen Zeitschriften und Zeitungen. Am 9. April 2013 wurden Mascolo und Müller von Blumencron „wegen unterschiedlicher Auffassungen zur strategischen Ausrichtung mit sofortiger Wirkung abberufen und beurlaubt“.

Nach dem Ausscheiden von Mascolo und Blumencron wurde Wolfgang Büchner im September 2013 Nachfolger sowohl als Leiter des "Spiegel" als auch von "Spiegel Online." Er teilte im Dezember 2013 mit, dass das gedruckte Heft von 2015 an nicht mehr montags, sondern regulär samstags erscheinen wird.

Die Personalentscheidung Nikolaus Blome löste 2013 im Haus Springer und in der Familie Augstein eine Kontroverse aus. Blome, vormals in der Chefredaktion der "Bild" tätig, sollte in die Chefredaktion des "Spiegel" wechseln, ein Vorgang, der seit 1995 im Einvernehmen zwischen der Mitarbeiter KG, die 50,5 % der Anteile hält, und der Geschäftsführung getroffen wird. Im Falle Blomes wollte Geschäftsführer Ove Saffe die Personalie mit Hilfe des Verlags Gruner + Jahr ohne Zustimmung der KG durchsetzen. Nach einer längeren Auseinandersetzung wurde Büchner schließlich gegen den Widerstand der Mitarbeiter KG Chefredakteur.

Außerdem scheiterte Büchner im August 2014 mit dem Plan, Online und Print unter dem Titel "Spiegel 3.0" zusammenzuführen. Die Gesellschafterversammlung gab ihm den Auftrag, die Printredaktion in die Erarbeitung der Umstellung einzubeziehen, wo er jedoch wegen umstrittener Personalmaßnahmen kein Vertrauen mehr fand. Zudem soll sich Büchner dieser strategischen Entwicklung vollständig widmen, womit er aus der täglichen Arbeit der Chefredaktion abgezogen wird. Seit 2014 unterhält der "Spiegel" ein „Labor für multimediales Storytelling“, in dem Mitarbeiter aller Sparten regelmäßig zusammenkommen, um Strukturen für Multi-Format Publishing und Datenjournalismus zu entwickeln. Es wird maßgeblich betrieben von Cordt Schnibben. "Der Spiegel" unterhält zudem eine Kooperation mit der niederländischen politischen Wochenzeitschrift "HP/De Tijd"; sie übernimmt Reportagen des Magazins.

Am 13. Januar 2015 wurde Wolfgang Büchner mit dem Votum der Mitarbeiter KG durch Klaus Brinkbäumer ersetzt. Er fungiert seitdem als Chefredakteur des Spiegel und als Herausgeber von Spiegel Online.

Am 3. Juli 2015 hat "Der Spiegel" bei der Bundesanwaltschaft in Karlsruhe Anzeige erstattet wegen des „Verdachts der geheimdienstlichen Agententätigkeit und der Verletzung des Fernmeldegeheimnisses“, weil man davon ausgehe von US-Geheimdiensten abgehört worden zu sein.

Am 1. Dezember 2015 kündigte der Spiegel-Verlag an, dass bis 2018 149 der 727 Vollzeitstellen abgebaut werden sollen. Im Frühjahr 2016 erschien der Spiegel in Nordrhein-Westfalen testweise mit einem Regionalteil. Am 27. Juni 2016 führte man Spiegel Plus ein, in dem man auf Spiegel Online ausgewählte Artikel nur gegen eine Gebühr lesen kann. Diese Artikel sind häufig aus dem gedruckten Spiegel übernommen und werden so auch Nutzern von Spiegel Online angeboten. Am 16. Mai 2017 erschien die erste Ausgabe der digitalen Abendzeitung Spiegel Daily.

1956/57, rund zehn Jahre nach der Gründung des Blattes, verfasste Hans Magnus Enzensberger eine kritische Analyse über "Die Sprache des Spiegel", in der er eine Reihe von Thesen aufstellte: "Das deutsche Nachrichtenmagazin" sei im Grunde kein Nachrichtenmagazin, da es seinen Informationsgehalt in die Form von „Storys“ kleide, "Der Spiegel" übe nicht Kritik, sondern deren Surrogat, der Leser des "Spiegels" werde nicht orientiert, sondern desorientiert. Diese kritische Einstellung revidierte Enzensberger auch nach der "Spiegel-Affäre" nicht; er sah das Magazin weiterhin als latente Gefahr für die deutsche Demokratie. Dennoch hatte er in den 1950er Jahren betont, "Der Spiegel" sei unentbehrlich, solange es in der Bundesrepublik kein kritisches Organ gebe, das ihn ersetzen könne.

Wolf Schneider nannte das Magazin 1985 „den obersten Verhunzer der deutschen Sprache“. In seinen Stilfibeln zitiert er aus dem "Spiegel" häufig Negativbeispiele für schlechtes Deutsch.

Die Berichterstattung des Magazins über die Krankheit AIDS wurde teilweise als „unangemessen“ kritisiert. Der Sexualwissenschaftler Volkmar Sigusch bezeichnete diese Form der Berichterstattung als „erschütternd“ und „Versagen jener Presse, die zwischendurch auch einmal liberal war“. Andere warfen dem Blatt vor, durch seinen Umgang mit Fallzahlen Panik zu verbreiten und, durch redaktionelle Aussagen wie „wenn erst Kinder an AIDS sterben werden, Frischoperierte, Unfallopfer, Krankenhauspatienten, ohne jedes Stigma also“ oder durch Veröffentlichung entsprechender Leserbriefe, Kranke, Betroffene und Infizierte zu stigmatisieren.

Allerdings diente das „Leitmedium Spiegel“ in Untersuchungen oft als Vorzeigeobjekt, an dem Kritik festgemacht wurde, die so auch auf vielen anderen Medien zu finden war. Außerdem erhielt "Der Spiegel" 1987 für eine Reportage auch den ersten Medienpreis der Deutschen AIDS-Stiftung, der für Arbeiten ausgelobt wird, „die sachkundig über HIV/AIDS berichten und damit zur Solidarität mit Betroffenen beitragen“.

Nachdem der Medienforscher Lutz Hachmeister die Tätigkeit ehemaliger SS-Offiziere als "Spiegel"-Redakteure und Serienautoren für den frühen "Spiegel" belegen konnte, so zum Beispiel die Autorenschaft des Kriminalrates und SS-Hauptsturmführers Bernhard Wehner für die am 29. September 1949 startende 30-teilige "Spiegel"-Serie „Das Spiel ist aus – Arthur Nebe“, geriet das Magazin 2006 verstärkt in die Kritik, weil es seine eigene NS-belastete Vergangenheit nicht ausreichend reflektiert habe. So bemängelte die "Süddeutsche Zeitung" in einem ganzseitigen Beitrag ebenso wie das medienpolitische ver.di-Magazin "M", dass die Rolle des ehemaligen Pressechefs im NS-Außenministerium und SS-Obersturmbannführers Paul Karl Schmidt alias Nachkriegsbestsellerautor Paul Carell als Serienautor des Magazins marginalisiert und die Tatsache, dass die SS-Hauptsturmführer Georg Wolff und Horst Mahnke in den 1950er Jahren zu leitenden Redakteuren avancierten, von dem sonst NS-kritischen Magazin ausgeblendet worden sei. Erst 2014 wurde bekannt, dass auch der langjährige Chef vom Dienst des "Spiegel" Johannes Matthiesen als ehemaliger SS-Untersturmführer sowie der Redakteur Kurt Blauhorn als früherer NS-Propagandist einschlägig vorbelastet waren.

Schon im Jahr 2000 hatte die "Neue Zürcher Zeitung" Augstein vorgeworfen, ehemaligen Nationalsozialisten bewusst die Möglichkeit gegeben zu haben, wieder gesellschaftsfähig zu werden. Zudem soll Augstein im Falle des Reichstagsbrandes mit dazu beigetragen haben, die kontroverse Alleintäterthese als allein gültig darzustellen. 2011 behauptete Peter-Ferdinand Koch, Rudolf Augstein sei mit den ehemaligen SS-Offizieren eine bewusste Kooperation eingegangen:
Am 22. Dezember 2006 brachte "Der Spiegel" eine Titelgeschichte des Redakteurs Matthias Schulz mit dem Titel "Das Testament des Pharao" heraus, die sich stark auf angeblich durch den deutschen Ägyptologen Jan Assmann aufgestellte Thesen berief und in der unter anderem behauptet wurde, die Juden hätten den Monotheismus von Echnatons Amarna-Religion „abgekupfert“. Assmann protestierte daraufhin zuerst in einem offenen Brief an die "Spiegel"-Redaktion und dann in einem Interview in der "Welt" „in aller Schärfe“ gegen die Verwendung seines Namens in dem "Spiegel"-Artikel, den er als „ungenießbare und antisemitische Suppe“ bezeichnete. Gleichzeitig wies Assmann die Kernthesen des Artikels zurück. Der jüdische Erziehungswissenschaftler Micha Brumlik zeigte sich empört, dass .

Italienische Medien zeigten sich ebenfalls empört, als im Heft 31 (1977) das Titelblatt "Urlaubsland Italien – Entführung, Erpressung, Straßenraub" einen Teller Spaghetti zusammen mit einem Revolver zeigte: Der Umgang der Zeitschrift mit Klischees über Italien wurde 2012 in Zusammenhang mit dem Schiffbruch der Costa Concordia wieder zum Thema, als ein "Spiegel"-Redakteur in einer Kolumne auf "Spiegel Online" suggerierte, es sei kein Zufall, dass ein solcher Unfall einem italienischen Schiffsführer passiert sei – im Gegensatz etwa zu einem Deutschen oder Briten.

Der Beschwerdeausschuss 2 des Deutschen Presserats missbilligte das Titelblatt „Stoppt Putin jetzt!“ vom 27. Juli 2014, da die dort gezeigten Opferfotos den Opferschutz verletzen. Außerdem würden sie politisch instrumentalisiert. Bis heute hat der Spiegel weder über die Missbilligung des Presserats noch über weitere Kritik zu dem Titelblatt und der Titelgeschichte berichtet, wie etwa Medienjournalist Stefan Niggemeier moniert.

In einer Studie der TU Dresden von 2014 wurde die Synchronisation von Nachricht und Werbung untersucht. Ergebnis war, „dass über Unternehmen sowohl im Spiegel als auch im Focus erstens häufiger, zweitens freundlicher, drittens mit mehr Produktnennungen berichtet wird, je mehr Anzeigen diese Unternehmen schalten.“

Der heutige "Spiegel-Verlag Rudolf Augstein GmbH & Co. KG" hat seit 1952 seinen Sitz in Hamburg und produziert neben dem Hauptblatt dort auch das "Manager Magazin". Augstein verfügte in seinem Testament Ende 2002, dass seine Erben ein Prozent ihres Anteils an die beiden übrigen Gesellschafter verkaufen müssten, damit verloren sie ihre Sperrminorität von 25 Prozent. 50,5 Prozent der Anteile an der Verlags-Holding "Rudolf Augstein GmbH" sind nun im Besitz der Kommanditgesellschaft der Mitarbeiter. Über die restlichen 25,5 Prozent verfügt der Hamburger Medienkonzern Gruner + Jahr, eine Tochter der Bertelsmann SE & Co. KGaA. Geschäftsführer des "Spiegel"-Verlags war seit 1991 Karl Dietrich Seikel. Im Januar 2007 löste ihn Mario Frank, der ehemalige Geschäftsführer des Dresdner Druck- und Verlagshauses, ab. Ihm folgte ab 15. September 2008 der vormalige Verlagsgeschäftsführer der Stern-Gruppe, Ove Saffe. Seit 11. Februar 2015 ist Thomas Hass, zuvor Leiter des Vertriebsmarketings und Vorsitzender der Mitarbeiter-KG, Geschäftsführer des Verlags.

Die Umsatzerlöse des Konzerns Rudolf Augstein GmbH verteilten sich laut Konzernabschluss 2012 so auf die einzelnen Geschäftsbereiche:

Die Redaktion war bis zum Bezug eines eigenen Gebäudes im Pressehaus an der Domstraße ansässig, in dem sich auch die Redaktionen der "Zeit" und des "Sterns" befanden. 1968 zog der Verlag an die Brandstwiete. Auf dem langgestreckten dreieckigen Grundstück zwischen Willy-Brandt-Straße, Dovenfleet und Brandstwiete hatte Werner Kallmorgen von 1963 bis 1967 zwei Bauten errichtet: Den mit betonten tragenden Elementen ursprünglichen "Spiegelbau" mit einem angrenzenden flachen Gebäudeteil sowie ein ursprünglich für IBM errichtetes Gebäude mit glatter dunkler Glasfassade. Derzeit steht der gesamte alte Gebäudetrakt leer. Am 7. Juni 2013 wurde es im Rahmen einer Protestaktion gegen kapitalistische Stadtentwicklung von etwa 300 Menschen aus der linken Szene besetzt, jedoch nach wenigen Stunden bereits wieder von der Polizei geräumt.

Der Verlag hat in der HafenCity auf der ehemaligen Bastion Ericus das Spiegel-Gebäude Ericusspitze nach Entwürfen des dänischen Architekten Henning Larsen errichten lassen, das im September 2011 bezogen wurde.




Die Schriftart Spiegel, die speziell von LucasFonts für die Zeitschrift entwickelt worden ist, wird in der gedruckten Version und auch im Internet verwendet.





</doc>
<doc id="12922" url="https://de.wikipedia.org/wiki?curid=12922" title="Ether">
Ether

Als Ether (in der Gemeinsprache auch Äther) werden in der Chemie organische Verbindungen bezeichnet, die als funktionelle Gruppe eine Ethergruppe – ein Sauerstoffatom, das mit zwei Organylresten substituiert ist – besitzen (R–O–R). In der Umgangssprache bezeichnet "Ether" oft auch den Diethylether (HC–O–CH), einen der wichtigsten und einfachsten Ether. Sind beide Reste an der Sauerstoffbrücke aliphatisch, so werden diese Ether nach der IUPAC auch als Alkoxyalkane bezeichnet.

Ether sind in der Natur weit verbreitete Verbindungen. Die glycosidische Bindung der Polysaccharide ist eine Sauerstoffbrücke zwischen zwei Kohlenstoffatomen; diese Acetale sind faktisch intramolekulare, geminal angeordnete Di-Ether. Auch viele andere Naturstoffe, wie z. B. die Aromastoffe Anethol, 1,8-Cineol, Eugenol und Vanillin, sowie die Gruppen der Ubichinone und Strobilurine und viele Arzneistoffe sind Ether.

Allgemein kann ein Ether als

dargestellt werden. R und R sind hier Alkyl- oder Aryl-Reste, die im Fall eines cyclischen Ethers miteinander verbunden sind. Es sind auch Alkyl-Aryl-Ether möglich (siehe "Anisol" und "Vanillin"). Die Bindungsverhältnisse in Ethern ähneln denen in Alkoholen und im Wasser, das als Grundkörper dieser beiden Verbindungsklassen aufgefasst werden kann. Kohlenstoff- und Sauerstoff-Atome sind jeweils sp hybridisiert. Dies führt zu einer tetraedrischen Anordnung der Atomorbitale um alle beteiligten Atome. Der Bindungswinkel des Sauerstoffs ist aufgrund der gegenüber Wasserstoff (104,5° im HO) voluminöseren Alkylsubstituenten mit 112° erweitert. Die C–O-Bindungen sind mit ca. 143 pm so lang wie in Alkoholen.

Gemäß der IUPAC-Nomenklatur werden aliphatische Ether als Alkoxyalkane bezeichnet:
R–O–R, wobei die Gruppe O–R als Alkoxy-Substituent einer Alkan-Kette R behandelt wird. Der niederrangigere Substituent der Kette ist hierbei der Alkoxy-Rest (–O–R), der höherrangigere bildet den Stamm des Stoffnamens. Ebenfalls von der IUPAC zugelassene Namen werden durch Nennung der beiden Alkylreste und der Endung "ether" gebildet und sind besonders für kleine, aliphatische Ether gebräuchlich. Bei symmetrischen Ethern ist dann die Bezeichnung sehr einfach durch Vorstellen eines "Di" möglich [z. B.: Diethylether (Ethoxyethan) oder Dimethylether (Methoxymethan)]. Cyclische und aromatische Ether sind fast sämtlich nur unter ihrem Trivialnamen bekannt.

Entsprechend verläuft die Benennung der Alkoxyalkane. Beispiele:


Cyclische Ether werden als Cycloalkane betrachtet, bei denen ein (oder mehrere) C-Atome durch (ein) O-Atom(e) ersetzt wurde(n). Um dies zu verdeutlichen, wird entsprechend dem Hantzsch-Widman-System die Silbe "Oxa" an der entsprechenden Position eingefügt. Beispiel:

Der IUPAC-Name ist Oxacyclohexan. Die Verbindung wird jedoch fast ausschließlich unter dem Namen Tetrahydropyran geführt. Die Verbindung ist cyclisch (cyclo), hat eine Ringgröße von 6 Atomen (hexan) und an einer Position ist ein C-Atom durch ein Sauerstoff-Atom ersetzt (oxa). Entsprechend gilt für die folgende Verbindung der Name 4-Fluoroxacyclohexan oder gängiger: 4-Fluortetrahydropyran [dem Heteroatom (Sauerstoff, O) im Ring wird dabei die Position 1 zugeordnet].

Die meisten Ether sind relativ reaktionsträge und werden daher oft als Lösungsmittel in der präparativen organischen Chemie verwendet. Da höhere Ether aufgrund wachsender sterischer Hinderungen schlechter Wasserstoffbrückenbindungen ausbilden können, nimmt die Löslichkeit in Wasser mit zunehmender Größe des Alkylrestes schnell ab.
In starken Säuren sind Ether wegen der darin erfolgenden Protonierung unter Bildung von Oxoniumionen dagegen gut löslich.

Die physikalischen Eigenschaften der Ether unterscheiden sich deutlich von denen der entsprechenden Alkohole mit ähnlicher molarer Masse. Die Schmelz- und Siedepunkte der Ether sind erheblich niedriger als die der vergleichbaren Alkohole, siehe den Alkohol Morphin (Smp. 253 °C) und dessen Methoxyether Codein (Smp. 157 °C). Die hohe Elektronegativität des Sauerstoffs bestimmt jedoch ähnlich wie bei den Alkoholen wesentlich die Eigenschaften der Ether. Besonders bei cyclischen Ethern führt dies zur Ausbildung eines ausgeprägten Dipolmoments. Außerdem liegt das polare Sauerstoff-Atom in einer cyclischen Struktur exponierter vor. Dies wird von der Wasserlöslichkeit einiger cyclischer Ether bewiesen.

Das niedrige Dipolmoment des 1,4-Dioxan wird durch seine symmetrische Struktur verursacht: die beiden sich im Ring gegenüberstehenden Sauerstoffatome verringern die Gesamtpolarität des Moleküls.

Für Ether sind verschiedene Synthesewege möglich. Der wohl bekannteste Mechanismus ist die Williamson-Ethersynthese. Hierbei wird ein Alkali-Alkoholat mit einem Halogenalkan umgesetzt, wobei neben dem entsprechenden Alkali-Halogen-Salz (nicht gezeigt) der Ether entsteht.

Die Reaktion verläuft nach einem S2-Mechanismus und wird zur Darstellung einfacher und gemischter Ether benutzt. Als Nebenreaktion kann Eliminierung auftreten, weshalb die Anwendung der Williamson-Ethersynthese mit tertiären Halogenalkanen nicht sinnvoll ist.

Die Williamson-Ethersynthese führt bei intramolekularer Reaktion zu cyclischen Ethern. Der einfachste Vertreter dieser Klasse ist Oxacyclopropan (Ethylenoxid, Oxiran); der bekannteste Vertreter Tetrahydrofuran (THF), ein beliebtes Lösemittel in der organischen Chemie.

Unter Säurekatalyse (hier Schwefelsäure) können zwei Moleküle Alkohol (gezeigt am Beispiel von Ethanol) unter Wasserabspaltung zu einem Ether (hier Diethylether) kondensiert werden:

Bei Verwendung nur einer Alkoholart (hier Ethanol) können auf diesem Weg symmetrische Ether (R–O–R) dargestellt werden. Verwendet man Gemische von z. B. zwei Alkoholen (z. B. R–OH und R–OH), so können unter Einwirkung von Schwefelsäure oder Phosphorsäure drei verschiedene Ether entstehen:



Alkohole können an Doppelbindungen addieren, wobei zunächst das Proton einer zugesetzten Säure elektrophil an die Doppelbindung addiert wird. Anschließend lagert sich der Alkohol nukleophil an, nach anschließender Deprotonierung entsteht der Ether:

Neben den „normalen“ Ethern, also Alkylresten mit Sauerstoffbrücke, gibt es auch Analoga mit Verwandten des Sauerstoffs. In der 6. Hauptgruppe folgt auf den Sauerstoff der Schwefel. Dieser bildet entsprechend den oben beschriebenen Regeln so genannte Thioether. Bei diesen ist die Sauerstoffbrücke durch eine Schwefelbrücke ersetzt. Zu den bekanntesten Thioethern zählen das „Senfgas“ oder S-Lost sowie die Aminosäure Methionin.

Kronenether sind eine besondere Gruppe von cyclischen Ethern, die aufgrund ihrer Bedeutung sowohl in der Chemie von Lebewesen als auch in der technischen Chemie Erwähnung verdienen. Allgemein sind es cyclische Ether, die aus aneinander gebundenen 1,2-Diethern bestehen. Die gängige Nomenklatur von Kronenethern ist ungewöhnlich. Einer der einfachsten Kronenether ist [12]Krone-4. Hierbei gibt [12] die Gesamtzahl der Atome (ohne Wasserstoffatome) in der cyclischen Ether-Teilstruktur an und -4 die Anzahl der Sauerstoffatome in diesem Molekülteil. Kronenether besitzen die einzigartige Fähigkeit, Metallatome (bzw. Metallionen) in einer Art Käfigstruktur zu binden und dadurch als Bausteine zu Transportsystemen dieser Metalle zu dienen.
Langkettige Verbindungen der Art

heißen "Polyether" (auch "Polyalkylenglycole", "Polyetherpolyole", "Polyalkylenoxide"). Beispiele für diese Gruppe polymerer Ether sind Polyethylenglycol und Polypropylenglycol, die beide durch katalytische Polymerisation der entsprechenden Epoxide ("Oxirane") Ethylenoxid bzw. Propylenoxid hergestellt werden. In Fall von Polyethylenglycol und Polypropylenglycol sind alle Reste (R, R, R…) mit Ausnahme der Endglieder der Ketten identisch.
Bei der Umsetzung von Epoxiden mit Diolen können verschiedenste Polymere hergestellt werden. Die Zugabe eines einfachen Alkanols stoppt die Polymerisierung.

Neben Diolen können auch mehrwertige Alkohole, wie z. B. Glycerin, 1,1,1-Trimethylolpropan (TMP), Pentaerythrit oder Sorbit mit Epoxiden in Gegenwart starker Basen (z. B. KOH) zu Polyetherpolyolen umgesetzt werden. Die monomeren Polyole wirken quasi als Starter für die basenkatalysierte ringöffnende Polymerisation von Oxiranen. In Analogie dazu steht die säurekatalysierte ringöffnende Polymerisation von Tetrahydrofuran zum Polyetherdiol Polytetramethylenglycol (PTMEG), auch Polytetrahydrofuran (PolyTHF) genannt.
Aus monomeren Triolen (Glycerin, TMP) werden mit Epoxiden entsprechend Polyethertriole erhalten. Bei der Polymerisation entstehen Gemische, die sich in der Molmassenverteilung der einzelnen Polyethertriolmoleküle und in den Kettenlängen der Ethersequenzen unterscheiden. Blockcopolymere können gezielt durch sequentielle Polymerisation mit unterschiedlichen Epoxiden hergestellt werden, wobei Copolymere mit außenständigen Ethylenoxideinheiten primäre, solche mit außenständigen Propylenoxideinheiten sekundäre Hydroxygruppen (mit verringerter Reaktivität) aufweisen.
Zur Charakterisierung von Polyetherpolyolen wird häufig die Hydroxylzahl (OH-Zahl) angegeben, deren Zahlenwert mit der Funktionalität des monomeren Polyols ansteigt und mit der molaren Masse des Polyetherpolyols abnimmt. Gängige Polyetherpolyole sind Lupranol (BASF) und Desmophen (Bayer Material Science).
Auch Epoxidharze sind Polyether mit endständigen Epoxidgruppen.
Polyetherdiole, wie z. B. Polyethylenglycol, sind wichtige Vorprodukte bei der Reaktion mit Isocyanaten zu Polyurethanen.

Bei Aufbewahrung von Ethern an Licht bilden diese mit Luftsauerstoff Peroxide. Diese können sich bei der (Vakuum-)Destillation eines Ethers im Rückstand ansammeln und zu Explosionen führen.

Dabei wird in α-Stellung zum Sauerstoff-Atom ein Wasserstoff-Atom unter Bildung eines Radikals abstrahiert und es bildet sich mit Sauerstoff ein Peroxid. Eine Ausnahme stellt Methyl-"tert"-butylether (MTBE) dar, da dieser auf der "tert"-Butyl-Seite kein α-ständiges Wasserstoff besitzt und auf der Methylseite die Entstehung eines Radikals zu ungünstig ist.
Die Peroxide können meist durch die Braunverfärbung von essigsauren Iodid-Lösungen nachgewiesen werden. Dabei wird Iodid zu Iod oxidiert, welches mit Iodid zu I reagiert und für die braune Farbe verantwortlich ist.
Im Handel sind zudem spezielle Teststäbchen erhältlich. Die Vernichtung von Peroxiden kann beispielsweise mit Eisen(II)-Salzen erfolgen. Die Lagerung von Ethern für den Labor-Gebrauch sollte daher nur in kleinen Gebinden von maximal 1 Liter über Kaliumhydroxid-Plätzchen in Braunglasflaschen erfolgen.

Bei dem Umgang mit niederen Ethern sollte deren niedriger Siedepunkt und leichte Entflammbarkeit nie unterschätzt werden. (Diethyl)Ether-Luft-Gemische sind zwischen 2 und 36 Vol.-% Ether explosiv.
Wichtig ist, dass Ether-Dämpfe nicht nur farblos, sondern auch schwerer als Luft sind. Sie sammeln sich also an tiefgelegenen Stellen. Aufgrund dieser Tatsache und der narkotisierenden Wirkung von Ethern sind sie nur in gut funktionierenden Abzügen zu verwenden.

Aufgrund ihres ambivalenten Charakters sind die meisten Ether hervorragende Lösungsmittel und lösen viele wasserunlösliche Verbindungen. So wird der Großteil des produzierten Diethylethers als Lösungsmittel im Umfeld der chemischen und medizinischen Industrie sowie im Laborbedarf verbraucht.




</doc>
<doc id="12923" url="https://de.wikipedia.org/wiki?curid=12923" title="Friedrich Luft">
Friedrich Luft

Friedrich Luft (* 24. August 1911 in Friedenau; † 24. Dezember 1990 in Berlin) war ein deutscher Theaterkritiker.

Friedrich Luft war der Sohn eines deutschen Studienrates und einer schottischen Mutter. Sein älterer Bruder war der deutsch-amerikanische Physiologe und Hochschullehrer Ulrich Cameron Luft. Friedrich Luft wuchs in der Friedenauer "Kaiserallee 74" (heute: Bundesallee) auf und besuchte das nahegelegene "Gymnasium Friedenau" am "Maybachplatz" (heute: Perelsplatz). Er studierte Germanistik, Anglistik und Geschichte in Berlin und Königsberg. Mit großem Interesse hörte er bei Max Herrmann die Vorlesungen über Theatergeschichte. Ab 1936 war er freier Autor. Er schrieb Feuilletons für das "Berliner Tageblatt" und die "Deutsche Allgemeine Zeitung". Für die Heeresfilmstelle verfasste er zahlreiche Drehbücher, beispielsweise für die Filme "Die Brieftaube im Einsatz" und "Das Pferd und die Gasmaske für das Pferd". Zudem produzierte er Texte für den Kabarettisten Werner Finck. Im Jahr 1940 heiratete er die Zeichnerin Heide Thilo.

Unmittelbar nach dem Zweiten Weltkrieg arbeitete er zunächst für den 1945 gegründeten "Tagesspiegel". Er hatte eine Kolumne unter dem Titel "Urbanus" mit bis heute lesenswerten Alltagsskizzen aus der Berliner Nachkriegszeit. Diese wurden 1948 vom Suhrkamp Verlag unter dem Titel "Tagesblätter von Urbanus" veröffentlicht. Die 1947 von der US-amerikanischen Besatzungsmacht gegründete "Neue Zeitung" nahm ihn als Feuilletonchef ihrer Berliner Ausgabe in Dienst, und zwar als Theater- und Filmkritiker, bis sie 1955 ihr Erscheinen einstellte.

Im Jahr 1959 schrieb er für die Autobiografie "Spiel im Dasein" von Max Ophüls, dem aus Saarbrücken stammenden Theater- und Filmregisseur "(Lola Montez", "Briefe einer Unbekannten)" das subtile 27-seitige Vorwort.

Vor allem aber war er beim Rundfunksender RIAS die „Stimme der Kritik“. Jeden Sonntagmittag, von der Erstsendung am 9. Februar 1946 bis zum 28. Oktober 1990 kurz vor seinem Tod, sprach er in dieser Funktion über Berliner Theaterpremieren der jeweils zurückliegenden Woche. Als rhetorische Eigenheiten galten sein schnelles und teilweise atemlos abgehackt wirkendes Sprechen, eine bisweilen drastische Ausdrucksweise verbunden mit barocken Schnörkeln wie auch die gleiche, immer wiederkehrende Verabschiedungsformel von den Hörern:
Zusätzlich dazu schrieb er im weiteren Verlauf auch Beiträge für die "Süddeutsche Zeitung" und "Die Welt". Von Luft stammte darüber hinaus das deutsche Dialogbuch zu dem David-Lean-Klassiker "Die Brücke am Kwai" aus dem Jahr 1957.

Friedrich Luft sprach fließend Englisch. Er wohnte und arbeitete 50 Jahre lang bis zu seinem Tode nahe dem Nollendorfplatz in der Schöneberger Maienstraße 4. Dort erinnert eine Gedenktafel an den in Berlin seinerzeit sehr beliebten Kritiker. Luft wurde auf dem Waldfriedhof Dahlem beigesetzt. Die gemeinsame Grabstätte mit seiner Frau Heide, die als Grafikerin und Illustratorin tätig war, befindet sich in der Abt. 8U-43. Sein Grab ist als Ehrengrab der Stadt Berlin gewidmet.

Im Jahr 1991 wurde in der Akademie der Künste das „Friedrich-Luft-Archiv“ eingerichtet. Es beinhaltet Manuskripte der Kritiken seiner Rundfunksendung "Stimme der Kritik" sowie eine Sammlung von Lufts Zeitungskritiken und Glossen aus den Jahren 1945 bis 1990, seine Bibliothek und ein Tonbandarchiv mit Mitschnitten seiner Rundfunksendungen aus den Beständen des RIAS.


Die "Berliner Morgenpost" verleiht seit 1992 den „Friedrich-Luft-Preis“. Dieser – derzeit mit 7500 Euro dotierte – Preis würdigt jährlich die beste Berliner Theateraufführung.




</doc>
<doc id="12924" url="https://de.wikipedia.org/wiki?curid=12924" title="Matrix">
Matrix

Matrix ([], []; lat. ' „Gebärmutter“, eigentlich „Muttertier“. Die Mehrzahl von Matrix heißt – je nach Bedeutung – ' [] oder eingedeutscht "Matrizen" [], []). Als Matrix wird bezeichnet:

Biologie:

weitere Naturwissenschaften:

Psychologie:

Technik:

Filme:

Literatur:

Namentlich:
MATRIX steht als Abkürzung für:
Siehe auch:



</doc>
<doc id="12926" url="https://de.wikipedia.org/wiki?curid=12926" title="Egon Erwin Kisch">
Egon Erwin Kisch

Egon Erwin Kisch (eigentlich "Egon Kisch;" 29. April 1885 in Prag – 31. März 1948 ebenda) war ein deutschsprachiger Schriftsteller, Journalist und Reporter. Er gilt als einer der bedeutendsten Reporter in der Geschichte des Journalismus. Nach dem Titel eines seiner Reportagebände ist er auch als „der rasende Reporter“ bekannt.

Egon Erwin Kisch war der zweite von fünf Söhnen des jüdischen Tuchhändlers Hermann Kisch und seiner Frau Ernestine. Sein ursprünglicher Name war Egon Kisch, den zweiten Vornamen Erwin begann er erst später als sein literarisches Pseudonym zu verwenden. Die Familie wohnte in einem Renaissancehaus „Zu den zwei goldenen Bären“ in der Prager Melantrichgasse (heute Melantrichova); im Erdgeschoss des Hauses befand sich ihre Tuchhandlung. Seine ersten Schuljahre verbrachte er in privaten Schulen, die sich in katholischen Klöstern befanden. 1891 lernte er in der Seidlschen Schule im Servitenkloster zu St. Michael, ab 1892 in der sogenannten Piaristenschule am Piaristenkloster. Ab 1895 besuchte er die Realschule – die kaiserlich-königliche Erste Deutsche Staatsschule in Prag in der Nikolandergasse, die im Volksmund als Nikolander-Schule bekannt war. Viele seiner Schulerfahrungen verwendete er später in seinen Erzählungen und Reportagen. Kischs Vater starb 1901. 1903 konnte Egon dank der finanziellen Unterstützung seiner Mutter seine erste weite Reise machen: Er besichtigte verschiedene Orte in Österreich und Bayern und schrieb seine Eindrücke von dieser Reise in einem Tagebuch auf. Im Oktober desselben Jahres begann er an der Technischen Hochschule in Prag zu studieren, wechselte jedoch nach einem Semester an die deutschsprachige Karl-Ferdinands-Universität, wo er Vorlesungen über Geschichte der deutschen Literatur und Geschichte der mittelalterlichen Philosophie belegte. In dieser Zeit wurde er Conkneipant der Saxonia Prag im Burschenbunds-Convent. Er focht mehrere Säbelmensuren: Im Ausschank eines jüdischen Branntweinhändlers in der Zigeunergasse gegen den Obmann des deutschvölkischen Vereins Germania; in der Garage eines deutschen Hotels in der Neustadt gegen einen Kontrahenten, der später im tschechisch-nationalen Leben der neugegründeten Republik eine Rolle spielte; und in einem verfallenen Klostertrakt gegen einen jüdischen Arzt aus Czernowitz. Er verfasste eine Abhandlung über das Prager Mensurwesen (enthalten in "Aus Prager Gassen und Nächten").

Im Oktober 1904 begann er seinen Militärdienst bei der k.u.k. Armee. Als Absolvent der Realschule konnte er den Dienst als Einjährig-Freiwilliger ableisten; auf Grund seiner Haltung kam es zu häufigen Konflikten zwischen ihm und seinen Vorgesetzten (die ihn für einen Anarchisten hielten), so verbrachte er einen großen Teil des Jahres im Arrest. Kisch erhielt zum Ende seiner Dienstzeit nicht die für Einjährig-Freiwillige übliche Beförderung zum Reserveoffizier, sondern wurde im Rang eines Korporals entlassen. Im Arrest kam er zum ersten Mal in Kontakt mit verschiedenen linksorientierten Gegnern des in Österreich-Ungarn herrschenden Systems, die er später so beschrieb:
Die ersten literarischen Versuche Kischs datieren noch aus seiner Schulzeit: um die Jahreswende 1899/1900 veröffentlichte er ein Gedicht in einer Prager Zeitung und unterschrieb es Erwin Kisch. Er tat dies, um Unannehmlichkeiten in der Schule zu vermeiden – die Leitung der Nikolander-Schule verbot es ihren Schülern, in der Presse zu publizieren. Dieser selbstgewählte zweite Vorname Erwin erschien auch auf dem Umschlag des Buchdebüts Kischs – des Gedichtbändchens "Vom Blütenzweig der Jugend," das mit finanzieller Unterstützung seiner Mutter 1905 in Dresden herausgegeben wurde und das er mit Egon Erwin Kisch unterschrieb. Von diesem Moment an verwandte Kisch in seinem Schaffen immer diesen doppelten Vornamen.

Im Jahr 1906 erschien das zweite Buch Kischs – der in Berlin herausgegebene Band mit Erzählungen und Geschichten (der einzige in seinem Leben, in dem er sich mit diesem Genre der Literatur befasste) unter dem Titel "Der freche Franz und andere Geschichten." Kischs Aufenthalt in Berlin war die Folge seiner Studien an der privaten Wredeschen Journalisten-Hochschule, an der er sich gleich nach seiner Entlassung aus dem Militär immatrikulierte. An dieser Hochschule studierte Kisch aber nur ein Semester; schon im März 1906 kehrte er nach Prag zurück und begann als Volontär bei dem deutschsprachigen „Prager Tagblatt“ zu arbeiten, wo er ca. sechs Wochen blieb. Im April wurde Kisch von der renommierten Prager Tageszeitung "Bohemia" beschäftigt, wo er als Lokalreporter arbeitete und über tägliche Ereignisse in Prag berichtete – dies war der Beginn der eigentlichen Karriere Kischs als Reporter und Journalist. Bei der "Bohemia" arbeitete Kisch mit Paul Wiegler zusammen, einem erfahrenen Schriftsteller und Journalisten, der ihn bei der Arbeit unterstützte. In den Jahren 1910–1911 hatte Kisch eine ständige Rubrik unter dem Titel "Prager Streifzüge;" seine journalistische und Reporterarbeit bei der Zeitung (bei der er sieben Jahre, von 1906 bis 1913, arbeitete), ging über das Schreiben von wöchentlichen Feuilletons hinaus. Wegen seines Berufs hatte Kisch oft Kontakt mit der Prager Halb- und Unterwelt, als er in seiner Zeitung Einbruchdiebstähle, Brandstiftungen, Dirnenschlägereien usw. beschrieb. Viele dieser Erfahrungen verwandte er später in seinen Reportagebänden "Aus Prager Gassen und Nächten" (1912), "Abenteuer in Prag" (1920) und in seinem einzigen Roman "Der Mädchenhirt" aus 1914, der über das Milieu der Prager Dirnen und Zuhälter erzählt.

Kisch lernte auch das literarische und artistische Milieu Prags kennen, sowohl das deutsche (Deutsche bzw. Deutsch-Österreicher bildeten damals einen großen Teil der Intelligenz und des Bürgertums Prags, Deutsch sprachen auch die meisten Prager Juden) als auch das tschechische. Unter den Schriftstellern, die er damals kennenlernte, waren Paul Leppin, Rainer Maria Rilke, Max Brod, Franz Kafka und Jaroslav Hašek, der Autor der "Abenteuer des braven Soldaten Schwejk während des Weltkrieges" – mit dem Letzteren verband ihn eine langjährige Freundschaft. Kisch war häufiger Gast in der Gaststätte „Zum Weißen Hasen“, dem Treffpunkt der Prager Boheme, und im Nachtcafé „Montmartre“. Von den dort erfahrenen Geschichten machte er in vielen seiner literarischen Reportagen Gebrauch, z. B. in der berühmten Erzählung "Die Himmelfahrt der Galgentoni."

Während seiner Arbeit bei der Bohemia fuhr Kisch auch ins Ausland: 1907 besuchte er Piräus, Konstantinopel und Neapel, 1909 besichtigte er die – damals noch heimische – adriatische Küste und Brioni, und 1911 machte er eine Reise auf einem Floß auf der Moldau und der Elbe, bis nach Magdeburg fahrend (seine Eindrücke von dieser Reise beschrieb er in einer Reportage). 1911 interviewte Kisch den Prag besuchenden amerikanischen Erfinder Thomas Alva Edison. 1912 unternahm er eine Reise nach London und Antwerpen.

Eine der letzten Aufgaben Kischs während seiner Tätigkeit für die Bohemia und gleichzeitig eine seiner größten Errungenschaften als Reporter war der investigative Journalismus in Gestalt der Offenlegung der Affäre um den Selbstmord des Obersten Alfred Redl. Redl, der für das Evidenzbüro – den k.u.k. Militärnachrichtendienst – arbeitete, wurde als russischer Spion enttarnt und beging schließlich am 25. Mai 1913 Selbstmord. Der Generalstab sah durch diese Affäre die Monarchie kompromittiert und suchte sie zu vertuschen, was durch Kischs Veröffentlichung vereitelt wurde. Schon in der Ausgabe der "Bohemia" vom 28. Mai veröffentlichte er eine kurze Notiz, in der zu lesen war:
Das angebliche Dementi erreichte sein Ziel. Durch die Notiz erfuhren nicht nur die breite Öffentlichkeit, sondern sogar der österreichische Kaiser Franz Joseph und der Thronfolger Franz Ferdinand von der größten Spionageaffäre vor dem Ersten Weltkrieg; sie war nicht mehr geheim zu halten. Seine Recherchen über Redl beschrieb Kisch detailliert im Buch "Der Fall des Generalstabschefs Redl," das 1924 herausgegeben wurde.

Im Juni 1913 siedelte Kisch nach Berlin um, wo er bei der Zeitung "Berliner Tageblatt" arbeitete. Im Frühjahr 1914 arbeitete er kurz als Dramaturg am Berliner Deutschen Künstlertheater (er ersetzte an diesem Posten Gerhart Hauptmann); schon am 31. Juli rückte er jedoch im Zuge der Mobilmachung beim "Infanterieregiment 11" in Písek (Südböhmen) ein. Drei Tage zuvor hatte Österreich-Ungarn dem Königreich Serbien den Krieg erklärt – der Erste Weltkrieg hatte begonnen.

Mit seinem Regiment, das zum „Prager“ VIII. Korps gehörte, nahm Kisch als Korporal am ersten Feldzug gegen Serbien 1914 teil. Er erlebte unter anderem die Niederlage der Österreicher an der Drina mit. Im Februar 1915 wurde Kisch mit dem Prager Korps an die russische Front verlegt und am 18. März schwer verwundet. Bis dahin führte er ein Tagebuch, das kurz nach dem Krieg (1922) unter dem Titel "Als Soldat im Prager Korps" herausgegeben wurde und heute unter dem 1929 geänderten Titel "Schreib das auf, Kisch!" bekannt ist. Nach der Entlassung aus einem Prager Krankenhaus wurde er als „felddienstuntauglich“ eingestuft. Seit 1916 arbeitete er als Zensor in der Etappe in Gyula in Ungarn. In dieser Zeit lernte er unter den Soldaten immer mehr Anarchisten, Pazifisten und Demokraten kennen; durch diese Kontakte verstärkte sich seine kritische Haltung zu sozialen und politischen Fragen.

Im Jahr 1917 wurde Kisch im Range eines Oberleutnants auf eigenes Ersuchen ins K.u.k. Kriegspressequartier in Wien abkommandiert, dessen Aufgabe die Koordination aller Presseinformationen und Propagandatätigkeiten der Donaumonarchie im Ersten Weltkrieg war. Paradoxerweise verursachte diese Verlegung den endgültigen Durchbruch in der Weltanschauung und der politischen Tätigkeit Kischs. In Wien kam er in Kontakt mit dem Verband der Unabhängigen Arbeiterjugend, und im November 1917 nahm Kisch in St. Aegyd am Neuwalde an einer Konferenz des illegalen Aktionskomitees der Linksradikalen teil. Das Komitee beschloss die Gründung eines illegalen Arbeiter- und Soldatenrates. Mit dieser Aufgabe wurde ein Dreier-Komitee betraut, dem auch Egon Erwin Kisch angehörte. Nach der Gründung des Rates wurde Kisch zu seinem Mitglied.

Im Januar 1918 wirkte er bei der Organisierung eines Generalstreiks mit. All das erregte die Aufmerksamkeit seiner Vorgesetzten, die ihn zum Dienst bei der k.u.k. Kriegsmarine befahlen. Kisch nahm an der letzten Offensive der österreichisch-ungarischen Kriegsmarine teil, deren Ziele das Durchbrechen der Otranto-Sperre und die Öffnung des Wegs von der Adria zum Mittelmeer waren. Die Offensive wurde unterbrochen, nachdem italienische Motortorpedoboote am 10. Juni das Schlachtschiff SMS Szent István versenkt hatten. Kisch kehrte nach Wien zurück und nahm aktiv an den stürmischen Ereignissen der letzten Monate des Jahres 1918 teil, die mit dem Fall der österreichisch-ungarischen Monarchie endeten. Am 1. November 1918 kam es zu einem Soldatentreffen, in dem die „Rote Garde“ gegründet und Oberleutnant Kisch – einer der Redner – zu ihrem ersten „Kommandeur“ gewählt wurde. Diese Funktion hatte er nur bis zum 18. November inne, als er unter Druck der Sozialdemokraten in der Regierung zurücktreten musste. Er befehligte aber weiter das zweite Bataillon, und die Soldaten wählten ihn zum „Kommissar“ der Roten Garde.

Kisch nahm an allen wichtigen Ereignissen teil, die am 12. November 1918 zum Fall der Monarchie und zur Ausrufung der Republik Deutschösterreich führten. An jenem Tag besetzte er mit seinen Soldaten für einige Stunden die Redaktion der "Neuen Freien Presse," in der auch sein älterer Bruder Paul als Redakteur tätig war. Dieser, wie alle anderen Redaktionsmitglieder aus dem Haus gewiesen, soll darauf mit den Worten „Egonek, Egonek, das schreibe ich der Mama“ reagiert haben. Kisch befahl, eine Sonderausgabe der Tageszeitung zu drucken, mit dem Ausgabedatum „8 Uhr abends“ des gleichen Tages, in der unter der Schlagzeile „Arbeiter und Soldaten Wiens!“ zu lesen war, die Kommunistische Partei Deutschösterreichs wolle mit der Besetzung der Redaktion „für die Idee der sofortigen Verwirklichung der sozialistischen Republik“ demonstrieren. Nach dem Erscheinen von zwei Sonderausgaben verließ die Rote Garde das Gebäude wieder.

Im November 1918 wirkte Kisch bei der Organisierung der Föderation Revolutionärer Sozialisten, „Internationale“, mit. Das Organ der Föderation war die Wochenzeitschrift "Der Freie Arbeiter," und Kisch war in der Zeitung für die ständige Beilage für Soldaten „Die Rote Garde“ verantwortlich. Die Beilage redigierte er bis März 1919. Wegen seiner Enttäuschung über die politische Entwicklung und immer häufigerer Drohungen verzichtete er schließlich auf diese Arbeit.

Im Mai 1919 wurde er Mitglied der Kommunistischen Partei Österreichs, nachdem sich seine „Föderation Revolutionärer Sozialisten“ mit ihr vereinigt hatte.

Nach dem Erlöschen der revolutionären Bestrebungen in der Tagespolitik engagierte Kisch sich weiterhin schriftstellerisch in politischen und sozialen Fragen. Vom März bis Juni 1919 arbeitete er als Reporter bei der links orientierten Wiener Zeitung "Der Neue Tag." Nachdem sich die politische Situation in Österreich stabilisiert hatte, wurde er zur unerwünschten Person erklärt und des Landes verwiesen. Er kehrte nach Prag zurück.

Schon 1921 siedelte Kisch wieder nach Berlin über, das bis 1933 sein Hauptwohnsitz bleiben sollte. Hier arbeitete er unter anderem an der Anthologie "Klassischer Journalismus;" er machte Recherchen und sammelte Materialien für dieses Buch in der Staatsbibliothek (Unter den Linden). Im Jahr 1921 lernte er in Berlin Jarmila Amrozová kennen, die, nach ihrer späteren Heirat mit dem Prager Journalisten Vincenc Nečas als Jarmila Haasová-Nečasová, seine langjährige Freundin und Übersetzerin seiner Werke ins Tschechische wurde. Im Jahr 1922 wurde er Berliner Korrespondent der Brünner Tageszeitung "Lidové noviny." Die Arbeit für diese Zeitung war seine Haupteinnahmequelle, er publizierte aber auch in vielen anderen Zeitungen und gab vor allem Reportagebände heraus.

Stoff für seine Reportagen lieferten Kisch die Reisen, die er von Berlin aus in ganz Europa und in der Welt unternahm, vor allem mehrfache Besuche in der Sowjetunion (zum ersten Mal 1925), Algerien und Tunesien (1927), den USA (mehrmonatiger Aufenthalt um die Jahreswende 1928–1929) und China (1932). Diese außerordentliche Aktivität Kischs bewirkte, dass der Titel eines seiner Reportagebände – "Der rasende Reporter" von 1924 – zu seinem bis heute bekannten Beinamen wurde.

Schon 1923 besuchte er Maxim Gorki, der sich damals in Bad Saarow aufhielt. Im November 1925 trat er der Kommunistischen Partei Deutschlands bei, und schon im folgenden Monat konnte er in das „Vaterland des Weltproletariats“ fahren. Seine Eindrücke veröffentlichte er in der Zeitschrift "Das Neue Russland" und der kommunistischen Tageszeitung "Die Rote Fahne;" 1927 gab er seinen ersten Reportageband über die Sowjetunion heraus: "Zaren, Popen und Bolschewiken," 1932 folgte der zweite Band: "Asien gründlich verändert," der von den Sowjetrepubliken in Zentralasien erzählte. Kisch war voller Enthusiasmus für die politischen und sozialen Veränderungen im kommunistischen Russland, ignorierte aber die Zwangsarbeitslager, die Hungersnot in der Ukraine oder die Verfolgungen der Russisch-Orthodoxen Kirche.

Ein ganz anderes Bild zeichnet Kisch in den Reportagen über seine mehrmonatige Reise in die Vereinigten Staaten um die Jahreswende 1928/1929. Nachdem Kisch das Schiff in New York City verlassen hatte, schiffte er sich wieder ein, diesmal als Leichtmatrose an Bord des Frachtschiffes „Jefferson Myers“, mit dem er von Baltimore über den Panamakanal nach San Pedro (heute Ortsteil von Los Angeles in Kalifornien) fuhr; dort traf er sich unter anderem mit Charlie Chaplin und dem sozialkritischen Schriftsteller Upton Sinclair. Über San Francisco, Chicago und Detroit kehrte er nach New York zurück. Eine Reportagereihe von dieser Reise (die er, als Kommunist, unter dem Decknamen Dr. Becker machen musste) veröffentlichte Kisch 1930 unter dem ironischen Titel "Paradies Amerika." Zwar ist in dem Buch auch eine verdeckte Faszination vom technologischen und Zivilisationsfortschritt Amerikas zu spüren, doch enthält es unter einem sozialistischen bzw. kommunistischen Gesichtspunkt sehr kritische Äußerungen über die sozialen Ungleichheiten und die kapitalistische Ausbeutung in den Vereinigten Staaten.

Der letzte große Reportageband, der in Deutschland in den 1930er Jahren erscheinen durfte, war "China geheim" von 1933 – die Frucht seiner Reise im Jahr 1932 nach China, das damals durch einen Bürgerkrieg zerrissen und durch die Mandschurei-Krise mit Japan bedroht war.

Der Schriftsteller befasste sich auch mit seiner näheren Umgebung, besonders unter geschichtlichem Aspekt. Er verarbeitete dabei eigene Erfahrungen, zum Beispiel als er 1922 sein Tagebuch aus dem Ersten Weltkrieg "Als Soldat im Prager Korps" (von 1929 an als "Schreib das auf, Kisch!") herausgab oder 1924 die Affäre um den Oberst Redl "(Der Fall des Generalstabschefs Redl)" aufdeckte. Er verwandte Geschichten, die er in Prager Kneipen gehört hatte, machte Recherchen, historische „Ermittlungen“ und interessierte sich für die jüdische Gemeinschaft. Früchte dieser Studien waren das "Kriminalistische Reisebuch" von 1937, eine Beschreibung von Verbrechen aus allen Zeiten und Ländern, die Sammlung "Geschichten aus sieben Ghettos" von 1934 und vor allem der viel gepriesene "Prager Pitaval" von 1931, in dem Kisch Kriminalgeschichten aus seiner Heimatstadt schilderte.

Kisch versuchte sich auch im Drama; die Stücke waren meistens Adaptationen seiner Prosawerke. Noch in Prag wurde in tschechischer Sprache sein Roman "Der Mädchenhirt" auf der Bühne aufgeführt; in Berlin schrieb er die Komödie "Die gestohlene Stadt" von 1922 (auf Grund seiner historischen Reportage "Käsebier und Fridericus Rex" über Christian Andreas Käsebier, einen Dieb aus Halle (Saale), und den preußischen König Friedrich II.), das Drama "Die Hetzjagd" (die Geschichte des Oberst Redl), die Tragikomödie "Die Himmelfahrt der Galgentoni" und, in Zusammenarbeit mit Jaroslav Hašek, die Satire "Die Reise um Europa in 365 Tagen" von 1930.

Einen Tag nach dem Reichstagsbrand, am 28. Februar um 5 Uhr morgens, wurde Kisch verhaftet und nach der Vernehmung im Polizeipräsidium Alexanderplatz in der Nacht vom 1. zum 2. März wegen „dringenden Verdachts der Teilnahme am Hochverrat“ in die Zitadelle Spandau gebracht. Kisch war jüdischer Abstammung, zunächst österreichisch-ungarischer und dann tschechoslowakischer Staatsbürger. Nach der Intervention der Botschaft der Tschechoslowakei wurde er am 11. März freigelassen, mit Polizeibegleitung an die deutsch-tschechoslowakische Grenze abtransportiert und aus Deutschland ausgewiesen. Über diese Erfahrung schrieb er den Bericht "In den Kasematten von Spandau," der in der Prager "Arbeiter Illustrierten Zeitung" veröffentlicht wurde und Aufsehen erregte.

Kisch engagierte sich sofort für den Widerstand gegen den Nationalsozialismus. 1933 hielt er eine Rede beim Antifaschistischen Arbeiterkongress Europas in Paris. 1934 übersiedelte er nach Paris und Versailles – bis 1939 seine „Stützpunkte“ für weitere Reisen. Seine Bücher wurden nun bei deutschen Emigrationsverlagen in Paris, Amsterdam und anderen Orten gedruckt.

1934 fuhr Kisch an Bord des britischen Passagierschiffs "Strathaird" nach Australien, um an dem Gesamtaustralischen Antikriegskongress teilzunehmen, der in Melbourne stattfinden sollte. Dies wurde eine der bekanntesten Reisen Kischs wegen der dramatischen Umstände seiner Ankunft: Als Kisch in Fremantle an der Westküste Australiens von Bord gehen wollte, wurde ihm der Aufenthalt im Land verweigert; auch der Pass wurde ihm abgenommen, obwohl er ein gültiges Visum hatte, vom britischen Konsulat in Paris ausgestellt. Der Grund war, dass die australischen Behörden inzwischen von Kischs kommunistischer Gesinnung vernommen hatten und ihn zur unerwünschten Person erklärten. Kisch fuhr mit dem Schiff weiter nach Melbourne. Dort, am 13. November, im letzten Augenblick, als das Schiff den Hafen in Melbourne schon verlassen sollte, sprang Kisch von der Reling aus fast sechs Metern Höhe auf den Kai und brach sich dabei ein Bein. Er wurde zurück an Bord gebracht, und als die "Strathaird" am 16. November im nächsten Hafen – Sydney – ankam, wurde er von Bord geholt, in das Polizeiquartier gebracht und nach langen Querelen wegen versuchter illegaler Grenzüberschreitung zu drei Monaten Zwangsarbeit verurteilt – die Strafe musste er allerdings nicht abbüßen, er wurde gegen Kaution entlassen. In der Zwischenzeit hatte Kischs Sache in Australien für großes Aufsehen gesorgt. Die australische Linke organisierte Proteste, Streiks und Demonstrationen, schließlich wäre es beinahe zu einer Regierungskrise gekommen: Der australische Generalstaatsanwalt Robert Menzies (der spätere Ministerpräsident Australiens) wurde nazistischer Sympathien bezichtigt. Schließlich wurde Kisch unter Druck der Öffentlichkeit befreit und konnte in Australien bleiben. Der enthusiastisch gefeierte Schriftsteller unternahm mehrere Reisen durch den fünften Kontinent, deren Frucht der Reportageband "Landung in Australien" war. Erst 1937 herausgegeben, war dies die letzte große Veröffentlichung Kischs vor Beginn des Zweiten Weltkriegs.

Im Jahr 1935 kehrte Kisch nach Europa zurück und engagierte sich wieder in der antifaschistischen Arbeit. Unter anderem nahm er im Juni 1935 am "I. Internationalen Schriftstellerkongress zur Verteidigung der Kultur" in Paris teil, auf dem er mit Heinrich Mann als Vertreter der deutschen Delegierten in den Kongressvorstand gewählt wurde. Auf dem Kongress hielt er das Referat "Reportage als Kunstform und Kampfform." Kisch nahm auch am "II. Internationalen Schriftstellerkongress" teil, der im Juli 1937 in Madrid, der Hauptstadt des damals durch den Bürgerkrieg zerrissenen Spaniens, stattfand. Kisch besuchte in dieser Zeit als Reporter verschiedene Frontabschnitte und interviewte Soldaten der Internationalen Brigaden. Die Früchte dieser Arbeit waren kleinere Zeitungsreportagen sowie die beiden Einzelpublikationen "Die drei Kühe" und "Soldaten am Meeresstrand," die 1938 von Verlagen der Internationalen Brigaden als Broschüren herausgegeben wurden. Anfang Mai 1938 kehrte Kisch nach Versailles zurück. Im Oktober heiratete er Gisela (Gisl) Lyner, die er 1919 in Wien kennengelernt hatte. 1939 arbeitete er an einem Manuskript über den Postmeister Jean-Baptiste Drouet aus Sainte-Menehould, der im Juni 1791 in Varennes die Flucht Ludwigs XVI. vereitelt hatte. Dieses Manuskript ist nicht erhalten.

Zu Beginn des Zweiten Weltkrieges im September 1939 wurde Kisch als „politisch unsicherer Ausländer“ durch die französischen Behörden zwangsweise in ein Dorf bei Versailles umgesiedelt und dort unter Polizeiaufsicht gestellt. Dank der Hilfe von Gilberto Bosques, des mexikanischen Generalkonsuls in Paris, der ihm ein Visum erteilte, gelang es Kisch Ende 1939, aus Frankreich auf den amerikanischen Kontinent zu fliehen.

Die erste Etappe auf seinem Exilweg waren die Vereinigten Staaten, wobei er Schwierigkeiten bei der Einreise in die USA bekam und mehrere Tage auf Ellis Island warten musste, bevor ihm am 28. Dezember 1939 ein Durchreisevisum erteilt wurde. In New York lebte Kisch unter schwierigen Bedingungen. Noch 1936 hatte er zwar mit dem amerikanischen Verlag Alfred A. Knopf, Inc. einen Vertrag über seine Autobiografie unter dem Titel "Crawling in the Inky River (Schwimmend im Tintenstrom)" geschlossen, in der geänderten politischen Lage kündigte der Verlag aber den Vertrag. Kisch befasste sich in New York unter anderem mit Recherchen über die Lebensverhältnisse der New Yorker Juden. Im Sommer 1940 kam aus Europa auch seine Frau Gisela (Gisl), und Ende des Jahres beschloss das Ehepaar, nach Mexiko zu fahren.

Mexiko war in den Jahren des Zweiten Weltkrieges ein reges Zentrum des kulturellen Lebens der deutschen Emigration. Im November 1941 gründeten die deutschen Emigranten – darunter die Schriftsteller Alexander Abusch, Ludwig Renn, Anna Seghers, Bodo Uhse – in Mexiko-Stadt den Heinrich-Heine-Klub; seine Präsidentin war Anna Seghers, zum Vize-Präsidenten wurde Kisch gewählt. Der Reporter schrieb Artikel für die Exilzeitung „Freies Deutschland“. 1941 erschienen bei Modern Age Books in New York in englischer Sprache auch seine Memoiren, deren Veröffentlichung der Verlag Alfred A. Knopf vorher verweigert hatte, allerdings unter einem anderen Titel: "Sensation Fair." Dies war der bekannte "Marktplatz der Sensationen," das große Erinnerungsbuch Kischs, das im folgenden Jahr beim Exilverlag El Libro Libre – Das Freie Buch – in Mexiko auch im Original in deutscher Sprache herausgegeben wurde.

Seine Reisen in Mexiko nutzte Kisch zum Schreiben des Bandes "Entdeckungen in Mexiko," der 1945 noch vor dem Ende des Krieges erschien. Dies war das letzte Buch von Egon Erwin Kisch.

Kisch verließ Mexiko-Stadt am 17. Februar 1946 und fuhr zuerst mit dem Zug nach New York. Nach einem kurzen Zwischenaufenthalt und Wiedersehen mit alten Freunden fuhr er mit dem Schiff nach Europa und kam am 21. März nach Prag zurück. Während des Krieges waren zwei seiner Brüder umgekommen – Arnold im Ghetto Litzmannstadt 1942, Paul im Konzentrationslager Theresienstadt 1944 (der dritte Bruder Wolfgang war bereits 1914 im Ersten Weltkrieg gefallen).

Kisch engagierte sich im politischen Leben der Tschechoslowakei, in der die Kommunistische Partei immer mehr an Bedeutung gewann. Er befürwortete die neue Ordnung, obwohl sie für seine deutschsprachigen Freunde die Vertreibung aus Prag und dem ganzen Land bedeutete.

Er wollte noch ein Buch über die befreite Tschechoslowakei schreiben; die letzte Reportage aus seiner Feder war "Karl Marx in Karlsbad." Seine Gesundheit verschlechterte sich plötzlich: Im November 1947 hatte er den ersten Schlaganfall, am 24. März 1948 folgte der zweite. Egon Erwin Kisch starb am 31. März 1948 in der Prager Klinik in der Kateřinská-Straße, bis ans Ende betreut von seiner Frau Gisl und seiner Freundin Jarmila Haasová-Nečasová. Er ist auf dem Friedhof Vinohrady in Prag begraben.

Kisch wird häufig als Schöpfer der literarischen Reportage bezeichnet. Er hat die literarische Reportage jedoch nicht erfunden, sondern selbst auf Anleihen verwiesen, die er bei Autoren des 19. Jahrhunderts genommen hat, wie etwa bei Jack London oder seinem journalistischen Vorbild aus Jugendjahren, Émile Zola. Kisch gebührt vielmehr das Verdienst, als „rasender Reporter“ durch seine ebenso informativen wie unterhaltsamen Milieuschilderungen der Reportage (die ursprünglich als rein journalistische Textsorte galt) im Literaturbetrieb erste und dauerhafte Anerkennung verschafft zu haben.

Im Sinne einer Würdigung der diesbezüglichen Verdienste wurde zwischen 1977 und 2004 an Kischs Geburtstag der von Henri Nannen gestiftete Egon-Erwin-Kisch-Preis verliehen – eine Auszeichnung für die beste journalistische Arbeit des jeweiligen Jahres. Der Journalistenpreis ging im Jahr 2005 in der Kategorie „Reportage“ des neu geschaffenen Henri-Nannen-Preises auf und gilt im deutschsprachigen Raum unter Journalisten nach wie vor als bedeutendste Auszeichnung.

Kischs intensives soziales und politisches Engagement (nicht zuletzt seine lebenslange Bindung an die Ideale der kommunistischen Bewegung) hatte bereits zu Lebzeiten wesentlichen Einfluss auf die Rezeption seiner Werke. Als exponierter Antifaschist wurde Kisch im nationalsozialistischen Deutschland nachhaltig aus dem kollektiven Bewusstsein gelöscht – wie viele der deutschsprachigen Exilautoren, deren Bücher 1933 ebenfalls verbrannt worden waren.

Nach dem Ende des Zweiten Weltkriegs und Kischs Tod im Jahr 1948 blieb der „rasende Reporter“ in der Zeit des Kalten Krieges westlich des Eisernen Vorhangs jahrzehntelang vergessen. In der DDR zählte er als sozialistischer Autor zum Kanon, seine Werke wurden laufend neu aufgelegt, in einer Gesamtausgabe zusammengefasst und waren trotz der Inanspruchnahme durch die staatstragende SED jahrzehntelang auf den Bestsellerlisten der Deutschen Demokratischen Republik (DDR) vertreten.

Ausgehend von der intensivierten Wiederentdeckung der deutschsprachigen Exilautoren in der Bundesrepublik Deutschland und in Österreich entstand spätestens seit den 1990er Jahren auch zu Kischs Person allmählich ein differenzierteres Bild, das ihn als sozial engagierten Kosmopoliten zeigt – sozialisiert inmitten der kulturellen Vielfalt, der sozialen Konflikte und Widersprüche der Habsburgermonarchie, traumatisiert von den Schrecken des Ersten Weltkriegs, die seine Entwicklung zum engagierten Reporter und Internationalisten mitbedingt haben.

Kisch selbst betrachtete sich spätestens ab den 1930er Jahren nach zahlreichen Reisen durch verschiedene Kontinente als „Weltbürger“. 1938 soll er sich im Gespräch mit Friedrich Torberg diesbezüglich geäußert haben:


In den Jahren 1960 bis 1985 erschien im Aufbau-Verlag unter der Bezeichnung "Gesammelte Werke in Einzelausgaben" eine elfbändige Werkausgabe, die in den 1990er Jahren erneut (diesmal in zwölf Bänden) aufgelegt wurde. Herausgegeben wurde sie von Bodo Uhse und Gisela Kisch, fortgeführt von Fritz Hofmann und Josef Polaček. Die Bände (in Klammern die Bandbezeichnung der zweiten Ausgabe) waren:




1985 entstand der Dokumentarfilm "Wissen Sie nicht, wo Herr Kisch ist," eine Koproduktion aus der DDR und der Tschechoslowakei.




</doc>
<doc id="12928" url="https://de.wikipedia.org/wiki?curid=12928" title="Naturrecht">
Naturrecht

Der Begriff Naturrecht ( oder , aus ‚Recht‘ und ‚Natur‘; bzw. natürliches Recht, lat. oder , aus ‚natürlich‘, „von Natur entstanden“) oder überpositives Recht ist eine Bezeichnung für universell gültiges Recht, das rechtsphilosophisch, moralphilosophisch oder theologisch begründet wird. Von diesen Vorstellungen abgeleitet dient es dem "gesetzten" (manchmal auch "gesatzten") oder "positiven Recht" als höchstrangige Rechtsquelle zur Legitimierung. Der Rechtspositivismus vertritt dagegen die Auffassung, dass verfassungsmäßig zustande gekommenes Recht keine höhere Begründung braucht.

Die säkularen rechtsphilosophischen Ausprägungen des Naturrechts, die nicht aus religiösen Grundwerten hergeleitet sind, sondern von der Erkennbarkeit durch menschliche Vernunft, werden als Vernunftrecht bezeichnet.

Dem Begriff des Naturrechts kann die Überzeugung zugrunde liegen, dass Dieses umfasst sowohl unstrittige Rechtsgrundlagen (Prämissen) in der Tradition antiker Philosophen wie Heraklit, den Sophisten, Aristoteles und Platon, die aus einer Idee einer objektiven oder absoluten Wahrheit herstammen, als auch die Vorstellung, jeder Mensch sei „von Natur aus“ (also nicht durch Konvention) mit unveräußerlichen Rechten ausgestattet – unabhängig von Geschlecht, Alter, Ort, Staatszugehörigkeit oder der Zeit und der Staatsform, in der er lebt. Insoweit ist die Naturrechtsidee eng verbunden mit der Idee der Menschenrechte. Die Naturrechte werden demnach als vor- und überstaatliche „ewige“ Rechte angesehen.

Daneben gibt es eine Auffassung von Naturrecht als „Recht des Stärkeren“. Unter der Voraussetzung der Gemeinnützigkeit bedeutete dies, dass gleiche Rechte den Sieg der besseren Leistung über angestammte Berechtigungen ermöglichen sollten. Im Sozialdarwinismus und Faschismus hat sich daraus allerdings ein paradoxes „angestammtes Recht der besseren Leistung“ ergeben – ähnlich wie zuvor beim Gottesgnadentum die „von Gottes Gnaden erwirkte“ Legitimation der nicht anzutastenden Monarchen­position aufgefasst worden war.

Die Berufung auf überpositives Recht geht davon aus, dass bestimmte Rechtssätze unabhängig von der konkreten Ausgestaltung durch die Rechtsordnung „schlechthin“ Geltung beanspruchen und somit durch einen positiven Akt der Rechtsetzung weder geschaffen werden müssen noch außer Kraft gesetzt werden können.
Fragestellungen des Naturrechts haben sich von alters her auf Aspekte konzentriert, mit denen sich sowohl Rechtsphilosophie als auch Philosophie und Theologie befassen. Das Naturrecht als wesentliches Teilgebiet der Rechtsphilosophie bildet eine der Grundlagen der Rechtswissenschaft.

Ferner ist das Naturrecht als Maßstab und Korrektiv des positiven Rechts zu verstehen. Diese Auffassung vertritt auch die römisch-katholische Kirche.

Die Idee der Naturrechte (in beiden Ausprägungen) reicht bis in die griechische Antike zurück und gewann mit der Aufklärung im 17. und 18. Jahrhundert politische Bedeutung. Sie befand sich nur teilweise in Opposition zum christlich-mittelalterlichen Verständnis der Gnade, demgemäß Eigenschaften wie Leben oder Freiheit durch gnädige Autoritäten wie Gott oder den Fürsten persönlich und willkürlich verliehen seien, ohne dass ein Recht darauf bestehe. Dennoch war die Naturrechtslehre im Mittelalter bei Philosophen wie Thomas von Aquin stark ausgeprägt, da die durch die Autoritäten verliehenen Eigenschaften nicht zur Disposition eines Nichtberechtigten gestellt wurden.

Die Wurzeln der Naturrechtslehren reichen zurück bis in die griechische Antike. Im sechsten vorchristlichen Jahrhundert entwickelten Ionier, die in Milet und den Hafenstädten am Westrand Kleinasiens lebten, die ionische Naturphilosophie. Diese Naturphilosophie verstand Natur (physis) als ursprünglich und von absoluter, ewiger innerer Gesetzmäßigkeit. Sie stellte sie dem menschlichen Gesetz gegenüber, dessen Gültigkeit nur auf Konventionen beruhe.

Lykurgs Gesetze, der Sage nach der Gründer Spartas, sollen von Apollon inspiriert gewesen sein. Es war üblich, dass Gesetzgeber sich an das Orakel von Delphi wandten, um von ihm die Genehmigung für ihre Pläne zu erbitten. Diese religiöse Grundlage der Gesetzgebung geriet ins Wanken, als die Sophisten sich der Naturphilosophie zuwandten und gegenüber dem Glauben an den göttlichen Ursprung der Gesetze einen respektlosen Skeptizismus entwickelten. Ein Teil der Sophisten übernahm die Vorstellung von der inneren Gesetzmäßigkeit der Natur und betrachtete aber auch die physische Wesensart des Menschen als von Natur gegeben. Gesetze stellten immer nur die Schwachen und die Menge auf. Dem Gesetz der Natur zu folgen bedeute, dass der Stärkere über den Schwächeren herrsche. Das Recht des Stärkeren sei naturgemäß. Anders urteilte der Sophist Protagoras aus Abdera, von dem der bekannte Satz stammt: „Der Mensch ist das Maß aller Dinge.“ Eine absolute Wahrheit gebe es nicht, auch keine objektive, sondern nur eine subjektive. Protagoras hatte im Jahr 443 v. Chr. an einer Verfassung für die athenische Pflanzstadt Thurioi in Süditalien mitgearbeitet und als erster die Theorie vom Ursprung der Gesetze aufgestellt, die unter dem Begriff eines Gesellschaftsvertrages bekannt wurde. Protagoras wurde der Gottlosigkeit angeklagt und aus Athen verbannt, seine Bücher vernichtet. Platon relativierte diese tiefgreifende positivistische Sichtweise des Protagoras. Seinem gleichnamigen Dialog stellte er eine Einleitung voran, die den Mythos wiedergibt, nach dem das Gewissen und der Sinn für Gerechtigkeit auf Zeus’ Befehl an die Menschen ausgeteilt worden seien.

Der zeitgleich mit Protagoras lebende antike Schriftsteller Sophokles thematisierte in seiner Tragödie Antigone das Verhältnis von durch Menschen erlassenen staatlichen Gesetzen, die auch Unrecht sein können, und göttlichen Gesetzen: Gegen das Gesetz des Herrschers, alle Staatsfeinde bei Todesstrafe unbestattet den Vögeln zum Fraß zu überlassen, begräbt Antigone ihren Bruder, der beim Angriff auf Theben gefallen war, um die Gebote der Götter der Unterwelt zu erfüllen.

Die nach Platon und Aristoteles einsetzende stoische Philosophie sah den Begriff der Natur in einer Einheit mit dem ewigen Weltgesetz, „lex aeterna“, das auch gleichzeitig „lex naturalis“ sei, das Gesetz der Natur. Am „logos“, der Vernunft des Weltgesetzes, habe der Mensch über seine eigene Natur teil, und auf dieser vernünftigen Natur des Menschen beruhe das Naturrecht. 

Diese Vorstellung liegt auch dem römischen Staats- und Rechtsdenken zu Grunde, denn die Stoa hatte erheblichen Einfluss auf das vorkaiserliche und besonders das klassische Recht der Kaiserzeit. Gemäß dem Begründer des systematisierenden Institutionensystems, Gaius, beruhte das "ius gentium" auf "ius naturale", einer als natürliche Vernunft verstandenen Normgewalt, die allen Völkern zugrunde läge. Es gebe eine höchste Vernunft, die in allen Menschen lebendig ist, mit der Natur übereinstimmend, unabänderlich und ewig. Dieser Vernunft zu gehorchen sei das einzige Gesetz, dem alle Menschen zu folgen haben.

Gegen Platons Ideenlehre wandte sich auch Epikur in seinem 33. Hauptlehrsatz der "Kyriai doxa": ; allein maßgeblich sei der Nutzen des Rechts, wie er im 37. Hauptlehrsatz aussagte: 

Sowohl die Kritik an der unterschiedlichen Behandlung der Menschen durch positive Gesetze wie auch Kritik an der Entwicklung der Gesetze überhaupt zum Vorteil der Schwachen ist in der Antike belegt (Platons "Gorgias" und "Kritias" oder Ciceros "De legibus").

Augustinus bezeichnet die von Ewigkeit her bestehende Schöpfungsordnung der Welt als "lex aeterna". Davon sei die "lex naturalis" ein Abdruck in der menschlichen „ratio“, der Vernunft. Die Schöpfungsordnung existiere in der Vernunft oder im Willen Gottes. In seinem Werk "Vom Gottesstaat" setzt er sich am Beispiel der Stadt Rom mit Ciceros Frage auseinander, ob der Staat möglicherweise ungerecht sein müsse. Was sich auf Unrecht der Menschen gründe, dürfe nicht Recht genannt oder für Recht gehalten werden.
Diese in der Spätantike entwickelte Vorstellung vom Schöpfergott als Urheber der Weltordnung trat im christlichen Mittelalter an die Stelle der antiken Vorstellung von unpersönlichen Weltgesetzen.

Zum philosophischen Grundproblem des Mittelalters wurde die Frage, ob in der "lex aeterna" die Vernunft oder der göttliche Willen den Vorrang habe. Eine erste einflussreiche Synthese der beiden Ursprünge der "lex aeterna" versuchte Thomas von Aquin.

In der scholastischen Moraltheologie und im Zeitalter der Aufklärung erlangten Naturrechtslehren erneut Bedeutung.

Die Renaissance wandte sich wieder der antiken Geisteswelt zu. Humanismus wurde die neue Bewegung genannt, die das Ideal einer an der Antike orientierten, rein „menschlichen“ (humanen), mithin nicht theologischen Bildung aufstellte. Nach Reformation und Gegenreformation, war die mittelalterliche Verbindung der Gerechtigkeitsfrage mit der Theologie nicht mehr selbstverständlich. Es begann nun eine Suche nach überkonfessionellen Standpunkten, die statt der christlichen Theologie ein Fundament der Gerechtigkeit bilden könnten. Schon bei Wilhelm von Ockham finden sich die „iura naturalia“, die Naturrechte auf Leben, Freiheit und Eigentum, wenn er auch noch als einzigen Grund für die Gerechtigkeit den Willen Gottes ansieht. Die Rechtsphilosophie der Aufklärung versuchte nun, diese Rechte als vernunftnotwendig abzuleiten.

Besonders einflussreich in der Ausformung eines „liberal“ bestimmten Naturrechtsgedankens waren hier die frühen Vordenker der Aufklärung. Hugo Grotius, ein protestantischer Jurist und Theologe, lebte in der Hafenstadt Rotterdam in Holland, das mit seinen Schiffen die Weltmeere befuhr und ein großes Interesse am Schutz seines Handels vor kriegerischen und räuberischen Übergriffen hatte. In der Konkurrenz zur portugiesischen, spanischen und englischen Handelsschifffahrt ging es als Wichtigstes um die Frage, ob es ein natürliches Recht auf freie Schifffahrt im Meer gebe. Dieses Recht durfte nicht von einem Staat gesetzt oder wieder aufgehoben werden können, es musste über den Staaten stehen und alle Staaten binden. Außerdem durfte dieses Recht „keinen Unterschied der Konfessionen kennen“, es musste sogar für nichtchristliche Konfessionen gelten, schließlich beschränkte sich der Handel nicht auf christliche Länder. Deswegen suchte Grotius das Recht in der Natur des Menschen, der vernunftgemäß eine „friedliche und einsichtig geordnete Gemeinschaft mit seinesgleichen“ anstrebe. Zum so verstandenen Naturrecht zählte Grotius, „daß man fremdes Gut respektiert und es zurückerstattet, wenn man es besitzt oder genommen hat, ferner die Pflicht, gegebene Versprechen zu erfüllen, sodann die Wiedergutmachung eines schuldhaft verursachten Schadens und die Vergeltung durch Strafe“. Zentraler Grundsatz des natürlichen Rechts sei die obligatio ex consensu (Verpflichtung aus Willensübereinstimmung) und die allgemeine Verpflichtung, Verträge einzuhalten.

Grotius und Samuel von Pufendorf lösten das Naturrecht von der religiös-theologischen Basis des sogenannten göttlichen Rechts und sahen es als konstantes Wertesystem, das über Gesellschaftsmodelle hinausgeht und von ihnen unabhängig ist. Allerdings stimmt für Pufendorf das Naturrecht Zu nennen ist in rechtspolitischer Hinsicht besonders John Locke, auf den sich die US-amerikanischen Gründerväter und insbesondere Thomas Jefferson bei der Formulierung der US-amerikanischen Unabhängigkeitserklärung stark bezogen.

Die Naturrechtsphilosophen Grotius, Pufendorf und Locke – alle drei waren Protestanten – entgingen der Vieldeutigkeit des Naturrechts, indem sie es mit der "biblischen Offenbarung" gleichsetzten. Ihrer Ansicht nach gingen Offenbarung und Naturrecht auf denselben Urheber, Gott, zurück. Sie nahmen in ihren Schriften, die sich mit politischen, rechtlichen und gesellschaftlichen Fragen beschäftigen, immer wieder Bezug auf das Alte und das Neue Testament. Insbesondere aus den Schöpfungsgeschichten (1. Mose 1 und 2), dem Dekalog (Zehn Gebote, 2. Mose 20), dem Verhalten und der Lehre Jesu (Barmherziger Samariter Luk. 10, 30–37, Liebesgebot Matth. 5, 44; 19, 19, Goldene Regel Matth 7, 12 u. a.) und den paulinischen Briefen gewannen sie zentrale Punkte ihrer politischen Theorien. Der Dekalog stellt unter anderem Leben, Eigentum und guten Ruf des Menschen, also seine Ehre und Würde, unter göttlichen Schutz. Der Vorspruch (2. Mose 20, 2) weist auf die Befreiung des Volkes Israel aus der ägyptischen Sklaverei hin. Gottes Befreiungstat geht den Forderungen voraus und begründet sie. Locke leitete die Gleichheit der Menschen, einschließlich der Gleichheit von Mann und Frau, nicht aus philosophisch-säkularen Prämissen ab, sondern aus 1. Mose 1, 27 f., der Grundlage der theologischen Imago-Dei-Lehre. Das Gleichheitsprinzip ist unabdingbare Grundlage jeder rechtsstaatlichen Demokratie. Sie begründet die Freiheits- und Teilhaberechte jedes Einzelnen. Aus ihr folgte für Locke, dass eine Regierung Macht nur mit der Zustimmung der Regierten ausüben darf. Das Recht auf Leben, (rechtliche) Gleichheit, Freiheit, Würde und Eigentum – damit waren zentrale Begriffe der Naturrechtslehren von Grotius, Pufendorf und Locke sowie anderer Gelehrten der Aufklärung benannt und mit biblischem Gehalt gefüllt.

Zu Beginn des 19. Jahrhunderts wurde in Europa das Naturrecht von der historischen Schule stark verdrängt, wozu insbesondere die deutsche Privatrechtswissenschaft beitrug, die die zeitlose Geltung von Naturrecht in Frage stellte. Als Vertreter dieses gedanklichen Ansatzes ist vornehmlich Friedrich Carl von Savigny zu nennen, der sein Augenmerk lieber auf das organische Wachstum von Gewohnheitsrecht richtete, das von Richtern und Rechtsgelehrten geschaffen wurde, als Naturrechtskodifikationen zu vertrauen. Als Quellen für ein funktionierendes Rechtssystem hatten für Savigny alle geschichtlich gewachsenen Rechtstraditionen Bedeutung. Nebenbei gelang es ihm die Differenz zum Rechtspositivismus einzuebnen. In der Sache richtete sich sein Vorwurf vornehmlich gegen die frühneuzeitlichen Einflussnahmen der Glossatoren und Kommentatoren auf die spätantiken, Rechtskompilationen, die seiner Auffassung nach ebenso zu Verfälschungen geführt hätten, wie Rechtsentwicklungen in den beiden Vorjahrhunderten.

In der Französischen Revolution wurde die biblisch-theologische Verankerung des Naturrechts durch die Lehre vom „gemeinsamen Nutzen“ ("utilité commune") ersetzt. Dadurch wurden die „Bürger- und Menschenrechte“ manipulierbar. Die jeweils an der Macht befindliche Gruppe der Revolutionäre bestimmte, was der „gemeinsame Nutzen“ war und schickte ihre politischen Gegner auf die Guillotine. Vor allem aus diesem Grund kritisierte z. B. Jakob Grimm im Frankfurter Parlament 1848 die französische Haltung und forderte die Rückkehr zu „den "religiösen Grundlagen" der Bruderschaft und Freiheit aller Menschen“ (Paulskirchenverfassung vom 28. März 1849). Damit berief er sich auf die amerikanische Unabhängigkeitserklärung (1776), die die unveräußerlichen Menschenrechte, zu denen „Leben, Freiheit und das Streben nach Glück“ gehören, theologisch begründete: Sie sind den Menschen von ihrem „Schöpfer“ ("Creator") verliehen worden.

Dieser vernunftbezogene Ansatz, der zum Begriff des "Vernunftrechtes" führt, prägt beispielsweise die österreichische Rechtsschule. So heißt es in Allgemeines Bürgerliches Gesetzbuch (ABGB) ausdrücklich: (Text aus der Erstfassung 1812). In der Folge ergibt sich in eine zentrale Rechtsaussage: , das heißt, wo keine explizite rechtliche Regelung vorhanden ist, bildet bei Persönlichkeitsrechten das „Vernünftige“ die Basis des Rechtmäßigen. Diese zentrale Aussage stellt Naturrecht also prinzipiell vor positives Recht: Das setzt voraus, dass der Bürger ein natürliches Empfinden hat respektive haben sollte, ob sein Handeln noch im Rahmen des Angemessenen ist. Entsprechendes gilt für die Justiz: ( ABGB). Diese Rechtsgrundlagen implizieren, dass das positive Recht nur als spezielles Regelwerk vor einem Hintergrund eines aus sich selbst heraus stabilen (aber auch entwicklungsfähigen) gesellschaftlichen Konsenses steht. Diese naturrechtlichen Ansätze prägen in Folge zentrale Begriffe wie die Rechtsfähigkeit und die Juristische Person, wie auch das österreichische Vertragsrecht, Erbrecht und Eherecht.

Das nationalsozialistische Recht war ideologisiertes Naturrecht, das das positiv gesetzte Recht unterlief. In seinem Mittelpunkt stehe die Gemeinschaft, so der nationalsozialistische Rechtstheoretiker Hans-Helmut Dietze in seinem Werk „Naturrecht in der Gegenwart“ von 1936. Das Naturrecht liege im Blut, sei also rassegebunden, und jeder Volksgenosse könne durch sein Rechtsempfinden die Entscheidung über Gut und Böse, über Recht und Unrecht treffen. Es wurzele „in den naturhaften Kräften, aus denen alles wirkliche Leben der Natur kommt: im Drängen des Blutes, in den Säften des Bodens und in der Innigkeit gleicher Gesinnung.“

Das Grundgesetz der Bundesrepublik Deutschland griff die naturrechtliche Tradition auf. Dass der Parlamentarische Rat tatsächlich Naturrecht dem Grundgesetz, insbesondere im Bereich der Menschenwürde, zugrundelegte, wird zunehmend anhand der Akten der Beratungen des Parlamentarischen Rates abgelehnt.

Nach dem Zweiten Weltkrieg und mit der Allgemeinen Erklärung der Menschenrechte von 1948 gewann das Naturrecht wieder an Bedeutung. So ist nach herrschender Meinung etwa auch der Gottesbezug in der Präambel des deutschen Grundgesetzes nicht etwa als theologische Verfassungskomponente aufzufassen, sondern im Wesentlichen als eine Berufung auf das Naturrecht.

Ein Beispiel für überpositives Recht stellt nach herrschendem Rechtsverständnis die Würde des Menschen dar (als Idee der unveräußerlichen Rechte). Das Grundgesetz garantiert diese zwar in Artikel 1 GG, doch wird ihre Unantastbarkeit hier nur als Prinzip des Rechts dargestellt; folgen soll sie vielmehr als allgemein gültiger Rechtssatz aus vorgelagerten ethischen oder religiösen Anschauungen, die für alle menschlichen Gesellschaften gelten sollen. Eine Konsequenz dieser Auffassung ist, dass die Menschenwürde nicht nur unantastbar, sondern insbesondere unverzichtbar sein soll. Der Rechtsträger kann somit nicht wirksam in ihre Verletzung einwilligen. Darüber hinaus führt der Gedanke, die Menschenwürde sei durch überpositives Recht vorgegeben, zu dem Ergebnis, dass ein Eingriff in die Menschenwürde eines Individuums auch außerhalb des Geltungsbereichs des Grundgesetzes unrechtmäßig ist. Der Eingriff verstoße gegen das gerade von keinem Rechtsetzungsakt geschaffene, sondern aus sich heraus geltende überpositive Recht.
In die Rechtsprechung des Bundesgerichtshofes floss das Naturrecht immer wieder auf dem Wege der Radbruchschen Formel ein, die unter bestimmten Umständen dem Naturrecht Vorrang vor dem positiven Recht gewährt.

Nach römisch-katholischer Morallehre ist anhand eines Moralcodex auch die Sittlichkeit des Menschen Teil des Naturrechts. Deutlich wird dies etwa in der Ansicht, dass laut Naturrecht die ausgelebte Homosexualität verwerflich sei. Begründet wird dies damit, dass es der Zweck der Sexualität sei, die Fortpflanzung der Art zu sichern. An diesen Ansichten wird kritisiert, Sexualität sei nicht nur auf die Fortpflanzung zu beschränken, und das Naturrecht gebiete daher keine absolute Rechtfertigung, homosexuelle Partnerschaften zu verurteilen. Denn erst der durch die Generationen entstandene sittliche Kodex gebe dem Naturrecht nach Ridley das natürliche Sittengesetz.

Die im Naturrecht gelehrten Rechtsprinzipien werden unterschiedlichen, aber immer vom Menschen nicht beeinflussbaren Quellen zugesprochen. Als Beispiele seien genannt:

Trotz der Möglichkeit, als Quelle des Naturrechts sowohl Gott als auch den Menschen anzusetzen, kann es nicht im Sinne der modernen Naturwissenschaft verworfen werden, sondern bildet einen Hauptgegenstand der Moral- und Rechtsphilosophie. Nach Johannes Messner besteht das für das Naturrecht als Hauptbasis angesehene (spezifisch menschliche) Naturgesetz „nicht in einem unveränderlich für alle Zeiten gleichen Moral­kodex, vielmehr in den das vollmenschliche Sein bedingenden und den Menschen verpflichtenden Grundwerten oder Grundprinzipien, die nur in ihrem allgemeinen Gehalt unveränderlich und nur insoweit absolute Geltung besitzen, als sie dem unveränderlichen und selbst einen absoluten Wert darstellenden Grundwesen der Personnatur des Menschen entsprechen“.

Für den Rechtspositivismus sind nur solche Normen verbindlich, die durch einen rechtsetzenden Akt erlassen worden sind. Überpositives Recht allein – als ein Bestand moralischer Grundsätze – unterliegt dann aus Sicht der positivistischen Rechtslehre einerseits nicht dem Zugriff des positiven Rechts, hat aber andererseits auch keine Rechtswirksamkeit. Der Druck konsens­fähiger Meinungen kann jedoch auf den Gesetzgeber Einfluss gewinnen, überpositive Grundsätze zum Gesetz (positives Recht) zu erheben.

Das Naturrecht bildet eine wesentliche Argumentationsgrundlage bestimmter Rechtsgebiete wie denen der Menschenrechte oder des Völkerrechts, die über nationale positivistische Regelungen hinausgehen müssen. , denn erst wo Gemeinschaft, dort auch Recht, weshalb Johannes Messner es so definiert:
Die Idee des Naturrechts entstammt in gewissen Aspekten dem Theismus, der ein göttliches Gesetz annimmt, das sich auch als Naturrecht zeige. Mit dem Wegfall Gottes innerhalb eines naturalistischen Weltbildes ergibt sich für die Naturrechtstheorie die Frage, wie Rechtsnormen jenseits menschlicher Institutionen entstehen können, insbesondere Normen, die für alle Menschen unabhängig von ihrer Kultur gelten sollen. Gibt es hierauf keine befriedigende Antwort, dann ist Naturrecht tatsächlich eine falsch bezeichnete ethische Theorie; dann kann es auch nicht zutreffen, dass etwa Gerichte angesichts zutiefst ungerechter positiver Gesetze nicht nach diesen Gesetzen, sondern stattdessen nach grundlegenden Moralprinzipien urteilen sollten. Diese Deutung entspricht der Begriffsgeschichte. Bei Christian Wolff bezeichnet der Ausdruck "Lex naturae" einfach das Sittengesetz, die moralischen Pflichten sind "officia naturalia".

Am Anfang der Naturrechtskritik steht die Einsicht, dass schon das Wort "Naturrecht" vieldeutig ist. Aus einer (angeblich) gottgestifteten Seinsordnung (so die katholische Naturrechtslehre), aus einem (angeblichen) Ur- oder Idealzustand der menschlichen Gesellschaft oder aus der „Natur des Menschen“ lasse sich als Naturrecht nur das herauslesen, was man zuvor als theologische oder moralische Prämissen hineingelegt habe. Solches normativ aufgeladene "Naturrecht" beruht also auf einem Zirkelschluss. Wenn der Inhalt des Naturrechts hingegen nur allgemeingültige Sätze wie „Das Gute ist zu tun, das Böse zu lassen“ beinhaltet, liegt kein Zirkelschluss vor.

Die Vieldeutigkeit des Naturrechts hebt auf andere Weise auch Erik Wolf hervor. Er schreibt: Helmut Thielicke pflichtet dem bei und meint, dass Wolf Dass das Naturrecht vieldeutig ist, ist auch daraus ersichtlich, dass die Sklaverei, die nach heutigem Verständnis wohl den gravierendsten Bruch der Menschenrechte darstellt, von der griechisch-römischen Antike bis ins 19. Jahrhundert naturrechtlich begründet wurde.











</doc>
<doc id="12930" url="https://de.wikipedia.org/wiki?curid=12930" title="Reporter">
Reporter

Ein Reporter (engl. "to report" ‚Bericht erstatten, wiedergeben, aufnehmen‘; altfranzös. "reporter" ‚berichten‘; latein. "reportare" ‚zurückbringen‘), auch Berichterstatter, ist eine Bezeichnung für die spezielle Tätigkeit eines Journalisten von einem Geschehen an dessen Ort und Stelle. 
Der Reporter berichtet über aktuelle Ereignisse vor allem aus den Bereichen Justiz, Kultur, Lokales, Politik, Ausland, Wissenschaft und Sport für Presse, Hörfunk und Fernsehen. Die Reportage kann im Hörfunk und Fernsehen sowohl „live“ – also zeitgleich – übertragen als auch aufgezeichnet und – meist noch redaktionell bearbeitet – nachträglich gesendet werden.

Berühmt als der „rasende Reporter“ wurde um 1920 in Deutschland Egon Erwin Kisch (1885–1948).

Zahlreiche Journalisten beziehungsweise Reporter wurden während ihrer Berufsausübung getötet.

Ein neuer Trend sind Amateurreporter, die Geschehen für wenig oder ganz ohne Bezahlung beobachten und fotografieren. Davon zu unterscheiden sind Bürgerreporter wie z. B. in Südkorea (OhmyNews).




</doc>
<doc id="12931" url="https://de.wikipedia.org/wiki?curid=12931" title="Reportage">
Reportage

Als Reportage (von = berichten, melden) bezeichnet man im Journalismus unterschiedliche Darstellungsformen, bei denen der Autor nicht vom Schreibtisch aus, sondern aus unmittelbarer Anschauung berichtet. In den Druckerzeugnissen steht der Begriff gemeinhin für einen dramaturgisch aufbereiteten (siehe auch Reportagefotografie) Hintergrundbericht, der einen Sachverhalt anhand von konkreten Beispielen, Personen oder deren Schicksalen anschaulich macht. Während Nachricht und Bericht Distanz wahren, geht die Reportage nah heran und gewährt auch Beobachtungen und weiteren Sinneswahrnehmungen ihrer Protagonisten Raum.

Im Rundfunkjargon gilt bereits die einfache Berichterstattung vom Ort des Geschehens als Reportage. So firmieren Sportjournalisten, die live aus dem Stadion Fußballspiele kommentieren, oft als Fußballreporter.

Dem Reporter ist es – im Gegensatz zum Verfasser von Nachrichten oder Berichten – erlaubt, Fakten durch eigene Eindrücke zu ergänzen, die er – oft bei Anwesenheit am Ort des Geschehens – gesammelt hat. Idealerweise erzählt er, ohne dabei zu werten oder zu kommentieren, auch nicht durch Weglassen. Er beschränkt sich auf eine narrative Funktion, spricht überwiegend im Präsens und bewirkt dadurch, dass sich der Rezipient (Leser, Zuhörer oder Fernsehzuschauer) gut in die Situation hineinversetzen kann.

Beispiel: „Ein Haus hat gebrannt.“ Die Reportage beschreibt detailliert, wie es darin aussieht, und versucht, beim Rezipienten oder bei der Rezipientin „Kino im Kopf“ ablaufen zu lassen. Sie schildert die „versengten, schwarzen Treppengeländer, denen man nur schwer ansieht, dass sie aus Holz sind“.

Eine Reportage kann verknüpft sein mit Interviews und Kommentaren. Sie kann aus Texten, Fotografien (Fotoreportage) oder einer Kombination aus beidem bestehen. Letzteres ist die verbreitetste Form.

Eine Sonderform ist die Gerichtsreportage. Zu den bekanntesten Autoren in diesem Genre gehören in Deutschland der Spiegel-Redakteur Gerhard Mauz (gestorben 2003), seine Nachfolgerin Gisela Friedrichsen sowie Peggy Parnass, Hans Holzhaider und Sabine Rückert.

Sozialreportagen üben Gesellschaftskritik. Als Begründer der Sozialreportage im deutschsprachigen Raum gilt Max Winter. 
Bekannte Beispiele sind 







</doc>
<doc id="12932" url="https://de.wikipedia.org/wiki?curid=12932" title="Erhaltungssatz">
Erhaltungssatz

Als Erhaltungssatz bezeichnet man in der Physik die Formulierung der beobachteten Tatsache, dass sich der Wert einer Größe, Erhaltungsgröße genannt, in bestimmten physikalischen Prozessen nicht ändert.

Der bekannteste Erhaltungssatz ist der der Energie. Umgangssprachlich lautet er: Was man vorn an Energie hineinsteckt, kommt auch hinten wieder heraus; es geht keine Energie verloren und es entsteht keine aus dem Nichts. Die allgemeinsten Erhaltungssätze gelten für die Größen Energie, Impuls, Drehimpuls, elektrische Ladung, Baryonenzahl und Leptonenzahl. Für bestimmte Klassen von physikalischen Vorgängen (siehe Grundkräfte der Physik) kommen weitere Erhaltungssätze hinzu.

Nach dem Noether-Theorem hat jede physikalische Symmetrie, die kontinuierlich ist, einen Erhaltungssatz zur Folge.

Erhaltungsgrößen lassen sich aus den Größen berechnen, die den Zustand eines Systems beschreiben, beispielsweise Orte und Geschwindigkeiten von Teilchen. Während sich die Zustandsgrößen bei Bewegung mit der Zeit ändern, bleiben die daraus berechneten Erhaltungsgrößen zeitlich konstant. So hängt die Energie eines Teilchens der Masse formula_1 im Potential formula_2 

von seiner Geschwindigkeit formula_4 und seinem Ort formula_5 ab. Auch wenn sich sowohl die Geschwindigkeit als auch der Ort im Laufe der Zeit formula_6 ändern, so bleibt die Energie

zeitlich unverändert. 

Erhaltungsgrößen schränken die denkbare Bewegung des physikalischen Systems ein. Beispielsweise folgt aus der Energie- und Impulserhaltung bei der Compton-Streuung, wie die Energie des gestreuten Photons mit seinem Streuwinkel zusammenhängt und (abhängig vom Streuwinkel des Photons, der nicht festgelegt wird) mit welcher Energie und in welche Richtung sich das ursprünglich ruhende Elektron nach der Streuung bewegt.

Viele Erhaltungsgrößen, beispielsweise der Gesamtimpuls, sind additiv. In Zwei- und Mehrteilchensystemen ist der Wert der additiven Erhaltungsgröße die Summe der Einzelwerte.
Der Gesamtimpuls, beispielsweise, ist die Summe der einzelnen Impulse. Diese scheinbare Selbstverständlichkeit gilt nur für Teilchen, die nicht (mehr) wechselwirken. Während der Wechselwirkung können Felder Energie und Impuls aufnehmen und an andere Teilchen übergeben.




Besitzt das betrachtete physikalische System so viele Erhaltungsgrößen formula_11 wie Freiheitsgrade, so lässt sich die zeitliche Entwicklung durch Integrale angeben. Man spricht von einem Integrablen System, wenn die formula_11 in Involution sind, das heißt die Poisson-Klammer
für alle formula_14, formula_15 Null wird.

Dies entspricht der Vertauschbarkeit der zu den Erhaltungsgrößen gehörenden Symmetrietransformationen bei Hintereinanderausführung.

Im einfachsten Fall, energieerhaltende Bewegung eines Freiheitsgrades formula_16, löst man den Energiesatz
nach der Geschwindigkeit auf
Die Ableitung der Umkehrfunktion formula_19, die angibt, zu welcher Zeit das Teilchen den Ort formula_16 durchläuft, ist der Kehrwert,
Integriert man diese Gleichung über formula_16 von einer unteren Grenze formula_23 bis zu einer frei wählbaren oberen Grenze formula_24, so ergibt sich
Es liegt also die Umkehrfunktion formula_26 als Funktion der oberen Grenze
eines Integrals über die gegebene Funktion formula_27 fest. Dabei ist die Startzeit formula_28 und die anfängliche Energie formula_29 frei wählbar.

Die Erhaltungssätze gehören zur modernen Physik des 20. Jahrhunderts. Ende des 19. Jahrhunderts listeten die großen deutschen Enzyklopädien unter „Erhaltung“ drei Themenbereiche auf: Bei „Erhaltung der Energie“ verwiesen sie direkt auf die Kraft, bei „Erhaltung der Flächen“ auf die Zentralbewegung, bei der „der Leitstrahl in gleichen Zeiten gleiche Flächenräume beschreibt“ (heute genannt: Erhaltung des Drehimpulses). Der einzige Erhaltungssatz, der als solcher breiteren Raum einnahm, war ein von den Autoren als schwierig deklarierter, der der „Erhaltung der Welt“:



</doc>
<doc id="12933" url="https://de.wikipedia.org/wiki?curid=12933" title="235">
235







</doc>
<doc id="12935" url="https://de.wikipedia.org/wiki?curid=12935" title="Litotes">
Litotes

Die Litotes ( "litótēs" „Sparsamkeit‚ Zurückhaltung“, zu "litos" „schlicht, einfach“) ist die Stilfigur der doppelten Verneinung (z. B. "nicht unüblich") oder der Verneinung des Gegenteils (z. B. "nicht selten"). Damit kann zum Beispiel eine Behauptung vorsichtig ausgedrückt oder eine Aussage abgeschwächt werden (Untertreibung). Aber auch eine Hervorhebung kann indirekt bewirkt werden. Die Litotes taucht oft im Rahmen von Ironie auf.

Doppelte Verneinung:

Verneinung des Gegenteils:

Ein bekanntes Beispiel aus dem Englischen ist "not amused". Zum Beispiel bedeutet "She is not amused" wörtlich „Sie ist nicht erfreut“, dahinter verbirgt sich jedoch eher die Bedeutung „Sie ist verärgert“. Die Ausdrucksweise veranschaulicht, dass eine Aussage („verärgert“) durch die Verneinung des Gegenteils („nicht erfreut“) abgeschwächt werden kann. Sie eignet sich dadurch für höfliche Ausdrucksweisen, aber auch für die ironische Verwendung. 

Ein lateinisches Beispiel ist "non ignorare" für „genau wissen“ (von "non", „nicht“, und "ignorare", „verkennen“).

Beispiele aus der Politik wären: 

In manchen Sprachen, auch in deutschen Dialekten, stellt die doppelte Verneinung tatsächlich eine Verneinung dar:



</doc>
<doc id="12937" url="https://de.wikipedia.org/wiki?curid=12937" title="Sorben">
Sorben

Die Sorben (, , vor allem in der Niederlausitz auf deutsch auch "Wenden", deutsch veraltet bzw. in den slawischen Sprachen bis heute "Lausitzer Serben") sind eine westslawische Ethnie, die vorwiegend in der Lausitz im östlichen Deutschland lebt. Zu ihr gehören die Obersorben in der sächsischen Oberlausitz und die Niedersorben/Wenden in der Niederlausitz in Brandenburg, die sich sprachlich und kulturell unterscheiden. Die Sorben sind in Deutschland als nationale Minderheit anerkannt. Sie haben neben ihrer Sprache eine offiziell anerkannte Flagge und Hymne. Sorben sind in aller Regel deutsche Staatsangehörige.

Im Mittelalter siedelte ein gleichnamiger Stamm zwischen Saale und Mulde. Dieser ist mit den Vorfahren der heutigen Sorben – Lusizern und Milzenern – nicht identisch.

Nach offiziellen Angaben gibt es rund 60.000 Sorben. Diese Zahlen beruhen auf Hochrechnungen aus den 1990er Jahren. Auf Grundlage der Selbstzuschreibung wurden dabei 45.000 bis 50.000 und auf Basis der aktiven Sprachkenntnis circa 67.000 Sorben ermittelt. Davon leben etwa zwei Drittel in der sächsischen Oberlausitz, vorwiegend im katholischen Dreieck zwischen den Städten Bautzen, Kamenz und Hoyerswerda (in den fünf Gemeinden am Klosterwasser sowie in der Gemeinde Radibor und Teilen der Gemeinden Göda, Neschwitz, Puschwitz und in der Stadt Wittichenau). Im amtlichen sorbischen Siedlungsgebiet in Sachsen liegt der Anteil der Sorben schätzungsweise bei durchschnittlich 12 % und beträgt an der Gesamtbevölkerung Sachsens etwa 0,9 %. Ein Drittel lebt in der Niederlausitz, vorwiegend zwischen Senftenberg im Süden und Lübben im Norden, wobei 90 % davon in dem Landkreis Spree-Neiße und der kreisfreien Stadt Cottbus leben. In den deutsch-sorbischen Teilen der Kreise in Brandenburg liegt der Anteil der Sorben schätzungsweise bei durchschnittlich 7 % und beträgt an der Gesamtbevölkerung Brandenburgs etwa 0,8 %.

Noch in den 1880er Jahren umfasste das Kernsiedlungsgebiet größere Gebiete südlich und östlich von Bautzen (bis Kirschau, Oelsa und Bad Muskau) sowie nördlich von Cottbus, in denen die Sprache heutzutage nicht mehr gesprochen wird. 

Auch östlich der Neiße, auf heutigem polnischen Staatsgebiet, gab es bis ins 20. Jahrhundert hinein Sorben. Das Zentrum ihrer Kultur und Sprache zur deutschen Zeit war die Stadt Sorau (sorbisch Žarow, heute polnisch Żary). Bis ins 18. Jahrhundert trugen die Frauen und Mädchen die traditionelle sorbische Sorauer Tracht, jedoch wurde das Sorbische immer mehr durch die damalige preußische Politik benachteiligt oder sogar unterdrückt. Daraus und aus natürlich ablaufenden Assimilationsprozessen resultierte, dass 1843 bis 1849 sich noch ca. 4–5 % der Sorauer Bevölkerung als Sorben bezeichneten, jedoch nur ca. 1–2 % im Jahr 1890 und 1905 sogar nur noch 0,1 %. Heute ist die Sprache der Bevölkerung fast ausschließlich Polnisch, wenige haben Deutsch als Muttersprache. Die damalige sorbische Bevölkerung wurde germanisiert und Ende des Zweiten Weltkrieges zum größten Teil vertrieben, da sie Reichsangehörige waren. Die wenigen in Polen verbliebenen Sorben wurden in das polnische Volk assimiliert.

Von der sorbischen Sprache existieren zwei Schriftsprachen (Standardvarietäten), Obersorbisch "()" und Niedersorbisch "()", jedoch wird meistens zwischen Niedersorbisch, Obersorbisch und der Gruppe der dazwischenliegenden Grenzdialekte unterschieden. Die niedersorbische Sprache ist akut vom Aussterben bedroht. Während das Obersorbische dem Tschechischen und Slowakischen näher steht, ist das Niedersorbische dem Polnischen ähnlicher.

Nach Schätzungen sorbischer Institutionen (Domowina, Sorbisches Institut) gibt es heute 20.000 bis 30.000 aktive Sprecher beider sorbischer Sprachen, anderen Hochrechnungen zufolge hat das Niedersorbische dagegen nur noch 7.000 aktive Sprecher und das Obersorbische etwa 15.000.
Der Kern des obersorbischen Gebiets, in dem das Sorbische Alltagssprache ist und von der großen Mehrheit der Bevölkerung genutzt wird, sind dabei die Gemeinden Crostwitz, Ralbitz-Rosenthal, Panschwitz-Kuckau, Nebelschütz und Räckelwitz sowie Teile der angrenzenden Gemeinden Neschwitz, Puschwitz und Göda. Ein weiteres Zentrum ist die Gemeinde Radibor. In der Niederlausitz kann von einem stabilen Kerngebiet in dieser Form nicht mehr gesprochen werden. Die meisten Niedersorbisch-Muttersprachler findet man jedoch in den Gemeinden zwischen dem Spreewald und Cottbus.

In einem Streifen von Bad Muskau im Osten über Schleife bis nach Hoyerswerda im Westen werden Übergangsdialekte gesprochen, die sogenannten Sorbischen Grenzdialekte. Sie unterscheiden sich von beiden Standardsprachen teils erheblich.

Aufgrund der vorherrschenden Armut in den ländlichen Gebieten des Deutschen Bundes Mitte des 19. Jahrhunderts kam es auch in der Lausitz zu einer Abwanderung kleinerer sorbischer Bevölkerungsteile.
Eine Gruppe von über 500 Sorben unter der Führung des evangelisch-lutherischen Pfarrers Jan Kilian segelte 1854 auf dem Schiff „Ben Nevis“ nach Galveston. Sie gründeten später die Siedlung Serbin im texanischen Lee County nahe Austin. Zwei Drittel der Emigranten stammten dabei aus dem preußischen, ein Drittel aus dem sächsischen Teil der Oberlausitz, darunter ca. 200 Sorben aus der Umgebung Klittens. Bis in die 1920er Jahre hielt sich die sorbische Sprache, eine Variante des Obersorbischen, die zuerst vom Deutschen, später vom Englischen stark beeinflusst wurde. Früher wurden in Serbin auch Zeitungen auf Sorbisch veröffentlicht. Heute befindet sich in der ehemaligen sorbischen Schule von Serbin das Texas Wendish Heritage Museum, das über die Geschichte der Sorben in den USA berichtet. Nachfahren dieser Auswanderer gründeten 1926 in der texanischen Hauptstadt Austin die Concordia Universität Texas.

Weitere sorbische Siedlungen – überwiegend gemeinsam mit deutschen Auswanderern – gab es in verschiedenen Gebieten Australiens, vor allem im Süden Australiens. In den Jahren 1848 bis 1860 kamen die meisten Sorben, etwa 2000 in 400 Familien, ein großer Teil von ihnen mit den Schiffen „Pribislaw“ und „Helena“. Auch in Australien nach der Auswanderung wurde die sorbische Sprache stark vom Deutschen beeinflusst, da sie wegen der fehlenden Englischkenntnisse meist in die deutschen Sprachregionen zogen. Die letzte Nachkommin der sorbischen Einwanderer, welche die Sprache noch beherrschte, starb 1957 in Sevenhill.

Die meisten Sprecher des Obersorbischen sind heutzutage katholischer Konfession. Ursprünglich war die Mehrzahl der Sorben noch bis ins 20. Jahrhundert evangelisch-lutherisch (86,9 % im Jahr 1900), nur die Sorben des Kreises Kamenz – angesiedelt überwiegend auf dem ausgedehnten ehemaligen Grundbesitz des Klosters St. Marienstern – waren zu 88,4 % Katholiken. In der Niederlausitz lag deren Anteil dagegen durchweg unter einem Prozent. Aufgrund des schnelleren Sprach- und Identitätsverlustes unter der evangelischen sorbischen Bevölkerung – insbesondere in der DDR-Zeit – ist dieses Verhältnis heute umgekehrt.

Die unterschiedliche Entwicklung des Sprachverhaltens im katholischen bzw. evangelischen Sorbentum ist zum einen auf die unterschiedliche Struktur der Kirchen zurückzuführen. Während es sich bei der evangelischen Kirche um eine Landeskirche handelt (wobei die Landesherren der sorbischen Bevölkerung immer deutschsprachig waren), ist die katholische Kirche in ihrer ultramontanen Ausrichtung auf den Vatikan seit jeher transnational. Die größere Staatsnähe der evangelischen Kirche sollte sich besonders mit der in der Niederlausitz seit dem 17. Jahrhundert betriebenen Germanisierungspolitik negativ auf das sorbische Sprachgebiet auswirken. Zum anderen herrschte in der katholischen Kirche eher die Meinung vor, dass die Muttersprache als göttliches Geschenk zu betrachten sei, welches abzulegen Sünde wäre. So erklärt sich der seit dem Ende des 19. Jahrhunderts verstärkt betonte außergewöhnlich enge Zusammenhang zwischen Katholizismus und Sorbentum, der bis in die heutige Zeit besteht.

Die katholischen Gemeinden stellen heute den Kern des verbliebenen Mehrheitsgebietes dar, während in den evangelischen Gebieten im Osten und Norden die Sprache zumeist verschwunden ist. Während in der westlichen Oberlausitz insbesondere die jahrhundertelange Verbundenheit der Sorben zur katholischen Kirche maßgeblich zum Erhalt der sorbischen Muttersprache beigetragen hat, zeigte in der Niederlausitz die evangelische Kirche vor und nach 1945, trotz allgemeiner Förderung der Sorben in der DDR, kein Interesse, die Sprache der Minderheit im kirchlichen Leben zu pflegen. Erst seit 1987 gibt es auf Initiative einiger Niedersorben wieder regelmäßigen wendischen Gottesdienst.

Seit der zweiten Hälfte des 20. Jahrhunderts gibt es zudem einen nennenswerten Anteil konfessionsloser Sorben.

Die 1912 gegründete zentrale Interessenvertretung Domowina (ein sorbischer poetischer Ausdruck für „Heimat“, voller Name "Domowina – Zwjazk Łužiskich Serbow z. t.", Domowina – Bund Lausitzer Sorben e. V.) ist der Dachverband von Ortsgruppen, fünf Regionalverbänden sowie zwölf überregional wirkender sorbischer Vereine, mit insgesamt ca. 7.300 Mitgliedern, wobei jene, die in mehreren Mitgliedsvereinen organisiert sind, auch mehrfach gezählt werden.

Am 10. Dezember 1716 gründeten sechs sorbische Theologiestudenten mit Erlaubnis des Senates der Universität Leipzig das „Wendische Predigercollegium“ (später umbenannt in „Lausitzer Predigergesellschaft“ und „Landsmannschaft Sorabia“), den ersten sorbischen Verein überhaupt. Ihr Grundsatz war zugleich ihre Grußformel: „Soraborum saluti!“ Heute ist das Institut für Sorabistik an der Universität Leipzig das einzige Institut in Deutschland, an dem Sorbischlehrer und Sorabisten ausgebildet werden. Unterrichtssprachen sind Ober- und Niedersorbisch. In letzter Zeit finden die Sorabistik und die dazu angebotenen Studiengänge an der Universität Leipzig zunehmendes Interesse, insbesondere im slawischen Ausland. Direktor des Institutes ist seit dem 1. März 2003 Prof. Dr. Eduard Werner (sorb. Edward Wornar).

Seit 1951 existiert in Bautzen eine außeruniversitäre Forschungseinrichtung der Sorabistik, die bis 1991 zur Deutschen Akademie der Wissenschaften in Berlin (Ost) gehörte. 1992 zum Sorbischen Institut e. V. "(Serbski Institut z. t.)" umgegründet, sind die ca. 25 festen Mitarbeiter nun an den beiden Standorten Bautzen (Sachsen) und Cottbus (Brandenburg) tätig. Komplexer Auftrag ist die Erforschung der sorbischen Sprache (Ober- und Niedersorbisch), der Geschichte, Kultur und Identität des sorbischen Volkes in der Ober- und Niederlausitz. Das Institut wirkt mit seinen vielfältigen Projekten zugleich auf die Praxis der Erhaltung und Entfaltung sorbischer nationaler Substanz ein. Ihm angegliedert sind die Sorbische Zentralbibliothek und das Sorbische Kulturarchiv, die das sorbische Kulturerbe aus nahezu 500 Jahren sammeln, bewahren und weitervermitteln.

Ebenfalls in Bautzen ist der Domowina-Verlag (sorb. "Ludowe nakładnistwo Domowina") ansässig, in dem die meisten sorbischen Bücher, Zeitungen und Zeitschriften erscheinen. Der Verlag ging aus dem 1958 gegründeten VEB Domowina-Verlag hervor, welcher 1990 in eine GmbH umgewandelt wurde. Der Verlag wird aus dem Etat der Stiftung für das sorbische Volk mit 2,9 Mio € finanziert (Stand 2012). Seit 1991 wird vom Verlag die Smoler’sche Verlagsbuchhandlung (sorb. "Smolerjec kniharnja") betrieben, die in Anlehnung an die 1851 eingerichtete sorbische Buchhandlung des ersten sorbischen Verlegers Jan Arnošt Smoler (1816–1884) benannt ist.

Das Sorbische Museum in Bautzen "(Serbski muzej Budyšin)" befindet sich im Salzhaus der Ortenburg. In seiner Ausstellung gibt es einen Überblick über die Geschichte der Sorben von seinen Anfängen im 6. Jahrhundert bis zur Gegenwart sowie über Kultur und Lebensweise der sorbischen Bevölkerung. In regelmäßig wechselnden Sonderausstellungen werden Werke sorbischer bildender Künstler präsentiert oder spezielle geschichtliche Themen behandelt. Träger des Sorbischen Museums ist der Landkreis Bautzen. Außerdem wird es aus Mitteln der Stiftung für das sorbische Volk und des Kulturraumes Oberlausitz-Niederschlesien gefördert.

Die Stiftung für das sorbische Volk "(Załožba za serbski lud)" soll als gemeinsames Instrument des Bundes und der beiden Länder Brandenburg und Sachsen die Bewahrung und Entwicklung, Förderung und Verbreitung der sorbischen Sprache, Kultur und Traditionen als Ausdruck der Identität des sorbischen Volkes unterstützen.

Sie wurde 1991 per Erlass zunächst als nichtrechtsfähige Stiftung des öffentlichen Rechts in Bautzen gegründet. Unter Berücksichtigung, dass das sorbische Volk jenseits der Grenzen der BRD keinen Mutterstaat besitzt und gestützt auf die in der Protokollnotiz Nr. 14 zu Art. 35 des Einigungsvertrages erklärte Verpflichtung der Bundesrepublik gegenüber dem sorbischen Volk wurden so die materiellen Rahmenbedingungen geschaffen. Mit Unterzeichnung des Staatsvertrages zwischen dem Land Brandenburg und dem Freistaat Sachsen über die Errichtung der "Stiftung für das sorbische Volk" vom 28. August 1998 erlangte die Stiftung ihre Rechtsfähigkeit. Gleichzeitig wurde ein erstes bis Ende 2007 gültiges Finanzierungsabkommen zwischen dem Bund und den Ländern Brandenburg und Sachsen vereinbart. Auf der Grundlage des Zweiten Abkommens über die gemeinsame Finanzierung vom 10. Juli 2009 erhält die Stiftung zur Erfüllung des Stiftungszweckes jährliche Zuwendungen des Freistaates Sachsen, des Landes Brandenburg und des Bundes. Das Abkommen gilt bis zum 31. Dezember 2013.

Die bis 2013 festgelegte Zuwendungssumme betrug 16,8 Millionen Euro. Sie setzte sich wie folgt zusammen: Bund 8,2 Millionen Euro, Sachsen 5,85 Millionen Euro, Brandenburg 2,77 Millionen Euro. Den größten Anteil des Stiftungsetats erhielten das "Sorbische National-Ensemble" (29 %), der "Domowina-Verlag" (17,2 %) und das "Sorbische Institut" (11,3 %) sowie die "Stiftungsverwaltung" (11,4 %). Um die absolute Fördermenge und die Verteilung für einzelne Institutionen und Projekte gibt es immer wieder öffentliche Kontroversen, die in einigen Fällen zu Demonstrationen führten.

Im Freistaat Sachsen und in Brandenburg gibt es im zweisprachigen Siedlungsgebiet der Sorben mehrere bilinguale sorbisch-deutsche Schulen, sowie weitere Schulen, an denen Sorbisch als Fremdsprache gelehrt wird. In Sachsen arbeiteten im Schuljahr 2013/14 acht Grund- und sechs Oberschulen zweisprachig und in Brandenburg vier Grund- und eine Oberschule mit Grundschulanteil als zweisprachige sorbisch-deutsche Schulen. Die Erlangung der Hochschulreife in sorbischer Sprache ermöglichen das Sorbische Gymnasium in Bautzen und das Niedersorbische Gymnasium in Cottbus.

In beiden Bundesländern gibt es weiterhin mehrere sorbische Kindergärten. Der bundeslandübergreifende "Sorbische Schulverein" hat zudem das Projekt Witaj zur zweisprachigen Betreuung und Ausbildung an Kindergärten und Schulen ins Leben gerufen, bei dem die Kinder per Immersion an die sorbische Sprache herangeführt werden.

"Siehe auch: Sorbisches Schulwesen"

Es erscheinen eine obersorbische Tageszeitung "Serbske Nowiny" (Sorbische Zeitung), eine niedersorbische Wochenzeitung "Nowy Casnik" (Neue Zeitung), die sorbische Kulturmonatsschrift "Rozhlad" (Umschau), die Kinderzeitschrift "Płomjo" (Flamme), die katholische Zeitschrift "Katolski Posoł" und die evangelische Kirchenzeitung "Pomhaj Bóh." Das Sorbische Institut bringt alle sechs Monate die wissenschaftliche Zeitschrift "Lětopis" heraus. Für Pädagogen gibt es die Fachzeitschrift "Serbska šula."

Ferner gibt es den Sorbischen Rundfunk, dessen Programm vom Mitteldeutschen Rundfunk und Rundfunk Berlin-Brandenburg produziert wird. Täglich werden einige Stunden sorbischsprachige Radiosendungen von Sendern in Calau (RBB) und Hoyerswerda (MDR 1) ausgestrahlt, wobei alle niedersorbischen Sendungen des RBB auch im Internet nachgehört werden können. Für junge Leute sendet der RBB jeden ersten Donnerstag im Monat das halbstündige Monatsmagazin "Bubak" und der MDR jeden Montag das zweistündige Wochenmagazin "Radio Satkula."

Der Rundfunk Berlin-Brandenburg produziert seit April 1992 monatlich das halbstündige niedersorbische Fernsehmagazin "Łužyca" (Lausitz), der MDR seit dem 8. September 2001 monatlich die halbstündige obersorbische Sendung "Wuhladko" (Aussicht). Außerdem sendet der MDR jeden Sonntag "Unser Sandmännchen" in Zweikanalton.

Bis in das späte Mittelalter gab es nur die mündliche Überlieferung von Sagen, Märchen, Zaubersprüchen, Sprichwörtern und ähnlichem.

Mit der Reformation begann die schriftliche Darstellung in nieder- und obersorbischer Sprache. Mikławš Jakubica schloss 1548 die Übersetzung des Neuen Testaments in das Niedersorbische als Handschrift ab, konnte diese jedoch nicht drucken lassen. Das erste gedruckte Werk im Niedersorbischen war schließlich Martin Luthers Gesangbuch in der Übersetzung von Albin Moller (1574), im Obersorbischen Luthers "Kleiner Katechismus" (1597). 

Erst im 19. Jahrhundert entstand eine nationalbewusste sorbische Literatur. Bis dahin hatte sich die niedergeschriebene und gedruckte sorbische Literatur fast ausschließlich auf religiöse und wirtschaftliche Inhalte beschränkt. Der Lyriker Handrij Zejler gilt als Begründer der modernen Literatur und war 1847 Mitbegründer der sorbischen wissenschaftlichen Gesellschaft Maćica Serbska. Sein 1827 veröffentlichtes Gedicht „Na sersku Łužicu“ ("„An die sorbische Lausitz“") wurde 1845 von Korla Awgust Kocor vertont, woraus die heutige Hymne der Sorben „Rjana Łužica“ ("„Schöne Lausitz“") entstand. Weitere klassische Dichter waren auf obersorbischer Seite der Lieder- und Märchensammler Jan Arnošt Smoler und der katholische Priester und Dichter Jakub Bart-Ćišinski. In der vom Obersorbischen dominierten sorbischen Literatur erbrachte unter anderem die Lyrikerin Mina Witkojc einen bedeutenden Beitrag für das in der Niederlausitz gesprochene Niedersorbisch.

Die literarischen Fassungen der Krabatsage, "Mišter Krabat" (1954) von Měrćin Nowak-Njechorński, "Die schwarze Mühle" (1968) von Jurij Brězan und "Krabat" (1971) des sudetendeutschen Schriftstellers Otfried Preußler wurden in viele Sprachen übersetzt und trugen dazu bei, die Sorben auch im Ausland bekanntzumachen.

Gegenwartsautoren sind beispielsweise Jurij Brězan, Kito Lorenc, Jurij Koch, Angela Stachowa, Róža Domašcyna, Jan Cyž, Benedikt Dyrlich, Marja Krawcec und Marja Młynkowa.

Mit den Bildhauern Jakub Delenka (1695–1763) und Maćij Wjacław Jakula tauchen die ersten Künstler im Zeitalter des Barock auf. Jäckel hatte in Prag eine Werkstatt und schuf mehrere Skulpturen für böhmische Klosterkirchen und die Prager Karlsbrücke. Zu den herausragenden Künstlern des 18./19. Jahrhunderts zählt der Landschaftszeichner und -radierer Hendrich Božidar Wjela, der zwischen 1793 und 1799 an der Dresdener Kunstakademie bei Johann Christian Klengel und Giovanni Battista Casanova studierte. Wjela kann als Zeichner und Radierer zwischen dem Sturm und Drang und der Romantik eingeordnet werden.

Ende des 19. Jahrhunderts entstand durch den Aufschwung der Volkskunde und des Heimatschutzes die sogenannte "Brauchtumsmalerei" und das Interesse deutscher und ausländischer Künstler für die Sorben wurde geweckt. Dem Landvolk widmeten sich mit dieser auf eine beschreibende Darstellung der Folklore zielenden Malerei Künstler wie William Krause, Ludvík Kuba sowie später unter anderem Friedrich Krause-Osten, und zeigten die Sorben in ihrer kulturellen Vielfalt und Tradition.

Zu den herausragenden sorbischen Künstlern des 20. Jahrhunderts zählen der Maler, Graphiker und Schriftsteller Měrćin Nowak-Njechorński sowie Hanka Krawcec und Fryco Latk. In den zwanziger Jahren versuchten die Künstler, nationale Ideale nicht durch die reine Abbildung der Folklore zu interpretierten, sondern durch ein stärkeres ästhetisches und philosophisches Eindringen in die Eigenarten des sorbischen Volkes. Nach dem Zweiten Weltkrieg fanden sich sorbische Maler und Grafiker 1948 zum "Arbeitskreis sorbischer bildender Künstler" zusammen. Der Arbeitskreis wurde von 1948 bis 1951 durch Conrad Felixmüller geleitet, in dessen folkloristisch geprägter Malerei aus dem ländlichen Milieu der sorbischen Oberlausitz ein Wiederentdecken seiner sorbischen Vorfahren zum Ausdruck kommt. Zum sorbischen Arbeitskreis gehörten unter anderem auch Horst Šlosar und Ota Garten. Heutige sorbische Kunstschaffende sind unter anderem die Maler Jan Buk und Božena Nawka-Kunysz sowie die Graphikerin und Keramikerin Jěwa Wórša Lanzyna.

"Siehe auch: Liste sorbischer bildender Künstler"

Die frühe sorbische Musik ist durch das Volkslied und die instrumentale Volksmusik gekennzeichnet, die über Jahrhunderte mündlich überliefert wurde und auch neu entstand.

Zur Zeit der Reformation gab es einige namhafte sorbische Kirchenmusiker, wie zum Beispiel den aus der Niederlausitz stammenden Kantor der St.-Nicolai-Kirche in Berlin, Jan Krygaŕ ("Johann Crüger"). Er gilt als wichtigster protestantischer Choralkomponist und Musiktheoretiker des 17. Jahrhunderts, aus dessen Schriften sogar Johann Sebastian Bach sein musikalisches Handwerk erwarb.

Das erste weltliche Werk sorbischer Kunstmusik stammt von Jurij Rak aus dem Jahre 1767. Es handelt sich dabei um eine „Jubiläumsode“ des damaligen Jurastudenten zur 50-Jahr-Feier des Wendischen Predigercollegiums zu Leipzig („Sorabia“).

Erste Dokumentationen sorbischer Volksmusik gibt es aus dem frühen 19. Jahrhundert, wie zum Beispiel das „Kralsche Geigenspielbuch“ des Volksmusikanten Mikławš Kral (1791–1812) und die in Bautzen erschienene Sammlung „Volkslieder der Sorben in der Ober- und Niederlausitz“ von Leopold Haupt (1797–1883) und Jan Arnošt Smoler.

Obwohl das sorbische Musikleben weder über Theater oder Orchester verfügte, erreichte die Kunstmusik Mitte bis Ende des 19. Jahrhunderts einen ersten bedeutsamen Höhepunkt. Entscheidenden Anteil hatte der Lehrer und Kantor Korla Awgust Kocor. Gemeinsam mit dem Dichter Handrij Zejler organisierte er ein erstes Gesangfest am 17. Oktober 1845 im Bautzener Schützenhaus. Dort wurde auch Zejlers Rjana Łužica erstmals aufgeführt, deren Vertonung von Kocor stammt. Sie begründeten die Tradition der Sorbischen Sängerfeste, welche sich zu populären Ereignissen im Oberlausitzer Kulturraum entwickelten. Eines der wichtigen Werke von Kocor ist das Oratorium „Nalěćo“ (deutsch "Frühling") auf einen Gedichtzyklus von Zejler. 

Um 1900 war Jurij Pilk einer der maßgeblichen Vertreter des sorbischen Musiklebens. Die Ouvertüre zum Singspiel „Smjertnica“ (Die Todesgöttin) zählt zu seinen wichtigsten Werken. Eine weitere Persönlichkeit mit bleibendem Einfluss war der sorbische Komponist, Musikpädagoge und Herausgeber von Musikliteratur Bjarnat Krawc. 

Nach 1945 war Jurij Winar (1909–1991) treibende Kraft zur Wiederbelebung des sorbischen Musiklebens. Winar gründete 1952 das heutige Sorbische National-Ensemble ("Serbski ludowy ansambl", SLA), an dem er bis 1960 Intendant und künstlerischer Leiter war. Gefördert durch die Stiftung für das sorbische Volk pflegen, bewahren und entwickeln heute die drei professionellen Sparten Ballett, Chor und Orchester die kulturelle Tradition der Sorben.

Zu den Vertretern der zeitgenössischen sorbischen klassischen Musik zählen Ulrich Pogoda, Jan Bulank, Detlef Kobjela, Sebastian Elikowski-Winkler und weitere Komponisten.

Seit den 1990er Jahren gibt es wieder vermehrt Musiker und Gruppen, die neben Volksmusik auch Pop, Rock, Metal und Punk in ober- und niedersorbischer Sprache spielten bzw. spielen, wie "Awful Noise", "DeyziDoxs", die "Folksamen", "Berlinska Dróha", "Jankahanka", Bernd Pittkunings und andere.

Das Deutsch-Sorbische Volkstheater "(Němsko-Serbske ludowe dźiwadło)" geht auf das seit Ende des 18. Jahrhunderts bestehende Bautzener Theater zurück, welches 1963 mit dem seit 1948 bestehenden Sorbischen Volkstheater vereint wurde. Es führt Werke in deutscher und sorbischer Sprache auf. Das Theater in Bautzen ist ein kommunaler Eigenbetrieb des Landkreises Bautzen und wird anteilig aus Mitteln der Stiftung für das sorbische Volk und des Kulturraumes Oberlausitz-Niederschlesien finanziert.

Viele Bräuche haben sich erhalten, vor allem das Osterreiten, die Vogelhochzeit und das traditionelle Bemalen von Ostereiern. Zahlreiche slawische mythologische Vorstellungen sind heute noch lebendig, wie zum Beispiel die Mittagsfrau (Připołdnica/Přezpołdnica), der Wassermann (Wódny muž), die Gottesklage (Bože sadleško) oder der geld- und glückbringende Drachen (obersorb. "zmij", niedersorb. "plón").

Im obersorbischen Kerngebiet, in etwa durch ein Dreieck zwischen den Städten Bautzen, Kamenz und Wittichenau beschrieben, sind Kruzifixe am Wegrand und in Vorgärten sowie gepflegte Kirchen und Kapellen Ausdruck einer bis in die Gegenwart gelebten (meist katholischen) Volksfrömmigkeit, die viel zur Bewahrung der sorbischen Substanz beigetragen hat.

Die sorbischen Trachten sind regional stark unterschiedlich. Sie werden vereinzelt von älteren Frauen noch täglich, von jüngeren jedoch nur zu den großen Feiertagen getragen, wie beispielsweise zu Fronleichnam die Tracht der Brautjungfer "(družka)".

Die Sorben können auf eine etwa 1400 Jahre lang nachweisbare Geschichte zurückblicken. In der ersten Hälfte des 6. Jahrhunderts n. Chr. verließen ihre Vorfahren im Zuge der damaligen Völkerwanderung ihre Wohngebiete nördlich der Karpaten zwischen Oder und Dnepr und zogen über Schlesien und Böhmen nach Westen, wo sie im 6. Jahrhundert das Gebiet zwischen dem Oberlauf der Neiße in Nordböhmen und dem Flussgebiet der Saale mit dem sächsischen Vorland des Erzgebirges und dem Fläming besiedelten. Diese Gebiete waren seit der Abwanderung germanischer Völkerschaften im Zuge der Völkerwanderung nahezu unbewohnt, verbliebene germanische Restbevölkerung wurde assimiliert.
In der sogenannten Fredegar-Chronik werden für 631/32 Wenden und erstmals Sorben erwähnt, welche wiederholt plündernd in Thüringen und anderen Gauen des Frankenreiches einfielen: "„Seither fielen die Wenden zu wiederholten Malen in Thüringen und anderen pagi des Frankenreiches ein, um sie auszuplündern; ja sogar Dervanus, der dux des Volkes des Sorben [lat. Dervanus dux gente Surbiorum], die von slawischer Herkunft waren und schon seit jeher zum Reiche der Franken gehört hatten, unterstellte sich mit seinem Volk dem Reiche Samos.“" Nach weiteren Überfällen durch die abtrünnigen Sorben wurde schließlich der in Thüringen herrschende Herzog Radulf mit einem bedeutenden Sieg 634/635 Herr der Lage und schloss 641 mit den benachbarten Slawenstämmen ein Bündnis auf der Basis der Gleichberechtigung.

Die in den Quellen des Früh- und Hochmittelalters als „Sorben“ (lat. "surbi, sorabi") bezeichneten westslawischen Stämme, Bewohner der Gebiete zwischen Saale und Mulde, gerieten im 8. und 9. Jahrhundert zunehmend in die Abhängigkeit des (ost)fränkischen Reiches und die Grenz- und Schutzzone Limes Sorabicus entstand in diesem Gebiet. Für das Jahr 806 ist belegt, dass ein König der Sorben namens Miliduch (oder Melito) getötet wurde, woraufhin sich andere Könige, zum Teil nach erbitterten Kämpfen, unterwarfen. Sie wurden zu Tributleistungen gezwungen, dem christlichen Glauben zugeführt und durch die mittelalterliche Deutsche Ostsiedlung assimiliert. Über die weiter östlich im Elbtal lebenden Daleminzier und die in den Lausitzen lebenden slawischen Stämme der Lusitzi (auch "Lusici", "Lusizer" oder "Lausitzer") und Milzener, deren Nachkommen heute den Namen „Sorben“ tragen, geben die fränkischen Geschichtsquellen auch nur spärlich Auskunft.

Während es in Böhmen und Mähren seit dem späten 7. Jahrhundert zu ersten Reichsbildungen und seit dem 9. Jahrhundert zur Entstehung stabilerer frühfeudaler Staatsgebilde kam, gab es bei den Slawen zwischen Saale und Neiße zur Zeit der Eroberung durch die Franken keine heute bekannten überregionalen politischen Strukturen. Die Slawen lebten vornehmlich als Bauern in kleinen Stammesverbänden, die jeweils nur einige Dutzend recht kleiner dörflicher Siedlungen umfassten. Die Gesellschaft der Westslawen war aber schon deutlich in die Masse abhängiger Bauern und eine schmale adlige Herrschaftsschicht gegliedert. Aus der letzteren rekrutierten sich auch die Stammes- oder Gaufürsten, die in den fränkischen Quellen meist "dux" (= Herzog, Fürst) genannt werden.
Herrschaftszentren waren wohl die zahlreichen Slawenburgen mit Wehrmauern aus Holz-Erde-Konstruktionen, welche ab dem Ende des 9. Jahrhunderts entstanden. Je nach Lage wurden Höhenburgen auf Standorten, die das umgebende Gelände überragten, errichtet, welche je nach am Ort vorhandenem Baumaterial auch mächtige steinerne Schalmauern besitzen konnten (z. B. auf der Landeskrone bei Görlitz). Wenn geeignete Höhenlagen fehlten, entstanden Niederungsburgen meist mit Gewässern oder Sumpflandschaften (Sumpfringwälle bzw. Sumpfburgen) als natürlichen Schutz. Der Auflistung des Bayerischen Geographen zufolge verfügten die Sorben über 50 und die Lusitzi und Milzener über je 30 "civitates". Der Begriff "civitas" bezeichnet vermutlich eine zentrale Burg oder einen Burgbezirk mit zugehörigen Siedlungen. Die Lokalisierung des Siedlungsgebietes der Sorben oder "surbi" nach den Angaben des bayerischen Geographen bleibt in der Forschung umstritten. Das Kerngebiet der heutigen sorbischen Besiedlung der Oberlausitz liegt im Stammesgebiet der Milzener mit ihrer Hauptburg "Budissin" (Bautzen). Das Siedlungsgebiet der Niederlausitzer Sorben entspricht jenem des für die Landschaft namengebenden slawischen Stammes der Lusitzi.

Über die vorchristliche Religion der Slawen zwischen Saale und Neiße ist wenig bekannt. Weder weiß man, ob es einen Priesterstand gab, noch haben die Archäologen in diesen Gebieten bisher ein Heiligtum von überregionaler Bedeutung entdecken können. Der mittelalterlichen Tradition nach wurden aber manche frühe christliche Kirchen an Stelle alter slawischer Heiligtümer errichtet, so zum Beispiel die Kirche auf dem "Opferberg" in Leipzig-Wahren.

Bis zum Beginn des 10. Jahrhunderts befanden sich die sorbisch besiedelten Gebiete an der Saale nur in einem mehr oder weniger engen Abhängigkeitsverhältnis vom Frankenreich. Die Slawen im Gebiet des "Limes Sorabicus" mussten Tribute an die Franken entrichten. Zu einer intensiveren deutschsprachigen Besiedlung und Herrschaftsbildung kam es erst unter König Heinrich I.

Nachdem Heinrich I. um 924–926 einen neunjährigen Waffenstillstand mit den Ungarn geschlossen hatte, nahm er die Ausdehnung seiner Macht an der Ostgrenze des Reiches in Angriff. 928/929 führte er einen groß angelegten erfolgreichen Feldzug zur Unterwerfung der slawischen Stämme östlich der Elbe (Obodriten, Wilzen, Heveller, Daleminzier und Redarier). Seinen Vormarsch sicherte der König durch die Anlage zahlreicher Burgen. Eine der wichtigsten Gründungen war 928/929 die Zwingburg in Meißen (an der Stelle der heutigen Albrechtsburg) gegen die besiegten Daleminzier, von wo aus er 932 die Milzener unterwarf. Durch weitere Siege 932 über die Lusizer – dabei zerstörte er ihre Stammesburg "Liubusua" – sowie 934 gegen die Ukranen zwang er auch diese slawischen Stämme in die Tributpflicht.

Zu Beginn der frühen Neuzeit wurde der Volksname "Sorben" allmählich auf die siedelnden Lusitzi und Milzener übertragen, die in den früh- und hochmittelalterlichen Quellen noch deutlich von den Sorben geschieden wurden. Wichtiger blieb bis ins 19. Jahrhundert hinein aber die deutsche Bezeichnung Wenden, die von Anfang an ein Oberbegriff für die östlich der alten Reichsgrenze lebenden slawischen Völker gewesen war. In der Sprachwissenschaft werden heute die Sprachen der südlichen Elbslawen bzw. deren überlieferte Reste insgesamt als sorbisch bezeichnet.

Gero, der von Kaiser Otto I. 939 eingesetzte Markgraf der Sächsischen Ostmark (sie umfasste das gesamte Gebiet zwischen Elbe, Havel und Saale) führte die gewaltsame Unterwerfung der Sorben fort. 939 lud er 30 slawische Fürsten zu einem Gastmahl ein und ließ sie ermorden. Die Bluttat hatte einen Aufstand der Slawen zur Folge, denen sich auch Stämme nördlich der Ostmark anschlossen. In mehreren Kriegszügen von 954 bis zu Geros Tod 965 besiegten Kaiser Otto I. und Gero die nordwestslawischen Stämme sowie die Lusitzi in der Lausitz, wodurch die sächsische Tributherrschaft bis an die Oder ausgedehnt und gefestigt wurde. Während die Slawen im heutigen nördlichen Brandenburg und Mecklenburg ihre Selbstständigkeit durch einen großen Aufstand 983 noch einmal für längere Zeit zurückgewinnen konnten, war die Unterwerfung der Sorben endgültig. Die Herrschaft über die Lausitz und das Milzenerland mit der strategisch bedeutenden Burg Bautzen war allerdings noch von 1002 bis 1032 mit wechselseitigem Erfolg zwischen den Deutschen und dem Polenherzog Bolesław Chrobry umkämpft. Die Untersuchung von 25 sogenannten "Ringwällen" in der Niederlausitz konnte sehr gut eine Übereinstimmung der Hochzeit des Burgenbaus Anfang des 10. Jahrhunderts mit den Eroberungsaktivitäten von Otto I. zeigen. Die Bauaktivitäten enden um 960-970 und sind wahrscheinlich auf die Unterwerfung der Lausitz durch Gero 963 zurückzuführen.

Im 10. Jahrhundert begann die christliche Kirche bei den Slawen im Elbe-Saale-Gebiet und in der Lausitz mit der Missionierung. Die Befestigung der deutschen Herrschaft und die Schaffung kirchlicher Strukturen gingen dabei Hand in Hand. Kaiser Otto I. gründete 968 das Erzbistum Magdeburg mit den Suffragen Brandenburg, Havelberg, Zeitz, Merseburg und Meißen. Die Sorben, Milzener und Lusizer mussten dem Bischof von Meißen den Zehnten entrichten. Parallel erfolgte unter den Markgrafen der sorbisch besiedelten Gebiete – die große Mark Geros war nach seinem Tod in mehrere kleinere Territorien untergliedert worden (Nordmark, Mark Lausitz, Mark Meißen, Mark Zeitz und Mark Merseburg) – die Einrichtung von Burgwarden. Die unterworfenen Gebiete wurden an deutsche Adelige zu Lehen gegeben, die neuen Herren errichteten Burgen und erhielten Abgaben von den zugehörigen slawischen Dörfern. Zum Teil trat der deutsche Adel dabei nur die Nachfolge der sorbischen Stammesfürsten an. Die ehemalige slawische Führungsschicht war durch die vorangegangenen Kriege dezimiert und ihre Reste wurden in untergeordnete Stellungen abgedrängt. Die Masse der sorbischen bäuerlichen Bevölkerung waren mittlere Bodenbesitzer ohne erbliches Besitzrecht, sowie rechtlose verarmte Bauern oder Leibeigene. Sie mussten Abgaben an den Lehnsherren sowie Handdieste leisten, wozu noch der Zehnte für die Kirche kam. Die obere Schicht der Bauern bildeten die Dorfvorsteher ("Župane" oder "Supane") sowie Kriegs- und Dienstleute.

Nach den zahlreichen Kriegen des 10. und am Beginn des 11. Jahrhunderts verlief die Integration des sorbischen Siedlungsgebiets in das Reich in der folgenden Zeit auf friedliche Weise. Der König, die Markgrafen und nicht zuletzt die kirchlichen Institutionen förderten den so genannten Landesausbau. Die Phase der "Hochkolonisation" erstreckte sich von etwa 1150 bis 1300 und wurde hauptsächlich von deutschen Siedlern getragen, welche unter anderem aus Flandern, den Niederlanden, Sachsen, Franken, Thüringen und dem Rheinland kamen. Die alteingessenen sorbischen Einwohner wurden zumeist nicht vertrieben, vielmehr entstanden die neuen deutschen Dörfer fast immer auf gerodeten Flächen. An bereits besiedelten Stellen erweiterte man die bestehenden slawischen Siedlungen. Eine erste Phase der "Frühkolonisation", mit einem beträchtlichen Anteil durch slawische Altsiedler, gab es aber schon ab 1100, so zum Beispiel um Gera, Zeitz und Altenburg im Pleißenland.

Auch in den Lausitzen waren die Rodungen in der ersten Hälfte des 12. Jahrhunderts vor allem von sorbischen Bauern getragen worden. In dieser Zeit entstanden z. B. viele neue Orte im Gebiet um Hoyerswerda, Spremberg und Weißwasser. Die Erweiterung des Kulturlands vergrößerte und stabilisierte in dieser Gegend das sorbische Sprachgebiet. In manchen Gegenden, etwa um das Zisterzienserinnenkloster St. Marienstern herum und bei Hoyerswerda, war das sorbische Element so stark, dass einige deutschsprachige Ortsgründungen über die Zeit slawisiert wurden, so z. B. in Dörgenhausen "(sorb. Němcy)". Unter den böhmischen Königen intensivierte sich Mitte des 12. Jahrhunderts der Landesausbau in der Oberlausitz, der von den Königen und den Meißener Bischöfen quasi im Wettbewerb betrieben wurde. Deutsche Bauern rodeten große Waldgebiete im Süden und Osten des Landes und legten zahlreiche neue Dörfer an, so zum Beispiel um Bischofswerda und Ortrand. In der Niederlausitz ließen sich die deutschen Siedler in den westlichen, nördlichen und östlichen Randgebieten nieder, so z. B. um Luckau, Storkow und Beeskow sowie Sorau im heutigen Polen.

Im Gegensatz zu den altsorbischen Siedlungen, konnten die Zuwanderer ihre Siedlungen zu flämischen, niederländischen oder fränkischen Recht gründen (die Bezeichnung "Deutsches Recht" bildete sich erst später heraus), erhielten somit Erbrecht am erschlossenen Land und waren persönlich frei. Weil durch Rodung und Bewirtschaftung die Herrschaftsgebiete der Adligen erst einen Wert bekamen, mussten die eingewanderten Deutschen zudem nur geringere Abgaben an die Grundherren zahlen und wenige Dienste für sie verrichten, oder waren für die ersten Jahre von diesen gänzlich befreit. Insofern sorbische Bauern beim Landesausbau beteiligt waren, genossen sie zumeist dieselben Rechte wie die deutschen Kolonisten.

Im Zuge des Landesausbaus, der Bevölkerungszunahme und dem Zuzug von deutschen Kaufleuten und Handwerkern, kam es auch zu zahlreichen Stadtgründungen. Vorwiegend an Kreuzungen wichtiger Handelsstraßen, an bestehenden Marktsiedlungen und um Burgen oder Markgrafensitze. Ab dem Ende des 12. Jahrhunderts wurden die ersten Stadtrechte verliehen, so z. B. westlich der Elbe an Leipzig (1165) und Meißen (um 1200) sowie östlich an Lübben und Cottbus (jeweils um 1220) in der Niederlausitz und Löbau (1221), Kamenz (1225) oder Bautzen (1240) in der Oberlausitz. Westlich der Elbe kam es schnell zu einem Übergewicht an deutschen Siedlern und die Verdrängung der sorbischen Sprache war im 14. Jahrhundert weitgehend abgeschlossen. Ausdruck finden diese Veränderungen in der Einschränkung der Verwendung der sorbischen Sprache vor Gericht, wie zum Beispiel im Sachsenspiegel Anfang des 13. Jahrhunderts – wer nachweislich der deutschen Sprache mächtig war, musste diese auch verwenden – oder in einem Erlass im Fürstentum Anhalt von 1293, der den Gebrauch des Wendischen als Gerichtssprache verbot. Diese Einschränkungen werden aber nicht hauptsächlich als Ausdruck nationalistischer Einstellungen angesehen, sondern mehr als Anpassung an die vorherrschenden Gegebenheiten.

Im 14./15. Jahrhundert bildeten in der Oberlausitz die Sorben noch ungefähr die Hälfte der ländlichen Bevölkerung und in der Niederlausitz lag der Anteil noch bedeutend höher. In den Städten war ihr Anteil meist geringer und variierte beträchtlich. So betrug er in Bautzen ungefähr 35 %, in Cottbus knapp 30 %, in Guben, Löbau und Bischofswerda war er erheblich geringer. In Luckau lag er bei 50 % und Calau hatte fast ausschließlich sorbische Bewohner. Ab der ersten Hälfte des 14. Jahrhunderts kam es in den Städten der Lausitzen zu einer verstärkten sorbischen Einwanderung, wovon zahlreiche sorbische Bürgereide zum Beispiel aus Luckau, Senftenberg oder Bautzen zeugen. Mit dem Auslaufen der dynamischen wirtschaftlichen Entwicklung kam es auch vermehrt zu einer ablehnenden Haltung gegenüber den sorbischen Bevölkerungsgruppen. Davon zeugen „Deutschtumsverordnungen“ z. B. aus Beeskow (1353), Luckau (1384), Cottbus (1405), Löbau (1448) oder Lübben (1452), wodurch Sorben vorübergehend – vor allem aus Konkurrenzgründen – der Zugang zu den Zünften verwehrt wurde. Im 16. Jahrhundert wurden viele dieser Beschränkungen seitens der Zünfte und auf Entscheid der Markgrafen wieder aufgehoben.

Zu Beginn des 16. Jahrhunderts war das sorbische Siedlungsgebiet weiter geschrumpft, vorwiegend durch Assimilation der Sorben und der einhergehenden Verdrängung der Sprache vom Westen her. Abgesehen von einigen verbliebenen größeren Sprachinseln um Wittenberg, Eilenburg und Meißen erstreckte sich das geschlossene sorbische Sprachgebiet jetzt nur noch über die Lausitzen mit einer Fläche von ungefähr 16.000 km². Dort lebten circa 195.000 Menschen, von denen mit 160.000 die überwiegende Mehrzahl Sorben waren. Nordöstlich von Guben und Sorau hatte das sorbischsprachige Gebiet um 1600 noch direkte Verbindung zum polnischen Sprachgebiet. Erst die Verheerungen des Dreißigjährigen Krieges und die damit verbundenen Verluste der sorbischen Bevölkerung sowie eine von der evangelischen Kirche gestützte gezielte Germanisierungspolitik führten in der zweiten Hälfte des 17. Jahrhunderts dazu, dass das sorbische Gebiet zu einer rings von deutschsprachigen Regionen umgebenen Insel wurde.

Großteile der Lausitzen gehörten bis 1635 als Nebenländer den böhmischen Königen aus dem Haus Habsburg. Die Herrschaft Cottbus sowie davon nördlich gelegene Herrschaften von Zossen bis Beeskow sowie Crossen waren im Besitz der Hohenzollern. Über die westlich der Lausitzen gelegene deutsch-sorbische Mischzone im sächsisch-meißnischen Gebiet verfügten die Wettiner. Für alle drei Herrscherhäuser waren es Randgebiete und besonders die Habsburger übten keine starke Zentralgewalt aus. Die Verwaltung wurde den Ständen überlassen, was auf Grund der schlechten wirtschaftlichen Situation des Adels Anfang des 16. Jahrhunderts zu einer verstärkten Ausbeutung der ländlichen Gebiete führte. Die Einforderung von "vollen landesüblichen Diensten" (sechs Tage in der Woche Arbeit auf den gutsherrlichen Besitzungen, von Sonnenaufgang bis -untergang) führte seit 1525 zu lokal begrenzten Bauernunruhen in Reichwalde, Lieberose und Hoyerswerda sowie 1548 zum Bauernaufstand von Uckro in der Nähe von Luckau.

Die Unruhen standen nicht im Zusammenhang mit der von Martin Luther in Wittenberg 1517 angestoßenen Reformation, welche erst verzögert in die beiden Lausitzen und damit ins sorbische Siedlungsgebiet vordrang. Die katholischen Habsburger versuchten die Reformation in den Lausitzen aufzuhalten, konnten sich aber nicht gegen die evangelisch gesinnten Landstände, Städte und Ritterschaften durchsetzen. Die Stände nahmen die Kirchenhoheit in die eigenen Hände und führten die Reformation bis etwa zur Mitte des 16. Jahrhunderts schrittweise in den einzelnen Herrschaften ein. Alle Sorben in der Niederlausitz und mehr als drei Viertel der Oberlausitzer Sorben waren Mitte des 16. Jahrhunderts evangelisch. Nur die Sorben in den Besitzungen des Klosters St. Marienstern und des Bautzener Domstifts St. Petri blieben überwiegend katholisch.

Eine aktive reformatorische Bewegung gab es zunächst in den überwiegend deutschsprachigen Städten. Das reformatorische Schrifttum fand in den ländlichen Gebieten kaum Eingang, weil die meisten Sorben damals weder Deutsch verstehen noch lesen und schreiben konnten. Dies führte dazu, dass der Gottesdienst für die protestantischen Sorben nun in ihrer Muttersprache durchgeführt wurde. Auch Sorben gehörten zu eifrigen Verfechtern der lutherischen Reformationsideen, der bekannteste unter ihnen war der Theologe Jan Brězan (Johann Briesmann) aus Cottbus. Ab der Mitte des 16. Jahrhunderts begannen weitere sorbische protestantische Geistliche, den reformatorischen Grundsatz von der Predigt in der Muttersprache aufnehmend, eine sorbische religiöse Literatur zu schaffen, indem sie die Kernwerke des Protestantismus, Bibel, Katechismus und Kirchenlieder, aus dem Deutschen übersetzten. Mikławš Jakubica aus der Herrschaft Sorau übersetzte 1548 Luthers Neues Testament, was die erste Bibelübersetzung ins Sorbische überhaupt war. Eine Drucklegung erfolgte jedoch auf Grund fehlender finanzieller Mittel nie. 1574 erschien dann Luthers Katechismus, verbunden mit einem Gesangbuch, in der niedersorbischen Übersetzung des Albin Moller aus Straupitz, 1595 gab Wjaclaw Warichius aus Göda Luthers Katechismus in obersorbischer Sprache heraus.

Ab 1538 förderten die Landstände in der Oberlausitz sorbische Theologiestudenten und bis 1546 studierten an der Universität Wittenberg 40 und bis 1600 hatten 147 Sorben dort ihr Theologiestudium abgeschlossen. Auch an der brandenburgischen Landesuniversität Viadrina in Frankfurt wurden zu jener Zeit sorbische Geistliche ausgebildet und bis 1656 sorbische Sprachübungen abgehalten, welche die ersten sorabistischen Veranstaltungen an einer Hochschule waren.

Die Verheerungen des Dreißigjährigen Krieges (1618–1648) unterbrachen die erste Blüte der sorbischen Bildung und des Schrifttums für viele Jahrzehnte. Wie viele andere Regionen Deutschlands, so waren auch die Lausitzen mehrfach von Durchzügen großer Heere und von Seuchen betroffen, die tausende Todesopfer forderten. Der Bevölkerungsverlust betrug nach vorsichtigen Schätzungen über 50 % und im östlichen Teil des sorbischen Siedlungsgebiets um Sorau und Liebenwerda über 75 %, wo am Ende des Krieges viele Orte fast menschenleer waren. Diese Gebiete an der Neiße und östlich davon, wurden später von Deutschen wiederbesiedelt, wodurch das geschlossene sorbische Gebiet wieder sehr viel kleiner wurde.

Im Jahr 1635, noch vor Beendigung des Dreißigjährigen Krieges (1618–1648) kamen mit dem Frieden von Prag die beiden Markgraftümer Nieder- und Oberlausitz von Böhmen an das Kurfürstentum Sachsen, mit Ausnahme der im Zentrum der Niederlausitz liegenden Herrschaft Cottbus mit Peitz, welche schon seit Mitte des 15. Jahrhunderts den Hohenzollern und somit zum brandenburgischen und später preußischen Herrschaftsbereich gehörte. Der Besitzwechsel der beiden Lausitzen änderte zunächst wenig an deren Autonomie, da der neue Landesherr im Traditionsrezess die Beibehaltung der ständischen Privilegien, die Lehnshoheit der böhmischen Krone und die kirchlich-konfessionellen Einrichtungen in ihrem Bestand zusagen musste. Dieser Sonderstatus verhinderte vorerst den Einfluss von staatlichen Zentralisierungsbestrebungen und begünstigte auf der einen Seite die Stärkung der sorbischen Kultur- und Sprachentwicklung, führte aber auf der anderen Seite zur Festigung der Positionen des einheimischen Adels und deren Gewalt über die bäuerliche Bevölkerung. Durch den verstärkt einsetzenden Übergang von der Eigenwirtschaft zur Gutswirtschaft, wurde der erbliche Grundbesitz in unerblichen Landbesitz (Lassbesitz) umgewandelt und die Bauern zu verschärften Frondiensten in den entstehenden Rittergütern gezwungen. Durch die 1651 in den sächsischen Teilen der Lausitz und 1653 in den brandenburgischen Teilen der Niederlausitz erlassenen Untertanenordnungen, wurden die Bauern durch die Erbuntertänigkeit an den Eigentümer des Rittergutes gebunden (Schollenzwang) und sie selbst, wie auch ihre Kinder, dem Gesindezwang unterworfen.

Dies führte auf der einen Seite zu einer starken Landflucht der bäuerlichen Bevölkerung. So verließen nach Schätzungen zwischen 1631 und 1720 allein in der Oberlausitz mehr als 8000 Fronbauern ihre Gutsherrschaften. Auf der anderen Seite kam es zu erbitterten Widerstandsaktionen über Bittschriften, Eingaben, Verweigerung von Diensten und Abgaben bis hin zu bewaffneten Aufständen. Die oftmals mehrere Dörfer umfassenden Bauernunruhen erstreckten sich zumeist über mehrere Jahre und wurden letztendlich durch den Einsatz von Militär niedergeschlagen. 1667/68 erhoben sich zum Beispiel im Kreis Cottbus an die 5000 Bauern und es gelang erst durch das Aufgebot von 800 Soldaten die Erhebung unter Kontrolle zubringen. Erneut in Cottbus kam es von 1715 bis 1717 zum größten Aufstand sorbischer und deutscher Bauern, an der sich unter der Führung des Eichower Dorfschulzen Hanzo Lehmann über 50 Dörfer beteiligten.

Mit der Herausbildung des Absolutismus, welcher sich in den brandenburgischen Gebieten der Hohenzollern stärker als in Sachsen entfaltete, begann die Eingliederung der Sorben in das organisierte Staatswesen und damit die Verdrängung der sorbischen Sprache. Aufgrund der unterschiedlichen politischen Zielsetzungen differierte das Vorgehen gegen das Sorbische von Landesherr zu Landesherr. Am intensivsten wurde durch Christian I. von Sachsen-Merseburg in der Niederlausitz und durch den brandenburgischen Kurfürst Friedrich Wilhelm im Wendischen Distrikt der Kurmark gegen das Sorbische vorgegangen. Sorbische Bücher und Manuskripte wurden eingezogen und die Ausbreitung des Deutschen im Schulunterricht und bei den Gottesdiensten vorangetrieben. Im Verlauf des 18. Jahrhunderts wurden in den meisten Kirchgemeinden der Niederlausitz die seit der Reformation abgehaltenen sorbischen Gottesdienste abgeschafft, obwohl die meisten betroffenen Gemeinden zu diesem Zeitpunkt fast ausschließlich einsprachig sorbisch waren. Auch die Schulen wurden zu einem Hauptfaktor der Germanisierung, indem man das Sorbische lediglich als Hilfssprache in den ersten Klassen nutzte, wo es nötig war, ansonsten aber ausschließlich Deutsch gelehrt und gesprochen wurde. In der Oberlausitz, wo die Stände ihre Autonomie weiterhin bewahren konnten, nahm man, auch aus Furcht vor einem Wiedererstarken des Katholizismus, wie zum Beispiel im angrenzenden Herzogtum Sagan oder in Wittichenau geschehen, eine gemäßigte Haltung gegenüber der sorbischen Sprache ein und im Kreis Cottbus wurde von Friedrich I. sogar das ländliche Schulwesen auf Grundlage der sorbischen Muttersprache begründet und religiöses sorbischen Schriftentum gefördert. Hintergrund war hier die Vermeidung von inneren Konflikten als Grundlage der Expansionsbestrebungen nach Osten.

Nach den ersten Anfängen einer sorbischen religiösen Literatur Mitte des 16. Jahrhunderts, kam es trotz aller politischen und ökonomischen Schwierigkeiten nach dem Dreißigjährigen Krieg zu einem Aufblühen des sorbischen Schrifttums und zur Festigung der sorbischen Sprache. Die stärkste kulturelle Aktivität gab es nach dem Krieg am nördlichen Rand des sorbischen Siedlungsgebietes, aufbauend und inspiriert durch die frühen Arbeiten des Übersetzers und Philologen Handroš Tara (Andreas Tharaeus, 1570–1640), Pfarrherrn vom Friedersdorf im Amt Storkow. So wurde 1650 die erste sorbische Grammatik vom Lübbenauer Oberpfarrer Johannes Choinan verfasst, die durch zahlreiche Abschriften verbreitet wurde. Um diese Zeit erschien auch die erste sorbische Fibel von Juro Ermelius, Rektor der Calauer Stadtschule, sowie von 1653 bis 1656 vier religiöse sorbische Druckschriften, angefertigt von mehreren Geistlichen, hauptsächlich aus dem Amt Beeskow. Durch die einsetzenden Maßnahmen zur Verdrängung des Sorbischen in der Niederlausitz und im Wendischen Distrikt der Kurmark, verlor das Gebiet an Bedeutung für die weitere kulturelle Entwicklung der Sorben und um die Wende zum 18. Jahrhundert trat an seine Stelle der Kreis Cottbus und die Oberlausitz.
Im Kreis Cottbus wirkte der in Halle ausgebildete und vom Pietismus beeinflusste Geistliche Jan Bogumil Fabricius. Er war selber kein Sorbe, erlernte aber in kürzester Zeit die Sprache der Sorben und schuf mit seinem 1706 (Katechismus) und 1709 (Neues Testament) veröffentlichten Werken, finanziell unterstützt durch Friedrich I., den Grundstein für die "niedersorbische Schriftsprache". Fabricius stieg später zum höchsten geistlichen Würdenträger im Kreis auf, wurde Oberpfarrer der Stadt Peitz und schließlich Kircheninspektor von Cottbus. Zwischen 1706 und 1806 erschienen 45 niedersorbische Bücher im Kreis Cottbus, darunter die Übersetzung des Alten Testaments von Jan Bjedrich Fryco.
In der Oberlausitz setzten sich führende Vertreter der pietistischen Bewegung für die Verbreitung von religiösem Schrifttum in der Volkssprache ein. Zugleich führte die Konkurrenz der Konfessionen zu einem Wettstreit im Editieren von Büchern, um den Bereich der eigenen Konfession auszubauen bzw. zu erhalten. Auf evangelischer Seite gab 1706 Michał Frencel (1628–1706), Pfarrer in Großpostwitz bei Bautzen, das Neue Testament heraus, in dem Dialekt, wie er in seiner Gemeinde gesprochen wurde, und begründete so die "obersorbische Schriftsprache". Sein Sohn Abraham Frencel (1656–1740) setzte später sein Werk fort. Von 1688 bis 1707 wurde erstmals die komplette Bibel durch den römisch-katholischen Geistlichen Jurij Hawštyn Swětlik (1650–1729) übersetzt – seine Fassung blieb allerdings ungedruckt – und schuf so die katholische Variante der obersorbischen Schriftsprache. Allein in den Jahren von 1688 bis 1728 erschienen in der Oberlausitz 31 Buchtitel in sorbischer Sprache, teilweise mit finanzieller Unterstützung der Stände.

Wurde die Kulturentwicklung zunächst hauptsächlich von Einzelpersönlichkeiten getragen, so entstanden ab Anfang des 18. Jahrhunderts erste Institutionen, die sich der Förderung und Entwicklung der sorbischen Sprache, Kultur und Bildung widmeten. 1724 wurde das katholische Wendische Seminar in Prag, als Ausbildungsstätte für katholische Priester aus der Oberlausitz gegründet. Zu den Studenten zählte unter anderem Franc Jurij Lok, der später Dekan des katholischen Kapitels St. Petri in Bautzen wurde (1796–1831), und sich erfolgreich für die Volksbildung der Sorben einsetzte. Von Studenten der evangelischen Theologie wurde 1716 an der Universität Leipzig das Wendische Predigerkollegium und 1746 in Wittenberg die Wendische Predigergesellschaft ins Leben gerufen. Ebenfalls in Leipzig wurden 1766 die "Lipske nowizny a wšitkizny" herausgegeben. Durch sorbische und deutsche Gelehrte wurde 1779 in Görlitz die Oberlausitzische Gesellschaft der Wissenschaften gegründet, welche die deutsch-sorbische Wechselseitigkeit im Zeichen der Aufklärung widerspiegelte. Als erster Deutscher beschäftigte sich Georg Körner, Mitglied des Wendisches Predigerkollegiums, intensiv mit der sorbischen Sprache und veröffentlichte 1767 die "Philologisch-kritische Abhandlung von der Wendischen Sprache und ihrem Nutzen in der Wissenschaft" sowie 1768 ein sorbisch-deutsches Wörterbuch.

Unter dem Eindruck der Französischen Revolution kam es kurz vor Ende des 18. Jahrhunderts zwischen 1790 und 1794 in beiden Lausitzen zu größeren Bauernunruhen, welche in Teilen der Oberlausitz auch unmittelbar durch den großen sächsischen Bauernaufstand von 1790 ausgelöst wurden. An der Wende zum 19. Jahrhundert war das sorbische Siedlungsgebiet mit Schauplatz der Napoleonischen Kriege. Neben wiederholten großen Truppendurchzügen, unter welchen die Bevölkerung aller Teile der Lausitzen litten, kam es 1813 während der Befreiungskriege zur Schlacht bei Bautzen und weiteren Gefechten bei Luckau und Hoyerswerda. Mit Beendigung des Krieges und dem Wiener Kongress 1815 kam es zu einer territorialen Neugliederung Europas, von denen auch große Teile des sorbischen Siedlungsgebietes betroffen waren. Die ehemalig zum Königreich Sachsen gehörenden Gebiete der Niederlausitz und die nördliche und östliche Oberlausitz um Hoyerswerda, Weißwasser und Görlitz fielen an Preußen. Dadurch wurde das bis dahin administrativ noch größtenteils zusammengehörige sorbische Siedlungsgebiet, was am Ende des 18. Jahrhunderts nur noch circa 7.000 km² umfasste, geteilt und mit 200.000 Sorben gehörte der Großteil der sorbischen Bevölkerung nun zu Preußen. Im verbliebenen sächsischen Teil der Oberlausitz lebten damals noch 50.000 Sorben.

Durch die Trennung der sorbischen Bevölkerung in zwei Staaten und die Tatsache, dass die Sorben durch die Neugliederung in Preußen in fast allen Regierungsbezirken nun in der Minderheit waren, wurde die intellektuelle und kulturelle Entwicklung, speziell in der Niederlausitz, nachteilig beeinflusst und die Bildung einer eigenen Nation nahezu unmöglich gemacht. Die Unterdrückung der sorbischen Sprache in Preußen wurde weiter verschärft und erreichte nach der Reichsgründung in der zweiten Hälfte des 19. Jahrhunderts einen Höhepunkt. Auf Grund des gespannten deutsch-russischen Verhältnisses jener Zeit, wurde die Existenz einer slawischen nationalen Minderheit als Bedrohung für Deutschland angesehen. Mit der Billigung durch Reichskanzler Otto von Bismarck wurde im Deutschen Reich eine Phase der antisorbischen Repression eingeleitet. Im preußischen Teil der Oberlausitz kam es 1875 zu einem generellen Verbot der sorbischen Sprache in Schulen, 1885 zum Verbot des sorbischen Konfirmandenunterrichts in Schlesien und 1888 verbot das preußische Kultusministerium den sorbischen Sprachunterricht am Gymnasium in Cottbus. Sorbische Intellektuelle reagierten zwar auf diese Angriffe und versuchten den Widerstand gegen die eingeschlagene Sorbenpolitik zu erhöhen, dennoch beschleunigte sich die Assimilation der Niederlausitzer Sorben unter dem erhöhten Druck der Obrigkeit gegen Ende des 19. Jahrhunderts erheblich.

Das 19. Jahrhundert war aber auch eine Blütezeit der bürgerlichen sorbischen Kultur, welche maßgeblich von einzelnen obersorbischen Persönlichkeiten getragen wurde. Die Sprachwissenschaftler und Verleger Jan Pětr Jordan und Jan Arnošt Smoler waren Verfechter der nationalen Bewegungen der slawischen Völker und derer kulturellen Wechselseitigkeit. Sie waren bemüht um eine sorbische Rechtschreibreform, die die bisherige sehr uneinheitliche Rechtschreibung an die anderer slawischer Völker angleichen sollte und als wesentliche Bedingung für die Entwicklung einer einheitlichen sorbischen Literatur angesehen wurde. Jordan war zudem maßgeblich an der Vorbereitung und Durchführung des im Juni 1848 durchgeführten Slawenkongress in Prag beteiligt, an dem auch eine sorbische Delegation teilnahm und wo die panslawischen Farben festgelegt wurden, auf denen auch die Flagge der Sorben beruht. Smoler trug gemeinsam mit Leopold Haupt (1797–1883) und Handrij Zejler die bedeutende sorbische Liedersammlung „Die Volkslieder der Wenden in der Ober- und Nieder-Lausitz“ zusammen. Der Dichter Handrij Zejler gilt als Begründer der modernen sorbischen Literatur sowie er selbst als treibende Kraft und seine Werke als Höhepunkt der "sorbischen nationalen Wiedergeburt", welche die sorbische Literaturentwicklung des 18. und 19. Jahrhunderts umfasst. "„Da Zejler die Möglichkeit eines sorbischen Nationalstaates ausschloß, war für ihn die nationale Emanzipation der Sorben gleichbedeutend mit dem Eintreten für die Konstituierung einer sorbischen bürgerlichen Identität innerhalb eines deutschen Staates“", was die Existenz des sorbischen Volkes seiner Ansicht nach sichern würde. Eine weitere herausragende Persönlichkeit dieser Zeit war der mit Zejler befreundete sorbische Komponist Korla Awgust Kocor. Beide organisierten ab 1845 sorbische Gesangsfeste, die einen nachhaltigen Eindruck in der obersorbischen Bevölkerung hinterließen und zur Festigung der sorbischen Sprache und Kultur beitrugen.

1847 wurde in Bautzen die wissenschaftliche Gesellschaft Maćica Serbska gegründet, was den Höhepunkt der Entfaltung des geistig-kulturellen sorbischen Lebens im Vormärz darstellte. Zu den Gründungsmitgliedern zählten unter anderem Smoler und Zejler und die Maćica Serbska entwickelte sich rasch zum Mittelpunkt der sorbischen Wissenschafts- und Kulturbemühungen; sie ist der älteste noch existierende sorbische Verein. Der sorbische Wissenschaftler Arnošt Muka, ebenfalls Mitglied der "Maćica Serbska", untersuchte in den Jahren 1880–1884 auf ausgedehnten Reisen den Zustand der sorbischen Sprache und Kultur in der Ober- und Niederlausitz und veröffentlichte danach seine "Statistika Łužiskich Serbow" („Statistik der Lausitzer Sorben“). Nach Muka gab es zu diesem Zeitpunkt 160.000 Sorben, die in weiten Teilen der nördlichen Ober- sowie der Niederlausitz noch die Bevölkerungsmehrheit stellten.

Im Jahre 1904 öffnete das Wendische Haus "(Serbski dom)" am Lauengraben in Bautzen seine Pforten. Am 12. Oktober 1912 wurde in Hoyerswerda der Dachverband der 31 sorbischen Vereine, die Domowina, gegründet. Sie fasste die nach 1848/49 entstandenen Bürger-, Bauern- und Bildungsvereine mit ihren rund 2.000 Mitgliedern zusammen und sollte das sorbische kulturelle Leben weiter festigen.

Nach dem Ende des Ersten Weltkrieges wurden Forderungen nach selbstständiger Verwaltung laut. Die Weimarer Verfassung legte im Artikel 113 lediglich fest, dass die „fremdsprachigen Volksteile des Reiches […] durch die Gesetzgebung und Verwaltung nicht in ihrer freien volkstümlichen Entwicklung, besonders nicht im Gebrauch ihrer Muttersprache beim Unterricht sowie bei der inneren Verwaltung und der Rechtspflege beeinträchtigt werden“ dürfen.

Im Jahre 1920 wurde die Wendische Volkspartei von Jan Skala gegründet, konnte im Parlament allerdings keine Mandate erringen. Sie setzte sich für die Ziele der sorbischen Nationalbewegung ein. Zusammen mit der Domowina und der wissenschaftlichen Vereinigung Maćica Serbska bildeten sie 1925 den Wendischen Volksrat. Auch in dem 1924 gegründeten Verband der nationalen Minderheiten Deutschlands arbeiteten die Sorben mit.

In den folgenden Jahren entstanden zahlreiche Vereinigungen, Genossenschaften und eine sorbische Volksbank. Die demokratischen Verhältnisse der Weimarer Republik boten den Sorben nun bessere Möglichkeiten, volkstümliche Aktivitäten zu entfalten. Hier leisteten, besonders in der Oberlausitz, die zahlreichen sorbischen Vereine breite Kultur- und Bildungsarbeit.

Nachdem die NSDAP zunächst versucht hatte, die Sorben in die neuen Strukturen einzugliedern und für ihre Ziele zu vereinnahmen, sowie die Domowina in den Bund Deutscher Osten einzugliedern, änderte sich die Politik, nachdem klar wurde, dass die sorbischen Organisationen unter dem Domowina-Vorsitzenden Pawoł Nedo sich dem widersetzten. Ab 1937 wurden alle sorbischen Vereinigungen verboten und der Gebrauch des Sorbischen in der Öffentlichkeit stark eingeschränkt. Sorbische Lehrer und Geistliche wurden aus der Lausitz in weit entfernte Teile Deutschlands versetzt. Das Regime versuchte damit, das sorbische Volk zur Assimilation zu zwingen. Unter der sorbischen Intelligenz kam es zu systematischen Verhaftungen; einige ihrer aktivsten Vertreter wurden in Konzentrationslagern inhaftiert, manche erlebten die Befreiung nicht mehr (u. a. Maria Grollmuß, Alois Andritzki).

Im gleichen Zug wurde vor allem das Lausitzbild propagandistisch verändert, teils agrarromantisch („Lausitzbauern“), dann auch mit industriell-modernen Zügen unter Bezug auf die Braunkohle („Umbruch“).

Nach dem Zweiten Weltkrieg war die Domowina eine der ersten Organisationen in der SBZ, deren Tätigkeit von der Sowjetischen Militäradministration zugelassen wurde, noch bevor es den besiegten Deutschen erlaubt war, wieder Organisationen zu gründen. Denn, so Marschall Iwan Stepanowitsch Konjew, das „kleine Volk, das auf dem Territorium Deutschlands lebt und im Faschismus soviel erdulden mußte, verdiente es, unterstützt zu werden.“ Nach ihrer Wiedergründung am 10. Mai 1945 in Crostwitz nahm die Domowina erneut ihre Arbeit auf, mit dem Ziel, die sorbische Identität in der Lausitz zu erhalten und zu beleben. Zunächst war sie nur in der Oberlausitz tätig, weil die Wiederaufnahme der Arbeit in der Niederlausitz auf Betreiben der Brandenburger SED-Leitung unter Friedrich Ebert sowie des Cottbusser Landrats Franz Saisowa (SED) bis 1949 im Hinblick auf ihre angeblich separatistischen Bestrebungen nicht zugelassen wurde. Sorbische Aktivitäten wurden dort zunächst systematisch unterdrückt, nationalbewusste Sorben überwacht und in einigen Fällen vorübergehend in Haft genommen (z. B. Mina Witkojc). Der in Prag ansässige Lausitzisch-Sorbische Nationalausschuss ("Łužisko-serbski narodny wuběrk") unter Führung von Pfarrer Jan Cyž und Jurij Cyž sah die Zukunft der Sorben zunächst tatsächlich in ihrer Anbindung an die Tschechoslowakei bzw. in staatlicher Unabhängigkeit und lehnte eine Zusammenarbeit mit deutschen Behörden grundsätzlich ab. Die Domowina setzte hingegen recht bald, zumal auch die Sowjetunion kein Interesse an einem von der SBZ getrennten Sorbengebiet hatte, auf den Verbleib in einem deutschen Staatswesen und ordnete sich ab März 1946 der politischen Linie der KPD unter; im Herbst 1946 stimmte sie der Vereinigung von SPD und KPD zur SED und der Aufstellung einheitlicher Wahllisten zu.

Der Konflikt zwischen den beiden sich als Vertreter des sorbischen Volkes betrachtenden Organisationen führte im Dezember 1946 dazu, dass zum Allslawischen Kongress in Belgrad zwei sorbische Delegationen anreisten. Auch darüber hinaus standen die Sorben in den vier Jahren bis zur Gründung der DDR in regem Kontakt mit anderen slawischen Ländern, nicht nur mit Polen und der Tschechoslowakei. Auf der Schadźowanka, einer regelmäßig stattfindenden Zusammenkunft sorbischer Studenten, lud 1946 ein Vertreter der jugoslawischen Militärmission die Brigaden der Sorbischen Jugend ("Serbska młodźina") auf den Balkan ein. Jugoslawien war zu dieser Zeit der einzige verbliebene Staat, der die Forderungen der Sorben nach politischer Autonomie offen unterstützte. Die Jugendorganisation unter Führung von Jurij Brězan war zu diesem Zeitpunkt noch unabhängig und nicht in den Weltbund der Demokratischen Jugend eingebunden. Nach dem Bruch der Beziehungen zwischen Moskau und Belgrad fanden keine weiteren Besuche statt. Die Sorbische Jugend wurde im Dezember 1948 in die FDJ eingegliedert.

Die Flüchtlingsströme von vertriebenen Deutschen aus Schlesien, dem Sudetenland und anderen ehemals deutsch besiedelten Gebieten setzten das sorbische Siedlungsgebiet unter starken Druck. War Sachsen zunächst nur Durchgangsgebiet für Flüchtlinge, wurde es von der sowjetischen Administration im März 1946 zum Siedlungsgebiet erklärt. Laut einer Statistik der Domowina waren viele vormals sorbische Dörfer binnen kurzem zu mehr als 20, manche sogar zu mehr als 50 Prozent von deutschsprachigen Flüchtlingen bewohnt. In der Folge wurden vor allem im evangelischen Teil des sorbischen Gebietes in zahlreichen Orten die sorbischen Gottesdienste durch deutsche ersetzt; Sorbisch wurde von der Alltags- zur Privatsprache. In den katholischen Gemeinden wurden die meisten Zugezogenen dagegen durch die Sorben assimiliert.

Im Mai 1947 wurde der Domowina von den sowjetischen Behörden die Einrichtung einer sorbischen Druckerei erlaubt; im Oktober wurde sie schließlich als alleinige Interessenvertreterin der Sorben anerkannt. Somit bewegte sich die sorbische Bewegung immer weiter auf die Linie der SED zu. Bei einem Treffen zwischen der Domowina-Führung unter Pawoł Nedo und den SED-Vorsitzenden Otto Grotewohl und Wilhelm Pieck wurden beinahe alle Vorschläge der Domowina, darunter die Schaffung einer Verwaltungseinheit Lausitz und die Anerkennung der Sorben als Volk, abgelehnt. Die Lausitz blieb weiterhin geteilt und den Sorben wurde lediglich der Status eines „Volksteils“ zuerkannt.

Am 23. März 1948 wurde vom Sächsischen Landtag das „Gesetz zur Wahrung der Rechte der sorbischen Bevölkerung“ verabschiedet, das erstmals den Anspruch der Sorben auf Förderung ihrer Sprache und Kultur festschrieb. 1950 wurde es durch Verordnung auch im Land Brandenburg eingeführt, nachdem die Domowina dort erst ein Jahr zuvor auf massiven Druck der sowjetischen Administration und der Berliner SED-Führung hin ihre Arbeit wieder hatte aufnehmen dürfen.

In den frühen 50er Jahren wurde die Eingliederung der Sorben in den sozialistischen Staatsapparat weiter vorangetrieben. Der bisherige Domowina-Vorsitzende Nedo hatte sich der Hinwendung zum Marxismus-Leninismus zwar nicht offen in den Weg gestellt, aber immer wieder auch die nationalen Rechte des sorbischen Volkes angemahnt. Er wurde im Dezember 1950 durch Kurt Krjeńc, einen Altkommunisten, ersetzt, der die Domowina in den folgenden Jahren zu einer Satellitenorganisation der SED umbaute, deren Kernaufgabe nicht mehr der Erhalt und die Förderung sorbischer Kultur, sondern die Eingliederung der Sorben in den Sozialismus war. In der Geschichtsschreibung wurde besonders die Rolle der „sorbischen Werktätigen“ betont, jene anderer Gruppen, z. B. die der für die nationale Bewegung wichtigen Geistlichen und Kleinbürger, dagegen heruntergespielt. Dennoch blieb die sorbische Dachorganisation unter strenger Beobachtung durch das Ministerium für Staatssicherheit; es war die Rede von „nationalistischen und titoistischen Umtrieben“. Persönlichkeiten wie Pawoł Nowotny (Leiter des Instituts für sorbische Volksforschung) und Pawoł Nedo, aber auch bekennende Kommunisten wie Jurij Brězan standen wegen möglicher „antistaatlicher Aktivitäten“ unter Überwachung. Bis in die 70er Jahre hinein wurden verschiedene sorbische Persönlichkeiten wegen ihres Protests gegen die Ausweitung der Tagebaue und den Bau von Großkraftwerken in der Lausitz oder gegen die Einrichtung von LPGen im sorbischen Gebiet, sowie später wegen verdächtiger Kontakte zur tschechoslowakischen Intelligenz überwacht und in Einzelfällen inhaftiert.

Eine Rolle spielten die Sorben auch im Prozess der Anerkennung der Deutschen Demokratischen Republik durch Jugoslawien in den fünfziger Jahren (in dessen Folge die Bundesrepublik Deutschland die Beziehungen zu Jugoslawien aufgrund des Alleinvertretungsanspruchs der BRD abbrach). Die DDR entsprach damals der Forderung Josip Broz Titos, in der einzurichtenden Botschaft in Belgrad einen bestimmten Prozentsatz an sorbischen Mitarbeitern zu beschäftigen. So wurde unter anderem ein Sorbe zum Chefdolmetscher der Botschaft ernannt. Kurze Zeit nach der Aufnahme diplomatischer Beziehungen am 15. Oktober 1957 wurden diese allerdings wieder zurückgerufen.

Offiziell wurde das sorbische Volk in Artikel 40 der DDR-Verfassung von 1968 als nationale Minderheit anerkannt. Für die Berücksichtigung der sorbischen Interessen wurden in den jeweiligen DDR-Ministerien Abteilungen für die sorbischen Belange eingerichtet (z. B. Kultur und Innenpolitik) und staatliche wissenschaftliche Institutionen (Neu: Institut für sorbische Volksforschung; Wiedereinrichtung: Institut für Sorabistik an der Universität Leipzig) geschaffen. Um eine Gleichstellung der sorbischen Bevölkerung zu sichern, wurden verschiedene juristische Regelungen erlassen. So wurden der sorbische Schulunterricht und die zweisprachige Beschriftung von öffentlichen Einrichtungen und Straßenschildern im deutsch-sorbischen Gebiet eingeführt.

Trotzdem war die offizielle Politik gegenüber den Sorben weiter von ideologischer Bevormundung und Kontrolle geprägt, wenngleich eine gewisse Eigenständigkeit gewahrt bleiben konnte. Im Vergleich mit nationalen Minderheiten anderer Länder konnten sich hier die sorbische Kultur und die Wissenschaft in einer überdurchschnittlichen Breite entwickeln. Dennoch vollzog sich der Rückgang des Sorbischen als Alltagssprache so schnell wie selten zuvor. Dafür gab es neben der allgemeinen Tendenz zur Assimilation auch zahlreiche politische Gründe: Sowohl das zunächst ambitionierte Bildungsprogramm als auch die praktische Unterstützung der Zweisprachigkeit durch offizielle Stellen wurden bereits ab 1958 nach dem Rücktritt von Fred Oelßner schrittweise wieder zurückgenommen. An den neu eingerichteten A-Schulen (Schulen mit sorbischer Unterrichtssprache) wurden naturwissenschaftliche Fächer ab 1962 wieder auf Deutsch gelehrt; die Losung „Die Lausitz wird zweisprachig“ war bereits mit Fred Oelßner aus der Öffentlichkeit verschwunden. Auf Druck vor allem der zugezogenen Energiearbeiter wurde schließlich 1964 auch der sorbische Fremdsprachunterricht in den B-Schulen fakultativ. Lernten 1962 noch 12.800 Schüler Sorbisch, waren es Ende 1964 nur noch 3200, Ende der 60er Jahre sogar weniger als 3000. Die Schülerzahl in A-Schulen blieb dagegen nahezu konstant.

Die Kollektivierung der Landwirtschaft zerstörte mit den traditionellen Familienhöfen den einzigen Wirtschaftszweig, in dem Sorbisch noch Alltagssprache war. Die Einrichtung von rein sorbischen LPGen wurde abgelehnt; in der Praxis wurden mehrheitlich sorbische Genossenschaften meist von Deutschen geleitet. Ebenso abgelehnt wurde die vorgeschlagene Einrichtung von sorbischen Brigaden in den Lausitzer Kohlekraftwerken. Über vorhandene Probleme zwischen Deutschen und Sorben konnte nicht offen diskutiert werden, da eine Kritik an der DDR-Nationalitätenpolitik und eine Thematisierung der Unterschiede zwischen staatlichem Ideal und der in langer Tradition wurzelnden latenten Sorbenfeindlichkeit nicht erwünscht war.
Zudem erlitt die sorbische Kultur in der Zeit nach 1945 nachhaltige Schäden durch die kriegsbedingte Massenzuwanderung von deutschsprachigen Aussiedlern und später Facharbeitern, die Zerstörung weiter Gebiete durch den Braunkohletagebau, die Verstädterung sowie schließlich die angestrebte Entkirchlichung (die sorbische Identität wurde wesentlich über die religiöse Praxis gewahrt), der sich fast ausschließlich die katholischen Sorben zu widersetzen wussten.

Diese Rahmenbedingungen, denen sich die Domowina als Vertreterin der Sorben nicht entgegenstellen konnte, bei deren Durchsetzung sie allerdings auch eine aktive Rolle spielte, führten zu einem starken Rückgang der sorbischen Bevölkerung zwischen 1945 und 1990. Während die DDR offiziell immer von 100.000 Angehörigen des Volkes sprach, wies der Forscher Ernst Tschernik schon 1955 darauf hin, dass es vermutlich noch 80.000 Sorben gebe, mit stark sinkender Tendenz. Sein Bericht durfte nie veröffentlicht werden. Schon kurz nach der Wiedervereinigung korrigierte man jedoch die Schätzungen auf 40.000 bis 60.000. Es ist also davon auszugehen, dass sich die Zahl der Sorben während der DDR-Zeit halbiert hat.

Erst 1987 nahm die Domowina wieder Kontakt zu den sorbischen Geistlichen beider Konfessionen auf, nachdem ihr Erster Sekretär hatte zugeben müssen, dass etwa die Hälfte der Mitglieder Protestanten und 20 Prozent Katholiken sind. Die jahrzehntelange Periode, während der viele – vor allem gläubige – Sorben die „rote Domowina“ als „Verräterin der sorbischen Interessen“ betrachtet hatten, hinterließ jedoch Spuren in ihrer öffentlichen Wahrnehmung und führte nach der Wiedervereinigung zu einem massiven Mitgliederschwund.

Neue politische Rahmenbedingungen ergaben sich mit dem Ende der DDR auch für die Sorben. Die Domowina sprach sich in einer Erklärung im März 1990 für die deutsche Einheit aus. Im selben Jahr eröffnete auch das Wendische Haus in Cottbus. 1991 konstituierte sich die Domowina nach demokratischen Prinzipien neu. Als gemeinsames staatliches Instrument des Bundes und der beiden Länder Brandenburg und Sachsen wurde die Stiftung für das sorbische Volk "(Załožba za serbski lud)" ebenfalls 1991 eingerichtet.

Nach der Jahrtausendwende kam es wiederholt zu Protestaktionen der sorbischen Bevölkerung, unter anderem gegen die Schließung der Sorbischen Mittelschule in Crostwitz (2001) oder die Kürzungspläne von Bundesregierung und brandenburgischer Landesregierung bei der Förderung der sorbischen Bildung, Kultur und Wissenschaft (2008). Im Jahr 2009 erregte ein Gutachten des Instituts für kulturelle Infrastruktur unter Leitung von Matthias Theodor Vogt die Gemüter, in dem eine teils radikale Umstrukturierung der sorbischen Institutionen, unter anderem auch die Schaffung eines sorbischen Parlaments, angeregt wurde.

Bis in die jüngste Vergangenheit waren durch den Braunkohleabbau seitens der LEAG Dörfer im sorbischen Siedlungsgebiet von Zwangsumsiedlung betroffen oder bedroht, so zum Beispiel die Ortschaften Rohne und Mulkwitz der Gemeinde Schleife, sorbische Orte mit eigenem Dialekt und Brauchtum. Beim Nachbarort Mühlrose hält die LEAG an der seit 2007 geplanten Inanspruchnahme ab etwa 2030 fest, wobei den Einwohnern bislang (Stand 2018) keine rechtsverbindlichen Verträge zur Unterzeichnung vorgelegt wurden. Über die Zukunft von Proschim hat sich die LEAG nach der Übernahme des Tagebaus Welzow-Süd noch nicht geäußert.

Nach Plänen der brandenburgischen und sächsischen Landesregierung soll die Braunkohle auch weiterhin Vorrang genießen.

Von 2008 bis 2017 war mit Stanislaw Tillich zum ersten Mal ein katholischer Sorbe Regierungschef Sachsens.

Eine Flagge der Sorben wurde zuerst 1842 erwähnt. Nach dem Panslawischen Kongress, der 1848 in Prag stattfand, erhielt sie ihre heutige Farbgebung. Die Flagge der Sorben wurde von den Nationalsozialisten 1935 verboten, seit dem 17. Mai 1945 aber wieder offiziell von der Domowina verwendet.
In den Flaggengesetzen der Deutschen Demokratischen Republik wurde die Sorbenflagge nicht erwähnt, in Verordnungen der Räte der Bezirke Cottbus und Dresden wurde jedoch ihre Verwendung für besondere Anlässe und Feiertage reguliert.

Die sorbische Hymne ist das Lied „Rjana Łužica“ "(„Schöne Lausitz“)", welches auf ein 1845 von Korla Awgust Kocor vertontes Gedicht Handrij Zejlers zurückgeht.

In der Verfassung des Freistaates Sachsen sowie im Sorben (Wenden)-Gesetz (SWG) des Landes Brandenburg ist heute geregelt, dass die sorbische Hymne und die sorbische Flagge gleichberechtigt neben staatlichen Symbolen geführt werden können.

Die Bundesrepublik Deutschland und die damalige DDR sprachen sich im Einigungsvertrag für eine Bestandssicherung der Sorben aus.


Die Rechte der Minderheit der Sorben sind verfassungsrechtlich in den Landesverfassungen von Brandenburg und Sachsen, sowie im Gerichtsverfassungsgesetz verankert. So garantiert die Verfassung des Landes Brandenburg in Artikel 25 (Rechte der Sorben [Wenden]) und die Verfassung des Freistaates Sachsen in Artikel 5 (Das Volk des Freistaates Sachsen) und Artikel 6 (Das sorbische Volk) das Recht auf Bewahrung ihrer nationalen Identität, Sprache, Religion und Kultur.

Die Ausgestaltung der Rechte regelt das "Gesetz zur Ausgestaltung der Rechte der Sorben (Wenden) im Land Brandenburg (SWG)" vom 7. Juli 1994 sowie das "Gesetz über die Rechte der Sorben im Freistaat Sachsen (Sächsisches Sorbengesetz – SächsSorbG)" vom 31. März 1999. So werden unter anderem im angestammten Siedlungsgebiet die zweisprachige Beschriftung von Verkehrszeichen und die zweisprachige Beschilderung im öffentlichen Raum geregelt (SWG § 11 bzw. SächsSorbG § 10). Vom Grundsatz der deutschen Gerichtssprache – Satz 1 Gerichtsverfassungsgesetz (GVG) – abweichend, erlaubt § 184 S. 2 GVG innerhalb der Heimatkreise der sorbischen Bevölkerung die Benutzung der sorbischen Sprache vor Gericht.

Theodor Fontane beschreibt in seinen Wanderungen durch die Mark Brandenburg (1862–1889) neben der Geschichte auch die Lebensweise, Sitten und die Tracht der Sorben in der Niederlausitz (Wenden). In Wilhelm Bölsches Gegenwartsroman "Die Mittagsgöttin" von 1891 sind die Schauplätze unter anderem im Spreewald im damaligen noch hauptsächlich Niedersorbisch sprechenden Dorf Lehde.
Ferner heißt der 2007 erschienene Roman Die Mittagsfrau von Julia Franck nach der bekannten sorbischen Sagengestalt. Der erste Teil des Romans behandelt die Kindheit von Martha und Helene in Bautzen, deren sorbisches Hausmädchen die Ursache für die geistige Umnachtung der Mutter im Fluch der Mittagsfrau vermutet.

Der Animationsfilm "Als es noch Wassermänner gab" der DEFA beruht auf einem sorbischen Märchen und beschäftigt sich unter anderem mit sorbischen Hochzeitsbräuchen. Im ZDF wurde 2010 der Kriminalfilm "" ausgestrahlt. Eine der Hauptfiguren ist der Sohn einer traditionsbewussten sorbischen Familie, der sich seinen kulturellen Wurzeln nicht verbunden fühlt. Mit dem Film wurde einem breiten Publikum die sorbische Kultur nähergebracht, wobei aber auch die Heimat- und Minderheiten-Problematik reflektiert wird.

Das Minet – Minderheitenmagazin strahlte 2007 auf RAI 3 (Sender Bozen) eine Sendung über die Sorben mit dem Titel "Die Sorben – ein slawisches Volk in Deutschland" aus. Radiotelevisiun Svizra Rumantscha hat im Rahmen der Serie "Minoritads en l’Europa" (Minderheiten in Europa) ebenfalls im Jahre 2007 den Film "Ils Sorbs en la Germania da l’ost" über die Sorben in Deutschland realisiert.







</doc>
<doc id="12940" url="https://de.wikipedia.org/wiki?curid=12940" title="Slawisch">
Slawisch

Slawisch bezieht sich auf

Siehe auch:


</doc>
<doc id="12942" url="https://de.wikipedia.org/wiki?curid=12942" title="Claire Waldoff">
Claire Waldoff

Claire Waldoff (* 21. Oktober 1884 in Gelsenkirchen; † 22. Januar 1957 in Bad Reichenhall), geboren als "Clara Wortmann", war eine deutsche Interpretin der Kleinkunst in verschiedenen Genres. Sie selbst verstand sich als Volkssängerin. Ihr Repertoire war breit gefächert.

Besonders erfolgreich wurde sie mit Darbietungen von Chansons, gesungen im Berliner Dialekt. Ihre wohl berühmtesten Lieder sind "Wer schmeißt denn da mit Lehm", "Nach meene Beene is ja janz Berlin verrückt" und "Hermann heeßta". Sie trat in Revuen und Operetten auf, sang ebenso Soldatenlieder wie auch Volksweisen. Claire Waldoff bot Lieder von etwa 15 Komponisten und 25 Liedtextern dar, am häufigsten von Walter Kollo und Willi Kollo, Rudolf Nelson, Claus Clauberg, Eduard Künneke, Hans May, Harry Senger und Kurt Tucholsky.

Clara Wortmann wurde als elftes von 16 Kindern einer Gastwirtsfamilie von Clementine (geb. Hiltropp) und Wilhelm Wortmann geboren. In den Jahren zum Ende des 19. Jahrhunderts nahm sie an den ersten gymnasialen Kursen für Mädchen in Hannover teil. Genauere Daten sind bisher nicht belegbar. Mehrere Quellen berichten, darunter sie selbst in ihrer Autobiografie von 1953, dass sie während dieser Zeit in der Drostestraße bei Maria und Theodor Schmitz, den späteren Eltern Theo Lingens wohnte. Da sich ihr Wunsch, Ärztin zu werden, aus finanziellen Gründen nicht verwirklichen ließ, entschloss sie sich, das Schauspielfach einzuschlagen, und nahm den Künstlernamen Claire Waldoff an.

1903 hatte Claire Waldoff ihre ersten schauspielerischen Engagements im niedersächsischen Bad Pyrmont und Kattowitz in Oberschlesien. 1906 kam sie nach Berlin zu kleineren Auftritten. Es gab 1915 auch ein Leinwanddebüt beim Stummfilm. Karriere machte sie aber als kabarettistische Chanson- und Liedsängerin. Ihre künstlerische Hochzeit hielt bis 1936 an und endete nach 1942 gänzlich.

1917 lernte Claire Waldoff in Berlin Olga von Roeder (1886–1963) kennen, die aus einer US-amerikanischen Schauspielerfamilie stammte und Nachkomme des Texas-Siedlers Albrecht von Roeder war. Die beiden waren nicht nur ein Mittelpunkt des lesbischen Nachtlebens im Berlin der 1920er-Jahre, sondern sie führten auch einen kulturell-politischen Salon zum Gedankenaustausch unter Lesben. Bis zu ihrem Tod waren beide einander Lebensgefährtinnen. „Wir hatten beide das große Los aneinander gezogen“, schrieb Waldoff in ihren Memoiren, „Olly ist überhaupt ein seltener, lauterer Charakter, ein wunderbarer Mensch“.

Sehr enge Freundschaft hielt Claire Waldoff zu den Künstlern Kurt Tucholsky, der u. a. ihr einige Liedtexte unter dem Pseudonym Theobald Tiger schrieb, und Heinrich Zille. Die Sicht des Malers, wie er Claire Waldoff sah, fand als Textzeile eines Liedes, das Claire zum Ableben in Gedenken an Zille sang, Eingang. Sie lautete: „Wie Du selbst es tatest schildern, [ich] bin ein Bild aus Deinen Bildern“.

Von 1939 bis zu ihrem Tod lebte sie mit Olga von Roeder zurückgezogen in Bayerisch Gmain. Die Währungsreform 1948 kostete sie ihre Ersparnisse, sie verarmte. Im Juli 1951 gewährte ihr der Senat von Berlin einen "Ehrensold" von monatlich 150 D-Mark. 1953 erschien ihre Autobiografie. Im Januar 1957 starb sie, 72 Jahre alt, nach einem Schlaganfall. Ihre Urne wurde im Roederschen Familiengrab auf dem Pragfriedhof Stuttgart beigesetzt wie nach Olgas Tod 1963 auch deren Urne. Als das Familiengrab zwanzig Jahre später aufgelöst wurde, wurden beide Grabgefäße auf Veranlassung der Stadt Stuttgart in eine gemeinsame Nische der rechten hinteren Außenmauer des Kolumbarium umgesetzt.

Claire Waldoff erhielt zunächst kleinere Komödienrollen im "Figaro-Theater" am Kurfürstendamm in 5 Stücken von Paul Scheerbart. 1907 wechselte sie zum Kabarett. Rudolf Nelson engagierte sie für das Theater "Roland von Berlin" an der Potsdamer Straße. Ihren ersten Auftritt hatte sie in einem Etonboy-Anzug. Er machte sie über Nacht zum Stern von Berlin. Kurz vor dem Auftritt schrieb ihr der Komponist Walter Kollo ein Lied über einen liebestollen Erpel und sein "Schmackeduzchen". Es war der Ersatz für ein von der Zensur verbotenes Programm mit antimilitaristischen Liedern. Bald gastierte sie auch im "Chat Noir" an der Friedrichstraße und am "Linden-Cabaret" Unter den Linden. Während des Ersten Weltkrieges spielte sie im Theater am Nollendorfplatz in Walter Kollos Kriegsoperette "Immer feste druff" (Textdichter Hermann Freund, Herman Haller, Willy Wolff, 1914) und war später (1916) im Apollo-Theater in Königsberg Pr. engagiert. Ab 1924 erhielt sie Engagements in Ausstattungsrevuen unter anderen bei Erik Charell.

Claire Waldoff spezialisierte sich auf Gassenhauer, Schlager und Chansons im Berliner Jargon, den sie auf Kneipentouren gelernt hatte. Ihr Markenzeichen waren Krawatte, Hemdbluse und bronzeroter Bubikopf. Sie rauchte und fluchte auf der Bühne. Sie selbst beschrieb ihre Ausstrahlung später so: „Meine einfache Art, ohne Geste, nur auf Mimik, nur auf das Mienenspiel der Augen gestellt, war etwas Neues auf der Kabarettbühne. Ich war und blieb die große Nummer in meiner Einfachheit.“

Den Höhepunkt ihrer Karriere erreichte sie Mitte der 1920er Jahre. Sie trat in den zwei größten Varietés Berlins, der "Scala" und dem "Wintergarten", auf und unternahm Tourneen durch Deutschland. Sie wurde für Operetten und Ausstattungsrevuen engagiert und stand mit der noch unbekannten Marlene Dietrich auf der Bühne. Der Rundfunk spielte ihre Lieder. Ihre Schallplattenverkäufe erreichten Rekordhöhen. Ihr Repertoire umfasste zu dieser Zeit rund 300 Stücke.

Mit ihrer Lebensgefährtin Olga von Roeder war sie zugleich Mittelpunkt des lesbischen Berlin. Regelmäßig besuchte sie den "Damenklub Pyramide", der sich im "Toppkeller" in Berlin-Schöneberg traf. Dort verkehrten unter anderen die Tänzerinnen Anita Berber und Cilly de Rheydt, elegante Frauen, Malerinnen und Modelle.

Die Machtübernahme durch die Nationalsozialisten 1933 bedeutete auch für Claire Waldoff einen Einschnitt. Für einige Zeit hatte sie ein politisches Auftrittsverbot, weil sie noch kurz zuvor bei der kommunistischen "Roten Hilfe" im Berliner Sportpalast aufgetreten war. Nachdem sie der Reichskulturkammer beigetreten war, wurde es wieder aufgehoben. Mitte der 1930er Jahre trat sie in Berlin in einem Doppelprogramm mit Lene Ludwig auf, die parodistische Tänze mit Masken von Prominenten aufführte.

1936 knickte ihre Karriere ein. Propagandaminister Joseph Goebbels verbot ihr, in der Berliner "Scala" zu gastieren. In Berlin gab es für sie immer weniger Engagements. 1939 trat sie noch in Rundfunk-Wunschkonzerten auf. Die Wehrmacht engagierte sie für die Truppenbetreuung. Im Januar 1942 sang sie vor deutschen Soldaten im besetzten Paris.

"M" = Melodie "T" = Text






Tonträger, mit Originalaufnahmen von Claire Waldoff, die post mortem publiziert und aufbereitet wurden:









</doc>
<doc id="12947" url="https://de.wikipedia.org/wiki?curid=12947" title="Seelsorge">
Seelsorge

Der Ausdruck Seelsorge () ist eine im Deutschen geschichtlich gewachsene Bezeichnung, die sich aus den Wörtern Seele und Sorge zusammensetzt. Er bezeichnet die persönliche geistliche Begleitung und Unterstützung eines Menschen insbesondere in Lebenskrisen durch einen entsprechend ausgebildeten "Seelsorger", meist einen Geistlichen der jeweiligen Konfession. Methodisch kann die Seelsorge – je nach Konzept – unterschiedlich gestaltet sein; meist handelt es sich um Gespräche unter vier Augen. Der Seelsorger unterliegt dabei der Schweigepflicht oder seiner noch strengeren Variante, dem Beichtgeheimnis.

Im Neuen Testament begegnen für die mit „Seelsorge“ umschriebene Interaktion Begriffe wie Paraklese (griech. παράκλησις "paráklēsis"), was man im weitesten Sinne mit „Begleitung“, im engeren Sinne mit „Ermutigung“, „Zuspruch“, „Ermahnung“ und „Tröstung“ wiedergeben kann (Beispiele: , , , ). Weitere neutestamentliche Seelsorge-Vokabeln sind z. B. νουθετεῖν "nouthetein" (= ans Herz legen, ermahnen, , ) und καταρτίζειν "katartízein" (= in Ordnung bringen, zurechtmachen, wiederherstellen, , ), die in ihrem jeweiligen Kontext seelsorgliches Handeln leiten und begründen. 

Auch der biblische Befund, dass Gott oder dass Jesus Christus "sieht, erkennt, besucht und tröstet", kann zum Vorbild einer biblisch begründeten Seelsorge-Theorie genommen werden. Zur Seelsorge gehören das Ermahnen und Zurechtweisen (), der praktische Einsatz für in Not geratene Menschen () und das Gewähren von Gastfreundschaft ().

Zur Definition von Seelsorge besteht ein gewisser Konsens dahingehend, dass es sich bei Seelsorge um eine verbale und durch andere Zeichen vermittelte Interaktion im kirchlichen wie individuellen Kontext handelt. Man kann Seelsorge bezeichnen als ein personal vermitteltes, thematisch strukturiertes, kontextuell eingebettetes Beziehungsgeschehen mit Transzendenzbezug.

Die verschiedenen Ansätze und Methoden der Seelsorge werden in der Poimenik (von griech. ποιμήν "poimḗn" „Hirte“) reflektiert. Diese "Lehre von der Seelsorge" ist Teilgebiet der Praktischen Theologie.

Seelsorgliches Handeln ist nicht zu verwechseln mit psychotherapeutischem Handeln. Die Arbeit mit pathologischen Dynamiken gehört nicht in den Kompetenzbereich eines Seelsorgers und wird daher bewusst ausgeklammert. Jedoch kommen in der Seelsorge auch psychotherapeutisch fundierte Methoden zur Anwendung. Insbesondere die durch Carl Rogers und die niederländische Seelsorgebewegung in Deutschland beeinflusste Pastoralpsychologie legt auf einen engen Austausch zwischen Seelsorge und Psychologie (hier meist Psychotherapie) Wert.

Nach evangelischem, katholischem sowie orthodoxem Verständnis ist jeder Christ und jede Christin zur begleitenden Seelsorge im allgemeinen Sinne des Beistehens, Mittragens und des Sich-Einfühlens berufen und befähigt. Im Fokus christlicher Seelsorge steht nicht die Lösung eines aktuellen Problems, sondern sie versteht sich als ein Beziehungsgeschehen. Diese Interaktion wiederum geschieht nicht nur zwischen zwei oder mehreren Personen, sondern sie lebt aus der Annahme, dass Gott eine Beziehung zu jedem Menschen hat, unabhängig davon, ob dieser je seelsorglich begleitet wurde oder nicht. In dem Wissen um diese Gegebenheit will die Seelsorge Menschen die Möglichkeit bieten, im Kontakt zu einem oder mehreren Menschen aufrichtige Anteilnahme in negativen – wie auch positiven – Lebenssituationen zu erfahren. 

Im speziellen Sinn gibt es jedoch auch amtlich bestellte Seelsorger, deren seelsorgliches Handeln über den rein begleitenden Aspekt hinausgehen und in eine beratende Seelsorge (Lebensberatung) münden kann. In diesem Fall geht es tatsächlich um einen nach methodischen Gesichtspunkten gestalteten Problemlösungsprozess, durch den die Eigenbemühungen des Ratsuchenden unterstützt und optimiert werden.

In der alten Kirche ging es bei der Seelsorge primär um den Kampf des Christen gegen die Sünde, die sein endzeitliches Seelenheil gefährdet, und die Aufgabe des Seelsorgers war es, dem einzelnen Christen dabei zu helfen. Eine erste seelsorgliche Bewegung entstand unter den Wüstenvätern, die Christen oft aufsuchten und um Rat fragten. Ebenso waren die ersten klosterähnlichen Gemeinschaften solche Seelsorgezentren. In den Briefen von Basilius von Ancyra, Gregor von Nazianz und Johannes Chrysostomos finden sich zahlreiche Beispiele für seelsorglichen Rat.

Am Übergang zum Mittelalter verfasste Gregor der Große das an den Papst gerichtete "Liber regulae pastoris", eines der einflussreichsten Bücher über Seelsorge, das je geschrieben wurde.

Im Mittelalter war die Seelsorge eng an die Praxis des Bußsakraments gebunden, die Schuldbekenntnis, Wiedergutmachung und Lossprechung durch den Priester umfasste. Gegen die oft veräußerlichte Routine wurde insbesondere aus dem Mönchstum angegangen, beispielsweise von Bernhard von Clairvaux.

Bei den Reformatoren galt nicht mehr die Betonung der Sünde, sondern die Betonung der Vergebung Gottes und des Trostes, insbesondere bei Martin Luther und Heinrich Bullinger, in vielen Fällen ersetzte die Kirchenzucht allerdings bald die Seelsorge.

Der Pietismus lehnte jede formelle Seelsorge ab; erstmals wurde das seelsorgliche Gespräch ein Thema. Ziel der pietistischen Seelsorge war, die Früchte des Glaubens im persönlichen Leben, in Diakonie und Mission zu entfalten, während gleichzeitig in der Aufklärung der Sinn der Seelsorge in der Belehrung gesehen wurde, die die Gläubigen zur sittlichen Lebensführung befähigte.

Im 19. Jahrhundert begründete der evangelische Theologe Friedrich Schleiermacher die Praktische Theologie. Er betonte, die Seelsorge solle die Freiheit und Mündigkeit des einzelnen Gemeindeglieds stärken. Bereits 1777 wurde katholischerseits in Österreich unter Franz Stephan Rautenstrauch im Sinne der josephinischen Kirchenreform das Fach "Pastoraltheologie" ins Vorlesungsverzeichnis der Wiener Universität aufgenommen und in Muttersprache, nicht mehr in Latein unterrichtet. In Deutschland wurde es vor allem unter Johann Michael Sailer weiter entwickelt und verbreitet und gilt als Vorläufer der modernen Seelsorge.

In den USA entwickelte A.T. Boisen, einer der wichtigsten Repräsentanten der amerikanischen Seelsorgebewegung, in den 1920er-Jahren das Konzept des „Clinical Pastoral Training“, das Seelsorge, Psychologie und Pädagogik einschloss.

Eduard Thurneysen betonte den kerygmatischen Aspekt der Seelsorge als „Ausrichtung der Botschaft und damit um die Erweckung geistlichen Lebens…“

Mitte der 1960er-Jahre kam die Seelsorgebewegung über die Niederlande nach Deutschland und führte auch dort zur Entwicklung der Pastoralpsychologie. In der Theologie der Landeskirchen ist die pastoralpsychologisch orientierte Seelsorge bis heute Standard.

In den 1980er-Jahren entwickelte der katholische Priester und Universitätsdozent Eugen Drewermann an der Universität Paderborn seine tiefenpsychologische Auslegung der Bibel, insbesondere im dreibändigen Werk "Psychoanalyse und Moraltheologie".

Kirchliche Seelsorge geschieht heute in unterschiedlichen Kontexten (Gemeinde, Krankenhausseelsorge, Notfallseelsorge, Psychiatrie, Telefonseelsorge, Flughafenseelsorge, Bahnhofseelsorge, Schule, Polizeiseelsorge, Künstlerseelsorge, Beratungsstellen, Alten- und Seniorenheimseelsorge, Behindertenarbeit, Hospiz und Sterbendenbegleitung, Trauerarbeit, Briefseelsorge, Internetseelsorge, SMS-Seelsorge, für spezielle Zielgruppen wie die Afrikaner-Seelsorge Hamburg und in Einkaufszentren wie in der Sihlcity-Kirche etc.). Insbesondere Kasualien haben durch das vorangehende persönliche Gespräch einen seelsorglichen Charakter: Beim Taufgespräch begleitet man junge Familien in einer neuen Lebensphase, im Vorgespräch zu Hochzeiten kommt es über die Klärung organisatorischer Fragen zu seelsorglichen Momenten, ganz besonders im Vorfeld von Aussegnungsgottesdiensten werden Fragen nach dem Fazit und dem Sinn eines Lebens wach.

Gemeinsam ist allen Handlungsfeldern der Anspruch, Menschen in Lebens- und Glaubensfragen zu begleiten. Dies geschieht im persönlichen Gespräch, je nach Situation aber auch durch Gebet, durch die Spendung der Sakramente, durch tröstende und aufmunternde Worte aus der Bibel, durch Segensgesten (z. B. Handauflegung), aber auch durch soziale Unterstützung.

Auch das Internet bietet inzwischen die Möglichkeit, seelsorgliche Hilfe in Anspruch zu nehmen. Zahlreiche Kirchen und andere Einrichtungen bieten E-Mail-Kontakte an. Hier können Hilfesuchende mit einem festen Gesprächspartner ihre Anliegen besprechen.

Seelsorge ist immer wieder neu an den konkreten Menschen auszurichten. So geschieht in der Seelsorgepraxis seit dem Beginn der Christenheit auch ein kontinuierlicher Wandel. In früheren Zeiten waren die Menschen sehr stark an ihren Wohnort gebunden. Die territoriale Ausrichtung der Kirche hat dieser Gegebenheit entsprochen. In einer modernen Gesellschaft herrscht jedoch große Mobilität, so dass Menschen sich Angebote auswählen und sich nicht mehr selbstverständlich ihrer Gemeinde vor Ort verbunden fühlen. Die Lebenswelt der Menschen erweitert sich über ihren Wohnort hinaus. Mit diesen Herausforderungen beschäftigt sich seit Ende der 90er Jahre ein neuer Ansatz, die Lebensraumorientierte Seelsorge. Dabei soll auf theologischer Grundlage und mit Hilfe der Soziologie ein Seelsorgeansatz entwickelt werden, der den Gegebenheiten der Seelsorge im 3. Jahrtausend gerecht werden kann.

Erlebnisorientierte Seelsorge verbindet Seelsorge mit Ansätzen aus der Erlebnispädagogik und Bewegungstherapie. Das Erlebnis (in der Natur) ist Raum, Ansatzpunkt und Metaphernträger für das seelsorgliche Gespräch. Gerade das gemeinsame Gehen wurde zur Grundsituation für Gespräche. Dabei spielen nicht allein die Themen des Gesprächs eine Rolle, sondern auch Bewegungsmuster, Atemrhythmus oder Geschwindigkeit und Verlangsamung. Entstanden sind erlebnisorientierte Ansätze zur Seelsorge aus der Klinikseelsorge und mit der Pilgerbewegung der letzten Jahre.

Umfassendes Ziel der Seelsorge ist es, Menschen in ihrer spezifischen Situation beizustehen:

Träger der Seelsorge ist nach katholischem Verständnis die gesamte Gemeinschaft der Gläubigen. Priester und Diakone sind in der Regel in Gemeinden oder im Pastoralverbund als Seelsorger tätig. Hauptamtliche Seelsorger können auch Männer und Frauen als Pastoralreferenten oder Gemeindereferenten sein, außerdem übernehmen auch Ordensleute seelsorgliche Aufgaben in ihrem Wirkungskreis. Von der gemeindlichen Seelsorge (Territorialseelsorge) ist die Kategorialseelsorge zu unterscheiden, die z. B. in Krankenhäusern, Altenheimen, Schulen und Gefängnissen geleistet wird.
Viele landeskirchliche Seelsorger sind in eigenen landeskirchlichen Seelsorgeinstituten ausgebildet, von denen das „modernste“ von Winkelmann in der Theologischen Schule Bethel bei Bielefeld entwickelt wurde. Die Gründung eines Seelsorgeinstituts in der Kirchlichen Hochschule Bethel mit ausgesprochen moderner Grundlegung kam einer Wende in der theologischen Ausrichtung der Kirchlichen Hochschule Bethel gleich. Denn diese Hochschule hatte noch 1961 eine ausgesprochen pietistische Grundausrichtung entsprechend der Theologie ihres Gründers von Bodelschwingh.

Zunächst Dietrich Stollberg und dann sein Nachfolger Klaus Winkler, die beiden ersten langjährigen Leiter des Seelsorgeinstituts, haben diesem eine psychoanalytische Prägung gegeben, die dazu berechtigt, der psychoanalytischen Seelsorge einen breiteren Raum in der evangelischen Kirche einzuräumen.

Eine große Unterstützung findet diese Richtung psychotherapeutischer Seelsorge seit einigen Jahren durch Professoren der Praktischen Theologie, die an vielen Universitäten durch Lehrveranstaltungen Einführungen in psychotherapeutische Seelsorge geben.

In der evangelikalen Seelsorgepraxis wird versucht, sich inhaltlich an biblischen Lebensordnungen zu orientieren. Der historisch-kritische Standpunkt, wie er in der universitären deutschen Pfarrerausbildung vorherrscht, findet als Grundlage seelsorglichen Handelns in der Regel keine Anwendung. Kam es zunächst zu einer strikten Ablehnung der Psychologie in den evangelikalen Seelsorgeströmungen, so wurde seit den 1980er Jahren zunehmend auf psychotherapeutische Methoden zurückgegriffen. Strittig ist nach wie vor das Verhältnis von Seelsorge und Psychotherapie.
In der Biblisch-Therapeutischen Seelsorge (BTS) beispielsweise ergänzen oder durchdringen sich biblische und psychologische bzw. psychotherapeutische Ansätze. Theologisch fundiert wird eine psychotherapeutische Vorgehensweise z. T. aufgrund der Annahme, dass psychologische bzw. psychotherapeutische Methoden der in der Bibel beschriebenen göttlichen Schöpfungsordnung bzw. Lebensordnung – beispielsweise in Analogie zur alttestamentlichen Weisheitsliteratur – entsprechen und daraus abgeleitet werden können.

Viele Seelsorger aus den evangelischen Landeskirchen wie auch Seelsorger der römisch-katholischen Kirche haben in der Deutschen Gesellschaft für Pastoralpsychologie e. V. (DGfP) ihren organisatorischen Rahmen gefunden. Die DGfP gliedert sich in 6 Sektionen:


Zusätzlich etabliert sich die systemisch integrative Seelsorge (SIS) in den Sparten









</doc>
<doc id="12948" url="https://de.wikipedia.org/wiki?curid=12948" title="Ferruccio Busoni">
Ferruccio Busoni

Ferruccio (Dante Michelangelo Benvenuto) Busoni (* 1. April 1866 in Empoli bei Florenz; † 27. Juli 1924 in Berlin) war ein italienischer Pianist, Komponist, Dirigent, Librettist, Essayist und Musikpädagoge.

Ferruccio Busoni war das einzige Kind eines italienischen Klarinettenvirtuosen und einer deutschstämmigen Pianistin aus Triest. Ferruccio wuchs zweisprachig auf. Mit 10 Jahren gab er sein Debüt als Pianist, Komponist und Improvisator in Wien. 1881 wurde er im Alter von 15 Jahren Mitglied der Accademia Filarmonica in Bologna. Ab 1886 unterrichtete er am Leipziger Konservatorium, ab 1888 war er Klavierlehrer am Konservatorium in Helsinki, wo er zu einem Förderer und Freund von Jean Sibelius wurde. Nach Stationen in Moskau (1890 bis 1891) und Boston (1891 bis 1894) ließ er sich 1894 endgültig in Berlin nieder.

Noch in Moskau heiratete er Gerda Sjöstrand (1862–1956), die Tochter eines schwedischen Bildhauers. Aus der Ehe gingen die beiden Söhne Benvenuto und Rafaello hervor. Während des Ersten Weltkrieges lebte Ferruccio Busoni im Exil in Zürich.

Von 1920 bis zu seinem Tod unterrichtete er an der Berliner Akademie der Künste eine Meisterklasse in Komposition. Ab 1910 bis zu seinem Tod wohnte Busoni in Berlin-Schöneberg am Viktoria-Luise-Platz 11, wo eine Gedenktafel an ihn erinnert. Sein Ehrengrab, welches Georg Kolbe (1877–1947) gestaltete, befindet sich in der Abt. 6-56 auf dem Friedhof in der Stubenrauchstraße in Berlin-Friedenau. In Berlin-Karow wurde 1927 eine Straße nach ihm benannt, die auch heute noch diesen Namen trägt.

Ferruccio Busoni gab u. a. Klavierwerke von Johann Sebastian Bach und Franz Liszt heraus. Der Kritik an seinen zahlreichen Änderungen, Varianten und Erweiterungen erwiderte Busoni, dass er stets den schöpferischen Gedanken für vollkommen halte, nicht aber dessen musikalische oder satztechnische Umsetzung. Als Dirigent lag ihm zeitgenössische Musik am Herzen.

Das Frühwerk Busonis zeigt den romantischen Hintergrund von Komponisten wie Schumann, Chopin und Mendelssohn, später auch Johannes Brahms, dem er zunächst mit respektvoller Distanz begegnete und dessen f-Moll-Sonate er 1884 im Beisein des Kritikers Eduard Hanslick in Wien spielte. Der Einfluss der Händel-Variationen lässt sich in Busonis frühen "Chopin-Variationen op. 22" (BV 213) nachweisen; in dem von Max Reger gelobten "Konzertstück op. 31 a" (BV 236) von 1890 ist Brahms ebenfalls hörbar.

Wie kein anderer Komponist bestimmte hingegen Johann Sebastian Bach die pianistische und kompositorisch-künstlerische Entwicklung Busonis, der später die Gesamtausgabe seines Klavierwerks bei Breitkopf & Härtel betreute und mit Anmerkungen versah. Die Bedeutung Bachs, der ebenfalls eigene und fremde Werke bearbeitete, zeigt sich in der kontrapunktischen Struktur vieler Kompositionen sowie in zahlreichen Transkriptionen. Die Schwierigkeit einiger Bach-Bearbeitungen ist den hohen Anforderungen und Klangvorstellungen Busonis geschuldet, der die Ausgangskompositionen auf das Niveau eines Virtuosen heben wollte. So wurde seine Fantasia contrappuntistica als Versuch gewertet, Bachs vermutlich als Quadrupelfuge konzipiertes Werk „zu Ende zu denken“ und das Klavier dabei „zu vergessen“.

Bereits mit seinen zwischen 1907 und 1909 geschriebenen "Elegien BV 249" zeigt sich ein Neubeginn seiner Entwicklung, was von Busoni selbst so gedeutet wurde, als er angab, in ihnen sein „ganz persönliches Gesicht“ aufgesetzt zu haben. Mit ihrer erweiterten Tonalität und den stellenweise bitonalen Ansätzen gehen sie über die gebräuchliche Funktionsharmonik der Zeit ebenso hinaus wie die "Sonatinen", in denen sich ebenfalls bitonale Strukturen finden.

Seine Rainer Maria Rilke gewidmete, 1907 erstmals erschienene musiktheoretische Schrift "Entwurf einer neuen Ästhetik der Tonkunst" enthält Überlegungen zu neuen Tonskalen, Sechsteltonsystemen und erste Ahnungen der Möglichkeiten elektrisch erzeugter Klänge. Die Veröffentlichung der überarbeiteten Fassung im Jahr 1916 in der Insel-Bücherei (IB 202) löste heftige Kontroversen aus. Der konservative Wagner-Verehrer Hans Pfitzner reagierte 1917 mit seiner polemischen Schrift "Futuristengefahr".


Thematisch-chronologisch geordnet wurden die Werke Ferruccio Busonis von Jürgen Kindermann. Er fasste sie im sogenannten "Kindermannverzeichnis" (KiV) bzw. "Busoni-Verzeichnis" (BV) zusammen.





chronologisch:



</doc>
<doc id="12950" url="https://de.wikipedia.org/wiki?curid=12950" title="Oktavian (Name)">
Oktavian (Name)

Oktavian (von ; , , , , ) ist ein männlicher Vorname. Die weibliche Form ist "Oktavia".

Der Name leitet sich von dem lateinischen Gentilnamen "Octavius" ab, der sich wiederum von dem in vorklassischer Zeit gebräuchlichen Praenomen "Octavus" (lat. für "der achte") ableitet.





</doc>
<doc id="12952" url="https://de.wikipedia.org/wiki?curid=12952" title="Sorbische Sprache">
Sorbische Sprache

Die sorbische Sprache (kurz "Sorbisch", veraltet "Wendisch, Lausitzserbisch", in beiden Standardvarietäten "serbšćina") ist die Gesamtheit der sorbischen Dialekte. Sie gehört zur Gruppe der westslawischen Sprachen und wird vor allem in der Lausitz gesprochen. Es werden zwei Schriftsprachen unterschieden,

An der Grenze der beiden Sprachgebiete existiert eine Reihe von Übergangsdialekten.

Historisch wurde für das Obersorbische und das Niedersorbische ebenso wie für die nordwestlich benachbarten polabischen Sprachen die Bezeichnung Wendisch verwendet. Wendisch ist also eine nicht näher differenzierende Bezeichnung für slawische Sprachen westlich des Polnischen und nördlich des Tschechischen.

Gab es an der Schwelle zum 20. Jahrhundert noch auf dem ganzen Territorium des heutigen sorbischen Siedlungsgebietes auch muttersprachlich sorbische Kinder und Jugendliche, so ist das bedingt durch die von Germanisierungsbestrebungen und wirtschaftlichen Entwicklungen begünstigte Assimilation heute fast nur noch im katholischen Gebiet der Oberlausitz der Fall.

Die Wissenschaft zur Erforschung und Dokumentation der sorbischen Sprache wird als Sorabistik bezeichnet, deren einziges universitäres Institut an der Universität Leipzig beheimatet ist.

Die Geschichte der sorbischen Sprache auf dem Gebiet des heutigen Deutschland beginnt mit der Völkerwanderung etwa seit dem 6. Jahrhundert.

Schon als die heutige Lausitz ins Blickfeld mittelalterlicher Chronisten geriet, war sie von zwei verschiedenen slawischen Völkern bewohnt, von den Milceni im Süden und den Lusici im Norden. Auch nach der Unterwerfung durch Teilstaaten des Heiligen Römischen Reiches standen Ober- und Niederlausitz bis auf weniger als hundert Jahre immer unter verschiedener Hoheit.

Seit dem 12. Jahrhundert, mit dem massenhaften Zuzug von bäuerlichen Siedlern aus Flandern, Sachsen, Thüringen und Franken und der vorangegangenen Verwüstung des Landes durch Kriege, begann der allmähliche Rückgang der sorbischen Sprache. Zudem wurde das Sorbische dem Deutschen rechtlich nachgeordnet, unter anderem im Sachsenspiegel. Später kamen Sprachverbote hinzu: 1293 wurde das „Wendische“ im Bereich des Klosters Nienburg als Gerichtssprache verboten, 1327 in Altenburg, Zwickau und Leipzig, 1424 in Meißen (wobei nur für 1293 die Überlieferung nachvollziehbar ist). Weiterhin gab es in vielen Zünften der Städte des Gebietes die Vorschrift, nur deutschsprachige Mitglieder aufzunehmen.

Das älteste schriftlich überlieferte Sprachdenkmal des Obersorbischen ist der „Burger Eydt Wendisch“, ein Bürgereid der Stadt Bautzen aus dem Jahr 1532. Eine sorbische Literatur entstand erst im Zusammenhang mit der Reformation, die zu ihrer Ausbreitung auf die sorbische Volkssprache angewiesen blieb. In einer in der Pfarrbibliothek von Jauernick verwahrten Handschrift aus dem Jahre 1510 wurde die bislang älteste Niedersorbische Notiz entdeckt. Es handelt sich um eine Randbemerkung zu einem lateinischsprachigen Werk Ovids. Experten des Handschriftenzentrums der Universität Leipzig stellten den sensationellen Fund am 13. Mai 2011 im Archiv des Bistums Görlitz vor. Die Randnotiz, die somit als ältester sorbischer Sprachbeleg gelten dürfte, lautet: "„Ach moyo luba lubka / biß weßola thy sy / my luba“" (übersetzt: „Ach meine liebe Liebste, sei fröhlich, du bist mir lieb“).
Im 13. bis 16. Jahrhundert wurden in mehreren Städten und Gemeinden Sprachverbote erlassen.
Das Kerngebiet der Milzener und Lusitzer, zwei der etwa zwanzig sorbischen Stämme, die im Gebiet der heutigen Lausitz lebten, war von deutschsprachiger Neusiedlung und rechtlichen Beschränkungen nur wenig betroffen. Die Sprache hatte daher dort einen guten Halt. Die Sprecherzahl wuchs dort bis in das 17. Jahrhundert auf über 300.000 an.

Im Zeitalter des Barock regte sich erstmals ein philologisches Interesse an der sorbischen Sprache, das sich in den umfangreichen grammatikalisch-lexikalischen Werken des Niedersorben Johannes Choinan sowie der Obersorben Jurij Hawštyn Swětlik und Xaver Jakub Ticin niederschlug. Einen beträchtlichen Auftrieb erhielt das Sorbische zu Beginn des 18. Jahrhunderts durch die Tätigkeit der evangelischen Wendischen Prediger-Collegien in Leipzig und Wittenberg. Als in Prag das Lausitzer Seminar, ein Konvikt für den katholischen Priesternachwuchs, errichtet wurde, entstand dadurch eine wichtige Verbindung zur tschechischen Sprache und Nationalität. Nach dem Siebenjährigen Krieg sank die Aufmerksamkeit für die sorbische Sprache wieder.

Erst der Einfluss der Romantik brachte einen neuen Aufschwung der literarischen Tätigkeit, und es entstand ein spezifisch sorbisches Nationalbewusstsein. Im 19. Jahrhundert war besonders in Preußen die „Eindeutschungspolitik“ sehr repressiv, obwohl die Sorben 1848 für ihre Königstreue zahlreiche Vergünstigungen erhielten.

1904 wurde in Bautzen unter Beteiligung der offiziellen Stellen das sorbische Kulturhaus eingeweiht. Am 13. Oktober 1912 wurde in Hoyerswerda der Verein Domowina zur Erhaltung der sorbischen Sprache und Kultur gegründet.

Schon in der Weimarer Republik, besonders aber im Deutschen Reich 1933 bis 1945 wurde die sorbische Sprache und Kultur durch Gerichtsurteile, Verbote, Germanisierung und dergleichen unterdrückt. Während der Weimarer Republik gab es eine eigens gegründete „Wendenabteilung“ zur Unterdrückung der sorbischen Sprache und Kultur, 1936 verboten die Nationalsozialisten die Domowina. 1937 wurde sie enteignet. Während des Zweiten Weltkriegs wurden v. a. sorbische Pfarrer und Lehrer als Träger sorbischer Identität ausgesiedelt.

Am 10. Mai 1945 wurde die Domowina wieder gegründet. Zu Zeiten der DDR wurden die sorbische Sprache und Kultur stark gefördert, die Sorben erhielten das Recht auf Zweisprachigkeit (Straßenschilder, Ortsschilder, Sprachunterricht, eigene Zeitungen). Diese Rechte wurden in der Verfassung der DDR in Artikel 40 ausdrücklich, im Einigungsvertrag zur Deutschen Einheit (Einheitsvertrag) von 1990 in Artikel 35 indirekt sowie in den Verfassungen der Bundesländer Brandenburg und Sachsen explizit verankert. Das Gerichtsverfassungsgesetz (GVG) gewährleistet in § 184 das Recht, . Dennoch sank die Zahl der Sorbisch-Sprecher stetig weiter. Nur in wenigen ländlichen Gebieten konnte sich die sorbische Sprache über das 20. Jahrhundert hinaus erhalten. Dies trifft in besonderem Maße auf den katholischen Teil des Siedlungsgebietes entlang des Klosterwassers in der Oberlausitz zu, wo die Assimilation des Sorbischen und damit der Sprachverlust im Gegensatz zum größeren evangelischen Gebiet und der Niederlausitz nur eingeschränkt erfolgte.
Insgesamt leben in Deutschland heute rund 60.000 Sorben, davon etwa 40.000 in Sachsen und 20.000 in Brandenburg. Da die Nationalitätenzugehörigkeit in Deutschland nicht amtlich erfasst wird und das Bekenntnis zur sorbischen Nationalität frei ist, gibt es über die genaue Zahl nur Schätzungen. Die Zahl der aktiven Sprecher des Sorbischen dürfte geringer sein. Anders als das Obersorbische gilt das Niedersorbische als akut vom Aussterben bedroht. Nach Hochrechnungen sprechen etwa 7.000 Menschen aktiv Niedersorbisch, welches bereits in 20 bis 30 Jahren aussterben könnte, und etwa 13.000 Obersorbisch. Nach Ansicht von Sprachexperten wird das Obersorbische das 21. Jahrhundert überdauern.
Heutzutage wird an 25 Grundschulen und mehreren weiterführenden Schulen Sorbisch unterrichtet. Am Niedersorbischen Gymnasium Cottbus und dem Sorbischen Gymnasium Bautzen ist es obligatorisch. An vielen Grundschulen und sorbischen Schulen wird der Unterricht in sorbischer Sprache abgehalten. Es erscheinen die Tageszeitung Serbske Nowiny auf Obersorbisch und die niedersorbische Wochenzeitung Nowy Casnik, außerdem die religiösen Wochenschriften Katolski Posoł und Pomhaj Bóh. Monatlich erscheinen die Kulturzeitschrift Rozhlad, je eine Kinderzeitschrift in ober- und niedersorbischer Sprache (Płomjo bzw. Płomje) sowie die Bildungszeitschrift Serbska šula. Mitteldeutscher Rundfunk und Rundfunk Berlin-Brandenburg senden außerdem monatlich halbstündliche Fernsehmagazine in sorbischer Sprache sowie täglich mehrere Stunden Hörfunkprogramm, den Sorbischen Rundfunk. Wikipedia-Sprachversionen existieren in beiden Schriftsprachen.

Beide sorbischen Standardvarietäten (Schriftsprachen) verfügen nominell über sieben Fälle, wobei der Vokativ nicht voll ausgeprägt ist:

Die Form žona ist im Niedersorbischen literarisch. Die niedersorbische Deklinationsweise ist adjektivisch wegen der Endung -ska.

Im Niedersorbischen ist der Vokativ nur in einigen erstarrten Formen erhalten.

Bemerkenswert ist, dass sich neben Singular und Plural auch der Numerus Dual (die Zweizahl) aus dem Altslawischen erhalten hat.
Singular: ruka („Hand“)
Dual: ruce („zwei Hände“)
Plural: ruki („mehr als zwei Hände“)

Im Gegensatz zu anderen westslawischen Sprachen (Tschechisch, Slowakisch, Polnisch, Kaschubisch) hat sich in der obersorbischen Schriftsprache und einem Teil der Dialekte bis in die heutige Zeit auch das synthetische Präteritum (Aorist, Imperfekt) erhalten. Auch in der niedersorbischen Schriftsprache war diese Form gebräuchlich, ist aber im Laufe des 20. Jahrhunderts immer seltener geworden und wird heute kaum noch verwendet.

Das Niedersorbische hat dafür aber das Supinum (als Variante des Infinitivs nach Verben der Bewegung) erhalten, z. B. „njok spaś“ (ich will nicht schlafen) gegenüber „źi spat“ (geh schlafen).

Nicht allzu anspruchsvolle geschriebene Texte des Sorbischen können von Sprechern der westslawischen Sprachen im Allgemeinen verstanden werden.

Zwischen den beiden Schriftsprachen Obersorbisch und Niedersorbisch bestehen einige Unterschiede, insbesondere auch beim Alphabet.

Die beiden Schriftsprachen unterscheiden sich sehr stark bei den Konsonanten. Der Buchstabe ć wird im Obersorbischen seit 2005 hinter č eingeordnet.

Sowohl das Nieder- als auch das Obersorbische verfügen über acht Vokale.



Bei einigen Wörtern unterscheidet sich die Anzahl der Silben, weil das Obersorbische hier verkürzt hat, ähnlich wie Tschechisch.
















</doc>
<doc id="12955" url="https://de.wikipedia.org/wiki?curid=12955" title="Slawen">
Slawen

Als Slawen wird die nach Bevölkerungszahl größte Gruppe von Ethnien in Europa bezeichnet, die seit dem 6. Jahrhundert vor allem das östliche Mitteleuropa, Osteuropa und Südosteuropa bewohnen. Slawische Sprachen gehören zur indoeuropäischen Sprachfamilie.

Staaten mit slawischen Titularnationen sind:


Große slawische Minderheiten (etwa 15 bis 35 % der Bevölkerung) leben in den ehemals zur Sowjetunion gehörigen Staaten Litauen, Lettland, Estland, Kasachstan und Moldau. In Deutschland und Österreich leben, abgesehen von der großen Bevölkerungsgruppe slawischer Zuwanderer, die autochthonen slawischen Volksgruppen der Sorben in der Lausitz, der Kroaten im Burgenland, der Tschechen und Slowaken in Wien sowie der Slowenen in Kärnten und der Steiermark. Des Weiteren lebt im Norden Polens die slawische Minderheit der Kaschuben und im äußersten Südwesten der Ukraine sowie in der Slowakei die slawische Minderheit der Russinen.

Die slawischen Sprachen bilden eine der Untergruppen der indogermanischen Sprachen und stehen hier den baltischen Sprachen am nächsten, vermutlich über eine (von Manchen bestrittene) vorhergehende balto-slawische Zwischenstufe. Man unterscheidet drei Hauptzweige, das Ostslawische, Westslawische und das Südslawische.

Die zahlreichen gegenseitigen Entlehnungen zwischen Slawisch und Germanisch kennzeichnen die heute noch bestehende lange Nachbarschaft.
Das nichtindogermanische Ungarisch hat die Namen der meisten Wochentage und einige andere Begriffe aus slawischen Sprachen übernommen.

In der lebhaften und noch keineswegs abgeschlossenen Diskussion über den Ursprung der Slawen stehen sich zwei völlig unterschiedliche Forschungsansätze gegenüber. Ausgehend von der Grundannahme, dass die Slawen ein Ursprungsgebiet haben, geht die klassische Auffassung von der Einwanderung einer oder mehrerer homogener „urslawischer“ Gruppen aus, deren Identität und Herkunft sie zu ermitteln sucht („Urheimat“). Dabei sollen nach einem älteren Modell homogene Verbände eingewandert sein, während sich nach einer modifizierten These die slawischen Völkerschaften erst auf der Wanderung oder am Ankunftsort im Rahmen einer Ethnogenese aus den wandernden Protoslawen gebildet haben. Insbesondere Sprachforscher haben als slawische „Urheimat“ einen Raum nördlich der Karpaten zwischen oberer Weichsel, mittlerem Dnepr und Desna vermutet.

Demgegenüber hat der rumänisch-amerikanische Forscher Florin Curta die Behauptung aufgestellt, die Slawen als ethnisch-politische Kategorie seien eine byzantinische Entdeckung in Form einer Fremdbezeichnung, also einer Kategorisierung von außen. Curtas Thesen haben zu einer angeregten Debatte geführt, in der auch lange als sicher geltende Deutungen von archäologischen Kulturen als „slawisch“ neu überdacht werden.

Plinius der Ältere, Tacitus und Ptolemäus von Alexandria erwähnen ab dem 1. Jahrhundert in unterschiedlichen Schreibweisen ein Volk der „Veneter“ "(Venedi / Venethi / Venadi" oder "Ouenedai)", das östlich der Weichsel beziehungsweise an der Danziger Bucht siedelte. Somit wird es – schon geografisch – auch eindeutig von den Venetern des Alpenraumes unterschieden. 

Eine ethnische Kontinuität von Venethi/Venedi und Wenden wird in der modernen Forschung bezweifelt. 

Die Vorbehalte stützen sich auf das späte Auftreten zweifelsfrei den Slawen zuzuordnender Keramik. Diese sogenannte frühslawische Keramik zeichnet sich jedoch im Wesentlichen durch ihre Einfachheit und Unscheinbarkeit aus. Zwischen den älteren Kulturen derselben Region und der frühslawischen Keramik liegen die Hinterlassenschaften des Gotensturms, und die "Getica" des Jordanes berichten von der Unterwerfung der verschiedenen Völker durch die Goten.

Zur Zeit von Kaiser Justinian I. (527–565) gerieten Slawen und Anten dann erstmals in das Blickfeld oströmischer Geschichtsschreiber wie Prokopios von Caesarea, Jordanes, Agathias sowie in der folgenden Zeit Menander Protektor und Theophylaktos Simokates. Sie berichten von zahlreichen Sklavinen (Slawen) und Anten, die aus den Karpaten, der unteren Donau und vom Schwarzen Meer kommend in die Donauprovinzen des Oströmischen Reiches einfielen. 

Prokopios schrieb, dass Anten und Slawen in fast allen Dingen gleich gewesen seien, gleiche Bräuche gehabt und dieselbe Sprache gesprochen hätten. In der modernen Forschung ist aber umstritten, ob die Anten slawischer Herkunft waren; andere Hypothesen gehen unter anderem von iranischer Herkunft aus. 

Das Strategikon des Maurikios stellt Slawen als fähige Schwimmer und Taucher dar, die in Sümpfen und im Gebirge zu Fuß als Guerilla kämpften und Bogenschützen und Speerwerfer stellten.

Jordanes schrieb in der "Getica", "Sclaveni", "Antes" und "Venethi" seien verschiedene Bezeichnungen für dieselbe Gruppe. Laut ihm siedelten die Sclaveni zwischen Weichsel und Donau und die Anten zwischen Dnister und Don.

Die Slawen rückten dabei auch in den Bereichen vor, die im Verlauf der Völkerwanderung von germanischen Gruppen geräumt worden waren.

Manche alte Quellen zeugen von geringer Sachkenntnis. So behauptet eine arabische Quelle, die Slawen hätten keine Landwirtschaft gekannt. Im 10. Jahrhundert schrieb al-Masʿūdī, das Reich der Bulgaren reiche bis in den Bereich der Mitternachtssonne, und das größte slawische Volk seien die Deutschen. Im selben Jahrhundert beschrieb dagegen Ibrahim ibn Jaqub westslawische Gebiete detaillierter als viele mitteleuropäische Autoren derselben Zeit.

Im 19. und 20. Jahrhundert wurde in oft erbitterten und zumeist nationalistisch gefärbten Debatten eine „Urheimat“ der Slawen gesucht, da man sich „Völker“ nur als homogene Einheiten vorstellen konnte. Inzwischen wurde jedoch erkannt, dass die verschiedenen historischen Disziplinen wie Archäologie, Historiographie und Sprachwissenschaft eigene, spezifische Quellen und Aussagemöglichkeiten besitzen, die sich nicht ohne weiteres zu einem Gesamtbild zusammenfügen lassen. Sie alle haben jedoch große methodische Schwierigkeiten, mit Hilfe ihrer Quellen der Ethnogenese näherzukommen. Vor allem polnische und tschechische Wissenschaftler nahmen an, dass die vorgeschichtlichen Slawen mit der Lausitzer Kultur zu identifizieren sind. Deutsch- und englischsprachige Wissenschaftler lehnten diese These überwiegend als spekulativ ab.

Erst mit ihrer Erwähnung in den oströmischen Quellen werden die Slawen als historische Größe greifbar, wobei diese Großgruppe keineswegs als ethnisch homogene Gruppierung aufgetreten sein muss, wenngleich sie von außen als solche gesehen wurde. Neu entstandene Großverbände der Völkerwanderungszeit waren meistens fragil und polyethnisch zusammengesetzt, das heißt, sie setzten sich aus Personen und Gruppen unterschiedlicher Herkunft zusammen, die allein durch den Glauben an eine gemeinsame Ideologie und Kultur sowie eine gemeinsame Abstammung zusammengehalten wurden, sich aber nicht zwangsläufig tatsächlich auch auf eine gemeinsame Kultur und gemeinsame Sprache begründen mussten. Ethnogenese ist ein historischer Prozess, an dessen Ende in diesem Fall das historisch greifbare „Volk“ der Slawen stand. Für die Bildung der slawischen Sprache "(Topogenese)" konnte mit einiger Wahrscheinlichkeit ein Gebiet zwischen mittlerer Weichsel beziehungsweise Bug und mittlerem Dnepr herausgearbeitet werden. Doch nicht allein Wanderungen der Träger dieser Sprache, sondern auch die Assimilation von Menschen verschiedener Herkunft führte zu der „Slawisierung“ Ostmittel- und Osteuropas.

In den folgenden Jahrhunderten besiedelten Slawen auf diese Weise allmählich weite Gebiete Mitteleuropas und Osteuropas, die sich vom Schwarzen und Ägäischen Meer bis zur Ostsee und dem Ilmensee sowie von der Elbe, der Saale, dem Böhmerwald, dem Inn, den Alpen und der Adria bis zum oberen Don und unteren Dnepr erstreckten.

Die große Fülle archäologischer Funde gibt umfangreiche Informationen über materielle Kultur und Lebensweise slawischer Bevölkerung in den verschiedenen Siedlungsperioden. 

Die archäologischen Zeugnisse der frühen Slawen (6.-8. Jhd.) zeigen kaum Unterschiede im gesamten Siedlungsgebiet zwischen Schwarzem Meer und mittlerer Elbe. Die Keramik ist handgeformt und häufig unverziert. Typische Zeugnisse sind Überreste slawischer Burgwälle im vormaligen Siedlungsgebiet.

In der Diskussion über die Klassifikation verschiedener regionaler Gruppen wird immer wieder auf die sehr geringen Unterschiede der materiellen Kultur verwiesen.
Daher wird heute nur noch zwischen regionalen Keramikgruppen unterschieden.

Als früheste archäologische Gruppen werden die Prag-Kortschak-Gruppe (Prager Gruppe, Kortschak-Gruppe, Sukow-Dziedzice-Gruppe) in Ostmitteleuropa und die Penkowka-Gruppe in Südosteuropa unterschieden.

Gegen Ende des 5. Jahrhunderts wurde der mittlere Donauraum (die heutige Slowakei, Ungarn, wohl auch das heutige Südmähren) und in der zweiten Hälfte des 6. Jahrhunderts auch Böhmen besiedelt. Gleichzeitig begannen die Slawen nach dem Abzug der Langobarden, sich von der Donau aus über Pannonien, Noricum und Karnien auszubreiten, und siedelten sich allmählich in den heutigen Gebieten Oberösterreichs nördlich der Donau und Niederösterreich, Steiermark, Kärnten, Krain und Osttirol an. Im 7. Jahrhundert dehnte sich das slawische Siedlungsgebiet bis an Elbe und Saale aus, weiter südlich in die Flussgebiete des oberen Main (bis Ochsenfurt), Regnitz und nördlicher Naab. Vom heutigen Polen war nur der äußerste Nordosten nicht slawisch. Dort siedelten die baltischen Prußen.

Die südlichen Westslawen bildeten um 623, als Reaktion auf die Besetzung Pannoniens durch die Awaren in den 60er-Jahren des 6. Jahrhunderts, das Reich des Samo mit vermutetem Mittelpunkt im südlichen March-Raum.

Im 9. Jahrhundert entstand das Mährerreich als bedeutende Reichsbildung auf dem Gebiet des heutigen Mähren und der Slowakei. Schriftsprache war das kyrillisch geschriebene Altkirchenslawisch. Anfang des 10. Jahrhunderts zerfiel das Reich unter der Invasion der nomadischen Stämme der Ungarn (Magyaren). Nach dem Ende des Mährerreiches traten neue Machtzentren hervor, aus denen sich heutige Staaten entwickelt haben, das Reich der Přemysliden in Böhmen, Grundlage des heutigen Tschechien, und das der Piasten in Polen. Die heutige Slowakei kam Stück für Stück, großenteils bis 1100, unter die Herrschaft der Magyaren und war jahrhundertelang der Norden des Königreichs Ungarn (vgl. Austroslawismus).

 
Seit Mitte des 6. Jahrhunderts drangen westslawische Gruppen in mehreren Einwanderungswellen bis in das Gebiet des heutigen Deutschland vor. Die erste Einwanderungswelle umfasste Stämme des sogenannten Sukow-Szeligi-Typs, die von Osten kommend die Oder überquerten und Stämme der Prager Gruppe, die von Südosten kommend entlang der Elbe bis zur Mündung der Saale vorstießen. Einzelne Gruppen der Prager Kultur erreichten auch das Havelland. Die Träger der Sukow-Szeligi-Kultur hatten sicher Anteil am Entstehen der Obodriten und der Havel-Spree-Stämme. Die sich im Elbgebiet ansiedelnden Slawen der Prager Kultur wurden häufig mit den Sorben gleichgesetzt, was aber umstritten ist. Eine archäologisch untersuchte frühe slawische Siedlung lag auf dem Zoberberg bei Mosigkau.

Ab dem Ende des 6. Jahrhunderts und im Verlauf des 7. Jahrhunderts wanderten die Lausitzer Stämme sowie die Vorläufer der Wilzen ins heutige Ostdeutschland ein. Seit dem 7. Jahrhundert bildeten sich aus den verschiedenen Einwanderern mehrere Stammesverbände heraus, insbesondere die Milzener und Lusitzi in der Lausitz, die Heveller an der Havel im heutigen Brandenburg und die Wilzen/Liutizen in Vorpommern und im nördlichen Brandenburg, sowie die Abodriten in Mecklenburg. Etwas isoliert lebten auf Rügen und auf dem angrenzenden Festland die Ruganen. Noch weiter westlich siedelten die Wagrier (Waigri) im östlichen Holstein (bis zur Schwentine an der Kieler Förde) und die Drewaner im Lüneburgischen. Die slawischen Verbände in Nordostdeutschland werden von der Forschung unter dem Begriff Wenden, Polaben oder Elbslawen zusammengefasst.

Der westlichste bekannte Fürstensitz war das wagrische Aldinburg (slaw. "Starigard" = Alte Burg) an der Ostsee, das heutige Oldenburg in Holstein (heute noch große sichtbare Wallanlage und Wall-Museum), zugleich wichtiger Handelsplatz für den Ostseehandel mit Beziehung zum sächsischen Hamburg und zur wikingischen Siedlung Haithabu. Die nachbarschaftlichen Beziehungen im Norden Deutschlands waren nicht immer friedlich. So gab es im 9. und 10. Jahrhundert mehrfach Überfälle auf Hamburg, 1066 wurde Haithabu von den Slawen geplündert, im 11. Jh. die slawische Handelsstadt Vineta vernichtet.

Unter Kaiser Otto I. begann die Christianisierung der Nordwestslawen über die Erzbistümer Magdeburg und Hamburg. Bistümer entstanden in Oldenburg, Merseburg, Meißen, Zeitz (1028 verlegt nach Naumburg (Saale)), Brandenburg und Havelberg.

Nachdem Rethra als religiöses Zentrum der nördlichen Westslawen im Winter 1068/69 zerstört worden war, übernahm die Tempelburg am Kap Arkona auf der Insel Rügen dessen Rang, bis auch dieses letzte bedeutende Heiligtum im Jahre 1168 durch die mit Heinrich dem Löwen verbündeten christlichen Dänen unter Waldemar I. zerstört wurde.

Im Mittelalter nach dem Beginn des 13. Jahrhunderts zogen sehr viele Deutsche in diese nach zwei kriegerischen Jahrhunderten (Slawenaufstand, Wendenkreuzzug) nur noch dünn besiedelten Gebiete, und die Slawen gingen in den Deutschen auf (Ostsiedlung in der Germania Slavica). Obwohl hierdurch die slawische Sprache in diesen Gebieten am Ende des 16. Jahrhunderts, außer in der Lausitz, überwiegend ausstarb, haben sich viele slawische Orts- und Familiennamen bis heute erhalten (zum Beispiel Buckow = Buche bzw. Kretzschmer = Krüger), wobei manche der „slawischen“ Orts-, Flur- und Gewässernamen wiederum aus älteren germanischen Bezeichnungen entstanden sind (z. B. Spree = die Sprühende).

Im heutigen Polen lebten mehrere Stämme. Das Land zu beiden Seiten der Weichsel bis etwa an die Wipper hin bewohnte der Stamm der Polanen (Feldbewohner) bzw. Lechen, die im 10. Jahrhundert den Kern des entstehenden Staates Polen bildeten und sich mit den Masowiern und anderen kleineren Stämmen zusammenschlossen. Hauptstadt des durch den Fürsten Mieszko I. gegründeten Staates war Gnesen. Die zwischen Wippermündung und Oder nahe der Ostsee wohnenden Slawen wurden Pomoranen genannt, von "po morju" („am Meer“).

Der genaue Zeitpunkt und der Prozess der Besiedelung ostslawischer Stämme ist unklar.

Für die Zeit ab dem 9. Jahrhundert sind folgende Gruppen erwähnt:


Die Ostslawen waren zunächst Heiden und hatten ein Pantheon an Göttern, unter denen der Donnergott Perun eine herausragende Stellung hatte. 

Den Weg von den Warägern zu den Griechen über das osteuropäische Flusssystem nutzend, bereisten wikingische Händler, Siedler und Krieger das ostslawische Gebiet, das sie wegen seiner zahlreichen Burgen und Städte Gardarike nannten. Diese Waräger oder Rus genannten Menschen einten die gesamte Region der heutigen Nordukraine, Weißrussland und Westrussland gegen Ende des 9. Jahrhunderts zum ersten ostslawischen Reich, der Kiewer Rus (ab 988 christlich). 

Im Spätmittelalter spalteten sich die Ostslawen in Weißrussen, Ukrainer und Russen auf, letztere breiteten sich seit dem späten 16. Jahrhundert und verstärkt im 19. und 20. Jahrhundert entlang der Transsibirischen Eisenbahn bis zum Pazifik aus.

In der ausgehenden Spätantike, im 6. Jahrhundert, rückten die Slawen über die untere (im 5. Jahrhundert von den Westgoten verlassene) Donau nach Moesia, Thrakien, Illyrien, Makedonien und bis zur Peloponnes vor. Der Kirchenhistoriker Johannes von Ephesos berichtet von einer großen slawischen Invasion seit 581, die erstmals eine dauerhafte Niederlassung zum Ziel gehabt habe. Tatsächlich begannen sich bald darauf die Slawen auf dem Balkan anzusiedeln, was jedoch durch die Balkanfeldzüge des Maurikios beinahe zur Episode wurde. Im 7. Jahrhundert vollzog sich der größte Teil der Landnahme der Slawen auf dem Balkan (siehe auch "Sklavinien"), was jedoch nicht zur völligen Beseitigung der ursprünglichen Bevölkerung führte. Die genauen Prozesse der slawischen „Landnahme“ sind hierbei Gegenstand angeregter wissenschaftlicher Diskussionen, in die auch politische und nationale Motive einfließen. Als Beispiel sei hier nur die überholte These von Fallmerayer genannt, wonach es sich bei dem modernen Griechen ausschließlich um hellenisierte Slawen handele.

Ab der Mitte des 6. Jahrhunderts siedelten Slawen auch im Ostalpenraum. Die Wanderung der Langobarden nach Italien (568) begünstigte die Besiedlung großer Teile Pannoniens durch Slawen. Um 600 kämpften Alpenslawen, Vorfahren der heutigen Slowenen, gegen Bajuwaren an der oberen Drau und stießen bis Italien vor. Ihre Ausbreitung wurde mit einer Kette langobardischer Festungen "(Limes Langobardorum)" entlang des Ostrandes von Friaul aufgehalten.

Laut dem byzantinischen Kaiser Konstantin VII. drangen die Kroaten und Serben in der ersten Hälfte des 7. Jahrhunderts über die Donau und siedelten sich nach Vertreibung der Awaren in Pannonien, Dalmatia und im übrigen Illyricum an.

In der 2. Hälfte des 7. Jahrhunderts kam ein Teil der Protobulgaren auf der östlichen Balkanhalbinsel an und gründete dort 681 das Bulgarische Reich, wobei sich das asiatische Reitervolk sehr schnell mit der ursprünglichen slawischen Bevölkerung vermischte und das heutige slawische Volk der Bulgaren bildete.

Ende des 7. Jahrhunderts waren die großen westlichen und südlichen Wanderungen der Slawen abgeschlossen.

Als geschichtliches Volk erscheinen die Slawen zuerst unter dem Namen der Serben (Sporen) und der Veneter, sie waren unter diesem Namen bis ins 5. Jahrhundert in den Ländern zwischen Ostsee und dem Schwarzen Meer ansässig, zwischen den Karpaten und dem Don, von der oberen Wolga bis nach Nowgorod und von dort bis zur Scheide der Weichsel und der Oder. Etwa mit dem 6. Jahrhundert treten die Namen Anten (für die Ostslawen, obwohl das historische Volk der Anten vielleicht gar nicht slawisch war) und (für manche Westslawen) "Slověne" (siehe oben unter Ausbreitung der heutigen Westslawen) auf. Beide erhielten sich aber als Bezeichnung der Gesamtheit nicht lange, und der Name Serben verengte sich bis zur Benennung einzelner slawischer Stämme. Aus der Bezeichnung Veneter aber wurde Wenden, die Bezeichnung der Slawen bei den Deutschen (für die heutigen Sorben). Die Bezeichnung "Slawen" ist zumindest seit dem frühen Mittelalter üblich, Adam von Bremen bezeichnet sie in seiner Chronik des Erzbistums Hamburg als "Sclavi".

Neben anderen Slawisten schreibt auch der sorbische Gelehrte Heinz Schuster-Šewc in seiner Abhandlung über die Geschichte und Geographie des ethnischen Namens "Sorb/Serb/Sarb/Srb", wonach sich der serbische Name aus dem urslawischen "*sĭrb-" „schlürfen“ ableiten soll, vgl. altostslawisch "sereblju", litauisch "srebiù", albanisch "gjerb", lateinisch "sorbeō", altgriechisch "rhophéō" „schlürfen“, armenisch "arbi" „trank“, hethitisch "sarāpi" „nippt“ (vorausgesetzte urindogermanische Wurzel "*srebʰ-" „schlürfen“ nach LIV). Die semantische Entwicklung fand sich dann weiter in "Srb" für Brüder und Schwestern nach der Muttermilch, also die von derselben Mutter gesäugt wurden, ohne unbedingt blutsverwandt gewesen zu sein. Daraus folgte die Bezeichnung für Angehörige derselben Familie oder Sippe und später für Angehörige desselben Stammes. Andere wollen den serbischen Namen mit den antiken Sarmaten in Verbindung bringen. Der tschechisch-slowakische Slawist Pavol Jozef Šafárik (1795–1861) wie auch Gottfried Wilhelm von Leibniz (1646–1716) vertraten die Meinung, wonach "Srb" ursprünglich der Eigenname aller Slawen gewesen sei. Jedenfalls stand der serbisch-sorbische Name mit dem historischen Auftreten sowohl der Serben wie auch der Sorben im 7. Jahrhundert für Stammesangehörige, Verwandte, Verbündete.

Die Bedeutung der in den byzantinischen Quellen genannten Begriffe der Veneter, Sklavinen, Sporen und Anten ist umstritten, doch dürfte es sich weniger um ethnische als vielmehr um politische oder geographische Bezeichnungen handeln. Lediglich der Name der Slawen "(sklabenoi, sklaboi)" stellt in heutiger Zeit eine Selbstbezeichnung dar. Die ebenfalls gebrauchten Namen der Wenden/Veneter und Anten sind dagegen ursprünglich von Germanen beziehungsweise Awaren für die Slawen verwendete Bezeichnungen.

Der Ursprung des Namens "Slawen" ist in der sprachwissenschaftlichen Forschung noch ungeklärt. Im Allgemeinen wird angenommen, dass er entweder vom gemeinslawischen *слŏвŏ (heute "slóvo") „Wort“ abgeleitet wird, womit sich die Sprechenden oder Beredeten selbst von den „Stummen“ "(némec)" abgrenzten, wobei das Wort "Némec" sich zur Bezeichnung für die Deutschen entwickelt hat. Als von Seiten romanischer Historiker im Barock Slawen, ohne sich intensiver mit ihrer Geschichte auseinandergesetzt zu haben, als Barbaren und unkultivierte Völker allgemein als vergleichsweise minderwertige Völker beschrieben wurden, mit der die vermeintliche etymologische Herkunft der Eigenbezeichnung aus dem lateinischen "sclavus" gerechtfertigt wurde, entwickelte sich in Gegenreaktion unter einer großen Zahl gelehrter slawischer Humanisten die Ausarbeitung eigener Historien, in denen sie den Volksnamen auf "slawa" (dt. „Ruhm“) zurückführten und dies ebenso klar ausformulierten und publizierten.

Die Familienverfassung war eine patriarchalische. Die Einwohner eines Ortes bildeten eine durch Blutsverwandtschaft verknüpfte Sippe "(obschtina, rod)", deren Mitglieder einen gemeinsamen Namen trugen, gemeinschaftliches Gut besaßen und unter einem gewählten Ältesten standen. Aus mehreren solcher Sippen bildete sich der Stamm "(pleme)", an dessen Spitze das Stammesoberhaupt, der Anführer im Krieg, stand. Die Stämme ihrerseits vereinigten sich wieder zu einem größeren Ganzen, zu Einzelvölkern "(narod)".

Die Ehe wurde heilig gehalten, es herrschte ursprünglich Monogamie. Noch vor der Abtrennung in einzelne Zweige hatten die Slawen durch Herkommen befestigte Rechtsnormen "(pravo, zakon)"; der Begriff „erben“ fehlte jedoch, da die Familienverfassung Erbschaften ausschloss.

Kultur- und Sittengeschichte des Gesamtvolkes: Nach den griechischen und deutschen Schriftstellern waren die alten Slawen ein friedliebendes und fleißiges Volk, fest am Althergebrachten hängend, leidenschaftlich Ackerbau und Viehzucht und auch, wie aus der Sprache und aus den archäologischen Funden hervorgeht, Handel treibend. Gerühmt wird auch ihre Gastfreundschaft. Kranke und Arme fanden sorgfältige Pflege, nur der Böse wurde ausgestoßen, und "chud" bedeutet in slawischer Sprache zugleich arm und böse. Vielweiberei war gestattet, wurde aber fast nur von den Vornehmen geübt.

Der Grundzug der Zivil- und Staatsverfassung war demokratisch; man kannte ursprünglich keine Stände, keine erbliche Fürstenwürde (siehe auch: Wetsche). Das Band der Sippeneinheit hielt alle umschlungen, und der "Starosta" (Älteste) war nur Verwalter des Gesamtvermögens der Sippe. Die Einheit der Sippe schloss die Erbfolge aus. Hierdurch unterschieden sich die Slawen wesentlich von den Germanen und Romanen. Standesunterschiede, erbliche Fürstenmacht, Leibeigenschaft und Sklaverei bildeten sich infolge fremder Einflüsse erst später bei den Slawen aus. Die Bezeichnungen für die Fürstenmacht "(knez, kralj, chrabia, cjesar)" und den Adel "(szlachta, Geschlecht)" sind fremden Ursprungs.

Die Slawen werden als sehr gesangliebend geschildert. Seele und Gemüt offenbaren sich bei ihnen in anmutigen Liedern und Gesängen. Von den mythischen Vorstellungen und der darin sich kundgebenden Weltanschauung der alten Slawen lässt sich kein deutliches und konsistentes Gesamtbild zeichnen, da eine zusammenhängende Überlieferung fehlt.

Die ursprüngliche Religion der Slawen war derjenigen anderer früher indogermanischer Völker ähnlich. In den Naturerscheinungen, besonders den Phänomenen des Himmels, sahen die Slawen wirkliche Wesen, die sie sich mit Denken und Empfinden ausgestattet vorstellten, einige wohltätig, andere zerstörend wirkend. Die ersteren wurden von den Slawen "bog", die letzteren "Bjes" genannt, und das Christentum übernahm diese Wörter teils für Gott und Teufel.

Sie verehrten einen höchsten Gott, den Urheber des Himmels und der Erde, des Lichts und des Gewitters. Diesem waren die anderen Götter untertan. Der Name dieses Gottes war Svarog (der "Schöpfer"), als Urheber des Donners heißt er Perun (balt. "Perkunas"). Seine Söhne waren die Sonne und das Feuer. Der Sonnengott (Daschbog, „Geber der Güter“) war auch Kriegsgott, als Theomorphose der Luft erscheint Sventovit oder Svantovit (nach Miklosich nur Sanctus Vitus), als Gott des Sturms Stribog.

Oberste Gottheit der westslawischen Wenden war Radegast, der ebenfalls als Kriegsgott verehrt wurde. Als Frühlingsgöttinnen erscheinen Wesna (Frühling) und Deva (oder Diva, wunderschöne Schönheit), als Göttin der Liebe und Schönheit Lada. Unter den bösen Gottheiten steht die Repräsentantin des Winters (Moraua) obenan.

Ein eigentlicher Dualismus bestand aber nicht, und was bei einigen Schriftstellern von einem Kampf zwischen den Göttern des Lichts und der Finsternis (dem Bjelbog und Tschernebog der Nordslawen) berichtet wird, scheint bereits auf christlichen Einfluss hinzuweisen.

Als mythische Wesen niederen Grades wurden verehrt: die Vílen und Rusálka, die Herrscherinnen über Flüsse, Wälder und Berge, welche in der Volkspoesie der Slawen bis auf den heutigen Tag "(1888)" eine große Rolle spielen; ferner die Rojenitze oder Schicksalsgöttinnen sowie zahlreiche Haus- und Feldgeister und die finsteren Mächte Baba Jaga (Hexe, altes verrücktes Weib), Bjes und Vjed, welch letzterem die Sonnen- und Mondfinsternisse zugeschrieben wurden.

Die Gunst der Götter und deren Schutz suchten die Slawen durch Gebet und Opfer zu erlangen. Letztere bestanden im Verbrennen von Rindern und Schafen auf Bergen und in Hainen, wo sich auch Götterbilder befanden. Menschenopfer kamen nur vereinzelt vor. Vollstrecker der Opfer waren die Stammesältesten. Einen Priesterstand kannten die alten Slawen ebenso wenig wie besondere Tempel. Von Festen sind jene zu erwähnen, die sich an den Wechsel der Jahreszeiten anknüpfen: die Wintersonnenwende (koleda, ovsen, kratshun), der Frühlingsanfang mit Austragung des Winters und die Sommersonnenwende (kapalo, jarilo). 

Mit dem leiblichen Tod hörte nach slawischer Auffassung das Leben nicht auf, vielmehr war die Seele "(dusza)" unsterblich. Sie gelangte ins Paradies "(nav, ráj)", das als schöne Wiese gedacht wurde. Die Leichen wurden entweder verbrannt oder begraben, beide Bestattungsweisen kommen nebeneinander vor. Schätzenswerte Untersuchungen über die alte Kultur und mythologische Vorstellungen der Slawen, soweit sie sich im Aberglauben, in Sagen und Märchen des Volkes erhalten haben, enthält Alexander Afanassjews Werk "Die poetischen Naturanschauungen der Slawen".

Die slawische Keramik war im 7. Jahrhundert in Mitteleuropa weit verbreitet. Die Slawen setzten kaum auf die Viehzucht, sondern auf den Getreideanbau. Auf zwei Dritteln einer Feldgemarkung wurden jeweils Roggen, Weizen, Gerste, Hafer und Hirse angebaut. Das Getreide wurde mit Sicheln gemäht. Später kam auch die Sense zum Einsatz. Die Häuser wurden leicht eingetieft auf einer Fläche von 16 bis 30 Quadratmetern gebaut.

Um 700 wurde die slawische Burgwallanlage in Spandow, dem heutigen Bezirk Spandau erstellt. Die Dörfer waren rund oder in einem Halbkreis angelegt. Im Schutze einer Burg konnte eine größere Siedlung angelegt werden, die zu einer Stadt heranwuchs. Dort wurden spezielle Handwerkszweige entwickelt, Lebensmittel auf Vorrat gehalten, Fernhandel betrieben und kulturelle Bauten erstellt. Die Häuser wurden mit Holzpalisaden und Holzerdemauern befestigt.

Besonders im gewässerreichen nordöstlichen Mitteleuropa bauten die Slawen beachtliche Holzbrücken, darunter vier über die mittlere Havel und eine 2 km lange über den Oberuckersee.

Detailgetreue Rekonstruktionen der Wohn- und Lebensweise der Slawen des 9. und 10. Jahrhunderts findet man in Deutschland beispielsweise im Freilichtmuseum Ukranenland in Torgelow (Vorpommern), im Archäologischen Freilichtmuseum Groß Raden (Mecklenburg) und im Geschichtspark Bärnau-Tachov (Bayern).

Die Slawen errichteten ihre Siedlungen an strategisch vorteilhaften Lagen, oft von Seen umgeben. Typisch sind hier die Städte Lychen, Feldberg und Penkun.
Ihre Burgen wurden oft auf Inseln oder in Sumpfgebieten angelegt und waren daher nur schwer zu erobern. Der einzige Zugang zu diesen bestand aus Holzbohlen und konnte bei Gefahr aufgenommen werden, daher auch die Redewendung „auf dem Holzweg sein“. Seltener waren Höhenburgen, typisch dafür ist die Burg Stargard („Altenburg“).




</doc>
<doc id="12956" url="https://de.wikipedia.org/wiki?curid=12956" title="Hygrometer">
Hygrometer

Das Hygrometer (von "hygrós" ‚feucht‘, ‚nass‘ und "métron" ‚Maß‘, ‚Maßstab‘) ist ein Messinstrument zur Bestimmung der Luftfeuchtigkeit. Mit der Lufttemperatur kann man aus der Luftfeuchtigkeit den Wasserdampfgehalt der Luft bestimmen.

Hygrometer werden zur Messung der Luftfeuchtigkeit eingesetzt. Je nach Geräteausführung lassen sich dabei die verschiedenen Feuchtemaße bestimmen.

Absorptionshygrometer enthalten ein hygroskopisches (wasseranziehendes) Material, dessen Eigenschaften sich durch die Feuchtigkeit ändern. Am bekanntesten ist das Haarhygrometer. Es enthält ein meist menschliches Haar, das sich bei Feuchtigkeit ausdehnt. Der Längenunterschied bei völlig trockener Luft (0 % relative Luftfeuchte (rF)) und gesättigter Luft (100 % rF) beträgt dabei etwa 2,5 %. Früher kamen dabei verschiedene Naturhaare von Menschen, Schafen oder Pferden zur Anwendung, heute werden nur noch menschliche Haare und Kunstfasern (Synthetikfasern) eingesetzt. Die traditionellen Wetterhäuschen sind im Prinzip ebenso Haarhygrometer.

Bei preiswerten Hygrometern werden zum Teil auch mit Kunststoffen beschichtete, aufgerollte Metallstreifen verwendet, die ebenfalls mit einer Längenausdehnung reagieren (ähnlich Bimetallthermometern). Diese so genannten Spiralhygrometer sind jedoch meist nicht so präzise wie Haarhygrometer.

Eine andere Möglichkeit ist die Messung der Gewichtszunahme bei der Einlagerung von Wasser. Moderne elektronische Absorptionshygrometer dagegen basieren auf der Veränderung der elektrischen Eigenschaften eines Sensors:


Psychrometer bestehen aus zwei gleichartigen Thermometern, wobei das Quecksilbergefäß bzw. der Temperatursensor des einen mit einem kontinuierlich befeuchteten Mullstrumpf überzogen ist. Dem "feuchten" Thermometer wird durch Verdunstung Wärme entzogen, und es zeigt infolgedessen eine niedrigere Temperatur als das "trockene" Thermometer an. Die Temperaturdifferenz zwischen beiden Thermometern ist ein Maß für die relative Feuchte. Mithilfe der Sprung'schen Formel lassen sich damit alle relevanten Feuchte-Maße berechnen. Anhand grafischer Psychrometertafeln lässt sich die relative Luftfeuchtigkeit auch direkt ohne Rechnung vor Ort bestimmen.
In der Regel unterscheidet man zwischen mechanisch arbeitenden (Aspirationspsychrometer, Schleuderpsychrometer) und elektronischen Geräten. Die theoretische Grundlage für das Gerät liefert die Mischungstheorie nach Dr. Sonntag. Dabei wird davon ausgegangen, dass beide Thermometer kontinuierlich mit ca. 3 m/s belüftet werden. Wenige Psychrometer arbeiten auch heute noch nach der Diffusionstheorie, die voraussetzt, dass am Thermometergefäß keine Belüftung stattfindet.

Die Bestimmung des Taupunkts ist ein fundamentales, vergleichsweise leicht verständliches und präzises Messverfahren. Es wird heute als das präziseste Verfahren zur Definition der nationalen Feuchtestandards eingesetzt. Bei dem Taupunktspiegelhygrometer wird ein Spiegel soweit abgekühlt, bis sich die Luftfeuchtigkeit auf ihm niederschlägt. Mit einer Lichtquelle und einem Photosensor wird der Moment der Kondensation bestimmt. Der Taupunkt versteht sich immer als Wertepaar aus Taupunkt-Temperatur und zugehörigem Druck (Druck der zum Messzeitpunkt herrschte), daher lässt sich der Taupunkt ohne Weiteres einfach in absolute Feuchte umrechnen. Lediglich zur Umrechnung in relative Feuchtewerte benötigt man zusätzlich noch die Temperatur der Probe zum Zeitpunkt der Taupunktmessung.




Daneben gibt es noch eine Reihe weiterer Möglichkeiten, die Luftfeuchtigkeit zu bestimmen, die aber vergleichsweise selten angewendet werden, beispielsweise das "Resistive Verfahren" (Bestimmung der Impedanz des Wechselstromwiderstandes eines hygroskopischen Elementes), das "Lithiumchlorid-Taupunkthygrometer" (Messverfahren, das auf der hygroskopischen Eigenschaft des Lithiumchlorids beruht) oder die Messung der "Neutronenbremsung" (Neutronen werden beim Auftreffen auf Wasserstoffkerne langsamer). Alle Verfahren haben ihre Vor- und Nachteile, das optimale Hygrometer für alle Anwendungen gibt es nicht.

Zur Bestimmung der Bodenfeuchte kommen besondere Verfahren zum Einsatz. Eine besondere Problematik dieser Bestimmung resultiert aus dem Gehalt des Bodens an verschiedenen Salzen, welche die meisten Messverfahren beeinträchtigen können und häufig auch korrosiv auf Sensoren wirken.




Das Kalibrieren und das Justieren sind ähnliche, aber nicht identische Vorgänge. Ziel des Justierens ist es eine Geräteeinstellung mit minimalem Anzeigefehler zu erhalten. Über Abweichungen der Messergebnisse (Soll- zu Ist-Wert) sagt eine Justage allerdings nichts aus, das ist Aufgabe der Kalibrierung. Ziel des Kalibrierens ist die Erstellung eines Protokolls (Kalibrierschein oder Kalibrierzertifikat), in diesem Protokoll wird die Anzeigeabweichung zu einem Normal höherer Ordnung (Soll- zu Ist-Wert) dokumentiert – am Gerät werden beim Kalibrieren keine Veränderungen (oder Justierungen) durchgeführt, siehe hierzu Kalibrieren im Vergleich zu Justieren





Zu den üblichen Wartungs- und Justierarbeiten bei Haarhygrometern gehört die Regeneration. Da diese Hygrometer auf Naturfasern beruhen, die durch zu langes Austrocknen ihre Funktion verlieren können, wirkt man diesem Effekt durch eine gelegentliche Regeneration entgegen. Bereits inaktiv gewordene Instrumente können so wieder reaktiviert werden. Dazu wird das Gerät etwa eine Stunde lang in ein feuchtes Tuch gehüllt oder aber das Messelement, falls direkt zugänglich, mit destilliertem Wasser befeuchtet. Danach sollte das Gerät etwa 94–98 % relative Feuchte anzeigen. Falls dieser Wert nicht angezeigt wird, muss auf diesen Wert justiert werden. Hierzu besitzen Haarhygrometer eine Einstellschraube, die eine Justierung ermöglicht.

Bereits im Mittelalter wurden unterschiedliche Verfahren zur Messung genutzt, die allerdings nur unzureichende Ergebnisse lieferten. Noch heute werden in Südfrankreich die Blütenstände getrockneter Korbblütler (Asteraceae), wie beispielsweise die Akanthusblättrige Eberwurz, zur Vorhersage von regnerischem Wetter genutzt. Eine Erläuterung findet sich hier.

Das erste Haarhygrometer wurde 1783 von Horace-Bénédict de Saussure demonstriert. Er benutzte dazu ein blondes Frauenhaar. Um 1820 gelang John Frederic Daniell die Messung der Luftfeuchtigkeit über den Taupunkt, 1877 erhielt der Astronom Wilhelm Klinkerfues ein Patent für ein Bifilar-Hygrometer mit zwei parallel gespannten Menschenhaaren, 1887 konstruierte Richard Aßmann das erste Psychrometer.



</doc>
<doc id="12958" url="https://de.wikipedia.org/wiki?curid=12958" title="Allel">
Allel

Als Allele (von gr. αλλήλων "allélon" „einander, gegenseitig“) bezeichnet man verschiedene Zustandsformen eines Gens an einem bestimmten Genlocus eines Chromosoms.

Varianten eines Gens mit jeweils gleichem Genlocus auf homologen Chromosomen können sich in einzelnen Positionen der Nukleotidsequenz unterscheiden. Diese Unterschiede entstehen durch Mutation.
Ihr Auftreten in der Population einer Art und das paarweise Vorkommen im diploiden Chromosomensatz ist die Voraussetzung für die Mendelsche Spaltungsregel. Sind die beiden Allele identisch, nennt man den Organismus "homozygot" bezüglich dieses Gens, sind sie verschieden, spricht man von "Heterozygotie".

William Bateson verteidigte in seiner Schrift "Mendel's Principles of Heredity" von 1902 die Annahme Mendels, dass es zwei Varianten der Erbfaktoren in jeder diploiden Zelle gebe. Er nannte die Kopie des Erbfaktors nach dem griechischen Wort für „Andere“ "Allelomorph". Dieser Begriff wurde später zu "Allel" verkürzt.

Durch geringfügige Variationen in der Basensequenz der DNA entstehen verschiedene Ausprägungsformen (Allele) von Genen. So kann es zum Beispiel für ein Gen, das für die Farbe einer Blüte verantwortlich ist, zwei verschiedene Allele geben, die bei der Pflanze entweder eine rote oder eine weiße Blütenfarbe hervorrufen. Entsprechend spricht man vom Allel für die rote oder vom Allel für die weiße Blütenfarbe. Im Genpool einer Population können mehr als zwei unterschiedliche Zustandsformen eines Gens vorkommen, das heißt, mehr als zwei Allele treten an einem Genort auf. Man spricht dann von "multipler Allelie". Die Allele eines Genortes werden nach dem Phänotyp benannt, den sie hervorrufen. Dabei wird ein Wildtyp-Allel durch ein zusätzliches „+“ gekennzeichnet.

Da Menschen einen doppelten Chromosomensatz haben, kann jeder Mensch in seinen diploiden Zellen auf den beiden homologen Chromosomen am betreffenden Genort entweder zwei unterschiedliche Allele eines Gens (Heterozygotie) besitzen oder aber zwei gleiche Allele des betreffenden Gens (Homozygotie). Dies gilt auch für alle anderen diploiden Lebewesen.

Bei der japanischen Wunderblume verhalten sich die beiden Allele für die Ausprägung der Blütenfarbe intermediär. Daher können drei verschiedene Typen der Blütenfarbe auftreten: Besitzt die Pflanze zwei identische Allele für die rote Blütenfarbe (homozygoter Zustand), dann entsteht eine rote Blüte. Besitzt die Pflanze zwei identische Allele für die weiße Blütenfarbe (ebenfalls homozygoter Zustand), entsteht eine weiße Blüte. Sind jedoch zwei verschiedene Allele vorhanden, nämlich eines für die rote und eines für die weiße Blütenfarbe (heterozygoter Zustand), kommt es zu einer rosa Blüte (intermediärer Erbgang).

In der Regel dominiert im heterozygoten Zustand ein Allel über das andere. Das Allel, das die Ausprägung des Merkmals im Phänotyp bestimmt, wird "dominant" genannt, während das andere Allel "rezessiv" genannt wird.

Von Kodominanz spricht man, wenn zwei verschiedene Allele gleichwertig nebeneinander die Ausprägung eines Merkmals bestimmen.





</doc>
<doc id="12959" url="https://de.wikipedia.org/wiki?curid=12959" title="Lilongwe">
Lilongwe

Lilongwe ist die Hauptstadt von Malawi und der Central Region in Malawi. Sie hat rund 674.000 Einwohner (Stand 2008), wobei die Bevölkerung schnell wächst. Lilongwe ist durch große Grundstücke und breite, parkähnliche Boulevards geprägt. Die Stadt ist das Ergebnis weitgreifender Stadtplanung und ist in eine Alt- sowie eine durch viele Bautätigkeiten sich ständig entwickelnde Neustadt unterteilt. Die Stadtteile liegen zum Teil weit auseinander.

Lilongwe liegt im Südwesten des Landes, 100 Kilometer westlich des Malawisees und rund 60 Kilometer östlich der Grenze zu Mosambik und Sambia, auf einer Hochebene am Lilongwe-Fluss. Die Stadt liegt rund 1050 Meter über dem Meeresspiegel und ist zugleich auch Hauptstadt der Central Region, einer der drei großen Verwaltungsregionen des Landes.

Die Stadt wurde 1947 als Handelszentrum gegründet. Nach der Unabhängigkeit Malawis 1964 konnte Präsident Kamuzu Banda die internationale Gebergemeinschaft von der Notwendigkeit einer zentralen Hauptstadt überzeugen, um dem Nord-Süd-Gefälle in Malawi entgegenzuwirken. So wurde Lilongwe zum Regierungssitz erklärt. Die Stadt entstand weitgehend auf dem Reißbrett.
Seit 1994 ist Lilongwe auch Sitz des malawischen Parlaments, das bis dahin noch in Zomba tagte. 2010 wurde das neue Parlamentsgebäude eingeweiht, das mit chinesischer Hilfe erbaut wurde. Deutschland, Frankreich, die USA, Mosambik, das Vereinigte Königreich und Sambia unterhalten Botschaften in der Stadt. Zudem haben die meisten in Malawi tätigen Nichtregierungsorganisationen und andere internationalen Organisationen, wie die GIZ, ihre Vertretungen in Lilongwe.

Der Markt auf der Malangalanga Road ist sehr lebhaft. In der Altstadt gibt es indische Geschäfte. In der Nähe befindet sich Salanjama, ein Gebiet mit zahlreichen Vogelarten. An den oberen Hängen zum Lilongwetal befinden sich Areale mit dichtem Regenwald und Büschen der Protea. Eine weitere Touristenattraktion sind die Tabakauktionen. Zwischen der Altstadt und dem neuen Zentrum befindet sich ein Tierpark, in dem gelegentlich auch Hyänen und Krokodile leben.

Lilongwe ist das Verwaltungszentrum des Landes. Mit der wirtschaftlichen Dynamik der Stadt Blantyre (547.500 Einwohner) kann es nicht konkurrieren. In begrenztem Maße ist es Handelszentrum in einer für die Landwirtschaft geeigneten Region. Hier finden die Tabakauktionen statt, Malawis wichtigstes Exportgut. In seiner Nähe befindet sich das mit deutscher Entwicklungshilfe gebaute zentrale Getreidesilo Malawis.

Die Wirtschaft von Lilongwe wird von Indern dominiert, die nur hier, in Blantyre und in Zomba siedeln dürfen. Darüber hinaus leben hier viele weitere Ausländer.

Lilongwe hat mit Kamuzu International Airport einen Flughafen, der die Abfertigung großer Flugzeuge 24 Stunden am Tag erlaubt. Seine Existenz verdankt er dem Bürgerkrieg in Mosambik, der einen Ausweichflughafen für Cuamba nötig machte.

Außerdem ist die Stadt durch die Bahnstrecke (Beira)–Nsanje–Mchinji angebunden (siehe auch: Schienenverkehr in Malawi).

In Lilongwe befinden sich unter anderem eine landwirtschaftliche Hochschule und das "Baptist Theological Seminary of Malawi", eine Ausbildungsstätte baptistischer Pastoren.




</doc>
<doc id="12961" url="https://de.wikipedia.org/wiki?curid=12961" title="Christopher Isherwood">
Christopher Isherwood

Christopher William Bradshaw-Isherwood (* 26. August 1904 in High Lane, Cheshire, England; † 4. Januar 1986 in Santa Monica, Kalifornien) war ein britisch-amerikanischer Schriftsteller. Bekannt wurde er durch seine "Berlin Stories", die Grundlage des Filmmusicals "Cabaret" wurden. Im Alter war er einer der ersten literarischen Exponenten der Lesben- und Schwulenbewegung.

Christopher Isherwood wurde als Sohn des Offiziers Frank Bradshaw-Isherwood und dessen Ehefrau Kathleen Machell-Smith geboren. Er hatte einen sieben Jahre jüngeren Bruder. Der Vater fiel 1915 während der Zweiten Flandernschlacht des Ersten Weltkriegs. Ab 1914 besuchte er die St. Edmund’s Schule, wo er sich mit W. H. Auden befreundete, später die Repton School in Derbyshire, wo er 1921 Edward Upward kennenlernte. In Cambridge studierte er Geschichtswissenschaft, fiel jedoch 1925 durch die Tripos-Prüfung. Vorübergehend lebte er bei dem Violinisten André Mangeot, arbeitete als Sekretär für dessen Streicherquartett. 1928 begann er ein Medizin-Studium am King’s College London, das er 1929 jedoch abbrach.

Im gleichen Jahr folgte er dem Schriftsteller W. H. Auden nach Berlin. Beide waren fasziniert von der Unwirtlichkeit, dem Tempo und der Schwulenszene der Stadt. „Berlin ist der Traum eines jeden Schwulen“, schrieb Auden damals, „Es gibt hier 170 von der Polizei überwachte einschlägige Bars und Gaststätten“. „Für Christopher war Berlin gleichbedeutend mit ‚Jungs‘“, fasste Isherwood seine Faszination später knapp zusammen. Fast jeden Abend besuchten er und Auden Stricherlokale in der Gegend des Halleschen Tores im Bezirk Kreuzberg. Ihr Stammlokal wurde das Cosy Corner in der Zossener Straße, ein schmuddeliges Café, in dem „immer ein halbes Dutzend Jungs herumlungerten und Bier tranken“.

Isherwood sprach bald fließend deutsch. Sein Leben finanzierte er als Sprachlehrer und aus vierteljährlichen Zuwendungen seines vermögenden Onkels Henry Isherwood. Zunächst wohnte er als Untermieter der ältesten Schwester Magnus Hirschfelds am Institut für Sexualwissenschaft unmittelbar am Großen Tiergarten, ungefähr dort wo heute die Kongresshalle steht. Im Oktober 1930 zog er in den Arbeiterbezirk Kreuzberg, zuerst in die Simeonstraße, nahe dem U-Bahnhof Prinzenstraße, einen Monat später in die Admiralstraße unmittelbar am Kottbusser Tor. Ab Dezember 1930 lebte er für zweieinhalb Jahre mitten in Berlins schwul-lesbischem Viertel, in der Nollendorfstraße 17, im Bezirk Schöneberg, wo heute eine Gedenktafel an ihn erinnert. Zwei Ecken weiter lag das Tanzkabarett Eldorado, berühmt für seine Transvestiten-Shows, in dem auch Marlene Dietrich verkehrte. Im März 1932 lernte er in Berlin seinen ersten dauerhaften Lebensgefährten kennen, den damals 17-jährigen Zugehmann Heinz Neddermeyer, mit dem er fünf Jahre zusammenlebte.

Nach der Machtergreifung Hitlers verließ Isherwood im Mai 1933 mit seinem Lebensgefährten Deutschland. Bis 1937 lebte er nacheinander auf einer Insel im Golf von Euböa, in London, auf den Kanaren, in Spanisch-Marokko, in Kopenhagen, Brüssel, Amsterdam und der portugiesischen Kleinstadt Sintra. Von Oktober 1933 bis Februar 1934 arbeitete er in London für das Filmstudio Gaumont-British an dem Film "Little Friend", zunächst als Drehbuchautor, dann als Dialogberater des Regisseurs Berthold Viertel. 1938 unternahm er mit W. H. Auden eine Reportagereise nach China.

1939 emigrierte Isherwood mit Auden von London aus in die Vereinigten Staaten. Die USA hatten ihn seit langem angezogen. Zunächst lebte er etwa drei Monate in New York City, fühlte sich dort aber nicht heimisch. So reiste er auf Einladung von Gerald Heard mit den Greyhound Lines über New Orleans und Houston nach Kalifornien. Obgleich er Los Angeles als „die vielleicht hässlichste Stadt der Welt“ empfand, entschloss er sich zu bleiben: „Los Angeles ist ein großartiger Platz, um sich zuhause zu fühlen, weil jeder von woanders kommt.“ Weil er nicht bereit war, auf Deutsche zu schießen, registrierte er sich nach dem Eintritt der USA in den Zweiten Weltkrieg als Kriegsdienstverweigerer. 1941 und 1942 lebte er in Haverford, Pennsylvania, wo er im Auftrage der Quaker-Organisation "Society of Friends" deutschen Flüchtlingen Englisch beibrachte.

Der Schriftsteller Henry F. Heard hatte ihn bereits 1939 dem hinduistischen Mönch Swami Prabhavananda vorgestellt, der Chef der Vedanta Society of Southern California war. Prabhavananda wurde für ihn zu einer Art Vaterfigur und Sinnstifter. Nach seiner Rückkehr nach Kalifornien 1943 half er ihm bei der Übersetzung der Bhagavad Gita ins Englische. 1944 lebte er kurz als Mönch im Vedanta Center Los Angeles, schied aber wieder aus, weil er nicht sexuell enthaltsam leben wollte.

1946 nahm Isherwood die US-amerikanische Staatsbürgerschaft an. Ende der 1940er Jahre zog er nach Santa Monica, reiste mit seinem Lebensgefährten Bill Caskey durch Südamerika und veröffentlichte dazu ein Buch. Er arbeitete als Drehbuchautor für die Filmstudios in Hollywood und traf dort auf Schriftsteller und Schauspieler. Er war mit den Schriftstellern Tennessee Williams, Aldous Huxley und Kenneth Anger, den Schauspielern Charles Laughton, Jennifer Jones und Leslie Caron, dem Regisseur John Boorman sowie dem Komponisten Igor Strawinsky und dessen Frau Vera befreundet. 1959 erwarb er ein Haus über dem Santa Monica Canyon, einer bei Künstlern und Schriftstellern beliebten Wohngegend. Von 1959 bis 1962 hatte er eine Gastprofessur für moderne englische Literatur am Los Angeles State College of Applied Arts and Sciences inne.

Von 1953 bis zu seinem Tod lebte Isherwood in einer Beziehung mit dem 30 Jahre jüngeren Don Bachardy. Der Schriftsteller bestärkte den zunächst Sprachen studierenden jungen Mann, seine künstlerischen Talente zu entfalten und sich als Porträtmaler zu etablieren. Das Paar bearbeitete Dramatisierungen der Isherwood-Novelle "Meeting By The River" und des Buchs "October" sowie das Drehbuch des Fernsehfilms "Frankenstein: The True Story". Im Alter engagierte sich Isherwood im US-Gay-Rights Movement. Die Verbindung von Isherwood und Bachardy wurde zu einem Vorbild für die schwul-lesbische Community in den USA. David Hockney malte 1968 ein Doppelporträt des Paares. Isherwood starb 1986 in seinem Haus in Santa Monica an Prostatakrebs.

Seine ersten Romane "All the Conspirators" (1928), und "The Memorial" (1932) sind Abrechnungen mit dem damaligen England. Die Romane "Mr. Norris steigt um" (1935) und "Leb wohl, Berlin" (1939), auch genannt die "Berlin Stories", begründeten in England seinen Ruf als literarisches Wunderkind und prägten im angelsächsischen Sprachraum das Berlinbild der frühen 1930er Jahre. Sie greifen Isherwoods Erlebnisse in Berlin zwischen 1929 und 1933 auf. Die bekanntesten Figuren der beiden Romane waren seine Mitbewohner der Privatpension Thurau in der Nollendorfstraße. 1931 lernte er dort Jean Ross kennen, die das Vorbild der Figur der kapriziösen Nachtklub-Sängerin und aufstrebenden Schauspielerin Sally Bowles wurde. Auch Gerald Hamilton, der Isherwood zu Mr. Norris, einem Journalisten, Kommunisten und Kriminellen inspirierte, lebte in der Pension Thurau. Die Vermieterin Meta Thurau wurde in seinen Romanen zu Lina Schröder, für Isherwood eine typische Berlinerin, die sich trotz anfänglicher Ablehnung des Nationalsozialismus schließlich mit ihm arrangierte.

In den Vereinigten Staaten geriet Isherwood in eine langandauernde Schaffens- und Sinnkrise. Bereits in New York hatte er den Eindruck, dass sein Talent als Schriftsteller aufgebraucht sei. In Los Angeles wuchs sein Unsicherheitsgefühl. Die literarische Produktivität ließ über zwei Jahrzehnte drastisch nach. Sein Leben in Santa Monica fand er „leer, eitel, trivial, tragisch“. Er betäubte sich mit viel Alkohol und Sex. Eine Autobiografie über die Zeit von 1945 bis 1951 trug den Titel "Verlorene Jahre". Isherwood kam von Berlin nicht los. „Im Hintergrund war immer Berlin“, schrieb er 1962 über seine frühen Jahre in den USA: „Es rief mich jede Nacht und seine Stimme war die raue, aufreizende Stimme der Grammophonplatten.“ 1949 erschien "Kondor und Kühe: Ein südamerikanisches Reisetagebuch" mit Fotos seines Lebensgefährten Bill Caskey. Die Motive seiner "Berlin Stories" wurden zunächst für das Broadway-Theaterstück "I Am a Camera" (1951) und den gleichnamigen Film (1955), dann für das Musical "Cabaret" (1966) und den Film "Cabaret" (1972) adaptiert.

Der 1945 erschienene Roman "Praterveilchen" spielt in Wien, das 1962 veröffentlichte Buch "Down there on a Visit" thematisiert erneut Berlin am Ende der Weimarer Republik. Der 1964 veröffentlichte Roman "Der Einzelgänger" war sein erstes durch und durch US-amerikanisches Werk; es bildete 2009 die Grundlage für das Filmdrama "A Single Man". Isherwood verfasste in den 1950er und 1960er mehrere Werke zur indischen Philosophie der Vedanta. In den 1970er Jahren thematisierten seine Werke die eigene Homosexualität, teilweise in sehr drastischen Beschreibungen. Den zwei Berlinromanen aus den 1930er Jahren wurde die Autobiografie "Christopher und die Seinen" (1976) an die Seite gestellt, in der er verheimlichte Dinge betreffs seiner eigenen Person zurechtrücken wollte.



Drehbuch

Literarische Vorlage



</doc>
<doc id="12963" url="https://de.wikipedia.org/wiki?curid=12963" title="Marguerite Yourcenar">
Marguerite Yourcenar

Marguerite Yourcenar (* 8. Juni 1903 als Marguerite Antoinette Jeanne Marie Ghislaine Cleenewerck de Crayencour in Brüssel; † 17. Dezember 1987 in Bar Harbor, Maine) war eine französische Schriftstellerin. 1947 wurde sie Bürgerin der USA. Sie wurde mit dem Prix Femina und dem Erasmuspreis ausgezeichnet und war die erste Frau, die in die Académie française aufgenommen wurde.

Marguerite Cleenewerck de Crayencour wurde als Tochter des aus Bailleul in Französisch-Flandern gebürtigen Michel Cleenewerck de Crayencour und seiner zweiten Frau Fernande, geb. de Cartier de Marchienne geboren. Die Familie des Vaters war großbürgerlicher Herkunft und hatte im 18. Jahrhundert das Lehngut "Crayencour" bei Terdeghem erworben, sowie 1851 durch die Heirat von Marguerites Großvater Michel Charles Cleenewerck de Crayencour (1822-1886) mit der reichen Großgrundbesitzer-Erbin Noémi Dufresne (1828-1909) einen großen Güterkomplex um das 1824 erbaute "Château du Mont-Noir" in Saint-Jans-Cappel. Die Mutter stammte aus belgischem Adel, in welchen 1925 auch Marguerites älterer Halbbruder Michel Cleenewerck de Crayencour (1885-1966) als "chevalier" aufgenommen wurde. Die Mutter starb noch im Kindbett, weshalb Marguerite von ihrer Großmutter Noémi aufgezogen wurde. Im Winter lebten sie im Hôtel particulier der Familie Dufresne in Lille und im Sommer auf dem "Château du Mont-Noir". In den ersten Jahren fungierte auch die beste Freundin und ehemalige Mitschülerin der verstorbenen Mutter, Jeanne de Vietinghoff, als eine Art Patin aus der Ferne. Selber Schriftstellerin, wurde sie zum Vorbild Yourcenars. "„Ihre Mutter … ist für mich zu einer Legende geworden, zu einer Legende, die mein Leben beeinflusste“", schreibt sie 1983 an den Sohn Egon von Vietinghoff. 1913 verkaufte der Vater das Familienschloss und begab sich auf ausgedehnte Reisen durch Europa, wobei ihn die Tochter häufig begleitete. Sie kam zur Erziehung auch in französischsprachige Familien in Brüssel und begann schon als Jugendliche mit dem Schreiben. Der Vater ging 1926 in Monaco eine dritte Ehe ein und verstarb 1929. Danach führte sie - wie dieser - ein Nomadenleben und war bis zum Ausbruch des Zweiten Weltkriegs fast ständig auf Reisen. Auch später reiste sie bis ins hohe Alter durch Europa, Asien und Afrika.

Erste Aufmerksamkeit erregte die junge Schriftstellerin, die sich ein Anagramm ihres Familiennamens Crayencour als Nom de plume wählte, 1929 mit "Alexis oder der vergebliche Kampf", nach dem Vorbild von André Gide. Es ist das in Briefform geschriebene Bekenntnis eines renommierten Musikers, der seiner Frau seine Homosexualität gesteht und sich, ringend mit dem Bedürfnis nach Wahrheit, von ihr trennt. Die Figur der "Monique" ist von ihrer Patin Jeanne de Vietinghoff inspiriert, in die der Vater Crayencour sich verliebt hatte, und die Figur des Ich-Erzählers durch deren Mann, den Pianisten Conrad von Vietinghoff. Wie auch in mehreren ihrer folgenden Werke, in denen die generelle Thematik des Ehepaars Vietinghoff variiert wird, zeigt sie sich in prägnanter Sprache als Meisterin der Verflechtung von „Dichtung und Wahrheit“ sowie des assoziativen Verwirr- und Versteckspiels. In ihrer Biografie schreibt Josyane Savigneau: "„Wie viel an diesem Durcheinander ist Absicht?“...„Wirklich interessiert hat sie an ihrem Leben nur, was einen Vorwand zu literarischer Umformung liefern konnte.“" Sie verliebte sich in ihren Herausgeber André Fraigneau (1905-1991), der jedoch homosexuell war und sie zurückwies, was sie in ihrem 1935 veröffentlichten Prosagedicht "Feux" verarbeitete und sie zum Bekenntnis ihrer eigenen lesbischen Neigung brachte. 1937 lernte sie Grace Frick kennen, eine amerikanische Professorin, mit der sie bis zu deren Tode 1979 zusammenlebte. Frick stand der zu Depression und Hypochondrie neigenden Dichterin seelisch und während des Zweiten Weltkriegs auch finanziell bei und übersetzte ihr Werk ins Englische. 

1936 veröffentlichte sie das Prosagedicht "Feuer", 1939 folgte der Roman "Der Fangschuss". Mit Kriegsbeginn ließ sie sich in den USA nieder, 1947 erhielt sie die US-amerikanische Staatsbürgerschaft. Von 1942 bis 1953 unterrichtete sie vergleichende und französische Literaturwissenschaften am Sarah Lawrence College in New York. An dem Roman "Ich zähmte die Wölfin" schrieb sie hauptsächlich von 1924–1927, 1934–1939 und nach Verlust von Manuskriptteilen noch einmal in den Jahren 1948–1950, in denen sie historische Recherchen unternahm. Mit dieser schließlich 1951 veröffentlichten fiktiven Autobiografie des römischen Kaisers Hadrian gelang ihr der internationale Durchbruch. Für dieses Buch, von dem bis 1989 fast eine Million Exemplare verkauft wurden, bekam sie den Prix Femina. 1968 folgte der Roman "Die schwarze Flamme".

Neben ihren eigenen Romanen, Essays, Theaterstücken und Artikeln veröffentlichte Marguerite Yourcenar Übersetzungen von Romanen, Gospels und Kindergeschichten aus Indien vom Englischen sowie von altgriechischen Gedichten ins Französische. Marguerite Yourcenar war Vegetarierin und setzte sich gegen die Robbenjagd ein, 1968 gelang es ihr, mit einem Brief an Brigitte Bardot diese für die sehr erfolgreiche Kampagne gegen die Robbenjagd in Kanada zu gewinnen.

Yourcenar erhielt viele Preise und Ehrungen. 1970 wurde sie in die Königliche Akademie der französischen Sprache und Literatur von Belgien aufgenommen und am 4. März 1980 als erste Frau in die renommierte Académie française. 1987 wurde sie in die American Academy of Arts and Sciences gewählt. Außerdem erhielt sie 1983 den Erasmuspreis, der mit 100.000 holländischen Gulden dotiert war, und insgesamt drei Ehrendoktor-Titel, darunter den der Harvard University. Ihr Werk wurde in viele Sprachen übersetzt. Es gibt einige Yourcenar-Biografien mit Übersetzungen in andere Sprachen, eine Fülle von Einzelartikeln zu verschiedenen Teilaspekten ihres Werks und ihres Lebens sowie mehrere Forschungsinstitute in Europa und in den USA, die sich mit ihr und ihrem Werk beschäftigen. Im Dezember 1996 wurde der Asteroid (7020) Yourcenar nach ihr benannt. Sie ist Namensgeberin des seit 2015 existierenden Prix Marguerite-Yourcenar, der jährlich von der Société civile des auteurs multimédia (Scam) vergeben wird und mit 8000 € dotiert ist. Die Preisträgerin 2016 war Hélène Cixous und 2017 Annie Ernaux.

An der Stelle des im Ersten Weltkriegs zerstörten Elternhauses der Schriftstellerin, des "Château du Mont-Noir" in Saint-Jans-Cappel, hatte der Industrielle Henri Coisne Dansette ab 1930 eine Villa im neo-normannischen Stil errichtet, die vom "Conseil départemental du Nord" erworben und 1997 als «Centre de résidence d’écrivains européens» (Zentrum für europäische Schriftsteller) unter dem Namen "Villa Marguerite-Yourcenar" eingerichtet wurde. Im Ortszentrum war bereits 1985, unter Beteiligung der Dichterin, das "Musée Marguerite-Yourcenar" mit Dokumenten und Erinnerungsstücken eingerichtet worden. In Paris wurde eine Bücherei, die "Médiathèque Marguerite-Yourcenar", nach ihr benannt. Auf dem Hof des "Château Bilquin-de Cartier" in Marchienne-au-Pont, Elternhaus ihrer Mutter, wurde eine Gedenkstele für sie errichtet, ebenso im Herkunftsort ihrer Familie in Bailleul vor der Kirche Saint-Vaast.





</doc>
<doc id="12964" url="https://de.wikipedia.org/wiki?curid=12964" title="Gebet">
Gebet

Das Gebet (von althochdeutsch "gibët", abgeleitet nicht von "beten", sondern zu "bitten") bezeichnet eine zentrale Glaubenspraxis vieler Religionen. Es ist eine verbale oder nonverbale rituelle Zuwendung an ein transzendentes Wesen (Gott, Gottheit, Göttin). 

Neben dem Vorgang des Betens (als gemeinschaftliches oder persönliches Gebet) wird im Deutschen mit "Gebet" auch ein vorformulierter, feststehender Text bezeichnet. Ein solches Gebet kann auf einen bestimmten Urheber zurückgehen (z. B. den Religionsstifter, einen Heiligen oder einen religiösen Schriftsteller). Manche Gebete werden zu einem bestimmten Anlass im Leben des einzelnen oder der Gemeinschaft gesprochen. Gebete werden in der Familie oder in der Religionsgemeinschaft tradiert und gelernt. Die bekanntesten Gebete sind im Judentum das Schma Jisrael und im Christentum das Vaterunser. Die Gebets- und Liedersammlung der Psalmen hat für Judentum und Christentum Bedeutung. 

Das Gebet unterscheidet sich durch seine persönliche und kommunikative Komponente von anderen religiösen Praktiken. Es setzt also die Vorstellung eines persönlichen Gottes voraus, die etwa in Buddhismus oder Taoismus nicht vorhanden ist. Außerdem setzt es voraus, dass ein solcher Gott empfänglich für eine solche Form der Zwiesprache ist und nicht etwa allein durch kultische Handlungen, Opferpraktiken etc. erreicht werden kann. 

Er muss dem Betenden gegenüber präsent sein; in den monotheistischen Religionen wird Gott zumeist als allgegenwärtig angesehen, während naturreligiöse Konzepte den Gottheiten oft bestimmte Orte zuordnen, sodass sich der Betende zunächst an den jeweiligen Ort begeben muss. 

Wenn Religionsgelehrte und Theologen an eine Vorherbestimmung glauben, dann erwarten sie nicht, dass der unveränderliche Wille der Gottheit durch menschliche Gebete geändert werden kann, sondern sie erwarten vom Gebet eine Änderung des betenden Menschen: Der das Gute erstrebende Wille Gottes sei nicht zu ändern, aber durch die Gebetstätigkeit werde der Wille des Menschen gestärkt, seine Seele geläutert und somit eine ganzheitliche Änderung zum Guten bewirkt. 

Gebetet werden kann im Gottesdienst, in einer Gruppe oder allein. Ganze Gottesdienste werden als Gebet verstanden, wie der jüdische Gottesdienst am Shabbat in der Synagoge, die heilige Messe der katholischen und die göttliche Liturgie der orthodoxen Kirche, das christliche Stundengebet oder das Freitagsgebet der Muslime. Viele Religionen kennen festgesetzte Gebetszeiten.

Gebete können gesungen, laut ausgesprochen oder im Stillen für sich formuliert werden. Es gibt dabei je nach Religion und Konfession unterschiedliche Körperhaltungen und Gesten: stehen, knien, niederwerfen, den Kopf senken, die Hände erheben oder falten. Im Zusammenhang mit Gebeten werden oftmals Symbole oder Hilfsmittel verwendet, wie Gebetsketten, Kruzifixe oder Ikonen.

Es gibt tradierte liturgische Gebete mit feststehenden Wortfolgen, manchmal in Form einer Litanei, Gebete mit Vorlagen oder spontan formulierte Gebete.

Zum täglichen Gebet (hebr. תפלה, "Tefillah") im Judentum gehören für religiöse Juden – Männer wie Frauen – drei Gebete: morgens Schacharit, nachmittags Mincha und abends Maariw. Beim Gebet bedecken Juden den Kopf mit einer Kippa oder einer anderen Kopfbedeckung und benutzen beim werktäglichen Morgengebet Tefillin (Gebetsriemen) und Tallit (Gebetsschal) – letzterer wird auch am Shabbat und an Festtagen verwendet.

Die Gebete werden nach einem Grundmuster gebetet, das je nach Wochentag oder Festtag leicht variiert. Das Gebetbuch, das diese Gebete enthält, heißt Siddur. Das Gebetbuch für einen Festtag heißt Machsor. Zu den Gebeten gehören Tehillim (Psalmen), das Schma Jisrael (Höre, Israel), Amida oder Achtzehnbittengebet (Schmone Esre). In orthodoxen und konservativen Synagogen wird alles in hebräischer Sprache gebetet, im liberalen Judentum werden einige Gebete in der Landessprache gesagt.








Für Festtage gibt es weitere besondere Texte, an Jom Kippur zum Beispiel das Gebet Kol Nidre.





Neben den Gebeten sagen religiöse Juden zu vielen Gelegenheiten Lobsprüche (hebr. ברכות, Brachot), so u. a. über das Essen oder vor der Ausübung einer Mizwa (hebr. מצות, "Gebote"). Diese Mini-Gebete heißen „Lobsprüche“ (Brachot), weil als „Gebet“ nur die Amida verstanden wird.




Brachot können in jeder Sprache gesagt werden.

Zum häuslichen Schabbat, der wöchentlichen Erinnerung an den Auszug aus Ägypten und der Erschaffung der Welt sowie auch ein Zeichen des Bundes Gottes mit dem Volk Israel (Geschenk der Liebe Gottes) gehört das Entzünden der Schabbatkerzen und ein Lobspruch über das Licht sowie der Kiddusch über ein Glas Wein zur Heiligung des Tages. Es liegen zwei zopfartig geflochtene Schabbatbrote ("Challot": Plural vom hebr.Challa, ostjiddisch Challe, westjidd. Barches oder Berches) auf dem Tisch. Sie werden für den Lobspruch über das Brot verwendet, mit dem das Essen am Schabbat beginnt. (Jedes Essen beginnt mit Brot, das Besondere am Schabbat sind die Challot.) Die Kerzen werden in der Regel zuhause vor der Dämmerung entzündet, das festliche Essen mit Kiddusch und Schabbatbrot und dem eigentlichen Abendessen folgt nach dem Gottesdienst – sofern der Gottesdienst besucht wird.


Das Gebet zu Gott gehörte von Anfang an zu den wichtigsten Ausdrucksformen des christlichen Glaubens. Jesus selber als gläubiger Jude hat gebetet und seine Schüler zum Beten angeleitet.

Das Neue Testament zeigt mehrere Gebetsformen: Psalmen, Klage, Bitte, Dank, Fürbitte, Anbetung. Einige der am häufigsten gebrauchten christlichen Gebete stammen aus dem Neuen Testament, z. B. das Vaterunser, das im Wortlaut nach alter Überlieferung auf Jesus selber zurückgeht (). 

Die Evangelien zeigen, wie Jesus den Menschen in all ihren praktischen Nöten helfen wollte. Aber je mehr er das tat, desto mehr neigten sie zur Fixierung auf Gottes momentane Hilfe – Jesus wurde umlagert von Kranken, die Heilung suchten. Dadurch wurde es für ihn schwer, Aufmerksamkeit für seine über momentane Hilfe hinausgehende Botschaft zu finden. Solche Erfahrungen betreffen generell das Bitten – werden sie erhört, sind sie "Zeichen", die auf Gott hinweisen; aber gleichzeitig fördern sie die Neigung der Menschen, von ihrer Gottesbeziehung primär die Erfüllung ihrer Wünsche zu erwarten.

Das NT gibt zahlreiche Hinweise auf den Stellenwert des Gebets im Verhältnis des Menschen zu Gott, und es gibt Empfehlungen zur Art des Betens. Wichtig für das christliche Gebet, auch im Hinblick auf seine Erhörung, ist der Einklang des Beters mit dem Willen Gottes, der Glaube (). Dann gelte: „Bittet, so wird euch gegeben“ (). Wenn der Mensch sich Gott und seiner Gottesherrschaft anvertraue, dann werde ihm alles zufallen, was er braucht (). Also könne sich der Mensch mit seinem Anliegen immer wieder im Gebet an Gott wenden, vermittelt durch Jesus (), und ihn um alles das bitten, was er täglich benötige. Der Beter dürfe dann erwarten, dass Gott „bei denen, die ihn lieben, alles zum Guten führt“ (). 

Gemäß Paulus und Johannes ist es der Heilige Geist, der betet, wenn Menschen „nicht wissen, wie und was wir beten sollen“ (). Der Heilige Geist tritt als Mittler (Paraklet, „Tröster“) ein ().

Neben dem vertrauensvollen Beten kennt die Bibel auch das klagende und aufschreiende Gebet des Menschen in Not. Jesus selbst wandte sich gemäß dem Markusevangelium am Kreuz mit den Psalmworten „Mein Gott, mein Gott, warum hast du mich verlassen?“ (Psalm 22,2, ) an seinen Vater. Die klagenden Lieder der Psalmen (so Psalm 51: „Gott, sei mir gnädig nach deiner Huld“, ) und der Propheten () sind Bestandteil christlichen Betens bis heute.

Nach Christi Himmelfahrt beteten die Christen auch zu Jesus. Die vom AT her bekannte Formel „den Namen JHWHs anrufen“ wurde nun auf Jesus angewandt; die Formel „die den Namen Jesus anrufen“ war dann die Kennzeichnung der Christen (z. B. , ).

Das Gebet in all seinen Formen, mit seinen unterschiedlichen Auswirkungen, fördert die Beziehung der Menschen zu Gott.

Das Christentum kennt viele Gebetsformen.

Beten ist nicht an bestimmte Worte, Haltungen und Orte gebunden. Im Matthäusevangelium kritisiert Jesus ein öffentlich zur Schau gestelltes, wortreiches Beten als heuchlerisch.

In der Kirche wird meistens stehend (Ausdruck des Respekts) oder kniend (Ausdruck der Anbetung) gebetet. 
Typisch für das christliche Beten der Alten Kirche ist das freie, selbstbewusste Stehen vor Gott mit geöffneten Armen, erhobenen Händen und Augen (Orantenhaltung). Das Ausstrecken der Arme im Gebet stammt aus dem vorchristlichen Mittelmeerraum und Orient, es geht auf die Körperhaltung der Bettler zurück. In der katholischen Kirche nimmt der Zelebrant die Orantenhaltung ein, wenn er die Amtsgebete (Tagesgebet, Gabengebet, Schlussgebet) spricht, in manchen Gemeinden tun dies auch die Mitfeiernden beim Beten des Vaterunsers. Diese Gebetshaltung wird häufiger von Christen der charismatischen Bewegung oder der Pfingstbewegung praktiziert.

In späterer Zeit wurde im Abendland das Falten der Hände üblich. Diese Geste soll verdeutlichen, dass sich der Beter nur auf Gott konzentriert und nicht mit anderen Dingen beschäftigt ist. Die aneinander gelegten offenen Handflächen entsprechen der Haltung bei der Huldigung des Lehnsherren im mittelalterlichen Feudalsystem; diese Form wird etwa seit dem 11. Jahrhundert praktiziert. Das Gebet mit verschränkten Fingern kam erst in der Reformation auf. Daneben gibt es noch seltenere, ältere Formen, wie das Kreuzen der Hände vor der Brust. 

Katholische Christen beginnen und beenden das persönliche Gebet oft mit dem Kreuzzeichen und den der Taufformel entnommenen Worten „Im Namen des Vaters und des Sohnes und des Heiligen Geistes“. Orthodoxe Christen bekreuzigen sich ebenfalls, wobei bei ihnen die Haltung der Finger eine wesentliche Rolle spielt (siehe Kreuzzeichen). Im Protestantismus ist das Kreuzzeichen kaum noch verbreitet, obwohl es noch Martin Luther im Kleinen Katechismus empfahl.

Auch zum persönlichen Gebet entzünden Christen gern eine Kerze als Zeichen der Sammlung oder der Hoffnung. Der Brauch, vor einem Kreuz oder einem Gnadenbild in einer Kirche eine Kerze anzuzünden, soll das Gebet für einen anderen Menschen oder für ein persönliches Anliegen versinnbildlichen.

Der christliche Glaube betont, dass der Mensch auch in (unheilbarer) Krankheit nicht von der Liebe Gottes getrennt ist. Ein Gebet für Kranke findet in sehr unterschiedlichem Rahmen statt:

Fürbitten werden oft gezielt in der Hoffnung getätigt, dadurch die Genesung Kranker beeinflussen zu können. Medizinische Forschungen konnten jedoch noch nie einen empirischen Wirkungszusammenhang zwischen dem Beten von Fürbitten und der Genesung von Krankheiten herstellen. Beten kann für den Betenden selbst einen Placeboeffekt bewirken und auf diese Weise zur Gesundung beitragen. Die Mehrheit der wissenschaftlichen Studien zum Thema konnte jedoch keine gesundheitsfördernde Wirkung von Gebeten feststellen.
Bis heute hat das Gebet einen zentralen Platz in der Praxis aller christlichen Konfessionen. 

Alle kennen das "Vaterunser" und die Psalmen ebenso wie persönlich formulierte Gebete und Kirchenlieder in Gebetsform. Die orthodoxen, katholischen und anglikanischen Kirchen haben eine reiche Tradition von vorformulierten Gebeten für den liturgischen und persönlichen Gebrauch (siehe liturgische Gebete), im Pietismus und im freikirchlichen Raum werden Gebete meistens frei formuliert.

Alle christlichen Konfessionen wenden sich im Gebet direkt an Gott und gehen davon aus, dass Gott Gebete hört. Christen wenden sich im Gebet an den Dreieinigen Gott, beten zu Gott dem Vater, zu Jesus Christus und manche auch direkt zum Heiligen Geist, wobei es in den meisten Konfessionen, von fest formulierten liturgischen Gebeten abgesehen, dem Einzelnen überlassen ist, an wen er sich im Gebet wendet. In der katholischen und der orthodoxen Kirche können Gebete auch an Maria (z. B. das Ave Maria, das die Anrede Marias durch den Engel aufgreift, oder Marias Lobgesang, das sog. Magnificat ) und an Heilige gerichtet werden, wobei diese Gebete als Bitte um Fürsprache beim dreieinigen Gott gelten.

Christen glauben, dass Gott Gebete erhört, wobei es über die Art und Häufigkeit der Gebets-Erhörung sehr unterschiedliche Sichtweisen gibt. 

Ebenso glauben viele Christen, dass Gott im Gebet durch den Heiligen Geist zum Betenden reden kann. Dabei kann es sich um Prophetie, Erleuchtung und persönliche Eingebungen handeln, aber ebenso um alltägliches, wie dass Gott z. B. die Aufmerksamkeit auf einen Bibelvers lenkt, der in die Situation passt, oder ein allgemeines Gefühl des Getröstetseins gibt. Praktisch alle Konfessionen, bei denen Prophetie oder Erleuchtung als Geistesgabe anerkannt sind, haben allerdings gewisse Sicherheitsregeln, um allzu wilde Fantasie in Grenzen zu halten, z. B. Beurteilung durch erfahrene Christen oder Gemeindeleiter, Beurteilung durch die Gemeinschaft anhand der Bibel, Beurteilung durch die kirchliche Lehre, vor allem aber Beurteilung vom Willen Gottes her: Liebe deinen Nächsten wie dich selbst (Mt 22,34–40). Was mit der Liebe (agape) nicht vereinbar ist, kann nicht Gottes Wille sein.

Bei manchen Sportlern ist zu beobachten, dass sie beim Betreten der Wettkampfstätte religiöse Rituale wie das Kreuzzeichen in das Vorwettkampfritual des Leistungssports einbeziehen. Mit dem "Fellowship of Christian Athletes" hat dies in den USA eine feste Organisationsform erhalten. Dänische Wissenschaftler haben empirisch ermittelt, dass Gläubige durch das Gebet in der Erwartung von Wettkampfstress und Schmerz zuversichtlicher sind und signifikant weniger Schmerz wahrnehmen als Nichtgläubige. 

Muslime unterscheiden zwischen Du'a (Bittgebet) und Ritualgebet. Beim Bittgebet wird Gott um Hilfe angerufen. Das Ritualgebet andererseits gehört zu den Fünf Säulen des Islam und wird fünfmal pro Tag gebetet. Es wird auf Arabisch rezitiert. Das Pflichtgebet hat im Islam eine zentrale Bedeutung. Laut Überlieferung hat der Prophet Mohammed die Anweisung zum Gebet von Gott persönlich während seiner Himmelfahrt empfangen. Durch das Gebet werden die Muslime dazu angehalten, in ihrem Tagesablauf innezuhalten und Gottes zu gedenken. Vor jedem Ritualgebet wird eine rituelle Waschung durchgeführt (Wudū'). Zentraler Baustein jedes Pflichtgebets ist die Rezitation der ersten Sure des Korans, der Sure Al-Fātiha. In Einzelheiten unterscheidet sich das Gebet bei den einzelnen islamischen Rechtsschulen.

In der Religion der Bahai spielt das Gebet eine wichtige Rolle. Drei rituelle Pflichtgebete unterschiedlicher Länge und Form stehen dem Gläubigen täglich zur Wahl: das lange Pflichtgebet (einmal in 24 Stunden zu beten), das mittlere Pflichtgebet (morgens, mittags und abends zu beten) und das kurze Pflichtgebet (mittags). Der Bahai hat die Pflicht täglich eines dieser Pflichtgebete zu beten. Die Zeitpunkte morgens (von Sonnenaufgang bis Mittag), mittags (zwischen Mittag und Sonnenuntergang) und abends (zwischen Sonnenuntergang und zwei Stunden danach) sind dabei einzuhalten. Diese Gebete werden vom Gläubigen alleine und zurückgezogen gesprochen oder gesungen. Das einzige Pflichtgebet, das in Gemeinschaft rezitiert wird, ist das Totengebet. Darüber hinaus dienen die für unterschiedliche Anlässe und Situationen wörtlich überlieferten Gebete des Bab, Baha’u’llahs und Abdul-Bahas als Vorlage.

Abdul-Baha sagt über das Gebet: „Es ist die Sprache des Geistes, die zu Gott spricht. Wenn wir uns, befreit von allen äußerlichen Dingen, im Gebet zu Gott wenden, dann ist es, als hörten wir die Stimme Gottes in unserem Herzen. Ohne Worte zu reden, treten wir in Verbindung, sprechen wir mit Gott und vernehmen die Antwort … Wir alle, wenn wir zu einem wahrhaft geistigen Zustand gelangen, können die Stimme Gottes vernehmen.“

Ein Beispiel für ein Bahai-Gebet, geschrieben von Abdul-Baha:

In der Frühzeit des Hinduismus, der vedischen Zeit (1200 v. Chr.), wurden Hymnen an die Götter gerichtet, die oft mit Bitten verbunden waren und einen durchaus utilitaristischen Charakter hatten. Auch die Rezitation von Mantras (wörtl.: Mittel zum Denken) war von frühester Zeit an ein wichtiges Mittel religiöser Versenkung. 

Heute ist wie bei Gläubigen aller Religionen das tägliche Gebet auch bei Hindus üblich. Gebetet wird in fast allen hinduistischen Richtungen, vor allem aber im Bhakti Yoga ist die persönliche Hingabe an Gott und somit die Kommunikation mit ihm wichtig. 
Eine populäre Form der Verehrung ist die Anbetung Gottes in einem Bild oder einem Emblem. Andererseits lehnen auch sehr viele Hindus die Verehrung in Bildern völlig ab – wie beispielsweise die Anhänger des Arya Samaj oder die Lingayats, eine im zwölften Jahrhundert gegründete shivaitische Bewegung. 

Es gibt keine allgemeingültigen Vorschriften für Gebete und keine festen Gebetszeiten, die für alle Hindus gelten, sondern sehr unterschiedlich gelebte Familientraditionen. Darum ist die Praxis des Gebetes individuell sehr verschieden:



Eine vorgeschriebene "Körperhaltung" für das Gebet gibt es nicht, es muss aber in jedem Fall eine Haltung des Respekts sein. Darum zieht man vorher immer die Schuhe aus, wäscht sich möglichst zumindest die Hände und wählt einen Sitz, der tiefer liegt als der Altar. Meistens sitzt man mit verschränkten Beinen im Schneidersitz auf dem Boden oder man steht vor dem Bildnis. Vor dem Hausaltar oder im Tempel ist auch die kniende Verbeugung üblich, bei der die Stirn den Boden berührt. 

Zur Gebetshaltung gehören auch die vor der Brust gefalteten Hände, wobei man diese oft vor und nach Beginn des Gebetes als Respektsgeste jeweils kurz an die Stirn führt; oder man betet mit vor der Stirn gefalteten Händen, was besondere Inbrunst ausdrückt. Letztlich ist aber keine äußere Form zwingend, nur die innere Haltung.

Quellen vieler Gebete sind die Veden, die Puranas und nicht zuletzt die Beispiele großer Bhaktas, der Verehrer Gottes. Selbst von jenen Personen, die das Göttliche als letztlich absolut formloses, nicht-personales Brahman definieren, sind inbrünstige Gebete überliefert, etwa vom großen Philosophen Shankara:

Das bekannteste Gebet ist das "Gayatri-Mantra", eine vedische Hymne, welche das Göttliche in Form der Sonnenkraft, Surya, um geistiges Licht anruft. Viele Hindus sprechen oder singen es täglich, wobei der Gebrauch sich nicht auf Brahmanen beschränkt, wie oft behauptet, sondern alle beten es. 

Das "Mrityunjaya-Mantra" verehrt Shiva:

"Ziel der Gebete" und Anrufungen sind die verschiedenen, oft, aber nicht immer, anthropomorph gedachten Formen des letztlich formlosen Höchsten.

Entgegen einer weit verbreiteten Meinung ist der Hinduismus nicht polytheistisch. Alle Schulen lehren das formlose Eine, wenn auch in unterschiedlichen Philosophien. Die am meisten verbreiteten Philosophien sehen die verschiedenen Götter und Göttinnen als verschiedene Formen des höchsten Einen, das letztlich formlos ist. 

Ein sehr populäres Gebet, das Millionen von Hindus täglich singen, besonders zur täglichen Lichtkreis-Zeremonie, dem Arati, ist das "Jay Jagadish Hare". In diesem Text kommt deutlich zum Ausdruck, dass das Wissen um die Einheit auch in den Gebeten der einfachen Gläubigen enthalten ist. Ein Ausschnitt: 

Fast alle Richtungen des Buddhismus begreifen eine transzendente, letzte Wirklichkeit als nicht persönlich, so dass zu ihr zu beten keinen Sinn hat. Trotzdem beten viele Buddhisten in Japan, China und Tibet zu Bodhisattvas, übernatürlichen, erleuchteten Wesen, die auf den letzten Schritt ins Nirwana verzichten, um anderen zu helfen. Gerade die alltäglichen Sorgen werden so oft einem der vielen der letzten Wirklichkeit sehr nahestehenden Bodhisattvas anvertraut. Besonders ausgeprägt ist dies im Amitabha-Buddhismus, aber auch in Tibet.

Der Theravada-Buddhismus Sri Lankas und Südostasiens kennt keine Bodhisattvas als Helfer. Stattdessen wenden sich Gläubige in weltlichen Anliegen an Götter, die man sich als mächtig, aber selbst der Erleuchtung bedürftig vorstellt. In Thailand sind dies Hindugötter wie Brahma, der z. B. im Erawan-Schrein in Bangkok verehrt wird. In Myanmar wenden sich besonders Angehörige des Mehrheitsvolks der Burmesen an die 37 Nats, die helfen, aber auch schaden können. Bei den meisten Nats handelt es sich um die Geister von Adligen, die gewaltsam zu Tode kamen. In Sri Lanka werden Yakshas verehrt, Naturgeister, die Fruchtbarkeit verleihen können.

Shintoisten beten vor einem Altar zu Hause oder im Shintō-Schrein. Der Shintoismus kennt unzählbar viele Götter, die durchaus nicht perfekt sind, aber mit ihrer Macht den Menschen helfen können. Gebetet wird für Anliegen des Diesseits; die Frage nach dem Jenseits spielt im Shintoismus keine große Rolle und wird in Japan vom Buddhismus übernommen. Voraussetzung für ein Gebet ist Reinheit, zu der man sich vor dem Gebet Hände und Gesicht wäscht. Ein Priester kann dabei sein, muss aber nicht. Gebete können einfach und kurz sein oder lange Rituale mit festen, teilweise altjapanischen Gebeten, Opfern von Speisen und Sake sowie Tanz junger, von den Schreinen angestellter Frauen (Miko).

Eine besondere Form des Betens wird beim Hoʻoponopono angewendet, einem psycho-spirituellen Verfahren der Hawaiier zur „Auflösung“ unerwünschter, vorwiegend zwischenmenschlicher Umstände. Traditionell wurde das Verfahren, bei dem alle an einem Problem beteiligten Personen anwesend waren (im Geiste auch die Ahnen), durch einen "kahuna" (Heilpriester, ähnlich einem Schamanen) geleitet. Die zur Mithilfe angerufenen höheren Wesen waren meistens Naturgeister, aber auch ein Familiengeist, genannt ’aumakua.

„Hoʻoponopono“ (= wieder richtig machen) dient einer Korrektur von Fehlverhalten. Durch Aussprache (bis zur Beichte), gegenseitiges Bereuen und Vergeben soll in versöhnlicher, friedlicher Weise zur Konfliktlösung (einschließlich Lossprechung) beigetragen werden, dabei bis zur praktizierten Feindesliebe reichend. Moderne Formen können allein durchgeführt werden, wobei die an einem gegebenen Problem Beteiligten auf einer Art Liste zugegen sind. Die dabei durchgeführten Gebete und Atemrunden können auch mit spiritueller Reinigung bezeichnet werden, da sie durch Einbeziehung des „Göttlichen Schöpfers“ im Sinne eines (gegenseitigen) Fürbittengebets ablaufen. Heute anzutreffende Mantras, die mit „Hoʻoponopono“ bezeichnet werden, sind weder hawaiisch noch gehören sie zu Ho'oponopono.





</doc>
<doc id="12965" url="https://de.wikipedia.org/wiki?curid=12965" title="Jungferninseln">
Jungferninseln

Die Jungferninseln (früher auch Jungfraueninseln) sind eine Inselgruppe der Kleinen Antillen zwischen dem Atlantik und der Karibik.

Politisch sind die Jungferninseln zwischen den Britischen Jungferninseln, den Amerikanischen Jungferninseln sowie den dem US-amerikanischen Außengebiet Puerto Rico administrativ angegliederten Spanischen Jungferninseln aufgeteilt. Letztere werden wegen ihrer Zugehörigkeit zu Puerto Rico mitunter auch als "Puerto-Ricanische Jungferninseln" bezeichnet und sind wegen ihrer Lage westlich der Virgin-Passage auch unter der Bezeichnung "Passage-Inseln" geläufig.

Im Osten sind die Jungferninseln durch die mindestens 80 Kilometer breite Anegada Passage von Anguilla und St. Martin und deren Nebeninseln getrennt. Die nächstgelegene Insel ist die politisch zu Anguilla gehörende Insel Sombrero.

Im Südwesten trennt die 21 Kilometer breite "Pasaje de Vieques" die Insel Vieques von der Hauptinsel von Puerto Rico.
Die sieben größeren und zahlreichen kleineren Inseln der Amerikanischen und Britischen Jungferninseln befinden sich etwa 100 km östlich von Puerto Rico und fast 200 km westlich von Anguilla. Die zwei größeren und viele kleinere Inseln der Spanischen Jungferninseln liegen nur einige Kilometer vor der Ostküste Puerto Ricos, dem sie administrativ angehören. Mitunter werden sie nicht zu den Jungferninseln gezählt, da sie anders als die Amerikanischen und Britischen Jungferninseln westlich der Virgin-Passage liegen. Allerdings liegen die Spanischen Jungferninseln dichter an Saint Thomas, der Hauptinsel (auf ihr befindet sich die Hauptstadt) der Amerikanischen Jungferninseln, als Saint Thomas an Saint Croix, der größten und bevölkerungsreichsten Insel der Amerikanischen Jungferninseln.

Die ersten Siedler der Inseln gehörten zum Stamm der zu den Arawak zählenden Taíno und besiedelten die Inseln um 300 n. Chr. von Südamerika aus. Etwa um 1000 drangen die Kariben auf die Inseln vor. Christoph Kolumbus legte auf seiner zweiten Fahrt in die Neue Welt am 14. November 1493 auf den Jungferninseln an. Er benannte sie zunächst „Santa Ursula y las Once Mil Vírgenes“ (Sankt Ursula und die elftausend Jungfrauen). Die Inseln wurden für die spanische Krone in Besitz genommen, aber nicht besiedelt. Im Reisebericht des damals mitfahrenden Diego Alvarez Chanca heißt es: „Eine ganze Gruppe von Inseln erhebt sich aus dem Meer, einige dicht bewaldet, andere ziemlich felsig. Die größte nennt Kolumbus Santa Ursula, den anderen gibt er den Namen ‚Las Once Mil Virgenes‘.“

Um 1600 drangen Europäer anderer Nationen auf die Inseln vor und nutzten sie als Basis für Piraterie und Schmuggel, aber auch für Angriffe auf die spanischen Kolonien der Karibik und Lateinamerikas. Ab dieser Zeit begann die Auslöschung der indigenen Bevölkerung durch die Kolonisatoren bzw. die von ihnen eingeschleppten Krankheiten. Offiziell waren die Inseln im 17. Jahrhundert in englischem und dänischem Besitz (Dänisch-Westindien), die Inseln Tortola, Anegada und Virgin Gorda waren zeitweise niederländischer Besitz, wurden aber 1672 von den Engländern annektiert und bilden heute die Britischen Jungferninseln. Vieques und Culebra sowie deren diversen kleineren Nebeninseln östlich der Virgin-Passage waren bis zum Spanisch-Amerikanischen Krieg in spanischem Besitz verblieben. Infolge dieses Krieges wurden die Spanischen Jungferninseln 1898 gemeinsam mit Puerto Rico, diesem administrativ angegliedert, US-amerikanisches Territorium. Unter administrativer Federführung von D. Hamilton Jackson kauften die USA 1917 den dänischen Kolonialbesitz der Jungferninseln für 25 Millionen Dollar, der seither als Amerikanische Jungferninseln separates uninkorporiertes US-amerikanisches Außengebiet ist. Der Kaufpreis entspricht inflationsbereinigt nach heutigem Wert Millionen Dollar bzw. Millionen Euro respektive Millionen Schweizer Franken.

Die Mehrzahl der Bewohner – eine Mischung aus afrikanischen und europäischen Gruppen – lebt auf den Hauptinseln St. John, St. Thomas und St. Croix (allesamt Teil der Amerikanischen Jungferninseln). Allein auf St. Croix leben mehr Menschen (ca. 53.000) als auf den gesamten Spanischen (ca. 11.000) und Britischen Jungferninseln (ca. 23.000) zusammen.

Die Währung auf den gesamten Jungferninseln ist der US-Dollar.

Auf den Amerikanischen Jungferninseln ist der Tourismus der wichtigste Wirtschaftszweig.

Anders die Britischen Jungferninseln, die vor allem Steuerflüchtige anziehen. Denn dort werden keine Steuern auf Gewinne oder Einkommen erhoben. Infolgedessen ließen sich dort 430.000 Briefkastenfirmen registrieren. Die dafür zu entrichtenden Gebühren machen 60 % der Staatseinnahmen aus (Stand: 2015).

Obwohl die Fahrzeuge auf den gesamten Jungferninseln üblicherweise Linkslenker sind, herrscht auf den Spanischen Jungferninseln Rechtsverkehr. Auf den Britischen wie auch Amerikanischen Jungferninseln herrscht Linksverkehr.





</doc>
<doc id="12966" url="https://de.wikipedia.org/wiki?curid=12966" title="Amen">
Amen

Amen [] oder [] (, "amēn", ) ist eine Akklamationsformel. "Amen" drückt die eigene Zustimmung zu Gebet und Segen anderer oder die Bestätigung des Vorgebeteten in der Liturgie aus.

Das hebräische Wort "Amen" stammt aus der jüdischen Bibel. Später wurde dieses im christlichen Alten und Neuen Testament übernommen und noch später in den Islam getragen. Die Formel ist daher auch im Gebet und Gottesdienst von Christen und Muslimen üblich und einer der Begriffe, die in identischer Form im Christentum, Judentum und Islam verwendet werden.

"Amen" kann übersetzt werden mit „sich fest machen in, sich verankern in, sich ausrichten auf Gott“, denn es stammt von der hebräischen Verb-Wurzel אמן mit der Grundbedeutung „fest/zuverlässig sein“ ab, von der die hebräischen Wörter für Emuna (Glaube, Zuversicht), Treue, Verlässlichkeit, Übung, Künstler, Handwerker u. a. abgeleitet werden. Im Arabischen hat der Wortstamm آمن "ʾAmana" die gleiche Bedeutung wie die hebräische Wortwurzel.

Amen bedeutet somit viel mehr, als die übliche Übersetzung „so sei es“, weil zum einen das Hebräische weder eine Konjunktiv- noch eine Indikativform des Verbs „sein“ im Präsens kennt. Zum anderen braucht Gott nach dem jüdischen Gottesbild unsere Billigung oder Zustimmung zu vorgetragenen Hymnen, Danksagungen und Fürbitten nicht. Wichtig ist hingegen, dass das Gemeindeglied im jüdischen Gottesdienst durch sein beherztes „Amen“ sich dem Gehörten durch seine persönliche Anteilnahme entschieden anschließt und in der Gemeinschaft bekennt, dass das Gehörte für ihn persönliche Gültigkeit besitzt.

Eine bekannte Bibelstelle in Jesaja übersetzte Luther mit: „Glaubt ihr nicht, so bleibt ihr nicht.“ Dieser Satz ist ein Wortspiel des Propheten Jesaja, das zur Grundlage die Wurzel „amen“ hat. Wörtlich übersetzt lautet der Satz: „Macht ihr euch nicht fest in Gott, so werdet ihr nicht fest-stehen/werdet ihr nicht gefestigt sein.“

Je nach Sprache kann die Aussprache variieren. Die häufigste Variante neben „Amen“ ist „Amin“, etwa im Neugriechischen, Russischen und Arabischen. Seltener werden Übersetzungen des Wortes verwendet, z. B. in der Septuaginta, einer christlichen Schriftüberlieferung des Alten Testaments in griechischer Sprache. Dort findet sich das Wort γένοιτο "genoito" („es geschehe“) anstelle von "Amen". "Omain" ist die Aussprache im aschkenasischen Judentum.

Einige Theosophen und Esoteriker vermuten, dass „Amen“ eine Ableitung des Namens des ägyptischen Gottes Amun ist, der manchmal auch „Amen“ buchstabiert wird. Einige Anhänger östlicher Religionen glauben, dass „Amen“ gemeinsame Wurzeln mit dem hinduistischen Sanskrit-Wort Aum hat, bzw. dass eine tiefere Verbindung durch eine ähnliche mystische Klangwirkung beim singenden Intonieren bestehe. Es gibt keine wissenschaftliche Unterstützung für diese Ansichten.

Der Ausruf „Amen“ (אָמֵן "āmén") als Bekräftigung und persönliche Aneignung von vorher Gesagtem kommt in der jüdischen Bibel 30 Mal vor. Den Kontext bilden Fluch- oder Segensworte, Bekenntnisse, Gebete oder Lobpreisungen. „Amen“ ist stets Antwort auf das erfahrene Reden und Handeln Gottes und damit Anerkennung seiner wirkenden Macht. „Amen“ ist Teil der jüdischen Liturgie, mit dem die Betenden dem Chasan antworten. Es kommt auch bei häuslichen Gebeten vor, beispielsweise bei der Birkat Hamason (hebr. ברכת המזון), dem jüdischen Tischgebet nach dem Essen einer Mahlzeit, in der Brot enthalten ist, oder den Segenssprüchen, die vor dem Genuss von Speisen gesprochen werden, wenn ein Beter für die Tischgesellschaft oder Familie spricht und die Anwesenden mit „Amen“ bestätigen.

Die Qumranschriften sowie die Apokryphen stehen der jüdischen Tradition sehr nahe und bieten „Amen“ im Kontext von Segens- und Fluchworten (4Q286 Frg. 7), am Ende von Eulogien, Hymnen, Gebeten (4Q504 3 II 3; 4,15; 4Q507 3,2; 4Q509 4,5; 4Q511 63 IV 3) oder am Schluss eines Buches (VitAd 43,4; TestAbr 20,15[14,7]; 2Bar 17,4; ApkSedr 16,10; ApkEsr 7,16; TestHiob 53,8). „Amen“ wird besonders in den Qumranschriften zu einem festen liturgischen Element bei verschiedenen Anlässen.

Die im Christentum überlieferte Septuaginta gebraucht zur Übersetzung des hebräischen אָמֵן "āmén" in der Regel den Optativ γένοιτο "genoito" „so sei/geschehe es“, seltener ἀληθινός "alēthinos" „wahr, wahrhaftig“ oder ἀληθῶς "alēthōs" „wahrhaftig, wirklich“. Mit großer Zurückhaltung gibt sie an wenigen Stellen (, , ) das hebräische אָמֵן "āmén" mit der Transkription ἀμήν "amēn" wieder. Neu hinzu kommt seit der Septuaginta das „Amen“ am Ende einer Schrift. Vergleiche hierzu die deuterokanonischen bzw. apokryphen alttestamentlichen Bücher , und (nach den Textzeugen S und B).

Im Neuen Testament kommt das Wort 152-mal vor, jedoch meist nicht zur Bekräftigung am Ende, sondern vor einer Aussage (z. B. ); Luther (und z. B. Herder) übersetzt mit „wahrlich“, die Vulgata und die katholische Einheitsübersetzung des NT haben immer „amen“.

In christlichen Gemeinden und ihrer Glieder, wird die Formel "Amen" meist zum Ende des entsprechenden Liturgieteils, vor allem des eucharistischen Hochgebets, gemeinsam gesprochen. In der katholischen Liturgie spricht jeder Einzelne das Amen auch vor dem Empfang der Kommunion als sein persönliches Bekenntnis zur Realpräsenz Christi im geheiligten Brot und Wein („Der Leib Christi“ – „Amen“ oder „Das Blut Christi“ – „Amen“).

Im Islam spricht ein gemeinschaftliches Bittgebet jeweils nur ein Mitglied der Umma. Die anderen schließen sich am Ende mit einem „Amin“-Ruf an. Für Muslime ist das „Amin“ ein Zeichen der Dankbarkeit und die Bitte an Gott, das Gebet anzunehmen.





</doc>
<doc id="12967" url="https://de.wikipedia.org/wiki?curid=12967" title="Amerikanische Jungferninseln">
Amerikanische Jungferninseln

Die Amerikanischen Jungferninseln (, "USVI") sind nicht inkorporiertes Außengebiet der Vereinigten Staaten. Geographisch sind sie ein Teil der in der Karibik, östlich von Puerto Rico gelegenen Inselgruppe der Jungferninseln. Sie bestehen aus den drei Hauptinseln Saint Croix, Saint John und Saint Thomas. Erst 1996 kam Water Island hinzu, daneben gibt es noch zahlreiche kleinere Inseln.

Die Landschaft ist größtenteils steinig, hügelig bis gebirgig mit nur wenig ebener Fläche. Der höchste Punkt ist der Crown Mountain mit 474 m über dem Meeresspiegel.
Das Klima auf den Inseln ist tropisch. Es wird gemäßigt durch östliche Winde mit einer niedrigen Luftfeuchtigkeit und nur geringen Temperaturunterschieden über das Jahr. Die Regenzeit ist von Mai bis November. Aber auch hier sind Abweichungen möglich. Die Inseln liegen entlang der Anegada-Passage, einem Schifffahrtsweg zum Panamakanal.

Die Inseln waren in den letzten Jahren mehreren Tropenstürmen ausgesetzt. Häufig sind schwere Dürreperioden oder auch Überschwemmungen, gelegentlich ereignen sich Erdbeben. Es mangelt an natürlichen Süßwasservorkommen.

Folgende Inseln und Inselgruppen sind Teil der Amerikanischen Jungferninseln:


Die Amerikanischen Jungferninseln haben etwa 108.605 Einwohner. 42 % sind Baptisten, 34 % Katholiken und 17 % Anglikaner. 76,0 % der Bevölkerung stammt von ehemaligen afrikanischen Sklaven ab, daneben gibt es noch Menschen gemischter Herkunft (2,1 %) und einige Weiße (15,6 %) sowie Asiaten (1,4 %). Die indianischen Ureinwohner wurden noch im 16. Jahrhundert ausgerottet. Neben der Amtssprache Englisch wird ein englischbasiertes Kreolisch gesprochen. Da auf den Inseln viele Zuwanderer aus anderen karibischen Ländern leben, sind auch Spanisch und französischbasierte Kreolsprachen verbreitet.

Die Lebenserwartung auf der Insel betrug 2016 80,0 Jahre (Frauen: 83,2 Jahre/Männer: 77,0 Jahre). Das Median-Alter der Bevölkerung war mit 45,6 Jahren sehr hoch (Stand 2016). Aufgrund der hohen Anzahl an Menschen, die die Insel verlassen, sank die Bevölkerungszahl in den letzten Jahren leicht.

Quelle: UN

Die von Taíno bewohnten Inseln wurden 1493 von Christoph Kolumbus entdeckt. Am 14. November 1493 betrat er zunächst eine Insel, der er den Namen "Santa Cruz" gab (Saint Croix). Dann segelte er 70 km nach Norden zu den Inseln Saint Thomas und Saint John. Aufgrund der großen Zahl an kleineren Inseln und ihrer Schönheit nannte er sie (nach der Legende von der Heiligen Ursula und ihren 11.000 Gefährtinnen, die bei Köln ihr Martyrium erlitten haben sollen) die „Jungfraueninseln“ "(Santa Ursula y las Once Mil Vírgenes", kurz: "Las Vírgenes)". Saint Croix wurde erst später zu den Jungferninseln gezählt.

Nach Siedlungsversuchen der Engländer und Holländer auf St. Croix ab 1625 kam es zur Inbesitznahme durch Spanier und Franzosen ab 1650. 1653 wurde St. Croix von Malta übernommen, 1665 aber von Frankreich zurückerworben.

Am 30. März 1666 wurde der Dannebrog auf St. Thomas gehisst, das fortan als dänische Kolonie zu Dänemark-Norwegen gehörte "(Dänisch-Westindien)". 1672 errichteten dänische Siedler auf St. Thomas die erste ständige Siedlung, 1685 schloss der kurbrandenburgische Marine-Generaldirektor Benjamin Raule mit Vertretern der Dänisch-Westindisch-Guinesischen Compagnie einen Vertrag über die Vermietung eines Teils von St. Thomas an Brandenburg. 1689 besetzte Brandenburg die zwischen Saint Thomas und Puerto Rico liegende Krabbeninsel.

1693 beschlagnahmten die Dänen, ohne auf Widerstand zu stoßen, die brandenburgischen Faktoreien. 1694 breiteten die Siedler sich auch auf Saint John aus. Am 13. August 1720 unterzeichnete der preußische König Friedrich Wilhelm I. eine Urkunde, in der er gegenüber der holländischen Handelsgesellschaft auf alle ehemaligen brandenburgischen Gebiete in Afrika (Arguin, heute Mauretanien, und Groß Friedrichsburg an der Goldküste, heute Ghana) und St. Thomas (Jungferninseln, USA) verzichtete. 

Saint Croix, seit 1674 in französischem Besitz, wurde 1733 von Dänemark erworben. Bedeutung erlangte der Handel mit Dänisch-Westindien für die damals dem dänischen Gesamtstaat zugehörige Stadt Flensburg (vor 1864) durch den Import und die Verarbeitung von Rohrzucker. 1733 und 1848 kam es hier zum Sklavenaufstand gegen die Dänen. Weil die Vereinigten Staaten im Ersten Weltkrieg in diesem Gebiet einen Marinestützpunkt benötigten, erwarben sie die Inseln 1917 für 25 Millionen Dollar von Dänemark. Inflationsbereinigt sind dies nach heutigem Wert Millionen Dollar bzw. Millionen Euro respektive Millionen Schweizer Franken.

P.W. Sparks, ein Offizier der US Navy, entwarf die Flagge der United States Virgin Islands. Nachdem sein Vorgesetzter Admiral Kitelle dem Design zugestimmt hatte, ließ Sparks die erste Flagge von seiner Frau und deren Schwester nähen. Für den Entwurf übernahm er Symbole des Siegels, das der US-amerikanische Präsident verwendet. Sparks entschied sich dazu, dem amerikanischen Adler einen Olivenzweig als Symbol des Friedens zu geben. Die drei Pfeile stehen für die drei Inseln.

Den Einwohnern garantieren die USA seit 1927 die amerikanische Staatsbürgerschaft. Das Innenministerium der USA übernahm 1931 administrative Pflichten. Seit 1946 steht das Territorium auf der UN-Liste der Hoheitsgebiete ohne Selbstregierung.
Das Straßennetz der Inseln ist 856 km lang. Die Inseln sind das einzige Besitztum der USA mit Linksverkehr.

Saint Thomas hat einen der besten Naturhäfen der Karibik. Daneben gibt es noch Häfen in Christiansted, Cruz Bay und Port Alucroix.

Ferner gibt es drei Flughäfen:
"Downtown Heliport" auf der Insel Saint Croix, "Henry E. Rohlson Airport" auf der Insel Saint Croix und den "Cyril E. King Flughafen" auf der Insel Saint Thomas.

Der Schwerpunkt der Wirtschaft liegt auf dem Tourismus, der für mehr als 70 % des Bruttosozialprodukts und 70 % der Beschäftigungsverhältnisse sorgt. Im Schnitt besuchen jährlich zwei Millionen Touristen die Inseln. Das Bruttoinlandsprodukt pro Kopf lag 2013 bei 36.100 US-Dollar pro Kopf zwar auf dem Niveau der entwickelten Industrieländer, jedoch deutlich unter dem des US-Festlands.

Der industrielle Sektor besteht vor allem aus Erdölraffinerien und der Herstellung von Textilien, Elektronik, pharmazeutischen Produkten und der Endmontage von Uhren. Eine der weltweit größten Erdölraffinerien steht auf Saint Croix. Die Raffinerie wurde 2012 nach 45 Jahren geschlossen. 

Die Landwirtschaft ist unbedeutend; die meisten Nahrungsmittel müssen importiert werden.

Internationaler Handel und der Finanzsektor sind kleine, aber wachsende Wirtschaftsbereiche.

Die Korallenriffe im Osten der Insel St. John sind seit 2001 als "Virgin Islands Coral Reef National Monument" ausgewiesen.





</doc>
<doc id="12969" url="https://de.wikipedia.org/wiki?curid=12969" title="Tyche">
Tyche

Tyche () ist in der griechischen Mythologie die Göttin des Schicksals, der glücklichen (oder bösen) Fügung und des Zufalls. Die römische Entsprechung ist die Göttin Fortuna, die germanische Entsprechung ist das abstraktere Heil.

Tyche erhöht und erniedrigt und führt launenhaft den Wechsel der Geschichte herbei. Ihre Attribute sind Füllhorn, Ruder, Flügel und ein Steuerruder auf einer Kugel oder einem Rad. Gelegentlich hält sie auch den als Knaben dargestellten Plutos, den Gott des Reichtums, im Arm.

Die frühsten Erwähnungen finden sich in der Theogonie des Hesiod gegen 700 v. Chr. und in der Homerischen Hymne an Demeter aus der zweiten Hälfte des 6. Jahrhunderts v. Chr., die sie noch als Tochter des Oceanus beschreiben. In der zwölften olympischen Ode des Pindar um 470 v. Chr. wird sie dann hingegen die Tochter des Zeus Eleutherios genannt.

Ab der zweiten Hälfte des 5. Jahrhunderts v. Chr. ist ein Kult der (Agathe) Tyche nachweisbar. Seit dieser Zeit finden sich auch verschiedene Darstellungen der Tyche mit ihren Attributen. Bekannt ist die in Antiochien gefertigte Skulptur des Bildhauers Eutychides, die die Tyche mit der Flussgottheit des Orontes, die zu ihren Füßen auftaucht, darstellt. Für Argos, Mégara, Theben und, außerhalb Griechenlands, Bupalos und Smyrna und vielleicht Elis, Korinth, Megalopolis, Sikyon wird mit Tempeln gerechnet.

Im Hellenismus wuchs ihre Verehrung, Antiochia, Alexandria und Skythopolis verehrten sie als Stadtgöttin. Die hellenistische Entwicklung der Tyche zu einer Stadtgöttin findet dann in der römischen Fortuna ihre Fortsetzung. Auch die kleinasiatischen Städte in der römischen Kaiserzeit, wie zum Beispiel Kibyra in Phrygien, Aspendos und Side in Pamphylien und Karallia in Kilikien, verehrten ihre jeweilige Tyche weiter als Schicksalsgöttin ihrer Stadt und bildeten gelegentlich stilisierte Tempel mit dem Kultbild der Tyche "(Tycheion)" auf den Rückseiten ihrer im lokalen Zahlungsverkehr gebräuchlichen Bronzemünzen ab.

In der antiken Alltagsverwendung des Wortes schwindet dann aber die personale Vorstellung zunehmend, so dass "týche" auch „Schicksal“ und „Zufall“, „zufällige Begegnung“ bedeuten kann und schließlich sogar als eine Art Ausruf bei einem Fehler oder Versehen Verwendung findet.

Goethe ließ in den 1770er Jahren in Weimar in Anspielung auf Tyche den Stein des guten Glücks errichten.

Der 1886 entdeckte Asteroid des Hauptgürtels trägt den Namen (258) Tyche.

Seit 1999 rechnet die Astronomie mit einem hypothetischen Planeten des Sonnensystems namens Tyche.




</doc>
<doc id="12970" url="https://de.wikipedia.org/wiki?curid=12970" title="Funny van Dannen">
Funny van Dannen

Funny van Dannen (eigentlich "Franz-Josef Hagmanns-Dajka", * 10. März 1958 in Tüddern, Gemeinde Selfkant (damals unter niederländischer Verwaltung)) ist ein deutscher Liedermacher, Schriftsteller und Maler niederländischer Herkunft.

Funny van Dannen wurde als Sohn einer Niederländerin geboren. Seine Muttersprache ist limburgisch. Er lernte Grafikdesign, übte diesen Beruf jedoch nie aus. Als Jugendlicher sammelte er erste musikalische Erfahrungen mit Liedern zur Gitarre im südlimburgischen Dialekt und als Heino-Parodist zum Karneval. Als Fußball-Jugendspieler wurde er von Fortuna Sittard zu einem Probetraining eingeladen. Der Wechsel scheiterte, da der damalige Zweitligist seinem alten Klub die Ablösesumme von 11.000 DM nicht zahlen wollte. Deswegen hörte Funny van Dannen mit dem Fußballspielen auf und wurde kein Fußballprofi.

Er brach die Schule drei Monate vor dem Abitur ab und zog 1978 nach Berlin. Dort spielte er bei diversen Punk- und Jazz-Bands und stellte ab 1980 mit der Absicht, Kunstmaler zu werden, eigene Bilder aus. Zeitweise arbeitete er im "Klinikum Steglitz", heute Teil der Charité, als Kunstbeauftragter. 1984 betrieb er zusammen mit seiner Frau für zwei Jahre das "Discount / Kaufhaus für Kunst". Seit 1987 tritt er mit selbstverfassten Texten und mit deutschen Liedern zur Gitarre auf. 1988 war er neben Christiane Rösinger und Almut Klotz Mitbegründer der Lassie Singers, verließ die Band aber nach wenigen Monaten. In den folgenden Jahren finanzierte er sich durch Lesungen seiner Geschichten in Kneipen, bis 1991 in Zusammenarbeit mit Erich Maas sein Buch "Spurt ins Glück" in niedriger Auflage im Verlag Warnke & Maas erschien. 2005 erreichte sein im Verlag Antje Kunstmann erschienenes Buch "Neues von Gott" Platz 12 der Spiegel-Bestsellerliste.

Seine erste CD "Clubsongs" erschien 1995 bei Trikont und wurde live im Café Treibeis und dem Golden Pudel Club aufgenommen. Rocko Schamoni, Betreiber des Clubs, stellte einen Kontakt zu Campino her. Seit 1999 arbeitet van Dannen regelmäßig mit der Band Die Toten Hosen zusammen. Seit 2007 erscheinen seine Alben bei JKP. Eine breite Anerkennung seiner Leistungen als Maler blieb bisher aus.

Van Dannen ist verheiratet und hat vier Söhne.

Van Dannens Texte sind von Chuzpe, Ironie und Satire geprägt. Daneben gibt es verschiedene Liebeslieder. Ein häufiges Motiv bei ihm ist die Personifikation von Tieren und Gegenständen. Die meisten seiner Platten sind Livemitschnitte. Musikalisch gestaltet er seine Lieder einfach mit akustischer Gitarre und manchmal mit der Mundharmonika. Teile seines Werks sind dem Chanson zuzuordnen. Auf den Studioalben "Herzscheiße" und "Nebelmaschine" wurde er musikalisch von der "No-Goods-Band" um Peter Pichler unterstützt. Auf dem Album "Saharasand" wirkte Vincent Sorg als Produzent und Musiker mit.

1991 erschienen auf dem Debütalbum der Lassie Singers seine Lieder "Falsche Gedanken" und "Jeder ist in seiner eigenen Welt". 1996 coverte die Band "Das Regenlied".

Teilweise erfolgreicher als seine eigenen Veröffentlichungen waren die Interpretationen anderer Musiker. Dackelblut veröffentlichte 1995 "Nimm deine traurigen Lieder" auf dem Album "Schützen und Fördern". Udo Lindenberg coverte 1996 auf dem Album "Und ewig rauscht die Linde" die Lieder "Nana Mouskouri" und "Gutes tun". Die Schröders machten 1997 auf ihrem Album "Gilp" das Lied "Saufen" einem breiten Publikum bekannt. Rantanplan spielten 1998 für das Album "Köpfer" eine Version des Liedes "Unbekanntes Pferd" ein.

Seit 1999 ist van Dannen an verschiedenen Liedern auf den Alben "Unsterblich", "Auswärtsspiel", "Reich & sexy II", "Zurück zum Glück" und "Nur zu Besuch" von Die Toten Hosen beteiligt, darunter die Chartsingles "Bayern" (DE #8), "Schön sein" (DE #9) und "Walkampf" (DE #24).

2000 interpretierten Queen Bee "Freundinnen" und "Homebanking". Japanische Kampfhörspiele coverten 2005 "Menschenverachtende Untergrundmusik" für das Album "Deutschland von vorne". 2005 verwendete Doris Metz den Titel "Als Willy Brandt Bundeskanzler war" für ihren Dokumentarfilm "Schattenväter" mit Pierre Boom und Matthias Brandt. Wiglaf Droste nahm einige Titel van Dannens mit ihm, sowie "Nana Mouskouri" und "Unbekanntes Pferd" zusammen mit dem Spardosen-Terzett auf. Franz Wittenbrink verwendete einige Lieder für das Theaterprojekt "Mütter". 2006 coverte Fitzoblong auf dem Album "Im Club der Melancholie" einige Lieder. 2007 schrieb van Dannen die Lieder "Staub" und "Nachtigall" für das Album "20359" der Band Rantanplan.





</doc>
<doc id="12971" url="https://de.wikipedia.org/wiki?curid=12971" title="Zink">
Zink

Zink ist ein chemisches Element mit dem Elementsymbol Zn und der Ordnungszahl 30. Zink wird zu den Übergangsmetallen gezählt, nimmt aber darin eine Sonderstellung ein, da es wegen der abgeschlossenen d-Schale in seinen Eigenschaften eher den Erdalkalimetallen ähnelt. Nach der veralteten Zählung wird die Zinkgruppe als 2. Nebengruppe bezeichnet (analog zu den Erdalkalimetallen als 2. Hauptgruppe), nach der aktuellen IUPAC-Nomenklatur bildet Zink mit Cadmium, Quecksilber und dem ausschließlich in der Forschung relevanten Copernicium die Gruppe 12. Es ist ein bläulich-weißes sprödes Metall und wird unter anderem zum Verzinken von Eisen und Stahlteilen sowie für Regenrinnen verwendet. Zink ist für alle Lebewesen essentiell und ist Bestandteil wichtiger Enzyme. Der Name Zink kommt von "Zinke, Zind" („Zahn, Zacke“), da Zink zackenförmig erstarrt.

Bereits im Altertum war Zink als Legierungsbestandteil von Messing in Gebrauch. Als eigenständiges Metall wurde es jedoch erst im 17. Jahrhundert in Indien entdeckt und verarbeitet. Bereits in dem 1679 erbauten Messinghof in Kassel wurde "Galmei" verhüttet. Im Jahre 1743 wurde in Bristol eine erste Zinkhütte in Betrieb genommen. Weitere entstanden im 19. Jahrhundert in Oberschlesien, z. B. Georg von Giesche bzw. deren Nachfolgefirma, im Aachen-Lütticher Raum sowie in Obersachsen und in Westfalen. Im Ruhrgebiet entstanden die ersten Hütten 1845 in Mülheim an der Ruhr und 1847 in Borbeck (heute Essen).

Zink ist auf der Erde mit einem Gehalt von 0,0076 % (oder 76 ppm) an der Erdkruste ein relativ häufiges Element. Wenn man die Elemente nach Häufigkeit ordnet, steht es damit an 24. Stelle. Es ist häufiger als Kupfer oder Blei. Zink kommt zwar nur selten gediegen vor, ist jedoch als Mineral meist anerkannt. Bisher sind rund 30 registrierte Fundorte für gediegen Zink bekannt.

Überwiegend findet sich Zink gebunden in Erzen. Die häufigsten und für die Zinkgewinnung wichtigsten Erze sind dabei Zinksulfiderze. Diese kommen natürlich entweder als Sphalerit oder Wurtzit vor und enthalten etwa 65 % Zink. Ein weiteres Zinkerz ist Galmei womit sowohl Smithsonit (auch "Zinkspat") ZnCO (ca. 52 % Zink) als auch Willemit Zn[SiO] bezeichnet werden. Daneben existieren noch seltenere Zinkmineralien wie unter anderem Zinkit (auch "Rotzinkerz") ZnO (ca. 73 % Zink), Hemimorphit Zn(OH)<nowiki>[</nowiki>SiO<nowiki>]</nowiki> (54 % Zink), Adamin Zn(AsO)(OH) (ca. 45 % Zink), Minrecordit CaZn[CO] (ca. 29 % Zink) und Franklinit (Zn,Fe,Mn)(FeMn)O (16 % Zink). Insgesamt sind zurzeit (Stand: 2010) über 300 Zink-Minerale bekannt.

Große Lagerstätten existieren in Nordamerika (Vereinigte Staaten, Kanada), Australien, der Volksrepublik China und Kasachstan.
Auch in Deutschland gab es Zinkerzlagerstätten, beispielsweise in Brilon, im Raum Eschweiler-Stolberg im Rheinland, am Rammelsberg im Harz, Freiberg oder bei Ramsbeck im Sauerland. Oberirdisch kann man in diesen Gebieten seltene Pflanzen finden, die auf zinkhaltigen Böden besonders gut wachsen, wie das gelbe Galmeiveilchen, das nach dem alten Namen für das Zinkerz Smithsonit ("Galmei") benannt ist.

Zinkerze werden hauptsächlich in der Volksrepublik China, Australien, Peru, Indien, den Vereinigten Staaten, Mexiko und Kanada gefördert. In Europa sind noch einige Zinkminen in Irland, Polen, Finnland, Bulgarien und Schweden aktiv. Die Gesamtproduktion an Zink belief sich 2015 auf 13,4 Millionen Tonnen, weitere 14 Millionen Tonnen wurden aus Recycling gewonnen. Die bedeutendste Firma für die Gewinnung von Zink ist die schweizerische Nyrstar.

Zink wird überwiegend aus Zinksulfid-Erzen gewonnen. Um diese zu verwenden, müssen sie zunächst in Zinkoxid umgewandelt werden. Dies geschieht durch Rösten an der Luft. Dabei entstehen neben dem Zinkoxid große Mengen Schwefeldioxid, die zu Schwefelsäure weiterverarbeitet werden können.

Wird Smithsonit als Rohstoff verwendet, kann dies durch Brennen unter Abspaltung von Kohlenstoffdioxid erfolgen.

Die Weiterverarbeitung kann durch zwei mögliche Verfahren geschehen. Dies sind das "nasse" und das "trockene" Verfahren. Über das trockene Verfahren werden heutzutage nur noch etwa 10 % der weltweite produzierten Zinkmenge gewonnen. Dabei wird das Zinkoxid mit feingemahlener Kohle vermengt und in einem Gebläseschachtofen (Imperial-Smelting-Ofen) auf 1100–1300 °C erhitzt. Dabei bildet sich zunächst Kohlenstoffmonoxid. Dieses reduziert dann das Zinkoxid zu metallischem Zink. Aus dem entstandenen Kohlenstoffdioxid bildet sich nach dem Boudouard-Gleichgewicht wiederum Kohlenstoffmonoxid.

Da im Ofen Temperaturen oberhalb des Siedepunktes von Zink herrschen, entweicht das Zink als Dampf am oberen Ende des Ofens. Dort wird nun Blei eingesprüht und das Zink so auskondensiert.

Das hierbei entstandene Rohzink enthält große Mengen Verunreinigungen, insbesondere Blei, Eisen und Cadmium. Durch fraktionierte Destillation kann das Rohzink weiter gereinigt werden. In einer ersten Stufe wird das Rohprodukt so erhitzt, dass nur Zink und Cadmium verdampfen, während Eisen und Blei zurückbleiben. Cadmium und Zink können durch Kondensation voneinander getrennt werden. Dabei kondensiert Zink bei höheren Temperaturen und bildet so 99,99 % reines Feinzink. Cadmium ist leichter flüchtig und wird an einer anderen Stelle als Cadmiumstaub gesammelt. Als Nebenprodukt der Destillation entsteht feinpulvriges Zink, der sogenannte Zinkstaub.

Das nasse Verfahren wird angewendet, wenn dafür billiger elektrischer Strom bereitsteht. Für das Verfahren wird das rohe Zinkoxid in verdünnter Schwefelsäure gelöst. Verunreinigungen von edleren Metallen wie Cadmium werden durch Zinkpulver ausgefällt. Anschließend wird die Lösung unter Verwendung von Bleianoden und Aluminiumkathoden elektrolysiert. Es entsteht an der Kathode wie beim trockenen Verfahren 99,99 % reines Elektrolysezink.

Zink ist ein bläulich weißes, unedles Metall, welches bei Zimmertemperatur und oberhalb 200 °C ziemlich spröde ist. Zwischen 100 und 200 °C ist es jedoch recht duktil und lässt sich leicht verformen. Sein Bruch ist silberweiß. Zink kristallisiert in einer hexagonal-dichtesten Kugelpackung. Diese ist allerdings senkrecht zu den Kugelschichten gestreckt, die Abstände zwischen den Zinkatomen unterscheiden sich leicht (in einer Schicht 264,4 pm, zwischen den Schichten 291,2 pm).

An der Luft bildet Zink eine witterungsbeständige Schutzschicht aus Zinkoxid und -carbonat (Zn(OH)(CO)). Daher verwendet man es trotz seines unedlen Charakters als Korrosionsschutz (Verzinken von Eisen). Zink löst sich in Säuren unter Bildung von Zink(II)-Salzen und in Laugen unter Bildung von Zinkaten, [Zn(OH)], auf. Eine Ausnahme ist Zink mit sehr hoher Reinheit (99,999 %), welches nicht mit Säuren reagiert. Zink liegt in seinen Verbindungen fast ausnahmslos in der Oxidationsstufe +II vor.

Chemisch zählt Zink zu den unedlen Metallen (Redoxpotential −0,763 Volt). Dies kann beispielsweise dafür ausgenutzt werden, edlere Metalle aus ihren Salzen durch Reduktion elementar abzuscheiden, wie hier am Beispiel der Umsetzung eines Kupfersalzes gezeigt wird:

In Pulverform ist Zink ein selbst entzündbarer (pyrophorer) Feststoff. Er kann sich bei Raumtemperatur an der Luft ohne Energiezufuhr erhitzen und schließlich entzünden. Die Zündbereitschaft hängt unter anderem sehr stark von der Korngröße und dem Verteilungsgrad ab.
Zinkpulver bildet bei Kontakt mit Wasser entzündbare Gase, die sich spontan entzünden können.

Von Zink sind insgesamt 31 Isotope von Zn bis Zn und weitere elf Kernisomere bekannt. Davon sind fünf, die Isotope Zn, Zn, Zn, Zn und Zn stabil und natürlich. Es gibt keine radioaktiven natürlichen Isotope. Das häufigste Isotop ist Zn mit 48,63 % Anteil am natürlichen Isotopenverhältnis. Danach folgen Zn mit 27,90 %, Zn mit 18,75 %, Zn mit 4,10 % und als seltenstes natürliches Isotop Zn mit einem Anteil von 0,62 %. Das stabilste künstliche Isotop ist der Beta- und Gammastrahler (K/β-Zerfall) Zn mit einer Halbwertszeit von 244 Tagen. Dieses und das Kernisomer dienen als Tracer. Als einziges natürliches Isotop kann Zn durch die NMR-Spektroskopie nachgewiesen werden.

"→ Liste der Zink-Isotope"

Im Jahr 2006 wurden über elf Millionen Tonnen Zink verbraucht. Davon wurden 47 % für den Korrosionsschutz von Eisen- und Stahlprodukten durch "Verzinken" genutzt. Nach Verbrauchsmengen bedeutendstes Einsatzgebiet sind dessen Legierungen, vorzugsweise solche mit Kupfer, wie Messing, oder mit Aluminium, entweder als AlZn-Legierung oder mit deutlich höheren Zinkgehalten als Alzen, das für im Sandguss und Kokillenguss hergestellte Teile verwendet wird. Auch in den genormten Magnesiumlegierungen ist Zink mit bis zu 5 % enthalten. Ungleich bedeutender sind die genormten Feinzink-Gusslegierungen, die überwiegend im Druckgießverfahren, aber auch in Sand und Kokille vergossen werden. Auch zu Walzmaterial wie Zinkblechen werden Zinklegierungen verarbeitet.

Zink wird seit langem als Korrosionsschutz (Rostschutz) für Stahl- und Eisenteile verwendet, indem man sie verzinkt, d. h. mit einem metallischen Überzug aus Zink überzieht. Das Zink schützt aktiv und passiv gegen Korrosion, d. h., es bildet einerseits eine Barriere und schützt andererseits auch freiliegende benachbarte Eisenflächen sowie Schichtfehler vor Korrosion, indem es wie eine Opferanode wirkt.

Die Verzinkung kann auf verschiedene Weisen erfolgen. Methoden sind das Feuerverzinken, die galvanische Verzinkung, mechanische Beschichtungen, Spritzverzinken und Zinklamellenüberzüge. Sie unterscheiden sich in der Art des Aufbringens der Zinkschicht, der Dicke und damit der Haltbarkeit.

Die älteste Verzinkungsmethode ist das diskontinuierliche Feuerverzinken (Stückverzinken). Dabei werden vorbehandelte und vorgefertigte Bauteile aus Stahl (z. B. Balkongeländer) in ein Bad mit flüssigem Zink getaucht. In den 1930er Jahren kam als Verfahrensvariante das kontinuierliche Feuerverzinken (Bandverzinken) erstmals zur Anwendung, bei dem Bänder aus Stahl im Durchlaufverfahren als Halbzeug verzinkt und danach erst weiterverarbeitet werden. Durch Stückverzinken entstehen Zinkschichten, die in der Regel zwischen 50 und 150 µm liegen und abhängig von den atmosphärischen Bedingungen für Jahrzehnte vor Korrosion schützen. Bandverzinkte Bleche weisen sehr dünne Zinkschichtdicken zwischen 7 und 25 µm auf und erreichen deshalb nur deutlich kürzere Schutzzeiträume. Die Schutzdauer von feuerverzinktem Stahl kann durch eine zusätzliche Beschichtung (Duplex-System) weiter gesteigert werden.

Beim galvanischen Verfahren wird die Zinkschicht elektrolytisch aufgebracht. Dazu wird das Werkstück gemeinsam mit einem Stück reinem Zink in eine saure oder basische Lösung eines Zinksalzes getaucht. Danach wird Gleichspannung angelegt, wobei das Werkstück die Kathode, das Stück Zink die Anode bildet. Am Werkstück wird durch Reduktion von Zinkionen Zink gebildet. Gleichzeitig wird das reine Zink der Anode oxidiert, die Anode löst sich dabei auf. Es entsteht eine dichte Zinkschicht, die in der Praxis 2,5 bis zu 25 µm. beträgt und somit deutlich geringer ist als beim diskontinuierlichen Feuerverzinken. Die Zinkschicht könnte theoretisch beim galvanischen Verfahren auch auf die Dicke einer feuerverzinkten Schicht gebracht werden. Allerdings wäre dies nicht mehr wirtschaftlich aufgrund der Dauer (ca. 0,5 µm in einer Minute) und der Energiekosten.

Beim Spritzverzinken wird das Zink geschmolzen und dann mit Hilfe von Druckluft auf das Werkstück aufgesprüht. Die thermische Belastung ist dabei geringer als beim Feuerverzinken. Dies kann für empfindliche Werkstoffe wichtig sein. Wird das Zink mechanisch auf das Werkstück aufgetragen, spricht man vom Plattieren. Ein Verfahren, das für Verzinken von Kleinteilen, etwa Schrauben, angewendet wird, ist das Sherardisieren. Dabei entsteht die Zinkschicht durch Diffusion von Zink in das Eisen des Werkstücks. Eine weitere mögliche Auftragungsart von Zinkschichten sind Zinksprays.

Zink wird als Opferanode zum Schutz größerer Stahlteile genutzt. Dabei wird das zu schützende Objekt leitend mit dem Zink verbunden. Es entsteht eine galvanische Zelle mit Zink als Anode und dem Objekt als Kathode. Da nun das unedle Zink bevorzugt oxidiert wird und sich dabei langsam auflöst, bleibt das Stahlteil unverändert. Solange Zink vorhanden ist, ist somit das Stahlstück vor Korrosion geschützt.

Aufgaben des Korrosionsschutzes haben auch die Weiß- und Farbpigmente auf Basis von Zinkverbindungen. Zinkverbindungen sind auch Bestandteil der Phosphatierungsmittel (Phosphatierung), die Verfahren, wie das Bondern von Blechen erst ermöglichen.

Metallisches Zink gehört zu den wichtigsten Materialien für negative Elektroden (Anoden) in nicht wiederaufladbaren Batterien und wird in großtechnischem Maßstab eingesetzt. Beispiele sind Alkali-Mangan-Batterien, Zink-Kohle-Batterien, Zink-Luft-Batterien, Silberoxid-Zink-Batterien und Quecksilberoxid-Zink-Batterien. Zink wurde auch als Anode in vielen historischen galvanischen Elementen verwendet. Dazu zählen unter anderen die Voltasche Säule, das Daniell-Element und das Bunsen-Element. In geringem Umfang wird Zink auch für negative Elektroden in Akkumulatoren (wiederaufladbaren Batterien) verwendet.

Der Grund für die vielfältige Verwendung von Zink in Batterien liegt in der Kombination von physikalischen und elektrochemischen Eigenschaften mit guter Umweltverträglichkeit und relativ niedrigen Kosten. Zink ist ein gutes Reduktionsmittel mit hoher theoretischer Kapazität (0,82 Ah/g). Aufgrund des niedrigen Standardpotenzials von etwa −0,76 V beziehungsweise in alkalischem Medium −1,25 V lassen sich relativ hohe Zellspannungen realisieren. Ferner hat Zink eine gute elektrische Leitfähigkeit und ist in wässrigen Elektrolytlösungen ausreichend stabil.

Um die Korrosion von Zink in der Batterie zu reduzieren und zur Verbesserung der elektrochemischen Eigenschaften wurde früher amalgamiertes Zink mit einem Quecksilbergehalt von bis zu 9 Prozent eingesetzt. Aus Umweltschutzgründen wurde diese Praxis zumindest in Industrieländern nahezu vollständig eingestellt. Im Jahr 2006 wird amalgamiertes Zinkpulver nur noch in Zink-Luft- und Silberoxid-Zink-Knopfzellen verwendet.

Die Anode in Zink-Kohle-Batterien hat die Form eines Zinkbechers. Die Becher werden durch mehrstufiges Tiefziehen aus Zinkblech oder durch schlagartige Verformung (englisch "impact extrusion") von runden oder sechseckigen Scheiben aus dickem Zinkblech (sogenannten Kalotten) hergestellt. Zur Verbesserung der Formbarkeit und zur Hemmung der Korrosion enthält das hierfür verwendete Zink geringe Mengen an Cadmium, Blei und/oder Mangan. In Alkali-Mangan-Batterien wird Zinkpulver als aktives Material in der Anode verwendet. Es wird meist durch Verdüsung von geschmolzenem Zink im Luftstrahl hergestellt. Zur Hemmung der Korrosion werden dem Zink geringe Mengen anderer Metalle beigemischt. Zu diesen zählen beispielsweise Blei, Bismut, Indium, Aluminium und Calcium.

Wichtige Zinkprodukte sind auch Halbzeuge, meist in Form von Blechen aus legiertem Zink/ Titanzink. Titanzinkblech wird als Werkstoff im Bauwesen verwendet. Heute wird dabei fast ausschließlich Titanzink verwendet, welches korrosionsfester, weniger spröde und dadurch mechanisch deutlich belastbarer ist als unlegiertes Zink bzw. das bis vor ca. 50 Jahren übliche Zinkblech, dass in sogenannten Paketwalzverfahren hergestellt worden ist. Gewalztes, massives Titanzinkblech wird hauptsächlich zur Dacheindeckung, als Fassadenbekleidung, für die Dachentwässerung (Regenrinnen, Fallrohre), für Abdeckungen z. B. von Gesimsen oder Außenfensterbänken oder für Anschlüsse und Dachkehlen eingesetzt. Es hält bis zu 100 Jahre und muss in dieser Zeit weder gewartet noch repariert werden, wenn es fachgerecht verarbeitet wurde. Die Verarbeitung erfolgt durch das Klempnerhandwerk.

Zinkblech sollte nicht verwechselt werden mit feuerverzinktem Stahlblech, welches fälschlich auch des Öfteren "Zinkblech" oder Weißblech genannt wird.

Legiertes Zinkblech wird in Coils oder in Tafeln geliefert. Für die Dachdeckung werden oft Metallbahnen (Schare) verwendet, die zwischen 40 und 60 Zentimeter breit sind und bis zu 16 Meter lang sein können. Die Materialdicke ist unterschiedlich, beträgt jedoch meist 0,7 Millimeter. Die Verbindung der einzelnen Blechteile erfolgt bei kleinteiligen Elementen meist durch Löten, bei Dachdeckungen meist durch doppeltes Falzen (Doppelstehfalzdeckung). Aufgrund der Wärmeausdehnung von legiertem Zink von 22·10/K müssen die Verbindungen und Anschlüsse der Zinkprofile Materialbewegungen zulassen.

Moderne Architekten verwirklichen mit Titanzink extravagante Ideen. Daniel Libeskind hat z. B. das Jüdische Museum Berlin oder die Libeskind-Villa in Datteln mit einer Fassade aus Bauzink ausgestattet. Zaha Haddid wählte den Werkstoff für das Transport Museum in Glasgow, welches die Verformungseigenschaften des Werkstoffes eindrucksvoll zeigt.

Zinkdruckguss ist die gebräuchliche Bezeichnung für im Druckgießverfahren hergestellte Teile aus Feinzink-Gusslegierungen. Diese Legierungen erbringen weitaus bessere Werte der Gussteile, als es beim Vergießen von reinem Zink möglich ist. Die Legierungen sind genormt. Viel verwendet wird die Legierung GD ZnAl4Cu1 (Z 410). Zinkdruckguss ermöglicht – wie jedes Druckgießverfahren – die Fertigung großer Stückzahlen. Die Gussteile zeichnen sich durch hohe Maßhaltigkeit aus, besitzen sehr gute mechanische Werte und sind für eine Oberflächenbehandlung wie Vernickeln oder Verchromen gut geeignet. Das Spektrum der Anwendungen umfasst Automobilzubehörteile und solche im Maschinen- und Apparatebau, ferner Beschläge aller Art, Teile für die Sanitärindustrie, für Feingeräte- und Elektrotechnik, für Metallspielwaren und viele Gebrauchsgegenstände im Haushalt.

Da Zink als Münzmetall vergleichsweise wenig kostet, wurde es in Notzeiten, zuletzt in den beiden Weltkriegen, in Form von Zinklegierungen zur Münzprägung verwendet, teilte sich diese Verwendung als sog. „Kriegsmetall“ aber mit Münzen aus einer Aluminiumlegierung. Seit 1982 besteht auch der US-Cent (Penny) im Kern aus Zink.

Analysenreines Zinkpulver dient als Urtitersubstanz nach Arzneibuch zur Einstellung von EDTA-Maßlösungen.

In der Organischen Synthese dient es verschiedenen Zwecken. So fungiert es als Reduktionsmittel und kann als solches in unterschiedlicher Weise aktiviert sein. Ein Beispiel ist die Clemmensen-Reduktion von Carbonylverbindungen mit amalgamiertem Zink. Des Weiteren lassen sich Allylalkohole zu Alkenen reduzieren, Acyloine zu Ketonen. Die Reduktion der aromatischen Nitrogruppe kann in Abhängigkeit von den Reaktionsbedingungen zu unterschiedlichen Produkten führen: Arylamin, Arylhydroxylamin, Azoaren, "N,N’"-Diarylhydrazin.

Im metallorganischen Bereich bieten Zinkorganyle gegenüber Grignard-Verbindungen Selektivitätsvorteile, da sie in der Regel weniger reaktiv sind und mehr funktionelle Gruppen tolerieren – ein Umstand, von dem die Reformatzky-Reaktion Gebrauch macht. Die Organyle lassen sich auf direkte Weise oder durch Transmetallierung herstellen. In Gegenwart asymmetrisch komplexierender Auxiliare, von denen mitunter katalytische Mengen ausreichen, ist eine stereoselektive Addition möglich. Der Effekt der Chiralitätsverstärkung wurde beobachtet.

Nicht zuletzt ist die Halogeneliminierung und Dehalogenierung möglich. Die Simmons-Smith-Reaktion zählt zu den selteneren Präparationsmethoden. Die Zeitschrift "Organic Syntheses" verzeichnet eine Reihe von Synthesen, in denen elementares Zink als Reagenz dient.

Zink wird im sogenannten Solzinc-Verfahren zur Herstellung von Wasserstoff genutzt. Hierzu wird in einem ersten Schritt Zinkoxid thermisch durch Sonnenenergie in Zink und Sauerstoff aufgespalten, und in einem zweiten Schritt wird das so gewonnene Zink mit Wasser zu Zinkoxid und Wasserstoff umgesetzt.

Zink zählt zu den unentbehrlichen (essentiellen) Spurenelementen für den Stoffwechsel. Es ist Bestandteil einer Vielzahl von Enzymen, beispielsweise der RNA-Polymerase und der Carboanhydrase. Zink erfüllt im Körper viele verschiedene Funktionen. So nimmt es Schlüsselrollen im Zucker-, Fett- und Eiweißstoffwechsel ein und ist beteiligt am Aufbau der Erbsubstanz und beim Zellwachstum. Sowohl das Immunsystem als auch viele Hormone benötigen Zink für ihre Funktion. Zink fördert das Immunsystem u. a. durch eine Abschwächung der Immunreaktion bei überschießenden Reaktionen des Immunsystems. Zink ist ebenfalls Bestandteil von Zinkfingerproteinen, die wichtige Transkriptionsfaktoren sind. Im Blut ist Zink überwiegend an Albumin gebunden.

Die empfohlene Tagesmenge für Zink liegt laut Weltgesundheitsorganisation für erwachsene Männer bei 15 mg, für Frauen bei 12 mg, für präpubertäre Kinder bei 10 mg und für Säuglinge bei 5 mg. Weil der Körper weniger Zink aufnehmen kann als vermutet - nur 30 Prozent können absorbiert werden - hat die Deutsche Gesellschaft für Ernährung die empfohlene Zinkmenge für erwachsene Männer auf 10 mg pro Tag, für erwachsene Frauen auf 7 mg pro Tag gesenkt.
In den Vereinigten Staaten beträgt die Aufnahme durch Nahrung gegenwärtig 9 mg/Tag für Frauen und 14 mg/Tag für Männer. Eine anhaltende erhöhte Zinkzufuhr kann zu Kupfermangel und Störungen in der Blutbildung führen.

Der empfohlene Tolerable Upper Intake Level der Europäischen Behörde für Lebensmittelsicherheit liegt bei 25 mg Zink pro Tag, das "Standing Committee on the Scientific Evaluation of Dietary Reference Intakes of the Food and Nutrition Board, Institute of Medicine, National Academy of Sciences" empfiehlt für Erwachsene 40 mg/Tag als Tolerable Upper Intake Level. Laut der Zeitschrift Ökotest empfiehlt das Bundesinstitut für Risikobewertung eine tägliche Aufnahme von höchstens 2,25 mg Zink über Nahrungsergänzungsmittel. Daneben betrachtet es 25 mg/Tag ebenfalls als tolerable obere Aufnahmemenge.

Eine Zufuhr von mehr als 100 mg pro Tag ist nicht empfehlenswert, ab 200 mg können Symptome wie Übelkeit, Erbrechen oder auch Durchfall auftreten. Beim Menschen führt die Aufnahme von Zink ab etwa 2 g zu akuten Vergiftungserscheinungen. Zinkpräparate sollten nur bei Zinkmangel (siehe unten) und erhöhtem Zinkbedarf (z. B. nach Operationen, Traumata oder Verbrennungen) eingenommen werden.

Wird Zink in hoher Dosis aufgenommen, indem z. B. beim Brennschneiden verzinkter Stähle Zinkdämpfe eingeatmet werden, so entsteht das sogenannte „Zinkfieber“. Hierbei entwickelt der Vergiftete grippeähnliche Symptome mit zum Teil starken Fieberanfällen. Die Symptome klingen im Allgemeinen nach 1–2 Tagen wieder ab.

Eine 2005 auf einer Konferenz der US-amerikanischen Gesellschaft für Ernährungswissenschaften in San Diego vorgestellte Studie deutet darauf hin, dass Kinder, die täglich die doppelte empfohlene Tagesdosis Zink erhalten (20 mg), eine deutliche Verbesserung der geistigen Leistungsfähigkeit erfahren. Zink verbesserte das visuelle Gedächtnis, die Leistungen in einem Wortfindungstest und die Konzentrationsfähigkeit.

Das Spurenelement kann im Körper nicht gespeichert werden, es muss regelmäßig von außen zugeführt werden. Aufgrund von falschen Ernährungsgewohnheiten ist Zinkmangel auch in westlichen Ländern nicht selten, insbesondere bei Säuglingen, Senioren, Jugendlichen und Frauen im gebärfähigen Alter. Es wird geschätzt, dass weltweit zwei Milliarden Menschen an Zinkmangel leiden und dass dieser Mangel mitverantwortlich für den Tod von einer Million Kinder pro Jahr ist.

Zinkmangel führt zu einer Unterfunktion der Keimdrüsen, Wachstumsstörungen und Blutarmut. Ein niedriger Zinkspiegel äußert sich oft auch durch eine verringerte Abwehrfunktion, Haarausfall, trockene Haut und brüchige Nägel. Bei Haushunden treten zink-reaktive Dermatosen auf. Zinkmangel kann zu Unfruchtbarkeit beim Mann führen.
Zinkmangel wird häufig durch einen hohen Kupferspiegel verursacht (z. B. bei reichlichem Trinkwassergenuss aus häuslichen Kupferrohrnetzen), da Zink und Kupfer Antagonisten sind. Selbiges gilt für Eisen, z. B. durch eine sehr eisenreiche Ernährung oder die Einnahme von eisenhaltigen Medikamenten. Die Aufnahme von Zink (wie auch anderen Metallionen) aus dem Darm wird ebenfalls durch phytinsäurehaltige Nahrungsmittel vermindert.

Folgende Nahrungsmittel sind gute Zinkquellen:

Erdnüsse enthalten zwar relativ viel Zink (ca. 3 mg pro 100 g), aber wie andere Hülsenfrüchte auch viel Phytinsäure, welche die Aufnahme behindert. Gleiches gilt für Ölsaaten und Vollkornprodukte.

Tabelle für Lebensmittel mit

Zink wirkt auf den Stoffwechsel der Darmzellen dahingehend, dass weniger Kupfer resorbiert wird. Zinksalze (z. B. Zinksulfat, Zinkacetat) eignen sich daher als Arzneistoffe in der Behandlung des Morbus Wilson, einer Erkrankung, bei der der Kupferstoffwechsel in der Leber gestört ist und es dadurch zu einer vermehrten Ansammlung von Kupfer in der Leber, dem Auge, dem Zentralnervensystem und anderen Organen kommt. Zinkhaltige Salben werden bei der Wundheilung und Hautausschlägen (Ekzeme) angewendet.

Eine oft zitierte Metastudie des indischen Institute of Medical Education and Research, die belegen sollte, dass Zink bei Erkältungskrankheiten eine mildernde und die Krankheitsdauer verkürzende Wirkung habe, wies so schwerwiegende Mängel auf, dass sie durch die Cochrane Collaboration zurück gezogen wurde. Ältere Untersuchungen konnten eine positive Wirkung ebenfalls nicht nachweisen.

2004 gaben World Health Organization (WHO) und die United Nations Children’s Fund (UNICEF) eine Stellungnahme zur Behandlung akuter Diarrhöe (Durchfall) ab, in der sie die gemeinsame Behandlung mit Zink und oraler Rehydrationslösung (ORS) empfahlen. Auch eine Meta-Analyse der Cochrane Collaboration stellte eine positive Wirkung von Zink bei der Behandlung von Diarrhöe bei Kindern fest, eingeschränkt auf Kinder über sechs Jahren und aus Regionen mit potenzieller Zink-Unterversorgung.

Beispiele für pharmazeutisch genutzte Zinksalze: Zinkacetat, Zinkacexamat, Zinkchlorid, Zinkgluconat, Zinkoxid, Zinkstearat, Zinksulfat, Zinkundecylenat.

Ein einfacher Zinknachweis beruht auf dem Erhitzen einer Probe mit wenigen Tropfen einer verdünnten Lösung eines Cobaltsalzes auf einer Magnesiarinne im Bunsenbrenner. Ist Zink zugegen, ist nach kurzer Zeit das so genannte Rinmans Grün zu erkennen.

Die quantitative Bestimmung kann mittels Komplexometrie mit einer EDTA-Maßlösung erfolgen. Zur Spurenbestimmung kommen die verschiedenen Methoden der Polarographie in Frage. Im Ultraspurenbereich setzt man die Graphitrohr-AAS ein. Zink ist ein relativ leicht flüchtiges Element, weshalb Matrixmodifizierer wie Palladium- und Magnesiumnitrat von Bedeutung sind, weil sie die mögliche Pyrolysetemperatur heraufsetzen. Alternativ bieten sich die Inversvoltammetrie oder die ICP-MS als äußerst empfindliche instrumentelle Methoden an.

"→ Kategorie: "





</doc>
<doc id="12972" url="https://de.wikipedia.org/wiki?curid=12972" title="Dornbirn">
Dornbirn

Dornbirn (lokales Vorarlbergerisch: []) ist die bevölkerungsreichste Stadtgemeinde im österreichischen Bundesland Vorarlberg und zugleich Sitz der Bezirkshauptmannschaft Dornbirn. Die Stadt ist ein wirtschaftliches Zentrum des westlichsten österreichischen Bundeslandes und ein regionaler Verkehrsknotenpunkt. Mit ihren  Einwohnern (Stand ) ist Dornbirn die zehntgrößte Stadt Österreichs und die größte ohne eigenes Statut.

Die Bedeutung der Stadt entwickelte sich erst relativ spät Ende des 19. Jahrhunderts mit dem Aufblühen der Textilindustrie, die Dornbirn rasch zur größten Gemeinde zwischen Alpenrhein und Arlberg machte.

Dornbirn liegt auf 437 Metern Höhe im Rheintal am Fuße des Bregenzerwaldgebirges und damit am westlichen Rande der Ostalpen. Der mit Abstand wichtigste Fluss ist die Dornbirner Ach, die das Ortsgebiet in zwei Hälften teilt und damit auch die Grenze einiger Stadtbezirke bildet.

Der größte Teil des Dornbirner Siedlungsgebiets liegt direkt auf dem Sedimentfächer der Dornbirner Ach. Durch die Lage im Rheintal befindet sich die Gemeinde geologisch gesehen im so genannten Bodenseebecken, welches zum Teil tektonisch entstanden ist, andererseits aber durch Erosionen des nach der letzten Eiszeit zurückweichenden Rheingletschers gebildet wurde. Das Bodenseebecken bildet den Untergrund, auf dem sich die von der Dornbirner Ach angeschwemmten Sedimente ablagern konnten und somit den heutigen Untergrund Dornbirns bestimmen. Im Osten des Gemeindegebiets erheben sich die ersten Berge der Ostalpen, die hier zum größten Teil noch aus brüchigen Diluvialmassen bestehen.

Die allgemeine Seehöhe der Stadt Dornbirn wird mit angegeben. Dies entspricht der Lage des steinernen Stadtwappens, das in der Mitte des Marktplatzes eingelassen ist. Den geografisch niedrigsten Punkt Dornbirns bildet das Flussbett der Dornbirner Ach wenige Meter vor der Einmündung des Vorarlberger Rheintal-Binnenkanals im äußersten Norden des Gemeindegebiets mit Der höchste Punkt ist der Gipfel der Sünser Spitze mit 

Dornbirn ist nicht aus ehemals eigenständigen Dörfern zusammengewachsen, sondern war immer eine einzige Gemeinde, deren Siedlungsgebiete allerdings sehr zerstreut waren und mit den heutigen Bezirken 1 bis 4 aus vier nicht zusammenhängenden Teilen bestanden. Diese „Viertel“ hießen damals noch "Niederdorf", "Hatlerdorf", "Oberdorf" und "Stiglingen". Erst 1902 wurden diese vier Bezirke offiziell mit ihren heutigen Namen (Niederdorf wurde zum Bezirk Markt, aus Stiglingen wurde Haselstauden) zu Stadtbezirken erklärt. Heute gibt es ein zusammengewachsenes Stadtgebiet, das sich vor allem in der zweiten Hälfte des 20. Jahrhunderts auch westlich der Bahnlinie stark ausgebreitet hat. In diesen Gebieten entstanden so teilweise die Bezirke Rohrbach und Schoren, die erst 1994 zu eigenen Stadtbezirken wurden.

Die Bevölkerung der Stadt konzentriert sich hauptsächlich auf das Kerngebiet im äußersten Nordwesten des Gemeindegebiets. Jedoch finden sich besonders an den Berghängen im Osten der Stadt noch zahlreiche kleinere Orte, die als "Bergparzellen" bezeichnet werden. Zu diesen zählen unter anderem Watzenegg und Kehlegg, die besonders wegen ihrer Hanglage und des Blicks ins Rheintal hohe Grundstückspreise aufweisen. Außerdem gehören auch Winsau, Heilgereuthe und zahlreiche andere Häuseransammlungen im östlichen Berggebiet zur Stadt Dornbirn. Die herausragendste Parzelle Dornbirns ist das Walserdorf Ebnit, das ehemals eine eigenständige Gemeinde war und 1932 aufgrund finanzieller Probleme Teil der Stadt wurde. Das Ebnit ist zugleich auch das südlichste und östlichste ganzjährig bewohnte Gebiet Dornbirns und bildet damit das Zentrum des von Gebirge und Wald geprägten südöstlichen Gemeindegebiets.

Aufgrund der Größe des Gemeindegebiets von Dornbirn hat die Stadt zahlreiche Grenzen zu anderen Gemeinden. Von den 15 Nachbargemeinden Dornbirns gehören neun zum politischen Bezirk Bregenz (Lauterach, Wolfurt, Schwarzach, Bildstein, Alberschwende, Schwarzenberg, Reuthe, Mellau und Damüls) und vier zum Bezirk Feldkirch (Laterns, Zwischenwasser, Viktorsberg und Fraxern). Außerdem grenzen die beiden anderen Gemeinden des Bezirks Dornbirn (Hohenems und Lustenau) an das Gemeindegebiet der Stadt, welche die einzige Kommune im Bezirk ist, die keine Staatsgrenze als Gemeindegrenze hat. 

Das gesamte Dornbirner Gemeindegebiet erstreckt sich über eine Fläche von rund 121 Quadratkilometern (12.097 Hektar). Von dieser Gesamtfläche entfallen etwa 4.815 Hektar auf Waldgebiete und 5.723 Hektar auf Wiesen, Weiden und Alpen. Das Gemeindegebiet der Stadt Dornbirn macht etwa 70 % der Fläche des Bezirks Dornbirn (172,37 Quadratkilometer) aus. Dornbirn ist damit nach Gaschurn und Sankt Gallenkirch die flächenmäßig drittgrößte Gemeinde Vorarlbergs und macht 4,65 % der Gesamtfläche des Bundeslands aus.

Durch ihre Lage am Rande der Ostalpen und des Bregenzerwaldgebirges kann die Stadt Dornbirn mehrere Bergspitzen über 1.500 und sogar 2.000 Meter Höhe in ihrem Gemeindegebiet nennen. Die markantesten sind dabei der 971 Meter hohe Karren, welcher durch eine Seilbahn erschlossen ist und als Hausberg Dornbirns gilt, sowie der Staufen (). Außerdem sind bei Wanderern die 1.830 Meter hohe Mörzelspitze und der Hohe Freschen, der 2.004 Meter hoch ist, beliebt. Der höchste Berg im Gemeindegebiet ist die eher unscheinbare Sünser Spitze mit Die meisten Bergspitzen im Gemeindegebiet sind durch gut ausgeschriebene und gepflegte Wanderwege erreichbar, dazu gibt es auch spezielle Wanderkarten. Bestimmt wird das Bergbild Dornbirns durch den sogenannten "First", die Bergkette, zu der unter anderem die genannte Mörzelspitze, der Hohe Freschen sowie die Sünser Spitze gehören und die an klaren Tagen noch von Friedrichshafen aus zu sehen ist.

Die Gewässerkarte des Dornbirner Gemeindegebiets wird von der Dornbirner Ach beherrscht, dem Hauptfluss Dornbirns. Die Ach ist einer der wichtigsten Entwässerungsflüsse im vorderen Bregenzerwald und zudem Abfluss für zahlreiche größere und kleinere Bäche in der Dornbirner Berglandschaft. Die zahllosen Flüsse und Bäche, die sich der Dornbirner Ach während ihres Verlaufs vom südlichsten bis zum nördlichsten Punkt des Dornbirner Gemeindegebiets anschließen, haben größtenteils keinen Namen. Der Fallbach ist der einzige Bach, der nicht direkt der Dornbirner Ach zufließt, sondern zuerst in den Rheintal-Binnenkanal fließt. Seen gibt es in Dornbirn nur wenige, zwei der bekanntesten sind der Sünser See und der Staufensee-Stausee. In ihrem Verlauf durchfließt die Dornbirner Ach auch die Alploch- und Rappenlochschlucht, zwei Jahrtausende alte Schluchten, die heute touristisch ausgebaut und begehbar sind.

Dornbirn zählt eine aktuelle Gesamtbevölkerung von knapp 46.000 Menschen – das sind etwa 12 % der Einwohner Vorarlbergs.

Die Bevölkerung der Stadt teilt sich nahezu gleichmäßig in Männer und Frauen. Während bei der Volkszählung im Jahr 2001 20.730 Männer (49,0 %) gezählt wurden, kam der weibliche Teil der Bevölkerung auf 21.571 (51,0 %). In derselben Volkszählung wurde erhoben, dass 86,6 % der Einwohner Dornbirns die österreichische Staatsbürgerschaft besitzen. Zur römisch-katholischen Kirche bekannten sich 74,8 % der Dornbirner (in ganz Vorarlberg 78,03 %), weitere 2,6 % waren evangelischen Glaubensbekenntnisses (Vorarlberg 2,23 %), und 2,7 % gehörten einer christlich-orthodoxen Kirche an (Vorarlberg 2,61 %). Die zweitgrößte Glaubensgruppe stellte jene des Islam dar. Im Jahr 2001 waren 9,9 % der Einwohner Dornbirns Muslime (Vorarlberg 8,36 %), nur 8 Bürger waren jüdischen Glaubens.

Die größte Altersgruppe stellten bei dieser Zählung mit 8,4 % die 35-bis-39-Jährigen. Dennoch ist der Altersdurchschnitt der Gesamtbevölkerung in Dornbirn leicht höher als der des Bundeslandes. 18,5 % (in ganz Vorarlberg 19,73 %) der Bevölkerung waren zum Erhebungszeitpunkt unter 15 Jahre alt, 63,3 % (Vorarlberg 63,16 %) waren zwischen 15 und 60 Jahren, und 18,2 % (Vorarlberg 17,29 %) waren über 60 Jahre alt. Rund 44,1 % der Dornbirner waren im Jahr 2001 ledig, weitere 7 % geschieden. Dem gegenüber standen 43,4 % verheiratete Personen sowie 5,5 % Verwitwete.

Dornbirn ist stark durch Einwanderung geprägt: Es ist die Stadt in Vorarlberg mit dem höchsten Ausländeranteil, was charakteristisch für den gesamten Bezirk ist. Im Jahr 2001 waren 1,7 % der in Dornbirn wohnhaften Menschen Bürger eines anderen EU-Staats und 11,7 % Bürger eines Landes außerhalb der EU (allerdings vor der EU-Osterweiterung).

Der mit Abstand größte Anteil an der ausländischen Bevölkerung ist wie in den meisten anderen Städten Vorarlbergs türkischstämmig. So gaben 3.484 Menschen als Umgangssprache Türkisch an, 4.206 Menschen bekannten sich zum muslimischen Glauben.

Dem gegenüber stehen 35.411 Menschen, die muttersprachig Deutsch sprechen, und 35.667 Menschen, die in Österreich geboren sind, sowie 39.812 österreichische Staatsbürger (im Jahr 2006). Dieser Umstand resultiert aus den großen Einwanderungswellen in den 1950er und 1960er Jahren, als mit dem erneuten Aufblühen der Textilindustrie immer mehr Arbeitskräfte aus der Türkei als Gastarbeiter angeworben wurden. Viele dieser ehemaligen Textilarbeiter leben heute mit ihren Familien in Vorarlberg, jüngere Generationen sind in Österreich geboren und in der westlichen Kultur aufgewachsen.

Aufgrund dessen wurde im Herbst 2001 von der Stadt Dornbirn ein Interkulturelles Leitbild in Auftrag gegeben, welches mit Hilfe des ethnologischen Seminars der Universität Basel sowie dem b.a.s.e. Büro für angewandte Sozialforschung und Entwicklung im November 2002 der Öffentlichkeit vorgestellt wurde.

Die frühesten Beweise für menschliche Anwesenheit auf heutigem Dornbirner Gemeindegebiet lassen sich in die mittlere Steinzeit (8000 bis 3000 v. Chr.) datieren. Hierzu zählt ein, 1971 unter der Achmühler Brücke gefundener, scheibenförmiger Keulenkopf aus grün-schwarzem Quarzit. Erste Funde auf heute noch bewohntem Stadtgebiet ließen sich der Bronzezeit (3000 bis 1800 v. Chr.) zuordnen. Hinweise auf eine römische Anwesenheit im Dornbirner Stadtgebiet liefern Münzen des 2. Jahrhunderts von der Rosenstraße und eine Fibel aus dem 1. Jahrhundert, gefunden im Flur Köblern. Den ersten Hinweis auf eine Siedlung auf dem Gebiet des heutigen Dornbirn liefert ein alamannisches Skelettgrab mit Sax und Messer als Beigaben aus dem 6. und 7. Jahrhundert. Dies lässt auf eine Ansiedlung im Bereich des heutigen Bezirks Hatlerdorf schließen.

Erstmals wird die Siedlung "Torrinpuirron" – übersetzt etwa „Die Höfe des Torro“ – in einem Aktenvermerk einer am 15. Oktober 895 ausgestellten St. Gallischen Urkunde erwähnt. Das Kloster St. Gallen besaß demnach auch in den darauf folgenden Jahrzehnten die Landesherrschaft über das Gebiet. Im fränkischen Reich befand sich die junge Siedlung im Reichsgau "Ringowe" und damit im Einflussbereich der Grafen von Bregenz.

In den darauf folgenden Jahrzehnten wechselte der Besitz erst an die Bregenzer Linie der Grafen von Montfort, anschließend an deren Feldkircher Linie. Schließlich wurden diese dem Habsburgerreich einverleibt, womit Dornbirn im Jahr 1380 österreichisch wurde. 1391 erfolgte eine urkundliche Erwähnung als "Veste Dorrenburren", womit wohl der Oberdorfer Turm gemeint war. In unmittelbarer Nähe des Standorts des heute nicht mehr existierenden Oberdorfer Turms befindet sich das Schlossguggerhaus, das mit seinem ungefähren Baudatum um 1294 das älteste noch erhaltene Gebäude Dornbirns ist.

Ende des 14. Jahrhunderts gelang es den Emser Grafen, einige wichtige Grundstücke auf Dornbirner Gemeindegebiet zu erwerben. Bereits in der Mitte des 15. Jahrhunderts befanden sich große Teile Dornbirns in Emser Hand (1575 bis 1759).

Im Jahr 1654 verkaufte Erzherzog Ferdinand Karl das Gericht zu Dornbirn an die Emser Grafen. Dagegen leistete die Dornbirner Bevölkerung erbitterten Widerstand und verweigerte sogar die Huldigung des neuen Landesherrn. Mithilfe der Landesstände gelang es den Dornbirnern, 4.000 Gulden für den Rückkauf der Gerichtsbarkeit aufzubringen, woraufhin der Erzherzog den Verkauf zurücknahm und Dornbirn für seine Treue zum Hause Habsburg mit dem heute noch gebräuchlichen Gerichtswappen belohnte (siehe Absatz Wappen). Im Jahr 1771 gelang es der Bevölkerung schließlich aufgrund der hohen Verschuldung der Emser, auch sämtlichen Grund und Boden, den diese in Dornbirn besaßen, zu kaufen. Dieses bedeutende Ereignis in der Geschichte der Stadt wird heute als "Loskauf von Ems" bezeichnet. 1793 wurde Dornbirn zur Marktgemeinde erhoben, fiel 1805 infolge des Friedensvertrages von Pressburg an den Illerkreis mit Kempten als Hauptstadt an Bayern und kam 1814 wieder zu Österreich zurück. Das Ende des 18. und der Beginn des 19. Jahrhunderts brachten einen regen Aufschwung der Wirtschaft mit sich, insbesondere auch durch den Bau der Eisenbahnlinie.

Mit Beschluss vom 21. November 1901 wurde Dornbirn von Kaiser Franz Joseph I. zur Stadt erhoben, was in den folgenden Tagen vor Ort ausgiebig gefeiert wurde. Damit war Dornbirn die vierte Stadt des Bundeslands Vorarlberg geworden (82 Jahre später stieß Hohenems als fünfte und bislang letzte Stadt hinzu). Im Jahr zuvor hatte der Kaiser bei einem Besuch in Dornbirn in der Textilfabrik F.M. Hämmerle die erste Außerhaus-Telefonanlage der Österreich-Ungarischen Monarchie in Betrieb genommen. 1902 wurde außerdem die Elektrische Bahn Dornbirn–Lustenau (EBDL), eine Straßenbahn zwischen den beiden Gemeinden, eingeweiht.

Im Ersten Weltkrieg (1914–1918) kamen 596 Einwohner der jungen Stadt als Soldaten ums Leben. In der Zwischenkriegszeit blieb Dornbirn von jeglichen Bürgerkriegsunruhen verschont, da sich ein Großteil der Dornbirner Bevölkerung zum austrofaschistischen Ständestaat bekannte. Im Jahr 1932 wurde die durch den Bau der Ebniterstraße hoch verschuldete eigenständige Gemeinde Ebnit in der Stadt Dornbirn eingemeindet.

Bereits vor dem Anschluss ans Deutsche Reich 1938 galt Dornbirn als „braunes Nest“ in Vorarlberg und regelrechte Hochburg der Nationalsozialisten. Es war auch Schauplatz der wenigen aufsehenerregenden Sprengstoffanschläge der zu diesem Zeitpunkt noch illegal agierenden Nationalsozialisten in Vorarlberg.

Am 12. März 1938 marschierten nach der Abdankung von Kanzler Kurt Schuschnigg tags zuvor auch in Dornbirn Truppen der deutschen Wehrmacht ein und vollzogen den „Anschluss Österreichs“. Der Dornbirner Anton Plankensteiner wurde zum neuen Kreisleiter ernannt, und Landeshauptmann Ernst Winsauer wurde seines Amtes enthoben. Bereits im Frühjahr 1939 wurde Dornbirn zur ersten „judenfreien Stadt“ Vorarlbergs erklärt. Dornbirn war während der Zeit des Nationalsozialismus neben Bregenz und Bludenz eine der drei Vorarlberger Kreisstädte im „Reichsgau Tirol-Vorarlberg“.

Während des Zweiten Weltkriegs leisteten aus Dornbirn insgesamt 5.789 Männer Kriegsdienst, davon starben 709. Anderen Quellen sprechen von 837 oder sogar mehr als 1.000 Gefallenen und Vermissten, was etwa 5,8 Prozent der Wohnbevölkerung von 1939 bedeutete.

Am 2. Mai 1945 wurde die Stadt von der 1. französischen Armee nahezu kampflos eingenommen. Um 21:30 Uhr wurden vom Rundfunksender in Dornbirn aus die historischen Worte: "„Hier spricht der österreichische Rundfunk, Sender Vorarlberg in Dornbirn. Wir beginnen als erste österreichische Sendestation den Dienst.“" gesendet. Im besetzten Nachkriegsösterreich gehörte Dornbirn in der Folge bis zum Ende der Besatzungszeit 1955 wie ganz Vorarlberg zur französischen Zone.

Der nach der Befreiung Österreichs folgende wirtschaftliche Aufschwung in Vorarlberg wird durch die erste Musterschau in Dornbirn (später Dornbirner Messe) im Jahr 1949 deutlich. Bereits im Jahr 1969 wurde Dornbirn zum Sitz der Bezirkshauptmannschaft des neu geschaffenen und vom Bezirk Feldkirch abgespaltenen Bezirks Dornbirn. Den durch den Niedergang der lokalen Textilindustrie seit den 1970er Jahren auftretenden regionalen Strukturwandel konnte die Stadt erfolgreich hinter sich bringen. Aufgrund des Baus einer neuen Stadtstraße 1987 konnte im darauf folgenden Jahr die Stadtmitte Dornbirns als Fußgängerzone eingerichtet werden. 1991 wurde als zukunftsweisendes Projekt für den öffentlichen Personennahverkehr der erste Stadtbus Vorarlbergs in Dornbirn eingerichtet. Der Dornbirner Stadtbus entwickelte sich rasch zum Pilotprojekt für viele weitere Städte und Gemeinden. Mit der Fachhochschule Vorarlberg wurde im Jahr 1994 die erste Hochschule mit Universitätscharakter im Bundesland gegründet. Im Jahr 2001 feierte die Stadt das 100-jährige Jubiläum ihrer Stadterhebung. Zur Verbesserung der Verkehrsinfrastruktur wurde in den Jahren 2008 und 2009 die Stadtstraße, die Hauptverkehrsader im innerstädtischen Bereich, grundlegend saniert und erneuert.

Mehrere kulturelle Veranstaltungsorte finden sich in der Messestadt Dornbirn. So bietet das Kulturhaus Dornbirn immer wieder Platz für diverse Theater- und Kabarettvorstellungen, wie auch für andere Anlässe. Über die regionalen Grenzen hinaus bekannt ist zudem der Spielboden, eine Bühne für Vorarlberger Künstler, sowie das Conrad Sohm.

Klassische Konzerte veranstaltet „Dornbirn Klassik“ das ganze Jahr hindurch.

Dornbirn verfügt als relativ junge Stadt (Stadterhebung erst 1901) nur über wenige Wahrzeichen oder touristische Ziele. Das Gemeindegebiet Dornbirns bietet gerade im Naturbereich eine Vielzahl sehenswerter Begebenheiten.

Zu den städtischen Einrichtungen, dem Stadtmuseum/Stadtarchiv kommt seit dem Jahr 2003 die "inatura Erlebnis Naturschau Dornbirn", ein über die regionalen Grenzen hinaus bekanntes naturkundliches und naturgeschichtliches, interaktives Museum auf dem ehemaligen Werksgelände der Rüsch-Werke inmitten des neuen Stadtparks. Auch zählen der Kunstraum Dornbirn, das Krippenmuseum Dornbirn sowie das Rolls-Royce Museum zu den bekannten Museen der Stadt.

Im umgebauten Gebäude der ehemaligen Vorarlberger Naturschau eröffnete im Juli 2009 ein Museum für den in München lebenden Bildhauer Wolfgang Flatz, der in Dornbirn geboren wurde. Das nur aus zwei Räumen bestehende Museum widmet sich ganz dem Werk des für seine provokanten Aktionen bekannten Künstlers.

Das junge Stadtbild Dornbirns ist geprägt vom Baustil des 19. und 20. Jahrhunderts. In der zweiten Hälfte des 20. Jahrhunderts machte die hiesige Architekturszene unter dem Begriff "Neue Vorarlberger Bauschule" international auf sich aufmerksam, zu deren Vertretern unter anderem die Cooperative Dornbirn – später Baumschlager & Eberle, Dietrich/Untertrifaller oder Oskar Leo Kaufmann gehören. In und um Dornbirn herum entstanden vor allem seit den 1980er Jahren viele Bauten, die unter diesem Label europaweit Beachtung in der Fachwelt fanden.

Auch sind ältere Bauwerke Dornbirns architektonisch interessant. Diese befinden sich zum einen direkt am Marktplatz, mit dem Wahrzeichen Dornbirns, dem „Roten Haus“ sowie der St. Martinskirche. Weitere historisch bedeutsame oder architektonisch interessante Bauwerke sind die Pfarrkirchen der anderen Stadtbezirke und Ortsteile.

Historische Bauten


Moderne Architektur


Der 976 Meter hohe Karren ist der Hausberg von Dornbirn, südöstlich der Stadt gelegen. Auf den Karren führt die Karrenseilbahn, eine Luftseilbahn, welche einen Höhenunterschied von rund 520 Metern überwindet. Am bewaldeten Gipfel befindet sich ein Panoramarestaurant und die „Karren-Kante“, eine 12 Meter über die Felskante hinausragende Panorama-Aussichtsplattform. Von der Bergstation aus kann man den Gipfel des Staufen besteigen oder entlang einem Waldlehrpfad zum Staufensee absteigen.

Im Gemeindegebiet der Stadt befinden sich zahlreiche weitere Berge, welche dank des neuen Vorarlberger Wanderwegsystems leicht begehbar sind. Die bekanntesten sind der bereits genannte Staufen, die Mörzelspitze und der markanteste Berg im Gemeindegebiet, der Hohe Freschen. Der höchste Berg ist die Sünser Spitze.

Die Rappenlochschlucht mit Staufensee und Alploch ist ein beliebtes Ausflugsziel südöstlich von Dornbirn. Die beiden Schluchten werden von der Dornbirner Ach durchflossen und zählen zu den größten Schluchten in den Ostalpen. Die beiden Klammen sind seit 1890 begehbar. Im kleinen Becken dazwischen liegt der Staufensee, der in demselben Jahr als Wasserreservoire für das Elektrizitätswerk einer Spinnerei in der Ortschaft Gütle (Stadtbezirk "Oberdorf") angelegt wurde.

Die Stadt Dornbirn bietet ihrer Bevölkerung ein reiches Angebot an Freizeitaktivitäten. Es gibt viele verschiedene Sportarten, die in der Gemeinde ausgeübt werden können. Aber auch die Liebhaber der Kulturszene kommen in Dornbirn nicht zu kurz. Familienfreundliche Freizeitgestaltung bietet auch "das stadtbad", das neue Hallenbad der Stadt, sowie das Waldbad Enz, ein Freibad im Tal der Dornbirner Ach. Mit dem Cinema 2000 existiert in Dornbirn zudem ein Kino.

Die bedeutendste Sportart ist wie in ganz Mitteleuropa Fußball. Eine Vielzahl von öffentlichen Fußballplätzen ermöglicht das Spielen sowohl in einem der zahlreichen Vereine als auch in der Freizeit. Der bedeutendste Verein ist der FC Dornbirn 1913 – der frühere Bundesligist spielt derzeit in der dritthöchsten Spielklasse, der Regionalliga West. Daneben existieren noch weitere Fußballvereine in niedrigeren Ligen, etwa die derzeit fünftklassigen Vereine Admira Dornbirn, Dornbirner SV oder der Sport- und Freizeitclub Hatlerdorf.

Die Eissporthalle "Messestadion" – Heimatstadion des Dornbirner EC – liegt im sportlichen Zentrum der Stadt, dem Messeareal, in welchem diverse Sportarten ausgeübt werden können, unter anderem Tennis, Badminton, Volleyball, Eishockey, Eiskunstlauf, Basketball, Radball etc. Ebenfalls im Gelände der Dornbirner Messe untergebracht ist das Sportgymnasium Dornbirn. Auch ist Dornbirn Standort des Vorarlberger Landessportzentrums, der Schnittstelle des Vorarlberger Sports. Das Landessportzentrum ist unter anderem mit einer Ballsporthalle, modernen Schießständen, Rasenplätzen, einer Gerättunrnhalle, einer Bodenturnhalle, einer Halle für die Rhythmische Gymnastik, einer Kampfsporthalle, einem Krafttrainingsraum sowie modernen medizinischen Diagnosegeräten ausgestattet. Im selben Gebäude wie die Landessportschule befindet sich ein Heeresleistungssportzentrum des Österreichischen Bundesheers. Das Turnsportzentrum Dornbirn wurde 2007 gegründet.

Eine besondere Bedeutung nimmt wie fast überall in Vorarlberg der Skisport in Dornbirn ein. Obwohl keines der größeren Vorarlberger Skigebiete im unmittelbaren Umfeld der Stadt liegt, sind viele der wichtigen Skiregionen – insbesondere im Bregenzerwald – von Dornbirn aus mit öffentlichen Verkehrsmitteln in kurzer Zeit erreichbar. Außerdem gibt es mehrere Skiclubs und -schulen in Dornbirn, welche jedoch nicht in den großen Skigebieten trainieren, sondern sich hauptsächlich auf kleinere, regionale Skiliftverbände aufteilen. Für die Dornbirner Bevölkerung dient insbesondere das Skigebiet Bödele als Naherholungs- und Sportgebiet. Dieses ist direkt an Dornbirn angrenzend größtenteils auf Schwarzenberger Gemeindegebiet gelegen, wird jedoch zum überwiegenden Teil von der Dornbirner Seilbahnen GmbH, einem Tochterunternehmen der Stadt Dornbirn, betrieben. Das einzige Skigebiet, das sich vollständig auf Dornbirner Gemeindegebiet befindet, ist das kleine Skigebiet Heumöser im Ebnit, das einen Schlepplift sowie einen kleinen Kinder-Schlepplift umfasst.

Abseits der gängigen Breitensportarten konnte die Baseball-Mannschaft Dornbirn Indians sich erfolgreich in der Austrian Baseball League behaupten und wurde 1999 und 2003 jeweils österreichischer Baseball-Staatsmeister. Seit dem 30. September 2006 befindet sich in Dornbirn mit der "K1 Kletterhalle Dornbirn" die größte Kletterhalle Österreichs, die rund 2.000 Quadratmetern Kletterfläche umfasst.

Dornbirn ist ein gewerbliches Zentrum in Vorarlberg und für das gesamte nördliche Alpenrheintal. Eine große Bedeutung hatte und hat seit der Blütezeit der Textilindustrie die Dornbirner Messe, welche einstmals eine der größten Textilfachmessen Österreichs war. Sowohl als Beschäftigte in Dornbirner Betrieben als auch als Konsumenten sind Personen aus der ländlichen Umgebung Dornbirns, besonders des Bregenzerwalds, ein wichtiger Wirtschaftsfaktor. Insbesondere das Stadtzentrum, in dem sich viele Geschäfte unter dem Namen "inside Dornbirn" zu einer Handelsgemeinschaft zusammengeschlossen haben, und das größte Einkaufszentrum in Vorarlberg, der Messepark, werden stark frequentiert.

Die bis Anfang der 1970er Jahre dominierende Textilindustrie (F. M. Hämmerle, Rhomberg, Mäser) hat ihren dominierenden Status längst verloren – die meisten Unternehmen existieren nicht mehr – und wurde durch eine rasch expandierende metallverarbeitende Industrie, Elektro- und Elektronikunternehmen, Dienstleistungsgeschäfte sowie viele kleine und mittelständische Gewerbebetriebe ersetzt. Durch die seitens der Stadtverwaltung getätigten Grundkäufe als Reserve für zukünftige Unternehmensansiedlungen (z. B. Betriebsansiedlungsgebiet Pfeller, situiert an der Autobahnabfahrt Dornbirn Nord Richtung Achraintunnel) wurden wichtige Weichenstellungen für die zukünftige wirtschaftliche Entwicklung getroffen.

Im Jahresdurchschnitt 2016 waren laut einer Erhebung der Wirtschaftskammer Österreich 15.301 unselbständig Beschäftigte in 1.455 Dornbirner Betrieben beschäftigt. Mit dieser Arbeitnehmerzahl war die Stadt der mit Abstand größte Arbeitsplatzstandort Vorarlbergs mit beinahe doppelt so vielen Arbeitnehmern wie der nächstgrößere Standort (Landeshauptstadt Bregenz; 8.899 Beschäftigte). Von Dornbirns Arbeitnehmern entfielen 4258 auf die 475 Handelsbetriebe der Stadt, 3695 auf Gewerbe- und Handwerksbetriebe und 3391 auf Industriebetriebe.

Der größte Arbeitgeber der Stadt ist die Zumtobel Group, ein Leuchtenhersteller, dessen Hauptsitz sich in Dornbirn befindet. Sowohl umsatz- als auch mitarbeitermäßig folgt dann die Rudolf Ölz Meisterbäcker GmbH. Ursprünglich bekannt geworden als Hersteller von Backerbsen, ist dieses Unternehmen heute ein internationaler Backwarenhersteller. Auch die Mohrenbrauerei, die älteste und größte Bierbrauerei Vorarlbergs, befindet sich in Dornbirn. Zudem hat die Spar Österreichische Warenhandels-AG in Dornbirn die für Vorarlberg zuständige Zentrale gebaut und das größte Vorarlberger Unternehmen, die Julius Blum GmbH aus Höchst, unterhält in Dornbirn ebenfalls eine Niederlassung.

Im Zeitraum von November 2013 bis Oktober 2014 wurden 144.632 Gäste in Dornbirn registriert, die insgesamt 283.584 Nächtigungen verzeichneten, wobei mehr als 87 % der Gäste in Hotels, Gasthöfen und Pensionen, also haupterwerbsmäßigen Fremdenverkehrseinrichtungen, unterkamen. Das Nächtigungswachstum im Vergleich zum Vorjahreszeitraum betrug 1,3 %. Dornbirn ist zentral gelegen und bildet für Touristen einen guten Ausgangspunkt für Aktivitäten und Ausflüge in der näheren Umgebung (Gesamter Bodenseeraum sowie ganz Vorarlberg, die Schweiz, das Fürstentum Liechtenstein und Teile des südwestdeutschen Raums). Aufgrund dessen haben sich in der Kleinstadt zahlreiche Hotels niedergelassen und die Stadt ist – gemessen an den Nächtigungszahlen – nach der Landeshauptstadt Bregenz die zweitgrößte Tourismusgemeinde Vorarlbergs außerhalb der klassischen Wintersportgebiete. Nach Anzahl der in Tourismusbetrieben beschäftigten Arbeitnehmer ist Dornbirn sogar noch vor Lech am Arlberg führender Tourismus-Arbeitsstandort Vorarlbergs.

Im Herbst 2005 wurde das vollständig verglaste Panoramahaus („Home of Balance“) als höchstes gewerblich genutztes Gebäude Vorarlbergs und größtes Hotel in Dornbirn eröffnet. Es beinhaltet ein Wellness Center und ein Four Points by Sheraton Hotel. Des Weiteren gibt es in der Stadt zahlreiche Restaurants, Lokale und Bars. Dennoch bildet das Gastgewerbe in Dornbirn entgegen dem Trend im Bundesland einen eher geringen Anteil an der Gesamtwirtschaft.

Als touristische Ziele gelten in Dornbirn die Rappenlochschlucht, das Bergdorf Ebnit sowie die umliegenden Berge im Gemeindegebiet. Die gut erschlossenen Wanderwege ermöglichen auch Touristen den Blick auf teils einzigartige Naturschönheiten. Im Winter suchen viele Dornbirner Erholung im nahe gelegenen Skigebiet Bödele, welches zwar hauptsächlich von Dornbirn aus angefahren wird, geografisch jedoch größtenteils zur Gemeinde Schwarzenberg gehört.

Im Jahr 2007 fand von 8. bis 14. Juli die 13. Weltgymnaestrada in Dornbirn statt. Dornbirn war nach Herning (1987) die zweite Mittelstadt, in der diese Breitensportveranstaltung ausgetragen wurde. Dies stellte eine besondere Herausforderung an die Veranstalter und die Stadt dar, da zu diesem Ereignis mehr als 20.000 Teilnehmer aus der ganzen Welt empfangen wurden. In Vorbereitung auf diese Großveranstaltung wurden etliche Projekte bezüglich der Infrastruktur in Dornbirn verwirklicht. Beispielsweise wurde der Bahnhof Dornbirn saniert und modernisiert, eine neue Autobahnauffahrt im Bereich des Messegeländes wurde in Planung genommen aber nicht verwirklicht und die bereits bestehende Autobahnauffahrt Dornbirn-Süd wurde komplett umgebaut. Im Jahr 2009 wurde Dornbirn erneut zum Austragungsort eines großen internationalen Turnereignisses, als die Austragung der ersten "Gym for Life World Challenge" aufgrund der guten Erfahrungen bei der Weltgymnaestrada an die Stadt vergeben wurde.

2015 wurde vom Exekutivkomitee der Fédération Internationale de Gymnastique bekannt gegeben, dass Dornbirn abermals den Zuschlag als Austragungsort der Weltgymnaestrada für das Jahr 2019 erhalten hatte. Dornbirn wird damit 2019 zwölf Jahre nach der erstmaligen Gastgeberschaft für das Turnsportevent erneut diese internationale Großveranstaltung beherbergen.

Verkehrstechnisch gesehen bildet Dornbirn den Knoten- und Mittelpunkt des Rheintales und daher die wichtigste Verbindung für den Landbus von Norden (Bregenz) nach Süden (Feldkirch und Bludenz). Aber auch die Busverbindungen in den Bregenzerwald (Osten) finden in Dornbirn ihren Knotenpunkt. Innerhalb der Stadt gibt es ein gut ausgebautes und funktionierendes Stadtbusnetz (Stadtbus Dornbirn). Von 1902 bis 1938 verband die nicht mehr existierende Straßenbahn Dornbirn–Lustenau die Stadt Dornbirn mit ihrer Nachbargemeinde Lustenau bzw. mit dem Grenzübergang zur Schweiz.

Der Bahnhof Dornbirn der Österreichischen Bundesbahnen (ÖBB) an der Vorarlbergbahn ist als reiner Durchgangsbahnhof verkehrstechnisch eher unwichtig, aufgrund der relativ hohen Fahrgastfrequenz halten aber auch in diesem Bahnhof alle passierenden Personenzüge. Daneben gibt es noch drei weitere Bahnstationen im Gemeindegebiet (Haselstauden, Dornbirn-Schoren und Hatlerdorf), die nur von Regional- und S-Bahnzügen bedient werden. Im Vorfeld der Weltgymnaestrada 2007 wurde der Dornbirner Bahnhof umgebaut und modernisiert, ebenso wurde die im Zuge dieser Großveranstaltung stark frequentierte Haltestelle Dornbirn-Schoren versetzt.

Die Rheintal/Walgau Autobahn A14 führt westlich des Stadtgebiets vorbei und schließt Dornbirn mit den beiden Anschlussstellen Dornbirn-Nord und Dornbirn-Süd an das höchstrangige Straßennetz an. Mit dem Achraintunnel an der Gemeindegrenze Dornbirns mit Schwarzach besteht eine direktere Verbindung von der Autobahnabfahrt Dornbirn-Nord in den Bregenzerwald. Aktuell in Planung befindet sich das Projekt zum Bau einer Anschlussstelle „Rheintal Mitte“ in Dornbirn. Im Bereich der heutigen Unterführung der L 45 Schmitternstraße unter der Rheintal/Walgau Autobahn soll hierzu ein neuer Autobahnanschluss entstehen, der in Verbindung mit dem Ausbau der L 45 insbesondere die Betriebsgebiete im Süden Dornbirns an das höchstrangige Straßennetz anbinden soll. Der Baubeginn ist dabei frühestens mit 2018 angesetzt. In Dornbirn treffen weiters drei ehemalige Bundesstraßen aufeinander, dies sind die Vorarlberger Straße L 190, die Bregenzerwaldstraße L 200 und die Lustenauer Straße L 204.

Die sogenannte Stadtstraße, der direkt im Zentrum Dornbirns liegende Teil der L 190, wurde im Jahr 2008 komplett neugebaut. Dabei wurde nicht nur die Verkehrsinfrastruktur den seit dem Bau der Stadtstraße in den 80er-Jahren veränderten Verhältnissen angepasst, sondern auch eine neue Tiefgarage unterhalb der Straße errichtet, um die Parkplatzsituation in der Innenstadt zu verbessern.

Zudem gibt es noch den Sportflugplatz Hohenems-Dornbirn und diverse Segelvereine am Bodensee. Der nächstgelegene Verkehrsflughafen befindet sich mit dem Flugplatz St. Gallen-Altenrhein in Altenrhein in der Schweiz.

In Vorarlberg ist die Verwaltung traditionell dezentral organisiert. Dies liegt zum einen daran, dass Vorarlberg bis 1918 kein eigenständiges Land war, deshalb auch keine Landeshauptstadt besaß und die Einrichtungen auf die größten Städte aufgeteilt wurden. Zum anderen liegt es daran, dass Bregenz zwar Sitz der Landesregierung ist, als drittgrößte Stadt des Landes aber nicht die zentrale Stellung einnimmt wie es beispielsweise in Tirol die Stadt Innsbruck tut.

Viele Organisationen sind deshalb auf die drei größten Städte im Land aufgeteilt. Während sich in Feldkirch das Landesgericht befindet, beherbergt Bregenz den Vorarlberger Landtag und andere politische Einrichtungen. In Dornbirn befinden sich folgende wichtige öffentliche Einrichtungen, die landesweit von Bedeutung sind:


Die Stadt Dornbirn verfügt über ein für Vorarlberg ungewöhnlich großes und breites Bildungsangebot. Statistisch wies die Stadt Dornbirn für das Schuljahr 2015/2016 einen Stand von 2001 Volksschülern und 1188 Mittelschülern auf. Alle Dornbirner Schulen zusammengerechnet kommen auf mehr als 8000 Schüler. Der Schülerverkehr bildet deshalb einen großen Anteil am täglichen Verkehrsaufkommen der Stadtbuslinien und Regionalzüge. An den 22 Dornbirner Kindergärten (20 städtische und 2 private) wurden im Schuljahr 2016/2017 insgesamt 1147 Kinder betreut.

In Dornbirn existieren 5 Mittelschulen, 15 Volksschulen und 22 Kindergärten. Diese werden größtenteils von der Stadtgemeinde Dornbirn geführt. Zu den öffentlichen Pflichtschulen gehören zudem das Zentrum für Inklusion und Sonderpädagogik (ZIS), die Polytechnische Schule und die Schule für Gehörlose (LZH). Weiters bieten die beiden Gymnasien in Dornbirn Unterstufenklassen an.

Im Bereich der höheren Schulen gibt es drei Gymnasien in Dornbirn. Das BG Dornbirn im Zentrum der Stadt ist dabei das älteste und sprachlich orientiert, während das BRG Dornbirn-Schoren mathematisch-naturwissenschaftlich geprägt ist. Das neueste der drei Gymnasien ist das seit dem Schuljahr 2010/11 eigenständige Sportgymnasium Dornbirn, das zuvor als Ableger des BRG Dornbirn-Schoren geführt worden war. Des Weiteren gibt es in Dornbirn eine HTL und zwei Berufsschulen (Landesberufsschule Dornbirn 1 & 2) sowie eine dreijährige Fachschule für wirtschaftliche Berufe, die allerdings kostenpflichtig ist. Außerdem ist in Dornbirn auch die Landessportschule angesiedelt.

Dornbirn ist Standort der Fachhochschule Vorarlberg, die neben der Pädagogischen Hochschule Vorarlberg in Feldkirch die einzige Hochschule im Bundesland Vorarlberg ist. Aufgrund der modernen und teils einzigartigen Studiengänge zu den Themen Informatik, Mediengestaltung, Mechatronik, Elektrotechnik, Betriebswirtschaft, Sozialarbeit und Wirtschaftsingenieurwesen sind viele der Studienplätze auch an ausländische Studenten vergeben, die damit mittelfristig in Dornbirn wohnen.

Neben diesen allgemeinen Bildungswegen bietet Dornbirn eine Vielzahl an sonstigen Weiter- und Ausbildungsstätten, so zum Beispiel die städtische Musikschule oder das Wirtschaftsförderungsinstitut der Vorarlberger Wirtschaftskammer. Daneben hat die Stadt noch weitere Einrichtungen geschaffen, welche im weiteren Sinne der Bildung dienen. So gibt es eine Stadtbücherei sowie ein Stadtmuseum und ein Stadtarchiv. Außerdem existieren sechs Pfarrbüchereien und eine weitere Bücherei im Naturkundemuseum "inatura".

Die größte Stadt des Landes Vorarlberg hat auch eines der meistfrequentierten Krankenhäuser. Das Krankenhaus Dornbirn ist zudem das einzige Spital in Vorarlberg, das sich nicht im Besitz des Landes, sondern der Stadt befindet. Die Rot-Kreuz-Abteilung Dornbirn zählt zu den am besten ausgelasteten Rettungseinheiten im Bundesland. Des Weiteren gibt es ein Notarzteinsatzfahrzeug, das im Rendezvous-System praktiziert und seit dem Jahr 2009 über eine eigene Garage beim städtischen Krankenhaus verfügt. Besetzt ist das Notarzteinsatzfahrzeug 24 Stunden am Tag mit einem Notarzt, einem Dipl. Krankenpfleger und einem Fahrer, der meist Notfallsanitäter ist. Das Krankenhaus Dornbirn verfügt auch über einen Hubschrauberlandeplatz auf dem Dach des Gebäudes.

Im Bereich der Pflege gibt es in Dornbirn außerdem zwei städtische Pflegeheime, drei Seniorenwohnhäuser sowie eine Seniorenwohngemeinschaft und ein privat betriebenes Altersheim. Dem Pflegeheim Birkenwiese angeschlossen ist seit 2015 auch eine Außenstelle der Gesundheits- und Krankenpflegeschule Unterland, die seit 2016 von der Stadt Dornbirn geführt wird.

Die Stadt Dornbirn zählt zu den Gemeinden Vorarlbergs mit der höchsten Kriminalitätsrate. So wurden im Dezember 2006 in Dornbirn 5401 Straftaten angezeigt. Gleichzeitig ist in Dornbirn die Aufklärungsrate von Verbrechen landesweit am höchsten (konstant bei etwa 55 %). Die Polizeiinspektion Dornbirn der Österreichischen Bundespolizei sowie eine eigene Stadtpolizei sorgen im Gemeindegebiet für die Sicherheit der Bevölkerung. In Dornbirn befindet sich auch das Bezirkspolizeikommando für den Bezirk Dornbirn und das Bezirksgericht Dornbirn mit angeschlossenem Gefängnis, welches als Zweigstelle der Justizanstalt Feldkirch betrieben wird. Zudem ist an der Autobahnauffahrt Dornbirn-Süd die Autobahnpolizei stationiert.

Dornbirn ist die Gemeinde in Vorarlberg mit der größten Zahl an Verkehrstoten, verglichen zur Einwohnerzahl. Im Jahr 2014 starben bei 280 Unfällen mit Personenschaden sieben Personen im Straßenverkehr, 335 wurden verletzt.

Die Stadt unterhält mit der Freiwilligen Feuerwehr Dornbirn eine eigene Freiwillige Feuerwehr, die mit 250 Mitgliedern (davon 186 aktiv) die größte Feuerwehr im Bundesland ist.

Seit dem 29. Mai 2013 leitet Bürgermeisterin Andrea Kaufmann die politischen Geschicke der Stadt Dornbirn.

Bei der letzten Gemeindevertretungs- und Bürgermeisterwahl im Jahr 2015 wurde Kaufmann mit 51,29 % der Stimmen in der Direktwahl im Amt bestätigt.

Bei der letzten Gemeindevertretungswahl am 15. März 2015 konnte gesondert über die Stadtvertretung, bei der die jeweiligen Parteien mit ihrem Spitzenkandidaten antraten, und den Bürgermeister (Direktwahl) bestimmt werden. Zusätzlich konnten noch Vorzugsstimmen innerhalb der gewählten Partei vergeben werden. Daraus resultieren die Abweichungen zwischen Parteienergebnis und Bürgermeisterergebnis.

Der Dornbirner Stadtrat setzt sich aus neun Stadträten (inklusive Bürgermeisterin und Vizebürgermeister) zusammen. Diese sind, abgesehen von der Bürgermeisterin, größtenteils nebenberufliche Politiker. Die Aufteilung der Ressorts sowie die Leitung des Stadtrats obliegen dem jeweils amtierenden Bürgermeister.

Derzeit sind im Stadtrat fünf Mitglieder der ÖVP, zwei der SPÖ, eines der Grünen und eines der FPÖ vertreten. Die Volkspartei stellt dabei sowohl die Bürgermeisterin als auch den Vizebürgermeister.

Im Jahr 1347 siegelte erstmals ein Dornbirner Ammann namens Huober eine Urkunde. Ihm folgten bis 1849 68 weitere, frei gewählte Ammänner nach. Seit 1849 führt jeweils ein frei gewählter Bürgermeister die Gemeindegeschäfte Dornbirns. So wurden von 1849 bis heute 18 Bürgermeister gewählt.

Bürgermeister der Stadt Dornbirn seit 1857

Das Dornbirner Wappen stützt sich auf drei rechtliche Grundlagen: Zum einen auf die Verleihung durch die Vorarlberger Landesregierung vom 1. Februar 1929, zweitens auf die Verleihung durch Kaiser Franz Joseph I. vom 28. Februar 1902 infolge der Stadterhebung 1901 und drittens auf den Wappenbrief von Erzherzog Ferdinand Karl vom 23. September 1655 an das Gericht Dornbirn. Es zeigt einen grünen Birnbaum auf rot-weiß-rotem Schild. Der Birnbaum steht demnach für die falsch verstandene Bedeutung des Worts „Dornbirn“. Der Schild ist ein Bekenntnis zu den Habsburgern und gleichzeitig eine Abgrenzung von den damaligen Regionalfeinden, den Emsern.


Die aktuellen Ehrenbürger der Stadt Dornbirn sind die beiden zuletzt aus dem Amt ausgeschiedenen Altbürgermeister Rudolf Sohm, dem die Ehrenbürgerwürde 1999 verliehen wurde, und Wolfgang Rümmele, dem sie 2014 verliehen wurde.

Die mittlerweile verstorbenen Ehrenbürger Dornbirns sind Johann Georg Waibel (Altbürgermeister, Verleihung 1894), Ferdinand Gierer (Geistlicher Rat und Stadtpfarrer im Hatlerdorf, Verleihung 1922), Karl Drexel (Abgeordneter zum österreichischen Nationalrat, Verleihung 1935), Victor Hämmerle (Großindustrieller, Verleihung 1935), Hermann Rhomberg (Gründungsvater der Dornbirner Messe, Verleihung 1960), Günther Anton Moosbrugger (Altbürgermeister, Verleihung 1975) sowie Karl Bohle (Altbürgermeister, Verleihung 1984).





</doc>
<doc id="12975" url="https://de.wikipedia.org/wiki?curid=12975" title="Barometer">
Barometer

Ein Barometer (altgriechisch: "barýs" „schwer, gedrückt“ und "métron" „Maß, Maßstab“) ist ein Messgerät zur Bestimmung des statischen Absolut-Luftdrucks und damit eine Sonderform des Manometers. Wird es für meteorologische Zwecke eingesetzt, zeigt es einen virtuellen Wert an, der dem aerostatischen Luftdruck auf Meereshöhe entsprechen würde. Als Sonderfall kann es indirekt zur Höhenmessung eingesetzt werden. Eine Weiterentwicklung des Barometers ist der Barograph, der die zeitliche Entwicklung des Luftdrucks an einem Ort schriftlich oder elektronisch erfasst. Eine weitere Weiterentwicklung des Barometers ist das Mikrobarometer, das in der Lage ist, auch winzige Druckunterschiede zu messen.

Der Begriff „Barometer“ wurde 1665/1666 durch den irischen Naturforscher Robert Boyle eingeführt. Er leitet sich vom griechischen "báros" „Schwere, Gewicht“ und "metreín" „messen“ ab.

Georgius Agricola erwähnt den Luftdruck als Ursache für das Aufsteigen des Wassers in Saugpumpen.

Zur Zeit Galileis, etwa um 1635, wurden die Ingenieure und Brunnenbauer von Florenz beauftragt, umfangreiche Bewässerungsanlagen in den Gärten des Palastes zu erbauen. Sie installierten Saugpumpen, stellten aber erstaunt fest, dass diese nicht in der Lage waren, Wasser in eine Höhe von etwa 10 Meter anzusaugen. Galilei wurde eingeschaltet und beschrieb das Problem 1638 in seinen "Discorsi e dimostrazioni matematiche", aber er starb 1642, ohne die Gelegenheit zur Ausarbeitung einer Lösung für dieses Problem gehabt zu haben. Galilei korrespondierte darüber schon 1630 mit Giovanni Battista Baliani, der ein Wasser-Barometer baute.

In seinen Aufzeichnungen, bereits aus dem Jahr 1614, ist zu lesen, dass er zwar über das Gewicht der Luft nachdachte und dieses als den 660ten Teil des Gewichts des Wassers bestimmte, allerdings hatte er hieraus keine weiteren Schlüsse gezogen. Die Idee, dass die Flüssigkeit nicht von der Saugpumpe angezogen, sondern durch den Druck der Luft in diese hineingetrieben wurde, stand im Widerspruch zu der damaligen Ansicht, dass das Wasser aufstiege, weil die Natur „Abscheu vor der Leere“ (lat. "horror vacui") habe.

Evangelista Torricelli folgte Galilei als Physiker am Hofe des Großherzogs der Toskana nach dessen Tod. Er nahm die Studien seines Vorgängers wieder auf und führte Experimente durch, um zu beweisen, dass es der Luftdruck war, der verhinderte, dass sich das Rohr vollständig entleerte, und dass immer eine bestimmte Quecksilbersäule bestehen blieb. Diese war ungefähr 76 cm hoch, unabhängig davon, wie weit er das Rohr ins Becken tauchte.

Er schloss daraus, dass der Luftdruck auf die Oberfläche des Beckens das auf die Säulenfläche bezogene Gewicht der Quecksilbersäule ausgleicht, und dass analog das Wasser in den Pumpen nur bis etwa 10 Meter gefördert werden kann, wenn man mit der Pumpe ein Vakuum erzeugt. Er stellte zudem fest, dass die Quecksilbersäule sich mit der Zeit änderte und dass eine Abnahme der Höhe einer Schlechtwetterperiode vorausging. Damit erfand Torricelli im Jahre 1643 das Barometer.

Da das offene Reservoir denkbar ungeeignet für den Transport des Messinstruments war, wurden verschiedene andere Lösungen erwogen. Man stellte zum Beispiel lederne poröse Reservoirs her, die an das Rohr angeschlossen wurden und die eine kleine Menge Quecksilber enthielten.
Sir Robert Boyle bog das Barometerrohr nach oben, was zu einem „Siphon-Rohr“ führt, wie es auch heute noch verwendet wird.

Der französische Physiker René Descartes (1596–1650) verbesserte das System von Torricelli, indem er eine Papierskala hinzufügte. Er ist zudem der Erste, der die Idee verbreitet, dass der Luftdruck mit der Höhe abnimmt.

Der Luftdruck führt dazu, dass sich eine Quecksilbersäule von etwa 76 cm Höhe bildet, er reicht aber nicht aus, um den luftleeren Raum darüber zu füllen. Um das Jahr 1640 war die Frage, ob Luft ein Gewicht besitzt, unter den Wissenschaftlern eines der meistdiskutierten Themen.

Blaise Pascal konnte diese "Streitfrage" 1647 mit seinem berühmten Experiment "vide dans le vide" beantworten. Pascal wiederholte darüber hinaus das Experiment von Torricelli, weil er wie Descartes davon überzeugt war, dass, wenn die Luft ein Gewicht hätte, das Quecksilber weniger hoch aufsteigen müsste, wenn man das Experiment in größerer Höhe durchführen würde. Dies bestätigte sich auch, wenn auch mit sehr geringer Genauigkeit, auf der Spitze des 52 Meter hohen Turms von Saint-Jacques in Paris. Mit der Hilfe seines Schwagers Florin Perrier, der am Fuße des Puy de Dôme wohnte, wiederholte er das Experiment am 19. September 1648. Er führte das Experiment in verschiedenen Höhen durch und stellte fest, dass die Höhe der Quecksilbersäule mit zunehmender Seehöhe tatsächlich abnimmt. Noch im darauffolgenden Monat veröffentlichte Pascal seine Ergebnisse in der Abhandlung "Récit de la grande expérience de l'équilibre des liqueurs".

Später benannte man die SI-Einheit für den Druck nach ihm als Pascal, was einem Newton pro Quadratmeter entspricht.

Otto von Guericke konnte 1663 den Luftdruck mit den Magdeburger Halbkugeln nachweisen und erlangte damit vor allem in Deutschland Bekanntheit. Es handelt sich dabei um zwei dicht aneinanderliegende halbe Hohlkugeln, die auch durch entgegengesetzt ziehende Pferdegespanne nicht mehr voneinander getrennt werden konnten, sobald der kugelige Hohlkörper luftleer gepumpt, evakuiert worden war. Nach diesem Prinzip arbeiten auch heute noch Unterdruckkabinen.

Erst ab Mitte des 19. Jahrhunderts wurden Barometer von Instrumentenherstellern, Optikern und Uhrmachern hergestellt, zunächst zu wissenschaftlichen Zwecken, dann auch für den Hausgebrauch. Ab 1870 wurden auf den Skalen meteorologische Bezeichnungen hinzugefügt (gutes Wetter, wechselhaft, etc.).

Im Jahre 1675 machte der Abt Picard, der nachts ein Quecksilberbarometer transportierte, eine merkwürdige Entdeckung. Bei jeder Bewegung erschien ein bläuliches Licht aus dem Rohr. Dieses Phänomen wurde von Francis Hauksbee, einem Schüler von Boyle, untersucht, aber es wurde zu dieser Zeit noch keine befriedigende Erklärung gefunden. Aber ab diesem Zeitpunkt begann man, erste Untersuchungen über elektrische Entladungen in hoch verdünnten Gasen anzustellen. Man weiß heute, dass es Reibungen von Quecksilberatomen an der Glaswand sind, die diese Lichterscheinung bewirken.

Flüssigkeitsbarometer bestehen aus einem mit einer Flüssigkeit gefüllten, senkrechten Rohr, das am oberen Ende luftdicht verschlossen ist. Das untere Ende taucht in ein Vorratsgefäß, das ebenfalls die jeweilige Flüssigkeit enthält. Durch ihr Eigengewicht fließt die Flüssigkeit aus dem Rohr, wobei am oberen Ende ein Unterdruck entsteht. Der Luftdruck wirkt dem entgegen, so dass die Flüssigkeitssäule bei einer bestimmten Höhe zur Ruhe kommt.

Am häufigsten wird hierbei Quecksilber als Flüssigkeit genutzt, wobei man in diesem Fall von einem
Quecksilberbarometer spricht. Bei Normalbedingungen erreicht Quecksilber eine Höhe von 760 mm, sodass für genaue Ergebnisse der abgelesene Wert rechnerisch auf die Standardbedingungen korrigiert werden muss, wobei es zu beachten gilt, dass sich Quecksilber und Glasrohr bei einer Temperaturerhöhung ausdehnen:

mit

Quecksilber wird verwendet, weil durch sein hohes spezifisches Gewicht das Rohr kurz gehalten werden kann. Zum Vergleich müsste das Rohr bei Wasser etwa 10 Meter lang sein. Zum anderen verdunstet nur sehr wenig Quecksilber, trotz des Vakuums am oberen Ende des Rohres und des geöffneten unteren Endes.

Das erste Quecksilberbarometer wurde 1643 von Evangelista Torricelli erfunden. Er beobachtete, dass sich die Höhe der Quecksilbersäule täglich veränderte und schloss daraus, dass sich auch der Luftdruck entsprechend ändert. Nach ihm wurde eine Einheit zur Messung des Luftdrucks (1 Torr = 1 mm Hg, entspricht ca. 133,32 Pa) benannt.

Seit 2009 ist die Herstellung und der Verkauf von Quecksilberbarometern sowie anderen Messgeräten, welche Quecksilber in leicht zerbrechlichen Behältnissen enthalten, in Deutschland, als Umsetzung einer EU-Verordnung, verboten.

Das Prinzip eines Flüssigkeitsbarometers wird auch in leicht abgewandelter Form bei einem so genannten Goethe-Barometer genutzt, welches man auch als Goethe-Glas, Goethe-Wetterglas, Donnerglas oder Wetterglas bezeichnet. Hierbei handelt es sich um ein mit einer Flüssigkeit gefülltes, meist dekoratives Gefäß, welches an der Unterseite einen nach oben gestülpten und zur Erdatmosphäre hin offenen Schnabelhals besitzt, während das Hauptgefäß selbst gegenüber dem Luftdruck abgeschlossen ist. Bei niedrigem Luftdruck (oder bei steigender Temperatur) steigt daher der Flüssigkeitspegel im Schnabelhals und sinkt dementsprechend bei hohem Luftdruck. Zwar hatte Goethe ein solches Barometer in seinem Besitz, jedoch war er nicht der Erfinder dieses Barometertyps. Es ist unklar, wann und von wem es tatsächlich entwickelt wurde. Es dürfte aber so alt sein, wie das Aufkommen gläserner Gefäße mit Tülle. Daher gibt es zum Goethe-Glas etliche, frühere Varianten, zu denen das Niederländische Donner- oder Wetterglas zählt, das bereits 1619 gesichert ist. Dem nach hinten geschlossenen Goethe-Barometer gehen karaffenförmige Wettergläser mit langer tief sitzender Tülle voraus, die sich bis in das 17. Jahrhundert hielten. Sie mussten noch am Hals durch einen Wachsstopfen abgedichtet werden. 

Die bedeutendste Abbildung eines mittelalterlichen Wetterglases findet sich vor 1514 gemalt auf dem Engelskonzert von Matthias Grünewald. Es kündigt auf der Stufe eines himmlischen Pavillons mit Hochstand in der Tülle die Ankunft Mariens an.

Messungen des absoluten Luftdrucks sind mit dem Goethe-Barometer nicht möglich, jedoch können Luftdruckänderungen gemessen werden, die innerhalb einiger Tage auftreten. Da die eingeschlossene Luft auch bei Temperaturänderungen ihr Volumen ändert, muss dazu die Änderung der Umgebungstemperatur im Beobachtungszeitraum gemessen werden. Außerdem müssen noch die Querschnittsfläche "A" des Schnabels und das Volumen formula_5 der eingeschlossenen Luftmenge bestimmt werden. Die eingetretene Luftdruckänderung formula_6 lässt sich dann aus der eingetretenen Höhenänderung formula_7 des Flüssigkeitspegels mit folgender Näherungsformel berechnen (Wasser als Flüssigkeit):

Hier werden nur die Maßzahlen der physikalischen Größen eingesetzt, die sich bei Verwendung der Einheiten gemäß der folgenden Tabelle ergeben:

Bei Dosenbarometern, auch Aneroidbarometern (v. griech.: „a-nerós“ „nicht flüssig“), wird ein dosenartiger Hohlkörper aus dünnem Blech durch den Luftdruck verformt. In der Dose herrscht ein Restdruck von etwa 5 mbar (= 5 hPa = 500 Pa), der die Änderung des Elastizitätsmoduls des Blechs durch die Temperatur kompensiert.

Ein derartiger Hohlkörper wird nach seinem Erfinder Lucien Vidie (1805–1866) auch "Vidie-Dose" genannt. Ab 1881 gab es mit Gotthilf Lufft auch in Deutschland einen ersten Hersteller für Dosenbarometer, der die Vidie-Dose weiterentwickelte und 1909 als eigenes Patent anmeldete.

Bessere Barometer oder Barographen benutzen einen Stapel von bis zu acht derartiger „Dosen“ übereinander, um die Empfindlichkeit der Messung zu erhöhen. Über eine Mechanik wird diese Verformung, bei steigendem Luftdruck eine Verdichtung und bei sinkendem Luftdruck eine Ausdehnung, auf einen Zeiger übertragen.

Ein Problem hierbei ist die Temperaturempfindlichkeit eines solchen Systems. Die Bestandteile der Dose selbst zeigen eine thermische Volumenausdehnung und für ihren Bau werden daher spezielle Legierungen verwendet, bei denen mehrere Komponenten sich nach ihrem Temperaturverhalten her gegenseitig kompensieren und auf diese Weise den störenden Effekt einer Wärmeausdehnung reduzieren, wobei es jedoch trotzdem temperaturbedingte Messfehler gibt. Druckmikrofon und Höhenmesser arbeiten ebenfalls nach diesem Prinzip.

Beim Röhrenbarometer (Bourdonfeder) wird der Umstand, dass bei einem gebogenen Rohr die Außenseite eine größere Fläche aufweist als die Innenseite und damit bei steigendem Druck die Kraftwirkung von außen größer ist, genutzt. Die Verformung in Abhängigkeit vom Druck wird auf einen Zeiger übertragen.

Barometer werden meist in der Meteorologie verwendet und gehören hier als Standardinstrument zu nahezu jeder Wetterstation. Da der Luftdruck mit der Höhe abnimmt, dienen sie auch als Höhenmesser (Altimeter) in Flugzeugen. Wird nicht der Luftdruck der Erdatmosphäre, sondern ein künstlich erzeugter Über- oder Unterdruck gemessen, so spricht man von einem Manometer. Ein weiteres verwandtes Gerät ist das Variometer, das über die Veränderung des Luftdruckes eine Höhenänderung anzeigt (siehe auch Hypsobarometer, Höhenschreiber und Luftdruckmessung in der Luftfahrt). Der Verlauf einer Luftdruckänderung wird mit Barographen aufgezeichnet.

Oft werden Barometer, meist minderer Qualität, in den mittleren Breitengraden als „Wetteranzeigen“ verwendet, da sich Luftdruckänderungen und „schlechtes“ bzw. „gutes“ Wetter hier gegenseitig teilweise beeinflussen. Grund hierfür ist, dass der Frontendurchzug dynamischer Tiefdruckgebiete eine typische Luftdruckänderung zur Folge hat. Ein steigender Luftdruck wird dabei als Anzeichen für gutes Wetter und ein fallender Luftdruck als Anzeichen für schlechtes Wetter interpretiert. Da diese Tendenzen jedoch nur in bestimmten Fällen meteorologisch zu rechtfertigen sind und auch Schlechtwetterereignisse mit einem steigenden Luftdruck einhergehen können, stellen diese nur eine sehr grobe Wettervorhersage dar.

In Kombination mit anderen Messgeräten finden Barometer in Aerographen Verwendung.

Zu Lehrzwecken ist am Meteorologischen Institut der Ludwig-Maximilians Universität München ein 10 m hohes Wasserbarometer aufgebaut. Hier kann auch der Einfluss des Dampfdruckes in dem Raum über der Wassersäule gezeigt werden.

Eine sehr interessante Anwendung des Dosenaneroids besteht in der selbsttätigen Kompensation der Einflüsse des schwankenden Luftdrucks auf Präzisionspendeluhren. Der Astronom Professor Bernhard Wanach schlug im 19. Jahrhundert erstmals die Anwendung eines Dosenbarometers an Pendelstäben vor. Die Anordnung der sogenannten "Aneroiddosenkompensation" besteht aus mehreren in Serie geschalteten Dosen, die mit einem Auflagegewicht belastet sind. Das Gewicht wird von den Dosen in Abhängigkeit vom Luftdruck längs des Pendelstabs bewegt und ändert so das Trägheitsmoment des Pendels. Noch heute werden mit genau berechneten Luftdruckkompensationsinstrumenten bei Präzisionspendeluhren hervorragende Ergebnisse erzielt.

Aufgrund seiner Verwendung zur Wettervorhersage werden auch andere Prognoseinstrumente umgangssprachlich als „Barometer“ bezeichnet. So spricht man von Börsenbarometern (zur Vorhersage von Aktienkursen), Wahlbarometern (zur Vorhersage der Stimmabgabe), etc.




</doc>
<doc id="12977" url="https://de.wikipedia.org/wiki?curid=12977" title="Zimt">
Zimt

Der Zimt, veraltet auch "Zimmet", Echter Zimt („Canehl“), ist ein Gewürz aus der getrockneten Rinde von Zimtbäumen.

Der Name leitet sich aus dem Mittelhochdeutschen "zinemīn"; , und "kinnámōmon", aus dem Semitischen ab.
Manche europäische Sprachen bilden ihre Namen für Zimt von lateinisch "canna" Rohr, womit auf die Form der Zimtstangen angespielt wird; z. B. , , , Zimtbaum (Röhrchenträger). Auch im Mittelhochdeutschen "kanêl", Zimtstange, Zimtröhre. Das lateinische cannella ist ein Diminutiv von canna, entlehnt von kanna für Schilf.

Zimt ist eines der ältesten Gewürze, das angeblich schon vor 2000 v. Chr. in China und Indien als solches verwendet wurde. Die Ägypter verwendeten es zur Einbalsamierung, als Gewürz und als Räuchermittel. Im antiken Griechenland wurde er ebenfalls schon verwendet, dies wird von Herodot und Hippokrates u. a. erwähnt. Er wurde im römischen Reich schon rege gehandelt, man benutzte ihn zuerst als Medizin, Aphrodisiakum und Räucherwerk, erst später als Gewürz. Der römische Kaiser Nero soll einer Legende zufolge nach dem Tod seiner Frau Poppäa, zu ihren Ehren, große Zimtfeuer in den Straßen Roms entzündet haben. Der Handel wurde nach dem Niedergang des römischen Reiches durch die Araber kontrolliert. Im Mittelalter war der Zimt in Europa als Heilmittel gegen Gicht u. a. bekannt und wurde auch schon als Gewürz benutzt. Venedig kontrollierte im 13. und 14. Jahrhundert den Zimthandel in Europa. Danach folgten die Portugiesen, welche 1505 Ceylon kolonisierten, dies führte im 17. Jahrhundert zum Krieg mit den Holländern im Kampf um die Kontrolle der ostindischen Gebiete →Niederländisch-Portugiesischer Krieg.
Im Europa des 16. bis 18. Jahrhunderts galt Zimt als eines der besonders teuren und kostbaren Gewürze. So verbrannte beispielsweise der Augsburger Kaufmann Anton Fugger 1530 die Schuldscheine Karls des V. vor dessen Augen in einem Feuer aus Zimtstangen und demonstrierte damit seinen Reichtum. Auf die Holländer folgten die Engländer →Englisch-Niederländische Seekriege, nach der Übernahme des Handelsmonopols durch die Briten wurde London im 18. Jahrhundert der Hauptumschlagsort für Zimt.

Quelle war ursprünglich der "echte" oder Ceylon-Zimtbaum ("Cinnamomum verum" ) aus Sri Lanka, Burma und Bangladesch; später – und heute mengenmäßig überwiegend – auch die Zimtkassie ("Cinnamomum cassia") (Cassiazimt) aus Seres (China) und auch der billige indonesische Zimt ("Cinnamomum burmannii") sowie der in Japan und China sehr geschätzte vietnamesische Zimt ("Cinnamomum loureiroi"). Diese drei Sorten werden auch generell als „Kassia-Zimt“ bezeichnet, wobei dies eigentlich nicht richtig ist. 

Seltener wird auch das Indische Lorbeerblatt ("Cinnamomum tamala" oder "Mutterzimt") beigemischt. Es werden auch noch "Cinnamomum bejolghota", "Cinnamomum culilawan" und "Cinnamomum philipinense" verwendet. Auch verwilderte Sorten von "Cinnamomum verum" von den Seychellen.

Die „Kassia-Zimtsorten“ sowie auch andere geringwertige Zimte werden auch als "Holzzimt" bezeichnet.

Zimt kommt gemahlen als typisch braunes Pulver, ganz als Zimtstange (zusammengerolltes, röhrenförmiges Rindenstück) oder als Zimtblüten in den Handel. Stangenzimt wird auch Kaneel genannt. 

Zur Gewinnung von Zimtöl werden kleinere Äste und auch die Blätter verwendet.

Das Aroma des Zimtbaumes geht auf das in ihm enthaltene Zimtöl zurück, das bis zu 75 Prozent aus Zimtaldehyd besteht (im Aromastoffverzeichnis: Fl-Nummer 05.014). Weitere wichtige Aromastoffe sind besonders beim Ceylon-Zimt das (auch in Gewürznelken vorkommende) Eugenol (Fl-Nummer 04.003) und beim Cassiazimt, sowie insbesondere beim vietnamesischen und indonesischen Zimt auch das nach Waldmeister duftende Cumarin.

Es gibt eine Reihe von Arten, welche einen zimtähnlichen Geschmack aufweisen. Sie wurden als Substitut oder zur Verfälschung verwendet.

Die Arten "Canella winterana"; Weißer oder Magellanischer Zimt und "Drimys winteri"; Winter(s)rinde (Winterzimt) und "Cinnamodendron corticosum"; Falsche Winter(s)rinde, sowie "Dicypellium caryophyllaceum" (Nelkenzimt) und "Cryptocarya massoia" (Massoirinde) Ferner gibt es noch den Ecuador- oder Amerikanischen Zimt "Ocotea quixos" sowie den Amazonas-Zimt "Aniba canelilla".

Dann gibt es noch viele Arten, die mit „Zimt“ bezeichnet werden, meistens bezieht es sich auf die Farbe, aber nicht auf den Geschmack z. B. Zimterlen, Zimt-Rose, Zimtapfel etc.

Zimt findet in vielen Bereichen eine Verwendung:

Zimt wird häufig zur Aromatisierung von Heißgetränken (Tee) und Spirituosen verwendet, in der indischen und vorderorientalischen Küche auch für Fleischgerichte. Man benutzt einen Teil der Rinde (lateinisch "Cinnamomi Cortex") des Ceylon-Zimtbaums, und zwar deren dünne Bastschicht, die sich röhrenartig zum Stangenzimt (bzw. zur Zimtstange oder Zimtröhre) zusammenrollt, sobald sie vom Holz getrennt wird. Es werden sechs bis zehn Stück der feinsten Innenrinde ineinandergeschoben, und man lässt sie trocknen. Je dünner die Rinde, desto feiner ist das Aroma, das die Stange abgibt. Diese Zimtrollen lassen sich lange verwenden, weil sie ihr Aroma nur langsam verlieren. 

Um die Qualität zu bestimmen, gibt es für den Ceylon-Zimt ein eigenes Wertmaß (Einheit: Ekelle). Der beste Zimt wird mit den Nummern (Ekellen) 00000 bewertet, dann sinkt die Qualität bis Ekelle 0, dann weiter über I bis Ekelle IV. Vom Zustand der Rollen hängt der Erzeugerpreis maßgeblich ab. Der nach Europa importierte Gewürz-Zimt wird vielerorts als Qualität „Hamburg“ bezeichnet und gilt als schlechteste verfügbare Qualität der Rollen, unterscheidet sich jedoch geschmacklich nicht von den anderen Qualitätsstufen, sobald er gemahlen ist. Für den europäischen Markt wird der Zimt fast immer gemahlen. Er ist in Mitteleuropa vor allem in Verbindung mit Zucker, für Süßspeisen, Gebäck und Glühwein, besonders in der Weihnachtszeit gebräuchlich, seltener für herzhafte oder scharfe Speisen oder Fleischgerichte. Für Kaugummi mit Zimtgeschmack wird der Geschmack künstlich erzeugt.

Auch in Asien wird Zimtpulver zur Herstellung von Gewürzmischungen verwendet. Aus Herstellungsabfällen und Spänen wird zudem das Zimtöl gewonnen, das zum Aromatisieren von Likören sowie als Duftstoff in der Parfümindustrie verwendet wird. Regional werden die Blätter ähnlich wie Lorbeerblätter verwendet.

Der Gewürzhandel unterscheidet hauptsächlich zwischen dem in Sri Lanka heimischen Ceylon-Zimt und dem etwas schärfer würzenden, aus China stammenden Zimt der Zimtkassie (Cassiazimt) sowie dem in den USA und den Niederlanden und in der Industrie häufig verwendeten indonesischen Zimt "Cinnamomum burmannii". Bis in die 1960er Jahre war Vietnam die wichtigste Quelle des Cassiazimtes, aufgrund der Auswirkungen des Vietnamkrieges wurde die Zimtproduktion im Hochland von Sumatra (Indonesien) forciert. In der vietnamesischen Küche ist Zimt sehr beliebt in Verbindung mit Fleischgerichten. Heutzutage (2014) sind China, Indonesien und Sri Lanka die Hauptproduzenten.

Echter Zimt besteht aus mehreren, feinen Lagen, die zu einer geschlossenen Stange zusammengerollt sind und im Querschnitt einer Zigarre ähneln. Andere Zimtsorten bestehen meist nur aus einer einzelnen, dicken Rindenschicht, die sich an beiden Enden einrollt und daher keine geschlossene Stange ergibt.

Ist der Zimt gemahlen kann man allerdings nur sehr schwer vermischte Zimtsorten unterscheiden. Es werden in der Industrie häufig Zimtsorten gemischt, aus Kostengründen oder sei es um das Aroma und die Backeigenschaften anzupassen, auch ist der echte Zimt nur begrenzt verfügbar.

Zimtpulver kann auch mit verschiedensten Mitteln gestreckt werden, mit Nuss-, Mandel-, Kakaoschalenpulver, Sandelholz, Holz-, Baumrindenmehl, Zimtabfällen (Chips), Ölsamenrückstände, Palmkernmehl, Nelkenstiele, Galgant, Birnenmehl, Eisenocker etc.

Von der Antike bis in die Frühe Neuzeit galt die Zimtrinde als heilsam unter anderem bei Husten und Schnupfen, als magenstärkend sowie harntreibend, abführend, menstruationsfördernd, aber auch blutstillend, zum Beispiel bei Hämorrhoiden.

Eine mögliche blutzuckersenkende Wirkung von Zimt in frühen Stadien des Diabetes mellitus wird in der modernen Medizin kontrovers diskutiert. In einer ersten Pilotstudie wurde die Wirksamkeit größerer Dosen Zimt (1–6 Gramm) auf Blutzucker- und Blutfettwerte untersucht. Hier konnte eine mögliche Senkung des Nüchternblutzuckers, der Triglyceride, des Gesamt- und des LDL-Cholesterins beobachtet werden. In einer weiteren Studie an 79 Patienten konnte eine Senkung des Blutzuckerspiegels, aber nicht des als „Langzeitblutzuckerspiegel“ geltenden HbA-Werts und der Blutfettwerte beobachtet werden. Zimtextrakt erfüllt nach bisherigem Wissensstand die Kriterien eines pflanzlichen Diätetikums zur adjuvanten Therapie bei Diabetes Typ 2, ein Wirksamkeitsnachweis der Anwendung von Zimt bei Diabetes mellitus durch klinische Studien steht aber noch aus. Zimtöl und Zimtrinde weisen eine gute antimikrobielle Aktivität aus. Dies geht vor allem auf die Wirkung des Zimtaldehyds zurück, die Hauptkomponente des im Zimt enthaltenen ätherischen Öls; besonders aktive Komponenten sind aber auch p-Cymol, Linalool und o-Methoxyzimtaldehyd.

Man unterscheidet das ätherische Öl aus den Blättern und dem aus der Rinde, das mittels Wasserdampfdestillation gewonnen wird. Das "Zimtblätteröl" besteht aus ca. 70–85 % Eugenol sowie Zimtaldehyd, (Phenole), Monoterpenen (Linalool), Sesquiterpenen, anderen Aldehyden und Estern. Das "Zimtrindenöl" hat 55–75 % Zimtaldehyd, bis ca. 10 % Eugenol (Phenole), Monoterpenen (Linalool), Sesquiterpene, Ester und Monoterpenole als Inhaltsstoffe. Beide ätherischen Öle sind sehr hautreizend. Wobei die Zusammensetzung je nach Herkunft sehr stark schwankt. Es können jedoch auch aus anderen Zimtbäumen, als dem echtem Zimt, Öle gewonnen werden, diese können aber eine unterschiedliche Zusammensetzung haben.

Ätherisches Öl aus den Zimtblättern und der Zimtrinde darf in der Schwangerschaft nicht verwendet werden, da es wehenfördernd wirkt. Wenn jedoch die Geburt schwer vorangeht, können durch die Anwendung von Zimt Wehen stimuliert werden. Für Zimtaldehyd konnten im Versuch fördernde Effekte auf die Progesteronsynthese nachgewiesen werden.

Zimt wurde bereits im Altertum als Räuchermittel verwendet. So war die Rinde u. a. eine Zutat des berühmten altägyptischen Räucherwerks Kyphi. Sowohl Blüte als auch Rinde setzen bei Verbrennung den typischen, blumig-zimtigen Geruch frei.

In Zimt, vor allem in den billigeren Zimtsorten, ist Cumarin enthalten, das in höheren Dosen als gesundheitsschädlich gilt. In Fertigprodukten wird fast ausschließlich dieser aus China, Indonesien oder Vietnam stammende Zimt („Kassia-Zimt“) verarbeitet.

Der Cumarin-Anteil der Zimtsorten unterscheidet sich erheblich: Während er beim Zimt der Zimtkassie (Cassiazimt) bei ca. 0,2–0,3 g pro kg liegt und im indonesischen sowie im vietnamesischen Zimt bis zu 9 g pro kg aufweist, finden sich in der gleichen Menge Ceylon-Zimt nur ca. 0,02 g Cumarin.
Cumarin gehört laut gültiger Aromenverordnung EG 1334/2008 zu den Stoffen, die Lebensmitteln nicht als solche zugesetzt werden dürfen (Anhang III, Teil A der Aromenverordnung) und unterliegt bestimmten Höchstmengen, wenn es von Natur aus in Aromen oder Lebensmittelzutaten mit Aromaeigenschaften vorkommt (Anhang III, Teil B). Die zulässigen Höchstmengen liegen je nach Art des Lebensmittels zwischen 5 mg/kg bei Dessertspeisen und 50 mg/kg bei traditionellen und/oder saisonalen Backwaren, bei denen Zimt in der Kennzeichnung angegeben ist.

Cumarin kann bei Überdosierung und bei empfindlichen Menschen Kopfschmerzen verursachen. Bei starken Überdosierungen können Leberschäden, Leberentzündungen und möglicherweise auch Krebs auftreten, wie in Tierversuchen mit Ratten festgestellt wurde. Deren Übertragbarkeit auf den Menschen ist jedoch ungewiss. Vergleichbare Studien am Menschen wurden nicht durchgeführt.

Bei Lebensmittelproben wurden erstmals im Januar 2006 in Nordrhein-Westfalen Zimtprodukte gefunden, die den Höchstwert des Cumarinanteils (gemäß gültiger Aromenverordnung) um das 37-fache überschritten. Im Juni 2006 warnte auch das Bundesinstitut für Risikobewertung (BfR) in einer Stellungnahme vor dem Verzehr großer Mengen von zimthaltigen Produkten: Schon bei 20 Gramm der höchstbelasteten Zimtsterne täglich – das entspricht etwa drei Stück – über einen längeren Zeitraum werde die maximal tolerierbare Aufnahme bei Kleinkindern erreicht. Eine zweite Stellungnahme des BfR bezieht sich auf Zimtkapseln, die zur Behandlung von Diabetes mellitus Typ II verkauft werden. Weitere Kontrollen wurden im Oktober 2006 vom Verbraucherministerium angekündigt. Hierbei wurden in Rheinland-Pfalz Zimtprodukte entdeckt, die 103 mg Cumarin pro Kilogramm aufwiesen, während der Höchstwert der seinerzeit gültigen deutschen Aromenverordnung nur 2 mg/kg betrug (bis 1. November 2006 jedoch 67 mg/kg).

Das BfR hat den 2006 veröffentlichten TDI-Wert (tolerable daily intake, tolerierte Tagesdosis) von 0,1 Milligramm pro Kilogramm Körpergewicht pro Tag auf Basis neuer Daten zur Aufnahme und Bioverfügbarkeit von Cumarin im September 2012 bestätigt. Gleichzeitig weist das Amt darauf hin, dass Überschreitungen des TDI-Wertes nur dann möglich sind, wenn täglich große Mengen an zimthaltigen Lebensmitteln verzehrt würden. Bei Kleinkindern mit einem Körpergewicht von 15 kg wäre laut BfR der TDI-Wert bei einem täglichen Verzehr von 6 Zimtsternen oder 100 g Lebkuchen ausgeschöpft. 

Auch in anderen Produkten, wie in Frühstücksprodukten, Lebkuchen, Puddings, Glühwein, diversen Teesorten, Gewürzmischungen (z. B. Curry) und sogar in Kosmetika kann weiterhin Zimt enthalten sein. Daher sollte die Tagesration, entsprechend dem persönlichen Konsum derartig „belasteter“ Produkte, ggf. unter die Empfehlungen des BfR gelegt werden.

Einen eindeutigen Beleg für die angebliche Gefährlichkeit von Cumarin beim normalen Gebrauch von cumarinhaltigen Gewürzen gibt es allerdings nicht. In allen Studien trat eine gesundheitschädigende Wirkung erst nach extremen Überdosierungen bei Versuchen an Ratten auf.

Im häuslichen Bereich wird empfohlen, den teureren Ceylon-Zimt zu verwenden, der in Asia-Shops (hier bes. Tamil-Shops), Reformhäusern, Apotheken oder Drogeriemärkten bezogen werden kann und aufgrund des geringen Cumarin-Gehalts als unbedenklich gilt.

Das BfR wirft der Lebensmittelindustrie vor, aus Kostengründen den billigeren „Kassia-Zimt“ anstelle des teureren Ceylon-Zimts einzusetzen. Die Lebensmittelindustrie bestreitet jedoch den Vorwurf mit dem Argument, dass „Kassia-Zimt“ vor allem wegen seines hervorragenden Geschmacks eingesetzt werde. Auch überstehe das typische Zimtaroma den Backprozess besser. Weiterhin sei es schon aus mengenmäßigen Gründen nicht möglich, den Ceylon-Zimt zu verwenden, da dieser dafür zu selten sei.





</doc>
<doc id="12979" url="https://de.wikipedia.org/wiki?curid=12979" title="TOS (Betriebssystem)">
TOS (Betriebssystem)

TOS (Akronym für "The Operating System", seltener "Tramiel Operating System", nach dem damaligen Atari-Chef Jack Tramiel) ist ein Computerbetriebssystem. Es wurde für die Heimcomputerserie Atari ST von 1985 bis 1994 entwickelt.

TOS war bei seinem Erscheinen 1985 vollständig in GEM, eine von Digital Research entwickelte und für ihre Zeit sehr komfortable grafische Benutzeroberfläche, integriert. Es bestand somit für Endanwender keine unmittelbare Notwendigkeit, den Rechner auf Betriebssystemebene zu bedienen.

TOS sollte ursprünglich auf CP/M-68K (einem Betriebssystem von Digital Research) aufbauen und über eine grafische Oberfläche ähnlich dem Mac namens GEM (ebenfalls von Digital Research) verfügen, die parallel dazu für 8086-basierte Rechner entwickelt wurde.
Aufgrund vieler Mängel von CP/M-68K wurde dies als Fundament für TOS verworfen, lediglich die Prototypen des Atari ST, die auf der CES gezeigt wurden, arbeiteten mit CP/M-68K.
Stattdessen entschied Atari, das noch in der Entwicklung befindliche GEMDOS, ebenfalls von Digital Research, zu verwenden, das leistungsfähiger schien und deutlich besser auf den Betrieb einer grafischen Oberfläche ausgerichtet war als CP/M-68K. Tatsächlich war GEMDOS den reinen DOS-Systemen MS-DOS und DR-DOS sehr ähnlich und verwendete ein kompatibles Diskettenformat.
Aufgrund des enormen Zeitdrucks wurde TOS nicht rechtzeitig fertiggestellt und musste auf frühen Atari 520ST (1. Serie) von Diskette geladen und im RAM ausgeführt werden.
Später wurde das Betriebssystem aber im ROM integriert.

Generell laufen alle Versionen des TOS 1.0x auf Atari ST- oder STE-Computern. Die folgenden Versionen wurden entwickelt und in Umlauf gebracht:

Auch „ROM-TOS“ genannt. Das TOS 1.00 wurde unter großem Zeitdruck entwickelt und gilt als stark fehlerbehaftet und extrem langsam. Fehler in der Speicherverwaltung des GEMDOS führte nach ausdauerndem Betrieb gerne zum Absturz und die Festplattenunterstützung war nur sehr rudimentär.
TOS 1.00 war die erste TOS-Version, die im ROM ausgeliefert wurde, vornehmlich in Rechnern mit der Bezeichnung 260ST und 520ST, bzw. 520STm in Form von 6 × 32KB EPROMs.

Auch „BLiTTER-TOS“ genannt, da es um die Routinen zur Verwaltung des Grafik-coprozessors „BLiTTER“ erweitert wurde. Einige grobe Fehler der Vorgängerversion wurden beseitigt, allerdings blieb dieses TOS weit hinter den Erwartungen zurück. Trotzdem erlangte es den höchsten Verbreitungsgrad aller TOS-Versionen, da es in den beliebten Rechnern 1040STf/520STf, bzw. 1040STfm/520STfm zum Einsatz kam, ebenfalls in 6 EPROMs a 32KB, oder, selten in 2 × 96KB.

Auch „Rainbow-TOS“ genannt, weil das Atari-Logo im „Desktop-Info“-Dialog in Regenbogenfarben gehalten war. In dieser Version waren die gröbsten Fehler der Vorgänger beseitigt und viele Grafikroutinen beschleunigt. Einige Eigenheiten der grafischen Oberfläche wurden verbessert, wie z. B. die Dateiauswahlbox oder die Möglichkeit, Dateien zu verschieben. Allerdings nicht fehlerfrei, und so bot Atari viele kleine Patches an, die idealerweise von Festplatte bei jedem Start geladen werden sollten. Inoffiziell galt diese Version lange als die „letzte“ TOS-Version für Atari ST-Computer und wurde vor allem in Rechnern der Mega- bzw. Mega ST-Reihe eingesetzt, wiederum in 6 × 32KB oder 2 × 96KB.

Diese Version entsprach im Wesentlichen der Version TOS 1.04, unterstützte jedoch die Hardware-Erweiterungen des STE und kam dementsprechend nur in diesen zum Einsatz. Zwar wird die Hardware des STE kaum durch zusätzliche Routinen unterstützt, die vorhandenen wurden aber entsprechend erweitert. Außerdem richtet diese Version als erste beim Start die sogenannte „Cookie-Jar“ ein, in der Daten über den Rechner zugänglich waren, z. B. ob es sich um einen ST oder STE handelt, ob eine FPU vorhanden etc.
Nur in 520STE und 1040STE eingesetzt, aufgrund der neuen Größe (256KB) immer in 2 × 128KB.

Trotz des scheinbar großen Versionssprungs nur eine minimale Erweiterung gegenüber TOS 1.06, welches einen deutlich sichtbaren Fehler hatte: An einem Farbmonitor startete der Rechner immer in der niedrigen Auflösung, gleich, welche der Benutzer eingestellt hatte. TOS 1.62 behob vor allem diesen Fehler. Nur in 520STE und 1040STE eingesetzt, ebenfalls in Form von 2 × 128KB EPROM-Chips.

Die unerwartete Versionsnummer geht auf die Bezeichnung „TOS030“ zurück, die für das TOS in den ersten Atari-TT-Prototypen verwendet wurde. Ursprünglich war der Atari TT als Unix-Computer mit AT&Ts System IV geplant, bevor Atari das eigene Betriebssystem auf diesen Computer portierte, vermutlich auf Basis von TOS 1.06, erweitert um Betriebssystemfunktionen zur Ansteuerung der neuen Hardware im Atari TT.
In den weiteren Schritten der Entwicklung des TOS 3.0x wurde vor allem die Benutzeroberfläche verbessert: Verknüpfungen zu Dateien können auf dem Desktop abgelegt werden, Icons nachgeladen und individuell zugewiesen werden, Datenträger durchsucht werden und Tastaturkürzel zugewiesen und verwendet werden.
Drei Versionen sind verbreitet worden: 3.01 als erste Variante, gefolgt von 3.05 und 3.06.
Neben dem Atari TT wurden auch die Atari-Klone Medusa und Hades mit TOS 3.0x-Varianten bestückt.

TOS 2.0x wurde mit dem MegaSTE und somit zeitlich nach TOS 3.0x eingeführt. Die erste Version war 2.05, da diese von TOS 3.05 für den Atari TT abgeleitet worden war. Es übernahm den erweiterten Desktop von TOS 3.05 und einige Betriebssystemfunktionen, um prinzipiell zum Atari TT kompatibel zu sein, sofern dessen CPU, Grafikauflösung oder Speicherausbau nicht explizit benötigt wurde.
TOS 2.05 war auf den Gebrauch in STE-Computern beschränkt und gerade dies löste Proteste bei Atari-Usern, Software-Entwicklern und Fachhändlern aus, die forderten, dieses deutlich modernere und freundlichere Betriebssystem auch in anderen ST- und STE-Computern einsetzen zu können.
Daraus entstand TOS 2.06, das nicht nur auf allen ST- und STE-Computern lief, sondern außerdem von IDE-Festplatten booten konnte und automatische Stepraten-Umschaltung für HD-Diskettenlaufwerke bot.
Da TOS 2.06 mit 256 KB größer war als TOS 1.00 bis TOS 1.04 mit 192 KB und damit auch einen anderen Adressraum belegte, war eine direkte Nachrüstung in existierenden ST-Computern nicht möglich und erforderte Adapterplatinen, die von verschiedenen Herstellern, oft auch in Verbindung mit IDE-Schnittstellen, angeboten wurden. In Atari 520STE- und 1040STE-Computern konnte das TOS einfach durch Austausch der EPROM-Chips aktualisiert werden.

Neben den Anpassungen an die leistungsfähigere Hardware des Falcon und der Unterstützung des DSP bot TOS 4 erstmals animierten 3D-Look, Farbicons, Pop-ups und Untermenüs. Diese Erweiterungen konnten dank eigener GEM-Bibliotheken (WinDom, SysGem, faceVALUE) auch unter älteren TOS-Versionen genutzt werden.
Erstmals in einem TOS sind die verschiedenen Sprachversionen in einem ROM zusammengefasst, die Einstellungen werden aus dem NVRAM ausgelesen.

Ein unerwartetes Comeback erlebte TOS 4 auf dem Atari-Klon Milan der Firma Milan Computersysteme. Neben der Verwendung eines moderneren Compilers (GNU C-Compiler) und Anpassungen an die veränderte Hardware (68040 CPU) gibt es in späteren Versionen (TOS 4.08) sichtbare Änderungen in Form von runden Optionsfeldern (Radiobutton) und eckigen Auswahlkästen (Checkbox). Diese rein optischen Neuerungen waren schon vor dem Milan-TOS in diversen GEM-Bibliotheken eingebaut worden. TOS 4.08 ist nur auf dem Milan lauffähig. An der Umsetzung und Erweiterung von TOS 4 auf den Milan war Atari nicht beteiligt.

Zeitlich vor dem Milan-TOS erschien noch inoffiziell TOS 4.92, welches als Beta-Version auf diversen Internet-Seiten kursiert. Auffälligste Änderungen: Zusatzprogramme (Accessories) können nun jederzeit nachgeladen werden, und die Fenster der Benutzeroberfläche sind minimierbar.

Ein unvollständiges Multitasking war schon in TOS 1 bis 4 möglich (Start sogenannter „Accessories“). Andere Hersteller (MultiGEM, Mag!X) boten hingegen schon echtes Multitasking an. Schließlich schloss Atari auf und veröffentlichte MultiTOS. Es war neu entwickelt und basierte nicht auf TOS 1–4, sondern auf dem von Eric Smith entwickelten MiNT, das in der Lage war, mehrere TOS-Programme ohne grafische Benutzeroberfläche auszuführen, und der grafischen Oberfläche "MultiAES", die den parallelen Einsatz von GEM-Programmen erlaubte. Sie war der Benutzeroberfläche des TOS 4.0x sehr ähnlich, brachte aber Inkompatibilitäten mit sich.

MultiTOS bot präemptives Multitasking und Speicherschutz (mit dem 68030 mit Hilfe der PMMU), die Benutzeroberfläche entsprach weitgehend dem Falcon-TOS. Besonders der (abschaltbare) Speicherschutz stellte viele Atari-Programme vor Probleme, ein großer Kritikpunkt war außerdem die niedrige Geschwindigkeit: Ein sinnvoller Einsatz war erst auf Rechnern mit 68030-CPU möglich.

MultiAES 4.1, eine fehlerbereinigte und beschleunigte Version der GEM-Komponente in MultiTOS, wurde nicht mehr offiziell als Update angeboten, das quelltextoffene MiNT wird hingegen bis heute weiterentwickelt.

TOS ist primär aus 5 Modulen und dem Desktop zusammengesetzt:

Das BIOS stellt die unterste Schicht des Betriebssystems dar und abstrahiert einen großen Teil der zugrunde liegenden Hardware. Das BIOS legt dabei die Grundlage für den Betrieb eines CP/M oder CP/M-ähnlichen Systems, das heißt, es verfügt über fundamentale Funktionen zum Lesen und Schreiben von Sektoren, Einlesen oder Ausgeben von Zeichen, einfache Verwaltung von Speicher und Zeitgebern.
Das BIOS wird innerhalb von TOS komplett von GEMDOS gekapselt und soll daher von Applikationsentwicklern nicht direkt verwendet werden.

Ähnlich wie das BIOS abstrahiert das XBIOS die Hardware auf eine sehr fundamentale Weise, bedient dabei aber nicht das GEMDOS. Im Wesentlichen bietet das XBIOS Funktionen zur Verwaltung von Hardware, die nicht von GEMDOS/BIOS genutzt wird aber vorhanden ist, wie z. B. Klangerzeugung (X32), Setzen der Farbpalette, Verwaltung von Tastatur, Maus, Auflösung, Bildschirmspeicher etc.

Das GEMDOS ist Systemen wie MS-DOS oder DR-DOS sehr ähnlich. Es bietet Funktionen zur Speicherverwaltung, Dateiverarbeitung mit hierarchischem Filesystem, fundamentale Verwaltung von Prozessen, Konsolen-ein- und -ausgabe über Kanäle etc.
Zwar bietet GEMDOS eine fundamentale Prozessverwaltung, ist aber nicht multitaskingfähig.
Daher wurde das GEMDOS in MultiTOS durch MiNT ersetzt.

Die Grundlage der grafischen Benutzeroberfläche GEM. Das Virtual Device Interface abstrahiert komplexere Ein- und Ausgabegeräte, wobei der Schwerpunkt – insbesondere innerhalb des TOS – auf Bildschirmausgaben liegt. Im Wesentlichen besteht das VDI aus einem (oder prinzipiell mehreren) Gerätetreibern und einem sogenannten Graphical Device Operating System (GDOS), das im TOS nur sehr rudimentär vorhanden ist. Letztlich bietet das VDI einen Katalog von Funktionen zum Zeichnen von grafischen Objekten (sogenannten Primitives) wie z. B. Linien, Kreise, Rechtecke, mit verschiedensten Attributen wie z. B. Farben, Füllmustern, Liniendicken, sowie zur Ausgabe von Zeichen mit variablen Zeichensätzen und -attributen.

Die Application Environment Services (AES) stellen eine Bibliothek von Funktionen für Applikationen zur Verfügung. Diese reichen von der Applikationsverwaltung selbst (Initialisierung, Betrieb, Deinitialisierung) über Ereignisverwaltung (z. B. Mausklick, Timer, Mitteilungen, etc.) hin zur Fenster- und Menüzeilenverwaltung, Dialogboxen und Dateiauswahlboxen. Das AES selbst ist sozusagen „unsichtbar“, wird aber von GEM-Programmen genutzt und verleiht diesen das charakteristische Verhalten und Aussehen.
Im Gegensatz zum restlichen TOS unterstützt das AES, wenn auch nur rudimentär, kooperatives Multitasking. Da das restliche TOS dies aber nicht erlaubt, kann TOS nur je ein Programm starten, aber gleichzeitig mehrere kleine Hilfsprogramme, sogenannte Accessories, bedienen.
In MultiTOS wird das sogenannte MultiAES nachgeladen, das diese Einschränkungen nicht mehr hat.

Dies ist zwar kein Betriebssystem-Modul, aber im TOS enthalten. Es stellt die primäre Arbeitsumgebung nach dem Start des Betriebssystems dar und erlaubt dem Benutzer, mit Hilfe der Maus, Dateioperationen auszuführen und Programme zu starten.

Aufgrund des „unfertigen“ GEMDOS, auf dem essentielle Teile des TOS basieren, und des enormen Zeitdrucks, unter dem TOS entwickelt worden ist, gibt es einige Besonderheiten im Vergleich mit anderen Betriebssystem aus dem gleichen Zeitraum:

Das Diskettenformat, wie es von GEMDOS verwendet wird, ist kompatibel zu MS-DOS, TOS 1.00 und 1.02 legen beim Formatieren aber einige Daten anders an, als MS-DOS diese benötigt. Erst ab TOS 1.04 formatiert TOS die Disketten so, dass MS-DOS diese auch akzeptiert. Unter MS-DOS formatierte Disketten sind unter jeder TOS-Version benutzbar.

Prinzipiell ist TOS in der Lage, von Diskette oder Festplatte zu booten, d. h. TOS liest den Bootsektor, prüft ihn und führt ihn aus. TOS beinhaltet aber keine Festplattentreiber, daher muss im Rootsektor einer eventuell angeschlossenen Festplatte ein Treiber vorliegen, um die Festplatte nutzen zu können (z. B. AHDI von Atari oder HDDriver von Uwe Seimet).

Im Gegensatz zu vielen anderen Betriebssystemen arbeitet TOS beim Booten kein Script ab. Programme, die automatisch gestartet werden, können daher keine Parameter annehmen und werden in der Reihenfolge ausgeführt, in der sie auf dem Boot-Medium vorliegen. Mit der Verbreitung größerer Festplatten wurden daher sogenannte Bootmanager populär, die relativ früh während des Bootens von Festplatte gestartet werden sollten und dem Benutzer erlaubten, (meist durch Umbenennung) Programme zu aktivieren und deaktivieren, die während des weiteren Bootvorgangs geladen werden sollten (z. B. XBoot III von Ten Software Design).

Wie CP/M erlaubt GEMDOS den Betrieb einer textbasierten Konsole, bringt aber selbst keinen Kommandozeileninterpreter mit. Software kann aber diese GEMDOS-Konsole für Ein- und Ausgaben nutzen, die sich wie ein VT52-Terminal verhält. Allerdings läuft diese Konsole unter TOS nicht in einem Fenster, sondern verwendet den gesamten Bildschirm exklusiv. Erst mit der Erweiterung „MINIWIN“ von MultiTOS wird die Konsolenausgabe in ein Fenster umgeleitet.

Das Vorhandensein dieser Konsole erlaubte eine Gruppierung der Software unter TOS in

In CP/M, DR-DOS und MS-DOS geben die Betriebssystemfunktionen „9“ eine Zeichenkette aus, die mit einem Dollarzeichen terminiert sein muss. Einen Grund für die Wahl dieses Zeichens scheint nur Gary Kildall selbst gekannt zu haben. Auch in GEMDOS wird die Funktion „9“ für die Ausgabe einer Zeichenkette verwendet, diese wird aber mit einem 0-Byte (also NULL = '\0', nicht dem Zeichen „0“) abgeschlossen, wie in der Programmiersprache C üblich.

Es gab mehrere Erweiterungen von TOS von anderen Anbietern, die bekannteste war wohl KaOS.

TOS unterliegt nach wie vor Lizenzbestimmungen und ist nicht frei verfügbar. Die Nutzungsrechte an TOS liegen heute bei der Milan Computer GmbH (Kiel, Deutschland) und der Medusa Computer Systems (Uster, Schweiz). Diese dürfen TOS anpassen und mit ihren Computern verwenden und verkaufen. So wurde TOS an die, nicht mehr von Atari entwickelte, neuere Hardware angepasst. 
Ab 2002 wurde von freien Entwicklern ein völlig freies TOS namens EmuTOS programmiert.




</doc>
<doc id="12980" url="https://de.wikipedia.org/wiki?curid=12980" title="Schriftgrad">
Schriftgrad

Die Begriffe Schriftgrad, Schriftsatzmaß oder Kegelhöhe (auch Kegelstärke) bezeichnen in der Typografie ein Maß für die Größe einer Schrift. Der Kegel (im Bild #6) ist im Bleisatz der Körper, der das etwas kleinere, spiegelverkehrte Abbild des Buchstabens (#2) trägt. Die Kegelhöhe (Strecke d) bezeichnet die Höhe der Bleikegel. Da die Kegel etwas höher als die Buchstaben sind, ist die Kegelhöhe oder der Schriftgrad immer etwas größer als die Summe aus Ober-, Mittel- und Unterlänge und damit größer als die tatsächliche Buchstabengröße.

Für den Schriftgrad werden verschiedene Maßeinheiten verwendet und meistens als „Punkt“ bezeichnet. Diese Maßeinheiten werden bei Druckerzeugnissen nicht nur für den Schriftgrad, sondern auch für Zeilenabstände und Ähnliches verwendet.

Festgeschrieben sind die Maße in der DIN 16507-1 (aktuell "Stand September 1998").

Das Messgerät für in Punkt anzugebende Größen ist das Typometer.

Das Bild zeigt die Schriften Helvetica, Garamond und Bickham Script bei gleichem Schriftgrad im Vergleich.

Da der Schriftgrad nur die Kegelhöhe (auch bei Fonts) beschreibt, sagt er nichts über den optischen Eindruck der Schriftgröße aus. Dieser ist vor allem von der Mittellänge der Schrift abhängig. Besitzt die Schrift eine besonders kleine Ober- und Unterlänge, so ist die Mittellänge auf dem Schriftkegel proportional größer, da der Schriftgestalter mit der Spannweite zwischen Ober- und Unterlänge meist die gesamte Kegelhöhe bespielt.

Script-Fonts mit besonders ausschweifenden Ober- und Unterlängen (wie die Bickham Script) wirken daher oft sehr klein. Aus demselben Grund ist die Annahme, Antiqua-Schriften sähen generell kleiner aus als Grotesk-Schriften, falsch. Dies gilt nur für den Vergleich von klassischen Antiqua (wie der Garamond) mit klassischen Grotesken (wie der Helvetica), bzw. von Antiqua und Grotesken mit vergleichbarer Metrik.

Der Punkt (p) ist die Grundeinheit zur Angabe von Schriftgrößen.

Das erste typographische Maßsystem konzipierte 1695 Sébastien Truchet (1657–1729) von der Französischen Akademie der Wissenschaften. Er nahm dazu als Längenmaß den königlichen Pariser Fuß ("Pied de Roi", „Königsfuß“) von etwa 32,484 cm, der als ein Sechstel der Pariser "Toise" (Klafter), des in Paris geltenden eisernen Normstabes "Toise du Grand Châtelet", definiert war. Ein Fuß ("Pied") wurde in 12 Zoll und ein Zoll ("Pouce") in 12 Linien unterteilt. Trouchet nannte nun ein Zwölftel der Pariser Linie ("Ligne") eine "Ligne seconde" („zweite Linie“), dies waren etwa 0,188 mm. Die "Ligne seconde" sollte jedoch keine allgemeine Verbreitung finden.

Etwa seit 1737 nannte der französische Drucker Pierre Simon Fournier ein Sechstel der von ihm verwendeten Linie einen "Point typographique" („typographischen Punkt“), wobei er von einem Fuß von nur rund 29,8 cm ausging, da es in Frankreich regional variierende Längen der "Toise" und damit auch des Fußes gab. Dieser sogenannte Fournier-Punkt (etwa 0,345 mm) wurde später nicht mehr verwendet.

Im Jahr 1766 wurde eine 1735 hergestellte Kopie der "Toise du Grand Châtelet", das Original verschwand 1755 vermutlich durch Diebstahl, zum Prototyp des gesetzlichen Längenmaßes in ganz Frankreich erklärt.

Ende des 18. Jahrhunderts entwickelten François Ambroise Didot und sein Sohn Firmin Didot das typographische Maßsystem weiter. Der Didot-Punkt, der sich später europaweit durchsetzte, entsprach einem Sechstel der Pariser Linie, also etwa 0,375972 mm (traditionell aber 0,376065 mm). Er wird üblicherweise mit 0,376 mm angegeben und auch so verwendet, da dies weit innerhalb aller technischen Toleranzen liegt. Das Grundmaß war also wie bei Truchet der Pariser Fuß, so sind 12 × 12 × 6 = 864 Didot-Punkt genau ein Pariser Fuß.

Die nächstgrößere Einheit in diesem System ist das Cicero. Ein Cicero entspricht 12 Didot-Punkt. Vier Cicero wiederum ergeben eine Konkordanz.

Im Jahr 1975 wurde von der ISO der Didot-Punkt auf genau 0,375 mm festgelegt. Für die Verwendung mit den existierenden Druckmaschinen war aber eine Modifikation von mehr als einem Viertel Prozent erheblich und daher technisch zu schwierig zu verwirklichen. Außerdem wurde zu dieser Zeit gerade auf Fotosatztechnik umgestellt, so wurde dieser Vorschlag in der Praxis nie vollständig umgesetzt, obwohl offiziell ein Didot-Punkt mm beträgt.

Ende des 19. Jahrhunderts kam aus den USA mit der Erfindung der Linotype-Zeilengussmaschine ein alternatives Punktmaß auch nach Europa: der Pica-Punkt (pp). Die amerikanischen Drucker verwendeten einen eigenen, amerikanischen „Druckerfuß“, der recht genau 1024/1000 römischem Fuß entspricht, also etwa 303,5 mm.

Von drei konkurrierenden, fast gleichen Definitionen verabschiedete das 15. Treffen der "US-Type Founders Association of the U.S.A." (1886) das sogenannte Johnson Pica zu genau 0,166 Zoll. Der Vorschlag von Nelson C. Hawks (1200/7227 in/pt ≈ 0.166044 in/pc) sowie die direkte Bezugnahme auf das metrische System (83/350 pc/mm ≈ 0,1660184 in/pc) blieben unberücksichtigt.

Analog zum Verhältnis von Cicero zu Didot-Punkt wird hier ein Pica in 12 Punkt geteilt.
Daher misst der traditionelle amerikanische Printer’s Point 351,36 µm.

In manchen Quellen wird der amerikanische Punkt als (näherungsweise) 100/7227 inch angegeben, das wäre ca. 351,4598 µm und entspricht der Definition nach Hawks. Der Punkt mit metrischem Bezug wäre etwa 351,4056 µm groß.

Im Desktop-Publishing (DTP) wird heute nahezu ausschließlich eine vereinfachte Definition des amerikanischen Punktes verwendet.

Der DTP-Punkt, abgekürzt ‚pt‘, gelegentlich auch PostScript-Punkt genannt, wurde als der 864. Teil des englischen "foot" von 1959 definiert. Er misst also exakt Zoll, d. h. 0,0138 Zoll oder 0,3527 mm. Er ist zurzeit das einzig verlässliche Maß in den meisten Anwendungsprogrammen (Druckerkommunikation, Word, Draw, Photoshop etc. – Calamus und CorelDraw hingegen wurden metrisch programmiert).

Das Satzsystem TeX verwendet ‚pt‘ als Abkürzung für den standardmäßigen "Printer’s Point" und nennt den DTP-Punkt entsprechend "big point" ‚bp‘, da er etwas größer ist.

In CSS wird dieser Punkt auch in ein einfaches Verhältnis von 4:3 zum Referenzpixel ‚px‘ gesetzt, der nicht unbedingt dem Gerätepixel entspricht.

Bei einer im Heimdruck häufig anzutreffenden Punktdichte von 300 dpi entspricht ein DTP-Punkt dann ungefähr vier Bildpunkten in der Reproduktion. Ein Schriftzeichen mit 12 pt wird in der Höhe unter diesen Voraussetzungen mit 50 Bildpunkten gedruckt.

Die deutsche Norm DIN 16507-2:1999 sieht für Schriftgrößenangaben und Zeilenhöhen im elektronischen Satz ein Modul von 250 µm vor, mit einem Submodul von 50 µm für Zwischengrößen. Dieser Modul wird teilweise auch wie eine dem Punkt entsprechende Einheit verwendet und heißt dann "Quart" (‚q‘), da sie einem Viertelmillimeter entspricht, und ist insbesondere in Japan als キュ "kyu" verbreitet. Als codice_1 ist es ab Level 3 auch Teil von CSS.

Statt der Kegelhöhe wird in DIN 16507-2 die messbare Größe der Versalhöhe zur Angabe der Schriftgröße verwendet. Dieses System hat bisher keine weite Verbreitung gefunden, allerdings unterstützen verschiedene Computertypographiesprachen (z. B. TeX, CSS, Framemaker) die Maßangabe in metrischen Einheiten.

Otl Aicher war einer der Befürworter dieses Systems und propagierte Schriftgrade, die teilweise an die traditionellen Namen angelehnt sind.
Neben den absoluten Schriftgrößen, bei denen einem Schriftgrad eine bestimmte Länge zugeordnet werden kann, gibt es in der Computergrafik auch eine Maßangabe in Pixel (px). Während die reale Größe eines Pixels bei Geräten durch die Konstruktion festgelegt ist, kann es beim Drucken eines in Pixel angegebenen Schriftgrads zu Überraschungen kommen, wenn die Zuordnung nicht festgelegt wird. Deshalb ist z. B. bei CSS für Pixelwerte eine Umrechnung in DTP von 1 Zoll = 72 pt = 96 Pixel festgelegt. Dadurch wird der relativen Schriftgröße eine absolute Schriftgröße zugeordnet. Andere in CSS definierte Einheiten wie "em" und "ex" beziehen sich auf die aktuell verwendete Schrift und sind deshalb erst mit Festlegung einer absoluten Schriftgröße umrechenbar.

Im Bleisatzzeitalter musste jeder Schriftgrad eigens geschnitten werden. Die verwendeten Namen beziehen sich daher auf absolute Größen und nicht auf bestimmte Punktangaben in einem beliebigen System. So erklärt sich die Verschiebung der französischen Bezeichnungen zwischen Fournier- und Didot-Punkt.

Ab einem Schriftgrad von 4 Punkt gilt die „Deutsche Normalschriftlinie“. Die Unterscheidung „Grobe“ vor dem Schriftnamen weist oft auf eine Absenkung der Schriftlinie hin, um ein etwas größeres (groberes) Schriftbild auf einem gleich hohen Kegel unterzubringen.

Im Deutschen waren für die Didot-Grade teils auch noch weitere Bezeichnungen im Gebrauch: Non Plus Ultra (2 Didot-Punkt), Microscopique (2½), Insertio (6½), Paragon (18), Text (20), Kanon (36, klein: 32, grob: 42), Konkordanz (48), Missal (klein: 48, grob: 54), Sabon (60) sowie das Präfix "Doppel" für Cicero (24), Mittel (28) und Tertia (32).

Ab der „Kanon“ (36 Punkt) aufwärts bezeichneten die deutschen Namen nicht immer dieselben Schriftkegel. So findet man „Kanon“ für 32 und 36 Punkt, „Grobe Kanon“ für 40 und 42 Punkt, „Missal“ gar für 48, 54 und 60 Punkte. „Sabon“ und Bezeichnungen größerer Grade standen immer für verschiedene Kegelhöhen.




</doc>
<doc id="12986" url="https://de.wikipedia.org/wiki?curid=12986" title="EPOC">
EPOC

Das Betriebssystem EPOC [, ] wurde von Psion für PDAs (Personal Digital Assistants) entwickelt. EPOC ist der direkte Vorläufer von Symbian OS (ab EPOC Version 6), das ausschließlich auf Smartphones eingesetzt wird.

Es ist ein multitasking<nowiki>fähiges</nowiki> 32-Bit-Betriebssystem. Es gilt als sehr stabil, bietet eine Zwischenablage, Druckerunterstützung, und die Möglichkeit, Objekte aus anderen Anwendungen in Dokumente einzufügen. In EPOC sind einige, für PDA-Verhältnisse vergleichsweise leistungsfähige, Office-Programme enthalten. Sie machten EPOC im Businessbereich sehr beliebt. 

Ursprünglich wurde EPOC für reine Tastatur-PDAs ohne Touchscreen wie beispielsweise den Psion Series 3 konzipiert. Seit der Weiterentwicklung EPOC32 ist EPOC auch touchscreenfähig.
Mit „EPOC“ ist meist EPOC32 gemeint, das 1997 für 32-Bit-Prozessoren der ARM-Familie heraus kam. Psion lieferte die Modelle Series 5, Series 5mx, Series 5mx PRO (dieses Modell wurde nur in Deutschland vertrieben), Revo, Revo Plus, Series 7, netBook und netpad mit EPOC aus.

Die Vorgängerversion EPOC16 lief ab 1989 auf Psions SIBO-Geräten (Sixteen Bit Organizer) bzw. 16-Bit-Prozessoren der 8086-Familie. Psion vertrieb die Geräte MC200, MC400, Series 3, Series 3a, Series 3c, Series 3mx, Siena, Workabout und Workabout mx mit dieser Betriebssystemversion. Der Workabout für industrielle Anwendungen wurde bis in das Jahr 2004 gefertigt.

Die Weiterentwicklung des Betriebssystems wurde 1998 in die Firma Symbian Ltd. ausgegliedert, an welcher sich neben Psion auch Ericsson, Motorola und Nokia beteiligten. Die Umbenennung in Symbian OS erfolgte mit EPOC-Version 6.

Die Oberflächen des Betriebssystems und der Programme lassen sich mit dem Touchscreen oder der Tastatur bedienen, wobei im Gegensatz zu Windows XP Tablet PC Edition oder Palm OS 5.2 (Sony UX50) beide Eingabearten gleichermaßen umfassend unterstützt werden. Das Bedienkonzept ähnelt dem bekannter Desktopumgebungen der gängigen Betriebssysteme Windows, macOS und Linux. Es gibt einen Desktop, auf dem Ordner, Dateien und die meisten installierten Programme liegen. Von dort aus sind weitere Programme und die Systemsteuerung aufrufbar. Mittels verschiedener Zusatzprogramme kann auch eine Kommandozeile verfügbar gemacht werden.

Bis ER5 (EPOC Release 5) wurde ausschließlich EIKON als Oberfläche eingesetzt. Die letzten gefertigten Psion-PDAs setzten ebenfalls Version 5 ein.

EPOC-Anwendungen sind für Querformat-Displays konzipiert. Sie sind mit Tastatur und Touchscreen-Stift bedienbar. Im Lieferumfang enthalten waren in der Regel eine Terminverwaltung, eine Textverarbeitung, eine Tabellenkalkulation, eine einfache OPL-Datenbank und verschiedene Hilfsprogramme.

Bereits 1997 fand sich mit Geofox ein Lizenznehmer für EPOC. Mit dem Osaris von Oregon Scientific erschien ein weiteres Produkt auf der Basis von EPOC. Die Versionen 2 und 3 waren für den Series 5 und den Geofox One verfügbar, Version 4 für den Osaris.

Das R380 von Ericsson (lief mit ER 5 in einer Unicodevariante und eigener Oberfläche ohne Erweiterungsmöglichkeit) verfügte als eines der ersten Mobiltelefone über einen Touchscreen. Ebenso wie das Philips Illium Smartphone, das nicht zur Marktreife gebracht wurde, nahm es das Design der Sony-Ericsson-Modelle P800 und P900 mit umklappbarer Tastatur und großem berührungsempfindlichem Bildschirm und einer auf den Touchscreen ausgerichteten Bedienung vorweg.




</doc>
<doc id="12993" url="https://de.wikipedia.org/wiki?curid=12993" title="Anchorage">
Anchorage

Anchorage ([], engl. „Ankerplatz“) ist eine Stadt an der Bucht des Cook Inlet im US-Bundesstaat Alaska. Mit 291.826 Einwohnern (laut der letzten Volkszählung 2010) ist Anchorage die mit Abstand größte Stadt Alaskas sowie dessen wichtigstes Industriezentrum. Anchorage ist Verwaltungssitz des gleichnamigen Boroughs.

¹ 

Anchorage wurde 1915 als Hauptquartier der Alaska Railroad gegründet. Am 27. März 1964 verursachte ein schweres Erdbeben Todesfälle und großen Sachschaden. Das Karfreitagsbeben gilt als heftigste seismische Aktivität, die je in den USA gemessen worden ist. Diesem Erdbeben fielen einige der wenigen historischen Gebäude der Stadt zum Opfer. Heute stehen an entsprechender Stelle Funktionsbauten von Industrie und Handel ohne historischen oder architektonischen Wert. Als bedeutendstes Bauwerk der Stadt gilt das 1924 von Frank Lloyd Wright errichtete Cityhospital. Mit seiner großzügigen, funktionalen Art-déco-Empfangshalle setzte der Architekt wesentliche Maßstäbe für nachfolgende Krankenhaus- und Pflegeheimbauten.

Wichtige Wirtschaftszweige sind die chemische Industrie, der Bergbau, Logistik und Tourismus. Wegen seiner Lage in einem Erdölfördergebiet ist Anchorage ein Zentrum der petrochemischen Industrie. Mehrere große Erdölunternehmen, etwa BP oder ConocoPhillips, sind mit Zweigstellen in Anchorage vertreten.

Die Stadt verfügt über einen internationalen Flughafen, den Ted Stevens Anchorage International Airport (bedeutender Frachtflughafen), und liegt an der wichtigsten Eisenbahnverbindung Alaskas, der Alaska Railroad. Weiterhin verfügt die Stadt über den wichtigsten Hafen von Alaska, den Port of Anchorage.

Anchorage ist außerdem ein wichtiger Militärstützpunkt. Die US Armed Forces unterhalten zwei Militärflugplätze und eine Kaserne mit insgesamt rund 8.500 Soldaten und zivilen Beschäftigten.

Anchorage beheimatet die University of Alaska (1954) und die Alaska Pacific University (1957). Das Alaska Center for the Performing Arts ist das größte Theaterhaus des US-Bundesstaates. In Anchorage gibt es mehrere große Museen, darunter das Alaska Native Heritage Center zur Geschichte der Ureinwohner Alaskas. Außerhalb der Stadt liegt der zehn Hektar große Alaska Zoo.

Anchorage besitzt ein Profi-Eishockeyteam, die Alaska Aces, die in der ECHL spielen.

In Anchorage befindet sich der "Alaska Botanical Garden", ein 445.122 m großer botanischer Garten.



In Anchorage herrscht subarktisches Klima ("Dfc").



</doc>
<doc id="12996" url="https://de.wikipedia.org/wiki?curid=12996" title="Idee">
Idee

Der Ausdruck Idee (von "idéa" „Gestalt“, „Erscheinung“, „Aussehen“, „Urbild“) hat allgemeinsprachlich und im philosophischen Sprachgebrauch unterschiedliche Bedeutungen. Allgemeinsprachlich versteht man darunter einen Gedanken, nach dem man handeln kann, oder ein Leitbild, an dem man sich orientiert. Die philosophische Bedeutung wurde zunächst in der Antike von Platon und dem Platonismus geprägt. In der platonischen Ideenlehre sind Ideen unwandelbare, nur geistig erfassbare Urbilder, die den sinnlich wahrnehmbaren Phänomenen zugrunde liegen. Dieses Ideenverständnis wirkte bis in die Neuzeit stark nach, doch erhielt der Begriff „Idee“ in unterschiedlichen philosophischen Richtungen verschiedene Inhalte.

Das altgriechische Substantiv "idea" bezeichnet ursprünglich das Erscheinungsbild von etwas, was gesehen wird und dabei einen bestimmten Eindruck macht. Es ist als Verbalabstraktum von "idein" „erblicken“, „erkennen“ (Aorist zu "horan" „sehen“) abgeleitet. Während im literarischen Schrifttum die Verwendung dieses Worts erst relativ spät – bei Pindar und im Corpus Theognideum – einsetzt, kommt das ältere Substantiv "eidos" zur Bezeichnung visueller Eindrücke schon in der Ilias häufig vor. Die beiden Wörter werden gewöhnlich synonym gebraucht. Allgemeinsprachlich bezeichnen beide das Aussehen, die Form oder Gestalt, eine äußere Erscheinung, die beispielsweise als schön oder hässlich beschrieben wird. Es ist eine Erscheinung, die auch als bloßer Schein täuschen kann; das Aussehen weckt Erwartungen, die manchmal enttäuscht werden. Nicht nur einzelne Individuen, sondern auch Gruppen und Mengen haben ein bestimmtes "eidos", nach dem man sie unterscheiden kann: Es gibt ein königliches und ein sklavenhaftes "eidos" und ein "eidos" ethnischer Gruppen.

Die Wörter "eidos" und "idea" bezeichnen nicht nur ein Erscheinungsbild, sondern in einem abgeleiteten Sinn auch dessen Träger. Gemeint ist dann eine Art oder ein Typus von etwas: eine Klasse von Personen, Dingen oder Phänomenen, die durch bestimmte – nicht nur optische – Merkmale charakterisiert ist. Beispielsweise ist in der Medizin ein bestimmter Patiententyp ein "eidos". Wenn der Begriff zur Bezeichnung eines Typus oder einer Art von etwas dient, kann es sich auch um unanschauliche Gegebenheiten handeln, etwa wenn von verschiedenen Vorgehensweisen, Lebensweisen, Staatsformen oder von Arten der Boshaftigkeit oder des Krieges die Rede ist. Hier geht es um Klassifizierung anhand der Beschaffenheit oder einer Qualität, die allen Elementen einer Gruppe oder Art gemeinsam ist und sich beispielsweise in der Gestalt eines Dings oder in der Vollzugsweise einer Handlung zeigt.

Platon prägte den philosophischen Ideenbegriff. Er führte keine starre Terminologie ein, sondern verwendete für die später so genannten „platonischen Ideen“ neben "idea" auch andere Ausdrücke, insbesondere "eidos", und Umschreibungen. Während sich "idea" dem ursprünglichen Wortsinn nach auf das sichtbare Erscheinungsbild von etwas bezieht, ist im Gegensatz dazu die platonische Idee das nicht sinnlich Wahrnehmbare, das den sichtbaren Erscheinungen zugrunde liegt. Sie ist aber geistig erfassbar und für Platon in einem übertragenen Sinn „sichtbar“; dies erklärt die Übertragung des Begriffs "idea" aus dem Bereich der Sinneswahrnehmung in den einer rein geistigen Wahrnehmung. Das geistige „Sehen“, die dem Philosophen mögliche „Schau“ der Ideen, spielt im Platonismus eine zentrale Rolle.

Auch der materialistische Denker Demokrit verwendete den Begriff "idea", allerdings in ganz anderem Sinn als Platon. Er bezeichnete die Atome von unterschiedlicher Gestalt, aus denen nach seiner Lehre alles besteht, als "ideai" (Formen).

Cicero, der platonisches Gedankengut in der lateinischsprachigen Welt verbreitete, trug dazu bei, dass "idea" auch in der lateinischen Literatur ein philosophischer Fachbegriff wurde. Er schrieb das Wort noch als Fremdwort in griechischer Schrift, bei späteren Autoren erscheint es meist in lateinischer Schrift. Im Lateinischen wurde das, was griechische Denker unter "eidos" oder "idea" verstanden, auch mit Ausdrücken wie "forma" („Form“), "figura" („Gestalt“), "exemplar" („Muster“), "exemplum" („Muster“, „Vorbild“) und "species" („Gestalt“, „Muster“, „Art“) wiedergegeben. Seneca sprach von „platonischen Ideen“ ("ideae Platonicae"). Der spätantike Übersetzer und Kommentator von Platons Dialog "Timaios", Calcidius, verwendete auch Ausdrücke wie "archetypus", "archetypum exemplar" oder "species archetypa" („urbildliches Muster“).

Der Kirchenvater Augustinus meinte, die Bezeichnung „Ideen“ habe zwar erst Platon eingeführt, der Inhalt dieses Begriffs müsse aber schon lange vor ihm bekannt gewesen sein. Ins Lateinische sei „Idee“ mit "forma" oder "species" zu übersetzen; auch die Übersetzung "ratio" sei akzeptabel, wenn auch nicht genau, da "ratio" eigentlich dem griechischen Wort "logos" entspreche.

Mittelalterliche Philosophen und Theologen übernahmen die antike lateinische Terminologie der Ideenlehre, die ihnen vor allem Augustinus, Calcidius und Boethius vermittelten. Zur Bezeichnung der platonischen Ideen verwendeten sie neben dem latinisierten griechischen Wort "idea" auch die schon in der Antike gebräuchlichen rein lateinischen Ausdrücke, vor allem "forma".

In der christlichen Schulphilosophie der Frühen Neuzeit, auch bei den Jesuiten, verstand man unter Ideen in erster Linie die Urbilder im Geist Gottes, nach denen er die Welt geschaffen habe, aber auch – in Analogie dazu – Entwürfe im menschlichen Geist, die der Verwirklichung von Werken vorausgehen. In einem weiteren Sinne bezeichnete man im 17. Jahrhundert als Ideen die Prinzipien im menschlichen Bewusstsein, nach denen es Erkenntnisobjekte identifiziert und ordnet, und allgemein von der Vorstellungskraft hervorgebrachte mentale Inhalte ("phantasmata"), darunter Gedächtnisinhalte. René Descartes definierte „Idee“ im weitesten Sinne als Bewusstseinsinhalt jeglicher Art. An diesem weiten Begriffsverständnis orientierte sich der allgemeine Sprachgebrauch. Das von "idea" abgeleitete französische Wort "idée" diente generell zur Bezeichnung von Vorstellungen und Gedanken. Im Deutschen wurde im 17. Jahrhundert noch oft das lateinische "idea" als Fremdwort für „Vorstellung“ und „Gedanke“ verwendet, daneben aber auch das französische "idée", das dann als „Idee“ eingedeutscht wurde und sich in dieser Form schließlich durchsetzte.

Im heutigen allgemeinen, nichtphilosophischen Sprachgebrauch bezeichnet „Idee“ einen Gedanken, nach dem man handeln kann, eine Vorstellung oder Meinung. Oft handelt es sich um einen Einfall, einen neuen, originellen, manchmal geistreichen oder witzigen Gedanken, den man in die Tat umsetzen kann. In diesem Sinne kann das Wort die Bedeutung von „Plan“ und „Absicht“ erhalten. Als Idee bezeichnet man auch den gedanklichen Entwurf zu einer Erfindung, einem Kunstwerk oder einer literarischen Schöpfung; in diesem Sinne sprach schon Goethe von seinen Ideen. Manchmal ist ein Prinzip gemeint, ein Leitbild oder ein Grundgedanke, der das Denken und Handeln einer Person bestimmt, beispielsweise „die Idee der Freiheit“ oder „die europäische Idee“. In der Musik kommt für ein Kernthema oder Leitmotiv eines mehrteiligen Werks die Bezeichnung „Idee“ vor.

Umgangssprachlich ist eine Idee auch eine kleine Menge (zum Beispiel: "Man füge nach Umrühren des Teigs noch eine Idee Zucker hinzu") oder etwas, was nur einen geringfügigen Unterschied ausmacht (zum Beispiel: "eine Idee lauter").

Die philosophische Ideenkonzeption geht auf Platon zurück. Daher spricht man von „platonischen Ideen“ und von Platons Ideenlehre. Die Einführung der Ideenlehre, die in Platons frühen Werken noch nicht vorkommt, wird häufig als die Trennlinie zwischen dem von Platons Lehrer Sokrates mitgeprägten Gedankengut der Anfangszeit und einer völlig eigenständigen platonischen Philosophie gesehen. Allerdings bereitet Platon seine Äußerungen zu den Ideen nicht systematisch auf, er präsentiert nirgends ein kohärentes Lehrgebäude. Daher ist der gängige Begriff „Ideenlehre“, der nicht von Platon stammt, etwas problematisch. Außerdem weist Platon selbst auf Schwächen der Ideenkonzeption hin.

Platon geht davon aus, dass der Bereich des sinnlich Wahrnehmbaren einem realen und eigenständig existierenden Reich der Ideen, das nur auf geistigem Weg erkannt werden kann, nachgeordnet ist. Ideen sind beispielsweise „das Schöne an sich“, „das Gerechte an sich“, „der Kreis an sich“ oder „der Mensch an sich“. Die Ideen, nicht die Objekte der Sinneserfahrung, stellen die eigentliche Wirklichkeit dar. Nur ihnen kommt das wahre Sein zu. Im Gegensatz zu den Sinnesobjekten sind die Ideen vollkommen und unveränderlich; sie unterliegen nicht dem Entstehen, dem Wandel und dem Vergehen. Die Existenzweise der sinnlich wahrnehmbaren Gegenstände hingegen ist durch Mangelhaftigkeit charakterisiert. Beispielsweise weist ein Einzelding immer nur eine begrenzte, relative Schönheit auf; es kann von etwas Schönerem übertroffen werden. Außerdem kann ein schönes Sinnesobjekt seine Schönheit im Lauf der Zeit einbüßen. Die Idee des Schönen hingegen ist solchem Mehr oder Weniger entzogen, denn das Schöne als Idee ist absolut (ohne Abstufung oder Einschränkung) schön.

Da Ideen in höherem Maße wirklich sind als die sinnlich wahrnehmbaren Einzelgegenstände, kommt ihnen ontologisch (in der Lehre von der Hierarchie der seienden Dinge) ein höherer Rang zu als den Sinnesobjekten. Die Ideen sind den Sinnesobjekten aber nicht nur aufgrund ihrer Vollkommenheit überlegen und in der Seinshierarchie übergeordnet, sondern sie sind auch die Ursache von deren Existenz. Sie sind die Urbilder, die Sinnesobjekte sind ihre Abbilder. Jedes Sinnesobjekt verdankt sein Dasein dem objektiven Sein der ihm zugrunde liegenden Idee, beispielsweise ein Pferd der Idee des Pferdes. Seine jeweilige besondere Beschaffenheit erhält es von den verschiedenen Ideen, die an seiner Gestaltung beteiligt sind und ihm die Gesamtheit seiner Merkmale (Größe, Farbe usw.) verleihen. Jedes Phänomen der physischen Welt hat „Anteil“ an denjenigen Ideen, deren Einwirkung es unterliegt. Die jeweilige Art dieser „Teilhabe“ ("Methexis") bestimmt, in welchem Maße etwas über die besondere Eigenschaft verfügt, die es von einer bestimmten Idee empfängt: Wie gerecht ein Mensch ist, ergibt sich aus der Art seiner Teilhabe an der Idee des Gerechten. Somit bewirken die Ideen, dass die einzelnen Sinnesobjekte so sind wie sie sind. Jede Idee, an der ein Objekt Anteil hat, ist in diesem anwesend.

Das Denken des Philosophen soll sich auf die Ideen richten. Wegen der Allgemeinheit und Unveränderlichkeit ihrer Natur sind sie diejenigen Objekte, von denen man echte Erkenntnis erlangen kann, denn alles Wissen beruht auf Einsicht in etwas Allgemeingültiges und zeitunabhängig Wahres, nicht auf Beobachtung von Zufälligem und Vereinzeltem. Das Besondere, Individuelle kann nur vom Allgemeinen her verstanden und richtig eingeordnet werden. Somit entspricht der seinsmäßigen (ontologischen) Höherrangigkeit der Ideen eine erkenntnismäßige (epistemische). Erkenntnis von Ideen kann man erlangen, indem man von den unwesentlichen Besonderheiten des einzelnen Phänomens abstrahiert und seine Aufmerksamkeit auf das Allgemeine richtet, das einer Anzahl von Einzeldingen zugrunde liegt und gemeinsam ist.

Die Ideenkonzeption Platons ist somit der Auffassung entgegengesetzt, dass die Einzeldinge die gesamte Wirklichkeit ausmachen und hinter den Allgemeinbegriffen nichts steht als ein menschliches Bedürfnis, zur Klassifizierung der Phänomene Ordnungskategorien zu konstruieren.

Während die Platoniker an der Ideenkonzeption Platons festhielten, fand sie in den anderen antiken Philosophenschulen keinen Anklang. Aristoteles setzte sich intensiv mit ihr auseinander und versuchte sie zu widerlegen. Insbesondere machte er geltend, dass die Annahme einer ontologischen Kluft zwischen Ideenwelt und Sinneswelt mit der Behauptung, die Sinneswelt sei ein Erzeugnis der Ideenwelt, unvereinbar sei, denn es gebe nichts, was eine solche Kluft überbrücken und damit eine Einwirkung der Ideen auf die Sinneswelt ermöglichen könnte („Chorismos“-Argument). Außerdem seien die scheinbar „allgemeinen“ Ideen, wenn sie separat existierten, nichts Allgemeines, sondern nur eine besondere Art von abgesonderten, einzelnen Dingen. Daher könne die Ideenlehre das Besondere nicht auf Allgemeines zurückführen. Da sie keine Erklärung für die Existenz der Sinnesobjekte biete, erfülle sie nicht den Zweck, zu dem sie eingeführt worden sei. Die Vorstellung von separaten Ideen neben den Sinnesobjekten führe nur zu einer hypothetischen Verdoppelung der Welt, die zum Verständnis der Wirklichkeit nichts beitrage und daher unnötig sei. Außerdem seien Ideen, wenn sie wie Einzeldinge separat existierten und daher einzeln und nicht allgemein seien, undefinierbar, denn nur das Allgemeine könne definiert werden. Folglich seien solche Ideen auch unerkennbar. Auch wenn Ideen und Einzeldinge ähnlich seien, folge daraus nicht, dass die Ideen die Urbilder der Einzeldinge sein müssen und diese ihnen nachgebildet sind. Die Vorstellung der Teilhabe sei nicht durchdacht; es handle sich nicht um eine philosophische Erklärung, sondern nur um ein leeres Wort, eine poetische Metapher.

Die Mittelplatoniker verbanden die Ideenkonzeption mit ihren Vorstellungen vom göttlichen Walten im Kosmos. Sie unterschieden zwischen der höchsten, absolut transzendenten Gottheit, die in keiner direkten Beziehung zur sinnlich wahrnehmbaren Welt steht, und dem ihr untergeordneten Schöpfergott, dem Demiurgen. Der Schöpfergott galt als Wirkursache der Sinnesobjekte, in den Ideen sah man die paradigmatische (urbildliche) Ursache, in der Materie die Stoffursache. Dies wird in der Forschung als die mittelplatonische „Drei-Prinzipien-Lehre“ bezeichnet. Meist betrachteten die Mittelplatoniker die Ideen als Gedanken des transzendenten Gottes oder des Schöpfergottes. Dabei standen sie unter dem Einfluss der Theologie des Aristoteles, der zufolge Gott sich selbst denkt und dies seine einzige Tätigkeit ist. Es gab aber auch die Ansicht, dass den Ideen eine eigenständige Existenz unabhängig vom göttlichen Intellekt zukomme. Dem mittelplatonischen Modell schloss sich der stark vom Platonismus beeinflusste jüdische Denker Philon von Alexandria an. Er identifizierte den „Ideenkosmos“, der das erste Abbild Gottes sei, mit Gottes Vernunft, dem göttlichen Logos. Der Logos sei die gedachte Welt, nach deren „höchst gottähnlichem“ Vorbild Gott die sichtbare Welt geschaffen habe. So erhalten die Ideen bei Philon die Rolle der vermittelnden Instanz zwischen dem transzendenten Gott und der geschaffenen Welt.

Die Neuplatoniker nahmen eine dreiteilige Grundstruktur der geistigen Welt mit drei hierarchisch geordneten Prinzipien an: Zuoberst steht das absolut transzendente „Eine“, darunter der überindividuelle Geist oder Intellekt (Nous), gefolgt vom seelischen Bereich. In der Nouslehre gingen die Neuplatoniker von Überlegungen des Aristoteles aus, der allerdings nicht zwischen dem Einen und dem Nous unterschieden hatte. Nach der neuplatonischen Lehre ist der vollkommene Nous die Welt des reinen Denkens. Sein Denken kann sich nur auf etwas richten, was ihm an Vollkommenheit nicht nachsteht, denn wenn er etwas ihm Untergeordnetes dächte, was nicht so vollkommen ist wie er selbst, würde dies seine Vollkommenheit beeinträchtigen. Das Eine kann er nicht denken, da es wegen seiner Transzendenz dem Denken prinzipiell entzogen ist. Somit kann er nichts anderes denken als sich selbst, das heißt: das, was in ihm ist. Daher sind die Objekte des reinen Denkens ausschließlich die eigenen Inhalte des Nous in ihrer Gesamtheit. Daraus ergibt sich aus neuplatonischer Sicht, dass der Nous aus nichts anderem als der Gesamtheit der platonischen Ideen besteht und dass er der einzige ontologische Ort der Ideen ist. Diese Position formuliert Plotin, der Begründer des Neuplatonismus, in seinem berühmten Lehrsatz: Die Ideen existieren nur innerhalb des Nous. Damit markiert er einen wesentlichen Unterschied zwischen Mittel- und Neuplatonismus. Die im Mittelplatonismus vorherrschende Auffassung war, die Ideen seien etwas vom Nous Produziertes und ihm somit Untergeordnetes. Daher verortete man die Ideen in einem separaten Bereich außerhalb des Nous. Zwar gab es schon vor Plotin Ansätze zu einer Theorie von der Immanenz der Ideen im Geist, doch hat er als erster das Konzept der Identität der Ideen mit dem Nous konsequent durchgeführt und begründet, was bei seinen Zeitgenossen als Neuerung galt.

Der Kirchenvater Augustinus übernahm die Grundzüge der platonischen Ideenlehre einschließlich des Teilhabe-Konzepts. Er stellte fest, die Ideen seien ungeschaffen und unvergänglich. Sie seien die Gründe ("rationes") der Dinge; alles Entstehende und Vergehende sei nach ihrem Muster gestaltet und erhalte von ihnen die Gesamtheit seiner Merkmale. Ihr Ort sei die göttliche Vernunft ("divina intelligentia"). Mit dieser Verortung der Ideen übernahm Augustinus ein mittelplatonisches Modell, das er christlich umdeutete, indem er es mit der Trinitätslehre verband. Die göttliche Vernunft, in der die Ideen enthalten seien, identifizierte er als das fleischgewordene Wort Gottes, Jesus Christus. Das Wort Gottes sei die nicht geformte Form aller geformten Einzeldinge. Zugleich sei es auch eine Aussage Gottes über sich selbst. In seinem Wort – und damit auch in den Ideen – erkenne Gott sich selbst. Auch die menschliche Erkenntnis fasste Augustinus als Erkenntnis der Ideen auf. Auf der Ideenerkenntnis beruhe das Wissen, ohne sie könne man keine Weisheit erlangen. Möglich sei die menschliche Ideenerkenntnis durch Teilhabe ("participatio") am Wort Gottes. Die unwandelbaren Wahrheiten, zu denen der Mensch dadurch Zugang erhalte, seien in ihm selbst angelegt und nicht aus Sinneswahrnehmung abgeleitet. Die Sinneswahrnehmung weise ihn nur auf das in ihm bereits latent vorhandene Wissen hin, so dass er sich dessen bewusst werde.

Bis um die Mitte des 12. Jahrhunderts war in der lateinischsprachigen Gelehrtenwelt West- und Mitteleuropas von den Werken Platons ausschließlich der Dialog "Timaios" bekannt, der überdies nur in den unvollständigen lateinischen Übersetzungen von Calcidius und Cicero zugänglich war. Die Rezeption der Ideenlehre erfolgte vorwiegend über spätantike Schriftsteller, die das Konzept dem Mittelalter in mittel- und neuplatonisch geprägter Gestalt vermittelten. Sehr einflussreiche Übermittler des platonischen Gedankenguts waren neben Augustinus und Calcidius, der auch einen viel beachteten Kommentar zum "Timaios" verfasst hatte, der neuplatonisch orientierte Theologe Pseudo-Dionysius Areopagita sowie Boethius, Macrobius und Martianus Capella. Eine nachhaltige Wirkung erzielte vor allem die Bestimmung der Ideen als überzeitliche Urbilder („Formen“), die im Geist Gottes vorhanden sind und nach deren Muster er die Sinnesobjekte erschafft. Die Abbilder der Ideen in den geschaffenen Dingen nannte man „Entstehungsideen“ ("formae nativae"). Von den Ideen als Urbildern unterschied man die Ideen, die Einzeldingen gemeinsam sind und mit den Begriffen von Gattung und Art erfasst werden ("formae communes", "ideae communes").

Die Kritik des Aristoteles an der platonischen Ideenlehre war schon im 12. Jahrhundert den Gelehrten der Schule von Chartres bekannt. Seine Auffassung wurde von den hoch- und spätmittelalterlichen Theologen und Philosophen insofern geteilt, als sie den Ideen keine eigenständige Realität zuerkannten, sondern sie im göttlichen Intellekt verorteten. Thomas von Aquin († 1274) nahm zwar Ideen als Schöpfungsprinzipien im Geist des Schöpfergottes an, zog aber eine eigene Ursächlichkeit der Ideen im Schöpfungsprozess nicht in Betracht. Er meinte, sie seien nur Formursachen, Wirkursache sei der Wille Gottes. Thomas kritisierte Platons Lehre von den „abgetrennten, durch sich selbst seienden Ideen“, wobei er sich auf Aristoteles berief.

Eine noch stärkere Distanzierung von der platonischen Ideenlehre brachte der spätmittelalterliche zeichentheoretische Nominalismus oder Konzeptualismus. Die Vertreter dieser Richtung bekämpften im „Universalienstreit“ den traditionell vorherrschenden Begriffsrealismus (Universalienrealismus, auch kurz „Realismus“ genannt). Dabei ging es um die Frage nach dem Wirklichkeitsbezug von Universalien (Allgemeinbegriffen) und damit um die Existenz von platonischen Ideen. Begriffsrealisten waren die Vertreter der herkömmlichen platonisch-augustinischen oder aristotelischen Lehren. Sie meinten, dass die Allgemeinbegriffe etwas objektiv real Existierendes bezeichnen. Diese Annahme ist die Ausgangsbasis aller mittelalterlichen Ideenkonzeptionen, die auf der traditionellen platonisch-augustinischen Lehre fußen. Sie ist auch die Voraussetzung der aristotelischen Vorstellung von Formen, die zwar nicht wie die platonischen Ideen eigenständig existieren, aber immerhin in den Sinnesobjekten als objektive Gegebenheiten real vorhanden sind. Nach der Auffassung der Nominalisten hingegen sind die Allgemeinbegriffe nur „Namen“ ("nomina"), das heißt Zeichen, die der menschliche Verstand für seine Tätigkeit benötigt. Demnach hat das Allgemeine eine subjektive, rein mentale Realität im Denken und nur dort. Eine ontologische Relevanz kommt ihm nicht zu. Wilhelm von Ockham, der Wortführer des zeichentheoretischen Nominalismus im 14. Jahrhundert, spricht den Ideen auch im Geist Gottes eine eigene Realität ab. Für ihn bezeichnet der Ausdruck „Idee“ nur ein Erkenntnisobjekt, insoweit es erkannt ist; er besagt nur, dass etwas erkannt ist, bezieht sich also nicht auf den Gegenstand als solchen, sondern auf die Tatsache seines Erkanntseins.

Einen scharfen Bruch mit der platonischen Tradition vollzog René Descartes. Er verwarf die Vorstellung, es gebe im göttlichen Geist ein Reich von Ideen, die als Muster der erschaffenen Sinnesobjekte dienen. Ein Denken Gottes, das dem Erschaffen vorangeht, hielt Descartes für unmöglich, da Gott absolut einfach und sein Erkennen mit seinem Wollen identisch sei. Daher verwendete er den Begriff „Ideen“ nicht im platonischen Sinne, sondern nur zur Bezeichnung menschlicher Bewusstseinsinhalte. Dazu zählte er neben den Wahrnehmungsinhalten und den vom Bewusstsein erzeugten Phantasieprodukten auch die „eingeborenen Ideen“ ("ideae innatae"), die potentiell im Bewusstsein vorhanden seien und für philosophische Erkenntnis benötigt würden. Descartes meinte, die eingeborenen Ideen könnten aus der Potenz in den Akt überführt werden und ermöglichten dann ein apriorisches Wissen. Gegen die Vorstellung von eingeborenen Ideen wandten sich Thomas Hobbes und John Locke. Die von Locke begründete sensualistische Bewusstseinslehre, die George Berkeley und David Hume auf unterschiedliche Weise weiterentwickelten, verneint die Existenz von Bewusstseinsinhalten, die nicht auf Wahrnehmung zurückführbar sind.

Immanuel Kant zählt die Ideen zur Klasse der reinen Begriffe und grenzt sie als notwendige Vernunftbegriffe („transzendentale Ideen“) von den bloßen Verstandesbegriffen ab. Eine Idee kann nach seinem Verständnis nur in der Vernunft entstehen, welche ihrer Natur gemäß die Existenz von Ideen fordert. Ideen sind Begriffe a priori. Ihr charakteristisches Merkmal ist, dass sie sich auf das Unbedingte beziehen, das den Bereich aller möglichen Erfahrung notwendig übersteigt. Daher kann eine Idee in theoretischer Hinsicht, als Idee der spekulativen Vernunft, niemals eine nachweisbare objektive Realität außerhalb von sich selbst erlangen; als Schlüssel zu möglichen Erfahrungen kommt sie nicht in Betracht, im Bereich der Sinneswahrnehmung entspricht ihr nichts. Eine ontologische Bedeutung haben die Ideen für Kant nicht, wohl aber eine regulative Funktion für das Erkennen und Handeln. Objektive Realität weist er ihnen nur im Bereich des Praktischen zu, wobei er ausdrücklich an Platon anknüpft. Er bezeichnet die moralischen Ideen als Urbilder der praktischen Vernunft, die als Richtschnur des sittlichen Verhaltens dienen. Außerdem nimmt er „ästhetische Ideen“ als besondere Ideenart an.

Hegel setzt sich mit der Ideenlehre Platons auseinander und würdigt die Pionierrolle des antiken Philosophen. In Hegels philosophischem System, vor allem in seiner Logik, spielt der Begriff Idee eine zentrale Rolle. Er erhält hier einen Inhalt, der von jedem früheren philosophischen Sprachgebrauch abweicht. Hegel definiert die Idee als Wahrheit von Subjektivität und Objektivität und als das Wahre an und für sich, womit er sich von den Lehren abgrenzt, in denen sie als etwas Subjektives, als bloße Vorstellung und als unwirklich erscheint. Mit Wahrheit meint er die Übereinstimmung der Wirklichkeit mit ihrem Begriff, der sie erzeugt. In der Idee sieht Hegel den Begriff, der die Wirklichkeit, die er hervorbringt, mit sich in Übereinstimmung bringt. Er bezeichnet sie als „die Einheit des Begriffs und der Objektivität“. Die Idee ist für ihn wie für Kant als Vernunftbegriff transzendent, sie ist das Unbedingte, von dem „kein ihm adäquater empirischer Gebrauch gemacht werden“ kann. Im Gegensatz zu Kant folgert Hegel daraus aber nicht, dass die Idee ontologisch bedeutungslos ist. Vielmehr führt er den Umstand, dass der Idee „kein kongruierender Gegenstand in der Sinnenwelt gegeben werden“ kann, auf einen Mangel der Sinnesobjekte, nicht der Idee zurück. Jedes einzelne Ding entsteht aus der Idee, und sein Existenzgrund ist es, sie so gut wie möglich auszudrücken.

Im Gegensatz zur platonischen Tradition schreibt Hegel der Idee nicht absolute Ruhe im Sinne von Bewegungslosigkeit zu, sondern eine Bewegung, mit der sie eine Welt endlicher Dinge setzt, die etwas Anderes als sie ist, etwas für sie Äußerliches und insofern ihr Gegenteil. Um ihr Gegenteil setzen zu können, muss sie es in sich selbst enthalten, muss sie in sich auch Unterschied und Teilung aufweisen. Somit umfasst sie das, was sie verneint, ihren eigenen Gegensatz.

Die philosophische Bemühung zielt auf die „absolute Idee“. Diese ist für Hegel „der vernünftige Begriff, der in seiner Realität nur mit sich selbst zusammengeht“ und „in seinem Anderen seine eigene Objektivität zum Gegenstande hat“. „Alles Übrige ist Irrtum, Trübheit, Meinung, Streben, Willkür und Vergänglichkeit; die absolute Idee allein ist Sein, unvergängliches Leben, sich wissende Wahrheit, und ist alle Wahrheit. Sie ist der einzige Gegenstand und Inhalt der Philosophie.“ Die Aufgabe der Philosophie ist es, die absolute Idee in ihren verschiedenen Gestaltungen zu erkennen.

Seit dem Ende der Epoche des Deutschen Idealismus haben eine Reihe von Philosophen – insbesondere Vertreter des Neuidealismus, Neuhegelianismus, Neukantianismus und Neuthomismus – den Ideen eine wesentliche Funktion im Rahmen ihrer ontologischen, erkenntnistheoretischen oder ethischen Konzepte zugewiesen, wobei sie von unterschiedlichen Bestimmungen des Begriffs Idee ausgingen. Solche Strömungen bestehen bis in die Gegenwart. Gegen die Ideenkonzeptionen metaphysischer Theorien erhoben jedoch schon im 19. Jahrhundert Positivisten, Linkshegelianer und Marxisten heftigen Widerspruch. Ein entschiedener Gegner der platonischen Ideenlehre war auch Nietzsche, der im Rahmen seiner Polemik gegen den Platonismus auch diese Lehre bekämpfte. Er schrieb in seiner "Götzen-Dämmerung", die Geschichte der Ideenlehre sei die Geschichte eines Irrtums, die angebliche „wahre Welt“ der Ideen habe sich als Fabel entpuppt; sie sei „eine unnütz, eine überflüssig gewordene Idee, folglich eine widerlegte Idee“.

In der Philosophie des 20. und 21. Jahrhunderts dominiert die Einschätzung derjenigen Denker, welche dem Begriff Idee jede philosophische Relevanz absprechen. Diese Kritiker machen geltend, man könne mit „Ideen“ nichts erklären, sondern nur eine Illusion von Erklärung erzeugen. Schon die Frage nach einer festen, kontextunabhängigen Bedeutung von „Idee“ sei verfehlt. Es handle sich bei Ideen um rein subjektive Konstrukte, über die keine überprüfbaren Aussagen möglich seien. Daher sei jede Beschäftigung mit ihnen unnütz. In diesem Sinne äußerten sich u. a. Wittgenstein und Quine. Ungeklärt bleiben allerdings die Probleme, die dazu geführt haben, dass der Begriff Idee in die philosophische Terminologie eingeführt und von der Antike bis in die Moderne beibehalten wurde. Dazu zählen die weiterhin offenen Fragen, wie die Allgemeingültigkeit wissenschaftlicher Erkenntnisse zu verstehen ist und wie die Einheit von Begriff und Gegenstand erklärt werden kann.




</doc>
<doc id="12997" url="https://de.wikipedia.org/wiki?curid=12997" title="Gewaltlosigkeit">
Gewaltlosigkeit

Gewaltlosigkeit oder Gewaltfreiheit ist ein Prinzip, das Gewalt ablehnt und zu überwinden sucht.

Terminologisch wird gelegentlich zwischen "gewaltlos" (situativer Gewaltverzicht) und "gewaltfrei" (prinzipieller Gewaltverzicht) unterschieden. Der Begriff „gewaltfrei“ wurde zuerst 1951 von Nikolaus Koch verwendet (s. u.), verbreitete sich aber erst durch die Publikationen des Politikwissenschaftlers Theodor Ebert Ende der 1960er / Anfang der 1970er Jahre.

Gene Sharp unterscheidet 198 Methoden des Vorgehens. Gewaltfreiheit folgt der Überzeugung, dass Gewalt oder deren Androhung Probleme nicht lösen, Ungerechtigkeit und Unterdrückung nicht beseitigen kann. "Gewaltlosigkeit" ist nicht "Wehrlosigkeit", "Passivität" und "Tatenlosigkeit". Konflikte sollen nicht vermieden, sondern durch gewaltfreien Widerstand geregelt werden. Wesentliches Element der Erziehung zur Gewaltfreiheit ist ferner das Erlernen von Methoden der Konfliktbearbeitung, z. B. Gewaltfreie Aktion.

Gewaltlosigkeit wurde bereits von einigen Religionsstiftern des Altertums gefordert, beispielsweise von Siddhartha Gautama, Mahavira und Jesus von Nazaret. In der Neuzeit gilt der Inder Mahatma Gandhi als „Apostel der Gewaltlosigkeit“ und Pazifist schlechthin. Bei Gandhi hatte der Begriff der Gewaltlosigkeit aber eine andere Bedeutung, als man ihn heutzutage in Rückbezug auf Gandhi versteht. Ihm ging es um das Prinzip des Satyagraha, übersetzbar mit dem Begriff „Gütekraft“, d. h. Festhalten an der Kraft der Wahrheit und der Liebe. Diese Kraft könne jeder einzelne besitzen und benutzen. Gandhis Idee ist: „Jede und jeder soll unabhängig davon, was irgendeine andere Person tut, damit beginnen gut zu sein; dann wird die Güte des einen zurückgestrahlt im andern.“

Begründend schreibt er:

Oft wird in diesem Zusammenhang auch der Begriff ahimsa gebraucht, der aus den Upanishaden stammt und von Gandhi aufgegriffen wurde. "Ahimsa" umfasst mehr als nur gewaltlosen Widerstand oder gewaltfreie Aktion. "Ahimsa" bezeichnet eine Lebens- und Geisteshaltung, die grundsätzlich eine Schädigung und Verletzung von Lebewesen aller Art vermeidet. Dazu gehören nach Gandhi auch negative Gedanken, Lüge, Hass und übermäßige Eile. Durch Leidensfähigkeit, Geduld und andauerndes Bemühen lernt der Mensch mit sich selbst und anderen in Frieden zu leben.

In der jüdischen Religion gibt es Begründungen für Gewaltlosigkeit mit Martin Buber in Israel.

Gewaltlosigkeit ist seit der griechischen Antike Thema im Humanismus, insbesondere im weltlichen Humanismus. Die griechische Polis verstand sich ausdrücklich als eine Gesellschaftsverfassung, die nicht auf Gewalt basierte. Sie hatte den Anspruch, dass der Mensch mündig sei zur Selbstregierung, Selbstbestimmung und Autonomie – zu beachten ist, dass dies nur für Bürger der Polis und beispielsweise nicht für Sklaven galt. Daran ausgerichtet war das politische Handeln eine ständige Bildungsaufgabe.
Gewaltlosigkeit im weltlichen Humanismus beruft sich u. a. auch auf Menschenrechte und Menschenwürde und die Ziel-Mittel-Korrelation. Das bedeutet, dass das Handeln an dem Ziel ausgerichtet sein sollte. Im Handeln und den tagespolitischen Forderungen soll das Ziel erkennbar sein.

In der Erziehung in westlichen Staaten kam es zu einer weitgehenden Abkehr von Gewalt in der Erziehung und von den Erziehungsmethoden der schwarzen Pädagogik. Ihren Niederschlag fand diese Entwicklung auch in der Gesetzgebung, so auch in Deutschland im Gesetz zur Ächtung von Gewalt in der Erziehung vom 2. November 2000.

Sogenannte Kampfmaßnahmen in der Arbeiter- und Gewerkschaftsbewegung waren in der Regel gewaltloses Handeln, z. B. bei Streiks, Betriebsbesetzungen und anderen direkten Aktionen. Der Friedensforscher Gernot Jochheim hat in seiner wissenschaftlichen Studie über die Entwicklung der Gewaltfreiheitstheorie in der europäischen antimilitaristischen und sozialistischen Bewegung 1890–1940 hingewiesen. Theorien der Gewaltlosigkeit gab es in diesem gesellschaftlichen Spektrum verbunden mit Gewaltkritik in den gesellschaftlichen Konflikten. Das waren Bewegungen, die sich als Anarcho-Syndikalisten, revolutionäre Unionisten und Rätekommunisten bezeichneten (z. B. Rudolf Rocker, Henriette Roland Holst, Anton Pannekoek u. a.)

Der Eröffnungstag der ordentlichen Tagung der UNO-Generalversammlung wurde seit 1981 offiziell als Internationaler Friedenstag gefeiert. Am 7. September 2001 beschloss die Generalversammlung in ihrer Resolution 55/282, den Weltfriedenstag jedes Jahr am 21. September als einen „Tag der Gewaltlosigkeit“ und der weltweiten Waffenruhe zu würdigen. Seit 2007 wird am 2. Oktober, dem Geburtstag Mahatma Gandhis, der Internationale Tag der Gewaltlosigkeit als ein Gedenktag der Vereinten Nationen begangen.

Dieses Datum ist eine Aufforderung an alle Nationen und Menschen, jegliche Feindseligkeiten an diesem Tag einzustellen. Auch die Waffen sollten an diesem Tag niedergelegt werden, um ohne Angst vor unmittelbarer Zerstörung humanitäre Hilfe leisten, Zivilisten aus umkämpften Gebieten bringen und Schutzräume errichten zu können.

Andere Vorschläge für den „Tag der Gewaltlosigkeit“ sind z. B. der 9. Oktober. An diesem Tag gelang es 1989 den Leipzigern mit einer friedlichen Massendemonstration erstmals, die SED-Machthaber an der Gewaltanwendung zu hindern.




</doc>
<doc id="12998" url="https://de.wikipedia.org/wiki?curid=12998" title="Altsaxophon">
Altsaxophon

Das Altsaxophon ist ein Saxophon der hohen Lage in Es und gehört zur Gruppe der Holzblasinstrumente. Als transponierendes Musikinstrument klingt es eine große Sexte tiefer als notiert, das heißt ein klingendes es wird für das Altsaxophon (9 Halbtöne höher) als c notiert.

Tonumfang: des – a (notiert im Violinschlüssel als b – fis).

Durch seinen prägnanten Klang eignet es sich zur Führung des Saxophonsatzes in einer Big Band, wird aber in der Jazz- und Popmusik oft auch solistisch eingesetzt. Einige sehr bekannte Jazzmusiker wie Charlie Parker, Cannonball Adderley, Ornette Coleman, Eric Dolphy und David Sanborn spielten vorwiegend Altsaxophon.




</doc>
<doc id="12999" url="https://de.wikipedia.org/wiki?curid=12999" title="Campus">
Campus

Der Campus (Plural: "Campus""," umgangssprachlich auch "Campusse") ist der zusammenhängende Komplex von Gebäuden, die zur selben Universität, Hochschule (Hochschulzentrum, Universitätszentrum) oder zum selben Forschungsinstitut gehören.

Die Bezeichnung "Campus" [] ist lateinischen Ursprungs und hat in dieser Sprache die Bedeutung ‚Feld‘. Er bezeichnete in den USA seit dem 18. Jahrhundert die außerhalb der Stadt errichteten Gebäude einer Universität, die üblicherweise von parkähnlichen Anlagen umgeben sind. Der Begriff wurde erstmals beim 1746 gegründeten College of New Jersey (heute Princeton University) verwendet.

In den 1960er Jahren wurde der Ausdruck in Deutschland aus dem Amerikanischen entlehnt. Unter „Campus-Hochschulen“ versteht man seitdem Hochschulen, bei denen Lehr- und Forschungseinrichtungen und häufig auch andere universitätsnahe Infrastruktur wie z. B. Wohnraum für Lehrende und Studenten sowie Grünflächen in einem Areal zusammengefasst sind, statt sich über die Stadt zu verteilen. Deutsche Universitätsneugründungen waren nun im Gegensatz zu den klassischen europäischen Universitäten häufig nicht mehr in zentraler Lage in die Stadt integriert, sondern bildeten eigene kleine Viertel am Rand oder unmittelbar außerhalb der Stadt. Diese Entwicklung begann 1946 mit der Freien Universität Berlin (FU Berlin) und ihrem Campus in Berlin-Dahlem. Zu den frühen Gründungen solcher Hochschulen, die „auf der grünen Wiese“ wie „Trabanten“ im urbanen Umfeld angesiedelt wurden, gehört Bochum (1962), der erste deutsche Universitätscampus mit Lehr- und Forschungseinrichtungen, Wohnheimen und universitätsnaher Infrastruktur. Es folgten Düsseldorf (1965), Bielefeld (1969), Bremen (1971) und zahlreiche andere. Weitere Beispiele sind die Universitäten Augsburg, Bayreuth, Cottbus, Dortmund, Dresden, Duisburg, Erfurt, Essen, Flensburg, Hohenheim, Ilmenau, Kaiserslautern, Kassel, Koblenz, Konstanz, Lübeck, Magdeburg, Mainz, Oldenburg, Paderborn, Passau, Universität Potsdam, Regensburg, Saarbrücken, Siegen, Ulm, Trier, Vechta sowie die Universitäten der Bundeswehr in Hamburg und München. Eine ähnliche Entwicklung ist der Neubau eines Campus fern von bestehenden Hochschuleinrichtungen in der Innenstadt wie beim "Campus Vaihingen-Pfaffenwald" der Universität Stuttgart. Vergleichbar war es mit neuen Campussen für Naturwissenschaften traditionsreicher Universitäten wie Heidelberg und Tübingen. Ein anderes Modell ergab sich durch eine Zusammenlegung beim Karlsruher Institut für Technologie.

In den USA hielt sich die ursprüngliche Bedeutung bis in die 1950er Jahre, wurde aber allmählich auf den gesamten universitären Komplex übertragen. Dort benutzten schließlich auch andere Einrichtungen wie Unternehmen oder Krankenhäuser den Begriff für ihr Gelände, vermutlich, um dessen positive Bedeutung zu nutzen oder auf den Forschungscharakter ihrer Aktivitäten zu verweisen. Ein Beispiel ist der Microsoft Campus in Redmond, Washington; die Struktur eines von Grün umgebenen Komplexes am Stadtrand war hier gegeben. In Deutschland wird der Begriff inzwischen auch ohne Universitätsbezug angewendet, zum Beispiel bei Bürogebäuden.

In jüngster Zeit erfuhr der Begriff auch in Deutschland eine Erweiterung und wird nun allgemein für universitäre Anlagen angewendet, auch wenn diese innerhalb der Stadt liegen. Ein Beispiel wäre die Universität Mannheim, deren Campus sich über das Schloss Mannheim und die direkte Umgebung erstreckt. In Bonn entsteht gerade auf freiem Feld, aber in Innenstadtnähe der „Campus Poppelsdorf“ der Rheinischen Friedrich-Wilhelms-Universität. Auch in Deutschland zeichnet sich, wohl um die jeweils eigene Bedeutung zu überhöhen, ähnlich wie in den USA eine Begriffsausweitung auf räumlich zusammenhängende Baulichkeiten anderer Institutionen, zum Beispiel von Krankenhäusern ab. In Kiel wird das Gelände der Universitätsklinik auch als "Campus Kiel" bezeichnet, zwecks Unterscheidung zum zweiten Standort Lübeck.

Insbesondere bezeichnet man als Campus lockere, moderne Gebäudekomplexe, die besonders für die Lehre und Forschung angelegt werden. Ein Beispiel ist der "Campus der Universität Wien" auf dem Gelände des Alten Allgemeinen Krankenhauses in der Nähe der Ringstraße. Er umfasst zwar nur einen kleinen Teil der Universität Wien, beherbergt aber über 15 vorher über das Stadtgebiet verteilte Fachbereiche und eine Reihe studentisch geprägter Lokale. Ähnlich das Techno-Z Salzburg für private Forschung ebenso wie als Campus der Universität Salzburg, oder das Universitätszentrum Rottenmann als Außenstelle zweier Universitäten in einer spezialisierten Forschungsregion. Hierbei wird die heute geförderte enge Vernetzung von Hochschulen und Unternehmen, teils auf Forschung und Entwicklung spezialisiert, teils direkte privatwirtschaftliche Spin-offs der Hochschulen, auch stadtplanerisch und architektonisch gefördert (Kompetenzzentrum).

Wenn funktionelle Infrastruktur in Web-Systemen abgebildet wird, wird das im übertragenen Sinne als ein E-Campus bezeichnet.



</doc>
<doc id="13001" url="https://de.wikipedia.org/wiki?curid=13001" title="Request for Comments">
Request for Comments

Die ' ('; englisch für "Bitte um Kommentare") sind eine Reihe technischer und organisatorischer Dokumente des RFC-Editors zum Internet (ursprünglich Arpanet), die am 7. April 1969 begonnen wurden. Bei der ersten Veröffentlichung noch im ursprünglichen Wortsinne zur Diskussion gestellt, behalten RFC auch dann ihren Namen, wenn sie sich durch allgemeine Akzeptanz und Gebrauch zum Standard entwickelt haben. Hingegen wird die fortlaufende Zählung (Nummerierung) der RFCs weitergeführt und eine neue RFC-Nummer vergeben, wenn eine abschließend geänderte Version durch eine neue Version, gegebenenfalls auch zusammengefasst aus mehreren Vorläufern und mit mehreren Ergänzungen versehen zu einem neuen Dokument zusammengeführt, abgelöst wird.

Jeder RFC besitzt einen Status für die Gültigkeit. Hier einige Beispiele:


Hinweise:

Einige RFCs sind zugleich "Internet Standard (STD)", "For Your Information (FYI)", "Best Current Practice (BCP)" oder "RARE Technical Report (RTR)" jeweils mit eigener Zählung.
Vereinzelt kommen auch Antworten auf allgemeine Fragen oder Nachrufe vor.

Die Kategorie FYI wurde 1990 eingeführt und richtet sich an ein breites Publikum, das ausdrücklich auch Anfänger umfasst.

Die Kategorie BCP wurde 1995 für RFC eingeführt, die kein Internetstandard werden können, aber relevant sind.

RFCs sind extrem formalistisch gestaltet:


All diese Formalismen sorgen für die Vermeidung von Missverständnissen in der Interpretation und Implementierung und somit für den Erfolg beim Betrieb des Internets. Als Beispiele hierfür und gleichermaßen für ihren Erfolg seien RFC 2822 (E-Mail) sowie RFC 2616 (HTTP) genannt.

Zwischen den offiziellen RFCs, die Quasi-Standards oder „Best Current Practices“ (derzeit beste Vorgehensweisen) beschreiben, finden sich aber auch immer RFCs, die nicht buchstabengetreu genommen werden sollten, oft aus Anlass des 1. April.


Nicht immer jedoch bleibt es bei RFC zum 1. April bei der Theorie.
So wurde am 6. März 2001 eine Implementierung des RFC 1149 "A Standard for the Transmission of IP Datagrams on Avian Carriers" (die Übertragung von IP-Datagrammen per Brieftaube) vorgestellt. Die durchschnittliche Antwortzeit eines Pings betrug jedoch 45 Minuten, so dass nicht mit einer regelmäßigen Nutzung im Echteinsatz zu rechnen sein wird. Allerdings führte dies zu einer Weiterentwicklung RFC 2549 "IP over Avian Carriers with Quality of Service", aber auch dieser Einsatz ist unwahrscheinlich.

Der Editor Emacs enthält schon seit Jahren eine vollständige Implementierung von RFC 2324: Das Hyper Text Coffee Pot Control Protocol (HTCPCP) dient der Fernsteuerung und -überwachung von Kaffeemaschinen.

Auf der Veranstaltung Hacking in Progress wurde RFC 2322, "Management of IP numbers by Peg DHCP", formuliert. Es definiert, wie IP-Nummern mit einem Filzstift auf Holzwäscheklammern geschrieben und diese an das zugehörige Kabel geklammert werden. Obwohl dieser RFC als Scherz gedacht war, wird das Verfahren regelmäßig eingesetzt.

Auch für das Pi Digit Generation Protocol gibt es mit "gpigen" eine freie Implementierung für mehrere Plattformen.




</doc>
<doc id="13002" url="https://de.wikipedia.org/wiki?curid=13002" title="Christoph Hartknoch">
Christoph Hartknoch

Christoph Hartknoch (* 1644 in Jablonken, Herzogtum Preußen; † 1687 in Thorn) war ein preußischer Historiker, Kartograf und Kupferstecher.

Christoph Hartknoch aus Passenheim kam im heutigen Powiat Szczycieński zur Welt. Hartknoch, Sohn des "Stephan Hartknoch" aus Lyck "(Ełk)", zog im Jahre 1650 zusammen mit seiner Familie nach Passenheim "(Pasym)". Dort erlebte er die Brutalität und Schrecken der Tatarenangriffe (siehe Mongolensturm), auf das südliche Ostpreußen. Sein Lehrer rettete ihm das Leben, indem er ihn aus dem Fenster schob. Viele Menschen wurden getötet und Orte zerstört, aber die Hartknochs konnten sich nach Königsberg retten.

In Königsberg fing er an, Theologie an einem evangelischen Institut zu lernen. Bald danach starben seine Eltern und er musste sich Arbeit suchen. Er wurde Privatlehrer in Kaunas und dann Rektor an der evangelischen Schule in Vilnius. Bald ging er nach Königsberg zurück und fing dort an, durch das Lesen von Büchern und Dokumenten sich für Geschichte zu interessieren.

1679 schrieb er ein Buch über Preußische Geschichte, erst in lateinisch, dann auch in deutscher Sprache "Alt- und Neues Preußen", sowie auch eine Preußische Kirchengeschichte ("Kirchen-Historia"). Die Werke enthalten Beschreibungen und Illustrationen der preußischen Menschen, ihrer Geschichte und Kultur und ebenfalls Kupferstiche von Städten in Preußen, zum Beispiel der Stadt Thorn "(Toruń)", wo Hartknoch zuletzt wohnte und am Gymnasium lehrte. Ethnographisches Material erhielt er vor allem von Matthäus Prätorius.

Durch seine Arbeit im litauischen Kaunas und Vilnius interessierte er sich ebenfalls für deren Geschichte. Er schrieb daraufhin eine erstmalige ausführliche Geschichte des Litauisch-Polnischen Bündnisses.

Die Stadt Thorn in Preußen war seinerzeit fast vollkommen evangelisch. Im Jahre 1677 wurde Hartknoch eingeladen, Direktor des Thorner Gymnasiums zu werden. Er nahm an und arbeitete dort zehn Jahre lang. Durch die schweren Lebensumstände, Tatarenangriffe und die dadurch resultierende Armut, gab Hartknochs Körper mit 43 Jahren auf. Er starb 1687 in Thorn und wurde dort begraben.

Seine ausführlichen wissenschaftlichen Arbeiten trugen viel zum Wissen über Preußen, Pommern, Samogitien, Kurland (Couronia) und Polen bei.

In seinem Buch "Alt- und Neues Preußen" veröffentlichte er auch eine Illustration von "Nikolaus Kopernikus", der aus Thorn stammte. "Alt- und Neues Preußen", sowie die "Preussische Kirchen-Historia" schrieb Hartknoch gegen Ende seines Lebens und während er Direktor am Thorner Gymnasium war. Er entschuldigt sich in dem Buch, dass er zeitbedrängt an der Ausgabe des Buches arbeitet, denn er merkte seinem Körper an, dass es bald mit ihm zum Ende ging. Ein Jahr später starb er, 43 Jahre alt.




</doc>
<doc id="13004" url="https://de.wikipedia.org/wiki?curid=13004" title="Protokoll">
Protokoll

Ein Protokoll zeichnet auf, hält fest oder schreibt vor, zu welchem Zeitpunkt oder in welcher Reihenfolge welcher Vorgang durch wen oder durch was veranlasst wurde oder wird. Hofprotokolle von Königshäusern und diplomatische Protokolle bei Staatsbesuchen legen u.a. Rangfolgen, Abläufe, Kleidervorschriften, Sitzordnungen und Verhalten fest.

Protokollierung oder "Niederlegung" bezeichnet das Aufzeichnen oder Verfassen eines Dokuments mit den drei Protokollbestandteilen erstens Zeitpunkt, zweitens Identifikator bzw. beteiligte Personen und drittens Vorgang. Die schriftliche Protokollierung wird auch Niederschrift genannt. Daneben kann eine Protokollierung auch ein elektronisches Dokument oder ein Ton- bzw. ein Videodokument erzeugen. Sind keine Menschen an der Protokollierung beteiligt, so erfolgt diese automatisch zum Beispiel bei Flugschreibern.

Das Wort "Protokoll" ist im deutschen Standardwortschatz seit dem 16. Jahrhundert nachweisbar und aus dem mittellateinischen "protocollum" entlehnt, welches wiederum selbst aus dem mittelgriechischen πρωτόκολλον, "protókollon" (aus πρώτος "prótos" „erster“ und κόλλα, "kólla", „Klebe, Leim“) mit der Ursprungsbedeutung „[den amtlichen Papyrusrollen] vorgeleimtes Blatt“ entlehnt wurde. Ein "prοtókollon" war zuerst ein vorn an Papyrusrollen geklebtes Blatt mit bibliografischen Daten, entspricht also etwa dem heutigen "Aktendeckel". Später übertrug sich der Begriff auf andere chronologische Aufzeichnungen, bis hin zur französischen Diplomatie, wo das Wort schließlich eine „Sammlung von Regeln“ bezeichnet.

Ein Protokoll wird von einem Schriftführer oder Protokollführer oder einem technischen Aufzeichnungsgerät angefertigt. Protokolle können nach dem Zeitpunkt ihrer Anfertigung, nach ihrem Inhalt und nach der Art der Niederlegung unterschieden werden.

Wenn eine richtige Durchführung festgelegter Abläufe auch im Nachhinein überprüfbar sein soll, wird das Voraus-Protokoll mit einem Jetzt-Protokoll oder Gedächtnisprotokoll, etwa in Form einer Prüfliste, verbunden.



Das Protokollieren ermöglicht Vorgänge zu rekonstruieren oder zu planen, um Fehler bzw. Fehlfunktionen zu orten bzw. zu vermeiden. Bei Staats- und Kommunikationsprotokollen soll die Festlegung von Abläufen absehbares Fehlerverhalten oder zumindest Unsicherheiten bei den Beteiligten oder bei den Abläufen zu vermeiden helfen. Bei Abfolge- bzw. den technischen Logging-Protokollen sollen mögliche Fehlentscheidungen bzw. Fehlfunktionen, die in der Gegenwart nicht erkennbar oder nicht unmittelbar behandelbar sind, zumindest im Nachhinein analysiert und kausal zugerechnet werden können (Fehleranalyse). Kommunikationsprotokolle dienen im weitesten Sinne ausschließlich der Beobachtung, Selbststeuerung und Behebung von Übertragungsfehlern.

Insofern werden Protokolle überall dort eingerichtet, wo ebenso mit regelmäßigen Abläufen aber auch Fehlern, Störungen oder Abweichungen gerechnet werden muss, weil deren Auftreten absehbar ist. Protokolle dienen der Kontrolle über Abläufe bzw. Operationen und Entitäten, entweder im Voraus, gegenwärtig oder im Nachhinein. Insofern kann die obige Definition ergänzt werden um die Funktion, die dem Protokollieren Im Allgemeinen kommt dem technischen Protokollieren die Funktion zu, adressierbare Entitäten anhand ihrer Daten erzeugenden Operationen zu beobachten oder beobachtbar zu machen, um Abweichungen zu analysieren oder gegenwärtig zu erkennen oder zukünftig zu vermeiden.

An eine Protokollierung zur Beweissicherung werden hohe Anforderungen gestellt. Darunter fallen insbesondere folgende Gesichtspunkte:


Liegt die Gewähr inhaltlicher Richtigkeit des Protokolls vor, kommt ihm positive Beweiskraft zu. Durch die positive Beweiskraft wird nachgewiesen, dass die protokollierten Vorgänge oder Ergebnisse wie erfasst stattgefunden haben. Ist die Vollständigkeit sichergestellt, kann einem Protokoll auch eine negative Beweiskraft zugeschrieben werden. Dadurch wird der Beweis erbracht, dass nicht beurkundete Vorgänge nicht stattfanden und nicht beurkundete Ergebnisse nicht zustande kamen. Mit der Echtheit des Protokolls steht und fällt seine gesamte Beweiskraft. Der Nachweis der Fälschung entkräftet das gesamte Protokoll. Die Gültigkeit eines Protokolls wird in der Regel mit der Unterschrift oder mit einem sonstigen Abschluss- und Identitätsvermerk des Protokollführers oder einer sonstigen Gewährsperson hergestellt.

Diese Anforderungen muss durch den Zeitpunkt der Anfertigung (Jetzt-Protokoll ist zuverlässiger als ein Gedächtnisprotokoll), die Art und Weise der Protokollierung (technisches Gerät oder Protokollführer), bei der Erfassung (Sensorik, Objektivität) und Lagern der Daten (Archivierung, stabiles Medium mit kontrollierter Zugänglichkeit) erfüllt werden.

Als Protokolle werden solche Aufzeichnungen bezeichnet, die nach einem definierten, in der Regel gleich bleibenden, Schema angefertigt werden. Als klassisches Paradigma für eine automatisierte, beweissichere Protokollierung gilt der Flugschreiber. Diesem ähnlich ist der noch in der Entwicklung befindliche Unfalldatenspeicher in Kraftfahrzeugen, durch den Bewegungsrichtungen vor einem Verkehrsunfall rekonstruiert werden können.

Bei Sitzungen, Tagungen, Verhandlungen usw. wird eine formelle Zusammenfassung der Gespräche und Ereignisse geschrieben. Aus diesem Grund bestimmen Vereine, Verbände und ähnliche Organisationen einen Protokollführer oder Sekretär, der damit beauftragt ist. Man unterscheidet bei diesen Aufzeichnungen zwischen Verlaufsprotokoll und Ergebnisprotokoll.

Bei Computern ist dies die Protokolldatei (die sogenannte Logdatei), in der Ereignisse, wie zum Beispiel der Empfang und Versand von E-Mails oder Vorkommnisse während einer Programmausführung, nach bestimmten Regeln festgehalten (protokolliert) werden.

Bei wissenschaftlichen Experimenten und den dazugehörigen Versuchs- oder Laborprotokollen werden neben dem Namen desjenigen, der den Versuch durchführt, sowie Zeit und Ort vor allem der Versuchsaufbau sowie die während des festgelegten Ablaufs ermittelten Messwerte notiert.

In dem Buch "Film verstehen" von James Monaco werden solche Geräte als Protokolltechniken bezeichnet, mit denen audiovisuelle Prozesse anhand von Filmkamera bzw. Projektor und Tonband (bzw. deren multimedialen Weiterentwicklungen) automatisiert aufgezeichnet und abgerufen werden können.

Protokolle haben eine feste äußere Form:

"Gemeinsames:" Im Kopf stehen Bezeichnung und Datum der Sitzung, Beginn und Ende, dazu Teilnehmer, Entschuldigte und Verteiler. Im Text einsortiert, vielleicht zusätzlich im Kopf, steht die Tagesordnung. Der Protokollant unterschreibt rechts, der Sitzungsleiter links.

Protokolle in der Telekommunikation und Informatik sind Regeln, welche das Format, den Inhalt, die Bedeutung und die Reihenfolge gesendeter Nachrichten zwischen verschiedenen Instanzen (der gleichen Schicht) festlegen, siehe "Netzprotokolle", "Protokoll (Datenbank)". Diese Protokolle regeln den Ablauf, und stellen gleichzeitig dessen Dokumentation sicher.

Eine weitere elementare Funktion der Datenbearbeitung ist die "Logdatei (Ereignisprotokoll)", die eine automatische zeitliche Aufstellung von gewissen Vorgängen enthält.

In der Diplomatie unterliegen sämtliche zwischenstaatliche Abläufe einer ganzen Reihe von Regeln, die möglichst genau eingehalten werden müssen, um keinen diplomatischen Zwischenfall auszulösen. Beispielsweise gelten für den Ablauf eines Staatsbesuches, aber auch für die Kleiderordnung, die Tischordnung usw. verbindliche Regeln.

Die Außenministerien der meisten Länder haben Angestellte, die sich ausschließlich mit der Einhaltung des diplomatischen Protokolls und der Beachtung der Protokollarischen Rangordnung, der Präzedenz, befassen. Weitere Protokollstellen gibt es meist beim Staatsoberhaupt, beim Innenministerium (für das innerstaatliche Protokoll und Zeremoniell) und beim Verteidigungsministerium (für die Repräsentationstruppenteile oder Garden). Nicht zum Protokoll gehören, wenngleich sie auch dort eine Rolle spielen, die Umgangsformen (Etikette). Vgl. auch Vereinbarte Niederschrift in Angelegenheiten der Europäischen Union mit Drittstaaten.

In der Lehre von den Urkunden des Mittelalters und der Frühen Neuzeit (Diplomatik) bezeichnet man als "Protokoll" den formelhaften einleitenden Teil einer Urkunde, der häufig eine Anrufung Gottes (Invocatio), den Titel des Ausstellers (Intitulatio) sowie die Angabe des Empfängers (Inscriptio), oft verbunden mit einer Grußformel (Salutatio), enthält. Für diesen Textteil ist auch der Begriff „Eingangsprotokoll“ gebräuchlich, der dann mit dem „Schlussprotokoll“ am Ende der Urkunde korrespondiert.

Ein Versuchsprotokoll beschreibt die Durchführung eines wissenschaftlichen Versuchs und dokumentiert mögliche Ergebnisse. Es beinhaltet Versuchsdurchführung, gegebenenfalls Beobachtungen und Erklärung sowie Auswertung der Ergebnisse.

Über die mündlichen Verhandlungen in Gerichtsverfahren wird ein Protokoll erstellt, so im Strafprozess das Hauptverhandlungsprotokoll. Die Protokollierung kann unter bestimmten Voraussetzungen durch einen Berichterstattervermerk ersetzt werden.





</doc>
<doc id="13005" url="https://de.wikipedia.org/wiki?curid=13005" title="Netzwerkprotokoll">
Netzwerkprotokoll

Ein Netzwerkprotokoll (auch Netzprotokoll) ist ein Kommunikationsprotokoll für den Austausch von Daten zwischen Computern bzw. Prozessen, die in einem Rechnernetz miteinander verbunden sind (verteiltes System). Die Vereinbarung besteht aus einem Satz von Regeln und Formaten (Syntax), die das Kommunikationsverhalten der kommunizierenden Instanzen in den Computern bestimmen (Semantik).

Der Austausch von Nachrichten erfordert häufig ein Zusammenspiel verschiedener Protokolle, die unterschiedliche Aufgaben übernehmen (beispielsweise Internetprotokollfamilie). Um die damit verbundene Komplexität beherrschen zu können, werden die einzelnen Protokolle in Schichten organisiert. Im Rahmen einer solchen Architektur gehört jedes Protokoll einer bestimmten Schicht an und ist für die Erledigung der speziellen Aufgaben zuständig (beispielsweise Übermitteln an einen bestimmten Knoten – Schicht 2). Protokolle höherer Schichten verwenden Dienste von Protokollen tieferer Schichten (Schicht 3 bildet ein logisches Netzwerk und verwendet Schicht 2 für die physische Zustellung). Zusammen bilden die so strukturierten Protokolle einen Protokollstapel – in Anlehnung an das ISO-OSI-Referenzmodell (siehe auch DoD-Schichtenmodell). Nachrichten einer bestimmten Schicht werden auch als "Protokolldateneinheiten" (protocol data units) bezeichnet.

Der in einem Protokoll beschriebene Aufbau eines Datenpaketes enthält für den Datenaustausch wichtige Informationen über das Paket wie beispielsweise:


Diese Informationen werden den Nutzdaten als "Header" vorangestellt oder als "Trailer" angehängt.

Außerdem werden in manchen Protokollen feste Paketsequenzen für den Verbindungsaufbau und -abbau beschrieben. Diese Maßnahmen verursachen weiteren Datenverkehr (Traffic) auf den Datenleitungen – den sogenannten "Overhead". Dieser Overhead ist unerwünscht, weil er die Kapazität belastet, wird aber aufgrund der wichtigen Aufgaben, die Protokolle leisten, in der Regel in Kauf genommen.

In der Internetprotokollfamilie steht mit dem User Datagram Protocol (UDP) in der Transportschicht auch ein Protokoll mit nur geringem Overhead zur Verfügung, das keine Ende-zu-Ende-Kontrolle der Übertragung gewährleistet, so dass Datagramme eventuell verloren gehen können oder die Reihenfolge beim Empfang nicht der beim Versand entspricht. Im Gegensatz dazu wird beim Transmission Control Protocol (TCP) die vollständige Zustellung der Datenpakete überwacht und diese außerdem in die richtige Reihenfolge gebracht, so dass der Anwendung ein zusammenhängender Datenstrom übergeben wird.



Anhand des Verbindungsaufbau-Prozederes des TCP-Protokolls soll ein einfaches praktisches Beispiel gezeigt werden (Handshake-Verfahren).


Die Verbindung ist damit hergestellt, und der eigentliche Datenaustausch kann beginnen, im Beispiel eine Dateiübertragung auf Anwendungsebene.


Es gibt eine Reihe von grundsätzlichen Protokollen, die den Datenverkehr in einem Netzwerk regeln. Sie werden vom Netzwerkstack – einem speziellen Systemprogramm – allen weiteren Programmen auf diesem Rechner zur Verfügung gestellt. Diese Protokolle dienen als Standard für die Datenübermittlung zwischen unterschiedlichen Systemen, dienen aber keiner Anwendung durch den Benutzer. Dabei legt man sich in der Regel auf eines dieser Protokolle für ein Netzwerk fest. Für das Internet wird die Internetprotokollfamilie verwendet, vor allem TCP/IP und UDP.

Die Funktionen der Protokolle bauen aufeinander auf: Transportprotokolle bereiten den Übertragungsweg für von ihnen prinzipiell unabhängige Anwendungsprotokolle. Das stellt sicher, dass Anwendungsprogramme auf unterschiedlichen Systemen untereinander kommunizieren können, sobald diese Systeme in der Lage sind, auf irgendeine Art eine Verbindung herzustellen. So regelt beispielsweise das Internet Protocol die weltweit eindeutige Adressierung von Rechnern. Diese Adressierung nutzen dann beispielsweise das Transmission Control Protocol zur Datenübertragung und das Simple Mail Transfer Protocol zum Übermitteln von E-Mails. Dieses schichtweise Aufeinanderaufbauen der Protokolle wird mit Hilfe des OSI-Modells dargestellt.

Auch dienen Anwendungsprotokolle als Standard für die Übertragung zwischen unterschiedlichen Programmen gleichen Typs. Bekannte Beispiele:


In der Anfangszeit der Vernetzung von Computern gestaltete sich die Datenübertragung schwierig, denn damit ein Computer einen anderen versteht, werden Regelwerke benötigt. Zunächst wurden sie in den Anwendungsprogrammen nur für den jeweiligen Nutzungszweck implementiert – mit dem Nachteil, dass dieses Programm an die vorhandene Netzwerktechnik und das Anwendungsprogramm auf der bzw. den Gegenseiten angepasst werden musste. Daraus folgte, dass oft nur gleiche Systeme untereinander kompatibel waren, was nicht zuletzt von Herstellern auch genutzt wurde, um die Kunden auch zu weiteren Anschaffungen ihrer Produkte zu animieren. Mit stetigen Neuentwicklungen und der Größe der Netzwerke stieg jedoch auch ihre Heterogenität, so dass sich die Forderung nach universell einsetzbarer Technik und Programmauswahl immer weiter durchsetzte. Dadurch wurden in den späten 1970er- und in den 1980er-Jahren von Computerherstellern modularisierte Protokolle entwickelt, die von nun an in abgeschlossenen Rechnernetzen als Übertragungsstandards galten.

Im Jahr 1968 wurden auf Veranlassung des amerikanischen Verteidigungsministeriums (DoD) von der staatlichen Forschungseinrichtung ARPA Versuche durchgeführt, mit denen grundlegende Erkenntnisse über die Funktionsweise von Rechnernetzen gewonnen werden sollten. Als praktisches Ergebnis wurde 1969 das ARPANET-Projekt aufgelegt, das die transparente Übertragung von Daten zwischen unterschiedlichen Teilnehmersystemen ermöglichen sollte – unabhängig von der Strecke, dem Medium oder dem Umstand der Übertragung. Ab 1983 hatte sich im ARPANET die Internetprotokollfamilie als Sammlung zusammenhängender Standards zuverlässiger und leistungsfähiger Datenübertragung durchgesetzt. Sie wird auch verwendet, nachdem das ARPANET als Internet der Öffentlichkeit zugänglich wurde, und gilt dadurch, dass viele Computer spätestens seit den 2000er Jahren mit dem Internet in Verbindung stehen, als Quasistandard für viele Netzwerkanwendungen.





</doc>
<doc id="13007" url="https://de.wikipedia.org/wiki?curid=13007" title="William Jones (Indologe)">
William Jones (Indologe)

Sir William Jones (* 28. September 1746 in London; † 27. April 1794 in Kalkutta) war ein britischer Indologe und Jurist. Er war ab 1783 Richter am Obersten Gericht in Kalkutta. Er ist besonders durch seine Arbeiten zur indogermanischen Sprachfamilie bekannt.

Bei den Brahmanen lernte er Sanskrit und erkannte als einer der Ersten dessen genetische Verwandtschaft mit dem Griechischen, Lateinischen, Gotischen und Keltischen. Er wurde damit zu einem wichtigen Wegbereiter für die neue Disziplin, der indoeuropäischen Sprachwissenschaft, die im deutschsprachigen Raum meist Indogermanistik genannt wird.

William Jones wurde 1746 in London geboren. Sein Vater war der Mathematiker William Jones. Der junge William Jones erwies sich als sprachbegabt und lernte schon früh Griechisch, Latein, Persisch und Arabisch. Es wird berichtet, dass er insgesamt in seinem Leben 28 Sprachen beherrscht habe. Trotz des frühen Todes seines Vaters konnte der Sohn die Universität besuchen und eine Karriere als Übersetzer beginnen. Er veröffentlichte "Histoire de Nader Chah", eine Übersetzung des auf Persisch geschriebenen Originals.

Ab 1770 studierte er Jura. Diese Berufsrichtung brachte ihn letztendlich nach Indien, wo er 1783 ans Oberste Gericht in Bengal (Kalkutta) berufen wurde.

Fasziniert von der indischen Kultur gründete Jones 1784 die Asiatic Society, deren Ziel die Erforschung aller Aspekte der Kultur und Natur Asiens war. Sie war eine der ersten Gelehrtengesellschaften, die einen fremden Kontinent zum Gegenstand ihrer Tätigkeit machte. Daneben widmete er sich vornehmlich dem Rechtswesen sowie der Musik, Literatur, Botanik und Geographie und war ein bedeutender Übersetzer indischer Literatur. Diese gewann ihre Bedeutung im Westen vor allem durch Jones' Übersetzungen. Sie wurden einer breiteren englischen Öffentlichkeit und darüber hinaus auch einer zunehmend größeren englisch-gebildeten indischen Elite vermittelt, die auf dieser Grundlage ein kulturelles Selbstbewusstsein "Indiens" als antiker Zivilisation entwickelte, eine Vorstellung, die in ihren Ansätzen wiederum in Europa entstanden war, unter anderem in der deutschen Romantik. In diesen Zusammenhang fällt auch die erste englische Übersetzung der Bhagavad Gita durch Charles Wilkins von 1785. Sie wurde ihrerseits 1787 ins Französische, 1802 ins Deutsche übertragen und hatte einen großen Einfluss auf die Literatur der Romantik und die Wahrnehmung hinduistischer Philosophie in der europäischen Geisteswelt.

William Jones ist dafür bekannt, als einer der Ersten die Ähnlichkeit des Sanskrit mit dem Griechischen und dem Latein erkannt zu haben (früher als Jones erkannten dies schon mehrere europäische Forscher: Filippo Sassetti im 16. Jahrhundert, Andreas Jäger (1660–1730), Benjamin Schulze im Jahre 1725 und Gaston-Laurent Cœurdoux im Jahre 1767). In "The Sanscrit Language" (1786) schlug Jones vor, dass alle drei Sprachen einen gemeinsamen Ursprung hätten und dass sie auch mit dem Gotischen und den keltischen Sprachen sowie dem Persischen verwandt seien. Dies war einer der frühen Hinweise auf die Existenz der indogermanischen Sprachfamilie und ein frühes Beispiel der Anwendung der vergleichenden Sprachwissenschaft.




</doc>
<doc id="13008" url="https://de.wikipedia.org/wiki?curid=13008" title="Thomas Alva Edison">
Thomas Alva Edison

Thomas Alva Edison (* 11. Februar 1847 in Milan, Ohio; † 18. Oktober 1931 in West Orange, New Jersey) war ein US-amerikanischer Erfinder und Unternehmer mit dem Schwerpunkt auf dem Gebiet der Elektrizität und Elektrotechnik. Seine Verdienste gründen in erster Linie auf der Marktfähigkeit seiner Erfindungen, die er mit Geschick zu einem ganzen System von Stromerzeugung, Stromverteilung und innovativen elektrischen Konsumprodukten verbinden konnte. Edisons grundlegende Erfindungen und Entwicklungen in den Bereichen elektrisches Licht, Telekommunikation sowie Medien für Ton und Bild hatten einen großen Einfluss auf die allgemeine technische und kulturelle Entwicklung. In späteren Jahren gelangen ihm wichtige Entwicklungen der Verfahrenstechnik für die Bereiche Chemie und Zement. Seine Organisation der industriellen Forschung prägte die Entwicklungsarbeit späterer Unternehmen.

Die Leistung von Edison bei der Elektrifizierung New Yorks und der Einführung von Elektrolicht markiert den Beginn der umfassenden Elektrifizierung der industrialisierten Welt. Diese epochale Veränderung ist insbesondere mit seinem Namen verbunden.

Thomas Alva Edison wurde am 11. Februar 1847 in Milan, einem Dorf im Norden Ohios, als siebtes Kind von Samuel Ogden Edison (1804–1896) und Nancy Matthews Elliott (1810–1871)
geboren. Seine Mutter arbeitete eine Zeit lang als Lehrerin, sein Vater übte häufig wechselnde selbstständige Tätigkeiten aus, unter anderem im Kiesabbau, in der Landwirtschaft und als Grundstücksspekulant. Der Vater war ein Freidenker und politischer Aktivist, der aus Kanada in die USA emigrieren musste. Das Elternhaus wird als intellektuell stimulierend eingeschätzt.

Thomas Edison erhielt nur einige Monate geregelten Schulunterricht. Danach wurde er durch seine Mutter weiter unterrichtet. Als er sieben Jahre alt war, zog die Familie nach Port Huron, Michigan, um. Vier Jahre später, 1859, erhielt er eine erste Anstellung für den Verkauf von Süßigkeiten und Zeitungen in der Grand-Trunk-Eisenbahn zwischen Port Huron und Detroit. Die langen Haltezeiten des Zuges in Detroit bis zur Rückfahrt nutzte er für das Lesen von Büchern in der dortigen Bibliothek.

Edison hatte bereits in seiner Kindheit Hörprobleme und war sein Leben lang schwerhörig.

1862 bekam er von einem Telegrafisten, dessen Sohn er vor einem Unfall bewahrt hatte, Unterricht in der Telegrafentechnik. Er arbeitete danach als Telegrafist bei James U. MacKenzie in Mount Clemens. Fünf Jahre lang, von 1863 bis 1868, hatte er häufig wechselnde Anstellungen als Telegrafist in Stratford, Indianapolis, Cincinnati, Memphis, Louisville und Boston. In dieser Zeit gewann er über die Bedienung hinaus ein profundes Verständnis für die Telegrafentechnik, da die Telegrafisten häufig auch die Wartung der Geräte und der Batterien übernehmen mussten. Durch die Zusammenarbeit mit Telegrafisten von Unternehmen und Zeitungen erkannte er die Bedeutung dieser Technik für viele Geschäftsbereiche. Er soll sich damals mit elektrotechnischen Fachbüchern und Fachzeitschriften weitergebildet und mit dem Experimentieren begonnen haben. 1868 kam er in Boston mit der Welt der Telegrafenhersteller, Telegrafenkonstrukteure und der Finanzierer dieser Technik in Kontakt und begann selbst mit der Entwicklung von Telegrafentechnik.

Am 11. April 1868 veröffentlichte die Fachzeitschrift "The Telegrapher" einen von Edison selbst geschriebenen Bericht. Thema war eine von ihm entwickelte Variante der Duplex-Technik für die gleichzeitige Übertragung von zwei Nachrichten über eine Leitung. Diese erste Veröffentlichung von Edison bewirkte zugleich seine Wahrnehmung in der Fachwelt außerhalb seines persönlichen Kreises. 1868 meldete er sein erstes Patent auf einen elektrischen Stimmenzähler für Versammlungen an. Dieser wurde im Kongress jedoch nicht eingesetzt. Die Abgeordneten bevorzugten das traditionelle, langsame Verfahren, da es mehr Möglichkeiten ließ, unbeliebte Anträge zu verzögern und andere Abgeordnete umzustimmen.

1869 ging Edison nach New York. Dort lernte er Franklin Leonard Pope kennen, kam durch ihn mit der "Gold & Stock Telegraph Company" in Kontakt und wurde für die gesamte Telegrafentechnik der Firma zuständig. Später wurde er Teilhaber der von Pope gegründeten Firma "Pope, Edison & Co." Beide erwarben gemeinsam Patente für Telegrafen mit Druckvorrichtungen. Solche wurden unter anderem zur Übermittlung der Goldpreise aus der Börse an die Händler benötigt. Ein weiterer von Edison und Pope entwickelter Drucktelegraf sollte speziell für die Bedienung durch Privatpersonen oder kleine Unternehmen ohne Fachpersonal geeignet sein. Gemeinsam mit weiteren Partnern wurde für dieses Marktsegment die "American Printing Telegraph Co." gegründet. Das gemeinsame Unternehmen "Pope, Edison & Co." wurde Ende 1870 wieder aufgelöst. Die gemeinsamen Patente und auch das erfolgreiche Geschäft der "American Printing Telegraph Co." kaufte die "Gold & Stock Telegraph Co." Unter anderem durch die Zusammenarbeit mit Pope, der mit vielen Fachzeitungen und Elektrounternehmen in Kontakt stand, wurde die Telegrafenbranche zunehmend auf das Talent von Edison aufmerksam. Die Entwicklungen von Pope und Edison waren zudem relevant im Kampf der Telegrafenunternehmen um den lukrativen Markt der Finanzinformationsdienstleistungen.

Franklin Pope hatte seit dem Ende der Zusammenarbeit bis zu seinem Tod 1895 eine von der öffentlichen Wahrnehmung signifikant abweichende Meinung über Thomas Edison. In Fachbüchern und Artikeln für Fachzeitschriften relativierte er Edison zugeschriebene Erfindungsleistungen. Als Patentanwalt oder Sachverständiger vertrat er häufig Kläger gegen Edison-Unternehmen.

1870 entstand Edisons erste eigene Werkstatt für Entwicklung und Fertigung in Newark, New Jersey. Sein Partner bei der Herstellung von Kurstelegrafen war der Mechaniker William Unger. Für das expandierende Geschäft gründete Edison 1872 eine neue Werkstatt mit dem Mechaniker Joseph Thomas Murray und zahlte Unger aus. Diese Werkstätten zur Herstellung von Kurstelegrafen und Telegrafen für private Leitungen hatten zirka 50 Mitarbeiter und wiesen eine Produktion von zirka 600 Geräten im Jahr auf. Sie markierten den Beginn der Tätigkeit Edisons als Erfinder-Unternehmer.

Durch zahlreiche Kooperationen und Verwertungen von Erfindungen in der Telegrafentechnik besserte sich Edisons finanzielle Situation in diesen Jahren. Während er 1869 noch bei der Familie seines damaligen Freundes Pope wohnte, konnte er bereits 1871 sein erstes eigenes Haus kaufen und eine eigene Familie gründen. Er heiratete Mary Stilwell. 1872 kam sein erstes Kind Marion auf die Welt. Die finanzielle Situation von Edison blieb aber unstabil, denn den hohen Kosten für seine Entwicklungsarbeiten und eigenen Fertigungswerkstätten standen nur unregelmäßige Einnahmen gegenüber. Sein Haus musste er 1874 wieder aufgeben und zeitweise in eine Wohnung ziehen.

Das zentrale Problem der Telegrafengesellschaften war damals die effiziente Nutzung der teuren Telegrafenleitungen. Automatische Telegrafen, die auf Papierlochstreifen vorgefertigte Nachrichten schnell senden, wurden von Julius Wilhelm Gintl konzipiert und von Joseph Barker Stearns (1831–1895) zur Anwendungsreife in England entwickelt. Auf den langen Distanzen der Telegrafenleitungen in Amerika funktionierten diese jedoch nicht. Edison konnte das Problem der Signalqualität lösen und die Telegrafen weiter beschleunigen, wobei insbesondere auch die Nachrichtenaufzeichnung beim Empfänger für die Geschwindigkeitsanforderungen weiterentwickelt werden musste. Von 25 bis 40 Wörtern je Minute bei den manuellen Telegrafen und 60 bis 120 Wörtern bei der Ursprungserfindung des automatischen Telegrafen verbesserte Edison die Übertragungsgeschwindigkeit auf 500 bis 1000 Wörter je Minute.

Der Versuch des Verkaufs der Technik an das "British Post Office Telegraph Department" schlug fehl. Edison stellte bei einer Reise nach London 1873 insbesondere Probleme seiner Lösung mit unterirdischen Telegrafenleitungen fest. Die Erkenntnis, weniger zu wissen als er glaubte, sowie der Kontakt mit der weiter entwickelten Elektrotechnik in England waren vermutlich der Anlass für die Erweiterung seiner Entwicklungstätigkeit auf experimentelle Forschungen und ein intensiveres Studium von Fachliteratur.

Edison entwickelte mit dem "Quadruplextelegrafen" eine Technik zur gleichzeitigen Übermittlung von vier Nachrichten und steigerte damit den Nutzen der Telegrafenleitungen weiter. Seine Lösung bestand darin, die Spannungsamplitude zur Signalübertragung einer Nachricht (Amplitudenmodulation) und die Polarität für die zweite Nachricht (Phasenmodulation) zu nutzen. Diese Technik kombinierte er mit der bekannten Duplextechnik, die die gleichzeitige Übertragung von Nachrichten in beide Richtungen ermöglichte. Telegrafenunternehmen, die über Rechte an dieser Technik verfügten, sparten hohe Beträge für die sonst erforderliche Ausweitung ihrer Übertragungskapazitäten durch zusätzliche Leitungen.

Der Verkauf von Rechten an der Quadruplex-Technik und weiteren Erfindungen Anfang 1875 eröffnete Edison neue Möglichkeiten. Er profitierte dabei von der Absicht des Eisenbahnindustriellen Jay Gould, mit der "Atlantic and Pacific Telegraph Co." ein zum Marktführer "Western Union" konkurrierendes Netz aufzubauen. Die Vorgehensweise von "Western Union", Telegrafenleitungen entlang von Eisenbahntrassen zu errichten, konnte Gould einfach kopieren, und die Rechte an leistungsfähiger Technik kaufte er von Edison. Mit dem Erlös konnte dieser seine damalige prekäre finanzielle Situation bereinigen und sein erstes Erfinder-Labor in Newark einrichten, welches er kurze Zeit später ausbaute und nach Menlo Park verlegte. Mit Charles Batchelor, Charles Wurth und John Kruesi, Mitarbeitern aus seinen Fertigungswerkstätten für Telegrafen, und dem neu angestellten James Adams machte Edison Forschung, Erfindung und Entwicklung zu seiner Kerntätigkeit.

Die 1875 begonnene Entwicklung des elektrischen Stiftes und einer darauf aufbauenden Kopier- und Drucktechnik, die später zur Mimeographie weiterentwickelt wurde, war durch die Arbeiten an der Telegrafentechnik inspiriert. Patentiert wurde die Erfindung durch das US-Patent 180.867 vom 8. August 1876 als "Autographic Printing". Es war Edisons erster Versuch, durch Erfindungen und deren Vermarktung regelmäßige Einnahmen zu erzielen. Der Erfinder und Unternehmer Albert Blake Dick entwickelte unter Verwendung eines Edison-Patents eine Variante ohne Elektrik, verkaufte das Produkt als "Edison Mimeograph" und erzielte damit für Jahrzehnte hohe Verkaufszahlen. Bis 1889 verkaufte er in den USA zirka 20.000 Geräte und etablierte die Kopiertechnik in Firmen und Behörden. Die von Edison selbst produzierten Geräte galten als „zu technisch“ und waren weit weniger erfolgreich. Während es bei den Telegrafie-Erfindungen um Infrastruktur für wenige Interessenten ging, war der elektrische Stift das erste Produkt von Thomas Edison für den Massenmarkt mit der besonderen Bedeutung von Werbung, Vertrieb und Kundenreaktionen. Seine Mitarbeiter Adams und Batchelor waren an den Erlösen beteiligt.

Kurzzeitig war Edison in einen wissenschaftlichen Disput über einen von ihm entdeckten "Etheric Force" genannten Effekt verwickelt, der sich später als die Entdeckung hochfrequenter elektromagnetischer Wellen herausstellte. Er versäumte es jedoch, seine fortgeschrittenen Experimente zur drahtlosen Telegrafie weiterzuentwickeln.

Mit der bedeutenden "Western Union Telegraph Co." stand Thomas Edison in einem Vertragsverhältnis. Das Unternehmen bezahlte ihn für die Entwicklung der akustischen Telegrafie. In der Telegrafentechnik hatte er 1869 bis 1875 seinen Ruf als Erfinder begründet und die finanziellen Voraussetzungen für seine weiteren Leistungen erarbeitet. In der Branche war Edison 1875 ein bekannter Mann, über den in Fachzeitschriften berichtete wurde. Der breiten Öffentlichkeit wurde er jedoch erst in den folgenden Jahren bekannt. Die Telegrafentechnik war fortan nicht mehr Schwerpunkt seiner Arbeit.

Franklin Pope, Marshall Lefferts, der Präsident der "Gold and Stock Telegraph Co.", und William Orton, der Präsident der "Western Union Telegraph Co.," gelten als wesentliche Wegbereiter für den weiteren Aufstieg von Thomas Edison. Ein Netzwerk an Beziehungen zu Zeitungen, Technologiefirmen und Patentanwälten verdankt er insbesondere Pope. Kontakte mit Investoren und das Wissen über Finanzierung und die Notwendigkeit eines Geschäftsplanes verdankt er Lefferts und Orton, die auch das Ansehen von Edison bei anderen Geschäftsleuten förderten. Von ihnen lernte er insbesondere, dass man für die Kontrolle über ein technologisches Vorhaben einen kompletten Satz aller notwendigen Patente benötigt.

Am 18. Juli 1877 ersann Edison den Phonographen, der in den folgenden Monaten entwickelt wurde. Im Unterschied zu vielen anderen seiner Erfindungen war diese etwas grundsätzlich Neues und keine Weiterentwicklung bekannter Technik. Edisons Arbeit an automatischen Telegrafen, die auf geprägte Papierstreifen gespeicherte Texte sendeten, führte zu der Entdeckung, dass die geprägten Papierstreifen bei der schnellen Ausführung in der Mechanik des Telegrafen Vibrationen und Töne erzeugten. Diese Beobachtung wurde von Edison zum Phonographen weiterentwickelt. Nach den Erinnerungen von Thomas Edison war die erste Aufnahme mit einem funktionstüchtigen Phonographen ein Vers "Mary had a little lamb". Er schrieb, er sei „ergriffen“ gewesen beim Hören der eigenen Stimme. Im November 1877 wurde der Phonograph der Öffentlichkeit vorgestellt und am 19. Februar 1878 erhielt er das Patent.

Ebenfalls 1877 gelang Thomas Edison mit der Entwicklung seines Kohlegrießmikrofons ein entscheidender Verbesserungsschritt in der Telefontechnik. Das Patent dafür wurde ihm jedoch erst nach langem Streit mit den Bell Labs zuerkannt, die ein später für ungültig erklärtes Patent von Emil Berliner erworben hatte. Bei den damals bereits von der Bell Telephone Company angebotenen Telefonen wurde die Energie zur Erzeugung eines elektrischen Signals im Mikrofon selbst aus dem aufgefangenen Schall gewonnen. Allerdings waren so erzeugte Signale ohne die erst im 20. Jahrhundert verfügbare elektronische Verstärkung zu schwach für die Übertragung über längere Distanzen. Bells Telefone konnten daher bisher nur im Ortsbereich genutzt werden. Mit Bell konkurrierende Telegrafengesellschaften, die selbst auch neue Geschäftsmodelle auf Basis der Telefonerfindung umsetzen wollten, beauftragten Edison, eine Lösung für dieses Problem zu entwickeln. Edisons Kohlegrießmikrofon gewinnt die für das elektrische Signal benötigte Energie nun nicht mehr aus dem Schall, sondern entnimmt sie einer externen Energiequelle. Durch das Mikrofon wird ein angemessen starker, von außen eingespeister Strom geleitet. Die Schallwellen beeinflussen den elektrischen Widerstand der in dem Mikrofon enthaltenen Kohlegrießfüllung. Auf diese Weise wird ein starker Signalstrom durch einen schwachen Schalldruck moduliert. Eine verständliche telefonische Sprachübertragung war damit über deutlich längere Distanzen möglich. Der wirtschaftliche Wert für die entstehenden Telefongesellschaften war erheblich.

Auf Thomas Edison geht die Verwendung des Rufs "hello" am Telefon zurück, während Alexander Graham Bell "ahoy" bevorzugte.

Edison wurde klar, dass eine Verbreitung von elektrischen Konsumprodukten elektrische Energieversorgungsnetze erforderlich machte. Als Schlüsselprodukt für deren Finanzierung und für die Bereitschaft von Hauseigentümern, Kabel zu verlegen, wurde elektrisches Licht angesehen. Vorbild war das Geschäftsmodell der Gasindustrie mit zentraler Versorgung, Gaszählern und dem einmaligen Verkauf von Lampen einerseits, aber dem nachhaltigen Verdienst an regelmäßigen Energielieferungen andererseits. Um seine Vision von der Elektrifizierung der Städte umzusetzen, arbeitete Edison mit seinen Mitarbeitern verstärkt an allen notwendigen Komponenten, insbesondere an der Glühlampe, den Schaltern und dem Stromzähler. Eine besondere Herausforderung war die Konstruktion geeigneter Generatoren. Die von Edison zunächst nur für den Eigenbedarf gebauten Dynamos konnten nur für 60 Glühlampen Strom liefern. Alle Komponenten der Stromversorgungs-Infrastruktur mussten somit neu konstruiert und dann selbst oder von Partnerfirmen gefertigt werden. Eine Gruppe von Investoren um J. P. Morgan stellte 130.000 Dollar für die Entwicklungsarbeiten an den Elektroerfindungen durch Beteiligung an der 1878 gegründeten "Edison Electric Light Co." zur Verfügung.

Auch vorherige Erfinder hatten sich schon mit der elektrischen Glühlampe beschäftigt. Aber keinem von ihnen war es gelungen, sie dauerhaft funktionstüchtig und ihren Energieverbrauch mit dem der Gaslampen wettbewerbsfähig zu machen. Die Vorteile wie Flacker- und Geruchsfreiheit, geringere Wärmeabgabe und einfacheres Ein- und Ausschalten konnten nicht in praktische Produkte umgesetzt werden. Ein weiteres ungelöstes Problem war die Teilung des Lichts. Nur wenige Lampen konnten mit den damals bekannten Lösungen an einer Stromquelle betrieben werden. Einige Physiker hielten das Problem für unlösbar und Elektrolicht prinzipiell nicht für den Ersatz des Gaslichts geeignet.

Auch Edison scheiterte zunächst mit seinen Versuchen, die bekannten Glühlampen mit Platinglühfaden zu verbessern. 1879 hatte er jedoch erste Erfolge bei Glühlampen mit einem hochohmigen Kohlefaden und perfekter Vakuumversiegelung, mit denen er angeblich zirka 40 Stunden Leuchtdauer erreichte. Der Durchbruch wird meist mit einem Test und einer Vorführung am 21. Oktober 1879 in Verbindung gebracht; dieses Datum gilt deswegen als Erfindungsdatum der praktischen Glühlampe. Die neuere Quellenforschung kann diese verbreitete Darstellung indes nicht bestätigen; die Laborbücher verzeichnen beginnende Tests mit Kohlefäden aus Baumwolle am 21. Oktober 1879 und zirka 14,5 Stunden Brenndauer einer Lampe mit hochohmigem Kohlefaden am 23. Oktober 1879. Die Verbesserung auf bis zu 1000 Stunden Leuchtdauer nahm weitere drei Jahre Entwicklungszeit in Anspruch. Präsentationsveranstaltungen in Menlo Park insbesondere am 31. Dezember 1879 beeindruckten jedoch bereits die Zeitungen und die Öffentlichkeit. Dabei entstand ein öffentliches Bewusstsein für das beginnende Elektrozeitalter. Edison konnte Unterstützer gewinnen und sein Projekt der Elektrifizierung New Yorks angehen. Das Basispatent der Lampenentwicklung von Thomas Edison, Nr. 223.898 „Electric Lamp“, wurde am 4. November 1879 beantragt und am 27. Januar 1880 erteilt.

Der für das Geschäftsmodell der Elektrizitätsnetze wichtige Verbrauchszähler beruhte auf einem nur für Gleichstrom geeigneten elektrolytischen Messprinzip, verschiedene andere Entwicklungen wurden verworfen. Die Konstruktion war stark beeinflusst von Michael Faradays Experimentaluntersuchungen der elektrochemischen Vorgänge der Elektrolyse und seiner Konstruktion des Voltameters. Der Verbrauchszähler von Edison ist eine Weiterentwicklung des Kupfervoltameters, später wurde Zink verwendet. Das Kernproblem des Messbereichs wurde durch eine Parallelschaltung gelöst, die nur einen proportionalen kleinen Anteil des Stroms durch das Messgerät führt; das Patent wurde am 20. März 1880 beantragt. Den Einfluss der Temperatur auf das Widerstandsverhalten des Elektrolyten mit negativem Temperaturkoeffizienten kompensierte Edison durch einen Spulenwiderstand mit positivem Temperaturkoeffizienten. Eine im Zählergehäuse angebrachte Glühlampe schaltete sich bei zu starkem Abfall der Temperatur als Wärmespender über einen Bimetallschalter ein. Weiterentwicklungen wurden von Edison als Webermeter bezeichnet, zu Ehren des deutschen Physikers Wilhelm Eduard Weber. Der Entwicklungsstand des auf der Elektrizitätsausstellung in Paris 1881 ausgestellten Modells war als Edisonzähler in den 1880er Jahren weltweit Bestandteil des Aufbaus der Elektrizitätswirtschaft. Obwohl der Zähler eine hohe Genauigkeit hatte, wegen der Einsparung mechanischer Teile wenig störanfällig war und nur einen sehr geringen Eigenverbrauch hatte, waren Verbraucher häufig skeptisch, da der Verbrauch nicht ablesbar war. Zur Verbrauchsbestimmung mussten Angestellte der Elektrizitätswirtschaft die Elektroden entnehmen und auf einer Feinwaage auswiegen; ein Gramm Gewichtsdifferenz entsprach 1000 Lampenbrennstunden. Zur Sicherheit hatte jeder Zähler eine zweite elektrolytische Messvorrichtung, die für ein Gramm Gewichtsabnahme der Anode je 3000 Lampenbrennstunden konstruiert war. Eine Lampenbrennstunde entspricht 0,8 Ah, bei 110 Volt Spannung des Edison-Netzes mithin 0,088 kWh.

Nach öffentlichen Vorführungen des Phonographen beim Präsidenten der USA und anderswo im April 1878 feierte die einheimische und europäische Presse Thomas Edison erstmals als großen Erfinder. Auch beeindruckte er die Öffentlichkeit im Dezember 1879 durch vorher unbekannte Lichtvorführungen mit augenblicklichem Ein- und Ausschalten einer großen Anzahl von Glühlampen und 1880 durch die Installation seines Beleuchtungssystems auf dem neu gebauten Dampfschiff SS "Columbia". Ab den späten 1870er Jahren berichteten nicht nur Fachzeitschriften, sondern auch Tageszeitungen über Edison, der dadurch eine weltweit bekannte Persönlichkeit wurde. Einige Zeitungen nannten ihn den „Zauberer von Menlo Park“. Diese von William Augustus Croffut geprägte Bezeichnung entwickelte sich zu einem feststehenden Begriff in der Kultur Amerikas.

In den folgenden Jahren verlagerte sich der Schwerpunkt der persönlichen Arbeit Edisons weg von der Entwicklung und hin zu der Vermarktung und Umsetzung von Elektrifizierungsprojekten. Zeitweise verlegte er seinen Wohnsitz und Teile seines Entwickler-Teams aus Menlo Park nach New York. Während bis dahin Produktionsorte meistens noch den Charakter von Werkstätten hatten, erforderte die Fertigung von Glühlampen und Komponenten für das Massengeschäft mit Licht und Strom den Aufbau von Fabriken und die Entwicklung rationeller Fertigungsprozesse. Edisons erste Lampenfabrik, die "Edison Lamp Co.", befand sich zunächst in Menlo Park und dann in Harrison, New Jersey. Von ihrer Gründung bis April 1882 wurden dort bereits 132.000 Glühlampen produziert.

Die "Edison Electric Light Co." wurde bereits am 15. November 1878 gegründet. Sie hatte das Recht, die in Menlo Park erarbeiteten Patente zu verwerten, und finanzierte im Gegenzug die Arbeit des Entwicklungslabors. Das Unternehmen gründete in den USA und im Ausland Tochter- und Kooperationsunternehmen und versorgte diese sowie andere Partner mit den notwendigen Patentrechten. Diese Gesellschaft kann daher als Kern des aus ihr entstehenden Elektrokonzerns gesehen werden. Die "Edison Electric Light Company of Europe" entstand im Dezember 1880. Im Jahr 1883 entstand durch eine Kooperation mit Emil Rathenau die "Deutsche Edison-Gesellschaft für angewandte Elektrizität", später AEG. Ende 1886 gehörten die von Edison gegründeten Unternehmen mit etwa 3000 Mitarbeitern und rund zehn Millionen Dollar Kapital zu den großen Konzernen ihrer Zeit. Die einzelnen Edison-Unternehmen in den USA hatten indes unterschiedliche Eigentümerstrukturen und Interessen. Edisons Fokussierung auf Lizenzeinnahmen aus dem Ausland statt auf den Aufbau eines globalen Unternehmens war insbesondere keine nachhaltige Strategie.

Die Beschaffung von Kapital für den Ausbau von Fertigungskapazitäten und für die hohen erforderlichen Investitionen in Kraftwerke und in die Verkabelung der Städte war das Hauptproblem bis Mitte der 1880er Jahre. Auch das Fehlen von Fachkräften für die Verkabelung und für den Betrieb von Kraftwerken stand einer schnellen und sicheren Umsetzung von Elektrifizierungsprojekten entgegen. Edison selbst standen einige wichtige Mitarbeiter in den USA nicht mehr zur Verfügung, da diese sich um Elektrifizierungsprojekte und die Gründung von Unternehmen in Europa kümmern mussten.

Aus diesen Gründen wurde die Elektrifizierung zunächst von Beleuchtungssystemen mit einem eigenen Dampfmaschinendynamo getragen. Edison entwickelte dazu Lösungen für unterschiedliche Mengen zu betreibender Lampen. Fabriken, für die Gaslampen eine Feuergefahr darstellten, Theater, Bahnhöfe und wohlhabende Privatleute waren die Kunden. So wurde ein Theater in Boston innerhalb weniger Tage verkabelt und über 600 Glühlampen sowie ein Dynamo wurden installiert. Das Mahen-Theater in Brünn war 1882 das erste Gebäude in Europa, in dem ein Edison-Beleuchtungssystem installiert wurde. In Deutschland gilt im Jahr 1884 das Café Bauer (Berlin) als erstes mit Glühlampen beleuchtetes Gebäude; die Lampen wurden von Emil Rathenau nach Edison-Patenten gefertigt.

Bis 1881 wurden unterirdische Kabel in New York verlegt. Außerdem erfand Edison elektrische Sicherungen, Messgeräte und verbesserte Dampfmaschinendynamos. Am 4. September 1882 wurde mit der "Pearl Street Station" das erste Zentralkraftwerk der USA in der New Yorker Pearl Street eröffnet; es war für Gleichstromtechnik ausgelegt. Im Büro des Bankiers J. P. Morgan, der in die "Edison Electric Light Co." investiert hatte, wurde das Netz durch Einschalten von Lampen in Betrieb genommen. Die konstruierten sechs Dampfmaschinendynamos wogen je 27 Tonnen und lieferten je 100 kW Leistung, ausreichend für zirka 1100 Lampen. Bereits am 1. Oktober 1882 wurden 59 Abnehmer versorgt, ein Jahr später waren es 513 Kunden. Die 1880 für das Projekt gegründete "Edison Electric Illuminating Company of New York" (ab 1901 "New York Edison Company") war der Prototyp für weitere lokale Elektrifizierungsgesellschaften. Im Jahr 1911 betrieb das Unternehmen 33 Kraftwerke, die für 4,6 Millionen Lampen von 108.500 Kunden Strom lieferten. Dieses Wachstum vollzog sich in anderen Städten der Welt analog und musste technisch und administrativ bewältigt werden. In Mailand wurde 1883 das erste kommerzielle Edison-Elektrizitätsnetz Europas in Betrieb genommen.

Die Kosten von Kraftwerken und Netzen mussten für die Verbreitung dieses Konzeptes gesenkt werden. Erste Elektrifizierungsprojekte in kleineren Orten der USA mit alternativen Konstruktionen wie überirdischer Verkabelung waren 1883 betriebsbereit. Die Suche nach geeigneten Standorten mit hinreichend vielen Kunden in der wirtschaftlich zu verkabelnden Umgebung eines Kraftwerks und die Finanzierung dieser Projekte blieben jedoch zunächst problematisch. Um geplante Kraftwerke über den ganzen Tag hinweg auszulasten und wirtschaftlich zu betreiben, beschäftigte sich Edison mit der Entwicklung von Motoren und der Elektrifizierung von Schienenfahrzeugen. Der Prozess bis zur Akzeptanz von Kraftwerken und Netzen bei Investoren und schließlich bis zu einer selbsttragenden Elektrifizierungswelle vollzog sich schleppend. Nach erfolgreichen Projekten hatten jedoch immer mehr Städte ohne Elektrizitätsnetz Angst vor Standortnachteilen und investierten in Kraftwerke und Netze; Edison konnte sich auf die Rolle als Technologielieferant beschränken.

Das von Edison entwickelte Dreileitersystem der elektrischen Energieversorgung erlaubt kleinere Querschnitte der Kabel und sparte mithin erhebliche Mengen an Kupfer. Edison dachte in Systemen und hatte ökonomische Faktoren wie die Kupferpreise stets im Blick, da der Erfolg seines Projektes von der Unterschreitung der Kosten von Gasbeleuchtungen abhing. Neben dem Dreileitersystem war die Erfindung einer speziellen Verkabelungstechnik von großer Bedeutung. Sie ermöglichte eine konstante Spannung im gesamten Versorgungsnetz ("Electric Distribution System", Patent 264642). Ohne diese Lösung hätte die Leuchtkraft der Glühlampen mit der Entfernung zum Kraftwerk abgenommen.

Das Schlüsselprodukt Glühlampe wurde kontinuierlich weiterentwickelt. Allein im Jahr 1882 wurden 32 Patente im Zusammenhang mit Glühlampen, deren Produktion und der Herstellung von Glühfäden angemeldet. Bereits am 13. Februar 1880 hatte Edison bei der Untersuchung des Grundes des Verbrauchs von Glühfäden erstmals den glühelektrischen Effekt beobachtet, der später zunächst Edison-Effekt genannt wurde und nach der mathematischen Beschreibung durch Owen Willans Richardson heute meist Edison-Richardson-Effekt genannt wird. Am 15. November 1883 meldete Edison das Patent 307.031 auf eine Anwendung dieses Effekts an. Er nutzte den Effekt, um Spannungsänderungen in einem Schaltkreis anzuzeigen und die Spannung zu regulieren.

Die Jahre von 1880 bis 1886 mit Aktivitäten in den USA und Europa und zahlreichen Firmengründen einerseits, aber auch technischen Problemen und der Notwendigkeit einer sofortigen Reaktion darauf sowie häufigem Kapitalmangel andererseits waren sehr intensiv im Leben von Thomas Edison. Entscheidungen mit großer Tragweite musste er aus Zeitmangel Mitarbeitern überlassen, und für den Austausch mit seinem Privatsekretär hatte er oft erst weit nach Mitternacht Zeit. In diese Phase fiel der Tod seiner Frau Mary im August 1884 im Alter von 29 Jahren. Seine zweite Eheschließung 1886 und das endgültige Verlassen seines Wohnhauses und des Labors in Menlo Park stehen am Beginn eines neuen Lebensabschnittes.

Nach dem Tod seiner Frau beschäftigte Edison sich zunächst mit der Verbesserung einiger seiner früheren Erfindungen. Unter anderem verbesserte er für die "Bell Telephone Co." sein Telefon durch Verwendung von Granulat aus Anthrazitkohle für das Mikrofon. Diese Konstruktion blieb bis in die 1970er Jahre gebräuchlich. Ferner fand er eine Lösung, mehrere Telefone an einer Leitung zu betreiben. Edison arbeitete dabei mit seinem Freund Ezra Gilliland zusammen. Beide erwarben 1885 in Fort Myers (Florida) benachbarte Grundstücke und errichteten gleiche Gebäude. Mit seiner zweiten Frau verbrachte Thomas Edison dort regelmäßig Winterurlaube; später wurde das Haus ein zweiter Wohnsitz.

1887 verlegte Edison die Entwicklungsarbeit in ein neues Laboratorium in West Orange, New Jersey, etwa zehnmal so groß wie sein bisheriges und das modernste seiner Zeit.

Als Reaktion auf die Weiterentwicklung "seines" Phonographen zum Graphophone, das erstmals mit einer Phonographenwalze aus Wachs arbeitete und eine erhebliche Verbesserung des Klangs aufwies, durch Alexander Graham Bell, dessen Cousin ersten Grades Chichester Alexander Bell sowie Charles Sumner Tainter, den drei Mitgliedern der "Volta Laboratory Association", tätig in dem gleichnamigen Volta Laboratory, entwickelte Edison seinerseits den Phonographen weiter, nachdem er ein Angebot der Entwickler des Graphophones, gemeinschaftlich die Kommerzialisierung ihrer „neuartigen“ Sprechmaschinen voranzubringen, abgelehnt hatte. Bis 1890 verbesserte er den Phonographen "(Improved Phonograph)" und entwickelte daraus ein Diktiergerät ("Edison Business Phonograph", später vertrieben als "Ediphone") sowie Phonographenwalzen aus Wachs, deren Aufnahmen man bei Bedarf durch Abschaben der obersten Wachsschicht und der darin eingravierten Rillen löschen und hiernach wiederverwenden konnte. Zeit- und Geldmangel wegen seines intensiven Engagements in der Elektroindustrie veranlassten ihn jedoch zu einem Verkauf der Vermarktungsrechte an den Unternehmer Jesse H. Lippincott der darauf hin die North American Phonograph Company gründete. Eine Anwendung des Phonographen in sprechenden Spielzeug-Puppen schlug indes fehl.

Im Wettbewerb um Marktanteile bei der Elektrifizierung gab es in den späten 1880er Jahren den sogenannten Stromkrieg zwischen Thomas Edison und seinen Konkurrenten George Westinghouse und Nikola Tesla. Edison bevorzugte das Gleichstromsystem, Westinghouse und Tesla die Elektrifizierung mit Wechselstrom. Hierbei wurden durch Edisons Firma Tierversuche mit Wechselspannung durchgeführt, um deren Gefährlichkeit gegenüber dem Gleichstrom zu demonstrieren. Diese riefen später bei Tierschützern Empörung hervor; damals regte indes die Gesellschaft zur Verhinderung von Grausamkeiten an Tieren die Entwicklung der Elektrokution als schmerzlose Alternative für das damals häufige Ertränken herumstreunender Tiere an. Auch für die Entwicklung des elektrischen Stuhls, einer Auftragsarbeit der amerikanischen Regierung an Edison, wurden von Harold P. Brown Tierversuche durchgeführt. Letztendlich setzte sich bei der Elektrifizierung wegen technischer Vorteile das Wechselspannungssystem von Westinghouse durch, und Thomas Edison musste zugeben, dass es einer seiner größten Fehler war, nach Erfindung des Transformators 1881 am Gleichstrom festgehalten zu haben. Edisons Lösung mit 110 Volt Gleichspannung war weder in ländlichen Gebieten mit weiten Entfernungen der Verbraucher zum Kraftwerk wirtschaftlich umzusetzen, noch konnte die preiswerte Energie aus entfernten Wasserkraftwerken zu den Verbrauchern transportiert werden.

Die Unternehmen von Westinghouse bekamen 1892 den Auftrag, ihr Wechselspannungssystem und eine große Anzahl einer neu entwickelten Glühlampe, der sogenannten "Westinghouse Stopper-Lamp", für die Weltausstellung in Chicago 1893 zu liefern. Das war ein besonders prestigeträchtiges Geschäft, denn mit dieser Ausstellung wurde das 400-jährige Jubiläum der Entdeckung Amerikas durch Kolumbus gefeiert. Der Verlust dieses Auftrags machte 1892 zu einem Jahr des Rückschlags in Edisons Karriere. Außerdem verlor er in dieser Zeit die finanzielle Kontrolle über seine Elektrounternehmen.

Edison fasste seine Unternehmen auf Rat des Managers Henry Villard bis 1890 zur "Edison General Electric Co." zusammen, da der vorherige Firmenverbund nicht mehr effizient zu leiten war. Die Fusion der zahlreichen Firmen zur "Edison General Electric Co." erforderte viel Kapital für den Aufkauf von Firmenanteilen Dritter an den zu fusionierenden Firmen, welches von Investoren kam, darunter die Deutsche Bank und "Siemens & Halske". Edison hatte keinen kontrollierenden finanziellen Aktienanteil an der "Edison General Electric Co." Er war Aktionär, hatte einen Sitz im Verwaltungsrat und war durch Verträge als externer Erfinder mit dem Unternehmen verbunden. Etliche Positionen in dem Unternehmen waren aber durch Vertraute von Edison besetzt, beispielsweise war sein vormaliger Privatsekretär Samuel Insull Vizepräsident.

Dieses Unternehmen fusionierte 1892 mit der "Thomson-Houston Electric Company" zur "General Electric Co." Das war aus finanziellen Gründen erforderlich, denn Fehlentscheidungen wie beim Wechselstrom, auslaufende Patente sowie hohe Kosten durch Expansion und Patentrechtsstreite brachten das Unternehmen in eine schwierige Lage. Die "Thomson-Houston Co." brachte die Edison fehlenden, aber zur weiteren Marktteilhabe erforderlichen Rechte an Wechselspannungspatenten und ihre Erfahrungen mit dieser Technologie in die Fusion ein. Chef der "General Electric Co." wurde Charles A. Coffin, der bis dahin Leiter von "Thomson-Houston Co." gewesen war. Elihu Thomson wurde der Chefentwickler des neuen Unternehmens; seine Entwicklungen und Patente führten in den Anfangsjahren zu Erfolgen der "General Electric Co." Edison verlor an Einfluss und Bedeutung. Die Fusion wurde von den anderen Anteilseignern der "Edison General Electric Co." und deren Analyse der Unternehmensituation initiiert, insbesondere der Bank Drexel, Morgan & Co. In der Denkweise der Banken, auch jener hinter der "Thomson-Houston Co.", führte die Reduzierung von Wettbewerb und die Bereinigung von Patentstreitigkeiten durch Fusion zu verlässlicheren Bedingungen für Investoren. Es ist unklar, wann Edison informiert war und ob er einverstanden war oder gezwungen wurde. Seine engen Mitarbeiter Samuel Insull und Alfred Tate berichteten, er sei vor vollendete Tatsachen gestellt worden und habe die Benutzung seines populären Namens für die neue Firma untersagt. Offiziell unterstützte Edison die Fusion, allerdings mit distanzierenden Angaben wie etwa, er habe ohnehin keine Zeit mehr für Elektrotechnik. Elektrotechnische Infrastruktur und Glühlampen spielten bei der weiteren Erfindertätigkeit von Edison nur noch eine marginale Rolle. Edisons Partner Charles Batchelor, der Anteilseigner der Edison-Unternehmen war und auch Aktionär bei "General Electric" wurde, arbeitete bis 1899 im Management von "General Electric".

Bereits 1894 und 1895 verkaufte Edison laufend General-Electric-Aktien und finanzierte mit dem Erlös seine Entwicklungen und Investitionen in anderen Branchen. Ferner kaufte er von ihm früher verkaufte Rechte im Phonographengeschäft und im Filmgeschäft zurück, um über seine damit verbundenen Patente und deren Verwertung die Kontrolle zurückzuerlangen.

1891 wurde in Edisons Labor der Kinetograph, ein Vorläufer der Filmkamera, erfunden. Ab 1896 beschäftigte er sich mit Röntgenstrahlen und der Entwicklung des Fluoroskops mit Kalziumwolframat-Schicht, welches gegenüber der Lösung von Wilhelm Conrad Röntgen die Bilddarstellung verbesserte. Edisons Mitarbeiter Clarence Dally starb an den Folgen der Experimente, er selbst erlitt gesundheitliche Schäden an Magen und Augen.

1895 gründete er zusammen mit dem befreundeten Schokoladeproduzenten Ludwig Stollwerck und anderen Gesellschaftern die "Deutsche Edison Phonograph Gesellschaft" mit Sitz in Köln.

Kinetograph, Kinetoskop (Wiedergabegerät) und das erste eingerichtete Filmstudio der Welt (die "Black Maria", 1893) in West Orange machten Edison zum Begründer der Filmindustrie. 1893 führte er den 35-mm-Film mit Lochperforation für den Transport ein, der ein Industriestandard wurde. 1894 entstand der Film „"Chinese Opium Den"“. Durch einen 1897 erfundenen Projektionsapparat wurde das Filmgeschäft zu einem seiner größten finanziellen Erfolge. In Deutschland gründete Ludwig Stollwerck 1895 die "Deutsch-Oesterreichische Edison-Kinetoskop-Gesellschaft" als Partner Edisons für die Vermarktung des Kinetoskops. Die produzierten Filme der Anfangsjahre nennen im Vorspann lediglich den Namen Thomas Edison. Das ist jedoch als Markenname zu verstehen; Edison persönlich war kaum mit der Filmproduktion beschäftigt. Die gesamte Entwicklung war wahrscheinlich inspiriert von Eadweard Muybridge und seiner Erfindung des Zoopraxiskops.

Ein Einstieg in das Eisenerzgeschäft scheiterte hingegen und wurde der größte Fehlschlag Edisons. Er hatte bereits in den 1880er Jahren ein magnetisches Verfahren zur Trennung von Erzgranulaten entwickelt, den Vertrieb vergeblich versucht und dann selbst mit Partnern in einige Pilotanlagen investiert. In den 1890er Jahren investierte er dann sehr viel von seinem in der Elektrobranche verdienten Geld und sehr viel seiner Zeit in die Umsetzung der großtechnischen Ausbeutung von Erzen mit geringem Eisengehalt, die aber nie wirtschaftlich funktionierte. Die Investitionen in die Verfahrensentwicklung wurden durch die Entdeckung von Eisenerzvorkommen mit höherem Eisengehalt ebenso wertlos wie die aufgekauften Abbaurechte. 1900 lief das Verfahren erstmals ein halbes Jahr störungsfrei, das Erz konnte jedoch nicht verkauft werden, und Edison beendete den Betrieb seines Bergwerks in Ogden, New Jersey. Vermutlich hatte Edison ein hohes Risiko in Kauf genommen, weil er den Verlust des Einflusses auf seine Elektrounternehmen mit einem unternehmerischen Erfolg in einem anderen Geschäftsfeld kompensieren wollte. Edison verkaufte 1897 auch seine Beteiligung am Energieversorger "New York Edison Electric Illuminating Co." zur Finanzierung des fehlgeschlagenen Eisenerzgeschäftes.

Die neuen geschäftlichen Aktivitäten mit einem Firmenverband von zirka 30 Firmen und zirka 3600 Mitarbeitern wurden zunächst unter der 1896 gegründeten "National Phonograph Co." zusammengefasst. 1911 wurde die Reorganisation abgeschlossen, und das Unternehmen wurde in "Thomas A. Edison Incorporated" umbenannt.

Die "National Phonograph Co." erzielte ab Ende der 1890er Jahre hohe Absatzzahlen mit einem von Edison neu entwickelten Phonographen für den Heimbereich. Insbesondere eine preiswerte Variante mit einem Federantrieb statt einem Elektromotor verkaufte sich gut. 25 Jahre nach der Ursprungserfindung des Phonographen erfolgte so die Wandlung zu einem Konsumgut des Massengeschäfts. Mit der Verbreitung der Geräte stieg die Nachfrage nach Tonträgern. Für zirka 10 Jahre blieb Edison der Marktführer in dem Segment in den USA. Von zirka 5.000 Geräten im Jahr 1896 stiegen die jährlichen Verkaufszahlen auf 113.000 Geräte und 7 Millionen Tonträger 1904.

Obwohl Edison den größten Teil seiner Zeit und seines Geldes in die Entwicklung von Investitionsgütern für industrielle Kunden wie Elektrizitätsnetze, Telegrafie, Telefon und Eisenerzgewinnung investierte, war die Produktion von Konsumgütern für private Verbraucher um die Jahrhundertwende seine Haupteinnahmequelle. Diese neuen Märkte entstanden gerade erst durch zunehmende Freizeit und steigenden Wohlstand infolge der Industrialisierung. Neben der Erfindung und Produktion von Geräten mussten hierfür Geschäftsmodelle gefunden und Vertriebswege aufgebaut werden. Insbesondere eine kosteneffiziente Produktion und niedrige Preise waren für den Massenmarkt von hoher Bedeutung. Edison beschäftigte sich intensiv mit der Automatisierung der Fertigung des Phonographen und der Vervielfältigung von Tonträgern.

Gemeinsam mit Ludwig Stollwerck entwickelte Edison die „Sprechende Schokolade“ als Schallplatte mit Tiefenschrift und einen 1903 speziell für Kinder produzierten Phonographen (wahlweise aus Blech oder Holz), der Musik von einer solchen Schokoladen-Schallplatte abspielte. Dieser Phonograph wurde „Eureka“ genannt, enthielt ein aufziehbares Uhrenlaufwerk von Junghans und wurde in Europa und in den USA verkauft. Außer den Schokoladen-Schallplatten wurden auch solche aus haltbarem Material angeboten.

Mit den verbesserten Phonographenwalzen, insbesondere dem kostengünstigeren Kopierverfahren der "Goldguss"-Walzen ab 1902 und der längeren Abspieldauer der "Amberol"-Walzen ab 1908, konnte Edison dem Wettbewerb gegen das von Emil Berliner erfundene Grammophon noch einige Jahre standhalten. Der Hauptwettbewerber in den USA war die Victor Talking Machine Company, die bekannte Musiker wie Enrico Caruso unter Vertrag hatte. Thomas Edison war der Meinung, die Stimmen bekannter Bühnenkünstler eigneten sich nicht für Aufnahmen und produzierte bekannte Musikstücke mit unbekannten Interpreten, die seinen Qualitätsstandards entsprachen. Auf den Tonträgern stand zunächst nur der Markenname Thomas Alva Edison, die Interpreten sollten möglichst wenig am Geschäft mit Tonträgern teilhaben. Für den direkten Konkurrenzkampf mit Berliners Schallplatte entwickelte Edison 1911 die Diamond Disc, ein eigenes Schallplattenformat mit Tiefenschrift, und den dazugehörigen Platten-Phonographen. Der Schellackplatten-Markt expandierte damals jedoch rapide; das Angebot wuchs enorm, insbesondere auch im unteren Preisbereich. Trotz technischer Vorteile konnte sich Edisons Erfindung wegen höherer Kosten und des eingeschränkten Sortiments nicht durchsetzen. Daneben stellte er unter dem Namen "Blue Amberol Record" unzerbrechliche Phonographenwalzen aus Zelluloid und den dazugehörenden, sehr kompakten "Amberola"-Phonographen her. 1919 hatte Edison in den USA nur noch 7,2 % Marktanteil bei Geräten und 11,3 % bei Tonträgern. Die Produktion von Geräten und Tonträgern zur Unterhaltung, auch die der Walzenphonographen und Tonwalzen, wurde 1929 eingestellt. Danach wurde der Phonograph mit Walze nur noch als Diktiergerät vermarktet. Ein Korrektursystem für Diktiermaschinen wurde bereits 1913 patentiert, das Telescribe-System (Kombination von Telefon und Phonograph) im Jahr 1914.

Bis 1910 beschäftigte sich Thomas Edison mit der Errichtung von Zementwerken in Stewartsville, mit Drehrohröfen, dem Bau von Betonfertighäusern und Alltagsgegenständen aus Beton, etwa Möbeln oder einem speziellen Phonographen. Ein von ihm entwickelter Drehrohrofen wurde ein Industriestandard. Sein Ziel war eine wirtschaftlichere Zementproduktion durch Automatisierung, Reduzierung des Energieverbrauchs und Dimensionierung der täglichen Produktionskapazität auf ein Mehrfaches der damals üblichen Kapazität von Zementproduktionen. Die Bewältigung der damit verbundenen Probleme nahm Jahre in Anspruch. In den 1920er Jahren war die "Edison Portland Cement Co." der größte Produzent in den USA und erwirtschaftete Gewinne. Die Qualität des Zements verbesserte Edison durch eine feinere Zermahlung des Ausgangsmaterials.

1912 wurde das Kinetofon patentiert, eine Kombination von Filmkamera und Phonograph (früher Tonfilm). Edison hatte gemeinsam mit anderen Unternehmern 1908 die Motion Picture Patents Company gegründet, die den amerikanischen Filmmarkt über die Patentrechte der beteiligten Unternehmen und die 1910 gegründete Vertriebsfirma "General Film Company" kontrollieren sollte. Eine Gerichtsentscheidung nach den Bestimmungen des Sherman Antitrust Act erklärte das Unternehmen 1916 jedoch für illegal. Auslaufende eigene Patente und der Verlust von Einnahmen aus dem Filmgeschäft in Europa infolge des Ersten Weltkriegs führten zu hohen Umsatzverlusten. Während nach 1900 zunächst noch insbesondere Filme von Edwin S. Porter für Erfolge sorgten, war die Produktion später nicht mehr wettbewerbsfähig. 1918 beendete Thomas Edison seine unternehmerischen Aktivitäten im Filmgeschäft.

Thomas Alva Edison war mit Henry Ford befreundet, der bei der "Edison Illuminating Co." seine Karriere begonnen hatte und von Edison dazu ermuntert worden sein soll, sich im Fahrzeugbau selbständig zu machen. Edisons intensive Beschäftigung mit der Weiterentwicklung der Batterietechnik geht auf die Anforderungen im Automobilbau zurück. Der Elektrifizierung der Automobile stand die unzureichende Batterietechnik entgegen. Die bekannten Bleiakkumulatoren waren insbesondere zu schwer. Auch die Eisenbahnen hatten einen Bedarf an wiederaufladbaren Batterien. Nach Vorarbeiten an dem Edison-Lalande-Element und einer langen Entwicklungszeit mit vielen Rückschlägen wurde der Nickel-Eisen-Akkumulator als Lösung perfektioniert. Die Grundlösung war 1904 gefunden und ging in Produktion. Die Kunden waren zufrieden, Edison machten jedoch die Ausfallraten Sorgen. Er stoppte die Produktion und investierte weitere 5 Jahre Entwicklungsarbeit in Detailverbesserungen. Die "Edison Storage Battery Company" erzielte bereits im ersten Produktionsjahr eine Million Dollar Umsatz, was den Marktbedarf dokumentiert. Die zahlreich durchgeführten und sorgfältig dokumentierten Experimente wurden eine wichtige Datenbasis für folgende Generationen von Batterieentwicklern. Im Rahmen der Batterieentwicklung konstruierte Thomas Edison Autos und Schienenfahrzeuge mit Elektroantrieb. Er sah in solchen Fahrzeugen den wichtigsten Zukunftsmarkt für Akkumulatoren und elektrische Energie aus Kraftwerken. Die Entwicklung der Verbrennungsmotoren führte aber zu einer Verdrängung der damals von verschiedenen Herstellern angebotenen Elektroautos. Der Wegfall dieses Marktes, der die Entwicklung der Batterie initiiert hatte, wurde jedoch durch die vielfältige andere Nachfrage kompensiert. Die Batterie ersetzte Phonograph und Filmgeschäft als Fundament von Edisons Unternehmen. Eine 1911 entwickelte kompakte Batterie wurde insbesondere die Grundlage sicherer elektrischer Lampen für Bergleute, ein anderes erfolgreiches Produkt von Edison. In Deutschland wurde 1904 die "Deutsche Edison Akkumulatoren Gesellschaft" gegründet. Die Gesellschaft ging in dem heutigen Unternehmen Varta auf.

Die USA bezogen Substanzen von der deutschen Chemieindustrie. Mit Ausbruch des Ersten Weltkriegs stockte die Versorgung. Dadurch wurde Edisons Beschäftigung mit Verfahrenstechniken in der Chemie angeregt. 1914 errichtete er Fabriken zur Synthese von Phenol (Karbolsäure) aus Benzol für die Schallplattenproduktion. 1915 baute er Fabriken zur Synthese von Anilin und para-Phenylendiamin in wenigen Wochen und 1916 Fabriken zur Synthese von Benzidin-Base und des Sulfats.

Gemeinsam mit anderen Erfindern und Wissenschaftlern stellte sich Edison nach der Versenkung der RMS Lusitania durch die deutsche Kaiserliche Marine der Regierung im Ersten Weltkrieg zur Verfügung, um Abwehrmaßnahmen gegen deutsche U-Boote zu erarbeiten. Er wurde Vorsitzender des "Naval Consulting Board", das Vorschläge und Erfindungen prüfen und in Prototypen umsetzen sollte.

Ab 1926 zog er sich aus seinen Unternehmen zurück. Sein Sohn Charles Edison wurde 1927 Präsident der Dachgesellschaft "Thomas A. Edison Inc." Anlässlich seines achtzigsten Geburtstags im Jahr 1927 wurde Thomas Edison durch den Besuch von Delegationen aus aller Welt und durch zahlreiche Auszeichnungen geehrt.

In den letzten beiden Jahrzehnten seines Lebens hatte Edison häufig aus seiner Berühmtheit resultierende Pflichten. Er wurde von bekannten Persönlichkeiten besucht, zu Eröffnungszeremonien eingeladen und zu aktuellen Ereignissen interviewt.

Die "Edison Botanic Research Company" war 1927 das letzte von Edison gegründete Unternehmen. Beteiligt waren Harvey Firestone und Henry Ford. Das Unternehmen sollte wegen der Importabhängigkeit der USA von Naturkautschuk nationale Alternativen suchen. Der alternde Edison engagierte sich in diesem Projekt mit seinen bewährten Arbeitsmethoden noch einmal persönlich. Ein biologisches Forschungslabor entstand 1928 nach dem Modell seiner erfolgreichen Entwicklungseinrichtung "Menlo Park". Zirka 17.000 Pflanzen wurden geprüft, ein Verfahren der Gewinnung von Kautschuk aus Goldruten erarbeitet und das Projekt der Regierung übergeben. Das Verfahren blieb ohne Bedeutung, da synthetische Materialien die Abhängigkeit von Naturkautschuk reduzierten.

Thomas A. Edison starb am 18. Oktober 1931 in seinem Haus „Glenmont“, Llewellyn Park in West Orange, New Jersey. US-Präsident Herbert Hoover bat die Amerikaner, zu Ehren von Edison anlässlich der Beisetzung die elektrischen Lampen auszuschalten, die wie kein anderes Produkt in der öffentlichen Wahrnehmung mit dessen Namen verbunden waren. In Anwesenheit von Lou Hoover, der Gattin von Herbert Hoover, sowie Henry Ford und Harvey Firestone wurde er am 21. Oktober 1931 auf dem Rosedale Cemetery in Orange, New Jersey, beigesetzt, am 52. Jahrestag des damals als Erfindungsdatum der praktischen Glühlampe geltenden 21. Oktober 1879.

Edison war politisch ein Anhänger der Republikanischen Partei. Unter anderem unterstützte er die republikanischen Präsidenten Theodore Roosevelt, Warren G. Harding, Calvin Coolidge und Herbert Hoover. 1912 sprach er sich für die Einführung des Wahlrechts für Frauen in den USA aus. Edison hatte selbst keine Schulausbildung. Er kritisierte das amerikanische Ausbildungssystem und äußerte sich geringschätzig über den Wert von Fächern wie zum Beispiel Latein. Die Ausbildung praktisch befähigter Ingenieure sah er als Hauptaufgabe.

Edison entschied persönlich über die auf seinen Tonträgern angebotenen Musikstücke und -interpreten. Er hatte jedoch eine Abneigung gegen Jazz-Musik. Der seit seiner Jugend Schwerhörige soll außerdem Interpreten nach der Verständlichkeit gesungener Texte ausgesucht haben. Im Laufe der Zeit entwickelte sich die von seinen persönlichen Vorlieben statt von der Marktnachfrage geleitete Auswahl zu einem wirtschaftlichen Nachteil seiner Unternehmen.

Er vertrat eine Philosophie der Gewaltfreiheit. Am 4. April 1878 trat er der Theosophischen Gesellschaft bei. Doch obwohl er ein Gegner der Todesstrafe war, übernahm seine Firma einen Regierungsauftrag zur Entwicklung des elektrischen Stuhls. Edison betonte mehrfach, dass er sich nie mit der Erfindung von Waffen beschäftigt habe.

Thomas Edison kritisierte christlich-religiöse Vorstellungen und engagierte sich gegen Religionsunterricht an Schulen. Er wird von Zeitungen zitiert mit „Religion is all bunk … All bibles are man-made.“ (Alle Religion ist Geschwätz … Alle Bibeln sind menschengemacht.) Im Oktober 1910 fanden Ausführungen von ihm in den USA Aufmerksamkeit, in denen er Vorstellungen von der Existenz einer Seele und deren Unsterblichkeit ablehnte. Seine zweite Frau, eine gläubige Methodistin, versuchte vergeblich, seine Einstellung zu ändern; er blieb ein religiös ungebundener Freidenker.

Der mit der Erforschung der Quellen zu Edison befasste Paul Israel weist darauf hin, dass dessen Sicht der Juden differenziert war und es keine Belege für eine Übereinstimmung mit den antisemitischen Publikationen seines Freundes Henry Ford gibt. Edison sah gesellschaftliche Konflikte als Folge jahrhundertelanger Verfolgung der Juden und nahm an, dass diese Probleme sich mit der Zeit von selbst verflüchtigen würden, da Juden in Amerika nicht weiter verfolgt wurden. Allerdings teilte Edison verbreitete Vorurteile über Juden wie etwa, diese hätten einen übernatürlichen Geschäftssinn.

Thomas Alva Edisons Eltern sind Samuel Ogden Edison, Jr. (1804–1896) und Nancy Matthews Elliott (1810–1871). In erster Ehe war er mit Mary Stilwell (1855–1884) von 1871 bis zu deren frühem Tod verheiratet. Aus der Ehe gingen drei Kinder hervor: Marion Estelle Edison (1873–1965), Thomas Alva Edison Jr. (1876–1935) und William Leslie Edison (1878–1937). In zweiter Ehe war Thomas Alva Edison von 1886 bis zu seinem Tod 1931 mit Mina Miller (1865–1947) verheiratet. Auch aus dieser Ehe gingen drei Kinder hervor: Madeleine Edison (1888–1979), Charles Edison (1890–1969) und Theodore Miller Edison (1898–1992).

In der Öffentlichkeit am bekanntesten wurde Thomas Edisons Sohn Charles Edison, der als Politiker der Demokratischen Partei zeitweise Gouverneur von New Jersey sowie US-Marineminister war. Seine Tochter Marion war mit dem deutschen Leutnant Oscar Oeser verheiratet und lebte von 1895 bis 1925 in Deutschland.

Edison hat im Laufe seines Lebens insgesamt 1.093 Patente eingereicht und zudem noch weitere zusammen mit anderen Forschern. Allein im Jahr 1882 legte er dem Patentamt fast 70 neue Erfindungen vor.

Das von Edison in Menlo Park betriebene Labor gilt gemeinhin als Vorläufer und Vorbild der sich herausbildenden industriellen Forschungs- und Entwicklungsabteilungen von Technologieunternehmen.

Die Suche nach einem geeigneten Material zur Herstellung von Kohleglühfäden ist ein Beispiel für Edisons Arbeitsmethoden. Seine Mitarbeiter fanden heraus, dass sich Fasern schnellwachsender tropischer Pflanzen gut eignen würden. Edison finanzierte daraufhin eine Expedition zur Einsammlung solcher Pflanzen. In umfangreichen Testreihen wurden die Eigenschaften der Pflanzenfasern geprüft und nach 18 Monaten die in Japan heimische Bambus-Art "Phyllostachys bambusoides", die dort als „Madake“ bezeichnet wird, als am besten geeignet bestimmt. Das Patent 251.540 datiert vom 27. Dezember 1881.

Die Aufzeichnungen der damals für die Entwicklung der Glühlampe und der elektrotechnischen Infrastruktur ausgeführten Experimente sollen 40.000 Seiten umfassen. Das empirische Erarbeiten gesuchter Lösungen in umfangreichen Versuchsreihen verbunden mit dem Verständnis, dass auch jeder Fehlschlag die Lösung näher bringt, gilt als wichtiger Grund für Erfindungserfolge von Thomas Edison.

Die Fähigkeit, kompetente Mitarbeiter für anstehende Probleme zu finden und einzubinden, ist ein weiterer Grund. Sein wichtigster Partner war langjährig der Engländer Charles Batchelor, der als besonders geschickt in der Durchführung von Experimenten gilt. Dessen Sonderstellung unter den Mitarbeitern wird durch seine Beteiligung von 10 % an Erlösen aus allen Erfindungen deutlich. Der Feinmechaniker John Kruesi arbeitete ab 1872 für Edison und war an der Umsetzung zahlreicher Konstruktionszeichnungen und Skizzen beteiligt. Der aus Lauscha stammende Glasbläser Ludwig Karl Böhm, der zuvor in Deutschland schon mit dem Erfinder der Vakuumpumpe Heinrich Geißler zusammengearbeitet hatte, war der erste Spezialist auf diesem Gebiet in seinem Team. Der Techniker und Organisator Sigmund Bergmann, der Mathematiker und Physiker Francis Robbins Upton, der Chemiker Otto Moses und der Elektroingenieur Harry Ward Leonard sind andere Beispiele für die Einbindung von Kompetenz zur Förderung der Geschäftsziele von Edison. Auch Erfinder wie Lewis Howard Latimer, der bereits eigene Patente auf dem Gebiet der Glühlampenentwicklung erworben hatte, arbeiteten für Edison-Unternehmen. Das Talent von Nikola Tesla erkannte Edison hingegen nicht. Dieser schied im Streit aus und wurde ein wichtiger Mitarbeiter seines Konkurrenten Westinghouse Electric. Tesla kritisierte später die seiner Meinung nach unwissenschaftliche Arbeitsweise von Edison als ineffizient.

Die Erfindungen in Menlo Park und später in West Orange wurden unter dem Namen von Thomas Edison patentiert, aber zum überwiegenden Teil von einem Team von Handwerkern, Ingenieuren und Wissenschaftlern unter seiner Leitung entwickelt. Kinetoskop und Kinetograph gelten beispielsweise als Erfindungen des im Edison-Labor tätigen William K. L. Dickson. Die Anteile einzelner Mitarbeiter des Teams an schöpferischen Leistungen sind nicht präzise feststellbar. In der tradierten öffentlichen Kommunikation entstand unzutreffend das Bild von Thomas Edison als alleinigem geistigen Urheber der Erfindungsleistungen. Technologische Führung, Organisation und Finanzierung waren die Schwerpunkte seiner mit Erfindungen verbundenen Leistungen ab 1875.

Edison wird als charismatische Persönlichkeit beschrieben. Mitarbeiter aus Menlo Park sagten später, er habe ihnen das Gefühl gegeben, Partner und nicht Angestellte zu sein. Bei relativ geringer Bezahlung stellte Edison seinen Mitarbeitern ihren Leistungen entsprechende Anteile an später zu gründenden Unternehmen in Aussicht. Als sich bei der Entwicklung der Glühlampe und der Elektroinfrastruktur erste Erfolge einstellten, hatten selbst geringste Anteile seiner Mitarbeiter bereits den Gegenwert mehrerer Jahresgehälter. Die Kombination einer charismatischen Person mit einer natürlichen Autorität, Teamgeist und die finanzielle Beteiligung der Mitarbeiter waren für deren hohe Leistungsbereitschaft und den sich einstellenden Erfolg maßgeblich. Die wenigen Regularien wie die Aufzeichnung aller durchgeführten Experimente in den Laborbüchern überwachte Edison selbst.

Diese im Entwicklungsbereich erfolgreiche, auf die Person Edison zugeschnittene Form der Organisation und Zusammenarbeit erwies sich bei dem entstehenden Unternehmen mit mehreren tausend Mitarbeitern als weitgehend untauglich. Erst mit Zusammenfassung der diversen in den 1880er Jahren gegründeten Edison-Unternehmen zu "Edison General Electric Co." 1890 und der Gründung von "General Electric" 1892 konnten die Defizite in Organisation, Berichtswesen und Management beseitigt werden. Das kostete Edison jedoch einen gravierenden Verlust an Einfluss auf von ihm gegründete Unternehmen. Diese waren in den 1880er Jahren zeitweise ohne Management, da Edison in technische Probleme vertieft war und sich um Post und notwendige Entscheidungen nicht kümmerte.

Ein weiteres Merkmal der Erfindertätigkeit Edisons ist das Aufkaufen von Patenten, die ergänzt um Weiterentwicklungen in neue Patente eingingen.

Der von ihm etablierte Erfindungsprozess wird gelegentlich als „Erfindung der Erfindung“ bezeichnet und "Menlo Park" selbst als wichtige Erfindung beschrieben. Das Zusammenführen wissenschaftlicher Experimentiereinrichtungen mit Werkstatteinrichtungen verschiedener Handwerksberufe, das Zusammenstellen eines Teams mit einer breiten Abdeckung von Wissen und handwerklichen Fähigkeiten und die Organisation von Arbeitsbedingungen, die die Kreativität aller Mitarbeiter fördern, gelten heute nicht nur als Gründe für den Erfolg von Thomas Edison, sondern auch als wegweisend für die Technologieunternehmen des 20. Jahrhunderts. "Menlo Park" wurde von vielen Industrieunternehmen kopiert und war insbesondere das Modell für die Bell Laboratories.

Thomas Edison kommentierte sein Erfolgskonzept mit den Worten:

Seine Art des Managements, welches unter den Bedingungen der täglichen persönlichen Kommunikation im Labor funktionierte, aber eine wahrscheinliche Ursache von Problemen seines Firmenverbundes war, kommentierte er ohne Selbstzweifel:

(Jeweils Kalenderjahr der ersten Patentanmeldung. Weitere Patentanmeldungen für Verbesserungen der Ursprungserfindung erfolgten häufig über viele Jahre hinweg. Erfindung, Patentanmeldung, Patenterteilung und Beginn der Vermarktung können in verschiedene Kalenderjahre fallen. Unterschiedliche Angaben in Veröffentlichungen haben darin ihre Ursache. Das damalige Patentsystem der USA sah ferner die Registrierung von Vorbehalten auf Erfindungen in Arbeit vor. Für das Patent auf den Kinetographen wurde beispielsweise 1891 ein Vorbehalt angemeldet, 1897 wurde es erteilt.)

Eine Erfindung Edisons ist heute noch in jedem Privathaushalt vorhanden: das sogenannte Edison-Gewinde, mit dem Glühlampen oder Kompaktleuchtstofflampen („Energiesparlampen“) und als jüngste Entwicklung die LED-Lampen in die zugehörige Fassung geschraubt werden können. Das früher aus Messingblech, heutzutage meist aus Kunststoff hergestellte Gewinde zeichnet sich durch eine einfache Produktion sowie durch eine sichere Handhabung auch für Laien aus. Die Lösung soll auf eine Idee von Thomas Alva Edison aus dem Jahr 1881 zurückgehen, die er dann gemeinsam mit Sigmund Bergmann in dessen "Bergmann and Company’s Shop" in New York entwickelte. Die erste Patentierung erfolgte am 27. Dezember 1881 im Patent 251554. Der Lampensockel wurde in einer gemeinsamen Firma produziert. Bergmann verkaufte seine Anteile 1889 an Edison und ging nach Berlin zurück. Die Lösung wird auch in Nachfolgeprodukten der Glühlampe und für andere Leuchtmittel weiterhin häufig verwendet.

Edison entwickelte nicht immer seine Erfindungen zu Produkten weiter. Er besaß mit dem Patent 465.971 „Mittel für die Übertragung elektrischer Signale“, beantragt 1885 und ausgestellt 1891, ein Basispatent für die drahtlose Telegrafie. 1903 verkaufte er es an den mit ihm befreundeten Guglielmo Marconi, der dadurch seine eigenen Patente vor Urheberrechtsansprüchen von Vorerfindern schützen konnte.

Das Tasimeter für feine thermometrische Beobachtungen ist ein Beispiel einer nicht patentierten Erfindung von Edison. Die Veröffentlichung ohne Patentanmeldung bedeutet eine Überlassung an die Allgemeinheit zur Nutzung ohne Urheberrechtsvergütung.

Zu den erfolglosen Erfindungen von Thomas Edison gehören einige skurril erscheinende Ideen wie die Herstellung von Möbeln und Klavieren aus Beton. Auch die aus der Glühlampenherstellung abgeleitete und patentierte Konservierung von Obst in evakuierten Glasbehältern blieb damals erfolglos.

Die technische Lösung und der mögliche Nutzen einer Erfindung sind nicht hinreichend für einen erfolgreichen Innovationsprozess. Die Transformation einer technischen Errungenschaft in einen gesellschaftlichen Prozess, der zu einer positiven Bewertung bei Verbrauchern, Investoren und Politikern führt, ist eine Schwierigkeit, an der Innovationen häufig scheitern. Die erfolgreiche Bewältigung dieser Probleme ist ein wesentlicher Teil der Gesamtleistung von Thomas Edison bei der Einführung von Elektrolicht.

Edison stand wie auch andere Erfinder und Wissenschaftler bei Neuerungen vor Kommunikationsproblemen, da etliche mit den Neuerungen verbundene Begrifflichkeiten wie Dynamo, Sicherung, Gleichstrom oder Glühlampe weiten Teilen der Bevölkerung unbekannt waren und die meisten auch keine Vorstellung über das Wesen von Elektrizität hatten. Neben der Akzeptanz der Verbraucher benötigte er das Vertrauen von Investoren und Politikern. Letztere hätten mit Sicherheitsbedenken gegen die Verlegung unterirdischer Elektrizitätskabel die Elektrifizierung New Yorks um Jahre verzögern können. Schließlich mussten die Widerstände der Gasindustrie und deren Lobbytätigkeit in der Politik überwunden werden.

Er löste die Aufgabe unter anderem durch persönliche Kontakte zu Entscheidungsträgern und zur Presse, wobei er seine charismatische Persönlichkeit, sein Selbstbewusstsein, seine rhetorischen Fähigkeiten und seine Popularität für seine Ziele einsetzte. Im Unterschied zur Entwicklungsarbeit in "Menlo Park" musste Edison für die Umsetzung seines Elektrifizierungsprojektes mit einer großen Anzahl von Akteuren kommunizieren, sein Vorhaben in den Begriffswelten von Investoren, Baubehörden usw. darstellen und für die Kooperation aller Akteure sorgen.

Dem Problem der mangelnden Verständlichkeit der Neuerungen begegnete er durch nonverbale Kommunikation wie Show-Veranstaltungen mit Lichteffekten. Die in New York gegründete Gesellschaft wurde nicht „Elektrizitätsgesellschaft“, sondern „Beleuchtungsgesellschaft“ genannt "(Edison Illuminating Co.)". Das Kraftwerk wurde „Lichtwerk“ genannt, und Edison kommunizierte damit, man liefere Licht und nicht Strom; er baute sprachlich auf dem auf, was die Menschen kannten. Da die Verbraucher einer ihnen unbekannten physikalischen Einheit für elektrische Energie wie "Amperestunde" als Basis der Abrechnung misstraut hätten, erfolgte eine Umrechnung in Lampenbrennstunden; Edison führte dafür die Einheit Lh (zirka 0,8 Ah) ein. Auf das Design von Lampen wurde großer Wert gelegt, sodass diese dem Zeitgeschmack entsprechend von Beginn an als schön und die persönliche Umgebung aufwertend empfunden wurden. Die Gestaltung der Glühlampe selbst als Birne mit Schraubgewinde gilt noch immer als ästhetisch gelungen. Die Glühbirne wurde ein ikonographisches Symbol für „Idee“, „Erleuchtung“ usw. Besonders aufgeschlossen für die Neuerung waren die Betreiber von Theatern. Dadurch wurde elektrisches Licht an Brennpunkten des öffentlichen Lebens frühzeitig präsent und in Verbindung mit Kultur und Unterhaltung wahrgenommen.

Die Integration der Innovation in ein bestehendes kulturelles System von Begrifflichkeiten, Bedeutungen und Werten war wesentlich für den Erfolg. Die Transformation dieser Erfindung in einen alltäglichen Gebrauchsgegenstand auf den verschiedenen gesellschaftlichen Ebenen gelang dadurch besonders gut. Charles Bazerman, ein Hochschullehrer aus den USA, analysiert Aspekte davon in seinem Buch "The Languages of Edison’s Light".

Thomas Edison machte mehr als 2000 Erfindungen, von denen er 1093 in den USA patentieren ließ. Bis Oktober 1910 wurden im Ausland 1239 Patente angemeldet, davon 130 Patente in Deutschland. Die Erfindungen beziehen sich nicht nur auf innovative Konsumprodukte, sondern auch auf Maschinen und Verfahren für deren Produktion, Verfahrenstechnik, Investitionsgüter und andere Bereiche.

Die Rechte der wirtschaftlichen Nutzung seiner Patente verkaufte Edison meistens an Unternehmen, die ihm gehörten oder an denen er Teilhaber war wie z. B. der "Edison Electric Light Co." Die "Edison Electric Light Co." verkaufte dann ihrerseits eingeschränkte Rechte an Elektrifizierungsgesellschaften, Hersteller oder ausländische Patentverwerter weiter.

Die Menge der von Edison erarbeiteten Patente machte es für Wettbewerber im Elektromarkt in den 1880er Jahren immer schwerer, davon nicht betroffene Produkte zu entwickeln. Die raschen technologischen Veränderungen und der hohe wirtschaftliche Wert der Erfindungen infolge des erfolgreichen Innovationsprozesses führten zu einer verbreiteten Missachtung der Patente. Das zwang die jeweiligen wirtschaftlichen Eigentümer der an Edison erteilten Patente, hohe Geldmittel für die juristische Verteidigung ihres Eigentums aufzuwenden. Die Unternehmen von Edison waren zeitweise dazu finanziell nicht mehr in der Lage. Der Druck, die an Dritte verkauften exklusiven Nutzungsrechte auch durchzusetzen, lastete besonders auf der "Edison Electric Light Co." und der Person Thomas Edison.

Insbesondere finanziell starke Unternehmen konnten sich jahrelange Gerichtsstreitigkeiten über alle Instanzen leisten und im schwebenden Verfahren die Patente weiter verletzen. Der Nutzen der Teilhabe am Markt überstieg offenkundig die anfallenden Rechtskosten. Ferner konnten die Patentverletzer die Dauer der Verfahren für die Entwicklung von Umgehungstechniken nutzen. Nach Angaben der Edison-Biografen Dyer und Martin wurden allein in den USA zwischen 80 und 90 Prozesse um die Glühlampenpatente geführt und weitere mindestens 125 Patentprozesse um die mit der Glühlampe verbundenen Erfindungen in der elektrotechnischen Infrastruktur. 1889 musste Edison einen eigenen Unternehmensbereich für die Steuerung und Administration der Verfahren gründen.

Bisher ist kein Patentrechtsstreit bekannt, der zu einer gerichtlich angeordneten Annullierung eines vom US-Patentamt an Edison erteilten Patents führte. Die zahlreichen Anfechtungen waren ein Mittel im Wettbewerb um Marktanteile. Die notwendige Fusion seiner Unternehmen mit der "Thomson-Houston Co." führte Edison unter anderem auf hohe Kosten für Patentrechtsstreite und Ertragsminderungen aus Patentverletzungen zurück.

Der Patentprozess der "Edison Electric Light Co." gegen die "United States Electric Lighting Co." dauerte von 1885 bis 1892 und soll zirka 6.500 Seiten Akten umfassen. Er endete mit der Bestätigung der Edison-Glühlampen-Patente in allen Gerichtsinstanzen. Das Unternehmen "United States Electric Lighting Co." konnte kontinuierlich weiter produzieren, da man bei Prozessende eine neue Glühlampe entwickelt hatte, die kein Edison-Patent verletzte. Die "United States Electric Lighting Co." kam zwischenzeitlich in finanzielle Schwierigkeiten, konnte sich den Rechtsstreit und teure Neuentwicklungen jedoch weiter leisten, da der Eisenbahn-Industrielle George Westinghouse das Unternehmen 1888 aufkaufte. Die Auseinandersetzungen zwischen Thomas Alva Edison und George Westinghouse hatten hier eine Ursache.

In Verfahren der "Edison Electric Light Co." gegen die "Beacon Vacuum Pump and Electric Co.," die "Electric Manufacturing Co." und die "Columbia Incandescent Lamp Co." wurde behauptet, der aus Deutschland stammende Heinrich Göbel habe die Glühlampe schon vor Thomas Edison erfunden, siehe dortigen Abschnitt zu den Patentprozessen mit „Goebel-Defense“.

Robert Rosenberg und Paul Israel meinen, Thomas Edison habe die moderne Welt nicht erfunden, er sei aber an ihrer Entstehung beteiligt gewesen. Der Edison-Biograph Robert Conot beschreibt die Leistung Edisons mit der Formulierung, er habe die Tür aufgestoßen.

Die Folgen der von Edison in diesem Sinn ausgehenden Innovationen haben eine außerordentliche Dimension. Globale und zeitlich andauernde Veränderungen erfolgten durch die Elektrifizierung und Medien für Ton und Bild. Neue Industrien entstanden weltweit. Die Wahrnehmung der Welt veränderte sich durch bewegte Bilder; mit den Kinos entstanden neue kulturelle Zentren in den Städten. Das elektrische Licht veränderte das soziale Leben, welches sich in die Abendstunden verschob; auch Schichtarbeit nahm infolge des besseren Lichts zu. Die Elektrizitätsnetze ermöglichten eine Rationalisierung der Fertigungsprozesse und führten zu mehr Wohlstand. Die von Edison entwickelten Kohlenfadenlampen waren die ersten elektrischen Produkte, die eine weite Verbreitung in Privathaushalten fanden, und die den Weg für die heute umfassende Elektrifizierung der Privathaushalte bahnten. Die von ihm entwickelten wiederaufladbaren Batterien zogen eine weitere Elektrifizierungswelle insbesondere von Autos, Schiffen und Eisenbahnen nach sich. An der globalen Innovation Telefon mit veränderten Abläufen zum Beispiel im Handel war Edison mit Erfindungen beteiligt, die bis zur Einführung der digitalen Telefonie in den 1980er Jahren ein Industriestandard waren.

Die enormen Veränderungen macht ein Ereignis zum Tod von Edison deutlich. Der Präsident der USA Herbert Hoover wollte die Kraftwerke des Landes zu Ehren von Edison für kurze Zeit abschalten lassen. Das war 1931 jedoch schon nicht mehr möglich.

Während Thomas Edison zunächst den Einsatz des Phonographen im Büro als Hauptanwendung sah, hatte die "Pacific Phonograph Co." 1889 in San Francisco mit einem Münzphonographen für Unterhaltungszwecke großen Erfolg. Dieses Geschäftsmodell verbreitete sich rasch in den USA. Schon 1890 soll es zirka 1500 solcher Phonographen in Kneipen, Restaurants, Eisdielen usw. gegeben haben, an denen die Menschen an Hörschläuchen Musik gegen Entrichtung einer Gebühr konsumierten. In Deutschland kopierten Schausteller das Geschäftsmodell und konnten durch den großen Zulauf ihre Investitionen in kurzer Zeit amortisieren und hohe Gewinne erwirtschaften. Während die Betreiber zunächst teilweise noch eigene Walzen für den Musikgeschmack ihrer Kunden produzieren mussten, entstand parallel zum veränderten Musikkonsum eine neue Industrie zur Herstellung und Vermarktung von Tonträgern. Der Erfolg der Münzphonographen führte zur Konstruktion und Fertigung preiswerter Phonographen für den Heimbereich; Geräte und Tonträger waren um 1900 ein Massengeschäft.

Musik wurde durch den Phonographen örtlich und zeitlich unabhängig von Konzertereignissen verfügbar. Das hatte unter anderem eine vermehrte Beeinflussung von Musikern untereinander sowie eine beschleunigte Verbreitung einiger Musikstile zur Folge. Die Kneipen mit Phonographen in den USA verstärkten zum Beispiel die Verbreitung der Musik von Afroamerikanern, die teilweise zuvor nur im lokalen Bereich des Wirkens der jeweiligen Tonkünstler bekannt war.

Dieser Effekt wurde rasch ein globales Phänomen; Musik wurde gezielt für den Weltmarkt produziert. Einige Autoren sehen deswegen in der Erfindung des Phonographen den Beginn der kulturellen Globalisierung von Musik. Die kulturelle Bedeutung der Erfindung für die Musik wird als vergleichbar mit der Bedeutung der Erfindung des Buchdrucks für die Literatur bewertet. Beide Erfindungen haben zu einer neuen Dimension des Austauschs und der wechselseitigen Beeinflussung zwischen Kulturkreisen geführt.

In den üblichen Listen von Unternehmer-Milliardären erscheinen Zeitgenossen wie Henry Ford (Automobilbau), Jason Gould (Eigner von Eisenbahnlinien wie Union Pacific Railroad) oder John D. Rockefeller (Erdöl), nicht jedoch Thomas Edison. Sein Versuch, eine marktbeherrschende Stellung mit Glühlampen und Elektroinfrastruktur zu erlangen, war gescheitert. Bei Unternehmen, die in den 1880er Jahren gegründet wurden, war Edison häufig lediglich Teilhaber, auch wenn diese seinen Namen trugen. Partner, Mitarbeiter und Investoren bauten Fabriken auf, organisierten Elektrifizierungsprojekte und hielten Firmenanteile. Diese Firmen zahlten Lizenzgebühren für die Verwendung von Edison-Patenten, was eine Haupteinnahmequelle von Thomas Alva Edison war. Die meisten der in den 1880er Jahren gegründeten Elektrofirmen gingen in "General Electric" auf, wo er Aktionär war, ohne das Unternehmen zu beherrschen (zu seinem Aktienanteil an "General Electric" liegt keine Quelle vor). Sein späteres Unternehmen "Thomas Alva Edison Inc." blieb zu Lebzeiten von Thomas Edison im Unterschied dazu unter der Kontrolle der Familie. Die meisten Patente waren ausgelaufen und viele Erfindungen technisch überholt. W. Bernard Carlson, Professor für Technologie an der "University of Virginia", sieht insbesondere ein mangelndes Verständnis von Edison für die Softwareseite der von ihm begründeten Industrien mit der Folge, dass er noch zu Lebzeiten Geschäftsbereiche wie Tonträger und Filme wieder aufgeben musste. Mit den frühen Erfindungen zur Telegrafie, die er für jeweils ein paar tausend Dollar verkaufte, haben andere hohe Gewinne erwirtschaftet. An den Umsatz- und Gewinnzuwächsen anderer Branchen infolge der Elektroerfindungen, zum Beispiel der Kupferproduzenten, profitierten Edison-Unternehmen nicht.

Die Biografen Dyer und Martin schildern Edison als genialen Löser technischer Probleme, nicht aber als großen Unternehmensstrategen. Sie stellen sogar eine Sorglosigkeit und Nachlässigkeit seinerseits in geschäftlichen Angelegenheiten sowie ein leichtgläubiges Vertrauen in Vertragspartner fest. Eine Folge davon war, dass Edison keinen Cent an der Verwertung seiner Elektropatente in England und Deutschland verdiente. Der Biograf Paul Israel sieht einerseits ein hohes Interesse von Thomas Edison an der Entwicklung von Technologien und der Gründung neuer Industrien, andererseits aber ein Desinteresse am Tagesgeschäft einmal gegründeter Unternehmen und ein ihm anzulastendes Fehlmanagement bei der notwendigen Reaktion seiner Unternehmen auf veränderte Marktbedingungen und technologischen Wandel. Seine Firmen waren deswegen jeweils nur für kurze Zeit marktbeherrschend. Edison war als Geschäftsmann in der Bewertung von Paul Israel demzufolge „mäßig erfolgreich“.

Die 1929 beginnende Weltwirtschaftskrise fiel in Edisons letzte Lebensjahre und hat wahrscheinlich den Wert seines Vermögens zum Todeszeitpunkt enorm reduziert.

Einige Männer, die zeitweise Mitarbeiter von Thomas Edison waren, wurden später selbst Erfinder-Unternehmer:

Vielen Labormitarbeitern von Edison gelangen erfolgreiche Karrieren. Beispiele sind:

In Anerkennung der Leistungen von Thomas Edison feiern die USA seit 1983 an seinem Geburtstag den National Inventor’s Day. Am Hollywood Walk of Fame wurde ihm ein Stern gewidmet. Zahlreiche Einrichtungen und Straßen, auch in Deutschland, wurden nach ihm benannt.

Anfang November 1915 berichteten Zeitungen, darunter die "New York Times", über die bevorstehende Verleihung des Nobelpreises für Physik zu gleichen Teilen an Nikola Tesla und Thomas Edison. Tatsächlich wurde der Physik-Nobelpreis 1915 an William Henry und William Lawrence Bragg verliehen.

Der Historiker Keith Near sagte 1995, Thomas Edison sei von allen berühmten Personen diejenige, über die man am wenigsten wisse. Was die meisten über ihn zu wissen glaubten, seien nichts Anderes als Märchen. Seit der Lebenszeit von Thomas Edison wurden Darstellungen tradiert, die von Legenden durchsetzt sind, welche Journalisten für die Ausschmückung ihrer Artikel oder Thomas Edison und seine Mitarbeiter zum Zweck der Selbstdarstellung frei erfanden. Ferner sind eine Fülle von Irrtümern in die tradierten Darstellungen eingegangen.

An der wissenschaftlichen Aufbereitung der umfangreichen Quellen arbeitet ein Team von zirka zehn Historikern seit über 20 Jahren im Projekt "The Thomas Edison Papers" an der Rutgers University in New Jersey; ein Ende ist nicht abzusehen. Thomas Edison hat allein 3.500 Notizbücher hinterlassen mit Zeichnungen, die das Entstehen vollendeter Erfindungen dokumentieren, sowie Skizzen von nicht realisierten Ideen.

Publikationen aus der Zeit nach 1990, die unmittelbar oder mittelbar auf dem Quellenprojekt aufbauen, entsprechen dem Stand der Forschung.

Die wissenschaftliche technikgeschichtliche Quellenforschung und die Innovationsforschung führten zu einer veränderten Sicht auf Thomas Edison. Das von ihm selbst und von Medien gepflegte Image eines heldenhaften Genies wurde relativiert, die Wertigkeit der ihm zugeschriebenen Leistungen verschob sich von den Erfindungen zur Arbeitsmethodik und zum Innovationsprozess.

Ungeachtet der Leistungen wird die Person Thomas Edison auch kritisch beurteilt. Der Edison-Biograf Neil Baldwin meint, er sei ein Homo faber der extremsten Form gewesen, seine intensive Arbeit sei pathologisch und seine raffinierteste Erfindung sei seine Selbstwandlung zu einer Kulturikone gewesen.

Die Bezeichnung "Zauberer von Menlo Park" hat viele Untersuchungen angeregt. Magie oder ungewöhnliche kognitive Prozesse kann beispielsweise Joseph F. Buonanno in seiner Untersuchung nicht entdecken. Vielmehr habe Edison mit gewöhnlichem Denken außerordentliche Ergebnisse erzielt.

Zur Zeit des Nationalsozialismus wurde Thomas Edison in Deutschland mitunter als superreicher Amerikaner und Herrscher über "General Electric" dargestellt, der seinen Reichtum dem Diebstahl von Erfindungen von Deutschen verdanke. Von der Propaganda wurde ein scharfer Gegensatz zwischen dem egoistischen Gewinnstreben skrupelloser Amerikaner mit der Falschdarstellung von Thomas Edison als Stereotyp und arischen Idealcharakteren der nationalsozialistischen Ideologie konstruiert:

Die Propagierung eines deutschen Glühlampenerfinders erfolgte schon vor der Zeit des Nationalsozialismus ab 1923, zunächst aber noch ohne Schmälerung der Leistungen Edisons.

In der Zeit vor dem Ersten Weltkrieg wurden die technischen Innovationen auch in Deutschland mit Thomas Edison verbunden. 1889 nahm er am Treffen der Naturforscher in Heidelberg teil und war im Kreis der akademischen Wissenschaftler akzeptiert. Unter anderem führte er Gespräche mit Heinrich Hertz und Hermann Helmholtz; beide berichteten Verwandten in Briefen von dem Zusammentreffen. Werner von Siemens würdigte die epochale Leistung von Edison für die Verbreitung der Elektrizität und wies darauf hin, dass neben der Glühlampe und der Energieversorgung Edisons Entwicklung eines Verbrauchszählers von entscheidender Bedeutung für das Funktionieren des Geschäfts mit der Elektrizität sei.

Von der Popularität Edisons auch in Deutschland zu jener Zeit zeugt eine Umfrage der Berliner Illustrirte Zeitung zur Jahrhundertwende 1899/1900. Die zirka 6.000 teilnehmenden Leser wählten Thomas Edison zum größten Erfinder.




Die Internetseiten sind ebenso wie die unter Literatur angegebenen Buchreihe "The Papers of Thomas A. Edison" eine Publikation des gleichnamigen Forschungsprojektes. Die Seiten werden von "Rutgers, The State University of New Jersey" betrieben. In New Jersey wohnte Edison den größten Teil seines Lebens, und dort befanden sich seine Entwicklungseinrichtungen. An der Rutgers University befindet sich ein Archiv "IEEE History Center" des IEEE Institute of Electrical and Electronics Engineers. Dort werden Quellen zur Technikgeschichte der Elektrotechnik archiviert und der wissenschaftlichen Auswertung zugänglich gemacht. Das Projekt "The Edison Papers" speziell ist ein seit den 1980er Jahren andauerndes technikwissenschaftliches Großprojekt zur Aufbereitung und Auswertung von zirka 5 Millionen Dokumenten zu Thomas Edison, die sich teilweise auch in anderen Archiven befinden.

Einzelnachweise aus dieser Publikation des Forschungsprojektes "The Thomas Edison Papers":





</doc>
<doc id="13010" url="https://de.wikipedia.org/wiki?curid=13010" title="Elektrokardiogramm">
Elektrokardiogramm

Das Elektrokardiogramm (EKG) (zu , und ) ist die Aufzeichnung der Summe der elektrischen Aktivitäten aller Herzmuskelfasern mittels eines Elektrokardiografen. Das Elektrokardiogramm trägt im Deutschen auch die Bezeichnung "Herzspannungskurve", gelegentlich wird es auch "Herzschrift" genannt.

Jeder Kontraktion des Herzmuskels geht eine elektrische Erregung voraus, die im Normalfall vom Sinusknoten ausgeht. Über das herzeigene elektrische Leitungssystem aus spezialisierten Herzmuskelzellen läuft sie zu den übrigen Herzmuskelzellen. Diese elektrischen Spannungsänderungen am Herzen kann man an der Körperoberfläche messen und im Zeitverlauf aufzeichnen. Es ergibt sich ein immer wiederkehrendes Bild der elektrischen Herzaktion. Mit dem EKG lassen sich vielfältige Aussagen zu Eigenschaften und Gesundheit des Herzens treffen. Zu beachten ist, dass das Oberflächen-EKG nur die elektrische Aktivität des Herzmuskels anzeigt, nicht jedoch die tatsächliche Auswurfleistung widerspiegelt. Meist wird das EKG von zunehmend verlässlicheren Computerprogrammen ausgewertet, was jedoch die Beurteilung der Aufzeichnung auf Papier oder auf dem Bildschirm durch den Arzt nicht entbehrlich macht.

1843 erkannte Carlo Matteucci durch Experimente an Taubenherzen, dass die Herztätigkeit auf elektrischen Vorgängen beruht. 1882 leitete der Physiologe Augustus Desiré Waller an seinem Hund "Jimmy" das erste Mal ein EKG ab, indem er dessen vier Pfoten in leitfähige Natriumchloridlösung tauchte. 1887 konnte er erstmals Herzströme mit Hilfe eines Kapillarelektrometers aufzeichnen.

Die Instrumente wurden 1903 wesentlich von Willem Einthoven verbessert, der das EKG, aufbauend auf seinem ab 1895 entwickelten Saitengalvanometer, zu einem brauchbaren Diagnoseverfahren entwickelte und in der Klinik einführte. Die von ihm eingeführte Terminologie wird noch heute verwendet.
Er wollte zunächst auf eine einzige Ableitung standardisieren, bei der der Patient beide Arme in getrennte Lösungen taucht (Einthoven I). Da das nicht ausreichte, kamen die weiteren Extremitätenableitungen Einthoven II (rechter Arm – linkes Bein) und III (linker Arm - linkes Bein) sowie später die Wilson-Ableitungen an der Brustwand (nach Frank Norman Wilson, 1934) und die Goldberger-Ableitungen (nach Emanuel Goldberger, 1942) hinzu, welche unten erläutert werden.

Das EKG ist ein schmerzloses, nicht eingreifendes "(nicht-invasives)," jederzeit wiederholbares und fast überall durchführbares Untersuchungsverfahren.

Aus dem EKG können Herzfrequenz, Herzrhythmus und der Lagetyp ("elektrische Herzachse", vgl. Cabrerakreis) bestimmt und die elektrische Aktivität von Herzvorhöfen und Herzkammern abgelesen werden. Für die Diagnostik von Herzrhythmusstörungen wie Extraschlägen "(Extrasystolen)" und Störungen der Erregungsleitung und -ausbreitung (z. B. Schenkelblock und AV-Block) ist das EKG ebenso unverzichtbar wie zur Erkennung einer Myokardischämie oder eines Herzinfarktes. Störungen der Erregungsrückbildung "(Repolarisation)" können zu sogenannten Kammerendteilveränderungen (Veränderungen der ST-Strecke oder der T-Welle) führen. Die Aktivität eines Herzschrittmachers stellt sich als sehr schmaler, senkrechter Strich "(Spike)" dar.

Das EKG kann auch Hinweise auf eine Verdickung der Herzwand (Hypertrophie des Myokards), eine abnorme Belastung des rechten oder linken Herzens, Entzündungen von Herzbeutel (Perikarditis) oder Herzmuskel (Myokarditis) sowie Elektrolytstörungen und unerwünschte Arzneimittelwirkungen liefern.

Bezüglich der meisten Diagnosen liefert das EKG nur "Hinweise" und darf nicht unabhängig vom klinischen Bild beurteilt werden (z. B. Herzinfarkt, Hypertrophiezeichen, Myokarditis). Lediglich bei Störungen des Herzrhythmus oder der Erregungsleitung kann man aus dem EKG allein meist schon eine klare Diagnose stellen.

Herzmuskelzellen weisen im Ruhezustand (wie alle Zellen) ein negatives Membranpotential auf, d. h. die Außenseite der Membran ist positiv geladen, während die Innenseite negativ geladen ist. Bei elektrisch erregten Zellen verhält es sich umgekehrt, hier ist der Extrazellularraum negativ geladen. Das EKG misst Spannungen an der Körperoberfläche, die von der Ladungsverteilung im Extrazellularraum herrühren; intrazelluläre Ladungen werden nicht erfasst. Eine extrazelluläre Spannungsmessung zwischen zwei Punkten über der Plasmamembran einer Herzmuskelzelle würde nur dann eine elektrische Spannung ungleich null ergeben, wenn an genau einer der beiden Elektroden die Membran depolarisiert ist, denn zwischen positiv und positiv oder negativ und negativ besteht keine Potentialdifferenz.

Zur Vereinfachung der mathematischen Beschreibung soll die Ladungsverteilung in diesem kleinen Teil des Herzmuskels zum elektrischen Dipol idealisiert werden. Dabei wird die gesamte negative Ladung gedanklich auf einen Punkt am erregten Membranabschnitt konzentriert, während die gesamte positive Ladung in gleicher Weise dem nicht erregten Abschnitt zugeschrieben wird. Die Strecke Vektor "d" von der negativen zur positiven Ladung multipliziert mit der Ladung "q" ist dann gleich dem elektrischen Dipolmoment Vektor "p":

Für das elektrische Potential im Feld eines Dipols gilt in Abständen "r", die den Abstand der Ladungen bei weitem übersteigen, die Gleichung

Zwischen den Punkten A und B, die sich im gleichen Abstand "r" von Zentrum des Dipols befinden (die Vektoren zu den beiden Punkten können sich trotzdem unterscheiden), besteht demnach die Spannung

Die Bildung des Skalarproduktes
kann dabei als Projektion des Vektors "p" auf die Gerade durch A und B verstanden werden. Da alle weiteren Größen zeitlich konstant sind, lautet die entscheidende Erkenntnis zum Verständnis des EKG, dass die gemessene Spannung zum projizierten Anteil des Dipolmoments proportional ist:

Bei Betrachtung des gesamten Herzens müssen freilich viele solcher Dipolmomente berücksichtigt werden, die beschriebenen Zusammenhänge gelten jedoch weiterhin, wenn man "p" durch die Summe aller Dipolmomente "P" ersetzt. Anstelle der Punkte A und B treten in der Praxis des EKG Ableitungen, deren korrespondierende Vektoren formula_6 im Cabrerakreis abgelesen werden können. Zur Ableitung I, die zwischen dem rechten und linken Arm gemessen wird, gehört beispielsweise ein Vektor, der horizontal nach links zeigt.

Umgekehrt kann auch aus gemessenen Spannungen der Vektor des summierten Dipolmoments errechnet werden. Dazu sind mindestens drei Ableitungen notwendig, deren Vektoren linear unabhängig sind, also nicht alle in einer Ebene liegen. Die sich ergebende Darstellung des EKG durch einen im zeitlichen Verlauf im 3D-Raum rotierenden und in der Länge veränderlichen Pfeil heißt Vektor-EKG.

Das normale Ruhe-EKG wird meist im Liegen angefertigt. Da es nur einige Sekunden dauert, kann man es auch bei Notfällen gut durchführen. Es ist als kardiologische Basisuntersuchung die Variante mit der größten Aussagekraft. Nur zeitweise auftretende Herzrhythmusstörungen (z. B. Extrasystolen, Salven, nächtliche Pausen) werden eventuell nicht erfasst.

Zur Aufzeichnung des Langzeit-EKGs (syn.: Holter Monitor oder kurz "Holter"; benannt nach seinem Erfinder Norman Jefferis Holter) trägt der Patient meist über 24, manchmal auch über 48 oder 72 Stunden ein tragbares EKG-Gerät mit sich. Es werden kontinuierlich meist zwei oder drei Kanäle abgeleitet. Es wird in erster Linie zur Rhythmusdiagnostik verwendet und beantwortet die Fragen, ob durchgehend ein Sinusrhythmus vorliegt und dieser der körperlichen Belastung entsprechend variabel ist, ob Pausen oder Bradykardien vorkommen (z. B. passagere Sinusbradykardie bei Sick-Sinus-Syndrom, AV-Blockierungen, bradykardes Vorhofflimmern), oder kann dem Nachweis bösartiger Herzrhythmusstörungen (z. B. ventrikuläre Salven oder ventrikuläre Tachykardien) dienen. - Davon abzugrenzen ist der Event-Recorder, welcher vom Patienten während bestimmter Ereignisse (englisch: event) ein- und ausgeschaltet wird. Er speichert die Daten. Wie beim Holter werden die Elektroden für mehrere Tage auf die Haut geklebt; es gibt auch implantierbare Ereignisrecorder, welche mehrere Jahre belassen und über Magnetspulen ausgelesen werden können.

Bei der Ergometrie wird üblicherweise entsprechend WHO-Schema der Patient definiert belastet. Dies wird verwendet, um das maximale Belastungsniveau sowie den Anstieg von Blutdruck und Herzfrequenz unter Belastung zu bestimmen. Des Weiteren können belastungsinduzierte Herzrhythmusstörungen sowie Erregungsrückbildungsstörungen provoziert und dokumentiert werden. Abgebrochen werden sollte das Belastungs-EKG, wenn der Blutdruck zu hoch ansteigt, bei fehlendem Blutdruckanstieg und Blutdruckabfall, bei Angina pectoris, bei allgemeiner Erschöpfung (Schwindel, Atemnot, Schmerzen in den Beinen etc.) und wenn der Maximalpuls erreicht ist (Faustregel zur Berechnung: [220 minus Lebensalter in Jahren] pro Minute). Blutdruck und Herzfrequenz sollten auch noch während einer Erholungsphase gemessen werden.

Das fetale Elektrokardiogramm ist ein selten in der Pränataldiagnostik verwendetes Verfahren zur vorgeburtlichen Analyse der kindlichen Herzaktionen. Hierbei kann nach Blasensprung das EKG direkt via spezieller Elektroden von der Kopfhaut des Fötus oder indirekt über die Bauchdecke oder das Rektum der Schwangeren abgeleitet werden.

Eine Telemetrie (kurz Tele) ist eine Überwachungsmöglichkeit im Krankenhaus. Ähnlich dem Langzeit-EKG trägt der gehfähige Patient ein mobiles Gerät bei sich, welches das EKG jedoch nicht aufzeichnet, sondern via Funk an einen Computer sendet. Die Daten werden dort kontinuierlich angezeigt und automatisch analysiert. Entsprechend einstellbarer Vorgaben (Alarmgrenzen) alarmiert der Computer akustisch und visuell das Personal. - Davon abzugrenzen ist zum Beispiel die Schwimmtelemetrie (auch Wassertelemetrie genannt). Hier werden die Herzaktionen entweder wie bei dem Holter Monitor diskontinuierlich gespeichert oder wie bei der Telemetrie kontinuierlich an eine Zentraleinheit gesendet.

Ähnlich der Telemetrie überwacht ein Monitor einen liegenden Patienten im Krankenhaus. Im Gegensatz zur Tele registriert dieses Gerät jedoch nicht nur das EKG, sondern teilweise auch eine Vielzahl anderer Parameter (Blutdruck, Sauerstoffsättigung, Körpertemperatur u. v. m.). Der Vorgang wird Monitoring genannt.

Der implantierbare Herzmonitor (engl. "insertable cardiac monitor" oder "implantable loop recorder", ILR) ist ein EKG-Gerät, das den Herzrhythmus bis zu drei Jahre lang 24 Stunden täglich überwacht und Unregelmäßigkeiten aufzeichnet. Das gespeicherte EKG kann Aufschluss darüber geben, ob Ohnmachtsanfälle eine kardiale Ursache haben. Der Herzmonitor ist so groß wie ein USB-Stick und wird bei einem Routineeingriff, unter örtlicher Betäubung, über einen kleinen Schnitt unter die Haut geschoben.

Im Rahmen einer elektrophysiologischen Untersuchung (abgekürzt EPU) wird ein intrakardiales EKG über Elektroden abgeleitet, die meist über einen venösen Zugang (Leiste oder Arm) zum Herzen vorgeschoben werden. Es wird verwendet, um Herzrhythmusstörungen genauer zu differenzieren. Der Untersucher ist hierdurch in der Lage, ein präzises elektrisches Bild des Herzens zu erstellen. So entsteht gewissermaßen eine Landkarte (englisch: map) des Herzens.

Gefilterte bipolare transösophageale elektrokardiograpische Ableitungen aus der Höhe der linken Herzkammer lassen sich im Rahmen einer kardialen Resynchronisationstherapie zur Darstellung interventrikulärer Leitungsverzögerungen nutzen. Transösophageale Ableitungen aus Höhe des mittleren linken Vorhofs eignen sich vorteilhaft für die Differentialdiagnose von Rhythmusstörungen. Bei Trägern vorhofbeteiligter Schrittmacher und Defibrillatoren gelingt mit ihnen die Bestimmung interatrialer Leitungszeiten, welche als Grundlage für eine individuelle Optimierung hämodynamischer Schrittmacherparameter (AV- Intervalle) genutzt werden können.

Elektrische Spannungen werden immer zwischen zwei Punkten gemessen, die in der Medizin "Ableitungspunkte" genannt werden. Auf diese Punkte werden Elektroden auf die Haut geklebt, die mit dem EKG-Gerät über elektrische Messkabel verbunden sind. Die gemessenen elektrischen Potentiale werden "Ableitungen" genannt.

Man unterscheidet bipolare und unipolare Ableitungen:

In der Kardiologie gibt es verschiedene Vereinbarungen, an welchen Stellen am Körper man die zeitlich variablen Spannungen des Herzens ableiten soll.


Diese Vielzahl verschiedener Ableitungen ist nötig, um Ströme in verschiedenen Richtungen und damit Veränderungen in verschiedenen Bereichen des Herzmuskels zu erfassen. Dies dient zur Lokalisierung von Infarkten, Leitungsblöcken und Lagetypen (s. u.). Dabei zeigen die Brustwandableitungen V2–V6 auf die Vorderwand, I und aVL auf die Seitenwand der linken Herzkammer und II, III, aVF auf ihre Hinterwand. Die rechte Herzkammer ist allgemein nur selten von Bedeutung. Neben den Standardableitungen gibt es noch weitere zusätzliche Ableitungen, zum Beispiel um eine Rechtsherzhypertrophie oder einen Situs inversus mit einer Dextrokardie zu diagnostizieren.

Auch unter den Bedingungen der präklinischen Notfallmedizin kommt es auf eine richtige Elektrodenposition an. Aus verschiedenen Gründen können die Extremitätenelektroden nicht ganz distal, sondern im proximalen Bereich der Extremitäten angebracht werden. Zum Aufsuchen der Brustwand-Ableitungen empfiehlt sich das Tasten des Sternalwinkels (Angulus sterni oder Ludovici, zwischen dem Handgriff und dem Körper des Brustbeins), in dessen Höhe die 2. Rippe ansetzt. Unterhalb befindet sich also der 2. Interkostalraum.






Das EKG wird auf Millimeterpapier oder elektronisch aufgezeichnet. Dabei betragen die (horizontale) Schreibgeschwindigkeit meist 25 mm/s oder 50 mm/s und die (vertikale) Auslenkung 10 mm/mV. Ein Millimeter entspricht also in Schreibrichtung 0,02 s und in der Höhe 0,1 mV. Vor der Aufzeichnung geben die meisten Geräte eine Eichzacke aus, die einem Ausschlag von 1 mV über 100 ms entspricht. Bei korrektem Normalbetrieb ist diese Eichzacke also 1 cm hoch und 5 mm breit; bei einer Schreibgeschwindigkeit von 25 mm/s hat sie dagegen eine Breite von nur 2,5 mm. Die Eichzacke dient also als Referenz für die folgende Ableitung und erlaubt eine Kontrolle der Gerätefunktion (Kalibrierung und Justierung). Bei älteren manuell bedienbaren Geräten wurden die Eichzacken durch Drücken einer Taste und Anlegen einer Spannung von 1 mV generiert, deren Dauer hatte keine Bedeutung. Bei diesen älteren Geräten wurde manchmal durch wiederholtes Drücken bei der EKG-Registrierung angezeigt, welche Ableitung geschrieben wurde, die aufgezeichneten Kurven wurden erst nachträglich beschriftet.

Bezeichnung und Bedeutung der einzelnen Abschnitte:

Die P-Welle entspricht der Vorhoferregung. Sie entsteht üblicherweise durch die Reizbildung im Sinusknoten. Der elektrische Reiz breitet sich vom hohen rechten Vorhof in die Richtung des AV-Knotens aus.
Normal-Konfiguration:
Entsteht die elektrische Erregung nicht im Bereich des Sinusknotens, sondern beispielsweise verursacht durch einen Extraschlag im Vorhofbereich (supraventrikuläre Extrasystole), so kann die Konfiguration von der obigen deutlich abweichen. Meist findet sich dann auch eine atypische PQ-Zeit.

→ " Hauptartikel: QRS-Komplex."


Die T-Welle entspricht der Erregungsrückbildung der Kammern. Da sie aufgrund unterschiedlicher Leitungsgeschwindigkeiten in verschiedenen Ventrikelregionen von der Herzspitze zur Herzbasis aus verläuft (und damit in umgekehrter Richtung der Kammererregung), erzeugt sie einen positiven Ausschlag im EKG.
Bei Kindern (außer Neugeborenen) ist sie gewöhnlich in den Brustwandableitungen V1, V2 und V3 - sowie bei 25 % der Individuen in Ableitung III - negativ. 

Bei einer Hypokaliämie kommt es zur Abflachung der T-Wellen, bei der Hyperkaliämie werden sie hoch und spitz.





Das EKG enthält den Namen des Untersuchten mit Datum und Uhrzeit. Meist sind auch die Werte der Herzfrequenz und der oben bezeichneten Strecken oder computererstellte Diagnosen aufgedruckt.

Die Diagnostik eines EKGs sollte entsprechend einem festen Schema erfolgen. Hilfreich bei der Interpretation ist ein EKG-Lineal.


Die Überleitung zwischen Vorhof und Kammer



Die Nulllinie wird auch als dauerhafte "isoelektrische Linie" bezeichnet. Sie tritt auf, wenn keine Potentialdifferenz zwischen zwei Ableitpunkten anliegt (keine elektrische Aktivität des Herzens) und daher auch weder ein positiver noch ein negativer Ausschlag erkennbar ist. Sie ist typisch für eine Asystolie.

Mit dem Lagetyp bezeichnet man die Verlaufsrichtung der elektrischen Erregungsausbreitung von der Herzbasis zur Herzspitze relativ zur Körperachse (elektrische Herzachse). Er kann einerseits etwas aussagen über die anatomische Stellung des Herzens im Brustkorb, andererseits über asymmetrische Verdickungen des Herzmuskels bei einer chronischen Belastung oder auch als Zeichen dienen für eine Größenzunahme bei einer akuten Belastung (beispielsweise Rechtslagetyp bei einer akuten Lungenembolie).

Physiologisch ist ein Steil- bis Linkstyp, wobei bei Neugeborenen ein Steiltyp vorherrscht. Mit zunehmendem Alter dreht sich die elektrische Herzachse nach links, sodass beim alten Menschen meist ein Linkstyp besteht.

Die Bestimmung des Lagetyps erfolgt am einfachsten und schnellsten, indem man die Extremitätenableitungen I und aVF betrachtet. Sind beide positiv, können nur physiologische Lagetypen in Betracht kommen und nur in bestimmten Fragestellungen ist es jetzt noch relevant, diese exakt voneinander zu unterscheiden, was man aber dennoch in jedem Fall in Ruhe tut. Für die Notfalldiagnostik jedoch ist dies ein sehr hilfreicher Ansatz für die zügig zu erledigende Bewertung eines EKGs. Sind I oder aVF oder gar beide negativ, kann entweder das EKG verpolt sein, d. h. falsch angelegt, oder es sind mehr oder weniger schwerwiegende Pathologien in Betracht zu ziehen und das nachfolgende Schema für die exakte Lagetypbestimmung anzuwenden.

Mit Hilfe des Cabrerakreises, welcher üblicherweise auf jedem EKG-Lineal aufgetragen ist, als Bild vor Augen sucht man in den Extremitätenableitungen (Einthoven und Goldberger) zunächst die Ableitung mit der größten R-Zacke. Sei dies beispielsweise die Ableitung aVF, so vergleicht man diese mit den R-Zacken der auf dem Cabrerakreis benachbarten Ableitungen, in diesem Falle II und III. Ist Ableitung II größer als III, so liegt ein Steiltyp vor, umgekehrt ein Rechtstyp. Alternativ sucht man sich die senkrechte Linie zu aVF, also die I, auf, und schaut, ob diese positiv oder negativ ist, wenn diese positiv ist dann handelt es sich wieder um einen Steiltyp, ansonsten um einen Rechtstyp. Um die Ableitung aVR in die Lagetypbestimmung mit einbinden zu können, wird sie an der isoelektrischen Linie gespiegelt. Manche EKGs zeichnen die so entstehende Ableitung −aVR eigenständig auf, meist misst man jedoch lediglich die R-Zacke.

Ein ganz besonderer, aber nicht zwingend pathologischer Fall liegt beim sogenannten Sagittaltyp vor, der besteht, wenn sich die elektrische Herzachse aus der normalen Frontalebene herausbewegt und beginnt, senkrecht dazu zu stehen. Dies macht sich durch S- oder Q-Zacken in I, II und/oder III bemerkbar, z. B. beim sogenannten S1Q3-Typ oder beim S1S2S3-Typ. Die weiter oben skizzierte Methode würde auch einen klassischen Lagetyp in diesem Fall generieren, dieser wäre aber objektiv falsch, daher ist auf solche Veränderungen besonders im Verdachtsrahmen einer möglichen Lungenembolie oder bei einer Rechtsherzbelastung zu achten.

Ein Vorhofflimmern erkennt man an einer absoluten Arrhythmie der Kammer, die QRS-Komplexe folgen in zufällig wechselnden Zeitabständen aufeinander. Die P-Welle ist nicht vorhanden, stattdessen sieht man häufig ein leichtes Zittern der Grundlinie, das sich gelegentlich vom normalen, messbedingten Zittern der Kurve wenig unterscheidet. Bei lang bestehendem Vorhofflimmern kann die isoelektrische Linie auch glatt verlaufen.

Beim typischen Vorhofflattern ist in den Ableitungen II, III und aVF meist ein sehr charakteristisches Sägezahnmuster der Grundlinie erkennbar.

Einen AV-Block I° erkennt man an einer Verlängerung des PQ-Intervalls auf über 0,2 s.

Bei einem AV-Block II° Typ 1 (auch Wenckebach oder Mobitz I genannt) wird das PQ-Intervall von Mal zu Mal länger, dann fällt ein QRS-Komplex ganz aus und es folgt eine weitere P-Welle, diesmal mit QRS-Komplex. Beim Grad II Typ 2 (auch Mobitz oder Mobitz II genannt) (benannt nach dem Kardiologen Woldemar Mobitz) fällt plötzlich ein QRS-Komplex aus, ohne dass zuvor das PQ-Intervall länger geworden ist. Fällt jeder zweite QRS-Komplex aus, kann sowohl ein Wenckebach- als auch ein Mobitz-Block vorliegen.

Beim AV-Block III° wird die Vorhoferregung (P-Welle) nicht auf die Herzkammer übergeleitet. Falls existent springt ein sekundärer Schrittmacher im Bereich der Herzkammer ein. Dieser ventrikuläre Ersatzrhythmus hat nur eine Frequenz um 40 Schläge pro Minute oder langsamer. Entsprechend niedrig ist auch der Puls des Patienten. Im EKG finden sich regelmäßige P-Wellen und, hiervon unabhängig und deutlich langsamer, relativ breite Kammerkomplexe.

Da ein AV-Block II° Mobitz in einen AV-Block III° degenerieren kann, ist hierbei eventuell eine Versorgung mit einem Herzschrittmacher notwendig. Dabei hängt es aber von weiteren Faktoren, wie dem Auftreten von Symptomen wie Schwindel etc. ab, ob tatsächlich ein Herzschrittmacher eingesetzt werden sollte. Vermehrt werden bei Ausdauersportathleten AV-Blockierungen I. und II. Grades (letztere sehr vereinzelt, oft nachts auftretend) diagnostiziert, die mit Veränderungen des vegetativen Nervensystems zusammenhängen und lediglich regelmäßige Verlaufskontrollen nötig machen, dabei aber keine Einschränkungen der sportlichen Aktivität nach sich ziehen.

AV-Blöcke III. Grades machen das Einsetzen eines Schrittmachers unbedingt erforderlich.

Von einem kompletten Schenkelblock spricht man bei einer QRS-Komplexdauer > 0,12 s, inkomplett ist der Block bei einer QRS-Breite von 0,1 bis 0,12 s. Es können, abhängig vom blockierten Tawara-Schenkel, Rechtsschenkelblock, Linksschenkelblock sowie linksanteriorer und
linksposteriorer Hemiblock unterschieden werden.

Besteht eine zusätzliche elektrische Verbindung zwischen Vorhöfen und Kammern neben dem AV-Knoten, so kann es zu einer vorzeitigen Erregung der Herzkammer kommen. Im EKG findet sich eine kleine positive Welle (rampenförmiger Aufstrich) direkt vor dem QRS-Komplex, die sogenannte Delta-Welle. Ein Beispiel für eine "AV-Reentrytachykardie mit Präexzitation" ist das WPW-Syndrom.

EKG-Zeichen der Erregungsrückbildung sind die ST-Strecke und die T-Welle sowie, falls vorhanden, die U-Welle.
Ein ausgedehnter (transmuraler) akuter Herzinfarkt äußert sich meist in einer horizontalen ST-Strecken-Hebung (ST-elevation myocardial infarction, ein Myokardinfarkt, mit ST-Strecken-Hebungen). Daneben sind auch Herzinfarkte ohne ST-Hebung möglich, so genannte nicht-transmurale Infarkte (oder Nicht-ST-Hebungsinfarkt, NSTEMI).

Mit Hilfe des EKGs kann eine Lokalisation des Infarktes vorgenommen werden. Die Ableitungen I, aVL, V1–5 weisen auf die Vorderseitenwand, II, III und avF auf die inferiore Wand hin. In den jeweils nicht betroffenen Ableitungen erscheint eine korrespondierende ST-Senkung. Daneben kann auch der zeitliche Verlauf des Infarktes bestimmt werden, der in verschiedenen Stadien typische Veränderungen zeigt.

Eine Hypercalciämie äußert sich in einer verkürzten, eine Hypocalciämie in einer verlängerten QT-Strecke.

Eine Hyperkaliämie kann zu (zeltförmig) erhöhten T-Wellen und zur Verkürzung der QT-Strecke führen. Eine Hypokaliämie kann zu einer ST-Strecken-Senkung mit Auftreten einer U-Welle, zu einer QRS-Verbreiterung, zu einer Abflachung der T-Welle und zu einer Verlängerung der QT-Strecke führen (cave: "Torsade de pointes").

Eine ganze Reihe von Medikamenten können die Erregungsrückbildung verändern. Häufig sind Verlängerungen der QT-Dauer (z. B. Amiodaron) mit der Gefahr gefährlicher Rhythmusstörungen. Digitalis bewirkt harmlose muldenförmige ST-Strecken-Senkungen.

Bei einer frequenzkorrigierten Verlängerung des QT-Intervalls, dem QT-Syndrom oder Long-QT-Syndrom, kann es zu bedrohlichen Herzrhythmusstörungen kommen. Deutlich seltener ist das ebenfalls mit bösartigen Rhythmusstörungen einhergehende Short-QT-Syndrom.

Die Vorhöfe werden gleichmäßig und annähernd radiär über die Arbeitsmuskulatur erregt, ohne spezifisches Reizleitungssystem wie in den Herzkammern. Entscheidend ist der Abstand vom Sinusknoten: Der erste Teil der P-Welle spiegelt die Aktivität des rechten, der zweite Teil die des linken Vorhofs.
Domänen des Echokardiogramms (USKG) sind die Messung der Vorhofdilatation sowie die Diagnose von Raumforderungen, Klappen- und Septumdefekten. Im Gegensatz zum Elektroatriogramm (Vorhof-EKG) können für das USKG keine Grenzwerte der Vorhofhypertrophie benannt werden, ebenso nicht für die Volumetrie des rechten Vorhofs.

Zeichen der Vergrößerung der Ventrikel ist der Sokolow-Lyon-Index. Weniger gebräuchlich sind der Lewis-Index (linksventrikuläre) und der Whitebock-Index (rechtsventrikuläre Hypertrophie).




</doc>
<doc id="13011" url="https://de.wikipedia.org/wiki?curid=13011" title="Innviertel">
Innviertel

Das Innviertel, amtlich Innkreis, ist das nordwestlichste der Viertel Oberösterreichs und umfasst die Bezirke Braunau am Inn, Ried im Innkreis und Schärding.

Seit der Bildung der politischen Bezirke 1868 haben die Viertel in Oberösterreich keine rechtliche Grundlage mehr und sind reine Landschaftsbezeichnungen. Dabei wurde die ältere Kreiseinteilung ersetzt, die sich noch an den alten Vierteln orientierte.

Anders als das übrige Oberösterreich war das Gebiet zum überwiegenden Teil bis zum Jahr 1779 (erzwungene Abtretung im Frieden von Teschen) ein Teil Bayerns. Es ist eine fruchtbare, dichtbesiedelte, flache bis hügelige Landschaft des Alpenvorlands und liegt zwischen Salzach, Inn, Donau und Hausruck. Die Fläche des Innviertels beträgt etwa 2250 km², die Einwohnerzahl knapp 218.000.

Die größte Stadt des Innviertels ist nach Fläche und Einwohnern Braunau am Inn mit Einwohnern, gefolgt von Ried im Innkreis (). Nicht minder bekannt und wegen der barocken Innenstadt ein touristisches Zentrum ist die Stadt Schärding mit () Einwohnern (Einwohnerstand jeweils ).

Die Bezeichnung "Innviertel" für diese Region ist vergleichsweise jung, davor war die Bezeichnung Innbaiern gebräuchlich. Sie wurde erst nach der Angliederung an Österreich im Jahre 1779 von der österreichischen Verwaltung erfunden, die zu dieser Zeit das Erzherzogtum ob der Enns (das heutige Oberösterreich) in vier Viertel unterteilt hatte. Entsprechend dieser Verwaltungsgliederung wurde das neu erworbene Gebiet anfangs als das "Fünfte Viertel", nach der Zusammenlegung von Mühlviertel und Machlandviertel schließlich als "Innviertel" bezeichnet.

Siehe auch die Abschnitte zur Geschichte bei Braunau am Inn, Ried im Innkreis und Schärding.

Siehe dazu auch

Das Innviertel mit den Herzogshöfen Ranshofen und Mattighofen gehörte seit dem 6. Jahrhundert zum "Mattiggau" im bayerischen Stammesherzogtum, der nördliche Teil zum "Rottachgau".

Das Innviertel wurde einst "Innbaiern" genannt, und bis heute sind viele Merkmale der langen Zugehörigkeit des Gebietes zu Bayern erhalten geblieben. Es war ab 1507 ein Teil des Rentamtes Burghausen mit den Gerichten Wildshut (mit dem Bezirksgericht Mattighofen zusammengelegt), Braunau, Mauerkirchen, Friedburg, Schärding und Ried.

Bis zum Bayerischen Erbfolgekrieg war das Gebiet des späteren Innviertels als "Innbaiern" ein Teil von Bayern. Auslöser dieses Krieges war der Tod des kinderlosen bayerischen Kurfürsten Maximilian III. Joseph (1745 bis 1777). Mit seinem Tod starb die bayerische Linie der Wittelsbacher aus. Eine Reihe von mitteleuropäischen Mächten erhob Anspruch auf Teile des Erbes, darunter und zuvörderst Österreich mit Forderungen nach der Abtretung Niederbayerns und der Oberpfalz. Mit der Ratifizierung des Friedens von Teschen, der den Bayerischen Erbfolgekrieg beendete, kam das Innviertel 1779 zu Oberösterreich. 

Aufgrund des Friedens von Schönbrunn 1809 ergriff Bayern 1810 noch einmal Besitz vom Innviertel. Es wurde zusammen mit Teilen des Hausruckviertels dem bayerischen Unterdonaukreis zugewiesen. 1811 wurden auch die in diesem Gebiet liegenden Pfarreien von der Diözese Linz abgetrennt und dem Bistum Passau zugewiesen. Erst im Münchener Vertrag trat das Königreich Bayern das Innviertel mit anderen Gebieten zum 1. Mai 1816 endgültig an das Kaisertum Österreich ab. Kirchlich übernahm auch das Bistum Linz am 1. Juli 1816 die entsprechenden Gebiete wieder vom Bistum Passau.
Auf politischer Ebene wurde durch eine Reihe von Maßnahmen (Treueeid der landesfürstlich-bayerischen Beamten, Huldigung des Innviertler Adels gegenüber dem neuen Landesherrn) die Eingliederung des neuen Landesteils in das Land ob der Enns vollzogen. Schwieriger war die verwaltungsmäßige Eingliederung, welche durch eine eigene „Landes-Einrichtungskommission“ unter Leitung des Freiherrn Franz Xaver Pockensteiner von Wolffenbach vorgenommen wurde, da das Innviertel bis dahin keine verwaltungsmäßige Einheit war.

Auch der bayerischen Bevölkerung fiel die Umstellung wegen der verwandtschaftlichen, kulturellen, rechtlichen und wirtschaftlichen Bindungen über die neue Grenze hinweg nicht leicht. Als die Reformen Kaiser Josefs II. durch Einführung einer neuen Kirchen- und Schulordnung verstärkt wurden, kam es 1795 bei geheimen Zusammenkünften zu Unterschriftensammlungen der Bevölkerung in der Pfarre St. Georgen. Auch die höheren Getränkesteuern, durch die Brauereien zum Zusperren gezwungen wurden, erregten den Unmut der Bevölkerung.

Die österreichische Führung begann sofort nach der Einverleibung des Innviertels damit, durch Entsendung von Lehrern aus der Hauptstadt den ehemaligen Innbaiern den österreichischen Dialekt zu vermitteln – ein Vorhaben, das bei der Landbevölkerung auf wenig Gegenliebe stieß. Trotz einer tendenziellen Annäherung an die österreichische Umgangssprache, die vor allem in der Übernahme des österreichischen Standardvokabulars bestand, blieben mundartliche Besonderheiten des Westmittelbairischen, die vor allem in einer Vielzahl regionaltypischer Vokalisierungsmerkmale (z. B. das Wort Milch, im Innviertel als Milli oder Muich bezeichnet, ist im Rest Österreichs größtenteils als Müch bekannt) bestehen, bis heute erhalten (vergleiche dazu Bairische Sprache). Sie gehen im Westen kontinuierlich in die niederbayerischen Dialekte über. Seither ist auch der Name "Innviertel" in Angleichung an die anderen oberösterreichischen "Viertel" in Gebrauch. Die Architektur in den Städten jedoch, die bunt bemalten Hausfassaden des Inn-Salzach-Stils, erinnert noch heute an die bayerische Vergangenheit.

Die erste bayerisch-oberösterreichische Landesausstellung fand 2004 in Passau, Asbach, Reichersberg und Schärding statt. Reichersberg war somit bereits das dritte Mal Veranstaltungsort einer oberösterreichischen Landesausstellung. Von 27. April bis 4. November 2012 fand die zweite gemeinsame Landesausstellung des Landes Oberösterreich und des Freistaates Bayern statt. Die Ausstellungsorte waren das Kloster Ranshofen bei Braunau am Inn, das Schloss Mattighofen und die Burg zu Burghausen in Bayern.

Das Innviertel war noch 1705 und 1706 ein Zentrum des gewaltsamen bayerischen Aufstandes gegen die österreichische Besatzung, nach der ersten längeren Machtübernahme des Hauses Habsburg 1779 fand sich jedoch trotz vereinzelter Versuche keine breite Widerstandsbasis. So avancierte beispielsweise mit Franz Stelzhamer, der die wechselseitige Staatszugehörigkeit in seinem prosaischen Werk „Dá Soldatnvödá“ behandelte, bereits ein Innviertler des 19. Jahrhunderts zum oberösterreichischen „Nationaldichter“.

Nichtsdestoweniger kam es bis ins 20. Jahrhundert vor allem auf der Ebene der Zechen zu zahlreichen Scharmützeln und blutigen Auseinandersetzungen zwischen Innviertler Gruppen und sogenannten „Landlern“ („Landl“ dient als Bezeichnung für das Hausruckviertel oder Oberösterreich im Allgemeinen). Aus dieser Zeit stammen auch bekannt gewordene Aussprüche und Kampfansagen, wie „Wenn d’ Innviertler keman, hoasts umirucka!“. Das bis ins späte letzte Jahrhundert gängige Innviertler Schimpfwort für Oberösterreicher, „Mostschädeln“, ist heute im Verschwinden begriffen.

Die Rivalitäten haben sich in den letzten Jahren tendenziell, auch nach institutionellen Annäherungen, etwa im Tourismussektor, des Bezirkes Grieskirchen an das Innviertel, weiter nach Osten zur Landeshauptstadt Linz verschoben und äußern sich primär in sportlichen Wettkämpfen und politischen und öffentlichen Debatten über die Benachteiligung des Innviertels gegenüber den zentrumsnahen Regionen Oberösterreichs, welche zeitweise die Berichterstattung in den lokalen Medien dominieren.

Einer dieser politischen Streitpunkte ist seit Jahren die unzureichend ausgebaute Straßenverbindung zur nahen Stadt Salzburg, an der sich vor allem das obere Innviertel (Bezirk Braunau, südwestliche Teile des Bezirks Ried) als Zentrumsregion orientiert. Trotzdem ist die Verbindung Wien-Linz-München eine bedeutende Verkehrsroute. Als städtisches Zentrum des unteren Innviertels (Bezirk Schärding, nordöstliche Teile des Bezirks Ried) spielt Passau eine große Rolle. Eine gefühlte Eigenständigkeit des Innviertels spiegelt sich auch in der „Hauptstadtdebatte“ wider, welche durch eine Plakataktion während des Wahlkampfes 2009 vom Rieder Bürgermeister Albert Ortig losgetreten wurde und in der er das Mittelzentrum Ried als Hauptstadt des Innviertels deklarierte und damit vor allem die Braunauer Politik provozierte.
Trotz all der genannten Umstände bildet das Innviertel als Region für seine Bewohner heute den mit Abstand größten identitätsstiftenden Bezugspunkt im Vergleich zu den restlichen Vierteln Oberösterreichs, welche teilweise, mit Ausnahme des Mühlviertels, welches von der Donau begrenzt wird, räumlich von den heutigen Bezirksgrenzen abweichen.

In der für die amtliche Statistik der EU geführte NUTS-Gliederung wird das "Innviertel" etwas abweichend definiert. Es ist eine der fünf Gruppen von Bezirken (Ebene -3) in Oberösterreich, trägt den Code codice_1 und umfasst folgende 4 politische Bezirke: Braunau am Inn, Ried im Innkreis, Schärding, Grieskirchen.
Inklusive des traditionell zum Hausruckviertel zählenden Bezirks Grieskirchen zählt die Region AT311 Innviertel ca. 282.000 Einwohner auf einer Fläche von ca. 2825 km²

Oberösterreich ist demnach in Statistiken auf europäischer Ebene nicht auf seine traditionellen vier Viertel aufgeteilt, sondern in seine Regionen Innviertel, Mühlviertel, Traunviertel, Linz-Wels und Steyr-Kirchdorf. Das entspricht auch dem modernen Raumordnungskonzept, in dem der Oberösterreichische Zentralraum als „fünftes“ Viertel herausgegriffen ist.

Der Landtagswahlkreis Innviertel mit Sitz der Wahlbehörde in Ried im Innkreis besteht aus den 3 traditionellen Innviertler Bezirken Ried im Innkreis, Braunau am Inn und Schärding.




</doc>
<doc id="13012" url="https://de.wikipedia.org/wiki?curid=13012" title="Kärnten">
Kärnten

Kärnten () ist das südlichste Bundesland der Republik Österreich. Landeshauptstadt ist Klagenfurt am Wörthersee. Kärnten grenzt im Westen an das Bundesland Tirol, im Norden an Salzburg, im Norden und Osten an die Steiermark und im Süden an Italien und Slowenien.

Der Name Kärnten geht möglicherweise auf die keltische Bezeichnung "karanto" für „Stein, Fels“ zurück. Zur selben Wurzel gehören auch Karnburg, Karawanken und ähnliche Namen. 
Es gibt auch im Venezianischen ein Wort "caranto" für dürren und harten Boden, im Friulanischen "carantàn" mit ähnlicher Bedeutung. Eine weitere Möglichkeit wäre eine Ableitung aus dem ebenfalls keltischen "carant" für „Freund“, von dem etwa die Personennamen Carantius und Carantia in der Römerzeit abgeleitet sind.

Die wahrscheinlich früheste Erwähnung des Namens Kärnten erfolgte in der Kosmographie des anonymen Ravennaten, welche zwischen das 8. und 9. Jh. datiert wird. Dort wird der slawische Volksstamm der "Carontani" genannt (IV 37). Paulus Diaconus erwähnt dann in seiner Langobardengeschichte die "„Sclavorum gens in Carnuntum, quod corrupte vocitant Carantanum“" (V 22: „der Stamm der Slawen in Carnuntum, das sie entstellend Carantanum nennen“) für das Jahr 663.

Mit "Karantanien" hängt auch das alte slowenische "Korotan" zusammen, aus dem das heutige slowenische "Koroška" oder "Koroško" (ursprünglich Adjektiv "*korot-sk-"), letzteres vor allem in der Lokativverwendung "na Koroškem" „in Kärnten“ abgeleitet wurde.

Im Mittelalter wurde der Name Kärnten verballhornend aus „caritate plena“ („voll der Liebe“) hergeleitet, um auf die weitherzige Nächstenliebe der Bewohner dieser Gegend hinzuweisen.

Blasonierung des Kärntner Wappens: „Gespalten von Gold und Rot, vorne pfahlweise drei schreitende rotbewehrte und -bezungte schwarze Löwen, hinten ein silberner Balken. Auf dem goldgekrönten Spangenhelm mit rot-goldenen Decken zwei goldene Büffelhörner, außen mit je fünf goldenen Stäbchen besteckt, an denen rechts je drei herabhängende schwarze, links je drei rote Lindenblätter.“

Es entstand als Anspruchswappen Herzog Ulrichs III. auf die Babenberger Lande. Das ursprüngliche Wappen war "In Silber ein schwarzer Panther".

Die Kärntner Flagge ist "Gold-Rot-Weiß" und damit als einzige Flagge eines österreichischen Bundeslandes dreifarbig.

Landeshymne ist das Kärntner Heimatlied. Die ersten drei Strophen entstanden 1822 durch Johann Thaurer Ritter von Gallenstein und wurden 1835 durch Josef Ritter von Rainer-Harbach vertont. Sie beschreiben Kärntner Landschaften. Zur Landeshymne wurde sie 1911 erhoben. 1930 wurde die Hymne nach einem Preisausschreiben um eine vierte Strophe von Agnes Millonig erweitert, die sich auf den Kärntner Abwehrkampf bezieht.

Kärnten grenzt im Westen an Osttirol, im Nordwesten an Salzburg, im Nordosten an die Steiermark und im Süden an Slowenien sowie die italienischen Regionen Friaul und Venetien. Die Gesamtlänge der Grenzen zu den Nachbarstaaten beträgt 280 km. Die Einschnürung des Landesgebietes ungefähr in der Mitte auf nur 44 km ergibt zusammen mit den unterschiedlichen Geländeformen die Unterteilung in Oberkärnten (vom Hochgebirge geprägt) und Unterkärnten (vom Klagenfurter Becken geprägt). Im Klagenfurter Becken, das von den Österreichischen Zentralalpen im Norden und den Karawanken im Süden begrenzt wird, liegt die Landeshauptstadt Klagenfurt. Westlich davon liegt der Wörthersee. Zusammen mit vielen anderen Seen ist er Zentrum des Sommertourismus.

Das Land wird von mehreren Tälern durchzogen, von denen die größten neben dem Drautal das Möll-, das Gail-, das Rosen-, das Jaun- und das Lavanttal sind. Der bedeutendste Fluss Kärntens ist die Drau. Die Wasserkraftwerke der ehemaligen „Draukraft“ liefern 12 % des Stroms für ganz Österreich.

Die Lage Kärntens in den Ostalpen spiegelt sich in einer großen Gesteinsvielfalt und komplexen Lagerungsverhältnissen der Gesteine wider. Folgende großtektonische Einheiten finden sich in Kärnten: Penninikum, Ostalpin, Südalpin, Tertiär und Quartär.

Das Penninikum ist in Kärnten durch das Tauernfenster in den Hohen Tauern vertreten. Die aus variszischen Graniten hervorgegangenen Zentralgneise bauen den Sonnblickkern und den Ankogel-Hochalmspitzkern auf. Um sie liegt die Untere Schieferhülle des Alten Daches (vorvariszische Gneise) und die Obere Schieferhülle (metamorphe karbonatische und klastische Sedimente – Quarzite, Marmore und Bündnerschiefer mit Einschaltungen von aus untermeerischem Vulkanismus herrührendem Prasinit wie etwa am Großglockner).

In Kärnten kommen alle Einheiten des Ostalpins vor: Unter-, Mittel- und Oberostalpin.




Die Gailtaler Alpen und die Nordkarawanken bestehen aus einem kristallinen Grundgebirge (Gailtalkristallin, Eisenkappler Kristallin) und aufgelagerten Sedimenten. Diese reichen in den Gailtaler Alpen vom Perm bis zur Obertrias, in den Karawanken bis in die Unterkreide; sie enthalten in unterschiedlichem Ausmaß karbonatische Gesteine. Eigene Schollen bilden das "Karbon von Nötsch" und das Dobratsch-Massiv. Die Nordkarawanken nördlich der Periadriatischen Naht bestehen aus permomesozoischen Gesteinen, dem Eisenkappler Diabaszug sowie dem Eisenkappler Altkristallin, Granit und Tonalit.

Zum Südalpin gehören in Kärnten die Karnischen Alpen und die Südkarawanken. Sie liegen südlich der Periadriatischen Naht. Die Karnischen Alpen sind aus überwiegend marinen Sedimenten aus dem jüngeren Ordovizium bis zur Trias aufgebaut. Ein tieferes, vorwiegend altpaläotisches Stockwerk ist überwiegend aus Sandsteinen (Grauwacken und Quarzite) aufgebaut. Das jüngere, höhere Stockwerk setzt sich aus quarzreichen Sandsteinen, Tonschiefern und fossilreichen Kalken zusammen und bildet die Auernig- und Rattendorfer Schichten. Die Südkarawanken sind ähnlich aufgebaut wie die Karnischen Alpen. Das tiefere Stockwerk aus ordovizischen bis karbonischen Gesteinen tritt im Seeberger Aufbruch zutage. Die Hauptkette besteht aus jungpaläozoischen Sedimentgesteinen und mächtigen marinen Ablagerungen der Trias. Letztere bauen die wichtigsten Massive wie Koschuta, Vertatscha, Hochstuhl und Mittagskogel auf.

Das Zeitalter des Tertiär war durch die alpidische Gebirgsbildung geprägt. Im Zuge der Faltungsprozesse sanken manche Gebiete ab, es entstand zum Beispiel das Lavanttaler Becken, das mit rund 1000 Meter mächtigen Sedimenten gefüllt wurde. Dabei entstanden auch die Braunkohleflöze, die bis 1968 bei St. Stefan abgebaut wurden. Bei Kollnitz nahe St. Paul liegt der einzige Basalt Kärntens. Im Klagenfurter Becken entstand im Zuge der Erosion der stark gehobenen Karawanken die Sattnitzkonglomerate abgelagert, ebenso die tertiären Sedimente des Karawankenvorlandes (Bärentalkonglomerat).

Das Quartär war durch die Eiszeiten geprägt. Durch die Gletscherwirkung entstanden die Trogtäler und Kare sowie zahlreiche Grund-, End- und Seitenmoränen. Schmelzwässer lagerten große Mengen an Sedimenten ab, besonders im Klagenfurter Becken. Auch die Becken der Kärntner Seen wurden in dieser Zeit ausgeschürft.

Kärnten befindet sich in der gemäßigten Klimazone Mitteleuropas. Der mediterrane Klimaeinfluss wird meist überschätzt. Auch ist der Alpenhauptkamm zwar eine deutliche Wetterscheide, aber insbesondere im östlichen Teil der Ostalpen keine Klimascheide. Das Klima wird jedoch durch die Lage nach Süden, durch das Relief und andere lokale Gegebenheiten stark modifiziert, so dass das Klima sehr kleinräumig strukturiert ist.

Ein wichtiges Phänomen des Klagenfurter Beckens und der angrenzenden Täler ist die winterliche Temperaturumkehr. Der Kaltluftsee und damit meist auch die Nebeldecke reicht dabei häufig in Höhen bis Die Temperatur in Höhenlagen zwischen 1000 und 1400 Metern sind daher oft um 15 °C höher als im Tal. Der Kärntner Kältesee ist der größte der Ostalpen. Er ist die Hauptursache für eine gegenüber anderen Regionen Österreichs relativ geringe Jahresmitteltemperatur und dafür, dass Kärnten anders als u. a. Teile Südtirols oder das Tessin keinen ganzjährigen Temperaturvorteil gegenüber den Regionen nördlich des Alpenhauptkamms aufweist.

Der (unzutreffende) Eindruck eines mediterran beeinflussten Klimas kommt im Wesentlichen durch die warmen, sonnenreichen Sommermonate zustande, die v. a. für den Tourismus relevant sind. So wird an vielen Stationen im Klagenfurter Becken und den angrenzenden Haupttälern im Juli ein mittleres Tagesmaximum von über 25 °C erreicht, was im Vergleich zu anderen Regionen Österreichs überdurchschnittlich ist.

Die jährliche Temperaturschwankung beträgt in Tallagen meist 20 bis 24 °C, während sie in Berglagen nur 14 bis 20 °C beträgt.

Der Niederschlag folgt dem mitteleuropäischen Muster mit Niederschlagsminima im Winter (Februar) und Maxima im Sommer. In den südlichen Landesteilen (Gailtal, Gailtaler Alpen, Karawanken) kommt als südalpisches Element ein zweites Niederschlagsmaximum im Spätherbst (Oktober/November) infolge der Adria- beziehungsweise Genua-Tiefs. Der Niederschlag im Sommer erfolgt vielfach über Starkregen, besonders Gewitter. Generell sinken die Jahresniederschlagsmengen von West nach Ost. Die Gebirge im Nordwesten und im Süden erhalten besonders hohe Niederschläge (über 2000 mm pro Jahr), während die übrigen Landesteile sich im Regenschatten befinden. Trocken sind vor allem die Bereiche Krappfeld (750 mm), Görtschitztal und Unteres Lavanttal (800 mm), aber auch das nördliche Klagenfurter Becken, das Möll- und Liesertal.

Die Zahl der Tage mit Schneebedeckung beträgt im Klagenfurter Becken und den großen Tälern 75 bis 100 Tage, im Unteren Lavanttal noch weniger. In weiten Teilen der Gebirge liegt sie jedoch über 150 Tagen. Umgekehrt verhält es sich mit der Dauer der Vegetationsperiode (Tage über +5 °C): Sie beträgt im Hochgebirge unter 90 Tage, in großen Teilen des Landes 180 bis 220 Tage, im Drautal, im Klagenfurter Becken und im Unteren Lavanttal 220 bis 230 Tage.

57,6 % der Landesfläche (5490 km²) sind von Wald bedeckt, rund die Hälfte davon sekundäre Fichtenforste. 15,6 % (1500 km²) sind subalpine und alpine waldfreie Vegetation, 19,4 % bilden den agrarischen Hauptarbeitsraum (9,1 % Acker-Grünlandkomplexe und 10,3 % Wirtschaftsgrünland). 0,31 % sind größere Feuchtbiotope, 5,13 % (490 km²) Siedlungs- und Verkehrsflächen, 1,14 % Wasserflächen, 0,54 % Gletscher und 0,28 % Pistenflächen. Eine detailliertere Darstellung nach agrarischen Gesichtspunkten bietet die Tabelle.

In Kärnten sind rund 15.000 Tierarten bekannt. Die Zusammensetzung der Fauna lässt sich durch die Wiederbesiedlung des Gebietes nach der letzten Eiszeit, in der Kärnten großteils vergletschert war, erklären. Die erste Welle der Wiederbesiedlung fand durch alpine Faunenelemente statt, die heute in den kühlen Gebirgsregionen beheimatet sind, zum Beispiel Alpenapollo ("Parnassius phoebus"), Alpenmurmeltier ("Marmota marmota") und Gämse ("Rupicapra rupicapra"). Vertreter der nordisch-alpinen Fauna, die heute in Skandinavien und in den Alpen vorkommen, sind die Bodenschrecke ("Podisma frigida") und der Schneehase ("Lepus timidus").

Der größte Teil der Kärntner Fauna ist in den Waldgebieten Europas und Asiens beheimatet (baltische Tierwelt). Diese Arten wanderten ein, als sich Kärnten wieder bewaldete. Typische Vertreter sind Hirschkäfer ("Lucanus cervus"), das Große Nachtpfauenauge ("Saturnia pyri") und die Kreuzotter ("Vipera berus").

Vertreter des pontischen Faunenelements aus Osteuropa ist der Balkan-Moorfrosch ("Rana arvalis wolterstorffi"). Die aus dem Mittelmeergebiet zugewanderten Arten der illyrisch-mediterranen Fauna sind zum Beispiel die Kroatische Gebirgseidechse ("Iberolacerta horvathi"), die Steinrötel ("Monticola saxatilis") und die Sandviper ("Vipera ammodytes"). Sie haben in Kärnten ihre nördliche Verbreitungsgrenze.

Etwa 150 Tierarten sind in Kärnten endemisch. Einige Beispiele sind Kärntner Schließmundschnecke ("Macrogastra badia carinthiaca"), Kärntner Rollassel ("Armadillidium carinthiacum") und die Kärntner Gebirgsschnecke ("Miramella carinthiaca").

In den letzten Jahrzehnten wurden auch etliche Neozoen heimisch. Neben den in Europa weitverbreiteten Arten wie Regenbogenforelle ("Oncorhynchus mykiss"), Kartoffelkäfer ("Leptinotarsa decemlineata"), Spanische Wegschnecke ("Arion vulgaris") oder Rosskastanienminiermotte ("Cameraria ohridella") kommen in Kärnten auch seltenere Arten wie die afrikanischen Buntbarsche "Hemichromis fasciatus" und "Hemichromis bimaculatus" im Warmbach von Villach oder der Japanische Eichenseidenspinner ("Antherea yamamai") vor.

Im Jahr 2014 erreichte Kärnten im Vergleich zum Bruttoinlandsprodukt der Europäischen Union zu Kaufkraftstandards einen Indexwert von 108 (EU-28: 100 Österreich: 129). Zu Marktpreisen entsprach Kärntens Bruttoinlandsprodukt pro Kopf im Jahr 2014 sogar einem Indexwert von 117 vom EU-Durchschnitt (Kärnten: 32.200 Euro, EU-28: 27.500 Euro).

2007 gab es in Kärnten 18.911 land- und forstwirtschaftliche Betriebe, davon 5.272 im Haupterwerb. Die Anzahl der Betriebe hat sich seit 1945 fast halbiert.

Im Jahr 2008 wurden 34.118 Milchkühe gehalten, die 206.000 Tonnen Milch lieferten. In Summe gab es 193.758 Rinder, 142.224 Schweine sowie 43.344 Schafe und 4.236 Ziegen.

Die Waldfläche beläuft sich in Kärnten auf 505.910 Hektar. 2008 wurden in Summe 2.798.455 Festmeter Holz eingeschlagen, das sind 12,8 % des österreichischen Gesamteinschlags.

Kärnten ist nach Tirol und Salzburg das wichtigste Tourismus-Bundesland in Österreich. 2012 erzielte es 12,6 Mio. Übernachtungen. Kärnten hat damit eine Tourismusintensität von 23 Übernachtungen je Einwohner, ebenfalls mehr als alle anderen Bundesländer mit Ausnahme von Tirol und Salzburg. Dies bedeutet, dass der Tourismus in Kärnten wirtschaftlich und sozioökonomisch eine besonders wichtige Rolle spielt.
Hinsichtlich der durchschnittlichen Aufenthaltsdauer liegt es mit 4,4 Übernachtungen je touristischer Ankunft zusammen mit Tirol an erster Stelle unter allen Bundesländern. Kärntens Tourismus unterscheidet sich von jenem der übrigen Bundesländer durch eine Reihe von Merkmalen.
Kärnten ist ein weitgehend einsaisonales Land: Kärnten hat einen Winteranteil bei den Übernachtungen von nur 28 % gegenüber 49 % im österreichischen Durchschnitt. Obwohl Kärnten einzelne bedeutende Wintersportgebiete (Naßfeld, Bad Kleinkirchheim, Mallnitz, Heiligenblut, Katschberg) aufweist, sind die Sommertourismusregionen (Wörthersee, Klopeiner See, Millstättersee, Weißensee, Pressegger See, Faaker See) so stark, dass sie rund 72 % der gesamten Jahresübernachtungen erzielen. Die Lage südlich des Alpenhauptkammes, relativ fern von den wichtigsten Quellräumen des Wintertourismus, die bei starkem Wintereinbruch erschwerte Erreichbarkeit und die Mauten an wichtigen Passstraßen tragen ebenfalls dazu bei.

Kärnten hat für ein alpines Bundesland eine relativ breite Herkunftsverteilung auf die Ausländer- und Inländer-Nachfrage. 2011 entfielen 37 % aller Übernachtungen auf Inländer und 63 % auf Ausländer. Gerade der ständig zunehmende Inländertourismus hat Kärnten vor zu starken Nachfragerückgängen in den letzten Jahren bewahrt.
Während Kärntens Auslastungsquoten der Bettenkapazität bei den gewerblichen Betrieben gut sind (4/5 Stern Betriebe im Sommerhalbjahr eine durchschnittliche Auslastung von 55 %, 3-Stern von 36 %, 2/1 Stern Betriebe allerdings nur von 23 %) ist sie bei den vielen Privatquartieren vielfach unzureichend. Viele davon sind daher im letzten Jahrzehnt aus dem Markt ausgeschieden. Kärnten hatte 1990 noch 220.000 Betten. Seither sind 90.000 Betten, vor allem in Privatquartieren und qualitativ geringwertigeren gewerblichen Betrieben aufgegeben worden, sodass Kärnten 2011 noch 130.000 Betten zählte – auch dies nach Tirol und Salzburg ein hoher Wert. Aber in keinem Bundesland hat die Bettenzahl in diesem Zeitraum so stark abgenommen. Der Hintergrund ist ein hoher Nachfragerückgang vor allem bei den ausländischen Übernachtungen. Kärnten erreichte um 1980 fast 20 Mio. Übernachtungen. Vor allem im Zeitraum 1990 bis 1995 verzeichnete es die stärksten Einbußen aller Bundesländer, einen dramatischen Rückgang um rund 5 Mio. Übernachtungen. Dies betraf vor allem die Ausländernachfrage und damit den Sommertourismus. Seither pendelte sich die Nachfrage auf rund 12 bis 13 Mio. Übernachtungen ein.

Rund 20 % der Nächtigungen entfielen 2008 auf die 128 Campingplätze, ein international gesehen hoher Wert. 85 % aller Nächtigungen entfielen auf Deutsche (41 %), Österreicher (37 %) und Niederländer (9 %).
Die höchste Tourismusdichte (Übernachtungen pro Einwohner) verzeichneten die Gemeinden Sankt Kanzian am Klopeinersee, Keutschach am See, Maria Wörth und Pörtschach.

Der Wintertourismus ist in Kärnten schwächer ausgeprägt, aber ein Wachstumssektor. In der Saison 2007/08 (November bis April) wurden 3,7 Millionen Übernachtungen gezählt, das ist der höchste Wert seit Beginn der statistischen Aufzeichnungen. Die Übernachtungen stiegen im Vergleich zum Vorjahr um 3,1 %. Nach dem Herkunftsland führten die Österreicher (33 %) vor den Deutschen (30 %) und Ungarn (7 %). Die höchste Tourismusdichte verzeichneten die Gemeinden Bad Kleinkirchheim, Heiligenblut, Rennweg und Mallnitz.

In Kärnten wird die Wasserkraft besonders intensiv genützt. Die 540 Kärntner Wasserkraftwerke (hiervon 330 Kleinwasserkraftwerke) decken 90 % des Kärntner Strombedarfs. Die Hälfte der Produktion entfällt auf die zehn Kraftwerke an der Drau. Größte Speicherkraftwerke sind das Maltakraftwerk, das Kraftwerk Reißeck und die besonders komplexe Kraftwerksgruppe Fragant.

Durch Kärnten verläuft die Adria-Wien Pipeline, die Transalpine Ölleitung und die Trans Austria Gasleitung.

Von den 268.200 Erwerbstätigen waren 7,0 % in der Land- und Forstwirtschaft, 26,6 % in Industrie und Gewerbe sowie 66,4 % im Dienstleistungssektor tätig.

Im Jahresdurchschnitt 2008 gab es in Kärnten 209.291 unselbständig Beschäftigte, davon rund 47 % Frauen. Die wichtigsten Bereiche waren dabei Sachgütererzeugung (37.062), Öffentliche Verwaltung/Sozialversicherung (33.650) und Handel/Reparatur von Kraftfahrzeugen (32.414), die zusammen 49 % der Arbeitnehmer beschäftigten. Im Bauwesen gab es 17.059, im Gesundheits- und Sozialwesen 16.168, im Beherbergungs- und Gaststättenwesen 13.659 Beschäftigte.

Die Arbeitslosenquote lag 2015 bei 6,1 % und damit nach Wien am zweithöchsten im Vergleich zu den anderen österreichischen Bundesländern.

Der größte Teil der Bevölkerung Kärntens siedelt im "Klagenfurter Becken" zwischen Villach und Klagenfurt.

2008 gab es 4718 Lebendgeborene. Der Anteil der unehelich Geborenen lag bei 53,3 %, mit Abstand Spitzenwert in Österreich. Dem standen 5385 Todesfälle gegenüber, was eine negative Geburtenbilanz von −667 ergab. Ein leichtes Bevölkerungswachstum ergab sich durch die positive Wanderungsbilanz von 939 Personen, wobei hier einer Abwanderung ins übrige Österreich von 675 Personen eine Zuwanderung aus dem Ausland von 1614 Personen gegenüberstand. Die Zahl der Einbürgerungen ging 2008 mit 427 Einbürgerungen wiederum stark zurück. Die Bevölkerungsprognose sagt Kärnten als einzigem Bundesland bis 2050 einen leichten Bevölkerungsrückgang um rund 2 % voraus.

2008 hatten rund 51.700 Personen einen Migrationshintergrund. Davon sind 41.500 Personen im Ausland geboren, 10.200 waren in Österreich geborene Kinder von im Ausland geborenen Eltern. Der Anteil der Bevölkerung mit Migrationshintergrund liegt in Kärnten bei 9,3 % der Gesamtbevölkerung, rund die Hälfte des Österreich-Wertes von 17,5 %.

Die Mehrheit der Bevölkerung Kärntens ist deutschsprachig. Im Süden des Bundeslandes (vor allem in den Bezirken Villach-Land, Klagenfurt-Land und Völkermarkt) leben Angehörige der slowenischsprachigen Volksgruppe als anerkannte Minderheit. Die Diskussion über die Volksgruppenrechte (z. B. zweisprachige Ortsschilder) wurde sehr emotional geführt (siehe hierzu Ortstafelstreit).

Die Anzahl der in Kärnten lebenden Slowenen ist umstritten. Als Resultat einer im Jahr 1991 durchgeführten Erhebung in zweisprachigen Pfarren, bei der nach der Umgangssprache der Pfarrangehörigen gefragt wurde, ergab sich eine Zahl von 50.000 slowenischen Volksgruppenangehörigen. Laut Volkszählung von 2001 gaben hingegen 13.225 in Österreich Geborene Slowenisch als Umgangssprache an, davon 11.119 in Kärnten mit der Angabe "Slowenisch" und 535 mit der Angabe "Windisch".

Der größte Teil der Bevölkerung bekennt sich zur römisch-katholischen Kirche, der Anteil von Anhängern der evangelischen Kirche ist nach dem Burgenland (13,3 %) in Kärnten mit 10,3 % der zweithöchste in Österreich.

Die katholische Diözese Gurk ist in ihrem Umfang praktisch deckungsgleich mit dem Bundesland. Der Landespatron von Kärnten ist der Heilige Josef (19. März), die Heilige Hemma von Gurk (27. Juni) ist die Landesmutter. Die evangelische Superintendentur Kärnten und Osttirol betreut die evangelischen Christen Augsburgischen und Helvetischen Bekenntnisses. Kärnten gehört zum Sprengel Graz der Islamischen Glaubensgemeinschaft in Österreich. Kärntner jüdischen Glaubens gehören zur israelitischen Kultusgemeinde für Steiermark, Kärnten und die politischen Bezirke des Burgenlandes Oberwart, Güssing und Jennersdorf.

Die hallstattzeitliche Bevölkerung Kärntens, meist aus Illyrern aber auch Venetern bestehend mischte sich 300 v. Chr. mit keltischen Einwanderern, wobei Religion, Brauchtum und Gesellschaftsstruktur fortbestanden.
Zu dieser Zeit verbanden sich die unabhängigen Stammesgesellschaften zum Fürstentum Noricum als erstes Staatengebilde auf dem Boden des heutigen Bundeslands Kärnten. Noricum ging unter Kaiser Augustus friedlich in der römischen Provinz "Regnum Noricum" auf. Am Magdalensberg auf dem Zollfeld sowie in Teurnia am Lurnfeld befanden sich damals die Zentren der Provinz. Zu Beginn der Völkerwanderung gab es eine ostgotische Oberschicht mit römischer Verwaltungs- und Militärstruktur. Nachdem die Slawen diese Oberschicht um das Jahr 600 ersetzten und einen eigenen Staat Karantanien mit dem Zentrum in Karnburg gebildet hatten, verdrängte die slawische Sprache bis zum 8. Jahrhundert die übrigen Sprachen unter Fortbestand der norischen, römischen und slawischen Bevölkerung. Zur Abwehr der Awaren ins Land gerufen gewannen nach und nach auch baierische beziehungsweise fränkische Herzöge in Kärnten an Einfluss. Von 743 bis 907 herrschten fränkische Könige und Kaiser über das Gebiet. Anschließend wurde Kärnten wieder ein Teil des Herzogtums Baiern, wobei große Mengen bairischer Siedler folgten und die deutsche Sprache verbreiteten.

976 begann eine Phase der Eigenständigkeit des Herzogtums Kärnten, die bis 1335 andauerte; in diese Zeit fallen zahlreiche Klostergründungen sowie der Bau von Schlössern und Befestigungsanlagen. Kaiser Ludwig der Bayer übertrug 1335 Kärnten an die Habsburger, die es mit Österreich, Steiermark und Krain vereinigten.

In der darauf folgenden Zeit bis ins 18. Jahrhundert hinein wurde Kärnten zunächst durch die Türkenkriege, Bauernaufstände und durch die Folgen von Reformation und Gegenreformation in Mitleidenschaft gezogen. Im Zuge der Rekatholisierung wurden Tausende von Protestanten ins Exil überwiegend nach Süddeutschland und Westungarn gedrängt bzw. zur Auswanderung gezwungen. Unter Maria Theresia kam es Ende des 18. Jahrhunderts zu Reformen, die die Macht der Stände beschnitten und den Bauern das Recht an ihrem Besitz zusicherten, allerdings verlor Kärnten auch seine administrative Selbständigkeit. Einen erneuten Rückschlag in der Entwicklung des Landes hatten die Koalitionskriege ab 1797 zur Folge, wodurch schließlich 1809 ganz Oberkärnten an Frankreich fiel. Schon 1813 wurde das Land wieder befreit und einem habsburgischen Königreich Illyrien unterstellt.

Nach dem Revolutionsjahr 1848 erlangte Kärnten im Jahr 1849 die Selbstständigkeit und Landeseinheit zurück und war von 1867 bis 1918 Herzogtum in der westlichen Reichshälfte Österreich-Ungarns. Nachdem im Zuge der Auflösung des Habsburger Vielvölkerreiches nach dem Ersten Weltkrieg am 21. Oktober 1918 die Provisorische Nationalversammlung für Deutschösterreich zusammengetreten war, beschloss am 11. November 1918 die Vorläufige Landesversammlung von Kärnten die Konstituierung des Landes Kärnten sowie den Beitritt Kärntens zum Staat Deutschösterreich. Nach Gebietsverlusten von Raibl und dem Kanaltal (445 km²) an Italien und Mießtal, Unterdrauburg und der Gemeinde Seeland im Kankertal (331 km²) an den neuen SHS-Staat und nach dem demokratisch gewährleisteten Erhalt von Südkärnten nach der Volksabstimmung vom 10. Oktober 1920 ist Kärnten in den im Friedensvertrag von Saint Germain festgelegten Grenzen ein Land der Republik Österreich.

Die "Legislative" des Landes Kärnten besteht aus einem Einkammer-Parlament, dem "Kärntner Landtag", mit 36 Abgeordneten, die für eine Legislaturperiode von fünf Jahren gewählt werden. Den Vorsitz in den Sitzungen führt einer der drei vom Landtag gewählten Landtagspräsidenten. Sitz des Landtages ist das Landhaus Klagenfurt.

Die "Exekutive" besteht aus der "Kärntner Landesregierung" unter dem Vorsitz des Landeshauptmanns von Kärnten. Bis 2018 war in dieser Konzentrationsregierung jede Fraktion des Landtages (ab einer bestimmten Stärke) vertreten. Die Wahl erfolgt durch den Landtag, wobei der Wahlmodus für den Landeshauptmann dem Mehrheitswahlrecht entspricht, der der übrigen Regierungsmitglieder dem Verhältniswahlrecht. Die Kärntner Landesregierung besteht aus sieben Mitgliedern: dem Landeshauptmann, zwei Landeshauptmann-Stellvertretern und vier Landesräten.

Den Landeshauptmann stellte die SPÖ von 1945 bis 1989 und ab 2013, die ÖVP 1991 bis 1999, und FPÖ bzw. BZÖ 1989–1991 und 1999–2013.

Die derzeitige "Landesregierung Kaiser II" wurde bei der konstituierenden Sitzung des Landtages am 12. April 2018 gewählt, wobei SPÖ und ÖVP eine Koalition bilden:

Auf Gemeindeebene werden die Bürgermeister direkt gewählt.

Das Kärntner E-Government-Portal bietet Online- und Druck-Formulare, mit denen Bürger ihre Anträge unabhängig von Zeit und Ort ausfüllen und einreichen können. Dabei wird u. a. in den Bereichen Gesundheit, Umwelt oder Wirtschaft und Tourismus der Weg auf die Behörde erspart. Die verwendeten Online-Formulare stammen von der Firma aforms2web, einem österreichischen IT-Dienstleister.

In Kärnten verdient der Landeshauptmann 2016 mit 14.254 Euro Monatsbrutto um 9–18 % weniger als in den acht anderen Bundesländern.

Größte Forschungs- und Bildungseinrichtung Kärntens ist die 1970 gegründete Alpen-Adria-Universität Klagenfurt mit Standorten in Klagenfurt, Wien und Graz, über 10.000 Studierenden und einem Jahresbudget von 54 Millionen Euro (Stand 2013, ohne Drittmittel). Sie bietet universitäre Bildung in den Kultur- und Sozialwissenschaften, Wirtschaftswissenschaften, Technischen Wissenschaften und im interdisziplinären Bereich.

Die Fachhochschule Kärnten betreibt an den vier Standorten Klagenfurt, Villach, Spittal an der Drau und Feldkirchen Studienangebote in den Sparten Technik, Wirtschaft, Gesundheit und Soziales.

Die Pädagogische Hochschule Kärnten ist seit 2013 gemeinsam mit der Universität Klagenfurt Teil des „Entwicklungsverbunds Süd-Ost“ der Lehrerbildung neu, gemeinsam mit Hochschulen und Universitäten der Steiermark und des Burgenlandes.

Kärnten hat in den letzten Jahrzehnten etliche Schriftsteller von internationalem Rang hervorgebracht. Im frühen 20. Jahrhundert erlangten Robert Musil, Josef Friedrich Perkonig, Dolores Viesèr und Gerhart Ellert einige Bekanntheit.

Nach dem Zweiten Weltkrieg traten zunächst die Lyriker Ingeborg Bachmann, Michael Guttenbrunner und Christine Lavant hervor. Ihnen folgten Peter Handke, Gert Jonke, Josef Winkler und Peter Turrini nach. Sie setzten sich unter anderem recht kritisch mit ihrer Heimat auseinander, wie Josef Winkler in seiner Trilogie "Das wilde Kärnten". Weitere wichtige Vertreter der Kärntner Literatur sind u. a. Janko Messner, Lydia Mischkulnig, Werner Kofler, Janko Ferk, Antonio Fian und Florjan Lipuš.

Die wichtigsten Verlage sind Johannes Heyn, Carinthia und die Kärntner Druck- und Verlagsgesellschaft. Slowenische Literatur wird vor allem von den Kärntner Verlagen Mohorjeva/Hermagoras, Drava und dem von Lojze Wieser gegründeten Wieser-Verlag gefördert.

Die bedeutendste Literaturveranstaltung Kärntens sind die "Tage der deutschsprachigen Literatur" in Klagenfurt, in deren Rahmen unter anderem der Ingeborg-Bachmann-Preis vergeben wird, die seit 1977 jährlich stattfinden und besonders jüngere Autoren fördern. Der Ingeborg-Bachmann-Preis gilt als eine der wichtigsten literarischen Auszeichnungen im deutschsprachigen Raum.

Im frühen 20. Jahrhundert war der Nötscher Kreis mit den Malern Sebastian Isepp, Franz Wiegele, Anton Kolig und Anton Mahringer mit seiner europäischen Ausrichtung tätig. Nur lose mit dem Kreis verbunden war der Maler Herbert Boeckl. Eine kunstpolitische Kontroverse war der Streit um die Kolig-Fresken im Klagenfurter Landhaus ab 1931, die in der Abschlagung der Fresken 1938 endete. In der Architektur ist Gustav Gugitz, der Erbauer des Landesmuseums zu nennen, während die Wörthersee-Architektur mit den Villen und Hotels vornehmlich von Wiener Architekten geprägt ist. Für seine Holzschnitte bekannt ist Switbert Lobisser. Holzschnitte und Gemälde, vor allem seiner Bleiburger Wahlheimat fertigte Werner Berg.

Nach 1945 leiteten Maria Lassnig, Hans Staudacher und Hans Bischoffshausen einen radikalen Neubeginn ein. Wichtige Stätten waren und sind der Kärntner Kunstverein, die Galerie Hildebrand, das Nötscher-Kreis-Museum sowie das 2003 eröffnete Museum Moderner Kunst Kärnten. Zwei öffentlichkeitswirksame „Kunstskandale“ waren 1950 die Fresken von Giselbert Hoke im Hauptbahnhof Klagenfurt sowie 1998 die Neugestaltung des Sitzungszimmers im Landhaus durch Anton Koligs Enkel, Cornelius Kolig.

Ein von Kiki Kogelnik entworfener Brunnen steht nahe dem Landhaus. Weitere bildende Künstler sind Valentin Oman, Bruno Gironcoli, Meina Schellander und Karl Brandstätter. Der Architekt Günther Domenig hat in Kärnten das Steinhaus am Ossiacher See, den Bau für die Landesausstellung in Hüttenberg und den Zubau für das Stadttheater Klagenfurt entworfen.

Kärnten besteht aus 132 selbständigen Gemeinden und ist in zehn politische Bezirke (inklusive der zwei Statutarstädte Klagenfurt und Villach) gegliedert.





</doc>
<doc id="13013" url="https://de.wikipedia.org/wiki?curid=13013" title="Schüttelreim">
Schüttelreim

Der Schüttelreim ist eine Reimform, bei der die (Anfangs-) Konsonanten der letzten beiden betonten Silben miteinander vertauscht werden. Er stellt somit eine Sonderform des Doppelreims dar (zwei Zeilen reimen nicht nur ab der letzten, sondern bereits ab der vorletzten betonten Silbe). Die Kadenzen können stumpf oder klingend sein. Beispiel: "„Er würgte eine Klapperschlang’, / bis ihre Klapper schlapper klang.“" mit stumpfer Kadenz. Gängiger ist die Version "„Es klapperten die Klapperschlangen, bis ihre Klappern schlapper klangen.“" mit klingender Kadenz.

Der Schüttelreim ist eine im deutschen Sprachraum seit dem 13. Jahrhundert bekannte Gedichtform. Seit dem 19. Jahrhundert werden Schüttelreime hauptsächlich für vergnügliche Zweizeiler verwendet.

<poem>
"Ich fuhr mit meinem Leiterwagen,"
"wo Steine und so weiter lagen."
</poem>
"(Volksgut)"

<poem>
"Du sollst ein krankes Nierenbecken"
"nicht mit zu kalten Bieren necken."
"Auch sollte man bei Magenleiden"
"den Wein aus sauren Lagen meiden."
</poem>
"(Eugen Roth)"

Die geschüttelten Buchstaben müssen nicht gleich sein. Es genügt, wenn sie gleich oder ähnlich lauten:
<poem>
"Frauengroll:"
"Grauenvoll!"
</poem>
"(Clemens Plassmann; strenggenommen nicht ganz sauber geschüttelt, weil ein "r" verlorengeht)"

Auch das Fehlen eines anlautenden Konsonanten kann geschüttelt werden:
<poem>
"Erst isst du mit den Indern Reis,"
"dann gibst du deinen Rindern Eis!"
</poem>

Es wurden ganze Bücher in Schüttelreimform herausgegeben, wie beispielsweise Versionen des "Faust" oder ein Opernführer. Viele Sprachkabarettisten haben traditionelle Texte, etwa Volksmärchen, in Schüttelreimen erzählt.

Eine Sonderform stellen vierfach abgewandelte Vierzeiler dar, bei denen auch die Vokale der Schüttelsilben vertauscht werden:
<poem>
"Ein Wagen fuhr in Gossensaß"
"durch a [eine] tiefe Soßengass,"
"Sodass die ganze Gassensoß"
"Sich über die Insassen goss."
</poem>

oder mit Kreuzstellung der Schüttelpaare:
<poem>
"Es war einmal ein Leibesriese,"
"der machte eine Liebesreise."
"Des Abends sprach er: „Reib es, Liese!“"
"Und Liese kam und rieb es leise."
</poem>






</doc>
<doc id="13014" url="https://de.wikipedia.org/wiki?curid=13014" title="Buttermilch">
Buttermilch

Als Buttermilch bezeichnet man allgemein verschiedene Milcherzeugnisse. Teilweise wird sie auch als Milchsorte angesehen. Sie entsteht bei der Butterung durch die Trennung des Butterkorns von der im Rahm enthaltenen Flüssigkeit. Sie hat üblicherweise einen Milchfettgehalt von weniger als einem Prozent.

Die Basis von Buttermilch ist Rahm, der durch Zentrifugieren der Rohmilch von der Magermilch getrennt wird. Nachdem der Rahm ggf. durch Standardisieren und Pasteurisieren weiterbehandelt wird, reift er für die Herstellung von Süßrahmbutter, oder man säuert ihn für Sauerrahmbutter. Bei der Butterung werden die meisten festen Bestandteile von der Flüssigkeit getrennt, die als Buttermilch bezeichnet wird.

Ebenso wird das aus der unmittelbaren Herstellung von Milchfetterzeugnissen der Gruppe XVII der Milcherzeugnisverordnung aus Sahne anfallende Erzeugnis als Buttermilch bezeichnet.

Eine Anreicherung der Flüssigkeit mit Milcheiweißerzeugnissen oder Rahm ist für Standardsorten untersagt. Eine Wärmebehandlung zur Verlängerung der Haltbarkeit ist zulässig.


Die Mischung von Buttermilch und Magermilch wird als Sauermilch, Trinksauermilch oder Saure Magermilch bezeichnet. Als Trockenmilcherzeugnis wird Buttermilchpulver aus diesen Erzeugnissen hergestellt.

Buttermilch enthält beispielsweise 3,5 g Eiweiß, 0,5 g Fett und 4,0 g Kohlenhydrate pro 100 g (100 ml), zudem keine Ballaststoffe, 1 mg Cholesterin und 750 mg Mineralstoffe. Der physiologische Brennwert entspricht somit 156 kJ (37 kcal) pro 100 g. In Buttermilch sind auch Vitamin B2, B5 und B12 sowie Calcium, Kalium und Phosphat in größeren Mengen vorhanden.



</doc>
<doc id="13016" url="https://de.wikipedia.org/wiki?curid=13016" title="Musical Instrument Digital Interface">
Musical Instrument Digital Interface

Musical Instrument Digital Interface, [], (engl. „digitale Schnittstelle für Musikinstrumente“), kurz: MIDI [] ist ein Industriestandard für den Austausch musikalischer Steuerinformationen zwischen elektronischen Instrumenten, wie z. B. Keyboards oder Synthesizern. Dieser Standard umfasst sowohl die genaue Beschaffenheit der erforderlichen Hardware als auch das Kommunikationsprotokoll für die zu übermittelnden Daten. MIDI 1.0 wurde im August 1982 eingeführt und ist inzwischen mehrfach erweitert worden. Entwickelt wurde MIDI von Dave Smith in Kooperation mit Ikutaro Kakehashi von der Roland Corporation, wofür beide im Jahr 2012 mit dem technischen Grammy ausgezeichnet wurden.

Das MIDI-Protokoll wurde ursprünglich zur Kommunikation von Synthesizern unterschiedlicher Hersteller entwickelt. Der eigentliche Sinn war, von einer Tastatur eines Synthesizers aus weitere Synthesizer anzusteuern. Davor konnten Synthesizer nur analog und mit großem Verkabelungsaufwand verbunden werden.

Zu der damaligen Zeit hatten die Synthesizer nur wenige Stimmen, d. h., sie konnten meist nur 4–8 Töne gleichzeitig erzeugen. Trotz einer gewissen Soundauswahl konnte kein Gerät mehr als einen Sound gleichzeitig erzeugen. Wollte man also zwei oder mehrere Sounds mit einem Tastendruck spielen, musste man zwei Geräte mit einer Tastatur verkoppeln. So konnte man unterschiedliche Sounds übereinanderlegen, um z. B. einen „dickeren“ Synthesizerstreicherklang zu bekommen oder Synthesizerstreicher mit Synthesizerbläsern zu kombinieren.

Das war nun mit der Verbindung über ein einzelnes MIDI-Kabel möglich, indem der MIDI-Out des Hauptgerätes mit dem MIDI-In des angesteuerten Gerätes per 5-poligem MIDI-Kabel verbunden wurde (wobei nur zwei Pole genutzt werden). Da die Audiosignale der verschiedenen Synthesizer keine MIDI-Steuerdaten sind, müssen diese über zusätzliche Leitungen einem Mischpult zugeführt werden.

MIDI trennte auch gleichzeitig die Tastatur eines Synthesizers von seiner Klangerzeugung, was natürlich die Einsatzmöglichkeiten eines Instrumentes massiv erhöhte:
Denn so war es auch möglich, eine Tastatur aufzuteilen (splitten) und die Tastaturbereiche auf verschiedene Synthesizer zu verteilen. So konnte der Keyboarder z. B. mit dem linken Tastaturbereich einen Streicherklang mit einem angesteuerten Synthesizer und mit der rechten Hand einen Solo-Synthesizerklang mit dem lokalen Gerät spielen.

Schnell wurde die MIDI-Schnittstelle für fast jede Art an elektronischen Musikinstrumenten adaptiert, so z. B. für Expandermodule, Sampler, Drumcomputer, Effektgeräte (Hall, Echo, Equalizer usw.), Hardwaresequencer (Aufnahme- und Abspielgeräte für MIDI-Daten), Computer, "Controller" (wie Masterkeyboards, Drum-Pads, Masterkeyboardcontroller, Standard-Midi-File-Player, Fader-Boxen, später auch für Sound- und Audiokarten usw.), nicht zuletzt auch – zweckentfremdet – zur Steuerung von Lichteffekten für Bühnen (MIDI Show Control).

Der Einsatz von Computern in der Tonstudiotechnik gab MIDI einen weiteren Schub. So konnte der wenig versierte Keyboarder mit Hilfe eines Hardwaresequencers bzw. des Computers und eines Sequencerprogrammes komplexe, schwierige oder gar manuell unspielbare Musikstücke erstellen, weil er die MIDI-Daten im Sequencer verändern und korrigieren konnte. Dadurch, dass nur die Steuerdaten gespeichert werden, kann der Sound auch nach einer Aufnahme im Sequencer beliebig ausgetauscht werden. Das ergab völlig neue Möglichkeiten – auch für versierte Musiker – und hat Auswirkungen auf die Produktionsweise von Musik bis heute:

Komposition, Arrangement und Notensatz wurden durch die Verbindung von MIDI-fähigem Keyboard und Computer erheblich vereinfacht. Variationen von Stimmen und Songabläufen sind sehr schnell realisierbar und bleiben jederzeit änderbar. Diese Zeitersparnis ist u. a. bei Studioproduktionen ein wichtiger Faktor. Der Komponist greift oft zwar auf das Hilfsmittel Computer zurück und editiert sein Konzept direkt über Software, viele Stimmen werden jedoch nach wie vor über eine Klaviertastatur bzw. ein Masterkeyboard eingespielt.

Mit speziellen Wandler-Geräten kann man auch aus den Tönen beliebiger akustischer Instrumente wie Gitarre oder Saxophon MIDI-Daten erzeugen. Dabei muss aus einem komplexen Klangmuster die gespielte Tonhöhe ermittelt werden, was, abhängig vom Instrument und der Spielweise, bald an Grenzen stößt. Bei einer Gitarre z. B. muss interpretiert werden, ob ein Ton durch einen Bundwechsel oder Ziehen einer Saite entstanden ist. Aber für viele Anwendungen ist das nicht erforderlich, und so kann man mit einem akustischen Instrument und einem über MIDI angeschlossenen Synthesizer oder Sampler völlig andere Sounds in Kombination oder eigenständig erzeugen.

In den 2000er Jahren, als der Speicher in Mobiltelefonen noch knapp war, benutzte man das MIDI-Format auch für Klingeltöne.

Spielt man auf einem Keyboard eine Taste, werden digitale Informationen über Tonhöhe und Anschlagstärke am MIDI-Ausgang des Keyboards ausgegeben und lassen sich an den MIDI-Eingang eines Computers übermitteln oder zur Steuerung der Klangerzeuger in elektronischen Instrumenten und Soundkarten verwenden. Solche Befehle sind beispielsweise "Note-on" („Taste für Note x wurde gedrückt“) und "Note-off" („Taste für Note x wurde wieder losgelassen“).

Ein vollständiger 3-Byte-Datensatz für einen Spielbefehl für eine Note könnte beispielsweise wie folgt aussehen:


Diesen Ton spielt ein angesteuerter Klangerzeuger so lange, bis dieser den 3-Byte-Befehl mit einem "Note aus"-Byte anstelle des "Note ein"-Byte empfängt. Welchen Sound der Klangerzeuger spielt, wird entweder zuvor am Klangerzeuger oder mit weiteren MIDI-Befehlen vor dem Spielbefehl für die Note eingestellt.

Ein Computer kann diese Informationen aufzeichnen, abspeichern und in verschiedenen Editoren visualisieren, eingeben und manipulieren. Üblich sind hierbei ein Listeneditor, in dem MIDI-Daten an sich editiert werden, der wohl am meisten verwendete Piano-Roll-Editor, der eine Klaviertastatur mit einem Zeitverlauf darstellen kann und ein Noteneditor, der die Notenschrift auch auf dem Bildschirm sichtbar macht. Letzterer ist aber oft in der Praxis nicht zu gebrauchen, weil das Notenbild völlig zerrissen aussieht, wenn Noten manuell ohne weitere Bearbeitung eingespielt werden.

Gleichzeitig oder auch später können die aufgezeichneten Daten an ein MIDI-Instrument zurückgesendet werden. So wird die Eingabe von Spielinformationen von der Tonerzeugung getrennt.

Neben den musikalischen Befehlen können weitere Datenpakete zur Steuerung des Zielgerätes genutzt werden, so etwa "Program-Change-Befehle" zur Auswahl eines seiner meist vielen hundert Klangspektren. Viele Klangerzeuger wie Synthesizer, Expander und andere verstehen Befehle, mit denen ihre interne Klangerzeugung direkt beeinflusst werden kann, um so aus einer Reihe einfacher Grundschwingungsformen komplexe, individuelle Klänge zu erzeugen.

Inzwischen nutzen neben elektronischen Instrumenten auch zahlreiche andere Geräte wie beispielsweise (digitale) Mischpulte und Mehrspuraufzeichnungsgeräte das MIDI-Protokoll, um darüber Steuerinformationen auszutauschen. Anstatt MIDI-Datenpakete zur Übertragung von Notenbefehlen zu nutzen, können die Daten hier beispielsweise zum Fernbedienen sämtlicher Mischpultfunktionen (Fader, Muteschalter, Panorama, etc.) oder zur Steuerung der Laufwerksfunktionen eines Recorders (Play, Stopp, Vor-/Rückspulen) verwendet werden.

MIDI verwendet ein unidirektionales Protokoll zur seriellen Datenübertragung ohne Datenflusskontrolle. Die Übertragungsgeschwindigkeit beträgt 31250 Bit/s (exakt 32 µs pro Bit). Zu jedem Byte, bestehend aus 8 Bit, kommt ein Start- sowie ein Stopp-Bit, sodass die komplette Übertragung eines Datensatzes bestehend aus 30 Bits 960 µs dauert. Bis auf das Fehlen des Parity-Bits entspricht es damit dem Protokoll bei PC-UARTs.

Im Unterschied zu pegelgesteuerten Schnittstellen wird bei MIDI jedoch eine 5-mA-Stromschleife verwendet. Physisch sind die Anschlüsse als fünfpolige DIN-Buchsen (DIN 5/180° – früher Diodenbuchse/-stecker) realisiert. Die Pins 4 und 5 werden als Datenleitung benutzt. Dabei liegt gemäß der MIDI-Spezifikation Pin 4 über einen 220-Ohm-Widerstand an +5 V. Pin 5 kann über 220 Ohm mit 0 V verbunden werden. Ist am anderen Ende ein MIDI-In-Port angeschlossen (nochmals 220 Ohm in Reihe mit einem Optokoppler), fließt ein Strom über die Leitung, dieser Zustand ist als logische „0“ definiert. Wird Pin 5 nicht verbunden, fließt kein Strom, was als logische „1“ gilt und auch den Ruhezustand darstellt.

Laut einer nachträglichen Erweiterung der MIDI-Spezifikation sind nun auch MIDI-Ausgänge möglich, die auf einer 3,3 V-Spannungsversorgung beruhen. In diesem Fall werden Serienwiderstände von 33 Ohm und 10 Ohm an Pin 4 bzw. an Pin 5 eingesetzt.

Durch den Optokoppler in der Empfangsleitung ergibt sich eine galvanische Trennung der einzelnen MIDI-Geräte untereinander, die Masseleitung (Pin 2 und Kabelabschirmung) darf an der MIDI-In-Schnittstelle nicht angeschlossen werden, um Masseschleifen zu vermeiden.

In manchen Ausnahmen (z. B. bei der MIDI-Interface-Karte „Roland MPU-401 AT“ als ISA-Karte) sind die Anschlüsse auch als 6-polige Mini-DIN-Buchsen ausgelegt. In solchen Fällen hilft ein Anschlussadapter, der baugleich zu einem Tastaturadapter „Mini-DIN-Stecker zu DIN-Buchse“ (PS/2 auf AT) ist.

Es existieren drei verschiedene Arten von MIDI-Anschlüssen, "MIDI-In", "MIDI-Out" und "MIDI-Thru".

MIDI arbeitet nach dem Master-Slave-Prinzip. Will man mit einem Keyboard einen Synthesizer steuern, verbindet man die MIDI-Out-Buchse des Keyboards (Master) mit der MIDI-In-Buchse des Synthesizers (Slave). Sollen mit einem Keyboard (Master) zwei Soundmodule als Slave A und B angesteuert werden, verbindet man die MIDI-Out-Buchse des Masters mit der MIDI-In-Buchse des Slave A sowie die MIDI-Thru-Buchse des Slave A mit der MIDI-In-Buchse des Slave B.

Ein häufig anzutreffendes Szenario ist der Einsatz eines Computers mit entsprechender Sequenzer-Software sowie der Anschluss eines Keyboards oder elektronischen Pianos zum Einspielen der Noten und mehreren Synthesizern zur Klangerzeugung. Dabei wird üblicherweise die MIDI-Out-Buchse des Keyboards mit der MIDI-In-Buchse des Computers verbunden, die MIDI-Out-Buchse des Computers mit den MIDI-In-Buchsen der Synthesizer, ggf. verkettet über die MIDI-Thru-Buchsen. Zu beachten ist, dass sich dabei die unvermeidlichen Verzögerungen im MIDI-Datenstrom summieren und damit zu Timingfehlern führen können. Eine sternförmige MIDI-Verkabelung, bei der das Master-Keyboard seine Daten an einen zentralen Verteiler (MIDI-Patchbay) sendet, an dem alle weiteren MIDI-Geräte angeschlossen sind, beseitigt solche Probleme.

Ein Masterkeyboard erzeugt Noteninformationen im MIDI-Format und dient ausschließlich der Steuerung von Expandern, Software-Synthesizern oder zur Aufzeichnung der Tastenbewegung beim Einspielen von Musik in Sequenzer. Es enthält keine eigene Klangerzeugung. Die Klangsteuerung an den Geräten kann über gerätespezifische Steuerfunktionen wie Bankumschaltung geschehen.

Dem gegenüber stehen die reinen MIDI-Controller. Dabei handelt es sich um Geräte ohne Tastatur, die lediglich Knöpfe und Drehregler besitzen, mit denen eingehende Daten modifiziert oder dem Datenstrom neue Daten auf anderen Kanälen hinzugefügt werden. Sie werden zwischen ein Masterkeyboard und einen Empfänger – oder parallel dazu geschaltet.
Heute werden oft kombinierte Eingabegeräte verwendet, die sowohl Noten- als auch umfangreiche Kontrollfunktionen ausüben können. Einige erzeugen reine MIDI-Informationen, andere sind zusätzlich oder alleinig an den PC anschließbar.
Für viele akustische Musikinstrumente existieren Tonaufnehmer zur Erzeugung von MIDI-Signalen (z. B. Guitar-to-MIDI-Converter, Piano-Aufsetzer etc.) Hier wird die akustische Schwingung durch ein Mikrofon aufgenommen und in eine MIDI-Tonhöhe umgerechnet, indem ein Grundton ermittelt und Controllerwerte zur Modulation desselben erzeugt werden. Damit sind Töne variierender Tonhöhe (Vibrato) erzeugbar. Einige dieser Systeme eignen sich auch zum Aufnehmen des menschlichen Gesangs. So können komplexe Stimmverläufe wie blue notes und Phrasierungen z. B. durch Pfeifen auf das Notenpapier gebracht werden.

Eine Reihe von Instrumenten existieren heute als reine MIDI-Geräte, bei denen die Tonerzeugung ausschließlich mit einem Expander möglich ist. Beispiele dafür sind MIDI-Geigen, MIDI-Gitarren, Blaswandler und das MIDI-Schlagzeug.

Um mit einem Computer über MIDI zu kommunizieren, muss ein "Signal-Konverter" zwischengeschaltet werden, der gewöhnlich als MIDI-Interface bezeichnet wird. Er übersetzt die Spannungspegel und sorgt für eine galvanische Entkopplung. Im Prinzip kann jede serielle Datenübertragungs-Schnittstelle eines Computers mit einem geeigneten MIDI-Interface für die MIDI-Übertragung genutzt werden.

Eine Pionierrolle spielte der Commodore 64, auf dem insbesondere die deutschen Softwareautoren Gerhard Lengeling und Karl Steinberg ihre ersten Sequenzer programmierten, die für die Namen C-LAB, Emagic und Steinberg stehen.

Der kommerzielle Durchbruch für MIDI als Plattform für professionelle Musikproduktion ist eng mit dem Atari ST verbunden, da dieser standardmäßig mit einer MIDI-Schnittstelle ausgeliefert wurde. Die Entwicklung wichtiger MIDI-Programme wie Cubase (Steinberg) oder Notator (Lengeling) begann auf dem Atari ST.

Auf dem Commodore Amiga prägte die Softwarefirma Blue Ribbon Inc. mit "Bars & Pipes Professional" ein neues Sequenzer-Software-Prinzip, das durch seine frei programmierbare Plugin-Schnittstelle in seinen Funktionen fast beliebig erweiterbar ist. Die meisten MIDI-Interfaces für den Commodore Amiga wurden als Adapter für die serielle Schnittstelle angeboten und sind mit einem MIDI-In, einem MIDI-Thru und meistens drei MIDI-Out ausgestattet. Es gibt sowohl synchrone als auch asynchrone MIDI-Interfaces. Bei einem asynchronen MIDI-Interface sind die verschiedenen MIDI-Out-Schnittstellen unabhängig voneinander ansteuerbar. Bei drei MIDI-Out-Schnittstellen gibt es also 48 MIDI-Kanäle (3×16).

Hier handelte es sich ursprünglich um eine 8-Bit-ISA-Steckkarte des Herstellers Roland. Viele für MS-DOS-PCs erhältliche Computerspiele zwischen 1988 und 1995 unterstützen diese MIDI-Schnittstelle zur Ansteuerung von Klangerzeugern wie z. B. der internen Roland LAPC-I oder dem externen MT-32. Andere Hersteller wie bspw. Creative Labs unterstützten den MPU-401-Modus nur eingeschränkt im so genannten Dumb-Mode "(UART)", während der "Intelligent-Mode", der genaues Timing durch Hardwareunterstützung garantierte, nur von Rolands eigenen Produkten beherrscht wurde.

Die standardmäßigen DIN-Buchsen für MIDI sind zu groß, um direkt in die Rückplatte einer PC-Steckkarte eingebaut zu werden. Lange Zeit war die übliche Vorgehensweise, die MIDI-Signale, die an einem kombinierten Game-/MIDI-Anschluss entsprechender Soundkarten verfügbar waren, über einen Adapter (siehe MIDI-Anschlüsse) auf die Standard-MIDI-Schnittstelle umzusetzen. Ältere PC-Soundkarten, ausgehend vom Soundblaster, haben einen Anschluss geprägt, bei dem sich Game-Interface und MIDI-Interface eine 15-polige D-Sub-Buchse teilen und der heute immer noch in billigeren, nicht professionellen MIDI-Interfaces in PCs vertreten ist. Die Soundkarte braucht dabei nur zwei digitale, serielle Leitungen ohne Datenflusskontrolle zur Verfügung zu stellen (MIDI verwendet keine Datenflusskontrolle). Bei dieser Art der Hardware-Implementierung ist ein Teil des MIDI-Interfaces in einen externen, oft separat zu erwerbenden Teil verlegt, der meist in dem dickeren Stecker eines Kabels vergossen ausgeführt ist. Motherboards, die Sound-, MIDI- und Game-Controller "on-Board" haben, haben diese kombinierte Game-/MIDI-Anschlussbuchse übernommen. Dem entsprechen Sound-, Game- und MIDI-Chipsätze, die diese Funktionalitäten teilweise oder ganz gemeinsam integrieren. Das Vorhandensein einer 15-poligen D-Sub-Buchse an sich erlaubt jedoch noch keinen Rückschluss darauf, ob ein MIDI-Interface vorhanden ist oder, falls vorhanden, von welcher Qualität es ist.

Softwareseitig war die Hardware meistens MPU-401-kompatibel. Vorher waren auch MIDI-Interfaces für die serielle (COM) und parallele (Druckerport) Schnittstelle im Gebrauch. Professionelle MIDI-Geräte für PCs benutzen oft proprietäre (herstellerspezifische) Buchsen zwischen Steckkarte und dem externen Gerät. Inzwischen gibt es jedoch viele MIDI-Interface-Geräte für USB, FireWire (mLAN) und LAN.

Ein "Expander" ist ein externer Klangerzeuger ohne eigene Tastatur. Er empfängt Noten ausschließlich per MIDI. Nur Parameter, die sich mit Knöpfen am Expander einstellen lassen, werden zurück übertragen und können aufgezeichnet werden.
Ein Expandermodul erweitert die Möglichkeiten eines Tastatur-Synthesizers oder Keyboards. Wie ihre Pendants mit Tastatur können Expander viele Formen der Klangerzeugung zur Verfügung stellen. Wegen ihres geringen Platzbedarfs sind sie von ihrer Bedeutung her mindestens ebenso relevant wie die Tastaturversionen für die Entwicklung und Verbreitung von MIDI.

Die Expandertechnik bietet die Möglichkeit, in relativ kleinen Geräten eine Vielfalt von Klängen zu erzeugen. Ohne sie hätte sich Midi sicher weniger schnell und weniger weit verbreitet, denn andere Verfahren verbieten sich vielerorts wegen ihres Platzbedarfs und ihrer Kosten.

Die Klangerzeugungsverfahren von Expandermodulen kann man in zwei Grundklassen aufteilen:


Diese Klangerzeuger stellen eine Vielzahl unterschiedlicher Grundklänge (Multisamples) zur Verfügung, die einfach abgespielt werden. Sie dienen dazu, einen Grundvorrat an Imitationsklängen natürlicher Instrumente bereitzustellen. Deshalb waren diese Geräte von Anfang an mit mindestens 16 Stimmen und mit mindestens 6 Klangfarben ("Timbres") ausgestattet. Dank dieser "Multitimbralität" können mehrere unterschiedliche Klänge auf unterschiedlichen Midikanälen abgerufen werden. In der Anfangszeit war dies nur mit wenigen Geräten möglich.

Diese Klangerzeugerklasse war zum Beginn der Expanderzeit am weitesten verbreitet. Beispiele sind "Roland U110" und "Roland U220". Etwas später bekamen diese Geräte einfache Bearbeitungsfunktionen, also einfache Filter. Dadurch wurden sie jedoch nicht zu ausgewachsenen Synthesizern, denn diese Filter dienten mehr zur Klangverfeinerung als zur echten Neuschaffung von Klängen. Ein Beispiel ist der "Korg M1r".

Sampler stellen keine Klänge zur Verfügung, sondern können diese aufnehmen und abspielen. Meist werden Samples aus einer Sound-Library in das Gerät geladen. Mit Samplern kann der Benutzer eigene Multisamples erstellen und so eine aufwändig zusammengestellte Instrumentenimitation schaffen. Sampler können auch Bearbeitungsfunktionen wie Loops bereitstellen. Sampler lassen neuartige Spielweisen für Musiker zu, beispielsweise das Verwenden von Drum-Loops und One-Shot-Effektsounds innerhalb einer Keymap, das heißt einer Tastaturzusammenstellung von verschiedenen Samples.

Die Samplertechnik hat die moderne Musik maßgeblich geprägt. Musikstile wie Hip Hop wären ohne Sampler nicht vorstellbar. Einen großen Einfluss hat diese Technik auch auf die Filmmusik. Gute Orchesterimitationen sind bis heute nur mit aufwändiger Samplingtechnik möglich.

Sampler wurden und werden auch im Live-Betrieb oft verwendet, beispielsweise um die Klangeigenschaften eines echten Schlagzeugs durch Samples zu erweitern, oder um Chöre oder Backing-Vocals bei kleinen Bandbesetzungen bereitzustellen. Die Chorsamples drückt ein Keyboarder mit einer Taste ab, oder der Schlagzeuger löst sie mit einem E-Pad per MIDI-Befehl aus.

Fast alle weitverbreiteten Sampler wurden nur als Expanderversionen ausgeführt. Ein bekanntes Beispiel ist die Akai-S-Serie.

Es gibt eine Vielzahl von samplebasierten Synthesetechniken:


Jede Klangerzeugung hat einen eigenen Charakter. Eine Auswahl an Geräten mit Tastatur live oder im Tonstudio bereitzustellen, ist aus Platzgründen oft nicht möglich, weshalb hier meist Expander zum Einsatz kommen.

Diese Geräteklasse ist ähnlich umfassend, wie die der samplebasierten Synthesizer, wobei die Klangerzeugung rein "synthetisch" geschieht. Sie reicht von modularen, analogen Schrankwänden, beispielsweise von Doepfer, bis hin zu digitalen Kleinstmodulen in Halbzollgröße.

Viel verwendete Syntheseverfahren sind (kleine Auswahl):

Virtuelle Simulationen sind die modernste Art der Synthese, sie bilden akustische, mechanische, elektrische und elektronische Bauweisen der Instrumente nach, weshalb sich ihre Bedienung an den baulichen Eigenheiten orientiert und deshalb völlig verschieden ist von den klassischen Syntheseverfahren. Ein Beispiel wäre das virtuelle Öffnen des Flügeldeckels, was einen mechanischen Vorgang widerspiegelt. Für einen Filter hingegen gibt es keine echten Gegenpart, er bleibt ein elektronischer Vorgang, der von der Charakteristik der elektronischen Schaltung abhängt.

Beispiele für virtuelle Synthese sind „virtuell-analoge“ Synthesizer, „virtual Strings“ für Gitarren-, Bassgitarren- und Streichinstrument-Simulationen; „virtual Brass“ für Blasinstrument-Simulationen, diverse Orgel-, Piano- und E-Piano-Simulationen für mechanische und elektromechanische Instrumente.

Unterschiedliche Synthesetechniken erfordern unterschiedliche Bearbeitungsweisen. Mittlerweile sind viele Expandermodule mit Steuerelementen wie Reglern, Fadern und Schaltern ausgestattet, die MIDI-Signale senden können. So können beispielsweise Regelverläufe eines Filters vom Regler eines Expandermoduls an einen Sequenzer zur Aufzeichnung gesendet werden. Ihre Midi-Noten-Befehle können sie durch den Sequenzer oder von einer Tastatur erhalten. Viele dieser Geräte sind daher je nach Situation Sender, Empfänger oder beides gleichzeitig.

Expandermodule werden normalerweise in genormter 19-Zoll-Bauweise hergestellt. Es gab und gibt immer wieder Ausnahmen. In den Anfangszeiten von MIDI gab es noch häufiger Geräte, die nicht dieser Norm entsprachen.

Der "Hardware-Sequenzer" dient der Aufzeichnung der MIDI-Daten und dem Arrangement eines Musikstückes. MIDI-Sequenzer erlauben das Programmieren, die Aufzeichnung sowie die Wiedergabe von aufgezeichneten oder programmierten MIDI-Informationen (Notenwerte, Anschlagsstärke sowie weiteren Steuerungsbefehlen wie z. B. Modulation). Für den Live-Einsatz erfreuen sich auch die in Keyboards oder Groove-Boxes integrierten Sequenzer großer Beliebtheit. Eine Kombination aus Klangerzeuger und Synthesizer, Masterkeyboard und Hardware-Sequenzer wird als Workstation bezeichnet.

"Softwaresequenzer" haben im Bereich der Komposition große Bedeutung, da sie über die Standardfunktionen (Programmieren, Aufzeichnen, Abspielen) hinaus auch weitere Bearbeitungsmöglichkeiten in grafischer Form bieten (nachträgliches Editieren, Quantisierung usw.) und heutzutage nicht nur MIDI-, sondern auch Audiomaterial verarbeiten können. Diese Kombination aus Audio- und MIDI-Bearbeitung auf einem PC nennt man DAW (Digital Audio Workstation).

Die heute überwiegend verwendeten Sequenzerprogramme sind das bereits erwähnte Cubase von Steinberg für Mac (OSX) und Windows-PC und sein Pendant Logic, das, inzwischen von Apple aufgekauft, nur noch für Apple Macintosh bezogen werden kann. Steinberg (einschließlich Cubase) wurde inzwischen von Yamaha aufgekauft. Daneben gibt es Rosegarden und MusE auf unixartigen Plattformen und einige weitere Lösungen wie Sonar, Ableton Live, REAPER, Renoise oder auch Reason.

Zahlreiche digitale Effektgeräte und Mischpulte sind heute ebenfalls über MIDI-Controller-Befehle steuerbar. Auf diese Weise können Aktivitäten am Pult mit einem Sequenzer oder einem PC aufgezeichnet werden, um z. B. einen Livemix nachzubearbeiten oder komplizierte Aktionen vorwegzunehmen. Auch sind Standardmischungen für bestimmte Aufnahmesituationen abspeicherbar. Größere Pulte der FOH sowie Monitormischpulte sind auf diese Weise durch Musiker fernsteuerbar.

Das Protokoll wurde 1981 von Dave Smith für die Audio Engineering Society entwickelt und von der MIDI Manufacturers Association erstmals 1983 auf der NAMM-Show in Anaheim, USA, vorgestellt. Der MIDI-Standard wird von der MMA (MIDI Manufacturers Association) festgelegt.

Der folgende Abschnitt erfordert das Verständnis des Hexadezimalsystems. Ein Byte ist aus zwei Hexadezimalziffern zwischen 0 und 15 aufgebaut, wobei die Zahlen ab 10 mit A bis F notiert werden. Eine 2-stellige Hex-Zahl besitzt damit einen Zahlenbereich von 0 bis 255.

Die meisten MIDI-Befehle enthalten neben ihrer Befehlskennung und den Befehlsdaten auch eine Kanalnummer. Die Kanalnummer ist 4 Bit groß, so dass sich 2, also 16 Kanäle ansteuern lassen. Jeder Kanal steuert ein spezielles Instrument, auch „Programm“ genannt.

Das Statusbyte ist das erste Byte eines Befehls. Außerdem enthält das Statusbyte den betreffenden MIDI-Kanal "n". Dieser reicht von 0 bis 15. In vielen Programmen wird bei der Darstellung der Kanalnummer die tatsächliche Kanalnummer um 1 erhöht dargestellt, also von 1 bis 16 statt von 0 bis 15. Die folgenden Bytes sind Datenbytes. Um einen unterbrochenen Datenstrom jederzeit korrekt wieder aufnehmen zu können beginnt ein Statusbyte stets mit einer 1 und ein Datenbyte mit einer 0. So liegen die Statusbytes im Bereich 80 bis FF und die Datenbytes zwischen 00 und 7F. Kommt anstelle eines erwarteten Statusbyte ein Datenbyte, dann gilt das letzte Statusbyte als wiederholt und das aktuelle Datenbyte zählt zu dessen Daten.

Zweck eines MIDI-Controllers (Continuous Controller = CC, vordefinierter, festgelegter Controller) ist es, dem Anwender für sein Instrument die typischen Spielhilfen bereitstellen zu können, so z. B. dem Klavierspieler ein Haltepedal (CC064) oder dem Orgelspieler einen Lautstärkeregler (CC007 bzw. CC011) und einen Lesliegeschwindigkeitsumschalter (z. B. CC004, CC006).

Dem Synthesizerspieler beispielsweise stehen eine ganze Reihe weiterer Beeinflussungsregler für sein Spiel zur Verfügung, z. B. ein Modulationsrad (CC001), Pitch-Bending-Hebel, diverse Pedale und Fußschalter, weitere Schiebe- und Druckregler und -schalter, Blaswandler (CC002), Steuerungen per Licht für die Hände. Es gibt sogar – externe – Steuerungen für das Gehirn (Brain-to-Midi).

So kann eine gute Haptik und Kontrolle bei der Beeinflussung seiner Spielweise ein ausdrucksstarkes Spielen ermöglichen. Dazu haben die Spielhilfen meist mechanisch bewegliche Elemente, die der Benutzer bedienen kann. Diese Bewegung wird in Nachrichten (Controllerdaten) übersetzt und an die Geräte sowie Klangerzeuger weitergegeben. Sie arbeiten somit ähnlich wie Gamecontroller. Teilweise sind die Spielhilfen per MIDI-Protokoll an bestimmte Controllerbefehle gebunden, wobei meist sowohl die Spielhilfen beim Sender (z. B. Tastatur) wie auch beim Empfänger (Expandermodul, Plugin) frei auf andere Controller(befehle) umgeändert werden können (z. B. Modulationsrad als Lautstärkeregler).

Erst in neuerer Zeit nutzt man Controller verstärkt auch derart, dass die ursprüngliche Semantik ignoriert wird. Dem Befehl werden ganz andere Funktionen zugeordnet als im MIDI-Protokoll vorgesehen. Das ist häufig der Fall, wenn die Musikbearbeitung ausschließlich auf einem Computer durchgeführt wird. Insbesondere bei DJ-Programmen sind angepasste Controller sehr verbreitet. Hier wird zum Beispiel mit dem MIDI-Signal ein Dialog zur Songauswahl geöffnet, oder Funktionen wie Start, Stopp werden steuerbar. Auf der anderen Seite können Anzeigeelemente in Controllern bedient werden. Der semantisch mit der Tonhöhe belegte MIDI-Befehl kann so beispielsweise die Länge einer Wiederholungsschleife codieren. Gerade hier ist die Controllerhaptik wichtig, da sich mit der Maus am Computer die erforderliche Reaktionszeit und Feinfühligkeit zum Beispiel bei der Synchronisierung des Beats zweier Songs nicht erreichen lässt. Dem proprietären Charakter dieser Anwendungsart kann durch freie Belegbarkeit der MIDI-Befehle sowohl im Programm als auch im Controller begegnet werden, was allerdings noch lange nicht die Regel ist.

Klassische Anwendungen des MIDI-Controllers halten sich hingegen streng an die Semantik des Protokolls. Diese haben im Bereich der Musikerzeugung größere Bedeutung, da sich mit ihnen auf einfache Art und Weise gerätespezifische Klangparameter des aktuellen Instruments steuern lassen. Unterschiedliche Geräte sind dabei untereinander austauschbar.

Die Controller senden auf einem bestimmten Kanal mit einer bestimmten Controllernummer einen bestimmten Wert. Einfache Controller können Werte von 0 bis 127 annehmen, was jedoch bei Tonhöhenänderungen sehr schnell zu unschönen treppenhaft-sprunghaften Tonhöhenveränderungen führt. Daher lassen sich die Controller 0–31 mit einem sogenannten LSB-Controller 32–63 koppeln, um so eine wesentlich höhere Auflösung zu erhalten. In der Praxis wird diese Technik jedoch selten angewandt, da eine Auflösung der Lautstärke beispielsweise in 128 Schritten ausreichend ist.

Schalter wie beispielsweise das Haltepedal Nummer 64 können zwar theoretisch Werte zwischen 0 und 127 senden, da ein Schalter allerdings nur zwei Werte annehmen kann, werden üblicherweise Werte von 0 bis 63 als „aus“ und Werte von 64 bis 127 als „ein“ interpretiert.

Wird ein programmierbares Steuergerät verwendet, so sind Kenntnisse der Controllernummern und was diese üblicherweise steuern von großem Nutzen. Die wichtigsten Controller sind in der nachfolgenden Tabelle zusammengestellt. Das erste Byte eines Controllerbefehles lautet immer B"n", wobei "n" die Kanalnummer angibt und "vv" für den Wert, den der zu steuernde Klangparameter annehmen soll, steht.

Die allgemeinen (RPN - Registered Parameter Number) und die herstellerspezifischen (NRPN - Non Registered Parameter Number) Controller dienen dazu, Parameter zu steuern, die im normalen Controller-Bereich keinen Platz finden. Es können Parameter mit einem Index zwischen 0 und 16383 verändert werden. Zum Setzen der Indizes dienen die Controller
Danach wird entweder ein normaler MIDI-Controller (06) mit einem Wert zwischen 0 und 127 gesendet oder ein Data Increment/Decrement (60 oder 61), wobei hier das dritte Byte ignoriert wird. Wichtig ist, dass der MSB-Controller immer vor dem LSB-Controller versendet wird. (siehe Tabelle).

"Systemexklusive Meldungen" (SysEx) sind Bestandteil des MIDI-Übertragungsprotokolles.

Während die übrigen MIDI-Befehle weitgehend als ein Standard festgelegt sind, wurde speziell durch die systemexklusiven Meldungen sichergestellt, dass die Hersteller von Hard- und Software auch Informationen übertragen können, die im MIDI-Protokoll nicht vorgesehen sind. So kann zum Beispiel der Speicherinhalt eines Gerätes zur Datensicherung an einen Rechner gesendet werden. Auch können Modellbezeichnungen zwischen den Geräten ausgetauscht werden. Das MIDI-Protokoll garantiert, dass systemexklusive Meldungen nicht durch andere Befehle unterbrochen werden. Daher werden systemexklusive Meldungen in Pausen übertragen, so dass es zu keinen unschönen Aussetzern oder Verzögerungen kommen kann.

Eine systemexklusive Meldung beginnt mit F0 und endet mit F7. Das zweite Byte ist die Herstellerkennung, die von der MIDI Manufacturers Association vergeben wird und weltweit eindeutig ist. Ist das zweite Byte gleich 00, identifizieren die beiden folgenden Bytes den Gerätehersteller. Die Herstellerkennung ermöglicht den Geräten eine Filterung, was den entsprechenden Geräten die Interpretation der Meldungen ermöglicht. Zwischen der Herstellerkennung und dem Schlusszeichen folgen beliebig viele Datenbytes, die aber nur Werte zwischen 00 und 7F enthalten können und so nur einen 7-Bit-Zeichensatz ermöglichen. In der Regel werden zu Beginn zuerst einige Bytes gesendet, die festlegen, für welches Gerät die Nachrichten bestimmt sind. Die Bedeutung legt der entsprechende Hersteller fest.

Beispiele:

Synchronisation ist immer dann nötig, wenn zwei oder mehrere MIDI- bzw. Audiogeräte zu einem System zusammengeschlossen werden müssen.

Dazu gibt es zwei MIDI-Protokolle:
Die ältere und tendenziell unpräzisere MC (Midi-Clock), die auf das Grundtempo eines Songs referenziert und eher für den musikalischen Einsatz vorgesehen ist, und den neueren MTC (Midi-Time-Code), der auf ein absolutes Zeitsystem referenziert und für Aufnahmesysteme relevant ist.

Jeder Systemverbund hat genau einen "Master", alle anderen Geräte sind "Slaves", die dem Master folgen müssen.

Synchronisation ist in vielen Bereichen notwendig. Dabei kann man zwei grundsätzlich verschiedene Einsatzzwecke feststellen, aus denen sich diverse Mischformen ergeben:

Hier werden verschiedene Aufnahme-, Wiedergabe- und Bearbeitungssysteme zu einer Systemeinheit verbunden. Sie sollen also zeitgleich und synchron starten, stoppen und mitlaufen und natürlich auch nicht während des Musikstücks auseinanderlaufen, was passieren würde, wenn man die einzelnen Systeme manuell gleichzeitig starten würde. Genau das übernimmt der MTC und verhindert derartige Probleme.

Einige Synchronisierungsbeispiele aus der Praxis (MTC):

Bei (analogen) Bandmaschinen muss vor einer Aufnahme der Timecode auf das Band aufgespielt werden. Dabei wird ein SMPTE-Timecode auf die letzte Spur (8-Spur auf Spur 8, 16-Spur auf Spur 16 usw.) der Maschine aufgenommen, der von einem SMPTE-Generator erzeugt wird. Ein SMPTE-Code stört durch Übersprechen daneben liegende Kanäle, weshalb man auf die Außenspur ausweicht, um neben der SMPTE-Code-Spur nur noch eine weitere Spur für Aufnahmen zu verlieren.

Aus dem aufgenommenen SMPTE-Code „liest“ ein SMPTE-Reader das Signal aus und wandelt es in MTC, das von den daran angeschlossenen Geräten gelesen werden kann.

Da nur professionelle Maschinen aufwändige Synchronisatoren besitzen, sind meist die Bandmaschinen MTC-Master über den SMPTE-Code, denen alle anderen Systeme folgen müssen. Ein weiterer Grund ist, dass selbst professionelle Bandmaschinen immer eine Spulzeit haben, weshalb es selten einen Sinn ergibt, beispielsweise eine DAW als Master einzusetzen.

Je nach Art des SMPTE-Codes kann es durchaus einen Sinn ergeben, bei Überspielungen von Bandmaterial auch den alten Timecode vom Band mit als Audiosignal aufzunehmen, um Rechendifferenzen zu minimieren. Manchmal aber ist der Timecode bei alten Bändern so schlecht, dass eine Synchronisation nicht möglich ist, so dass alle Spuren mit einem Mal aufgenommen werden müssen. Den Timecode kann man nachträglich mit spezieller Software bzw. Geräten reparieren und wieder nutzbar machen.

Hier werden Sequencer und Synthesizer bzw. Effektgeräte miteinander gleichgeschaltet, um musikalisch wichtige Ereignisse auszulösen.

Einige Synchronisierungs-Beispiele aus der Praxis (MC):

Die Möglichkeiten für den Einsatz von MC ist nur begrenzt durch die technischen Möglichkeiten der angeschlossenen Geräte.

Die MIDI-Clock basiert auf Takt- und Notenebene. Die Einheit ist ein Tick, ein 96tel eines Schlages (bei vielen Liedern Viertelnote). Die Dichte, mit der die Clock-Informationen gesendet werden, ergibt sich daher aus der gewählten BPM-Einstellung des Liedes. Folgende Messages sind möglich:

Durch diese Signale starten alle Sequenzer gleichzeitig, folgen dem gegebenen Tempo und stoppen auch wieder gleichzeitig.

Während MC im Grunde lediglich Clock-Ticks sendet, ist SPP dafür zuständig, die Position im Song zu übermitteln. Er wird jede Sechzehntelnote übertragen und ist auf maximal 1024 Takte beschränkt.

Die relativ grobe Unterteilung von SPP-Befehlen dient zur groben Gleichschaltung von Geräten, während die exakte Gleichschaltung per MC erfolgt.

Angeschlossene Geräte können so auch im "Stopp-Modus" eines Sequenzers erkennen, an welcher Stelle in einem Musikstück sie sich befinden. Außerdem können sie bei bestimmten Songpositionen Funktionen ausführen, z. B. dass Drumcomputer vorprogrammierte Wiederholungen auslösen.

Der "MIDI timecode" (MTC) ist eine Umsetzung des SMPTE-Timecodes auf das MIDI-Format. Im Gegensatz zur MIDI-Clock ist der MTC eine reine Zeitinformation, eine Umrechnung auf Lied, Position innerhalb des Liedes und Abspieltempo muss durch die Software erfolgen.

Bei größeren Sprüngen der Position sendet der Master die absolute Position innerhalb einer SysEx-Message


Während des Abspielens werden nur Short-Messages gesendet
Das Byte xx ist in der Bit-Darstellung am besten verständlich

Bei Rücklauf des Bandes kommen die Messages allerdings in umgekehrter Reihenfolge.

Für das Speichern von MIDI-Befehlen in "Standard-MIDI-Files" (kurz: SMF) gibt es drei Dateiformate:

Die standardisierte Dateiendung für MIDI-Dateien ist .mid. Daneben finden noch .kar Verwendung. Diese sogenannten Karaoke-Dateien enthalten den gesamten Liedtext. Das Dateiformat ist exakt dasselbe wie bei .mid. Viele Programme erkennen Dateien mit der Endung .kar jedoch nicht als MIDI-Dateien. (Die Datei kann aber in der Praxis einfach umbenannt werden.) Windows unterscheidet die Dateien, so dass erkennbar bleibt, dass es sich um eine Karaoke-Datei handelt. Die Datei kann trotzdem sowohl mit Karaoke-fähiger Software als auch mit normalen „Playern“ abgespielt werden. Microsoft benutzt die Endung .rmi für RIFF-RMID-Dateien. Bei diesen ist eine reguläre MIDI-Datei in einen RIFF-Container verpackt. RIFF-RMID ist kein offizieller MMA- oder AMEI-MIDI-Standard. Für Dateien, die MIDI-SysEx-Daten enthalten, wird .syx verwendet. Meist sind das Sound-Presets von Synthesizern.

Da MIDI im Wesentlichen ein Datenprotokoll zur Steuerung von elektronischen Musikinstrumenten darstellt, ist es prinzipiell unerheblich, über welche Hardware die Daten übertragen werden. Um eine kostengünstige, plattformübergreifende und vor allem schnelle Anbindung externer MIDI-Interfaces an einen Rechner zu erreichen, statten immer mehr Hersteller ihre Geräte neben den klassischen MIDI-Anschlüssen mit USB- oder FireWire-Anschluss (IEEE1394) aus. Dabei werden die MIDI-Befehle über USB bzw. FireWire getunnelt. Auf diese Art lassen sich mehrere virtuelle MIDI-Verbindungen realisieren, wodurch die Begrenzung auf 16 pro Verbindung praktisch keine Rolle mehr spielt. Diese Art von MIDI-Interfaces stellt die im Vergleich zum PC-Gameport deutlich zuverlässigere Variante zum Anschluss von MIDI-Geräten an den Rechner dar, da die verwendeten Treiber von den Herstellern dieser verhältnismäßig teuren Geräte zumeist auf Timinggenauigkeit hin optimiert werden. Für den professionellen Einsatz werden Interfaces mit vier bis acht einzeln adressierbaren Out-Ports verwendet, mit denen Timingprobleme deutlich vermindert werden können (vgl. auch folgender Absatz).

Wichtig ist zu wissen, dass sich das USB-MIDI-Protokoll vom herkömmlichen MIDI-Protokoll unterscheidet. Die dort genannten „Jacks“, max. 16 pro USB-Endpoint, haben jeweils wieder 16 Kanäle.

Dem Trend hin zur drahtlosen Datenübertragung folgend werden auch Geräte angeboten, mit denen sich MIDI-Daten per Funk übertragen lassen. Die Geräte benutzen in der Regel Übertragungsfrequenzen im ISM-Band und senden bei Übertragungsfehlern ein „ALL NOTES OFF“, um hängende Töne zu vermeiden. Laut Herstellerangaben haben diese Geräte eine Reichweite von 10 bis 80 Metern.

Seit einiger Zeit gibt es eine Reihe von virtuellen Gerätetreibern, die es erlauben, MIDI-Daten über IP-basierende Netzwerke zu übermitteln. Während die meisten dieser Produkte auf proprietärer Basis die MIDI-Daten per TCP oder UDP über das Netzwerk übertragen, gibt es mittlerweile auch einen RFC für eine genormte Übertragung von MIDI-Daten über Netzwerke auf Basis des RTP-Protokolls: RFC 4695. Es gibt mehrere Open-Source-Implementierungen dieses Standards und auch das Apple-Netzwerk-MIDI von Mac OS X Tiger und iOS 4.2 basiert auf dieser Spezifikation. Es existiert auch ein Windows RTP-MIDI Treiber, welcher auf Windows XP bis Windows 7 (32-Bit and 64-Bit) läuft und kompatibel zur Apple-Implementation ist.

Bis vor Kurzem gab es Bemühungen, den von Yamaha entwickelten mLAN-Standard als Verknüpfung von MIDI- und Audiodaten auf der Basis von FireWire zu etablieren. Dies konnte sich jedoch nicht durchsetzen und wurde inzwischen eingestellt.

Eine weitere Option ist die Übertragung von MIDI-Daten über S/PDIF-Schnittstellen.

Bevor MIDI entstand, war digitale Audioaufzeichnung noch extrem teuer und damit wenigen Produktionen vorbehalten. Somit eröffnete das technisch nicht sehr aufwendige MIDI mit seiner enormen Leistungsfähigkeit mittels Aufzeichnung reiner Steuersignale Anfang der 1980er Jahre einer breiten Masse von Musikschaffenden plötzlich neue Horizonte. Dank MIDI können auch Amateurmusiker mit entsprechenden Kenntnissen komplexere musikalische Strukturen kreieren. Beispielsweise können Streicher und Bläser synthetisch imitiert werden, während man Schlagzeug, Gitarre und Gesang über Audiospuren einspielt.

MIDI-Signale enthalten lediglich Steuerdaten. Digitale „Audiosignale“ hingegen sind ein kontinuierlicher binärer Datenstrom, entstanden durch die sehr schnelle Abtastung (Digitalisierung) analoger Schwingungen einer Audioquelle (Mikrofon oder elektronisches Instrument). Sie haben eine konstant hohe Datenrate und können nach erfolgter Digital-Analog-Wandlung über ein Verstärker-Lautsprecher-System hörbar gemacht werden. MIDI-Daten fallen nur an, wenn Tasten auf einem Keyboard gedrückt oder losgelassen werden. So entstehen bei MIDI ungleich geringere Datenmengen. Aufgezeichnete MIDI-Signale können leicht im Nachhinein an einen anderen Klangerzeuger gesendet werden. Auch besteht die Möglichkeit, eingespielte MIDI-Daten im Nachhinein beliebig zu editieren, um etwa falsche Töne auf die richtige Tonhöhe oder Abspielposition zu bringen oder ihre Dynamik anzupassen. All diese Veränderungen der Originaleinspielung kosten im Vergleich zur Nachbearbeitung von digitalen Audioaufzeichnungen sehr wenig Rechenaufwand und sind mit allen heute verfügbaren Sequenzerprogrammen möglich.

Die Geschwindigkeit der MIDI-Schnittstelle ist vom technischen Standpunkt überholt.
Da für das Auslösen eines Tons bis zu 3 Bytes übertragen werden müssen, was 0,960 ms in Anspruch nimmt, kommt es bei mehreren Events, die eigentlich gleichzeitig gesendet werden sollen, zu Verzögerungen, die bei Instrumenten mit deutlichem Anschlag auch hörbar werden können.
Eine deutlich hörbare, durch MIDI verursachte Verzögerung tritt normalerweise auf, wenn zu viele MIDI-Daten auf einmal übertragen werden sollen, wie in den folgenden Beispielszenarien:

Bei Studioarbeit werden dagegen mehrere Maßnahmen ergriffen:
Bei Live-Anwendungen sind diese Maßnahmen allerdings oft nicht möglich. Ein Masterkeyboard hat üblicherweise nur ein MIDI-Out, das heißt, alles, was dort an Noten und Controllern ausgelöst wird, muss über diese eine Schnittstelle.

Trotz dieser Einschränkungen und des hohen Alters erfreut sich MIDI nach wie vor großer Beliebtheit, da es weit verbreitet, gut standardisiert und sehr zuverlässig ist. Eine Fortentwicklung wäre aus technischer Sicht vielleicht wünschenswert, hätte aber für den normalen Anwender mehr Komplikationen als Vorteile. Eine neue MIDI-Spezifikation würde möglicherweise alle vorher produzierten Instrumente inkompatibel machen. Weiterhin ist zu bedenken, dass heute vornehmlich mit Plugins in der Musikproduktion gearbeitet wird, wo das MIDI-Timing kein Problem darstellt.

Die Präzision einer MIDI-Sequenz ist auf 1/96 einer Viertelnote definiert (siehe MIDI Clock), in einigen Fällen können Sequenzerprogramme eine noch höhere Genauigkeit erreichen (bei der Verwendung von Plugins). Das bedeutet, dass die kleinste reproduzierbare Timingschwankung vom Songtempo abhängig ist. In einem Lied mit 120 bpm beträgt dieser Wert 5,21 Millisekunden.

Von Yamaha gibt es mit XG-MIDI eine Erweiterung, die genau wie Rolands GS-MIDI Verbesserungen in der Kompatibilität von Standard-MIDI-Files bringt, allerdings nicht über ein proprietäres System hinaus gedieh. Als Quasi-Standard durchgesetzt hat sich lediglich GM (General MIDI). Beide Standards nutzen das normale MIDI-System ohne Änderungen an der MIDI-Hardware oder dem Protokoll.

Schwerer wiegen die Einschränkungen musikalischer Art: MIDI wurde für die Steuerung von Synthesizern konzipiert, die überwiegend in derselben temperierten Stimmung betrieben werden. Für nicht-temperierte Stimmungen oder andere Skalen müssen die Notenwerte entweder per Controller im Sequenzer künstlich modifiziert oder in den Endgeräten uminterpretiert werden. Viele hochwertige Keyboards verfügen inzwischen über eine Stimmungseinstellung, die das bewerkstelligt. Für komplexere Stimmungprobleme und alle anderen Geräte existiert spezielle Software (sog. Mikrotuner). Diese setzt wiederum eine MIDI-Schnittstelle (z. B. USB-MIDI-Adapter) am Rechner voraus.

Alle analogen und kontinuierlichen Aspekte wie die Anschlagdynamik, das Verhalten des Klangs während des Drückens (after touch) und nach dem Loslassen der Taste sowie die Echtzeitmodifikationen der Amplitude, der Frequenz etc. sind in den 128 Stufen des MIDI-Formats aufgelöst. Das schafft unweigerlich eine verfälschende Vergröberung des manuellen Spiels schon bei der Aufnahme und verhindert eine stufenlose Änderung, was vor allen bei der Lautstärke und dem Spieltempo problematisch ist. Zwar werden in vielen modernen Keyboards, Klangerzeugern und Synthesizern die ankommenden Controllerwerte geglättet und sanft auf neue Werte übergegangen, dennoch hat damit der Musiker nur eine eingeschränkte Kontrolle über den Klang.

Ein reales Instrument verfügt über keinerlei Abstufung in Tonhöhe oder Lautstärke. Selbst bei der Steuerung von künstlichen Klangparametern bei Synthesizern, wie z. B. der Cutoff-Frequenz eines Filters, macht sich diese „Stufigkeit“ teilweise hörbar bemerkbar.

Auch Instrumente mit scheinbar festen Tonhöhen wie Flöten oder Klaviere besitzen eine gewisse Varianz in der Tonhöhe während des Spiels, die bei Blasinstrumenten vom Luftstrom und bei Saiteninstrumenten vom Anschlag und der Momentanlautstärke sowie allerlei Resonanzeffekten abhängt. Die während eines komplexen Tonverlaufes existierenden Schwankungen der Tonparameter Amplitude und Phase sind daher nur sehr grob von MIDI-Hard- und Software nachzubilden bzw. zu erzeugen. Bei anschlagsdynamischen Instrumenten macht sich dieses besonders bemerkbar (Bösendorfer 290SE). Auch Vibrato und Blue-Note-Technik kann kaum korrekt abgebildet werden.

Dieses Problem kann nur durch die Nutzung zweier aufeinander folgender MIDI-Controller umgangen werden, was den zeitlichen Rahmen weiter einschränkt. Ein anderes Beispiel für die Benutzung zweier verknüpfter Controller ist der Bank Select-Befehl (MIDI CC 0 und 32 des General-MIDI-Standards), der es erlaubt, bis zu 128 Bänken zu adressieren. Jede Bank kann wiederum Subbänke (max. 128) enthalten. Auf diese Weise können theoretisch 16384 Soundbänke, jede einzelne mit 128 Klängen, realisiert werden. Spezielle Klangbibliotheken bieten deshalb verschiedene Artikulationen und Spielweisen akustischer Instrumente an, um diesen Nachteil zu umgehen.





</doc>
<doc id="13018" url="https://de.wikipedia.org/wiki?curid=13018" title="Maß">
Maß

Maß steht für:


Gewässer:


Personen:

Mass steht für:


Personen:

MASS steht für:

Siehe auch:



</doc>
<doc id="13019" url="https://de.wikipedia.org/wiki?curid=13019" title="Burgenland">
Burgenland

Das Burgenland (burgenlandkroatisch "Gradišće," /, oder neuerdings ) ist ein Bundesland von Österreich. Landeshauptstadt ist Eisenstadt. Von den neun Bundesländern Österreichs ist es das östlichste und gemessen an seiner Einwohnerzahl kleinste. Das Gebiet gehörte einst zum Königreich Ungarn, das im Vertrag von Trianon 1920 verpflichtet wurde, das damalige Deutsch-Westungarn an die neue Republik Österreich abzutreten. 1921 kam die Landnahme des Burgenlandes zu einem Abschluss; das neu hinzugekommene Land wurde danach in Burgenland umbenannt.

Das Burgenland grenzt im Norden an das Pressburger Land (Slowakei), im Osten an die Komitate Győr-Moson-Sopron und Vas (beide Ungarn), im Süden auf wenigen Kilometern an die zwei Gemeinden Kuzma und Rogašovci (Slowenien) und im Westen an die österreichischen Bundesländer Steiermark und Niederösterreich.

Die Außengrenzen zu den vorgenannten Staaten bildeten bis zum 21. Dezember 2007 auf 397 km die Schengener Außengrenze der EU.

Das Burgenland ist geprägt vom Neusiedler See im Norden und den Ausläufern der Alpen im hügeligen Süden, es ist langgezogen und verengt sich bei Sieggraben im Ödenburger Gebirge auf eine Breite von 4 km. Das Burgenland ist Mitglied der Europaregion Centrope.

Ungefähr 700 v. Chr. siedelten die Illyrer in Eisenstadt, Donnerskirchen und Purbach. Circa 400 v. Chr. siedelten Kelten auf dem Gebiet des heutigen Burgenlands. Etwa um die Zeit Christi Geburt kam das Burgenland zum (antiken) Römischen Reich; sein Gebiet gehörte zur Provinz Pannonien. Die Römerherrschaft endete im Jahr 378 n. Chr. Daraufhin wurde das Land von den Ostgoten besiedelt. Von 433 bis 453 n. Chr. herrschten hier die Hunnen. Im Jahr 454 wurde der spätere Ostgotenkönig Theoderich der Große in der Gegend des Neusiedler Sees geboren. Auf die Hunnen folgten von 490 bis 568 die Langobarden. Von 600 bis 800 wurde das Land von den Awaren beherrscht. Ende des 8. Jahrhunderts besiegte der Frankenkönig Karl der Große die Awaren und das Land wurde als Teil der Awarenmark in das Fränkische Reich eingegliedert. Nach 800 erfolgte die erste deutsche Besiedlung unter Karl dem Großen. Im 9. Jhdt. war es Teil des slawischen Plattensee-Fürstentums und des Großmährischen Reiches. 907 eroberten die Magyaren das Land.

Um 1260 besaßen die Güssinger Grafen 25 Burgen im Gebiet. Auch die aus Aragonien in Spanien stammenden Mattersdorf-Forchtensteiner Grafen hatten große Besitzungen im heutigen Nord- und Mittelburgenland inne. Zur Zeit der ersten Wiener Türkenbelagerung im Jahr 1529 wurden die Ortschaften des Seewinkels verwüstet. Um 1530 wurden Kroaten im heutigen Burgenland angesiedelt. Das seit den Türkenkriegen vorwiegend deutsch besiedelte Gebiet, Teil des Königreichs Ungarn, war von den ungarischen Königen im Mittelalter an die Habsburger als Erzherzöge des benachbarten Österreich unter der Enns und als Herzöge der ebenfalls angrenzenden Steiermark verpachtet worden. Als Habsburg 1526 die ungarische Königskrone erbte, wurde diese Verpachtung obsolet. 1622 wurde Nikolaus Esterházy mit der Herrschaft Forchtenstein belehnt, 1648 mit Eisenstadt.

Von 1648 bis 1921 befand sich das Gebiet in ungarischer Verwaltung. 1664 hatte das Land unter dem Türkenkrieg, 1678 unter dem Kuruzenkrieg zu leiden. Zur Zeit der zweiten Wiener Türkenbelagerung wurde das nördliche Burgenland abermals schwer getroffen.

Nach dem österreichisch-ungarischen Ausgleich 1867 wurde auch das später "Deutsch-Westungarn" genannte Gebiet der in ganz Altungarn einsetzenden Magyarisierung unterzogen: dem Versuch, die nichtmagyarischen Völker des Königreichs Ungarn, die etwa 50 % der Gesamtbevölkerung ausmachten, sukzessive zu Magyaren (Ungarn) zu machen bzw. sie zu assimilieren. Dem stand das von Woodrow Wilson am Ausgang des Ersten Weltkrieges für die Völker der Donaumonarchie geforderte Selbstbestimmungsrecht der Völker gegenüber.

Als die Habsburger-Monarchie Österreich-Ungarn 1918 zerfiel, beanspruchte der neu gegründete Staat Deutschösterreich unter anderem den deutschsprachigen Teil Westungarns für sich. In dem zwischen Österreich und den Siegermächten des Ersten Weltkrieges abgeschlossenen Vertrag von St. Germain wurde das Gebiet 1919 Österreich zuerkannt; Ungarn musste sich im Vertrag von Trianon 1920 dazu verpflichten, es abzutreten. Nach Errichtung der kurzlebigen Republik Lajtabánság unter Führung des Freischärlerbefehlshabers Pál Prónay im Oktober 1921 wurde das Gebiet im Folgemonat durch das österreichische Bundesheer besetzt und am 5. Dezember 1921 von Ungarn an Österreich offiziell übergeben. Die Haltung der deutschsprachigen Siedler in Westungarn zum Anschluss an Österreich war (eher) aus wirtschaftlichen Gründen uneinheitlich.

Nach heftigen Protesten Ungarns wurde für Ödenburg "(Sopron)," das als Hauptstadt des neuen Bundeslandes vorgesehen war, und seine Umgebung eine Volksabstimmung durchgeführt, die zum Verbleib Ödenburgs bei Ungarn führte. Bei der Volksabstimmung ergab sich im Gesamtergebnis eine eindeutige Zwei-Drittel-Mehrheit für Ungarn. Die Gemeinden um Ödenburg stimmten für Österreich (blieben aber dennoch bei Ungarn, da das Abstimmungsgebiet nur insgesamt gewertet wurde); die Bevölkerungsmehrheit in der Stadt Ödenburg stimmte für einen Verbleib bei Ungarn.

Die Aufnahme des Landes in die Republik Österreich wurde im "Bundesverfassungsgesetz über die Stellung des Burgenlandes als selbständiges und gleichberechtigtes Land im Bund und über seine vorläufige Einrichtung" vom 25. Jänner 1921 geregelt.
Von einigen Befürwortern der Eingliederung in die Republik Österreich wurde die Landesbezeichnung "Heinzenland" (nach dem Hianzn-Dialekt, siehe auch die kurzlebige Republik Heinzenland) propagiert, der Vorschlag Burgenland setzte sich schließlich durch.

Die Übernahme des Burgenlandes in österreichische Verwaltung erfolgte im Herbst 1921. Bis 1925 war Bad Sauerbrunn provisorischer Sitz der Landesregierung und -verwaltung; dann wurde die bis dahin relativ unbedeutende Kleinstadt Eisenstadt (ungarisch: Kismarton) zur Hauptstadt des Burgenlands bestimmt.

Im „Großdeutschen Reich“ nach dem „Anschluss“ Österreichs wurden die Städte Eisenstadt, Rust und die Bezirke Eisenstadt, Mattersburg, Neusiedl am See und Oberpullendorf per 15. Oktober 1938 dem Reichsgau Niederdonau zugeschlagen, die Bezirke Güssing, Jennersdorf und Oberwart dem Reichsgau Steiermark.

Nach dem Ende des Zweiten Weltkrieges und der Wiedererrichtung der Republik Österreich 1945 (Zweite Republik) entstand auch das Burgenland als Bundesland wieder. Bis 1955 lag es in der sowjetischen Besatzungszone, bis 1989 bestand an seiner Ostgrenze der Eiserne Vorhang.

Der Name „Burgenland“ erinnert daran, dass das Land aus Teilen von drei altungarischen Komitaten zusammengesetzt ist, die alle „Burg“ im Namen trugen. Kurios ist dabei die Tatsache, dass sich keine der drei namensgebenden Burgen im Burgenland befindet. Sie liegen alle auf ungarischem Staatsgebiet:

Anfang 1919 wurden von Österreich auch Teile des Komitats Pressburg (slowakisch Bratislava, ungarisch "Pozsony") für das Burgenland beansprucht. Man schlug daher im Juni 1919 den Namen „Vierburgenland“ vor. Mitte August 1919 zeichnete sich aber in den Friedensverhandlungen ab, dass Pressburg an die Tschechoslowakei ging. Der Politiker Karl Renner empfahl (von Saint-Germain aus), den Namen auf „Dreiburgenland“ zu ändern.

Der Name Burgenland wurde angeblich vom Frauenkirchener Gregor Meidlinger erstmals vorgeschlagen, und zwar am 6. September 1919 nach der Vorsprache einer deutsch-westungarischen Delegation bei Staatskanzler Karl Renner. Dieser Name wurde spätestens mit dem Bundesverfassungsgesetz über die Stellung des Burgenlandes als gleichberechtigtes Bundesland vom 25. Jänner 1921 allgemein gebräuchlich.

Das Burgenland weist eine Fläche von 3.965,46 km² auf, und teilt eine 397 km lange Staatsgrenze zum Großteil mit Ungarn, zu kleinen Teilen auch mit Slowenien und der Slowakei.

Höchste Erhebung des Burgenlandes ist der 884 m hohe Geschriebenstein "(Írott-kő)", durch dessen Gipfelwarte die Staatsgrenze verläuft. Tiefster Punkt ist der Hedwighof (Gemeinde Apetlon – Bezirk Neusiedl am See) mit 114 m.
Tiefste Gemeinde ist Illmitz mit 116 m.

Der geografische Mittelpunkt des Burgenlandes, (Koordinaten: 47°28'34" N, 16°34'24" O) befindet sich in Unterpullendorf (Gemeinde Frankenau-Unterpullendorf) und wurde von Geografen des Burgenlandes durch den „Mittelpunktstein“ (Basaltstein vom Pauliberg) markiert. Im Süden sind Riedel landschaftsprägend.

Es wird landschaftlich in drei Regionen eingeteilt, wobei das Mittelburgenland manchmal dem Südburgenland zugerechnet wird.


Das "Nordburgenland" nördlich des Ödenburger Gebirges gehört landschaftlich großteils zur Pannonischen Tiefebene und zählt die Bezirke Eisenstadt, Eisenstadt-Umgebung, Neusiedl am See, Mattersburg und Rust. Hier liegt der Neusiedler See, ein von einem breiten Schilfgürtel umgebener Steppensee, das „Meer der Wiener“. In seiner Nähe bietet das Naturschutzgebiet Lange Lacke seltenen Vogelarten ein Refugium. Im Jahr 1992 wurde in diesem Gebiet der Nationalpark Neusiedler See-Seewinkel gegründet, der grenzüberschreitend im ungarischen Nationalpark Fertő-Hanság seine Fortsetzung findet.

Das "Mittelburgenland", bestehend aus dem Bezirk Oberpullendorf, ist hingegen hügelig und wird im Süden durch das Günser Gebirge, in dem sich der 884 Meter hohe Geschriebenstein befindet, vom ebenfalls hügeligen Südburgenland getrennt. Charakteristisch für das Mittelburgenland ist der lehmige Boden. Dazwischen befinden sich einige Hügel aus Basalt, die von früherer Transdanubische Vulkanregion stammen. Entwässert wird das ganze Gebiet vom Fluss Rabnitz (Donau), der in Richtung Osten zur Donau fließt.

Das "Südburgenland" besteht aus den Bezirken Güssing, Jennersdorf und Oberwart. Das hügelige Gelände fällt vom oststeirischen Hügelland und dem Günser Gebirge in Richtung Südosten ab. Die höchsten Erhebungen in diesem Teil südlich des Günser Gebirges gehen nur knapp über 400 Meter Seehöhe. Der Süden wird vom Fluss Raab und seinen vielen Zu- und Nebenläufen geprägt.

Beinahe die gesamte Fläche des Burgenlandes entwässert über die Raab in die Donau.
Während der Neusiedler See über den Einserkanal tributär ist, bestimmen im Südburgenland die Pinka und die Raab selbst die Gewässer. Im äußersten Norden bildet die Leitha den historischen Grenzfluss zu Niederösterreich. Die Wulka entspringt im Rosaliengebirge und mündet in den Neusiedlersee. Die Zöbern ist ein linker Zufluss der Güns und mündet in diese in der burgenländischen Marktgemeinde Lockenhaus. Der Tauchenbach bzw. Tauchen (ungarisch "Tava") ist ein rund 40 km langer Nebenfluss, der linksseitig in die Pinka mündet.

Das Burgenland hat Anteil am illyrischen Klima im Südburgenland und am pannonischen Klima in den restlichen Landesteilen. Das Mittel- und Nordburgenland ist stärker kontinental geprägt als der Landessüden. Die durchschnittlichen Temperaturen betragen hier zwischen −2 °C und −4 °C im Jänner und etwa 21 °C im Juli.

Am 8. August 2013 wurde in Neusiedl am See mit einer Höchsttemperatur von 40,3 Grad Celsius ein neuer burgenländischer Temperaturrekord erreicht.

Das Burgenland besteht aus 171 selbständigen Gemeinden und ist in neun politische Bezirke (inklusive der zwei Statutarstädte Rust und Eisenstadt) gegliedert. Das Burgenland hat 2015 mit im Durchschnitt nur 1686 Einwohnern je Gemeinde von allen Bundesländern Österreichs die geringste durchschnittliche Einwohnerzahl je Gemeinde, siehe dazu auch Gemeinden der Staaten Europas. Ganz Österreich hatte im Jahr 2015 im Durchschnitt 4086 Einwohner je Gemeinde.

Die Landesregierung des Burgenlandes mit dem Sitz im Landhaus besteht aus sieben Mitgliedern, die seit 2015 nach einem Koalitionssystem besetzt werden. Zuvor galt das Proporzsystem.

Seit der Landtagswahl 2015 stellt die SPÖ fünf Regierungsmitglieder, zwei kommen von der FPÖ. Landeshauptmann ist seit 2000 Hans Niessl (SPÖ).


Bei den Gemeinderatswahlen 2012 ging die SPÖ trotz leichter Verluste als stärkste Partei hervor.

Beschreibung: In Gold ein roter natürlich auf einem schwarzen Berg sitzender nach links blickender goldgekrönter rotgezungter und goldbewehrter Adler mit ausgebreiteten Schwingen und über den Sachsen schwebenden schwarzen Tatzenkreuzen. Auf der Brust ein Schild dreimal gespalten in Rot und weißem Hermelin.

Die Online-Plattform "E-Government Burgenland" stellt Online-Formulare und Druck-Formulare für Bürger und Unternehmen bereit, mit denen zeit- und ortsunabhängig Eingaben an das Land Burgenland, seine Behörden und Dienststellen gerichtet werden können. Das Formularservice Burgenland stellt somit eine zentrale Zugangsmöglichkeit zu Formularen aus den vielfältigsten Lebensbereichen wie Arbeit, Bauen und Wohnen, Gesundheit usw. zur Verfügung. Dabei werden Formularlösungen des österreichischen IT-Dienstleisters aforms2web verwendet.

In der wirtschaftlich schwierigen Zeit nach dem Ersten Weltkrieg wanderten viele Burgenländer in die Vereinigten Staaten aus, was zur scherzhaften Mutmaßung führte, dass Chicago zur größten Stadt der Burgenländer wurde. Aber auch durch die wirtschaftlichen Schwierigkeiten in der Zeit des eisernen Vorhanges konnte die wirtschaftliche Entwicklung mit der Restösterreichs nicht mithalten, so dass viele Burgenländer auch heute nach Wien auspendeln. Erst langsam durch einerseits größere EU-Förderungen und der Öffnung und EU-Erweiterung nach Osten entstehen im Burgenland vermehrt Arbeitsplätze mit der Möglichkeit im eigenen Bundesland zu arbeiten.

Bei der Volkszählung von 2001 gaben österreichweit 19.374 Menschen an, Burgenland-Kroatisch zu sprechen, wobei 16.245 im Burgenland selbst ansässig sind. Nach Selbsteinschätzung der Volksgruppe selber beträgt ihre Anzahl 40.000. Dazu kamen 4.704 Burgenland-Ungarn (Selbsteinschätzung 25.000). 263 gaben Romanes als Umgangssprache an. Die wirkliche Zahl der Burgenland-Roma liegt vermutlich jedoch ebenfalls deutlich höher.

Die verschiedenen Volksgruppen sind als autochthone Sprachgruppen gesetzlich anerkannt. Die kroatischen und ungarischen Burgenländer sowie die Sinti und Roma haben daher ein Anrecht auf Verwendung ihrer Sprachen im öffentlichen Schriftverkehr. Aufgrund eines Beschlusses des Ministerrates vom 23. Mai 2000
wurden in Orten bzw. Ortsteilen mit einem Anteil von mindestens 25 % zweisprachiger Bevölkerung (bei der Volkszählung 1991) Ortstafeln mit zweisprachigen Aufschriften deutsch/kroatisch (47 Orte) bzw. deutsch/ungarisch (4 Orte) aufgestellt. Deren Existenz sowie die hohe 25-Prozent-Grenze werden im Burgenland nicht kontrovers diskutiert – im Gegensatz zum Ortstafelstreit in Kärnten.

Obwohl die Mehrheit der Burgenländer wie im übrigen Österreich vorwiegend römisch-katholisch ist, gibt es hier mit 14 % einen relativ hohen Anteil an Protestanten, die in den 29 Pfarrgemeinden der Superintendentur A. B. Burgenland und in der evangelischen Kirchengemeinde H.B. Oberwart organisiert sind. Es gab früher eine große und bedeutende jüdische Kultur, vor allem in den sogenannten „Siebengemeinden“ (Eisenstadt, Mattersburg, Kittsee, Frauenkirchen, Kobersdorf, Lackenbach sowie Deutschkreutz) mit hohem Anteil jüdischer Bevölkerung. In Lackenbach bildeten die Juden 1869 volle 62 % der Bevölkerung; die größte jüdische Gemeinde Burgenlands war jedoch diejenige in Mattersburg. Hier bildeten die Juden bis Ende des 19. Jahrhunderts mehr als ein Drittel der Einwohner. 1938 wurden sämtliche Juden aus dem Burgenland vertrieben oder ermordet, heute erinnert nur noch sehr wenig im Burgenland daran, was einmal war.

Der Landespatron für das Burgenland ist der heilige Martin von Tours.

Mangels Alternativen war das Land lange von der Landwirtschaft geprägt. Als wirtschaftlich unterentwickeltes Bundesland Österreichs wurde das Burgenland 1995 zur Gänze zum Ziel-1-Gebiet der Europäischen Union erklärt. Diese Förderungen liefen in einer „Phasing Out“ Phase bis 2013 weiter. In den zehn Jahren hat sich das Burgenland wirtschaftlich weiter entwickelt. Im Vergleich mit dem Bruttoinlandsprodukt der Europäischen Union ausgedrückt als Kaufkraftstandard (KKS) erreicht die Region einen Index von 89 (EU-28: 100, Österreich: 129) (2014). Nach wie vor herrscht auch ein Nord-Süd-Gefälle in der Wirtschaftskraft. Diese Disparitäten können nur sehr langsam abgebaut werden. Rund 23.000 Burgenländer pendeln je nach Entfernung als Tages- oder Wochenpendler zur Arbeit nach Wien.

Das Burgenland ist sehr landwirtschaftlich geprägt. Mit Niederösterreich ist es das wichtigste Weinbaugebiet Österreichs. Über 16.000 Hektar werden im burgenländischen Weinbau bewirtschaftet. Es wird untergliedert in die Weinbauregionen Neusiedlersee (7.303 Hektar), Neusiedlersee-Hügelland (3.923 Hektar), Mittelburgenland (Blaufränkischland) (2.326 Hektar) und Südburgenland (507 Hektar).

Burgenland ist europäischer Vorreiter im Bereich der Windenergie. Im Jahr 2000 kamen zirka drei Prozent des im Land produzierten Stroms aus Windkraftanlagen, im Jahr 2011 waren es bereits die Hälfte. Bis 2013 sollen es 100 Prozent sein. Derzeit befinden sich mehrere große Windparks in Bau. Der Windpark Andau/Halbturn soll mit 79 Windkraftanlagen des Typs Enercon E-101 und einer installierten Leistung von 237 MW bei Fertigstellung der größte Windpark Mitteleuropas sein.

Ein weiterer wichtiger Wirtschaftsfaktor ist der Sommertourismus.

Die Tourismuszahlen im Burgenland wurden in den letzten Jahren kontinuierlich besser. Jedoch kann es bei den Nächtigungszahlen nicht mit den Tourismushochburgen im Westen Österreichs mithalten. Mangels Skigebieten gibt es kaum Wintertourismus. Zugpferde des Tourismus im Burgenland sind der Neusiedler See, die Thermen Lutzmannsburg (Sonnentherme), Stegersbach und Bad Tatzmannsdorf und nicht zuletzt der Wein, der nahezu im gesamten Burgenland angebaut wird.

Besonders beliebt ist das über 5000 km lange gut ausgebaute Radwegenetz. Obwohl der nördliche Teil des Burgenlandes eher flach ist, können Radtouren anstrengend werden, wenn der Wind durch das Land zieht.

Nicht zu unterschätzen ist auch der Shopping-Tourismus. Nahe Parndorf befinden sich mittlerweile zwei Designer-Outlets, mit über 200 Geschäften und Lokalen. Diese ziehen jährlich über vier Millionen Gäste an, die für Einkaufstouren nicht nur aus dem nahen Wien, sondern aus ganz Osteuropa anreisen und teilweise sogar aus anderen Kontinenten anreisen. Da viele Kunden es nicht schaffen, das ganze Outlet an einem Tag zu bewältigen, hat 2009 sogar ein Hotel am Gelände eröffnet.

Ebenfalls viele Gäste bringen Kulturveranstaltungen ins Burgenland, z. B. die Seefestspiele Mörbisch und die Opernfestspiele in Sankt Margarethen.

Auch ein wichtiger Touristenmagnet ist der Familypark Neusiedlersee, der größte Freizeitpark Österreichs, der jährlich rund 500.000 Gäste anlockt.

Kulturelle Angebote bestehen vor allem im Sommer, mit den Seefestspielen Mörbisch auf der Seebühne am Neusiedler See, den Opernfestspielen im Römersteinbruch St. Margarethen, den Schloss-Spielen Kobersdorf, den Burgspielen Güssing, Musical Güssing, Kultursommer Güssing, Festivalsommer Jennersdorf oder dem Europa-Symposium Kaisersteinbruch mit den Kaisersteinbrucher Konzerten.

Durch die vielen Minderheiten ist das Volksbrauchtum im Burgenland besonders vielfältig. Es werden nämlich auch von den Minderheiten kulturelle Veranstaltungen wie z. B. kroatische oder ungarische Heimatabende abgehalten. Mit Romano Rath aus Oberwart gibt es im Burgenland auch eine bekannte Roma-Band.

In Wiesen finden jährlich von Juni bis September mehrere Festivals statt, bei denen unter anderem Rock, Reggae, Jazz oder elektronische Musik im Vordergrund stehen. Darüber hinaus gibt es zahlreiche Konzerte mit Weltstars verschiedener Genres. Seit 2016 finden auch Jazz- und Rockfestivals in Eisenstadt statt. In Nickelsdorf zieht außerdem Österreichs größtes Rockmusik-Festival, das Nova Rock, jedes Jahr im Juni bis zu 160.000 Gäste aus dem In- und Ausland an. Auch in Nickelsdorf findet das Jazz-Festival Konfrontationen seit 1980 jedes Jahr im Juli statt; neben den Konzerten werden auch Filmvorführungen, Kunstausstellungen, Theaterstücke und Lesungen geboten. Ein weiteres kleines Festival, das aber dennoch regelmäßig namhafte Musiker und Bands ins Burgenland bringt, ist das Picture on im Dorf Bildein. Mit der Cselley Mühle in Oslip verfügt das Burgenland außerdem über ein überregional bedeutendes Aktions- und Kulturzentrum, in dem regelmäßig Konzerte oder Vorstellungen von Kabarettisten stattfinden.

Das Forum „Gewaltfreies Burgenland“ veranstaltet regelmäßig den Literaturwettbewerb „Goldenes Kleeblatt“.

Oberste Dienststelle der Polizei ist die Landespolizeidirektion mit Sitz in Eisenstadt. In jedem Bezirk besteht ein Bezirkspolizeikommando, dem die einzelnen Polizeiinspektionen unterstehen. 2016 wurden, als Pilotversuch in einigen Gemeinden, die Sicherheitspartner gegründet, um das Sicherheitsgefühl zu heben und notfalls die Polizei zu alarmieren.

Für den Brandschutz und die allgemeine Hilfe waren 2011 insgesamt 319 Freiwillige Feuerwehren und 7 Betriebsfeuerwehren verantwortlich, die im burgenländischen Landesfeuerwehrverband organisiert sind. Berufsfeuerwehren gibt es im Burgenland keine. Für die Ausbildung der rund 15.000 Feuerwehrmitglieder besteht in Eisenstadt die verbandseigene Landesfeuerwehrschule.

Den Rettungsdienst führt im Burgenland hauptsächlich das Rote Kreuz durch. Auch der Samariter-Bund unterhält eine Gruppe mit Stützpunkten.

Die Koordination der Blaulichtorganisationen wird im gesamten Bundesland von der "LSZ Burgenland" (Landessicherheitszentrale) mit dem Sitz im Landhaus Eisenstadt durchgeführt. Auch die Sturmwarnungen für den Neusiedler See werden hier ausgelöst.

Die Fachhochschule Burgenland hat zwei Standorte: Der Standort im Norden (Eisenstadt) spezialisiert sich auf Informationstechnologie, Soziale Arbeit und Wirtschaft, der im Süden (Pinkafeld) auf Energie- und Umweltmanagement sowie Gesundheit. Studierende im Burgenland haben keine Studiengebühren zu bezahlen.
Neben der Pädagogischen Hochschule Burgenland und dem Joseph-Haydn-Konservatorium des Landes Burgenland (beide in Eisenstadt), gab es bis 2014 die European Peace University in Stadtschlaining.




</doc>
<doc id="13021" url="https://de.wikipedia.org/wiki?curid=13021" title="Metrisches Einheitensystem">
Metrisches Einheitensystem

Ein metrisches Einheitensystem, kurz metrisches System, ist ein Einheitensystem mit dem Meter als Basiseinheit für die Länge einer Strecke. Anders als bei vielen anderen Einheitensystemen werden im metrischen Einheitensystem unhandlich große oder kleine Angaben strikt als dezimale Vielfache oder dezimale Bruchteile angegeben. Dazu dient ein System von Vorsätzen für Maßeinheiten.

Wichtige Beispiele für metrische Einheitensysteme sind das SI, das cgs- und das mks-System. Das erste metrische Einheitensystem wurde 1793 in Frankreich im Zuge der französischen Revolution eingeführt und wird heute in fast allen Ländern verwendet. Nur die USA sowie Myanmar und Liberia haben es noch nicht verbindlich eingeführt; in weiteren Ländern wie dem Vereinigten Königreich, Kanada oder den Philippinen steht es nach wie vor in Konkurrenz zu älteren Maßsystemen.

Somit basiert das zurzeit wichtigste und auch fast weltweit gültige Internationale Einheitensystem auf dem MKSA-System, welches eine Erweiterung des MKS-Systems um das Ampere ist.

Die internationale Vereinheitlichung des Einheitensystems verhindert Missverständnisse im Umgang mit Größen und Einheiten und macht Größenwerte unmittelbar exakt vergleichbar. Bedeutend ist dies sowohl für Wissenschaft und Technik als auch für Industrie und Handel.

Sowohl für den internationalen als auch den heimischen wissenschaftlichen und wirtschaftlichen Austausch ist ein einheitliches und in sich geschlossenes, also konsistentes Einheitensystem von großem Nutzen, zum Beispiel, um fehlerträchtige Umrechnungen und Missverständnisse durch mehrdeutige Angaben zu vermeiden. So existierten auf dem Gebiet des späteren Deutschen Reiches bis 1870 noch etwa 300 unterschiedliche Flächenmaße. Auch Einheiten gleichen Namens waren bzw. sind unterschiedlich. Beispielsweise ist die deutsche Pferdestärke (PS) nicht gleich der britischen "horsepower" (HP), und für eine Meile existierten über Jahrhunderte hinweg unterschiedliche Definitionen in den verschiedenen Anwendungsbereichen und Regionen. Für die Temperaturmessung wurden verschiedene Skalen genutzt.

In China und Teilen Indiens gab es Dezimalmaßsysteme schon im Altertum. Vorschläge, ein rein dezimales Maßsystem zu schaffen, gab es im Europa der Neuzeit schon seit etwa Ende des 16. Jahrhunderts. Doch bevorzugte man bis Ende des 18. Jahrhunderts die auf hochzusammengesetzte Zahlen hin orientierten alten Maßsysteme. Diese waren aber weder international noch Stellenwertsysteme. Die moderne Ökonomie und Verwaltung ließ beides jedoch zur Effizienzsteigerung als wünschenswert erscheinen. Deshalb führte man im revolutionären Frankreich unter der bürgerlichen Terrorherrschaft das dezimalmetrische System am 1. August 1793 im Nationalkonvent auch ein.

Im 19. Jahrhundert wurden z. B. im Rheinbund nur Vorbereitungen zur Einführung des französischen Dezimalsystems unternommen, etwa durch Dezimalisierung des jeweiligen lokalen bzw. Einführung eines runden, z. B. 30-cm-Fußmaßes. Erst gegen Ende des 19. Jahrhunderts setzte sich das dezimalmetrische System allmählich auch international durch. So wurde am 20. Mai 1875 in Paris die Meterkonvention unterzeichnet, ein diplomatischer Vertrag unter den 17 führenden Industrienationen, die sich darin auf einheitliche Normale für die wichtigsten Größen einigten. Ohne diese Maßnahme wäre die weitere Entwicklung der industrialisierten Welt vielleicht unmöglich gewesen, weil national unterschiedliche Einheiten den internationalen Handel sowie wissenschaftlichen und technischen Austausch enorm erschwert hätten. Die Meterkonvention ist weiterhin gültig und ist Grundlage des Internationalen Einheitensystems (SI). Mit der Pflege des in der Meterkonvention festgelegten Standards wurde die internationale Organisation „Bureau International des Poids et Mesures“ (BIPM) beauftragt.

1874 wurde in Großbritannien das kohärente CGS-System mit drei Basiseinheiten, abgeleiteten Einheiten und den Präfixen „Micro“ bis „Mega“ festgelegt. Da sich die bisherigen Einheiten als zu kompliziert erwiesen hatten, wurden 1880 für die Gebiete der Elektrizität und des Magnetismus zusätzlich „praktische Einheiten“ eingeführt, darunter Ohm, Volt und Ampere.

Auf der ersten „Conférence Générale des Poids et Mesures“ (CGPM) 1889 wurden Meter, Kilogramm und Sekunde als internationale Basiseinheiten festgelegt ("MKS-System"). Die neuen Prototypen für den Meter und das Kilogramm wurden genehmigt und an die Mitgliedstaaten verteilt. Dabei ersetzte der sogenannte Internationale Meterprototyp den Urmeter von 1799. Das Urkilogramm (auch Internationaler Kilogrammprototyp) ist weiterhin gültig. Beide werden in einem Tresor des BIPM in Sèvres bei Paris aufbewahrt.

Der Internationale Elektrische Kongress führte 1893 in Chicago „international“ genannte Einheiten für Spannung und Widerstand ein. Die Internationale Konferenz 1908 in London bestätigte die „internationalen“ Einheiten Volt und Ohm.

1946 kam das Ampere schließlich als weitere Basiseinheit hinzu ("MKSA-System"), und 1954 folgten Kelvin und Candela. 1971 wurde als vorerst letzte Basiseinheit das Mol beschlossen. Die folgende Übersicht zeigt Beispiele dafür, durch welche Definitionen die heutigen SI-Basiseinheiten in der Vergangenheit festgelegt wurden:

Die Einführung des metrischen Systems begann in Frankreich. 1799 wurde der Meter in Paris gesetzlich eingeführt. Die Einführung wurde zeitweise auch wieder rückgängig gemacht. Die radikale Umstellung der Uhrzeiten und des Kalenders auf ein Dezimalsystem setzte sich jedoch nicht durch (u. a. sollte eine Woche aus zehn Tagen bestehen).

Im 19. Jahrhundert wurde das metrische System in den meisten europäischen Staaten eingeführt: in Teilen Deutschlands während der französischen Besatzung vor 1815 (beispielsweise der Pfalz, dort blieb es auch nach der Niederlage Napoleons bestehen), in den Niederlanden, Belgien und Luxemburg 1820, in Spanien in den 1850ern, in Italien 1861, in Deutschland 1872 (Gesetz vom 17. August 1868 für den Norddeutschen Bund, 29. April 1869 für die süddeutschen Länder), in Österreich 1876 (verbindlich, Gesetzesveröffentlichung 1871), in der Schweiz 1877 (legalisiert 1868, durch Bundesgesetz von 1875 verbindlich erklärt; kantonal allerdings zum Teil schon in napoleonischer Zeit eingeführt) und schließlich 1907 in Dänemark. Als letztes europäisches Land befindet sich das Vereinigte Königreich in der Umstellung, in Irland wurde sie am 20. Januar 2005 mit der Umstellung der Verkehrsschilder (km statt Meilen) abgeschlossen. Im englischsprachigen Raum wird die Einführung als „Metrication“ oder „Metrification“ bezeichnet.

Heute wird das metrische System in fast allen Ländern verwendet. Nur die USA sowie Myanmar und Liberia haben es noch nicht verbindlich eingeführt, wobei es jedoch in der Praxis von den beiden letztgenannten genutzt wird. Myanmar beschloss im Jahr 2013 den Übergang zum metrischen System. In den USA sind metrische Einheiten seit einem Parlamentsbeschluss 1866 und einem Regierungsdekret 1894 anerkannte Einheiten.<ref name="NZZ02/05">NZZ Folio 02/05. Neue Zürcher Zeitung</ref> Am 23. Dezember 1975 wurde zwar in den Vereinigten Staaten von Präsident Gerald Ford der vom US-Kongress gebilligte Metric Conversion Act unterzeichnet, doch wird weithin am althergebrachten System festgehalten.

Widerstand gegen die Einführung, meist aus traditionellen oder ästhetischen Gründen, gab oder gibt es besonders in den USA, dem Vereinigten Königreich, Kanada (außer Québec) und Japan. Relikte alter Systeme finden sich in vielen Ländern, z. T. in Form umdefinierter („metrifizierter“) Einheiten (z. B. Pfund zu 500 g) und teilweise durch den Einfluss der US-Wirtschaft (Zoll, z. B. bei Bildschirmgrößenangaben). Dieses Vorgehen ist zwar verbreitet, widerspricht jedoch der Rechtslage. Daher verlangen US-Bundesbehörden in der Regel die Verwendung des metrischen Systems bei Auftragsvergaben (wenn z. B. bei Ausschreibungen technische Unterlagen eingereicht werden müssen).



</doc>
<doc id="13022" url="https://de.wikipedia.org/wiki?curid=13022" title="CGS-Einheitensystem">
CGS-Einheitensystem

Das CGS-Einheitensystem (auch CGS-System, cgs-System, CGS oder cgs, aus dem Englischen „centimetre gram second“) ist ein metrisches, kohärentes Einheitensystem basierend auf den Einheiten "Zentimeter", "Gramm" und "Sekunde". Die CGS-Einheiten der Mechanik lassen sich eindeutig aus diesen Basiseinheiten ableiten, es existieren jedoch mehrere konkurrierende Erweiterungen des CGS-Systems für elektromagnetische Einheiten. Die vier am weitesten verbreiteten Varianten sind:
Nennenswerte Bedeutung hat heute nur noch das gaußsche Einheitensystem, mit „CGS-Einheit“ ist in moderner Literatur meistens eine gaußsche CGS-Einheit gemeint.

Das CGS-System wurde 1874 von der British Association for the Advancement of Science eingeführt und 1889 durch das MKS-Einheitensystem, basierend auf den Basiseinheiten "Meter", "Kilogramm" und "Sekunde", abgelöst. Das MKS wurde seinerseits um die elektromagnetische Basiseinheit "Ampere" erweitert (dann häufig als MKSA-System bezeichnet) und ging schließlich 1960 im "Système International d’Unités (SI)" auf, welches heute zusätzlich die Basiseinheiten "Mol", "Candela" und "Kelvin" umfasst. Auf den meisten Feldern ist das SI das einzig gebräuchliche Einheitensystem, es existieren jedoch Bereiche, in denen das CGS – insbesondere dessen erweiterte Formen – noch Verwendung findet.

Da CGS und MKS (oder das SI im Bereich der Mechanik) auf dem gleichen Größensystem mit den Basisgrößen "Länge", "Masse" und "Zeit" fußen, sind die Dimensionsprodukte der abgeleiteten Einheiten in beiden Systemen gleich. Eine Umrechnung zwischen Einheiten beschränkt sich auf die Multiplikation mit einem reinen Zahlenfaktor. Vereinfachend kommt hinzu, dass nur Umrechnungsfaktoren in Potenzen von 10 auftreten, wie es sich ausgehend von den Beziehungen 100 cm = 1 m und 1000 g = 1 kg ergibt. Ein Beispiel: Für die Kraft ist die abgeleitete CGS-Einheit das dyn (entspricht 1 g·cm·s) und die abgeleitete MKS-Einheit das Newton (entspricht 1 kg·m·s). Damit lautet die Umrechnung 1 dyn = 10 N.

Auf der anderen Seite sind Umrechnungen zwischen elektromagnetischen Einheiten des CGS und denen des MKSA recht umständlich. Während das MKSA hierfür das Ampere als Einheit für die elektrische Stromstärke einführt, benötigt keine der Erweiterungen des CGS eine weitere Basiseinheit. Stattdessen werden die Proportionalitätskonstanten im Coulomb-Gesetz (elektrische Permittivität), im ampèreschen Gesetz und im faradayschen Induktionsgesetz per Definition festgelegt. Die verschiedenen sinnvollen Wahlmöglichkeiten bei der Festlegung haben zu den verschiedenen Ausprägungen des CGS-Systems geführt. In jedem Fall lassen sich alle elektromagnetischen Einheiten auf die drei rein mechanischen Basiseinheiten zurückführen. Allerdings ändern sich dadurch nicht nur die Dimensionsprodukte jener abgeleiteten Einheiten, sondern auch die Form von physikalischen Größengleichungen der Elektrodynamik (siehe z. B. Maxwell-Gleichungen). Es gibt damit keine Eins-zu-Eins-Entsprechung zwischen den elektromagnetischen Einheiten des MKSA (bzw. des SI) und des CGS, auch nicht zwischen den verschiedenen CGS-Varianten untereinander. Umrechnungen beinhalten neben einem reinen Zahlenfaktor eben auch die Größenwerte der obigen, im CGS eingesparten Konstanten.

Das Prinzip der Festschreibung von Naturkonstanten (statt der Einführung von Basiseinheiten) lässt sich auch auf andere Bereiche der Physik übertragen und hat zur Entwicklung weiterer Einheitensysteme wie des atomaren Einheitensystem geführt. Auch das SI setzt in seinen jüngeren Inkarnationen auf diese Methode; im Gegensatz zum CGS und anderen Einheitensystemen werden die bisherigen Basiseinheiten trotzdem als solche weitergeführt.

Wie in anderen Einheitensystemen auch, umfassen die CGS-Einheiten zwei Einheitengruppen, die Basiseinheiten und die abgeleiteten Einheiten. Letztere lassen sich jeweils als Produkt von Potenzen (Potenzprodukt) der Basiseinheiten schreiben. Da das System kohärent („zusammenhängend“) ist, kommen in den Potenzprodukten keine weiteren Zahlenfaktoren vor. Für die CGS-Einheit einer beliebigen Größe "G" heißt das mathematisch:

Dabei sind cm, g und s die Einheitenzeichen der Basiseinheiten Zentimeter, Gramm und Sekunde. Die Exponenten "α", "β" und "γ" sind jeweils positive oder negative ganze Zahlen oder Null. Obige Einheitengleichung kann auch als entsprechende Dimensionsgleichung dargestellt werden:

Dabei sind L, M und T die Dimensionszeichen der Basisgrößen Länge, Masse und Zeit (englisch "time").

Da das MKS-Einheitensystem die gleichen Basisgrößen benutzt, ist die Dimension einer Größe in beiden Systemen gleich (gleiche Basen und gleiche Exponenten im Dimensionsprodukt). Wegen der zwei unterschiedlichen Basiseinheiten stimmen in der Einheitengleichung neben der Basis "s" nur die Exponenten überein. Formal lautet die Umrechnung:
Jeder CGS-Einheit entspricht somit eindeutig eine MKS-Einheit, sie unterscheiden sich nur um einen Zahlenfaktor.

Einigen abgeleiteten CGS-Einheiten wurden eigene Namen und Einheitenzeichen (Symbole) zugeordnet, die selbst wieder mit allen Basis- und abgeleiteten Einheiten kombiniert werden können. So eignet sich zum Beispiel die CGS-Einheit der Kraft, das "Dyn" (= g·cm/s), um die Einheit der Energie, das "Erg", als Dyn mal Zentimeter (dyn·cm) auszudrücken. Die folgende Tabelle listet die benannten Einheiten auf.

Elektrodynamische Größen sind über mehrere Naturgesetze mit mechanischen Größen verknüpft. Die Elektrodynamik selbst wird vollständig durch die Maxwell'schen Gleichungen beschrieben, die sich unabhängig vom Einheitensystem mit Hilfe zweier Proportionalitätskonstanten formula_4 und formula_5 formulieren lassen:

wobei formula_7 die Ladungsdichte und formula_8 die elektrische Stromdichte meint. Wie aus den obigen Gleichungen ersichtlich wird, verknüpft die Konstante formula_4 die elektrische Ladung formula_10 mit der elektrischen Feldstärke formula_11 (Coulomb-Gesetz) und die Konstante formula_5 den elektrischen Strom formula_13 mit der magnetischen Flussdichte formula_14 (Ampèresches Gesetz). Das konstante Verhältnis formula_15 und dessen Kehrwert beschreibt die Abhängigkeit von elektrischem und magnetischem Feld, wenn diese sich zeitlich ändern (Verschiebungsstrom und Induktionsgesetz).

Jedes Einheitensystem der Mechanik kann zur Beschreibung der Elektrodynamik erweitert werden, indem die Größenwerte von jeweils 2 der 3 Konstanten formula_4, formula_5 und formula_15 festgelegt werden. Prinzipiell stehen dazu drei Wege offen:

Im SI wurde der zweite Weg mit der Einführung des Amperes als Einheit von formula_13 und der Definition formula_24 beschritten. Alle Erweiterungen des CGS-Systems setzen hingegen auf den dritten Weg. Folgende Tabelle fasst die unterschiedlichen Einheitensysteme zusammen.

In der Tabelle werden die folgenden Abkürzungen für elektromagnetische CGS-Einheiten mit besonderen Namen verwendet:


</doc>
<doc id="13023" url="https://de.wikipedia.org/wiki?curid=13023" title="CUP-Syndrom">
CUP-Syndrom

Die Abkürzung CUP für das englische „"cancer of unknown primary"“ (verkürzt für: "cancer of unknown primary origin") hat sich auch im deutschen Sprachraum eingebürgert und ersetzt die zuvor übliche Bezeichnung Krebs bei unbekanntem Primärtumor.

Von einem CUP spricht man, wenn sich Metastasen finden, ohne dass der maligne (bösartige) Primärtumor bekannt ist. In der Regel handelt es sich dabei histologisch um neuroendokrine Tumoren wie kleinzellige Bronchialkarzinome, Karzinoide oder maligne Melanome.

Bei etwa 3–5 % aller Krebspatienten ist der Primärtumor unbekannt. Die Prognose ist dabei ausgesprochen ungünstig. Weniger als 25 % der Patienten überleben das erste Jahr nach der Diagnosestellung.

Bei einem CUP besteht eine histologisch nachgewiesene Metastasierung eines unbekannten Primärtumors. Die Primärtumorsuche umfasst eine dermatologische Untersuchung der gesamten Haut, einschließlich Gehörgang, Nase, Mundraum und Anus, ferner eine ausgiebige Sonografie aller inneren Organe, die Endoskopie des Magens, des Darms und der Lunge sowie Untersuchungen mit hochauflösenden bildgebenden Verfahren wie Computertomografie und Magnetresonanztomografie, bei Frauen außerdem noch eine gynäkologische Untersuchung und eine Mammografie.

CUP entstehen in der Regel, wenn der Primärtumor entweder verschwindet oder sehr klein bleibt. Da Metastasen normalerweise in weitaus größerem Maße entartet sind als der Primärtumor, geht man davon aus, dass das Immunsystem nach einer Metastasierung den Tumor zerstört oder aber klein gehalten hat, während ihm dies bei den hochmalignen Metastasen nicht möglich gewesen ist. Eine weitere Theorie besagt, dass ein Teil der CUP durch Heterotopien entstehen, bei denen in der embryonalen Phase Gewebe in andere Organe verschleppt wurde und dort entartete. In diesem Falle würde es sich bei den vermeintlichen Metastasen etwa eines malignen Melanoms in der Lunge in Wirklichkeit um einen Primärtumor handeln.



</doc>
<doc id="13024" url="https://de.wikipedia.org/wiki?curid=13024" title="MKS-Einheitensystem">
MKS-Einheitensystem

Das MKS-Einheitensystem, kurz auch MKS-System genannt, ist ein absolutes metrisches System mit den drei Basiseinheiten Meter (m), Kilogramm (kg) und Sekunde (s). Durch Hinzunahme des Ampere (A) als vierte Basiseinheit gelangte man 1939 zum MKSA-System. Dieses System ging 1960 in dem heute gebräuchlichen Internationalen Einheitensystem ("SI") auf.



</doc>
<doc id="13026" url="https://de.wikipedia.org/wiki?curid=13026" title="Alte Maße und Gewichte (deutschsprachiger Raum)">
Alte Maße und Gewichte (deutschsprachiger Raum)

Hier sind historische Maße und Gewichte des deutschsprachigen Raumes, vor allem des 19. Jahrhunderts, aufgeführt. In den Abbildungen sind auch alte internationale Maßeinheiten mit ihrer Umrechnung ins metrische System angegeben. Zwar sind die Beziehungen innerhalb eines Systems einigermaßen gleichbleibend, die Einheiten waren örtlich und zeitlich aber teils erheblichen Veränderungen unterworfen. Vor einer Umrechnung in das metrische System ist stets genau zu prüfen, ob der verwendete Umrechnungsfaktor für die entsprechende Zeit am jeweiligen Ort tatsächlich Geltung hatte.

Speziell siehe auch Alte Maße und Gewichte in:

Zur Überwindung der örtlichen Unterschiede, vor allem bei den Längenmaßen und Gewichten, wurde, ausgehend von Frankreich (1791, 29. November 1800), das metrische System eingeführt, das auf dem dafür geschaffenen Urmeter basiert. Dem französischen Beispiel folgten nach und nach viele andere Staaten.

Die „Preußische Maaß- und Gewichtsordnung“ vom 16. Mai 1816 vereinheitlichte die Größen unter Zugrundelegung des Rheinländischen Fußes, definiert als Teil des alten (in Frankreich gesetzlich nicht mehr gültigen) französischen Längenmaßes, der Toise du Pérou: 1 preußischer Fuß = 139,13 Pariser Linien (Untereinheit der Toise, entspricht 31,387728 cm).

Der Norddeutsche Bund beschloss am 17. August 1868 die Norddeutsche Maß- und Gewichtsordnung, die zum 1. Januar 1872 das metrische System einführte; Bayern folgte am 29. April 1869 mit Wirkung zum 1. Januar 1872. Das metrische System galt ab 1872 im gesamten Deutschen Reich. Am 20. Mai 1875 unterzeichneten 17 Staaten die Meterkonvention.

Im Mittelalter gab es in größeren Städten eigene Maßsysteme, die auch Stückmaße für örtlich häufig gehandelte Güter umfassten. Ein Beispiel ist die Stadt Speyer, die Stückmaße für Stroh, Heu, Bündelholz und Heringe hatte.

Maßeinheiten der Flächenmessung.
Die Raummaße wurden auch als Hohlmaße bezeichnet, da mit ihnen das „Hohle“ eines Gefäßes ausgemessen werden kann. Zumeist wird das Flüssigkeitsmaß so eingeordnet, die Flüssigkeit wird in das hohle Gefäß gefüllt. In jüngerer Zeit kommt die Bezeichnung Volumenmaß hinzu.

"siehe" Schöpfmaß






</doc>
<doc id="13028" url="https://de.wikipedia.org/wiki?curid=13028" title="Stadtstaat">
Stadtstaat

Ein Stadtstaat ist im Gegensatz zum Flächenstaat ein Staat, der nur das Gebiet einer Stadt (und gegebenenfalls ihr engeres Umland) umfasst. Es kann sich dabei um einen souveränen Staat oder um einen Gliedstaat innerhalb eines Bundesstaats handeln.

Städte in Einheitsstaaten sind in keinem Fall Stadtstaaten, auch wenn sie Verwaltungseinheiten oberhalb der kommunalen Ebene gleichgestellt sind, da in Einheitsstaaten per definitionem keine Gliedstaaten existieren. Ebenfalls keine Stadtstaaten sind Städte, die in föderativen Staaten keinem der Gliedstaaten angehören, sondern den Status von Bundesterritorien haben wie z. B. Washington, D.C., Brasilia D.F., Canberra oder die indische Stadt Chandigarh.

Historische Stadtstaaten stehen am Anfang der Zivilisation in Mesopotamien. Diese Staatsform breitete sich unter anderem nach Phönizien und Griechenland aus. Die griechische Polis wurde zum klassischen Begriff für den antiken Stadtstaat. Rom wuchs von einem Stadtstaat zum Weltreich. Auch die indianischen Hochkulturen der Maya und Azteken in Mittelamerika organisierten sich in Stadtstaaten.

Stadtstaaten im Mittelalter waren etwa die großen Stadtrepubliken im heutigen Italien und Russland (unter anderem Florenz und die "Seerepubliken" Republik Venedig, Republik Genua, Republik Pisa, Herzogtum Amalfi, Republik Ancona, Herzogtum Gaeta in Italien, Republik Ragusa in Dalmatien und Nowgorod und Pskow in Russland). Auch viele Schweizer Kantone gingen aus Stadtstaaten hervor. Mit der Eroberung der Waadt 1539 wurde z. B. die Stadt und Republik Bern zum größten Stadtstaat nördlich der Alpen.

Nach dem Wiener Kongress 1815 gab es im Deutschen Bund vier Stadtstaaten: Bremen, Freie Stadt Frankfurt, Hamburg und Lübeck sowie, direkt angrenzend an den Deutschen Bund, die polnischsprachige Republik Krakau, die 31 Jahre später durch Österreich annektiert wurde. Frankfurt wurde 1866 von Preußen annektiert, Lübeck verlor 1937 durch das Groß-Hamburg-Gesetz seine mehr als 700-jährige Eigenstaatlichkeit als Freie und Hansestadt und kam zur preußischen Provinz Schleswig-Holstein. Dazu war von 1807 bis 1815 und von 1920 bis 1939 auch die Freie Stadt Danzig ein souveräner Stadtstaat.

→ "Siehe auch: Freie und Reichsstädte"

Berlin war nach dem Zweiten Weltkrieg bis zur Wiedervereinigung 1990 geteilt, West-Berlin war somit von der DDR umgeben und hatte als Stadtstaat einen Sonderstatus. Es war nicht offizieller Bestandteil der Bundesrepublik, wurde aber weitgehend so behandelt. Berlin als Ganzes stand eigentlich bis 1990 unter dem sogenannten "Viermächte-Status" und war in der Rechtsprechung beeinflusst durch die Besatzungsmächte.

→ "Siehe auch: Berlin-Frage"

Souveräne Stadtstaaten und auch Zwergstaaten sind Monaco, Singapur und die Vatikanstadt.

In Deutschland werden heute üblicherweise drei Länder als Stadtstaaten bezeichnet: Berlin, Hamburg und Bremen.

Die drei Stadtstaaten sind als Länder auch im Bundesrat vertreten und nehmen am Finanzausgleich des Bundes und der Länder teil, wo sie das sogenannte Stadtstaatenprivileg genießen, das besagt, dass Stadtstaaten aufgrund ihrer höheren Ausgaben pro Einwohner mehr Geld pro Einwohner aus dem Länderfinanzausgleich erhalten als die Flächenstaaten.

Für die deutschen Stadtstaaten wurde in der Vergangenheit immer wieder die Möglichkeit einer Fusion mit angrenzenden Ländern diskutiert, zum Beispiel Bremen mit Niedersachsen, Hamburg mit Schleswig-Holstein und Berlin mit Brandenburg. Für Berlin und Brandenburg wird diese erneut diskutiert, obwohl ein Fusionsvertrag beim Volksentscheid 1996 in Brandenburg die Mindestbeteiligung von 25 % der Wahlberechtigten (Quorum) erreichte (von der Mehrheit der Berliner angenommen, aber 62,7 % der abstimmenden Brandenburger lehnten ihn ab).




</doc>
<doc id="13030" url="https://de.wikipedia.org/wiki?curid=13030" title="Luftverschmutzung">
Luftverschmutzung

Als Luftverschmutzung wird die Freisetzung umwelt- und gesundheitsschädlicher Schadstoffe in die Luft bezeichnet. Zu diesen Schadstoffen gehören z. B. Rauch, Ruß, Staub, Gase, Aerosole, Dämpfe und Geruchsstoffe. Luftverschmutzung ist eine Form der Umweltverschmutzung. Laut Angaben der WHO starben 2012 ca. acht Millionen Menschen vorzeitig durch Folgen von Luftverschmutzung. Ca. 3,7 Millionen dieser Menschen starben vorzeitig durch Outdoor-Luftverschmutzung und ca. 4,3 Mio. durch Indoor-Luftverschmutzung. Insbesondere in Ländern der Dritten Welt, in Russland, in der Volksrepublik China und anderen Schwellenländern ist die Luftverschmutzung hoch.

In den Industrieländern ist die Luftverschmutzung durch Maßnahmen zur Luftreinhaltung in den letzten Jahrzehnten zurückgegangen. 
Die EU-Kommission hat die direkt verursachten Schäden für Mensch und Umwelt in der EU 2013 auf 23 Milliarden Euro pro Jahr geschätzt. Die indirekten Kosten werden auf etwa 330 bis 940 Milliarden Euro pro Jahr geschätzt. So ist in der EU die Zahl der vorzeitigen Todesfälle (ca. 470.000 im Jahr, Stand 2016) durch Luftverschmutzung höher als die der Unfalltoten durch den Straßenverkehr.

Für Deutschland wurde die Zahl der 2010 durch Outdoor-Luftverschmutzung vorzeitig Gestorbenen auf ca. 34.400 geschätzt. Größter Verursacher war die Landwirtschaft mit 15.675 bzw. 45 % aller vorzeitigen Todesfälle. Es folgten Verkehr an Land mit 6.928 Todesfällen (20 %), Industrie mit 4.452 Todesfällen (13 %), Stromerzeugung mit 4.402 Todesfällen (13 %), Gebäudeheizungen 2.684 Todesfällen (8 %) und das Verbrennen von Biomasse mit 279 vorzeitigen Todesfällen (1 %).

Es wird angenommen, dass die Energiewende zukünftig wesentlich dazu beitragen wird, die Luftverschmutzung zu senken. Da Maßnahmen zur Eindämmung der globalen Erwärmung häufig auch die Luftverschmutzung reduzieren, ist die Verbesserung der Luftqualität ein wichtiger positiver Nebenaspekt von Klimaschutzmaßnahmen. Zum Teil lohnen sich Klimaschutzmaßnahmen alleine schon durch die volkswirtschaftlichen Vorteile reduzierter Luftverschmutzung.

Mit der gezielten Anwendung des Feuers durch den Menschen begann die Verschmutzung der Luft mit luftfremden Stoffen. An Torfablagerungen wurde nachgewiesen, dass der Abbau und die Verarbeitung von Blei durch menschliche Kulturen seit 6000 Jahren zu erhöhten Blei-Emissionen in die Luft führte, die sich weltweit auswirkten. In den letzten Jahrzehnten sanken diese Emissionswerte u. a. durch die Verwendung „bleifreien“ Benzins und Auflagen für die Industrie.

Im Antiken Rom und später auch in anderen europäischen Städten des Mittelalters finden sich dokumentierte Beschwerden über Luftverschmutzungen. In diesen Beschwerden ging es in der Regel zunächst nur um die Belästigung durch Geruch und Schmutz, eine mögliche Gesundheitsgefahr wurde zunächst nicht erkannt.

Der Rauch aus den Öfen von Glasschmelzen im antiken Rom um 150 n. Christus war so störend, dass die Glasmacher gezwungen wurden, ihre Werkstätten in die Vororte zu verlegen.

Im England des 13. Jahrhunderts gab es viele Beschwerden und Probleme durch die Verbrennung stark schwefelhaltiger Kohle. 1257 musste Königin Eleanor von England wegen der herrschenden Verqualmung Nottingham verlassen. 1272 verbot König Edward I. unter Androhung der Todesstrafe den Gebrauch der schwefelhaltigen Kohle.

In Köln wurde 1464 einem Kupfer- und Bleischmelzer aufgrund von Nachbarschaftsbeschwerden per Ratsbeschluss der Weiterbetrieb seines Handwerks in der Stadt untersagt. In Augsburg wurde 1623 eine Schmelzhütte wegen Nachbarschaftsbeschwerden über ungesunden Rauch und Dampf abgerissen und die Wiederinbetriebnahme außerhalb der Stadt genehmigt.
1947 versammelte sich kurz nach der Veröffentlichung eines sehr kritischen Artikels über eine Smog-Krise in Los Angeles in einer großen kalifornischen Zeitung eine Gruppe von Managern der US-Ölindustrie in der Stadt zur Gründung des "Smoke and Fumes-Komitees" („Rauch und Dämpfe-Ausschuss“): Es sollte die wissenschaftliche Forschung der Öl- und Gasindustrie finanzieren und wissenschaftliche Erkenntnisse mittels Public Relations bekannt machen, „um die öffentliche Wahrnehmung von Luftverschmutzung und Regeln zur Eindämmung der Luftverschmutzung in eine bestimmte Richtung zu lenken. Das erklärte Ziel war es, gesetzgeberische Maßnahmen zu verhindern, die die Ölindustrie für unnötig hielt und die sie nicht haben wollte.“

Im Dezember 1952 kam es in London zu einer Smog-Katastrophe ("The Great Smog"), bei der bis zu 12.000 Einwohner am Smog starben.

2006 und 2015 traten in Südostasien zwei schwere Hazefälle auf. Bei massiven Waldbränden in Indonesien kam es im September und Oktober 2015 zu einer Smogkrise, bei der etwa 100.000 Menschen starben.

Daneben existieren auch Luftverschmutzungen, welche absichtlich herbeigeführt werden: Hierzu zählt u. A. das in den USA praktizierte Rolling Coal-Fahrzeugtuning („Rollende Kohle“), bei dem Autos und Pick-Ups so umgerüstet werden, dass sie besonders viel Ruß und Schadstoffe ausstoßen. Motivation dieser zumeist politisch rechts stehenden US-Amerikaner ist häufig, ein politisches Statement gegen Umweltschützer und Umweltschutzmaßnahmen zu setzen.

Obwohl es einen breiten wissenschaftlichen Konsens über die gesundheitlichen Schäden der Luftverschmutzung gibt, werden diese in manchen Staaten wie den USA, Indien oder Polen zunehmend von politischen Akteuren geleugnet. Teilweise sind dies dieselben Kräfte, die auch die menschengemachte Erderwärmung leugnen, beispielsweise das Heartland Institute.

Das Problem der Luftverschmutzung kann hinsichtlich
betrachtet werden.

Unser heutiger Lebensstandard ist gekennzeichnet unter anderem durch einen hohen Energiebedarf, viele industriell hergestellte Produkte aus einer Vielzahl von Rohstoffen sowie ein hohes (teils weiterhin zunehmendes) Verkehrsaufkommen. Die Energieerzeugung, der Verkehr, die Produktionsprozesse (Industrie, landwirtschaftliche Tierhaltung) sowie Gewerbebetriebe und Haushalte sind wichtige Ursachen für die anthropogene (vom Menschen verursachte) Luftverschmutzung.

Für die Vereinigten Staaten kam eine 2013 erschienene Studie zum Ergebnis, dass im Jahr 2005 rund 210.000 Menschen vorzeitig aufgrund von Luftverschmutzung infolge von menschgemachten Verbrennungsprozessen starben. Etwa 200.000 von ihnen starben durch Feinstaub (PM) und ca. 10.000 durch erhöhte Ozonwerte. Die drei wichtigsten Emissionsquellen waren in dieser Reihenfolge Verkehr, Kraftwerke und Industrieprozesse mit ca. 53.000, 52.000 bzw. 41.000 vorzeitigen Todesfällen durch Feinstaub sowie 5000, 2000 bzw. 2000 Todesfällen durch Ozon.

Wichtige Schadstoffe aus den drei Bereichen (Emittentengruppen) sowie daraus resultierende Probleme sind nachfolgend zusammengefasst.

Heute stellt der Straßenverkehr eine der wichtigsten Quellen für die Luftverschmutzung in Städten dar. Die Abgase der Kraftfahrzeuge belasten die Umgebungsluft primär mit Stickoxiden, flüchtigen organischen Verbindungen ohne Methan (NMVOC), Ruß und andere Partikel. Die Emissionen von Kraftfahrzeugen wurden sukzessive durch immer strengere Abgasnormen verringert; der Kraftfahrzeugbestand nahm zu. Extrem starke lokale Luftverschmutzungen finden sich heute weltweit in vielen der sogenannten Megastädte („Mega-City“), zum Beispiel in Peking.

Die Emissionen des weltweiten Schiffsverkehrs sind beträchtlich. Seeschiffe betreiben den Hauptmotor in der Regel mit minderwertigem und schadstoffreichem Schweröl (engl. Heavy Fuel Oil (HFO)), das bei der Erdölverarbeitung als Rückstandsöl anfällt, und haben so gut wie nie eine Abgasfilterung.
So lagen die 2003 geschätzten Emissionen für
Die MARPOL#Anlage VI hat die Situation verbessert. Seit 2008 hat der Schadstoffausstoß dank des oft praktizierten Slow steamings (bewusstes Langsamfahren) abgenommen. Niedrige Frachtraten (siehe Schifffahrtskrise) zwingen die Reedereien, alle Sparmöglichkeiten auszuschöpfen.

Megastädte sind Städte, in denen mehr als 10 Millionen Menschen wohnen. Bekannte Megastädte sind z. B.

Die Weltgesundheitsorganisation (WHO) und das Umweltprogramm der Vereinten Nationen (UNEP) messen im Rahmen eines weltweiten Monitoring-Programms auch die Luftqualität in Mega-Cities. Als größte Probleme der Luftverschmutzung in Mega-Cities gelten Partikel und Ozon.

Dass Luftschadstoffe nicht an nationalen Grenzen stoppen, ist spätestens seit dem Auftreten von stark sauren Niederschlägen in den skandinavischen Ländern bekannt, deren wesentliche Ursache Schwefeldioxid-Emissionen in den mitteleuropäischen Ländern waren. Dieses leicht wasserlösliche Gas ist entlang feuchten Luftströmungen in Wolken mehrere hundert bis maximal 1500 km stabil.

Laut Umweltbundesamt wurden 1998 in Deutschland 983 kt Schwefeldioxid emittiert. Diese Menge erhöht sich gemäß Tabelle „Transport von oxidiertem Schwefel“ um ca. 9 kt Schwefeldioxid aus angrenzenden Staaten (Vergleich von Import 153,2 kt mit Export 144,1 kt).

In den USA wurden die Schwefeldioxid-Emissionen gesenkt von 23,5 Mio. t (1980), 21,5 Mio. t (1990), 16,6 Mio. t (2000) auf 12 Mio. t Schwefeldioxid in 2010.

China verursacht heute die weltweit höchsten Schwefeldioxid-Emissionen. Die Menge stieg von 2000 bis 2005 auf 25,5 Mio. t (+27 %) an; dies entspricht dem USA-Niveau von ca. 1980.
Die Tabelle zeigt auch, dass das Ziel der Verringerung der Luftverschmutzung keine nationale, sondern eine länderübergreifende Aufgabe darstellt (s.u.: Internationale Maßnahmen).

Luftschadstoffe können sowohl in der näheren Umgebung ihres Entstehungsortes als auch weit entfernt davon nachgewiesen werden. Die wesentlichen Einflussfaktoren dieser Ausbreitung bilden Wind und Schichtungszustand der Erdatmosphäre. Als besonders gefährlich erweisen sich dabei Fumigation-Lagen wie im Bild rechts. Sie treten insbesondere bei Stadtklimaten und im Bereich von großen Industrieanlagen auf. Dies war in Mitteleuropa und speziell London noch bis in die 1970er Jahre der Fall und tritt heute vor allem in ostasiatischen Metropolen wie Peking oder Shanghai auf. 
Die Ausbreitung von Luftschadstoffen kann mittels Ausbreitungsrechnung prognostiziert werden.

Als es noch keine Abgasfiltertechniken gab, waren hohe Schornsteine eine verbreitete Methode, um lokale Immissionen zu reduzieren: man emittierte die Abgase in bis zu 300 m Höhe, um sie weiträumiger zu verteilen. sollten die Abgase in höhere Luftschichten gebracht werden, um sie weiträumiger und damit in geringeren Konzentrationen zu verteilen. 

Ein Luftschadstoff kann direkt den Menschen schaden, der Umwelt schaden oder beiden schaden.

Anfang der 1980er Jahre erregte das Waldsterben große Sorgen in der Bevölkerung. Es wurde vermutet, dass Luftschadstoffe wie Schwefeldioxid und Stickoxide Ursachen des Waldsterbens waren. Schwefeldioxid und andere Schadstoffe in der Luft wurden vom Regen zu Boden befördert (der Regen wurde dadurch zu saurem Regen), gelangte an die Wurzeln von Pflanzen und schädigte diese. Zur Beunruhigung trug bei, dass geschädigte Waldbestände weitab von Emissionsschwerpunkten waren, z. B. im Schwarzwald und in anderen deutschen Mittelgebirgen.

Die Schadstoffe in der Luft können je nach Art des Stoffes und der vorherrschenden Konzentration(en) die menschliche Gesundheit beeinträchtigen (hauptsächlich Erkrankungen der Atemwege und des Kreislaufsystems) oder im schlimmsten Fall zum Tode führen. Wegen Luftverschmutzung sterben laut WHO jährlich ca. acht Millionen Menschen.

Luftverschmutzung verursacht Lungenkrebs und erhöht das Risiko auf Blasenkrebs. Im Jahr 2010 sind mehr als 220.000 Lungenkrebstote weltweit auf die Verschmutzung der Luft zurückzuführen, das entspricht ca. 15 Prozent aller Lungenkrebstoten dieses Jahres. Am 17. Oktober 2013 wurde Luftverschmutzung von der WHO offiziell als Krebsursache eingestuft.

In einer Studie aus dem Jahr 2018 wird Feinstaub (PM) sowie Ozon (O) mit einem erhöhten Alzheimer-Risiko in Verbindung gebracht.<ref name="DOI10.1016/j.envres.2018.03.023">Lilian Calderón-Garcidueñas, Angélica Gónzalez-Maciel u. a.: "Hallmarks of Alzheimer disease are evolving relentlessly in Metropolitan Mexico City infants, children and young adults. APOE4 carriers have higher suicide risk and higher odds of reaching NFT stage V at ≤ 40 years of age." In: "Environmental Research." 164, 2018, S. 475, .</ref>

Die Zunahme von Erkrankungen beziehungsweise die Erhöhung der Sterblichkeit während solcher Smog-Episoden wird heute vor allem auf die zu diesen Zeiten erhöhten Konzentrationen von fünf Stoffen zurückgeführt:

Die Wirkung dieser Stoffe auf den Menschen lässt sich aber nicht isoliert betrachten, sondern wird auch durch Faktoren wie z. B. die Temperatur oder die Luftfeuchtigkeit beeinflusst. Zu unterscheiden ist ferner zwischen akuten Gesundheitsfolgen und längerfristigen chronischen Krebserkrankungen, etwa durch Feinstaub.

Luftverschmutzungen können zu zahlreichen Umweltproblemen führen:

Luftverschmutzung wirkt sich zudem negativ auf das Pflanzenwachstum aus und verringert z. B. den Ertrag von wichtigen Nutzpflanzen, was sich negativ auf die Nahrungsmittelversorgung der Welt auswirkt. Beispielsweise lag der Ertrag von Weizen in Indien aufgrund von Luftverschmutzung und Klimawandel im Jahr 2010 um 36 % niedriger als in einem Referenzszenario ohne diese negativen Faktoren; teilweise betrug der Ertragsrückgang bis ca. 50 %. Etwa 90 % des Ertragsrückgangs ist auf die direkte Wirkung kurzlebiger Schadstoffe wie Ruß und Ozon zurückzuführen, der Rest auf deren Beitrag zur Erwärmung.

Luftverschmutzung beeinträchtigt auch Materialien, die vom Menschen als Werkstoffe eingesetzt werden. So werden durch Luftschadstoffe Materialien wie Stahl, Glas, und Stein angegriffen. Die Korrosionsrate von Stahl erlaubt dabei sogar erste Rückschlüsse auf die Höhe der Luftverunreinigungen. Bei Bronze wurde die Beobachtung gemacht, dass unterschiedliche Legierungen trotz gleicher Umweltbedingungen zu verschiedenartigen Korrosionserscheinungen führen können.

Die aufgrund von Luftverschmutzung in Verbindung mit Wasser entstehenden Säuren greifen auch Kulturgüter an und führen z. B. zu Steinfraß, beschädigen Glasmalerei oder zerstören, wenn sie mit dem Regen in den Boden eindringen, in hohem Maß archäologisches Kulturgut, insbesondere Nicht-Edelmetalle wie Eisen. Gewisse Anzeichen deuten darauf hin, dass sich das Aussehen von Bronzeskulpturen erst durch das Auftreten der industriellen Luftverschmutzung geändert hat.

In Deutschland gibt es eine Reihe von Bundes-Immissionsschutzverordnungen (BImSchV) auf Grundlage des Bundes-Immissionsschutzgesetzes (BImSchG), die z. B. auf die europäische Luftqualitätsrichtlinie 2008/50/EG vom 21. Mai 2008 zurückgehen. Die Betreiber genehmigungsbedürftiger Anlagen müssen Art, Menge, räumliche und zeitliche Verteilung der von der Anlage ausgehenden Luftverunreinigungen in einer Emissionserklärung angeben.

EU-Bürger haben seit dem 26. Mai 2011 die Möglichkeit, genau zu sehen, wer in ihrer Umgebung Luft verschmutzt: Europäische Kommission und Europäische Umweltagentur haben im Rahmen des Europäischen Schadstoffemissionsregisters neue Karten veröffentlicht, die auf einer Skala von 5×5 km zeigen, wo Emissionsquellen wie Straßen- und Luftverkehr für die Freisetzung u. a. von Feinstaub verantwortlich sind. Bisher waren solche Werte nur punktuell, z. B. bei einzelnen Industrieanlagen einsehbar.

Das Umweltbundesamt und Bundesländer veröffentlichen seit Jahren aktuelle Messwerte (zum Beispiel Feinstaub, Ozon) von etwa 450 Messstationen in Deutschland im Internet.



Luftreinhaltung und Abgasreinigung

Gesundheitliche Aspekte



</doc>
<doc id="13032" url="https://de.wikipedia.org/wiki?curid=13032" title="Font">
Font

Font bezeichnet:

Font heißen folgende geographische Objekte:
Font oder La Font ist der Familienname folgender Personen:
Siehe auch:


</doc>
<doc id="13036" url="https://de.wikipedia.org/wiki?curid=13036" title="Entropie (Informationstheorie)">
Entropie (Informationstheorie)

Entropie (nach dem Kunstwort ἐντροπία) ist in der Informationstheorie ein Maß für den mittleren Informationsgehalt einer Nachricht. Der Begriff ist eng verwandt mit der Entropie in der Thermodynamik und Statistischen Mechanik.

Das informationstheoretische Verständnis des Begriffes "Entropie" geht auf Claude E. Shannon zurück und existiert seit etwa 1948. In diesem Jahr veröffentlichte Shannon seine fundamentale Arbeit "A Mathematical Theory of Communication" und prägte damit die moderne Informationstheorie.

Die Entropie wird üblicherweise mit einem großen Eta (formula_1) bezeichnet.

Claude Elwood Shannon definierte die Entropie formula_1 einer diskreten, gedächtnislosen Quelle (diskreten Zufallsvariable) formula_3 über einem endlichen, aus Zeichen bestehenden Alphabet formula_4 wie folgt: Zunächst ordnet man jeder Wahrscheinlichkeit formula_5 eines Ereignisses seinen Informationsgehalt formula_6 zu. Dann ist die Entropie eines Zeichens definiert als der Erwartungswert des Informationsgehalts
Sei formula_8, dann ist formula_9 die Wahrscheinlichkeit, mit der das Zeichen formula_10 des Alphabets auftritt, oder gleichwertig

mit formula_12. Dabei wird formula_13 gesetzt (entsprechend dem Grenzwert formula_14). Summanden mit verschwindender Wahrscheinlichkeit tragen daher aufgrund der Definition nicht zur Summe bei.

Die Entropie formula_15 für Wörter formula_16 der Länge formula_17 ergibt sich durch
wobei formula_19 die Wahrscheinlichkeit ist, mit der das Wort formula_16 auftritt. Die Entropie formula_1 ist dann der Limes formula_22 davon:
Wenn die einzelnen Zeichen voneinander stochastisch unabhängig sind, dann gilt formula_24 für alle formula_17, also formula_26 (vgl. Blockentropie)

Entropie ist ein Maß für den mittleren Informationsgehalt pro Zeichen einer Quelle, die ein System oder eine Informationsfolge darstellt. In der Informationstheorie spricht man bei Information ebenso von einem Maß für "beseitigte Unsicherheit". Je mehr Zeichen im Allgemeinen von einer Quelle empfangen werden, desto mehr Information erhält man und gleichzeitig sinkt die Unsicherheit über das, was hätte gesendet werden können.

Anschaulich lässt sich die Definition des Informationsgehalts wie folgt begründen: Wenn ein Ereignis, das mit Wahrscheinlichkeit formula_27 eintreten kann, tatsächlich eintritt, dann wird dadurch ein konkretes Ereignis aus einer hypothetischen Menge von formula_28 gleich wahrscheinlichen stochastisch unabhängigen Ereignissen ausgewählt. Um diese Anzahl von Ereignissen unterscheiden zu können, benötigt man formula_29 Binärbits. Dieser Wert gibt also den Informationsgehalt eines speziellen Ereignisses in Bits an. Gewichtet man den tatsächlichen Informationsgehalt der möglichen Ereignisse mit der jeweiligen Eintrittswahrscheinlichkeit, so erhält man den mittleren oder erwarteten Informationsgehalt eines Zeichens.

Die Einheit 1 Shannon ist definiert als der Informationsgehalt eines Ereignisses mit der Wahrscheinlichkeit formula_30. Ein Beispiel für ein solches Ereignis ist das Ergebnis "Kopf" eines Münzwurfs.

Die Basis 2 für den Logarithmus ist willkürlich. Es stellt sich nur heraus, dass sich Bits (Binärziffern) besonders einfach technisch handhaben lassen. Würde eine andere Basis gewählt werden, zum Beispiel 3, so erhielte man "ternäre" Ziffern (Trits). Der Informationsgehalt lässt sich leicht durch Multiplikation mit dem Modulus formula_31 von Bits auf Trits umrechnen.

Die mindestens notwendige Anzahl von Bits, die zur Darstellung der Information (des Textes) notwendig sind, ergibt sich aus dem Produkt des durchschnittlichen Informationsgehalts eines Zeichens formula_32 und der Anzahl formula_17 der Zeichen formula_10 im Informationstext: formula_35.

Shannons ursprüngliche Absicht, die Entropie als das Maß der benötigten Bandbreite eines Übertragungskanals zu nutzen, wurde schnell verallgemeinert.
Die Entropie wurde generell als ein Maß für den Informationsgehalt betrachtet.

Bei einer kleinen Entropie enthält der Informationstext Redundanzen oder statistische Regelmäßigkeiten.
Die Entropie ist im Allgemeinen nicht durch (1) gegeben. Beispielsweise ist die Wahrscheinlichkeit, eine "0" oder "1" in der Zeichenkette formula_36 zu finden, genauso groß, wie in einer Zeichenkette, die durch statistisch unabhängige Ereignisse (etwa wiederholten Münzwurf) entstanden ist. Daher ist die Entropie formula_37 einzelner Zeichen für beide Zeichenketten gleich, obwohl die erste Kette weniger zufällig ist. Bereits formula_38 zeigt einen Unterschied: Die erste Zeichenkette liefert formula_39, die zweite liefert formula_40. Man kann das auch so deuten: Die Wahrscheinlichkeit eines Zeichens hängt vom vorangegangenen Zeichen ab. Stochastische Unabhängigkeit ist also nicht gegeben.

Für aufeinander folgende Ereignisse, die nicht stochastisch unabhängig sind, reduziert sich die Entropie aufeinander folgender abhängiger Ereignisse fortlaufend. In einem solchen Fall kann man auch mit der bedingten Entropie und der Quellentropie arbeiten, die beide auf Verbundwahrscheinlichkeiten aufbauen.

In engem Zusammenhang mit bedingter Entropie steht auch die Transinformation, welche die Stärke des statistischen Zusammenhangs zweier Zufallsgrößen angibt.

Noch einfacher formuliert, ist die Entropie die durchschnittliche Anzahl von Entscheidungen (bits), die benötigt werden, um ein Zeichen aus einer Zeichenmenge zu identifizieren oder zu isolieren.

Es ist sinnvoll, dass ein Alphabet aus mindestens zwei verschiedenen Zeichen vorliegt. Eine Alphabetsgröße von "eins" bedeutet, dass man weder über neu ankommende Zeichen aus der Senderquelle neue Information erhält, noch die Unsicherheit über das vorangegangene Zeichen verringern kann.

Möchte man ein normiertes Maß für die Entropie einer beliebigen diskreten Verteilung haben, ist es von Vorteil, die maximal mögliche Entropie, die bei Gleichverteilung der formula_27 erreicht wird, zur Normierung heranzuziehen. Sei formula_42 die Anzahl der Zeichen in formula_3 über dem Alphabet formula_44, dann ist die "maximale Entropie" formula_45 gegeben wenn
Daraus folgt beispielsweise formula_48 für eine Binärverteilung (formula_49), also benötigt man ein Bit pro Zeichen und formula_50 Zeichen für die komplette Information formula_51. Dieser Wert wird erreicht, wenn Nullen und Einsen gleich häufig vorkommen.
Normiert man nun die Entropie einer beliebigen Verteilung mit formula_42 verschiedenen Zeichen mit formula_45 erhält man:

Die so erhaltene Entropie wird immer maximal gleich formula_55.

Um die Entropien von Nachrichten unterschiedlicher Länge vergleichen zu können, hat man die Entropierate eingeführt, die die Entropie auf das einzelne Zeichen bezieht (siehe dort).

Bei gleichmäßiger Verteilung kann bei einem Alphabet auf kein Zeichen verzichtet werden. Dagegen ist die Buchstabenhäufigkeit in der deutschen Sprache ungleichmäßig, siehe auch: Entropie (Kryptologie). Beispielsweise ist der Buchstabe E im Deutschen siebenmal so häufig wie "M" oder "O", was zu Redundanz im Alphabet führt. Nun möchte man ermitteln, wie groß diese Redundanz ist.

Sei formula_56 die Größe des Alphabets. Die Redundanz R berechnet sich mit formula_57. Für das deutsche Alphabet errechnet man anhand der Buchstabenhäufigkeit eine Entropie formula_1 von 4,0629 bit/Zeichen. Die maximale Entropie beträgt formula_59 bit/Zeichen. Damit folgt eine Redundanz von formula_60 bit/Zeichen. Berechnet man weiter die gesamte Redundanz, die sich aus der Summe der Redundanzen eines jeden Zeichens ergibt, so erhält man formula_61 Bits. Nun wäre interessant zu wissen, wie vielen Zeichen dies aus unserem Alphabet entspricht. Dividiert man die redundanten Bits durch den durchschnittlichen Informationsgehalt eines gleichverteilten Zeichens, so erhält man formula_62 Zeichen → 3 Zeichen (ohne Redundanzen). Rechnet man allerdings formula_63 (⇒ 4 Zeichen), so bestimmt man die Anzahl von Zeichen mit einer Redundanz, wie sie auch im Alphabet vorhanden ist.

Ohne Informationsverlust könnte das Alphabet also um vier Buchstaben reduziert werden. Diese Überlegung berücksichtigt nur die statistische Verteilung der Buchstaben. Häufige Buchstabenkombinationen wie "SCH" oder "ST" bleiben genauso unberücksichtigt (bedingte Entropie) wie gleich klingende Buchstaben ("Q", "K").

Bei einem Münzwurf sind idealerweise "Kopf" oder "Zahl" gleich wahrscheinlich. Wenn man die Entropie als Maß für die Ungewissheit auffasst, wird sie hier einen maximalen Wert aufweisen. Es ist völlig ungewiss, ob beim nächsten Wurf "Kopf" oder aber "Zahl" geworfen wird.

Sei formula_3 eine diskrete Zufallsvariable und der Erwartungswert formula_65 mit
so ergibt sich aus obiger Definition Entropie formula_68 bit.

Anders bei einer gezinkten Münze, etwa einer Münze, die im Mittel in 60 % der Fälle "Kopf" und nur in 40 % der Fälle "Zahl" anzeigt. Die Ungewissheit ist hier geringer als bei der normalen Münze, da man eine gewisse Präferenz für "Kopf" hat. Gemessen als Entropie liegt die Ungewissheit bei nur noch etwa 0,971.

Die Summe der Wahrscheinlichkeiten ist immer 1.

Die Entropie lässt sich aus der Summe der Teilentropien berechnen:

Ersetzt man formula_71 durch den Ausdruck formula_72, so erhält man die Formel

Dies kann man grafisch folgendermaßen darstellen:

Für jedes formula_5 kann man daraus die Entropie direkt ablesen. Die Funktion ist symmetrisch zur Geraden formula_30. Sie fällt bei formula_76 steil zu einem Entropie-Wert von 0 ab. Auch bei Werten, die sich dem sicheren Ereignis von formula_77 nähern, fällt die Entropie auf 0 ab.

Dieser Zusammenhang gilt jeweils für ein Zufallsereignis. Bei mehreren Zufallsereignissen muss man die einzelnen Entropien zusammenzählen und man kann so leicht Entropiewerte über 1 erreichen. Die Wahrscheinlichkeit formula_5 dagegen bleibt auch bei Wiederholungen definitionsgemäß immer zwischen 0 und 1.

Wiederholt man den Münzwurf zweimal, wächst die Zahl der Möglichkeiten auf vier. Die Wahrscheinlichkeit jeder einzelnen Möglichkeit liegt bei 0,25. Die Entropie des zweimaligen Münzwurfes ist dann 2 Sh. Wenn man einen idealen Münzwurf mehrfach wiederholt, dann addiert sich die Entropie einfach. Die Entropie einer Reihe von 20 idealen Münzwürfen berechnet sich einfach: formula_79. Dies ist im Bild dargestellt.

Man kann nicht einfach aus "einem" Wert der Wahrscheinlichkeit die Entropie ausrechnen. Die Entropie betrifft den gesamten Zufallsprozess. Jede Teilwahrscheinlichkeit eines möglichen Ergebnisses geht in die Berechnung der Entropie des Gesamtprozesses ein. Die Angabe einer Teilentropie für jedes mögliche Ergebnis ist dabei wenig sinnvoll. In der Shannonschen Entropieformel sollte also die Summe der Wahrscheinlichkeiten 1 ergeben, sonst kann das Ergebnis missverständlich sein.

Speichert man eine Folge von Münzwürfen als Bitfolge, dann bietet es sich an, "Kopf" stets durch 0 und "Zahl" stets durch 1 zu repräsentieren (oder umgekehrt). Bei der gezinkten Münze sind kompaktere Kodierungen möglich, zum Beispiel die Huffman-Kodierung.

Bei einem Wurf eines idealen Würfels mit sechs Möglichkeiten ist die Entropie größer als 1. Im Allgemeinen ist die Entropie größer als 1 für ein Zufallsereignis mit stochastisch unabhängigen Zufallsvariablen aus einem Zufallsexperiment mit mehr als zwei gleichberechtigten Möglichkeiten im Ergebnisraum. Ihr Wert wird bei gleich wahrscheinlichen Möglichkeiten im Ergebnisraum folgendermaßen berechnet:

Sei n die Anzahl der Möglichkeiten, dann sind die Wahrscheinlichkeiten formula_80 und die Entropie

Beim idealen Würfel sind sechs Möglichkeiten im Ergebnisraum. Daraus folgt die Entropie für einmaliges Werfen:

Einfach zu berechnen ist die Entropie eines Wurfes eines idealen Achterwürfels: Er hat acht gleichberechtigte Möglichkeiten.

Die Entropie eines Wurfes mit dem idealen Achterwürfel entspricht der Entropie von drei Würfen mit der idealen Münze.

Die Abbildung stellt den Zusammenhang zwischen der Entropie und der Zahl der gleichberechtigten Möglichkeiten eines Zufallsexperimentes dar.

Um zu testen, wie gut Daten komprimierbar sind, oder um Zufallszahlen zu testen, werden Entropietests verwendet. Als Zufallszahltest wird die Entropie einer bestimmten Anzahl von Zufallszahlen bestimmt und ab einem Mindestwert, beispielsweise 7 Bit je Byte, gilt er als bestanden. Allerdings gibt es viele solcher Tests, da die Entropie nicht eindeutig ist; sie kann beispielsweise bitbasiert oder bytebasiert definiert sein.

Ein einfaches Beispiel:

Eine Quelle, etwa ein Spielwürfel oder eine Münze, gebe nur die Werte 0xAA (dezimal 170) und 0x55 (dezimal 85) aus, beide mit gleicher Wahrscheinlichkeit. Bitweise ist die Ausgabe zu 50 % 0 oder 1, byteweise ist sie zu 50 % 0xAA oder 0x55. Die bitweise Entropie ist (mit formula_84)

während die byteweise Entropie mit

deutlich kleiner ist.

Der Hersteller dieses Zufallszahlengenerators wird natürlich als Entropie des Geräts die bitweise Entropie, also 1, angeben.
Analog wird ein Programmierer eines Kompressionsprogramms möglichst diejenige Basis wählen, bei der die Entropie minimal ist (hier Bytes), sich also die Daten am besten komprimieren lassen.

Dieses Beispiel ist wenig realistisch, da nur zwei von 256 möglichen Werten verwendet werden, aber wenn auch die anderen Bytes mit einer kleinen Wahrscheinlichkeit von beispielsweise 1/123456789 ausgegeben werden, so ändert dies an der bitweisen Entropie nichts und die byteweise wird kaum größer; sie bleibt unter 1/2. Erst mit Annäherung der Byte-Wahrscheinlichkeiten an 1/256 erreicht die byteweise Entropie den Wert 1, aber dann kann es noch Korrelationen der Bytes geben, also etwa die Folge "0xaaaa" viel häufiger sein als die Folge "0x5555". Dies ist der Hauptgrund, weshalb es viele verschiedene Zufallszahlentests gibt.

Diese Mehrdeutigkeit ist nicht möglich beim Entropiebelag, da dort nicht nur über Wahrscheinlichkeiten summiert wird, sondern über ergodische Wahrscheinlichkeiten von Zuständen, Zustandsübergangswahrscheinlichkeiten und bedingte Wahrscheinlichkeiten. Berechnet wird er mit der Theorie der Markow-Kette. Allerdings ist der Rechenaufwand dafür bei realen Zufallszahlengeneratoren hoch.

Es ist wichtig zu erklären, dass Entropietests nur Gleichwahrscheinlichkeit messen, und keine echte Unvorhersehbarkeit. Der Unterschied zwischen echten Zufallszahlengeneratoren und Pseudozufallszahlengeneratoren ist unmessbar.

Die Entropiekodierung ist ein Kompressionsalgorithmus, um Daten verlustfrei zu komprimieren. In diesem Zusammenhang spielen die Kreuzentropie sowie die Kullback-Leibler-Divergenz als Maß für die durch eine schlechte Kodierung ausgelösten Verschwendungen von Bits eine Rolle.

Beispiel:

Ein anderer Zugang, den Informationsgehalt einer Nachricht zu messen, ist durch die Kolmogorow-Komplexität gegeben, worin der kürzestmögliche Algorithmus zur Darstellung einer gegebenen Zeichenkette die Komplexität der Nachricht angibt. Ähnlich ist die Logische Tiefe definiert, die sich aber auf die Zeitkomplexität eines Algorithmus zur Erzeugung der Daten bezieht. Gregory Chaitin ist ebenfalls über die Shannonsche Definition der Entropie einer Information hinausgegangen (siehe Algorithmische Informationstheorie).

In der Physik (siehe Thermodynamik, speziell Entropie) spielt eine gleich benannte Größe eine wesentliche Rolle. Die physikalische Entropie unterscheidet sich von der Shannon'schen Informationsentropie durch einen zusätzlichen Normierungsfaktor formula_94, die Boltzmannsche Konstante, und durch die Ersetzung der im Logarithmus benutzten Basis (der "duale Logarithmus" wird durch den "natürlichen Logarithmus" ersetzt). Somit unterscheiden sich physikalische Entropie und mathematische Entropie durch den positiven Umrechnungsfaktor formula_95, versehen mit seiner physikalischen Einheit. Der Zusammenhang wurde durch ein Maxwellscher Dämon genanntes Gedankenexperiment hergestellt.





</doc>
<doc id="13040" url="https://de.wikipedia.org/wiki?curid=13040" title="Eigenwertproblem">
Eigenwertproblem

Ein Eigenvektor einer Abbildung ist in der linearen Algebra ein vom Nullvektor verschiedener Vektor, dessen Richtung durch die Abbildung nicht verändert wird. Ein Eigenvektor wird also nur skaliert und man bezeichnet den Skalierungsfaktor als Eigenwert der Abbildung.

Eigenwerte charakterisieren wesentliche Eigenschaften linearer Abbildungen, etwa ob ein entsprechendes lineares Gleichungssystem eindeutig lösbar ist oder nicht. In vielen Anwendungen beschreiben Eigenwerte auch physikalische Eigenschaften eines mathematischen Modells. Die Verwendung der Vorsilbe „Eigen-“ für charakteristische Größen in diesem Sinne lässt sich auf eine Veröffentlichung von David Hilbert aus dem Jahre 1904 zurückführen und wird als Germanismus auch in einigen weiteren Sprachen, darunter dem Englischen, verwendet.

Die im Folgenden beschriebene mathematische Problemstellung heißt "spezielles Eigenwertproblem" und bezieht sich nur auf lineare Abbildungen eines endlichdimensionalen Vektorraums in sich (Endomorphismen), wie sie durch quadratische Matrizen dargestellt werden.

Die Frage, die sich hier stellt, lautet: Unter welchen Bedingungen ist eine Matrix ähnlich zu einer Diagonalmatrix?

Ist formula_1 ein Vektorraum über einem Körper formula_2 (in Anwendungen meist der Körper formula_3 der reellen Zahlen oder der Körper formula_4 der komplexen Zahlen) und formula_5 eine lineare Abbildung von formula_1 in sich selbst (Endomorphismus), so bezeichnet man als "Eigenvektor" einen Vektor formula_7, der durch formula_8 auf ein Vielfaches formula_9 von sich selbst mit formula_10 abgebildet wird:
Den Faktor formula_12 nennt man dann den zugehörigen "Eigenwert."

Anders formuliert: Hat für ein formula_10 die Gleichung
eine Lösung formula_7 (der Nullvektor ist natürlich immer eine Lösung), so heißt formula_12 "Eigenwert" von formula_17 Jede Lösung formula_7 heißt "Eigenvektor" von formula_8 zum Eigenwert formula_20

Hat der Vektorraum eine endliche Dimension formula_21 so kann jeder Endomorphismus formula_8 durch eine quadratische formula_23 beschrieben werden. Die obige Gleichung lässt sich dann als Matrizengleichung
schreiben, wobei formula_25 hier einen Spaltenvektor bezeichnet. Man nennt in diesem Fall eine Lösung formula_26 Eigenvektor und formula_12 Eigenwert der Matrix formula_28

Diese Gleichung kann man auch in der Form
schreiben, wobei formula_30 die Einheitsmatrix bezeichnet, und äquivalent zu
oder
umformen.

Bei kleinen Matrizen können die Eigenwerte symbolisch (exakt) berechnet werden. Bei großen Matrizen ist dies oft nicht möglich, sodass hier Verfahren der numerischen Mathematik zum Einsatz kommen.

Die Gleichung
definiert die Eigenwerte und stellt ein homogenes lineares Gleichungssystem dar.
Da formula_34 vorausgesetzt wird, ist dieses genau dann lösbar, wenn
gilt. Diese Determinante heißt „charakteristisches Polynom“. Es handelt sich um ein normiertes Polynom formula_36-ten Grades in formula_20 Seine Nullstellen, also die Lösungen der Gleichung
über formula_2, sind die Eigenwerte. Da ein Polynom vom Grad formula_36 höchstens formula_36 Nullstellen hat, gibt es auch höchstens formula_36 Eigenwerte. Zerfällt das Polynom vollständig in Linearfaktoren, so gibt es genau formula_36 Nullstellen, wobei mehrfache Nullstellen mit ihrer Vielfachheit gezählt werden. Ist der Grad formula_36 eine ungerade Zahl und gilt formula_45 oder formula_46, dann ist mindestens einer der Eigenwerte reell.

Ist formula_12 ein Eigenwert der linearen Abbildung formula_48 dann nennt man die Menge aller Eigenvektoren zu diesem Eigenwert vereinigt mit dem Nullvektor den Eigenraum zum Eigenwert formula_20 Der Eigenraum ist durch
definiert. Falls die Dimension des Eigenraums größer als 1 ist, wenn es also mehr als einen linear unabhängigen Eigenvektor zum Eigenwert formula_12 gibt, so nennt man den zum Eigenraum zugehörigen Eigenwert "entartet." Die Dimension des Eigenraums formula_52 wird als "geometrische Vielfachheit" von formula_12 bezeichnet.

Eine Verallgemeinerung des Eigenraums ist der Hauptraum.

Für den Rest dieses Abschnittes sei formula_54 Dann besitzt jede formula_23 genau formula_36 Eigenwerte, wenn man diese mit ihren Vielfachheiten zählt. Mehrfaches Vorkommen eines bestimmten Eigenwertes fasst man zusammen und erhält so nach Umbenennung die Aufzählung formula_57 der "verschiedenen" Eigenwerte mit ihren Vielfachheiten formula_58 Dabei ist formula_59 und formula_60

Die eben dargestellte Vielfachheit eines Eigenwertes als Nullstelle des charakteristischen Polynoms bezeichnet man als algebraische Vielfachheit. Eigenwerte der algebraischen Vielfachheit formula_61 werden als einfacher Eigenwert bezeichnet.

Die Menge der Eigenwerte wird "Spektrum" genannt und formula_62 geschrieben, sodass also
gilt. Als Spektralradius bezeichnet man den größten Betrag aller Eigenwerte.

Gilt für einen Eigenwert, dass seine algebraische Vielfachheit gleich seiner geometrischen Vielfachheit ist, so spricht man von einem halbeinfachen Eigenwert (aus dem englischen ‚semisimple‘). Dies entspricht genau der Diagonalisierbarkeit der Blockmatrix zum gegebenen Eigenwert.

Kennt man die Eigenwerte sowie ihre algebraischen und geometrischen Vielfachheiten (siehe unten), kann man die Jordansche Normalform der Matrix erstellen.

Es sei die quadratische Matrix
gegeben. Subtraktion der mit formula_12 multiplizierten Einheitsmatrix von formula_66 ergibt:
Ausrechnen der Determinante dieser Matrix (mit Hilfe der Regel von Sarrus) liefert:
Die Eigenwerte sind die Nullstellen dieses Polynoms, man erhält:
Der Eigenwert 2 hat algebraische Vielfachheit 2, weil er doppelte Nullstelle des charakteristischen Polynoms ist.

Während die exakte Berechnung der Nullstellen des charakteristischen Polynoms schon für dreireihige Matrizen nicht so einfach ist, wird sie für große Matrizen meist unmöglich, sodass man sich dann auf das Bestimmen von Näherungswerten beschränkt. Hierzu werden Verfahren bevorzugt, die sich durch numerische Stabilität und geringen Rechenaufwand auszeichnen. Dazu gehören Methoden für dichtbesetzte kleine bis mittlere Matrizen, wie
sowie spezielle Methoden für symmetrische Matrizen als auch Methoden für dünnbesetzte große Matrizen wie
Des Weiteren gibt es noch Methoden zur Abschätzung, z. B. mithilfe
die immer eine grobe Abschätzung (unter gewissen Bedingungen sogar genaue Bestimmung) zulassen.

Für einen Eigenwert formula_12 lassen sich die Eigenvektoren aus der Gleichung
bestimmen. Die Eigenvektoren spannen den Eigenraum auf, dessen Dimension als "geometrische Vielfachheit" des Eigenwertes bezeichnet wird. Für einen Eigenwert formula_12 der geometrischen Vielfachheit formula_73 lassen sich also formula_73 linear unabhängige Eigenvektoren formula_75 finden, sodass die Menge aller Eigenvektoren zu formula_12 gleich der Menge der Linearkombinationen von formula_75 ist. Die Menge formula_78 heißt dann eine "Basis aus Eigenvektoren" des zum Eigenwert formula_12 gehörenden Eigenraumes.

Die geometrische Vielfachheit eines Eigenwertes kann man also auch als die maximale Anzahl linear unabhängiger Eigenvektoren zu diesem Eigenwert definieren.

Die geometrische Vielfachheit ist höchstens gleich der algebraischen Vielfachheit.

Gegeben ist wie in obigem Beispiel die quadratische Matrix
Die Eigenwerte formula_81 wurden oben schon berechnet. Zunächst werden hier die Eigenvektoren (und der durch die Eigenvektoren aufgespannte Eigenraum) zum Eigenwert formula_82 berechnet:
Man muss also das folgende lineare Gleichungssystem lösen:
Bringt man die Matrix auf obere Dreiecksform, so erhält man:
Die gesuchten Eigenvektoren sind alle Vielfachen des Vektors formula_86 (jedoch nicht das Nullfache des Vektors, da der Nullvektor niemals ein Eigenvektor ist).

Obwohl der Eigenwert formula_82 eine algebraische Vielfachheit von 2 hat, existiert "nur ein" linear unabhängiger Eigenvektor (der Eigenraum zu dem Eigenwert ist "ein"dimensional); also hat dieser Eigenwert eine geometrische Vielfachheit von 1. Das hat eine wichtige Konsequenz: Die Matrix ist nicht diagonalisierbar. Man kann nun versuchen, die Matrix stattdessen in die Jordansche Normalform überzuführen. Dazu muss ein weiterer Eigenvektor zu diesem Eigenwert „erzwungen“ werden. Solche Eigenvektoren nennt man generalisierte Eigenvektoren oder Hauptvektoren.

Für den Eigenwert formula_88 geht man genauso vor:
Wieder bringt man die Matrix auf Dreiecksform:
Hier ist die Lösung der Vektor formula_91 wieder mit allen seinen vom Nullvektor verschiedenen Vielfachen.


Speziell für reelle symmetrische oder komplexe hermitesche Matrizen gilt:


Für kommutierende diagonalisierbare (insbesondere symmetrische) Matrizen ist es möglich, ein System gemeinsamer Eigenvektoren zu finden:

Kommutieren zwei Matrizen formula_66 und formula_111 (gilt also formula_112) und ist formula_12 ein nichtentarteter Eigenwert (d. h., der zugehörige Eigenraum ist eindimensional) von formula_66 mit Eigenvektor formula_115 so gilt
Auch formula_117 ist also ein Eigenvektor von formula_66 zum Eigenwert formula_20 Da dieser Eigenwert nicht entartet ist, muss formula_117 ein Vielfaches von formula_121 sein. Das bedeutet, dass formula_121 auch ein Eigenvektor der Matrix formula_111 ist.

Aus diesem einfachen Beweis geht hervor, dass die Eigenvektoren zu nichtentarteten Eigenwerten mehrerer paarweise kommutierender Matrizen Eigenvektoren aller dieser Matrizen sind.

Allgemein können auch für kommutierende diagonalisierbare Matrizen mit entarteten Eigenwerten gemeinsame Eigenvektoren gefunden werden. Aus diesem Grund können mehrere paarweise kommutierende diagonalisierbare Matrizen auch simultan (d. h. mit einer Basistransformation für alle Matrizen) diagonalisiert werden.

Manchmal bezeichnet man einen so definierten Eigenvektor auch als "Rechtseigenvektor" und definiert dann entsprechend den Begriff des "Linkseigenvektors" durch die Gleichung
Linkseigenvektoren finden sich z. B. in der Stochastik bei der Berechnung von stationären Verteilungen von Markow-Ketten mittels einer Übergangsmatrix.

Wegen formula_125 sind die Linkseigenvektoren von formula_66 gerade die Rechtseigenvektoren der transponierten Matrix formula_127
Bei normalen Matrizen fallen Links- und Rechtseigenvektoren zusammen.

Allgemeiner kann man auch quadratische Matrizen formula_66 und formula_111 und die Gleichung
untersuchen. Dieses verallgemeinerte Eigenwertproblem wird hier jedoch nicht weiter betrachtet.

In der Funktionalanalysis betrachtet man lineare Abbildungen zwischen linearen Funktionenräumen (also lineare Abbildungen zwischen unendlichdimensionalen Vektorräumen). Meistens spricht man von linearen Operatoren anstatt von linearen Abbildungen. Sei formula_1 ein Vektorraum über einem Körper formula_2 mit formula_133 und formula_66 ein linearer Operator. In der Funktionalanalysis ordnet man formula_66 ein Spektrum zu. Dieses besteht aus allen formula_136 für die der Operator formula_137 nicht invertierbar ist. Dieses Spektrum muss jedoch nicht – wie bei Abbildungen zwischen endlichdimensionalen Vektorräumen – diskret sein. Denn im Gegensatz zu den linearen Abbildungen zwischen endlichdimensionalen Vektorräumen, die nur formula_138 verschiedene Eigenwerte haben, haben lineare Operatoren im Allgemeinen unendlich viele Elemente im Spektrum. Daher ist es zum Beispiel möglich, dass das Spektrum von linearen Operatoren Häufungspunkte besitzt. Um die Untersuchung des Operators und des Spektrums zu vereinfachen, unterteilt man das Spektrum in unterschiedliche Teilspektren. Elemente, die die Gleichung formula_139 für ein formula_34 lösen, nennt man wie in der linearen Algebra "Eigenwerte." Die Gesamtheit der Eigenwerte nennt man das "Punktspektrum" von formula_28 Wie in der linearen Algebra wird jedem Eigenwert ein Raum von Eigenvektoren zugeordnet. Da die Eigenvektoren meist als Funktionen aufgefasst werden, spricht man auch von Eigenfunktionen.

Sei formula_142 offen. Dann besitzt der Ableitungsoperator formula_143 ein nichtleeres Punktspektrum. Betrachtet man nämlich für alle formula_144 die Gleichung
und wählt formula_146 dann sieht man, dass die Gleichung formula_147 für alle formula_148 erfüllt ist. Also ist jedes formula_149 ein Eigenwert mit zugehöriger Eigenfunktion formula_150

Durch Lösung eines Eigenwertproblems berechnet man
Eigenwerte spielen in der Quantenmechanik eine besondere Rolle. Physikalische Größen wie z. B. der Drehimpuls werden hier durch Operatoren repräsentiert. Messbar sind nur die Eigenwerte der Operatoren. Hat z. B. der Hamiltonoperator, der die Energie eines quantenmechanischen Systems repräsentiert, ein diskretes Spektrum, so kann die Energie nur diskrete Werte annehmen, was z. B. für die Energieniveaus in einem Atom typisch ist. So stellen bei den Lösungen der bekannten Schrödingergleichung (im Jahr 1926 durch den Physiker Erwin Schrödinger aufgestellt) die Eigenwerte die erlaubten Energiewerte der Elektronen und die Eigenfunktionen die zugehörigen Wellenfunktionen der Elektronen dar.

Auch die Unmöglichkeit der gleichzeitigen präzisen Messung gewisser Größen (z. B. von Ort und Impuls), wie von der Heisenbergschen Unschärferelation ausgedrückt, ist letztlich darauf zurückzuführen, dass für die jeweiligen Operatoren kein gemeinsames System von Eigenvektoren existiert.




</doc>
<doc id="13041" url="https://de.wikipedia.org/wiki?curid=13041" title="Drama">
Drama

Drama ( "dráma" ,Handlung‘) ist ein Oberbegriff für Texte mit verteilten Rollen. Die Dramatik ist neben der Epik und der Lyrik eine der drei grundlegenden literarischen Gattungen.

Manchmal wird der Begriff Drama sehr weit gefasst und schließt sämtliche Theaterstücke, Operntexte, Ballettszenarien, Hörspielmanuskripte oder Drehbücher mit ein, manchmal wird er als Eingrenzung verwendet, etwa nur für Sprechtheater oder nur für die „gehobenen“ (oder im Gegenteil für die besonders spannenden oder sentimentalen) Theaterstücke. Drama ist Theater mit Textgrundlage, im Unterschied zum improvisierten Stegreiftheater.

Das Hauptkennzeichen des Dramas nach Aristoteles ist die Darstellung der Handlung durch Dialoge. Dadurch unterscheidet es sich in der Antike vom erzählenden Epos – seit der Neuzeit unterscheidet es sich damit hauptsächlich vom Roman. Nach modernem Verständnis sind Dramen dafür geschrieben, durch Schauspieler im Theater aufgeführt zu werden. Oft enthalten sie daher neben den Dialogtexten auch Anweisungen für die Schauspieler und seit dem 19. Jahrhundert für den Regisseur. Das Lesedrama ist eine spezielle Form des Dramas, die nicht in erster Linie aufgeführt, sondern wie ein Roman gelesen werden soll.

Die Handlung eines Dramas ist häufig in Akte und diese wiederum sind in Szenen oder Auftritte gegliedert. Wenn es mehrere Dekorationen pro Akt gibt, gibt es manchmal eine zusätzliche Einteilung in Bilder. Das klassische französische Drama (Racine, Corneille) teilt sich in fünf Akte. Die italienische, stark mit der Oper verbundene Tradition (vgl. Metastasio) bevorzugt drei Akte. Die Form des Einakters ist aus Zwischenspielen zwischen den Akten der drei- bis fünfaktigen Dramen hervorgegangen.

Das europäische Drama entstand zur Zeit der griechischen Antike im 5. Jahrhundert v. Chr. in Athen: Aischylos, Sophokles und Euripides waren die wichtigsten Dichter der Tragödie. Aristoteles unterteilte im darauf folgenden Jahrhundert in seiner "Poetik" das Drama in die Tragödie und die später entstandene Komödie. Seine Theorie der Katharsis wurde wegweisend für die europäische Dramengeschichte.

Das geistliche Spiel des Mittelalters ist weder Tragödie noch Komödie. Erst seit der Renaissance erfolgte eine Weiterentwicklung des antiken Dramas. Lange Zeit war das Versdrama die vorherrschende Gattung. In neuerer Zeit überwiegt in den Sprechstücken freie Prosa. – Dass ein Drama gesprochen wird, ist nicht selbstverständlich. Die Oper ab etwa 1600 verstand sich als Wiedergeburt des klassischen griechischen Dramas (siehe Florentiner Camerata).

Während die spanische und englische Dramatik um 1600 (Lope de Vega, Shakespeare) noch Ausläufer einer mittelalterlichen Theatertradition ohne theoretischen Hintergrund waren, besann sich die Französische Klassik auf das antike Drama und legte strenge Regeln dafür fest ("doctrine classique", Regeldrama), zum Beispiel die sogenannten Drei Aristotelischen Einheiten. Seither haben Dramentheorien eine wichtige gesellschaftliche Funktion, indem sie versuchen, Normen aufzustellen oder zu bekämpfen.

Seit dem 18. Jahrhundert sind Bezeichnungen wie Schauspiel, Lustspiel, Tragikomödie, Rührende Komödie, Bürgerliches Trauerspiel mit überlappenden Bedeutungen in Gebrauch. Seit dem 19. Jahrhundert wird das Melodrama, das besonders gefühlsbetonte oder spannende Handlungen hat, oft zum Begriff Drama verkürzt.

Manchmal wird das Drama von anderen Theatergattungen unterschieden. Johann Wolfgang Goethe grenzte es von der Tragödie ab (das modernere Drama sei vom „Wollen“, die ältere Tragödie vom „Sollen“ bestimmt), Gustav Freytag unterschied es vom Schauspiel (als einer weniger hochstehenden Gattung). Beide versuchten mit dem Begriff Drama ein „ernstes“ Theater zu umschreiben, das keine klassische Tragödie war.

Aus der Theatertheorie des 20. Jahrhunderts stammen Unterteilungen wie Soziales Drama, Analytisches Drama oder Geschlossene und offene Form im Drama. In dieser Zeit haben neue Medien zu neuen Formen der Dramatik geführt, wie dem Hörspiel oder dem Filmdrama.

Kein dramatischer Text, sondern eine Therapiemethode ist das Rollenspiel im Psychodrama.

In den letzten Jahrzehnten haben sich viele Theaterformen ohne Dramentext etabliert, die auch unter dem Schlagwort Postdramatisches Theater zusammengefasst werden. Umgekehrt wird die strenge Unterscheidung zwischen improvisiertem und schriftlich festgelegtem Dialog durch Formen des Rollenspiels im Internet (Chat) aufgeweicht.





</doc>
<doc id="13043" url="https://de.wikipedia.org/wiki?curid=13043" title="Tragödie">
Tragödie

Die Tragödie ist eine Form des Dramas und neben der Komödie die bedeutsamste Vertreterin dieser Gattung. Sie lässt sich bis in das antike Griechenland zurückführen.

Kennzeichnend für die Tragödie ist der schicksalhafte Konflikt der Hauptfigur. Ihre Situation verschlechtert sich ab dem Punkt, an dem die Katastrophe eintritt. In diesem Fall bedeutet das Wort Katastrophe nur die unausweichliche Verschlechterung für den tragischen Helden. Allerdings bedeutet diese Verschlechterung nicht zwangsläufig den Tod des Protagonisten.

Das Scheitern des Helden ist in der Tragödie unausweichlich; die Ursache liegt in der Konstellation und dem Charakter der Figur. Der Keim der Tragödie ist, dass der Mensch der Hybris verfällt und dem ihm vorbestimmten Schicksal durch sein Handeln entgehen will.

Das Wort „Tragödie“ entstammt dem Theater der griechischen Antike und bezeichnet einen "„Bocksgesang“" bzw. „Gesang um den Bockspreis“ (griech. τραγωδία, "tragodía").
Beim Dionysoskult wurde ein „Komos“ (altgriechisch "kōmos") veranstaltet, ein festlicher Straßenumzug oder eine Prozession mit Gesang, verkleidet mit Maske und Bocksfell (griech. τράγος/"tragos"), zur Darstellung des Gottes selbst oder der ihn begleitenden Satyrn. So entwickelte sich die Form der Tragödie aus einem im Chor gesungenen Mythos, der Dichtung einer meist heldischen Vergangenheit. Die Chorpartien der erhaltenen Dramen sind Rudimente dieser Urform, der Dialog und die dargestellte Handlung spätere Entwicklungen, in historischer Sicht sekundär. Träger der Handlung im Drama war ursprünglich ein einziger Schauspieler, ein Sprecher, der mehrere Figuren repräsentieren konnte, indem er ihre Reden übernahm. Erst Aischylos führte einen zweiten Schauspieler ein. Das Chorlied entwickelte seine eigene Chorlyrik, es entstanden Spezialformen mit eigenen Bezeichnungen, Hymne, Paian, Dithyrambus, Epinikion, Epithalamium, und andere mehr.

Im Kontext der Tragödie bedeutet „tragisch“ im Gegensatz zur Alltagssprache aber nicht, dass etwas sehr traurig ist, sondern dass jemand aus einer hohen Stellung „schuldlos schuldig“ wird und damit den Sturz über eine große „Fallhöhe“ (→Ständeklausel) erlebt, wie zum Beispiel Ödipus, Orestes, Hamlet oder Maria Stuart.

Für Hegel steht nicht der tragische Held, sondern die tragische Kollision im Mittelpunkt der Tragödie. Der Konflikt besteht für ihn „nicht zwischen Gut und Böse, sondern zwischen einseitigen Positionen, von denen jede etwas Gutes enthält“.

Walter Benjamin unterscheidet mit Rückgriffen auf Franz Rosenzweig und Georg Lukács die Tradition des christlichen Trauerspiels von der griechischen Tragödie und kritisiert damit die Idee einer historischen Kontinuität des Sagenstoffes bei Wagner und Nietzsche.

Wichtig ist, dass Walter Benjamin die Tragödie nicht mit dem Trauerspiel gleichsetzt. Nach Aristoteles ist die Tragödie die „Nachahmung einer guten, in sich geschlossenen Handlung mit guter Sprache und Abwechslungsreichtum in der Geschichte“. Hierbei bedient sie sich mythologischer Figuren. Das Trauerspiel jedoch bedient sich geschichtlicher Figuren.

Ein zentrales Definitionselement der Gattung "Tragödie" ist die Wirkung auf den Zuschauer. Hier unterscheiden sich die vielen Theorien über die Tragödie. Es handelt sich dabei um ein Übersetzungs- und Deutungsproblem der drei Begriffe eleos, phobos und Katharsis aus der Poetik des Aristoteles. In einer aktuellen Übersetzung definiert Aristoteles die Tragödie wie folgt:
Die Begriffe "eleos" und "phobos" wurden jedoch lange Zeit mit ‘Mitleid’ und ‘Schrecken’ übersetzt. In Gottscheds Poetik wurden diese beiden Übersetzungen um den Begriff ‘Bewunderung’ erweitert, den er von Corneille übernommen hatte. In der Zeit der Aufklärung stellte sich Lessing vehement gegen diese Auslegung und verbannte den bei Aristoteles nicht vorkommenden Begriff "Verwunderung" wieder. Zudem passte die Übersetzung von "phobos" nicht in seine Tragödienkonzeption, weshalb er das Wort umdeutete:

Lessings Übersetzung wurde lange Zeit beibehalten, jedoch von der neueren Forschung teils scharf kritisiert, sodass etwa Manfred Fuhrmann "eleos" und "phobos" die Begriffe als ‘Jammer’ und ‘Schaudern’ übersetzt.

Noch problematischer ist der Katharsis-Begriff. Selbst bei Aristoteles ist es nicht ganz klar, wie er den Genitiv, der sich auf die Reinigung bezieht, meint. So haben wir es schließlich mit gleich drei zur Wahl stehenden Genitiven zu tun:

In der Praxis werden die Gefühle des Zuschauers einer Tragödie oft durch ein geschickt angelegtes Wechselspiel der Ereignisse zwischen der Sympathie mit dem Helden, dem Erschrecken vor dem näher rückenden, unabänderlichen Ende und der immer wieder angeregten Hoffnung auf einen günstigeren Ausgang hin und her gezogen. Um dieses Wechselbad der Gefühle zu erzeugen, wenden die Autoren bestimmte Hilfsmittel an.

Eines dieser Hilfsmittel ist die Einfügung einer possenhaften Szene unmittelbar vor einem wichtigen Ereignis, um die Spannung zu entlasten (Comic relief). Beispiele hierfür sind der Auftritt des Leichenwächters in Sophokles’ "Antigone" oder der übernächtigte Torwächter in William Shakespeares "Macbeth".

Häufig hört man zu Beginn des Spiels die Ankündigung, der „Held“ werde sterben. Damit wird die moralische Wirkung auf den Zuschauer erhöht, denn die Ankündigung wird zwar ernst und in sich glaubwürdig vorgetragen, die weiteren Umstände der Szene bewegen den Zuschauer jedoch dazu, sich selbst zu täuschen und die Voraussage als unsinnig abzutun. Im Prolog von Shakespeares "Romeo und Julia" wird etwa schon verkündet, dass die Liebenden sterben werden, der Spannung und Dramatik des Stücks tut dies aber keinen Abbruch.

→ "Siehe auch: Griechische Tragödie"

Die Tragödie hat ihre Ursprünge in Griechenland und erlebte dort von 490 bis 406 v. Chr. ihre Blütezeit. Die bedeutendsten Tragödiendichter der Antike waren die Griechen Aischylos (525–456 v. Chr.), Sophokles (496–406 v. Chr.) und Euripides (480–406 v. Chr.). In "Die Geburt der Tragödie aus dem Geiste der Musik" vertritt Friedrich Nietzsche die Auffassung, dass die Tragödie aus dem rituellen Chortanz des Dionysoskultes entstanden und nach dem Tod von Sophokles und Euripides vom kritischen sokratischen Geist zerstört worden sei.

→ "Siehe auch: Römische Tragödie"

Die römische Tragödie wurde stark von den großen griechischen Tragödiendichtern beeinflusst. Deren bedeutendste Vertreter waren Quintus Ennius (239–169 v. Chr.) und Lucius Accius (170–90/80 v. Chr.), von denen nur Fragmente überliefert sind, sowie später Lucius Annaeus Seneca (4 v. Chr.–65 n. Chr.).

Eine sehr große Rolle spielte die Gattung Tragödie in der Literatur der französischen Klassik des 17. und frühen 18. Jahrhunderts. Ihre bedeutendsten Autoren waren Pierre Corneille, Jean Racine und Voltaire. Nach der von ihnen etablierten Praxis hatte eine Tragödie in fürstlichen Kreisen zu spielen und die drei Einheiten der Zeit, des Ortes und der Handlung einzuhalten. Die Stoffe stammten ganz überwiegend aus der antiken griechischen und römischen Geschichte sowie aus der Mythologie. Versmaß war in aller Regel der paarweise reimende Alexandriner mit „alternance“ d. h. regelmäßigem Wechsel männlicher und weiblicher Reime.

→ "Hauptartikel: Bürgerliches Trauerspiel"

Im Zuge der Emanzipationsbewegung des 18. Jahrhunderts entstand das Bürgerliche Trauerspiel, das sich vom Zwang nach adeligen Hauptpersonen entfernte und die Tragödie für das Bürgertum erschloss. Als man den Gedanken verwarf, dass nur der Adel die Fähigkeit zum tragischen Erleben habe, eröffneten sich auch neue Thematiken wie der Konflikt zwischen Adel und Bürgertum (Friedrich Schiller, "Kabale und Liebe") oder Konflikte innerhalb des Standes (Friedrich Hebbel, "Maria Magdalena" oder Goethes "Faust. Eine Tragödie").




</doc>
<doc id="13044" url="https://de.wikipedia.org/wiki?curid=13044" title="Multiplikation">
Multiplikation

Die Multiplikation (, von "multiplicare" ‚vervielfachen‘, auch Malnehmen genannt) ist eine der vier Grundrechenarten in der Arithmetik. Ihre Umkehroperation ist die Division (das Teilen). Das Rechenzeichen für die Multiplikation ist das Malzeichen „·“ bzw. „×“.

Die Multiplikation natürlicher Zahlen entsteht durch das wiederholte Addieren (Zusammenzählen) des gleichen Summanden:

formula_2 und formula_3 nennt man Faktoren, wobei formula_2 auch als "Multiplikator" und formula_3 auch als "Multiplikand" bezeichnet werden. 

Die Rechnung, gesprochen „formula_2 mal formula_3“, heißt Multiplikation. Das Ergebnis Produkt.

Merkhilfe:

Zum Beispiel schreibt man formula_8 für formula_9, und spricht diesen Term als „drei mal vier“. Anstelle von formula_10 wird manchmal auch formula_11 oder formula_12 geschrieben.

Bei der Multiplikation mit Variablen wird der Punkt oft weggelassen formula_13. Zur richtigen Schreibweise siehe Malzeichen.

Bei der Multiplikation mehrerer oder vieler Zahlen kann man das Produktzeichen formula_14 (abgeleitet vom großen griechischen Pi) verwenden:
formula_16 sind ganze Zahlen, formula_17 wird Laufvariable genannt. Im Fall formula_18 hat man das leere Produkt, welches als formula_19 definiert ist.

Beispiele:
oder auch

Die unter anderem in der Kombinatorik häufig verwendete Fakultät ist eine besondere Multiplikation natürlicher Zahlen:

Wiederholtes Multiplizieren mit dem gleichen Faktor führt zum Potenzieren, z. B. ist
Die anschauliche Verallgemeinerung der Multiplikation und ihrer Rechenregeln auf die rationalen und reellen Zahlen erreicht man durch Betrachten eines Rechtecks mit den Seitenlängen formula_2 und formula_3 (in einer vorgegebenen Längeneinheit). Der Flächeninhalt dieses Rechtecks (in der entsprechenden Flächeneinheit) ist definiert als das Produkt formula_26.

Die Multiplikation rationaler Zahlen lässt sich auch formal mit Hilfe von Brüchen definieren. Ebenso kann man die Multiplikation während des Konstruktionsvorganges der reellen aus den rationalen Zahlen definieren.

Die Umkehroperation zur Multiplikation ist die Division, die auch als Multiplikation mit dem Kehrwert aufgefasst werden kann.

In einem Körper formula_27 (also insb. formula_28) gelten für alle formula_29 (siehe Mathematik)

Die Multiplikation von formula_30 kann nach folgendem Algorithmus berechnet werden, wobei r die Radix (Basis) und n,m die Stellen darstellen:

formula_31

formula_32

formula_33

formula_34

Der Algorithmus beruht darauf, dass die einzelnen Stellen einer Zahl mit der anderen Zahl multipliziert und geschoben werden. Am Schluss werden die ausmultiplizierten und geschobenen Zahlen addiert.

Bei der Multiplikation einer Anzahl beliebiger Faktoren wird dann das größtmögliche Produkt erreicht, wenn bei gleichbleibender Summe der Faktoren die Gesamtdifferenz zwischen den Faktoren möglichst gering ist. Die Gesamtdifferenz errechnet sich, indem man alle Differenzen zwischen den Faktoren addiert.

"Produkt dreier Faktoren. Die Summe der Faktoren ist jeweils 30." 
"Mit steigender Gesamtdifferenz zwischen den Faktoren wird das Produkt (in der Regel) kleiner."

Die Gaußsche Summenfaktor-Regel ist äquivalent mit der Aussage, dass der Inhalt einer geometrischen Figur maximal ist, wenn dessen Seiten gleiche Länge haben. So ist das Quadrat bei gleichem Umfang das Rechteck mit dem größten Flächeninhalt.

Das Produkt von mehr als zwei Faktoren wird so definiert, dass man von links beginnend je zwei Faktoren multipliziert und so fortfährt, bis nur eine Zahl übrigbleibt. Das Assoziativgesetz besagt nun, dass man an beliebiger Stelle beginnen kann; also auch von rechts. Aufgrund des Kommutativgesetzes ist auch die Reihenfolge irrelevant, so dass mit zwei beliebigen Faktoren (welche also nicht direkt beieinanderstehen müssen) angefangen werden kann.

Auch das Produkt von einem einzigen oder von gar keinen Faktoren ist definiert, obwohl man dazu nicht mehr multiplizieren muss: Das Produkt einer Zahl ist diese Zahl selbst, und das Produkt von keinem Faktor ist 1 (allgemein das neutrale Element der Multiplikation).

Es ist auch möglich, ein unendliches Produkt zu bilden. Dabei spielt die Reihenfolge der Faktoren allerdings eine Rolle, man kann die Faktoren also nicht mehr beliebig vertauschen, und auch beliebige Zusammenfassungen zu Teilprodukten sind nicht immer möglich. (Ähnlich wie bei unendlichen Summen.)

Nicht nur das Addieren, sondern auch das Multiplizieren lässt sich in begrenztem Umfang mit den Fingern bewerkstelligen. Hierzu müssen beide Faktoren in ein und derselben Dekadenhälfte liegen, also entweder beide auf Ziffern von 1 bis 5 oder auf Ziffern von 6 bis 0 enden.

Im ersten Fall nummeriert man die Finger beginnend beim kleinen Finger mit 10 · ("d"-1) + 1 bis 10 · ("d"-1) + 5 für den Daumen durch, wobei "d" für die Dekade der entsprechenden Zahl steht (also beispielsweise 11 bis 15 für die zweite Dekade). Danach hält man die zwei Finger, deren Produkt man ausrechnen will, aneinander. Das entsprechende Produkt erhält man, indem man die unteren Finger zählt (die beiden aneinandergehaltenen Finger zählen dazu) und mit ("d"-1) · 10 multipliziert, dazu das Produkt der unteren Finger der linken Hand mit den unteren Fingern der rechten Hand (jeweils mit den zusammengehaltenen Fingern) und schließlich eine additive Konstante ("d"-1)² · 100 addiert.

Im zweiten Fall nummeriert man die Finger von 10 · ("d"-1) + 6 bis 10 · "d" durch (also beispielsweise 16 bis 20). Danach hält man analog zum ersten Fall die beiden Finger der gewünschten Faktoren aneinander, zählt die unteren Finger, aber multipliziert diese jetzt mit "d" · 10 und zählt zu diesem das Produkt der oberen Finger (wieder ohne die zusammengehaltenen Finger) hinzu und die additive Konstante ergibt sich als ("d"-1) · "d" · 100.



Besonders geeignet ist dieses Verfahren für das schnelle Errechnen von Quadratzahlen ohne Taschenrechner. Für Faktoren verschiedener Dekaden und Dekadenhälften kann man dieses Verfahren immer noch anwenden, indem man die Faktoren in Summen aufspaltet.

Hintergrund für dieses Verfahren ist die Tatsache, dass man solche Produkte schreiben kann als:

und Produkte der zweiten Dekadenhälfte errechnen kann, indem man die Komplemente der letzten Ziffer bzgl. 10 bildet. Die letzte Ziffer ist dann das Produkt der Komplemente, die "Zehner" das Komplement der Summe der Komplemente.

Diese Rechenart kommt aus Indien und ist ein Teil der sogenannten vedischen Mathematik. Bei diesem Rechensystem werden zuerst die Zahlen analysiert und danach ein passendes Verfahren zu deren Berechnung ausgewählt. So existiert z. B. ein Verfahren, welches sich immer dann zu einer „Blitz“-Multiplikation auch großer Faktoren eignet, wenn diese knapp unter oder über derselben Zehnerpotenz liegen. 

Dem Rechenweg liegt folgende Beziehung zugrunde: formula_2 und formula_3 seien zwei Zahlen dicht unterhalb einer Zehnerpotenz formula_38 und formula_39 bzw. formula_40 die Differenzen hierzu. Dann ist

Falls nun formula_42 ist, kann man die beiden Ziffernfolgen von formula_43 und formula_44 einfach nebeneinander schreiben, um so zur Lösung der Multiplikation zu gelangen. (Achtung: Führende Nullen des zweiten Terms müssen mitgeschrieben werden.)


Im letzten Fall liegt eine Zahl über und eine unter 100. Da in diesem Fall das Produkt formula_45 ist, muss von der linken Zahl noch ein Übertrag besorgt werden, also links formula_46, rechts formula_47.

Natürlich ergibt eine Vertauschung der Faktoren dasselbe Ergebnis, da: formula_48 ist, siehe dazu die letzte Zeile des Beispiels. Da gleiche Vorzeichen beim Multiplizieren von zwei Zahlen immer zu + werden, kann man sie für diese Fälle auch weglassen wie in der letzten Zeile angegeben.

Als Basis können außerdem noch formula_49 und formula_50 verwendet werden. Berechnet wird hier wie bei formula_38, nur wird rechts formula_52 bzw. formula_53 als Differenz gebildet und links mit 2 multipliziert (Basis 20) bzw. durch 2 dividiert (Basis 50). Für die Basis 50 wird im Fall, dass die linke Summe ungerade ist, nur der ganzzahlige Anteil nach Division durch 2 verwendet und als Übertrag rechts formula_54 addiert. Beweis entsprechend zu formula_38 durch einsetzen und umformen.

A und B seien ganzzahlige Faktoren.
Das Produkt P = A · B kann auch auf folgende – scheinbar kuriose – Art ermittelt werden:

Beispiel: 11 · 3 = ?

In der Spalte A werden Streichungen vorgenommen, wo bei der dezimalen Zahl 11 in der binären Darstellung Nullen stehen: 11(dezimal) = 1011(binär). Dabei ist die Spalte A von unten nach oben zu lesen. Diese Methode ist auch die einfachste Art, dezimale Zahlen in binäre zu transformieren. Die fortlaufenden Verdoppelungen in der Spalte B entsprechen den Zweierpotenzen des binären Zahlensystems, multipliziert mit dem zweiten Faktor. Wo in Spalte A eine Null steht, wird die entsprechende Zahl in B mit 0 multipliziert, daher gestrichen. Alle übrigen Zahlen der Spalte B gehören zum Produkt und werden summiert.

Man kann dies auch leicht anders formulieren.

Die letzte Gleichung kommt der binären Darstellung 1011 von 11 gleich.

Für eine graphische Multiplikation mit Zirkel und Lineal kann man den Sehnensatz verwenden: Durch einen Punkt "O" zeichnet man eine Gerade und trägt von "O" aus die zu multiplizierenden Längen formula_2 und formula_3 in entgegengesetzten Richtungen ab. 
Dadurch entstehen zwei neue Punkte "A" und "B". Durch "O" zeichnet man eine zweite Gerade. Auf dieser trägt man eine Strecke der Länge eins ab, wodurch ein weiterer Punkt "E" entsteht. Die zweite Gerade wird durch den Kreis durch die Punkte "A", "B" und "E" in einem Punkt "C" geschnitten. Der Abstand von "O" und "C" hat nach dem Sehnensatz die gesuchte Länge

Den benötigten Kreis kann man als Umkreis um das von "A", "B" und "E" aufgespannte Dreieck konstruieren.
Neben dem Sehnensatz ist auch der Sekantensatz für die Konstruktion des Produkts zweier Zahlen dienlich. Bei Verwendung des Sekantensatzes liegt der Startpunkt "O" außerhalb des Kreises, und die Größen "a" und "b" werden von "O" aus gesehen in die gleiche Richtung abgetragen. Dementsprechend liegt dann auch "C" von "O" aus gesehen in der gleichen Richtung, in der die Eins abgetragen wurde.
Eine weitere Möglichkeit zur graphischen Multiplikation mit Zirkel und Lineal ergibt sich aus dem Strahlensatz. Hier trägt man zunächst auf einem Strahl mit Ausgangspunkt "A" Strecken der Längen 1 und "b", die beide in "A" beginnen. Dann trägt man vom Endpunkt "E" der Strecke der Länge 1 eine Strecke der Länge "a" ab und zeichnet einen zweiten Strahl durch deren Endpunkt "C" und "A", so dass "A" wiederum der Ausgangspunkts des Strahls ist. Dann zeichnet man durch den Endpunkt "B" der Strecke "b" eine zu "a" parallele Gerade. Diese schneidet den zweiten Strahl in "D". Die Länge der Strecke BD entspricht dem Produkt von "a" und "b".

Die bekannte Multiplikation reeller Zahlen kann zur Multiplikation komplexer Zahlen verallgemeinert werden, indem man eine imaginäre Einheit "i" einführt und die Faktoren in der Form "a"+"b"·i formal ausmultipliziert.

Durch Forderung einiger der oben angegebenen Rechengesetze gelangt man zu algebraischen Strukturen mit zwei Verknüpfungen, einer Addition und einer Multiplikation. In einem Ring gibt es eine Addition, mit der die Menge eine Abelsche Gruppe bildet, und eine Multiplikation, die assoziativ und distributiv ist. Hat die Multiplikation ein neutrales Element, nennt man den Ring "unitär". Ist zusätzlich die Division immer möglich, erhält man einen Schiefkörper. Ist zusätzlich die Multiplikation kommutativ, erhält man einen Körper.

Mit dieser Multiplikation nicht zu verwechseln sind andere Verknüpfungen, die gemeinhin auch als Produkte bezeichnet werden, z. B. das Skalarprodukt in euklidischen Vektorräumen, die Skalarmultiplikation in Vektorräumen, die Matrizenmultiplikation und das Kreuzprodukt im dreidimensionalen Raum formula_60. Von Multiplikation spricht man auch bei Größenwerten von physikalischen Größen.




</doc>
<doc id="13045" url="https://de.wikipedia.org/wiki?curid=13045" title="Tritonus">
Tritonus

Der Tritonus, gelegentlich auch Halboktave genannt, ist ein musikalisches Intervall, das drei Ganztöne umspannt.<br>Beispiel: Tritonus "f’–h’:"      

Das Wort "Tritonus" setzt sich aus den altgriechischen Wörtern "tri-" („drei“) und "tónos" („Spannung“, sc. der Saite, daraus metonymisch „Ton“) zusammen. Im Lateinischen wird daraus "tritonus," woraus sich der Plural "Tritoni" ergibt.

Obwohl der Tritonus in diatonischen Tonleitern enthalten ist, wird er als übermäßige Quarte, also als chromatische Variante der reinen Quarte aufgefasst und somit nicht zu den diatonischen Intervallen gerechnet. Streng genommen gilt die Bezeichnung "Tritonus" nur für die übermäßige Quarte (zum Beispiel "F–H"), da nur sie durch drei diatonische Ganztonschritte ("F-G," "G-A" und "A-H") darstellbar ist. Es ist jedoch üblich, auch die verminderte Quinte – das Komplementärintervall zur übermäßigen Quarte, zum Beispiel "H-C-D-E-F" (Halbton+Ganzton+Ganzton+Halbton) – als Tritonus zu bezeichnen, da sie in der Summe ebenfalls drei Ganztöne umfasst.
Der Tritonus wurde früher wegen der mit ihm verbundenen gesangstechnischen und harmonischen Probleme auch der "Teufel in der Musik" () oder Teufelsintervall genannt.

In der europäischen Musik galt der Tritonus seit jeher als sehr instabiles Intervall, das anfangs völlig gemieden und später zumindest als unbedingt auflösungsbedürftig empfunden wurde. Diese Auflösungsbedürftigkeit sorgt dafür, dass der Tritonus einen stark dominantischen Charakter hat und seine Bestandteile als Leittöne fungieren. Die Art der Auflösung hängt davon ab, ob man den Tritonus als übermäßige Quarte oder verminderte Quinte deutet. Letztere löst sich standardmäßig „nach innen“, erstere „nach außen“ auf.

Dabei ist die Richtung der Leittonwirkung wie beim verminderten Septakkord oft mehrdeutig bzw. leicht umkehrbar, was zur Bewerkstelligung raffinierter Modulationen ausgenutzt wurde.

Das folgende Beispiel deutet die übermäßige Quarte f'-h' von C-Dur in die verminderte Quinte eis'-h' von Fis-Dur um. Dabei wird f' enharmonisch mit eis' (in der gleichstufigen Stimmung: gleiche Frequenz) verwechselt.


In der folgenden Tabelle werden neben dem gleichstufigen Tritonus einige in der Obertonreihe natürlich vorkommende Tritonusintervalle aufgelistet:
Der Tritonus kann in jeglicher Musik eingesetzt werden, die viel mit tonalen Spannungen arbeitet, da dieses Intervall stärker als viele andere nach Auflösung verlangt. Tritonushaltige Akkorde eignen sich auch besonders gut für chromatische oder enharmonische Modulationen. Oft ist der Tritonus aber auch in einer über diese alltägliche satztechnische Funktion hinausgehenden Bedeutung verwendet worden. Sein Ruf als „Teufelsintervall“ ("diabolus in musica") wurde häufig genutzt, um tonsymbolisch Düsteres, Schmerzliches, Unheimliches oder Dämonisches darzustellen. 
Bei den meisten der folgenden charakteristischen Beispiele aus der Musikgeschichte ist dies der Fall:



</doc>
<doc id="13046" url="https://de.wikipedia.org/wiki?curid=13046" title="Joseph-Marie Jacquard">
Joseph-Marie Jacquard

Joseph-Marie Jacquard (eigentlich Joseph-Marie Charles "genannt" Jacquard; * 7. Juli 1752 in Lyon; † 7. August 1834 in Oullins) war ein französischer Erfinder, der durch seine Weiterentwicklung des (programmierbaren) Webstuhls entscheidend zur industriellen Revolution beitrug.

Joseph-Marie Jacquard wurde am 7. Juli 1752 als Sohn eines Webers in Lyon geboren. Er war das fünfte von neun Kindern, die sein Vater Jean Charles (genannt Jaquard) und seine Mutter Antoinette Rive zur Welt brachten. Nur Joseph-Marie und seine Schwester Clémence (geboren 1747) erreichten das Erwachsenen-Alter. Sein Vater besaß eine Werkstatt mit mehreren Webstühlen und seine Mutter arbeitete als Mustereinleserin in einer Seidenmanufaktur. Bereits als Kind musste Jacquard in der Werkstatt seines Vaters arbeiten. Wie viele Webersöhne konnte er daher keine Schule besuchen, doch lernte er im Alter von 13 Jahren von seinem Schwager, einem kultivierten Mann, Lesen und Schreiben.

Der junge Jacquard erlernte das Gewerbe eines Buchbinders. Trotzdem erbte er nach dem Tod seiner Eltern (Mutter 1762, Vater 1772) deren Werkstatt und begann in dieser, die Musterwebtechnik zu mechanisieren.
Seine ersten Versuche blieben jedoch erfolglos und Jacquard verarmte zusehends. 1778 heiratete er die reiche Witwe Claudine Boichon, mit der er einen Sohn hatte, welchen sie, nach seinem Vater, Jean-Marie nannten.

1789 brach die Französische Revolution aus. 1793 nahmen Jaquard und sein Sohn Jean-Marie an der erfolglosen Verteidigung von Lyon teil – Lyon und Jacquards Werkstatt wurden zerstört. Anschließend flohen Vater und Sohn gemeinsam, nahmen falsche Namen an und traten der "" bei. 1797 wurde Jean-Marie im Kampf getötet und Joseph-Marie kehrte 1798 zurück nach Lyon. Durch die Revolution lag die Wirtschaft darnieder und Jacquard fand einige Textilfabrikanten, die seine Versuche bezüglich der Weiterentwicklung der Webstühle finanziell unterstützten. Einige wichtige Verbesserungen am Produktionsprozess und den Webstühlen verhalfen ihm zu einigem Ansehen und einer Berufung an das „Conservatoire des arts et métiers“ durch Napoléon Bonaparte im Jahr 1804.
Dort entdeckte Jacquard die zerlegten Reste von Vaucansons Webmaschine und rekonstruierte diese.
Schließlich kombinierte er dessen Steuerungstechnik mit Techniken der österreichischen Musterwebstühle.

Die wichtigste Verbesserung von Jacquards Musterwebstuhl gegenüber all seinen Vorläufern bestand darin, dass er die Nockenwalze der österreichischen Webstühle durch das Endlosprinzip der Lochkartensteuerung ersetzte. Dadurch konnten endlose Muster von beliebiger Komplexität mechanisch hergestellt werden.

Auf der Lochkarte waren allerlei Informationen über das zu webende Muster enthalten. Die Karten wurden mit Nadeln abgetastet; ein Loch bedeutete Fadenhebung, kein Loch Fadensenkung. Diese beiden Informationen reichten aus, um großflächige Musterungen herzustellen. Genauer gesagt handelt es sich nicht um Karten, sondern um lange Lochstreifen und somit um eine frühe Anwendung der Digitaltechnik.

Dieser Webstuhl war somit die erste „programmierbare“ Maschine, deren Steuerung (nach einer Umrüstung der Maschine für ein anderes Muster) dauerhaft aufgehoben und später erneut verwendet werden konnte. Sie ist damit ein Grundstein zur heutigen Automatisierung. Der Jacquard-Webstuhl beseitigte das letzte Hindernis zur vollständigen Automatisierung der Weberei: die kostengünstige Umstellung von Mustern bei der Herstellung wechselnder Webmuster auf derselben Maschine.

Napoléon war von Jacquards Steuerungssystem begeistert und sprach ihm zur Belohnung eine lebenslange Rente zu. 1806 versuchte Napoléon, die neuen Webstühle per Regierungsdekret durchzusetzen, stieß jedoch auf erbitterten Widerstand der Zünfte, die sich durch die fortschreitende Automatisierung in der Textilindustrie bedroht fühlten. Jacquard wurde mehrmals angegriffen und vor Gericht gebracht. Nachdem jedoch die englischen Textilfabriken anfingen, Jacquard-Webstühle einzusetzen, konnte sich die Technik in Frankreich ebenfalls durchsetzen.

Im Jahr 1810 wurde Jacquard mit dem Kreuz der Ehrenlegion geehrt. 1812 gab es in Frankreich etwa 18.000 Jacquard-Webstühle.

Joseph-Marie Jaquard starb am 7. August 1834 in Oullins (Rhône).

Noch heute werden in der Cammann-Jaquardweberei in Braunsdorf bei Chemnitz diese Stoffe (auf 60  Jahre alten Chemnitzer Webstühlen) hergestellt.

Im Weberei-Museum in Bramsche bei Osnabrück und im Haus der Seidenkultur in Krefeld werden Jacquard-Webstühle in Funktion gezeigt. Eine funktionstüchtige Jacquard-Maschine (Steuereinheit) ist außerdem im Heinz Nixdorf MuseumsForum in Paderborn, im TIM (Textilindustrie-Museum) in Augsburg, im Museum für Frühindustrialisierung in Wuppertal und im Textilmuseum Zell im Wiesental ausgestellt.


Joseph-Marie Jaquard – Sein Leben und die Entwicklung der programmierbaren Webstühle


</doc>
<doc id="13047" url="https://de.wikipedia.org/wiki?curid=13047" title="Grundton">
Grundton

Als Grundton bezeichnet man den fundamentalen Ton einer Tonleiter, eines Intervalls, eines Akkords, eines akustischen Klangs oder der Stimmung eines Musikinstruments. Auf tonale musikalische Abschnitte oder Musikstücke bezogen ist "Grundton" sinnverwandt mit den Bezeichnungen Tonika oder tonales Zentrum.

Der Grundton einer Tonleiter ist ihr wichtigster Ton und daher namensgebend für die Tonart, wie zum Beispiel C-Dur oder a-Moll. Meist ist er zugleich auch der erste Ton der Tonleiter. Eine Ausnahme bilden hier jedoch die plagalen Kirchentonarten (z. B. Hypodorisch), bei denen sich der Grundton nicht am Beginn, sondern in der Mitte der Skala befindet.

Beim Gregorianischen Choral war der Grundton mit dem Schlusston einer Melodie identisch und wurde deshalb auch als „Finalis“ bezeichnet.

In älterer Literatur wird bei einem Intervall unter dessen Grundton einfach der tiefere der beiden beteiligten Töne verstanden. Intervallgrundtöne im eigentlichen Sinne, nämlich eines dominierenden Haupttons wurden erst von Paul Hindemith in seiner 1937 erschienenen Unterweisung im Tonsatz in die Musiktheorie eingeführt. Hindemith stützt sich dabei auf das Phänomen der Kombinationstöne, die in bestimmten Fällen dafür sorgen, dass einer der beiden Intervalltöne klanglich verstärkt wird und somit den anderen an Gewicht übertrifft. So wird etwa bei einer Quinte der untere, bei einer Quarte der obere Ton verstärkt. Entsprechend erweist sich bei der großen Terz der untere, bei der kleinen Sexte der obere Ton als Grundton. Bei den übrigen Intervallen ergeben die Kombinationstöne allerdings kein klares Ergebnis, da sie nicht mehr mit einem der beiden Intervalltöne zusammenfallen. Hier nimmt Hindemith die Zuweisung der Intervallgrundtöne nach eher pragmatischen Kriterien vor.

Im Generalbass und teils auch in der Harmonielehre gilt als Grundton eines Akkords der tiefste Ton seiner Grundstellung, in welcher er aus aufeinandergeschichteten Terzen besteht. Während bei der Grundstellung Grund- und Basston identisch sind, ändert sich letzterer bei Umkehrung des Akkords, wogegen der Grundton gleich bleibt.

Die Gleichsetzung des Grundtons mit dem Basston der Grundstellung gilt uneingeschränkt nur in der Stufentheorie. In der später entwickelten Funktionstheorie versteht man unter dem Grundton eines Akkords denjenigen, der seiner harmonischen Funktion entspricht, wodurch sich Abweichungen zur Stufentheorie ergeben können. So schreibt man z. B. dem Akkord h-d'-f' in C-Dur wegen seines Auflösungsbestreben in die Tonika eine dominantische Funktion zu. Man betrachtet ihn als verkürzten Dominantseptakkord und weist ihm den Grundton g zu, obwohl dieser gar nicht erklingt. Während stufentheoretisch der Akkord zur VII. Stufe gehört, ordnet ihn die Funktionstheorie der V. Stufe (Dominante) zu.

Ein weiteres Beispiel für die unterschiedliche Interpretation eines Akkords ist der Sixte-ajoutée-Akkord f-a-c'-d'. Die Stufentheorie deutet ihn als erste Umkehrung des Septakkords der II. Stufe mit Grundton d, die Funktionstheorie als subdominantischen Klang mit Grundton f.

Da die traditionelle Harmonielehre Probleme mit der Deutung von Akkorden hat, die sich nicht auf das Terzenbauprinzip zurückführen lassen, empfindet Hindemith sie als ein zu enges System der Klangbestimmung und entwickelt eine neue Akkordlehre, die auf alle denkbaren Klänge gleichermaßen anwendbar ist. Hiernach wird der Grundton eines Akkords mit dem Grundton des „besten“ in ihm enthaltenen Intervalls identifiziert. Das „beste“ Intervall ist dasjenige mit dem höchsten Konsonanzgrad, also das in der Reihe der nach abnehmendem Klangwert angeordneten Intervalle (Quinte, Quarte, große Terz, kleine Sext…) am weitesten vorne stehende. Wenn also im Akkord eine Quinte enthalten ist, was häufig der Fall ist, so ist deren unterster Ton Grundton; kommen zwei Quinten im Akkord vor, so bestimmt wegen ihres größeren Gewichts die tiefer liegende Quinte den Grundton.

In einfachen Fällen liefern Stufentheorie, Funktionstheorie und Hindemiths Verfahren das gleiche Ergebnis. Alle drei sehen z. B. beim C-Dur-Dreiklang das c als Grundton. In anderen Fällen können jedoch Unterschiede in der Deutung auftreten. So wird etwa in C-Dur der halbverminderte Septakkord h-d'-f'-a' von der Stufentheorie als Septakkord der VII. Stufe (Grundton h) gedeutet, von der Funktionstheorie als verkürzter Dominantseptnonakkord (Grundton g), und nach Hindemith bestimmt sich der Grundton aus der Quinte d'-a' zu d'.

Ein einzelner Ton ist im akustischen Sinne in der Regel kein Sinuston, sondern ein aus solchen zusammengesetzter komplexer Klang. Dessen Grundfrequenz wird auch "Grundton" genannt und entspricht in den meisten Fällen der wahrgenommenen eigentlichen Tonhöhe. Seltener gibt es das akustische Phänomen, dass die Grundfrequenz bei einem Klang ganz fehlt und dieser trotzdem in Höhe der fehlenden Grundfrequenz wahrgenommen wird ('Missing Fundamental', Residualton).

Die Obertonreihe eines Grundtones bestimmt generell nicht nur die Klangfarbe, sondern hat aufgrund ihrer Zusammensetzung (etwa bezüglich der Unterschiede in der Stärke der einzelnen Obertöne) auch direkten Einfluss auf die Klangfarbe des wahrgenommen Tones.

Sind die Obertöne eher gering ausgeprägt, spricht man von einem „grundtönigen“ Klang. Die Zweierpotenzen der Grundfrequenz (diese entsprechen den Partialtönen 2, 4, 8 und 16) eines Tones ergeben stets deren Oktavierungen.

Bei transponierenden Instrumenten bezeichnet man als Grundton jenen Ton, der erklingt, wenn der Musiker ein „klingendes C“ spielt bzw. greift.
Bei vielen Blasinstrumenten entspricht er dem tiefsten Ton bei kompletter, unmodifizierter Luftsäule, wobei alle Grifflöcher geschlossen bzw. keine Ventile oder Zusatzklappen betätigt sind. Der tatsächlich erreichbare tiefste Ton hängt noch zusätzlich von der Bauart des Blasinstrumentes und vom Können des Musikers ab. Der Grundton von Blasinstrumenten ist daher nicht zwingend mit der Bezeichnung oder Stimmung der Instrumente in Übereinstimmung.

Bei Saiteninstrumenten mit Griffbrett (z. B. Violine, Gitarre) wird der Ton einer „leeren“ (ungegriffenen) Saite auch als deren "Grundton" bezeichnet.



</doc>
<doc id="13049" url="https://de.wikipedia.org/wiki?curid=13049" title="Hard Bop">
Hard Bop

Der Hard Bop (auch Hardbop) ist ein besonders ausgeprägter Jazzstil, der in den 1950er Jahren der Geschichte des Jazz entwickelt wurde.

Diese Weiterführung des Bebop seit Mitte 1950 wurde als afro-amerikanische Gegenbewegung zum West Coast Jazz (Cool Jazz) verstanden. Die Hardbopper vereinfachten die technisch herausfordernden Melodienfolgen des Bebop, aber ohne die Intensität aufzugeben. Sie benutzten dafür beispielsweise die Quartenharmonik. Außerdem wurden neben dem rhythmischen Drive des Bebop Elemente aus dem Soul und Blues aufgenommen, was eine insgesamt „härtere“ als die bisherige Spielweise mit sich brachte. Die traditionellen Elemente der genannten Richtungen wurden technisch an ihre Grenzen entwickelt. Eine Unterart des Hard Bop ist der Soul Jazz, der noch geradliniger aufgebaut ist.

Art Blakey und seine Jazz Messengers waren für Jahrzehnte die wohl bekanntesten Vertreter dieses Stils. Viele Hardbopper gingen aus dieser Band hervor, etwa der Pianist Horace Silver (Mitbegründer der Vorläuferband der Jazz Messengers), der Trompeter Clifford Brown und der Saxophonist Lou Donaldson. Brown war auch der Co-Leiter des Max-Roach-Quintetts, das ebenfalls entscheidend an der Ausbildung dieses Stils beteiligt war. Weiterhin sind hier Musiker wie die Saxophonisten Dexter Gordon, Sonny Rollins, Cannonball Adderley und die Posaunisten Curtis Fuller und J. J. Johnson zu nennen, die jedoch noch anderen Jazzstilen zuzuordnen sind. Dasselbe gilt für Miles Davis und John Coltrane, die ab 1956 einige Stücke im Stil des Hardbop in ihr Repertoire aufnahmen.







</doc>
<doc id="13050" url="https://de.wikipedia.org/wiki?curid=13050" title="Bebop">
Bebop

Der Bebop ist eine Musikrichtung, die Anfang der 1940er Jahre im Jazz den Swing als Hauptstilrichtung ablöste und somit den Ursprung des Modern Jazz bildete.

Wesentliche Elemente sind größere rhythmische Freiheiten für Schlagzeug und Bass, schnelles Tempo und komplexe Harmonie-Schemata. Komponisten des Bebop griffen oft auf bestehende musikalische Themen und Harmonieabfolgen zurück. Wesentlich für den Bebop sind zudem die Improvisationen auf langen formalen Strecken.

Miles Davis beschrieb Bebop so: "„... es fehlten die Harmonien, die man auf der Straße vor sich hin summte, um sein Mädchen aufs Küssen einzustimmen. Der Bebop hatte nicht die Menschlichkeit eines Duke Ellington. Man konnte sich nicht einmal die Melodien merken.“" 

Mit dem Bebop verabschiedet sich der Jazz als Unterhaltungsmusik und wird nach und nach als Kunstmusik definiert. Dies beruht auf der Ablehnung des Bebop durch große Teile von Kritikern und Publikum sowie auf einem neuen Verständnis der Schallplatte als Medium. Die flüchtigen Improvisationen der Musiker sind durch die Schallplatte gespeichert und bringen ein Sammler- und Expertentum hervor – gerade auch in der weißen amerikanischen Mittelschicht und unter den europäischen Intellektuellen. Mit der verbesserten Aufnahmetechnik tritt der Solist stärker denn je als Individuum und Künstlerpersönlichkeit hervor. Niemals wieder jedoch fügte sich der Jazz in das Bild ein, das man sich zuvor von ihm gemacht hatte, in das Bild einer für alle zugänglichen Populärkultur.

Vermutlich hat eine Verkettung verschiedener Faktoren zur Entstehung dieses neuen Stils geführt. Am Ende der 1930er Jahre war Swing zu einem großen Geschäft geworden. Der kreative Zenit vieler Swingorchester war überschritten, und die Musik drohte in Formelhaftigkeit zu erstarren. Gelangweilt von der Routine als „Orchesterangestellte“ begannen zahlreiche Musiker – oft „afterhours“, nachdem sie ihren Job in der Big Band erledigt hatten – sich zu informellen Jam-Sessions zu treffen. Hier wurde gespielt und nach musikalischen Formen jenseits der Big Bands gesucht. Ein Kristallisationspunkt dieser Entwicklung war Minton’s Playhouse in Harlem und nicht die 52nd Street in Manhattan, wie oftmals fälschlicherweise behauptet wird. Zu den wichtigsten Musikern dieses Zirkels gehörten Dizzy Gillespie, Charlie Parker (die beide 1943 bei Earl Hines and His Orchestra spielten), Charlie Christian, Thelonious Monk und Kenny Clarke. Außerdem wird vermutet, dass die auf den Kriegseintritt der USA 1941 zurückzuführende Steuererhöhung auf Tanzveranstaltungen die Wirtschaftlichkeit der Big Bands allmählich untergrub, damit den Niedergang des Swing beschleunigte und die Entwicklung des neuen Stils in Form einer autonomen Kunstmusik begünstigte.

Die kleinen Bands, die den neuen Jazzstil entwickelten, galten nicht als Tanz- oder Unterhaltungskapellen und waren dies in ihrem Selbstverständnis auch nicht, weswegen die Besitzer der Nachtclubs nicht mit den kriegsbedingten Sonderabgaben belegt wurden, wenn sie junge Bebop-Musiker mit ihren Combos engagierten. Wegen des Recording ban existieren keine Studioaufnahmen aus der Entstehungsphase dieses Stils; es existieren einzig einige private, technisch sehr unzulängliche Live-Mitschnitte aus „Minton's Playhouse“ und „Monroe's Uptown House“. Als eine der frühesten Aufnahmen des Bebop gilt „Bu-Dee-Dah“ (Apollo, 16. Februar 1944), unter Leitung von Coleman Hawkins u. a. mit Dizzy Gillespie, Leo Parker, Budd Johnson, Ray Abrams, Don Byas, Clyde Hart, Oscar Pettiford und Max Roach.

Man sagt auch, dass der Bebop als Reaktion der afroamerikanischen Bevölkerung auf den von Weißen dominierten Swing entstanden sei.

Die Herkunft des Worts „Bebop“ ist, wie so oft im Jazz, nicht ganz geklärt und es gibt viele Legenden über die Entstehung dieses Begriffs. Er geht wahrscheinlich auf die lautmalerischen Scat-Silben „be“, „re“, „de“ und „bop“ zurück, mit deren Hilfe sich Musiker untereinander komplizierte Linien in schnellen Tempi vorzusingen pflegten. Das ist wohl die wahrscheinlichste aller angebotenen Erklärungen, die es gibt; wobei dieser Name, wie so oft in der Musik, nicht von den Musikern selbst, sondern von der Presse stammt.

Ist der Zusammenhang unmissverständlich, wird auch von Bop gesprochen. Hingegen ist die Bezeichnung "Rebop" aus einem Unverständnis der damaligen Swingmusiker gegenüber dem Bebop heraus entstanden und bezeichnet den Bebop eben gerade nicht. Ebenso ist in vielen Fällen das Scatten kein Bebop, sondern lediglich Silbengesang, das die eigentümlichen Wendungen des Bebop vermissen lässt.


Quintett: Trompete, Saxophon (meist Alt oder Tenor), Klavier, Kontrabass, Schlagzeug. Bigbands waren eher selten (eine Ausnahme bildet das Orchester von Dizzy Gillespie; auch Gene Krupa and His Orchestra unternahm 1947/48 Versuche, Bigband-Bop zu spielen, wie der von Gerry Mulligan arrangierte „Disc Jockey Jump“).





</doc>
