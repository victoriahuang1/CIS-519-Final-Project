<doc id="1164" url="https://en.wikipedia.org/wiki?curid=1164" title="Artificial intelligence">
Artificial intelligence

Artificial intelligence (AI, also machine intelligence, MI) is intelligence demonstrated by machines, in contrast to the natural intelligence (NI) displayed by humans and other animals. In computer science AI research is defined as the study of "intelligent agents": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term "artificial intelligence" is applied when a machine mimics "cognitive" functions that humans associate with other human minds, such as "learning" and "problem solving".

The scope of AI is disputed: as machines become increasingly capable, tasks considered as requiring "intelligence" are often removed from the definition, a phenomenon known as the AI effect, leading to the quip, "AI is whatever hasn't been done yet." For instance, optical character recognition is frequently excluded from "artificial intelligence", having become a routine technology. Capabilities generally classified as AI include successfully understanding human speech, competing at the highest level in strategic game systems (such as chess and Go), autonomous cars, intelligent routing in content delivery network and military simulations.
Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an "AI winter"), followed by new approaches, success and renewed funding. For most of its history, AI research has been divided into subfields that often fail to communicate with each other. These sub-fields are based on technical considerations, such as particular goals (e.g. "robotics" or "machine learning"), the use of particular tools ("logic" or "neural networks"), or deep philosophical differences. Subfields have also been based on social factors (particular institutions or the work of particular researchers).
The traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects. General intelligence is among the field's long-term goals. Approaches include statistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in AI, including versions of search and mathematical optimization, neural networks and methods based on statistics, probability and economics. The AI field draws upon computer science, mathematics, psychology, linguistics, philosophy and many others.
The field was founded on the claim that human intelligence "can be so precisely described that a machine can be made to simulate it". This raises philosophical arguments about the nature of the mind and the ethics of creating artificial beings endowed with human-like intelligence, issues which have been explored by myth, fiction and philosophy since antiquity. Some people also consider AI to be a danger to humanity if it progresses unabatedly. Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.
In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understanding; and AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science.

Thought-capable artificial beings appeared as storytelling devices in antiquity, and have been common in fiction, as in Mary Shelley's "Frankenstein" or Karel Čapek's "R.U.R. (Rossum's Universal Robots)". These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.
The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable act of mathematical deduction. This insight, that digital computers can simulate any process of formal reasoning, is known as the Church–Turing thesis. Along with concurrent discoveries in neurobiology, information theory and cybernetics, this led researchers to consider the possibility of building an electronic brain. Turing proposed that "if a human could not distinguish between responses from a machine and a human, the machine could be considered “intelligent". The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete "artificial neurons".
The field of AI research was born at a workshop at Dartmouth College in 1956. Attendees Allen Newell (CMU), Herbert Simon (CMU), John McCarthy (MIT), Marvin Minsky (MIT) and Arthur Samuel (IBM) became the founders and leaders of AI research. They and their students produced programs that the press described as "astonishing": computers were learning checkers strategies (c. 1954) (and by 1959 were reportedly playing better than the average human), solving word problems in algebra, proving logical theorems (Logic Theorist, first run c. 1956) and speaking English. By the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense and laboratories had been established around the world. AI's founders were optimistic about the future: Herbert Simon predicted, "machines will be capable, within twenty years, of doing any work a man can do". Marvin Minsky agreed, writing, "within a generation ... the problem of creating 'artificial intelligence' will substantially be solved".
They failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an "AI winter", a period when obtaining funding for AI projects was difficult.
In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985 the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting hiatus began.
In the late 1990s and early 21st century, AI began to be used for logistics, data mining, medical diagnosis and other areas. The success was due to increasing computational power (see Moore's law), greater emphasis on solving specific problems, new ties between AI and other fields (such as statistics, economics and mathematics), and a commitment by researchers to mathematical methods and scientific standards. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov on 11 May 1997.
In 2011, a "Jeopardy!" quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy champions, Brad Rutter and Ken Jennings, by a significant margin. Faster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012. The Kinect, which provides a 3D body–motion interface for the Xbox 360 and the Xbox One use algorithms that emerged from lengthy AI research as do intelligent personal assistants in smartphones. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. In the 2017 Future of Go Summit, AlphaGo won a three-game match with Ke Jie, who at the time continuously held the world No. 1 ranking for two years. This marked the completion of a significant milestone in the development of Artificial Intelligence as Go is an extremely complex game, more so than Chess.

According to Bloomberg's Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI within Google increased from a "sporadic usage" in 2012 to more than 2,700 projects. Clark also presents factual data indicating that error rates in image processing tasks have fallen significantly since 2011. He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets. Other cited examples include Microsoft's development of a Skype system that can automatically translate from one language to another and Facebook's system that can describe images to blind people.

A typical AI perceives its environment and takes actions that maximize its chance of successfully achieving its goals. An AI's intended goal function can be simple ("1 if the AI wins a game of Go, 0 otherwise") or complex ("Do actions mathematically similar to the actions that got you rewards in the past"). Goals can be explicitly defined, or can be induced. If the AI is programmed for "reinforcement learning", goals can be implicitly induced by rewarding some types of behavior and punishing others. Alternatively, an evolutionary system can induce goals by using a "fitness function" to mutate and preferentially replicate high-scoring AI systems; this is similar to how animals evolved to innately desire certain goals such as finding food, or how dogs can be bred via artificial selection to possess desired traits. Some AI systems, such as nearest-neighbor, instead reason by analogy; these systems are not generally given goals, except to the degree that goals are somehow implicit in their training data. Such systems can still be benchmarked if the non-goal system is framed as a system whose "goal" is to successfully accomplish its narrow classification task.

AI often revolves around the use of algorithms. An algorithm is a set of unambiguous instructions that a mechanical computer can execute. A complex algorithm is often built on top of other, simpler, algorithms. A simple example of an algorithm is the following recipe for optimal play at tic-tac-toe:


Many AI algorithms are capable of learning from data; they can enhance themselves by learning new heuristics (strategies, or "rules of thumb", that have worked well in the past), or can themselves write other algorithms. Some of the "learners" described below, including Bayesian networks, decision trees, and nearest-neighbor, could theoretically, if given infinite data, time, and memory, learn to approximate any function, including whatever combination of mathematical functions would best describe the entire world. These learners could therefore, in theory, derive all possible knowledge, by considering every possible hypothesis and matching it against the data. In practice, it is almost never possible to consider every possibility, because of the phenomenon of "combinatorial explosion", where the amount of time needed to solve a problem grows exponentially. Much of AI research involves figuring out how to identify and avoid considering broad swaths of possibililities that are unlikely to be fruitful. For example, when viewing a map and looking for the shortest driving route from Denver to New York in the East, one can in most cases skip looking at any path through San Francisco or other areas far to the West; thus, an AI wielding an pathfinding algorithm like A* can avoid the combinatorial explosion that would ensue if every possible route had to be ponderously considered in turn.

The earliest (and easiest to understand) approach to AI was symbolism (such as formal logic): "If an otherwise healthy adult has a fever, then they may have influenza". A second, more general, approach is Bayesian inference: "If the current patient has a fever, adjust the probability they have influenza in such-and-such way". The third major approach, extremely popular in routine business AI applications, is analogizers such as SVM and nearest-neighbor: "After examining the records of known past patients whose temperature, symptoms, age, and other factors mostly match the current patient, X% of those patients turned out to have influenza". A fourth approach is harder to intuitively understand, but is inspired by how the brain's machinery works: the neural network approach uses artificial "neurons" that can learn by comparing itself to the desired output and altering the strengths of the connections between its internal neurons to "reinforce" connections that seemed to be useful. These four main approaches can overlap with each other and with evolutionary systems; for example, neural nets can learn to make inferences, to generalize, and to make analogies. Some systems implicitly or explicitly use multiple of these approaches, alongside many other AI and non-AI algorithms; the best approach is often different depending on the problem.
Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as "since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well". They can be nuanced, such as "X% of families have geographically separate species with color variants, so there is an Y% chance that undiscovered black swans exist". Learners also work on the basis of "Occam's razor": The simplest theory that explains the data is the likeliest. Therefore, to be successful, a learner must be designed such that it prefers simpler theories to complex theories, except in cases where the complex theory is proven substantially better. Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data, but penalizing the theory in accordance with how complex the theory is. Besides classic overfitting, learners can also disappoint by "learning the wrong lesson". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses. A real-world example is that, unlike humans, current image classifiers don't determine the spatial relationship between components of the picture; instead, they learn abstract patterns of pixels that humans are oblivious to, but that linearly correlate with images of certain types of real objects. Faintly superimposing such a pattern on a legitimate image results in an "adversarial" image that the system misclassifies.
Compared with humans, existing AI lacks several features of human "commonsense reasoning"; most notably, humans have powerful mechanisms for reasoning about "naïve physics" such as space, time, and physical interactions. This enables even young children to easily make inferences like "If I roll this pen off a table, it will fall on the floor". Humans also have a powerful mechanism of "folk psychology" that helps them to interpret natural-language sentences such as "The city councilmen refused the demonstrators a permit because they advocated violence". (A generic AI has difficulty inferring whether the councilmen or the demonstrators are the ones alleged to be advocating violence.) This lack of "common knowledge" means that AI often makes different mistakes than humans make, in ways that can seem incomprehensible. For example, existing self-driving cars cannot reason about the location nor the intentions of pedestrians in the exact way that humans do, and instead must use non-human modes of reasoning to avoid accidents.

The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.

Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.

These algorithms proved to be insufficient for solving large reasoning problems, because they experienced a "combinatorial explosion": they became exponentially slower as the problems grew larger. In fact, even humans rarely use the step-by-step deduction that early AI research was able to model. They solve most of their problems using fast, intuitive judgements.

Knowledge representation and knowledge engineering are central to classical AI research. Some "expert systems" attempt to gather together explicit knowledge possessed by experts in some narrow domain. In addition, some projects attempt to gather the "commonsense knowledge" known to the average person into a database containing extensive knowledge about the world. Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects; situations, events, states and time; causes and effects; knowledge about knowledge (what we know about what other people know); and many other, less well researched domains. A representation of "what exists" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them. The semantics of these are captured as description logic concepts, roles, and individuals, and typically implemented as classes, properties, and individuals in the Web Ontology Language. The most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge by acting as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). Such formal knowledge representations can be used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining "interesting" and actionable inferences from large databases), and other areas.

Among the most difficult problems in knowledge representation are:

Intelligent agents must be able to set goals and achieve them. They need a way to visualize the future—a representation of the state of the world and be able to make predictions about how their actions will change it—and be able to make choices that maximize the utility (or "value") of available choices.

In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions. However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that can not only assess its environment and make predictions, but also evaluate its predictions and adapt based on its assessment.

Multi-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.

Machine learning, a fundamental concept of AI research since the field's inception, is the study of computer algorithms that improve automatically through experience.

Unsupervised learning is the ability to find patterns in a stream of input. Supervised learning includes both classification and numerical regression. Classification is used to determine what category something belongs in, after seeing a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space.

Natural language processing gives machines the ability to read and understand human language. A sufficiently powerful natural language processing system would enable natural language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include information retrieval, text mining, question answering and machine translation. Many current approaches use word co-occurrence frequencies to construct syntactic representations of text. "Keyword spotting" strategies for search are popular and scalable but dumb; a search query for "dog" might only match documents with the literal word "dog" and miss a document with the word "poodle". "Lexical affinity" strategies use the occurrence of words such as "accident" to assess the sentiment of a document. Modern statistical NLP approaches can combine all these strategies as well as others, and often achieve acceptable accuracy at the page or paragraph level, but continue to lack the semantic understanding required to classify isolated sentences well. Besides the usual difficulties with encoding semantic commonsense knowledge, existing semantic NLP sometimes scales too poorly to be viable in business applications. Beyond semantic NLP, the ultimate goal of "narrative" NLP is to embody a full understanding of commonsense reasoning.

Machine perception is the ability to use input from sensors (such as cameras, microphones, tactile sensors, sonar and others) to deduce aspects of the world. Computer vision is the ability to analyze visual input. A few selected subproblems are speech recognition, facial recognition and object recognition.

The field of robotics is closely related to AI. Intelligence is required for robots to handle tasks such as object manipulation and navigation, with sub-problems such as localization, mapping, and motion planning. These systems require that an agent is able to: Be spatially cognizant of its surroundings, learn from and build a map of its environment, figure out how to get from one point in space to another, and execute that movement (which often involves compliant motion, a process where movement requires maintaining physical contact with an object).

Within developmental robotics, developmental learning approaches are elaborated upon to allow robots to accumulate repertoires of novel skills through autonomous self-exploration, social interaction with human teachers, and the use of guidance mechanisms (active learning, maturation, motor synergies, etc.).

Affective computing is the study and development of systems that can recognize, interpret, process, and simulate human affects. It is an interdisciplinary field spanning computer sciences, psychology, and cognitive science. While the origins of the field may be traced as far back as the early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on "affective computing". A motivation for the research is the ability to simulate empathy, where the machine would be able to interpret human emotions and adapts its behavior to give an appropriate response to those emotions.

Emotion and social skills are important to an intelligent agent for two reasons. First, being able to predict the actions of others by understanding their motives and emotional states allow an agent to make better decisions. Concepts such as game theory, decision theory, necessitate that an agent be able to detect and model human emotions. Second, in an effort to facilitate human–computer interaction, an intelligent machine may want to display emotions (even if it does not experience those emotions itself) to appear more sensitive to the emotional dynamics of human interaction.

Many researchers think that their work will eventually be incorporated into a machine with artificial general intelligence, combining all the skills mentioned above and even exceeding human ability in most or all these areas. A few believe that anthropomorphic features like artificial consciousness or an artificial brain may be required for such a project.

Many of the problems above may also require general intelligence, if machines are to solve the problems as well as people do. For example, even specific straightforward tasks, like machine translation, require that a machine read and write in both languages (NLP), follow the author's argument (reason), know what is being talked about (knowledge), and faithfully reproduce the author's original intent (social intelligence). A problem like machine translation is considered "AI-complete", because all of these problems need to be solved simultaneously in order to reach human-level machine performance.

There is no established unifying theory or paradigm that guides AI research. Researchers disagree about many issues. A few of the most long standing questions that have remained unanswered are these: should artificial intelligence simulate natural intelligence by studying psychology or neurobiology? Or is human biology as irrelevant to AI research as bird biology is to aeronautical engineering?
Can intelligent behavior be described using simple, elegant principles (such as logic or optimization)? Or does it necessarily require solving a large number of completely unrelated problems?
Can intelligence be reproduced using high-level symbols, similar to words and ideas? Or does it require "sub-symbolic" processing?
John Haugeland, who coined the term GOFAI (Good Old-Fashioned Artificial Intelligence), also proposed that AI should more properly be referred to as synthetic intelligence, a term which has since been adopted by some non-GOFAI researchers.

Stuart Shapiro divides AI research into three approaches, which he calls computational psychology, computational philosophy, and computer science. Computational psychology is used to make computer programs that mimic human behavior. Computational philosophy, is used to develop an adaptive, free-flowing computer mind. Implementing computer science serves the goal of creating computers that can perform tasks that only people could previously accomplish. Together, the humanesque behavior, mind, and actions make up artificial intelligence.

In the 1940s and 1950s, a number of researchers explored the connection between neurobiology, information theory, and cybernetics. Some of them built machines that used electronic networks to exhibit rudimentary intelligence, such as W. Grey Walter's turtles and the Johns Hopkins Beast. Many of these researchers gathered for meetings of the Teleological Society at Princeton University and the Ratio Club in England. By 1960, this approach was largely abandoned, although elements of it would be revived in the 1980s.

When access to digital computers became possible in the middle 1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. The research was centered in three institutions: Carnegie Mellon University, Stanford and MIT, and each one developed its own style of research. John Haugeland named these approaches to AI "good old fashioned AI" or "GOFAI". During the 1960s, symbolic approaches had achieved great success at simulating high-level thinking in small demonstration programs. Approaches based on cybernetics or neural networks were abandoned or pushed into the background.
Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.

Economist Herbert Simon and Allen Newell studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as cognitive science, operations research and management science. Their research team used the results of psychological experiments to develop programs that simulated the techniques that people used to solve problems. This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s.

Unlike Newell and Simon, John McCarthy felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem solving, regardless of whether people used the same algorithms. His laboratory at Stanford (SAIL) focused on using formal logic to solve a wide variety of problems, including knowledge representation, planning and learning. Logic was also the focus of the work at the University of Edinburgh and elsewhere in Europe which led to the development of the programming language Prolog and the science of logic programming.

Researchers at MIT (such as Marvin Minsky and Seymour Papert) found that solving difficult problems in vision and natural language processing required ad-hoc solutions – they argued that there was no simple and general principle (like logic) that would capture all the aspects of intelligent behavior. Roger Schank described their "anti-logic" approaches as "scruffy" (as opposed to the "neat" paradigms at CMU and Stanford). Commonsense knowledge bases (such as Doug Lenat's Cyc) are an example of "scruffy" AI, since they must be built by hand, one complicated concept at a time.

When computers with large memories became available around 1970, researchers from all three traditions began to build knowledge into AI applications. This "knowledge revolution" led to the development and deployment of expert systems (introduced by Edward Feigenbaum), the first truly successful form of AI software. The knowledge revolution was also driven by the realization that enormous amounts of knowledge would be required by many simple AI applications.

By the 1980s progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into "sub-symbolic" approaches to specific AI problems. Sub-symbolic methods manage to approach intelligence without specific representations of knowledge.

This includes embodied, situated, behavior-based, and nouvelle AI. Researchers from the related field of robotics, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move and survive. Their work revived the non-symbolic viewpoint of the early cybernetics researchers of the 1950s and reintroduced the use of control theory in AI. This coincided with the development of the embodied mind thesis in the related field of cognitive science: the idea that aspects of the body (such as movement, perception and visualization) are required for higher intelligence.

Interest in neural networks and "connectionism" was revived by David Rumelhart and others in the middle of the 1980s. Neural networks are an example of soft computing --- they are solutions to problems which cannot be solved with complete logical certainty, and where an approximate solution is often sufficient. Other soft computing approaches to AI include fuzzy systems, evolutionary computation and many statistical tools. The application of soft computing to AI is studied collectively by the emerging discipline of computational intelligence.

In the 1990s, AI researchers developed sophisticated mathematical tools to solve specific subproblems. These tools are truly scientific, in the sense that their results are both measurable and verifiable, and they have been responsible for many of AI's recent successes. The shared mathematical language has also permitted a high level of collaboration with more established fields (like mathematics, economics or operations research). Stuart Russell and Peter Norvig describe this movement as nothing less than a "revolution" and "the victory of the neats". Critics argue that these techniques (with few exceptions) are too focused on particular problems and have failed to address the long-term goal of general intelligence. There is an ongoing debate about the relevance and validity of statistical approaches in AI, exemplified in part by exchanges between Peter Norvig and Noam Chomsky.


In the course of 60 or so years of research, AI has developed a large number of tools to solve the most difficult problems in computer science. A few of the most general of these methods are discussed below.

Many problems in AI can be solved in theory by intelligently searching through many possible solutions: Reasoning can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from premises to conclusions, where each step is the application of an inference rule. Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis. Robotics algorithms for moving limbs and grasping objects use local searches in configuration space. Many learning algorithms use search algorithms based on optimization.

Simple exhaustive searches are rarely sufficient for most real world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. The solution, for many problems, is to use "heuristics" or "rules of thumb" that prioritize choices in favor of those that are more likely to reach a goal, and to do so in a shorter number of steps. In some search methodologies heuristics can also serve to entirely eliminate some choices that are unlikely to lead to a goal (called "pruning the search tree"). Heuristics supply the program with a "best guess" for the path on which the solution lies. Heuristics limit the search for solutions into a smaller sample size.

A very different kind of search came to prominence in the 1990s, based on the mathematical theory of optimization. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are simulated annealing, beam search and random optimization.

Evolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses). Forms of evolutionary computation include swarm intelligence algorithms (such as ant colony or particle swarm optimization) and evolutionary algorithms (such as genetic algorithms, gene expression programming, and genetic programming).

Logic is used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the satplan algorithm uses logic for planning and inductive logic programming is a method for learning.

Several different forms of logic are used in AI research. Propositional or sentential logic is the logic of statements which can be true or false. First-order logic also allows the use of quantifiers and predicates, and can express facts about objects, their properties, and their relations with each other. Fuzzy logic, is a version of first-order logic which allows the truth of a statement to be represented as a value between 0 and 1, rather than simply True (1) or False (0). Fuzzy systems can be used for uncertain reasoning and have been widely used in modern industrial and consumer product control systems. Subjective logic models uncertainty in a different and more explicit manner than fuzzy-logic: a given binomial opinion satisfies belief + disbelief + uncertainty = 1 within a Beta distribution. By this method, ignorance can be distinguished from probabilistic statements that an agent makes with high confidence.

Default logics, non-monotonic logics and circumscription are forms of logic designed to help with default reasoning and the qualification problem. Several extensions of logic have been designed to handle specific domains of knowledge, such as: description logics; situation calculus, event calculus and fluent calculus (for representing events and time); causal calculus; belief calculus; and modal logics.

Many problems in AI (in reasoning, planning, learning, perception and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of powerful tools to solve these problems using methods from probability theory and economics.

Bayesian networks are a very general tool that can be used for a large number of problems: reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks) and perception (using dynamic Bayesian networks). Bayesian networks are used in AdSense to choose what ads to place and on XBox Live to rate and match players. Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).

A key concept from the science of economics is "utility": a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis, and information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.

The simplest AI applications can be divided into two types: classifiers ("if shiny then diamond") and controllers ("if shiny then pick up"). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems. Classifiers are functions that use pattern matching to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class can be seen as a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.

A classifier can be trained in various ways; there are many statistical and machine learning approaches. The decision tree is perhaps the most widely used machine learning algorithm. Other widely used classifiers are the neural network,
k-nearest neighbor algorithm,
kernel methods such as the support vector machine (SVM),
Gaussian mixture model
and the extremely popular naive Bayes classifier.
The performance of these classifiers have been compared over a wide range of tasks. Classifier performance depends greatly on the characteristics of the data to be classified. There is no single classifier that works best on all given problems; this is also referred to as the "no free lunch" theorem. Determining a suitable classifier for a given problem is still more an art than science.

Neural networks, or neural nets, were inspired by the architecture of neurons in the human brain. A simple "neuron" "N" accepts input from multiple other neurons, each of which, when activated (or "fired"), cast a weighted "vote" for or against whether neuron "N" should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed "fire together, wire together") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. The net forms "concepts" that are distributed among a subnetwork of shared neurons that tend to fire together; a concept meaning "leg" might be coupled with a subnetwork meaning "foot" that includes the sound for "foot". Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes. Modern neural nets can learn both continuous functions and, surprisingly, digital logical operations. Neural networks' early successes included predicting the stock market and (in 1995) a mostly self-driving car. In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related M&A in 2017 was over 25 times as large as in 2015.

The study of non-learning artificial neural networks began in the decade before the field of AI research was founded, in the work of Walter Pitts and Warren McCullouch. Frank Rosenblatt invented the perceptron, a learning network with a single layer, similar to the old concept of linear regression. Early pioneers also include Alexey Grigorevich Ivakhnenko, Teuvo Kohonen, Stephen Grossberg, Kunihiko Fukushima, Christoph von der Malsburg, David Willshaw, Shun-Ichi Amari, Bernard Widrow, John Hopfield, Eduardo R. Caianiello, and others.

The main categories of networks are acyclic or feedforward neural networks (where the signal passes in only one direction) and recurrent neural networks (which allow feedback and short-term memories of previous input events). Among the most popular feedforward networks are perceptrons, multi-layer perceptrons and radial basis networks. Neural networks can be applied to the problem of intelligent control (for robotics) or learning, using such techniques as Hebbian learning ("fire together, wire together"), GMDH or competitive learning.

Today, neural networks are often trained by the backpropagation algorithm, which had been around since 1970 as the reverse mode of automatic differentiation published by Seppo Linnainmaa, and was introduced to neural networks by Paul Werbos.

Hierarchical temporal memory is an approach that models some of the structural and algorithmic properties of the neocortex.

In short, most neural networks use some form of gradient descent on a hand-created neural topology. However, some research groups, such as Uber, argue that simple neuroevolution to mutate new neural network topologies and weights may be competitive with sophisticated gradient descent approaches. One advantage of neuroevolution is that it may be less prone to get caught in "dead ends".

Deep learning is any artificial neural network that can learn a long chain of causal links. For example, a feedforward network with six hidden layers can learn a seven-link causal chain (six hidden layers + output layer) and has a "credit assignment path" (CAP) depth of seven. Many deep learning systems need to be able to learn chains ten or more causal links in length. Deep learning has transformed many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing and others.

According to one overview, the expression "Deep Learning" was introduced to the Machine Learning community by Rina Dechter in 1986 and gained traction after
Igor Aizenberg and colleagues introduced it to Artificial Neural Networks in 2000. The first functional Deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965. These networks are trained one layer at a time. Ivakhnenko's 1971 paper describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of pre-training many-layered feedforward neural networks (FNNs) one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning. Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Over the last few years, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.

Deep learning often uses convolutional neural networks (CNNs), whose origins can be traced back to the Neocognitron introduced by Kunihiko Fukushima in 1980. In 1989, Yann LeCun and colleagues applied backpropagation to such an architecture. In the early 2000s, in an industrial application CNNs already processed an estimated 10% to 20% of all the checks written in the US.
Since 2011, fast implementations of CNNs on GPUs have
won many visual pattern recognition competitions.

CNNs with 12 convolutional layers were used in conjunction with reinforcement learning by Deepmind's "AlphaGo Lee", the program that beat a top Go champion in 2016.

Early on, deep learning was also applied to sequence learning with recurrent neural networks (RNNs) which are in theory Turing complete and can run arbitrary programs to process arbitrary sequences of inputs. The depth of an RNN is unlimited and depends on the length of its input sequence; thus, an RNN is an example of deep learning. RNNs can be trained by gradient descent but suffer from the vanishing gradient problem. In 1992, it was shown that unsupervised pre-training of a stack of recurrent neural networks can speed up subsequent supervised learning of deep sequential problems.

Numerous researchers now use variants of a deep learning recurrent NN called the long short-term memory (LSTM) network published by Hochreiter & Schmidhuber in 1997. LSTM is often trained by Connectionist Temporal Classification (CTC). At Google, Microsoft and Baidu this approach has revolutionised speech recognition. For example, in 2015, Google's speech recognition experienced a dramatic performance jump of 49% through CTC-trained LSTM, which is now available through Google Voice to billions of smartphone users. Google also used LSTM to improve machine translation, Language Modeling and Multilingual Language Processing. LSTM combined with CNNs also improved automatic image captioning and a plethora of other applications.

Early symbolic AI inspired Lisp and Prolog, which dominated early AI programming. Modern AI development often uses mainstream languages such as Python or C++, or niche languages such as Wolfram Language.

In 1950, Alan Turing proposed a general procedure to test the intelligence of an agent now known as the Turing test. This procedure allows almost all the major problems of artificial intelligence to be tested. However, it is a very difficult challenge and at present all agents fail.

Artificial intelligence can also be evaluated on specific problems such as small problems in chemistry, hand-writing recognition and game-playing. Such tests have been termed subject matter expert Turing tests. Smaller problems provide more achievable goals and there are an ever-increasing number of positive results.

For example, performance at draughts (i.e. checkers) is optimal, performance at chess is high-human and nearing super-human (see computer chess: computers versus human) and performance at many everyday tasks (such as recognizing a face or crossing a room without bumping into something) is sub-human.

A quite different approach measures machine intelligence through tests which are developed from "mathematical" definitions of intelligence. Examples of these kinds of tests start in the late nineties devising intelligence tests using notions from Kolmogorov complexity and data compression. Two major advantages of mathematical definitions are their applicability to nonhuman intelligences and their absence of a requirement for human testers.

A derivative of the Turing test is the Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). As the name implies, this helps to determine that a user is an actual person and not a computer posing as a human. In contrast to the standard Turing test, CAPTCHA is administered by a machine and targeted to a human as opposed to being administered by a human and targeted to a machine. A computer asks a user to complete a simple test then generates a grade for that test. Computers are unable to solve the problem, so correct solutions are deemed to be the result of a person taking the test. A common type of CAPTCHA is the test that requires the typing of distorted letters, numbers or symbols that appear in an image undecipherable by a computer.

AI is relevant to any intellectual task. Modern artificial intelligence techniques are pervasive and are too numerous to list here. Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.

High-profile examples of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google search), online assistants (such as Siri), image recognition in photographs, spam filtering, prediction of judicial decisions and targeting online advertisements.

With social media sites overtaking TV as a source for news for young people and news organisations increasingly reliant on social media platforms for generating distribution, major publishers now use artificial intelligence (AI) technology to post stories more effectively and generate higher volumes of traffic.

There are a number of competitions and prizes to promote research in artificial intelligence. The main areas promoted are: general machine intelligence, conversational behavior, data-mining, robotic cars, robot soccer and games.

Artificial intelligence is breaking into the healthcare industry by assisting doctors. According to Bloomberg Technology, Microsoft has developed AI to help doctors find the right treatments for cancer. There is a great amount of research and drugs developed relating to cancer. In detail, there are more than 800 medicines and vaccines to treat cancer. This negatively affects the doctors, because there are too many options to choose from, making it more difficult to choose the right drugs for the patients. Microsoft is working on a project to develop a machine called "Hanover". Its goal is to memorize all the papers necessary to cancer and help predict which combinations of drugs will be most effective for each patient. One project that is being worked on at the moment is fighting myeloid leukemia, a fatal cancer where the treatment has not improved in decades. Another study was reported to have found that artificial intelligence was as good as trained doctors in identifying skin cancers. Another study is using artificial intelligence to try and monitor multiple high-risk patients, and this is done by asking each patient numerous questions based on data acquired from live doctor to patient interactions.

According to CNN, there was a recent study by surgeons at the Children's National Medical Center in Washington which successfully demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel during open surgery, and doing so better than a human surgeon, the team claimed. IBM has created its own artificial intelligence computer, the IBM Watson, which has beaten human intelligence (at some levels). Watson not only won at the game show "Jeopardy!" against former champions, but, was declared a hero after successfully diagnosing a women who was suffering from leukemia.

Advancements in AI have contributed to the growth of the automotive industry through the creation and evolution of self-driving vehicles. As of 2016, there are over 30 companies utilizing AI into the creation of driverless cars. A few companies involved with AI include Tesla, Google, and Apple.

Many components contribute to the functioning of self-driving cars. These vehicles incorporate systems such as braking, lane changing, collision prevention, navigation and mapping. Together, these systems, as well as high performance computers, are integrated into one complex vehicle.

Recent developments in autonomous automobiles have made the innovation of self-driving trucks possible, though they are still in the testing phase. The UK government has passed legislation to begin testing of self-driving truck platoons in 2018. Self-driving truck platoons are a fleet of self-driving trucks following the lead of one non-self-driving truck, so the truck platoons aren't entirely autonomous yet. Meanwhile, the Daimler, a German automobile corporation, is testing the Freightliner Inspiration which is a semi-autonomous truck that will only be used on the highway.

One main factor that influences the ability for a driver-less automobile to function is mapping. In general, the vehicle would be pre-programmed with a map of the area being driven. This map would include data on the approximations of street light and curb heights in order for the vehicle to be aware of its surroundings. However, Google has been working on an algorithm with the purpose of eliminating the need for pre-programmed maps and instead, creating a device that would be able to adjust to a variety of new surroundings. Some self-driving cars are not equipped with steering wheels or brake pedals, so there has also been research focused on creating an algorithm that is capable of maintaining a safe environment for the passengers in the vehicle through awareness of speed and driving conditions.

Another factor that is influencing the ability for a driver-less automobile is the safety of the passenger. To make a driver-less automobile, engineers must program it to handle high risk situations. These situations could include a head on collision with pedestrians. The car's main goal should be to make a decision that would avoid hitting the pedestrians and saving the passengers in the car. But there is a possibility the car would need to make a decision that would put someone in danger. In other words, the car would need to decide to save the pedestrians or the passengers. The programing of the car in these situations is crucial to a successful driver-less automobile.

Financial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking can be traced back to 1987 when Security Pacific National Bank in US set-up a Fraud Prevention Task force to counter the unauthorised use of debit cards. Programs like Kasisto and Moneystream are using AI in financial services.

Banks use artificial intelligence systems today to organize operations, maintain book-keeping, invest in stocks, and manage properties. AI can react to changes overnight or when business is not taking place. In August 2001, robots beat humans in a simulated financial trading competition. AI has also reduced fraud and financial crimes by monitoring behavioral patterns of users for any abnormal changes or anomalies.

The use of AI machines in the market in applications such as online trading and decision making has changed major economic theories. For example, AI based buying and selling platforms have changed the law of supply and demand in that it is now possible to easily estimate individualized demand and supply curves and thus individualized pricing. Furthermore, AI machines reduce information asymmetry in the market and thus making markets more efficient while reducing the volume of trades. Furthermore, AI in the markets limits the consequences of behavior in the markets again making markets more efficient. Other theories where AI has had impact include in rational choice, rational expectations, game theory, Lewis turning point, portfolio optimization and counterfactual thinking.

In video games, artificial intelligence is routinely used to generate dynamic purposeful behavior in non-player characters (NPCs). In addition, well-understood AI techniques are routinely used for pathfinding. Some researchers consider NPC AI in games to be a "solved problem" for most production tasks. Games with more atypical AI include the AI director of "Left 4 Dead" (2008) and the neuroevolutionary training of platoons in "Supreme Commander 2" (2010).

Worldwide annual military spending on robotics rose from 5.1 billion USD in 2010 to 7.5 billion USD in 2015. Military drones capable of autonomous action are widely considered a useful asset. In 2017, Vladimir Putin stated that "Whoever becomes the leader in (artificial intelligence) will become the ruler of the world". Many artificial intelligence researchers seek to distance themselves from military applications of AI.

A platform (or "computing platform") is defined as "some sort of hardware architecture or software framework (including application frameworks), that allows software to run". As Rodney Brooks pointed out many years ago, it is not just the artificial intelligence software that defines the AI features of the platform, but rather the actual platform itself that affects the AI that results, i.e., there needs to be work in AI problems on real-world platforms rather than in isolation.

A wide variety of platforms has allowed different aspects of AI to develop, ranging from expert systems such as Cyc to deep-learning frameworks to robot platforms such as the Roomba with open interface. Recent advances in deep artificial neural networks and distributed computing have led to a proliferation of software libraries, including Deeplearning4j, TensorFlow, Theano and Torch.

Collective AI is a platform architecture that combines individual AI into a collective entity, in order to achieve global results from individual behaviors. With its collective structure, developers can crowdsource information and extend the functionality of existing AI domains on the platform for their own use, as well as continue to create and share new domains and capabilities for the wider community and greater good. As developers continue to contribute, the overall platform grows more intelligent and is able to perform more requests, providing a scalable model for greater communal benefit. Organizations like SoundHound Inc. and the Harvard John A. Paulson School of Engineering and Applied Sciences have used this collaborative AI model.

A McKinsey Global Institute study found a shortage of 1.5 million highly trained data and AI professionals and managers and a number of private bootcamps have developed programs to meet that demand, including free programs like The Data Incubator or paid programs like General Assembly.

Amazon, Google, Facebook, IBM, and Microsoft have established a non-profit partnership to formulate best practices on artificial intelligence technologies, advance the public's understanding, and to serve as a platform about artificial intelligence. They stated: "This partnership on AI will conduct research, organize discussions, provide thought leadership, consult with relevant third parties, respond to questions from the public and media, and create educational material that advance the understanding of AI technologies including machine perception, learning, and automated reasoning." Apple joined other tech companies as a founding member of the Partnership on AI in January 2017. The corporate members will make financial and research contributions to the group, while engaging with the scientific community to bring academics onto the board.

There are three philosophical questions related to AI:

Can a machine be intelligent? Can it "think"?







Widespread use of artificial intelligence could have unintended consequences that are dangerous or undesirable. Scientists from the Future of Life Institute, among others, described some short-term research goals to see how AI influences the economy, the laws and ethics that are involved with AI and how to minimize AI security risks. In the long-term, the scientists have proposed to continue optimizing function while minimizing possible security risks that come along with new technologies.

Machines with intelligence have the potential to use their intelligence to make ethical decisions. Research in this area includes "machine ethics", "artificial moral agents", and the study of "malevolent vs. friendly AI".

A common concern about the development of artificial intelligence is the potential threat it could pose to humanity. This concern has recently gained attention after mentions by celebrities including the late Stephen Hawking, Bill Gates, and Elon Musk. A group of prominent tech titans including Peter Thiel, Amazon Web Services and Musk have committed $1billion to OpenAI a nonprofit company aimed at championing responsible AI development. The opinion of experts within the field of artificial intelligence is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI.

In his book "", Nick Bostrom provides an argument that artificial intelligence will pose a threat to mankind. He argues that sufficiently intelligent AI, if it chooses actions based on achieving some goal, will exhibit convergent behavior such as acquiring resources or protecting itself from being shut down. If this AI's goals do not reflect humanity's – one example is an AI told to compute as many digits of pi as possible – it might harm humanity in order to acquire more resources or prevent itself from being shut down, ultimately to better achieve its goal.

For this danger to be realized, the hypothetical AI would have to overpower or out-think all of humanity, which a minority of experts argue is a possibility far enough in the future to not be worth researching. Other counterarguments revolve around humans being either intrinsically or convergently valuable from the perspective of an artificial intelligence.

Concern over risk from artificial intelligence has led to some high-profile donations and investments. In January 2015, Elon Musk donated ten million dollars to the Future of Life Institute to fund research on understanding AI decision making. The goal of the institute is to "grow wisdom with which we manage" the growing power of technology. Musk also funds companies developing artificial intelligence such as Google DeepMind and Vicarious to "just keep an eye on what's going on with artificial intelligence. I think there is potentially a dangerous outcome there."

Development of militarized artificial intelligence is a related concern. Currently, 50+ countries are researching battlefield robots, including the United States, China, Russia, and the United Kingdom. Many people concerned about risk from superintelligent AI also want to limit the use of artificial soldiers.

Joseph Weizenbaum wrote that AI applications cannot, by definition, successfully simulate genuine human empathy and that the use of AI technology in fields such as customer service or psychotherapy was deeply misguided. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known as computationalism). To Weizenbaum these points suggest that AI research devalues human life.

The relationship between automation and employment is complicated. While automation eliminates old jobs, it also creates new jobs through micro-economic and macro-economic effects. Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; "The Economist" states that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously". Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classifies only 9% of U.S. jobs as "high risk". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. Author Martin Ford and others go further and argue that a large number of jobs are routine, repetitive and (to an AI) predictable; Ford warns that these jobs may be automated in the next couple of decades, and that many of the new jobs may not be "accessible to people with average capability", even with retraining. Economists point out that in the past technology has tended to increase rather than reduce total employment, but acknowledge that "we're in uncharted territory" with AI.

This raises the issue of how ethically the machine should behave towards both humans and other AI agents. This issue was addressed by Wendell Wallach in his book titled "Moral Machines" in which he introduced the concept of artificial moral agents (AMA). For Wallach, AMAs have become a part of the research landscape of artificial intelligence as guided by its two central questions which he identifies as "Does Humanity Want Computers Making Moral Decisions" and "Can (Ro)bots Really Be Moral". For Wallach the question is not centered on the issue of "whether" machines can demonstrate the equivalent of moral behavior in contrast to the "constraints" which society may place on the development of AMAs.

The field of machine ethics is concerned with giving machines ethical principles, or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making. The field was delineated in the AAAI Fall 2005 Symposium on Machine Ethics: "Past research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines. In all cases, only human beings have engaged in ethical reasoning. The time has come for adding an ethical dimension to at least some machines. Recognition of the ethical ramifications of behavior involving machines, as well as recent and potential developments in machine autonomy, necessitate this. In contrast to computer hacking, software property issues, privacy issues and other topics normally ascribed to computer ethics, machine ethics is concerned with the behavior of machines towards human users and other machines. Research in machine ethics is key to alleviating concerns with autonomous systems—it could be argued that the notion of autonomous machines without such a dimension is at the root of all fear concerning machine intelligence. Further, investigation of machine ethics could enable the discovery of problems with current ethical theories, advancing our thinking about Ethics." Machine ethics is sometimes referred to as machine morality, computational ethics or computational morality. A variety of perspectives of this nascent field can be found in the collected edition "Machine Ethics" that stems from the AAAI Fall 2005 Symposium on Machine Ethics.

Political scientist Charles T. Rubin believes that AI can be neither designed nor guaranteed to be benevolent. He argues that "any sufficiently advanced benevolence may be indistinguishable from malevolence." Humans should not assume machines or robots would treat us favorably, because there is no "a priori" reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share). Hyper-intelligent software may not necessarily decide to support the continued existence of humanity, and would be extremely difficult to stop. This topic has also recently begun to be discussed in academic publications as a real source of risks to civilization, humans, and planet Earth.

Physicist Stephen Hawking, Microsoft founder Bill Gates, and SpaceX founder Elon Musk have expressed concerns about the possibility that AI could evolve to the point that humans could not control it, with Hawking theorizing that this could "spell the end of the human race".

One proposal to deal with this is to ensure that the first generally intelligent AI is 'Friendly AI', and will then be able to control subsequently developed AIs. Some question whether this kind of check could really remain in place.

Leading AI researcher Rodney Brooks writes, "I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI, and the enormity and complexity of building sentient volitional intelligence."

If an AI system replicates all key aspects of human intelligence, will that system also be sentient – will it have a mind which has conscious experiences? This question is closely related to the philosophical problem as to the nature of human consciousness, generally referred to as the hard problem of consciousness.

Computationalism is the position in the philosophy of mind that the human mind or the human brain (or both) is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind-body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.

The philosophical position that John Searle has named "strong AI" states: "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds." Searle counters this assertion with his Chinese room argument, which asks us to look "inside" the computer and try to find where the "mind" might be.

Mary Shelley's "Frankenstein" considers a key issue in the ethics of artificial intelligence: if a machine can be created that has intelligence, could it also "feel"? If it can feel, does it have the same rights as a human? The idea also appears in modern science fiction, such as the film "", in which humanoid machines have the ability to feel emotions. This issue, now known as "robot rights", is currently being considered by, for example, California's Institute for the Future, although many critics believe that the discussion is premature. Some critics of transhumanism argue that any hypothetical robot rights would lie on a spectrum with animal rights and human rights. The subject is profoundly discussed in the 2010 documentary film "Plug & Pray".

Are there limits to how intelligent machines – or human-machine hybrids – can be? A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. ‘’Superintelligence’’ may also refer to the form or degree of intelligence possessed by such an agent.

If research into Strong AI produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to recursive self-improvement. The new intelligence could thus increase exponentially and dramatically surpass humans. Science fiction writer Vernor Vinge named this scenario "singularity". Technological singularity is when accelerating progress in technologies will cause a runaway effect wherein artificial intelligence will exceed human intellectual capacity and control, thus radically changing or even ending civilization. Because the capabilities of such an intelligence may be impossible to comprehend, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.

Ray Kurzweil has used Moore's law (which describes the relentless exponential improvement in digital technology) to calculate that desktop computers will have the same processing power as human brains by the year 2029, and predicts that the singularity will occur in 2045.

Robot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, which has roots in Aldous Huxley and Robert Ettinger, has been illustrated in fiction as well, for example in the manga "Ghost in the Shell" and the science-fiction series "Dune".

In the 1980s artist Hajime Sorayama's Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later "the Gynoids" book followed that was used by or influenced movie makers including George Lucas and other creatives. Sorayama never considered these organic robots to be real part of nature but always unnatural product of the human mind, a fantasy existing in the mind even when realized in actual form.

Edward Fredkin argues that "artificial intelligence is the next stage in evolution", an idea first proposed by Samuel Butler's "Darwin among the Machines" (1863), and expanded upon by George Dyson in his book of the same name in 1998.

Thought-capable artificial beings appeared as storytelling devices since antiquity.
The implications of a constructed machine exhibiting artificial intelligence have been a persistent theme in science fiction since the twentieth century. Early stories typically revolved around intelligent robots. The word "robot" itself was coined by Karel Čapek in his 1921 play "R.U.R.", the title standing for "Rossum's Universal Robots". Later, the SF writer Isaac Asimov developed the Three Laws of Robotics. He subsequently explored these in his many books, most notably the "Multivac" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during layman discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.

The novel "Do Androids Dream of Electric Sheep?", by Philip K. Dick, tells a science fiction story about Androids and humans clashing in a futuristic world. Elements of artificial intelligence include the empathy box, mood organ, and the androids themselves. Throughout the novel, Dick portrays the idea that human subjectivity is altered by technology created with artificial intelligence.

Nowadays AI is firmly rooted in popular culture; intelligent robots appear in innumerable works. HAL 9000, the murderous computer in charge of the "Discovery One" spaceship in and "" (both 1968), is an example of the common "robotic rampage" archetype in science fiction movies. "The Terminator" (1984) and "The Matrix" (1999) provide additional widely familiar examples. In contrast, the rare loyal robots such as Gort from "The Day the Earth Stood Still" (1951) and Bishop from "Aliens" (1986) are less prominent in popular culture.




</doc>
<doc id="1166" url="https://en.wikipedia.org/wiki?curid=1166" title="Afro Celt Sound System">
Afro Celt Sound System

Their albums have been released through Peter Gabriel's Real World Records, and they have frequently performed at WOMAD festivals worldwide. Their sales on the label are exceeded only by Gabriel himself. Their recording contract with Real World was for five albums, of which "Volume 5: Anatomic" was the last.

After a number of festival dates in 2007, the band went on hiatus. In 2010, they regrouped to play a number of shows (including a return to WOMAD), releasing a re-mastered retrospective titled "Capture."

On 20 May 2014 Afro Celt Sound System announced the upcoming release of a new album, "Born". In January 2016, a posting to that website revealed that due to a dispute with Emmerson, who announced his departure from the band in 2015, there were two active versions of the band, a version led by Emmerson and a separate line-up headed by James McNally and Martin Russell. Emmerson's version of the band released the album "The Source" in 2016.

The dispute ended on December 21, 2016, with an announcement on social media.

The inspiration behind the project dates back to 1991, when Simon Emmerson, a Grammy Award-nominated British producer and guitarist, collaborated with Afro-pop star Baaba Maal. While making an album with Maal in Senegal, Emmerson was struck by the similarity between one African melody and a traditional Irish air. Back in London, Irish musician Davy Spillane told Emmerson about a belief that nomadic Celts lived in Africa or India before they migrated to Western Europe. Whether or not the theory was true, Emmerson was intrigued by the two countries' musical affinities.

In an experiment that would prove successful, Emmerson brought two members of Baaba Maal's band together with traditional Irish musicians to see what kind of music the two groups would create. Adding a dash of modern sound, Emmerson also brought in English dance mixers for an electronic beat. "People thought I was mad when I touted the idea," Emmerson told Jim Carroll of "The Irish Times". "At the time, I was out of favour with the London club scene. I was broke and on income support but the success was extraordinary".

Jamming in the studios at Real World, musician Peter Gabriel's recording facilities in Wiltshire, England, the diverse group of musicians recorded the basis of their first album in one week. This album, "", was released by Real World Records in 1996, and marked the debut of the Afro Celt Sound System.

"Prior to that first album being made, none of us knew if it would work," musician James McNally told Larry Katz of the Boston Herald. "We were strangers who didn't even speak the same language. But we were bowled over by this communication that took place beyond language." McNally, who grew up second-generation Irish in London, played whistles, keyboards, piano, bodhran, and bamboo flute.

"Sound Magic" has now sold over 300,000 copies. The band performed at festivals, raves, and dance clubs and regularly included two African musicians, Moussa Sissokho on talking drum and djembe and N'Faly Kouyate on vocals, kora and balafon.

Just as the second album was getting off the ground, one of the group's core musicians, 27-year-old keyboardist Jo Bruce (son of Cream bass player Jack Bruce), died suddenly of an asthma attack. The band was devastated, and the album was put on hold. Then Irish pop star Sinéad O'Connor came to the rescue, collaborating with the band and helping them cope with their loss. "[O'Connor] blew into the studio on a windy November night and blew away again leaving us something incredibly emotional and powerful," McNally told Katz. "We had this track we didn't know what to do with. Sinéad scribbled a few lyrics and bang! She left us completely choked up." So taken was the band with O'Connor's song, "Release," that they used the name for the title of their album. "" hit the music stores in 1999, and by the spring of 2000 it had sold more than half a million copies worldwide.

In 2000 the group was nominated for a Grammy Award in the Best World Music category. The band, composed at the time of eight members from six countries (England, Senegal, Guinea, Ireland, France and Kenya), took pride in its ability to bring people together through music. "We can communicate anywhere at any corner of the planet and feel that we're at home," McNally told Patrick MacDonald of The Seattle Times". "We're breaking down categories of world music and rock music and black music. We leave a door open to communicate with each other's traditions. And it's changed our lives".

In 2001 the group released "", which climbed to number one on Billboard's Top World Music Albums chart. Featuring guest spots by Peter Gabriel and Robert Plant, the album also incorporated a heightened African sound. "On the first two records, the pendulum swung more toward the Celtic, London club side of the equation," Emmerson told the Irish Times's Carroll. "For this one, we wanted to have more African vocals and input than we'd done before." Again the Afro Celt Sound System met with success. Chuck Taylor of Billboard magazine praised the album as "a cultural phenomenon that bursts past the traditional boundaries of contemporary music." The single "When You're Falling", with vocals by Gabriel, became a radio hit in the United States.

In 2003, for the "Seed" album, they temporarily changed their name to the simpler Afrocelts; this was subsequently regarded as a mistake, and they reverted to the longer and more familiar band name for their subsequent albums, "Pod", a compilation of new mixes of songs from the first four albums, "" (their fifth studio album), and "Capture - Afro Celt Sound System 1995-2010".

They played a number of shows to promote "Volume 5: Anatomic" in 2006 and summer 2007, ending with a gig in Korea, before taking an extended break to work on side projects, amongst them "The Imagined Village" featuring Simon Emmerson and Johnny Kalsi. Starting in the summer of 2010, the band performed a series of live shows to promote a new 2-CD album, "Capture - Afro Celt Sound System 1995-2010", released on 6 September 2010 on Real World Records. Further performances continue to the present day, and a new album-in-progress titled "Born" was announced on their website in 2014. Following the split (see below), Emmerson's version of the band released the album The Source in 2016.

During the year 2015, the band had split into two formations, one of them including Simon Emmerson, N'Faly Kouyate and Johnny Kalsi, the other one James McNally and Martin Russell. The split was announced on the band's website in January 2016. The dispute officially ended with an announcement on social media on December 21, 2016. "Simon Emmerson, James McNally and Martin Russell are pleased to announce that they have been able to set aside their differences and come to an amicable agreement to bring their dispute to an end. Going forward, McNally, Russell and Emmerson have agreed that Emmerson will continue to perform as Afro Celt Sound System and McNally and Russell will work under a new name to be announced in due course.
While McNally, Russell and Emmerson will no longer be performing or working together they recognise, and are grateful for each other's contribution to Afro Celt Sound System over the past two decades and will be working with the extensive community of musicians that make up the long standing Afro Celt Sound System family." Emmerson's version of the band released the album The Source in 2016.

When Afro Celt Sound System began their musical journey in the mid-1990s during the Real World Recording Week, the difference between a guest artist and a band member was virtually non-existent. However, over time, a combination of people became most often associated with the name Afro Celt Sound System (while "Volume 5: Anatomic" only lists Emmerson, McNally, Ó Lionáird and Russell as regulars). The divided grouping of the band into two versions, both operating under the name Afro Celt Sound System, began in January 2016 and was resolved in December 2016 after McNally and Russell agreed to work under a different name from Emmerson.

Russell/McNally version

Other musicians who have performed or recorded with Afro Celt Sound System include: Jimmy Mahon, Demba Barry, Babara Bangoura, Iarla Ó Lionáird, Peter Gabriel, Robert Plant, Pete Lockett, Sinéad O'Connor, Pina Kollar, Dorothee Munyaneza, Sevara Nazarkhan, Simon Massey, Jesse Cook, Martin Hayes, Eileen Ivers, Mundy, Mairéad Ní Mhaonaigh and Ciarán Tourish of Altan, Ronan Browne, Michael McGoldrick, Myrdhin, Shooglenifty, Mairead Nesbitt, Nigel Eaton, Davy Spillane, Jonas Bruce, Heather Nova, Julie Murphy and Ayub Ogada, Ross Ainslie.


They also recorded the soundtrack for the PC game "Magic and Mayhem", released in 1998.



</doc>
<doc id="1167" url="https://en.wikipedia.org/wiki?curid=1167" title="Ancient philosophy">
Ancient philosophy

This page lists some links to ancient philosophy. In Western philosophy, the spread of Christianity in the Roman Empire marked the ending of Hellenistic philosophy and ushered in the beginnings of Medieval philosophy, whereas in Eastern philosophy, the spread of Islam through the Arab Empire marked the end of Old Iranian philosophy and ushered in the beginnings of early Islamic philosophy.

Genuinely philosophical thought, depending upon original individual insights, arose in many cultures roughly contemporaneously. Karl Jaspers termed the intense period of philosophical development beginning around the 7th century and concluding around the 3rd century BCE an Axial Age in human thought.

Chinese philosophy is the dominant philosophical thought in China and other countries within the East Asian cultural sphere that share a common language, including Japan, Korea, and Vietnam.

The Hundred Schools of Thought were philosophers and schools that flourished from the 6th century to 221 BCE, an era of great cultural and intellectual expansion in China. Even though this period – known in its earlier part as the Spring and Autumn period and the Warring States period – in its latter part was fraught with chaos and bloody battles, it is also known as the Golden Age of Chinese philosophy because a broad range of thoughts and ideas were developed and discussed freely. The thoughts and ideas discussed and refined during this period have profoundly influenced lifestyles and social consciousness up to the present day in East Asian countries. The intellectual society of this era was characterized by itinerant scholars, who were often employed by various state rulers as advisers on the methods of government, war, and diplomacy. This period ended with the rise of the Qin Dynasty and the subsequent purge of dissent. The Book of Han lists ten major schools, they are:

The founder of the Qin Dynasty, who implemented Legalism as the official philosophy, quashed Mohist and Confucianist schools. Legalism remained influential until the emperors of the Han Dynasty adopted Daoism and later Confucianism as official doctrine. These latter two became the determining forces of Chinese thought until the introduction of Buddhism.

Confucianism was particularly strong during the Han Dynasty, whose greatest thinker was Dong Zhongshu, who integrated Confucianism with the thoughts of the Zhongshu School and the theory of the Five Elements. He also was a promoter of the New Text school, which considered Confucius as a divine figure and a spiritual ruler of China, who foresaw and started the evolution of the world towards the Universal Peace. In contrast, there was an Old Text school that advocated the use of Confucian works written in ancient language (from this comes the denomination "Old Text") that were so much more reliable. In particular, they refuted the assumption of Confucius as a godlike figure and considered him as the greatest sage, but simply a human and mortal.

The 3rd and 4th centuries saw the rise of the "Xuanxue" (mysterious learning), also called "Neo-Taoism". The most important philosophers of this movement were Wang Bi, Xiang Xiu and Guo Xiang. The main question of this school was whether Being came before Not-Being (in Chinese, "ming" and "wuming"). A peculiar feature of these Taoist thinkers, like the Seven Sages of the Bamboo Grove, was the concept of "feng liu" (lit. wind and flow), a sort of romantic spirit which encouraged following the natural and instinctive impulse.

Buddhism arrived in China around the 1st century AD, but it was not until the Northern and Southern, Sui and Tang Dynasties that it gained considerable influence and acknowledgement. At the beginning, it was considered a sort of Taoist sect, and there was even a theory about Laozi, founder of Taoism, who went to India and taught his philosophy to Buddha. Mahayana Buddhism was far more successful in China than its rival Hinayana, and both Indian schools and local Chinese sects arose from the 5th century. Two chiefly important monk philosophers were Sengzhao and Daosheng. But probably the most influential and original of these schools was the Chan sect, which had an even stronger impact in Japan as the Zen sect.






See also: "Christian philosophy"


The ancient Indian philosophy is a fusion of two ancient traditions : Sramana tradition and Vedic tradition.

Indian philosophy begins with the "Vedas" where questions related to laws of nature, the origin of the universe and the place of man in it are asked. In the famous Rigvedic "Hymn of Creation" (Nasadiya Sukta) the poet says:

In the Vedic view, creation is ascribed to the self-consciousness of the primeval being ("Purusha"). This leads to the inquiry into "the one being" that underlies the diversity of empirical phenomena and the origin of all things. Cosmic order is termed "rta" and causal law by "karma". Nature ("prakriti") is taken to have three qualities ("sattva", "rajas", and "tamas").

Jainism and Buddhism are continuation of the Sramana school of thought. The Sramanas cultivated a pessimistic worldview of the samsara as full of suffering and advocated renunciation and austerities. They laid stress on philosophical concepts like Ahimsa, Karma, Jnana, Samsara and Moksa. Cārvāka (Sanskrit: चार्वाक) (atheist) philosophy, also known as Lokāyata, it is a system of Hindu philosophy that assumes various forms of philosophical skepticism and religious indifference. It is named after its founder, Cārvāka, author of the Bārhaspatya-sūtras.

In classical times, these inquiries were systematized in six schools of philosophy. Some of the questions asked were:

The Six schools of Indian philosophy are:






See also: "Dualism, Dualism (philosophy of mind)"

While there are ancient relations between the Indian Vedas and the Iranian Avesta, the two main families of the Indo-Iranian philosophical traditions were characterized by fundamental differences in their implications for the human being's position in society and their view of man's role in the universe. The first charter of human rights by Cyrus the Great as understood in the Cyrus cylinder is often seen as a reflection of the questions and thoughts expressed by Zarathustra and developed in Zoroastrian schools of thought of the Achaemenid Era of Iranian history.

Ideas and tenets of Zoroastrian schools of Early Persian philosophy are part of many works written in Middle Persian and of the extant scriptures of the zoroastrian religion in Avestan language. Among these are treatises such as the Shikand-gumanic Vichar by Mardan-Farrux Ohrmazddadan, selections of Denkard, Wizidagīhā-ī Zātspram ("Selections of Zātspram") as well as older passages of the book Avesta, the Gathas which are attributed to Zarathustra himself and regarded as his "direct teachings".

Anacharsis







See also: "Jewish philosophy"








</doc>
<doc id="1168" url="https://en.wikipedia.org/wiki?curid=1168" title="Anaximander">
Anaximander

Anaximander (; "Anaximandros"; was a pre-Socratic Greek philosopher who lived in Miletus, a city of Ionia (in modern-day Turkey). He belonged to the Milesian school and learned the teachings of his master Thales. He succeeded Thales and became the second master of that school where he counted Anaximenes and, arguably, Pythagoras amongst his pupils.

Little of his life and work is known today. According to available historical documents, he is the first philosopher known to have written down his studies, although only one fragment of his work remains. Fragmentary testimonies found in documents after his death provide a portrait of the man.

He was an early proponent of science and tried to observe and explain different aspects of the universe, with a particular interest in its origins, claiming that nature is ruled by laws, just like human societies, and anything that disturbs the balance of nature does not last long. Like many thinkers of his time, Anaximander's philosophy included contributions to many disciplines. In astronomy, he attempted to describe the mechanics of celestial bodies in relation to the Earth. In physics, his postulation that the indefinite (or apeiron) was the source of all things led Greek philosophy to a new level of conceptual abstraction. His knowledge of geometry allowed him to introduce the gnomon in Greece. He created a map of the world that contributed greatly to the advancement of geography. He was also involved in the politics of Miletus and was sent as a leader to one of its colonies.

Anaximander, son of Praxiades, was born in the third year of the 42nd Olympiad (610 BC). According to Apollodorus of Athens, Greek grammarian of the 2nd century BC, he was sixty-four years old during the second year of the 58th Olympiad (547–546 BC), and died shortly afterwards.

Establishing a timeline of his work is now impossible, since no document provides chronological references. Themistius, a 4th-century Byzantine rhetorician, mentions that he was the "first of the known Greeks to publish a written document on nature." Therefore, his texts would be amongst the earliest written in prose, at least in the Western world. By the time of Plato, his philosophy was almost forgotten, and Aristotle, his successor Theophrastus and a few doxographers provide us with the little information that remains. However, we know from Aristotle that Thales, also from Miletus, precedes Anaximander. It is debatable whether Thales actually was the teacher of Anaximander, but there is no doubt that Anaximander was influenced by Thales' theory that everything is derived from water. One thing that is not debatable is that even the ancient Greeks considered Anaximander to be from the Monist school which began in Miletus, with Thales followed by Anaximander and finished with Anaximenes. 3rd-century Roman rhetorician Aelian depicts him as leader of the Milesian colony to Apollonia on the Black Sea coast, and hence some have inferred that he was a prominent citizen. Indeed, "Various History" (III, 17) explains that philosophers sometimes also dealt with political matters. It is very likely that leaders of Miletus sent him there as a legislator to create a constitution or simply to maintain the colony’s allegiance.

Anaximander's theories were influenced by the Greek mythical tradition, and by some ideas of Thales – the father of philosophy – as well as by observations made by older civilizations in the East (especially by the Babylonian astrologers). All these were elaborated rationally. In his desire to find some universal principle, he assumed, like traditional religion, the existence of a cosmic order; and in elaborating his ideas on this he used the old mythical language which ascribed divine control to various spheres of reality. This was a common practice for the Greek philosophers in a society which saw gods everywhere, therefore they could fit their ideas into a tolerably elastic system.

Some scholars see a gap between the existing mythical and the new rational way of thought which is the main characteristic of the archaic period (8th to 6th century BC) in the Greek city-states. This has given rise to the phrase "Greek miracle". But if we follow carefully the course of Anaximander's ideas, we will notice that there was not such an abrupt break as initially appears. The basic elements of nature (water, air, fire, earth) which the first Greek philosophers believed that constituted the universe represent in fact the primordial forces of previous thought. Their collision produced what the mythical tradition had called cosmic harmony. In the old cosmogonies – Hesiod (8th – 7th century BC) and Pherecydes (6th century BC) – Zeus establishes his order in the world by destroying the powers which were threatening this harmony, (the Titans). Anaximander claimed that the cosmic order is not monarchic but geometric and this causes the equilibrium of the earth which is lying in the centre of the universe. This is the projection on nature of a new political order and a new space organized around a centre which is the static point of the system in the society as in nature. In this space there is "isonomy" (equal rights) and all the forces are symmetrical and transferrable. The decisions are now taken by the assembly of "demos" in the "agora" which is lying in the middle of the city.

The same "rational" way of thought led him to introduce the abstract "apeiron" (indefinite, infinite, boundless, unlimited) as an origin of the universe, a concept that is probably influenced by the original Chaos (gaping void, abyss, formless state) of the mythical Greek cosmogony from which everything else appeared. It also takes notice of the mutual changes between the four elements. Origin, then, must be something else unlimited in its source, that could create without experiencing decay, so that genesis would never stop.

The "Refutation" attributed to Hippolytus of Rome (I, 5), and the later 6th century Byzantine philosopher Simplicius of Cilicia, attribute to Anaximander the earliest use of the word "apeíron" ( "infinite" or "limitless") to designate the original principle. He was the first philosopher to employ, in a philosophical context, the term "archế" (), which until then had meant beginning or origin. For him, it became no longer a mere point in time, but a source that could perpetually give birth to whatever will be. The indefiniteness is spatial in early usages as in Homer (indefinite sea) and as in Xenophanes (6th century BC) who said that the earth went down indefinitely (to "apeiron") i.e. beyond the imagination or concept of men.

Aristotle writes ("Metaphysics", I III 3–4) that the Pre-Socratics were searching for the element that constitutes all things. While each pre-Socratic philosopher gave a different answer as to the identity of this element (water for Thales and air for Anaximenes), Anaximander understood the beginning or first principle to be an endless, unlimited primordial mass ("apeiron"), subject to neither old age nor decay, that perpetually yielded fresh materials from which everything we perceive is derived. He proposed the theory of the "apeiron" in direct response to the earlier theory of his teacher, Thales, who had claimed that the primary substance was water. The notion of temporal infinity was familiar to the Greek mind from remote antiquity in the religious concept of immortality and Anaximander's description was in terms appropriate to this conception. This "arche" is called "eternal and ageless". (Hippolytus (?), "Refutation", I,6,I;DK B2)

For Anaximander, the principle of things, the constituent of all substances, is nothing determined and not an element such as water in Thales' view. Neither is it something halfway between air and water, or between air and fire, thicker than air and fire, or more subtle than water and earth. Anaximander argues that water cannot embrace all of the opposites found in nature — for example, water can only be wet, never dry — and therefore cannot be the one primary substance; nor could any of the other candidates. He postulated the "apeiron" as a substance that, although not directly perceptible to us, could explain the opposites he saw around him.

Anaximander explains how the four elements of ancient physics (air, earth, water and fire) are formed, and how Earth and terrestrial beings are formed through their interactions. Unlike other Pre-Socratics, he never defines this principle precisely, and it has generally been understood (e.g., by Aristotle and by Saint Augustine) as a sort of primal chaos. According to him, the Universe originates in the separation of opposites in the primordial matter. It embraces the opposites of hot and cold, wet and dry, and directs the movement of things; an entire host of shapes and differences then grow that are found in "all the worlds" (for he believed there were many).

Anaximander maintains that all dying things are returning to the element from which they came ("apeiron"). The one surviving fragment of Anaximander's writing deals with this matter. Simplicius transmitted it as a quotation, which describes the balanced and mutual changes of the elements:
Whence things have their origin,
Thence also their destruction happens,
According to necessity;
For they give to each other justice and recompense
For their injustice
In conformity with the ordinance of Time.
Simplicius mentions that Anaximander said all these "in poetic terms", meaning that he used the old mythical language. The goddess Justice (Dike) keeps the cosmic order.
This concept of returning to the element of origin was often revisited afterwards, notably by Aristotle, and by the Greek tragedian Euripides: "what comes from earth must return to earth." Friedrich Nietzsche, in his "Philosophy in the Tragic Age of the Greeks", stated that Anaximander viewed "... all coming-to-be as though it were an illegitimate emancipation from eternal being, a wrong for which destruction is the only penance." Physicist Max Born, in commenting upon Werner Heisenberg's arriving at the idea that the elementary particles of quantum mechanics are to be seen as different manifestations, different quantum states, of one and the same “primordial substance,”' proposed that this primordial substance be called "apeiron".

Anaximander's bold use of non-mythological explanatory hypotheses considerably distinguishes him from previous cosmology writers such as Hesiod. It confirms that pre-Socratic philosophers were making an early effort to demystify physical processes. His major contribution to history was writing the oldest prose document about the Universe and the origins of life; for this he is often called the "Father of Cosmology" and founder of astronomy. However, pseudo-Plutarch states that he still viewed celestial bodies as deities.

Anaximander was the first to conceive a mechanical model of the world. In his model, the Earth floats very still in the centre of the infinite, not supported by anything. It remains "in the same place because of its indifference", a point of view that Aristotle considered ingenious, but false, in "On the Heavens". Its curious shape is that of a cylinder with a height one-third of its diameter. The flat top forms the inhabited world, which is surrounded by a circular oceanic mass.

Anaximander's realization that the Earth floats free without falling and does not need to be resting on something has been indicated by many as the first cosmological revolution and the starting point of scientific thinking. Karl Popper calls this idea "one of the boldest, most revolutionary, and most portentous ideas in the whole history of human thinking." Such a model allowed the concept that celestial bodies could pass under the Earth, opening the way to Greek astronomy.

At the origin, after the separation of hot and cold, a ball of flame appeared that surrounded Earth like bark on a tree. This ball broke apart to form the rest of the Universe. It resembled a system of hollow concentric wheels, filled with fire, with the rims pierced by holes like those of a flute. Consequently, the Sun was the fire that one could see through a hole the same size as the Earth on the farthest wheel, and an eclipse corresponded with the occlusion of that hole. The diameter of the solar wheel was twenty-seven times that of the Earth (or twenty-eight, depending on the sources) and the lunar wheel, whose fire was less intense, eighteen (or nineteen) times. Its hole could change shape, thus explaining lunar phases. The stars and the planets, located closer, followed the same model.

Anaximander was the first astronomer to consider the Sun as a huge mass, and consequently, to realize how far from Earth it might be, and the first to present a system where the celestial bodies turned at different distances. Furthermore, according to Diogenes Laertius (II, 2), he built a celestial sphere. This invention undoubtedly made him the first to realize the obliquity of the Zodiac as the Roman philosopher Pliny the Elder reports in "Natural History" (II, 8). It is a little early to use the term ecliptic, but his knowledge and work on astronomy confirm that he must have observed the inclination of the celestial sphere in relation to the plane of the Earth to explain the seasons. The doxographer and theologian Aetius attributes to Pythagoras the exact measurement of the obliquity.

According to Simplicius, Anaximander already speculated on the plurality of worlds, similar to atomists Leucippus and Democritus, and later philosopher Epicurus. These thinkers supposed that worlds appeared and disappeared for a while, and that some were born when others perished. They claimed that this movement was eternal, "for without movement, there can be no generation, no destruction".

In addition to Simplicius, Hippolytus reports Anaximander's claim that from the infinite comes the principle of beings, which themselves come from the heavens and the worlds (several doxographers use the plural when this philosopher is referring to the worlds within, which are often infinite in quantity). Cicero writes that he attributes different gods to the countless worlds.

This theory places Anaximander close to the Atomists and the Epicureans who, more than a century later, also claimed that an infinity of worlds appeared and disappeared. In the timeline of the Greek history of thought, some thinkers conceptualized a single world (Plato, Aristotle, Anaxagoras and Archelaus), while others instead speculated on the existence of a series of worlds, continuous or non-continuous (Anaximenes, Heraclitus, Empedocles and Diogenes).

Anaximander attributed some phenomena, such as thunder and lightning, to the intervention of elements, rather than to divine causes. In his system, thunder results from the shock of clouds hitting each other; the loudness of the sound is proportionate with that of the shock. Thunder without lightning is the result of the wind being too weak to emit any flame, but strong enough to produce a sound. A flash of lightning without thunder is a jolt of the air that disperses and falls, allowing a less active fire to break free. Thunderbolts are the result of a thicker and more violent air flow.

He saw the sea as a remnant of the mass of humidity that once surrounded Earth. A part of that mass evaporated under the sun's action, thus causing the winds and even the rotation of the celestial bodies, which he believed were attracted to places where water is more abundant. He explained rain as a product of the humidity pumped up from Earth by the sun. For him, the Earth was slowly drying up and water only remained in the deepest regions, which someday would go dry as well. According to Aristotle's "Meteorology" (II, 3), Democritus also shared this opinion.

Anaximander speculated about the beginnings and origin of animal life. Taking into account the existence of fossils , he claimed that animals sprang out of the sea long ago. The first animals were born trapped in a spiny bark, but as they got older, the bark would dry up and break. As the early humidity evaporated, dry land emerged and, in time, humankind had to adapt. The 3rd century Roman writer Censorinus reports:

Anaximander put forward the idea that humans had to spend part of this transition inside the mouths of big fish to protect themselves from the Earth's climate until they could come out in open air and lose their scales. He thought that, considering humans' extended infancy, we could not have survived in the primeval world in the same manner we do presently.

Both Strabo and Agathemerus (later Greek geographers) claim that, according to the geographer Eratosthenes, Anaximander was the first to publish a map of the world. The map probably inspired the Greek historian Hecataeus of Miletus to draw a more accurate version. Strabo viewed both as the first geographers after Homer.

Maps were produced in ancient times, also notably in Egypt, Lydia, the Middle East, and Babylon. Only some small examples survived until today. The unique example of a world map comes from late Babylonian tablet BM 92687 later than 9th century BC but is based probably on a much older map. These maps indicated directions, roads, towns, borders, and geological features. Anaximander's innovation was to represent the entire inhabited land known to the ancient Greeks.

Such an accomplishment is more significant than it at first appears. Anaximander most likely drew this map for three reasons. First, it could be used to improve navigation and trade between Miletus's colonies and other colonies around the Mediterranean Sea and Black Sea. Second, Thales would probably have found it easier to convince the Ionian city-states to join in a federation in order to push the Median threat away if he possessed such a tool. Finally, the philosophical idea of a global representation of the world simply for the sake of knowledge was reason enough to design one.

Surely aware of the sea's convexity, he may have designed his map on a slightly rounded metal surface. The centre or “navel” of the world ( "omphalós gẽs") could have been Delphi, but is more likely in Anaximander's time to have been located near Miletus. The Aegean Sea was near the map's centre and enclosed by three continents, themselves located in the middle of the ocean and isolated like islands by sea and rivers. Europe was bordered on the south by the Mediterranean Sea and was separated from Asia by the Black Sea, the Lake Maeotis, and, further east, either by the Phasis River (now called the Rioni) or the Tanais. The Nile flowed south into the ocean, separating Libya (which was the name for the part of the then-known African continent) from Asia.

The "Suda" relates that Anaximander explained some basic notions of geometry. It also mentions his interest in the measurement of time and associates him with the introduction in Greece of the gnomon. In Lacedaemon, he participated in the construction, or at least in the adjustment, of sundials to indicate solstices and equinoxes. Indeed, a gnomon required adjustments from a place to another because of the difference in latitude.

In his time, the gnomon was simply a vertical pillar or rod mounted on a horizontal plane. The position of its shadow on the plane indicated the time of day. As it moves through its apparent course, the sun draws a curve with the tip of the projected shadow, which is shortest at noon, when pointing due south. The variation in the tip’s position at noon indicates the solar time and the seasons; the shadow is longest on the winter solstice and shortest on the summer solstice.

The invention of the gnomon itself cannot be attributed to Anaximander because its use, as well as the division of days into twelve parts, came from the Babylonians. It is they, according to Herodotus' Histories (II, 109), who gave the Greeks the art of time measurement. It is likely that he was not the first to determine the solstices, because no calculation is necessary. On the other hand, equinoxes do not correspond to the middle point between the positions during solstices, as the Babylonians thought. As the "Suda" seems to suggest, it is very likely that with his knowledge of geometry, he became the first Greek to accurately determine the equinoxes.

In his philosophical work De Divinatione (I, 50, 112), Cicero states that Anaximander convinced the inhabitants of Lacedaemon to abandon their city and spend the night in the country with their weapons because an earthquake was near. The city collapsed when the top of the Taygetus split like the stern of a ship. Pliny the Elder also mentions this anecdote (II, 81), suggesting that it came from an "admirable inspiration", as opposed to Cicero, who did not associate the prediction with divination.

Bertrand Russell in the "History of Western Philosophy" interprets Anaximander's theories as an assertion of the necessity of an appropriate balance between earth, fire, and water, all of which may be independently seeking to aggrandize their proportions relative to the others. Anaximander seems to express his belief that a natural order ensures balance between these elements, that where there was fire, ashes (earth) now exist. His Greek peers echoed this sentiment with their belief in natural boundaries beyond which not even the gods could operate.

Friedrich Nietzsche, in "Philosophy in the Tragic Age of the Greeks", claimed that Anaximander was a pessimist who asserted that the primal being of the world was a state of indefiniteness. In accordance with this, anything definite has to eventually pass back into indefiniteness. In other words, Anaximander viewed "...all coming-to-be as though it were an illegitimate emancipation from eternal being, a wrong for which destruction is the only penance". ("Ibid.", § 4) The world of individual objects, in this way of thinking, has no worth and should perish.

Martin Heidegger lectured extensively on Anaximander, and delivered a lecture entitled "Anaximander's Saying" which was subsequently included in "Off the Beaten Track". The lecture examines the ontological difference and the oblivion of Being or "Dasein" in the context of the Anaximander fragment. Heidegger's lecture is, in turn, an important influence on the French philosopher Jacques Derrida.

According to the "Suda":







</doc>
<doc id="1169" url="https://en.wikipedia.org/wiki?curid=1169" title="APL">
APL

APL is an abbreviation, acronym, or initialism that may refer to:







</doc>
<doc id="1170" url="https://en.wikipedia.org/wiki?curid=1170" title="Architect">
Architect

An architect is a person who plans, designs, and reviews the construction of buildings. To "practice architecture" means to provide services in connection with the design of buildings and the space within the site surrounding the buildings, that have as their principal purpose human occupancy or use. Etymologically, "architect" derives from the Latin "architectus", which derives from the Greek ("arkhi-", chief + "tekton", builder), i.e., chief builder.

Professionally, an architect's decisions affect public safety, and thus an architect must undergo specialized training consisting of advanced education and a "practicum" (or "internship") for practical experience to earn a license to practice architecture. Practical, technical, and academic requirements for becoming an architect vary by jurisdiction (see below).

The terms architect and architecture are also commonly used in the disciplines of landscape architecture, naval architecture, and information technology, which includes roles of solution architect, enterprise architect, systems architect, and software architect. The title of Architect is protected by statute in the United Kingdom and should only be used by Architects registered in the UK with the Architects Registration Board(ARB).

Throughout ancient and medieval history, most of the architectural design and construction was carried out by artisans—such as stone masons and carpenters, rising to the role of master builder. Until modern times, there was no clear distinction between architect and engineer. In Europe, the titles "architect" and "engineer" were primarily geographical variations that referred to the same person, often used interchangeably.

It is suggested that various developments in technology and mathematics allowed the development of the professional 'gentleman' architect, separate from the hands-on craftsman. Paper was not used in Europe for drawing until the 15th century but became increasingly available after 1500. Pencils were used more often for drawing by 1600. The availability of both allowed pre-construction drawings to be made by professionals. Concurrently, the introduction of linear perspective and innovations such as the use of different projections to describe a three-dimensional building in two dimensions, together with an increased understanding of dimensional accuracy, helped building designers communicate their ideas. However, the development was gradual. Until the 18th-century, buildings continued to be designed and set out by craftsmen with the exception of high-status projects.

In most developed countries, only qualified people with appropriate license, certification, or registration with a relevant body, often governmental, may legally practice architecture. Such licensure usually requires an accredited university degree, successful completion of exams, and a training period. The use of terms and titles and the representation of oneself as an architect is restricted to licensed individuals by law, although in general, derivatives such as "architectural designer" are often not legally protected.

To practice architecture implies the ability to practice independently of supervision. The term "building design professional" (or "Design professional)", by contrast, is a much broader term that includes professionals who practice independently under an alternate profession, such as engineering professionals, or those who assist in the practice architecture under the supervision of a licensed architect, such as "architectural technologists" and "intern architects". In many places, independent, non-licensed individuals may perform design services outside the professional restrictions, such design houses and other smaller structures.

In the architectural profession, technical and environmental knowledge, design and construction management, and an understanding of business are as important as design. However, design is the driving force throughout the project and beyond. An architect accepts a commission from a client. The commission might involve preparing feasibility reports, building audits, the design of a building or of several buildings, structures, and the spaces among them. The architect participates in developing the requirements the client wants in the building. Throughout the project (planning to occupancy), the architect co-ordinates a design team. Structural, mechanical, and electrical engineers and other specialists, are hired by the client or the architect, who must ensure that the work is co-ordinated to construct the design.

The architect hired by a client is responsible for creating a design concept that meets the requirements of that client and provides a facility suitable to the required use. In that, the architect must meet with and question the client to ascertain all the requirements and nuances of the planned project. Often the full brief is not entirely clear at the beginning, entailing a degree of risk in the design undertaking. The architect may make early proposals to the client which may rework the terms of the brief. The program or brief is essential to producing a project that meets all the needs of the owner — it is a guide for the architect in creating the design concept.

It is generally expected that the design proposal(s)is both imaginative as well as pragmatic, but the precise extent and nature of these expectations will vary, depending on the place, time, finance, culture, and available crafts and technology in which the design takes place.

Design buildings is a very complex and demanding undertaking, no matter what the scale of the project might be. A strong degree of foresight is a prerequisite. Any design concept must at a very early stage in its generation take into account a great number of issues and variables which include qualities of space(s), the end-use and life-cycle of these proposed spaces, connections, relations, and aspects between spaces including how they are put together as well as the impact of proposals on the immediate and wider locality. Selection of appropriate materials and technology must be considered, tested and reviewed at an early stage in the design to ensure there are no setbacks (such as higher-than-expected costs) which may occur later. The site and its environs, as well as the culture and history of the place, will also influence the design. The design must also countenance increasing concerns with environmental sustainability. The architect may introduce (intentionally or not), to greater or lesser degrees, aspects of mathematics and architecture, new or current architectural theory, or references to architectural history.

A key part of design is that the architect often consults with engineers, surveyors and other specialists throughout the design, ensuring that aspects such as the structural supports and air conditioning elements are coordinated in the scheme as a whole. The control and planning of construction costs are also a part of these consultations. Coordination of the different aspects involves a high degree of specialized communication, including advanced computer technology such as BIM (Building Information Management), CAD, and cloud-based technologies.

At all times in the design, the architect reports back to the client who may have reservations or recommendations, introducing a further variable into the design.

Architects deal with local and federal jurisdictions about regulations and building codes. The architect might need to comply with local planning and zoning laws, such as required setbacks, height limitations, parking requirements, transparency requirements (windows), and land use. Some established jurisdictions require adherence to design and historic preservation guidelines. Health and safety risks form a vital part of current design, and in many jurisdictions, design reports and records are required which include ongoing considerations such as materials and contaminants, waste management and recycling, traffic control and fire safety.

Previously, architects employed drawings to illustrate and generate design proposals. While conceptual sketches are still widely used by architects, computer technology has now become the industry standard. However, design may include the use of photos, collages, prints, linocuts, and other media in design production. 
Increasingly, computer software such as BIM is shaping how architects work. BIM technology allows for the creation of a virtual building that serves as an information database for the sharing of design and building information throughout the life-cycle of the building's design, construction and maintenance.

As current buildings are now known to be high emitters of carbon into the atmosphere, increasing controls are being placed on buildings and associated technology to reduce emissions, increase energy efficiency, and make use of renewable energy sources. Renewable energy sources may be developed within the proposed building or via local or national renewable energy providers. As a result, the architect is required to remain abreast of current regulations which are continually tightening. Some new developments exhibit extremely low energy use.
However, the architect is also increasingly required to provide initiatives in a wider environmental sense, such as making provision for low-energy transport, natural daylighting instead of artificial lighting, natural ventilation instead of air conditioning, pollution, and waste management, use of recycled materials and employment of materials which can be easily recycled in the future.

As the design becomes more advanced and detailed, specifications and detail designs are made of all the elements and components of the building. Techniques in the production of building are continually advancing which places a demand on the architect to ensure that he or she remains up to date with these advances.

Depending on the client's needs and the jurisdiction's requirements, the spectrum of the architect's services during construction stages may be extensive (detailed document preparation and construction review) or less involved (such as allowing a contractor to exercise considerable design-build functions).

Architects typically put projects to tender on behalf of their clients, advise on the award of the project to a general contractor, facilitate and then administer a contract of agreement which is often between the client and the contractor. This contract is legally binding and covers a very wide range of aspects including the insurances and commitments of all stakeholders, the status of the design documents, provisions for the architect's access, and procedures for the control of the works as they proceed. Depending on the type of contract utilized, provisions for further sub-contract tenders may be required. The architect may require that some elements are covered by a warranty which specifies the expected life and other aspects of the material, product or work.

In most jurisdictions, prior notification to the relevant local authority must be given before commencement on site, thus giving the local authority notice to carry out independent inspections. The architect will then review and inspect the progress of the work in coordination with the local authority.

The architect will typically review contractor shop drawings and other submittals, prepare and issue site instructions, and provide Certificates for Payment to the contractor (see also Design-bid-build) which is based on the work done to date as well as any materials and other goods purchased or hired. In the United Kingdom and other countries, a quantity surveyor is often part of the team to provide cost consulting. With very large, complex projects, an independent construction manager is sometimes hired to assist in design and to manage construction.

In many jurisdictions, mandatory certification or assurance of the completed work or part of works is required. This demand for certification entails a high degree of risk - therefore, regular inspections of the work as it progresses on site is required to ensure that is in compliance with the design itself as well as with all relevant statutes and permissions.

Recent decades have seen the rise of specializations within the profession. Many architects and architectural firms focus on certain project types (for example, healthcare, retail, public housing, event management), technological expertise or project delivery methods. Some architects specialize as building code, building envelope, sustainable design, technical writing, historic preservation(US) or conservation (UK), accessibility and other forms of specialist consultants.

Many architects elect to move into real estate (property) development, corporate facilities planning, project management, construction management, interior design, city planning, or other related fields.

Although there are variations from place to place, most of the world's architects are required to register with the appropriate jurisdiction. To do so, architects are typically required to meet three common requirements: education, experience, and examination.

Educational requirements generally consist of a university degree in architecture. The experience requirement for degree candidates is usually satisfied by a practicum or internship (usually two to three years, depending on jurisdiction). Finally, a Registration Examination or a series of exams is required prior to licensure.

Professionals engaged in the design and supervision of construction projects prior to the late 19th century were not necessarily trained in a separate architecture program in an academic setting. Instead, they often trained under established architects. Prior to modern times, there was no distinction between architects, engineers and often artists, and the title used varied depending on geographical location. They often carried the title of master builder or surveyor after serving a number of years as an apprentice (such as Sir Christopher Wren). The formal study of architecture in academic institutions played a pivotal role in the development of the profession as a whole, serving as a focal point for advances in architectural technology and theory.

According to the American Institute of Architects, titles and job descriptions within American architectural offices might be as follows:

Architects' fee structures are typically based on a percentage of construction value, as a rate per unit area of the proposed construction, hourly rates or a fixed lump sum fee. Combinations of these structures are also common. Fixed fees are usually based on a project's allocated construction cost and can range between 4 and 12% of new construction cost, for commercial and institutional projects, depending on a project's size and complexity. Residential projects range from 12 to 20%. Renovation projects typically command higher percentages, as high as 15-20%.

Overall billings for architectural firms range widely, depending on location and economic climate. Billings have traditionally been dependent on the local economic conditions but, with rapid globalization, this is becoming less of a factor for larger international firms. Salaries also vary, depending on experience, position within the firm (staff architect, partner, or shareholder, etc.), and the size and location of the firm.

A number of national professional organizations exist to promote career and business development in architecture.

The American Institute of Architects (AIA) USA

Royal Institute of British Architects (RIBA) UK

Architects Registration Board (ARB) UK

A wide variety of prizes is awarded by national professional associations and other bodies, recognizing accomplished architects, their buildings, structures, and professional careers.

The most lucrative award an architect can receive is the Pritzker Prize, sometimes termed the "Nobel Prize for architecture." Other prestigious architectural awards are the Royal Gold Medal, the AIA Gold Medal (USA), AIA Gold Medal (Australia), and the Praemium Imperiale.

Architects in the UK, who have made contributions to the profession through design excellence or architectural education, or have in some other way advanced the profession, might until 1971 be elected Fellows of the Royal Institute of British Architects and can write FRIBA after their name if they feel so inclined. Those elected to chartered membership of the RIBA after 1971 may use the initials RIBA but cannot use the old ARIBA and FRIBA. An Honorary Fellow may use the initials Hon. FRIBA. and an International Fellow may use the initials Int. FRIBA. Architects in the US, who have made contributions to the profession through design excellence or architectural education, or have in some other way advanced the profession, are elected Fellows of the American Institute of Architects and can write FAIA after their name. Architects in Canada, who have made outstanding contributions to the profession through contribution to research, scholarship, public service, or professional standing to the good of architecture in Canada, or elsewhere, may be recognized as a Fellow of the Royal Architectural Institute of Canada and can write FRAIC after their name. In Hong Kong, those elected to chartered membership may use the initial HKIA, and those who have made special contribution after nomination and election by The Hong Kong Institute of Architects (HKIA), may be elected as fellow members of HKIA and may use FHKIA after their name.

Architects in the Philippines and Filipino communities overseas (whether they are Filipinos or not), especially those who also profess other jobs at the same time, are addressed and introduced as "Architect", rather than "Sir/Madam" in speech or "Mr./Mrs./Ms." ("G./Gng./Bb." in Filipino) before surnames. That word is used either in itself or before the given name or surname.


</doc>
<doc id="1171" url="https://en.wikipedia.org/wiki?curid=1171" title="Abbreviation">
Abbreviation

An abbreviation (from Latin "brevis", meaning "short" ) is a shortened form of a word or phrase. It consists of a group of letters taken from the word or phrase. For example, the word "abbreviation" can itself be represented by the abbreviation "abbr.", "abbrv.", or "abbrev."

In strict analysis, abbreviations should not be confused with contractions, crasis, acronyms, or initialisms, with which they share some semantic and phonetic functions, though all four are connected by the term "abbreviation" in loose parlance.An abbreviation is a shortening by any method; a contraction is a reduction of size by the drawing together of the parts. A contraction of a word is made by omitting certain letters or syllables and bringing together the first and last letters or elements; an abbreviation may be made by omitting certain portions from the interior or by cutting off a part. A contraction is an abbreviation, but an abbreviation is not necessarily a contraction. Acronyms and initialisms are regarded as subsets of abbreviations (e.g. by the Council of Science Editors). They are abbreviations that consist of the initial letters or parts of words.

Abbreviations have a long history, created so that spelling out a whole word could be avoided. This might be done to save time and space, and also to provide secrecy. Shortened words were used and initial letters were commonly used to represent words in specific applications. In classical Greece and Rome, the reduction of words to single letters was common. In Roman inscriptions, "Words were commonly abbreviated by using the initial letter or letters of words, and most inscriptions have at least one abbreviation." However, "some could have more than one meaning, depending on their context. (For example, "A" can be an abbreviation for many words, such as "ager", "amicus", "annus", "as", "Aulus", "Aurelius", "aurum" and "avus".)"

Abbreviations in English were frequently used from its earliest days. Manuscripts of copies of the old English poem "Beowulf" used many abbreviations, for example "7" or "&" for "and", and "y" for "since", so that "not much space is wasted". The standardisation of English in the 15th through 17th centuries included such a growth in the use of abbreviations. At first, abbreviations were sometimes represented with various suspension signs, not only periods. For example, sequences like ‹er› were replaced with ‹ɔ›, as in ‹mastɔ› for "master" and ‹exacɔbate› for "exacerbate". While this may seem trivial, it was symptomatic of an attempt by people manually reproducing academic texts to reduce the copy time. An example from the Oxford University Register, 1503:

The Early Modern English period, between the 15th and 17th centuries, had abbreviations like "y" for "Þ", used for the word "the": "hence, by later misunderstanding, Ye Olde Tea Shoppe."

During the growth of philological linguistic theory in academic Britain, abbreviating became very fashionable. The use of abbreviation for the names of J. R. R. Tolkien and his friend C. S. Lewis, and other members of the Oxford literary group known as the Inklings, are sometimes cited as symptomatic of this. Likewise, a century earlier in Boston, a fad of abbreviation started that swept the United States, with the globally popular term OK generally credited as a remnant of its influence.

After World War II, the British greatly reduced the use of the full stop and other punctuation points after abbreviations in at least semi-formal writing, while the Americans more readily kept such use until more recently, and still maintain it more than Britons. The classic example, considered by their American counterparts quite curious, was the maintenance of the internal comma in a British organisation of secret agents called the "Special Operations, Executive"—"S.O., E"—which is not found in histories written after about 1960.

But before that, many Britons were more scrupulous at maintaining the French form. In French, the period only follows an abbreviation if the last letter in the abbreviation is "not" the last letter of its antecedent: "M." is the abbreviation for "monsieur" while "Mme" is that for "madame". Like many other cross-channel linguistic acquisitions, many Britons readily took this up and followed this rule themselves, while the Americans took a simpler rule and applied it rigorously.

Over the years, however, the lack of convention in some style guides has made it difficult to determine which two-word abbreviations should be abbreviated with periods and which should not. The U.S. media tend to use periods in two-word abbreviations like United States (U.S.), but not personal computer (PC) or television (TV). Many British publications have gradually done away with the use of periods in abbreviations.

Minimization of punctuation in typewritten material became economically desirable in the 1960s and 1970s for the many users of carbon-film ribbons since a period or comma consumed the same length of non-reusable expensive ribbon as did a capital letter.

Widespread use of electronic communication through mobile phones and the Internet during the 1990s allowed for a marked rise in colloquial abbreviation. This was due largely to increasing popularity of textual communication services such as instant- and text messaging. SMS, for instance, supports message lengths of 160 characters at most (using the GSM 03.38 character set). This brevity gave rise to an informal abbreviation scheme sometimes called Textese, with which 10% or more of the words in a typical SMS message are abbreviated. More recently Twitter, a popular social networking service, began driving abbreviation use with 140 character message limits.

In modern English, there are several conventions for abbreviations, and the choice may be confusing. The only rule universally accepted is that one should be "consistent", and to make this easier, publishers express their preferences in a style guide. Questions which arise include those in the following subsections.

If the original word was capitalized then the first letter of its abbreviation should retain the capital, for example Lev. for "Leviticus". When a word is abbreviated to more than a single letter and was originally spelled with lower case letters then there is no need for capitalization. However, when abbreviating a phrase where only the first letter of each word is taken, then all letters should be capitalized, as in YTD for "year-to-date", PCB for "printed circuit board" and FYI for "for your information". However, see the following section regarding abbreviations that have become common vocabulary: these are no longer written with capital letters.

A period (full stop) is often used to signify an abbreviation, but opinion is divided as to when and if this should happen.

According to Hart's Rules, the traditional rule is that abbreviations (in the narrow sense that includes only words with the ending, and not the middle, dropped) terminate with a full stop, whereas contractions (in the sense of words missing a middle part) do not, but there are exceptions. Fowler's Modern English Usage says full stops are used to mark both abbreviations and contractions, but recommends against this practice: advising them only for abbreviations and lower-case initialisms and not for upper-case initialisms and contractions.

In American English, the period is usually included regardless of whether or not it is a contraction, e.g. "Dr." or "Mrs.". In some cases, periods are optional, as in either "US" or "U.S." for "United States", "EU" or "E.U." for "European Union", and "UN" or "U.N." for "United Nations". There are some house styles, however—American ones included—that remove the periods from almost all abbreviations. For example:

Acronyms that were originally capitalized (with or without periods) but have since entered the vocabulary as generic words are no longer written with capital letters nor with any periods. Examples are sonar, radar, lidar, laser, snafu, and scuba.

Today, spaces are generally not used between single-letter abbreviations of words in the same phrase, so one almost never encounters "U. S."

When an abbreviation appears at the end of a sentence, only one period is used: "The capital of the United States is Washington, D.C".

There is a question about how to pluralize abbreviations, particularly acronyms. Often a writer will add an 's' following an apostrophe, as in "PC's". However, this style is not preferred by many style guides. For instance, Kate Turabian, writing about style in academic writings, allows for an apostrophe to form plural acronyms "only when an abbreviation contains internal periods or both capital and lowercase letters". Turabian would therefore prefer "DVDs" and "URLs" and "Ph.D.'s", while the Modern Language Association explicitly says, "do not use an apostrophe to form the plural of an abbreviation". Also, the American Psychological Association specifically says, "without an apostrophe".

However, the 1999 style guide for the "New York Times" states that the addition of an apostrophe is necessary when pluralizing all abbreviations, preferring "PC's, TV's and VCR's".

Following those who would generally omit the apostrophe, to form the plural of run batted in, simply add an s to the end of RBI.


For all other rules, see below:

To form the plural of an abbreviation, a number, or a capital letter used as a noun, simply add a lowercase "s" to the end. Apostrophes following decades and single letters are also common.

To indicate the plural of the abbreviation or symbol of a unit of measure, the same form is used as in the singular.

When an abbreviation contains more than one full point, "Hart's Rules" recommends putting the "s" after the final one.
However, subject to any house style or consistency requirement, the same plurals may be rendered less formally as:

According to "Hart's Rules", an apostrophe may be used in rare cases where clarity calls for it, for example when letters or symbols are referred to as objects.
However, the apostrophe can be dispensed with if the items are set in italics or quotes:

In Latin, and continuing to the derivative forms in European languages as well as English, single-letter abbreviations had the plural being a doubling of the letter for note-taking. Most of these deal with writing and publishing. A few longer abbreviations use this as well.

Publications based in the U.S. tend to follow the style guides of "The Chicago Manual of Style" and the Associated Press. The U.S. Government follows a style guide published by the U.S. Government Printing Office. The National Institute of Standards and Technology sets the style for abbreviations of units.

Many British publications follow some of these guidelines in abbreviation:


Writers often use shorthand to denote units of measure. Such shorthand can be an abbreviation, such as "in" for "inch" or can be a symbol such as "km" for "kilometre/kilometer".

The shorthand "in" applies to English only—in Afrikaans for example, the shorthand "dm" is used for the equivalent Afrikaans word "duim". Since both "in" and "dm" are contractions of the same word, but in different languages, they are abbreviations. A symbol on the other hand, defined as "Mark or character taken as the conventional sign of some object or idea or process" applies the appropriate shorthand by "substitution" rather than by "contraction". Since the shorthand for kilometre/kilometer ("" in Portuguese or "" in Greek) is "km" in both languages and the letter "k" does not appear in the expansion of either translation, "km" is a symbol as it is a substitution rather than a contraction. It is a logogram rather than an abbreviation.

In the International System of Units (SI) manual the word "symbol" is used consistently to define the shorthand used to represent the various SI units of measure. The manual also defines the way in which units should be written, the principal rules being:

A syllabic abbreviation is usually formed from the initial syllables of several words, such as "Interpol" = International" + police". It is a variant of the acronym. Syllabic abbreviations are usually written using lower case, sometimes starting with a capital letter, and are always pronounced as words rather than letter by letter. Syllabic abbreviations should be distinguished from portmanteaus, which combine two words without necessarily taking whole syllables from each.

Syllabic abbreviations are not widely used in English. Some UK government ministries such as Ofcom (Office of Communications") and Oftel (Office of Telecommunications") use this style.

New York City has various neighborhoods named by syllabic abbreviation, such as Tribeca (Triangle below Canal Street") and SoHo (South of Houston Street"). This usage has spread into other American cities, giving SoMa, San Francisco (South of Market") and LoDo, Denver (Lower Downtown"), among others. New Orleans, Louisiana is often abbreviated as NOLA, while Northern Virginia is known as NOVA.

On the other hand, syllabic abbreviations prevailed both in Germany under the Nazis and in the Soviet Union for naming the plethora of new bureaucratic organisations. For example, "Gestapo" stands for Geheime Staats-Polizei", or "secret state police". Similarly, Leninist organisations such as the "Comintern" ("Communist International") and "Komsomol" (Kommunisticheskii Soyuz Molodyozhi", or "Communist youth union") used Russian language syllabic abbreviations. This has given syllabic abbreviations negative connotations in some countries, (as in Orwell's Newspeak), notwithstanding that such abbreviations were used in Germany even before the Nazis came to power, e.g., "" for "Schutzpolizei", and are still used, e.g. "" for "".

In the modern Russian language words like "Minoborony" (from Ministerstvo oborony — Ministry of Defence) and "Minobrnauki" (from Ministerstvo obrazovaniya i nauki — Ministry of Education and Science) are still commonly used.

Syllabic abbreviations were also typical for the German language used in the German Democratic Republic, e.g. "Stasi" for Staatssicherheit" ("state security", the secret police) or "Vopo" for "Volkspolizist" ("people's policeman"). Other uses are in company or product names such as Aldi, from the name of the founder, Theo Albrecht, and the German word Diskont" (discount) or Haribo, from the name of the founder and the headquarters of the company, Hans Riegl Bonn.

Syllabic abbreviations are "de rigueur" in Spanish; examples abound in organization names such as Pemex for Petróleos Mexicanos" ("Mexican Petroleums") or Fonafifo for Fondo Nacional de Financimiento Forestal" (National Forestry Financing Fund).

East Asian languages whose writing systems use Chinese characters form abbreviations similarly by using key Chinese characters from a term or phrase. For example, in Japanese the term for the United Nations, "kokusai rengō" (国際連合) is often abbreviated to "kokuren" (国連). (Such abbreviations are called (略語) in Japanese; see also Japanese abbreviated and contracted words). The syllabic abbreviation is frequently used for universities: for instance, "Běidà" (北大) for "Běijīng Dàxué" (北京大学, Peking University) and "Tōdai" (東大) for "Tōkyō daigaku" (東京大学, University of Tokyo). The English phrase "Gung ho" originated as a Chinese abbreviation.

Partially syllabic abbreviations are preferred by the US Navy, as it increases readability amidst the large number of initialisms that would otherwise have to fit into the same acronyms. Hence "DESRON 6" is used (in the full capital form) to mean "Destroyer Squadron 6", while "COMNAVAIRLANT" would be "Commander, Naval Air Force (in the) Atlantic."



</doc>
<doc id="1174" url="https://en.wikipedia.org/wiki?curid=1174" title="Aphrodite">
Aphrodite

Aphrodite ( ; "Aphrodítē") is the ancient Greek goddess of love, beauty, pleasure, and procreation. She is identified with the planet Venus, which is named after the Roman goddess , with whom Aphrodite was extensively syncretized. Aphrodite's major symbols include myrtles, roses, doves, sparrows, and swans.

The cult of Aphrodite was largely derived from that of the Phoenician goddess Astarte, a cognate of the East Semitic goddess Ishtar, whose cult was based on the Sumerian cult of Inanna. Aphrodite's main cult centers were Cythera, Cyprus, Corinth, and Athens. Her main festival was the Aphrodisia, which was celebrated annually in midsummer. In Laconia, Aphrodite was worshipped as a warrior goddess. She was also the patron goddess of prostitutes, an association which led early scholars to propose the concept of "sacred prostitution", an idea which is now generally seen as erroneous.

In Hesiod's "Theogony", Aphrodite is born off the coast of Cythera from the foam ("aphros") produced by Uranus's genitals, which his son Cronus has severed and thrown into the sea. In Homer's "Iliad", however, she is the daughter of Zeus and Dione. Plato, in his "Symposium" 180e, asserts that these two origins actually belong to separate entities: Aphrodite Ourania (a transcendent, "Heavenly" Aphrodite) and Aphrodite Pandemos (Aphrodite common to "all the people"). Aphrodite had many other epithets, each emphasizing a different aspect of the same goddess, or used by a different local cult. Thus she was also known as Cytherea ("Lady of Cythera") and Cypris ("Lady of Cyprus"), due to the fact that both locations claimed to be the place of her birth.

In Greek mythology, Aphrodite was married to Hephaestus, the god of blacksmiths and metalworking. Despite this, Aphrodite was frequently unfaithful to him and had many lovers; in the "Odyssey", she is caught in the act of adultery with Ares, the god of war. In the "First Homeric Hymn to Aphrodite", she seduces the mortal shepherd Anchises. Aphrodite was also the surrogate mother and lover of the mortal shepherd Adonis, who was killed by a wild boar. Along with Athena and Hera, Aphrodite was one of the three goddesses whose feud resulted in the beginning of the Trojan War and she plays a major role throughout the "Iliad". Aphrodite has been featured in western art as a symbol of female beauty and has appeared in numerous works of western literature. She is a major deity in modern Neopagan religions, including the Church of Aphrodite, Wicca, and Hellenismos.

Hesiod derives "Aphrodite" from "aphrós" (ἀφρός) "sea-foam", interpreting the name as "risen from the foam", but most modern scholars regard this as a spurious folk etymology. Early modern scholars of classical mythology attempted to argue that Aphrodite's name was of Greek or Indo-European origin, but these efforts have now been mostly abandoned. Aphrodite's name is generally accepted to be of non-Greek, probably Semitic, origin, but its exact derivation cannot be determined.

Scholars in the late nineteenth and early twentieth centuries, accepting Hesiod's "foam" etymology as genuine, analyzed the second part of Aphrodite's name as *"-odítē" "wanderer" or *"-dítē" "bright". Michael Janda, also accepting Hesiod's etymology, has argued in favor of the latter of these interpretations and claims the story of a birth from the foam as an Indo-European mytheme. Likewise, Witczak proposes an Indo-European compound ' "very" and ' "to shine", also referring to Eos. Other scholars have argued that these hypotheses are unlikely since Aphrodite's attributes are entirely different from those of both Eos and the Vedic deity Ushas.

A number of improbable non-Greek etymologies have also been suggested. One Semitic etymology compares Aphrodite to the Assyrian "barīrītu", the name of a female demon that appears in Middle Babylonian and Late Babylonian texts. Hammarström looks to Etruscan, comparing "(e)prϑni" "lord", an Etruscan honorific loaned into Greek as πρύτανις. This would make the theonym in origin an honorific, "the lady". Most scholars reject this etymology as implausible, especially since Aphrodite actually appears in Etruscan in the borrowed form "Apru" (from Greek "Aphrō", clipped form of "Aphrodite").

The medieval "Etymologicum Magnum" (c. 1150) offers a highly contrived etymology, deriving "Aphrodite" from the compound "habrodíaitos" (), "she who lives delicately", from "habrós" and "díaita". The alteration from "b" to "ph" is explained as a "familiar" characteristic of Greek "obvious from the Macedonians".

The cult of Aphrodite in Greece was imported from, or at least influenced by, the cult of Astarte in Phoenicia, which, in turn, was influenced by the cult of the Mesopotamian goddess known as "Ishtar" to the East Semitic peoples and as "Inanna" to the Sumerians. Pausanias states that the first to establish a cult of Aphrodite were the Assyrians, after the Assyrians, the Paphians of Cyprus, and then the Phoenicians at Ascalon. The Phoenicians, in turn, taught her worship to the people of Cythera.

Aphrodite took on Inanna-Ishtar's associations with sexuality and procreation. Furthermore, she was known as Ourania (Οὐρανία), which means "heavenly", a title corresponding to Inanna's role as the Queen of Heaven. Early artistic and literary portrayals of Aphrodite are extremely similar on Inanna-Ishtar. Like Inanna-Ishtar, Aphrodite was also a warrior goddess; the second-century AD Greek geographer Pausanias records that, in Sparta, Aphrodite was worshipped as "Aphrodite Areia", which means "warlike". He also mentions that Aphrodite's most ancient cult statues in Sparta and on Cythera showed her bearing arms. Modern scholars note that Aphrodite's warrior-goddess aspects appear in the oldest strata of her worship and see it as an indication of her Near Eastern origins.

Nineteenth century classical scholars had a general aversion to the idea that ancient Greek religion was at all influenced by the cultures of the Near East, but, even Friedrich Gottlieb Welcker, who argued that Near Eastern influence on Greek culture was largely confined to material culture, admitted that Aphrodite was clearly of Phoenician origin. The significant influence of Near Eastern culture on early Greek religion in general, and on the cult of Aphrodite in particular, is now widely recognized as dating to a period of orientalization during the eighth century BC, when archaic Greece was on the fringes of the Neo-Assyrian Empire.

Some early comparative mythologists opposed to the idea of a Near Eastern origin argued that Aphrodite originated as an aspect of the Greek dawn goddess Eos and that she was therefore ultimately derived from the Proto-Indo-European dawn goddess *"Héusōs" (properly Greek Eos, Latin Aurora, Sanskrit Ushas). Most modern scholars have now rejected the notion of a purely Indo-European Aphrodite, but it is possible that Aphrodite, originally a Semitic deity, may have been influenced by the Indo-European dawn goddess. Both Aphrodite and Eos were known for their erotic beauty and aggressive sexuality and both had relationships with mortal lovers. Both goddesses were associated with the colors red, white, and gold. Michael Janda etymologizes Aphrodite's name as an epithet of Eos meaning "she who rises from the foam [of the ocean]" and points to Hesiod's "Theogony" account of Aphrodite's birth as an archaic reflex of Indo-European myth. Aphrodite rising out of the waters after Cronus defeats Uranus as a mytheme would then be directly cognate to the Rigvedic myth of Indra defeating Vrtra, liberating Ushas. Another key similarity between Aphrodite and the Indo-European dawn goddess is her close kinship to the Greek sky deity, since both of the main claimants to her paternity (Zeus and Uranus) are sky deities.

Aphrodite's most common cultic epithet was "Ourania", meaning "heavenly", but this epithet almost never occurs in literary texts, indicating a purely cultic significance. Another common name for Aphrodite was "Pandemos" ("For All the Folk"). In her role as Aphrodite Pandemos, Aphrodite was associated with "Peithō" (Πείθω), meaning "persuasion", and could be prayed to for aid in seduction. Plato, in his "Symposium", argues that "Aphrodite Ourania" and "Aphrodite Pandemos" are, in fact, separate goddesses. He asserts that "Aphrodite Ourania" is the celestial Aphrodite, born from the sea foam after Cronus castrated Uranus, and the older of the two goddesses. According to the "Symposium", Aphrodite Ourania is the inspiration of male homosexual desire, specifically the ephebic eros. "Aphrodite Pandemos", by contrast, is the younger of the two goddesses: the common Aphrodite, born from the union of Zeus and Dione, and the inspiration of heterosexual desire, the "lesser" of the two loves.

Among the Neoplatonists and, later, their Christian interpreters, Aphrodite Ourania is associated with spiritual love, and Aphrodite Pandemos with physical love (desire). A representation of Aphrodite Ourania with her foot resting on a tortoise came to be seen as emblematic of discretion in conjugal love; it was the subject of a chryselephantine sculpture by Phidias for Elis, known only from a parenthetical comment by the geographer Pausanias.

One of Aphrodite's most common literary epithets is "Philommeidḗs" (φιλομμειδής), which means "smile-loving", but is sometimes mistranslated as "laughter-loving". This epithet occurs throughout both of the Homeric epics and the "First Homeric Hymn to Aphrodite". Hesiod references it once in his "Theogony" in the context of Aphrodite's birth, but interprets it as "genital-loving" rather than "smile-loving". Monica Cyrino notes that the epithet may relate to the fact that, in many artistic depictions of Aphrodite, she is shown smiling. Other common literary epithets are "Cypris" and "Cythereia", which derive from her associations with the islands of Cyprus and Cythera respectively.

On Cyprus, Aphrodite was sometimes called "Eleemon" ("the merciful"). In Athens, she was known as "Aphrodite en kopois" ("Aphrodite of the Gardens"). At Cape Colias, a town along the Attic coast, she was venerated as "Genetyllis" ("the mother"). The Spartans worshipped her as "Potnia" ("the Mistress"), "Enoplios" ("the armed"), "Morpho" ("the shapely"), "Ambologera" ("she who postpones old age"). Across the Greek world, she was known under epithets such as "Melainis" ("the Black One"), "Skotia" ("the Dark One"), "Androphonos" ("the Killer of Men"), "Anosia" ("the Unholy"), and "Tymborychos" ("the gravedigger"), all of which indicate her darker, more violent nature.

A male version of Aphrodite known as Aphroditus was worshipped in the city of Amathus on Cyprus. Aphroditus was depicted with the figure and dress of a woman, but had a full beard, and was shown lifting his dress to reveal an erect phallus. This gesture was believed to be an apotropaic symbol, and was thought to convey good fortune upon the viewer. Eventually, the popularity of Aphroditus waned as the mainstream, fully feminine version of Aphrodite became more popular, but traces of his cult are preserved in the later legends of Hermaphroditus.

Aphrodite's main festival, the Aphrodisia, was celebrated across Greece, but particularly in Athens and Corinth. In Athens, the Aphrodisia was celebrated on the fourth day of the month of Hekatombaion in honor of Aphrodite's role in the unification of Attica. During this festival, the priests of Aphrodite would purify the temple of Aphrodite Pandemos on the southwestern slope of the Acropolis with the blood of a sacrificed dove. Next, the altars would be anointed and the cult statues of Aphrodite Pandemos and Peitho would be escorted in a majestic procession to a place where they would be ritually bathed. Aphrodite was also honored in Athens as part of the Arrhephoria festival. The fourth day of every month was sacred to Aphrodite.

Pausanias records that, in Sparta, Aphrodite was worshipped as "Aphrodite Areia", which means "warlike". This epithet stresses Aphrodite's connections to Ares, with whom she had extramarital relations. Pausanias also records that, in Sparta and on Cythera, a number of extremely ancient cult statues of Aphrodite portrayed her bearing arms. Other cult statues showed her bound in chains.

Aphrodite was the patron goddess of prostitutes of all varieties, ranging from "pornai" (cheap street prostitutes typically owned as slaves by wealthy pimps) to "hetairai" (expensive, well-educated hired companions, who were usually self-employed and sometimes provided sex to their customers). The city of Corinth was renowned throughout the ancient world for its many "hetairai", who had a widespread reputation for being among the most skilled, but also the most expensive, prostitutes in the Greek world. Corinth also had a major temple to Aphrodite located on the Acrocorinth and was one of the main centers of her cult. Records of numerous dedications to Aphrodite made by successful courtesans have survived in poems and in pottery inscriptions. References to Aphrodite in association with prostitution are found in Corinth as well as on the islands of Cyprus, Cythera, and Sicily. Aphrodite's Mesopotamian precursor Inanna-Ishtar was also closely associated with prostitution.

Scholars in the nineteenth and twentieth centuries believed that the cult of Aphrodite may have involved ritual prostitution, an assumption based on ambiguous passages in certain ancient texts, particularly a fragment of a "skolion" by the Boeotian poet Pindar, which mentions prostitutes in Corinth in association with Aphrodite. Modern scholars now dismiss the notion of ritual prostitution in Greece as a "historiographic myth" with no factual basis.

During the Hellenistic Period, the Greeks identified Aphrodite with the ancient Egyptian goddesses Hathor and Isis. Aphrodite was the patron goddess of the Lagid queens and Queen Arsinoe II was identified as her mortal incarnation. Aphrodite was worshipped in Alexandria and had numerous temples in and around the city. Arsinoe II introduced the cult of Adonis to Alexandria and many of the women there partook in it. The Tessarakonteres, a gigantic catamaran galley designed by Archimedes for Ptolemy IV Philopator, had a circular temple to Aphrodite on it with a marble statue of the goddess herself. In the second century BC, Ptolemy VIII Physcon and his wives Cleopatra II and Cleopatra III dedicated a temple to Aphrodite Hathor at Philae. Statuettes of Aphrodite for personal devotion became common in Egypt starting in the early Ptolemaic times and extending until long after Egypt became a Roman province.

The ancient Romans identified Aphrodite with their goddess Venus, who was originally a goddess of agricultural fertility, vegetation, and springtime. According to the Roman historian Livy, Aphrodite and Venus were officially identified in the third century BC when the cult of "Venus Erycina" was introduced to Rome from the Greek sanctuary of Aphrodite on Mount Eryx in Sicily. After this point, Romans adopted Aphrodite's iconography and myths and applied them to Venus. Because Aphrodite was the mother of the Trojan hero Aeneas in Greek mythology and Roman tradition claimed Aeneas as the founder of Rome, Venus became venerated as "Venus Genetrix", the mother of the entire Roman nation. Julius Caesar claimed to be directly descended from Aeneas's son Iulus and became a strong proponent of the cult of Venus. This precedent was later followed by his nephew Augustus and the later emperors claiming succession from him.

This syncretism greatly impacted Greek worship of Aphrodite. During the Roman era, the cults of Aphrodite in many Greek cities began to emphasize her relationship with Troy and Aeneas. They also began to adopt distinctively Roman elements, portraying Aphrodite as more maternal, more militaristic, and more concerned with administrative bureaucracy. She was claimed as a divine guardian by many political magistrates. Appearances of Aphrodite in Greek literature also vastly proliferated, usually showing Aphrodite in a characteristically Roman manner.

Aphrodite is usually said to have been born near her chief center of worship, Paphos, on the island of Cyprus, which is why she is sometimes called "Cyprian", especially in the poetic works of Sappho. However, other versions of her myth have her born near the island of Cythera, hence another of her names, "Cytherea". Cythera was a stopping place for trade and culture between Crete and the Peloponesus, so these stories may preserve traces of the migration of Aphrodite's cult from the Middle East to mainland Greece.

According to the version of her birth recounted by Hesiod in his "Theogony", Cronus severed Uranus' genitals and threw them behind him into the sea. The foam from his genitals gave rise to Aphrodite (hence her name, which Hesiod interprets as "foam-arisen"), while the Giants, the Erinyes (furies), and the Meliae emerged from the drops of his blood. Hesiod states that the genitals "were carried over the sea a long time, and white foam arose from the immortal flesh; with it a girl grew." Hesiod's account of Aphrodite's birth following Uranus's castration is probably derived from "The Song of Kumarbi", an ancient Hittite epic poem in which the god Kumarbi overthrows his father Anu, the god of the sky, and bites off his genitals, causing him to become pregnant and give birth to Anu's children, which include Ishtar and her brother Teshub, the Hittite storm god.

In the "Iliad", Aphrodite is described as the daughter of Zeus and Dione. Dione's name appears to be a feminine cognate to "Dios" and "Dion", which are oblique forms of the name "Zeus". Zeus and Dione shared a cult at Dodona in northwestern Greece. In "Theogony", Hesiod describes Dione as an Oceanid.

Aphrodite is consistently portrayed as a nubile, infinitely desirable adult, having had no childhood. She is often depicted nude. In the "Iliad", Aphrodite is the apparently unmarried consort of Ares, the god of war, and the wife of Hephaestus is a different goddess named Charis. Likewise, in Hesiod's "Theogony", Aphrodite is unmarried and the wife of Hephaestus is Aglaea, the youngest of the three Charites.

In Book Eight of the "Odyssey", however, the blind singer Demodocus describes Aphrodite as the wife of Hephaestus and tells how she committed adultery with Ares during the Trojan War. The sun-god Helios saw Aphrodite and Ares having sex in Hephaestus's bed and warned Hephaestus, who fashioned a net of gold. The next time Ares and Aphrodite had sex together, the net trapped them both. Hephaestus brought all the gods into the bedchamber to laugh at the captured adulterers, but Apollo, Hermes, and Poseidon had sympathy for Ares and Poseidon agreed to pay Hephaestus for Ares's release. Humiliated, Aphrodite returned to Cyprus, where she was attended by the Charites. This narrative probably originated as a Greek folk tale, originally independent of the "Odyssey".

Later stories were invented to explain Aphrodite's marriage to Hephaestus. In the most famous story, Zeus hastily married Aphrodite to Hephaestus in order to prevent the other gods from fighting over her. In another version of the myth, Hephaestus gave his mother Hera a golden throne, but, when she sat on it, she became trapped and he refused to let her go until she agreed to give him Aphrodite's hand in marriage. Hephaestus was overjoyed to be married to the goddess of beauty, and forged her beautiful jewelry, including a "strophion" known as the "kestos imas", a saltire-shaped undergarment (usually translated as "girdle"), which accentuated her breasts and made her even more irresistible to men. Such "strophia" were commonly used in depictions of the Near Eastern goddesses Ishtar and Atargatis.

Aphrodite is almost always accompanied by Eros, the god of lust and sexual desire. In his "Theogony", Hesiod describes Eros as one of the four original primeval forces born at the beginning of time, but, after the birth of Aphrodite from the sea foam, he is joined by Himeros and, together, they become Aphrodite's constant companions. In early Greek art, Eros and Himeros are both shown as idealized handsome youths with wings. The Greek lyric poets regarded the power of Eros and Himeros as dangerous, compulsive, and impossible for anyone to resist. In modern times, Eros is often seen as Aphrodite's son, but this is actually a comparatively late innovation. A "scholion" on Theocritus's "Idylls" remarks that the sixth-century BC poetess Sappho had described Eros as the son of Aphrodite and Uranus, but the first surviving reference to Eros as Aphrodite's son comes from Apollonius of Rhodes's "Argonautica", written in the third century BC, which makes him the son of Aphrodite and Ares. Later, the Romans, who saw Venus as a mother goddess, seized on this idea of Eros as Aphrodite's son and popularized it, making it the predominant portrayal in works on mythology until the present day.

Aphrodite's main attendants were the three Charites, whom Hesiod identifies as the daughters of Zeus and Eurynome and names as Aglaea ("Splendor"), Euphrosyne ("Good Cheer"), and Thalia ("Abundance"). The Charites had been worshipped as goddesses in Greece since the beginning of Greek history, long before Aphrodite was introduced to the pantheon. Aphrodite's other set of attendants was the three Horae (the "Hours"), whom Hesiod identifies as the daughters of Zeus and Themis and names as Eunomia ("Good Order"), Dike ("Justice"), and Eirene ("Peace"). Aphrodite was also sometimes accompanied by Harmonia, her own daughter by Ares, and Hebe, the daughter of Zeus and Hera.

The fertility god Priapus was usually considered to be Aphrodite's son by Dionysus, but he was sometimes also described as her son by Hermes, Adonis, or even Zeus. A "scholion" on Apollonius of Rhodes's "Argonautica" states that, while Aphrodite was pregnant with Priapus, Hera envied her and applied an evil potion to her belly while she was sleeping to ensure that the child would be hideous. When Aphrodite gave birth, she was horrified to see that the child had a massive, permanently erect penis, a potbelly, and a huge tongue. Aphrodite abandoned the infant to die in the wilderness, but a herdsman found him and raised him, later discovering that Priapus could use his massive penis to aid in the growth of plants.

The "First Homeric Hymn to Aphrodite" (Hymn 5), which was probably composed sometime in the mid-seventh century BC, describes how Zeus once became annoyed with Aphrodite for causing deities to fall in love with mortals, so he caused her to fall in love with Anchises, a handsome mortal shepherd who lived in the foothills beneath Mount Ida near the city of Troy. Aphrodite appears to Anchises in the form of a tall, beautiful, mortal virgin while he is alone in his home. Anchises sees her dressed in bright clothing and gleaming jewelry, with her breasts shining with divine radiance. He asks her if she is Aphrodite and promises to build her an altar on top of the mountain if she will bless him and his family.

Aphrodite, however, lies and tells him that she not a goddess, but the daughter of one of the noble families of Phrygia. She claims to be able to understand the Trojan language because she had a Trojan nurse as a child and says that she found herself on the mountainside after she was snatched up by Hermes while dancing in a celebration in honor of Artemis, the goddess of virginity. Aphrodite tells Anchises that she is still a virgin and begs him to take her to his parents. Anchises immediately becomes overcome with mad lust for Aphrodite and swears that he will have sex with her. Anchises takes Aphrodite, with her eyes cast downwards, to his bed, which is covered in the furs of lions and bears. He then strips her naked and makes love to her.

After the lovemaking is complete, Aphrodite reveals her true divine form. Anchises is terrified, but Aphrodite consoles him and promises that she will bear him a son. She prophecizes that their son will be the demigod Aeneas, who will be raised by the nymphs of the wilderness for five years before going to Troy to become a nobleman like his father. The story of Aeneas's conception is also mentioned in Hesiod's "Theogony" and in Book II of Homer's "Iliad".

The myth of Aphrodite and Adonis is probably derived from the ancient Sumerian legend of Inanna and Dumuzid. The Greek name ("Adōnis", ) is derived from the Canaanite word "ʼadōn", meaning "lord". The earliest known Greek reference to Adonis comes from a fragment of a poem by the Lesbian poetess Sappho, dating to the seventh century BC, in which a chorus of young girls asks Aphrodite what they can do to mourn Adonis's death. Aphrodite replies that they must beat their breasts and tear their tunics. Later references flesh out the story with more details: Adonis was the son of Myrrha, who was cursed by Aphrodite with insatiable lust for her own father, King Cinyras of Cyprus, after Myrrha's mother bragged that her daughter was more beautiful than the goddess. Driven out after becoming pregnant, Myrrha was changed into a myrrh tree, but still gave birth to Adonis.

Aphrodite found the baby, and took him to the underworld to be fostered by Persephone. She returned for him once he was grown and discovered him to be strikingly handsome. Persephone wanted to keep Adonis, resulting in a custody battle between the two goddesses over which of them Adonis rightly belonged to. Zeus settled the dispute by decreeing that Adonis would spend one third of the year with Aphrodite, one third with Persephone, and one third with whomever he chose. Adonis chose Aphrodite, and they remained constantly together. Then, one day while Adonis was out hunting, he was wounded by a wild boar, and bled to death in Aphrodite's arms. In different versions of the story, the boar was either sent by Ares, who was jealous that Aphrodite was spending so much time with Adonis, or by Artemis, who wanted revenge against Aphrodite for having killed her devoted follower Hippolytus. The story also provides an etiology for Aphrodite's associations with certain flowers. Reportedly, as she mourned Adonis's death, she caused anemones to grow wherever his blood fell, and declared a festival on the anniversary of his death. In one version of the story, Aphrodite injured herself on a thorn from a rose bush and the rose, which had previously been white, was stained red by her blood. According to Lucian's "De Dea Syria", each year during the festival of Adonis, the Adonis River in Lebanon (now known as the Abraham River) ran red with blood.

The myth of Adonis is associated with the festival of the Adonia, which was celebrated by Greek women every year in midsummer. The festival, which was evidently already celebrated in Lesbos by Sappho's time, seems to have first become popular in Athens in the mid-fifth century BC. At the start of the festival, the women would plant a "garden of Adonis", a small garden planted inside a small basket or a shallow piece of broken pottery containing a variety of quick-growing plants, such as lettuce and fennel, or even quick-sprouting grains such as wheat and barley. The women would then climb ladders to the roofs of their houses, where they would place the gardens out under the heat of the summer sun. The plants would sprout in the sunlight, but wither quickly in the heat. Then the women would mourn and lament loudly over the death of Adonis, tearing their clothes and beating their breasts in a public display of grief.

In Hesiod's "Works and Days", Zeus orders Aphrodite to make Pandora, the first woman, physically beautiful and sexually attractive, so that she may become "an evil men will love to embrace". Aphrodite "spills grace" over Pandora's head and equips her with "painful desire and knee-weakening anguish", thus making her the perfect vessel for evil to enter the world. Aphrodite's attendants, Peitho, the Charites, and the Horae, adorn Pandora with gold and jewelry.

According to one myth, Aphrodite aided Hippomenes, a noble youth who wished to marry Atalanta, a maiden who was renowned throughout the land for her beauty, but who refused to marry any man unless he could outrun her in a footrace. Atalanta was an exceedingly swift runner and she beheaded all of the men who lost to her. Aphrodite gave Hippomenes three golden apples from the Garden of the Hesperides and instructed him to toss them in front of Atalanta as he raced her. Hippomenes obeyed Aphrodite's order and Atalanta, seeing the beautiful, golden fruits, bent down to pick up each one, allowing Hippomenes to outrun her. In the version of the story from Ovid's "Metamorphoses", Hippomenes forgets to repay Aphrodite for her aid, so she causes the couple to become inflamed with lust while they are staying at the temple of Cybele. The couple desecrate the temple by having sex in it, leading Cybele to turn them into lions as punishment.

The myth of Pygmalion is first mentioned by the third-century BC Greek writer Philostephanus of Cyrene, but is first recounted in detail in Ovid's "Metamorphoses". According to Ovid, Pygmalion was an exceedingly handsome sculptor from the island of Cyprus, who was so sickened by the immorality of women that he refused to marry. He fell madly and passionately in love with the ivory cult statue he was carving of Aphrodite and longed to marry it. Because Pygmalion was extremely pious and devoted to Aphrodite, the goddess brought the statue to life. Pygmalion married the girl the statue became and they had a son named Paphos, after whom the capital of Cyprus received its name. Pseudo-Apollodorus later mentions "Metharme, daughter of Pygmalion, king of Cyprus".

Aphrodite generously rewarded those who honored her, but also punished those who disrespected her, often quite brutally. A myth described in Apollonius of Rhodes's "Argonautica" and later summarized in the "Bibliotheca" of Pseudo-Apollodorus tells how, when the women of the island of Lemnos refused to sacrifice to Aphrodite, the goddess cursed them to stink horribly so that their husbands would never have sex with them. Instead, their husbands started having sex with their Thracian slave-girls. In anger, the women of Lemnos murdered the entire male population of the island, as well as all the Thracian slaves. When Jason and his crew of Argonauts arrived on Lemnos, they mated with the sex-starved women under Aphrodite's approval and repopulated the island. From then on, the women of Lemnos never disrespected Aphrodite again.

In Euripides's tragedy "Hippolytus", which was first performed at the City Dionysia in 428 BC, Theseus's son Hippolytus worships only Artemis, the goddess of virginity, and refuses to engage in any form of sexual contact. Aphrodite is infuriated by his prideful behavior and, in the prologue to the play, she declares that, by honoring only Artemis and refusing to venerate her, Hippolytus has directly challenged her authority. Aphrodite therefore causes Hippolytus's stepmother, Phaedra, to fall in love with him, knowing Hippolytus will reject her. After being rejected, Phaedra commits suicide and leaves a suicide note to Theseus telling him that she killed herself because Hippolytus attempted to rape her. Theseus prays to Poseidon to kill Hippolytus for his transgression. Poseidon sends a wild bull to scare Hippolytus's horses as he is riding by the sea in his chariot, causing the horses to bolt and smash the chariot against the cliffs, dragging Hippolytus to a bloody death across the rocky shoreline. The play concludes with Artemis vowing to kill Aphrodite's own mortal beloved (presumably Adonis) in revenge.

Glaucus of Corinth angered Aphrodite by refusing to let his horses for chariot racing mate, since doing so would hinder their speed. During the chariot race at the funeral games of King Pelias, Aphrodite drove his horses mad and they tore him apart. Polyphonte was a young woman who chose a virginal life with Artemis instead of marriage and children, as favoured by Aphrodite. Aphrodite cursed her, causing her to have children by a bear. The resulting offspring, Agrius and Oreius, were wild cannibals who incurred the hatred of Zeus. Ultimately, he transformed all the members of the family into birds of ill omen.

The myth of the Judgement of Paris is mentioned briefly in the "Iliad", but is described in depth in an epitome of the "Cypria", a lost poem of the Epic Cycle, which records that all the gods and goddesses as well as various mortals were invited to the marriage of Peleus and Thetis (the eventual parents of Achilles). Only Eris, goddess of discord, was not invited. She was annoyed at this, so she arrived with a golden apple inscribed with the word καλλίστῃ (kallistēi, "for the fairest"), which she threw among the goddesses. Aphrodite, Hera, and Athena all claimed to be the fairest, and thus the rightful owner of the apple.

The goddesses chose to place the matter before Zeus, who, not wanting to favor one of the goddesses, put the choice into the hands of Paris, a Trojan prince. After bathing in the spring of Mount Ida where Troy was situated, the goddesses appeared before Paris for his decision. In the extant ancient depictions of the Judgement of Paris, Aphrodite is only occasionally represented nude, and Athena and Hera are always fully clothed. Since the Renaissance, however, western paintings have typically portrayed all three goddesses as completely naked.

All three goddesses were ideally beautiful and Paris could not decide between them, so they resorted to bribes. Hera tried to bribe Paris with power over all Asia and Europe, and Athena offered wisdom, fame and glory in battle, but Aphrodite promised Paris that, if he were to choose her as the fairest, she would let him marry the most beautiful woman on earth. This woman was Helen, who was already married to King Menelaus of Sparta. Paris selected Aphrodite and awarded her the apple. The other two goddesses were enraged and, as a direct result, sided with the Greeks in the Trojan War.

Aphrodite plays an important and active role throughout the entirety of Homer's "Iliad". In Book III, she rescues Paris from Menelaus after he foolishly challenges him to a one-on-one duel. She then appears to Helen in the form of an old woman and attempts to persuade her to have sex with Paris, reminding her of his physical beauty and athletic prowess. Helen immediately recognizes Aphrodite by her beautiful neck, perfect breasts, and flashing eyes and chides the goddess, addressing her as her equal. Aphrodite sharply rebukes Helen, reminding her that, if she vexes her, she will punish her just as much as she has favored her already. Helen demurely obeys Aphrodite's command.

In Book V, Aphrodite charges into battle to rescue her son Aeneas from the Greek hero Diomedes. Diomedes recognizes Aphrodite as a "weakling" goddess and, thrusting his spear, nicks her wrist through her "ambrosial robe". Aphrodite borrows Ares's chariot to ride back to Mount Olympus. Zeus chides her for putting herself in danger, reminding her that "her specialty is love, not war." In Book XIV, during the "Dios Apate" episode, Aphrodite lends her "kestos himas" to Hera for the purpose of seducing Zeus and distracting him from the combat while Poseidon aids the Greek forces on the beach. In the "Theomachia" in Book XXI, Aphrodite again enters the battlefield to carry Ares away after he is wounded.

Aphrodite's most prominent avian symbol was the dove, which was originally an important symbol of her Near Eastern precursor Inanna-Ishtar. (In fact, the ancient Greek word for "dove" was "peristerá", derived from the Semitic phrase "peraḥ Ištar", meaning "bird of Ishtar".) Aphrodite frequently appears with doves in ancient Greek pottery and the temple of Aphrodite Pandemos on the southwest slope of the Athenian Acropolis was decorated with relief sculptures of doves with knotted fillets in their beaks. Votive offerings of small, white, marble doves were also discovered in the temple of Aphrodite at Daphni. In addition to her associations with doves, Aphrodite was also closely linked with sparrows and she is described riding in a chariot pulled by sparrows in Sappho's "Ode to Aphrodite".

Because of her connections to the sea, Aphrodite was associated with a number of different types of water fowl, including swans, geese, and ducks. Aphrodite's other symbols included the sea, conch shells, and roses. The rose and myrtle flowers were both sacred to Aphrodite. Her most important fruit emblem was the apple, but she was also associated with pomegranates, possibly because the red seeds suggested sexuality or because Greek women sometimes used pomegranates as a method of birth control. In Greek art, Aphrodite is often also accompanied by dolphins and Nereids.

A scene of Aphrodite rising from the sea appears on the back of the Ludovisi Throne ( 460 BC), which was probably originally part of a massive altar that was constructed as part of the Ionic temple to Aphrodite in the Greek polis of Locri Epizephyrii in Magna Graecia in southern Italy. The throne shows Aphrodite rising from the sea, clad in a diaphanous garment, which is drenched with seawater and clinging to her body, revealing her upturned breasts and the outline of her navel. Her hair hangs dripping as she reaches to two attendants standing barefoot on the rocky shore on either side of her, lifting her out of the water. Scenes with Aphrodite appear in works of classical Greek pottery, including a famous white-ground "kylix" by the Pistoxenos Painter dating the between 470 and 460 BC, showing her riding on a swan or goose.

In BC, the Athenian sculptor Praxiteles carved the marble statue "Aphrodite of Knidos", which Pliny the Elder later praised as the greatest sculpture ever made. The statue showed a nude Aphrodite modestly covering her pubic region while resting against a water pot with her robe draped over it for support. The "Aphrodite of Knidos" was the first ever full-sized statue to depict Aphrodite completely naked and one of the first sculptures that was intended to be viewed from all sides. The statue was purchased by the people of Knidos in around 350 BC and proved to be tremendously influential on later depictions of Aphrodite. The original sculpture has been lost, but written descriptions of it as well several depictions of it on coins are still extant and over sixty copies, small-scale models, and fragments of it have been identified.

The Greek painter Apelles of Kos, a contemporary of Praxiteles, produced the panel painting "Aphrodite Anadyomene" ("Aphrodite Rising from the Sea"). According to Athenaeus, Apelles was inspired to paint the painting after watching the courtesan Phryne take off her clothes, untie her hair, and bathe naked in the sea at Eleusis. The painting was displayed in the Asclepeion on the island of Kos. The "Aphrodite Anadyomene" went unnoticed for centuries, but Pliny the Elder records that, in his own time, it was regarded as Apelles's most famous work.

During the Hellenistic and Roman periods, statues depicting Aphrodite proliferated; many of these statues were modeled at least to some extent on Praxiteles's "Aphrodite of Knidos". Some statues show Aphrodite crouching naked; others show her wringing water out of her hair as she rises from the sea. Another common type of statue is known as "Aphrodite Kallipygos", the name of which is Greek for "Aphrodite of the Beautiful Buttocks"; this type of sculpture shows Aphrodite lifting her "peplos" to display her buttocks to the viewer while looking back at them from over her shoulder. The ancient Romans produced massive numbers of copies of Greek sculptures of Aphrodite and more sculptures of Aphrodite have survived from antiquity than of any other deity.

Early Christians frequently adapted pagan iconography to suit Christian purposes. In the Early Middle Ages, Christians adapted elements of Aphrodite/Venus's iconography and applied them to Eve and prostitutes, but also female saints and even the Virgin Mary. Christians in the east reinterpreted the story of Aphrodite's birth as a metaphor for baptism; in a Coptic stele from the sixth century AD, a female orant is shown wearing Aphrodite's conch shell as a sign that she is newly baptized. Throughout the Middle Ages, villages and communities across Europe still maintained folk tales and traditions about Aphrodite/Venus and travelers reported a wide variety of stories. Numerous Roman mosaics of Venus survived in Britain, preserving memory of the pagan past. In North Africa in the late fifth century AD, Fulgentius of Ruspe encountered mosaics of Aphrodite and reinterpreted her as a symbol of the sin of Lust, arguing that she was shown naked because "the sin of lust is never cloaked" and that she was often shown "swimming" because "all lust suffers shipwreck of its affairs." He also argued that she was associated with doves and conchs because these are symbols of copulation, and that she was associated with roses because "as the rose gives pleasure, but is swept away by the swift movement of the seasons, so lust is pleasant for a moment, but is swept away forever."

While Fulgentius had appropriated Aphrodite as a symbol of Lust, Isidore of Seville ( 560–636) interpreted her as a symbol of marital procreative sex and declared that the moral of the story of Aphrodite's birth is that sex can only be holy in the presence of semen, blood, and heat, which he regarded as all being necessary for procreation. Meanwhile, Isidore denigrated Aphrodite/Venus's son Eros/Cupid as a "demon of fornication" ("daemon fornicationis"). Aphrodite/Venus was best known to Western European scholars through her appearances in Virgil's "Aeneid" and Ovid's "Metamorphoses". Venus is mentioned in the Latin poem "Pervigilium Veneris" ("The Eve of Saint Venus"), written in the third or fourth century AD, and in Giovanni Boccaccio's "Genealogia Deorum Gentilium".

Aphrodite is the central figure in Sandro Botticelli's painting "Primavera", which has been described as "one of the most written about, and most controversial paintings in the world", and "one of the most popular paintings in Western art". The story of Aphrodite's birth from the foam was a popular subject matter for painters during the Italian Renaissance, who were attempting to consciously reconstruct Apelles of Kos's lost masterpiece "Aphrodite Anadyomene" based on the literary "ekphrasis" of it preserved by Cicero and Pliny the Elder. Artists also drew inspiration from Ovid's description of the birth of Venus in his "Metamorphoses". Sandro Botticelli's "The Birth of Venus" ( 1485) was also partially inspired by a description by Poliziano of a relief on the subject. Later Italian renditions of the same scene include Titian's "Venus Anadyomene" ( 1525) and Raphael's painting in the "Stufetta del cardinal Bibbiena" (1516). Titian's biographer Giorgio Vasari identified all of Titian's paintings of naked women as paintings of "Venus", including an erotic painting from 1534, which he called the "Venus of Urbino", even though the painting does not contain any of Aphrodite/Venus's traditional iconography and the woman in it is clearly shown in a contemporary setting, not a classical one.
Jacques-Louis David's final work was his 1824 "magnum opus", "Mars Being Disarmed by Venus", which combines elements of classical, Renaissance, traditional French art, and contemporary artistic styles. While he was working on the painting, David described it, saying, "This is the last picture I want to paint, but I want to surpass myself in it. I will put the date of my seventy-five years on it and afterwards I will never again pick up my brush." The painting was exhibited first in Brussels and then in Paris, where over 10,000 people came to see it. Jean-Auguste-Dominique Ingres's painting "Venus Anadyomene" was one of his major works. Louis Geofroy described it as a "dream of youth realized with the power of maturity, a happiness that few obtain, artists or others." Théophile Gautier declared: "Nothing remains of the marvelous painting of the Greeks, but surely if anything could give the idea of antique painting as it was conceived following the statues of Phidias and the poems of Homer, it is M. Ingres's painting: the "Venus Anadyomene" of Apelles has been found." Other critics dismissed it as a piece of unimaginative, sentimental kitsch, but Ingres himself considered it to be among his greatest works and used the same figure as the model for his later 1856 painting "La Source".

Paintings of Venus were favorites of the late nineteenth-century Academic artists in France. In 1863, Alexandre Cabanel won widespread critical acclaim at the Paris Salon for his painting "The Birth of Venus", which the French emperor Napoleon III immediately purchased for his own personal art collection. Édouard Manet's 1865 painting "Olympia" parodied the nude Venuses of the Academic painters, particularly Cabanel's "Birth of Venus". In 1867, the English Academic painter Frederic Leighton displayed his "Venus Disrobing for the Bath" at the Academy. The art critic J. B. Atkinson praised it, declaring that "Mr Leighton, instead of adopting corrupt Roman notions regarding Venus such as Rubens embodied, has wisely reverted to the Greek idea of Aphrodite, a goddess worshipped, and by artists painted, as the perfection of female grace and beauty." A year later, the English painter Dante Gabriel Rossetti, a founding member of the Pre-Raphaelite Brotherhood, painted "Venus Verticordia" (Latin for "Aphrodite, the Changer of Hearts"), showing Aphrodite as a nude red-headed woman in a garden of roses. Though he was reproached for his "outré" subject matter, Rossetti refused to alter the painting and it was soon purchased by J. Mitchell of Bradford. In 1879, William Adolphe Bouguereau exhibited at the Paris Salon his own "Birth of Venus", which imitated the classical tradition of "contrapposto" and was met with widespread critical acclaim, rivalling the popularity of Cabanel's version from nearly two decades prior.
William Shakespeare's erotic narrative poem "Venus and Adonis" (1593), a retelling of the courtship of Aphrodite and Adonis from Ovid's "Metamorphoses", was the most popular of all his works published within his own lifetime. Six editions of it were published before Shakespeare's death (more than any of his other works) and it enjoyed particularly strong popularity among young adults. In 1605, Richard Barnfield lauded it, declaring that the poem had placed Shakespeare's name "in fames immortall Booke". Despite this, the poem has received mixed reception from modern critics; Samuel Taylor Coleridge defended it, but Samuel Butler complained that it bored him and C. S. Lewis described an attempted reading of it as "suffocating".

Aphrodite appears in Richard Garnett's short story collection "The Twilight of the Gods and Other Tales" (1888), in which the gods' temples have been destroyed by Christians. Stories revolving around sculptures of Aphrodite were common in the late nineteenth and early twentieth centuries. Examples of such works of literature include the novel "The Tinted Venus: A Farcical Romance" (1885) by Thomas Anstey Guthrie and the short story "The Venus of Ille" (1887) by Prosper Mérimée, both of which are about statues of Aphrodite that come to life. Another noteworthy example is "Aphrodite in Aulis" by the Anglo-Irish writer George Moore, which revolves around an ancient Greek family who moves to Aulis. The French writer Pierre Louÿs titled his erotic historical novel "" (1896) after the Greek goddess. The novel enjoyed widespread commercial success, but scandalized French audiences due to its sensuality and its decadent portrayal of Greek society.

In the early twentieth century, stories of Aphrodite were used by feminist poets, such as Amy Lowell and Alicia Ostriker. Many of these poems dealt with Aphrodite's legendary birth from the foam of the sea. Other feminist writers, including Claude Cahun, Thit Jensen, and Anaïs Nin also made use of the myth of Aphrodite in their writings. Ever since the publication of Isabel Allende's book "Aphrodite: A Memoir of the Senses" in 1998, the name "Aphrodite" has been used as a title for dozens of books dealing with all topics even superficially connected to her domain. Frequently these books do not even mention Aphrodite, or mention her only briefly, but make use of her name as a selling point.

In 1938, Gleb Botkin, a Russian immigrant to the United States, founded the Church of Aphrodite, a Neopagan religion centered around the worship of a Mother Goddess, whom its practitioners identified as Aphrodite. The Church of Aphrodite's theology was laid out in the book "In Search of Reality", published in 1969, two years before Botkin's death. The book portrayed Aphrodite in a drastically different light than the one in which the Greeks envisioned her, instead casting her as "the sole Goddess of a somewhat Neoplatonic Pagan monotheism". It claimed that the worship of Aphrodite had been brought to Greece by the mystic teacher Orpheus, but that the Greeks had misunderstood Orpheus's teachings and had not realized the importance of worshipping Aphrodite alone.

Aphrodite is a major deity in Wicca, a contemporary nature-based syncretic Neopagan religion. Wiccans regard Aphrodite as one aspect of the Goddess and she is frequently invoked by name during enchantments dealing with love and romance. Wiccans regard Aphrodite as the ruler of human emotions, erotic spirituality, creativity, and art. As one of the twelve Olympians, Aphrodite is a major deity within Hellenismos (Hellenic Polytheistic Reconstructionism), a Neopagan religion which seeks to authentically revive and recreate the religion of ancient Greece in the modern world. Unlike Wiccans, Hellenists are usually strictly polytheistic or pantheistic. Hellenists venerate Aphrodite primarily as the goddess of romantic love, but also as a goddess of sexuality, the sea, and war. Her many epithets include "Sea Born", "Killer of Men", "She upon the Graves", "Fair Sailing", and "Ally in War".





</doc>
<doc id="1175" url="https://en.wikipedia.org/wiki?curid=1175" title="April 1">
April 1





</doc>
<doc id="1176" url="https://en.wikipedia.org/wiki?curid=1176" title="Antisymmetric relation">
Antisymmetric relation

In mathematics, a binary relation "R" on a set "X" is anti-symmetric if there is no pair of "distinct" elements of "X" each of which is related by "R" to the other. More formally, "R" is anti-symmetric precisely if for all "a" and "b" in "X"
or, equivalently,

As a simple example, the divisibility order on the natural numbers is an anti-symmetric relation. In this context, anti-symmetry means that the only way each of two numbers can be divisible by the other is if the two are, in fact, the same number; equivalently, if "n" and "m" are distinct and "n" is a factor of "m", then "m" cannot be a factor of "n".

In mathematical notation, this is:

or, equivalently,

The usual order relation ≤ on the real numbers is anti-symmetric: if for two real numbers "x" and "y" both inequalities "x" ≤ "y" and "y" ≤ "x" hold then "x" and "y" must be equal. Similarly, the subset order ⊆ on the subsets of any given set is anti-symmetric: given two sets "A" and "B", if every element in "A" also is in "B" and every element in "B" is also in "A", then "A" and "B" must contain all the same elements and therefore be equal:

Partial and total orders are anti-symmetric by definition. A relation can be both symmetric and anti-symmetric (e.g., the equality relation), and there are relations which are neither symmetric nor anti-symmetric (e.g., the "preys on" relation on biological species).

Anti-symmetry is different from asymmetry, which requires both anti-symmetry and irreflexivity.

The relation ""x" is even, "y" is odd" between a pair ("x", "y") of integers is anti-symmetric:

Every asymmetric relation is also an anti-symmetric relation.




</doc>
<doc id="1177" url="https://en.wikipedia.org/wiki?curid=1177" title="Aleister Crowley">
Aleister Crowley

Aleister Crowley (; born Edward Alexander Crowley; 12 October 1875 – 1 December 1947) was an English occultist, ceremonial magician, poet, painter, novelist, and mountaineer. He founded the religion of Thelema, identifying himself as the prophet entrusted with guiding humanity into the Æon of Horus in the early 20th century. A prolific writer, he published widely over the course of his life.

Born to a wealthy Plymouth Brethren family in Royal Leamington Spa, Warwickshire, Crowley rejected the fundamentalist Christian faith to pursue an interest in Western esotericism. He was educated at the University of Cambridge, where he focused his attentions on mountaineering and poetry, resulting in several publications. Some biographers allege that here he was recruited into a British intelligence agency, further suggesting that he remained a spy throughout his life. In 1898 he joined the esoteric Hermetic Order of the Golden Dawn, where he was trained in ceremonial magic by Samuel Liddell MacGregor Mathers and Allan Bennett. Moving to Boleskine House by Loch Ness in Scotland, he went mountaineering in Mexico with Oscar Eckenstein, before studying Hindu and Buddhist practices in India. He married Rose Edith Kelly and in 1904 they honeymooned in Cairo, Egypt, where Crowley claimed to have been contacted by a supernatural entity named Aiwass, who provided him with "The Book of the Law", a sacred text that served as the basis for Thelema. Announcing the start of the Æon of Horus, "The Book" declared that its followers should "Do what thou wilt" and seek to align themselves with their True Will through the practice of magick.

After an unsuccessful attempt to climb Kanchenjunga and a visit to India and China, Crowley returned to Britain, where he attracted attention as a prolific author of poetry, novels, and occult literature. In 1907, he and George Cecil Jones co-founded a Thelemite order, the A∴A∴, through which they propagated the religion. After spending time in Algeria, in 1912 he was initiated into another esoteric order, the German-based Ordo Templi Orientis (O.T.O.), rising to become the leader of its British branch, which he reformulated in accordance with his Thelemite beliefs. Through the O.T.O., Thelemite groups were established in Britain, Australia, and North America. Crowley spent the First World War in the United States, where he took up painting and campaigned for the German war effort against Britain, later revealing that he had infiltrated the pro-German movement to assist the British intelligence services. In 1920 he established the Abbey of Thelema, a religious commune in Cefalù, Sicily where he lived with various followers. His libertine lifestyle led to denunciations in the British press, and the Italian government evicted him in 1923. He divided the following two decades between France, Germany, and England, and continued to promote Thelema until his death.

Crowley gained widespread notoriety during his lifetime, being a recreational drug experimenter, bisexual and an individualist social critic. He was denounced in the popular press as "the wickedest man in the world" and a Satanist. Crowley has remained a highly influential figure over Western esotericism and the counter-culture, and continues to be considered a prophet in Thelema. He is the subject of various biographies and academic studies.

Crowley was born as Edward Alexander Crowley at 30 Clarendon Square in Royal Leamington Spa, Warwickshire, on 12 October 1875. His father, Edward Crowley (1829–87), was trained as an engineer, but his share in a lucrative family brewing business, Crowley's Alton Ales, had allowed him to retire before his son was born. His mother, Emily Bertha Bishop (1848–1917), came from a Devonshire-Somerset family and had a strained relationship with her son; she described him as "the Beast", a name that he revelled in. The couple had been married at London's Kensington Registry Office in November 1874, and were evangelical Christians. Crowley's father had been born a Quaker, but had converted to the Exclusive Brethren, a faction of a Christian fundamentalist group known as the Plymouth Brethren, with Emily joining him upon marriage. Crowley's father was particularly devout, spending his time as a travelling preacher for the sect and reading a chapter from the Bible to his wife and son after breakfast every day. Following the death of their baby daughter in 1880, in 1881 the Crowleys moved to Redhill, Surrey. At the age of 8, Crowley was sent to H.T. Habershon's evangelical Christian boarding school in Hastings, and then to Ebor preparatory school in Cambridge, run by the Reverend Henry d'Arcy Champney, whom Crowley considered a sadist.

In March 1887, when Crowley was 11, his father died of tongue cancer. Crowley described this as a turning point in his life, and he always maintained an admiration of his father, describing him as "my hero and my friend". Inheriting a third of his father's wealth, he began misbehaving at school and was harshly punished by Champney; Crowley's family removed him from the school when he developed albuminuria. He then attended Malvern College and Tonbridge School, both of which he despised and left after a few terms. He became increasingly skeptical regarding Christianity, pointing out inconsistencies in the Bible to his religious teachers, and went against the Christian morality of his upbringing by smoking, masturbating, and having sex with prostitutes from whom he contracted gonorrhea. Sent to live with a Brethren tutor in Eastbourne, he undertook chemistry courses at Eastbourne College. Crowley developed interests in chess, poetry, and mountain climbing, and in 1894 climbed Beachy Head before visiting the Alps and joining the Scottish Mountaineering Club. The following year he returned to the Bernese Alps, climbing the Eiger, Trift, Jungfrau, Mönch, and Wetterhorn.

Having adopted the name of Aleister over Edward, in October 1895 Crowley began a three-year course at Trinity College, Cambridge, where he was entered for the Moral Science Tripos studying philosophy. With approval from his personal tutor, he changed to English literature, which was not then part of the curriculum offered. Crowley spent much of his time at university engaged in his pastimes, becoming president of the chess club and practising the game for two hours a day; he briefly considered a professional career as a chess player. Crowley also embraced his love of literature and poetry, particularly the works of Richard Francis Burton and Percy Bysshe Shelley. Many of his own poems appeared in student publications such as "The Granta", "Cambridge Magazine", and "Cantab". He continued his mountaineering, going on holiday to the Alps to climb every year from 1894 to 1898, often with his friend Oscar Eckenstein, and in 1897 he made the first ascent of the Mönch without a guide. These feats led to his recognition in the Alpine mountaineering community.

Crowley had his first significant mystical experience while on holiday in Stockholm in December 1896. Several biographers, including Lawrence Sutin, Richard Kaczynski, and Tobias Churton, believed that this was the result of Crowley's first same-sex sexual experience, which enabled him to recognise his bisexuality. At Cambridge, Crowley maintained a vigorous sex life with women—largely with female prostitutes, from one of whom he caught syphilis—but eventually he took part in same-sex activities, despite their illegality. In October 1897, Crowley met Herbert Charles Pollitt, president of the Cambridge University Footlights Dramatic Club, and the two entered into a relationship. They broke apart because Pollitt did not share Crowley's increasing interest in Western esotericism, a break-up that Crowley would regret for many years.

In 1897, Crowley travelled to St Petersburg in Russia, later claiming that he was trying to learn Russian as he was considering a future diplomatic career there. Biographers Richard Spence and Tobias Churton suggested that Crowley had done so as an intelligence agent under the employ of the British secret service, speculating that he had been enlisted while at Cambridge.

In October 1897, a brief illness triggered considerations of mortality and "the futility of all human endeavour", and Crowley abandoned all thoughts of a diplomatic career in favour of pursuing an interest in the occult. In March 1898, he obtained A.E. Waite's "The Book of Black Magic and of Pacts" (1898), and then Karl von Eckartshausen's "The Cloud Upon the Sanctuary" (1896), furthering his occult interests.
In 1898 Crowley privately published 100 copies of his poem "Aceldama: A Place to Bury Strangers In", but it was not a particular success. That same year he published a string of other poems, including "White Stains", a Decadent collection of erotic poetry that was printed abroad lest its publication be prohibited by the British authorities. In July 1898, he left Cambridge, not having taken any degree at all despite a "first class" showing in his 1897 exams and consistent "second class honours" results before that.

In August 1898, Crowley was in Zermatt, Switzerland, where he met the chemist Julian L. Baker, and the two began discussing their common interest in alchemy. Back in London, Baker introduced Crowley to George Cecil Jones, Baker's brother in-law, and a fellow member of the occult society known as the Hermetic Order of the Golden Dawn, which had been founded in 1888. Crowley was initiated into the Outer Order of the Golden Dawn on 18 November 1898 by the group's leader, Samuel Liddell MacGregor Mathers. The ceremony took place in the Golden Dawn's Isis-Urania Temple held at London's Mark Masons Hall, where Crowley took the magical motto and name "Frater Perdurabo", which he interpreted as "I shall endure to the end". Biographers Richard Spence and Tobias Churton have suggested that Crowley joined the Order under the command of the British secret services to monitor the activities of Mathers, who was known to be a Carlist.

Crowley moved into his own luxury flat at 67–69 Chancery Lane and soon invited a senior Golden Dawn member, Allan Bennett, to live with him as his personal magical tutor. Bennett taught Crowley more about ceremonial magic and the ritual use of drugs, and together they performed the rituals of the "Goetia", until Bennett left for South Asia to study Buddhism. In November 1899, Crowley purchased Boleskine House in Foyers on the shore of Loch Ness in Scotland. He developed a love of Scottish culture, describing himself as the "Laird of Boleskine", and took to wearing traditional highland dress, even during visits to London. He continued writing poetry, publishing "Jezebel and Other Tragic Poems", "Tales of Archais", "Songs of the Spirit", "Appeal to the American Republic", and "Jephthah" in 1898–99; most gained mixed reviews from literary critics, although "Jephthah" was considered a particular critical success.

Crowley soon progressed through the lower grades of the Golden Dawn, and was ready to enter the group's inner Second Order. He was unpopular in the group; his bisexuality and libertine lifestyle had gained him a bad reputation, and he had developed feuds with some of the members, including W.B. Yeats. When the Golden Dawn's London lodge refused to initiate Crowley into the Second Order, he visited Mathers in Paris, who personally admitted him into the Adeptus Minor Grade. A schism had developed between Mathers and the London members of the Golden Dawn, who were unhappy with his autocratic rule. Acting under Mathers' orders, Crowley – with the help of his mistress and fellow initiate Elaine Simpson – attempted to seize the Vault of the Adepts, a temple space at 36 Blythe Road in West Kensington, from the London lodge members. When the case was taken to court, the judge ruled in favour of the London lodge, as they had paid for the space's rent, leaving both Crowley and Mathers isolated from the group. Spence suggested that the entire scenario was part of an intelligence operation to undermine Mathers' authority.

In 1900, Crowley travelled to Mexico via the United States, settling in Mexico City and taking a local woman as his mistress. Developing a love of the country, he continued experimenting with ceremonial magic, working with John Dee's Enochian invocations. He later claimed to have been initiated into Freemasonry while there, and he wrote a play based on Richard Wagner's "Tannhäuser" as well as a series of poems, published as "Oracles" (1905). Eckenstein joined him later that year, and together they climbed several mountains, including Iztaccihuatl, Popocatepetl, and Colima, the latter of which they had to abandon owing to a volcanic eruption. Spence has suggested that the purpose of the trip might have been to explore Mexican oil prospects for British intelligence. Leaving Mexico, Crowley headed to San Francisco before sailing for Hawaii aboard the "Nippon Maru". On the ship he had a brief affair with a married woman named Mary Alice Rogers; saying he had fallen in love with her, he wrote a series of poems about the romance, published as "Alice: An Adultery" (1903).
Briefly stopping in Japan and Hong Kong, Crowley reached Ceylon, where he met with Allan Bennett, who was there studying Shaivism. The pair spent some time in Kandy before Bennett decided to become a Buddhist monk in the Theravada tradition, travelling to Burma to do so. Crowley decided to tour India, devoting himself to the Hindu practice of "raja yoga", from which he claimed to have achieved the spiritual state of "dhyana". He spent much of this time studying at the Meenakshi Amman Temple in Madura. At this time he also composed and also wrote poetry which was published as "The Sword of Song" (1904). He contracted malaria, and had to recuperate from the disease in Calcutta and Rangoon. In 1902, he was joined in India by Eckenstein and several other mountaineers: Guy Knowles, H. Pfannl, V. Wesseley, and Jules Jacot-Guillarmod. Together the Eckenstein-Crowley expedition attempted K2, which had never been climbed. On the journey, Crowley was afflicted with influenza, malaria, and snow blindness, and other expedition members were also struck with illness. They reached an altitude of before turning back.

Having arrived in Paris in November 1902 he socialised with friend and future brother-in-law, the painter Gerald Kelly, and through him became a fixture of the Parisian arts scene. Whilst there, Crowley wrote a series of poems on the work of an acquaintance, the sculptor Auguste Rodin. These poems were later published as "Rodin in Rime" (1907). One of those frequenting this milieu was W. Somerset Maugham, who after briefly meeting Crowley later used him as a model for the character of Oliver Haddo in his novel "The Magician" (1908). Returning to Boleskine in April 1903, in August Crowley wed Gerald's sister Rose Edith Kelly in a "marriage of convenience" to prevent her entering an arranged marriage; the marriage appalled the Kelly family and damaged his friendship with Gerald. Heading on a honeymoon to Paris, Cairo, and then Ceylon, Crowley fell in love with Rose and worked to prove his affections. While on his honeymoon, he wrote her a series of love poems, published as "Rosa Mundi and other Love Songs" (1906), as well as authoring the religious satire "Why Jesus Wept" (1904).

In February 1904, Crowley and Rose arrived in Cairo. Claiming to be a prince and princess, they rented an apartment in which Crowley set up a temple room and began invoking ancient Egyptian deities, while studying Islamic mysticism and Arabic. According to Crowley's later account, Rose regularly became delirious and informed him "they are waiting for you." On 18 March, she explained that "they" were the god Horus, and on 20 March proclaimed that "the Equinox of the Gods has come". She led him to a nearby museum, where she showed him a seventh-century BCE mortuary stele known as the Stele of Ankh-ef-en-Khonsu; Crowley thought it important that the exhibit's number was 666, the number of the beast in Christian belief, and in later years termed the artefact the "Stele of Revealing."

According to Crowley's later statements, on 8 April he heard a disembodied voice that claimed to be that of Aiwass, the messenger of Horus, or Hoor-Paar-Kraat. Crowley said that he wrote down everything the voice told him over the course of the next three days, and titled it "Liber L vel Legis" or "The Book of the Law". The book proclaimed that humanity was entering a new Aeon, and that Crowley would serve as its prophet. It stated that a supreme moral law was to be introduced in this Aeon, "Do what thou wilt shall be the whole of the Law," and that people should learn to live in tune with their Will. This book, and the philosophy that it espoused, became the cornerstone of Crowley's religion, Thelema. Crowley said that at the time he had been unsure what to do with "The Book of the Law". Often resenting it, he said that he ignored the instructions which the text commanded him to perform, which included taking the Stele of Revealing from the museum, fortifying his own island, and translating the book into all the world's languages. According to his account, he instead sent typescripts of the work to several occultists he knew, putting the manuscript away and ignoring it.

Returning to Boleskine, Crowley came to believe that Mathers had begun using magic against him, and the relationship between the two broke down. On 28 July 1905, Rose gave birth to Crowley's first child, a daughter named Lilith, with Crowley writing the pornographic "Snowdrops From a Curate's Garden" to entertain his recuperating wife. He also founded a publishing company through which to publish his poetry, naming it the Society for the Propagation of Religious Truth in parody of the Society for Promoting Christian Knowledge. Among its first publications were Crowley's "Collected Works", edited by Ivor Back. His poetry often received strong reviews (either positive or negative), but never sold well. In an attempt to gain more publicity, he issued a reward of £100 for the best essay on his work. The winner of this was J. F. C. Fuller, a British Army officer and military historian, whose essay, "The Star in the West" (1907), heralded Crowley's poetry as some of the greatest ever written.

Crowley decided to climb Kangchenjunga in the Himalayas of Nepal, widely recognised as the world's most treacherous mountain. Assembling a team consisting of Jacot-Guillarmod, Charles Adolphe Reymond, Alexis Pache, and Alcesti C. Rigo de Righi, the expedition was marred by much argument between Crowley and the others, who thought that he was reckless. They eventually mutinied against Crowley's control, with the other climbers heading back down the mountain as nightfall approached despite Crowley's warnings that it was too dangerous. Subsequently, Pache and several porters were killed in an accident, something for which Crowley was widely blamed by the mountaineering community.

Spending time in Moharbhanj, where he took part in big game hunting and wrote the homoerotic work "The Scented Garden", Crowley met up with Rose and Lilith in Calcutta before being forced to leave India after shooting dead a native man who tried to mug him. Briefly visiting Bennett in Burma, Crowley and his family decided to tour Southern China, hiring porters and a nanny for the purpose. Spence has suggested that this trip to China was orchestrated as part of a British intelligence scheme to monitor the region's opium trade. Crowley smoked opium throughout the journey, which took the family from Tengyueh through to Yungchang, Tali, Yunnanfu, and then Hanoi. On the way he spent much time on spiritual and magical work, reciting the "Bornless Ritual", an invocation to his Holy Guardian Angel, on a daily basis.

While Rose and Lilith returned to Europe, Crowley headed to Shanghai to meet old friend Elaine Simpson, who was fascinated by "The Book of the Law"; together they performed rituals in an attempt to contact Aiwass. Crowley then sailed to Japan and Canada, before continuing to New York City, where he unsuccessfully solicited support for a second expedition up Kangchenjunga. Upon arrival in Britain, Crowley learned that his daughter Lilith had died of typhoid in Rangoon, something he later blamed on Rose's increasing alcoholism. Under emotional distress, his health began to suffer, and he underwent a series of surgical operations. He began short-lived romances with actress Vera "Lola" Neville (née Snepp) and author Ada Leverson, while Rose gave birth to Crowley's second daughter, Lola Zaza, in February 1907.

With his old mentor George Cecil Jones, Crowley continued performing the Abramelin rituals at the Ashdown Park Hotel in Coulsdon, Surrey. Crowley claimed that in doing so he attained "samadhi", or union with Godhead, thereby marking a turning point in his life. Making heavy use of hashish during these rituals, he wrote an essay on "The Psychology of Hashish" (1909) in which he championed the drug as an aid to mysticism. He also claimed to have been contacted once again by Aiwass in late October and November 1907, adding that Aiwass dictated two further texts to him, "Liber VII" and "Liber Cordis Cincti Serpente", both of which were later classified in the corpus of Holy Books of Thelema. Crowley wrote down more Thelemic Holy Books during the last two months of the year, including "Liber LXVI", "Liber Arcanorum", "Liber Porta Lucis, Sub Figura X", "Liber Tau", "Liber Trigrammaton" and "Liber DCCCXIII vel Ararita", which he again claimed to have received from a preternatural source. Crowley stated that in June 1909, when the manuscript of "The Book of the Law" was rediscovered at Boleskine, he developed the opinion that Thelema represented objective truth.

Crowley's inheritance was running out. Trying to earn money, he was hired by George Montagu Bennett, the Earl of Tankerville, to help protect him from witchcraft; recognising Bennett's paranoia as being based in his cocaine addiction, Crowley took him on holiday to France and Morocco to recuperate. In 1907, he also began taking in paying students, whom he instructed in occult and magical practice. Victor Neuburg, whom Crowley met in February 1907, became his sexual partner and closest disciple; in 1908 the pair toured northern Spain before heading to Tangier, Morocco. The following year Neuburg stayed at Boleskine, where he and Crowley engaged in sadomasochism. Crowley continued to write prolifically, producing such works of poetry as "Ambergris", "Clouds Without Water", and "Konx Om Pax", as well as his first attempt at an autobiography, "The World's Tragedy". Recognising the popularity of short horror stories, Crowley wrote his own, some of which were published, and he also published several articles in "Vanity Fair", a magazine edited by his friend Frank Harris. He also wrote "Liber 777", a book of magical and Qabalistic correspondences that borrowed from Mathers and Bennett.

In November 1907, Crowley and Jones decided to found an occult order to act as a successor to the Hermetic Order of the Golden Dawn, being aided in doing so by Fuller. The result was the A∴A∴. The group's headquarters and temple were situated at 124 Victoria Street in central London, and their rites borrowed much from those of the Golden Dawn, but with an added Thelemic basis. Its earliest members included solicitor Richard Noel Warren, artist Austin Osman Spare, Horace Sheridan-Bickers, author George Raffalovich, Francis Henry Everard Joseph Feilding, engineer Herbert Edward Inman, Kenneth Ward, and Charles Stansfeld Jones. In March 1909, Crowley began production of a biannual periodical titled "The Equinox". He billed this periodical, which was to become the "Official Organ" of the A∴A∴, as "The Review of Scientific Illuminism".

Crowley had become increasingly frustrated with Rose's alcoholism, and in November 1909 he divorced her on the grounds of his own adultery. Lola was entrusted to Rose's care; the couple remained friends and Rose continued to live at Boleskine. Her alcoholism worsened, and as a result she was institutionalised in September 1911.

In November 1909, Crowley and Neuburg travelled to Algeria, touring the desert from El Arba to Aumale, Bou Saâda, and then Dā'leh Addin, with Crowley reciting the Quran on a daily basis. During the trip he invoked the thirty aethyrs of Enochian magic, with Neuburg recording the results, later published in "The Equinox" as "The Vision and the Voice". Following a mountaintop sex magic ritual, Crowley also performed an invocation to the demon Choronzon involving blood sacrifice, considering the results to be a watershed in his magical career. Returning to London in January 1910, Crowley found that Mathers was suing him for publishing Golden Dawn secrets in "The Equinox"; the court found in favour of Crowley. The case was widely reported in the press, with Crowley gaining wider fame. Crowley enjoyed this, and played up to the sensationalist stereotype of being a Satanist and advocate of human sacrifice, despite being neither.

The publicity attracted new members to the A∴A∴, among them Frank Bennett, James Bayley, Herbert Close, and James Windram. The Australian violinist Leila Waddell soon became Crowley's lover. Deciding to expand his teachings to a wider audience, Crowley developed the Rites of Artemis, a public performance of magic and symbolism featuring A∴A∴ members personifying various deities. It was first performed at the A∴A∴ headquarters, with attendees given a fruit punch containing peyote to enhance their experience. Various members of the press attended, and reported largely positively on it. In October and November 1910, Crowley decided to stage something similar, the Rites of Eleusis, at Caxton Hall, Westminster; this time press reviews were mixed. Crowley came under particular criticism from West de Wend Fenton, editor of "The Looking Glass" newspaper, who called him "one of the most blasphemous and cold-blooded villains of modern times". Fenton's articles suggested that Crowley and Jones were involved in homosexual activity; Crowley did not mind, but Jones unsuccessfully sued for libel. Fuller broke off his friendship and involvement with Crowley over the scandal, and Crowley and Neuburg returned to Algeria for further magical workings.

"The Equinox" continued publishing, and various books of literature and poetry were also published under its imprint, like Crowley's "Ambergris", "The Winged Beetle", and "The Scented Garden", as well as Neuburg's "The Triumph of Pan" and Ethel Archer's "The Whirlpool". In 1911, Crowley and Waddell holidayed in Montigny-sur-Loing, where he wrote prolifically, producing poems, short stories, plays, and 19 works on magic and mysticism, including the two final Holy Books of Thelema. In Paris, he met Mary Desti, who became his next "Scarlet Woman", with the two undertaking magical workings in St. Moritz; Crowley believed that one of the Secret Chiefs, Ab-ul-Diz, was speaking through her. Based on Desti's statements when in trance, Crowley wrote the two-volume "Book 4" (1912–13) and at the time developed the spelling "magick" in reference to the paranormal phenomenon as a means of distinguishing it from the stage magic of illusionists.

In early 1912, Crowley published "The Book of Lies", a work of mysticism that biographer Lawrence Sutin described as "his greatest success in merging his talents as poet, scholar, and magus". The German occultist Theodor Reuss later accused him of publishing some of the secrets of his own occult order, the Ordo Templi Orientis (O.T.O.), within "The Book". Crowley convinced Reuss that the similarities were coincidental, and the two became friends. Reuss appointed Crowley as head of the O.T.O's British branch, the Mysteria Mystica Maxima (MMM), and at a ceremony in Berlin Crowley adopted the magical name of Baphomet and was proclaimed "X° Supreme Rex and Sovereign Grand Master General of Ireland, Iona, and all the Britons". With Reuss' permission, Crowley set about advertising the MMM and re-writing many O.T.O. rituals, which were then based largely on Freemasonry; his incorporation of Thelemite elements proved controversial in the group. Fascinated by the O.T.O's emphasis on sex magic, Crowley devised a magical working based on anal sex and incorporated it into the syllabus for those O.T.O. members who had been initiated into the eleventh degree.

In March 1913 Crowley acted as producer for "The Ragged Ragtime Girls", a group of female violinists led by Waddell, as they performed at London's Old Tivoli theatre. They subsequently performed in Moscow for six weeks, where Crowley had a sadomasochistic relationship with the Hungarian Anny Ringler. In Moscow, Crowley continued to write plays and poetry, including "Hymn to Pan", and the Gnostic Mass, a Thelemic ritual that became a key part of O.T.O. liturgy. Churton suggested that Crowley had travelled to Moscow on the orders of British intelligence to spy on revolutionary elements in the city. In January 1914 Crowley and Neuburg settled into an apartment in Paris, where the former was involved in the controversy surrounding Jacob Epstein's new monument to Oscar Wilde. Together Crowley and Neuburg performed the six-week "Paris Working", a period of intense ritual involving strong drug use in which they invoked the gods Mercury and Jupiter. As part of the ritual, the couple performed acts of sex magic together, at times being joined by journalist Walter Duranty. Inspired by the results of the Working, Crowley wrote "Liber Agapé", a treatise on sex magic. Following the Paris Working, Neuburg began to distance himself from Crowley, resulting in an argument in which Crowley cursed him.

By 1914 Crowley was living a hand-to-mouth existence, relying largely on donations from A∴A∴ members and dues payments made to O.T.O. In May he transferred ownership of Boleskine House to the MMM for financial reasons, and in July he went mountaineering in the Swiss Alps. During this time the First World War broke out.
After recuperating from a bout of phlebitis, Crowley set sail for the United States aboard the "RMS Lusitania" in October 1914. Arriving in New York City, he moved into a hotel and began earning money writing for the American edition of "Vanity Fair" and undertaking freelance work for the famed astrologer Evangeline Adams. In the city, he continued experimenting with sex magic, through the use of masturbation, female prostitutes, and male clients of a Turkish bathhouse; all of these encounters were documented in his diaries.
Professing to be of Irish ancestry and a supporter of Irish independence from Great Britain, Crowley began to espouse support for Germany in their war against Britain. He became involved in New York's pro-German movement, and in January 1915 German spy George Sylvester Viereck employed him as a writer for his propagandist paper, "The Fatherland", which was dedicated to keeping the US neutral in the conflict. In later years, detractors denounced Crowley as a traitor to Britain for this action. In reality, Crowley was a double agent, working for the British intelligence services to infiltrate and undermine Germany's operation in New York. Many of his articles in "The Fatherland" were hyperbolic, for instance comparing Kaiser Wilhelm II to Jesus Christ; in July 1915 he orchestrated a publicity stunt – reported on by "The New York Times" – in which he declared independence for Ireland in front of the Statue of Liberty; the real intention was to make the German lobby appear ridiculous in the eyes of the American public. It has been argued that he encouraged the German Navy to destroy the "Lusitania", informing them that it would ensure the US stayed out of the war, while in reality hoping that it would bring the US into the war on Britain's side.

Crowley entered into a relationship with Jeanne Robert Foster, with whom he toured the West Coast. In Vancouver, headquarters of the North American O.T.O., he met with Charles Stansfeld Jones and Wilfred Talbot Smith to discuss the propagation of Thelema on the continent. In Detroit he experimented with anhalonium at Parke-Davis, then visited Seattle, San Francisco, Santa Cruz, Los Angeles, San Diego, Tijuana, and the Grand Canyon, before returning to New York. There he befriended Ananda Coomaraswamy and his wife Alice Richardson; Crowley and Richardson performed sex magic in April 1916, following which she became pregnant and then miscarried. Later that year he took a "magical retirement" to a cabin by Lake Pasquaney owned by Evangeline Adams. There, he made heavy use of drugs and undertook a ritual after which he proclaimed himself "Master Therion". He also wrote several short stories based on J.G. Frazer's "The Golden Bough" and a work of literary criticism, "The Gospel According to Bernard Shaw".

In December he moved to New Orleans, his favourite US city, before spending February 1917 with evangelical Christian relatives in Titusville, Florida. Returning to New York City, he moved in with artist and A∴A∴ member Leon Engers Kennedy in May, learning of his mother's death. After the collapse of "The Fatherland", Crowley continued his association with Viereck, who appointed him contributing editor of arts journal "The International". Crowley used it to promote Thelema, but it soon ceased publication. He then moved to the studio apartment of Roddie Minor, who became his partner and Scarlet Woman. Through their rituals, which Crowley called "The Amalantrah Workings", he believed that they were contacted by a preternatural entity named Lam. The relationship soon ended.

In 1918, Crowley went on a magical retreat in the wilderness of Esopus Island on the Hudson River. Here, he began a translation of the "Tao Te Ching", painted Thelemic slogans on the riverside cliffs, and – he later claimed – experienced past life memories of being Ge Xuan, Pope Alexander VI, Alessandro Cagliostro, and Eliphas Levi. Back in New York City, he moved to Greenwich Village, where he took Leah Hirsig as his lover and next Scarlet Woman. He took up painting as a hobby, exhibiting his work at the Greenwich Village Liberal Club and attracting the attention of the "New York Evening World". With the financial assistance of sympathetic Freemasons, Crowley revived "The Equinox" with the first issue of volume III, known as "The Blue Equinox". He spent mid-1919 on a climbing holiday in Montauk before returning to London in December.

Now destitute and back in London, Crowley came under attack from the tabloid "John Bull", which labelled him traitorous "scum" for his work with the German war effort; several friends aware of his intelligence work urged him to sue, but he decided not to. When he was suffering from asthma, a doctor prescribed him heroin, to which he soon became addicted. In January 1920, he moved to Paris, renting a house in Fontainebleau with Leah Hirsig; they were soon joined in a "ménage à trois" by Ninette Shumway, and also (in living arrangement) by Leah's newborn daughter Anne "Poupée" Leah. Crowley had ideas of forming a community of Thelemites, which he called the Abbey of Thelema after the Abbaye de Thélème in François Rabelais' satire "Gargantua and Pantagruel". After consulting the "I Ching", he chose Cefalù (on Sicily, Italy) as a location, and after arriving there, began renting the old Villa Santa Barbara as his Abbey on 2 April.
Moving to the commune with Hirsig, Shumway, and their children Hansi, Howard, and Poupée, Crowley described the scenario as "perfectly happy ... my idea of heaven." They wore robes, and performed rituals to the sun god Ra at set times during the day, also occasionally performing the Gnostic Mass; the rest of the day they were left to follow their own interests. Undertaking widespread correspondences, Crowley continued to paint, wrote a commentary on "The Book of the Law", and revised the third part of "Book 4". He offered a libertine education for the children, allowing them to play all day and witness acts of sex magic. He occasionally travelled to Palermo to visit rent boys and buy supplies, including drugs; his heroin addiction came to dominate his life, and cocaine began to erode his nasal cavity. There was no cleaning rota, and wild dogs and cats wandered throughout the building, which soon became unsanitary. Poupée died in October 1920, and Ninette gave birth to a daughter, Astarte Lulu Panthea, soon afterwards.

New followers continued to arrive at the Abbey to be taught by Crowley. Among them was film star Jane Wolfe, who arrived in July 1920, where she was initiated into the A∴A∴ and became Crowley's secretary. Another was Cecil Frederick Russell, who often argued with Crowley, disliking the same-sex sexual magic that he was required to perform, and left after a year. More conducive was the Australian Thelemite Frank Bennett, who also spent several months at the Abbey. In February 1922, Crowley returned to Paris for a retreat in an unsuccessful attempt to kick his heroin addiction. He then went to London in search of money, where he published articles in "The English Review" criticising the Dangerous Drugs Act 1920 and wrote a novel, "Diary of a Drug Fiend", completed in July. On publication, it received mixed reviews; he was lambasted by the "Sunday Express", which called for its burning and used its influence to prevent further reprints.

Subsequently, a young Thelemite named Raoul Loveday moved to the Abbey with his wife Betty May; while Loveday was devoted to Crowley, May detested him and life at the commune. She later said that Loveday was made to drink the blood of a sacrificed cat, and that they were required to cut themselves with razors every time they used the pronoun "I". Loveday drank from a local polluted stream, soon developing a liver infection resulting in his death in February 1923. Returning to London, May told her story to the press. "John Bull" proclaimed Crowley "the wickedest man in the world" and "a man we'd like to hang", and although Crowley deemed many of their accusations against him to be slanderous, he was unable to afford the legal fees to sue them. As a result, "John Bull" continued its attack, with its stories being repeated in newspapers throughout Europe and in North America. The Fascist government of Benito Mussolini learned of Crowley's activities and in April 1923 he was given a deportation notice forcing him to leave Italy; without him, the Abbey closed.

Crowley and Hirsig went to Tunis, where, dogged by continuing poor health, he unsuccessfully tried again to give up heroin, and began writing what he termed his "autohagiography", "The Confessions of Aleister Crowley". They were joined in Tunis by the Thelemite Norman Mudd, who became Crowley's public relations consultant. Employing a local boy, Mohammad ben Brahim, as his servant, Crowley went with him on a retreat to Nefta, where they performed sex magic together. In January 1924, Crowley travelled to Nice, France, where he met with Frank Harris, underwent a series of nasal operations, and visited the Institute for the Harmonious Development of Man and had a positive opinion of its founder, George Gurdjieff. Destitute, he took on a wealthy student, Alexander Zu Zolar, before taking on another American follower, Dorothy Olsen. Crowley took Olsen back to Tunisia for a magical retreat in Nefta, where he also wrote "To Man" (1924), a declaration of his own status as a prophet entrusted with bringing Thelema to humanity. After spending the winter in Paris, in early 1925 Crowley and Olsen returned to Tunis, where he wrote "The Heart of the Master" (1938) as an account of a vision he experienced in a trance. In March Olsen became pregnant, and Hirsig was called to take care of her; she miscarried, following which Crowley took Olsen back to France. Hirsig later distanced herself from Crowley, who then denounced her.

According to Crowley, Reuss had named him head of the O.T.O. upon his death, but this was challenged by a leader of the German O.T.O., Heinrich Tränker. Tränker called the Hohenleuben Conference in Thuringia, Germany, which Crowley attended. There, prominent members like Karl Germer and Martha Küntzel championed Crowley's leadership, but other key figures like Albin Grau, Oskar Hopfer, and Henri Birven backed Tränker by opposing it, resulting in a split in the O.T.O. Moving to Paris, where he broke with Olsen in 1926, Crowley went through a large number of lovers over the following years, with whom he experimented in sex magic. Throughout, he was dogged by poor health, largely caused by his heroin and cocaine addictions. In 1928, Crowley was introduced to young Englishman Israel Regardie, who embraced Thelema and became Crowley's secretary for the next three years. That year, Crowley also met Gerald Yorke, who began organising Crowley's finances but never became a Thelemite. He also befriended Thomas Driberg; Driberg did not accept Thelema either. It was here that Crowley also published one of his most significant works, "Magick in Theory and Practice", which received little attention at the time.

In December 1928 Crowley met the Nicaraguan Maria Teresa Sanchez. Crowley was deported from France by the authorities, who disliked his reputation and feared that he was a German agent. So that she could join him in Britain, Crowley married Sanchez in August 1929. Now based in London, Mandrake Press agreed to publish his autobiography in a limited edition six-volume set, also publishing his novel "Moonchild" and book of short stories "The Stratagem". Mandrake went into liquidation in November 1930, before the entirety of Crowley's "Confessions" could be published. Mandrake's owner P.R. Stephenson meanwhile wrote "The Legend of Aleister Crowley", an analysis of the media coverage surrounding him.

In April 1930, Crowley moved to Berlin, where he took Hanni Jaegar as his magical partner; the relationship was troubled. In September he went to Lisbon in Portugal to meet the poet Fernando Pessoa. There, he decided to fake his own death, doing so with Pessoa's help at the Boca do Inferno rock formation. He then returned to Berlin, where he reappeared three weeks later at the opening of his art exhibition at the Gallery Neumann-Nierendorf. Crowley's paintings fitted with the fashion for German Expressionism; few of them sold, but the press reports were largely favourable. In August 1931, he took Bertha Busch as his new lover; they had a violent relationship, and often physically assaulted one another. He continued to have affairs with both men and women while in the city, and met with famous people like Aldous Huxley and Alfred Adler. After befriending him, in January 1932 he took the communist Gerald Hamilton as a lodger, through whom he was introduced to many figures within the Berlin far left; it is possible that he was operating as a spy for British intelligence at this time, monitoring the communist movement.

Crowley left Busch and returned to London, where he took Pearl Brooksmith as his new Scarlet Woman. Undergoing further nasal surgery, it was here in 1932 that he was invited to be guest of honour at Foyles' Literary Luncheon, also being invited by Harry Price to speak at the National Laboratory of Psychical Research. In need of money, he launched a series of court cases against people whom he believed had libelled him, some of which proved successful. He gained much publicity for his lawsuit against Constable and Co for publishing Nina Hamnett's "Laughing Torso" (1932) – a book he thought libelled him – but lost the case. The court case added to Crowley's financial problems, and in February 1935 he was declared bankrupt. During the hearing, it was revealed that Crowley had been spending three times his income for several years.

Crowley developed a platonic friendship with Deidre Patricia O'Doherty; she offered to bear his child, who was born in May 1937. Named Randall Gair, Crowley nicknamed him Aleister Atatürk. Crowley continued to socialise with friends, holding curry parties in which he cooked particularly spicy food for them. In 1936, he published his first book in six years, "The Equinox of the Gods", which contained a facsimile of "The Book of the Law" and was considered to be volume III, number 3, of "The Equinox" periodical. The work sold well, resulting in a second print run. In 1937 he gave a series of public lectures on yoga in Soho. Crowley was now living largely off contributions supplied by the O.T.O.'s Agape Lodge in California, led by rocket scientist John Whiteside "Jack" Parsons. Crowley was intrigued by the rise of Nazism in Germany, and influenced by his friend Martha Küntzel believed that Adolf Hitler might convert to Thelema; when the Nazis abolished the German O.T.O. and imprisoned Germer, who fled to the US, Crowley then lambasted Hitler as a black magician.

When the Second World War broke out, Crowley wrote to the Naval Intelligence Division offering his services, but they declined. He associated with a variety of figures in Britain's intelligence community at the time, including Dennis Wheatley, Roald Dahl, Ian Fleming, and Maxwell Knight, and claimed to have been behind the "V for Victory" sign first used by the BBC; this has never been proven.
In 1940, his asthma worsened, and with his German-produced medication unavailable, he returned to using heroin, once again becoming addicted. As the Blitz hit London, Crowley relocated to Torquay, where he was briefly hospitalised with asthma, and entertained himself with visits to the local chess club. Tiring of Torquay, he returned to London, where he was visited by American Thelemite Grady McMurtry, to whom Crowley awarded the title of "Hymenaeus Alpha". He stipulated that though Germer would be his immediate successor, McMurty should succeed Germer as head of the O.T.O. after the latter's death. With O.T.O. initiate Lady Frieda Harris, Crowley developed plans to produce a tarot card set, designed by him and painted by Harris. Accompanying this was a book, published in a limited edition as "The Book of Thoth" by Chiswick Press in 1944. To aid the war effort, he wrote a proclamation on the rights of humanity, "Liber Oz", and a poem for the liberation of France, "Le Gauloise". Crowley's final publication during his lifetime was a book of poetry, "Olla: An Anthology of Sixty Years of Song". Another of his projects, "Aleister Explains Everything", was posthumously published as "Magick Without Tears".

In April 1944 Crowley briefly moved to Aston Clinton in Buckinghamshire, where he was visited by the poet Nancy Cunard, before relocating to Hastings in Sussex, where he took up residence at the Netherwood boarding house. He took a young man named Kenneth Grant as his secretary, paying him in magical teaching rather than wages. He was also introduced to John Symonds, whom he appointed to be his literary executor; Symonds thought little of Crowley, later publishing negative biographies of him. Corresponding with the illusionist Arnold Crowther, it was through him that Crowley was introduced to Gerald Gardner, the future founder of Gardnerian Wicca. They became friends, with Crowley authorising Gardner to revive Britain's ailing O.T.O. Another visitor was Eliza Marian Butler, who interviewed Crowley for her book "The Myth of the Magus". Other friends and family also spent time with him, among them Doherty and Crowley's son Aleister Atatürk. On 1 December 1947, Crowley died at Netherwood of chronic bronchitis aggravated by pleurisy and myocardial degeneration, aged 72. His funeral was held at a Brighton crematorium on 5 December; about a dozen people attended, and Louis Wilkinson read excerpts from the Gnostic Mass, "The Book of the Law", and "Hymn to Pan". The funeral generated press controversy, and was labelled a Black Mass by the tabloids. Crowley's ashes were sent to Karl Germer in the US, who buried them in his garden in Hampton, New Jersey.

Crowley's belief system, Thelema, has been described by scholars as a religion, and more specifically as both a new religious movement, and as a "magico-religious doctrine". It has also been characterised as a form of esotericism and modern Paganism. Although holding "The Book of the Law"—which was composed in 1904—as its central text, Thelema took shape as a complete system in the years after 1904.

In his autobiography, Crowley claimed that his purpose in life had been to "bring oriental wisdom to Europe and to restore paganism in a purer form", although what he meant by "paganism" was unclear.
Crowley's thought was not always cohesive, and was influenced by a variety of sources, ranging from eastern religious movements and practices like Hindu yoga and Buddhism, scientific naturalism, and various currents within Western esotericism, among them ceremonial magic, alchemy, astrology, Rosicrucianism, Kabbalah, and the Tarot. He was steeped in the esoteric teachings he had learned from the Hermetic Order of the Golden Dawn, although pushed further with his own interpretations and strategies than the Golden Dawn had done. Crowley incorporated concepts and terminology from South Asian religious traditions like yoga and Tantra into his Thelemic system, believing that there was a fundamental underlying resemblance between Western and Eastern spiritual systems.
The historian Alex Owen noted that Crowley adhered to the "modus operandi" of the Decadent movement throughout his life.

Crowley believed that the twentieth century marked humanity's entry to the Aeon of Horus, a new era in which humans would take increasing control of their destiny. He believed that this Aeon follows on from the Aeon of Osiris, in which paternalistic religions like Christianity, Islam, and Buddhism dominated the world, and that this in turn had followed the Aeon of Isis, which had been maternalistic and dominated by goddess worship. He believed that Thelema was the proper religion of the Aeon of Horus, and also deemed himself to be the prophet of this new Aeon. Thelema revolves around the idea that human beings each have their own True Will that they should discover and pursue, and that this exists in harmony with the Cosmic Will that pervades the universe. Crowley referred to this process of searching and discovery of one's True Will to be "the Great Work" or the attaining of the "knowledge and conversation of the Holy Guardian Angel". His favoured method of doing so was through the performance of the Abramelin operation, a ceremonial magic ritual obtained from a 17th-century grimoire. The moral code of "Do What Thou Wilt" is believed by Thelemites to be the religion's ethical law, although the historian of religion Marco Pasi noted that this was not anarchistic or libertarian in structure, as Crowley saw individuals as part of a wider societal organism.

Crowley believed in the objective existence of magic, which he chose to spell "Magick", an older archaic spelling of the word. He provided various different definitions of this term over his career. In his book "Magick in Theory and Practice", Crowley defined Magick as "the Science and Art of causing change to occur in conformity with Will". He also told his disciple Karl Germer that "Magick is getting into communication with individuals who exist on a higher plane than ours. Mysticism is the raising of oneself to their level." Crowley saw Magick as a third way between religion and science, giving "The Equinox" the subtitle of "The Method of Science; the Aim of Religion". Within that journal he expressed positive sentiments toward science and the scientific method, and urged magicians to keep detailed records of their magical experiments, "The more scientific the record is, the better." His understanding of magic was also influenced by the work of the anthropologist James Frazer, in particular the view that magic was a precursor to science in a cultural evolutionary framework. Unlike Frazer, however, Crowley did not see magic as a survival from the past that required eradication, but rather he believed that magic had to be adapted to suit the new age of science.

Sexuality played an important role in Crowley's ideas about magick and his practice of it, and has been described as being central to Thelema. He outlined three forms of sex magick—the autoerotic, homosexual, and heterosexual—and argued that such acts could be used to focus the magician's will onto a specific goal such as financial gain or personal creative success. For Crowley, sex was treated as a sacrament, with the consumption of sexual fluids interpreted as a Eucharist. This was often manifested as the Cakes of Light, a biscuit containing either menstrual blood or a mixture of semen and vaginal fluids. The Gnostic Mass is the central religious ceremony within Thelema.

Crowley's theological beliefs were not clear. The historian Ronald Hutton noted that some of Crowley's writings could be used to argue that he was an atheist, while some support the idea that he was a polytheist, and others would bolster the idea that he was a mystical monotheist. On the basis of the teachings in "The Book of the Law", Crowley described a pantheon of three deities taken from the ancient Egyptian pantheon: Nuit, Hadit, and Ra-Hoor-Khuit. In 1928, he made the claim that all "true" deities were "derived" from this trinity.

Both during his life and after it, Crowley has been widely described as a Satanist, usually by detractors. Crowley stated he did not consider himself a Satanist, nor did he worship Satan, as he did not accept the Christian world view in which Satan was believed to exist. He nevertheless used Satanic imagery, for instance by describing himself as "the Beast 666" and referring to the Whore of Babylon in his work, while in later life he sent "Antichristmas cards" to his friends. In his writings, Crowley occasionally identified Aiwass as Satan and designated him as "Our Lord God the Devil" at one occasion. The scholar of religion Gordan Djurdjevic stated that Crowley "was emphatically not" a Satanist, "if for no other reason than simply because he did not identify himself as such". Crowley nevertheless expressed anti-Christian sentiment, stating that he hated Christianity "as Socialists hate soap", an animosity likely stemming from his experiences among the Plymouth Brethren. He was also accused of advocating human sacrifice, largely because of a passage in "Book 4" in which he stated that "A male child of perfect innocence and high intelligence is the most satisfactory victim" and added that he had sacrificed about 150 every year. This was a tongue-in-cheek reference to ejaculation, something not realised by his critics, thus reflecting their own "ignorance and prejudice" toward Crowley.

Crowley considered himself to be one of the outstanding figures of his time. The historian Ronald Hutton stated that in Crowley's youth, he was "a self-indulgent and flamboyant young man" who "set about a deliberate flouting and provocation of social and religious norms", while being shielded from an "outraged public opinion" by his inherited wealth. Hutton also described Crowley as having both an "unappeasable desire" to take control of any organisation that he belonged to, and "a tendency to quarrel savagely" with those who challenged him. Crowley biographer Martin Booth asserted that Crowley was "self-confident, brash, eccentric, egotistic, highly intelligent, arrogant, witty, wealthy, and, when it suited him, cruel". Similarly, Richard Spence noted that Crowley was "capable of immense physical and emotional cruelty". Biographer Lawrence Sutin noted that Crowley exhibited "courage, skill, dauntless energy, and remarkable focus of will" while at the same time showing a "blind arrogance, petty fits of bile, [and] contempt for the abilities of his fellow men". The Thelemite Lon Milo DuQuette noted that Crowley "was by no means perfect" and "often alienated those who loved him dearest."
Crowley enjoyed being outrageous and flouting conventional morality, with John Symonds noting that he "was in revolt against the moral and religious values of his time". Crowley's political thought was studied by academic Marco Pasi, who noted that for Crowley, socio-political concerns were subordinate to metaphysical and spiritual ones. He was neither on the political left nor right but perhaps best categorised as a "conservative revolutionary" despite not being affiliated with the German-based conservative revolutionary movement. Pasi described Crowley's affinity to the extreme ideologies of Nazism and Marxism–Leninism, which aimed to violently overturn society: "What Crowley liked about Nazism and communism, or at least what made him curious about them, was the anti-Christian position and the revolutionary and socially subversive implications of these two movements. In their subversive powers, he saw the possibility of an annihilation of old religious traditions, and the creation of a void that Thelema, subsequently, would be able to fill." Crowley described democracy as an "imbecile and nauseating cult of weakness", and commented that "The Book of the Law" proclaimed that "there is the master and there is the slave; the noble and the serf; the 'lone wolf' and the herd". In this attitude he was influenced by the work of Friedrich Nietzsche and by Social Darwinism. Although he had contempt for most of the British aristocracy, he regarded himself as an aristocrat and styled himself as Laird Boleskine, once describing his ideology as "aristocratic communism".

Crowley was bisexual, and exhibited a sexual preference for women, with his homosexual relationships being fewer and clustered in the early part of his life. In particular he had an attraction toward "exotic women", and claimed to have fallen in love on multiple occasions; Kaczynski stated that "when he loved, he did so with his whole being, but the passion was typically short-lived". Even in later life, Crowley was able to attract young bohemian women to be his lovers, largely due to his charisma. During homosexual anal intercourse, he usually played the passive role, which Booth believed "appealed to his masochistic side". Crowley argued that homosexual and bisexual people should not suppress their sexual orientation, commenting that a person "must not be ashamed or afraid of being homosexual if he happens to be so at heart; he must not attempt to violate his own true nature because of public opinion, or medieval morality, or religious prejudice which would wish he were otherwise." On other issues he adopted a more conservative attitude; he opposed abortion on moral grounds, believing that no woman following her True Will would ever desire one.

Biographer Lawrence Sutin stated that "blatant bigotry is a persistent minor element in Crowley's writings". Sutin thought Crowley "a spoiled scion of a wealthy Victorian family who embodied many of the worst John Bull racial and social prejudices of his upper-class contemporaries", noting that he "embodied the contradiction that writhed within many Western intellectuals of the time: deeply held racist viewpoints courtesy of society, coupled with a fascination with people of colour". Crowley insulted his close Jewish friend Victor Neuburg using anti-Semitic slurs and he had mixed opinions about Jews as a group. Although he praised their "sublime" poetry and stated that they exhibited "imagination, romance, loyalty, probity and humanity", he also thought that centuries of persecution had led some Jews to exhibit "avarice, servility, falseness, cunning and the rest". He was also known to praise various ethnic and cultural groups, for instance he thought that the Chinese people exhibited a "spiritual superiority" to the English, and praised Muslims for exhibiting "manliness, straightforwardness, subtlety, and self-respect".

Crowley also exhibited a "general misogyny" that Booth believed arose from his bad relationship with his mother. Sutin noted that Crowley "largely accepted the notion, implicitly embodied in Victorian sexology, of women as secondary social beings in terms of intellect and sensibility". Crowley described women as "moral inferiors" who had to be treated with "firmness, kindness and justice".

Crowley has remained an influential figure, both amongst occultists and in popular culture, particularly that of Britain, but also of other parts of the world. In 2002, a BBC poll placed Crowley seventy-third in a list of the 100 Greatest Britons. Richard Cavendish has written of him that "In native talent, penetrating intelligence and determination, Aleister Crowley was the best-equipped magician to emerge since the seventeenth century." The scholar of esotericism Egil Asprem described him as "one of the most well-known figures in modern occultism". The scholar of esotericism Wouter Hanegraaff asserted that Crowley was an extreme representation of "the dark side of the occult", adding that he was "the most notorious occultist magician of the twentieth century". The philosopher John Moore opined that Crowley stood out as a "Modern Master" when compared with other prominent occult figures like George Gurdjieff, P.D. Ouspensky, Rudolf Steiner, or Helena Blavatsky, also describing him as a "living embodiment" of Oswald Spengler's "Faustian Man".
Biographer Tobias Churton considered Crowley "a pioneer of consciousness research". Hutton noted that Crowley had "an important place in the history of modern Western responses to Oriental spiritual traditions", while Sutin thought that he had made "distinctly original contributions" to the study of yoga in the West.

Thelema continued to develop and spread following Crowley's death. In 1969, the O.T.O. was reactivated in California under the leadership of Grady Louis McMurtry; in 1985 its right to the title was unsuccessfully challenged in court by a rival group, the Society Ordo Templi Orientis, led by Brazilian Thelemite Marcelo Ramos Motta.
Another American Thelemite was the filmmaker Kenneth Anger, who had been influenced by Crowley's writings from a young age. In the United Kingdom, Kenneth Grant propagated a tradition known as Typhonian Thelema through his organisation, the Typhonian O.T.O., later renamed the Typhonian Order.
Also in Britain, an occultist known as Amado Crowley claimed to be Crowley's son; this has been refuted by academic investigation. Amado argued that Thelema was a false religion created by Crowley to hide his true esoteric teachings, which Amado claimed to be propagating.

Several Western esoteric traditions other than Thelema were also influenced by Crowley, with Djurdjevic observing that "Crowley's influence on twentieth-century and contemporary esotericism has been enormous". Gerald Gardner, founder of Gardnerian Wicca, made use of much of Crowley's published material when composing the Gardnerian ritual liturgy, and the Australian witch Rosaleen Norton was also heavily influenced by Crowley's ideas. More widely, Crowley became "a dominant figure" in the modern Pagan community. L. Ron Hubbard, the American founder of Scientology, was involved in Thelema in the early 1940s (with Jack Parsons), and it has been argued that Crowley's ideas influenced some of Hubbard's work. The scholars of religion Asbjørn Dyrendel, James R. Lewis, and Jesper Petersen noted that despite the fact that Crowley was not a Satanist, he "in many ways embodies the pre-Satanist esoteric discourse on Satan and Satanism through his lifestyle and his philosophy", with his "image and ought" becoming an "important influence" on the later development of religious Satanism. For instance, two prominent figures in religious Satanism, Anton LaVey and Michael Aquino, were influenced by Crowley's work.

Crowley also had a wider influence in British popular culture. After his time in Cefalu which had brought him to public attention in Britain, various "literary Crowleys" appeared; characters in fiction based upon him. One of the earliest was the character of the poet Shelley Arabin in John Buchan's 1926 novel "The Dancing Floor". In his novel "The Devil Rides Out", the writer Dennis Wheatley used Crowley as a partial basis for the character of Damien Morcata, a portly bald defrocked priest who engages in black magic. The occultist Dion Fortune used Crowley as a basis for characters in her books "The Secrets of Doctor Taverner" (1926) and "The Winged Bull" (1935). He was included as one of the figures on the cover art of The Beatles' album "Sgt. Pepper's Lonely Hearts Club Band" (1967), and his motto of "Do What Thou Wilt" was inscribed on the vinyl of Led Zeppelin's album "Led Zeppelin III" (1970). Led Zeppelin co-founder Jimmy Page bought Boleskine in 1971, and part of the band's film "The Song Remains the Same" was filmed in the grounds. He sold it in 1992. David Bowie made reference to Crowley in the lyrics of his song "Quicksand" (1971), while Ozzy Osbourne and his lyricist Bob Daisley wrote a song titled "Mr Crowley" (1980). Crowley began to receive scholarly attention from academics in the late 1990s.



</doc>
<doc id="1178" url="https://en.wikipedia.org/wiki?curid=1178" title="Afterlife">
Afterlife

The afterlife (also referred to as life after death or the hereafter) is the belief that an essential part of an individual's identity or the stream of consciousness continues to manifest after the death of the physical body. According to various ideas about the afterlife, the essential aspect of the individual that lives on after death may be some partial element, or the entire soul or spirit, of an individual, which carries with it and may confer personal identity or, on the contrary, may not, as in Indian nirvana. Belief in an afterlife, which may be naturalistic or supernatural, is in contrast to the belief in oblivion after death.

In some views, this continued existence often takes place in a spiritual realm, and in other popular views, the individual may be reborn into this world and begin the life cycle over again, likely with no memory of what they have done in the past. In this latter view, such rebirths and deaths may take place over and over again continuously until the individual gains entry to a spiritual realm or Otherworld. Major views on the afterlife derive from religion, esotericism and metaphysics.

Some belief systems, such as those in the Abrahamic tradition, hold that the dead go to a specific plane of existence after death, as determined by God, or other divine judgment, based on their actions or beliefs during life. In contrast, in systems of reincarnation, such as those in the Indian religions, the nature of the continued existence is determined directly by the actions of the individual in the ended life, rather than through the decision of different being.
Theists generally believe some type of afterlife awaits people when they die. Members of some generally non-theistic religions tend to believe in an afterlife, but without reference to a deity. The Sadducees were an ancient Jewish sect that generally believed that there was a God but no afterlife.

Many religions, whether they believe in the soul's existence in another world like Christianity, Islam and many pagan belief systems, or in reincarnation like many forms of Hinduism and Buddhism, believe that one's status in the afterlife is a reward or punishment for their conduct during life.

Reincarnation is the philosophical or religious concept that an aspect of a living being starts a new life in a different physical body or form after each biological death. It is also called rebirth or transmigration, and is a part of the Saṃsāra doctrine of cyclic existence. It is a central tenet of all major Indian religions, namely Buddhism, Hinduism, Jainism, and Sikhism. The idea of reincarnation is found in many ancient cultures, and a belief in rebirth/metempsychosis was held by Greek historic figures, such as Pythagoras, Socrates, and Plato. It is also a common belief of various ancient and modern religions such as Spiritism, Theosophy, and Eckankar and is found as well in many tribal societies around the world, in places such as Australia, East Asia, Siberia, and South America.

Although the majority of denominations within the Abrahamic religions of Judaism, Christianity, and Islam do not believe that individuals reincarnate, particular groups within these religions do refer to reincarnation; these groups include the mainstream historical and contemporary followers of Kabbalah, the Cathars, Alawites, the Druze, and the Rosicrucians. The historical relations between these sects and the beliefs about reincarnation that were characteristic of Neoplatonism, Orphism, Hermeticism, Manicheanism, and Gnosticism of the Roman era as well as the Indian religions have been the subject of recent scholarly research. Unity Church and its founder Charles Fillmore teach reincarnation.

Rosicrucians speak of a life review period occurring immediately after death and before entering the afterlife's planes of existence (before the silver cord is broken), followed by a judgment, more akin to a final review or end report over one's life.

Heaven, the heavens, seven heavens, pure lands, Tian, Jannah, Valhalla, or the Summerland, is a common religious, cosmological, or transcendent place where beings such as gods, angels, jinn, saints, or venerated ancestors are said to originate, be enthroned, or live. According to the beliefs of some religions, heavenly beings can descend to earth or incarnate, and earthly beings can ascend to Heaven in the afterlife, or in exceptional cases enter Heaven alive.

Heaven is often described as a "higher place", the holiest place, a Paradise, in contrast to Hell or the Underworld or the "low places", and universally or conditionally accessible by earthly beings according to various standards of divinity, goodness, piety, faith or other virtues or right beliefs or simply the will of God. Some believe in the possibility of a Heaven on Earth in a World to Come. 

In Indian religions, Heaven is considered as "Svarga loka". There are seven positive regions the soul can go to after death and seven negative regions. After completing its stay in the respective region, the soul is subjected to rebirth in different living forms according to its "karma". This cycle can be broken after a soul achieves "Moksha" or "Nirvana". Any place of existence, either of humans, souls or deities, outside the tangible world (Heaven, Hell, or other) is referred to as "otherworld."

Hell, in many religious and folkloric traditions, is a place or state of torment and punishment in an afterlife. Religions with a linear divine history often depict hells as eternal destinations while Religions with a cyclic history often depict a hell as an intermediary period between incarnations. Typically these traditions locate hell in another dimension or under the Earth's surface and often include entrances to Hell from the land of the living. Other afterlife destinations include Heaven, Purgatory, Paradise, and Limbo.

Other traditions, which do not conceive of the afterlife as a place of punishment or reward, merely describe hell as an abode of the dead, the grave, a neutral place located under the surface of Earth (for example, see sheol and Hades).

The afterlife played an important role in Ancient Egyptian religion, and its belief system is one of the earliest known in recorded history. When the body died, parts of its soul known as "ka" (body double) and the "ba" (personality) would go to the Kingdom of the Dead. While the soul dwelt in the Fields of Aaru, Osiris demanded work as restitution for the protection he provided. Statues were placed in the tombs to serve as substitutes for the deceased.

Arriving at one's reward in afterlife was a demanding ordeal, requiring a sin-free heart and the ability to recite the spells, passwords and formulae of the Book of the Dead. In the Hall of Two Truths, the deceased's heart was weighed against the "Shu" feather of truth and justice taken from the headdress of the goddess Ma'at. If the heart was lighter than the feather, they could pass on, but if it were heavier they would be devoured by the demon Ammit.

Egyptians also believed that being mummified and put in a sarcophagus (an ancient Egyptian "coffin" carved with complex symbols and designs, as well as pictures and hieroglyphs) was the only way to have an afterlife. Only if the corpse had been properly embalmed and entombed in a mastaba, could the dead live again in the Fields of Yalu and accompany the Sun on its daily ride. Due to the dangers the afterlife posed, the Book of the Dead was placed in the tomb with the body as well as food, jewellery, and 'curses'. They also used the "opening of the mouth".

Ancient Egyptian civilization was based on religion; their belief in the rebirth after death became the driving force behind their funeral practices. Death was simply a temporary interruption, rather than complete cessation, of life, and that eternal life could be ensured by means like piety to the gods, preservation of the physical form through mummification, and the provision of statuary and other funerary equipment. Each human consisted of the physical body, the "ka", the "ba", and the "akh". The Name and Shadow were also living entities. To enjoy the afterlife, all these elements had to be sustained and protected from harm.

On March 30, 2010, a spokesman for the Egyptian Culture Ministry claimed it had unearthed a large red granite door in Luxor with inscriptions by User, a powerful adviser to the 18th dynasty Queen Hatshepsut who ruled between 1479 BC and 1458 BC, the longest of any woman. It believes the false door is a 'door to the Afterlife'. According to the archaeologists, the door was reused in a structure in Roman Egypt.

The Greek god Hades is known in Greek mythology as the king of the underworld, a place where souls live after death. The Greek god Hermes, the messenger of the gods, would take the dead soul of a person to the underworld (sometimes called Hades or the House of Hades). Hermes would leave the soul on the banks of the River Styx, the river between life and death.

Charon, also known as the ferry-man, would take the soul across the river to Hades, if the soul had gold: Upon burial, the family of the dead soul would put coins under the deceased's tongue. Once crossed, the soul would be judged by Aeacus, Rhadamanthus and King Minos. The soul would be sent to Elysium, Tartarus, Asphodel Fields, or the Fields of Punishment. The Elysian Fields were for the ones that lived pure lives. It consisted of green fields, valleys and mountains, everyone there was peaceful and contented, and the Sun always shone there. Tartarus was for the people that blasphemed against the gods, or were simply rebellious and consciously evil.

The Asphodel Fields were for a varied selection of human souls: Those whose sins equalled their goodness, were indecisive in their lives, or were not judged. The Fields of Punishment were for people that had sinned often, but not so much as to be deserving of Tartarus. In Tartarus, the soul would be punished by being burned in lava, or stretched on racks. Some heroes of Greek legend are allowed to visit the underworld. The Romans had a similar belief system about the afterlife, with Hades becoming known as Pluto. In the ancient Greek myth about the Labours of Heracles, the hero Heracles had to travel to the underworld to capture Cerberus, the three-headed guard dog, as one of his tasks.

In "Dream of Scipio", Cicero describes what seems to be an out of body experience, of the soul traveling high above the Earth, looking down at the small planet, from far away.

In Book VI of Virgil's "Aeneid", the hero, Aeneas, travels to the underworld to see his father. By the River Styx, he sees the souls of those not given a proper burial, forced to wait by the river until someone buries them. While down there, along with the dead, he is shown the place where the wrongly convicted reside, the fields of sorrow where those who committed suicide and now regret it reside, including Aeneas' former lover, the warriors and shades, Tartarus (where the titans and powerful non-mortal enemies of the Olympians reside) where he can hear the groans of the imprisoned, the palace of Pluto, and the fields of Elysium where the descendants of the divine and bravest heroes reside. He sees the river of forgetfulness, Lethe, which the dead must drink to forget their life and begin anew. Lastly, his father shows him all of the future heroes of Rome who will live if Aeneas fulfills his destiny in founding the city.

The Poetic and Prose Eddas, the oldest sources for information on the Norse concept of the afterlife, vary in their description of the several realms that are described as falling under this topic. The most well-known are:

She'ol, in the Hebrew Bible, is a place of darkness to which all the dead go, both the righteous and the unrighteous, regardless of the moral choices made in life, a place of stillness and darkness cut off from life and from God.

The inhabitants of Sheol are the "shades" ("rephaim"), entities without personality or strength. Under some circumstances they are thought to be able to be contacted by the living, as the Witch of Endor contacts the shade of Samuel for Saul, but such practices are forbidden (Deuteronomy 18:10).

While the Hebrew Bible appears to describe Sheol as the permanent place of the dead, in the Second Temple period (roughly 500 BC–70 AD) a more diverse set of ideas developed. In some texts, Sheol is considered to be the home of both the righteous and the wicked, separated into respective compartments; in others, it was considered a place of punishment, meant for the wicked dead alone. When the Hebrew scriptures were translated into Greek in ancient Alexandria around 200 BC, the word "Hades" (the Greek underworld) was substituted for Sheol. This is reflected in the New Testament where Hades is both the underworld of the dead and the personification of the evil it represents.

The Talmud offers a number of thoughts relating to the afterlife. After death, the soul is brought for judgment. Those who have led pristine lives enter immediately into the "Olam Haba" or world to come. Most do not enter the world to come immediately, but now experience a period of review of their earthly actions and they are made aware of what they have done wrong. Some view this period as being a "re-schooling", with the soul gaining wisdom as one's errors are reviewed. Others view this period to include spiritual discomfort for past wrongs. At the end of this period, not longer than one year, the soul then takes its place in the world to come. Although discomforts are made part of certain Jewish conceptions of the afterlife, the concept of "eternal damnation", so prevalent in other religions, is not a tenet of the Jewish afterlife. According to the Talmud, extinction of the soul is reserved for a far smaller group of malicious and evil leaders, either whose very evil deeds go way beyond norms, or who lead large groups of people to utmost evil.

Maimonides describes the "Olam Haba" in spiritual terms, relegating the prophesied physical resurrection to the status of a future miracle, unrelated to the afterlife or the Messianic era. According to Maimonides, an afterlife continues for the soul of every human being, a soul now separated from the body in which it was "housed" during its earthly existence.

The Zohar describes Gehenna not as a place of punishment for the wicked but as a place of spiritual purification for souls.

Although there is no reference to reincarnation in the Talmud or any prior writings, according to rabbis such as Avraham Arieh Trugman, reincarnation is recognized as being part and parcel of Jewish tradition. Trugman explains that it is through oral tradition that the meanings of the Torah, its commandments and stories, are known and understood. The classic work of Jewish mysticism, the Zohar, is quoted liberally in all Jewish learning; in the Zohar the idea of reincarnation is mentioned repeatedly. Trugman states that in the last five centuries the concept of reincarnation, which until then had been a much hidden tradition within Judaism, was given open exposure.

Shraga Simmons commented that within the Bible itself, the idea [of reincarnation] is intimated in Deut. 25:5-10, Deut. 33:6 and Isaiah 22:14, 65:6.

Yirmiyahu Ullman wrote that reincarnation is an "ancient, mainstream belief in Judaism". The Zohar makes frequent and lengthy references to reincarnation. Onkelos, a righteous convert and authoritative commentator of the same period, explained the verse, "Let Reuben live and not die ..." (Deuteronomy 33:6) to mean that Reuben should merit the World to Come directly, and not have to die again as a result of being reincarnated. Torah scholar, commentator and kabbalist, Nachmanides (Ramban 1195–1270), attributed Job's suffering to reincarnation, as hinted in Job's saying "God does all these things twice or three times with a man, to bring back his soul from the pit to ... the light of the living' (Job 33:29,30)."

Reincarnation, called "gilgul", became popular in folk belief, and is found in much Yiddish literature among Ashkenazi Jews. Among a few kabbalists, it was posited that some human souls could end up being reincarnated into non-human bodies. These ideas were found in a number of Kabbalistic works from the 13th century, and also among many mystics in the late 16th century. Martin Buber's early collection of stories of the Baal Shem Tov's life includes several that refer to people reincarnating in successive lives.

Among well known (generally non-kabbalist or anti-kabbalist) rabbis who rejected the idea of reincarnation are Saadia Gaon, David Kimhi, Hasdai Crescas, Yedayah Bedershi (early 14th century), Joseph Albo, Abraham ibn Daud, the Rosh and Leon de Modena. Saadia Gaon, in Emunoth ve-Deoth (Hebrew: "beliefs and opinions") concludes Section VI with a refutation of the doctrine of metempsychosis (reincarnation). While refuting reincarnation, Saadia Gaon further states that Jews who hold to reincarnation have adopted non-Jewish beliefs. By no means do all Jews today believe in reincarnation, but belief in reincarnation is not uncommon among many Jews, including Orthodox.

Other well-known rabbis who are reincarnationists include Yonassan Gershom, Abraham Isaac Kook, Talmud scholar Adin Steinsaltz, DovBer Pinson, David M. Wexelman, Zalman Schachter, and many others. Reincarnation is cited by authoritative biblical commentators, including Ramban (Nachmanides), Menachem Recanti and Rabbenu Bachya.

Among the many volumes of Yitzchak Luria, most of which come down from the pen of his primary disciple, Chaim Vital, are insights explaining issues related to reincarnation. His "Shaar HaGilgulim", "The Gates of Reincarnation", is a book devoted exclusively to the subject of reincarnation in Judaism.

Rabbi Naftali Silberberg of The Rohr Jewish Learning Institute notes that "Many ideas that originate in other religions and belief systems have been popularized in the media and are taken for granted by unassuming Jews."

Mainstream Christianity professes belief in the Nicene Creed, and English versions of the Nicene Creed in current use include the phrase: "We look for the resurrection of the dead, and the life of the world to come." Although punishments are made part of certain Christian conceptions of the afterlife, the prevalent concept of "eternal damnation" is a tenet of the Christian afterlife.

When questioned by the Sadducees about the resurrection of the dead (in a context relating to who one's spouse would be if one had been married several times in life), Jesus said that marriage will be irrelevant after the resurrection as the resurrected will be like the angels in heaven.

Jesus also maintained that the time would come when the dead would hear the voice of the Son of God, and all who were in the tombs would come out, who have done good deeds to the resurrection of life, but those who have done wicked deeds to the resurrection of condemnation.

The Book of Enoch describes Sheol as divided into four compartments for four types of the dead: the faithful saints who await resurrection in Paradise, the merely virtuous who await their reward, the wicked who await punishment, and the wicked who have already been punished and will not be resurrected on Judgment Day. The Book of Enoch is considered apocryphal by most denominations of Christianity and all denominations of Judaism.

The book of 2 Maccabees gives a clear account of the dead awaiting a future resurrection and judgment, plus prayers and offerings for the dead to remove the burden of sin.
The author of Luke recounts the story of Lazarus and the rich man, which shows people in Hades awaiting the resurrection either in comfort or torment. The author of the Book of Revelation writes about God and the angels versus Satan and demons in an epic battle at the end of times when all souls are judged. There is mention of ghostly bodies of past prophets, and the transfiguration.

The non-canonical Acts of Paul and Thecla speak of the efficacy of prayer for the dead, so that they might be "translated to a state of happiness".

Hippolytus of Rome pictures the underworld (Hades) as a place where the righteous dead, awaiting in the bosom of Abraham their resurrection, rejoice at their future prospect, while the unrighteous are tormented at the sight of the "lake of unquenchable fire" into which they are destined to be cast.

Gregory of Nyssa discusses the long-before believed possibility of purification of souls after death.

Pope Gregory I repeats the concept, articulated over a century earlier by Gregory of Nyssa that the saved suffer purification after death, in connection with which he wrote of "purgatorial flames".

The noun "purgatorium" (Latin: place of cleansing) is used for the first time to describe a state of painful purification of the saved after life. The same word in adjectival form ("purgatorius -a -um", cleansing), which appears also in non-religious writing, was already used by Christians such as Augustine of Hippo and Pope Gregory I to refer to an after-death cleansing.

During the Age of Enlightenment, theologians and philosophers presented various philosophies and beliefs. A notable example is Emanuel Swedenborg who wrote some 18 theological works which describe in detail the nature of the afterlife according to his claimed spiritual experiences, the most famous of which is "Heaven and Hell". His report of life there covers a wide range of topics, such as marriage in heaven (where all angels are married), children in heaven (where they are raised by angel parents), time and space in heaven (there are none), the after-death awakening process in the World of Spirits (a place halfway between Heaven and Hell and where people first wake up after death), the allowance of a free will choice between Heaven or Hell (as opposed to being sent to either one by God), the eternity of Hell (one could leave but would never want to), and that all angels or devils were once people on earth.

On the other hand, the enlightenment produced more rationalist philosophies such as deism. Many deist freethinkers held that belief in an afterlife with reward and punishment was a necessity of reason and good morals.

Some Christians deny that entry into Heaven can be properly earned, rather it is a gift that is solely God's to give through his unmerited grace. They underlie this belief to a passage from St. Paul: "For it is by grace you have been saved, through faith—and this not from yourselves, it is the gift of God, not by works, so that no one can boast." Since the Protestant Reformation, Lutheran and Calvinist theological traditions emphasize the necessity of God's undeserved grace for salvation, and reject so-called Pelagianism, which would make man earn salvation through good works. Other Christians do not accept this doctrine, leading to many controversies on grace and free will, and the idea of predestination. In particular, the belief that heaven is a reward for good behavior is a common folk belief in Christian societies, even among members of churches which reject that belief.

Some Christian believers have come to downplay the punishment of hell. Universalists teach that salvation is for all. Jehovah's Witnesses and Seventh-day Adventists teach that sinners are destroyed rather than tortured forever. John 3:16 says that only those that accept Jesus will be given eternal life, so the people that do not accept him cannot burn in hell for eternity because Jesus has not given them eternal life, instead it says they will perish.

In American pop culture depictions of Heaven, particularly in vintage cartoons such as those by Looney Tunes in the mid-20th century, the souls of virtuous people ascend to Heaven and are converted into angels. However, this is not in accordance with the orthodox Christian theology. Christianity depicts a sharp distinction between "angels", divine beings created by God before the creation of humanity and are used as messengers, and "saints", the souls of humans who have received immortality from the grace of God through faith in Jesus Christ of Nazareth, who dwell in Heaven with God.

Latter Day Saints believe that the soul existed before earth life and will exist in the hereafter. Angels are either spirits that have not yet come to earth to experience their mortality, or spirits or resurrected beings that have already passed through mortality and do the will of God. See Job 38:4-7, D&C 93:29. According to LDS Doctrine, Michael the Archangel became the first man on earth, Adam, to experience his mortality. The Angel of Moroni visited the boy, Joseph Smith, after living out his mortal life in ancient America. Later, he received Angelic administrations from the Apostles Peter, James, and John, John the Baptist, and others.

The Catholic conception of the afterlife teaches that after the body dies, the soul is judged, the righteous and free of sin enter Heaven. However, those who die in unrepented mortal sin go to hell. In the 1990s, the Catechism of the Catholic Church defined hell not as punishment imposed on the sinner but rather as the sinner's self-exclusion from God. Unlike other Christian groups, the Catholic Church teaches that those who die in a state of grace, but still carry venial sin go to a place called Purgatory where they undergo purification to enter Heaven.

Despite popular opinion, Limbo, which was elaborated upon by theologians beginning in the Middle Ages, was never recognized as a dogma of the Catholic Church, yet, at times, it has been a very popular theological theory within the Church. Limbo is a theory that unbaptized but innocent souls, such as those of infants, virtuous individuals who lived before Jesus Christ was born on earth, or those that die before baptism exist in neither Heaven or Hell proper. Therefore, these souls neither merit the beatific vision, nor are subjected to any punishment, because they are not guilty of any personal sin although they have not received baptism, so still bear original sin. So they are generally seen as existing in a state of natural, but not supernatural, happiness, until the end of time.

In other Christian denominations it has been described as an intermediate place or state of confinement in oblivion and neglect.

The notion of purgatory is associated particularly with the Catholic Church. In the Catholic Church, all those who die in God's grace and friendship, but still imperfectly purified, are indeed assured of their eternal salvation; but after death they undergo purification, so as to achieve the holiness necessary to enter the joy of heaven or the final purification of the elect, which is entirely different from the punishment of the damned. The tradition of the church, by reference to certain texts of scripture, speaks of a "cleansing fire" although it is not always called purgatory.

Anglicans of the Anglo-Catholic tradition generally also hold to the belief. John Wesley, the founder of Methodism, believed in an intermediate state between death and the resurrection of the dead and in the possibility of "continuing to grow in holiness there", but Methodism does not officially affirm this belief and denies the possibility of helping by prayer any who may be in that state.

The Orthodox Church is intentionally reticent on the afterlife, as it acknowledges the mystery especially of things that have not yet occurred. Beyond the second coming of Jesus, bodily resurrection, and final judgment, all of which is affirmed in the Nicene Creed (325 CE), Orthodoxy does not teach much else in any definitive manner. Unlike Western forms of Christianity, however, Orthodoxy is traditionally non-dualist and does not teach that there are two separate literal locations of heaven and hell, but instead acknowledges that "the 'location' of one’s final destiny—heaven or hell—as being figurative." Instead, Orthodoxy teaches that the final judgment is simply one's uniform encounter with divine love and mercy, but this encounter is experienced multifariously depending on the extent to which one has been transformed, partaken of divinity, and is therefore compatible or incompatible with God. "The monadic, immutable, and ceaseless object of eschatological encounter is therefore the love and mercy of God, his glory which infuses the heavenly temple, and it is the subjective human reaction which engenders multiplicity or any division of experience." For instance, St. Isaac the Syrian observes that "those who are punished in Gehenna, are scourged by the scourge of love. ... The power of love works in two ways: it torments sinners . . . [as] bitter regret. But love inebriates the souls of the sons of Heaven by its delectability." In this sense, the divine action is always, immutably, and uniformly love and if one experiences this love negatively, the experience is then one of self-condemnation because of free will rather than condemnation by God. Orthodoxy therefore uses the description of Jesus' judgment in John 3:19-21 as their model: "19 And this is the judgment: the light has come into the world, and people loved the darkness rather than the light because their works were evil. 20 For everyone who does wicked things hates the light and does not come to the light, lest his works should be exposed. 21 But whoever does what is true comes to the light, so that it may be clearly seen that his works have been carried out in God." As a characteristically Orthodox understanding, then, Fr. Thomas Hopko writes, "[I]t is precisely the presence of God’s mercy and love which cause the torment of the wicked. God does not punish; he forgives. . . . In a word, God has mercy on all, whether all like it or not. If we like it, it is paradise; if we do not, it is hell. Every knee will bend before the Lord. Everything will be subject to Him. God in Christ will indeed be "all and in all," with boundless mercy and unconditional pardon. But not all will rejoice in God’s gift of forgiveness, and that choice will be judgment, the self-inflicted source of their sorrow and pain."

Moreover, Orthodoxy includes a prevalent tradition of "apokatastasis", or the restoration of all things in the end. This has been taught most notably by Origen, but also many other Church fathers and Saints, including Gregory of Nyssa. The Second Council of Constantinople (553 C.E.) affirmed the orthodoxy of Gregory of Nyssa while simultaneously condemning Origen's brand of universalism because it taught the restoration back to our pre-existent state, which Orthodoxy doesn't teach. It is also a teaching of such eminent Orthodox theologians as Olivier Clément, Metropolitan Kallistos Ware, and Bishop Hilarion Alfeyev. Although apokatastasis is not a dogma of the church but instead a theologoumena, it is no less a teaching of the Orthodox Church than its rejection. As Met. Kallistos Ware explains, "It is heretical to say that all must be saved, for this is to deny free will; but, it is legitimate to hope that all may be saved," as insisting on torment without end also denies free will.

Joseph F. Smith of The Church of Jesus Christ of Latter-day Saints presents an elaborate vision of the afterlife. It is revealed as the scene of an extensive missionary effort by righteous spirits in paradise to redeem those still in darkness—a spirit prison or "hell" where the spirits of the dead remain until judgment. It is divided into two parts: Spirit Prison and Paradise. Together these are also known as the Spirit World (also Abraham's Bosom; see Luke 16:19-25). They believe that Christ visited spirit prison (1 Peter 3:18-20) and opened the gate for those who repent to cross over to Paradise. This is similar to the Harrowing of Hell doctrine of some mainstream Christian faiths. Both Spirit Prison and Paradise are temporary according to Latter-day Saint beliefs. After the resurrection, spirits are assigned "permanently" to three degrees of heavenly glory, determined by how they lived– Celestial, Terrestrial, and Telestial.(1 Cor 15:44-42; Doctrine and Covenants, Section 76) Sons of Perdition, or those who have known and seen God and deny it, will be sent to the realm of Satan, which is called Outer Darkness, where they shall live in misery and agony forever.

The Celestial Kingdom is believed to be a place where we can live eternally with our families. Progression does not end once one has entered the Celestial Kingdom, but it extends eternally. According to "True to the Faith" (a handbook on doctrines in the LDS faith), "The celestial kingdom is the place prepared for those who have "received the testimony of Jesus" and been "made perfect through Jesus the mediator of the new covenant, who wrought out this perfect atonement through the shedding of his own blood" (D&C 76:51, 69). To inherit this gift, we must receive the ordinances of salvation, keep the commandments, and repent of our sins."

Jehovah's Witnesses occasionally use terms such as "afterlife" to refer to any hope for the dead, but they understand Ecclesiastes 9:5 to preclude belief in an immortal soul. Individuals judged by God to be wicked, such as in the Great Flood or at Armageddon, are given no hope of an afterlife. However, they believe that after Armageddon there will be a bodily resurrection of "both righteous and unrighteous" dead (but not the "wicked"). Survivors of Armageddon and those who are resurrected are then to gradually restore earth to a paradise. After Armageddon, unrepentant sinners are punished with eternal death (non-existence).

The Seventh-day Adventist Church, teaches that the first death, or death brought about by living on a planet with sinful conditions (sickness, old age, accident, etc.) is a sleep of the soul. Adventists believe that the body + the breath of God = a living soul. Like Jehovah's Witnesses, Adventists use key phrases from the Bible, such as "For the living know that they shall die: but the dead know not any thing, neither have they any more a reward; for the memory of them is forgotten" (Eccl. 9:5 KJV). Adventists also point to the fact that the wage of sin is death and God alone is immortal. Adventists believe God will grant eternal life to the redeemed who are resurrected at Jesus' second coming. Until then, all those who have died are "asleep". When Jesus the Christ, who is the Word and the Bread of Life, comes a second time, the righteous will be raised incorruptible and will be taken in the clouds to meet their Lord. The righteous will live in heaven for a thousand years (the millennium) where they will sit with God in judgment over the unredeemed and the fallen angels. During the time the redeemed are in heaven, the Earth will be devoid of human and animal inhabitation. Only the fallen angels will be left alive. The second resurrection is of the unrighteous, when Jesus brings the New Jerusalem down from heaven to relocate to Earth. Jesus will call to life all those who are unrighteous. Satan and his angels will convince the unrighteous to surround the city, but hell fire and brimstone will fall from heaven and consume them, thus cleansing Earth of all sin. The universe will be then free from sin forever. This is called the second death. On the new earth God will provide an eternal home for all the redeemed and a perfect environment for everlasting life, where Eden will be restored. The great controversy will be ended and sin will be no more. God will reign in perfect harmony forever.(Rom. 6:23; 1 Tim. 6:15, 16; Eccl. 9:5, 6; Ps. 146:3, 4; John 11:11-14; Col. 3:4; 1 Cor. 15:51-54; 1 Thess. 4:13-17; John 5:28, 29; Rev. 20:1-10; Rev. 20; 1 Cor. 6:2, 3; Jer. 4:23-26; Rev. 21:1-5; Mal. 4:1; Eze. 28:18, 19; 2 Peter 3:13; Isa. 35; 65:17-25; Matt. 5:5; Rev. 21:1-7; 22:1-5; 11:15.)

The Islamic belief in the afterlife as stated in the Quran is descriptive. The Arabic word for Paradise is "Jannah" and Hell is "Jahannam". Their level of comfort while in the grave depends wholly on their level of "Iman" or faith in the one almighty creator or supreme being God or Allah. In order for one to achieve proper, firm and healthy Iman one must practice righteous deeds or else his level of Iman chokes and shrinks and eventually can wither away if one does not practice Islam long enough, hence the depth of practicing Islam is good deeds. One may also acquire "Tasbih" and recite the names of Allah in such manner as "SubahannAllah" or Glory be to Allah over and over again to acquire good deeds.

Islam teaches that the purpose of Man's entire creation is to worship the Creator of the Heavens and Earth (Allah) alone that includes being kind to other human beings and life including bugs, and to trees, by not oppressing them. Islam teaches that the life we live on Earth is nothing but a test for us and to determine each individual's ultimate abode be it punishment or "Jannat" in the afterlife, which is eternal and everlasting.

"Jannah" and "Jahannam" both have different levels. "Jannah" has eight gates and seven levels. The higher the level the better it is and the happier you are. "Jahannam" possess 7 deep terrible layers. The lower the layer the worse it is. Individuals will arrive at both everlasting homes during Judgment Day, which commences after the Angel Israfil blows the trumpet the second time. Islam teaches the continued existence of the soul and a transformed physical existence after death. Muslims believe there will be a day of judgment when all humans will be divided between the eternal destinations of Paradise and Hell.

In the 20th century, discussions about the afterlife address the interconnection between human action and divine judgment, the need for moral rectitude, and the eternal consequences of human action in this life and world.

A central doctrine of the Quran is the Last Day, on which the world will be destroyed and Allah will raise all people and jinn from the dead to be judged. The Last Day is also called the Day of Standing Up, Day of Separation, Day of Reckoning, Day of Awakening, Day of Judgment, The Encompassing Day or The Hour.

Until the Day of Judgment, deceased souls remain in their graves awaiting the resurrection. However, they begin to feel immediately a taste of their destiny to come. Those bound for hell will suffer in their graves, while those bound for heaven will be in peace until that time.

The resurrection that will take place on the Last Day is physical, and is explained by suggesting that God will re-create the decayed body (17:100: "Could they not see that God who created the heavens and the earth is able to create the like of them"?).

On the Last Day, resurrected humans and jinn will be judged by Allah according to their deeds. One's eternal destination depends on balance of good to bad deeds in life. They are either granted admission to Paradise, where they will enjoy spiritual and physical pleasures forever, or condemned to Hell to suffer spiritual and physical torment for eternity. The day of judgment is described as passing over Hell on a narrow bridge in order to enter Paradise. Those who fall, weighted by their bad deeds, will remain in Hell forever.

Ahmadi Muslims believe that the afterlife is not material but of a spiritual nature. According to Mirza Ghulam Ahmad, the founder of Ahmadiyya sect in Islam, the soul will give birth to another rarer entity and will resemble the life on this earth in the sense that this entity will bear a similar relationship to the soul as the soul bears relationship with the human existence on earth. On earth, if a person leads a righteous life and submits to the will of God, his or her tastes become attuned to enjoying spiritual pleasures as opposed to carnal desires. With this, an "embryonic soul" begins to take shape. Different tastes are said to be born which a person given to carnal passions finds no enjoyment. For example, sacrifice of one's own's rights over that of other's becomes enjoyable, or that forgiveness becomes second nature. In such a state a person finds contentment and Peace at heart and at this stage, according to Ahmadiyya beliefs, it can be said that a soul within the soul has begun to take shape.

The Sufi scholar Ibn 'Arabi defined Barzakh as the intermediate realm or "isthmus". It is between the world of corporeal bodies and the world of spirits, and is a means of contact between the two worlds. Without it, there would be no contact between the two and both would cease to exist. He described it as simple and luminous, like the world of spirits, but also able to take on many different forms just like the world of corporeal bodies can. In broader terms Barzakh, "is anything that separates two things". It has been called the dream world in which the dreamer is in both life and death.

The teachings of the Bahá'í Faith state that the nature of the afterlife is beyond the understanding of those living, just as an unborn fetus cannot understand the nature of the world outside of the womb. The Bahá'í writings state that the soul is immortal and after death it will continue to progress until it attains God's presence. In Bahá'í belief, souls in the afterlife will continue to retain their individuality and consciousness and will be able to recognize and communicate spiritually with other souls whom they have made deep profound friendships with, such as their spouses.

The Bahá'í scriptures also state there are distinctions between souls in the afterlife, and that souls will recognize the worth of their own deeds and understand the consequences of their actions. It is explained that those souls that have turned toward God will experience gladness, while those who have lived in error will become aware of the opportunities they have lost. Also, in the Baha'i view, souls will be able to recognize the accomplishments of the souls that have reached the same level as themselves, but not those that have achieved a rank higher than them.

The Upanishads describe reincarnation ("punarjanma") (see also: samsara). The Bhagavad Gita, an important Hindu script, talks extensively about the afterlife. Here, Krishna says that just as a man discards his old clothes and wears new ones; similarly the soul discards the old body and takes on a new one. In Hinduism, the belief is that the body is nothing but a shell, the soul inside is immutable and indestructible and takes on different lives in a cycle of birth and death. The end of this cycle is called "mukti" (Sanskrit: मुक्ति) and staying finally with supreme God forever; is "moksha" (Sanskrit: मोक्ष) or salvation.

The Garuda Purana deals solely with what happens to a person after death. The God of Death Yama sends his representatives to collect the soul from a person's body whenever he is due for death and they take the soul to Yama. A record of each person's timings & deeds performed by him is kept in a ledger by Yama's assistant, Chitragupta.

According to the Garuda Purana, a soul after leaving the body travels through a very long and dark tunnel towards the South. This is why an oil lamp is lit and kept beside the head of the corpse, to light the dark tunnel and allow the soul to travel comfortably.

The soul, called "atman" leaves the body and reincarnates itself according to the deeds or "karma" performed by one in last birth. Rebirth would be in form of animals or other lower creatures if one performed bad karmas and in human form in a good family with joyous lifetime if the person was good in last birth. In between the two births a human is also required to either face punishments for bad karmas in "naraka" or hell or enjoy for the good karmas in "swarga" or heaven for good deeds. Whenever his or her punishments or rewards are over he or she is sent back to earth, also known as "Mrutyulok" or human world. A person stays with the God or ultimate power when he discharges only & only "yajna karma" (means work done for satisfaction of supreme lord only) in last birth and the same is called as "moksha" or "nirvana", which is the ultimate goal of a self realised soul. "Atma" moves with "Parmatma" or the greatest soul. According to Bhagavad Gita an "Atma" or soul never dies, what dies is the body only made of five elements—Earth, Water, Fire, Air, and Sky. Soul is believed to be indestructible. None of the five elements can harm or influence it. Hinduism through Garuda Purana also describes in detail various types of "narkas" or Hells where a person after death is punished for his bad "karmas" and dealt with accordingly.

Hindus also believe in "karma". "Karma" is the accumulated sums of one's good or bad deeds. "Satkarma" means good deeds, "vikarma" means bad deeds. According to Hinduism the basic concept of karma is 'As you sow, you shall reap'. So, if a person has lived a good life, they will be rewarded in the afterlife. Similarly their sum of bad deeds will be mirrored in their next life. Good karma brings good rewards and bad karmas lead to bad results. There is no judgment here. People accumulate karma through their actions and even thoughts. In Bhagavad Gita when Arjuna hesitates to kill his kith and kin the lord reprimands him saying thus "Do you believe that you are the doer of the action. No. You are merely an instrument in MY hands. Do you believe that the people in front of you are living? Dear Arjuna, they are already dead. As a "kshatriya" (warrior) it is your duty to protect your people and land. If you fail to do your duty, then you are not adhering to dharmic principles."

Buddhists maintain that rebirth takes place without an unchanging self or soul passing from one form to another. The type of rebirth will be conditioned by the moral tone of the person's actions (kamma or karma). For example, if a person has committed harmful actions of body, speech and mind based on greed, hatred and delusion, rebirth in a lower realm, i.e. an animal, a hungry ghost or a hell realm, is to be expected. On the other hand, where a person has performed skillful actions based on generosity, loving-kindness (metta), compassion and wisdom, rebirth in a happy realm, i.e. human or one of the many heavenly realms, can be expected.

Yet the mechanism of rebirth with kamma is not deterministic. It depends on various levels of kamma. The most important moment that determines where a person is reborn into is the last thought moment. At that moment, heavy kamma would ripen if there were performed, if not then near death kamma, if not then habitual kamma, finally if none of the above happened, then residual kamma from previous actions can ripen. According to Theravada Buddhism, there are 31 realms of existence that one can be reborn into.

Pure Land Buddhism of Mahayana believes in a special place apart from the 31 planes of existence called Pure Land. It is believed that each Buddha has their own pure land, created out of their merits for the sake of sentient beings who recall them mindfully to be able to be reborn in their pure land and train to become a Buddha there. Thus the main practice of pure land Buddhism is to chant a Buddha's name.

In Tibetan Buddhism the Tibetan Book of the Dead explains the intermediate state of humans between death and reincarnation. The deceased will find the bright light of wisdom, which shows a straightforward path to move upward and leave the cycle of reincarnation. There are various reasons why the deceased do not follow that light. Some had no briefing about the intermediate state in the former life. Others only used to follow their basic instincts like animals. And some have fear, which results from foul deeds in the former life or from insistent haughtiness. In the intermediate state the awareness is very flexible, so it is important to be virtuous, adopt a positive attitude, and avoid negative ideas. Ideas which are rising from subconsciousness can cause extreme tempers and cowing visions. In this situation they have to understand, that these manifestations are just reflections of the inner thoughts. No one can really hurt them, because they have no more material body. The deceased get help from different Buddhas who show them the path to the bright light. The ones who do not follow the path after all will get hints for a better reincarnation. They have to release the things and beings on which or whom they still hang from the life before. It is recommended to choose a family where the parents trust in the Dharma and to reincarnate with the will to care for the welfare of all beings.

"Life is cosmic energy of the universe and after death it merges in universe again and as the time comes to find the suitable place for the entity died in the life condition it gets born. There are 10 life states of any life: Hell, hunger, anger, animality, rapture, humanity, learning, realization, bodhisatva and buddhahood. The life dies in which life condition it reborn in the same life condition."

Sikhism may have a belief in the afterlife. They believe that the soul belongs to the spiritual universe which has its origins in God. However it's been a matter of great debate amongst the Sikhs about Sikhism's belief in afterlife. Many believe that Sikhism endorses the afterlife and the concept of reward and punishment as there are verses given in "Guru Granth Sahib", but a large number of Sikhs believe otherwise and treat those verses as metaphorical or poetic.

Also it has been noted by many scholars that the Guru Granth Sahib includes poetic renditions from multiple saints and religious traditions like that of Kabir, Farid and Ramananda. The essential doctrine is to experience the divine through simple living, meditation and contemplation while being alive. Sikhism also has the belief of being in union with God while living. Accounts of afterlife are considered to be aimed at the popular prevailing views of the time so as to provide a referential framework without necessarily establishing a belief in the afterlife. Thus while it is also acknowledged that living the life of a householder is above the metaphysical truth, Sikhism can be considered agnostic to the question of an afterlife. Some scholars also interpret the mention of reincarnation to be naturalistic akin to the biogeochemical cycles. 

But if one analyses the Sikh Scriptures carefully, one may find that on many occasions the afterlife and the existence of heaven and hell are mentioned in "Guru Granth Sahib" and in "Dasam granth", so from that it can be concluded that Sikhism does believe in the existence of heaven and hell; however, heaven and hell are created to temporarily reward and punish, and one will then take birth again until one merges in God. According to the Sikh scriptures, the human form is the closet form to God and the best opportunity for a human being to attain salvation and merge back with God. Sikh Gurus said that nothing dies, nothing is born, everything is ever present, and it just changes forms. Like standing in front of a wardrobe, you pick up a dress and wear it and then you discard it. You wear another one. Thus, in the view of Sikhism, your soul is never born and never dies. Your soul is a part of God and hence lives forever.

Jainism also believes in the after life. They believe that the soul takes on a body form based on previous karmas or actions performed by that soul through eternity. Jains believe the soul is eternal and that the freedom from the cycle of reincarnation is the means to attain eternal bliss. 

Traditional African religions are diverse in their beliefs in an afterlife. Hunter-gatherer societies such as the Hadza have no particular belief in an afterlife, and the death of an individual is a straightforward end to their existence. Ancestor cults are found throughout Sub-Saharan Africa, including cultures like the Yombe, Beng, Yoruba and Ewe, "[T]he belief that the dead come back into life and are reborn into their families is given concrete expression in the personal names that are given to children...What is reincarnated are some of the dominant characteristics of the ancestor and not his soul. For each soul remains distinct and each birth represents a new soul." The Yoruba, Dogon and LoDagoa have eschatological ideas similar to Abrahamic religions, "but in most African societies, there is a marked absence of such clear-cut notions of heaven and hell, although there are notions of God judging the soul after death." In some societies like the Mende, multiple beliefs coexist. The Mende believe that people die twice: once during the process of joining the secret society, and again during biological death after which they become ancestors. However, some Mende also believe that after people are created by God they live ten consecutive lives, each in progressively descending worlds. One cross-cultural theme is that the ancestors are part of the world of the living, interacting with it regularly.

It is common for families to participate in ceremonies for children at a shrine, yet have a Buddhist funeral at the time of death. In old Japanese legends, it is often claimed that the dead go to a place called "yomi" (黄泉), a gloomy underground realm with a river separating the living from the dead mentioned in the legend of Izanami and Izanagi. This "yomi" very closely resembles the Greek Hades; however, later myths include notions of resurrection and even Elysium-like descriptions such as in the legend of Okuninushi and Susanoo. Shinto tends to hold negative views on death and corpses as a source of pollution called "kegare". However, death is also viewed as a path towards apotheosis in Shintoism as can be evidenced by how legendary individuals become enshrined after death. Perhaps the most famous would be Emperor Ojin who was enshrined as Hachiman the God of War after his death.

Some Unitarian Universalists believe in universalism: that all souls will ultimately be saved and that there are no torments of hell. Unitarian Universalists differ widely in their theology hence there is no exact same stance on the issue. Although Unitarians historically believed in a literal hell, and Universalists historically believed that everyone goes to heaven, modern Unitarian Universalists can be categorized into those believing in a heaven, reincarnation and oblivion. Most Unitarian Universalists believe that heaven and hell are symbolic places of consciousness and the faith is largely focused on the worldly life rather than any possible afterlife.

According to Edgar Cayce, the afterlife consisted of nine realms equated with the nine planets of astrology. The first, symbolized by Saturn, was a level for the purification of the souls. The second, Mercury's realm, gives us the ability to consider problems as a whole. The third of the nine soul realms is ruled by Earth and is associated with the Earthly pleasures. The fourth realm is where we find out about love and is ruled by Venus. The fifth realm is where we meet our limitations and is ruled by Mars. The sixth realm is ruled by Neptune, and is where we begin to use our creative powers and free ourselves from the material world. The seventh realm is symbolized by Jupiter, which strengthens the soul's ability to depict situations, to analyze people and places, things, and conditions. The eighth afterlife realm is ruled by Uranus and develops psychic ability. The ninth afterlife realm is symbolized by Pluto, the astrological realm of the unconscious. This afterlife realm is a transient place where souls can choose to travel to other realms or other solar systems, it is the souls liberation into eternity, and is the realm that opens the doorway from our solar system into the cosmos.

Mainstream Spiritualists postulate a series of seven realms that are not unlike Edgar Cayce's nine realms ruled by the planets. As it evolves, the soul moves higher and higher until it reaches the ultimate realm of spiritual oneness. The first realm, equated with hell, is the place where troubled souls spend a long time before they are compelled to move up to the next level. The second realm, where most souls move directly, is thought of as an intermediate transition between the lower planes of life and hell and the higher perfect realms of the universe. The third level is for those who have worked with their karmic inheritance. The fourth level is that from which evolved souls teach and direct those on Earth. The fifth level is where the soul leaves human consciousness behind. At the sixth plane, the soul is finally aligned with the cosmic consciousness and has no sense of separateness or individuality. Finally, the seventh level, the goal of each soul, is where the soul transcends its own sense of "soulfulness" and reunites with the World Soul and the universe.

The Wiccan afterlife is most commonly described as The Summerland. Here, souls rest, recuperate from life, and reflect on the experiences they had during their lives. After a period of rest, the souls are reincarnated, and the memory of their previous lives is erased. Many Wiccans see The Summerland as a place to reflect on their life actions. It is not a place of reward, but rather the end of a life journey at an end point of incarnations.

Zoroastrianism states that the "urvan", the disembodied spirit, lingers on earth for three days before departing downward to the kingdom of the dead that is ruled by Yima. For the three days that it rests on Earth, righteous souls sit at the head of their body, chanting the Ustavaiti Gathas with joy, while a wicked person sits at the feet of the corpse, wails and recites the Yasna. Zoroastrianism states that for the righteous souls, a beautiful maiden, which is the personification of the soul's good thoughts, words and deeds, appears. For a wicked person, a very old, ugly, naked hag appears. After three nights, the soul of the wicked is taken by the demon Vizaresa (Vīzarəša), to Chinvat bridge, and is made to go to darkness (hell).

Yima is believed to have been the first king on earth to rule, as well as the first man to die. Inside of Yima's realm, the spirits live a shadowy existence, and are dependent on their own descendants which are still living on Earth. Their descendants are to satisfy their hunger and clothe them, through rituals done on earth.

Rituals which are done on the first three days are vital and important, as they protect the soul from evil powers and give it strength to reach the underworld. After three days, the soul crosses Chinvat bridge which is the Final Judgment of the soul. Rashnu and Sraosha are present at the final judgment. The list is expanded sometimes, and include Vahman and Ormazd. Rashnu is the yazata who holds the scales of justice. If the good deeds of the person outweigh the bad, the soul is worthy of paradise. If the bad deeds outweigh the good, the bridge narrows down to the width of a blade-edge, and a horrid hag pulls the soul in her arms, and takes it down to hell with her.

Misvan Gatu is the 'place of the mixed ones' where the souls lead a gray existence, lacking both joy and sorrow. A soul goes here if his/her good deeds and bad deeds are equal, and Rashnu's scale is equal.

The Society for Psychical Research was founded in 1882 with the express intention of investigating phenomena relating to Spiritualism and the afterlife. Its members continue to conduct scientific research on the paranormal to this day. Some of the earliest attempts to apply scientific methods to the study of phenomena relating to an afterlife were conducted by this organization. Its earliest members included noted scientists like William Crookes, and philosophers such as Henry Sidgwick and William James.

Parapsychological investigation of the afterlife includes the study of haunting, apparitions of the deceased, instrumental trans-communication, electronic voice phenomena, and mediumship. But also the study of the near death experience. Scientists who have worked in this area include Raymond Moody, Susan Blackmore, Charles Tart, William James, Ian Stevenson, Michael Persinger, Pim van Lommel and Penny Sartori among others.

A study conducted in 1901 by physician Duncan MacDougall sought to measure the weight lost by a human when the soul "departed the body" upon death. MacDougall weighed dying patients in an attempt to prove that the soul was material, tangible and thus measurable. Although MacDougall's results varied considerably from "21 grams", for some people this figure has become synonymous with the measure of a soul's mass. The title of the 2003 movie "21 Grams" is a reference to MacDougall's findings. His results have never been reproduced, and are generally regarded either as meaningless or considered to have had little if any scientific merit.

Frank Tipler has argued that physics can explain immortality, though such arguments are not falsifiable and thus do not qualify, in Karl Popper's views, as science.

After 25 years of parapsychological research, Susan Blackmore came to the conclusion that there is no empirical evidence for an afterlife.

There is still the position, based on the philosophical question of personal identity, termed open individualism, and in some ways similar to the old belief of monopsychism, that concludes that individual existence is illusory, and our consciousness continues existing after death in other conscious beings. Positions regarding existence after death were supported by some notable physicists such as Erwin Schrödinger and Freeman Dyson.

Certain problems arise with the idea of a particular person continuing after death. Peter van Inwagen, in his argument regarding resurrection, notes that the materialist must have some sort of physical continuity. John Hick also raises some questions regarding personal identity in his book, "Death and Eternal Life" using an example of a person ceasing to exist in one place while an exact replica appears in another. If the replica had all the same experiences, traits, and physical appearances of the first person, we would all attribute the same identity to the second, according to Hick.

In the panentheistic model of process philosophy and theology the writers Alfred North Whitehead and Charles Hartshorne rejected that the universe was made of substance, instead reality is composed of living experiences (occasions of experience). According to Hartshorne people do not experience subjective (or personal) immortality in the afterlife, but they do have objective immortality because their experiences live on forever in God, who contains all that was. However other process philosophers such as David Ray Griffin have written that people may have subjective experience after death.

Regarding the mind–body problem, most neuroscientists take a physicalist position according to which consciousness derives from and/or is reducible to physical phenomena such as neuronal activity occurring in the brain. The implication of this premise is that once the brain stops functioning at brain death, consciousness fails to survive and ceases to exist. In general, scientists and philosophers tend to practice increased skepticism when it comes to belief in life after death. 

Psychological proposals for the origin of a belief in an afterlife include cognitive disposition, cultural learning, and as an intuitive religious idea. In one study, children were able to recognize the ending of physical, mental, and perceptual activity in death, but were hesitant to conclude the ending of will, self, or emotion in death.


 



</doc>
<doc id="1181" url="https://en.wikipedia.org/wiki?curid=1181" title="Astrometry">
Astrometry

Astrometry is the branch of astronomy that involves precise measurements of the positions and movements of stars and other celestial bodies. The information obtained by astrometric measurements provides information on the kinematics and physical origin of the Solar System and our galaxy, the Milky Way.

The history of astrometry is linked to the history of star catalogues, which gave astronomers reference points for objects in the sky so they could track their movements. This can be dated back to Hipparchus, who around 190 BC used the catalogue of his predecessors Timocharis and Aristillus to discover Earth's precession. In doing so, he also developed the brightness scale still in use today. Hipparchus compiled a catalogue with at least 850 stars and their positions. Hipparchus's successor, Ptolemy, included a catalogue of 1,022 stars in his work the "Almagest", giving their location, coordinates, and brightness.

In the 10th century, Abd al-Rahman al-Sufi carried out observations on the stars and described their positions, magnitudes and star color, and gave drawings for each constellation, in his "Book of Fixed Stars". Ibn Yunus observed more than 10,000 entries for the Sun's position for many years using a large astrolabe with a diameter of nearly 1.4 metres. His observations on eclipses were still used centuries later in Simon Newcomb's investigations on the motion of the Moon, while his other observations inspired Laplace's "Obliquity of the Ecliptic" and "Inequalities of Jupiter and Saturn". In the 15th century, the Timurid astronomer Ulugh Beg compiled the "Zij-i-Sultani", in which he catalogued 1,019 stars. Like the earlier catalogs of Hipparchus and Ptolemy, Ulugh Beg's catalogue is estimated to have been precise to within approximately 20 minutes of arc.

In the 16th century, Tycho Brahe used improved instruments, including large mural instruments, to measure star positions more accurately than previously, with a precision of 15–35 arcsec. Taqi al-Din measured the right ascension of the stars at the Istanbul observatory of Taqi al-Din using the "observational clock" he invented. When telescopes became commonplace, setting circles sped measurements

James Bradley first tried to measure stellar parallaxes in 1729. The stellar movement proved too insignificant for his telescope, but he instead discovered the aberration of light and the nutation of the Earth's axis. His cataloguing of 3222 stars was refined in 1807 by Friedrich Bessel, the father of modern astrometry. He made the first measurement of stellar parallax: 0.3 arcsec for the binary star 61 Cygni.

Being very difficult to measure, only about 60 stellar parallaxes had been obtained by the end of the 19th century, mostly by use of the filar micrometer. Astrographs using astronomical photographic plates sped the process in the early 20th century. Automated plate-measuring machines and more sophisticated computer technology of the 1960s allowed more efficient compilation of star catalogues. In the 1980s, charge-coupled devices (CCDs) replaced photographic plates and reduced optical uncertainties to one milliarcsecond. This technology made astrometry less expensive, opening the field to an amateur audience.

In 1989, the European Space Agency's Hipparcos satellite took astrometry into orbit, where it could be less affected by mechanical forces of the Earth and optical distortions from its atmosphere. Operated from 1989 to 1993, Hipparcos measured large and small angles on the sky with much greater precision than any previous optical telescopes. During its 4-year run, the positions, parallaxes, and proper motions of 118,218 stars were determined with an unprecedented degree of accuracy. A new "Tycho catalog" drew together a database of 1,058,332 to within 20-30 mas (milliarcseconds). Additional catalogues were compiled for the 23,882 double/multiple stars and 11,597 variable stars also analyzed during the Hipparcos mission.

Today, the catalogue most often used is USNO-B1.0, an all-sky catalogue that tracks proper motions, positions, magnitudes and other characteristics for over one billion stellar objects. During the past 50 years, 7,435 Schmidt camera plates were used to complete several sky surveys that make the data in USNO-B1.0 accurate to within 0.2 arcsec.

Apart from the fundamental function of providing astronomers with a reference frame to report their observations in, astrometry is also fundamental for fields like celestial mechanics, stellar dynamics and galactic astronomy. In observational astronomy, astrometric techniques help identify stellar objects by their unique motions. It is instrumental for keeping time, in that UTC is basically the atomic time synchronized to Earth's rotation by means of exact observations. Astrometry is an important step in the cosmic distance ladder because it establishes parallax distance estimates for stars in the Milky Way.

Astrometry has also been used to support claims of extrasolar planet detection by measuring the displacement the proposed planets cause in their parent star's apparent position on the sky, due to their mutual orbit around the center of mass of the system. Although, as of 2009, none of the extrasolar planets detected by ground-based astrometry has been verified in subsequent studies, astrometry is expected to be more accurate in space missions that are not affected by the distorting effects of the Earth's atmosphere. NASA's planned Space Interferometry Mission (SIM PlanetQuest) (now cancelled) was to utilize astrometric techniques to detect terrestrial planets orbiting 200 or so of the nearest solar-type stars, and the European Space Agency's Gaia Mission, launched in 2013, which will be applying astrometric techniques in its stellar census.

Astrometric measurements are used by astrophysicists to constrain certain models in celestial mechanics. By measuring the velocities of pulsars, it is possible to put a limit on the asymmetry of supernova explosions. Also, astrometric results are used to determine the distribution of dark matter in the galaxy.

Astronomers use astrometric techniques for the tracking of near-Earth objects. Astrometry is responsible for the detection of many record-breaking Solar System objects. To find such objects astrometrically, astronomers use telescopes to survey the sky and large-area cameras to take pictures at various determined intervals. By studying these images, they can detect Solar System objects by their movements relative to the background stars, which remain fixed. Once a movement per unit time is observed, astronomers compensate for the parallax caused by Earth’s motion during this time and the heliocentric distance to this object is calculated. Using this distance and other photographs, more information about the object, including its orbital elements, can be obtained.

50000 Quaoar and 90377 Sedna are two Solar System objects discovered in this way by Michael E. Brown and others at Caltech using the Palomar Observatory's Samuel Oschin telescope of and the Palomar-Quest large-area CCD camera. The ability of astronomers to track the positions and movements of such celestial bodies is crucial to the understanding of the Solar System and its interrelated past, present, and future with others in the Universe.

A fundamental aspect of astrometry is error correction. Various factors introduce errors into the measurement of stellar positions, including atmospheric conditions, imperfections in the instruments and errors by the observer or the measuring instruments. Many of these errors can be reduced by various techniques, such as through instrument improvements and compensations to the data. The results are then analyzed using statistical methods to compute data estimates and error ranges.







</doc>
<doc id="1182" url="https://en.wikipedia.org/wiki?curid=1182" title="Athena">
Athena

Athena or Athene, often given the epithet Pallas, is the ancient Greek goddess of wisdom, handicraft, and warfare, who was later syncretized with the Roman goddess Minerva. Athena was regarded as the patron and protectress of various cities across Greece, particularly the city of Athens, from which she most likely received her name. She is usually shown in art wearing a helmet and holding a spear. Her major symbols include owls, olive trees, snakes, and the Gorgoneion.

From her origin as an Aegean palace goddess, Athena was closely associated with the city. She was known as "Polias" and "Poliouchos" (both derived from "polis", meaning "city-state"), and her temples were usually located atop the fortified Acropolis in the central part of the city. The Parthenon on the Athenian Acropolis is dedicated to her, along with numerous other temples and monuments. As the patron of craft and weaving, Athena was known as "Ergane". She was also a warrior goddess, and was believed to lead soldiers into battle as "Athena Promachos". Her main festival in Athens was the Panathenaia, which was celebrated during the month of Hekatombaion in midsummer and was the most important festival on the Athenian calendar.

In Greek mythology, Athena was believed to have been born from the head of her father Zeus. In the founding myth of Athens, Athena bested Poseidon in a competition over patronage of the city by creating the first olive tree. She was known as "Athena Parthenos" ("Athena the Virgin"), but, in one archaic Attic myth, the god Hephaestus tried and failed to rape her, resulting in Gaia giving birth to Erichthonius, an important Athenian founding hero. Athena was the patron goddess of heroic endeavor; she was believed to have also aided the heroes Perseus, Heracles, Bellerophon, and Jason. Along with Aphrodite and Hera, Athena was one of the three goddesses whose feud resulted in the beginning of the Trojan War. She plays an active role in the "Iliad", in which she assists the Achaeans and, in the "Odyssey", she is the divine counselor to Odysseus.

In the later writings of the Roman poet Ovid, Athena was said to have competed against the mortal Arachne in a weaving competition, afterwards transforming Arachne into the first spider; Ovid also describes how she transformed Medusa into a Gorgon after witnessing her being raped by Poseidon in her temple. Since the Renaissance, Athena has become an international symbol of wisdom, the arts, and classical learning. Western artists and allegorists have often used Athena as a symbol of freedom and democracy.

Athena is associated with the city of Athens. The name of the city in ancient Greek is "Ἀθῆναι" ("Athenai"), a plural toponym, designating the place where—according to myth—she presided over the "Athenai", a sisterhood devoted to her worship. In ancient times, scholars argued whether Athena was named after Athens or Athens after Athena. Now scholars generally agree that the goddess takes her name from the city; the ending -"ene" is common in names of locations, but rare for personal names. Testimonies from different cities in ancient Greece attest that similar city goddesses were worshipped in other cities and, like Athena, took their names from the cities where they were worshipped. For example, in Mycenae there was a goddess called Mykene, whose sisterhood was known as "Mykenai", whereas at Thebes an analogous deity was called Thebe, and the city was known under the plural form "Thebai" (or Thebes, in English, where the ‘s’ is the plural formation). The name "Athenai" is likely of Pre-Greek origin because it contains the presumably Pre-Greek morpheme "*-ān-".

In his dialogue "Cratylus", the Greek philosopher Plato (428–347 BC) gives some rather imaginative etymologies of Athena's name, based on the theories of the ancient Athenians and his own etymological speculations:

Thus, Plato believed that Athena's name was derived from Greek , "Atheonóa"—which the later Greeks rationalised as from the deity's (θεός, "theós") mind (νοῦς, "noũs"). The second-century AD orator Aelius Aristides attempted to derive natural symbols from the etymological roots of Athena's names to be "aether", "air", "earth", and "moon".

Athena was originally the Aegean goddess of the palace, who presided over household crafts and protected the king. A single Mycenaean Greek inscription "a-ta-na po-ti-ni-ja" /Athana potnia/ appears at Knossos in the Linear B tablets from the Late Minoan II-era "Room of the Chariot Tablets"; these comprise the earliest Linear B archive anywhere. Although "Athana potnia" is often translated "Mistress Athena", it could also mean "the "Potnia" of Athana", or "the Lady of Athens". However, any connection to the city of Athens in the Knossos inscription is uncertain. In the still undeciphered corpus of Linear A tablets—written in the unclassified Minoan language—a sign series "a-ta-no-dju-wa-ja" is to be found. This could be connected with the Linear B Mycenaean expressions "a-ta-na po-ti-ni-ja" and "di-u-ja" or "di-wi-ja" ("Diwia", "of Zeus" or, possibly, related to a homonymous goddess), resulting in a translation "Athena of Zeus" or "divine Athena". Similarly, in the Greek mythology and epic tradition, Athena figures as a daughter of Zeus (Διός θυγάτηρ; "cfr." Dyeus). However, the inscription quoted seems to be very similar to "a-ta-nū-tī wa-ya", quoted as SY Za 1 by Jan Best. Best translates the initial "a-ta-nū-tī", which is recurrent in line beginnings, as "I have given".

A Mycenean fresco depicts two women extending their hands towards a central figure, who is covered by an enormous figure-eight shield; this may depict the warrior-goddess with her "palladion", or her palladion in an aniconic representation. In the "Procession Fresco" at Knossos, which was reconstructed by the Mycenaeans, two rows of figures carrying vessels seem to meet in front of a central figure, which is probably the Minoan precursor to Athena. The early twentieth-century scholar Martin Persson Nilsson argued that the Minoan snake goddess figurines are early representations of Athena.

Nilsson and others have claimed that, in early times, Athena was either an owl herself or a bird goddess in general. In the third book of the "Odyssey", she takes the form of a sea-eagle. Proponents of this view argue that she dropped her prophylactic owl-mask before she lost her wings. "Athena, by the time she appears in art," Jane Ellen Harrison remarks, "has completely shed her animal form, has reduced the shapes she once wore of snake and bird to attributes, but occasionally in black-figure vase-paintings she still appears with wings."

It is generally agreed that the cult of Athena preserves some aspects of the Proto-Indo-European transfunctional goddess. The cult of Athena may have also been influenced by those of Near Eastern warrior goddesses such as the East Semitic Ishtar and the Ugaritic Anat, both of whom were often portrayed bearing arms. Athena's birth from the head of Zeus may be derived from the earlier Sumerian myth of Inanna's descent into and return from the Netherworld.

Miriam Robbins Dexter has suggested that, at least at some point in her history, Athena was a solar deity. Athena bears traits common with Indo-European solar goddesses, including the possession of a mirror and the invention of weaving, characteristics which are also held by the Baltic goddess Saulė. Athena's association with Medusa, who is also suspected of being a solar goddess, adds further solar iconography to her cultus. Athena was later syncretized with Sulis, a Celtic goddess whose name is derived from the common Proto-Indo-European root for many solar deities. Though the sun in Greek myth is personified as the male Helios, several relictual solar goddesses are known, such as Alectrona.

Plato notes that the citizens of Sais in Egypt worshipped a goddess known as Neith, whom he identifies with Athena. Neith was the ancient Egyptian goddess of war and hunting, who was also associated with weaving; her worship began during the Egyptian Pre-Dynastic period. In Greek mythology, Athena was reported to have visited mythological sites in North Africa, including Libya's Triton River and the Phlegraean plain. Based on these similarities, the sinologist Martin Bernal created the "Black Athena" hypothesis, which claimed that Neith was brought to Greece from Egypt, along with "an enormous number of features of civilization and culture in the third and second millennia". The "Black Athena" hypothesis stirred up widespread controversy near the end of the twentieth century, but it has now been widely rejected by modern scholars.
In her aspect of "Athena Polias", Athena was venerated as the goddess of the city and the protectress of the citadel. In Athens, the Plynteria, or "Feast of the Bath", was observed every year at the end of the month of Thargelion. The festival lasted for five days. During this period, the priestesses of Athena, or "plyntrídes", performed a cleansing ritual within the Erechtheion, a sanctuary devoted to Athena and Poseidon. Here Athena's statue was undressed, her clothes washed, and body purified.

Athena was worshipped at festivals such as Chalceia as "Athena Ergane", the patroness of various crafts, especially weaving. She was also the patron of metalworkers and was believed to aid in the forging of armor and weapons. During the late 5th century BC, the role of goddess of philosophy became a major aspect of Athena's cult.

As "Athena Promachos", she was believed to lead soldiers into battle. Athena represented the disciplined, strategic side of war, in contrast to her brother Ares, the patron of violence, bloodlust, and slaughter—"the raw force of war". Athena was believed to only support those fighting for a just cause and was thought to view war primarily as a means to resolve conflict. In her aspect as a warrior maiden, Athena was also known as "Parthenos", which means "virgin", because she was believed to have never married or taken a lover. Athena was especially worshipped in this role during the festivals of the Panathenaea and Pamboeotia, both of which prominently featured displays of athletic and military prowess. As the patroness of heroes and warriors, Athena was believed to favor those who used cunning and intelligence rather than brute strength.

Athena was not only the patron goddess of Athens, but also other cities, including Argos, Sparta, Gortyn, Lindos, and Larisa. The various cults of Athena were all branches of her panhellenic cult and often proctored various initiation rites of Grecian youth, such as the passage into citizenship by young men or the passage of young women into marriage. These cults were portals of a uniform socialization, even beyond mainland Greece.

Athena was frequently equated with Aphaea, a local goddess of the island of Aegina, originally from Crete and also associated with Artemis and the nymph Britomartis. In Arcadia, she was assimilated with the ancient goddess Alea and worshiped as Athena Alea. Sanctuaries dedicated to Athena Alea were located in the Laconian towns of Mantineia and Tegea. The temple of Athena Alea in Tegea was an important religious center of ancient Greece. The geographer Pausanias was informed that the "temenos" had been founded by Aleus. Votive bronzes at the site from the Geometric and Archaic periods take the forms of horses and deer; there are sealstone and fibulae. In the Archaic period, the nine villages that underlie Tegea banded together in a synoecism to form one city. Tegea was listed in Homer's Catalogue of Ships as one of the cities that contributed ships and men for the Achaean assault on Troy.

Athena had a major temple on the Spartan Acropolis, where she was venerated as Poliouchos and "Khalkíoikos" ("of the Brazen House", often latinized as "Chalcioecus"). This epithet may refer to the fact that cult statue held there may have been made of bronze, that the walls of the temple itself may have been made of bronze, or that Athena was the patron of metal-workers. Bells made of terracotta and bronze were used in Sparta as part of Athena's cult.

An Ionic-style temple to Athena Polias was built at Priene in the fourth century BC. It was designed by Pytheos of Priene, the same architect who designed the Mausoleum at Halicarnassus. The temple was dedicated by Alexander the Great and an inscription from the temple declaring his dedication is now held in the British Museum.

Athena was known as Atrytone ( "the Unwearying"), Parthenos ( "Virgin"), and Promachos ( "she who fights in front"). The epithet Polias (Πολιάς "of the city"), refers to Athena's role as protectress of the city. The epithet Ergane (Εργάνη "the Industrious") pointed her out as the patron of craftsmen and artisans. Burkert notes that the Athenians sometimes simply called Athena "the Goddess", "hē theós" (ἡ θεός), certainly an ancient title. After serving as the judge at the trial of Orestes in which he was acquitted of having murdered his mother Clytemnestra, Athena won the epithet Areia (Αρεία).

Athena was sometimes given the epithet Hippia (Ἵππια "of the horses", "equestrian"), referring to her invention of the bit, bridle, chariot, and wagon. The Greek geographer Pausanias mentions in his "Guide to Greece" that the temple of Athena Chalinitis ("the bridler") in Corinth was located near the tomb of Medea's children. Other epithets include Ageleia, Itonia and Aethyia, under which she was worshiped in Megara. The word "aíthyia" () signifies a "diver", also some diving bird species (possibly the shearwater) and figuratively, a "ship", so the name must reference Athena teaching the art of shipbuilding or navigation. In a temple at Phrixa in Elis, reportedly built by Clymenus, she was known as Cydonia (Κυδωνία).

The Greek biographer Plutarch (46–120 AD) refers to an instance during the Parthenon's construction of her being called Athena Hygieia (Ὑγίεια, i. e. personified "Health"):

In Homer's epic works, Athena's most common epithet is Glaukopis (), which usually is translated as, "bright-eyed" or "with gleaming eyes". The word is a combination of "glaukós" (, meaning "gleaming, silvery", and later, "bluish-green" or "gray") and "ṓps" (, "eye, face"). The word "glaúx" (, "little owl") is from the same root, presumably according to some, because of the bird's own distinctive eyes. Athena was clearly associated with the owl from very early on; in archaic images, she is frequently depicted with an owl perched on her hand. Through its association with Athena, the owl evolved into the national mascot of the Athenians and eventually became a symbol of wisdom.

In the "Iliad" (4.514), the "Odyssey" (3.378), the "Homeric Hymns", and in Hesiod's "Theogony", Athena is also given the curious epithet Tritogeneia (Τριτογένεια), whose significance remains unclear. It could mean various things, including "Triton-born", perhaps indicating that the homonymous sea-deity was her parent according to some early myths. One myth relates the foster father relationship of this Triton towards the half-orphan Athena, whom he raised alongside his own daughter Pallas. Karl Kerényi suggests that "Tritogeneia did not mean that she came into the world on any particular river or lake, but that she was born of the water itself; for the name Triton seems to be associated with water generally." In Ovid's "Metamorphoses", Athena is occasionally referred to as "Tritonia".

Another possible meaning may be "triple-born" or "third-born", which may refer to a triad or to her status as the third daughter of Zeus or the fact she was born from Metis, Zeus, and herself; various legends list her as being the first child after Artemis and Apollo, though other legends identify her as Zeus' first child. Several scholars have suggested a connection to the Rigvedic god Trita, who was sometimes grouped in a body of three mythological poets. Michael Janda has connected the myth of Trita to the scene in the "Iliad" in which the "three brothers" Zeus, Poseidon, and Hades divide the world between them, receiving the "broad sky", the sea, and the underworld respectively. Janda further connects the myth of Athena being born of the head (i. e. the uppermost part) of Zeus, understanding "Trito-" (which perhaps originally meant "the third") as another word for "the sky". In Janda's analysis of Indo-European mythology, this heavenly sphere is also associated with the mythological body of water surrounding the inhabited world ("cfr." Triton's mother, Amphitrite).

Although Athena appears before Zeus at Knossos—in Linear B, as , "a-ta-na po-ti-ni-ja", "Mistress Athena"—in the Classical Olympian pantheon, Athena was remade as the favourite daughter of Zeus, born fully armed from his forehead. The story of her birth comes in several versions. In the version recounted by Hesiod in his "Theogony", Zeus lay with Metis, the goddess of crafty thought and wisdom, but he immediately feared the consequences because Gaia and Ouranos had prophesized that Metis would bear children wiser than he himself. In order to prevent this, Zeus swallowed Metis, but it was too late because Metis had already conceived.

Eventually Zeus experienced an enormous headache; Prometheus, Hephaestus, Hermes, Ares, or Palaemon (depending on the sources examined) cleaved Zeus’ head with the double-headed Minoan axe, the "labrys". Athena leaped from Zeus's head, fully grown and armed, with a shout—"and pealed to the broad sky her clarion cry of war. And Ouranos trembled to hear, and Mother Gaia…" Plato, in the "Laws", attributes the cult of Athena to the culture of Crete, introduced, he thought, from Libya during the dawn of Greek culture. Classical myths thereafter note that Hera was so annoyed at Zeus for having produced a child that she conceived and bore Hephaestus by herself, but in "Imagines" 2. 27 (trans. Fairbanks), the third-century AD Greek rhetorician Philostratus the Elder writes that Hera "rejoices" at Athena's birth "as though Athena were her daughter also." The second-century AD Christian apologist Justin Martyr takes issue with those pagans who erect at springs images of Kore, whom he interprets as Athena: "They said that Athena was the daughter of Zeus not from intercourse, but when the god had in mind the making of a world through a word ("logos") his first thought was Athena."

A "scholium" on the "Iliad" makes Athena the daughter of Brontes the Cyclops, who seduced Metis and impregnated her, prompting Zeus to swallow her. The "Etymologicum Magnum" instead deems Athena the daughter of the Daktyl Itonos. Fragments attributed by the Christian Eusebius of Caesarea to the semi-legendary Phoenician historian Sanchuniathon, which Eusebius thought had been written before the Trojan war, make Athena instead the daughter of Cronus, a king of Byblos who visited "the inhabitable world" and bequeathed Attica to Athena.

Athena's epithet "Pallas" is derived either from , meaning "to brandish [as a weapon]", or, more likely, from and related words, meaning "youth, young woman". On this topic, Walter Burkert says "she is the Pallas of Athens, "Pallas Athenaie", just as Hera of Argos is "Here Argeie"." In later times, after the original meaning of the name had been forgotten, the Greeks invented myths to explain its origin, such as those reported by the Epicurean philosopher Philodemus and the ancient mythographer Pseudo-Apollodorus, which claim that "Pallas" was originally a separate entity, whom Athena had slain in combat.

In one version of the myth, Pallas was the daughter of the sea-god Triton; she and Athena were childhood friends, but Athena accidentally killed her during a friendly sparring match. Distraught over what she had done, Athena took the name Pallas for herself as a sign of her grief. In another version of the story, Pallas was a Gigante; Athena slew him during the Gigantomachy and flayed off his skin to make her cloak, which she wore as a victory trophy. In an alternate variation of the same myth, Pallas was instead Athena's father, who attempted to assault his own daughter, causing Athena to kill him and take his skin as a trophy.

The "palladion" was a statue of Athena that was said to have stood in her temple on the Trojan Acropolis. Athena was said to have carved the statue herself in the likeness of her dead friend Pallas. The statue had special talisman-like properties and it was thought that, as long as it was in the city, Troy could never fall. When the Greeks captured Troy, Cassandra, the daughter of Priam, clung to the palladion for protection, but Ajax the Lesser violently tore her away from it and dragged her over to the other captives. Athena was infuriated by this violation of her protection. Though Agamemnon attempted to placate her anger with sacrifices, Athena sent a storm at Cape Kaphereos to destroy almost the entire Greek fleet and scatter all of the surviving ships across the Aegean.

In a founding myth reported by Pseudo-Apollodorus, Athena competed with Poseidon for the patronage of Athens. They agreed that each would give the Athenians one gift and that Cecrops, the king of Athens, would determine which gift was better. Poseidon struck the ground with his trident and a salt water spring sprang up; this gave the Athenians access to trade and water. Athens at its height was a significant sea power, defeating the Persian fleet at the Battle of Salamis—but the water was salty and undrinkable. In an alternative version of the myth from Vergil's "Georgics", Poseidon instead gave the Athenians the first horse. Athena offered the first domesticated olive tree. Cecrops accepted this gift and declared Athena the patron goddess of Athens. The olive tree brought wood, oil, and food, and became a symbol of Athenian economic prosperity. Robert Graves was of the opinion that "Poseidon's attempts to take possession of certain cities are political myths", which reflect the conflict between matriarchal and patriarchal religions.

Pseudo-Apollodorus records an archaic legend, which claims that Hephaestus once attempted to rape Athena, but she pushed him away, causing him to ejaculate on her thigh. Athena wiped the semen off using a tuft of wool, which she tossed into the dust, impregnating Gaia and causing her to give birth to Erichthonius, whom Athena adopted as her own child. The Roman mythographer Hyginus records a similar story in which Hephaestus demanded Zeus to let him marry Athena since he was the one who had smashed open Zeus's skull, allowing Athena to be born. Zeus agreed to this and Hephaestus and Athena were married, but, when Hephaestus was about to consummate the union, Athena vanished from the bridal bed, causing him to ejaculate on the floor, thus impregnating Gaia with Erichthonius.

The geographer Pausanias records that Athena placed the infant Erichthonius into a small chest ("cista"), which she entrusted to the care of the three daughters of Cecrops: Herse, Pandrosos, and Aglauros of Athens. She warned the three sisters not to open the chest, but did not explain to them why or what was in it. Aglauros, and possibly one of the other sisters, opened the chest. Differing reports say that they either found that the child itself was a serpent, that it was guarded by a serpent, that it was guarded by two serpents, or that it had the legs of a serpent. In Pausanias's story, the two sisters were driven mad by the sight of the chest's contents and hurled themselves off the Acropolis, dying instantly, but an Attic vase painting shows them being chased by the serpent off the edge of the cliff instead.

Erichthonius was one of the most important founding heroes of Athens and the legend of the daughters of Cecrops was a cult myth linked to the rituals of the Arrhephoria festival. Pausanias records that, during the Arrhephoria, two young girls known as the "Arrhephoroi", who lived near the temple of Athena Polias, would be given hidden objects by the priestess of Athena, which they would carry on their heads down a natural underground passage. They would leave the objects they had been given at the bottom of the passage and take another set of hidden objects, which they would carry on their heads back up to the temple. The ritual was performed in the dead of night and no one, not even the priestess, knew what the objects were. The serpent in the story may be the same one depicted coiled at Athena's feet in Pheidias's famous statue of the "Athena Parthenos" in the Parthenon. Many of the surviving sculptures of Athena show this serpent.

Herodotus records that a serpent lived in a crevice on the north side of the summit of the Athenian Acropolis and that the Athenians left a honey cake for it each month as an offering. On the eve of the Second Persian invasion of Greece in 480 BC, the serpent did not eat the honey cake and the Athenians interpreted it as a sign that Athena herself had abandoned them. Another version of the myth of the Athenian maidens is told in "Metamorphoses" by the Roman poet Ovid (43 BC17 AD); in this late variant Hermes falls in love with Herse. Herse, Aglaulus, and Pandrosus go to the temple to offer sacrifices to Athena. Hermes demands help from Aglaulus to seduce Herse. Aglaulus demands money in exchange. Hermes gives her the money the sisters have already offered to Athena. As punishment for Aglaulus's greed, Athena asks the goddess Envy to make Aglaulus jealous of Herse. When Hermes arrives to seduce Herse, Aglaulus stands in his way instead of helping him as she had agreed. He turns her to stone.

Athena never had a consort or lover and is thus known as "Athena Parthenos", "Virgin Athena". Her most famous temple, the Parthenon, on the Acropolis in Athens takes its name from this title. It is not merely an observation of her virginity, but a recognition of her role as enforcer of rules of sexual modesty and ritual mystery. Even beyond recognition, the Athenians allotted the goddess value based on this pureness of virginity as it upheld a rudiment of female behavior in the patriarchal society. Kerényi's study and theory of Athena accredits her virginal epithet to be a result of the relationship to her father Zeus and a vital, cohesive piece of her character throughout the ages. This role is expressed in a number of stories about Athena. Marinus of Neapolis reports that when Christians removed the statue of the Goddess from the Parthenon, a beautiful woman appeared in a dream to Proclus, a devotee of Athena, and announced that the ""Athenian Lady"" wished to dwell with him.

According to Pseudo-Apollodorus's "Bibliotheca", Athena guided the hero Perseus in his quest to behead Medusa. She and Hermes, the god of travelers, appeared to Perseus after he set off on his quest and gifted him with tools he would need to kill the Gorgon. Athena gave Perseus a polished bronze shield to view Medusa's reflection rather than looking at her directly and thereby avoid being turned to stone. Hermes gave him an adamantine scythe to cut off Medusa's head. When Perseus swung his blade to behead Medusa, Athena guided it, allowing his scythe to cut it clean off. According to Pindar's "Thirteenth Olympian Ode", Athena helped the hero Bellerophon tame the winged horse Pegasus by giving him a bit. In ancient Greek art, Athena is frequently shown aiding the hero Heracles. She appears in four of the twelve metopes on the Temple of Zeus at Olympia depicting Heracles's Twelve Labors, including the first, in which she passively watches him slay the Nemean lion, and the tenth, in which she is shown actively helping him hold up the sky. She is presented as his "stern ally", but also the "gentle... acknowledger of his achievements." Artistic depictions of Heracles's apotheosis show Athena driving him to Mount Olympus in her chariot and presenting him to Zeus for his deification. In Aeschylus's tragedy "Orestes", Athena intervenes to save Orestes from the wrath of the Erinyes and presides over his trial for the murder of his mother Clytemnestra. When half the jury votes to acquit and the other half votes to convict, Athena casts the deciding vote to acquit Orestes and declares that, from then on, whenever a jury is tied, the defendant shall always be acquitted.

In "The Odyssey", Odysseus' cunning and shrewd nature quickly wins Athena's favour. For the first part of the poem, however, she largely is confined to aiding him only from "afar", mainly by implanting thoughts in his head during his journey home from Troy. Her guiding actions reinforce her role as the "protectress of heroes," or, as mythologian Walter Friedrich Otto dubbed her, the "goddess of nearness," due to her mentoring and motherly probing. It is not until he washes up on the shore of the island of the Phaeacians, where Nausicaa is washing her clothes that Athena arrives personally to provide more tangible assistance. She appears in Nausicaa's dreams to ensure that the princess rescues Odysseus and plays a role in his eventual escort to Ithaca. Athena appears to Odysseus upon his arrival, disguised as a herdsman; she initially lies and tells him that Penelope, his wife, has remarried and that he is believed to be dead, but Odysseus lies back to her, employing skillful prevarications to protect himself. Impressed by his resolve and shrewdness, she reveals herself and tells him what he needs to know in order to win back his kingdom. She disguises him as an elderly beggar so that he will not be recognized by the suitors or Penelope, and helps him to defeat the suitors. Athena also appears to Odysseus's son Telemachus. Her actions lead him to travel around to Odysseus's comrades and ask about his father. He hears stories about some of Odysseus's journey. Athena's push for Telemachos's journey helps him grow into the man role, that his father once held. She also plays a role in ending the resultant feud against the suitors' relatives. She instructs Laertes to throw his spear and to kill Eupeithes, the father of Antinous.

The Gorgoneion appears to have originated as an apotropaic symbol intended to ward off evil. In a late myth invented to explain the origins of the Gorgon, Medusa is described as having been a young priestess who served in the temple of Athena in Athens. Poseidon lusted after Medusa, and raped her in the temple of Athena, refusing to allow her vow of chastity to stand in his way. Upon discovering the desecration of her temple, Athena transformed Medusa into a hideous monster with serpents for hair whose gaze would turn any mortal to stone.

In his "Twelfth Pythian Ode", Pindar recounts the story of how Athena invented the "aulos", a kind of flute, in imitation of the lamentations of Medusa's sisters, the Gorgons, after she was beheaded by the hero Perseus. According to Pindar, Athena gave the aulos to mortals as a gift. Later, the comic playwright Melanippides of Melos ( 480-430 BC) embellished the story in his comedy "Marsyas", claiming that Athena looked in the mirror while she was playing the aulos and saw how blowing into it puffed up her cheeks and made her look silly, so she threw the aulos away and cursed it so that whoever picked it up would meet an awful death. The aulos was picked up by the satyr Marsyas, who was later killed by Apollo for his hubris. Later, this version of the story became accepted as canonical and the Athenian sculptor Myron created a group of bronze sculptures based on it, which was installed before the western front of the Parthenon in around 440 BC.

In one version of the Tiresias myth, Tiresias stumbled upon Athena bathing, and she struck him blind to ensure he would never again see what man was not intended to see. Tiresias's mother Chariclo intervened on his behalf and begged Athena to have mercy. Athena could not restore Tiresias's eyesight, so instead she gave him the ability to understand the language of the birds and thus foretell the future.

The fable of Arachne appears in Ovid's "Metamorphoses" (8 AD) (vi.5–54 and 129–145), which is nearly the only extant source for the legend. The story does not appear to have been well known prior to Ovid's rendition of it and the only earlier reference to it is a brief allusion in Virgil's "Georgics", (29 BC) (iv, 246) that does not mention Arachne by name. According to Ovid, Arachne (whose name means "spider" in ancient Greek) was the daughter of a famous dyer in Tyrian purple in Hypaipa of Lydia, and a weaving student of Athena. She became so conceited of her skill as a weaver that she began claiming that her skill was greater than that of Athena herself. Athena gave Arachne a chance to redeem herself by assuming the form of an old woman and warning Arachne not to offend the deities. Arachne scoffed and wished for a weaving contest, so she could prove her skill.

Athena wove the scene of her victory over Poseidon in the contest for the patronage of Athens. Arachne's tapestry featured twenty-one episodes of the deities' infidelity, including Zeus being unfaithful with Leda, with Europa, and with Danaë. Athena admitted that Arachne's work was flawless, but was outraged at Arachne's offensive choice of subject, which displayed the failings and transgressions of the deities. Finally, losing her temper, Athena destroyed Arachne's tapestry and loom, striking it with her shuttle. Athena then struck Arachne across the face with her staff four times. Arachne hanged herself in despair, but Athena took pity on her and brought her back from the dead in the form of a spider.

The myth of the Judgement of Paris is mentioned briefly in the "Iliad", but is described in depth in an epitome of the "Cypria", a lost poem of the Epic Cycle, which records that all the gods and goddesses as well as various mortals were invited to the marriage of Peleus and Thetis (the eventual parents of Achilles). Only Eris, goddess of discord, was not invited. She was annoyed at this, so she arrived with a golden apple inscribed with the word καλλίστῃ (kallistēi, "for the fairest"), which she threw among the goddesses. Aphrodite, Hera, and Athena all claimed to be the fairest, and thus the rightful owner of the apple.

The goddesses chose to place the matter before Zeus, who, not wanting to favor one of the goddesses, put the choice into the hands of Paris, a Trojan prince. After bathing in the spring of Mount Ida where Troy was situated, the goddesses appeared before Paris for his decision. In the extant ancient depictions of the Judgement of Paris, Aphrodite is only occasionally represented nude, and Athena and Hera are always fully clothed. Since the Renaissance, however, western paintings have typically portrayed all three goddesses as completely naked.

All three goddesses were ideally beautiful and Paris could not decide between them, so they resorted to bribes. Hera tried to bribe Paris with power over all Asia and Europe, and Athena offered wisdom, fame and glory in battle, but Aphrodite promised Paris that, if he were to choose her as the fairest, she would let him marry the most beautiful woman on earth. This woman was Helen, who was already married to King Menelaus of Sparta. Paris selected Aphrodite and awarded her the apple. The other two goddesses were enraged and, as a direct result, sided with the Greeks in the Trojan War.

In Books V-VI of the "Iliad", Athena aids the hero Diomedes, who, in the absence of Achilles, proves himself to be the most effective Greek warrior. Several artistic representations from the early sixth century BC may show Athena and Diomedes, including an early sixth-century BC shield band depicting Athena and an unidentified warrior riding on a chariot, a vase painting of a warrior with his charioteer facing Athena, and an inscribed clay plaque showing Diomedes and Athena riding in a chariot. Numerous passages in the "Iliad" also mention Athena having previously served as the patron of Diomedes's father Tydeus. When the Trojan women go to the temple of Athena on the Acropolis to plead her for protection from Diomedes, Athena ignores them.

In Book XXII of the "Iliad", while Achilles is chasing Hector around the walls of Troy, Athena appears to Hector disguised as his brother Deiphobus and persuades him to hold his ground so that they can fight Achilles together. Then, Hector throws his spear at Achilles and misses, expecting Deiphobus to hand him another, but Athena disappears instead, leaving Hector to face Achilles alone without his spear. In Sophocles's tragedy "Ajax", she punishes Odysseus's rival Ajax the Great, driving him insane and causing him to massacre the Achaeans' cattle, thinking that he is slaughtering the Achaeans themselves. Even after Odysseus himself expresses pity for Ajax, Athena declares, "To laugh at your enemies - what sweeter laughter can there be than that?" (lines 78-9). Ajax later commits suicide as a result of his humiliation.

In early, archaic portraits of Athena in black-figure pottery, the goddess retains some of her Minoan-Mycenaean character, such as great bird wings, although this is not true of archaic sculpture such as those of Aphaean Athena, where Athena has subsumed an earlier, invisibly numinous—"Aphaea"—goddess with Cretan connections in her "mythos".

In classical depictions, Athena is usually portrayed standing upright, wearing a full-length chiton. She is sometimes dressed in armor, and is often represented wearing a Corinthian helmet raised high atop her forehead. Her shield bears at its centre the aegis with the head of the gorgon ("gorgoneion") in the center and snakes around the edge. It is in this standing posture that she was depicted in Phidias's famous lost gold and ivory statue of her, 36 m tall, the "Athena Parthenos" in the Parthenon.

Apart from her attributes, there seems to be a relative consensus in late sculpture from the Classical period, the fifth century BC onward, as to what Athena looked like. Most noticeable in the face is perhaps the full round strong, chin with a high nose that has a high bridge as a natural extension of the forehead. The eyes typically are somewhat deeply set. The unsmiling lips are usually full, but the mouth is depicted fairly narrow, usually just slightly wider than the nose. The neck is somewhat long.

The "Mourning Athena" is a famous relief sculpture dating to around 470-460 BC that has been interpreted to represent Athena Polias. Athena Polias is also represented in a Neo-Attic relief now held in the Virginia Museum of Fine Arts, which depicts her holding an owl in her hand and wearing her characteristic Corinthian helmet while resting her shield against a nearby "herma".

Early Christian writers such as Clement of Alexandria and Firmicus denigrated Athena as representative of all the things that were detestable about paganism; they condemned her as "immodest and immoral". During the Middle Ages, however, many attributes of Athena were given to the Virgin Mary, who, in fourth century portrayals, was often depicted wearing the Gorgoneion. Some even viewed the Virgin Mary as a warrior maiden, much like Athena Parthenos; one anecdote tells that the Virgin Mary once appeared upon the walls of Constantinople when it was under siege by the Avars, clutching a spear and urging the people to fight. During the Middle Ages, Athena became widely used as a Christian symbol and allegory, and she appeared on the family crests of certain noble houses.

During the Renaissance, Athena donned the mantle of patron of the arts and human endeavor; allegorical paintings involving Athena were a favorite of the Italian Renaissance painters. In Sandro Botticelli's painting "Pallas and the Centaur", probably painted sometime in the 1480s, Athena is the personification of chastity, who is shown grasping the forelock of a centaur, who represents lust. Andrea Mantegna's 1502 painting "Minerva Expelling the Vices from the Garden of Virtue" uses Athena as the personification of Graeco-Roman learning chasing the vices of medievalism from the garden of modern scholarship.

During the sixteenth and seventeenth centuries, Athena was used as a symbol for female rulers. In his book "A Revelation of the True Minerva" (1582), Thomas Blennerhassett portrays Queen Elizabeth I of England as a "new Minerva" and "the greatest goddesse nowe on earth". A series of paintings by Peter Paul Rubens depict Athena as Marie de' Medici's patron and mentor; the final painting in the series goes even further and shows Marie de' Medici with Athena's iconography, as the mortal incarnation of the goddess herself. During the French Revolution, statues of pagan gods were torn down all throughout France, but statues of Athena were not. Instead, Athena was transformed into the personification of freedom and the republic and a statue of the goddess stood in the center of the Place de la Revolution in Paris. In the years following the Revolution, artistic representations of Athena proliferated.

A statue of Athena stands directly in front of the Austrian Parliament Building in Vienna, and depictions of Athena have influenced other symbols of western freedom, including the Statue of Liberty and Britannia. For over a century, a full-scale replica of the Parthenon has stood in Nashville, Tennessee. In 1990, the curators added a gilded forty-two foot (12.5 m) tall replica of Phidias's "Athena Parthenos", built from concrete and fiberglass. The state seal of California bears the image of Athena kneeling next to a brown grizzly bear. Athena has occasionally appeared on modern coins, as she did on the ancient Athenian drachma. Her head appears on the $50 1915-S Panama-Pacific commemorative coin.

One of Sigmund Freud's most treasured possessions was a small, bronze statue of Athena, which sat on his desk. Freud once described Athena as "a woman who is unapproachable and repels all sexual desires - since she displays the terrifying genitals of the Mother." Feminist views on Athena are sharply divided; some feminists regard her as a symbol of female empowerment, while others regard her as "the ultimate patriarchal sell out... who uses her powers to promote and advance men rather than others of her sex." In contemporary Wicca, Athena is venerated as an aspect of the Goddess and some Wiccans believe that she may bestow the "Owl Gift" ("the ability to write and communicate clearly") upon her worshippers. Due to her status as one of the twelve Olympians, Athena is a major deity in Hellenismos, a Neopagan religion which seeks to authentically revive and recreate the religion of ancient Greece in the modern world.

Athena is a natural patron of universities: At Bryn Mawr College in Pennsylvania a statue of Athena (a replica of the original bronze one in the arts and archaeology library) resides in the Great Hall. It is traditional at exam time for students to leave offerings to the goddess with a note asking for good luck, or to repent for accidentally breaking any of the college's numerous other traditions. Pallas Athena is the tutelary goddess of the international social fraternity Phi Delta Theta. Her owl is also a symbol of the fraternity.





</doc>
<doc id="1183" url="https://en.wikipedia.org/wiki?curid=1183" title="Amber Diceless Roleplaying Game">
Amber Diceless Roleplaying Game

The Amber Diceless Roleplaying Game is a role-playing game created and written by Erick Wujcik, set in the fictional universe created by author Roger Zelazny for his "Chronicles of Amber". The game is unusual in that no dice are used in resolving conflicts or player actions; instead a simple diceless system of comparative ability, and narrative description of the action by the players and gamemaster, is used to determine how situations are resolved.

"Amber DRPG" was created in the 1980s, and is much more focused on relationships and roleplaying than most of the roleplaying games of that era. Most "Amber" characters are members of the two ruling classes in the "Amber" multiverse, and are much more advanced in matters of strength, endurance, psyche, warfare and sorcery than ordinary beings. This often means that the only individuals who are capable of opposing a character are from his or her family, a fact that leads to much suspicion and intrigue.

The original 256-page game book was published in 1991 by Phage Press, covering material from the first five novels (the "Corwin Cycle") and some details – sorcery and the Logrus – from the remaining five novels (the "Merlin Cycle"), in order to allow players to roleplay characters from the Courts of Chaos. Some details were changed slightly to allow more player choice – for example, players can be full Trump Artists without having walked the Pattern or the Logrus, which Merlin says is impossible; and players' psychic abilities are far greater than those shown in the books.
A 256-page companion volume, "Shadow Knight", was published in 1993. This supplemental rule book includes the remaining elements from the Merlin novels, such as Broken Patterns, and allows players to create Constructs such as Merlin's Ghostwheel. The book presents the second series of novels not as additions to the series' continuity but as an example of a roleplaying campaign with Merlin, Luke, Julia, Jurt and Coral as the PCs. The remainder of the book is a collection of essays on the game, statistics for the new characters and an update of the older ones in light of their appearance in the second series, and (perhaps most usefully for GMs) plot summaries of each of the ten books. The book includes some material from the short story "The Salesman's Tale," and some unpublished material cut from "Prince of Chaos", notably Coral's pregnancy by Merlin.

Both books were translated into French and published by Jeux Descartes in 1994 and 1995.

A third book, "Rebma", was promised. Cover art was commissioned and pre-orders were taken, but it never arrived. Wujcik also expressed a desire to create a book giving greater detail to the Courts of Chaos. The publishing rights to the "Amber DRPG" games were acquired in 2004 by Guardians of Order, who took over sales of the game and announced their intention to release a new edition of the game. However, no new edition was released before Guardians of Order went out of business in 2006. The two existing books are now out-of-print, but they have been made available as PDF downloads.

In June 2007 a new publishing company, headed by Edwin Voskamp and Eric Todd, was formed with the express purpose of bringing "Amber DRPG" back into print. The new company is named "Diceless by Design".

In May 2010, "Rite Publishing" secured a license from Diceless by Design to use the rules system with a new setting in the creation of a new product to be written by industry and system veteran Jason Durall. The project Lords of Gossamer & Shadow (Diceless) was funded via Kickstarter in May 2013. In Sept 2013 the project was completed, and on in Nov 2013 Lords of Gossamer and Shadow (Diceless) was released publicly in full-color Print and PDF, along with additional supplements and continued support.

The game is set in the multiverse described in Zelazny's "Chronicles of Amber". The first book assumes that gamemasters will set their campaigns after the Patternfall war; that is, after the end of the fifth book in the series, "The Courts of Chaos", but uses material from the following books to describe those parts of Zelazny's cosmology that were featured there in more detail. The "Amber" multiverse consists of Amber, a city at one pole of the universe wherein is found the Pattern, the symbol of Order; The Courts of Chaos, an assembly of worlds at the other pole where can be found the Logrus, the manifestation of Chaos, and the Abyss, the source or end of all reality; and Shadow, the collection of all possible universes (shadows) between and around them. Inhabitants of either pole can use one or both of the Pattern and the Logrus to travel through Shadow.

It is assumed that players will portray the children of the main characters from the books – the ruling family of Amber, known as the Elder Amberites – or a resident of the Courts. However, since some feel that being the children of the main characters is too limiting, it is fairly common to either start with King Oberon's death "before" the book begins and roleplay the Elder Amberites as they vie for the throne; or to populate Amber from scratch with a different set of Elder Amberites. The former option is one presented in the book; the latter is known in the Amber community as an "Amethyst" game. A third option is to have the players portray Corwin's children, in an Amber-like city built around Corwin's pattern; this is sometimes called an "Argent" game, since one of Corwin's heraldic colours is Silver.

Characters in "Amber DRPG" are represented by four attributes: "Psyche", "Strength", "Endurance" and "Warfare".
The attributes run from −25 (normal human level), through −10 (normal level for a denizen of the Courts of Chaos) and 0 (normal level for an inhabitant of Amber), upwards without limit. Scores above 0 are "ranked", with the highest score being ranked 1st, the next-highest 2nd, and so on. The character with 1st rank in each attribute is considered "superior" in that attribute, being considered to be substantially better than the character with 2nd rank even if the difference in scores is small. All else being equal, a character with a higher rank in an attribute will always win a contest based on that attribute.

A character's ability scores are purchased during character creation in an auction; players get 100 character points, and bid on each attribute in turn. The character who bids the most for an attribute is "ranked" first and is considered superior to all other characters in that attribute. Unlike conventional auctions, bids are non-refundable; if one player bids 65 for psyche and another wins with a bid of 66, then the character with 66 is "superior" to the character with 65 even though there is only one bid difference. Instead, lower bidding characters are ranked in ascending order according to how much they have bid, the characters becoming progressively weaker in that attribute as they pay less for it. After the auction, players can secretly pay extra points to raise their ranks, but they can only pay to raise their scores to an existing rank. Further, a character with a bid-for rank is considered to have a slight advantage over character with a bought-up rank.

The Auction simulates a 'history' of competition between the descendants of Oberon for player characters who have not had dozens of decades to get to know each other. Through the competitive Auction, characters may begin the game vying for standings. The auction serves to introduce some unpredictability into character creation without the need to resort to dice, cards, or other randomizing devices. A player may intend, for example, to create a character who is a strong, mighty warrior, but being "outplayed" in the auction may result in lower attribute scores than anticipated, therefore necessitating a change of character concept. Since a player cannot control another player's bids, and since all bids are non-refundable, the auction involves a considerable amount of strategizing and prioritization by players. A willingness to spend as many points as possible on an attribute may improve your chances of a high ranking, but too reckless a spending strategy could leave a player with few points to spend on powers and objects. In a hotly contested auction, such as for the important attribute of warfare, the most valuable skill is the ability to force one's opponents to back down. With two or more equally determined players, this can result in a "bidding war" where the attribute is driven up by increments to large sums. An alternative strategy is to try to cow other players into submission with a high opening bid. Most players bid low amounts between one and ten points in an initial bid in order to feel out the competition and to save points for other uses. A high enough opening bid could signal a player's determination to be first ranked in that attribute, thereby dissuading others from competing.

Characters with high psyche are presented as having strong telepathic abilities, being able to hypnotise and even mentally dominate any character with lesser psyche with whom they can make eye-contact. This is likely due to three scenes in the "Chronicles": first, when Eric paralyzes Corwin with an attack across the Trump and refuses to desist because one or the other would be dominated; second, when Corwin faces the demon Strygalldwir, it is able to wrestle mentally with him when their gazes meet; and third, when Fiona is able to keep Brand immobile in the final battle at the Courts of Chaos. However, in general, the books only feature mental battles when there is some reason for mind-to-mind contact (for example, Trump contact) and magic or Trump is involved in all three of the above conflicts, so it is not clear whether Zelazny intended his characters to have such a power; the combination of Brand's "living trump" powers and his high Psyche (as presented in the roleplaying game) would have guaranteed him victory over Corwin. "Shadow Knight" does address this inconsistency somewhat, by presenting the "living trump" abilities as somewhat limited.

Characters in "Amber DRPG" have access to the powers seen in the "Chronicles of Amber": "Pattern", "Logrus", "Shape-shifting", "Trump", and "magic".


Each of the first four powers is available in an advanced form.

While a character with Pattern, Logrus or Conjuration can acquire virtually any object, players can choose to spend character points to obtain objects with particular virtues – unbreakability, or a mind of their own. Since they have paid points for the items, they are a part of the character's legend, and cannot lightly be destroyed. Similarly, a character can find any possible universe, but they can spend character points to know of or inhabit shadows which are (in some sense) "real" and therefore useful. The expansion, "Shadow Knight", adds Constructs – artifacts with connections to shadows.

Unspent character points become good stuff – a good luck for the character. Players are also allowed to overspend (in moderation), with the points becoming bad stuff – bad luck which the Gamemaster should inflict on the character. Stuff governs how non-player characters perceive and respond to the character: characters with good stuff will often receive friendly or helpful reactions, while characters with bad stuff are often treated with suspicion or hostility.

As well as representing luck, stuff can be seen as representing a character's outlook on the universe: characters with good stuff seeing the multiverse as a cheerful place, while characters with bad stuff see it as hostile.

In any given fair conflict between two characters, the character with the higher score in the relevant attribute will eventually win. The key words here are "fair" and "eventually" – if characters' ranks are close, and the weaker character has obtained some advantage, then the weaker character can escape defeat or perhaps prevail. Close ranks result in longer contests while greater difference between ranks result in fast resolution. Alternatively, if characters' attribute ranks are close, the weaker character can try to change the relevant attribute by changing the nature of the conflict. For example, if two characters are wrestling the relevant attribute is Strength; a character could reveal a weapon, changing it to Warfare; they could try to overcome the other character's mind using a power, changing it to Psyche; or they could concentrate their strength on defense, changing it to Endurance. If there is a substantial difference between characters' ranks, the conflict is generally over before the weaker character can react.

"Amber DRPG" advises gamemasters to change rules as they see fit – even to the point of adding or removing powers or attributes.

Despite the game's out-of-print status, a thriving convention scene exists supporting the game. Amber conventions, known as "Ambercons", are held yearly in Massachusetts, Michigan, Portland (United States), Milton Keynes (England) and Modena, Italy. Additionally, Phage Press published 12 volumes of a dedicated "Amber DRPG" magazine called "Amberzine". Some "Amberzine" issues are still available from Phage Press.




</doc>
<doc id="1184" url="https://en.wikipedia.org/wiki?curid=1184" title="Athene (disambiguation)">
Athene (disambiguation)

Athene or Athena is the shrewd companion of heroes and the goddess of heroic endeavour in Greek mythology.

Athene may also refer to:




</doc>
<doc id="1187" url="https://en.wikipedia.org/wiki?curid=1187" title="Alloy">
Alloy

An alloy is a combination of metals or of a metal and another element. Alloys are defined by a metallic bonding character. An alloy may be a solid solution of metal elements (a single phase) or a mixture of metallic phases (two or more solutions). Intermetallic compounds are alloys with a defined stoichiometry and crystal structure. Zintl phases are also sometimes considered alloys depending on bond types (see also: Van Arkel-Ketelaar triangle for information on classifying bonding in binary compounds).

Alloys are used in a wide variety of applications. In some cases, a combination of metals may reduce the overall cost of the material while preserving important properties. In other cases, the combination of metals imparts synergistic properties to the constituent metal elements such as corrosion resistance or mechanical strength. Examples of alloys are steel, solder, brass, pewter, duralumin, bronze and amalgams.

The alloy constituents are usually measured by mass percentage for practical applications, and in atomic fraction for basic science studies. Alloys are usually classified as substitutional or interstitial alloys, depending on the atomic arrangement that forms the alloy. They can be further classified as homogeneous (consisting of a single phase), or heterogeneous (consisting of two or more phases) or intermetallic.

An alloy is a mixture of chemical elements, which forms an impure substance (admixture) that retains the characteristics of a metal. An alloy is distinct from an impure metal in that, with an alloy, the added elements are well controlled to produce desirable properties, while impure metals such as wrought iron are less controlled, but are often considered useful. Alloys are made by mixing two or more elements, at least one of which is a metal. This is usually called the primary metal or the base metal, and the name of this metal may also be the name of the alloy. The other constituents may or may not be metals but, when mixed with the molten base, they will be soluble and dissolve into the mixture.
The mechanical properties of alloys will often be quite different from those of its individual constituents. A metal that is normally very soft (malleable), such as aluminium, can be altered by alloying it with another soft metal, such as copper. Although both metals are very soft and ductile, the resulting aluminium alloy will have much greater strength. Adding a small amount of non-metallic carbon to iron trades its great ductility for the greater strength of an alloy called steel. Due to its very-high strength, but still substantial toughness, and its ability to be greatly altered by heat treatment, steel is one of the most useful and common alloys in modern use. By adding chromium to steel, its resistance to corrosion can be enhanced, creating stainless steel, while adding silicon will alter its electrical characteristics, producing silicon steel.

Although the elements of an alloy usually must be soluble in the liquid state, they may not always be soluble in the solid state. If the metals remain soluble when solid, the alloy forms a solid solution, becoming a homogeneous structure consisting of identical crystals, called a phase. If as the mixture cools the constituents become insoluble, they may separate to form two or more different types of crystals, creating a heterogeneous microstructure of different phases, some with more of one constituent than the other phase has. However, in other alloys, the insoluble elements may not separate until after crystallization occurs. If cooled very quickly, they first crystallize as a homogeneous phase, but they are supersaturated with the secondary constituents. As time passes, the atoms of these supersaturated alloys can separate from the crystal lattice, becoming more stable, and form a second phase that serve to reinforce the crystals internally.
Some alloys, such as electrum which is an alloy consisting of silver and gold, occur naturally. Meteorites are sometimes made of naturally occurring alloys of iron and nickel, but are not native to the Earth. One of the first alloys made by humans was bronze, which is a mixture of the metals tin and copper. Bronze was an extremely useful alloy to the ancients, because it is much stronger and harder than either of its components. Steel was another common alloy. However, in ancient times, it could only be created as an accidental byproduct from the heating of iron ore in fires (smelting) during the manufacture of iron. Other ancient alloys include pewter, brass and pig iron. In the modern age, steel can be created in many forms. Carbon steel can be made by varying only the carbon content, producing soft alloys like mild steel or hard alloys like spring steel. Alloy steels can be made by adding other elements, such as chromium, molybdenum, vanadium or nickel, resulting in alloys such as high-speed steel or tool steel. Small amounts of manganese are usually alloyed with most modern steels because of its ability to remove unwanted impurities, like phosphorus, sulfur and oxygen, which can have detrimental effects on the alloy. However, most alloys were not created until the 1900s, such as various aluminium, titanium, nickel, and magnesium alloys. Some modern superalloys, such as incoloy, inconel, and hastelloy, may consist of a multitude of different elements.

As a noun, the term alloy is used to describe a mixture of atoms in which the primary constituent is a metal. When used as a verb, the term refers to the act of mixing a metal with other elements. The primary metal is called the "base", the "matrix", or the "solvent". The secondary constituents are often called "solutes". If there is a mixture of only two types of atoms (not counting impurities) such as a copper-nickel alloy, then it is called a "binary alloy." If there are three types of atoms forming the mixture, such as iron, nickel and chromium, then it is called a "ternary alloy." An alloy with four constituents is a "quaternary alloy," while a five-part alloy is termed a "quinary alloy." Because the percentage of each constituent can be varied, with any mixture the entire range of possible variations is called a "system". In this respect, all of the various forms of an alloy containing only two constituents, like iron and carbon, is called a "binary system," while all of the alloy combinations possible with a ternary alloy, such as alloys of iron, carbon and chromium, is called a "ternary system".

Although an alloy is technically an impure metal, when referring to alloys, the term "impurities" usually denotes those elements which are not desired. Such impurities are introduced from the base metals and alloying elements, but are removed during processing. For instance, sulfur is a common impurity in steel. Sulfur combines readily with iron to form iron sulfide, which is very brittle, creating weak spots in the steel. Lithium, sodium and calcium are common impurities in aluminium alloys, which can have adverse effects on the structural integrity of castings. Conversely, otherwise pure-metals that simply contain unwanted impurities are often called "impure metals" and are not usually referred to as alloys. Oxygen, present in the air, readily combines with most metals to form metal oxides; especially at higher temperatures encountered during alloying. Great care is often taken during the alloying process to remove excess impurities, using fluxes, chemical additives, or other methods of extractive metallurgy.

In practice, some alloys are used so predominantly with respect to their base metals that the name of the primary constituent is also used as the name of the alloy. For example, 14 karat gold is an alloy of gold with other elements. Similarly, the silver used in jewelry and the aluminium used as a structural building material are also alloys.

The term "alloy" is sometimes used in everyday speech as a synonym for a particular alloy. For example, automobile wheels made of an aluminium alloy are commonly referred to as simply "alloy wheels", although in point of fact steels and most other metals in practical use are also alloys. Steel is such a common alloy that many items made from it, like wheels, barrels, or girders, are simply referred to by the name of the item, assuming it is made of steel. When made from other materials, they are typically specified as such, (i.e.: "bronze wheel", "plastic barrel", or "wood girder").

Alloying a metal is done by combining it with one or more other elements that often enhance its properties. For example, the combination of carbon with iron produces steel, which is stronger than iron, its primary element. The electrical and thermal conductivity of alloys is usually lower than that of the pure metals. The physical properties, such as density, reactivity, Young's modulus of an alloy may not differ greatly from those of its base element, but engineering properties such as tensile strength, ductility, and shear strength may be substantially different from those of the constituent materials. This is sometimes a result of the sizes of the atoms in the alloy, because larger atoms exert a compressive force on neighboring atoms, and smaller atoms exert a tensile force on their neighbors, helping the alloy resist deformation. Sometimes alloys may exhibit marked differences in behavior even when small amounts of one element are present. For example, impurities in semiconducting ferromagnetic alloys lead to different properties, as first predicted by White, Hogan, Suhl, Tian Abrie and Nakamura.
Some alloys are made by melting and mixing two or more metals. Bronze, an alloy of copper and tin, was the first alloy discovered, during the prehistoric period now known as the Bronze Age. It was harder than pure copper and originally used to make tools and weapons, but was later superseded by metals and alloys with better properties. In later times bronze has been used for ornaments, bells, statues, and bearings. Brass is an alloy made from copper and zinc.

Unlike pure metals, most alloys do not have a single melting point, but a melting range during which the material is a mixture of solid and liquid phases (a slush). The temperature at which melting begins is called the solidus, and the temperature when melting is just complete is called the liquidus. For many alloys there is a particular alloy proportion (in some cases more than one), called either a eutectic mixture or a peritectic composition, which gives the alloy a unique and low melting point, and no liquid/solid slush transition.

Alloying elements are added to a base metal, to induce hardness, toughness, ductility, or other desired properties. Most metals and alloys can be work hardened by creating defects in their crystal structure. These defects are created during plastic deformation by hammering, bending, extruding, etcetera, and are permanent unless the metal is recrystallized. Otherwise, some alloys can also have their properties altered by heat treatment. Nearly all metals can be softened by annealing, which recrystallizes the alloy and repairs the defects, but not as many can be hardened by controlled heating and cooling. Many alloys of aluminium, copper, magnesium, titanium, and nickel can be strengthened to some degree by some method of heat treatment, but few respond to this to the same degree as does steel.

The base metal iron of the iron-carbon alloy known as steel, undergoes a change in the arrangement (allotropy) of the atoms of its crystal matrix at a certain temperature (usually between and , depending on carbon content). This allows the smaller carbon atoms to enter the interstices of the iron crystal. When this diffusion happens, the carbon atoms are said to be in "solution" in the iron, forming a particular single, homogeneous, crystalline phase called austenite. If the steel is cooled slowly, the carbon can diffuse out of the iron and it will gradually revert to its low temperature allotrope. During slow cooling, the carbon atoms will no longer be as soluble with the iron, and will be forced to precipitate out of solution, nucleating into a more concentrated form of iron carbide (FeC) in the spaces between the pure iron crystals. The steel then becomes heterogeneous, as it is formed of two phases, the iron-carbon phase called cementite (or carbide), and pure iron ferrite. Such a heat treatment produces a steel that is rather soft. If the steel is cooled quickly, however, the carbon atoms will not have time to diffuse and precipitate out as carbide, but will be trapped within the iron crystals. When rapidly cooled, a diffusionless (martensite) transformation occurs, in which the carbon atoms become trapped in solution. This causes the iron crystals to deform as the crystal structure tries to change to its low temperature state, leaving those crystals very hard but much less ductile (more brittle).

While the high strength of steel results when diffusion and precipitation is prevented (forming martinsite), most heat-treatable alloys are precipitation hardening alloys, that depend on the diffusion of alloying elements to achieve their strength. When heated to form a solution and then cooled quickly, these alloys become much softer than normal, during the diffusionless transformation, but then harden as they age. The solutes in these alloys will precipitate over time, forming intermetallic phases, which are difficult to discern from the base metal. Unlike steel, in which the solid solution separates into different crystal phases (carbide and ferrite), precipitation hardening alloys form different phases within the same crystal. These intermetallic alloys appear homogeneous in crystal structure, but tend to behave heterogeneously, becoming hard and somewhat brittle.

When a molten metal is mixed with another substance, there are two mechanisms that can cause an alloy to form, called "atom exchange" and the "interstitial mechanism". The relative size of each element in the mix plays a primary role in determining which mechanism will occur. When the atoms are relatively similar in size, the atom exchange method usually happens, where some of the atoms composing the metallic crystals are substituted with atoms of the other constituent. This is called a "substitutional alloy". Examples of substitutional alloys include bronze and brass, in which some of the copper atoms are substituted with either tin or zinc atoms respectively. In the case of the interstitial mechanism, one atom is usually much smaller than the other and can not successfully substitute for the other type of atom in the crystals of the base metal. Instead, the smaller atoms become trapped in the spaces between the atoms of the crystal matrix, called the "interstices". This is referred to as an "interstitial alloy". Steel is an example of an interstitial alloy, because the very small carbon atoms fit into interstices of the iron matrix. Stainless steel is an example of a combination of interstitial and substitutional alloys, because the carbon atoms fit into the interstices, but some of the iron atoms are substituted by nickel and chromium atoms.

The use of alloys by humans started with the use of meteoric iron, a naturally occurring alloy of nickel and iron. It is the main constituent of iron meteorites which occasionally fall down on Earth from outer space. As no metallurgic processes were used to separate iron from nickel, the alloy was used as it was. Meteoric iron could be forged from a red heat to make objects such as tools, weapons, and nails. In many cultures it was shaped by cold hammering into knives and arrowheads. They were often used as anvils. Meteoric iron was very rare and valuable, and difficult for ancient people to work.

Iron is usually found as iron ore on Earth, except for one deposit of native iron in Greenland, which was used by the Inuit people. Native copper, however, was found worldwide, along with silver, gold, and platinum, which were also used to make tools, jewelry, and other objects since Neolithic times. Copper was the hardest of these metals, and the most widely distributed. It became one of the most important metals to the ancients. Eventually, humans learned to smelt metals such as copper, and tin from ore, and, around 2500 BC, began alloying the two metals to form bronze, which was much harder than its ingredients. Tin was rare, however, being found mostly in Great Britain. In the Middle East, people began alloying copper with zinc to form brass. Ancient civilizations took into account the mixture and the various properties it produced, such as hardness, toughness and melting point, under various conditions of temperature and work hardening, developing much of the information contained in modern alloy phase diagrams. Arrowheads from the Chinese Qin dynasty (around 200 BC) were often constructed with a hard bronze-head, but a softer bronze-tang, combining the alloys to prevent both dulling and breaking during use.

Mercury has been smelted from cinnabar for thousands of years. Mercury dissolves many metals, such as gold, silver, and tin, to form amalgams (an alloy in a soft paste or liquid form at ambient temperature). Amalgams have been used since 200 BC in China for gilding objects such as armor and mirrors with precious metals. The ancient Romans often used mercury-tin amalgams for gilding their armor. The amalgam was applied as a paste and then heated until the mercury vaporized, leaving the gold, silver, or tin behind. Mercury was often used in mining, to extract precious metals like gold and silver from their ores.

Many ancient civilizations alloyed metals for purely aesthetic purposes. In ancient Egypt and Mycenae, gold was often alloyed with copper to produce red-gold, or iron to produce a bright burgundy-gold. Gold was often found alloyed with silver or other metals to produce various types of colored gold. These metals were also used to strengthen each other, for more practical purposes. Copper was often added to silver to make sterling silver, increasing its strength for use in dishes, silverware, and other practical items. Quite often, precious metals were alloyed with less valuable substances as a means to deceive buyers. Around 250 BC, Archimedes was commissioned by the king to find a way to check the purity of the gold in a crown, leading to the famous bath-house shouting of "Eureka!" upon the discovery of Archimedes' principle.

The term pewter covers a variety of alloys consisting primarily of tin. As a pure metal, tin is much too soft to be used for any practical purpose. However, during the Bronze Age, tin was a rare metal in many parts of Europe and the Mediterranean; due to this it was often valued higher than gold. To make jewellery, cutlery, or other objects from tin, it was usually alloyed with other metals to increase its strength and hardness. These metals were typically lead, antimony, bismuth or copper. These solutes were sometimes added individually in varying amounts, or added together, making a wide variety of objects, ranging from practical items such as dishes, surgical tools, candlesticks or funnels, to decorative items like ear rings and hair clips.

The earliest examples of pewter come from ancient Egypt, around 1450 BC. The use of pewter was widespread across Europe, from France to Norway and Britain (where most of the ancient tin was mined) to the Near East. The alloy was also used in China and the Far East, arriving in Japan around 800 AD, where it was used for making objects like ceremonial vessels, tea canisters, or chalices used in shinto shrines.

The first known smelting of iron began in Anatolia, around 1800 BC. Called the bloomery process, it produced very soft but ductile wrought iron. By 800 BC, iron-making technology had spread to Europe, arriving in Japan around 700 AD. Pig iron, a very hard but brittle alloy of iron and carbon, was being produced in China as early as 1200 BC, but did not arrive in Europe until the Middle Ages. Pig iron has a lower melting point than iron, and was used for making cast-iron. However, these metals found little practical use until the introduction of crucible steel around 300 BC. These steels were of poor quality, and the introduction of pattern welding, around the 1st century AD, sought to balance the extreme properties of the alloys by laminating them, to create a tougher metal. Around 700 AD, the Japanese began folding bloomery-steel and cast-iron in alternating layers to increase the strength of their swords, using clay fluxes to remove slag and impurities. This method of Japanese swordsmithing produced one of the purest steel-alloys of the early Middle Ages.

While the use of iron started to become more widespread around 1200 BC, mainly because of interruptions in the trade routes for tin, the metal was much softer than bronze. However, very small amounts of steel, (an alloy of iron and around 1% carbon), was always a byproduct of the bloomery process. The ability to modify the hardness of steel by heat treatment had been known since 1100 BC, and the rare material was valued for the manufacture of tools and weapons. Because the ancients could not produce temperatures high enough to melt iron fully, the production of steel in decent quantities did not occur until the introduction of blister steel during the Middle Ages. This method introduced carbon by heating wrought iron in charcoal for long periods of time, but the penetration of carbon was not very deep, so the alloy was not homogeneous. In 1740, Benjamin Huntsman began melting blister steel in a crucible to even out the carbon content, creating the first process for the mass production of tool steel. Huntsman's process was used for manufacturing tool steel until the early 1900s.

With the introduction of the blast furnace to Europe in the Middle Ages, pig iron was able to be produced in much higher volumes than wrought iron. Because pig iron could be melted, people began to develop processes of reducing the carbon in the liquid pig iron to create steel. Puddling had been used in China since the first century, and was introduced in Europe during the 1700s, where molten pig iron was stirred while exposed to the air, to remove the carbon by oxidation. In 1858, Sir Henry Bessemer developed a process of steel-making by blowing hot air through liquid pig iron to reduce the carbon content. The Bessemer process was able to produce the first large scale manufacture of steel.

Although steel is an alloy of iron and carbon, the term "alloy steel" usually only refers to those steels which contain other elements like vanadium, molybdenum, or cobalt in amounts sufficient to alter the properties of the base steel. Since ancient times when steel was used primarily for tools and weapons, the methods of producing and working the metal were often closely guarded secrets. Even long after the Age of reason, the steel industry was very competitive and manufacturers went though great lengths to keep their processes confidential, resisting any attempts to scientifically analyze the material for fear it would reveal their methods. For example, the people of Sheffield, a center of steel production in England, were known to routinely bar visitors and tourists from entering town to deter industrial espionage. Thus, almost no metallurgical information existed about steel until 1860. Because of this lack of understanding, steel was not generally considered an alloy until the decades between 1930 and 1970 (primarily due to the work of scientists like William Chandler Roberts-Austen, Adolph Martens, and Edgar Bain), so "alloy steel" became the popular term for ternary and quaternary steel-alloys.

After Benjamin Huntsman developed his crucible steel in 1740, he began experimenting with the addition of elements like manganese (in the form of a high-manganese pig-iron called "spiegeleisen"), which helped remove impurities such as phosphorus and oxygen; a process adopted by Bessemer and still used in modern steels (albeit in concentrations low enough to still be considered carbon steel). Afterward, many people began experimenting with various alloys of steel without much success. However, in 1882, Robert Hadfield, being a pioneer in steel metallurgy, took an interest and produced a steel alloy containing around 12% manganese. Called mangalloy, it exhibited extreme hardness and toughness, becoming the first commercially viable alloy-steel. Afterward, he created silicon steel, launching the search for other possible alloys of steel.

Robert Forester Mushet found that by adding tungsten to steel it could produce a very hard edge that would resist losing its hardness at high temperatures. "R. Mushet's special steel" (RMS) became the first high-speed steel. In 1912, the Krupp Ironworks in Germany developed a rust-resistant steel by adding 21% chromium and 7% nickel, producing the first stainless steel.

In 1906, precipitation hardening alloys were discovered by Alfred Wilm. Precipitation hardening alloys, such as certain alloys of aluminium, titanium, and copper, are heat-treatable alloys that soften when quenched (cooled quickly), and then harden over time. After quenching a ternary alloy of aluminium, copper, and magnesium, Wilm discovered that the alloy increased in hardness when left to age at room temperature. Although an explanation for the phenomenon was not provided until 1919, duralumin was one of the first "age hardening" alloys to be used, and was soon followed by many others. Because they often exhibit a combination of high strength and low weight, these alloys became widely used in many forms of industry, including the construction of modern aircraft.




</doc>
<doc id="1192" url="https://en.wikipedia.org/wiki?curid=1192" title="Artistic revolution">
Artistic revolution

Throughout history, forms of art have gone through periodic abrupt changes called artistic revolutions. Movements have come to an end to be replaced by a new movement markedly different in striking ways. See also cultural movements.

The role of fine art has been to simultaneously express values of the current culture while also offering criticism, balance, or alternatives to any such values that are proving no longer useful. So as times change, art changes. If changes were abrupt they were deemed revolutions. The best artists have predated society's changes due not to any prescience, but because sensitive perceptivity is part of their talent of seeing.

Artists who succeeded enough to portray visions that future generations could live to see, often had to navigate an often treacherous path between their own capacity to see and execute what lesser artists could not, while still appealing to powerful patrons who could finance their visions. For example, paintings glorified aristocracy in the early 17th century when leadership was needed to nationalize small political groupings, but later as leadership became oppressive, satirization increased and subjects were less concerned with leaders and more with more common plights of mankind.

No art owes quite as much to state power as French painting does. It was in the age of absolute monarchy launched by Louix XIV in the 17th century that the likes of Poussin and Le Brun put France in the forefront of European art. Versailles found its stately mirror in the powerful idea of classicism – a painting style, enduring in later artists like Ingres, whose austerity and grandeur express the authority of a world where Jove is very much in his throne.

Examples of revolutionary art in conjunction with cultural and political movements:


Here is an example of an Artistic Revolution Pieces

Not all artistic revolutions were political. Sometimes, science and technological innovations have brought about unforeseen transformations in the works of artists. The stylistic revolution known as Impressionism, by painters eager to more accurately capture the changing colors of light and shadow, is inseparable from discoveries and inventions in the mid-19th century in which the style was born.

Eugene Chevreul, a French chemist hired as director of dyes at a French tapestry works, began to investigate the optical nature of color in order to improve color in fabrics. Chevreul realized It was the eye, and not the dye, that had the greatest influence on color, and from this, he revolutionized color theory by grasping what came to be called the law of simultaneous contrast: that colors mutually influence one another when juxtaposed, each imposing its own complementary color on the other. The French painter Eugène Delacroix, who had been experimenting with what he called broken tones, embraced Chevreul's book, "The Law of Contrast of Color (1839) with its explanations of how juxtaposed colors can enhance or diminish each other, and his exploration of all the visible colors of the spectrum. Inspired by Chevreul’s 1839 treatise, Delacroix passed his enthusiasm on to the young artists who were inspired by him. It was Chevreul who led the Impressionists to grasp that they should apply separate brushstrokes of pure color to a canvas and allow the viewer’s eye to combine them optically.

They were aided greatly in this by innovations in oil paint itself. Since the Renaissance, painters had to grind pigment, add oil and thus create their own paints; these time-consuming paints also quickly dried out, making studio painting a necessity for large works, and limiting painters to mix one or two colors at a time and fill in an entire area using just that one color before it dried out. in 1841, a little-known American painter named John G. Rand invented a simple improvement without which the Impressionist movement could not have occurred: the small, flexible tin tube with removable cap in which oil paints could be stored. Oil paints kept in such tubes stayed moist and usable -- and quite portable. For the first time since the Renaissance, painters were not trapped by the time frame of how quickly oil paint dried.

Paints in tubes could be easily loaded up and carried out into the real world, to directly observe the play of color and natural light, in shadow and movement, to paint in the moment. Selling the oil paint in tubes also brought about the arrival of dazzling new pigments - chrome yellow, cadmium blue - invented by 19th century industrial chemists. The tubes freed the Impressionists to paint quickly, and across an entire canvas, rather than carefully delineated single-color sections at a time; in short, to sketch directly in oil - racing across the canvas in every color that came to hand and thus inspiring their name of "impressionists" - since such speedy, bold brushwork and dabs of separate colors made contemporary critics think their paintings were mere impressions, not finished paintings, which were to have no visible brush marks at all, seamless under layers of varnish.

Pierre-Auguste Renoir said, “Without colors in tubes, there would be no Cézanne, no Monet, no Pissarro, and no Impressionism.”

Finally, the careful, hyper-realistic techniques of French neo-classicism were seen as stiff and lifeless when compared to the remarkable new vision of the world as seen through the new invention of photography by the mid-1850s. It was not merely that the increasing ability of this new invention, particularly by the French inventor Daguerre, made the realism of the painted image redundant as he deliberately competed in the Paris diorama with large-scale historical paintings. The neo-classical subject matter, limited by Academic tradition to Greek and Roman legends, historical battles and Biblical stories, seemed oppressively cliched and limited to artists eager to explore the actual world in front of their own eyes revealed by the camera - daily life, candid groupings of everyday people doing simple things, Paris itself, rural landscapes and most particularly the play of captured light - not the imaginary lionizing of unseen past events. Early photographs influenced Impressionist style by its use of asymmetry, cropping and most obviously the blurring of motion, as inadvertently captured in the very slow speeds of early photography.

Their initial break with realism into an exploration of light, color and the nature of paint was brought to an ultimate conclusion by the Abstract Expressionists who broke away from recognizable content of any kind into works of pure shape, color and painterliness which emerged at the end of the second world war. At first thought of as primitive, inept works - as in "my four year old could do that"—these works were misunderstood and neglected until given critical and support by the rise of art journalists and critics who championed their work in the 1940s and 50's, expressing the power of such work in aesthetic terms the artists themselves seldom used, or even understood. Jackson Pollock who pioneered splatter painting, dispensing with a paint brush altogether, soon became lionized as the angry young man in a large spread in Life Magazine.

In fact, in a deliberate, secret and successful effort to separate artistic revolutions from political ones, abstract expressionists like Pollack, Robert Motherwell, Willem de Kooning and Mark Rothko, while seemingly difficult, pathbreaking artists, were in fact secretly supported for twenty years by the C.I.A. in a Cold War policy begun in 1947 to prove that the United States could foster more artistic freedom than the Soviet bloc. "It was recognized that Abstract Expressionism was the kind of art that made Socialist Realism look even more stylized and rigid and confined than it was, " said former C.I.A. case worker Donald Jameson, who finally broke the silence on this program in 1995. Ironically, the covert C.I.A. support for these radical works was required because an attempt to use government funds for a European tour of these works during the Truman administration led to a public uproar in conservative McCarthy-era America, with Truman famously remarking, "If that's art, I'm a Hottentot." Thus the program was hidden under the guise of fabricated foundations and the support of wealthy patrons who were actually using C.I.A. funds, not their own, to sponsor traveling exhibitions of American abstract expressionists all over the world, publish books and articles praising them and to purchase and exhibit Abstract Expressionist works in major American and British museums. Thomas Braden, in charge of these cultural programs for the C.I.A.. in the early years of the Cold War, had formerly been executive secretary of the Museum of Modern Art, America's leading institution for 20th Century art and the charges of collusion between the two echoed for many years after this program was revealed, though most of the artists involved had no idea they were being used in this way and were furious when they found out.

Key dates: 15000 BCE / 400 BCE-200CE / 350 CE-450CE
Ancient - There are few remaining examples with early art often favouring drawing over colour. Work has been found recently in tombs, Egyptian frescoes, pottery and metalwork.
Classical - Relating to or from ancient Roman or Greek architecture and art. Mainly concerned with geometry and symmetry rather than individual expression.
Byzantine - A religious art characterised by large domes, rounded arches and mosaics from the eastern Roman Empire in the 4th Century.

Key dates: 400CE
Medieval - A highly religious art beginning in the 5th Century in Western Europe. It was characterised by iconographic paintings illustrating scenes from the bible.
Gothic - This style prevailed between the 12th century and the 16th century in Europe. Mainly an architectural movement, Gothic was characterised by its detailed ornamentation most noticeably the pointed archways and elaborate rib vaulting.
First developed in France, Gothic was intended as a solution to the inadequacies of Romanesque architecture. It allowed for cathedrals to be built with thinner walls and it became possible to introduce stained glass windows instead of traditional mosaic decorations. Some of the finest examples of the style include the cathedrals of Chartres, Reims and Amiens. The term was also used to describe sculpture and painting that demonstrated a greater degree of naturalism.

Key dates: 14th century
This movement began in Italy in the 14th century and the term, literally meaning rebirth, describes the revival of interest in the artistic achievements of the Classical world. Initially in a literary revival Renaissance was determined to move away from the religion-dominated Middle Ages and to turn its attention to the plight of the individual man in society. It was a time when individual expression and worldly experience became two of the main themes of Renaissance art. The movement owed a lot to the increasing sophistication of society, characterised by political stability, economic growth and cosmopolitanism. Education blossomed at this time, with libraries and academies allowing more thorough research to be conducted into the culture of the antique world. In addition, the arts benefited from the patronage of such influential groups as the Medici family of Florence, the Sforza family of Milan and Popes Julius II and Leo X. The works of Petrarch first displayed the new interest in the intellectual values of the Classical world in the early 14th century and the romance of this era as rediscovered in the Renaissance period can be seen expressed by Boccaccio. Leonardo da Vinci was the archetypal Renaissance man representing the humanistic values of the period in his art, science and writing. Michelangelo and Raphael were also vital figures in this movement, producing works regarded for centuries as embodying the classical notion of perfection. Renaissance architects included Alberti, Brunelleschi and Bramante. Many of these artists came from Florence and it remained an important centre for the Renaissance into the 16th century eventually to be overtaken by Rome and Venice. Some of the ideas of the Italian Renaissance did spread to other parts of Europe, for example to the German artist Albrecht Dürer of the 'Northern Renaissance'. But by the 16th century Mannerism had overtaken the Renaissance and it was this style that caught on in Europe. 
Representative artists:
Leonardo da Vinci, Sandro Botticelli, Filippo Brunelleschi, Raphael da Urbino, Titian, Michelangelo Buonarroti, and Donatello Bardi.

Key dates: 1520-1600
Artists of the Early Renaissance and the High Renaissance developed their characteristic styles from the observation of nature and the formulation of a pictorial science. When Mannerism matured after 1520(The year Raphael died), all the representational problems had been solved. A body of knowledge was there to be learned. Instead of nature as their teacher, Mannerist artists took art. While Renaissance artists sought nature to find their style, the Mannerists looked first for a style and found a manner. In Mannerist paintings, compositions can have no focal point, space can be ambiguous, figures can be characterized by an athletic bending and twisting with distortions, exaggerations, an elastic elongation of the limbs, bizarre posturing on one hand, graceful posturing on the other hand, and a rendering of the heads as uniformly small and oval. The composition is jammed by clashing colors, which is unlike what we've seen in the balanced, natural, and dramatic colors of the High Renaissance. Mannerist artwork seeks instability and restlessness. There is also a fondness for allegories that have lascivious undertones. 
Representative artists:
Andrea del Sarto, Jacopo da Pontormo, Correggio

Key dates: 17th century
Baroque Art emerged in Europe around 1600, as a reaction against the intricate and formulaic Mannerist style which dominated the Late Renaissance. Baroque Art is less complex, more realistic and more emotionally affecting than Mannerism.
This movement was encouraged by the Catholic Church, the most important patron of the arts at that time, as a return to tradition and spirituality.
One of the great periods of art history, Baroque Art was developed by Caravaggio, Annibale Carracci, and Gianlorenzo Bernini, among others. This was also the age of Rubens, Rembrandt, Velázquez, and Vermeer.
In the 18th century, Baroque Art was replaced by the more elegant and elaborate Rococo style.
Representative artists:
Caravaggio, Annibale Carracci, Gianlorenzo Bernini, Rubens, Rembrandt, Nicolas Poussin

Key dates: 18th century
Throughout the 18th century in France, a new wealthy and influential middle-class was beginning to rise, even though the royalty and nobility continued to be patrons of the arts. Upon the death of Louis XIV and the abandonment of Versailles, the Paris high society became the purveyors of style. This style, primarily used in interior decoration, came to be called Rococo. The term Rococo was derived from the French word "rocaille", which means pebbles and refers to the stones and shells used to decorate the interiors of caves. Therefore, shell forms became the principal motif in Rococo. The society women competed for the best and most elaborate decorations for their houses. Hence the Rococo style was highly dominated by the feminine taste and influence.
François Boucher was the 18th century painter and engraver whose works are regarded as the perfect expression of French taste in the Rococo period. Trained by his father who was a lace designer, Boucher won fame with his sensuous and light-hearted mythological paintings and landscapes. He executed important works for both the Queen of France and Mme. de Pompadour, Louis XV's mistress, who was considered the most powerful woman in France at the time. Boucher was Mme. de Pompadour's favorite artist and was commissioned by her for numerous paintings and decorations. Boucher also became the principal designer for the royal porcelain factory and the director of the Gobelins tapestry factory. The Vulcan Presenting Venus with Arms for Aeneas is a template for a tapestry made by this factory. 
Characterized by elegant and refined yet playful subject matters, Boucher's style became the epitome of the court of Louis XV. His style consisted of delicate colors and gentle forms painted within a frivolous subject matter. His works typically utilized delightful and decorative designs to illustrate graceful stories with Arcadian shepherds, goddesses and cupids playing against a pink and blue sky. These works mirrored the frolicsome, artificial and ornamented decadence of the French aristocracy of the time.
The Rococo is sometimes considered a final phase of the Baroque period.
Representative artists:
François Boucher, William Hogarth, Giovanni Battista Tiepolo, Angelica Kauffman, Giovanni Antonio Canaletto, Velázquez Vermeer

Key dates: 1750-1880
A nineteenth-century French art style and movement that originated as a reaction to the Baroque. It sought to revive the ideals of ancient Greek and Roman art. Neoclassic artists used classical forms to express their ideas about courage, sacrifice, and love of country. David and Canova are examples of neo-classicists.
Representative artists:
Jacques-Louis David, Sir Henry Raeburn, Sir Joshua Reynolds, Jean-Auguste-Dominique Ingres, Thomas Gainsborough, Antonio Canova, Arnold Bocklin

Key dates: 1800-1880
Romanticism was basically a reaction against Neoclassicism, it is a deeply felt style which is individualistic, beautiful, exotic, and emotionally wrought.
Although Romanticism and Neoclassicism were philosophically opposed, they were the dominant European styles for generations, and many artists were affected to a greater or lesser degree by both. Artists might work in both styles at different times or even mix the styles, creating an intellectually Romantic work using a Neoclassical visual style, for example.
Great artists closely associated with Romanticism include J.M.W. Turner, Caspar David Friedrich, John Constable, and William Blake.
In the United States, the leading Romantic movement was the Hudson River School of dramatic landscape painting.
Obvious successors of Romanticism include the Pre-Raphaelite movement and the Symbolists. But Impressionism, and through it almost all of 20th-century art, is also firmly rooted in the Romantic tradition. 
Representative artists:
George Stubbs, William Blake, John Martin, Francisco Goya, Sir Thomas Lawrence, John Constable, Eugène Delacroix, Sir Edwin landseer, Caspar David Friedrich, JMW Turner


</doc>
<doc id="1193" url="https://en.wikipedia.org/wiki?curid=1193" title="Agrarianism">
Agrarianism

Agrarianism is a social philosophy or political philosophy which values rural society as superior to urban society, the independent farmer as superior to the paid worker, and sees farming as a way of life that can shape the ideal social values. It stresses the superiority of a simpler rural life as opposed to the complexity of city life.

M. Thomas Inge defines agrarianism by the following basic tenets:

The philosophical roots of agrarianism include European and Chinese philosophers. The Chinese school of Agriculturalism (农家/農家) was a philosophy that advocated peasant utopian communalism and egalitarianism. In societies influenced by Confucianism, the farmer was considered an esteemed productive member of society, but merchants who made money were looked down upon. That influenced European intellectuals like François Quesnay, an avid Confucianist and advocate of China's agrarian policies, in forming the French agrarian philosophy of physiocracy. The physiocrats, along with the ideas of John Locke and the Romantic Era, formed the basis of modern European and American agrarianism.

United States president (1801–1809) Thomas Jefferson was a representative agrarian who built Jeffersonian democracy around the notion that farmers are “the most valuable citizens” and the truest republicans.

Peasant parties first appeared across Eastern Europe between 1860 and 1910, when commercialized agriculture and world market forces disrupted traditional rural society, and the railway and growing literacy facilitated the work of roving organizers. Agrarian parties advocated land reforms to redistribute land on large estates among those who work it. They also wanted village cooperatives to keep the profit from crop sales in local hands and credit institutions to underwrite needed improvements. Many peasant parties were also nationalist parties because peasants often worked their land for the benefit of landlords of different ethnicity.

Peasant parties rarely had any power before World War I but some became influential in the interwar era, especially in Bulgaria and Czechoslovakia. For a while, in the 1920s and the 1930s, there was a Green International (International Agrarian Bureau) based on the peasant parties in Bulgaria, Czechoslovakia, Poland, and Serbia. It functioned primarily as an information center that spread the ideas of agrarianism and combating socialism on the left and landlords on the right and never launched any significant activities.

The Farmers' Voice Party won a seat in the district of Jendouba after the parliamentary election of 2014.

In Bulgaria, the Bulgarian Agrarian National Union (BZNS) was organized in 1899 to resist taxes and build cooperatives. BZNS came to power in 1919 and introduced many economic, social, and legal reforms. However, conservative forces crushed BZNS in a 1923 coup and assassinated its leader, Aleksandar Stamboliyski (1879–1923). BZNS was made into a communist puppet group until 1989, when it reorganized as a genuine party.

In Czechoslovakia, the Republican Party of Agricultural and Smallholder People often shared power in parliament as a partner in the five-party pětka coalition. The party's leader, Antonin Svehla (1873–1933), was prime minister several times. It was consistently the strongest party, forming and dominating coalitions. It moved beyond its original agrarian base to reach middle-class voters.The party was banned by the National Front after the Second World War.

In France, the Hunting, Fishing, Nature, Tradition party is a moderate conservative, agrarianist party, reaching a peak of 4,23% in the French presidential election, 2002. It would later on become affiliated to France's main conservative party, Union for a Popular Movement.

In the late 19th century, the Irish National Land League aimed to abolish landlordism in Ireland and enable tenant farmers to own the land they worked on. The "Land War" of 1878–1909 led to the Irish Land Acts, ending such iniquities as absentee landlords and ground rent and redistributing land among peasant farmers.

Post-independence, the Farmers' Party operated in the Irish Free State from 1922, folding into the National Centre Party in 1932. It was mostly supported by wealthy farmers in the east of Ireland.

Clann na Talmhan (Family of the Land; also called the "National Agricultural Party") were founded in 1938. They focused more on the poor smallholders of the west, supporting land reclamation, afforestation, social democracy and rates reform. They formed part of the governing coalition of the Government of the 13th Dáil and Government of the 15th Dáil. Economic improvement in the 1960s saw farmers vote for other parties and Clann na Talmhan disbanded in 1965.

In Latvia, the Union of Greens and Farmers is supportive of traditional small farms and perceives them as more environmentally friendly than large-scale farming: Nature is threatened by development, while small farms are threatened by large industrial-scale farms.

In Lithuania, as of 2017, the government is led by the Lithuanian Farmers and Greens Union, under the leadership of industrial farmer Ramūnas Karbauskis.

In Poland, the Polish People's Party traces its tradition to an agrarian party in Austro-Hungarian-controlled Galician Poland. After the fall of the communist regime, PPP's biggest success came in 1993 elections, where it won 132 out of 460 parliamentary seats. Since then, PPP's support has steadily declined.

In Romania, older parties from Transylvania, Moldavia, and Wallachia merged to become the National Peasants' Party in 1926. Iuliu Maniu (1873–1953) was a prime minister with an agrarian cabinet from 1928–1930 and briefly in 1932–1933, but the Great Depression made proposed reforms impossible. The communist regime dissolved the party in 1947, but it reformed in 1989 after they fell from power.

The reformed party, which also incorporated elements of Christian democracy in its ideology, governed Romania as part of the Romanian Democratic Convention between 1996–2000.

In Serbia, Nikola Pašić (1845–1926) and his People's Radical Party dominated Serbian politics after 1903. The party also monopolized power in Yugoslavia from 1918 to 1929. During the dictatorship of the 1930s, the prime minister was from that party.

In Ukraine, the Radical Party of Oleh Lyashko has promised to purify the country of oligarchs "with a pitchfork". The party advocates a number of traditional left-wing positions (lower salary taxes, a ban on agricultural land sale and eliminating the illegal land market, a tenfold increase in budget spending on health, setting up primary health centres in every village
), and mixes them with strong nationalist sentiments.

Historian F.K. Crowley finds that:

The National Party of Australia (formerly called the Country Party), from the 1920s to the 1970s, promulgated its version of agrarianism, which it called "countrymindedness". The goal was to enhance the status of the graziers (operators of big sheep ranches) and small farmers and justified subsidies for them.

The New Zealand Liberal Party aggressively promoted agrarianism in its heyday (1891–1912). The landed gentry and aristocracy ruled Britain at this time. New Zealand never had an aristocracy but its wealthy landowners largely controlled politics before 1891. The Liberal Party set out to change that by a policy it called "populism." Richard Seddon had proclaimed the goal as early as 1884: "It is the rich and the poor; it is the wealthy and the landowners against the middle and labouring classes. That, Sir, shows the real political position of New Zealand." The Liberal strategy was to create a large class of small landowning farmers who supported Liberal ideals. The Liberal government also established the basis of the later welfare state such as old age pensions and developed a system for settling industrial disputes, which was accepted by both employers and trade unions. In 1893, it extended voting rights to women, making New Zealand the first country in the world to do so.

To obtain land for farmers, the Liberal government from 1891 to 1911 purchased of Maori land. The government also purchased from large estate holders for subdivision and closer settlement by small farmers. The Advances to Settlers Act (1894) provided low-interest mortgages, and the agriculture department disseminated information on the best farming methods. The Liberals proclaimed success in forging an egalitarian, anti-monopoly land policy. The policy built up support for the Liberal Party in rural North Island electorates. By 1903, the Liberals were so dominant that there was no longer an organized opposition in Parliament.

Agrarianism is similar to but not identical with the back-to-the-land movement. Agrarianism concentrates on the fundamental goods of the earth, on communities of more limited economic and political scale than in modern society, and on simple living, even when the shift involves questioning the "progressive" character of some recent social and economic developments. Thus, agrarianism is not industrial farming, with its specialization on products and industrial scale.








</doc>
<doc id="1194" url="https://en.wikipedia.org/wiki?curid=1194" title="Atomic">
Atomic

Atomic may refer to:






</doc>
<doc id="1196" url="https://en.wikipedia.org/wiki?curid=1196" title="Angle">
Angle

In planar geometry, an angle is the figure formed by two rays, called the "sides" of the angle, sharing a common endpoint, called the "vertex" of the angle.
Angles formed by two rays lie in a plane, but this plane does not have to be a Euclidean plane. Angles are also formed by the intersection of two planes in Euclidean and other spaces. These are called dihedral angles. Angles formed by the intersection of two curves in a plane are defined as the angle determined by the tangent rays at the point of intersection. Similar statements hold in space, for example, the spherical angle formed by two great circles on a sphere is the dihedral angle between the planes determined by the great circles.

"Angle" is also used to designate the measure of an angle or of a rotation. This measure is the ratio of the length of a circular arc to its radius. In the case of a geometric angle, the arc is centered at the vertex and delimited by the sides. In the case of a rotation, the arc is centered at the center of the rotation and delimited by any other point and its image by the rotation.

The word "angle" comes from the Latin word "angulus", meaning "corner"; cognate words are the Greek "(ankylοs)", meaning "crooked, curved," and the English word "ankle". Both are connected with the Proto-Indo-European root "*ank-", meaning "to bend" or "bow".
Euclid defines a plane angle as the inclination to each other, in a plane, of two lines which meet each other, and do not lie straight with respect to each other. According to Proclus an angle must be either a quality or a quantity, or a relationship. The first concept was used by Eudemus, who regarded an angle as a deviation from a straight line; the second by Carpus of Antioch, who regarded it as the interval or space between the intersecting lines; Euclid adopted the third concept, although his definitions of right, acute, and obtuse angles are certainly quantitative.

In mathematical expressions, it is common to use Greek letters (α, β, γ, θ, φ, . . . ) to serve as variables standing for the size of some angle. (To avoid confusion with its other meaning, the symbol is typically not used for this purpose.) Lower case Roman letters ("a", "b", "c", . . . ) are also used, as are upper case Roman letters in the context of polygons. See the figures in this article for examples.

In geometric figures, angles may also be identified by the labels attached to the three points that define them. For example, the angle at vertex A enclosed by the rays AB and AC (i.e. the lines from point A to point B and point A to point C) is denoted ∠BAC (in Unicode ) or formula_1. Sometimes, where there is no risk of confusion, the angle may be referred to simply by its vertex ("angle A").

Potentially, an angle denoted, say, ∠BAC might refer to any of four angles: the clockwise angle from B to C, the anticlockwise angle from B to C, the clockwise angle from C to B, or the anticlockwise angle from C to B, where the direction in which the angle is measured determines its sign (see Positive and negative angles). However, in many geometrical situations it is obvious from context that the positive angle less than or equal to 180 degrees is meant, and no ambiguity arises. Otherwise, a convention may be adopted so that ∠BAC always refers to the anticlockwise (positive) angle from B to C, and ∠CAB to the anticlockwise (positive) angle from C to B.


The names, intervals, and measured units are shown in a table below:


When two straight lines intersect at a point, four angles are formed. Pairwise these angles are named according to their location relative to each other.


A transversal is a line that intersects a pair of (often parallel) lines and is associated with "alternate interior angles", "corresponding angles", "interior angles", and "exterior angles".

There are three special angle pairs which involve the summation of angles:






The size of a geometric angle is usually characterized by the magnitude of the smallest rotation that maps one of the rays into the other. Angles that have the same size are said to be "equal" or "congruent" or "equal in measure".

In some contexts, such as identifying a point on a circle or describing the "orientation" of an object in two dimensions relative to a reference orientation, angles that differ by an exact multiple of a full turn are effectively equivalent. In other contexts, such as identifying a point on a spiral curve or describing the "cumulative rotation" of an object in two dimensions relative to a reference orientation, angles that differ by a non-zero multiple of a full turn are not equivalent.

In order to measure an angle θ, a circular arc centered at the vertex of the angle is drawn, e.g. with a pair of compasses. The ratio of the length s of the arc by the radius r of the circle is the measure of the angle in radians.

The measure of the angle in another angular unit is then obtained by multiplying its measure in radians by the scaling factor , where "k" is the measure of a complete turn in the chosen unit (for example 360 for degrees or 400 for gradians):

The value of θ thus defined is independent of the size of the circle: if the length of the radius is changed then the arc length changes in the same proportion, so the ratio "s"/"r" is unaltered. (Proof. The formula above can be rewritten as One turn, for which units, corresponds to an arc equal in length to the circle's circumference, which is 2"r", so . Substituting "n" for "θ" and 2"r" for "s" in the formula, results in ) 

The angle addition postulate states that if "B" is in the interior of angle "AOC", then

The measure of the angle "AOC" is the sum of the measure of angle AOB and the measure of angle "BOC". In this postulate it does not matter in which unit the angle is measured as long as each angle is measured in the same unit.

Units used to represent angles are listed below in descending magnitude order. Of these units, the "degree" and the "radian" are by far the most commonly used. Angles expressed in radians are dimensionless for the purposes of dimensional analysis.

Most units of angular measurement are defined such that one "turn" (i.e. one full circle) is equal to "n" units, for some whole number "n". The two exceptions are the radian and the diameter part.
















Although the definition of the measurement of an angle does not support the concept of a negative angle, it is frequently useful to impose a convention that allows positive and negative angular values to represent orientations and/or rotations in opposite directions relative to some reference.

In a two-dimensional Cartesian coordinate system, an angle is typically defined by its two sides, with its vertex at the origin. The "initial side" is on the positive x-axis, while the other side or "terminal side" is defined by the measure from the initial side in radians, degrees, or turns. With "positive angles" representing rotations toward the positive y-axis and "negative angles" representing rotations toward the negative "y"-axis. When Cartesian coordinates are represented by "standard position", defined by the "x"-axis rightward and the "y"-axis upward, positive rotations are anticlockwise and negative rotations are clockwise.

In many contexts, an angle of −"θ" is effectively equivalent to an angle of "one full turn minus "θ"". For example, an orientation represented as  −45° is effectively equivalent to an orientation represented as 360° − 45° or 315°. Although the final position is the same, a physical rotation (movement) of  −45° is not the same as a rotation of 315° (for example, the rotation of a person holding a broom resting on a dusty floor would leave visually different traces of swept regions on the floor).

In three-dimensional geometry, "clockwise" and "anticlockwise" have no absolute meaning, so the direction of positive and negative angles must be defined relative to some reference, which is typically a vector passing through the angle's vertex and perpendicular to the plane in which the rays of the angle lie.

In navigation, bearings are measured relative to north. By convention, viewed from above, bearing angles are positive clockwise, so a bearing of 45° corresponds to a north-east orientation. Negative bearings are not used in navigation, so a north-west orientation corresponds to a bearing of 315°.

There are several alternatives to measuring the size of an angle by the angle of rotation.
The "grade of a slope", or "gradient" is equal to the tangent of the angle, or sometimes (rarely) the sine. A gradient is often expressed as a percentage. For very small values (less than 5%), the grade of a slope is approximately the measure of the angle in radians.

In rational geometry the "spread" between two lines is defined as the square of the sine of the angle between the lines. As the sine of an angle and the sine of its supplementary angle are the same, any angle of rotation that maps one of the lines into the other leads to the same value for the spread between the lines.

Astronomers measure angular separation of objects in degrees from their point of observation.

These measurements clearly depend on the individual subject, and the above should be treated as rough rule of thumb approximations only.

The angle between a line and a curve (mixed angle) or between two intersecting curves (curvilinear angle) is defined to be the angle between the tangents at the point of intersection. Various names (now rarely, if ever, used) have been given to particular cases:—"amphicyrtic" (Gr. , on both sides, κυρτός, convex) or "cissoidal" (Gr. κισσός, ivy), biconvex; "xystroidal" or "sistroidal" (Gr. ξυστρίς, a tool for scraping), concavo-convex; "amphicoelic" (Gr. κοίλη, a hollow) or "angulus lunularis", biconcave.

The ancient Greek mathematicians knew how to bisect an angle (divide it into two angles of equal measure) using only a compass and straightedge, but could only trisect certain angles. In 1837 Pierre Wantzel showed that for most angles this construction cannot be performed.

In the Euclidean space, the angle "θ" between two Euclidean vectors u and v is related to their dot product and their lengths by the formula

This formula supplies an easy method to find the angle between two planes (or curved surfaces) from their normal vectors and between skew lines from their vector equations.

To define angles in an abstract real inner product space, we replace the Euclidean dot product ( · ) by the inner product formula_6, i.e.

In a complex inner product space, the expression for the cosine above may give non-real values, so it is replaced with

or, more commonly, using the absolute value, with

The latter definition ignores the direction of the vectors and thus describes the angle between one-dimensional subspaces formula_10 and formula_11 spanned by the vectors formula_12 and formula_13 correspondingly.

The definition of the angle between one-dimensional subspaces formula_10 and formula_11 given by

in a Hilbert space can be extended to subspaces of any finite dimensions. Given two subspaces formula_17, formula_18 with formula_19, this leads to a definition of formula_20 angles called canonical or principal angles between subspaces.

In Riemannian geometry, the metric tensor is used to define the angle between two tangents. Where "U" and "V" are tangent vectors and "g" are the components of the metric tensor "G",

A hyperbolic angle is an argument of a hyperbolic function just as the circular angle is the argument of a circular function. The comparison can be visualized as the size of the openings of a hyperbolic sector and a circular sector since the areas of these sectors correspond to the angle magnitudes in each case. Unlike the circular angle, the hyperbolic angle is unbounded. When the circular and hyperbolic functions are viewed as infinite series in their angle argument, the circular ones are just alternating series forms of the hyperbolic functions. This weaving of the two types of angle and function was explained by Leonhard Euler in "Introduction to the Analysis of the Infinite".

In geography, the location of any point on the Earth can be identified using a "geographic coordinate system". This system specifies the latitude and longitude of any location in terms of angles subtended at the centre of the Earth, using the equator and (usually) the Greenwich meridian as references.

In astronomy, a given point on the celestial sphere (that is, the apparent position of an astronomical object) can be identified using any of several "astronomical coordinate systems", where the references vary according to the particular system. Astronomers measure the "angular separation" of two stars by imagining two lines through the centre of the Earth, each intersecting one of the stars. The angle between those lines can be measured, and is the angular separation between the two stars.

In both geography and astronomy, a sighting direction can be specified in terms of a vertical angle such as altitude /elevation with respect to the horizon as well as the azimuth with respect to north.

Astronomers also measure the "apparent size" of objects as an angular diameter. For example, the full moon has an angular diameter of approximately 0.5°, when viewed from Earth. One could say, "The Moon's diameter subtends an angle of half a degree." The small-angle formula can be used to convert such an angular measurement into a distance/size ratio.


Attribution



</doc>
<doc id="1197" url="https://en.wikipedia.org/wiki?curid=1197" title="Asa">
Asa

Asa may refer to:





</doc>
<doc id="1198" url="https://en.wikipedia.org/wiki?curid=1198" title="Acoustics">
Acoustics

Acoustics is the branch of physics that deals with the study of all mechanical waves in gases, liquids, and solids including topics such as vibration, sound, ultrasound and infrasound. A scientist who works in the field of acoustics is an acoustician while someone working in the field of acoustics technology may be called an acoustical engineer. The application of acoustics is present in almost all aspects of modern society with the most obvious being the audio and noise control industries.

Hearing is one of the most crucial means of survival in the animal world, and speech is one of the most distinctive characteristics of human development and culture. Accordingly, the science of acoustics spreads across many facets of human society—music, medicine, architecture, industrial production, warfare and more. Likewise, animal species such as songbirds and frogs use sound and hearing as a key element of mating rituals or marking territories. Art, craft, science and technology have provoked one another to advance the whole, as in many other fields of knowledge. Robert Bruce Lindsay's 'Wheel of Acoustics' is a well accepted overview of the various fields in acoustics.

The word "acoustic" is derived from the Greek word ἀκουστικός ("akoustikos"), meaning "of or for hearing, ready to hear" and that from ἀκουστός ("akoustos"), "heard, audible", which in turn derives from the verb ("akouo"), "I hear".

The Latin synonym is "sonic", after which the term sonics used to be a synonym for acoustics and later a branch of acoustics. Frequencies above and below the audible range are called "ultrasonic" and "infrasonic", respectively.

In the 6th century BC, the ancient Greek philosopher Pythagoras wanted to know why some combinations of musical sounds seemed more beautiful than others, and he found answers in terms of numerical ratios representing the harmonic overtone series on a string. He is reputed to have observed that when the lengths of vibrating strings are expressible as ratios of integers (e.g. 2 to 3, 3 to 4), the tones produced will be harmonious, and the smaller the integers the more harmonious the sounds. If, for example, a string of a certain length would sound particularly harmonious with a string of twice the length (other factors being equal). In modern parlance, if a string sounds the note C when plucked, a string twice as long will sound a C an octave lower. In one system of musical tuning, the tones in between are then given by 16:9 for D, 8:5 for E, 3:2 for F, 4:3 for G, 6:5 for A, and 16:15 for B, in ascending order.

Aristotle (384–322 BC) understood that sound consisted of compressions and rarefactions of air which "falls upon and strikes the air which is next to it...", a very good expression of the nature of wave motion.

In about 20 BC, the Roman architect and engineer Vitruvius wrote a treatise on the acoustic properties of theaters including discussion of interference, echoes, and reverberation—the beginnings of architectural acoustics. In Book V of his "De architectura" ("The Ten Books of Architecture") Vitruvius describes sound as a wave comparable to a water wave extended to three dimensions, which, when interrupted by obstructions, would flow back and break up following waves. He described the ascending seats in ancient theaters as designed to prevent this deterioration of sound and also recommended bronze vessels of appropriate sizes be placed in theaters to resonate with the fourth, fifth and so on, up to the double octave, in order to resonate with the more desirable, harmonious notes.

The physical understanding of acoustical processes advanced rapidly during and after the Scientific Revolution. Mainly Galileo Galilei (1564–1642) but also Marin Mersenne (1588–1648), independently, discovered the complete laws of vibrating strings (completing what Pythagoras and Pythagoreans had started 2000 years earlier). Galileo wrote "Waves are produced by the vibrations of a sonorous body, which spread through the air, bringing to the tympanum of the ear a stimulus which the mind interprets as sound", a remarkable statement that points to the beginnings of physiological and psychological acoustics. Experimental measurements of the speed of sound in air were carried out successfully between 1630 and 1680 by a number of investigators, prominently Mersenne. Meanwhile, Newton (1642–1727) derived the relationship for wave velocity in solids, a cornerstone of physical acoustics (Principia, 1687).

The eighteenth century saw major advances in acoustics as mathematicians applied the new techniques of calculus to elaborate theories of sound wave propagation. In the nineteenth century the major figures of mathematical acoustics were Helmholtz in Germany, who consolidated the field of physiological acoustics, and Lord Rayleigh in England, who combined the previous knowledge with his own copious contributions to the field in his monumental work "The Theory of Sound" (1877). Also in the 19th century, Wheatstone, Ohm, and Henry developed the analogy between electricity and acoustics.

The twentieth century saw a burgeoning of technological applications of the large body of scientific knowledge that was by then in place. The first such application was Sabine’s groundbreaking work in architectural acoustics, and many others followed. Underwater acoustics was used for detecting submarines in the first World War. Sound recording and the telephone played important roles in a global transformation of society. Sound measurement and analysis reached new levels of accuracy and sophistication through the use of electronics and computing. The ultrasonic frequency range enabled wholly new kinds of application in medicine and industry. New kinds of transducers (generators and receivers of acoustic energy) were invented and put to use.

Acoustics is defined by ANSI/ASA S1.1-2013 as "(a) Science of sound, including its production, transmission, and effects, including biological and psychological effects. (b) Those qualities of a room that, together, determine its character with respect to auditory effects."

The study of acoustics revolves around the generation, propagation and reception of mechanical waves and vibrations.

The steps shown in the above diagram can be found in any acoustical event or process. There are many kinds of cause, both natural and volitional. There are many kinds of transduction process that convert energy from some other form into sonic energy, producing a sound wave. There is one fundamental equation that describes sound wave propagation, the acoustic wave equation, but the phenomena that emerge from it are varied and often complex. The wave carries energy throughout the propagating medium. Eventually this energy is transduced again into other forms, in ways that again may be natural and/or volitionally contrived. The final effect may be purely physical or it may reach far into the biological or volitional domains. The five basic steps are found equally well whether we are talking about an earthquake, a submarine using sonar to locate its foe, or a band playing in a rock concert.

The central stage in the acoustical process is wave propagation. This falls within the domain of physical acoustics. In fluids, sound propagates primarily as a pressure wave. In solids, mechanical waves can take many forms including longitudinal waves, transverse waves and surface waves.

Acoustics looks first at the pressure levels and frequencies in the sound wave and how the wave interacts with the environment. This interaction can be described as either a diffraction, interference or a reflection or a mix of the three. If several media are present, a refraction can also occur. Transduction processes are also of special importance to acoustics.

In fluids such as air and water, sound waves propagate as disturbances in the ambient pressure level. While this disturbance is usually small, it is still noticeable to the human ear. The smallest sound that a person can hear, known as the threshold of hearing, is nine orders of magnitude smaller than the ambient pressure. The loudness of these disturbances is related to the sound pressure level (SPL) which is measured on a logarithmic scale in decibels.

Physicists and acoustic engineers tend to discuss sound pressure levels in terms of frequencies, partly because this is how our ears interpret sound. What we experience as "higher pitched" or "lower pitched" sounds are pressure vibrations having a higher or lower number of cycles per second. In a common technique of acoustic measurement, acoustic signals are sampled in time, and then presented in more meaningful forms such as octave bands or time frequency plots. Both of these popular methods are used to analyze sound and better understand the acoustic phenomenon.

The entire spectrum can be divided into three sections: audio, ultrasonic, and infrasonic. The audio range falls between 20 Hz and 20,000 Hz. This range is important because its frequencies can be detected by the human ear. This range has a number of applications, including speech communication and music. The ultrasonic range refers to the very high frequencies: 20,000 Hz and higher. This range has shorter wavelengths which allow better resolution in imaging technologies. Medical applications such as ultrasonography and elastography rely on the ultrasonic frequency range. On the other end of the spectrum, the lowest frequencies are known as the infrasonic range. These frequencies can be used to study geological phenomena such as earthquakes.

Analytic instruments such as the spectrum analyzer facilitate visualization and measurement of acoustic signals and their properties. The spectrogram produced by such an instrument is a graphical display of the time varying pressure level and frequency profiles which give a specific acoustic signal its defining character.

A transducer is a device for converting one form of energy into another. In an electroacoustic context, this means converting sound energy into electrical energy (or vice versa). Electroacoustic transducers include loudspeakers, microphones, hydrophones and sonar projectors. These devices convert a sound pressure wave to or from an electric signal. The most widely used transduction principles are electromagnetism, electrostatics and piezoelectricity.

The transducers in most common loudspeakers (e.g. woofers and tweeters), are electromagnetic devices that generate waves using a suspended diaphragm driven by an electromagnetic voice coil, sending off pressure waves. Electret microphones and condenser microphones employ electrostatics—as the sound wave strikes the microphone's diaphragm, it moves and induces a voltage change. The ultrasonic systems used in medical ultrasonography employ piezoelectric transducers. These are made from special ceramics in which mechanical vibrations and electrical fields are interlinked through a property of the material itself.

An acoustician is an expert in the science of sound.

There are many types of acoustician, but they usually have a Bachelor's degree or higher qualification. Some possess a degree in acoustics, while others enter the discipline via studies in fields such as physics or engineering. Much work in acoustics requires a good grounding in Mathematics and science. Many acoustic scientists work in research and development. Some conduct basic research to advance our knowledge of the perception (e.g. hearing, psychoacoustics or neurophysiology) of speech, music and noise. Other acoustic scientists advance understanding of how sound is affected as it moves through environments, e.g. Underwater acoustics, Architectural acoustics or Structural acoustics. Others areas of work are listed under subdisciplines below. Acoustic scientists work in government, university and private industry laboratories. Many go on to work in Acoustical Engineering. Some positions, such as Faculty (academic staff) require a Doctor of Philosophy.

These subdisciplines are a slightly modified list from the PACS (Physics and Astronomy Classification Scheme) coding used by the Acoustical Society of America.

Archaeoacoustics is the study of sound within archaeology. This typically involves studying the acoustics of archaeological sites and artefacts.

Aeroacoustics is the study of noise generated by air movement, for instance via turbulence, and the movement of sound through the fluid air. This knowledge is applied in acoustical engineering to study how to quieten aircraft. Aeroacoustics is important to understanding how wind musical instruments work.

Acoustic signal processing is the electronic manipulation of acoustic signals. Applications include: active noise control; design for hearing aids or cochlear implants; echo cancellation; music information retrieval, and perceptual coding (e.g. MP3 or Opus).

Architectural acoustics (also known as building acoustics) involves the scientific understanding of how to achieve a good sound within a building. It typically involves the study of speech intelligibility, speech privacy, music quality, and vibration reduction in the built environment.

Bioacoustics is the scientific study of the hearing and calls of animal calls, as well as how animals are affected by the acoustic and sounds of their habitat.

This subdiscipline is concerned with the recording, manipulation and reproduction of audio using electronics. This might include products such as mobile phones, large scale public address systems or virtual reality systems in research laboratories.

Environmental acoustics is concerned with noise and vibration caused by railways, road traffic, aircraft, industrial equipment and recreational activities. The main aim of these studies is to reduce levels of environmental noise and vibration. Research work now also has a focus on the positive use of sound in urban environments: soundscapes and tranquility.

Musical acoustics is the study of the physics of acoustic instruments; the audio signal processing used in electronic music; the computer analysis of music and composition, and the perception and cognitive neuroscience of music.

Psychoacoustics explains how humans respond to sounds.

Acousticians study the production, processing and perception of speech. Speech recognition and Speech synthesis are two important areas of speech processing using computers. The subject also overlaps with the disciplines of physics, physiology, psychology, and linguistics.

Ultrasonics deals with sounds at frequencies too high to be heard by humans. Specialisms include medical ultrasonics (including medical ultrasonography), sonochemistry, material characterisation and underwater acoustics (Sonar).

Underwater acoustics is the scientific study of natural and man-made sounds underwater. Applications include sonar to locate submarines, underwater communication by whales, climate change monitoring by measuring sea temperatures acoustically, sonic weapons, and marine bioacoustics.

This is the study of how mechanical systems vibrate and interact with their surroundings. Applications might include: ground vibrations from railways; vibration isolation to reduce vibration in operating theatres; studying how vibration can damage health (vibration white finger); vibration control to protect a building from earthquakes, or measuring how structure-borne sound moves through buildings.






</doc>
<doc id="1200" url="https://en.wikipedia.org/wiki?curid=1200" title="Atomic physics">
Atomic physics

Atomic physics is the field of physics that studies atoms as an isolated system of electrons and an atomic nucleus. It is primarily concerned with the arrangement of electrons around the nucleus and
the processes by which these arrangements change. This comprises ions, neutral atoms and, unless otherwise stated, it can be assumed that the term "atom" includes ions.[citation needed]

The term "atomic physics" can be associated with nuclear power and nuclear weapons, due to the synonymous use of "atomic" and "nuclear" in standard English. Physicists distinguish between atomic physics — which deals with the atom as a system consisting of a nucleus and electrons — and nuclear physics, which considers atomic nuclei alone.

As with many scientific fields, strict delineation can be highly contrived and atomic physics is often considered in the wider context of "atomic, molecular, and optical physics". Physics research groups are usually so classified.

Atomic physics primarily considers atoms in isolation. Atomic models will consist of a single nucleus that may be surrounded by one or more bound electrons. It is not concerned with the formation of molecules (although much of the physics is identical), nor does it examine atoms in a solid state as condensed matter. It is concerned with processes such as ionization and excitation by photons or collisions with atomic particles.

While modelling atoms in isolation may not seem realistic, if one considers atoms in a gas or plasma then the time-scales for atom-atom interactions are huge in comparison to the atomic processes that are generally considered. This means that the individual atoms can be treated as if each were in isolation, as the vast majority of the time they are. By this consideration atomic physics provides the underlying theory in plasma physics and atmospheric physics, even though both deal with very large numbers of atoms.

Electrons form notional shells around the nucleus. These are normally in a ground state but can be excited by the absorption of energy from light (photons), magnetic fields, or interaction with a colliding particle (typically ions or other electrons).

If the electron absorbs a quantity of energy less than the binding energy, it will be transferred to an excited state. After a certain time, the electron in an excited state will "jump" (undergo a transition) to a lower state. In a neutral atom, the system will emit a photon of the difference in energy, since energy is conserved.

If an inner electron has absorbed more than the binding energy (so that the atom ionizes), then a more outer electron may undergo a transition to fill the inner orbital. In this case, a visible photon or a characteristic x-ray is emitted, or a phenomenon known as the Auger effect may take place, where the released energy is transferred to another bound electron, causing it to go into the continuum. The Auger effect allows one to multiply ionize an atom with a single photon.

There are rather strict selection rules as to the electronic configurations that can be reached by excitation by light — however there are no such rules for excitation by collision processes.

The majority of fields in physics can be divided between theoretical work and experimental work,
and atomic physics is no exception. It is usually the case, but not always, that progress goes
in alternate cycles from an experimental observation, through to a theoretical explanation
followed by some predictions that may or may not be confirmed by experiment, and so on. Of course, the current state of technology at any given time can put limitations on what can be achieved experimentally and theoretically so it may take considerable time for theory to be refined.

One of the earliest steps towards atomic physics was the recognition that matter was composed
of "atoms". It forms a part of the texts written in 6th century BC to 2nd century BC such as those of Democritus or Vaisheshika Sutra written by Kanad. This theory was later developed in the modern sense of the basic unit of a chemical element by the British chemist and physicist John Dalton in the 18th century. At this stage, it wasn't clear what atoms were although they could be described and classified by their properties (in bulk). The invention of the periodic system of elements by Mendeleev was another great step forward.

The true beginning of atomic physics is marked by the discovery of spectral lines and attempts to describe the phenomenon, most notably by Joseph von Fraunhofer. The study of these lines led to the Bohr atom model and to the birth of quantum mechanics. In seeking to explain atomic spectra an entirely new mathematical model of matter was revealed. As far as atoms and their electron shells were concerned, not only did this yield a better overall description, i.e. the atomic orbital model, but it also provided a new theoretical basis for chemistry
(quantum chemistry) and spectroscopy.

Since the Second World War, both theoretical and experimental fields have advanced at a rapid pace. This can be attributed to progress in computing technology, which has allowed larger and more sophisticated models of atomic structure and associated collision processes. Similar technological advances in accelerators, detectors, magnetic field generation and lasers have greatly assisted experimental work.




</doc>
<doc id="1201" url="https://en.wikipedia.org/wiki?curid=1201" title="American Sign Language">
American Sign Language

American Sign Language (ASL) is a natural language that serves as the predominant sign language of Deaf communities in the United States and most of Anglophone Canada. Besides North America, dialects of ASL and ASL-based creoles are used in many countries around the world, including much of West Africa and parts of Southeast Asia. ASL is also widely learned as a second language, serving as a lingua franca. ASL is most closely related to French Sign Language (LSF). It has been proposed that ASL is a creole language of LSF, although ASL shows features atypical of creole languages, such as agglutinative morphology.

ASL originated in the early 19th century in the American School for the Deaf (ASD) in Hartford, Connecticut, from a situation of language contact. Since then, ASL use has propagated widely via schools for the deaf and Deaf community organizations. Despite its wide use, no accurate count of ASL users has been taken, though reliable estimates for American ASL users range from 250,000 to 500,000 persons, including a number of children of deaf adults. ASL users face stigma due to beliefs in the superiority of oral language to sign language, compounded by the fact that ASL is often glossed in English due to the lack of a standard writing system.

ASL signs have a number of phonemic components, including movement of the face and torso as well as the hands. ASL is not a form of pantomime, but iconicity does play a larger role in ASL than in spoken languages. English loan words are often borrowed through fingerspelling, although ASL grammar is unrelated to that of English. ASL has verbal agreement and aspectual marking and has a productive system of forming agglutinative classifiers. Many linguists believe ASL to be a subject–verb–object (SVO) language, but there are several alternative proposals to account for ASL word order.

ASL emerged as a language in the American School for the Deaf (ASD), founded in 1817. This school brought together Old French Sign Language, various village sign languages, and home sign systems; ASL was created in this situation of language contact. ASL was influenced by its forerunners but distinct from all of them.

The influence of French Sign Language (LSF) on ASL is readily apparent; for example, it has been found that about 58% of signs in modern ASL are cognate to Old French Sign Language signs. However, this is far less than the standard 80% measure used to determine whether related languages are actually dialects. This suggests that nascent ASL was highly affected by the other signing systems brought by the ASD students, despite the fact that the school's original director Laurent Clerc taught in LSF. In fact, Clerc reported that he often learned the students' signs rather than conveying LSF:
It has been proposed that ASL is a creole with LSF as the superstrate language and with the native village sign languages as substrate languages. However, more recent research has shown that modern ASL does not share many of the structural features that characterize creole languages. ASL may have begun as a creole and then undergone structural change over time, but it is also possible that it was never a creole-type language. There are modality-specific reasons that sign languages tend towards agglutination, for example the ability to simultaneously convey information via the face, head, torso, and other body parts. This might override creole characteristics such as the tendency towards isolating morphology. Additionally, Clerc and Gallaudet may have used an artificially constructed form of manually coded language in instruction rather than true LSF.

Although the United States, the United Kingdom, and Australia share English as a common oral and written language, ASL is not mutually intelligible with British Sign Language (BSL) or Auslan. All three languages show degrees of borrowing from English, but this alone is not sufficient for cross-language comprehension. It has been found that a relatively high percentage (37–44%) of ASL signs have similar translations in Auslan, which for oral languages would suggest that they belong to the same language family. However, this does not seem justified historically for ASL and Auslan, and it is likely that this resemblance is due to the higher degree of iconicity in sign languages in general, as well as contact with English.

American Sign Language is growing in popularity among many states. Many people in high school and colleges wanting to take it as a foreign language, but until recently, it was not a creditable foreign language elective. The issue was that many didn't consider it a foreign language. ASL users, however, have a very distinct culture and way they interact when talking. Their facial expressions and hand movements reflect what they are conveying. They also have their own sentence structure which sets the language apart.

Prior to the birth of ASL, sign language had been used by various communities in the United States. In the United States, as elsewhere in the world, hearing families with deaf children have historically employed ad-hoc home sign, which often reaches much higher levels of sophistication than gestures used by hearing people in spoken conversation. As early as 1541 at first contact by Francisco Vásquez de Coronado, there were reports that the Plains Indians had developed a sign language to communicate between tribes of different languages.

In the 19th century, a "triangle" of village sign languages developed in New England: one in Martha's Vineyard, Massachusetts; one in Henniker, New Hampshire, and one in Sandy River Valley, Maine. Martha's Vineyard Sign Language (MVSL), which was particularly important for the history of ASL, was used mainly in Chilmark, Massachusetts. Due to intermarriage in the original community of English settlers of the 1690s, and the recessive nature of genetic deafness, Chilmark had a high 4% rate of genetic deafness. MVSL was used even by hearing residents whenever a deaf person was present.

ASL is thought to have originated in the American School for the Deaf (ASD), founded in Hartford, Connecticut in 1817. Originally known as "The American Asylum, At Hartford, For The Education And Instruction Of The Deaf And Dumb", the school was founded by the Yale graduate and divinity student Thomas Hopkins Gallaudet. Gallaudet, inspired by his success in demonstrating the learning abilities of a young deaf girl Alice Cogswell, traveled to Europe in order to learn deaf pedagogy from European institutions. Ultimately, Gallaudet chose to adopt the methods of the French Institut National de Jeunes Sourds de Paris, and convinced Laurent Clerc, an assistant to the school's founder Charles-Michel de l'Épée, to accompany him back to the United States. Upon his return, Gallaudet founded the ASD on April 15, 1817.

The largest group of students during the first seven decades of the school were from Martha's Vineyard, and they brought MVSL with them. There were also 44 students from around Henniker, New Hampshire, and 27 from the Sandy River valley in Maine, each of which had their own village sign language. Other students brought knowledge of their own home signs. Laurent Clerc, the first teacher at ASD, taught using French Sign Language (LSF), which itself had developed in the Parisian school for the deaf established in 1755. From this situation of language contact, a new language emerged, now known as ASL.
More schools for the deaf were founded after ASD, and knowledge of ASL spread to these schools. In addition, the rise of Deaf community organizations bolstered the continued use of ASL. Societies such as the National Association of the Deaf and the National Fraternal Society of the Deaf held national conventions that attracted signers from across the country. This all contributed to ASL's wide use over a large geographical area, atypical of a sign language.

Up to the 1950s, the predominant method in deaf education was oralism – acquiring oral language comprehension and production. Linguists did not consider sign language to be true "language", but rather something inferior. Recognition of the legitimacy of ASL was achieved by William Stokoe, a linguist who arrived at Gallaudet University in 1955 when this was still the dominant assumption. Aided by the civil rights movement of the 1960s, Stokoe argued for manualism, the use of sign language in deaf education. Stokoe noted that sign language shares the important features that oral languages have as a means of communication, and even devised a transcription system for ASL. In doing so, Stokoe revolutionized both deaf education and linguistics. In the 1960s, ASL was sometimes referred to as "Ameslan", but this term is now considered obsolete.

Counting the number of ASL signers is difficult because ASL users have never been counted by the American census. The ultimate source for current estimates of the number of ASL users in the United States is a report for the National Census of the Deaf Population (NCDP) by Schein and Delk (1974). Based on a 1972 survey of the NCDP, Schein and Delk provided estimates consistent with a signing population between 250,000 and 500,000. The survey did not distinguish between ASL and other forms of signing; in fact, the name "ASL" was not yet in widespread use.

Incorrect figures are sometimes cited for the population of ASL speakers in the United States based on misunderstandings of known statistics. Demographics of the deaf population have been confused with those of ASL use, since adults who become deaf late in life rarely use ASL in the home. This accounts for currently cited estimations which are greater than 500,000; such mistaken estimations can reach as high as 15,000,000. A 100,000-person lower bound has been cited for ASL users; the source of this figure is unclear, but it may be an estimate of prelingual deafness, which is correlated with but not equivalent to signing.

ASL is sometimes incorrectly cited as the third- or fourth-most-spoken language in the United States. These figures misquote Schein and Delk (1974), who actually concluded that ASL speakers constituted the third-largest population "requiring an interpreter in court". Although this would make ASL the third-most used language among monolinguals other than English, it does not imply that it is the fourth-most-spoken language in the United States, since speakers of other languages may also speak English.

ASL is used throughout Anglo-America. This contrasts with Europe, where a variety of sign languages are used within the same continent. The unique situation of ASL seems to have been caused by the proliferation of ASL through schools influenced by the American School for the Deaf, wherein ASL originated, and the rise of community organizations for the Deaf.

Throughout West Africa, ASL-based sign languages are spoken by educated Deaf adults. These languages, imported by boarding schools, are often considered by associations to be the official sign languages of their countries, and are named accordingly, e.g. Nigerian Sign Language, Ghanaian Sign Language. Such signing systems are found in Benin, Burkina Faso, Ivory Coast, Ghana, Liberia, Mauritania, Mali, Nigeria, and Togo. Due to lack of data, it is still an open question how similar these sign languages are to the variety of ASL used in America.

In addition to the aforementioned West African countries, ASL is reported to be used as a first language in Barbados, Bolivia, Cambodia, the Central African Republic, Chad, China (Hong Kong), the Democratic Republic of the Congo, Gabon, Jamaica, Kenya, Madagascar, the Philippines, Singapore, and Zimbabwe. ASL is also used as a lingua franca throughout the deaf world, widely learned as a second language.

Sign production can often vary according to location. Signers from the South tend to sign with more flow and ease. Native signers from New York have been reported as signing comparatively more quickly and sharply. Sign production of native Californian signers has also been reported as being fast as well. Research on this phenomenon often concludes this fast paced production for signers form the coast could be due to the fast paced nature of living in large metropolitan areas. This conclusion also supports how the ease with which Southern sign could be due to the easy going environment of the South in comparison to that of the East and West coast.

Most popularly there are variants of the signs for English words such as "birthday", "pizza", "Halloween", "early", and "soon". These are just a sample of the most commonly recognized signs with variant based on regional change.

The prevalence of residential Deaf schools can account for much of the regional variance of signs and sign productions across the United States. Deaf schools often serve students of the state in which the school resides. This limited access to signers from other regions, combined with the residential quality of Deaf Schools promoted specific use of certain sign variants. Native signers did not have much access to signers from other regions during the beginning years of their education. It is hypothesized that because of this seclusion, certain variants of a sign prevailed over others other due to the choice of variant used by the student of the school/signers in the community. 

However, American Sign Language does not appear to be vastly varied when compared to other signed languages. This is because when Deaf education was beginning in the United States, many educators flocked to the American School for the Deaf in Hartford, Connecticut. This central location for the first generation of educators in Deaf education to learn American Sign Language allows ASL to be more standardized than it is variant.

Varieties of ASL are found throughout the world. There is little difficulty in comprehension among the varieties of the United States and Canada.

Mutual intelligibility among these ASL varieties is high, and the variation is primarily lexical. For example, there are three different words for English "about" in Canadian ASL; the standard way, and two regional variations (Atlantic and Ontario), as shown in the videos on the right. Variation may also be phonological, meaning that the same sign may be signed in a different way depending on the region. For example, an extremely common type of variation is between the handshapes /1/, /L/, and /5/ in signs with one handshape.

There is also a distinct variety of ASL used by the Black Deaf community. Black ASL evolved as a result of racially segregated schools in some states, which included the residential schools for the deaf. Black ASL differs from standard ASL in vocabulary, phonology, and some grammatical structure. While African American English (AAE) is generally viewed as more innovating than standard English, Black ASL is more conservative than standard ASL, preserving older forms of many signs. Black sign language speakers use more two-handed signs than in mainstream ASL, are less likely to show assimilatory lowering of signs produced on the forehead (e.g. KNOW) and use a wider signing space. Modern Black ASL borrows a number of idioms from AAE; for instance, the AAE idiom "I feel you" is calqued into Black ASL.

ASL is used internationally as a lingua franca, and a number of closely related sign languages derived from ASL are used in many different countries. Even so, there have been varying degrees of divergence from standard ASL in these imported ASL varieties. Bolivian Sign Language is reported to be a dialect of ASL, no more divergent than other acknowledged dialects. On the other hand, it is also known that some imported ASL varieties have diverged to the extent of being separate languages. For example, Malaysian Sign Language, which has ASL origins, is no longer mutually comprehensible with ASL and must be considered its own language. For some imported ASL varieties, such as those used in West Africa, it is still an open question how similar they are to American ASL.

When communicating with hearing English speakers, ASL-speakers often use what is commonly called Pidgin Signed English (PSE) or 'contact signing', a blend of English structure with ASL. Various types of PSE exist, ranging from highly English-influenced PSE (practically relexified English) to PSE which is quite close to ASL lexically and grammatically, but may alter some subtle features of ASL grammar. Fingerspelling may be used more often in PSE than it is normally used in ASL. There have been some constructed sign languages, known as Manually Coded English (MCE), which match English grammar exactly and simply replace spoken words with signs; these systems are not considered to be varieties of ASL.

Tactile ASL (TASL) is a variety of ASL used throughout the United States by and with the deaf-blind. It is particularly common among those with Usher's syndrome. This syndrome results in deafness from birth followed by loss of vision later in life; consequently, those with Usher's syndrome often grow up in the Deaf community using ASL, and later transition to TASL. TASL differs from ASL in that signs are produced by touching the palms, and there are some grammatical differences from standard ASL in order to compensate for the lack of non-manual signing.

In 2013 the White House published a response to a petition that gained over 37,000 signatures to "officially recognize American Sign Language as a community language and a language of instruction in schools". The response is titled "there shouldn't be any stigma about American Sign Language" and addressed that ASL is a vital language for the Deaf and hard of hearing. Stigmas associated with sign languages and the use of sign for educating children often lead to the absence of sign during periods in children's lives when they can access languages most effectively. Scholars such as Beth S. Benedict advocate not only for bilingualism (using ASL and English training) but also for early childhood intervention for children who are deaf. York University psychologist Ellen Bialystok has also campaigned for bilingualism, arguing that those who are bilingual acquire cognitive skills that may help to prevent dementia later in life.

The majority of children born to deaf parents are hearing. These children, known as CODAs ("Children Of Deaf Adults") are often more culturally Deaf than deaf children, the majority of whom are born to hearing parents. Unlike many deaf children, CODAs acquire ASL as well as Deaf cultural values and behaviors from birth. These bilingual hearing children may be mistakenly labeled as being "slow learners" or as having "language difficulties" due to preferential attitudes towards spoken language.

Although there is no well-established writing system for ASL, written sign language dates back almost two centuries. The first systematic writing system for a sign language seems to be that of Roch-Ambroise Auguste Bébian, developed in 1825. However, written sign language remained marginal among the public. In the 1960s, linguist William Stokoe created Stokoe notation specifically for ASL. It is alphabetic, with a letter or diacritic for every phonemic (distinctive) hand shape, orientation, motion, and position, though it lacks any representation of facial expression, and is better suited for individual words than for extended passages of text. Stokoe used this system for his 1965 "A Dictionary of American Sign Language on Linguistic Principles".

SignWriting, proposed in 1974 by Valerie Sutton, is the first writing system to gain use among the public and the first writing system for sign languages to be included in the Unicode Standard. SignWriting consists of more than 5000 distinct iconic graphs/glyphs. Currently, it is in use in many schools for the Deaf, particularly in Brazil, and has been used in International Sign forums with speakers and researchers in more than 40 countries, including Brazil, Ethiopia, France, Germany, Italy, Portugal, Saudi Arabia, Slovenia, Tunisia, and the United States. Sutton SignWriting has both a printed and an electronically produced form so that persons can use the system anywhere that oral languages are written (personal letters, newspapers, and media, academic research). The systematic examination of the International Sign Writing Alphabet (ISWA) as an equivalent usage structure to the International Phonetic Alphabet for spoken languages has been proposed. According to some researchers, SignWriting is not a phonemic orthography and does not have a one-to-one map from phonological forms to written forms. This assertion has been disputed and the process for each country to look at the ISWA and create a phonemic/morphemic assignment of features of each sign language was proposed by researchers Msc. Roberto Cesar Reis da Costa and Madson Barreto in a thesis forum on June 23, 2014. The SignWriting community has an open project on Wikimedia Labs to support the various Wikimedia projects on Wikimedia Incubator and elsewhere involving SignWriting. The ASL Wikipedia request was marked as eligible in 2008 and the test ASL Wikipedia has 50 articles written in ASL using SignWriting.

The most widely used transcription system among academics is HamNoSys, developed at the University of Hamburg. Based on Stokoe Notation, HamNoSys was expanded to about 200 graphs in order to allow transcription of any sign language. Phonological features are usually indicated with single symbols, though the group of features that make up a handshape is indicated collectively with a symbol.

Several additional candidates for written ASL have appeared over the years, including SignFont, ASL-phabet, and Si5s.

For English-speaking audiences, ASL is often glossed using English words. These glosses are typically all-capitalized and are arranged in ASL order. For example, the ASL sentence DOG NOW CHASE>IX=3 CAT, meaning "the dog is chasing the cat", uses NOW to mark ASL progressive aspect and shows ASL verbal inflection for the third person (written with >IX=3). However, glossing is not used to write the language for speakers of ASL.

Each sign in ASL is composed of a number of distinctive components, generally referred to as parameters. A sign may use one hand or both. All signs can be described using the five parameters involved in signed languages, which are handshape, movement, palm orientation, location and non-manual markers. Just as phonemes of sound distinguish meaning in spoken languages, these parameters are the phonemes that distinguish meaning in signed languages like ASL. Changing any one of these may change the meaning of a sign, as illustrated by the ASL signs THINK and DISAPPOINTED:
There are also meaningful non-manual signals in ASL. This may include movement of the eyebrows, the cheeks, the nose, the head, the torso, and the eyes.

William Stokoe proposed that these components are analogous to the phonemes of spoken languages. There has also been a proposal that these are analogous to classes like place and manner of articulation. As in spoken languages, these phonological units can be split into distinctive features. For instance, the handshapes /2/ and /3/ are distinguished by the presence or absence of the feature [± closed thumb], as illustrated to the right. ASL has processes of allophony and phonotactic restrictions. There is ongoing research into whether ASL has an analog of syllables in spoken language.

ASL has a rich system of verbal inflection. This involves both grammatical aspect—how the action of verbs flows in time—and agreement marking. Aspect can be marked by changing the manner of movement of the verb; for example, continuous aspect is marked by incorporating rhythmic, circular movement, while punctual aspect is achieved by modifying the sign so that it has a stationary hand position. Verbs may agree with both the subject and the object, and are marked for number and reciprocity. Reciprocity is indicated by using two one-handed signs; for example, the sign SHOOT, made with an L-shaped handshape with inward movement of the thumb, inflects to SHOOT, articulated by having two L-shaped hands "shooting" at each other.

ASL has a productive system of classifiers, which are used to classify objects and their movement in space. For example, a rabbit running downhill would use a classifier consisting of a bent V classifier handshape with a downhill-directed path; if the rabbit is hopping, the path is executed with a bouncy manner. In general, classifiers are composed of a "classifier handshape" bound to a "movement root". The classifier handshape represents the object as a whole, incorporating such attributes as surface, depth, and shape, and is usually very iconic. The movement root consists of a path, a direction and a manner.

ASL possesses a set of 26 signs known as the American manual alphabet, which can be used to spell out words from the English language. These signs make use of the 19 handshapes of ASL. For example, the signs for 'p' and 'k' use the same handshape but different orientations. A common misconception is that ASL consists only of fingerspelling; although such a method (Rochester Method) has been used, it is not ASL.

Fingerspelling is a form of borrowing, a linguistic process wherein words from one language are incorporated into another. In ASL, fingerspelling is used for proper nouns and for technical terms with no native ASL equivalent. There are also some other loan words which are fingerspelled, either very short English words or abbreviations of longer English words, e.g. "O-N" from English 'on', and "A-P-T" from English 'apartment'. Fingerspelling may also be used to emphasize a word that would normally be signed otherwise.

The basic word order of ASL is disputed. Most linguists agree that ASL is a subject–verb–object (SVO) language with various phenomena affecting this basic word order. Basic SVO sentences are signed without any pauses:

However, other word orders may also occur, as ASL allows the topic of a sentence to be moved to sentence-initial position, a phenomenon known as topicalization. In object-subject-verb (OSV) sentences, the object is topicalized, marked by a forward head-tilt and a pause:
Even more, word orders can be obtained through the phenomenon of subject copy. In subject copy, the subject is repeated at the end of the sentence, accompanied by head nodding, either for clarification or emphasis:

ASL also allows null subject sentences, where the subject is implied rather than stated explicitly. Subjects can be copied even in a null subject sentence, in which the subject is omitted from its original position, yielding a verb–object–subject (VOS) construction:

Topicalization, accompanied with a null subject and a subject copy, can produce yet another word order, object–verb–subject (OVS).

These properties of ASL allow it a variety of word orders, leading many to question which is the true, underlying, "basic" order. There are several other proposals that attempt to account for the flexibility of word order in ASL. One proposal is that languages like ASL are best described with a topic–comment structure, where words are ordered by their importance in the sentence rather than by their syntactic properties. Another hypothesis is that ASL exhibits free word order, in which syntax is not encoded in word order whatsoever, but can be encoded by other means (e.g. head nods, eyebrow movement, body position).

A common misconception is that signs are iconically self-explanatory, that they are a transparent imitation of what they mean, or even that they are pantomime. In fact, many signs bear no resemblance to their referent, either because they were originally arbitrary symbols or because their iconicity has been obscured over time. Even so, in ASL iconicity plays a significant role; a high percentage of signs resemble their referents in some way. This may be due to the fact that the medium of sign—three-dimensional space—naturally allows more iconicity than oral language.

In the era of the influential linguist Ferdinand de Saussure, it was assumed that the mapping between form and meaning in language must be completely arbitrary. Although onomatopoeia is a clear exception, since words like 'choo-choo' bear clear resemblance to the sounds that they mimic, the Saussurean approach was to treat these as marginal exceptions. ASL, with its significant inventory of iconic signs, directly challenges this theory.

Research on acquisition of pronouns in ASL has shown that children do not always take advantage of the iconic properties of signs when interpreting their meaning. It has been found that when children acquire the pronoun "you", the iconicity of the point (at the child) is often confused, being treated more like a name. This is a similar finding to research in oral languages on pronoun acquisition. It has also been found that iconicity of signs does not affect immediate memory and recall; less iconic signs are remembered just as well as highly iconic signs.




</doc>
<doc id="1202" url="https://en.wikipedia.org/wiki?curid=1202" title="Applet">
Applet

In computing, an applet is any small application that performs one specific task that runs within the scope of a dedicated widget engine or a larger program, often as a plug-in. The term is frequently used to refer to a Java applet, a program written in the Java programming language that is designed to be placed on a web page. Applets are typical examples of transient and auxiliary applications that don't monopolize the user's attention. Applets are not full-featured application programs, and are intended to be easily accessible.

The word "applet" was first used in 1990 in PC Magazine. However, the concept of an applet, or more broadly a small interpreted program downloaded and executed by the user, dates at least to RFC 5 (1969) by Jeff Rulifson, which described the Decode-Encode Language (DEL), which was designed to allow remote use of the oN-Line System (NLS) over ARPANET, by downloading small programs to enhance the interaction. This has been specifically credited as a forerunner of Java's downloadable programs in RFC 2555.
Applet is an event driven program .

In some cases, an applet does not run independently. These applets must run either in a container provided by a host program, through a plugin, or a variety of other applications including mobile devices that support the applet programming model.

Applets are used to provide interactive features to web applications that cannot be provided by HTML alone. They can capture mouse input and also have controls like buttons or check boxes. In response to the user action an applet can change the provided graphic content. This makes applets well suitable for demonstration, visualization, and teaching. There are online applet collections for studying various subjects, from physics to heart physiology. Applets are also used to create online game collections that allow players to compete against live opponents in real-time.

An applet can also be a text area only, providing, for instance, a cross platform command-line interface to some remote system. If needed, an applet can leave the dedicated area and run as a separate window. However, applets have very little control over web page content outside the applet dedicated area, so they are less useful for improving the site appearance in general (while applets like news tickers or WYSIWYG editors are also known). Applets can also play media in formats that are not natively supported by the browser

HTML pages may embed parameters that are passed to the applet. Hence the same applet may appear differently depending on the parameters that were passed.

Examples of Web-based Applets include:


A larger application distinguishes its applets through several features:


A Java Applet is a java program that is launched from HTML and run in a web browser. It can provide web applications with interactive features that cannot be provided by HTML. Since Java's bytecode is platform-independent, Java applets can be executed by browsers running under many platforms, including Windows, Unix, macOS, and Linux. When a Java technology-enabled web browser processes a page that contains an applet, the applet's code is transferred to the client's system and executed by the browser's Java Virtual Machine (JVM). An HTML page references an applet either via the deprecated <applet> tag or via its replacement, the <object> tag.

Recent developments in the coding of applications including mobile and embedded systems have led to the awareness of the security of applets.

Applets in an open platform environment should provide secure interactions between different applications. A compositional approach can be used to provide security for open platform applets. Advanced compositional verification methods have been developed for secure applet interactions.

A Java applet contains different security models: unsigned Java applet security, signed Java applet security, and self signed Java applet security.

In an applet-enabled web browser, many methods can be used to provide applet security for malicious applets. A malicious applet can infect a computer system in many ways, including denial of service, invasion of privacy, and annoyance. A typical solution for malicious applets is to make the web browser to monitor applets' activities. This will result in a web browser that will enable the manual or automatic stopping of malicious applets. To illustrate this method, AppletGuard was used to observe and control any applet in a browser successfully.




</doc>
<doc id="1203" url="https://en.wikipedia.org/wiki?curid=1203" title="Alternate history">
Alternate history

Alternate history or alternative history (Commonwealth English), sometimes abbreviated as AH, is a genre of fiction consisting of stories in which one or more historical events occur differently. These stories usually contain "what if" scenarios at crucial points in history and present outcomes other than those in the historical record. The stories are conjectural, but are sometimes based on fact. Alternate history has been seen as a subgenre of literary fiction, science fiction, or historical fiction; alternate history works may use tropes from any or all of these genres. Another term occasionally used for the genre is "allohistory" (literally "other history").

Since the 1950s, this type of fiction has, to a large extent, merged with science fiction tropes involving time travel between alternate histories, psychic awareness of the existence of one universe by the people in another, or time travel that results in history splitting into two or more timelines. Cross-time, time-splitting, and alternate history themes have become so closely interwoven that it is impossible to discuss them fully apart from one another.

In Spanish, French, German, Portuguese, Italian, Catalan and Galician, the genre of alternate history is sometimes called "uchronie / ucronia / ucronía / Uchronie", which has given rise to the term "Uchronia" in English. This neologism is based on the prefix (which in Ancient Greek means "not/not any/no") and the Greek (), meaning "time." A "uchronia" means literally "(in) no time." This term apparently also inspired the name of the alternate history book list, "".

The Collins English Dictionary defines alternative history as "a genre of fiction in which the author speculates on how the course of history might have been altered if a particular historical event had had a different outcome." According to Steven H Silver, an American science fiction editor, alternate history requires three things: a point of divergence from the history of our world prior to the time at which the author is writing, a change that would alter history as it is known, and an examination of the ramifications of that change.

Several genres of fiction have been misidentified as alternate history. Science fiction set in what was the future but is now the past, like Arthur C. Clarke's "" or George Orwell's "Nineteen Eighty-Four", is not alternate history because the author did not make the choice to change the past at the time of writing. Secret history, which can take the form of fiction or nonfiction, documents events that may or may not have happened historically but did not have an effect on the overall outcome of history, and so is not to be confused with alternate history. 

Alternate history is related to, but distinct from, counterfactual history. This term is used by some professional historians to describe the practice of using thoroughly researched and carefully reasoned speculations on "what might have happened if..." as a tool of academic historical research, as opposed to a literary device.

The earliest example of alternate (or counterfactual) history is found in Livy's "Ab Urbe Condita Libri" (book IX, sections 17–19). Livy contemplated an alternative 4th century BC in which Alexander the Great had expanded his empire westward instead of eastward; he asked, "What would have been the results for Rome if she had been engaged in a war with Alexander?" Livy concluded that the Romans would likely have defeated Alexander.

Another example of counterfactual was posited by cardinal and Doctor of the Church Peter Damian in the 11th century. In his famous work "De Divina Omnipotentia", a long letter in which he discusses God's omnipotence, he treats questions related to the limits of divine power, including the question of whether God can change the past, for example, bringing about that Rome was never founded:I see I must respond finally to what many people, on the basis of your holiness’s [own] judgment, raise as an objection on the topic of this dispute. For they say: If, as you assert, God is omnipotent in all things, can he manage this, that things that have been made were not made? He can certainly destroy all things that have been made, so that they do not exist now. But it cannot be seen how he can bring it about that things that have been made were not made. To be sure, it can come about that from now on and hereafter Rome does not exist; for it can be destroyed. But no opinion can grasp how it can come about that it was not founded long ago...One early work of fiction detailing an alternate history is Joanot Martorell's 1490 epic romance "Tirant lo Blanch", which was written when the loss of Constantinople to the Turks was still a recent and traumatic memory for Christian Europe. It tells the story of the knight Tirant the White from Brittany who travels to the embattled remnants of the Byzantine Empire. He becomes a Megaduke and commander of its armies and manages to fight off the invading Ottoman armies of . He saves the city from Islamic conquest, and even chases the Turks deeper into lands they had previously conquered.

Although the Book of Mormon (1830) is regarded by those in the Latter Day Saint movement as a sacred text and companion to The Bible, Mitch Horowitz has characterized the document as alternate history. The narrative in "The Book of Mormon" states that Old World migrants to the Americas came in several waves, mainly Jews from the Levant, and inhabited the region from about 2000 BC to 400 AD, built elaborate cities large enough to support hundreds of thousands of soldiers, and that Native Americans were largely descended from these peoples. "The Book of Mormon" was allegedly translated from inscribed Golden Plates written in Reformed Egyptian, while there is no evidence of any Egyptian language or writing system in the Americas. Horowitz notes that "The Book of Mormon" depicts a variation on a commonly-believed theme in early 19th-century America: the idea that the Americas had been settled by immigrants from the Old World who had established an advanced culture that fell into decline and was thus vanished by the arrival of Europeans in the 1490s and later. The Book of Mormon narrative is rejected as non-historical by a broad consensus of scholars, scientists and researchers.

One of the earliest works of alternate history published in large quantities for the reception of a large audience may be Louis Geoffroy's "Histoire de la Monarchie universelle: Napoléon et la conquête du monde (1812–1832)" (History of the Universal Monarchy: Napoleon And The Conquest Of The World) (1836), which imagines Napoleon's First French Empire emerging victorious in the French invasion of Russia in 1811 and in an invasion of England in 1814, later unifying the world under Bonaparte's rule.

In the English language, the first known complete alternate history is Nathaniel Hawthorne's short story "P.'s Correspondence", published in 1845. It recounts the tale of a man who is considered "a madman" due to his perceptions of a different 1845, a reality in which long-dead famous people, such as the poets Robert Burns, Lord Byron, Percy Bysshe Shelley and John Keats, the actor Edmund Kean, the British politician George Canning, and even Napoleon Bonaparte, are still alive.

The first novel-length alternate history in English would seem to be Castello Holford's "Aristopia" (1895). While not as nationalistic as Louis Geoffroy's "Napoléon et la conquête du monde, 1812–1823", "Aristopia" is another attempt to portray a Utopian society. In "Aristopia", the earliest settlers in Virginia discover a reef made of solid gold and are able to build a Utopian society in North America.

A number of alternate history stories and novels appeared in the late 19th and early 20th centuries (see, for example, Charles Petrie's "If: A Jacobite Fantasy" [1926]). In 1931, British historian Sir John Squire collected a series of essays from some of the leading historians of the period for his anthology "If It Had Happened Otherwise". In this work, scholars from major universities (as well as important non-university-based authors) turned their attention to such questions as "If the Moors in Spain Had Won" and "If Louis XVI Had Had an Atom of Firmness". The essays range from serious scholarly efforts to Hendrik Willem van Loon's fanciful and satiric portrayal of an independent 20th century Dutch city state on the island of Manhattan. Among the authors included were Hilaire Belloc, André Maurois, and Winston Churchill.
One of the entries in Squire's volume was Churchill's "If Lee Had Not the Battle of Gettysburg", written from the viewpoint of a historian in a world where the Confederate States of America had won the American Civil War. The entry considers what would have happened if the North had been victorious (in other words, a character from an alternate world imagines a world more like the real one we live in, although not identical in every detail). Speculative work that narrates from the point of view of an alternate history is variously known as "recursive alternate history", a "double-blind what-if", or an "alternate-alternate history". Churchill's essay was one of the influences behind Ward Moore's alternate history novel "Bring the Jubilee", in which General Robert E. Lee won the Battle of Gettysburg, paving the way for the eventual victory of the Confederacy in the American Civil War (named the "War of Southron Independence" in this timeline). The protagonist, autodidact Hodgins Backmaker, travels back to the aforementioned battle and inadvertently changes history, resulting in the emergence of our own timeline and the consequent victory of the Union instead.

American humorist author James Thurber parodied alternate history stories about the American Civil War in his 1930 story "If Grant had been drinking at Appomattox", which he accompanied with this very brief introduction: ""Scribner's" magazine is publishing a series of three articles: 'If Booth Had Missed Lincoln', 'If Lee Had Won the Battle of Gettysburg', and 'If Napoleon Had Escaped to America'. This is the fourth.".

Another example of alternate history from this period (and arguably the first to explicitly posit cross-time travel from one universe to another as anything more than a visionary experience) is H.G. Wells' "Men Like Gods" (1923), in which several Englishmen are transferred via an accidental encounter with a cross-time machine into an alternate universe featuring a seemingly pacifistic and utopian Britain. When the Englishmen, led by a satiric figure based on Winston Churchill, try to seize power, the utopians simply point a ray gun at them and send them on to someone else's universe. Wells describes a multiverse of alternative worlds, complete with the paratime travel machines that would later become popular with U.S. pulp writers. However, since his hero experiences only a single alternate world, this story is not very different from conventional alternate history.

In the 1930s, alternate history moved into a new arena. The December 1933 issue of "Astounding" published Nat Schachner's "Ancestral Voices", which was quickly followed by Murray Leinster's "Sidewise in Time". While earlier alternate histories examined reasonably straightforward divergences, Leinster attempted something completely different. In his "World gone mad", pieces of Earth traded places with their analogs from different timelines. The story follows Professor Minott and his students from a fictitious Robinson College as they wander through analogues of worlds that followed a different history.

A somewhat similar approach was taken by Robert A. Heinlein in his 1941 novelette "Elsewhen", in which a professor trains his mind to move his body across timelines. He then hypnotizes his students so they can explore more of them. Eventually each settles into the reality most suitable for him or her. Some of the worlds they visit are mundane, some very odd; others follow science fiction or fantasy conventions.

World War II produced alternate history for propaganda: both British and American authors wrote works depicting Nazi invasions of their respective countries as cautionary tales.

The period around World War II also saw the publication of the time travel novel "Lest Darkness Fall" by L. Sprague de Camp, in which an American academic travels to Italy at the time of the Byzantine invasion of the Ostrogoths. De Camp's time traveler, Martin Padway, is depicted as making permanent historical changes and implicitly forming a new time branch, thereby making the work an alternate history.

Time travel as the cause of a point of divergence (POD), which can denote either the bifurcation of a historical timeline or a simple replacement of the future that existed before the time traveling event, has continued to be a popular theme. In Ward Moore's "Bring the Jubilee", the protagonist lives in an alternate history in which the Confederacy has won the American Civil War; he travels backward through time, and brings about a Union victory in the Battle of Gettysburg.

When a story's assumptions about the nature of time travel lead to the complete replacement of the visited time's future rather than just the creation of an additional time line, the device of a "time patrol" is often used, most notably in Poul Anderson's "Time Patrol" collection—where guardians race uptime and downtime to preserve the "correct" history. In the most celebrated of this series, "Delenda Est", the interference of time traveling outlaws causes Carthage to win the Second Punic War and destroy Rome with massive consequences for the present day.

A more recent example is "Making History" by Stephen Fry, in which a time machine is used to alter history so that Adolf Hitler was never born. This ironically results in a more competent leader of the Third Reich, resulting in the country's ascendancy and longevity in this altered timeline.

H.G. Wells' "cross-time" or "many universes" variant (see above) was fully developed by Murray Leinster in his 1934 short story "Sidewise in Time", in which sections of the Earth's surface begin changing places with their counterparts in alternate timelines.

Fredric Brown employed this subgenre to satirize the science fiction pulps and their adolescent readers—and fears of foreign invasion—in the classic "What Mad Universe" (1949). In Clifford D. Simak's "Ring Around the Sun" (1953), the hero ends up in an alternate earth of thick forests in which humanity never developed but a band of mutants is establishing a colony; the story line appears to frame the author's anxieties regarding McCarthyism and the Cold War.

In the late 1940s and the 1950s, however, writers such as H. Beam Piper, Sam Merwin, Jr. and Andre Norton wrote thrillers set in a multiverse in which all alternate histories are co-existent and travel between them occurs via a technology involving portals and/or paratime capsules. These authors established the convention of a secret paratime trading empire that exploits and/or protects worlds lacking the paratime technology via a network of James Bond-style secret agents (Piper called them the "paratime police").

This concept provided a convenient framing for packing a smörgåsbord of historical alternatives (and even of timeline "branches") into a single novel, either via the hero chasing or being chased by the villain(s) through multiple worlds or (less artfully) via discussions between the paratime cops and their superiors (or between paratime agents and new recruits) regarding the histories of such worlds.

The paratime theme is sometimes used without the police; Poul Anderson dreamed up the Old Phoenix tavern as a nexus between alternate histories. A character from a modern American alternate history "Operation Chaos" can thus appear in the English Civil War setting of "A Midsummer's Tempest". In this context, the distinction between an alternate history and a parallel universe with some points in common but no common history may not be feasible, as the writer may not provide enough information to distinguish.

Paratime thrillers published in recent decades often cite the many-worlds interpretation of quantum mechanics (first formulated by Hugh Everett III in 1957) to account for the differing worlds. Some science fiction writers interpret the splitting of worlds to depend on human decision-making and free will, while others rely on the butterfly effect from chaos theory to amplify random differences at the atomic or subatomic level into a macroscopic divergence at some specific point in history; either way, science fiction writers usually have all changes flow from a particular historical point of divergence (often abbreviated 'POD' by fans of the genre). Prior to Everett, science-fiction writers drew on higher dimensions and the speculations of P. D. Ouspensky to explain their characters' cross-time journeys.

While many justifications for alternate histories involve a multiverse, the "many world" theory would naturally involve many worlds, in fact a continually exploding array of universes. In quantum theory, new worlds would proliferate with every quantum event, and even if the writer uses human decisions, every decision that could be made differently would result in a different timeline. A writer's fictional multiverse may, in fact, preclude some decisions as humanly impossible, as when, in "Night Watch", Terry Pratchett depicts a character informing Vimes that while anything that can happen, has happened, nevertheless there is no history whatsoever in which Vimes has ever murdered his wife. When the writer explicitly maintains that "all" possible decisions are made in all possible ways, one possible conclusion is that the characters were neither brave, nor clever, nor skilled, but simply lucky enough to happen on the universe in which they did not choose the cowardly route, take the stupid action, fumble the crucial activity, etc.; few writers focus on this idea, although it has been explored in stories such as Larry Niven's story "All the Myriad Ways", where the reality of all possible universes leads to an epidemic of suicide and crime because people conclude their choices have no moral import.

In any case, even if it is true that every possible outcome occurs in some world, it can still be argued that traits such as bravery and intelligence might still affect the relative frequency of worlds in which better or worse outcomes occurred (even if the total number of worlds with each type of outcome is infinite, it is still possible to assign a different measure to different infinite sets). The physicist David Deutsch, a strong advocate of the many-worlds interpretation of quantum mechanics, has argued along these lines, saying that "By making good choices, doing the right thing, we thicken the stack of universes in which versions of us live reasonable lives. When you succeed, all the copies of you who made the same decision succeed too. What you do for the better increases the portion of the multiverse where good things happen." This view is perhaps somewhat too abstract to be explored directly in science fiction stories, but a few writers have tried, such as Greg Egan in his short story "The Infinite Assassin", where an agent is trying to contain reality-scrambling "whirlpools" that form around users of a certain drug, and the agent is constantly trying to maximize the consistency of behavior among his alternate selves, attempting to compensate for events and thoughts he experiences, he guesses are of low measure relative to those experienced by most of his other selves.

Many writers—perhaps the majority—avoid the discussion entirely. In one novel of this type, H. Beam Piper's "Lord Kalvan of Otherwhen", a Pennsylvania State Police officer, who knows how to make gunpowder, is transported from our world to an alternate universe where the recipe for gunpowder is a tightly held secret and saves a country that is about to be conquered by its neighbors. The paratime patrol members are warned against going into the timelines immediately surrounding it, where the country "will" be overrun, but the book never depicts the slaughter of the innocent thus entailed, remaining solely in the timeline where the country is saved.

The cross-time theme was further developed in the 1960s by Keith Laumer in the first three volumes of his "Imperium" sequence, which would be completed in "Zone Yellow" (1990). Piper's politically more sophisticated variant was adopted and adapted by Michael Kurland and Jack Chalker in the 1980s; Chalker's "G.O.D. Inc" trilogy (1987–89), featuring paratime detectives Sam and Brandy Horowitz, marks the first attempt at merging the paratime thriller with the police procedural. Kurland's "Perchance" (1988), the first volume of the never-completed "Chronicles of Elsewhen", presents a multiverse of secretive cross-time societies that utilize a variety of means for cross-time travel, ranging from high-tech capsules to mutant powers. Harry Turtledove has launched the Crosstime Traffic series for teenagers featuring a variant of H. Beam Piper's paratime trading empire.

The concept of a cross-time version of a world war, involving rival paratime empires, was developed in Fritz Leiber's Change War series, starting with the Hugo Award winning "The Big Time" (1958); followed by Richard C. Meredith's "Timeliner" trilogy in the 1970s, Michael McCollum's "A Greater Infinity" (1982) and John Barnes' "Timeline Wars" trilogy in the 1990s.

Such "paratime" stories may include speculation that the laws of nature can vary from one universe to the next, providing a science fictional explanation—or veneer—for what is normally fantasy. Aaron Allston's "Doc Sidhe" and "Sidhe Devil" take place between our world, the "grim world" and an alternate "fair world" where the Sidhe retreated to. Although technology is clearly present in both worlds, and the "fair world" parallels our history, about fifty years out of step, there is functional magic in the fair world. Even with such explanation, the more explicitly the alternate world resembles a normal fantasy world, the more likely the story is to be labelled fantasy, as in Poul Anderson's "House Rule" and "Loser's Night". In both science fiction and fantasy, whether a given parallel universe is an alternate history may not be clear. The writer might allude to a POD only to explain the existence and make no use of the concept, or may present the universe without explanation of its existence.

Keith Laumer's "Worlds of the Imperium" is one of the earliest alternate history novels: It was published by "Fantastic Stories of the Imagination" in 1961 in magazine form, and reprinted by Ace Books in 1962 as one half of an Ace Double. Besides our world. Laumer describes a world in which the American Revolution never happened, ruled by Britain; and a world ruled by a ruthless dictatorship.

In 1962, Philip K. Dick published "The Man in the High Castle", an alternate history in which Nazi Germany and Imperial Japan won World War II. This book contained an example of "alternate-alternate" history, in that one of its characters is the author of a book depicting a reality in which the Allies won the war, itself divergent from real-world history in several aspects.

It was followed by Vladimir Nabokov's "" (1969), a story of incest that takes place within an alternate North America settled in part by Czarist Russia, and that borrows from Dick's idea of "alternate-alternate" history (the world of Nabokov's hero is wracked by rumors of a "counter-earth" that apparently is ours). Some critics believe that the references to a counter-earth suggest that the world portrayed in "Ada" is a delusion in the mind of the hero (another favorite theme of Dick's novels). Strikingly, the characters in "Ada" seem to acknowledge their own world as the copy or negative version, calling it "Anti-Terra" while its mythical twin is the real "Terra." Not only history but science has followed a divergent path on Anti-Terra: it boasts all the same technology as our world, but all based on water instead of electricity, when a character in "Ada" makes a long-distance call, all the toilets in the house flush at once to provide hydraulic power.

Isaac Asimov's short story "What If—" is about a couple who can explore alternate realities by means of a television-like device. This idea can also be found in Asimov's 1955 novel "The End of Eternity". In that novel, the "Eternals" can change the realities of the world, without people being aware of it.

Guido Morselli described the defeat of Italy (and subsequently France) in World War I in his 1975 novel "Past Conditional" () where the static Alpine front line which divided Italy from Austria during that war collapses when the Germans and the Austrians forsake trench warfare and adopt blitzkrieg twenty years in advance.

Kingsley Amis set his 1976 novel "The Alteration" in the 20th century, but major events in the Reformation did not take place, and Protestantism is limited to the breakaway Republic of New England. Martin Luther was reconciled to the Roman Catholic Church and later became Pope Germanian I.

2002 saw Kim Stanley Robinson publish "The Years of Rice and Salt", starting at the point of divergence with Timur turning his army away from Europe, where the Black Death has killed 99% of Europe's population, instead of only a third. Robinson explores world history from that point in AD 1405 (807 AH) to about AD 2045 (1467 AH). Rather than following the great man theory of history, focusing on leaders, wars, and major events, Robinson writes more about social history, similar to the Annales School of history theory and Marxist historiography, focusing on the lives of ordinary people living in their time and place.

"The Plot Against America" (2004) by Philip Roth looks at an America where Franklin D. Roosevelt is defeated in 1940 in his bid for a third term as President of the United States, and Charles Lindbergh is elected, leading to a U.S. that features increasing fascism and anti-Semitism.

Michael Chabon, occasionally an author of speculative fiction, contributed to the genre with his 2007 novel "The Yiddish Policemen's Union". This book explores a world in which the State of Israel was destroyed in its infancy and many of the world's Jews instead live in a small strip of Alaska set aside by the US government for Jewish settlement. The story follows a Jewish detective solving a murder case in the Yiddish-speaking semi-autonomous city state of Sitka. Stylistically, Chabon borrows heavily from the noir and detective fiction genres, while exploring social issues related to Jewish history and culture. Apart from the alternate history of the Jews and Israel, Chabon also plays with other common tropes of AH Fiction; in the book, Germany actually loses the war even "harder" than they did in reality, getting hit with a nuclear bomb instead of just simply losing a ground war (subverting the common "what if Germany won WWII?" trope).

The late 1980s and the 1990s saw a boom in popular-fiction versions of alternate history, fueled by the emergence of the prolific alternate history author Harry Turtledove, as well as the development of the steampunk genre and two series of anthologies—the "What Might Have Been" series edited by Gregory Benford and the "Alternate ..." series edited by Mike Resnick. This period also saw alternate history works by S. M. Stirling, Kim Stanley Robinson, Harry Harrison, Howard Waldrop, and others.

Since the late 1990s, Harry Turtledove has been the most prolific practitioner of alternate history and has been given the title "Master of Alternate History" by some. His books include those of Timeline 191 (a.k.a. Southern Victory, also known as TL-191), in which, while the Confederate States of America won the American Civil War, the Union and Imperial Germany defeat the Entente Powers in the two "Great War"s of the 1910s and 1940s (with a Nazi-esque Confederate government attempting to exterminate its Black population), and the Worldwar series, in which aliens invaded Earth during World War II. Other stories by Turtledove include "A Different Flesh", in which America was not colonized from Asia during the last ice age; "In the Presence of Mine Enemies", in which the Nazis won World War II; and "Ruled Britannia", in which the Spanish Armada succeeded in conquering Britain in the Elizabethan era, with William Shakespeare being given the task of writing the play that will motivate the Britons to rise up against their Spanish conquerors. He also co-authored a book with actor Richard Dreyfuss, "The Two Georges", in which the United Kingdom retained the American colonies, with George Washington and King George III making peace. He did a two-volume series in which the Japanese not only bombed Pearl Harbor but also invaded and occupied the Hawaiian Islands.

Perhaps the most incessantly explored theme in popular alternate history focuses on worlds in which the Nazis won World War Two. In some versions, the Nazis and/or Axis Powers conquer the entire world; in others, they conquer most of the world but a "Fortress America" exists under siege; while in others, there is a Nazi/Japanese Cold War comparable to the US/Soviet equivalent in 'our' timeline. "Fatherland" (1992), by Robert Harris, is set in Europe following the Nazi victory. Several writers have posited points of departure for such a world but then have injected time splitters from the future or paratime travel, for instance James P. Hogan's "The Proteus Operation". Norman Spinrad wrote "The Iron Dream" in 1972, which is intended to be a science fiction novel written by Adolf Hitler after fleeing from Europe to North America in the 1920s.

In Jo Walton's "Small Change" series, the United Kingdom made peace with Hitler before the involvement of the United States in World War II, and fascism slowly strangled the UK. Former House Speaker Newt Gingrich and William R. Forstchen have written a novel, "1945", in which the U.S. defeated Japan but not Germany in World War II, resulting in a Cold War with Germany rather than the Soviet Union. Gingrich and Forstchen neglected to write the promised sequel; instead, they wrote a trilogy about the American Civil War, starting with "", in which the Confederates win a victory at the Battle of Gettysburg - however, after Lincoln responds by bringing Grant and his forces to the eastern theater, the Army of Northern Virginia is soon trapped and destroyed in Maryland, and the war ends within weeks. Also from that general era, Martin Cruz Smith, in his first novel, posited an independent American Indian nation following the defeat of Custer in "The Indians Won" (1970).

Beginning with "The Probability Broach" in 1980, L. Neil Smith wrote several novels that postulated the disintegration of the U.S. Federal Government after Albert Gallatin joins the Whiskey Rebellion in 1794 and eventually leads to the creation of a libertarian utopia.

A recent time traveling splitter variant involves entire communities being shifted elsewhere to become the unwitting creators of new time branches. These communities are transported from the present (or the near-future) to the past or to another time-line via a natural disaster, the action of technologically advanced aliens, or a human experiment gone wrong. S. M. Stirling wrote the "Island in the Sea of Time" trilogy, in which Nantucket Island and all its modern inhabitants are transported to Bronze Age times to become the world's first superpower. In Eric Flint's 1632 series, a small town in West Virginia is transported to 17th century central Europe and drastically changes the course of the Thirty Years' War, which was then underway. John Birmingham's "Axis of Time" trilogy deals with the culture shock when a United Nations naval task force from 2021 finds itself back in 1942 helping the Allies against the Empire of Japan and the Germans (and doing almost as much harm as good in spite of its advanced weapons). Similarly, Robert Charles Wilson's "Mysterium" depicts a failed U.S. government experiment which transports a small American town into an alternative version of the U.S. run by believers in a form of Christianity known as Gnosticism, who are engaged in a bitter war with the "Spanish" in Mexico (the chief scientist at the laboratory where the experiment occurred is described as a Gnostic, and references to Christian Gnosticism appear repeatedly in the book).

Many fantasies and science fantasies are set in a world that has a history somewhat similar to our own world, but with magic added. Some posit points of divergence, but some also feature magic altering history all along. One example of a universe that is in part historically recognizable but also obeys different physical laws is Poul Anderson's "Three Hearts and Three Lions" in which the Matter of France is history, and the fairy folk are real and powerful. A partly familiar European history for which the author provides a point of divergence is Randall Garrett's "Lord Darcy" series: a monk systemizing magic rather than science, so the use of foxglove to treat heart disease is called superstition. The other great point of divergence in this timeline occurs in 1199, when Richard the Lionheart survives the Siege of Chaluz and returns to England, making the Angevin Empire so strong it survives into the 20th century.

"Jonathan Strange & Mr Norrell" takes place in an alternative version of England where a separate Kingdom ruled by the Raven King and founded on magic existed in Northumbria for over 300 years. In Patricia Wrede's Regency fantasies, Great Britain has a Royal Society of Wizards, and in Poul Anderson's "A Midsummer Tempest" William Shakespeare is remembered as the Great Historian, with the novel itself taking place in the era of Oliver Cromwell and Charles I, with an alternate outcome for the English Civil War and an earlier Industrial Revolution.

"The Tales of Alvin Maker" series by Orson Scott Card (a parallel to the life of Joseph Smith, founder of the Latter Day Saint movement) takes place in an alternate America, beginning in the early 19th century. Prior to that time, a POD occurred: England, under the control of Oliver Cromwell, had banished "makers", or anyone else demonstrating "knacks" (an ability to perform seemingly supernatural feats) to the North American continent. Thus the early American colonists embraced as perfectly ordinary these gifts, and counted on them as a part of their daily lives. The political division of the continent is considerably altered, with two large English colonies bookending a smaller "American" nation, one aligned with England, and the other governed by exiled Cavaliers. Actual historical figures are seen in a much different light: Ben Franklin is revered as the continent's finest "maker", George Washington was executed at the hands of an English army, and "Tom" Jefferson is the first president of "Appalachia", the result of a compromise between the Continentals and the British.

On the other hand, when the "Old Ones" still manifest themselves in England in Keith Roberts's "Pavane", which takes place in a technologically backward world after a Spanish assassination of Elizabeth I allowed the Spanish Armada to conquer England, the possibility that the fairies were real but retreated from modern advances makes the POD possible: the fairies really were present all along, in a secret history. Again, in the English Renaissance fantasy "Armor of Light" by Melissa Scott and Lisa A. Barnett, the magic used in the book, by Dr. John Dee and others, actually was practiced in the Renaissance; positing a secret history of effective magic makes this an alternate history with a POD, Sir Philip Sidney's surviving the Battle of Zutphen in 1586, and shortly thereafter saving the life of Christopher Marlowe.

Many works of fantasy posit a world in which known practitioners of magic were able to make it function, and where the consequences of such reality would not, in fact, disturb history to such an extent as to make it plainly alternate history. Many ambiguous alternate/secret histories are set in Renaissance or pre-Renaissance times, and may explicitly include a "retreat" from the world, which would explain the current absence of such phenomena.

When the magical version of our world's history is set in contemporary times, the distinction becomes clear between alternate history on the one hand and contemporary fantasy, using in effect a form of secret history (as when Josepha Sherman's "Son of Darkness" has an elf living in New York City, in disguise) on the other. In works such as Robert A. Heinlein's "Magic, Incorporated" where a construction company can use magic to rig up stands at a sporting event and Poul Anderson's "Operation Chaos" and its sequel "Operation Luna", where djinns are serious weapons of war—with atomic bombs—the use of magic throughout the United States and other modern countries makes it clear that this is not secret history—although references in "Operation Chaos" to degaussing the effects of cold iron make it possible that it is the result of a POD. The sequel clarifies this as the result of a collaboration of Einstein and Planck in 1901, resulting in the theory of "rhea tics". Henry Moseley applies this theory to "degauss the effects of cold iron and release the goetic forces." This results in the suppression of ferromagnetism and the re-emergence of magic and magical creatures.

Alternate history shades off into other fantasy subgenres when the use of actual, though altered, history and geography decreases, although a culture may still be clearly the original source; Barry Hughart's "Bridge of Birds" and its sequels take place in a fantasy world, albeit one clearly based on China, and with allusions to actual Chinese history, such as the Empress Wu. Richard Garfinkle's "Celestial Matters" incorporates ancient Chinese physics and Greek Aristotelian physics, using them as if factual.

A fantasy version of the paratime police was developed by children's writer Diana Wynne Jones in her "Chrestomanci" quartet (1977–1988), with wizards taking the place of high tech secret agents. Among the novels in this series, "Witch Week" stands out for its vivid depiction of a history alternate to that of Chrestomanci's own world rather than our own (and yet with a specific POD that turned it away from the "normal" history of most worlds visited by the wizard).

Terry Pratchett's works include several references to alternate histories of Discworld. "Men At Arms" observes that in millions of universes, Edward d'Eath became an obsessive recluse rather than the instigator of the plot that he is in the novel. In "Jingo", Vimes accidentally picks up a pocket organizer that should have gone down another leg of the Trousers of Time, and so can hear the organizer reporting on the deaths that would have occurred had his decision gone otherwise. Indeed, Discworld contains an equivalent of the Time Patrol in its History Monks. "Night Watch" revolves around a repair of history after a time traveller’s murder of an important figure in Vimes's past. "Thief of Time" presents them functioning as a full-scale Time Patrol, ensuring that history occurs at all.

Alternate history has long been a staple of Japanese speculative fiction with such authors as Futaro Yamada and Ryō Hanmura writing novels set in recognizable historical settings with supernatural or science fiction elements present. In 1973, Ryō Hanmura wrote "Musubi no Yama Hiroku" which recreated 400 years of Japan's history from the perspective of a secret magical family with psychic abilities. The novel has since come to be recognized as a masterpiece of Japanese speculative fiction. Twelve years later, author Hiroshi Aramata wrote the groundbreaking "Teito Monogatari" which reimagined the history of Tokyo across the 20th century in a world heavily influenced by the supernatural.

The TV show "Sliders" explores different possible alternate realities by having the protagonist "slide" into different parallel dimensions of the same planet Earth.

The two-part Theatre play "Harry Potter and the Cursed Child" contains alternate timelines set within the world of Harry Potter.

In "World of Winx," the seven fairies- Bloom, Stella, Musa, Tecna, Flora, Aisha and Roxy- live on Earth, where humans are ignorant of the existence of fairies or belief in magic; much unlike the fourth season of "Winx Club", where they had brought all magic back to Earth by releasing its terrestrial fairies.

For the same reasons that this genre is explored by role-playing games, alternate history is also an intriguing backdrop for the storylines of many video games. A famous example of an alternate history game is "". Released in 1996, the game presents a point of divergence in 1946 where Albert Einstein goes back in time to prevent World War II from ever taking place by erasing Adolf Hitler from time after he is released from Landsberg Prison in 1924. He is successful in his mission, but in the process allows Joseph Stalin and the Soviet Union to become powerful enough to launch a massive campaign to conquer Europe.

In the "Civilization" series, the player guides a civilization from prehistory to the present day, creating radically altered versions of history on a long time-scale. Several scenarios recreate a particular period which becomes the "point of divergence" in an alternate history shaped by the player's actions. Popular examples in "Sid Meier's Civilization IV" include "Desert War", set in the Mediterranean theatre of World War II and featuring scripted events tied to possible outcomes of battles; "Broken Star", set in a hypothetical Russian civil war in 2010; and "Rhye's and Fall of Civilization", an 'Earth simulator' designed to mirror a history as closely as possible but incorporating unpredictable elements to provide realistic alternate settings.

In some games such as the "Metal Gear" and "Resident Evil" series, events that were originally intended to represent the near future at the time the games were originally released later ended up becoming alternate histories in later entries in those franchises. For example, "" (1990), set in 1999, depicted a near future that ended up becoming an alternate history in "Metal Gear Solid" (1998). Likewise, "Resident Evil" (1996) and "Resident Evil 2" (1998), both set in 1998, depicted near-future events that had later become an alternative history by the time "Resident Evil 4" (2005) was released.

In the 2009 steampunk shooter, "Damnation" is set on an alternate version of planet Earth, in the early part of the 20th century after the American Civil War, which had spanned over several decades, where steam engines replace combustion engines. The game sees the protagonists fighting off a rich industrialist who wants to do away with both the Union and Confederacy in one swift movement and turn the United States of America into a country called the "American Empire" with a totalitarian dictatorship.
"Crimson Skies" is one example of an alternate history spawning multiple interpretations in multiple genres. The stories and games in "Crimson Skies" take place in an alternate 1930s United States, where the nation crumbled into many hostile states following the effects of the Great Depression, the Great War, and Prohibition. With the road and railway system destroyed, commerce took to the skies, which led to the emergence of air pirate gangs who plunder the aerial commerce.

The game "Freedom Fighters" portrays a situation similar to that of the movie "Red Dawn" and "Red Alert 2", though less comically than the latter. The point of divergence is during World War II, where the Soviet Union develops an atomic bomb first and uses it on Berlin. With the balance of power and influence tipped in Russia's favor, history diverges; brief summaries at the beginning of the game inform the player of the Communist bloc's complete takeover of Europe by 1953, a different ending to the Cuban Missile Crisis, and the spread of Soviet influence into South America and Mexico.

Similarly, the 2007 video game "World in Conflict" is set in 1989, with the Soviet Union on the verge of collapse. The point of divergence is several months before the opening of the game, when Warsaw Pact forces staged a desperate invasion of Western Europe. As the game begins, a Soviet invasion force lands in Seattle, taking advantage of the fact that most of the US military is in Europe.

The game "", released in 2008, offered in alternate history campaign for the Imperial Japanese Navy, wherein Japan destroys all three carriers in the Battle of Midway, which follows with a successful invasion of the island. Because of this, the United States lacked any sort of aerial power to fight the Japanese, and is continuously forced into the defense.

"", released in February 2008, is an alternate history first person shooter where Winston Churchill died in 1931 from being hit by a taxi cab. Because of this, Great Britain lacks the charismatic leader needed to keep the country together and Nazi Germany successfully conquers Great Britain via Operation Sea Lion in 1940. Germany later conquers the rest of Europe, North Africa and the Middle East while mass-producing their wunderwaffe. The Axis launch a surprise invasion of an isolationist United States' Eastern Seaboard in 1953, which forces the country to surrender and submit to a puppet government.
Another alternate history game involving Nazis is "" in which Hitler died during the early days of World War II and thus, a much more effective leadership rose to power. Under the command of a new Führer (who is referred to as "Chancellor", and his real name is never revealed), Operation Sealion succeeds and the Nazis successfully conquer Britain, sparking a cold war between the Allied Powers and Germany.

The "Fallout" series of computer role-playing games is set in a divergent America, where history after World War II diverges from the real world to follow a retro-futuristic timeline. For example, fusion power was invented quite soon after the end of the war, but the transistor was never developed. The result was a future that has a 1950s 'World of Tomorrow' feel to it, with extremely high technology such as artificial intelligence implemented with thermionic valves and other technologies now considered obsolete.

Many game series by Swedish developer Paradox Interactive start off at a concise point in history, allowing the player to immerse in the role of a contemporary leader and alter the course of in-game history. The most prominent game with this setting is "Crusader Kings II".

"S.T.A.L.K.E.R." games have an alternate history at the Chernobyl Exclusion Zone, where a special area called "The Zone" is formed.

"" is set in an alternate 1960 in which the Nazis won the Second World War, also thanks to their acquisition of high technology. The sequel "" continues this, although being set in the conquered United States of America.

Fans of alternate history have made use of the internet from a very early point to showcase their own works and provide useful tools for those fans searching for anything alternate history, first in mailing lists and usenet groups, later in web databases and forums.

The "Usenet Alternate History List" was first posted on April 11, 1991, to the Usenet newsgroup rec.arts.sf-lovers. In May 1995, the dedicated newsgroup "soc.history.what-if" was created for showcasing and discussing alternate histories. Its prominence declined with the general migration from unmoderated usenet to moderated web forums, most prominently AlternateHistory.com, the self-described "largest gathering of alternate history fans on the internet" with over 10,000 active members.

In addition to these discussion forums, in 1997 was created as an online repository, now containing over 2,900 alternate history novels, stories, essays, and other printed materials in several different languages. Uchronia was selected as the Sci Fi Channel's "Sci Fi Site of the Week" twice.

Collaborative attempts by several amateur writers have led to notable accomplishments. The contributors at Ill Bethisad have made two constructed languages: Brithenig and Wenedyk.





</doc>
<doc id="1206" url="https://en.wikipedia.org/wiki?curid=1206" title="Atomic orbital">
Atomic orbital

In quantum mechanics, an atomic orbital is a mathematical function that describes the wave-like behavior of either one electron or a pair of electrons in an atom. This function can be used to calculate the probability of finding any electron of an atom in any specific region around the atom's nucleus. The term "atomic orbital" may also refer to the physical region or space where the electron can be calculated to be present, as defined by the particular mathematical form of the orbital.

Each orbital in an atom is characterized by a unique set of values of the three quantum numbers , , and , which respectively correspond to the electron's energy, angular momentum, and an angular momentum vector component (the magnetic quantum number). Each such orbital can be occupied by a maximum of two electrons, each with its own spin quantum number . The simple names s orbital, p orbital, d orbital and f orbital refer to orbitals with angular momentum quantum number and respectively. These names, together with the value of , are used to describe the electron configurations of atoms. They are derived from the description by early spectroscopists of certain series of alkali metal spectroscopic lines as sharp, principal, diffuse, and fundamental. Orbitals for > 3 continue alphabetically, omitting j (g, h, i, k, …) because some languages do not distinguish between the letters "i" and "j".

Atomic orbitals are the basic building blocks of the atomic orbital model (alternatively known as the electron cloud or wave mechanics model), a modern framework for visualizing the submicroscopic behavior of electrons in matter. In this model the electron cloud of a multi-electron atom may be seen as being built up (in approximation) in an electron configuration that is a product of simpler hydrogen-like atomic orbitals. The repeating "periodicity" of the blocks of 2, 6, 10, and 14 elements within sections of the periodic table arises naturally from the total number of electrons that occupy a complete set of s, p, d and f atomic orbitals, respectively, although for higher values of the quantum number , particularly when the atom in question bears a positive charge, the energies of certain sub-shells become very similar and so the order in which they are said to be populated by electrons (e.g. Cr = [Ar]4"s"3"d" and Cr = [Ar]3"d") can only be rationalized somewhat arbitrarily.

With the development of quantum mechanics and experimental findings (such as the two slit diffraction of electrons), it was found that the orbiting electrons around a nucleus could not be fully described as particles, but needed to be explained by the wave-particle duality. In this sense, the electrons have the following properties:

Wave-like properties:

Particle-like properties:

Thus, despite the popular analogy to planets revolving around the Sun, electrons cannot be described simply as solid particles. In addition, atomic orbitals do not closely resemble a planet's elliptical path in ordinary atoms. A more accurate analogy might be that of a large and often oddly shaped "atmosphere" (the electron), distributed around a relatively tiny planet (the atomic nucleus). Atomic orbitals exactly describe the shape of this "atmosphere" only when a single electron is present in an atom. When more electrons are added to a single atom, the additional electrons tend to more evenly fill in a volume of space around the nucleus so that the resulting collection (sometimes termed the atom's "electron cloud") tends toward a generally spherical zone of probability describing the electron's location, because of the uncertainty principle.

Atomic orbitals may be defined more precisely in formal quantum mechanical language. Specifically, in quantum mechanics, the state of an atom, i.e., an eigenstate of the atomic Hamiltonian, is approximated by an expansion (see configuration interaction expansion and basis set) into linear combinations of anti-symmetrized products (Slater determinants) of one-electron functions. The spatial components of these one-electron functions are called atomic orbitals. (When one considers also their spin component, one speaks of atomic spin orbitals.) A state is actually a function of the coordinates of all the electrons, so that their motion is correlated, but this is often approximated by this independent-particle model of products of single electron wave functions. (The London dispersion force, for example, depends on the correlations of the motion of the electrons.)

In atomic physics, the atomic spectral lines correspond to transitions (quantum leaps) between quantum states of an atom. These states are labeled by a set of quantum numbers summarized in the term symbol and usually associated with particular electron configurations, i.e., by occupation schemes of atomic orbitals (for example, 1s 2s 2p for the ground state of neon—term symbol: S).

This notation means that the corresponding Slater determinants have a clear higher weight in the configuration interaction expansion. The atomic orbital concept is therefore a key concept for visualizing the excitation process associated with a given transition. For example, one can say for a given transition that it corresponds to the excitation of an electron from an occupied orbital to a given unoccupied orbital. Nevertheless, one has to keep in mind that electrons are fermions ruled by the Pauli exclusion principle and cannot be distinguished from the other electrons in the atom. Moreover, it sometimes happens that the configuration interaction expansion converges very slowly and that one cannot speak about simple one-determinant wave function at all. This is the case when electron correlation is large.

Fundamentally, an atomic orbital is a one-electron wave function, even though most electrons do not exist in one-electron atoms, and so the one-electron view is an approximation. When thinking about orbitals, we are often given an orbital visualization heavily influenced by the Hartree–Fock approximation, which is one way to reduce the complexities of molecular orbital theory.

Atomic orbitals can be the hydrogen-like "orbitals" which are exact solutions to the Schrödinger equation for a hydrogen-like "atom" (i.e., an atom with one electron). Alternatively, atomic orbitals refer to functions that depend on the coordinates of one electron (i.e., orbitals) but are used as starting points for approximating wave functions that depend on the simultaneous coordinates of all the electrons in an atom or molecule. The coordinate systems chosen for atomic orbitals are usually spherical coordinates in atoms and cartesians in polyatomic molecules. The advantage of spherical coordinates (for atoms) is that an orbital wave function is a product of three factors each dependent on a single coordinate: . The angular factors of atomic orbitals generate s, p, d, etc. functions as real combinations of spherical harmonics (where and are quantum numbers). There are typically three mathematical forms for the radial functions  which can be chosen as a starting point for the calculation of the properties of atoms and molecules with many electrons:


Although hydrogen-like orbitals are still used as pedagogical tools, the advent of computers has made STOs preferable for atoms and diatomic molecules since combinations of STOs can replace the nodes in hydrogen-like atomic orbital. Gaussians are typically used in molecules with three or more atoms. Although not as accurate by themselves as STOs, combinations of many Gaussians can attain the accuracy of hydrogen-like orbitals.

The term "orbital" was coined by Robert Mulliken in 1932 as an abbreviation for "one-electron orbital wave function". However, the idea that electrons might revolve around a compact nucleus with definite angular momentum was convincingly argued at least 19 years earlier by Niels Bohr, and the Japanese physicist Hantaro Nagaoka published an orbit-based hypothesis for electronic behavior as early as 1904. Explaining the behavior of these electron "orbits" was one of the driving forces behind the development of quantum mechanics.

With J. J. Thomson's discovery of the electron in 1897, it became clear that atoms were not the smallest building blocks of nature, but were rather composite particles. The newly discovered structure within atoms tempted many to imagine how the atom's constituent parts might interact with each other. Thomson theorized that multiple electrons revolved in orbit-like rings within a positively charged jelly-like substance, and between the electron's discovery and 1909, this "plum pudding model" was the most widely accepted explanation of atomic structure.

Shortly after Thomson's discovery, Hantaro Nagaoka predicted a different model for electronic structure. Unlike the plum pudding model, the positive charge in Nagaoka's "Saturnian Model" was concentrated into a central core, pulling the electrons into circular orbits reminiscent of Saturn's rings. Few people took notice of Nagaoka's work at the time, and Nagaoka himself recognized a fundamental defect in the theory even at its conception, namely that a classical charged object cannot sustain orbital motion because it is accelerating and therefore loses energy due to electromagnetic radiation. Nevertheless, the Saturnian model turned out to have more in common with modern theory than any of its contemporaries.

In 1909, Ernest Rutherford discovered that the bulk of the atomic mass was tightly condensed into a nucleus, which was also found to be positively charged. It became clear from his analysis in 1911 that the plum pudding model could not explain atomic structure. In 1913 as Rutherford's post-doctoral student, Niels Bohr proposed a new model of the atom, wherein electrons orbited the nucleus with classical periods, but were only permitted to have discrete values of angular momentum, quantized in units "h"/2π. This constraint automatically permitted only certain values of electron energies. The Bohr model of the atom fixed the problem of energy loss from radiation from a ground state (by declaring that there was no state below this), and more importantly explained the origin of spectral lines.
After Bohr's use of Einstein's explanation of the photoelectric effect to relate energy levels in atoms with the wavelength of emitted light, the connection between the structure of electrons in atoms and the emission and absorption spectra of atoms became an increasingly useful tool in the understanding of electrons in atoms. The most prominent feature of emission and absorption spectra (known experimentally since the middle of the 19th century), was that these atomic spectra contained discrete lines. The significance of the Bohr model was that it related the lines in emission and absorption spectra to the energy differences between the orbits that electrons could take around an atom. This was, however, "not" achieved by Bohr through giving the electrons some kind of wave-like properties, since the idea that electrons could behave as matter waves was not suggested until eleven years later. Still, the Bohr model's use of quantized angular momenta and therefore quantized energy levels was a significant step towards the understanding of electrons in atoms, and also a significant step towards the development of quantum mechanics in suggesting that quantized restraints must account for all discontinuous energy levels and spectra in atoms.

With de Broglie's suggestion of the existence of electron matter waves in 1924, and for a short time before the full 1926 Schrödinger equation treatment of hydrogen-like atom, a Bohr electron "wavelength" could be seen to be a function of its momentum, and thus a Bohr orbiting electron was seen to orbit in a circle at a multiple of its half-wavelength (this physically incorrect Bohr model is still often taught to beginning students). The Bohr model for a short time could be seen as a classical model with an additional constraint provided by the 'wavelength' argument. However, this period was immediately superseded by the full three-dimensional wave mechanics of 1926. In our current understanding of physics, the Bohr model is called a semi-classical model because of its quantization of angular momentum, not primarily because of its relationship with electron wavelength, which appeared in hindsight a dozen years after the Bohr model was proposed.

The Bohr model was able to explain the emission and absorption spectra of hydrogen. The energies of electrons in the "n" = 1, 2, 3, etc. states in the Bohr model match those of current physics. However, this did not explain similarities between different atoms, as expressed by the periodic table, such as the fact that helium (two electrons), neon (10 electrons), and argon (18 electrons) exhibit similar chemical inertness. Modern quantum mechanics explains this in terms of electron shells and subshells which can each hold a number of electrons determined by the Pauli exclusion principle. Thus the "n" = 1 state can hold one or two electrons, while the "n" = 2 state can hold up to eight electrons in 2s and 2p subshells. In helium, all "n" = 1 states are fully occupied; the same for "n" = 1 and "n" = 2 in neon. In argon the 3s and 3p subshells are similarly fully occupied by eight electrons; quantum mechanics also allows a 3d subshell but this is at higher energy than the 3s and 3p in argon (contrary to the situation in the hydrogen atom) and remains empty.

Immediately after Heisenberg discovered his uncertainty principle, Bohr noted that the existence of any sort of wave packet implies uncertainty in the wave frequency and wavelength, since a spread of frequencies is needed to create the packet itself. In quantum mechanics, where all particle momenta are associated with waves, it is the formation of such a wave packet which localizes the wave, and thus the particle, in space. In states where a quantum mechanical particle is bound, it must be localized as a wave packet, and the existence of the packet and its minimum size implies a spread and minimal value in particle wavelength, and thus also momentum and energy. In quantum mechanics, as a particle is localized to a smaller region in space, the associated compressed wave packet requires a larger and larger range of momenta, and thus larger kinetic energy. Thus the binding energy to contain or trap a particle in a smaller region of space increases without bound as the region of space grows smaller. Particles cannot be restricted to a geometric point in space, since this would require an infinite particle momentum.

In chemistry, Schrödinger, Pauling, Mulliken and others noted that the consequence of Heisenberg's relation was that the electron, as a wave packet, could not be considered to have an exact location in its orbital. Max Born suggested that the electron's position needed to be described by a probability distribution which was connected with finding the electron at some point in the wave-function which described its associated wave packet. The new quantum mechanics did not give exact results, but only the probabilities for the occurrence of a variety of possible such results. Heisenberg held that the path of a moving particle has no meaning if we cannot observe it, as we cannot with electrons in an atom.

In the quantum picture of Heisenberg, Schrödinger and others, the Bohr atom number "n" for each orbital became known as an "n-sphere" in a three dimensional atom and was pictured as the mean energy of the probability cloud of the electron's wave packet which surrounded the atom.

Orbitals are given names in the form:
where "X" is the energy level corresponding to the principal quantum number , type is a lower-case letter denoting the shape or subshell of the orbital and it corresponds to the angular quantum number , and is the number of electrons in that orbital.

For example, the orbital 1s (pronounced as the individual numbers and letters: "one ess two") has two electrons and is the lowest energy level () and has an angular quantum number of . In X-ray notation, the principal quantum number is given a letter associated with it. For , the letters associated with those numbers are K, L, M, N, O, … respectively.

The simplest atomic orbitals are those that are calculated for systems with a single electron, such as the hydrogen atom. An atom of any other element ionized down to a single electron is very similar to hydrogen, and the orbitals take the same form. In the Schrödinger equation for this system of one negative and one positive particle, the atomic orbitals are the eigenstates of the Hamiltonian operator for the energy. They can be obtained analytically, meaning that the resulting orbitals are products of a polynomial series, and exponential and trigonometric functions. (see hydrogen atom).

For atoms with two or more electrons, the governing equations can only be solved with the use of methods of iterative approximation. Orbitals of multi-electron atoms are "qualitatively" similar to those of hydrogen, and in the simplest models, they are taken to have the same form. For more rigorous and precise analysis, the numerical approximations must be used.

A given (hydrogen-like) atomic orbital is identified by unique values of three quantum numbers: , , and . The rules restricting the values of the quantum numbers, and their energies (see below), explain the electron configuration of the atoms and the periodic table.

The stationary states (quantum states) of the hydrogen-like atoms are its atomic orbitals. However, in general, an electron's behavior is not fully described by a single orbital. Electron states are best represented by time-depending "mixtures" (linear combinations) of multiple orbitals. See Linear combination of atomic orbitals molecular orbital method.

The quantum number first appeared in the Bohr model where it determines the radius of each circular electron orbit. In modern quantum mechanics however, determines the mean distance of the electron from the nucleus; all electrons with the same value of "n" lie at the same average distance. For this reason, orbitals with the same value of "n" are said to comprise a "shell". Orbitals with the same value of "n" and also the same value of  are even more closely related, and are said to comprise a "subshell".

Because of the quantum mechanical nature of the electrons around a nucleus, atomic orbitals can be uniquely defined by a set of integers known as quantum numbers. These quantum numbers only occur in certain combinations of values, and their physical interpretation changes depending on whether real or complex versions of the atomic orbitals are employed.

In physics, the most common orbital descriptions are based on the solutions to the hydrogen atom, where orbitals are given by the product between a radial function and a pure spherical harmonic. The quantum numbers, together with the rules governing their possible values, are as follows:

The principal quantum number describes the energy of the electron and is always a positive integer. In fact, it can be any positive integer, but for reasons discussed below, large numbers are seldom encountered. Each atom has, in general, many orbitals associated with each value of "n"; these orbitals together are sometimes called "electron shells".

The azimuthal quantum number describes the orbital angular momentum of each electron and is a non-negative integer. Within a shell where is some integer , ranges across all (integer) values satisfying the relation formula_3. For instance, the  shell has only orbitals with formula_4, and the  shell has only orbitals with formula_4, and formula_6. The set of orbitals associated with a particular value of  are sometimes collectively called a "subshell".

The magnetic quantum number, formula_7, describes the magnetic moment of an electron in an arbitrary direction, and is also always an integer. Within a subshell where formula_8 is some integer formula_9, formula_7 ranges thus: formula_11.

The above results may be summarized in the following table. Each cell represents a subshell, and lists the values of formula_7 available in that subshell. Empty cells represent subshells that do not exist.

Subshells are usually identified by their formula_13- and formula_8-values. formula_13 is represented by its numerical value, but formula_8 is represented by a letter as follows: 0 is represented by 's', 1 by 'p', 2 by 'd', 3 by 'f', and 4 by 'g'. For instance, one may speak of the subshell with formula_17 and formula_4 as a '2s subshell'.

Each electron also has a spin quantum number, s, which describes the spin of each electron (spin up or spin down). The number s can be + or −.

The Pauli exclusion principle states that no two electrons in an atom can have the same values of all four quantum numbers. If there are two electrons in an orbital with given values for three quantum numbers, (n, l, m), these two electrons must differ in their spin.

The above conventions imply a preferred axis (for example, the "z" direction in Cartesian coordinates), and they also imply a preferred direction along this preferred axis. Otherwise there would be no sense in distinguishing from . As such, the model is most useful when applied to physical systems that share these symmetries. The Stern–Gerlach experiment — where an atom is exposed to a magnetic field — provides one such example.

An atom that is embedded in a crystalline solid feels multiple preferred axes, but often no preferred direction. Instead of building atomic orbitals out of the product of radial functions and a single spherical harmonic, linear combinations of spherical harmonics are typically used, designed so that the imaginary part of the spherical harmonics cancel out. These real orbitals are the building blocks most commonly shown in orbital visualizations.

In the real hydrogen-like orbitals, for example, and have the same interpretation and significance as their complex counterparts, but is no longer a good quantum number (though its absolute value is). The orbitals are given new names based on their shape with respect to a standardized Cartesian basis. The real hydrogen-like p orbitals are given by the following

where , , and , are the complex orbitals corresponding to .

The equations for the p and p orbitals depend on the phase convention used for the spherical harmonics. The above equations suppose that the spherical harmonics are defined by formula_22. However some quantum physicists include a phase factor (-1) in these definitions, which has the effect of relating the p orbital to a "difference" of spherical harmonics and the p orbital to the corresponding "sum". (For more detail, see Spherical harmonics#Conventions).

Simple pictures showing orbital shapes are intended to describe the angular forms of regions in space where the electrons occupying the orbital are likely to be found. The diagrams cannot show the entire region where an electron can be found, since according to quantum mechanics there is a non-zero probability of finding the electron (almost) anywhere in space. Instead the diagrams are approximate representations of boundary or contour surfaces where the probability density has a constant value, chosen so that there is a certain probability (for example 90%) of finding the electron within the contour. Although as the square of an absolute value is everywhere non-negative, the sign of the wave function is often indicated in each subregion of the orbital picture.

Sometimes the function will be graphed to show its phases, rather than the which shows probability density but has no phases (which have been lost in the process of taking the absolute value, since is a complex number). orbital graphs tend to have less spherical, thinner lobes than graphs, but have the same number of lobes in the same places, and otherwise are recognizable. This article, in order to show wave function phases, shows mostly graphs.

The lobes can be viewed as standing wave interference patterns between the two counter rotating, ring resonant travelling wave "" and "" modes, with the projection of the orbital onto the xy plane having a resonant "" wavelengths around the circumference. Though rarely depicted the travelling wave solutions can be viewed as rotating banded tori, with the bands representing phase information. For each there are two standing wave solutions and . For the case where the orbital is vertical, counter rotating information is unknown, and the orbital is z-axis symmetric. For the case where there are no counter rotating modes. There are only radial modes and the shape is spherically symmetric. For any given , the smaller is, the more radial nodes there are. Loosely speaking "n" is energy, is analogous to eccentricity, and is orientation. In the classical case, a ring resonant travelling wave, for example in a circular transmission line, unless actively forced, will spontaneously decay into a ring resonant standing wave because reflections will build up over time at even the smallest imperfection or discontinuity.

Generally speaking, the number determines the size and energy of the orbital for a given nucleus: as increases, the size of the orbital increases. When comparing different elements, the higher nuclear charge of heavier elements causes their orbitals to contract by comparison to lighter ones, so that the overall size of the whole atom remains very roughly constant, even as the number of electrons in heavier elements (higher ) increases.

Also in general terms, determines an orbital's shape, and its orientation. However, since some orbitals are described by equations in complex numbers, the shape sometimes depends on also. Together, the whole set of orbitals for a given and fill space as symmetrically as possible, though with increasingly complex sets of lobes and nodes.

The single s-orbitals (formula_4) are shaped like spheres. For it is roughly a solid ball (it is most dense at the center and fades exponentially outwardly), but for or more, each single s-orbital is composed of spherically symmetric surfaces which are nested shells (i.e., the "wave-structure" is radial, following a sinusoidal radial component as well). See illustration of a cross-section of these nested shells, at right. The s-orbitals for all numbers are the only orbitals with an anti-node (a region of high wave function density) at the center of the nucleus. All other orbitals (p, d, f, etc.) have angular momentum, and thus avoid the nucleus (having a wave node "at" the nucleus). Recently, there has been an effort to experimentally image the 1"s" and 2"p" orbitials in a SrTiO crystal using scanning transmission electron microscopy with energy dispersive x-ray spectroscopy. Because the imaging was conducted using an electron beam, Coulombic beam-orbital interaction that is often termed as the impact parameter effect is included in the final outcome (see the figure at right).

The shapes of p, d and f-orbitals are described verbally here and shown graphically in the "Orbitals table" below. The three p-orbitals for have the form of two ellipsoids with a point of tangency at the nucleus (the two-lobed shape is sometimes referred to as a "dumbbell"—there are two lobes pointing in opposite directions from each other). The three p-orbitals in each shell are oriented at right angles to each other, as determined by their respective linear combination of values of . The overall result is a lobe pointing along each direction of the primary axes.

Four of the five d-orbitals for look similar, each with four pear-shaped lobes, each lobe tangent at right angles to two others, and the centers of all four lying in one plane. Three of these planes are the xy-, xz-, and yz-planes—the lobes are between the pairs of primary axes—and the fourth has the centres along the x and y axes themselves. The fifth and final d-orbital consists of three regions of high probability density: a torus with two pear-shaped regions placed symmetrically on its z axis. The overall total of 18 directional lobes point in every primary axis direction and between every pair.

There are seven f-orbitals, each with shapes more complex than those of the d-orbitals.

Additionally, as is the case with the s orbitals, individual p, d, f and g orbitals with values higher than the lowest possible value, exhibit an additional radial node structure which is reminiscent of harmonic waves of the same type, as compared with the lowest (or fundamental) mode of the wave. As with s orbitals, this phenomenon provides p, d, f, and g orbitals at the next higher possible value of (for example, 3p orbitals vs. the fundamental 2p), an additional node in each lobe. Still higher values of further increase the number of radial nodes, for each type of orbital.

The shapes of atomic orbitals in one-electron atom are related to 3-dimensional spherical harmonics. These shapes are not unique, and any linear combination is valid, like a transformation to cubic harmonics, in fact it is possible to generate sets where all the d's are the same shape, just like the and are the same shape.
Although individual orbitals are most often shown independent of each other, the orbitals coexist around the nucleus at the same time.

This table shows all orbital configurations for the real hydrogen-like wave functions up to 7s, and therefore covers the simple electronic configuration for all elements in the periodic table up to radium. "ψ" graphs are shown with − and + wave function phases shown in two different colors (arbitrarily red and blue). The orbital is the same as the orbital, but the and are formed by taking linear
combinations of the and orbitals (which is why they are listed under the label). Also, the and are not
the same shape as the , since they are pure spherical harmonics.

The shapes of atomic orbitals can be qualitatively understood by considering the analogous case of standing waves on a circular drum. To see the analogy, the mean vibrational displacement of each bit of drum membrane from the equilibrium point over many cycles (a measure of average drum membrane velocity and momentum at that point) must be considered relative to that point's distance from the center of the drum head. If this displacement is taken as being analogous to the probability of finding an electron at a given distance from the nucleus, then it will be seen that the many modes of the vibrating disk form patterns that trace the various shapes of atomic orbitals. The basic reason for this correspondence lies in the fact that the distribution of kinetic energy and momentum in a matter-wave is predictive of where the particle associated with the wave will be. That is, the probability of finding an electron at a given place is also a function of the electron's average momentum at that point, since high electron momentum at a given position tends to "localize" the electron in that position, via the properties of electron wave-packets (see the Heisenberg uncertainty principle for details of the mechanism).

This relationship means that certain key features can be observed in both drum membrane modes and atomic orbitals. For example, in all of the modes analogous to s orbitals (the top row in the animated illustration below), it can be seen that the very center of the drum membrane vibrates most strongly, corresponding to the antinode in all s orbitals in an atom. This antinode means the electron is most likely to be at the physical position of the nucleus (which it passes straight through without scattering or striking it), since it is moving (on average) most rapidly at that point, giving it maximal momentum.

A mental "planetary orbit" picture closest to the behavior of electrons in s orbitals, all of which have no angular momentum, might perhaps be that of a Keplerian orbit with the orbital eccentricity of 1 but a finite major axis, not physically possible (because particles were to collide), but can be imagined as a limit of orbits with equal major axes but increasing eccentricity.

Below, a number of drum membrane vibration modes and the respective wave functions of the hydrogen atom are shown. A correspondence can be considered where the wave functions of a vibrating drum head are for a two-coordinate system and the wave functions for a vibrating sphere are three-coordinate .

None of the other sets of modes in a drum membrane have a central antinode, and in all of them the center of the drum does not move. These correspond to a node at the nucleus for all non-s orbitals in an atom. These orbitals all have some angular momentum, and in the planetary model, they correspond to particles in orbit with eccentricity less than 1.0, so that they do not pass straight through the center of the primary body, but keep somewhat away from it.

In addition, the drum modes analogous to p and d modes in an atom show spatial irregularity along the different radial directions from the center of the drum, whereas all of the modes analogous to s modes are perfectly symmetrical in radial direction. The non radial-symmetry properties of non-s orbitals are necessary to localize a particle with angular momentum and a wave nature in an orbital where it must tend to stay away from the central attraction force, since any particle localized at the point of central attraction could have no angular momentum. For these modes, waves in the drum head tend to avoid the central point. Such features again emphasize that the shapes of atomic orbitals are a direct consequence of the wave nature of electrons.

In atoms with a single electron (hydrogen-like atoms), the energy of an orbital (and, consequently, of any electrons in the orbital) is determined exclusively by formula_13. The formula_25 orbital has the lowest possible energy in the atom. Each successively higher value of formula_13 has a higher level of energy, but the difference decreases as formula_13 increases. For high formula_13, the level of energy becomes so high that the electron can easily escape from the atom. In single electron atoms, all levels with different formula_8 within a given formula_13 are (to a good approximation) degenerate, and have the same energy. This approximation is broken to a slight extent by the effect of the magnetic field of the nucleus, and by quantum electrodynamics effects. The latter induce tiny binding energy differences especially for s electrons that go nearer the nucleus, since these feel a very slightly different nuclear charge, even in one-electron atoms; see Lamb shift.

In atoms with multiple electrons, the energy of an electron depends not only on the intrinsic properties of its orbital, but also on its interactions with the other electrons. These interactions depend on the detail of its spatial probability distribution, and so the energy levels of orbitals depend not only on formula_13 but also on formula_8. Higher values of formula_8 are associated with higher values of energy; for instance, the 2p state is higher than the 2s state. When formula_34, the increase in energy of the orbital becomes so large as to push the energy of orbital above the energy of the s-orbital in the next higher shell; when formula_35 the energy is pushed into the shell two steps higher. The filling of the 3d orbitals does not occur until the 4s orbitals have been filled.

The increase in energy for subshells of increasing angular momentum in larger atoms is due to electron–electron interaction effects, and it is specifically related to the ability of low angular momentum electrons to penetrate more effectively toward the nucleus, where they are subject to less screening from the charge of intervening electrons. Thus, in atoms of higher atomic number, the formula_8 of electrons becomes more and more of a determining factor in their energy, and the principal quantum numbers formula_13 of electrons becomes less and less important in their energy placement.

The energy sequence of the first 35 subshells (e.g., 1s, 2p, 3d, etc.) is given in the following table. Each cell represents a subshell with formula_13 and formula_8 given by its row and column indices, respectively. The number in the cell is the subshell's position in the sequence. For a linear listing of the subshells in terms of increasing energies in multielectron atoms, see the section below.

"Note: empty cells indicate non-existent sublevels, while numbers in italics indicate sublevels that could (potentially) exist, but which do not hold electrons in any element currently known."

Several rules govern the placement of electrons in orbitals ("electron configuration"). The first dictates that no two electrons in an atom may have the same set of values of quantum numbers (this is the Pauli exclusion principle). These quantum numbers include the three that define orbitals, as well as , or spin quantum number. Thus, two electrons may occupy a single orbital, so long as they have different values of . However, "only" two electrons, because of their spin, can be associated with each orbital.

Additionally, an electron always tends to fall to the lowest possible energy state. It is possible for it to occupy any orbital so long as it does not violate the Pauli exclusion principle, but if lower-energy orbitals are available, this condition is unstable. The electron will eventually lose energy (by releasing a photon) and drop into the lower orbital. Thus, electrons fill orbitals in the order specified by the energy sequence given above.

This behavior is responsible for the structure of the periodic table. The table may be divided into several rows (called 'periods'), numbered starting with 1 at the top. The presently known elements occupy seven periods. If a certain period has number "i", it consists of elements whose outermost electrons fall in the "i"th shell. Niels Bohr was the first to propose (1923) that the periodicity in the properties of the elements might be explained by the periodic filling of the electron energy levels, resulting in the electronic structure of the atom.

The periodic table may also be divided into several numbered rectangular 'blocks'. The elements belonging to a given block have this common feature: their highest-energy electrons all belong to the same -state (but the associated with that -state depends upon the period). For instance, the leftmost two columns constitute the 's-block'. The outermost electrons of Li and Be respectively belong to the 2s subshell, and those of Na and Mg to the 3s subshell.

The following is the order for filling the "subshell" orbitals, which also gives the order of the "blocks" in the periodic table:

The "periodic" nature of the filling of orbitals, as well as emergence of the s, p, d and f "blocks", is more obvious if this order of filling is given in matrix form, with increasing principal quantum numbers starting the new rows ("periods") in the matrix. Then, each subshell (composed of the first two quantum numbers) is repeated as many times as required for each pair of electrons it may contain. The result is a compressed periodic table, with each entry representing two successive elements:

Although this is the general order of orbital filling according to the Madelung rule, there are exceptions, and the actual electronic energies of each element are also dependent upon additional details of the atoms (see ).

The number of electrons in an electrically neutral atom increases with the atomic number. The electrons in the outermost shell, or "valence electrons", tend to be responsible for an element's chemical behavior. Elements that contain the same number of valence electrons can be grouped together and display similar chemical properties.

For elements with high atomic number , the effects of relativity become more pronounced, and especially so for s electrons, which move at relativistic velocities as they penetrate the screening electrons near the core of high- atoms. This relativistic increase in momentum for high speed electrons causes a corresponding decrease in wavelength and contraction of 6s orbitals relative to 5d orbitals (by comparison to corresponding s and d electrons in lighter elements in the same column of the periodic table); this results in 6s valence electrons becoming lowered in energy.

Examples of significant physical outcomes of this effect include the lowered melting temperature of mercury (which results from 6s electrons not being available for metal bonding) and the golden color of gold and caesium.

In the Bohr Model, an  electron has a velocity given by formula_40, where is the atomic number, formula_41 is the fine-structure constant, and is the speed of light. In non-relativistic quantum mechanics, therefore, any atom with an atomic number greater than 137 would require its 1s electrons to be traveling faster than the speed of light. Even in the Dirac equation, which accounts for relativistic effects, the wave function of the electron for atoms with is oscillatory and unbounded. The significance of element 137, also known as untriseptium, was first pointed out by the physicist Richard Feynman. Element 137 is sometimes informally called feynmanium (symbol Fy). However, Feynman's approximation fails to predict the exact critical value of  due to the non-point-charge nature of the nucleus and very small orbital radius of inner electrons, resulting in a potential seen by inner electrons which is effectively less than . The critical  value which makes the atom unstable with regard to high-field breakdown of the vacuum and production of electron-positron pairs, does not occur until is about 173. These conditions are not seen except transiently in collisions of very heavy nuclei such as lead or uranium in accelerators, where such electron-positron production from these effects has been claimed to be observed. See Extension of the periodic table beyond the seventh period.

There are no nodes in relativistic orbital densities, although individual components of the wave function will have nodes.

Bound quantum states have discrete energy levels. When applied to atomic orbitals, this means that the energy differences between states are also discrete. A transition between these states (i.e., an electron absorbing or emitting a photon) can thus only happen if the photon has an energy corresponding with the exact energy difference between said states.

Consider two states of the hydrogen atom:

State 1) , , and 

State 2) , , and 

By quantum theory, state 1 has a fixed energy of , and state 2 has a fixed energy of . Now, what would happen if an electron in state 1 were to move to state 2? For this to happen, the electron would need to gain an energy of exactly . If the electron receives energy that is less than or greater than this value, it cannot jump from state 1 to state 2. Now, suppose we irradiate the atom with a broad-spectrum of light. Photons that reach the atom that have an energy of exactly will be absorbed by the electron in state 1, and that electron will jump to state 2. However, photons that are greater or lower in energy cannot be absorbed by the electron, because the electron can only jump to one of the orbitals, it cannot jump to a state between orbitals. The result is that only photons of a specific frequency will be absorbed by the atom. This creates a line in the spectrum, known as an absorption line, which corresponds to the energy difference between states 1 and 2.

The atomic orbital model thus predicts line spectra, which are observed experimentally. This is one of the main validations of the atomic orbital model.

The atomic orbital model is nevertheless an approximation to the full quantum theory, which only recognizes many electron states. The predictions of line spectra are qualitatively useful but are not quantitatively accurate for atoms and ions other than those containing only one electron.





</doc>
<doc id="1207" url="https://en.wikipedia.org/wiki?curid=1207" title="Amino acid">
Amino acid

Amino acids are organic compounds containing amine (-NH) and carboxyl (-COOH) functional groups, along with a side chain (R group) specific to each amino acid. The key elements of an amino acid are carbon (C), hydrogen (H), oxygen (O), and nitrogen (N), although other elements are found in the side chains of certain amino acids. About 500 naturally occurring amino acids are known (though only 20 appear in the genetic code) and can be classified in many ways. They can be classified according to the core structural functional groups' locations as alpha- (α-), beta- (β-), gamma- (γ-) or delta- (δ-) amino acids; other categories relate to polarity, pH level, and side chain group type (aliphatic, acyclic, aromatic, containing hydroxyl or sulfur, etc.). In the form of proteins, amino acid residues form the second-largest component (water is the largest) of human muscles and other tissues. Beyond their role as residues in proteins, amino acids participate in a number of processes such as neurotransmitter transport and biosynthesis.

In biochemistry, amino acids having both the amine and the carboxylic acid groups attached to the first (alpha-) carbon atom have particular importance. They are known as 2-, alpha-, or α-amino acids (generic formula HNCHRCOOH in most cases, where R is an organic substituent known as a "side chain"); often the term "amino acid" is used to refer specifically to these. They include the 22 proteinogenic ("protein-building") amino acids, which combine into peptide chains ("polypeptides") to form the building-blocks of a vast array of proteins. These are all -stereoisomers ("left-handed" isomers), although a few -amino acids ("right-handed") occur in bacterial envelopes, as a neuromodulator (-serine), and in some antibiotics.

Twenty of the proteinogenic amino acids are encoded directly by triplet codons in the genetic code and are known as "standard" amino acids. The other two ("non-standard" or "non-canonical") are selenocysteine (present in many prokaryotes as well as most eukaryotes, but not coded directly by DNA), and pyrrolysine (found only in some archea and one bacterium). Pyrrolysine and selenocysteine are encoded via variant codons; for example, selenocysteine is encoded by stop codon and SECIS element. "N"-formylmethionine (which is often the initial amino acid of proteins in bacteria, mitochondria, and chloroplasts) is generally considered as a form of methionine rather than as a separate proteinogenic amino acid. Codon–tRNA combinations not found in nature can also be used to "expand" the genetic code and form novel proteins known as alloproteins incorporating non-proteinogenic amino acids.

Many important proteinogenic and non-proteinogenic amino acids have biological functions. For example, in the human brain, glutamate (standard glutamic acid) and gamma-amino-butyric acid ("GABA", non-standard gamma-amino acid) are, respectively, the main excitatory and inhibitory neurotransmitters. Hydroxyproline, a major component of the connective tissue collagen, is synthesised from proline. Glycine is a biosynthetic precursor to porphyrins used in red blood cells. Carnitine is used in lipid transport.

Nine proteinogenic amino acids are called "essential" for humans because they cannot be produced from other compounds by the human body and so must be taken in as food. Others may be conditionally essential for certain ages or medical conditions. Essential amino acids may also differ between species.

Because of their biological significance, amino acids are important in nutrition and are commonly used in nutritional supplements, fertilizers, and food technology. Industrial uses include the production of drugs, biodegradable plastics, and chiral catalysts.

The first few amino acids were discovered in the early 19th century. In 1806, French chemists Louis-Nicolas Vauquelin and Pierre Jean Robiquet isolated a compound in asparagus that was subsequently named asparagine, the first amino acid to be discovered. Cystine was discovered in 1810, although its monomer, cysteine, remained undiscovered until 1884. Glycine and leucine were discovered in 1820. The last of the 20 common amino acids to be discovered was threonine in 1935 by William Cumming Rose, who also determined the essential amino acids and established the minimum daily requirements of all amino acids for optimal growth.

The unity of the chemical category was recognized by Wurtz in 1865, but he gave no particular name to it. Usage of the term "amino acid" in the English language is from 1898, while the German term, "Aminosäure", was used earlier. Proteins were found to yield amino acids after enzymatic digestion or acid hydrolysis. In 1902, Emil Fischer and Franz Hofmeister independently proposed that proteins are formed from many amino acids, whereby bonds are formed between the amino group of one amino acid with the carboxyl group of another, resulting in a linear structure that Fischer termed "peptide".

In the structure shown at the top of the page, R represents a side chain specific to each amino acid. The carbon atom next to the carboxyl group (which is therefore numbered 2 in the carbon chain starting from that functional group) is called the α–carbon. Amino acids containing an amino group bonded directly to the alpha carbon are referred to as "alpha amino acids". These include amino acids such as proline which contain secondary amines, which used to be often referred to as "imino acids".

The alpha amino acids are the most common form found in nature, but only when occurring in the -isomer. The alpha carbon is a chiral carbon atom, with the exception of glycine which has two indistinguishable hydrogen atoms on the alpha carbon. Therefore, all alpha amino acids but glycine can exist in either of two enantiomers, called or amino acids, which are mirror images of each other ("see also Chirality"). While -amino acids represent all of the amino acids found in proteins during translation in the ribosome, -amino acids are found in some proteins produced by enzyme posttranslational modifications after translation and translocation to the endoplasmic reticulum, as in exotic sea-dwelling organisms such as cone snails. They are also abundant components of the peptidoglycan cell walls of bacteria, and -serine may act as a neurotransmitter in the brain. -amino acids are used in racemic crystallography to create centrosymmetric crystals, which (depending on the protein) may allow for easier and more robust protein structure determination. The and convention for amino acid configuration refers not to the optical activity of the amino acid itself but rather to the optical activity of the isomer of glyceraldehyde from which that amino acid can, in theory, be synthesized (-glyceraldehyde is dextrorotatory; -glyceraldehyde is levorotatory).
In alternative fashion, the "(S)" and "(R)" designators are used to indicate the absolute stereochemistry. Almost all of the amino acids in proteins are "(S)" at the α carbon, with cysteine being "(R)" and glycine non-chiral. Cysteine has its side chain in the same geometric position as the other amino acids, but the "R/S" terminology is reversed because of the higher atomic number of sulfur compared to the carboxyl oxygen gives the side chain a higher priority, whereas the atoms in most other side chains give them lower priority.

In amino acids that have a carbon chain attached to the α–carbon (such as lysine, shown to the right) the carbons are labeled in order as α, β, γ, δ, and so on. In some amino acids, the amine group is attached to the β or γ-carbon, and these are therefore referred to as "beta" or "gamma amino acids".

Amino acids are usually classified by the properties of their side chain into four groups. The side chain can make an amino acid a weak acid or a weak base, and a hydrophile if the side chain is polar or a hydrophobe if it is nonpolar. The chemical structures of the 22 standard amino acids, along with their chemical properties, are described more fully in the article on these proteinogenic amino acids.

The phrase "branched-chain amino acids" or BCAA refers to the amino acids having aliphatic side chains that are non-linear; these are leucine, isoleucine, and valine. Proline is the only proteinogenic amino acid whose side-group links to the α-amino group and, thus, is also the only proteinogenic amino acid containing a secondary amine at this position. In chemical terms, proline is, therefore, an imino acid, since it lacks a primary amino group, although it is still classed as an amino acid in the current biochemical nomenclature, and may also be called an "N-alkylated alpha-amino acid".

The α-carboxylic acid group of amino acids is a weak acid, meaning that it releases a hydron (such as a proton) at moderate pH values. In other words, carboxylic acid groups (−COH) can be deprotonated to become negative carboxylates (−CO ). The negatively charged carboxylate ion predominates at pH values greater than the pKa of the carboxylic acid group (mean for the 20 common amino acids is about 2.2, see the table of amino acid structures above). In a complementary fashion, the α-amine of amino acids is a weak base, meaning that it accepts a proton at moderate pH values. In other words, α-amino groups (NH−) can be protonated to become positive α-ammonium groups (NH−). The positively charged α-ammonium group predominates at pH values less than the pKa of the α-ammonium group (mean for the 20 common α-amino acids is about 9.4).

Because all amino acids contain amine and carboxylic acid functional groups, they share amphiprotic properties. Below pH 2.2, the predominant form will have a neutral carboxylic acid group and a positive α-ammonium ion (net charge +1), and above pH 9.4, a negative carboxylate and neutral α-amino group (net charge −1). But at pH between 2.2 and 9.4, an amino acid usually contains both a negative carboxylate and a positive α-ammonium group, as shown in structure (2) on the right, so has net zero charge. This molecular state is known as a zwitterion, from the German Zwitter meaning "hermaphrodite" or "hybrid". The fully neutral form (structure (1) on the left) is a very minor species in aqueous solution throughout the pH range (less than 1 part in 10). Amino acids exist as zwitterions also in the solid phase, and crystallize with salt-like properties unlike typical organic acids or amines.

The variation in titration curves when the amino acids can be grouped by category. With the exception of tyrosine, using titration to distinguish among hydrophobic amino acids is problematic.

At pH values between the two pKa values, the zwitterion predominates, but coexists in dynamic equilibrium with small amounts of net negative and net positive ions. At the exact midpoint between the two pKa values, the trace amount of net negative and trace of net positive ions exactly balance, so that average net charge of all forms present is zero. This pH is known as the isoelectric point pI, so pI = ½(pKa + pKa). The individual amino acids all have slightly different pKa values, so have different isoelectric points. For amino acids with charged side chains, the pKa of the side chain is involved. Thus for Asp, Glu with negative side chains, pI = ½(pKa + pKa), where pKa is the side chain pKa. Cysteine also has potentially negative side chain with pKa = 8.14, so pI should be calculated as for Asp and Glu, even though the side chain is not significantly charged at neutral pH. For His, Lys, and Arg with positive side chains, pI = ½(pKa + pKa). Amino acids have zero mobility in electrophoresis at their isoelectric point, although this behaviour is more usually exploited for peptides and proteins than single amino acids. Zwitterions have minimum solubility at their isoelectric point and some amino acids (in particular, with non-polar side chains) can be isolated by precipitation from water by adjusting the pH to the required isoelectric point.

Amino acids are the structural units (monomers) that make up proteins. They join together to form short polymer chains called peptides or longer chains called either polypeptides or proteins. These polymers are linear and unbranched, with each amino acid within the chain attached to two neighboring amino acids. The process of making proteins encoded by DNA/RNA genetic material is called "translation" and involves the step-by-step addition of amino acids to a growing protein chain by a ribozyme that is called a ribosome. The order in which the amino acids are added is read through the genetic code from an mRNA template, which is a RNA copy of one of the organism's genes.

Twenty-two amino acids are naturally incorporated into polypeptides and are called proteinogenic or natural amino acids. Of these, 20 are encoded by the universal genetic code. The remaining 2, selenocysteine and pyrrolysine, are incorporated into proteins by unique synthetic mechanisms. Selenocysteine is incorporated when the mRNA being translated includes a SECIS element, which causes the UGA codon to encode selenocysteine instead of a stop codon. Pyrrolysine is used by some methanogenic archaea in enzymes that they use to produce methane. It is coded for with the codon UAG, which is normally a stop codon in other organisms. This UAG codon is followed by a PYLIS downstream sequence.

Aside from the 22 proteinogenic amino acids, many "non-proteinogenic" amino acids are known. Those either are not found in proteins (for example carnitine, GABA, Levothyroxine) or are not produced directly and in isolation by standard cellular machinery (for example, hydroxyproline and selenomethionine).

Non-proteinogenic amino acids that are found in proteins are formed by post-translational modification, which is modification after translation during protein synthesis. These modifications are often essential for the function or regulation of a protein. For example, the carboxylation of glutamate allows for better binding of calcium cations, and collagen contains hydroxyproline, generated by hydroxylation of proline. Another example is the formation of hypusine in the translation initiation factor EIF5A, through modification of a lysine residue. Such modifications can also determine the localization of the protein, e.g., the addition of long hydrophobic groups can cause a protein to bind to a phospholipid membrane.

Some non-proteinogenic amino acids are not found in proteins. Examples include 2-aminoisobutyric acid and the neurotransmitter gamma-aminobutyric acid. Non-proteinogenic amino acids often occur as intermediates in the metabolic pathways for standard amino acids – for example, ornithine and citrulline occur in the urea cycle, part of amino acid catabolism (see below). A rare exception to the dominance of α-amino acids in biology is the β-amino acid beta alanine (3-aminopropanoic acid), which is used in plants and microorganisms in the synthesis of pantothenic acid (vitamin B), a component of coenzyme A.

-isomers are uncommon in live organisms. For instance, gramicidin is a polypeptide made up from mixture of - and -amino acids. Other compounds containing -amino acid are tyrocidine and valinomycin. These compounds disrupt bacterial cell walls, particularly in Gram-positive bacteria. Only 837 -amino acids were found in Swiss-Prot database (187 million amino acids analysed).

The 20 amino acids that are encoded directly by the codons of the universal genetic code are called "standard" or "canonical" amino acids. A modified form of methionine ("N"-formylmethionine) is often incorporated in place of methionine as the initial amino acid of proteins in bacteria, mitochondria and chloroplasts. Other amino acids are called "non-standard" or "non-canonical". Most of the non-standard amino acids are also non-proteinogenic (i.e. they cannot be incorporated into proteins during translation), but two of them are proteinogenic, as they can be incorporated translationally into proteins by exploiting information not encoded in the universal genetic code.

The two non-standard proteinogenic amino acids are selenocysteine (present in many non-eukaryotes as well as most eukaryotes, but not coded directly by DNA) and pyrrolysine (found only in some archaea and one bacterium). The incorporation of these non-standard amino acids is rare. For example, 25 human proteins include selenocysteine (Sec) in their primary structure, and the structurally characterized enzymes (selenoenzymes) employ Sec as the catalytic moiety in their active sites. Pyrrolysine and selenocysteine are encoded via variant codons. For example, selenocysteine is encoded by stop codon and SECIS element.

When taken up into the human body from the diet, the 20 standard amino acids either are used to synthesize proteins and other biomolecules or are oxidized to urea and carbon dioxide as a source of energy. The oxidation pathway starts with the removal of the amino group by a transaminase; the amino group is then fed into the urea cycle. The other product of transamidation is a keto acid that enters the citric acid cycle. Glucogenic amino acids can also be converted into glucose, through gluconeogenesis. Of the 20 standard amino acids, nine (His, Ile, Leu, Lys, Met, Phe, Thr, Trp and Val) are called essential amino acids because the human body cannot synthesize them from other compounds at the level needed for normal growth, so they must be obtained from food. In addition, cysteine, taurine, tyrosine, and arginine are considered semiessential amino-acids in children (though taurine is not technically an amino acid), because the metabolic pathways that synthesize these amino acids are not fully developed. The amounts required also depend on the age and health of the individual, so it is hard to make general statements about the dietary requirement for some amino acids. Dietary exposure to the non-standard amino acid BMAA has been linked to human neurodegenerative diseases, including ALS.

In humans, non-protein amino acids also have important roles as metabolic intermediates, such as in the biosynthesis of the neurotransmitter gamma-amino-butyric acid (GABA). Many amino acids are used to synthesize other molecules, for example:

Some non-standard amino acids are used as defenses against herbivores in plants. For example, canavanine is an analogue of arginine that is found in many legumes, and in particularly large amounts in "Canavalia gladiata" (sword bean). This amino acid protects the plants from predators such as insects and can cause illness in people if some types of legumes are eaten without processing. The non-protein amino acid mimosine is found in other species of legume, in particular "Leucaena leucocephala". This compound is an analogue of tyrosine and can poison animals that graze on these plants.

Amino acids are used for a variety of applications in industry, but their main use is as additives to animal feed. This is necessary, since many of the bulk components of these feeds, such as soybeans, either have low levels or lack some of the essential amino acids: lysine, methionine, threonine, and tryptophan are most important in the production of these feeds. In this industry, amino acids are also used to chelate metal cations in order to improve the absorption of minerals from supplements, which may be required to improve the health or production of these animals.

The food industry is also a major consumer of amino acids, in particular, glutamic acid, which is used as a flavor enhancer, and aspartame (aspartyl-phenylalanine-1-methyl ester) as a low-calorie artificial sweetener. Similar technology to that used for animal nutrition is employed in the human nutrition industry to alleviate symptoms of mineral deficiencies, such as anemia, by improving mineral absorption and reducing negative side effects from inorganic mineral supplementation.

The chelating ability of amino acids has been used in fertilizers for agriculture to facilitate the delivery of minerals to plants in order to correct mineral deficiencies, such as iron chlorosis. These fertilizers are also used to prevent deficiencies from occurring and improving the overall health of the plants. The remaining production of amino acids is used in the synthesis of drugs and cosmetics.

Similarly, some amino acids derivatives are used in pharmaceutical industry. They include 5-HTP (5-hydroxytryptophan) used for experimental treatment of depression, -DOPA (-dihydroxyphenylalanine) for Parkinson's treatment, and eflornithine drug that inhibits ornithine decarboxylase and used in the treatment of sleeping sickness.

Since 2001, 40 non-natural amino acids have been added into protein by creating a unique codon (recoding) and a corresponding transfer-RNA:aminoacyl – tRNA-synthetase pair to encode it with diverse physicochemical and biological properties in order to be used as a tool to exploring protein structure and function or to create novel or enhanced proteins.

Nullomers are codons that in theory code for an amino acid, however in nature there is a selective bias against using this codon in favor of another, for example bacteria prefer to use CGA instead of AGA to code for arginine. This creates some sequences that do not appear in the genome. This characteristic can be taken advantage of and used to create new selective cancer-fighting drugs and to prevent cross-contamination of DNA samples from crime-scene investigations.

Amino acids are important as low-cost feedstocks. These compounds are used in chiral pool synthesis as enantiomerically pure building-blocks.

Amino acids have been investigated as precursors chiral catalysts, e.g., for asymmetric hydrogenation reactions, although no commercial applications exist.

Amino acids are under development as components of a range of biodegradable polymers. These materials have applications as environmentally friendly packaging and in medicine in drug delivery and the construction of prosthetic implants. These polymers include polypeptides, polyamides, polyesters, polysulfides, and polyurethanes with amino acids either forming part of their main chains or bonded as side chains. These modifications alter the physical properties and reactivities of the polymers. An interesting example of such materials is polyaspartate, a water-soluble biodegradable polymer that may have applications in disposable diapers and agriculture. Due to its solubility and ability to chelate metal ions, polyaspartate is also being used as a biodegradeable anti-scaling agent and a corrosion inhibitor. In addition, the aromatic amino acid tyrosine is being developed as a possible replacement for toxic phenols such as bisphenol A in the manufacture of polycarbonates.

As amino acids have both a primary amine group and a primary carboxyl group, these chemicals can undergo most of the reactions associated with these functional groups. These include nucleophilic addition, amide bond formation, and imine formation for the amine group, and esterification, amide bond formation, and decarboxylation for the carboxylic acid group. The combination of these functional groups allow amino acids to be effective polydentate ligands for metal-amino acid chelates.
The multiple side chains of amino acids can also undergo chemical reactions. The types of these reactions are determined by the groups on these side chains and are, therefore, different between the various types of amino acid.

Several methods exist to synthesize amino acids. One of the oldest methods begins with the bromination at the α-carbon of a carboxylic acid. Nucleophilic substitution with ammonia then converts the alkyl bromide to the amino acid. In alternative fashion, the Strecker amino acid synthesis involves the treatment of an aldehyde with potassium cyanide and ammonia, this produces an α-amino nitrile as an intermediate. Hydrolysis of the nitrile in acid then yields a α-amino acid. Using ammonia or ammonium salts in this reaction gives unsubstituted amino acids, whereas substituting primary and secondary amines will yield substituted amino acids. Likewise, using ketones, instead of aldehydes, gives α,α-disubstituted amino acids. The classical synthesis gives racemic mixtures of α-amino acids as products, but several alternative procedures using asymmetric auxiliaries or asymmetric catalysts have been developed.

At the current time, the most-adopted method is an automated synthesis on a solid support (e.g., polystyrene beads), using protecting groups (e.g., Fmoc and t-Boc) and activating groups (e.g., DCC and DIC).

As both the amine and carboxylic acid groups of amino acids can react to form amide bonds, one amino acid molecule can react with another and become joined through an amide linkage. This polymerization of amino acids is what creates proteins. This condensation reaction yields the newly formed peptide bond and a molecule of water. In cells, this reaction does not occur directly; instead, the amino acid is first activated by attachment to a transfer RNA molecule through an ester bond. This aminoacyl-tRNA is produced in an ATP-dependent reaction carried out by an aminoacyl tRNA synthetase. This aminoacyl-tRNA is then a substrate for the ribosome, which catalyzes the attack of the amino group of the elongating protein chain on the ester bond. As a result of this mechanism, all proteins made by ribosomes are synthesized starting at their N-terminus and moving toward their C-terminus.

However, not all peptide bonds are formed in this way. In a few cases, peptides are synthesized by specific enzymes. For example, the tripeptide glutathione is an essential part of the defenses of cells against oxidative stress. This peptide is synthesized in two steps from free amino acids. In the first step, gamma-glutamylcysteine synthetase condenses cysteine and glutamic acid through a peptide bond formed between the side chain carboxyl of the glutamate (the gamma carbon of this side chain) and the amino group of the cysteine. This dipeptide is then condensed with glycine by glutathione synthetase to form glutathione.

In chemistry, peptides are synthesized by a variety of reactions. One of the most-used in solid-phase peptide synthesis uses the aromatic oxime derivatives of amino acids as activated units. These are added in sequence onto the growing peptide chain, which is attached to a solid resin support. The ability to easily synthesize vast numbers of different peptides by varying the types and order of amino acids (using combinatorial chemistry) has made peptide synthesis particularly important in creating libraries of peptides for use in drug discovery through high-throughput screening.

In plants, nitrogen is first assimilated into organic compounds in the form of glutamate, formed from alpha-ketoglutarate and ammonia in the mitochondrion. In order to form other amino acids, the plant uses transaminases to move the amino group to another alpha-keto carboxylic acid. For example, aspartate aminotransferase converts glutamate and oxaloacetate to alpha-ketoglutarate and aspartate. Other organisms use transaminases for amino acid synthesis, too.

Nonstandard amino acids are usually formed through modifications to standard amino acids. For example, homocysteine is formed through the transsulfuration pathway or by the demethylation of methionine via the intermediate metabolite S-adenosyl methionine, while hydroxyproline is made by a posttranslational modification of proline.

Microorganisms and plants can synthesize many uncommon amino acids. For example, some microbes make 2-aminoisobutyric acid and lanthionine, which is a sulfide-bridged derivative of alanine. Both of these amino acids are found in peptidic lantibiotics such as alamethicin. However, in plants, 1-aminocyclopropane-1-carboxylic acid is a small disubstituted cyclic amino acid that is a key intermediate in the production of the plant hormone ethylene.

Amino acids must first pass out of organelles and cells into blood circulation via amino acid transporters, since the amine and carboxylic acid groups are typically ionized. Degradation of an amino acid, occurring in the liver and kidneys, often involves deamination by moving its amino group to alpha-ketoglutarate, forming glutamate. This process involves transaminases, often the same as those used in amination during synthesis. In many vertebrates, the amino group is then removed through the urea cycle and is excreted in the form of urea. However, amino acid degradation can produce uric acid or ammonia instead. For example, serine dehydratase converts serine to pyruvate and ammonia. After removal of one or more amino groups, the remainder of the molecule can sometimes be used to synthesize new amino acids, or it can be used for energy by entering glycolysis or the citric acid cycle, as detailed in image at right.

The 20 amino acids encoded directly by the genetic code can be divided into several groups based on their properties. Important factors are charge, hydrophilicity or hydrophobicity, size, and functional groups. These properties are important for protein structure and protein–protein interactions. The water-soluble proteins tend to have their hydrophobic residues (Leu, Ile, Val, Phe, and Trp) buried in the middle of the protein, whereas hydrophilic side chains are exposed to the aqueous solvent. (Note that in biochemistry, a residue refers to a specific monomer within the polymeric chain of a polysaccharide, protein or nucleic acid.) The integral membrane proteins tend to have outer rings of exposed hydrophobic amino acids that anchor them into the lipid bilayer. In the case part-way between these two extremes, some peripheral membrane proteins have a patch of hydrophobic amino acids on their surface that locks onto the membrane. In similar fashion, proteins that have to bind to positively charged molecules have surfaces rich with negatively charged amino acids like glutamate and aspartate, while proteins binding to negatively charged molecules have surfaces rich with positively charged chains like lysine and arginine. There are different hydrophobicity scales of amino acid residues.

Some amino acids have special properties such as cysteine, that can form covalent disulfide bonds to other cysteine residues, proline that forms a cycle to the polypeptide backbone, and glycine that is more flexible than other amino acids.

Many proteins undergo a range of posttranslational modifications, when additional chemical groups are attached to the amino acids in proteins. Some modifications can produce hydrophobic lipoproteins, or hydrophilic glycoproteins. These type of modification allow the reversible targeting of a protein to a membrane. For example, the addition and removal of the fatty acid palmitic acid to cysteine residues in some signaling proteins causes the proteins to attach and then detach from cell membranes.

Two additional amino acids are in some species coded for by codons that are usually interpreted as stop codons:

In addition to the specific amino acid codes, placeholders are used in cases where chemical or crystallographic analysis of a peptide or protein cannot conclusively determine the identity of a residue. They are also used to summarise conserved protein sequence motifs. The use of single letters to indicate sets of similar residues is similar to the use of abbreviation codes for degenerate bases.

Unk is sometimes used instead of Xaa, but is less standard.

In addition, many non-standard amino acids have a specific code. For example, several peptide drugs, such as Bortezomib and MG132, are artificially synthesized and retain their protecting groups, which have specific codes. Bortezomib is Pyz-Phe-boroLeu, and MG132 is Z-Leu-Leu-Leu-al. To aid in the analysis of protein structure, photo-reactive amino acid analogs are available. These include photoleucine (pLeu) and photomethionine (pMet).


</doc>
<doc id="1208" url="https://en.wikipedia.org/wiki?curid=1208" title="Alan Turing">
Alan Turing

Alan Mathison Turing (; 23 June 1912 – 7 June 1954) was an English computer scientist, mathematician, logician, cryptanalyst, philosopher, and theoretical biologist.

Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general purpose computer. Turing is widely considered to be the father of theoretical computer science and artificial intelligence.

During the Second World War, Turing worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. For a time he led Hut 8, the section which was responsible for German naval cryptanalysis. Here he devised a number of techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bombe method, an electromechanical machine that could find settings for the Enigma machine. Turing played a pivotal role in cracking intercepted coded messages that enabled the Allies to defeat the Nazis in many crucial engagements, including the Battle of the Atlantic, and in so doing helped win the war. Counterfactual history is difficult with respect to the effect Ultra intelligence had on the length of the war, but at the upper end it has been estimated that this work shortened the war in Europe by more than two years and saved over fourteen million lives.

After the war, Turing worked at the National Physical Laboratory, where he designed the ACE, among the first designs for a stored-program computer. In 1948 Turing joined Max Newman's Computing Machine Laboratory at the Victoria University of Manchester, where he helped develop the Manchester computers and became interested in mathematical biology. He wrote a paper on the chemical basis of morphogenesis, and predicted oscillating chemical reactions such as the Belousov–Zhabotinsky reaction, first observed in the 1960s.

Turing was prosecuted in 1952 for homosexual acts, when by the Labouchere Amendment, "gross indecency" was criminal in the UK. He accepted chemical castration treatment, with DES, as an alternative to prison. Turing died in 1954, 16 days before his 42nd birthday, from cyanide poisoning. An inquest determined his death as suicide, but it has been noted that the known evidence is also consistent with accidental poisoning. In 2009, following an Internet campaign, British Prime Minister Gordon Brown made an official public apology on behalf of the British government for "the appalling way he was treated." Queen Elizabeth II granted him a posthumous pardon in 2013. The Alan Turing law is now an informal term for a 2017 law in the United Kingdom that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.

Turing was born in Maida Vale, London, while his father, Julius Mathison Turing (1873–1947), was on leave from his position with the Indian Civil Service (ICS) at Chhatrapur, Bihar and Orissa Province, in British India. Turing's father was the son of a clergyman, the Rev. John Robert Turing, from a Scottish family of merchants that had been based in the Netherlands and included a baronet. Turing's mother, Julius' wife, was Ethel Sara Turing (née Stoney 1881–1976), daughter of Edward Waller Stoney, chief engineer of the Madras Railways. The Stoneys were a Protestant Anglo-Irish gentry family from both County Tipperary and County Longford, while Ethel herself had spent much of her childhood in County Clare.

Julius' work with the ICS brought the family to British India, where his grandfather had been a general in the Bengal Army. However, both Julius and Ethel wanted their children to be brought up in Britain, so they moved to Maida Vale, London, where Alan Turing was born on 23 June 1912, as recorded by a blue plaque on the outside of the house of his birth, later the Colonnade Hotel. Turing had an elder brother, John (the father of Sir John Dermot Turing, 12th Baronet of the Turing baronets).

Turing's father's civil service commission was still active and during Turing's childhood years Turing's parents travelled between Hastings in England and India, leaving their two sons to stay with a retired Army couple. At Hastings, Turing stayed at Baston Lodge, Upper Maze Hill, St Leonards-on-Sea, now marked with a blue plaque. The plaque was unveiled on 23 June 2012, the centenary of Turing's birth.

Very early in life, Turing showed signs of the genius that he was later to display prominently. His parents purchased a house in Guildford in 1927, and Turing lived there during school holidays. The location is also marked with a blue plaque.

Turing's parents enrolled him at St Michael's, a day school at 20 Charles Road, St Leonards-on-Sea, at the age of six. The headmistress recognised his talent early on, as did many of his subsequent teachers.

Between January 1922 and 1926, Turing was educated at Hazelhurst Preparatory School, an independent school in the village of Frant in Sussex (now East Sussex). In 1926, at the age of 13, he went on to Sherborne School, a boarding independent school in the market town of Sherborne in Dorset. The first day of term coincided with the 1926 General Strike in Britain, but he was so determined to attend, that he rode his bicycle unaccompanied from Southampton to Sherborne, stopping overnight at an inn.

Turing's natural inclination towards mathematics and science did not earn him respect from some of the teachers at Sherborne, whose definition of education placed more emphasis on the classics. His headmaster wrote to his parents: "I hope he will not fall between two stools. If he is to stay at public school, he must aim at becoming "educated". If he is to be solely a "Scientific Specialist", he is wasting his time at a public school". Despite this, Turing continued to show remarkable ability in the studies he loved, solving advanced problems in 1927 without having studied even elementary calculus. In 1928, aged 16, Turing encountered Albert Einstein's work; not only did he grasp it, but it is possible that he managed to deduce Einstein's questioning of Newton's laws of motion from a text in which this was never made explicit.

At Sherborne, Turing formed a significant friendship with fellow pupil Christopher Morcom, who has been described as Turing's "first love". Their relationship provided inspiration in Turing's future endeavours, but it was cut short by Morcom's death, in February 1930, from complications of bovine tuberculosis, contracted after drinking infected cow's milk some years previously.

The event caused Turing great sorrow. He coped with his grief by working that much harder on the topics of science and mathematics that he had shared with Morcom. In a letter to Morcom's mother Turing said:I am sure I could not have found anywhere another companion so brilliant and yet so charming and unconceited. I regarded my interest in my work, and in such things as astronomy (to which he introduced me) as something to be shared with him and I think he felt a little the same about me ... I know I must put as much energy if not as much interest into my work as if he were alive, because that is what he would like me to do.

Some have speculated that Morcom's death was the cause of Turing's atheism and materialism. Apparently, at this point in his life he still believed in such concepts as a spirit, independent of the body and surviving death. In a later letter, also written to Morcom's mother, Turing said: Personally, I believe that spirit is really eternally connected with matter but certainly not by the same kind of body ... as regards the actual connection between spirit and body I consider that the body [can] hold on to a 'spirit', whilst the body is alive and awake the two are firmly connected. When the body is asleep I cannot guess what happens but when the body dies, the 'mechanism' of the body, holding the spirit is gone and the spirit finds a new body sooner or later, perhaps immediately.

After Sherborne, Turing studied as an undergraduate from 1931 to 1934 at King's College, Cambridge, where he was awarded first-class honours in mathematics. In 1935, at the age of 22, he was elected a fellow of King's on the strength of a dissertation in which he proved the central limit theorem. Unknown to the committee, the theorem had already been proven, in 1922, by Jarl Waldemar Lindeberg.

In 1936, Turing published his paper "On Computable Numbers, with an Application to the Entscheidungsproblem" (1936). In this paper, Turing reformulated Kurt Gödel's 1931 results on the limits of proof and computation, replacing Gödel's universal arithmetic-based formal language with the formal and simple hypothetical devices that became known as Turing machines. The "Entscheidungsproblem" (decision problem) was originally posed by German mathematician David Hilbert in 1928. Turing proved that his "universal computing machine" would be capable of performing any conceivable mathematical computation if it were representable as an algorithm. He went on to prove that there was no solution to the "decision problem" by first showing that the halting problem for Turing machines is undecidable: It is not possible to decide algorithmically whether a Turing machine will ever halt.
Although Turing's proof was published shortly after Alonzo Church's equivalent proof using his lambda calculus, Turing's approach is considerably more accessible and intuitive than Church's. It also included a notion of a 'Universal Machine' (now known as a universal Turing machine), with the idea that such a machine could perform the tasks of any other computation machine (as indeed could Church's lambda calculus). According to the Church–Turing thesis, Turing machines and the lambda calculus are capable of computing anything that is computable. John von Neumann acknowledged that the central concept of the modern computer was due to Turing's paper. To this day, Turing machines are a central object of study in theory of computation.

From September 1936 to July 1938, Turing spent most of his time studying under Church at Princeton University, in the second year as a Jane Eliza Procter Visiting Fellow. In addition to his purely mathematical work, he studied cryptology and also built three of four stages of an electro-mechanical binary multiplier. In June 1938, he obtained his PhD from Princeton; his dissertation, "Systems of Logic Based on Ordinals", introduced the concept of ordinal logic and the notion of relative computing, where Turing machines are augmented with so-called oracles, allowing the study of problems that cannot be solved by Turing machines. John von Neumann wanted to hire him as his postdoctoral assistant, but he went back to England.

When Turing returned to Cambridge, he attended lectures given in 1939 by Ludwig Wittgenstein about the foundations of mathematics. The lectures have been reconstructed verbatim, including interjections from Turing and other students, from students' notes. Turing and Wittgenstein argued and disagreed, with Turing defending formalism and Wittgenstein propounding his view that mathematics does not discover any absolute truths, but rather invents them.

During the Second World War, Turing was a leading participant in the breaking of German ciphers at Bletchley Park. The historian and wartime codebreaker Asa Briggs has said, "You needed exceptional talent, you needed genius at Bletchley and Turing's was that genius."
From September 1938, Turing had been working part-time with the GC&CS, the British codebreaking organisation. He concentrated on cryptanalysis of the Enigma with Dilly Knox, a senior GC&CS codebreaker. Soon after the July 1939 Warsaw meeting at which the Polish Cipher Bureau had provided the British and French with the details of the wiring of Enigma rotors and their method of decrypting Enigma code messages, Turing and Knox started to work on a less fragile approach to the problem. The Polish method relied on an insecure indicator procedure that the Germans were likely to change, which they did in May 1940. Turing's approach was more general, using crib-based decryption for which he produced the functional specification of the bombe (an improvement of the Polish Bomba).

On 4 September 1939, the day after the UK declared war on Germany, Turing reported to Bletchley Park, the wartime station of GC&CS.
Specifying the bombe was the first of five major cryptanalytical advances that Turing made during the war. The others were: deducing the indicator procedure used by the German navy; developing a statistical procedure for making much more efficient use of the bombes dubbed "Banburismus"; developing a procedure for working out the cam settings of the wheels of the Lorenz SZ 40/42 ("Tunny") dubbed "Turingery" and, towards the end of the war, the development of a portable secure voice scrambler at Hanslope Park that was codenamed "Delilah".

By using statistical techniques to optimise the trial of different possibilities in the code breaking process, Turing made an innovative contribution to the subject. He wrote two papers discussing mathematical approaches, titled "The Applications of Probability to Cryptography" and "Paper on Statistics of Repetitions", which were of such value to GC&CS and its successor GCHQ that they were not released to the UK National Archives until April 2012, shortly before the centenary of his birth. A GCHQ mathematician, "who identified himself only as Richard," said at the time that the fact that the contents had been restricted for some 70 years demonstrated their importance, and their relevance to post-war cryptanalysis: 

Turing had something of a reputation for eccentricity at Bletchley Park. He was known to his colleagues as 'Prof' and his treatise on Enigma was known as 'The Prof's Book'. Jack Good, a cryptanalyst who worked with him, is quoted by Ronald Lewin as having said of Turing:

While working at Bletchley, Turing, who was a talented long-distance runner, occasionally ran the to London when he was needed for high-level meetings, and he was capable of world-class marathon standards. Turing tried out for the 1948 British Olympic team, hampered by an injury. His tryout time for the marathon was only 11 minutes slower than British silver medallist Thomas Richards' Olympic race time of 2 hours 35 minutes. He was Walton Athletic Club's best runner, a fact discovered when he passed the group while running alone.

In 1946, Turing was appointed an Officer of the Order of the British Empire (OBE) by King George VI for his wartime services, but his work remained secret for many years.

Within weeks of arriving at Bletchley Park, Turing had specified an electromechanical machine that could help break Enigma more effectively than the Polish "bomba kryptologiczna", from which its name was derived. The bombe, with an enhancement suggested by mathematician Gordon Welchman, became one of the primary tools, and the major automated one, used to attack Enigma-enciphered messages.

Jack Good opined:
The bombe searched for possible correct settings used for an Enigma message (i.e., rotor order, rotor settings and plugboard settings), using a suitable "crib": a fragment of probable plaintext. For each possible setting of the rotors (which had on the order of 10 states, or 10 states for the four-rotor U-boat variant), the bombe performed a chain of logical deductions based on the crib, implemented electromechanically.

The bombe detected when a contradiction had occurred and ruled out that setting, moving on to the next. Most of the possible settings would cause contradictions and be discarded, leaving only a few to be investigated in detail. A contradiction would occur when an enciphered letter would be turned back into the same plaintext letter—this simply wasn't possible with the Enigma. The first bombe was installed on 18 March 1940.

By late 1941, Turing and his fellow cryptanalysts Gordon Welchman, Hugh Alexander, and Stuart Milner-Barry were frustrated. Building on the work of the Poles, they had set up a good working system for decrypting Enigma signals, but they only had a few people and a few bombes, so they did not have time to translate all the signals. In the summer, they had considerable success, and shipping losses had fallen to under 100,000 tons a month, but they were still on a knife-edge. They badly needed more resources to keep abreast of German adjustments. They had tried to get more people and fund more bombes through the proper channels, but they were getting nowhere. Finally, breaking all the rules, on 28 October they wrote directly to Winston Churchill spelling out their difficulties, with Turing as the first named. They emphasised how small their need was compared with the vast expenditure of men and money by the forces and compared with the level of assistance they could offer to the forces.

As Andrew Hodges, biographer of Turing, later wrote, "This letter had an electric effect." Churchill wrote a memo to General Ismay, which read: "ACTION THIS DAY. Make sure they have all they want on extreme priority and report to me that this has been done." On 18 November, the chief of the secret service reported that every possible measure was being taken. The cryptographers at Bletchley Park did not know of the Prime Minister's response, but as Milner-Barry later recalled, "All that we did notice was that almost from that day the rough ways began miraculously to be made smooth." More than two hundred bombes were in operation by the end of the war.

Turing decided to tackle the particularly difficult problem of German naval Enigma "because no one else was doing anything about it and I could have it to myself". In December 1939, Turing solved the essential part of the naval indicator system, which was more complex than the indicator systems used by the other services.

That same night, he also conceived of the idea of "Banburismus", a sequential statistical technique (what Abraham Wald later called sequential analysis) to assist in breaking the naval Enigma, "though I was not sure that it would work in practice, and was not, in fact, sure until some days had actually broken." For this, he invented a measure of weight of evidence that he called the "ban". "Banburismus" could rule out certain sequences of the Enigma rotors, substantially reducing the time needed to test settings on the bombes.

Turing travelled to the United States in November 1942 and worked with US Navy cryptanalysts on the naval Enigma and bombe construction in Washington; he also visited their Computing Machine Laboratory in Dayton, Ohio.

Turing's reaction to the American bombe design was far from enthusiastic:
During this trip, he also assisted at Bell Labs with the development of secure speech devices. He returned to Bletchley Park in March 1943. During his absence, Hugh Alexander had officially assumed the position of head of Hut 8, although Alexander had been "de facto" head for some time (Turing having little interest in the day-to-day running of the section). Turing then became a general consultant for cryptanalysis at Bletchley Park.

Alexander wrote this about Turing's contribution:
In July 1942, Turing devised a technique termed "Turingery" (or jokingly "Turingismus") for use against the Lorenz cipher messages produced by the Germans' new "Geheimschreiber" (secret writer) machine. This was a teleprinter rotor cipher attachment codenamed "Tunny" at Bletchley Park. Turingery was a method of "wheel-breaking", i.e., a procedure for working out the cam settings of Tunny's wheels. He also introduced the Tunny team to Tommy Flowers who, under the guidance of Max Newman, went on to build the Colossus computer, the world's first programmable digital electronic computer, which replaced a simpler prior machine (the Heath Robinson), and whose superior speed allowed the statistical decryption techniques to be applied usefully to the messages. Some have mistakenly said that Turing was a key figure in the design of the Colossus computer. Turingery and the statistical approach of Banburismus undoubtedly fed into the thinking about cryptanalysis of the Lorenz cipher, but he was not directly involved in the Colossus development.

Following his work at Bell Labs in the US, Turing pursued the idea of electronic enciphering of speech in the telephone system, and in the latter part of the war, he moved to work for the Secret Service's Radio Security Service (later HMGCC) at Hanslope Park. There he further developed his knowledge of electronics with the assistance of engineer Donald Bayley. Together they undertook the design and construction of a portable secure voice communications machine codenamed "Delilah". It was intended for different applications, lacking capability for use with long-distance radio transmissions, and in any case, Delilah was completed too late to be used during the war. Though the system worked fully, with Turing demonstrating it to officials by encrypting and decrypting a recording of a Winston Churchill speech, Delilah was not adopted for use. Turing also consulted with Bell Labs on the development of SIGSALY, a secure voice system that was used in the later years of the war.

Between 1945 and 1947, Turing lived in Hampton, London, while he worked on the design of the ACE (Automatic Computing Engine) at the National Physical Laboratory (NPL). He presented a paper on 19 February 1946, which was the first detailed design of a stored-program computer. Von Neumann's incomplete "First Draft of a Report on the EDVAC" had predated Turing's paper, but it was much less detailed and, according to John R. Womersley, Superintendent of the NPL Mathematics Division, it "contains a number of ideas which are Dr. Turing's own". Although ACE was a feasible design, the secrecy surrounding the wartime work at Bletchley Park led to delays in starting the project and he became disillusioned. In late 1947 he returned to Cambridge for a sabbatical year during which he produced a seminal work on "Intelligent Machinery" that was not published in his lifetime. While he was at Cambridge, the Pilot ACE was being built in his absence. It executed its first program on 10 May 1950, and a number of later computers around the world owe much to it, including the English Electric DEUCE and the American Bendix G-15. The full version of Turing's ACE was not built until after his death.

According to the memoirs of the German computer pioneer Heinz Billing from the Max Planck Institute for Physics, published by Genscher, Düsseldorf, there was a meeting between Alan Turing and Konrad Zuse. It took place in Göttingen in 1947. The interrogation had the form of a colloquium. Participants were Womersley, Turing, Porter from England and a few German researchers like Zuse, Walther, and Billing (for more details see Herbert Bruderer, "Konrad Zuse und die Schweiz").

Turing was appointed Reader in the Mathematics Department at the Victoria University of Manchester in 1948 and in 1949, became Deputy Director of the Computing Machine Laboratory there, working on software for one of the earliest stored-program computers—the Manchester Mark 1. During this time he continued to do more abstract work in mathematics,<ref name="doi10.1093/qjmam/1.1.287"></ref> and in "Computing Machinery and Intelligence" ("Mind", October 1950), Turing addressed the problem of artificial intelligence, and proposed an experiment that became known as the Turing test, an attempt to define a standard for a machine to be called "intelligent". The idea was that a computer could be said to "think" if a human interrogator could not tell it apart, through conversation, from a human being. In the paper, Turing suggested that rather than building a program to simulate the adult mind, it would be better rather to produce a simpler one to simulate a child's mind and then to subject it to a course of education. A reversed form of the Turing test is widely used on the Internet; the CAPTCHA test is intended to determine whether the user is a human or a computer.

In 1948 Turing, working with his former undergraduate colleague, D. G. Champernowne, began writing a chess program for a computer that did not yet exist. By 1950, the program was completed and dubbed the Turochamp. In 1952, he tried to implement it on a Ferranti Mark 1, but lacking enough power, the computer was unable to execute the program. Instead, Turing "ran" the program by flipping through the pages of the algorithm and carrying out its instructions on a chessboard, taking about half an hour per move. The game was recorded. According to Garry Kasparov, Turing's program "played a recognizable game of chess." The program lost to Turing's colleague Alick Glennie, although it is said that it won a game against Champernowne's wife.

His Turing test was a significant, characteristically provocative, and lasting contribution to the debate regarding artificial intelligence, which continues after more than half a century. He also invented the LU decomposition method in 1948, used today for solving matrix equations.

In 1951, when Turing was 39 years old, he turned to mathematical biology, finally publishing his masterpiece "The Chemical Basis of Morphogenesis" in January 1952. He was interested in morphogenesis, the development of patterns and shapes in biological organisms. Among other things, he wanted to understand Fibonacci phyllotaxis, the existence of Fibonacci numbers in plant structures. He suggested that a system of chemicals reacting with each other and diffusing across space, termed a reaction-diffusion system, could account for "the main phenomena of morphogenesis". He used systems of partial differential equations to model catalytic chemical reactions. For example, if a catalyst A is required for a certain chemical reaction to take place, and if the reaction produced more of the catalyst A, then we say that the reaction is autocatalytic, and there is positive feedback that can be modelled by nonlinear differential equations. Turing discovered that patterns could be created if the chemical reaction not only produced catalyst A, but also produced an inhibitor B that slowed down the production of A. If A and B then diffused through the container at different rates, then you could have some regions where A dominated and some where B did. To calculate the extent of this, Turing would have needed a powerful computer, but these were not so freely available in 1951, so he had to use linear approximations to solve the equations by hand. Fortunately these calculations gave the right qualitative results, and produced, for example, a uniform mixture that oddly enough had regularly spaced fixed red spots. The Russian biochemist Boris Belousov had performed experiments with similar results, but could not get his papers published because of the contemporary prejudice that any such thing violated the second law of thermodynamics. Unfortunately Belousov was not aware of Turing's paper in the "Philosophical Transactions of the Royal Society".

Although published before the structure and role of DNA was understood, Turing's work on morphogenesis remains relevant today, and is considered a seminal piece of work in mathematical biology. One of the early applications of Turing's paper was the work by James Murray explaining spots and stripes on the fur of cats, large and small. Further research in the area suggests that Turing's work can partially explain the growth of "feathers, hair follicles, the branching pattern of lungs, and even the left-right asymmetry that puts the heart on the left side of the chest." In 2012, Sheth, et al. found that in mice, removal of Hox genes causes an increase in the number of digits without an increase in the overall size of the limb, suggesting that Hox genes control digit formation by tuning the wavelength of a Turing-type mechanism. Later papers were not available until "Collected Works of A. M. Turing" was published in 1992.

In 1941, Turing proposed marriage to Hut 8 colleague Joan Clarke, a fellow mathematician and cryptanalyst, but their engagement was short-lived. After admitting his homosexuality to his fiancée, who was reportedly "unfazed" by the revelation, Turing decided that he could not go through with the marriage.

In January 1952, Turing, then 39, started a relationship with Arnold Murray, a 19-year-old unemployed man. Turing had met Murray just before Christmas outside the Regal Cinema when walking down Manchester's Oxford Road and invited him to lunch. On 23 January Turing's house was burgled. Murray told Turing that the burglar was an acquaintance of his, and Turing reported the crime to the police. During the investigation he acknowledged a sexual relationship with Murray. Homosexual acts were criminal offences in the United Kingdom at that time, and both men were charged with gross indecency under Section 11 of the Criminal Law Amendment Act 1885. Initial committal proceedings for the trial were held on 27 February during which Turing's solicitor "reserved his defence", i.e., did not argue or provide evidence against the allegations.

Later, convinced by the advice of his brother and his own solicitor, Turing entered a plea of guilty. The case, "Regina v. Turing and Murray," was brought to trial on 31 March 1952. Turing was convicted and given a choice between imprisonment and probation, which would be conditional on his agreement to undergo hormonal treatment designed to reduce libido. He accepted the option of treatment via injections of what was then called stilboestrol (now known as diethylstilbestrol or DES), a synthetic oestrogen; this treatment was continued for the course of one year. The treatment rendered Turing impotent and caused gynaecomastia, fulfilling in the literal sense Turing's prediction that "no doubt I shall emerge from it all a different man, but quite who I've not found out". Murray was given a conditional discharge.

Turing's conviction led to the removal of his security clearance and barred him from continuing with his cryptographic consultancy for the Government Communications Headquarters (GCHQ), the British signals intelligence agency that had evolved from GC&CS in 1946 (though he kept his academic job). He was denied entry into the United States after his conviction in 1952, but was free to visit other European countries. Turing was never accused of espionage but, in common with all who had worked at Bletchley Park, he was prevented by the Official Secrets Act from discussing his war work.

On 8 June 1954, Turing's housekeeper found him dead. He had died the previous day. A post-mortem examination established that the cause of death was cyanide poisoning. When his body was discovered, an apple lay half-eaten beside his bed, and although the apple was not tested for cyanide, it was speculated that this was the means by which a fatal dose was consumed. An inquest determined that he had committed suicide, and he was cremated at Woking Crematorium on 12 June 1954. Turing's ashes were scattered there, just as his father's had been. Andrew Hodges and another biographer, David Leavitt, have both suggested that Turing was re-enacting a scene from the Walt Disney film "Snow White and the Seven Dwarfs" (1937), his favourite fairy tale, both noting that (in Leavitt's words) he took "an especially keen pleasure in the scene where the Wicked Queen immerses her apple in the poisonous brew."

Philosophy professor Jack Copeland has questioned various aspects of the coroner's historical verdict. He suggests an alternative explanation for the cause of Turing's death, this being the accidental inhalation of cyanide fumes from an apparatus for electroplating gold onto spoons, which uses potassium cyanide to dissolve the gold. Turing had such an apparatus set up in his tiny spare room. Copeland notes that the autopsy findings were more consistent with inhalation than with ingestion of the poison. Turing also habitually ate an apple before bed, and it was not unusual for it to be discarded half-eaten. In addition, Turing had reportedly borne his legal setbacks and hormone treatment (which had been discontinued a year previously) "with good humour" and had shown no sign of despondency prior to his death, even setting down a list of tasks he intended to complete upon return to his office after the holiday weekend. Turing's mother believed that the ingestion was accidental, resulting from her son's careless storage of laboratory chemicals. Biographer Andrew Hodges suggests Turing arranged the delivery of the equipment to deliberately allow his mother plausible deniability regarding any suicide claims.

In August 2009, John Graham-Cumming started a petition urging the British Government to apologise for Turing's prosecution as a homosexual. The petition received more than 30,000 signatures. The Prime Minister, Gordon Brown, acknowledged the petition, releasing a statement on 10 September 2009 apologising and describing the treatment of Turing as "appalling":
In December 2011, William Jones created an e-petition requesting the British Government pardon Turing for his conviction of "gross indecency":
The petition gathered over 37,000 signatures, but the request was discouraged by Lord McNally, who gave the following opinion in his role as the Justice Minister:
John Leech, the MP for Manchester Withington (2005–15), submitted several bills to Parliament and campaigned with William Jones to secure the pardon. Leech made the case in the House of Commons that Turing's contribution to the war made him a national hero and that it was "ultimately just embarrassing" that the conviction still stood. Leech continued to take the bill through Parliament and campaigned for several years until it was passed.

On 26 July 2012, a bill was introduced in the House of Lords to grant a statutory pardon to Turing for offences under section 11 of the Criminal Law Amendment Act 1885, of which he was convicted on 31 March 1952. Late in the year in a letter to "The Daily Telegraph", the physicist Stephen Hawking and 10 other signatories including the Astronomer Royal Lord Rees, President of the Royal Society Sir Paul Nurse, Lady Trumpington (who worked for Turing during the war) and Lord Sharkey (the bill's sponsor) called on Prime Minister David Cameron to act on the pardon request. The Government indicated it would support the bill, and it passed its third reading in the Lords in October.

Before the bill could be debated in the House of Commons, the Government elected to proceed under the royal prerogative of mercy. On 24 December 2013, Queen Elizabeth II signed a pardon for Turing's conviction for gross indecency, with immediate effect. Announcing the pardon, Justice Secretary Chris Grayling said Turing deserved to be "remembered and recognised for his fantastic contribution to the war effort" and not for his later criminal conviction. The Queen officially pronounced Turing pardoned in August 2014. The Queen's action is only the fourth royal pardon granted since the conclusion of the Second World War. This case is unusual in that pardons are normally granted only when the person is technically innocent, and a request has been made by the family or other interested party. Neither condition was met in regard to Turing's conviction.

In a letter to the Prime Minister, David Cameron, after announcement of the pardon, human rights advocate Peter Tatchell criticised the decision to single out Turing due to his fame and achievements, when thousands of others convicted under the same law have not received pardons. Tatchell also called for a new investigation into Turing's death:

In September 2016, the government announced its intention to expand this retroactive exoneration to other men convicted of similar historical indecency offences, in what was described as an "Alan Turing law". The Alan Turing law is now an informal term for the law in the United Kingdom, contained in the Policing and Crime Act 2017, which serves as an amnesty law to retroactively pardon men who were cautioned or convicted under historical legislation that outlawed homosexual acts. The law applies in England and Wales.

Turing was appointed to the Order of the British Empire 1946. He was also elected a Fellow of the Royal Society (FRS) in 1951. Several things are named in his honour:

Various institutions have paid tribute to Turing by naming things after him including:
A biography published by the Royal Society shortly after Turing's death, while his wartime work was still subject to the Official Secrets Act, recorded:

Since 1966, the Turing Award has been given annually by the Association for Computing Machinery for technical or theoretical contributions to the computing community. It is widely considered to be the computing world's highest honour, equivalent to the Nobel Prize.

On 23 June 1998, on what would have been Turing's 86th birthday, his biographer, Andrew Hodges, unveiled an official English Heritage blue plaque at his birthplace and childhood home in Warrington Crescent, London, later the Colonnade Hotel. To mark the 50th anniversary of his death, a memorial plaque was unveiled on 7 June 2004 at his former residence, Hollymeade, in Wilmslow, Cheshire.

On 13 March 2000, Saint Vincent and the Grenadines issued a set of postage stamps to celebrate the greatest achievements of the 20th century, one of which carries a portrait of Turing against a background of repeated 0s and 1s, and is captioned: "1937: Alan Turing's theory of digital computing". On 1 April 2003, Turing's work at Bletchley Park was named an IEEE Milestone. On 28 October 2004, a bronze statue of Alan Turing sculpted by John W. Mills was unveiled at the University of Surrey in Guildford, marking the 50th anniversary of Turing's death; it portrays him carrying his books across the campus.

Turing was one of four mathematicians examined in the BBC documentary entitled "Dangerous Knowledge" (2008). The "Princeton Alumni Weekly" named Turing the second most significant alumnus in the history of Princeton University, second only to President James Madison. A 1.5-ton, life-size statue of Turing was unveiled on 19 June 2007 at Bletchley Park. Built from approximately half a million pieces of Welsh slate, it was sculpted by Stephen Kettle, having been commissioned by the American billionaire Sidney Frank.

Turing has been honoured in various ways in Manchester, the city where he worked towards the end of his life. In 1994, a stretch of the A6010 road (the Manchester city intermediate ring road) was named "Alan Turing Way". A bridge carrying this road was widened, and carries the name Alan Turing Bridge. A statue of Turing was unveiled in Manchester on 23 June 2001 in Sackville Park, between the University of Manchester building on Whitworth Street and Canal Street. The memorial statue depicts the "father of computer science" sitting on a bench at a central position in the park. Turing is shown holding an apple. The cast bronze bench carries in relief the text 'Alan Mathison Turing 1912–1954', and the motto 'Founder of Computer Science' as it could appear if encoded by an Enigma machine: 'IEKYF ROMSI ADXUO KVKZC GUBJ'.

A plaque at the statue's feet reads 'Father of computer science, mathematician, logician, wartime codebreaker, victim of prejudice'. There is also a Bertrand Russell quotation: "Mathematics, rightly viewed, possesses not only truth, but supreme beauty—a beauty cold and austere, like that of sculpture." The sculptor buried his own old Amstrad computer under the plinth as a tribute to "the godfather of all modern computers".

In 1999, "Time" magazine named Turing as one of the and stated, "The fact remains that everyone who taps at a keyboard, opening a spreadsheet or a word-processing program, is working on an incarnation of a Turing machine."

In 2002, Turing was ranked twenty-first on the BBC's poll of the 100 Greatest Britons following a UK-wide vote. In 2006, British writer and mathematician Ioan James chose Turing as one of twenty people to feature in his book about famous historical figures who may have had some of the traits of Asperger syndrome. In 2010, actor/playwright Jade Esteban Estrada portrayed Turing in the solo musical, "ICONS: The Lesbian and Gay History of the World, Vol. 4". In 2011, in "The Guardian"s "My hero" series, writer Alan Garner chose Turing as his hero and described how they had met while out jogging in the early 1950s. Garner remembered Turing as "funny and witty" and said that he "talked endlessly". In 2006, Alan Turing was named with online resources as an LGBT History Month Icon. In 2006, Boston Pride named Turing their Honorary Grand Marshal.

The logo of Apple Inc. is often erroneously referred to as a tribute to Alan Turing, with the bite mark a reference to his death. Both the designer of the logo and the company deny that there is any homage to Turing in the design. Stephen Fry has recounted asking Steve Jobs whether the design was intentional, saying that Jobs' response was, "God, we wish it were." In February 2011, Turing's papers from the Second World War were bought for the nation with an 11th-hour bid by the National Heritage Memorial Fund, allowing them to stay at Bletchley Park.

In 2012, Turing was inducted into the Legacy Walk, an outdoor public display that celebrates LGBT history and people.

The song "Alan et la Pomme", by francophone singer-songwriter Salvatore Adamo, is a tribute to Turing. Turing's life and work featured in a BBC children's programme about famous scientists,"Absolute Genius with Dick and Dom", first broadcast on 12 March 2014.

On 17 May 2014, the world's first work of public art to recognise Alan Turing as gay was commissioned in Bletchley, close by to Bletchley Park where his war-time work was carried out. The commission was announced to mark International Day Against Homophobia and Transphobia.
The work was unveiled at a ceremony on Turing's birthday, 23 June 2014, and is placed alongside busy Watling Street, the old main road to London, where Turing himself would have passed by on many occasions. On 22 October 2014, Turing was inducted into the NSA Hall of Honor.

To mark the 100th anniversary of Turing's birth, the Turing Centenary Advisory Committee (TCAC) co-ordinated the Alan Turing Year, a year-long programme of events around the world honouring Turing's life and achievements. The TCAC, chaired by S. Barry Cooper with Alan Turing's nephew Sir John Dermot Turing acting as Honorary President, worked with the University of Manchester faculty members and a broad spectrum of people from Cambridge University and Bletchley Park.

On 23 June 2012, Google featured an interactive doodle where visitors had to change the instructions of a Turing Machine, so when run, the symbols on the tape would match a provided sequence, featuring "Google" in Baudot-Murray code.

The Bletchley Park Trust collaborated with Winning Moves to publish an Alan Turing edition of the board game Monopoly. The game's squares and cards have been revised to tell the story of Alan Turing's life, from his birthplace in Maida Vale to Hut 8 at Bletchley Park. The game also includes a replica of an original hand-drawn board created by William Newman, son of Turing's mentor, Max Newman, which Turing played on in the 1950s.

In the Philippines, the Department of Philosophy at De La Salle University-Manila hosted Turing 2012, an international conference on philosophy, artificial intelligence, and cognitive science from 27 to 28 March 2012 to commemorate the centenary birth of Turing. Madurai, India held celebrations with a programme attended by 6,000 students.
There was a three-day conference in Manchester in June, the Alan Turing Centenary Conference, a two-day conference in San Francisco, organised by the ACM, and a birthday party and Turing Centenary Conference in Cambridge organised at King's College, Cambridge, and the University of Cambridge, the latter organised by the association Computability in Europe.

The Science Museum in London launched a free exhibition devoted to Turing's life and achievements in June 2012, to run until July 2013. In February 2012, the Royal Mail issued a stamp featuring Turing as part of its "Britons of Distinction" series. The London 2012 Olympic Torch flame was passed on in front of Turing's statue in Sackville Gardens, Manchester, on the evening of 23 June 2012, the 100th anniversary of his birth.

On 22 June 2012 Manchester City Council, in partnership with the Lesbian and Gay Foundation, launched the Alan Turing Memorial Award, which will recognise individuals or groups who have made a significant contribution to the fight against homophobia in Manchester.

At the University of Oxford, a new course in Computer Science and Philosophy was established to coincide with the centenary of Turing's birth.

Previous events have included a celebration of Turing's life and achievements, at the University of Manchester, arranged by the British Logic Colloquium and the British Society for the History of Mathematics on 5 June 2004.











</doc>
<doc id="1209" url="https://en.wikipedia.org/wiki?curid=1209" title="Area">
Area

Area is the quantity that expresses the extent of a two-dimensional figure or shape, or planar lamina, in the plane. Surface area is its analog on the two-dimensional surface of a three-dimensional object. Area can be understood as the amount of material with a given thickness that would be necessary to fashion a model of the shape, or the amount of paint necessary to cover the surface with a single coat. It is the two-dimensional analog of the length of a curve (a one-dimensional concept) or the volume of a solid (a three-dimensional concept).

The area of a shape can be measured by comparing the shape to squares of a fixed size. In the International System of Units (SI), the standard unit of area is the square metre (written as m), which is the area of a square whose sides are one metre long. A shape with an area of three square metres would have the same area as three such squares. In mathematics, the unit square is defined to have area one, and the area of any other shape or surface is a dimensionless real number.

There are several well-known formulas for the areas of simple shapes such as triangles, rectangles, and circles. Using these formulas, the area of any polygon can be found by dividing the polygon into triangles. For shapes with curved boundary, calculus is usually required to compute the area. Indeed, the problem of determining the area of plane figures was a major motivation for the historical development of calculus.

For a solid shape such as a sphere, cone, or cylinder, the area of its boundary surface is called the surface area. Formulas for the surface areas of simple shapes were computed by the ancient Greeks, but computing the surface area of a more complicated shape usually requires multivariable calculus.

Area plays an important role in modern mathematics. In addition to its obvious importance in geometry and calculus, area is related to the definition of determinants in linear algebra, and is a basic property of surfaces in differential geometry. In analysis, the area of a subset of the plane is defined using Lebesgue measure, though not every subset is measurable. In general, area in higher mathematics is seen as a special case of volume for two-dimensional regions.

Area can be defined through the use of axioms, defining it as a function of a collection of certain plane figures to the set of real numbers. It can be proved that such a function exists.

An approach to defining what is meant by "area" is through axioms. "Area" can be defined as a function from a collection M of special kind of plane figures (termed measurable sets) to the set of real numbers which satisfies the following properties:

It can be proved that such an area function actually exists.

Every unit of length has a corresponding unit of area, namely the area of a square with the given side length. Thus areas can be measured in square metres (m), square centimetres (cm), square millimetres (mm), square kilometres (km), square feet (ft), square yards (yd), square miles (mi), and so forth. Algebraically, these units can be thought of as the squares of the corresponding length units.

The SI unit of area is the square metre, which is considered an SI derived unit.

Calculation of the area of a square whose length and width are 1 metre would be:

1 metre x 1 metre = 1 m

and so, a rectangle with different sides (say length of 3 metres and width of 2 metres) would have an area in square units that can be calculated as:

3 metres x 2 metres = 6 m. This is equivalent to 6 million square millimetres. Other useful conversions are:

In non-metric units, the conversion between two square units is the square of the conversion between the corresponding length units.
the relationship between square feet and square inches is
where 144 = 12 = 12 × 12. Similarly:
In addition, conversion factors include:

There are several other common units for area. The "Are" was the original unit of area in the metric system, with;
Though the are has fallen out of use, the hectare is still commonly used to measure land:
Other uncommon metric units of area include the tetrad, the hectad, and the myriad.

The acre is also commonly used to measure land areas, where
An acre is approximately 40% of a hectare.

On the atomic scale, area is measured in units of barns, such that:
The barn is commonly used in describing the cross sectional area of interaction in nuclear physics.

In India,

In the 5th century BCE, Hippocrates of Chios was the first to show that the area of a disk (the region enclosed by a circle) is proportional to the square of its diameter, as part of his quadrature of the lune of Hippocrates, but did not identify the constant of proportionality. Eudoxus of Cnidus, also in the 5th century BCE, also found that the area of a disk is proportional to its radius squared.

Subsequently, Book I of Euclid's "Elements" dealt with equality of areas between two-dimensional figures. The mathematician Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book "Measurement of a Circle". (The circumference is 2"r", and the area of a triangle is half the base times the height, yielding the area "r" for the disk.) Archimedes approximated the value of π (and hence the area of a unit-radius circle) with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle (and did the same with circumscribed polygons).

Swiss scientist Johann Heinrich Lambert in 1761 proved that π, the ratio of a circle's area to its squared radius, is irrational, meaning it is not equal to the quotient of any two whole numbers. In 1794 French mathematician Adrien-Marie Legendre proved that π is irrational; this also proves that π is irrational. In 1882, German mathematician Ferdinand von Lindemann proved that π is transcendental (not the solution of any polynomial equation with rational coefficients), confirming a conjecture made by both Legendre and Euler.

Heron (or Hero) of Alexandria found what is known as Heron's formula for the area of a triangle in terms of its sides, and a proof can be found in his book, "Metrica", written around 60 CE. It has been suggested that Archimedes knew the formula over two centuries earlier, and since "Metrica" is a collection of the mathematical knowledge available in the ancient world, it is possible that the formula predates the reference given in that work.

In 499 Aryabhata, a great mathematician-astronomer from the classical age of Indian mathematics and Indian astronomy, expressed the area of a triangle as one-half the base times the height in the "Aryabhatiya" (section 2.6).

A formula equivalent to Heron's was discovered by the Chinese independently of the Greeks. It was published in 1247 in "Shushu Jiuzhang" ("Mathematical Treatise in Nine Sections"), written by Qin Jiushao.

In the 7th century CE, Brahmagupta developed a formula, now known as Brahmagupta's formula, for the area of a cyclic quadrilateral (a quadrilateral inscribed in a circle) in terms of its sides. In 1842 the German mathematicians Carl Anton Bretschneider and Karl Georg Christian von Staudt independently found a formula, known as Bretschneider's formula, for the area of any quadrilateral.

The development of Cartesian coordinates by René Descartes in the 17th century allowed the development of the surveyor's formula for the area of any polygon with known vertex locations by Gauss in the 19th century.

The development of integral calculus in the late 17th century provided tools that could subsequently be used for computing more complicated areas, such as the area of an ellipse and the surface areas of various curved three-dimensional objects.

For a non-self-intersecting (simple) polygon, the Cartesian coordinates formula_1 ("i"=0, 1, ..., "n"-1) of whose "n" vertices are known, the area is given by the surveyor's formula:

where when "i"="n"-1, then "i"+1 is expressed as modulus "n" and so refers to 0.

The most basic area formula is the formula for the area of a rectangle. Given a rectangle with length and width , the formula for the area is:

That is, the area of the rectangle is the length multiplied by the width. As a special case, as in the case of a square, the area of a square with side length is given by the formula:

The formula for the area of a rectangle follows directly from the basic properties of area, and is sometimes taken as a definition or axiom. On the other hand, if geometry is developed before arithmetic, this formula can be used to define multiplication of real numbers.

Most other simple formulas for area follow from the method of dissection.
This involves cutting a shape into pieces, whose areas must sum to the area of the original shape.

For an example, any parallelogram can be subdivided into a trapezoid and a right triangle, as shown in figure to the left. If the triangle is moved to the other side of the trapezoid, then the resulting figure is a rectangle. It follows that the area of the parallelogram is the same as the area of the rectangle:
However, the same parallelogram can also be cut along a diagonal into two congruent triangles, as shown in the figure to the right. It follows that the area of each triangle is half the area of the parallelogram:
Similar arguments can be used to find area formulas for the trapezoid as well as more complicated polygons.

The formula for the area of a circle (more properly called the area enclosed by a circle or the area of a disk) is based on a similar method. Given a circle of radius , it is possible to partition the circle into sectors, as shown in the figure to the right. Each sector is approximately triangular in shape, and the sectors can be rearranged to form an approximate parallelogram. The height of this parallelogram is , and the width is half the circumference of the circle, or . Thus, the total area of the circle is :
Though the dissection used in this formula is only approximate, the error becomes smaller and smaller as the circle is partitioned into more and more sectors. The limit of the areas of the approximate parallelograms is exactly , which is the area of the circle.

This argument is actually a simple application of the ideas of calculus. In ancient times, the method of exhaustion was used in a similar way to find the area of the circle, and this method is now recognized as a precursor to integral calculus. Using modern methods, the area of a circle can be computed using a definite integral:

The formula for the area enclosed by an ellipse is related to the formula of a circle; for an ellipse with semi-major and semi-minor axes and the formula is:

Most basic formulas for surface area can be obtained by cutting surfaces and flattening them out. For example, if the side surface of a cylinder (or any prism) is cut lengthwise, the surface can be flattened out into a rectangle. Similarly, if a cut is made along the side of a cone, the side surface can be flattened out into a sector of a circle, and the resulting area computed.

The formula for the surface area of a sphere is more difficult to derive: because a sphere has nonzero Gaussian curvature, it cannot be flattened out. The formula for the surface area of a sphere was first obtained by Archimedes in his work "On the Sphere and Cylinder". The formula is:
where is the radius of the sphere. As with the formula for the area of a circle, any derivation of this formula inherently uses methods similar to calculus.


(see Green's theorem) or the "z"-component of

To find the bounded area between two quadratic functions, we subtract one from the other to write the difference as
where "f"("x") is the quadratic upper bound and "g"("x") is the quadratic lower bound. Define the discriminant of "f"("x")-"g"("x") as
By simplifying the integral formula between the graphs of two functions (as given in the section above) and using Vieta's formula, we can obtain
The above remains valid if one of the bounding functions is linear instead of quadratic.


The general formula for the surface area of the graph of a continuously differentiable function formula_35 where formula_36 and formula_37 is a region in the xy-plane with the smooth boundary:
An even more general formula for the area of the graph of a parametric surface in the vector form formula_39 where formula_40 is a continuously differentiable vector function of formula_41 is:

The above calculations show how to find the areas of many common shapes.

The areas of irregular polygons can be calculated using the "Surveyor's formula".

The isoperimetric inequality states that, for a closed curve of length "L" (so the region it encloses has perimeter "L") and for area "A" of the region that it encloses,

and equality holds if and only if the curve is a circle. Thus a circle has the largest area of any closed figure with a given perimeter.

At the other extreme, a figure with given perimeter "L" could have an arbitrarily small area, as illustrated by a rhombus that is "tipped over" arbitrarily far so that two of its angles are arbitrarily close to 0° and the other two are arbitrarily close to 180°.

For a circle, the ratio of the area to the circumference (the term for the perimeter of a circle) equals half the radius "r". This can be seen from the area formula "πr" and the circumference formula 2"πr".

The area of a regular polygon is half its perimeter times the apothem (where the apothem is the distance from the center to the nearest point on any side).

Doubling the edge lengths of a polygon multiplies its area by four, which is two (the ratio of the new to the old side length) raised to the power of two (the dimension of the space the polygon resides in). But if the one-dimensional lengths of a fractal drawn in two dimensions are all doubled, the spatial content of the fractal scales by a power of two that is not necessarily an integer. This power is called the fractal dimension of the fractal.
There are an infinitude of lines that bisect the area of a triangle. Three of them are the medians of the triangle (which connect the sides' midpoints with the opposite vertices), and these are concurrent at the triangle's centroid; indeed, they are the only area bisectors that go through the centroid. Any line through a triangle that splits both the triangle's area and its perimeter in half goes through the triangle's incenter (the center of its incircle). There are either one, two, or three of these for any given triangle.

Any line through the midpoint of a parallelogram bisects the area.

All area bisectors of a circle or other ellipse go through the center, and any chords through the center bisect the area. In the case of a circle they are the diameters of the circle.

Given a wire contour, the surface of least area spanning ("filling") it is a minimal surface. Familiar examples include soap bubbles.

The question of the filling area of the Riemannian circle remains open.

The circle has the largest area of any two-dimensional object having the same perimeter.

A cyclic polygon (one inscribed in a circle) has the largest area of any polygon with a given number of sides of the same lengths.

A version of the isoperimetric inequality for triangles states that the triangle of greatest area among all those with a given perimeter is equilateral.

The triangle of largest area of all those inscribed in a given circle is equilateral; and the triangle of smallest area of all those circumscribed around a given circle is equilateral.

The ratio of the area of the incircle to the area of an equilateral triangle, formula_44, is larger than that of any non-equilateral triangle.

The ratio of the area to the square of the perimeter of an equilateral triangle, formula_45 is larger than that for any other triangle.



</doc>
<doc id="1210" url="https://en.wikipedia.org/wiki?curid=1210" title="Astronomical unit">
Astronomical unit

The astronomical unit (symbol: au, ua, or AU) is a unit of length, roughly the distance from Earth to the Sun. However, that distance varies as Earth orbits the Sun, from a maximum (aphelion) to a minimum (perihelion) and back again once a year. Originally conceived as the average of Earth's aphelion and perihelion, it was defined exactly as metres or about since 2012. The astronomical unit is used primarily for measuring distances within the Solar System or around other stars. However, it is also a fundamental component in the definition of another unit of astronomical length, the parsec.

A variety of unit symbols and abbreviations have been in use for the astronomical unit. In a 1976 resolution, the International Astronomical Union (IAU) used the symbol "A" for the astronomical unit. In the astronomical literature, the symbol AU was (and remains) common. In 2006, the International Bureau of Weights and Measures (BIPM) recommended ua as the symbol for the unit. In the non-normative Annex C to ISO 80000-3 (2006), the symbol of the astronomical unit is "ua". In 2012, the IAU, noting "that various symbols are presently in use for the astronomical unit", recommended the use of the symbol "au". In the 2014 revision of the SI Brochure, the BIPM used the unit symbol "au".

Earth's orbit around the Sun is an ellipse. The semi-major axis of this elliptic orbit is defined to be half of the straight line segment that joins the perihelion and aphelion. The centre of the Sun lies on this straight line segment, but not at its midpoint. Because ellipses are well-understood shapes, measuring the points of its extremes defined the exact shape mathematically, and made possible calculations for the entire orbit as well as predictions based on observation. In addition, it mapped out exactly the largest straight-line distance that Earth traverses over the course of a year, defining times and places for observing the largest parallax (apparent shifts of position) in nearby stars. Knowing Earth's shift and a star's shift enabled the star's distance to be calculated. But all measurements are subject to some degree of error or uncertainty, and the uncertainties in the length of the astronomical unit only increased uncertainties in the stellar distances. Improvements in precision have always been a key to improving astronomical understanding. Throughout the twentieth century, measurements became increasingly precise and sophisticated, and ever more dependent on accurate observation of the effects described by Einstein's theory of relativity and upon the mathematical tools it used.

Improving measurements were continually checked and cross-checked by means of improved understanding of the laws of celestial mechanics, which govern the motions of objects in space. The expected positions and distances of objects at an established time are calculated (in AU) from these laws, and assembled into a collection of data called an ephemeris. NASA Jet Propulsion Laboratory HORIZONS System provides one of several ephemeris computation services.

In 1976, in order to establish a yet more precise measure for the astronomical unit, the IAU formally adopted a new definition. Although directly based on the then-best available observational measurements, the definition was recast in terms of the then-best mathematical derivations from celestial mechanics and planetary ephemerides. It stated that "the astronomical unit of length is that length ("A") for which the Gaussian gravitational constant ("k") takes the value when the units of measurement are the astronomical units of length, mass and time". Equivalently, by this definition, one AU is "the radius of an unperturbed circular Newtonian orbit about the sun of a particle having infinitesimal mass, moving with an angular frequency of "; or alternatively that length for which the heliocentric gravitational constant (the product "G") is equal to () AU/d, when the length is used to describe the positions of objects in the Solar System.

Subsequent explorations of the Solar System by space probes made it possible to obtain precise measurements of the relative positions of the inner planets and other objects by means of radar and telemetry. As with all radar measurements, these rely on measuring the time taken for photons to be reflected from an object. Because all photons move at the speed of light in vacuum, a fundamental constant of the universe, the distance of an object from the probe is calculated as the product of the speed of light and the measured time. However, for precision the calculations require adjustment for things such as the motions of the probe and object while the photons are transiting. In addition, the measurement of the time itself must be translated to a standard scale that accounts for relativistic time dilation. Comparison of the ephemeris positions with time measurements expressed in the TDB scale leads to a value for the speed of light in astronomical units per day (of ). By 2009, the IAU had updated its standard measures to reflect improvements, and calculated the speed of light at (TDB).

In 1983, the International Committee for Weights and Measures (CIPM) modified the International System of Units (SI, or "modern" metric system) to make the metre independent of physical objects entirely, because other measurements had become too precise for reference to the prototype platinum metre to remain useful. Instead, the metre was redefined in terms of the speed of light in vacuum, which could be independently determined at need. The speed of light could then be expressed exactly as "c" = , a standard also adopted by the IERS numerical standards. From this definition and the 2009 IAU standard, the time for light to traverse an AU is found to be τ = , more than 8 minutes. By multiplication, the best IAU 2009 estimate was "A" = "c"τ = , based on a comparison of JPL and IAA–RAS ephemerides.

In 2006, the BIPM reported a value of the astronomical unit as . In the 2014 revision of the SI Brochure, the BIPM recognised the IAU's 2012 redefinition of the astronomical unit as . or an increase of 9 meters.

This estimate was still derived from observation and measurements subject to error, and based on techniques that did not yet standardize all relativistic effects, and thus were not constant for all observers. In 2012, finding that the equalization of relativity alone would make the definition overly complex, the IAU simply used the 2009 estimate to redefine the astronomical unit as a conventional unit of length directly tied to the metre (exactly ). The new definition also recognizes as a consequence that the astronomical unit is now to play a role of reduced importance, limited in its use to that of a convenience in some applications.

This definition makes the speed of light, defined as exactly , equal to exactly  ×  ÷  or about AU/d, some 60 parts per trillion less than the 2009 estimate.

With the definitions used before 2012, the astronomical unit was dependent on the heliocentric gravitational constant, that is the product of the gravitational constant "G" and the solar mass . Neither "G" nor can be measured to high accuracy separately, but the value of their product is known very precisely from observing the relative positions of planets (Kepler's Third Law expressed in terms of Newtonian gravitation). Only the product is required to calculate planetary positions for an ephemeris, so ephemerides are calculated in astronomical units and not in SI units.

The calculation of ephemerides also requires a consideration of the effects of general relativity. In particular, time intervals measured on Earth's surface (terrestrial time, TT) are not constant when compared to the motions of the planets: the terrestrial second (TT) appears to be longer during the Northern Hemisphere winter and shorter during the Northern Hemisphere summer when compared to the "planetary second" (conventionally measured in barycentric dynamical time, TDB). This is because the distance between Earth and the Sun is not fixed (it varies between and ) and, when Earth is closer to the Sun (perihelion), the Sun's gravitational field is stronger and Earth is moving faster along its orbital path. As the metre is defined in terms of the second and the speed of light is constant for all observers, the terrestrial metre appears to change in length compared to the "planetary metre" on a periodic basis.

The metre is defined to be a unit of proper length, but the SI definition does not specify the metric tensor to be used in determining it. Indeed, the International Committee for Weights and Measures (CIPM) notes that "its definition applies only within a spatial extent sufficiently small that the effects of the non-uniformity of the gravitational field can be ignored". As such, the metre is undefined for the purposes of measuring distances within the Solar System. The 1976 definition of the astronomical unit was incomplete because it did not specify the frame of reference in which time is to be measured, but proved practical for the calculation of ephemerides: a fuller definition that is consistent with general relativity was proposed, and "vigorous debate" ensued until August 2012 when the IAU adopted the current definition of 1 astronomical unit = metres.

The astronomical unit is typically used for stellar system scale distances, such as the size of a protostellar disk or the heliocentric distance of an asteroid, whereas other units are used for other distances in astronomy. The astronomical unit is too small to be convenient for interstellar distances, where the parsec and light-year are widely used. The parsec (parallax arcsecond) is defined in terms of the astronomical unit, being the distance of an object with a parallax of 1 arcsecond. The light-year is often used in popular works, but is not an approved non-SI unit and is rarely used by professional astronomers.

When simulating a numerical model of the Solar System, the astronomical unit provides an appropriate scale that minimizes (overflow, underflow and truncation) errors in floating point calculations.

According to Archimedes in the "Sandreckoner" (2.1), Aristarchus of Samos estimated the distance to the Sun to be times Earth's radius (the true value is about ). However, the book "On the Sizes and Distances of the Sun and Moon", which has long been ascribed to Aristarchus, says that he calculated the distance to the Sun to be between 18 and 20 times the distance to the Moon, whereas the true ratio is about 389.174. The latter estimate was based on the angle between the half moon and the Sun, which he estimated as 87° (the true value being close to 89.853°). Depending on the distance that Van Helden assumes Aristarchus used for the distance to the Moon, his calculated distance to the Sun would fall between 380 and Earth radii.

According to Eusebius of Caesarea in the "Praeparatio Evangelica" (Book XV, Chapter 53), Eratosthenes found the distance to the Sun to be "σταδιων μυριαδας τετρακοσιας και οκτωκισμυριας" (literally "of "stadia" myriads 400 and ") but with the additional note that in the Greek text the grammatical agreement is between "myriads" (not "stadia") on the one hand and both "400" and "" on the other, as in Greek, unlike English, all three (or all four if one were to include "stadia") words are inflected. This has been translated either as "stadia" (1903 translation by Edwin Hamilton Gifford), or as "stadia" (edition of , dated 1974–1991). Using the Greek stadium of 185 to 190 metres, the former translation comes to to , which is far too low, whereas the second translation comes to 148.7 to 152.8 million kilometres (accurate within 2%). Hipparchus also gave an estimate of the distance of Earth from the Sun, quoted by Pappus as equal to 490 Earth radii. According to the conjectural reconstructions of Noel Swerdlow and G. J. Toomer, this was derived from his assumption of a "least perceptible" solar parallax of 7 arc minutes.

A Chinese mathematical treatise, the "Zhoubi Suanjing" (c. 1st century BCE), shows how the distance to the Sun can be computed geometrically, using the different lengths of the noontime shadows observed at three places li apart and the assumption that Earth is flat.

In the 2nd century CE, Ptolemy estimated the mean distance of the Sun as times Earth's radius. To determine this value, Ptolemy started by measuring the Moon's parallax, finding what amounted to a horizontal lunar parallax of 1° 26′, which was much too large. He then derived a maximum lunar distance of 64 Earth radii. Because of cancelling errors in his parallax figure, his theory of the Moon's orbit, and other factors, this figure was approximately correct. He then measured the apparent sizes of the Sun and the Moon and concluded that the apparent diameter of the Sun was equal to the apparent diameter of the Moon at the Moon's greatest distance, and from records of lunar eclipses, he estimated this apparent diameter, as well as the apparent diameter of the shadow cone of Earth traversed by the Moon during a lunar eclipse. Given these data, the distance of the Sun from Earth can be trigonometrically computed to be Earth radii. This gives a ratio of solar to lunar distance of approximately 19, matching Aristarchus's figure. Although Ptolemy's procedure is theoretically workable, it is very sensitive to small changes in the data, so much so that changing a measurement by a few percent can make the solar distance infinite.

After Greek astronomy was transmitted to the medieval Islamic world, astronomers made some changes to Ptolemy's cosmological model, but did not greatly change his estimate of the Earth–Sun distance. For example, in his introduction to Ptolemaic astronomy, al-Farghānī gave a mean solar distance of Earth radii, whereas in his "zij", al-Battānī used a mean solar distance of Earth radii. Subsequent astronomers, such as al-Bīrūnī, used similar values. Later in Europe, Copernicus and Tycho Brahe also used comparable figures ( and Earth radii), and so Ptolemy's approximate Earth–Sun distance survived through the 16th century.

Johannes Kepler was the first to realize that Ptolemy's estimate must be significantly too low (according to Kepler, at least by a factor of three) in his "Rudolphine Tables" (1627). Kepler's laws of planetary motion allowed astronomers to calculate the relative distances of the planets from the Sun, and rekindled interest in measuring the absolute value for Earth (which could then be applied to the other planets). The invention of the telescope allowed far more accurate measurements of angles than is possible with the naked eye. Flemish astronomer Godefroy Wendelin repeated Aristarchus' measurements in 1635, and found that Ptolemy's value was too low by a factor of at least eleven.

A somewhat more accurate estimate can be obtained by observing the transit of Venus. By measuring the transit in two different locations, one can accurately calculate the parallax of Venus and from the relative distance of Earth and Venus from the Sun, the solar parallax "α" (which cannot be measured directly). Jeremiah Horrocks had attempted to produce an estimate based on his observation of the 1639 transit (published in 1662), giving a solar parallax of 15 arcseconds, similar to Wendelin's figure. The solar parallax is related to the Earth–Sun distance as measured in Earth radii by
The smaller the solar parallax, the greater the distance between the Sun and Earth: a solar parallax of 15" is equivalent to an Earth–Sun distance of Earth radii.

Christiaan Huygens believed that the distance was even greater: by comparing the apparent sizes of Venus and Mars, he estimated a value of about Earth radii, equivalent to a solar parallax of 8.6". Although Huygens' estimate is remarkably close to modern values, it is often discounted by historians of astronomy because of the many unproven (and incorrect) assumptions he had to make for his method to work; the accuracy of his value seems to be based more on luck than good measurement, with his various errors cancelling each other out.
Jean Richer and Giovanni Domenico Cassini measured the parallax of Mars between Paris and Cayenne in French Guiana when Mars was at its closest to Earth in 1672. They arrived at a figure for the solar parallax of 9", equivalent to an Earth–Sun distance of about Earth radii. They were also the first astronomers to have access to an accurate and reliable value for the radius of Earth, which had been measured by their colleague Jean Picard in 1669 as thousand "toises". Another colleague, Ole Rømer, discovered the finite speed of light in 1676: the speed was so great that it was usually quoted as the time required for light to travel from the Sun to the Earth, or "light time per unit distance", a convention that is still followed by astronomers today.

A better method for observing Venus transits was devised by James Gregory and published in his "Optica Promata" (1663). It was strongly advocated by Edmond Halley and was applied to the transits of Venus observed in 1761 and 1769, and then again in 1874 and 1882. Transits of Venus occur in pairs, but less than one pair every century, and observing the transits in 1761 and 1769 was an unprecedented international scientific operation. Despite the Seven Years' War, dozens of astronomers were dispatched to observing points around the world at great expense and personal danger: several of them died in the endeavour. The various results were collated by Jérôme Lalande to give a figure for the solar parallax of 8.6″.
Another method involved determining the constant of aberration. Simon Newcomb gave great weight to this method when deriving his widely accepted value of 8.80″ for the solar parallax (close to the modern value of ″), although Newcomb also used data from the transits of Venus. Newcomb also collaborated with A. A. Michelson to measure the speed of light with Earth-based equipment; combined with the constant of aberration (which is related to the light time per unit distance), this gave the first direct measurement of the Earth–Sun distance in kilometres. Newcomb's value for the solar parallax (and for the constant of aberration and the Gaussian gravitational constant) were incorporated into the first international system of astronomical constants in 1896, which remained in place for the calculation of ephemerides until 1964. The name "astronomical unit" appears first to have been used in 1903.

The discovery of the near-Earth asteroid 433 Eros and its passage near Earth in 1900–1901 allowed a considerable improvement in parallax measurement. Another international project to measure the parallax of 433 Eros was undertaken in 1930–1931.

Direct radar measurements of the distances to Venus and Mars became available in the early 1960s. Along with improved measurements of the speed of light, these showed that Newcomb's values for the solar parallax and the constant of aberration were inconsistent with one another.

The unit distance "A" (the value of the astronomical unit in metres) can be expressed in terms of other astronomical constants:
where "G" is the Newtonian gravitational constant, is the solar mass, "k" is the numerical value of Gaussian gravitational constant and "D" is the time period of one day.
The Sun is constantly losing mass by radiating away energy, so the orbits of the planets are steadily expanding outward from the Sun. This has led to calls to abandon the astronomical unit as a unit of measurement.

As the speed of light has an exact defined value in SI units and the Gaussian gravitational constant "k" is fixed in the astronomical system of units, measuring the light time per unit distance is exactly equivalent to measuring the product "G" in SI units. Hence, it is possible to construct ephemerides entirely in SI units, which is increasingly becoming the norm.

A 2004 analysis of radiometric measurements in the inner Solar System suggested that the secular increase in the unit distance was much larger than can be accounted for by solar radiation, + metres per century.

The measurements of the secular variations of the astronomical unit are not confirmed by other authors and are quite controversial.
Furthermore, since 2010, the astronomical unit has not been estimated by the planetary ephemerides.

The following table contains some distances given in astronomical units. It includes some examples with distances that are normally not given in astronomical units, because they are either too short or far too long. Distances normally change over time. Examples are listed by increasing distance.




</doc>
<doc id="1212" url="https://en.wikipedia.org/wiki?curid=1212" title="Artist">
Artist

An artist is a person engaged in an activity related to creating art, practicing the arts, or demonstrating an art. The common usage in both everyday speech and academic discourse is a practitioner in the visual arts only. The term is often used in the entertainment business, especially in a business context, for musicians and other performers (less often for actors). "Artiste" (the French for artist) is a variant used in English only in this context. Use of the term to describe writers, for example, is valid, but less common, and mostly restricted to contexts like criticism.

Wiktionary defines the noun 'artist' (Singular: artist; Plural: artists) as follows:
The Oxford English Dictionary defines the older broad meanings of the term "artist":


The Greek word "techně", often translated as "art," implies mastery of any sort of craft. The adjectival Latin form of the word, "technicus",
became the source of the English words technique, technology, technical.

In Greek culture each of the nine Muses oversaw a different field of human creation:

No muse was identified with the visual arts of painting and sculpture. In ancient Greece sculptors and painters were held in low regard, somewhere between freemen and slaves, their work regarded as mere manual labour.

The word "art" derives from the Latin "ars" (stem "art-"), which, although literally defined, means "skill method" or "technique", and conveys a connotation of beauty.

During the Middle Ages the word "artist" already existed in some countries such as Italy, but the meaning was something resembling "craftsman", while the word "artesan" was still unknown. An artist was someone able to do a work better than others, so the skilled excellency was underlined, rather than the activity field. In this period some "artisanal" products (such as textiles) were much more precious and expensive than paintings or sculptures.

The first division into major and minor arts dates back at least to the works of Leon Battista Alberti (1404–1472): "De re aedificatoria, De statua, De pictura", which focused on the importance of the intellectual skills of the artist rather than the manual skills (even if in other forms of art there was a project behind).

With the Academies in Europe (second half of 16th century) the gap between fine and applied arts was definitely set.

Many contemporary definitions of "artist" and "art" are highly contingent on culture, resisting aesthetic prescription, in much the same way that the features constituting beauty and the beautiful cannot be standardized easily without corruption into kitsch.

"Artist" is a descriptive term applied to a person who engages in an activity deemed to be an art. An artist also may be defined unofficially as "a person who expresses him- or herself through a medium". The word is also used in a qualitative sense of, a person creative in, innovative in, or adept at, an artistic practice.

Most often, the term describes those who create within a context of the fine arts or 'high culture', activities such as drawing, painting, sculpture, acting, dancing, writing, filmmaking, new media, photography, and music—people who use imagination, talent, or skill to create works that may be judged to have an aesthetic value. Art historians and critics define artists as those who produce art within a recognized or recognizable discipline. Contrasting terms for highly skilled workers in media in the applied arts or decorative arts include artisan, craftsman, and specialized terms such as potter, goldsmith or glassblower. Fine arts artists such as painters succeeded in the Renaissance in raising their status, formerly similar to these workers, to a decisively higher level, but in the 20th century the distinction became rather less relevant .

The term may also be used loosely or metaphorically to denote highly skilled people in any non-"art" activities, as well— law, medicine, mechanics, or mathematics, for example.

Often, discussions on the subject focus on the differences among "artist" and "technician", "entertainer" and "artisan", "fine art" and "applied art", or what constitutes art and what does not. The French word "artiste" (which in French, simply means "artist") has been imported into the English language where it means a performer (frequently in Music Hall or Vaudeville). Use of the word "artiste" can also be a pejorative term.

The English word 'artiste' has thus a narrower range of meaning than the word 'artiste' in French.

In "Living with Art", Mark Getlein proposes six activities, services or functions of contemporary artists:

After looking at years of data on arts school graduates as well as policies & program outcomes regarding artists, arts, & culture, Elizabeth Lingo and Steven Tepper propose the divide between "arts for art's sake" artists and commercially successful artists is not as wide as may be perceived, and that "this bifurcation between the commercial and the noncommercial, the excellent and the base, the elite and the popular, is increasingly breaking down" (Eikhof & Haunschild, 2007). Lingo and Tepper point out:

The US Bureau of Labor Statistics classifies many visual artists as either "craft artists" or "fine artists". A craft artist makes handmade functional works of art, such as pottery or clothing. A fine artist makes paintings, illustrations (such as book illustrations or medical illustrations), sculptures, or similar artistic works primarily for their aesthetic value.

The main source of skill for both craft artists and fine artists is long-term repetition and practice. Many fine artists have studied their art form at university and some have a master's degree in fine arts. Artists may also study on their own or receive on-the-job training from an experienced artist.

The number of available jobs as an artist is increasing more slowly than other fields. About half of US artists are self-employed. Others work in a variety of industries. For example, a pottery manufacturer will employ craft artists, and book publishers will hire illustrators.

In the US, fine artists have a median income of approximately US $50,000 per year, and craft artists have a median income of approximately US $33,000 per year. This compares to US $61,000 for all art-related fields, including related jobs such as graphic designers, multimedia artists, animators, and fashion designers. Many artists work part-time as artists and hold a second job!




</doc>
<doc id="1213" url="https://en.wikipedia.org/wiki?curid=1213" title="Actaeon">
Actaeon

Actaeon (; "Aktaion"), in Greek mythology, son of the priestly herdsman Aristaeus and Autonoe in Boeotia, was a famous Theban hero. Like Achilles in a later generation, he was trained by the centaur Chiron.

He fell to the fatal wrath of Artemis, but the surviving details of his transgression vary: "the only certainty is in what Aktaion suffered, his pathos, and what Artemis did: the hunter became the hunted; he was transformed into a stag, and his raging hounds, struck with a 'wolf's frenzy' (Lyssa), tore him apart as they would a stag." This is the iconic motif by which Actaeon is recognized, both in ancient art and in Renaissance and post-Renaissance depictions.

Among others, John Heath has observed, "The unalterable kernel of the tale was a hunter's transformation into a deer and his death in the jaws of his hunting dogs. But authors were free to suggest different motives for his death." In the version that was offered by the Hellenistic poet Callimachus, which has become the standard setting, Artemis was bathing in the woods when the hunter Actaeon stumbled across her, thus seeing her naked. He stopped and stared, amazed at her ravishing beauty. Once seen, Artemis got revenge on Actaeon: she forbade him speech — if he tried to speak, he would be changed into a stag — for the unlucky profanation of her virginity's mystery. Upon hearing the call of his hunting party, he cried out to them and immediately transformed. At this he fled deep into the woods, and doing so he came upon a pond and, seeing his reflection, groaned. His own hounds then turned upon him and pursued him, not recognizing him. In an endeavour to save himself, he raised his eyes (and would have raised his arms, had he had them) toward Mount Olympus. The gods did not heed his plea, and he was torn to pieces. An element of the earlier myth made Actaeon the familiar hunting companion of Artemis, no stranger. In an embroidered extension of the myth, the hounds were so upset with their master's death, that Chiron made a statue so lifelike that the hounds thought it was Actaeon.

There are various other versions of his transgression: The Hesiodic "Catalogue of Women" and pseudo-Apollodoran "Bibliotheke" state that his offense was that he was a rival of Zeus for Semele, his mother's sister, whereas in Euripides' "Bacchae" he has boasted that he is a better hunter than Artemis:
Further materials, including fragments that belong with the Hesiodic "Catalogue of Women" and at least four Attic tragedies, including a "Toxotides" of Aeschylus, have been lost. Diodorus Siculus (4.81.4), in a variant of Actaeon's "hubris" that has been largely ignored, has it that Actaeon wanted to marry Artemis. Other authors say the hounds were Artemis' own; some lost elaborations of the myth seem to have given them all names and narrated their wanderings after his loss.

According to the Latin version of the story told by the Roman Ovid having accidentally seen Diana (Artemis) on Mount Cithaeron while she was bathing, he was changed by her into a stag, and pursued and killed by his fifty hounds. This version also appears in Callimachus' Fifth Hymn, as a mythical parallel to the blinding of Tiresias after he sees Athena bathing.

The literary testimony of Actaeon's myth is largely lost, but Lamar Ronald Lacy, deconstructing the myth elements in what survives and supplementing it by iconographic evidence in late vase-painting, made a plausible reconstruction of an ancient Actaeon myth that Greek poets may have inherited and subjected to expansion and dismemberment. His reconstruction opposes a too-pat consensus that has an archaic Actaeon aspiring to Semele, a classical Actaeon boasting of his hunting prowess and a Hellenistic Actaeon glimpsing Artemis' bath. Lacy identifies the site of Actaeon's transgression as a spring sacred to Artemis at Plataea where Actaeon was a " hero archegetes" ("hero-founder") The righteous hunter, the companion of Artemis, seeing her bathing naked in the spring, was moved to try to make himself her consort, as Diodorus Siculus noted, and was punished, in part for transgressing the hunter's "ritually enforced deference to Artemis" (Lacy 1990:42).

The following list is as given in Hyginus' "Fabulae". The first part of the list is taken from Ovid's "Metamorphoses" (Book III, 206–235), and the second from an unknown source.

"Note:" In the first part of the list, Hyginus fails to correctly differentiate between masculine and feminine names.

Dogs: Melampus, Ichnobates, Pamphagos, Dorceus, Oribasos, Nebrophonos, Laelaps, Theron, Pterelas, Hylaeus, Ladon, Dromas, Tigris, Leucon, Asbolos, Lacon, Aello, Thoos, Harpalos, Melaneus, Labros, Arcas, Argiodus, Hylactor.

Bitches: Agre, Nape, Poemenis, Harpyia, Canache, Sticte, Alce, Lycisce, Lachne, Melanchaetes, Therodamas, Oresitrophos.

Dogs: Acamas, Syrus, Leon, Stilbon, Agrius, Charops, Aethon, Corus, Boreas, Draco, Eudromus, Dromius, Zephyrus, Lampus, Haemon, Cyllopodes, Harpalicus, Machimus, Ichneus, Melampus, Ocydromus, Borax, Ocythous, Pachylus, Obrimus;

Bitches: Argo, Arethusa, Urania, Theriope, Dinomache, Dioxippe, Echione, Gorgo, Cyllo, Harpyia, Lynceste, Leaena, Lacaena, Ocypete, Ocydrome, Oxyrhoe, Orias, *Sagnos, Theriphone, *Volatos, *Chediaetros.

In the second century AD, the traveller Pausanias was shown a spring on the road in Attica leading to Plataea from Eleutherae, just beyond Megara "and a little farther on a rock. It is called the bed of Actaeon, for it is said that he slept thereon when weary with hunting and that into this spring he looked while Artemis was bathing in it."

In the standard version of the "Epic of Gilgamesh" (tablet vi) there is a parallel, in the series of examples Gilgamesh gives Ishtar of her mistreatment of her serial lovers:
"You loved the herdsman, shepherd and chief shepherd<br> Who was always heaping up the glowing ashes for you,<br> And cooked ewe-lambs for you every day.<br> But you hit him and turned him into a wolf,<br> His own herd-boys hunt him down<br>
And his dogs tear at his haunches.<br><nowiki>"</nowiki>Actaeon, torn apart by dogs incited by Artemis, finds another Near Eastern parallel in the Ugaritic hero Aqht, torn apart by eagles incited by Anath who wanted his hunting bow.

The virginal Artemis of classical times is not directly comparable to Ishtar of the many lovers, but the mytheme of Artemis shooting Orion, was linked to her punishment of Actaeon by T.C.W. Stinton; the Greek context of the mortal's reproach to the amorous goddess is translated to the episode of Anchises and Aphrodite. Daphnis too was a herdsman loved by a goddess and punished by her: see Theocritus' First Idyll.

In Greek Mythology, Actaeon is thought by many, including Hans Biedermann, to symbolize ritual human sacrifice in attempt to please a God or Goddess. In the case of Actaeon, the dogs symbolize the sacrificers and Actaeon symbolizes the sacrifice. Actaeon also may symbolize a human curiosity or irreverence.

The myth is seen by Jungian psychologist Wolfgang Giegerich as a symbol of spiritual transformation and/or enlightenment.

The two main scenes are Actaeon surprising Artemis/Diana, and his death. In classical art Actaeon is normally shown as fully human, even as his hounds are killing him (sometimes he has small horns), but in Renaissance art he is often given a deer's head with antlers even in the scene with Diana, and by the time he is killed he has at the least this head, and has often completely transformed into the shape of a deer. 






</doc>
<doc id="1214" url="https://en.wikipedia.org/wiki?curid=1214" title="Anglicanism">
Anglicanism

Anglicanism is a Western Christian tradition that evolved out of the practices, liturgy and identity of the Church of England following the Protestant Reformation.

Adherents of Anglicanism are called "Anglicans". The majority of Anglicans are members of national or regional ecclesiastical provinces of the international Anglican Communion, which forms the third-largest Christian communion in the world, after the Roman Catholic Church and the Eastern Orthodox Church. They are in full communion with the See of Canterbury, and thus the Archbishop of Canterbury, whom the communion refers to as its "primus inter pares" (Latin, "first among equals"). He calls the decennial Lambeth Conference, chairs the meeting of primates, and the Anglican Consultative Council. Some churches that are not part of the Anglican Communion also consider themselves Anglican, including those that are part of the Continuing Anglican movement.

Anglicans base their Christian faith on the Bible, traditions of the apostolic Church, apostolic succession ("historic episcopate"), and writings of the Church Fathers. Anglicanism forms one of the branches of Western Christianity, having definitively declared its independence from the Holy See at the time of the Elizabethan Religious Settlement. Many of the new Anglican formularies of the mid-16th century corresponded closely to those of contemporary Protestantism. These reforms in the Church of England were understood by one of those most responsible for them, Thomas Cranmer, the Archbishop of Canterbury, as navigating a middle way between two of the emerging Protestant traditions, namely Lutheranism and Calvinism. By the end of the century, the retention in Anglicanism of many traditional liturgical forms and of the episcopate was already seen as unacceptable by those promoting the most developed Protestant principles.

In the first half of the 17th century, the Church of England and its associated Church of Ireland were presented by some Anglican divines as comprising a distinct Christian tradition, with theologies, structures, and forms of worship representing a different kind of middle way, or "via media", between Protestantism and Roman Catholicism – a perspective that came to be highly influential in later theories of Anglican identity and expressed in the description of Anglicanism as "Catholic and Reformed". The degree of distinction between Protestant and Catholic tendencies within the Anglican tradition is routinely a matter of debate both within specific Anglican churches and throughout the Anglican Communion. Unique to Anglicanism is the Book of Common Prayer, the collection of services that worshippers in most Anglican churches have used for centuries, and is thus acknowledged as one of the ties that bind the Anglican Communion together.

After the American Revolution, Anglican congregations in the United States and British North America (which would later form the basis for the modern country of Canada) were each reconstituted into autonomous churches with their own bishops and self-governing structures; these were known as the American Episcopal Church and the Church of England in the Dominion of Canada. Through the expansion of the British Empire and the activity of Christian missions, this model was adopted as the model for many newly formed churches, especially in Africa, Australasia, and Asia-Pacific. In the 19th century, the term "Anglicanism" was coined to describe the common religious tradition of these churches; as also that of the Scottish Episcopal Church, which, though originating earlier within the Church of Scotland, had come to be recognised as sharing this common identity.

The word "Anglican" originates in , a medieval Latin phrase dating to at least 1246 that means the "English Church". Adherents of Anglicanism are called "Anglicans". As an adjective, "Anglican" is used to describe the people, institutions and churches, as well as the liturgical traditions and theological concepts developed by the Church of England. As a noun, an Anglican is a member of a church in the Anglican Communion. The word is also used by followers of separated groups which have left the communion or have been founded separately from it, although this is sometimes considered as a misuse. The word "Anglicanism" came into being in the 19th century. The word originally referred only to the teachings and rites of Christians throughout the world in communion with the see of Canterbury, but has come to sometimes be extended to any church following those traditions rather than actual membership in the modern Anglican Communion.

Although the term "Anglican" is found referring to the Church of England as far back as the 16th century, its use did not become general until the latter half of the 19th century. In British parliamentary legislation referring to the English established church, there is no need for a description; it is simply the Church of England, though the word "Protestant" is used in many Acts specifying the succession to the Crown and qualifications for office. When the Union with Ireland Act created the United Church of England and Ireland, it is specified that it shall be one "Protestant Episcopal Church", thereby distinguishing its form of church government from the Presbyterian polity that prevails in the Church of Scotland.

The word "Episcopal" is preferred in the title of the Episcopal Church (the province of the Anglican Communion covering the United States) and the Scottish Episcopal Church, though the full name of the former is "The Protestant Episcopal Church of the United States of America". Elsewhere, however, the term "Anglican Church" came to be preferred as it distinguished these churches from others that maintain an episcopal polity.

Anglicanism, in its structures, theology and forms of worship, is commonly understood as a distinct Christian tradition representing a middle ground between what are perceived to be the extremes of the claims of 16th-century Roman Catholicism and the Lutheran and Reformed varieties of Protestantism of that era. As such, it is often referred to as being a "via media" (or "middle way") between these traditions.

The faith of Anglicans is founded in the Scriptures and the Gospels, the traditions of the Apostolic Church, the historical episcopate, the first four ecumenical councils, and the early Church Fathers (among these councils, especially the premier four ones, and among these Fathers, especially those active during the five initial centuries of Christianity, according to the "quinquasaecularist" principle proposed by the English bishop Lancelot Andrewes and the Lutheran dissident Georg Calixtus). Anglicans understand the Old and New Testaments as "containing all things necessary for salvation" and as being the rule and ultimate standard of faith. Reason and tradition are seen as valuable means to interpret scripture (a position first formulated in detail by Richard Hooker), but there is no full mutual agreement among Anglicans "exactly how" scripture, reason, and tradition interact (or ought to interact) with each other. Anglicans understand the Apostles' Creed as the baptismal symbol and the Nicene Creed as the sufficient statement of the Christian faith.

Anglicans believe the catholic and apostolic faith is revealed in Holy Scripture and the Catholic creeds and interpret these in light of the Christian tradition of the historic church, scholarship, reason and experience.

Anglicans celebrate the traditional sacraments, with special emphasis being given to the Eucharist, also called Holy Communion, the Lord's Supper or the Mass. The Eucharist is central to worship for most Anglicans as a communal offering of prayer and praise in which the life, death and resurrection of Jesus Christ are proclaimed through prayer, reading of the Bible, singing, giving God thanks over the bread and wine for the innumerable benefits obtained through the passion of Christ, the breaking of the bread, and reception of the bread and wine as representing the body and blood of Christ as instituted at the Last Supper. While many Anglicans celebrate the Eucharist in similar ways to the predominant western Catholic tradition, a considerable degree of liturgical freedom is permitted, and worship styles range from the simple to elaborate.

Unique to Anglicanism is the "Book of Common Prayer" (BCP), the collection of services that worshippers in most Anglican churches used for centuries. It was called "common prayer" originally because it was intended for use in all Church of England churches which had previously followed differing local liturgies. The term was kept when the church became international because all Anglicans used to share in its use around the world.

In 1549, the first "Book of Common Prayer" was compiled by Thomas Cranmer, who was then Archbishop of Canterbury. While it has since undergone many revisions and Anglican churches in different countries have developed other service books, the Prayer Book is still acknowledged as one of the ties that bind Anglicans together.

The founding of Christianity in Britain is commonly attributed to Joseph of Arimathea, according to Anglican legend, and is commemorated in Glastonbury Abbey. Many of the early Church fathers wrote of the presence of Christianity in Roman Britain, with Tertullian stating "those parts of Britain into which the Roman arms had never penetrated were become subject to Christ". Saint Alban, who was executed in AD 209, is the first Christian martyr in the British Isles. The historian Heinrich Zimmer writes that "Just as Britain was a part of the Roman Empire, so the British Church formed (during the fourth century) a branch of the Catholic Church of the West; and during the whole of that century, from the Council of Arles (316) onward, took part in all proceedings concerning the Church."

After Roman troops withdrew from Britain, however, the "absence of Roman military and governmental influence and overall decline of Roman imperial political power enabled Britain and the surrounding isles to develop distinctively from the rest of the West. A new culture emerged around the Irish Sea among the Celtic peoples with Celtic Christianity at its core. What resulted was a form of Christianity distinct from Rome in many traditions and practices." The historian Charles Thomas, in addition to the Celticist Heinrich Zimmer, writes that the distinction between sub-Roman and post-Roman Insular Christianity, also known as Celtic Christianity, began to become apparent around AD 475, with the Celtic churches allowing married clergy, observing Lent and Easter according to their own calendar, and having a different tonsure; moreover, like the Eastern Orthodox Churches and the Oriental Orthodox Churches, the Celtic churches operated independently of the Pope's authority, namely a result of their isolated development in the British Isles.
In what is known as the Gregorian mission, the Roman Catholic Pope Gregory I, sent Augustine of Canterbury to the British Isles in AD 596, with the purpose of evangelising the pagans there (who were largely Anglo-Saxons), as well as to reconcile the Celtic churches in the British Isles to the See of Rome. In Kent, Augustine persuaded the Anglo-Saxon king "Æthelberht and his people to accept Christianity." Augustine, on two occasions, "met in conference with members of the Celtic episcopacy, but no understanding was reached between them." Eventually, the "Christian Church of the Anglo-Saxon kingdom of Northumbria convened the Synod of Whitby in 663/664 to decide whether to follow Celtic or Roman usages." This meeting, with King Oswiu as the final decision maker, "led to the acceptance of Roman usage elsewhere in England and brought the English Church into close contact with the Continent." As a result of assuming Roman usages, the Celtic Church surrendered its independence and from this point on, the Church in England "was no longer purely Celtic, but became Anglo-Roman-Celtic". The theologian Christopher L. Webber writes that although "the Roman form of Christianity became the dominant influence in Britain as in all of western Europe, Anglican Christianity has continued to have a distinctive quality because of its Celtic heritage."

The Church in England remained united with Rome until the English Parliament, through the Act of Supremacy (1534), declared King Henry VIII to be the Supreme Head of the Church of England to fulfill the "English desire to be independent from continental Europe religiously and politically." Although now separate from Rome, the English Church, at this point in history, continued to maintain the Roman Catholic theology on many things, such as the sacraments. Under King Edward VI, however, the Church in England underwent what is known as the English Reformation, in the course of which it acquired a number of characteristics that would subsequently become recognised as constituting a distinct, Anglican, identity.

By the Elizabethan Settlement, the Protestant identity of the English and Irish churches was affirmed through parliamentary legislation which assumed allegiance and loyalty to the English Crown in all their members. However, from the first, the Elizabethan church began to develop distinct religious traditions; assimilating some of the theology of Reformed churches with the services in the "Book of Common Prayer" (which drew extensively on the Sarum Rite native to England), under the leadership and organisation of a continuing episcopate; and over the years these traditions themselves came to command adherence and loyalty. The Elizabethan Settlement stopped the radical Protestant tendencies under Edward VI by combining the more radical elements of the Second Prayer Book of 1552 with the conservative 'Catholic' First Prayer Book of 1549. From then on Protestantism was in a "state of arrested development" regardless of the attempts to detach the Church of England from its "idiosyncratic anchorage in the medieval past" by various groups which tried to push it towards a more Reformed theology and governance in the years 1560–1660. It has resolutely refused to identify decisively as Catholic or Protestant and sees it as a "virtue" rather than a "handicap," indeed it prefers to see itself as both.
Although two important constitutive elements of what later would emerge as Anglicanism, were present in 1559 – the historic episcopate and the "Book of Common Prayer" – neither the laypeople nor the clergy perceived themselves as Anglicans at the beginning of Elizabeth I's reign. Historical studies on the period 1560–1660 written before the late 1960s tended to project the predominant conformist spirituality and doctrine of the 1660s on the ecclesiastical situation one hundred years before, and there was also a tendency to take polemically binary partitions of reality claimed by contestants studied (such as the dichotomies Protestant-'Popish' or 'Laudian'-'Puritan') at face value. Since the late 1960s these interpretations have been criticised. Studies on the subject written during the last forty-five years have, however, not reached any consensus on how to interpret this period in English church history. The extent to which one or several positions concerning doctrine and spirituality existed alongside the more well-known and articulate Puritan movement and the Durham House Party, and the exact extent of continental Calvinism among the English elite and among the ordinary churchgoers from the 1560s to the 1620s are subjects of current and ongoing debate.

In 1662, under King Charles II, a revised "Book of Common Prayer" was produced, which was acceptable to high churchmen as well as some Puritans, and is still considered authoritative to this day.

In so far as Anglicans derived their identity from both parliamentary legislation and ecclesiastical tradition, a crisis of identity could result wherever secular and religious loyalties came into conflict – and such a crisis indeed occurred in 1776 with the American Declaration of Independence, most of whose signatories were, at least nominally, Anglican. For these American patriots, even the forms of Anglican services were in doubt, since the Prayer Book rites of Matins, Evensong and Holy Communion, all included specific prayers for the British Royal Family. Consequently, the conclusion of the War of Independence eventually resulted in the creation of two new Anglican churches, the Episcopal Church in the United States in those states that had achieved independence; and in the 1830s The Church of England in Canada became independent from the Church of England in those North American colonies which had remained under British control and to which many Loyalist churchmen had migrated.

Reluctantly, legislation was passed in the British Parliament (the Consecration of Bishops Abroad Act 1786) to allow bishops to be consecrated for an American church outside of allegiance to the British Crown (whereas no bishoprics had ever been established in the former American colonies). Both in the United States and in Canada, the new Anglican churches developed novel models of self-government, collective decision-making, and self-supported financing; that would be consistent with separation of religious and secular identities.

In the following century, two further factors acted to accelerate the development of a distinct Anglican identity. From 1828 and 1829, Dissenters and Catholics could be elected to the House of Commons, which consequently ceased to be a body drawn purely from the established churches of Scotland, England and Ireland; but which nevertheless, over the following ten years, engaged in extensive reforming legislation affecting the interests of the English and Irish churches; which by the Acts of Union of 1800, had been reconstituted as the United Church of England and Ireland. The propriety of this legislation was bitterly contested by the Oxford Movement (Tractarians), who in response developed a vision of Anglicanism as religious tradition deriving ultimately from the ecumenical councils of the patristic church. Those within the Church of England opposed to the Tractarians, and to their revived ritual practices, introduced a stream of bills in parliament aimed to control innovations in worship. This only made the dilemma more acute, with consequent continual litigation in the secular and ecclesiastical courts.

Over the same period, Anglican churches engaged vigorously in Christian missions, resulting in the creation, by the end of the century, of over ninety colonial bishoprics; which gradually coalesced into new self-governing churches on the Canadian and American models. However, the case of John Colenso, Bishop of Natal, reinstated in 1865 by the English Judicial Committee of the Privy Council over the heads of the Church in South Africa, demonstrated acutely that the extension of episcopacy had to be accompanied by a recognised Anglican ecclesiology of ecclesiastical authority, distinct from secular power.

Consequently, at the instigation of the bishops of Canada and South Africa, the first Lambeth Conference was called in 1867; to be followed by further conferences in 1878 and 1888, and thereafter at ten-year intervals. The various papers and declarations of successive Lambeth Conferences, have served to frame the continued Anglican debate on identity, especially as relating to the possibility of ecumenical discussion with other churches. This ecumenical aspiration became much more of a possibility, as other denominational groups rapidly followed the example of the Anglican Communion in founding their own transnational alliances: the Alliance of Reformed Churches, the Ecumenical Methodist Council, the International Congregational Council, and the Baptist World Alliance.

In their rejection of absolute parliamentary authority, the Tractarians – and in particular John Henry Newman – looked back to the writings of 17th-century Anglican divines, finding in these texts the idea of the English church as a "via media" between the Protestant and Catholic traditions. This view was associated – especially in the writings of Edward Bouverie Pusey – with the theory of Anglicanism as one of three "branches" (alongside the Catholic Church and the Orthodox Church) historically arising out of the common tradition of the earliest ecumenical councils. Newman himself subsequently rejected the theory of the "via media", as essentially historicist and static; and hence unable to accommodate any dynamic development within the church. Nevertheless, the aspiration to ground Anglican identity in the writings of the 17th-century divines, and in faithfulness to the traditions of the Church Fathers reflects a continuing theme of Anglican ecclesiology, most recently in the writings of Henry Robert McAdoo.

The Tractarian formulation of the theory of the "via media" was essentially a party platform, and not acceptable to Anglicans outside the confines of the Oxford Movement. However, the theory of the "via media" was reworked in the ecclesiological writings of Frederick Denison Maurice, in a more dynamic form that became widely influential. Both Maurice and Newman saw the Church of England of their day as sorely deficient in faith; but whereas Newman had looked back to a distant past when the light of faith might have appeared to burn brighter, Maurice looked forward to the possibility of a brighter revelation of faith in the future. Maurice saw the Protestant and Catholic strands within the Church of England as contrary but complementary, both maintaining elements of the true church, but incomplete without the other; such that a true catholic and evangelical church might come into being by a union of opposites.
Central to Maurice's perspective was his belief that the collective elements of family, nation, and church represented a divine order of structures through which God unfolds his continuing work of creation. Hence, for Maurice, the Protestant tradition had maintained the elements of national distinction which were amongst the marks of the true universal church, but which had been lost within contemporary Roman Catholicism in the internationalism of centralised papal authority. Within the coming universal church that Maurice foresaw, national churches would each maintain the six signs of Catholicity: baptism, Eucharist, the creeds, Scripture, an episcopal ministry, and a fixed liturgy (which could take a variety of forms in accordance with divinely ordained distinctions in national characteristics). Not surprisingly, this vision of a becoming universal church as a congregation of autonomous national churches, proved highly congenial in Anglican circles; and Maurice's six signs were adapted to form the Chicago-Lambeth Quadrilateral of 1888.

In the latter decades of the 20th century, Maurice's theory, and the various strands of Anglican thought that derived from it, have been criticised by Stephen Sykes; who argues that the terms "Protestant" and "Catholic" as used in these approaches are synthetic constructs denoting ecclesiastic identities unacceptable to those to whom the labels are applied. Hence, the Catholic Church does not regard itself as a party or strand within the universal church – but rather identifies itself as the universal church. Moreover, Sykes criticises the proposition, implicit in theories of "via media", that there is no distinctive body of Anglican doctrines, other than those of the universal church; accusing this of being an excuse not to undertake systematic doctrine at all.

Contrariwise, Sykes notes a high degree of commonality in Anglican liturgical forms, and in the doctrinal understandings expressed within those liturgies. He proposes that Anglican identity might rather be found within a shared consistent pattern of prescriptive liturgies, established and maintained through canon law, and embodying both a historic deposit of formal statements of doctrine, and also framing the regular reading and proclamation of scripture. Sykes nevertheless agrees with those heirs of Maurice who emphasise the incompleteness of Anglicanism as a positive feature, and quotes with qualified approval the words of Michael Ramsey:

In the time of Henry VIII the nature of Anglicanism was based on questions of jurisdiction – specifically, the belief of the Crown that national churches should be autonomous – rather than theological disagreement. The effort was to create a national church in legal continuity with its traditions, but inclusive of certain doctrinal and liturgical beliefs of the Reformers. The result has been a movement with a distinctive self-image among Christian movements. The question often arises as to whether the Anglican Communion should be identified as a Protestant or Catholic church, or perhaps as a distinct branch of Christianity altogether.

The distinction between Reformed and Catholic, and the coherence of the two, is routinely a matter of debate both within specific Anglican churches and throughout the Anglican Communion by members themselves. Since the Oxford Movement of the mid-19th century, many churches of the communion have revived and extended liturgical and pastoral practices similar to Roman Catholicism. This extends beyond the ceremony of high-church services to even more theologically significant territory, such as sacramental theology (see Anglican sacraments). While Anglo-Catholic practices, particularly liturgical ones, have resurfaced and become more common within the tradition over the last century, there remain many places where practices and beliefs remain on the more Reformed or evangelical side (see Sydney Anglicanism).

For high-church Anglicans, doctrine is neither established by a magisterium, nor derived from the theology of an eponymous founder (such as Calvinism), nor summed up in a confession of faith beyond the ecumenical creeds (such as the Lutheran Book of Concord). For them, the earliest Anglican theological documents are its prayer books, which they see as the products of profound theological reflection, compromise and synthesis. They emphasise the "Book of Common Prayer" as a key expression of Anglican doctrine. The principle of looking to the prayer books as a guide to the parameters of belief and practice is called by the Latin name "lex orandi, lex credendi" ("the law of prayer is the law of belief").

Within the prayer books are the fundamentals of Anglican doctrine: the Apostles' and Nicene creeds, the Athanasian Creed (now rarely used), the scriptures (via the lectionary), the sacraments, daily prayer, the catechism and apostolic succession in the context of the historic threefold ministry. For some low-church and evangelical Anglicans, the 16th-century Reformed Thirty-Nine Articles form the basis of doctrine.

The Thirty-Nine Articles played a significant role in Anglican doctrine and practice. Following the passing of the 1604 canons, all Anglican clergy had to formally subscribe to the articles. Today, however, the articles are no longer binding, but are seen as a historical document which has played a significant role in the shaping of Anglican identity. The degree to which each of the articles has remained influential varies.

On the doctrine of justification, for example, there is a wide range of beliefs within the Anglican Communion, with some Anglo-Catholics arguing for a faith with good works and the sacraments. At the same time, however, some evangelical Anglicans ascribe to the Reformed emphasis on "sola fide" ("faith alone") in their doctrine of justification (see Sydney Anglicanism). Still other Anglicans adopt a nuanced view of justification, taking elements from the early Church Fathers, Catholicism, Protestantism, liberal theology, and latitudinarian thought.

Arguably, the most influential of the original articles has been Article VI on the "sufficiency of scripture" which says that "Scripture containeth all things necessary to salvation: so that whatsoever is not read therein, nor may be proved thereby, is not to be required of any man, that it should be believed as an article of the Faith, or be thought requisite or necessary to salvation." This article has informed Anglican biblical exegesis and hermeneutics since earliest times.

Anglicans look for authority in their "standard divines" (see below). Historically, the most influential of these – apart from Cranmer – has been the 16th century cleric and theologian Richard Hooker who after 1660 was increasingly portrayed as the founding father of Anglicanism. Hooker's description of Anglican authority as being derived primarily from scripture, informed by reason (the intellect and the experience of God) and tradition (the practices and beliefs of the historical church), has influenced Anglican self-identity and doctrinal reflection perhaps more powerfully than any other formula. The analogy of the "three-legged stool" of scripture, reason, and tradition is often incorrectly attributed to Hooker. Rather Hooker's description is a hierarchy of authority, with scripture as foundational and reason and tradition as vitally important, but secondary, authorities.

Finally, the extension of Anglicanism into non-English cultures, the growing diversity of prayer books and the increasing interest in ecumenical dialogue, has led to further reflection on the parameters of Anglican identity. Many Anglicans look to the Chicago-Lambeth Quadrilateral of 1888 as the "sine qua non" of communal identity. In brief, the quadrilateral's four points are the scriptures, as containing all things necessary to salvation; the creeds (specifically, the Apostles' and Nicene Creeds) as the sufficient statement of Christian faith; the dominical sacraments of Baptism and Holy Communion; and the historic episcopate.

Within the Anglican tradition, "divines" are clergy of the Church of England whose theological writings have been considered standards for faith, doctrine, worship and spirituality and whose influence has permeated the Anglican Communion in varying degrees through the years. While there is no authoritative list of these Anglican divines, there are some whose names would likely be found on most lists – those who are commemorated in lesser feasts of the Anglican churches and those whose works are frequently anthologised.

The corpus produced by Anglican divines is diverse. What they have in common is a commitment to the faith as conveyed by scripture and the "Book of Common Prayer", thus regarding prayer and theology in a manner akin to that of the Apostolic Fathers. On the whole, Anglican divines view the "via media" of Anglicanism not as a compromise, but as "a positive position, witnessing to the universality of God and God's kingdom working through the fallible, earthly "ecclesia Anglicana"."

These theologians regard scripture as interpreted through tradition and reason as authoritative in matters concerning salvation. Reason and tradition, indeed, is extant in and presupposed by scripture, thus implying co-operation between God and humanity, God and nature, and between the sacred and secular. Faith is thus regarded as incarnational and authority as dispersed.
Amongst the early Anglican divines of the 16th and 17th centuries, the names of Thomas Cranmer, John Jewel, Matthew Parker, Richard Hooker, Lancelot Andrewes, and Jeremy Taylor predominate. The influential character of Hooker's "Of the Laws of Ecclesiastical Polity" cannot be overestimated. Published in 1593 and subsequently, Hooker's eight-volume work is primarily a treatise on church-state relations, but it deals comprehensively with issues of biblical interpretation, soteriology, ethics and sanctification. Throughout the work, Hooker makes clear that theology involves prayer and is concerned with ultimate issues and that theology is relevant to the social mission of the church.

The 18th century saw the rise of two important movements in Anglicanism: Cambridge Platonism, with its mystical understanding of reason as the "candle of the Lord" and the evangelical revival with its emphasis on the personal experience of the Holy Spirit. The Cambridge Platonist movement evolved into a school called Latitudinarianism, which emphasised reason as the barometer of discernment and took a stance of indifference towards doctrinal and ecclesiological differences.

The evangelical revival, influenced by such figures as John Wesley and Charles Simeon, re-emphasised the importance of justification through faith and the consequent importance of personal conversion. Some in this movement, such as Wesley and George Whitefield, took the message to the United States, influencing the First Great Awakening and creating an Anglo-American movement called Methodism that would eventually break away, structurally, from the Anglican churches after the American Revolution.

By the 19th century, there was a renewed interest in pre-Reformation English religious thought and practice. Theologians such as John Keble, Edward Bouverie Pusey and John Henry Newman had widespread influence in the realm of polemics, homiletics and theological and devotional works, not least because they largely repudiated the old high church tradition and replaced it with a dynamic appeal to antiquity which looked beyond the Reformers and Anglican formularies. Their work is largely credited with the development of the Oxford Movement, which sought to reassert Catholic identity and practice in Anglicanism.

In contrast to this movement, clergy such as the Bishop of Liverpool, J. C. Ryle, sought to uphold the distinctly Reformed identity of the Church of England. He was not a servant of the status quo, but argued for a lively religion which emphasised grace, holy and charitable living and the plain use of the 1662 "Book of Common Prayer" (interpreted in a partisan evangelical way) without additional rituals. Frederick Denison Maurice, through such works as "The Kingdom of Christ", played a pivotal role in inaugurating another movement, Christian socialism. In this, Maurice transformed Hooker's emphasis on the incarnational nature of Anglican spirituality to an imperative for social justice.

In the 19th century, Anglican biblical scholarship began to assume a distinct character, represented by the so-called "Cambridge triumvirate" of Joseph Lightfoot, F. J. A. Hort and Brooke Foss Westcott. Their orientation is best summed up by Lightfoot's observation that "Life which Christ is and which Christ communicates, the life which fills our whole beings as we realise its capacities, is active fellowship with God."

The earlier part of the 20th century is marked by Charles Gore, with his emphasis on natural revelation, and William Temple's focus on Christianity and society, while from outside England, Robert Leighton, Archbishop of Glasgow, and several clergy from the United States have been suggested, such as William Porcher DuBose, John Henry Hobart (1775–1830, Bishop of New York 1816–30), William Meade, Phillips Brooks, and Charles Brent.

"Churchmanship" can be defined as the manifestation of theology in the realms of liturgy, piety and, to some extent, spirituality. Anglican diversity in this respect has tended to reflect the diversity in the tradition's Reformed and Catholic identity. Different individuals, groups, parishes, dioceses and provinces may identify more closely with one or the other, or some mixture of the two.

The range of Anglican belief and practice became particularly divisive during the 19th century when some clergy were disciplined and even imprisoned on charges of introducing illegal ritual while, at the same time, others were criticised for engaging in public worship services with ministers of Reformed churches. Resistance to the growing acceptance and restoration of traditional Catholic ceremonial by the mainstream of Anglicanism ultimately led to the formation of small breakaway churches such as the Free Church of England in England (1844) and the Reformed Episcopal Church in North America (1873).

Anglo-Catholic (and some broad-church) Anglicans celebrate public liturgy in ways that understand worship to be something very special and of utmost importance. Vestments are worn by the clergy, sung settings are often used and incense may be used. Nowadays, in most Anglican churches, the Eucharist is celebrated in a manner similar to the usage of Catholics and some Lutherans though, in many churches, more traditional, "pre–Vatican II", models of worship are common, (e.g. an "eastward orientation" at the altar). Whilst many Anglo-Catholics derive much of their liturgical practice from that of the pre-Reformation English church, others more closely follow traditional Roman Catholic practices.

The Eucharist may sometimes be celebrated in the form known as High Mass, with a priest, deacon and subdeacon dressed in traditional vestments, with incense and sanctus bells and with prayers adapted from the Roman Missal or other sources by the celebrant. Such churches may also have forms of Eucharistic adoration such as Benediction of the Blessed Sacrament. In terms of personal piety some Anglicans may recite the Rosary and Angelus, be involved in a devotional society dedicated to "Our Lady" (the Blessed Virgin Mary) and seek the intercession of the saints.

In recent years the prayer books of several provinces have, out of deference to a greater agreement with Eastern Conciliarism (and a perceived greater respect accorded Anglicanism by Eastern Orthodoxy than by Roman Catholicism), instituted a number of historically Eastern and Oriental Orthodox elements in their liturgies, including introduction of the Trisagion and deletion of the filioque clause from the Nicene Creed.

For their part, those evangelical (and some broad-church) Anglicans who emphasise the more Protestant aspects of the Church stress the Reformation theme of salvation by grace through faith. They emphasise the two dominical sacraments of Baptism and Eucharist, viewing the other five as "lesser rites". Some evangelical Anglicans may even tend to take the inerrancy of scripture literally, adopting the view of Article VI that it contains all things necessary to salvation in an explicit sense. Worship in churches influenced by these principles tends to be significantly less elaborate, with greater emphasis on the Liturgy of the Word (the reading of the scriptures, the sermon and the intercessory prayers).

The Order for Holy Communion may be celebrated bi-weekly or monthly (in preference to the daily offices), by priests attired in choir habit, or more regular clothes, rather than Eucharistic vestments. Ceremony may be in keeping with their view of the provisions of the 17th-century Puritans – being a Reformed interpretation of the Ornaments Rubric – no candles, no incense, no bells and a minimum of manual actions by the presiding celebrant (such as touching the elements at the Words of Institution).

In recent decades there has been a growth of charismatic worship among Anglicans. Both Anglo-Catholics and evangelicals have been affected by this movement such that it is not uncommon to find typically charismatic postures, music, and other themes evident during the services of otherwise Anglo-Catholic or evangelical parishes.

The spectrum of Anglican beliefs and practice is too large to be fit into these labels. Many Anglicans locate themselves somewhere in the spectrum of the broad-church tradition and consider themselves an amalgam of evangelical and Catholic. Such Anglicans stress that Anglicanism is the ""via media"" (middle way) between the two major strains of Western Christianity and that Anglicanism is like a "bridge" between the two strains.

In accord with its prevailing self-identity as a "via media" or "middle path" of Western Christianity, Anglican sacramental theology expresses elements in keeping with its status as being both a church in the Catholic tradition as well as a Reformed church. With respect to sacramental theology the Catholic heritage is perhaps most strongly asserted in the importance Anglicanism places on the sacraments as a means of grace, sanctification and salvation as expressed in the church's liturgy and doctrine.

Of the seven sacraments, all Anglicans recognise Baptism and the Eucharist as being directly instituted by Christ. The other five – Confession and absolution, Matrimony, Confirmation, Holy Orders (also called Ordination) and Anointing of the Sick (also called Unction) – are regarded variously as full sacraments by Anglo-Catholics, many high-church and some broad-church Anglicans, but merely as "sacramental rites" by other broad-church and low-church Anglicans, especially evangelicals associated with Reform UK and the Diocese of Sydney.

Anglican eucharistic theology is divergent in practice, reflecting the essential comprehensiveness of the tradition. Some Low Church Anglicans take a strictly memorialist (Zwinglian) view of the sacrament. In other words, they see Holy Communion as a memorial to Christ's suffering, and participation in the Eucharist as both a re-enactment of the Last Supper and a foreshadowing of the heavenly banquet – the fulfilment of the eucharistic promise.

Other low-church Anglicans believe in the real presence of Christ in the Eucharist but deny that the presence of Christ is carnal or is necessarily localised in the bread and wine. Despite explicit criticism in the Thirty-Nine Articles, many high-church or Anglo-Catholic Anglicans hold, more or less, the Catholic view of the real presence as expressed in the doctrine of transubstantiation, seeing the Eucharist as a liturgical representation of Christ's atoning sacrifice with the elements actually transformed into Christ's body and blood.

The majority of Anglicans, however, have in common a belief in the real presence, defined in one way or another. To that extent, they are in the company of the continental reformer Martin Luther rather than Ulrich Zwingli.

A famous Anglican aphorism regarding Christ's presence in the sacrament, commonly misattributed to Queen Elizabeth I, is first found in print in a poem by John Donne:

<poem>
He was the word that spake it,
He took the bread and brake it:
And what that word did make it,
I do believe and take it.</poem>

An Anglican position on the eucharistic sacrifice ("Sacrifice of the Mass") was expressed in the response "Saepius officio" of the Archbishops of Canterbury and York to Pope Leo XIII's Papal Encyclical "Apostolicae curae".

Anglican and Catholic representatives declared that they had "substantial agreement on the doctrine of the Eucharist" in the 'Windsor Statement on Eucharistic Doctrine" from the Anglican-Roman Catholic International Consultation (1971) and the Elucidation of the ARCIC Windsor Statement (1979). The final response (1991) to these documents by the Vatican made it plain that it did not consider the degree of agreement reached to be satisfactory.

In Anglicanism there is a distinction between liturgy, which is the formal public and communal worship of the Church, and personal prayer and devotion which may be public or private. Liturgy is regulated by the prayer books and consists of the Holy Eucharist (some call it Holy Communion or Mass), the other six Sacraments, and the Divine Office or Liturgy of the Hours.

The "Book of Common Prayer" (BCP) is the foundational prayer book of Anglicanism. The original book of 1549 (revised 1552) was one of the instruments of the English Reformation, replacing the various "uses" or rites in Latin that had been used in different parts of the country with a single compact volume in the language of the people, so that "now from henceforth all the Realm shall have but one use". Suppressed under Queen Mary I, it was revised in 1559, and then again in 1662, after the Restoration of Charles II. This version was made mandatory in England and Wales by the Act of Uniformity and was in standard use until the mid-20th century.

With British colonial expansion from the 17th century onwards, Anglican churches were planted around the globe. These churches at first used and then revised the "Book of Common Prayer" until they, like their parent church, produced prayer books which took into account the developments in liturgical study and practice in the 19th and 20th centuries, which come under the general heading of the Liturgical Movement.

Anglican worship services are open to all visitors. Anglican worship originates principally in the reforms of Thomas Cranmer, who aimed to create a set order of service like that of the pre-Reformation church but less complex in its seasonal variety and said in English rather than Latin. This use of a set order of service is not unlike the Catholic tradition. Traditionally the pattern was that laid out in the "Book of Common Prayer". Although many Anglican churches now use a wide range of modern service books written in the local language, the structures of the "Book of Common Prayer" are largely retained. Churches which call themselves Anglican will have identified themselves so because they use some form or variant of the "Book of Common Prayer" in the shaping of their worship.

Anglican worship, however, is as diverse as Anglican theology. A contemporary "low church" service may differ little from the worship of many mainstream non-Anglican Protestant churches. The service is constructed around a sermon focused on Biblical exposition and opened with one or more Bible readings and closed by a series of prayers (both set and extemporised) and hymns or songs. A "high-church" or Anglo-Catholic service, by contrast, is usually a more formal liturgy celebrated by clergy in distinctive vestments and may be almost indistinguishable from a Roman Catholic service, often resembling the "pre–Vatican II" Tridentine rite.

Between these extremes are a variety of styles of worship, often involving a robed choir and the use of the organ to accompany the singing and to provide music before and after the service. Anglican churches tend to have pews or chairs and it is usual for the congregation to kneel for some prayers but to stand for hymns and other parts of the service such as the Gloria, Collect, Gospel reading, Creed and either the Preface or all of the Eucharistic Prayer. High Anglicans may genuflect or cross themselves in the same way as Roman Catholics.

Other more traditional Anglicans tend to follow the 1662 "Book of Common Prayer", and retain the use of the King James Bible. This is typical in many Anglican cathedrals and particularly in Royal Peculiars such as the Savoy Chapel and the Queen's Chapel. These services reflect the original Anglican doctrine and differ from the Traditional Anglican Communion in that they are in favour of women vicars and the ability of vicars to marry. These Anglican church services include classical music instead of songs, hymns from the New English Hymnal (usually excluding modern hymns such as Lord of the Dance), and are generally non-evangelical and formal in practice. Due to their association with royalty, these churches are generally host to staunch Anglicans who are strongly opposed to Catholicism.

Until the mid-20th century the main Sunday service was typically morning prayer, but the Eucharist has once again become the standard form of Sunday worship in many Anglican churches; this again is similar to Roman Catholic practice. Other common Sunday services include an early morning Eucharist without music, an abbreviated Eucharist following a service of morning prayer and a service of evening prayer, sometimes in the form of sung Evensong, usually celebrated between 3 and 6 pm The late-evening service of Compline was revived in parish use in the early 20th century. Many Anglican churches will also have daily morning and evening prayer and some have midweek or even daily celebration of the Eucharist.

An Anglican service (whether or not a Eucharist) will include readings from the Bible that are generally taken from a standardised lectionary, which provides for much of the Bible (and some passages from the Apocrypha) to be read out loud in the church over a cycle of one, two or three years (depending on which eucharistic and office lectionaries are used, respectively). The sermon (or homily) is typically about ten to twenty minutes in length, often comparably short to sermons in evangelical churches. Even in the most informal Anglican services it is common for set prayers such as the weekly Collect to be read. There are also set forms for intercessory prayer, though this is now more often extemporaneous. In high and Anglo-Catholic churches there are generally prayers for the dead.

Although Anglican public worship is usually ordered according to the canonically approved services, in practice many Anglican churches use forms of service outside these norms. Liberal churches may use freely structured or experimental forms of worship, including patterns borrowed from ecumenical traditions such as those of Taizé Community or the Iona Community.

Anglo-Catholic parishes might use the modern Roman Catholic liturgy of the Mass or more traditional forms, such as the Tridentine Mass (which is translated into English in the English Missal), the Anglican Missal, or, less commonly, the Sarum Rite. Catholic devotions such as the Rosary, Angelus and Benediction of the Blessed Sacrament are also common among Anglo-Catholics.

Only baptised persons are eligible to receive communion, although in many churches communion is restricted to those who have not only been baptised but also confirmed. In many Anglican provinces, however, all baptised Christians are now often invited to receive communion and some dioceses have regularised a system for admitting baptised young people to communion before they are confirmed.

The discipline of fasting before communion is practised by some Anglicans. Most Anglican priests require the presence of at least one other person for the celebration of the Eucharist (referring back to Christ's statement in Matthew 18:20, "When two or more are gathered in my name, I will be in the midst of them."), though some Anglo-Catholic priests (like Roman Catholic priests) may say private Masses. As in the Roman Catholic Church, it is a canonical requirement to use fermented wine for communion.

Unlike in Roman Catholicism, the consecrated bread and wine are always offered to the congregation at a eucharistic service ("communion in both kinds"). This practice is becoming more frequent in the Roman Catholic Church as well, especially through the Neocatechumenal Way. In some churches the sacrament is reserved in a tabernacle or aumbry with a lighted candle or lamp nearby. In Anglican churches, only a priest or a bishop may be the celebrant at the Eucharist.

All Anglican prayer books contain offices for Morning Prayer (Matins) and Evening Prayer (Evensong). In the original "Book of Common Prayer" these were derived from combinations of the ancient monastic offices of Matins and Lauds; and Vespers and Compline respectively. The prayer offices have an important place in Anglican history.

Prior to the Catholic revival of the 19th century, which eventually restored the Holy Eucharist as the principal Sunday liturgy, and especially during the 18th century, a morning service combining Matins, the Litany and ante-Communion comprised the usual expression of common worship; while Matins and Evensong were sung daily in cathedrals and some collegiate chapels. This nurtured a tradition of distinctive Anglican chant applied to the canticles and psalms used at the offices (although plainsong is often used as well).

In some official and many unofficial Anglican service books these offices are supplemented by other offices such as the Little Hours of Prime and prayer during the day such as (Terce, Sext, None and Compline). Some Anglican monastic communities have a Daily Office based on that of the "Book of Common Prayer" but with additional antiphons and canticles, etc. for specific days of the week, specific psalms, etc. See, for example, Order of the Holy Cross and Order of St Helena, editors, "A Monastic Breviary" (Wilton, Conn.: Morehouse-Barlow, 1976). The All Saints Sisters of the Poor, with convents in Catonsville, Maryland and elsewhere use an elaborated version of the Anglican Daily Office. The Society of St. Francis publishes "Celebrating Common Prayer" which has become especially popular for use among Anglicans.

In England, the United States, Canada, Australia, New Zealand and some other Anglican provinces the modern prayer books contain four offices:

In addition, most prayer books include a section of prayers and devotions for family use. In the US, these offices are further supplemented by an "Order of Worship for the Evening", a prelude to or an abbreviated form of Evensong, partly derived from Orthodox prayers. In the United Kingdom, the publication of "Daily Prayer", the third volume of "Common Worship" was published in 2005. It retains the services for Morning and Evening Prayer and Compline and includes a section entitled "Prayer during the Day". 'A New Zealand Prayer Book' of 1989 provides different outlines for Matins and Evensong on each day of the week, as well as "Midday Prayer", "Night Prayer" and "Family Prayer".

Some Anglicans who pray the office on daily basis use the present Divine Office of the Catholic Church. In many cities, especially in England, Anglican and Catholic priests and lay people often meet several times a week to pray the office in common. A small but enthusiastic minority use the Anglican Breviary, or other translations and adaptations of the pre–Vatican II Roman Rite and Sarum Rite, along with supplemental material from cognate western sources, to provide such things as a common of Octaves, a common of Holy Women and other additional material. Others may privately use idiosyncratic forms borrowed from a wide range of Christian traditions.

In the late medieval period, many English cathedrals and monasteries had established small choirs of trained lay clerks and boy choristers to perform polyphonic settings of the Mass in their Lady chapels. Although these "Lady Masses" were discontinued at the Reformation, the associated musical tradition was maintained in the Elizabethan Settlement through the establishment of choral foundations for daily singing of the Divine Office by expanded choirs of men and boys. This resulted from an explicit addition by Elizabeth herself to the injunctions accompanying the 1559 "Book of Common Prayer" (that had itself made no mention of choral worship) by which existing choral foundations and choir schools were instructed to be continued, and their endowments secured. Consequently, some thirty-four cathedrals, collegiate churches and royal chapels maintained paid establishments of lay singing men and choristers in the late 16th century.

All save four of these have – with an interruption during the Commonwealth – continued daily choral prayer and praise to this day. In the Offices of Matins and Evensong in the 1662 "Book of Common Prayer", these choral establishments are specified as "Quires and Places where they sing".

For nearly three centuries, this round of daily professional choral worship represented a tradition entirely distinct from that embodied in the intoning of Parish Clerks, and the singing of "west gallery choirs" which commonly accompanied weekly worship in English parish churches. In 1841, the rebuilt Leeds Parish Church established a surpliced choir to accompany parish services, drawing explicitly on the musical traditions of the ancient choral foundations. Over the next century, the Leeds example proved immensely popular and influential for choirs in cathedrals, parish churches and schools throughout the Anglican communion. More or less extensively adapted, this choral tradition also became the direct inspiration for robed choirs leading congregational worship in a wide range of Christian denominations.

In 1719 the cathedral choirs of Gloucester, Hereford and Worcester combined to establish the annual Three Choirs Festival, the precursor for the multitude of summer music festivals since. By the 20th century, the choral tradition had become for many the most accessible face of worldwide Anglicanism – especially as promoted through the regular broadcasting of choral evensong by the BBC; and also in the annual televising of the festival of Nine lessons and carols from King's College, Cambridge. Composers closely concerned with this tradition include Edward Elgar, Ralph Vaughan Williams, Gustav Holst, Charles Villiers Stanford and Benjamin Britten. A number of important 20th-century works by non-Anglican composers were originally commissioned for the Anglican choral tradition – for example the "Chichester Psalms" of Leonard Bernstein, and the "Nunc dimittis" of Arvo Pärt.

Contrary to popular misconception, the British monarch is not the constitutional "head" but in law the "Supreme Governor" of the Church of England, nor does he or she have any role in provinces outside England. The role of the crown in the Church of England is practically limited to the appointment of bishops, including the Archbishop of Canterbury, and even this role is limited, as the Church presents the government with a short list of candidates to choose from. This process is accomplished through collaboration with and consent of ecclesial representatives "(see Ecclesiastical Commissioners)". The monarch has no constitutional role in Anglican churches in other parts of the world, although the prayer books of several countries where she is head of state maintain prayers for her as sovereign.

A characteristic of Anglicanism is that it has no international juridical authority. All thirty-nine provinces of the Anglican Communion are autonomous, each with their own primate and governing structure. These provinces may take the form of national churches (such as in Canada, Uganda, or Japan) or a collection of nations (such as the West Indies, Central Africa, or South Asia), or geographical regions (such as Vanuatu and Solomon Islands) etc. Within these Communion provinces may exist subdivisions, called ecclesiastical provinces, under the jurisdiction of a metropolitan archbishop.

All provinces of the Anglican Communion consist of dioceses, each under the jurisdiction of a bishop. In the Anglican tradition, bishops must be consecrated according to the strictures of apostolic succession, which Anglicans consider one of the marks of Catholicity. Apart from bishops, there are two other orders of ordained ministry: deacon and priest.

No requirement is made for clerical celibacy, though many Anglo-Catholic priests have traditionally been bachelors. Because of innovations that occurred at various points after the latter half of the 20th century, women may be ordained as deacons in almost all provinces, as priests in some, and as bishops in a few provinces. Anglican religious orders and communities, suppressed in England during the Reformation, have re-emerged, especially since the mid-19th century, and now have an international presence and influence.

Government in the Anglican Communion is synodical, consisting of three houses of laity (usually elected parish representatives), clergy, and bishops. National, provincial, and diocesan synods maintain different scopes of authority, depending on their canons and constitutions. Anglicanism is not congregational in its polity: it is the diocese, not the parish church, which is the smallest unit of authority in the church. "(See Episcopal polity)".

The Archbishop of Canterbury has a precedence of honour over the other primates of the Anglican Communion, and for a province to be considered a part of the Communion means specifically to be in full communion with the See of Canterbury. The Archbishop is, therefore, recognised as "primus inter pares", or first amongst equals even though he does not exercise any direct authority in any province outside England, of which he is chief primate. Rowan Williams, the Archbishop of Canterbury from 2002 to 2012, was the first archbishop appointed from outside the Church of England since the Reformation: he was formerly the Archbishop of Wales.

As "spiritual head" of the Communion, the Archbishop of Canterbury maintains a certain moral authority, and has the right to determine which churches will be in communion with his See. He hosts and chairs the Lambeth Conferences of Anglican Communion bishops, and decides who will be invited to them. He also hosts and chairs the Anglican Communion Primates' Meeting and is responsible for the invitations to it. He acts as president of the secretariat of the Anglican Communion Office, and its deliberative body, the Anglican Consultative Council.

The Anglican Communion has no international juridical organisation. All international bodies are consultative and collaborative, and their resolutions are not legally binding on the autonomous provinces of the Communion. There are three international bodies of note.


Like the Roman Catholic Church and the Orthodox churches, the Anglican Communion maintains the threefold ministry of deacons, presbyters (usually called "priests") and bishops.

Bishops, who possess the fullness of Christian priesthood, are the successors of the Apostles. Primates, archbishops and metropolitans are all bishops and members of the historical episcopate who derive their authority through apostolic succession – an unbroken line of bishops that can be traced back to the 12 apostles of Jesus.

Bishops are assisted by priests and deacons. Most ordained ministers in the Anglican Communion are priests, who usually work in parishes within a diocese. Priests are in charge of the spiritual life of parishes and are usually called the rector or vicar. A curate (or, more correctly, an 'assistant curate') is a term often used for a priest or deacon who assists the parish priest. Non-parochial priests may earn their living by any vocation, although employment by educational institutions or charitable organisations is most common. Priests also serve as chaplains of hospitals, schools, prisons, and in the armed forces.

An archdeacon is a priest or deacon responsible for administration of an archdeaconry, which is often the name given to the principal subdivisions of a diocese. An archdeacon represents the diocesan bishop in his or her archdeaconry. In the Church of England the position of archdeacon can only be held by someone in priestly orders who has been ordained for at least six years. In some other parts of the Anglican Communion the position can also be held by deacons. In parts of the Anglican Communion where women cannot be ordained as priests or bishops but can be ordained as deacons, the position of archdeacon is effectively the most senior office an ordained woman can be appointed to.

A dean is a priest who is the principal cleric of a cathedral or other collegiate church and the head of the chapter of canons. If the cathedral or collegiate church has its own parish, the dean is usually also rector of the parish. However, in the Church of Ireland the roles are often separated and most cathedrals in the Church of England do not have associated parishes. In the Church in Wales, however, most cathedrals are parish churches and their deans are now also vicars of their parishes.

The Anglican Communion recognises Roman Catholic and Eastern Orthodox ordinations as valid. Outside the Anglican Communion, Anglican ordinations (at least of male priests) are recognised by the Old Catholic Church Porvoo Communion Lutherans and various Independent Catholic churches.

In Anglican churches, deacons often work directly in ministry to the marginalised inside and outside the church: the poor, the sick, the hungry, the imprisoned. Unlike Orthodox and most Roman Catholic deacons who may be married only before ordination, deacons are permitted to marry freely both before and after ordination, as are priests. Most deacons are preparing for priesthood and usually only remain as deacons for about a year before being ordained priests. However, there are some deacons who remain so.

Many provinces of the Anglican Communion ordain both men and women as deacons. Many of those provinces that ordain women to the priesthood previously allowed them to be ordained only to the diaconate. The effect of this was the creation of a large and overwhelmingly female diaconate for a time, as most men proceeded to be ordained priest after a short time as a deacon.

Deacons, in some dioceses, can be granted licences to solemnise matrimony, usually under the instruction of their parish priest and bishop. They sometimes officiate at Benediction of the Blessed Sacrament in churches which have this service. Deacons are not permitted to preside at the Eucharist (but can lead worship with the distribution of already consecrated communion where this is permitted), absolve sins, or pronounce a blessing. It is the prohibition against deacons pronouncing blessings that leads some to believe that deacons cannot solemnise matrimony.

All baptised members of the church are called Christian faithful, truly equal in dignity and in the work to build the church. Some non-ordained people also have a formal public ministry, often on a full-time and long-term basis – such as lay readers (also known as readers), churchwardens, vergers and sextons. Other lay positions include acolytes (male or female, often children), lay eucharistic ministers (also known as chalice bearers) and lay eucharistic visitors (who deliver consecrated bread and wine to "shut-ins" or members of the parish who are unable to leave home or hospital to attend the Eucharist). Lay people also serve on the parish altar guild (preparing the altar and caring for its candles, linens, flowers etc.), in the choir and as cantors, as ushers and greeters and on the church council (called the "vestry" in some countries) which is the governing body of a parish.

A small yet influential aspect of Anglicanism is its religious orders and communities. Shortly after the beginning of the Catholic Revival in the Church of England, there was a renewal of interest in re-establishing religious and monastic orders and communities. One of Henry VIII's earliest acts was their dissolution and seizure of their assets. In 1841 Marian Rebecca Hughes became the first woman to take the vows of religion in communion with the Province of Canterbury since the Reformation. In 1848, Priscilla Lydia Sellon became the superior of the Society of the Most Holy Trinity at Devonport, Plymouth, the first organised religious order. Sellon is called "the restorer, after three centuries, of the religious life in the Church of England." For the next one hundred years, religious orders for both men and women proliferated throughout the world, becoming a numerically small but disproportionately influential feature of global Anglicanism.

Anglican religious life at one time boasted hundreds of orders and communities, and thousands of religious. An important aspect of Anglican religious life is that most communities of both men and women lived their lives consecrated to God under the vows of poverty, chastity and obedience (or in Benedictine communities, Stability, Conversion of Life, and Obedience) by practising a mixed life of reciting the full eight services of the Breviary in choir, along with a daily Eucharist, plus service to the poor. The mixed life, combining aspects of the contemplative orders and the active orders remains to this day a hallmark of Anglican religious life. Another distinctive feature of Anglican religious life is the existence of some mixed-gender communities.

Since the 1960s there has been a sharp decline in the number of professed religious in most parts of the Anglican Communion, especially in North America, Europe, and Australia. Many once large and international communities have been reduced to a single convent or monastery with memberships of elderly men or women. In the last few decades of the 20th century, novices have for most communities been few and far between. Some orders and communities have already become extinct. There are however, still thousands of Anglican religious working today in approximately 200 communities around the world, and religious life in many parts of the Communion – especially in developing nations – flourishes.

The most significant growth has been in the Melanesian countries of the Solomon Islands, Vanuatu and Papua New Guinea. The Melanesian Brotherhood, founded at Tabalia, Guadalcanal, in 1925 by Ini Kopuria, is now the largest Anglican Community in the world with over 450 brothers in the Solomon Islands, Vanuatu, Papua New Guinea, the Philippines and the United Kingdom. The Sisters of the Church, started by Mother Emily Ayckbowm in England in 1870, has more sisters in the Solomons than all their other communities. The Community of the Sisters of Melanesia, started in 1980 by Sister Nesta Tiboe, is a growing community of women throughout the Solomon Islands.

The Society of Saint Francis, founded as a union of various Franciscan orders in the 1920s, has experienced great growth in the Solomon Islands. Other communities of religious have been started by Anglicans in Papua New Guinea and in Vanuatu. Most Melanesian Anglican religious are in their early to mid-20s – vows may be temporary and it is generally assumed that brothers, at least, will leave and marry in due course – making the average age 40 to 50 years younger than their brothers and sisters in other countries. Growth of religious orders, especially for women, is marked in certain parts of Africa.

Anglicanism represents the third largest Christian communion in the world, after the Roman Catholic Church and the Eastern Orthodox Churches. The number of Anglicans in the world is over 85 million . The 11 provinces in Africa saw growth in the last two decades. They now include 36.7 million members, more Anglicans than there are in England. England remains the largest single Anglican province, with 26 million members. In most industrialised countries, church attendance has decreased since the 19th century. Anglicanism's presence in the rest of the world is due to large-scale emigration, the establishment of expatriate communities or the work of missionaries.

The Church of England has been a church of missionaries since the 17th century when the Church first left English shores with colonists who founded what would become the United States, Australia, Canada, New Zealand and South Africa and established Anglican churches. For example, an Anglican chaplain, Robert Wolfall, with Martin Frobisher's Arctic expedition celebrated the Eucharist in 1578 in Frobisher Bay.

The first Anglican church in the Americas was built at Jamestown, Virginia, in 1607. By the 18th century, missionaries worked to establish Anglican churches in Asia, Africa and Latin America. The great Church of England missionary societies were founded; for example the Society for Promoting Christian Knowledge (SPCK) in 1698. Society for the Propagation of the Gospel in Foreign Parts (SPG) in 1701, and the Church Mission Society (CMS) in 1799.

The 19th century saw the founding and expansion of social oriented evangelism with societies such as the Church Pastoral Aid Society (CPAS) in 1836, Mission to Seafarers in 1856, Girls' Friendly Society (GFS) in 1875, Mothers' Union in 1876 and Church Army in 1882 all carrying out a personal form of evangelism.

The 20th century saw the Church of England developing new forms of evangelism such as the Alpha course in 1990 which was developed and propagated from Holy Trinity Brompton Church in London. In the 21st century, there has been renewed effort to reach children and youth. Fresh expressions is a Church of England missionary initiative to youth begun in 2005, and has ministries at a skate park through the efforts of St George's Church, Benfleet, Essex – Diocese of Chelmsford – or youth groups with evocative names, like the C.L.A.W (Christ Little Angels – Whatever!) youth group at Coventry Cathedral. And for the unchurched who do not actually wish to visit a bricks and mortar church there are Internet ministries such as the Diocese of Oxford's online Anglican i-Church which appeared on the web in 2005.

Anglican interest in ecumenical dialogue can be traced back to the time of the Reformation and dialogues with both Orthodox and Lutheran churches in the 16th century. In the 19th century, with the rise of the Oxford Movement, there arose greater concern for reunion of the churches of "Catholic confession". This desire to work towards full communion with other denominations led to the development of the Chicago-Lambeth Quadrilateral, approved by the third Lambeth Conference of 1888. The four points (the sufficiency of scripture, the historic creeds, the two dominical sacraments, and the historic episcopate) were proposed as a basis for discussion, although they have frequently been taken as a non-negotiable bottom-line for any form of reunion.

Anglicanism in general has always sought a balance between the emphases of Catholicism and Protestantism, while tolerating a range of expressions of evangelicalism and ceremony. Clergy and laity from all Anglican churchmanship traditions have been active in the formation of the Continuing movement.

While there are high-church, broad-church, and low-church Continuing Anglicans, many Continuing churches are Anglo-Catholic with highly ceremonial liturgical practices. Others belong to a more evangelical or low-church tradition and tend to support the Thirty-nine Articles and simpler worship services. Morning Prayer, for instance, is often used instead of the Holy Eucharist for Sunday worship services, although this is not necessarily true of all low church parishes.

Most Continuing churches in the United States reject the 1979 revision of the "Book of Common Prayer" by the Episcopal Church and use the 1928 version for their services instead. In addition, Anglo-Catholic bodies may use the Anglican Missal or English Missal in celebrating the Eucharist.

A changing focus on social issues after the Second World War led to Lambeth Conference resolutions countenancing contraception and the remarriage of divorced persons. They led to most provinces approving the ordination of women. In more recent years it has led some jurisdictions to permit the ordination of people in same-sex relationships and to authorise rites for the blessing of same-sex unions (see Homosexuality and Anglicanism). "The more liberal provinces that are open to changing Church doctrine on marriage in order to allow for same-sex unions include Brazil, Canada, New Zealand, Scotland, South India, South Africa, the US and Wales." More conservative elements within and outside of Anglicanism (primarily African churches and factions within North American Anglicanism) have opposed these proposals.

Some liberal and moderate Anglicans see this opposition as representing a new fundamentalism within Anglicanism. Others see the advocacy for these proposals as representing a breakdown of Christian theology and commitment. The lack of social consensus among and within provinces of diverse cultural traditions has resulted in considerable conflict and even schism concerning some or all of these developments (see Anglican realignment). Some Anglicans opposed to various liberalising changes, in particular the ordination of women, have become Roman Catholics or Orthodox. Others have, at various times, joined the Continuing Anglican movement.

These latter trends reflect a countervailing tendency in Anglicanism towards insularity, reinforced perhaps by the "big tent" nature of the tradition which seeks to be comprehensive of various views and tendencies. The insularity and complacency of the early established Church of England has tended to influence Anglican self-identity and inhibit engagement with the broader society in favour of internal debate and dialogue. Nonetheless, there is significantly greater cohesion among Anglicans when they turn their attention outward.

The term "Continuing Anglicanism" refers to a number of church bodies which have formed outside of the Anglican Communion in the belief that traditional forms of Anglican faith, worship and order have been unacceptably revised or abandoned within some Anglican Communion churches in recent decades. They therefore claim that they are "continuing" traditional Anglicanism.

The modern Continuing Anglican movement principally dates to the Congress of St. Louis, held in the United States in 1977, where participants rejected changes that had been made in the Episcopal Church's "Book of Common Prayer" and also the Episcopal Church's approval of the ordination of women to the priesthood. More recent changes in the North American churches of the Anglican Communion, such as the introduction of same-sex marriage rites and the ordination of gay and lesbian people to the priesthood and episcopate, have created further separations.

Continuing churches have generally been formed by people who have left the Anglican Communion. The original Anglican churches are charged by the Continuing Anglicans with being greatly compromised by secular cultural standards and liberal theology. Many Continuing Anglicans believe that the faith of some churches in communion with the Archbishop of Canterbury has become unorthodox and therefore have not sought to also be in communion with him.

The original generation of continuing parishes in the United States were found mainly in metropolitan areas. Since the late 1990s a number have appeared in smaller communities, often as a result of a division in the town's existing Episcopal churches. The 2007–08 "Directory of Traditional Anglican and Episcopal Parishes", published by the Fellowship of Concerned Churchmen, contained information on over 900 parishes affiliated with either the Continuing Anglican churches or the Anglican realignment movement, a more recent wave of Anglicans withdrawing from the Anglican Communion's North American provinces.

A concern for social justice can be traced to very early Anglican beliefs, relating to an intertwined theology of God, nature, and humanity. The Anglican theologian Richard Hooker wrote in his book "The Works of that Learned and Judicious Divine" that, "God hath created nothing simply for itself, but each thing in all things, and of every thing each part in other have such interest, that in the whole world nothing is found whereunto any thing created can say, 'I need thee not.'" Such statements demonstrate a theological Anglican interest in social activism, which has historically appeared in movements such as evangelical Anglican William Wilberforce's campaign against slavery in the 18th century, or 19th century issues concerning industrialisation.

Lord Shaftesbury, a devout evangelical, campaigned to improve the conditions in factories, in mines, for chimney sweeps, and for the education of the very poor. For years he was chairman of the Ragged School Board. Frederick Denison Maurice was a leading figure advocating reform, founding so-called "producer's co-operatives" and the Working Men's College. His work was instrumental in the establishment of the Christian socialist movement, although he himself was not in any real sense a socialist but, "a Tory paternalist with the unusual desire to theories his acceptance of the traditional obligation to help the poor", influenced Anglo-Catholics such as Charles Gore, who wrote that, "the principle of the incarnation is denied unless the Christian spirit can be allowed to concern itself with everything that interests and touches human life. Anglican focus on labour issues culminated in the work of William Temple in the 1930s and 1940s."

A question of whether or not Christianity is a pacifist religion has remained a matter of debate for Anglicans. The leading Anglican spokesman for pacifist ideas, 1914 to 1945, was Ernest Barnes, bishop of Birmingham 1924–1953. He opposed both world wars. In 1937, the Anglican Pacifist Fellowship emerged as a distinct reform organisation, seeking to make pacifism a clearly defined part of Anglican theology. The group rapidly gained popularity amongst Anglican intellectuals, including Vera Brittain, Evelyn Underhill, and the former British political leader George Lansbury. Furthermore, Dick Sheppard, who during the 1930s was one of Britain's most famous Anglican priests due to his landmark sermon broadcasts for BBC Radio, founded the Peace Pledge Union a secular pacifist organisation for the non-religious that gained considerable support throughout the 1930s.

Whilst never actively endorsed by Anglican churches, many Anglicans unofficially have adopted the Augustinian "Just War" doctrine. The Anglican Pacifist Fellowship remain highly active throughout the Anglican world. It rejects this doctrine of "just war" and seeks to reform the Church by reintroducing the pacifism inherent in the beliefs of many of the earliest Christians and present in their interpretation of Christ's Sermon on the Mount. The principles of the Anglican Pacifist Fellowship are often formulated as a statement of belief that "Jesus' teaching is incompatible with the waging of war ... that a Christian church should never support or justify war ... [and] that our Christian witness should include opposing the waging or justifying of war."

Confusing the matter was the fact that the 37th Article of Religion in the "Book of Common Prayer" states that "it is lawful for Christian men, at the commandment of the Magistrate, to wear weapons, and serve in the wars." Therefore, the Lambeth Council in the modern era has sought to provide a clearer position by repudiating modern war and developed a statement that has been affirmed at each subsequent meeting of the Council.

This statement was strongly reasserted when "the 67th General Convention of the Episcopal Church reaffirms the statement made by the Anglican Bishops assembled at Lambeth in 1978 and adopted by the 66th General Convention of the Episcopal Church in 1979, calling "Christian people everywhere ... to engage themselves in non-violent action for justice and peace and to support others so engaged, recognising that such action will be controversial and may be personally very costly... this General Convention, in obedience to this call, urges all members of this Church to support by prayer and by such other means as they deem appropriate, those who engaged in such non-violent action, and particularly those who suffer for conscience' sake as a result; and be it further Resolved, that this General Convention calls upon all members of this Church seriously to consider the implications for their own lives of this call to resist war and work for peace for their own lives."

The focus on other social issues became increasingly diffuse after the Second World War. On the one hand, the growing independence and strength of Anglican churches in the global south brought new emphasis to issues of global poverty, the inequitable distribution of resources, and the lingering effects of colonialism. In this regard, figures such as Desmond Tutu and Ted Scott were instrumental in mobilising Anglicans worldwide against the apartheid policies of South Africa. Rapid social change in the industrialised world during the 20th century compelled the church to examine issues of gender, sexuality and marriage.

On 4 November 2009, Pope Benedict XVI issued an apostolic constitution, "Anglicanorum Coetibus", to allow groups of former Anglicans to enter into full communion with the Roman Catholic Church as members of personal ordinariates. The 20 October 2009 announcement of the imminent constitution mentioned:

For each personal ordinariate the ordinary may be a former Anglican bishop or priest. It is expected that provision will be made to allow the retention of aspects of Anglican liturgy; cf. Anglican Use.



</doc>
<doc id="1216" url="https://en.wikipedia.org/wiki?curid=1216" title="Athens">
Athens

Athens (; , "Athína" , , "Athênai" ) is the capital and largest city of Greece. Athens dominates the Attica region and is one of the world's oldest cities, with its recorded history spanning over 3,400 years and its earliest human presence starting somewhere between the 11th and 7th millennium BC.

Classical Athens was a powerful city-state that emerged in conjunction with the seagoing development of the port of Piraeus, which had been a distinct city prior to its 5th century BCE incorporation with Athens. A centre for the arts, learning and philosophy, home of Plato's Academy and Aristotle's Lyceum, it is widely referred to as the cradle of Western civilization and the birthplace of democracy, largely because of its cultural and political impact on the European continent, and in particular the Romans. In modern times, Athens is a large cosmopolitan metropolis and central to economic, financial, industrial, maritime, political and cultural life in Greece. In 2012, Athens was ranked the world's 39th richest city by purchasing power and the 67th most expensive in a UBS study.

Athens is a global city and one of the biggest economic centres in southeastern Europe. It has a large financial sector, and its port Piraeus is both the largest passenger port in Europe, and the second largest in the world. 
The Municipality of Athens (also City of Athens) had a population of 664,046 (in 2011) within its administrative limits, and a land area of . The urban area of Athens (Greater Athens and Greater Piraeus) extends beyond its administrative municipal city limits, with a population of 3,090,508 (in 2011) over an area of . According to Eurostat in 2011, the functional urban area (FUA) of Athens was the 9th most populous FUA in the European Union (the 6th most populous capital city of the EU), with a population of 3.8 million people. Athens is also the southernmost capital on the European mainland.

The heritage of the classical era is still evident in the city, represented by ancient monuments and works of art, the most famous of all being the Parthenon, considered a key landmark of early Western civilization. The city also retains Roman and Byzantine monuments, as well as a smaller number of Ottoman monuments. Athens is home to two UNESCO World Heritage Sites, the Acropolis of Athens and the medieval Daphni Monastery. Landmarks of the modern era, dating back to the establishment of Athens as the capital of the independent Greek state in 1834, include the Hellenic Parliament and the so-called "architectural trilogy of Athens", consisting of the National Library of Greece, the National and Kapodistrian University of Athens and the Academy of Athens. Athens is also home to several museums and cultural institutions, such as the National Archeological Museum, featuring the world's largest collection of ancient Greek antiquities, the Acropolis Museum, the Museum of Cycladic Art, the Benaki Museum and the Byzantine and Christian Museum. Athens was the host city of the first modern-day Olympic Games in 1896, and 108 years later it welcomed home the 2004 Summer Olympics, making it one of only a handful of cities to have hosted the Olympics more than once.

In Ancient Greek, the name of the city was ("Athēnai", in Classical Attic) a plural. In earlier Greek, such as Homeric Greek, the name had been current in the singular form though, as ("Athēnē"). It was possibly rendered in the plural later on, like those of ("Thêbai") and ("Μukênai"). The root of the word is probably not of Greek or Indo-European origin, and is possibly a remnant of the Pre-Greek substrate of Attica. In antiquity, it was debated whether Athens took its name from its patron goddess Athena (Attic , "Athēnā", Ionic , "Athēnē", and Doric , "Athānā") or Athena took her name from the city. Modern scholars now generally agree that the goddess takes her name from the city, because the ending -"ene" is common in names of locations, but rare for personal names. During the medieval period, the name of the city was rendered once again in the singular as . However, after the establishment of the modern Greek state, and partly due to the conservatism of the written language, became again the official name of the city and remained so until the abandonment of Katharevousa in the 1970s, when Ἀθήνα, "Athína", became the official name.

According to the ancient Athenian founding myth, Athena, the goddess of wisdom, competed against Poseidon, the god of the seas, for patronage of the yet-unnamed city; they agreed that whoever gave the Athenians the better gift would become their patron and appointed Cecrops, the king of Athens, as the judge. According to the account given by Pseudo-Apollodorus, Poseidon struck the ground with his trident and a salt water spring welled up. In an alternative version of the myth from Vergil's "Georgics", Poseidon instead gave the Athenians the first horse. In both versions, Athena offered the Athenians the first domesticated olive tree. Cecrops accepted this gift and declared Athena the patron goddess of Athens.

Different etymologies, now commonly rejected, were proposed during the 19th century. Christian Lobeck proposed as the root of the name the word ("áthos") or ("ánthos") meaning "flower", to denote Athens as the "flowering city". Ludwig von Döderlein proposed the stem of the verb , stem θη- ("tháō", "thē-", "to suck") to denote Athens as having fertile soil.

In classical literature, the city was sometimes referred to as the City of the Violet Crown, first documented in Pindar's ἰοστέφανοι Ἀθᾶναι ("iostéphanoi Athânai"), or as ("tò kleinòn ásty", "the glorious city"). In medieval texts, variant names include Setines, Satine, and Astines, all derivations involving false splitting of prepositional phrases. Today the caption ("ī protévousa"), "the capital", has become somewhat common.

Athens sprawls across the central plain of Attica that is often referred to as the "Athens or Attica Basin" (Greek: Λεκανοπέδιο Αττικής). The basin is bounded by four large mountains: Mount Aigaleo to the west, Mount Parnitha to the north, Mount Pentelicus to the northeast and Mount Hymettus to the east. Beyond Mount Aegaleo lies the Thriasian plain, which forms an extension of the central plain to the west. The Saronic Gulf lies to the southwest. Mount Parnitha is the tallest of the four mountains (), and has been declared a national park.

Athens is built around a number of hills. Lycabettus is one of the tallest hills of the city proper and provides a view of the entire Attica Basin. The geomorphology of Athens is deemed to be one of the most complex in the world because its mountains cause a temperature inversion phenomenon which, along with the Greek Government's difficulties controlling industrial pollution, was responsible for the air pollution problems the city has faced. This issue is not unique to Athens; for instance, Los Angeles and Mexico City also suffer from similar geomorphology inversion problems.

The Cephissus river, the Ilisos and the Eridanos stream are the historical rivers of Athens.

By the late 1970s, the pollution of Athens had become so destructive that according to the then Greek Minister of Culture, Constantine Trypanis, ""...the carved details on the five the caryatids of the Erechtheum had seriously degenerated, while the face of the horseman on the Parthenon's west side was all but obliterated."" A series of measures taken by the authorities of the city throughout the 1990s resulted in the improvement of air quality; the appearance of smog (or "nefos" as the Athenians used to call it) has become less common.

Measures taken by the Greek authorities throughout the 1990s have improved the quality of air over the Attica Basin. Nevertheless, air pollution still remains an issue for Athens, particularly during the hottest summer days. In late June 2007, the Attica region experienced a number of brush fires, including a blaze that burned a significant portion of a large forested national park in Mount Parnitha, considered critical to maintaining a better air quality in Athens all year round. Damage to the park has led to worries over a stalling in the improvement of air quality in the city.

The major waste management efforts undertaken in the last decade (particularly the plant built on the small island of Psytalia) have improved water quality in the Saronic Gulf, and the coastal waters of Athens are now accessible again to swimmers. In January 2007, Athens faced a waste management problem when its landfill near Ano Liosia, an Athenian suburb, reached capacity. The crisis eased by mid-January when authorities began taking the garbage to a temporary landfill.

Athens has a hot-summer Mediterranean climate (Köppen climate classification: "Csa"). The dominant feature of Athens' climate is alternation between prolonged hot and dry summers and mild winters with moderate rainfall. With an average of of yearly precipitation, rainfall occurs largely between the months of October and April. July and August are the driest months, where thunderstorms occur sparsely once or twice a month.

The annual precipitation of Athens is typically lower than in other parts of Greece, mainly in western Greece. As an example, Ioannina receives around per year, and Agrinio around per year. Daily average highs for July (1988–2017) have been measured at , but some parts of the city may be even warmer, in particular its western areas partly because of industrialization and partly because of a number of natural factors, knowledge of which has been available from the mid-19th century.

Athens is affected by the urban heat island effect in some areas which is caused by human activity, altering its temperatures compared to the surrounding rural areas, and bearing detrimental effects on energy usage, expenditure for cooling, and health. The urban heat island of the city has also been found to be partially responsible for alterations of the climatological temperature time-series of specific Athens meteorological stations, because of its impact on the temperatures and the temperature trends recorded by some meteorological stations. On the other hand, specific meteorological stations, such as the National Garden station and Thiseio meteorological station, are less affected or do not experience the urban heat island.

Athens holds the World Meteorological Organization record for the highest temperature ever recorded in Europe, at , which was recorded in the Elefsina and Tatoi suburbs of Athens on 10 July 1977.

The municipality of Athens, the city centre of the Athens Urban Area, is divided into several districts: Omonoia, Syntagma, Exarcheia, Agios Nikolaos, Neapolis, Lykavittos, Lofos Strefi, Lofos Finopoulou, Lofos Filopappou, Pedion Areos, Metaxourgeio, Aghios Kostantinos, Larissa Station, Kerameikos, Psiri, Monastiraki, Gazi, Thission, Kapnikarea, Aghia Irini, Aerides, Anafiotika, Plaka, Acropolis, Pnyka, Makrygianni, Lofos Ardittou, Zappeion, Aghios Spyridon, Pangrati, Kolonaki, Dexameni, Evaggelismos, Gouva, Aghios Ioannis, Neos Kosmos, Koukaki, Kynosargous, Fix, Ano Petralona, Kato Petralona, Rouf, Votanikos, Profitis Daniil, Akadimia Platonos, Kolonos, Kolokynthou, Attikis Square, Lofos Skouze, Sepolia, Kypseli, Aghios Meletios, Nea Kypseli, Gyzi, Polygono, Ampelokipoi, Panormou-Gerokomeio, Pentagono, Ellinorosson, Nea Filothei, Ano Kypseli, Tourkovounia-Lofos Patatsou, Lofos Elikonos, Koliatsou, Thymarakia, Kato Patisia, Treis Gefyres, Aghios Eleftherios, Ano Patisia, Kypriadou, Menidi, Prompona, Aghios Panteleimonas, Pangrati, Goudi and Ilisia.


The Gazi () area, one of the latest in full redevelopment, is located around a historic gas factory, now converted into the "Technopolis" cultural multiplex, and also includes artists' areas, small clubs, bars and restaurants, as well as Athens's "Gay village". The metro's expansion to the western suburbs of the city has brought easier access to the area since spring 2007, as the blue line now stops at Gazi (Kerameikos station).

Parnitha National Park is punctuated by well-marked paths, gorges, springs, torrents and caves dotting the protected area. Hiking and mountain-biking in all four mountains are popular outdoor activities for residents of the city. The National Garden of Athens was completed in 1840 and is a green refuge of 15.5 hectares in the centre of the Greek capital. It is to be found between the Parliament and Zappeion buildings, the latter of which maintains its own garden of seven hectares.

Parts of the city centre have been redeveloped under a masterplan called the "Unification of Archeological Sites of Athens", which has also gathered funding from the EU to help enhance the project. The landmark Dionysiou Areopagitou Street has been pedestrianised, forming a scenic route. The route starts from the Temple of Olympian Zeus at Vasilissis Olgas Avenue, continues under the southern slopes of the Acropolis near Plaka, and finishes just beyond the Temple of Hephaestus in Thiseio. The route in its entirety provides visitors with views of the Parthenon and the Agora (the meeting point of ancient Athenians), away from the busy city centre.

The hills of Athens also provide green space. Lycabettus, Philopappos hill and the area around it, including Pnyx and Ardettos hill, are planted with pines and other trees, with the character of a small forest rather than typical metropolitan parkland. Also to be found is the Pedion tou Areos ("Field of Mars") of 27.7 hectares, near the National Archaeological Museum.

Athens' largest zoo is the Attica Zoological Park, a 20-hectare (49-acre) private zoo located in the suburb of Spata. The zoo is home to around 2000 animals representing 400 species, and is open 365 days a year. Smaller zoos exist within public gardens or parks, such as the zoo within the National Garden of Athens.

The large City Centre of the Greek capital falls directly within the municipality of Athens, which is the largest in population size in Greece. Piraeus also forms a significant city centre on its own, within the Athens Urban Area and being the second largest in population size within it, with Peristeri and Kallithea following.

The Athens Metropolitan Area consists of 58 densely populated municipalities, sprawling around the municipality of Athens (the city centre) in virtually all directions. For the Athenians, all the urban municipalities surrounding the city centre are called suburbs. According to their geographic location in relation to the City of Athens, the suburbs are divided into four zones; the northern suburbs (including Agios Stefanos, Dionysos, Ekali, Nea Erythraia, Kifissia, Maroussi, Pefki, Lykovrysi, Metamorfosi, Nea Ionia, Nea Filadelfeia, Irakleio, Vrilissia, Melissia, Penteli, Chalandri, Agia Paraskevi, Galatsi, Psychiko and Filothei); the southern suburbs (including Alimos, Nea Smyrni, Moschato, Kallithea, Agios Dimitrios, Palaio Faliro, Elliniko, Glyfada, Argyroupoli, Ilioupoli, Voula and Vouliagmeni); the eastern suburbs (including Zografou, Dafni, Vyronas, Kaisariani, Cholargos and Papagou); and the western suburbs (including Peristeri, Ilion, Egaleo, Koridallos, Agia Varvara, Chaidari, Petroupoli, Agioi Anargyroi and Kamatero).

The Athens city coastline, extending from the major commercial port of Piraeus to the southernmost suburb of Varkiza for some , is also connected to the city centre by a tram.

In the northern suburb of Maroussi, the upgraded main Olympic Complex (known by its Greek acronym OAKA) dominates the skyline. The area has been redeveloped according to a design by the Spanish architect Santiago Calatrava, with steel arches, landscaped gardens, fountains, futuristic glass, and a landmark new blue glass roof which was added to the main stadium. A second Olympic complex, next to the sea at the beach of Palaio Faliro, also features modern stadia, shops and an elevated esplanade. Work is underway to transform the grounds of the old Athens Airport – named Elliniko – in the southern suburbs, into one of the largest landscaped parks in Europe, to be named the Hellenikon Metropolitan Park.

Many of the southern suburbs (such as Alimos, Palaio Faliro, Elliniko, Voula, Vouliagmeni and Varkiza) known as the Athens Riviera, host a number of sandy beaches, most of which are operated by the Greek National Tourism Organisation and require an entrance fee. Casinos operate on both Mount Parnitha, some from downtown Athens (accessible by car or cable car), and the nearby town of Loutraki (accessible by car via the Athens – Corinth National Highway, or the suburban rail service Proastiakos).

The Athens Urban Area today consists of 40 municipalities, 35 of which make up what is referred to as the Greater Athens municipalities, located within 4 regional units (North Athens, West Athens, Central Athens, South Athens); and a further 5, which make up the Greater Piraeus municipalities, located within the regional unit of Piraeus as mentioned above. The densely built up urban area of the Greek capital sprawls across throughout the "Attica Basin" and has a total population of 3,074,160 (in 2011).

The Athens municipality forms the core and center of Greater Athens, which consists of the Athens municipality and 34 more municipalities, divided in four regional units (Central, North, South and West Athens), accounting for 2,641,511 people (in 2011) within an area of . Until 2010, these four regional units made up the abolished Athens Prefecture. The municipality of Piraeus, the historic Athenian port, with its 4 suburban municipalities make up the regional unit of Piraeus, which in turn forms Greater Piraeus.

Greater Athens and Greater Piraeus combined make up the continuous built up Athens Urban Area (), also called the Urban Area of the Capital () or simply Athens (the most common use of the term), spanning over , with a population of 3,090,508 people as of 2011. The Athens Urban Area is considered to form the city of Athens as a whole, despite its administrative divisions, which is the largest in Greece and one of the most populated urban areas in Europe.

The Athens Metropolitan Area spans within the Attica region and includes a total of 58 municipalities, which are organized in 7 regional units (those outlined above, along with East Attica and West Attica), having reached a population of 3,737,550 based on the preliminary results of the 2011 census. Athens and Piraeus municipalities serve as the two metropolitan centres of the Athens Metropolitan Area. There are also some inter-municipal centres serving specific areas. For example, Kifissia and Glyfada serve as inter-municipal centres for northern and southern suburbs respectively.

The municipality of Athens has an official population of 664,046 people. The four regional units that make up what is referred to as Greater Athens have a combined population of 2,640,701. They together with the regional unit of Piraeus (Greater Piraeus) make up the dense Athens Urban Area which reaches a total population of 3,090,508 inhabitants (in 2011). As Eurostat the FUA of Athens had in 2013 3,828,434 inhabitants, being apparently decreasing compared with the pre-economic crisis date of 2009 (4,164,175)

The municipality (City) of Athens is the most populous in Greece, with a population of 664,046 people (in 2011) and an area of , forming the core of the Athens Urban Area within the "Attica Basin". The current mayor of Athens is Giorgos Kaminis. The municipality is divided into seven municipal districts which are mainly used for administrative purposes.

As of the 2011 census, the population for each of the seven municipal districts of Athens is as follows:


For the Athenians the most popular way of dividing the city proper is through its neighbourhoods such as Pagkrati, Ambelokipi, Exarcheia, Patissia, Ilissia, Petralona, Koukaki and Kypseli, each with its own distinct history and characteristics.

The Athens Metropolitan Area, with an area of and inhabited by 3,753,783 people in 2011, consists of the Athens Urban Area with the addition of the towns and villages of East and West Attica, which surround the dense urban area of the Greek capital. It actually sprawls over the whole peninsula of Attica, which is the best part of the region of Attica, excluding the islands.

Mycenean Athens in 1600–1100 BCE could have reached the size of Tiryns; that would put the population at the range of 10,000 – 15,000. During the Greek Dark Ages the population of Athens was around 4,000 people. In 700 BC the population grew to 10,000. In 500 BCE the area probably contained 200,000 people. During the classical period the city's population is estimated from 150,000 – 350,000 and up to 610,000 according to Thucydides. When Demetrius of Phalerum conducted a population census in 317 BCE the population was 21,000 free citizens, plus 10,000 resident aliens and 400,000 slaves. This suggests a total population of 431,000. This figure is highly suspect because of the lopsided number of slaves and does not include free women and children and resident foreigners: an estimated based on Thucydides is: 40,000 male citizens, 100,000 family members, 70,000 metics (resident foreigners) and 150,000-400,000 slaves. However the numbers would include Attica and not just Athens the city, Urban History of Athens, 2008.

The ancient site of Athens is centred on the rocky hill of the acropolis. In ancient times the port of Piraeus was a separate city, but it has now been absorbed into the Athens Urban Area. The rapid expansion of the city, which continues to this day, was initiated in the 1950s and 1960s, because of Greece's transition from an agricultural to an industrial nation. The expansion is now particularly toward the East and North East (a tendency greatly related to the new Eleftherios Venizelos International Airport and the Attiki Odos, the freeway that cuts across Attica). By this process Athens has engulfed many former suburbs and villages in Attica, and continues to do so. The table below shows the historical population of Athens in recent times.

Athens became the capital of Greece in 1834, following Nafplion, which was the provisional capital from 1829. The municipality (City) of Athens is also the capital of the Attica region. The term "Athens" can refer either to the municipality of Athens, to Greater Athens, or to the entire Athens Urban Area.

Athens is twinned with:


The oldest known human presence in Athens is the Cave of Schist, which has been dated to between the 11th and 7th millennia BCE. Athens has been continuously inhabited for at least 7000 years.
By 1400 BCE the settlement had become an important centre of the Mycenaean civilization and the Acropolis was the site of a major Mycenaean fortress, whose remains can be recognised from sections of the characteristic Cyclopean walls. Unlike other Mycenaean centers, such as Mycenae and Pylos, it is not known whether Athens suffered destruction in about 1200 BCE, an event often attributed to a Dorian invasion, and the Athenians always maintained that they were "pure" Ionians with no Dorian element. However, Athens, like many other Bronze Age settlements, went into economic decline for around 150 years afterwards.

Iron Age burials, in the Kerameikos and other locations, are often richly provided for and demonstrate that from 900 BCE onwards Athens was one of the leading centres of trade and prosperity in the region. The leading position of Athens may well have resulted from its central location in the Greek world, its secure stronghold on the Acropolis and its access to the sea, which gave it a natural advantage over inland rivals such as Thebes and Sparta.

By the 6th century BCE, widespread social unrest led to the reforms of Solon. These would pave the way for the eventual introduction of democracy by Cleisthenes in 508 BCE. Athens had by this time become a significant naval power with a large fleet, and helped the rebellion of the Ionian cities against Persian rule. In the ensuing Greco-Persian Wars Athens, together with Sparta, led the coalition of Greek states that would eventually repel the Persians, defeating them decisively at Marathon in 490 BCE, and crucially at Salamis in 480 BCE. However, this did not prevent Athens from being captured and sacked twice by the Persians within one year, after a heroic resistance at Thermopylae by Spartans and other Greeks led by King Leonidas, after both Boeotia and Attica fell to the Persians.

The decades that followed became known as the Golden Age of Athenian democracy, during which time Athens became the leading city of Ancient Greece, with its cultural achievements laying the foundations for Western civilization. The playwrights Aeschylus, Sophocles and Euripides flourished in Athens during this time, as did the historians Herodotus and Thucydides, the physician Hippocrates, and the philosopher Socrates. Guided by Pericles, who promoted the arts and fostered democracy, Athens embarked on an ambitious building program that saw the construction of the Acropolis of Athens (including the Parthenon), as well as empire-building via the Delian League. Originally intended as an association of Greek city-states to continue the fight against the Persians, the league soon turned into a vehicle for Athens's own imperial ambitions. The resulting tensions brought about the Peloponnesian War (431–404 BCE), in which Athens was defeated by its rival Sparta.

By the mid-4th century BCE, the northern Greek kingdom of Macedon was becoming dominant in Athenian affairs. In 338 BCE the armies of Philip II defeated an alliance of some of the Greek city-states including Athens and Thebes at the Battle of Chaeronea, effectively ending Athenian independence. Later, under Rome, Athens was given the status of a free city because of its widely admired schools. The Roman emperor Hadrian, in the 2nd century CE, constructed a library, a gymnasium, an aqueduct which is still in use, several temples and sanctuaries, a bridge and financed the completion of the Temple of Olympian Zeus.

By the end of Late Antiquity, the city experienced decline followed by recovery in the second half of the Middle Byzantine Period, in the 9th to 10th centuries CE, and was relatively prosperous during the Crusades, benefiting from Italian trade. After the Fourth Crusade the Duchy of Athens was established. In 1458 it was conquered by the Ottoman Empire and entered a long period of decline.

Following the Greek War of Independence and the establishment of the Greek Kingdom, Athens was chosen as the capital of the newly independent Greek state in 1834, largely because of historical and sentimental reasons. At the time it was a town of modest size built around the foot of the Acropolis. The first King of Greece, Otto of Bavaria, commissioned the architects Stamatios Kleanthis and Eduard Schaubert to design a modern city plan fit for the capital of a state.

The first modern city plan consisted of a triangle defined by the Acropolis, the ancient cemetery of Kerameikos and the new palace of the Bavarian king (now housing the Greek Parliament), so as to highlight the continuity between modern and ancient Athens. Neoclassicism, the international style of this epoch, was the architectural style through which Bavarian, French and Greek architects such as Hansen, Klenze, Boulanger or Kaftantzoglou designed the first important public buildings of the new capital. In 1896, Athens hosted the first modern Olympic Games. During the 1920s a number of Greek refugees, expelled from Asia Minor after the Greco-Turkish War, swelled Athens's population; nevertheless it was most particularly following World War II, and from the 1950s and 1960s, that the population of the city exploded, and Athens experienced a gradual expansion.

In the 1980s it became evident that smog from factories and an ever-increasing fleet of automobiles, as well as a lack of adequate free space due to congestion, had evolved into the city's most important challenge. A series of anti-pollution measures taken by the city's authorities in the 1990s, combined with a substantial improvement of the city's infrastructure (including the Attiki Odos motorway, the expansion of the Athens Metro, and the new Athens International Airport), considerably alleviated pollution and transformed Athens into a much more functional city. In 2004 Athens hosted the 2004 Summer Olympics.

The city is a world centre of archaeological research. Along with national institutions, such as the Athens University and the Archaeological Society, there are multiple archaeological Museums including the National Archaeological Museum, the Cycladic Museum, the Epigraphic Museum, the Byzantine & Christian Museum, as well as museums at the ancient Agora, Acropolis, Kerameikos, and the Kerameikos Archaeological Museum. The city is also home to the Demokritos laboratory for Archaeometry, alongside regional and national archaeological authorities that form part of the Greek Department of Culture.

Athens hosts 17 Foreign Archaeological Institutes which promote and facilitate research by scholars from their home countries. As a result, Athens has more than a dozen archaeological libraries and three specialized archaeological laboratories, and is the venue of several hundred specialized lectures, conferences and seminars, as well as dozens of archaeological exhibitions, each year. At any given time, hundreds of international scholars and researchers in all disciplines of archaeology are to be found in the city.

Athens incorporates architectural styles ranging from Greco-Roman and Neoclassical to modern times. They are often to be found in the same areas, as Athens is not marked by a uniformity of architectural style.

For the greatest part of the 19th century Neoclassicism dominated Athens, as well as some deviations from it such as Eclecticism, especially in the early 20th century. Thus, the Old Royal Palace was the first important public building to be built, between 1836 and 1843. Later in the mid and late 19th century, Theophil Freiherr von Hansen and Ernst Ziller took part in the construction of many neoclassical buildings such as the Athens Academy and the Zappeion Hall. Ziller also designed many private mansions in the centre of Athens which gradually became public, usually through donations, such as Schliemann's Iliou Melathron.

Beginning in the 1920s, Modern architecture including Bauhaus and Art Deco began to exert an influence on almost all Greek architects, and buildings both public and private were constructed in accordance with these styles. Localities with a great number of such buildings include Kolonaki, and some areas of the centre of the city; neighbourhoods developed in this period include Kypseli.

In the 1950s and 1960s during the extension and development of Athens, other modern movements such as the International style played an important role. The centre of Athens was largely rebuilt, leading to the demolition of a number of neoclassical buildings. The architects of this era employed materials such as glass, marble and aluminium, and many blended modern and classical elements. After World War II, internationally known architects to have designed and built in the city included Walter Gropius, with his design for the US Embassy, and, among others, Eero Saarinen, in his postwar design for the east terminal of the Ellinikon Airport.

All over the city can be found several statues or busts. Apart from the neoclassicals by Leonidas Drosis at the Academy of Athens (Plato, Socrates, Apollo, Athena), other notable include the statue of Theseus by Georgios Fytalis at Thiseion, of philhellenes like Lord Byron, George Canning and William Gladstone, the equestrian statue of Theodoros Kolokotronis by Lazaros Sochos in front of the Old Parliament, statues of Ioannis Kapodistrias, Rigas Feraios and Adamantios Korais at the University, of Evangelos Zappas and Konstantinos Zappas at Zappeion, of Ioannis Varvakis at the National Garden, the "woodbreaker" by Dimitrios Filippotis, the equestrian statue of Alexandros Papagos at Papagou district and various busts of fighters of Greek independence at the Pedion tou Areos. An important landmark is also the Tomb of the Unknown Soldier in Syntagma.

Athens' most important museums include:

Athens has been a destination for travellers since antiquity. Over the past decade, the city's infrastructure and social amenities have improved, in part because of its successful bid to stage the 2004 Olympic Games. The Greek Government, aided by the EU, has funded major infrastructure projects such as the state-of-the-art Eleftherios Venizelos International Airport, the expansion of the Athens Metro system, and the new Attiki Odos Motorway.

Athens was voted as the third best European city to visit in 2015 by European Best Destination. More than 240,000 people voted.

Athens is home to 148 theatrical stages, more than any other city in the world, including the ancient Odeon of Herodes Atticus, home to the Athens Festival, which runs from May to October each year. In addition to a large number of multiplexes, Athens plays host to open air garden cinemas. The city also supports music venues, including the Athens Concert Hall ("Megaron Moussikis"), which attracts world class artists. The Athens Planetarium, located in Andrea Syngrou Avenue, is one of the largest and best equipped digital planetaria in the world. The Stavros Niarchos Foundation Cultural Center, inaugurated in 2016, will house the National Library of Greece and the Greek National Opera.

The most successful songs during the period 1870–1930 were the so-called Athenian serenades (Αθηναϊκές καντάδες), based on the Heptanesean kantádhes (καντάδες 'serenades'; sing.: καντάδα) and the songs performed on stage (επιθεωρησιακά τραγούδια 'theatrical revue songs') in revues, musical comedies, operettas and nocturnes that were dominating Athens' theatre scene.

Notable composers of operettas or nocturnes were Kostas Giannidis, Dionysios Lavrangas, Nikos Hatziapostolou, while Theophrastos Sakellaridis' "The Godson" remains probably the most popular operetta. Despite the fact that the Athenian songs were not autonomous artistic creations (in contrast with the serenades) and despite their original connection with mainly dramatic forms of Art, they eventually became hits as independent songs. Notable actors of Greek operettas, who made also a series of melodies and songs popular at that time, include Orestis Makris, Kalouta sisters, Vasilis Avlonitis, Afroditi Laoutari, Eleni Papadaki, Marika Nezer, Marika Krevata and others. After 1930, wavering among American and European musical influences as well as the Greek musical tradition. Greek composers begin to write music using the tunes of the tango, waltz, swing, foxtrot, some times combined with melodies in the style of Athenian serenades' repertory. Nikos Gounaris was probably the most renowned composer and singer of the time.

In 1923, after the population exchange between Greece and Turkey, many ethnic Greeks from Asia Minor fled to Athens as a result of the Greco-Turkish War. They settled in poor neighborhoods and brought with them Rebetiko music, making it popular also in Greece, which became later the base for the Laïko music. Other forms of song popular today in Greece are elafrolaika, entechno, dimotika, and skyladika. Greece's most notable, and internationally famous, composers of Greek song, mainly of the entechno form, are Manos Hadjidakis and Mikis Theodorakis. Both composers have achieved fame abroad for their composition of film scores.

Athens has a long tradition in sports and sporting events, serving as home to the most important clubs in Greek sport and housing a large number of sports facilities. The city has also been host to sports events of international importance.

Athens has hosted the Summer Olympic Games twice, in 1896 and 2004. The 2004 Summer Olympics required the development of the Athens Olympic Stadium, which has since gained a reputation as one of the most beautiful stadiums in the world, and one of its most interesting modern monuments. The biggest stadium in the country, it hosted two finals of the UEFA Champions League, in 1994 and 2007. Athens' other major stadium, located in the Piraeus area, is the Karaiskakis Stadium, a sports and entertainment complex, host of the 1971 UEFA Cup Winners' Cup Final.

Athens has hosted the Euroleague final three times, the first in 1985 and second in 1993, both at the Peace and Friendship Stadium, most known as SEF, a large indoor arena, and the third time in 2007 at the Olympic Indoor Hall. Events in other sports such as athletics, volleyball, water polo etc., have been hosted in the capital's venues.

Athens is home to three European multi-sport clubs: Olympiacos, Panathinaikos, AEK Athens. In football, Olympiacos have dominated the domestic competitions, Panathinaikos made it to the 1971 European Cup Final, while AEK Athens is the other member of the big three. These clubs also have basketball teams; Panathinaikos and Olympiacos are among the top powers in European basketball, having won the Euroleague six times and three respectively, whilst AEK Athens was the first Greek team to win a European trophy in any team sport.

Other notable clubs within Athens are Athinaikos, Panionios, Atromitos, Apollon, Panellinios, Ethnikos Piraeus, Maroussi BCE and Peristeri B.C.. Athenian clubs have also had domestic and international success in other sports.

The Athens area encompasses a variety of terrain, notably hills and mountains rising around the city, and the capital is the only major city in Europe to be bisected by a mountain range. Four mountain ranges extend into city boundaries and thousands of miles of trails criss-cross the city and neighbouring areas, providing exercise and wilderness access on foot and bike.

Beyond Athens and across the prefecture of Attica, outdoor activities include skiing, rock climbing, hang gliding and windsurfing. Numerous outdoor clubs serve these sports, including the Athens Chapter of the Sierra Club, which leads over 4,000 outings annually in the area.

Beside the above clubs, inside the boundaries of Athens municipality there are some more clubs with presence in national divisions or notable action for short periods. Some of them are PAO Rouf (Rouf) with earlier presence in Gamma Ethniki, Petralona F.C.() (Petralona), football club founded in 1963, with earlier presence in Beta Ethniki, Attikos F.C.() (Kolonos), football club founded in 1919 with short presence in Gamma Ethniki, Athinais Kypselis() (Kypseli), football club founded in 1938 with short presence in Gamma Ethniki, Gyziakos (Gyzi), basketball club founded in 1937 with short presence in Beta Ethniki basketball and Aetos B.C.() (Agios Panteleimonas), basketball club founded in 1992 with earlier presence in A2 Ethniki Basketball. Another important Athenian sport club is the Athens Tennis Club founded in 1895 with important offer for the Greek tennis.

1896 brought forth the revival of the modern Olympic Games, by Frenchman Pierre de Coubertin. Thanks to his efforts, Athens was awarded the first modern Olympic Games. In 1896, the city had a population of 123,000 and the event helped boost the city's international profile. Of the venues used for these Olympics, the Kallimarmaro Stadium, and Zappeion were most crucial. The Kallimarmaro is a replica of the ancient Athenian stadiums, and the only major stadium (in its capacity of 60,000) to be made entirely of white marble from Mount Penteli, the same material used for construction of the Parthenon.

The 1906 Summer Olympics, or the 1906 Intercalated games, were held in Athens. The intercalated competitions were intermediate games to the internationally organized Olympics, and were meant to be organized in Greece every four years, between the main Olympics. This idea later lost support from the IOC and these games were discontinued.

Athens was awarded the 2004 Summer Olympics on 5 September 1997 in Lausanne, Switzerland, after having lost a previous bid to host the 1996 Summer Olympics, to Atlanta, United States. It was to be the second time Athens would host the games, following the inaugural event of 1896. After an unsuccessful bid in 1990, the 1997 bid was radically improved, including an appeal to Greece's Olympic history. In the last round of voting, Athens defeated Rome with 66 votes to 41. Prior to this round, the cities of Buenos Aires, Stockholm and Cape Town had been eliminated from competition, having received fewer votes.

During the first three years of preparations, the International Olympic Committee had expressed concern over the speed of construction progress for some of the new Olympic venues. In 2000 the Organising Committee's president was replaced by Gianna Angelopoulos-Daskalaki, who was the president of the original Bidding Committee in 1997. From that point forward, preparations continued at a highly accelerated, almost frenzied pace.

Although the heavy cost was criticized, estimated at $1.5 billion, Athens was transformed into a more functional city that enjoys modern technology both in transportation and in modern urban development. Some of the finest sporting venues in the world were created in the city, all of which were fully ready for the games. The games welcomed over 10,000 athletes from all 202 countries.

The 2004 Games were judged a success, as both security and organization worked well, and only a few visitors reported minor problems mainly concerning accommodation issues. The 2004 Olympic Games were described as "Unforgettable, dream Games", by IOC President Jacques Rogge for their return to the birthplace of the Olympics, and for meeting the challenges of holding the Olympic Games. The only observable problem was a somewhat sparse attendance of some early events. Eventually, however, a total of more than 3.5 million tickets were sold, which was higher than any other Olympics with the exception of Sydney (more than 5 million tickets were sold there in 2000).

In 2008 it was reported that most of the Olympic venues had fallen into disrepair: according to those reports, 21 of the 22 facilities built for the games had either been left abandoned or are in a state of dereliction, with several squatter camps having sprung up around certain facilities, and a number of venues afflicted by vandalism, graffiti or strewn with rubbish. These claims, however, are disputed and likely to be inaccurate, as most of the facilities used for the Athens Olympics are either in use or in the process of being converted for post-Olympics use. The Greek Government has created a corporation, Olympic Properties SA, which is overseeing the post-Olympics management, development and conversion of these facilities, some of which will be sold off (or have already been sold off) to the private sector, while other facilities are still in use just as during the Olympics, or have been converted for commercial use or modified for other sports. Concerts and theatrical shows, such as those by the troupe Cirque du Soleil, have recently been held in the complex.

The 2011 Special Olympics World Summer Games was in Athens. The opening ceremony of the games took place on 25 June 2011 at the Panathinaiko Stadium and the closing ceremony was held on 4 July 2011.

Over 7,500 athletes, from 185 countries, competed in a total of 22 sports.

Athens is the financial capital of Greece, and multinational companies such as Ericsson, Siemens, Motorola and Coca-Cola have their regional research and development headquarters there.

Athens is serviced by a variety of transportation means, forming the largest mass transit system of Greece. The Athens Mass Transit System consists of a large bus fleet, a trolleybus fleet that mainly serves Athens's city center, the city's Metro, a commuter rail service and a tram network, connecting the southern suburbs to the city centre.

Ethel () (Etaireia Thermikon Leoforeion), or "Thermal Bus Company", is the main operator of buses in Athens. Its network consists of about 300 bus lines which span the Athens Metropolitan Area, with an operating staff of 5,327, and a fleet of 1,839 buses. Of those 1,839 buses 416 run on compressed natural gas, making up the largest fleet of natural gas-powered buses in Europe.

Besides being served by a fleet of natural-gas and diesel buses, the Athens Urban Area is also served by trolleybuses – or electric buses, as they are referred to in the name of the operating company. The network is operated by "Electric Buses of the Athens and Piraeus Region", or ILPAP () and consists of 22 lines with an operating staff of 1,137. All of the 366 trolleybuses are equipped to enable them to run on diesel in case of power failure.

International and regional bus links are provided by KTEL from two InterCity Bus Terminals, Kifissos Bus Terminal A and Liosion Bus Terminal B, both located in the north-western part of the city. "Kifissos" provides connections towards the Peloponnese and Attica, whereas "Liosion" is used for most northerly mainland destinations.

The Athens Metro is more commonly known in Greece as the Attiko Metro () and provides public transport throughout the Athens Urban Area. While its main purpose is transport, it also houses Greek artifacts found during construction of the system. The Athens Metro has an operating staff of 387 and runs two of the three metro lines; namely the Red (line 2) and Blue (line 3) lines, which were constructed largely during the 1990s, with the initial sections opened in January 2000. All routes run entirely underground and a fleet of 42 trains consisting of 252 cars operate within the network, with a daily occupancy of 550,000 passengers.

The Red Line (line 2) runs from Anthoupoli station to Elliniko station and covers a distance of . The line connects the western suburbs of Athens with the southeast suburbs passing through the center of Athens. The line associated with Green (line 1) stations at Attiki and Omonoia Square station. Also the line connected with the Blue (line 3) at Syntagma Square station and connected with Tram at Syntagma Square, Sygrou-Fix and Agios Ioannis station.

The Blue Line (line 3) runs from the western suburbs, namely Agia Marina to the Egaleo station, through the central Monastiraki and Syntagma stations to Doukissis Plakentias avenue in the northeastern suburb of Halandri, covering a distance of , then ascending to ground level and reaching Eleftherios Venizelos International Airport, using the Suburban Railway infrastructure and extending its length to . The spring 2007 extension from Monastiraki westwards, to Egaleo, connected some of the main night life hubs of the city, namely the ones of Gazi (Kerameikos station) with Psirri (Monastiraki station) and the city centre (Syntagma station). Extensions are under construction to the west southwest suburbs of Athens, reaching to the port and the center of Piraeus. The new stations will be Agia Barvara, Koridallos, Nikaia, Maniatika, Piraeus and Dimotiko Theatro station. The stations will be ready in 2017, connecting the biggest port of Greece Piraeus Port with the biggest airport of Greece the Athens International Airport.

Not run by the Athens Metro company, is the ISAP (), the "Electric Railway Company" line, which for many years served as Athens's primary urban rail transport. This is today the Green Line (line 1) of the Athens Metro network as shown on maps, and unlike the red and blue lines, ISAP has many above-ground sections on its route. This was the original metro line from Piraeus to Kifisia; serving 22 stations, with a network length of , an operating staff of 730 and a fleet of 44 trains and 243 cars. ISAP's occupancy rate is 600,000 passengers daily.

The Green Line (line 1) now serves 24 stations, and forms the oldest line of the Athens metro network and for the most part runs at ground level, connecting the port of Piraeus with the northern suburb of Kifissia. The line is set to be extended to Agios Stefanos, a suburb located to the north of Athens, reaching to .

The Athens Metropolitan Railway system is managed by three companies; namely ISAP (line 1), Attiko Metro (lines 2 & 3), while its commuter rail, the Proastiakós is considered as line 4.

The Athens commuter rail service, referred to as the "Proastiakós", connects Eleftherios Venizelos International Airport to the city of Kiato, west of Athens, via Larissa station, the city's central rail station and the port of Piraeus. The service is sometimes considered the fourth line of the Athens Metro. The length of Athens's commuter rail network extends to , and is expected to stretch to by 2010. The Proastiakos will be extended to Xylokastro west of Athens and Chalkida.

Athens Tram SA operates a fleet of 35 Sirio type vehicles which serve 48 stations, employ 345 people with an average daily occupancy of 65,000 passengers. The tram network spans a total length of and covers ten Athenian suburbs. The network runs from Syntagma Square to the southwestern suburb of Palaio Faliro, where the line splits in two branches; the first runs along the Athens coastline toward the southern suburb of Voula, while the other heads toward the Piraeus district of Neo Faliro. The network covers the majority of the Saronic coastline. Further extensions are planned towards the major commercial port of Piraeus. The expansion to Piraeus will include 12 new stations, increase the overall length of tram route by , and increase the overall transportation network.

Athens is served by the Athens International Airport (ATH), located near the town of Spata, in the eastern Messoghia plain, some east of Athens. The airport, awarded the "European Airport of the Year 2004" Award, is intended as an expandable hub for air travel in southeastern Europe and was constructed in 51 months, costing 2.2 billion euros. It employs a staff of 14,000.

The airport is served by the Metro, the suburban rail, buses to Piraeus port, Athens' city centre and its suburbs, and also taxis. The airport accommodates 65 landings and take-offs per hour, with its 24-passenger boarding bridges, 144 check-in counters and broader main terminal; and a commercial area of which includes cafés, duty-free shops, and a small museum.

In 2014, the airport handled 15,196,369 passengers, an increase of 21.2% over the previous year of 2013. Of those 15,196,369 passengers, 5,267,593 passed through the airport for domestic flights, and 9,970,006 passengers travelled through for international flights. Beyond the dimensions of its passenger capacity, ATH handled 205,294 total flights in 2007, or approximately 562 flights per day.

Athens is the hub of the country's national railway system (OSE), connecting the capital with major cities across Greece and abroad (Istanbul, Sofia and Bucharest).The Port of Piraeus connects Athens to the numerous Greek islands of the Aegean Sea, with ferries departing, while also serving the cruise ships that arrive.

Two main motorways of Greece begin in Athens, namely the A1/E75, which crosses through Athens's Urban Area from Piraeus, heading north towards Greece's second largest city, Thessaloniki; and the A8/E94 heading west, towards Patras, which incorporated the GR-8A. Before their completion much of the road traffic used the GR-1 and the GR-8.

Athens' Metropolitan Area is served by the motorway network of the Attiki Odos toll-motorway (code: A6). Its main section extends from the western industrial suburb of Elefsina to Athens International Airport; while two beltways, namely the Aigaleo Beltway (A65) and the Hymettus Beltway (A64) serve parts of western and eastern Athens respectively. The span of the Attiki Odos in all its length is , making it the largest metropolitan motorway network in all of Greece.

Located on Panepistimiou Street, the old campus of the University of Athens, the National Library, and the Athens Academy form the "Athens Trilogy" built in the mid-19th century. Most of the university's workings have been moved to a much larger, modern campus located in the eastern suburb of Zografou. The second higher education institution in the city is the Athens Polytechnic School, found in Patission Street. This was the location where on 17 November 1973, more than 13 students were killed and hundreds injured inside the university during the Athens Polytechnic uprising, against the military junta that ruled the nation from 21 April 1967 until 23 July 1974.

Other universities that lie within Athens are the Athens University of Economics and Business, the Panteion University, the Agricultural University of Athens and the University of Piraeus. There are overall eleven state-supported Institutions of Higher (or Tertiary) education located in the Metropolitan Area of Athens, these are by chronological order: Athens School of Fine Arts (1837), National Technical University of Athens (1837), National and Kapodistrian University of Athens (1837), Agricultural University of Athens (1920), Athens University of Economics and Business (1920), Panteion University of Social and Political Sciences (1927), University of Piraeus (1938), Technological Educational Institute of Piraeus (1976), Technological Educational Institute of Athens (1983), Harokopio University (1990), School of Pedagogical and Technological Education (2002). There are also several other private "colleges", as they called formally in Greece, as the establishment of private universities is prohibited by the constitution. Many of them are accredited by a foreign state or university such as the American College of Greece and the Athens Campus of the University of Indianapolis.







</doc>
<doc id="1217" url="https://en.wikipedia.org/wiki?curid=1217" title="Anguilla">
Anguilla

Anguilla ( ) is a British overseas territory in the Caribbean. It is one of the most northerly of the Leeward Islands in the Lesser Antilles, lying east of Puerto Rico and the Virgin Islands and directly north of Saint Martin. The territory consists of the main island of Anguilla, approximately long by wide at its widest point, together with a number of much smaller islands and cays with no permanent population. The island's capital is The Valley. The total land area of the territory is , with a population of approximately ( estimate).

Anguilla has become a popular tax haven, having no capital gains, estate, profit or other forms of direct taxation on either individuals or corporations. In April 2011, faced with a mounting deficit, it introduced a 3% "Interim Stabilisation Levy", Anguilla's first form of income tax.

The name Anguilla is an anglicised or latinate form of earlier Spanish "" meaning "eel" in reference to the island's shape. It is believed by most sources to have been named by Christopher Columbus. For similar reasons, it was also known as "Snake" or "Snake Island".

Anguilla was first settled by Indigenous Amerindian peoples who migrated from South America. The earliest Native American artefacts found on Anguilla have been dated to around 1300 ; remains of settlements date from  600. The Arawak name for the island seems to have been "Malliouhana". The date of European colonisation is uncertain: some sources claim that Columbus sighted the island during his second voyage in 1493, while others state that the island's first European explorer was the French Huguenot nobleman and merchant mariner René Goulaine de Laudonnière in 1564. The Dutch West India Company established a fort on the island in 1631. The Dutch withdraw after the destruction of the fort by Spanish forces in 1633.

Traditional accounts state that Anguilla was first colonised by English settlers from Saint Kitts beginning in 1650. In this early colonial period, however, Anguilla sometimes served as a place of refuge and recent scholarship focused on Anguilla has placed greater significance on other Europeans and creoles migrating from St. Christopher, Barbados, Nevis and Antigua. The French temporarily took over the island in 1666 but returned it to English control under the terms of the Treaty of Breda the next year. A Major John Scott who visited in September 1667, wrote of leaving the island "in good condition" and noted that in July 1668, "200 or 300 people fled thither in time of war".

It is likely that some of these early Europeans brought enslaved Africans with them. Historians confirm that African slaves lived in the region in the early 17th century. For example, Africans from Senegal lived in St. Christopher in 1626. By 1672 a slave depot existed on the island of Nevis, serving the Leeward Islands. While the time of African arrival in Anguilla is difficult to place precisely, archival evidence indicates a substantial African presence of at least 100 enslaved people by 1683. These seem to have come from Central Africa as well as West Africa.

Attempts by the French to capture the island during the War of Austrian Succession (1745) and the Napoleonic Wars (1796) ended in failure.

During the early colonial period, Anguilla was administered by the British through Antigua; in 1825, it was placed under the administrative control of nearby Saint Kitts. In 1967, Britain granted Saint Kitts and Nevis full internal autonomy. Anguilla was also incorporated into the new unified dependency, named Saint Christopher-Nevis-Anguilla, against the wishes of many Anguillians. This led to two Anguillian Revolutions in 1967 and 1969 headed by Atlin Harrigan and Ronald Webster. The island briefly operated as the independent "Republic of Anguilla". The goal of the revolution was not independence per se, but rather independence from Saint Kitts and Nevis and a return to being a British colony. British authority was fully restored in July 1971; in 1980, Anguilla was finally allowed to secede from Saint Kitts and Nevis and become a separate British Crown colony (now a British overseas territory).

On 7 September 2017, the Category 5 Hurricane Irma hit the island. As of the next day, one death had been reported; the island also sustained extensive damage to many buildings, including government ones, as well as its electricity infrastructure and water supply. The UK government summarised this as "severe and in places critical" damage. A few days later, Hurricane Jose largely bypassed Anguilla.

Anguilla is an internally self-governing overseas territory of the United Kingdom. Its politics take place in a framework of a parliamentary representative democratic dependency, whereby the Chief Minister is the head of government, and of a pluriform multi-party system.

The United Nations Committee on Decolonization includes Anguilla on the United Nations list of Non-Self-Governing Territories. The territory's constitution is Anguilla Constitutional Order 1 April 1982 (amended 1990). Executive power is exercised by the government. Legislative power is vested in both the government and the House of Assembly. The judiciary is independent of the executive and the legislature. 

As a dependency of the UK, the UK is responsible for Anguilla's military defence, although there are no active garrisons or armed forces present. Anguilla has a small marine police force, comprising around 32 personnel, which operates one VT Halmatic M160-class 52-foot fast patrol boat.

The majority of residents (90.08%) are black, the descendants of slaves transported from Africa. Minorities include whites at 3.74% and people of mixed race at 4.65% (figures from 2001 census).

72% of the population is Anguillian while 28% is non-Anguillian (2001 census). Of the non-Anguillian population, many are citizens of the United States, United Kingdom, St Kitts & Nevis, the Dominican Republic, Jamaica and Nigeria.

2006 and 2007 saw an influx of large numbers of Chinese, Indian and Mexican workers, brought in as labour for major tourist developments due to the local population not being large enough to support the labour requirements.

Christian churches did not have a consistent or strong presence during the initial period of English colonisation. Spiritual and religious practices of Europeans and Africans tended to reflect their regional origins. As early as 1813, Christian ministers formally ministered to enslaved Africans and promoted literacy among converts. The Wesleyan (Methodist) Missionary Society of England built churches and schools in 1817.

According to the 2001 census, Christianity is Anguilla's predominant religion, with 29 percent of the population practising Anglicanism. Another 23.9 percent are Methodist. Other churches on the island include Seventh-day Adventist, Baptist, Roman Catholic (served by the Roman Catholic Diocese of Saint John's - Basseterre, with see at Saint John on Antigua and Barbuda) and a community of Jehovah's Witnesses (0.7%). Between 1992 and 2001 the number of followers of the Church of God and Pentecostals increased considerably. There are at least 15 churches on the island. Although a minority on the island, it is an important location to followers of Rastafarian religion—Anguilla is the birthplace of Robert Athlyi Rogers, author of the "Holy Piby" which has had a strong influence on Rastafarian beliefs. Various other religions are practised as well. More recently, a Muslim cultural centre has opened on the island.

Today most people in Anguilla speak a British-influenced variety of standard English. Other languages are also spoken on the island, including varieties of Spanish, Chinese and the languages of other immigrants. However, the most common language other than Standard English is the island's own English-lexifier Creole language (not to be confused with Antillean Creole ('French Creole'), spoken in French islands such as Martinique and Guadeloupe). It is referred to locally by terms such as "dialect" (pronounced "dialek"), Anguilla Talk or "Anguillian". It has its main roots in early varieties of English and West African languages, and is similar to the dialects spoken in English-speaking islands throughout the Eastern Caribbean, in terms of its structural features and to the extent of being considered one single language.

Linguists who are interested in the origins of Anguillian and other Caribbean Creoles point out that some of its grammatical features can be traced to African languages while others can be traced to European languages. Three areas have been identified as significant for the identification of the linguistic origins of those forced migrants who arrived before 1710: the Gold Coast, the Slave Coast and the Windward Coast.

Sociohistorical information from Anguilla's archives suggest that Africans and Europeans formed two distinct, but perhaps overlapping speech communities in the early phases of the island's colonisation. "Anguillian" is believed to have emerged as the language of the masses as time passed, slavery was abolished and locals began to see themselves as "belonging" to Anguillian society.

There are six government primary schools, one government secondary school (Albena Lake Hodge Comprehensive School), and two private schools. There is a single library, the Edison L. Hughes Education & Library Complex of the Anguilla Public Library. A branch of the Saint James School of Medicine was established in 2011 in Anguilla. It is a private, for-profit medical school headquartered in Park Ridge, Illinois.

The Anguilla National Trust (ANT) was established in 1988 and opened its offices in 1993 charged with the responsibility of preserving the heritage of the island, including its cultural heritage. The Trust has programmes encouraging Anguillian writers and the preservation of the island's history. In 2015, "Where I See The Sun – Contemporary Poetry in Anguilla" A New Anthology by Lasana M. Sekou was published by House of Nehesi Publishers. Among the forty three poets in the unprecedented collection are Rita Celestine-Carty, Bankie Banx, John T. Harrigan, Patricia J. Adams, Fabian Fahie, Dr. Oluwakemi Linda Banks, and Reuel Ben Lewi.

The island's cultural history begins with the Taino Native Americans. Artifacts have been found around the island, telling of life before European settlers arrived by the Arawak and Carib peoples.

As throughout the Caribbean, holidays are a cultural fixture. Anguilla's most important holidays are of historic as much as cultural importance – particularly the anniversary of the emancipation (previously August Monday in the Park), celebrated as the Summer Festival. British festivities, such as the Queen's Birthday, are also celebrated.

Anguillian cuisine is influenced by native Caribbean, African, Spanish, French and English cuisines. Seafood is abundant, including prawns, shrimp, crab, spiny lobster, conch, mahi-mahi, red snapper, marlin and grouper. Salt cod is a staple food eaten on its own and used in stews, casseroles and soups. Livestock is limited due to the small size of the island and people there use poultry, pork, goat and mutton, along with imported beef. Goat is the most commonly eaten meat, used in a variety of dishes.

A significant amount of the island's produce is imported due to limited land suitable for agriculture production; much of the soil is sandy and infertile. Among the agriculture produced in Anguilla includes tomatoes, peppers, limes and other citrus fruits, onion, garlic, squash, pigeon peas and callaloo. Starch staple foods include imported rice and other foods that are imported or locally grown, including yams, sweet potatoes and breadfruit.

Due to its internationally recognised culinary community, the island has enjoyed a reputation as "the culinary capital of the Caribbean". This reputation was reinforced with the publication of the "(WE) Are Anguilla Cookbook", a guide to the cuisine of Anguilla featuring emerging and established local chefs, who share both their signature dishes and personal anecdotes regarding the island's epicurean culture. A publishing contract was secured by The Britto Agency, which had conceived the idea for the book itself.

The island's burgeoning musical community made history with the recording of "Sounds of Anguilla (Volume 1)", the first album ever composed solely of artists from a single Caribbean island representing multiple musical genres: pop, reggae, hip-hop, soca music and R&B. The album, featuring Anguillian musicians such as Bankie Banx, Amalia Watty, True Intentions and Gerswin Lake and The Parables, was released on iTunes in June 2015.

Boat racing has deep roots in Anguillian culture and is the national sport.
There are regular sailing regattas on national holidays, such as Carnival, which are contested by locally built and designed boats. These boats have names and have sponsors that print their logo on their sails.

As in many other former British colonies, cricket is also a popular sport. Anguilla is the home of Omari Banks, who played for the West Indies Cricket Team, while Cardigan Connor played first-class cricket for English county side Hampshire and was 'chef de mission' (team manager) for Anguilla's Commonwealth Games team in 2002.

Rugby union is represented in Anguilla by the Anguilla Eels RFC, who were formed in April 2006. The Eels have been finalists in the St. Martin tournament in November 2006 and semi-finalists in 2007, 2008, 2009 and Champions in 2010. The Eels were formed in 2006 by Scottish club national second row Martin Welsh, Club Sponsor and President of the AERFC Ms. Jacquie Ruan, and Canadian standout Scrumhalf Mark Harris (Toronto Scottish RFC).

Anguilla is also the birthplace of sprinter Zharnel Hughes who has represented Great Britain since 2015. He specialises in the 100m and 200m sprints. He won the 100m in the 2013 CARIFTA Games with a time of 10.44 seconds, despite his time being some way below his personal best. He currently holds the ISSA/GraceKennedy Boys' and Girls' Athletics Championships record for the 100m, with a time of 10.12 seconds having taken the record from Yohan Blake.[5][6] On 13 March 2015, Hughes made his Diamond League debut where he was commended for almost beating world champion Usain Bolt.[7] On 24 July 2015, Hughes won the 200m at the London Diamond League meet to take the lead in the Diamond League standings for the season.[8] On 27 August 2015, Hughes came 5th in the 200m at the World Championships in Beijing with a time of 20.02 seconds.

Shara Proctor, British Long Jump Silver Medalist in World Championships in Beijing first represented Anguilla in the event until 2010 when she began to represent the UK. Under the Anguillian Flag she achieved several medals in the NACAC games.

Keith Connor, triple jumper, is also an Anguillian. He represented Great Britain and achieved several international titles including Commonwealth and European Games gold medals and an Olympic bronze medal. Keith later became Head Coach of Australia Athletics.

Chesney Hughes, is a West Indian cricketer who plays for Derbyshire. He was born in Anguilla. Having signed for the side in June 2009, and holding a British passport, Hughes made his List A debut for the side during the 2009 Pro40 League against Warwickshire.

Anguilla has habitat for the Cuban tree frogs ("Osteopilus septentrionalis"). The red-footed tortoise ("Chelonoidis carbonaria") is a species of tortoise found here, it somehow came from South America. Hurricanes led to over-water dispersal for the green iguanas ("Iguana iguana") to colonise Anguilla. All three animals are introduced.

Five species of bats are known in the literature from Anguilla – the threatened insular single leaf bat ("Monophyllus plethodon"), the Antillean fruit-eating bat ("Brachyphylla cavernarum"), the Jamaican fruit bat ("Artibeus jamaicensis"), the Mexican funnel-eared bat ("Natalus stramineus"), and the velvety free-tailed bat ("Molossus molossus").

Anguilla is a flat, low-lying island of coral and limestone in the Caribbean Sea, east of Puerto Rico and the Virgin Islands. It is directly north of Saint Martin, separated from that island by the Anguilla Channel. The soil is generally thin and poor, supporting scrub, tropical and forest vegetation.

Anguilla is noted for its spectacular and ecologically important coral reefs and beaches. Apart from the main island of Anguilla itself, the territory includes a number of other smaller islands and cays, mostly tiny and uninhabited. Some of these are:

Anguilla has a volcanic origin and has been submerged repeatedly from climate change.

Northeastern trade winds keep this tropical island relatively cool and dry. Average annual temperature is . July–October is its hottest period, December–February, its coolest.

Rainfall averages annually, although the figures vary from season to season and year to year. The island is subject to both sudden tropical storms and hurricanes, which occur in the period from July to November. The island suffered damage in 1995 from Hurricane Luis and severe flooding 5–20 feet from Hurricane Lenny.

Anguilla's thin arid soil being largely unsuitable for agriculture, the island has few land-based natural resources. Its main industries are tourism, offshore incorporation and management, offshore banking, captive insurance and fishing.

Before the 2008 worldwide crisis the economy of Anguilla was expanding rapidly, especially the tourism sector which was driving major new developments in partnerships with multi-national companies.

Anguilla's currency is the East Caribbean dollar, though the US dollar is also widely accepted. The exchange rate is fixed to the US dollar at US$1 = EC$2.70.

The economy, and especially the tourism sector, suffered a setback in late 1995 due to the effects of Hurricane Luis in September but recovered in 1996. Hotels were hit particularly hard during this time. Another economic setback occurred during the aftermath of Hurricane Lenny in 2000.

Anguilla's financial system comprises 7 banks, 2 money services businesses, more than 40 company managers, more than 50 insurers, 12 brokers, more than 250 captive intermediaries, more than 50 mutual funds and 8 trust companies.

Anguilla's tourism industry received a major boost when it was selected to host the World Travel Awards in December 2014. Known as "the Oscars of the travel industry", the awards ceremony was held at the CuisinArt Resort and Spa and was hosted by award-winning actress Vivica A. Fox. Anguilla was voted the World's Leading Luxury Island Destination from a short list of top-tier candidates such as St. Barts, Maldives and Mauritius.

Anguilla aims to obtain 15% of its energy from solar power so it is less reliant on expensive imported diesel. The Climate & Development Knowledge Network is helping the government gather the information it needs to change the territory's legislation, so it can integrate renewables into its grid. Barbados, have also made good progress in switching to renewables, but many other SIDS are still at the early stages of planning how to integrate renewable energy into their grids. "For a small island we're very far ahead," said Beth Barry, Coordinator of the Anguilla Renewable Energy Office. "We've got an Energy Policy and a draft Climate Change policy and have been focussing efforts on the question of sustainable energy supply for several years now. As a result, we have a lot of information we can share with other islands."

Anguilla is served by Clayton J. Lloyd International Airport (prior to 4 July 2010 known as Wallblake Airport). The primary runway at the airport is in length and can accommodate moderate-sized aircraft. Services connect to various other Caribbean islands via regional carrier LIAT, local charter airlines and others. Although there are no direct scheduled flights to or from continental America or Europe, Tradewind Aviation and Cape Air provide scheduled air service to San Juan, Puerto Rico. The airport can handle large narrow-body jets such as the Boeing 727, Boeing 737 and Boeing 757.

Aside from taxis, there is no public transport on the island. Cars drive on the left.

There are regular ferries from Saint Martin to Anguilla. It is a 20-minute crossing from Marigot, St. Martin to Blowing Point, Anguilla. Ferries commence service from 7:00 am. There is also a Charter Service, from Blowing Point, Anguilla to Princess Juliana Airport to make travel easier. This way of travel is the most common method of transport between Anguilla and St. Martin or St. Maarten.






</doc>
<doc id="1223" url="https://en.wikipedia.org/wiki?curid=1223" title="Telecommunications in Anguilla">
Telecommunications in Anguilla

This article is about communications systems in Anguilla.

Telephones - main lines in use: 6,200 (2002)

Telephones - mobile cellular: 1,800 (2002)

Telephone system:
<br>"Domestic:" Modern internal telephone system
<br>"International:" EAST CARIBBEAN FIBRE SYSTEM ECFS (cable system)
" microwave radio relay to island of Saint Martin (Guadeloupe and Netherlands Antilles)

Mobile Phone Operators:

Mobiles: ? (2007)

Radio broadcast stations: AM 3, FM 7, shortwave 0 (2007)
Radios: 3,000 (1997)

Television broadcast stations: 1 (1997)

Televisions: 1,000 (1997)

Internet country code: .ai (Top level domain)

Internet Service Providers (ISPs): 3 (Cable & Wireless - , Weblinks - , Caribbean Cable Communications - )

Internet hosts: 205 (2008)

Internet: users: 3,000 (2002)



</doc>
<doc id="1227" url="https://en.wikipedia.org/wiki?curid=1227" title="Ashmore and Cartier Islands">
Ashmore and Cartier Islands

The Territory of Ashmore and Cartier Islands is an uninhabited external territory of Australia consisting of four low-lying tropical islands in two separate reefs, and the 12 nautical mile territorial sea generated by the islands. The territory is located in the Indian Ocean situated on the edge of the continental shelf, about off the northwest coast of Australia and south of the Indonesian island of Rote.

Ashmore Reef is called "Pulau Pasir" by Indonesians and it is called "Nusa Solokaek" in the Rotenese language. Both names have the meaning "sand island".

The Territory comprises Ashmore Reef, which includes West, Middle, and East Islands, and two lagoons, and Cartier Reef, which includes Cartier Island. Ashmore Reef covers approximately and Cartier Reef , both to the limits of the reefs. They have a total of of shoreline, measured along the outer edge of the reef. Australia also claims a 12 nautical mile territorial sea generated by the islands.

West, Middle, and East Islands have a combined land area variously reported as 54 ha, 93 ha, and 112 ha (1 hectare is 0.01 km, or about 2.5 acres). Cartier Island has a reported land area of 0.4 ha.

By a British Order-in-council dated 23 July 1931, Ashmore and Cartier Islands were placed under the authority of the Commonwealth of Australia, but Australia officially accepted the Territory on 10 May 1934 when the "Ashmore and Cartier Islands Acceptance Act 1933" came into operation. The Act authorised the Governor of Western Australia to make Ordinances for the Territory. In July 1938 the Territory was annexed to the Northern Territory, then also administered by the Commonwealth, whose laws, ordinances and regulations applied to the Territory. When self-government was granted to the Northern Territory on 1 July 1978, administration of the Territory was retained by the Commonwealth.

Due to its proximity to Indonesia, and the area being traditional fishing grounds of Indonesian fishermen for centuries, some Indonesian groups claim Ashmore Reef to be part of Rote Ndao Regency of East Nusa Tenggara province. However, the Indonesian government does not appear to actively contest Australia's sovereignty of the Territory. Australia's sovereignty is backed up by the fact that the Territory was not administered by the Netherlands (Indonesia's former colonial power), but by the British before it was transferred to Australia.

In 1983 the Territory was declared a nature reserve under the "National Parks and Wildlife Conservation Act 1975", now replaced by the "Environment Protection and Biodiversity Conservation Act 1999".

After the islands became a first point of contact with the Australian migration zone, in September 2001, the Australian government excised the Ashmore and Cartier Islands from the Australian migration zone.

Today, the Territory is administered from Canberra by the Department of Infrastructure, Regional Development and Cities, which is also responsible for the administration of the territories of Christmas Island, Cocos (Keeling) Islands, the Coral Sea Islands, Jervis Bay Territory and Norfolk Island.

The Attorney-General's Department had been responsible for the administration of Australian territories until the 2010 federal election. In that year the responsibility for Australian territories was transferred to the then Department of Regional Australia, Local Government, Arts and Sport, and from 18 September 2013 the Department of Infrastructure and Regional Development has administered Australian territories.

Defence of Ashmore and Cartier Islands is the responsibility of Australia, with periodic visits by the Royal Australian Navy, Royal Australian Air Force and Australian Customs and Border Protection Service.

Nearby Hibernia Reef, northeast of Ashmore Reef, is not part of the Territory, but belongs to Western Australia. It has no permanently dry land area, although large parts of the reef become exposed during low tide.

The Ashmore Reef Commonwealth Marine Reserve (formerly Ashmore Reef National Nature Reserve), established in August 1983, comprises an area of approximately . It is of significant biodiversity value as it is in the flow of the Indonesian Throughflow ocean current from the Pacific Ocean through Maritime Southeast Asia to the Indian Ocean. It is also in a surface current west from the Arafura Sea and Timor Sea.

The Reserve comprises several marine habitats, including seagrass meadows, intertidal sand flats, coral reef flats, and lagoons, and supports an important and diverse range of species, including 14 species of sea snakes, a population of dugong that may be genetically distinct, a diverse marine invertebrate fauna, and many endemic species, especially of sea snakes and molluscs. There are feeding and nesting sites for loggerhead, hawksbill and green turtles. It is classified as an Important Bird Area and has 50,000 breeding pairs of various kinds of seabirds. A high abundance and diversity of sea cucumbers, over-exploited on other reefs in the region, is present, with 45 species recorded.

In 2003 the nature reserve was recognised as a wetland of international importance due to the importance of its islands providing a resting place for migratory shorebirds and supporting large seabird breeding colonies. It was designated Ramsar Site 1220 under the Ramsar Convention on Wetlands.

The Cartier Island Commonwealth Marine Reserve (formerly Cartier Island Marine Reserve) was established in June 2000, and comprises an area of approximately , within a 4 nautical mile radius from the center of Cartier Island, and extends to a depth of below the sea floor. It includes the reef around Cartier island, a small submerged pinnacle called Wave Governor Bank, and two shallow pools to the island's northeast. The Reserve is part of the North-west Commonwealth Marine Reserve Network.

There is no economic activity in the Territory, Ashmore and Cartier Islands being uninhabited. Cartier Island is an unvegetated sand island. Access to Cartier Island is prohibited because of the risk of unexploded ordnances. There are no ports or harbours, only offshore anchorage. The customs vessel ACV "Ashmore Guardian" is stationed off the reef for up to 330 days per year. The islands are also visited by seasonal caretakers and occasional scientific researchers.

The area has been a traditional fishing ground of Indonesian fishermen for centuries, and continues. In the 1850s, American whalers operated in the region. Mining of phosphate deposits took place on Ashmore Island in the latter half of the 19th century. Today, all the wells in the Territory are infected with cholera or contaminated and undrinkable.

Petroleum extraction activities take place at the Jabiru and Challis oil fields, which are adjacent to the Territory, and which are administered by the Northern Territory Department of Mines and Energy on behalf of the Commonwealth.

As Ashmore Reef is the closest point of Australian territory to Indonesia, it was a popular target for people smugglers transporting asylum seekers en route to Australia. Once they had landed on Ashmore Island, asylum seekers could claim to have entered Australian migration zone and request to be processed as refugees. The use of Ashmore Island for this purpose created great notoriety during late 2001, when refugee arrivals became a major political issue in Australia. The Australian Government argued that as Australia was not the country of first asylum for these "boat people", Australia did not have a responsibility to accept them.

A number of things were done to discourage the use of the Territory for this purpose, such as attempting to have the people smugglers arrested in Indonesia; the so-called Pacific Solution of processing them in third countries; the boarding and forced turnaround of the boats by Australian military forces; and finally excising the Territory and many other small islands from the Australian migration zone.

Two boatloads of asylum seekers were each detained for several days in the lagoon at Ashmore Island after failed attempts by the Royal Australian Navy to turn them back to Indonesia in October 2001.




</doc>
<doc id="1234" url="https://en.wikipedia.org/wiki?curid=1234" title="Acoustic theory">
Acoustic theory

Acoustic theory is a scientific field that relates to the description of sound waves. It derives from fluid dynamics. See acoustics for the engineering approach.

Propagation of sound waves in a fluid (such as water) can be modeled by an equation of continuity (conservation of mass) and an equation of motion (conservation of momentum) . With some simplifications, in particular constant density, they can be given as follows:
where formula_2 is the acoustic pressure and formula_3 is the flow velocity vector, formula_4 is the vector of spatial coordinates formula_5, formula_6 is the time, formula_7 is the static mass density of the medium and formula_8 is the bulk modulus of the medium. The bulk modulus can be expressed in terms of the density and the speed of sound in the medium (formula_9) as
If the flow velocity field is irrotational, formula_11, then the acoustic wave equation is a combination of these two sets of balance equations and can be expressed as
where we have used the vector Laplacian, formula_13
The acoustic wave equation (and the mass and momentum balance equations) are often expressed in terms of a scalar potential formula_14 where formula_15. In that case the acoustic wave equation is written as
and the momentum balance and mass balance are expressed as

The derivations of the above equations for waves in an acoustic medium are given below.

The equations for the conservation of linear momentum for a fluid medium are
where formula_19 is the body force per unit mass, formula_20 is the pressure, and formula_21 is the deviatoric stress. If formula_22 is the Cauchy stress, then
where formula_24 is the rank-2 identity tensor.

We make several assumptions to derive the momentum balance equation for an acoustic medium. These assumptions and the resulting forms of the momentum equations are outlined below.

In acoustics, the fluid medium is assumed to be Newtonian. For a Newtonian fluid, the deviatoric stress tensor is related to the flow velocity by
where formula_26 is the shear viscosity and formula_27 is the bulk viscosity.

Therefore, the divergence of formula_21 is given by
Using the identity formula_30, we have
The equations for the conservation of momentum may then be written as

For most acoustics problems we assume that the flow is irrotational, that is, the vorticity is zero. In that case
and the momentum equation reduces to

Another frequently made assumption is that effect of body forces on the fluid medium is negligible. The momentum equation then further simplifies to

Additionally, if we assume that there are no viscous forces in the medium (the bulk and shear viscosities are zero), the momentum equation takes the form

An important simplifying assumption for acoustic waves is that the amplitude of the disturbance of the field quantities is small. This assumption leads to the linear or small signal acoustic wave equation. Then we can express the variables as the sum of the (time averaged) mean field (formula_37) that varies in space and a small fluctuating field (formula_38) that varies in space and time. That is
and
Then the momentum equation can be expressed as
Since the fluctuations are assumed to be small, products of the fluctuation terms can be neglected (to first order) and we have

Next we assume that the medium is homogeneous; in the sense that the time averaged variables
formula_43 and formula_44 have zero gradients, i.e.,
The momentum equation then becomes

At this stage we assume that the medium is at rest, which implies that the mean flow velocity is zero, i.e., formula_47. Then the balance of momentum reduces to
Dropping the tildes and using formula_49, we get the commonly used form of the acoustic momentum equation

The equation for the conservation of mass in a fluid volume (without any mass sources or sinks) is given by
where formula_52 is the mass density of the fluid and formula_53 is the flow velocity.

The equation for the conservation of mass for an acoustic medium can also be derived in a manner similar to that used for the conservation of momentum.

From the assumption of small disturbances we have
and
Then the mass balance equation can be written as
If we neglect higher than first order terms in the fluctuations, the mass balance equation becomes

Next we assume that the medium is homogeneous, i.e.,
Then the mass balance equation takes the form

At this stage we assume that the medium is at rest, i.e., formula_47. Then the mass balance equation can be expressed as

To close the system of equations we need an equation of state for the pressure. To do that we assume that the medium is an ideal gas and all acoustic waves compress the medium in an adiabatic and reversible manner. The equation of state can then be expressed in the form of the differential equation:
where formula_63 is the specific heat at constant pressure, formula_64 is the specific heat at constant volume, and formula_65 is the wave speed. The value of formula_66 is 1.4 if the acoustic medium is air.

For small disturbances
where formula_9 is the speed of sound in the medium.

Therefore,
The balance of mass can then be written as
Dropping the tildes and defining formula_71 gives us the commonly used expression for the balance of mass in an acoustic medium:

If we use a cylindrical coordinate system formula_73 with basis vectors formula_74, then the gradient of formula_20 and the divergence of formula_76 are given by
where the flow velocity has been expressed as formula_78.

The equations for the conservation of momentum may then be written as
In terms of components, these three equations for the conservation of momentum in cylindrical coordinates are

The equation for the conservation of mass can similarly be written in cylindrical coordinates as

The acoustic equations for the conservation of momentum and the conservation of mass are often expressed in time harmonic form (at fixed frequency). In that case, the pressures and the flow velocity are assumed to be time harmonic functions of the form
where formula_83 is the frequency. Substitution of these expressions into the governing equations in cylindrical coordinates gives us the fixed frequency form of the conservation of momentum
and the fixed frequency form of the conservation of mass

In the special case where the field quantities are independent of the z-coordinate we can eliminate formula_86 to get
Assuming that the solution of this equation can be written as
we can write the partial differential equation as
The left hand side is not a function of formula_90 while the right hand side is not a function of formula_91. Hence,
where formula_93 is a constant. Using the substitution
we have
The equation on the left is the Bessel equation, which has the general solution
where formula_97 is the cylindrical Bessel function of the first kind and formula_98 are undetermined constants. The equation on the right has the general solution
where formula_100 are undetermined constants. Then the solution of the acoustic wave equation is
Boundary conditions are needed at this stage to determine formula_102 and the other undetermined constants.



</doc>
<doc id="1235" url="https://en.wikipedia.org/wiki?curid=1235" title="Alexander Mackenzie (politician)">
Alexander Mackenzie (politician)

Alexander Mackenzie, PC (January 28, 1822April 17, 1892), was a Scottish-Canadian politician who served as the second Prime Minister of Canada, in office from 1873 to 1878.

Mackenzie was born in Logierait, Perthshire, Scotland. He left school at the age of 13, following his father's death, and trained as a stonemason. Mackenzie immigrated to Canada when he was 20, settling in what became Ontario. His masonry business prospered, allowing him to pursue other interests – such as the editorship of a pro-Reformist newspaper. Mackenzie was elected to the Legislative Assembly of the Province of Canada in 1861, as a supporter of George Brown.

In 1867, Mackenzie was elected to the new Canadian House of Commons for the Liberal Party. He became leader of the party (and thus Leader of the Opposition) in mid-1873, and a few months later succeeded John A. Macdonald as prime minister, following Macdonald's resignation in the aftermath of the Pacific Scandal. Mackenzie and the Liberals won a clear majority at the 1874 election. He was popular among the general public for his humble background and apparent democratic tendencies.

As prime minister, Mackenzie continued the nation-building programme that had been begun by his predecessor. His government established the Supreme Court of Canada and Royal Military College of Canada, and created the District of Keewatin to better administer Canada's newly acquired western territories. However, it made little progress on the transcontinental railway, and struggled to deal with the aftermath of the Panic of 1873. At the 1878 election, Mackenzie's government suffered a landslide defeat. He remained leader of the Liberal Party for another two years, and continued on as a member of parliament until his death, due to a stroke.

Mackenzie was born on 28 January 1822 in Logierait, Perthshire, Scotland, the son of Mary Stewart (Fleming) and Alexander Mackenzie Sr. who were married in 1817. The site of his birthplace is known as Clais-'n-deoir "The Hollow of the Weeping", where families said their goodbyes as the convicted were led to nearby Gallows Hill. The house he was born in was built by his father and is still standing in 2017. He was the third of ten boys, seven of who survived infancy. Alexander Mackenzie Sr. was a carpenter and ship's joiner who had to move around frequently for work after the end of the Napoleonic Wars in 1815. Mackenzie's father died on 7 March 1836 and at the age of thirteen Alexander Mackenzie Jr. was thus forced to end his formal education in order to help support his family. He apprenticed as a stonemason and met his future wife, Helen Neil, in Irvine, where her father was also a stonemason. The Neils were Baptist and shortly thereafter, Mackenzie converted from Presbyterianism to Baptist beliefs. Together with the Neils, he immigrated to Canada in 1842 to seek a better life. Mackenzie's faith was to link him to the increasingly influential temperance cause, particularly strong in Canada West where he lived, a constituency of which he was to represent in the Parliament of Canada.

The Neils and Mackenzie settled in Kingston, Ontario. The limestone in the area proved too hard for his stonemason tools and, not having money to buy new tools, Mackenzie took a job as a labourer constructing a building on Princess Street. The contractor on the job claimed financial difficulty and so Mackenzie accepted a promissory note for summer wages. The note later proved to be worthless. Subsequently, Mackenzie won a contract building a bomb-proof arch at Fort Henry. He later became a foreman on the construction of Kingston's four Martello Towers - Murney Tower, Fort Frederick, Cathcart Tower, and Shoal Tower. He was also a foreman on the construction of the Welland Canal and the Lachine Canal. While working on the Beauharnois Canal a one-ton stone fell and crushed one of his legs. He recovered but never regained the strength in that leg. It was while in Kingston that Mackenzie became a vocal opponent of religious and political entitlement and corruption in government.

Mackenzie married Helen Neil (1826–52) in 1845 and with her had three children, with only one girl, Mary, surviving infancy. He and Helen moved to Sarnia, Ontario (known as Canada West) in 1847 and Mary was born in 1848. They were soon joined from Scotland by the rest of Mackenzie's brothers and his mother. He began working as a general contractor, earning a reputation for being a hard working, honest man as well as having a working man's view on fiscal policy. Mackenzie helped construct many courthouses and jails across southern Ontario. A number of these still stand today including the Sandwich Courthouse and Jail now known as the Mackenzie Hall Cultural Centre in Windsor, Ontario and the Kent County Courthouse and Jail in Chatham, Ontario. He even bid, unsuccessfully, on the construction of the Parliament Buildings in Ottawa in 1859. Helen died in 1852, finally succumbing to the effects of excessive doses of mercury-based calomel used to treat a fever while in Kingston. In 1853, he married Jane Sym (1825–93).

Mackenzie involved himself in politics almost from the moment he arrived in Canada. He fought passionately for equality and the elimination of all forms of class distinction. In 1851 he became the Secretary for the Reform Party for Lambton. After convincing him to run in Kent/Lambton, Mackenzie campaigned relentlessly for George Brown, owner of the Reformist paper "The Globe" in the 1851 election, helping Brown to win his first seat in the Legislative Assembly. Mackenzie and Brown remained the closest of friends and colleagues for the rest of their lives. In 1852 Mackenzie became editor of another reformist paper, the Lambton Shield. As editor, Mackenzie was perhaps a little too vocal, leading the paper to a lawsuit for libel against the local conservative candidate. Because a key witness claimed Cabinet Confidence and would not testify, the paper lost the suit and was forced to fold due to financial hardship. After his brother, Hope Mackenzie, declined to run, Alexander was petitioned to run and won his first seat in the Legislative Assembly as a supporter of George Brown in 1861. When George Brown resigned from the Great Coalition in 1865 over reciprocity negotiations with the United States, Mackenzie was invited to replace him as the President of the Council. Wary of Macdonald's motivations and true to his principles, Mackenzie declined.

He entered the Canadian House of Commons in 1867, representing the Lambton, Ontario, riding. There was no cohesive national Liberal Party of Canada at the time and with George Brown not winning his seat, there was no official leader. Mackenzie did not believe he was the best qualified for the position and although he resisted offers of the position, he nevertheless sat as the de facto leader of the Official Opposition.

When the Macdonald government fell due to the Pacific Scandal in 1873, the Governor General, Lord Dufferin, called upon Mackenzie, who had been chosen as the leader of the Liberal Party a few months earlier, to form a new government. Mackenzie formed a government and asked the Governor General to call an election for January 1874. The Liberals won, having garnered 53.8% of the popular vote. The voter support of 53.8% remains the record in Canada for all federal elections. Mackenzie remained prime minister until the 1878 election when Macdonald's Conservatives returned to power with a majority government.

It was unusual for a man of Mackenzie's humble origins to attain such a position in an age which generally offered such opportunity only to the privileged. Lord Dufferin, the current Governor General, expressed early misgivings about a stonemason taking over government. But on meeting Mackenzie, Dufferin revised his opinions: "However narrow and inexperienced Mackenzie may be, I imagine he is a thoroughly upright, well-principled, and well-meaning man."

Mackenzie served concurrently as Minister of Public Works and oversaw the completion of the Parliament Buildings. While drawing up the plans for the West Block, he included a circular staircase leading directly from his office to the outside of the building which allowed him to escape the patronage-seekers waiting for him in his ante-chamber. Proving Dufferin's reflections on his character to be true, Mackenzie disliked intensely the patronage inherent in politics. Nevertheless, he found it a necessary evil in order to maintain party unity and ensure the loyalty of his fellow Liberals.

As Prime Minister, Alexander Mackenzie strove to reform and simplify the machinery of government, achieving a remarkable record of reform legislation. He introduced the secret ballot; advised the creation of the Supreme Court of Canada; the establishment of the Royal Military College of Canada in Kingston in 1874; and, the creation of the Office of the Auditor General in 1878. He completed the Intercolonial Railway but struggled to progress on the national railway due to a worldwide economic depression, almost coming to blows with the then Governor General Lord Dufferin over imperial interference. Mackenzie stood up for the rights of Canada as a nation and fought for the supremacy of Parliament and honesty in government. Above all else, he was known and loved for his honesty and integrity.

However, his term was marked by economic depression that had grown out of the Panic of 1873, which Mackenzie's government was unable to alleviate. In 1874, Mackenzie negotiated a new free trade agreement with the United States, eliminating the high protective tariffs on Canadian goods in US markets. However, this action did not bolster the economy, and construction of the CPR slowed drastically due to lack of funding. In 1876 the Conservative opposition announced a National Policy of protective tariffs, which resonated with voters. When an election was held at the conclusion of Mackenzie's five-year term, the Conservatives were swept back into office in a landslide victory.

Mackenzie chose the following jurists to be appointed as justices of the Supreme Court of Canada by the Governor General:

After his government's defeat, Mackenzie remained Leader of the Opposition for another two years, until 1880. He was soon struck with a mysterious ailment that sapped his strength and all but took his voice. Sitting in silence, he nevertheless remained an undefeated MP until his death in 1892 from a stroke that resulted from hitting his head during a fall. He died in Toronto and was buried in Lakeview Cemetery in Sarnia, Ontario.

In their 1999 study of the Prime Ministers of Canada, which included the results of a survey of Canadian historians, J.L. Granatstein and Norman Hillmer found that Mackenzie was in the No. 11 place just after John Sparrow David Thompson.

The following are named in honour of Alexander Mackenzie:






 


</doc>
<doc id="1239" url="https://en.wikipedia.org/wiki?curid=1239" title="Ashoka">
Ashoka

Ashoka (; ; died 232 BCE), or Ashoka the Great, was an Indian emperor of the Maurya Dynasty, who ruled almost all of the Indian subcontinent from to 232 BCE. He was the grandson of the founder of the Maurya Dynasty, Chandragupta Maurya, who had created one of the largest empires in ancient India and then, according to Jain sources, renounced it all to become a Jain monk. One of India's greatest emperors, Ashoka expanded Chandragupta's empire, and reigned over a realm that stretched from present-day Afghanistan in the west to Bangladesh in the east. It covered the entire Indian subcontinent except for parts of present-day Tamil Nadu, Karnataka and Kerala. The empire's capital was Pataliputra (in Magadha, present-day Patna), with provincial capitals at Taxila and Ujjain.

In about 260 BCE, Ashoka waged a destructive war against the state of Kalinga (modern Odisha). He conquered Kalinga, which none of his ancestors had done. Some scholars suggest he belonged to the Jain tradition, but it is generally accepted that he embraced Buddhism. Legends state he converted after witnessing the mass deaths of the Kalinga War, which he himself had waged out of a desire for conquest. "Ashoka reflected on the war in Kalinga, which reportedly had resulted in more than 100,000 deaths and 150,000 deportations, ending at around 200,000 deaths." Ashoka converted to Buddhism about 263 BCE. He is remembered for the Ashoka pillars and edicts, for sending Buddhist monks to Sri Lanka and Central Asia, and for establishing monuments marking several significant sites in the life of Gautama Buddha.

Beyond the Edicts of Ashoka, biographical information about him relies on legends written centuries later, such as the 2nd-century CE "Ashokavadana" (""Narrative of Ashoka"", a part of the "Divyavadana"), and in the Sri Lankan text "Mahavamsa" (""Great Chronicle""). The emblem of the modern Republic of India is an adaptation of the Lion Capital of Ashoka. Ashoka's name "" means "painless, without sorrow" in Sanskrit (the "a" privativum and "śoka", "pain, distress"). In his edicts, he is referred to as ' (Pali ' or "the Beloved of the Gods"), and ' (Pali ' or "He who regards everyone with affection"). His fondness for his name's connection to the "Saraca asoca" tree, or "Ashoka tree", is also referenced in the Ashokavadana. H.G. Wells wrote of Ashoka in his book "The Outline of History": "Amidst the tens of thousands of names of monarchs that crowd the columns of history, their majesties and graciousnesses and serenities and royal highnesses and the like, the name of Ashoka shines, and shines, almost alone, a star."

Ashoka was born to the Mauryan emperor, Bindusara and Subhadrangī (or Dharmā). He was the grandson of Chandragupta Maurya, founder of the Maurya dynasty. Broadly, Chandragupta was born in a humble family, abandoned, raised as a son by another family, then with the training and counsel of Chanakya of "Arthashastra" fame ultimately built one of the largest empires in ancient India. Ashoka's grandfather Chandragupta renounced it all, and became a monk in the Jain tradition. According to Roman historian Appian, Chandragupta had made a "marital alliance" with Seleucus; An Indian Puranic source, the Pratisarga Parva of the Bhavishya Purana, also described the marriage of Chandragupta with a Greek ("Yavana") princess, daughter of Seleucus.

The ancient Buddhist, Hindu, and Jain texts provide varying biographical accounts. The Avadana texts mention that his mother was queen Subhadrangī. According to the Ashokavadana, she was the daughter of a Brahmin from the city of Champa. She gave him the name Ashoka, meaning "one without sorrow". The "Divyāvadāna" tells a similar story, but gives the name of the queen as Janapadakalyānī. Ashoka had several elder siblings, all of whom were his half-brothers from the other wives of his father Bindusara. Ashoka was given royal military training.

The Buddhist text "Divyavadana" describes Ashoka putting down a revolt due to activities of wicked ministers. This may have been an incident in Bindusara's times. Taranatha's account states that Chanakya, Bindusara's chief advisor, destroyed the nobles and kings of 16 towns and made himself the master of all territory between the eastern and the western seas. Some historians consider this as an indication of Bindusara's conquest of the Deccan while others consider it as suppression of a revolt. Following this, Ashoka was stationed at Ujain, the capital of Malwa, as governor.

Bindusara's death in 272 BCE led to a war over succession. According to the "Divyavadana", Bindusara wanted his elder son Susima to succeed him but Ashoka was supported by his father's ministers, who found Susima to be arrogant and disrespectful towards them. A minister named Radhagupta seems to have played an important role in Ashoka's rise to the throne. The Ashokavadana recounts Radhagupta's offering of an old royal elephant to Ashoka for him to ride to the Garden of the Gold Pavilion where King Bindusara would determine his successor. Ashoka later got rid of the legitimate heir to the throne by tricking him into entering a pit filled with live coals. Radhagupta, according to the Ashokavadana, would later be appointed prime minister by Ashoka once he had gained the throne. The "Dipavansa" and "Mahavansa" refer to Ashoka's killing 99 of his brothers, sparing only one, named Vitashoka or Tissa, although there is no clear proof about this incident (many such accounts are saturated with mythological elements). The coronation happened in 269 BCE, four years after his succession to the throne.
Buddhist legends state that Ashoka was bad-tempered and of a wicked nature. He built Ashoka's Hell, an elaborate torture chamber described as a "Paradisal Hell" due to the contrast between its beautiful exterior and the acts carried out within by his appointed executioner, Girikaa. This earned him the name of "Chanda Ashoka" () meaning "Ashoka the Fierce" in Sanskrit. Professor Charles Drekmeier cautions that the Buddhist legends tend to dramatise the change that Buddhism brought in him, and therefore, exaggerate Ashoka's past wickedness and his piousness after the conversion.

Ascending the throne, Ashoka expanded his empire over the next eight years, from the present-day Assam in the East to Balochistan in the West; from the Pamir Knot in Afghanistan in the north to the peninsula of southern India except for present day Tamil Nadu and Kerala which were ruled by the three ancient Tamil kingdoms.

From the various sources that speak of his life, Ashoka is believed to have had five wives. They were named Devi (or Vedisa-Mahadevi-Shakyakumari), the second queen, Karuvaki, Asandhimitra (designated "" or "chief queen"), Padmavati, and Tishyarakshita. He is similarly believed to have had four sons and two daughters: a son by Devi named Mahendra (Pali: "Mahinda"), Tivara (son of Karuvaki), Kunala (son of Padmavati, and Jalauka (mentioned in the Kashmir Chronicle), a daughter of Devi named Sanghamitra (Pali: "Sanghamitta"), and another daughter named Charumati.

According to one version of the "Mahavamsa", the Buddhist chronicle of Sri Lanka, Ashoka, when he was heir-apparent and was journeying as Viceroy to Ujjain, is said to have halted at Vidisha (10 kilometers from Sanchi), and there married the daughter of a local banker. She was called Devi and later gave Ashoka two sons, Ujjeniya and Mahendra, and a daughter Sanghamitta. After Ashoka's accession, Mahendra headed a Buddhist mission, sent probably under the auspices of the Emperor, to Sri Lanka.

While the early part of Ashoka's reign was apparently quite bloodthirsty, he became a follower of the Buddha's teachings after his conquest of the Kalinga on the east coast of India in the present-day states of Odisha and North Coastal Andhra Pradesh. Kalinga was a state that prided itself on its sovereignty and democracy. With its monarchical parliamentary democracy it was quite an exception in ancient Bharata where there existed the concept of Rajdharma. Rajdharma means the duty of the rulers, which was intrinsically entwined with the concept of bravery and dharma. The Kalinga War happened eight years after his coronation. From his 13th inscription, we come to know that the battle was a massive one and caused the deaths of more than 100,000 soldiers and many civilians who rose up in defence; over 150,000 were deported.

Edict 13 of the Edicts of Ashoka Rock Inscriptions expresses the great remorse the king felt after observing the destruction of Kalinga:

Legend says that one day after the war was over, Ashoka ventured out to roam the city and all he could see were burnt houses and scattered corpses. The lethal war with Kalinga transformed the vengeful Emperor Ashoka to a stable and peaceful emperor and he became a patron of Buddhism. According to the prominent Indologist, A. L. Basham, Ashoka's personal religion became Buddhism, if not before, then certainly after the Kalinga war. However, according to Basham, the Dharma officially propagated by Ashoka was not Buddhism at all. Nevertheless, his patronage led to the expansion of Buddhism in the Mauryan empire and other kingdoms during his rule, and worldwide from about 250 BCE. Prominent in this cause were his son Mahinda (Mahendra) and daughter Sanghamitra (whose name means "friend of the Sangha"), who established Buddhism in Ceylon (now Sri Lanka).

Ashoka ruled for an estimated 36 years and died in 232 BCE. Legend states that during his cremation, his body burned for seven days and nights. After his death, the Mauryan dynasty lasted just fifty more years until his empire stretched over almost all of the Indian subcontinent. Ashoka had many wives and children, but many of their names are lost to time. His chief consort ("agramahisi") for the majority of his reign was his wife, Asandhimitra, who apparently bore him no children.

In his old age, he seems to have come under the spell of his youngest wife Tishyaraksha. It is said that she had got Ashoka's son Kunala, the regent in Takshashila and the heir presumptive to the throne, blinded by a wily stratagem. The official executioners spared Kunala and he became a wandering singer accompanied by his favourite wife Kanchanmala. In Pataliputra, Ashoka heard Kunala's song, and realised that Kunala's misfortune may have been a punishment for some past sin of the emperor himself. He condemned Tishyaraksha to death, restoring Kunala to the court. In the Ashokavadana, Kunala is portrayed as forgiving Tishyaraksha, having obtained enlightenment through Buddhist practice. While he urges Ashoka to forgive her as well, Ashoka does not respond with the same forgiveness. Kunala was succeeded by his son, Samprati, who ruled for 50 years until his death.

The reign of Ashoka Maurya might have disappeared into history as the ages passed by, had he not left behind records of his reign. These records are in the form of sculpted pillars and rocks inscribed with a variety of actions and teachings he wished to be published under his name. The language used for inscription was in one of the Prakrit "common" languages etched in a Brahmi script.

In the year 185 BCE, about fifty years after Ashoka's death, the last Maurya ruler, Brihadratha, was assassinated by the commander-in-chief of the Mauryan armed forces, Pushyamitra Shunga, while he was taking the Guard of Honor of his forces. Pushyamitra Shunga founded the Shunga dynasty (185-75 BCE) and ruled just a fragmented part of the Mauryan Empire. Many of the northwestern territories of the Mauryan Empire (modern-day Afghanistan and Northern Pakistan) became the Indo-Greek Kingdom.

King Ashoka, the third monarch of the Indian Mauryan dynasty, is also considered as one of the most exemplary rulers who ever lived.

One of the more enduring legacies of Ashoka was the model that he provided for the relationship between Buddhism and the state. Emperor Ashoka was seen as a role model to leaders within the Buddhist community. He not only provided guidance and strength, but he also created personal relationships with his supporters. Throughout Theravada Southeastern Asia, the model of rulership embodied by Ashoka replaced the notion of divine kingship that had previously dominated (in the Angkor kingdom, for instance). Under this model of 'Buddhist kingship', the king sought to legitimise his rule not through descent from a divine source, but by supporting and earning the approval of the Buddhist "sangha". Following Ashoka's example, kings established monasteries, funded the construction of stupas, and supported the ordination of monks in their kingdom. Many rulers also took an active role in resolving disputes over the status and regulation of the sangha, as Ashoka had in calling a conclave to settle a number of contentious issues during his reign. This development ultimately led to a close association in many Southeast Asian countries between the monarchy and the religious hierarchy, an association that can still be seen today in the state-supported Buddhism of Thailand and the traditional role of the Thai king as both a religious and secular leader. Ashoka also said that all his courtiers always governed the people in a moral manner.

According to the legends mentioned in the 2nd-century CE text "Ashokavadana", Ashoka was not non-violent after adopting Buddhism. In one instance, a non-Buddhist in Pundravardhana drew a picture showing the Buddha bowing at the feet of Nirgrantha Jnatiputra (identified with Mahavira, 24th Tirthankara of Jainism). On complaint from a Buddhist devotee, Ashoka issued an order to arrest him, and subsequently, another order to kill all the Ajivikas in Pundravardhana. Around 18,000 followers of the Ajivika sect were executed as a result of this order. Sometime later, another Nirgrantha follower in Pataliputra drew a similar picture. Ashoka burnt him and his entire family alive in their house. He also announced an award of one dinara (silver coin) to anyone who brought him the head of a Nirgrantha heretic. According to "Ashokavadana", as a result of this order, his own brother was mistaken for a heretic and killed by a cowherd. However, for several reasons, scholars say, these stories of persecutions of rival sects by Ashoka appear to be clear fabrications arising out of sectarian propaganda.

Ashoka was almost forgotten by the historians of the early British India, but James Prinsep contributed in the revelation of historical sources. Another important historian was British archaeologist John Hubert Marshall, who was director-General of the Archaeological Survey of India. His main interests were Sanchi and Sarnath, in addition to Harappa and Mohenjodaro. Sir Alexander Cunningham, a British archaeologist and army engineer, and often known as the father of the Archaeological Survey of India, unveiled heritage sites like the Bharhut Stupa, Sarnath, Sanchi, and the Mahabodhi Temple. Mortimer Wheeler, a British archaeologist, also exposed Ashokan historical sources, especially the Taxila.
Information about the life and reign of Ashoka primarily comes from a relatively small number of Buddhist sources. In particular, the Sanskrit "Ashokavadana" ('Story of Ashoka'), written in the 2nd century, and the two Pāli chronicles of Sri Lanka (the Dipavamsa and "Mahavamsa") provide most of the currently known information about Ashoka. Additional information is contributed by the Edicts of Ashoka, whose authorship was finally attributed to the Ashoka of Buddhist legend after the discovery of dynastic lists that gave the name used in the edicts ("Priyadarshi"—'He who regards everyone with affection') as a title or additional name of Ashoka Maurya. Architectural remains of his period have been found at Kumhrar, Patna, which include an 80-pillar hypostyle hall.

Edicts of Ashoka -The Edicts of Ashoka are a collection of 33 inscriptions on the Pillars of Ashoka, as well as boulders and cave walls, made by Ashoka during his reign. These inscriptions are dispersed throughout modern-day Pakistan and India, and represent the first tangible evidence of Buddhism. The edicts describe in detail the first wide expansion of Buddhism through the sponsorship of one of the most powerful kings of Indian history, offering more information about Ashoka's proselytism, moral precepts, religious precepts, and his notions of social and animal welfare.

Ashokavadana – The "Aśokāvadāna" is a 2nd-century CE text related to the legend of Ashoka. The legend was translated into Chinese by Fa Hien in 300 CE. It is essentially a Hinayana text, and its world is that of Mathura and North-west India. The emphasis of this little known text is on exploring the relationship between the king and the community of monks (the Sangha) and setting up an ideal of religious life for the laity (the common man) by telling appealing stories about religious exploits. The most startling feature is that Ashoka’s conversion has nothing to do with the Kalinga war, which is not even mentioned, nor is there a word about his belonging to the Maurya dynasty. Equally surprising is the record of his use of state power to spread Buddhism in an uncompromising fashion. The legend of Veetashoka provides insights into Ashoka’s character that are not available in the widely known Pali records.

"Mahavamsa" -The "Mahavamsa" ("Great Chronicle") is a historical poem written in the Pali language of the kings of Sri Lanka. It covers the period from the coming of King Vijaya of Kalinga (ancient Odisha) in 543 BCE to the reign of King Mahasena (334–361). As it often refers to the royal dynasties of India, the "Mahavamsa" is also valuable for historians who wish to date and relate contemporary royal dynasties in the Indian subcontinent. It is very important in dating the consecration of Ashoka.

Dwipavamsa -The Dwipavamsa, or "Dweepavamsa", (i.e., Chronicle of the Island, in Pali) is the oldest historical record of Sri Lanka. The chronicle is believed to be compiled from Atthakatha and other sources around the 3rd or 4th century CE. King Dhatusena (4th century) had ordered that the Dipavamsa be recited at the Mahinda festival held annually in Anuradhapura.

The caduceus appears as a symbol of the punch-marked coins of the Maurya Empire in India, in the 3rd-2nd century BCE. Numismatic research suggests that this symbol was the symbol of king Ashoka, his personal "Mudra". This symbol was not used on the pre-Mauryan punch-marked coins, but only on coins of the Maurya period, together with the three arched-hill symbol, the "peacock on the hill", the triskelis and the Taxila mark.

The use of Buddhist sources in reconstructing the life of Ashoka has had a strong influence on perceptions of Ashoka, as well as the interpretations of his Edicts. Building on traditional accounts, early scholars regarded Ashoka as a primarily Buddhist monarch who underwent a conversion to Buddhism and was actively engaged in sponsoring and supporting the Buddhist monastic institution. Some scholars have tended to question this assessment. Romila Thappar writes about Ashoka that "We need to see him both as a statesman in the context of inheriting and sustaining an empire in a particular historical period, and as a person with a strong commitment to changing society through what might be called the propagation of social ethics." The only source of information not attributable to Buddhist sources are the Ashokan Edicts, and these do not explicitly state that Ashoka was a Buddhist. In his edicts, Ashoka expresses support for all the major religions of his time: Buddhism, Brahmanism, Jainism, and Ajivikaism, and his edicts addressed to the population at large (there are some addressed specifically to Buddhists; this is not the case for the other religions) generally focus on moral themes members of all the religions would accept. For example, Amartya Sen writes, "The Indian Emperor Ashoka in the third century BCE presented many political inscriptions in favor of tolerance and individual freedom, both as a part of state policy and in the relation of different people to each other".

However, the edicts alone strongly that he was a Buddhist. In one edict he belittles rituals, and he banned Vedic animal sacrifices; these strongly suggest that he at least did not look to the Vedic tradition for guidance. Furthermore, many edicts are expressed to Buddhists alone; in one, Ashoka declares himself to be an "upasaka", and in another he demonstrates a close familiarity with Buddhist texts. He erected rock pillars at Buddhist holy sites, but did not do so for the sites of other religions. He also used the word "dhamma" to refer to qualities of the heart that underlie moral action; this was an exclusively Buddhist use of the word. However, he used the word more in the spirit than as a strict code of conduct. Romila Thappar writes, "His dhamma did not derive from divine inspiration, even if its observance promised heaven. It was more in keeping with the ethic conditioned by the logic of given situations. His logic of Dhamma was intended to influence the conduct of categories of people, in relation to each other. Especially where they involved unequal relationships." Finally, he promotes ideals that correspond to the first three steps of the Buddha's graduated discourse.

Interestingly, the Ashokavadana presents an alternate view of the familiar Ashoka; one in which his conversion has nothing to do with the Kalinga war or about his descent from the Maurya dynasty. Instead, Ashoka's reason for adopting non-violence appears much more personal. The Ashokavadana shows that the main source of Ashoka's conversion and the acts of welfare that followed are rooted instead in intense personal anguish at its core, from a wellspring inside himself rather than spurred by a specific event. It thereby illuminates Ashoka as more humanly ambitious and passionate, with both greatness and flaws. "This" Ashoka is very different from the "shadowy do-gooder" of later Pali chronicles.

Much of the knowledge about Ashoka comes from the several inscriptions that he had carved on pillars and rocks throughout the empire. All his inscriptions present him as compassionate and loving. In the Kalinga rock edits, he addresses his people as his "children" and mentions that as a father he desires their good. These inscriptions promoted Buddhist morality and encouraged nonviolence and adherence to dharma (duty or proper behaviour), and they talk of his fame and conquered lands as well as the neighbouring kingdoms holding up his might. One also gets some primary information about the Kalinga War and Ashoka's allies plus some useful knowledge on the civil administration. The Ashoka Pillar at Sarnath is the most notable of the relics left by Ashoka. Made of sandstone, this pillar records the visit of the emperor to Sarnath, in the 3rd century BCE. It has a four-lion capital (four lions standing back to back), which was adopted as the emblem of the modern Indian republic. The lion symbolises both Ashoka's imperial rule and the kingship of the Buddha. In translating these monuments, historians learn the bulk of what is assumed to have been true fact of the Mauryan Empire. It is difficult to determine whether or not some events ever actually happened, but the stone etchings clearly depict how Ashoka wanted to be thought of and remembered.

Recently scholarly analysis determined that the three major foci of debate regarding Ashoka involve the nature of the Maurya empire; the extent and impact of Ashoka's pacifism; and what is referred to in the Inscriptions as "dhamma" or dharma, which connotes goodness, virtue, and charity. Some historians have argued that Ashoka's pacifism undermined the "military backbone" of the Maurya empire, while others have suggested that the extent and impact of his pacifism have been "grossly exaggerated". The "dhamma" of the Edicts has been understood as concurrently a Buddhist lay ethic, a set of politico-moral ideas, a "sort of universal religion", or as an Ashokan innovation. On the other hand, it has also been interpreted as an "essentially political" ideology that sought to knit together a vast and diverse empire. Scholars are still attempting to analyse both the expressed and implied political ideas of the Edicts (particularly in regard to imperial vision), and make inferences pertaining to how that vision was grappling with problems and political realities of a "virtually subcontinental, and culturally and economically highly variegated, 3rd century BCE Indian empire. Nonetheless, it remains clear that Ashoka's Inscriptions represent the earliest corpus of royal inscriptions in the Indian subcontinent, and therefore prove to be a very important innovation in royal practices."

Until the Ashokan inscriptions were discovered and deciphered, stories about Ashoka were based on the legendary accounts of his life and not strictly on historical facts. These legends were found in Buddhist textual sources such as the text of "Ashokavadana". The "Ashokavadana" is a subset of a larger set of legends in the "Divyavadana", though it could have existed independently as well. Following are some of the legends narrated in the "Ashokavadana" about Ashoka:

1) One of the stories talks about an event that occurred in a past life of Ashoka, when he was a small child named Jaya. Once when Jaya was playing on the roadside, the Buddha came by. The young child put a handful of earth in the Buddha’s begging bowl as his gift to the saint and declared his wish to one day become a great emperor and follower of the Buddha. The Buddha is said to have smiled a smile that “illuminated the universe with its rays of light”. These rays of light are then said to have re-entered the Buddha’s left palm, signifying that this child Jaya would, in his next life, become a great emperor. The Buddha is said to have even turned to his disciple Ananda and is said to have predicted that this child would be “a great, righteous chakravarti king, who would rule his empire from his capital at Pataliputra”.

2) Another story aims to portray Ashoka as an evil person in order to convey the importance of his transformation into a good person upon adopting Buddhism. It begins by stating that due to Ashoka’s physical ugliness he was disliked by his father Bindusara. Ashoka wanted to become king and so he got rid of the heir by tricking him into entering a pit filled with live coals. He became famous as “Ashoka the Fierce” because of his wicked nature and bad temper. He is said to have subjected his ministers to a test of loyalty and then have 500 of them killed for failing it. He is said to have burnt his entire harem to death when certain women insulted him. He is supposed to have derived sadistic pleasure from watching other people suffer. And for this he built himself an elaborate and horrific torture chamber where he amused himself by torturing other people. The story then goes on to narrate how it was only after an encounter with a pious Buddhist monk that Ashoka himself transformed into “Ashoka the pious”. A Chinese traveler who visited India in the 7th century CE, XuanZang recorded in his memoirs that he visited the place where the supposed torture chamber stood.

3) Another story is about events that occurred towards the end of Ashoka’s time on earth. Ashoka is said to have started gifting away the contents of his treasury to the Buddhist "sangha". His ministers however were scared that his eccentricity would be the downfall of the empire and so denied him access to the treasury. As a result, Ashoka started giving away his personal possessions and was eventually left with nothing and so died peacefully.

At this point it is important to note that the "Ashokavadana" being a Buddhist text in itself sought to gain new converts for Buddhism and so used all these legends. Devotion to the Buddha and loyalty to the "sangha" are stressed. Such texts added to the perception that Ashoka was essentially the ideal Buddhist monarch who deserved both admiration and emulation.

According to Buddhist legend, particularly the Mahaparinirvana, the relics of the Buddha had been shared among eight countries following his death. Ashoka endeavoured to take back the relics and share them among 84,000 stupas. This story is amply depicted in the reliefs of Sanchi and Bharhut. According to the legend, Ashoka obtained the ashes from seven of the countries, but failed to take the ashes from the Nagas at Ramagrama. This scene is depicted on the tranversal portion of the southern gateway at Sanchi.

According to Indian historian Romila Thapar, Ashoka emphasized respect for all religious teachers, and harmonious relationship between parents and children, teachers and pupils, and employers and employees. Ashoka's religion contained gleanings from all religions. He emphasized the virtues of "Ahimsa", respect to all religious teachers, equal respect for and study of each other's scriptures, and rational faith.

As a Buddhist emperor, Ashoka believed that Buddhism is beneficial for all human beings as well as animals and plants, so he built a number of stupas, Sangharama, viharas, chaitya, and residences for Buddhist monks all over South Asia and Central Asia. According to the Ashokavadana, he ordered the construction of 84,000 stupas to house the Buddha's relics. In the Aryamanjusrimulakalpa, Ashoka takes offerings to each of these stupas traveling in a chariot adorned with precious metals. He gave donations to viharas and mathas. He sent his only daughter Sanghamitra and son Mahindra to spread Buddhism in Sri Lanka (then known as Tamraparni).

According to the "Mahavamsa", in the 17th year of Ashoka's reign, at the end of the Third Buddhist Council, Ashoka sent Buddhist missionaries to nine parts of the world to propagate Buddhism.
Ashoka also invited Buddhists and non-Buddhists for religious conferences. He inspired the Buddhist monks to compose the sacred religious texts, and also gave all types of help to that end. Ashoka also helped to develop viharas (intellectual hubs) such as Nalanda and Taxila. Ashoka helped to construct Sanchi and Mahabodhi Temple. Ashoka also gave donations to non-Buddhists. As his reign continued his even-handedness was replaced with special inclination towards Buddhism. Ashoka helped and respected both Shramanas (Buddhists monks) and Brahmins (Vedic monks). Ashoka also helped to organise the Third Buddhist council () at Pataliputra (today's Patna). It was conducted by the monk Moggaliputta-Tissa who was the spiritual teacher of Ashoka.

Emperor Ashoka's son, Mahinda, also helped with the spread of Buddhism by translating the Buddhist Canon into a language that could be understood by the people of Sri Lanka.

It is well known that Ashoka sent "dütas" or emissaries to convey messages or letters, written or oral (rather both), to various people. The VIth Rock Edict about "oral orders" reveals this. It was later confirmed that it was not unusual to add oral messages to written ones, and the content of Ashoka's messages can be inferred likewise from the XIIIth Rock Edict: They were meant to spread his "dhammavijaya," which he considered the highest victory and which he wished to propagate everywhere (including far beyond India). There is obvious and undeniable trace of cultural contact through the adoption of the Kharosthi script, and the idea of installing inscriptions might have travelled with this script, as Achaemenid influence is seen in some of the formulations used by Ashoka in his inscriptions. This indicates to us that Ashoka was indeed in contact with other cultures, and was an active part in mingling and spreading new cultural ideas beyond his own immediate walls.

In his edicts, Ashoka mentions some of the people living in Hellenic countries as converts to Buddhism and recipients of his envoys, although no Hellenic historical record of this event remains:

It is not too far-fetched to imagine, however, that Ashoka received letters from Greek rulers and was acquainted with the Hellenistic royal orders in the same way as he perhaps knew of the inscriptions of the Achaemenid kings, given the presence of ambassadors of Hellenistic kings in India (as well as the "dütas" sent by Ashoka himself). Dionysius is reported to have been such a Greek ambassador at the court of Ashoka, sent by Ptolemy II Philadelphus, who himself is mentioned in the Edicts of Ashoka as a recipient of the Buddhist proselytism of Ashoka. Some Hellenistic philosophers, such as Hegesias of Cyrene, who probably lived under the rule of King Magas, one of the supposed recipients of Buddhist emissaries from Asoka, are sometimes thought to have been influenced by Buddhist teachings.

The Greeks in India even seem to have played an active role in the propagation of Buddhism, as some of the emissaries of Ashoka, such as Dharmaraksita, are described in Pali sources as leading Greek (Yona) Buddhist monks, active in spreading Buddhism (the "Mahavamsa", XII).

Some Greeks (Yavana) may have played an administrative role in the territories ruled by Ashoka. The Girnar inscription of Rudradaman records that during the rule of Ashoka, a Yavana Governor was in charge in the area of Girnar, Gujarat, mentioning his role in the construction of a water reservoir.

Ashoka's military power was strong, but after his conversion to Buddhism, he maintained friendly relations with three major Tamil kingdoms in the South—namely, Cheras, Cholas and Pandyas—the post-Alexandrian empire, Tamraparni, and Suvarnabhumi. His edicts state that he made provisions for medical treatment of humans and animals in his own kingdom as well as in these neighbouring states. He also had wells dug and trees planted along the roads for the benefit of the common people.

Ashoka's rock edicts declare that injuring living things is not good, and no animal should be sacrificed for slaughter. However, he did not prohibit common cattle slaughter or beef eating.

He imposed a ban on killing of "all four-footed creatures that are neither useful nor edible", and of specific animal species including several birds, certain types of fish and bulls among others. He also banned killing of female goats, sheep and pigs that were nursing their young; as well as their young up to the age of six months. He also banned killing of all fish and castration of animals during certain periods such as Chaturmasa and Uposatha.

Ashoka also abolished the royal hunting of animals and restricted the slaying of animals for food in the royal residence. Because he banned hunting, created many veterinary clinics and eliminated meat eating on many holidays, the Mauryan Empire under Ashoka has been described as "one of the very few instances in world history of a government treating its animals as citizens who are as deserving of its protection as the human residents".

The Ashoka Chakra (the wheel of Ashoka) is a depiction of the Dharmachakra (the Wheel of Dharma). The wheel has 24 spokes which represent the 12 Laws of Dependent Origination and the 12 Laws of Dependent Termination. The Ashoka Chakra has been widely inscribed on many relics of the Mauryan Emperor, most prominent among which is the Lion Capital of Sarnath and The Ashoka Pillar. The most visible use of the Ashoka Chakra today is at the centre of the National flag of the Republic of India (adopted on 22 July 1947), where it is rendered in a Navy-blue color on a White background, by replacing the symbol of Charkha (Spinning wheel) of the pre-independence versions of the flag. The Ashoka Chakra can also been seen on the base of the Lion Capital of Ashoka which has been adopted as the National Emblem of India.

The Ashoka Chakra was created by Ashoka during his reign. Chakra is a Sanskrit word which also means "cycle" or "self-repeating process". The process it signifies is the cycle of time—as in how the world changes with time.

A few days before India became independent in August 1947, the specially-formed Constituent Assembly decided that the flag of India must be acceptable to all parties and communities. A flag with three colours, Saffron, White and Green with the Ashoka Chakra was selected.

Ashoka is often credited with the beginning of stone architecture in India, possibly following the introduction of stone-building techniques by the Greeks after Alexander the Great. Before Ashoka's time, buildings were probably built in non-permanent material, such as wood, bamboo or thatch. Ashoka may have rebuilt his palace in Pataliputra by replacing wooden material by stone, and may also have used the help of foreign craftmen. Ashoka also innovated by using the permament qualities of stone for his written edicts, as well as his pillars with Buddhist symbolism.

The pillars of Ashoka are a series of columns dispersed throughout the northern Indian subcontinent, and erected by Ashoka during his reign in the 3rd century BCE. Originally, there must have been many pillars of Ashoka although only ten with inscriptions still survive. Averaging between forty and fifty feet in height, and weighing up to fifty tons each, all the pillars were quarried at Chunar, just south of Varanasi and dragged, sometimes hundreds of miles, to where they were erected. The first Pillar of Ashoka was found in the 16th century by Thomas Coryat in the ruins of ancient Delhi. The wheel represents the sun time and Buddhist law, while the swastika stands for the cosmic dance around a fixed center and guards against evil.

The Lion capital of Ashoka is a sculpture of four lions standing back to back. It was originally placed atop the Ashoka pillar at Sarnath, now in the state of Uttar Pradesh, India. The pillar, sometimes called the Ashoka Column, is still in its original location, but the Lion Capital is now in the Sarnath Museum. This Lion Capital of Ashoka from Sarnath has been adopted as the National Emblem of India and the wheel ("Ashoka Chakra") from its base was placed onto the center of the National Flag of India.

The capital contains four lions (Indian / Asiatic Lions), standing back to back, mounted on a short cylindrical abacus, with a frieze carrying sculptures in high relief of an elephant, a galloping horse, a bull, and a lion, separated by intervening spoked chariot-wheels over a bell-shaped lotus. Carved out of a single block of polished sandstone, the capital was believed to be crowned by a 'Wheel of Dharma' (Dharmachakra popularly known in India as the "Ashoka Chakra"). The Sarnath pillar bears one of the Edicts of Ashoka, an inscription against division within the Buddhist community, which reads, "No one shall cause division in the order of monks."

The four animals in the Sarnath capital are believed to symbolise different steps of Lord Buddha's life.

Besides the religious interpretations, there are some non-religious interpretations also about the symbolism of the Ashoka capital pillar at Sarnath. According to them, the four lions symbolise Ashoka's rule over the four directions, the wheels as symbols of his enlightened rule (Chakravartin) and the four animals as symbols of four adjoining territories of India.

The British restoration was done under guidance from Weligama Sri Sumangala.






</doc>
<doc id="1241" url="https://en.wikipedia.org/wiki?curid=1241" title="American (word)">
American (word)

The meaning of the word American in the English language varies according to the historical, geographical, and political context in which it is used. "American" is derived from "America", a term originally denoting all of the New World (also called the Americas). In some expressions, it retains this Pan-American sense, but its usage has evolved over time and, for various historical reasons, the word came to denote people or things specifically from the United States of America.

In modern English, "American" generally refers to persons or things related to the United States of America; among native English speakers this usage is almost universal, with any other use of the term requiring specification. However, this usage is seen by some as a semantic "misappropriation" by those who argue that "American" should be widened in English to also include people or things from anywhere in the American continents.

The word can be used as either an adjective or a noun (viz. a demonym). In adjectival use, it means "of or relating to the United States"; for example, "Elvis Presley was an American singer" or "the man prefers American English". In its noun form, the word generally means a resident or citizen of the US, or occasionally someone whose ethnic identity is simply "American". The noun is rarely used in American English to refer to people not connected to the United States. When used with a grammatical qualifier, the adjective "American" can mean "of or relating to the Americas", as in Latin American or Indigenous American. Less frequently, the adjective can take this meaning without a qualifier, as in "American Spanish dialects and pronunciation differ by country", or the name of the Organization of American States. A third use of the term pertains specifically to the indigenous peoples of the Americas, for instance, "In the 16th century, many Americans died from imported diseases during the European conquest".

Compound constructions such as "African Americans" likewise refer exclusively to people in or from the United States of America, as does the prefix "Americo-". For instance, the Americo-Liberians and their language Merico derive their name from the fact that they are descended from African American settlers, i.e. former slaves in the United States of America.

French, German, Italian, Japanese, Hebrew, Arabic, and Russian speakers may use cognates of "American" to refer to inhabitants of the Americas or to U.S. nationals. They generally have other terms specific to U.S. nationals, such as the German ', French ', Japanese , Arabic ' ( as opposed to ' ), and Italian "". These specific terms may be less common than the term "American".

In French, ', ' or ', from ' ("United States of America"), is a rarely used word that distinguishes U.S. things and persons from the adjective "", which denotes persons and things from the United States, but may also refer to "the Americas".

Likewise, German's use of ' and ' observe said cultural distinction, solely denoting U.S. things and people. Note that these are "politically correct" terms and that in normal parlance, the adjective "American" and its direct cognates are usually used if the context renders the nationality of the person clear.

This differentiation is prevalent in German-speaking countries, as indicated by the style manual of the "Neue Zürcher Zeitung" (one of the leading German-language newspapers in Switzerland) which dismisses the term ' as both ′unnecessary′ and ′artificial′ and recommends replacing it with "amerikanisch". The respective guidelines of the foreign ministries of Austria, Germany and Switzerland all prescribe "Amerikaner" and "amerikanisch" in reference to the United States for official usage, making no mention of ' or "".

Portuguese has ', denoting both a person or thing from the Americas and a U.S. national. For referring specifically to a U.S. national and things, some words used are ' (also spelled ', "United States person"), from ', and ' ("Yankee")—both usages exist in Brazil, but are uncommon in Portugal—but the term most often used, and the only one in Portugal, is ', even though it could, as with its Spanish equivalent, apply to Canadians, Mexicans, etc. as well.

In Spanish, ' denotes geographic and cultural origin in the New World, as well as (infrequently) a U.S. citizen; the more common term is ' ("United States person"), which derives from ' ("United States of America"). The Spanish term ' ("North American") is frequently used to refer things and persons from the United States, but this term can also denote people and things from Canada and Mexico. Among Spanish-speakers, North America generally doesn't include Central America or the Caribbean.

In other languages, however, there is no possibility for confusion. For example, the Chinese word for "U.S. national" is ' () is derived from a word for the United States, ', where ' is an abbreviation for "Yàměilìjiā" ("America") and ' is "country". The name for the American continents is ', from ' plus ' ("continent"). Thus, a ' is an American in the continent sense, and a "" is an American in the U.S. sense.

Conversely, in Czech, there is no possibility for disambiguation. "Američan" (m.) and "američanka" (f.) can refer to persons from the United States or from the continents of the Americas, and there is no specific word capable of distinguishing the two meanings. For this reason, the latter meaning is very rarely used, and word "američan(ka)" is used almost exclusively to refer to persons from the United States. The usage is exactly parallel to the English word.

Korean and Vietnamese also use unambiguous terms, with Korean having ' () for the country versus ' () for the continents, and Vietnamese having ' for the country versus ' for the continents. Japanese has such terms as well (' [ versus ' []), but they are found more in newspaper headlines than in speech, where "" predominates.

In Swahili, ' means specifically the United States, and ' is a U.S. national, whereas the international form ' refers to the continents, and ' would be an inhabitants thereof. Likewise, the Esperanto word ' refers to the continents. For the country there is the term '. Thus, a citizen of the United States is an ', whereas an ' is an inhabitant of the Americas.

In Hungarian the term amerikai (American) refers to a person or a thing from the United States.

The name "America" was coined by Martin Waldseemüller from "Americus Vespucius", the Latinized version of the name of Amerigo Vespucci (1454–1512), the Italian explorer who mapped South America's east coast and the Caribbean Sea in the early 16th century. Later, Vespucci's published letters were the basis of Waldseemüller's 1507 map, which is the first usage of "America". The adjective "American" subsequently denoted the New World.

16th-century European usage of "American" denoted the native inhabitants of the New World. The earliest recorded use of this term in English is in Thomas Hacket's 1568 translation of André Thévet's book "France Antarctique"; Thévet himself had referred to the natives as "Ameriques". In the following century, the term was extended to European settlers and their descendants in the Americas. The earliest recorded use of "English-American" dates to 1648, in Thomas Gage's "The English-American his travail by sea and land: or, a new survey of the West India's".

In English, "American" was used especially for people in the British America. Samuel Johnson, the leading English lexicographer, wrote in 1775, before the United States declared independence: "That the Americans are able to bear taxation is indubitable." The Declaration of Independence of July 1776 refers to "[the] unanimous Declaration of the thirteen United States of America" adopted by the "Representatives of the United States of America" on July 4, 1776. The official name of the country was reaffirmed on November 15, 1777, when the Second Continental Congress adopted the Articles of Confederation, the first of which says, "The Stile of this Confederacy shall be 'The United States of America'". The Articles further state:
Sam Haselby, a history professor in Lebanon and Egypt, claims it was British officials who first called the colonists "Americans". When the drafters of the "Declaration"—Thomas Jefferson from Virginia, for example, or John Adams from Massachusetts—talked about "my country", they meant Virginia or Massachusetts, respectively. This situation was changed by the Revolution and the impulse toward nationalism. Jefferson, newly elected president in May 1801 wrote, "I am sure the measures I mean to pursue are such as would in their nature be approved by every American who can emerge from preconceived prejudices; as for those who cannot, we must take care of them as of the sick in our hospitals. The medicine of time and fact may cure some of them."

In "The Federalist Papers" (1787–88), Alexander Hamilton and James Madison used the adjective "American" with two different meanings: one political and one geographic; "the American republic" in Federalist No. 51 and in Federalist No. 70, and, in Federalist No. 24, Hamilton used "American" to denote the lands beyond the U.S.'s political borders.

Early official U.S. documents show inconsistent usage; the 1778 Treaty of Alliance with France used "the United States of North America" in the first sentence, then "the said United States" afterwards; "the United States of America" and "the United States of North America" derive from "the United Colonies of America" and "the United Colonies of North America". The Treaty of Peace and Amity of September 5, 1795, between the United States and the Barbary States contains the usages "the United States of North America", "citizens of the United States", and "American Citizens".
U.S. President George Washington, in his 1796 "Farewell Address", declaimed that "The name of American, which belongs to you in your national capacity, must always exalt the just pride of patriotism more than any appellation." Political scientist Virginia L. Arbery notes that, in his "Farewell Address": "...Washington invites his fellow citizens to view themselves now as Americans who, out of their love for the truth of liberty, have replaced their maiden names (Virginians, South Carolinians, New Yorkers, etc.) with that of “American”. Get rid of, he urges, “any appellation derived from local discriminations.” By defining himself as an American rather than as a Virginian, Washington set the national standard for all citizens. "Over and over, Washington said that America must be something set apart. As he put it to Patrick Henry, 'In a word, I want an "American" character, that the powers of Europe may be convinced we act for "ourselves" and not for "others".'" As the historian Garry Wills has noted: "This was a theme dear to Washington. He wrote to Timothy Pickering that the nation 'must never forget that we are Americans; the remembrance of which will convince us we ought not to be French or English'." Washington's countrymen subsequently embraced his exhortation with notable enthusiasm.

This semantic divergence among North American anglophones, however, remained largely unknown in the Spanish-American colonies. In 1801, the document titled "Letter to American Spaniards"—published in French (1799), in Spanish (1801), and in English (1808)—might have influenced Venezuela's Act of Independence and its 1811 constitution.

The Latter-day Saints' Articles of Faith refer to the American continents as where they are to build Zion. 
Common short forms and abbreviations are the "United States", the "U.S.", the "U.S.A.", and "America"; colloquial versions include the "U.S. of A." and "the States". The term "Columbia" (from the Columbus surname) was a popular name for the U.S. and for the entire geographic Americas; its usage is present today in the District of Columbia's name. Moreover, the womanly personification of Columbia appears in some official documents, including editions of the U.S. dollar.

Use of the term "American" for U.S. nationals is common at the United Nations, and financial markets in the United States are referred to as "American financial markets".

"American Samoa" is a recognized territorial name at the United Nations.

The use of "American" as a national demonym for U.S. nationals is challenged, primarily by Hispanic Americans. Spanish speakers in Spain and Latin America use the term ' to refer to people and things from the United States (from '), while ' refers to the continents as a whole. The term ' is also accepted in many parts of Latin America to refer to a person or something from the United States, however this term may be ambiguous in certain parts. Up to and including the 1992 edition, the ', published by the Real Academia Española, did not include the United States definition in the entry for '; this was added in the 2001 edition. The Real Academia Española advised against using "" exclusively for U.S. nationals:
Modern Canadians typically refer to people from the United States as "Americans", though they seldom refer to the United States as "America"; they use the terms "the United States", "the U.S.", or (informally) "the States" instead. Canadians rarely apply the term "American" to themselves – some Canadians resent either being referred to as Americans because of mistaken assumptions that they are U.S. citizens or others' inability, particularly of those overseas, to distinguish Canadian from American accents. Some Canadians have protested the use of "American" as a national demonym. People of U.S. ethnic origin in Canada are categorized as "Other North American origins" by Statistics Canada for purposes of census counts.

Generally, ' denotes "U.S. citizen" in Portugal. Usage of ' to exclusively denote people and things of the U.S. is discouraged by the Lisbon Academy of Sciences, because the specific word ' (also ') clearly denotes a person from the United States. The term currently used by the Portuguese press is ".

In Brazil, the term ' is used to address both that which pertains to both American continents and, in current speech, that which pertains to the U.S.; the particular meaning is deduced from context. Alternatively, the term ' ("North American") is also used in more informal contexts, while ' (of the U.S.) is the preferred form in academia. Use of the three terms is common in schools, government, and media. The term ' is used almost exclusively for the continents, and the U.S. is called ' ("United States") or ' ("United States of America"), often abbreviated ".

The Getting Through Customs website advises business travelers not to use "in America" as a U.S. reference when conducting business in Brazil.

"American" in the 1994 "Associated Press Stylebook" was defined as, "An acceptable description for a resident of the United States. It also may be applied to any resident or citizen of nations in North or South America." Elsewhere, the "AP Stylebook" indicates that "United States" must "be spelled out when used as a noun. Use U.S. (no space) only as an adjective."

The entry for "America" in "The New York Times Manual of Style and Usage" from 1999 reads:
Media releases from the Pope and Holy See frequently use "America" to refer to the United States, and "American" to denote something or someone from the United States.

At least one international law uses "U.S. citizen" in defining a citizen of the United States rather than "American citizen"; for example, the English version of the North American Free Trade Agreement includes:
Many international treaties use the terms "American" and "American citizen":

Products that are labeled, advertised, and marketed in the U.S. as "Made in the USA" must be, as set by the Federal Trade Commission (FTC), "all or virtually all made in the U.S." The FTC, to prevent deception of customers and unfair competition, considers an unqualified claim of "American Made" to expressly claim exclusive manufacture in the U.S: "The FTC Act gives the Commission the power to bring law enforcement actions against false or misleading claims that a product is of U.S. origin."

There are a number of alternatives to the demonym "American" as a citizen of the United States that do not simultaneously mean any inhabitant of the Americas. One uncommon alternative is "Usonian", which usually describes a certain style of residential architecture designed by Frank Lloyd Wright. Other alternatives have also surfaced, but most have fallen into disuse and obscurity. "Merriam-Webster's Dictionary of English Usage" says:

Nevertheless, no alternative to "American" is common.




</doc>
<doc id="1242" url="https://en.wikipedia.org/wiki?curid=1242" title="Ada (programming language)">
Ada (programming language)

Ada is a structured, statically typed, imperative, wide-spectrum, and object-oriented high-level computer programming language, extended from Pascal and other languages. It has built-in language support for design-by-contract, extremely strong typing, explicit concurrency, tasks, synchronous message passing, protected objects, and non-determinism. Ada improves code safety and maintainability by using the compiler to find errors in favor of runtime errors. Ada is an international standard; the current version (known as Ada 2012) is defined by ISO/IEC 8652:2012.

Ada was originally designed by a team led by Jean Ichbiah of CII Honeywell Bull under contract to the United States Department of Defense (DoD) from 1977 to 1983 to supersede over 450 programming languages used by the DoD at that time. Ada was named after Ada Lovelace (1815–1852), who has been credited with being the first computer programmer.

Ada was originally targeted at embedded and real-time systems. The Ada 95 revision, designed by S. Tucker Taft of Intermetrics between 1992 and 1995, improved support for systems, numerical, financial, and object-oriented programming (OOP).

Features of Ada include: strong typing, modularity mechanisms (packages), run-time checking, parallel processing (tasks, synchronous message passing, protected objects, and nondeterministic select statements), exception handling, and generics. Ada 95 added support for object-oriented programming, including dynamic dispatch.

The syntax of Ada minimizes choices of ways to perform basic operations, and prefers English keywords (such as "or else" and "and then") to symbols (such as "||" and "&&"). Ada uses the basic arithmetical operators "+", "-", "*", and "/", but avoids using other symbols. Code blocks are delimited by words such as "declare", "begin", and "end", where the "end" (in most cases) is followed by the identifier of the block it closes (e.g., "if … end if", "loop … end loop"). In the case of conditional blocks this avoids a "dangling else" that could pair with the wrong nested if-expression in other languages like C or Java.

Ada is designed for development of very large software systems. Ada packages can be compiled separately. Ada package specifications (the package interface) can also be compiled separately without the implementation to check for consistency. This makes it possible to detect problems early during the design phase, before implementation starts.

A large number of compile-time checks are supported to help avoid bugs that would not be detectable until run-time in some other languages or would require explicit checks to be added to the source code. For example, the syntax requires explicitly named closing of blocks to prevent errors due to mismatched end tokens. The adherence to strong typing allows detection of many common software errors (wrong parameters, range violations, invalid references, mismatched types, etc.) either during compile-time, or otherwise during run-time. As concurrency is part of the language specification, the compiler can in some cases detect potential deadlocks. Compilers also commonly check for misspelled identifiers, visibility of packages, redundant declarations, etc. and can provide warnings and useful suggestions on how to fix the error.

Ada also supports run-time checks to protect against access to unallocated memory, buffer overflow errors, range violations, off-by-one errors, array access errors, and other detectable bugs. These checks can be disabled in the interest of runtime efficiency, but can often be compiled efficiently. It also includes facilities to help program verification. For these reasons, Ada is widely used in critical systems, where any anomaly might lead to very serious consequences, e.g., accidental death, injury or severe financial loss. Examples of systems where Ada is used include avionics, ATC, railways, banking, military and space technology.

Ada's dynamic memory management is high-level and type-safe. Ada does not have generic or untyped pointers; nor does it implicitly declare any pointer type. Instead, all dynamic memory allocation and deallocation must take place through explicitly declared "access types".
Each access type has an associated "storage pool" that handles the low-level details of memory management; the programmer can either use the default storage pool or define new ones (this is particularly relevant for Non-Uniform Memory Access). It is even possible to declare several different access types that all designate the same type but use different storage pools.
Also, the language provides for "accessibility checks", both at compile time and at run time, that ensures that an "access value" cannot outlive the type of the object it points to.

Though the semantics of the language allow automatic garbage collection of inaccessible objects, most implementations do not support it by default, as it would cause unpredictable behaviour in real-time systems. Ada does support a limited form of region-based memory management; also, creative use of storage pools can provide for a limited form of automatic garbage collection, since destroying a storage pool also destroys all the objects in the pool.

A double-dash ("--"), resembling an em dash, denotes comment text. Comments stop at end of line, to prevent unclosed comments from accidentally voiding whole sections of source code. Prefixing each line (or column) with "--" will skip all that code, while being clearly denoted as a column of repeated "--" down the page.

The semicolon (";") is a statement terminator, and the null or no-operation statement is codice_1. A single codice_2 without a statement to terminate is not allowed.

Unlike most ISO standards, the Ada language definition (known as the "Ada Reference Manual" or "ARM", or sometimes the "Language Reference Manual" or "LRM") is free content. Thus, it is a common reference for Ada programmers and not just programmers implementing Ada compilers. Apart from the reference manual, there is also an extensive rationale document which explains the language design and the use of various language constructs. This document is also widely used by programmers. When the language was revised, a new rationale document was written.

One notable free software tool that is used by many Ada programmers to aid them in writing Ada source code is the GNAT Programming Studio.

In the 1970s, the US Department of Defense (DoD) was concerned by the number of different programming languages being used for its embedded computer system projects, many of which were obsolete or hardware-dependent, and none of which supported safe modular programming. In 1975, a working group, the High Order Language Working Group (HOLWG), was formed with the intent to reduce this number by finding or creating a programming language generally suitable for the department's and the UK Ministry of Defence requirements. After many iterations beginning with an original Straw man proposal the eventual programming language was named Ada. The total number of high-level programming languages in use for such projects fell from over 450 in 1983 to 37 by 1996.

The HOLWG working group crafted the Steelman language requirements, a series of documents stating the requirements they felt a programming language should satisfy. Many existing languages were formally reviewed, but the team concluded in 1977 that no existing language met the specifications.

Requests for proposals for a new programming language were issued and four contractors were hired to develop their proposals under the names of Red (Intermetrics led by Benjamin Brosgol), Green (CII Honeywell Bull, led by Jean Ichbiah), Blue (SofTech, led by John Goodenough) and Yellow (SRI International, led by Jay Spitzen). In April 1978, after public scrutiny, the Red and Green proposals passed to the next phase. In May 1979, the Green proposal, designed by Jean Ichbiah at CII Honeywell Bull, was chosen and given the name Ada—after Augusta Ada, Countess of Lovelace. This proposal was influenced by the programming language LIS that Ichbiah and his group had developed in the 1970s. The preliminary Ada reference manual
was published in ACM SIGPLAN Notices in June 1979. The Military Standard reference manual was approved on December 10, 1980 (Ada Lovelace's birthday), and
given the number MIL-STD-1815 in honor of Ada Lovelace's birth year. In 1981, C. A. R. Hoare took advantage of his Turing Award speech to criticize Ada for being overly complex and hence unreliable, but subsequently seemed to recant in the foreword he wrote for an Ada textbook.

Ada attracted much attention from the programming community as a whole during its early days. Its backers and others predicted that it might become a dominant language for general purpose programming and not just defense-related work. Ichbiah publicly stated that within ten years, only two programming languages would remain, Ada and Lisp. Early Ada compilers struggled to implement the large, complex language, and both compile-time and run-time performance tended to be slow and tools primitive. Compiler vendors expended most of their efforts in passing the massive, language-conformance-testing, government-required "ACVC" validation suite that was required in another novel feature of the Ada language effort.

The first validated Ada implementation was the NYU Ada/Ed translator, certified on April 11, 1983. NYU Ada/Ed is implemented in the high-level set language SETL. A number of commercial companies began offering Ada compilers and associated development tools, including Alsys, TeleSoft, DDC-I, Advanced Computer Techniques, Tartan Laboratories, TLD Systems, Verdix, and others.
In 1991, the US Department of Defense began to require the use of Ada (the "Ada mandate") for all software, though exceptions to this rule were often granted. The Department of Defense Ada mandate was effectively removed in 1997, as the DoD began to embrace COTS technology. Similar requirements existed in other NATO countries: Ada was required for NATO systems involving command and control and other functions, and Ada was the mandated or preferred language for defense-related applications in countries such as Sweden, Germany, and Canada.

By the late 1980s and early 1990s, Ada compilers had improved in performance, but there were still barriers to full exploitation of Ada's abilities, including a tasking model that was different from what most real-time programmers were used to.

Because of Ada's safety-critical support features, it is now used not only for military applications, but also in commercial projects where a software bug can have severe consequences, e.g., avionics and air traffic control, commercial rockets such as the Ariane 4 and 5, satellites and other space systems, railway transport and banking.
For example, the Airplane Information Management System, the fly-by-wire system software in the Boeing 777, was written in Ada. Developed by Honeywell Air Transport Systems in collaboration with consultants from DDC-I, it became arguably the best-known of any Ada project, civilian or military. The Canadian Automated Air Traffic System was written in 1 million lines of Ada (SLOC count). It featured advanced distributed processing, a distributed Ada database, and object-oriented design. Ada is also used in other air traffic systems, e.g., the UK’s next-generation Interim Future Area Control Tools Support (iFACTS) air traffic control system is designed and implemented using SPARK Ada.
It is also used in the French TVM in-cab signalling system on the TGV high-speed rail system, and the metro suburban trains in Paris, London, Hong Kong and New York City.

The language became an ANSI standard in 1983 (ANSI/MIL-STD 1815A), and without any further changes became
an ISO standard in 1987 (ISO-8652:1987). This version of the language is commonly known as Ada 83, from the date of its adoption by ANSI, but is sometimes referred to also as Ada 87, from the date of its adoption by ISO.

Ada 95, the joint ISO/ANSI standard (ISO-8652:1995) was published in February 1995, making Ada 95 the first ISO standard object-oriented programming language. To help with the standard revision and future acceptance, the US Air Force funded the development of the GNAT Compiler. Presently, the GNAT Compiler is part of the GNU Compiler Collection.

Work has continued on improving and updating the technical content of the Ada programming language. A Technical Corrigendum to Ada 95 was published in October 2001, and a major Amendment, ISO/IEC 8652:1995/Amd 1:2007 was published on March 9, 2007. At the Ada-Europe 2012 conference in Stockholm, the Ada Resource Association (ARA) and Ada-Europe announced the completion of the design of the latest version of the Ada programming language and the submission of the reference manual to the International Organization for Standardization (ISO) for approval. ISO/IEC 8652:2012 was published in December 2012.

Other related standards include ISO 8651-3:1988 "Information processing systems—Computer graphics—Graphical Kernel System (GKS) language bindings—Part 3: Ada".

Ada is an ALGOL-like programming language featuring control structures with reserved words such as "if", "then", "else", "while", "for", and so on. However, Ada also has many data structuring facilities and other abstractions which were not included in the original ALGOL 60, such as type definitions, records, pointers, enumerations. Such constructs were in part inherited from or inspired by Pascal.

A common example of a language's syntax is the Hello world program:

with Ada.Text_IO; use Ada.Text_IO;
procedure Hello is
begin
end Hello;

This program can be compiled by using the freely available open source compiler GNAT, by executing
gnatmake hello.adb

Ada's type system is not based on a set of predefined primitive types but allows users to declare their own types. This declaration in turn is not based on the internal representation of the type but on describing the goal which should be achieved. This allows the compiler to determine a suitable memory size for the type, and to check for violations of the type definition at compile time and run time (i.e., range violations, buffer overruns, type consistency, etc.). Ada supports numerical types defined by a range, modulo types, aggregate types (records and arrays), and enumeration types. Access types define a reference to an instance of a specified type; untyped pointers are not permitted.
Special types provided by the language are task types and protected types.

For example, a date might be represented as:
type Day_type is range 1 .. 31;
type Month_type is range 1 .. 12;
type Year_type is range 1800 .. 2100;
type Hours is mod 24;
type Weekday is (Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday);

type Date is
Types can be refined by declaring subtypes:

subtype Working_Hours is Hours range 0 .. 12; -- at most 12 Hours to work a day
subtype Working_Day is Weekday range Monday .. Friday; -- Days to work

Work_Load: constant array(Working_Day) of Working_Hours -- implicit type declaration

Types can have modifiers such as "limited, abstract, private" etc. Private types can only be accessed and limited types can only be modified or copied within the scope of the package that defines them.
Ada 95 adds additional features for object-oriented extension of types.

Ada is a structured programming language, meaning that the flow of control is structured into standard statements. All standard constructs and deep level early exit are supported so the use of the also supported 'go to' commands is seldom needed.
-- while a is not equal to b, loop.
while a /= b loop
end loop;

if a > b then
else
end if;

for i in 1 .. 10 loop
end loop;

loop
end loop;

case i is
end case;

for aWeekday in Weekday'Range loop -- loop over an enumeration
end loop;
Among the parts of an Ada program are packages, procedures and functions.

Example:
Package specification (example.ads)

package Example is
end Example;

Package body (example.adb)

with Ada.Text_IO;
package body Example is

-- package initialization executed when the package is elaborated
begin
end Example;

This program can be compiled, e.g., by using the freely available open source compiler GNAT, by executing
gnatmake -z example.adb

Packages, procedures and functions can nest to any depth and each can also be the logical outermost block.

Each package, procedure or function can have its own declarations of constants, types, variables, and other procedures, functions and packages, which can be declared in any order.

Ada has language support for task-based concurrency. The fundamental concurrent unit in Ada is a "task", which is a built-in limited type. Tasks are specified in two parts – the task declaration defines the task interface (similar to a type declaration), the task body specifies the implementation of the task.
Depending on the implementation, Ada tasks are either mapped to operating system threads or processes, or are scheduled internally by the Ada runtime.

Tasks can have entries for synchronisation (a form of synchronous message passing). Task entries are declared in the task specification. Each task entry can have one or more "accept" statements within the task body. If the control flow of the task reaches an accept statement, the task is blocked until the corresponding entry is called by another task (similarly, a calling task is blocked until the called task reaches the corresponding accept statement). Task entries can have parameters similar to procedures, allowing tasks to synchronously exchange data. In conjunction with "select" statements it is possible to define "guards" on accept statements (similar to Dijkstra's guarded commands).

Ada also offers "protected objects" for mutual exclusion. Protected objects are a monitor-like construct, but use guards instead of conditional variables for signaling (similar to conditional critical regions). Protected objects combine the data encapsulation and safe mutual exclusion from monitors, and entry guards from conditional critical regions. The main advantage over classical monitors is that conditional variables are not required for signaling, avoiding potential deadlocks due to incorrect locking semantics. Like tasks, the protected object is a built-in limited type, and it also has a declaration part and a body.

A protected object consists of encapsulated private data (which can only be accessed from within the protected object), and procedures, functions and entries which are guaranteed to be mutually exclusive (with the only exception of functions, which are required to be side effect free and can therefore run concurrently with other functions). A task calling a protected object is blocked if another task is currently executing inside the same protected object, and released when this other task leaves the protected object. Blocked tasks are queued on the protected object ordered by time of arrival.

Protected object entries are similar to procedures, but additionally have "guards". If a guard evaluates to false, a calling task is blocked and added to the queue of that entry; now another task can be admitted to the protected object, as no task is currently executing inside the protected object. Guards are re-evaluated whenever a task leaves the protected object, as this is the only time when the evaluation of guards can have changed.

Calls to entries can be "requeued" to other entries with the same signature. A task that is requeued is blocked and added to the queue of the target entry; this means that the protected object is released and allows admission of another task.

The "select" statement in Ada can be used to implement non-blocking entry calls and accepts, non-deterministic selection of entries (also with guards), time-outs and aborts.

The following example illustrates some concepts of concurrent programming in Ada.

with Ada.Text_IO; use Ada.Text_IO;

procedure Traffic is

begin
end Traffic;
A pragma is a compiler directive that conveys information to the compiler to allow specific manipulation of compiled output. Certain pragmas are built into the language while other are implementation-specific.

Examples of common usage of compiler pragmas would be to disable certain features, such as run-time type checking or array subscript boundary checking, or to instruct the compiler to insert object code in lieu of a function call (as C/C++ does with inline functions).







</doc>
<doc id="1247" url="https://en.wikipedia.org/wiki?curid=1247" title="Alfonso Cuarón">
Alfonso Cuarón

Alfonso Cuarón Orozco (; born November 28, 1961) is a Mexican film director, screenwriter, producer, and editor. He is best known for his dramas "A Little Princess" (1995) and "Y Tu Mamá También" (2001), fantasy film "Harry Potter and the Prisoner of Azkaban" (2004), and science fiction thrillers "Children of Men" (2006) and "Gravity" (2013). Cuarón is the first Mexican director to win an Oscar for Best Director.

Most of his work has been praised by both audiences and critics, and has been nominated for six Academy Awards including Best Original Screenplay for "Y Tu Mamá También", and both Best Adapted Screenplay and Best Film Editing for "Children of Men". For "Gravity", Cuarón received several major accolades for his achievement in direction, winning in the respective categories at the Academy Awards, the Golden Globe Awards, the BAFTA Awards and the Directors Guild of America; and in addition winning the BAFTA Award Best British Film and the Academy Award for Best Film Editing (shared with Mark Sanger). He was also awarded the BAFTA Award for Best Film Not in the English Language as producer of "Pan's Labyrinth" (2006).

Cuarón's brother Carlos, as well as his son Jonás, are also writers and directors and have both acted as co-writers in some of his works. He is also close friends with fellow Mexican filmmakers Guillermo del Toro and Alejandro G. Iñárritu, collectively known as "The Three Amigos of Cinema".

Alfonso Cuarón Orozco was born in Mexico City on November 28, 1961, the son of Alfredo Cuarón, a nuclear physicist who worked for the United Nations' International Atomic Energy Agency for many years. He has two brothers, Carlos, also a filmmaker, and Alfredo, a conservation biologist. Cuarón studied philosophy at the National Autonomous University of Mexico (UNAM) and filmmaking at CUEC (Centro Universitario de Estudios Cinematográficos), a school within the same university. There, he met the director Carlos Marcovich and cinematographer Emmanuel Lubezki, and they made what would be his first short film, "Vengeance Is Mine".

Cuarón began working in television in Mexico, first as a technician and then as a director. His television work led to assignments as an assistant director for several film productions including " La Gran Fiesta", "" and "Romero", and in 1991, he landed his first big-screen directorial assignment.

"Sólo con tu pareja" was a sex comedy about a womanizing businessman (played by Daniel Giménez Cacho) who, after having sex with an attractive nurse, is fooled into believing he's contracted AIDS. In addition to writing, producing and directing, Cuarón co-edited the film with Luis Patlán. It is somewhat unusual for directors to be credited co-editors, although the Coen Brothers and Robert Rodriguez have both directed and edited nearly all of their films. Cuarón continued this close involvement in editing on several of his later films.

The film, which also starred cabaret singer Astrid Hadad and model/actress Claudia Ramírez (with whom Cuarón was linked between 1989 and 1993), was a big hit in Mexico. After this success, director Sydney Pollack hired Cuarón to direct an episode of "Fallen Angels", a series of neo-noir stories produced for the Showtime premium cable network in 1993; other directors who worked on the series included Steven Soderbergh, Jonathan Kaplan, Peter Bogdanovich and Tom Hanks.

In 1995, Cuarón released his first feature film produced in the United States, "A Little Princess", an adaptation of Frances Hodgson Burnett's classic novel. Cuarón's next feature was also a literary adaptation, a modernized version of Charles Dickens's "Great Expectations" starring Ethan Hawke, Gwyneth Paltrow and Robert De Niro.

Cuarón's next project found him returning to Mexico with a Spanish-speaking cast to film "Y Tu Mamá También", starring Gael García Bernal, Diego Luna and Maribel Verdú. It was a provocative and controversial road comedy about two sexually obsessed teenagers who take an extended road trip with an attractive married woman that is much older than them. The film's open portrayal of sexuality and frequent rude humor, as well as the politically and socially relevant asides, made the film an international hit and a major success with critics. Cuarón shared an Academy Award nomination for Best Original Screenplay with co-writer and brother Carlos Cuarón.

In 2004, Cuarón directed the third film in the successful "Harry Potter" series, "Harry Potter and the Prisoner of Azkaban". Cuarón faced criticism from some of the more purist "Harry Potter" fans for his approach to the film. At the time of the movie's release, however, author J. K. Rowling, who had seen and loved Cuarón's film "Y Tu Mamá También", said that it was her personal favorite from the series so far. Critically, the film was also better received than the first two installments, with some critics remarking its new tone and for being the first "Harry Potter" film to truly capture the essence of the novels. It remained as the most critically acclaimed film of the "Harry Potter" film franchise.

Cuarón's feature "Children of Men", an adaptation of the P. D. James novel starring Clive Owen, Julianne Moore and Michael Caine, received wide critical acclaim, including three Academy Award nominations. Cuarón himself received two nominations for his work on the film in Best Film Editing (with Alex Rodríguez) and Best Adapted Screenplay (with several collaborators).

He created the production and distribution company Esperanto Filmoj ("Esperanto Films", named because of his support for the international language Esperanto), which has credits in the films "Duck Season", "Pan's Labyrinth", and "Gravity".

Cuarón also directed the controversial public service announcement "I Am Autism" for Autism Speaks that was sharply criticized by disability rights groups for its negative portrayal of autism.

In 2010, Cuarón began to develop the film "Gravity", a drama set in space. He was joined by producer David Heyman, with whom Cuarón worked on "Harry Potter and the Prisoner of Azkaban". Starring Sandra Bullock and George Clooney, the film was released in the fall of 2013 and opened the 70th Venice International Film Festival in August. On January 12, 2014, Alfonso accepted the Golden Globe Award in the category of Best Director. The film received ten Academy Award nominations, including Best Picture and Best Director. Cuarón won for Best Directing, becoming the first Latin American to win the award, while he and Mark Sanger shared the award for Best Film Editing.

In 2013, Cuarón created "Believe", a science fiction/fantasy/adventure series that was broadcast as part of the 2013–14 United States network television schedule on NBC as a mid-season entry. The series was created by Cuarón for Bad Robot Productions and Warner Bros. Television. In 2014, "TIME" placed him in its list of "100 Most Influential People in the World" – Pioneers.

In May 2015 Cuarón was announced as the President of the Jury for the 72nd Venice International Film Festival.

On September 8, 2016, it was announced that he would be writing and directing "Roma", a project focusing on a Mexican family living in Mexico City in the 1970s. Production began in fall 2016. The project will be produced by Cuarón, Gabriela Rodríguez and Nicolás Celis. On November 3, 2016, it was revealed that the crew was robbed on set during filming.

Cuarón is a vegetarian and has been living in London since 2000. He was 20 when his girlfriend at the time became pregnant with Jonás. He was married to Italian actress and freelance journalist Annalisa Bugliani from 2001 to 2008. They have two children: daughter Tess Bu Cuarón (born 2002) and son Olmo Teodoro Cuarón (born 2005).







</doc>
<doc id="1252" url="https://en.wikipedia.org/wiki?curid=1252" title="Arianism">
Arianism

In Christianity, Arianism is a monotheistic Christological doctrine which asserts the belief that Jesus Christ is the Son of God who was begotten by God the Father at a point in time, is distinct from the Father and is therefore subordinate to the Father. Arian teachings were first attributed to Arius (c. AD 256–336), a Christian presbyter in Alexandria, Egypt. The teachings of Arius and his supporters were opposed to the theological views held by Homoousian Christians, regarding the nature of the Trinity and the nature of Christ. The Arian concept of Christ is based on the belief that the Son of God did not always exist but was begotten by God the Father.

There was a dispute between two interpretations (Arianism and Homoousianism) based upon the theological orthodoxy of the time, and both of them attempted to solve its theological dilemmas. So there were, initially, two equally orthodox interpretations which initiated a conflict in order to attract adepts and define the new orthodoxy. Homoousianism was formally affirmed by the first two Ecumenical Councils. The Ecumenical First Council of Nicaea of 325 deemed Arianism to be a heresy. All mainstream branches of Christianity now consider Arianism to be heterodox and heretical.

According to Everett Ferguson, "The great majority of Christians had no clear views about the nature of the Trinity and they did not understand what was at stake in the issues that surrounded it." At the regional First Synod of Tyre in 335, Arius was exonerated. Constantine the Great was baptized by the Arian bishop Eusebius of Nicomedia. After the deaths of both Arius and Constantine, Arius was again anathemised and pronounced a heretic again at the Ecumenical First Council of Constantinople of 381. The Roman Emperors Constantius II (337–361) and Valens (364–378) were Arians or Semi-Arians, as was the first King of Italy, Odoacer (433?–493), and the Lombards were also Arians or Semi-Arians until the 7th century.

Arianism is also used to refer to other nontrinitarian theological systems of the 4th century, which regarded Jesus Christ—the Son of God, the Logos—as either a begotten being (as in Arianism proper and Anomoeanism) or as neither uncreated nor created in the sense other beings are created (as in Semi-Arianism).

Arius had been a pupil of Lucian of Antioch at Lucian's private academy in Antioch and inherited from him a modified form of the teachings of Paul of Samosata. He taught that God the Father and the Son of God did not always exist together eternally.

Arians taught that the Logos was a divine being begotten by God the Father before the creation of the world, made him a medium through whom everything else was created, and that the Son of God is subordinate to God the Father. A verse from Proverbs was also used: "The Lord created me at the beginning of his work" (Proverbs ). Therefore, the Son was rather the very first and the most perfect of God's creatures, and he was made "God" only by the Father's permission and power.

Controversy over Arianism arose in the late 3rd century and persisted throughout most of the 4th century. It involved most church members—from simple believers, priests, and monks to bishops, emperors, and members of Rome's imperial family. Two Roman emperors, Constantius II and Valens, became Arians or Semi-Arians, as did prominent Gothic, Vandal, and Lombard warlords both before and after the fall of the Western Roman Empire. Such a deep controversy within the Church during this period of its development could not have materialized without significant historical influences providing a basis for the Arian doctrines. Of the roughly three hundred bishops in attendance at the Council of Nicea, two bishops did not sign the Nicene Creed that condemned Arianism. Emperor Constantine also ordered a penalty of death for those who refused to surrender the Arian writings:

Reconstructing what Arius actually taught, and why, is a formidable task, both because little of his own work survives except in quotations selected for polemical purposes by his opponents, and also because there is no certainty about what theological and philosophical traditions formed his thought.

Arians do not believe in the traditional doctrine of the Trinity. The letter of Arian Auxentius regarding the Arian missionary Ulfilas gives a picture of Arian beliefs. Arian Ulfilas, who was ordained a bishop by Arian Eusebius of Nicomedia and returned to his people to work as a missionary, believed: God, the Father, ("unbegotten" God; Almighty God) always existing and who is the only true God (John 17:3). The Son of God, Jesus Christ, ("only-begotten God" John 1:18; Mighty God Isaiah 9:6) begotten before time began (Proverbs 8:22–29; Revelation 3:14; Colossians 1:15) and who is Lord/Master (1 Cor 8:6). The Holy Spirit (the illuminating and sanctifying power, who is neither God the Father nor Lord/Master. First Corinthians 8:5–8:6 was cited as proof text:

The creed of Arian Ulfilas (c. 311 – 383), which concludes a letter praising him written by Auxentius, distinguishes God the Father ("unbegotten"), who is the only true God from Son of God ("only-begotten"), who is Lord/Master; and the Holy Spirit, the illuminating and sanctifying power, who is neither God the Father nor Lord/Master:

A letter from Arius (c. 250–336) to the Arian Eusebius of Nicomedia (died 341) succinctly states the core beliefs of the Arians:

According to Bart Ehrman, the dispute between Trinitarianism and Arianism was about:


Arianism had several different variants, including Eunomianism and Homoian Arianism. Homoian Arianism is associated with Akakius and Eudoxius. Homoian Arianism avoided the use of the word "ousia" to describe the relation of Father to Son, and described these as "like" each other. Hanson lists twelve creeds that reflect the Homoian faith:

In 321, Arius was denounced by a synod at Alexandria for teaching a heterodox view of the relationship of Jesus to God the Father. Because Arius and his followers had great influence in the schools of Alexandria—counterparts to modern universities or seminaries—their theological views spread, especially in the eastern Mediterranean.

By 325, the controversy had become significant enough that the Emperor Constantine called an assembly of bishops, the First Council of Nicaea, which condemned Arius's doctrine and formulated the original Nicene Creed of 325. The Nicene Creed's central term, used to describe the relationship between the Father and the Son, is Homoousios (), or Consubstantiality, meaning "of the same substance" or "of one being". (The Athanasian Creed is less often used but is a more overtly anti-Arian statement on the Trinity.)

The focus of the Council of Nicaea was the nature of the Son of God and his precise relationship to God the Father. (see Paul of Samosata and the Synods of Antioch). Arius taught that Jesus Christ was divine/holy and was sent to earth for the salvation of mankind but that Jesus Christ was not equal to God the Father (infinite, primordial origin) in rank "and" that God the Father and the Son of God were not equal to the Holy Spirit (power of God the Father). Under Arianism, Christ was instead not consubstantial with God the Father since both the Father and the Son under Arius were made of "like" essence or being (see homoiousia) but not of the same essence or being (see homoousia).

In the Arian view, God the Father is a Deity and is divine "and" the Son of God is not a Deity but divine (I, the LORD, am Deity alone. Isaiah 46:9). God the Father sent Jesus to earth for salvation of mankind (John 17:3). Ousia is essence or being, in Eastern Christianity, and is the aspect of God that is completely incomprehensible to mankind and human perception. It is all that subsists by itself and which has not its being in another, God the Father and God the Son and God the Holy Spirit all being uncreated.

According to the teaching of Arius, the pre-existent Logos and thus the incarnate Jesus Christ was a begotten being; only the Son was directly begotten by God the Father, before ages, but was of a distinct, though similar, essence or substance from the Creator. His opponents argued that this would make Jesus less than God and that this was heretical. Much of the distinction between the differing factions was over the phrasing that Christ expressed in the New Testament to express submission to God the Father. The theological term for this submission is kenosis. This Ecumenical council declared that Jesus Christ was a distinct being of God in existence or reality (hypostasis), which the Latin fathers translated as persona. Jesus was God in essence, being, and/or nature (ousia), which the Latin fathers translated as substantia.

Constantine is believed to have exiled those who refused to accept the Nicean creed—Arius himself, the deacon Euzoios, and the Libyan bishops Theonas of Marmarica and Secundus of Ptolemais—and also the bishops who signed the creed but refused to join in condemnation of Arius, Eusebius of Nicomedia and Theognis of Nicaea. The Emperor also ordered all copies of the "Thalia", the book in which Arius had expressed his teachings, to be burned. However, there is no evidence that his son and ultimate successor, Constantius II, who was a Semi-Arian Christian, was exiled.

Although he was committed to maintaining what the church had defined at Nicaea, Constantine was also bent on pacifying the situation and eventually became more lenient toward those condemned and exiled at the council. First he allowed Eusebius of Nicomedia, who was a protégé of his sister, and Theognis to return once they had signed an ambiguous statement of faith. The two, and other friends of Arius, worked for Arius's rehabilitation.

At the First Synod of Tyre in AD 335, they brought accusations against Athanasius, now bishop of Alexandria, the primary opponent of Arius. After this, Constantine had Athanasius banished since he considered him an impediment to reconciliation. In the same year, the Synod of Jerusalem under Constantine's direction readmitted Arius to communion in AD 336. Arius died on the way to this event in Constantinople. Some scholars suggest that Arius may have been poisoned by his opponents. Eusebius and Theognis remained in the Emperor's favor, and when Constantine, who had been a catechumen much of his adult life, accepted baptism on his deathbed, it was from Eusebius of Nicomedia.

The historian Jacob Burckhardt wrote of the Council: 
The Council of Nicaea did not end the controversy, as many bishops of the Eastern provinces disputed the "homoousios", the central term of the Nicene creed, as it had been used by Paul of Samosata, who had advocated a monarchianist Christology. Both the man and his teaching, including the term "homoousios", had been condemned by the Synods of Antioch in 269.

Hence, after Constantine's death in 337, open dispute resumed again. Constantine's son Constantius II, who had become Emperor of the eastern part of the Empire, actually encouraged the Arians and set out to reverse the Nicene creed. His advisor in these affairs was Eusebius of Nicomedia, who had already at the Council of Nicea been the head of the Arian party, who also was made bishop of Constantinople.

Constantius used his power to exile bishops adhering to the Nicene creed, especially St Athanasius of Alexandria, who fled to Rome. In 355 Constantius became the sole Emperor and extended his pro-Arian policy toward the western provinces, frequently using force to push through his creed, even exiling Pope Liberius and installing Antipope Felix II.

The third Council of Sirmium in 357 was the high point of Arianism. The Seventh Arian Confession (Second Sirmium Confession) held that both "homoousios" (of one substance) and "homoiousios" (of similar substance) were unbiblical and that the Father is greater than the Son. (This confession was later known as the Blasphemy of Sirmium.)
But since many persons are disturbed by questions concerning what is called in Latin "substantia", but in Greek "ousia", that is, to make it understood more exactly, as to 'coessential,' or what is called, 'like-in-essence,' there ought to be no mention of any of these at all, nor exposition of them in the Church, for this reason and for this consideration, that in divine Scripture nothing is written about them, and that they are above men's knowledge and above men's understanding;

As debates raged in an attempt to come up with a new formula, three camps evolved among the opponents of the Nicene creed. The first group mainly opposed the Nicene terminology and preferred the term "homoiousios" (alike in substance) to the Nicene "homoousios", while they rejected Arius and his teaching and accepted the equality and coeternality of the persons of the Trinity. Because of this centrist position, and despite their rejection of Arius, they were called "semi-Arians" by their opponents. The second group also avoided invoking the name of Arius, but in large part followed Arius' teachings and, in another attempted compromise wording, described the Son as being like ("homoios") the Father. A third group explicitly called upon Arius and described the Son as unlike ("anhomoios") the Father. Constantius wavered in his support between the first and the second party, while harshly persecuting the third.

Epiphanius of Salamis labelled the party of Basil of Ancyra in 358 "Semi-Arianism". This is considered unfair by Kelly who states that some members of the group were virtually orthodox from the start but disliked the adjective "homoousios" while others had moved in that direction after the out-and-out Arians had come into the open.

The debates among these groups resulted in numerous synods, among them the Council of Sardica in 343, the Council of Sirmium in 358 and the double Council of Rimini and Seleucia in 359, and no fewer than fourteen further creed formulas between 340 and 360, leading the pagan observer Ammianus Marcellinus to comment sarcastically: "The highways were covered with galloping bishops." None of these attempts were acceptable to the defenders of Nicene orthodoxy: writing about the latter councils, Saint Jerome remarked that the world "awoke with a groan to find itself Arian."

After Constantius' death in 361, his successor Julian, a devotee of Rome's pagan gods, declared that he would no longer attempt to favor one church faction over another, and allowed all exiled bishops to return; this resulted in further increasing dissension among Nicene Christians. The Emperor Valens, however, revived Constantius' policy and supported the "Homoian" party, exiling bishops and often using force. During this persecution many bishops were exiled to the other ends of the Empire, (e.g., St Hilary of Poitiers to the Eastern provinces). These contacts and the common plight subsequently led to a rapprochement between the Western supporters of the Nicene creed and the "homoousios" and the Eastern semi-Arians.

It was not until the co-reigns of Gratian and Theodosius that Arianism was effectively wiped out among the ruling class and elite of the Eastern Empire. Theodosius' wife St Flacilla was instrumental in his campaign to end Arianism. Valens died in the Battle of Adrianople in 378 and was succeeded by Theodosius I, who adhered to the Nicene creed. This allowed for settling the dispute.

Two days after Theodosius arrived in Constantinople, 24 November 380, he expelled the Homoiousian bishop, Demophilus of Constantinople, and surrendered the churches of that city to Gregory Nazianzus, the leader of the rather small Nicene community there, an act which provoked rioting. Theodosius had just been baptized, by bishop Acholius of Thessalonica, during a severe illness, as was common in the early Christian world. In February he and Gratian had published an edict that all their subjects should profess the faith of the bishops of Rome and Alexandria (i.e., the Nicene faith), or be handed over for punishment for not doing so.

Although much of the church hierarchy in the East had opposed the Nicene creed in the decades leading up to Theodosius' accession, he managed to achieve unity on the basis of the Nicene creed. In 381, at the Second Ecumenical Council in Constantinople, a group of mainly Eastern bishops assembled and accepted the Nicene Creed of 381, which was supplemented in regard to the Holy Spirit, as well as some other changes: see Comparison between Creed of 325 and Creed of 381. This is generally considered the end of the dispute about the Trinity and the end of Arianism among the Roman, non-Germanic peoples.

During the time of Arianism's flowering in Constantinople, the Gothic convert Ulfilas (later the subject of the letter of Auxentius cited above) was sent as a missionary to the Gothic tribes across the Danube, a mission favored for political reasons by emperor Constantius II. Ulfilas' initial success in converting this Germanic people to an Arian form of Christianity was strengthened by later events. When the Germanic peoples entered the provinces of the Western Roman Empire and began founding their own kingdoms there, most had been Arian Christians for more than a century.

The conflict in the 4th century AD had seen Arian and Nicene factions struggling for control of the Church. In contrast, among the Arian German kingdoms established in the collapsing Western Empire in the 5th century, there were entirely separate Arian and Nicene Churches with parallel hierarchies, each serving different sets of believers. The Germanic elites were Arians, and the Romance majority population was Nicene.

Most Germanic tribes were generally tolerant of the Nicene beliefs of their subjects. However, the Vandals tried for several decades to force their Arian beliefs on their North African Nicene subjects, exiling Nicene clergy, dissolving monasteries, and exercising heavy pressure on non-conforming Nicene Christians.
The apparent resurgence of Arianism after Nicaea was more an anti-Nicene reaction exploited by Arian sympathizers than a pro-Arian development. By the end of the 4th century it had surrendered its remaining ground to Trinitarianism. In western Europe, Arianism, which had been taught by Ulfilas, the Arian missionary to the Germanic tribes, was dominant among the Goths, Lombards and Vandals. By the 8th century it had ceased to be the tribes' mainstream belief as the tribal rulers gradually came to adopt Nicene orthodoxy. This trend began in 496 with Clovis I of the Franks, then Reccared I of the Visigoths in 587 and Aripert I of the Lombards in 653.

The Franks and the Anglo-Saxons were unlike the other Germanic peoples in that they entered the empire as pagans and converted to Chalcedonian Christianity directly, guided by their kings, Clovis and Æthelberht of Kent. The remaining tribes – the Vandals and the Ostrogoths – did not convert as a people nor did they maintain territorial cohesion. Having been militarily defeated by the armies of Emperor Justinian I, the remnants were dispersed to the fringes of the empire and became lost to history. The Vandalic War of 533–534 dispersed the defeated Vandals. Following their final defeat at the Battle of Mons Lactarius in 553, the Ostrogoths went back north and (re)settled in south Austria.
Much of south-eastern Europe and central Europe, including many of the Goths and Vandals respectively, had embraced Arianism (the Visigoths converted to Arian Christianity in 376), which led to Arianism being a religious factor in various wars in the Roman Empire. In the west, organized Arianism survived in North Africa, in Hispania, and parts of Italy until it was finally suppressed in the 6th and 7th centuries. Grimwald, King of the Lombards (662–671), and his young son and successor Garibald (671), were the last Arian kings in Europe.

Following the Protestant Reformation from 1517, it did not take long for Arian and other non-trinitarian views to resurface. The first recorded English antitrinitarian was John Assheton, who was forced to recant before Thomas Cranmer in 1548. At the Anabaptist Council of Venice 1550, the early Italian instigators of the Radical Reformation committed to the views of Miguel Servetus (burned alive by Calvin in 1553), and these were promulgated by Giorgio Biandrata and others into Poland and Transylvania.

The antitrinitarian wing of the Polish Reformation separated from the Calvinist "ecclesia maior" to form the "ecclesia minor" or Polish Brethren. These were commonly referred to as "Arians" due to their rejection of the Trinity, though in fact the Socinians, as they were later known, went further than Arius to the position of Photinus. The epithet "Arian" was also applied to the early Unitarians such as John Biddle though in denial of the pre-existence of Christ they were again largely Socinians not Arians.

In 1683, when Anthony Ashley Cooper, 1st Earl of Shaftesbury, lay dying in Amsterdam – driven into exile by his outspoken opposition to King Charles II – he spoke to the minister Robert Ferguson, and professed himself an Arian.

In the 18th century the "dominant trend" in Britain, particularly in Latitudinarianism, was towards Arianism, with which the names of Samuel Clarke, Benjamin Hoadly, William Whiston and Isaac Newton are associated. To quote the "Encyclopædia Britannica" article on Arianism: "In modern times some Unitarians are virtually Arians in that they are unwilling either to reduce Christ to a mere human being or to attribute to him a divine nature identical with that of the Father." However, their doctrines cannot be considered representative of traditional Arian doctrines or vice versa.

A similar view was held by the ancient anti-Nicene Pneumatomachi (Greek: , "breath" or "spirit" and "fighters", combining as "fighters against the spirit"), so called because they opposed the deifying of the Nicene Holy Ghost. However, the Pneumatomachi were adherents of Macedonianism, and though their beliefs were somewhat reminiscent of Arianism, they were distinct enough to be distinguishably different.

The Iglesia ni Cristo is one of the largest groups that teaches a similar doctrine, though they are really closer to Socinianism, believing the Word in John 1:1 is God's plan of salvation, not Christ. So Christ did not preexist.

The teachings of the first two ecumenical councils – which entirely reject Arianism – are held by the Catholic Church, the Eastern Orthodox Church, the Oriental Orthodox Churches, the Assyrian Church of the East and all churches founded during the Reformation in the 16th century or influenced by it (Lutheran, Reformed/Presbyterian, and Anglican). Also, nearly all Protestant groups (such as Methodists, Baptists, and most Pentecostals) entirely reject the teachings associated with Arianism. Modern groups which currently appear to embrace some of the principles of Arianism include Unitarians and Jehovah's Witnesses. Although the origins of their beliefs are not necessarily attributed to the teachings of Arius, many of the core beliefs of Unitarians and Jehovah's Witnesses are entirely similar to them.

Jehovah's Witnesses are often referred to as "modern-day Arians" or they are sometimes referred to as "Semi-Arians", usually by their opponents. While there are some significant similarities in theology and doctrine, the Witnesses differ from Arians by saying that the Son can fully know the Father (something which Arius himself denied), and by their denial of personality to the Holy Spirit. The original Arians also generally prayed directly to Jesus, whereas the Witnesses pray to God, through Jesus as a mediator.

The Church of God (7th day) - Salem Conference, a line of Sabbatarian Adventists hold views similar to Arianism:
Other groups which oppose the belief in the Trinity are not necessarily Arian.




</doc>
<doc id="1254" url="https://en.wikipedia.org/wiki?curid=1254" title="August 1">
August 1





</doc>
