<doc id="7794" url="https://en.wikipedia.org/wiki?curid=7794" title="Crystallography">
Crystallography

Crystallography is the experimental science of determining the arrangement of atoms in crystalline solids (see crystal structure). The word "crystallography" derives from the Greek words "crystallon" "cold drop, frozen drop", with its meaning extending to all solids with some degree of transparency, and "graphein" "to write". In July 2012, the United Nations recognised the importance of the science of crystallography by proclaiming that 2014 would be the International Year of Crystallography. X-ray crystallography is used to determine the structure of large biomolecules such as proteins. 
Before the development of X-ray diffraction crystallography (see below), the study of crystals was based on physical measurements of their geometry. This involved measuring the angles of crystal faces relative to each other and to theoretical reference axes (crystallographic axes), and establishing the symmetry of the crystal in question. This physical measurement is carried out using a goniometer. The position in 3D space of each crystal face is plotted on a stereographic net such as a Wulff net or Lambert net. The pole to each face is plotted on the net. Each point is labelled with its Miller index. The final plot allows the symmetry of the crystal to be established.

Crystallographic methods now depend on analysis of the diffraction patterns of a sample targeted by a beam of some type. X-rays are most commonly used; other beams used include electrons or neutrons. This is facilitated by the wave properties of the particles. Crystallographers often explicitly state the type of beam used, as in the terms "X-ray crystallography, neutron diffraction" and "electron diffraction". These three types of radiation interact with the specimen in different ways. 
Because of these different forms of interaction, the three types of radiation are suitable for different crystallographic studies.

An image of a small object is made using a lens to focus the beam, similar to a lens in a microscope. However, the wavelength of visible light (about 4000 to 7000 ångström) is three orders of magnitude longer than the length of typical atomic bonds and atoms themselves (about 1 to 2 Å). Therefore, obtaining information about the spatial arrangement of atoms requires the use of radiation with shorter wavelengths, such as X-ray or neutron beams. Employing shorter wavelengths implied abandoning microscopy and true imaging, however, because there exists no material from which a lens capable of focusing this type of radiation can be created. Scientists have had some success focusing X-rays with microscopic Fresnel zone plates made from gold, and by critical-angle reflection inside long tapered capillaries. Diffracted X-ray or neutron beams cannot be focused to produce images, so the sample structure must be reconstructed from the diffraction pattern. Sharp features in the diffraction pattern arise from periodic, repeating structure in the sample, which are often very strong due to coherent reflection of many photons from many regularly spaced instances of similar structure, while non-periodic components of the structure result in diffuse (and usually weak) diffraction features - areas with a higher density and repetition of atom order tend to reflect more light toward one point in space when compared to those areas with fewer atoms and less repetition.

Because of their highly ordered and repetitive structure, crystals give diffraction patterns of sharp Bragg reflection spots, and are ideal for analyzing the structure of solids.


Some materials that have been analyzed crystallographically, such as proteins, do not occur naturally as crystals. Typically, such molecules are placed in solution and allowed to slowly crystallize through vapor diffusion. A drop of solution containing the molecule, buffer, and precipitants is sealed in a container with a reservoir containing a hygroscopic solution. Water in the drop diffuses to the reservoir, slowly increasing the concentration and allowing a crystal to form. If the concentration were to rise more quickly, the molecule would simply precipitate out of solution, resulting in disorderly granules rather than an orderly and hence usable crystal.

Once a crystal is obtained, data can be collected using a beam of radiation. Although many universities that engage in crystallographic research have their own X-ray producing equipment, synchrotrons are often used as X-ray sources, because of the purer and more complete patterns such sources can generate. Synchrotron sources also have a much higher intensity of X-ray beams, so data collection takes a fraction of the time normally necessary at weaker sources. Complementary neutron crystallography techniques are used to identify the positions of hydrogen atoms, since X-rays only interact very weakly with light elements such as hydrogen.

Producing an image from a diffraction pattern requires sophisticated mathematics and often an iterative process of modelling and refinement. In this process, the mathematically predicted diffraction patterns of an hypothesized or "model" structure are compared to the actual pattern generated by the crystalline sample. Ideally, researchers make several initial guesses, which through refinement all converge on the same answer. Models are refined until their predicted patterns match to as great a degree as can be achieved without radical revision of the model. This is a painstaking process, made much easier today by computers.

The mathematical methods for the analysis of diffraction data only apply to "patterns," which in turn result only when waves diffract from orderly arrays. Hence crystallography applies for the most part only to crystals, or to molecules which can be coaxed to crystallize for the sake of measurement. In spite of this, a certain amount of molecular information can be deduced from patterns that are generated by fibers and powders, which while not as perfect as a solid crystal, may exhibit a degree of order. This level of order can be sufficient to deduce the structure of simple molecules, or to determine the coarse features of more complicated molecules. For example, the double-helical structure of DNA was deduced from an X-ray diffraction pattern that had been generated by a fibrous sample.

Crystallography is used by materials scientists to characterize different materials. In single crystals, the effects of the crystalline arrangement of atoms is often easy to see macroscopically, because the natural shapes of crystals reflect the atomic structure. In addition, physical properties are often controlled by crystalline defects. The understanding of crystal structures is an important prerequisite for understanding crystallographic defects. Mostly, materials do not occur as a single crystal, but in poly-crystalline form (i.e., as an aggregate of small crystals with different orientations). Because of this, the powder diffraction method, which takes diffraction patterns of polycrystalline samples with a large number of crystals, plays an important role in structural determination.

Other physical properties are also linked to crystallography. For example, the minerals in clay form small, flat, platelike structures. Clay can be easily deformed because the platelike particles can slip along each other in the plane of the plates, yet remain strongly connected in the direction perpendicular to the plates. Such mechanisms can be studied by crystallographic texture measurements.

In another example, iron transforms from a body-centered cubic (bcc) structure to a face-centered cubic (fcc) structure called austenite when it is heated. The fcc structure is a close-packed structure unlike the bcc structure; thus the volume of the iron decreases when this transformation occurs.

Crystallography is useful in phase identification. When manufacturing or using a material, it is generally desirable to know what compounds and what phases are present in the material, as their composition, structure and proportions will influence the material's properties. Each phase has a characteristic arrangement of atoms. X-ray or neutron diffraction can be used to identify which patterns are present in the material, and thus which compounds are present. Crystallography covers the enumeration of the symmetry patterns which can be formed by atoms in a crystal and for this reason is related to group theory and geometry.

X-ray crystallography is the primary method for determining the molecular conformations of biological macromolecules, particularly protein and nucleic acids such as DNA and RNA. In fact, the double-helical structure of DNA was deduced from crystallographic data. The first crystal structure of a macromolecule was solved in 1958, a three-dimensional model of the myoglobin molecule obtained by X-ray analysis. The Protein Data Bank (PDB) is a freely accessible repository for the structures of proteins and other biological macromolecules. Computer programs such as RasMol or Pymol can be used to visualize biological molecular structures.
Neutron crystallography is often used to help refine structures obtained by X-ray methods or to solve a specific bond; the methods are often viewed as complementary, as X-rays are sensitive to electron positions and scatter most strongly off heavy atoms, while neutrons are sensitive to nucleus positions and scatter strongly even off many light isotopes, including hydrogen and deuterium.
Electron crystallography has been used to determine some protein structures, most notably membrane proteins and viral capsids.

The "International Tables for Crystallography" is an eight book series that outlines the standard notations for formatting, describing and testing crystals. The series contains books that covers analysis methods and the mathematical procedures for determining organic structure though x-ray crystallography, electron diffraction, and neutron diffraction. The International tables are focused on procedures, techniques and descriptions and does not list the physical properties of individual crystals themselves. Each book is about 1000 pages and the titles of the books are:



</doc>
<doc id="7796" url="https://en.wikipedia.org/wiki?curid=7796" title="Claude Auchinleck">
Claude Auchinleck

Field Marshal Sir Claude John Eyre Auchinleck (21 June 1884 – 23 March 1981) was a British Army commander during the Second World War. He was a career soldier who spent much of his military career in India, where he rose to become Commander-in-Chief of the Indian Army by early 1941. In July 1941 he was appointed Commander-in-Chief of the Middle East theatre, but after initial successes the war in North Africa turned against the British, and he was relieved of the post in 1942 during the crucial Alamein campaign. In June 1943 he was once more appointed Commander-in-Chief, India, where his support through the organisation of supply, maintenance and training for Slim's Fourteenth Army played an important role in its success. He served as Commander-in-Chief India until Partition in 1947, when he assumed the role of Supreme Commander of all British forces in India and Pakistan until late 1948.

Born at 89 Victoria Road in Aldershot, the son of Colonel John Auchinleck and Mary Auchinleck, Auchinleck attended Eagle House School at Crowthorne and then Wellington College on scholarships. After attending the Royal Military College, Sandhurst, Auchinleck was commissioned as an unattached second lieutenant in the Indian Army on 21 January 1903 and joined to the 62nd Punjabis in April 1904. He soon learnt several Indian languages and, able to speak fluently with his soldiers, he absorbed a knowledge of local dialects and customs: this familiarity engendered a lasting mutual respect, enhanced by his own personality. He was promoted to lieutenant on 21 April 1905 and then spent the next two years in Tibet and Sikkim before moving to Benares in 1907 where he caught diphtheria. After briefly serving with the Royal Inniskilling Fusiliers at Aldershot he returned Benares in 1909 and became adjutant of the 62nd Punjabis with promotion to captain on 21 January 1912. Auchinleck was an active freemason.

Auchinleck saw active service in the First World War and was deployed with his regiment to defend the Suez Canal: in February 1915 he was in action against the Turks at Ismaïlia. His regiment moved into Aden to counter the Turkish threat there in July 1915. The 6th Indian Division, of which the 62nd Punjabis were a part, was landed at Basra on 31 December 1915 for the Mesopotamian campaign. In July 1916 Auchinleck was promoted acting major and made second in command of his battalion. He took part in a series of fruitless attacks on the Turks at the Battle of Hanna in January 1916 and was one of the few British officers in his regiment to survive these actions. He became acting commanding officer of his battalion in February 1917 and led his regiment at the Second Battle of Kut in February 1917 and the Fall of Baghdad in March 1917. Having been mentioned in despatches and having received the Distinguished Service Order in 1917 for his service in Mesopotamia, he was promoted to the substantive rank of major on 21 January 1918, to temporary lieutenant-colonel on 23 May 1919 and to brevet lieutenant-colonel on 15 November 1919 for his "distinguished service in Southern and Central Kurdistan" on the recommendation of the Commander-in-Chief of the Mesopotamia Expeditionary Force.

Auchinleck attended the Staff College, Quetta between 1920 and 1921. He married Jessie Stewart in 1921. Jessie had been born in 1900 in Tacoma, Washington, to Alexander Stewart, head of the Blue Funnel Line that plied the west coast of the United States. When he died about 1919, their mother took her, her twin brother Alan and her younger brother Hepburne back to Bun Rannoch, the family estate at Innerhadden in Perthshire. Holidaying at Grasse on the French Riviera, Auchinleck, who was on leave from India at the time, met Jessie on the tennis courts. She was a high-spirited, blue-eyed beauty. Things moved quickly, and they were married within five months. Sixteen years younger than Auchinleck, Jessie became known as 'the little American girl' in India, but adapted readily to life there.

Auchinleck became temporary Deputy Assistant Quartermaster-General at Army Headquarters in February 1923 and then second-in-command of his regiment, which in the 1923 reorganisation of the Indian Army had become the 1st battalion, 1st Punjab Regiment, in September 1925. He attended the Imperial Defence College in 1927 and, having been promoted to lieutenant-colonel on 21 January 1929 he was appointed to command his regiment. Promoted to full colonel on 1 February 1930 with seniority from 15 November 1923, he became an instructor at the Staff College, Quetta in February 1930 where he remained until April 1933. He was promoted to temporary brigadier on 1 July 1933 and given command of the Peshawar Brigade, which was active in the pacification of the adjacent tribal areas during the Mohmand and Bajaur Operations between July and October 1933: during his period of command he was mentioned in despatches. He led a second punitive expedition during the Second Mohmand Campaign in August 1935 for which he was again mentioned in despatches, promoted to Major-General on 30 November 1935 and appointed a Companion of the Order of the Star of India on 8 May 1936.

On leaving his brigade command in April 1936 Auchinleck was on the unemployed list (on half pay) until September 1936 when he was appointed Deputy Chief of the General Staff and Director of Staff Duties in Delhi. He was then appointed to command the Meerut District in India in July 1938. In 1938 Auchinleck was appointed to chair a committee to consider the modernisation, composition and re-equipment of the British Indian Army: the committee's recommendations formed the basis of the 1939 Chatfield Report which outlined the transformation of the Indian Army – it grew from 183,000 in 1939 to over 2,250,000 men by the end of the war.

On the outbreak of war Auchinleck was appointed to command the Indian 3rd Infantry Division but in January 1940 was summoned to the United Kingdom to command IV Corps, the only time in the war that a wholly British corps was commanded by an Indian Army officer. He received promotion to acting Lieutenant-General on 1 February 1940 and to the substantive rank of Lieutenant-General on 16 March 1940. In May 1940 Auchinleck took over command of the Anglo-French ground forces in Norway, a military operation that was doomed to fail. After the fall of Norway, in June 1940 he briefly commanded V Corps before becoming General Officer Commanding-in-Chief, Southern Command in July 1940, where he had an uneasy relationship with his subordinate Bernard Montgomery, the new V Corps commander. Montgomery later wrote: "In the 5th Corps I first served under Auchinleck... I cannot recall that we ever agreed on anything."

Promoted to full General on 26 December 1940, Auchinleck was recalled to India in January 1941 to become Commander-in-Chief, India in which position he also was appointed to the Executive Council of the Governor-General of India and appointed ADC General to the King which ceremonial position he held until after the end of the War.

In April 1941 RAF Habbaniya was threatened by the new pro-Axis regime of Rashid Ali. This large Royal Air Force station was west of Baghdad in Iraq and General Archibald Wavell, Commander-in-Chief Middle East Command, was reluctant to intervene, despite the urgings of Winston Churchill, because of his pressing commitments in the Western Desert and Greece. Auchinleck, however, acted decisively, sending a battalion of the King's Own Royal Regiment by air to Habbaniya and shipping the Indian 10th Infantry Division by sea to Basra. Wavell was prevailed upon by London to send "Habforce", a relief column, from the British Mandate of Palestine but by the time it arrived in Habbaniya on 18 May the Anglo-Iraqi War was virtually over.

Following the see-saw of Allied and Axis successes and reverses in North Africa, Auchinleck was appointed to succeed General Sir Archibald Wavell as C-in-C Middle East Command in July 1941; Wavell took up Auchinleck's post as C-in-C of the Indian Army, swapping jobs with him.

As Commander-in-Chief Middle East Auchinleck, based in Cairo, held responsibility not just for North Africa but also for Persia and the Middle East. He launched an offensive in the Western Desert, Operation Crusader, in November 1941: despite some tactical reverses during the fighting which resulted in Auchinleck replacing the Eighth Army commander Alan Cunningham with Neil Ritchie, by the end of December the besieged garrison of Tobruk had been relieved and Rommel obliged to withdraw to El Agheila. Auchinleck appears to have believed that enemy had been defeated, writing on 12 January 1942 that the Axis forces were "beginning to feel the strain" and were "hard pressed". In fact the Axis forces had managed to withdraw in good order and a few days after Auchinleck's optimistic appreciation, having reorganised and been reinforced, struck at the dispersed and weakened British forces, driving them back to the Gazala positions near Tobruk. The British Chief of the Imperial General Staff (CIGS), General Sir Alan Brooke, wrote in his diary that it was "Nothing less than bad generalship on the part of Auchinleck. He has been overconfident and has believed everything his overoptimistic [DMI] Shearer has told him." Brooke commented that Auchinleck "could have been one of the finest of commanders" but lacked the ability to select the men to serve him. Brooke sent him one of his best armoured division commanders Richard McCreery, whose advice was ignored in favour of Dorman-Smith's.

Rommel's attack at the Battle of Gazala of 26 May 1942 resulted in a significant defeat for the British. Auchinleck's appreciation of the situation written to Ritchie on 20 May had suggested that the armoured reserves be concentrated in a position suitable to meet both a flanking attack around the south of the front or a direct attack through the centre (which was the likelihood more favoured by Auchinleck). In the event, Ritchie chose a more dispersed and rearward positioning of his two armoured divisions and when the attack in the centre came, it proved to be a diversion and the main attack, by Rommel's armoured formations, came round the southern flank. Poor initial positioning and subsequent handling and coordination of Allied formations by Ritchie and his corps commanders resulted in their heavy defeat and the Eighth Army retreating into Egypt; Tobruk fell to the Axis on 21 June 1942.

On 24 June Auchinleck stepped in to take direct command of the Eighth Army, having lost confidence in Neil Ritchie's ability to control and direct his forces. Auchinleck discarded Ritchie's plan to stand at Mersa Matruh, deciding to fight only a delaying action there, while withdrawing to the more easily defendable position at El Alamein. Here Auchinleck tailored a defence that took advantage of the terrain and the fresh troops at his disposal, stopping the exhausted German/Italian advance in the First Battle of El Alamein. Enjoying a considerable superiority of material and men over the weak German/Italian forces, Auchinleck organised a series of counter-attacks. Poorly conceived and badly coordinated, these attacks achieved little.

"The Auk", as he was known, appointed a number of senior commanders who proved to be unsuitable for their positions, and command arrangements were often characterised by bitter personality clashes. Auchinleck was an Indian Army officer and was criticised for apparently having little direct experience or understanding of British and Dominion troops. His controversial chief of operations, Major-General Dorman-Smith, was regarded with considerable distrust by many of the senior commanders in Eighth Army. By July 1942 Auchinleck had lost the confidence of Dominion commanders and relations with his British commanders had become strained.

Like his foe Rommel (and his predecessor Wavell and successor Montgomery), Auchinleck was subjected to constant political interference, having to weather a barrage of hectoring telegrams and instructions from Prime Minister Churchill throughout late 1941 and the spring and summer of 1942. Churchill constantly sought an offensive from Auchinleck, and was downcast at the military reverses in Egypt and Cyrenaica. Churchill was desperate for some sort of British victory before the planned Allied landings in North Africa, Operation Torch, scheduled for November 1942. He badgered Auchinleck immediately after the Eighth Army had all but exhausted itself after the first battle of El Alamein. Churchill and the Chief of the Imperial General Staff, Alan Brooke, flew to Cairo in early August 1942, to meet Auchinleck, where it emerged he had lost the confidence of both men. He was replaced as Commander-in-Chief Middle East Command by General Sir Harold Alexander (later Field Marshal Earl Alexander of Tunis).

Joseph M. Horodyski and Maurice Remy both praise Auchinleck as an underrated military leader who contributed the most to the successful defence of El Alamein and consequently the final defeat of Rommel in Africa. The two historians also criticize Churchill for the unreasonable decision to put the blame on Auchinleck and to relieve him.

Churchill offered Auchinleck command of the newly created Persia and Iraq Command (this having been separated from Alexander's command), but Auchinleck declined this post, as he believed that separating the area from the Middle East Command was not good policy and the new arrangements would not be workable. He set his reasons out in his letter to the Chief of the Imperial General Staff dated 14 August 1942. Instead he returned to India, where he spent almost a year "unemployed" before in June 1943 being again appointed Commander-in-Chief of the Indian Army, General Wavell meanwhile having been appointed Viceroy: on this appointment it was announced that responsibility for the prosecution of the war with Japan would move from the C-in-C India to a newly created South East Asia Command. However, the appointment of the new command's Supreme Commander, Admiral Louis Mountbatten, was not announced until August 1943 and until Mountbatten could set up his headquarters and assume control (in November) Auchinleck retained responsibility for operations in India and Burma while conducting a review and revision of Allied plans based on the decisions taken by the Allied Combined Chiefs of Staff at the Quadrant Conference which ended in August.

Following Mountbatten's arrival, Auchinleck's India Command (which had equal status with South East Asia Command in the military hierarchy) was responsible for the internal security of India, the defence of the North West Frontier and the buildup of India as a base, including most importantly the reorganisation of the Indian Army, the training of forces destined for SEAC and the lines of communication carrying men and material to the forward areas and to China. Auchinleck made the supply of Fourteenth Army, with probably the worst lines of communication of the war, his immediate priority; as William Slim, commander of the Fourteenth Army was later to write:

Auchinleck suffered a personal disappointment when his wife Jessie left him for his friend Air Chief Marshal Sir Richard Peirse. Peirse and Auchinleck had been students together at the Imperial Defence College, but that was long before. Peirse was now Allied Air Commander-in-Chief, South-East Asia, and also based in India. The affair became known to Mountbatten in early 1944, and he passed the information to the Chief of the RAF, Sir Charles Portal, hoping that Peirse would be recalled. The affair was common knowledge by September 1944, and Peirse was neglecting his duties. Mountbatten sent Peirse and Lady Auchinleck back to England on 28 November 1944, where they lived together at a Brighton hotel. Peirse had his marriage dissolved, and Auchinleck obtained a divorce in 1946. Auchinleck was reportedly very badly affected. According to his sister, he was never the same after the break-up. He always carried a photograph of Jessie in his wallet even after the divorce.

Auchinleck continued as Commander-in-Chief of the Indian Army after the end of the war helping, though much against his own convictions, to prepare the future Indian and Pakistani armies for the Partition of India: in November 1945 he was forced to commute the more serious judicial sentences awarded against officers of the Indian National Army in face of growing unease and unrest both within the Indian population, and the British Indian Army. On 1 June 1946 he was promoted to field marshal, but he refused to accept a peerage, lest he be thought associated with a policy (i.e. Partition) that he thought fundamentally dishonourable.

Sending a report to British Government on 28 September 1947 Auchinleck wrote: "I have no hesitation, whatever, in affirming that the present Indian Cabinet are implacably determined to do all in their power to prevent the establishment of the Dominion of Pakistan on firm basis." He stated in the second, political part of his assessment, "Since 15th August, the situation has steadily deteriorated and the Indian leaders, cabinet ministers, civil officials and others have persistently tried to obstruct the work of partition of the armed forces."

When partition was effected in August 1947, Auchinleck was appointed Supreme Commander of all British forces remaining in India and Pakistan and remained in this role until the winding up and closure of the Supreme H.Q. at the end of November 1948. This marked his effective retirement from the army (although technically field marshals in the British Army never retire, remaining on the active list on half pay). He left India on 1 December.

After a brief period in Italy in connection with an unsuccessful business project, Auchinleck retired to London, where he occupied himself with a number of charitable and business interests and became a respectably skilled watercolour painter. In 1960 he settled in Beccles in the county of Suffolk, remaining there for seven years until, at the age of eighty-four, he decided to emigrate and set up home in Marrakesh, where he died on 23 March 1981.

Auchinleck was buried in Ben M'Sik European Cemetery, Casablanca, in the Commonwealth War Graves Commission plot in the cemetery, next to the grave of Raymond Steed who was the second youngest non-civilian Commonwealth casualty of the Second World War.

A memorial plaque was erected in the crypt of St Paul's Cathedral. The tour guides relate how in 1979, as plaques for the other great Second World War military leaders were being installed, no one in the establishment had been in contact with his family for some years. Cathedral officials telephoned to enquire the date of his death only to be told "Auchinleck here – but I won't be keeping you much longer!" A bronze statue of Auchinleck can be seen on Broad Street adjacent to Auchinleck House, Five Ways, Birmingham.







 


</doc>
<doc id="7797" url="https://en.wikipedia.org/wiki?curid=7797" title="Camilla Hall">
Camilla Hall

Camilla Christine Hall (March 24, 1945 - May 17, 1974) was an artist, college trained social worker, and an early member of the Symbionese Liberation Army. She is best known for being one of the kidnappers of heiress Patricia Hearst.

On March 24, 1945, Camilla Christine Hall was born in Saint Peter, Minnesota. Her parents, George Fridolph Hall (1908-2000) and Lorena Daeschner Hall (1911-1995), worked at Gustavus Adolphus College in Saint Peter, Minnesota from 1938-1952. In addition, her father was a minister in the Augustana Evangelical Lutheran Church, Lutheran Church in America, and later the Evangelical Lutheran Church in America. Her mother, Lorena (Daeschner) Hall, helped found Gustavus Adolphus College's Art Department and served as the department head. Camilla Hall was the only surviving child of four; two of her siblings died of a kidney disorder, Peter and Nan, and a third, Terry, of congenital heart disease.

In 1952, the Hall family moved to what is now Tanzania in East Africa. George and Lorena Hall taught in schools and did mission work, while Camilla and Nan played with the native children. In 1954, when Camilla was nine, the family moved back to Saint Peter, because of seven-year-old Nan's poor health. While Camilla Hall attended elementary school in Minnesota, the family moved to Montclair, New Jersey until Hall was to start high school.

After moving back to Minnesota, Hall went to Washburn High School in Minneapolis where she was involved in many activities. The 1963 Washburn Yearbook says, "Candy was a member of Blue Tri, Class Play, Poplars Staff, Quill Club, Forensics, Pep Club, and Hall of Fame" Blue Tri club was an organization that encouraged Christian ideals and put together service projects. In addition, Camilla Hall was voted class clown in High School. In 1963, she graduated from Washburn High School.

Camilla Hall attended Gustavus Adolphus College in St. Peter, Minnesota. She transferred to the University of Minnesota after her freshman year at Gustavus. Hall attended special lectures, exhibits, and concerts at the University. On June 10, 1967, Hall graduated with a humanities degree from the University of Minnesota.

Following graduation, Hall moved to Duluth, Minnesota where she was a caseworker for St. Louis County, Minnesota. In early 1968 she was elected to carry the Eugene McCarthy banner, in support of the Eugene McCarthy Presidential Campaign, for the St. Louis County precinct. Even though Hall enjoyed helping people in her work, she found it difficult to separate her feelings while being a caseworker. For her job in Duluth, Minnesota, Hall used her musical and poetic talents in an advertising campaign.

In June 1968, Hall returned to Minneapolis, Minnesota and worked as a caseworker for the Hennepin County, Minnesota welfare office. Co-workers and friends of Hall described her as witty, sympathetic, helpful, and compassionate. Also, she had an outgoing personality and had a passion for literature. At the same time, Hall frequently talked with family and friends about philosophy and how she was disappointed with the state of welfare. In 1968, Hall was 23 years old and carefully monitored the political situation in America, including the 1968 Democratic National Convention. She was active in the peace movement and food boycotts, including the Mobilization Committee to End the War in Vietnam. Despite her active participation in urging social change and working as a caseworker, Hall's mother says Camilla became dissatisfied with her work.

In November 1969, Hall moved to Topanga, a northern suburb of Los Angeles, California. In March, she moved into Los Angeles proper in west Los Angeles. According to Rachael Hanel, "She lived off her savings, interest income from a trust, money from her parents, and selling her simple, Rubenesque line drawings." Even though Hall didn't express dissatisfaction at being an artist, she decided to move again.

Hall moved to Berkeley in February 1971. In May 1971, Hall moved into an apartment complex on Channing Way where she met Patricia Soltysik. Previous to this relationship, Hall had not lived publicly in a lesbian relationship. Patricia Soltysik was the object of Hall's love poem named "Mizmoon".

In Berkeley, Hall continued being politically active. She was one of the activists in the People's Park reoccupation during the summer of 1972. She and Soltysik became involved with the Venceremos prison outreach project, through which they became associates of future Symbionese Liberation Army members Russell Little and Willie Wolfe. In October 1972, Hall travelled to Europe and stayed with friends while she traveled for three months. Once she returned, she continued being politically active and through her association with Soltysik, Little, and Wolfe, became involved in founding the Symbionese Liberation Army. The SLA would soon gain notoriety for the murder of Oakland school superintendent Marcus Foster, a bank robbery, and most famously, the kidnapping of heiress Patricia Hearst. Hall was identified from a security camera image as a participant in the April 15, 1974 robbery of the Hibernia Bank in San Francisco during which two civilians were shot.

Hall died in a shootout (May 17, 1974) with police in which five other SLA members were killed. As their hideout burned, Hall and fellow SLA member Nancy Ling Perry exited from the back door. Police claimed that Perry came out firing a revolver while Hall was firing an automatic pistol. Police shot them immediately, killing both. Perry was shot twice. One shot hit her right lung, the other shot severed her spine. Hall was shot once in the forehead. Her body was pulled back into the burning house by SLA member Angela Atwood, who also died.

Investigators working for Hall's parents claimed that Perry had come walking out of the house intending to surrender.



</doc>
<doc id="7800" url="https://en.wikipedia.org/wiki?curid=7800" title="Clone">
Clone

Clone or Clones or The Clone may refer to:









</doc>
<doc id="7801" url="https://en.wikipedia.org/wiki?curid=7801" title="Critical psychology">
Critical psychology

Critical psychology is a perspective on psychology that draws extensively on critical theory. Critical psychology challenges mainstream psychology and attempts to apply psychological understandings in more progressive ways, often looking towards social change as a means of preventing and treating psychopathology.

One of critical psychology's main criticisms of conventional psychology is that it fails to consider or deliberately ignores the way power differences between social classes and groups can affect the mental and physical well-being of individuals or groups of people. It does this, in part, because it tends to explain behavior at the level of the individual.

Criticisms of mainstream psychology consistent with current critical psychology usage have existed since psychology's modern development in the late 19th century. Use of the term "critical psychology" started in the 1970s in Berlin at Freie Universität Berlin. The German branch of critical psychology predates and has developed largely separately from the rest of the field. As of May 2007, only a few works have been translated into English. The German Critical Psychology movement is rooted in the post-war babyboomers' student revolt of the late '60s; see German student movement. Marx's "Critique of Political Economy" played an important role in the German branch of the student revolt, which was centered in Berlin. Then Berlin was a capitalist city surrounded by communist-ruled East Germany, represented a "hot spot" of political and ideological controversy for the revolutionary German students. The sociological foundations of critical psychology are decidedly Marxist.

One of the most important and sophisticated books in the field is the "Grundlegung der Psychologie" ("Foundations of Psychology") by Klaus Holzkamp, who might be considered the theoretical founder of critical psychology. Holzkamp, who had written two books on theory of science and one on sensory perception before publishing the "Grundlegung der Psychologie" in 1983, thought this major work provided a solid paradigm for psychological research, as he viewed psychology as a pre-paradigmatic scientific discipline (T.S. Kuhn had used the term "pre-paradigmatic" for social science).

Holzkamp mostly based his sophisticated attempt to provide a comprehensive and integrated set of categories defining the field of psychological research on Aleksey Leontyev's approach to cultural–historical psychology and activity theory. Leontyev had seen human action as a result of biological as well as cultural evolution and, drawing on Marx's materialist conception of culture, stressed that individual cognition is always part of social action which in turn is mediated by man-made tools (cultural artifacts), language and other man-made systems of symbols, which he viewed as a major distinguishing feature of human culture and, thus, human cognition. Another important source was Lucien Séve's theory of personality, which provided the concept of "social activity matrices" as mediating structure between individual and social reproduction. At the same time, the "Grundlegung" systematically integrated previous specialized work done at Free University of Berlin in the '70s by critical psychologists who also had been influenced by Marx, Leontyev and Seve. This included books on animal behavior/ethology, sensory perception, motivation and cognition. He also incorporated ideas from Freud's psychoanalysis and Merleau-Ponty's phenomenology into his approach.

One core result of Holzkamp's historical and comparative analysis of human reproductive action, perception and cognition is a very specific concept of meaning that identifies symbolic meaning as historically and culturally constructed, purposeful conceptual structures that humans create in close relationship to material culture and within the context of historically specific formations of social reproduction.

Coming from this phenomenological perspective on culturally mediated and socially situated action, Holzkamp launched a devastating and original methodological attack on behaviorism (which he termed S–R (stimulus–response) psychology) based on linguistic analysis, showing in minute detail the rhetorical patterns by which this approach to psychology creates the illusion of "scientific objectivity" while at the same time losing relevance for understanding culturally situated, intentional human actions. Against this approach, he developed his own approach to generalization and objectivity, drawing on ideas from Kurt Lewin in Chapter 9 of "Grundlegung der Psychologie".

His last major publication before his death in 1995 was about learning. It appeared in 1993 and contained a phenomenological theory of learning from the standpoint of the subject. One important concept Holzkamp developed was "reinterpretation" of theories developed by conventional psychology. This meant to look at these concepts from the standpoint of the paradigm of critical psychology, thereby integrating their useful insights into critical psychology while at the same time identifying and criticizing their limiting implications, which in the case of S–R psychology were the rhetorical elimination of the subject and intentional action, and in the case of cognitive psychology which did take into account subjective motives and intentional actions, methodological individualism. 

The first part of the book thus contains an extensive look at the history of psychological theories of learning and a minute re-interpretation of those concepts from the perspective of the paradigm of critical psychology, which focuses on intentional action situated in specific socio-historical/cultural contexts. The conceptions of learning he found most useful in his own detailed analysis of "classroom learning" came from cognitive anthropologists Jean Lave (situated learning) and Edwin Hutchins (distributed cognition). 

The book's second part contained an extensive analysis on the modern state's institutionalized forms of "classroom learning" as the cultural–historical context that shapes much of modern learning and socialization. In this analysis, he heavily drew upon Michel Foucault's Discipline and Punish. Holzkamp felt that classroom learning as the historically specific form of learning does not make full use of student's potentials, but rather limits her or his learning potentials by a number of "teaching strategies." Part of his motivation for the book was to look for alternative forms of learning that made use of the enormous potential of the human psyche in more fruitful ways. Consequently, in the last section of the book, Holzkamp discusses forms of "expansive learning" that seem to avoid the limitations of classroom learning, such as apprenticeship and learning in contexts other than classrooms. 

This search culminated in plans to write a major work on life leadership in the specific historical context of modern (capitalist) society. Due to his death in 1995, this work never got past the stage of early (and premature) conceptualizations, some of which were published in the journals "Forum Kritische Psychologie" and "Argument".

In the 1960s and 1970s the term "radical psychology" was used by psychologists to denote a branch of the field which rejected conventional psychology's focus on the individual as the basic unit of analysis and sole source of psychopathology. Instead, radical psychologists examined the role of society in causing and treating problems and looked towards social change as an alternative to therapy to treat mental illness and as a means of preventing psychopathology. Within psychiatry the term "anti-psychiatry" was often used and now British activists prefer the term "critical psychiatry". "Critical psychology" is currently the preferred term for the discipline of psychology keen to find alternatives to the way the discipline of psychology reduces human experience to the level of the individual and thereby strips away possibilities for radical social change.

Starting in the 1990s a new wave of books started to appear on critical psychology, the most influential being the edited book "Critical Psychology" by Dennis Fox and Isaac Prilleltensky. Various introductory texts to critical psychology written in the United Kingdom have tended to focus on discourse, but this has been seen by some proponents of critical psychology as a reduction of human experience to language which is as politically dangerous as the way mainstream psychology reduces experience to the individual mind. Attention to language and ideological processes, others would argue, is essential to effective critical psychology - it is not simply a matter of applying mainstream psychological concepts to issues of social change.

In 1999 Ian Parker published an influential manifesto in both the online journal "Radical Psychology" and the Annual Review of Critical Psychology. This manifesto argues that critical psychology should include the following four components:

There are a few international journals devoted to critical psychology, including the no longer published "International Journal of Critical Psychology" (continued in the journal Subjectivity) and the "Annual Review of Critical Psychology". The journals still tend to be directed to an academic audience, though the "Annual Review of Critical Psychology" runs as an open-access online journal. There are close links between critical psychologists and critical psychiatrists in Britain through the Asylum Collective. Critical psychology courses and research concentrations are available at Manchester Metropolitan University, York St Johns University, the University of East London, the University of Edinburgh, the University of KwaZulu Natal, the Graduate Center of the City University of New York, and the University of West Georgia. Undergraduate concentrations can also be found at the California Institute of Integral Studies and Prescott College.

Like many critical applications, critical psychology has expanded beyond Marxist and feminist roots to benefit from other critical approaches. Consider ecopsychology and transpersonal psychology. Critical psychology and related work has also sometimes been labelled radical psychology and liberation psychology. In the field of developmental psychology, the work of Erica Burman has been influential.

Various sub-disciplines within psychology have begun to establish their own critical orientations. Perhaps the most extensive are critical health psychology and community psychology.

An early international overview of critical psychology perspectives can be found in Critical Psychology: Voices for Change, edited by Tod Sloan (Macmillan, 2000). In 2015, Ian Parker edited the Handbook of Critical Psychology.
At FU-Berlin, critical psychology was not really seen as a division of psychology and followed its own methodology, trying to reformulate traditional psychology on an unorthodox Marxist base and drawing from Soviet ideas of cultural–historical psychology, particularly Aleksey Leontyev. Some years ago the department of critical psychology at FU-Berlin was merged into the traditional psychology department.

An April 2009 issue of the Sage journal "Theory & Psychology" (edited by Desmond Painter, Athanasios Marvakis, and Leendert Mos) is devoted to an examination of German critical psychology.

The University of KwaZulu-Natal in Durban, South Africa, is one of few worldwide to offer a Master's course in critical psychology. For an overview of critical psychology in South Africa, see Desmond Painter and Martin Terre Blanche's article on "Critical Psychology in South Africa: Looking back and looking forwards". They have also now started a critical psychology blog.

Critical psychology in the United States and Canada has, for the most part, focused on critiques of mainstream psychology's support for an unjust "status quo". No departments of critical psychology exist, with the exception of the Bachelor's Completion Program with a minor in Critical Psychology, offered at the California Institute of Integral Studies in San Francisco, though critical perspectives are sometimes encountered in traditional universities, perhaps especially within community psychology programs. The University of West Georgia offers a Ph.D. in Consciousness and Society with critical psychology being one of the main three theoretical orientations. North American efforts include the 1993 founding of RadPsyNet, the 1997 publication of "Critical Psychology: An Introduction" (edited by Dennis Fox and Isaac Prilleltensky; expanded 2009 edition edited by Dennis Fox, Isaac Prilleltensky, and Stephanie Austin), the 2001 Monterey Conference on Critical Psychology, and in underlying themes of many contributions to the "Journal of Social Action in Counseling and Psychology".






</doc>
<doc id="7803" url="https://en.wikipedia.org/wiki?curid=7803" title="Crossfire">
Crossfire

A crossfire (also known as interlocking fire) is a military term for the siting of weapons (often automatic weapons such as assault rifles or sub-machine guns) so that their arcs of fire overlap. This tactic came to prominence in World War I.

Siting weapons this way is an example of the application of the defensive principle of "mutual support". The advantage of siting weapons that mutually support one another is that it is difficult for an attacker to find a covered approach to any one defensive position. 

Use of armour, air support, indirect fire support, and stealth are tactics that may be used to assault a defensive position. However, when combined with land mines, snipers, barbed wire, and air cover, crossfire became a difficult tactic to counter in the early 20th century.

The tactic of using overlapping arcs of fire came to prominence during World War I where it was a feature of trench warfare. Machine guns were placed in groups, called machine-gun nests, and they protected the front of the trenches. Many lives were lost in futile attempts to charge across the no man's land where these crossfires were set up. After these attacks many bodies could be found in the no man's land. 

To be "caught in the crossfire" is an expression that often refers to unintended casualties (bystanders, etc.) who were killed or wounded by being exposed to the gunfire of a battle or gun fight, such as in a position to be hit by bullets of either side. The phrase has come to mean any injury, damage or harm (physical or otherwise) caused to a third party due to the action of belligerents (collateral damage).


</doc>
<doc id="7805" url="https://en.wikipedia.org/wiki?curid=7805" title="CNO">
CNO

CNO is a three-letter initialism. It can mean:


CNO may also refer to:



</doc>
<doc id="7806" url="https://en.wikipedia.org/wiki?curid=7806" title="Cruising (maritime)">
Cruising (maritime)

Cruising by boat is a lifestyle that involves living for extended time on a vessel while traveling from place to place for pleasure. Cruising generally refers to trips of a few days or more, and can extend to round-the-world voyages.

Boats were almost exclusively used for working purposes prior to the nineteenth century. In 1857, the philosopher Henry David Thoreau, with his book "Canoeing in Wilderness" chronicling his canoe voyaging in the wilderness of Maine, was the first to convey the enjoyment of spiritual and lifestyle aspects of cruising.
The modern conception of cruising for pleasure was first popularised by the Scottish explorer and sportsman John MacGregor. He was introduced to the canoes and kayaks of the Native Americans on a camping trip in 1858, and on his return to the United Kingdom constructed his own 'double-ended' canoe in Lambeth. The boat, nicknamed 'Rob Roy' after a famous relative of his, was built of lapstrake oak planking, decked in cedar covered with rubberized canvas with an open cockpit in the center. He cruised around the waterways of Britain, Europe and the Middle East and wrote a popular book about his experiences, "A Thousand Miles in the Rob Roy Canoe".

In 1866, Macgregor was a moving force behind the establishment of the Royal Canoe Club, the first club in the world to promote pleasure cruising. The first recorded regatta was held at on 27 April 1867, and it received Royal patronage in 1873. The latter part of the century saw cruising for leisure being enthusiastically taken up by the middle class. The author Robert Louis Stevenson wrote "An Inland Voyage" in 1877 as a travelogue on his canoeing trip through France and Belgium. Stevenson and his companion, Sir Walter Grindlay Simpson travelled in two 'Rob Roys' along the Oise River and witnessed the Romantic beauty of rural Europe.

The Canadian-American Joshua Slocum was one of the first people to carry out a long-distance sailing voyage for pleasure, circumnavigating the world between 1895 and 1898. Despite opinion that such a voyage was impossible, Slocum rebuilt a derelict sloop "Spray" and sailed her single-handed around the world. His book "Sailing Alone Around the World" was a classic adventure, and inspired many others to take to the seas.
Other cruising authors have provided both inspiration and instruction to prospective cruisers. Key among these during the post World War II period are Electa and Irving Johnson, Miles and Beryl Smeeton, Bernard Moitessier, Peter Pye, and Eric and Susan Hiscock. During the 1970s - 1990s Robin Lee Graham, Lin and Larry Pardey, Annie Hill, Herb Payson, Linda and Steve Dashew, Margaret and Hal Roth, and Beth Leonard & Evans Starzinger have provided inspiration for people to set off voyaging.

The development of ocean crossing rallies, most notably the ARC (Atlantic Rally for Cruisers), have encouraged less experienced sailors to undertake ocean crossings. These rallies provide a group of sailors crossing the same ocean at the same time with safety inspections, weather information and social functions.

Cruising is done on both sail and power boats, monohulls and multihulls although sail predominates over longer distances, as ocean-going power boats are considerably more expensive to purchase and operate. The size of the typical cruising boat has increased over the years and is currently in the range of 10 to 15 metres (33 to 50 feet) although smaller boats have been used in around-the-world trips, but are generally not recommended given the dangers involved. Many cruisers are "long term" and travel for many years, the most adventurous among them circle the globe over a period of three to ten years. Many others take a year or two off from work and school for shorter trips and the chance to experience the cruising lifestyle.

Blue-water cruising is more involved and inherently more dangerous than coastal cruising. 
Before embarking on an open-ocean voyage, planning and preparation will include studying charts, weather reports/warnings, almanacs and navigation books of the route to be followed. In addition, supplies need to be stocked (including fresh water and fuel), navigation instruments checked and the ship itself needs to be inspected and the crew needs to be given exact instruction on the jobs are expected to perform (e.g. the watch; which is generally 4 hours on and 4 hours off, navigation, steering, rigging sails, ...). In addition, the crew needs to be well trained at working together and with the ship in question. Finally, the sailor must be mentally prepared for dealing with harsh situations. There have been many well-documented cases where sailors had to be rescued simply because they were not sufficiently prepared (the sailors as well as the ship) or lacked experience for their venture and ran into serious trouble.

Sailing near the coast (coastal cruising) gives a certain amount of safety. A ship is always granted 'innocent passage' through the country (most countries usually claim up to off the coast). When this method is practiced however, one must still remember that if the ship needs to stop (e.g. for repairs), a trip to a customs checkpoint to have passports checked would be required.

Cruisers use a variety of equipment and techniques to make their voyages possible, or simply more comfortable. 
The use of wind vane self steering was common on long distance cruising yachts but is increasingly being supplemented or replaced by electrical auto-pilots.

Though in the past many cruisers had no means of generating electricity on board and depended on kerosene and dry-cell batteries, today electrical demands are much higher and nearly all cruisers have electrical devices such as lights, communications equipment and refrigeration. Although most boats can generate power from their inboard engines, an increasing number carry auxiliary generators. Carrying sufficient fuel to power engine and generator over a long voyage can be a problem, so many cruising boats are equipped with other ancillary generating devices such as solar panels, wind turbines and towed turbines. Cruisers choosing to spend extended time in very remote locations with minimal access to marinas can opt to equip their vessels with watermakers (reverse-osmosis seawater desalination units) used to convert sea water to potable fresh water.

Satellite communications are becoming more common on cruising boats. Many boats are now equipped with satellite telephone systems; however, these systems can be expensive to use, and may operate only in certain areas. Many cruisers still use short wave maritime SSB and amateur radio, which has no running costs. These radios provide two-way voice communications, can receive weather fax graphics or GRIB files via a laptop computer, and with a compatible modem (e.g. PACTOR) can send and receive email at very slow speed. Such emails are usually limited to basic communication using plain text, without HTML formatting or attachments.

Awareness of impending weather conditions is particularly important to cruising sailors who are often far from safe harbours and need to steer clear of dangerous weather conditions. Most cruising boats are equipped with a barometer or a weather station that records barometric pressure as well as temperature and provides rudimentary forecasting. For more sophisticated weather forecasting, cruisers rely on their ability to receive forecasts by radio, phone or satellite.

In order to avoid collisions with other vessels, cruisers rely on a maintaining a regular watch schedule. At night, color-coded running lights help determine the position and orientation of vessels. Radar and AIS systems are often employed to detect vessels positions and movement in all conditions (day, night, rain and fog).

Cruisers navigate using paper charts and radar. Modern yachts are often also equipped with a chartplotter which enables the use of electronic charts and is linked to GPS satellites that provide position reports. Some chartplotters have the ability to interface charts and radar images. Those that still wish to work with traditional charts as well as with GPS may do so using a Yeoman Plotter. Certain advanced sailing vessels have a completely automated sailing system which includes a plotter, as well as course correcting through a link with the ship's steering organs (e.g. sails, propeller). One such device can be found at the Maltese Falcon.

Purchasing and maintaining a yacht can be costly. Most cruising sailors do not own a house and consider their boat their home during the duration of their cruise. Many cruisers find they spend, on average, 4% of their boat's purchase price annually on boat maintenance.

Like living a conventional life on land, the cost of cruising is variable. How much a person ends up spending depends largely on their spending habits (for example, eating out a lot and frequenting marinas vs. preparing local foods aboard and anchoring out) and the type of boat (fancy modern production boats are very expensive to purchase and maintain, while low-key cruising boats often involve much lower expenses). Most long-term cruisers prefer to live a simple life, usually with far lower expenses than people who live ashore.

An alternative solution is to sail on someone else's yacht. Those who know how to sail can sometimes find boats looking for an extra crewmember for a long trip, while some non-sailors are also able to find boats willing to carry a hitch-hiker. Crew-finding websites exist to help match-up people looking for a crossing with yachts with a berth available or looking for a temporary crewmember, Find a Crew for example. Another common tactic for finding a yacht is to visit local yacht clubs and marinas and get to know the sailors there, in the hope that one of them will be able to provide a berth.

Travel by water brings hazards: collision, weather, and equipment failure can lead to dangerous situations such as a sinking or severely disabled and dangerous vessel. For this reason many long distance cruising yachts carry with them emergency equipment such as SARTs, EPIRBs and liferafts or proactive lifeboats. Medical emergencies are also of concern, as a medical emergency can occur on a long passage when the closest port is over a week away. For this reason before going cruising many people go through first aid training and carry medical kits. In some parts of the world (e.g., near the Horn of Africa) piracy can be a problem.



</doc>
<doc id="7807" url="https://en.wikipedia.org/wiki?curid=7807" title="Cavitation">
Cavitation

Cavitation is the formation of vapour cavities in a liquid, small liquid-free zones ("bubbles" or "voids"), that are the consequence of forces acting upon the liquid. It usually occurs when a liquid is subjected to rapid changes of pressure that cause the formation of cavities in the liquid where the pressure is relatively low. When subjected to higher pressure, the voids implode and can generate an intense shock wave.

Cavitation is a significant cause of wear in some engineering contexts. Collapsing voids that implode near to a metal surface cause cyclic stress through repeated implosion. This results in surface fatigue of the metal causing a type of wear also called "cavitation". The most common examples of this kind of wear are to pump impellers, and bends where a sudden change in the direction of liquid occurs. Cavitation is usually divided into two classes of behavior: inertial (or transient) cavitation and non-inertial cavitation.

Inertial cavitation is the process where a void or bubble in a liquid rapidly collapses, producing a shock wave. Inertial cavitation occurs in nature in the strikes of mantis shrimps and pistol shrimps, as well as in the vascular tissues of plants. In man-made objects, it can occur in control valves, pumps, propellers and impellers.

Non-inertial cavitation is the process in which a bubble in a fluid is forced to oscillate in size or shape due to some form of energy input, such as an acoustic field. Such cavitation is often employed in ultrasonic cleaning baths and can also be observed in pumps, propellers, etc.

Since the shock waves formed by collapse of the voids are strong enough to cause significant damage to moving parts, cavitation is usually an undesirable phenomenon. It is very often specifically avoided in the design of machines such as turbines or propellers, and eliminating cavitation is a major field in the study of fluid dynamics. However, it is sometimes useful and does not cause damage when the bubbles collapse away from machinery, such as in supercavitation.

Inertial cavitation was first observed in the late 19th century, considering the collapse of a spherical void within a liquid. When a volume of liquid is subjected to a sufficiently low pressure, it may rupture and form a cavity. This phenomenon is coined "cavitation inception" and may occur behind the blade of a rapidly rotating propeller or on any surface vibrating in the liquid with sufficient amplitude and acceleration. A fast-flowing river can cause cavitation on rock surfaces, particularly when there is a drop-off, such as on a waterfall.

Other ways of generating cavitation voids involve the local deposition of energy, such as an intense focused laser pulse (optic cavitation) or with an electrical discharge through a spark. Vapor gases evaporate into the cavity from the surrounding medium; thus, the cavity is not a perfect vacuum, but has a relatively low gas pressure. Such a low-pressure bubble in a liquid begins to collapse due to the higher pressure of the surrounding medium. As the bubble collapses, the pressure and temperature of the vapor within increases. The bubble eventually collapses to a minute fraction of its original size, at which point the gas within dissipates into the surrounding liquid via a rather violent mechanism which releases a significant amount of energy in the form of an acoustic shock wave and as visible light. At the point of total collapse, the temperature of the vapor within the bubble may be several thousand kelvin, and the pressure several hundred atmospheres.

Inertial cavitation can also occur in the presence of an acoustic field. Microscopic gas bubbles that are generally present in a liquid will be forced to oscillate due to an applied acoustic field. If the acoustic intensity is sufficiently high, the bubbles will first grow in size and then rapidly collapse. Hence, inertial cavitation can occur even if the rarefaction in the liquid is insufficient for a Rayleigh-like void to occur. High-power ultrasonics usually utilize the inertial cavitation of microscopic vacuum bubbles for treatment of surfaces, liquids, and slurries.

The physical process of cavitation inception is similar to boiling. The major difference between the two is the thermodynamic paths that precede the formation of the vapor. Boiling occurs when the local temperature of the liquid reaches the saturation temperature, and further heat is supplied to allow the liquid to sufficiently phase change into a gas. Cavitation inception occurs when the local pressure falls sufficiently far below the saturated vapor pressure, a value given by the tensile strength of the liquid at a certain temperature.

In order for cavitation inception to occur, the cavitation "bubbles" generally need a surface on which they can nucleate. This surface can be provided by the sides of a container, by impurities in the liquid, or by small undissolved microbubbles within the liquid. It is generally accepted that hydrophobic surfaces stabilize small bubbles. These pre-existing bubbles start to grow unbounded when they are exposed to a pressure below the threshold pressure, termed Blake's threshold.

The vapor pressure here differs from the meteorological definition of vapor pressure, which describes the partial pressure of water in the atmosphere at some value less than 100% saturation. Vapor pressure as relating to cavitation refers to the vapor pressure in equilibrium conditions and can therefore be more accurately defined as the equilibrium (or saturated) vapor pressure.

Non-inertial cavitation is the process in which small bubbles in a liquid are forced to oscillate in the presence of an acoustic field, when the intensity of the acoustic field is insufficient to cause total bubble collapse. This form of cavitation causes significantly less erosion than inertial cavitation, and is often used for the cleaning of delicate materials, such as silicon wafers.

Hydrodynamic cavitation describes the process of vaporisation, bubble generation and bubble implosion which occurs in a flowing liquid as a result of a decrease and subsequent increase in local pressure. Cavitation will only occur if the local pressure declines to some point below the saturated vapor pressure of the liquid and subsequent recovery above the vapor pressure. If the recovery pressure is not above the vapor pressure then flashing is said to have occurred. In pipe systems, cavitation typically occurs either as the result of an increase in the kinetic energy (through an area constriction) or an increase in the pipe elevation.

Hydrodynamic cavitation can be produced by passing a liquid through a constricted channel at a specific flow velocity or by mechanical rotation of an object through a liquid. In the case of the constricted channel and based on the specific (or unique) geometry of the system, the combination of pressure and kinetic energy can create the hydrodynamic cavitation cavern downstream of the local constriction generating high energy cavitation bubbles.

The process of bubble generation, and the subsequent growth and collapse of the cavitation bubbles, results in very high energy densities and in very high local temperatures and local pressures at the surface of the bubbles for a very short time. The overall liquid medium environment, therefore, remains at ambient conditions. When uncontrolled, cavitation is damaging; by controlling the flow of the cavitation, however, the power can be harnessed and non-destructive. Controlled cavitation can be used to enhance chemical reactions or propagate certain unexpected reactions because free radicals are generated in the process due to disassociation of vapors trapped in the cavitating bubbles. .

Orifices and venturi are reported to be widely used for generating cavitation. A venturi has an inherent advantage over an orifice because of its smooth converging and diverging sections, such that it can generate a higher flow velocity at the throat for a given pressure drop across it. On the other hand, an orifice has an advantage that it can accommodate a greater number of holes (larger perimeter of holes) in a given cross sectional area of the pipe.

The cavitation phenomenon can be controlled to enhance the performance of high-speed marine vessels and projectiles, as well as in material processing technologies, in medicine, etc. Controlling the cavitating flows in liquids can be achieved only by advancing the mathematical foundation of the cavitation processes. These processes are manifested in different ways, the most common ones and promising for control being bubble cavitation and supercavitation. The first exact classical solution should perhaps be credited to the well- known solution by H. Helmholtz in 1868. The earliest distinguished studies of academic type on the theory of a cavitating flow with free boundaries and supercavitation were published in the book "Jets, wakes and cavities" followed by "Theory of jets of ideal fluid". Widely used in these books was the well-developed theory of conformal mappings of functions of a complex variable, allowing one to derive a large number of exact solutions of plane problems. Another venue combining the existing exact solutions with approximated and heuristic models was explored in the work "Hydrodynamics of Flows with Free Boundaries" that refined the applied calculation techniques based on the principle of cavity expansion independence, theory of pulsations and stability of elongated axisymmetric cavities, etc. and in "Dimensionality and similarity methods in the problems of the hydromechanics of vessels".

A natural continuation of these studies was recently presented in "The Hydrodynamics of Cavitating Flows" – an encyclopedic work encompassing all the best advances in this domain for the last three decades, and blending the classical methods of mathematical research with the modern capabilities of computer technologies. These include elaboration of nonlinear numerical methods of solving 3D cavitation problems, refinement of the known plane linear theories, development of asymptotic theories of axisymmetric and nearly axisymmetric flows, etc. As compared to the classical approaches, the new trend is characterized by expansion of the theory into the 3D flows. It also reflects a certain correlation with current works of an applied character on the hydrodynamics of supercavitating bodies.

Hydrodynamic cavitation can also improve some industrial processes. For instance, cavitated corn slurry shows higher yields in ethanol production compared to uncavitated corn slurry in dry milling facilities.

This is also used in the mineralization of bio-refractory compounds which otherwise would need extremely high temperature and pressure conditions since free radicals are generated in the process due to the dissociation of vapors trapped in the cavitating bubbles, which results in either the intensification of the chemical reaction or may even result in the propagation of certain reactions not possible under otherwise ambient conditions.

In industry, cavitation is often used to homogenize, or mix and break down, suspended particles in a colloidal liquid compound such as paint mixtures or milk. Many industrial mixing machines are based upon this design principle. It is usually achieved through impeller design or by forcing the mixture through an annular opening that has a narrow entrance orifice with a much larger exit orifice. In the latter case, the drastic decrease in pressure as the liquid accelerates into a larger volume induces cavitation. This method can be controlled with hydraulic devices that control inlet orifice size, allowing for dynamic adjustment during the process, or modification for different substances. The surface of this type of mixing valve, against which surface the cavitation bubbles are driven causing their implosion, undergoes tremendous mechanical and thermal localized stress; they are therefore often constructed of super-hard or tough materials such as stainless steel, Stellite, or even polycrystalline diamond (PCD).

Cavitating water purification devices have also been designed, in which the extreme conditions of cavitation can break down pollutants and organic molecules. Spectral analysis of light emitted in sonochemical reactions reveal chemical and plasma-based mechanisms of energy transfer. The light emitted from cavitation bubbles is termed sonoluminescence.

Use of this technology has been tried successfully in alkali refining of vegetable oils.

Hydrophobic chemicals are attracted underwater by cavitation as the pressure difference between the bubbles and the liquid water forces them to join together. This effect may assist in protein folding.

Cavitation plays an important role for the destruction of kidney stones in shock wave lithotripsy. Currently, tests are being conducted as to whether cavitation can be used to transfer large molecules into biological cells (sonoporation). Nitrogen cavitation is a method used in research to lyse cell membranes while leaving organelles intact.

Cavitation plays a key role in non-thermal, non-invasive fractionation of tissue for treatment of a variety of diseases. Cavitation also probably plays a role in HIFU, a thermal non-invasive treatment methodology for cancer.

Ultrasound sometimes is used to increase bone formation, for instance in post-surgical applications.
Ultrasound treatments or exposure can create cavitation that potentially may "result in a syndrome involving manifestations of nausea, headache, tinnitus, pain, dizziness, and fatigue.".

It has been suggested that the sound of "cracking" knuckles derives from the collapse of cavitation in the synovial fluid within the joint. Movements that cause cracking expand the joint space, thus reducing pressure to the point of cavitation. It remains controversial whether this is associated with clinically significant joint injury such as osteoarthritis. Some physicians say that osteoarthritis is caused by cracking knuckles regularly, as this causes wear and tear and may cause the bone to weaken. The implication being that, it is not the "bubbles popping," but rather, the bones rubbing together, that causes osteoarthritis.

In industrial cleaning applications, cavitation has sufficient power to overcome the particle-to-substrate adhesion forces, loosening contaminants. The threshold pressure required to initiate cavitation is a strong function of the pulse width and the power input. This method works by generating controlled acoustic cavitation in the cleaning fluid, picking up and carrying contaminant particles away so that they do not reattach to the material being cleaned.

Cavitation has been applied to egg pasteurization. A hole-filled rotor produces cavitation bubbles, heating the liquid from within. Equipment surfaces stay cooler than the passing liquid, so eggs don't harden as they did on the hot surfaces of older equipment. The intensity of cavitation can be adjusted, making it possible to tune the process for minimum protein damage.

Cavitation is, in many cases, an undesirable occurrence. In devices such as propellers and pumps, cavitation causes a great deal of noise, damage to components, vibrations, and a loss of efficiency. Cavitation has also become a concern in the renewable energy sector as it may occur on the blade surface of tidal stream turbines.

When the cavitation bubbles collapse, they force energetic liquid into very small volumes, thereby creating spots of high temperature and emitting shock waves, the latter of which are a source of noise. The noise created by cavitation is a particular problem for military submarines, as it increases the chances of being detected by passive sonar.

Although the collapse of a small cavity is a relatively low-energy event, highly localized collapses can erode metals, such as steel, over time. The pitting caused by the collapse of cavities produces great wear on components and can dramatically shorten a propeller or pump's lifetime.

After a surface is initially affected by cavitation, it tends to erode at an accelerating pace. The cavitation pits increase the turbulence of the fluid flow and create crevices that act as nucleation sites for additional cavitation bubbles. The pits also increase the components' surface area and leave behind residual stresses. This makes the surface more prone to stress corrosion.

Major places where cavitation occurs are in pumps, on propellers, or at restrictions in a flowing liquid.

As an impeller's (in a pump) or propeller's (as in the case of a ship or submarine) blades move through a fluid, low-pressure areas are formed as the fluid accelerates around and moves past the blades. The faster the blade moves, the lower the pressure around it can become. As it reaches vapor pressure, the fluid vaporizes and forms small bubbles of gas. This is cavitation. When the bubbles collapse later, they typically cause very strong local shock waves in the fluid, which may be audible and may even damage the blades.

Cavitation in pumps may occur in two different forms:

Suction cavitation occurs when the pump suction is under a low-pressure/high-vacuum condition where the liquid turns into a vapor at the eye of the pump impeller. This vapor is carried over to the discharge side of the pump, where it no longer sees vacuum and is compressed back into a liquid by the discharge pressure. This imploding action occurs violently and attacks the face of the impeller. An impeller that has been operating under a suction cavitation condition can have large chunks of material removed from its face or very small bits of material removed, causing the impeller to look spongelike. Both cases will cause premature failure of the pump, often due to bearing failure. Suction cavitation is often identified by a sound like gravel or marbles in the pump casing.

In automotive applications, a clogged filter in a hydraulic system (power steering, power brakes) can cause suction cavitation making a noise that rises and falls in synch with engine RPM. It is fairly often a high pitched whine, like set of nylon gears not quite meshing correctly.

Discharge cavitation occurs when the pump discharge pressure is extremely high, normally occurring in a pump that is running at less than 10% of its best efficiency point. The high discharge pressure causes the majority of the fluid to circulate inside the pump instead of being allowed to flow out the discharge. As the liquid flows around the impeller, it must pass through the small clearance between the impeller and the pump housing at extremely high flow velocity. This flow velocity causes a vacuum to develop at the housing wall (similar to what occurs in a venturi), which turns the liquid into a vapor. A pump that has been operating under these conditions shows premature wear of the impeller vane tips and the pump housing. In addition, due to the high pressure conditions, premature failure of the pump's mechanical seal and bearings can be expected. Under extreme conditions, this can break the impeller shaft.

Discharge cavitation in joint fluid is thought to cause the popping sound produced by bone joint cracking, for example by deliberately cracking one's knuckles.

Since all pumps require well-developed inlet flow to meet their potential, a pump may not perform or be as reliable as expected due to a faulty suction piping layout such as a close-coupled elbow on the inlet flange. When poorly developed flow enters the pump impeller, it strikes the vanes and is unable to follow the impeller passage. The liquid then separates from the vanes causing mechanical problems due to cavitation, vibration and performance problems due to turbulence and poor filling of the impeller. This results in premature seal, bearing and impeller failure, high maintenance costs, high power consumption, and less-than-specified head and/or flow.

To have a well-developed flow pattern, pump manufacturer's manuals recommend about (10 diameters?) of straight pipe run upstream of the pump inlet flange. Unfortunately, piping designers and plant personnel must contend with space and equipment layout constraints and usually cannot comply with this recommendation. Instead, it is common to use an elbow close-coupled to the pump suction which creates a poorly developed flow pattern at the pump suction.

With a double-suction pump tied to a close-coupled elbow, flow distribution to the impeller is poor and causes reliability and performance shortfalls. The elbow divides the flow unevenly with more channeled to the outside of the elbow. Consequently, one side of the double-suction impeller receives more flow at a higher flow velocity and pressure while the starved side receives a highly turbulent and potentially damaging flow. This degrades overall pump performance (delivered head, flow and power consumption) and causes axial imbalance which shortens seal, bearing and impeller life.
To overcome cavitation:
Increase suction pressure if possible.
Decrease liquid temperature if possible.
Throttle back on the discharge valve to decrease flow-rate.
Vent gases off the pump casing.

Cavitation can occur in control valves. If the actual pressure drop across the valve as defined by the upstream and downstream pressures in the system is greater than the sizing calculations allow, pressure drop flashing or cavitation may occur. The change from a liquid state to a vapor state results from the increase in flow velocity at or just downstream of the greatest flow restriction which is normally the valve port. To maintain a steady flow of liquid through a valve the flow velocity must be greatest at the vena contracta or the point where the cross sectional area is the smallest. This increase in flow velocity is accompanied by a substantial decrease in the fluid pressure which is partially recovered downstream as the area increases and flow velocity decreases. This pressure recovery is never completely to the level of the upstream pressure. If the pressure at the vena contracta drops below the vapor pressure of the fluid bubbles will form in the flow stream. If the pressure recovers after the valve to a pressure that is once again above the vapor pressure, then the vapor bubbles will collapse and cavitation will occur.

When water flows over a dam spillway, the irregularities on the spillway surface will cause small areas of flow separation in a high-speed flow, and, in these regions, the pressure will be lowered. If the flow velocities are high enough the pressure may fall to below the local vapor pressure of the water and vapor bubbles will form. When these are carried downstream into a high pressure region the bubbles collapse giving rise to high pressures and possible cavitation damage.

Experimental investigations show that the damage on concrete chute and tunnel spillways can start at clear water flow velocities of between 12 and 15 m/s, and, up to flow velocities of 20 m/s, it may be possible to protect the surface by streamlining the boundaries, improving the surface finishes or using resistant materials.

When some air is present in the water the resulting mixture is compressible and this damps the high pressure caused
by the bubble collapses. If the flow velocities near the spillway invert are sufficiently high, aerators (or aeration devices) must be introduced to prevent cavitation. Although these have been installed for some years, the mechanisms of air entrainment at the aerators and the slow movement of the air away from the spillway surface are still challenging.

The spillway aeration device design is based upon a small deflection of the spillway bed (or sidewall) such as a ramp and offset to deflect the high flow velocity flow away from the spillway surface. In the cavity formed below the nappe, a local subpressure beneath the nappe is produced by which air is sucked into the flow. The complete design includes the deflection device (ramp, offset) and the air supply system.

Some larger diesel engines suffer from cavitation due to high compression and undersized cylinder walls. Vibrations of the cylinder wall induce alternating low and high pressure in the coolant against the cylinder wall. The result is pitting of the cylinder wall, which will eventually let cooling fluid leak into the cylinder and combustion gases to leak into the coolant.

It is possible to prevent this from happening with the use of chemical additives in the cooling fluid that form a protective layer on the cylinder wall. This layer will be exposed to the same cavitation, but rebuilds itself. Additionally a regulated overpressure in the cooling system (regulated and maintained by the coolant filler cap spring pressure) prevents the forming of cavitation.

From about the 1980s, new designs of smaller gasoline engines also displayed cavitation phenomena. One answer to the need for smaller and lighter engines was a smaller coolant volume and a correspondingly higher coolant flow velocity. This gave rise to rapid changes in flow velocity and therefore rapid changes of static pressure in areas of high heat transfer. Where resulting vapor bubbles collapsed against a surface, they had the effect of first disrupting protective oxide layers (of cast aluminium materials) and then repeatedly damaging the newly formed surface, preventing the action of some types of corrosion inhibitor (such as silicate based inhibitors). A final problem was the effect that increased material temperature had on the relative electrochemical reactivity of the base metal and its alloying constituents. The result was deep pits that could form and penetrate the engine head in a matter of hours when the engine was running at high load and high speed. These effects could largely be avoided by the use of organic corrosion inhibitors or (preferably) by designing the engine head in such a way as to avoid certain cavitation inducing conditions.

Some hypotheses relating to diamond formation posit a possible role for cavitation—namely cavitiation in the kimberlite pipes providing the extreme pressure needed to change pure carbon into the rare allotrope that is diamond.

The loudest three sounds ever recorded, during the 1883 eruption of Krakatoa, are now understood as the bursts of three huge cavitation bubbles, each larger than the last, formed in the volcano's throat. Rising magma, filled with dissolved gasses and under immense pressure, encountered a different magma that compressed easily, allowing bubbles to grow and combine. 

There exist macroscopic white lamellae inside quartz and other minerals in the Bohemian Massif and even at another places in whole of the world like wavefronts generated by a meteorite impact according to the Rajlich's Hypothesis. The hypothetical wavefronts are composed of many microcavities. Their origin is seen in a physical phenomenon of ultrasonic cavitation, which is well known from the technical practice.

Cavitation occurs in the xylem of vascular plants when the tension of water within the xylem exceeds atmospheric pressure. The sap vaporizes locally so that either the vessel elements or tracheids are filled with water vapor. Plants are able to repair cavitated xylem in a number of ways. For plants less than 50 cm tall, root pressure can be sufficient to redissolve the vapor. Larger plants direct solutes into the xylem via "ray cells", or in tracheids, via osmosis through bordered pits. Solutes attract water, the pressure rises and vapor can redissolve. In some trees, the sound of the cavitation is audible, particularly in summer, when the rate of evapotranspiration is highest. Some deciduous trees have to shed leaves in the autumn partly because cavitation increases as temperatures decrease.

Just as cavitation bubbles form on a fast-spinning boat propeller, they may also form on the tails and fins of aquatic animals. This primarily occurs near the surface of the ocean, where the ambient water pressure is low.

Cavitation may limit the maximum swimming speed of powerful swimming animals like dolphins and tuna. Dolphins may have to restrict their speed because collapsing cavitation bubbles on their tail are painful. Tuna have bony fins without nerve endings and do not feel pain from cavitation. They are slowed down when cavitation bubbles create a vapor film around their fins. Lesions have been found on tuna that are consistent with cavitation damage.

Some sea animals have found ways to use cavitation to their advantage when hunting prey. The pistol shrimp snaps a specialized claw to create cavitation, which can kill small fish. The mantis shrimp (of the "smasher" variety) uses cavitation as well in order to stun, smash open, or kill the shellfish that it feasts upon.

Thresher sharks use 'tail slaps' to debilitate their small fish prey and cavitation bubbles have been seen rising from the apex of the tail arc.

In the last half-decade, coastal erosion in the form of inertial cavitation has been generally accepted. Bubbles in an incoming wave are forced into cracks in the cliff being eroded. Varying pressure decompresses some vapor pockets which subsequently implode. The resulting pressure peaks can blast apart fractions of the rock.





</doc>
<doc id="7808" url="https://en.wikipedia.org/wiki?curid=7808" title="Cyprinodontiformes">
Cyprinodontiformes

Cyprinodontiformes is an order of ray-finned fish, comprising mostly small, freshwater fish. Many popular aquarium fish, such as killifish and live-bearers, are included. They are closely related to the Atheriniformes and are occasionally included with them. A colloquial term for the order as a whole is toothcarps, though they are not actually close relatives of the true carps – the latter belong to the superorder Ostariophysi, while the toothcarps are Acanthopterygii.

The families of Cyprinodontiformes can be divided into three groups: viviparous and ovoviviparous (all species give live birth), and oviparous (all species are egg-laying). The live-bearing groups differ in whether the young are carried to term within (ovoviviparous) or without (viviparous) an enclosing eggshell. Phylogenetically however, one of the two suborders – the Aplocheiloidei – contains oviparous species exclusively, as do two of the four superfamilies of the other suborder (the Cyprinodontoidea and Valencioidea of the Cyprinodontoidei). Vivipary and ovovivipary have evolved independently from oviparous ancestors, the latter possibly twice.

Some members of this order are notable for inhabiting extreme environments, such as saline or very warm waters, water of poor quality, rain water pools devoid of minerals and made acid by decaying vegetation, or isolated situations where no other types of fish occur.

They are typically carnivores, and often live near the surface, where the oxygen-rich water compensates for environmental disadvantages. Scheel (1968) observed the gut contents were invariably ants, others have reported insects, worms and aquatic crustaceans. Aquarium specimens are invariably seen eating protozoans from the water column and the surfaces of leaves, however these are not apparent as stomach contents. North American "pupfish" eat plant material as well and some have adapted to a diet very high in algae to the point where one, the American Flag Fish is well known to eat algae especially thread algae in the aquarium, despite being in a family of fishes that do not generally consume any plant material. Although even this is a slight misnomer and killifish derive from some foods the carotenoids and other chemicals required to make these pigments which come from pollen grains from on the surface of and in the gut of insects they eat from the surface of the water, simulated in culture by the use of special color enhancing foods that contain them similar the same case with red factor canaries.

They are small to medium-sized fish, with small mouths, large eyes, a single dorsal fin, and a rounded caudal fin. The largest species is the "cuatro ojos" ("Anableps dowi"), which measures in length, while the smallest, the least killifish ("Heterandria formosa"), is just long as an adult.

CYPRINODONTIFORMES


</doc>
<doc id="7810" url="https://en.wikipedia.org/wiki?curid=7810" title="Church of the Holy Sepulchre">
Church of the Holy Sepulchre

The Church of the Holy Sepulchre ( "Kanīsatu al-Qiyāmah"; "Naos tes Anastaseos"; "Surb Harut'yan tač̣ar"; ; also called the Church of the Resurrection or Church of the "Anastasis" by Orthodox Christians) is a church in the Christian Quarter of the Old City of Jerusalem. The church contains, according to traditions dating back to at least the fourth century, the two holiest sites in Christianity: the site where Jesus of Nazareth was crucified, at a place known as "Calvary" or "Golgotha", and Jesus's empty tomb, where he is said to have been buried and resurrected. The tomb is enclosed by the 19th-century shrine, called the Aedicule (Edicule). The "Status Quo", a 150-year-old understanding between religious communities, applies to the site.

Within the church proper are the last four (or, by some definitions, five) Stations of the Via Dolorosa, representing the final episodes of Jesus' Passion. The church has been a major Christian pilgrimage destination since its creation in the fourth century, as the traditional site of the Resurrection of Christ, thus its original Greek name, Church of the Anastasis.

Today, the wider complex accumulated during the centuries around the Church of the Holy Sepulchre also serves as the headquarters of the Greek Orthodox Patriarch of Jerusalem, while control of the church itself is shared between several Christian denominations and secular entities in complicated arrangements essentially unchanged for over 160 years, and some for much longer. The main denominations sharing property over parts of the church are the Greek Orthodox, Armenian Apostolic and Roman Catholic, and to a lesser degree the Coptic Orthodox, Syriac Orthodox and Ethiopian Tewahedo. Meanwhile, Protestants, including Anglicans, have no permanent presence in the Church. Some Protestants prefer The Garden Tomb, elsewhere in Jerusalem, as a more evocative site to commemorate Jesus' crucifixion and resurrection.

According to Eusebius of Caesarea, the Roman emperor Hadrian in the 2nd century AD built a temple dedicated to the goddess Venus in order to bury the cave in which Jesus had been buried. The first Christian emperor, Constantine the Great, ordered in about 325/326 that the temple be replaced by a church. During the building of the Church, Constantine's mother, Helena, is believed to have rediscovered the tomb (although there are some discrepancies among authors). Socrates Scholasticus (born c. 380), in his "Ecclesiastical History," gives a full description of the discovery.

Constantine's church was built as two connected churches over the two different holy sites, including a great basilica (the "Martyrium" visited by Egeria in the 380s), an enclosed colonnaded atrium (the "Triportico") with the traditional site of "Golgotha" in one corner, and a rotunda, called the "Anastasis" ("Resurrection" in Greek), which contained the remains of a rock-cut room that Helena and Macarius identified as the burial site of Jesus.

According to tradition, Constantine arranged for the rockface to be removed from around the tomb, without harming it, in order to isolate the tomb; in the centre of the rotunda is a small building called the "Kouvouklion" in Greek or the "Aedicula" in Latin, which encloses this tomb. The remains are completely enveloped by a marble sheath placed some 500 years before to protect the ledge from Ottoman attacks. However, there are several thick window wells extending through the marble sheath, from the interior to the exterior that are not marble clad. They appear to reveal an underlying limestone rock, which may be part of the original living rock of the tomb.

The church was built starting in 325/326, and was consecrated on 13 September 335. From pilgrim reports it seems that the chapel housing the tomb of Jesus was freestanding at first, and that the Rotunda was only erected around the chapel in the 380s.

Each year, the Eastern Orthodox Church celebrates the anniversary of the consecration of the Church of the Resurrection (Holy Sepulchre) on 13 September.

This building was damaged by fire in May of 614 when the Sassanid Empire, under Khosrau II, invaded Jerusalem and captured the True Cross. In 630, the Emperor Heraclius restored it and rebuilt the church after recapturing the city. After Jerusalem came under Arab rule, it remained a Christian church, with the early Muslim rulers protecting the city's Christian sites. A story reports that the Caliph Umar ibn al-Khattab visited the church and stopped to pray on the balcony; but at the time of prayer, he turned away from the church and prayed outside. He feared that future generations would misinterpret this gesture, taking it as a pretext to turn the church into a mosque. Eutychius added that Umar wrote a decree prohibiting Muslims from praying at this location. The building suffered severe damage due to an earthquake in 746.

Early in the ninth century, another earthquake damaged the dome of the Anastasis. The damage was repaired in 810 by Patriarch Thomas. In the year 841, the church suffered a fire. In 935, the Orthodox Christians prevented the construction of a Muslim mosque adjacent to the Church. In 938, a new fire damaged the inside of the basilica and came close to the rotunda. In 966, due to a defeat of Muslim armies in the region of Syria, a riot broke out, which was followed by reprisals. The basilica was burned again. The doors and roof were burnt, and the Patriarch John VII was murdered.

On 18 October 1009, Fatimid caliph Al-Hakim bi-Amr Allah ordered the complete destruction of the church as part of a more general campaign against Christian places of worship in Palestine and Egypt. The damage was extensive, with few parts of the early church remaining. Christian Europe reacted with shock and expulsions of Jews (for example, Cluniac monk Rodulfus Glaber blamed the Jews, with the result that Jews were expelled from Limoges and other French towns) and an impetus to later Crusades.

In wide-ranging negotiations between the Fatimids and the Byzantine Empire in 1027–28, an agreement was reached whereby the new Caliph Ali az-Zahir (Al-Hakim's son) agreed to allow the rebuilding and redecoration of the Church. The rebuilding was finally completed with the financing at a huge expense by Emperor Constantine IX Monomachos and Patriarch Nicephorus of Constantinople in 1048. As a concession, the mosque in Constantinople was re-opened and the khutba sermons were to be pronounced in az-Zahir's name. Muslim sources say a by-product of the agreement was the recanting of Islam by many Christians who had been forced to convert under Al-Hakim's persecutions. In addition, the Byzantines, while releasing 5,000 Muslim prisoners, made demands for the restoration of other churches destroyed by Al-Hakim and the re-establishment of a Patriarch in Jerusalem. Contemporary sources credit the emperor with spending vast sums in an effort to restore the Church of the Holy Sepulchre after this agreement was made. Despite the Byzantines spending vast sums on the project, "a total replacement was far beyond available resources. The new construction was concentrated on the rotunda and its surrounding buildings: the great basilica remained in ruins." The rebuilt church site consisted of "a court open to the sky, with five small chapels attached to it." The chapels were to the east of the court of resurrection, where the wall of the great church had been. They commemorated scenes from the passion, such as the location of the prison of Christ and of his flagellation, and presumably were so placed because of the difficulties of free movement among shrines in the streets of the city. The dedication of these chapels indicates the importance of the pilgrims' devotion to the suffering of Christ. They have been described as 'a sort of Via Dolorosa in miniature'... since little or no rebuilding took place on the site of the great basilica. Western pilgrims to Jerusalem during the eleventh century found much of the sacred site in ruins." Control of Jerusalem, and thereby the Church of the Holy Sepulchre, continued to change hands several times between the Fatimids and the Seljuk Turks (loyal to the Abbasid caliph in Baghdad) until the arrival of the Crusaders in 1099.

Many historians maintain that the main concern of Pope Urban II, when calling for the First Crusade, was the threat to Constantinople from the Turkish invasion of Asia Minor in response to the appeal of Byzantine Emperor Alexios I Komnenos. Historians agree that the fate of Jerusalem and thereby the Church of the Holy Sepulchre was of concern if not the immediate goal of papal policy in 1095. The idea of taking Jerusalem gained more focus as the Crusade was underway. The rebuilt church site was taken from the Fatimids (who had recently taken it from the Abassids) by the knights of the First Crusade on 15 July 1099.
The First Crusade was envisioned as an armed pilgrimage, and no crusader could consider his journey complete unless he had prayed as a pilgrim at the Holy Sepulchre. Crusader Prince Godfrey of Bouillon, who became the first crusader monarch of Jerusalem, decided not to use the title "king" during his lifetime, and declared himself "Advocatus Sancti Sepulchri" ("Protector [or Defender] of the Holy Sepulchre"). By the crusader period, a cistern under the former basilica was rumoured to have been the location where Helena had found the True Cross, and began to be venerated as such; although the cistern later became the "Chapel of the Invention of the Cross," there is no evidence of the rumour before the 11th century, and modern archaeological investigation has now dated the cistern to 11th century repairs by Monomachos.

According to the German clergyman and orient pilgrim Ludolf von Sudheim, the keys of the Chapel of the Holy Sepulchre were in hands of the "ancient Georgians" and the food, alms, candles and oil for lamps were given them by the pilgrims in the south door of the church.

William of Tyre, chronicler of the Crusader Kingdom of Jerusalem, reports on the renovation of the Church in the mid-12th century. The crusaders investigated the eastern ruins on the site, occasionally excavating through the rubble, and while attempting to reach the cistern, they discovered part of the original ground level of Hadrian's temple enclosure; they decided to transform this space into a chapel dedicated to Helena (the Chapel of Saint Helena), widening their original excavation tunnel into a proper staircase. The crusaders began to refurnish the church in a Romanesque style and added a bell tower. These renovations unified the small chapels on the site and were completed during the reign of Queen Melisende in 1149, placing all the Holy places under one roof for the first time. The church became the seat of the first Latin Patriarchs, and was also the site of the kingdom's scriptorium. The church was lost to Saladin, along with the rest of the city, in 1187, although the treaty established after the Third Crusade allowed for Christian pilgrims to visit the site. Emperor Frederick II (r. 1220–50) regained the city and the church by treaty in the 13th century while he himself was under a ban of excommunication, with the curious consequence that the holiest church in Christianity was laid under interdict. The church seems to have been largely in Greek Orthodox Patriarch Athanasius II of Jerusalem's hands, c. 1231–47, during the Latin control of Jerusalem. Both city and church were captured by the Khwarezmians in 1244.

The Franciscan friars renovated it further in 1555, as it had been neglected despite increased numbers of pilgrims. The Franciscans rebuilt the Aedicule, extending the structure to create an ante-chamber. After the renovation of 1555, control of the church oscillated between the Franciscans and the Orthodox, depending on which community could obtain a favorable "firman" from the "Sublime Porte" at a particular time, often through outright bribery, and violent clashes were not uncommon. There was no agreement about this question, although it was discussed at the negotiations to the Treaty of Karlowitz in 1699. In 1767, weary of the squabbling, the "Porte" issued a "firman" that divided the church among the claimants.

A fire severely damaged the structure again in 1808, causing the dome of the Rotunda to collapse and smashing the Aedicule's exterior decoration. The Rotunda and the Aedicule's exterior were rebuilt in 1809–1810 by architect Nikolaos Ch. Komnenos of Mytilene in the then current Ottoman Baroque style. The fire did not reach the interior of the Aedicule, and the marble decoration of the Tomb dates mainly to the 1555 restoration, although the interior of the ante-chamber, now known as the "Chapel of the Angel," was partly rebuilt to a square ground-plan, in place of the previously semi-circular western end. Another decree in 1853 from the sultan solidified the existing territorial division among the communities and set a "status quo" for arrangements to "remain forever," causing differences of opinion about upkeep and even minor changes, including disagreement on the removal of the "Immovable Ladder", an exterior ladder under one of the windows; this ladder has remained in the same position since then.
The cladding of red marble applied to the Aedicule by Komnenos has deteriorated badly and is detaching from the underlying structure; since 1947 it has been held in place with an exterior scaffolding of iron girders installed by the British authorities. A careful renovation is undergoing, funded by a $4 million gift from King Abdullah II of Jordan and a $1.3-million gift from Mica Ertegun.

The current dome dates from 1870, although it was restored between 1994–1997, as part of extensive modern renovations to the church which have been ongoing since 1959. During the 1970–1978 restoration works and excavations inside the building, and under the nearby Muristan, it was found that the area was originally a quarry, from which white "meleke" limestone was struck. To the east of the "Chapel of Saint Helena", the excavators discovered a void containing a 2nd-century drawing of a Roman ship, two low walls which supported the platform of Hadrian's 2nd-century temple, and a higher 4th-century wall built to support Constantine's basilica. After the excavations of the early 1970s, the Armenian authorities converted this archaeological space into the Chapel of Saint Vartan, and created an artificial walkway over the quarry on the north of the chapel, so that the new Chapel could be accessed (by permission) from the "Chapel of Saint Helena".

In 2016, restoration works were performed in the Aedicule. For the first time since at least 1555, marble cladding which protected the estimated burial bed of Jesus from vandalism and souvenir takers was removed. When the cladding was first removed on October 26, an initial inspection by the National Technical University of Athens team showed only a layer of fill material underneath. By the night of October 28, the original limestone burial bed was revealed intact. This suggested that the tomb location has not changed through time and confirmed the existence of the original limestone cave walls within the Aedicule. The tomb was resealed shortly thereafter.

The courtyard facing the entrance to the church is known as the parvis.

Located around the parvis are a few smaller structures.

South of the parvis, opposite the church:

On the eastern side of the parvis, south to north:
North of the parvis, in front of the church façade or against it:

A group of three chapels is bordering the parvis on its west side. They originally formed the baptistery complex of the Constantinian church. The southernmost chapel was the vestibule, the middle chapel the actual baptistery, and the north chapel the chamber in which the patriarch chrismated the newly baptized before leading them into the rotunda north of this complex. Now they are dedicated as (from south to north)

The church's bell tower is located to the left of the façade. It is currently almost half its original size.

The entrance to the church, a single door in the south transept—through the crusader façade—is found past a group of streets winding through the outer Via Dolorosa, by way of a local souq in the Muristan. This narrow way of access to such a large structure has proven to be hazardous at times. For example, when a fire broke out in 1840, dozens of pilgrims were trampled to death.

The "Immovable Ladder", in its latest incarnation, stands beneath a window on the façade.

Historically, two large, arched doors allowed access to the church. However, only the left-hand entrance is currently accessible, as the right door has long since been bricked up. These entrances are located in the parvis of a larger courtyard, or plaza.

Just inside the church is a stairway climbing to Calvary (Golgotha), traditionally regarded as the site of Jesus' crucifixion and the most lavishly decorated part of the church. The exit is via another stairway opposite the first, leading down to the ambulatory. The Golgotha and its chapels are just south of the main altar of the Catholicon.

On the ground floor, underneath the Golgotha chapel proper, are the Chapel of Adam and the Treasury of the Greek Orthodox Patriarchate, holding many relics including an alleged fragment of the Holy Cross.

The raised Chapel of the Calvary, or Golgotha Chapel, contains the apex of the Rock of Calvary (12th Station of the Cross). It is split into two halves, one Greek Orthodox and one Catholic, each one with its own altar. The northern half with the main altar belongs to the Greek Orthodox. The rock can be seen under glass on both sides of the altar, and beneath the altar there is a hole in the rock, said to be the place where the cross was raised. Due to the significance of this, it is the most visited site in the Church of the Holy Sepulchre along with the Tomb of Jesus. The Roman Catholic (Franciscan) Chapel of the Nailing of the Cross (11th Station of the Cross) stretches south of it. Between the Catholic and the Orthodox altar, there is a statue of Mary, believed by some to be miraculous. It marks the 13th Station of the Cross, where Jesus' body was removed from the cross and given to his family and disciples.

Beneath the Calvary and the two chapels there, on the main floor, there is the Chapel of Adam. According to tradition, Jesus was crucified over the place where Adam's skull was buried. According to some, at the crucifixion, the blood of Christ ran down the cross and through the rocks to fill the skull of Adam. The Rock of Calvary appears cracked through a window on the altar wall, with the crack traditionally claimed to be caused by the earthquake that occurred when Jesus died on the cross, while some scholars claim it to be the result of quarrying against a natural flaw in the rock.

Just inside the entrance to the church is the Stone of Anointing (also Stone of the Anointing or Stone of Unction), which tradition believes to be the spot where Jesus' body was prepared for burial by Joseph of Arimathea. However, this tradition is only attested since the crusader era (notably by the Italian Dominican pilgrim Riccoldo da Monte di Croce in 1288), and the present stone was only added in the 1810 reconstruction.

The wall behind the stone is defined by its striking blue balconies and tau cross-bearing red banners (depicting the insignia of the Brotherhood of the Holy Sepulchre), and is decorated with lamps. The modern three-part mosaic along the wall depicts the anointing of Jesus' body, preceded on the right by the Descent from the Cross, and succeeded on the left by the Burial of Jesus.

The wall was a temporary addition to support the arch above it, which had been weakened after the damage in the 1808 fire; it blocks the view of the rotunda, separates the entrance from the Catholicon, sits on top of the now-empty and desecrated graves of four 12th-century crusader kings—including Godfrey of Bouillon and Baldwin I of Jerusalem—and is no longer structurally necessary. There is a difference of opinion as to whether it is to be seen as the 13th Station of the Cross, which others identify as the lowering of Jesus from the cross and locate between the 11th and 12th stations up on Calvary.

The lamps that hang over the Stone of Unction, adorned with cross-bearing chain links, are contributed by Armenians, Copts, Greeks and Latins.

Immediately to the left of the entrance is a bench that has traditionally been used by the church's Muslim doorkeepers, along with some Christian clergy, as well as electrical wiring. To the right of the entrance is a wall along the ambulatory containing, to the very right, the staircase leading to Golgotha. Further along the same wall is the entrance to the Chapel of Adam.

The Rotunda is located in the centre of the Anastasis, beneath the larger of the church's two domes. In the center of the Rotunda is the chapel called the Aedicule, which contains the Holy Sepulchre itself. The Aedicule has two rooms, the first holding the Angel's Stone, which is believed to be a fragment of the large stone that sealed the tomb; the second is the tomb itself. Possibly due to the fact that pilgrims laid their hands on the tomb and/or to prevent eager pilgrims from removing bits of the original rock as souvenirs, a marble plaque was placed in the fourteenth century on the tomb to prevent further damage to the tomb.

Under the "status quo", the Eastern Orthodox, Roman Catholic, and Armenian Apostolic Churches all have rights to the interior of the tomb, and all three communities celebrate the Divine Liturgy or Holy Mass there daily. It is also used for other ceremonies on special occasions, such as the Holy Saturday ceremony of the Holy Fire led by the Greek Orthodox Patriarch (with the participation of the Coptic and Armenian patriarchs). To its rear, in a chapel constructed of iron latticework upon a stone base semicircular in plan, lies the altar used by the Coptic Orthodox. Historically, the Georgians also retained the key to the Aedicule.

From May 2016 to March 2017, the Aedicule underwent restoration and repairs after the Israel Antiquities Authority declared the structure unsafe. Much of the $3 million project was funded by the World Monuments Fund.

West of the Aedicule, to the rear of the Rotunda, is a chapel (see "Syriac Chapel with Tomb of Joseph of Arimathea") located in a Constantinian apse and containing an opening to a rock-cut ancient Jewish tomb. This chapel is where the Syriac Orthodox celebrate their Liturgy on Sundays.

To the right of the Sepulchre on the northwestern edge of the Rotunda is the Chapel of the Apparition, which is reserved for Roman Catholic use (see "Franciscan area north of the Aedicule").


East of this is a large iconostasis demarcating the Orthodox sanctuary before which is set the throne of the Greek Orthodox Patriarch of Jerusalem on the south side facing the throne of the Greek Orthodox Patriarch of Antioch on the north side.


Further to the east in the ambulatory are three chapels (from south to north):




It is accessed from the Rotunda, by a door west of the Aedicule. On the far side of the chapel is the low entrance to an almost complete 1st-century Jewish tomb, initially holding six "kokh"-type funeral shafts radiating from a central chamber, of which two are still exposed. Although this space was discovered recently and contains no identifying marks, many Christians believe that Saints Joseph of Arimathea and Nicodemus were buried here.

Since Jews always buried their dead outside the city, the presence of this tomb proves that the Holy Sepulchre site was outside the city walls at the time of the crucifixion.

South of the Aedicule is the "Place of the Three Marys", marked by a stone canopy and a large modern wall mosaic. From here one can enter the Armenian monastery which stretches over the ground and first upper floor of the church's southeastern part.

The Sultan's firman (decree) of 1853, known as the "status quo", pinned down the now permanent statutes of property and the regulations concerning the roles of the different denominations and other custodians.

The primary custodians are the Greek Orthodox, Armenian Apostolic, and Roman Catholic Churches, with the Greek Orthodox Church having the lion's share. In the 19th century, the Coptic Orthodox, the Ethiopian Orthodox and the Syriac Orthodox acquired lesser responsibilities, which include shrines and other structures in and around the building. Times and places of worship for each community are strictly regulated in common areas. The Greek Orthodox act through the Greek Orthodox Patriarchate as well as through the Brotherhood of the Holy Sepulchre. The Roman Catholics act through the Franciscan Custody of the Holy Land.

The establishment of the 1853 status quo did not halt controversy and sometimes violence, which continues to break out occasionally. On a hot summer day in 2002, a Coptic monk moved his chair from its agreed spot into the shade. This was interpreted as a hostile move by the Ethiopians, and eleven were hospitalized after the resulting fracas.

In another incident in 2004, during Orthodox celebrations of the Exaltation of the Holy Cross, a door to the Franciscan chapel was left open. This was taken as a sign of disrespect by the Orthodox and a fistfight broke out. Some people were arrested, but no one was seriously injured.
On Palm Sunday, in April 2008, a brawl broke out when a Greek monk was ejected from the building by a rival faction. Police were called to the scene but were also attacked by the enraged brawlers. On Sunday, 9 November 2008, a clash erupted between Armenian and Greek monks during celebrations for the Feast of the Cross.

A less grave sign of this state of affairs is located on a window ledge over the church's entrance. A wooden ladder was placed there at some time before 1852, when the "status quo" defined both the doors and the window ledges as common ground. This ladder, the "Immovable Ladder", in its latest incarnation, remains to this day, in almost exactly the same position it occupied in century-old photographs and engravings, as it must be replaced whenever it falls apart. An engraving by David Roberts in 1839 also shows the same ladder in the same position.

No one controls the main entrance. In 1192, Saladin assigned door-keeping responsibilities to the Muslim Nuseibeh family. The wooden doors that compose the main entrance are the original, highly carved doors. The Joudeh Al-Goudia family were entrusted as custodian to the keys of the Holy Sepulchre by Saladin in 1187.

Despite occasional disagreements, the religious services take place in the Church with regularity and coexistence is generally peaceful. An example of concord between the Church custodians is the recent (2016–17) full restoration of the Aedicule.

In late February 2018 after a tax dispute over 152 million euros of uncollected taxes on church properties the Church had closed until further notice. The city hall stressed that the Church of the Holy Sepulchre and all other churches are exempt from the taxes, with the changes only affecting establishments like "hotels, halls and businesses" owned by the churches. NPR had reported that the Greek Orthodox Church calls itself the second-largest landowner in Israel, after the Israeli government.

There was a lock in protest against an Israeli legislative proposal which would expropriate church lands that had been sold to private companies since 2010, a measure which church leaders assert constitutes a serious violation of their property rights and the status quo. In a joint official statement the church authorities protested what they considered to be the peak of a systematic campaign in
'a discriminatory and racist bill that targets solely the properties of the Christian community in the Holy Land,' adding, 'This reminds us all of laws of a similar nature which were enacted against the Jews during dark periods in Europe.'

The 2018 Taxation affair does not cover any church buildings or religious related facilities (because they are exempt by law), but commercial facilities such as the Notre Dame Hotel which was not paying the arnona tax, and any land which is owned and used as a commercial land. The church hold the rights to land where private homes have been constructed, and some of the disagreement had been raised after the Knesset had proposed a bill that will make it harder for a private company not to extend a lease for land used by homeowners. According to the JPost 'The stated aim of the bill is to protect homeowners against the possibility that private companies will not extend their leases of land on which their houses or apartments stand.' The church leaders have said that such a bill will make it harder for them to sell church owned lands.

The site of the Church had been a temple of Venus before Constantine's edifice was built. Hadrian's temple had actually been located there because it was the junction of the main north-south road with one of the two main east-west roads and directly adjacent to the forum (which is now the location of the (smaller) Muristan); the forum itself had been placed, as is traditional in Roman towns, at the junction of the main north-south road with the (other) main east-west road (which is now El-Bazar/David Street). The temple and forum together took up the entire space between the two main east-west roads (a few above-ground remains of the east end of the temple precinct still survive in the Alexander Nevsky Church complex of the "Russian Mission in Exile").

From the archaeological excavations in the 1970s, it is clear that construction took over most of the site of the earlier temple enclosure and that the "Triportico" and "Rotunda" roughly overlapped with the temple building itself; the excavations indicate that the temple extended at least as far back as the Aedicule, and the temple enclosure would have reached back slightly further. Virgilio Canio Corbo, a Franciscan priest and archaeologist, who was present at the excavations, estimated from the archaeological evidence that the western retaining wall of the temple itself would have passed extremely close to the east side of the supposed tomb; if the wall had been any further west any "tomb" would have been crushed under the weight of the wall (which would be immediately above it) if it had not already been destroyed when foundations for the wall were made.

Other archaeologists have criticized Corbo's reconstructions. Dan Bahat, the former city archaeologist of Jerusalem, regards them as unsatisfactory, as there is no known temple of Aphrodite matching Corbo's design, and no archaeological evidence for Corbo's suggestion that the temple building was on a platform raised high enough to avoid including anything sited where the Aedicule is now; indeed Bahat notes that many temples to Aphrodite have a rotunda-like design, and argues that there is no archaeological reason to assume that the present rotunda was not based on a rotunda in the temple previously on the site.

The New Testament describes Jesus's tomb as being outside the city wall, as was normal for burials across the ancient world, which were regarded as unclean. Today, the site of the Church is within the current walls of the old city of Jerusalem. It has been well documented by archaeologists that in the time of Jesus, the walled city was smaller and the wall then was to the east of the current site of the Church. In other words, the city had been much narrower in Jesus' time, with the site then having been outside the walls; since Herod Agrippa (41–44) is recorded by history as extending the city to the north (beyond the present northern walls), the required repositioning of the western wall is traditionally attributed to him as well.

The area immediately to the south and east of the sepulchre was a quarry and outside the city during the early 1st century as excavations under the Lutheran Church of the Redeemer across the street demonstrated.

The church is a part of the UNESCO World Heritage Site Old City of Jerusalem.

The Christian Quarter and the (also Christian) Armenian Quarter of the Old City of Jerusalem are both located in the northwestern and western part of the Old City, due to the fact that the Holy Sepulchre is located close to the northwestern corner of the walled city. The adjacent neighbourhood within the Christian Quarter is called the Muristan, a term derived from the Persian word for hospital—Christian pilgrim hospices have been maintained in this area near the Holy Sepulchre since at least the time of Charlemagne.

From the 9th century, the construction of churches inspired in the Anastasis was extended across Europe. One example is Santo Stefano in Bologna, Italy, an agglomeration of seven churches recreating shrines of Jerusalem.

Several churches and monasteries in Europe, for instance, in Germany and Russia, and at least one church in the United States have been modeled on the Church of the Resurrection, some even reproducing other holy places for the benefit of pilgrims who could not travel to the Holy Land. They include the of Görlitz, constructed between 1481 and 1504, the New Jerusalem Monastery in Moscow Oblast, constructed by Patriarch Nikon between 1656 and 1666, and Mount St. Sepulchre Franciscan Monastery built by the Franciscans in Washington, DC in 1898.





</doc>
<doc id="7811" url="https://en.wikipedia.org/wiki?curid=7811" title="Cernunnos">
Cernunnos

Cernunnos is the conventional name given in Celtic studies to depictions of the "horned god" of Celtic polytheism. Cernunnos was a Celtic god of fertility, life, animals, wealth, and the underworld. The name itself is only attested once, on the 1st-century Pillar of the Boatmen, but he appears all over Gaul, and among the Celtiberians. Cernunnos is depicted with the antlers of a stag, sometimes carries a purse filled with coin, often seated cross-legged and often associated with animals and holding or wearing torcs, are known from over 50 examples in the Gallo-Roman period, mostly in north-eastern Gaul. 

Not much is known about the god from literary sources, and details about his name, his followers or his significance in Celtic religion are unknown. Speculative interpretations identify him as a god of nature, life or fertility. 

The theonym "[C]ernunnos" appears on the Pillar of the Boatmen, a Gallo-Roman monument dating to the early 1st century CE, to label a god depicted with stag's antlers in their early stage of annual growth. Both antlers have torcs hanging from them.

The name has been compared to a divine epithet "Carnonos" in a Celtic inscription written in Greek characters at Montagnac, Hérault (as καρνονου, "karnonou", in the dative case).
A Gallo-Latin adjective "carnuātus", "horned," is also found. 

The Proto-Celtic form of the theonym is reconstructed as either *"Cerno-on-os" or *"Carno-on-os". The augmentative "-on-" is characteristic of theonyms, as in Maponos, Epona, Matronae, and Sirona.
Maier (2010) states that the etymology of "Cernunnos" is unknown, as the Celtic word for "horn" has an "a" (as in "Carnonos").

Gaulish "karnon" "horn"is cognate with Latin "cornu" and Germanic "*hurnaz", English "horn", ultimately from Proto-Indo-European "".
The etymon "karn-" "horn" appears in both Gaulish and Galatian branches of Continental Celtic. Hesychius of Alexandria glosses the Galatian word "karnon" (κάρνον) as "Gallic trumpet", that is, the Celtic military horn listed as the carnyx (κάρνυξ) by Eustathius of Thessalonica, who notes the instrument's animal-shaped bell. The root also appears in the names of Celtic polities, most prominent among them the Carnutes, meaning something like "the Horned Ones," and in several personal names found in inscriptions.

The name "Cernunnos" occurs only on the "Pillar of the Boatmen" ("Pilier des nautes"), now displayed in the Musée National du Moyen Age in Paris. Constructed by Gaulish sailors probably in 14 CE, it was discovered in 1710 within the foundations of the cathedral of Notre-Dame de Paris, site of ancient Lutetia, the "civitas" capital of the Celtic Parisii. The distinctive stone pillar is an important monument of Gallo-Roman religion. Its low reliefs depict and label by name several Roman deities such as Jupiter, Vulcan, and Castor and Pollux, along with Gallic deities such as Esus, Smertrios, and Tarvos Trigaranus. The name "Cernunnos" can be read clearly on 18th century drawings of the inscriptions, but the initial letter has been obscured since, so that today only a reading "[_]ernunnos" can be verified

Additional evidence is given by one inscription on a metal plaque from Steinsel-Rëlent in Luxembourg, in the territory of the Celtic Treveri. This inscription read "Deo Ceruninco", "to the God Cerunincos", assumed to be the same deity. The Gaulish inscription from Montagnac reads αλλετ[ει]νος καρνονου αλ[ι]σο[ντ]εας ("Alletinos [dedicated this] to Carnonos of Alisontea"), with the last word possibly a place name based on "Alisia", "service-tree" or "rock" (compare Alesia, Gaulish "Alisiia").

The god labelled "[C]ernunnos" on the Pillar of the Boatmen is depicted with stag's antlers in their early stage of annual growth. Both antlers have torcs hanging from them. The lower part of the relief is lost, but the dimensions suggest that the god was sitting cross-legged, providing a direct parallel to the antlered figure on the Gundestrup cauldron.

In spite of the name "Cernunnos" being attested nowhere else, it is commonly used in Celtological literature as describing all comparable depictions of horned/antlered deities.

This "Cernunnos" type in Celtic iconography is often portrayed with animals, in particular the stag, and also frequently associated with the ram-horned serpent, and less frequently bulls (at Rheims), dogs and rats. Because of his frequent association with creatures, scholars often describe Cernunnos as the "Lord of the Animals" or the "Lord of Wild Things", and Miranda Green describes him as a "peaceful god of nature and fruitfulness".

The "Pilier des nautes" links him with sailors and with commerce, suggesting that he was also associated with material wealth as does the coin pouch from the Cernunnos of Rheims (Marne, Champagne, France)—in antiquity, Durocortorum, the "civitas" capital of the Remi tribe—and the stag vomiting coins from Niedercorn-Turbelslach (Luxembourg) in the lands of the Treveri. The god may have symbolized the fecundity of the stag-inhabited forest.

Other examples of "Cernunnos" images include a petroglyph in Val Camonica in Cisalpine Gaul. The antlered human figure has been dated as early as the 7th century BCE or as late as the 4th. An antlered child appears on a relief from Vendeuvres, flanked by serpents and holding a purse and a torc. The best known image appears on the Gundestrup cauldron found on Jutland, dating to the 1st century BCE, thought to depict Celtic subject matter though usually regarded as of Thracian workmanship.

Among the Celtiberians, horned or antlered figures of the Cernunnos type include a "Janus-like" god from Candelario (Salamanca) with two faces and two small horns; a horned god from the hills of Ríotinto (Huelva); and a possible representation of the deity Vestius Aloniecus near his altars in Lourizán (Pontevedra). The horns are taken to represent "aggressive power, genetic vigor and fecundity."

Divine representations of the Cernunnos type are exceptions to the often-expressed view that the Celts only began to picture their gods in human form after the Roman conquest of Gaul.
The Celtic "horned god", while well attested in iconography, cannot be identified in description of Celtic religion in Roman ethnography and does not appear to have been given any "interpretatio romana", perhaps due to being too distinctive to be translatable into the Roman pantheon.
While Cernunnos was never assimilated, scholars have sometimes compared him functionally to Greek and Roman divine figures such as Mercury, Actaeon, specialized forms of Jupiter, and Dis Pater, the latter of whom Julius Caesar said was considered the ancestor of the Gauls.

There have been attempts to find the "cern" root in the name of Conall Cernach, the foster brother of the Irish hero Cuchulainn in the Ulster Cycle. In this line of interpretation, "Cernach" is taken as an epithet with a wide semantic field — "angular; victorious; bearing a prominent growth" — and Conall is seen as "the same figure" as the ancient Cernunnos.

There is even greater evidence available to connect Conall Cernach to Cernunnos than the similarity in the names. A brief passage involving Conall in an eighth-century story entitled "Táin Bó Fraích" (“The Cattle Raid on Fraech”) has been questioned before for its anti-climatic conclusion to an epic Celtic tale. In this passage Conall Cernach is portrayed as a hero and mighty warrior who assists the protagonist Fraech in rescuing his wife and son, and in reclaiming for Fraech his cattle. The fort that Conall must penetrate is guarded by a mighty serpent. The supposed anti-climax of this tale is when the fearsome serpent, instead of attacking Conall, darts to Conall’s waist and girdles him as a belt. Rather than killing the serpent, Conall allows it to live, and then proceeds to attack and rob the fort of its great treasures the serpent previously protected.

Cernunnos, as the conjectured Gaulish manifestation of the Roman Dis Pater, is considered to share the latter’s attributes of ruling over the hidden treasures of the underworld. Subterranean treasures were commonly linked in Medieval Bestiaries to the serpent, the occupant of the underground, or otherworld, and the keeper of its treasures and mysteries. This aspect of Cernunnos is depicted on a stone statue from a well in Sommerécourt, Haute-Marne, France, and on a bronze figurine from Autun. Both statue and figurine portray Cernunnos with the two ram-headed serpents encircling his waist. This is more than just a small similarity to the instance of the serpent that guarded the treasure of the fort in "Táin Bó Fraích" surrendering to Conall Cernach and becoming his belt. Cernunno’s connections to the deity Mars serve to underline Conall’s role as hero-warrior in the tale.

The anti-climatic nature of the eighth-century Irish tale then gains significant clarity in the light of the relationship between a horned or antler-bearing deity, warrior, or progenitor, and the chthonic dwelling, treasure-guarding serpent that encircled the waist of the one it chose to protect. This universal Celtic concept comes down to us as a mere echo of its ancient self through centuries of the Christianization of Ireland. The Gaelic Cernunnos may now possibly only be found in the slight similarity of a name and the peculiarity of a single passage from a Middle Ages Irish epic.

Some see the qualities of Cernunnos subsumed into the "life" of Saint Ciarán of Saighir, one of the Twelve Apostles of Ireland. When he was building his first tiny cell, as his hagiograph goes, his first disciple and monk was a boar that had been rendered gentle by God. This was followed by a fox, a badger, a wolf and a stag.

In Wicca and other forms of Neopaganism a Horned God is revered; this divinity syncretises a number of horned or antlered gods from various cultures, including Cernunnos. The Horned God reflects the seasons of the year in an annual cycle of life, death and rebirth.
In the tradition of Gardnerian Wicca, the Horned God is sometimes specifically referred to as Cernunnos, or sometimes also as Kernunno.





</doc>
<doc id="7816" url="https://en.wikipedia.org/wiki?curid=7816" title="Click consonant">
Click consonant

Click consonants, or clicks, are speech sounds that occur as consonants in many languages of Southern Africa and in three languages of East Africa. Examples familiar to English-speakers are the "Tut-tut" (British spelling) or "Tsk! Tsk!" (American spelling) used to express disapproval or pity, the "tchick!" used to spur on a horse, and the "clip-clop!" sound children make with their tongue to imitate a horse trotting.

Technically, clicks are obstruents articulated with two closures (points of contact) in the mouth, one forward and one at the back. The enclosed pocket of air is rarefied by a sucking action of the tongue (in technical terminology, clicks have a lingual ingressive airstream mechanism). The forward closure is then released, producing what may be the loudest consonants in the language, but in some languages such as Hadza and Sandawe, clicks can be more subtle and may even be mistaken for ejectives.

Click consonants occur at five principal places of articulation. The International Phonetic Alphabet (IPA) represents a click by placing the assigned symbol for the place of click articulation adjacent to a symbol for a non-click sound at the rear place of articulation. The IPA symbols are used in writing most Khoisan languages, but Bantu languages such as Zulu typically use Latin , and for dental, lateral and alveolar clicks respectively.

The above clicks sound like affricates, in that they involve a lot of friction. The other two families are more abrupt sounds that do not have this friction.

Clicks occur in all three Khoisan language families of southern Africa, where they may be the most numerous consonants. To a lesser extent they occur in three neighbouring groups of Bantu languages—which borrowed them, directly or indirectly, from Khoisan. In the southeast, in eastern South Africa, Swaziland, Lesotho, Zimbabwe and southern Mozambique, they were adopted from a Tuu language or languages by the languages of the Nguni cluster (especially Zulu, Xhosa and Phuthi, but also to a lesser extent Swazi and Ndebele), and spread from them in a reduced fashion to the Zulu-based pidgin Fanagalo, Sesotho, Tsonga, Ronga, the Mzimba dialect of Tumbuka and more recently to Ndau and urban varieties of Pedi, where the spread of clicks continues. The second point of transfer was near the Caprivi Strip and the Okavango River where, apparently, the Yeyi language borrowed the clicks from a West Kalahari Khoe language; a separate development led to a smaller click inventory in the neighbouring Mbukushu, Kwangali, Gciriku, Kuhane and Fwe languages in Angola, Namibia, Botswana and Zambia. These sounds occur not only in borrowed vocabulary, but have spread to native Bantu words as well, in the case of Nguni at least partially due to a type of word taboo called hlonipha. Some creolised varieties of Afrikaans, such as Oorlams, retain clicks in Khoekhoe words.

Three languages in East Africa use clicks: Sandawe and Hadza of Tanzania, and Dahalo, an endangered South Cushitic language of Kenya that has clicks in only a few dozen words. It is thought the latter may remain from an episode of language shift.

The only non-African language known to have clicks as regular speech sounds is Damin, a ritual code used by speakers of Lardil in Australia. One of the clicks in Damin is actually an egressive click, using the tongue to compress the air in the mouth for an outward (egressive) "spurt".

For the most part, the Southern African Khoisan languages only use root-initial clicks. Hadza, Sandawe and several Bantu languages also allow syllable-initial clicks within roots, but in no language does a click close a syllable or end a word. Once clicks are borrowed into a language as regular speech sounds, they may spread to native words, as has happened due to "hlonipa" word-taboo in the Nguni languages. In Gciriku, for example, the European loanword "tomate" (tomato) appears as "cumáte" with a click "c", though it begins with a "t" in all neighbouring languages.

Scattered clicks are found in ideophones in other languages, such as Kongo , Mijikenda and Hadza (Hadza does not otherwise have labial clicks). Ideophones often use phonemic distinctions not found in normal vocabulary.

English and many other languages may use bare clicks in interjections, without the accompaniment of vowels, such as the dental "tsk-tsk" sound used to express disapproval, or the lateral "tchick" used with horses. In Ningdu Chinese (a variety of Hakka), flapped nasal clicks are used in nursery rhymes. In Armenian, Bulgarian, Greek, Levantine Arabic, Maltese, Persian, Turkish, some time in French, as well as southern Italian languages such as Sicilian, a bare dental click accompanied by tipping the head upwards signifies "no". Libyan Arabic apparently has three such sounds.

Clicks occasionally turn up elsewhere, as in the special registers twins sometimes develop with each other. In West Africa, clicks have been reported allophonically, and similarly in German, faint clicks have been recorded in rapid speech where the consonants and overlap between words.

Occasionally other languages are said to have click sounds. This is usually a misnomer for ejective consonants, which are found across much of the world.

Like other consonants, clicks can be described using four parameters: place of articulation, manner of articulation, phonation (including glottalisation) and airstream mechanism. As noted above, clicks necessarily involve at least two closures, which in some cases operate partially independently: an anterior articulation traditionally represented by the special click symbol in the IPA—and a posterior articulation traditionally described as oral or nasal, voiced or voiceless, etc. The literature also describes a contrast between velar and uvular rear articulations for some languages.

However, recent work shows that in languages that make this distinction, all clicks have a uvular, or even pharyngeal, rear closure—and the clicks explicitly described as uvular are in fact clusters/contours of a click plus a pulmonic or ejective component, in which the cluster/contour has two release bursts, the forward (click) and then the rearward (uvular) component. "Velar" clicks in these languages have only a single release burst, that of the forward click release, and the release of the rear articulation isn't separately audible (Miller 2011).

Nonetheless, in most of the literature the stated place of the click is the anterior articulation (called the "release" or "influx)," whereas the manner is ascribed to the posterior articulation (called the "accompaniment" or "efflux)." The anterior articulation defines the "click type" and is written with the IPA letter for the click (dental , alveolar , etc.), whereas the traditional term 'accompaniment' conflates the categories of manner (nasal, affricated), phonation (voiced, aspirated, breathy voiced, glottalised), as well as any change in the airstream with the release of the posterior articulation (pulmonic, ejective), all of which are transcribed with additional letters or diacritics, as in the "nasal alveolar click", or or—to take an extreme example—the "voiced (uvular) ejective alveolar click", .

The size of click inventories ranges from as few as three (in Sesotho) or four (in Dahalo), to dozens in the Kx'a and Tuu (Northern and Southern Khoisan) languages. Taa, the last vibrant language in the latter family, has 45 to 115 click phonemes, depending on analysis (clusters vs. contours), and over 70% of words in the dictionary of this language begin with a click.

Clicks appear more stop-like (sharp/abrupt) or affricate-like (noisy) depending on their place of articulation: In southern Africa, clicks involving an apical alveolar or laminal postalveolar closure are acoustically abrupt and sharp, like stops, whereas labial, dental and lateral clicks typically have longer and acoustically noisier releases that are superficially more like affricates. In East Africa, however, the alveolar clicks tend to be flapped, whereas the lateral clicks tend to be more sharp.

The five click releases with dedicated symbols in the International Phonetic Alphabet (IPA) are labial , dental , palato-alveolar or "palatal" , (post)alveolar or "retroflex" and lateral . In most languages, the retroflex and palatal releases are "abrupt"; that is, they are sharp popping sounds with little frication (turbulent airflow). The labial, dental and lateral releases, on the other hand, are typically "noisy": they are longer, lip- or tooth-sucking sounds with turbulent airflow, and are sometimes called affricates. (This applies to the forward articulation; both may also have either an affricate or non-affricate rear articulation as well.) The apical releases, and , are sometimes called "grave", because their pitch is dominated by low frequencies; whereas the laminal releases, and , are sometimes called "acute", because they are dominated by high frequencies. (At least in the Nǁng language and Juǀʼhoan, this is associated with a difference in the placement of the rear articulation: "grave" clicks are uvular, whereas "acute" clicks are pharyngeal.) Thus the alveolar click sounds something like a cork pulled from a bottle (a low-pitch pop), at least in Xhosa; whereas the dental click is like English "tsk! tsk!," a high-pitched sucking on the incisors. The lateral clicks are pronounced by sucking on the molars of one or both sides. The labial click is different from what many people associate with a kiss: the lips are pressed more-or-less flat together, as they are for a or an , not rounded as they are for a .

The most populous languages with clicks, Zulu and Xhosa, use the letters "c, q, x," by themselves and in digraphs, to write click consonants. Most Khoisan languages, on the other hand (with the notable exceptions of Naro and Sandawe), use a more iconic system based on the pipe . (The exclamation point for the "retroflex" click was originally a pipe with a subscript dot, along the lines of "ṭ, ḍ, ṇ" used to transcribe the retroflex consonants of India.) There are also two main conventions for the second letter of the digraph as well: voicing may be written with "g" and uvular affrication with "x", or voicing with "d" and affrication with "g" (a convention of Afrikaans). In two orthographies of Juǀ’hoan, for example, is written "g!" or "dq", and "!x" or "qg". In languages without , such as Zulu, may be written "gq".

There are a few less-well-attested articulations. A reported subapical retroflex release in Grootfontein !Kung turns out to be alveolar with lateral release, ; Ekoka !Kung has a fricated alveolar click with an s-like release, provisionally transcribed ; and Hadza and Sandawe have a "slapped" alveolar click, provisionally transcribed (in turn, the lateral clicks in Hadza and Sandawe are more abrupt and less noisy than in southern Africa). However, the Khoisan languages are poorly attested, and it is quite possible that, as they become better described, more click releases will be found.

Formerly when a click consonant was transcribed, two symbols were used, one for each articulation, and connected with a tie bar. This is because a click such as was analysed as a nasal velar rear articulation pronounced simultaneously with the forward ingressive release . The symbols may be written in either order, depending on the analysis: or . However, a tie bar was not often used in practice, and when the manner is tenuis (a simple ), it was often omitted as well. That is, = = = = . Regardless, elements that do not overlap with the release are always written according to their temporal order: Prenasalisation is always written first ( = = ), and the non-lingual part of a contour is always written second ( = = ).

However, it has become standard to analyse clicks as simplex segments, as research has shown that the front and rear articulations are not independent, and to use click symbols to cover the rear articulation as well, with diacritics rather than digraphs for the accompaniments. At first this tended to be for , based on the belief that the rear articulation was velar; but as it has become clear that the rear articulation of both "velar" and "uvular" clicks is actually uvular or even pharyngeal, voicing and nasalisation diacritics more in keeping with the IPA have started to appear: for .

In practical orthography, the voicing or nasalisation is sometimes given the anterior place of articulation: "dc" for and "mʘ" for , for example.

Kirshenbaum transcription uses a very different convention: clicks are denoted by (always ) added to the letter for the stop homorganic to the release, but with the manner of the accompaniment. For example, is a voiceless dental click, and is a nasal bilabial click. This convention is used in the literature on Damin, where the clicks are transcribed as .

Places of articulation are often called click "types, releases," or "influxes." There are seven or eight known releases, not counting slapped or egressive clicks. These are "(bi)labial affricated" , or "(bi)labial"; "laminal denti-alveolar affricated" , or "dental"; "apical (post)alveolar plosive" , or "alveolar"; "laminal postalveolar (palato-alveolar) plosive" , or "palatal"; "laminal postalveolar (palato-alveolar) affricated" (known only from Ekoka !Kung); "subapical postalveolar (retroflex)" (only known from Central !Kung and Damin); and "apical postalveolar lateral" . 

Languages illustrating each of these articulations are listed below. Given the poor state of documentation of Khoisan languages, it is quite possible that additional releases will turn up. No language is known to contrast more than five places of articulation, though one publication has reconstructed Proto-Kx'a with six.

Extra-linguistically, Coatlán Zapotec of Mexico uses a linguolabial click, , as mimesis for a pig drinking water, and several languages, such as Wolof, use a velar click , long judged to be physically impossible, for backchanneling and to express approval. A sublingual click ("sucking-teeth") is found across West Africa, the Caribbean and into the United States. 

The terms for the click releases were originally developed by Bleek in 1911. Since then there has been some conflicting variation. Here are the terms used in some of the main references.

The dental, lateral and bilabial clicks are rarely confused. However, the palatal and alveolar clicks frequently have the opposite names in older literature, and they were not distinguished in the IPA until 1989. However, since Ladefoged & Traill (1984) clarified the places of articulation, the terms in the left column above have become standard.

In several languages, including Nama and Juǀ'hoan, the alveolar click types and only occur, or preferentially occur, before back vowels, whereas the dental and palatal clicks occur before any vowel. The effect is most noticeable with the high front vowel . In Nama, for example, the diphthong is common but is rare after alveolar clicks, whereas the opposite is true after dental and palatal clicks. This is a common effect of uvular or uvularised consonants on vowels in both click and non-click languages. In Taa, for example, the back-vowel constraint is triggered by both alveolar clicks and uvular stops, but not by palatal clicks or velar stops: sequences such as and are rare to non-existent, whereas sequences such as and are common. It is also triggered by labial clicks, though not by labial stops. Clicks subject to this constraint involve a sharp retraction of the tongue during release.

Miller and colleagues (2003) used ultrasound imaging to show that the rear articulation of the alveolar clicks () in Nama is substantially different from that of palatal and dental clicks. Specifically, the shape of the body of the tongue in palatal clicks is very similar to that of the vowel , and involves the same tongue muscles, so that sequences such as involved a simple and quick transition. The rear articulation of the alveolar clicks, however, is several centimetres further back, and involves a different set of muscles in the uvular region. The part of the tongue required to approach the palate for the vowel is deeply retracted in , as it lies at the bottom of the air pocket used to create the vacuum required for click airstream. This makes the transition required for much more complex and the timing more difficult than the shallower and more forward tongue position of the palatal clicks. Consequently, takes 50 ms longer to pronounce than , the same amount of time required to pronounce .

Languages do not all behave alike. In Nǀuu, the simple clicks trigger the and allophones of and , whereas do not. All of the affricated contour clicks, such as , do as well, as do the uvular stops . However, the occlusive contour clicks pattern like the simple clicks, and does not trigger the back-vowel constraint. This is because they involve tongue-root raising rather than tongue-root retraction in the uvular-pharyngeal region. However, in Gǀwi, which is otherwise largely similar, both and trigger the back-vowel constraint (Miller 2009).

Click manners are often called click "accompaniments" or "effluxes", but both terms have met with objections on theoretical grounds.

There is a great variety of click manners, both simplex and complex, the latter variously analysed as consonant clusters or contours. With so few click languages, and so little study of them, it is also unclear to what extent clicks in different languages are equivalent. For example, the of Khoekhoe, of Sandawe and of Hadza may be essentially the same phone; no language distinguishes them, and the differences in transcription may have more to do with the approach of the linguist than with actual differences in the sounds. Such suspected allophones/allographs are listed on a common row in the table below.

Some Khoisan languages are typologically unusual in allowing mixed voicing in non-click consonant clusters/contours, such as , so it is not surprising that they would allow mixed voicing in clicks as well. This may be an effect of epiglottalised voiced consonants, because voicing is incompatible with epiglottalisation.

As do other consonants, clicks vary in phonation. Oral clicks are attested with four phonations: tenuis, aspirated, voiced and breathy voiced (murmured). Nasal clicks may also vary, with plain voiced, breathy voiced / murmured nasal, aspirated and unaspirated voiceless clicks attested (the last only in Taa). The aspirated nasal clicks are often said to have 'delayed aspiration'; there is nasal airflow throughout the click, which may become voiced between vowels, though the aspiration itself is voiceless. A few languages also have pre-glottalised nasal clicks, which have very brief prenasalisation but have not been phonetically analysed to the extent that other types of clicks have.

All languages have nasal clicks, and all but Dahalo and Damin also have oral clicks. All languages but Damin have at least one phonation contrast as well.

Clicks may be pronounced with a third place of articulation, glottal. A glottal stop is made during the hold of the click; the (necessarily voiceless) click is released, and then the glottal hold is released into the vowel. Glottalised clicks are very common, and they are generally nasalised as well. The nasalisation cannot be heard during the click release, as there is no pulmonic airflow, and generally not at all when the click occurs at the beginning of an utterance, but it has the effect of nasalising preceding vowels, to the extent that the glottalised clicks of Sandawe and Hadza are often described as prenasalised when in medial position. Two languages, Gǀwi and Yeyi, contrast plain and nasal glottalised clicks, but in languages without such a contrast, the glottalised click is nasal. Miller (2011) analyses the glottalisation as phonation, and so considers these to be simple clicks.

Various languages also have prenasalised clicks, which may be analysed as consonant sequences. Sotho, for example, allows a syllabic nasal before its three clicks, as in "nnqane" 'the other side' (prenasalised nasal) and "seqhenqha" 'hunk'.

There is ongoing discussion as to how the distinction between what were historically described as 'velar' and 'uvular' clicks is best described. The 'uvular' clicks are only found in some languages, and have an extended pronunciation that suggests that they are more complex than the simple ('velar') clicks, which are found in all. Nakagawa (1996) describes the extended clicks in Gǀwi as consonant clusters, sequences equivalent to English "st" or "pl", whereas Miller (2011) analyses similar sounds in several languages as click–non-click contours, where a click transitions into a pulmonic or ejective articulation within a single segment, analogous to how English "ch" and "j" transition from occlusive to fricative but still behave as unitary sounds. With ejective clicks, for example, Miller finds that although the ejective release follows the click release, it is the rear closure of the click that is ejective, not an independently articulated consonant. That is, in a simple click, the release of the rear articulation is not audible, whereas in a contour click, the rear (uvular) articulation is audibly released after the front (click) articulation, resulting in a double release.

These contour clicks may be "linguo-pulmonic", that is, they may transition from a click (lingual) articulation to a normal pulmonic consonant like (e.g. ); or "linguo-glottalic" and transition from lingual to an ejective consonant like (e.g. ): that is, a sequence of ingressive (lingual) release + egressive (pulmonic or glottalic) release. In some cases there is a shift in place of articulation as well, and instead of a uvular release, the uvular click transitions to a velar or epigottal release (depending on the description, or ). Although homorganic does not contrast with heterorganic in any known language, they are phonetically quite distinct (Miller 2011).

Apart from Dahalo, Damin and many of the Bantu languages (Yeyi and Xhosa being exceptions), 'click' languages have glottalised clicks. Contour clicks are restricted to southern Africa, but are very common there: they are found in all members of the Tuu, Kx'a and Khoe families, as well as in the Bantu language Yeyi.

In a comparative study of clicks across various languages, using her own field work as well as phonetic descriptions and data by other field researchers, Miller (2011) posits 21 types of clicks that contrast in manner or airstream. The homorganic and heterorganic affricated ejective clicks do not contrast in any known language, but are judged dissimilar enough to keep separate. Miller's conclusions differ from those of the primary researcher of a language; see the individual languages for details.
(all spoken primarily in South Africa, Namibia and Botswana; Khoekhoe is like Korana except it has lost ejective )
(Zulu is like Xhosa apart from not having )

Each language below is illustrated with alveolar clicks, apart from Dahalo, which only has dental. Under each language are the orthography (in italics, with old forms in parentheses), the researchers' transcription (in ), or allophonic variation (in [brackets]). Some languages also have labialised or prenasalised clicks.
Yeyi also has prenasalised . The original researchers believe that and are allophones.

A DoBeS (2008) study of the Western !Xoo dialect of Taa found several new manners: creaky voiced (the voiced equivalent of glottalised oral), breathy-voiced nasal, prenasalised ɡlottalised (the voiced equivalent of glottalised) and a (pre)voiced ejective. These extra voiced clicks reflect Western !Xoo morphology, where many nouns form their plural by voicing their initial consonant. DoBeS analyses most Taa clicks as clusters, leaving nine basic manners (marked with asterisks in the table). This comes close to Miller's distinction between simple and contour clicks, shaded light and medium grey in the table.

Clicks are often portrayed as a primordial feature of human language, a romantic reflection of the primordial lifestyle imagined of the speakers of Khoisan languages. One genetic study concluded that clicks, which occur in the languages of the genetically divergent populations Hadza and !Kung, may be an ancient element of human language. However, this conclusion relies on several dubious assumptions (see Hadza language), and most linguists assume that clicks, being quite complex consonants, arose relatively late in human history. How they arose is not known, but it is generally assumed that they developed from sequences of non-click consonants, as they are found allophonically for doubly articulated consonants in West Africa (Ladefoged 1968), where sequences overlap at word boundaries in German, and for the sequence in Ndau and Tonga. Such developments have also been posited in historical reconstruction. For example, the Sandawe word for 'horn', , with a lateral affricate, may be a cognate with the root found throughout the Khoe family, which has a lateral click. This and other words suggests that at least some Khoe clicks may have formed from consonant clusters when the first vowel of a word was lost; in this instance * > * > .

On the other side of the equation, several non-endangered languages in vigorous use demonstrate click loss. For example, the East Kalahari languages have lost clicks from a large percentage of their vocabulary, presumably due to Bantu influence. As a rule, a click is replaced by a consonant with close to the manner of articulation of the click and the place of articulation of the forward release: alveolar click releases (the family) tend to mutate into a velar stop or affricate, such as ; palatal clicks ( "etc.") tend to mutate into a palatal stop such as , or a post-alveolar affricate ; and dental clicks ( "etc.") tend to mutate into an alveolar affricate .

Clicks are often presented as difficult sounds to articulate within words. However, children acquire them readily; a two-year-old, for example, may be able to pronounce a word with a lateral click with no problem, but still be unable to pronounce . Lucy Lloyd reported that after long contact with the Khoi and San, it was difficult for her to refrain from using clicks when speaking English.





</doc>
<doc id="7817" url="https://en.wikipedia.org/wiki?curid=7817" title="The Cider House Rules">
The Cider House Rules

The Cider House Rules (1985) is John Irving's sixth published novel, a "Bildungsroman", and was later adapted into a film (1999) and a stage play by Peter Parnell. The story, which is set in the pre-WWII and post-war era, is about a young man, Homer Wells, growing up under the guidance of Dr. Wilbur Larch, an obstetrician and abortionist. The story relates his early life at Larch's orphanage in Maine and follows Homer as he eventually leaves the nest and comes of age in the world.

The story about Wally being shot down over Burma was based in part on that of Irving's biological father (whom he never met), who had been shot down over Burma and survived.

Homer Wells grows up in an orphanage where he spends his childhood "being of use" as a medical assistant to the director, Dr. Wilbur Larch, whose history is told in flashbacks: After a traumatic misadventure with a prostitute as a young man, Wilbur turns his back on sex and love, choosing instead to help women with unwanted pregnancies give birth and then keeping the babies in an orphanage. He makes a point of maintaining an emotional distance from the orphans, so that they can more easily make the transition into an adoptive family, but when it becomes clear that Homer is going to spend his entire childhood at the orphanage, Wilbur trains the orphan as an obstetrician and then comes to love him like a son.

Wilbur's and Homer's lives are complicated by Wilbur also secretly being an abortionist. Wilbur came to this work reluctantly, but he is driven by having seen the horrors of back-alley operations. Homer, upon learning Wilbur's secret, considers it morally wrong.

As a young man, Homer befriends a young couple, Candy Kendall and Wally Worthington, who come to St. Cloud's for an abortion. Homer leaves the orphanage, and returns with them to Ocean View Orchards (Wally's family's orchard) in Heart's Rock, near the Maine coast. Wally and Homer become best friends and Homer develops a secret love for Candy. Wally goes off to serve in the Second World War and his plane is shot down over Burma. He is presumed missing by the military, but Homer and Candy both believe he is dead and move on with their lives, which includes beginning a romantic relationship. When Candy becomes pregnant, they go back to St. Cloud's Orphanage, where their son is born and named Angel.

Subsequently, Wally is found in Burma and returns home, paralyzed from the waist down. He is still able to have sexual intercourse but is sterile due to an infection caught in Burma. They lie to the family about Angel's parentage, claiming that Homer decided to adopt him. Wally and Candy marry shortly afterward, but Candy and Homer maintain a secret affair that lasts some 15 years.

Many years later, teenaged Angel falls in love with Rose. Rose, the daughter of the head migrant worker at the apple orchard, becomes pregnant by her father, and Homer performs an abortion on her. Homer decides to return to the orphanage after the death of Wilbur, to work as the new director. Though he maintains his distaste for abortions, he continues Dr. Larch's legacy of honoring the choice of his patients, and he dreams of the day when abortions are free, legal, and safe, so he'll no longer feel obliged to offer them.

The name "The Cider House Rules" refer to the list of rules that the migrant workers are supposed to follow at the Ocean View Orchards. However, none of them can read, and they are completely unaware of the rules - which have been posted for years.

A subplot follows the character Melony, who grew up alongside Homer in the orphanage. She was Homer's first girlfriend in a relationship of circumstances. After Homer leaves the orphanage, so does she in an effort to find him. She eventually becomes an electrician and takes a female lover, Lorna. Melony is an extremely stoic woman, who refuses to press charges against a man who brutally broke her nose and arm so that she can later take revenge herself. She is the catalyst that transforms Homer from his comfortable but not entirely admirable position at the apple orchard to becoming Dr. Larch's replacement at the orphanage.


</doc>
<doc id="7818" url="https://en.wikipedia.org/wiki?curid=7818" title="Consumer">
Consumer

A consumer is a person or organization that uses economic services or commodities.

The consumer is the one who pays something to consume goods and services produced. As such, consumers play a vital role in the economic system of a nation. Without consumer demand, producers would lack one of the key motivations to produce: to sell to consumers. The consumer also forms part of the chain of distribution.

Recently in marketing instead of marketers generating broad demographic profiles and Fisio-graphic profiles of market segments, marketers have started to engage in personalized marketing, permission marketing, and mass customization.

Largely due to the rise of the Internet, consumers are shifting more and more towards becoming "prosumers", consumers who are also producers (often of information and media on the social web), influence the products created (e.g. by customization, crowdfunding or publishing their preferences), actively participate in the production process, or use interactive products.

The law primarily uses a notion of the consumer in relation to consumer protection laws, and the definition of consumer is often restricted to living persons (i.e. not corporations or businesses) and excludes commercial users. A typical legal rationale for protecting the consumer is based on the notion of policing market failures and inefficiencies, such as inequalities of bargaining power between a consumer and a business. As all potential voters are also consumers, consumer protection has a clear political significance.

Concern over the interests of consumers has spawned consumer activism, where organized activists do research, education and advocacy to improve the offer of products and services. Consumer education has been incorporated into some school curricula. There are also various non-profit publications, such as "Which?", "Consumer Reports" and "Choice Magazine", dedicated to assist in consumer education and decision making.

In India, the Consumer Protection Act 1986 differentiates the consummation of a commodity or service for personal use or to earn a livelihood. Only consumers are protected per this act and any person, entity or organization purchasing a commodity for commercial reasons are exempted from any benefits of this act.



</doc>
<doc id="7819" url="https://en.wikipedia.org/wiki?curid=7819" title="Cactus">
Cactus

A cactus (plural: "cacti", "cactuses", or "cactus") is a member of the plant family Cactaceae, a family comprising about 127 genera with some 1750 known species of the order Caryophyllales. The word "cactus" derives, through Latin, from the Ancient Greek , "kaktos", a name originally used by Theophrastus for a spiny plant whose identity is not certain. Cacti occur in a wide range of shapes and sizes. Most cacti live in habitats subject to at least some drought. Many live in extremely dry environments, even being found in the Atacama Desert, one of the driest places on earth. Cacti show many adaptations to conserve water. Almost all cacti are succulents, meaning they have thickened, fleshy parts adapted to store water. Unlike many other succulents, the stem is the only part of most cacti where this vital process takes place. Most species of cacti have lost true leaves, retaining only spines, which are highly modified leaves. As well as defending against herbivores, spines help prevent water loss by reducing air flow close to the cactus and providing some shade. In the absence of leaves, enlarged stems carry out photosynthesis. Cacti are native to the Americas, ranging from Patagonia in the south to parts of western Canada in the north—except for "Rhipsalis baccifera", which also grows in Africa and Sri Lanka.

Cactus spines are produced from specialized structures called areoles, a kind of highly reduced branch. Areoles are an identifying feature of cacti. As well as spines, areoles give rise to flowers, which are usually tubular and multipetaled. Many cacti have short growing seasons and long dormancies, and are able to react quickly to any rainfall, helped by an extensive but relatively shallow root system that quickly absorbs any water reaching the ground surface. Cactus stems are often ribbed or fluted, which allows them to expand and contract easily for quick water absorption after rain, followed by long drought periods. Like other succulent plants, most cacti employ a special mechanism called "crassulacean acid metabolism" (CAM) as part of photosynthesis. Transpiration, during which carbon dioxide enters the plant and water escapes, does not take place during the day at the same time as photosynthesis, but instead occurs at night. The plant stores the carbon dioxide it takes in as malic acid, retaining it until daylight returns, and only then using it in photosynthesis. Because transpiration takes place during the cooler, more humid night hours, water loss is significantly reduced.

Many smaller cacti have globe-shaped stems, combining the highest possible volume for water storage, with the lowest possible surface area for water loss from transpiration. The tallest free-standing cactus is "Pachycereus pringlei", with a maximum recorded height of , and the smallest is "Blossfeldia liliputiana", only about in diameter at maturity. A fully grown saguaro ("Carnegiea gigantea") is said to be able to absorb as much as of water during a rainstorm. A few species differ significantly in appearance from most of the family. At least superficially, plants of the genus "Pereskia" resemble other trees and shrubs growing around them. They have persistent leaves, and when older, bark-covered stems. Their areoles identify them as cacti, and in spite of their appearance, they, too, have many adaptations for water conservation. "Pereskia" is considered close to the ancestral species from which all cacti evolved. In tropical regions, other cacti grow as forest climbers and epiphytes (plants that grow on trees). Their stems are typically flattened, almost leaf-like in appearance, with fewer or even no spines, such as the well-known Christmas cactus or Thanksgiving cactus (in the genus "Schlumbergera").

Cacti have a variety of uses: many species are used as ornamental plants, others are grown for fodder or forage, and others for food (particularly their fruit). Cochineal is the product of an insect that lives on some cacti.

Many succulent plants in both the Old and New World, such as some Euphorbiaceae (euphorbias), bear a striking resemblance to cacti, and may incorrectly be called "cactus" in common usage.

The 1,500 to 1,800 species of cacti mostly fall into one of two groups of "core cacti": opuntias (subfamily Opuntioideae) and "cactoids" (subfamily Cactoideae). Most members of these two groups are easily recognizable as cacti. They have fleshy succulent stems that are major organs of photosynthesis. They have absent, small, or transient leaves. They have flowers with ovaries that lie below the sepals and petals, often deeply sunken into a fleshy receptacle (the part of the stem from which the flower parts grow). All cacti have areoles—highly specialized short shoots with extremely short internodes that produce spines, normal shoots, and flowers.

The remaining cacti fall into only two genera, "Pereskia" and "Maihuenia", and are rather different, which means any description of cacti as a whole must frequently make exceptions for them. "Pereskia" species superficially resemble other tropical forest trees. When mature, they have woody stems that may be covered with bark and long-lasting leaves that provide the main means of photosynthesis. Their flowers may have superior ovaries (i.e., above the points of attachment of the sepals and petals), and areoles that produce further leaves. The two species of "Maihuenia" have small, globe-shaped bodies with prominent leaves at the top.

Cacti show a wide variety of growth habits, which are difficult to divide into clear, simple categories. They can be tree-like (arborescent), meaning they typically have a single more-or-less woody trunk topped by several to many branches. In the genus "Pereskia", the branches are covered with leaves, so the species of this genus may not be recognized as cacti. In most other cacti, the branches are more typically cactus-like, bare of leaves and bark, and covered with spines, as in "Pachycereus pringlei" or the larger opuntias. Some cacti may become tree-sized but without branches, such as larger specimens of "Echinocactus platyacanthus". Cacti may also be described as shrubby, with several stems coming from the ground or from branches very low down, such as in "Stenocereus thurberi".

Smaller cacti may be described as columnar. They consist of erect, cylinder-shaped stems, which may or may not branch, without a very clear division into trunk and branches. The boundary between columnar forms and tree-like or shrubby forms is difficult to define. Smaller and younger specimens of "Cephalocereus senilis", for example, are columnar, whereas older and larger specimens may become tree-like. In some cases, the "columns" may be horizontal rather than vertical. Thus, "Stenocereus eruca" has stems growing along the ground, rooting at intervals.

Cacti whose stems are even smaller may be described as globular (or globose). They consist of shorter, more ball-shaped stems than columnar cacti. Globular cacti may be solitary, such as "Ferocactus latispinus", or their stems may form clusters that can create large mounds. All or some stems in a cluster may share a common root.

Other cacti have a quite different appearance. In tropical regions, some grow as forest climbers and epiphytes. Their stems are typically flattened, almost leaf-like in appearance, with fewer or even no spines. Climbing cacti can be very large; a specimen of "Hylocereus" was reported as long from root to the most distant stem. Epiphytic cacti, such as species of "Rhipsalis" or "Schlumbergera", often hang downwards, forming dense clumps where they grow in trees high above the ground.

The leafless, spiny stem is the characteristic feature of the majority of cacti (and all of those belonging to the largest subfamily, the Cactoideae). The stem is typically succulent, meaning it is adapted to store water. The surface of the stem may be smooth (as in some species of "Opuntia") or covered with protuberances of various kinds, which are usually called tubercles. These vary from small "bumps" to prominent, nipple-like shapes in the genus "Mammillaria" and outgrowths almost like leaves in "Ariocarpus" species. The stem may also be ribbed or fluted in shape. The prominence of these ribs depends on how much water the stem is storing: when full (up to 90% of the mass of a cactus may be water), the ribs may be almost invisible on the swollen stem, whereas when the cactus is short of water and the stems shrink, the ribs may be very visible.

The stems of most cacti are some shade of green, often bluish or brownish green. Such stems contain chlorophyll and are able to carry out photosynthesis; they also have stomata (small structures that can open and close to allow passage of gases). Cactus stems are often visibly waxy.

Areoles are structures unique to cacti. Although variable, they typically appear as woolly or hairy areas on the stems from which spines emerge. Flowers are also produced from areoles. In the genus "Pereskia", believed similar to the ancestor of all cacti, the areoles occur in the axils of leaves (i.e. in the angle between the leaf stalk and the stem). In leafless cacti, areoles are often borne on raised areas on the stem where leaf bases would have been.

Areoles are highly specialized and very condensed shoots or branches. In a normal shoot, nodes bearing leaves or flowers would be separated by lengths of stem (internodes). In an areole, the nodes are so close together, they form a single structure. The areole may be circular, elongated into an oval shape, or even separated into two parts; the two parts may be visibly connected in some way (e.g. by a groove in the stem) or appear entirely separate (a dimorphic areole). The part nearer the top of the stem then produces flowers, the other part spines. Areoles often have multicellular hairs (trichomes) that give the areole a hairy or woolly appearance, sometimes of a distinct color such as yellow or brown.

In most cacti, the areoles produce new spines or flowers only for a few years, and then become inactive. This results in a relatively fixed number of spines, with flowers being produced only from the ends of stems, which are still growing and forming new areoles. In "Pereskia", a genus close to the ancestor of cacti, areoles remain active for much longer; this is also the case in "Opuntia" and "Neoraimondia".

The great majority of cacti have no visible leaves; photosynthesis takes place in the stems (which may be flattened and leaflike in some species). Exceptions occur in three groups of cacti. All the species of "Pereskia" are superficially like normal trees or shrubs and have numerous leaves. Many cacti in the opuntia group (subfamily Opuntioideae, opuntioids) also have visible leaves, which may be long-lasting (as in "Pereskiopsis" species) or be produced only during the growing season and then be lost (as in many species of "Opuntia"). The small genus "Maihuenia" also relies on leaves for photosynthesis. The structure of the leaves varies somewhat between these groups. "Pereskia" species have "normal" leaves, with a midrib and a flattened blade (lamina) on either side. Opuntioids and "Maihuenia" have leaves that appear to consist only of a midrib.

Even those cacti without visible photosynthetic leaves do usually have very small leaves, less than long in about half of the species studied and almost always less than long. The function of such leaves cannot be photosynthesis; a role in the production of plant hormones, such as auxin, and in defining axillary buds has been suggested.

Botanically, "spines" are distinguished from "thorns": spines are modified leaves, and thorns are modified branches. Cacti produce spines, always from areoles as noted above. Spines are present even in those cacti with leaves, such as "Pereskia", "Pereskiopsis" and "Maihuenia", so they clearly evolved before complete leaflessness. Some cacti only have spines when young, possibly only when seedlings. This is particularly true of tree-living cacti, such as "Rhipsalis" or "Schlumbergera", but some ground-living cacti, such as "Ariocarpus", also lack spines when mature.

The spines of cacti are often useful in identification, since they vary greatly between species in number, color, size, shape and hardness, as well as in whether all the spines produced by an areole are similar or whether they are of distinct kinds. Most spines are straight or at most slightly curved, and are described as hair-like, bristle-like, needle-like or awl-like, depending on their length and thickness. Some cacti have flattened spines (e.g. "Schlerocactus papyracanthus"). Other cacti have hooked spines. Sometimes, one or more central spines are hooked, while outer spines are straight (e.g., "Mammillaria rekoi").

In addition to normal-length spines, members of the subfamily Opuntioideae have relatively short spines, called glochids, that are barbed along their length and easily shed. These enter the skin and are difficult to remove, causing long-lasting irritation.

Most ground-living cacti have only fine roots, which spread out around the base of the plant for varying distances, close to the surface. Some cacti have taproots; in genera such as "Copiapoa", these are considerably larger and of a greater volume than the body. Taproots may aid in stabilizing the larger columnar cacti. Climbing, creeping and epiphytic cacti may have only adventitious roots, produced along the stems where these come into contact with a rooting medium.

Like their spines, cactus flowers are variable. Typically, the ovary is surrounded by material derived from stem or receptacle tissue, forming a structure called a pericarpel. Tissue derived from the petals and sepals continues the pericarpel, forming a composite tube—the whole may be called a floral tube, although strictly speaking only the part furthest from the base is floral in origin. The outside of the tubular structure often has areoles that produce wool and spines. Typically, the tube also has small scale-like bracts, which gradually change into sepal-like and then petal-like structures, so the sepals and petals cannot be clearly differentiated (and hence are often called "tepals"). Some cacti produce floral tubes without wool or spines (e.g. "Gymnocalycium") or completely devoid of any external structures (e.g. "Mammillaria"). Unlike the flowers of other cacti, "Pereskia" flowers may be borne in clusters.

Cactus flowers usually have many stamens, but only a single style, which may branch at the end into more than one stigma. The stamens usually arise from all over the inner surface of the upper part of the floral tube, although in some cacti, the stamens are produced in one or more distinct "series" in more specific areas of the inside of the floral tube.

The flower as a whole is usually radially symmetrical (actinomorphic), but may be bilaterally symmetrical (zygomorphic) in some species. Flower colors range from white through yellow and red to magenta.

All cacti have some adaptations to promote efficient water use. Most cacti—opuntias and cactoids—specialize in surviving in hot and dry environments (i.e. they are xerophytes), but the first ancestors of modern cacti were already adapted to periods of intermittent drought. A small number of cactus species in the tribes Hylocereeae and Rhipsalideae have become adapted to life as climbers or epiphytes, often in tropical forests, where water conservation is less important.

The absence of visible leaves is one of the most striking features of most cacti. "Pereskia" (which is close to the ancestral species from which all cacti evolved) does have long-lasting leaves, which are, however, thickened and succulent in many species. Other species of cactus with long-lasting leaves, such as the opuntioid "Pereskiopsis", also have succulent leaves. A key issue in retaining water is the ratio of surface area to volume. Water loss is proportional to surface area, whereas the amount of water present is proportional to volume. Structures with a high surface area-to-volume ratio, such as thin leaves, necessarily lose water at a higher rate than structures with a low area-to-volume ratio, such as thickened stems.

Spines, which are modified leaves, are present on even those cacti with true leaves, showing the evolution of spines preceded the loss of leaves. Although spines have a high surface area-to-volume ratio, at maturity they contain little or no water, being composed of fibers made up of dead cells. Spines provide protection from herbivores and camouflage in some species, and assist in water conservation in several ways. They trap air near the surface of the cactus, creating a moister layer that reduces evaporation and transpiration. They can provide some shade, which lowers the temperature of the surface of the cactus, also reducing water loss. When sufficiently moist air is present, such as during fog or early morning mist, spines can condense moisture, which then drips onto the ground and is absorbed by the roots.

The majority of cacti are stem succulents, i.e., plants in which the stem is the main organ used to store water. Water may form up to 90% of the total mass of a cactus. Stem shapes vary considerably among cacti. The cylindrical shape of columnar cacti and the spherical shape of globular cacti produce a low surface area-to-volume ratio, thus reducing water loss, as well as minimizing the heating effects of sunlight. The ribbed or fluted stems of many cacti allow the stem to shrink during periods of drought and then swell as it fills with water during periods of availability. A mature saguaro ("Carnegiea gigantea") is said to be able to absorb as much as of water during a rainstorm. The outer layer of the stem usually has a tough cuticle, reinforced with waxy layers, which reduce water loss. These layers are responsible for the grayish or bluish tinge to the stem color of many cacti.

The stems of most cacti have adaptations to allow them to conduct photosynthesis in the absence of leaves. This is discussed further below under Metabolism.

Many cacti have roots that spread out widely, but only penetrate a short distance into the soil. In one case, a young saguaro only tall had a root system with a diameter of , but no more than deep. Cacti can also form new roots quickly when rain falls after a drought. The concentration of salts in the root cells of cacti is relatively high. All these adaptations enable cacti to absorb water rapidly during periods of brief or light rainfall. Thus, "Ferocactus cylindraceus" reportedly can take up a significant amount of water within 12 hours of as little as of rainfall, becoming fully hydrated in a few days.

Although in most cacti, the stem acts as the main organ for storing water, some cacti have in addition large taproots. These may be several times the length of the above-ground body in the case of species such as "Copiapoa atacamensis", which grows in one of the driest places in the world, the Atacama Desert in northern Chile.
Photosynthesis requires plants to take in carbon dioxide gas (). As they do so, they lose water through transpiration. Like other types of succulents, cacti reduce this water loss by the way in which they carry out photosynthesis. "Normal" leafy plants use the C mechanism: during daylight hours, is continually drawn out of the air present in spaces inside leaves and converted first into a compound containing three carbon atoms (3-phosphoglycerate) and then into products such as carbohydrates. The access of air to internal spaces within a plant is controlled by stomata, which are able to open and close. The need for a continuous supply of during photosynthesis means the stomata must be open, so water vapor is continuously being lost. Plants using the C mechanism lose as much as 97% of the water taken up through their roots in this way. A further problem is that as temperatures rise, the enzyme that captures starts to capture more and more oxygen instead, reducing the efficiency of photosynthesis by up to 25%.

Crassulacean acid metabolism (CAM) is a mechanism adopted by cacti and other succulents to avoid the problems of the C mechanism. In full CAM, the stomata open only at night, when temperatures and water loss are lowest. enters the plant and is captured in the form of organic acids stored inside cells (in vacuoles). The stomata remain closed throughout the day, and photosynthesis uses only this stored . CAM uses water much more efficiently at the price of limiting the amount of carbon fixed from the atmosphere and thus available for growth. CAM-cycling is a less efficient system whereby stomata open in the day, just as in plants using the C mechanism. At night, or when the plant is short of water, the stomata close and the CAM mechanism is used to store produced by respiration for use later in photosynthesis. CAM-cycling is present in "Pereskia" species.

By studying the ratio of C to C incorporated into a plant—its isotopic signature—it is possible to deduce how much is taken up at night and how much in the daytime. Using this approach, most of the "Pereskia" species investigated exhibit some degree of CAM-cycling, suggesting this ability was present in the ancestor of all cacti. "Pereskia" leaves are claimed to only have the C mechanism with CAM restricted to stems. More recent studies show that "it is highly unlikely that significant carbon assimilation occurs in the stem"; "Pereskia" species are described as having "C with inducible CAM." Leafless cacti carry out all their photosynthesis in the stem, using full CAM. , it is not clear whether stem-based CAM evolved once only in the core cacti, or separately in the opuntias and cactoids; CAM is known to have evolved convergently many times.

To carry out photosynthesis, cactus stems have undergone many adaptations. Early in their evolutionary history, the ancestors of modern cacti (other than one group of "Pereskia" species) developed stomata on their stems and began to delay developing bark. However, this alone was not sufficient; cacti with only these adaptations appear to do very little photosynthesis in their stems. Stems needed to develop structures similar to those normally found only in leaves. Immediately below the outer epidermis, a hypodermal layer developed made up of cells with thickened walls, offering mechanical support. Air spaces were needed between the cells to allow carbon dioxide to diffuse inwards. The center of the stem, the cortex, developed "chlorenchyma" – a plant tissue made up of relatively unspecialized cells containing chloroplasts, arranged into a "spongy layer" and a "palisade layer" where most of the photosynthesis occurs.

Naming and classifying cacti has been both difficult and controversial since the first cacti were discovered for science. The difficulties began with Carl Linnaeus. In 1737, he placed the cacti he knew into two genera, "Cactus" and "Pereskia". However, when he published "Species Plantarum" in 1753—the starting point for modern botanical nomenclature—he relegated them all to one genus, "Cactus". The word "cactus" is derived through Latin from the Ancient Greek ("kaktos"), a name used by Theophrastus for a spiny plant, which may have been the cardoon ("Cynara cardunculus").

Later botanists, such as Philip Miller in 1754, divided cacti into several genera, which, in 1789, Antoine Laurent de Jussieu placed in his newly created family Cactaceae. By the early 20th century, botanists came to feel Linnaeus's name "Cactus" had become so confused as to its meaning (was it the genus or the family?) that it should not be used as a genus name. The 1905 Vienna botanical congress rejected the name "Cactus" and instead declared "Mammillaria" was the type genus of the family Cactaceae. It did, however, conserve the name Cactaceae, leading to the unusual situation in which the family Cactaceae no longer contains the genus after which it was named.

The difficulties continued, partly because giving plants scientific names relies on "type specimens". Ultimately, if botanists want to know whether a particular plant is an example of, say, "Mammillaria mammillaris", they should be able to compare it with the type specimen to which this name is permanently attached. Type specimens are normally prepared by compression and drying, after which they are stored in herbaria to act as definitive references. However, cacti are very difficult to preserve in this way; they have evolved to resist drying and their bodies do not easily compress. A further difficulty is that many cacti were given names by growers and horticulturalists rather than botanists; as a result, the provisions of the "International Code of Nomenclature for algae, fungi, and plants" (which governs the names of cacti, as well as other plants) were often ignored. Curt Backeberg, in particular, is said to have named or renamed 1,200 species without one of his names ever being attached to a specimen, which, according to David Hunt, ensured he "left a trail of nomenclatural chaos that will probably vex cactus taxonomists for centuries."

In 1984, it was decided that the Cactaceae Section of the International Organization for Succulent Plant Study should set up a working party, now called the International Cactaceae Systematics Group (ICSG), to produce consensus classifications down to the level of genera. Their system has been used as the basis of subsequent classifications. Detailed treatments published in the 21st century have divided the family into around 125–130 genera and 1,400–1,500 species, which are then arranged into a number of tribes and subfamilies. The ICSG classification of the cactus family recognizes four subfamilies, the largest of which is divided into nine tribes. The subfamilies are:


Molecular phylogenetic studies have supported the monophyly of three of these subfamilies (not Pereskioideae), but have not supported all of the tribes or even genera below this level; indeed, a 2011 study found only 39% of the genera in the subfamily Cactoideae sampled in the research were monophyletic. Classification of the cacti currently remains uncertain and is likely to change.

A 2005 study suggested the genus "Pereskia" was basal within the Cactaceae, but confirmed earlier suggestions it was not monophyletic, i.e., did not include all the descendants of a common ancestor. The Bayesian consensus cladogram from this study is shown below.

A more recent 2011 study using fewer genes but more species also found that "Pereskia" was divided into these two clades, but was unable to resolve the members of the "core cacti" clade. It was accepted that the relationships shown above are "the most robust to date."

The two clades of "Pereskia" differ in their geographical distribution; with one exception, clade A is found around the Gulf of Mexico and the Caribbean Sea, whereas clade B occurs south of the Amazon Basin. Species of "Pereskia" within clade A always lack two key features of the stem present in most of the remaining "caulocacti": like most non-cacti, their stems begin to form bark early in the plants' life and also lack stomata—structures that control admission of air into a plant and hence control photosynthesis. By contrast, caulocacti, including species of "Pereskia" clade B, typically delay forming bark and have stomata on their stems, thus giving the stem the potential to become a major organ for photosynthesis. (The two highly specialized species of "Maihuenia" are something of an exception.)

The first cacti are thought to have been only slightly succulent shrubs or small trees whose leaves carried out photosynthesis. They lived in tropical areas that experienced periodic drought. If "Pereskia" clade A is a good model of these early cacti, then, although they would have appeared superficially similar to other trees growing nearby, they had already evolved strategies to conserve water (some of which are present in members of other families in the order Caryophyllales). These strategies included being able to respond rapidly to periods of rain, and keeping transpiration low by using water very efficiently during photosynthesis. The latter was achieved by tightly controlling the opening of stomata. Like "Pereskia" species today, early ancestors may have been able to switch from the normal C mechanism, where carbon dioxide is used continuously in photosynthesis, to CAM cycling, in which when the stomata are closed, carbon dioxide produced by respiration is stored for later use in photosynthesis.

"Pereskia" clade B marks the beginnings of an evolutionary switch to using stems as photosynthetic organs. Stems have stomata and the formation of bark takes place later than in normal trees. The "core cacti" show a steady increase in both stem succulence and photosynthesis accompanied by multiple losses of leaves, more-or-less complete in the Cactoideae. One evolutionary question at present unanswered is whether the switch to full CAM photosynthesis in stems occurred only once in the core cacti, in which case it has been lost in "Maihuenia", or separately in Opuntioideae and Cactoideae, in which case it never evolved in "Maihuenia".

Understanding evolution within the core cacti clade is difficult , since phylogenetic relationships are still uncertain and not well related to current classifications. Thus, a 2011 study found "an extraordinarily high proportion of genera" were not monophyletic, so were not all descendants of a single common ancestor. For example, of the 36 genera in the subfamily Cactoideae sampled in the research, 22 (61%) were found not monophyletic. Nine tribes are recognized within Cactoideae in the International Cactaceae Systematics Group (ICSG) classification; one, Calymmantheae, comprises a single genus, "Calymmanthium". Only two of the remaining eight, Cacteae and Rhipsalideae, were shown to be monophyletic in a 2011 study by Hernández-Hernández et al. For a more detailed discussion of the phylogeny of the cacti, see Classification of the Cactaceae.

No known fossils of cacti exist to throw light on their evolutionary history. However, the geographical distribution of cacti offers some evidence. Except for a relatively recent spread of "Rhipsalis baccifera" to parts of the Old World, cacti are plants of South America and mainly southern regions of North America. This suggests the family must have evolved after the ancient continent of Gondwana split into South America and Africa, which occurred during the Early Cretaceous, around . Precisely when after this split cacti evolved is less clear. Older sources suggest an early origin around 90 – 66 million years ago, during the Late Cretaceous. More recent molecular studies suggest a much younger origin, perhaps in very Late Eocene to early Oligocene periods, around 35–30 million years ago. Based on the phylogeny of the cacti, the earliest diverging group ("Pereskia" clade A) may have originated in Central America and northern South America, whereas the caulocacti, those with more-or-less succulent stems, evolved later in the southern part of South America, and then moved northwards. Core cacti, those with strongly succulent stems, are estimated to have evolved around 25 million years ago. A possible stimulus to their evolution may have been uplifting in the central Andes, some 25–20 million years ago, which was associated with increasing and varying aridity. However, the current species diversity of cacti is thought to have arisen only in the last 10–5 million years (from the late Miocene into the Pliocene). Other succulent plants, such as the Aizoaceae in South Africa, the Didiereaceae in Madagascar and the genus "Agave" in the Americas, appear to have diversified at the same time, which coincided with a global expansion of arid environments.

Cacti inhabit diverse regions, from coastal plains to high mountain areas. With one exception, they are native to the Americas, where their range extends from Patagonia to British Columbia and Alberta in western Canada. A number of centers of diversity exist. For cacti adapted to drought, the three main centers are Mexico and the southwestern United States; the southwestern Andes, where they are found in Peru, Bolivia, Chile and Argentina; and eastern Brazil, away from the Amazon Basin. Tree-living epiphytic and climbing cacti necessarily have different centers of diversity, as they require moister environments. They are mainly found in the coastal mountains and Atlantic forests of southeastern Brazil; in Bolivia, which is the center of diversity for the subfamily Rhipsalideae; and in forested regions of Central America, where the climbing Hylocereeae are most diverse.

"Rhipsalis baccifera" is the exception; it is native to both the Americas and the Old World, where it is found in tropical Africa, Madagascar, and Sri Lanka. One theory is it was spread by being carried as seeds in the digestive tracts of migratory birds; the seeds of "Rhipsalis" are adapted for bird distribution. Old World populations are polyploid, and regarded as distinct subspecies, supporting the idea that the spread was not recent. The alternative theory is the species initially crossed the Atlantic on European ships trading between South America and Africa, after which birds may have spread it more widely.

Many other species have become naturalized outside the Americas after having been introduced by people, especially in Australia, Hawaii, and the Mediterranean region. In Australia, species of "Opuntia", particularly "Opuntia stricta", were introduced in the 19th century for use as natural agricultural fences and in an attempt to establish a cochineal industry. They rapidly became a major weed problem, but are now controlled by biological agents, particularly the moth "Cactoblastis cactorum". The weed potential of Opuntia species in Australia continues however, leading to all opuntioid cacti except "O. ficus-indica" being declared Weeds of National Significance by the Australian Weeds Committee in April 2012.

Cactus flowers are pollinated by insects, birds and bats. None are known to be wind-pollinated and self-pollination occurs in only a very few species; for example the flowers of some species of "Frailea" do not open (cleistogamy). The need to attract pollinators has led to the evolution of pollination syndromes, which are defined as groups of "floral traits, including rewards, associated with the attraction and utilization of a specific group of animals as pollinators."

Bees are the most common pollinators of cacti; bee-pollination is considered to have been the first to evolve. Day-flying butterflies and nocturnal moths are associated with different pollination syndromes. Butterfly-pollinated flowers are usually brightly colored, opening during the day, whereas moth-pollinated flowers are often white or pale in color, opening only in the evening and at night. As an example, "Pachycereus schottii" is pollinated by a particular species of moth, "Upiga virescens", which also lays its eggs among the developing seeds its caterpillars later consume. The flowers of this cactus are funnel-shaped, white to deep pink, up to long, and open at night.

Hummingbirds are significant pollinators of cacti. Species showing the typical hummingbird-pollination syndrome have flowers with colors towards the red end of the spectrum, anthers and stamens that protrude from the flower, and a shape that is not radially symmetrical, with a lower lip that bends downwards; they produce large amounts of nectar with a relatively low sugar content. "Schlumbergera" species, such as "S. truncata", have flowers that correspond closely to this syndrome. Other hummingbird-pollinated genera include "Cleistocactus" and "Disocactus".

Bat-pollination is relatively uncommon in flowering plants, but about a quarter of the genera of cacti are known to be pollinated by bats—an unusually high proportion, exceeded among eudicots by only two other families, both with very few genera. Columnar cacti growing in semidesert areas are among those most likely to be bat-pollinated; this may be because bats are able to travel considerable distances, so are effective pollinators of plants growing widely separated from one another. The pollination syndrome associated with bats includes a tendency for flowers to open in the evening and at night, when bats are active. Other features include a relatively dull color, often white or green; a radially symmetrical shape, often tubular; a smell described as "musty"; and the production of a large amount of sugar-rich nectar. "Carnegiea gigantea" is an example of a bat-pollinated cactus, as are many species of "Pachycereus" and "Pilosocereus".

The fruits produced by cacti after the flowers have been fertilized vary considerably; many are fleshy, although some are dry. All contain a large number of seeds. Fleshy, colorful and sweet-tasting fruits are associated with seed dispersal by birds. The seeds pass through their digestive systems and are deposited in their droppings. Fruit that falls to the ground may be eaten by other animals; giant tortoises are reported to distribute "Opuntia" seeds in the Galápagos Islands. Ants appear to disperse the seeds of a few genera, such as "Blossfeldia". Drier spiny fruits may cling to the fur of mammals or be moved around by the wind.

, there is still controversy as to the precise dates when humans first entered those areas of the New World where cacti are commonly found, and hence when they might first have used them. An archaeological site in Chile has been dated to around 15,000 years ago, suggesting cacti would have been encountered before then. Early evidence of the use of cacti includes cave paintings in the Serra da Capivara in Brazil, and seeds found in ancient middens (waste dumps) in Mexico and Peru, with dates estimated at 12,000–9,000 years ago. Hunter-gatherers likely collected cactus fruits in the wild and brought them back to their camps.

It is not known when cacti were first cultivated. Opuntias (prickly pears) were used for a variety of purposes by the Aztecs, whose empire, lasting from the 14th to the 16th century, had a complex system of horticulture. Their capital from the 15th century was Tenochtitlan (now Mexico City); one explanation for the origin of the name is that it includes the Nahuatl word "nōchtli", referring to the fruit of an opuntia. The coat of arms of Mexico shows an eagle perched on a cactus while holding a snake, an image at the center of the myth of the founding of Tenochtitlan. The Aztecs symbolically linked the ripe red fruits of an opuntia to human hearts; just as the fruit quenches thirst, so offering human hearts to the sun god ensured the sun would keep moving.

Europeans first encountered cacti when they arrived in the New World late in the 15th century. Their first landfalls were in the West Indies, where relatively few cactus genera are found; one of the most common is the genus "Melocactus". Thus, melocacti were possibly among the first cacti seen by Europeans. "Melocactus" species were present in English collections of cacti before the end of the 16th century (by 1570 according to one source,) where they were called "Echinomelocactus", later shortened to "Melocactus" by Joseph Pitton de Tourneville in the early 18th century. Cacti, both purely ornamental species and those with edible fruit, continued to arrive in Europe, so Carl Linnaeus was able to name 22 species by 1753. One of these, his "Cactus opuntia" (now part of "Opuntia ficus-indica"), was described as """" (with larger fruit ... now in Spain and Portugal), indicative of its early use in Europe.

The plant now known as "Opuntia ficus-indica", or the Indian fig cactus, has long been an important source of food. The original species is thought to have come from central Mexico, although this is now obscure because the indigenous people of southern North America developed and distributed a range of horticultural varieties (cultivars), including forms of the species and hybrids with other opuntias. Both the fruit and pads are eaten, the former often under the Spanish name "tuna", the latter under the name "nopal". Cultivated forms are often significantly less spiny or even spineless. The nopal industry in Mexico was said to be worth US$150 million in 2007. The Indian fig cactus was probably already present in the Caribbean when the Spanish arrived, and was soon after brought to Europe. It spread rapidly in the Mediterranean area, both naturally and by being introduced—so much so, early botanists assumed it was native to the area. Outside the Americas, the Indian fig cactus is an important commercial crop in Sicily, Algeria and other North African countries. Fruits of other opuntias are also eaten, generally under the same name, "tuna". Flower buds, particularly of "Cylindropuntia" species, are also consumed.

Almost any fleshy cactus fruit is edible. The word "pitaya" or "pitahaya" (usually considered to have been taken into Spanish from Haitian creole) can be applied to a range of "scaly fruit", particularly those of columnar cacti. The fruit of the saguaro ("Carnegiea gigantea") has long been important to the indigenous peoples of northwestern Mexico and the southwestern United States, including the Sonoran Desert. It can be preserved by boiling to produce syrup and by drying. The syrup can also be fermented to produce an alcoholic drink. Fruits of "Stenocereus" species have also been important food sources in similar parts of North America; "Stenocereus queretaroensis" is cultivated for its fruit. In more tropical southern areas, the climber "Hylocereus undatus" provides "pitahaya orejona", now widely grown in Asia under the name dragon fruit. Other cacti providing edible fruit include species of "Echinocereus", "Ferocactus", "Mammillaria", "Myrtillocactus", "Pachycereus", "Peniocereus" and "Selenicereus". The bodies of cacti other than opuntias are less often eaten, although Anderson reported that "Neowerdermannia vorwerkii" is prepared and eaten like potatoes in upland Bolivia.

A number of species of cacti have been shown to contain psychoactive agents, chemical compounds that can cause changes in mood, perception and cognition through their effects on the brain. Two species have a long history of use by the indigenous peoples of the Americas: peyote, "Lophophora williamsii", in North America, and the San Pedro cactus, "Echinopsis pachanoi", in South America. Both contain mescaline.

"L. williamsii" is native to northern Mexico and southern Texas. Individual stems are about high with a diameter of , and may be found in clumps up to wide. A large part of the stem is usually below ground. Mescaline is concentrated in the photosynthetic portion of the stem above ground. The center of the stem, which contains the growing point (the apical meristem), is sunken. Experienced collectors of peyote remove a thin slice from the top of the plant, leaving the growing point intact, thus allowing the plant to regenerate. Evidence indicates peyote was in use more than 5,500 years ago; dried peyote buttons presumed to be from a site on the Rio Grande, Texas, were radiocarbon dated to around 3780–3660 BC. Peyote is perceived as a means of accessing the spirit world. Attempts by the Roman Catholic church to suppress its use after the Spanish conquest were largely unsuccessful, and by the middle of the 20th century, peyote was more widely used than ever by indigenous peoples as far north as Canada. It is now used formally by the Native American Church.

"Echinopsis pachanoi" is native to Ecuador and Peru. It is very different in appearance from "L. williamsii". It has tall stems, up to high, with a diameter of , which branch from the base, giving the whole plant a shrubby or tree-like appearance. Archaeological evidence of the use of this cactus appears to date back to 2,000–2,300 years ago, with carvings and ceramic objects showing columnar cacti. Although church authorities under the Spanish attempted to suppress its use, this failed, as shown by the Christian element in the common name "San Pedro cactus"—Saint Peter cactus. Anderson attributes the name to the belief that just as St Peter holds the keys to heaven, the effects of the cactus allow users "to reach heaven while still on earth." It continues to be used for its psychoactive effects, both for spiritual and for healing purposes, often combined with other psychoactive agents, such as "Datura ferox" and tobacco. Several other species of "Echinopsis", including "E. peruviana", also contain mescaline.

Cacti were cultivated as ornamental plants from the time they were first brought from the New World. By the early 1800s, enthusiasts in Europe had large collections (often including other succulents alongside cacti). Rare plants were sold for very high prices. Suppliers of cacti and other succulents employed collectors to obtain plants from the wild, in addition to growing their own. In the late 1800s, collectors turned to orchids, and cacti became less popular, although never disappearing from cultivation.

Cacti are often grown in greenhouses, particularly in regions unsuited to the cultivation of cacti outdoors, such the northern parts of Europe and North America. Here, they may be kept in pots or grown in the ground. Cacti are also grown as houseplants, many being tolerant of the often dry atmosphere. Cacti in pots may be placed outside in the summer to ornament gardens or patios, and then kept under cover during the winter. Less drought-resistant epiphytes, such as epiphyllum hybrids, "Schlumbergera" (the Thanksgiving or Christmas cactus) and "Hatiora" (the Easter cactus), are widely cultivated as houseplants.

Cacti may also be planted outdoors in regions with suitable climates. Concern for water conservation in arid regions has led to the promotion of gardens requiring less watering (xeriscaping). For example, in California, the East Bay Municipal Utility District sponsored the publication of a book on plants and landscapes for summer-dry climates. Cacti are one group of drought-resistant plants recommended for dry landscape gardening.

Cacti have many other uses. They are used for human food and as fodder for animals, usually after burning off their spines. In addition to their use as psychoactive agents, some cacti are employed in herbal medicine. The practice of using various species of "Opuntia" in this way has spread from the Americas, where they naturally occur, to other regions where they grow, such as India.

Cochineal is a red dye produced by a scale insect that lives on species of "Opuntia". Long used by the peoples of Central and North America, demand fell rapidly when European manufacturers began to produce synthetic dyes in the middle of the 19th century. Commercial production has now increased following a rise in demand for natural dyes.

Cacti are used as construction materials. Living cactus fences are employed as barricades. The woody parts of cacti, such as "Cereus repandus" and "Echinopsis atacamensis", are used in buildings and in furniture. The frames of wattle and daub houses built by the Seri people of Mexico may use parts of "Carnegiea gigantea". The very fine spines and hairs (trichomes) of some cacti were used as a source of fiber for filling pillows and in weaving.

All cacti are included in Appendix II of the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES), which "lists species that are not necessarily now threatened with extinction but that may become so unless trade is closely controlled." Control is exercised by making international trade in most specimens of cacti illegal unless permits have been issued, at least for exports. Some exceptions are allowed, e.g., for "naturalized or artificially propagated plants". Some cacti, such as all "Ariocarpus" and "Discocactus" species, are included in the more restrictive Appendix I, used for the "most endangered" species. These may only be moved between countries for scientific purposes, and only then when accompanied by both export and import permits.

The three main threats to cacti in the wild are development, grazing and over-collection. Development takes many forms. The construction of a dam near Zimapan, Mexico, caused the destruction of a large part of the natural habitat of "Echinocactus grusonii". Urban development and highways have destroyed cactus habitats in parts of Mexico, New Mexico and Arizona, including the Sonoran Desert. The conversion of land to agriculture has affected populations of "Ariocarpus kotschoubeyanus" in Mexico, where dry plains were plowed for maize cultivation, and of "Copiapoa" and "Eulychnia" in Chile, where valley slopes were planted with vines. Grazing, in many areas by introduced animals, such as goats, has caused serious damage to populations of cacti (as well as other plants); two examples cited by Anderson are the Galápagos Islands generally and the effect on "Browningia candelaris" in Peru. Over-collection of cacti for sale has greatly affected some species. For example, the type locality of "Pelecyphora strobiliformis" near Miquihuana, Mexico, was virtually denuded of plants, which were dug up for sale in Europe. Illegal collecting of cacti from the wild continues to pose a threat.

Conservation of cacti can be "in situ" or "ex situ". "In situ" conservation involves preserving habits through enforcement of legal protection and the creation of specially protected areas such as national parks and reserves. Examples of such protected areas in the United States include Big Bend National Park, Texas; Joshua Tree National Park, California; and Saguaro National Park, Arizona. Latin American examples include Parque Nacional del Pinacate, Sonora, Mexico and Pan de Azúcar National Park, Chile. "Ex situ" conservation aims to preserve plants and seeds outside their natural habitats, often with the intention of later reintroduction. Botanical gardens play an important role in "ex situ" conservation; for example, seeds of cacti and other succulents are kept in long-term storage at the Desert Botanical Garden, Arizona.

The popularity of cacti means many books are devoted to their cultivation. Cacti naturally occur in a wide range of habitats and are then grown in many countries with different climates, so precisely replicating the conditions in which a species normally grows is usually not practical. A broad distinction can be made between semidesert cacti and epiphytic cacti, which need different conditions and are best grown separately. This section is primarily concerned with the cultivation of semidesert cacti in containers and under protection, such as in a greenhouse or in the home, rather than cultivation outside in the ground in those climates that permit it. For the cultivation of epiphytic cacti, see Cultivation of "Schlumbergera" (Christmas or Thanksgiving cacti), and Cultivation of epiphyllum hybrids.

The purpose of the growing medium is to provide support and to store water, oxygen and dissolved minerals to feed the plant. In the case of cacti, there is general agreement that an open medium with a high air content is important. When cacti are grown in containers, recommendations as to how this should be achieved vary greatly; Miles Anderson says that if asked to describe a perfect growing medium, "ten growers would give 20 different answers". Roger Brown suggests a mixture of two parts commercial soilless growing medium, one part hydroponic clay and one part coarse pumice or perlite, with the addition of soil from earthworm castings. The general recommendation of 25–75% organic-based material, the rest being inorganic such as pumice, perlite or grit, is supported by other sources. However, the use of organic material is rejected altogether by others; Hecht says that cacti (other than epiphytes) "want soil that is low in or free of humus", and recommends coarse sand as the basis of a growing medium.

Semi-desert cacti need careful watering. General advice is hard to give, since the frequency of watering required depends on where the cacti are being grown, the nature of the growing medium, and the original habitat of the cacti. Brown says that more cacti are lost through the "untimely application of water than for any other reason" and that even during the dormant winter season, cacti need some water. Other sources say that water can be withheld during winter (November to March in the Northern Hemisphere). Another issue is the hardness of the water; where it is necessary to use hard water, regular re-potting is recommended to avoid the build up of salts. The general advice given is that during the growing season, cacti should be allowed to dry out between thorough waterings. A water meter can help in determining when the soil is dry.

Although semi-desert cacti may be exposed to high light levels in the wild, they may still need some shading when subjected to the higher light levels and temperatures of a greenhouse in summer. Allowing the temperature to rise above is not recommended. The minimum winter temperature required depends very much on the species of cactus involved. For a mixed collection, a minimum temperature of between and is often suggested, except for cold-sensitive genera such as "Melocactus" and "Discocactus". Some cacti, particularly those from the high Andes, are fully frost-hardy when kept dry (e.g. "Rebutia minuscula" survives temperatures down to in cultivation) and may flower better when exposed to a period of cold.

Cacti can be propagated by seed, cuttings or grafting. Seed sown early in the year produces seedlings that benefit from a longer growing period. Seed is sown in a moist growing medium and then kept in a covered environment, until 7–10 days after germination, to avoid drying out. A very wet growing medium can cause both seeds and seedlings to rot. A temperature range of is suggested for germination; soil temperatures of around promote the best root growth. Low light levels are sufficient during germination, but afterwards semi-desert cacti need higher light levels to produce strong growth, although acclimatization is needed to conditions in a greenhouse, such as higher temperatures and strong sunlight.

Reproduction by cuttings makes use of parts of a plant that can grow roots. Some cacti produce "pads" or "joints" that can be detached or cleanly cut off. Other cacti produce offsets that can be removed. Otherwise, stem cuttings can be made, ideally from relatively new growth. It is recommended that any cut surfaces be allowed to dry for a period of several days to several weeks until a callus forms over the cut surface. Rooting can then take place in an appropriate growing medium at a temperature of around .

Grafting is used for species difficult to grow well in cultivation or that cannot grow independently, such as some chlorophyll-free forms with white, yellow or red bodies, or some forms that show abnormal growth (e.g., cristate or monstrose forms). For the host plant—the "stock"—growers choose one that grows strongly in cultivation and is compatible with the plant to be propagated—the "scion." The grower makes cuts on both stock and scion and joins the two, binding them together while they unite. Various kinds of graft are used—flat grafts, where both scion and stock are of similar diameters, and cleft grafts, where a smaller scion is inserted into a cleft made in the stock.

Commercially, huge numbers of cacti are produced annually. For example, in 2002 in Korea alone, 49 million plants were propagated, with a value of almost US$9 million. Most of them, 31 million plants, were propagated by grafting.

A range of pests attack cacti in cultivation. Those that feed on sap include: mealybugs, living on both stems and roots; scale insects, generally only found on stems; whiteflies, which are said to be an "infrequent" pest of cacti; red spider mites, which are very small but can occur in large numbers, constructing a fine web around themselves and badly marking the cactus via their sap sucking, even if they do not kill it; and thrips, which particularly attack flowers. Some of these pests are resistant to many insecticides, although there are biological controls available. Roots of cacti can be eaten by the larvae of sciarid flies and fungus gnats. Slugs and snails also eat cacti.

Fungi, bacteria and viruses attack cacti, the first two particularly when plants are over-watered. Fusarium rot can gain entry through a wound and cause rotting accompanied by red-violet mold. "Helminosporium rot" is caused by "Bipolaris cactivora" (syn. "Helminosporium cactivorum"); "Phytophthora" species also cause similar rotting in cacti. Fungicides may be of limited value in combating these diseases. Several viruses have been found in cacti, including cactus virus X. These appear to cause only limited visible symptoms, such as chlorotic (pale green) spots and mosaic effects (streaks and patches of paler color). However, in an "Agave" species, cactus virus X has been shown to reduce growth, particularly when the roots are dry. There are no treatments for virus diseases.




</doc>
<doc id="7820" url="https://en.wikipedia.org/wiki?curid=7820" title="CCC">
CCC

CCC may refer to:



















</doc>
<doc id="7821" url="https://en.wikipedia.org/wiki?curid=7821" title="Civilian Conservation Corps">
Civilian Conservation Corps

The Civilian Conservation Corps (CCC) was a public work relief program that operated from 1933 to 1942 in the United States for unemployed, unmarried men. Originally for young men ages 18–25, it was eventually expanded to ages 17–28. Robert Fechner was the first director of the agency, succeeded by James McEntee following Fechner's death. The CCC was a major part of President Franklin D. Roosevelt's New Deal that provided unskilled manual labor jobs related to the conservation and development of natural resources in rural lands owned by federal, state, and local governments. The CCC was designed to provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States. Maximum enrollment at any one time was 300,000. Through the course of its nine years in operation, 3 million young men participated in the CCC, which provided them with shelter, clothing, and food, together with a wage of $30 (about $570 in 2017) per month ($25 of which had to be sent home to their families).

The American public made the CCC the most popular of all the New Deal programs. Sources written at the time claimed an individual's enrollment in the CCC led to improved physical condition, heightened morale, and increased employability. The CCC also led to a greater public awareness and appreciation of the outdoors and the nation's natural resources, and the continued need for a carefully planned, comprehensive national program for the protection and development of natural resources.

Enrollees of the CCC planted nearly 3 billion trees to help reforest America; constructed trails, lodges, and related facilities in more than 800 parks nationwide; and upgraded most state parks, updated forest fire fighting methods, and built a network of service buildings and public roadways in remote areas.

The CCC operated separate programs for veterans and Native Americans. Approximately 15,000 Native Americans participated in the program, helping them weather the Great Depression.

Despite its popular support, the CCC was not a permanent agency. It depended on emergency and temporary Congressional legislation and funding to operate. By 1942, with World War II and the draft in operation, the need for work relief declined, and Congress voted to close the program.

As governor of New York, Franklin Delano Roosevelt had run a similar program on a much smaller scale. Long interested in conservation, as president, he proposed to Congress a full-scale national program on March 21, 1933:
He promised this law would provide 250,000 young men with meals, housing, workwear, and medical care for working in the national forests and other government properties. The Emergency Conservation Work (ECW) Act was introduced to Congress the same day and enacted by voice vote on March 31. Roosevelt issued Executive Order 6101 on April 5, 1933, which established the CCC organization and appointed a director, Robert Fechner, a former labor union official who served until 1939. The organization and administration of the CAC was a new experiment in operations for a federal government agency. The order indicated that the program was to be supervised jointly by four government departments: Labor, which recruited the young men, War, which operated the camps, and Agriculture and Interior, which organized and supervised the work projects. A CAC Advisory Council was composed of a representative from each of the supervising departments. In addition, the Office of Education and Veterans Administration participated in the program. To end the opposition from labor unions (which wanted no training programs started when so many of their men were unemployed) Roosevelt chose Robert Fechner, vice president of the American Machinists Union, as director of the corps. William Green, head of the American Federation of Labor, was taken to the first camp to demonstrate that there would be no job training involved beyond simple manual labor.

Reserve officers from the U.S. Army were in charge of the camps, but there was no military training. General Douglas MacArthur was placed in charge of the program but said that the number of Army officers and soldiers assigned to the camps was affecting the readiness of the Regular Army. But the Army also found numerous benefits in the program. When the draft began in 1940, the policy was to make CCC alumni corporals and sergeants. CCC also provided command experience to Organized Reserve Corps officers. Through the CCC, the Regular Army could assess the leadership performance of both Regular and Reserve Officers. The CCC provided lessons which the Army used in developing its wartime and mobilization plans for training camps.

The legislation and mobilization of the program occurred quite rapidly. Roosevelt made his request to Congress on March 21, 1933; the legislation was submitted to Congress the same day; Congress passed it by voice vote on March 31; Roosevelt signed it the same day, then issued an executive order on April 5 creating the agency, appointing its director (Fechner), and assigning War Department corps area commanders to begin enrollment. The first CCC enrollee was selected April 8, and subsequent lists of unemployed men were supplied by state and local welfare and relief agencies for immediate enrollment. On April 17, the first camp, NF-1, Camp Roosevelt, was established at George Washington National Forest near Luray, Virginia. On June 18, the first of 161 soil erosion control camps was opened, in Clayton, Alabama. By July 1, 1933 there were 1,463 working camps with 250,000 junior enrollees (18–25 years of age); 28,000 veterans; 14,000 American Indians; and 25,000 Locally Enrolled (or Experienced) Men (LEM).

The typical CCC enrollee was a U.S. citizen, unmarried, unemployed male, 18–25 years of age. Normally his family was on local relief. Each enrollee volunteered and, upon passing a physical exam and/or a period of conditioning, was required to serve a minimum six-month period, with the option to serve as many as four periods, or up to two years, if employment outside the Corps was not possible. Enrollees worked 40 hours per week over five days, sometimes including Saturdays if poor weather dictated. In return they received $30 per month with a compulsory allotment of $22–25 sent to a family dependent, as well as food, clothing, and medical care.

Following the second Bonus Army march on Washington D.C., President Roosevelt amended the CCC program on May 11, 1933, to include work opportunities for veterans. Veteran qualifications differed from the junior enrollee; one needed to be certified by the Veterans Administration by an application. They could be any age, and married or single as long as they were in need of work. Veterans were generally assigned to entire veteran camps. Enrollees were eligible for the following "rated" positions to help with camp administration: senior leader, mess steward, storekeeper and two cooks; assistant leader, company clerk, assistant educational advisor and three second cooks. These men received additional pay ranging from $36 to $45 per month depending on their rating.

Each CCC camp was located in the area of particular conservation work to be performed and organized around a complement of up to 200 civilian enrollees in a designated numbered "company" unit. The CCC camp was a temporary community in itself, structured to have barracks (initially Army tents) for 50 enrollees each, officer/technical staff quarters, medical dispensary, mess hall, recreation hall, educational building, lavatory and showers, technical/administrative offices, tool room/blacksmith shop and motor pool garages.

The company organization of each camp had a dual-authority supervisory staff: firstly, Department of War personnel or Reserve officers (until July 1, 1939), a "company commander" and junior officer, who were responsible for overall camp operation, logistics, education and training; and secondly, ten to fourteen technical service civilians, including a camp "superintendent" and "foreman", employed by either the Departments of Interior or Agriculture, responsible for the particular fieldwork. Also included in camp operation were several non-technical supervisor LEMs, who provided knowledge of the work at hand, "lay of the land," and paternal guidance for inexperienced enrollees. Enrollees were organized into work detail units called "sections" of 25 men each, according to the barracks they resided in. Each section had an enrollee " senior leader" and "assistant leader" who were accountable for the men at work and in the barracks.

The CCC performed 300 types of work projects within ten approved general classifications:

The responses to this seven-month experimental conservation program were enthusiastic. On October 1, 1933, Director Fechner was directed to arrange for the second period of enrollment. By January 1934, 300,000 men were enrolled. In July 1934, this cap was increased by 50,000 to include men from Midwest states that had been affected by drought. The temporary tent camps had also developed to include wooden barracks. An education program had been established, emphasizing job training and literacy.

Approximately 55% of enrollees were from rural communities, a majority of which were non-farm; 45% came from urban areas. Level of education for the enrollee averaged 3% illiterate; 38% had less than eight years of school; 48% did not complete high school; and 11% were high school graduates. At the time of entry, 70% of enrollees were malnourished and poorly clothed. Few had work experience beyond occasional odd jobs. Peace was maintained by the threat of "dishonorable discharge". "This is a training station; we're going to leave morally and physically fit to lick 'Old Man Depression,'" boasted the newsletter, "Happy Days," of a North Carolina camp.

Because of the power of the Solid South white Democrats in Congress, who insisted on racial segregation, the New Deal programs were racially segregated; blacks and whites rarely worked alongside each other. At this time, all the states of the South had passed legislation imposing racial segregation and, since the turn of the century, laws and constitutional provisions that disenfranchised most blacks; they were excluded from formal politics. Because of discrimination by white officials at the local and state levels, blacks in the South did not receive as many benefits as whites from New Deal programs.

In the first few weeks of operation, CCC camps in the North were integrated. By July 1935, however, all the camps in the United States were segregated.

A total of 200,000 blacks were enrolled in the CCC; they served in 143 all-black camps and received equal pay and housing. Black leaders lobbied to secure leadership roles. Adult white men held the major leadership roles in all the camps. Director Fechner refused to appoint black adults to any supervisory positions except that of education director in the all-black camps.

The CCC operated a separate division for members of federally recognized tribes: the "Indian Emergency Conservation Work" (IECW or CCC-ID). Native men from reservations worked on roads, bridges, clinics, shelters, and other public works near their reservations. Although they were organized as groups classified as camps, no permanent camps were established for Native Americans. Instead, organized groups moved with their families from project to project and were provided with an additional rental allowance in their pay. The CCC often provided the only paid work, as many reservations were in remote rural areas. Enrollees had to be between the ages of 17 and 35.

During 1933, about half the male heads of households on the Sioux reservations in South Dakota were employed by the CCC-ID. With grants from the Public Works Administration (PWA), the Indian Division built schools and conducted an extensive road-building program in and around many reservations to improve infrastructure. The mission was to reduce erosion and improve the value of Indian lands. Crews built dams of many types on creeks, then sowed grass on the eroded areas from which the damming materials had been taken. They built roads and planted shelter-belts on federal lands. The steady income helped participants regain self-respect, and many used the funds to improve their lives. John Collier, the federal Commissioner of Indian Affairs and Daniel Murphy, the director of the CCC-ID, both based the program on Indian self-rule and the restoration of tribal lands, governments, and cultures. The next year, Congress passed the Indian Reorganization Act of 1934, which ended allotments and helped preserve tribal lands, and encouraged tribes to re-establish self-government.

Collier said of the CCC-Indian Division, "no previous undertaking in Indian Service has so largely been the Indians' own undertaking". Education programs also trained participants in gardening, stock raising, safety, native arts, and some academic subjects. IECW differed from other CCC activities in that it explicitly trained men in skills to be carpenters, truck drivers, radio operators, mechanics, surveyors, and technicians. With the passage of the National Defense Vocational Training Act of 1941, enrollees began participating in defense-oriented training. The government paid for the classes and after individuals completed courses and passed a competency test, guaranteed automatic employment in the defense work. A total of 85,000 Native Americans were enrolled in this training. This proved valuable social capital for the 24,000 alumni who later served in the military and the 40,000 who left the reservations for city jobs supporting the war effort.

Responding to favorable public opinion to alleviate unemployment, Congress approved the Emergency Relief Appropriation Act of 1935, on April 8, 1935, which included continued funding for the CCC program through March 31, 1937. The age limit was expanded to 18-28 to include more men. From April 1, 1935 to March 31, 1936 was the period of greatest activity and work accomplished by the CCC program. Enrollment had peaked at 505,782 in about 2,900 camps by August 31, 1935, followed by a reduction to 350,000 enrollees in 2,019 camps by June 30, 1936. During this period the public response to the CCC program was overwhelmingly popular. A Gallup poll of April 18, 1936, asked: "Are you in favor of the CCC camps?"; 82% of respondents said yes, including 92% of Democrats and 67% of Republicans.

On June 28, 1937, the Civilian Conservation Corps was legally established and transferred from its original designation as the Emergency Conservation Work program. Funding was extended for three more years by Public Law No. 163, 75th Congress, effective July 1, 1937. Congress changed the age limits to 17–23 years old and changed the requirement that enrollees be on relief to "not regularly in attendance at school, or possessing full-time employment." The 1937 law mandated the inclusion of vocational and academic training for a minimum of 10 hours per week. Students in school were allowed to enroll during summer vacation. During this period, the CCC forces contributed to disaster relief following 1937 floods in New York, Vermont, and the Ohio and Mississippi river valleys, and response and clean-up after the 1938 hurricane in New England.

In 1939 Congress ended the independent status of the CCC, transferring it to the control of the Federal Security Agency. The National Youth Administration, U.S. Employment Service, the Office of Education, and the Works Progress Administration also had some responsibilities. About 5,000 Reserve officers for the camps were affected, as they were transferred to federal Civil Service, and military ranks and titles were eliminated. Despite the loss of overt military leadership in the camps by July 1940, with war underway in Europe and Asia, the government directed an increasing number of CCC projects on resources for national defense. It developed infrastructure for military training facilities and forest protection. By 1940 the CCC was no longer wholly a relief agency, was rapidly losing its non-military character, and it was becoming a system for work-training, as its ranks had become increasingly younger, with little experience.

Although the CCC was probably the most popular New Deal program, it never was authorized as a permanent agency. The program was reduced in scale as the Depression waned and employment opportunities improved. After conscription began in 1940, fewer eligible young men were available. Following the attack on Pearl Harbor in December 1941, the Roosevelt administration directed all federal programs to emphasize the war effort. Most CCC work, except for wildland firefighting, was shifted onto U.S. military bases to help with construction.

The CCC disbanded one year earlier than planned, as the 77th United States Congress ceased funding it. Operations were formally concluded at the end of the federal fiscal year on June 30, 1942. The end of the CCC program and closing of the camps involved arrangements to leave the incomplete work projects in the best possible state, the separation of about 1,800 appointed employees, the transfer of CCC property to the War and Navy Departments and other agencies, and the preparation of final accountability records. Liquidation of the CCC was ordered by Congress by the Labor-Federal Security Appropriation Act (56 Stat. 569) on July 2, 1942; and virtually completed on June 30, 1943. Liquidation appropriations for the CCC continued through April 20, 1948.

Some former CCC sites in good condition were reactivated from 1941 to 1947 as Civilian Public Service camps where conscientious objectors performed "work of national importance" as an alternative to military service. Other camps were used to hold Japanese, German and Italian Americans interned under the Western Defense Command's Enemy Alien Control Program, as well as Axis prisoners of war. Most of the Japanese American internment camps were built by the people held there. After the CCC disbanded, the federal agencies responsible for public lands organized their own seasonal fire crews, modeled after the CCC. These have performed a firefighting function formerly done by the CCC and provided the same sort of outdoor work experience for young people. Approximately 47 young men have died while in this line of duty.



In several cities where CCC workers worked, statues were erected to commemorate them.


The CCC program was never officially terminated. Congress provided funding for closing the remaining camps in 1942 with the equipment being reallocated. It became a model for conservation programs that were implemented in the period after World War II. Present-day corps are national, state, and local programs that engage primarily youth and young adults (ages 16–25) in community service, training, and educational activities. The nation's approximately 113 corps programs operate in 41 states and the District of Columbia. During 2004, they enrolled more than 23,000 young people. The Corps Network, known originally as the National Association of Service and Conservation Corps (NASCC), works to expand and enhance corps-type programs throughout the country. The Corps Network began in 1985 when the nation's first 24 Corps directors banded together to secure an advocate at the federal level and a repository of information on how best to start and manage a corps. Early financial assistance from the Ford, Hewlett and Mott Foundations was critical to establishing the association.

Another similar program is the National Civilian Community Corps, part of the AmeriCorps program, a team-based national service program in which young adults ages 18-24 spend 10 months working for non-profit and government organizations.

The CCC program became a model for the creation of team-based national service youth conservation programs such as the Student Conservation Association (SCA). The SCA, founded in 1959, is a nonprofit organization that offers conservation internships and summer trail crew opportunities to more than 4,000 people each year. The SCA mission is to build a new generation of conservation managers by inspiring lifelong stewardship of the environment and communities by engaging high school and college-age volunteers in hands-on service to the land. SCA program is active nationwide in the USA, including national and state parks, forests, wildlife refuges, seashores and historic sites. SCA National Headquarters is located in Charlestown, New Hampshire, with regional offices across the country.

In 1976, Governor of California Jerry Brown established the California Conservation Corps. This program had many similar characteristics - residential centers, high expectations for participation, and emphasis on hard work on public lands. Young adults from different backgrounds were recruited for a term of one year. Corps members attended a training session called the Corpsmember Orientation Motivation Education and Training (COMET) program before being assigned to one of the various centers. Project work is also similar to the original CCC of the 1930s - work on public forests, state and federal parks.

Established in 1995, Environmental Corps, now Texas Conservation Corps (TxCC), is an American YouthWorks program which allows youth, ages 17 to 28, to contribute to the restoration and preservation of parks and public lands in Texas. The only conservation corps in Texas, TxcC is a nonprofit corporation based in Austin, Texas, which serves the entire state. Their work ranges from disaster relief to trail building to habitat restoration. TxCC has done projects in national, state, and city parks.

The Montana Conservation Corps (MCC) is a non-profit organization with a mission to equip young people with the skills and values to be vigorous citizens who improve their communities and environment. Collectively, MCC crews contribute more than 90,000 work hours each year. The MCC was established in 1991 by Montana's Human Resource Development Councils in Billings, Bozeman and Kalispell. Originally, it was a summer program for disadvantaged youth, although it has grown into an AmeriCorps-sponsored non-profit organization with six regional offices that serve Montana, Idaho, Wyoming, North Dakota, and South Dakota. All regions also offer Montana YES (Youth Engaged in Service) summer programs for teenagers who are 14 to 17 years old.
The Washington Conservation Corps (WCC) is a sub-agency of the Washington State Department of Ecology. It employs men and women 18 to 25 years old in a program to protect and enhance Washington's natural resources. WCC is a part of the AmeriCorps program.

Conservation Corps Minnesota & Iowa provides environmental stewardship and service-learning opportunities to youth and young adults while accomplishing conservation, natural resource management projects and emergency response work through its Young Adult Program and the Summer Youth Program. These programs emphasize the development of job and life skills by conservation and community service work.

The Vermont Youth Conservation Corps (VYCC) is a non-profit, youth service and education organization that hires Corps Members, aged 16–24, to work on high-priority conservation projects in Vermont. Through these work projects, Corps Members develop a strong work ethic, strengthen their leadership skills, and learn how to take personal responsibility for their actions. VYCC Crews work at VT State Parks, U.S. Forest Service Campgrounds, in local communities, and throughout the state's backcountry. The VYCC has also given aid to a similar program in North Carolina, which is currently in its infancy.

Conservation Legacy is a non-profit employment, job training, and education organization with locations across the United States including Arizona Conservation Corps in Tucson and Flagstaff, Arizona; Southwest Conservation Corps in Durango and Salida, Colorado; and Southeast Conservation Corps in Chattanooga, Tennessee. Conservation Legacy also operates an AmeriCorps VISTA team serving to improve the environment and economies of historic mining communities in the American West and Appalachia. Conservation Legacy also hosts the Environmental Stewards Program - providing internships with federal, state, municipal and NGO land management agencies nationwide. Conservation Legacy formed as a merger of the Southwest Youth Corps, San Luis Valley Youth Corps, The Youth Corps of Southern Arizona, and Coconino Rural Environmental Corps.

Conservation Legacy engages young adults ages 14 to 26 and U.S. military veterans of all ages in personal and professional development experiences involving conservation projects on public lands. Corp members live, work, and learn in teams of six to eight for terms of service ranging from 3 months to 1 year.












</doc>
<doc id="7822" url="https://en.wikipedia.org/wiki?curid=7822" title="Caribbean Sea">
Caribbean Sea

The Caribbean Sea (; ; ) is a sea of the Atlantic Ocean in the tropics of the Western Hemisphere. It is bounded by Mexico and Central America to the west and south west, to the north by the Greater Antilles starting with Cuba, to the east by the Lesser Antilles, and to the south by the north coast of South America.

The entire area of the Caribbean Sea, the numerous islands of the West Indies, and adjacent coasts, are collectively known as the Caribbean. The Caribbean Sea is one of the largest seas and has an area of about . The sea's deepest point is the Cayman Trough, between the Cayman Islands and Jamaica, at below sea level. The Caribbean coastline has many gulfs and bays: the Gulf of Gonâve, Gulf of Venezuela, Gulf of Darién, Golfo de los Mosquitos, Gulf of Paria and Gulf of Honduras.

The Caribbean Sea has the world's second biggest barrier reef, the Mesoamerican Barrier Reef. It runs along the coasts of Mexico, Belize, Guatemala, and Honduras.

The name "Caribbean" derives from the Caribs, one of the region's dominant Native American groups at the time of European contact during the late 15th century. After the discovery of America by Christopher Columbus in 1492, the Spanish term "Antillas" applied to the lands; stemming from this, "Sea of the Antilles" became a common alternative name for "Caribbean Sea" in various European languages. During the first century of development, Spanish dominance in the region remained undisputed.

From the 16th century, Europeans visiting the Caribbean region identified the "South Sea" (the Pacific Ocean, to the south of the isthmus of Panama) as opposed to the "North Sea" (the Caribbean Sea, to the north of the same isthmus).

The Caribbean Sea had been unknown to the populations of Eurasia until 1492, when Christopher Columbus sailed into Caribbean waters on a quest to find a sea route to Asia. At that time the Western Hemisphere in general was unknown to Europeans. But first discovered between the years 800 and 1000 by the vikings. Following the Eurasias discovery of the islands by Columbus, The area was quickly colonised by several Western cultures (initially Spain, then later England, the Dutch Republic, France, Courland and Denmark). Following the colonisation of the Caribbean islands, the Caribbean Sea became a busy area for European-based marine trading and transport, and this commerce eventually attracted pirates such as Samuel Bellamy and Blackbeard. (See Piracy in the Caribbean)

Due to the abundance of sunshine, year-round tropical temperatures moderated by the almost constant trade winds and the great variety of scenic destinations to visit, during the second half of the 20th century and on into the 21st the Caribbean Sea became a popular place for tourism.

The International Hydrographic Organization defines the limits of the Caribbean Sea as follows:

Note that, although Barbados is an island on the same continental shelf, it is considered to be in the Atlantic Ocean rather than the Caribbean Sea.

The Caribbean Sea is an oceanic sea largely situated on the Caribbean Plate. The Caribbean Sea is separated from the ocean by several island arcs of various ages. The youngest stretches from the Lesser Antilles to the Virgin Islands to the north east of Trinidad and Tobago off the coast of Venezuela. This arc was formed by the collision of the South American Plate with the Caribbean Plate and includes active and extinct volcanoes such as Mount Pelee, the Quill (volcano) on Sint Eustatius in the Caribbean Netherlands and Morne Trois Pitons on Dominica. The larger islands in the northern part of the sea Cuba, Hispaniola, Jamaica and Puerto Rico lie on an older island arc.

The geological age of the Caribbean Sea is estimated to be between 160 and 180 million years and was formed by a horizontal fracture that split the supercontinent called Pangea in the Mesozoic Era. It is assumed the proto-caribbean basin existed in the Devonian period. In the early Carboniferous movement of Gondwana to the north and its convergence with the Euramerica basin decreased in size. The next stage of the Caribbean Sea's formation began in the Triassic. Powerful rifting led to the formation of narrow troughs, stretching from modern Newfoundland to the west coast of the Gulf of Mexico which formed siliciclastic sedimentary rocks. In the early Jurassic due to powerful marine transgression, water broke into the present area of the Gulf of Mexico creating a vast shallow pool. The emergence of deep basins in the Caribbean occurred during the Middle Jurassic rifting. The emergence of these basins marked the beginning of the Atlantic Ocean and contributed to the destruction of Pangaea at the end of the late Jurassic. During the Cretaceous the Caribbean acquired the shape close to that seen today. In the early Paleogene due to Marine regression the Caribbean became separated from the Gulf of Mexico and the Atlantic Ocean by the land of Cuba and Haiti. The Caribbean remained like this for most of the Cenozoic until the Holocene when rising water levels of the oceans restored communication with the Atlantic Ocean.
The Caribbean's floor is composed of sub-oceanic sediments of deep red clay in the deep basins and troughs. On continental slopes and ridges calcareous silts are found. Clay minerals likely having been deposited by the mainland river Orinoco and the Magdalena River. Deposits on the bottom of the Caribbean Sea and Gulf of Mexico have a thickness of about . Upper sedimentary layers relate to the period from the Mesozoic to the Cenozoic (250 million years ago to present) and the lower layers from the Paleozoic to the Mesozoic.

The Caribbean sea floor is divided into five basins separated from each other by underwater ridges and mountain ranges. Atlantic Ocean water enters the Caribbean through the "Anegada Passage" lying between the Lesser Antilles and Virgin Islands and the "Windward Passage" located between Cuba and Haiti. The Yucatán Channel between Mexico and Cuba links the Gulf of Mexico with the Caribbean. The deepest points of the sea lie in Cayman Trough with depths reaching approximately . Despite this, the Caribbean Sea is considered a relatively shallow sea in comparison to other bodies of water.
The pressure of the South American Plate to the east of the Caribbean causes the region of the Lesser Antilles to have high volcanic activity. There was a very serious eruption of Mount Pelée in 1902 which caused many casualties.

The Caribbean sea floor is also home to two oceanic trenches: the Cayman Trench and Puerto Rico Trench, which put the area at a high risk of earthquakes. Underwater earthquakes pose a threat of generating tsunamis which could have a devastating effect on the Caribbean islands. Scientific data reveals that over the last 500 years the area has seen a dozen earthquakes above 7.5 magnitude. Most recently, a 7.1 earthquake struck Haiti on January 12, 2010.

The hydrology of the sea has a high level of homogeneity. Annual variations in monthly average water temperatures at the surface do not exceed . Over the past fifty years the Caribbean has gone through three stages: cooling until 1974; a cold phase with peaks during 1974–1976 and 1984–1986 then; a warming phase with an increase in temperature of per year. Virtually all temperature extremes were associated with the phenomena of El Niño and La Niña. The salinity of seawater is about 3.6% and its density is . The surface water colour is blue-green to green.

The Caribbean's depth in its wider basins and deep water temperatures are similar to those of the Atlantic. Atlantic deep water is thought to spill into the Caribbean and contribute to the general deep water of its sea. The surface water (30 feet; 100 m) acts as an extension of the northern Atlantic as the Guiana Current and part of the North Equatorial Current enter the sea on the east. On the western side of the sea the trade winds influence a northerly current which causes an upwelling and a rich fishery near Yucatán.

The Caribbean is home to about 9% of the world's coral reefs covering about , most of which are located off the Caribbean Islands and the Central American coast. Among them stands out the Belize Barrier Reef with an area of which was declared a World Heritage Site in 1996. It forms part of the Great Mayan Reef also known as the MBRS and being over in length is the world's second longest. It runs along the Caribbean coasts of Mexico, Belize, Guatemala and Honduras.

During the past ten years, unusually warm Caribbean waters have been increasingly threatening Caribbean coral reefs. Coral reefs support some of the most diverse marine habitats in the world, but they are fragile ecosystems. When tropical waters become unusually warm for extended periods of time, microscopic plants called zooxanthellae, which are symbiotic partners living within the coral polyp tissues, die off. These plants provide food for the corals, and give them their color. The result of the death and dispersal of these tiny plants is called coral bleaching, and can lead to the devastation of large areas of reef. Over 42% of corals are completely bleached and 95% are experiencing some type of whitening. Historically the Caribbean is thought to contain 14% of the world's coral reefs.

The habitats supported by the reefs are critical to such tourist activities as fishing and diving, and provide an annual economic value to Caribbean nations of US$3.1–4.6 billion. Continued destruction of the reefs could severely damage the region's economy. A "Protocol of the Convention for the Protection and Development of the Marine Environment of the Wider Caribbean Region" came in effect in 1986 to protect the various endangered marine life of the Caribbean through forbidding human activities that would advance the continued destruction of such marine life in various areas. Currently this protocol has been ratified by 15 countries. Also, several charitable organisations have been formed to preserve the Caribbean marine life, such as "Caribbean Conservation Corporation" which seeks to study and protect sea turtles while educating others about them.

In connection with the foregoing, the Institute of Marine Sciences and Limnology of the National Autonomous University of Mexico, conducted a regional study, funded by the Department of Technical Cooperation of the International Atomic Energy Agency, in which specialists from 11 Latin American countries (Colombia, Costa Rica, Cuba, Guatemala, Haiti, Honduras, Mexico, Nicaragua, Panama, Dominican Republic, Venezuela plus Jamaica) participated. The findings indicate that heavy metals such as mercury, arsenic, and lead, have been identified in the coastal zone of the Caribbean Sea. Analysis of toxic metals and hydrocarbons is based on the investigation of coastal sediments that have accumulated less than 50 meters deep during the last hundred and fifty years. The project results were presented in Vienna in the forum "Water Matters", and the 2011 General Conference of said multilateral organization.

The Caribbean weather is influenced by the Gulf Stream and Humboldt Current ocean currents. The tropical location of the sea helps the water to maintain a warm temperature ranging from the low of by the season.

The Caribbean is a focal area for many hurricanes within the Western Hemisphere. A series of low pressure systems develop off the West coast of Africa and make their way across the Atlantic Ocean. While most of these systems do not become tropical storms, some do. The tropical storms can develop into Atlantic hurricanes, often in the low pressure areas of the eastern Caribbean. The Caribbean hurricane season as a whole lasts from June through November, with the majority of hurricanes occurring during August and September. On average around 9 tropical storms form each year, with 5 reaching hurricane strength. According to the National Hurricane Center 385 hurricanes occurred in the Caribbean between 1494 and 1900.

Every year hurricanes represent a potential threat to the islands of the Caribbean, due to the extremely destructive nature of these powerful weather systems. Coral reefs can easily be damaged by violent wave action, and can be destroyed when a hurricane dumps sand or mud onto a reef. When this happens, the coral organisms are smothered and the reef dies and ultimately breaks apart.

The region has a high level of biodiversity and many species are endemic to the Caribbean.

The vegetation of the region is mostly tropical but differences in topography, soil and climatic conditions increase species diversity. Where there are porous limestone terraced islands these are generally poor in nutrients. It is estimated that 13,000 species of plants grow in the Caribbean of which 6,500 are endemic. For example, guaiac wood ("Guaiacum officinale"), the flower of which is the national flower of Jamaica and the Bayahibe rose ("Pereskia quisqueyana") which is the national flower of the Dominican Republic and the ceiba which is the national tree of both Puerto Rico and Guatemala. The mahogany is the national tree of the Dominican Republic and Belize. The caimito ("Chrysophyllum cainito") grows throughout the Caribbean. In coastal zones there are coconut palms and in lagoons and estuaries are found thick areas of black mangrove and red mangrove ("Rhizophora mangle").

In shallow water flora and fauna is concentrated around coral reefs where there is little variation in water temperature, purity and salinity. Leeward side of lagoons provide areas of growth for sea grasses. Turtle grass ("Thalassia testudinum") is common in the Caribbean as is manatee grass ("Syringodium filiforme") which can grow together as well as in fields of single species at depths up to . Another type shoal grass ("Halodule wrightii") grows on sand and mud surfaces at depths of up to . In brackish water of harbours and estuaries at depths less than widgeongrass ("Ruppia maritima") grows. Representatives of three species belonging to the genus "Halophila", ("Halophila baillonii", "Halophila engelmannii" and "Halophila decipiens") are found at depths of up to except for "Halophila engelmani" which does not grow below and is confined to the Bahamas, Florida, the Greater Antilles and the western part of the Caribbean. "Halophila baillonii" has been found only in the Lesser Antilles.

Marine biota in the region have representatives of both the Indian and Pacific oceans which were caught in the Caribbean before the emergence of the Isthmus of Panama four million years ago. In the Caribbean Sea there are around 1,000 documented species of fish, including sharks (bull shark, tiger shark, silky shark and Caribbean reef shark), flying fish, giant oceanic manta ray, angel fish, spotfin butterflyfish, parrotfish, Atlantic Goliath grouper, tarpon and moray eels. Throughout the Caribbean there is industrial catching of lobster and sardines (off the coast of Yucatán Peninsula).

There are 90 species of mammals in the Caribbean including sperm whales, humpback whales and dolphins. The island of Jamaica is home to seals and manatees. The Caribbean monk seal which lived in the Caribbean is considered extinct. The solenodon is endangered.

There are 500 species of reptiles (94% of which are endemic). Islands are inhabited by some endemic species such as rock iguanas and American crocodile. The blue iguana, endemic to the island of Grand Cayman, is endangered. The green iguana is invasive to Grand Cayman. The Mona ground iguana which inhabits the island of Mona, Puerto Rico, is endangered. The rhinoceros iguana from the island of Hispaniola which is shared between Haiti and the Dominican Republic is also endangered. The region has several types of sea turtle (loggerhead, green turtle, hawksbill, leatherback turtle, Atlantic ridley and olive ridley). Some species are threatened with extinction. Their populations have been greatly reduced since the 17th century – the number of green turtles has declined from 91 million to 300,000 and hawksbill turtles from 11 million to less than 30,000 by 2006.

All 170 species of amphibians that live in the region are endemic. The habitats of almost all members of the toad family, poison dart frogs, tree frogs and leptodactylidae (a type of frog) are limited to only one island. The Golden coqui is in serious threat of extinction.

In the Caribbean 600 species of birds have been recorded of which 163 are endemic such as the tody, Fernandina's flicker and palmchat. The American yellow warbler is found in many areas as is the green heron. Of the endemic species 48 are threatened with extinction including the Puerto Rican amazon, yellow-breasted crake and the Zapata wren. According to Birdlife International in 2006 in Cuba 29 species of bird are in danger of extinction and two species officially extinct. The black-fronted piping guan is endangered as is the plain pigeon. The Antilles along with Central America lie in the flight path of migrating birds from North America so the size of populations is subject to seasonal fluctuations. In the forests are found parrots, bananaquit and toucans. Over the open sea can be seen frigatebirds and tropicbirds.

The Caribbean region has seen a significant increase in human activity since the colonization period. The sea is one of the largest oil production areas in the world, producing approximately 170 million per year. The area also generates a large fishing industry for the surrounding countries, accounting for of fish a year.

Human activity in the area also accounts for a significant amount of pollution, The Pan American Health Organization estimated in 1993 that only about 10% of the sewage from the Central American and Caribbean Island countries is properly treated before being released into the sea.

The Caribbean region supports a large tourism industry. The Caribbean Tourism Organization calculates that about 12 million people a year visit the area, including (in 1991–1992) about 8 million cruise ship tourists. Tourism based upon scuba diving and snorkeling on coral reefs of many Caribbean islands makes a major contribution to their economies.

The Caribbean is the setting for countless literary efforts often related to piracy acts and swashbuckling. One memorable work of pulp fiction has in its title a geographic feature unique in its way to the islands: "Fear Cay", the eleventh Doc Savage adventure by Lester Dent. Many James Bond adventures were set there. It is also well known as the location of the Pirates of the Caribbean films, featuring Port Royal. Peter Matthiessen's "Far Tortuga" (1975) chronicles the adventures of a turtling crew in the late 1960s.




</doc>
<doc id="7824" url="https://en.wikipedia.org/wiki?curid=7824" title="Colin Maclaurin">
Colin Maclaurin

Colin Maclaurin (; ; 1 February 1698 – 14 June 1746) was a Scottish mathematician who made important contributions to geometry and algebra. The Maclaurin series, a special case of the Taylor series, is named after him.

Owing to changes in orthography since that time (his name was originally rendered as “M‘Laurine”), his surname is alternatively written MacLaurin.

Maclaurin was born in Kilmodan, Argyll. His father, Reverend and Minister of Glendaruel John Maclaurin, died when Maclaurin was in infancy, and his mother died before he reached nine years of age. He was then educated under the care of his uncle, the Reverend Daniel Maclaurin, minister of Kilfinan.

At eleven, Maclaurin entered the University of Glasgow. He graduated MA three years later by defending a thesis on "the Power of Gravity," and remained at Glasgow to study divinity until he was 19, when he was elected professor of mathematics in a ten-day competition at the Marischal College in the University of Aberdeen. This record as the world's youngest professor endured until March 2008, when the record was officially given to Alia Sabur.

In the vacations of 1719 and 1721, Maclaurin went to London, where he became acquainted with Sir Isaac Newton, Dr Benjamin Hoadly, Samuel Clarke, Martin Folkes, and other philosophers. He was admitted a member of the Royal Society.

In 1722, having provided a substitute for his class at Aberdeen, he travelled on the Continent as tutor to George Hume, the son of Alexander Hume, 2nd Earl of Marchmont. During their time in Lorraine, he wrote his essay on the percussion of bodies ("Demonstration des loix du choc des corps"), which gained the prize of the Royal Academy of Sciences in 1724. Upon the death of his pupil at Montpellier, Maclaurin returned to Aberdeen.

In 1725, Maclaurin was appointed deputy to the mathematical professor at Edinburgh, James Gregory (brother of David Gregory and nephew of the esteemed James Gregory), upon the recommendation of Isaac Newton. On 3 November of that year Maclaurin succeeded Gregory, and went on to raise the character of that university as a school of science. Newton was so impressed with Maclaurin that he had offered to pay his salary himself.

Maclaurin used Taylor series to characterize maxima, minima, and points of inflection for infinitely differentiable functions in his "Treatise of Fluxions". Maclaurin attributed the series to Taylor, though the series was known before to Newton and Gregory, and in special cases to Madhava of Sangamagrama in fourteenth century India.
Nevertheless, Maclaurin received credit for his use of the series, and the Taylor series expanded around 0 is sometimes known as the "Maclaurin series" .

Maclaurin also made significant contributions to the gravitation attraction of ellipsoids, a subject that furthermore attracted the attention of d'Alembert, A.-C. Clairaut, Euler, Laplace, Legendre, Poisson and Gauss. Maclaurin showed that an oblate spheroid was a possible equilibrium in Newton's theory of gravity. The subject continues to be of scientific interest, and Nobel Laureate Subramanyan Chandrasekhar dedicated a chapter of his book "Ellipsoidal Figures of Equilibrium" to Maclaurin spheroids. 

Independently from Euler and using the same methods, Maclaurin discovered the Euler–Maclaurin formula. He used it to sum powers of arithmetic progressions, derive Stirling's formula, and to derive the Newton-Cotes numerical integration formulas which includes Simpson's rule as a special case. 

Maclaurin contributed to the study of elliptic integrals, reducing many intractable integrals to problems of finding arcs for hyperbolas. His work was continued by d'Alembert and Euler, who gave a more concise approach.

In his "Treatise of Algebra" (Ch. XII, Sect 86), published in 1748 two years after his death, Maclaurin proved a rule for solving square linear systems in the cases of 2 and 3 unknowns, and discussed the case of 4 unknowns.

In 1733, Maclaurin married Anne Stewart, the daughter of Walter Stewart, the Solicitor General for Scotland, by whom he had seven children. His eldest son John Maclaurin studied Law, was a Senator of the College of Justice, and became Lord Dreghorn; he was also joint founder of the Royal Society of Edinburgh.

Maclaurin actively opposed the Jacobite rising of 1745 and superintended the operations necessary for the defence of Edinburgh against the Highland army. Maclaurin compiled a diary of his exertions against the Jacobites, both within and without the city. When the Highland army entered the city, however, he fled to York, where he was invited to stay by the Archbishop of York.

On his journey south, Maclaurin fell from his horse, and the fatigue, anxiety, and cold to which he was exposed on that occasion laid the foundations of dropsy. He returned to Edinburgh after the Jacobite army marched south, but died soon after his return.

He is buried at Greyfriars Kirkyard, Edinburgh.

Mathematician and former MIT President Richard Cockburn Maclaurin was from the same family.

The Maclaurin Society (MacSoc), the Mathematics and Statistics Society at Glasgow University, is named in his honour.

Colin MacLaurin Road within Edinburgh University's King's Buildings complex is named in his honour.

Some of his important works are:


Colin Maclaurin was the name used for the new Mathematics and Actuarial Mathematics and Statistics Building at Heriot-Watt University, Edinburgh.





</doc>
<doc id="7825" url="https://en.wikipedia.org/wiki?curid=7825" title="Celestial globe">
Celestial globe

Celestial globes show the apparent positions of the stars in the sky. They omit the Sun, Moon, and planets because the positions of these bodies vary relative to those of the stars, but the ecliptic, along which the Sun moves, is indicated.

There is an issue regarding the “handedness” of celestial globes. If the globe is constructed so that the stars are in the positions they actually occupy on the imaginary celestial sphere, then the star field will appear back-to-front on the surface of the globe (all the constellations will appear as their mirror images). This is because the view from Earth, positioned at the centre of the celestial sphere, is of the "inside" of the celestial sphere, whereas the celestial globe is viewed from the "outside". For this reason, celestial globes are often produced in mirror image, so that at least the constellations appear the “right way round”. Some modern celestial globes address this problem by making the surface of the globe transparent. The stars can then be placed in their proper positions and viewed "through" the globe, so that the view is of the inside of the celestial sphere. However, the proper position from which to view the sphere would be from its centre, but the viewer of a transparent globe must be outside it, far from its centre. Viewing the inside of the sphere from the outside, through its transparent surface, produces serious distortions. Opaque celestial globes that are made with the constellations correctly placed, so they appear as mirror images when directly viewed from outside the globe, are often viewed in a mirror, so the constellations have their familiar appearances. Written material on the globe, e.g. constellation names, is printed in reverse, so it can easily be read in the mirror.



</doc>
<doc id="7827" url="https://en.wikipedia.org/wiki?curid=7827" title="Covenant-breaker">
Covenant-breaker

Covenant-breaker is a term used by Bahá'ís to refer to a person who has been excommunicated from the Bahá'í community for the act of covenant-breaking, roughly defined as active opposition to the Bahá'í Faith from a current member. According to Bahá'í law, only the head of the religion, currently the Universal House of Justice, has the authority to declare a person a covenant-breaker. 

A person may be declared a covenant-breaker for actions which are seen as challenging the unity of the Bahá'í community, not for personal matters such as failure to obey Bahá'í law or conversion to another religion. 

When a person is a declared a covenant-breaker all Bahá'ís are expected to avoid unnecessary association with that person. 

Covenant-breaking does not refer to attacks from non-Bahá'ís or former Baha'is. Rather, it is in reference to internal campaigns of opposition where the Covenant-breaker is seen as challenging the unity of the Bahá'í Faith, causing internal division, or by claiming or supporting an alternate succession of authority or administrative structure. The central purpose of the covenant is to prevent schism and dissension.
In a letter to an individual dated 23 March 1975, the Universal House of Justice wrote:
The term 'Covenant-breaker' or, in Arabic 'naqid al-mithaq' [pl. Naqidu 'l-mithaq], was first used by `Abdu'l-Bahá to describe the partisans of his brother Mírzá Muhammad `Alí, who challenged his leadership. In `Abdu'l-Bahá's Will and Testament, He appointed Shoghi Effendi as the "Guardian" of the religion and called for the eventual election of the Universal House of Justice, and defined in the same manner opposition to these two institutions as Covenant-Breaking. `Abdu'l-Bahá advised all Bahá'ís to shun anyone opposing the Covenant: "...one of the greatest and most fundamental principles of the Cause of God is to shun and avoid entirely the Covenant-breakers, for they will utterly destroy the Cause of God, exterminate His Law and render of no account all efforts exerted in the past."

Most Covenant-breakers are involved in schismatic groups, but not always. For example, a Bahá'í who refuses to follow guidance on treatment of Covenant-breakers is at risk of being named one. One article originally written for the Bahá'í Encyclopedia, characterized Covenant-breakers that have emerged in the course of Bahá'í history as belonging to one of four categories:


Shoghi Effendi wrote to the National Spiritual Assembly of Canada in 1957:
Beyond this, many other relationships to the Bahá'í Faith exist, both positive and negative. Covenant-breaking does not apply to most of them. The following is a partial list of those who could not rightly be termed Covenant-breakers:


Bábís are generally regarded as another religion altogether. Since Covenant-breaking presumes that one has submitted oneself to a covenant and then broken it, and Bábís never recognized or swore allegiance to Bahá'u'lláh, they are not Covenant-breakers.

Followers of Subh-i-Azal, Bahá'u'lláh's half-brother who tried to poison him, engaged in active opposition to Bahá'ís, and Shoghi Effendi did inform Bahá'ís that they should avoid contact with his descendants, writing that "No intelligent and loyal Baha'i would associate with a descendant of Azal, if he traced the slightest breath of criticism of our Faith, in any aspect, from that person. In fact these people should be strenuously avoided as having an inherited spiritual disease -- the disease of Covenant-breaking!".

Through the influence of Bahiyyih Khanum, the eldest daughter of Bahá'u'lláh, everyone in the household initially rallied around Shoghi Effendi after the death of `Abdu'l-Bahá. For several years his brother Husayn and several cousins served him as secretaries. The only ones publicly opposing him were Mírzá Muhammad `Alí and his followers, who were declared Covenant-breakers by `Abdu'l-Bahá. Contrary to `Abdu'l-Bahá's specific instruction, certain family members established illicit links with those whom `Abdu'l-Bahá had declared Covenant-breakers. After Bahiyyih Khanum died in 1932, Shoghi Effendi's eldest sister – Ruhangiz – married a son of Siyyid Ali Afnan. Bahá'u'lláh's son-in-law was, thus, a long-standing enemy of `Abdu'l-Bahá (who had declared him a Covenant-breaker.) Through Ruhangiz's efforts, Shoghi Effendi's other sister and his cousin Thurayya also married sons of Siyyid Ali Afnan. Presumably being faced with a choice between shunning their disobedient family members and being themselves disobedient to `Abdu'l-Bahá and Shoghi Effendi, his cousins, aunts and uncles chose the latter.

After years of silence on these developments, cables sent by Shoghi Effendi on November 2, 1941 provide background to developments among family members. Ruhi Afnan, Shoghi Effendi's cousin through `Abdu'l-Bahá's daughter Tuba:


Faydi was the son of Furughiyyih Khanum, a daughter of Bahá'u'lláh by his third wife Gawhar. Furughiyyih and her children all supported Mírzá Muhammad `Alí. Faydi had two elder brothers. Hussein Effendi Afnan was aide-de-camp to Faisal II of Iraq and Nayyer Effendi Afnan was Commissioner of Parks in Cairo, Egypt. The entire Bahá'í Family was stigmatized by Shoghi Effendi as Covenant-breakers as he was displeased with their marriages.

Then in a 1950 cable:


And in 1953:


Later, Ruhi was presented with a copy of Sohrab's book about his excommunication:

Concerning Munib Shahid, Shoghi Effendi's cousin through `Abdu'l-Bahá's daughter Ruha, Shoghi Effendi sent the following cable to the Bahá'í world in November 1944:


Husayn Ali was Shoghi Effendi's brother. In April 1945, Shoghi Effendi sent the following cable to the Bahá'í world: "My faithless brother Husayn, after long period of dishonourable conduct, has abandoned the Master's home to consort with his sister and other Covenant-breakers" ("Bahá'í News", No. 174, p.2). In March 1950, Shoghi Effendi would send a further cable: "Faithless brother Hussein, already abased through dishonorable conduct over period (of) years followed by association with Covenant-breakers (in) Holy Land and efforts (to) undermine Guardian's position, recently further demeaned himself through marriage under obscure circumstances with lowborn Christian girl (in) Europe" ("Bahá'í News", No. 229, p.1). Shoghi Effendi would later defend the use of the term "lowborn Christian girl" as follows: "Regarding his cable concerning Hussein: he has been very surprised to note that the terms 'low-born Christian girl ' and 'disgraceful alliance' should arouse any question; it seems to him that the friends should realize it is not befitting for the Guardian's own brother, the grandchild of the Master, an Afnán and Aghsán mentioned in the Will and Testament of the Master, and of whom so much was expected because of his relation to the family of the Prophet, to marry an unknown girl, according to goodness knows what rite, who is not a believer at all" ("Bahá'í News", No. 236, p.4).

Concerning his own brother Riaz, the following cable was sent in December 1951:


He dispatched a cable concerning his younger sister in December 1941:


The reason for her being declared a Covenant-breaker was that she followed the example of Ruhi's sister by marrying to one of his cousins without the Guardian's consent. Mehrangiz married to Hassan Afnan, the son of Furughiyyih Khanum, a daughter of Bahá'u'lláh by his third wife Gawhar.

Most of the groups regarded by the larger group of Bahá'ís as Covenant-breakers originated in the claims of Charles Mason Remey to the Guardianship in 1960. The Will and Testament of `Abdu'l-Bahá states that Guardians should be lineal descendants of Bahá'u'lláh, that each Guardian must select his successor during his lifetime, and that the nine Hands of the Cause of God permanently stationed in the holy land must approve the appointment by majority vote. Bahá'ís interpret lineal descendency to mean physical familial relation to Bahá'u'lláh, of which Mason Remey was not.

Almost all of Bahá'ís accepted the determination of the Hands of the Cause that upon the death of Shoghi Effendi, he died "without having appointed his successor". There was an absence of a valid descendant of Bahá'u'lláh who could qualify under the terms of `Abdu'l-Bahá's will. Later the Universal House of Justice, initially elected in 1963, made a ruling on the subject that it was not possible for another Guardian to be appointed.

In 1960 Remey, a Hand of the Cause himself, retracted his earlier position, and claimed to have been coerced. He claimed to be the successor to Shoghi Effendi. He and the small number of people who followed him were expelled from the Faith by the Hands of the Cause. Those close to Remey claimed that he went senile in old age, and by the time of his death he was largely abandoned, with his most prominent followers fighting amongst themselves for leadership.

The largest group of the remaining followers of Remey, members of the so called "Orthodox Bahá'í Faith", believe that legitimate authority passed from Shoghi Effendi to Mason Remey to Joel Marangella. They, therefore, regard the Universal House of Justice in Haifa, Israel to be illegitimate, and its members and followers to be Covenant-breakers.

The present descendants of expelled members of Bahá'u'lláh's family have not specifically been declared Covenant-breakers, though they mostly do not associate themselves with the Bahá'í religion.

A small group of Bahá'ís in Northern New Mexico believe that these descendants are eligible for appointment to the Guardianship and are waiting for such a direct descendant of Bahá'u'lláh to arise as the rightful Guardian.

There is also a small group in Montana, originally inspired by Leland Jensen, who claimed a status higher than that of the Guardian. His failed apocalyptic predictions and unsuccessful efforts to reestablish the Guardianship and the administration were apparent by his death in 1996. A dispute among Jensen's followers over the identity of the Guardian resulted in another division in 2001.




</doc>
<doc id="7828" url="https://en.wikipedia.org/wiki?curid=7828" title="Concord, Michigan">
Concord, Michigan

Concord is a village in Jackson County in the U.S. state of Michigan. The population was 1,050 at the 2010 census. The village is located at , west of Spring Arbor, Michigan.

Concord first received a post office in 1836. It was incorporated as a village in 1871.

The Michigan Historical Center operates a museum in Concord called the Mann House. The Mann House is an excellent example of typical middle-class domestic architecture of the early 1880s and features the family's sleigh and buggy as well as Jackson's Michigan State Prison made furniture.

Concord is a general-law village incorporated within the Township of Concord.

According to the United States Census Bureau, the village has a total area of , of which is land and is water.

The village is located within the T3S R3W survey township.

Concord Community Schools (Enrollment 900) participate in Class C and Division 4 of MHSAA athletics. Their teams are known as the Yellow Jackets and play in the Big 8 Conference. The schools' colors are purple and gold. The boys' cross country and track & field teams both claimed MHSAA State Championships during the 2009–10 school year, as well as back to back MHSAA State Championships in the 2014 and 2015 school years. In 2011 and 2012, the boys cross country team won back to back MHSAA State Championships.

As of the census of 2010, there were 1,050 people, 412 households, and 293 families residing in the village. The population density was . There were 484 housing units at an average density of . The racial makeup of the village was 99.0% White, 0.3% African American, 0.1% Native American, 0.1% Asian, 0.1% from other races, and 0.4% from two or more races. Hispanic or Latino of any race were 1.8% of the population.

There were 412 households of which 33.7% had children under the age of 18 living with them, 54.6% were married couples living together, 10.4% had a female householder with no husband present, 6.1% had a male householder with no wife present, and 28.9% were non-families. 25.7% of all households were made up of individuals and 12.6% had someone living alone who was 65 years of age or older. The average household size was 2.55 and the average family size was 3.02.

The median age in the village was 40.9 years. 26% of residents were under the age of 18; 8.3% were between the ages of 18 and 24; 21.4% were from 25 to 44; 28.7% were from 45 to 64; and 15.6% were 65 years of age or older. The gender makeup of the village was 48.9% male and 51.1% female.

As of the census of 2000, there were 1,101 people, 428 households, and 308 families residing in the village. The population density was 748.4 per square mile (289.2/km²). There were 499 housing units at an average density of 339.2 per square mile (131.1/km²). The racial makeup of the village was 97.91% White, 0.09% Black or African American, 0.27% Native American, 0.73% Asian, 0.64% from other races, and 0.36% from two or more races. 0.82% of the population were Hispanic or Latino of any race.

There were 428 households out of which 34.3% had children under the age of 18 living with them, 57.9% were married couples living together, 10.7% had a female householder with no husband present, and 28.0% were non-families. 25.0% of all households were made up of individuals and 10.5% had someone living alone who was 65 years of age or older. The average household size was 2.57 and the average family size was 3.09.

In the village, the population was spread out with 28.1% under the age of 18, 7.5% from 18 to 24, 28.2% from 25 to 44, 21.7% from 45 to 64, and 14.5% who were 65 years of age or older. The median age was 37 years. For every 100 females there were 92.8 males. For every 100 females age 18 and over, there were 87.7 males.

The median income for a household in the village was $46,500, and the median income for a family was $54,531. Males had a median income of $39,167 versus $23,594 for females. The per capita income for the village was $19,348. About 4.8% of families and 5.2% of the population were below the poverty line, including 3.1% of those under age 18 and 7.1% of those age 65 or over.



</doc>
<doc id="7829" url="https://en.wikipedia.org/wiki?curid=7829" title="Chaos Computer Club">
Chaos Computer Club

The Chaos Computer Club (CCC) is Europe's largest association of hackers with 5,500 registered members.
It is incorporated as an "eingetragener Verein" in Germany, with local chapters (called "Erfa-Kreise") in various cities in Germany and other German-speaking countries.
Some chapters in Switzerland are organized in the independent sister association Chaos Computer Club Schweiz instead.

The CCC describes itself as "a galactic community of life forms, independent of age, sex, race or societal orientation, which strives across borders for freedom of information..." In general, the CCC advocates more transparency in government, freedom of information, and the human right to communication. Supporting the principles of the hacker ethic, the club also fights for free universal access to computers and technological infrastructure as well as the use of Open-source software. The CCC spreads an entrepreneurial vision refusing capitalist control. It has been characterized as "...one of the most influential digital organisations anywhere, the centre of German digital culture, hacker culture, hacktivism, and the intersection of any discussion of democratic and digital rights."

Members of the CCC have demonstrated and publicized a number of important information security problems.
The CCC frequently criticizes new legislation and products with weak information security which endanger citizen rights or the privacy of users.
Notable members of the CCC regularly function as expert witnesses for the German constitutional court, organize lawsuits and campaigns, or otherwise influence the political process.

The CCC hosts the annual Chaos Communication Congress, Europe's biggest hacker gathering.
When the event was held in the Hamburg congress center in 2013, it drew 9,000 guests.
For the 2016 installment, 11,000 guests were expected., with additional viewers following the event via live streaming.

Every four years, the Chaos Communication Camp is the outdoor alternative for hackers worldwide.
The CCC also held, from 2009 to 2013, a yearly conference called SIGINT in Cologne which focused on the impact of digitalization on society. The SIGINT conference has been discontinued in 2014.
Another yearly CCC event taking place on the Easter weekend is the Easterhegg, which is more workshop oriented than the other events.

The CCC often uses the c-base station located in Berlin as an event location or as function rooms.

The CCC publishes the irregular magazine "Datenschleuder" ("data slingshot") since 1984.
The Berlin chapter produces a monthly radio show called which picks up various technical and political topics in a two-hour talk radio show. The program is aired on a local radio station called and on the internet.
Other programs have emerged in the context of Chaosradio, including radio programs offered by some regional Chaos Groups and the podcast spin-off "CRE" by Tim Pritlove.

Many of the chapters of CCC participate in the volunteer project "Chaos macht Schule" which supports teaching in local schools. Its aims are to improve technology and media literacy of pupils, parents, and teachers.

CCC members are present in big tech companies and in administrative instances. One of the spokespersons of the CCC,as of 1986, Andy Müller-Maguhn, was a member of the executive committee of the ICANN (Internet Corporation for Assigned Names and Numbers) between 2000 and 2002 .

The CCC sensitizes and introduces people to the questions of data privacy. They regularly host so-called cryptoparties in bars in Berlin to which anyone is invited to better understand how to protect their personal data and their computer from hacking. 

The CCC encourages some basic behaviors :

The CCC was founded in Berlin on 12 September 1981 at a table which had previously belonged to the Kommune 1 in the rooms of the newspaper Die Tageszeitung by Wau Holland and others in anticipation of the prominent role that information technology would play in the way people live and communicate.

The CCC became world-famous when they drew public attention to the security flaws of the German Bildschirmtext computer network by causing it to debit DM 134,000 in a Hamburg bank in favor of the club. The money was returned the next day in front of the press. Prior to the incident, the system provider had failed to react to proof of the security flaw provided by the CCC, claiming to the public that their system was safe. Bildschirmtext was the biggest commercially available online system targeted at the general public in its region at that time, run and heavily advertised by the German telecommunications agency Deutsche Bundespost which also strove to keep up-to-date alternatives out of the market.

In 1987, the CCC was peripherally involved in the first cyberespionage case to make international headlines. A group of German hackers led by Karl Koch, who was loosely affiliated with the CCC, was arrested for breaking into US government and corporate computers, and then selling operating-system source code to the Soviet KGB.
This incident was portrayed in the movie "23".

In April 1998, the CCC successfully demonstrated the cloning of a GSM customer card, breaking the COMP128 encryption algorithm used at that time by many GSM SIMs.

In 2001, the CCC celebrated its twentieth birthday with an interactive light installation dubbed "Project Blinkenlights" that turned the building Haus des Lehrers in Berlin into a giant computer screen. A follow up installation, "Arcade", at the Bibliothèque nationale de France was the world's biggest light installation.
Later in October 2008, CCC's Project Blinkenlights went to Toronto, Ontario, Canada with project Stereoscope.

In March 2008, the CCC acquired and published the fingerprints of German Minister of the Interior Wolfgang Schäuble. The magazine also included the fingerprint on a film that readers could use to fool fingerprint readers. This was done to protest the use of biometric data in German identity devices such as e-passports.

The Staatstrojaner ("Federal Trojan horse") is a computer surveillance program installed secretly on a suspect's computer, which the German police uses to wiretap Internet telephony. This "source wiretapping" is the only feasible way to wiretap in this case, since Internet telephony programs will usually encrypt the data when it leaves the computer. The Federal Constitutional Court of Germany has ruled that the police may only use such programs for telephony wiretapping, and for no other purpose, and that this restriction should be enforced through technical and legal means.

On October 8, 2011, the CCC published an analysis of the Staatstrojaner software. The software was found to have the ability to remote control the target computer, to capture screenshots, and to fetch and run arbitrary extra code. The CCC says that having this functionality built in is in direct contradiction to the ruling of the constitutional court.

In addition, there were a number of security problems with the implementation. The software was controllable over the Internet, but the commands were sent completely unencrypted, with no checks for authentication or integrity. This leaves any computer under surveillance using this software vulnerable to attack. The captured screenshots and audio files were encrypted, but so incompetently that the encryption was ineffective. All captured data was sent over a proxy server in the United States, which is problematic since the data is then temporarily outside the German jurisdiction.

The CCC's findings were widely reported in the German press. This trojan has also been nicknamed R2-D2 because the string "C3PO-r2d2-POE" was found in its code; another alias for it is 0zapftis. According to a Sophos analysis, the trojan's behavior matches that described in a confidential memo between the German Landeskriminalamt and a software firm called ; the memo was leaked on WikiLeaks in 2008. Among other correlations is the dropper's file name scuinst.exe, short for Skype Capture Unit Installer. The 64-bit Windows version installs a digitally signed driver, but signed by the non-existing certificate authority "Goose Cert". DigiTask later admitted selling spy software to governments.

The Federal Ministry of the Interior released a statement in which they denied that R2-D2 has been used by the Federal Criminal Police Office (BKA); this statement however does not eliminate the possibility that it has been used by state-level German police forces. The BKA had previously announced however (in 2007) that they had somewhat similar trojan software that can inspect a computer's hard drive.

Former WikiLeaks spokesman Daniel Domscheit-Berg was expelled from the national CCC (but not the Berlin chapter) in August 2011. This decision was revoked on February 2012.
As a result of his role in the expulsion, board member Andy Müller-Maguhn was not reelected for another term.

The CCC has repeatedly warned phone users of the weakness of biometric identification means, in the continuation of the 2008 Schäuble fingerprints affair. In their "hacker ethics" the CCC includes "protect people data", but also "Computers can change your life for the better" . The club considers privacy as an individual right: the CCC does not discourage people from sharing or storing personal information on their phones, but militates for better privacy protection, and the use of specific browsing and sharing means by the users.

From a photography of the user's fingerprint on a glass surface, using "easy everyday means", the biometrics hacking team of the CCC, was able to unlock IPhone 5Ss.

The Samsung Galaxy S8's iris recognition system claims to be"one of the safest ways to keep your phone locked and the contents private" as "patterns in your irises are unique to you and are virtually impossible to replicate", as quoted in official Samsung content.

However, in some cases, using a high resolution iris photography of the phone owner and a lense, the CCC claimed to be able to trick the authentification system.

The Chaos Computer Club France (CCCF) was a fake hacker organization created in 1989 in Lyon (France) by Jean-Bernard Condat, under the command of Jean-Luc Delacour, an agent of the Direction de la surveillance du territoire governmental agency. The primary goal of the CCCF was to watch and to gather information about the French hacker community, identifying the hackers who could harm the country . Journalist Jean Guisnel said that this organization also worked with the French National Gendarmerie.

The name of the organization is directly inspired by the name of the German Chaos Computer Club organization, which in contrast is a real hacker organization.

The CCCF had an electronic magazine called "Chaos Digest (ChaosD)". Between January 4, 1993 and August 5, 1993, seventy-three issues were published ().




</doc>
<doc id="7830" url="https://en.wikipedia.org/wiki?curid=7830" title="Convention (norm)">
Convention (norm)

A convention is a set of agreed, stipulated, or generally accepted standards, norms, social norms, or criteria, often taking the form of a custom.

Certain types of rules or customs may become law and regulatory legislation may be introduced to formalize or enforce the convention (for example, laws that define on which side of the road vehicles must be driven). In a social context, a convention may retain the character of an "unwritten law" of custom (for example, the manner in which people greet each other, such as by shaking each other's hands).

In physical sciences, numerical values (such as constants, quantities, or scales of measurement) are called conventional if they do not represent a measured property of nature, but originate in a convention, for example an average of many measurements, agreed between the scientists working with these values.

A convention is a selection from among two or more alternatives, where the rule or alternative is agreed upon among participants. Often the word refers to unwritten customs shared throughout a community. For instance, it is conventional in many societies that strangers being introduced shake hands. Some conventions are explicitly legislated; for example, it is conventional in the United States and in Germany that motorists drive on the right side of the road, whereas in New Zealand and the United Kingdom motorists drive on the left. The standardization of time is a human convention based on the solar cycle or calendar. The extent to which justice is conventional (as opposed to natural or objective) is historically an important debate among philosophers.

The nature of conventions has raised long-lasting philosophical discussion. Quine, Davidson, and David Lewis published influential writings on the subject. Lewis's account of convention received an extended critique in Margaret Gilbert's "On Social Facts" (1989), where an alternative account is offered. Another view of convention comes from Ruth Millikan's "Language: A Biological Model" (2005), once more against Lewis.

According to David Kalupahana, The Buddha described conventions—whether linguistic, social, political, moral, ethical, or even religious—as arising dependent on specific conditions. According to his paradigm, when conventions are considered absolute realities, they contribute to dogmatism, which in turn leads to conflict. This does not mean that conventions should be absolutely ignored as unreal and therefore useless. Instead, according to Buddhist thought, a wise person adopts a middle way without holding conventions to be ultimate or ignoring them when they are fruitful.

In sociology a "social rule" refers to any social convention commonly adhered to in a society. These "rules" are not written in law or otherwise formalized. In social constructionism there is a great focus on social rules. It is argued that these rules are socially constructed, that these rules act upon every member of a society, but at the same time, are re-produced by the individuals.

Sociologists representing symbolic interactionism argue that social rules are created through the interaction between the members of a society. The focus on active interaction highlights the fluid, shifting character of social rules. These are specific to the social context, a context that varies through time and place. That means a social rule changes over time within the same society. What was acceptable in the past may no longer be the case. Similarly, rules differ across space: what is acceptable in one society may not be so in another.

Social rules reflect what is "acceptable" or "normal" behaviour in any situation. Michel Foucault's concept of discourse is closely related to social rules as it offers a possible explanation how these rules are shaped and change. It is the social rules that tell people what is "normal" behaviour for any specific category. Thus, social rules tell a woman how to behave in a womanly manner, and a man, how to be manly. Other such rules are as follows:


In government, convention is a set of unwritten rules that participants in the government must follow. These rules can be ignored only if justification is clear, or can be provided. Otherwise, consequences follow. Consequences may include ignoring some other convention that has until now been followed. According to the traditional doctrine (Dicey), conventions cannot be enforced in courts, because they are non-legal sets of rules. Convention is particularly important in the Westminster System of government, where many of the rules are unwritten.

The term "convention" is also used in international law to refer to certain formal statements of principle such as the Convention on the Rights of the Child. Conventions are adopted by international bodies such as the International Labour Organization and the United Nations. Conventions so adopted usually apply only to countries that ratify them, and do not automatically apply to member states of such bodies. These conventions are generally seen as having the force of international treaties for the ratifying countries. The best known of these are perhaps the several Geneva Conventions.




</doc>
<doc id="7832" url="https://en.wikipedia.org/wiki?curid=7832" title="Complete metric space">
Complete metric space

In mathematical analysis, a metric space "M" is called complete (or a Cauchy space) if every Cauchy sequence of points in "M" has a limit that is also in "M" or, alternatively, if every Cauchy sequence in "M" converges in "M".

Intuitively, a space is complete if there are no "points missing" from it (inside or at the boundary). For instance, the set of rational numbers is not complete, because e.g. formula_1 is "missing" from it, even though one can construct a Cauchy sequence of rational numbers that converges to it. (See the examples below.) It is always possible to "fill all the holes", leading to the "completion" of a given space, as explained below.

The space Q of rational numbers, with the standard metric given by the absolute value of the difference, is not complete. Consider for instance the sequence defined by formula_2 and formula_3. This is a Cauchy sequence of rational numbers, but it does not converge towards any rational limit: If the sequence did have a limit "x", then necessarily "x" = 2, yet no rational number has this property. However, considered as a sequence of real numbers, it does converge to the irrational number formula_1.

The open interval , again with the absolute value metric, is not complete either. The sequence defined by "x" = is Cauchy, but does not have a limit in the given space. However the closed interval is complete; for example the given sequence does have a limit in this interval and the limit is zero.

The space R of real numbers and the space C of complex numbers (with the metric given by the absolute value) are complete, and so is Euclidean space R, with the usual distance metric. In contrast, infinite-dimensional normed vector spaces may or may not be complete; those that are complete are Banach spaces. The space C of continuous real-valued functions on a closed and bounded interval is a Banach space, and so a complete metric space, with respect to the supremum norm. However, the supremum norm does not give a norm on the space C of continuous functions on , for it may contain unbounded functions. Instead, with the topology of compact convergence, C can be given the structure of a Fréchet space: a locally convex topological vector space whose topology can be induced by a complete translation-invariant metric.

The space Q of "p"-adic numbers is complete for any prime number "p". This space completes Q with the "p"-adic metric in the same way that R completes Q with the usual metric.

If "S" is an arbitrary set, then the set "S" of all sequences in "S" becomes a complete metric space if we define the distance between the sequences ("x") and ("y") to be , where "N" is the smallest index for which "x" is distinct from "y", or 0 if there is no such index. This space is homeomorphic to the product of a countable number of copies of the discrete space "S".

A metric space "X" is complete if and only if every decreasing sequence of non-empty closed subsets of "X", with diameters tending to 0, has a non-empty intersection: if "F" is closed and non-empty, for every "n", and diam("F") → 0, then there is a point "x" ∈ "X" common to all sets "F".

Every compact metric space is complete, though complete spaces need not be compact. In fact, a metric space is compact if and only if it is complete and totally bounded. This is a generalization of the Heine–Borel theorem, which states that any closed and bounded subspace "S" of R is compact and therefore complete.

Let ("X",d(x,y)) be a complete metric space. If "A"⊆"X" is a closed set, then "A" is also complete. Let ("X",d(x,y)) be a complete metric space. If "A"⊆"X" is a complete set, then "A" is also closed.

If "X" is a set and "M" is a complete metric space, then the set B("X", "M") of all bounded functions "f" from "X" to "M" is a complete metric space. Here we define the distance in B("X", "M") in terms of the distance in "M" with the supremum norm

If "X" is a topological space and "M" is a complete metric space, then the set C("X", "M") consisting of all continuous bounded functions "f" from "X" to "M" is a closed subspace of B("X", "M") and hence also complete.

The Baire category theorem says that every complete metric space is a Baire space. That is, the union of countably many nowhere dense subsets of the space has empty interior.

The Banach fixed point theorem states that a contraction mapping on a complete metric space admits a fixed point. The fixed point theorem is often used to prove the inverse function theorem on complete metric spaces such as Banach spaces.

The expansion constant of a metric space is the infimum of all constants formula_6 such that whenever the family formula_7 intersects pairwise, the intersection

is nonempty. A metric space is complete if and only if its expansion constant is ≤ 2.

For any metric space "M", one can construct a complete metric space "M′" (which is also denoted as ), which contains "M" as a dense subspace. It has the following universal property: if "N" is any complete metric space and "f" is any uniformly continuous function from "M" to "N", then there exists a unique uniformly continuous function "f′" from "M′" to "N", which extends "f". The space "M"' is determined up to isometry by this property, and is called the "completion" of "M".

The completion of "M" can be constructed as a set of equivalence classes of Cauchy sequences in "M". For any two Cauchy sequences x=("x") and y=("y") in "M", we may define their distance as

(This limit exists because the real numbers are complete.) This is only a pseudometric, not yet a metric, since two different Cauchy sequences may have the distance 0. But "having distance 0" is an equivalence relation on the set of all Cauchy sequences, and the set of equivalence classes is a metric space, the completion of "M". The original space is embedded in this space via the identification of an element "x" of "M" with the equivalence class of sequences converging to "x" (i.e., the equivalence class containing the sequence with constant value "x"). This defines an isometry onto a dense subspace, as required. Notice, however, that this construction makes explicit use of the completeness of the real numbers, so completion of the rational numbers needs a slightly different treatment.

Cantor's construction of the real numbers is similar to the above construction; the real numbers are the completion of the rational numbers using the ordinary absolute value to measure distances. The additional subtlety to contend with is that it is not logically permissible to use the completeness of the real numbers in their own construction. Nevertheless, equivalence classes of Cauchy sequences are defined as above, and the set of equivalence classes is easily shown to be a field that has the rational numbers as a subfield. This field is complete, admits a natural total ordering, and is the unique totally ordered complete field (up to isomorphism). It is "defined" as the field of real numbers (see also Construction of the real numbers for more details). One way to visualize this identification with the real numbers as usually viewed is that the equivalence class consisting of those Cauchy sequences of rational numbers that "ought" to have a given real limit is identified with that real number. The truncations of the decimal expansion give just one choice of Cauchy sequence in the relevant equivalence class.

For a prime "p", the "p"-adic numbers arise by completing the rational numbers with respect to a different metric.

If the earlier completion procedure is applied to a normed vector space, the result is a Banach space containing the original space as a dense subspace, and if it is applied to an inner product space, the result is a Hilbert space containing the original space as a dense subspace.

Note that completeness is a property of the "metric" and not of the "topology", meaning that a complete metric space can be homeomorphic to a non-complete one. An example is given by the real numbers, which are complete but homeomorphic to the open interval , which is not complete.

In topology one considers "completely metrizable spaces", spaces for which there exists at least one complete metric inducing the given topology. Completely metrizable spaces can be characterized as those spaces that can be written as an intersection of countably many open subsets of some complete metric space. Since the conclusion of the Baire category theorem is purely topological, it applies to these spaces as well.

Completely metrizable spaces are often called "topologically complete". However, the latter term is somewhat arbitrary since metric is not the most general structure on a topological space for which one can talk about completeness (see the section Alternatives and generalizations). Indeed, some authors use the term "topologically complete" for a wider class of topological spaces, the completely uniformizable spaces.

A topological space homeomorphic to a separable complete metric space is called a Polish space.

Since Cauchy sequences can also be defined in general topological groups, an alternative to relying on a metric structure for defining completeness and constructing the completion of a space is to use a group structure. This is most often seen in the context of topological vector spaces, but requires only the existence of a continuous "subtraction" operation. In this setting, the distance between two points "x" and "y" is gauged not by a real number "ε" via the metric "d" in the comparison "d"("x", "y") < "ε", but by an open neighbourhood "N" of 0 via subtraction in the comparison "x" − "y" ∈ "N".

A common generalisation of these definitions can be found in the context of a uniform space, where an entourage is a set of all pairs of points that are at no more than a particular "distance" from each other.

It is also possible to replace Cauchy "sequences" in the definition of completeness by Cauchy "nets" or Cauchy filters. If every Cauchy net (or equivalently every Cauchy filter) has a limit in "X", then "X" is called complete. One can furthermore construct a completion for an arbitrary uniform space similar to the completion of metric spaces. The most general situation in which Cauchy nets apply is Cauchy spaces; these too have a notion of completeness and completion just like uniform spaces.




</doc>
<doc id="7833" url="https://en.wikipedia.org/wiki?curid=7833" title="The Amazing Criswell">
The Amazing Criswell

Jeron Criswell King (August 18, 1907 – October 4, 1982), born Jeron Criswell Konig, and known by his stage-name The Amazing Criswell , was an American psychic known for wildly inaccurate predictions. In person, he went by Charles Criswell King, and was sometimes credited as Jeron King Criswell.

Criswell was flamboyant, with spit curled hair, a stentorian style of speaking, and a sequined tuxedo. He owned a coffin in which he claimed to sleep. He grew up in a troubled family in Indiana with relatives who owned a funeral home, and said that he became comfortable with sleeping in caskets in the storeroom. He appeared in two of Ed Wood's films.

Criswell said he had once worked as a radio announcer and news broadcaster. He began buying time on a local Los Angeles television station in the early 1950s to run infomercials for his Criswell Family Vitamins. To fill the time, he began his "Criswell Predicts" part of the show. This made him a minor off-beat celebrity in Los Angeles and around Hollywood, and his friendship with old show-business people such as Mae West and rising fringe celebrities such as Korla Pandit made Criswell an entertaining presence at parties. His fame brought him appearances on "The Jack Paar Show" (1957–1962) which allowed him to publish his predictions in three publications of Spaceway Magazine (February 1955, April 1955, and June 1955), as well as run a weekly syndicated newspaper article starting on September 6th, 1951. He later published three books of predictions; "From Now to the Year 2000", "Your Next Ten Years", and "Forbidden Predictions". He also recorded a long playing record, "Your Incredible Future" (which was later released on CD), featuring 84 minutes of his predictions in his own voice. Criswell appeared in the movies of writer and director Ed Wood. After Criswell's death, his longtime friend Paul Marco released Criswell's song "Someone Walked Over My Grave" on a 7" record which was recorded by Criswell as a memorial song that he wanted released posthumously.

Criswell's predictions were nationally syndicated and he appeared on the television show "Criswell Predicts" on KLAC Channel 13 (now KCOP-13) in Los Angeles as well as being recorded for syndication. His announcer was Bob Shields, who later played the judge on "Divorce Court". Criswell wore heavy makeup in public after his live program was broadcast in Los Angeles. Only selected people were allowed in the KCOP studio during his broadcast.

Criswell wrote several books of predictions, including 1968's "Criswell Predicts: From Now to the Year 2000." In it, he claimed that Denver, Colorado would be struck by a ray from space that would cause all metal to adopt the qualities of rubber, leading to horrific accidents at amusement parks. He predicted mass cannibalism and the end of planet Earth, which he set as happening on August 18, 1999.

Criswell was a student of history. He believed history repeated itself, that the United States were the "modern Romans". Each day, he read the "St. Louis Post-Dispatch" looking for clues for his predictions.

Some sources claim Criswell's most famous prediction was on "The Jack Paar Program" (1962–65) in March 1963, when he predicted that US President John F. Kennedy would not run for reelection in 1964 because something was going to happen to him in November 1963.

Sources say that Criswell never claimed to be a real psychic; however, those who knew him, including actress and fellow "Plan 9" alumna Maila Nurmi ("Vampira"), believed he was. According to writer Charles A. Coulombe, whose family rented an apartment from him, Criswell told Coulombe's father "[I] had the gift, but ... lost it when I started taking money for it."

Criswell married a former speakeasy dancer named Halo Meadows, who once appeared on "You Bet Your Life", and whom Coulombe describes as "quite mad": "Mrs Criswell had a huge standard poodle (named "Buttercup") which she was convinced was the reincarnation of her cousin Thomas. She spent a great deal of time sunbathing ... which, given her size, was not too pleasing a sight."

Mae West used Criswell as her personal psychic; he once predicted her rise to President of the United States, whereupon she, Criswell and George Liberace, the brother of showman Liberace, would take a rocket to the Moon. Criswell and West were great friends and she would lavish him with home-cooked food which she had delivered to the studio that he shared with Maila Nurmi ("Vampira"). It is said that West sold Criswell her old luxury cars for five dollars.

He died in 1982.




</doc>
<doc id="7834" url="https://en.wikipedia.org/wiki?curid=7834" title="Chain reaction">
Chain reaction

A chain reaction is a sequence of reactions where a reactive product or by-product causes additional reactions to take place. In a chain reaction, positive feedback leads to a self-amplifying chain of events.

Chain reactions are one way in which systems which are in thermodynamic non-equilibrium can release energy or increase entropy in order to reach a state of higher entropy. For example, a system may not be able to reach a lower energy state by releasing energy into the environment, because it is hindered or prevented in some way from taking the path that will result in the energy release. If a reaction results in a small energy release making way for more energy releases in an expanding chain, then the system will typically collapse explosively until much or all of the stored energy has been released. 

A macroscopic metaphor for chain reactions is thus a snowball causing a larger snowball until finally an avalanche results ("snowball effect"). This is a result of stored gravitational potential energy seeking a path of release over friction. Chemically, the equivalent to a snow avalanche is a spark causing a forest fire. In nuclear physics, a single stray neutron can result in a prompt critical event, which may finally be energetic enough for a nuclear reactor meltdown or (in a bomb) a nuclear explosion.

Numerous chain reactions can be represented by a mathematical model based on Markov chains.

In 1913, the German chemist Max Bodenstein first put forth the idea of chemical chain reactions. If two molecules react, not only molecules of the final reaction products are formed, but also some unstable molecules which can further react with the parent molecules with a far larger probability than the initial reactants (In the new reaction, further unstable molecules are formed besides the stable products, and so on ..).

In 1918, Walther Nernst proposed that the photochemical reaction between hydrogen and chlorine is a chain reaction in order to explain what's known as the "quantum yield" phenomena. This means that one photon of light is responsible for the formation of as many as 10 molecules of the product HCl. Nernst suggested that the photon dissociates a Cl molecule into two Cl atoms which each initiate a long chain of reaction steps forming HCl.

In 1923, Danish and Dutch scientists Christian Christiansen and Hendrik Anthony Kramers, in an analysis of the formation of polymers, pointed out that such a chain reaction need not start with a molecule excited by light, but could also start with two molecules colliding violently due to thermal energy as previously proposed for initiation of chemical reactions by van' t Hoff. 

Christiansen and Kramers also noted that if, in one link of the reaction chain, two or more unstable molecules are produced, the reaction chain would branch and grow. The result is in fact an exponential growth, thus giving rise to explosive increases in reaction rates, and indeed to chemical explosions themselves. This was the first proposal for the mechanism of chemical explosions.

A quantitative chain chemical reaction theory was created later on by Soviet physicist Nikolay Semyonov in 1934. Semyonov shared the Nobel Prize in 1956 with Sir Cyril Norman Hinshelwood, who independently developed many of the same quantitative concepts. 

The main types of steps in chain reaction are of the following types.

The "chain length" is defined as the average number of times the propagation cycle is repeated, and equals the overall reaction rate divided by the initiation rate.

Some chain reactions have complex rate equations with fractional order or mixed order kinetics.

The reaction H + Br → 2 HBr proceeds by the following mechanism:




As can be explained using the steady-state approximation, the thermal reaction has an initial rate of fractional order (3/2), and a complete rate equation with a two-term denominator (mixed-order kinetics).


A "nuclear" chain reaction was proposed by Leo Szilard in 1933, shortly after the neutron was discovered, yet more than five years before nuclear fission was first discovered. Szilárd knew of "chemical" chain reactions, and he had been reading about an energy-producing nuclear reaction involving high-energy protons bombarding lithium, demonstrated by John Cockcroft and Ernest Walton, in 1932. Now, Szilárd proposed to use neutrons theoretically produced from certain nuclear reactions in lighter isotopes, to induce further reactions in light isotopes that produced more neutrons. This would in theory produce a chain reaction at the level of the nucleus. He did not envision fission as one of these neutron-producing reactions, since this reaction was not known at the time. Experiments he proposed using beryllium and indium failed.

Later, after fission was discovered in 1938, Szilárd immediately realized the possibility of using neutron-induced fission as the particular nuclear reaction necessary to create a chain-reaction, so long as fission also produced neutrons. In 1939, with Enrico Fermi, Szilárd proved this neutron-multiplying reaction in uranium. In this reaction, a neutron plus a fissionable atom causes a fission resulting in a larger number of neutrons than the single one that was consumed in the initial reaction. Thus was born the practical nuclear chain reaction by the mechanism of neutron-induced nuclear fission.

Specifically, if one or more of the produced neutrons themselves interact with other fissionable nuclei, and these also undergo fission, then there is a possibility that the macroscopic overall fission reaction will not stop, but continue throughout the reaction material. This is then a self-propagating and thus self-sustaining chain reaction. This is the principle for nuclear reactors and atomic bombs.

Demonstration of a self-sustaining nuclear chain reaction was accomplished by Enrico Fermi and others, in the successful operation of Chicago Pile-1, the first artificial nuclear reactor, in late 1942.

An electron avalanche happens between two unconnected electrodes in a gas when an electric field exceeds a certain threshold. Random thermal collisions of gas atoms may result in a few free electrons and positively charged gas ions, in a process called impact ionization. Acceleration of these free electrons in a strong electric field causes them to gain energy, and when they impact other atoms, the energy causes release of new free electrons and ions (ionization), which fuels the same process. If this process happens faster than it is naturally quenched by ions recombining, the new ions multiply in successive cycles until the gas breaks down into a plasma and current flows freely in a discharge.

Electron avalanches are essential to the dielectric breakdown process within gases. The process can culminate in corona discharges, streamers, leaders, or in a spark or continuous electric arc that completely bridges the gap. The process may extends to huge sparks — streamers in lightning discharges propagate by formation of electron avalanches created in the high potential gradient ahead of the streamers' advancing tips. Once begun, avalanches are often intensified by the creation of photoelectrons as a result of ultraviolet radiation emitted by the excited medium's atoms in the aft-tip region. The extremely high temperature of the resulting plasma cracks the surrounding gas molecules and the free ions recombine to create new chemical compounds.

The process can also be used to detect radiation that initiates the process, as the passage of a single particles can amplified to large discharges. This is the mechanism of a Geiger counter and also the visualization possible with a spark chamber and other wire chambers.

An avalanche breakdown process can happen in semiconductors, which in some ways conduct electricity analogously to a mildly ionized gas. Semiconductors rely on free electrons knocked out of the crystal by thermal vibration for conduction. Thus, unlike metals, semiconductors become better conductors the higher the temperature. This sets up conditions for the same type of positive feedback—heat from current flow causes temperature to rise, which increases charge carriers, lowering resistance, and causing more current to flow. This can continue to the point of complete breakdown of normal resistance at a semiconductor junction, and failure of the device (this may be temporary or permanent depending on whether there is physical damage to the crystal). Certain devices, such as avalanche diodes, deliberately make use of the effect.




</doc>
<doc id="7837" url="https://en.wikipedia.org/wiki?curid=7837" title="Caddie">
Caddie

In golf, a caddie (or caddy) is the person who carries a player's bag and clubs, and gives insightful advice and moral support. A good caddie is aware of the challenges and obstacles of the golf course being played, along with the best strategy in playing it. This includes knowing overall yardage, pin placements and club selection. A caddie is not usually an employee of a private club or resort. They are classified as an "independent contractor", meaning that he or she is basically self-employed and does not receive any benefits or perks from his association with the club. Some clubs and resorts do have caddie programs, although benefits are rarely offered. Particularly in Europe, the vast majority of clubs do not offer caddies, and amateur players will commonly carry or pull their own bags.

Traditional caddying involves both the golfer and the caddie walking the course. The caddie is in charge of carrying the player’s bag, and walks ahead of the golfer to locate his ball and calculate the yardage to the pin and/or hazards. This is the most common method used in golf clubs and is the only method allowed in the PGA (Professional Golf Association) and LPGA (Ladies Professional Golf Association). The three "ups" of caddying are: show up, shut up, and keep up.

Fore-Caddying entails the caddie walking while the players ride in carts. The fore-caddie will give a hole description and then walk ahead to spot the players tee shots. The caddie then gets the players yardage (either with a GPS watch, laser, course knowledge, or sprinkler heads) while the players drive their carts from the tee to their shots. The caddie walks ahead again to spot the golfers next shots. This process is continued until the players reach the green. Once on the green the caddie will read greens (if asked per proper golf etiquette), clean golf balls (if asked), fix ball marks, and attend the flag. The caddie is also responsible for raking traps on the course. Caddies will help with club selection, reading greens, weather variables, and marking balls on the green but should do so only if asked by the player. More than anything else, the caddie is there to make the player's round enjoyable by taking care of menial tasks, speeding up play, and providing mental support if asked.

Many clubs use a ranking system. Caddies will start as a trainee, and be promoted through the ranks of Intermediate, Captain, Honor, and finally Championship. Many courses start their caddies off at the B level, and after a year move them to A, and on their fourth year (if they have earned it), they will receive the title of Honor caddie. The intermediate and captain ranks can usually be obtained within the first year of caddying, and the honor rank is usually obtained in the second or third year of caddying. Championship takes at least 6 years and often as many as 10 years to obtain. An alternative ranking system often used in the American Mid-West proceeds as B level, A level, AA level, Honor level, and Evans Scholar. Caddies often obtain a promotion in rank once a year, while often Honor takes two years to achieve and Evans Scholars are only produced by winning the venerable Evans Scholarship for university. However, in many American clubs, caddies are divided simply between "B" caddies (usually younger, less experienced caddies who often carry only one bag), and "A" caddies (usually older, more experienced caddies who almost always carry two bags).

Caddies are most frequently employed at clubs on weekends, when the majority of country club golf takes place. Some (but usually not as many) opportunities to caddie exist during the week, as well. Additionally, caddies are often allowed to play the course at which they caddie for free, usually on a Monday (the day that most private clubs choose to close their course for maintenance). On pro golf tours, professional caddies accompany their player to all events, which usually take place from Thursday through Sunday. Additionally, the player may hire their caddie to carry their bag for them during training sessions and practice rounds.

At most clubs, caddies are paid at the end of the round by cash, or receive a payment ticket for which they can redeem their wages in the clubhouse. Generally, the player will tip the caddie based on their performance during the round, with extra money given for exemplary work. Most American club caddies earn between $80 and $120 per bag, though newer caddies will often earn less than more experienced caddies. Caddies working during a tournament, high-stakes match, or 4-Day member-guest will often earn significantly more, upwards of $150 per round, per bag, at times. It is common for experienced caddies to carry two bags at a time. It is considered acceptable to ask a professional at the course what the average pay for a caddie is, as courses differ.

In a professional golf tour setting, a player often pays their caddie a percentage of their winnings, which can be as high as 10%. A common pay scale is 5% for making the cut, 7% for a top 10, and 10% for a win. The caddie also usually receives a salary, as the player is not guaranteed to win money at every tournament.




</doc>
<doc id="7838" url="https://en.wikipedia.org/wiki?curid=7838" title="Compound turbine">
Compound turbine

A compound turbine is a steam turbine in which there are two casings, a high-pressure casing and a low-pressure casing, operating in concert to extract work from a single source of steam. The steam is partially expanded in the high-pressure casing, then exhausted to the low-pressure casing. 

The rotor arrangement can be either tandem-compound in which the two axles are joined end to end, or cross-compound in which the two turbines have separate axles. In the cross-compound case two separate generators are usually supplied, although a gearbox can reduce this to one.

The principal advantages of compound turbines are the reduction in size of any one casing, the confinement of the highest pressure to the smaller casing (which may be made of stronger and more expensive materials) and the possibility of divided flow in the low-pressure casing for the purpose of equalizing end thrusts.



</doc>
<doc id="7839" url="https://en.wikipedia.org/wiki?curid=7839" title="Corona">
Corona

A corona (Latin, 'crown') is an aura of plasma that surrounds the Sun and other stars. The Sun's corona extends millions of kilometres into space and is most easily seen during a total solar eclipse, but it is also observable with a coronagraph. The word "corona" is a Latin word meaning "crown", from the Ancient Greek κορώνη (korōnè, “garland, wreath”).

The high temperature of the Sun's corona gives it unusual spectral features, which led some in the 19th century to suggest that it contained a previously unknown element, "coronium". Instead, these spectral features have since been explained by highly ionized iron (Fe-XIV, or Fe). Bengt Edlén, following the work of Grotrian (1939), first identified the coronal spectral lines in 1940 (observed since 1869) as transitions from low-lying metastable levels of the ground configuration of highly ionised metals (the green Fe-XIV line from Fe at 5303 Å, but also the red Fe-X line from Fe at 6374 Å). These high stages of ionisation indicate a plasma temperature in excess of 1,000,000 kelvins, much hotter than the surface of the Sun.

Light from the corona comes from three primary sources, from the same volume of space. The K-corona (K for "kontinuierlich", "continuous" in German) is created by sunlight scattering off free electrons; Doppler broadening of the reflected photospheric absorption lines spreads them so greatly as to completely obscure them, giving the spectral appearance of a continuum with no absorption lines. The F-corona (F for Fraunhofer) is created by sunlight bouncing off dust particles, and is observable because its light contains the Fraunhofer absorption lines that are seen in raw sunlight; the F-corona extends to very high elongation angles from the Sun, where it is called the zodiacal light. The E-corona (E for emission) is due to spectral emission lines produced by ions that are present in the coronal plasma; it may be observed in broad or forbidden or hot spectral emission lines and is the main source of information about the corona's composition.

The sun's corona is much hotter (by a factor from 150 to 450) than the visible surface of the Sun: the photosphere's average temperature is 5800 kelvins compared to the corona's one to three million kelvins. The corona is 10 times as dense as the photosphere, and so produces about one-millionth as much visible light. The corona is separated from the photosphere by the relatively shallow chromosphere. The exact mechanism by which the corona is heated is still the subject of some debate, but likely possibilities include induction by the Sun's magnetic field and magnetohydrodynamic waves from below. The outer edges of the Sun's corona are constantly being transported away due to open magnetic flux and hence generating the solar wind.

The corona is not always evenly distributed across the surface of the sun. During periods of quiet, the corona is more or less confined to the equatorial regions, with coronal holes covering the polar regions. However, during the Sun's active periods, the corona is evenly distributed over the equatorial and polar regions, though it is most prominent in areas with sunspot activity. The solar cycle spans approximately 11 years, from solar minimum to the following minimum. Since the solar magnetic field is continually wound up due to the faster rotation of mass at the sun's equator (differential rotation), sunspot activity will be more pronounced at solar maximum where the magnetic field is more twisted. Associated with sunspots are coronal loops, loops of magnetic flux, upwelling from the solar interior. The magnetic flux pushes the hotter photosphere aside, exposing the cooler plasma below, thus creating the relatively dark sun spots.

Since the corona has been photographed at high resolution in the X-ray range of the spectrum by the satellite Skylab in 1973, and then later by Yohkoh and the other following space instruments, it has been seen that the structure of the corona is quite varied and complex: different zones have been immediately classified on the coronal disc.
The astronomers usually distinguish several regions, as described below.

Active regions are ensembles of loop structures connecting points of opposite magnetic polarity in the photosphere, the so-called coronal loops.
They generally distribute in two zones of activity, which are parallel to the solar equator. The average temperature is between two and four million kelvins, while the density goes from 10 to 10 particle per cm.
Active regions involve all the phenomena directly linked to the magnetic field, which occur at different heights above the Sun's surface: sunspots and faculae, occur in the photosphere, spicules, Hα filaments and plages in the chromosphere, prominences in the chromosphere and transition region, and flares and coronal mass ejections happen in the corona and chromosphere. If flares are very violent, they can also perturb the photosphere and generate a Moreton wave. On the contrary, quiescent prominences are large, cool dense structures which are observed as dark, "snake-like" Hα ribbons (appearing like filaments) on the solar disc. Their temperature is about 5000–8000 K, and so they are usually considered as chromospheric features.

In 2013, images from the High Resolution Coronal Imager revealed never-before-seen "magnetic braids" of plasma within the outer layers of these active regions.

Coronal loops are the basic structures of the magnetic solar corona. These loops are the closed-magnetic flux cousins of the open-magnetic flux that can be found in coronal hole (polar) regions and the solar wind. Loops of magnetic flux well-up from the solar body and fill with hot solar plasma. Due to the heightened magnetic activity in these coronal loop regions, coronal loops can often be the precursor to solar flares and coronal mass ejections (CMEs).

The Solar plasma that feed these structures is heated from under 6000 K to well over 10 K from the photosphere, through the transition region, and into the corona. Often, the solar plasma will fill these loops from one point and drain to another, called foot points (siphon flow due to a pressure difference, or asymmetric flow due to some other driver).

When the plasma rises from the foot points towards the loop top, as always occurs during the initial phase of a compact flare, it is defined as chromospheric evaporation. When the plasma rapidly cools and falls toward the photosphere, it is called chromospheric condensation. There may also be symmetric flow from both loop foot points, causing a build-up of mass in the loop structure. The plasma may cool rapidly in this region (for a thermal instability), its dark filaments obvious against the solar disk or prominences off the Sun's limb.

Coronal loops may have lifetimes in the order of seconds (in the case of flare events), minutes, hours or days. Where there is a balance in loop energy sources and sinks, coronal loops can last for long periods of time and are known as "steady state" or "quiescent" coronal loops. ().

Coronal loops are very important to our understanding of the current "coronal heating problem". Coronal loops are highly radiating sources of plasma and are therefore easy to observe by instruments such as "TRACE". An explanation of the coronal heating problem remains as these structures are being observed remotely, where many ambiguities are present (i.e. radiation contributions along the LOS). "In-situ" measurements are required before a definitive answer can be had, but due to the high plasma temperatures in the corona, "in-situ" measurements are, at present, impossible. The next mission of the NASA, the Parker Solar Probe will approach the Sun very closely allowing more direct observations.

Large-scale structures are very long arcs which can cover over a quarter of the solar disk but contain plasma less dense than in the coronal loops of the active regions.

They were first detected in the June 8, 1968 flare observation during a rocket flight.

The large-scale structure of the corona changes over the 11-year solar cycle and becomes particularly simple during the minimum period, when the magnetic field of the Sun is almost similar to a dipolar configuration (plus a quadrupolar component).

The interconnections of active regions are arcs connecting zones of opposite magnetic field, of different active regions. Significant variations of these structures are often seen after a flare.

Some other features of this kind are helmet streamers—large cap-like coronal structures with long pointed peaks that usually overlie sunspots and active regions. Coronal streamers are considered as sources of the slow solar wind.

Filament cavities are zones which look dark in the X-rays and are above the regions where Hα filaments are observed in the chromosphere. They were first observed in the two 1970 rocket flights which also detected "coronal holes".

Filament cavities are cooler clouds of gases (plasma) suspended above the Sun's surface by magnetic forces. The regions of intense magnetic field look dark in images because they are empty of hot plasma. In fact, the sum of the magnetic pressure and plasma pressure must be constant everywhere on the heliosphere in order to have an equilibrium configuration: where the magnetic field is higher, the plasma must be cooler or less dense. The plasma pressure formula_1 can be calculated by the state equation of a perfect gas formula_2, where formula_3 is the particle number density, formula_4 the Boltzmann constant and formula_5 the plasma temperature. It is evident from the equation that the plasma pressure lowers when the plasma temperature decreases with respect to the surrounding regions or when the zone of intense magnetic field empties. The same physical effect renders sunspots apparently dark in the photosphere.

Bright points are small active regions found on the solar disk. X-ray bright points were first detected on April 8, 1969 during a rocket flight.

The fraction of the solar surface covered by bright points varies with the solar cycle. They are associated with small bipolar regions of the magnetic field. Their average temperature ranges from 1.1x10 K to 3.4x10 K. The variations in temperature are often correlated with changes in the X-ray emission.

Coronal holes are the Polar Regions which look dark in the X-rays since they do not emit much radiation. These are wide zones of the Sun where the magnetic field is unipolar and opens towards the interplanetary space. The high speed solar wind arises mainly from these regions.

In the UV images of the coronal holes, some small structures, similar to elongated bubbles, are often seen as they were suspended in the solar wind. These are the coronal plumes. More exactly, they are long thin streamers that project outward from the Sun's north and south poles.

The solar regions which are not part of active regions and coronal holes are commonly identified as the quiet Sun.

The equatorial region has a faster rotation speed than the polar zones. The result of the Sun's differential rotation is that the active regions always arise in two bands parallel to the equator and their extension increases during the periods of maximum of the solar cycle, while they almost disappear during each minimum. Therefore, the quiet Sun always coincides with the equatorial zone and its surface is less active during the maximum of the solar cycle. Approaching the minimum of the solar cycle (also named butterfly cycle), the extension of the quiet Sun increases until it covers the whole disk surface excluding some bright points on the hemisphere and the poles, where there are the coronal holes.

A portrait as diversified as the one already pointed out for the coronal features is emphasized by the analysis of the dynamics of the main structures of the corona, which evolve in times very different among them. Studying the coronal variability in its complexity is not easy because the times of evolution of the different structures can vary considerably: from seconds to several months. The typical sizes of the regions where coronal events take place vary in the same way, as it is shown in the following table.

Flares take place in active regions and are characterized by a sudden increase of the radiative flux emitted from small regions of the corona. They are very complex phenomena, visible at different wavelengths; they involve several zones of the solar atmosphere and many physical effects, thermal and not thermal, and sometimes wide reconnections of the magnetic field lines with material expulsion.

Flares are impulsive phenomena, of average duration of 15 minutes, and the most energetic events can last several hours. Flares produce a high and rapid increase of the density and temperature.

An emission in white light is only seldom observed: usually, flares are only seen at extreme UV wavelengths and into the X-rays, typical of the chromospheric and coronal emission.

In the corona, the morphology of flares, is described by observations in the UV, soft and hard X-rays, and in Hα wavelengths, and is very complex. However, two kinds of basic structures can be distinguished:

As for temporal dynamics, three different phases are generally distinguished, whose duration are not comparable. The durations of those periods depend on the range of wavelengths used to observe the event:
Sometimes also a phase preceding the flare can be observed, usually called as "pre-flare" phase.

Accompanying solar flares or large solar prominences, "coronal transients" (also called coronal mass ejections) are sometimes released. These are enormous loops of coronal material that travel outward from the Sun at over a million kilometers per hour, containing roughly 10 times the energy of the solar flare or prominence that accompanies them. Some larger ejections can propel hundreds of millions of tons of material into space at roughly 1.5 million kilometers an hour.

Coronal stars are ubiquitous among the stars in the cool half of the Hertzsprung–Russell diagram. These coronae can be detected using X-ray telescopes. Some stellar coronae, particularly in young stars, are much more luminous than the Sun's. For example, FK Comae Berenices is the prototype for the FK Com class of variable star. These are giants of spectral types G and K with an unusually rapid rotation and signs of extreme activity. Their X-ray coronae are among the most luminous ("L" ≥ 10 erg·s or 10W) and the hottest known with dominant temperatures up to 40 MK.

The astronomical observations planned with the Einstein Observatory by Giuseppe Vaiana and his group showed that F-, G-, K- and M-stars have chromospheres and often coronae much like our Sun.
The "O-B stars", which do not have surface convection zones, have a strong X-ray emission. However these stars do not have coronae, but the outer stellar envelopes emit this radiation during shocks due to thermal instabilities in rapidly moving gas blobs.
Also A-stars do not have convection zones but they do not emit at the UV and X-ray wavelengths. Thus they appear to have neither chromospheres nor coronae.

The matter in the external part of the solar atmosphere is in the state of plasma, at very high temperature (a few million kelvins) and at very low density (of the order of 10 particles/m).
According to the definition of plasma, it is a quasi-neutral ensemble of particles which exhibits a collective behaviour.

The composition is similar to that in the Sun's interior, mainly hydrogen, but with much greater ionization than that found in the photosphere. Heavier metals, such as iron, are partially ionized and have lost most of the external electrons. The ionization state of a chemical element depends strictly on the temperature and is regulated by the Saha equation in the lowest atmosphere, but by collisional equilibrium in the optically-thin corona. Historically, the presence of the spectral lines emitted from highly ionized states of iron allowed determination of the high temperature of the coronal plasma, revealing that the corona is much hotter than the internal layers of the chromosphere.

The corona behaves like a gas which is very hot but very light at the same time: the pressure in the corona is usually only 0.1 to 0.6 Pa in active regions, while on the Earth the atmospheric pressure is about 100 kPa, approximately a million times higher than on the solar surface.
However it is not properly a gas, because it is made of charged particles, basically protons and electrons, moving at different velocities.
Supposing that they have the same kinetic energy on average
(for the equipartition theorem), electrons have a mass roughly 1800 times smaller than protons, therefore they acquire more velocity. Metal ions are always slower. This fact has relevant physical consequences either on radiative processes (that are very different from the photospheric radiative processes), or on thermal conduction.
Furthermore, the presence of electric charges induces the generation of electric currents and high magnetic fields.
Magnetohydrodynamic waves (MHD waves) can also propagate in this plasma, even if it is not still clear how they can be transmitted or generated in the corona.

The corona emits radiation mainly in the X-rays, observable only from space.

The plasma is transparent to its own radiation and to that one coming from below, therefore we say that it is optically-thin. The gas, in fact, is very rarefied and the photon mean free-path overcomes by far all the other length-scales, including the typical sizes of the coronal features.

Different processes of radiation take place in the emission, due to binary collisions between plasma particles, while the interactions with the photons, coming from below; are very rare.
Because the emission is due to collisions between ions and electrons, the energy emitted from a unit volume in the time unit is proportional to the squared number of particles in a unit volume, or more exactly, to the product of the electron density and proton density.

In the corona thermal conduction occurs from the external hotter atmosphere towards the inner cooler layers. Responsible for the diffusion process of the heat are the electrons, which are much lighter than ions and move faster, as explained above.

When there is a magnetic field the thermal conductivity of the plasma becomes higher in the direction which is parallel to the field lines rather than in the perpendicular direction.
A charged particle moving in the direction perpendicular to the magnetic field line is subject to the Lorentz force which is normal to the plane individuated by the velocity and the magnetic field. This force bends the path of the particle. In general, since particles also have a velocity component along the magnetic field line, the Lorentz force constrains them to bend and move along spirals around the field lines at the cyclotron frequency.

If collisions between the particles are very frequent, they are scattered in every direction. This happens in the photosphere, where the plasma carries the magnetic field in its motion. In the corona, on the contrary, the mean free-path of the electrons is of the order of kilometres and even more, so each electron can do a helicoidal motion long before being scattered after a collision. Therefore, the heat transfer is enhanced along the magnetic field lines and inhibited in the perpendicular direction.

In the direction longitudinal to the magnetic field, the thermal conductivity of the corona is

formula_6

where formula_7 is the Boltzmann constant,
formula_5 is the temperature in kelvins,
formula_9 the electron mass,
formula_10 the electric charge of the electron,

formula_11

the Coulomb logarithm, and

formula_12

the Debye length of the plasma with particle density formula_3.
The Coulomb logarithm formula_14 is roughly 20 in the corona, with a mean temperature of 1 MK and a density of 10 particles/m, and about 10 in the chromosphere, where the temperature is approximately 10kK and the particle density is of the order of 10 particles/m, and in practice it can be assumed constant.

Thence, if we indicate with formula_15 the heat for a volume unit, expressed in J m, the Fourier equation of heat transfer, to be computed only along the direction formula_16 of the field line, becomes

formula_17.

Numerical calculations have shown that the thermal conductivity of the corona is comparable to that of copper.

Coronal seismology is a new way of studying the plasma of the solar corona with the use of magnetohydrodynamic (MHD) waves. Magnetohydrodynamics studies the dynamics of electrically conducting fluids—in this case the fluid is the coronal plasma. Philosophically, coronal seismology is similar to the Earth's seismology, the Sun's helioseismology, and MHD spectroscopy of laboratory plasma devices. In all these approaches, waves of various kinds are used to probe a medium. The potential of coronal seismology in the estimation of the coronal magnetic field, density scale height, fine structure and heating has been demonstrated by different research groups.

The coronal heating problem in solar physics relates to the question of why the temperature of the Sun's corona is millions of kelvins higher than that of the surface. The high temperatures require energy to be carried from the solar interior to the corona by non-thermal processes, because the second law of thermodynamics prevents heat from flowing directly from the solar photosphere (surface), which is at about 5800 K, to the much hotter corona at about 1 to 3 MK (parts of the corona can even reach 10 MK).

Between the photosphere and the corona, is the thin region through which the temperature increases known as the transition region. It ranges from only tens to hundreds of kilometers thick. Energy cannot be transferred from the cooler photosphere to the corona by conventional heat transfer as this would violate the second law of thermodynamics. An analogy of this would be a light bulb raising the temperature of the air surrounding it to something greater than its glass surface. Hence, some other manner of energy transfer must be involved in the heating of the corona.

The amount of power required to heat the solar corona can easily be calculated as the difference between coronal radiative losses and heating by thermal conduction toward the chromosphere through the transition region. It is about 1 kilowatt for every square meter of surface area on the Sun's chromosphere, or 1/40000 of the amount of light energy that escapes the Sun.

Many coronal heating theories have been proposed, but two theories have remained as the most likely candidates: wave heating and magnetic reconnection (or nanoflares). Through most of the past 50 years, neither theory has been able to account for the extreme coronal temperatures.

In 2012, high resolution (<0.2″) soft X-ray imaging with the High Resolution Coronal Imager aboard a sounding rocket revealed tightly wound braids in the corona. It is hypothesized that the reconnection and unravelling of braids can act as primary sources of heating of the active solar corona to temperatures of up to 4 million kelvins. The main heat source in the quiescent corona (about 1.5 million kelvins) is assumed to originate from MHD waves.

The NASA mission Parker Solar Probe is intended to approach the Sun to a distance of approximately 9.5 solar radii to investigate coronal heating and the origin of the solar wind. It is scheduled to launch on July 31, 2018.

The wave heating theory, proposed in 1949 by Evry Schatzman, proposes that waves carry energy from the solar interior to the solar chromosphere and corona. The Sun is made of plasma rather than ordinary gas, so it supports several types of waves analogous to sound waves in air. The most important types of wave are magneto-acoustic waves and Alfvén waves. Magneto-acoustic waves are sound waves that have been modified by the presence of a magnetic field, and Alfvén waves are similar to ultra low frequency radio waves that have been modified by interaction with matter in the plasma. Both types of waves can be launched by the turbulence of granulation and super granulation at the solar photosphere, and both types of waves can carry energy for some distance through the solar atmosphere before turning into shock waves that dissipate their energy as heat.

One problem with wave heating is delivery of the heat to the appropriate place. Magneto-acoustic waves cannot carry sufficient energy upward through the chromosphere to the corona, both because of the low pressure present in the chromosphere and because they tend to be reflected back to the photosphere. Alfvén waves can carry enough energy, but do not dissipate that energy rapidly enough once they enter the corona. Waves in plasmas are notoriously difficult to understand and describe analytically, but computer simulations, carried out by Thomas Bogdan and colleagues in 2003, seem to show that Alfvén waves can transmute into other wave modes at the base of the corona, providing a pathway that can carry large amounts of energy from the photosphere through the chromosphere and transition region and finally into the corona where it dissipates it as heat.

Another problem with wave heating has been the complete absence, until the late 1990s, of any direct evidence of waves propagating through the solar corona. The first direct observation of waves propagating into and through the solar corona was made in 1997 with the Solar and Heliospheric Observatory space-borne solar observatory, the first platform capable of observing the Sun in the extreme ultraviolet (EUV) for long periods of time with stable photometry. Those were magneto-acoustic waves with a frequency of about 1 millihertz (mHz, corresponding to a 1,000 second wave period), that carry only about 10% of the energy required to heat the corona. Many observations exist of localized wave phenomena, such as Alfvén waves launched by solar flares, but those events are transient and cannot explain the uniform coronal heat.

It is not yet known exactly how much wave energy is available to heat the corona. Results published in 2004 using data from the TRACE spacecraft seem to indicate that there are waves in the solar atmosphere at frequencies as high as 100 mHz (10 second period). Measurements of the temperature of different ions in the solar wind with the UVCS instrument aboard SOHO give strong indirect evidence that there are waves at frequencies as high as 200 Hz, well into the range of human hearing. These waves are very difficult to detect under normal circumstances, but evidence collected during solar eclipses by teams from Williams College suggest the presences of such waves in the 1–10 Hz range.

Recently, Alfvénic motions have been found in the lower solar atmosphere 
These Alfvénic oscillations have significant power, and seem to be connected to the chromospheric Alfvénic oscillations previously reported with the Hinode spacecraft

Solar wind observations with the WIND (spacecraft) have recently shown evidence to support theories of Alfvén-cyclotron dissipation, leading to local ion heating.

The magnetic reconnection theory relies on the solar magnetic field to induce electric currents in the solar corona. The currents then collapse suddenly, releasing energy as heat and wave energy in the corona. This process is called "reconnection" because of the peculiar way that magnetic fields behave in plasma (or any electrically conductive fluid such as mercury or seawater). In a plasma, magnetic field lines are normally tied to individual pieces of matter, so that the topology of the magnetic field remains the same: if a particular north and south magnetic pole are connected by a single field line, then even if the plasma is stirred or if the magnets are moved around, that field line will continue to connect those particular poles. The connection is maintained by electric currents that are induced in the plasma. Under certain conditions, the electric currents can collapse, allowing the magnetic field to "reconnect" to other magnetic poles and release heat and wave energy in the process.

Magnetic reconnection is hypothesized to be the mechanism behind solar flares, the largest explosions in our solar system. Furthermore, the surface of the Sun is covered with millions of small magnetized regions 50–1,000 km across. These small magnetic poles are buffeted and churned by the constant granulation. The magnetic field in the solar corona must undergo nearly constant reconnection to match the motion of this "magnetic carpet", so the energy released by the reconnection is a natural candidate for the coronal heat, perhaps as a series of "microflares" that individually provide very little energy but together account for the required energy.

The idea that nanoflares might heat the corona was proposed by Eugene Parker in the 1980s but is still controversial. In particular, ultraviolet telescopes such as TRACE and SOHO/EIT can observe individual micro-flares as small brightenings in extreme ultraviolet light, but there seem to be too few of these small events to account for the energy released into the corona. The additional energy not accounted for could be made up by wave energy, or by gradual magnetic reconnection that releases energy more smoothly than micro-flares and therefore doesn't appear well in the TRACE data. Variations on the micro-flare hypothesis use other mechanisms to stress the magnetic field or to release the energy, and are a subject of active research in 2005.

For decades, researchers believed spicules could send heat into the corona. However, following observational research in the 1980s, it was found that spicule plasma did not reach coronal temperatures, and so the theory was discounted.

As per studies performed in 2010 at the "National Center for Atmospheric Research" in Colorado, in collaboration with the "Lockheed Martin's Solar and Astrophysics Laboratory" (LMSAL) and the "Institute of Theoretical Astrophysics" of the University of Oslo, a new class of spicules (TYPE II) discovered in 2007, which travel faster (up to 100 km/s) and have shorter lifespans, can account for the problem. These jets insert heated plasma into the Sun's outer atmosphere.

Thus, a much greater understanding of the Corona and improvement in the knowledge of the Sun's subtle influence on the Earth's upper atmosphere can be expected henceforth. The Atmospheric Imaging Assembly on NASA's recently launched Solar Dynamics Observatory and NASA's Focal Plane Package for the Solar Optical Telescope on the Japanese Hinode satellite which was used to test this hypothesis. The high spatial and temporal resolutions of the newer instruments reveal this coronal mass supply.

These observations reveal a one-to-one connection between plasma that is heated to millions of degrees and the spicules that insert this plasma into the corona.




</doc>
<doc id="7840" url="https://en.wikipedia.org/wiki?curid=7840" title="Chrono Cross">
Chrono Cross

The story of "Chrono Cross" focuses on a teenage boy named Serge and a theme of parallel worlds. Faced with an alternate reality in which he died as a child, Serge endeavors to discover the truth of the two worlds' divergence. The flashy thief Kid and many other characters assist him in his travels around the tropical archipelago El Nido. Struggling to uncover his past and find the mysterious Frozen Flame, Serge is chiefly challenged by Lynx, a shadowy antagonist working to apprehend him.

Upon its release in Japan in 1999 and North America in 2000, "Chrono Cross" received critical acclaim, earning a perfect 10.0 score from GameSpot. The game shipped over copies worldwide, leading to a Greatest Hits re-release and continued life in Japan as part of the Ultimate Hits series. "Chrono Cross" was later re-released for the PlayStation Network in Japan in July 2011, and in North America four months later.

"Chrono Cross" features standard role-playing video game gameplay with some differences. Players advance the game by controlling the protagonist Serge through the game's world, primarily by foot and boat. Navigation between areas is conducted via an overworld map, much like "Chrono Trigger's", depicting the landscape from a scaled-down overhead view. Around the island world are villages, outdoor areas, and dungeons, through which the player moves in three dimensions. Locations such as cities and forests are represented by more realistically scaled field maps, in which players can converse with locals to procure items and services, solve puzzles and challenges, or encounter enemies. Like "Chrono Trigger", the game features no random encounters; enemies are openly visible on field maps or lie in wait to ambush the party. Touching the monster switches perspectives to a battle screen, in which players can physically attack, use "Elements", defend, or run away from the enemy. Battles are turn-based, allowing the player infinite time to select an action from the available menu. For both the playable characters and the computer-controlled enemies, each attack reduces their number of hit points (a numerically based life bar), which can be restored through some Elements. When a playable character loses all hit points, he or she faints. If all the player's characters fall in battle, the game ends and must be restored from a previously saved chapter—except for specific storyline-related battles that allow the player to lose. "Chrono Cross"<nowiki>'</nowiki>s developers aimed to break new ground in the genre, and the game features several innovations. For example, players can run away from all conflicts, including boss fights and the final battle.

The Element system of "Chrono Cross" handles all magic, consumable items, and character-specific abilities. Elements unleash magic effects upon the enemy or party and must be equipped for use, much like the materia of 1997's "Final Fantasy VII". Elements can be purchased from shops or found in treasure chests littered throughout areas. Once acquired, they are allocated to a grid whose size and shape are unique to each character. They are ranked according to eight tiers; certain high level Elements can only be assigned on equivalent tiers in a character's grid. As the game progresses, the grid expands, allowing more Elements to be equipped and higher tiers to be accessed. Elements are divided into six paired oppositional types, or "colors," each with a natural effect. Red (fire/magma) opposes Blue (water/ice), Green (wind/flora) opposes Yellow (earth/lightning), and White (light/cosmos) opposes Black (darkness/gravity). Each character and enemy has an innate color, enhancing the power of using same-color Elements while also making them weak against elements of the opposite color. "Chrono Cross" also features a "field effect", which keeps track of Element color used in the upper corner of the battle screen. If the field is purely one color, characters are able to unleash a powerful summon element at the cost of one the player's stars. The field will also enhance the power of Elements of the colors present, while weakening Elements of the opposite colors. Characters also innately learn some special techniques ("Techs") that are unique to each character but otherwise act like Elements. Like "Chrono Trigger", characters can combine certain Techs to make more powerful Double or Triple Techs. Consumable Elements may be used to restore hit points or heal status ailments after battle.

Another innovative aspect of "Chrono Cross" is its stamina bar. At the beginning of a battle, each character has seven points of stamina. When a character attacks or uses an Element, stamina is decreased proportionally to the potency of the attack. Stamina slowly recovers when the character defends or when other characters perform actions in battle. Characters with stamina below one point must wait to take action. Use of an Element reduces the user's stamina bar by seven stamina points; this often means that the user's stamina gauge falls into the negative and the character must wait longer than usual to recover. With each battle, players can enhance statistics such as strength and defense. However, no system of experience points exists; after four or five upgrades, statistics remain static until players defeat a boss. This adds a star to a running count shown on the status screen, which allows for another few rounds of statistical increases. Players can equip characters with weapons, armor, helmets, and accessories for use in battle; for example, the "Power Seal" upgrades attack power. Items and equipment may be purchased or found on field maps, often in treasure chests. Unlike Elements, weapons and armor cannot merely be purchased with money; instead, the player must obtain base materials—such as copper, bronze, or bone—for a blacksmith to forge for a fee. The items can later be disassembled into their original components at no cost.
The existence of two major parallel dimensions, like time periods in "Chrono Trigger", plays a significant role in the game. Players must go back and forth between the worlds to recruit party members, obtain items, and advance the plot. Much of the population of either world have counterparts in the other; some party members can even visit their other versions. The player must often search for items or places found exclusively in one world. Events in one dimension sometimes have an impact in another—for instance, cooling scorched ground on an island in one world allows vegetation to grow in the other world. This system assists the presentation of certain themes, including the questioning of the importance of one's past decisions and humanity's role in destroying the environment. Rounding out the notable facets of "Chrono Cross"<nowiki>'</nowiki>s gameplay are the New Game+ option and multiple endings. As in "Chrono Trigger", players who have completed the game may choose to start the game over using data from the previous session. Character levels, learned techniques, equipment, and items gathered copy over, while acquired money and some story-related items are discarded. On a New Game+, players can access twelve endings. Scenes viewed depend on players' progress in the game before the final battle, which can be fought at any time in a New Game+ file.

"Chrono Cross" features a diverse cast of 45 party members. Each character is outfitted with an innate Element affinity and three unique special abilities that are learned over time. If taken to the world opposite their own, characters react to their counterparts (if available). Many characters tie in to crucial plot events. Since it is impossible to obtain all 45 characters in one playthrough, players must replay the game to witness everything. Through use of the New Game+ feature, players can ultimately obtain all characters on one save file.

Serge, the game's protagonist, is a 17-year-old boy with blue hair who lives in the fishing village of Arni. One day, he slips into an alternate world in which he drowned ten years before. Determined to find the truth behind the incident, he follows a predestined course that leads him to save the world. He is assisted by Kid, a feisty, skilled thief who seeks the mythical Frozen Flame. Portrayed as willful and tomboyish due to her rough, thieving past, she helps Serge sneak into Viper Manor in order to obtain the Frozen Flame. Kid vows to find and defeat Lynx, an anthropomorphic panther who burned down her adopted mother's orphanage.

Lynx, a cruel agent of the supercomputer FATE, is bent on finding Serge and using his body as part of a greater plan involving the Frozen Flame. Lynx travels with Harle, a mysterious, playful girl dressed like a harlequin. Harle was sent by the Dragon God to shadow Lynx and one day steal the Frozen Flame from Chronopolis, a task she painfully fulfills despite being smitten with Serge.

To accomplish this goal, Harle helps Lynx manipulate the Acacia Dragoons, the powerful militia governing the islands of El Nido. As the Dragoons maintain order, they contend with Fargo, a former Dragoon turned pirate captain who holds a grudge against their leader, General Viper. Though tussling with Serge initially, the Acacia Dragoons—whose ranks include the fierce warriors Karsh, Zoah, Marcy, and Glenn—later assist him when the militaristic nation of Porre invades the archipelago. The invasion brings Norris and Grobyc to the islands, a heartful commander of an elite force and a prototype cyborg soldier, respectively, as they too seek the Frozen Flame.

"Chrono Cross" begins with Serge located in El Nido, a tropical archipelago inhabited by ancient natives, mainland colonists, and beings called Demi-humans. Serge slips into an alternate dimension in which he drowned on the beach ten years prior, and meets the thief, "Kid". As his adventure proceeds from here, Serge is able to recruit a multitude of allies to his cause. While assisting Kid in a heist Viper Manor to steal the Frozen Flame, he learns that ten years before the present, the universe split into two dimensions—one in which Serge lived, and one in which he perished. Through Kid's Astral Amulet charm, Serge travels between the dimensions. At Fort Dragonia the use of a Dragonian artifact called the Dragon Tear, Lynx switches bodies with Serge. Unaware of the switch, Kid confides in Lynx, who stabs her as the real Serge helplessly watches. Lynx boasts of his victory and banishes Serge to a strange realm called the Temporal Vortex. He takes Kid under his wing, brainwashing her to believe the real Serge (in Lynx's body) is her enemy. Serge escapes with help from Harle, although his new body turns him into a stranger in his own world, with all the allies he had gained up to that point abandoning him due to his new appearance. Discovering that his new body prevents him from traveling across the dimensions, he sets out to regain his former body and learn more of the universal split that occurred ten years earlier, gaining a new band of allies along the way.. He travels to a forbidden lagoon known as the Dead Sea—a wasteland frozen in time, dotted with futuristic ruins. At the center, he locates a man named Miguel and presumably "Home" world's Frozen Flame. Charged with guarding the Dead Sea by an entity named FATE, Miguel and three visions of Crono, Marle, and Lucca from "Chrono Trigger" explain that Serge's existence dooms "Home" world's future to destruction at the hands of Lavos. To prevent Serge from obtaining the Frozen Flame, FATE destroys the Dead Sea.

Able to return to "Another" world, Serge allies with the Acacia Dragoons against Porre and locates that dimension's Dragon Tear, allowing him to return to his human form. He then enters the Sea of Eden, "Another" world's physical equivalent of the Dead Sea, finding a temporal research facility from the distant future called Chronopolis. Lynx and Kid are inside; Serge defeats Lynx and the supercomputer FATE, allowing the six Dragons of El Nido to steal the Frozen Flame and retire to Terra Tower, a massive structure raised from the sea floor. Kid falls into a coma, and Harle bids the party goodbye to fly with the Dragons. Serge regroups his party and tends to Kid, who remains comatose. Continuing his adventure, he obtains and cleanses the corrupted Masamune sword from "Chrono Trigger". He then uses the Dragon relics and shards of the Dragon Tears to create the mythic Element Chrono Cross. The spiritual power of the Masamune later allows him to lift Kid from her coma. At Terra Tower, the prophet of time, revealed to be Belthasar from "Chrono Trigger", visits him with visions of Crono, Marle, and Lucca. Serge learns that the time research facility Chronopolis created El Nido thousands of years ago after a catastrophic experimental failure drew it to the past. The introduction of a temporally foreign object in history caused the planet to pull in a counterbalance from a different dimension. This was Dinopolis, a city of Dragonians—parallel universe descendants of "Chrono Trigger"<nowiki>'</nowiki>s Reptites. The institutions warred and Chronopolis subjugated the Dragonians. Humans captured their chief creation—the Dragon God, an entity capable of controlling nature.

Chronopolis divided this entity into six pieces and created an Elements system. FATE then terraformed an archipelago, erased the memories of most Chronopolis's staff, and sent them to inhabit and populate its new paradise. Thousands of years later, a panther demon attacked a three-year-old Serge. His father took him to find assistance at Marbule, but Serge's boat blew off course due to a raging magnetic storm caused by Schala. Schala, the princess of the Kingdom of Zeal, had long ago accidentally fallen to a place known as the Darkness Beyond Time and began merging with Lavos, the chief antagonist of "Chrono Trigger". Schala's storm nullified Chronopolis's defenses and allowed Serge to contact the Frozen Flame; approaching it healed Serge but corrupted his father. A circuit in Chronopolis then designated Serge "Arbiter", simultaneously preventing FATE from using the Frozen Flame by extension. The Dragons were aware of this situation, creating a seventh Dragon under the storm's cover named Harle, who manipulated Lynx to steal the Frozen Flame for the Dragons.

After Serge returned home, FATE sent Lynx to kill Serge, hoping that it would release the Arbiter lock. Ten years after Serge drowned, the thief Kid—presumably on Belthasar's orders—went back in time to save Serge and split the dimensions. FATE, locked out of the Frozen Flame again, knew that Serge would one day cross to "Another" world and prepared to apprehend him. Lynx switched bodies with Serge to dupe the biological check of Chronopolis on the Frozen Flame. Belthasar then reveals that these events were part of a plan he had orchestrated named Project Kid. Serge continues to the top of Terra Tower and defeats the Dragon God. Continuing to the beach where the split in dimensions had occurred, Serge finds apparitions of Crono, Marle, and Lucca once more. They reveal that Belthasar's plan was to empower Serge to free Schala from melding with Lavos, lest they evolve into the "Time Devourer", a creature capable of destroying spacetime. Lucca explains that Kid is Schala's clone, sent to the modern age to take part in Project Kid. Serge uses a Time Egg—given to him by Belthasar—to enter the Darkness Beyond Time and vanquish the Time Devourer, separating Schala from Lavos and restores the dimensions to one. Thankful, Schala muses on evolution and the struggle of life and returns Serge to his home, noting that he will forget the entire adventure. She then seemingly records the experience in her diary, noting she will always be searching for Serge in this life and beyond, signing the entry as Schala "Kid" Zeal, implying that she and Kid have merged and became whole again. A wedding photo of Kid and an obscured male sits on the diary's desk. Scenes then depict a real-life Kid searching for someone in a modern city, intending to make players entertain the possibility that their own Kid is searching for them. The ambiguous ending leaves the events of the characters' lives following the game up to interpretation.

"Chrono Cross" employs story arcs, characters, and themes from "", a Satellaview side story to "Chrono Trigger" released in Japan. An illustrated text adventure, "Radical Dreamers" was created to wrap up an unresolved plot line of "Chrono Trigger". Though it borrows from "Radical Dreamers" in its exposition, "Chrono Cross" is not a remake of "Radical Dreamers", but a larger effort to fulfill that game's purpose; the plots of the games are irreconcilable. To resolve continuity issues and acknowledge "Radical Dreamers", the developers of "Chrono Cross" suggested the game happened in a parallel dimension. A notable difference between the two games is that Magus—present in "Radical Dreamers" as Gil—is absent from "Chrono Cross". Director Masato Kato originally planned for Magus to appear in disguise as Guile, but scrapped the idea due to plot difficulties. In the DS version of "Chrono Trigger", Kato teases the possibility of an amnesiac Magus.

Square began planning "Chrono Cross" immediately after the release of "Xenogears" in 1998 (which itself was originally conceived as a sequel to the SNES game). "Chrono Trigger"<nowiki>'</nowiki>s scenario director Masato Kato had brainstormed ideas for a sequel as early as 1996, following the release of "". Square's managers selected a team, appointed Hiromichi Tanaka producer, and asked Kato to direct and develop a new "Chrono" game in the spirit of "Radical Dreamers". Kato thought "Dreamers" was released in a "half-finished state", and wanted to continue the story of the character Kid. Kato and Tanaka decided to produce an indirect sequel. They acknowledged that Square would soon re-release "Chrono Trigger" as part of "Final Fantasy Chronicles", which would give players a chance to catch up on the story of "Trigger" before playing "Cross". Kato thought that using a different setting and cast for "Chrono Cross" would allow players unfamiliar with "Chrono Trigger" to play "Cross" without becoming confused. The "Chrono Cross" team decided against integrating heavy use of time travel into the game, as they thought it would be "rehashing and cranking up the volume of the last game". Masato Kato cited the belief, "there's no use in making something similar to before ", and noted, "we're not so weak nor cheap as to try to make something exactly the same as "Trigger" ... Accordingly, "Chrono Cross" is not "Chrono Trigger 2". It doesn't simply follow on from "Trigger", but is another, different "Chrono" that interlaces with "Trigger"." Kato and Tanaka further explained their intentions after the game's release:

Full production began on "Chrono Cross" in mid-1998. The "Chrono Cross" team reached 80 members at its peak, with additional personnel of 10–20 cut-scene artists and 100 quality assurance testers. The team felt pressure to live up to the work of "Chrono Trigger"<nowiki>'</nowiki>s "Dream Team" development group, which included famous Japanese manga artist Akira Toriyama. Kato and Tanaka hired Nobuteru Yūki for character design and Yasuyuki Honne for art direction and concept art. The event team originally envisioned a short game, and planned a system by which players would befriend any person in a town for alliance in battle. Developers brainstormed traits and archetypes during the character-creation process, originally planning 64 characters with unique endings that could vary in three different ways per character. Kato described the character creation process: "Take Pierre, for example: we started off by saying we wanted a wacko fake hero like Tata from "Trigger". We also said things like 'we need at least one powerful mom', 'no way we're gonna go without a twisted brat', and so on so forth."

As production continued, the length of "Cross" increased, leading the event team to reduce the number of characters to 45 and scrap most of the alternate endings. Developers humorously named the character Pip "Tsumaru" in Japanese (which means "packed") as a pun on their attempts to pack as much content into the game as possible. To avoid the burden of writing unique, accented dialogue for several characters, team member Kiyoshi Yoshii coded a system that produces accents by modifying basic text for certain characters. Art director Nobuteru Yuuki initially wanted the characters to appear in a more "chibi" format with diminutive proportions. The game world's fusion of high technology and ethnic, tribal atmospheres proved challenging at first. He later recalled striving to harmonize the time period's level of technology, especially as reflected in characters' garb.

The "Chrono Cross" team devised an original battle system using a stamina bar and Elements. Kato planned the system around allowing players to avoid repetitive gameplay (also known as "grinding") to gain combat experience. Hiromichi Tanaka likened the Elements system to card games, hoping players would feel a sense of complete control in battle. The team programmed each battle motion manually instead of performing motion capture. Developers strove to include tongue-in-cheek humor in the battle system's techniques and animations to distance the game from the "Final Fantasy" franchise. Masato Kato planned for the game's setting to feature a small archipelago, for fear that players would become confused traveling in large areas with respect to parallel worlds. He hoped El Nido would still impart a sense of grand scale, and the development team pushed hardware limitations in creating the game's world. To create field maps, the team modeled locations in 3D, then chose the best angle for 2D rendering. The programmers of "Chrono Cross" did not use any existing Square programs or routines to code the game, instead writing new, proprietary systems. Other innovations included variable-frame rate code for fast-forward and slow-motion gameplay (awarded as a bonus for completing the game) and a "CD-read swap" system to allow quick data retrieval.

Masato Kato directed and wrote the main story, leaving sub-plots and minor character events to other staff. The event team sometimes struggled to mesh their work on the plot due to the complexity of the parallel worlds concept. Masato Kato confirmed that "Cross" featured a central theme of parallel worlds, as well as the fate of Schala, which he was previously unable to expound upon in "Chrono Trigger". Concerning the ending sequences showing Kid searching for someone in a modern city, he hoped to make players realize that alternate futures and possibilities may exist in their own lives, and that this realization would "not ... stop with the game". He later added, "Paraphrasing one novelist's favorite words, what's important is not the message or theme, but how it is portrayed as a game. Even in Cross, it was intentionally made so that the most important question was left unanswered." Kato described the finished story as "ole' boy-meets-girl type of story" with sometimes-shocking twists. Kato rode his motorcycle to relieve the stress of the game's release schedule. He continued refining event data during the final stages of development while the rest of the team undertook debugging and quality control work. Square advertised the game by releasing a short demo of the first chapter with purchases of "Legend of Mana". The North American version of "Cross" required three months of translation and two months of debugging before release. Richard Honeywood translated, working with Kato to rewrite certain dialogue for ease of comprehension in English. He also added instances of wordplay and alliteration to compensate for difficult Japanese jokes. To streamline translation for all 45 playable characters, Honeywood created his own version of the accent generator which needed to be more robust than the simple verbal tics of the Japanese cast. Although the trademark "Chrono Cross" was registered in the European Union, the game was not released in Europe.

"Chrono Cross" was scored by freelance video game music composer Yasunori Mitsuda, who previously worked on "Chrono Trigger". Director Masato Kato personally commissioned Mitsuda's involvement, citing a need for the "Chrono sound". Kato envisioned a "Southeast Asian feel, mixed with the foreign tastes and the tones of countries such as Greece"; Mitsuda centered his work around old world cultural influences, including Mediterranean, Fado, Celtic, and percussive African music. Mitsuda cited visual inspiration for songs: "All of my subjects are taken from scenery. I love artwork." To complement the theme of parallel worlds, he gave "Another" and "Home" respectively dark and bright moods, and hoped players would feel the emotions of "'burning soul,' 'lonely world,' and 'unforgettable memories'". Mitsuda and Kato planned music samples and sound effects with the philosophy of "a few sounds with a lot of content".

"Xenogears" contributor Tomohiko Kira played guitar on the beginning and ending themes. Noriko Mitose, as selected by Masato Kato, sang the ending song—"Radical Dreamers – The Unstolen Jewel". Ryo Yamazaki, a synthesizer programmer for Square Enix, helped Mitsuda transfer his ideas to the PlayStation's sound capabilities; Mitsuda was happy to accomplish even half of what he envisioned. Certain songs were ported from the score of "", such as "Gale", "Frozen Flame", and "Viper Mansion". Other entries in the soundtrack contain leitmotifs from "Chrono Trigger" and "Radical Dreamers". The melody of "Far Promise ~ Dream Shore" features prominently in "The Dream That Time Dreams" and "Voyage ~ Another World." Masato Kato faced internal opposition in hiring Noriko Mitose:


</doc>
<doc id="7843" url="https://en.wikipedia.org/wiki?curid=7843" title="Planned economy">
Planned economy

A planned economy is a type of economic system where investment and the allocation of capital goods is performed through economy-wide economic and production plans. A planned economy may be based on centralized, decentralized or participatory forms of economic planning. A command economy or administrative command economy is any of the nominally-planned economies of the former Soviet Union and Eastern Bloc, highlighting the central role of hierarchical administration in guiding the allocation of resources in these economic systems as opposed to planned coordination.

Planned economies are usually associated with Soviet-type central planning, which involves centralized state planning and administrative decision making. In command economies, important allocation decisions are made by government authorities and are imposed by law. Planned economies are held in contrast to unplanned economies, specifically market economies, where production, distribution, pricing and investment decisions are made by autonomous firms operating in markets. Market economies that use indicative planning are sometimes referred to as “planned market economies”.

The traditional conception of socialism involves the integration of socially-owned economic enterprises via some form of planning with direct calculation substituting factor markets. As such the concept of a planned economy is often associated with socialism and "socialist planning." More recent approaches to socialist planning and allocation have come from some economists and computer scientists proposing planning mechanisms based on advances in computer science and information technology.

Planned economies are held in contrast with "command" economies, where a planned economy is "an economic system in which the government controls and regulates production, distribution, prices, etc." but a command economy, while also having this type of regulation, necessarily has substantial public ownership of industry. Therefore, command economies are planned economies, but not necessarily the reverse.

Whereas most of the economy is organized in a top-down administrative model by a central authority, where decisions regarding investment and production output requirements are decided upon at the top in the chain of command, with little input from lower levels. Advocates of economic planning have sometimes been staunch critics of these command economies. For example, Leon Trotsky believed that those at the top of the chain of command, regardless of their intellectual capacity, operated without the input and participation of the millions of people who participate in the economy and understand/respond to local conditions and changes in the economy, and therefore would be unable to effectively coordinate all economic activity.

Although planned economies have historically been associated with Marxist-Leninist states and the Soviet economic model, some argue that the Soviet economic model did not actually constitute a planned economy in that a comprehensive and binding plan did not guide production and investment; therefore the further distinction of an "administrative command economy" emerged as a more accurate designation for the economic system that existed in the former Soviet Union and Eastern bloc, highlighting the role of centralized hierarchical decision-making in the absence of popular control over the economy. The possibility of a digital planned economy was explored by Chile with the creation of Project Cybersyn and Alexander Kharkevich head of the Department of technical physics in Kiev in 1962.

Another key difference is that command economies are inherently authoritarian, whereas economic planning in general can be either participatory and democratic or authoritarian. Indicative planning is a form of planning in market economies that directs the economy through incentive-based methods. Economic planning can be practiced in a decentralized manner through different government authorities. For example, in some predominately market-oriented and mixed economies, the state utilizes economic planning in strategic industries such as the aerospace industry. Mixed economies usually employ macroeconomic planning, while micro-economic affairs are left to the market and price system.

Another example of this is the utilization of dirigisme, or government direction of the economy through non coercive means, both of which were practiced in France and Great Britain after the Second World War. Swedish public housing models were planned by the government in a similar fashion as urban planning in a project called Million Programme.

The government can harness land, labours, and capital to serve the economic objectives of the state. Consumer demand can be restrained in favor of greater capital investment for economic development in a desired pattern. In international comparisons, state-socialist nations compared favorably with capitalist nations in health indicators such as infant mortality and life expectancy, although the statistics concerning infant mortality are self-reported and based on varying standards. The state can begin building a heavy industry at once in an underdeveloped economy without waiting years for capital to accumulate through the expansion of light industry, and without reliance on external financing. This is what happened in the Soviet Union during the 1930s when the government forced the share of GNP dedicated to private consumption from eighty percent to fifty percent. As a result, the Soviet Union experienced massive growth in heavy industry, with a concurrent massive contraction of its agricultural sector, in both relative and absolute terms.

Critics of planned economies argue that planners cannot detect consumer preferences, shortages, and surpluses with sufficient accuracy and therefore cannot efficiently co-ordinate production (in a market economy, a free price system is intended to serve this purpose). This difficulty was notably written about by economists Ludwig von Mises and Friedrich Hayek, who referred to subtly distinct aspects of the problem as the "economic calculation problem" and "local knowledge problem" respectively. These opponents of central planning argue that the only way to satisfy individuals who have a constantly changing hierarchy of needs, and are the only ones to possess their particular individual's circumstances, is by allowing those with the most knowledge of their needs to have it in their power to use their resources in a competing marketplace to meet the needs of the most consumers, most efficiently. This phenomenon is recognized as spontaneous order. Additionally, misallocation of resources would naturally ensue by redirecting capital away from individuals with direct knowledge and circumventing it into markets where a coercive monopoly influences behavior, ignoring market signals. According to Tibor R. Machan, "Without a market in which allocations can be made in obedience to the law of supply and demand, it is difficult or impossible to funnel resources with respect to actual human preferences and goals."

Economist Robin Hahnel notes that, even if central planning overcame its inherent inhibitions of incentives and innovation, it would nevertheless be unable to maximize economic democracy and self-management, which he believes are concepts that are more intellectually coherent, consistent and just than mainstream notions of economic freedom.

Says Hahnel, "Combined with a more democratic political system, and redone to closer approximate a best case version, centrally planned economies no doubt would have performed better. But they could never have delivered economic self-management, they would always have been slow to innovate as apathy and frustration took their inevitable toll, and they would always have been susceptible to growing inequities and inefficiencies as the effects of differential economic power grew. Under central planning neither planners, managers, nor workers had incentives to promote the social economic interest. Nor did impeding markets for final goods to the planning system enfranchise consumers in meaningful ways. But central planning would have been incompatible with economic democracy even if it had overcome its information and incentive liabilities. And the truth is that it survived as long as it did only because it was propped up by unprecedented totalitarian political power."

Studies of Eastern European planned economies in the 1950s and 1960s by both American and Eastern European economists found that, contrary to the expectations of both groups, they showed greater fluctuations in output than market economies during the same period.

While socialism is not equivalent to economic planning or to the concept of a planned economy, an influential conception of socialism involves the replacement of capital markets with some form of economic planning in order to achieve ex-ante coordination of the economy. The goal of such an economic system would be to achieve conscious control over the economy by the population, specifically, so that the use of the surplus product is controlled by the producers. The specific forms of planning proposed for socialism and their feasibility are subjects of the socialist calculation debate.

In their book "Towards a New Socialism" (1993) the computer scientist Paul Cockshott from the University of Glasgow and the economist Allin Cottrell from the Wake Forest University shows in detail how a democratically planned economy built on modern computer technology is possible and drives the thesis that it would be both economically more stable than the free market economies and also morally desirable.

In 1971, when the development of computer technology was still its early stages, the democratically elected socialist Allende regime launched the Project Cybersyn to install a telex machine in every corporation and organisation in the economy for the communication of economic data between the corporations and the government. The data was also fed into a computer simulated economy for forecasting. A control room was built for realtime observation and management of the overall economy. The project was initially successful but in 1973 it was violently ended by a CIA sponsored military coup led by Pinochet. He installed himself as a dictator and replaced the socialist economy with a neoliberal free market economy inspired and advised by Milton Friedman.

The 1888 novel "Looking Backward" by Edward Bellamy depicts a fictional planned economy in a United States around the year 2000 which has become a socialist utopia.

The World State in Aldous Huxley's "Brave New World" and Airstrip One in George Orwell's "Nineteen Eighty-Four" are both fictional examples of command economies, albeit with diametrically opposed aims: The former is a consumer economy designed to engender productivity while the latter is a shortage economy designed as an agent of totalitarian social control. Airstrip One is organised by the euphemistically named Ministry of Plenty.

Other literary portrayals of planned economies were Yevgeny Zamyatin's "We", which was an influence on Orwell's work. Like "Nineteen Eighty Four", Ayn Rand's dystopian story "Anthem" was also an artistic portrayal of a command economy that was influenced by "We". The difference is that it was a primitivist planned economy, as opposed to the advanced technology of "We" or "Brave New World".






</doc>
<doc id="7844" url="https://en.wikipedia.org/wiki?curid=7844" title="Common chimpanzee">
Common chimpanzee

The common chimpanzee ("Pan troglodytes"), also known as the robust chimpanzee, is a species of great ape. Colloquially, the common chimpanzee is often called the chimpanzee (or "chimp"), though this term can be used to refer to both species in the genus "Pan": the common chimpanzee and the closely related bonobo, formerly called the pygmy chimpanzee. Evidence from fossils and DNA sequencing shows both species of chimpanzee are the sister taxon to the modern human lineage.

The common chimpanzee is covered in coarse black hair, but has a bare face, fingers, toes, palms of the hands, and soles of the feet. It is considered more robust than the bonobo, weighing between and measuring about . Its gestation period is eight months. The infant is weaned at about three years old, but usually maintains a close relationship with its mother for several more years; it reaches puberty at the age of eight to 10. Its lifespan in the wild is 36 years and its lifespan in captivity is about 50 years.

The common chimpanzee lives in groups which range in size from 15 to 150 members, although individuals travel and forage in much smaller groups during the day. The species lives in a male-dominated, strict hierarchy, which means disputes can generally be settled without the need for violence. Nearly all chimpanzee populations have been recorded using tools, modifying sticks, rocks, grass and leaves and using them for acquiring honey, termites, ants, nuts and water. The species has also been found creating sharpened sticks to spear Senegal bushbabies out of small holes in trees.

The common chimpanzee is listed on the IUCN Red List as an endangered species. Between 170,000 and 300,000 individuals are estimated across its range in the forests and savannahs of West and Central Africa. The biggest threats to the common chimpanzee are habitat loss, poaching and disease.

The common chimpanzee was named "Simia troglodytes" by Johann Friedrich Blumenbach in 1776; Lorenz Oken moved it to the new genus "Pan" in 1816. The species name "troglodytes" is a reference to the Troglodytae (literally "cave-goers"), an African people described by Greco-Roman geographers. Blumenbach first used it in his "De generis humani varietate nativa liber" ("[Book] on the natural varieties of the human genus") in 1776. 
This book was based on his dissertation presented one year before (it had a date 16 September 1775 printed on its title page) to the University of Göttingen for internal use only, thus the dissertation did not meet the conditions for published work in the sense of zoological nomenclature.

The English name "chimpanzee" is first recorded in 1738. It is derived from a Tshiluba language term "kivili-chimpenze", with a meaning of "mockman" or possibly just "ape". The colloquialism "chimp" was most likely coined some time in the late 1870s.

Despite a large number of "Homo" fossil finds, chimpanzee fossils (genus "Pan") were not described until 2005. Existing chimpanzee populations in West and Central Africa do not overlap with the major human fossil sites in East Africa. However, chimpanzee fossils have now been reported from Kenya. This would indicate that both humans and members of the "Pan" clade were present in the East African Rift Valley during the Middle Pleistocene.

DNA evidence suggests the bonobo and common chimpanzee species separated from each other less than one million years ago (similar in relation between "Homo sapiens" and Neanderthals). The chimpanzee line split from the last common ancestor of the human line around six million years ago. Because no species other than "Homo sapiens" has survived from the human line of that branching, both chimpanzee species are the closest living relatives of humans. The lineage of humans and chimpanzees diverged from that of the gorilla about seven million years ago. A 2003 study argues the common chimpanzee should be included in the human branch as "Homo troglodytes", and notes "experts say many scientists are likely to resist the reclassification, especially in the emotionally-charged and often disputed field of anthropology"

Four subspecies of the common chimpanzee have been recognised, with the possibility of a fifth:

The adult male common chimpanzee weighs between , the female weighs . However, large wild males can weigh up to and males in captivity, such as Travis the Chimp, have reached . Head-body length (from the nose to the rump while on all fours) ranges from . Males can measure up to tall while standing and females up to tall. Their bodies are covered by coarse, black hair, except for the face, fingers, toes, palms of the hands, and soles of the feet. Both its thumbs and big toes are opposable, allowing a precise grip. The common chimpanzee is both arboreal and terrestrial, and spends its nights in the trees, while most daylight hours are spent on the ground.

Its habitual gait is quadrupedal, using the soles of its feet and resting on its knuckles, but it can walk upright for short distances. The common chimpanzee is a 'knuckle walker', like the gorilla and the bonobo, in contrast to the quadrupedal locomotion of the orangutan, a 'palm walker' that uses the outside edge of its palms. It is the anatomically closest relative of the human.

The common chimpanzee is a highly adaptable species. It lives in a variety of habitats, including dry savanna, evergreen rainforest, montane forest, swamp forest and dry woodland-savanna mosaic. In Gombe, the chimpanzee lives in subalpine moorland, open woodland, semideciduous forest, evergreen forest, and grassland with scattered trees. At Bossou, the chimpanzee inhabits multistage secondary deciduous forests, which have grown after shifting cultivation, as well as primary forests and grasslands. At Taï, it can be found in the last remaining tropical rain forest in Ivory Coast.

The chimpanzee has an advanced cognitive map of its home range and can repeatedly find food. The chimpanzee makes a night nest in a tree in a new location every night, with every chimpanzee in a separate nest other than infants or juvenile chimpanzees, which sleep with their mothers. Leopard predation is apparently a significant cause of mortality in chimpanzees at Taï and Lopé National Parks. Chimps are generally hostile towards leopards and may mob the predators and even kill their cubs. Lions may have preyed on the chimpanzees at Mahale Mountains National Park, where at least four chimpanzees could have fallen prey to them. Although no other instances of lion predation on chimpanzees have been recorded, the larger group sizes of savanna chimps may have developed as a response to threats from these big cats. Isolated cases of cannibalism have also been documented.

The chimpanzee is an omnivorous frugivore. It prefers fruit above all other food items and even seeks out and eats them when they are not abundant. It also eats leaves and leaf buds, seeds, blossoms, stems, pith, bark and resin. Insects and meat make up a small proportion of their diet, estimated as 2%. While the common chimpanzee is mostly herbivorous, it does eat honey, soil, insects, birds and their eggs, and small to medium-sized mammals, including other primates. The western red colobus ranks at the top of preferred mammal prey. Other mammalian prey include red-tailed monkeys, yellow baboons, blue duikers, bushbucks, and common warthogs.

Despite the fact that common chimpanzees are known to hunt, and to collect insects and other invertebrates, such food actually makes up a tiny portion of their diet, from as little as 2% yearly to as much as 65 grams of animal flesh per day for each adult chimpanzee in peak hunting seasons. This also varies from troop to troop and year to year. However, in all cases, the majority of their diet consists of fruits, leaves, roots, and other plant matter. Female chimpanzees appear to consume much less animal flesh than males, according to several studies. Goodall documented many occasions within Gombe Stream National Park of chimpanzees and western red colobus monkeys ignoring each other within close proximity.

It is suspected that human observers can influence chimpanzee behavior. It is suggested that drones, camera traps and remote microphones should be used rather than human observers.

Common chimpanzees live in communities that typically range from 20 to more than 150 members, but spend most of their time traveling in small, temporary groups consisting of a few individuals, "which may consist of any combination of age and sex classes." Both males and females sometimes travel alone. The common chimpanzee lives in a fission-fusion society and may be found in groups of these types: all-male, adult females and offspring, both sexes, or one female and her offspring. Chimpanzees have complex social relationships and spend a large amount of time grooming each other.

At the core of social structures are males, which roam around, protect group members, and search for food. Males remain in their natal communities, while females generally emigrate at adolescence. As such, males in a community are more likely to be related to one another than females are to each other. Among males is generally a dominance hierarchy, and males are dominant over females. However, this unusual fission-fusion social structure, "in which portions of the parent group may on a regular basis separate from and then rejoin the rest," is highly variable in terms of which particular individual chimpanzees congregate at a given time. This is mainly due to chimpanzees having a high level of individual autonomy within their fission-fusion social groups. Also, communities have large ranges that overlap with those of other groups.

As a result, individual chimpanzees often forage for food alone, or in smaller groups (as opposed to the much larger "parent" group, which encompasses all the chimpanzees which regularly come into contact and congregate into parties in a particular area). As stated, these smaller groups also emerge in a variety of types, for a variety of purposes. For example, an all-male troop may be organized to hunt for meat, while a group consisting of lactating females serves to act as a "nursery group" for the young. An individual may encounter certain individuals quite frequently, but have run-ins with others almost never or only in large-scale gatherings. Due to the varying frequency at which chimpanzees associate, the structure of their societies is highly complicated.

Male chimpanzees exist in a linear dominance hierarchy. Top-ranking males tend to be aggressive even during dominance stability. This is likely due to the chimp’s fission-fusion society, with male chimps leaving groups and returning after extended periods of time. With this, a dominant male is unsure if any "political maneuvering" has occurred and must re-establish his dominance. Thus, a large amount of aggression occurs 5–15 minutes after a reunion. During aggressive encounters, displays are preferred over attacks.

Males maintain and improve their social ranks by forming coalitions, which have been characterized as "exploitative" and are based on an individual’s influence in agonistic interactions. Being in a coalition allows males to dominate a third individual when they could not by themselves, as politically apt chimps can exert power over aggressive interactions regardless of their rank. Coalitions can also give an individual male the confidence to challenge a dominant male. The more allies a male has, the better his chance of becoming dominant. However, most changes in hierarchical rank are caused by dyadic interactions. Chimpanzee alliances can be very fickle and one member may turn on another if it serves him.

Low-ranking males commonly switch sides in disputes between more dominant individuals. Low-ranking males benefit from an unstable hierarchy and have increased sexual opportunities. In addition, conflicts between dominant males cause them to focus on each other rather than the lower-ranking males. Social hierarchies among adult females tend to be weaker. Nevertheless, the status of an adult female may be important for her offspring. Females in Taï have also been recorded to form alliances. Social grooming appears to be important in the formation and maintenance of coalitions. It is more common among adult males than adult females.

Chimpanzees have been described as highly territorial and are known to kill other chimps, although Margaret Power wrote in her 1991 book "The Egalitarians" that the field studies from which the aggressive data came, Gombe and Mahale, use artificial feeding systems that increased aggression in the chimpanzee populations studied, so might not reflect innate characteristics of the species as a whole. In the years following her artificial feeding conditions at Gombe, Jane Goodall described groups of male chimps patrolling the borders of their territory, brutally attacking chimps which had split off from the Gombe group. A study published in 2010 found that the chimpanzees wage wars over land, not mates. Patrol parties from smaller groups are more likely to avoid contact with their neighbors. Patrol parties from large groups even take over a smaller group's territory, gaining access to more resources, food, and females.

Chimpanzees mate throughout the year, although the number of females in oestrus varies seasonally in a group. Female chimps are more likely to come into oestrus when food is readily available. Oestrous females exhibit sexual swellings. Chimps tend to be promiscuous, and during estrus females mate with several males in her community, and males have large testicles for sperm competition. However, other forms of mating also exist. A community's dominant males sometimes restrict reproductive access to females. A male and female can form consortship and mate outside their community. In addition, females sometimes leave their communities and mate with males from neighboring communities.

These alternative mating strategies give females more mating opportunities without losing the support of the males in their community. Infanticide has been recorded in chimp communities in Gombe, Mahale, and Kibale National Parks. Male chimps practice infanticide on unrelated young to shorten the interbirth intervals in the females. Also, accounts of infanticide by females have been reported; cases of female infanticide may be related to the dominance hierarchy in females or simply isolated pathological behaviors.

Care for the young is provided mostly by their mothers. The survival and emotional health of the young is dependent on maternal care. Mothers provide their young with food, warmth, and protection, and teach them certain skills. In addition, a chimp’s future rank may be dependent on its mother’s status. For their first 30 days, infants cling to their mother's bellies. Newborn chimps are helpless; their grasping reflex is not strong enough to support them for more than a few seconds. Infants are unable to support their own weight for their first two months and need their mothers' support.

When they reach five to six months, infants ride on their mothers’ backs. They remain in continual contact for the rest of their first year. When they reach two years of age, they are able to move and sit independently. By three years, infants move farther away from their mothers. By four to six years, chimps are weaned and infancy ends.

The juvenile period for chimps lasts from their sixth to ninth years. Juveniles remain close to their mothers, but they also have more interactions with other members of their community. Adolescent females move between groups and are supported by their mothers in agonistic encounters. Adolescent males spend time with adult males in social activities like hunting and boundary patrolling.

Chimpanzees use a variety of facial expressions, postures and sounds to communicate with each other. Chimps have expressive faces which are important in close-up communications. When frightened, a "full closed grin" causes nearby individuals to be fearful, as well. Other facial expressions include the "lip flip", "pout", "sneer", and "compressed-lips face". When submitting to a conspecific, a chimp crunches, bobs, and extends a hand. When in an aggressive mode, a chimp swaggers bipedally, hunched over and arms waving, in an attempt to exaggerate its size. Chimps beat their hands and feet against the trunks of large trees, an act known as "drumming".

Vocalizations are also important in chimp communication. The most common and important call in adults is the "pant-hoot". These calls are made when individuals are excited. Pant-hoots are made of four parts, starting with soft "hoos" that get louder and louder and climax into screams and sometimes barks; the former die down to soft "hoos" again as the call ends. Submissive individuals will make "pant-grunts" towards their superiors. Chimps use distance calls to draw attention to danger, food sources, or other community members. "Barks" may be made as "short barks" when hunting and "tonal barks" when sighting large snakes.

Nearly all chimpanzee populations have been recorded using tools. They modify sticks, rocks, grass, and leaves and use them when foraging for honey, termites, ants, nuts, and water. Despite the lack of complexity, forethought and skill are seen in making these tools and should be considered such. While it has been known since Jane Goodall's 1960s discovery that modern chimpanzees use tools, research published in 2007 indicates chimpanzee stone tool use dates to at least 4,300 years ago.

A common chimpanzee from the Kasakela chimpanzee community was the first nonhuman animal reported making a tool, by modifying a twig to use as an instrument for extracting termites from their mound. At Taï, chimps simply use their hands to extract termites. When foraging for honey, chimps use modified short sticks to scoop the honey out of the hive, that is, if the bees are stingless. For hives of the dangerous African honeybees, chimps use longer and thinner sticks to extract the honey. Chimps also fish for ants using the same tactic.

Ant dipping is difficult and some chimps never master it. West African chimps crack open hard nuts with stones or branches. Some forethought in this activity is apparent, as these items are not found together or near a source of nuts. Nut cracking is also difficult and must be learned. Chimps also use leaves as sponges or spoons to drink water.

A recent study revealed the use of such advanced tools as spears, which West African chimpanzees in Senegal sharpen with their teeth, being used to spear Senegal bushbabies out of small holes in trees. An eastern chimpanzee has been observed using a modified branch as a tool to capture a squirrel.

When hunting small monkeys such as the red colobus, the chimpanzee hunts where the forest canopy is interrupted or irregular. This allows it to easily corner the monkeys when chasing them in the appropriate direction. Chimps may also hunt as a coordinated team, so that they can corner their prey even in a continuous canopy. During an arboreal hunt, each chimp in the hunting groups has a role. "Drivers" serve to keep the prey running in a certain direction and follow them without attempting to make a catch. "Blockers" are stationed at the bottom of the trees and climb up to block prey that take off in a different direction. "Chasers" move quickly and try to make a catch. Finally, "ambushers" hide and rush out when a monkey nears. While both adults and infants are taken, adult male black-and-white colobus monkeys will attack the hunting chimps. In Gombe, the chimpanzee also fears adult female colobus monkeys, and prefers to snatch infants from their mother's bellies without harming the mothers. Male chimps hunt more than females. When caught and killed, the meal is distributed to all hunting party members and even bystanders.

Chimpanzees are rarely represented in African culture, as the natives regard them as too similar to humans and thus "too close for comfort." They were even thought to have kidnapped and raped women. The Gio people of Liberia and the Hemba people of the Congo have created blocky and crude masks of the animals. The mask may have a smile which suggests drunken anger, insanity or horror. They wear these masks when teaching young people how not to act; performing rituals where they act wildly and uncivilized. They may also act out these rituals during funerals, representing the "awful reality of death."

In Western popular culture, chimpanzees have been commonly stereotyped as childlike companions, sidekicks or clowns. They are especially suited for the latter role on account of their prominent facial features, long limbs and fast movements, which humans often find amusing. Accordingly, entertainment acts featuring chimpanzees dressed up as humans have been traditional staples of circuses and stage shows. Westerners have also been disturbed by the chimps' resemblance to humans as well as their "frank sexuality".

Jane Goodall undertook the first long-term field study of the common chimpanzee, begun in Tanzania at Gombe Stream National Park in 1960. Other long-term study sites begun in 1960 include A. Kortlandt in the eastern Democratic Republic of the Congo and Junichiro Itani in Mahale Mountains National Park in Tanzania. Current understanding of the species' typical behaviours and social organization are formed largely from Goodall's ongoing 50-year Gombe research study.

Human and common chimpanzee DNA are very similar. After the completion of the Human Genome Project, a Chimpanzee Genome Project was initiated. In December 2003, a preliminary analysis of 7600 genes shared between the two genomes confirmed that certain genes, such as the forkhead-box P2 transcription factor which is involved in speech development, have undergone rapid evolution in the human lineage. A draft version of the chimpanzee genome was published on September 1, 2005, in an article produced by the Chimpanzee Sequencing and Analysis Consortium.

The DNA sequence differences between humans and chimpanzees is about 35 million single-nucleotide changes, five million insertion/deletion events, and various chromosomal rearrangements. Typical human and chimp protein homologs differ in only an average of two amino acids. About 30% of all human proteins are identical in sequence to the corresponding chimp protein. Duplications of small parts of chromosomes have been the major source of differences between human and chimp genetic material; about 2.7% of the corresponding modern genomes represent differences, produced by gene duplications or deletions, during the roughly four to six million years since humans and chimps diverged from their common evolutionary ancestor. Results from human and chimp genome analyses, currently being conducted by geneticists including David Reich, should help in understanding the genetic basis of some human diseases.

Common chimpanzees have been known to attack humans. In Uganda, several attacks on children have happened, some of them fatal. Some of these attacks may be due to the chimpanzees being intoxicated (from alcohol obtained from rural brewing operations) and mistaking human children for the western red colobus, one of their favorite meals. Human interactions with chimpanzees may be especially dangerous if the chimpanzees perceive humans as potential rivals. At least six cases of chimpanzees snatching and eating human babies are documented.

A chimpanzee's great strength and sharp teeth mean that attacks, even on adult humans, can cause severe injuries. This was evident after the attack and near death of former NASCAR driver St. James Davis, who was mauled by two chimps before they were killed. Another example of chimpanzees being aggressive toward humans occurred in 2009 in Stamford, Connecticut, when a , 13-year-old pet chimp named Travis attacked his owner's friend, who lost her hands, eyelids, nose, and part of her maxilla from the attack.

Two types of human immunodeficiency virus (HIV) infect humans: HIV-1 and HIV-2. HIV-1 is the more virulent and easily transmitted, and is the source of the majority of HIV infections throughout the world; HIV-2 is largely confined to west Africa. Both types originated in west and central Africa, jumping from primates to humans. HIV-1 has evolved from a simian immunodeficiency virus (SIVcpz) found in the common chimpanzee subspecies, "P. t. troglodytes", native to southern Cameroon. Kinshasa, in the Democratic Republic of Congo, has the greatest genetic diversity of HIV-1 so far discovered, suggesting the virus has been there longer than anywhere else. HIV-2 crossed species from a different strain of SIV, found in the sooty mangabey monkeys in Guinea-Bissau.

Chimpanzee are a legally protected species in most of their range and can be found both in and outside national parks. Between 172,700 and 299,700 individuals are thought to be living in the wild, a decrease from about a million chimpanzees in the early 1900s.

The biggest threats to the common chimpanzee are habitat destruction, poaching, and disease. Chimpanzee habitats have been limited by deforestation in both West and Central Africa. Road building has caused habitat degradation and fragmentation of chimpanzee populations and may allow poachers more access to areas that had not been seriously affected by humans. While deforestation rates are low in western Central Africa, selective logging may be done outside national parks.

Chimpanzees are a common target for poachers. In Ivory Coast, chimpanzees make up 1–3% of bushmeat sold in urban markets. They are also taken in pet trades despite it being illegal in many countries where they live. Chimpanzees are also hunted for medicinal purposes in some areas. Capturing chimpanzees for scientific research is still allowed in some countries, such as Guinea. People sometimes kill chimpanzees that threaten their crops. Chimps may also be unintentionally maimed or killed by snares meant for other animals.

Infectious diseases are a main cause of death for chimpanzees. They succumb to many diseases that afflict humans, because the two species are so similar. As human populations grow, so does the risk of disease transmission between humans and chimpanzees.

On 12 June 2015, the U.S. Fish and Wildlife Service announced it will classify all chimpanzees, both wild and captive, as endangered under the Endangered Species Act. Before this ruling, only wild chimpanzees were listed as endangered, while captive chimpanzees were listed as threatened under the act. The final rule was published in the Federal Register of 16 June 2015 (), and came into effect 90 days after publication on September 14, 2015.


General:




</doc>
<doc id="7845" url="https://en.wikipedia.org/wiki?curid=7845" title="Charcot–Marie–Tooth disease">
Charcot–Marie–Tooth disease

Charcot–Marie–Tooth disease (CMT) is one of the hereditary motor and sensory neuropathies, a group of varied inherited disorders of the peripheral nervous system characterized by progressive loss of muscle tissue and touch sensation across various parts of the body. Currently incurable, this disease is the most commonly inherited neurological disorder, and affects approximately 1 in 2,500 people. CMT was previously classified as a subtype of muscular dystrophy.

Symptoms of CMT usually begin in early childhood or early adulthood, but can begin later. Some people do not experience symptoms until their early thirties or forties. Usually, the initial symptom is foot drop early in the course of the disease. This can also cause hammer toe, where the toes are always curled. Wasting of muscle tissue of the lower parts of the legs may give rise to a "stork leg" or "inverted champagne bottle" appearance. Weakness in the hands and forearms occurs in many people as the disease progresses.

Loss of touch sensation in the feet, ankles and legs, as well as in the hands, wrists and arms occur with various types of the disease. Early and late onset forms occur with 'on and off' painful spasmodic muscular contractions that can be disabling when the disease activates. High-arched feet (pes cavus) or flat-arched feet (pes planus) are classically associated with the disorder. Sensory and proprioceptive nerves in the hands and feet are often damaged, while unmyelinated pain nerves are left intact. Overuse of an affected hand or limb can activate symptoms including numbness, spasm, and painful cramping.

Symptoms and progression of the disease can vary. Involuntary grinding of teeth as well as squinting are prevalent and often go unnoticed by the person affected. Breathing can be affected in some; so can hearing, vision, as well as the neck and shoulder muscles. Scoliosis is common, causing hunching and loss of height. Hip sockets can be malformed. Gastrointestinal problems can be part of CMT, as can difficulty chewing, swallowing, and speaking (due to atrophy of vocal cords). A tremor can develop as muscles waste. Pregnancy has been known to exacerbate CMT, as well as severe emotional stress. Patients with CMT must avoid periods of prolonged immobility such as when recovering from a secondary injury as prolonged periods of limited mobility can drastically accelerate symptoms of CMT.

Pain due to postural changes, skeletal deformations, muscle fatigue and cramping is fairly common in people with CMT. It can be mitigated or treated by physical therapies, surgeries, and corrective or assistive devices. Analgesic medications may also be needed if other therapies do not provide relief from pain. Neuropathic pain is often a symptom of CMT, though, like other symptoms of CMT, its presence and severity varies from case to case. For some people, pain can be significant to severe and interfere with daily life activities. However, pain is not experienced by all people with CMT. When neuropathic pain is present as a symptom of CMT, it is comparable to that seen in other peripheral neuropathies, as well as postherpetic neuralgia and complex regional pain syndrome, among other diseases.

Charcot–Marie–Tooth disease is caused by mutations that cause defects in neuronal proteins. Nerve signals are conducted by an axon with a myelin sheath wrapped around it. Most mutations in CMT affect the myelin sheath, but some affect the axon.

The most common cause of CMT (70–80% of the cases) is the duplication of a large region on the short arm of chromosome 17 that includes the gene PMP22. Some mutations affect the gene MFN2, which codes for a mitochondrial protein. Cells contain separate sets of genes in their nucleus and in their mitochondria. In nerve cells, the mitochondria travel down the long axons. In some forms of CMT, mutated MFN2 causes the mitochondria to form large clusters, or clots, which are unable to travel down the axon towards the synapses. This prevents the synapses from functioning.

CMT is divided into the primary demyelinating neuropathies (CMT1, CMT3, and CMT4) and the primary axonal neuropathies (CMT2), with frequent overlap. Another cell involved in CMT is the Schwann cell, which creates the myelin sheath, by wrapping its plasma membrane around the axon.

Neurons, Schwann cells, and fibroblasts work together to create a functional nerve. Schwann cells and neurons exchange molecular signals that regulate survival and differentiation. These signals are disrupted in CMT.

Demyelinating Schwann cells causes abnormal axon structure and function. They may cause axon degeneration, or they may simply cause axons to malfunction.

The myelin sheath allows nerve cells to conduct signals faster. When the "myelin sheath" is damaged, nerve signals are slower, and this can be measured by a common neurological test, electromyography. When the "axon" is damaged, on the other hand, this results in a reduced compound muscle action potential (CMAP).

CMT can be diagnosed through symptoms, through measurement of the speed of nerve impulses (nerve conduction studies), through biopsy of the nerve, and through DNA testing. DNA testing can give a definitive diagnosis, but not all the genetic markers for CMT are known. CMT is first noticed when someone develops lower leg weakness, such as foot drop; or foot deformities, including hammertoes and high arches. But signs alone do not lead to diagnosis. Patients must be referred to a physician specialising in neurology or rehabilitation medicine. To see signs of muscle weakness, the neurologist asks patients to walk on their heels or to move part of their leg against an opposing force. To identify sensory loss, the neurologist tests for deep tendon reflexes, such as the knee jerk, which are reduced or absent in CMT. The doctor also asks about family history, because CMT is hereditary. The lack of family history does not rule out CMT, but helps rule out other causes of neuropathy, such as diabetes or exposure to certain chemicals or drugs.

In 2010, CMT was one of the first diseases where the genetic cause of a particular patient's disease was precisely determined by sequencing the whole genome of an affected individual. This was done by the scientists employed by the Charcot Marie Tooth Association (CMTA) Two mutations were identified in a gene, SH3TC2, known to cause CMT. Researchers then compared the affected patient's genome to the genomes of the patient's mother, father, and seven siblings with and without the disease. The mother and father each had one normal and one mutant copy of this gene, and had mild or no symptoms. The offspring that inherited two mutant genes presented fully with the disease.

The constant cycle of demyelination and remyelination, which occurs in CMT, can lead to the formation of layers of myelin around some nerves, termed an "onion bulb". These are also seen in chronic inflammatory demyelinating polyneuropathy (CIDP). Muscles show fiber type grouping, a similarly non-specific finding that indicates a cycle of denervation/reinnervation. Normally, type I and type II muscle fibers show a checkerboard-like random distribution. However, when reinnervation occurs, the group of fibers associated with one nerve are of the same type. The standard for indicating fiber type is histoenzymatic adenosine triphosphatase (ATPase at pH 9.4).

CMT is a result of genetic mutations in a number of genes. Based on the affected gene, CMT can be categorized into types and subtypes.

Often the most important goal for patients with CMT is to maintain movement, muscle strength, and flexibility. Therefore, an interprofessional team approach with occupational therapy, physical therapy, orthotist, podiatrist and or orthopedic surgeon is recommended. PT typically focuses on muscle strength training, muscle stretching and aerobic exercise while OT can provide education on energy conservation strategies and activities of daily living. Physical therapy should be involved in designing an exercise program that fits a person's personal strengths and flexibility. Bracing can also be used to correct problems caused by CMT. An orthotist may address gait abnormalities by prescribing the use of ankle-foot orthoses (AFOs). These orthoses help control foot drop and ankle instability and often provide a better sense of balance for patients. Appropriate footwear is also very important for people with CMT, but they often have difficulty finding well-fitting shoes because of their high arched feet and hammer toes. Due to the lack of good sensory reception in the feet, CMT patients may also need to see a podiatrist for help in trimming nails or removing calluses that develop on the pads of the feet. A final decision a patient can make is to have surgery. Using a podiatrist or an orthopedic surgeon, patients can choose to stabilize their feet or correct progressive problems. These procedures include straightening and pinning the toes, lowering the arch, and sometimes, fusing the ankle joint to provide stability. CMT patients must take extra care to avoid falling because fractures take longer to heal in someone with an underlying disease process. Additionally, the resulting inactivity may cause the CMT to worsen.

The Charcot-Marie-Tooth Association classifies the chemotherapy drug vincristine as a "definite high risk" and states that "vincristine has been proven hazardous and should be avoided by all CMT patients, including those with no symptoms."

There are also several corrective surgical procedures that can be done to improve physical condition.

The severity of symptoms vary widely even for the same type of CMT. There have been cases of monozygotic twins with varying levels of disease severity, showing that identical genotypes are associated with different levels of severity (see penetrance). Some patients are able to live a normal life and are almost or entirely asymptomatic. A 2007 review stated that "Life expectancy is not known to be altered in the majority of cases".

The disease is named after those who classically described it: Jean-Martin Charcot (1825–1893), his pupil Pierre Marie (1853–1940) (), and Howard Henry Tooth (1856–1925) ("The peroneal type of progressive muscular atrophy", dissertation, London, 1886.)



</doc>
<doc id="7846" url="https://en.wikipedia.org/wiki?curid=7846" title="Central pontine myelinolysis">
Central pontine myelinolysis

Central pontine myelinolysis (CPM) is a neurological disorder caused by severe damage of the myelin sheath of nerve cells in the area of the brainstem termed the "pons", predominately of iatrogenic, treatment-induced cause. It is characterized by acute paralysis, dysphagia (difficulty swallowing), and dysarthria (difficulty speaking), and other neurological symptoms.

Central pontine myelinolysis was first described by Adams et al. in 1959 as a clinicopathological entity. The original paper described four cases with fatal outcomes, and the findings on autopsy. The cause was not known then but the authors suspected either a toxin or a nutritional deficiency. ‘Central pontine’ indicated the site of the lesion and ‘myelinolysis’ was used to emphasise that myelin was affected preferentially compared to the other neuronal elements. The authors intentionally avoided the term ‘demyelination’ to describe the condition, in order to differentiate this condition from multiple sclerosis and other neuroinflammatory disorders.

Since this original description, demyelination in other areas of the central nervous system associated with osmotic stress has been described outside the pons. The more general term "osmotic demyelination syndrome" is now preferred to the original more restrictive term "central pontine myelinolysis".

Central pontine myelinolysis presents most commonly as a complication of treatment of patients with profound hyponatremia (low sodium), which can result from a varied spectrum of conditions, based on different mechanisms. It occurs as a consequence of a rapid rise in serum tonicity following treatment in individuals with chronic, severe hyponatremia who have made intracellular adaptations to the prevailing hypotonicity.

Clinical presentation of CPM is heterogeneous and depend on the regions of the brain involved. Prior to its onset, patients may present with the neurological signs and symptoms of hyponatraemic encephalopathy such as nausea and vomiting, confusion, headache and seizures. These symptoms may resolve with normalisation of the serum sodium concentration. Three to five days later, a second phase of neurological manifestations occurs correlating with the onset of myelinolysis. Observable immediate precursors may include seizures, disturbed consciousness, gait changes, and decrease or cessation of respiratory function.

The classical clinical presentation is the progressive development of spastic quadriparesis, pseudobulbar palsy, and emotional lability (pseudobulbar affect), with other more variable neurological features associated with brainstem damage. These result from a rapid myelinolysis of the corticobulbar and corticospinal tracts in the brainstem.

The most common cause of is overly rapid correction of low blood sodium levels (hyponatremia). Apart from rapid correction of hyponatraemia, there are case reports of central pontine myelinolysis in association with hypokalaemia, anorexia nervosa when feeding is started, patients undergoing dialysis and burns victims. There is a case report of central pontine myelinolysis occurring in the context of re-feeding syndrome, in the absence of hyponatremia.

It has also been known to occur in patients suffering withdrawal symptoms of chronic alcoholism. In these instances, occurrence may be entirely unrelated to hyponatremia or rapid correction of hyponatremia. It could affect patients who take some prescription medicines that are able to cross the blood-brain barrier and cause abnormal thirst reception - in this scenario the CPM is caused by polydipsia leading to low blood sodium levels (hyponatremia).

In schizophrenic patients with psychogenic polydipsia, inadequate thirst reception leads to excessive water intake, severely diluting serum sodium. With this excessive thirst combined with psychotic symptoms, brain damage such as CPM may result from hyperosmolarity caused by excess intake of fluids, (primary polydipsia) although this is difficult to determine because such patients are often institutionalised and have a long history of mental health conditions.

It has been observed following hematopoietic stem cell transplantation.

CPM may also occur in patients prone to hyponatraemia affected by:

The currently accepted theory states that the brain cells adjust their osmolarities by changing levels of certain osmolytes like inositol, betaine, and glutamine in response to varying serum osmolality. In the context of chronic low plasma sodium (hyponatremia), the brain compensates by decreasing the levels of these osmolytes within the cells, so that they can remain relatively isotonic with their surroundings and not absorb too much fluid. The reverse is true in hypernatremia, in which the cells increase their intracellular osmolytes so as not to lose too much fluid to the extracellular space.

With correction of the hyponatremia with intravenous fluids, the extracellular tonicity increases, followed by an increase in intracellular tonicity. When the correction is too rapid, not enough time is allowed for the brain's cells to adjust to the new tonicity, namely by increasing the intracellular osmoles mentioned earlier. If the serum sodium levels rise too rapidly, the increased extracellular tonicity will continue to drive water out of the brain's cells. This can lead to cellular dysfunction and CPM.

It can be diagnosed clinically in the appropriate context, but may be difficult to confirm radiologically using conventional imaging techniques. Changes are more prominent on MRI than on CT, but often take days or weeks after acute symptom onset to develop. Imaging by MRI typically demonstrates areas of hyperintensity on T2-weighted images.

To minimise the risk of this condition developing from its most common cause, overly rapid reversal of hyponatremia, the hyponatremia should be corrected at a rate not exceeding 10 mmol/L/24 h or 0.5 mEq/L/h; or 18 mEq/L/48hrs; thus avoiding demyelination. No large clinical trials have been performed to examine the efficacy of therapeutic re-lowering of serum sodium, or other interventions sometimes advocated such as steroids or plasma exchange. 
Alcoholic patients should receive vitamin supplementation and a formal evaluation of their nutritional status.

Once osmotic demyelination has begun, there is no cure or specific treatment. Care is mainly supportive. Alcoholics are usually given vitamins to correct for other deficiencies. The favourable factors contributing to the good outcome in CPM without hyponatremia were: concurrent treatment of all electrolyte disturbances, early Intensive Care Unit involvement at the advent of respiratory complications, early introduction of feeding including thiamine supplements with close monitoring of the electrolyte changes and input.

Research has led to improved outcomes. Animal studies suggest that inositol reduces the severity of osmotic demyelination syndrome if given before attempting to correct chronic hyponatraemia. Further study is required before using inositol in humans for this purpose.

Though traditionally, the prognosis is considered poor, a good functional recovery is possible. All patients at risk of developing refeeding syndrome should have their electrolytes closely monitored, including sodium, potassium, magnesium, glucose and phosphate. 
Recent data indicate that the prognosis of critically ill patients may even be better than what is generally considered, despite severe initial clinical manifestations and a tendency by the intensivists to underestimate a possible favorable evolution.
While some patients die, most survive and of the survivors, approximately one-third recover; one-third are disabled but are able to live independently; one-third are severely disabled. Permanent disabilities range from minor tremors and ataxia to signs of severe brain damage, such as spastic quadriparesis and locked-in syndrome. Some improvements may be seen over the course of the first several months after the condition stabilizes.

The degree of recovery depends on the extent of the original axonal damage.



</doc>
<doc id="7849" url="https://en.wikipedia.org/wiki?curid=7849" title="Crystallographic defect">
Crystallographic defect

Crystalline solids exhibit a periodic crystal structure. The positions of atoms or molecules occur on repeating fixed distances, determined by the unit cell parameters. However, the arrangement of atoms or molecules in most crystalline materials is not perfect. The regular patterns are interrupted by crystallographic defects.

Point defects are defects that occur only at or around a single lattice point. They are not extended in space in any dimension. Strict limits for how small a point defect is are generally not defined explicitly. However, these defects typically involve at most a few extra or missing atoms. Larger defects in an ordered structure are usually considered dislocation loops. For historical reasons, many point defects, especially in ionic crystals, are called "centers": for example a vacancy in many ionic solids is called a luminescence center, a color center, or F-center. These dislocations permit ionic transport through crystals leading to electrochemical reactions. These are frequently specified using Kröger–Vink Notation.




Line defects can be described by gauge theories.

Dislocations are linear defects, around which (the atoms of the crystal lattice are misaligned.
There are two basic types of dislocations, the "edge" dislocation and the "screw" dislocation. "Mixed" dislocations, combining aspects of both types, are also common.

Edge dislocations are caused by the termination of a plane of atoms in the middle of a crystal. In such a case, the adjacent planes are not straight, but instead bend around the edge of the terminating plane so that the crystal structure is perfectly ordered on either side. The analogy with a stack of paper is apt: if a half a piece of paper is inserted in a stack of paper, the defect in the stack is only noticeable at the edge of the half sheet.

The screw dislocation is more difficult to visualise, but basically comprises a structure in which a helical path is traced around the linear defect (dislocation line) by the atomic planes of atoms in the crystal lattice.

The presence of dislocation results in lattice strain (distortion). The direction and magnitude of such distortion is expressed in terms of a Burgers vector (b). For an edge type, b is perpendicular to the dislocation line, whereas in the cases of the screw type it is parallel. In metallic materials, b is aligned with close-packed crystallographic directions and its magnitude is equivalent to one interatomic spacing.

Dislocations can move if the atoms from one of the surrounding planes break their bonds and rebond with the atoms at the terminating edge.

It is the presence of dislocations and their ability to readily move (and interact) under the influence of stresses induced by external loads that leads to the characteristic malleability of metallic materials.

Dislocations can be observed using transmission electron microscopy, field ion microscopy and atom probe techniques.
Deep level transient spectroscopy has been used for studying the electrical activity of dislocations in semiconductors, mainly silicon.

Disclinations are line defects corresponding to "adding" or "subtracting" an angle around a line. Basically, this means that if you track the crystal orientation around the line defect, you get a rotation. Usually, they were thought to play a role only in liquid crystals, but recent developments suggest that they might have a role also in solid materials, e.g. leading to the self-healing of cracks.



A successful mathematical classification method for physical lattice defects, which works not only with the theory of dislocations and other defects in crystals but also, e.g., for disclinations in liquid crystals and for excitations in superfluid He, is the topological homotopy theory.

Density functional theory, classical molecular dynamics and kinetic Monte Carlo 
simulations are widely used to study the properties of defects in solids with computer simulations. 
Simulating jamming of hard spheres of different sizes and/or in containers with non-commeasurable sizes using the Lubachevsky–Stillinger algorithm
can be an effective technique for demonstrating some types of crystallographic defects.




</doc>
<doc id="7850" url="https://en.wikipedia.org/wiki?curid=7850" title="Chomsky normal form">
Chomsky normal form

In formal language theory, a context-free grammar "G" is said to be in Chomsky normal form (first described by Noam Chomsky) if all of its production rules are of the form:
where "A", "B", and "C" are nonterminal symbols, "a" is a terminal symbol (a symbol that represents a constant value), "S" is the start symbol, and ε denotes the empty string. Also, neither "B" nor "C" may be the start symbol, and the third production rule can only appear if ε is in "L"("G"), namely, the language produced by the context-free grammar "G".

Every grammar in Chomsky normal form is context-free, and conversely, every context-free grammar can be transformed into an equivalent one which is in Chomsky normal form and has a size no larger than the square of the original grammar's size.

To convert a grammar to Chomsky normal form, a sequence of simple transformations is applied in a certain order; this is described in most textbooks on automata theory.
The presentation here follows Hopcroft, Ullman (1979), but is adapted to use the transformation names from Lange, Leiß (2009). Each of the following transformations establishes one of the properties required for Chomsky normal form.

Introduce a new start symbol "S", and a new rule 
where "S" is the previous start symbol.
This doesn't change the grammar's produced language, and "S" won't occur on any rule's right-hand side.

To eliminate each rule 
with a terminal symbol "a" being not the only symbol on the right-hand side, introduce, for every such terminal, a new nonterminal symbol "N", and a new rule 
Change every rule 
to 
If several terminal symbols occur on the right-hand side, simultaneously replace each of them by its associated nonterminal symbol.
This doesn't change the grammar's produced language.

Replace each rule 
with more than 2 nonterminals "X"...,"X" by rules 
where "A" are new nonterminal symbols.
Again, this doesn't change the grammar's produced language.

An ε-rule is a rule of the form 
where "A" is not "S", the grammar's start symbol.

To eliminate all rules of this form, first determine the set of all nonterminals that derive ε.
Hopcroft and Ullman (1979) call such nonterminals "nullable", and compute them as follows:

Obtain an intermediate grammar by replacing each rule 
by all versions with some nullable "X" omitted.
By deleting in this grammar each ε-rule, unless its left-hand side is the start symbol, the transformed grammar is obtained.

For example, in the following grammar, with start symbol "S",
the nonterminal "A", and hence also "B", is nullable, while neither "C" nor "S" is.
Hence the following intermediate grammar is obtained:
In this grammar, all ε-rules have been "inlined at the call site".
In the next step, they can hence be deleted, yielding the grammar:
This grammar produces the same language as the original example grammar, viz. {"ab","aba","abaa","abab","abac","abb","abc","b","bab","bac","bb","bc","c"}, but apparently has no ε-rules.

A unit rule is a rule of the form 
where "A", "B" are nonterminal symbols.
To remove it, for each rule 
where "X" ... "X" is a string of nonterminals and terminals, add rule 
unless this is a unit rule which has already been (or is being) removed.

When choosing the order in which the above transformations are to be applied, it has to be considered that some transformations may destroy the result achieved by other ones. For example, START will re-introduce a unit rule if it is applied after UNIT. The table shows which orderings are admitted.

Moreover, the worst-case bloat in grammar size depends on the transformation order. Using |"G"| to denote the size of the original grammar "G", the size blow-up in the worst case may range from |"G"| to 2, depending on the transformation algorithm used. The blow-up in grammar size depends on the order between DEL and BIN. It may be exponential when DEL is done first, but is linear otherwise. UNIT can incur a quadratic blow-up in the size of the grammar. The orderings START,TERM,BIN,DEL,UNIT and START,BIN,DEL,UNIT,TERM lead to the least (i.e. quadratic) blow-up.

The following grammar, with start symbol "Expr", describes a simplified version of the set of all syntactical valid arithmetic expressions in programming languages like C or Algol60. Both "number" and "variable" are considered terminal symbols here for simplicity, since in a compiler front-end their internal structure is usually not considered by the parser. The terminal symbol "^" denoted exponentiation in Algol60.

In step "START" of the above conversion algorithm, just a rule "S"→"Expr" is added to the grammar.
After step "TERM", the grammar looks like this:

After step "BIN", the following grammar is obtained:

Since there are no ε-rules, step "DEL" doesn't change the grammar.
After step "UNIT", the following grammar is obtained, which is in Chomsky normal form:

The "N" introduced in step "TERM" are "PowOp", "Open", and "Close".
The "A" introduced in step "BIN" are "AddOp_Term", "MulOp_Factor", "PowOp_Primary", and "Expr_Close".

Another way to define the Chomsky normal form is:

A formal grammar is in Chomsky reduced form if all of its production rules are of the form:
where formula_3, formula_4 and formula_5 are nonterminal symbols, and formula_6 is a terminal symbol. When using this definition, formula_4 or formula_5 may be the start symbol. Only those context-free grammars which do not generate the empty string can be transformed into Chomsky reduced form.

In a paper where he proposed a term Backus–Naur form (BNF), Donald E. Knuth implied a BNF "syntax in which all definitions have such a form may be said to be in 'Floyd Normal Form'",
where formula_12, formula_13 and formula_14 are nonterminal symbols, and formula_6 is a terminal symbol,
because Robert W. Floyd found any BNF syntax can be converted to the above one in 1961. But he withdrew this term, "since doubtless many people have independently used this simple fact in their own work, and the point is only incidental to the main considerations of Floyd's note."

Besides its theoretical significance, CNF conversion is used in some algorithms as a preprocessing step, e.g., the CYK algorithm, a bottom-up parsing for context-free grammars, and its variant probabilistic CKY.




</doc>
<doc id="7851" url="https://en.wikipedia.org/wiki?curid=7851" title="Comprehensive Nuclear-Test-Ban Treaty">
Comprehensive Nuclear-Test-Ban Treaty

The Comprehensive Nuclear-Test-Ban Treaty (CTBT) is a multilateral treaty that bans all nuclear explosions, for both civilian and military purposes, in all environments. It was adopted by the United Nations General Assembly on 10 September 1996, but has not entered into force, as eight specific states have not ratified the treaty.

The movement for international control of nuclear weapons began in 1945, with a call from Canada and United Kingdom for a conference on the subject. In June 1946, Bernard Baruch, an emissary of President Harry S. Truman, proposed the Baruch Plan before the United Nations Atomic Energy Commission, which called for an international system of controls on the production of atomic energy. The plan, which would serve as the basis for United States nuclear policy into the 1950s, was rejected by the Soviet Union as a US ploy to cement its nuclear dominance.

Between the Trinity nuclear test of 16 July 1945 and the signing of the Partial Test Ban Treaty (PTBT) on 5 August 1963, 499 nuclear tests were conducted. Much of the impetus for the PTBT, the precursor to the CTBT, was rising public concern surrounding the size and resulting nuclear fallout from underwater and atmospheric nuclear tests, particularly tests of powerful thermonuclear weapons (hydrogen bombs). The Castle Bravo test of 1 March 1954, in particular, attracted significant attention as the detonation resulted in fallout that spread over inhabited areas and sickened a group of Japanese fishermen. Between 1945 and 1963, the US conducted 215 atmospheric tests, the Soviet Union conducted 219, the UK conducted 21, and France conducted three.

In 1954, following the Castle Bravo test, Prime Minister Jawaharlal Nehru of India issued the first appeal for a "standstill agreement" on testing, which was soon echoed by the British Labour Party. Negotiations on a comprehensive test ban, primarily involved the US, UK, and Soviet Union, began in 1955 following a proposal by Soviet leader Nikita Khrushchev. Of primary concern throughout the negotiations, which would stretch with some interruptions to July 1963, was the system of verifying compliance with the test ban and detecting illicit tests. On the Western side, there were concerns that the Soviet Union would be able to circumvent any test ban and secretly leap ahead in the nuclear arms race. These fears were amplified following the US "Rainier" shot of 19 September 1957, which was the first contained underground test of a nuclear weapon. Though the US held a significant advantage in underground testing capabilities, there was worry that the Soviet Union would be able to covertly conduct underground tests during a test ban, as underground detonations were more difficult to detect than above-ground tests. On the Soviet side, conversely, the on-site compliance inspections demanded by the US and UK were seen as amounting to espionage. Disagreement over verification would lead to the Anglo-American and Soviet negotiators abandoning a comprehensive test ban (i.e., a ban on all tests, including those underground) in favor of a partial ban, which would be finalized on 25 July 1963. The PTBT, joined by 123 states following the original three parties, banned detonations for military and civilian purposes underwater, in the atmosphere, and in outer space.

The PTBT had mixed results. On the one hand, enactment of the treaty was followed by a substantial drop in the atmospheric concentration of radioactive particles. On the other hand, nuclear proliferation was not halted entirely (though it may have been slowed) and nuclear testing continued at a rapid clip. Compared to the 499 tests from 1945 to the signing of the PTBT, 436 tests were conducted over the ten years following the PTBT. Furthermore, US and Soviet underground testing continued "venting" radioactive gas into the atmosphere. Additionally, though underground testing was generally safer than above-ground testing, underground tests continued to risk the leaking of radionuclides, including plutonium, into the ground. From 1964 through 1996, the year of the CTBT's adoption, an estimated 1,377 underground nuclear tests were conducted. The final non-underground (atmospheric or underwater) test was conducted by China in 1980.

The PTBT has been seen as a step towards the Nuclear Non-proliferation Treaty (NPT) of 1968, which directly made reference to the PTBT. Under the NPT, non-nuclear weapon states were prohibited from possessing, manufacturing, and acquiring nuclear weapons or other nuclear explosive devices. All signatories, including nuclear weapon states, were committed to the goal of total nuclear disarmament. However, India, Pakistan, and Israel have declined to sign the NPT on grounds that such a treaty is fundamentally discriminatory as it places limitations on states that do not have nuclear weapons while making no efforts to curb weapons development by declared nuclear weapons states.

In 1974, a step towards a comprehensive test ban was made with the Threshold Test Ban Treaty (TTBT), ratified by the US and Soviet Union, which banned underground tests with yields above 150 kilotons. In April 1976, the two states reached agreement on the Peaceful Nuclear Explosions Treaty (PNET), which concerns nuclear detonations outside the weapons sites discussed in the TTBT. As in the TTBT, the US and Soviet Union agreed to bar peaceful nuclear explosions (PNEs) at these other locations with yields above 150 kilotons, as well as group explosions with total yields in excess of 1,500 kilotons. To verify compliance, the PNET requires that states rely on national technical means of verification, share information on explosions, and grant on-site access to counterparties. The TTBT and PNET did not enter into force for the US and Soviet Union until 11 December 1990.

In October 1977, the US, UK, and Soviet Union returned to negotiations over a test ban. The three nuclear powers made notable progress in the late 1970s, agreeing to terms on a ban on all testing, including a temporary prohibition on PNEs, but continued disagreements over the compliance mechanisms led to an end to negotiations ahead of Ronald Reagan's inauguration as President in 1981. In 1985, Soviet leader Mikhail Gorbachev announced a unilateral testing moratorium, and in December 1986, Reagan reaffirmed US commitment to pursue the long-term goal of a comprehensive test ban. In November 1987, negotiations on a test ban restarted, followed by a joint US-Soviet program to research underground-test detection in December 1987.

Given the political situation prevailing in the subsequent decades, little progress was made in nuclear disarmament until the end of the Cold War in 1991. Parties to the PTBT held an amendment conference that year to discuss a proposal to convert the Treaty into an instrument banning all nuclear-weapon tests. With strong support from the UN General Assembly, negotiations for a comprehensive test-ban treaty began in 1993.

Extensive efforts were made over the next three years to draft the Treaty text and its two annexes. However, the Conference on Disarmament, in which negotiations were being held, did not succeed in reaching consensus on the adoption of the text. Under the direction of Prime Minister John Howard and Foreign Minister Alexander Downer, Australia then sent the text to the United Nations General Assembly in New York, where it was submitted as a draft resolution. On 10 September 1996, the Comprehensive Test-Ban Treaty (CTBT) was adopted by a large majority, exceeding two-thirds of the General Assembly's Membership.

(Article I):

The Treaty was adopted by the United Nations General Assembly on 10 September 1996. It opened for signature in New York on 24 September 1996, when it was signed by 71 States, including five of the eight then nuclear-capable states. As of October 2016, 166 states have ratified the CTBT and another 17 states have signed but not ratified it.

The treaty will enter into force 180 days after the 44 states listed in Annex 2 of the treaty have ratified it. These "Annex 2 states" are states that participated in the CTBT’s negotiations between 1994 and 1996 and possessed nuclear power reactors or research reactors at that time. As of 2016, eight Annex 2 states have not ratified the treaty: China, Egypt, Iran, Israel and the United States have signed but not ratified the Treaty; India, North Korea and Pakistan have not signed it.

Geophysical and other technologies are used to monitor for compliance with the Treaty: forensic seismology, hydroacoustics, infrasound, and radionuclide monitoring. The technologies are used to monitor the underground, the waters and the atmosphere for any sign of a nuclear explosion. Statistical theories and methods are integral to CTBT monitoring providing confidence in verification analysis. Once the Treaty enters into force, on-site inspection will be provided for where concerns about compliance arise.

The Preparatory Commission for the Comprehensive Test Ban Treaty Organization (CTBTO), an international organization headquartered in Vienna, Austria, was created to build the verification regime, including establishment and provisional operation of the network of monitoring stations, the creation of an international data centre, and development of the On Site Inspection capability.

The monitoring network consists of 337 facilities located all over the globe. As of May 2012, more than 260 facilities have been certified. The monitoring stations register data that is transmitted to the international data centre in Vienna for processing and analysis. The data are sent to states that have signed the Treaty.

Three countries have tested nuclear weapons since the CTBT opened for signature in 1996. India and Pakistan both carried out two sets of tests in 1998. North Korea carried out six announced tests in 2006, 2009, 2013, two in 2016 and one in 2017. All six North Korean tests were picked up by the International Monitoring System set up by the Comprehensive Nuclear-Test-Ban Treaty Organization Preparatory Commission. A North Korean test is believed to have taken place in January 2016, evidenced by an "artificial earthquake" measured as a magnitude 5.1 by the U.S. Geological Survey. The first successful North Korean hydrogen bomb test supposedly took place September 2017. It was estimated to have an explosive yield of 120 kilotons .




</doc>
<doc id="7885" url="https://en.wikipedia.org/wiki?curid=7885" title="Dance">
Dance

Dance is a performing art form consisting of purposefully selected sequences of human movement. This movement has aesthetic and symbolic value, and is acknowledged as dance by performers and observers within a particular culture. Dance can be categorized and described by its choreography, by its repertoire of movements, or by its historical period or place of origin.

An important distinction is to be drawn between the contexts of theatrical and participatory dance, although these two categories are not always completely separate; both may have special functions, whether social, ceremonial, competitive, erotic, martial, or sacred/liturgical. Other forms of human movement are sometimes said to have a dance-like quality, including martial arts, gymnastics, cheerleading, figure skating, synchronized swimming, marching bands, and many other forms of athletics.

Theatrical dance, also called performance or concert dance, is intended primarily as a spectacle, usually a performance upon a stage by virtuoso dancers. It often tells a story, perhaps using mime, costume and scenery, or else it may simply interpret the musical accompaniment, which is often specially composed. Examples are western ballet and modern dance, Classical Indian dance and Chinese and Japanese song and dance dramas. Most classical forms are centred upon dance alone, but performance dance may also appear in opera and other forms of musical theatre.

Participatory dance, on the other hand, whether it be a folk dance, a social dance, a group dance such as a line, circle, chain or square dance, or a partner dance such as is common in western Western ballroom dancing, is undertaken primarily for a common purpose, such as social interaction or exercise, of participants rather than onlookers. Such dance seldom has any narrative. A group dance and a "corps de ballet", a social partner dance and a "pas de deux", differ profoundly. Even a solo dance may be undertaken solely for the satisfaction of the dancer. Participatory dancers often all employ the same movements and steps but, for example, in the rave culture of electronic dance music, vast crowds may engage in free dance, uncoordinated with those around them. On the other hand, some cultures lay down strict rules as to the particular dances in which, for example, men, women and children may or must participate.

Archeological evidence for early dance includes 9,000-year-old paintings in India at the Rock Shelters of Bhimbetka, and Egyptian tomb paintings depicting dancing figures, dated c. 3300 BC. It has been proposed that before the invention of written languages, dance was an important part of the oral and performance methods of passing stories down from generation to generation. The use of dance in ecstatic trance states and healing rituals (as observed today in many contemporary "primitive" cultures, from the Brazilian rainforest to the Kalahari Desert) is thought to have been another early factor in the social development of dance.

References to dance can be found in very early recorded history; Greek dance ("horos") is referred to by Plato, Aristotle, Plutarch and Lucian. The Bible and Talmud refer to many events related to dance, and contain over 30 different dance terms. In Chinese pottery as early as the Neolithic period, groups of people are depicted dancing in a line holding hands, and the earliest Chinese word for "dance" is found written in the oracle bones. Dance is further described in the "Lüshi Chunqiu". Primitive dance in ancient China was associated with sorcery and shamanic rituals.

During the first millennium BCE in India, many texts were composed which attempted to codify aspects of daily life. Bharata Muni's "Natyashastra" (literally ""the text of dramaturgy"") is one of the earlier texts. It mainly deals with drama, in which dance plays an important part in Indian culture. It categorizes dance into four types - secular, ritual, abstract, and, interpretive - and into four regional varieties. The text elaborates various hand-gestures ("mudras") and classifies movements of the various limbs, steps and so on. A strong continuous tradition of dance has since continued in India, through to modern times, where it continues to play a role in culture, ritual, and, notably, the Bollywood entertainment industry. Many other contemporary dance forms can likewise be traced back to historical, traditional, ceremonial, and ethnic dance.

Dance is generally, though not exclusively, performed with the accompaniment of music and may or may not be performed "in time" to such music. Some dance (such as tap dance) may provide its own audible accompaniment in place of (or in addition to) music. Many early forms of music and dance were created for each other and are frequently performed together. Notable examples of traditional dance/music couplings include the jig, waltz, tango, disco, and salsa. Some musical genres have a parallel dance form such as baroque music and baroque dance; other varieties of dance and music may share nomenclature but developed separately, such as classical music and classical ballet.

Rhythm and dance are deeply linked in history and practice. The American dancer Ted Shawn wrote; "The conception of rhythm which underlies all studies of the dance is something about which we could talk forever, and still not finish." A musical rhythm requires two main elements; first, a regularly-repeating pulse (also called the "beat" or "tactus") that establishes the tempo and, second, a pattern of accents and rests that establishes the character of the metre or basic rhythmic pattern. The basic pulse is roughly equal in duration to a simple step or gesture. 

Dances generally have a characteristic tempo and rhythmic pattern. The tango, for example, is usually danced in time at approximately 66 beats per minute. The basic slow step, called a "slow", lasts for one beat, so that a full "right–left" step is equal to one measure. The basic forward and backward walk of the dance is so counted - "slow-slow" - while many additional figures are counted "slow - quick-quick.

Just as musical rhythms are defined by a pattern of strong and weak beats, so repetitive body movements often depends on alternating "strong" and "weak" muscular movements. Given this alternation of left-right, of forward-backward and rise-fall, along with the bilateral symmetry of the human body, it is natural that many dances and much music are in duple and quadruple meter. However, since some such movements require more time in one phase than the other - such as the longer time required to lift a hammer than to strike - some dance rhythms fall equally naturally into triple metre. Occasionally, as in the folk dances of the Balkans, dance traditions depend heavily on more complex rhythms. Further, complex dances composed of a fixed sequence of steps always require phrases and melodies of a certain fixed length to accompany that sequence.
The very act of dancing, the steps themselves, generate an "initial skeleton of rhythmic beats" that must have preceded any separate musical accompaniment, while dance itself, as much as music, requires time-keeping just as utilitarian repetitive movements such as walking, hauling and digging take on, as they become refined, something of the quality of dance.

Musical accompaniment therefore arose in the earliest dance, so that ancient Egyptians attributed the origin of the dance to the divine Athotus, who was said to have observed that music accompanying religious rituals caused participants to move rhythmically and to have brought these movements into proportional measure. The same idea, that dance arises from musical rhythm, is still found in renaissance Europe in the works of the dancing master Guglielmo Ebreo da Pesaro who speaks of dance as a physical movement that arises from and expresses inward, spiritual motion agreeing with the "measures and perfect concords of harmony" that fall upon the human ear, while, earlier, Mechthild of Magdeburg, seizing upon dance as a symbol of the holy life foreshadowed in Jesus' saying "I have piped and ye have not danced", writes;

Thoinot Arbeau's celebrated 16th century dance-treatise "Orchésographie", indeed, begins with definitions of over eighty distinct drum-rhythms.
As has been shown above, dance has been represented through the ages as having emerged as a response to music yet, as Lincoln Kirstein implied, it is at least as likely that primitive music arose from dance. Shawn concurs, stating that dance "was the first art of the human race, and the matrix out of which all other arts grew" and that even the "metre in our poetry today is a result of the accents necessitated by body movement, as the dancing and reciting were performed simultaneously" - an assertion somewhat supported by the common use of the term "foot" to describe the fundamental rhythmic units of poetry.

Scholes, not a dancer but a musician, offers support for this view, stating that the steady measures of music, of two, three or four beats to the bar, its equal and balanced phrases, regular cadences, contrasts and repetitions, may all be attributed to the "incalculable" influence of dance upon music.

Émile Jaques-Dalcroze, primarily a musician and teacher, relates how a study of the physical movements of pianists led him "to the discovery that musical sensations of a rhythmic nature call for the muscular and nervous response of the whole organism", to develop "a special training designed to regulate nervous reactions and effect a co-ordination of muscles and nerves" and ultimately to seek the connections between "the art of music and the art of dance", which he formulated into his system of eurhythmics. He concluded that "musical rhythm is only the transposition into sound of movements and dynamisms spontaneously and involuntarily expressing emotion".

Hence, though doubtless, as Shawn asserts, "it is quite possible to develop the dance without music and... music is perfectly capable of standing on its own feet without any assistance from the dance", nevertheless the "two arts will always be related and the relationship can be profitable both to the dance and to music", the precedence of one art over the other being a moot point. The common ballad measures of hymns and folk-songs takes their name from dance, as does the carol, originally a circle dance. Many purely musical pieces have been named "waltz" or "minuet", for example, while many concert dances have been produced that are based upon abstract musical pieces, such as "2 and 3 Part Inventions, Adams Violin Concerto" and "Andantino". Similarly, poems are often structured and named after dances or musical works, while dance and music have both drawn their conception of "measure" or "metre" from poetry.

Shawn quotes with approval the statement of Dalcroze that, while the art of musical rhythm consists in differentiating and combining time durations, pauses and accents "according to physiological law", that of "plastic rhythm" (i.e. dance) "is to designate movement in space, to interpret long time-values by slow movements and short ones by quick movements, regulate pauses by their divers successions and express sound accentuations in their multiple nuances by additions of bodily weight, by means of muscular innervations".

Shawn nevertheless points out that the system of musical time is a "man-made, artificial thing... a manufactured tool, whereas rhythm is something that has always existed and depends on man not at all", being "the continuous flowing time which our human minds cut up into convenient units", suggesting that music might be revivified by a return to the values and the time-perception of dancing.

The early-20th-century American dancer Helen Moller stated simply that "it is rhythm and form more than harmony and color which, from the beginning, has bound music, poetry and dancing together in a union that is indissoluble."

Concert dance, like opera, generally depends for its large-scale form upon a narrative dramatic structure. The movements and gestures of the choreography are primarily intended to mime the personality and aims of the characters and their part in the plot. Such theatrical requirements tend towards longer, freer movements than those usual in non-narrative dance styles. On the other hand, the "ballet blanc", developed in the 19th century, allows interludes of rhythmic dance that developed into entirely "plotless" ballets in the 20th century and that allowed fast, rhythmic dance-steps such as those of the "petit allegro". A well-known example is "The Cygnets' Dance" in act two of "Swan Lake".

The ballet developed out of courtly dramatic productions of 16th- and 17th-century France and Italy and for some time dancers performed dances developed from those familiar from the musical suite, all of which were defined by definite rhythms closely identified with each dance. These appeared as character dances in the era of romantic nationalism.

Ballet reached widespread vogue in the romantic era, accompanied by a larger orchestra and grander musical conceptions that did not lend themselves easily to rhythmic clarity and by dance that emphasised dramatic mime. A broader concept of rhythm was needed, that which Rudolf Laban terms the "rhythm and shape" of movement that communicates character, emotion and intention, while only certain scenes required the exact synchronisation of step and music essential to other dance styles, so that, to Laban, modern Europeans seemed totally unable to grasp the meaning of "primitive rhythmic movements", a situation that began to change in the 20th century with such productions as Igor Stravinsky's "The Rite of Spring" with its new rhythmic language evoking primal feelings of a primitive past.

Indian classical dance styles, like ballet, are often in dramatic form, so that there is a similar complementarity between narrative expression and "pure" dance. In this case, however, the two are separately defined, though not always separately performed. The rhythmic elements, which are abstract and technical, are known as "nritta". Both this and expressive dance "(nritya)", though, are closely tied to the rhythmic system ("tala"). Teachers have adapted the spoken rhythmic mnemonic system called "bol" to the needs of dancers.

Japanese classical dance-theatre styles such as Kabuki and Noh, like Indian dance-drama, distinguish between narrative and abstract dance productions. The three main categories of kabuki are "jidaimono" (historical), "sewamono" (domestic) and "shosagoto" (dance pieces). Somewhat similarly, Noh distinguishes between "Geki Noh", based around the advancement of plot and the narration of action, and "Furyū Noh", dance pieces involving acrobatics, stage properties, multiple characters and elaborate stage action.

Social dances, those intended for participation rather than for an audience, may include various forms of mime and narrative, but are typically set much more closely to the rhythmic pattern of music, so that terms like waltz and polka refer as much to musical pieces as to the dance itself. The rhythm of the dancers' feet may even form an essential part of the music, as in tap dance. African dance, for example, is rooted in fixed basic steps, but may also allow a high degree of rhythmic interpretation: the feet or the trunk mark the basic pulse while cross-rhythms are picked up by shoulders, knees, or head, with the best dancers simultaneously giving plastic expression to all the elements of the polyrhythmic pattern.

Dance in Africa is deeply integrated into society and major events in a community are frequently reflected in dances: dances are performed for births and funerals, weddings and wars. Traditional dances impart cultural morals, including religious traditions and sexual standards; give vent to repressed emotions, such as grief; motivate community members to cooperate, whether fighting wars or grinding grain; enact spiritual rituals; and contribute to social cohesiveness.

Thousands of dances are performed around the continent. These may be divided into traditional, neotraditional, and classical styles: folkloric dances of a particular society, dances created more recently in imitation of traditional styles, and dances transmitted more formally in schools or private lessons. African dance has been altered by many forces, such as European missionaries and colonialist governments, who often suppressed local dance traditions as licentious or distracting. Dance in contemporary African cultures still serves its traditional functions in new contexts; dance may celebrate the inauguration of a hospital, build community for rural migrants in unfamiliar cities, and be incorporated into Christian church ceremonies.

All Indian classical dances are to varying degrees rooted in the "Natyashastra" and therefore share common features: for example, the "mudra"s (hand positions), some body positions, and the inclusion of dramatic or expressive acting or abhinaya. Indian classical music provides accompaniment and dancers of nearly all the styles wear bells around their ankles to counterpoint and complement the percussion.

There are now many regional varieties of Indian classical dance. Dances like ""Odra Magadhi"", which after decades long debate, has been traced to present day Mithila, Odisha region's dance form of Odissi (Orissi), indicate influence of dances in cultural interactions between different regions.

The Punjab area overlapping India and Pakistan is the place of origin of Bhangra. It is widely known both as a style of music and a dance. It is mostly related to ancient harvest celebrations, love, patriotism or social issues. Its music is coordinated by a musical instrument called the 'Dhol'. Bhangra is not just music but a dance, a celebration of the harvest where people beat the dhol (drum), sing Boliyaan (lyrics) and dance. It developed further with the Vaisakhi festival of the Sikhs.

The dances of Sri Lanka include the devil dances ("yakun natima"), a carefully crafted ritual reaching far back into Sri Lanka's pre-Buddhist past that combines ancient "Ayurvedic" concepts of disease causation with psychological manipulation and combines many aspects including Sinhalese cosmology. Their influence can be seen on the classical dances of Sri Lanka.
The dances of the Middle East are usually the traditional forms of circle dancing which are modernized to an extent. They would include dabke, tamzara, Assyrian folk dance, Kurdish dance, Armenian dance and Turkish dance, among others. All these forms of dances would usually involve participants engaging each other by holding hands or arms (depending on the style of the dance). They would make rhythmic moves with their legs and shoulders as they curve around the dance floor. The head of the dance would generally hold a cane or handkerchief.

Folk dances vary across Europe and may date back hundreds or thousands of years, but many have features in common such as group participation led by a caller, hand-holding or arm-linking between participants, and fixed musical forms known as caroles. Some, such as the maypole dance are common to many nations, while others such as the céilidh and the polka are deeply-rooted in a single culture. Some European folk dances such as the square dance were brought to the New World and subsequently became part of American culture.

Ballet developed first in Italy and then in France from lavish court spectacles that combined music, drama, poetry, song, costumes and dance. Members of the court nobility took part as performers. During the reign of Louis XIV, himself a dancer, dance became more codified. Professional dancers began to take the place of court amateurs, and ballet masters were licensed by the French government. The first ballet dance academy was the Académie Royale de Danse (Royal Dance Academy), opened in Paris in 1661. Shortly thereafter, the first institutionalized ballet troupe, associated with the Academy, was formed; this troupe began as an all-male ensemble but by 1681 opened to include women as well.

20th century concert dance brought an explosion of innovation in dance style characterized by an exploration of freer technique. Early pioneers of what became known as modern dance include Loie Fuller, Isadora Duncan, Mary Wigman and Ruth St. Denis. The relationship of music to dance serves as the basis for Eurhythmics, devised by Emile Jaques-Dalcroze, which was influential to the development of Modern dance and modern ballet through artists such as Marie Rambert. Eurythmy, developed by Rudolf Steiner and Marie Steiner-von Sivers, combines formal elements reminiscent of traditional dance with the new freer style, and introduced a complex new vocabulary to dance. In the 1920s, important founders of the new style such as Martha Graham and Doris Humphrey began their work. Since this time, a wide variety of dance styles have been developed; see Modern dance.
African American dance developed in everyday spaces, rather than in dance studios, schools or companies. Tap dance, disco, jazz dance, swing dance, hip hop dance, the lindy hop with its relationship to rock and roll music and rock and roll dance have had a global influence. Dance styles fusing classical ballet technique with African-American dance have also appeared in the 21st century, including Hiplet.

Dance is central to Latin American social life and culture. Brazilian Samba, Argentinian tango, and Cuban salsa are internationally popular partner dances, and other national dances—merengue, cueca, plena, jarabe, joropo, marinera, cumbia, and others—are important components of their respective countries' cultures. Traditional Carnival festivals incorporate these and other dances in enormous celebrations.

Dance has played an important role in forging a collective identity among the many cultural and ethnic groups of Latin America. Dance served to unite the many African, European, and indigenous peoples of the region. Certain dance genres, such as capoeira, and body movements, especially the characteristic "quebrada" or pelvis swing, have been variously banned and celebrated throughout Latin American history.

Hip Hop originated in New York, specifically in the area known as the Bronx. It was created for those who struggled in society and didn't seem to have a voice in the community that surrounded them because of their lack of wealth. It helped those in the same situation come together and speak about difficult topics by using movement and feeling.

Dance studies are offered through the arts and humanities programs of many higher education institutions. Some universities offer Bachelor of Arts and higher academic degrees in Dance. A dance study curriculum may encompass a diverse range of courses and topics, including dance practice and performance, choreography, ethnochoreology, kinesiology, dance notation, and dance therapy.

Professional dancers are usually employed on contract or for particular performances or productions. The professional life of a dancer is generally one of constantly changing work situations, strong competitive pressure and low pay. Consequently, professional dancers often must supplement their incomes to achieve financial stability. In the U.S. many professional dancers belong to unions (such as the American Guild of Musical Artists, Screen Actors Guild and Actors' Equity Association) that establish working conditions and minimum salaries for their members. Professional dancers must possess large amounts of athleticism. To lead a successful career, it is advantageous to be versatile in many styles of dance, have a strong technical background and to utilize other forms of physical training to remain fit and healthy.

Dance teachers typically focus on teaching dance performance, or coaching competitive dancers, or both. They typically have performance experience in the types of dance they teach or coach. For example, dancesport teachers and coaches are often tournament dancers or former dancesport performers. Dance teachers may be self-employed, or employed by dance schools or general education institutions with dance programs. Some work for university programs or other schools that are associated with professional classical dance (e.g., ballet) or modern dance companies. Others are employed by smaller, privately owned dance schools that offer dance training and performance coaching for various types of dance.

Choreographers are often university trained and are typically employed for particular projects or, more rarely may work on contract as the resident choreographer for a specific dance company.

A dance competition is an organized event in which contestants perform dances before a judge or judges for awards, and in some cases, monetary prizes. There are several major types of dance competitions, distinguished primarily by the style or styles of dances performed. Major types of dance competitions include:

In addition, there are numerous dance competitions shows presented on television and other mass media.





</doc>
<doc id="7886" url="https://en.wikipedia.org/wiki?curid=7886" title="Drew Barrymore">
Drew Barrymore

Drew Blythe Barrymore (born February 22, 1975) is an American actress, author, director, model, and producer. She is a member of the Barrymore family of American stage and film actors, and the granddaughter of John Barrymore. She made her breakout role as a child actress in Steven Spielberg's film "E.T. the Extra-Terrestrial" (1982).

Following a highly publicized, turbulent childhood marked by drug and alcohol abuse with two stints in rehab, she released her autobiography, "Little Girl Lost" (1991). Barrymore subsequently appeared in a string of successful films, including "Poison Ivy" (1992), "Scream" (1996), and "Ever After" (1998). She is also known for co-starring with Adam Sandler in "The Wedding Singer" (1998), "50 First Dates" (2004), and "Blended" (2014). 

In 1995, she and Nancy Juvonen formed a joint production company, Flower Films, and went on to produce several films in which Barrymore also starred, such as "Never Been Kissed" (1999), "Charlie's Angels" (2000), "Donnie Darko" (2001), "Fever Pitch" (2005), "Music and Lyrics" (2007), and her directorial debut "Whip It!" (2009). Barrymore won a Screen Actors Guild Award and a Golden Globe Award for her performance in the HBO drama film "Grey Gardens" (2009). Since 2017, she has starred in the Netflix television series "Santa Clarita Diet".

Barrymore was born in Culver City, California, to actor John Barrymore and aspiring actress Jaid (born Ildikó Jaid Makó). Jaid was born in a displaced persons camp in Brannenburg, West Germany, to Hungarian World War II refugees. Barrymore is one of four children with a half-brother, John, who is also an actor. Her parents divorced in 1984, when she was nine years old. 

She was born into the Barrymore acting dynasty: All of her paternal great-grandparents – Maurice and Georgie Drew Barrymore, Maurice and Mae Costello ( Altschuk) – as well as her paternal grandparents, John Barrymore and Dolores Costello, were actors, with John being arguably the most acclaimed actor of his generation. Barrymore is a niece of Diana Barrymore, a grandniece of Lionel Barrymore, Ethel Barrymore, and Helene Costello, and a great-great-granddaughter of Irish-born John and English-born Louisa Lane Drew, all of whom were also actors. She was a great-grandniece of Broadway idol John Drew, Jr. and silent film actor, writer and director Sidney Drew. 

Her godmothers are actress Sophia Loren and Lee Strasberg's widow Anna Strasberg; Barrymore described her relationship with the latter as one that "would become so important to me as a kid because she was so kind and nurturing." Her godfather is director Steven Spielberg.

Her first name, "Drew", was the maiden name of her paternal great-grandmother, Georgie Drew, and her middle name, "Blythe," was the original surname of the dynasty founded by her great-grandfather, Maurice. Barrymore recounted in her 1989 autobiography, "Little Girl Lost", early memories of her abusive father, who left the family when Barrymore was six months old. They never had anything resembling a significant relationship and seldom spoke to each other.

Barrymore grew up on Poinsetta Place in West Hollywood until the age of 7, when she moved to Sherman Oaks. In her 2015 memoir "Wildflower", she says she talks "like a valley girl" because she grew up in Sherman Oaks. She moved back to West Hollywood, upon becoming emancipated at 14. Barrymore attended elementary school at Fountain Day School in West Hollywood and Country School.

In the wake of her sudden stardom, Barrymore endured a notoriously troubled childhood. She was already a regular at the racy Studio 54 as a young girl, smoking cigarettes at the age of nine, drinking alcohol at age eleven, smoking marijuana at age twelve and snorting cocaine at age thirteen. Her nightlife and constant partying became a popular subject with the media. She was in rehab at the age of fourteen, and spent eighteen months in an institution for the mentally ill. A suicide attempt, also at 14, put her back in rehab, followed by a three-month stay with singer David Crosby (of rock group Crosby, Stills, Nash & Young) and his wife. The stay was precipitated, Crosby said, because she "needed to be around some people that were committed to sobriety." Barrymore later described this period of her life in her autobiography, "Little Girl Lost." After a successful juvenile court petition for emancipation, she moved into her own apartment at the age of fifteen.

Barrymore's professional career began at eleven months, when she auditioned for a dog food commercial. She was nipped by her canine costar, to which she merely laughed and was hired for the job. After her film debut with a small role in "Altered States" (1980), she played Gertie in "E.T. the Extra-Terrestrial" (1982), directed by Steven Spielberg. He felt that she had the right imagination for her role after she impressed him with a story that she led a punk rock band. "E.T." is the highest-grossing film of the 1980s and made her one of the most famous child stars of the time. For her work, she won a Young Artist Award for Best Supporting Actress.

In the 1984 science fiction horror adaptation of the 1980 eponymous Stephen King novel "Firestarter," Barrymore played a girl with pyrokinesis who becomes the target of a secret government agency known as The Shop. The same year, she played a young girl divorcing her famous parents in "Irreconcilable Differences", for which she was nominated for her first Golden Globe Award for Best Supporting Actress. In a review in the "Chicago Sun-Times", Roger Ebert stated, "Barrymore is the right actress for this role precisely because she approaches it with such grave calm."

She endured a troubled youth and continued to act intermittently during the decade. She starred in the 1985 anthology horror film "Cat's Eye," written again by Stephen King. The film received positive reviews and Barrymore was nominated for a Young Artist Award for Best Leading Young Actress. She starred alongside Jeff Bridges and Alice Krige in the 1989 romantic comedy "See You in the Morning." Vincent Canby of "The New York Times" criticized "the fashionable phoniness" of the film, but positively singled out Barrymore for her performance.

After her twelve-day rehab treatment at ASAP, Barrymore starred in "Far from Home" (1989), as a teenager who gets stranded with her father in the small town in a remote part of the desert. The film went largely unnoticed by audiences and received negative reviews from critics, who dismissed the sexual portrayal of her role.

In the early 1990s, her rebelliousness played itself out on screen and in print. Barrymore forged an image as a manipulative teenage seductress, beginning with "Poison Ivy" (1992), which was a box office failure, but was popular on video and cable. Her character Ivy was ranked at #6 on the list of the top 26 "bad girls" of all time by "Entertainment Weekly". In 1992, Barrymore posed nude for the cover of the July issue of "Interview" magazine with her then-fiancé, actor Jamie Walters, as well as appearing nude in pictures inside the issue.

In the crime thriller "Guncrazy" (1992), she starred as a teenager who kills her sexual abusive stepfather, after he teaches her how to use a gun. "Variety" remarked she "pulls off impressively" her character, Barrymore was nominated for the Golden Globe Award. In 1993, she took on the role of the younger sister of a murdered ballerina in "No Place to Hide" and starred as a writer followed by what is apparently her evil twin in "Doppelganger". Both thrillers were panned by critics and failed to find an audience. She appeared in the western comedy "Bad Girls" (1994), which follows four former prostitutes on the run following a justifiable homicide and prison escape. Roger Ebert, in his review for the film, wrote for "Chicago Sun-Times": "What a good idea, to make a Western about four tough women. And what a sad movie."

When she was nineteen, she posed nude for the January 1995 issue of "Playboy". Steven Spielberg, who is also her godfather, gave her a quilt for her twentieth birthday with a note that read, "Cover yourself up." Enclosed were copies of her "Playboy" pictures, with the pictures altered by his art department so that she appeared fully clothed. During her appearance on the "Late Show with David Letterman", Barrymore climbed onto David Letterman's desk and bared her breasts to him, her back to the camera, in celebration of his birthday. She modeled in a series of "Guess?" jeans ads during this time.

By the mid and late 1990s, Barrymore re-established her image and continued to be a highly bankable star. In "Boys on the Side" (1995), Barrymore played a pregnant girl who wants to escape from her abusive boyfriend. The film went little seen in theaters, but was positively received by critics. In the same year, she appeared in Joel Schumacher's film "Batman Forever", as Sugar, a moll to Two-Face (Tommy Lee Jones). In 1996, she made a brief but notable appearance in Wes Craven's slasher "Scream". Barrymore read the film's script and was interested in being involved, approaching the production team herself to request a role. The producers were quick to take advantage of her unexpected interest, and signed her to play the lead role of Sidney Prescott, but when she was faced with unexpected commitments, she instead played the smaller role of Casey Becker. "Scream" was released to critical acclaim and made an impressive US$173 million worldwide.

In "The Wedding Singer" (1998), Barrymore played Julia Sullivan, the friendly waitress of Robbie Hart (Adam Sandler). "Variety" found the film to be a "spirited, funny and warm saga" that serves them up "in a new way that enhances their most winning qualities". Budgeted at US$18 million, the film grossed US$123.3 million internationally. That same year, she starred in "Home Fries", and "Ever After" which is inspired by the fairy tale Cinderella and served as a reminder, according to Roger Ebert, of how well Barrymore "can hold the screen and involve us in her characters". She played the title role in the television special "Olive, the Other Reindeer", for which she was nominated for an Primetime Emmy Award. After Barrymore and Nancy Juvonen established Flower Films in 1995, she produced the company's first film, "Never Been Kissed" (1999), released to critical and commercial success.

In "Charlie's Angels" (2000), Barrymore, Cameron Diaz and Lucy Liu played the trio of investigators in Los Angeles. The film was a major box office success and helped solidify the standing between Barrymore and the company. Barrymore starred in "Riding in Cars with Boys" (2001), as a teenage mother in a failed marriage with the drug-addicted father (based on Beverly Donofrio's real-life story). When the production of Richard Kelly's "Donnie Darko" was threatened, Barrymore stepped forward with financing from the company, and played the title character's English teacher. Although the film was less than successful at the box office in the wake of 9/11, it reached cult film status after the DVD release, inspiring numerous websites devoted to unraveling the plot twists and meanings.

In 2002, Barrymore starred with Sam Rockwell and Julia Roberts in George Clooney's directorial debut "Confessions of a Dangerous Mind", based on the autobiography of television producer Chuck Barris. In 2003, she reprised her role as Dylan Sanders in "", and starred with Ben Stiller in "Duplex". Flower Films and Happy Madison Productions produced "50 First Dates" (2004), which Barrymore reunited with Adam Sandler. Summing up Barrymore's appeal, Roger Ebert, in his review for the film, remarked that Barrymore displayed a "smiling, coy sincerity," in what he described as a "ingratiating and lovable" film.
In the American adaptation of the 1997 eponymous British remake "Fever Pitch" (2005), Barrymore played Lindsey Meeks, the love interest of Ben Wrightman (Jimmy Fallon). The film grossed a modest US$50 million worldwide and was favorably by reviewers who felt it "has enough charm and on-screen chemistry between [Fallon and Barrymore] to make it a solid hit".

She and Hugh Grant starred in "Music and Lyrics", which focuses on the relationship that evolves between a former pop music idol and an aspiring writer as they struggle to compose a song for a reigning pop diva. The romantic comedy, released in February 2007, received largely positive reviews, with the "Washington Post" finding the two to be "great together" in it. The film was a commercial success, grossing US$145 million globally. Barrymore starred in Curtis Hanson's poker film "Lucky You". A lukewarm critical and commercial reception greeted the film upon its release, with "The New Yorker" remarking that her role "belongs in front of a sixth-grade class, not [where the film is set]."

In 2009, Barrymore starred in the ensemble comedy "He's Just Not That Into You", which garnered mixed reviews from critics, who observed her limited time on screen, while it grossed US$178 million worldwide. She played the lead role of Edith Bouvier Beale, the daughter of Edith Ewing Bouvier Beale (Jessica Lange), in the HBO film "Grey Gardens", directed by Michael Sucsy and based on the 1975 documentary of the same name. The television film was a huge success, winning five Primetime Emmy Awards and two Golden Globe Awards. "Rolling Stone" writer Peter Travels found Barrymore to be a "revelation" in her role and she won the Best Supporting Actress – Series, Miniseries or Television Film for her performance.

Barrymore made her directorial debut film "Whip It" (2009), in which she also starred alongside Ellen Page and Marcia Gay Harden, and centers on an obsession with beauty pageants and the Austin Hurl Scouts roller derby team. Critical reception towards the film was largely positive despite it not making an impression commercially. For her venture, she was nominated for a Bronze Horse at the Stockholm Film Festival and for the EDA Female Focus Award at the 2009 Alliance of Women Film Journalists. In "Everybody's Fine", Barrymore played the daughter of Frank Goode (Robert De Niro). The drama flopped at the box office and garnered average reviews, but Stephen Holden for "The New York Times" considered Barrymore "as ingenuous as ever" in what he described as a "small role".

In 2010, Barrymore starred with Justin Long in Nanette Burstein's "Going the Distance". The film follows a couple dealing the ups and downs of a long-distance relationship, while commuting between New York City and San Francisco. It garnered generally mixed reviews by critics, who summed it as "timelier and a little more honest than most romantic comedies", and budgeted at US$32 million, the film made US$40 million at the worldwide box office.
On August 2, 2011, Barrymore directed the music video for the song "Our Deal," for the band Best Coast, which features Chloë Grace Moretz, Miranda Cosgrove, Tyler Posey, Donald Glover, Shailene Woodley and Alia Shawkat. Barrymore starred with John Krasinski in the drama "Big Miracle" (2012), which covers Operation Breakthrough, the 1988 international effort to rescue gray whales from being trapped in ice near Point Barrow, Alaska. The film saw her play Rachel Krameron, based on Greenpeace activist Cindy Lowry. Despite a positive critical reception, the film bombed commercially.

In "Blended" (2014), Barrymore played Lauren Reynolds, a recently divorced woman ending up on a family resort with Jim Friedman (Adam Sandler). Film critic James Berardinelli dismissed the "hit-and-miss humor" of the story and wrote that "as [Sandler and Barrymore] are concerned, the third time is definitely not the charm", as part of an overall lukewarm critical response. The film, however, ultimately grossed US$128 million worldwide. She and Toni Collette starred in "Miss You Already" (2015), as two long-time friends whose relationship is put to the test when one starts a family and the other becomes ill. Reviewers embraced the film, while it received a limited theatrical release. In February 2018, it was announced that Barrymore is set to produce and star in Jamie Babbit's upcoming romantic comedy film "The Stand-In".

Barrymore currently stars in the Netflix television series "Santa Clarita Diet". She plays a family wife, who becomes a flesh eating zombie. Barrymore also produces the series. The single-camera series premiered on February 3, 2017, to positive reviews. A second season was released on March 23, 2018.

Barrymore became a CoverGirl Cosmetics's model and spokeswoman in 2007. In February 2015, she remained one of the faces of CoverGirl, alongside Queen Latifah and Taylor Swift. The company partnered with her because "she emulates the iconic image of CoverGirl with her fresh, natural beauty and energetic yet authentic spirit," said Esi Eggleston Bracey, Vice President and General Manager of CoverGirl Cosmetics North America. She brought not only her personality into this endorsement but also her creative side, as she also helped create the ads. She was No. 1 in "People's" annual 100 Most Beautiful People list in 2007. Later, she was named the new face for the Gucci jewelry line. As a model, Barrymore signed a contract with IMG Models New York City. She also was a spokeswoman for Crocs.

She launched a women's fashion line in fall 2017 in conjunction with Amazon.com called Dear Drew which featured a pop-up shop in New York City that opened in November.

In May 2007, Barrymore was named Ambassador Against Hunger for the United Nations World Food Programme and later donated $1 million to the cause. As a guest photographer for a magazine series called "They Shoot New York," she appeared on the cover holding a Pentax K1000 film camera. She expressed hopes of exposing her work in a gallery one day, as she had documented the most recent decade of her life with a Pentax camera.

At age 16 in 1991, Barrymore became engaged to Leland Hayward, namesake and grandson of Hollywood producer Leland Hayward. The engagement was called off a few months later. Barrymore was engaged to and lived with musician and actor Jamie Walters from 1992 to 1993.

She married her first husband, Welsh-born Los Angeles bar owner Jeremy Thomas, at age nineteen on March 20, 1994. She filed for divorce from him less than two months later.

Barrymore dated MTV host and comedian Tom Green in 1999, before getting engaged in July 2000 and married a year later. Together, they starred in "Charlie's Angels" and Green's directorial film debut "Freddy Got Fingered". Green filed for divorce in December 2001, which was finalized on October 15, 2002.

In 2002, she began dating The Strokes' drummer Fabrizio Moretti, soon after they met at a concert. Their five-year relationship ended in January 2007. She began dating Justin Long, but they broke up in July 2008. While filming "Going the Distance," Barrymore and Long reunited in 2009, but broke up again the next year.""

In early 2011, Barrymore began dating art consultant Will Kopelman, the son of former Chanel CEO Arie Kopelman. The couple announced their engagement in January 2012, and married on June 2, 2012 in Montecito, California. Four days later, the couple's wedding image appeared on the cover of "People" magazine. Barrymore and Kopelman have two daughters: Olive Barrymore Kopelman (born 2012) and Frankie Barrymore Kopelman (born 2014). On April 2, 2016, Barrymore and Kopelman released a statement confirming they had separated and intended to divorce. On July 15, 2016, Barrymore officially filed for divorce, which was finalized on August 3, 2016.

Barrymore said in an interview with Contact Music in 2003 that she had always considered herself bisexual.

Barrymore is the godmother of Kurt Cobain and Courtney Love's daughter, Frances Bean Cobain.

In 1999, Barrymore was honored by the Young Artist Foundation with its Former Child Star "Lifetime Achievement" Award commemorating her outstanding achievements within the film industry as a child actress. 

For her contributions to the film industry, Barrymore received a motion pictures star on the Hollywood Walk of Fame in 2004. Her star is located at 6925 Hollywood Boulevard.

Barrymore's films compiled a worldwide box office gross that stood at over US$2.3 billion. According to "The Hollywood Reporter"<nowiki>'</nowiki>s annual Star Salary Top 10, she was tied for eighth place on the top ten list of actresses' salaries, commanding 10 to 12 million dollars per film for 2006. Barrymore became the youngest person to have hosted "Saturday Night Live" (SNL) having hosted on November 20, 1982 at 7 years of age, a record that remained unbroken as of 2015. On February 3, 2007, Barrymore hosted "SNL" for the fifth time, making her the second female host (after Candice Bergen) in the show's history to do so. She hosted again on October 10, 2009, becoming the first female to host six times.





</doc>
<doc id="7888" url="https://en.wikipedia.org/wiki?curid=7888" title="D. W. Griffith">
D. W. Griffith

David Wark Griffith (January 22, 1875 – July 23, 1948) was an American director, writer, and producer who pioneered modern cinematic techniques. He is most remembered for "The Birth of a Nation" (1915) and "Intolerance" (1916). "The Birth of a Nation" made use of advanced camera and narrative techniques, and its popularity set the stage for the dominance of the feature-length film in the United States. The film has sparked significant controversy surrounding racism in the United States, focusing on its negative depiction of black people and the glorification of the Ku Klux Klan. Today, it is both acclaimed for its radical technique and condemned for its inherently racist philosophy. The film was subject to boycotts by the NAACP; screenings caused riots at several theaters and it was censored in many cities, including New York City. "Intolerance" was an answer to his critics.

Several of Griffith's later films were also successful, including "Broken Blossoms" (1919), "Way Down East" (1920), and "Orphans of the Storm" (1921), but his high costs for production, promotion, and roadshow often made his ventures commercial failures. He made roughly 500 films by the time of his final feature "The Struggle" (1931).

Griffith is one of the founders of the Academy of Motion Picture Arts and Sciences and among the most important figures in the history of film. He popularized the use of the close-up shot.

Griffith was born on a farm in Oldham County, Kentucky, the son of Mary Perkins ("née" Oglesby) and Jacob Wark "Roaring Jake" Griffith a Confederate Army colonel in the American Civil War who was elected as a Kentucky state legislator. Griffith was raised a Methodist, and he attended a one-room schoolhouse where he was taught by his older sister Mattie. His father died when he was ten, and the family struggled with poverty.

When Griffith was 14, his mother abandoned the farm and moved the family to Louisville, Kentucky, where she opened a boarding house. It failed shortly after. Griffith then left high school to help support the family, taking a job in a dry goods store and later in a bookstore. He began his creative career as an actor in touring companies. Meanwhile, he was learning how to become a playwright, but had little success—only one of his plays was accepted for a performance. He traveled to New York City in 1907 in an attempt to sell a script to Edison Studios producer Edwin Porter; Porter rejected the script but gave him an acting part in "Rescued from an Eagle's Nest" instead. He then decided to become an actor and appeared in many films as an extra.

In 1908, Griffith accepted a role as a stage extra in "Professional Jealousy" for the American Mutoscope and Biograph Company, where he met cameraman Billy Bitzer, and his career in the film industry changed forever. In 1908, Biograph's main director Wallace McCutcheon, Sr. grew ill, and his son Wallace McCutcheon, Jr. took his place. McCutcheon, Jr. did not bring the studio success; Biograph co-founder Harry Marvin gave Griffith the position, and he made the short "The Adventures of Dollie". He directed a total of 48 shorts for the company that year.

His short "In Old California" (1910) was the first film shot in Hollywood, California. Four years later, he produced and directed his first feature film "Judith of Bethulia" (1914), one of the earliest to be produced in the US. Biograph believed that longer features were not viable at that point. According to Lillian Gish, the company thought that "a movie that long would hurt [the audience's] eyes".

Griffith left Biograph because of company resistance to his goals and his cost overruns on the film. He took his company of actors with him and joined the Mutual Film Corporation. There, he co-produced The Life of General Villa, a biographical action–drama film starring Pancho Villa as himself, shot on location in México during a civil war. He formed a studio with Majestic Studio manager Harry Aitken which became known as Reliance-Majestic Studios and was later renamed Fine Arts Studio. His new production company became an autonomous production unit partner in Triangle Film Corporation along with Thomas H. Ince and Keystone Studios' Mack Sennett. The Triangle Film Corporation was headed by Aitken, who was released from the Mutual Film Corporation, and his brother Roy.

Griffith directed and produced "The Clansman" through Reliance-Majestic Studios in 1915, which became known as "The Birth of a Nation" and is considered one of the first feature length American films. The film was a success, but it aroused much controversy due to its depiction of slavery, the Ku Klux Klan, and race relations in the American Civil War and the reconstruction era of the United States. It was based on Thomas Dixon, Jr.'s 1905 novel "The Clansman"; it depicts Southern slavery as benign, the enfranchisement of freedmen as a corrupt plot by the Republican party, and the Ku Klux Klan as a band of heroes restoring the rightful order. This view of the era was popular at the time and was endorsed for decades by historians of the Dunning School, although it met with strong criticism from the National Association for the Advancement of Colored People (NAACP) and other groups.

The NAACP attempted to stop showings of the film. They were successful in some cities, but it was shown widely and became the most successful box office attraction of its time. It is considered among the first "blockbuster" motion pictures and broke all box office records that had been established until then. "They lost track of the money it made", Lillian Gish remarked in a Kevin Brownlow interview.

Audiences in some major northern cities rioted over the film's racial content, which was filled with action and violence. Griffith responded to his critics in his next film "Intolerance". He portrayed the effects of intolerance in four different historical periods: the Fall of Babylon; the Crucifixion of Jesus; the events surrounding the St. Bartholomew's Day massacre (during religious persecution of French Huguenots); and a modern story. "Intolerance" was not a financial success, although it had good box office turn-outs; it did not bring in enough profits to cover the lavish road show that accompanied it. Griffith put a huge budget into the film's production which could not be recovered in its box office. He mostly financed "Intolerance" himself, contributing to his financial ruin for the rest of his life.

Griffith's production partnership was dissolved in 1917 and he went to Artcraft, part of Paramount Pictures, and then to First National Pictures (1919–1920). At the same time, he founded United Artists together with Charlie Chaplin, Mary Pickford, and Douglas Fairbanks. He continued to make films, but he never achieved box office grosses as high as either "The Birth of a Nation" or "Intolerance."

Though United Artists survived as a company, Griffith's association with it was short-lived. While some of his later films did well at the box office, commercial success often eluded him. Griffith features from this period include "Broken Blossoms" (1919), "Way Down East" (1920), "Orphans of the Storm" (1921), "Dream Street" (1921), "One Exciting Night" (1922) and "America" (1924). Of these, the first three were successes at the box office. Griffith was forced to leave United Artists after "Isn't Life Wonderful" (1924) failed at the box office.

He made a part-talkie, "Lady of the Pavements" (1929), and only two full-sound films, "Abraham Lincoln" (1930) and "The Struggle" (1931). Neither was successful, and after "The Struggle" he never made another film.

In 1936, director Woody Van Dyke, who had worked as Griffith's apprentice on "Intolerance", asked Griffith to help him shoot the famous earthquake sequence for "San Francisco", but did not give him any film credit. Starring Clark Gable, Jeanette MacDonald and Spencer Tracy, it was the top-grossing film of the year.

In 1939, the producer Hal Roach hired Griffith to produce "Of Mice and Men" (1939) and "One Million B.C." (1940). He wrote to Griffith: "I need help from the production side to select the proper writers, cast, etc. and to help me generally in the supervision of these pictures."

Although Griffith eventually disagreed with Roach over the production and parted, Roach later insisted that some of the scenes in the completed film were directed by Griffith. This would make the film the final production in which Griffith was actively involved. But, cast members' accounts recall Griffith directing only the screen tests and costume tests. When Roach advertised the film in late 1939 with Griffith listed as producer, Griffith asked that his name be removed.

Although mostly forgotten by movie-goers of the time, Griffith was held in awe by many in the film industry. In the mid-1930s, he was given a special Oscar by the Academy of Motion Picture Arts and Sciences. In 1946, he made an impromptu visit to the film location of David O. Selznick's epic western "Duel in the Sun", where some of his veteran actors, Lillian Gish, Lionel Barrymore and Harry Carey, were cast members. Gish and Barrymore found their old mentor's presence distracting and became self-conscious. While the two were filming their scenes, Griffith hid behind set scenery.

On the morning of July 23, 1948, Griffith was discovered unconscious in the lobby at the Knickerbocker Hotel in Los Angeles, California, where he had been living alone. He died of a cerebral hemorrhage at 3:42 PM on the way to a Hollywood hospital. A large public service was held in his honor at the Hollywood Masonic Temple, but few stars came to pay their last respects. He is buried at Mount Tabor Methodist Church Graveyard in Centerfield, Kentucky. In 1950, The Directors Guild of America provided a stone and bronze monument for his gravesite.

Performer and director Charlie Chaplin called Griffith "The Teacher of us All". Filmmakers such as John Ford, Alfred Hitchcock, Orson Welles, Lev Kuleshov, Jean Renoir, Cecil B. DeMille, King Vidor, Victor Fleming, Raoul Walsh, Carl Theodor Dreyer, Sergei Eisenstein, and Stanley Kubrick have spoken of their respect for the director of "Intolerance." Welles said "I have never really hated Hollywood except for its treatment of D. W. Griffith. No town, no industry, no profession, no art form owes so much to a single man."

Griffith seems to have been the first to understand how certain film techniques could be used to create an expressive language; it gained popular recognition with the release of his "The Birth of a Nation" (1915). His early shorts—such as Biograph's "The Musketeers of Pig Alley" (1912), the first "gangster film"—show that Griffith's attention to camera placement and lighting heightened mood and tension. In making "Intolerance", the director opened up new possibilities for the medium, creating a form that seems to owe more to music than to traditional narrative.

Griffith has five films preserved in the United States National Film Registry deemed as being "culturally, historically, or aesthetically significant." These are "Lady Helen's Escapade" (1909), "A Corner in Wheat" (1909), "The Birth of a Nation" (1915), "Intolerance: Love's Struggle Throughout the Ages" (1916), and "Broken Blossoms" (1919).





</doc>
<doc id="7890" url="https://en.wikipedia.org/wiki?curid=7890" title="Dune">
Dune

In physical geography, a dune is a hill of loose sand built by aeolian processes (wind) or the flow of water. Dunes occur in different shapes and sizes, formed by interaction with the flow of air or water. Most kinds of dunes are longer on the stoss (upflow) side, where the sand is pushed up the dune, and have a shorter "slip face" in the lee side. The valley or trough between dunes is called a "slack". A "dune field" or erg is an area covered by extensive dunes. 

Dunes occur in some deserts and along some coasts. Some coastal areas have one or more sets of dunes running parallel to the shoreline directly inland from the beach. In most cases, the dunes are important in protecting the land against potential ravages by storm waves from the sea. Although the most widely distributed dunes are those associated with coastal regions, the largest complexes of dunes are found inland in dry regions and associated with ancient lake or sea beds. Dunes can form under the action of water flow (fluvial processes), and on sand or gravel beds of rivers, estuaries and the sea-bed.

The modern word "dune" came into English from French 1790, which in turn came from Middle Dutch "dūne".

Dunes are made of sand; the sand may be quartz, calcium carbonate, snow, gypsum, or other materials. The upwind/upstream/upcurrent side of the dune is called the stoss side; the downflow side is called the lee side. Sand is pushed (creep) or bounces (saltation) up the stoss side, and slides down the lee side. A side of a dune that the sand has slid down is called a slip face.

The Bagnold formula gives the speed at which particles can be transported.

Barchan dunes are crescent-shaped mounds which are generally wider than they are long. The lee-side slipfaces are on the concave sides of the dunes. These dunes form under winds that blow consistently from one direction (unimodal winds). They form separate crescents when the sand supply is comparatively small. When the sand supply is greater, they may merge into barchanoid ridges, and then transverse dunes (see below).

Some types of crescentic dunes move more quickly over desert surfaces than any other type of dune. A group of dunes moved more than 100 metres per year between 1954 and 1959 in China's Ningxia Province, and similar speeds have been recorded in the Western Desert of Egypt. The largest crescentic dunes on Earth, with mean crest-to-crest widths of more than three kilometres, are in China's Taklamakan Desert.

See lunettes and parabolic dues, below, for other crescent-shaped dunes.

Abundant barchan dunes (see above) may merge into barchanoid ridges, which then grade into linear (or slightly sinuous) transverse dunes, so called because they lie transverse, or across, the wind direction, with the wind blowing perpendicular to the ridge crest.

Seif dunes are linear (or slightly sinuous) dunes with two slip faces. The two slip faces make them sharp-crested. They are called "seif" dunes after the Arabic word for "sword". They may be more than 160 kilometres (100 miles) long, and thus easily visible in satellite images (see illustrations). 

Seif dunes are associated with bidirectional winds. The long axes and ridges of these dunes extend along the resultant direction of sand movement (hence the name "longitudinal"). Some linear dunes merge to form Y-shaped compound dunes. 

Formation is debated. Bagnold, in "The Physics of Blown Sand and Desert Dunes", suggested that some seif dunes form when a barchan dune moves into a bidirectional wind regime, and one arm or wing of the crescent elongates. Others suggest that seif dunes are formed by vortices in a unidirectional wind. In the sheltered troughs between highly developed seif dunes, barchans may be formed, because the wind is constrained to be unidirectional by the dunes.

Seif dunes are common in the Sahara. They range up to in height and in length. In the southern third of the Arabian Peninsula, a vast erg, called the Rub' al Khali or Empty Quarter, contains seif dunes that stretch for almost 200 km and reach heights of over 300 m.

Linear loess hills known as pahas are superficially similar. These hills appear to have been formed during the last ice age under permafrost conditions dominated by sparse tundra vegetation.

Radially symmetrical, star dunes are pyramidal sand mounds with slipfaces on three or more arms that radiate from the high center of the mound. They tend to accumulate in areas with multidirectional wind regimes. Star dunes grow upward rather than laterally. They dominate the Grand Erg Oriental of the Sahara. In other deserts, they occur around the margins of the sand seas, particularly near topographic barriers. In the southeast Badain Jaran Desert of China, the star dunes are up to 500 metres tall and may be the tallest dunes on Earth.

Oval or circular mounds that generally lack a slipface. Dome dunes are rare and occur at the far upwind margins of sand seas.

Fixed crescentic dunes that form on the leeward margins of playas and river valleys in arid and semiarid regions in response to the direction(s) of prevailing winds, are known as lunettes, source-bordering dunes, bourrelets and clay dunes. They may be composed of clay, silt, sand, or gypsum, eroded from the basin floor or shore, transported up the concave side of the dune, and deposited on the convex side. Examples in Australia are up to 6.5 km long, 1 km wide, and up to 50 metres high. They also occur in southern and West Africa, and in parts of the western United States, especially Texas.

U-shaped mounds of sand with convex noses trailed by elongated arms are parabolic dunes. These dunes are formed from blowout dunes where the erosion of vegetated sand leads to a U-shaped depression. The elongated arms are held in place by vegetation; the largest arm known on Earth reaches 12 km. Sometimes these dunes are called U-shaped, blowout, or hairpin dunes, and they are well known in coastal deserts. Unlike crescent shaped dunes, their crests point upwind. The bulk of the sand in the dune migrates forward.

In plan view, these are U-shaped or V-shaped mounds of well-sorted, very fine to medium sand with elongated arms that extend upwind behind the central part of the dune. There are slipfaces that often occur on the outer side of the nose and on the outer slopes of the arms.

These dunes often occur in semiarid areas where the precipitation is retained in the lower parts of the dune and underlying soils. The stability of the dunes was once attributed to the vegetative cover but recent research has pointed to water as the main source of parabolic dune stability. The vegetation that covers them—grasses, shrubs, and trees—help anchor the trailing arms. In inland deserts, parabolic dunes commonly originate and extend downwind from blowouts in sand sheets only partly anchored by vegetation. They can also originate from beach sands and extend inland into vegetated areas in coastal zones and on shores of large lakes.

Most parabolic dunes do not reach heights higher than a few tens of metres except at their nose, where vegetation stops or slows the advance of accumulating sand.

Simple parabolic dunes have only one set of arms that trail upwind, behind the leading nose. Compound parabolic dunes are coalesced features with several sets of trailing arms. Complex parabolic dunes include subsidiary superposed or coalesced forms, usually of barchanoid or linear shapes.

Parabolic dunes, like crescent dunes, occur in areas where very strong winds are mostly unidirectional. Although these dunes are found in areas now characterized by variable wind speeds, the effective winds associated with the growth and migration of both the parabolic and crescent dunes probably are the most consistent in wind direction.

The grain size for these well-sorted, very fine to medium sands is about 0.06 to 0.5 mm. Parabolic dunes have loose sand and steep slopes only on their outer flanks. The inner slopes are mostly well packed and anchored by vegetation, as are the corridors between individual dunes. Because all dune arms are oriented in the same direction, and, the inter-dune corridors are generally swept clear of loose sand, the corridors can usually be traversed in between the trailing arms of the dune. However to cross straight over the dune by going over the trailing arms, can be very difficult. Also, traversing the nose is very difficult as well because the nose is usually made up of loose sand without much if any vegetation.

A type of extensive parabolic dune that lacks discernible slipfaces and has mostly coarse grained sand is known as a "zibar". The term zibar comes from the Arabic word to describe "rolling transverse ridges ... with a hard surface". The dunes are small, have low relief, and can be found in many places across the planet from Wyoming (United States) to Saudi Arabia to Australia. Spacing between zibars ranges from 50 to 400 metres and they don't become more than 10 metres high. The dunes form at about ninety degrees to the prevailing wind which blows away the small, fine-grained sand leaving behind the coarser grained sand to form the crest.

Occurring wherever winds periodically reverse direction, reversing dunes are varieties of any of the above shapes. These dunes typically have major and minor slipfaces oriented in opposite directions. The minor slipfaces are usually temporary, as they appear after a reverse wind and are generally destroyed when the wind next blows in the dominant direction.

Draas are very large-scale dune bedforms; they may be tens or a few hundreds of meters in height, kilometers wide, and hundreds of kilometers in length. After a draa has reached a certain size, it generally develops superimposed dune forms. They are thought to be more ancient and slower-moving than smaller dunes, and to form by vertical growth of existing dunes. Draas are widespread in sand seas and are well-represented in the geological record.

All these dune shapes may occur in three forms: simple, compound, and complex. Simple dunes are basic forms with the minimum number of slipfaces that define the geometric type. Compound dunes are large dunes on which smaller dunes of similar type and slipface orientation are superimposed. Complex dunes are combinations of two or more dune types. A crescentic dune with a star dune superimposed on its crest is the most common complex dune. Simple dunes represent a wind regime that has not changed in intensity or direction since the formation of the dune, while compound and complex dunes suggest that the intensity and direction of the wind has changed.

The sand mass of dunes can move either windward or leeward, depending on if the wind is making contact with the dune from below or above its apogee. If wind hits from above, the sand particles move leeward. If sand hits from below, sand particles move windward. The leeward flux of sand is greater than the windward flux. Further, when the wind carrying sand particles when it hits the dune, the dune’s sand particles will saltate more than if the wind had hit the dune without carrying sand particles.

Dunes form where the beach is wide enough to allow for the accumulation of wind-blown sand, and where prevailing onshore winds tend to blow sand inland. Obstacles—for example, vegetation, pebbles and so on—tend to slow down the wind and lead to the deposition of sand grains. These small "incipient dunes or "shadow dunes" tend to grow in the vertical direction if the obstacle slowing the wind can also grow vertically (i.e., vegetation). Coastal dunes expand laterally as a result of lateral growth of coastal plants via seed or rhizome. Models of coastal dunes suggest that their final equilibrium height is related to the distance between the water line and where vegetation can grow. Additionally the height of coastal dunes is impacted by storm events, which can erode dunes. Recent work has suggested that coastal dunes tend to evolve toward a high or low morphology depending on the growth rate of dunes relative to storm frequency. In certain conditions, both low and high dunes are possible — dunes are a system that shows bistable dynamics.

Dunes provide privacy and shelter from the wind.

As a dune forms, plant succession occurs. The conditions on an "embryo dune" are harsh, with salt spray from the sea carried on strong winds. The dune is well drained and often dry, and composed of calcium carbonate from seashells. Rotting seaweed, brought in by storm waves adds nutrients to allow pioneer species to colonize the dune. These pioneer species are marram grass, sea wort grass and other sea grasses in the United Kingdom. These plants are well adapted to the harsh conditions of the foredune
typically having deep roots which reach the water table, root nodules that produce nitrogen compounds, and protected stoma, reducing transpiration. Also, the deep roots bind the sand together, and the dune grows into a foredune as more sand is blown over the grasses. The grasses add nitrogen to the soil, meaning other, less hardy plants can then colonize the dunes. Typically these are heather, heaths and gorses. These too are adapted to the low soil water content and have small, prickly leaves which reduce transpiration. Heather adds humus to the soil and is usually replaced by coniferous trees, which can tolerate low soil pH, caused by the accumulation and decomposition of organic matter with nitrate leaching. Coniferous forests and heathland are common climax communities for sand dune systems.

Young dunes are called yellow dunes and dunes which have high humus content are called grey dunes. Leaching occurs on the dunes, washing humus into the slacks, and the slacks may be much more developed than the exposed tops of the dunes. It is usually in the slacks that more rare species are developed and there is a tendency for the dune slacks soil to be waterlogged and where only marsh plants can survive. These plants would include: creeping willow, cotton grass, yellow iris, reeds, and rushes. As for the species, there is a tendency for natterjack toads to breed here.

Dune ecosystems are extremely difficult places for plants to survive. This is due to a number of pressures related to their proximity to the ocean and confinement to growth on sandy substrates. These include:
There are many adaptations plants have evolved to cope with these pressures:

A nabkha, or coppice dune, is a small dune anchored by vegetation. They usually indicate desertification or soil erosion, and serve as nesting and burrow sites for animals.

Sub-aqueous (underwater) dunes form on a bed of sand or gravel under the actions of water flow. They are ubiquitous in natural channels such as rivers and estuaries, and also form in engineered canals and pipelines. Dunes move downstream as the upstream slope is eroded and the sediment deposited on the downstream or lee slope in typical bedform construction.

These dunes most often form as a continuous 'train' of dunes, showing remarkable similarity in wavelength and height. The shape of a dune gives information about its formation environment. For instance, rives produce asymmetrical ripples, with the steeper slip face facing downstream. This is useful when they are found fossilized in the geological record.

Dunes on the bed of a channel significantly increase flow resistance, their presence and growth playing a major part in river flooding.

A lithified (consolidated) sand dune is a type of sandstone that is formed when a marine or aeolian sand dune becomes compacted and hardened. Once in this form, water passing through the rock can carry and deposit minerals, which can alter the color of the rock. Cross-bedded layers of stacks of lithified dunes can produce the cross-hatching patterns, such as those seen in the Zion National Park in the western United States.

A slang term, used in the southwest US, for consolidated and hardened sand dunes is "slickrock", a name that was introduced by pioneers of the Old West because their steel-rimmed wagon wheels could not gain traction on the rock.

Sand dunes can have a negative impact on humans when they encroach on human habitats. Sand dunes move via a few different means, all of them helped along by wind. One way that dunes can move is by saltation, where sand particles skip along the ground like a bouncing ball. When these skipping particles land, they may knock into other particles and cause them to move as well, in a process known as creep. With slightly stronger winds, particles collide in mid-air, causing sheet flows. In a major dust storm, dunes may move tens of metres through such sheet flows. Also as in the case of snow, sand avalanches, falling down the slipface of the dunes—that face away from the winds—also move the dunes forward.

Sand threatens buildings and crops in Africa, the Middle East, and China. Drenching sand dunes with oil stops their migration, but this approach is quite destructive to the dunes' animal habitats and uses a valuable resource. Sand fences might also slow their movement to a crawl, but geologists are still analyzing results for the optimum fence designs. Preventing sand dunes from overwhelming towns, villages, and agricultural areas has become a priority for the United Nations Environment Programme. Planting dunes with vegetation also helps to stabilise them.

Dune habitats provide niches for highly specialized plants and animals, including numerous rare species and some endangered species. Due to widespread human population expansion, dunes face destruction through land development and recreational usages, as well as alteration to prevent the encroachment of sand onto inhabited areas. Some countries, notably the United States, Australia, Canada, New Zealand, the United Kingdom, Netherlands, and Sri Lanka have developed significant programs of dune protection through the use of sand dune stabilization. In the U.K., a Biodiversity Action Plan has been developed to assess dunes loss and to prevent future dunes destruction.








Dunes can likely be found in any environment where there is a substantial atmosphere, winds, and dust to be blown. Dunes are common on Mars and in the equatorial regions of Titan.

Titan's dunes include large expanses with modal lengths of about 20–30 km. The regions are not topographically confined, resembling sand seas. These dunes are interpreted to be longitudinal dunes whose crests are oriented parallel to the dominant wind direction, which generally indicates west-to-east wind flow. The sand is likely composed of hydrocarbon particles, possibly with some water ice mixed in.





</doc>
<doc id="7891" url="https://en.wikipedia.org/wiki?curid=7891" title="David Lynch">
David Lynch

David Keith Lynch (born January 20, 1946) is an American filmmaker, painter, musician, actor, and photographer. He has been described by "The Guardian" as "the most important director of this era," while AllMovie called him "the Renaissance man of modern American filmmaking." He has received three Academy Award nominations for Best Director, and has won France's César Award for Best Foreign Film twice, as well as the Palme d'Or at the Cannes Film Festival and a Golden Lion award for lifetime achievement at the Venice Film Festival. His films "Blue Velvet" (1986) and "Mulholland Drive" (2001) are widely considered by critics to be among the greatest films of their respective decades. Following the success of his 1990–91 television series "Twin Peaks", film critic Pauline Kael labeled him "the first popular Surrealist."

Born to a middle-class family in Missoula, Montana, Lynch spent his childhood traveling around the United States, before going on to study painting at the Pennsylvania Academy of Fine Arts in Philadelphia, where he first made the transition to producing short films. He moved to Los Angeles, where he produced his first motion picture, the surrealist horror film "Eraserhead" (1977). After "Eraserhead" became a cult classic on the midnight movie circuit, Lynch was employed to direct the biographical film "The Elephant Man" (1980), from which he gained mainstream success. He was then employed by the De Laurentiis Entertainment Group and proceeded to make two films: the science-fiction epic "Dune" (1984), which proved to be a critical and commercial failure, and then a neo-noir mystery film "Blue Velvet" (1986), which stirred controversy over its violence but later grew in critical reputation.

Next, Lynch created his own television series with Mark Frost, the popular murder mystery "Twin Peaks" (1990–1991). He also created a cinematic prequel, "" (1992), a road film "Wild at Heart" (1990) and a family film "The Straight Story" (1999) in the same period. Turning further towards surrealist filmmaking, three of his subsequent films operated on "dream logic" non-linear narrative structures: "Lost Highway" (1997), "Mulholland Drive" (2001), and "Inland Empire" (2006). Meanwhile, Lynch embraced the Internet as a medium, producing several web-based shows, such as the animated "DumbLand" (2002) and the surreal sitcom "Rabbits" (2002). Lynch and Frost reunited for the Showtime limited series "Twin Peaks: The Return" (2017), with Lynch co-writing and directing every episode.

Lynch's other artistic endeavours include: his work as a musician, encompassing two solo albums—"Crazy Clown Time" (2011) and "The Big Dream" (2013)—as well as music and sound design for a variety of his films; painting and photography; writing two books—"Images" (1994) and "Catching the Big Fish" (2006); and directing several music videos and advertisements, including the Dior promotional film "Lady Blue Shanghai" (2006). An avid practitioner of Transcendental Meditation (TM), Lynch founded the David Lynch Foundation in 2005, which sought to fund the teaching of TM in schools and has since widened its scope to other "at-risk populations", including the homeless, veterans, and refugees.

Lynch was born in Missoula, Montana on January 20, 1946. His father, Donald Walton Lynch (1915–2007), was a research scientist working for the U.S. Department of Agriculture, and his mother, Edwina "Sunny" Lynch ("née" Sundholm; 1919–2004), was an English language tutor. Two of Lynch's maternal great-grandparents were Finnish, and had immigrated to the United States from Finland in the 19th century. Lynch was raised a Presbyterian.

The Lynch family often moved around according to where the USDA assigned Donald. It was because of this that when he was two months old, Lynch moved with his parents to Sandpoint, Idaho, and only two years after that, following the birth of his brother John, the family moved to Spokane, Washington. It was here that Lynch's sister Martha was born. The family then moved to Durham, North Carolina, then Boise, Idaho, and then Alexandria, Virginia. Lynch found this transitory early life relatively easy to adjust to, noting that he found it fairly easy to meet new friends whenever he started attending a new school. Commenting on much of his early life, Lynch has remarked:

Alongside his schooling, Lynch joined the Boy Scouts, although he would later note that he only "became [a Scout] so I could quit and put it behind me". He rose to the highest rank of Eagle Scout. It was through being an Eagle Scout that he was present with other Boy Scouts outside of the White House at the inauguration of President John F. Kennedy, which took place on Lynch's birthday in 1961. Lynch had become interested in painting and drawing from an early age, becoming intrigued by the idea of pursuing it as a career path when living in Virginia, where his friend's father was a professional painter.

At Francis C. Hammond High School in Alexandria, Lynch did poorly academically, having little interest in school work, but was popular with other students, and after leaving decided that he wanted to study painting at college, beginning his studies at the School of the Museum of Fine Arts, Boston in 1964, where he was a roommate of Peter Wolf. Nonetheless, he left the School of the Museum of Fine Arts after only a year, stating that "I was not inspired AT ALL in that place", and instead deciding that he wanted to travel around Europe for three years with his friend Jack Fisk, who was similarly unhappy with his studies at Cooper Union. They had some hopes that in Europe they could train with the expressionist painter Oskar Kokoschka at his school. Upon reaching Salzburg, however, they found that he was not available and, disillusioned, returned to the United States after spending only 15 days of their planned three years in Europe.

Back in the United States, Lynch returned to Virginia, but since his parents had moved to Walnut Creek, California, he stayed with his friend Toby Keeler for a while. He decided to move to the city of Philadelphia and enroll at the Pennsylvania Academy of Fine Arts, after advice from Jack Fisk, who was already enrolled there. He preferred this college to his previous school in Boston, claiming that "In Philadelphia there were great and serious painters, and everybody was inspiring one another and it was a beautiful time there." It was here that he began a relationship with a fellow student, Peggy Reavey, and they were married in 1967. The following year, Peggy gave birth to their daughter Jennifer. Later describing this situation, Peggy stated that "[Lynch] definitely was a reluctant father, but a very loving one. Hey, I was pregnant when we got married. We were both reluctant." As a family, they moved to the Fairmount neighborhood of Philadelphia, where they were able to purchase a large 12-room house for the relatively low price of $3,500 due to the high crime and poverty rates in the area. Later describing living there, Lynch stated that

Meanwhile, to help financially support his family alongside his art studies, he took up a job printing engravings.

At the Pennsylvania Academy Lynch made his first short film, which was titled "Six Men Getting Sick (Six Times)" (1967). He had first come up with the idea when he developed a wish to see his paintings move, and he subsequently began discussing the idea of creating an animation with an artist named Bruce Samuelson. When this project never came about, Lynch decided to work on a film alone, and so purchased the cheapest 16mm camera that he could find in order to do so. Taking one of the abandoned upper rooms of the Academy as a working space, he spent $200 – which at the time he felt to be a lot of money – to produce "Six Men Getting Sick". Describing the work as "57 seconds of growth and fire, and three seconds of vomit", Lynch played the film on a loop at the Academy's annual end-of-year exhibit, where it shared joint first prize with a painting by Noel Mahaffey. This led to a commission from one of his fellow students, the wealthy H. Barton Wasserman, who offered him $1000 to create a film installation in his home. Spending $478.28 of that on purchasing the second-hand Bolex camera "of [his] dreams", Lynch produced a new animated short, but upon getting the film developed, realized that the result was simply a blurred, frameless print. As he would later relate, "So I called up Bart [Wasserman] and said, 'Bart, the film is a disaster. The camera was broken and what I've done hasn't turned out.' And he said, 'Don't worry, David, take the rest of the money and make something else for me. Just give me a print.' End of story."
Using this leftover money, Lynch decided to experiment on making a work that was a mix of animation with live action, producing a four-minute short called "The Alphabet" (1968). The film starred Lynch's wife Peggy as a character known as The Girl, who chants the alphabet to a series of images of horses before dying at the end by hemorrhaging blood all over her bed sheets. Adding a sound effect, Lynch used a broken Uher tape recorder to record the sound of his baby daughter Jennifer crying, creating a distorted sound that Lynch felt to be particularly effective. Later describing what had inspired him, Lynch stated that "Peggy's niece was having a bad dream one night and was saying the alphabet in her sleep in a tormented way. So that's sort of what started "The Alphabet" going. The rest of it was just subconscious."

Learning about the newly founded American Film Institute, which gave grants to film makers who could support their application with a prior work and a script for a new project, Lynch decided to send them a copy of "The Alphabet" along with a script that he had written for a new short film, one that would be almost entirely live action, named "The Grandmother". The Institute agreed to help finance the work, initially offering him $5000 out of his requested budget of $7,200, but later granting him the additional $2,200 that he had requested. Starring people he knew from both work and college and filmed in his own house, "The Grandmother" featured a neglected boy who "grows" a grandmother from a seed to care for him. The film critics Michelle Le Blanc and Colin Odell later remarked that "this film is a true oddity but contains many of the themes and ideas that would filter into his later work, and shows a remarkable grasp of the medium".

In 1971, Lynch moved with his wife and daughter to Los Angeles, where he began studying filmmaking at the AFI Conservatory, a place that he would later describe as being "completely chaotic and disorganized, which was great ... you quickly learned that if you were going to get something done, you would have to do it yourself. They wanted to let people do their thing." He began writing a script for a proposed work titled "Gardenback", which had "unfolded from this painting I'd done". In this venture he was supported by a number of figures at the Conservatory, who encouraged him to lengthen the script and add more dialogue, something that he reluctantly agreed to do. Nonetheless, with all the interference on his "Gardenback" project, he became fed up with the Conservatory and quit after returning to start the second year and being put in first year classes. Dean of the AFI, Frank Daniel, asked Lynch to reconsider, believing that he was one of the school's best students. Lynch agreed on the condition that he could create his own project that would not be interfered with. Feeling that "Gardenback" was "wrecked", he instead set about on a new film, which he called "Eraserhead".

Despite the fact that the film was planned to be about forty-two minutes long (it ended up being eighty-nine minutes long), the script for "Eraserhead" was only 21 pages long, and Lynch was able to create the film free from interference. Filming, which began on May 29, 1972, took place at night in some abandoned stables, allowing the production team, which was largely Lynch and some of his friends, including Sissy Spacek, Jack Fisk, cinematographer Frederick Elmes and sound designer Alan Splet to set up a camera room, green room, editing room, sets as well as a food room and a bathroom. Initially, funding for the project came from the AFI, who gave Lynch a $10,000 grant, but it was not enough to complete the work, and under pressure from studios after the success of the relatively cheap feature film "Easy Rider", they were unable to provide him with any more. Lynch was then supported by a loan from his father, and by money that he was able to bring in from a paper route that he took up delivering the "Wall Street Journal". Not long into the production of "Eraserhead", Lynch and his wife Peggy amicably separated and divorced, and so he began living full-time on set. In 1977, Lynch would remarry, this time to Mary Fisk, sister of Jack Fisk.

Filmed in black and white, "Eraserhead" tells the story of a quiet young man named Henry (Jack Nance) living in a dystopian industrial wasteland, whose girlfriend gives birth to a deformed baby whom she leaves in his care. The baby constantly cries, causing much concern. When he realizes the baby has actually become ill, Henry tries to help it. This leads to its accidental death, after which he is haunted by what seem to be daemons that represent the baby and Henry finds himself in a "heaven" which he arrives at by entering the center of a planet rock. Lynch has consistently refused to either confirm or deny any interpretation of "Eraserhead", or to "confess his own thinking behind the many abstractions in the film". Nonetheless, he admits that it was heavily influenced by the fearful mood of Philadelphia, and referred to the film as "my "Philadelphia Story"".

Due to financial problems the filming of "Eraserhead" was haphazard, regularly stopping and starting again. It was in one such break in 1974 that Lynch created a short film titled "The Amputee", which revolved around a woman with two amputated legs (played by Jack Nance's wife, Catherine Coulson) reading aloud a letter and having her stumps washed by a doctor (played by Lynch himself).

"Eraserhead" was finally finished in 1976, after five years of production. Lynch subsequently tried to get the film entered into the Cannes Film Festival, but while some reviewers liked it, others felt that it was awful, and so it was not selected for screening. Similarly, reviewers from the New York Film Festival also rejected it, though it was screened at the Los Angeles Film Festival, where Ben Barenholtz, the distributor of the Elgin Theater, heard about it. He was very supportive of the movie, helping to distribute it around the United States in 1977, and "Eraserhead" subsequently became popular on the midnight movie underground circuit, and was later described as one of the most important midnight movies of the seventies along with "El Topo", "Pink Flamingos", "The Rocky Horror Picture Show", "The Harder They Come" and "Night of the Living Dead". The acclaimed film maker Stanley Kubrick said that it was one of his all-time favorite films.

After the cult success of "Eraserhead" on the underground circuit, Stuart Cornfeld, an executive producer for Mel Brooks, saw it and later remarked that "I was just 100 percent blown away ... I thought it was the greatest thing I'd ever seen. It was such a cleansing experience." Contacting Lynch, he agreed to help him with his next planned project, a film titled "Ronnie Rocket" for which Lynch had already written a script. However, Lynch soon realized that "Ronnie Rocket", a film that he described as being about "electricity and a three-foot guy with red hair", was not going to be picked up by any financiers, and so he asked Cornfeld to find him a script written by someone else which he could direct. Cornfeld found him four possible scripts. On hearing the title of the first, "The Elephant Man", Lynch chose the script.

"The Elephant Man" script, written by Chris de Vore and Eric Bergren, was based on a true story, that of Joseph Merrick, a heavily deformed man living in Victorian London, who was held in a sideshow but was later taken under the care of a London surgeon, Frederick Treves. Lynch wanted to make some alterations that would alter the story from true events, but in his view make a better plot. However, in order to do so he would have to get the permission of Mel Brooks, whose company, Brooksfilms, would be responsible for production; subsequently Brooks viewed "Eraserhead", and after coming out of the screening theatre, embraced Lynch, declaring that "You're a madman, I love you! You're in."

The resulting film, "The Elephant Man", starred John Hurt as John Merrick (his name was changed from Joseph), as well as Anthony Hopkins as Frederick Treves. Filming took place in London, and Lynch brought his own distinctively surrealist approach to the film, filming it in color stock black and white. Nonetheless it has been described as "one of the most conventional" of his films. "The Elephant Man" was a huge critical and commercial success, and earned eight Academy Award nominations, including Best Director and Best Adapted Screenplay for Lynch personally.

Following on from the success of "The Elephant Man", the filmmaker George Lucas, himself a fan of "Eraserhead", offered Lynch the opportunity to direct the third film in his "Star Wars" trilogy, "Return of the Jedi". Lynch refused, arguing that Lucas should direct the film himself as the movie should reflect his own vision, not Lynch's take on it. Soon after however, the opportunity to direct another big-budget science fiction epic arose when Dino de Laurentiis of the De Laurentiis Entertainment Group asked him to create a film adaptation of Frank Herbert's science fiction novel "Dune" (1965). Lynch agreed, and in doing so was also contractually obliged to produce two other works for the company. He then set about writing a script based upon the original novel, initially with both Chris de Vore and Eric Bergren, and then just by himself when De Laurentiis wasn't happy with their ideas. Lynch also helped build some of the sets, attempting to create "a certain look" for the film, and he particularly enjoyed building the set for the oil planet of Giedi Prime, for which he "used steel, bolts, and porcelain to construct" it.

"Dune" is set in the far future, when humans live in an interstellar empire under a feudal system. The main character, Paul Atreides (played by Kyle MacLachlan), is the son of a noble who takes control of the desert planet Arrakis, which grows the rare spice melange, the most highly prized commodity in the empire. Lynch, however, was unhappy with the work, later remarking that ""Dune" was a kind of studio film. I didn't have final cut. And, little by little, I was subconsciously making compromises" to his own vision. Much of his footage was eventually removed from the final theatrical cut, dramatically condensing the plot. Although De Laurentiis hoped it would be as successful as "Star Wars", Lynch's "Dune" (1984) was a critical and commercial dud; it had cost $45 million to make, and grossed a mere $27.4 million domestically. Later on, Universal Studios released an "extended cut" of the film for syndicated television, containing almost an hour of cutting-room-floor footage and new narration. Such was not representative of Lynch's intentions, but the studio considered it more comprehensible than the original two-hour version. Lynch objected to these changes and had his name struck from the extended cut, which has "Alan Smithee" credited as the director and "Judas Booth" (a pseudonym which Lynch himself invented, inspired by his own feelings of betrayal) as the screenwriter.

Meanwhile, in 1983, he had begun the writing and drawing of a comic strip, "The Angriest Dog in the World", which featured unchanging graphics of a tethered dog that was so angry that it could not move, alongside cryptic philosophical references. It ran from 1983 until 1992 in the "Village Voice", "Creative Loafing" and other tabloid and alternative publications. It was around this period that Lynch also became interested in photography as an art form, and travelled to northern England to take photos of the degrading industrial landscape, something that he was particularly interested in.

Following on from "Dune", Lynch was contractually still obliged to produce two other projects for De Laurentiis: the first of these was a planned sequel, which due to the film's lack of success never went beyond the script stage. The other was a more personal work, based upon a script that Lynch had been working on for some time. Developing from ideas that Lynch had had since 1973, the resulting film, "Blue Velvet", was set in the fictional town of Lumberton, USA, and revolves around a college student named Jeffrey Beaumont (Kyle MacLachlan), who finds a severed ear in a field. Subsequently, investigating further with the help of friend Sandy (Laura Dern), he uncovers that it is related to a criminal gang led by psychopath Frank Booth (Dennis Hopper), who has kidnapped the husband and child of singer Dorothy Vallens (Isabella Rossellini) and repeatedly subjects her to rape. Lynch himself characterizes the story as "a dream of strange desires wrapped inside a mystery story".

For the film, Lynch decided to include pop songs from the 1960s, including "In Dreams" by Roy Orbison and "Blue Velvet" by Bobby Vinton, the latter of which was largely inspirational for the film, with Lynch stating that "It was the song that sparked the movie ... There was something mysterious about it. It made me think about things. And the first things I thought about were lawns – lawns and the neighborhood." Other music for the film was also produced, this time composed by Angelo Badalamenti, who would go on to produce the music for most of Lynch's subsequent cinematic works. Dino de Laurentiis loved the film, and it achieved support from some of the early specialist screenings, but the preview screenings to a mainstream audience were instead highly negative, with most of the audience hating the film. Although Lynch had found success previously with "The Elephant Man", "Blue Velvet"s controversy with audiences and critics introduced him into the mainstream, and it became a huge critical and moderate commercial success. The film earned Lynch his second Academy Award nomination for Best Director. Woody Allen, whose film "Hannah and Her Sisters" was nominated for Best Picture, said that "Blue Velvet" was his favorite film of the year.

During the late 1980s, Lynch had begun to work in television as well as cinema, directing a short piece titled "The Cowboy and the Frenchman" for French television in 1989. Around this time, he met the television producer Mark Frost, who had formerly worked on such projects as the television police series "Hill Street Blues", and they decided to start working together on a biopic of singer and actress Marilyn Monroe based upon Anthony Summers's book, "The Goddess: The Secret Lives of Marilyn Monroe". While this project never got off the ground, the duo went on to work on a comedy script named "One Saliva Bubble", but that did not see completion either. While they were talking in a coffee shop, Lynch and Frost had the idea of a corpse washing up on the shore of a lake, and subsequently set about on their third project, initially called "Northwest Passage" but would eventually become the television series "Twin Peaks" (1990–1991).
A drama series set in a small Washington town where popular high school student Laura Palmer has been raped and murdered, "Twin Peaks" featured FBI Special Agent Dale Cooper (Kyle MacLachlan) as the investigator trying to unearth the killer, and discovering not only the supernatural elements to the murder but also the secrets of many of the local townsfolk; as Lynch himself summed it up, "The project was to mix a police investigation with the ordinary lives of the characters." Lynch later revealed that "[Mark Frost and I] worked together, especially in the initial stages. Later on we started working more apart." They pitched the series to the ABC Network, who agreed to finance the pilot episode and eventually commissioned the first season, comprising seven episodes.

A second season went into production soon on 22 additional episodes. Lynch himself only directed six episodes of the series, devoting his time to working on the film "Wild at Heart", but carefully chose the directors for other episodes. Lynch appeared in several episodes of the series as the deaf FBI agent Gordon Cole. The series was a success, with high ratings both in the United States and in many nations abroad, and soon spawned a cult following. Executives at the ABC Network, however, believed that public interest in the show was decreasing. The network insisted that Lynch and Frost reveal who the killer of Laura Palmer was prematurely, which they begrudgingly agreed to do. Lynch felt that agreeing to do so is one of his biggest professional regrets. Following the revealing of the murderer and the series' move from Thursday to Saturday night, "Twin Peaks" continued for several more episodes, but was cancelled following a ratings drop. Lynch, who disliked the direction that the writers and directors took in the previous episodes, directed the final episode. He ended the season on a cliffhanger, later remarking that "that's not the ending. That's the ending that people were stuck with."

While "Twin Peaks" was in production, the Brooklyn Academy of Music asked Lynch and the composer Angelo Badalamenti, who had been responsible for the music in "Twin Peaks", to create a theatrical piece which would be performed only twice in 1989 as a part of the New Music America Festival. The result was "Industrial Symphony No. 1: The Dream of the Broken Hearted", which starred frequent Lynch collaborators such as Laura Dern, Nicolas Cage and Michael J. Anderson, and contained five songs sung by Julee Cruise. David Lynch produced a fifty-minute video of the performance in 1990. Meanwhile, Lynch was also involved in the creation of various commercials for different companies, including perfume companies like Yves Saint Laurent, Calvin Klein and Giorgio Armani and the Japanese coffee company Namoi, which featured a Japanese man searching the town of Twin Peaks for his missing wife.

While Lynch was working on the first few episodes of "Twin Peaks", his friend Monty Montgomery "gave me a book that he wanted to direct as a movie. He asked if I would maybe be executive producer or something, and I said 'That's great, Monty, but what if I read it and fall in love with it and want to do it myself?' And he said, 'In that case, you can do it yourself'." The book was Barry Gifford's novel "Wild at Heart: The Story of Sailor and Lula", which told the tale of two lovers on a road trip. Lynch felt that it was "just exactly the right thing at the right time. The book and the violence in America merged in my mind and many different things happened." With Gifford's support, Lynch adapted the novel into a film called "Wild at Heart", a crime and road movie starring Nicolas Cage as Sailor and Laura Dern as Lula. Describing his plot as a "strange blend" of "a road picture, a love story, a psychological drama and a violent comedy", Lynch altered much from the original novel, changing the ending and incorporating numerous references to the classic film "The Wizard of Oz". Despite receiving a muted response from American critics and viewers, it won the Palme d'Or at the 1990 Cannes Film Festival.

Following on from the success of "Wild at Heart", Lynch decided to return to the world of the now-cancelled "Twin Peaks", this time without Mark Frost, to create a film that acted primarily as a prequel but also, in part, as a sequel, with Lynch stating that "I liked the idea of the story going back and forth in time." The result, "" (1992), primarily revolved around the last few days in the life of Laura Palmer, and was much "darker" in tone than the television series, having much of the humour removed, and dealing with such topics as incest and murder. Lynch himself stated that the film was about "the loneliness, shame, guilt, confusion and devastation of the victim of incest". "Twin Peaks: Fire Walk with Me" was financed by the company CIBY-2000, and most of the cast of the series agreed to reprise their roles for the film, although some refused and many were not enthusiastic about the project. The film was a commercial and critical failure in the United States; however, it was a hit in Japan and some critics, such as Mark Kermode, have hailed it as Lynch's "masterpiece".

Meanwhile, Lynch worked with Mark Frost on some new television shows. After "Twin Peaks", they produced a series of documentaries titled "American Chronicles" (1990) which examined life across the United States, the comedy series "On the Air" (1992), which was cancelled after only three episodes had aired, and the three-episode HBO miniseries "Hotel Room" (1993) about events that happen in one hotel room but on different dates.

Following these unsuccessful television ventures, Lynch returned to making feature films. In 1997 he released the non-linear, noiresque "Lost Highway", which was co-written by Barry Gifford and starred Bill Pullman and Patricia Arquette. The film failed commercially and received a mixed response from critics.

Following "Lost Highway", Lynch began work directing a film from a script written by Mary Sweeney and John E. Roach. The resulting motion picture, "The Straight Story" was based upon a true story: that of Alvin Straight (played in the film by Richard Farnsworth), an elderly man from Laurens, Iowa, who goes on a three hundred mile journey to visit his sick brother (played by Harry Dean Stanton) in Mount Zion, Wisconsin, riding a lawnmower for the entire journey. Commenting on why he chose this script, Lynch said that "that's what I fell in love with next", and displayed his admiration for Straight, describing him as "like James Dean, except he's old". Angelo Badalamenti again produced the music for the film, although it was "very different from the kind of score he's done for [Lynch] in the past".

Among the many differences with his earlier films, "The Straight Story" did not contain profanities, sexual content or violence; it was rated G (general viewing) by the Motion Picture Association of America, which came as "shocking news" to many in the film industry, who were surprised that it "did not disturb, offend or mystify". As Le Blanc and Odell stated, the plot made it "seem as far removed from Lynch's earlier works as could be imagined, but in fact right from the very opening, this is entirely his film – a surreal road movie".

The same year, Lynch approached ABC once again with ideas for a television drama. The network gave Lynch the go-ahead to shoot a two-hour pilot for the series "Mulholland Drive", but disputes over content and running time led to the project being shelved indefinitely. However, with seven million dollars from the French production company StudioCanal, Lynch completed the pilot as a film, "Mulholland Drive". The film, a non-linear narrative surrealist tale of the dark side of Hollywood, stars Naomi Watts, Laura Harring and Justin Theroux. The film performed relatively well at the box office worldwide and was a critical success, earning Lynch a Best Director prize at the 2001 Cannes Film Festival (shared with Joel Coen for "The Man Who Wasn't There") and a Best Director award from the New York Film Critics Association. In addition, Lynch received his third Academy Award nomination for Best Director. In 2016, the film was named the top film of the 21st century by the BBC following a poll of 177 film critics from 36 countries.

With the rising popularity of the Internet, Lynch decided to utilize it as a new distribution channel, releasing several new series that he had created exclusively on his website, davidlynch.com. In 2002, he created a series of online shorts named "DumbLand". Intentionally crude both in content and execution, the eight-episode series was later released on DVD. The same year, Lynch released a surreal sitcom on his website called "Rabbits", about a family of humanoid rabbits. Later, he made his experiments with Digital Video available in the form of the Japanese-style horror short "Darkened Room". In 2006, Lynch's feature film "Inland Empire" was released. At three hours long, it was the longest of Lynch's films. Like "Mulholland Drive" and "Lost Highway" before it, the film did not follow a traditional narrative structure. It starred Lynch regulars Laura Dern, Harry Dean Stanton and Justin Theroux, with cameos by Naomi Watts and Laura Harring (voices of Suzie and Jane Rabbit), and a performance by Jeremy Irons. Lynch described the piece as "a mystery about a woman in trouble". In an effort to promote the film, Lynch made appearances with a cow and a placard bearing the slogan "Without cheese there would be no "Inland Empire"".

In 2009, Lynch produced a documentary web series directed by his son, Austin Lynch, and friend Jason S. called "Interview Project". Interested in working with Werner Herzog, Lynch collaborated with him in 2009 to produce Herzog's film "My Son, My Son, What Have Ye Done?". Using a non-standard narrative, the film was based on the true story of an actor who committed matricide while acting in a production of the Oresteia, and starred Grace Zabriskie, a Lynch regular.
Lynch has plans to direct a documentary on Maharishi Mahesh Yogi consisting of interviews with people who knew him.

In 2010, Lynch began making guest appearances on the "Family Guy" spin-off "The Cleveland Show" as Gus the Bartender. He had been convinced to appear in the show by its lead actor, Mike Henry, who is a fan of Lynch and who felt that his whole life had changed after seeing "Wild at Heart". "Lady Blue Shanghai" is a 16-minute promotional film that was written, directed and edited by Lynch for Dior. It was released on the Internet in May 2010.

Lynch directed a concert by English new wave band Duran Duran on March 23, 2011. The concert was streamed live on YouTube from the Mayan Theater in Los Angeles as the kickoff to the second season of "". "The idea is to try and create on the fly, layers of images permeating Duran Duran on the stage", Lynch said. "A world of experimentation and hopefully some happy accidents". The animated short "I Touch a Red Button Man", a collaboration between Lynch and the band Interpol, played in the background during Interpol's concert at the Coachella Valley Music and Arts Festival in April 2011. The short, which features Interpol's song "Lights", was later made available online.

It was believed that Lynch was going to retire from the film industry; according to Abel Ferrara, Lynch "doesn't even want to make films any more. I've talked to him about it, OK? I can tell when he talks about it." However, in a June 2012 "Los Angeles Times" interview, Lynch stated that he lacked the inspiration to start a new movie project, but "If I got an idea that I fell in love with, I'd go to work tomorrow". In September 2012, Lynch appeared in the three-part "Late Show" arc on FX's "Louie" as Jack Dahl. In November 2012, Lynch hinted at plans for a new film while attending Plus Camerimage in Bydgoszcz, Poland. Speaking at the festival, Lynch said "something is coming up. It will happen but I don't know exactly when". At Plus Camerimage, Lynch was also presented with a lifetime achievement award and the key to the city by Bydgoszcz's mayor Rafał Bruski. During an interview with the "Los Angeles Times" in January 2013, frequent Lynch collaborator Laura Dern confirmed she and Lynch are planning a new project, and "The New York Times" later revealed Lynch is working on the script. "Idem Paris", a short documentary film about the lithographic process, was released online in February 2013. On June 28, 2013, a music video directed by Lynch for the Nine Inch Nails song "Came Back Haunted" was released. He also did photography for the self-titled album from Dumb Numbers released August 2013.

On October 6, 2014, Lynch confirmed via Twitter that he would start shooting together with Mark Frost a new, nine-episode season of "Twin Peaks" in 2015, with the episodes expected to air in early 2016 on Showtime. Lynch and Frost wrote all nine episodes. On April 5, 2015, Lynch announced via Twitter that the project was still alive, but he was no longer going to direct because the budget was too low for what he wanted to do. However, he later announced on May 15, 2015, via Twitter, that he would indeed be returning to the revival, as he had sorted out his issues with Showtime. This was later confirmed by Showtime CEO David Nevins, who announced that Lynch would direct every episode of the revival and that the original order of nine episodes had been extended to eighteen episodes. By January 2016, the series was halfway through the shooting schedule and filming was completed by April 2016. The two-episode premiere aired May 21, 2017.
While doing press for "Twin Peaks", he was again asked if he was retired from film and confirmed that he had made his last feature film, responding, "Things changed a lot... So many films were not doing well at the box office even though they might have been great films and the things that were doing well at the box office weren't the things that I would want to do". Lynch later clarified that this statement had been misconstrued, and reiterated "I did not say I quit cinema. Simply that nobody knows what the future holds."
Since the last episode of "The Return" aired, there has been speculation on whether there will be a fourth season of "Twin Peaks" or not. Though Lynch has not denied the possibility of another season, he has said it would be unlikely to air before 2021.

Lynch says that his work is more similar in many respects to that of European filmmakers than American ones, believing that most films that "get down and thrill your soul" are from European directors. Lynch has commented on his admiration for such film makers as Federico Fellini, Werner Herzog, Alfred Hitchcock, Roman Polanski, and Jacques Tati, along with the American movie directors Stanley Kubrick and Billy Wilder. He has stated that Billy Wilder's "Sunset Boulevard" (1950) is one of his favourite motion pictures, as is Kubrick's "Lolita" (1962). He has also cited Herk Harvey's "Carnival of Souls" (1962) and Jerzy Skolimowski's "Deep End" (1970) as an influence on his work.

There are several recurring themes within Lynch's work, leading film critics Le Blanc and Odell to state that "his films are so packed with motifs, recurrent characters, images, compositions and techniques that you could view his entire output as one large jigsaw puzzle of ideas". One of the key themes that they noted was the usage of dreams and dreamlike imagery and structure within his works, something they related to the "surrealist ethos" of relying "on the subconscious to provide visual drive". This can be seen in John Merrick's dream of his mother in "The Elephant Man", Agent Cooper's dreams of the red room in "Twin Peaks" and the "dreamlike logic" of the narrative found in "Eraserhead", "Mulholland Drive" and "Inland Empire". Discussing his attitude to dreams, Lynch has stated that "Waking dreams are the ones that are important, the ones that come when I'm quietly sitting in a chair, letting my mind wander. When you sleep, you don't control your dream. I like to dive into a dream world that I've made or discovered; a world I choose ... [You can't really get others to experience it, but] right there is the power of cinema." His films are known for their use of magic realism.

Another of Lynch's prominent themes is industry, with repeated imagery of "the clunk of machinery, the power of pistons, shadows of oil drills pumping, screaming woodmills and smoke billowing factories", as can be seen with the industrial wasteland in "Eraserhead", the factories in "The Elephant Man", the sawmill in "Twin Peaks" and the lawn mower in "The Straight Story". Describing his interest in such things, Lynch stated that "It makes me feel good to see giant machinery, you know, working: dealing with molten metal. And I like fire and smoke. And the sounds are so powerful. It's just big stuff. It means that things are being made, and I really like that."

Another theme is the dark underbelly of violent criminal activity within a society, such as with Frank's gang in "Blue Velvet" and the cocaine smugglers in "Twin Peaks". The idea of deformity is also found in several of Lynch's films, from "The Elephant Man" to the deformed baby in "Eraserhead", as well as death from head wounds, found in most of Lynch's films. Other imagery commonly used in Lynch's works are flickering electricity or lights, fire and stages upon which a singer performs, often surrounded by drapery.

With the exception of "The Elephant Man" and "Dune", which are set in Victorian London and a fictitious galaxy respectively, all of Lynch's films have been set in the United States, and he has stated that "I like certain things about America and it gives me ideas. When I go around and I see things, it sparks little stories, or little characters pop out, so it just feels right to me to, you know, make American films." A number of his works, including "Blue Velvet", "Twin Peaks" and "Lost Highway" are intentionally reminiscent of the 1950s American culture despite being set in the later decades of the 20th century. Lynch stated that "It was a fantastic decade in a lot of ways ... there was something in the air that is not there any more at all. It was such a great feeling, and not just because I was a kid. It was a really hopeful time, and things were going up instead of going down. You got the feeling you could do anything. The future was bright. Little did we know we were laying the groundwork for a disastrous future."

Lynch also tends to feature his leading female actors in "split" roles, so that many of his female characters have multiple, fractured identities. This practice began with his choice to cast Sheryl Lee as both Laura Palmer and her cousin Maddy Ferguson in "Twin Peaks" and continued in his later works. In "Lost Highway", Patricia Arquette plays the dual role of Renee Madison/Alice Wakefield, while in "Mulholland Drive" Naomi Watts plays Diane Selwyn/Betty Elms and Laura Harring plays Camilla Rhodes/Rita and in "Inland Empire" Laura Dern plays Nikki Grace/Susan Blue. The numerous alternate versions of lead characters and numerous examples of fragmented timelines may echo and/or reference the many worlds interpretation of quantum physics and perhaps Lynch's broader interest in quantum physics/ quantum theory. Some have also suggested that Lynch's love for the 1958 Alfred Hitchcock film "Vertigo", which employs a split lead character (the Judy Barton and Madeleine Elster characters, both portrayed by Kim Novak) may have had an influence on this aspect of Lynch's work.

He frequently tends to have characters that have supernatural and omnipotent qualities. They can be seen as physical manifestations of various different concepts, such as hatred or fear. Examples of these characters are The Man Inside the Planet from "Eraserhead", Bob from "Twin Peaks", The Mystery Man from "Lost Highway", The Bum in "Mulholland Drive", and The Phantom in "Inland Empire". Lynch approaches his characters and film content in a way that steeps them in a dream state rather than reality.

Lynch is also widely noted for his collaborations with various production artists and composers on his films and other productions. He frequently works with Angelo Badalamenti to compose music for his productions, former wife Mary Sweeney as a film editor, casting director Johanna Ray, and cast members Harry Dean Stanton, Jack Nance, Kyle MacLachlan, Naomi Watts, Isabella Rossellini, Grace Zabriskie, and Laura Dern.

Lynch first trained as a painter, and although he is now better known as a filmmaker, he has continued to paint. Lynch has stated that "all my paintings are organic, violent comedies. They have to be violently done and primitive and crude, and to achieve that I try to let nature paint more than I paint." Many of his works are very dark in colour, and Lynch has said this is because

I wouldn't know what to do with [colour]. Colour to me is too real. It's limiting. It doesn't allow too much of a dream. The more you throw black into a colour, the more dreamy it gets ... Black has depth. It's like a little egress; you can go into it, and because it keeps on continuing to be dark, the mind kicks in, and a lot of things that are going on in there become manifest. And you start seeing what you're afraid of. You start seeing what you love, and it becomes like a dream.
Many of his works also contain letters and words added to the painting. He explains: The words in the paintings are sometimes important to make you start thinking about what else is going on in there. And a lot of times, the words excite me as shapes, and something'll grow out of that. I used to cut these little letters out and glue them on. They just look good all lined up like teeth ... sometimes they become the title of the painting.

Lynch considers the 20th-century Irish-born British artist Francis Bacon to be his "number one kinda hero painter", stating that "Normally I only like a couple of years of a painter's work, but I like everything of Bacon's. The guy, you know, had the stuff."

Lynch was the subject of a major art retrospective at the Fondation Cartier, Paris from March 3 – May 27, 2007. The show was titled "The Air is on Fire" and included numerous paintings, photographs, drawings, alternative films and sound work. New site-specific art installations were created specially for the exhibition. A series of events accompanied the exhibition including live performances and concerts.
Some of Lynch's art include photographs of dissected chickens and other animals as a "Build your own Chicken" toy ad.

His alma mater, the Pennsylvania Academy of Fine Arts, presented an exhibition of his work, entitled "The Unified Field", which opened on September 12, 2014 and ended in January 2015.

His favorite photographers include William Eggleston ("The Red Ceiling"), Joel-Peter Witkin, and Diane Arbus.

Lynch has also been involved in a number of music projects, many of them related to his films. His album genres switch mainly between experimental rock, ambient soundscapes and, most recently, avant-garde electropop music. Most notably he produced and wrote lyrics for Julee Cruise's first two albums, "Floating into the Night" (1989) and "The Voice of Love" (1993), in collaboration with Angelo Badalamenti who composed the music and also produced. Lynch also worked on the 1998 Jocelyn Montgomery album "Lux Vivens". For his own productions, he composed music for "Wild at Heart", "Twin Peaks: Fire Walk with Me", "Mulholland Drive", and "Rabbits". In 2001, he released "BlueBob", a rock album performed by Lynch and John Neff. The album is notable for Lynch's unusual guitar playing style. He plays "upside down and backwards, like a lap guitar", and relies heavily on effects pedals. Most recently Lynch composed several pieces for "Inland Empire", including two songs, "Ghost of Love" and "Walkin' on the Sky", in which he makes his public debut as a singer. In 2009, his new book-CD set "" was released. In 2008, he started his own record label called David Lynch MC which first released "Fox Bat Strategy: A Tribute to Dave Jaurequi" in early 2009. In August 2009, it was announced that he was releasing Afghani/American singer Ariana Delawari's "Lion of Panjshir" album in conjunction with Manimal Vinyl record company.

In November 2010, Lynch released two electropop music singles, "Good Day Today" and "I Know", through the independent British label Sunday Best Recordings. Describing why he created them, he stated that "I was just sitting and these notes came and then I went down and started working with Dean [Hurley, his engineer] and then these few notes, 'I want to have a good day, today' came and the song was built around that". The singles were followed by an album, "Crazy Clown Time", which was released in November 2011 and described as an "electronic blues album". The songs were sung by Lynch, with guest vocals on one track by Karen O of the Yeah Yeah Yeahs, and composed and performed by Lynch and Dean Hurley.

On September 29, 2011, Lynch released "This Train" with vocalist and long-time musical collaborator Chrysta Bell on the La Rose Noire label. The 11-song album was produced by Lynch and co-written primarily by Lynch and Chrysta Bell. It includes the song "Polish Poem" which is featured on the "Inland Empire" soundtrack. The musical partnership also yielded a 5- song EP entitled "Somewhere In the Nowhere", released October 7, 2016, on Meta Hari Records.

Lynch's second studio album, "The Big Dream", was released in 2013 and included the single, "I'm Waiting Here", with Swedish singer-songwriter Lykke Li. "The Big Dream"s release was preceded by "TBD716", an enigmatic 43-second video featured on Lynch's YouTube and Vine accounts.

For Record Store Day 2014 David Lynch released "The Big Dream Remix EP" which featured four songs from his album remixed by various artists. This included the track "Are You Sure" remixed by Bastille. The band Bastille have been known to take inspiration from David Lynch's work for their songs and music videos, the main one being their song "Laura Palmer" which is influenced by Lynch's television show "Twin Peaks".

Lynch designed and constructed furniture for his 1997 film "Lost Highway", notably the small table in the Madison house and the VCR case.

In April 1997 he presented a furniture collection at the prestigious Milan Furniture Fair in Italy. "Design and music, art and architecture – they all belong together."

Working with designer Raphael Navot, architectural agency Enia and light designer Thierry Dreyfus, Lynch has conceived and designed a nightclub in Paris. "Silencio" opened in October 2011, and is a private members' club although is free to the public after midnight. Patrons have access to concerts, films and other performances by artists and guests. Inspired by the club of the same name in his 2001 film "Mulholland Drive", the underground space consists of a series of rooms, each dedicated to a certain purpose or atmosphere. "Silencio is something dear to me. I wanted to create an intimate space where all the arts could come together. There won't be a Warhol-like guru, but it will be open to celebrated artists of all disciplines to come here to programme or create what they want."

In 2006, Lynch authored a short book describing his creative processes, stories from throughout his career, and the benefits he had realized through his practice of Transcendental Meditation called "Catching the Big Fish: Meditation, Consciousness, and Creativity". He describes the metaphor behind the title in the introduction:
Ideas are like fish.

If you want to catch little fish, you can stay in the shallow water. But if you want to catch the big fish, you've got to go deeper.

Down deep, the fish are more powerful and more pure. They're huge and abstract. And they're very beautiful.

The book weaves a non-linear autobiography with descriptions of Lynch's cognitive experiences during Transcendental Meditation. All author's royalties will be donated to the David Lynch Foundation.

Lynch has had several long-term relationships. In 1967, he married Peggy Lentz in Chicago, Illinois. They had one child, Jennifer Chambers Lynch, born in 1968, who is a film director. They filed for divorce in 1974. On June 21, 1977, Lynch married Mary Fisk, and the couple had one child, Austin Jack Lynch, born in 1982. They divorced in 1987, and Lynch later developed a relationship with Mary Sweeney, with whom he had one son. Sweeney also worked as Lynch's longtime film editor/producer and co-wrote and produced "The Straight Story". The two married in May 2006, but divorced that July. In 2009 Lynch married actress Emily Stofle, who appeared in his 2006 film "Inland Empire" as well as the . The couple have one child, Lula Boginia Lynch, born in 2012.

Lynch has said that he is "not a political person" and that politics are "something I know little about." However, in the 1990s he expressed admiration for former US President Ronald Reagan, stating that "I mostly liked that he carried a wind of old Hollywood, of a cowboy." Describing his political philosophy, he stated, "at that time, I thought of myself as a libertarian. I believed in next to zero government. And I still would lean toward no government and not so many rules, except for traffic lights and things like this. I really believe in traffic regulations." Lynch continued to state that "I'm a Democrat now. And I've always been a Democrat, really. But I don't like the Democrats a lot, either, because I'm a smoker, and I think a lot of the Democrats have come up with these rules for non-smoking."

He endorsed the center-left Natural Law Party in the 2000 presidential election and later stated that he would vote for Democratic incumbent Barack Obama in the 2012 presidential election. In the 2016 United States presidential election, he endorsed Bernie Sanders, whom he described as "for the people."

Lynch advocates the use of Transcendental Meditation in bringing peace to the world. He was initiated into Transcendental Meditation in July 1973, and has practiced the technique consistently since then. Lynch says he met Maharishi Mahesh Yogi, the founder of the TM movement, for the first time in 1975 at the Spiritual Regeneration Movement center in Los Angeles, California. He reportedly became close with the Maharishi during a month-long "Millionaire's Enlightenment Course" held in 2003, the fee for which was 1 million.

In July 2005, he launched the David Lynch Foundation for Consciousness-Based Education and Peace, established to help finance scholarships for students in middle and high schools who are interested in learning the Transcendental Meditation technique and to fund research on the technique and its effects on learning. Together with John Hagelin and Fred Travis, a brain researcher from Maharishi University of Management (MUM), Lynch promoted his vision on college campuses with a tour that began in September 2005. Lynch is on the board of trustees of MUM and has hosted an annual "David Lynch Weekend for World Peace and Meditation" there since 2005.

Lynch was working for the building and establishment of seven buildings, in which 8,000 salaried people would practice advanced meditation techniques, "pumping peace for the world". He estimates the cost at US$7 billion. As of December 2005, he had spent US$400,000 of personal money, and raised US$1 million in donations. In December 2006, the "New York Times" reported that he continued to have that goal. Lynch's book, "Catching the Big Fish" (Tarcher/Penguin 2006), discusses the impact of the Transcendental Meditation technique on his creative process. Lynch attended the funeral of the Maharishi in India in 2008. He told a reporter, "In life, he revolutionised the lives of millions of people. ... In 20, 50, 500 years there will be millions of people who will know and understand what the Maharishi has done." In 2009, he went to India to film interviews with people who knew the Maharishi as part of a biographical documentary.

In 2009, Lynch organized a benefit concert at Radio City Music Hall for the David Lynch Foundation. On April 4, 2009, the "Change Begins Within" concert featured Paul McCartney, Ringo Starr, Donovan, Sheryl Crow, Eddie Vedder, Moby, Bettye LaVette, Ben Harper, and Mike Love of the Beach Boys. "David Wants to Fly", released in May 2010, is a documentary by German filmmaker David Sieveking "that follows the path of his professional idol, David Lynch, into the world of Transcendental Meditation (TM)".

An independent project starring Lynch called "Beyond The Noise: My Transcendental Meditation Journey", directed by film student Dana Farley, who has severe dyslexia and attention deficit disorder, was shown at film festivals in 2011, including the Marbella Film Festival. Filmmaker Kevin Sean Michaels is one of the producers. In 2013 Lynch wrote: "Transcendental Meditation leads to a beautiful, peaceful revolution. A change from suffering and negativity to happiness and a life more and more free of any problems."

Lynch designed his personal website, a site exclusive to paying members, where he posts short videos and his absurdist series "Dumbland", plus interviews and other items. The site also featured a daily weather report, where Lynch gives a brief description of the weather in Los Angeles, where he resides. Until June 2010, this weather report (usually no longer than 30 seconds) was also being broadcast on his personal YouTube channel, "David Lynch – Daily Weather Report". An absurd ringtone ("I like to kill deer") from the website was a common sound bite on "The Howard Stern Show" in early 2006.

Lynch is a coffee drinker and even has his own line of special organic blends available for purchase on his website as well as in Whole Foods. Called "David Lynch Signature Cup", the coffee has been advertised via flyers included with several recent Lynch-related DVD releases, including "Inland Empire" and the Gold Box edition of "Twin Peaks". The possibly self-mocking tag-line for the brand is "It's all in the beans ... and I'm just full of beans." This is also a quote of a line said by Justin Theroux's character in "Inland Empire".

The moving image collection of David Lynch is held at the Academy Film Archive, which has preserved two of his student films therein.

Studio albums

Collaborative albums



</doc>
<doc id="7892" url="https://en.wikipedia.org/wiki?curid=7892" title="David Cronenberg">
David Cronenberg

David Paul Cronenberg, (born March 15, 1943) is a Canadian director, screenwriter and actor. He is one of the principal originators of what is commonly known as the body horror genre, with his films exploring visceral bodily transformation, infection, technology, and the intertwining of the psychological with the physical. In the first half of his career, he explored these themes mostly through horror and science fiction films such as "Scanners" (1981) and "Videodrome" (1983), although his work has since expanded beyond these genres.

Cronenberg's films have polarized audiences and critics alike; he has earned critical acclaim and has sparked controversy for his depictions of gore and violence. "The Village Voice" called him "the most audacious and challenging narrative director in the English-speaking world". His films have won numerous awards, including the Jury Prize at the Cannes Film Festival for his film "Crash" (1996).

Born in Toronto, Ontario, Cronenberg is the son of Esther ("née" Sumberg), a musician, and Milton Cronenberg, a writer and editor. He was raised in a "middle-class progressive Jewish family". His father was born in Baltimore, Maryland, and his mother was born in Toronto; all of his grandparents were from Lithuania.

He began writing as a child and wrote constantly. He attended high school at Harbord Collegiate Institute and North Toronto Collegiate Institute. A keen interest in science, especially botany and lepidopterology, led him to enter the Honours Science program at the University of Toronto in 1963, but he switched to Honours English Language and Literature later in his first year.

Cronenberg's fascination with the film "Winter Kept Us Warm" (1966), by classmate David Secter, sparked his interest in film. He began frequenting film camera rental houses, learning the art of filmmaking, and made two 16mm films ("Transfer" and "From the Drain"). Inspired by the New York underground film scene, he founded the Toronto Film Co-op with Iain Ewing and Ivan Reitman. After taking a year off to travel in Europe, he returned to Canada in 1967 and graduated from University College at the top of his class.

After two short sketch films and two short art-house features (the black-and-white "Stereo" and the colour "Crimes of the Future") Cronenberg went into partnership with Ivan Reitman. The Canadian government provided financing for his films throughout the 1970s. He alternated his signature "body horror" films such as "Shivers" with projects reflecting his interest in car racing and bike gangs ("Fast Company"). "Rabid" provided pornographic actress Marilyn Chambers with work in a different genre. (Cronenberg's first choice for the role had been a then little-known Sissy Spacek). "Rabid" was a breakthrough with international distributors, and his next two horror features gained stronger support.

Cronenberg's films follow a definite progression: a movement from the social world to the inner life. In his early films, scientists modify human bodies, which results in the breakdown of social order (e.g. "Shivers", "Rabid"). In his middle period, the chaos wrought by the scientist is more personal, (e.g. "The Brood", "Scanners", "Videodrome"). In the later middle period, the scientist himself is altered by his experiment (e.g. his remake of "The Fly"). This trajectory culminates in "Dead Ringers" in which a twin pair of gynecologists spiral into codependency and drug addiction. His later films tend more to the psychological, often contrasting subjective and objective realities ("eXistenZ", "M. Butterfly", "Spider").

Cronenberg has cited William S. Burroughs and Vladimir Nabokov as influences. Perhaps the best example of a film that straddles the line between his works of personal chaos and psychological confusion is Cronenberg's 1991 "adaptation" of "Naked Lunch" (1959), his literary hero William S. Burroughs' most controversial book. The novel was considered "unfilmable", and Cronenberg acknowledged that a straight translation into film would "cost 400 million dollars and be banned in every country in the world". Instead—much like in his earlier film, "Videodrome"—he consistently blurred the lines between what appeared to be reality and what appeared to be hallucinations brought on by the main character's drug addiction. Some of the book's "moments" (as well as incidents loosely based upon Burroughs' life) are presented in this manner within the film. Cronenberg stated that while writing the screenplay for "Naked Lunch" (1991), he felt a moment of synergy with Burroughs' writing style. He felt the connection between his screenwriting style and Burroughs' prose style was so strong, that he jokingly remarked that should Burroughs pass on, "I'll just write his next book."

Cronenberg has said that his films should be seen "from the point of view of the disease", and that in "Shivers", for example, he identifies with the characters "after" they become infected with the anarchic parasites. Disease and disaster, in Cronenberg's work, are less problems to be overcome than agents of personal transformation. Of his characters' transformations, Cronenberg said, "But because of our necessity to impose our own structure of perception on things we look on ourselves as being relatively stable. But, in fact, when I look at a person I see this maelstrom of organic, chemical and electron chaos; volatility and instability, shimmering; and the ability to change and transform and transmute." Similarly, in "Crash" (1996), people who have been injured in car crashes attempt to view their ordeal as "a fertilizing rather than a destructive event". In 2005, Cronenberg publicly disagreed with Paul Haggis' choice of the same name for the latter's Oscar-winning film "Crash" (2004), arguing that it was "very disrespectful" to the "important and seminal" J.G. Ballard novel on which Cronenberg's film was based.

Aside from "The Dead Zone" (1983) and "The Fly" (1986), Cronenberg has not generally worked within the world of big-budget, mainstream Hollywood filmmaking, although he has had occasional near misses. At one stage he was considered by George Lucas as a possible director for "Return of the Jedi" (1983) but was passed over. Cronenberg also worked for nearly a year on a version of "Total Recall" (1990), but experienced "creative differences" with producers Dino De Laurentiis and Ronald Shusett; a different version of the film was eventually made by Paul Verhoeven. A fan of Philip K. Dick's, author of "We Can Remember it For You Wholesale", the short story upon which the film was based, Cronenberg related in the biography/overview of his work, "Cronenberg on Cronenberg" (1992) that his dissatisfaction with what he envisioned the film to be and what it ended up being pained him so greatly that for a time, he suffered a migraine just thinking about it, akin to a needle piercing his eye.

In the late 1990s, Cronenberg was announced as director of a sequel to another Verhoeven film, "Basic Instinct" (1992), but this also fell through. His thriller "A History of Violence" (2005) is one of his highest budgeted and most accessible to date. He has said that the decision to direct it was influenced by his having had to defer some of his salary on the low-budgeted "Spider" (2002), but it was one of his most critically acclaimed films to date, along with "Eastern Promises" (2007), a film about the struggle of one man to gain power in the Russian Mafia.
Cronenberg has collaborated with composer Howard Shore on all of his films since "The Brood" (1979), (see List of noted film director and composer collaborations) with the exception of "The Dead Zone" (1983), which was scored by Michael Kamen. Other regular collaborators include actor Robert Silverman, art director Carol Spier, sound editor Bryan Day, film editor Ronald Sanders, his sister, costume designer Denise Cronenberg, and, from 1979 until 1988, cinematographer Mark Irwin. In 2008, Cronenberg directed Howard Shore's first opera, "The Fly".

Since "Dead Ringers" (1988), Cronenberg has worked with cinematographer Peter Suschitzky on each of his films (see List of film director and cinematographer collaborations). Suschitzky was the director of photography for "The Empire Strikes Back" (1980), and Cronenberg remarked that Suschitzky's work in that film "was the only one of those movies that actually looked good", which was a motivating factor to work with him on "Dead Ringers".

Having worked with many Hollywood stars, Cronenberg says that he did not get to make a film with an actor he wanted to work with for a long time, Burt Reynolds. Cronenberg remains a staunchly Canadian filmmaker, with nearly all of his films (including major studio vehicles "The Dead Zone" and "The Fly") having been filmed in his home province Ontario. Notable exceptions include "M. Butterfly" (1993), most of which was shot in China, "Spider", and "Eastern Promises" (2007), which were both filmed primarily in England, and "A Dangerous Method" (2011), which was filmed in Germany and Austria. "Rabid" and "Shivers" were shot in and around Montreal. Most of his films have been at least partially financed by Telefilm Canada, and Cronenberg, a vocal supporter of government-backed film projects, has said: "Every country needs [a system of government grants] in order to have a national cinema in the face of Hollywood".

Cronenberg has also appeared as an actor in other directors' films. Most of his roles are cameo appearances, as in the films "Into the Night" (1985), "Blood and Donuts" (1995), "To Die For" (1995), and "Jason X" (2002) and the television series "Alias", but on occasion he has played major roles, as in "Nightbreed" (1990) and "Last Night" (1998). He has not played major roles in any of his own films, but he did put in a brief appearance as a gynecologist in "The Fly"; he can also be glimpsed among the sex-crazed hordes in "Shivers"; he can be heard as an unseen car-pound attendant in "Crash"; his hands can be glimpsed in "eXistenZ" (1999); and he appeared as a stand-in for James Woods in "Videodrome" for shots in which Woods' character wore a helmet that covered his head.

In 2008, Cronenberg realized two extra-cinematographic projects: the exhibition "Chromosomes" at the Rome Film Fest, and the opera "The Fly" at the LaOpera in Los Angeles and Theatre Châtelet in Paris. In July 2010, Cronenberg completed production on "A Dangerous Method" (2011), an adaptation of Christopher Hampton's play "The Talking Cure", starring Keira Knightley, Michael Fassbender, and frequent collaborator Viggo Mortensen. The film was produced by independent British producer Jeremy Thomas.

In 2012, his film "Cosmopolis" competed for the Palme d'Or at the 2012 Cannes Film Festival.

In the October 2011 edition of "Rue Morgue", Cronenberg stated that he has written a companion piece to his 1986 remake of "The Fly", which he would like to direct if given the chance. He has stated that it is not a traditional sequel, but rather a "parallel story".

For a time it appeared that, as "Eastern Promises" producer Paul Webster told Screen International, a sequel is in the works that would reunite the key team of Cronenberg, Steven Knight, and Viggo Mortensen. The film was to be made by Webster's new production company "Shoebox Films" in collaboration with Focus Features, and shot in early 2013. However, in 2012, Cronenberg commented that the "Eastern Promises" sequel had fallen through due to budget disagreement with Focus Features. 

Filming for Cronenberg's next film, a satire drama entitled "Maps to the Stars" (2014)—with Julianne Moore, Mia Wasikowska, John Cusack, and Robert Pattinson—began on July 8, 2013 in Toronto, Ontario and Los Angeles. This was the first time Cronenberg filmed in the United States.

In a September 2013 interview, Cronenberg stated that he is not concerned about posthumous representations of his film work: "It wouldn't disturb me to think that my work would just sink beneath the waves without trace and that would be it. So what? It doesn't bother me." In the same interview, Cronenberg revealed that it depends on the "time of day" as to whether or not he is afraid of death.

On June 26, 2014, Cronenberg's short film "The Nest" was published on YouTube. The film was commissioned for "David Cronenberg - The Exhibition" at EYE Film Institute in Amsterdam and was available on YouTube for the duration of the exhibition, until September 14, 2014.

In a 2016, interview Viggo Mortensen revealed that Cronenberg is considering retiring due to difficulty financing his film projects.

In 2014, Cronenberg published his first novel, "Consumed".

He married his first wife, Margaret Hindson, in 1972: their seven-year marriage ended in 1979 amidst personal and professional differences. They had one daughter, Cassandra Cronenberg.

He was married to film editor Carolyn Zeifman until her death in 2017. The couple met on the set of "Rabid" while she was working as a production assistant. They have two children, Caitlin and Brandon. In the book "Cronenberg on Cronenberg" (1992), he revealed that "The Brood" was inspired by events that occurred during the unraveling of his first marriage, which caused both Cronenberg and his daughter Cassandra a great deal of turmoil. The character Nola Carveth, mother of the brood, is based on Cassandra's mother. Cronenberg said that he found the shooting of the climactic scene, in which Nola was strangled by her husband, to be "very satisfying". 

Cronenberg lives in Toronto.

Cronenberg describes himself as an atheist. His atheism was further explained in a September 2013 interview:

"Anytime I've tried to imagine squeezing myself into the box of any particular religion, I find it claustrophobic and oppressive. I think atheism is an acceptance of what is real."

In the same interview, Cronenberg revealed that film director Martin Scorsese admitted to him that he was intrigued by Cronenberg's early work but was subsequently "terrified" to meet him in person. Cronenberg responded to Scorsese: "You're the guy who made "Taxi Driver" and you're afraid to meet me?"

Cronenberg has appeared on various "Greatest Director" lists. In 2004, Science Fiction magazine "Strange Horizons" named him the second greatest director in the history of the genre, ahead of better known directors such as Steven Spielberg, James Cameron, Jean-Luc Godard, and Ridley Scott. In the same year, "The Guardian" listed him 9th on their list of "The world's 40 best directors". In 2007, Total Film named him as the 17th greatest director of all-time. Film professor Charles Derry, in his overview of the horror genre "Dark Dreams", called the director one of the most important in his field, and that "no discussion of contemporary horror film can conclude without reference to the films of David Cronenberg."

Cronenberg received the Special Jury Prize at the 1996 Cannes Film Festival for "Crash". In 1999, he was inducted onto Canada's Walk of Fame, awarded the Silver Bear Award at the 49th Berlin International Film Festival. and that November received the Governor General's Performing Arts Award, Canada's highest honour in the performing arts.

In 2002, he was made an Officer of the Order of Canada, and was promoted to Companion of the Order of Canada (the order's highest rank) in 2014. In 2006 he was awarded the Cannes Film Festival's lifetime achievement award, the Carrosse d'Or. Also in 2006, Cronenberg was made a Fellow of the Royal Society of Canada, the senior national body of distinguished Canadian scientists and scholars. In 2009 Cronenberg received the Légion d'honneur from the government of France. The following year Cronenberg was named an honorary patron of the University Philosophical Society, Trinity College, Dublin. In 2012, he received the Queen Elizabeth II Diamond Jubilee Medal.

The opening of the "David Cronenberg: Evolution" Toronto International Film Festival (TIFF) exhibition occurred on October 30, 2013. Held at the TIFF Bell Lightbox venue, the exhibition paid tribute to the director's entire filmmaking career and the festival's promotional material referred to Cronenberg as "one of Canada's most prolific and iconic filmmakers". The exhibition was shown internationally following the conclusion of the TIFF showing on January 19, 2014.

In 2014, he was made a Member of the Order of Ontario in recognition for being "Canada's most celebrated internationally acclaimed filmmaker".

On April 2018, it was announced that Cronenberg will receive the honorary Golden Lion at the 75th Venice International Film Festival.








</doc>
<doc id="7893" url="https://en.wikipedia.org/wiki?curid=7893" title="Dale Earnhardt">
Dale Earnhardt

Ralph Dale Earnhardt Sr. (; April 29, 1951 – February 18, 2001), known professionally as Dale Earnhardt, was an American professional stock car racing driver and team owner, best known for his involvement in stock car racing for NASCAR. The third child of racing driver Ralph Earnhardt and first of two to Martha Coleman, he began his career in 1975 in the World 600 as part of the Winston Cup Series.

Regarded as one of the most significant drivers in NASCAR history, Earnhardt won a total of 76 Winston Cup races over the course of his career, including the 1998 Daytona 500. He also earned seven NASCAR Winston Cup championships, tying for the most all-time with Richard Petty. This feat, accomplished in 1994, was not equaled again for 22 years until Jimmie Johnson in 2016. His aggressive driving style earned him the nicknames "The Intimidator", "The Man in Black", and "The Count of Monte Carlo". Also, his success at the restrictor plate tracks of Daytona and Talladega earned him the nickname, "Mr. Restrictor Plate".

In February 2001, Earnhardt was killed instantly after a collision with Sterling Marlin during the final lap of the Daytona 500 – an unexpected event that was widely lamented in the racing industry. Earnhardt has been inducted into numerous halls of fame, including the NASCAR Hall of Fame inaugural class in 2010.

Earnhardt had German ancestry. He was born on April 29, 1951, in Kannapolis, North Carolina, as the third child of Martha (Coleman) and Ralph Earnhardt. Earnhardt's father was one of the best short-track drivers in North Carolina at the time and won his first and only NASCAR Sportsman Championship in 1956 at Greenville Pickens Speedway in Greenville, South Carolina. Although Ralph did not want his son to pursue a career as a race car driver, Dale dropped out of school to pursue his dreams. Ralph was a hard teacher for Dale, and after Ralph died of a heart attack at his home in 1973 at age 45, it took many years before Dale felt as though he had finally "proven" himself to his father. Earnhardt had four siblings: two brothers, Danny and Randy (died 2013); and two sisters, Cathy and Kaye.

In 1968, at the age of 17, Earnhardt married his first wife, Latane Brown. With her, Earnhardt fathered his first son, Kerry, a year later. Dale and Latane divorced in 1970. In 1971, Earnhardt married his second wife, Brenda Gee, the daughter of NASCAR car builder Robert Gee. In his marriage with Gee, Earnhardt had two more children: a daughter, Kelley King Earnhardt, in 1972, and a son, Ralph Dale Earnhardt Jr., in 1974. Not long after Dale Jr. was born, Earnhardt and Gee divorced. Earnhardt then married his third and final wife, Teresa Houston (Tommy Houston's niece), in 1982. She gave birth to their daughter, Taylor Nicole Earnhardt, in 1988. Taylor and her husband, Brandon Putnam, are professional rodeo performers.

Earnhardt began his professional career in the Winston Cup in 1975, making his debut at Charlotte Motor Speedway in North Carolina in the longest race on the Cup circuit—the 1975 World 600. He drove the No. 8 Ed Niegre Dodge Charger and finished 22nd in that race, just one spot ahead of his future car owner, Richard Childress. Earnhardt competed in eight more races until 1979.

When he joined car owner Rod Osterlund Racing in a season that included a rookie class of future stars including Earnhardt, Harry Gant, and Terry Labonte in his rookie season, Earnhardt won one race at Bristol, captured four poles, scored eleven Top 5's and seventeen Top 10's, and finished seventh in the points standings despite missing four races due to a broken collarbone, winning Rookie of the Year honors.

During his sophomore season, Earnhardt, now with 20-year-old Doug Richert as his crew chief, began the season winning the Busch Clash. With wins at Atlanta, Bristol, Nashville, Martinsville, and Charlotte, Earnhardt won his first Winston Cup points championship. He is the only driver in NASCAR Winston Cup history to follow a Rookie of the Year title with a NASCAR Winston Cup Championship the next season. He was also the third driver in NASCAR history to win both the Rookie of the Year and Cup Series championship, following David Pearson (1960, 1966) and Richard Petty (1959, 1964). Only seven drivers have joined this exclusive club since: Rusty Wallace (1984, 1989), Alan Kulwicki (1986, 1992), Jeff Gordon (1993, 1995), Tony Stewart (1999, 2002), Matt Kenseth (2000, 2003), Kevin Harvick (2001, 2014), and Kyle Busch (2005, 2015).

In 1981, after Osterlund sold his team to J. D. Stacy, Earnhardt left for Richard Childress Racing and finished the season seventh in the points standings but winless.

The following year, at Childress's suggestion, Earnhardt joined car owner Bud Moore for the 1982 and 1983 seasons driving the No. 15 Wrangler Jeans-sponsored Ford Thunderbird (the only full-time Ford ride in his career). During the 1982 season, Earnhardt struggled. Although he won at Darlington, he failed to finish 15 races and completed the season 12th in points, the worst of his career. He also suffered a broken kneecap at Pocono Raceway when he flipped after contact with Tim Richmond. In 1983, Earnhardt rebounded and won his first of 12 Twin 125 Daytona 500 qualifying races. He won at Nashville and at Talladega, finishing eighth in the points standings.

After the 1983 season, Earnhardt returned to Richard Childress Racing, replacing Ricky Rudd in the No. 3. Rudd went to Bud Moore's No. 15, replacing Earnhardt. Wrangler sponsored both drivers at their respective teams. During the 1984 and 1985 seasons, Earnhardt went to victory lane six times, at Talladega, Atlanta, Richmond, Bristol (twice), and Martinsville, where he finished fourth and eighth in the season standings respectively.

The 1986 season saw Earnhardt win his second career Winston Cup Championship and the first owner's championship for RCR. He won five races and had ten Top 5's and sixteen Top 10's. Earnhardt successfully defended his championship the following year, going to victory lane eleven times and winning the championship by 489 points over Bill Elliott. In the process, Earnhardt set a NASCAR modern era record of four consecutive wins and won five of the first seven races. In the 1987 season, he earned the nickname "The Intimidator", and his final season for the blue and yellow Wrangler Jeans sponsorship. During this race, Earnhardt was briefly forced into the infield grass but kept control of his car and returned to the track without giving up his lead. The maneuver is now referred to as the "Pass in the Grass", even though Earnhardt did not pass anyone while he was off the track.

The 1988 season saw Earnhardt racing with a new sponsor, GM Goodwrench, after Wrangler Jeans dropped its sponsorship in 1987. During this season, he changed the color of his paint scheme from blue and yellow to the signature black in which the No. 3 car was painted for the rest of his life. He won three races in 1988, finishing third in the points standings behind Bill Elliott in first and Rusty Wallace in second. The following year, Earnhardt won five races, but a late spin out at North Wilkesboro arguably cost him the 1989 championship, as Rusty Wallace edged him out for it. It was his first season for the GM Goodwrench Chevrolet Lumina.

The 1990 season started for Earnhardt with victories in the Busch Clash and his heat of the Gatorade Twin 125's. Near the end of the Daytona 500, he had a dominant forty-second lead when the final caution flag came out with a handful of laps to go. When the green flag waved, Earnhardt was leading Derrike Cope. On the final lap, Earnhardt ran over a piece of metal, which was later revealed as a bell housing, in turn 4, cutting down a tire. Cope, in an upset, won the race while Earnhardt finished fifth after leading 155 of the 200 laps. The No. 3 Goodwrench-sponsored Chevy team took the flat tire that cost them the win and hung it on the shop wall as a reminder of how close they had come to winning the Daytona 500. Earnhardt won nine races that season and won his fourth Winston Cup title, beating Mark Martin by 26 points. He also became the first multiple winner of the annual all-star race, The Winston.

The 1991 season saw Earnhardt win his fifth Winston Cup championship. This season, he scored four wins and won the championship by 195 points over Ricky Rudd. One of his wins came at North Wilkesboro, in a race where Harry Gant had a chance to set a single-season record by winning his fifth consecutive race, breaking a record held by Earnhardt. Late in the race, Gant lost his brakes, which gave Earnhardt the chance he needed to make the pass for the win and maintain his record.

Earnhardt's only win of the 1992 season came at Charlotte, in the Coca-Cola 600, ending a 13-race win streak by Ford teams. Earnhardt finished a career-low 12th in the points for the second time in his career, and the only time he had finished that low since joining RCR. He still made the trip to the annual Awards Banquet with Rusty Wallace but did not have the best seat in the house. Wallace stated he and Earnhardt had to sit on the backs of their chairs to see, and Earnhardt said, "This sucks, I could have gone hunting." At the end of the year, longtime crew chief Kirk Shelmerdine left to become a driver. Andy Petree took over as crew chief.

Hiring Petree turned out to be beneficial, as Earnhardt returned to the front in 1993. He once again came close to a win at the Daytona 500 and dominated Speedweeks before finishing second to Dale Jarrett on a last-lap pass. Earnhardt scored six wins en route to his sixth Winston Cup title, including wins in the first prime-time Coca-Cola 600 and The Winston both at Charlotte, and the Pepsi 400 at Daytona. He beat Rusty Wallace for the championship by 80 points. On November 14, 1993, after the Hooters 500 (Atlanta), the last race of that season, the race winner Wallace and 1993 series champion Dale Earnhardt ran a dual Polish Victory Lap together while carrying #28 and #7 flags commemorating Davey Allison and Alan Kulwicki, both drivers died during the season, respectively.

In 1994, Earnhardt achieved a feat that he himself had believed to be impossible—he scored his seventh Winston Cup championship, tying Richard Petty. He was very consistent, scoring four wins, and after Ernie Irvan was sidelined due to a near-deadly crash at Michigan (the two were neck-and-neck at the top of the points up until the crash), won the title by over 400 points over Mark Martin. Earnhardt sealed the deal at Rockingham by winning the race over Rick Mast. It was his final NASCAR championship and his final season for the GM Goodwrench Chevrolet Lumina.

Earnhardt started off the 1995 season by finishing second in the Daytona 500 to Sterling Marlin. He won five races in 1995, including his first road course victory at Sears Point. He also won the Brickyard 400 at Indianapolis Motor Speedway, a win he called the biggest of his career. But in the end, Earnhardt lost the championship to Jeff Gordon by 34 points. The GM Goodwrench racing team changed to Chevrolet Monte Carlos.

1996 for Earnhardt started just like it had done in 1993—he dominated Speedweeks, only to finish second in the Daytona 500 to Dale Jarrett for the second time. He won early in the year, scoring consecutive victories at Rockingham and Atlanta. In late July in the DieHard 500 at Talladega, he was in the points lead and looking for his eighth season title, despite the departure of crew chief Andy Petree. Late in the race, Ernie Irvan lost control of his No. 28 Havoline-sponsored Ford Thunderbird, made contact with the No. 4 Kodak-sponsored Chevy Monte Carlo of Sterling Marlin, and ignited a crash that saw Earnhardt's No. 3 Chevrolet hit the tri-oval wall nearly head-on at almost 200 mph. After hitting the wall, Earnhardt's car flipped and slid across the track, in front of race-traffic. His car was hit in the roof and windshield. This accident, as well as a similar accident that led to the death of Russell Phillips at Charlotte, led NASCAR to mandate the "Earnhardt Bar", a metal brace located in the center of the windshield that reinforces the roof in case of a similar crash. This bar is also required in NASCAR-owned United SportsCar Racing and its predecessors for road racing.

Rain delays had canceled the live telecast of the race, and most fans first learned of the accident during the night's sports newscasts. Video of the crash showed what appeared to be a fatal incident, but once medical workers arrived at the car, Earnhardt climbed out and waved to the crowd, refusing to be loaded onto a stretcher despite a broken collarbone, sternum, and shoulder blade. Many thought the incident would end his season early, but Earnhardt refused to give up. The next week at Indianapolis, he started the race but exited the car on the first pit stop, allowing Mike Skinner to take the wheel. When asked, Earnhardt said that vacating the No. 3 car was the hardest thing he had ever done. The following weekend at Watkins Glen, he drove the No. 3 Goodwrench Chevrolet to the fastest time in qualifying, earning the "True Grit" pole. T-shirts emblazoned with Earnhardt's face were quickly printed up, brandishing the caption, "It Hurt So Good". Earnhardt led for most of the race and looked to have victory in hand, but fatigue took its toll and he ended up sixth behind race winner Geoff Bodine. Earnhardt did not win again in 1996 but still finished fourth in the standings behind Terry Labonte, Jeff Gordon, and Dale Jarrett. David Smith departed as crew chief of the No. 3 team and RCR at the end of the year for personal reasons, and he was replaced by Larry McReynolds.

In 1997, Earnhardt went winless for only the second time in his career. The only (non-points) win came during Speedweeks at Daytona in the Twin 125-mile qualifying race, his record eighth-straight win in the event. Once again in the hunt for the Daytona 500 with 10 laps to go, Earnhardt was taken out of contention by a late crash which sent his car upside down on the backstretch. He hit the low point of his year when he blacked out early in the Mountain Dew Southern 500 at Darlington in September, causing him to hit the wall. Afterward, he was disoriented, and it took several laps before he could find his pit stall. When asked, Earnhardt complained of double vision which made it difficult to pit. Mike Dillon (Richard Childress's son-in-law) was brought in to relieve Earnhardt for the remainder of the race. Earnhardt was evaluated at a local hospital and cleared to race the next week, but the cause of the blackout and double vision was never determined. Despite no wins, the RCR team finished the season fifth in the final standings.

1998 saw Earnhardt finally win the Daytona 500 in his 20th attempt after being shut out in his previous 19 attempts. He began the season by winning his Twin 125-mile qualifier race for the ninth straight year, and the week before was the first to drive around the track under the newly installed lights, for coincidentally 20 times. On race day, he showed himself to be a contender early. Halfway through the race, however, it seemed that Jeff Gordon had the upper hand. But by lap 138, Earnhardt had taken the lead and thanks to a push by teammate Mike Skinner, he maintained it. Earnhardt made it to the caution-checkered flag before Bobby Labonte. Afterwards, there was a large show of respect for Earnhardt, in which every crew member of every team lined pit road to shake his hand as he made his way to victory lane. Earnhardt then drove his No. 3 into the infield grass, starting a trend of post-race celebrations. He spun the car twice, throwing grass and leaving tire tracks in the shape of a No. 3 in the grass. He then spoke about the victory, saying, "I have had a lot of great fans and people behind me all through the years and I just can't thank them enough. The Daytona 500 is ours. We won it, we won it, we won it!" The rest of the season did not go as well, and the 500 was his only victory that year. Despite that, he did almost pull off a Daytona sweep, where he was one of the contenders for the win in the first nighttime Pepsi 400, but a pit stop late in the race in which he caught a rogue tire like a hockey puck cost him the race win. He slipped to 12th in the point standings halfway through the season, and Richard Childress decided to make a crew chief change, taking Mike Skinner's crew chief Kevin Hamlin and putting him with Earnhardt while giving Skinner Larry McReynolds (Earnhardt's crew chief). Earnhardt finished eighth in the final standings.

Before the 1999 season, fans began discussing Earnhardt's age and speculating that with his son, Dale Jr., making his Winston Cup debut, Earnhardt might be contemplating retirement. Earnhardt swept both races for the year at Talladega, leading some to conclude that his talent had become limited to the restrictor plate tracks, which require a unique skill set and an exceptionally powerful racecar to win. But halfway through the year, Earnhardt began to show some of the old spark. In the August race at Michigan, he led laps late in the race and nearly pulled off his first win on a non-restrictor-plate track since 1996.

One week later, he provided NASCAR with one of its most controversial moments. At the Bristol night race, Earnhardt found himself in contention to win his first short track race since Martinsville in 1995. When a caution came out with 15 laps to go, leader Terry Labonte got hit from behind by the lapped car of Darrell Waltrip. His spin put Earnhardt in the lead with five cars between him and Labonte with 5 laps to go. Labonte had four fresh tires, and Earnhardt was driving on old tires, which made Earnhardt's car considerably slower. Labonte caught Earnhardt and passed him coming to the white flag, but Earnhardt drove hard into turn two, bumping Labonte and spinning him around. Earnhardt collected the win while spectators booed and made obscene gestures. "I didn't mean to turn him around, I just wanted to rattle his cage," Earnhardt said of the incident. He finished seventh in the standings that year.

In the 2000 season, Earnhardt had a resurgence, which was commonly attributed to neck surgery he underwent to correct a lingering injury from his 1996 Talladega crash. He scored what were considered the two most exciting wins of the year—winning by 0.010 seconds over Bobby Labonte at Atlanta, then gaining seventeen positions in the final four laps to win at Talladega, claiming his only No Bull million-dollar bonus along with his record 10th win at the track. Earnhardt also had second-place runs at Richmond and Martinsville, tracks where he had struggled through the late 1990s. On the strength of those performances, Earnhardt got to second in the standings. However, poor performances at the road course of Watkins Glen, where he wrecked coming out of the chicane, a wreck with Kenny Irwin Jr. while leading the spring race at Bristol, and mid-pack runs at intermediate tracks like Charlotte and Dover in a season dominated by the Ford Taurus in those tracks from Roush, Yates, and Penske, coupled with Labonte's extreme consistency, denied Earnhardt an eighth championship title.

During the Daytona 500 at Daytona International Speedway on February 18, 2001, Earnhardt was killed in a three-car crash on the final lap of the race. He collided with Ken Schrader after making small contact with Sterling Marlin and hit the outside wall head-on. Earnhardt's and Schrader's cars both slid off the track's asphalt banking into the infield grass just inside of turn 4. Seconds later, his driver Michael Waltrip won the race, with his teammate and son Dale Earnhardt Jr. finishing second. Earnhardt's death was officially pronounced at the Halifax Medical Center at 5:16 PM Eastern Standard Time (22:16 UTC); he was 49 years old. NASCAR president Mike Helton confirmed Earnhardt's death in a statement to the press. An autopsy conducted on February 19, 2001 concluded that Earnhardt died instantly of blunt force trauma to his head due to the accident, and it also reported that Earnhardt sustained a fatal basilar skull fracture. Days later, on February 22, public funeral services were held at the Calvary Church in Charlotte, North Carolina.

After Earnhardt's death, both a police investigation and a NASCAR-sanctioned investigation commenced; nearly every detail of the crash was made public. The allegations of seatbelt failure resulted in Bill Simpson's resignation from the company bearing his name, which manufactured the seatbelts used in Earnhardt's car and nearly every other NASCAR driver's car. NASCAR implemented rigorous safety improvements, such as mandating the HANS device, which Earnhardt refused to wear after finding it restrictive and uncomfortable. Several press conferences were held in the days following Earnhardt's death. After driver Sterling Marlin and his relatives received hate mail and death threats from angry fans, Waltrip and Earnhardt Jr. absolved him of any responsibility. Richard Childress made a public pledge that the number 3 would never again adorn the side of a black race car with a GM Goodwrench sponsorship. Childress, who holds the rights from NASCAR to the No.3, placed a moratorium on using it; the number returned for the 2014 season, driven by Childress's grandson Austin Dillon.
At this time, his team was re-christened as the No. 29 team. Childress' second-year Busch Series driver Kevin Harvick was named as Earnhardt's replacement, beginning with the 2001 Dura Lube 400 at North Carolina Speedway. Special pennants bearing the No.3 were distributed to everyone at the track to honor Earnhardt, and the Childress team wore blank uniforms out of respect, something which disappeared quickly and was soon replaced by the previous GM Goodwrench Service Plus uniforms. Harvick's car always displayed the Earnhardt stylized number 3 on the "B" posts (metal portion on each side of the car to the rear of the front windows) above the number 29 until the end of 2013, when he departed for Stewart-Haas Racing.

Fans began honoring Earnhardt by holding three fingers aloft on the third lap of every race, a black screen of No. 3 in the beginning of "NASCAR Thunder 2002" before the EA Sports logo, and the television coverage of "NASCAR on Fox" and "NASCAR on NBC" went silent for each third lap from Rockingham to the following year's race there in honor of Earnhardt. On-track incidents brought out the caution flag on the third lap. Three weeks after Earnhardt's death, Harvick, driving a car that had been prepared for Earnhardt, scored his first career Cup win at Atlanta. On the final lap of the 2001 Cracker Barrel Old Country Store 500, he beat Jeff Gordon by .006 seconds (the margin being 0.004 of a second closer than Earnhardt had won over Bobby Labonte at the same race a year ago) in an identical photo finish, and the images of Earnhardt's longtime gas man Danny "Chocolate" Myers crying after the victory, Harvick's tire-smoking burnout on the frontstretch with three fingers held aloft outside the driver's window; and the Fox television call by Mike Joy, Larry McReynolds, and Darrell Waltrip concluding with "Just like a year ago [with Earnhardt and Bobby Labonte], but he [Harvick] is gonna get him though...Gordon got loose... it's Harvick! Harvick by inches!" are memorable to many NASCAR fans. The win was also considered cathartic for a sport whose epicenter had been ripped away. Harvick would win another race at the inaugural event at Chicagoland en route to a ninth-place finish in the final points, and won Rookie of the Year honors along with the 2001 NASCAR Busch Series Championship.

Dale Earnhardt, Inc. won five races in the 2001 season, beginning with Steve Park's victory in the race at Rockingham just one week after Earnhardt's death. Earnhardt Jr. and Waltrip finished first and second in the series' return to Daytona in July for the Pepsi 400, a reverse of the finish in the Daytona 500. Earnhardt Jr. also won the fall races at Dover (first post 9/11 race) and Talladega and came to an eighth-place points finish.

Earnhardt's remains were interred at his estate in Mooresville after a private funeral service on February 21, 2001.

Earnhardt drove the No. 3 car for the majority of his career, spanning the early 1980s until his death in 2001. Although he had other sponsors during his career, his No. 3 is associated in fans' minds with his last sponsor GM Goodwrench and his last color scheme — a predominantly black car with bold red and silver trim. The black and red No. 3 continues to be one of the most famous logos in North American motor racing.
A common misconception is that Richard Childress Racing "owns the rights" to the No. 3 in NASCAR competition (fueled by the fact that Kevin Harvick's car has a little No. 3 as an homage to Earnhardt and the usage of the No. 3 on the Camping World Series truck of Ty Dillon), but in fact no team owns the rights to this or any other number. However, according to established NASCAR procedures, RCR would have priority over other teams if and when the time came to reuse the number. RCR owns the stylized No. 3 logos used during Earnhardt's lifetime; however these rights may not prevent a future racing team from using a different No. 3 design (also, a new No. 3 team would most likely, in any case, need to create logos which fit with their sponsor's logos).

In 2004, ESPN released a made-for-TV movie entitled "", which used a new (but similarly colored) No. 3 logo. The movie was a sympathetic portrayal of Earnhardt's life, but the producers were sued for using the No. 3 logo. In December 2006, the ESPN lawsuit was settled, but details were not released to the public.

It is generally believed that current NASCAR owners have agreed never to use the No. 3 in Sprint Cup competition again, although this is not official NASCAR policy. Dale Earnhardt Jr. made two special appearances in 2002 in a No. 3 Busch Series car: these appearances were at the track where his father died (Daytona) and the track where he made his first Winston Cup start (Charlotte). Earnhardt Jr. won the first of those two races, which was the season-opening event at Daytona. He also raced a No. 3 sponsored by Wrangler on July 2, 2010, for Richard Childress Racing at Daytona. In a green-white- checker finish he outran Joey Logano to win his second race in the No. 3.

Otherwise, the No. 3 was missing from the national touring series until September 5, 2009, when Austin Dillon, the 19-year-old grandson of Richard Childress, debuted an RCR-owned No. 3 truck in the Camping World Truck Series. Dillon and his younger brother Ty Dillon drove No. 3s in various lower level competitions for several years, including the Camping World East Series. In 2012, A. Dillon began driving in the Nationwide Series full-time, using the No. 3; he had previously used the No. 33 while driving in that series part-time.

Richard Childress Racing entered a No. 3 in the Daytona truck race on February 13, 2010, painted identically to when Earnhardt drove it, but with a sponsorship from Bass Pro Shops. It was driven by A. Dillon. It was involved in a wreck almost identical to that which took the life of Earnhardt: being spun out, colliding with another vehicle, and being turned into the outside wall in turn number four. He walked away unscathed. Dillon again returned to a number "3" marked racecar when he started fifth in the 2012 Daytona Nationwide Series opener in an Advocare sponsored black Chevrolet Impala. On December 11, 2013, RCR announced that A. Dillon would drive the No. 3 car in the upcoming 2014 Sprint Cup season, bringing the number back to the series for the first time in 13 years.

Only the former International Race of Champions actually retired the No. 3, which they did in a rule change effective in 2004. Until the series folded in 2007, anyone wishing to use the No. 3 again had to use No. 03 instead.

Formula One driver Daniel Ricciardo chose the number "3" as his permanent racing number when F1's rules changed to allow drivers to choose their own numbers for 2014 and stated on Twitter that part of the reason for his choice was that he was a fan of Earnhardt's, while his helmet design features the number stylized in the same way.

"Earnhardt Tower", a seating section at Daytona International Speedway was opened and named in his honor a month before his death at the track.

Earnhardt has several roads named after him, including a street in his hometown Kannapolis. Dale Earnhardt Boulevard (originally Earnhardt Road) is marked as Exit 60 off Interstate 85, northeast of Charlotte. Dale Earnhardt Drive is also the start of The Dale Journey Trail, a self-guided driving tour of landmarks in the lives of Earnhardt and his family. The North Carolina Department of Transportation switched the designation of a road between Kannapolis and Mooresville near the headquarters of DEI (that used to be called NC 136) with NC 3, which was in Currituck County. In addition, Exit 72 off Interstate 35W, one of the entrances to Texas Motor Speedway, is named "Dale Earnhardt Way".

Between the 2004 and 2005 JGTC (renamed Super GT from 2005) season, Hasemi Sport competed in the series with a sole black G'Zox sponsored Nissan 350Z with the same number and letterset as Earnhardt on the roof.

During the NASCAR weekend races at Talladega Superspeedway on April 29, 2006 – May 1, 2006, the DEI cars competed in identical special black paint schemes on Dale Earnhardt Day, which is held annually on his birthday—April 29. Martin Truex Jr., won the Aaron's 312 in the black car, painted to reflect Earnhardt's Intimidating Black No. 3 NASCAR Busch Grand National series car. In the Nextel Cup race on May 1, No. 8 Dale Earnhardt Jr.; No. 1 Martin Truex Jr.; and No. 15 Paul Menard competed in cars with the same type of paint scheme.

On June 18, 2006, at Michigan for the 3M Performance 400, Earnhardt Jr. ran a special vintage Budweiser car to honor his father and his grandfather Ralph Earnhardt. He finished third after rain caused the race to be cut short. The car was painted to resemble Ralph's 1956 dirt cars, and carried 1956-era Budweiser logos to complete the throwback look.

In the summer of 2007, Dale Earnhardt, Inc. (DEI) with the Dale Earnhardt Foundation, announced it will fund an annual undergraduate scholarship at Clemson University in Clemson, South Carolina for students interested in motorsports and automotive engineering. Scholarship winners are also eligible to work at DEI in internships. The first winner was William Bostic, a senior at Clemson majoring in mechanical engineering.

In 2008, on the 50th anniversary of the first Daytona 500 race, DEI and RCR teamed up to make a special COT sporting Earnhardt's 1998 Daytona 500 paint scheme to honor the tenth anniversary of his Daytona 500 victory. In a tribute to all previous Daytona 500 winners, the winning drivers appeared in a lineup on stage, in chronological order. The throwback No. 3 car stood in the infield, in the approximate position Earnhardt would have taken in the processional. The throwback car featured the authentic 1998-era design on a current-era car, a concept similar to modern throwback jerseys in other sports. The car was later sold in 1:64 and 1:24 scale models.

The Intimidator 305 roller coaster has been open since April 2010 at Kings Dominion in Doswell, Virginia. Named after Earnhardt, the ride's trains are modeled after his black-and-red Chevrolet.

Atlanta Braves assistant coach Ned Yost was a friend of Earnhardt, and Richard Childress. When Yost was named Milwaukee Brewers manager, he changed jersey numbers, from No. 5 to No. 3 in Earnhardt's honor. (No. 3 is retired by the Braves in honor of outfielder Dale Murphy, so Yost could not make the change while in Atlanta.) When Yost was named Kansas City Royals assistant coach, he wore No. 2 for the 2010 season, even when he was named manager in May 2010, but for the 2011 season, he switched back to No. 3.

During the third lap of the 2011 Daytona 500 (a decade since Earnhardt's death), the commentators on FOX fell silent while fans raised three fingers in a similar fashion to the tributes throughout 2001.

The north entrance to New Avondale City Center in Arizona will bear the name Dale Earnhardt Drive. Avondale is where Earnhardt won a Cup race in 1990.

His helmet from the 1998 season is at the National Museum of American History in the Smithsonian museum in Washington D.C.

Weedeater, a sludge metal band from North Carolina, paid tribute to Earnhardt on their 2003 album "Sixteen Tons", with the song "No. 3". The song is played with audio clips from television broadcasts about Earnhardt mixed in the background.

On February 28, 2016, after winning the Folds of Honor QuikTrip 500 at Atlanta Motor Speedway, during his victory lap, driver Jimmie Johnson held his hand out of his window, with three fingers extended in tribute to Earnhardt. This was following Johnson's 76th Cup Series win, which tied the career mark of Earnhardt's. This is also the track where Earnhardt claimed his sixth Winston Cup Series title.




 


</doc>
<doc id="7896" url="https://en.wikipedia.org/wiki?curid=7896" title="List of games based on Dune">
List of games based on Dune

A number of games have been published which are based on the "Dune" universe created by Frank Herbert.




To date, there have been five licensed "Dune"-related video games released. There have also been many "Dune"-based MUDs (Multi-User Dimension) and browser-based online games, all created and run by fans.

1992's "Dune" from Cryo Interactive/Virgin Interactive blends adventure with strategy. Loosely following the story of the 1965 novel "Dune" and using many visual elements from the 1984 film of the same name by David Lynch, the game casts the player as Paul Atreides, with the ultimate goal of driving the Harkonnens from the planet Dune and taking control of its valuable export, the spice. Key to success is the management of spice mining, military forces, and ecology as the player amasses allies and skills.

"Dune II: The Building of a Dynasty", later retitled "Dune II: Battle for Arrakis" for the Mega Drive/Genesis port, was released in December 1992 from Westwood Studios/Virgin Interactive. Often considered to be the first "mainstream modern real-time strategy game", "Dune II" established many conventions of the genre. Only loosely connected to the plot of the novels or films, the game pits three interplanetary houses — the Atreides, the Harkonnens, and the Ordos — against each other for control of the planet Arrakis and its valuable spice, all while fending off the destructive natural forces of the harsh desert planet itself.

"Dune 2000", a 1998 remake of "Dune II" from Intelligent Games/Westwood Studios/Virgin Interactive, added improved graphics and live-action cutscenes. Though gameplay is similar to its predecessor, "Dune 2000" features an enhanced storyline and functionality.

"Emperor: Battle for Dune" (Intelligent Games/Westwood Studios/Electronic Arts) was released on June 12, 2001. A sequel to "Dune 2000", the real-time strategy game features 3D graphics and live-action cutscenes and casts players as Atreides, Harkonnens, or Ordos.

Released in 2001 by Cryo Interactive/DreamCatcher Interactive, "Frank Herbert's Dune" is a 3D video game based on the 2000 Sci Fi Channel miniseries of the same name. As Paul Muad'Dib Atreides, the player must become leader of the Fremen, seize control of Dune, and defeat the evil Baron Harkonnen. The game was not a commercial or critical success, and Cryo subsequently filed for bankruptcy in July 2002.

In 2001, Cryonetworks disclosed information about "Dune Generations", an online, 3D real-time strategy game set in the "Dune" universe. An official website for the upcoming game featured concept images, a brief background story and description of the persistent gameworld, and a list of frequently asked questions. The game would be constructed using Cryo's own online multimedia development framework SCOL.

Within "the infrastructure of a permanent and massive multiplayer world that exists online," "Dune Generations" would let players assume control of a dynasty in the "Dune" universe, with the goal of first mastering the natural resources of their own homeworlds and ultimately rising in power and influence through conflicts and alliances with other player dynasties. Each of the three available dynasty types — traders, soldiers, or mercenaries — would provide a different playing experience, all with the long-term goal of gaining control of Arrakis and its valuable spice.

A preview video trailer was released in November 2001. The game was still in the alpha testing stage in February 2002, and the project was ultimately halted after Cryo filed for bankruptcy in July 2002.

The "Dune Wars" mod is a total conversion of "" to the "Dune" setting. The mod was featured by Tom Chick in the relauched Tom vs Bruce series. In 2015 an updated version of the mod called "Dune Wars: Revival" was released.

Based on the PennMUSH text environment the popular Multi-User Shared Hallucination, DuneMUSH, began in December 1992 and ran through August 1994. Another MUSH, Dune III, was later created on MUSHPark. Its timeline was set 100 years prior to that of the novel, and ran for a few years before closing in 2011.

Around since 1992, Dune MUD is a text based virtual environment that promotes the hack and slash gameplay mechanic.



</doc>
<doc id="7900" url="https://en.wikipedia.org/wiki?curid=7900" title="List of Dune characters">
List of Dune characters

This is a list of the characters who appear in the novels of the fictional Dune universe, created by Frank Herbert and later expanded by Brian Herbert and Kevin J. Anderson.

This article provides links to many of the main characters in the "Dune" universe. They are grouped by primary allegiances. In some cases these allegiances change or reveal themselves to be different throughout the novels.
















Titans:
Neo-Cymeks:




</doc>
<doc id="7901" url="https://en.wikipedia.org/wiki?curid=7901" title="Vladimir Harkonnen">
Vladimir Harkonnen

The Baron Vladimir Harkonnen is a fictional character and antagonist from the "Dune" universe created by Frank Herbert. He is primarily featured in the 1965 novel "Dune" and is also a prominent character in the "Prelude to Dune" prequel trilogy (1999-2001) by Brian Herbert and Kevin J. Anderson. The character is brought back as a ghola in the Herbert/Anderson sequels which conclude the original series, "Hunters of Dune" (2006) and "Sandworms of Dune" (2007).

Frank Herbert wanted a harsh-sounding name for the antagonists of his novel, "Dune". Herbert came across the name "Härkönen" in a California telephone book and thought that it sounded "Soviet" (it is in fact Finnish), which touched a nerve with Cold War-era readers. In earlier drafts of his novel, the lead villain was called "Valdemar Hoskanner".

Herbert's "Appendix IV: The Almanak en-Ashraf (Selected Excerpts of the Noble Houses)" in "Dune" says of Harkonnen (in part):
In "Dune", Herbert writes that the Baron possesses a "basso voice" and is so "grossly and immensely fat" that he requires anti-gravity devices known as suspensors to support his weight.

As ruthless and cruel as he is intelligent and cunning, the Baron has a talent for manipulating others and exploiting their weaknesses. His sexual preference for young men is implied in "Dune" and "Children of Dune". It is noted, however, that he "once permitted himself to be seduced" in the liaison which produced his secret daughter.

As "Dune" begins, a longstanding feud exists between the Harkonnens of Giedi Prime and the Atreides of Caladan. The Baron's intent to exterminate the Atreides line seems close to fruition as Duke Leto Atreides is lured to the desert planet Arrakis on the pretense of taking over the valuable melange operation there. The Baron has an agent in the Atreides household: Leto's own physician, the trusted Suk doctor Wellington Yueh. Though Suk Imperial Conditioning supposedly makes the subject incapable of inflicting harm, the Baron's twisted Mentat Piter De Vries notes:

The Baron has taken Yueh's wife Wanna prisoner, threatening her with interminable torture unless Yueh complies with his demands. Harkonnen also distracts Leto's Mentat Thufir Hawat from discovering Yueh by guiding Hawat toward another suspect: Leto's Bene Gesserit concubine Lady Jessica, of whom Hawat is already distrustful. The Atreides are soon attacked by Harkonnen forces (secretly supplemented by the seemingly unstoppable Imperial Sardaukar) as Yueh disables the protective shields around the Atreides palace on Arrakis. As instructed, Yueh takes Leto prisoner; however, desiring to slay the Baron, Yueh provides the captive Leto with a fake tooth filled with poisonous gas as a means of simultaneous assassination and suicide. De Vries kills Yueh but he also dies with Leto in the assassination attempt; however Harkonnen survives. The Baron then manipulates Hawat into his service, by convincing Hawat that Lady Jessica was the traitor and using Hawat's desire for revenge on Lady Jessica and the Emperor as motivation to assist House Harkonnen.

Leto and Jessica's son Paul Atreides flee into the desert with Jessica, and both are presumed dead. Paul's prescience helps him determine the identity of Jessica's father, the "maternal grandfather who cannot be named" — the Baron himself. Over the next two years, Harkonnen learns that his nephews Glossu Rabban and Feyd-Rautha are conspiring against him to usurp his throne; he lets them continue to do so, reasoning that they have to somehow learn to organize a conspiracy. As punishment for a failed assassination attempt against him, Harkonnen forces Feyd to single-handedly slaughter all the female slaves who serve as Feyd's lovers. He explains that Feyd has to learn the price of failure.

The Baron's plan to assure Feyd's power is to install him as ruler of Arrakis after a period of tyrannical misrule by Rabban, making Feyd appear to be the savior of the people. However, a crisis on Arrakis begins when the mysterious Muad'Dib emerges as a leader of the native Fremen tribes against the rule of the Harkonnens. Eventually, a series of Fremen victories against Beast Rabban threaten to disrupt the trade of the spice. The Padishah Emperor Shaddam IV decides to intervene himself and arrives on Arrakis along with legions of Sardaukar forces. Shaddam and the Baron are shocked to learn that Muad'Dib is, of course, a very-much-alive Paul Atreides. The Imperial forces fall prey to a surprise attack by the Fremen. Part of the Fremen/Atreides strategy is to wait until a sandstorm shorts out the force field shields of the Harkonnen/Imperial transport ships, disable them with projectile weapons, and then attack with a vast assault force, using sandworms under cover of the severe weather to break the enemy lines. The Sardaukar and Harkonnen forces are trapped on the planet, astonished at the sandworm mounts and vast numbers of their attackers. Their past ruthlessness gives them little hope of quarter from the enraged Fremen.

Rabban dies in the initial part of the battle; the Harkonnen army is massacred to the last man and almost all the Imperial Sardaukar are killed. Baron Harkonnen himself is poisoned with a gom jabbar by Paul's young sister Alia Atreides, his own granddaughter, and dies at the age of 83, with the latter also revealing her direct lineage to him just beforehand. Paul then kills Feyd in ritual combat. House Harkonnen's virtual extermination removes it as a galactic power, but Paul's ascension to the Imperial throne in Shaddam's place guarantees that Vladimir's descendants will long reign as the Imperial House Atreides.

Alia had been born with her ancestral memories in the womb, a circumstance the Bene Gesserit refer to as Abomination, because in their experience it is inevitable that the individual will become possessed by the personality of one of their ancestors. In "Children of Dune", Alia falls victim to this prediction when she shares control of her body with the ego-memory of the Baron Harkonnen, and eventually falls under his power. Alia eventually commits suicide, realizing that Harkonnen's consciousness has surpassed her abilities to contain him.

In the "Prelude to Dune" prequel series by Brian Herbert and Anderson, it is established that Baron Vladimir Harkonnen is the son and heir of Dmitri Harkonnen and his wife Victoria. Harkonnen's father had been the head of House Harkonnen and ruled the planet Giedi Prime. Trained since youth as a possible successor, Vladimir had been eventually chosen over his half-brother Abulurd (namesake of the original). Unhappy with his brother's doings, Abulurd eventually marries Emmi Rabban and renounces the family name and his rights to the title. Under the name Abulurd Rabban, he reigns as governor of the secondary Harkonnen planet Lankiveil. Abulurd and his wife have two sons: Glossu Rabban (later nicknamed "Beast Rabban" after he murders his own father) and Feyd-Rautha; Vladimir later adopts the boys back into House Harkonnen, and Feyd becomes his designated heir.

The Baron's most prominent political rival is Duke Leto Atreides; the Harkonnens and the Atreides have been bitter enemies for millennia, since the Battle of Corrin that ended the Butlerian Jihad. When Emperor Shaddam IV orchestrates a plot to destroy the "Red Duke" Leto, the Baron eagerly lends his aid.

The young Baron Vladimir is described as an exceedingly handsome man, possessing red hair and a near-perfect physique. The Bene Gesserit Reverend Mother Gaius Helen Mohiam is instructed by the Sisterhood to collect the genetic material of Baron Vladimir Harkonnen (through conception) for their breeding program. As the Baron's homosexuality is something of an open secret, Mohiam blackmails him into having sexual relations with her and conceives his child. When that daughter proves genetically undesirable, Mohiam kills her and returns to Harkonnen for a second try; at this point he drugs and viciously rapes her. She exacts her retribution by infecting him with a rare, incurable disease that later causes his obesity. Mohiam's second child with the Baron is Jessica.

In "", the deteriorating Baron at first walks with the assistance of a cane, then relies on belt-mounted suspensors to retain mobility. He consults numerous doctors in the expanse of time between the "" and "Dune: House Harkonnen", up to and including his future instrument Dr. Yueh, all of whom are ultimately no help. To conceal this debilitation, he pretends that his obesity is due to intentional overindulgence, lest the Landsraad remove him from power. When he determines that Mohiam inflicted him with the disease, he attempts to coerce her into revealing the cure, but soon discovers that there is none.

The Baron, Duke Leto, and Jessica herself are unaware that Jessica is secretly the Baron's daughter or that he has even fathered one; in the year 10,176, the Baron's grandson Paul is born to Leto and Jessica.

In "Hunters of Dune" (2006), the continuation of the original series by Brian Herbert and Kevin J. Anderson, the Baron is resurrected as a ghola (5,029 years after the death of Alia) by the Lost Tleilaxu Uxtal, acting on orders from the Face Dancer Khrone. Khrone intends to use the Baron ghola to manipulate a ghola of Paul Atreides, named Paolo. Khrone tries various torture techniques for three years to awaken the 12-year-old Baron's genetic memories; these methods fail due to the Baron's sadomasochistic nature. Khrone is successful when he imprisons the Baron in a sensory deprivation tank for a prolonged period; the Baron's memories of his former life return. Ironically, the reincarnated Baron is soon haunted by the voice of Alia in his mind; the source of this inner Alia is never explained.

In David Lynch's 1984 film, Baron Harkonnen was portrayed by Kenneth McMillan. In this characterization, he is grotesquely overweight, dressed in filthy garments and covered in large, black pustules which require constant draining and treatment. This version of the character is more overtly unstable than in the novel, screaming and laughing incoherently at any given moment and even drinking the blood of a servant after removing a "heart plug." Diverging from the novel, after Alia pricks Harkonnen with the gom jabbar, she pushes him and sends him flying through a hole in the palace wall, to be devoured by a giant sandworm.

British actor Ian McNeice's interpretation of the Baron in the 2000 Sci-Fi Channel miniseries "Frank Herbert's Dune" (and its sequel, 2003's "Children of Dune") is, though dramatic, somewhat lighter, more eloquent and sane in comparison to Lynch's version, and therefore more consistent with the novel. Though the Baron still takes sadistic enjoyment in the suffering of others, he is portrayed as somewhat flamboyant, pompous, calculating and self-indulgent, with a tendency to speak in iambic pentameter when the mood strikes him.

Though Herbert's novel "Dune" seems to describe Harkonnen's suspensor belt as simply enabling him to stand and walk upright rather than actually "fly," both the 1984 film and the 2000 miniseries feature the Baron utilizing the suspensors to levitate off the ground and float through the air in a flying-like manner. The later "Prelude to Dune" prequels also employ this floating ability. Herbert does, however, note Harkonnen floating slightly off the floor after he is killed.

The video game "", whose in-game cut scenes are visually inspired by David Lynch's film, features a character named Baron Rakan Harkonnen, portrayed by Mike McShane. This Harkonnen is nearly identical to the film's version of Vladimir in both appearance (minus the belt-mounted suspensors) and personality, and also dies by poisoning.

H. R. Giger's Harkonnen Capo Chair is a chair originally designed by the artist as set dressing for an unrealized 1970s adaptation of "Dune" by Alejandro Jodorowsky.



</doc>
<doc id="7902" url="https://en.wikipedia.org/wiki?curid=7902" title="Piter De Vries">
Piter De Vries

Piter De Vries is a fictional character from the "Dune" universe created by Frank Herbert. He is primarily featured in the 1965 novel "Dune", but also appears in the "Prelude to Dune" prequel trilogy (1999–2001) by Brian Herbert and Kevin J. Anderson.

De Vries is portrayed by Brad Dourif in David Lynch's 1984 film "Dune", and by Jan Unger in the 2000 "Dune" miniseries.

In the service of the ruthless Baron Vladimir Harkonnen, De Vries is a Mentat — a human specially trained to perform mental functions rivaling computers, which are forbidden universe-wide. In addition, De Vries has been "twisted" into an amoral sadist by his Tleilaxu creators.

De Vries is so loyal to Harkonnen that he continues to serve the Baron with great enthusiasm even though his Mentat abilities and great intelligence confirm his suspicions that his master plans to eventually kill him. As he says in "Dune":

De Vries is described in the novel "Dune" (though not portrayed on screen) as being addicted to the drug melange, which has colored both the sclera and irises of his eyes a characteristic deep blue.

In "Dune", it is established that De Vries had pioneered a type of toxin called "residual poison" which remains in the body for years and requires an antidote to be administered regularly. One such fatal poison is secretly administered by the Harkonnens to Thufir Hawat, the Mentat of House Atreides, in order to keep Hawat's allegiance as the only provider of the antidote (in the 1984 movie version, it is shown that Hawat has to milk a gruesome captive cat for the antidote every day).

De Vries is generally regarded as architect of the plan to destroy House Atreides, long-time enemy of the Harkonnens, while restoring the Baron's stewardship over the planet Arrakis. Through torture and psychological manipulation, De Vries breaks the Suk conditioning of Wellington Yueh, personal physician to House Atreides, which renders him incapable of inflicting harm on his patients. Yueh eventually betrays House Atreides. De Vries originally plans to claim Lady Jessica, the concubine of Duke Leto Atreides, as his slave, but he decides to become governor of Arrakis instead. However, Yueh has given the captured Leto a false tooth filled with poison gas. When Leto crushes the tooth, the intended victim Baron Harkonnen escapes, but Leto and De Vries die.

In "" (published in 2001 and the third novel in the "Prelude to Dune" prequel series by Brian Herbert and Kevin J. Anderson), Piter De Vries discovers the Harkonnen heritage of Lady Jessica and her newborn son Paul, and attempts to kidnap and ransom the infant. The plot is thwarted and the secret preserved — the Reverend Mother Gaius Helen Mohiam kills the Mentat and arranges for his corpse to be shipped home to Giedi Prime. An enraged Baron is left with no choice but to order a duplicate from the Bene Tleilax: the Mentat De Vries featured in Herbert's original novel "Dune".



</doc>
<doc id="7903" url="https://en.wikipedia.org/wiki?curid=7903" title="Diffie–Hellman key exchange">
Diffie–Hellman key exchange

Diffie–Hellman key exchange (DH) is a method of securely exchanging cryptographic keys over a public channel and was one of the first public-key protocols as originally conceptualized by Ralph Merkle and named after Whitfield Diffie and Martin Hellman. DH is one of the earliest practical examples of public key exchange implemented within the field of cryptography. 

Traditionally, secure encrypted communication between two parties required that they first exchange keys by some secure physical channel, such as paper key lists transported by a trusted courier. The Diffie–Hellman key exchange method allows two parties that have no prior knowledge of each other to jointly establish a shared secret key over an insecure channel. This key can then be used to encrypt subsequent communications using a symmetric key cipher.

Diffie–Hellman is used to secure a variety of Internet services. However, research published in October 2015 suggests that the parameters in use for many DH Internet applications at that time are not strong enough to prevent compromise by very well-funded attackers, such as the security services of large governments.

The scheme was first published by Whitfield Diffie and Martin Hellman in 1976, but in 1997 it was revealed that James H. Ellis, Clifford Cocks and Malcolm J. Williamson of GCHQ, the British signals intelligence agency, had previously, in 1969, shown how public-key cryptography could be achieved.

Although Diffie–Hellman key agreement itself is a non-authenticated key-agreement protocol, it provides the basis for a variety of authenticated protocols, and is used to provide forward secrecy in Transport Layer Security's ephemeral modes (referred to as EDH or DHE depending on the cipher suite).

The method was followed shortly afterwards by RSA, an implementation of public-key cryptography using asymmetric algorithms.

In 2002, Hellman suggested the algorithm be called Diffie–Hellman–Merkle key exchange in recognition of Ralph Merkle's contribution to the invention of public-key cryptography (Hellman, 2002), writing:

Diffie–Hellman Key Exchange establishes a shared secret between two parties that can be used for secret communication for exchanging data over a public network. The following conceptual diagram illustrates the general idea of the key exchange by using colors instead of very large numbers.

The process begins by having the two parties, Alice and Bob, agree on an arbitrary starting color that does not need to be kept secret (but should be different every time); in this example the color is yellow. Each of them selects a secret color that they keep to themselves. In this case, orange and blue-green. The crucial part of the process is that Alice and Bob now mix their secret color together with their mutually shared color, resulting in orange-tan and light-blue mixtures respectively, then publicly exchange the two mixed colors. Finally, each of the two mix together the color they received from the partner with their own private color. The result is a final color mixture yellow-brown that is identical to the partner's color mixture.

If a third party listened to the exchange, it would be computationally difficult for them to determine the secret colors. In fact, when using large numbers rather than colors, this action is computationally expensive for modern supercomputers to do in a reasonable amount of time. 

The simplest and the original implementation of the protocol uses the multiplicative group of integers modulo "p", where "p" is prime, and "g" is a primitive root modulo "p". These two values are chosen in this way to ensure that the resulting shared secret can take on any value from 1 to "p"–1. Here is an example of the protocol, with non-secret values in blue, and secret values in red.


Both Alice and Bob have arrived at the same value s, because, under mod p,

More specifically,

Note that only "a", "b", and ("g" mod "p" = "g" mod "p") are kept secret. All the other values – "p", "g", "g" mod "p", and "g" mod "p" – are sent in the clear. Once Alice and Bob compute the shared secret they can use it as an encryption key, known only to them, for sending messages across the same open communications channel.

Of course, much larger values of "a", "b", and "p" would be needed to make this example secure, since there are only 23 possible results of "n" mod 23. However, if "p" is a prime of at least 600 digits, then even the fastest modern computers cannot find "a" given only "g", "p" and "g" mod "p". Such a problem is called the discrete logarithm problem. The computation of "g" mod "p" is known as modular exponentiation and can be done efficiently even for large numbers.
Note that "g" need not be large at all, and in practice is usually a small integer (like 2, 3, ...).

The chart below depicts who knows what, again with non-secret values in blue, and secret values in red. Here Eve is an eavesdropper—she watches what is sent between Alice and Bob, but she does not alter the contents of their communications.


Now s is the shared secret key and it is known to both Alice and Bob, but "not" to Eve.

Note: It should be difficult for Alice to solve for Bob's private key or for Bob to solve for Alice's private key. If it is not difficult for Alice to solve for Bob's private key (or vice versa), Eve may simply substitute her own private / public key pair, plug Bob's public key into her private key, produce a fake shared secret key, and solve for Bob's private key (and use that to solve for the shared secret key. Eve may attempt to choose a public / private key pair that will make it easy for her to solve for Bob's private key).

Another demonstration of Diffie–Hellman (also using numbers too small for practical use) is given here.

Here is a more general description of the protocol:


Both Alice and Bob are now in possession of the group element "g", which can serve as the shared secret key. The group "G" satisfies the requisite condition for secure communication if there is not an efficient algorithm for determining "g" given "g", "g", and "g".

For example, the elliptic curve Diffie–Hellman protocol is variant that uses elliptic curves instead of the multiplicative group of integers modulo p. Variants using hyperelliptic curves have also been proposed. The supersingular isogeny key exchange is a Diffie–Hellman variant that has been designed to be secure against quantum computers.

Diffie–Hellman key agreement is not limited to negotiating a key shared by only two participants. Any number of users can take part in an agreement by performing iterations of the agreement protocol and exchanging intermediate data (which does not itself need to be kept secret). For example, Alice, Bob, and Carol could participate in a Diffie–Hellman agreement as follows, with all operations taken to be modulo "p":


An eavesdropper has been able to see "g", "g", "g", "g", "g", and "g", but cannot use any combination of these to efficiently reproduce "g".

To extend this mechanism to larger groups, two basic principles must be followed:


These principles leave open various options for choosing in which order participants contribute to keys. The simplest and most obvious solution is to arrange the "N" participants in a circle and have "N" keys rotate around the circle, until eventually every key has been contributed to by all "N" participants (ending with its owner) and each participant has contributed to "N" keys (ending with their own). However, this requires that every participant perform "N" modular exponentiations.

By choosing a more optimal order, and relying on the fact that keys can be duplicated, it is possible to reduce the number of modular exponentiations performed by each participant to using a divide-and-conquer-style approach, given here for eight participants:


Once this operation has been completed all participants will possess the secret "g", but each participant will have performed only four modular exponentiations, rather than the eight implied by a simple circular arrangement.

The protocol is considered secure against eavesdroppers if "G" and "g" are chosen properly. In particular, the order of the group G must be large, particularly if the same group is used for large amounts of traffic. The eavesdropper ("Eve") has to solve the Diffie–Hellman problem to obtain "g". This is currently considered difficult for groups whose order is large enough. An efficient algorithm to solve the discrete logarithm problem would make it easy to compute "a" or "b" and solve the Diffie–Hellman problem, making this and many other public key cryptosystems insecure. Fields of small characteristic may be less secure.

The order of "G" should have a large prime factor to prevent use of the Pohlig–Hellman algorithm to obtain "a" or "b". For this reason, a Sophie Germain prime "q" is sometimes used to calculate , called a safe prime, since the order of "G" is then only divisible by 2 and "q". "g" is then sometimes chosen to generate the order "q" subgroup of "G", rather than "G", so that the Legendre symbol of "g" never reveals the low order bit of "a". A protocol using such a choice is for example IKEv2.

"g" is often a small integer such as 2. Because of the random self-reducibility of the discrete logarithm problem a small "g" is equally secure as any other generator of the same group.

If Alice and Bob use random number generators whose outputs are not completely random and can be predicted to some extent, then Eve's task is much easier.

In the original description, the Diffie–Hellman exchange by itself does not provide authentication of the communicating parties and is thus vulnerable to a man-in-the-middle attack. Mallory (an active attacker executing the man-in-the-middle attack) may establish two distinct key exchanges, one with Alice and the other with Bob, effectively masquerading as Alice to Bob, and vice versa, allowing her to decrypt, then re-encrypt, the messages passed between them. Note that Mallory must continue to be in the middle, transferring messages every time Alice and Bob communicate. If she is ever absent, her previous presence is then revealed to Alice and Bob. They will know that all of their private conversations had been intercepted and decoded by someone in the channel.

A method to authenticate the communicating parties to each other is generally needed to prevent this type of attack. Variants of Diffie–Hellman, such as STS protocol, may be used instead to avoid these types of attacks.

The number field sieve algorithm, which is generally the most effective in solving the discrete logarithm problem, consists of four computational steps. The first three steps only depend on the order of the group G, not on the specific number whose finite log is desired. It turns out that much Internet traffic uses one of a handful of groups that are of order 1024 bits or less. By precomputing the first three steps of the number field sieve for the most common groups, an attacker need only carry out the last step, which is much less computationally expensive than the first three steps, to obtain a specific logarithm. The Logjam attack used this vulnerability to compromise a variety of Internet services that allowed the use of groups whose order was a 512-bit prime number, so called export grade. The authors needed several thousand CPU cores for a week to precompute data for a single 512-bit prime. Once that was done, individual logarithms could be solved in about a minute using two 18-core Intel Xeon CPUs.

As estimated by the authors behind the Logjam attack, the much more difficult precomputation needed to solve the discrete log problem for a 1024-bit prime would cost on the order of $100 million, well within the budget of large national intelligence agency such as the U.S. National Security Agency (NSA). The Logjam authors speculate that precomputation against widely reused 1024-bit DH primes is behind claims in leaked NSA documents that NSA is able to break much of current cryptography.

To avoid these vulnerabilities, authors recommend use of elliptic curve cryptography, for which no similar attack is known. Failing that, they recommend that the order, "p", of the Diffie–Hellman group should be at least 2048 bits. They estimate that the pre-computation required for a 2048-bit prime is 10 more difficult than for 1024-bit primes.

Public key encryption schemes based on the Diffie–Hellman key exchange have been proposed. The first such scheme is the ElGamal encryption. A more modern variant is the 
Integrated Encryption Scheme.

Protocols that achieve forward secrecy generate new key pairs for each session and discard them at the end of the session.
The Diffie–Hellman key exchange is a frequent choice for such protocols, because of its fast key generation.

When Alice and Bob share a password, they may use a password-authenticated key agreement (PK) form of Diffie–Hellman to prevent man-in-the-middle attacks. One simple scheme is to compare the hash of s concatenated with the password calculated independently on both ends of channel. A feature of these schemes is that an attacker can only test one specific password on each iteration with the other party, and so the system provides good security with relatively weak passwords. This approach is described in ITU-T Recommendation X.1035, which is used by the G.hn home networking standard.

An example of such a protocol is the Secure Remote Password Protocol.

It is also possible to use Diffie–Hellman as part of a public key infrastructure, allowing Bob to encrypt a message so that only Alice will be able to decrypt it, with no prior communication between them other than Bob having trusted knowledge of Alice's public key. Alice's public key is formula_3. To send her a message, Bob chooses a random "b" and then sends Alice formula_4 (un-encrypted) together with the message encrypted with symmetric key formula_5. Only Alice can determine the symmetric key and hence decrypt the message because only she has "a" (the private key). A pre-shared public key also prevents man-in-the-middle attacks.

In practice, Diffie–Hellman is not used in this way, with RSA being the dominant public key algorithm. This is largely for historical and commercial reasons, namely that RSA Security created a certificate authority for key signing that became Verisign. Diffie–Hellman cannot be used to sign certificates. However, the ElGamal and DSA signature algorithms are mathematically related to it, as well as MQV, STS and the IKE component of the IPsec protocol suite for securing Internet Protocol communications.





</doc>
<doc id="7906" url="https://en.wikipedia.org/wiki?curid=7906" title="Destry Rides Again">
Destry Rides Again

Destry Rides Again is a 1939 western starring Marlene Dietrich and James Stewart, and directed by George Marshall. The supporting cast includes Mischa Auer, Charles Winninger, Brian Donlevy, Allen Jenkins, Irene Hervey, Billy Gilbert, Bill Cody, Jr., Lillian Yarbo, and Una Merkel. Although the title comes from Max Brand's popular novel, which inspired the earlier screenplay with Tom Mix, this version is almost entirely unrelated to either.

In 1996, "Destry Rides Again" was selected for preservation in the United States National Film Registry by the Library of Congress as being "culturally, historically, or aesthetically significant".

Saloon owner Kent (Brian Donlevy), the unscrupulous boss of the fictional Western town of Bottleneck, has the town's sheriff, Mr. Keogh (Joe King), killed when Keogh asks one too many questions about a rigged poker game. Kent and "Frenchy" (Marlene Dietrich), his girlfriend and the dance hall queen, now have a stranglehold over the local cattle ranchers. The crooked town's mayor, Hiram J. Slade (Samuel S. Hinds), who is in collusion with Kent, appoints the town drunk, Washington Dimsdale (Charles Winninger), as the new sheriff, assuming that he will be easy to control and manipulate. But what the mayor does not know is that Dimsdale was a deputy under the famous lawman Tom Destry, and is able to call upon the latter's equally formidable son, Tom Destry, Jr. (James Stewart), to help him make Bottleneck a lawful, respectable town. 

Destry confounds the townsfolk by refusing to strap on a gun in spite of demonstrating that he is an expert marksman. He still carries out the "letter of the law", as deputy sheriff, and earns their respect. A final confrontation between Destry and Kent's gang is inevitable, but "Frenchy" is won over by Destry and changes sides. A final gunfight ensues where Frenchy is killed in the crossfire, and the rule of law wins the day.

As appearing in screen credits:

Dietrich sings "See What the Boys in the Back Room Will Have" and "You've Got That Look", written by Frank Loesser, set to music by Frederick Hollander, which have become classics.

Famed Western writer Max Brand contributed the novel, "Destry Rides Again", but the film also owes its origins to Brand's serial "Twelve Peers", published in a pulp-magazine. In the original work, Harrison (or "Harry") Destry was not a pacifist. As filmed in 1932, with Tom Mix in the starring role, the central character differed in that Destry did wear six-guns in that version.

The film was James Stewart's first western (he would not return to the genre until 1950, with "Broken Arrow" and "Winchester 73"). The story featured a ferocious cat-fight between Marlene Dietrich and Una Merkel, which apparently caused a mild censorship problem at the time of release.

According to writer/director Peter Bogdanovich, Marlene Dietrich told him during an aircraft flight that she and James Stewart had an affair during shooting and that she became pregnant but had a surreptitious abortion without telling Stewart.

Internationally, the film was released under the alternate titles "" in French and "Arizona" in Spanish.

"Destry Rides Again" was generally well accepted by the public, as well as critics. It was reviewed by Frank S. Nugent in "The New York Times," who noted that the film did not follow the usual Hollywood type-casting. On Dietrich's role, he characterized, "It's difficult to reconcile Miss Dietrich's Frenchy, the cabaret girl of the Bloody Gulch Saloon, with the posed and posturing Dietrich we last saw in Mr. Lubitsch's 'Angel'." Stewart's contribution was similarly treated, "turning in an easy, likable, pleasantly humored performance."


Notes
Bibliography



</doc>
<doc id="7921" url="https://en.wikipedia.org/wiki?curid=7921" title="Derivative">
Derivative

The derivative of a function of a real variable measures the sensitivity to change of the function value (output value) with respect to a change in its argument (input value). Derivatives are a fundamental tool of calculus. For example, the derivative of the position of a moving object with respect to time is the object's velocity: this measures how quickly the position of the object changes when time advances.

The derivative of a function of a single variable at a chosen input value, when it exists, is the slope of the tangent line to the graph of the function at that point. The tangent line is the best linear approximation of the function near that input value. For this reason, the derivative is often described as the "instantaneous rate of change", the ratio of the instantaneous change in the dependent variable to that of the independent variable.

Derivatives may be generalized to functions of several real variables. In this generalization, the derivative is reinterpreted as a linear transformation whose graph is (after an appropriate translation) the best linear approximation to the graph of the original function. The Jacobian matrix is the matrix that represents this linear transformation with respect to the basis given by the choice of independent and dependent variables. It can be calculated in terms of the partial derivatives with respect to the independent variables. For a real-valued function of several variables, the Jacobian matrix reduces to the gradient vector.

The process of finding a derivative is called differentiation. The reverse process is called "antidifferentiation". The fundamental theorem of calculus states that antidifferentiation is the same as integration. Differentiation and integration constitute the two fundamental operations in single-variable calculus.

"Differentiation" is the action of computing a derivative. The derivative of a function of a variable is a measure of the rate at which the value of the function changes with respect to the change of the variable . It is called the "derivative" of with respect to . If and are real numbers, and if the graph of is plotted against , the derivative is the slope of this graph at each point.
The simplest case, apart from the trivial case of a constant function, is when is a linear function of , meaning that the graph of is a line. In this case, , for real numbers and , and the slope is given by
where the symbol (Delta) is an abbreviation for "change in". This formula is true because
Thus, since
it follows that

This gives an exact value for the slope of a line.
If the function is not linear (i.e. its graph is not a straight line), however, then the change in divided by the change in varies: differentiation is a method to find an exact value for this rate of change at any given value of .

The idea, illustrated by Figures 1 to 3, is to compute the rate of change as the limit value of the ratio of the differences as becomes infinitely small.

Two distinct notations are commonly used for the derivative, one deriving from Leibniz and the other from Joseph Louis Lagrange.

In Leibniz's notation, an infinitesimal change in is denoted by , and the derivative of with respect to is written
suggesting the ratio of two infinitesimal quantities. (The above expression is read as "the derivative of "y" with respect to "x"", "d y by d x", or "d y over d x". The oral form "d y d x" is often used conversationally, although it may lead to confusion.)

In Lagrange's notation, the derivative with respect to of a function is denoted (read as "f prime of x") or (read as "f prime x of x"), in case of ambiguity of the variable implied by the derivation. Lagrange's notation is sometimes incorrectly attributed to Newton.

The most common approach to turn this intuitive idea into a precise definition is to define the derivative as a limit of difference quotients of real numbers. This is the approach described below.

Let be a real valued function defined in an open neighborhood of a real number . In classical geometry, the tangent line to the graph of the function at was the unique line through the point that did "not" meet the graph of transversally, meaning that the line did not pass straight through the graph. The derivative of with respect to at is, geometrically, the slope of the tangent line to the graph of at . The slope of the tangent line is very close to the slope of the line through and a nearby point on the graph, for example . These lines are called secant lines. A value of close to zero gives a good approximation to the slope of the tangent line, and smaller values (in absolute value) of will, in general, give better approximations. The slope of the secant line is the difference between the values of these points divided by the difference between the values, that is, 

This expression is Newton's difference quotient. Passing from an approximation to an exact answer is done using a limit. Geometrically, the limit of the secant lines is the tangent line. Therefore, the limit of the difference quotient as approaches zero, if it exists, should represent the slope of the tangent line to . This limit is defined to be the derivative of the function at :

When the limit exists, is said to be "differentiable" at . Here is one of several common notations for the derivative (see below).

Equivalently, the derivative satisfies the property that
which has the intuitive interpretation (see Figure 1) that the tangent line to at gives the "best linear approximation"
to near (i.e., for small ). This interpretation is the easiest to generalize to other settings (see below).

Substituting 0 for in the difference quotient causes division by zero, so the slope of the tangent line cannot be found directly using this method. Instead, define to be the difference quotient as a function of :

In practice, the existence of a continuous extension of the difference quotient to is shown by modifying the numerator to cancel in the denominator. Such manipulations can make the limit value of for small clear even though is still not defined at . This process can be long and tedious for complicated functions, and many shortcuts are commonly used to simplify the process.

Relative to a hyperreal extension of the real numbers, the derivative of a real function at a real point can be defined as the shadow of the quotient for infinitesimal , where . Here the natural extension of to the hyperreals is still denoted . Here the derivative is said to exist if the shadow is independent of the infinitesimal chosen.

The squaring function is differentiable at , and its derivative there is 6. This result is established by calculating the limit as approaches zero of the difference quotient of :

The last expression shows that the difference quotient equals when and is undefined when , because of the definition of the difference quotient. However, the definition of the limit says the difference quotient does not need to be defined when . The limit is the result of letting go to zero, meaning it is the value that tends to as becomes very small:

Hence the slope of the graph of the squaring function at the point is , and so its derivative at is .

More generally, a similar computation shows that the derivative of the squaring function at is :

If is differentiable at , then must also be continuous at . As an example, choose a point and let be the step function that returns the value 1 for all less than , and returns a different value 10 for all greater than or equal to . cannot have a derivative at . If is negative, then is on the low part of the step, so the secant line from to is very steep, and as tends to zero the slope tends to infinity. If is positive, then is on the high part of the step, so the secant line from to has slope zero. Consequently, the secant lines do not approach any single slope, so the limit of the difference quotient does not exist.

However, even if a function is continuous at a point, it may not be differentiable there. For example, the absolute value function is continuous at , but it is not differentiable there. If is positive, then the slope of the secant line from 0 to is one, whereas if is negative, then the slope of the secant line from 0 to is negative one. This can be seen graphically as a "kink" or a "cusp" in the graph at . Even a function with a smooth graph is not differentiable at a point where its tangent is vertical: For instance, the function is not differentiable at .

In summary: for a function to have a derivative it is "necessary" for the function to be continuous, but continuity alone is not "sufficient".

Most functions that occur in practice have derivatives at all points or at almost every point. Early in the history of calculus, many mathematicians assumed that a continuous function was differentiable at most points. Under mild conditions, for example if the function is a monotone function or a Lipschitz function, this is true. However, in 1872 Weierstrass found the first example of a function that is continuous everywhere but differentiable nowhere. This example is now known as the Weierstrass function. In 1931, Stefan Banach proved that the set of functions that have a derivative at some point is a meager set in the space of all continuous functions. Informally, this means that hardly any continuous functions have a derivative at even one point.

Let be a function that has a derivative at every point in the domain of . Because every point has a derivative, there is a function that sends the point to the derivative of at . This function is written and is called the "derivative function" or the "derivative" of . The derivative of collects all the derivatives of at all the points in the domain of .

Sometimes has a derivative at most, but not all, points of its domain. The function whose value at equals whenever is defined and elsewhere is undefined is also called the derivative of . It is still a function, but its domain is strictly smaller than the domain of .

Using this idea, differentiation becomes a function of functions: The derivative is an operator whose domain is the set of all functions that have derivatives at every point of their domain and whose range is a set of functions. If we denote this operator by , then is the function . Since is a function, it can be evaluated at a point . By the definition of the derivative function, .

For comparison, consider the doubling function ; is a real-valued function of a real number, meaning that it takes numbers as inputs and has numbers as outputs:
The operator , however, is not defined on individual numbers. It is only defined on functions:
Because the output of is a function, the output of can be evaluated at a point. For instance, when is applied to the squaring function, , outputs the doubling function , which we named . This output function can then be evaluated to get , , and so on.

Let be a differentiable function, and let be its derivative. The derivative of (if it has one) is written and is called the "second derivative of ". Similarly, the derivative of a second derivative, if it exists, is written and is called the "third derivative of ". Continuing this process, one can define, if it exists, the th derivative as the derivative of the th derivative. These repeated derivatives are called "higher-order derivatives". The th derivative is also called the derivative of order .

If represents the position of an object at time , then the higher-order derivatives of have physical interpretations. The second derivative of is the derivative of , the velocity, and by definition this is the object's acceleration. The third derivative of is defined to be the jerk, and the fourth derivative is defined to be the jounce.

A function need not have a derivative, for example, if it is not continuous. Similarly, even if does have a derivative, it may not have a second derivative. For example, let
Calculation shows that is a differentiable function whose derivative is

On the real line, every polynomial function is infinitely differentiable. By standard differentiation rules, if a polynomial of degree is differentiated times, then it becomes a constant function. All of its subsequent derivatives are identically zero. In particular, they exist, so polynomials are smooth functions.

The derivatives of a function at a point provide polynomial approximations to that function near . For example, if is twice differentiable, then
in the sense that
If is infinitely differentiable, then this is the beginning of the Taylor series for evaluated at around .

A point where the second derivative of a function changes sign is called an "inflection point". At an inflection point, the second derivative may be zero, as in the case of the inflection point of the function , or it may fail to exist, as in the case of the inflection point of the function . At an inflection point, a function switches from being a convex function to being a concave function or vice versa.

The symbols "dx", "dy", and "dx"/"dy" were introduced by Gottfried Wilhelm Leibniz in 1675. It is still commonly used when the equation is viewed as a functional relationship between dependent and independent variables. Then the first derivative is denoted by

and was once thought of as an infinitesimal quotient. Higher derivatives are expressed using the notation

for the "n"th derivative of (with respect to "x"). These are abbreviations for multiple applications of the derivative operator. For example,

With Leibniz's notation, we can write the derivative of "y" at the point in two different ways:

Leibniz's notation allows one to specify the variable for differentiation (in the denominator). This is especially relevant for partial differentiation. It also makes the chain rule easy to remember:

Sometimes referred to as "prime notation", one of the most common modern notation for differentiation is due to Joseph-Louis Lagrange and uses the prime mark, so that the derivative of a function "f"("x") is denoted "f"("x") or simply "f". Similarly, the second and third derivatives are denoted
To denote the number of derivatives beyond this point, some authors use Roman numerals in superscript, whereas others place the number in parentheses:
The latter notation generalizes to yield the notation "f" for the "n"th derivative of "f" – this notation is most useful when we wish to talk about the derivative as being a function itself, as in this case the Leibniz notation can become cumbersome.

Newton's notation for differentiation, also called the dot notation, places a dot over the function name to represent a time derivative. If , then
denote, respectively, the first and second derivatives of "y" with respect to "t". This notation is used exclusively for derivatives with respect to time or arc length. It is very common in physics, differential equations, and differential geometry. While the notation becomes unmanageable for high-order derivatives, in practice only few derivatives are needed.

Euler's notation uses a differential operator "D", which is applied to a function "f" to give the first derivative "Df". The second derivative is denoted "D""f", and the "n"th derivative is denoted "D""f".

If is a dependent variable, then often the subscript "x" is attached to the "D" to clarify the independent variable "x".
Euler's notation is then written
although this subscript is often omitted when the variable "x" is understood, for instance when this is the only variable present in the expression.

Euler's notation is useful for stating and solving linear differential equations.

The derivative of a function can, in principle, be computed from the definition by considering the difference quotient, and computing its limit. In practice, once the derivatives of a few simple functions are known, the derivatives of other functions are more easily computed using "rules" for obtaining derivatives of more complicated functions from simpler ones.

Most derivative computations eventually require taking the derivative of some common functions. The following incomplete list gives some of the most frequently used functions of a single real variable and their derivatives.


where "r" is any real number, then

wherever this function is defined. For example, if formula_35, then

and the derivative function is defined only for positive "x", not for . When , this rule implies that "f"′("x") is zero for , which is almost the constant rule (stated below).


In many cases, complicated limit calculations by direct application of Newton's difference quotient can be avoided using differentiation rules. Some of the most basic rules are the following.


The derivative of

is

Here the second term was computed using the chain rule and third using the product rule. The known derivatives of the elementary functions "x", "x", sin("x"), ln("x") and , as well as the constant 7, were also used.

A vector-valued function y("t") of a real variable sends real numbers to vectors in some vector space R. A vector-valued function can be split up into its coordinate functions "y"("t"), "y"("t"), …, "y"("t"), meaning that . This includes, for example, parametric curves in R or R. The coordinate functions are real valued functions, so the above definition of derivative applies to them. The derivative of y("t") is defined to be the vector, called the tangent vector, whose coordinates are the derivatives of the coordinate functions. That is,

Equivalently,

if the limit exists. The subtraction in the numerator is the subtraction of vectors, not scalars. If the derivative of y exists for every value of "t", then y′ is another vector-valued function.

If e, …, e is the standard basis for R, then y("t") can also be written as . If we assume that the derivative of a vector-valued function retains the linearity property, then the derivative of y("t") must be
because each of the basis vectors is a constant.

This generalization is useful, for example, if y("t") is the position vector of a particle at time "t"; then the derivative y′("t") is the velocity vector of the particle at time "t".

Suppose that "f" is a function that depends on more than one variable—for instance,
"f" can be reinterpreted as a family of functions of one variable indexed by the other variables:
In other words, every value of "x" chooses a function, denoted "f", which is a function of one real number. That is,
Once a value of "x" is chosen, say "a", then determines a function "f" that sends "y" to :
In this expression, "a" is a "constant", not a "variable", so "f" is a function of only one real variable. Consequently, the definition of the derivative for a function of one variable applies:
The above procedure can be performed for any choice of "a". Assembling the derivatives together into a function gives a function that describes the variation of "f" in the "y" direction:
This is the partial derivative of "f" with respect to "y". Here ∂ is a rounded "d" called the partial derivative symbol. To distinguish it from the letter "d", ∂ is sometimes pronounced "der", "del", or "partial" instead of "dee".

In general, the partial derivative of a function in the direction "x" at the point ("a" …, "a") is defined to be:
In the above difference quotient, all the variables except "x" are held fixed. That choice of fixed values determines a function of one variable
and, by definition,
In other words, the different choices of "a" index a family of one-variable functions just as in the example above. This expression also shows that the computation of partial derivatives reduces to the computation of one-variable derivatives.

An important example of a function of several variables is the case of a scalar-valued function on a domain in Euclidean space R (e.g., on R or R). In this case "f" has a partial derivative ∂"f"/∂"x" with respect to each variable "x". At the point "a", these partial derivatives define the vector
This vector is called the gradient of "f" at "a". If "f" is differentiable at every point in some domain, then the gradient is a vector-valued function ∇"f" that takes the point "a" to the vector ∇"f"("a"). Consequently, the gradient determines a vector field.

If "f" is a real-valued function on R, then the partial derivatives of "f" measure its variation in the direction of the coordinate axes. For example, if "f" is a function of "x" and "y", then its partial derivatives measure the variation in "f" in the "x" direction and the "y" direction. They do not, however, directly measure the variation of "f" in any other direction, such as along the diagonal line . These are measured using directional derivatives. Choose a vector
The directional derivative of "f" in the direction of v at the point x is the limit
In some cases it may be easier to compute or estimate the directional derivative after changing the length of the vector. Often this is done to turn the problem into the computation of a directional derivative in the direction of a unit vector. To see how this works, suppose that . Substitute into the difference quotient. The difference quotient becomes:
This is λ times the difference quotient for the directional derivative of "f" with respect to u. Furthermore, taking the limit as "h" tends to zero is the same as taking the limit as "k" tends to zero because "h" and "k" are multiples of each other. Therefore, . Because of this rescaling property, directional derivatives are frequently considered only for unit vectors.

If all the partial derivatives of "f" exist and are continuous at x, then they determine the directional derivative of "f" in the direction v by the formula:
This is a consequence of the definition of the total derivative. It follows that the directional derivative is linear in v, meaning that .

The same definition also works when "f" is a function with values in R. The above definition is applied to each component of the vectors. In this case, the directional derivative is a vector in R.

When "f" is a function from an open subset of R to R, then the directional derivative of "f" in a chosen direction is the best linear approximation to "f" at that point and in that direction. But when , no single directional derivative can give a complete picture of the behavior of "f". The total derivative gives a complete picture by considering all directions at once. That is, for any vector v starting at a, the linear approximation formula holds:
Just like the single-variable derivative, is chosen so that the error in this approximation is as small as possible.

If "n" and "m" are both one, then the derivative is a number and the expression is the product of two numbers. But in higher dimensions, it is impossible for to be a number. If it were a number, then would be a vector in R while the other terms would be vectors in R, and therefore the formula would not make sense. For the linear approximation formula to make sense, must be a function that sends vectors in R to vectors in R, and must denote this function evaluated at v.

To determine what kind of function it is, notice that the linear approximation formula can be rewritten as
Notice that if we choose another vector w, then this approximate equation determines another approximate equation by substituting w for v. It determines a third approximate equation by substituting both w for v and for a. By subtracting these two new equations, we get
If we assume that v is small and that the derivative varies continuously in a, then is approximately equal to , and therefore the right-hand side is approximately zero. The left-hand side can be rewritten in a different way using the linear approximation formula with substituted for v. The linear approximation formula implies:
This suggests that is a linear transformation from the vector space R to the vector space R. In fact, it is possible to make this a precise derivation by measuring the error in the approximations. Assume that the error in these linear approximation formula is bounded by a constant times ||v||, where the constant is independent of v but depends continuously on a. Then, after adding an appropriate error term, all of the above approximate equalities can be rephrased as inequalities. In particular, is a linear transformation up to a small error term. In the limit as v and w tend to zero, it must therefore be a linear transformation. Since we define the total derivative by taking a limit as v goes to zero, must be a linear transformation.

In one variable, the fact that the derivative is the best linear approximation is expressed by the fact that it is the limit of difference quotients. However, the usual difference quotient does not make sense in higher dimensions because it is not usually possible to divide vectors. In particular, the numerator and denominator of the difference quotient are not even in the same vector space: The numerator lies in the codomain R while the denominator lies in the domain R. Furthermore, the derivative is a linear transformation, a different type of object from both the numerator and denominator. To make precise the idea that is the best linear approximation, it is necessary to adapt a different formula for the one-variable derivative in which these problems disappear. If , then the usual definition of the derivative may be manipulated to show that the derivative of "f" at "a" is the unique number such that
This is equivalent to
because the limit of a function tends to zero if and only if the limit of the absolute value of the function tends to zero. This last formula can be adapted to the many-variable situation by replacing the absolute values with norms.

The definition of the total derivative of "f" at a, therefore, is that it is the unique linear transformation such that
Here h is a vector in R, so the norm in the denominator is the standard length on R. However, "f"′(a)h is a vector in R, and the norm in the numerator is the standard length on R. If "v" is a vector starting at "a", then is called the pushforward of v by "f" and is sometimes written .

If the total derivative exists at a, then all the partial derivatives and directional derivatives of "f" exist at a, and for all v, is the directional derivative of "f" in the direction v. If we write "f" using coordinate functions, so that , then the total derivative can be expressed using the partial derivatives as a matrix. This matrix is called the Jacobian matrix of "f" at a:

The existence of the total derivative "f"′(a) is strictly stronger than the existence of all the partial derivatives, but if the partial derivatives exist and are continuous, then the total derivative exists, is given by the Jacobian, and depends continuously on a.

The definition of the total derivative subsumes the definition of the derivative in one variable. That is, if "f" is a real-valued function of a real variable, then the total derivative exists if and only if the usual derivative exists. The Jacobian matrix reduces to a 1×1 matrix whose only entry is the derivative "f"′("x"). This 1×1 matrix satisfies the property that is approximately zero, in other words that

Up to changing variables, this is the statement that the function formula_87 is the best linear approximation to "f" at "a".

The total derivative of a function does not give another function in the same way as the one-variable case. This is because the total derivative of a multivariable function has to record much more information than the derivative of a single-variable function. Instead, the total derivative gives a function from the tangent bundle of the source to the tangent bundle of the target.

The natural analog of second, third, and higher-order total derivatives is not a linear transformation, is not a function on the tangent bundle, and is not built by repeatedly taking the total derivative. The analog of a higher-order derivative, called a jet, cannot be a linear transformation because higher-order derivatives reflect subtle geometric information, such as concavity, which cannot be described in terms of linear data such as vectors. It cannot be a function on the tangent bundle because the tangent bundle only has room for the base space and the directional derivatives. Because jets capture higher-order information, they take as arguments additional coordinates representing higher-order changes in direction. The space determined by these additional coordinates is called the jet bundle. The relation between the total derivative and the partial derivatives of a function is paralleled in the relation between the "k"th order jet of a function and its partial derivatives of order less than or equal to "k".

By repeatedly taking the total derivative, one obtains higher versions of the Fréchet derivative, specialized to R. The "k"th order total derivative may be interpreted as a map
which takes a point x in R and assigns to it an element of the space of "k"-linear maps from R to R – the "best" (in a certain precise sense) "k"-linear approximation to "f" at that point. By precomposing it with the diagonal map Δ, , a generalized Taylor series may be begun as
where f(a) is identified with a constant function, are the components of the vector , and and are the components of and as linear transformations.

The concept of a derivative can be extended to many other settings. The common thread is that the derivative of a function at a point serves as a linear approximation of the function at that point.

Calculus, known in its early history as "infinitesimal calculus", is a mathematical discipline focused on limits, functions, derivatives, integrals, and infinite series. Isaac Newton and Gottfried Leibniz independently discovered calculus in the mid-17th century. However, each inventor claimed the other stole his work in a bitter dispute that continued until the end of their lives.






</doc>
<doc id="7922" url="https://en.wikipedia.org/wiki?curid=7922" title="Dravidian languages">
Dravidian languages

The Dravidian languages are a language family spoken mainly in southern India and parts of eastern and central India, as well as in Sri Lanka with small pockets in southwestern Pakistan, southern Afghanistan, Nepal, Bangladesh and Bhutan, and overseas in other countries such as Malaysia, Indonesia and Singapore. The Dravidian languages with the most speakers are Telugu, Tamil, Kannada and Malayalam. There are also small groups of Dravidian-speaking scheduled tribes, who live outside Dravidian-speaking areas, such as the Kurukh in Eastern India and Gondi in Central India.

Though some scholars have argued that the Dravidian languages may have been brought to India by migrations in the fourth or third millennium BCE or even earlier, the Dravidian languages cannot easily be connected to any other language family, and they could well be indigenous to India.

Epigraphically the Dravidian languages have been attested since the 2nd century BCE as Tamil-Brahmi script on the cave walls discovered in the Madurai and Tirunelveli districts of Tamil Nadu. Only two Dravidian languages are spoken exclusively outside the post-1947 state of India: Brahui in Pakistan's, and to a lesser extent, Afghanistan's Balochistan region, and Dhangar, a dialect of Kurukh, in parts of Nepal and Bhutan. Dravidian place names along the Arabian Sea coasts and Dravidian grammatical influence such as clusivity in the Indo-Aryan languages, namely Marathi, Konkani, Gujarati, Marwari, and Sindhi, suggest that Dravidian languages were once spoken more widely across the Indian subcontinent.

The 15th or 16th century Sanskrit text "Lilatilakam", which is a grammar of Manipravalam, states that the spoken languages of present-day Kerala and Tamil Nadu were similar, terming them as "Dramiḍa". The author doesn't consider the "Karṇṇāṭa" (Kannada) and the "Andhra" (Telugu) languages as "Dramiḍa", because they were very different from the language of the "Tamil Veda" ("Tiruvaymoli"), but states that some people would include them in the "Dramiḍa" category.

In 1816, Alexander D. Campbell suggested the existence of a Dravidian language family in his "Grammar of the Teloogoo Language", in which he and Francis W. Ellis argued that Tamil and Telugu descended from a common, non-Indo-European ancestor. In 1856 Robert Caldwell published his "Comparative Grammar of the Dravidian or South-Indian Family of Languages", which considerably expanded the Dravidian umbrella and established Dravidian as one of the major language groups of the world. Caldwell coined the term "Dravidian" for this family of languages, based on the usage of the Sanskrit word द्रविदा (Dravidā) in the work "Tantravārttika" by . In his own words, Caldwell says,

As for the origin of the Sanskrit word ' itself, researchers have proposed various theories. Basically the theories deal with the direction of derivation between ' and '. There is no definite philological and linguistic basis for asserting unilaterally that the name "Dravida" also forms the origin of the word "Tamil" (Dravida → Dramila → Tamizha or Tamil). Kamil Zvelebil cites the forms such as "dramila" (in 's Sanskrit work "Avanisundarīkathā") ' (found in the Sri Lankan (Ceylonese) chronicle "Mahavamsa") and then goes on to say, "The forms "damiḷa"/"damila" almost certainly provide a connection of ' " and "... ' < ' ...whereby the further development might have been *' > *' > '- / "damila"- and further, with the intrusive, 'hypercorrect' (or perhaps analogical) -"r"-, into "". The -"m"-/-"v"- alternation is a common enough phenomenon in Dravidian phonology"
Zvelebil in his earlier treatise states, "It is obvious that the Sanskrit ', Pali "damila", ' and Prakrit ' are all etymologically connected with '", and further remarks, "The "r" in ' → ' is a hypercorrect insertion, cf. an analogical case of DED 1033 Ta. "kamuku", Tu. "kangu" "areca nut": Skt. "kramu(ka)"."

Furthermore, another Dravidianist and linguist, Bhadriraju Krishnamurti, in his book "Dravidian Languages" states: 

Based on what Krishnamurti states (referring to a scholarly paper published in the "International Journal of Dravidian Linguistics"), the Sanskrit word ' itself is later than ' since the dates for the forms with -r- are centuries later than the dates for the forms without -r- (', '-, "damela"- etc.). The "Monier-Williams Sanskrit Dictionary" lists for the Sanskrit word "draviḍa" a meaning of "collective Name for 5 peoples, viz. the Āndhras, Karṇāṭakas, Gurjaras, Tailaṅgas, and Mahārāṣṭras".

The Dravidian languages form a close-knit family. Most scholars agree on four groups: South (or South DravidianI), South-Central (or South DravidianII), Central, and North Dravidian, but there are different proposals regarding the relationship between these groups. Earlier classifications grouped Central and South-Central Dravidian in a single branch. Krishnamurti groups South-Central and South Dravidian. Languages recognized as official languages of India appear here in boldface.

Some authors deny that North Dravidian forms a valid subgroup, splitting it into Northeast (Kurukh–Malto) and Northwest (Brahui). Their affiliation has been proposed primarily based on a small number of common phonetic developments, including:
McAlpin (2003) notes that no exact conditioning can be established for the first two changes, and proposes that distinct Proto-Dravidian *q and *kʲ should be reconstructed behind these correspondences, and that Brahui, Kurukh-Malto, and the rest of Dravidian may be three coordinate branches, possibly with Brahui being the earliest language to split off. A few morphological parallels between Brahui and Kurukh-Malto are also known, but according to McAlpin they are analyzable as shared archaisms rather than shared innovations.

In addition, "Ethnologue" lists several unclassified Dravidian languages: Allar, Bazigar, Bharia, Malankuravan (possibly a dialect of Malayalam), and Vishavan. "Ethnologue" also lists several unclassified Southern Dravidian languages: Mala Malasar, Malasar, Thachanadan, Ullatan, Kalanadi, Kumbaran, Kunduvadi, Kurichiya, Attapady Kurumba, Muduga, Pathiya, and Wayanad Chetti.

A computational phylogenetic study of the Dravidian language family was undertaken by Kolipakam, et al. (2018).

Since 1981, the Census of India has reported only languages with more than 10,000 speakers, including 17 Dravidian languages. In 1981, these accounted for approximately 24% of India's population.
In the 2001 census, they included 214 million people, about 21% of India's total population of 1.02 billion. In addition, the largest Dravidian-speaking group outside India, Tamil speakers in Sri Lanka, number around 4.7 million. The total number of speakers of Dravidian languages is around 227 million people, around 13% of the population of the Indian subcontinent.

Telugu is the most spoken Dravidian language, with over 74 million native speakers. The total number of speakers of Telugu, including those whose first language is not Telugu, is around 84 million people, which is around 6% of India's total population.

The smallest branch of the Dravidian languages is the Central branch, which has only around 200,000 speakers. These languages are mostly tribal, and spoken in central India.

The second-smallest branch is the Northern branch, with around 6.3 million speakers. This is the only sub-group to have a language spoken in Pakistan — Brahui.

The next-largest is the South-Central branch, which has 78 million native speakers, the vast majority of whom speak Telugu. This branch also includes the tribal language Gondi spoken in central India.

The largest group is South Dravidian, with almost 150 million speakers. Tamil, Malayalam, and Kannada make up around 98% of the speakers, with Tamil being by far the most spoken language, with almost half of all South Dravidian speakers speaking it. 

The Dravidian family has defied all of the attempts to show a connection with other languages, including Indo-European, Hurrian, Basque, Sumerian, Korean and Japanese. Comparisons have been made not just with the other language families of the Indian subcontinent (Indo-European, Austroasiatic, Sino-Tibetan, and Nihali), but with all typologically similar language families of the Old World. Nonetheless, although there are no readily detectable genealogical connections, Dravidian shares strong areal features with the Indo-Aryan languages, which have been attributed to a substratum influence from Dravidian.

Dravidian languages display typological similarities with the Uralic language group, suggesting to some a prolonged period of contact in the past. This idea is popular amongst Dravidian linguists and has been supported by a number of scholars, including Robert Caldwell, Thomas Burrow, Kamil Zvelebil, and Mikhail Andronov. This hyphothesis has, however, been rejected by some specialists in Uralic languages, and has in recent times also been criticised by other Dravidian linguists such as Bhadriraju Krishnamurti.

In the early 1970s, the linguist David McAlpin produced a detailed proposal of a genetic relationship between Dravidian and the extinct Elamite language of ancient Elam (present-day southwestern Iran). The Elamo-Dravidian hypothesis was supported in the late 1980s by the archaeologist Colin Renfrew and the geneticist Luigi Luca Cavalli-Sforza, who suggested that Proto-Dravidian was brought to India by farmers from the Iranian part of the Fertile Crescent. (In his 2000 book, Cavalli-Sforza suggested western India, northern India and northern Iran as alternative starting points.) However, linguists have found McAlpin's cognates unconvincing and criticized his proposed phonological rules as "ad hoc". Elamite is generally believed by scholars to be a language isolate, and the theory has had no effect on studies of the language.

Dravidian is one of the primary language families in the Nostratic proposal, which would link most languages in North Africa, Europe and Western Asia into a family with its origins in the Fertile Crescent sometime between the last Ice Age and the emergence of Proto-Indo-European 4,000–6,000 BCE. However, the general consensus is that such deep connections are not, or not yet, demonstrable.

The origins of the Dravidian languages, as well as their subsequent development and the period of their differentiation are unclear, partially due to the lack of comparative linguistic research into the Dravidian languages. Though some scholars have argued that the Dravidian languages may have been brought to India by migrations in the fourth or third millennium BCE or even earlier, the Dravidian languages cannot easily be connected to any other language, and they could well be indigenous to India. The Dravidian language was the most widespread indigenous language before the advance of the Indo-Aryan languages.

As a proto-language, the Proto-Dravidian language is not itself attested in the historical record. Its modern conception is based solely on reconstruction. It is suggested that the language was spoken in the 4th millennium BCE, and started disintegrating into various branches around 3rd millennium BCE. According to Krishnamurti, Proto-Dravidian may have been spoken in the Indus civilization, suggesting a "tentative date of Proto-Dravidian around the early part of the third millennium." Krishnamurti further states that South Dravidian I (including pre-Tamil) and South Dravidian II (including Pre-Telugu) split around the eleventh century BCE, with the other major branches splitting off at around the same time.

The Indus Valley civilisation (3,300-1,900 BCE), located in Northwestern Indian subcontinent, is often understood to have been Dravidian. Cultural and linguistic similarities have been cited by researchers Henry Heras, Kamil Zvelebil, Asko Parpola and Iravatham Mahadevan as being strong evidence for a proto-Dravidian origin of the ancient Indus Valley civilisation. The discovery in Tamil Nadu of a late Neolithic (early 2nd millennium BCE, i.e. post-dating Harappan decline) stone celt allegedly marked with Indus signs has been considered by some to be significant for the Dravidian identification.

Yuri Knorozov surmised that the symbols represent a logosyllabic script and suggested, based on computer analysis, an underlying agglutinative Dravidian language as the most likely candidate for the underlying language. Knorozov's suggestion was preceded by the work of Henry Heras, who suggested several readings of signs based on a proto-Dravidian assumption.

Linguist Asko Parpola writes that the Indus script and Harappan language are "most likely to have belonged to the Dravidian family". Parpola led a Finnish team in investigating the inscriptions using computer analysis. Based on a proto-Dravidian assumption, they proposed readings of many signs, some agreeing with the suggested readings of Heras and Knorozov (such as equating the "fish" sign with the Dravidian word for fish, "min") but disagreeing on several other readings. A comprehensive description of Parpola's work until 1994 is given in his book "Deciphering the Indus Script".

Although in modern times speakers of the various Dravidian languages have mainly occupied the southern portion of India, in earlier times they probably were spoken in a larger area. After the Indo-Aryan migrations into north-western India, starting ca. 1500 BCE, and the establishment of the Kuru kingdom ca. 1100 BCE, a process of Sanskritisation started, which resulted in a language shift in northern India. Southern India has remained majority Dravidian, but pockets of Dravidian can be found in central India, Pakistan, Bangladesh and Nepal.

The Kurukh and Malto are pockets of Dravidian languages in central India, spoken by people who may have migrated from south India. They do have myths about external origins. The Kurukh have traditionally claimed to be from the Deccan Peninsula, more specifically Karnataka. The same tradition has existed of the Brahui, who call themselves immigrants. Holding this same view of the Brahui are many scholars such as L.H. Horace Perera and M.Ratnasabapathy.

The Brahui population of Pakistan's Balochistan province has been taken by some as the linguistic equivalent of a relict population, perhaps indicating that Dravidian languages were formerly much more widespread and were supplanted by the incoming Indo-Aryan languages. However, it has been argued that the absence of any Old Iranian (Avestan) loanwords in Brahui suggests that the Brahui migrated to Balochistan from central India less than 1,000 years ago. The main Iranian contributor to Brahui vocabulary, Balochi, is a western Iranian language like Kurdish, and arrived in the area from the west only around 1,000AD. Sound changes shared with Kurukh and Malto also suggest that Brahui was originally spoken near them in central India.

Dravidian languages show extensive lexical (vocabulary) borrowing, but only a few traits of structural (either phonological or grammatical) borrowing from Indo-Aryan, whereas Indo-Aryan shows more structural than lexical borrowings from the Dravidian languages. Many of these features are already present in the oldest known Indo-Aryan language, the language of the "Rigveda" (c.1500 BCE), which also includes over a dozen words borrowed from Dravidian.

Vedic Sanskrit has retroflex consonants (/, ) with about 88 words in the "Rigveda" having unconditioned retroflexes. Some sample words are ', ', ', ', ' and '.
Since other Indo-European languages, including other Indo-Iranian languages, lack retroflex consonants, their presence in Indo-Aryan is often cited as evidence of substrate influence from close contact of the Vedic speakers with speakers of a foreign language family rich in retroflex consonants. The Dravidian family is a serious candidate since it is rich in retroflex phonemes reconstructible back to the Proto-Dravidian stage.

In addition, a number of grammatical features of Vedic Sanskrit not found in its sister Avestan language appear to have been borrowed from Dravidian languages. These include the gerund, which has the same function as in Dravidian, and the quotative marker "iti". Some linguists explain this asymmetrical borrowing by arguing that Middle Indo-Aryan languages were built on a Dravidian substratum. These scholars argue that the most plausible explanation for the presence of Dravidian structural features in Indic is language shift, that is, native Dravidian speakers learning and adopting Indic languages. Although each of the innovative traits in Indic could be accounted for by internal explanations, early Dravidian influence is the only explanation that can account for all of the innovations at once; moreover, it accounts for several of the innovative traits in Indic better than any internal explanation that has been proposed.

The most characteristic grammatical features of Dravidian languages are:

Dravidian languages are noted for the lack of distinction between aspirated and unaspirated stops. While some Dravidian languages have accepted large numbers of loan words from Sanskrit and other Indo-Iranian languages in addition to their already vast vocabulary, in which the orthography shows distinctions in voice and aspiration, the words are pronounced in Dravidian according to different rules of phonology and phonotactics: aspiration of plosives is generally absent, regardless of the spelling of the word. This is not a universal phenomenon and is generally avoided in formal or careful speech, especially when reciting. For instance, Tamil does not distinguish between voiced and voiceless stops. In fact, the Tamil alphabet lacks symbols for voiced and aspirated stops. Dravidian languages are also characterized by a three-way distinction between dental, alveolar, and retroflex places of articulation as well as large numbers of liquids.

Proto-Dravidian had five short and long vowels: "*a", "*ā", "*i", "*ī", "*u", "*ū", "*e", "*ē", "*o", "*ō". There were no diphthongs; "ai" and "au" are treated as *"ay" and *"av" (or *"aw").
The five-vowel system is largely preserved in the descendent subgroups.

The following consonantal phonemes are reconstructed:

The numerals from 1 to 10 in various Dravidian and Indo-Aryan languages (here exemplified by Hindi, Sanskrit and Marathi).

Four Dravidian languages, Tamil, Kannada, Malayalam and Telugu, have lengthy literary traditions.
Literature in Tulu and Kodava is more recent.

The earliest known Dravidian inscriptions are 76 Old Tamil inscriptions on cave walls in Madurai and Tirunelveli districts in Tamil Nadu, dating from the 2nd century BCE.
These inscriptions are written in a variant of the Brahmi script called Tamil Brahmi.
The earliest long text in Old Tamil is the "Tolkāppiyam", an early work on Tamil grammar and poetics, whose oldest layers could date from the 1st century BCE.





</doc>
<doc id="7923" url="https://en.wikipedia.org/wiki?curid=7923" title="Dracula">
Dracula

Dracula is an 1897 Gothic horror novel by Irish author Bram Stoker. It introduced Count Dracula, and established many conventions of subsequent vampire fantasy. The novel tells the story of Dracula's attempt to move from Transylvania to England so that he may find new blood and spread the undead curse, and of the battle between Dracula and a small group of men and a woman led by Professor Abraham Van Helsing.

"Dracula" has been assigned to many literary genres including vampire literature, horror fiction, the gothic novel, and invasion literature. The novel has spawned numerous theatrical, film, and television interpretations.

The story is told in epistolary format, as a series of letters, diary entries, newspaper articles, and ships' log entries, whose narrators are the novel's protagonists, and occasionally supplemented with newspaper clippings relating events not directly witnessed. The events portrayed in the novel take place chronologically and largely in England and Transylvania during the 1890s and all transpire within the same year between 3 May and 6 November. A short note is located at the end of the final chapter written 7 years after the events outlined in the novel.

The tale begins with Jonathan Harker, a newly qualified English solicitor, visiting Count Dracula in the Carpathian Mountains on the border of Transylvania, Bukovina, and Moldavia, to provide legal support for a real estate transaction overseen by Harker's employer, Mr Peter Hawkins of Exeter. At first enticed by Dracula's gracious manners, Harker soon realizes that he is Dracula's prisoner. Wandering the Count's castle against Dracula's admonition, Harker encounters three female vampires, called "the sisters", from whom he is rescued by Dracula. Harker soon realizes that Dracula himself is also a vampire. After the preparations are made, Dracula leaves Transylvania and abandons Harker to the sisters. Harker barely escapes from the castle with his life.

Dracula boards a Russian ship, the "Demeter", taking along with him boxes of Transylvanian soil, which he required in order to regain his strength. Not long afterward, the ship having weighed anchor at Varna, runs aground on the shores of Whitby in the east coast of England. The captain's log narrates the gradual disappearance of the entire crew, until the captain alone remained, himself bound to the helm to maintain course. An animal resembling "a large dog" is seen leaping ashore. The ship's cargo is described as silver sand and 50 boxes of "mould", or earth, from Transylvania. It is later learned that Dracula successfully purchased multiple estates under the alias 'Count De Ville' throughout London and devised to distribute the 50 boxes to each of them utilizing transportation services as well as moving them himself. He does this to secure for himself "lairs" and the 50 boxes of earth would be used as his graves which would grant safety and rest during times of feeding and replenishing his strength.

Harker's fiancée, Mina Murray, is staying with her friend Lucy Westenra, who is holidaying in Whitby. Lucy receives three marriage proposals from Dr. John Seward, Quincey Morris, and Arthur Holmwood (the son of Lord Godalming who later obtains the title himself). Lucy accepts Holmwood's proposal while turning down Seward and Morris, but all remain friends. Dracula communicates with Seward's patient, Renfield, an insane man who wishes to consume insects, spiders, birds, and rats to absorb their "life force". Renfield is able to detect Dracula's presence and supplies clues accordingly.

Soon Dracula is indirectly shown to be stalking Lucy. As time passes she begins to suffer from episodes of sleepwalking and dementia, as witnessed by Mina. When Lucy begins to waste away suspiciously, Seward invites his old teacher, Abraham Van Helsing, who immediately determines the true cause of Lucy's condition. He refuses to disclose it but diagnoses her with acute blood-loss. Van Helsing prescribes numerous blood transfusions to which he, Seward, Quincey, and Arthur all contribute over time. Van Helsing also prescribes garlic flowers to be placed throughout her room and weaves a necklace of withered garlic blossoms for her to wear. However she continues to waste away – appearing to lose blood every night. While both doctors are absent, Lucy and her mother are attacked by a wolf and Mrs. Westenra, who has a heart condition, dies of fright. Van Helsing attempts to protect her with garlic but fate thwarts him each night, whether Lucy's mother removes the garlic from her room, or Lucy herself does so in her restless sleep. The doctors have found two small puncture marks about her neck, which Dr. Seward is at a loss to understand. After Lucy dies, Van Helsing places a golden crucifix over her mouth, ostensibly to delay or prevent Lucy's vampiric conversion. Fate conspires against him again when Van Helsing finds the crucifix in the possession of one of the servants who stole it off Lucy's corpse.

Following Lucy's death and burial, the newspapers report children being stalked in the night by a "bloofer lady" (i.e., "beautiful lady"). Van Helsing, knowing Lucy has become a vampire, confides in Seward, Lord Godalming, and Morris. The suitors and Van Helsing track her down and, after a confrontation with her, stake her heart, behead her, and fill her mouth with garlic. Around the same time, Jonathan Harker arrives from Budapest, where Mina marries him after his escape, and he and Mina join the campaign against Dracula.

The vampire hunters stay at Dr. Seward's residence, holding nightly meetings and providing reports based on each of their various tasks. Mina discovers that each of their journals and letters collectively contain clues to which they can track him down. She tasks herself with collecting them, researching newspaper clippings, fitting the most relevant entries into chronological order and typing out copies to distribute to each of the party which they are to study. Jonathan Harker tracks down the shipments of boxed graves and the estates which Dracula has purchased in order to store them. Van Helsing conducts research along with Dr. Seward to analyze the behaviour of their patient Renfield who they learn is directly influenced by Dracula. They also research historical events, folklore, and superstitions from various cultures to understand Dracula's powers and weaknesses. Van Helsing also establishes a criminal profile on Dracula in order to better understand his actions and predict his movements. Arthur Holmwood's fortune assists in funding the entire operation and expenses. As they discover the various properties Dracula had purchased, the male protagonists team up to raid each property and are several times confronted by Dracula. As they discover each of the boxed graves scattered throughout London, they pry them open to place and seal wafers of sacramental bread within. This act renders the boxes of earth completely useless to Dracula as he is unable to open, enter or further transport them.

After Dracula learns of the group's plot against him, he attacks Mina on three occasions, and feeds Mina his own blood to control her. This curses Mina with vampirism and changes her but does not completely turn her into a vampire. Van Helsing attempts to bless Mina through prayer and by placing a wafer of sacrament against her forehead, but it burns her upon contact leaving a wretched scar. Under this curse, Mina oscillates from consciousness to a semi-trance during which she perceives Dracula's surroundings and actions. Van Helsing is able to use hypnotism twice a day, at dawn and at sunset, to put her into this trance to further track Dracula's movements. Mina, afraid of Dracula's link with her, urges the team not to tell her their plans out of fear that Dracula will be listening. After the protagonists discover and sterilize 49 boxes found throughout his lairs in London, they learn that Dracula has fled with the missing 50th box back to his castle in Transylvania. They pursue him under the guidance of Mina. They split up into teams once they reach Europe; Van Helsing and Mina team up to locate the castle of Dracula while the others attempt to ambush the boat Dracula is using to reach his home. Van Helsing raids the castle and destroys the vampire "sisters". Upon discovering Dracula being transported by Gypsies, the three teams converge and attack the caravan carrying Dracula in the 50th box of Earth. After dispatching many Gypsies who were sworn to protect the Count, Harker shears Dracula through the throat with a kukri knife, while the mortally wounded Quincey stabs the Count in the heart with a Bowie knife. Dracula crumbles to dust, and Mina is freed from her curse of vampirism, as the scar on her forehead disappears. Soon after, Quincey dies from his wounds.

The book closes with a note left by Jonathan Harker seven years after the events of the novel, detailing his married life with Mina and the birth of their son, whom they name after all four members of the party, but address as "Quincey". Quincey is depicted sitting on the knee of Van Helsing as they recount their adventure. Seward and Arthur have each gotten married.

A small section was removed from a draft of the final chapter, in which Dracula's castle falls apart as he dies, hiding the fact that vampires were ever there.

Between 1879 and 1898, Stoker was a business manager for the Lyceum Theatre in London, where he supplemented his income by writing a large number of sensational novels, his most successful being the vampire tale "Dracula" published on 26 May 1897. Parts of it are set around the town of Whitby, where he spent summer holidays.

Throughout the 1880s and 1890s, authors such as H. Rider Haggard, Rudyard Kipling, Robert Louis Stevenson, Arthur Conan Doyle, and H. G. Wells wrote many tales in which fantastic creatures threatened the British Empire. Invasion literature was at a peak, and Stoker's formula was very familiar by 1897 to readers of fantastic adventure stories, of an invasion of England by continental European influences. Victorian readers enjoyed "Dracula" as a good adventure story like many others, but it did not reach its legendary status until later in the 20th century when film versions began to appear.

Before writing "Dracula", Stoker spent seven years researching European folklore and stories of vampires, being most influenced by Emily Gerard's 1885 essay "Transylvania Superstitions" which includes content about a vampire myth. Some historians are convinced that a historic figure, Vlad III Dracula, often called Vlad the Impaler, was the model for Stoker's Count although there is no supporting evidence. Stoker borrowed only "scraps of miscellaneous information", according to one expert, about this bloodthirsty tyrant of Wallachia and there are no comments about him in Stoker's working notes. Dracula scholar Elizabeth Miller has remarked that aside from the name and some mention of Romanian history, the background of Stoker's Count bears no resemblance to that of Vlad III Dracula.

Later he also claimed that he had a nightmare, caused by eating too much crab meat, about a "vampire king" rising from his grave.

Although a widely known vampire novel, "Dracula" was not the first. Johann Wolfgang von Goethe published "The Bride of Corinth" in 1797. (“From my grave to wander I am forc’d Still to seek The God’s long-sever’d link, Still to love the bridegroom I have lost, And the life-blood of his heart to drink;) Later Sheridan Le Fanu's 1871 "Carmilla", about a lesbian vampire could have inspired Bram Stoker's Dracula, or "Varney the Vampire", a lengthy penny dreadful serial from the mid-Victorian period by James Malcolm Rymer. John Polidori created the image of a vampire portrayed as an aristocratic man, like the character of Dracula, in his tale "The Vampyre" (1819). (He wrote "Vampyre" during a summer which he spent with "Frankenstein" creator Mary Shelley, her husband poet Percy Bysshe Shelley, and Lord Byron in 1816.)

The Lyceum Theatre where Stoker worked between 1878 and 1898 was headed by actor-manager Henry Irving, who was Stoker's real-life inspiration for Dracula's mannerisms and who Stoker hoped would play Dracula in a stage version. Irving never did agree to do a stage version, but Dracula's dramatic sweeping gestures and gentlemanly mannerisms drew their living embodiment from Irving.

"The Dead Un-Dead" was one of Stoker's original titles for "Dracula", and the manuscript was entitled simply "The Un-Dead" up until a few weeks before publication. Stoker's notes for "Dracula" show that the name of the count was originally "Count Wampyr", but Stoker became intrigued by the name "Dracula" while doing research, after reading William Wilkinson's book "An Account of the Principalities of Wallachia and Moldavia with Political Observations Relative to Them" (London 1820), which he found in the Whitby Library and consulted a number of times during visits to Whitby in the 1890s. The name Dracula was the patronym ("Drăculea") of the descendants of Vlad II of Wallachia, who took the name "Dracul" after being invested in the Order of the Dragon in 1431. In the Old Romanian language, the word "dracul" (Romanian "drac" "dragon" + "-ul" "the") meant "the dragon" and Dracula meant "son of the dragon". In the present day however, dracul means "the devil".

"Dracula" was published in London in May 1897 by Archibald Constable and Company. Costing six shillings, the novel was bound yellow cloth and titled in red letters. It was copyrighted in the United States in 1899 with the publication by Doubleday & McClure of New York. But when Universal Studios purchased the rights, it came to light that Bram Stoker had not complied with a portion of US copyright law, placing the novel into the public domain. In the United Kingdom and other countries following the Berne Convention on copyrights, the novel was under copyright until April 1962, fifty years after Stoker's death.

"Dracula" was not an immediate bestseller when it was first published, although reviewers were unstinting in their praise. The contemporary "Daily Mail" ranked Stoker's powers above those of Mary Shelley and Edgar Allan Poe, as well as Emily Brontë's "Wuthering Heights".

According to literary historians Nina Auerbach and David J. Skal in the Norton Critical Edition, the novel has become more significant for modern readers than it was for Victorian readers, most of whom enjoyed it just as a good adventure story. It reached its broad and iconic status only later in the 20th century when the movie versions appeared. A. Asbjørn Jøn has also noted that "Dracula" has had a significant impact on the image of the vampire in popular culture, folklore, and legend.

It did not make much money for Stoker. In the last year of his life, he was so poor that he had to petition for a compassionate grant from the Royal Literary Fund, and his widow was forced to sell his notes and outlines of the novel at a Sotheby's auction in 1913, where they were purchased for a little over £2. But then F. W. Murnau's unauthorized adaptation of the story was released in theatres in 1922 in the form of "Nosferatu". Stoker's widow took affront and, during the legal battle that followed, the novel's popularity started to grow.

"Nosferatu" was followed by a highly successful stage adaptation, touring the UK for three years before arriving in the US where Stoker's creation caught Hollywood's attention and, after the American 1931 movie version was released, the book has never been out of print.

However, some Victorian fans were ahead of the time, describing it as "the sensation of the season" and "the most blood-curdling novel of the paralysed century". Sherlock Holmes author Sir Arthur Conan Doyle wrote to Stoker in a letter, "I write to tell you how very much I have enjoyed reading "Dracula". I think it is the very best story of diablerie which I have read for many years." The "Daily Mail" review of 1 June 1897 proclaimed it a classic of Gothic horror, "In seeking a parallel to this weird, powerful, and horrorful story our mind reverts to such tales as "The Mysteries of Udolpho", "Frankenstein", "The Fall of the House of Usher" ... but Dracula is even more appalling in its gloomy fascination than any one of these."

Similarly good reviews appeared when the book was published in the U.S. in 1899. The first American edition was published by Doubleday & McClure in New York.

In the last several decades, literary and cultural scholars have offered diverse analyses of Stoker's novel and the character of Count Dracula. C.F. Bentley reads Dracula as an embodiment of the Freudian id. Carol A. Senf reads the novel as a response to the powerful New Woman, while Christopher Craft sees Dracula as embodying latent homosexuality and sees the text as an example of a 'characteristic, if hyperbolic instance of Victorian anxiety over the potential fluidity of gender roles'. Stephen D. Arata interprets the events of the novel as anxiety over colonialism and racial mixing, and Talia Schaffer construes the novel as an indictment of Oscar Wilde. Franco Moretti reads Dracula as a figure of monopoly capitalism, though Hollis Robbins suggests that Dracula's inability to participate in social conventions and to forge business partnerships undermines his power. Richard Noll reads "Dracula" within the context of 19th century alienism (psychiatry) and asylum medicine. D. Bruno Starrs understands the novel to be a pro-Catholic pamphlet promoting proselytization.

"Dracula" is a work of fiction, but it does contain some historical references; although it is a matter of conjecture and debate as to how much historical connection was deliberate on Stoker's part.

Attention was drawn to the supposed connections between the historical Transylvanian-born Vlad III Dracula (also known as Vlad Tepes) of Wallachia and Bram Stoker's fictional Dracula, following the publication of "In Search of Dracula" by Radu Florescu and Raymond McNally in 1972.

During his main reign (1456–1462), "Vlad the Impaler" is said to have killed from 40,000 to 100,000 European civilians (political rivals, criminals, and anyone that he considered "useless to humanity"), mainly by impaling. The sources depicting these events are records by Saxon settlers in neighbouring Transylvania who had frequent clashes with Vlad III. Vlad III is revered as a folk hero by Romanians for driving off the invading Ottoman Turks, of whom his impaled victims are said to have included as many as 100,000. There is no solid evidence that the Count in the novel was modelled on Vlad the Impaler of Wallachia. At most, Stoker borrowed only the name Dracula and "scraps of miscellaneous information" about Romanian history, according to one expert, Elizabeth Miller; as well, and there are no comments about him in the author's working notes.

Historically, the name "Dracula" is derived from a Chivalric order called the Order of the Dragon, founded by Sigismund of Luxembourg (then king of Hungary) to uphold Christianity and defend the Empire against the Ottoman Turks. Vlad II Dracul, father of Vlad III, was admitted to the order around 1431, after which Vlad II wore the emblem of the order and later, as ruler of Wallachia, his coinage bore the dragon symbol, from which the name "Dracula" is derived since "dracul" in Romanian means "the dragon". People of Wallachia only knew "voievod" (king) Vlad III as Vlad Țepeș (the Impaler). The name "Dracula" became popular in Romania after publication of Stoker's book. Contrary to popular belief, the name Dracula does not translate to "son of the devil" in Romanian, which would be ""pui de drac"".

Stoker came across the name Dracula in his reading on Romanian history, and chose this to replace the name ("Count Wampyr") originally intended for his villain.Some Dracula scholars led by Elizabeth Miller argue that Stoker knew little of the historic Vlad III except for the name "Dracula" in addition to a few bits of Romanian history. Stoker mentions that his Dracula fought against the Turks and was later betrayed by his brother, historical facts in the novel which point to Vlad III:

The Count's identity is later speculated on by Professor Van Helsing:

Many of Stoker's biographers and literary critics have found strong similarities to the earlier Irish writer Sheridan Le Fanu's classic of the vampire genre "Carmilla". In writing "Dracula", Stoker may also have drawn on stories about the sídhe, some of which feature blood-drinking women. The Irish legend of Abhartach has also been suggested as a source.

In 1983, McNally additionally suggested that Stoker was influenced by the history of Hungarian Countess Elizabeth Bathory, who allegedly tortured and killed between 36 and 700 young women. It was later a commonly believed rumor that she committed these crimes to bathe in their blood, believing that this preserved her youth.

In her book "The Essential Dracula", Clare Haword-Maden suggested that the castle of Count Dracula was inspired by Slains Castle, at which Bram Stoker was a guest of the 19th Earl of Erroll. According to Miller, he first visited Cruden Bay in 1893, three years after work had begun on "Dracula". Haining and Tremaine maintain that, during this visit, Stoker was especially impressed by Slains Castle's interior and the surrounding landscape. Miller and Leatherdale question the stringency of this connection.

Possibly, Stoker was not inspired by a real edifice at all, but by Jules Verne's novel "The Carpathian Castle" (1892) or Anne Radcliffe's "The Mysteries of Udolpho" (1794). A third possibility is that he copied information about a castle at Vécs from one of his sources on Transylvania, the book by Major E.C. Johnson. A further option is that Stoker saw an illustration of Castle Bran (Törzburg) in the book on Transylvania by Charles Boner, or read about it in the books by Mazuchelli or Crosse.

Many of the scenes in Whitby and London are based on real places that Stoker frequently visited, although he distorts the geography for the sake of the story in some cases. One scholar has suggested that Stoker chose Whitby as the site of Dracula's first appearance in England because of the Synod of Whitby, given the novel's preoccupation with timekeeping and calendar disputes.

Daniel Farson, Leonard Wolf, and Peter Haining have suggested that Stoker received much historical information from Ármin Vámbéry, a Hungarian professor whom he met at least twice. Miller argues, "there is nothing to indicate that the conversation included Vlad, vampires, or even Transylvania", and "furthermore, there is no record of any other correspondence between Stoker and Vámbéry, nor is Vámbéry mentioned in Stoker's notes for Dracula."

The short story "Dracula's Guest" was posthumously published in 1914, two years after Stoker's death. It was, according to most contemporary critics, the deleted first (or second) chapter from the original manuscript and the one which gave the volume its name, but which the original publishers deemed unnecessary to the overall story.

"Dracula's Guest" follows an unnamed Englishman traveller as he wanders around Munich before leaving for Transylvania. It is Walpurgis Night and the young Englishman foolishly leaves his hotel, in spite of the coachman's warnings, and wanders through a dense forest alone. Along the way, he feels that he is being watched by a tall and thin stranger (possibly Count Dracula).

The short story climaxes in an old graveyard where the Englishman, caught in a blizzard, takes refuge in the marble tomb of "Countess Dolingen of Gratz". Within the tomb, he sees the Countess—apparently asleep and healthy—but before he can investigate further, a mysterious force throws him clear of the tomb. A lightning bolt then strikes the tomb, destroying it and incinerating the undead screaming countess. The Englishman then loses consciousness. He awakens to find a "gigantic" wolf lying on his chest and licking at his throat; however, the wolf merely keeps him warm and protects him until help arrives.

When the Englishman is finally taken back to his hotel, a telegram awaits him from his expectant host Dracula, with a warning about "dangers from snow and wolves and night".

In 2009, an official sequel was published, written by Bram Stoker's great grand-nephew Dacre Stoker and Ian Holt.

Dacre Stoker and J. D. Barker will write a prequel to "Dracula" titled "Dracul". An interpretation of the missing 101 pages of the original novel, it was pieced together from Bram Stoker's editorial notes, artifacts, and journals.

The story of "Dracula" has been the basis for numerous films and plays. Stoker himself wrote the first theatrical adaptation, which was presented at the Lyceum Theatre on 18 May 1897 under the title "Dracula, or The Undead" shortly before the novel's publication and performed only once, in order to establish his own copyright for such adaptations. This adaption was first published only a century later in October 1997. The first motion picture to feature Dracula was "Dracula's Death", produced in Hungary in 1921. The now-lost film, however, was not an adaptation of Stoker's novel, but featured an original story.

F. W. Murnau's unauthorised film adaptation "Nosferatu" was released in 1922, and the popularity of the novel increased considerably, owing to an attempt by Stoker's widow to have the film removed from public circulation. Prana Film, the production company, had been unable to obtain permission to adapt the story from Bram's widow Florence Stoker, so screenwriter Henrik Galeen was told to alter numerous details to avoid legal trouble. Galeen transplanted the action of the story from 1890s England to 1830s Germany and reworked several characters, dropping some (such as Lucy and all three of her suitors), and renaming others (Dracula became Orlok, Jonathan Harker became Thomas Hutter, Mina became Ellen, and so on). This attempt failed to avoid a court case, however; Florence Stoker sued Prana Film, and all copies of the film were ordered to be destroyed. However, the company was bankrupt, and Stoker only recovered her legal fees in damages. Some copies survived and found their way into theatres. Eventually, Florence Stoker gave up the fight against public displays of the film. Subsequent rereleases of the film have typically undone some of the changes, such as restoring the original character names (a practice also followed by Werner Herzog in his 1979 remake of Murnau's film "Nosferatu the Vampyre").

Florence Stoker licensed the story to playwright Hamilton Deane, whose 1924 stage play adaptation toured England for several years before settling down in London. In 1927, American stage producer Horace Liveright hired John L. Balderston to revise Deane's script in advance of its American premiere. Balderston significantly compressed the story, most notably consolidating or removing several characters. The Deane play and its Balderston revisions introduced an expanded role and history for Renfield, who now replaced Jonathan Harker as Dracula's solicitor in the first part of the story; combined Mina Harker and Lucy Westenra into a single character (named Lucy); and omitted both Arthur Holmwood and Quincey Morris entirely. When the play premiered in New York, it was with Bela Lugosi in the title role, and with Edward van Sloan as Abraham Van Helsing, roles which both actors (as well as Herbert Bunston as Dr. Seward) reprised for the English-language version of the 1931 Universal Studios film production. The 1931 film was one of the most commercially successful adaptations of the story to date; it and the Deane/Balderston play that preceded it set the standard for film and television adaptations of the story, with the alterations to the novel becoming standard for later adaptations for decades to come. Universal Studios continued to feature the character of Dracula in many of their horror films from the 1930s and 1940s.
In 1958, British film company Hammer Film Productions followed the success of its "The Curse of Frankenstein" from the previous year with "Dracula", released in the US as "The Horror of Dracula", directed by Terence Fisher. Fisher's production featured Christopher Lee as Dracula and Peter Cushing as Van Helsing. It was an international hit for Hammer Film, and Lee fixed the image of the fanged vampire in popular culture. Both Lee and Cushing reprised their roles multiple times over the next decade and a half, concluding with "The Legend of the 7 Golden Vampires" (with Cushing but not Lee) in 1974. Christopher Lee also took on the role of Dracula in "Count Dracula", a 1970 Spanish-Italian-German coproduction notable for its adherence to the plot of the original novel. Playing the part of Renfield in that version was Klaus Kinski, who later played Dracula himself in 1979's "Nosferatu the Vampyre".

In 1977, the BBC made "Count Dracula", a 155-minute adaptation for television starring Louis Jourdan. Later film adaptations include John Badham's 1979 "Dracula", starring Frank Langella and inspired by the 1977 Broadway revival of the Deane/Hamilton play, and Francis Ford Coppola's 1992 "Bram Stoker's Dracula", starring Gary Oldman. The character of Count Dracula has remained popular over the years, and many films have used the character as a villain, while others have named him in their titles, including "Dracula's Daughter" and "The Brides of Dracula". As of 2009, an estimated 217 films feature Dracula in a major role, a number second only to Sherlock Holmes (223 films). A large number of these appearances are not adaptations of Stoker's novel, but merely feature the character in an unrelated story.





</doc>
<doc id="7925" url="https://en.wikipedia.org/wiki?curid=7925" title="David Hume">
David Hume

David Hume (; born David Home; 7 May 1711 NS – 25 August 1776) was a Scottish philosopher, historian, economist, and essayist, who is best known today for his highly influential system of philosophical empiricism, skepticism, and naturalism. Hume's empiricist approach to philosophy places him with John Locke, Francis Bacon and Thomas Hobbes as a British Empiricist. Beginning with his "A Treatise of Human Nature" (1739), Hume strove to create a total naturalistic science of man that examined the psychological basis of human nature. Against philosophical rationalists, Hume held that passion rather than reason governs human behaviour. Hume argued against the existence of innate ideas, positing that all human knowledge is founded solely in experience; Hume thus held that genuine knowledge must either be directly traceable to objects perceived in experience, or result from abstract reasoning about relations between ideas which are derived from experience, calling the rest "nothing but sophistry and illusion", a dichotomy later given the name "Hume's fork".

In what is sometimes referred to as Hume's problem of induction, he argued that inductive reasoning and belief in causality cannot be justified rationally; instead, our trust in causality and induction result from custom and mental habit, and are attributable only to the experience of "constant conjunction" of events. This is because we can never actually perceive that one event causes another, but only that the two are always conjoined. Accordingly, to draw any causal inferences from past experience it is necessary to presuppose that the future will resemble the past, a presupposition which cannot itself be grounded in prior experience.

Hume's opposition to the teleological argument for God's existence, the argument from design, is generally regarded as the most intellectually significant attempt to rebut the argument prior to Darwinism.

Hume was also a sentimentalist who held that ethics are based on emotion or sentiment rather than abstract moral principle, famously proclaiming that "Reason is, and ought only to be the slave of the passions". Hume's moral theory has been seen as a unique attempt to synthesise the modern sentimentalist moral tradition to which Hume belonged, with the virtue ethics tradition of ancient philosophy, with which Hume concurred in regarding traits of character, rather than acts or their consequences, as ultimately the proper objects of moral evaluation. Hume maintained an early commitment to naturalistic explanations of moral phenomena, and is usually taken to have first clearly expounded the is–ought problem, or the idea that a statement of fact alone can never give rise to a normative conclusion of what "ought" to be done. Hume also denied that humans have an actual conception of the self, positing that we experience only a bundle of sensations, and that the self is nothing more than this bundle of causally-connected perceptions. Hume's compatibilist theory of free will takes causal determinism as fully compatible with human freedom.

Hume influenced utilitarianism, logical positivism, Immanuel Kant, the philosophy of science, early analytic philosophy, cognitive science, theology, and other movements and thinkers. Kant himself credited Hume as the spur to his philosophical thought who had awakened him from his "dogmatic slumbers".

David Hume was the second of two sons born to Joseph Home of Ninewells, an advocate, and his wife The Hon. Katherine ("née" Falconer), daughter of Sir David Falconer. He was born on 26 April 1711 (Old Style) in a tenement on the north side of the Lawnmarket in Edinburgh. Hume's father died when Hume was a child, just after his second birthday, and he was raised by his mother, who never remarried. He changed the spelling of his name in 1734, because of the fact that his surname "Home," pronounced "Hume," was not known in England. Throughout his life Hume, who never married, spent time occasionally at his family home at Ninewells in Berwickshire, which had belonged to his family since the sixteenth century. His finances as a young man were very "slender". His family was not rich, and, as a younger son, he had little patrimony to live on. He was therefore forced to make a living somehow.

Hume attended the University of Edinburgh at the unusually early age of twelve (possibly as young as ten) at a time when fourteen was normal. At first, because of his family, he considered a career in law, but came to have, in his words, "an insurmountable aversion to everything but the pursuits of Philosophy and general Learning; and while [my family] fanceyed I was poring over Voet and Vinnius, Cicero and Virgil were the Authors which I was secretly devouring". He had little respect for the professors of his time, telling a friend in 1735 that "there is nothing to be learnt from a Professor, which is not to be met with in Books". Hume did not graduate.

Aged around 18, he made a philosophical discovery that opened up to him "a new Scene of Thought", which inspired him "to throw up every other Pleasure or Business to apply entirely to it". He did not recount what this scene was, and commentators have offered a variety of speculations. One popular interpretation, prominent in contemporary Hume scholarship, is that the new "scene of thought" was Hume's realization that Francis Hutcheson's "moral sense" theory of morality could be applied to the understanding as well. Due to this inspiration, Hume set out to spend a minimum of ten years reading and writing. He soon came to the verge of a mental breakdown, suffering from what a doctor diagnosed as the "Disease of the Learned". Hume wrote that it started with a coldness, which he attributed to a "Laziness of Temper", that lasted about nine months. Later, some scurvy spots broke out on his fingers. This was what persuaded Hume's physician to make his diagnosis. Hume wrote that he "went under a Course of Bitters and Anti-Hysteric Pills", taken along with a pint of claret every day. Hume also decided to have a more active life to better continue his learning. His health improved somewhat, but, in 1731, he was afflicted with a ravenous appetite and palpitations of the heart. After eating well for a time, he went from being "tall, lean and raw-bon'd" to being "sturdy, robust [and] healthful-like". Indeed, Hume would become well known in his time for his "corpulence", and his fondness for good port and cheese.

At 25 years of age, Hume, although of noble ancestry, had no source of income and no learned profession. As was common at his time, he became a merchant's assistant, but he had to leave his native Scotland. He travelled via Bristol to La Flèche in Anjou, France. There he had frequent discourse with the Jesuits of the College of La Flèche.

While Hume was derailed in his attempts to start a university career by protests over his "atheism" and bemoaned that his literary debut, "A Treatise of Human Nature", 'fell dead-born from the press', he found literary success in his lifetime as an essayist, and a career as a librarian at the University of Edinburgh. His tenure there, and the access to research materials it provided, ultimately resulted in Hume's writing the massive six-volume "The History of England", which became a bestseller and the standard history of England in its day. Hume described his "love for literary fame" as his "ruling passion" and judged his two late works, the so-called "first" and "second" enquiries, "An Enquiry Concerning Human Understanding" and "An Enquiry Concerning the Principles of Morals", respectively, as his greatest literary and philosophical achievements, asking his contemporaries to judge him on the merits of the later texts alone, rather than the more radical formulations of his early, youthful work, dismissing his philosophical debut as juvenilia: "A work which the Author had projected before he left College." Despite Hume's protestations, a general consensus exists today that Hume's most important arguments and philosophically distinctive doctrines are found in the original form they take in the "Treatise". Hume was just 23 years old when he started this work and it is now regarded as one of the most important in the history of Western philosophy.

He worked for four years on his first major work, "A Treatise of Human Nature", subtitled "Being an Attempt to Introduce the Experimental Method of Reasoning into Moral Subjects", completing it in 1738 at the age of 28. Although many scholars today consider the "Treatise" to be Hume's most important work and one of the most important books in Western philosophy, the critics in Great Britain at the time did not agree, describing it as "abstract and unintelligible". As Hume had spent most of his savings during those four years, he resolved "to make a very rigid frugality supply my deficiency of fortune, to maintain unimpaired my independency, and to regard every object as contemptible except the improvements of my talents in literature". Despite the disappointment, Hume later wrote, "Being naturally of a cheerful and sanguine temper, I soon recovered from the blow and prosecuted with great ardour my studies in the country." There, in an attempt to make his larger work better known and more intelligible, he published the "An Abstract of a Book lately Published" as a summary of the main doctrines of the "Treatise", without revealing its authorship. Although there has been some academic speculation as to who actually wrote this pamphlet it is generally regarded as Hume's creation.

After the publication of "Essays Moral and Political" in 1741, which was included in the later edition called "Essays, Moral, Political, and Literary", Hume applied for the Chair of Pneumatics and Moral Philosophy at the University of Edinburgh. However, the position was given to William Cleghorn after Edinburgh ministers petitioned the town council not to appoint Hume because he was seen as an atheist.

During the 1745 Jacobite rising, Hume tutored the Marquess of Annandale (1720–92), who was "judged to be a lunatic". This engagement ended in disarray after about a year. However, it was then that Hume started his great historical work "The History of England". This took him fifteen years and ran to over a million words. During this time he was also involved with the Canongate Theatre through his friend John Home, a preacher.

In this context, he associated with Lord Monboddo and other Scottish Enlightenment luminaries in Edinburgh. From 1746, Hume served for three years as secretary to General James St Clair, who was envoy to the courts of Turin and Vienna. At that time Hume also wrote "Philosophical Essays Concerning Human Understanding", later published as "An Enquiry Concerning Human Understanding". Often called the "First Enquiry", it proved little more successful than the "Treatise", perhaps because of the publishing of his short autobiography, "My Own Life", which "made friends difficult for the first Enquiry".
In 1749 he went to live with his brother in the countryside.

Hume's religious views were often suspect. It was necessary in the 1750s for his friends to avert a trial against him on the charge of heresy. However, he "would not have come and could not be forced to attend if he said he was not a member of the Established Church". Hume failed to gain the chair of philosophy at the University of Glasgow for his religious views, too. He had published the "Philosophical Essays" by this time which were decidedly anti-religious. Even Adam Smith, his personal friend who had vacated the Glasgow philosophy chair, was against his appointment out of concern public opinion would be against it.

Hume returned to Edinburgh in 1751. In the following year "the Faculty of Advocates chose me their Librarian, an office from which I received little or no emolument, but which gave me the command of a large library". This resource enabled him to continue historical research for "The History of England". Hume's volume of "Political Discourses", written in 1749 and published by Kincaid & Donaldson in 1752, was the only work he considered successful on first publication.

Eventually, with the publication of his six volume "The History of England" between 1754 and 1762, Hume achieved the fame that he coveted. The volumes traced events from the Invasion of Julius Caesar to the Revolution of 1688, and was a bestseller in its day.

Hume was also a longtime friend of bookseller Andrew Millar, who sold Hume's "History ("after acquiring the rights from Scottish bookseller Gavin Hamilton), although the relationship was sometimes complicated. Letters between them illuminate both men's interest in the success of the "History."

From 1763 to 1765, Hume was invited to attend Lord Hertford in Paris, where he became secretary to the British embassy. Hume was well received in Paris, and while there he met with Isaac de Pinto In 1766, Hume left Paris to accompany Jean-Jacques Rousseau to England. Once in England, Hume and Rousseau fell out. Hume was sufficiently worried about the damage to his reputation from the quarrel with Rousseau (who is generally believed to have suffered from paranoia) to have authored an account of the dispute, which he titled, appropriately enough ""A concise and genuine account of the dispute between Mr. Hume and Mr. Rousseau."" In 1765, he served as British Chargé d'affaires, writing "despatches to the British Secretary of State". He wrote of his Paris life, "I really wish often for the plain roughness of The Poker Club of Edinburgh ... to correct and qualify so much lusciousness". In 1766, upon returning to Britain, Hume encouraged Lord Hertford to invest in a number of slave plantations, acquired by George Colebrooke and others in the Windward Islands. In 1767, Hume was appointed Under Secretary of State for the Northern Department. Here he wrote that he was given "all the secrets of the Kingdom". In 1769 he returned to James' Court in Edinburgh, and then lived, from 1771 until his death in 1776, at the southwest corner of St. Andrew's Square in Edinburgh's New Town, at what is now 21 Saint David Street. A popular story, consistent with some historical evidence, suggests the street may have been named after Hume.

In the last year of his life, Hume wrote an extremely brief autobiographical essay titled "My Own Life" which summed up his entire life in "fewer than 5 pages", and notably contains many interesting judgments that have been of enduring interest to subsequent readers of Hume. The scholar of 18th century literature Donald Seibert judged it a "remarkable autobiography, even though it may lack the usual attractions of that genre. Anyone hankering for startling revelations or amusing anecdotes had better look elsewhere." Hume here confesses his belief that the"love of literary fame" had served as his "ruling passion" in life, and claims that this desire "never soured my temper, notwithstanding my frequent disappointments." One such disappointment Hume discusses in the mini-autobiography was his disappointment that with the initial literary reception of the "Treatise", which he claims to have overcome by means of the success of the "Essays": "the work was favourably received, and soon made me entirely forget my former disappointment". Perhaps most notable is Hume's revelation of his own retrospective judgment that his philosophical debut's apparent failure "had proceeded more from the manner than the matter." Hume thus suggests that "I had been guilty of a very usual indiscretion, in going to the press too early." Hume provides an unambiguous self-assessment of the relative value of his works: "my Enquiry concerning the Principles of Morals; which, in my own opinion (who ought not to judge on that subject) is of all my writings, historical, philosophical, or literary, incomparably the best." Hume also makes a number of self-assessments in the essay, writing of his social relations that "My company was not unacceptable to the young and careless, as well as to the studious and literary", noting of his complex relation to religion, as well as the state, that "though I wantonly exposed myself to the rage of both civil and religious factions, they seemed to be disarmed in my behalf of their wonted fury", and professing of his character that "My friends never had occasion to vindicate any one circumstance of my character and conduct." Hume concludes the essay with the frank admission: " I cannot say there is no vanity in making this funeral oration of myself, but I hope it is not a misplaced one; and this is a matter of fact which is easily cleared and ascertained."

Diarist and biographer James Boswell saw Hume a few weeks before his death, which was from some form of abdominal cancer. Hume told him he sincerely believed it a "most unreasonable fancy" that there might be life after death. This meeting was dramatised in semi-fictional form for the BBC by Michael Ignatieff as "Dialogue in the Dark". Hume asked that his body be interred in a "simple Roman tomb". In his will he requests that it be inscribed only with his name and the year of his birth and death, "leaving it to Posterity to add the Rest". It stands, as he wished it, on the southwestern slope of Calton Hill, in the Old Calton Cemetery. Adam Smith later recounted Hume's amusing speculation that he might ask Charon to allow him a few more years of life in order to see "the downfall of some of the prevailing systems of superstition." The ferryman replied, "You loitering rogue, that will not happen these many hundred years ... Get into the boat this instant".

In the introduction to "A Treatise of Human Nature", Hume wrote, "'Tis evident, that all the sciences have a relation, more or less, to human nature ... Even Mathematics, Natural Philosophy, and Natural Religion, are in some measure dependent on the science of Man." He also wrote that the science of man is the "only solid foundation for the other sciences" and that the method for this science requires both experience and observation as the foundations of a logical argument. On this aspect of Hume's thought, philosophical historian Frederick Copleston wrote that it was Hume's aim to apply to the science of man the method of experimental philosophy (the term that was current at the time to imply Natural philosophy), and that "Hume's plan is to extend to philosophy in general the methodological limitations of Newtonian physics".

Until recently, Hume was seen as a forerunner of logical positivism; a form of anti-metaphysical empiricism. According to the logical positivists, unless a statement could be verified by experience, or else was true or false by definition (i.e. either tautological or contradictory), then it was meaningless (this is a summary statement of their verification principle). Hume, on this view, was a proto-positivist, who, in his philosophical writings, attempted to demonstrate how ordinary propositions about objects, causal relations, the self, and so on, are semantically equivalent to propositions about one's experiences.

Many commentators have since rejected this understanding of Humean empiricism, stressing an epistemological (rather than a semantic) reading of his project. According to this opposing view, Hume's empiricism consisted in the idea that it is our knowledge, and not our ability to conceive, that is restricted to what can be experienced. Hume thought that we can form beliefs about that which extends beyond any possible experience, through the operation of faculties such as custom and the imagination, but he was sceptical about claims to knowledge on this basis.

One of the most central doctrines of Hume's philosophy, stated in the very first lines of the "Treatise", is his notion that the mind consists of its mental perceptions, or the mental objects which are present to it, and which divide into two categories: "impressions" and "ideas". Hume's Treatise thus opens with the words: 'All the perceptions of the human mind resolve themselves into two distinct kinds, which I shall call IMPRESSIONS and IDEAS." Hume states that "I believe it will not be very necessary to employ many words in explaining this distinction" and commentators have generally taken Hume to mean the distinction between feeling and thinking. Controversially, Hume may regard the difference as in some sense a matter of degree, as he takes "impressions" to be distinguished from ideas, on the basis of their force, liveliness, and vivacity, or what Henry Allison calls the "FLV criterion" in his book on Hume. Ideas are therefore "faint" impressions. For example, experiencing the painful sensation of touching the handle of a hot pan is more forceful than simply thinking about touching a hot pan. According to Hume, impressions are meant to be the original form of all our ideas, and Don Garret has thus coined the term "the copy principle" to refer to Hume's doctrine that all ideas are ultimately all copied from some original impression, whether it be a passion or sensation, from which they derive.

After establishing the forcefulness of impressions and ideas, these two categories are further broken down into simple and complex: simple impressions and ideas, and complex impressions and ideas. Hume states that “simple perceptions or impressions and ideas are such as admit of no distinction nor separation,” while “the complex are the contrary to these, and may be distinguished into parts.” When looking at an apple, a person experiences a variety of color-sensations, which Hume sees as a complex impression. Similarly, a person experiences a variety of taste-sensations, tactile-sensations, and smell-sensations when biting into an apple, with the overall sensation again being a complex impression. Thinking about an apple allows a person to form complex ideas, which are made of similar parts as the complex impressions they were developed from, but which are also less forceful. Hume believes that complex perceptions can be broken down into smaller and smaller parts until perceptions are reached that have no parts of their own, and these perceptions are thereby referred to as being simple.
A person’s imagination, regardless of how boundless it may seem, is confined to the mind’s ability to recombine the information it has already acquired from the body’s sensory experience (the ideas that have been derived from impressions). In addition, “as our imagination takes our most basic ideas and leads us to form new ones, it is directed by three principles of association, namely, resemblance, contiguity, and cause and effect." The principle of resemblance refers to the tendency of ideas to become associated if the objects they represent resemble one another. For example, a person looking at an illustration of a flower can conceive of an idea of the physical flower because the idea of the illustrated object is associated with the idea of the physical object. The principle of contiguity describes the tendency of ideas to become associated if the objects they represent are near to each other in time or space, such as when the thought of one crayon in a box leads a person to think of the crayon contiguous to it. Finally, the principle of cause and effect refers to the tendency of ideas to become associated if the objects they represent are causally related, which explains how remembering a broken window can make someone think of the baseball that caused the window to shatter.
Hume elaborates more on this last principle of cause and effect. When a person observes that one object or event consistently produces the same object or event, it results in “an expectation that a particular event (a ‘cause’) will be followed by another event (an ‘effect’) previously and constantly associated with it." Hume calls this principle custom, or habit, saying that “custom…renders our experience useful to us, and makes us expect, for the future, a similar train of events with those which have appeared in the past." However, even though custom can serve as a guide in life, it still only represents an expectation. In other words, “experience cannot establish a necessary connection between cause and effect, because we can imagine without contradiction a case where the cause does not produce its usual effect…the reason why we mistakenly infer that there is something in the cause that necessarily produces its effect is because our past experiences have habituated us to think in this way." Continuing this idea, Hume argues that “only in the pure realm of ideas, logic, and mathematics, not contingent on the direct sense awareness of reality, [can] causation safely…be applied – all other sciences are reduced to probability." He uses this skepticism to reject metaphysics and many theological views on the basis that they are not grounded in fact and observations, and are therefore beyond the reach of human understanding.

The cornerstone of Hume's epistemology is the problem of induction. This may be the area of Hume's thought where his scepticism about human powers of reason is most pronounced. The problem revolves around the plausibility of inductive reasoning, that is, reasoning from the observed behaviour of objects to their behaviour when unobserved. As Hume wrote, induction concerns how things behave when they go "beyond the present testimony of the senses, or the records of our memory". Hume argues that we tend to believe that things behave in a regular manner, meaning that patterns in the behaviour of objects seem to persist into the future, and throughout the unobserved present. Hume's argument is that we cannot rationally justify the claim that nature will continue to be uniform, as justification comes in only two varieties—demonstrative reasoning and probable reasoning—and both of these are inadequate. With regard to demonstrative reasoning, Hume argues that the uniformity principle cannot be demonstrated, as it is "consistent and conceivable" that nature might stop being regular. Turning to probable reasoning, Hume argues that we cannot hold that nature will continue to be uniform because it has been in the past. As this is using the very sort of reasoning (induction) that is under question, it would be circular reasoning. Thus, no form of justification will rationally warrant our inductive inferences.

Hume's solution to this problem is to argue that, rather than reason, natural instinct explains the human practice of making inductive inferences. He asserts that "Nature, by an absolute and uncontroulable necessity has determin'd us to judge as well as to breathe and feel." Agreeing, philosopher John D. Kenyon writes: "Reason might manage to raise a doubt about the truth of a conclusion of natural inductive inference just for a moment ... but the sheer agreeableness of animal faith will protect us from excessive caution and sterile suspension of belief." Commentators such as Charles Sanders Peirce have demurred from Hume's solution, while, some, such as Kant and Karl Popper, saw that Hume's analysis "had posed a most fundamental challenge to all human knowledge claims."

The notion of causation is closely linked to the problem of induction. According to Hume, we reason inductively by associating constantly conjoined events. It is the mental act of association that is the basis of our concept of causation. There are at least three interpretations of Hume's theory of causation represented in the literature: (1) the logical positivist; (2) the sceptical realist; and (3) the quasi-realist.

David Hume acknowledged that there are events constantly unfolding, humanity cannot guarantee that these events are caused by events prior or if they are independent instances. Hume opposed the widely accepted theory of Causation that ‘all events have a specific course or reason.’ Therefore Hume crafted his own theory of causation, which he formed through his empiricist and skeptic beliefs. He split Causation, into two realms “All the objects of human reason or enquiry may naturally be divided into two kinds, to wit, Relations of Ideas, and Matters of Fact”. Relations of Ideas are a priori, and represent universal bonds between ideas that mark the cornerstones of human thought. Matters of Fact are dependent on the observer and experience. They are often not universally held to be true among multiple persons. Hume was an Empiricist, meaning he believed “causes and effects are discoverable not by reason, but by experience”. Hume later goes onto say that even with the perspective of the past, humanity cannot dictate future events because thoughts of the past are limited, compared to the possibilities for the future. Hume’s separation between Matters of Fact and Relations of Ideas is often referred to as “Hume’s Fork”.
Hume explains his theory of Causation and causal inference by division into three different parts. In these three branches he explains his ideas, in addition to comparing and contrasting his views to his predecessors. These branches are the Critical Phase, the Constructive Phase, and Belief. In the Critical Phase, Hume denies his predecessors' theories of causation. Next, Hume uses the Constructive Phase to resolve any doubts the reader may have while observing the Critical Phase. “Habit or Custom” mend the gaps in reasoning that occur without the human mind even realizing it. Associating ideas has become second nature to the human mind. It “makes us expect for the future, a similar train of events with those which have appeared in the past” However, Hume says that this association cannot be trusted because the span of the human mind to comprehend the past is not necessarily applicable to the wide and distant future. This leads Hume to the third branch of causal inference, Belief. Belief is what drives the human mind to hold that expectancy of the future based on past experience. Throughout his explanation of causal inference, Hume is arguing that the future is not certain to be repetition of the past and the only way to justify induction is through uniformity.

The logical positivist interpretation is that Hume analyses causal propositions, such as "A caused B", in terms of regularities in perception: "A causes B" is equivalent to "Whenever A-type events happen, B-type ones follow", where "whenever" refers to all possible perceptions. In his "Treatise of Human Nature", Hume wrote:
power and necessity ... are ... qualities of perceptions, not of objects ... felt by the soul and not perceiv'd externally in bodies.
This view is rejected by skeptical realists, who argue that Hume thought that causation amounts to more than just the regular succession of events. Hume said that when two events are causally conjoined, a necessary connection underpins the conjunction:
Shall we rest contented with these two relations of contiguity and succession, as affording a complete idea of causation? By no means ... there is a "necessary connexion" to be taken into consideration.
Philosopher Angela Coventry writes that, for Hume, "there is nothing in any particular instance of cause and effect involving external objects which suggests the idea of power or necessary connection" and that "we are ignorant of the powers that operate between objects". However, while denying the possibility of knowing the powers between objects, Hume accepted the causal principle, writing, "I never asserted so absurd a proposition as that something could arise without a cause."

It has been argued that, while Hume did not think causation is reducible to pure regularity, he was not a fully fledged realist either. Philosopher Simon Blackburn calls this a quasi-realist reading. Blackburn writes that "Someone talking of cause is voicing a distinct mental set: he is by no means in the same state as someone merely describing regular sequences. In Hume's words, "nothing is more usual than to apply to external bodies every internal sensation, which they occasion".

Empiricist philosophers, such as Hume and Berkeley, favoured the bundle theory of personal identity. In this theory, "the mind itself, far from being an independent power, is simply 'a bundle of perceptions' without unity or cohesive quality". The self is nothing but a bundle of experiences linked by the relations of causation and resemblance; or, more accurately, that the empirically warranted idea of the self is just the idea of such a bundle. This view is forwarded by, for example, positivist interpreters, who saw Hume as suggesting that terms such as "self", "person", or "mind" referred to collections of "sense-contents". A modern-day version of the bundle theory of the mind has been advanced by Derek Parfit in his "Reasons and Persons".

However, some philosophers have criticised Hume's bundle-theory interpretation of personal identity. They argue that distinct selves can have perceptions that stand in relations of similarity and causality with one another. Thus, perceptions must already come parcelled into distinct "bundles" before they can be associated according to the relations of similarity and causality. In other words, the mind must already possess a unity that cannot be generated, or constituted, by these relations alone. Since the bundle-theory interpretation portrays Hume as answering an ontological question, philosophers, like Galen Strawson, who see Hume as not very concerned with such questions have queried whether the view is really Hume's. Instead, it is suggested by Strawson that Hume might have been answering an epistemological question about the causal origin of our concept of the self. In the Appendix to the "Treatise", Hume declares himself dissatisfied with his earlier account of personal identity in Book 1. Philosopher Corliss Swain notes that "Commentators agree that if Hume did find some new problem" when he reviewed the section on personal identity, "he wasn't forthcoming about its nature in the Appendix." One interpretation of Hume's view of the self has been argued for by philosopher and psychologist James Giles. According to his view, Hume is not arguing for a bundle theory, which is a form of reductionism, but rather for an eliminative view of the self. That is, rather than reducing the self to a bundle of perceptions, Hume is rejecting the idea of the self altogether. On this interpretation, Hume is proposing a "no-self theory" and thus has much in common with Buddhist thought. On this point, psychologist Alison Gopnik has argued that Hume was in a position to learn about Buddhist thought during his time in France in the 1730s.

An essential question of practical reason for Hume was whether or not standards or principles exist (and if they do, what they are) for practical reason, that are also authoritative for all rational beings, dictating people’s intentions and actions. Hume is mainly considered an anti-rationalist, denying the possibility for practical reason as a principle to exist, although other philosophers such as Christine Korsgaard, Jean Hampton, and Elijah Millgram claim that Hume is not so much of an anti-rationalist as he is just a skeptic of practical reason.

Hume denied the existence of practical reason as a principle because he claimed reason does not have any effect on morality, since morality is capable of producing effects in people that reason alone cannot create. As Hume explains in "A Treatise of Human Nature" (1740): “Morals excite passions, and produce or prevent actions. Reason of itself is utterly impotent in this particular. The rules of morality, therefore, are not conclusions of our reason.”

Since practical reason is supposed to regulate our actions (in theory), Hume denied practical reason on the grounds that reason cannot directly oppose passions. As Hume puts it, “Reason is, and ought only to be the slave of the passions, and can never pretend to any other office than to serve and obey them.” Reason is less significant than any passion because reason has no original influence, while "A passion is an original existence, or, if you will, modification of existence".

Practical reason is also concerned with the value of actions rather than the truth of propositions, so Hume believed that reason’s shortcoming of affecting morality proved that practical reason could not be authoritative for all rational beings, since morality was essential for dictating people’s intentions and actions.

Hume's writings on ethics began in the "Treatise" and were refined in his "An Enquiry Concerning the Principles of Morals" (1751). His views on ethics are that "[m]oral decisions are grounded in moral sentiment." It is not knowing that governs ethical actions, but feelings. Arguing that reason cannot be behind morality, he wrote:
Morals excite passions, and produce or prevent actions. Reason itself is utterly impotent in this particular. The rules of morality, therefore, are not conclusions of our reason.
Hume's sentimentalism about morality was shared by his close friend Adam Smith, and Hume and Smith were mutually influenced by the moral reflections of their older contemporary Francis Hutcheson. Peter Singer claims that Hume's argument that morals cannot have a rational basis alone "would have been enough to earn him a place in the history of ethics".

Hume also put forward the is–ought problem, later called "Hume's Law", denying the possibility of logically deriving what "ought" to be from what "is". He wrote in the "Treatise" that in every system of morality he has read, the author begins with stating facts about the world, but then suddenly is always referring to what ought to be the case. Hume demands that a reason should be given for inferring what ought to be the case, from what is the case. This because it "seems altogether inconceivable, how this new relation can be a deduction from others".

Hume's theory of ethics has been influential in modern day meta-ethical theory, helping to inspire emotivism, and ethical expressivism and non-cognitivism, as well as Allan Gibbard's general theory of moral judgment and judgments of rationality.

Hume's ideas about aesthetics and the theory of art are spread throughout his works, but are particularly connected with his ethical writings, and also the essays "Of the Standard of Taste" and "Of Tragedy". His views are rooted in the work of Joseph Addison and Francis Hutcheson. In the "Treatise" he wrote of the connection between beauty and deformity and vice and virtue, and his later writings on this subject continue to draw parallels of beauty and deformity in art, with conduct and character.

In "Of the Standard of Taste", Hume argues that no rules can be drawn up about what is a tasteful object. However, a reliable critic of taste can be recognised as being objective, sensible and unprejudiced, and having extensive experience. "Of Tragedy" addresses the question of why humans enjoy tragic drama. Hume was concerned with the way spectators find pleasure in the sorrow and anxiety depicted in a tragedy. He argued that this was because the spectator is aware that he is witnessing a dramatic performance. There is pleasure in realising that the terrible events that are being shown are actually fiction. Furthermore, Hume laid down rules for educating people in taste and correct conduct, and his writings in this area have been very influential on English and Anglo-Saxon aesthetics.

Hume, along with Thomas Hobbes, is cited as a classical compatibilist about the notions of freedom and determinism. The thesis of compatibilism seeks to reconcile human freedom with the mechanist belief that human beings are part of a deterministic universe, whose happenings are governed by physical laws. Hume, to this end, was influenced greatly by the scientific revolution and by in particular Sir Isaac Newton. Hume argued that the dispute about the compatibility of freedom and determinism has been continued over two thousand years by ambiguous terminology. He wrote: "From this circumstance alone, that a controversy has been long kept on foot ... we may presume that there is some ambiguity in the expression", and that different disputants use different meanings for the same terms.

Hume defines the concept of necessity as "the uniformity, observable in the operations of nature; where similar objects are constantly conjoined together", and liberty as "a power of acting or not acting, according to the determinations of the will". He then argues that, according to these definitions, not only are the two compatible, but liberty "requires" necessity. For if our actions were not necessitated in the above sense, they would "have so little in connexion with motives, inclinations and circumstances, that one does not follow with a certain degree of uniformity from the other". But if our actions are not thus connected to the will, then our actions can never be free: they would be matters of "chance; which is universally allowed to have no existence". Australian philosopher John Passmore writes that confusion has arisen because "necessity" has been taken to mean "necessary connexion". Once this has been abandoned, Hume argues that "liberty and necessity will be found not to be in conflict one with another".

Moreover, Hume goes on to argue that in order to be held morally responsible, it is required that our behaviour be caused or necessitated, for, as he wrote:

Actions are, by their very nature, temporary and perishing; and where they proceed not from some "cause" in the character and disposition of the person who performed them, they can neither redound to his honour, if good; nor infamy, if evil.

Hume describes the link between causality and our capacity to rationally make a decision from this an inference of the mind. Human beings assess a situation based upon certain predetermined events and from that form a choice. Hume believes that this choice is made spontaneously. Hume calls this form of decision making the liberty of spontaneity.

Education writer Richard Wright considers that Hume's position rejects a famous moral puzzle attributed to French philosopher Jean Buridan. The Buridan's ass puzzle describes a donkey that is hungry. This donkey has on both sides of him separate bales of hay, which are of equal distances from him. The problem concerns which bale the donkey chooses. Buridan was said to believe that the donkey would die, because he has no autonomy. The donkey is incapable of forming a rational decision as there is no motive to choose one bale of hay over the other. However, human beings are different, because a human who is placed in a position where he is forced to choose one loaf of bread over another will make a decision to take one in lieu of the other. For Buridan, humans have the capacity of autonomy, and he recognises the choice that is ultimately made will be based on chance, as both loaves of bread are exactly the same. However, Wright says that Hume completely rejects this notion, arguing that a human will spontaneously act in such a situation because he is faced with impending death if he fails to do so. Such a decision is not made on the basis of chance, but rather on necessity and spontaneity, given the prior predetermined events leading up to the predicament.

Hume's argument is supported by modern day compatibilists such as R. E. Hobart, a pseudonym of philosopher Dickinson S. Miller. However, P. F. Strawson argued that the issue of whether we hold one another morally responsible does not ultimately depend on the truth or falsity of a metaphysical thesis such as determinism. This is because our so holding one another is a non-rational human sentiment that is not predicated on such theses.

The "Stanford Encyclopedia of Philosophy" states that Hume "wrote forcefully and incisively on almost every central question in the philosophy of religion." His "various writings concerning problems of religion are among the most important and influential contributions on this topic." His writings in this field cover the philosophy, psychology, history, and anthropology of religious thought. All of these aspects were discussed in Hume's 1757 dissertation, "The Natural History of Religion". Here he argued that the monotheistic religions of Judaism, Christianity and Islam all derive from earlier polytheistic religions. He also suggested that all religious belief "traces, in the end, to dread of the unknown." Hume had also written on religious subjects in the first "Enquiry", as well as later in the "Dialogues Concerning Natural Religion".

Although he wrote a great deal about religion, Hume's personal views are unclear, and there has been much discussion concerning his religious position. Contemporaries considered him to be an atheist, or at least un-Christian, and the Church of Scotland seriously considered bringing charges of infidelity against him. The fact that contemporaries thought that he may have been an atheist is exemplified by a story Hume liked to tell:

The best theologian he ever met, he used to say, was the old Edinburgh fishwife who, having recognized him as Hume the atheist, refused to pull him out of the bog into which he had fallen until he declared he was a Christian and repeated the Lord's prayer.

However, in works such as "Of Superstition and Enthusiasm", Hume specifically seems to support the standard religious views of his time and place. This still meant that he could be very critical of the Catholic Church, dismissing it with the standard Protestant accusations of superstition and idolatry, as well as dismissing as idolatry what his compatriots saw as uncivilised beliefs. He also considered extreme Protestant sects, the members of which he called "enthusiasts", to be corrupters of religion. By contrast, in his "The Natural History of Religion", Hume presented arguments suggesting that polytheism had much to commend it over monotheism.

Philosopher Paul Russell writes that it is likely that Hume was sceptical about religious belief, but not to the extent of complete atheism. He suggests that perhaps Hume's position is best characterised by the term "irreligion", while philosopher David O'Connor argues that Hume's final position was "weakly deistic". For O'Connor, Hume's "position is deeply ironic. This is because, while inclining towards a weak form of deism, he seriously doubts that we can ever find a sufficiently favourable balance of evidence to justify accepting any religious position." He adds that Hume "did not believe in the God of standard theism ... but he did not rule out all concepts of deity", and that "ambiguity suited his purposes, and this creates difficulty in definitively pinning down his final position on religion".

One of the traditional topics of natural theology is that of the existence of God, and one of the "a posteriori" arguments for this is the "argument from design" or the teleological argument. The argument is that the existence of God can be proved by the design that is obvious in the complexity of the world. "Encyclopædia Britannica" states that this is "the most popular, because [it is] the most accessible of the theistic arguments ... which identifies evidences of design in nature, inferring from them a divine designer ... The fact that the universe as a whole is a coherent and efficiently functioning system likewise, in this view, indicates a divine intelligence behind it."

In "An Enquiry Concerning Human Understanding", Hume wrote that the design argument seems to depend upon our experience, and its proponents "always suppose the universe, an effect quite singular and unparalleled, to be the proof of a Deity, a cause no less singular and unparalleled". Philosopher Louise E. Loeb notes that Hume is saying that only experience and observation can be our guide to making inferences about the conjunction between events. However, according to Hume, "we observe neither God nor other universes, and hence no conjunction involving them. There is no observed conjunction to ground an inference either to extended objects or to God, as unobserved causes."

Hume also criticised the argument in his "Dialogues Concerning Natural Religion" (1779). In this, he suggested that, even if the world is a more or less smoothly functioning system, this may only be a result of the "chance permutations of particles falling into a temporary or permanent self-sustaining order, which thus has the appearance of design."

A century later, the idea of order without design was rendered more plausible by Charles Darwin's discovery that the adaptations of the forms of life are a result of the natural selection of inherited characteristics. For philosopher James D. Madden, it is "Hume, rivaled only by Darwin, [who] has done the most to undermine in principle our confidence in arguments from design among all figures in the Western intellectual tradition."

Finally, Hume discussed a version of the anthropic principle, which is the idea that theories of the universe are constrained by the need to allow for man's existence in it as an observer. Hume has his sceptical mouthpiece Philo suggest that there may have been many worlds, produced by an incompetent designer, whom he called a "stupid mechanic". In his "Dialogues Concerning Natural Religion", Hume wrote:

Many worlds might have been botched and bungled throughout an eternity, ere this system was struck out: much labour lost: many fruitless trials made: and a slow, but continued improvement carried on during infinite ages in the art of world-making.
American philosopher Daniel Dennett has suggested that this mechanical explanation of teleology, although "obviously ... an amusing philosophical fantasy", anticipated the notion of natural selection, the 'continued improvement' being like "any Darwinian selection algorithm."

In his discussion of miracles, Hume argues that we should not believe that miracles have occurred and that they do not therefore provide us with any reason to think that God exists. In "An Enquiry Concerning Human Understanding" (Section 10), Hume defines a miracle as "a transgression of a law of nature by a particular volition of the Deity, or by the interposition of some invisible agent". Hume says that we believe an event that has frequently occurred is likely to occur again, but we also take into account those instances where the event did not occur. Hume wrote:

A wise man [...] considers which side is supported by the greater number of experiments [...] A hundred instances or experiments on one side, and fifty on another, afford a doubtful expectation of any event; though a hundred uniform experiments, with only one that is contradictory, reasonably beget a pretty strong degree of assurance. In all cases, we must balance the opposite experiments [...] and deduct the smaller number from the greater, in order to know the exact force of the superior evidence.

Hume discusses the testimony of those who report miracles. He wrote that testimony might be doubted even from some great authority in case the facts themselves are not credible. "[T]he evidence, resulting from the testimony, admits of a diminution, greater or less, in proportion as the fact is more or less unusual."

Although Hume leaves open the possibility for miracles to occur and be reported, he offers various arguments against this ever having happened in history: He points out that people often lie, and they have good reasons to lie about miracles occurring either because they believe they are doing so for the benefit of their religion or because of the fame that results. Furthermore, people by nature enjoy relating miracles they have heard without caring for their veracity and thus miracles are easily transmitted even where false. Also, Hume notes that miracles seem to occur mostly in "ignorant and barbarous nations" and times, and the reason they do not occur in the civilised societies is such societies are not awed by what they know to be natural events. Finally, the miracles of each religion argue against all other religions and their miracles, and so even if a proportion of all reported miracles across the world fit Hume's requirement for belief, the miracles of each religion make the other less likely.

Hume was extremely pleased with his argument against miracles in his "Enquiry". He states "I flatter myself, that I have discovered an argument of a like nature, which, if just, will, with the wise and learned, be an everlasting check to all kinds of superstitious delusion, and consequently, will be useful as long as the world endures." Thus, Hume's argument against miracles had a more abstract basis founded upon the scrutiny, not just primarily of miracles, but of all forms of belief systems. It is a common sense notion of veracity based upon epistemological evidence, and founded on a principle of rationality, proportionality and reasonability.

The criterion for assessing a belief system for Hume is based on the balance of probability whether something is more likely than not to have occurred. Since the weight of empirical experience contradicts the notion for the existence of miracles, such accounts should be treated with scepticism. Further, the myriad of accounts of miracles contradict one another, as some people who receive miracles will aim to prove the authority of Jesus, whereas others will aim to prove the authority of Muhammad or some other religious prophet or deity. These various differing accounts weaken the overall evidential power of miracles.

Despite all this, Hume observes that belief in miracles is popular, and that "The gazing populace [...] receive greedily, without examination, whatever soothes superstition, and promotes wonder."

Critics have argued that Hume's position assumes the character of miracles and natural laws prior to any specific examination of miracle claims, thus it amounts to a subtle form of begging the question. To assume that testimony is a homogeneous reference group seems unwise- to compare private miracles with public miracles, unintellectual observers with intellectual observers and those who have little to gain and much to lose with those with much to gain and little to lose is not convincing to many. Indeed, many have argued that miracles not only do not contradict the laws of nature, but require the laws of nature to be intelligible as miraculous, and thus subverting the law of nature. For example, William Adams remarks that "there must be an ordinary course of nature before anything can be extraordinary. There must be a stream before anything can be interrupted". They have also noted that it requires an appeal to inductive inference, as none have observed every part of nature nor examined every possible miracle claim, for instance those in the future. This, in Hume's philosophy, was especially problematic.

Little appreciated is the voluminous literature either foreshadowing Hume, in the likes of Thomas Sherlock or directly responding to and engaging with Hume- from William Paley, William Adams, John Douglas, John Leland and George Campbell, among others. Of Campbell, it is rumoured that, having read Campbell's Dissertation, Hume remarked that "the Scotch theologue had beaten him".

Hume's main argument concerning miracles is that miracles by definition are singular events that differ from the established laws of nature. Such natural laws are codified as a result of past experiences. Therefore, a miracle is a violation of all prior experience and thus incapable on this basis of reasonable belief. However, the probability that something has occurred in contradiction of all past experience should always be judged to be less than the probability that either ones senses have deceived one, or the person recounting the miraculous occurrence is lying or mistaken. Hume would say, all of which he had past experience of. For Hume, this refusal to grant credence does not guarantee correctness. He offers the example of an Indian Prince, who, having grown up in a hot country, refuses to believe that water has frozen. By Hume's lights, this refusal is not wrong and the Prince "reasoned justly"; it is presumably only when he has had extensive experience of the freezing of water that he has warrant to believe that the event could occur.

So for Hume, either the miraculous event will become a recurrent event or else it will never be rational to believe it occurred. The connection to religious belief is left unexplained throughout, except for the close of his discussion where Hume notes the reliance of Christianity upon testimony of miraculous occurrences. He makes an ironic remark that anyone who "is moved by faith to assent" to revealed testimony "is conscious of a continued miracle in his own person, which subverts all principles of his understanding, and gives him a determination to believe what is most contrary to custom and experience." Hume writes that "All the testimony which ever was really given for any miracle, or ever will be given, is a subject of derision."

From 1754 to 1762 Hume published "The History of England", a 6-volume work, which extends, says its subtitle, "From the Invasion of Julius Caesar to the Revolution in 1688". Inspired by Voltaire's sense of the breadth of history, Hume widened the focus of the field away from merely kings, parliaments, and armies, to literature and science as well. He argued that the quest for liberty was the highest standard for judging the past, and concluded that after considerable fluctuation, England at the time of his writing had achieved "the most entire system of liberty that was ever known amongst mankind". It "must be regarded as an event of cultural importance. In its own day, moreover, it was an innovation, soaring high above its very few predecessors."

Hume's coverage of the political upheavals of the 17th century relied in large part on the Earl of Clarendon's "History of the Rebellion and Civil Wars in England" (1646–69). Generally, Hume took a moderate royalist position and considered revolution unnecessary to achieve necessary reform. Hume was considered a Tory historian, and emphasised religious differences more than constitutional issues. Laird Okie explains that "Hume preached the virtues of political moderation, but ... it was moderation with an anti-Whig, pro-royalist coloring." For "Hume shared the ... Tory belief that the Stuarts were no more high-handed than their Tudor predecessors". "Even though Hume wrote with an anti-Whig animus, it is, paradoxically, correct to regard the "History" as an establishment work, one which implicitly endorsed the ruling oligarchy".
Historians have debated whether Hume posited a universal unchanging human nature, or allowed for evolution and development.

Robert Roth argues that Hume's histories display his biases against Presbyterians and Puritans. Roth says his anti-Whig pro-monarchy position diminished the influence of his work, and that his emphasis on politics and religion led to a neglect of social and economic history.

Hume was an early cultural historian of science. His short biographies of leading scientists explored the process of scientific change. He developed new ways of seeing scientists in the context of their times by looking at how they interacted with society and each other. He covers over forty scientists, with special attention paid to Francis Bacon, Robert Boyle, and Isaac Newton. Hume particularly praised William Harvey, writing about his treatise of the circulation of the blood: "Harvey is entitled to the glory of having made, by reasoning alone, without any mixture of accident, a capital discovery in one of the most important branches of science".

The "History" became a best-seller and made Hume a wealthy man who no longer had to take up salaried work for others. It was influential for nearly a century, despite competition from imitations by Smollett (1757), Goldsmith (1771) and others. By 1894, there were at least 50 editions as well as abridgements for students, and illustrated pocket editions, probably produced specifically for women.

It is difficult to categorise Hume's political affiliations. His writings contain elements that are, in modern terms, both conservative and liberal, although these terms are anachronistic. Thomas Jefferson banned the "History" from University of Virginia, feeling that it had "spread universal toryism over the land". By comparison, Samuel Johnson thought Hume "a Tory by chance ... for he has no principle. If he is anything, he is a Hobbist", a follower of Thomas Hobbes. A major concern of Hume's political philosophy is the importance of the rule of law. He also stresses throughout his political essays the importance of moderation in politics: public spirit and regard to the community.

This outlook needs to be seen within the historical context of eighteenth century Scotland. Here, the legacy of religious civil war, combined with the relatively recent memory of the 1715 and 1745 Jacobite risings, fostered in a historian such as Hume a distaste for enthusiasm and factionalism. These appeared to threaten the fragile and nascent political and social stability of a country that was deeply politically and religiously divided. Hume thought that society is best governed by a general and impartial system of laws; he is less concerned about the form of government that administers these laws, so long as it does so fairly. However, he does write that a republic must produce laws, while "monarchy, when absolute, contains even something repugnant to law."

Hume expressed suspicion of attempts to reform society in ways that departed from long-established custom, and he counselled peoples not to resist their governments except in cases of the most egregious tyranny. However, he resisted aligning himself with either of Britain's two political parties, the Whigs and the Tories. Hume wrote:

My views of "things" are more conformable to Whig principles; my representations of "persons" to Tory prejudices.

Canadian philosopher Neil McArthur writes that Hume believed that we should try to balance our demands for liberty with the need for strong authority, without sacrificing either. McArthur characterises Hume as a "precautionary conservative", whose actions would have been "determined by prudential concerns about the consequences of change, which often demand we ignore our own principles about what is ideal or even legitimate." Hume supported the liberty of the press, and was sympathetic to democracy, when suitably constrained. American historian Douglass Adair has argued that Hume was a major inspiration for James Madison's writings, and the essay "Federalist No. 10" in particular.

Hume offered his view on the best type of society in an essay titled "Idea of a Perfect Commonwealth", which lays out what he thought was the best form of government. He hoped that, "in some future age, an opportunity might be afforded of reducing the theory to practice, either by a dissolution of some old government, or by the combination of men to form a new one, in some distant part of the world". He defended a strict separation of powers, decentralisation, extending the franchise to anyone who held property of value and limiting the power of the clergy. The system of the Swiss militia was proposed as the best form of protection. Elections were to take place on an annual basis and representatives were to be unpaid. Political philosophers Leo Strauss and Joseph Cropsey, writing of Hume's thoughts about "the wise statesman", note that he "will bear a reverence to what carries the marks of age". Also, if he wishes to improve a constitution, his innovations will take account of the "ancient fabric", in order not to disturb society.

In the political analysis of philosopher George Sabine, the scepticism of Hume extended to the doctrine of government by consent. He notes that "allegiance is a habit enforced by education and consequently as much a part of human nature as any other motive."

In the 1770's, Hume was critical of British policies toward the American colonies and advocated for American independence. He wrote in 1771 that "our union with America... in the nature of things, cannot long subsist".

Hume noted his views as economist in his "Political Discourses", which were incorporated in "Essays and Treatises" as Part II of "Essays, Moral and Political". To what extent he was influenced by Adam Smith is difficult to stress, however both of them had similar principles supported from historical events. At the same time Hume did not demonstrate concrete system of economic theory which could be observed in Smith's Wealth of Nations. However, he introduced several new ideas around which the “classical economics” of the 18th century was built. Through his discussions on politics, Hume developed many ideas that are prevalent in the field of economics. This includes ideas on private property, inflation, and foreign trade. Referring to his essay "Of the Balance of Trade", economist Paul Krugman has remarked that "David Hume created what I consider the first true economic model."

In contrast to Locke, Hume believes that private property is not a natural right. Hume argues it is justified, because resources are limited. Private property would be an unjustified, "idle ceremonial", if all goods were unlimited and available freely. Hume also believed in an unequal distribution of property, because perfect equality would destroy the ideas of thrift and industry. Perfect equality would thus lead to impoverishment.

Due to Hume's vast influence on contemporary philosophy, a large number of approaches in contemporary philosophy and cognitive science are today called "Humean."

Attention to Hume's philosophical works grew after the German philosopher Immanuel Kant, in his "Prolegomena to Any Future Metaphysics" (1783), credited Hume with awakening him from his "dogmatic slumber".

According to Schopenhauer, "there is more to be learned from each page of David Hume than from the collected philosophical works of Hegel, Herbart and Schleiermacher taken together."

A. J. Ayer, while introducing his classic exposition of logical positivism in 1936, claimed: "The views which are put forward in this treatise derive from ... doctrines ... which are themselves the logical outcome of the empiricism of Berkeley and David Hume." Albert Einstein, in 1915, wrote that he was inspired by Hume's positivism when formulating his theory of special relativity.

Hume's problem of induction was also of fundamental importance to the philosophy of Karl Popper. In his autobiography, "Unended Quest", he wrote: "Knowledge ... is "objective"; and it is hypothetical or conjectural. This way of looking at the problem made it possible for me to reformulate Hume's "problem of induction"". This insight resulted in Popper's major work "The Logic of Scientific Discovery". Also, in his "Conjectures and Refutations", he wrote:

I approached the problem of induction through Hume. Hume, I felt, was perfectly right in pointing out that induction cannot be logically justified.
The writings of Scottish philosopher and contemporary of Hume, Thomas Reid, were often criticisms of Hume's scepticism. Reid formulated his common sense philosophy in part as a reaction against Hume's views.

Hume influenced and was influenced by the Christian philosopher Joseph Butler. Hume was impressed by Butler's way of thinking about religion, and Butler may well have been influenced by Hume's writings.

Hume's rationalism in religious subjects influenced, via German-Scottish theologian Johann Joachim Spalding, the German neology school and rational theology, and contributed to the transformation of German theology in the age of enlightenment. Hume pioneered a comparative history of religion, tried to explain various rites and traditions as being based on deception and challenged various aspects of rational and natural theology, such as the argument from design.

Danish theologian and philosopher Søren Kierkegaard adopted "Hume's suggestion that the role of reason is not to make us wise but to reveal our ignorance." However, Kierkegaard took this as a reason for the necessity of religious faith, or fideism. The "fact that Christianity is contrary to reason ... is the necessary precondition for true faith." Political theorist Isaiah Berlin, for example, has pointed out the similarities between the arguments of Hume and Kierkegaard against rational theology. Berlin also writes about Hume's influence on what Berlin calls the counter-enlightenment, and German anti-rationalism.

According to philosopher Jerry Fodor, Hume's "Treatise" is "the founding document of cognitive science".

Hume engaged with contemporary intellectual luminaries such as Jean-Jacques Rousseau, James Boswell, and Adam Smith (who acknowledged Hume's influence on his economics and political philosophy).

Isaiah Berlin once said of Hume that "No man has influenced the history of philosophy to a deeper or more disturbing degree."

The "Stanford Encyclopedia of Philosophy" writes that Hume is "[g]enerally regarded as one of the most important philosophers to write in English."

His nephew and namesake, David Hume of Ninewells (1757–1838) was a co-founder of the Royal Society of Edinburgh in 1783. He was a Professor of Scots Law at Edinburgh University and rose to be Principal Clerk Of Session in the scottish High court and Baron of the Exchequer. He is buried with his uncle in Old Calton Cemetery.




</doc>
<doc id="7928" url="https://en.wikipedia.org/wiki?curid=7928" title="Dalton Trumbo">
Dalton Trumbo

James Dalton Trumbo (December 9, 1905 – September 10, 1976) was an American screenwriter and novelist who scripted many award-winning films including "Roman Holiday", "Exodus", "Spartacus", and "Thirty Seconds Over Tokyo". One of the Hollywood Ten, he refused to testify before the House Un-American Activities Committee (HUAC) in 1947 during the committee's investigation of communist influences in the motion picture industry. He, along with the other members of the Hollywood Ten and hundreds of other industry professionals, was subsequently blacklisted by that industry. 

His talents as one of the top screenwriters allowed him to continue working clandestinely, producing work under other authors' names or pseudonyms. His uncredited work won two Academy Awards: for "Roman Holiday" (1953), which was given to a front writer, and for "The Brave One" (1956) which was awarded to a pseudonym of Trumbo's. When he was given public screen credit for both "Exodus" and "Spartacus" in 1960, this marked the beginning of the end of the Hollywood Blacklist for Trumbo and other screenwriters. He finally was given full credit by the Writers' Guild for all his achievements, the work of which encompassed six decades of screenwriting.

Trumbo was born in Montrose, Colorado, the son of Maud (née Tillery) and Orus Bonham Trumbo. His family moved to Grand Junction in 1908. He was proud of his paternal immigrant ancestor, a Protestant Swiss man named Jacob Trumbo, who settled in the colony of Virginia in 1736. Trumbo graduated from Grand Junction High School. While still in high school, he worked for Walter Walker as a cub reporter for the "Grand Junction Daily Sentinel," covering courts, the high school, the mortuary and civic organizations. He attended the University of Colorado at Boulder for two years, working as a reporter for the "Boulder Daily Camera" and contributing to the campus humor magazine, the yearbook, and the campus newspaper. He was a member of Delta Tau Delta International Fraternity.

For nine years after his father died, Trumbo worked the night shift wrapping bread at a Los Angeles bakery, and attended the University of Southern California. At the same time, he wrote movie reviews, 88 short stories and six novels, all of which were rejected for publication.

Trumbo began his professional writing career in the early 1930s, when several of his articles and stories were published in mainstream magazines, including the "Saturday Evening Post," "McCall's Magazine," "Vanity Fair," and the "Hollywood Spectator". In 1934 Trumbo was hired as managing editor of the "Hollywood Spectator." Later he left the magazine to become a reader in the story department at Warner Bros. studio.

His first published novel was "Eclipse" (1935), released during the Great Depression. Writing in the social realist style, Trumbo drew on his years in Grand Junction to portray a town and its people. The book was controversial in his home town, where many people took issue with his fictional portrayal. But years after his death, Trumbo was honored by installation of a statue of him in front of the Avalon Theater on Main Street, where he was depicted writing a screenplay in a bathtub.
Trumbo started working in movies in 1937 but continued writing prose. His anti-war novel "Johnny Got His Gun" won one of the early National Book Awards: the Most Original Book of 1939. It was inspired by an article Trumbo had read several years earlier, an account of a hospital visit by the Prince of Wales to a Canadian soldier who had lost all his limbs in World War I.

During the late 1930s and early 1940s, Trumbo became one of Hollywood's highest-paid screenwriters, at about $4000 per week while on assignment, and earning as much as $80,000 in one year. He worked on such films as "Thirty Seconds Over Tokyo" (1944), "Our Vines Have Tender Grapes" (1945), and "Kitty Foyle" (1940), for which he was nominated for an Academy Award for Writing Adapted Screenplay.

Trumbo aligned with the Communist Party in the United States before the 1940s, although he did not join the party until 1943. He was an isolationist. His novel "The Remarkable Andrew" featured the ghost of President Andrew Jackson appearing to caution the United States against getting involved in World War II. In a review of the book, "Time Magazine" wise-cracked, "General Jackson's opinions need surprise no one who has observed George Washington and Abraham Lincoln zealously following the Communist Party Line in recent years."

Shortly after the German invasion of the Soviet Union in 1941, Trumbo and his publisher decided to suspend reprinting "Johnny Got His Gun" until the end of the war. During the war, Trumbo received letters from individuals "denouncing Jews" and using "Johnny" to support their arguments for "an immediate negotiated peace" with Nazi Germany; Trumbo reported these correspondents to the FBI. Trumbo regretted this decision, which he called "foolish." After two FBI agents showed up at his home, he understood that "their interest lay not in the letters but in me."

In a 1946 article titled "The Russian Menace" published in Rob Wagner's "Script Magazine", Trumbo wrote from the perspective of a post-World War II Russian citizen. He argued that Russians were likely fearful of the mass of U.S. military power that surrounded them, at a time when any sympathetic view toward communist countries was viewed with suspicion. He ended the article by stating, "If I were a Russian ... I would be alarmed, and I would petition my government to take measures at once against what would seem an almost certain blow aimed at my existence. This is how it must appear in Russia today". He argued that the U.S. was a "menace" to Russia, rather than the more popular American view of Russia as the "red menace". According to anti-communist author Kenneth Billingsley in 2000, Trumbo had written in "The Daily Worker" that communist influence in Hollywood had prevented films from being made from anti-communist books, such as Arthur Koestler's "Darkness at Noon" and "The Yogi and the Commissar".

On July 29, 1946, William R. Wilkerson, publisher and founder of "The Hollywood Reporter", published a "TradeView" column entitled "A Vote For Joe Stalin". It named Trumbo and several others as Communist sympathizers, the first persons identified on what became known as "Billy's Blacklist". In October 1947, drawing upon these names, the House Un-American Activities Committee (HUAC) summoned Trumbo and nine others to testify for their investigation as to whether Communist agents and sympathizers had surreptitiously planted propaganda in U.S. films. The writers refused to give information about their own or any other person's involvement and were convicted for contempt of Congress. They appealed the conviction to the Supreme Court on First Amendment grounds and lost. In 1950, Trumbo served eleven months in the federal penitentiary in Ashland, Kentucky. In the 1976 documentary "Hollywood On Trial", Trumbo said "As far as I was concerned, it was a completely just verdict. I had contempt for that Congress and have had contempt for several since. And on the basis of guilt or innocence, I could never really complain very much. That this was a crime or misdemeanor was the complaint, my complaint."

Meanwhile, the MPAA had issued a statement that Trumbo and his compatriots would not be permitted to work in the industry, unless they disavowed Communism under oath. After completing his sentence, Trumbo sold his ranch and moved with his family to Mexico City with Hugo Butler and his wife Jean Rouverol, who had also been blacklisted. In Mexico Trumbo wrote 30 scripts under pseudonyms, for B-movie studios such as King Brothers Productions. In the case of "Gun Crazy" (1950), adapted from a short story by MacKinlay Kantor, Kantor agreed to be the front for Trumbo's screenplay. Trumbo's role in the screenplay was not revealed until 1992.

During this blacklist period, Trumbo also wrote "The Brave One" (1956) for the King Brothers. Like "Roman Holiday", it received an Academy Award for Best Story he couldn't claim. The script was credited to Robert Rich, a name borrowed from a nephew of the producers. Trumbo recalled earning an average fee of $1,750 per film for 18 screenplays written in two years and said, "None was very good".

In 1956 he published "The Devil in the Book", an analysis of the conviction of 14 California Smith Act defendants. The statute set criminal penalties for advocating the overthrow of the U.S. government and required all non-citizen adult residents to register with the government.

Gradually the blacklist weakened; with the support of director Otto Preminger, Trumbo was credited for his screenplay for the 1960 film "Exodus", which he adapted from the novel of the same name by Leon Uris. Shortly thereafter, actor Kirk Douglas announced that Trumbo had written the screenplay for Stanley Kubrick's film "Spartacus". With these actions, Preminger and Douglas helped end the power of the blacklist. Trumbo was reinstated into the Writers Guild of America, West and was credited on all subsequent scripts. Eventually in 2011, the Guild gave him full credit for the script of "Roman Holiday". In 1971, Trumbo directed the film adaptation of his novel "Johnny Got His Gun", which starred Timothy Bottoms, Diane Varsi, Jason Robards and Donald Sutherland. One of the last films Trumbo wrote, "Executive Action" (1973), was based on the Kennedy assassination. In 1975, the Academy officially recognized Trumbo as the winner of the Oscar for "The Brave One" and presented him with a statuette.

In 1938, Trumbo married Cleo Fincher. She was born in Fresno on July 17, 1916, and moved with her divorced mother and her brother and sister to Los Angeles. Cleo Trumbo died of natural causes at the age of 93 on October 9, 2009, in Los Altos. At the time she was living with her younger daughter Mitzi. The Trumbos had three children: the filmmaker and screenwriter Christopher Trumbo, who became an expert on the Hollywood blacklist; Melissa, known as Mitzi, a photographer; and Nikola Trumbo, a psychotherapist. His daughter Mitzi dated comedian Steve Martin when they were both in their early 20s, which is recounted in Martin's 2007 book "Born Standing Up". Martin wrote of her, "Mitzi became my official photographer, and she snapped dozens of rolls of film, all to find the perfect publicity photo."

Trumbo died in Los Angeles of a heart attack at the age of 70 on September 10, 1976. He donated his body to scientific research.

In 1993, Trumbo was posthumously awarded the Academy Award for writing "Roman Holiday" (1953). The screen credit and award were previously given to Ian McLellan Hunter, who had been a front for Trumbo. A new statue was made for this award because Hunter's son refused to hand over the one his father had received.

In 2003, Christopher Trumbo mounted an Off-Broadway play based on his father's letters called "Trumbo: Red, White and Blacklisted", in which a wide variety of actors played his father during the run, including Nathan Lane, Tim Robbins, Brian Dennehy, Ed Harris, Chris Cooper and Gore Vidal. He adapted it as the film "Trumbo" (2007), which added documentary footage and new interviews.

A dramatization of Trumbo's life, also called "Trumbo", was released in November 2015. It starred Bryan Cranston as the screenwriter and was directed by Jay Roach. For his portrayal of Trumbo, Cranston was nominated for Best Actor at the 88th Academy Awards.

The moving image collection of Trumbo is held at the Academy Film Archive and consists primarily of extensive 35mm production materials relating to the 1971 anti-war film "Johnny Got His Gun".







</doc>
<doc id="7930" url="https://en.wikipedia.org/wiki?curid=7930" title="Delaware">
Delaware

Delaware () is one of the 50 states of the United States, in the Mid-Atlantic or Northeastern region. It is bordered to the south and west by Maryland, to the north by Pennsylvania, and to the east by New Jersey and the Atlantic Ocean. The state takes its name from Thomas West, 3rd Baron De La Warr, an English nobleman and Virginia's first colonial governor.

Delaware occupies the northeastern portion of the Delmarva Peninsula. It is the second smallest and sixth least populous state, but the sixth most densely populated. Delaware is divided into three counties, the lowest number of any state. From north to south, they are New Castle County, Kent County, and Sussex County. While the southern two counties have historically been predominantly agricultural, New Castle County is more industrialized.

Before its coastline was explored by Europeans in the 16th century, Delaware was inhabited by several groups of Native Americans, including the Lenape in the north and Nanticoke in the south. It was initially colonized by Dutch traders at Zwaanendael, near the present town of Lewes, in 1631. Delaware was one of the 13 colonies participating in the American Revolution. On December 7, 1787, Delaware became the first state to ratify the Constitution of the United States, and has since been known as "The First State".

The state was named after the Delaware River, which in turn derived its name from Thomas West, 3rd Baron De La Warr (1577–1618) who was the ruling governor of the Colony of Virginia at the time Europeans first explored the river. The Delaware Indians, a name used by Europeans for Lenape people indigenous to the Delaware Valley, also derive their name from the same source.

The surname "de La Warr" comes from Sussex and is of Anglo-Norman origin. It came probably from a Norman lieu-dit "La Guerre". This toponymic could derive from the Latin word "ager", from the Breton "gwern" or from the Late Latin "varectum" (fallow). The toponyms Gara, Gare, Gaire (the sound [ä] often mutated in [æ]) also appear in old texts cited by Lucien Musset, where the word "ga(i)ra" means gore. It could also be linked with a patronymic from the Old Norse "verr".

Delaware is long and ranges from to across, totaling , making it the second-smallest state in the United States after Rhode Island. Delaware is bounded to the north by Pennsylvania; to the east by the Delaware River, Delaware Bay, New Jersey and the Atlantic Ocean; and to the west and south by Maryland. Small portions of Delaware are also situated on the eastern side of the Delaware River sharing land boundaries with New Jersey. The state of Delaware, together with the Eastern Shore counties of Maryland and two counties of Virginia, form the Delmarva Peninsula, which stretches down the Mid-Atlantic Coast.

The definition of the northern boundary of the state is unusual. Most of the boundary between Delaware and Pennsylvania was originally defined by an arc extending from the cupola of the courthouse in the city of New Castle. This boundary is often referred to as the Twelve-Mile Circle. This is the only nominally circular state boundary in the United States.

This border extends all the way east to the low-tide mark on the New Jersey shore, then continues south along the shoreline until it again reaches the 12-mile (19 km) arc in the south; then the boundary continues in a more conventional way in the middle of the main channel (thalweg) of the Delaware River. To the west, a portion of the arc extends past the easternmost edge of Maryland. The remaining western border runs slightly east of due south from its intersection with the arc. The Wedge of land between the northwest part of the arc and the Maryland border was claimed by both Delaware and Pennsylvania until 1921, when Delaware's claim was confirmed.

Delaware is on a level plain, with the lowest mean elevation of any state in the nation. Its highest elevation, located at Ebright Azimuth, near Concord High School, is less than above sea level. The northernmost part of the state is part of the Piedmont Plateau with hills and rolling surfaces. The Atlantic Seaboard fall line approximately follows the Robert Kirkwood Highway between Newark and Wilmington; south of this road is the Atlantic Coastal Plain with flat, sandy, and, in some parts, swampy ground. A ridge about in elevation extends along the western boundary of the state and separates the watersheds that feed Delaware River and Bay to the east and the Chesapeake Bay to the west.

Since almost all of Delaware is a part of the Atlantic coastal plain, the effects of the ocean moderate its climate. The state lies in the humid subtropical climate zone. Despite its small size (roughly from its northernmost to southernmost points), there is significant variation in mean temperature and amount of snowfall between Sussex County and New Castle County. Moderated by the Atlantic Ocean and Delaware Bay, the southern portion of the state has a milder climate and a longer growing season than the northern portion of the state. Delaware's all-time record high of was recorded at Millsboro on July 21, 1930. The all-time record low of was also recorded at Millsboro on January 17, 1893.

The transitional climate of Delaware supports a wide variety of vegetation. In the northern third of the state are found Northeastern coastal forests and mixed oak forests typical of the northeastern United States. In the southern two-thirds of the state are found Middle Atlantic coastal forests. Trap Pond State Park, along with areas in other parts of Sussex County, for example, support the northernmost stands of bald cypress trees in North America.

Delaware provides government subsidy support for the clean-up of property "lightly contaminated" by hazardous waste, the proceeds for which come from a tax on wholesale petroleum sales.

Before Delaware was settled by European colonists, the area was home to the Eastern Algonquian tribes known as the Unami Lenape, or Delaware, who lived mostly along the coast, and the Nanticoke who occupied much of the southern Delmarva Peninsula. John Smith also shows two Iroquoian tribes, the Kuskarawock & Tockwogh, living north of the Nanticoke & they may have held small portions of land in the western part of the state before migrating across the Chesapeake Bay. The Kuskarawocks were most likely the Tuscarora.

The Unami Lenape in the Delaware Valley were closely related to Munsee Lenape tribes along the Hudson River. They had a settled hunting and agricultural society, and they rapidly became middlemen in an increasingly frantic fur trade with their ancient enemy, the Minqua or Susquehannock. With the loss of their lands on the Delaware River and the destruction of the Minqua by the Iroquois of the Five Nations in the 1670s, the remnants of the Lenape who wished to remain identified as such left the region and moved over the Alleghany Mountains by the mid-18th century. Generally, those who did not relocate out of the state of Delaware were baptized, became Christian and were grouped together with other persons of color in official records and in the minds of their non-Native American neighbors.

The Dutch were the first Europeans to settle in present-day Delaware in the middle region by establishing a trading post at Zwaanendael, near the site of Lewes in 1631. Within a year all the settlers were killed in a dispute with area Native American tribes. In 1638 New Sweden, a Swedish trading post and colony, was established at Fort Christina (now in Wilmington) by Peter Minuit at the head of a group of Swedes, Finns and Dutch. The colony of New Sweden lasted for 17 years. In 1651 the Dutch, reinvigorated by the leadership of Peter Stuyvesant, established a fort at present-day New Castle, and in 1655 they conquered the New Sweden colony, annexing it into the Dutch New Netherland. Only nine years later, in 1664, the Dutch were conquered by a fleet of English ships by Sir Robert Carr under the direction of James, the Duke of York. Fighting off a prior claim by Cecil Calvert, 2nd Baron Baltimore, Proprietor of Maryland, the Duke passed his somewhat dubious ownership on to William Penn in 1682. Penn strongly desired access to the sea for his Pennsylvania province and leased what then came to be known as the "Lower Counties on the Delaware" from the Duke.

Penn established representative government and briefly combined his two possessions under one General Assembly in 1682. However, by 1704 the Province of Pennsylvania had grown so large that their representatives wanted to make decisions without the assent of the Lower Counties and the two groups of representatives began meeting on their own, one at Philadelphia, and the other at New Castle. Penn and his heirs remained proprietors of both and always appointed the same person Governor for their Province of Pennsylvania and their territory of the Lower Counties. The fact that Delaware and Pennsylvania shared the same governor was not unique. From 1703 to 1738 New York and New Jersey shared a governor. Massachusetts and New Hampshire also shared a governor for some time.

Dependent in early years on indentured labor, Delaware imported more slaves as the number of English immigrants decreased with better economic conditions in England. The colony became a slave society and cultivated tobacco as a cash crop, although English immigrants continued to arrive.

Like the other middle colonies, the Lower Counties on the Delaware initially showed little enthusiasm for a break with Britain. The citizenry had a good relationship with the Proprietary government, and generally were allowed more independence of action in their Colonial Assembly than in other colonies. Merchants at the port of Wilmington had trading ties with the British.

So it was that New Castle lawyer Thomas McKean denounced the Stamp Act in the strongest terms, and Kent County native John Dickinson became the "Penman of the Revolution." Anticipating the Declaration of Independence, Patriot leaders Thomas McKean and Caesar Rodney convinced the Colonial Assembly to declare itself separated from British and Pennsylvania rule on June 15, 1776. The person best representing Delaware's majority, George Read, could not bring himself to vote for a Declaration of Independence. Only the dramatic overnight ride of Caesar Rodney gave the delegation the votes needed to cast Delaware's vote for independence.

Initially led by John Haslet, Delaware provided one of the premier regiments in the Continental Army, known as the "Delaware Blues" and nicknamed the "Blue Hen's Chicks." In August 1777 General Sir William Howe led a British army through Delaware on his way to a victory at the Battle of Brandywine and capture of the city of Philadelphia. The only real engagement on Delaware soil was the Battle of Cooch's Bridge, fought on September 3, 1777, at Cooch's Bridge in New Castle County, although there was a minor Loyalist rebellion in 1778.

Following the Battle of Brandywine, Wilmington was occupied by the British, and State President John McKinly was taken prisoner. The British remained in control of the Delaware River for much of the rest of the war, disrupting commerce and providing encouragement to an active Loyalist portion of the population, particularly in Sussex County. Because the British promised slaves of rebels freedom for fighting with them, escaped slaves flocked north to join their lines.

Following the American Revolution, statesmen from Delaware were among the leading proponents of a strong central United States with equal representation for each state.

Many colonial settlers came to Delaware from Maryland and Virginia, which had been experiencing a population boom. The economies of these colonies were chiefly based on tobacco culture and were increasingly dependent on slave labor for its intensive cultivation. Most of the English colonists arrived as indentured servants, under contracts to work as laborers for a fixed period to pay for their passage. In the early years the line between indentured servants and African slaves or laborers was fluid, and the working classes often lived closely together. Most of the free African-American families in Delaware before the Revolution had migrated from Maryland to find more affordable land. They were descendants chiefly of relationships or marriages between white servant women and enslaved, servant or free African or African-American men. As the flow of indentured laborers to the colony decreased with improving economic conditions in England, more slaves were imported for labor and the caste lines hardened.

At the end of the colonial period, the number of enslaved people in Delaware began to decline. Shifts in the agriculture economy from tobacco to mixed farming created less need for slaves' labor. Local Methodists and Quakers encouraged slaveholders to free their slaves following the American Revolution, and many did so in a surge of individual manumissions for idealistic reasons. By 1810 three-quarters of all blacks in Delaware were free. When John Dickinson freed his slaves in 1777, he was Delaware's largest slave owner with 37 slaves. By 1860, the largest slaveholder owned 16 slaves.

Although attempts to abolish slavery failed by narrow margins in the legislature, in practical terms, the state had mostly ended the practice. By the 1860 census on the verge of the Civil War, 91.7% of the black population were free; 1,798 were slaves, as compared to 19,829 "free colored persons".

The independent black denomination was chartered by freed slave Peter Spencer in 1813 as the "Union Church of Africans". This followed the 1793 establishment of the African Methodist Episcopal Church in Philadelphia, which had ties to the Methodist Episcopal Church until 1816. Spencer built a church in Wilmington for the new denomination.

This was renamed the African Union First Colored Methodist Protestant Church and Connection, more commonly known as the A.U.M.P. Church. Begun by Spencer in 1814, the annual gathering of the Big August Quarterly still draws people together in a religious and cultural festival, the oldest such cultural festival in the nation.

Delaware voted against secession on January 3, 1861, and so remained in the Union. While most Delaware citizens who fought in the war served in the regiments of the state, some served in companies on the Confederate side in Maryland and Virginia Regiments. Delaware is notable for being the only slave state from which no Confederate regiments or militia groups were assembled. Delaware essentially freed the few slaves that were still in bondage shortly after the Civil War, but rejected the 13th, 14th, and 15th Amendments to the Constitution; the 13th Amendment was rejected on February 8, 1865, the 14th Amendment was rejected on February 8, 1867, and the 15th Amendment was rejected on March 18, 1869. Delaware officially ratified the 13th, 14th, and 15th amendments on February 12, 1901.

The United States Census Bureau estimates that the population of Delaware was 952,065 people on July 1, 2016, a 6.0% increase since the 2010 United States Census.

According to the 2010 United States Census, Delaware had a population of 897,934 people. The racial composition of the state was:

Ethnically, Hispanics and Latinos of any race made up 8.2% of the population.

Delaware is the sixth most densely populated state, with a population density of 442.6 people per square mile, 356.4 per square mile more than the national average, and ranking 45th in population. Delaware is one of five states that do not have a single city with a population over 100,000 as of the 2010 census, the other four being West Virginia, Vermont, Maine and Wyoming. The center of population of Delaware is in New Castle County, in the town of Townsend.

As of 2011, 49.7% of Delaware's population younger than one year of age belonged to minority groups (i.e., did not have two parents of non-Hispanic white ancestry). In 2000 approximately 19% of the population were African-American and 5% of the population is Hispanic (mostly of Puerto Rican or Mexican ancestry).

The largest European ancestry groups in Delaware are, according to 2012 Census Bureau estimates:


"Note: Births in table don't add up because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number."
As of 2000 91% of Delaware residents age 5 and older speak only English at home; 5% speak Spanish. French is the third most spoken language at 0.7%, followed by Chinese at 0.5% and German at 0.5%.

Legislation had been proposed in both the House and the Senate in Delaware to designate English as the official language. Neither bill was passed in the legislature.

As of the year 2010, The Association of Religion Data Archives reported that the three largest denominational groups in Delaware by number of adherents are the Catholic Church at 182,532 adherents, the United Methodist Church with 53,656 members reported, and non-denominational Evangelical Protestant with 22,973 adherents reported. The religious body with the largest number of congregations is the United Methodist Church (with 158 congregations) followed by non-denominational Evangelical Protestant (with 106 congregations), then the Catholic Church (with 45 congregations).

The Roman Catholic Diocese of Wilmington and the Episcopal Diocese of Delaware oversee the parishes within their denominations. The A.U.M.P. Church, the oldest African-American denomination in the nation, was founded in Wilmington. It still has a substantial presence in the state. Reflecting new immigrant populations, an Islamic mosque has been built in the Ogletown area, and a Hindu temple in Hockessin.

Delaware is home to an Amish community that resides to the west of Dover in Kent County, consisting of 9 church districts and between 1,200 and 1,500 people. The Amish first settled in Kent County in 1915. In recent years, increasing development has led to the decline in the number of Amish living in the community.

A 2012 survey of religious attitudes in the United States found that 34% of Delaware residents considered themselves "moderately religious," 33% "very religious," and 33% as "non-religious."

A 2012 Gallup poll found that Delaware's proportion of lesbian, gay, bisexual, and transgender adults stood at 3.4 percent of the population. This constitutes a total LGBT adult population estimate of 23,698 people. The number of same-sex couple households in 2010 stood at 2,646. This grew by 41.65% from a decade earlier. On July 1, 2013, same-sex marriage was legalized, and all civil unions would be converted into marriages.

According to a 2013 study by Phoenix Marketing International, Delaware had the ninth-largest number of millionaires per capita in the United States, with a ratio of 6.20 percent.

Delaware's agricultural output consists of poultry, nursery stock, soybeans, dairy products and corn.

As of October 2015, the state's unemployment rate was 5.1%.

The state's largest employers are:

Dover Air Force Base, located next to the state capital of Dover, is one of the largest Air Force bases in the country and is a major employer in Delaware. In addition to its other responsibilities in the United States Air Force Air Mobility Command, this air base serves as the entry point and mortuary for American military personnel and some U.S. government civilians who die overseas.

The recent merger of E.I. du Pont de Nemours & Co. and Dow Chemical Company into DowDuPont on September 1, 2017 has caused many to question the viability of the remaining operations of the merged company in Delaware. DuPont employed over 8,000 at its peak as the state's second largest private employer. The stability of the state's economic future is of concern. In late 2015, DuPont announced that 1,700 employees, nearly a third of its footprint in Delaware, would be laid off in early 2016.

Since the mid-2000s, Delaware has suffered an onslaught of economic downfalls affecting stable middle class jobs including the departure of the state's automotive manufacturing industry (General Motors Wilmington Assembly and Chrysler Newark Assembly), the corporate buyout of a major bank holding company (MBNA), the departure of the state's steel industry (Evraz Claymont Steel), the bankruptcy of a fiber mill (National Vulcanized Fibre), and the diminishing presence of Astra Zeneca in Wilmington.

More than 50% of all U.S. publicly traded companies and 63% of the Fortune 500 are incorporated in Delaware. The state's attractiveness as a corporate haven is largely because of its business-friendly corporation law. Franchise taxes on Delaware corporations supply about one-fifth of its state revenue. Although "USA (Delaware)" ranked as the world's most opaque jurisdiction on the Tax Justice Network's 2009 Financial Secrecy Index, the same group's 2011 Index ranks the USA fifth and does not specify Delaware. In Delaware, there are more than a million registered corporations, meaning there are more corporations than people.

 stipulates that alcoholic liquor only be sold in specifically licensed establishments, and only between 9:00 am and 1:00 am. Until 2003, Delaware was among the several states enforcing blue laws and banned the sale of liquor on Sunday.

The transportation system in Delaware is under the governance and supervision of the Delaware Department of Transportation, also known as "DelDOT". Funding for DelDOT projects is drawn, in part, from the Delaware Transportation Trust Fund, established in 1987 to help stabilize transportation funding; the availability of the Trust led to a gradual separation of DelDOT operations from other Delaware state operations. DelDOT manages programs such as a Delaware Adopt-a-Highway program, major road route snow removal, traffic control infrastructure (signs and signals), toll road management, Delaware Division of Motor Vehicles, the Delaware Transit Corporation (branded as "DART First State", the state government public transportation organization), among others. In 2009, DelDOT maintained 13,507 lane miles of roads, totaling 89 percent of the state's public roadway system; the remaining public road miles are under the supervision of individual municipalities. This far exceeds the United States national average of 20 percent for state department of transportation maintenance responsibility.

The "DART First State" public transportation system was named "Most Outstanding Public Transportation System" in 2003 by the American Public Transportation Association. Coverage of the system is broad within northern New Castle County with close association to major highways in Kent and Sussex counties. The system includes bus, subsidized passenger rail operated by Philadelphia transit agency SEPTA, and subsidized taxi and paratransit modes. The paratransit system, consisting of a statewide door-to-door bus service for the elderly and disabled, has been described by a Delaware state report as "the most generous paratransit system in the United States." , fees for the paratransit service have not changed since 1988.

One major branch of the U.S. Interstate Highway System, Interstate 95 (I-95), crosses Delaware southwest-to-northeast across New Castle County. In addition to I-95, there are six U.S. highways that serve Delaware: U.S. Route 9 (US 9), US 13, US 40, US 113, US 202, and US 301. There are also several state highways that cross the state of Delaware; a few of them include Delaware Route 1 (DE 1), DE 9, and DE 404. US 13 and DE 1 are primary north-south highways connecting Wilmington and Pennsylvania with Maryland, with DE 1 serving as the main route between Wilmington and the Delaware beaches. DE 9 is a north-south highway connecting Dover and Wilmington via a scenic route along the Delaware Bay. US 40, is a primary east-west route, connecting Maryland with New Jersey. DE 404 is another primary east-west highway connecting the Chesapeake Bay Bridge in Maryland with the Delaware beaches. The state also operates two toll highways, the Delaware Turnpike, which is I-95, between Maryland and New Castle and the Korean War Veterans Memorial Highway, which is DE 1, between Wilmington and Dover.

A bicycle route, Delaware Bicycle Route 1, spans the north-south length of the state from the Maryland border in Fenwick Island to the Pennsylvania border north of Montchanin. It is the first of several signed bike routes planned in Delaware.

Delaware has around 1,450 bridges, 95 percent of which are under the supervision of DelDOT. About 30 percent of all Delaware bridges were built before 1950, and about 60 percent of the number are included in the National Bridge Inventory. Some bridges not under DelDOT supervision includes the four bridges on the Chesapeake and Delaware Canal, which are under the jurisdiction of the U.S. Army Corps of Engineers, and the Delaware Memorial Bridge, which is under the bi-state Delaware River and Bay Authority.

It has been noted that the tar and chip composition of secondary roads in Sussex County make them more prone to deterioration than asphalt roadways found in almost the rest of the state. Among these roads, Sussex (county road) 236 is among the most problematic.

There are three ferries that operate in the state of Delaware:

Amtrak has two stations in Delaware along the Northeast Corridor; the relatively quiet Newark Rail Station in Newark, and the busier Wilmington Rail Station in Wilmington. The Northeast Corridor is also served by SEPTA's Wilmington/Newark Line of Regional Rail, which serves Claymont, Wilmington, Churchmans Crossing, and Newark.

Two Class I railroads, Norfolk Southern and CSX, provide freight rail service in northern New Castle County. Norfolk Southern provides freight service along the Northeast Corridor and to industrial areas in Edgemoor, New Castle, and Delaware City. CSX's Philadelphia Subdivision passes through northern New Castle County parallel to the Amtrak Northeast Corridor. Multiple short-line railroads provide freight service in Delaware. The Delmarva Central Railroad operates the most trackage of the short-line railroads, running from an interchange with Norfolk Southern in Porter south through Dover, Harrington, and Seaford to Delmar, with another line running from Harrington to Frankford. The Delmarva Central Railroad connects with two shortline railroads, the Delaware Coast Line Railroad and the Maryland and Delaware Railroad, which serve local customers in Sussex County. CSX connects with the freight/heritage operation, the Wilmington and Western Railroad, based in Wilmington and the East Penn Railroad, which operates a line from Wilmington to Coatesville, Pennsylvania.

The last north-south passenger train through the main part of Delaware was the Pennsylvania Railroad's "The Cavalier," which ended service from Philadelphia through the state's interior in 1951.

, there is no scheduled air service from any Delaware airport, as has been the case in various years since 1991. Various airlines had served Wilmington Airport, with the latest departure being Frontier Airlines in April 2015.

Delaware is centrally situated in the Northeast megalopolis region of cities along I-95. Therefore, Delaware commercial airline passengers most frequently use Philadelphia International Airport (PHL), Baltimore-Washington International Thurgood Marshall Airport (BWI) and Washington Dulles International Airport (IAD) for domestic and international transit. Residents of Sussex County will also use Wicomico Regional Airport (SBY), as it is located less than from the Delaware border. Atlantic City International Airport (ACY), Newark Liberty International Airport (EWR), and Ronald Reagan Washington National Airport (DCA) are also within a radius of New Castle County.

The Dover Air Force Base of the Air Mobility Command is in the central part of the state, and it is the home of the 436th Airlift Wing and the 512th Airlift Wing.

Other general aviation airports in Delaware include Summit Airport near Middletown, Delaware Airpark near Cheswold, and Delaware Coastal Airport near Georgetown.

Delaware's fourth and current constitution, adopted in 1897, provides for executive, judicial and legislative branches.

The Delaware General Assembly consists of a House of Representatives with 41 members and a Senate with 21 members. It sits in Dover, the state capital. Representatives are elected to two-year terms, while senators are elected to four-year terms. The Senate confirms judicial and other nominees appointed by the governor.

Delaware's U.S. Senators are Tom Carper (Democrat) and Chris Coons (Democrat). Delaware's single U.S. Representative is Lisa Blunt Rochester (Democrat).

The Delaware Constitution establishes a number of courts:

Minor non-constitutional courts include the Justice of the Peace Courts and Aldermen's Courts.

Significantly, Delaware has one of the few remaining Courts of Chancery in the nation, which has jurisdiction over equity cases, the vast majority of which are corporate disputes, many relating to mergers and acquisitions. The Court of Chancery and the Delaware Supreme Court have developed a worldwide reputation for rendering concise opinions concerning corporate law which generally (but not always) grant broad discretion to corporate boards of directors and officers. In addition, the Delaware General Corporation Law, which forms the basis of the Courts' opinions, is widely regarded as giving great flexibility to corporations to manage their affairs. For these reasons, Delaware is considered to have the most business-friendly legal system in the United States; therefore a great number of companies are incorporated in Delaware, including 60% of the companies listed on the New York Stock Exchange. Delaware was the last U.S. state to use judicial corporal punishment, in 1952.

The executive branch is headed by the Governor of Delaware. The present governor is John Carney (Democrat), who took office January 17, 2017. The lieutenant governor is Bethany Hall-Long. The governor presents a "State of the State" speech to a joint session of the Delaware legislature annually.

Delaware is subdivided into three counties; from north to south they are New Castle, Kent and Sussex. This is the fewest among all states. Each county elects its own legislative body (known in New Castle and Sussex counties as County Council, and in Kent County as Levy Court), which deal primarily in zoning and development issues. Most functions which are handled on a county-by-county basis in other states – such as court and law enforcement – have been centralized in Delaware, leading to a significant concentration of power in the Delaware state government. The counties were historically divided into hundreds, which were used as tax reporting and voting districts until the 1960s, but now serve no administrative role, their only current official legal use being in real-estate title descriptions.

The Democratic Party holds a plurality of registrations in Delaware. Until the 2000 presidential election, the state tended to be a Presidential bellwether, sending its three electoral votes to the winning candidate since 1952. This trend ended in 2000 when Delaware's electoral votes went to Al Gore. In 2004 John Kerry won Delaware by eight percentage points. In 2008 Democrat Barack Obama defeated Republican John McCain in Delaware 62.63% to 37.37%. Obama's running mate was Joe Biden, who had represented Delaware in the United States Senate since 1973. Obama carried Delaware again in 2012. In 2016, Delaware's electoral votes went to Hillary Clinton.

Delaware's swing to the Democrats is in part due to a strong Democratic trend in New Castle County, home to 55 percent of Delaware's population (the two smaller counties have only 359,000 people between them to New Castle's 535,000). New Castle has not voted Republican in a presidential election since 1988. In 1992, 2000, 2004, and 2016, the Republican presidential candidate carried both Kent and Sussex but lost by double-digits each time in New Castle, which was a large enough margin to swing the state to the Democrats. New Castle also elects a substantial majority of the legislature; 27 of the 41 state house districts and 14 of the 21 state senate districts are based in New Castle.

The Democrats have held the governorship since 1993, having won the last six gubernatorial elections in a row. Democrats presently hold seven of the nine statewide elected offices, while the Republicans hold only two statewide offices, State Auditor and State Treasurer.

Each of the 50 states of the United States has passed some form of freedom of information legislation, which provides a mechanism for the general public to request information of the government. In 2011 Delaware passed legislation placing a 15 business day time limit on addressing freedom-of-information requests, to either produce information or an explanation of why such information would take longer than this time to produce.

Delaware has six different income tax brackets, ranging from 2.2% to 5.95%. The state does not assess sales tax on consumers. The state does, however, impose a tax on the gross receipts of most businesses. Business and occupational license tax rates range from 0.096% to 1.92%, depending on the category of business activity.

Delaware does not assess a state-level tax on real or personal property. Real estate is subject to county property taxes, school district property taxes, vocational school district taxes, and, if located within an incorporated area, municipal property taxes.

Gambling provides significant revenue to the state. For instance, the casino at Delaware Park Racetrack provided more than $100 million USD to the state in 2010.

Wilmington is the state's largest city and its economic hub. It is located within commuting distance of both Philadelphia and Baltimore. All regions of Delaware are enjoying phenomenal growth, with Dover and the beach resorts expanding at a rapid rate.






Delaware was the origin of "Belton v. Gebhart", one of the four cases which was combined into "Brown v. Board of Education", the Supreme Court of the United States decision that led to the end of segregated public schools. Significantly, "Belton" was the only case in which the state court found for the plaintiffs, thereby ruling that segregation was unconstitutional.

Unlike many states, Delaware's educational system is centralized in a state Superintendent of Education, with local school boards retaining control over taxation and some curriculum decisions.

, the Delaware Department of Education had authorized the founding of 25 charter schools in the state, one of them being all-girls.

All teachers in the State's public school districts are unionized. , none of the State's charter schools are members of a teachers union. One of the State's teachers' unions is Delaware State Education Association (DSEA), whose President as of January 2012 is Frederika Jenner.


Delaware's sister state in Japan is Miyagi Prefecture.

The northern part of the state is served by network stations in Philadelphia and the southern part by network stations in Baltimore and Salisbury, Maryland. Philadelphia's ABC affiliate, WPVI-TV, maintains a news bureau in downtown Wilmington. Salisbury's ABC affiliate, WMDT covers Sussex and lower Kent County; while CBS affiliate, WBOC-TV, maintains bureaus in Dover and Milton.

Few television stations are based solely in Delaware; the local PBS station from Philadelphia (but licensed to Wilmington), WHYY-TV, maintains a studio and broadcasting facility in Wilmington and Dover, Ion Television affiliate WPPX is licensed to Wilmington but maintains their offices in Philadelphia and their digital transmitter outside of that city and an analog tower in New Jersey, and MeTV affiliate KJWP is licensed to Wilmington but maintains their offices in New Jersey and their transmitter is located at the antenna farm in Philadelphia.

In April 2014, it was revealed that Rehoboth Beach's WRDE-LD would affiliate with NBC, becoming the first major network-affiliated station in Delaware.

In addition to First State National Historical Park, Delaware has several museums, , , , , and other .

Rehoboth Beach, together with the towns of Lewes, Dewey Beach, Bethany Beach, South Bethany, and Fenwick Island, comprise Delaware's beach resorts. Rehoboth Beach often bills itself as "The Nation's Summer Capital" because it is a frequent summer vacation destination for Washington, D.C. residents as well as visitors from Maryland, Virginia, and in lesser numbers, Pennsylvania. Vacationers are drawn for many reasons, including the town's charm, artistic appeal, nightlife, and tax free shopping. According to SeaGrant Delaware, the Delaware Beaches generate $6.9 billion annually and over $711 million in tax revenue.

Delaware is home to several festivals, fairs, and events. Some of the more notable festivals are the Riverfest held in Seaford, the World Championship Punkin Chunkin formerly held at various locations throughout the state since 1986, the Rehoboth Beach Chocolate Festival, the Bethany Beach Jazz Funeral to mark the end of summer, the Apple Scrapple Festival held in Bridgeville, the Clifford Brown Jazz Festival in Wilmington, the Rehoboth Beach Jazz Festival, the Sea Witch Halloween Festival and Parade in Rehoboth Beach, the Rehoboth Beach Independent Film Festival, the Nanticoke Indian Pow Wow in Oak Orchard, Firefly Music Festival, and the Return Day Parade held after every election in Georgetown.

In 2015, tourism in Delaware generated $3.1 billion, which makes up of 5 percent of the state's GDP. Delaware saw 8.5 million visitors in 2015, with the tourism industry employing 41,730 people, making it the 4th largest private employer in the state. Major origin markets for Delaware tourists include Philadelphia, Baltimore, New York City, Washington, D.C., and Harrisburg, with 97% of tourists arriving to the state by car and 75% of tourists coming from or less.

As Delaware has no franchises in the major American professional sports leagues, many Delawareans follow either Philadelphia or Baltimore teams. The University of Delaware's football team has a large following throughout the state with the Delaware State University and Wesley College teams also enjoying a smaller degree of support.

Delaware is home to Dover International Speedway and Dover Downs. DIS, also known as the "Monster Mile", hosts two NASCAR race weekends each year, one in the late spring and one in the early fall. Dover Downs is a popular harness racing facility. It is the only co-located horse and car-racing facility in the nation, with the Dover Downs track inside the DIS track.

Delaware is represented in USA Rugby League by 2015 expansion club, the Delaware Black Foxes.

Delaware has been home to professional wrestling outfit Combat Zone Wrestling (CZW). CZW has been affiliated with the annual Tournament of Death and ECWA with its annual Super 8 Tournament.

Delaware's official state sport is bicycling.

Delaware is also the name of a Native American group (called in their own language Lenni Lenape) that was influential in the colonial period of the United States and is today headquartered in Cheswold, Kent County, Delaware. A band of the Nanticoke tribe of American Indians today resides in Sussex County and is headquartered in Millsboro, Sussex County, Delaware.


History
General


</doc>
<doc id="7931" url="https://en.wikipedia.org/wiki?curid=7931" title="Dictionary">
Dictionary

A dictionary, sometimes known as a wordbook, is a collection of words in one or more specific languages, often arranged alphabetically (or by radical and stroke for ideographic languages), which may include information on definitions, usage, etymologies, pronunciations, translation, etc. or a book of words in one language with their equivalents in another, sometimes known as a lexicon. It is a lexicographical product which shows inter-relationships among the data.

A broad distinction is made between general and specialized dictionaries. Specialized dictionaries include words in specialist fields, rather than a complete range of words in the language. Lexical items that describe concepts in specific fields are usually called terms instead of words, although there is no consensus whether lexicology and terminology are two different fields of study. In theory, general dictionaries are supposed to be semasiological, mapping word to definition, while specialized dictionaries are supposed to be onomasiological, first identifying concepts and then establishing the terms used to designate them. In practice, the two approaches are used for both types. There are other types of dictionaries that do not fit neatly into the above distinction, for instance bilingual (translation) dictionaries, dictionaries of synonyms (thesauri), and rhyming dictionaries. The word dictionary (unqualified) is usually understood to refer to a general purpose monolingual dictionary.

There is also a contrast between "prescriptive" or "descriptive" dictionaries; the former reflect what is seen as correct use of the language while the latter reflect recorded actual use. Stylistic indications (e.g. "informal" or "vulgar") in many modern dictionaries are also considered by some to be less than objectively descriptive.

Although the first recorded dictionaries date back to Sumerian times (these were bilingual dictionaries), the systematic study of dictionaries as objects of scientific interest themselves is a 20th-century enterprise, called lexicography, and largely initiated by Ladislav Zgusta. The birth of the new discipline was not without controversy, the practical dictionary-makers being sometimes accused by others of "astonishing" lack of method and critical-self reflection.

The oldest known dictionaries were Akkadian Empire cuneiform tablets with bilingual Sumerian–Akkadian wordlists, discovered in Ebla (modern Syria) and dated roughly 2300 BCE. The early 2nd millennium BCE "Urra=hubullu" glossary is the canonical Babylonian version of such bilingual Sumerian wordlists. A Chinese dictionary, the c. 3rd century BCE "Erya", was the earliest surviving monolingual dictionary; although some sources cite the c. 800 BCE Shizhoupian as a "dictionary", modern scholarship considers it a calligraphic compendium of Chinese characters from Zhou dynasty bronzes. Philitas of Cos (fl. 4th century BCE) wrote a pioneering vocabulary "Disorderly Words" (Ἄτακτοι γλῶσσαι, "") which explained the meanings of rare Homeric and other literary words, words from local dialects, and technical terms. Apollonius the Sophist (fl. 1st century CE) wrote the oldest surviving Homeric lexicon. The first Sanskrit dictionary, the Amarakośa, was written by Amara Sinha c. 4th century CE. Written in verse, it listed around 10,000 words. According to the "Nihon Shoki", the first Japanese dictionary was the long-lost 682 CE "Niina" glossary of Chinese characters. The oldest existing Japanese dictionary, the c. 835 CE "Tenrei Banshō Meigi", was also a glossary of written Chinese. In "Frahang-i Pahlavig", Aramaic heterograms are listed together with their translation in Middle Persian language and phonetic transcription in Pazand alphabet. A 9th-century CE Irish dictionary, Sanas Cormaic, contained etymologies and explanations of over 1,400 Irish words. In India around 1320, Amir Khusro compiled the Khaliq-e-bari which mainly dealt with Hindustani and Persian words.
Arabic dictionaries were compiled between the 8th and 14th centuries CE, organizing words in rhyme order (by the last syllable), by alphabetical order of the radicals, or according to the alphabetical order of the first letter (the system used in modern European language dictionaries). The modern system was mainly used in specialist dictionaries, such as those of terms from the Qur'an and hadith, while most general use dictionaries, such as the "Lisan al-`Arab" (13th century, still the best-known large-scale dictionary of Arabic) and "al-Qamus al-Muhit" (14th century) listed words in the alphabetical order of the radicals. The "Qamus al-Muhit" is the first handy dictionary in Arabic, which includes only words and their definitions, eliminating the supporting examples used in such dictionaries as the "Lisan" and the "Oxford English Dictionary".
In medieval Europe, glossaries with equivalents for Latin words in vernacular or simpler Latin were in use (e.g. the Leiden Glossary). The "Catholicon" (1287) by Johannes Balbus, a large grammatical work with an alphabetical lexicon, was widely adopted. It served as the basis for several bilingual dictionaries and was one of the earliest books (in 1460) to be printed. In 1502 Ambrogio Calepino's "Dictionarium" was published, originally a monolingual Latin dictionary, which over the course of the 16th century was enlarged to become a multilingual glossary. In 1532 Robert Estienne published the "Thesaurus linguae latinae" and in 1572 his son Henri Estienne published the "Thesaurus linguae graecae", which served up to the 19th century as the basis of Greek lexicography. The first monolingual dictionary written in Europe was the Spanish, written by Sebastián Covarrubias' "Tesoro de la lengua castellana o española", published in 1611 in Madrid, Spain. In 1612 the first edition of the "Vocabolario dell'Accademia della Crusca", for Italian, was published. It served as the model for similar works in French and English. In 1690 in Rotterdam was published, posthumously, the "Dictionnaire Universel" by Antoine Furetière for French. In 1694 appeared the first edition of the "Dictionnaire de l'Académie française". Between 1712 and 1721 was published the "Vocabulario portughez e latino" written by Raphael Bluteau. The Real Academia Española published the first edition of the "Diccionario de la lengua española" in 1780, but their "Diccionario de Autoridades", which included quotes taken from literary works, was published in 1726. The "Totius Latinitatis lexicon" by Egidio Forcellini was firstly published in 1777; it has formed the basis of all similar works that have since been published.

The first edition of "A Greek-English Lexicon" by Henry George Liddell and Robert Scott appeared in 1843; this work remained the basic dictionary of Greek until the end of the 20th century. And in 1858 was published the first volume of the Deutsches Wörterbuch by the Brothers Grimm; the work was completed in 1961. Between 1861 and 1874 was published the "Dizionario della lingua italiana" by Niccolò Tommaseo. Between 1862 and 1874 was published the six volumes of "A magyar nyelv szótára" (Dictionary of Hungarian Language) by Gergely Czuczor and János Fogarasi. Émile Littré published the Dictionnaire de la langue française between 1863 and 1872. In the same year 1863 appeared the first volume of the "Woordenboek der Nederlandsche Taal" which was completed in 1998. Also in 1863 Vladimir Ivanovich Dahl published the "Explanatory Dictionary of the Living Great Russian Language". The Duden dictionary dates back to 1880, and is currently the prescriptive source for the spelling of German. The decision to start work on the "Svenska Akademiens ordbok" was taken in 1787.

The earliest dictionaries in the English language were glossaries of French, Spanish or Latin words along with their definitions in English. The word "dictionary" was invented by an Englishman called John of Garland in 1220 — he had written a book "Dictionarius" to help with Latin "diction". An early non-alphabetical list of 8000 English words was the "Elementarie", created by Richard Mulcaster in 1582.

The first purely English alphabetical dictionary was "A Table Alphabeticall", written by English schoolteacher Robert Cawdrey in 1604. The only surviving copy is found at the Bodleian Library in Oxford. This dictionary, and the many imitators which followed it, was seen as unreliable and nowhere near definitive. Philip Stanhope, 4th Earl of Chesterfield was still lamenting in 1754, 150 years after Cawdrey's publication, that it is "a sort of disgrace to our nation, that hitherto we have had no… standard of our language; our dictionaries at present being more properly what our neighbors the Dutch and the Germans call theirs, word-books, than dictionaries in the superior sense of that title." 

In 1616, John Bullokar described the history of the dictionary with his "English Expositor". "Glossographia" by Thomas Blount, published in 1656, contains more than 10,000 words along with their etymologies or histories. Edward Phillips wrote another dictionary in 1658, entitled "The New World of English Words: Or a General Dictionary" which boldly plagiarized Blount's work, and the two denounced each other. This created more interest in the dictionaries. John Wilkins' 1668 essay on philosophical language contains a list of 11,500 words with careful distinctions, compiled by William Lloyd. Elisha Coles published his "English Dictionary" in 1676.

It was not until Samuel Johnson's "A Dictionary of the English Language" (1755) that a more reliable English dictionary was produced. Many people today mistakenly believe that Johnson wrote the first English dictionary: a testimony to this legacy. By this stage, dictionaries had evolved to contain textual references for most words, and were arranged alphabetically, rather than by topic (a previously popular form of arrangement, which meant all animals would be grouped together, etc.). Johnson's masterwork could be judged as the first to bring all these elements together, creating the first "modern" dictionary.

Johnson's dictionary remained the English-language standard for over 150 years, until the Oxford University Press began writing and releasing the "Oxford English Dictionary" in short fascicles from 1884 onwards. It took nearly 50 years to complete this huge work, and they finally released the complete "OED" in twelve volumes in 1928. It remains the most comprehensive and trusted English language dictionary to this day, with revisions and updates added by a dedicated team every three months. One of the main contributors to this modern dictionary was an ex-army surgeon, William Chester Minor, a convicted murderer who was confined to an asylum for the criminally insane.

In 1806, American Noah Webster published his first dictionary, "". In 1807 Webster began compiling an expanded and fully comprehensive dictionary, "An American Dictionary of the English Language;" it took twenty-seven years to complete. To evaluate the etymology of words, Webster learned twenty-six languages, including Old English (Anglo-Saxon), German, Greek, Latin, Italian, Spanish, French, Hebrew, Arabic, and Sanskrit.

Webster completed his dictionary during his year abroad in 1825 in Paris, France, and at the University of Cambridge. His book contained seventy thousand words, of which twelve thousand had never appeared in a published dictionary before. As a spelling reformer, Webster believed that English spelling rules were unnecessarily complex, so his dictionary introduced American English spellings, replacing "colour" with "color", substituting "wagon" for "waggon", and printing "center" instead of "centre". He also added American words, like "skunk" and "squash", that did not appear in British dictionaries. At the age of seventy, Webster published his dictionary in 1828; it sold 2500 copies. In 1840, the second edition was published in two volumes.

In a general dictionary, each word may have multiple meanings. Some dictionaries include each separate meaning in the order of most common usage while others list definitions in historical order, with the oldest usage first.

In many languages, words can appear in many different forms, but only the undeclined or unconjugated form appears as the headword in most dictionaries. Dictionaries are most commonly found in the form of a book, but some newer dictionaries, like StarDict and the "New Oxford American Dictionary" are dictionary software running on PDAs or computers. There are also many online dictionaries accessible via the Internet.

According to the "Manual of Specialized Lexicographies", a specialized dictionary, also referred to as a technical dictionary, is a dictionary that focuses upon a specific subject field. Following the description in "The Bilingual LSP Dictionary", lexicographers categorize specialized dictionaries into three types: A multi-field dictionary broadly covers several subject fields (e.g. a business dictionary), a single-field dictionary narrowly covers one particular subject field (e.g. law), and a sub-field dictionary covers a more specialized field (e.g. constitutional law). For example, the 23-language Inter-Active Terminology for Europe is a multi-field dictionary, the American National Biography is a single-field, and the African American National Biography Project is a sub-field dictionary. In terms of the coverage distinction between "minimizing dictionaries" and "maximizing dictionaries", multi-field dictionaries tend to minimize coverage across subject fields (for instance, "Oxford Dictionary of World Religions" and "Yadgar Dictionary of Computer and Internet Terms") whereas single-field and sub-field dictionaries tend to maximize coverage within a limited subject field ("The Oxford Dictionary of English Etymology").

Another variant is the glossary, an alphabetical list of defined terms in a specialized field, such as medicine (medical dictionary).

The simplest dictionary, a defining dictionary, provides a core glossary of the simplest meanings of the simplest concepts. From these, other concepts can be explained and defined, in particular for those who are first learning a language. In English, the commercial defining dictionaries typically include only one or two meanings of under 2000 words. With these, the rest of English, and even the 4000 most common English idioms and metaphors, can be defined.

Lexicographers apply two basic philosophies to the defining of words: "prescriptive" or "descriptive". Noah Webster, intent on forging a distinct identity for the American language, altered spellings and accentuated differences in meaning and pronunciation of some words. This is why American English now uses the spelling "color" while the rest of the English-speaking world prefers "colour". (Similarly, British English subsequently underwent a few spelling changes that did not affect American English; see further at American and British English spelling differences.)

Large 20th-century dictionaries such as the "Oxford English Dictionary" (OED) and "Webster's Third" are descriptive, and attempt to describe the actual use of words. Most dictionaries of English now apply the descriptive method to a word's definition, and then, outside of the definition itself, and information alerting readers to attitudes which may influence their choices on words often considered vulgar, offensive, erroneous, or easily confused. "Merriam-Webster" is subtle, only adding italicized notations such as, "sometimes offensive" or "stand" (nonstandard). "American Heritage" goes further, discussing issues separately in numerous "usage notes." "Encarta" provides similar notes, but is more prescriptive, offering warnings and admonitions against the use of certain words considered by many to be offensive or illiterate, such as, "an offensive term for..." or "a taboo term meaning...".

Because of the widespread use of dictionaries in schools, and their acceptance by many as language authorities, their treatment of the language does affect usage to some degree, with even the most descriptive dictionaries providing conservative continuity. In the long run, however, the meanings of words in English are primarily determined by usage, and the language is being changed and created every day. As Jorge Luis Borges says in the prologue to "El otro, el mismo": ""It is often forgotten that (dictionaries) are artificial repositories, put together well after the languages they define. The roots of language are irrational and of a magical nature.""

Sometimes the same dictionary can be descriptive in some domains and prescriptive in others. For example, according to Ghil'ad Zuckermann, the "Oxford English-Hebrew Dictionary" is "at war with itself": whereas its coverage (lexical items) and glosses (definitions) are descriptive and colloquial, its vocalization is prescriptive. This internal conflict results in absurd sentences such as "hi taharóg otí kshetiré me asíti lamkhonít" (she'll tear me apart when she sees what I've done to the car). Whereas "hi taharóg otí", literally 'she will kill me', is colloquial, me (a variant of ma 'what') is archaic, resulting in a combination that is unutterable in real life.

A historical dictionary is a specific kind of descriptive dictionary which describes the development of words and senses over time, usually using citations to original source material to support its conclusions.

In contrast to traditional dictionaries, which are designed to be used by human beings, dictionaries for natural language processing (NLP) are built to be used by computer programs. The final user is a human being but the direct user is a program. Such a dictionary does not need to be able to be printed on paper. The structure of the content is not linear, ordered entry by entry but has the form of a complex network (see Diathesis alternation). Because most of these dictionaries are used to control machine translations or cross-lingual information retrieval (CLIR) the content is usually multilingual and usually of huge size. In order to allow formalized exchange and merging of dictionaries, an ISO standard called Lexical Markup Framework (LMF) has been defined and used among the industrial and academic community.


In many languages, such as the English language, the pronunciation of some words is not apparent from their spelling. In these languages, dictionaries usually provide the pronunciation. For example, the definition for the word "dictionary" might be followed by the International Phonetic Alphabet spelling . American English dictionaries often use their own pronunciation respelling systems with diacritics, for example "dictionary" is respelled as "dĭk′shə-nĕr′ē" in the American Heritage Dictionary. The IPA is more commonly used within the British Commonwealth countries. Yet others use their own pronunciation respelling systems without diacritics: for example, "dictionary" may be respelled as . Some online or electronic dictionaries provide audio recordings of words being spoken.

Histories and descriptions of the dictionaries of other languages include:


The age of the Internet brought online dictionaries to the desktop and, more recently, to the smart phone. David Skinner in 2013 noted that "Among the top ten lookups on Merriam-Webster Online at this moment are 'holistic, pragmatic, caveat, esoteric' and 'bourgeois.' Teaching users about words they don’t already know has been, historically, an aim of lexicography, and modern dictionaries do this well."
There exist a number of websites which operate as online dictionaries, usually with a specialized focus. Some of them have exclusively user driven content, often consisting of neologisms. Some of the more notable examples include:





</doc>
<doc id="7935" url="https://en.wikipedia.org/wiki?curid=7935" title="David D. Friedman">
David D. Friedman

David Director Friedman (born February 12, 1945) is an American economist, physicist, legal scholar, and libertarian theorist. He is known for his textbook writings on microeconomics and the libertarian theory of anarcho-capitalism, which is the subject of his most popular book, "The Machinery of Freedom". Besides "The Machinery of Freedom", he has authored several other books and articles, including "Price Theory: An Intermediate Text" (1986), "Law's Order: What Economics Has to Do with Law and Why It Matters" (2000), "Hidden Order: The Economics of Everyday Life" (1996), and "Future Imperfect" (2008).

David Friedman is the son of economists Rose and Milton Friedman. He graduated "magna cum laude" from Harvard University in 1965, with a bachelor's degree in chemistry and physics. He later earned a master's (1967) and a Ph.D. (1971) in theoretical physics from the University of Chicago. Despite his later career, he never took a class for credit in either economics or law. He is currently a professor of law at Santa Clara University, and a contributing editor for "Liberty" magazine. He is an atheist. His son, Patri Friedman, has also written about libertarian theory and market anarchism, particularly seasteading.

In his book "The Machinery of Freedom" (1973), Friedman sketched a form of anarcho-capitalism where all goods and services including law itself can be produced by the free market. This differs from the version proposed by Murray Rothbard, where a legal code would first be consented to by the parties involved in setting up the anarcho-capitalist society. Friedman advocates an incrementalist approach to achieve anarcho-capitalism by gradual privatization of areas that government is involved in, ultimately privatizing law and order itself. In the book, he states his opposition to violent anarcho-capitalist revolution.

He advocates a consequentialist version of anarcho-capitalism, arguing for anarchism on a cost-benefit analysis of state versus no state. It is contrasted with the natural-rights approach as propounded most notably by economist and libertarian theorist Murray Rothbard.

Friedman is a longtime member of the Society for Creative Anachronism, where he is known as "Duke Cariadoc of the Bow". He is known throughout the worldwide society for his articles on the philosophy of recreationism and practical historical recreations, especially those relating to the medieval Middle East. His work is compiled in the popular "Cariadoc's Miscellany". He is sometimes credited with founding the largest and longest-running SCA event, the Pennsic War; as king of the Middle Kingdom he challenged the East Kingdom, and later as king of the East accepted the challenge...and lost.

He is a long-time science fiction fan, and has written two fantasy novels, "Harald" (Baen Books, 2006) and "Salamander" (2011).

He has spoken in favor of a non-interventionist foreign policy.





</doc>
<doc id="7938" url="https://en.wikipedia.org/wiki?curid=7938" title="Diatomic molecule">
Diatomic molecule

Diatomic molecules are molecules composed of only two atoms, of the same or different chemical elements. The prefix "di-" is of Greek origin, meaning "two". If a diatomic molecule consists of two atoms of the same element, such as hydrogen (H) or oxygen (O), then it is said to be homonuclear. Otherwise, if a diatomic molecule consists of two different atoms, such as carbon monoxide (CO) or nitric oxide (NO), the molecule is said to be heteronuclear.

The only chemical elements that form stable homonuclear diatomic molecules at standard temperature and pressure (STP) (or typical laboratory conditions of 1 bar and 25 °C) are the gases hydrogen (H), nitrogen (N), oxygen (O), fluorine (F), and chlorine (Cl).

The noble gases (helium, neon, argon, krypton, xenon, and radon) are also gases at STP, but they are monatomic. The homonuclear diatomic gases and noble gases together are called "elemental gases" or "molecular gases", to distinguish them from other gases that are chemical compounds.

At slightly elevated temperatures, the halogens bromine (Br) and iodine (I) also form diatomic gases. All halogens have been observed as diatomic molecules, except for astatine, which is uncertain.

The mnemonics BrINClHOF, pronounced "Brinklehof", and HONClBrIF, pronounced "Honkelbrif", have been coined to aid recall of the list of diatomic elements.

Other elements form diatomic molecules when evaporated, but these diatomic species repolymerize when cooled. Heating ("cracking") elemental phosphorus gives diphosphorus, P. Sulfur vapor is mostly disulfur (S). Dilithium (Li) is known in the gas phase. Ditungsten (W) and dimolybdenum (Mo) form with sextuple bonds in the gas phase. The bond in a homonuclear diatomic molecule is non-polar. Dirubidium is diatomic.

All other diatomic molecules are chemical compounds of two different elements. Many elements can combine to form heteronuclear diatomic molecules, depending on temperature and pressure.

Common examples include the gases carbon monoxide (CO), nitric oxide (NO), and hydrogen chloride (HCl).

Many 1:1 binary compounds are not normally considered diatomic because they are polymeric at room temperature, but they form diatomic molecules when evaporated, for example gaseous MgO, SiO, and many others.

Hundreds of diatomic molecules have been identified in the environment of the Earth, in the laboratory, and in interstellar space. About 99% of the Earth's atmosphere is composed of two species of diatomic molecules: nitrogen (78%) and oxygen (21%). The natural abundance of hydrogen (H) in the Earth's atmosphere is only of the order of parts per million, but H is the most abundant diatomic molecule in the universe. The interstellar medium is, indeed, dominated by hydrogen atoms.

Diatomic elements played an important role in the elucidation of the concepts of element, atom, and molecule in the 19th century, because some of the most common elements, such as hydrogen, oxygen, and nitrogen, occur as diatomic molecules. John Dalton's original atomic hypothesis assumed that all elements were monatomic and that the atoms in compounds would normally have the simplest atomic ratios with respect to one another. For example, Dalton assumed water's formula to be HO, giving the atomic weight of oxygen as eight times that of hydrogen, instead of the modern value of about 16. As a consequence, confusion existed regarding atomic weights and molecular formulas for about half a century.

As early as 1805, Gay-Lussac and von Humboldt showed that water is formed of two volumes of hydrogen and one volume of oxygen, and by 1811 Amedeo Avogadro had arrived at the correct interpretation of water's composition, based on what is now called Avogadro's law and the assumption of diatomic elemental molecules. However, these results were mostly ignored until 1860, partly due to the belief that atoms of one element would have no chemical affinity toward atoms of the same element, and also partly due to apparent exceptions to Avogadro's law that were not explained until later in terms of dissociating molecules.

At the 1860 Karlsruhe Congress on atomic weights, Cannizzaro resurrected Avogadro's ideas and used them to produce a consistent table of atomic weights, which mostly agree with modern values. These weights were an important prerequisite for the discovery of the periodic law by Dmitri Mendeleev and Lothar Meyer.

Diatomic molecules are normally in their lowest or ground state, which conventionally is also known as the formula_1 state. When a gas of diatomic molecules is bombarded by energetic electrons, some of the molecules may be excited to higher electronic states, as occurs, for example, in the natural aurora; high-altitude nuclear explosions; and rocket-borne electron gun experiments. Such excitation can also occur when the gas absorbs light or other electromagnetic radiation. The excited states are unstable and naturally relax back to the ground state. Over various short time scales after the excitation (typically a fraction of a second, or sometimes longer than a second if the excited state is metastable), transitions occur from higher to lower electronic states and ultimately to the ground state, and in each transition results a photon is emitted. This emission is known as fluorescence. Successively higher electronic states are conventionally named formula_2, formula_3, formula_4, etc. (but this convention is not always followed, and sometimes lower case letters and alphabetically out-of-sequence letters are used, as in the example given below). The excitation energy must be greater than or equal to the energy of the electronic state in order for the excitation to occur.

In quantum theory, an electronic state of a diatomic molecule is represented by

where formula_6 is the total electronic spin quantum number, formula_7 is the total electronic angular momentum quantum number along the internuclear axis, and formula_8 is the vibrational quantum number. formula_7 takes on values 0, 1, 2, …, which are represented by the electronic state symbols formula_10, formula_11, formula_12,….
For example, the following table lists the common electronic states (without vibrational quantum numbers) along with the energy of the lowest vibrational level (formula_13) of diatomic nitrogen (N), the most abundant gas in the Earth's atmosphere. In the table, the subscripts and superscripts after formula_7 give additional quantum mechanical details about the electronic state.

Note: The "energy" units in the above table are actually the reciprocal of the wavelength of a photon emitted in a transition to the lowest energy state. The actual energy can be found by multiplying the given statistic by the product of "c" (the speed of light) and "h" (Planck's constant), i.e., about 1.99 × 10 Joule metres, and then multiplying by a further factor of 100 to convert from cm to m.

The aforementioned fluorescence occurs in distinct regions of the electromagnetic spectrum, called "emission bands": each band corresponds to a particular transition from a higher electronic state and vibrational level to a lower electronic state and vibrational level (typically, many vibrational levels are involved in an excited gas of diatomic molecules). For example, N formula_2-formula_1 emission bands (a.k.a. Vegard-Kaplan bands) are present in the spectral range from 0.14 to 1.45 μm (micrometres). A given band can be spread out over several nanometers in electromagnetic wavelength space, owing to the various transitions that occur in the molecule's rotational quantum number, formula_17. These are classified into distinct sub-band branches, depending on the change in formula_17. The formula_19 branch corresponds to formula_20, the formula_21 branch to formula_22, and the formula_23 branch to formula_24. Bands are spread out even further by the limited spectral resolution of the spectrometer that is used to measure the spectrum. The spectral resolution depends on the instrument's point spread function.

The molecular term symbol is a shorthand expression of the angular momenta that characterize the electronic quantum states of a diatomic molecule, which are eigenstates of the electronic molecular Hamiltonian. It is also convenient, and common, to represent a diatomic molecule as two point masses connected by a massless spring. The energies involved in the various motions of the molecule can then be broken down into three categories: the translational, rotational, and vibrational energies.

The translational energy of the molecule is given by the kinetic energy expression:

where formula_26 is the mass of the molecule and formula_8 is its velocity.

Classically, the kinetic energy of rotation is

For microscopic, atomic-level systems like a molecule, angular momentum can only have specific discrete values given by

Also, for a diatomic molecule the moment of inertia is

So, substituting the angular momentum and moment of inertia into E, the rotational energy levels of a diatomic molecule are given by:

Another type of motion of a diatomic molecule is for each atom to oscillate—or vibrate—along the line connecting the two atoms. The vibrational energy is approximately that of a quantum harmonic oscillator:

The spacing, and the energy of a typical spectroscopic transition, between vibrational energy levels is about 100 times greater than that of a typical transition between rotational energy levels.

The good quantum numbers for a diatomic molecule, as well as good approximations of rotational energy levels, can be obtained by modeling the molecule using Hund's cases.





</doc>
<doc id="7939" url="https://en.wikipedia.org/wiki?curid=7939" title="Duopoly">
Duopoly

A duopoly (from Greek δύο, "duo" (two) + πωλεῖν, "polein" (to sell)) is a form of oligopoly where only two sellers exist in one market. In practice, the term is also used where two firms have dominant control over a market. It is the most commonly studied form of oligopoly due to its simplicity.

There are two principal duopoly models, Cournot duopoly and Bertrand duopoly:


Modern American politics, in particular the electoral college system has been described as duopolistic since the Republican and Democratic parties have dominated and framed policy debate as well as the public discourse on matters of national concern for about a century and a half. Third Parties have encountered various blocks in getting onto ballots at different levels of government as well as other electoral obstacles, such as denial of access to general election debates.

A commonly cited example of a duopoly is that involving Visa and MasterCard, who between them control a large proportion of the electronic payment processing market. In 2000 they were the defendants in a U.S. Department of Justice antitrust lawsuit. An appeal was upheld in 2004.

Examples where two companies control a large proportion of a market are:

In Finland, the state-owned broadcasting company Yleisradio and the private broadcaster Mainos-TV had a legal duopoly (in the economists' sense of the word) from the 1950s to 1993. No other broadcasters were allowed. Mainos-TV operated by leasing air time from Yleisradio, broadcasting in reserved blocks between Yleisradio's own programming on its two channels. This was a unique phenomenon in the world. Between 1986 and 1992 there was an independent third channel but it was jointly owned by Yle and MTV; only in 1993 did MTV get its own channel.

In the United Kingdom, the BBC and ITV formed an effective duopoly (with Channel 4 originally being economically dependent on ITV) until the development of multichannel from the 1990s onwards.

Safaricom mobile service provider and Airtel in Kenya are perfect examples of Duopoly market in the African telecommunication industry.

Duopoly is also used in the United States broadcast television and radio industry to refer to a single company owning two outlets in the same city.

This usage is technically incompatible with the normal definition of the word and may lead to confusion, inasmuch as there are generally more than two owners of broadcast television stations in markets with broadcast duopolies. In Canada, this definition is therefore more commonly called a "twinstick".



</doc>
<doc id="7940" url="https://en.wikipedia.org/wiki?curid=7940" title="Dungeons &amp; Dragons">
Dungeons &amp; Dragons

Dungeons & Dragons (abbreviated as D&D or DnD) is a fantasy tabletop role-playing game (RPG) originally designed by Gary Gygax and Dave Arneson. It was first published in 1974 by Tactical Studies Rules, Inc. (TSR). The game has been published by Wizards of the Coast (now a subsidiary of Hasbro) since 1997. It was derived from miniature wargames with a variation of Chainmail serving as the initial rule system. "D&D" publication is commonly recognized as the beginning of modern role-playing games and the role-playing game industry.

"D&D" departs from traditional wargaming and assigns each player a specific character to play instead of a military formation. These characters embark upon imaginary adventures within a fantasy setting. A Dungeon Master serves as the game's referee and storyteller while maintaining the setting in which the adventures occur, and playing the role of the inhabitants. The characters form a party that interacts with the setting's inhabitants, and each other. Together they solve dilemmas, engage in battles, and gather treasure and knowledge. In the process the characters earn experience points in order to rise in levels, and become increasingly powerful over a series of sessions.

The early success of "Dungeons & Dragons" led to a proliferation of similar game systems. Despite the competition, "D&D" has remained as the market leader in the role-playing game industry. In 1977, the game was split into two branches: the relatively rules-light game system of basic "Dungeons & Dragons" and the more structured, rules-heavy game system of "Advanced Dungeons & Dragons" (abbreviated as "AD&D"). "AD&D" 2nd Edition was published in 1989. In 2000, a new system was released as "Dungeons & Dragons" 3rd edition. These rules formed the basis of the d20 System which is available under the Open Game License (OGL) for use by other publishers. "Dungeons & Dragons" version 3.5 was released in June 2003, with a (non-OGL) 4th edition in June 2008. A 5th edition was released during the second half of 2014.

, "Dungeons & Dragons" remained the best-known and best-selling role-playing game, with an estimated 20 million people having played the game and more than US$1 billion in book and equipment sales. The game has been supplemented by many pre-made adventures as well as commercial campaign settings suitable for use by regular gaming groups. "Dungeons & Dragons" is known beyond the game for other "D&D"-branded products, references in popular culture, and some of the controversies that have surrounded it, particularly a moral panic in the 1980s falsely linking it to Satanism and suicide. The game has won multiple awards and has been translated into many languages beyond the original English.

"Dungeons & Dragons" is a structured yet open-ended role-playing game. It is normally played indoors with the participants seated around a tabletop. Typically, each player controls only a single character, which represents an individual in a fictional setting. When working together as a group, these player characters (PCs) are often described as a "party" of adventurers, with each member often having their own area of specialty which contributes to the success of the whole. During the course of play, each player directs the actions of their character and their interactions with other characters in the game. This activity is performed through the verbal impersonation of the characters by the players, while employing a variety of social and other useful cognitive skills, such as logic, basic mathematics and imagination. A game often continues over a series of meetings to complete a single adventure, and longer into a series of related gaming adventures, called a "campaign".

The results of the party's choices and the overall storyline for the game are determined by the Dungeon Master (DM) according to the rules of the game and the DM's interpretation of those rules. The DM selects and describes the various non-player characters (NPCs) that the party encounters, the settings in which these interactions occur, and the outcomes of those encounters based on the players' choices and actions. Encounters often take the form of battles with "monsters" – a generic term used in "D&D" to describe potentially hostile beings such as animals, aberrant beings, or mythical creatures. The game's extensive rules – which cover diverse subjects such as social interactions, magic use, combat, and the effect of the environment on PCs – help the DM to make these decisions. The DM may choose to deviate from the published rules or make up new ones if they feel it is necessary.

The most recent versions of the game's rules are detailed in three core rulebooks: The "Player's Handbook", the "Dungeon Master's Guide" and the "Monster Manual".

The only items required to play the game are the rulebooks, a character sheet for each player, and a number of polyhedral dice. Many players also use miniature figures on a grid map as a visual aid, particularly during combat. Some editions of the game presume such usage. Many optional accessories are available to enhance the game, such as expansion rulebooks, pre-designed adventures and various campaign settings.

Before the game begins, each player creates their player character and records the details (described below) on a character sheet. First, a player determines their character's ability scores, which consist of Strength, Constitution, Dexterity, Intelligence, Wisdom, and Charisma. Each edition of the game has offered differing methods of determining these statistics. The player then chooses a race (species) such as human or elf, a character class (occupation) such as fighter or wizard, an alignment (a moral and ethical outlook), and other features to round out the character's abilities and backstory, which have varied in nature through differing editions.

During the game, players describe their PC's intended actions, such as punching an opponent or picking a lock, and converse with the DM, who then describes the result or response. Trivial actions, such as picking up a letter or opening an unlocked door, are usually automatically successful. The outcomes of more complex or risky actions are determined by rolling dice. Factors contributing to the outcome include the character's ability scores, skills and the difficulty of the task. In circumstances where a character does not have control of an event, such as when a trap or magical effect is triggered or a spell is cast, a saving throw can be used to determine whether the resulting damage is reduced or avoided. In this case the odds of success are influenced by the character's class, levels and ability scores.

As the game is played, each PC changes over time and generally increases in capability. Characters gain (or sometimes lose) experience, skills and wealth, and may even alter their alignment or gain additional character classes. The key way characters progress is by earning experience points (XP), which happens when they defeat an enemy or accomplish a difficult task. Acquiring enough XP allows a PC to advance a level, which grants the character improved class features, abilities and skills. XP can be lost in some circumstances, such as encounters with creatures that drain life energy, or by use of certain magical powers that come with an XP cost.

Hit points (HP) are a measure of a character's vitality and health and are determined by the class, level and constitution of each character. They can be temporarily lost when a character sustains wounds in combat or otherwise comes to harm, and loss of HP is the most common way for a character to die in the game. Death can also result from the loss of key ability scores or character levels. When a PC dies, it is often possible for the dead character to be resurrected through magic, although some penalties may be imposed as a result. If resurrection is not possible or not desired, the player may instead create a new PC to resume playing the game.

A typical "Dungeons & Dragons" game consists of an "adventure", which is roughly equivalent to a single story. The DM can either design an adventure on their own, or follow one of the many pre-made adventures (also known as "modules") that have been published throughout the history of "Dungeons & Dragons". Published adventures typically include a background story, illustrations, maps and goals for PCs to achieve. Some include location descriptions and handouts. Although a small adventure entitled "Temple of the Frog" was included in the "Blackmoor" rules supplement in 1975, the first stand-alone "D&D" module published by TSR was 1978's "Steading of the Hill Giant Chief", written by Gygax.

A linked series of adventures is commonly referred to as a "campaign". The locations where these adventures occur, such as a city, country, planet or an entire fictional universe, are referred to as "campaign settings" or "world". "D&D" settings are based in various fantasy genres and feature different levels and types of magic and technology. Popular commercially published campaign settings for "Dungeons & Dragons" include Greyhawk, Dragonlance, Forgotten Realms, Mystara, Spelljammer, Ravenloft, Dark Sun, Planescape, Birthright, and Eberron. Alternatively, DMs may develop their own fictional worlds to use as campaign settings.

The wargames from which "Dungeons & Dragons" evolved used miniature figures to represent combatants. "D&D" initially continued the use of miniatures in a fashion similar to its direct precursors. The original "D&D" set of 1974 required the use of the "Chainmail" miniatures game for combat resolution. By the publication of the 1977 game editions, combat was mostly resolved verbally. Thus miniatures were no longer required for game play, although some players continued to use them as a visual reference.

In the 1970s, numerous companies began to sell miniature figures specifically for "Dungeons & Dragons" and similar games. Licensed miniature manufacturers who produced official figures include Grenadier Miniatures (1980–1983), Citadel Miniatures (1984–1986), Ral Partha, and TSR itself. Most of these miniatures used the 25 mm scale.

Periodically, "Dungeons & Dragons" has returned to its wargaming roots with supplementary rules systems for miniatures-based wargaming. Supplements such as "Battlesystem" (1985 & 1989) and a new edition of "Chainmail" (2001) provided rule systems to handle battles between armies by using miniatures.

An immediate predecessor of "Dungeons & Dragons" was a set of medieval miniature rules written by Jeff Perren. These were expanded by Gary Gygax, whose additions included a fantasy supplement, before the game was published as "Chainmail". When Dave Wesely entered the Army in 1970, his friend and fellow Napoleonics wargamer Dave Arneson began a medieval variation of Wesely's Braunstein games, where players control individuals instead of armies. Arneson used "Chainmail" to resolve combat. As play progressed, Arneson added such innovations as character classes, experience points, level advancement, armor class, and others. Having partnered previously with Gygax on "Don't Give Up the Ship!", Arneson introduced Gygax to his Blackmoor game and the two then collaborated on developing "The Fantasy Game", the role-playing game (RPG) that became "Dungeons & Dragons", with the final writing and preparation of the text being done by Gygax. The name was chosen by Gygax's two-year-old daughter Cindy — upon being presented with a number of choices of possible names, she exclaimed, "Oh Daddy, I like Dungeons and Dragons best!", although less prevalent versions of the story gave credit to his wife Mary Jo.

Many "Dungeons & Dragons" elements appear in hobbies of the mid-to-late 20th century. For example, character-based role playing can be seen in improvisational theatre. Game-world simulations were well developed in wargaming. Fantasy milieux specifically designed for gaming could be seen in Glorantha's board games among others. Ultimately, however, "Dungeons & Dragons" represents a unique blending of these elements.

The world of "D&D" was influenced by world mythology, history, pulp fiction, and contemporary fantasy novels. The importance of J. R. R. Tolkien's "The Lord of the Rings" and "The Hobbit" as an influence on "D&D" is controversial. The presence in the game of halflings, elves, half-elves, dwarves, orcs, rangers, and the like, draw comparisons to these works. The resemblance was even closer before the threat of copyright action from Tolkien Enterprises prompted the name changes of hobbit to 'halfling', ent to 'treant', and balrog to 'balor'. For many years, Gygax played down the influence of Tolkien on the development of the game. However, in an interview in 2000, he acknowledged that Tolkien's work had a "strong impact".

The "D&D" magic system, in which wizards memorize spells that are used up once cast and must be re-memorized the next day, was heavily influenced by the "Dying Earth" stories and novels of Jack Vance. The original alignment system (which grouped all characters and creatures into 'Law', 'Neutrality' and 'Chaos') was derived from the novel "Three Hearts and Three Lions" by Poul Anderson. A troll described in this work influenced the "D&D" definition of that monster.

Other influences include the works of Robert E. Howard, Edgar Rice Burroughs, A. Merritt, H. P. Lovecraft, Fritz Leiber, L. Sprague de Camp, Fletcher Pratt, Roger Zelazny, and Michael Moorcock. Monsters, spells, and magic items used in the game have been inspired by hundreds of individual works such as A. E. van Vogt's "Black Destroyer", Coeurl (the Displacer Beast), Lewis Carroll's "Jabberwocky" (vorpal sword) and the Book of Genesis (the clerical spell 'Blade Barrier' was inspired by the "flaming sword which turned every way" at the gates of Eden).

"Dungeons & Dragons" has gone through several revisions. Parallel versions and inconsistent naming practices can make it difficult to distinguish between the different editions.

The original "Dungeons & Dragons", now referred to as "OD&D", was a small box set of three booklets published in 1974. It was amateurish in production and assumed the player was familiar with wargaming. Nevertheless, it grew rapidly in popularity, first among wargamers and then expanding to a more general audience of college and high school students. Roughly 1,000 copies of the game were sold in the first year followed by 3,000 in 1975, and much more in the following years. This first set went through many printings and was supplemented with several official additions, such as the original Greyhawk and Blackmoor supplements (both 1975), as well as magazine articles in TSR's official publications and many fanzines.

In early 1977, TSR created the first element of a two-pronged strategy that would divide "D&D" for nearly two decades. A "Dungeons & Dragons Basic Set" boxed edition was introduced that cleaned up the presentation of the essential rules, made the system understandable to the general public, and was sold in a package that could be stocked in toy stores. Later in 1977, the first part of "Advanced Dungeons & Dragons" ("AD&D") was published, which brought together the various published rules, options and corrections, then expanded them into a definitive, unified game for hobbyist gamers. TSR marketed them as an introductory game for new players and a more complex game for experienced ones; the "Basic Set" directed players who exhausted the possibilities of that game to switch to the advanced rules.

As a result of this parallel development, the basic game included many rules and concepts which contradicted comparable ones in "AD&D". John Eric Holmes, the editor of the basic game, preferred a lighter tone with more room for personal improvisation. "AD&D", on the other hand, was designed to create a tighter, more structured game system than the loose framework of the original game. Between 1977 and 1979, three hardcover rulebooks, commonly referred to as the "core rulebooks", were released: the "Player's Handbook" (PHB), the "Dungeon Master's Guide" (DMG), and the "Monster Manual" (MM). Several supplementary books were published throughout the 1980s, notably "Unearthed Arcana" (1985) that included a large number of new rules. Confusing matters further, the original "D&D" boxed set remained in publication until 1979, since it remained a healthy seller for TSR.

In the 1980s, the rules for "Advanced Dungeons & Dragons" and "basic" "Dungeons & Dragons" remained separate, each developing along different paths.

In 1981, the basic version of "Dungeons & Dragons" was revised by Tom Moldvay to make it even more novice-friendly. It was promoted as a continuation of the original "D&D" tone, whereas "AD&D" was promoted as advancement of the mechanics. An accompanying "Expert Set", originally written by David "Zeb" Cook, allowed players to continue using the simpler ruleset beyond the early levels of play. In 1983, revisions of those sets by Frank Mentzer were released, revising the presentation of the rules to a more tutorial format. These were followed by "Companion" (1983), "Master" (1985), and "Immortals" (1986) sets. Each set covered game play for more powerful characters than the previous. The first four sets were compiled in 1991 as a single hardcover book, the "Dungeons & Dragons Rules Cyclopedia", which was released alongside a new introductory boxed set.

"Advanced Dungeons & Dragons 2nd Edition" was published in 1989, again as three core rulebooks; the primary designer was David "Zeb" Cook. The "Monster Manual" was replaced by the "Monstrous Compendium", a loose-leaf binder that was subsequently replaced by the hardcover "Monstrous Manual" in 1993. In 1995, the core rulebooks were slightly revised, although still referred to by TSR as the 2nd Edition, and a series of "Player's Option" manuals were released as optional rulebooks.

The release of "AD&D 2nd Edition" deliberately excluded some aspects of the game that had attracted negative publicity. References to demons and devils, sexually suggestive artwork, and playable, evil-aligned character types – such as assassins and half-orcs – were removed. The edition moved away from a theme of 1960s and 1970s "sword and sorcery" fantasy fiction to a mixture of medieval history and mythology. The rules underwent minor changes, including the addition of non-weapon proficiencies – skill-like abilities that originally appeared in 1st Edition supplements. The game's magic spells were divided into schools and spheres. A major difference was the promotion of various game settings beyond that of traditional fantasy. This included blending fantasy with other genres, such as horror (Ravenloft), science fiction (Spelljammer), and apocalyptic (Dark Sun), as well as alternative historical and non-European mythological settings.

In 1997, a near-bankrupt TSR was purchased by Wizards of the Coast. Following three years of development, "Dungeons & Dragons" 3rd edition was released in 2000. The new release folded the Basic and Advanced lines back into a single unified game. It was the largest revision of the "D&D" rules to date, and served as the basis for a multi-genre role-playing system designed around 20-sided dice, called the d20 System. The 3rd Edition rules were designed to be internally consistent and less restrictive than previous editions of the game, allowing players more flexibility to create the characters they wanted to play. Skills and feats were introduced into the core rules to encourage further customization of characters. The new rules standardized the mechanics of action resolution and combat. In 2003, "Dungeons & Dragons v.3.5" was released as a revision of the 3rd Edition rules. This release incorporated hundreds of rule changes, mostly minor, and expanded the core rulebooks.

In early 2005, Wizards of the Coast's R&D team started to develop "Dungeons & Dragons 4th Edition", prompted mainly by the feedback obtained from the "D&D" playing community and a desire to make the game faster, more intuitive, and with a better play experience than under the 3rd Edition. The new game was developed through a number of design phases spanning from May 2005 until its release. "Dungeons & Dragons 4th Edition" was announced at Gen Con in August 2007, and the initial three core books were released June 6, 2008. 4th Edition streamlined the game into a simplified form and introduced numerous rules changes. Many character abilities were restructured into "Powers". These altered the spell-using classes by adding abilities that could be used at will, per encounter, or per day. Likewise, non-magic-using classes were provided with parallel sets of options. Software tools, including player character and monster building programs, became a major part of the game.

On January 9, 2012, Wizards of the Coast announced that it was working on a 5th edition of the game. The company planned to take suggestions from players and let them playtest the rules. Public playtesting began on May 24, 2012. At Gen Con 2012 in August, Mike Mearls, lead developer for 5th Edition, said that Wizards of the Coast had received feedback from more than 75,000 playtesters, but that the entire development process would take two years, adding, "I can't emphasize this enough ... we're very serious about taking the time we need to get this right." The release of the 5th Edition, coinciding with "D&D"s 40th anniversary, occurred in the second half of 2014.

The game had more than three million players around the world by 1981, and copies of the rules were selling at a rate of about 750,000 per year by 1984. Beginning with a French language edition in 1982, "Dungeons & Dragons" has been translated into many languages beyond the original English. By 2004, consumers had spent more than US$1 billion on "Dungeons & Dragons" products and the game had been played by more than 20 million people. As many as six million people played the game in 2007.

The various editions of "Dungeons & Dragons" have won many Origins Awards, including "All Time Best Roleplaying Rules of 1977", "Best Roleplaying Rules of 1989", and "Best Roleplaying Game of 2000" for the three flagship editions of the game. Both "Dungeons & Dragons" and "Advanced Dungeons & Dragons" are Origins Hall of Fame Games inductees as they were deemed sufficiently distinct to merit separate inclusion on different occasions. The independent "Games" magazine placed "Dungeons & Dragons" on their "Games 100" list from 1980 through 1983, then entered the game into the magazine's Hall of Fame in 1984. "Advanced Dungeons & Dragons" was ranked 2nd in the 1996 reader poll of "Arcane" magazine to determine the 50 most popular roleplaying games of all time.

Eric Goldberg reviewed "Dungeons & Dragons" in "Ares Magazine" #1, rating it a 6 out of 9. Goldberg commented that ""Dungeons and Dragons" is an impressive achievement based on the concept alone, and also must be credited with cementing the marriage between the fantasy genre and gaming."

"Dungeons & Dragons" was the first modern role-playing game and it established many of the conventions that have dominated the genre. Particularly notable are the use of dice as a game mechanic, character record sheets, use of numerical attributes and gamemaster-centered group dynamics. Within months of "Dungeons & Dragons"'s release, new role-playing game writers and publishers began releasing their own role-playing games, with most of these being in the fantasy genre. Some of the earliest other role-playing games inspired by "D&D" include "Tunnels & Trolls" (1975), "Empire of the Petal Throne" (1975), and "Chivalry & Sorcery" (1976).

The role-playing movement initiated by "D&D" would lead to release of the science fiction game "Traveller" (1977), the fantasy game "RuneQuest" (1978), and subsequent game systems such as Chaosium's "Call of Cthulhu" (1981), "Champions" (1982), "GURPS" (1986), and "" (1991). "Dungeons & Dragons" and the games it influenced fed back into the genre's origin – miniatures wargames – with combat strategy games like "Warhammer Fantasy Battles". "D&D" also had a large impact on modern video games.

Director Jon Favreau credits "Dungeons & Dragons" with giving him "... a really strong background in imagination, storytelling, understanding how to create tone and a sense of balance."

Early in the game's history, TSR took no action against small publishers' production of "D&D" compatible material, and even licensed Judges Guild to produce "D&D" materials for several years, such as "City State of the Invincible Overlord." This attitude changed in the mid-1980s when TSR took legal action to try to prevent others from publishing compatible material. This angered many fans and led to resentment by the other gaming companies. Although TSR took legal action against several publishers in an attempt to restrict third-party usage, it never brought any court cases to completion, instead settling out of court in every instance. TSR itself ran afoul of intellectual property law in several cases.

With the launch of "Dungeons & Dragons"'s 3rd Edition, Wizards of the Coast made the d20 System available under the Open Game License (OGL) and d20 System trademark license. Under these licenses, authors were free to use the d20 System when writing games and game supplements. The OGL and d20 Trademark License made possible new games, some based on licensed products like "Star Wars", and new versions of older games, such as "Call of Cthulhu".

With the release of the fourth edition, Wizards of the Coast introduced its Game System License, which represented a significant restriction compared to the very open policies embodied by the OGL. In part as a response to this, some publishers (such as Paizo Publishing with its "Pathfinder Roleplaying Game") who previously produced materials in support of the "D&D" product line, decided to continue supporting the 3rd Edition rules, thereby competing directly with Wizards of the Coast. Others, such as Kenzer & Company, are returning to the practice of publishing unlicensed supplements and arguing that copyright law does not allow Wizards of the Coast to restrict third-party usage.

During the 2000s, there has been a trend towards reviving and recreating older editions of "D&D", known as the Old School Revival. Game systems based on earlier editions of "D&D". "Castles & Crusades" (2004), by Troll Lord Games, is a reimagining of early editions by streamlining rules from OGL. This in turn inspired the creation of "retro-clones", games which more closely recreate the original rule sets, using material placed under the OGL along with non-copyrightable mechanical aspects of the older rules to create a new presentation of the games.

Alongside the publication of the fifth edition, Wizards of the Coast established a two-pronged licensing approach. The core of the fifth edition rules have been made available under the OGL, while publishers and independent creators have also been given the opportunity to create licensed materials directly for Dungeons & Dragons and associated properties like the Forgotten Realms under a program called the DM's Guild. The DM's Guild does not function under the OGL, but uses a community agreement intended to foster liberal cooperation among content creators.

At various times in its history, "Dungeons & Dragons" has received negative publicity, in particular from some Christian groups, for alleged promotion of such practices as devil worship, witchcraft, suicide, and murder, and for the presence of naked breasts in drawings of female humanoids in the original "AD&D" manuals (mainly monsters such as harpies, succubi, etc.). These controversies led TSR to remove many potentially controversial references and artwork when releasing the 2nd Edition of "AD&D". Many of these references, including the use of the names "devils" and "demons", were reintroduced in the 3rd edition. The moral panic over the game led to problems for fans of "D&D" who faced social ostracism, unfair treatment, and false association with the occult and Satanism, regardless of an individual fan's actual religious affiliation and beliefs.

"Dungeons & Dragons" has been the subject of rumors regarding players having difficulty separating fantasy from reality, even leading to psychotic episodes. The most notable of these was the saga of James Dallas Egbert III, the facts of which were fictionalized in the novel "Mazes and Monsters" and later made into a TV movie in 1982 starring Tom Hanks. The game was blamed for some of the actions of Chris Pritchard, who was convicted in 1990 of murdering his stepfather. Research by various psychologists, starting with Armando Simon, has concluded that no harmful effects are related to the playing of "D&D".

The game's commercial success was a factor that led to lawsuits regarding distribution of royalties between original creators Gygax and Arneson. Gygax later became embroiled in a political struggle for control of TSR which culminated in a court battle and Gygax's decision to sell his ownership interest in the company in 1985.

"D&D"'s commercial success has led to many other related products, including "Dragon" Magazine, "Dungeon" Magazine, an animated television series, a film series, an official role-playing soundtrack, novels, and computer games such as the MMORPG "Dungeons & Dragons Online". Hobby and toy stores sell dice, miniatures, adventures, and other game aids related to "D&D" and its game offspring.

"D&D" grew in popularity through the late 1970s and 1980s. Numerous games, films, and cultural references based on "D&D" or "D&D"-like fantasies, characters or adventures have been ubiquitous since the end of the 1970s. "D&D" players are (sometimes pejoratively) portrayed as the epitome of geekdom, and have become the basis of much geek and gamer humor and satire. Famous "D&D" players include Pulitzer Prize winning author Junot Díaz, professional basketball player Tim Duncan, comedian Stephen Colbert, and actors Vin Diesel and Robin Williams. "D&D" and its fans have been the subject of spoof films, including "Fear of Girls" and "".







</doc>
<doc id="7941" url="https://en.wikipedia.org/wiki?curid=7941" title="Double jeopardy">
Double jeopardy

Double jeopardy is a procedural defence that prevents an accused person from being tried again on the same (or similar) charges and on the same facts, following a valid acquittal or conviction.

If this issue is raised, evidence will be placed before the court, which will normally rule as a preliminary matter whether the plea is substantiated; if it is, the projected trial will be prevented from proceeding. In some countries, including Canada, Mexico and the United States, the guarantee against being "twice put in jeopardy" is a constitutional right. In other countries, the protection is afforded by statute.

In common law countries, a defendant may enter a peremptory plea of "autrefois acquit" (formerly acquitted) or "autrefois convict" (formerly convicted), with the same effect.

The doctrine appears to have originated in Roman law, in the principle "non bis in idem" ("an issue once decided must not be raised again").

The 72 signatories and 166 parties to the International Covenant on Civil and Political Rights recognise, under Article 14 (7): "No one shall be liable to be tried or punished again for an offence for which he has already been finally convicted or acquitted in accordance with the law and penal procedure of each country."

All members of the Council of Europe (which includes nearly all European countries and every member of the European Union) have adopted the European Convention on Human Rights. The optional Protocol No. 7 to the Convention, Article 4, protects against double jeopardy: "No one shall be liable to be tried or punished again in criminal proceedings under the jurisdiction of the same State for an offence for which he or she has already been finally acquitted or convicted in accordance with the law and penal procedure of that State."

This optional protocol has been ratified by all EU states except three: Germany, the Netherlands, and the United Kingdom. In those member states, national rules governing double jeopardy may or may not comply with the provision cited above.

Member states may, however, implement legislation which allows reopening of a case in the event that new evidence is found or if there was a fundamental defect in the previous proceedings:

The provisions of the preceding paragraph shall not prevent the reopening of the case in accordance with the law and penal procedure of the State concerned, if there is evidence of new or newly discovered facts, or if there has been a fundamental defect in the previous proceedings, which could affect the outcome of the case.

In many European countries, the prosecution may appeal an acquittal to a higher court. This is not regarded as double jeopardy, but as a continuation of the same case. The European Convention on Human Rights permits this by using the phrase ""finally" acquitted or convicted" (emphasis added) as the trigger for prohibiting subsequent prosecution.

In contrast to other common law nations, Australian double jeopardy law has been held to further prevent the prosecution for perjury following a previous acquittal where a finding of perjury would controvert the acquittal. This was confirmed in the case of "R v Carroll", where the police found new evidence convincingly disproving Carroll's sworn alibi two decades after he had been acquitted of murder charges in the death of Ipswich child Deidre Kennedy, and successfully prosecuted him for perjury. Public outcry following the overturn of his conviction (for perjury) by the High Court has led to widespread calls for reform of the law along the lines of the England and Wales legislation.

During a Council of Australian Governments (COAG) meeting of 2007, model legislation to rework double jeopardy laws was drafted, but there was no formal agreement for each state to introduce it. All states have now chosen to introduce legislation that mirrors COAG's recommendations on "fresh and compelling" evidence.

In New South Wales, retrials of serious cases with a minimum sentence of 20 years or more are now possible, whether or not the original trial preceded the 2006 reform. On 17 October 2006, the New South Wales Parliament passed legislation abolishing the rule against double jeopardy in cases where:

On 30 July 2008, South Australia also introduced legislation to scrap parts of its double jeopardy law, legalising retrials for serious offences with "fresh and compelling" evidence, or if the acquittal was tainted.

In Western Australia, on 8 September 2011 amendments were introduced that would allow also retrial if "new and compelling" evidence was found. It would apply to serious offences where the penalty was life imprisonment or imprisonment for 14 years or more. Acquittal because of tainting (witness intimidation, jury tampering, or perjury) would also allow retrial.

In Tasmania, on 19 August 2008, amendments were introduced to allow retrial in serious cases, if there is "fresh and compelling" evidence.

In Victoria on 21 December 2011, legislation was passed allowing new trials where there is "fresh and compelling DNA evidence, where the person acquitted subsequently admits to the crime, or where it becomes clear that key witnesses have given false evidence". Retrial applications however could only be made for serious offences such as murder, manslaughter, arson causing death, serious drug offences and aggravated forms of rape and armed robbery.

In Queensland on 18 October 2007, the double jeopardy laws were modified to allow a retrial where fresh and compelling evidence becomes available after an acquittal for murder or a "tainted acquittal" for a crime carrying a 25-year or more sentence. A "tainted acquittal" requires a conviction for an administration of justice offence, such as perjury, that led to the original acquittal. Unlike reforms in the United Kingdom, New South Wales, Tasmania, Victoria, South Australia, Western Australia, this law does not have a retrospective effect, which is unpopular with some advocates of the reform.

The Canadian Charter of Rights and Freedoms includes provisions such as section 11(h) prohibiting double jeopardy. However, this prohibition applies only after an accused person has been "finally" convicted or acquitted. Canadian law allows the prosecution to appeal an acquittal: if the acquittal is thrown out, the new trial is not considered to be double jeopardy, as the verdict of the first trial would have been annulled. In rare circumstances, a court of appeal might also substitute a conviction for an acquittal. This is not considered to be double jeopardy, either – in this case, the appeal and subsequent conviction are deemed to be a continuation of the original trial.

For an appeal from an acquittal to be successful, the Supreme Court of Canada requires that the Crown show that an error in law was made during the trial and that the error contributed to the verdict. It has been suggested that this test is unfairly beneficial to the prosecution. For instance, lawyer Martin Friedland, in his book "My Life in Crime and Other Academic Adventures", contends that the rule should be changed so that a retrial is granted only when the error is shown to be "responsible" for the verdict, not just a factor.

A notable example of this is Guy Paul Morin, who was wrongfully convicted in his second trial after the acquittal in his first trial was vacated by the Supreme Court of Canada.

In the Guy Turcotte case, for instance, the Quebec Court of Appeal overturned Turcotte's not criminally responsible verdict and ordered a second trial after it found that the judge committed an error in the first trial while giving instructions to the jury. Turcotte was later convicted of second-degree murder in the second trial.

Once all appeals have been exhausted on a case, the judgement is final and the action of the prosecution is closed (code of penal procedure, art. 6), except if the final ruling was forged. Prosecution for a crime already judged is impossible even if incriminating evidence has been found. However, a person who has been convicted may request another trial on grounds of new exculpating evidence through a procedure known as "révision".

The Basic Law ("Grundgesetz") for the Federal Republic of Germany does provide protection against double jeopardy if a final verdict is pronounced. A verdict is final if nobody appeals against it.

However, each trial party can appeal against a verdict in the first instance. This means the prosecution and/or the defendants can appeal against a judgement if they do not agree with it. In this case the trial starts again in the second instance, the court of appeal ("Berufungsgericht"), which considers the facts and reasons again and delivers the final judgement then.

If one of the parties disagrees with the judgement of the second instance, he or she can appeal it, but only on formal judicial reasons. The case will checked in the third instance ("Revisionsgericht"), whether all laws are applied correctly.

The rule applies to the whole "historical event, which is usually considered a single historical course of actions the separation of which would seem unnatural". This is true even if new facts occur that indicate other and/or much serious crimes.

The Penal Procedural Code ("Strafprozessordnung") permits a retrial ("Wiederaufnahmeverfahren"), if it is in favor of the defendant or if following events had happened:

In the case of an order of summary punishment, which can be issued by the court without a trial for lesser misdemeanours, there is a further exception:

In Germany, a felony is defined by § 12 (1) StGB as a crime which has a minimum of one year of imprisonment.

A partial protection against double jeopardy is a Fundamental Right guaranteed under Article 20 (2) of the Constitution of India, which states "No person shall be prosecuted and punished for the same offence more than once". This provision enshrines the concept of "autrefois convict", that no one convicted of an offence can be tried or punished a second time. However, it does not extend to "autrefois acquit", and so if a person is acquitted of a crime he can be retried. In India, protection against "autrefois acquit" is a statutory right, not a fundamental one. Such protection is provided by provisions of the Code of Criminal Procedure rather than by the Constitution.

The Constitution of Japan states in Article 39 that

In practice, however, if someone is acquitted in a lower District Court, then the prosecutor can appeal to the High Court, and then to the Supreme Court. Only the acquittal in the Supreme Court is the final acquittal which prevents any further retrial. This process sometimes takes decades.

The above is not considered a violation of the constitution. Because of Supreme Court precedent, this process is all considered part of a single proceeding.

In the Netherlands, the state prosecution can appeal a not-guilty verdict at the bench. New evidence can be brought to bear during a retrial at a district court. Thus one can be tried twice for the same alleged crime. If one is convicted at the district court, the defence can make an appeal on procedural grounds to the supreme court. The supreme court might admit this complaint, and the case will be reopened yet again, at another district court. Again, new evidence might be introduced by the prosecution.

On 9 April 2013 the Dutch senate voted 36 "yes" versus 35 "no" in favor of a new law that allows the prosecutor to re-try a person who was found not guilty in court. This new law is limited to crimes where someone died and new evidence must have been gathered. The new law also works retroactively.

Article 13 of the Constitution of Pakistan protects a person from being punished or prosecuted more than once for the same offence.

This principle is incorporated into the Constitution of the Republic of Serbia and further elaborated in its Criminal Procedure Act.

The Bill of Rights in the Constitution of South Africa forbids a retrial when there has already been an acquittal or a conviction.
Article 13 of the South Korean constitution provides that no citizen shall be placed in double jeopardy.

Double jeopardy has been permitted in England and Wales in certain (exceptional) circumstances since the Criminal Justice Act 2003.

The doctrines of "autrefois acquit" and "autrefois convict" persisted as part of the common law from the time of the Norman conquest of England; they were regarded as essential elements for protection of the subject's liberty and respect for due process of law in that there should be finality of proceedings. There were only three exceptions, all relatively recent, to the rules:

In Connelly v DPP ([1964] AC 1254), the Law Lords ruled that a defendant could not be tried for any offence arising out of substantially the same set of facts relied upon in a previous charge of which he had been acquitted, unless there are "special circumstances" proven by the prosecution. There is little case law on the meaning of "special circumstances", but it has been suggested that the emergence of new evidence would suffice.

A defendant who had been convicted of an offence could be given a second trial for an aggravated form of that offence if the facts constituting the aggravation were discovered after the first conviction. By contrast, a person who had been acquitted of a lesser offence could not be tried for an aggravated form even if new evidence became available.

Following the murder of Stephen Lawrence, the Macpherson Report recommended that the double jeopardy rule should be abrogated in murder cases, and that it should be possible to subject an acquitted murder suspect to a second trial if "fresh and viable" new evidence later came to light. The Law Commission later added its support to this in its report "Double Jeopardy and Prosecution Appeals" (2001). A parallel report into the criminal justice system by Lord Justice Auld, a past Senior Presiding Judge for England and Wales, had also commenced in 1999 and was published as the Auld Report six months after the Law Commission report. It opined that the Law Commission had been unduly cautious by limiting the scope to murder and that "the exceptions should [...] extend to other grave offences punishable with life and/or long terms of imprisonment as Parliament might specify."

Both Jack Straw (then Home Secretary) and William Hague (then Leader of the Opposition) favoured this measure. These recommendations were implemented—not uncontroversially at the time—within the Criminal Justice Act 2003, and this provision came into force in April 2005. It opened certain serious crimes (including murder, manslaughter, kidnapping, rape, armed robbery, and serious drug crimes) to a retrial, regardless of when committed, with two conditions: the retrial must be approved by the Director of Public Prosecutions, and the Court of Appeal must agree to quash the original acquittal due to "new and compelling evidence". Pressure by Ann Ming, the mother of 1989 murder victim Julie Hogg—whose killer, William Dunlop, was initially acquitted in 1991 and subsequently confessed—also contributed to the demand for legal change.

On 11 September 2006, Dunlop became the first person to be convicted of murder following a prior acquittal for the same crime, in his case his 1991 acquittal of Julie Hogg's murder. Some years later he had confessed to the crime, and was convicted of perjury, but was unable to be retried for the killing itself. The case was re-investigated in early 2005, when the new law came into effect, and his case was referred to the Court of Appeal in November 2005 for permission for a new trial, which was granted. Dunlop pleaded guilty to murdering Julie Hogg and was sentenced to life imprisonment, with a recommendation he serve no less than 17 years.

On 13 December 2010, Mark Weston became the first person to be retried and found guilty of murder by a jury (Dunlop having confessed). In 1996 Weston had been acquitted of the murder of Vikki Thompson at Ascott-under-Wychwood on 12 August 1995, but following the discovery in 2009 of compelling new evidence (Thompson's blood on Weston's boots) he was arrested and tried for a second time. He was sentenced to life imprisonment, to serve a minimum of 13 years.

The double jeopardy rule no longer applies absolutely in Scotland since the Double Jeopardy (Scotland) Act 2011 came into force on 28 November 2011. The Act introduced three broad exceptions to the rule: where the acquittal had been tainted by an attempt to pervert the course of justice; where the accused admitted his guilt after acquittal; and where there was new evidence.

In Northern Ireland the Criminal Justice Act 2003, effective 18 April 2005, makes certain "qualifying offence" (including murder, rape, kidnapping, specified sexual acts with young children, specified drug offences, defined acts of terrorism, as well as in certain cases attempts or conspiracies to commit the foregoing) subject to retrial after acquittal (including acquittals obtained before passage of the Act) if there is a finding by the Court of Appeal that there is "new and compelling evidence."

The ancient protection of the Common Law against double jeopardy is maintained in its full rigor in the United States, beyond reach of any change save that of a Constitutional Amendment. The Fifth Amendment to the United States Constitution provides:

Conversely, double jeopardy comes with a key exception. Under the dual sovereignty doctrine, multiple sovereigns can indict a defendant for the same crime. The federal and state governments can have overlapping criminal laws, so a criminal offender may be convicted in individual states and federal courts for exactly the same crime or for different crimes arising out of the same facts. However, in 2016, the Supreme Court held that Puerto Rico is not a separate sovereign for purposes of the Double Jeopardy Clause. The dual sovereignty doctrine has been the subject of substantial scholarly criticism.

The Double Jeopardy Clause encompasses four distinct prohibitions: subsequent prosecution after acquittal, subsequent prosecution after conviction, subsequent prosecution after certain mistrials, and multiple punishment in the same indictment. Jeopardy "attaches" when the jury is empanelled, the first witness is sworn, or a plea is accepted.

With two exceptions, the government is not permitted to appeal or retry the defendant once jeopardy attaches to a trial unless the case does not conclude. Conditions which constitute "conclusion" of a case include
In these cases the trial is concluded and the prosecution is precluded from appealing or retrying the defendant over the offense to which they were acquitted.

This principle does not prevent the government from appealing a pre-trial motion to dismiss or other non-merits dismissal, or a directed verdict after a jury conviction, nor does it prevent the trial judge from entertaining a motion for reconsideration of a directed verdict, if the jurisdiction has so provided by rule or statute. Nor does it prevent the government from retrying the defendant after an appellate reversal other than for sufficiency, including "habeas corpus", or "thirteenth juror" appellate reversals notwithstanding sufficiency on the principle that jeopardy has not "terminated."

The "dual sovereignty" doctrine allows a federal prosecution of an offense to proceed regardless of a previous state prosecution for that same offense and vice versa because "an act denounced as a crime by both national and state sovereignties is an offense against the peace and dignity of both and may be punished by each." The doctrine is solidly entrenched in the law, but there has been a traditional reluctance in the federal executive branch to gratuitously wield the power it grants, due to public opinion being generally hostile to such action.

The first exception to a ban on retrying a defendant is if, in a trial, the defendant bribed the judge into acquitting him or her, since the defendant was not in jeopardy 

The other exception to a ban on retrying a defendant is that the perpetrator can be retried by court martial in a military court, if they have been previously acquitted by a civilian court, and are members of the military.

In "Blockburger v. United States" (1932), the Supreme Court announced the following test: the government may separately try and punish the defendant for two crimes if each crime contains an element that the other does not. "Blockburger" is the default rule, unless the governing statute legislatively intends to depart; for example, Continuing Criminal Enterprise (CCE) may be punished separately from its predicates, as can conspiracy.

The "Blockburger" test, originally developed in the multiple punishments context, is also the test for prosecution after conviction. In "Grady v. Corbin" (1990), the Court held that a double jeopardy violation could lie even where the "Blockburger" test was not satisfied, but "Grady" was overruled in "United States v. Dixon" (1993).

The rule for mistrials depends upon who sought the mistrial. If the defendant moves for a mistrial, there is no bar to retrial, unless the prosecutor acted in "bad faith," i.e. goaded the defendant into moving for a mistrial because the government specifically wanted a mistrial. If the prosecutor moves for a mistrial, there is no bar to retrial if the trial judge finds "manifest necessity" for granting the mistrial. The same standard governs mistrials granted sua sponte.

Retrials are not common, due to the legal expenses to the government. However, in the mid-1980s Georgia antiques dealer James Arthur Williams was tried a record four times for the murder of Danny Hansford and (after three mistrials) was finally acquitted on the grounds of self-defense. The case is recounted in the book "Midnight in the Garden of Good and Evil" which was adapted into a film directed by Clint Eastwood (the movie omits the first three murder trials). 




Research and Notes produced for the UK Parliament, summarising the history of legal change, views and responses, and analyses:




</doc>
<doc id="7942" url="https://en.wikipedia.org/wiki?curid=7942" title="Disbarment">
Disbarment

Disbarment is the removal of a lawyer from a bar association or the practice of law, thus revoking his or her law license or admission to practice law. Disbarment is usually a punishment for unethical or criminal conduct. Procedures vary depending on the law society.

In Germany, the "Berufsverbot" is a ban on practicing a profession, which can be issued to a lawyer for misconduct, Volksverhetzung or for serious mismanagement of personal finances.

In April 1933, the Nazi government issued a "Berufsverbot" forbidding the practice of law by Jews, communists, and other political opponents, except for those protected by the Frontkämpferprivileg.

Generally disbarment is imposed as a sanction for conduct indicating that an attorney is not fit to practice law, willfully disregarding the interests of a client, or engaging in fraud which impedes the administration of justice. In addition, any lawyer who is convicted of a felony is automatically disbarred in most jurisdictions, a policy that, although opposed by the American Bar Association, has been described as a convicted felon's just deserts.

In the United States legal system, disbarment is specific to regions; one can be disbarred from some courts, while still being a member of the bar in another jurisdiction. However, under the American Bar Association's Model Rules of Professional Conduct, which have been adopted in most states, disbarment in one state or court is grounds for disbarment in a jurisdiction which has adopted the Model Rules.

Disbarment is quite rare (in 2011, only 1,046 lawyers were disbarred). Instead, lawyers are usually sanctioned by their own clients through civil malpractice proceedings, or via fine, censure, suspension, or other punishments from the disciplinary boards. To be disbarred is considered a great embarrassment and shame, even if one no longer wishes to pursue a career in the law.

Because disbarment rules vary by area, different rules can apply depending on where a lawyer is disbarred. Notably, the majority of US states have no procedure for permanently disbarring a person. Depending on the jurisdiction, a lawyer may reapply to the bar immediately, after five to seven years, or be banned for life.

The 20th and the 21st centuries have seen one former U.S. president and one former U.S. vice president disbarred, and another president suspended from one bar and caused to resign from another bar rather than face disbarment.

Former Vice President Spiro Agnew, having pleaded no contest (which subjects a person to the same criminal penalties as a guilty plea, but is not an admission of guilt for a civil suit) to charges of bribery and tax evasion, was disbarred from Maryland, the state of which he had previously been governor.

Former President Richard Nixon was disbarred from New York in 1976. for obstruction of justice related to the Watergate scandal. He had attempted to resign from the New York bar, as he had done with California and the Supreme Court, but his resignation was not accepted as he would not acknowledge that he was unable to defend himself from the charges brought against him.

In 2001, following a 5-year suspension by the Arkansas bar, the United States Supreme Court disbarred Bill Clinton, providing 40 days for him to contest the action. He resigned before the end of the 40 day period, avoiding permanent disbarment hearings.

Alger Hiss was disbarred for a felony conviction, but later became the first person reinstated to the bar in Massachusetts after disbarment.

In 2007, Mike Nifong, the District Attorney of Durham County, North Carolina who presided over the 2006 Duke University lacrosse case, was disbarred for prosecutorial misconduct related to his handling of the case.

In April 2012, a three-member panel appointed by the Arizona Supreme Court voted unanimously to disbar Andrew Thomas, former County Attorney of Maricopa County, Arizona, and a former close confederate of Maricopa County Sheriff Joe Arpaio. According to the panel, Thomas "outrageously exploited power, flagrantly fostered fear, and disgracefully misused the law" while serving as Maricopa County Attorney. The panel found "clear and convincing evidence" that Thomas brought unfounded and malicious criminal and civil charges against political opponents, including four state judges and the state attorney general. "Were this a criminal case," the panel concluded, "we are confident that the evidence would establish this conspiracy beyond a reasonable doubt."

Jack Thompson, the Florida lawyer noted for his activism against video games and rap music, was permanently disbarred for various charges of misconduct. The action was the result of several grievances claiming that Thompson had made defamatory, false statements and attempted to humiliate, embarrass, harass or intimidate his opponents. The order was made on September 25, 2008, effective October 25. However, Thompson attempted to appeal to the higher courts in order to avoid the penalty actually taking effect. Neither the US District court, nor the US Supreme Court would hear his appeal, rendering the judgment of the Florida Supreme Court final.

Ed Fagan, a New York lawyer who prominently represented Holocaust victims against Swiss banks, was disbarred in New York (in 2008) and New Jersey (in 2009) for failing to pay court fines and fees; and for misappropriating client and escrow trust funds.

F. Lee Bailey, noted criminal defense attorney, was disbarred by the state of Florida in 2001, with reciprocal disbarment in Massachusetts in 2002. The Florida disbarment was the result of his handling of stock in the DuBoc marijuana case. Bailey was found guilty of 7 counts of attorney misconduct by the Florida Supreme Court. Bailey had transferred a large portion of DuBoc's assets into his own accounts, using the interest gained on those assets to pay for personal expenses. In March 2005, Bailey filed to regain his law license in Massachusetts. The book "Florida Pulp Nonfiction" details the peculiar facts of the DuBoc case along with extended interviews with Bailey that include his own defense. Bailey is also best known for infamously representing murder suspect O. J. Simpson in 1994.


</doc>
<doc id="7946" url="https://en.wikipedia.org/wiki?curid=7946" title="Dog tag">
Dog tag

"Dog tag" is an informal but common term for the type of identification tag worn by military personnel. The tags are primarily used for the identification of dead and wounded soldiers; they have personal information about the soldiers and convey essential basic medical information, such as blood type and history of inoculations. The tags often indicate religious preference as well. Dog tags are usually fabricated from a corrosion-resistant metal. They commonly contain two copies of the information, either in the form of a single tag that can be broken in half or two identical tags on the same chain. This duplication allows one tag (or half-tag) to be collected from a soldier's body for notification and the second to remain with the corpse when battle conditions prevent it from being immediately recovered. The term "dog tags" arose because of their resemblance to animal registration tags.

The earliest mention of an identification tag for soldiers comes in Polyaenus (Stratagems 1.17) where the Spartans wrote their names on sticks tied to their left wrists. A type of dog tag ("signaculum"), was given to the Roman legionnaire at the moment of enrollment. The legionnaire "signaculum" was a lead disk with a leather string, worn around the neck, with the name of the recruit and the indication of the legion of which the recruit was part. 
This procedure, together with enrolment in the list of recruits, was made at the beginning of a four-month probatory period ("probatio"). The recruit got the military status only after the oath of allegiance ("sacramentum"), at the end of "probatio", meaning that from a legal point of view the "signaculum" was given to a subject who was no longer a civilian, but not yet in the military.

In more recent times, dog tags were provided to Chinese soldiers as early as the mid-19th century. During the Taiping revolt (1851–66), both the Imperialists (i.e., the Chinese Imperial Army regular servicemen) and those Taiping rebels wearing a uniform wore a wooden dog tag at the belt, bearing the soldier's name, age, birthplace, unit, and date of enlistment.

During the American Civil War from 1861–1865, some soldiers pinned paper notes with their name and home address to the backs of their coats. Other soldiers stenciled identification on their knapsacks or scratched it in the soft lead backing of their army belt buckle.

Manufacturers of identification badges recognized a market and began advertising in periodicals. Their pins were usually shaped to suggest a branch of service, and engraved with the soldier's name and unit. Machine-stamped tags were also made of brass or lead with a hole and usually had (on one side) an eagle or shield, and such phrases as "War for the Union" or "Liberty, Union, and Equality". The other side had the soldier's name and unit, and sometimes a list of battles in which he had participated.

On a volunteer basis Prussian soldiers had decided to wear identification tags in the Austro-Prussian War of 1866. However, many rejected dog tags as a bad omen for their lives. So until eight months after the Battle of Königgrätz, with almost 8,900 Prussian casualties, only 429 of them could be identified. With the formation of the North German Confederation in 1867 Prussian military regulations became binding for the militaries of all North German member states. With the Prussian "Instruktion über das Sanitätswesen der Armee im Felde" (i.e., instruction on the medical corps organisation of the army afield) issued on 29 April 1869 the identification tags (then called "Recognitionsmarke"; i.e. literally recognition mark) were obligatorily to be handed out to each soldier before marching afield. The Prussian Army issued identification tags for its troops at the beginning of the Franco-Prussian War in 1870. They were nicknamed "Hundemarken" (the German equivalent of "dog tags") and compared to a similar identification system instituted by the dog licence fee, adding tags to collars of those dogs whose owners paid the fee, in the Prussian capital city of Berlin at around the same time period.

The British Army introduced identity discs in place of identity cards in 1907, in the form of aluminium discs, typically made at Regimental depots using machines similar to those common at fun fairs, the details being pressed into the thin metal one letter at a time.

Army Order 287 of September 1916 required the British Army provide all soldiers with two official tags, both made of vulcanised asbestos fibre (which were more comfortable to wear in hot climates) carrying identical details, again impressed one character at a time. The first tag, an octagonal green disc, was attached to a long cord around the neck. The second tag, a circular red disc, was threaded on a 6-inch cord suspended from the first tag. The first tag was intended to remain on the body for future identification, while the second tag could be taken to record the death.

British and Empire/Commonwealth forces (Australia, Canada, and New Zealand) were issued essentially identical identification discs of basic pattern during the Great War, Second World War and Korea, though official identity discs were frequently supplemented by private-purchase items such as identity bracelets, particularly favoured by sailors who rightly believed the official discs were unlikely to survive long immersion in water.

The U.S. Army first authorized identification tags in War Department General Order No. 204, dated December 20, 1906, which essentially prescribes the Kennedy identification tag:

An aluminum identification tag, the size of a silver half dollar and of suitable thickness, stamped with the name, rank, company, regiment, or corps of the wearer, will be worn by each officer and enlisted man of the Army whenever the field kit is worn, the tag to be suspended from the neck, underneath the clothing, by a cord or thong passed through a small hole in the tab. It is prescribed as a part of the uniform and when not worn as directed herein will be habitually kept in the possession of the owner. The tag will be issued by the Quartermaster's Department gratuitously to enlisted men and at cost price to officers.

The army changed regulations on July 6, 1916, so that all soldiers were issued two tags: one to stay with the body and the other to go to the person in charge of the burial for record-keeping purposes. In 1918, the army adopted and allotted the serial number system, and name and serial numbers were ordered stamped on the identification tags. (Serial number 1 was assigned to enlisted man Arthur B. Crane of Chicago in the course of his fifth enlistment period.)

There is a recurring myth about the notch situated in one end of the dog tags issued to United States Army personnel during World War II, and up until the Vietnam War era. It was rumored that the notch's purpose was that, if a soldier found one of his comrades on the battlefield, he could take one tag to the commanding officer and stick the other between the teeth of the soldier to ensure that the tag would remain with the body and be identified.

In reality, the notch was used with the Model 70 Addressograph Hand Identification Imprinting Machine (a pistol-type imprinter used primarily by the Medical Department during World War II). American dogtags of the 1930s through 1970s were produced using a Graphotype machine, in which characters are debossed into metal plates. Some tags are still debossed, using earlier equipment, and some are embossed (with raised letters) on computer-controlled equipment.

In the Graphotype process, commonly used commercially from the early 1900s through the 1980s, a debossing machine was used to stamp characters into metal plates; the plates could then be used to repetitively stamp such things as addresses onto paper in the same way that a typewriter functions, except that a single stroke of the printer could produce a block of text, rather than requiring each character to be printed individually. The debossing process creates durable, easily legible metal plates, well-suited for military identification tags, leading to adoption of the system by the American military. It was also realized that debossed tags can function the same way the original Graphotype plates do.

The Model 70 took advantage of this fact, and was intended to rapidly print all of the information from a soldier's dogtag directly onto medical and personnel forms, with a single squeeze of the trigger. However, this requires that the tag being inserted with the proper orientation (stamped characters facing down), and it was believed that battlefield stress could lead to errors. To force proper orientation of the tags, the tags are produced with a notch, and there is a locator tab inside the Model 70 which prevents the printer from operating if the tag is inserted with the notch in the wrong place (as it is if the tag is upside down).

This feature was not as useful in the field as had been hoped, however, due to adverse conditions such as weather, dirt and dust, water, etc. In addition, the Model 70 resembled a pistol, thus attracting the attention of snipers (who might assume that a man carrying a pistol was an officer). As a result, use of the Model 70 hand imprinter by field medics was rapidly abandoned (as were most of the Model 70s themselves), and eventually the specification that tags include the locator notch was removed from production orders. Existing stocks of tags were used until depleted, and in the 1960s it was not uncommon for a soldier to be issued one tag with the notch and one tag without. Notched tags are still in production, to satisfy the needs of hobbyists, film production, etc., while the Model 70 imprinter has become a rare collector's item.

It appears instructions that would confirm the notch's mythical use were issued at least unofficially by the Graves Registration Service during the Vietnam War to Army troops headed overseas.

Dog tags are traditionally part of the makeshift battlefield memorials soldiers created for their fallen comrades. The casualty's rifle with bayonet affixed is stood vertically atop the empty boots, with the helmet over the rifle's stock. The dog tags hang from the rifle's handle or trigger guard.

Some tags (along with similar items such as MedicAlert bracelets) are used also by civilians to identify their wearers and specify them as having health problems that may <br>
"(a)" suddenly incapacitate their wearers and render them incapable of providing treatment guidance (as in the cases of heart problems, epilepsy, diabetic coma, accident or major trauma) and/or <br> 
"(b)" interact adversely with medical treatments, especially standard or "first-line" ones (as in the case of an allergy to common medications) and/or <br>
"(c)" provide in case of emergency ("ICE") contact information and/or <br> 
"(d)" state a religious, moral, or other objection to artificial resuscitation, if a first responder attempts to administer such treatment when the wearer is non-responsive and thus unable to warn against doing so. A DNR Signed by a physician is still required in some states. 

Military personnel in some jurisdictions may wear a supplementary medical information tag.

Dog tags have recently found their way into youth fashion by way of military chic. Originally worn as a part of a military uniform by youth wishing to present a tough or militaristic image, dog tags have since seeped out into wider fashion circles. They may be inscribed with a person's details, their beliefs or tastes, a favorite quote, or may bear the name or logo of a band or performer.

Since the late 1990s, custom dog tags have been fashionable amongst musicians (particularly rappers), and as a marketing give-away item. Numerous companies offer customers the opportunity to create their own personalized dog tags with their own photos, logos, and text. Even high-end jewelers have featured gold and silver dog tags encrusted with diamonds and other jewels.

The Austrian Bundesheer utilized a single long, rectangular tag, with oval ends, stamped with blood group & Rh factor at the end, with ID number underneath. Two slots and a hole stamped beneath the nunicew the tag to be broken in half, and the long bottom portion has both the ID number and a series of holes which allows the tag to be inserted into a dosimeter. This has been replaced with a more conventional, wider and rounded rectangle which can still be halved, but lacks the dosimeter reading holes.

The Australian Defence Force issues soldiers two tags of different shapes, one octagonal and one circular, containing the following information:

The information is printed exactly the same on both discs. In the event of a casualty, the circular tag is removed from the body.

Belgian Forces identity tags are, like the Canadian and Norwegian, designed to be broken in two in case of fatality; the lower half is returned to Belgian Defence tail, while the upper half remains on the body. The tags contain the following information:


Canadian Forces identity discs (abbreviated "I discs") are designed to be broken in two in the case of fatality; the lower half is returned to National Defence Headquarters with the member's personal documents, while the upper half remains on the body. The tags contain the following information:

Before the Service Number was introduced in the 1990s, military personnel were identified on the I discs (as well as other documents) by their Social Insurance Number.

The People's Liberation Army issues two long, rectangular tags. All information is stamped in Simplified Chinese:
PLA is introducing a two-dimensional matrix code on the second tag, the matrix code contains a link to the official database. This allows the inquirer get more details about the military personnel.

The Ejército Nacional de Colombia uses long, rectangular metal tags with oval ends tags stamped with the following information:

Duplicate tags are issued. Often, tags are issued with a prayer inscribed on the reverse.

In Cyprus, identification tags include the following information:

The military of Denmark use dog tags made from small, rectangular metal plates. The tag is designed to be broken into two pieces each with the following information stamped onto it:
Additionally, the right hand side of each half-tag is engraved 'DANMARK', .
Starting in 1985, the individual's service number (which is the same as the social security number) is included on the tag. In case the individual dies, the lower half-tag is supposed to be collected, while the other will remain with the corpse. In the army, navy, and air force but not in the national guard, the individual's blood type is indicated on the lower half-tag only, since this information becomes irrelevant if the individual dies. In 2009, Danish dog tags were discontinued for conscripts.

The Nationale Volksarmee used a tag nearly identical to that used by both the Wehrmacht and the West German Bundeswehr. The oval aluminum tag was stamped "DDR" (Deutsche Demokratische Republik) above the personal ID number; this information was repeated on the bottom half, which was intended to be broken off in case of death. Oddly, the tag was not worn, but required to be kept in a plastic sleeve in the back of the WDA identity booklet.

The "Placas de identificación de campaña" consists of two long, rectangular steel or aluminum tags with rounded corners and a single hole punched in one end. It is suspended by a US-type ball chain, with a shorter chain for the second tag. The information on the tag is:

Estonian dog tags are designed to be broken in two. The dog tag is a metallic rounded rectangle suspended by a ball chain. Information consists of four fields: 

Example: 

In the Finnish Defence Forces, "tunnuslevy" or WWII term "tuntolevy" (Finnish for "Identification plate") is made of stainless steel and designed to be broken in two; however, the only text on it is the personal identification number and the letters "SF" (rarely FI), which stands for Suomi Finland, within a tower stamped atop of the upper half.

France issues either a metallic rounded rectangle (army) or disk (navy), designed to be broken in half, bearing family name & first name above the ID number.

German Bundeswehr ID tags are an oval-shaped disc designed to be broken in half. The two sides contain different information which are mirrored upside-down on the lower half of the ID tag. They feature the following information on segmented and numbered fields:

On the front:


On the back:


In Greece, identification tags include the following information:

The Hungarian army dog tag is made out of steel, forming a 25×35 mm tag designed to split diagonally. Both sides contain the same information: the soldier's personal identity code, blood group and the word HUNGARIA. Some may not have the blood group on them. These are only issued to soldiers who are serving outside of the country. If the soldier should die, one side is removed and kept for the army's official records, while the other side is left attached to the body.

The Saddam-era Iraqi Army utilized a single, long, rectangular metal tag with oval ends, inscribed (usually by hand) with Name and Number or Unit, and occasionally Blood Type.

Dog tags of the Israel Defense Forces are designed to be broken in two. The information appears in three lines (twice):

Another two dog tags are kept inside each military boot in order to identify dead soldiers.

Originally the IDF issued two circular aluminum tags (1948 – late 1950s) stamped in three lines with serial number, family name, and first name. The tags were threaded together through a single hole onto a cord worn around the neck.

Japan follows a similar system to the US Army for its Self Defence Force personnel, and the appearance of the tags is similar, although laser etched. The exact information order is as follows.


Malaysian Armed Forces have two identical oval tags with this information:

If more information needed, another two oval wrist tags are provided. The term "wrist tags" can be used to refer to the bracelet-like wristwatch. The additional tags only need to be worn on the wrist, with the main tags still on the neck. All personnel are allowed to attach a small religious pendant or locket; this makes a quick identifiable reference for their funeral services.

The Ejército de Mexico uses a single long, rectangular metal tag with oval ends, embossed with Name, serial number, and blood type plus Rh factor.

Military of the Netherlands identity tags, like the Canadian and Norwegian ones, are designed to be broken in two in case of a fatality; the lower end is returned to Dutch Defence Headquarters, while the upper half remains on the body. There is a difference in the Army and Airforce service number and the Navy service number:

The tags contain the following information:

Norwegian dog tags are designed to be broken in two like the Canadian version:

The first dog tags were issued in Poland following the order of the General Staff of December 12, 1920. The earliest design (dubbed "kapala" in Polish, more properly called "kapsel legitymacyjny" - meaning "identification cap") consisted of a tin-made 30×50 mm rectangular frame and a rectangular cap fitting into the frame. Soldiers' details were filled in a small ID card placed inside the frame, as well as on the inside of the frame itself. The dog tag was similar to the tags used by the Austro-Hungarian Army during World War I. In case the soldier died, the frame was left with his body, while the lid was returned to his unit together with a note on his death. The ID card was handed over to the chaplain or the rabbi.

In 1928, a new type of dog tag was proposed by gen. bryg. Stanisław Rouppert, Poland's representative at the International Red Cross. It was slightly modified and adopted in 1931 under the name of Nieśmiertelnik wz. 1931 (literally, Immortalizer mark 1931). The new design consisted of an oval piece of metal (ideally steel, but in most cases aluminum alloy was used), roughly 40 by 50 millimeters. There were two notches on both sides of the tag, as well as two rectangular holes in the middle to allow for easier breaking of the tag in two halves. The halves contained the same set of data and were identical, except the upper half had two holes for a string or twine to go through. The data stamped on the dog tag included:


Sometimes the rank of the soldier was added to the reverse, and most members of the medical corps had a tiny cross stamped near the string holes, regardless of their religion.

The former Republic of Rhodesia used two WW2 British-style compressed asbestos fiber tags, a No. 1 octagonal (green) tag and a No. 2 circular (red) tag, stamped with identical information. The red tag was supposedly fireproof and the green tag rotproof. The following information was stamped on the tags: Number, Name, Initials, & Religion; Blood Type was stamped on reverse. The air force and BSAP often stamped their service on the reverse side above the blood group.

Many soldiers state they were issued blank tags and told to punch the information in themselves. 

The Russian Armed Forces use oval metal tags, similar to the dog tags of the Soviet Army. Each tag contains the title " () and the individual's alphanumeric number, as shown on the photo.

The Singapore Armed Forces-issued dog tags are inscribed (not embossed) with up to four items:

The dog tags consist of two metal pieces, one oval with two holes and one round with one hole. A synthetic lanyard is threaded through both holes in the oval piece and tied around the wearer's neck. The round piece is tied to the main loop on a shorter loop.

The former South African Defense Force used two long, rectangular aluminum tags with oval ends, stamped with serial number, name and initials, religion, and blood type.

The South Korean Army issues two long, rectangular tags with oval ends, stamped (in Korean lettering). The tags are worn on the neck with a ball chain. The tags contain the information listed below:

The South Vietnamese Army used two American-style dog tags. Some tags added religion, e.g., Công Giáo for Catholic. They were stamped or inscribed with: 

During World War II, the Red Army did not issue metal dog tags to its troops. They were issued small ebony cylinders containing a slip of paper with a soldier's s particulars written on it. These do not hold up as well as metal dog tags.
After World War II, the Soviet Army used oval metal tags, similar to today's dog tags of the Russian Armed forces. Each tag contains the title " () and the individual's alphanumeric number.

Issues a single metal oval, worn vertically, stamped "" above and below the 3-slot horizontal break line. It is stamped in 4 lines with:

Swedish identification tags are designed to be able to break apart. The information on them was prior to 2010:

Swedish dog tags issued to Armed Forces personnel after 2010 are, for personal security reasons, only marked with a personal identity number.

During the Cold War, dog tags were issued to everyone, often soon after birth, since the threat of total war also meant the risk of severe civilian casualties. However, in 2010, the Government decided that the dog tags were not needed anymore.

Swiss Armed Forces ID tag is an oval shaped non reflective plaque, containing the following information:
On the back side the letters CH standing for (Confoederatio Helvetica) are engraved next to a Swiss cross.

Tags are properly known as identification tags; the term "dog tags" has never been used in regulations.

A persistent rumor is that debossed (imprinted with stamped in letters) dog tags were issued from World War II till the end of the Vietnam War and that currently the U.S. Armed Forces is issuing embossed (imprinted with raised letters) dog tags. In actuality, the U.S. Armed Forces issues dog tags with both types of imprinting, depending on the machine used at a given facility. The military issued 95% of their identification tags up until recently (within the past 10 years) with debossed text.

The U.S. Armed Forces typically carry two identical oval dog tags containing:

During World War II, an American dog tag could indicate only one of three religions through the inclusion of one letter: "P" for Protestant, "C" for Catholic, or "H" for Jewish (from the word, "Hebrew"), or (according to at least one source) "NO" to indicate no religious preference. Army regulations (606-5) soon included X and Y in addition to P, C, and H: the X indicating any religion not included in the first three, and the Y indicating either no religion or a choice not to list religion.
By the time of the Vietnam War, some IDs spelled out the broad religious choices such as PROTESTANT and CATHOLIC, rather than using initials, and also began to show individual denominations such as "METHODIST" or "BAPTIST." Tags did vary by service, however, such as the use of "CATH," not "CATHOLIC" on some Navy tags. For those with no religious affiliation and those who chose not to list an affiliation, either the space for religion was left blank or the words "NO PREFERENCE" or "NO RELIGIOUS PREF" (or the abbreviation "NO PREF") were included.

Although American dog tags currently include the recipient's religion as a way of ensuring that religious needs will be met, some personnel have them reissued without religious affiliation listed—or keep two sets, one with the designation and one without—out of fear that identification as a member of a particular religion could increase the danger to their welfare or their lives if they fell into enemy hands. Some Jewish personnel avoided flying over German lines during WWII with ID tags that indicated their religion, and some Jewish personnel avoid the religious designation today out of concern that they could be captured by extremists who are anti-Semitic. Additionally, when American troops were first sent to Saudi Arabia during the Gulf War there were allegations that some U.S. military authorities were pressuring Jewish military personnel to avoid listing their religions on their ID tags.




</doc>
<doc id="7950" url="https://en.wikipedia.org/wiki?curid=7950" title="Drum">
Drum

The drum is a member of the percussion group of musical instruments. In the Hornbostel-Sachs classification system, it is a membranophone. Drums consist of at least one membrane, called a drumhead or drum skin, that is stretched over a shell and struck, either directly with the player's hands, or with a drum stick, to produce sound. There is usually a "resonance head" on the underside of the drum, typically tuned to a slightly lower pitch than the top drumhead. Other techniques have been used to cause drums to make sound, such as the thumb roll. Drums are the world's oldest and most ubiquitous musical instruments, and the basic design has remained virtually unchanged for thousands of years.

Drums may be played individually, with the player using a single drum, and some drums such as the djembe are almost always played in this way. Others are normally played in a set of two or more, all played by the one player, such as bongo drums and timpani. A number of different drums together with cymbals form the basic modern drum kit.

Drums are usually played by striking with the hand, or with one or two sticks. A wide variety of sticks are used, including wooden sticks and sticks with soft beaters of felt on the end. In jazz, some In many traditional cultures, drums have a symbolic function and are used in religious ceremonies. Drums are often used in music therapy, especially hand drums, because of their tactile nature and easy use by a wide variety of people.

In popular music and jazz, "drums" usually refers to a drum kit or a set of drums (with some cymbals, or in the case of harder rock music genres, many cymbals), and "drummer" to the person who plays them.

Drums acquired even divine status in places such as Burundi, where the "karyenda" was a symbol of the power of the king.

The shell almost invariably has a circular opening over which the drumhead is stretched, but the shape of the remainder of the shell varies widely. In the western musical tradition, the most usual shape is a cylinder, although timpani, for example, use bowl-shaped shells. Other shapes include a frame design (tar, Bodhrán), truncated cones (bongo drums, Ashiko), goblet shaped (djembe), and joined truncated cones (talking drum).

Drums with cylindrical shells can be open at one end (as is the case with timbales), or can have two drum heads, one head on each end. Single-headed drums typically consist of a skin stretched over an enclosed space, or over one of the ends of a hollow vessel. Drums with two heads covering both ends of a cylindrical shell often have a small hole somewhat halfway between the two heads; the shell forms a resonating chamber for the resulting sound. Exceptions include the African slit drum, also known as a log drum as it is made from a hollowed-out tree trunk, and the Caribbean steel drum, made from a metal barrel. Drums with two heads can also have a set of wires, called snares, held across the bottom head, top head, or both heads, hence the name snare drum. On some drums with two heads, a hole or bass reflex port may be cut or installed onto one head, as with some 2010s era bass drums in rock music.

On modern band and orchestral drums, the drumhead is placed over the opening of the drum, which in turn is held onto the shell by a "counterhoop" (or "rim"), which is then held by means of a number of tuning screws called "tension rods" that screw into lugs placed evenly around the circumference. The head's tension can be adjusted by loosening or tightening the rods. Many such drums have six to ten tension rods. The sound of a drum depends on many variables—including shape, shell size and thickness, shell materials, counterhoop material, drumhead material, drumhead tension, drum position, location, and striking velocity and angle.

Prior to the invention of tension rods, drum skins were attached and tuned by rope systems—as on the Djembe—or pegs and ropes such as on Ewe Drums. These methods are rarely used today, though sometimes appear on regimental marching band snare drums. The head of a talking drum, for example, can be temporarily tightened by squeezing the ropes that connect the top and bottom heads. Similarly, the tabla is tuned by hammering a disc held in place around the drum by ropes stretching from the top to bottom head. Orchestral timpani can be quickly tuned to precise pitches by using a foot pedal.

Several factors determine the sound a drum produces, including the type, shape and construction of the drum shell, the type of drum heads it has, and the tension of these drumheads. Different drum sounds have different uses in music. Take, for example, the modern Tom-tom drum. A jazz drummer may want drums that are high pitched, resonant and quiet whereas a rock drummer may prefer drums that are loud, dry and low-pitched. Since these drummers want different sounds, their drums are constructed and tuned differently.

The drum head has the most effect on how a drum sounds. Each type of drum head serves its own musical purpose and has its own unique sound. Double-ply drumheads dampen high frequency harmonics because they are heavier and they are suited to heavy playing. Drum heads with a white, textured coating on them muffle the overtones of the drum head slightly, producing a less diverse pitch. Drum heads with central silver or black dots tend to muffle the overtones even more. And drum heads with perimeter sound rings mostly eliminate overtones (Howie 2005). Some jazz drummers avoid using thick drum heads, preferring single ply drum heads or drum heads with no muffling. Rock drummers often prefer the thicker or coated drum heads.

The second biggest factor that affects drum sound is head tension against the shell. When the hoop is placed around the drum head and shell and tightened down with tension rods, the tension of the head can be adjusted. When the tension is increased, the amplitude of the sound is reduced and the frequency is increased, making the pitch higher and the volume lower.

The type of shell also affects the sound of a drum. Because the vibrations resonate in the shell of the drum, the shell can be used to increase the volume and to manipulate the type of sound produced. The larger the diameter of the shell, the lower the pitch. The larger the depth of the drum, the louder the volume. Shell thickness also determines the volume of drums. Thicker shells produce louder drums. Mahogany raises the frequency of low pitches and keeps higher frequencies at about the same speed. When choosing a set of shells, a jazz drummer may want smaller maple shells, while a rock drummer may want larger birch shells. For more information about tuning drums or the physics of a drum, visit the external links listed below.

Drums made with alligator skins have been found in Neolithic cultures located in China, dating to a period of 5500–2350 BC. In literary records, drums manifested shamanistic characteristics were often used in ritual ceremonies.

The bronze Dong Son drum was fabricated by the Bronze Age Dong Son culture of northern Vietnam. They include the ornate Ngoc Lu drum.

Macaque monkeys drum objects in a rhythmic way to show social dominance and this has been shown to be processed in a similar way in their brains to vocalizations suggesting an evolutionary origin to drumming as part of social communication. Other primates make drumming sounds by chest beating or hand clapping, and rodents such as kangaroo rats also make similar sounds using their paws on the ground.

Drums are used not only for their musical qualities, but also as a means of communication over great distances. The talking drums of Africa are used to imitate the tone patterns of spoken language. Throughout Sri Lankan history drums have been used for communication between the state and the community, and Sri Lankan drums have a history stretching back over 2500 years.

Drumming may be a purposeful expression of emotion for entertainment, spiritualism and communication. Many cultures practice drumming as a spiritual or religious passage and interpret drummed rhythm similarly to spoken language or prayer. Drumming has developed over millennia to be a powerful art form. Drumming is commonly viewed as the root of music and is sometimes performed as a kinesthetic dance. As a discipline, drumming concentrates on training the body to punctuate, convey and interpret musical rhythmic intention to an audience and to the performer.

Chinese troops used tàigǔ drums to motivate troops, to help set a marching pace, and to call out orders or announcements. For example, during a war between Qi and Lu in 684 BC, the effect of drum on soldier's morale is employed to change the result of a major battle. Fife-and-drum corps of Swiss mercenary foot soldiers also used drums. They used an early version of the snare drum carried over the player's right shoulder, suspended by a strap (typically played with one hand using traditional grip). It is to this instrument that the English word "drum" was first used. Similarly, during the English Civil War rope-tension drums would be carried by junior officers as a means to relay commands from senior officers over the noise of battle. These were also hung over the shoulder of the drummer and typically played with two drum sticks. Different regiments and companies would have distinctive and unique drum beats only they recognized. In the mid-19th century, the Scottish military started incorporating pipe bands into their Highland Regiments.

During pre-Columbian warfare, Aztec nations were known to have used drums to send signals to the battling warriors. The Nahuatl word for drum is roughly translated as huehuetl.

The Rig Veda, one of the oldest religious scriptures in the world, contain several references to the use of Dundhubi (war drum). Arya tribes charged into battle to the beating of the war drum and chanting of a hymn that appears in Book VI of the Rig Veda and also the Atharva Veda where it is referred to as the "Hymn to the battle drum".






</doc>
