<doc id="1440" url="https://es.wikipedia.org/wiki?curid=1440" title="Heráldica">
Heráldica

La heráldica es la ciencia del blasón (según la RAE, «blasón» se define como el «arte de explicar y describir los escudos de armas de cada linaje, ciudad o persona»). Es también un campo de expresión artística, un elemento del derecho medieval y de las dinastías reales hasta nuestros días. Más recientemente, ha sido admitida dentro de las ciencias anexas de la historia junto con la diplomática, la falerística, la sigilografía y la vexilología.

Se desarrolló durante la Edad Media en toda Europa hasta convertirse en un código coherente de identificación de personas, progresivamente incorporado por estamentos de la sociedad feudal como la nobleza y la Iglesia Católica para la identificación de linajes y miembros de la jerarquía, siendo igualmente adoptado por otros colectivos humanos, como gremios y asociaciones, además de ser adoptado para la identificación de ciudades, villas y territorios.

Siguiendo a Alberto Montaner Frutos, la heráldica es un sistema de comunicación que forma parte del sistema de la emblemática y está formado por signos constituidos por armerías (escudos de armas). Estas armerías están conformadas por cuatro conjuntos de elementos (repertorios paradigmáticos): el campo (normalmente limitado por la representación de un escudo, aunque no siempre), que solo excepcionalmente posee valor distintivo; las particiones del campo, que delimitan zonas en su interior; las señales, también denominadas muebles (figuras geométricas u objetos) y los esmaltes, o colores heráldicos, que se dividen en metales (oro y plata) y colores (gules, azur, sable, sinople y púrpura). A partir del siglo XIV aparece un cuarto repertorio paradigmático, el de los ornamentos exteriores al campo, que pueden situarse encima del escudo (el timbre, que tiene como formas
básicas la corona y el yelmo, este último con o sin cimera), a sus lados, sosteniéndolo (soportes o tenantes, cuya distinción es irrelevante), rodeándolo (collares, cintas, cordones...) o enmarcándolo (como el caso de mantos y pabellones). Estos elementos paradigmáticos se seleccionan para formar signos sintagmáticos según ciertos principios, como la que prescribe que no se utilice en el campo y las señales esmaltes del mismo grupo (colores y metales), sino combinar metal y color.

Blasón es una palabra de origen oscuro, puede ser que venga de alguna lengua franconia de la palabra "blâsjan" (antorcha encendida, gloria), o más probablemente del latín "blasus" significando ‘arma de guerra’. “Blasonar” significa "describir" las armerías siguiendo las reglas de la ciencia heráldica. En un estricto sentido, el blasón es, entonces, un enunciado que puede ser oral o escrito. Es la descripción de las armerías hecha en un lenguaje técnico, el lenguaje heráldico. El blasonamiento es la acción que consiste en describir las armerías (y por tanto de enunciar el blasón que representa). La ciencia del blasón es muy antigua, se funda menos de un siglo después que se estableciera el uso de armerías en la Edad Media. En esgrima, los blasones (amarillo, rojo, azul...) son exámenes que permiten probar un nivel de técnica adquirida, de arbitrar o de participar en ciertas competencias. Algunos son distribuidos igualmente después de una victoria. Se expresan en una pieza de tela (cuyo color cambia siguiendo el nivel) en el codo o añadida al hombro desarmado.

Las definiciones siguientes son precisas, aunque está lejos de reflejar su uso real. En la práctica los términos “blasón”, “armas”, “escudo” y “armerías” funcionan como sinónimos y son intercambiables, tanto en las obras comunes como en las de los estudiosos de la heráldica.





La heráldica es lo relativo al lenguaje del blasón, a la ciencia de los heraldos y al diseño de las armerías. Más específicamente, es la disciplina que tiene por objeto el conocimiento y el estudio de las armerías. La heráldica cubre cuatro disciplinas conexas:





El uso de las armerías viene de la evolución del equipo militar entre los siglos XI y XII, que hicieron prácticamente imposible el reconocimiento del rostro de un caballero. El casco de los caballeros (que figura todavía en los ornamentos exteriores) cubría progresivamente la cara: la nariz está protegida por un nasal, la cota de malla (que protege la cabeza y el cuello) tiende a cubrir la parte baja del rostro y está definitivamente cerrado por una visera móvil.

Para hacerse reconocer en las batallas y los torneos, los caballeros comienzan a pintar figuras distintivas sobre sus escudos (muebles y piezas o figuras geométricas).

El escudero es un gentil hombre que acompaña a un caballero y carga su escudo. A partir del momento en el que el escudo porta las figuras distintivas, el escudero que porta el escudo puede representar al caballero, aun en su ausencia. El escudero es probablemente el origen de la representación de los tenantes en los ornamentos exteriores.

Las cinco regiones principales del escudo (jefe, corazón, flancos diestro y siniestro, punta) se refieren a partes del cuerpo del escudero que porta el blasón en el pecho y se presenta de frente. Como el escudero está visto de frente, “diestra” y “siniestra” están invertidos en heráldica en cuanto a su significación usual: la diestra del escudero es la izquierda del observador y viceversa.

La razón de ser de un caballero es librar batallas. La batalla le permite probar su valentía a través de sus encuentros y los rescates recolectados sobre los vencidos aumentaban sus bienes materiales.

En un comienzo no hay gran diferencia entre el desarrollo de una batalla y el de un torneo. En los dos casos se trata de una gran trifulca armada organizada en un campo de batalla entre dos bandos, donde los participantes respetan ciertas reglas. La diferencia es en el entorno de la confrontación.




La batalla de Crécy es la primera gran batalla donde la “regla del juego” no fue respetada: las tropas inglesas libraron una batalla no para obtener gloria y rescates, sino para neutralizar a las tropas francesas (y lo lograron). Los franceses protestaron que los ingleses no hubieran respetado las reglas del juego (pérfidamente, de ahí la locución "pérfida Albión") aplicada a Inglaterra, pero esas reglas simplemente habían cambiado ya. A partir entonces los géneros se separan. Los torneos se desarrollan en campos cerrados y las batallas se convierten cada vez más en un asunto de mercenarios y soldados, no de caballeros.

Aunque menos conocidas, también podemos encontrar en esta época heraldas. Tenían las mismas ocupaciones que los heraldos. Las más destacadas fueron Escolástica de Muñón y Cesarea Taberné.

Para los grandes señores, el rol del escudero tomó progresivamente una dimensión diplomática y se especializó en la función del heraldo. Desarmados, sin valor de rescate, se benefician de inmunidad diplomática de facto, y pueden desplazarse libremente para asegurar su misión, incluyendo los campos y países enemigos. Son sujetos, en consecuencia, de una imparcialidad y discreción estrictas. La actividad de los heraldos se rige por todo un código de derechos y obligaciones.

Los heraldos de armas portan una túnica, el tabardo, que los hace inmediatamente identificables. Es una túnica densa y desciende hasta las rodillas, armada de las armas de su señor por adelante, detrás y en las mangas. Es una vestimenta que indica que su portador se beneficia de los privilegios de inmunidad de los heraldos. El tabardo transforma al heraldo en un símbolo viviente de las armas y del honor de su señor.

En la Edad Media, el heraldo se vuelve un servidor público al servicio de un príncipe o un señor. En el desarrollo de la guerra, está encargado de llevar la declaración de guerra, las advertencias. Para los caballeros que participan en una refriega (sea en batalla o en torneo), puede recibir testamentos o depósitos sagrados y se asegura de los dignos servicios funerales en caso de ser necesario. Su papel se completa finalmente sobre todo lo que respecta al honor: reconoce las armas de los nobles y vigila los blasones, preside las ceremonias y los juegos, y es testigo de actos de valor.

En los torneos y las justas, los heraldos anunciaban al caballero mencionando su blasón, es decir la descripción de las figuras cubriendo su escudo, antes de nombrar a su titular. Esta práctica es el origen del lenguaje heráldico, en un origen natural y comprensible para todo el público. Es esta práctica la que funda y establece la heráldica.


A partir del siglo XIV, los heraldos se convierten en especialistas de la heráldica, o la ciencia de las armerías y blasones. Son ellos quienes codifican la composición y la descripción formulando, notablemente, las reglas del blasón, viajando y estableciendo armerías para pintar y retener las que encontraban.

El rey de armas es aquel que está designado para juzgar las armerías (y los títulos de nobleza).

Las figuras pintadas en el escudo, establecidas y enunciadas por los heraldos, dan origen a la heráldica. La heráldica es esencialmente la ciencia de los heraldos, y su origen no puede comprenderse sino a través de su rol.

El primer elemento que fue armado, con un objetivo militar, fue el escudo del caballero. Después estos elementos fueron retomados en todo su equipo, para permitir reconocer al titular (en los lados de sus armas) pero también para representar (estandarte) o marcar su propiedad (cascos y armaduras de caballos)...

Este vínculo entre las armas y su titular fue retomado en la composición de los sellos. Las armerías fueron así transformadas en la imagen de la personalidad jurídica. La práctica de sellos armados se extendió hasta ser de uso común de todas las entidades capaces de tener un sello. Esta práctica aún está viva en el uso de los anillos armados, los cuales están, en principio, destinados a servir de sello —es por lo que están grabados de manera cóncava y normalmente usados en el dedo meñique—.

En un principio reservadas a los jefes de guerra que las portaban en sus escudos (fin del s. XI), el uso de armerías se extendió progresivamente a los caballeros y después a la nobleza (s. XII). A través de la identificación de la persona por las armerías, notablemente en los sellos, el uso se extendió a las mujeres y a los nobles prelados (fin del s. XII). y de los prelados a los burgueses, artesanos y jueces, capítulos, corporaciones, comunidades urbanas (principios del s. XIII), comunidades eclesiásticas y órdenes religiosas (s. XIV), señoríos, dominios, provincias, universidades y administraciones civiles... Transformadas en un signo de identidad social, las armas se vuelven hereditarias y designan a casas, es decir a las familias y vínculos de parentesco (s. XV), después, y más generalmente, a vínculos sociales, que son cada vez más representados.

Hasta el siglo XVI, las figuras empleadas eran principalmente figuras animales, en número bastante restringido (una quincena de uso corriente), así como algunos muebles inanimados (varias veces abstractos), y sobre todo figuras geométricas. Sin embargo, el repertorio se engrandece con objetos, armas, partes del cuerpo, edificios, etcétera.

Armar un objeto le agregaba un elemento decorativo y afirmaba un vínculo con el titular, legible y comprensible por aquellos que no sabían leer. Las armerías se encontraban así en todos los testimonios del pasado: documentos, libros, tapicerías, monumentos, placas de chimeneas, muebles, joyas, vehículos... La identificación de las armerías (cuando no son fantásticas) permiten remplazar su soporte en el tiempo y el espacio social, y de retrasar parte de la historia del origen geográfico. La identificación del titular es facilitada por los ornamentos exteriores, notablemente las órdenes de caballería representadas. Estos pueden conducir a una gran precisión (incluyendo el año de creación), cuando esta ha modificado frecuentemente la composición de sus armas y la conjunción de armas sobre un mismo soporte puede conducir a conclusiones incluso más precisas.

La composición de un blasón representó gráficamente la situación de un titular conforme a un cierto orden social, entre los siglos XIII y XIX. El estudio del blasón supone entonces un cierto conocimiento de la sociedad y de su organización en nobleza, rangos, órdenes y costumbres.

Sin embargo, tener armerías nunca ha sido, desde el punto de vista histórico, un privilegio de una clase noble.

Las armas no son nobles por naturaleza, en un inicio no son más que la insignia del titular. Es la obligación de este titular “ennoblecerlas”, es decir manifestar su nobleza por sus actos, otorgándoles honor y gloria a sus armas. El reconocimiento social oficial de este carácter noble, o “ennoblecimiento”, no viene a reconocer sino una nobleza que ya ha sido adquirida previamente.

El noble es esencialmente el “jefe” de algo, es quien tiene gloria y honor. El medio para acceder puede ser por las armas, por violencia o usurpación, por herencia de posesiones o siendo el titular de un cargo... En esta lógica, el ejercicio eficaz y durable del poder es su propia legitimación y solo el resultado cuenta en el largo plazo. Una persona es reconocida como noble cuando ocupa una situación de mando o responsabilidad por un tiempo prolongado, al punto de identificarla con esa persona social. Las armas representan a la vez a la persona, su poder actual y la gloria acumulada por muchas generaciones.

El éxito atrae más éxito, incluido a los miembros de su familia, y una casa “noble” tiende a mantenerse así. La dirección de unas tierras o de un territorio es generalmente hereditaria y no es siempre posible distinguir las armas de una tierra de aquellas de la casa que la dirige. En cambio, un cargo es generalmente personal, aunque está más a voluntad que figure en los ornamentos exteriores que en las armas propiamente dichas.

Las armas más famosas son el signo de una propiedad colectiva con las que se debe o desea relacionar. La relación se traduce en retomar las armas integralmente (en caso del jefe de la rama), con una brisura o en una composición. Esta relación se obtiene por derecho (título, herencia y rama), por adquisición (dominios poseídos) o por privilegio adquirido o concedido. Es un honor el portar armas famosas y este honor obliga en principio al titular a contribuir a la gloria de esas armas. Es eso lo que se expresa en la frase “Nobleza obligada”: portar armas nobles significa simplemente que se es de una rama noble pero no dice nada más sobre su propio carácter.

El titular de un blasón es la “persona” que designa ese blasón. Las armas le pertenecen a un cierto titular, del cual se representan los atributos por los adornos exteriores. Es el conjunto de esta relación lo que representan las armerías. El titular puede ser de cualquier tipo (individuo, familia, colectividad o institución).

La composición de armas nuevas traduce lo que el titular poner por delante en relación a un tejido de vínculos y de derechos sociales: simbólica primitiva, pero también pertenencia a una rama (por las armas de la familia), afirmación de su genealogía (por composición de las armas de sus padres, abuelos), matrimonio (por composición de las armas del cónyuge), dominios sobre los cuales se tienen derechos reales o supuestos, actuales o pasados. Las armas de las ciudades o instituciones se componen con aquellas de su fundador o señor.

Las armas, propiamente dicho, son generalmente invariables pero los adornos exteriores dependen generalmente del titular: sus títulos, dignidades y cualidades, su función o su condición social.

Las órdenes de caballería nacen con las cruzadas, alrededor de órdenes religiosas con vocación militar (Orden del Temple, Orden del Santo Sepulcro, Orden de los Hospitalarios...). Como todas las órdenes monásticas, esas órdenes pueden asociar a no-religiosos: la pertenencia a una orden manifiesta su asociación con una cierta vocación (varia de acuerdo a la orden) y el prestigio de la orden descansa sobre el miembro asociado. Al término de la Edad Media, las órdenes de corte sin vocación religiosa fueron creadas, la más prestigiosa siendo la orden del Toisón de Oro.

Las órdenes pueden ser soberanas (por ejemplo, la Orden de Malta). Lo más frecuente es que estaban unidas al país o a la casa dinástica que la ha creado.

Las insignias de la orden de caballería fueron generalmente parte de los ornamentos exteriores de las armerías. Ciertas órdenes se inscribían, dependiendo del jefe, en el escudo del titular. Lo más usual es que se añadiera un collar de la orden alrededor del escudo. Cuando el titular era miembro de muchas órdenes, la orden más prestigiosa se situaba en el exterior.

La admisión a una orden era el objeto de un acto oficial y registrado, es por ello que la representación de un collar de la orden en las armerías permiten identificar al titular más precisamente que simplemente enunciando las armas familiares.

En Francia, las órdenes de caballería nacionales (Saint-Michel, Saint-Esprit...) fueron suprimidas por la Asamblea Constituyente, al mismo tiempo que los atributos de la nobleza. Napoleón creó la orden nacional de la Legión de Honor y la Orden Nacional del Mérito fue creada en el Siglo XX.

En Francia, la Asamblea Constituyente decreta el 19 de junio de 1790 la supresión de la nobleza (como estatuto de la persona) y de sus atributos reales o supuestos: títulos de dominio, privilegios, órdenes de caballería, armerías y libertades. Prohibidas por un tiempo, las armerías fueron restauradas al principio del s. XIX por Napoleón por decreto el 1 de marzo de 1808 que limitó, durante el Imperio, su uso a los nobles, limitación abolida por Luis XVIII durante la restauración. Las armerías ya no son el objetivo social en las que se habían convertido al final del antiguo régimen.

Jurídicamente, las armas son el equivalente designado de un nombre propio (nombre de familia o nombre de lugar) y son accesorios a ese nombre. Las armas son una propiedad regular, de transmisión hereditaria y susceptible de ser adquirido o conferido. El derecho asociado con las armerías se parece como a aquel de las marcas y es probablemente el primer tema sobre el que se elaboró un derecho internacional (por normas o costumbres).

Como regla general, cada uno puede portar armas, a reserva de no usurpar aquellas de otros. Algunos países que han conservado una nobleza (notablemente el Reino Unido) le han impuesto una reglamentación específica, hasta un tribunal dedicado (Escocia). Sin embargo, el “derecho” a portar tales o tales armas es por la mayor parte un asunto de costumbre.

El principal problema del derecho de armas es, para un titular, el probar la anterioridad en el uso de un blasón que ha reivindicado. Esta prueba es generalmente aportada a través de actos oficiales que registran un blasón dado o acuerdan una modificación en las armas preexistentes.

Las reglas del blasón per se, es decir aquellas que hablan sobre la composición de las armas, están implícitas y responden a las costumbres. El carácter bien o mal constituido de un blasón se evalúa en función de un “espíritu heráldico”. La evaluación se apoya sobre el concejo de autoridades eminentes que pronuncian sus lecciones en sus tratados de heráldica a los que hacen referencia. Estas reglas modificadas o movibles como aquellas de buen tono: cuando el consejo de las autoridades es unánime, el juicio puede ser trazado, para los casos más marginales este debe ser modificado.

Aunque la creación de los blasones depende de la iniciativa de sus futuros propietarios, tiene, desde el inicio, reglas más o menos estrictas, con vistas a hacer la identificación eficaz: lectura fácil por el empleo de colores francos sobreponiéndose los unos sobre los otros, motivos de gran tamaño con contornos simplificados fácilmente legibles, y sobre todo la unicidad de las armerías —a menudo no respetada, más por ignorancia que por voluntad de plagio—.

Esta voluntad de identidad se traduce también por el uso de símbolos, recuerdo de hechos marcantes o traducciones de rasgos característicos vinculados al propietario ("Armas alusivas"), o por figuración del patronímico, juego de palabras ("Armas parlantes") —p.e. el “jeroglífico” que constituyen las armas de "Gonesse", una comuna del Valle del Oise, el “gozne” ("gond" en francés) enlazado por una letra S: "gond-esse" en francés—.

Pero el blasón no está fijado y puede evolucionar en función:


De igual manera puede desaparecer y ser reemplazado por un blasón de sustitución, cuando el blasón original ha sido “deshonrado” por una acción poco honorable de su propietario o de un ancestro del mismo (ver león, león "cobarde", "vil", etc.).

De hecho no se conoce más que una sola regla que se pueda enunciar en términos indiscutibles —es decir para la que se pueda determinar con certeza si es respetada o no—: «No metal sobre metal, no esmalte sobre esmalte». Esta es la "regla de contrariedad de los esmaltes".

A veces se puede afirmar:


Las armas son indudablemente significativas, hay sistemas precisos y completos de interpretación simbólica de armas ya definidos, pero tales sistemas aparentan ser una “mancia” (arte adivinatorio). Aunque hay armas que han sido deliberadamente compuestas en referencia a uno de esos sistemas, no es el caso general, y la identificación precisa del sistema utilizado es igualmente una tarea delicada.

El valor que puede tomar una figura en un sistema particular es el propio de cada sistema y no puede generalizarse. Si muchos cruzados portaron una cruz, si el bezante carga usualmente el blasón de un antiguo cruzado, no podemos deducir por eso que todas las cruces heráldicas fueron creadas en las cruzadas, ni que la pieza honorable en forma de cruz haya tenido siempre un motivo religioso: puede no ser más que una figura puramente geométrica, o resultar de una composición, o referirse a un lugar.

Pero después de establecer como principio que hay siempre un significado en cada elección de figuras, hemos de decir que numerosas armas no tienen significados conocidos, y los que se les dan habitualmente no son, frecuentemente, más que hipótesis. La interpretación de lo simbólico debe ser prudente con su contexto: el titular de las armas no las ha compuesto arbitrariamente y un significado puede tener su origen en armas preexistentes.

Los escudos compuestos pueden corresponder a matrimonios, a piezas concedidas por la Gracia del Rey o por adquisiciones. Quienes cargan sus derechos en las armas correspondientes los traducen gráficamente en la composición de las armerías.

La composición más simple consiste en poner dos escudos juntos manteniendo la forma individual de cada uno. En la Edad Media se tenía el hábito de juntar los blasones de los cónyuges, el marido a diestra (el lugar de honor) y la mujer a la siniestra. Después esta moda evolucionó y se acuartelaron los blasones con las armas de los esposos —en el primer y cuarto las armas del esposo, en el segundo y el tercero las de la esposa—.

En los siglos XVII al XVIII, las armas subcompuestas buscaban (muy artificialmente) representar sistemáticamente todas las alianzas y ancestros de un personaje, por sus cuarteles de nobleza, al punto de volverse globalmente ilegibles. En estos excesos, que completaban las grandes armas, la composición se opone a la primera regla del blasón, que le impone a las armas el ser simples. Sin embargo, es legítimo (aun por vanidad) representar sobre un mismo escudo las armas de todos los abuelos, bisabuelos, tatarabuelos etc. (para mostrar respectivamente 8, 16, 32 ó 64 cuarteles de nobleza), pero esta composición es artificial y no muestra más que las alianzas. Las armas personales deben mantenerse simples.

Los esmaltes son el nombre de las diferentes tonalidades cromáticas representadas en heráldica. Los esmaltes se dividen en tres grupos: metales, colores y una combinación de ambos llamada forros.








</doc>
<doc id="1442" url="https://es.wikipedia.org/wiki?curid=1442" title="Harry Potter">
Harry Potter

Harry Potter (también abreviado HP) es una serie de novelas fantásticas escrita por la autora británica J. K. Rowling, considerada una de las sagas más importantes de la historia. Realmente la más leída según el Libro de los récords Guiness. En ella se describen las aventuras del joven aprendiz de magia y hechicería Harry Potter y sus amigos Hermione Granger y Ron Weasley, durante los años que pasan en el Colegio Hogwarts de Magia y Hechicería. El argumento se centra en la lucha entre Harry Potter y el malvado mago Lord Voldemort, quien asesinó a los padres de Harry en un intento fallido de matar a Harry, para así poder acabar con la profecía que citaba su propia muerte. Voldemort no consigue acabar con la vida de Harry Potter, pues este último, al estar protegido por el amor de su madre, logra protegerse, y, a la vez, adquirir una relación (hablando tanto de manera mental como de poderes) con Voldemort. De ahí viene su cicatriz con forma de rayo (Rowling explicó que la forma de esta cicatriz era tan solo por su gusto a los rayos, no tenía nada escondido detrás).

Desde el lanzamiento de la primera novela, "Harry Potter y la piedra filosofal" en 1997, la serie logró una inmensa popularidad, críticas favorables y éxito comercial alrededor del mundo. Para julio de 2013 se habían vendido entre 400 y 450 millones de ejemplares de los siete libros, que los ubican como la de la historia y los cuales han sido traducidos a más de 65 idiomas, entre los que se incluyen el latín y el griego antiguo. El séptimo y último libro, "Harry Potter y las Reliquias de la Muerte" fue lanzado mundialmente en inglés el 21 de julio de 2007, mientras que en español se publicó el 21 de febrero de 2008.

La editora Bloomsbury Publishing tiene los derechos de publicación en inglés para el Reino Unido y el resto de Europa, mientras que la editorial Scholastic los tiene para Estados Unidos y la Editorial Salamandra los tiene para el idioma español y su distribución por España e Hispanoamérica.

El éxito de las novelas ha hecho de la marca "Harry Potter" una de las más exitosas del mundo, con un valor de US$15 000 millones, y a Rowling la primera escritora de la historia en alcanzar US$1000 millones en concepto de ganancias gracias a su trabajo. En 2005, fue la novena persona con el ingreso anual más alto del mundo. 

En 1999, la productora de cine Warner Bros. adquirió los derechos para adaptar los siete libros a una serie de películas. La última de ellas, "Harry Potter y las Reliquias de la Muerte - Parte 2", se estrenó el 15 de julio de 2011 y con ocho películas realizadas, la serie se convirtió en la del cine en concepto de recaudaciones en taquilla.

La historia comienza con la celebración del mundo mágico. Durante muchos años, había sido aterrorizado por el malvado mago Lord Voldemort. La noche del 31 de octubre, mató a Lily y James Potter. Sin embargo, cuando intenta matar a su hijo de 1 año, Harry, la maldición asesina "" se vuelve sobre sí mismo. El cuerpo de Voldemort resulta destruido, pero él sobrevive: no está muerto ni vivo. Por su parte, a Harry solo le queda una cicatriz con forma de rayo en la frente que es el único remanente físico de la maldición de Voldemort. Harry es el único sobreviviente de la maldición asesina, y a raíz de la misteriosa derrota de Voldemort, el mundo mágico empieza a llamarlo como «el niño que sobrevivió». 

El 1 de noviembre, Rubeus Hagrid, un semi-gigante, deja a Harry con los únicos parientes que le quedan, los crueles Dursley. Estos son su tío Vernon, su tía Petunia y Dudley, su primo malcriado. Ellos intentarán en vano esconder su herencia mágica (por ejemplo, al decirle que sus padres murieron en un accidente de tráfico, o castigándolo severamente después de cualquier comportamiento extraño). Sin embargo, la víspera de su undécimo cumpleaños, Harry tiene su primer contacto con el mundo mágico cuando recibe cartas del Colegio Hogwarts de Magia y Hechicería, las cuales eran entregadas por lechuzas, aunque su tío impide que pueda leerlas. Ya en su cumpleaños, Hagrid aparece y le dice a Harry que existe un mundo mágico y otro «muggle» , puesto que él es un mago, ha sido invitado a asistir al colegio.

Al contrario que en novelas como las de "Las Crónicas de Narnia", en las que se trata un universo alternativo, o "El Señor de los Anillos", donde la «Tierra Media» se trata de un pasado ficticio, el mundo mágico de las novelas de Harry Potter es un universo paralelo al nuestro y contiene diversos elementos mágicos análogos a cosas del mundo no mágico o muggle. Este universo mágico tiene una organización política para cada Estado; en el caso del Reino Unido, donde se desarrolla la mayor parte de la acción, la máxima institución es el Ministerio de Magia. Existe un «Estatuto Internacional del Secreto» que obliga a todos los magos y brujas del mundo a mantener en secreto la existencia del mundo mágico de los muggles. 

La capacidad de hacer magia, según las novelas, es innata más que aprendida, aunque los jóvenes magos deben asistir a escuelas con el fin de dominarla y controlarla. Esta capacidad es totalmente hereditaria, aunque existan magos hijos de muggles (o «sangre sucia» de forma despectiva) pues estos siempre debieron tener un ascendente mago; también es posible que existan hijos de magos sin alguna capacidad mágica. A estos últimos se los llama «squibs». Los magos tienen un desarrollado sistema social, con su propia moneda, sanidad y una compleja red de transportes y comunicaciones.

Dentro del mundo mágico, coexisten con los magos que también son mantenidas en secreto y fuera de contacto con los muggles. Entre ellas se encuentran dragones, fantasmas, unicornios, sirenas, centauros y otras inventadas o adaptadas por la autora como los o los .

Los libros evitan ubicar la historia en algún año en particular, sin embargo hay un par de referencias que permiten establecer una línea de tiempo con años reales. La primera se da en la segunda novela, "Harry Potter y la cámara secreta", en la que el fantasma Nick Casi Decapitado celebra el 500º aniversario de su muerte, que ocurrió el 31 de octubre de 1492, por lo tanto, el libro se ubica en el ciclo lectivo de 1992 a 1993. Esta cronología se reitera en "Harry Potter y las reliquias de la Muerte", cuando se indica que la muerte de James y Lily Potter ocurrió el 31 de octubre de 1981. Estos datos permiten deducir que el argumento de la historia transcurre desde 1981, cuando Dumbledore entrega a Harry a sus tíos al comienzo de "La piedra filosofal", hasta 1998, al final de "Las Reliquias de la Muerte".


"Harry Potter y la piedra filosofal" ("Harry Potter and the Philosopher's Stone") es el primer libro de la serie, fue publicado en Reino Unido el 26 de junio de 1997 y en español en marzo de 1999. Se trata de uno de los libros más vendidos de la historia, las estimaciones de sus ventas mundiales superan los 110 millones de copias. En la primavera de 2007, una primera edición firmada por Rowling fue subastada en Londres por £27 876.

En esta primera obra se introducen la mayoría de los personajes principales de la serie, así como muchos de los lugares donde se desarrollará la acción. Se narran los primeros pasos de Harry en el mundo de la magia, así como su primer enfrentamiento con Voldemort, quien en su búsqueda de la inmortalidad quiere obtener el poder de la piedra filosofal.

"Harry Potter y la cámara secreta" ("Harry Potter and the Chamber of Secrets") fue publicado originalmente el 2 de julio de 1998, y en español en octubre de 1999. Muchos de los elementos del primer boceto de este libro fueron eliminados tanto por su autora como por el editor. Además, el libro tiene una importante relación temática con el sexto libro. Mucha de la información que iba a ser develada en este tomo fue desplazada a la sexta entrega. Como consecuencia de esto, muchos de los elementos que aparecen en una forma cotidiana en "La cámara secreta" aparecen nuevamente en "El misterio del príncipe" con su verdadera relevancia.

El libro relata el segundo año de Harry en Hogwarts. Un día un elfo llamado Dobby vino a casa de Harry para avisarle de que Hogwarts corría un grave peligro. Más tarde su amigo Ron, le recogerá en un coche volador y así empieza su curso en Hogwarts durante el cual aparecen mensajes en las paredes de los pasillos de la escuela que advierten que la Cámara de los Secretos ha sido abierta, seguidos de una serie de ataques a alumnos que no provienen de familias con sangre mágica. En esta entrega introducen la figura del elfo doméstico y personajes relevantes para el resto de la serie, como Lucius Malfoy, Ginny Weasley y Arthur Weasley, además de revelar un poco más del pasado de Voldemort a través de su diario personal.

"Harry Potter y el prisionero de Azkaban" ("Harry Potter and the Prisoner of Azkaban") fue publicado en inglés el 8 de julio de 1999, mientras que en español lo hizo en abril de 2000. Este fue el libro que más rápido escribió Rowling, pues lo terminó en tan solo un año después de comenzar a escribirlo. Fue además acreedor del Premio Costa y del Premio Bram Stoker, entre otros, que lo ubican como uno de los libros fantásticos más laureados de los últimos años.

En esta oportunidad se introducen la figura del dementor y los personajes de Remus Lupin y Sirius Black, quien al inicio de la novela escapa de la prisión de Azkaban, además de desarrollar la historia de los padres de Harry. Es el único libro de la serie en el que no aparece Voldemort.

"Harry Potter y el cáliz de fuego" ("Harry Potter and the Goblet of Fire") fue publicado en inglés el 8 de julio de 2000 y en español en marzo de 2001. El tamaño del libro incrementó considerablemente respecto a los primeros tres, una idea de la que Rowling estaba al tanto desde la concepción de la novela. El título atravesó diversas modificaciones, entre las cuales se incluyeron "Harry Potter y el Torneo Doomspeell", "Harry Potter y el Torneo de los tres magos", hasta que la autora se inclinó por "El cáliz de fuego" pues recordaba al concepto de la «copa del destino», que de acuerdo a ella era el tema del libro. La novela fue ganadora del Premio Hugo a la mejor novela en 2001.

En esta ocasión, se narra el cuarto año de Harry en Hogwarts y el misterio que rodea el ingreso involuntario de su nombre en el Torneo de los tres magos, en el cual es obligado a competir junto a otros tres participantes. La historia explora más a fondo el mundo mágico y termina con el resurgimiento de Lord Voldemort. Previo a la publicación del libro, se generó mucha controversia y anticipación ante el anuncio de la autora de que un personaje moriría.

"Harry Potter y la Orden del Fénix" ("Harry Potter and the Order of the Phoenix") es con casi 900 páginas en su edición inglesael libro más largo de la serie, un hecho que la propia autora considera un defecto. Fue publicado mundialmente en inglés el 21 de junio de 2003, y en español el 21 de febrero de 2004. La edición en español a cargo de Salamandra constó de tres versiones: una para España, otra para el cono sur y otra para Colombia, México y Estados Unidos. Esta distinción se hizo para respetar algunas particularidades del lenguaje regional. Su tirada inicial en español fue de 1 100 000 copias. 

En el quinto libro, Harry Potter debe enfrentarse tanto a un Voldemort resurgido como al resto del mundo mágico que se niega a creer que esto es cierto, empezando por el Ministerio de Magia. Este nombra a Dolores Umbridge como la nueva directora de Hogwarts, y junto con Luna Lovegood y Bellatrix Lestrange son los tres personajes más destacados que se introducen en esta entrega. Por otro lado, se revela una importante profecía que concierne a Harry y a Voldemort.

"Harry Potter y el misterio del príncipe" ("Harry Potter and the Half-Blood Prince") fue publicado en inglés el 16 de julio de 2005 y fue presentado por Rowling en una rueda de prensa reservada solo a niños entre 8 y 16 años. Por su parte, en español fue publicado el 23 de febrero de 2006, con una tirada inicial de un millón de ejemplares. Casi un año antes de su publicación original, Rowling había manifestado en su sitio web oficial su voluntad de matar a otro personaje, por lo que se sucedieron una serie de apuestas no oficiales en las que se barajaron las posibilidades.

En esta sexta entrega, Harry se topa con un antiguo libro de texto de pociones lleno de anotaciones y recomendaciones firmadas por un misterioso príncipe. Al mismo tiempo, recibe clases particulares por el propio director del colegio, Albus Dumbledore, que le hace conocer momentos del pasado de Voldemort, para así enseñarle lo que son los horrocruxes, objetos elementales para lograr su victoria. Al final del libro, el profesor Severus Snape, cuya lealtad estuvo en duda durante toda la serie, asesina a Dumbledore. La frase "Snape kills Dumbledore" (Snape mata a Dumbledore) se convirtió en un fenómeno de internet que impulsó todo tipo de videos y gráficos.

La séptima novela, "Harry Potter y las reliquias de la Muerte" ("Harry Potter and the Deathly Hallows"), fue publicada en inglés el 21 de julio de 2007, cerrando la serie que duró una década. En español fue publicado el 21 de febrero de 2008, con una tirada inicial de un millón y medio de ejemplares. El libro batió récords de venta, con más de 11 millones de copias vendidas en sus primeras 48 horas, solo en el Reino Unido y Estados Unidos. La marca anterior la tenía el "Misterio del príncipe".

Esta última novela narra los acontecimientos que siguen directamente a la muerte de Dumbledore, en los que Voldemort finaliza su ascenso al poder y logra dominar el Ministerio de Magia. Harry y sus amigos deciden no asistir a su último año en Hogwarts, para salir en la búsqueda de los horrocruxes restantes. Finalmente, se lleva a cabo la batalla de Hogwarts, entre la Orden del Fénix, alumnos y profesores del colegio, por un lado, y Voldemort y los Mortífagos, por el otro. La novela finaliza con un epílogo que cuenta el futuro de los personajes supervivientes 19 años después del enfrentamiento, mostrando que cada uno de ellos ha formado sus vidas.

El 23 de octubre de 2015, J.K Rowing anunció una octava parte de la saga.

La octava entrega de la serie de Harry Potter (que está dividida en dos partes) se publicó el 31 de julio de 2016. No será una novela como las anteriores, sino sencillamente el guion utilizado en la obra de teatro sobre el mismo, la cual se estrenó el 30 de julio de 2016.

Adicionalmente, Rowling escribió seis libros secundarios que se ubican dentro del universo argumental de las ocho novelas principales. Todos se escribieron con un carácter benéfico, dado que sus recaudaciones fueron donadas a las entidades Comic Relief y The Children's Voice.

"Animales fantásticos y dónde encontrarlos" (en inglés, "Fantastic Beasts and Where to Find Them") es un libro de texto usado por los estudiantes de Hogwarts, escrito en la ficción por Newt Scamander, un afamado mago biólogo. Describe y analiza las distintas criaturas mágicas que habitan en el mundo. Fue publicado el 5 de marzo de 2001, con un diseño que representa a la copia usada por Harry Potter en "el prisionero de Azkaban". Incluye además algunas notas al margen hechas supuestamente por los tres protagonistas. El 12 de septiembre de 2013 Warner Bros. anunció que se estaba preparando una película basada en este libro con el guion de J.K. Rowling. El 15 de octubre de 2014, Donde ya es oficial que el actor Eddie redmayne Protagonizara la película. Warner Bros anunció que "Animales fantásticos y dónde encontrarlos" sería una pentalogía que se estrenará en 2016, 2018, 2020, 2022 y 2024.

"Quidditch a través de los tiempos" (en inglés, "Quidditch Through the Ages") fue publicado en forma conjunta con el anterior, y persiguió los mismos fines benéficos. En este caso, se trata de un manual sobre las reglas y la historia del quidditch, el deporte más popular entre los magos. Aunque en la serie aparece como un regalo de Navidad de Hermione a Harry, el libro está diseñado como un ejemplar de la biblioteca de Hogwarts, con un aspecto algo ajado y con una pegatina que detalla los alumnos que han solicitado su préstamo anteriormente.

Por su parte, "Los cuentos de Beedle el Bardo" ("The Tales of Beedle the Bard") fue escrito a finales de 2007 como una «despedida de la serie» por parte de la autora. Solo se hicieron siete copias manuscritas e ilustradas por Rowling, de las cuales seis fueron regaladas y una fue subastada en Londres. La subasta se llevó a cabo en la casa Sotheby's de la ciudad, y el libro fue comprado por Amazon.com por un precio de £ 1 950 000. Todas las copias, de 157 páginas, están forradas en cuero marroquí con ornamentos de plata e incrustaciones de piedras semi preciosas.

Según la serie, Beedle el Bardo es al ficticio mundo mágico, lo que los hermanos Grimm o Hans Christian Andersen son al mundo real. Sus cuentos son conocidos popularmente entre los niños magos como lo son Cenicienta o Blancanieves entre los muggles. Una recopilación de estas historias, escrita en runas antiguas, aparece en el último libro de la heptalogía como una herencia de Albus Dumbledore a Hermione Granger y tiene un papel fundamental en el desarrollo del argumento.






Según cuenta en su sitio web, en 1990 Rowling estaba viajando en un tren de Mánchester a Londres, cuando la idea «de repente se formó en su cabeza».

En 1995, "Harry Potter y la piedra filosofal" estaba terminado y el manuscrito fue enviado a diversos agentes. El segundo agente al que acudió, se ofreció a representarla y enviar su manuscrito a Bloomsbury Publishing. Después de que ocho editoras rechazaron el libro, Bloomsbury ofreció a Rowling un adelanto de £2500 para la publicación.

A pesar de que Rowling no había tenido en mente una categoría de edad particular para sus potenciales lectores cuando comenzó a escribir, los editores apuntaron inicialmente a niños de entre nueve y once años. En la víspera de la publicación, los editores pidieron a Joanne Rowling adoptar un seudónimo con un género más neutral, para abordar a los chicos varones de esta edad, temiendo que no estarían interesados en leer una novela escrita por una mujer. Ella eligió utilizar J.K. Rowling (Joanne Kathleen Rowling), omitiendo su nombre y usando el de su abuela como segundo.

El primer libro de "Harry Potter" fue publicado en Reino Unido por Bloomsbury en junio de 1997 y en los Estados Unidos por Scholastic en septiembre de 1998, previo pago de $105 000 a Rowling, una suma sin precedentes para un libro para niños por el derecho de las ediciones en EU. Temiendo que algunos de los lectores no entendieran la palabra «filosofal» ni la asociaran a un tema mágico (la piedra filosofal está relacionada con la alquimia), Scholastic insistió en que el libro sea retitulado como "Harry Potter and the Sorcerer's Stone" ("Harry Potter y la piedra del hechicero") para el mercado estadounidense.

Los editores de Rowling lograron capitalizar este fenómeno gracias a las rápidas y sucesivas publicaciones de los cuatro primeros libros que no permitieron que decayera el interés de los lectores, aun incluso cuando Rowling se tomó un descanso entre la publicación de "el cáliz de fuego" y "la Orden del Fénix". La serie también logró seguidores adultos, lo que impulsó dos ediciones de cada libro de Harry Potter, con texto idéntico, pero con una carátula dirigida a los niños y otra a los mayores.

En diciembre de 2005, Rowling declaró en su sitio web que «2006 será el año en el que escribiré el último libro de la serie "Harry Potter".» El progreso de "Harry Potter y las reliquias de la Muerte" fue detallado en subsecuentes actualizaciones de su diario virtual hasta su publicación, el 21 de julio de 2007.

Rowling terminó el libro el 11 de enero de 2007 en el hotel Balmoral, en Edimburgo, donde escribió un mensaje debajo de un busto de Hermes que reza: «JK Rowling terminó de escribir Harry Potter y las reliquias de la Muerte en esta habitación (652) el 11 de enero de 2007.» 

Sin embargo, Rowling declaró que el último capítulo del séptimo libro (el epílogo) lo escribió «en más o menos 1990». En junio de 2006, en una aparición en el talk show británico "Richard & Judy", Rowling anunció que este capítulo había sido modificado, dado que un personaje «se salvó» y otros dos que anteriormente sobrevivían a la historia, ahora morían. También dijo que veía la lógica en matar a Harry Potter, con el fin de evitar que otros autores escribiesen libros sobre la vida de Harry luego de Hogwarts.

Rowling escribió los siete libros de "Harry Potter" en 17 años. En una entrevista en el año 2000 a su editor estadounidense, Rowling declaró que no hay una universidad después de Hogwarts. En cuanto a la continuación de la serie luego del séptimo libro, dijo: «no voy a decir "nunca", pero no tengo planes de escribir un octavo libro».

Cuando se le preguntó sobre escribir otros libros relacionados con la serie, al estilo de "Quidditch a través de los tiempos" o "Animales fantásticos y dónde encontrarlos", respondió que consideraría hacerlo si los beneficios son destinados a la caridad, como bien sucedió con estos dos libros. Otra sugerencia fue un tipo de enciclopedia, que contuviera información que no tuvo cabida en la serie. Sobre esto, el 24 de julio de 2007, Rowling anunció en una entrevista que «probablemente» escribirá una enciclopedia del mundo de "Harry Potter", la cual incluiría datos descartados de la historia, así como también información a lo ocurrido después de "reliquias de la Muerte", como detalles acerca del futuro de los personajes, etc.

Las novelas se basan principalmente dentro del género fantástico, aunque en muchos aspectos también pueden ser consideradas "Bildungsromane", o novelas de formación, en las que se detalla algún tipo de desarrollo de un personaje. La historia se ubica principalmente en Hogwarts, un internado británico para magos. En este sentido, las novelas son «descendientes directos de "Tom Brown's School Days" de Thomas Hughes y otras novelas victorianas y eduardianas que se basan en la vida en los colegios públicos». Por su parte, en palabras de Stephen King, las novelas son «astutos cuentos de misterio», y cada libro está construido al estilo de las aventuras de Sherlock Holmes, donde se dejan un número de pistas escondidas en la narrativa, mientras los personajes persiguen a una serie de sospechosos a lo largo de exóticos escenarios, llevando a un giro final inesperado. Están escritas en tercera persona con un narrador omnisciente que focaliza en Harry salvo contadas excepciones (como los primeros capítulos de "La piedra filosofal", "El misterio del príncipe" o "Las Reliquias de la Muerte"), y los secretos de la historia le son desvelados al lector al mismo tiempo que a Harry.

Los libros tienden a seguir una fórmula muy estricta. Ubicados a lo largo de años consecutivos, generalmente comienzan con Harry en casa de los Dursley, en el mundo "muggle". Seguido, se traslada a algún escenario mágico, como , el o , por un breve período antes de empezar el año escolar, el cual comienza cuando se sube al Expreso de Hogwarts, en el Andén 9¾. Una vez allí, se desarrolla la historia que alcanza su clímax cerca o justo después de los exámenes finales, cuando Harry debe enfrentarse a Voldemort o alguno de sus Mortífagos. Por último, aprende una importante lección o detalle clave de la trama en una conversación con Albus Dumbledore. Esta fórmula se rompe completamente en la última novela, en la que Harry y sus amigos pasan la mayor parte del tiempo fuera de Hogwarts, y solo regresan allí para la confrontación final.

Por otro lado, Voldemort está presente de alguna manera (físicamente, a través de un sueño o una visión) en cada capítulo hasta el quinto libro, y a partir del cual, aparece en la mayoría. Esta estructura permite al lector desentrañar los misterios al mismo tiempo que Harry, encontrando pistas solo cuando él lo hace.

Según Rowling, el principal tema del que se rodea la heptalogía es la muerte: «Mis libros son en buena parte sobre la muerte. Se inician con la muerte de los padres de Harry. Después está la obsesión de Voldemort de conquistar la muerte y su búsqueda de la inmortalidad a cualquier precio, el objetivo de cualquiera capaz de hacer magia. Entiendo por qué Voldemort quiere conquistar a la muerte. Todos le tenemos tanto miedo».

Distintos especialistas de la industria literaria han desarrollado otras interpretaciones de los temas que presentan los libros, unas más complejas que otras, y algunas incluyendo matices políticos. En general, se ha concluido que en las novelas se manifiestan temas como la normalidad, opresión, supervivencia, y la superación de estándares establecidos. Rowling ha declarado que los libros comprenden «un argumento a favor de la tolerancia» y que además transmiten un mensaje que propone «cuestionar la autoridad y no asumir que el "establishment" o la prensa te cuentan toda la verdad».

Mientras que se podría decir que los libros comprenden muchas otras temáticas, tales como el poder (o abuso de él), amor y prejuicio, las mismas están, según Rowling, «fuertemente arraigadas al argumento»; la autora prefiere dejar que estos conceptos «crezcan orgánicamente» más que sentarse e intentar de impartir conscientemente tales ideas a sus lectores. En la misma línea se encuentra la siempre presente temática adolescente, en cuya descripción la autora estuvo resuelta en admitir la sexualidad de sus personajes, con el fin de no «estancar a Harry en un permanente estado prepubescente».

El incremento del hábito de la lectura entre los niños y jóvenes ha sido la tendencia más destacada que se le atribuyó a "Harry Potter". Una encuesta llevada a cabo en 2006 por "Kids and Family Reading Report" y Scholastic arrojó como resultados que el 51 % de los lectores de la serie de entre 5 y 17 años dijo que no había leído por placer anteriormente a Harry Potter, pero que después sí lo hace. Además, el estudio afirma que el 65 % de los niños y el 76 % de los padres declaraba que el desempeño escolar de ellos mismos o de sus hijos había mejorado desde que empezaron a leer los libros. Charlie Griffiths, director de la "National Literacy Association", dijo «cualquiera que persuada a los niños a leer debería ser atesorado, y lo que Rowling nos ha dado con "Harry Potter" es por poco un milagro». Por su parte, el Primer Ministro británico, Gordon Brown, alabó a la escritora diciendo: «Creo que J. K. Rowling ha hecho más por la literatura que ningún otro ser humano».
A medida que la serie avanza, cada libro se vuelve progresivamente más largo, desarrollando habilidades literarias en los lectores. Una comparación muestra que cada libro, salvo el sexto, es más largo que su predecesor, requiriendo una mayor concentración y atención en aquellos niños que abordan la lectura de la serie.

También es destacable el fanatismo que consiguieron los libros. En respuesta a la ansiedad de los fanáticos, las librerías de todo el mundo comenzaron a organizar eventos que coincidían con el lanzamiento de los libros, empezando con la publicación de "el cáliz de fuego", en el 2000. Estos eventos, que incluían generalmente juegos, actuaciones y pintadas en la cara, han logrado una gran popularidad entre los fanáticos y han sido increíblemente exitosos en atraer compradores, hecho que se pone de manifiesto con la venta en el primer día de publicación de casi 9 millones de copias de las 10,8 millones de la tirada inicial.

"Harry Potter" también trajo cambios al mundo editorial, siendo uno de los más destacados la reforma de la lista de "best-sellers" del New York Times. El cambio vino inmediatamente después del lanzamiento de "el cáliz de fuego", en 2000, cuando los editores se quejaron del número de puestos que ocupaban los libros de Harry Potter y otros destinados al público infantil. Como consecuencia, el New York Times creó una lista separada para la literatura infantil.

La palabra "muggle" se ha extendido más allá de sus orígenes, siendo usada por muchas personas para indicar a aquel que le falta alguna habilidad. En 2003, el término entró en el Oxford English Dictionary con esa definición.

En noviembre de 2007, la revista "Advertising Age" estimó el valor total de la marca "Harry Potter" en US$15 000 millones. La popularidad de la serie se tradujo en un sustancial éxito financiero para Rowling, sus editores y otros dueños de los derechos de la marca. Este éxito hizo de Rowling la primera y hasta ahora única persona que amasó mil millones de dólares estadounidenses escribiendo libros. Esta cifra la ubicaría, según algunas fuentes, como la mujer más adinerada del Reino Unido, por encima de la Reina Isabel II.

Para el lanzamiento de "el cáliz de fuego", se usaron 9000 camiones de FedEx únicamente para entregar los libros. En Estados Unidos, la tirada inicial del libro fue de 3,8 millones de copias. Este récord fue sobrepasado por "la Orden del Fénix", con 8,5 millones, que a su vez fue superado por "el misterio del príncipe", cuya tirada inicial fue de 10,8 millones. Solo en EE. UU. y Reino Unido, se vendieron casi 9 millones de copias del sexto libro en las primeras 24 horas desde su publicación. Por su parte, la tirada inicial en inglés de "reliquias de la Muerte" fue de 12 millones de copias, estableciendo así un nuevo récord.

Por otro lado, algunas librerías declararon que la venta de libros de Harry Potter no es beneficiosa. La intensa competencia para ofrecer el mejor precio de las populares novelas rebajó los ingresos esperados. El precio sugerido para "las reliquias de la Muerte" fue de $35, pero Amazon.com ofreció el libro a un precio de oferta de $18, comportamiento que siguieron otras cadenas para mantenerse competitivas. Esto llevó a las librerías más pequeñas a vender el libro al precio sugerido, pero añadiendo otros beneficios, como cupones de descuento para la próxima compra u objetos de recuerdo relacionados con Harry Potter.

En sus principios, "Harry Potter" recibió críticas sobresalientes, que ayudaron a crear una gran base de lectores para la serie. Tras su publicación, muchos de los principales diarios británicos elogiaron a "la piedra filosofal". El "Mail on Sunday" lo describió como «el debut más imaginativo desde Roald Dahl», un punto de vista secundado por el "Sunday Times". Por su parte, "The Guardian" lo llamó «una novela ricamente texturizada, despegada por un ingenio imaginativo» y "The Scotsman" dijo que tiene «todas las señas de un clásico».

Llegada la publicación del quinto volumen, "Harry Potter y la Orden del Fénix", los libros comenzaron a recibir fuertes críticas de distintos expertos literarios. El crítico y catedrático de Yale, Harold Bloom cuestionó los méritos literarios de los libros al decir «la mente de Rowling está tan gobernada por "clichés" y metáforas muertas que no tiene otro estilo de escritura». En un artículo del "New York Times", A. S. Byatt denominó al universo de Rowling como un «mundo secundario compuesto de una colección de partes incongruentes derivadas de todo tipo de literatura infantil [...] escrito para personas cuya imaginación está confinada a dibujos animados de la televisión, las telenovelas, telerrealidad y la prensa del corazón». 

Por el contrario, la autora Fay Weldon admitió que la serie «no es lo que esperarían los poetas», mas «esto no es poesía, es prosa legible, vendible, útil y cotidiana». El crítico literario A.N. Wilson elogió la serie en "The Times": «No hay muchos autores con la habilidad "dickensiana" de JK capaz de hacernos dar vuelta las páginas, llorar -abiertamente, con lágrimas saltando- y unas pocas páginas después reír con chistes buenos [...] Hemos vivido en la década en la que se publicó la más divertida, espeluznante y conmovedora historia infantil jamás escrita»." 

Stephen King denominó a la serie como «una obra de la que solo una imaginación superior es capaz de hacer», y calificó al sentido del humor de Rowling como «admirable». Sin embargo, escribió que si bien la historia es «buena», él está «un poco cansado de encontrarse a Harry en casa con sus horribles tíos», la fórmula con la que comienzan todos los libros. También predijo que la serie «soportará la prueba del tiempo, y terminará en la estantería donde solo queda lo mejor; y Harry tomará su lugar con Alicia, Huck, Frodo y Dorothy». El autor Orson Scott Card escribió una crítica de "las reliquias de la muerte" en la que dice «JK Rowling ha creado algo que merece permanecer en el tiempo, volverse un clásico permanente de la literatura inglesa, y no solo una "ficción infantil"».

Los libros fueron objeto de numerosos procedimientos legales, los cuales varían desde quejas de grupos religiosos estadounidenses que proclaman que la magia en los libros promueve la brujería entre los niños, hasta conflictos sobre los derechos de autor o infracciones de marcas registradas.

La inmensa popularidad y el alto valor del mercado de los libros ha llevado a Rowling, sus editores y la productora de cine Warner Bros. a tomar medidas legales para proteger sus derechos, las cuales incluyen prohibir la venta de imitaciones, «perseguir» a dueños de páginas web sobre el uso del dominio "Harry Potter" y demandar a la autora Nancy Stouffer para contrarrestar sus acusaciones de plagio sobre su trabajo.

Por otro lado, algunos grupos criticaron a los libros por promover distintas agendas políticas, mientras que ciertos religiosos declararon que los libros promueven la brujería y por tanto no son aptos para niños. En 2003, Joseph Ratzinger, el Papa Benedicto XVI, declaró antes de asumir como Sumo Pontífice que los libros «seducen a los jóvenes lectores de manera subliminal y distorsionan la cristiandad en el alma antes de que ésta pueda desarrollarse». Por último, las declaraciones de Rowling que señalan a Dumbledore como homosexual han aumentado las controversias políticas que rodean la serie.

Este libro fue duramente rechazado por los cristianos ultraconservadores de Estados Unidos y prohibida en los Emiratos Árabes Unidos.

La serie ha sido traducida a 65 idiomas, ubicando a Rowling entre los autores más traducidos de la historia. La primera traducción se hizo al inglés estadounidense, dado que muchas palabras y conceptos usados por los personajes en las novelas, propios del inglés británico, podrían ser malinterpretados por los jóvenes lectores estadounidenses. Subsecuentemente, los libros fueron traducidos a idiomas tan diversos como el ucraniano, hindi, bengalí, galés, afrikáans y vietnamita. El primer volumen, "La piedra filosofal", fue traducido al latín e incluso al griego antiguo, haciendo de este el texto más extenso publicado en ese idioma desde las novelas de Heliodoro, en el Siglo III a. C. 

La enorme demanda de una traducción local decente hacen que se tome con sumo cuidado la tarea de traducción e interpretación. En algunos países como Italia, se publicó una segunda edición actualizada, teniendo en cuenta las sugerencias de los lectores. En otros países, como China o Portugal, la traducción está hecha por un grupo de intérpretes para reducir el tiempo entre la publicación inglesa y la local. La edición turca del segundo al séptimo libro fue llevada a cabo por Sevin Okyay, un popular crítico literario y comentarista cultural. Con la finalidad de mantener en secreto el argumento, las traducciones autorizadas solo podían empezar después de que los libros fueran publicados en inglés. Por lo tanto, se dio un retardo de varios meses hasta que las traducciones estuvieran disponibles. Esto derivó en que muchas copias de las ediciones en inglés se vendieran a fanáticos impacientes en muchos países de habla no inglesa. Tanta fue la impaciencia para leer el quinto libro, que su edición británica se convirtió en el primer libro de lengua inglesa en lograr el primer puesto en la lista francesa de "best sellers".

Todas las novelas de la heptalogía fueron publicadas en inglés como audiolibros. Existe una versión británica, narrada por Stephen Fry y una estadounidense, por Jim Dale. Por su parte, en español solo se editó el primer volumen, en formato CD-ROM.

En 1999, Rowling vendió los derechos cinematográficos de los cuatro primeros libros a la Warner Bros. por £1 000 000. La principal condición que puso Rowling fue que el reparto principal fuese estrictamente británico, aunque se permitió la contratación de actores irlandeses, como el fallecido Richard Harris como Dumbledore, además de actores y actrices franceses y de Europa del este para "Harry Potter y el cáliz de fuego", puesto que algunos personajes del libro son de ese origen. Tras considerar muchos directores de la talla de Steven Spielberg, Terry Gilliam, Jonathan Demme y Alan Parker, el 28 de marzo de 2000, Chris Columbus fue confirmado por Warner, quien apuntó su trabajo previo en películas infantiles como "Home Alone" y "Mrs. Doubtfire" como el principal argumento para esta decisión. Después de un , el rodaje comenzó en octubre de 2000 en los estudios Leavesden y en la propia Londres, mientras que la producción finalizó en julio de 2001. El 16 de noviembre de 2001 se estrenó mundialmente "La piedra filosofal". Solo tres días después de ese estreno, comenzó la producción de la segunda película, "Harry Potter y la cámara secreta", con Columbus repitiendo en el rol de director. Esta adaptación se estrenó el 15 de noviembre de 2002.

Columbus rechazó la oferta de dirigir "Harry Potter y el prisionero de Azkaban", película en la que solo participó como productor. Fue el director mexicano Alfonso Cuarón quien se hizo cargo de la dirección, el rodaje tuvo fecha en el año 2003. La película se estrenó el 4 de junio de 2004. Puesto que la producción de la cuarta película comenzaría antes del estreno de la tercera, Mike Newell fue elegido para dirigir "Harry Potter y el cáliz de fuego", que se estrenó el 18 de noviembre de 2005. Newell también rechazó la propuesta de dirigir la siguiente película, por lo que se designó en la dirección para "Harry Potter y la Orden del Fénix" al director de telefilmes británico David Yates. El estreno de esta película fue el 11 de julio de 2007. Yates también dirigió la sexta entrega, traducida por Warner Bros como "Harry Potter y el misterio del príncipe", que fue estrenada el 15 de julio de 2009. 
La última adaptación, "Harry Potter y las Reliquias de la Muerte", se dividió en dos partes. La "Parte 1" fue estrenada el 19 de noviembre de 2010 en 2D y en formato IMAX, y la "Parte 2" en 2D, 3D y formato IMAX el 15 de julio de 2011, ambas dirigidas también por David Yates.

Rowling ejerció cierta influencia en las películas, supervisando el proceso de filmación de la primera adaptación y fungiendo como productora de las últimas dos películas, al lado de David Heyman y David Barron. Los filmes fueron un enorme éxito de taquilla, figurando todas ellas en su momento entre las 20 películas que más recaudaron a nivel mundial de la historia. Por otro lado, las películas como conjunto componen la , sobrepasando a las de "James Bond", cuya serie consta de 23 títulos, o "Star Wars", de 7. Además de suponer un éxito financiero, las películas en general recibieron aclamación por parte de la crítica. En efecto, según el recopilador de reseñas Rotten Tomatoes, la última entrega fue el segundo título mejor criticado de 2011.

El 31 de mayo de 2007, Warner Bros., Universal Studios y Leavesden Studios anunciaron que se construiría un parque temático sobre Harry Potter en Islands of Adventure, titulado "The Wizarding World of Harry Potter", en Orlando, Estados Unidos. El parque cuenta con atracciones interactivas, además de tiendas y restaurantes. Los planes para llevar a cabo este parque se estaban desarrollando desde hacía año y medio antes, con contribuciones de J.K. Rowling y Stuart Craig. El parque abrió sus puertas en junio de 2010.

El 15 de julio de 2014, se inauguró un parque temático similar titulado de la misma manera, "The Wizarding World of Harry Potter", en los Universal Studios de Japón en Osaka, Japón. También, se encuentra bajo construcción "The Wizarding World of Harry Potter" en Universal Studios Hollywood, cerca de Los Ángeles, California, con una inauguración programada para 2016.

Hasta el momento, Electronic Arts ha lanzado ocho videojuegos basados en las tramas de las películas y las novelas. Además, EA produjo en 2003 un juego de simulación de Quidditch: "". LEGO también produjo dos videojuegos uno sobre las cuatro primeras entregas y otro sobre las tres últimas, además de una serie de muñecos y escenarios basados en las cinco películas estrenadas. Por otro lado, Wizards of the Coast creó un juego de cartas coleccionables similar a "" basado en el mundo de Harry Potter. Este mazo de cartas llegó a ser el segundo juguete más vendido de Estados Unidos. Por último, Harry Potter: Hogwarts Mystery es el nuevo videojuego de Harry Potter para dispositivos móviles. Puede descargarse gratuitamente en Android.




</doc>
<doc id="1444" url="https://es.wikipedia.org/wiki?curid=1444" title="Historia de América">
Historia de América

La Historia de América es la historia colectiva de los pueblos del continente americano, incluidas las Antillas y demás islas próximas. Los acontecimientos históricos notables ocurren en el continente con mucha antelación al uso de la escritura, especialmente a partir del surgimiento de la civilización Caral hacia el 2600 a. C. y de la cultura olmeca hacia el 1500 a. C. durante el Periodo Formativo hasta el presente.
"Cronología de la Prehistoria de América"
"La cronología superior "corresponde a las Migraciones""

"La cronología inferior: "desarrollo de la civilización en América"

La Historia de América según los arqueólogos Gordon Willey y Philip Phillips, se divide en los siguientes períodos: Paleoamericano, el Periodo Arcaico, el Periodo Formativo, el Periodo Clásico (comprende el esplendor de las civilizaciones americanas 292–900), el Periodo Posclásico (comprende lo que se denomina la "América precolombina" 900–1527), el encuentro cultural de América con Europa en lo que se denomina la "Conquista de América" (1492–1527), el dominio de Europa sobre el continente en lo que se denomina las colonias americanas de Europa (siglo XVI–siglo XIX), el periodo de independencia de las colonias (siglo XVIII a siglo XIX) y la consolidación de las nacientes repúblicas americanas entre el siglo XIX y la actualidad.
"Cronología de la Historia de América"
"La cronología superior "corresponde a las Migraciones""

"La cronología inferior: "desarrollo de civilización en América"
La Prehistoria de América es el periodo del tiempo que comprende el poblamiento del continente hasta la formación de las grandes civilizaciones americanas. Se trata de un tiempo de sumo interés e investigación dado que el continente americano fue la única porción de tierra en el planeta que tuvo un desarrollo humano aislado hasta su encuentro directo con las culturas de Europa, África y el resto del mundo. Ello no significa que no hubo de una u otra forma una interacción mínima o significativa con el resto, pero los pueblos americanos no participaron de los acontecimientos históricos y logros que unieron a los demás continentes hasta 1492.

La Prehistoria de América es objeto de permanente estudio dadas las muchas preguntas que permanecen sin respuestas contundentes, como las teorías del poblamiento y la historia y el desarrollo de muchos pueblos americanos aborígenes. La fascinación por la América prehistórica y precolombina estimulan no pocas veces la imaginación, los mitos y las suposiciones. Ciertos o no, ellos representan un reto para la ciencia en un continente aún por descubrir. En la Prehistoria americana, la Cultura Clovis (de hace 13.500 años aproximadamente), es la que más restos arqueológicos deja y la que permite darse una idea de la intensa actividad de los pueblos de cazadores y recolectores que poblaron en el continente.

Durante el periodo arcaico (8000 a. C. - 1500 a. C.), el hombre americano descubrió la Agricultura, a la par de otros pueblos en otros continentes. Ello tendría como consecuencia la sedentarización, la creación de sociedades más complejas y la construcción de ciudades. Caral-Supe situada en el actual Perú, corresponde a ese periodo con dataciones del 2627 a. C., es decir, casi a la par con las ciudades mesopotámicas, egipcias, indias y chinas. Ese era el preludio que marcaba el fin de la Prehistoria de América y que daría origen a la Cultura Olmeca hacia el 1500 a. C., la primera gran civilización del continente cuyo esplendor iría hasta el 900 cuando San Lorenzo, su principal centro ceremonial, fue saqueado. La Cultura Olmeca se sitúa entonces en el llamado Periodo Formativo de América (también llamado "Periodo Preclásico" o "Periodo Agricola") y se desarrolló en Mesoamérica. Tres fueron los centros principales de esta primera civilización: San Lorenzo (datado del 1500 a. C.), Tres Zapotes y La Venta (el más grande centro urbano que podía albergar hasta 18 mil habitantes). Teotihuacán, datada del 1500 a. C., sería en este periodo la ciudad más importante de América.
En América del Sur los grandes protagonistas serían los pueblos de la Cultura Chavín, que llegaron a dominar extensos territorios y a construir importantes centros urbanos en torno a santuarios dedicados al "dios Jaguar". Por su parte, en la actual Colombia florecían las llamadas Cultura San Agustín y Calima. Otras culturas reseñables son las de los Anasazi y sus similares (Arizona), así como los "constructores de Montículos" de Norteamérica. El desarrollo de estas culturas en el continente fue en general aisladas las unas de las otras, pero la complejidad de sus creaciones denota ya una gran madurez que prepararía el Periodo Clásico.

Con el Periodo Clásico se entra en el áuge de las civilizaciones americanas. El surgimiento de la Cultura Maya en 292 y de sus ciudades-estado, especialmente Tikal, Palenque y Copán, marcan el inicio histórico del Clásico, que se cierra con el saqueo de la ciudad olmeca de San Lorenzo y el abandono de los Mayas de la parte central de México y Centroamérica para ubicarse en la Península de Yucatán en 900. Mesoamérica posee entonces dos culturas (Olmecas y Mayas), se desarrolla el comercio, el urbanismo, la administración, la religión, la guerra, la astronomía, la matemática, la escritura y la política. Entre los grandes legados a la humanidad de este período quedan el Calendario maya, el más preciso jamás inventado y la Escritura maya.

El "Periodo Posclásico, Alto Clásico" o "Precolombino" comprende la formación de los pueblos en América tal como fueron encontrados por los europeos en 1492. Para muchos observadores, en realidad la distinción "clásico" - "posclásico" no reviste una gran distinción. Hacerla, implicaría decir que las culturas precolombinas del posclásico eran inferiores a las del clásico y no hay pruebas de ello.

Por otra parte, especialmente la actividad cultural en Mesoamérica. Los pueblos americanos desarrollaron culturas autónomas originales hasta el punto de producir dos revoluciones neolíticas separadas, en Mesoamérica y los Andes Sudamericanos que dieron origen a docenas de civilizaciones agrocerámicas, entre ellas se encuentran:

Las civilizaciones agroalfareras americanas desarrollaron sistemas originales de organización social basados fundamentalmente en el cultivo de maíz y complejas técnicas de gestión de los ecosistemas, así como la cría de algunos animales domésticos (muy pocos) como es el caso del pavo en América del Norte y el acure o la llama en la Cordillera de los Andes. Los cultivos más importantes en el caso de Mesoamérica fueron el maíz, las alubias (también llamadas caraotas, porotos, etc., en algunos países hispanoamericanos) y la auyama o calabaza. En Sudamérica, el papel predominante del maíz era complementado por el de los tubérculos (papa en las tierras altas de los Andes, batata en las de menor altitud) y raíces, como la yuca. Las civilizaciones andinas desarrollaron también una depurada tecnología textil de que permitía tejidos de hasta 500 hilos por pulgada estructurados en capas sucesivas. Otros cultivos desarrollados por las civilizaciones americanas fueron el algodón, el tomate, el chocolate, la vainilla, el pimiento, etc.

Las culturas agroalfareras de América del Norte también se organizaron en torno al maíz y a la gestión ecológica de las praderas. Los pueblos cazadores se organizaron en torno a la caza del bisonte (impropiamente llamados búfalos) o de la pesca y la caza de mamíferos marinos, en el caso de los esquimales e indígenas del extremo norte del continente. Elementos comunes de las culturas precolombinas que alcanzaron un alto grado de desarrollo fueron la edificación de templos y sitios religiosos monumentales, con avanzados sistemas antisísmicos, siendo claro ejemplo las zonas arqueológicas de Cuzco, Machu Pichu, Teotihuacan, Templo Mayor en la ciudad de México, Nazca, Palenque, Tulum y Tikal entre otros. La ciencia precolombina alcanzó sus puntos más altos con el descubrimiento del cero por la civilización maya, y los calendarios. Contaron con avanzados sistemas de escritura en Mesoamérica y un misterioso sistema de registros (quipos) en los Andes Sudamericanos, así como una refinada metalurgia. Prácticamente todas las culturas americanas contaban con complejos conocimientos y prácticas de gestión ambiental.

El Imperio incaico fue el de mayor extensión en la América precolombina. Surgió a fines del siglo XII; y llegó a abarcar desde el actual Ecuador y el sur de Colombia, pasando por los andes y el altiplano de Perú y Bolivia, hasta Chile y el norte de Argentina. Dichos territorios fueron cuna de diversas culturas preincaicas que fueron conquistadas y anexadas al territorio imperial. Para una mejor organización política el Imperio Inca también llamado "Tahuantinsuyo" (que proviene de la frase quechua "Tawantin Suyu" "las cuatro regiones -en su conjunto-"), estuvo conformado por cuatro suyukuna o regiones:


La capital del imperio era la ciudad del Cuzco, "el ombligo del mundo". Luego de una época de expansión y gran apogeo, el imperio entró en una crisis sucesoria y consecuentemente en una gran decadencia, que culminó con su desaparición gradual producto de la conquista española a principios del siglo XVI. El territorio imperial fue anexado a lo que sería el virreinato del Perú. Por datos arqueológicos y antropológicos se ha ido estudiando el verdadero proceso de la ocupación del Cuzco. El consenso apunta a que, debido al colapso del reino de Taypiqala se produjo la migración de su pueblo. Este grupo de cerca de 500 hombres se habría establecido paulatinamente en el valle del río Huatanay, proceso que culminaría con la fundación del Cuzco. Posteriormente, los reyes cusqueños fueron pactando alianzas y conquistando otros reinos. Hacia fines del siglo XV, gobernaban sobre las zonas altas y medias del valle del Vilcanota y vivían en constante fricción con los Estados colindantes.

Manco Cápac fundó el Imperio incaico, aproximadamente el año 1200 d. C. y fue su primer gobernante. Durante el gobierno de Pachacútec se produjo el mayor crecimiento del imperio. Inauguró el periodo imperial, porque los incas se convirtieron en emperadores al anexionar numerosos reinos. Pachacútec mejoró la organización del estado, dividiendo el imperio en cuatro regiones o "suyus". Por el norte, sometió a los "huancas" y "tarmas", hasta llegar a la zona de los "cajamarcas" y "cañaris" (Ecuador). Por el sur sometió a los "collas" y "lupacas", que ocupaban la meseta del altiplano. Organizó a los "chasquis" e instituó la obligatoriedad de los tributos. Se le considera el último gran emperador del incario. Huayna Cápac, considerado el último monarca, continuó la política de su padre, "Túpac Inca Yupanqui", en cuanto a la organización y fortalecimiento del estado. Para conservar los territorios conquistados tuvo que sofocar en forma sangrienta continuas sublevaciones. Derrotó a los "chachapoyas" y anexionó la región del golfo de Guayaquil, llegando hasta el río Ancasmayo (Colombia). Estando en Quito, enfermó gravemente y falleció en 1525. Con su muerte se inició la decadencia del imperio. Antes de morir, designó a su hijo "Ninan Cuyuch" como su sucesor. Pero el príncipe murió repentinamente y en su lugar fue coronado su hermano Huáscar (1525). Este debió enfrentar a su medio hermano Atahualpa, quien también se consideraba legítimo heredero del trono.

Muy pronto importantes regiones del imperio fueron sacudidas por sangrientas batallas entre tropas cusqueñas y quiteñas, que terminaron con la victoria final de los últimos. "Huáscar" fue tomado prisionero y muerto posteriormente por orden de "Atahualpa". Este último era hijo de Huayna Cápac con una princesa de Quito. Tras la muerte de su padre, se rebeló contra Huáscar, apoyado por la nobleza quiteña. Sus tropas, dirigidas por "Calcuchímac" y "Quizquiz", derrotaron al ejército cusqueño en la batalla de Cotabamba (Apurímac) y entraron triunfantes al Cuzco. Enterado de la victoria, "Atahualpa" marchó a Cajamarca para ser coronado inca. En el trayecto era aclamado por los pueblos del norte. Sin embargo, al llegar a Cajamarca, fue tomado prisionero por los españoles. Era el año 1532. Este hecho marcó el fin del "Imperio Incaico". En contra de lo pensado, "Atahualpa" (que gobernó "de facto" entre 1532 - 1533), no forma parte de la "capaccuna" al nunca ceñir la "mascapaicha". Por lo tanto es impropio llamarle "Sapa Inca", como algunas veces se le titula.

Los aztecas, nombre comúnmente usado para referirse a los mexicas, constituyeron un pueblo dominante en el área norte de Mesoamérica durante el periodo posclásico tardío (1320-1521). En 1325 fundaron su ciudad, Tenochtitlan, actual Ciudad de México. Ya sentados en su ciudad los mexicas estuvieron por varias décadas bajo el dominio del poderoso señorío de Azcapotzalco, al que sirvieron como soldados a sueldo. Hacia 1430, los mexicas habían asimilado la cultura de los pueblos avanzados del valle y se habían convertido en un eficiente poder militar. Atacaron y derrotaron entonces a Azcapotzalco y se transformaron en uno de los señoríos más fuertes de la región. Iniciaron así una hazaña guerrera, que en sólo 70 años les haría dueños del mayor imperio que había existido en Mesoamérica.

El imperio sería forjado principalmente por Tlacaélel, quien convenció a los mexicas de atacar al señor de Azcapotzalco en lugar de rendirse. Tlacaelel además reformó la historia y la religión mexica. Ordenó la quema de los libros mexicas y reescribió su historia. Elevó al Huitzilopochtli, semi-dios mexica, al nivel de los antiguos dioses nahuas, (Quetzalcóatl, Tláloc y Tezcatlipoca). Identificó a Huitzilopochtli con el sol y creó la necesidad de sacrificios humanos constantes, también creó las guerras floridas para poder tener una fuerza militar eficiente incluso en tiempos de paz. Les dio a los mexicas una conciencia histórica y la responsabilidad de mantener la existencia del universo a través de los sacrificios humanos, la mayoría de los sacrificados eran los esclavos que se capturaban durante las guerras. Esa visión místico-guerrera se contraponía a la antigua visión tolteca de Quetzalcóatl que tenían los demás pueblos nahuas.

En la poesía náhuatl se puede apreciar el conflicto entre esas dos visiones del mundo. Tlacaélel rehusó convertirse en tlatoani (rey), pero fue el poder detrás del trono a lo largo de tres reinados. Los mexicas formaron una alianza con los señoríos de Texcoco y Tlacopan creando así lo que se conoció como la Triple Alianza. Bajo el mando de notables jefes militares, como Moctezuma I lhuicamina y Ahuízotl, los mexicas conquistaron el centro de México, Veracruz, la costa de Guerrero, parte de Oaxaca y dominaron el territorio de Soconusco, en los límites con Guatemala. Sólo unos cuantos pueblos lograron resistir el empuje mexica: los purépechas (también conocidos como purhépechas), los tlaxcaltecas y algunos señoríos mixtecos.

Los vikingos fueron los primeros europeos en llegar a América, al que llamaron Vinland, estableciendo al menos un poblado en la isla de Terranova (Canadá), en L'Anse aux Meadows. Hay teorías sobre otros "descubrimientos" anteriores y posteriores al de la costa este (o de la oeste por los chinos), pero ninguno de estos ha sido probado con evidencia firme.

La llegada de los europeos causó la entrada a América de una serie de peligrosas enfermedades (viruela, tifus, fiebre amarilla, etc.) para las que los pueblos originarios no tenían defensas biológicas adecuadas.

El investigador estadounidense H. F. Dobyns ha calculado que un 95% de la población total de América murió en los primeros 130 años después de la llegada de Colón. Por su parte, Cook y Borak, de la Universidad de Berkeley, establecieron luego de décadas de investigación, que la población en México disminuyó de 25,2 millones en 1518 a 700 mil personas en 1623, menos del 3% de la población original. En 1492 España y Portugal juntas no superaban los 10 millones de personas.

No cabe duda alguna que el colapso demográfico de la población original de América fue la causa esencial de la derrota militar de muchas de las civilizaciones conquistadas por los europeos, como México y 

El historiador estadounidense Charles Mann dice que Cortés: 
Algo similar sucedió con el Imperio incaico, derrotado por las huestes de Francisco Pizarro en 1531. La primera epidemia de viruela fue en 1529 y mató entre otros al Emperador Huayna Cápac, padre de Atahualpa. Nuevas epidemias de viruela se declararon en 1533, 1535, 1558 y 1565, así como de tifus en 1546, gripe en 1558, difteria en 1614 y sarampión en 1618. Dobyns estimó que el 90% de la población del Imperio Inca murió en esas epidemias.

En 1492 Cristóbal Colón realizó el primer viaje documentado de Europa a América lo que condujo a la colonización extensa europea del continente.

Cada una de las potencias europeas que conquistaron y colonizaron el continente que recién habían descubierto, utilizaron diferentes mecanismos de dominación de los habitantes de América. En general los historiadores españoles sostienen que la colonización británica fue bárbara y genocida, mientras que los historiadores británicos sostienen que la colonización española explotó el trabajo indígena hasta su exterminio para reemplazarlo luego con esclavos secuestrados en África. Estas visiones son conocidas respectivamente como la leyenda rosa y la leyenda negra de la colonización de América por Europa.

El resultado general fue una enorme mortandad de indígenas que se ha llegado a estimar en el 95% (Dobyns,1983).

Para responder a la masiva mortandad de indoamericanos, a partir del siglo XVII los portugueses, anglo-sajones, franceses y holandeses secuestraron alrededor de 60 millones de africanos, de los cuales unos 12 millones llegaron vivos a América donde fueron reducidos a la esclavitud.

Se realizó un gran flujo de mercancías y herramientas entre ambos continentes, también intercambios culturales y costumbres. En uno y otro continente se introdujeron nuevas especies de alimentos, plantas y animales. De manera negativa también, se introdujeron nuevos tipos de enfermedades que particularmente diezmaron algunas comunidades indígenas.

Hay que señalar también que la conquista europea fue rechazada en la mayor parte del continente. Varios pueblos originarios resistieron exitosamente las invasiones europeas sobre vastos territorios, y mantuvieron el dominio sobre ellos hasta finales del siglo XIX: la Patagonia, la Araucanía, la llanura pampeana, el Mato Grosso, la Región Amazónica, la región del Darién, y las grandes praderas del oeste norteamericano, permanecieron bajo el dominio de naciones como los Mapuche, Het, Ranquel, Wichí, Qom, Amazónicas, Algonquina, Hopi, Comanche, etc.

También se crearon en América del Sur algunas repúblicas de afroamericanos que lograron huir de la esclavitud a la que habían sido reducidos por los portugueses, como el Quilombo de los Palmares o el Quilombo de Macaco o los simarrones en Colombia como el "Palenque".

El control directo de Europa comenzó a decaer el 4 de julio de 1776 con la declaración de Independencia de los Estados Unidos ante la corona británica, aunque siempre hubo insurrecciones e inconformidad por parte de los nativos, dicho acontecimiento sería un aliciente más para la emancipación de las restantes colonias del continente.

El proceso de independencia en América Latina empezó a principios del siglo XIX, si bien a mediados del siglo XVIII comenzaron las primeras revoluciones "Comuneras" contra el poder español. Entre ellas destacan los "Comuneros del Paraguay", 1735 y la Insurrección de los comuneros en el Virreinato de la Nueva Granada. El nombre de "comuneros" se debe al lema de José de Antequera y Castro: ""La voluntad del común es superior a la del propio rey"". Si bien los comuneros fueron derrotados originalmente (por ejemplo los del Paraguay en la "Batalla de Tavapy") poco a poco los diferentes países bajo dominio español obtuvieron su independencia.

El 25 de mayo de 1809 con la Revolución de Chuquisaca se inició la Guerra de Independencia Hispanoamericana que finalizaría en 1824 con la Batalla de Ayacucho. Al finalizar la misma, España había perdido prácticamente todas sus colonias en América, con excepción de las islas de Cuba y Puerto Rico.

Los territorios independizados darían origen luego de complejos procesos a 15 nuevas naciones independientes. Paraguay, Bolivia, Colombia, Costa Rica, Chile, Ecuador, El Salvador, Guatemala, Honduras, México, Nicaragua, Argentina, Perú, Uruguay y Venezuela. En 1844 y 1898 el proceso se completaría con la independencia de República Dominicana y Cuba, respectivamente.

En los primeros años después de la independencia se registran varios intentos de conformar grandes estados nacionales en Hispanoamérica. En 1819 se conformó un gran estado independiente sudamericano, denominado Gran Colombia, y que abarcó los territorios de los actuales Panamá, Colombia, Venezuela y Ecuador. La República se disolvió en 1830. En 1816 se conformaron las Provincias Unidas del Río de la Plata como gran estado sudamericano, incluyendo una gran parte del Alto Perú que luego integró Bolivia, y la Banda Oriental que luego se independizó como República Oriental del Uruguay. Entre 1837 se formó la Confederación Perú-Boliviana que se disolvió dos años después. En 1823 se formaron las Provincias Unidas del Centro de América que se disolvieron en 1839 para formar Costa Rica, Nicaragua, El Salvador, Honduras y Guatemala.

Un estado que logró la independencia de manera pacífica en este periodo fue el Brasil. A raíz de las Guerras Napoleónicas, la capital fue trasladada de Lisboa a Río de Janeiro implicándose con ello la asignación de la categoría de "reino" a Brasil, un reino dentro del Reino Unido de Portugal, Brasil y Algarve (1807 – 1821). Al disolverse pacíficamente tal reino surgió el "Imperio de Brasil". La independencia fue proclamada el 7 de septiembre de 1822 por el hijo del rey de Portugal, Pedro I, que estableció una monarquía constitucional, de economía basada en el trabajo esclavista. Durante el siglo la mano de obra esclava fue gradualmente sustituida por inmigrantes europeos, sobre todo alemanes e italianos. Otro país que logró la independencia de manera pacífica fue el Paraguay.

Los grandes protagonistas de este periodo en América fueron George Washington, Simón Bolívar, José de San Martín, Miguel Hidalgo y Costilla, Agustín de Iturbide y otros que son considerados los "padres" de las patrias americanas contemporáneas por sus luchas contra el dominio colonial. La mayor parte de los países caribeños y Canadá se independizaron durante el siglo XX.

En 1868 la flota de España atacó las costas de Chile y Perú en razón de un conflicto colonial. También restableció brevemente su dominación en Santo Domingo, entre 1861 y 1865, y mantuvo control sobre Puerto Rico y Cuba hasta 1898. En 1888-1889 Brasil abolió la esclavitud y luego la monarquía para establecerse como república.

Los diferendos limítrofes provocaron guerras constantes entre las nuevas repúblicas de América a lo largo de las décadas posteriores. Las más destacadas fueron la Guerra del Pacífico (1879-1884, Chile contra Bolivia-Perú) y la Guerra de la Triple Alianza (1865-1870, Argentina-Brasil-Uruguay contra Paraguay). Esta última terminó con una derrota total de Paraguay, que conllevó incluso un desastre demográfico: la población del país, aproximadamente 525.000 personas antes de la guerra, fue reducida a unos 221.000 en 1871, de los que solamente unos 28.000 eran hombres. La consolidación de las nuevas repúblicas no fue pacífica en cambio. No sólo las luchas limítrofes, sino guerras civiles sacudieron los cimientos de los nuevos estados. El expansionismo de países como Estados Unidos que cercenó el territorio de México; Brasil que impuso su soberanía en los territorios amazónicos aún a costa de correr las fronteras de sus vecinos, los conflictos territoriales entre Perú, Bolivia y Chile; la creación del Uruguay, la desintegración de la Gran Colombia que crearía tres nuevos estados: Colombia, Venezuela y Ecuador, son la prueba de una época convulsa causada por la desaparición de las colonias. Esta época de grandes cambios para el continente que trajo el siglo XIX entre independencia y consolidación terminaría todavía con la construcción del canal de Panamá, un canal interoceánico que partió el continente en dos, a costa de cercenar el territorio colombiano y crear un nuevo estado, Panamá (1903), bajo la creciente influencia de una nueva potencia: Estados Unidos.

El Siglo XX en América representó una época de grandes cambios e interacciones. El continente que había estado aislado del resto del planeta por siglos, era ahora uno de los más célebres, de los más visitados, de los más mencionados. Seguía siendo el "Nuevo Mundo" y el territorio de las oportunidades. Los Estados Unidos especialmente tendría un papel central en el desarrollo de la ciencia y la tecnología: el cine de Hollywood conquistaría el mundo, el jazz, Elvis Presley, el rey del "Rock'N Roll", los inventos, Broadway, los monopolios, los viajes espaciales y otros tantos factores. El cine mexicano, argentino y brasileño serían la contraparte, Carlos Gardel, el rey del tango, el boom de la literatura hispanoamericana con autores a la altura de los grandes clásicos universales como Gabriela Mistral, Pablo Neruda, Jorge Luis Borges, Gabriel García Márquez, Mario Vargas Llosa y otros, artistas de renombre mayor como Fernando Botero, Diego Rivera, Frida Kahlo, Reverón, Torres García, y centenares de nombres en la pintura, la escultura, las artes escénicas, el cine. El continente de las razas y de las culturas, harían que el siglo XX se hiciera de una u otra forma, americano.

El siglo XX se caracterizó por dos fenómenos contradictorios, por un lado Estados Unidos y Canadá establecieron libres democracias estables firmemente, mientras que el resto del continente sufrió en muchos de sus países diversos tipos de dictaduras y hombres temibles de todo tipo. Si bien debe señalarse que las elecciones en Estados Unidos entre finales del siglo XIX y XX eran altamente fraudulentas, y en México el sistema demográfico desembocó en un régimen autoritario sin alternancia democrática en la presidencia. Algunas fuentes explican que no es casual esta división, y que esta inestabilidad política es consecuencia de un proceso económico y político de injerencia estadounidense aliada a las clases dirigentes de cada país latinoamericano. A finales del siglo que la mayor parte del continente logró hacerse de gobernantes elegidos democráticamente, aunque no en todas las circunstancias se han establecido instituciones duraderas. El desarrollo económico de los Estados Unidos haría de ese país ya desde principios de siglo la meca de la inmigración, sobre todo desde Europa y Asia, junto a los países rioplatenses de Argentina y Uruguay.

En menor medida el resto de los países americanos no fueron ajenos a esa nueva oleada de pueblos que "colonizaban" a su forma el Nuevo Mundo. El desarrollo industrial del norte del continente que haría de Estados Unidos una potencia mundial, crearía una desface de frente a un sur empobrecido. La emigración de latinoamericanos hacia este país aumentaría con el paso de las décadas hasta convertirlos como la segunda ""minoría"" en su territorio. El canal de Panamá, inaugurado en 1914, con su ubicación en el punto más angosto entre el mar Caribe y el océano Pacífico, tuvo un efecto de amplias proyecciones al acortar la distancia y tiempos de comunicación marítima, produciendo adelantos económicos y comerciales que beneficiarían especialmente a Estados Unidos. El liberalismo económico se abriría cancha en Latinoamérica especialmente después de la crisis económica de 1929, pero en numerosos países serían las clases altas y dirigentes los beneficiarios ante una campesinado pobre y marginal. Los recursos naturales latinoamericanos estarían en manos de las multinacionales estadounidenses, pero también europeas. La Matanza de la Escuela Santa María de Iquique en 1907 en Chile y la "Masacre de las Bananeras", protagonizada por la United Fruit Company en 1928 en Colombia, son dos de los muchos ejemplos de cómo fueron las políticas del desarrollo económico en Latinoamérica. La guerra del Chaco (1932 - 1935) entre Bolivia y Paraguay por el control del río Paraguay, terminó con la victoria paraguaya y dejó a ambos como los más pobres de este subcontinente hacia finales del siglo XX.

El 9 de abril de 1948 fue asesinado el caudillo popular Jorge Eliécer Gaitán en Bogotá, lo que desbocaría a Colombia en un conflicto político por el resto del siglo. El 22 de noviembre de 1963 otros magnicidios atentarían contra las intenciones de cambiar una realidad política desfasada en el continente, la falta de derechos de los afro-americanos en Estados Unidos: es asesinado el presidente estadounidense John Fitzgerald Kennedy y el líder político Martin Luther King. Hacia finales del siglo, América contaba con varios de los países más pobres del mundo como Haití, Bolivia y El Salvador, entre otros o países en donde convivía el primer con el tercer mundo como Brasil, Argentina, Colombia y México, toda esta realidad en el mismo continente del país más rico del mundo. La idea de ver a ""Latinoamérica como el patio trasero de los Estados Unidos"" según el presidente estadounidense Ronald Reagan se convirtió en el resumen de lo que fue la historia del continente durante el siglo XX y el cumplimiento de la profecía del Libertador Simón Bolívar:

Durante la Primera y Segunda Guerra Mundial, el continente se mantuvo a salvo de la ola destructiva que arrasó Europa, Asia y África y se volvió una vez más receptor natural de cientos de refugiados. Con el fin del conflicto, el 30 de abril de 1948, se funda la Organización de los Estados Americanos. El 25 de abril de 1945 se celebró la primera conferencia en San Francisco de la Organización de las Naciones Unidas para garantizar la paz del mundo, la cual tendría como sede definitiva a la ciudad de Nueva York. La Organización de los Estados Americanos se fundaría el 30 de abril de 1948 en Bogotá como culmen de un largo ideal comenzado en 1890 con la "Primera Conferencia Internacional Americana", efectuada en la ciudad de Washington D.C., que se convertiría en 1910 en la "Unión Panamericana". La Carta de la OEA confirmó el respaldo a metas comunes y respeto a la soberanía de cada uno de los países del continente.

El comandante Neil Armstrong fue el primer ser humano que pisó la superficie de la luna el 20 de julio de 1969 al Sur de "Mar de la Tranquilidad", ("Mare Tranquilitatis"). Armstrong, nacido en Ohio en 1930, viajó con otros dos compañeros en la misión Apollo 11.

Pero la llamada guerra fría tendría consecuencias nefastas en suelo americano. En el primer lustro de los años 1960 el régimen implantado en Cuba por Fidel Castro y el Che Guevara, entre otros, orientó la política de su país hacia la Unión de Repúblicas Socialistas Soviéticas (URSS), de la cual pasó a ser un incondicional aliado en detrimento de los intereses geoestratégicos de Estados Unidos. La situación tuvo su punto más dramático en la "Crisis de los misiles de Cuba" que llevó a la humanidad a estar más cerca que nunca de una "tercera guerra mundial", pero que pudo evitarse gracias a la voluntad de Nikita Jrushchov y John F. Kennedy. Como consecuencia, estalló el conflicto armado en Colombia en 1964, hubo más series de violentos regímenes dictatoriales en diversos países de América Latina: Brasil (1964), Argentina (1968 y 1976), Chile (1973), Uruguay (1973), Bolivia (1980), además del estallido del conflicto armado en el Perú en 1980.

El 4 de abril de 1968 otro magnicidio sacudió al continente: era asesinado el Dr. Martin Luther King, Jr. en Memphis, uno de los grandes activistas del Movimiento por los Derechos Civiles en Estados Unidos para los afroamericanos, laureado con el . Organizó y llevó a cabo marchas por el derecho al voto, la no discriminación, y otros derechos civiles básicos. La mayoría de estos derechos fueron promulgados en las leyes de los Estados Unidos con la aprobación del Acta de los Derechos Civiles y el Acta de los derechos de votación. Es tal vez más famoso por su discurso "I Have a Dream (Yo tengo un sueño)" dado en frente del Monumento a Lincoln durante la Marcha en Washington por el trabajo y la libertad en 1963. King es recordado como uno de los mayores líderes y héroes de la historia de Estados Unidos, y en la moderna historia de la no violencia.

Después del fin de la guerra fría con la caída del Muro de Berlín, el continente vio el avance del Neoliberalismo, un conjunto de propuestas político-económicas con énfasis en la libre circulación de capitales, la privatización de empresas públicas y el desmantelamiento del "Estado Benefactor". Los padres de dichos procesos fueron el Banco Mundial, la Organización Mundial del Comercio y el Fondo Monetario Internacional (FMI). Dichas políticas que obedecen a una más compleja red del mercado internacional, si bien puso fin a gobiernos de facto como las dictaduras latinoamericanas, generó por ejemplo la crisis financiera argentina a partir de 1998 que crearía una alarma económica continental

Otra característica del fin de siglo, especialmente en la década de los 80, sería el fortalecimiento financiero de las mafias de la droga que tuvieron como epicentro Colombia, México y Estados Unidos, especialmente. La mafia, ligada a la droga, adquirió un enorme poder económico que llegó incluso a ser un verdadero poder paralelo al Estado. Uno de los nombres claves de la época, que llegó a proporciones de mito, fue el de Pablo Escobar, que, aparte de su enriquecimiento ilícito, y de acuerdo de la edición de 1985 de la Revista Forbes, llegó a ser el quinto "hombre más rico del mundo", con la capacidad de poner en jaque la política colombiana y crear un conflicto internacional que involucró a otros países americanos en la llamada "guerra contra el narcotráfico".

El 2001 marcó el inicio de un nuevo milenio y un nuevo siglo. Si el siglo XX no fue el siglo de la paz y la prosperidad continental, la manera en la que irrumpió la nueva data cronológica no auguró mejores tiempos. El 11 de septiembre de 2001 tendrían lugar los ataques suicidas que implicaron el secuestro de cuatro aviones de pasajeros, que fueron empleados como bombas aéreas dejando alrededor de 3.000 muertes. Las Torres Gemelas del Centro Mundial de Comercio (WTC por sus siglas en inglés), fueron destruidas y el Pentágono resultó dañado. La historia se precipitaría para el mundo entero: el presidente George W. Bush iniciaría las invasiones de Afganistán e Irak y Oriente y Occidente se verían enfrentados en un conflicto que despertó viejas disputas, abrió la perspectiva a nuevas ambiciones y creó nuevas situaciones históricas.

Las siguientes son los grandes bloques económicos en el continente, aunque existen numerosos tratados bilaterales:


Historia del siglo XX




</doc>
<doc id="1450" url="https://es.wikipedia.org/wiki?curid=1450" title="Historia de Oceanía">
Historia de Oceanía

El poblamiento humano de Oceanía se produjo en varias oleadas. Los primeros pobladores de Oceanía fueron Homo sapiens procedentes del sureste de Asia. Los primeros pobladores humanos de Oceanía procedían del sureste de Asia: de ellos descienden los actuales papúes y nativos australianos. El poblamiento de Australia y Nueva Guinea se remonta al 40 000 a.C.

Una segunda oleada mucho más reciente, es la que pobló el resto de islas del pacífico. Esta segunda oleada humana fue la de los pueblos austronesios (iniciada entre el 3000 a. C. y el 2000 a. C.), también de origen asiático, más concretamente procedentes de Taiwán. Los austronesios fueron grandes navegantes y fueron los primeros pobladores de muchas partes de Oceanía, en particular de Polinesia, Nueva Zelanda o Hawái'i, llegaron al menos tan lejos como la Isla de Pascua. El poblamiento de Micronesia y Polinesia, se prolongó durante tres milenios desde el 2000 a. C. hasta el I milenio d. C.. Nueva Zelanda por ejemplo fue poblada entre el s. IX y XIV por los maoríes.

En el 950 d. C. el Imperio Tu'i Tonga dominó la mayoría de las islas de Oceanía, en sus comienzos los reyes lograron deshacerse del dominio extranjero y consolidó el poder del imperio en lo que hoy es Tonga. Cerca al año 1200 comenzó su expansión que se dio hasta, aproximadamente el 1500. El imperio conquistó lo que hoy en día se conoce como Fiyi, partes de Samoa y otras islas de la polinesia como las Islas Cook y Niue. La gran habilidad para construir canoas y el buen sistema aplicado a las invasiones facilitó que Tu'i Tonga se estableciera en más islas aún. 

Cercano al año 1500 se desataron muchos problemas en la realeza del imperio que debilitó su figura en las colonias, que consiguieron mucha autonomía de la corona real y el poder central. En 1799 fue asesinado Tuku'aho, el rey que poseía el poder en ese momento, lo que desató una terrible guerra civil. Ya con la presencia europea la guerra civil terminó de devastar a los dos bandos, dejando al imperio diezmado en manos de la corona británica.

En el primer viaje de circunnavegación del globo, Fernando de Magallanes divisó las Islas Marianas y otras islas de Oceanía en 1521, antes de encontrar su muerte en las Filipinas en la isla de Mactan en una refriega con los naturales del país. Independientemente, el portugués Cristovão de Mendonça llegó a Botany Bay (Australia) en el año 1522, costas también visitadas tres años después por Gomes de Sequeira. Poco después otros marinos portugueses se unieron a la explotación de la región; en 1525 Diego de Rocha descubrió las islas Carolinas, visitadas al año siguiente también por Toribio Alonso de Salazar, y en 1526 Jorge de Meneses arribó a Nueva Guinea. Otros exploradores de la región en esta época fueron Luis Váez de Torres, Miguel López de Legazpi, García Jofre de Loaísa, Álvaro de Mendaña y Ruy López de Villalobos.

También los holandeses navegaron la región, y Abel Tasman recorrió el litoral de Australia en 1642, arribando a la isla que en su honor se llamó Tasmania y las islas, Tonga, Fiyi y Nueva Guinea Alemana. Entre tanto desde Acapulco (México) y Callao (Perú) partieron expediciones que hallaron numerosas islas del Pacífico.

Las rivalidades portuguesas, españolas y holandesas fueron reemplazadas por la de los ingleses y franceses en el siglo XVIII. Entre 1764 y 1770 exploraron la zona John Byron, Samuel Wallis, Philip Carteret y otros, quienes recorrieron Tahití, Samoa, Islas Salomón y Nuevas Hébridas. Por su parte, el inglés James Cook realizó tres viajes por islas de Pacífico entre 1768 y 1779, y llegó a las Islas de la Sociedad, Nueva Zelanda, Islas Marquesas, Nuevas Hébridas y Hawái. 

El 6 de abril de 1772, el día de Pascua, Jacobo Roggeveen, un navegante neerlandés avistó la Isla de Pascua, descubriéndola de manera oficial, aunque una expedición enviada desde Callao, el 10 de octubre de 1770, avistó la isla el 15 de noviembre. Se realizó una circunnavegación para poder cartografiar la isla. Los navegantes quedaron muy sorprendidos por las estatuas de gran tamaño, los Moái. En otras expediciones también los marines se sorprendieron de la gran altura de algunos nativos, que llegaban a medir 2,17 metros. Además, los hombres eran muchos más numerosos que las mujeres en aquella isla, la diferencia era muy notoria. Los nativos vivían en cuevas y estaban llenos de tatuajes, los nativos de la Isla de Pascua fueron una de las etnias que más sorprendió a los colonizadores europeos.

Los franceses exploraron las islas simultáneamente con los ingleses. Entre 1826 y 1840 lo hizo Jules Dumont D'Urville y luego Jean-François de La Pérouse entre 1785 y 1787. Todos estos viajes determinaron el reparto de Oceanía entre las potencias colonizadoras: Reino Unido, Holanda, Francia, España, Portugal, Estados Unidos y Alemania en menor medida.

A finales del siglo XIX y comienzos del XX comenzaron los deseos de independencia en las colonias, Australia y Nueva Zelanda, en 1901 y en 1907 abrieron el camino a los demás países hacia la independencia. Los países más débiles y pobres tardaron mucho en declararse independientes, en 1962, Samoa declaró la independencia de Nueva Zelanda, que la había ocupado años atrás, luego Nauru en 1968, Fiyi y Tonga en 1970, Islas Salomón y Tuvalu en 1978, los Estados Federados de Micronesia y Kiribati en 1979 (aunque reconocida en 1990 para Micronesia), Vanuatu en 1980, Islas Marshall en 1990 y Palaos en 1994 los siguieron en el proceso de libertad. Formaron el Foro de las Islas del Pacífico y aún hoy intentan ayudar a países como Guam, Nueva Caledonia y Polinesia Francesa que todavía están bajo el mandato de potencias.



</doc>
<doc id="1452" url="https://es.wikipedia.org/wiki?curid=1452" title="Historia de África">
Historia de África

La historia de África se refiere al conjunto de sucesos relativos al poblamiento humano del continente africano, desde los orígenes de los seres humanos hasta la actualidad.

La prehistoria de África comienza con el surgimiento de los primeros homínidos hace unos cinco millones de años, por lo que el período prehistórico en África incluye hechos mucho más antiguos que la historia de los otros continentes poblados por seres humanos mucho más tardíamente.

El período propiamente histórico de la Edad Antigua en África incluye la aparición de la civilización egipcia, el posterior desarrollo de las sociedades fuera del valle del Nilo y la interacción entre ellas y las civilizaciones fuera de África. A fines del siglo VII el norte y este de África fueron fuertemente influenciados por la expansión del islam, propiciando la aparición de nuevas culturas, tales como los pueblos suajili. Esto también incrementó el tráfico de esclavos (previamente existente) y que culminaría formalmente en el siglo XIX. La historia africana precolonial se enfoca en la época que transcurre entre comienzos del siglo XVI, caracterizada por el traslado de grandes cantidades de pobladores africanos en calidad de esclavos al Nuevo Mundo, hasta el inicio de la disputa europea por África. El periodo colonial africano transcurrió desde finales de los años 1800 hasta el advenimiento de los movimientos independentistas en 1951 cuando Libia se convirtió en la primera colonia africana en ganar su independencia. La historia africana moderna ha estado plagada de revoluciones y guerras, contando también, no obstante, con el crecimiento de las economías de algunas naciones africanas a lo largo del continente.

Los viejos prejuicios contra los africanos de raza negra han hecho que hasta hace poco la historia africana fuera narrada o representada de forma marcadamente eurocéntrica o racista. La historia africana ha sido un reto para los investigadores dada la escasez de fuentes escritas en grandes partes del África subsahariana, y también debido a las opiniones contrastantes sobre lo que es y no es africano. Algunas técnicas de estudio como el registro de la historia oral, la arqueología, la paleontología lingüística y la genética —para rastrear el movimiento de los pueblos— han sido cruciales a la hora de escribir la historia de varias regiones africanas que en el pasado había sido un misterio.

Según se dice en las últimas exploraciones paleontológicas y arqueológicas, los homínidos ya existían en África hace por lo menos 5 millones de años. La anatomía de su cráneo era similar a la de sus parientes cercanos, los grandes simios africanos, pero habían adoptado una forma bípeda de locomoción, la cual les otorgaba una ventaja crucial, pues les permitía vivir tanto en áreas boscosas como en la sabana en una era en la que África se estaba volviendo árida, con las sabanas superponiéndose a los bosques y selvas. 

Hace unos 3 millones de años varias especies de homínidos del género "Australopithecus" habían surgido a lo largo del sur, este y centro de África. El siguiente gran paso evolutivo ocurrió hace aproximadamente 2 millones de años con la llegada del "Homo habilis", la cual se cree que fue la primera especie de homínido capaz de fabricar herramientas. Esto le permitió a "H. habilis" comenzar a comer carne. En la cacería, "H. habilis" no era capaz de competir con grandes depredadores, y seguía siendo más presa que cazador, aunque probablemente podía robar huevos de nidos y pudo haber sido capaz de capturar pequeños animales.

Hace 1,8 millones de años, "Homo erectus" apareció por primera vez en África, aunque de igual forma lo hizo casi simultáneamente en el Cáucaso (Europa Oriental). Algunos de los primeros representantes de esta especie seguían teniendo cerebros bastante pequeños y usaban primitivas herramientas de roca, de forma muy similar a "H. habilis". Su cerebro más adelante creció y "H. erectus" terminó desarrollando una tecnología de herramientas más compleja, de tipo achelense. Posiblemente fueron los primeros grandes cazadores. Además, "Homo erectus" dominó el arte de producir fuego, y fue el primer homínido en salir de África, expandiéndose por todo el Viejo Mundo. También se ha sugerido que "Homo georgicus", un descendiente de "Homo habilis", pudo ser el primero homínido y el más primitivo en vivir fuera de África. No obstante, muchos científicos consideran al "Homo georgicus" como un miembro anterior y más primitivo de la especie "Homo erectus".

El registro de fósiles muestra que "Homo sapiens" pudo haber vivido en el sur y este de África hace al menos 100.000 y posiblemente 150.000 años. Hace unos 40.000 años comenzó la colonización de nuestro planeta por los seres humanos modernos con su expansión hacia fuera de África. Su migración es indicada por evidencias lingüísticas, culturales y genéticas.

Al final de la Edad de Hielo (alrededor del 10.500 a. C.), el Sahara se había convertido de nuevo en un fértil valle, y su población africana regresó del interior del continente y de las montañas costeras en el África subsahariana. Sin embargo, el clima cada vez más seco y cálido hizo que para el año 5000 a. C. la región del Sahara se fuera volviendo cada vez más árida. La población se desplazó fuera de la zona dirigiéndose hacia el valle del Nilo, donde crearon asentamientos permanentes o semipermanentes. Una recesión climática mayor ocurrió, disminuyendo las fuertes y persistentes lluvias en África central y oriental; desde entonces las condiciones secas han prevalecido en el este de África.

El fenómeno internacional conocido como la cultura del vaso campaniforme comenzó a afectar a África noroccidental. Llamada así por las vasijas de cerámica de forma característica encontradas en tumbas, la cultura del vaso campaniforme está asociada con el surgimiento de una mentalidad guerrera. El arte rupestre de este periodo en el norte de África representa animales pero también pone un nuevo énfasis en la figura humana, equipada con armas y adornos. La gente procedente de la región de los Grandes Lagos de África se asentó a lo largo de la costa oriental del Mar Mediterráneo para convertirse en los proto-canaanitas, quienes dominaron las tierras bajas entre el río Jordán, el Mediterráneo y el Desierto de Sinaí.

Grabados en roca del Neolítico, conocidos como petroglifos, y los megalitos en el desierto del Sahara en Libia dan fe de la prematura cultura cazadora-recolectora establecida en las secas praderas de África del Norte durante la Glaciación. La región donde actualmente se encuentra el Sahara fue originalmente un buen sitio para la agricultura (cerca del año 4000 a. C.). No obstante, después de la desertificación del Sahara, el establecimiento en el norte de África se concentró en el valle del Nilo, donde los nomos de Egipto sentaron las bases para la cultura del Antiguo Egipto. Hallazgos arqueológicos muestran que las tribus primitivas vivieron a lo largo del Nilo mucho antes de que la historia dinástica de los faraones comenzara. Para el año 6000 a. C. había aparecido la agricultura organizada.

Las evidencias más antiguas de historia escrita en África provienen del Antiguo Egipto, y el calendario egipcio sigue siendo usado como el patrón para datar a las culturas de la Edad del Bronce y la Edad de Hierro en la región.

Alrededor del año 3100 a. C. Egipto fue unificado bajo el primer faraón conocido, Narmer, quien inauguró la primera de las 31 dinastías en las que se divide la historia del Antiguo Egipto, las cuales se agrupan en tres fases: Imperio Antiguo, Imperio Medio e Imperio Nuevo. Las Pirámides de Guiza (cerca de El Cairo), construidas durante la cuarta dinastía, dan fe del poder de la religión y el gobierno faraónicos. La Gran Pirámide, que es la tumba del faraón Keops (también conocido como Jufu), es la única de las Siete Maravillas del Mundo que aún se mantiene en pie. El Antiguo Egipto alcanzó su máximo poder, riqueza y extensión territorial en el periodo del Nuevo Imperio (1567-1085 a. C.).

La importancia del Antiguo Egipto en el desarrollo del resto de África se ha debatido. Los antiguos académicos de occidente generalmente veían a Egipto como una civilización mediterránea con poco impacto sobre el resto de África. Los estudios recientes, no obstante, han comenzado a desacreditar esta noción. Algunos han argumentado que varios egipcios antiguos, como los badarienses, probablemente migraron hacia el norte desde Nubia, mientras que otros hablan de un movimiento de pueblos de gran envergadura a lo largo y ancho del Sahara antes del comienzo de la desertificación. Sea cual sea el origen de cualquier pueblo o civilización, parece razonablemente seguro que las comunidades predinásticas del valle del Nilo eran esencialmente indígenas en su cultura, recibiendo poca influencia por parte de fuentes externas del continente durante varios siglos precediendo directamente al comienzo de los tiempos históricos.

Justo antes de la desertificación del Sahara, las comunidades que se desarrollaron al sur de Egipto, en lo que hoy en día es Sudán, fueron plenos partícipes en la Revolución Neolítica y tuvieron un estilo de vida entre sedentario y seminómada, pudiendo domesticar plantas y animales. Megalitos encontrados en Nabta Playa son ejemplos de lo que probablemente fueron los primeros instrumentos arqueoastronómicos del mundo, unos 1000 años más antiguos que Stonehenge. Esta complejidad, como fue observada en Playa Natba y expresada por diferentes niveles de autoridad dentro la sociedad del lugar, posiblemente sentó las bases para la estructura tanto de la sociedad neolítica en Nabta Playa como del Imperio Antiguo de Egipto. Los pobladores pertenecientes al llamado "Grupo A", quienes habitaron el actual norte de Sudán y fueron contemporáneos del Naqada predinástico en el Alto Egipto, fueron responsables de lo que puede haber sido uno de los reinos más antiguos conocidos en el valle del Nilo, al que los egipcios llaman "Ta-seti" (Tierra del arco). Su desaparición con el surgimiento del Egipto dinástico más tarde permitió el surgimiento de reinos como Kush, Kerma y Meroe, los cuales en conjunto comprendían lo que en ocasiones es llamado Nubia. El último de ellos vería su devastador golpe final dado por el líder de un reino creciente en Etiopía, Ezana de Aksum, llevando efectivamente a su fin a las civilizaciones nubianas clásicas.

Separadas por el "mar de arena" —el Sahara—, el África septentrional y el África subsahariana han estado conectadas por las fluctuantes rutas comerciales transaharianas. Las historias fenicia, griega y romana en el norte de África pueden ser seguidas a través de textos acerca del Imperio romano y de sus provincias en el Magreb, tales como Mauritania, África, Tripolitania, Cirenaica, Egipto, etc.

Las regiones alrededor del Mediterráneo fueron colonizadas y pobladas por los fenicios antes del año 1000 a. C. Cartago, fundada cerca del año 814 a. C., creció rápidamente hasta convertirse en una ciudad sin rivales en el Mediterráneo. Los fenicios sometieron a las tribus bereberes, las cuales constituían la mayor parte de la población local, convirtiéndose en los dominadores de toda la región habitable en África del Norte, y hallando en el comercio una fuente de inmensa prosperidad.

Para el primer milenio a. C., el trabajo del hierro había sido introducido en el norte de África y rápidamente se comenzó a expandir a través del Sahara hacia las regiones septentrionales del África subsahariana, y para el año 500 a. C., la metalurgia empezó a volverse común en África occidental, posiblemente después de ser introducida por los cartagineses. El trabajo del hierro fue establecido plenamente alrededor de 500 a. C. en áreas de África oriental y occidental, a pesar de que en otras regiones no se comenzó a realizar esta actividad hasta los primeros siglos de nuestra era. Algunos objetos de cobre originarios de Egipto, el norte de África, Nubia y Etiopía se han hallado en el oeste de África, datando de alrededor del año 500 a. C., sugiriendo que las redes comerciales ya habían sido establecidas en aquella época.

Los griegos fundaron la ciudad de Cirene en la Antigua Libia alrededor del año 631 a. C. Cirenaica se convirtió en una floreciente colonia, aunque al estar completamente rodeada por desiertos tuvo poca o nula influencia sobre el interior de África. Los griegos, no obstante, ejercían una fuerte influencia sobre Egipto. La ciudad de Alejandría fue fundada por Alejandro Magno en 332 a. C., y bajo el mando de la dinastía helenística de los ptolemaicos se hicieron intentos por penetrar hacia el sur, y de esta forma se obtuvo cierto conocimiento de Etiopía.

Entre los años 500 a. C. y 500 d. C. aproximadamente, la civilización de los garamantes (posiblemente los ancestros de los tuareg) existió en lo que hoy en día es el desierto libio.

Las tres potencias —Cirenaica, Egipto y Cartago— terminarían siendo desplazadas por los romanos. Después de siglos de rivalidad con Roma, Cartago finalmente caería en 146 a. C. Dentro de poco más de un siglo Egipto y Cirene se incorporaron al Imperio romano. Bajo el dominio de Roma, las porciones pobladas de la región fueron muy prósperas. A pesar de que Fezzan fue ocupado por ellos, los romanos hallaron en el resto del Sahara una barrera impenetrable. Nubia y Etiopía fueron alcanzadas, pero una expedición enviada por Nerón para descubrir el nacimiento del Nilo fracasó. La mayor extensión de conocimiento geográfico mediterráneo del continente africano se muestra en los escritos de Ptolomeo (siglo II), quien conocía o intuía la existencia de las grandes reservas acuíferas del Nilo, de puestos comerciales a lo largo de las costas del Océano Índico en lugares tan al sur como Rhapta —en la actual Tanzania—, y había oído hablar del río Níger.

La interacción entre Asia, Europa y África del Norte durante este periodo fue significativa. Algunos efectos importantes incluyen la difusión de la cultura clásica alrededor de las costas del Mediterráneo; la continua lucha entre Roma y las tribus bereberes; la introducción del cristianismo en toda la región, y los efectos culturales de las iglesias en Túnez, Egipto y Etiopía. La era clásica llegó a su fin con la invasión y conquista de las provincias romanas en África por parte de los vándalos en el siglo V. El poder en la región regresaría al siglo siguiente al Imperio bizantino.

Los árabes musulmanes conquistaron el norte de África desde el Mar Rojo hasta el Océano Atlántico y continuaron hacia España, comenzando con la invasión de Egipto en el siglo VII. A lo largo del norte de África el cristianismo prácticamente desapareció, excepto en Egipto donde la Iglesia Copta permaneció sólida, en parte debido a la influencia de Etiopía. Algunos argumentan que cuando los árabes hubieron convertido Egipto intentaron acabar con los coptos, pero Etiopía —donde también se practicaba esta religión— le advirtió a los musulmanes que si intentaban acabar con los coptos, reducirían el flujo del agua del Nilo que corría hacia Egipto. Esto se debía a que el Lago Tana era la fuente del Nilo Azul, mismo que fluye hacia la corriente principal del Nilo. Algunos creen que esta es una de las razones por las que las minorías coptas aún existen hoy en día.

Alrededor del año 3000 a. C. la agricultura surgió independientemente en Etiopía, con cultivos como el café, teff, mijo dedo, sorgo, cebada y ensete. Los burros también fueron domesticados independientemente en la región de Etiopía y Somalia, pero la mayoría de los animales domesticados llegaron ahí desde las regiones del Sahel y el Nilo. Algunos cultivos también fueron adoptados de otras regiones en esta época, entre ellos se pueden mencionar el mijo perla, caupí, algodón, sandía y porongo, mismos que comenzaron a ser cultivados tanto en África occidental como en la región de Sahel mientras que el mijo dedo, guisante, lenteja y lino se asentaron en Etiopía.

Etiopía tenía una cultura antigua diferente con una historia intermitente de contacto con Eurasia después de la diáspora de homínidos hacia el exterior de África. Conservaba un lenguaje, cultura y sistema de cultivo únicos. El sistema de cultivo estaba adaptado a las zonas montañosas del norte y no se aplicaba a ningún cultivo de otras regiones. El miembro más famoso de este sistema de cultivo era el café, pero una de las plantas más útiles era el sorgo, un cereal de tierras áridas; el teff era endémico de la región.

Etiopía tuvo un gobierno centralizado por muchos milenios y el Reino de Aksum, el cual se desarrolló allí, había creado un poderoso imperio comerciante —con rutas comerciales que llegaban a lugares tan lejanos como la India—.

Históricamente, los swahili podían ser encontrados en lugares tan septentrionales como Mogadiscio en Somalia, y tan meridionales como el río Ruvuma en Mozambique. Aunque alguna vez se creyó que eran los descendientes de los colonos persas, los antiguos swahili ahora son reconocidos por la mayor parte de los historiadores, lingüistas históricos y arqueólogos como un pueblo bantú que tuvo importante interacción con mercantes musulmanes desde fines del siglo VII y comienzos del siglo VIII de nuestra era.

El inicio de la agricultura Sahel occidental se sitúa hacia el 5000 a. C. Aunque en el área tropical de África occidental la fecha del inicio de la agricultura se sitúa hacia el año 3000 a. C., donde se empezaron a cultivar de manera independiente palmas aceiteras. También se domestican ñames africanos aunque la ganadería se propaga allí desde el Sahel y la región del Nilo. También fueron adoptados cultivos de otras regiones en esta época, tales como el mijo perla, caupí, maní, algodón, sandía y porongo, comenzando a ser cultivados tanto en África occidental como en el Sahel.

Alrededor del año 1000 a. C., los emigrantes bantúes habían llegado a la región de los Grandes Lagos de África oriental. A mediados de ese milenio, los bantúes también se habían asentado en regiones donde actualmente se encuentran países como Angola y la República Democrática del Congo. Uno de los principales eventos ocurridos en África central durante este periodo fue el establecimiento del Imperio Kanem-Bornu en lo que hoy en día es Chad. El Imperio Kanem florecería en los siglos posteriores poniendo las bases para el surgimiento de futuros grandes estados en la región del Sahel.

La historia del sur de África sigue siendo en gran parte un misterio, debido a su aislamiento de otras culturas del continente. En el año 500 a. C. aquel aislamiento llegó a su fin con el asentamiento de emigrantes bantúes en la actual Zambia. Al sureste, los khoisan, también conocidos como bosquimanos, iniciaron la domesticación del ganado y cambiaron su estilo de vida cazador-recolector que había sido el dominante en la región desde el inicio de los tiempos. Para el año 300 a. C., los bantúes habían llegado al actual territorio de Sudáfrica, sirviendo de base para la aparición de estados centralizados.

Desde antes del I milenio a. C. se había iniciado en África central, una importante expansión bantú, probablemente asociada a la expansión de ciertos cultivos, que alteró profundamente la distribución genética y lingüística del África negra. Dándole una apariencia similar a la actual, donde existe un océano de pueblos que hablan lenguas nigero-congoleñas quedando poblaciones marginales que o bien hablan lenguas no emparentadas con el bantú (khoisano, sandawe, hadza) o tienen marcadores genéticos bastante diferentes de los bantúes comunes (e.g. pigmeos).

La expansión de los bantúes se prolongaría durante los primeros siglos de nuestra era hasta incluso después de la llegada de los exploradores europeos culminando en la formación del reino zulú en África Meridional

En el siglo VII hubo una considerable inmigración árabe, resultando en una gran absorción de la cultura bereber. Incluso antes de esto los bereberes en general habían adoptado la lengua y religión de sus conquistadores. La influencia árabe y la religión islámica se adhirieron indeleblemente al norte de África. Juntas se propagaron hacia el sur, a través del Sahara. También se establecieron firmemente a lo largo de la costa oriental, donde los árabes, los persas y los indios establecieron florecientes colonias, tales como Mombasa, Malindi y Sofala, ejerciendo una influencia análoga a aquella desempeñado en siglos previos por los cartagineses en la costa norte. Hasta el siglo XIV, Europa y los árabes en África del Norte ignoraban la existencia de estas ciudades y estados orientales.

Los primeros inmigrantes árabes habían reconocido la autoridad de los califas de Bagdad, y la dinastía Aglabí —fundada por Aglab, uno de los generales de Harún al-Rashid, a fines del siglo VIII— reinó como vasalla del califato. No obstante, a comienzos del siglo X la dinastía Fatimí se estableció en Egipto donde El Cairo había sido fundado en el año 968, y desde ahí dominó hasta regiones tan lejanas como la costa del Atlántico. Más tarde surgirían otras dinastías como la Almorávide y la Almohade. Eventualmente los turcos, quienes habían conquistado Constantinopla en 1453 y habían tomado Egipto en 1517, establecieron las regencias de Argelia, Túnez y Trípoli (entre 1519 y 1551), permaneciendo Marruecos como un estado bereber arabizado independiente bajo el dominio de la dinastía Sharifan, la cual surgió a fines del siglo XIII.

Bajo el dominio de las dinastías previas, la cultura árabe había alcanzado un alto grado de excelencia, mientras que el proselitismo de los seguidores del islam condujeron a una considerable extensión de esta religión en el continente. Esto se llevó a cabo más fácilmente por el uso del camello (introducido originalmente en África por los conquistadores persas de Egipto), el cual permitió que los árabes pudieran atravesar el desierto. De esta forma las regiones de Senegambia y el centro de Níger se convirtieron en zonas clave para el comercio transahariano y el intercambio de ideas.

El islam también se difundió a través del interior de África occidental, como la religión de los mansas del Imperio de Malí (1235-1400) y muchos gobernantes del Imperio Songhay (1460-1591). Después del legendario hajj de 1324 de Mansa Musa, Timbuctú se volvió célebre como centro de enseñanza islámica teniendo la primera universidad de África subsahariana. La ciudad había sido visitada en 1352 por el gran viajero árabe Ibn Battuta, cuya travesía a Mombasa y Quiloa (Kilwa) proporcionó los primeros conocimientos acertados de aquellas florecientes ciudades musulmanes de los swahili en las costas orientales africanas.

El avance árabe hacia el sur fue detenido por el ancho cinturón de densa selva, desplegándose casi a todo el ancho del continente aproximadamente al sur de la latitud 10° N, y mismo que bloqueó su avance tal como el Sahara lo había hecho con sus predecesores. La selva evitó que supieran de la existencia de la costa de Guinea y del resto de África que se encontraba más allá. Una de las últimas regiones en caer bajo el control de los árabes fue Nubia, la cual había sido dominada por cristianos hasta el siglo XIV.

Por un tiempo las conquistas musulmanes en el sur de Europa prácticamente convirtieron al Mediterráneo en un lago musulmán, pero la expulsión en el siglo XI de los sarracenos de Sicilia y el sur de Italia por parte de los normandos fue seguida por descendientes de los conquistadores de Túnez y Trípoli. Un poco después un fuerte comercio con las costas africanas, y especialmente con Egipto, se desarrolló con Venecia, Pisa, Génova y otras ciudades del norte de Italia. Para fines del siglo XV España había expulsado completamente a los musulmanes, pero aún en la época en la que los moros seguían en Granada, Portugal había sido lo suficientemente fuerte para llevar la guerra hacia África. En 1415 un ejército portugués capturó la ciudadela de Ceuta en la costa mora. De ahí en adelante Portugal interfirió repetidamente en los asuntos de Marruecos, mientras que España adquirió muchos puertos en Argelia y Túnez.

Portugal, no obstante, sufrió una aplastante derrota en 1578 en Alcazarquivir, siendo comandados los moros por Abu Marwan Abd al-Malik I Saadi de la entonces recién establecida Dinastía Saadi. Por ese entonces los españoles habían perdido casi todas sus posesiones africanas. Los Estados berberiscos, primariamente a partir del ejemplo de los moros expulsados de España, degeneraron en meras comunidades de piratas, y bajo la influencia turca la civilización y el comercio decayeron. La historia de estos estados desde inicios del siglo XVI hasta la tercera década del siglo XIX se compone en gran parte de hazañas piratas por una parte y de inútiles represalias por la otra.

El comercio de oro y otros materias primas, propició la formación de aristocracias en la región del Sahel, en que un soberano centralizaba el comercio con la costa norte de África. Entre estos imperios estuvieron el Imperio de Ghana, el Imperio de Malí, el Imperio Songhay, el Imperio Kanem-Bornu o el Imperio Wadai.

En la región de los grandes lagos a partir del siglo XV surgieron reinos bien organizados y centralizados como Bunyoro, Budanda, Ruanda y Burundi. El surgimiento de estos reinos debió mucho al inicio del uso del hierro en la región y a nuevos cultivos como la banana. Ambas innovaciones permitieron una mejora de los rendimientos agrícolas que conllevó un aumento importante de la densidad de población.

Durante el siglo XV Enrique el Navegante, hijo del Rey Juan I de Portugal, planeó adquirir territorio africano para Portugal. Bajo su inspiración y dirección algunos navegantes portugueses emprendieron una serie de viajes de exploración que resultaron en la circunnavegación de África y el establecimiento de la soberanía portuguesa sobre una gran cantidad de zonas costeras.

Las naves portuguesas rodearon al Cabo Bojador en 1434, Cabo Verde en 1445 y para 1480 la totalidad de la costa de Guinea era conocida por los portugueses. En 1482, Diogo Cão llegó a la desembocadura del Congo, el Cabo de Buena Esperanza fue rodeado por Bartolomé Díaz en 1488, y en 1498 Vasco da Gama, después de haber rodeado aquel cabo, exploró la costa oriental, desembarcando en Sofala y Malindi, y de ahí fue hacia la India. Portugal declaró su soberanía en todo punto en que sus navegantes desembarcaran, pero esta no fue ejercida en el extremo sur del continente.

La costa de Guinea, siendo la más cercana a Europa, fue la primera en ser explotada. Numerosos fuertes europeos y establecimientos comerciales fueron fundados, siendo el primero de ellos São Jorge da Mina (Elmina), establecido en 1482. Las principales mercancías comerciadas fueron esclavos, oro, marfil y especias. El descubrimiento europeo de América (1492) fue seguido por un gran desarrollo del tráfico de esclavos, el cual, antes de la era portuguesa, había sido un tráfico por tierra confinado casi exclusivamente al África musulmana. La naturaleza lucrativa de este tráfico y las grandes cantidades de oro aluvial obtenido por los portugueses atrajeron a otras naciones a la costa de Guinea. Los navegantes ingleses llegaron en 1553, y fueron seguidos por los españoles, holandeses, franceses y daneses, entre otros. La supremacía colonial a lo largo de la costa pasó en el siglo XVII de Portugal a los Países Bajos y de los holandeses en los siglos XVIII y XIX a Francia y el Reino Unido. Toda la costa de Senegal a Lagos fue dotada de fuertes y "fábricas" de las potencias europeas, y este panorama internacional persistió hasta el siglo XX aunque todas las tierras interiores del oeste de África se habían vuelto territorio francés o británico.

Al sur de la desembocadura del Congo en la región de Damaraland (en lo que hoy en día es Namibia), los portugueses, de 1491 en adelante, ganaron influencia sobre los nativos, y a comienzos del siglo XVI a través de sus esfuerzos el cristianismo fue adoptado en gran parte del Reino del Congo. Una incursión de tribus del interior más tarde ese mismo siglo acabó con el poder del estado semi-cristiano, y la actividad portuguesa fue transferida en buena parte hacia el sur, fundando São Paulo de Loanda (hoy Luanda) en 1576. Antes de la independencia de Angola en 1975, la soberanía de Portugal sobre esta región costera, excepto en la desembocadura del Congo, solamente había sido desafiada por una potencia europea, los holandeses, de 1640 a 1648 cuando Portugal perdió el control de los puertos marítimos.

El más antiguo tráfico africano de esclavos externo fue transahariano. Aunque hace mucho ya había ocurrido algo de tráfico a lo largo del Nilo y muy poco a través del desierto occidental, el transporte de grandes cantidades de esclavos no fue viable hasta que se introdujeron los camellos provenientes de Arabia en el siglo X. En este punto, una red transahariana comercial fue establecida para transportar esclavos hacia el norte. A diferencia de las Américas, los esclavos en África del Norte eran principalmente sirvientes en lugar de peones, y un número de mujeres igual o mayor que de hombres fue llevado, mismas que por lo general eran empleadas como camareras de las mujeres de los harenes. Tampoco era poco común convertir a los esclavos varones en eunucos.

El tráfico de esclavos a través del Atlántico se desarrolló más adelante, pero terminaría convirtiéndose mucho más grande y tendría un impacto mucho mayor. La penetración en incremento de las Américas por parte de portugueses, españoles, ingleses, franceses y holandeses, entre otros, propició una enorme demanda de mano de obra en Brasil, Guyena, el Caribe y Norteamérica. Los trabajadores eran requeridos para la agricultura, la minería y otras tareas. Para satisfacer esta demanda, se desarrolló un tráfico transatlántico de esclavos. Los esclavos adquiridos en aquellas regiones de África occidental conocidas por los europeos como Costa del Esclavo, Costa de Oro y Costa de Marfil con frecuencia eran el desafortunado producto de las luchas entre los estados africanos enemigos. Los poderosos reyes africanos de la bahía de Biafra podían vender sus presos internamente o intercambiarlos con los traficantes de esclavos europeos por bienes como armas de fuego, ron, telas y semillas. Cabe destacar que los traficantes europeos también realizaban sus propias cacerías de esclavos.

A pesar de que las Guerras Napoleónicas distrajeron a Europa de la exploración de África, hubo desarrollos significativos. La invasión de Egipto (1798-1803) primero por parte de Francia y luego por Gran Bretaña resultó en un intento de Turquía de recuperar el control directo sobre aquel país, seguido en 1811 por el establecimiento bajo el mando de Mehmet Alí de un estado casi independiente, y la extensión del dominio egipcio sobre el este de Sudán (de 1820 en adelante). En el sur de África la lucha contra Napoleón llevó al Reino Unido a tomar asentamientos holandeses en El Cabo, y en 1814 la Colonia del Cabo, la cual había sido ocupada continuamente por tropas británicas desde 1806, fue cedida formalmente a la corona británica.

Para mediados del siglo XIX, las misiones protestantes realizaron actividades misioneras en la costa de Guinea, en Sudáfrica y en los dominios de Zanzíbar. Se llevaban a cabo entre personas a quienes los europeos conocían poco. En muchos casos los misioneros se convertían en exploradores o agentes comerciales y de colonialismo. Uno de los primeros en intentar rellenar los espacios en blanco restantes en el mapa europeo fue David Livingstone, que había estado involucrado en las labores misioneras desde 1840 al norte del Orange. En 1849 Livingstone cruzó el desierto de Kalahari de sur a norte y llegó al lago Ngami, y entre 1851 y 1856 atravesó el continente de oeste a este, dando a conocer las grandes vías fluviales del alto Zambeze. Durante estas travesías Livingstone "descubrió", en noviembre de 1855, las famosas Cataratas Victoria, nombradas así en honor de la reina Victoria I del Reino Unido. En África, este salto de agua es llamado "Mosi-oa-Tunya" ("humo que truena"). Entre 1858 y 1864 el bajo Zambeze, el río Shire y el lago Nyasa fueron explorados por Livingstone. Una meta primordial para los exploradores era localizar el nacimiento del Nilo. Las expediciones de Burton y Speke (1857-1858) y Speke y Grant (1863) lograron localizar el lago Tanganica y el lago Victoria. Más adelante fue demostrado que era del segundo lago del que nacía el Nilo.

Henry Morton Stanley, quien en 1871 había tenido éxito al encontrar y socorrer a Livingstone, se dirigió a Zanzíbar en 1874, y en una de las más memorables de todas las expediciones de exploración en África circunnavegó los lagos Victoria y Tanganica, y, adentrándose más hasta el río Lualaba, siguió su curso río abajo hasta el Océano Atlántico —a donde llegó en agosto de 1877— y probó que era el río Congo.

Los exploradores también estuvieron activos en otras partes del continente. El sur de Marruecos, el Sahará y Sudán fueron atravesados en muchas direcciones entre 1860 y 1875 por Friedrich Gerhard Rohlfs, Georg August Schweinfurth y Gustav Nachtigal. Estos viajeros no solo aumentaron considerablemente el conocimiento geográfico, sino que también obtuvieron información invaluable respecto a la gente, los lenguajes y la historia natural de los países que visitaron. Entre los descubrimientos de Schweinfurth hubo uno que confirmó las leyendas griegas acerca de la existencia más allá de Egipto de una "raza pigmea". Pero el primer occidental en descubrir a los pigmeos de África central fue Paul du Chaillu, quien los halló en el distrito de Ogowe de la costa oeste en 1865, cinco años antes que el primer encuentro de Schweinfurth con ellos; du Chaillu hubo previamente, como resultado de sus viajes en la región de Gabón entre 1855 y 1859, hecho popular en Europa el conocimiento de la existencia del gorila, posiblemente el simio gigante visto por Hannón el Navegante, y cuya existencia, hasta mediados del siglo XIX, era concebida como legendaria al igual que la de los pigmeos de Aristóteles.

Mientras la exploración de las áreas más remotas e inaccesibles del continente era incipientes, ya se habían producido en otras partes del continente, siendo el más notable la invasión de Argel por parte de Francia en 1830. Esta acción puso fin a los estados bereberes independientes, un obstáculo mayor para la estrategia francesa en el Mediterráneo. La autoridad egipcia continuó su expansión hacia el sur. La ciudad de Zanzíbar, en la isla homónima, rápidamente cobró importancia. Relatos acerca de un vasto mar interior, y el "descubrimiento" en 1840-1848, por parte de los misioneros Johann Ludwig Krapf y Johannes Rebmann, del monte Kilimanjaro y de Kenia, estimularon en Europa el deseo de mayor conocimiento.

Aun así a finales del siglo XIX, el África subsahariana, era una de las últimas regiones del mundo en gran parte sin afectar por el "imperialismo informal", también resultaba atractiva para las potencias europeas por razones económicas y raciales. Durante una época donde la balanza comercial de Gran Bretaña mostraba un creciente déficit, con los mercados continentales encogiéndose y cada vez más proteccionistas debido a la Gran Depresión entre los años 1873 y 1896, África ofrecía al Reino Unido, Imperio Alemán, Francia y otros países un mercado abierto del que se cosecharía un gran excedente: un mercado que comprara más de la metrópoli de lo que vendía en total. El Reino Unido, al igual que la mayoría de los otros países industriales, había empezado a tener un desfavorable balance de comercio (que era contrarrestado, de todos modos, por el ingreso de las inversiones de sus colonias). Estas razones de fondo condujeron a la conferencia de Berlín donde los principales imperios europeos decidirían el reparto de África y la asignación de áreas de influencia que llevarían al colonialismo europeo de finales del siglo XIX y al sometimiento militar efectivo de millones de africanos.

La descolonización de África se refiere los procesos independentistas que ocurrieron en el continente posteriormente al término de la Segunda Guerra Mundial. Comenzó con Libia en 1951, a pesar de que Liberia, Sudáfrica, Egipto y Etiopía ya eran independientes. Lo siguieron Sudán y Túnez en 1956, Ghana en 1957 y Guinea en 1958, y con un apogeo en 1960, con el llamado "Año de África", donde 17 países africanos declararon la independencia, incluyendo gran parte de África Occidental Francesa. La mayor parte de los demás países se independizaron durante la década de 1960, aunque algunos colonizadores como Portugal, eran reacios a renunciar a la soberanía, lo que resultó en amargas guerras de independencia que se prolongaron durante una década o más. Los últimos países africanos en lograr la independencia formal fueron Angola de Portugal en 1975, Seychelles del Reino Unido en 1976, y Yibuti de Francia en 1977. Debido a que muchas ciudades fueron fundadas, ampliadas y rebautizadas por los europeos, después de la independencia a muchos lugares se les cambió el nombre.

Desde el fin de la Guerra Fría tres estados realizaron procesos de secesión y lograron su independencia de otras repúblicas africanas. Namibia se independizó de Sudáfrica en 1990, Eritrea de Etiopía en 1993, y Sudán del Sur de la República de Sudán en 2011.

Hoy en día, África contiene , la mayoría de los cuales tienen fronteras que se dibujaron durante la era del colonialismo europeo. Desde el colonialismo, los estados africanos han sido frecuentemente obstaculizados por la inestabilidad, la corrupción, la violencia y el autoritarismo. La gran mayoría de los estados africanos son repúblicas que operan bajo alguna forma del sistema presidencial de gobierno. Sin embargo, pocos de ellos han sido capaces de sostener gobiernos democráticos de manera permanente, y muchos en su lugar tenido ciclos a través de una serie de golpes de Estado, produciendo dictaduras militares. Como ejemplos opuestos se puede tomar a Botsuana que desde su independencia en 1966 a mantenido una fuerte tradición de estables democracias representativas, con consistentes registros de elecciones ininterrumpidas y la percepción de corrupción más baja de África, mientras que por el otro extremo está Somalía, país que sufre de una guerra civil desde 1991, entre varios bandos que han declarado autonomías regionales sin que un gobierno estatal pueda revertirlo. Estas autonomías regionales no son reconocidas internacionalmente, y han generado que Somalía sea considerado un Estado fallido. 

Gran inestabilidad fue principalmente el resultado de la marginación de los grupos étnicos, y el injerto bajo estos líderes. Por razones políticas, muchos dirigentes abrieron conflictos étnicos, algunos de los cuales fueron exacerbados, o incluso creados, por el dominio colonial. En muchos países, el ejército era percibido como el único grupo que podía mantener efectivamente el orden y gobernó a muchas naciones en África durante los años setenta y principios de los ochenta. Durante el período comprendido entre los primeros años de la década de 1960 y finales de los ochenta, África tuvo más de 70 golpes de Estado y 13 asesinatos presidenciales. Las disputas fronterizas y territoriales también eran comunes, con las fronteras impuestas por Europa de muchas naciones siendo ampliamente disputadas a través de conflictos armados.

El conflicto de la guerra fría entre los Estados Unidos y la Unión Soviética, así como las políticas del Fondo Monetario Internacional (FMI) también jugaron un papel en la inestabilidad. Cuando un país se independizó por primera vez, se esperaba que se alineara con una de las dos superpotencias. Muchos países del norte de África recibieron ayuda militar soviética, mientras que otros en África central y meridional recibieron el apoyo de Estados Unidos, Francia o ambos. La década de 1970 vio una escalada de los conflictos de la Guerra Fría, ya que la nueva Angola independiente y Mozambique se alinearon con la Unión Soviética, y África Occidental y Sudáfrica trataron de contener la influencia soviética apoyando regímenes amistosos o movimientos insurgentes. En Rhodesia, la guerrilla izquierdista apoyada por los soviéticos y los chinos del Frente Patriótico de Zimbabue llevó a cabo una brutal guerra de guerrillas contra el gobierno blanco del país. Hubo una gran hambruna en Etiopía, cuando cientos de miles de personas murieron de hambre. Algunos afirmaron que las políticas económicas marxistas empeoraron la situación. El conflicto militar más devastador en África independiente moderna ha sido la Segunda Guerra del Congo; este conflicto y sus secuelas han causado la muerte de unos 5,5 millones de personas. Desde 2003 se ha producido un Conflicto de Darfur que se ha convertido en un desastre humanitario. Otro acontecimiento trágico notable es el genocidio ruandés de 1994 en el cual se calcula que 800,000 personas fueron asesinadas. El SIDA en el África poscolonial también ha sido una cuestión frecuente.

En el siglo XXI, sin embargo, el número de conflictos armados en África ha disminuido constantemente. Por ejemplo, la guerra civil de Angola llegó a su fin en 2002 después de casi 30 años. Esto ha coincidido con muchos países que abandonan las economías de mando del estilo comunista y se abren a las reformas del mercado. La mejora de la estabilidad y las reformas económicas han llevado a un gran aumento de la inversión extranjera en muchas naciones africanas, principalmente de China, lo que ha impulsado un rápido crecimiento económico en muchos países, paralizando décadas de estancamiento y declive. Varias economías africanas se encuentran entre las de mayor crecimiento mundial a partir de 2016. Una parte significativa de este crecimiento, que a veces se denomina "Africa Rising", también puede atribuirse a la difusión facilitada de las tecnologías de la información y específicamente el teléfono móvil.

Por otra parte, el surgimiento de la primavera árabe y los conflictos asociados, sumado a la insurgencia del Estado Islámico y movimientos que lo apoyan tales como el Boko Haram en Nigeria, han generados nuevos brotes de violencia en el norte y occidente de áfrica durante la década de 2010.










</doc>
<doc id="1455" url="https://es.wikipedia.org/wiki?curid=1455" title="Hidrología">
Hidrología

La hidrología es una rama de las ciencias de la Tierra que estudia el agua, su ocurrencia, distribución, circulación, y propiedades físicas, químicas y mecánicas en los océanos, atmósfera y superficie terrestre. Esto incluye las precipitaciones, la escorrentía, la humedad del suelo, la evapotranspiración y el equilibrio de las masas glaciares. Por otra parte, el estudio de las aguas subterráneas corresponde a la hidrogeología.

Por el contrario, se denomina hidrografía al estudio de todas las masas de agua de la Tierra y, en sentido más estricto, a la medida, recopilación y representación de los datos relativos al fondo del océano, las costas, las mareas y las corrientes, de manera que se puedan plasmar sobre una carta hidrográfica. No obstante esta diferencia, los términos se utilizarán casi como sinónimos, ya que la parte de la hidrografía que interesa aquí es aquella que crea relieve, por lo tanto, la que está en contacto con la superficie terrestre, y por eso mismo la que es objeto de un análisis hidrológico.

La circulación de las masas de agua en el planeta son responsables del modelado de la corteza terrestre, como queda de manifiesto en el ciclo geográfico. Esa influencia se manifiesta en función de la distribución de las masas de rocas coherentes y deleznables, y de las deformaciones que las han afectado, y son fundamentales en la definición de los diferentes relieves.

Recordemos que un río es una corriente de agua que fluye por un cauce desde las tierras altas a las tierras bajas y vierte en el mar o en una región endorreica (río colector) o a otro río (afluente). Los ríos se organizan en redes. Una cuenca hidrográfica es el área total que vierte sus aguas de escorrentía a un único río, aguas que dependen de las características de la alimentación. Una cuenca de drenaje es la parte de la superficie terrestre que es drenada por un sistema fluvial unitario. Su perímetro queda delimitado por la divisoria o interfluvio.

Los trazados de los elementos hidrográficos se caracteriza por la adaptación o inadaptación a las estructuras litológicas y tectónicas, pero también la estructura geológica actúa en el dominio de las redes hidrográficas determinando su estructura y evolución.

El estudio hidrológico, inicia con el análisis morfométrico de la cuenca, que incluye: la delimitación de la cuenca, la medición del área y la longitud, altura máxima y mínima, índice de compacidad, factor de forma, curva hipsométrica, pendiente media, caracterización de la red de drenaje y el perfil altimétrico del cauce principal, entre otros.

En el transcurso de su desarrollo la hidrología se ha definido de diversas formas, una de las más simples es la que se deriva del análisis etimológico del vocablo, por ello, se tendría: La hidrología es la ciencia del agua.

En el nivel actual de desarrollo de las actividades humanas y de las ciencias en general no se puede satisfacer con la definición anterior, demasiado simplista e incompleta, por ello se recomienda analizar las siguientes:

Generalmente los diversos autores reconocen 8 períodos en el desarrollo histórico de la hidrología, estos son:

Aunque las fechas no son exactas, varios autores como O.E. Meinzer, definen este período, desde la antigüedad hasta el 1400.
Durante este período el concepto de ciclo hidrológico fue especulado
La mayoría de los conceptos desarrollados en esta época resultaron ser erróneos, con excepción del propuesto por Marco Vitruvio, quien estableció que el agua subterránea provenía de la infiltración del agua de lluvia y del derretimiento de la nieve.

A este período pertenecen las grandes construcciones hidráulicas de la antigüedad las que requirieron un conocimiento hidrológico práctico, entre ellos los pozos de Arabia, los Kanats de Persia, los acueductos de Roma, los canales y sistemas de irrigación y obras de control de inundaciones en China, y zonas de riego en Egipto, Mesopotamia, India y en los Andes.

Entre el 1400 y el 1600. En el período conocido como el Renacimiento, se tuvo un cambio gradual de los conceptos filosóficos puros de la hidrología a la ciencia observacional de tal época. Por ejemplo, basándose en observaciones, Leonardo da Vinci y Bernard Palissy lograron una correcta comprensión del ciclo hidrológico, especialmente en lo relativo a la infiltración de la lluvia y retorno del agua a través de manantiales.

Entre el 1600 y el 1700. El inicio de la moderna ciencia de la hidrología puede ser considerado en el siglo XVII, con las mediciones, por ejemplo: las de Pierre Perrault y Edmé Mariotte en el río Sena de París y Edmond Halley en el mar Mediterráneo, los cuales llegaron a conclusiones correctas del fenómeno hidrológico estudiado. A este período corresponde también los primeros estudios de los pozos artesianos.

Entre el 1700 y el 1800. Durante el Siglo XVIII, los estudios experimentales hidráulicos tuvieron gran auge y como resultado de ellos muchos principios hidráulicos fueron obtenidos, por ejemplo: el teorema y piezómeto de Bernouilli, la fórmula de Chézy y el principio de D'Alembert, los tubos de Pitot y Borda.

Entre el 1800 y el 1900.El Siglo XIX fue una gran era de hidrología experimental que tuvo su inicio en el período precedente y que marcó más firmemente el comienzo de la ciencia de la hidrología. Sin embargo la mayoría de contribuciones se tuvieron en la geohidrología y en la medición de las aguas superficiales (Hidrometría). Por ejemplo: la ecuación de Hagen-Poiseuille del flujo capilar (1840), la Ley de Darcy (1856), la fórmula del pozo de Dupuit-Thiem (1863) y el principio de Ghyben-Herzberg (1889).

En el campo de la hidrometría, en relación al aforo de aguas superficiales, se tuvo un gran avance, incluyendo: el desarrollo de varias fórmulas del flujo e instrumentos de medida y el comienzo del aforo sistemático de corrientes. Entre las contribuciones principales se tiene la fórmula de descarga de los vertedores de Francis (1855), la determinación del coeficiente de Chézy propuesta por Ganguillet y Kutter (1869) y por Manning (1889) y en el campo de la evaporación, la ley deDalton (1802), por último, en el campo de la precipitación, la correlación entre la lluvia y la altitud, determinada por Miller (1849).

Entre el 1900 y el 1930.
Aunque muchos trabajos de hidrología moderna fueron iniciados en el Siglo XIX, el desarrollo de la hidrología cuantitativa fue todavía inmaduro y entonces la ciencia de la hidrología fue enormemente empírica, debido a que la base física para varias determinaciones hidrológicas no era bien conocida, o bien porque se disponía de mucha información cuantitativa experimental para ser usada y procesada. Durante la parte final del Siglo XIX, y los siguientes 30 años, el empirismo hidrológico fue evidente, por ejemplo: cientos de fórmulas empíricas fueron propuestas, seleccionando sus coeficientes y parámetros en base al juicio y experiencia.

Entre el 1930 y el 1950. En este período se inician los grandes hidrólogos que utilizan el análisis racional para resolver los problemas hidrológicos planteados, así por ejemplo se tienen a: Sherman (1932) con el concepto de hidrograma unitario. Horton (1953) con la teoría de la infiltración de la lluvia, Theis (1935) que introduce el concepto de noequilibrio en la hidráulica de pozos, Gumbel (1941) que propone la distribución de probabilidades de valores extremos, Hazen (1930) que promueve el uso de la estadística en la hidrología, Bernard (1944) que discute el papel de la meteorología y marca el inicio de la hidrometeorología y Einstein (1950) quien introduce el análisis teórico en los estudios de sedimentación. Otro notable desarrollo de este período fue el establecimiento de muchos laboratorios hidráulicos e hidrológicos en el mundo.

Desde el 1950 hasta el presente. Alrededor del año 1950, las aproximaciones teóricas tienen uso extensivo a los problemas hidrológicos, ya que muchos principios racionales propuestos anteriormente, pueden ser sujetos a un verdadero análisis matemático. Los instrumentos sofisticados y las computadoras de alta velocidad empiezan su desarrollo y entonces, se pueden tomar medidas delicadas del fenómeno hidrológico y resolver ecuaciones matemáticas complicadas involucradas en la aplicación de modernas teorías hidrológicas.

Son ejemplos de los estudios hidrológicos teóricos: el análisis linear y no linear de sistemas hidrológicos, la adopción de conceptos estadísticos y transitorios en la hidrodinámica del agua subterránea y superficial, La aplicación de le las teorías de transferencia de masa y calor al análisis de evaporaciones, al estudio energético y dinámico de la humedad del suelo, la generación secuencial de datos hidrológicos sintéticos y el uso de la investigación de operaciones en el diseño de sistemas de recursos hídricos.

En la actualidad la hidrología tiene un papel muy importante en el planeamiento del uso de los Recursos Hidráulicos, y ha llegado a convertirse en parte fundamental de los proyectos de ingeniería que tienen que ver con suministro de agua, disposición de aguas servidas, drenaje, protección contra la acción de ríos y recreación. De otro lado, la integración de la hidrología con la Geografía matemática en especial a través de los sistemas de información geográfica ha conducido al uso imprescindible del computador en el procesamiento de información existente y en la simulación de ocurrencia de eventos futuros.

Los estudios hidrológicos son fundamentales para:

Todo esto y muchas aplicaciones más hacen que el hidrólogo sea un personaje importante en todo equipo multidisciplinar que enfrenta problemas de ingeniería civil en general y problemas de carácter ambiental.

La hidrología puede catalogarse, de acuerdo con la forma de análisis, y el uso que se dará de los resultados. Puede clasificarse, aun sabiendo de la limitación de cualquier clasificación en:

En la hidrología cualitativa el énfasis está dado en la descripción de los procesos. Por ejemplo en la determinación de las formas y causas que provocan la formación de un banco de arena en un río, estudio asociado al transporte sólido de los cursos de agua; o al análisis de la ocurrencia de condensaciones en determinados puntos de una carretera, que afectan la visibilidad y por lo tanto pueden aconsejar a cambiar el trazado de la misma.

La hidrología hidrométrica, o hidrometría, se centra en la medición de las variables hidrológicas, se trata básicamente de trabajos de campo, donde el uso adecuado de los instrumentos de medición, la selección adecuada de los locales en los cuales las medidas son efectuadas y la correcta interpretación de los resultados es fundamental para la calidad de la información recabada. Ayudando en su totalidad a poder calcular aspectos relacionados con cauces y las dependencias hidrológicas.

El énfasis de la hidrología cuantitativa esta en el estudio de la distribución temporal de los recursos hídricos en una determinada cuenca hidrográfica. Los instrumentos más utilizados en esta rama de la hidrología son los instrumentos matemáticos, modelos estadísticos y modelos conceptuales.

Es la rama más nueva de la hidrología, y se populariza a partir de los años 1960 - 70, con el auge de las redes telemétricas, donde sensores ubicados en varios puntos de una cuenca transmiten, en tiempo real los datos a una central operativa donde son analizados inmediatamente para utilizarlos en auxilio de la toma de decisiones de carácter operativo, como abrir o cerrar compuertas de una determinada obra hidráulica.

La Asociación Internacional de Hidrología Científica (IASH, por su sigla en inglés de International Association of Scientific Hydrology) propone la siguiente división de la hidrología:




</doc>
<doc id="1462" url="https://es.wikipedia.org/wiki?curid=1462" title="Célula haploide">
Célula haploide

Una célula haploide es aquella que contiene un solo juego de cromosomas o la mitad (n, haploide) del número normal de cromosomas, en células diploides (2n, diploide). Las células reproductoras, como los óvulos y los espermatozoides de los mamíferos, la etapa asexual de hongos, briófitos y algunas algas contienen un solo juego de cromosomas, mientras que el resto de las células de un organismo superior suelen tener dos juegos de ellos. Cuando los gametos se unen durante la fecundación el huevo fecundado contiene un número normal de cromosomas (2n): es una célula diploide.

La génesis de una célula haploide puede ocurrir de dos maneras:

La meiosis de hecho se divide en meiosis 1 y meiosis 2. Es en la meiosis 1; además de una división citoplasmática, se genera una duplicación del ADN, de tal forma que cada uno de los 46 cromosomas (en el caso del homo sapiens) queda constituido por dos cromátidas hermanas (46 cromosomas de estructura doble). Luego, la división citoplasmática se da y las dos células hijas fruto de la meiosis 1, entran a meiosis 2.

La meiosis se encarga de separar las cromátidas hermanas sin inducir una nueva replicación en el ADN; creando así cuatro células con la mitad de cromosomas de sus predecesoras, es decir, células haploides o gametos.

Individuos de algunas especies, como los zánganos, de la abeja melífera "Apis melífera", se desarrollan a partir de óvulos no fecundados y son por tanto haploides.




</doc>
<doc id="1463" url="https://es.wikipedia.org/wiki?curid=1463" title="Hedonismo">
Hedonismo

El hedonismo (del griego ἡδονή "hēdonḗ" 'placer' e "-ismo") es una doctrina moral que establece la satisfacción como fin superior y fundamento de la vida. Su principal objetivo consiste en la búsqueda del placer que pueda asociarse con el bien.

El hedonismo no consiste en afirmar que el placer es un bien, ya que dicha afirmación ha sido admitida por otras muchas doctrinas éticas muy alejadas del hedonismo, sino en considerar que el placer es el único y supremo bien.

El término «hedonismo» puede tomarse en dos sentidos, lato y estricto. En el primero, el hedonismo sería una teoría ética de gran amplitud en la que la palabra placer tendría un significado muy extenso, que abarcaría tanto el placer como la utilidad; en este sentido, el utilitarismo se encuadraría dentro del hedonismo. En un sentido más restringido, el hedonismo se diferencia del utilitarismo, fundamentalmente, porque el primero cifra el bien en el placer individual, mientras que el segundo afirma como bien sumo el placer, el bienestar y la utilidad social. El hedonismo tiene un carácter individualista, el utilitarismo es de índole social y sostiene el punto de vista de que la satisfacción humana se encuentra en la búsqueda y posesión del placer material y físico.

Dentro del hedonismo en sentido estricto se pueden distinguir dos formas del mismo, de acuerdo con los dos significados que tiene el término placer. Este designa al placer sensible, o inferior, y al placer espiritual, o superior. En consecuencia, habrá dos formas de hedonismo llamadas hedonismo absoluto y hedonismo mitigado, o eudemonismo.

El hedonismo radical sostiene que todos los placeres físicos deben ser satisfechos sin ninguna restricción, mientras que el hedonismo moderado afirma que las actividades placenteras deben ser moderadas, para que así aumente el placer. En ambos casos el placer es la principal motivación del comportamiento.

Por lo que se refiere al hedonismo psicológico, son varias las doctrinas existentes según la determinación temporal del placer. La teoría del placer de los fines, o «hedonismo psicológico del futuro», sostiene que el placer personal es el fin último y único de una persona. 

Las dos escuelas clásicas del hedonismo, formuladas en la Antigua Grecia, son la escuela cirenaica y el epicureísmo.

Aristipo de Cirene, discípulo de Sócrates y fundador de la escuela cirenaica de filosofía fue uno de los máximos representantes del hedonismo. Él consideraba el placer como principal objetivo, es decir, como fin que al ser alcanzado rápidamente es posible llegar a la felicidad. Resalta más el placer del cuerpo sobre los placeres mentales.

La escuela cirenaica, fundada entre los siglos IV y III a. C., plantea que el placer es elegible por uno mismo, caso contrario de la felicidad que no es más que el conjunto de los distintos placeres. El placer es guiado por la prudencia pues es el hombre quien debe dominar al placer y no dejarse dominar por él. Tanta prioridad se le otorga al placer, que sobrepone la realización de los deseos personales para satisfacerse de manera inmediata ignorando los intereses de los demás incluso si esto implicara actos inmorales. Su interés por el placer presente invita a preocuparse por el hoy, ya que el futuro es incierto. (Primero mis dientes, luego mis parientes).

Fue una de las más antiguas escuelas socráticas y enfatizaba solo un lado de las enseñanzas de Sócrates. Con base en la afirmación de Sócrates de que la felicidad es uno de los fines de la acción moral, Aristipo mantenía que el placer era el bien superior. Decía que las gratificaciones corpóreas, que consideraba intensas, eran preferibles a las mentales. Los cirenaicos también negaban que se pospusiera la gratificación inmediata por la ganancia a largo plazo. En este respecto difieren de los epicúreos.

Epícuro de Samos, discípulo de Aristipo, cuyo objetivo en la filosofía era evitar el sufrimiento procurando la felicidad, por lo tanto, el objetivo principal para el ser humano debía ser el alcance de la felicidad priorizando la satisfacción obtenida por los deseos para subsistir y moderando aquellos que son naturales, pero no vitales. 

El epicureísmo, movimiento fundado entre 341 y 270 a. C., plantea que la felicidad consiste en vivir continuamente bajo la satisfacción del placer que no excita los sentidos, sino al que se refiere a la ausencia del dolor o de cualquier tipo de aflicción; más que buscar un placer inmediato busca aquel que requiere del uso de la razón, es decir, el que valora las consecuencias sobre las acciones y otorga placer a largo plazo. El placer se encuentra asociado con la tranquilidad, por lo que está relacionado con la "ataraxia", o la capacidad de controlarse uno mismo y aceptar los problemas naturales fuera de nuestro control, como lo es la muerte.

El epicureísmo identificaba el placer con la tranquilidad y enfatizaba la reducción del deseo sobre la adquisición inmediata del placer. En esta forma, el epicureísmo escapa a la objeción precedente: mientras el placer y el bien mayor son de hecho lo mismo, Epicuro argumentaba que el placer más alto consiste en una vida simple, moderada, complementada con discusiones filosóficas entre amigos. Enfatizaba que no era bueno hacer algo que a uno le haga sentir bien si después de experimentarlo denigraría las experiencias posteriores y no le permitiría sentirse bien. Así mismo afirmaba que a veces por tener placeres momentáneos intensos se sacrifica el bienestar posterior. Epicuro entendía por placer la ausencia de dolor.

Existen escritos de Epicuro y de sus seguidores que nos muestran sus doctrinas: entre los deseos, algunos son naturales y necesarios y otros ni lo uno ni lo otro, solo consagrados a la opinión vana. La disposición que tengamos hacia cada uno de estos casos determina nuestra aptitud para ser felices o no. 


Epicuro formuló algunas recomendaciones con respecto a estas categorías:


La filosofía epicúrea ganó un gran número de adeptos. Fue una importante escuela de pensamiento que perduró durante siete siglos después de la muerte de su creador. Hacia la Edad Media decayó y fueron destruidos muchos de sus escritos. Sin embargo, hoy existen remanentes de esta doctrina que han sido compilados y difundidos por el mundo.

Las dos escuelas convergen en su repudio por la superstición y la religión y sus bases en la conducta y el juicio mediante la experiencia y la razón. Así anticipan las posiciones del humanismo e iluminismo posteriores.

En los siglos XVIII y XIX, los filósofos británicos Jeremy Bentham, James Mill y John Stuart Mill hicieron la propuesta de una doctrina universal más conocida como utilitarismo. Según esta teoría, el comportamiento humano debe tener como criterio final el bien social. Hay que guiarse moralmente buscando todo aquello que proporciona y favorece el bienestar de un mayor número de personas.

Dentro de la filosofía contemporánea se destaca la figura de Michel Onfray como abierto proponente del hedonismo, quien manifiesta en una entrevista que «se cree que el hedonista es aquel que hace el elogio de la propiedad, de la riqueza, del tener, que es un consumidor. Eso es un hedonismo vulgar que propicia la sociedad. Yo propongo un hedonismo filosófico que es en gran medida lo contrario, del ser en vez del tener, que no pasa por el dinero, pero sí por una modificación del comportamiento. Lograr una presencia real en el mundo, y disfrutar jubilosamente de la existencia: oler mejor, gustar, escuchar mejor, no estar enojado con el cuerpo y considerar las pasiones y pulsiones como amigos y no como adversarios».

Otra figura destacable en defensa de este planteamiento hedonista es la escritora Valérie Tasso. Su libro "Antimanual de sexo" intenta abordar desde esta perspectiva el fenómeno de la sexualidad humana con declaraciones como la siguiente: «El hedonismo es una actitud ante la vida. Es una filosofía vital que prima al instante sobre el devenir, que reivindica la valentía sobre el miedo, que respeta la materialidad y cuestiona el espíritu, que gestiona lo que sucede sin despreciarse por lo que nunca sucedió, que aprecia la lógica de la vida y cuestiona la lógica de la muerte, que sabe que lo suficiente es suficiente, que busca el placer donde está, no donde se busca, que hace de su cuerpo su aliado y no su prisión, que desea sin que lo esclavice su deseo, que emplea su tiempo más que su dinero [...] El hedonista ejerce el difícil arte de establecer la paz consigo mismo».

La fe católica se opone a las formas más sensuales del hedonismo, considerando que minan los valores y las virtudes del eudemonismo espiritual, en el cual el Cristianismo frecuentemente ha fundado su moral.

El hedonismo es considerado por muchas religiones una actitud carente de moral pero no porque aprecie algún placer, sino porque lo antepone a las exigencias del amor a Dios y al prójimo. Para el catolicismo, es una actitud que corre el riesgo de caer en el egocentrismo, el cual incapacita gravemente al sujeto para relacionarse con otros, a menos que sea para explotarlos y satisfacer su afán de placer.

El filósofo británico G. E. Moore dedica gran parte de su libro "Principia Ethica" (1903) a la refutación del hedonismo. Entiende que considerar que el placer y solamente el placer es bueno significa caer en lo que llamó «falacia naturalista». Al decir que «el placer y solamente el placer es bueno», el placer se convierte en un equivalente de «bueno». Así, la proposición «el placer es bueno» significa realmente «el placer es el placer», tautología de ningún interés ético. Moore defendía que el bien era indefinible, si bien podían atribuírsele ciertas características que no obstante no delimitarían su significación por completo.

La psicología positiva, basada en investigaciones científicas de psicológica cognoscitiva, ha pensado muchas veces que sustentar la felicidad en la búsqueda del placer, «la vida placentera», deriva en un mayor índice de insatisfacción. La búsqueda de una felicidad auténtica, como indica el psicólogo Martin E. P. Seligman, implica poner un mayor enfoque en el compromiso y el significado. La «vida comprometida» está basada en gratificaciones que no pueden ser adquiridas por atajos, como aprender un oficio, o un deporte; se busca el «flujo», que es el balance del reto con la habilidad. Por otra parte, la vida significativa son las acciones y creencias basadas en algo mayor a nuestro ego, acciones motivadas por un bien común, etcétera. Se ha dicho que aquellos que basan su felicidad en la «vida comprometida» y «la vida significativa» cuentan con un mayor índice de satisfacción en la vida. La «felicidad auténtica» es un concepto superior al simple hecho de no sentir dolor, sentir placer, o no sufrir enfermedades psicológicas.

Estos datos, sin embargo, no son científicos, sino más bien ideales. La mayoría de neurocientíficos cree que nuestro cerebro funciona con un esquema de «castigo-recompensa», en el que algo que beneficiaría a nuestros antepasados (comida, pertenecer a un grupo o tener sexo) llevan a la producción de endorfinas, u hormonas del placer, lo que haría que los hedonistas tengan la razón. Aunque se advierte que algunas partes de las teorías hedonistas puedan ser morales y no precisamente abordan un tema objetivo.



</doc>
<doc id="1466" url="https://es.wikipedia.org/wiki?curid=1466" title="Ingeniería">
Ingeniería

La ingeniería es el conjunto de conocimientos científicos y tecnológicos para la innovación, invención, desarrollo y mejora de técnicas y herramientas para satisfacer las necesidades y resolver los problemas de las empresas y la sociedad.

El ingeniero se apoya en las matemáticas, la física, la química, la programación y otras ciencias tanto para el desarrollo de tecnologías, como para el manejo eficiente y productivo de recursos y fuerzas de la naturaleza en beneficio de la sociedad. La ingeniería es una actividad que transforma el conocimiento en algo práctico.

La ingeniería aplica los conocimientos y métodos científicos a la invención o perfeccionamiento de tecnologías de manera pragmática y ágil, adecuándose a las limitaciones de tiempo, recursos, requisitos legales, requisitos de seguridad, ecológicos, etc.

Su estudio como campo del conocimiento está directamente relacionado con el comienzo de la Revolución Industrial, constituyendo una de las actividades pilares en el desarrollo de las sociedades modernas.

Su función principal es la de realizar diseños o desarrollar soluciones tecnológicas a necesidades sociales, industriales o económicas. Para ello el ingeniero debe identificar y comprender los obstáculos más importantes para poder realizar un buen diseño. Algunos de los obstáculos son los recursos disponibles, las limitaciones físicas o técnicas, la flexibilidad para futuras modificaciones y adiciones y otros factores como el coste, la posibilidad de llevarlo a cabo, las prestaciones y las consideraciones estéticas y comerciales. Mediante la comprensión de los obstáculos, los ingenieros deciden cuáles son las mejores soluciones para afrontar las limitaciones encontradas cuando se tiene que producir y utilizar un objeto o sistema.

Los ingenieros utilizan el conocimiento de la ciencia, las matemáticas y la experiencia para encontrar las mejores soluciones a los problemas concretos, creando los modelos matemáticos de los problemas que les permiten analizarlos rigurosamente y probar las soluciones potenciales. Si existen múltiples soluciones razonables, los ingenieros evalúan las diferentes opciones de diseño sobre la base de sus cualidades y eligen la solución que mejor se adapta a las necesidades, costo, seguridad y otras condiciones de contorno.

En general, los ingenieros intentan probar si sus diseños logran sus objetivos antes de proceder a la producción en cadena. Para ello, emplean entre otras cosas prototipos, modelos a escala, simulaciones, pruebas destructivas y pruebas de fuerza. Los ensayos comprueban si los artefactos funcionarán como se había previsto.

Para hacer diseños estándares y fáciles, las computadoras tienen un papel importante. Utilizando los programas de diseño asistido por ordenador (DAO, más conocido por CAD, "computer-aided design"), los ingenieros pueden obtener más información sobre sus diseños. El ordenador puede traducir automáticamente algunos modelos en instrucciones aptas para fabricar un diseño. La computadora también permite una reutilización mayor de diseños desarrollados anteriormente, mostrándole al ingeniero una biblioteca de partes predefinidas para ser utilizadas en sus propios diseños.

Los ingenieros deben tomar muy seriamente su responsabilidad profesional para producir diseños que se desarrollen como estaba previsto y no causen un daño inesperado a la gente en general. Normalmente, los ingenieros incluyen un factor de seguridad en sus diseños para reducir el riesgo de fallos inesperados.

La ciencia intenta abordar la explicación de los fenómenos, creando modelos matemáticos que correspondan con los resultados experimentales. Tecnología e ingeniería constituyen la aplicación del conocimiento obtenido a través de la ciencia, produciendo resultados prácticos. Los científicos trabajan con la ciencia y los tecnólogos con la tecnología. Sin embargo, la ingeniería se desarrolla al congeniar ciencia y tecnología (p. ej. creando formatos, diseños, herramientas y materiales para la industria). No es raro que los científicos se vean implicados en el desarrollo de la tecnología y de la ingeniería por las aplicaciones de sus descubrimientos. De modo análogo los ingenieros y tecnólogos, descubren a veces nuevos fenómenos o teorías que desenvuelven el campo de la ciencia.

Los ingenieros tienen como su función principal hallar soluciones a los problemas utilizando destrezas tecnológicas y científicas; el ingeniero debe tener una gran pericia visual espacial para realizar distintas cosas con ayuda de esta capacidad.

También puede haber conexiones entre el funcionamiento de los ingenieros y los artistas, principalmente en los campos de la arquitectura y del diseño industrial.





La profesión de ingeniero está regulada en varios países, que tienen profesores con doctorados, maestrías y licenciaturas que certifican que el aspirante está preparado para ejercer como ingeniero.

La ciencia, investiga, le interesa saber, su producto son los conocimientos.

La ingeniería por su lado, aplica todos aquellos conocimientos que son el resultado de la investigación. Le interesa el conocimiento de la ciencia en la medida en que lo pueda aplicar; el producto son las obras y los aparatos físicos que crea.

La ingeniería tenía antiguamente dos ramas fundamentales: militar y civil. Esta última dio origen a la ramas mecánica y eléctrica. De las ramas citadas, derivan las demás.








A inicios del siglo XXI la ingeniería en sus muy diversos campos ha logrado explorar los planetas del sistema solar con alto grado de detalle, destacan los exploradores que se introducen hasta la superficie planetaria; también ha creado un equipo capaz de derrotar al campeón mundial de ajedrez; ha logrado comunicar al planeta en fracciones de segundo; ha generado internet y la capacidad de que una persona se conecte a esta red desde cualquier lugar de la superficie del planeta mediante una computadora portátil y teléfono satelital; ha apoyado y permitido innumerables avances de la ciencia médica, astronómica, química y en general de cualquier otra. Gracias a la ingeniería se han creado máquinas automáticas y semiautomáticas capaces de producir con muy poca ayuda humana grandes cantidades de productos como alimentos, automóviles y teléfonos móviles. Elisa Leonida Zamfirescu (1887-1973) fue la primera mujer ingeniera del mundo. En 1909 se inscribió en la Academia Real Técnica de Berlín, Charlottemburgen y se graduó en 1912.

Pese a los avances de la ingeniería, la humanidad no ha logrado eliminar el hambre del planeta, ni mucho menos la pobreza, siendo evitable la muerte de un niño de cada tres en el año 2005. Sin embargo, además de ser este un problema de ingeniería, es principalmente un problema de índole social, político y económico.

Un aspecto negativo que ha generado la ingeniería y compete en gran parte resolver a la misma es el impacto ambiental que muchos procesos y productos emanados de estas disciplinas han generado y es deber y tarea de la ingeniería contribuir a resolver el problema.

En sus inicios la Ingeniería estuvo vinculada, casi exclusivamente a actividades militares, gubernamentales y religiosas. Basta con mencionar los caminos, puentes, murallas, torres, faros, puertos, Monumentos funerarios y demás. En tiempos de paz la Ingeniería fue puesta al servicio del bienestar del Ser Humano, al margen de la guerra y los ejércitos. De ahí que cuando, en el siglo XIX, Algunas Universidades empezaron a ofrecer esta carrera, la llamaron ingeniería civil para distinguirla de la ejercida por los militares (Ingeniería Militar).

A continuación se listan algunas de las primeras escuelas universitarias en Europa y América:

Aquí están las conexiones entre la ingeniería y el arte, que son directos, en algunos campos, por ejemplo, la arquitectura, arquitectura del paisaje y el diseño industrial (incluso estas disciplinas a veces pueden ser incluidas en una Facultad de la Universidad de Ingeniería); e indirecta en otros.
El Instituto de Arte de Chicago, por ejemplo, organizó una exposición sobre el arte del diseño aeroespacial de la NASA. Diseño de Robert Maillart puente es percibido por algunos como han sido deliberadamente artística. En la Universidad del Sur de Florida, un profesor de ingeniería, a través de una subvención con la Fundación Nacional de Ciencias, ha desarrollado un curso que se conecta el arte y la ingeniería.
Entre los famosos de la historia, Leonardo Da Vinci es un artista del Renacimiento y un ingeniero bien conocido, y un excelente ejemplo del vínculo entre el arte y la ingeniería.

Del mismo modo, existen numerosos puentes que han sido considerados como monumentos con categoría de Patrimonio Mundial por la UNESCO, como el acueducto Pontcysyllte o el conjunto de los puentes del centro de París. 


</doc>
<doc id="1467" url="https://es.wikipedia.org/wiki?curid=1467" title="Impresora">
Impresora

Una impresora es un dispositivo periférico del ordenador que permite producir una gama permanente de textos o gráficos de documentos almacenados en un formato electrónico, imprimiéndolos en medios físicos, normalmente en papel, utilizando cartuchos de tinta o tecnología láser (con tóner).

Muchas de las impresoras son usadas como periféricos, y están permanentemente unidas al ordenador por un cable. Otras impresoras, llamadas impresoras de red, tienen una interfaz de red interno (típicamente wireless o ethernet), y que puede servir como un dispositivo para imprimir en papel algún documento para cualquier usuario de la red.

Además, muchas impresoras modernas permiten la conexión directa de aparatos de multimedia electrónicos como las tarjetas "CompactFlash", "Secure Digital" o "Memory Stick", "pendrives", o aparatos de captura de imagen como cámaras digitales y escáneres. También existen aparatos multifunción que constan de impresora, escáner o máquinas de fax en un solo aparato. Una impresora combinada con un escáner puede funcionar básicamente como una fotocopiadora.

Son diseñadas para realizar trabajos repetitivos de poco volumen, que no requieran virtualmente un tiempo de configuración para conseguir una copia de un determinado documento. Sin embargo, las impresoras son generalmente dispositivos lentos (10 páginas por minuto es considerado rápido), y el gasto por página es relativamente alto.

Para trabajos de mayor volumen existen las imprentas, que son máquinas que realizan la misma función que las impresoras pero están diseñadas y optimizadas para realizar trabajos de impresión de gran volumen, como sería la impresión de periódicos. Las imprentas son capaces de imprimir cientos de páginas por minuto o más.

En general, las impresoras se pueden dividir en categorías siguiendo diversos criterios.

La distinción más común se hace entre:

Además, se pueden seguir los siguientes criterios para clasificar las impresoras:


Técnicamente, las impresoras láser son matriciales, pero la nitidez de la impresión y el tamaño reducido de los puntos impresos con alta densidad, se puede considerar que los trazos de sus caracteres son continuos.

Esta clasificación se refiere al medio utilizado para enviar los datos a la impresora:

Muchas versiones de impresoras estaban disponibles en paralelo y en serie, e incluso incorporaban ambas opciones, aumentando la flexibilidad para instalarlas. Actualmente, la tendencia es a favor de las impresoras en serie, a través del estándar USB.



Los distintos tipos de impresoras se diferencian en la velocidad de impresión y en la calidad del producto impreso.

Las impresoras de caracteres, como las matriciales, imprimen en un rango de velocidad entre 200 y 400 caracteres por segundo (cps), que supone de 90 a 180 líneas por minuto (lpm). Las impresoras de línea presentan un amplio rango de velocidades, desde 400 a 2000 líneas por minuto. La velocidad de las impresoras de página oscila entre 4 y 800 páginas por minuto (ppm) para impresiones en blanco y negro, y la décima parte para la impresión en color.

En entornos de oficinas en los que se empleen formularios en papel continuo o de varias hojas de papel continuo, la impresora más adecuada es la de matriz de puntos, pero si se requiere mayor calidad de impresión se utilizará impresora láser. Las impresoras de inyección de tinta son las preferidas para entornos domésticos, por precio asequible.

La elección del motor de compresión tiene un efecto substancial en los trabajos a los que una impresora está destinada. Hay diferentes tecnologías que tienen diferentes niveles de calidad de imagen, velocidad de impresión, coste, ruido y además, algunas tecnologías son inapropiadas para ciertos tipos de medios físicos (como papel carbón o transparencias).

Otro aspecto de la tecnología de impresión que es frecuentemente olvidado es la resistencia a la alteración: la tinta líquida como de una cabeza de inyección de tinta es absorbida por las fibras del papel, y por eso los documentos impresos con tinta líquida son más difíciles de alterar que los que están impresos por tóner o tinta sólida, que no penetran por debajo de la superficie del papel.

Las impresoras láser e impresoras térmicas utilizan este método para adherir tóner al medio. Trabajan utilizando el principio de la "xerografía" que está funcionando en la mayoría de las fotocopiadoras: adhiriendo tóner a un tambor de impresión sensible a la luz, y utilizando electricidad estática para transferir el tóner al medio de impresión al cual se une gracias al calor y la presión.

Las impresoras láser son conocidas por su impresión de alta calidad, buena velocidad de impresión y su bajo costo por copia; son las impresoras más comunes para muchas de las aplicaciones de oficina de propósito general. Son menos utilizadas por el consumidor, generalmente debido a su alto coste inicial. Las impresoras láser están disponibles tanto en color como en monocromo.

El advenimiento de láseres de precisión a precio razonable ha hecho a la impresora monocromática basada en tóner dominante en aplicaciones para la oficina.
Otro tipo de impresora basada en tóner es la impresora led la cual utiliza una colección de ledes en lugar de láser para causar la adhesión del tóner al tambor de impresión.
El tóner (del inglés, "toner"), también denominado tinta seca por analogía funcional con la tinta, es un polvo fino, normalmente de color negro, que se deposita en el papel que se pretende imprimir por medio de atracción electrostática.

Una vez adherido el pigmento, este se fija en el papel por medio de presión o calor adecuados.
Debido a que en el proceso no intervienen diluyentes, originalmente se ha denominado xerografía, del griego "xeros" que significa seco.

Las impresoras de inyección de tinta ("Ink Jet") rocían hacia el medio cantidades muy pequeñas de tinta, usualmente unos picolitros. Para aplicaciones de color, incluyendo impresión de fotos, los métodos de chorro de tinta son los dominantes, ya que las impresoras de alta calidad son poco costosas de producir. Virtualmente todas las impresoras de inyección son dispositivos en color; algunas, conocidas como impresoras fotográficas, incluyen pigmentos extra para una mejor reproducción de la gama de colores necesaria para la impresión de fotografías de alta calidad (y son adicionalmente capaces de imprimir en papel fotográfico, en contraposición al papel normal de oficina).

Las impresoras de inyección de tinta consisten en inyectores que producen burbujas muy pequeñas de tinta que se convierten en pequeñísimas gotitas de tinta. Los puntos formados son el tamaño de los pequeños pixeles. Las impresoras de inyección pueden imprimir textos y gráficos de alta calidad de manera casi silenciosa.

Existen dos métodos para inyectar la tinta:

Las impresoras de inyección tienen un coste inicial mucho menor que las impresoras láser, pero tienen un coste por copia mucho mayor, ya que la tinta necesita ser repuesta frecuentemente. Las impresoras de inyección son también más lentas que las impresoras láser, además de tener la desventaja de dejar secar las páginas antes de poder ser manipuladas agresivamente; la manipulación prematura puede causar que la tinta (que está adherida a la página en forma líquida) se mueva.

Las impresoras de tinta sólida, también llamadas de cambio de fase, son un tipo de impresora de transferencia térmica pero utiliza barras sólidas de tinta en color CMYK (similar en consistencia a la cera de las velas). La tinta se derrite y alimenta una cabeza de impresión operada por un cristal piezoeléctrico (por ejemplo cuarzo). La cabeza distribuye la tinta en un tambor engrasado. El papel entonces pasa sobre el tambor al tiempo que la imagen se transfiere al papel.

Son comúnmente utilizadas como impresoras en color en las oficinas, ya que son excelentes imprimiendo transparencias y otros medios no porosos, y pueden conseguir grandes resultados. Los costes de adquisición y utilización son similares a las impresoras láser.

Las desventajas de esta tecnología son el alto consumo energético y los largos periodos de espera ("calentamiento") de la máquina. También hay algunos usuarios que se quejan de que la escritura es difícil sobre las impresiones de tinta sólida (la cera tiende a repeler la tinta de los bolígrafos), y son difíciles de alimentar de papel automáticamente, aunque estos rasgos han sido significantemente reducidos en los últimos modelos. Además, este tipo de impresora solo se puede obtener de un único fabricante, Xerox, como parte de su línea de impresoras de oficina Xerox Phaser. Previamente las impresoras de tinta sólida fueron fabricadas por Tektronix, pero vendió su división de impresión a Xerox en el año 2000.

Las impresoras de impacto o impresoras de golpe se basan en la fuerza de impacto para transferir tinta al medio, de forma similar a las máquinas de escribir, están generalmente limitadas a reproducir texto. En su momento dominaron la impresión de calidad. Hay dos tipos principales:

Las impresoras de impacto trabajan con un cabezal en el que hay agujas, estas agujas golpean una cinta, similar al de una máquina de escribir, que genera la impresión de la letra.

En el sentido general, muchas impresoras se basan en una matriz de muchos píxeles o puntos que, juntos, forman la imagen más grande. Sin embargo, el término matriz o de puntos se usa específicamente para las impresoras de impacto que utilizan una matriz de pequeños alfileres para crear puntos precisos. Dichas impresoras son conocidas como matriciales. La ventaja de la matriz de puntos sobre otras impresoras de impacto es que estas pueden producir imágenes gráficas además de texto. Sin embargo, el texto es generalmente de calidad más pobre que las impresoras basadas en impacto de tipos.

Algunas sub-clasificaciones de impresoras de matriz de puntos son las impresoras de alambre balístico y las impresoras de energía almacenada.

Las impresoras de matriz de puntos pueden estar basadas bien en caracteres o bien en líneas, refiriéndose a la configuración de la cabeza de impresión.

Las impresoras de matriz de puntos son todavía de uso común para aplicaciones de bajo costo y baja calidad como las cajas registradoras. El hecho de que usen el método de impresión de impacto les permite ser usadas para la impresión de documentos autocopiativos como los recibos de tarjetas de crédito, donde otros métodos de impresión no pueden utilizar este tipo de papel. Las impresoras de matriz de puntos han sido superadas para el uso general en computación.

Las impresoras de sublimación de tinta emplean un proceso de impresión que utiliza calor para transferir tinta a medios como tarjetas de plástico, papel o lienzos. El proceso consiste usualmente en poner un color cada vez utilizando una cinta que tiene paneles de color. Estas impresoras están principalmente pensadas para aplicaciones de color de alta calidad, incluyendo fotografía en color, y son menos recomendables para texto. Primeramente utilizadas en las copisterías, cada vez más se están dirigiendo a los consumidores de impresoras fotográficas.

Las impresoras térmicas se basan en una serie de agujas calientes que recorren el papel termosensible que al contacto se vuelve de color negro. Por su bajo coste, son muy usadas en los cajeros automáticos y supermercados.

Las impresoras llevan consigo memoria interna. Van desde los 6 KB en las impresoras matriciales hasta como mínimo 2 MB en las impresoras láser.

Actualmente en las láser venden módulos de memoria independientes para ampliar la capacidad de la misma.

La memoria se usa como búfer y como almacenamiento permanente y semipermanente. Además su uso es necesario porque el tratamiento de gráficos vectoriales y el diseño de fuentes en mapa de bits consumen memoria.

El búfer es utilizado para mantener trabajos de impresión activos y la permanencia se utiliza para almacenar el diseño de las fuentes y los datos.

Hay que tener en cuenta que para tratar la impresión de un documento la página tiene que estar enteramente almacenada en memoria.
El rendimiento de la memoria depende tanto del sistema operativo como de la configuración del controlador de impresora.

Por ejemplo, la gestión de impresión varía si estamos en un sistema operativo DOS u otro multiplataforma.

La conexión de la impresora con el computador ha ido evolucionando conllevando a la mejora de rendimiento de impresión y comodidad de usuario.

La forma más antigua de conexión era mediante puerto serie en donde la transferencia se hacía bit a bit, permitía distancias largas con velocidades lentas que no superaban los 19 200 bytes/segundo.

Se elevó hasta la conexión mediante puerto paralelo en la que las transferencias eran byte a byte permitiendo 8 conexiones paralelas consiguiendo una velocidad más rápida entre los ½ MB/segundo hasta los 4 MB/segundo. El inconveniente era la limitación de la distancia del cable que une la impresora con el computador ya que no permite una longitud mayor de 2 metros.

Otra forma de conexión se consiguió poniendo la impresora en red Ethernet mediante conexiones RJ-45 basadas en el estándar IEEE 802.3.
Las velocidades conseguidas superan los 10 Mb/segundo basada en el manejo de paquetes.
No hay que confundirla con una impresora compartida, ya que las impresoras en red operan como un elemento de red con dirección IP propia.

Otro método de conexión más actual es por medio de puertos USB ("Universal Serial Bus"). La velocidad vuelve a mejorar con 480Mb/segundo con las ventajas que conlleva el puerto USB: compatibilidad con varios sistemas y la posibilidad de usarla en dispositivos portátiles.

Finalmente, la conexión inalámbrica Wi-Fi, mediante el protocolo IEEE 802.11, está siendo la más novedosa. Alcanza 300 Mb/segundo y funciona tanto para impresoras de tinta, láser o multifunción.

Aunque consigue menos velocidad que las conectadas por USB, las wifi proporcionan ventajas tales como la autonomía, la movilidad y libertad del usuario sin la utilización de cables. Para la correcta utilización y evitar accesos no deseados deberemos cifrar la red.

Un “lenguaje de descripción de página” (PDL) es un medio de codificar cada elemento de un documento para poder así transmitirlo a la impresora para que esta lo imprima. Es el medio que define las características y composición que describirían un documento impreso dentro de un flujo de datos. Hay varios tipos de PDL:

Fue creado por Apple para no depender tecnológicamente de los tipos PostScript de Adobe, pero su calidad resultó ser inferior. Fue comprada por Microsoft lo cual ha contribuido a que no llegara a desaparecer. La principal fortaleza de "TrueType" es que ofrece a los diseñadores de fuentes un gran grado de control sobre la forma que sus fuentes se muestran a diferentes tamaños.

El problema con la mayoría de los programas es que no usan normalmente el truetype. En general cargan las fuentes en estilo Postscript y se descartan todas las insinuaciones; esto es una gran pérdida para fuentes con alta calidad. Aparte del diseño de la fuente, hay que tener en cuenta otras dos claves para la calidad de fuente: el perfil del carácter y la insinuación. Solo algunas fundiciones actualmente producen fuentes que exploten al máximo el potencial de insinuación de truetype. Ahora hay aplicaciones que convierten un Type 1 de Postscript en un truetype, pero son los manuscritos mejores que los generados automáticamente.

Los plóteres sirven para hacer impresiones de dibujo de planos de arquitectura, ingeniería, diseño industrial, etc., para la impresión de láminas, pósteres, ampliaciones fotográficas, gigantografías, carteles en rutas, vía pública, señalización, etc. Existen dos clases de plóter según el uso de sus tintas, a base de agua o disolventes. Un caso particular es el plóter de corte, que corta un medio adhesivo que luego se fijará a otra superficie, desde camisetas a carrocerías.

Existen dispositivos como celulares, que se utilizan en casas de revelado fotográfico o en el hogar. Estos dispositivos suelen ser conocidos como impresora fotográfica, impresora con calidad fotográfica o bases de impresión fotográfica. Estos dispositivos imprimen en color, produciendo imágenes que imitan el rango de colores y resoluciones de los métodos de revelado fotográfico previos a esta tecnología.

A menudo se utiliza el modelo comercial de las maquinillas y las cuchillas de afeitar en el negocio de las impresoras. Las compañías pueden vender una impresora por debajo de su coste, y obtener beneficios de los cartuchos de tinta, papel u otras partes que se reemplazan. Esto ha causado disputas legales respecto al derecho de otras compañías distintas al fabricante de la impresora de vender cartuchos de tinta compatibles o alternativos. Para proteger al modelo comercial de las maquinillas y las cuchillas de afeitar muchos fabricantes invierten considerables sumas en desarrollo de nuevas tecnologías y sus patentes.

Otros fabricantes, en reacción a los desafíos que trae este modelo comercial, apuntan a obtener mayores beneficios de las impresoras y menos de los cartuchos de tinta, promoviendo los menores precios de los cartuchos a través de campañas de publicidad. Esto genera dos propuestas bien diferentes: "impresora barata - tinta cara" o "impresora cara - tinta barata". Finalmente, la decisión del consumidor depende de su tasa de interés de referencia o su preferencia intertemporal.

Tanto los cartuchos, como la tinta y el papel son 3 elementos imprescindibles para poder realizar copias con una impresora, y el saber escoger el elemento más adecuado en función del tipo de impresión que se pretende realizar puede aumentar el rendimiento de nuestra impresora hasta límites insospechados.

En el caso de las impresoras láser, la vida útil del cartucho depende de la cantidad de tóner que contenga y cuando el tóner se agota, el cartucho debe ser reemplazado. En el caso de que el cartucho y el OPC (órgano sensible fotoconductivo) se encuentren en compartimentos separados, cuando se agota el tóner solo se reemplaza el cartucho, pero en el caso de que el OPC esté dentro del cartucho se deben cambiar ambos, aumentando considerablemente el gasto. La situación es más crítica en el caso de las impresoras láser en color.

En las impresoras de chorro de tinta la vida útil del cartucho depende de la duración de la tinta, aunque muchos cartuchos se pueden rellenar de nuevo, lo que ayuda a reducir el gasto de comprar uno nuevo aunque el uso excesivo de un cartucho puede provocar que realice sus impresiones con menor calidad.

Existen dos tipos de tinta para impresoras:

El objetivo de todo fabricante de tintas para impresoras es que sus tintas puedan imprimir sobre cualquier medio y para ello desarrollan casi diariamente nuevos tipos de tinta con composiciones químicas diferentes.

Actualmente, cuando se quiere hacer una copia de alta calidad en una impresora se ha de usar papel satinado de alta calidad. Este papel resulta bastante caro y en el caso de querer hacer muchas copias en calidad fotográfica su costo sería muy alto. Por ello, los fabricantes desarrollan nuevas impresoras que permitan obtener impresiones de alta calidad sobre papel común.

Algunos fabricantes, como por ejemplo Epson, fabrican su propio papel.

Si no se tiene cuidado a la hora de seleccionar el tipo de papel adecuado para la impresora o en el momento de colocar el papel pueden aparecer pequeños problemas. Puede que la mala colocación del papel de lugar a que la impresora no detecte el papel, para lo que bastará con volver a colocarlo bien. Esta mala colocación o una mala elección del papel también puede dar lugar a que durante la impresión se produzca un atasco debido a que la impresora ha tomado varias hojas a la vez, por lo que se debe ser cuidadoso a la hora de situar el papel en la bandeja y no se debe sobrecargar con mucho papel esta bandeja.

En ocasiones al imprimir documentos o fotografías pueden aparecer bandas horizontales que hacen empeorar la calidad de la impresión. Aunque este problema puede estar ocasionalmente relacionado con una mala elección del papel de impresión generalmente se debe a problemas de tinta en impresiones de inyección de tinta. Una causa posible es la configuración de calidad de la impresión, puesto que el documento puede requerir una configuración de mayor calidad de la impresora. Otras posibles causas pueden ser que la tinta del cartucho se está agotando o que los cabezales están sucios.

Algunas otras clases de impresoras son importantes por razones históricas o para usos especiales, entre ellas están las siguientes:




</doc>
<doc id="1470" url="https://es.wikipedia.org/wiki?curid=1470" title="Iridio">
Iridio

El iridio es un elemento químico de número atómico 77 que se sitúa en el grupo 9 de la tabla periódica. Su símbolo es Ir. Se trata de un metal de transición, del grupo del platino, duro, frágil, pesado, de color blanco plateado. Es el segundo elemento más denso (después del osmio) y es el elemento más resistente a la corrosión, incluso a temperaturas tan altas como 2000 °C. Solo algunos halógenos y sales fundidas son corrosivas para el iridio en estado sólido. El iridio en polvo es mucho más reactivo y puede llegar a ser inflamable.

Fue descubierto en 1803 entre las impurezas insolubles del platino natural. Smithson Tennant, el primer descubridor, llamó al metal iridio en honor a la diosa Iris, la personificación del arcoíris, debido a los diversos y llamativos colores de sus sales. El iridio es uno de los elementos más raros en la corteza terrestre, con una extracción y consumo anual de tan solo tres toneladas. El Ir y el Ir son los dos isótopos naturales del iridio y también sus únicos isótopos estables; el Ir es el más abundante de los dos.

Los compuestos de iridio más importantes son las sales y ácidos que forma junto con el cloro, aunque el iridio también forma una serie de compuestos organometálicos, utilizados en la catálisis industrial y en investigación. El iridio metálico es usado cuando se necesita alta resistencia a la corrosión a altas temperaturas, como en las bujías de gama alta, crisoles para la recristalización de los semiconductores a altas temperaturas, y los electrodos para la producción de cloro mediante el proceso de cloro-álcali. Los radioisótopos de iridio se usan en algunos generadores de radioisótopos.

La abundancia inusual de iridio en la capa de arcilla en el límite geológico K-T dio lugar a la hipótesis de Álvarez del impacto de un objeto supermasivo extraterrestre, el cual habría sido la causa de la extinción de los dinosaurios y muchas otras especies hace 65 millones de años. El iridio se encuentra en meteoritos en una abundancia muchísimo más alta que en la corteza terrestre. Se cree que la cantidad total de iridio en el planeta Tierra es mucho mayor que la observada en las rocas de la corteza, pero, como con otros metales del grupo del platino, la alta densidad y la tendencia del iridio para unirse con el hierro, el osmio y el níquel, causa que la mayoría del iridio haya descendido debajo de la corteza, pasando este metal a formar parte de su núcleo cuando el planeta aún era joven y todavía estaba en estado fundido.

El iridio también se emplea en aleaciones de alta resistencia que pueden soportar altas temperaturas. Es un elemento poco abundante y se encuentra en la naturaleza en aleaciones con platino y osmio. Se emplea en contactos eléctricos, aparatos que trabajan a altas temperaturas, y como agente endurecedor del platino.

Es de color blanco, parecido al platino, pero presenta una ligera coloración amarilla. Es difícil trabajar este metal, pues es muy duro y quebradizo. Es el metal más resistente a la corrosión. No es atacado por los ácidos, ni siquiera por el agua regia. Para disolverlo se emplea ácido clorhídrico, HCl, concentrado con clorato de sodio, NaClO a temperaturas altas.

El iridio es considerado comúnmente un metal extraterrestre, ya que abunda en los meteoritos y es raro en la corteza terrestre, con solo una pequeña concentración de 0,001 ppm. Es el metal más denso después del osmio. Se sabe que en el núcleo de la Tierra es precisamente este metal el que acompaña al hierro y al níquel, sus componentes más importantes.

Pertenece al grupo del platino. Debido a su dureza, fragilidad y su alto punto de fusión (el noveno más alto de todos los elementos), es difícil dar forma o trabajar sobre el iridio sólido como se haría con otros metales, por lo que se prefiere trabajarlo en forma de polvo metálico. Es el único metal que mantiene buenas propiedades mecánicas por encima de los 1600 °C. El iridio tiene un punto de ebullición muy alto (el décimo entre todos los elementos) y se convierte en superconductor a temperaturas debajo de los 0.14 K.

El módulo de elasticidad del iridio es el segundo más alto de todos los elementos, superado únicamente por el del osmio; esto, junto con un alto módulo de rigidez y un bajo coeficiente de Poisson, indica el alto grado de rigidez y resistencia a la deformación que han hecho que su manipulación sea una cuestión de gran dificultad. A pesar de estas limitaciones y del alto costo del iridio, es muy valioso para aplicaciones donde la resistencia mecánica es un factor esencial y se usa en algunas tecnologías modernas que operan en condiciones extremas.

La densidad medida del iridio es ligeramente inferior (0,1%) a la del osmio, el cual es el elemento más denso conocido. Anteriormente existía una ambigüedad respecto a qué elemento era más denso, debido a la pequeña diferencia de densidades entre estos dos elementos y la dificultad para medir con precisión dicha diferencia. Con la mayor precisión en los factores utilizados para calcular la densidad cristalográfica mediante rayos X se pudieron calcular sus densidades como 22,56 g/cm para el iridio y 22,59 g/cm para el osmio.

El iridio es el metal más resistente a la corrosión conocido: no es atacado por casi ningún ácido, el aqua regia(aunque si pulverizado), metales fundidos o silicatos a altas temperaturas. Puede, sin embargo, ser atacado por algunas sales fundidas, tales como el cianuro sódico y cianuro potásico, como también por el oxígeno y los halógenos (particularmente el flúor) a altas temperaturas.

El iridio forma compuesto en estados de oxidación entre -3 hasta +6, los más comunes son +3 y +4. Los estados de oxidación mayores son poco comunes, pero incluyen al IrF6 y a dos óxidos mixtos, el SrMgIrO y el SrCaIrO. El dióxido de iridio, un polvo marrón, es el único óxido de iridio bien caracterizado, un sesquióxido de iridio, el IrO, ha sido descrito como un polvo de color azul-negro el cual se oxida a IrO por exposición al HNO. También se han encontrado compuestos de iridio y Azufre, como el IrS. El iridio también forma compuestos con estados de oxidación +4 y +5, como KIrO y KIrO, que puede ser preparado a partir de la reacción del óxido de potasio o del superóxido de potasio con iridio a altas temperaturas.
Actualmente no se conocen hidruros binarios de iridio (IrH), pero se conocen hidruros complejos como el IrH
de iridio con todos los hálogenos. Para estados de oxidación +4 y superiores, únicamente se conocen el tetrafluoruro, el pentafluoruro y el hexafluoruro. El hexafluoruro de iridio, es un sólido amarillo volátil y altamente reactivo, compuesto de moléculas octaédricas. Se descompone en agua y se reduce a IrF, un sólido cristalino de iridio negro. El pentafluoruro de iridio tiene propiedades similares pero en realidad es un tetrámero, IrF, formado por cuatro octaedros que comparten esquinas.

El HIrC, y su sal amónica son los compuestos de iridio más importantes desde el punto de vista industrial. Estos compuestos están involucrados en la purificación de iridio y se utilizan como precursores para la mayoría de los otros compuestos de iridio, así como en la preparación de recubrimientos para ánodos. El ion IrCl tiene un intenso color marrón oscuro, y puede ser fácilmente reducido a IrCl, de un color más claro, y viceversa. El tricloruro de iridio (IrCl), que se puede obtener en forma anhidra de la oxidación directa del polvo de iridio mediante cloro a 650 °C, o en forma hidratada mediante la disolución de IrO en ácido clorhídrico, es a menudo utilizado como materia prima para la síntesis de otros compuestos de Ir(III). Otro compuesto que se utilizan para sintetizar otros compuestos de Ir(III) son el hexacloroiridio de amonio ((NH)IrC). Los compuesto de Ir(III) son diamagneticos con una geometría molecular octaédrica.

Los compuestos organoiridicos contienen enlaces iridio-carbono, donde por lo general, el metal se encuentra en los estados de oxidación más bajos, por ejemplo, el estado de oxidación 0 se encuentra en el tetrairidio dodecarbolino (Ir(CO)), el cual es el más común y estable carbonilo binario de iridio, en este compuesto, cada uno de los átomos de iridio se enlaza a los otros tres, formando así una estructura tetraédrica. Algunos compuestos organometálicos de Ir(I) so lo suficientemente importantes como para llevar el nombre de sus descubridores. Uno de ellos es el complejo de Vaska (IrCl(CO)[P(CH)]), el cual tiene la rara cualidad de unirse a la molécula de oxígeno diatómico (O). Otra es la catálisis de Crabtree, una catálisis homogénea llevada a cabo mediante reacciones de hidrogenación. Estos compuestos tienen una estructura cuaternaria planar, d compleja, con un total de 16 electrones de valencia, lo que explica su capacidad de reacción.

El iridio tiene dos isotopos naturales estables, el Ir y el Ir, con una abundancia natural de 37.3% y 62.7%, respectivamente. Al menos 34 radioisótopos han sido sintetizados variando entre números másicos de 164 a 199. El Ir, el cual se desintegra en los dos isótopos estables, es el radioisótopo más estable con una vida media de 73.827 días. Otros tres isótopos, el Ir, Ir, Ir, tienen una vida media de al menos un día. Isótopos con número de masa debajo de 191 decaen mediante una combinación de desintegración ß, desintegración α y emisión de protones, con la excepción del Ir, que decae por medio de captura electrónica, y el Ir, el cual decae por medio de emisión de positrones. Isótopos sintéticos con una masa atómica mayor a 191 decaen mediante desintegración β, aunque el Ir también puede decaer en menor medida mediante captura de electrones. Todos los isotopos conocidos de iridio fueron descubiertos entre 1934 y 2001, el más reciente de ellos es el Ir.

Al menos 32 isómeros metaestables han sido caracterizados, variando en masa atómica entre 164 a 197, el más estable de todos estos es el Ir, el cual decae mediante transición isomérica con una vida media de 241 años, por lo que es más estable que cualquiera de los isótopos sintéticos de iridio en sus estados fundamentales. El menos estable es el Ir, con una vida media de apenas 2 µs. El isótopo Ir fue el primer elemento en que se vio el efecto Mößbauer, lo que lo hace útil para la espectroscopia Mössbauer en investigaciones físicas, químicas, bioquímicas, metalúrgicas y mineralogicas.

El descubrimiento del iridio data de la misma época en que se descubrió el platino y el resto de metales de su grupo. El platino elemental fue usado por los antiguos etíopes y por las culturas sudamericanas, las cuales siempre tuvieron acceso a una pequeña cantidad de metales del grupo del platino, incluyendo el iridio. El platino llegó a Europa con el nombre de "platina" (pequeña plata), descubierto en el siglo XVII por españoles en la región que hoy se conoce como Departamento de Chocó en Colombia. Pero el descubrimiento de que este metal era un elemento nuevo y no una aleación de elemento conocidos no se produjo hasta 1748.

Los químicos que estudiaron el platino encontraron que este se disolvía en aqua regia, creando sales solubles. Estos químicos siempre notaban una pequeña cantidad de un residuo de color oscuro insoluble. Joseph Louis Proust pensó que este residuo se debía a grafito. Los químicos franceses Victor Collet-Descotils, Antoine François, el conde de Fourcroy, y Louis Nicolas Vauquelin también observaron el residuo oscuro en 1803, sin embargo, no obtuvieron suficiente como para realizar experimentos. Ese mismo año un científico británico, Smithson Tennant analizó el residuo insoluble y concluyó que este debía de contener un nuevo metal. Vauquelin expuso el residuo en polvo a álcalis y ácidos y obtuvo un nuevo óxido volátil, el cual él creía que se trataba del nuevo metal que llamó "ptene", que provenía de la palabra griega πτηνος (ptènos) y significaba "Alado". Tennant, que contaba con una cantidad mucho más grande del residuo, continuó su investigación e identificó dos nuevos elementos dentro del residuo negro, el iridio y el osmio. Obtuvo cristales de color rojo oscuro (probablemente de Na[IrCl]•nHO)por una serie de reacciones con hidróxido de sodio y ácido clorhídrico. Llamó a uno de los elemento iridio en honor a la diosa griega Iris, debido a los colores de sus sales. El descubrimiento de los nuevos elementos fue documentado en una carta a la Royal Society el 21 de junio de 1804.

El científico británico John George Children fue el primero en fundir una muestra de iridio en 1813 con la ayuda de la "mejor batería galvánica que jamás se haya construido" (hasta esa época).

El primero en obtener iridio puro fue Robert Hare en 1842. Encontró que la densidad del iridio rondaba los 21.8 g/cm y noto que el metal no era maleable y era extremadamente duro.

La primera fundición de una cantidad significativa del metal fue realizada por Henri Sainte-Claire Deville y Jules Henri Debray en 1860. Para fundir el metal, se necesitó más de 300 litros de O puro y H por cada kilogramo de iridio. Estas dificultades extremas para fundir el metal han limitado las posibilidades de manejar el iridio.

John Isaac Hawkins estaba buscando obtener una pluma con una punto fina y dura, y en 1834 logró crear una pluma de oro con punta de iridio.

En 1880, Jhon Holland y William Lofland Dudley, lograron fundir iridio añadiendo fósforo, más tarde patentarían el proceso en los Estados Unidos. La compañía británica Johnson Matthey indicó más adelante que había estado utilizando un proceso similar desde 1837 y ya había presentado iridio fundido en una serie de ferias por todo el mundo. El primer uso de una aleación de iridio con rutenio fue realizada para fabricar termopares por Otto Feussner en 1933. Esto permitió medir temperaturas en el aire de hasta 2000 °C.

En 1957 Rudolf Ludwig Mößbauer, descubrió el efecto de la resonancia y retroceso-libre y absorción de rayos gamma en átomos de una muestra de sólido que únicamente contenía Ir. Por este fenómeno, conocido como el Efecto Mößbauer (que desde entonces se ha observado en otros núcleos como el del Fe), Mößbauer recibió el premio nobel de física en el año de 1961, solo tres años después de publicar su descubrimiento

El iridio es uno de los elementos menos abundantes en la corteza terrestre, en promedio solo se encuentra una fracción de masa de 0.001 ppm en toda la corteza; el oro es 40 veces más abundante, el platino 10 veces más, y la plata y el Mercurio unas 80 veces más abundantes que el iridio. El telurio es tan abundante como el iridio. Únicamente existen tres elementos tan poco abundantes como el iridio: el renio, el rutenio y el rodio; el iridio es 10 veces más abundante que los últimos dos. En contraste con su escasa abundancia en la corteza terrestre, el iridio es relativamente común en los meteoritos, con una concentración de 0,5 ppm o más.

El iridio se puede encontrar en la naturaleza como un elemento sin combinar o en aleaciones naturales, especialmente las aleaciones de osmio-iridio, estas aleaciones se pueden separar en dos grandes grupos: las aleaciones osmiridio, las cuales son más ricas en osmio, y las iridiosmio que contienen una mayor cantidad de iridio que de osmio. También se encuentra en los depósitos de níquel y cobre, normalmente se encuentran metales del grupo del platino en estos yacimientos en forma de sulfuros, telururos, antimoniuros, y arseniuros. Dentro de la corteza terrestre, el iridio se encuentra en concentraciones más altas en tres tipos de estructura geológica: los depósitos ígneos, los cráteres de impacto, y depósitos elaborados a partir de una de estas estructuras. La reserva primaria de iridio más grande conocida es la del complejo ígneo Bushveld en Sudáfrica, aunque los grandes depósitos de cobre-níquel cerca de Norilsk, en Rusia, y la cuenca de Sudbury en Canadá también son importantes fuentes de iridio. Pequeñas reservas de este metal también han sido encontradas en los Estados Unidos. El iridio puede encontrarse en depósitos secundarios, combinado con el platino u otros metales del grupo del platino en depósitos aluviales. Este tipo de depósitos fueron explotados por las culturas precolombinas en el departamento del chocó, aún hoy en día siguen siendo una fuente de metales del grupo del platino.

El límite K-T de 65 millones de años, marca la frontera temporal entre los períodos Cretácico y el Cenozoico del tiempo geológico, fue identificado debido a una delgada capa de arcilla rica en iridio, la cantidad de esta capa de iridio podría contener 200.000 toneladas de ese metal. En 1980, un equipo liderado por Luis Walter Álvarez, propuso un origen extraterrestre para todo este iridio encontrado en la capa; lo atribuyó a un impacto de asteroide o de un cometa. Esta teoría, conocida como la hipótesis Álvarez, es la más aceptada para explicar la extinción de los dinosaurios. Un gran cráter de impacto enterrado que data de hace 65 millones de años fue identificado en lo que hoy se conoce como la península de Yucatán (el cráter de Chicxulub). Dewey M. McLean y otros científicos argumentan que ese iridio podría tener orígenes volcánicos debido a que el núcleo de la tierra es rica en iridio, y aún hoy, volcanes activos como el Piton de la Fournaise ("pico del horno") en la isla de Reunión siguen liberando iridio.

El iridio se obtiene comercialmente como un subproducto de la minería y producción de níquel y cobre. Mediante la electrorrefinación del cobre y el níquel, metales nobles como la plata, el oro y los metales del grupo del platino, así como el selenio y el telurio se depositan en el fondo de la celda como barro anódico, el cual constituye el punto de partida para su extracción. Con el fin de separar los metales, lo primero que debe hacerse es disolver el barro en una solución. Existen varios métodos, dependiendo del proceso de separación y la composición de la mezcla. Dos métodos muy usados son fundir con peróxido de sodio y luego disolver en aqua regia, el otro consiste en disolver en una mezcla de cloro y ácido clorhídrico.

Después de que se disuelva, el iridio se separa de otros metales del grupo platino por la precipitación de (NH)IrCl o mediante la extracción de IrCl con aminas orgánicas. El primer método es similar al procedimiento de Tennant y Wollaston utilizado para su separación. El segundo método se puede planificar como una continua extracción líquido-líquido y por lo tanto más adecuada para la producción a escala industrial. En cualquier caso, el producto se reduce mediante el uso de hidrógeno, produciendo el metal en forma de polvo o esponja que se puede tratar con técnicas de metalurgia de polvos.

La producción anual de iridio en el año 2000 fue de alrededor de 3 toneladas, lo que equivale a aproximadamente 100.000 onzas troy (ozt). El precio del iridio alcanzó en 2007 un precio de 440 dólares por onza troy, pero el precio ha fluctuado considerablemente, como se muestra en la tabla, en el año 2010 el precio se elevó a más 750 USD/ozt, sin embargo, en promedio se ha mantenido en el rango de los años 2007-2009, es decir, de $425–$460 USD/ozt. La alta volatilidad en los precios de los metales pertenecientes al grupo del platino se ha atribuido a la oferta, demanda, la especulación y acaparamiento, amplificada por el pequeño tamaño del mercado y la inestabilidad de los países productores.

El alto punto de fusión, la dureza y resistencia a la corrosión del iridio y sus aleaciones determinan la mayoría de sus aplicaciones. El iridio y especialmente las aleaciones iridio-platino u osmio-iridio tienden a desgastarse muy poco y son usadas, por ejemplo, en múltiples hileras de poros, a través de las cuales un plástico fundido se extruye para formar fibras, como el rayón. Las aleaciones de osmio-iridio son usadas en brújulas y balanzas.

La resistencia a la corrosión y al calor hacen del iridio un agente de aleación importante. Algunas piezas de larga duración en motores de avión están hechas de iridio aleado y en tuberías para aguas profundas se usa una aleación especial de titanio-iridio debido a su resistencia a la corrosión. El iridio también es ampliamente utilizado como agente endurecedor en aleaciones de platino. La dureza Vickers del platino puro es de 56 HV, mientras que la de una aleación con 50% de iridio puede alcanzar durezas por encima de los 500 HV.

A menudo, dispositivos que están expuestos a temperaturas extremas se hacen de iridio, por ejemplo, crisoles de alta temperatura hechos de iridio se utilizan en el proceso Czochralski para producir óxido de monocristales (como zafiros) para usar en dispositivos de memoria en computadoras y en láseres de estado sólido. La gran resistencia a la abrasión del iridio y sus aleaciones lo hacen ideal para fabricar los contactos eléctricos en bujías.

Compuestos de iridio se utilizan como catalizadores en el proceso Cativa para la carbonilación del metanol para producir ácido acético El iridio en sí mismo es usado como catalizador en un tipo de motor para automóvil introducido en 1996 llamado motor de ignición directa. El radioisótopo Ir es una de los dos fuentes de energía más importantes para uso industrial de la radiografía de rayos γ en los ensayos no destructivos para metales. Además, Ir se utiliza como una fuente de radiación gamma para el tratamiento del cáncer mediante braquiterapia, una forma de radioterapia donde se coloca una fuente radiactiva sellada en el interior o junto a la zona que requiere tratamiento.

En 1889 se usó una aleación de 90% de platino y 10% de iridio para construir el prototipo internacional de metro y kilogramo realizado por la oficina internacional de pesas y medidas cerca a París. La definición de la barra de metro fue reemplazada de la unidad fundamental de medición en 1960 por una línea del espectro atómico del kriptón, pero el prototipo de kilogramo sigue siendo el estándar internacional de masa. El iridio ha sido utilizado en los generadores termoeléctricos de radioisótopos de naves espaciales no tripuladas, como el Voyager, Viking, Pioneer, Cassini, Galileo y en la nave New Horizons. El iridio fue escogido para encapsular el combustible de plutonio-238 en el generador debido a la gran resistencia del material y sus capacidades operativas por encima de los 2000 °C. También se utiliza este metal para generar Rayos X ópticos, en especial en telescopios de rayos X. Los espejos del observatorio de rayos X Chandra están recubiertos con una capa de iridio 60 nm de espesor. El iridio demostró ser la mejor opción para reflejar rayos X, superando a metales como el níquel, el oro, el platino. La capa de iridio, la cual tuvo que ser del espesor de apenas unos cuantos átomos, fue aplicada mediante alto vacío depositando iridio gaseoso en una capa base de cromo.

El iridio se usa en la física de partículas para la producción de antiprotones, una forma de antimateria. Los antiprotones se producen al disparar un haz de protones de alta intensidad a un "objetivo de conversión", que debe ser hecho de un material extremadamente denso. A pesar de que el tungsteno se puede utilizar en lugar del iridio, este último tiene la ventaja de que posee una mejor estabilidad bajo las ondas de choque inducidas por el aumento de la temperatura durante el rayo incidente. Complejos de iridio están siendo investigados como catalizadores para hidrogenación asimétrica. Estos catalizadores se han utilizado en la síntesis de productos naturales capaces de hidrogenar determinados sustratos difíciles, tales como alquenos, enantioselectivamente (la generación de sólo uno de los dos enantiómeros posibles). El iridio forma una variedad de complejos de interés fundamental en la recolección de tripletes.

Aleaciones de iridio-osmio se han usado en plumas estilográficas. El primer uso de una cantidad importante de iridio fue en el año de 1834 en una punta de iridio montada en oro. Desde 1944, la famosa pluma estilográfica "Parker 51" fue equipada con una punta de una aleación de rutenio e iridio (3.8% de iridio). Se han utilizado aleaciones de platino-iridio en los agujeros de ventilación de cañones; esta es una aplicación importante pues evita los gastos ocasionados por el desgaste de estos orificios cuando están en servicio. El pigmento ""iridio negro"", el cual consiste en iridio dividido muy finamente, se usa para colorear porcelanas de un color negro intenso.

El iridio en forma de metal no es peligroso para la salud debido a su poca reactividad con los tejidos, únicamente hay 20 partes por trillón de iridio en los tejidos humanos. Sin embargo, el polvo finamente dividido de iridio puede ser peligroso de manejar, ya que es irritante y puede inflamarse en el aire. Se sabe muy poco acerca de la toxicidad de los compuestos de iridio debido a la escasez del metal y a que sus compuestos se utilizan en cantidades muy pequeñas, pero las sales solubles, tales como los haluros de iridio, podrían ser peligrosos debido a los otros elementos que hacen parte del compuesto. Sin embargo, la gran mayoría de los compuestos de iridio son insolubles, lo que hace que la absorción involuntaria de estos compuestos por el cuerpo humano sea difícil. Un radioisótopo de iridio, el Ir, es peligroso al igual que cualquier otro isótopo radioactivo. Los únicos reportes relacionados con lesiones por iridio conciernen a la exposición accidental de Ir usado en braquiterapia. Las altas radiaciones de rayos gamma de alta energía por el Ir pueden incrementar el riesgo de cáncer. La exposición externa puede causar quemaduras, envenenamiento por radiación, y la muerte. La ingestión de Ir puede quemar el revestimiento del estómago y de los intestinos. Ir, Ir y Ir tienden a depositarse en el hígado, y puede plantear riesgos para la salud tanto por radiación gamma como por radiación beta.




</doc>
<doc id="1471" url="https://es.wikipedia.org/wiki?curid=1471" title="Intérprete de comandos">
Intérprete de comandos

Un intérprete de órdenes o de comandos, es un programa informático que tiene la capacidad de traducir las órdenes que introducen los usuarios, mediante un conjunto de instrucciones facilitadas por él mismo directamente al núcleo y al conjunto de herramientas que forman el sistema operativo. Las órdenes se introducen siguiendo la sintaxis incorporada por dicho intérprete, dentro del entorno proporcionado por el emulador de terminal, mediante un inductor que espera a que le sean introducidos los comandos o instrucciones codice_1

Al ingresar la orden con la tecla 'Intro', el intérprete analiza la secuencia de caracteres ingresada y, si la sintaxis de la orden es correcta, la ejecuta, recurriendo para ello a las funciones que ofrece el sistema operativo o el programa que representa, bien sea un gestor de datos de banco, una sesión de FTP, de ssh, etc. La respuesta al usuario se representa en el monitor o en forma de segundo plano. Se trabaja de manera interactiva, es decir, usuario y máquina se comunican de forma sucesiva.

Incorporan características tales como control de procesos, redirección de entrada/salida, listado y lectura de ficheros, protección, comunicaciones y un lenguaje de órdenes para escribir programas por lotes o (scripts o guiones). Uno de los intérpretes más conocidos, es el Bourne Shell, el cual fue el intérprete usado en las primeras versiones de Unix y se convirtió en un estándar de facto.



</doc>
<doc id="1473" url="https://es.wikipedia.org/wiki?curid=1473" title="Islas Baleares">
Islas Baleares

Las Islas Baleares (en catalán y oficialmente, "Illes Balears") son una comunidad autónoma uniprovincial española, compuesta por las islas del archipiélago balear. Se encuentran situadas en el mar Mediterráneo, frente a la costa oriental de la península ibérica. Su capital es Palma (también conocida como Palma de Mallorca).

El archipiélago está formado por dos grupos de islas y numerosos islotes: las islas Gimnesias (Mallorca, Menorca, Cabrera y algunos islotes cercanos como Dragonera, Conejera o la isla del Aire) y las islas Pitiusas (Ibiza —en catalán y oficialmente Eivissa— y Formentera, junto los islotes que las rodean, como Espalmador —esta de propiedad privada— y Espardell).

La geografía del archipiélago de las Islas Baleares comprende Mallorca, Cabrera, Menorca, Ibiza y Formentera. En total el territorio tiene 4492km² y va desde el nivel del mar hasta los 1445m de altitud en el Puig Mayor de la Sierra de Tramontana de Mallorca. Las coordenadas geográficas están entre los 40º5'48' y 38º40'30' de latitud N y entre 1º12'47' y 4º19' de longitud E. Ibiza está separada de la costa de la Comunidad Valenciana por solo 75 km de mar, esta misma distancia separa Mallorca de Ibiza. La distancia mínima que separa Mallorca de Menorca es de 35 km.

La Prehistoria e historia antigua de las Islas Baleares precisa diferenciar entre las islas de Mallorca y Menorca y las de Ibiza y Formentera.

En las islas de Mallorca y Menorca, las primeras evidencias claras de población estable se remontan al Actualmente su prehistoria se divide en cinco fases sucesivas:


En el caso de Ibiza y Formentera la presencia de población estable es similar a la de las islas mayores pero en torno al (mediados del s. VII) aparece la presencia confirmada de asentamientos fenicios, probablemente procedentes de Gadir más que de Oriente en los asentamientos de Sa Caleta y Vila (Iboshim), convirtiendo así a la ciudad en la primera fundada del archipiélago y una de las primeras de España. Desde Iboshim un floreciente comercio unía las islas con todos los puntos del Mediterráneo, con productos importados o propios como la sal de Ibiza o la de Mallorca explotada por los iboshitanos desde los islotes de Na guardis o de Na Galera en Mallorca.

Los romanos conquistaron las islas de Mallorca y Menorca y se aliaron con Iboshim en torno al año , unificando por primera vez todo el archipiélago bajo una misma administración y una misma cultura (pues había una dicotomía del fondo étnico —que persiste actualmente en una diferencia insalvable de cultura— entre las Pitiusas, pobladas por fenicios, y las Gimnesias, con gentes pertenecientes a la cultura talayótica), aunque la colonización romana fue poco intensa. Incorporadas al principio a la Hispania Citerior, y posteriormente a la Tarraconensis, las islas formaron parte de la provincia Cartaginense durante el Bajo Imperio, y a finales del siglo IV se constituyeron en provincia independiente (Balearica).

En el año 406 la helada del Rin facilitó la entrada de pueblos germánicos (suevos, vándalos y alanos), que en el año 409 traspasaron los Pirineos para asentarse temporalmente en la Península. En el año 429 las islas Baleares fueron saqueadas junto a Cartagena, Sevilla y el resto de Hispania, según cuenta el historiador Hidacio. Después de ello cruzaron el estrecho fundando el Reino vándalo, incorporando las islas en el año 455. Más tarde, en el año 534, fueron conquistadas por las
tropas de Justiniano I e integradas al Imperio bizantino hasta principios del siglo VIII. La crisis económica y demográfica del archipiélago, a lo largo de los siglos VII al IX, les expuso de forma creciente a los ataques exteriores. Después de una etapa de incursiones, el Emirato de Córdoba las ocupó en el año 903. Posteriormente, dependieron de la Taifa de Denia (1013-1067), del Imperio Almorávide (1120-1203) y de los Almohades (del 1203 hasta la conquista cristiana).

La Corona de Aragón experimentó durante los siglos XII y XIII una fuerte expansión hacia el Mediterráneo, que la llevó hasta las Baleares. El origen de la actual extensión del catalán se encuentra en la Corona de Aragón, donde el catalán era el idioma dominante y más hablado, hablado por el 80% de la población. Jaime I de Aragón capitaneó una flota que desembarcó en Mallorca a finales del verano de 1229. Después de largos combates que se prolongaron durante meses, el rey entró victorioso en la ciudad el 31 de diciembre de ese mismo año. El asalto fue seguido de una matanza indiscriminada que ocasionó un verdadero genocidio de la población mallorquina; tanto es así que los miles de cadáveres que no pudieron ser enterrados provocaron una epidemia entre los conquistadores que causó numerosas bajas. Como consecuencia, los nobles quisieron quedarse con todo el botín en lugar de sortearlo entre la tropa. Esto provocó la revuelta de peones y caballeros. Finalmente se produjo el reparto del botín que duró hasta el 30 de abril de 1230.

Gracias a todo esto, los musulmanes supervivientes tuvieron tiempo de organizar diversos focos de resistencia en las montañas, lo que prolongó un par de años las luchas contra los musulmanes de Mallorca que, finalmente, terminaron convertidos en esclavos o semiesclavos.
Así, las Baleares fueron repobladas mayoritariamente por payeses del Rosellón, Gerona y Barcelona.

Toda esta destrucción debilitó también al ejército de Jaime I hasta el punto de que, cuando Menorca pidió el vasallazgo de la Corona, se le concedió. Así, Menorca se convirtió en una Taifa autónoma, donde la religión y la cultura árabe se mantuvieron durante medio siglo más. Pero en enero de 1287, la flota de Alfonso III, el Franco, llegó al puerto de Mahón. Se pactó la capitulación de la isla de forma que los caudillos y nobles pudieron escapar a cambio de entregar al resto de la población para que se les esclavizara. Las Islas Baleares fueron repobladas por cristianos originarios del Ampurdán y de la Cataluña Vieja, quienes importaron el catalán a la zona.

Por lo que respecta a Ibiza, también fue conquistada por Jaime I, pero en agosto de 1235. Sus habitantes fueron también esclavizados y sus bienes repartidos entre los magnates.

Durante la II República (1931-1939) se proyectó sin éxito un Estatuto de Autonomía para las Islas Baleares.

En 1936, con el inicio de la guerra civil española, el archipiélago queda dividido en dos zonas: la parte central y oeste (Formentera, Ibiza, Mallorca) quedan dentro del área dominada por los militares alzados contra la Segunda República Española, mientras en Menorca fracasa la insurrección. En los primeros meses del conflicto, se desarrollará desde Cataluña principalmente, una operación para tomar Mallorca, el llamado desembarco de Mallorca, que se desarrollaría entre agosto y septiembre de 1936 y que finalmente sería rechazado por el ejército franquista, volviendo a quedar las cosas igual que antes. En ese momento llegaron desde Italia refuerzos aéreos y de tierra dirigidos por el jerarca fascista Arconovaldo Bonaccorsi, que durante algunos meses de 1936 se convirtió en el verdadero jefe de Mallorca. De hecho, durante toda la contienda la isla de Mallorca se convirtió en una importante base aeronaval italiana, desde la cual las fuerzas italianas acosaron las rutas de suministro republicanas y bombardearon sistemáticamente la retaguardia republicana en Levante. En febrero de 1939 la isla de Menorca fue ocupada por las tropas franquistas.

Tras la transición regresan los ánimos autonomistas y en 1983 finalmente es aprobado un Estatuto de Autonomía de las Islas Baleares.

La provincia de las islas Baleares es la 13.ª de España en que existe un mayor porcentaje de habitantes concentrados en su capital (36,05%, frente a 31.96% del conjunto de España).

El archipiélago ha sufrido un gran crecimiento demográfico tras el boom turístico de los años 1960: en el periodo 1970-2005, éste fue del +76,10%, frente al +29,90% de la media española. En el año 2010, la población total de las islas asciende a personas.

Según el Padrón municipal de habitantes (INE, 2010), un 21,9% de la población balear es de nacionalidad extranjera, siendo la Comunidad Autónoma y la segunda provincia de España —tras Alicante— con mayor número de residentes foráneos. Un 52,4% de los extranjeros provienen de la Unión Europea, destacando los alemanes (14,9% del total), británicos (9,7%), italianos (6,9%), rumanos (5,2%) y franceses (3,6%). Un 24,1% viene de América del Sur, destacando por su número los ecuatorianos (5,4%), argentinos (4,5%), y colombianos (4,2%). Un 14,8% viene de África, principalmente de Marruecos (9,9%) y Nigeria (1,4%).

El catalán es la lengua propia de las Islas Baleares (así definida en su Estatuto de Autonomía) y cooficial, junto al español, por serlo ésta en todo el Estado. El castellano es, además, la lengua habitual de uso para una mayoría de la población balear. La denominación del catalán en las islas no es unánime en tanto que se reivindica también la distinción de los dialectos baleares (mallorquín, menorquín e ibicenco) como idiomas con entidad propia, lo cual no está exento de connotaciones políticas.

En las zonas turísticas se hablan el inglés y el alemán. Aunque con menor impacto, el italiano es también un idioma frecuente, sobre todo en Formentera, que cuenta con un alto índice de turismo de esa nacionalidad.

De acuerdo con los datos del censo del Instituto de Estadística de las Islas Baleares de 2001 y los datos sociolingüísticos del IEC de 2002, con respecto al catalán la población se distribuiría de la siguiente manera: sabe hablarlo el 74,6%, lo entiende el 93,1%, sabe leerlo el 79,6%, sabe escribirlo el 46,9%. Por su parte, según una encuesta realizada en 2003 por la Secretaría de Política Lingüística, de los habitantes de Baleares lo entienden 749100, lo saben hablar 600500, y es la lengua habitual para 404800 personas.

La capital de las Islas Baleares y de la isla de Mallorca es la ciudad de Palma, también llamada "Ciutat". En ella se encuentra la sede del Gobierno Balear, del Parlamento de las Islas Baleares y del Consejo Insular de Mallorca.

Al margen del gobierno autonómico, cada una de las islas está dotada con una organización política y administración propia detentada por los denominadas Consejos Insulares: el Consejo Insular de Mallorca con asiento en la propia ciudad de Palma, el Consejo Insular de Menorca que tiene su sede principal en Mahón a pesar de que esta isla no tiene atribuida la capitalidad legal reconocida a ninguna población, el Consejo Insular de Ibiza cuya sede está en la ciudad de Ibiza (popularmente identificada como "Vila") y el Consejo Insular de Formentera con sede en San Francisco Javier.
El Consejo Insular de Formentera fue creado en 2007 con la reforma del estatuto de autonomía de las Islas Baleares, ya que anteriormente Formentera e Ibiza compartían órgano de gobierno y administración (el llamado Consejo Insular de Ibiza y Formentera). Desde las elecciones de 2007 se vota separadamente de manera directa para elegir la composición de los Consejos Insulares, cuyos miembros anteriormente coincidían con los diputados de cada isla elegidos para el Parlamento de las Islas Baleares.

Existen muchas teorías sobre la procedencia del término "Baleares". Algunos consideran que proviene de la palabra griega "ballein" que significa "lanzar". Otras descartan el origen helénico, pues los griegos utilizaron la palabra "Gimnesias" para referirse a las islas de Menorca y Mallorca. En cambio, cartagineses y romanos prefirieron la denominación "Baleares" para Menorca y Mallorca. Todos ellos llamaron a Ibiza y Formentera Pitiusas. Afirman que "Baleares" no es griego, sino púnico y proviene del plural "ba' lé yaroh". El substantivo "ba' lé" significa "los que ejercitan el oficio de" y actúa como sujeto del verbo "yaroh" que significa "tirar piedras". El significado final sería algo así como "los maestros del lanzamiento". Y estos maestros del lanzamiento eran los honderos de las islas. Autores clásicos como Plinio el Viejo o Diodoro Sículo han hablado mucho de ellos. Pero es la narración de Licofronte de Calcis, en su poema hermético "Alexandra" (versos 633-641), cuando habla de los fugitivos de la guerra de Troya que llegan a las Baleares, a las que él llama Gimnesias, donde se da esta descripción:

Esta fama y probablemente un exceso de población dio lugar a que muchos de estos honderos de las islas terminaran nutriendo a los ejércitos cartaginés y, más tarde, romano.

Parece ser que la costumbre de utilizar la honda en las islas no se abandonó entre los campesinos hasta bien entrado el siglo XX. En Menorca, hasta no hace muchos años, existía la tradición de que, para entrar en determinados gremios, el aspirante tenía que acertar con una piedra, y sin errar ningún tiro, ocho espacios vacíos entre dos barras.

Gimnesias y Pitiusas han tenido una historia geográfica diferente. Durante las glaciaciones del Cuaternario, debido a la acumulación de agua en forma de hielo en los casquetes polares y en las grandes sierras, mares y océanos bajaron de nivel. Esto provocó que se unieran Menorca y Mallorca por un lado e Ibiza y Formentera por el otro. Todas las faunas y floras se mezclaron, pero entre la Gran Gimnesia y la Gran Pitiusa no fue así, ya que permaneció un canal marino de más de 70km, infranqueable por la fauna terrestre. La menor medida de la Gran Gimnesia (2000km²) y un clima más árido provocó la extinción de la fauna terrestre y la falta de vegetales arbóreos notables.

En el pasado, Gimnesias y Pitiusas tuvieron ecosistemas distintos. Las Gimnesias tenían bosques de encinas en el interior y en los llanos costeros grandes bosques de boj balear ("Buxus balearica"), planta que aún se puede encontrar de forma residual en Mallorca. Las Pitiusas estaban prácticamente desnudas de vegetación arbórea y predominaban las hierbas nitrófilas producto del efecto de las deyecciones de la gran cantidad de colonias de aves que tenían.

Actualmente hay en las Baleares numerosas plantas endémicas, entre otras "Apium bermejoi, Euphorbia fontqueriana, Euphorbia margalidiana, Euphorbia pithyusa, Galium balearicum, Galium crespianum, Galium friedrichii" o "Helleborus lividus".

En el pasado, la fauna de las Gimnesias y de las Pitiusas era muy distinta. Parece ser que, a excepción de las especies voladoras (aves, murciélagos e insectos voladores) no compartían casi ninguna especie terrestre: diferentes comunidades vegetales, diferentes herbívoros, diferentes carnívoros como Hypnomys morpheus, especies de "Myotragus" o "Nesiotites hidalgo".

Cuenta con algunas especies endémicas como el sapillo balear ("Alytes muletensis"), o las lagartijas balear ("Podarcis lilfordi") y de las Pitiusas ("Podarcis pityusensis").

El fenómeno del turismo ha modificado el tipo de economía de las islas. Más de un 70% de la población (2001) se dedica al sector servicios. La industria de la zona es básicamente la del textil, el cuero y el calzado. El turismo está muy desarrollado y es la principal fuente de ingresos. Palma, la capital de las Islas Baleares, y Mallorca son las zonas más visitadas y famosas por los turistas.

Las Islas Baleares constituyen la tercera comunidad autónoma española con mayor número de turistas extranjeros, detrás de Canarias, en segundo lugar y Cataluña, en primer lugar. Recibe más de 9,8 millones de turistas extranjeros anualmente. Según los datos aportados por AENA (Aeropuertos Españoles y Navegación Aérea) Mallorca es el principal destino turístico en las islas, con el 65% del total. La sigue Ibiza, con un 37% y luego Menorca y Formentera, con un 18,13% y un 12,37%, respectivamente. Los turistas que visitan las islas provienen principalmente de Europa, sobre todo de Alemania y Reino Unido.

La generación de energía en las islas corre a cargo básicamente de las cinco centrales térmicas instaladas en Mallorca, Menorca e Ibiza:

Como muestra del arte prehistórico, las islas conservan muchos restos de la denominada cultura megalítica balear entre los que destacan los talayot o "talaiots", las navetas o "navetes" y las taulas o "taules", todos ellos del periodo comprendido entre 1800 y 1500 a. C.
No son muchos los restos que quedan de la época musulmana. La catedral de Santa María de Palma de Mallorca, la Lonja y el castillo de Bellver (construcción circular que preside con su Torre del Homenaje la bahía de Palma) son claras muestras del arte gótico. Cabe destacar también, durante ese periodo iglesias como la de Santa Creu, Santa Eulalia, San Jaume, San Nicolás... Posteriormente iglesias como San Francisco, Montesión... En Ciudadela y Palma existen algunos ejemplos de la arquitectura del siglo XVIII, periodo en el que destacó como pintor P. Calvo.

La gastronomía de Baleares posee muchos puntos de contacto con la cocina catalana y valenciana. Es de características puramente mediterráneas. Las islas han sido conquistadas varias veces durante su historia entre franceses e ingleses, lo que puede decirse que ha dejado ciertas influencias culinarias. Cabe mencionar que existen marcadas diferencias entre la cocina mallorquina y menorquina.

Entre los ingredientes más típicos se encuentran el cerdo y sus subproductos. Uno de los más típicos es la sobrasada (embutido con carne, tocino y abundante pimentón), que se consume de diversas formas: en Mallorca se hornea y se asa, y en Menorca se fríe (a veces se sirve con miel). Existen otros embutidos, como el "camaiot", la butifarra ("botifarró") y el "xolís" (de origen campesino).





</doc>
<doc id="1477" url="https://es.wikipedia.org/wiki?curid=1477" title="Ibn Hazm">
Ibn Hazm

Abu Muḥammad ʿAli ibn Aḥmad ibn Saʿīd ibn Ḥazm (árabe: ), más conocido como Ibn Hazm (Córdoba, 7 de noviembre de 994 - Montíjar, Huelva, 15 de agosto de 1064), fue un filósofo, teólogo, historiador, narrador y poeta andalusí. Fue el único autor que dejó algunas indicaciones sobre los grupos tribales que pasaron a al-Ándalus en la época de la conquista

Nació en los últimos años del siglo X y justo antes de la crisis que acabaría para siempre con el Califato de Córdoba. Provenía de una familia muladí que vivía de la explotación de una finca por Montíjar, cerca de Huelva. Su abuelo se trasladó a la capital califal en los tiempos en que la fama de ésta descollaba por todo el mundo, aunque poco se sabe de él. En cambio, sí se sabe que su padre, Ahmad, fue un hombre culto y hábil, ya que, una vez que hubo entrado en el mundo político cordobés, se ganó la confianza tanto del Califa como del visir, Almanzor, llegando a ser nombrado él mismo visir y tomando el mando cuando se ausentaba Almanzor. Así, su hijo 'Ali pasó su infancia en la corte cordobesa de al-Zahira.

Perteneciendo pues a la aristocracia cordobesa, vivió de primera mano el estallido de la guerra civil cordobesa, que quebró su apacible vida. La familia de 'Ali se situó de lado del bando legitimista Omeya, en contraposición de los que apoyaban el nuevo linaje amirí, el de su antiguo protector Almanzor, y ello produjo su caída en desgracia. En 1012 murió su padre Ahmad, y 'Ali tuvo que marcharse desterrado a Almería.

En Almería, acompañado por su amigo y correligionario Muhammad ibn Ishāq, se enfrentaron al gobernador cuando él cambió de bando y apoyó a un nuevo pretendiente, y acabaron desterrados de nuevo, esta vez en un pueblo llamado Aznalcázar. Estando allí, oyeron que un nuevo pretendiente Omeya estaba levantando un ejército en Játiva con el que reclamar de nuevo el Califato, así que se pusieron en camino para unirse a él. Este, bisnieto de Abderramán III llamado 'Abd al-Rahmān ibn Muhammad ibn 'Abd al-Malik, decidió atacar a los ziríes de Granada antes de llegar a la capital, y allí éstos acabaron con su ejército. En esta batalla Ibn Hazm fue hecho prisionero. De ahí se retiró a Játiva, donde, contando unos 28 años, escribió "El collar de la paloma".

En 1023 la ciudad de Córdoba eligió al nuevo Califa, tras la caída del Califato hammudí, siendo el elegido Abderramán V, que eligió como equipo gobernante a Ibn Hazm y su grupo de amigos, haciéndolos visires; antiguos aristócratas cordobeses, eran personas cultas y preparadas, pero sin embargo su gobierno no duró más de mes y medio, tiempo tras el cual el Califa fue ejecutado e Ibn Hazm puesto de nuevo en la cárcel.

A partir de ahí, nuestro 'Ali renunció definitivamente a la política para dedicarse por completo a los estudios jurídicos y teológicos. Abrazó la escuela zahirí, de la que daba cursos junto a su maestro Abū-l-Jiyār de Santarén en la Mezquita mayor de Córdoba hasta que en 1027 fue denunciado por el vulgo cordobés por contravenir la escuela malikí oficial. Desde ese momento renunció a la enseñanza y se dedicó a vagar por los distintos reinos de taifas como polemista y erudito. En 1039 se refugió durante un tiempo en Mallorca, protegido por un magnate. Mantuvo encendidas disputas con tantos otros sabios y reyezuelos de su época, entre otros, con al-Mutadid de Sevilla, que dio como fruto la quema de sus libros en la taifa sevillana, y que inspiró a Ibn Hazm sus famosos versos:

Así, mantuvo esta vida de sabio errante hasta el final de sus días, cuando por fin se retira al cortijo familiar de Montíjar, con la única compañía de sus hijos, y donde se dedica a escribir y escribir. Poco se sabe sin embargo de su vida familiar, ya que habla poco de ella en sus obras.

Fue un ingente polígrafo cuyas miles de páginas no pueden reducirse a una breve explicación. Escribió obras históricas, como "Risāla fī faḍl al-Andalus" («Epístola en elogio de al-Ándalus») o "Naqt al-ʿarūs" («Bordado de la novia»), "Ŷamharat ansāb al-ʿarab" (conocido como Yamhara, «Linajes árabes»), "Al-faṣl fī-l-milal wa-l-ahwāʾ wa-l-niḥal" («Historia crítica de las religiones, sectas y escuelas»). Estas obras solo fueron superadas en Occidente en el siglo XIX.

De carácter didáctico es "Falsafat al-ajlāq" («Los caracteres y la conducta»), traducida al castellano por Miguel Asín Palacios y de tema polémico teológico es "Risālat fī radd ʿalà bni Nagrīla (Polémica teológica con Ibn Nagrella)".

Su obra más famosa es "Ṭawq al-ḥamāma" o "El collar de la paloma" en la que trata el tema del amor. Fue escrito en Játiva hacia 1023. Se trata de un libro de reflexiones sobre la verdadera esencia del amor, intentando descubrir lo que tiene de común e inmutable a través de los siglos y las civilizaciones de influencia neoplatónica, conocido en la cultura musulmana como "amor udrí", incluyendo detalles autobiográficos y documentales. Constituye también un diwan, o antología poética de tema amoroso, pues está empedrado de composiciones elegantes y refinadas.

Ibn Hazm era un hombre de profundas convicciones religiosas. Este dirigió parte de sus críticas contra la relajación de costumbres en Al-Ándalus, ya que su obra está penetrada por la firme creencia en "Alá" y el Islam como única religión verdadera, además de considerar que fue esta una de las causas fundamentales de la decadencia del Califato de Córdoba. Dentro de su más profundo pensamiento religioso establece la preeminencia de estas cuatro ciencias: ciencia del Corán, ciencia de las traducciones, ciencia del Derecho y ciencia de la Teología. Esto indica la preeminencia, como entre tanto otros autores de su época, de la religión sobre el pensamiento especulativo. De hecho llega a reconocer la imposibilidad de conocer la esencia, atributos y naturaleza de Dios, situando, por tanto, la fe por encima de cualquier otra consideración. Su obra más importante en este ámbito fue el "Libro de las decisiones sobre las religiones", en la que intenta desentrañar dentro de los diferentes movimientos religiosos cuál es la doctrina islámica verdadera, buscando la más literal y menos alegórica.

También escribió numerosas obras filosóficas. Su pensamiento se basaba en Aristóteles y se esfuerza en distinguir lo verdadero de lo falso, lo que lleva a un sexto sentido o "sentido común" por el cual se demuestran las verdades. Dichas verdades están en estrecha relación con la fe por lo que un conocimiento cabal de la filosofía puede relacionar a estas verdades con la teología. De este modo, elabora una teología natural acercándose a los postulados de Santo Tomás y desarrollando el tema de la esencia y la existencia, concluyendo que son idénticas solo en Dios, pero con un significado diferente que la doctrina tomista.

Pero quizás su aporte más significativo esté dado por su testimonio acerca del motivo de la actividad del hombre, cuando indica que todo lo que hace el hombre lo hace para evitar la preocupación, para distraerse. ¿Distraerse de que? De la muerte.





</doc>
<doc id="1478" url="https://es.wikipedia.org/wiki?curid=1478" title="I milenio">
I milenio

El primer milenio comenzó el 1 de enero del año 1 y terminó el 31 de diciembre del 1000.




</doc>
<doc id="1480" url="https://es.wikipedia.org/wiki?curid=1480" title="Isótopo">
Isótopo

La palabra isótopo (del griego: ἴσος "isos" 'igual, mismo'; τόπος "tópos" 'lugar', "en mismo sitio") se usa para indicar que todos los tipos de átomos de un mismo elemento químico (isótopos) se encuentran en el mismo sitio de la tabla periódica. Los átomos que son isótopos entre sí son los que tienen igual número atómico (número de protones en el núcleo), pero diferente número másico (suma del número de neutrones y el de protones en el núcleo). Los distintos isótopos de un elemento difieren, pues, en el número de neutrones.

La mayoría de los elementos químicos tienen más de un isótopo. Solamente 8 elementos (por ejemplo berilio o sodio) poseen un solo isótopo natural. En contraste, el estaño es el elemento con más isótopos estables, 10. 

Otros elementos tienen isótopos naturales, pero inestables, como el uranio, cuyos isótopos pueden transformarse o "decaer" en otros isótopos más estables, emitiendo en el proceso radiación, por lo que se dice que son "radiactivos". 

Los isótopos inestables son útiles para estimar la edad de una gran variedad de muestras naturales, como rocas y materia orgánica. Esto es posible, siempre y cuando, se conozca el ritmo promedio de desintegración de determinado isótopo, en relación a los que ya han decaído. Gracias a este método de datación, se puede estimar la edad de la Tierra.

Todos los isótopos tienen el mismo número atómico pero difieren en el número másico.

Si la relación entre el número de protones y de neutrones no es la apropiada para obtener la estabilidad nuclear, el isótopo es radiactivo.

Por ejemplo, en la naturaleza el carbono se presenta como una mezcla de tres isótopos con números másicos 12, 13 y 14: C, C y C. Sus abundancias respecto a la cantidad global de carbono son respectivamente 98,89 %, 1,11 % y trazas.



Los isótopos se subdividen en isótopos estables (existen menos de 300) y no estables o isótopos radiactivos (existen alrededor de 1200). El concepto de estabilidad no es exacto, ya que existen isótopos casi estables. Su estabilidad se debe al hecho de que, aunque son radiactivos, tienen un periodo de semidesintegración extremadamente largo comparado con la edad de la Tierra. 

Inicialmente los nombres de los isótopos de cada elemento que se iban descubriendo recibieron nombres propios diferentes al del elemento al que pertenecían. Así cuando se descubrieron tres isótopos del hidrógeno, recibieron los nombres de protio, deuterio y tritio. El núcleo del protio consta de un protón, el del deuterio de un protón y un neutrón, y el del tritio de un protón y dos neutrones.

Cuando se siguieron descubriendo isótopos de casi todos los elementos se vio que serían necesarios cientos o miles de nombres y se cambió el sistema de nomenclatura. Actualmente cada isótopo se representa con el símbolo del elemento al que pertenece, colocando como subíndice a la izquierda su número atómico (número de protones en el núcleo), y como superíndice a la izquierda su número másico (suma del número de protones y de neutrones). Así los isótopos del hidrógeno protio, deuterio y tritio se denotan H, H y H, respectivamente.

Como todos los isótopos de un mismo elemento tienen el mismo número atómico, que es el de orden en la tabla periódica, y el mismo símbolo, habitualmente se elide el número atómico. Así para los isótopos del hidrógeno escribiremos H, H y H. Esto se hace porque todos los isótopos de un elemento particular se comportan de la misma manera en cualquier reacción química. Por ejemplo, un átomo del escaso isótopo de oxígeno que tiene número másico 18, se combinará exactamente igual con dos átomos de hidrógeno para formar agua que si se tratara del abundante átomo de oxígeno de número másico 16. Sin embargo cuando se están describiendo reacciones nucleares es útil tener el número atómico como referencia. 

En el caso de textos no científicos, como textos periodísticos, esta notación con subíndices y superíndices es incómoda, por lo que también se usa una notación consistente en el nombre del elemento unido por un guion al número másico del isótopo de que se trate. De esta forma los isótopos del hidrógeno H, H y H, también se pueden nombrar como hidrógeno-1, hidrógeno-2 e hidrógeno-3 respectivamente.

Estas son las reglas de nomenclatura científicamente aceptadas, correspondientes a la "Nomenclatura de Química Inorgánica. Recomendaciones de 2005 (Libro Rojo de la IUPAC)", tal y como se pueden encontrar en su sección IR-3.3.

Hay que recordar que los nombres de los elementos químicos son nombres comunes y como tales deben escribirse sin mayúscula inicial, salvo que otra regla ortográfica lo imponga.

Los radioisótopos son isótopos radiactivos ya que tienen un núcleo atómico inestable y emiten energía y partículas cuando se transforman (decaen) en un isótopo diferente más estable. La energía liberada al decaer puede detectarse con un contador Geiger o con una película fotográfica. 

La principal razón de la inestabilidad está en el exceso de protones o neutrones. La fuerza nuclear fuerte, que une protones y neutrones entre sí, requiere que la cantidad de neutrones y protones esté cerca de cierta relación. Cuando el número de neutrones es superior al que requiere esta relación el átomo puede presentar decaimiento beta negativo. Cuando el átomo tiene un exceso de protones (defecto de neutrones) suele presentar decaimiento beta positivo. 

Esto sucede porque la fuerza nuclear fuerte residual depende de la proporción de neutrones y protones. Si la relación está muy sesgada hacia uno de los extremos la fuerza nuclear débil responsable del decaimiento beta puede producir esporádicamente la pérdida de algún nucleón. Para números atómicos elevados ("Z" > 80) también se vuelve frecuente la desintegración alfa (que casi es mucho más frecuente cuando además hay exceso de protones).

Cada radioisótopo tiene un periodo de semidesintegración o semivida característico. La energía puede ser liberada principalmente en forma de radiación alfa (partículas constituidas por núcleos de helio), beta (partículas formadas por electrones o positrones) o gamma (energía en forma de radiación electromagnética).

Varios isótopos radiactivos inestables y artificiales tienen usos en técnicas de radioterapia en medicina. Por ejemplo, un isótopo del tecnecio (Tc, la "" indica que es un isómero nuclear metaestable) puede usarse para identificar vasos sanguíneos bloqueados. 

Varios isótopos radiactivos naturales se usan en datación radiométrica para determinar cronologías, por ejemplo, arqueológicas.

Las siguientes son varias de las aplicaciones de diferentes isótopos en diversas áreas, como la medicina:






</doc>
<doc id="1481" url="https://es.wikipedia.org/wiki?curid=1481" title="Iodopsina">
Iodopsina

La iodopsina o yodopsina es una cromoproteína, un pigmento situado en los segmentos exteriores de los conos del ojo humano, siendo responsable de la percepción del color. Esta tiene una mayor concentración en la fóvea. Viene asociada a la vitamina A. Al recibir la luz produce una diferencia de potencial que da lugar a una corriente eléctrica por medio de la cual la información visual se transmite por las neuronas hasta el cerebro.


</doc>
<doc id="1482" url="https://es.wikipedia.org/wiki?curid=1482" title="Inercia">
Inercia

En física, la inercia (del latín ("inertĭa") es la propiedad que tienen los cuerpos de permanecer en su estado de reposo relativo o movimiento relativo. Dicho de forma general, es la resistencia que opone la materia a modificar su estado de movimiento, incluyendo cambios en la velocidad o en la dirección del movimiento. Como consecuencia, un cuerpo conserva su estado de reposo relativo o movimiento rectilíneo uniforme relativo si no hay una fuerza que, actuando sobre él, logre cambiar su estado de movimiento. 

En la naturaleza no existe el reposo, siempre toda la materia está en movimiento, por eso cuando se habla de reposo o Movimiento Rectilíneo Uniforme (MRU) se debe añadir la palabra "relativo" (relativo a un sistema de referencia). El cuerpo está en reposo o en MRU sólo con respecto de ese sistema de referencia. Cuando un cuerpo está en reposo relativo sobre la superficie de la Tierra, en realidad está participando de los distintos movimientos que realiza el planeta y está sometido a diferentes fuerzas como las gravitatorias de la Tierra, el Sol, La Luna y otros cuerpos, así como la resistencia mecánica que impide que se hunda en la tierra, o se deslice. Se puede decir que el cuerpo se encuentra en equilibrio sobre la superficie de la Tierra y por lo tanto en reposo relativo.

Podríamos decir que es la resistencia que opone un sistema de partículas a modificar su estado dinámico. 

En física se dice que un sistema tiene más inercia cuando resulta más difícil lograr un cambio en el estado físico del mismo. Los dos usos más frecuentes en física son la inercia mecánica y la inercia térmica.

La primera de ellas aparece en mecánica y es una medida de dificultad para cambiar el estado de movimiento o reposo de un cuerpo. La inercia mecánica depende de la cantidad de masa y del tensor de inercia.

La inercia térmica mide la dificultad con la que un cuerpo cambia su temperatura al estar en contacto con otros cuerpos o ser calentado. La inercia térmica depende de la capacidad calorífica.

Las llamadas fuerzas de inercia son fuerzas ficticias o aparentes que un observador percibe en un sistema de referencia no-inercial.

Hay investigadores que consideran la inercia mecánica como manifestación de la masa, y están interesados en las ideas de la física de partículas sobre el bosón de Higgs. De acuerdo al modelo estándar de física de partículas todas las partículas elementales carecen prácticamente de masa. Sus masas (y por lo tanto su inercia) provienen del Mecanismo de Higgs vía intercambio con un campo omnipresente de Higgs. Esto lleva a deducir la existencia de una partícula elemental, el bosón de Higgs.
Otros están inclinados a ver la inercia como una característica conectada con la masa, y trabajan a lo largo de otros caminos. El número de los investigadores que entregan nuevas ideas aquí es reducido. Muchas de las ideas presentadas al respecto todavía son miradas como protociencia, pero ilustra cómo está avanzando la formación de teorías en esta área.
Una publicación reciente del físico sueco-americano C. Johan Masreliez propone que el fenómeno de la inercia puede ser explicado, si los coeficientes métricos en la línea elemento de Minkowskian son cambiados como consecuencia de la aceleración. Cierto factor de posicionamiento modela la inercia como efecto de tipo gravitacional.
En un artículo sucesivo para "Physica Scripta", explica cómo la relatividad especial puede ser compatible con un cosmos con un marco cosmológico fijo y único de la referencia. La transformación de Lorentz modela la formación de la estructura ("morphing") de las partículas móviles, que pudieran preservar sus características cambiando sus geometrías del espacio-tiempo local. Con esto la geometría se convierte en dinámica y una parte integral de movimiento. Masreliez dice que es esta geometría la que cambia para ser la fuente de la inercia; ergo, para generar la fuerza de inercia.Si fuera aceptada, la inercia podría conectar la relatividad especial con la general. Sin embargo, aunque los marcos de inercia siguen siendo físicamente equivalentes y las leyes de la Física se aplican igualmente, no modelan el mismo espacio-tiempo. Estas nuevas ideas, SEC han sido comprobadas hasta ahora no sólo por el proponente sino también por algunos miembros de la comunidad científica.La teoría de la SEC es controversial, ya que refuta la hipótesis del Big Bang
Otro acercamiento ha sido sugerido por Emil Marinchev (2002).



</doc>
<doc id="1489" url="https://es.wikipedia.org/wiki?curid=1489" title="Instrumento musical">
Instrumento musical

Un instrumento musical es un objeto compuesto por la combinación de uno o más sistemas resonantes y los medios para su vibración, construido con el fin de reproducir sonido en uno o más tonos que puedan ser combinados por un intérprete para producir música. Al final, cualquier cosa que produzca sonido puede servir de instrumento musical, pero la expresión se reserva, generalmente, a aquellos objetos que tienen ese propósito específico.

El cuerpo humano, generando sonidos por medio de las vías aéreas superiores vocales y percusivos, fue, probablemente, el primer instrumento. Sachs y otros han especulado sobre la capacidad de "Homo habilis" de agregar sonidos de modo idiofónico a impulsos de expresión emocional motriz como la danza, empleando diversos medios como piedras, troncos huecos, brazaletes, conchas y dientes de animales.

Excavaciones arqueológicas y demás han encontrado aerófonos de filo (flautas) de hueso de treinta mil años de antigüedad. Resulta evidente que algunos aerófonos producen sonido por la acción natural del viento (sobre cañas de bambú), ofreciendo el fenómeno sonoro al observador casual.
Asimismo, otros aerófonos como los cuernos de animales, por el volumen de los sonidos producidos, pudieron ser y fueron empleados como instrumentos de señales sonoras para la caza.
La gran cantidad de instrumentos musicales de viento, cuerda y percusión encontrados en excavaciones arqueológicas de todas las grandes civilizaciones antiguas y la extensa documentación pictórica y literaria coinciden con la gran importancia que la música ha tenido siempre para el ser humano.

En tiempos del Egipto ptolemaico, el ingeniero Ctesibio de Alejandría desarrolló el "órgano hidráulico" o hydraulis, destinado a producir melodías con gran volumen sonoro, que podía ser empleado en funciones circenses al aire libre.

Existen muchas divisiones alternativas y subdivisiones de instrumentos. Generalmente, al estudiar los instrumentos musicales es frecuente encontrarse con la clásica división de los instrumentos en cuatro familias: viento, cuerda, percusión y los instrumentos eléctricos (creados por el hombre hace aproximadamente 50 años). Sin embargo, debido a que esta clasificación está orientada a los instrumentos de la orquesta sinfónica, adolece de ciertas restricciones y defectos. Debido a ello, algunos musicólogos sencillamente amplían esta clasificación añadiendo hasta tres categorías adicionales: voz, teclados y electrónicos. Sin embargo, en 1914 los músicos Curt Sachs y Erich Hornbostel idearon un nuevo método de clasificación que, atendiendo a las propiedades físicas de cada instrumento, pretendía ser capaz de englobar a todos los existentes. Una tercera clasificación, muy seguida en el este de Asia, clasifica los instrumentos atendiendo a sus materiales de construcción: metal, madera, barro, cuero, entre otros.

La clasificación más usada de manera convencional es la de viento, cuerda y percusión.

Erich von Hornbostel y Curt Sachs publicaron en 1914 una clasificación de los instrumentos musicales en su trabajo "Zeitschrift für Ethnologie" que es ampliamente seguida en la actualidad.

Establecieron cuatro clases o categorías principales de instrumentos musicales (a la que añadieron una quinta posteriormente), que a su vez se dividen en grupos y subgrupos, según el modo de generación del sonido:

Son aquellos instrumentos en los que el sonido procede de un cuerpo sólido y es generado por vibración del instrumento mismo mediante percusión, frotación o pulsación, como en el caso de las claves, xilófono, campana.

Los membranófonos son aquellos en los cuales el sonido es generado por la vibración de una membrana por percusión o frotación, como es el caso del timbal, tambor, conga.
Son los llamados instrumentos de viento, donde el sonido es generado por la vibración del aire, a causa del roce con una lengüeta, labios o cuerdas vocales, como es en el caso de la flauta, trompeta, saxofón.
Son los llamados instrumentos de cuerda, donde el sonido es generado por la vibración de una cuerda mediante percusión, frotación o pinzamiento, como en el caso del arpa, guitarra, violín, piano.

Durante el siglo XX se desarrolló un nuevo tipo de instrumento, los denominados electrófonos. En estos instrumentos, el sonido es generado por medios electrónicos, como en el sintetizador o el theremín. No deben ser confundidos con los "instrumentos electroacústicos", donde el sonido es generado de modo no electrónico pero modificado electrónicamente, como en el caso de la guitarra eléctrica y el bajo eléctrico. Sachs, por esta razón, más tarde añadió una quinta categoría a su clasificación, los electrófonos.



</doc>
<doc id="1490" url="https://es.wikipedia.org/wiki?curid=1490" title="Imprenta">
Imprenta

La imprenta es un método mecánico destinado a reproducir textos e imágenes sobre papel, tela u otros materiales. En su forma clásica, consiste en aplicar una tinta, generalmente oleosa, sobre unas piezas metálicas (tipos) para transferirla al papel por presión. Aunque comenzó como un método artesanal, su implantación trajo consigo una revolución cultural.

Más modernamente, la evolución de diversas tecnologías ha dado lugar a diferentes métodos de impresión y reproducción, como son la flexografía, la serigrafía, el huecograbado, el alto grabado, la fotografía electrolítica, la fotolitografía, la litografía, la impresión ófset, la xerografía y los métodos digitales.

Ya los romanos tuvieron sellos que imprimían hojas de inscripciones sobre objetos de arcilla alrededor del año 440 a. C. y el 430 a. C. Entre 1041 y 1048, Bi Sheng inventó en China —donde ya existía un tipo de papel de arroz— el primer sistema de imprenta de tipos móviles, a base de complejas piezas de porcelana en las que se tallaban los caracteres chinos; esto constituía un complejo procedimiento por la inmensa cantidad de caracteres que hacían falta para la escritura china. En 1234 artesanos durante la dinastía Koryo (en la actual Corea), conocedores de los avances chinos con los tipos móviles, crearon un juego de tipos móviles de metal que se anticipó a la imprenta moderna, pero lo usaron raramente. Sin embargo, la imprenta moderna no se creó hasta el año 1450 aproximadamente, de la mano de Johannes Gutenberg.

En la antigua Europa, muchas personas y poblaciones pretendieron ser parte de este arte; aunque las opiniones apuntan a que fue el alemán Johannes Gutenberg, por las ideas que tenía y la iniciativa de unirse a un equipo de impresores, lo que lo apoya como el inventor de la tipografía. Existe documentación subsecuente que le atribuye la invención aunque, curiosamente, no consta el nombre de Gutenberg en ningún impreso conocido.

Ante la controvertida historia, aparecieron a disputar la gloria del llamado "Padre de la Imprenta" los nombres del alemán Mentelin, impresor de Estrasburgo (1410-1478); el italiano Panfilo Castaldi, médico y después tipógrafo en 1470, el italiano Aldo Manucio, Lorenzo de Coster, de Haarlem, (Países Bajos) (1370-1430). Cada uno tiene un monumento en sus respectivas localidades; sin embargo, perdieron el pleito definitivamente los partidarios de Mentelin y Castaldi.

Una edición que data del año 1502 en Maguncia, Alemania, impresa por Peter Schöffer, sucesor de la imprenta que inicialmente fue creada por Gutenberg, dice:

Hasta 1450 y aun en años posteriores, los libros se difundían en copias manuscritas por amanuenses, muchos de los cuales eran monjes y frailes dedicados exclusivamente al rezo y a la réplica de ejemplares por encargo del propio clero o de reyes y nobles. A pesar de lo que se cree, no todos los monjes copistas sabían leer y escribir. Realizaban la función de copistas, imitadores de signos que en muchas ocasiones no entendían, lo cual era fundamental para copiar libros prohibidos que hablasen de medicina interna o de sexo. Las ilustraciones y las letras mayúsculas eran producto decorativo y artístico del propio copista, que decoraba cada ejemplar que realizaba según su gusto o visión. Cada uno de sus trabajos podía durar hasta diez años.

En la Alta Edad Media se utilizaba la xilografía en Europa para publicar panfletos publicitarios o políticos, etiquetas, y trabajos de pocas hojas. Para realizarlas se trabajaba el texto en hueco sobre una tablilla de madera, incluyendo los dibujos —un duro trabajo de artesanía—. Una vez confeccionada, se acoplaba a una mesa de trabajo, también de madera, y se impregnaban de tinta negra, azul o roja (sólo existían esos colores). Después se aplicaba el papel y con un rodillo se fijaba la tinta. El desgaste de la madera era considerable por lo que no se podían hacer muchas copias con el mismo molde. Este tipo de impresión recibe el nombre de xilografía.

Cada impresor fabricaba su propio papel, estampando una marca de agua a modo de firma de impresor. Por estas marcas de agua es por lo que se conocen sus trabajos.

En este entorno, Gutenberg apostó a que era capaz de hacer a la vez varias copias de la Biblia en menos de la mitad del tiempo que tardaba en copiar una el más rápido de todos los monjes copistas del mundo cristiano y que éstas no se diferenciarían en absoluto de las manuscritas por ellos.

Pidió dinero a Johann Fust, y comenzó su reto sin ser consciente de lo que su invento iba a representar para el futuro de toda la humanidad. 

En vez de usar las habituales tablillas de madera, que se desgastaban con el uso, confeccionó moldes en madera de cada una de las letras del alfabeto y posteriormente rellenó los moldes con plomo, creando los primeros tipos móviles. Tuvo que hacer varios modelos de las mismas letras para que coincidiesen todas entre sí: en total, más de 150 tipos, que imitaban la escritura de un manuscrito. Había que unir una a una las letras que se sujetaban en un ingenioso soporte, sistema mucho más rápido que el grabado en madera y considerablemente más resistente al uso. 

Como plancha de impresión, amoldó una vieja prensa para uva a la que sujetó el soporte con los tipos móviles con un hueco para las letras mayúsculas y los dibujos. Éstos, posteriormente, serían añadidos mediante el viejo sistema xilográfico y terminados de decorar de forma manual.

Lo que Gutenberg no calculó bien fue el tiempo que le llevaría poner en marcha su nuevo invento, por lo que antes de finalizar el trabajo se quedó sin dinero. Volvió a solicitar un nuevo crédito a Johann Fust y, ante la negativa del prestamista, le ofreció formar una sociedad. Johann Fust aceptó la propuesta y delegó la vigilancia de los trabajos de Gutenberg a su sobrino, Peter Schöffer, quien se puso a trabajar codo a codo con él, al tiempo que vigilaba la inversión de su tío.

Tras dos años de trabajo, Gutenberg volvió a quedarse sin dinero. Estaba cerca de acabar las 150 Biblias que se había propuesto, pero Johann Fust no quiso ampliarle el crédito y dio por vencidos los anteriores, quedándose con el negocio y poniendo al frente a su sobrino, ducho ya en las artes de la nueva impresión como socio-aprendiz de Gutenberg.

Gutenberg salió de su imprenta arruinado y se cuenta que fue acogido por el obispo de la ciudad, el único que reconoció su trabajo hasta su muerte, pocos años después.

Peter Schöffer terminó el cometido que inició su maestro y las Biblias fueron vendidas rápidamente a altos cargos del clero, incluida la Santa Sede, a muy buen precio. Pronto empezaron a llover encargos de nuevos trabajos. La rapidez de la ejecución fue sin duda el detonante de su expansión, puesto que antes la entrega de un solo libro podía posponerse durante años.

Actualmente, se conservan muy pocas "Biblias de Gutenberg" —o de 42 líneas— y, menos aún, completas. En España se conservan dos, una completa en Burgos y otra con sólo el Nuevo Testamento en Sevilla.

En 1449, Johannes Gutenberg ya había impreso el primer libro, el llamado Misal de Constanza, en la imprenta de Mainz, Alemania. La Biblia de Gutenberg no fue únicamente el segundo libro impreso, sino que, además, fue el más perfecto. Su imagen no difiere en absoluto de un manuscrito. El mimo, el detalle y el cuidado con que fue hecha, sólo su inventor pudo habérselo otorgado.

Gutenberg, en su labor de impresor, creó su famoso incunable "Catholicon", de Juan Balbu de Janna. Pocos años después, imprimió hojas por ambas caras y calendarios para el año 1448. Además, junto con su amigo Fust editaron algunos libritos y bulas de indulgencia y en particular, aquel monumento de la imprenta primitiva, la Biblia de las 42 líneas, en dos tomos de doble folio, de 324 y 319 páginas respectivamente, con espacios en blanco para después pintar a mano las letras capitulares, las alegorías y viñetas que ilustrarían coloridamente cada una de las páginas de la Biblia.

Según las declaraciones de diversos testigos resulta que, mientras en apariencia fabricaba espejos, Gutenberg se servía de todos los instrumentos, materiales y herramientas necesarios para la secreta imprenta: plomo, prensas, crisoles, etc., con el supuesto pretexto de fabricar con planchas xilográficas de madera unos pequeños devocionarios latinos de título "Speculum" que eran fabricados en Holanda y Alemania con los títulos de "Speculum, Speculum humanae salvationis, Speculum vitae humanae, Speculum salutis", etc. Pero algunos declararon que con el pretexto de imprimir espejos, "Gutenberg, durante cerca de tres años, había ganado unos 100 florines en las cosas de la imprenta."

Hungría sería el primer reino que recibiría el renacimiento en Europa después de Italia, bajo el reinado de Matías Corvino en el siglo XVI se inauguraría la primera imprenta húngara en 1472. Andrés Hess sería llamado a Hungría desde Italia, quien usando el sistema de Gutenberg organizaría la imprenta húngara y haría publicar dos obras: "Cronica Hungarorum" ("La crónica de los húngaros"), y el "Magnus Basilius: De legendis poëtis - Xenophon: Apologia Socratis" (dos obras griegas clásicas en un solo tomo).

Años más tarde y hacia 1500 la situación social cambiaba en Alemania y una guerra civil hizo que en Maguncia los impresores huyeran para evitar caer en la guerra. A los impresores les costó mucho guardar el secreto y los talleres de imprentas se esparcieron por toda Europa.

La imprenta se conoce en América una vez concluida la conquista española. En 1539 el impresor Juan Cromberger monta una filial de su imprenta de Sevilla en Ciudad de México en un local de Juan de Zumárraga. Esta filial estará a cargo de Juan Pablos, que comienza su labor de impresión ese mismo año. El cronista Gil González Dávila ha querido decir que la primera obra impresa fue "Escala espiritual para llegar al Cielo" por San Juan Clímaco en 1532, en su versión traducida del latín por un fraile español, y aunque concuerda en el título del libro con el historiador Dávila Padilla, la fecha de 1532 es equivocada ya que en ese año no había medios para imprimir nada por aquellas tierras. El primer libro impreso sería "Breve y más compendiosa Doctrina Christiana", escrito por Juan de Zumárraga, en la imprenta de Juan Cromberger gestionada por Juan Pablos en 1539.

Así inició la más grande repercusión de la imprenta en la cultura de la humanidad. La palabra escrita ahora podía llegar a cualquier rincón, la gente podía tener acceso a más libros y comenzar a preocuparse por enseñar a leer a sus hijos. Las ideas cruzaban las fronteras y el arte de la tipografía fue el medio de difundirlas.

Libros, incunables, ediciones ilustradas con grabados de madera: la mejora de las técnicas y materiales de imprenta llevaron durante cuatro siglos las palabras por todo el mundo. El arte tipográfico evolucionó y llegó a crear obras maestras en la formación y estructuras de libros y ediciones especiales impresas. Actualmente las técnicas de impresión en calidad y volumen han mejorado de forma impresionante, algunas por medio de computadora, olvidándose del arte tipográfico que muchos tipógrafos del mundo se resisten a cambiar.

Pocos inventos han tenido la influencia en el ser humano como la creación de la imprenta, ese antiguo arte que, si va unido en una obra la labor del tipógrafo y la obra escrita de un buen autor, proporciona una obra de arte completa, lista para conmover con belleza literaria y estética tipográfica al lector, el fin primero y último de la imprenta.
A finales del siglo XIX, se perfeccionó el proceso, gracias a la invención en 1885 de la linotipia, por Ottmar Mergenthaler.

Los nuevos medios de comunicación aparecieron en un momento de un cambio acelerado y de comunicaciones más veloces y fueron la respuesta a la mayor demanda de información y entretenimiento. Los nuevos sistemas y estructuras nunca borran por completo los anteriores sino que se superponen. Así, las nuevas técnicas de almacenamiento y recuperación de información han necesitado de los medios de impresión en este campo para reagrupar y encontrar nuevas colocaciones, a menudo de carácter más especializado.

La revolución audiovisual se ha presenciado en medio de un diluvio de material de promoción impreso. Todo esto ha traído consigo cambios que afectan al libro; por ejemplo, la composición convencional es ahora tan cara que solamente se justifica en tiradas muy grandes, pero hay una gran variedad de métodos de impresión más económicos, como la fotocopia y la duplicación electrostática.

Nuevos horizontes se desplegaron con la llegada de la impresión digital. El ahorro de tiempo y los costos ofrecidos por las nuevas técnicas digitales valen también para la industria editorial que se beneficia de la rapidez y amplias posibilidades que la impresión digital ofrece:

Con la aparición de la tinta electrónica y los conocidos libros electrónicos o "eBooks" se ha logrado que ya no sea necesario imprimir un libro para poder distribuirlo y por ende leerlo. Diversos dispositivos permiten la compra y adquisición de libros, publicaciones y revistas desde el mismo aparato, lo que reduce de forma notable el costo de producción de la propiedad intelectual además de aportar una solución ecológica. También hay que resaltar el papel de internet como gran medio para distribuir información a través de páginas web y correo electrónico, sustituyendo muchas veces al uso tradicional del papel en ámbitos como la prensa escrita o el correo postal. Por estas razones alguna gente presume un futuro incierto para la imprenta, después de más de cinco siglos jugando un papel fundamental en la historia de la humanidad por la capacidad tangible que tiene de propagar el conocimiento.




</doc>
<doc id="1491" url="https://es.wikipedia.org/wiki?curid=1491" title="Iridaceae">
Iridaceae

Las iridáceas (Iridaceae) son una familia de plantas perennes, herbáceas y bulbosas pertenecientes al orden "Asparagales" dentro de las monocotiledóneas. La familia, cuyo nombre deriva del género "Iris", cuenta con más de 2000 especies que se distribuyen por casi todo el mundo, siendo una de las familias más importantes en horticultura. Géneros tales como "Crocus" e "Iris" son componentes preponderantes de las floras de varias regiones de Eurasia e "Iris" se halla muy bien representado en Norte América. "Gladiolus" y "Moraea" son géneros muy amplios y componentes principales de la flora subsahariana y sudafricana. "Sisyrinchium", con más de 140 especies, es el género de iridáceas más diversificado en América, donde también se encuentran varios otros miembros de la familia, muchos de los cuales son importantes en la floricultura tropical.

Actualmente se reconocen 66 géneros que se distribuyen entre siete subfamilias y ocupan una gran variedad de hábitats. La mayoría de las especies se adapta a climas estacionales que tienen un período de pronunciada sequía o frío desfavorables para el crecimiento vegetal y durante el cual las plantas permanecen latentes. Por esa razón, la mayoría de las iridáceas son de hoja caduca ya que sus partes aéreas (hojas y tallos) se secan cuando el bulbo o el cormo entra en letargo o dormancia. Las plantas así sobreviven períodos que no son favorables para el crecimiento refugiándose bajo el suelo. Las especies de iridáceas de hoja perenne se limitan a los bosques subtropicales y a las sabanas, a las praderas templadas y a los fynbos húmedos.

Las iridáceas son plantas generalmente herbáceas y perennes, raramente anuales o arbustivas leñosas con crecimiento secundario anómalo. El follaje puede mantenerse todo el año o puede secarse en alguna estación para luego rebrotar, por lo que las iridáceas pueden ser perennifolias o caducifolias. Excepcionalmente, como es el caso de "Geosiris", no presentan clorofila ya que los miembros de este género son plantas saprofíticas. Los tallos son rizomas, cormos o bulbos, o un cáudice leñoso. Presentan grandes cristales prismáticos de oxalato de calcio en los haces vasculares de las vainas como así también taninos o varios tipos de terpenoides. Los pelos que cubren varios órganos aéreos son simples.

Las hojas son simples, de margen entero, delgadas y en general lineares o ensiformes, paralelinervadas, alternadas y dísticas, muchas veces equitantes, y con lámina unifacial (con el plano de la hoja paralelo al tallo) o terete (circulares en el corte transversal), a lo largo del tallo a basales, de base envainadora, sin estípulas. En "Geosiris" las hojas son solo escamas y no presentan clorofila.

Las flores de la mayor parte de las iridáceas son grandes y llamativas, perfectas, esto es, son hermafroditas con órganos femeninos y masculinos funcionales. Además, son pentacícilicas ya que poseen cinco verticilos o ciclos de piezas florales: dos ciclos constituyen el perigonio, un ciclo forma el androceo y el último verticilo conforma el gineceo. Con respecto a su simetría, las flores de las iridáceas pueden ser cigomorfas a actinomorfas ya que presentan desde uno a varios planos de simetría. Pueden estar sostenidas a través de un pedicelo, o bien, ser sésiles. En general están encerradas por una a dos brácteas. El perigonio está compuesto por tres piezas externas de sépalos petaloideos y tres piezas internas de pétalos, los que colectivamente se denominan tépalos ya que no difieren en cuanto a su textura o color. El perigonio, no obstante, puede ser homoclamídeo —"Sysirinchium"— o heteroclamídeo —"Moraea, Iris, Trimezia"— según si la forma de los tépalos externos difiere de la de los tépalos internos. Los tépalos internos pueden ser más pequeños y más erectos que los externos, como en el caso de muchas especies de "Iris" y algunas de "Moraea", estar muy reducidos y curvados hacia abajo, como en el caso de los miembros del subgénero "Scorpiris"; o directamente pueden faltar, como ocurre en "Patersonia". Los tépalos usualmente son grandes, imbricados, vistosos, a veces punteados, y pueden ser libres o estar unidos en sus bases, hasta formando un tubo prominente en el caso de los miembros de "Ixioideae" el que puede tener una longitud de hasta 20 cm como en el caso de "Iris unguicularis". Los tépalos externos en el caso de las tribus "Irideae" y "Tigrideae" pueden diferenciarse en dos porciones y la porción proximal se denomina «garra». Las garras, especialmente en los tépalos internos, son frecuentemente pilosas y están cubiertos de manchas o marcas y, a menudo, están cubiertos de glándulas. En los tépalos externos de las especies del subgénero "Iris" se hallan las guías de néctar, las que se encuentran cubiertas de pelos largos y multicelulares que forman lo que se conoce como «barba» y que explica su denominación popular de «iris barbados». El androceo está formado por tres estambres, excepcionalmente solo dos como en el caso de "Diplarrhena", los que se hallan insertos en la base de los tépalos externos. Los estambres pueden disponerse separados entre sí o estar unidos por sus filamentos formando un tubo, lo que conforma un androceo monadelfo. La posición de los estambres es variable, ya que pueden disponerse radial o unilateralmente. Las anteras a veces se hallan unidas a las ramas del estilo, son de dehiscencia longitudinal y extrorsa o poricida. El polen usualmente es monosulcado. El gineceo está constituido por tres carpelos unidos entre sí y es de ovario ínfero, a excepción de "Isophysis" que posee ovario súpero y por esa razón, al menos parcialmente, se halla segregado en su propia subfamilia, "Isophysidae". El ovario presenta tres cavidades o lóculos, cada uno de los cuales lleva desde uno a varios óvulos con placentación axilar y, más raramente, parietal. Los óvulos suelen ser anátropos o campilótropos y bitégmicos. El estilo es filiforme, terminal, usualmente con tres ramas o con tres lóbulos, las ramas a veces se hallan expandidas y son petaloideas, como ocurre en muchas especies de "Iridoideae". El estigma es trífido, a veces bífido, terminal o bien, dispuesto en la cara abaxial de las ramas del estilo. Los nectarios se hallan en los septos del ovario, en la base de los tépalos externos, en los tépalos internos ("Tigridia"), en la base de los estambres ("Iris") o bien, pueden estar ausentes, como en el caso del género "Sisyrinchium".

Las flores son solitarias o bien se hallan en varios tipos de inflorescencias terminales por lo común sostenidas por una bráctea. Los tipos de inflorescencia pueden ser umbelas, ripidios, muchas veces altamente modificadas, o espigas. Los ripidios están cubiertos por dos brácteas (espatas) opuestas, usualmente grandes, foliosas o secas. Cada flor en las espigas presenta dos brácteas opuestas. En "Geosiris" la inflorescencia es subterránea.

El fruto es una cápsula loculicida normalmente dehiscente, puede ser dura o cartilaginosa y en ocasiones leñosa. Las semillas son entre globulares a angulosas (en forma de prisma) o incluso discoidales y pueden presentar alas, arilo o una cubierta seminal, normalmente con estructura celular y de tono amarronado. El endosperma es duro y contiene hemicelulosa, aceite y proteína. En su interior se ubica un pequeño embrión.

Ampliamente distribuidas, siendo especialmente diversas en el sur de África. Las especies de esta familia ocupan hábitats muy diversos, tanto en climas tropicales, subtropicales como templados. La mayoría de las especies de "Iridaceae" se hallan adaptadas a climas estacionales que presentan períodos excesivamente secos o fríos, desfavorables para el crecimiento vegetal, y en los cuales estas plantas entran en reposo. De hecho, la mayoría de las especies son caducifolias. Las especies perennifolias se hallan restringidas en su distribución a los bosques subtropicales, a las sabanas y a las estepas templadas. En las especies deciduas, la parte aérea (tallos y hojas) se seca durante el período desfavorable y las plantas entran en reposo gracias a que poseen órganos subterráneos de supervivencia y de reserva de nutrientes (rizomas, bulbos y cormos). Esta adaptación es particularmente ventajosa para todas las iridáceas que habitan comunidades que soportan incendios periódicos durante la estación seca. En esos períodos, las plantas se hallan en reposo y de ese modo sobreviven al calor del fuego. Los incendios limpian de vegetación la superficie, eliminando la competencia y, además, aportan nutrientes al suelo a través de las cenizas. Cuando las primeras lluvias caen, los bulbos, cormo (tallo subterráneo)s y rizomas comienzan a brotar rápidamente, iniciando un nuevo período de crecimiento y desarrollo sostenido por las reservas acumuladas en sus tejidos durante la estación previa.

Las iridáceas presentan una gran variabilidad en su ecología reproductiva y una gran diversidad de tipos y estructuras florales congruentes con la adaptación a la polinización por animales (zoofilia). La mayoría de las especies son entomófilas y son polinizadas por diversos órdenes de insectos (especialmente escarabajos, abejas y moscas), mientras que otras son polinizadas por pájaros (ornitófilas). Las recompensas florales son néctar o polen.

Las semillas usualmente son dispersadas por viento o agua, pero también ocurre dispersión biótica.

La mayoría de las especies que componen este género florecen en verano, cuando las hojas ya están secas. Las flores, actinomorfas a cigomorfas, son usualmente de color rosado o rojo, si bien también hay especies con flores de color blanco, amarillo, marrón o crema. El género presenta dos números cromosómicos básicos, x= 15 y 16.

La biología de la polinización de "Tritoniopsis" es bastante sorprendente. Hay especies que presentan flores con los tépalos unidos en sus bases formando un tubo corto y de color rosado que son polinizadas por abejas que buscan su néctar. A partir de estos caracteres florales, considerados ancestrales, se han derivado varios modos más especializados de polinización durante la evolución del género. Así, cuatro especies con tubos florales alargados y con perianto bilabiado rosado o rojo son polinizadas por pájaros del género "Nectarinia" ("Passeriformes") o bien por la mariposa "Aeropetes tulbaghia". Otras dos especies con flores rosadas con márgenes rojos son polinizadas por moscas del género "Prosoeca" ("Nemestrinidae"). "Tritoniopsis parviflora", finalmente, se considera única entre las iridáceas de Sudáfrica, ya que además de presentar néctar azucarado, produce aceite en las flores como recompensa para la abeja "Redivia gigas" ("Melittidae").

Las iridáceas son una de las familias más grandes y mejor estudiadas dentro del orden "Asparagales", se distingue de las otras familias de aspargales debido a la estructura única de su inflorescencia (un ripidio) y su combinación de ovario ínfero con tres estambres. En las iridáceas también son comunes las hojas unifaciales, mientras que las hojas bifaciales son la norma en las restantes asparagales.

La divergencia entre las doryantáceas y las iridáceas ocurrió hace aproximadamente 82 millones de años, durante el período Campaniense del Cretácico. "Isophysis" es el único miembro viviente de las iridáceas que es hermano de todos los demás integrantes de la familia, de los cuales divergió hace unos 66 millones de años, en el período Maastrichtiense.
La familia se originó en el Hemisferio Sur, cuando Australia estaba unida a la Antártida formando un solo supercontinente que se hallaba a latitudes mayores, antes de que ocurriera una glaciación significativa. Los dos clados más grandes de la familia divergieron hace 61 millones de años en el Cretácico tardío. Los análisis filogenéticos basados en la morfología y en las secuencias de ADN indican que las iridáceas constituyen un clado monofilético. Los caracteres morfológicos analizados en forma independiente ubicaron a las iridáceas dentro del orden de las liliales, mientras que las secuencias de ADN, o el análisis conjunto de datos morfológicos y moleculares, la ubican dentro de las asparagales.

Tres clados grandes son evidentes dentro de "Iridaceae":

Muchas especies de iridáceas han sido estudiadas con respecto a su número cromosómico y cariotipo. Tales estudios han permitido determinar el número cromosómico básico de casi todos los géneros (los cuales varían desde x=6 hasta x=16) y delinear cuáles han sido los cambios cromosómicos que han acompañado la evolución de las iridáceas, desde su centro de diversificación en el sur de África hasta su actual distribución global. La reducción disploide (o sea, la disminución progresiva del número cromosómico básico como consecuencia de rearreglos cromosómicos) ha jugado un papel fundamental en la evolución de varios géneros, tales como "Gladiolus, Romulea, Crocus, Iris, Morea" y "Sisyrinchium." Todos estos géneros presentan varios números cromosómicos básicos y una especialización adaptativa que ha acompañado los cambios a nivel cromosómico. Un ejemplo de estos cambios en el número cromosómico lo ofrece "Gladiolus". En este género el número cromosómico básico más frecuente es x=15, con una gran mayoría de especies diploides (2n=30) en África. No obstante, para varias especies africanas se han informado otros números cromosómicos básicos. Así, "G. atropurpureus" presenta x = 12 (2n = 24 y 36); "G. serapiflorus", "G. gregarius," y "G. pseudospicatus" son diploides con x = 11 (2n = 22); "G. unguiculatus" presenta x = 13 (2n = 26) y x = 12 (2n = 24); mientras que "G. actinomorphanthus" presenta x = 14 (2n = 28). Estos números básicos x= 10, 11, 12, 13 y 14 se han originado por disploidía a partir de x = 15. Debido a que todas estas especies no se encuentran relacionadas desde el punto de vista morfológico, la reducción disploide en "Gladiolus" ha ocurrido en varias oportunidades durante la evolución del género, aparentemente en 4 linajes diferentes. Los cambios en el número cromosómico básico no estuvieron acompañados con reducciones en la cantidad de ADN nuclear ya que las mediciones de la longitud cromosómica total indican que todas las especies diploides presentan aproximadamente la misma cantidad de material cromosómico, con independencia del número básico de cromosomas. Finalmente, en África la poliploidía en las especies de "Gladiolus" es infrecuente, pero en las especies euroasiáticas es la regla más que la excepción. De hecho, el análisis cromosómico de las entidades europeas "G. atroviolaceus, G. communis, G. illyricus, G. imbricatus" y " G. italicus" indicó que no existen poblaciones diploides, sino que la mayoría de esos taxones forman series poliploides (3x, 4x, 6x, 8x y 12x) basadas en el número básico x = 15.

El nombre de la familia se basa en el del género "Iris", el mayor y más conocido de Europa y cuyo origen se remonta a 1753, cuando Carlos Linneo viendo el extenso colorido de sus especies lo nombró como la diosa griega Iris. Este es un nombre conservado, de modo que incluso si un nombre anterior llega a ser descubierto para la familia, el nombre «"Iridaceae"» seguiría siendo válido. Se atribuye a la obra de 1789 de Antoine Laurent de Jussieu "Genera plantarum secundum ordines naturales disposita, juxta methodum in horto Regio Parisiensi exaratum anno 1774".

La familia ha sido aceptada en todos los grandes sistemas de clasificación del siglo XX. En el sistema de Cronquist es tratada como parte del orden "Liliales" dentro de la subclase "Liliidae", el sistema de Takhtajan la colocó en su propio orden —"Iridales"— junto con "Isophysidaceae" y "Geosiridaceae", las cuales fueron tratadas como familias separadas con un solo género cada una, y en el sistema de Thorne es tratada como parte del orden "Orchidales", en su propio suborden, "Iridineae". En el sistema creado por el Grupo para la filogenia de las angiospermas en 1998, 2003 y 2009 (APG, APG II y APG III, respectivamente) se coloca a las iridáceas en el orden de las asparagales, que forma parte a su vez de un clado llamado «monocotiledóneas no commelinóideas».

Sobre la base de la morfología floral y vegetativa, la anatomía, la embriología, la ultraestructura del polen, el análisis cromosómico y la quimiosistemática de compuestos flavonoides, la familia "Iridaceae" ha sido subdividida por el botánico Peter Goldblatt en cuatro subfamilias, las cuales se corresponden con los cuatro linajes principales que sugiere el análisis filogenético:

La familia comprende aproximadamente 70 géneros y más de 1600 especies, distribuidas por todo el globo, con una marcada concentración de especies en el Hemisferio Sur y el mayor centro de radiación en África, al sur del Sahara.

Muchas especies de Iridaceae presentan una gran importancia económica en la horticultura ornamental y en la industria de la flor cortada, especialmente "Gladiolus", "Freesia", "Sparaxis", "Iris", "Tigridia" («flor tigre»), "Ixia" («lirio del maíz»), "Romulea", "Neomarica", "Moraea" («lirio mariposa»), "Nemastylis", "Belamcanda", "Sisyrinchium" («pasto de ojos azules»), "Crocosmia", y "Trimezia". Muchos otros géneros ("Watsonia", "Crocus", "Dietes", "Tritonia", "Hesperantha" y "Neomarica") se cultivan en jardines en regiones tropicales y templadas, como plantas perennes y bulbosas.

"Moraea" y "Homeria" son dos géneros de plantas venenosas y representan un problema en las regiones productoras de ovinos y bovinos, notablemente en Sudáfrica.
Numerosas especies de iridáceas han sido utilizadas como plantas alimenticias, condimenticias, ornamentales y medicinales por diferentes culturas a través de los siglos. Los indios Navajo, por ejemplo, utilizaban decocciones de la planta de "Iris missouriensis" Nutt. como emético. Trozos de rizomas de la misma especie eran utilizados para controlar el dolor de muelas o se aplicaba la decocción caliente de la planta en los oídos para calmar la otitis. Las raíces pisadas de "Iris versicolor" L. se aplicaban en las heridas, probablemente como antiséptico y las infusiones de las raíces secas se suministraban para calmar cualquier dolor. En Hawái, "Sisyrinchium acre" se utilizaba de diversos modos. Las hojas y el jugo que se podía extraer de ellas se utilizaban para dar color azul a los tatuajes. Las hojas, maceradas con sal, azúcar y otras especies se recomendaba para limpiar y curar enfermedades de la piel. En India, "Iris ensata" se usaba como antihelmíntico, depurativo, diurético y vermífugo y, junto con otras especies, en el tratamiento de afecciones venéreas. El lirio leopardo ("Iris domestica") tiene una larga historia de uso en la medicina tradicional china ya que aparentemente es muy efectiva para controlar enfermedades causadas por bacterias, hongos y virus, como así también para disminuir la fiebre o disminuir inflamaciones. Las raíces de esta especie se cosechaba en el verano o el otoño y se secaba para usar más tarde. Otra Iridácea muy utilizada en medicina popular durante siglos es el azafrán ("Crocus sativus"). Los usos eran múltiples: antiespasmódico, afrodisíaco, carminativo, expectorante, narcótico, sedativo y estimulante, siendo en la actualidad reemplazado por medicinas menos onerosas.

La raíz de orris son los rizomas secos de "Iris germanica", "Iris florentina" o "Iris pallida". Antiguamente se utilizaba en medicina herbal occidental y, en la actualidad, se usa principalmente como fijador y nota de base en perfumería, como así también como ingrediente de muchas marcas de ginebra.

La flor de lis (en el francés original "fleur de l'iris") de la heráldica es una flor estilizada de una especie del género "Iris". Específicamente, se trata de "Iris pseudacorus", una especie común al borde de los cursos de aguas en Francia. Se utiliza como un diseño decorativo o como un símbolo. Puede tener, a un mismo tiempo, un significado religioso, político, dinástico, artístico, emblemático o simbólico.

La flor de lis se ha usado en heráldica desde hace siglos. En el siglo XII, Luis VI y Luis VII fueron los primeros monarcas franceses en usarla en su escudo. Los reyes ingleses la usaron más tarde en sus armas para enfatizar sus reclamos sobre el trono de Francia. En el siglo XIV, se incorporó a menudo en las insignias de familia que se cosían en el manto del caballero, que era usado por su propietario sobre la cota de mallas, de ahí el término «manto de armas».

Durante el siglo XX el símbolo de la flor de lis fue adoptado por el Movimiento Scout Mundial, organización presente en todo el mundo. Los scouts la representan sobre fondo de color violeta morado, pintada en blanco o plateado y rodeada por cuerda que acaba en un nudo «llano» (nudo de la hermandad), y con dos estrellas de cinco picos en los pétalos exteriores. Cada pétalo representa uno de los tres principios y deberes (hogar, sociedad y creencia) y tres virtudes (abnegación, lealtad y pureza) que todo Scout debe seguir y tener. Las estrellas representan la vida al aire libre y los diez artículos de la ley scout.

Existen especies de iridáceas que se consideran vulnerables o amenazadas de extinción. Las causas pueden ser la degradación de su hábitat natural o una distribución muy restringida. Según la Lista Roja de la IUCN las siguientes especies son vulnerables o se hallan amenazadas: "Gladiolus pole-evansii", "Gladiolus usambarensis", "Moraea callista", "Moraea stagnalis", "Mastigostyla orurensis", "Stahlia monosperma", "Crocus cyprius", "Crocus etruscus", "Crocus hartmannianus", "Iris boissieri", "Mastigostyla orurensis", "Romulea antiatlantica", "Romulea aquatica" y "Romulea multisulcata".

















</doc>
<doc id="1492" url="https://es.wikipedia.org/wiki?curid=1492" title="Internet Relay Chat">
Internet Relay Chat

IRC (Internet Relay Chat) es un protocolo de comunicación en tiempo real basado en texto, que permite debates entre dos o más personas. Se diferencia de la mensajería instantánea en que los usuarios no deben acceder a establecer la comunicación de antemano, de tal forma que todos los usuarios que se encuentran en un canal pueden comunicarse entre sí, aunque no hayan tenido ningún contacto anterior. Las conversaciones se desarrollan en los llamados canales de IRC, designados por nombres que habitualmente comienzan con el carácter # o & (este último solo es utilizado en canales locales del servidor). Es un sistema de charlas ampliamente utilizado por personas de todo el mundo.

Los usuarios del IRC utilizan una aplicación cliente para conectarse con un servidor, en el que funciona una aplicación IRCd (IRC daemon o servidor de IRC) que gestiona los canales y las conversaciones murales.

IRC fue creado por Jarkko Oikarinen en agosto de 1988 con el motivo de reemplazar al programa MUT (talk multiusuario) en un BBS llamado OuluBox en Finlandia. Oikarinen se inspiró en el Bitnet Relay Chat el cual operaba en la red Bitnet.

Fue utilizado en el intento de golpe de estado en la Unión Soviética de 1991 para informar a través de un periodo de censura en los medios y por los kuwaitíes durante la Primera Guerra del golfo, eventos tras los cuales el IRC ganó popularidad.

Durante la primera mitad de la década de los 2000 la mayoría de redes vivieron un rápido incremento de usuarios, correspondiente con la popularización de Internet y especialmente de las redes de Chat. Desde entonces, la mayoría de redes ha sufrido un estancamiento o un retroceso en el número de usuarios, a pesar de la mayor implantación de Internet. La caída coincide con la popularización de otro tipo de redes, como la mensajería instantánea o las redes sociales.


Después de la primera implementación de Jarkko Oikarinen, han surgido una gran cantidad de implementaciones distintas de clientes IRC, tanto como programas independientes, como mIRC, Irssi, Konversation o X-Chat de los más populares, como integradas dentro de otros programas, como Chatzilla.

Se destaca también la utilización de distintos scripts, los cuales tienen como finalidad tomar un cliente existente de IRC como plataforma para el desarrollo de distintos scripts los cuales añaden funcionalidades extra y facilitan la operación de diversos clientes IRC.
En este caso se destacan Looksharp, NavIRC, IRCap, Xscript, entre otros.

IRC se definió originalmente como un protocolo de texto plano (extendido posteriormente), al que IANA asignó el puerto 194/TCP.
De todos modos el estándar de facto siempre ha sido utilizar IRC en el puerto 6667/TCP y otros cercanos (por ejemplo los puertos TCP 6660–6669, 7000) para evitar tener que ejecutar el servicio IRCd con privilegios de Root.

Algunos de los programas responsables del funcionamiento del IRC son:

Además de los Servidores y Clientes, en IRC se usan hoy en día diversos programas que entregan servicios tanto a la red en general, como a los usuarios en forma específica.
Algunos servicios como NickServ, ChanServ, MemoServ, HelpServ, HostServ, OperServ y StatServ son básicos en el funcionamiento de las redes de IRC.

Algunos de los servicios más usados en IRC son:


El IRC es popularmente utilizado para hablar, hacer amigos y reunir grupos de gente con los mismos gustos. Para ello, cualquier persona puede iniciar el canal específico.
Además de esto un canal de IRC también es utilizado como sitio para compartir archivos. Los hay especializados en música y en libros, entre otros. Otra modalidad muy utilizada es la de los juegos, en el que se destacan los Cyberjuegos, habiendo cientos de canales en todos los servidores.



</doc>
<doc id="1493" url="https://es.wikipedia.org/wiki?curid=1493" title="Illicium">
Illicium

El género Illicium comprende 45 especies de arbolitos o arbustos aromáticos y pertenece a la familia Schisandraceae. La especie tipo es "I. anisatum" 

Con los caracteres generales de la familia Schisandraceae.


Polinización entomógama, fundamentalmente llevada a cabo por dípteros, atraídos por el olor de las flores similar al pescado, en el caso de "I. floridanum".

La especie con mayor interés económico es el badián, cuyo fruto, denominado anís estrellado, badiana o badiana de China, "Illicium verum", de sabor a anís, por la presencia de anetol, se usan como condimento y en infusión, para tratar las flatulencias de los lactantes (carminativo) y las malas digestiones (eupéptico). 

Otras especies, sin embargo, son tóxicas por contener alcaloides venenosos. Este es el caso de un sucedáneo irregular del anterior, el anís estrellado del Japón, badiana del Japón o shikkimi, "Illicium anisatum", cuyo consumo puro o mezclado con el anterior provoca intoxicaciones, porque contiene sikamina, ácido sikímico, sikimipicrina y los alcaloides tóxicos shikimina y shikimotoxina, neurotóxicos. Los síntomas de envenenamiento incluyen vómitos, convulsiones, revulsión ocular (nistagmo) e irritabilidad alternando con somnolencia, detectadas en lactantes. Pueden resultar gravemente afectados los riñones, el tracto urinario, los órganos digestivos y el sistema nervioso. El ácido siquímico es la substancia base en la obtención del antivírico Oseltamivir. 

Algunas especies de "Illicum" tienen uso en jardinería, por ejemplo "Illicum anisatum", "Illicum floridanum".

El género se distribuye por el sureste de Asia, sureste de los Estados Unidos, México oriental, Cuba, Haití y República Dominicana.





</doc>
<doc id="1495" url="https://es.wikipedia.org/wiki?curid=1495" title="Infinitesimal">
Infinitesimal

Lo infinitesimal o infinitésimo se puede definir como una cantidad infinitamente pequeña, y originalmente fundamentó ciertos razonamientos del cálculo infinitesimal. En la crisis de los fundamentos matemáticos de principios del siglo XIX los infinitésimos fueron abandonados por los matemáticos, aunque siguieron siendo tratados informalmente en las ciencias aplicadas, y se suelen considerar como números en la práctica. Sólo después de la segunda mitad del siglo XX apareció un enfoque totalmente riguroso de los números infinitesimales.

El análisis no estándar introducido en los años 1960 por Abraham Robinson es un enfoque axiomático y riguroso que permite introducir infinitesimales (números hiperreales no nulos cuyo valor absoluto es más pequeño que cualquier número real estándar). Si bien los resultados que pueden lograrse mediante el análisis no estándar pueden ser alcanzados por la teoría estándar de los números reales, existen muchas demostraciones matemáticas y deducciones que son más simples y breves cuando se usan el análisis no estándar. El inverso multiplicativo de un infinitesimal es un número real no estándar ilimitado.

El cálculo infinitesimal fue propuesto inicialmente por Arquímedes. Luego fue utilizado por Isaac Newton y Gottfried Leibniz, en los albores del surgimiento del Análisis matemático moderno, pero posteriormente fue desacreditado por George Berkeley y finalmente olvidado. Durante el siglo XIX Karl Weierstrass y Cauchy comenzaron a utilizar la definición formal de límite matemático, por lo que el cálculo infinitesimal ya no era necesario. Sin embargo durante el siglo XX los infinitesimales fueron rescatados como una herramienta que ayuda a calcular límites de forma simple. Es bastante popular el uso de infinitésimos en la bibliografía rusa.

Otra manera de trabajar con los infinitésimos es considerarlos como números, y no como límites, es decir trabajar en un conjunto formula_1 que contenga más números que los usuales. Se les llaman números hiperreales, y son una creación del análisis no estándar.

Un infinitesimal o infinitésimo es una cantidad infinitamente pequeña. Se puede definir matemáticamente como:

Algunas funciones son infinitésimos en determinados puntos, por ejemplo:

Por lo tanto, toda función cuando tiende a 0 en un punto se denomina infinitésima.


Dadas formula_2 y formula_6


Si dos infinitésimos son equivalentes entonces se puede aproximar uno a otro. Es decir si "f"("x") y "g"("x") son infinitésimos equivalentes cuando formula_12 entonces se puede decir que formula_13 cuando formula_14. Si se presentan como factor o divisor pueden sustituirse uno por otro para el cálculo de límites cuando formula_14.

formula_16 es un infinitésimo cuando formula_17.


formula_16 es un infinitésimo cuando formula_26.

El análisis no estándar es una generalización del análisis real. El análisis no estándar permite definir además de los objetos definibles en la teoría ordinaria de los números reales nuevos objetos denomiandos "externos" o "no estándar". Cualquier objeto (número, conjunto o función) definible en la teoría convencional de los números reales es un objeto "estándar" dentro del análisis no estándar. Junto con los objetos "estándar" el análisis no estándar de Robinson permite introducir "objetos no estándar" como número inifinitesimales o números ilimitados (infinitos) y manejarlos de manera totalmente coherente dentro de la teoría.

La teoría no estándar parte de introducir un nuevo predicado formula_28, ese predicado permite construir un lenguaje formal que incluye a la teoría ordinaria de los números reales pero permite definir nuevos números (concretamente la noción de número "i-pequeño" e "i-grande" permiten construir números infinitesimales y números ilimitados más grandes que cualquier número real estándar u ordinario). El predicado "estándar" se caracteriza por tres axiomas adicionales que no posee la teoría ordinaria de los números reales, y que por tanto crean un lenguaje formal que permite formalizar números adicionales. El análisis no estándar hace un uso crucial de números infinitesimales e ilimitados:

El análisis no estándar por tanto permite construir un conjunto de números que extiende al de los números reales, este conjunto es de los números hiperreales y se representa como formula_29 y en él se pueden definirse reglas aritméticas para los números infinitesimales (inf(·)), ilimitados (Inf(·)), limitados (complemento del anterior: ¬Inf(·)) y apreciables (ni infinitesimos, ni ilimitados: ¬inf(·)∧¬Inf(·)), a partir de estos cuatro conjuntos se tienen las siguientes reglas de Leibniz para las operaciones aritméticas de estos conjuntos:
Para la multiplicación las reglas de Leibniz son las siguientes:




</doc>
<doc id="1498" url="https://es.wikipedia.org/wiki?curid=1498" title="Imperata">
Imperata

Imperata es un género de plantas de la familia de las poáceas. Es originario de zonas tropicales y regiones cálidas y templadas de todo el mundo.
Son hierbas perennes gramíneas rizomatosas nativas de las zonas tropicales y regiones cálidas y templadas de todo el mundo. Tienen tallos sólidos erguidos y sedosas inflorescencias. La especie más conocida es Imperata cylindrica, que es reconocido como una devastadora maleza nociva en muchos lugares y cultivada como planta ornamental en otros.

Tiene hojas con lígula membranosa, truncada, ciliada. Inflorescencia en panícula densa. Espiguillas todas semejantes, articuladas por debajo de las glumas, redondeadas, con 2 flores; la inferior reducida a la lema, y la superior hermafrodita. Pedúnculos con la parte apical ensanchada, ciatiforme. Glumas más largas que las flores, subiguales, con 5-7 nervios. Lema mútica. Palea más corta que la lema. Sin lodículas. Androceo con 2 estambres.
El género fue descrito por Domenico Maria Leone Cirillo y publicado en "Plantarum Rariorum Regni Neapolitani" 2: 26. 1792. La especie tipo es: "Imperata arundinacea" Cirillo. 
Imperata: nombre genérico otorgado en honor del naturalista italiano Ferrante Imperato (1525? – 1615?). 

El número cromosómico básico del género es x = 5 y 10, con números cromosómicos somáticos 2n = 20, 40, 50 y 60 , ya que hay especies diploides y una serie poliploide. Los cromosomas son relativamente pequeños.



</doc>
<doc id="1500" url="https://es.wikipedia.org/wiki?curid=1500" title="Intérprete (informática)">
Intérprete (informática)

En ciencias de la computación, intérprete o interpretador es un programa informático capaz de analizar y ejecutar otros programas. Los intérpretes se diferencian de los compiladores o de los ensambladores en que mientras estos traducen un programa desde su descripción en un lenguaje de programación al código de máquina del sistema, los intérpretes sólo realizan la traducción a medida que sea necesaria, típicamente, instrucción por instrucción, y normalmente no guardan el resultado de dicha traducción.

Usando un intérprete, un solo archivo fuente puede producir resultados iguales incluso en sistemas sumamente diferentes (ejemplo. una PC y una PlayStation 4). Usando un compilador, un solo archivo fuente puede producir resultados iguales solo si es compilado a distintos ejecutables específicos a cada sistema.

Los programas interpretados suelen ser más lentos que los compilados debido a la necesidad de traducir el programa mientras se ejecuta, pero a cambio son más flexibles como entornos de programación y depuración (lo que se traduce, por ejemplo, en una mayor facilidad para reemplazar partes enteras del programa o añadir módulos completamente nuevos), y permiten ofrecer al programa interpretado un entorno no dependiente de la máquina donde se ejecuta el intérprete, sino del propio intérprete (lo que se conoce comúnmente como máquina virtual).

Para mejorar el desempeño, algunas implementaciones de programación de lenguajes de programación pueden interpretar o compilar el código fuente original en una más compacta forma intermedia y después traducir eso al código de máquina (ej. Perl, Python, MATLAB, y Ruby). Algunos aceptan los archivos fuente guardados en esta representación intermedia (ej. Python, UCSD Pascal y Java).

En la actualidad, uno de los entornos más comunes de uso de los intérpretes es en los navegadores web, debido a la posibilidad que estos tienen de ejecutarse independientemente de la plataforma.

Hay un espectro de posibilidades entre la interpretación y la compilación, dependiendo de la cantidad de análisis realizados antes de que el programa sea ejecutado. Por ejemplo, el Emacs Lisp es compilado a bytecode, que es una representación altamente comprimida y optimizada del código fuente del Lisp, pero no es código de máquina (y por lo tanto no está atado a cualquier hardware particular). Este bytecode es entonces interpretado por un intérprete de bytecode (que está escrito en C). En este caso, el código compilado es el código de máquina para una máquina virtual, que no está implementada en el hardware, sino en el intérprete de bytecode. El mismo acercamiento es utilizado con el código Forth usado en sistemas Open Firmware: el lenguaje fuente es compilado en "código F" (un bytecode),

La desventaja principal de los interpretadores es que cuando se interpreta un programa, típicamente corre más lentamente que si hubiera sido compilado. La diferencia en velocidades puede ser minúscula o grande; a menudo un orden de magnitud y a veces más. Generalmente toma más tiempo correr un programa bajo un interpretador que correr el código compilado, pero puede tomar menos tiempo para interpretarlo que el tiempo total requerido para compilarlo y ejecutarlo. Esto es especialmente importante si se está haciendo y probando un código prototipo cuando un ciclo de editar, interpretar y depurar del interpretador, a menudo puede ser mucho más corto que el ciclo de editar, compilar, ejecutar y depurar del compilador.

La interpretación de código es más lenta que la ejecución de código compilado porque el interpretador debe analizar cada sentencia en el programa cada vez que es ejecutada y entonces realizar la acción deseada, mientras que el código compilado solo realiza la acción dentro de un determinado contexto fijo por la compilación. Este análisis en tiempo de ejecución se conoce como "sobrecarga interpretativa". En un interpretador, el acceso a las variables es también más lento porque el mapeo de identificadores hacia las localizaciones de almacenamiento debe hacerse repetidamente en tiempo de ejecución en vez de en el tiempo de compilación. Hay varios compromisos entre la velocidad de desarrollo al usar un interpretador y la velocidad de ejecución al usar un compilador. Algunos sistemas (ej., algunos LISPs) permiten al código interpretado y al compilado llamarse el uno al otro y compartir variables. Esto significa que una vez que una rutina ha sido probada y depurada bajo el interpretador puede ser compilada y por lo tanto beneficiarse de una ejecución más rápida mientras que otras rutinas están siendo desarrolladas. Muchos interpretadores no ejecutan el código fuente tal y como está sino que lo convierten en una forma interna más compacta. Por ejemplo, algunos interpretadores BASIC reemplazan palabras clave (keywords) con tokens de un simple byte que pueden ser usados para encontrar la instrucción en una tabla de saltos. Un interpretador puede bien usar el mismo analizador lexicográfico y el analizador sintáctico (parser) que el compilador y entonces interpretar el árbol de sintaxis abstracta resultante.

En el espectro entre la interpretación y la compilación, otro acercamiento está transformando el código fuente en un árbol de sintaxis abstracta optimizado (AST), y después procediendo a ejecutar el programa siguiendo esta estructura arborescente. En este acercamiento cada sentencia necesita ser analizada (parsed) solo una vez. Como una ventaja sobre el bytecode, el AST mantiene la estructura y las relaciones globales del programa entre las sentencias (que se pierden en una representación de bytecode), y proporciona una representación más compacta.

Así, el AST se ha propuesto como un mejor formato intermedio para los compiladores justo a tiempo que el bytecode. También, permite realizar un mejor análisis durante tiempo de ejecución. Un interpretador Java basado en AST ha demostrado ser más rápido que un interpretador similar basado en bytecode, gracias a las más poderosas optimizaciones permitidas al tener la estructura completa del programa, así como tipos de datos de alto nivel, disponibles durante la ejecución.

Para desdibujar más la distinción entre los interpretadores, los interpretadores de bytecode y la compilación, está la compilación justo a tiempo (o JIT), una técnica en la cual la representación intermedia es compilada a código de máquina nativo en tiempo de ejecución. Esto confiere la eficiencia de ejecutar el código nativo, al costo de tiempo de inicio y de un uso creciente de la memoria cuando el bytecode o el AST es compilado por primera vez. La optimización adaptativa es una técnica complementaria en la cual el interpretador hace un análisis de desempeño del programa que está corriendo (profiling) y compila sus partes más frecuentemente ejecutadas a código nativo. Ambas técnicas tienen algunas décadas, apareciendo en lenguajes tales como Smalltalk en la década de 1980.

En años recientes, la compilación justo a tiempo ha ganado la atención de la mayoría de los implementadores de lenguajes de programación, con Java, Python, y el Microsoft .NET Framework todos ahora incluyendo JITs.

Algunos ejemplos de intérpretes:


Un lenguaje interpretado es un lenguaje de programación para el que la mayoría de sus implementaciones ejecuta las instrucciones directamente, sin una previa compilación del programa a instrucciones en lenguaje máquina. El intérprete ejecuta el programa directamente, traduciendo cada sentencia en una secuencia de una o más subrutinas ya compiladas en código máquina.

Los términos "lenguaje interpretado" y "lenguaje compilado" no están bien definidos porque, en teoría, cualquier lenguaje de programación puede ser interpretado o compilado. Cada vez es más popular, en las implementaciones más modernas de un lenguaje de programación, ofrecer ambas opciones.

Los lenguajes interpretados también pueden diferenciarse de los lenguajes de máquina. Funcionalmente, tanto la ejecución y la interpretación significan lo mismo -obtener la siguiente instrucción/sentencia del programa y su ejecución-. Aunque el "bytecode" (código byte) interpretado es además idéntico a su forma en código máquina y tiene una representación en ensamblador, el término "interpretado" se reserva en la práctica para lenguajes "procesados por software" (como las máquinas virtuales o emuladores) por encima del procesado nativo (por ejemplo, por hardware).

En principio, los programas de muchos lenguajes se pueden compilar o interpretar, emular o ejecutar nativamente, así que esta designación se aplica solamente a la implementación práctica más usual, en vez de representar una propiedad esencial del lenguaje. De forma parecida al microcódigo del procesador, muchos intérpretes, internamente recaen en una compilación en tiempo de ejecución.

Evitando la compilación, los programas interpretados son más fáciles de evolucionar durante el desarrollo y la ejecución (transformándose en ocasiones de uno en la otra). De otra parte, ya que la compilación implica una traducción a un formato más amigable con la máquina, los programas interpretados corren más lentamente y menos eficientemente (es decir, gastan considerablemente más energía). Esto es especialmente verdad para los lenguajes de guion, cuyas sentencias son más complejas de analizar comparadas con las instrucciones máquina.

Muchos lenguajes se han implementado usando tanto compiladores como intérpretes, incluyendo BASIC, C, Lisp, Pascal y Python. Java y C# se compilan a código byte, el lenguaje interpretado específico para la máquina virtual. Muchas implementaciones de Lisp pueden mezclar libremente código interpretado y compilado.

En los comienzos de la computación, el diseño de lenguajes fue fuertemente influenciado por la decisión de usar la compilación o la interpretación como modos de ejecución. Por ejemplo, algunos lenguajes compilados requieren que los programas deban indicar explícitamente el tipo de dato de una variable en el momento en que sea declarada o al ser usada por primera vez, mientras que algunos lenguajes interpretados toman ventaja de los aspectos dinámicos de la interpretación para hacer tales declaraciones innecesarias. Por ejemplo, Smalltalk (1980), que fue diseñado para ser interpretado en tiempo de ejecución, permite a objetos genéricos interactuar dinámicamente entre sí.

Inicialmente, los lenguajes interpretados eran compilados línea por línea, es decir, cada línea era compilada a medida que estaba a punto de ser ejecutada, y si un bucle o una subrutina hicieran que ciertas líneas se ejecutaran múltiples veces, serían recompiladas repetidamente. Esto ha llegado a ser mucho menos común. La mayoría de los lenguajes interpretados usan una representación intermedia, que combina tanto la compilación como la interpretación. En este caso, un compilador puede producir el código byte o el código enhebrado, que entonces es ejecutado por un intérprete de código byte.

Los ejemplos incluyen:

La representación intermedia se puede compilar una sola vez (como en Java), cada vez que se vaya a ejecutar (como en Perl o Ruby), o cada vez que se detecte un cambio en el código fuente antes de la ejecución (como en Python).

Interpretar un lenguaje da a las implementaciones una flexibilidad adicional sobre las implementaciones compiladas. Algunas características son más fáciles de implementar en intérpretes que en compiladores son (pero no se limitan a estas):


La principal desventaja de la interpretación es una velocidad de ejecución del programa mucho más lenta, comparada con la ejecución directa del código máquina en la CPU del ordenador. Una técnica utilizada para mejorar las prestaciones es la compilación en tiempo de ejecución, que convierte las secuencias ejecutadas más frecuentes en código máquina del ordenador.


Muchos lenguajes interpretados son primero compilados a código byte, que luego es normalmente interpretado por la máquina virtual usando la compilación en tiempo de ejecución, del código byte a código nativo. Sin embargo, algunas veces, el código byte también puede ser compilado a un binario nativo usando un compilador "Ahead-of-time compilation" (compilación por adelantado), o ejecutado nativamente, por el procesador hardware.





</doc>
<doc id="1501" url="https://es.wikipedia.org/wiki?curid=1501" title="Intérprete">
Intérprete

El término intérprete puede estar vinculado o referido a los artículos de Wikipedia que se indican a continuación:


</doc>
<doc id="1503" url="https://es.wikipedia.org/wiki?curid=1503" title="Inteligencia artificial">
Inteligencia artificial

La inteligencia artificial (IA), también llamada inteligencia computacional, es la inteligencia exhibida por máquinas. En ciencias de la computación, una máquina «inteligente» ideal es un agente racional flexible que percibe su entorno y lleva a cabo acciones que maximicen sus posibilidades de éxito en algún objetivo o tarea. Coloquialmente, el término inteligencia artificial se aplica cuando una máquina imita las funciones «cognitivas» que los humanos asocian con otras mentes humanas, como por ejemplo: "aprender" y "resolver problemas". A medida que las máquinas se vuelven cada vez más capaces, tecnología que alguna vez se pensó que requería de inteligencia se elimina de la definición. Por ejemplo, el reconocimiento óptico de caracteres ya no se percibe como un ejemplo de la "inteligencia artificial" habiéndose convertido en una tecnología común. Avances tecnológicos todavía clasificados como inteligencia artificial son los sistemas capaces de jugar ajedrez, GO y manejar por si mismos.

Según Tayekas (2007) la IA es una rama de las ciencias computacionales encargada de estudiar modelos de cómputo capaces de realizar actividades propias de los seres humanos en base a dos de sus características primordiales: el razonamiento y la conducta.

En 1956, John McCarthy acuñó la expresión «inteligencia artificial», y la definió como: "...la ciencia e ingenio de hacer máquinas inteligentes, especialmente programas de cómputo inteligentes".

Para Nils John Nilsson son cuatro los pilares básicos en los que se apoya la inteligencia artificial:


También existen distintos tipos de percepciones y acciones, que pueden ser obtenidas y producidas, respectivamente, por sensores físicos y sensores mecánicos en máquinas, pulsos eléctricos u ópticos en computadoras, tanto como por entradas y salidas de bits de un software y su entorno software.

Varios ejemplos se encuentran en el área de control de sistemas, planificación automática, la habilidad de responder a diagnósticos y a consultas de los consumidores, reconocimiento de escritura, reconocimiento del habla y reconocimiento de patrones. Los sistemas de IA actualmente son parte de la rutina en campos como economía, medicina, ingeniería y la milicia, y se ha usado en gran variedad de aplicaciones de software, juegos de estrategia, como ajedrez de computador, y otros videojuegos.

Búsqueda heurística. Podemos definir una heurística como un truco o estrategia que limita grandiosamente la búsqueda de soluciones ante grandes espacios de problemas.
Por lo tanto, ante un problema, nos ayuda a seleccionar las bifurcaciones dentro de un árbol con más posibilidades; con ello se restringe la búsqueda, aunque no siempre se garantiza una solución adecuada. Todo lo que se debe tener en cuenta para que una heurística sea adecuada es que nos proporcione soluciones que sean lo suficientemente buenas.
Además, con la utilización de la búsqueda heurística, no será necesario replantear un problema cada vez que se afronte, ya que si ya ha sido planteado anteriormente, ésta sugerirá la forma en que se ha de proceder para resolverlo.

Representación del conocimiento. La representación es una cuestión clave a la hora de encontrar soluciones adecuadas a los problemas planteados.
Si analizamos más detenidamente el término encontramos varias definiciones: según Barr y Feigenbaum, la representación del conocimiento es una combinación de estructuras de datos y procedimientos de interpretación que, si son utilizados correctamente por un programa, éste podrá exhibir una conducta inteligente; según Fariñas y Verdejo, la Inteligencia Artificial tiene como objetivo construir modelos computacionales que al ejecutarse resuelvan tareas con resultados similares a los obtenidos por una persona, por lo que el tema central de esta disciplina es el estudio del conocimiento y su manejo; y según Buchanan y Shortliffe, la Representación del Conocimiento en un programa de Inteligencia Artificial significa elegir una serie de convenciones para describir objetos, relaciones, y procesos en el mundo.
Gran parte del esfuerzo realizado en la consecución de ordenadores inteligentes, según Rahael, ha sido caracterizado por el intento continuo de conseguir más y mejores estructuras de representación del conocimiento, junto con técnicas adecuadas para su manipulación, que permitiesen la resolución inteligente de algunos de los problemas ya planteados.
Otra característica importante es la inclusión en los programas de Inteligencia artificial, aunque por separado, de los conocimientos y la unidad que controla y dirige la búsqueda de soluciones. Dada esta disposición, en estos programas la modificación, ampliación y actualización de los mismos es sencilla.

El razonamiento que puede tener cualquier persona, ha demostrado ser una de los aspectos más difíciles de modelar "dentro" de un ordenador. El sentido común a menudo nos ayuda a prever multitud de hechos y fenómenos corrientes, pero, como ya hemos dicho, es muy complicado representarlos en un ordenador, dado que los razonamientos son casi siempre inexactos y que sus conclusiones y reglas en las que se basan solamente son aproximadamente verdaderas.

Lenguajes, entornos y herramientas de Inteligencia Artificial. En la Inteligencia Artificial, se han desarrollado diferentes lenguajes específicos para los diferentes campos de aplicación.
Estos lenguajes en su mayoría cuentan con una serie de características comunes que podemos resumir de la siguiente forma:
Este tipo de software ofrece una gran modularidad.
Poseen gran capacidad de tomar decisiones de programación hasta el último momento, es decir cuando el programa ya está ejecutándose.
Ofrecen grandes facilidades en el manejo de listas, y esto es importante, ya que las listas son la estructura más habitual usada para la representación del conocimiento en la Inteligencia Artificial.
Facilitan la realización de ciertos tipos de deducción automática permitiendo también la creación de una base de hechos (lugar donde se recogen los datos iniciales del problema a resolver y los resultados intermedios una vez obtenidos).
Permite el uso simultáneo de estructuras que incorporan conocimiento declarativo y conocimiento procedimental.
Tienen una marcada orientación gráfica. Además, las herramientas de Inteligencia Artificial permiten hacer un seguimiento de todos los cambios realizados a lo largo de toda la sesión
Disponen herramientas capaces de desarrollar programas que son capaces de comprender otros programas y también de realizar modificaciones sobre ellos.

Stuart Russell y Peter Norvig diferencian estos tipos de la inteligencia artificial:

La IA se divide en dos escuelas de pensamiento:

Se conoce también como IA simbólico-deductiva. Está basada en el análisis formal y estadístico del comportamiento humano ante diferentes problemas:

La Inteligencia Computacional (también conocida como IA subsimbólica-inductiva) implica desarrollo o aprendizaje interactivo (por ejemplo, modificaciones interactivas de los parámetros en sistemas de conexiones). El aprendizaje se realiza basándose en datos empíricos.


El concepto de IA es aún demasiado difuso. Contextualizando, y teniendo en cuenta un punto de vista científico, podríamos definir esta ciencia como la encargada de imitar el cerebro, que no el cuerpo, de una persona en todas sus funciones. Estas pueden ser las ya existentes en el humano o bien otras novedosas e incorporadas en el desarrollo de una máquina inteligente.

En relación a la conciencia y las emociones, y aunque por el momento la mayoría de los investigadores en el ámbito de la Inteligencia Artificial se centran sólo en el aspecto racional, hay expertos que consideran seriamente la posibilidad de incorporar componentes «emotivos» como "indicadores de estado", a fin de aumentar la eficacia de los sistemas inteligentes en determinadas situaciones.

A diferencia de los humanos, hay términos que la Inteligencia Artificial no puede comprender o entender conceptos humanos como el amor, el matrimonio, el sentido de la vida, el libre albedrío el cariño o las emociones humanas

Particularmente, en el caso de los robots móviles, es necesario que estos cuenten con algo similar a las emociones con el objeto de saber –en cada instante y como mínimo– qué hacer a continuación [Pinker, 2001, p. 481].

Al tener «sentimientos» y, al menos potencialmente, «motivaciones», podrán actuar de acuerdo con sus «intenciones» [Mazlish, 1995, p. 318]. Así, se podría equipar a un robot con dispositivos que controlen su medio interno; por ejemplo, que «sientan hambre» al detectar que su nivel de energía está descendiendo o que «sientan miedo» cuando este esté demasiado bajo.

Esta señal podría interrumpir los procesos de alto nivel y obligar al robot a conseguir el preciado elemento [Johnson-Laird, 1993, p. 359]. Incluso se podría introducir el «dolor» o el «sufrimiento físico», a fin de evitar las torpezas de funcionamiento como, por ejemplo, introducir la mano dentro de una cadena de engranajes o saltar desde una cierta altura, lo cual le provocaría daños irreparables.

Esto significa que los sistemas inteligentes deben ser dotados con mecanismos de retroalimentación que les permitan tener conocimiento de estados internos, igual que sucede con los humanos que disponen de propiocepción, interocepción, nocicepción, etcétera. Esto es fundamental tanto para tomar decisiones como para conservar su propia integridad y seguridad. La retroalimentación en sistemas está particularmente desarrollada en cibernética: por ejemplo, en el cambio de dirección y velocidad autónomo de un misil, utilizando como parámetro la posición en cada instante en relación al objetivo que debe alcanzar. Esto debe ser diferenciado del conocimiento que un sistema o programa computacional puede tener de sus estados internos, por ejemplo la cantidad de ciclos cumplidos en un loop o bucle en sentencias tipo "do... for", o la cantidad de memoria disponible para una operación determinada.

A los sistemas inteligentes el no tener en cuenta elementos emocionales les permite no olvidar la meta que deben alcanzar. En los humanos el olvido de la meta o el abandonar las metas por perturbaciones emocionales es un problema que en algunos casos llega a ser incapacitante. Los sistemas inteligentes, al combinar una memoria durable, una asignación de metas o "motivación", junto a la toma de decisiones y asignación de prioridades con base en estados actuales y estados meta, logran un comportamiento en extremo eficiente, especialmente ante problemas complejos y peligrosos.

En síntesis, lo racional y lo emocional están de tal manera interrelacionados entre sí, que se podría decir que no sólo no son aspectos contradictorios sino que son –hasta cierto punto– complementarios.

Las principales críticas a la inteligencia artificial tienen que ver con su capacidad de imitar por completo a un ser humano. Sin embargo, hay expertos en el tema que indican que ningún humano individual tiene capacidad para resolver todo tipo de problemas, y autores como Howard Gardner han teorizado que existen inteligencias múltiples. Un sistema de inteligencia artificial debería resolver problemas por lo que es fundamental en su diseño la delimitación de los tipos de problemas que resolverá y las estrategias y algoritmos que utilizará para encontrar la solución.

En los humanos, la capacidad de resolver problemas tiene dos aspectos: los aspectos innatos y los aspectos aprendidos. Los aspectos innatos permiten, por ejemplo, almacenar y recuperar información en la memoria, mientras que en los aspectos aprendidos reside el saber resolver un problema matemático mediante el algoritmo adecuado. Del mismo modo que un humano debe disponer de herramientas que le permitan solucionar ciertos problemas, los sistemas artificiales deben ser programados de modo tal que puedan llegar a resolverlos.

Muchas personas consideran que el test de Turing ha sido superado, citando conversaciones en que al dialogar con un programa de inteligencia artificial para chat no saben que hablan con un programa. Sin embargo, esta situación no es equivalente a un test de Turing, que requiere que el participante esté sobre aviso de la posibilidad de hablar con una máquina.

Otros experimentos mentales como la Habitación china, de John Searle, han mostrado cómo una máquina podría simular pensamiento sin realmente poseerlo, pasando el test de Turing sin siquiera entender lo que hace, tan solo reaccionando de una forma concreta a determinados estímulos (en el sentido más amplio de la palabra). Esto demostraría que la máquina en realidad no está pensando, ya que actuar de acuerdo con un programa preestablecido sería suficiente. Si para Turing el hecho de engañar a un ser humano que intenta evitar que le engañen es muestra de una mente inteligente, Searle considera posible lograr dicho efecto mediante reglas definidas a priori.

Uno de los mayores problemas en sistemas de inteligencia artificial es la comunicación con el usuario. Este obstáculo es debido a la ambigüedad del lenguaje, y se remonta a los inicios de los primeros sistemas operativos informáticos. La capacidad de los humanos para comunicarse entre sí implica el conocimiento del lenguaje que utiliza el interlocutor. Para que un humano pueda comunicarse con un sistema inteligente hay dos opciones: o bien que el humano aprenda el lenguaje del sistema como si aprendiese a hablar cualquier otro idioma distinto al nativo, o bien que el sistema tenga la capacidad de interpretar el mensaje del usuario en la lengua que el usuario utiliza.

Un humano, durante toda su vida, aprende el vocabulario de su lengua nativa o materna, siendo capaz de interpretar los mensajes (a pesar de la polisemia de las palabras) utilizando el contexto para resolver ambigüedades. Sin embargo, debe conocer los distintos significados para poder interpretar, y es por esto que lenguajes especializados y técnicos son conocidos solamente por expertos en las respectivas disciplinas. Un sistema de inteligencia artificial se enfrenta con el mismo problema, la polisemia del lenguaje humano, su sintaxis poco estructurada y los dialectos entre grupos.

Los desarrollos en inteligencia artificial son mayores en los campos disciplinares en los que existe mayor consenso entre especialistas. Un sistema experto es más probable que sea programado en física o en medicina que en sociología o en psicología. Esto se debe al problema del consenso entre especialistas en la definición de los conceptos involucrados y en los procedimientos y técnicas a utilizar. Por ejemplo, en física hay acuerdo sobre el concepto de velocidad y cómo calcularla. Sin embargo, en psicología se discuten los conceptos, la etiología, la psicopatología y cómo proceder ante cierto diagnóstico. Esto dificulta la creación de sistemas inteligentes porque siempre habrá desacuerdo sobre la forma en que debería actuar el sistema para diferentes situaciones. A pesar de esto hay grandes avances en el diseño de sistemas expertos para el diagnóstico y toma de decisiones en el ámbito médico y psiquiátrico (Adaraga Morales, Zaccagnini Sancho, 1994).

Al desarrollar un robot con inteligencia artificial se debe tener cuidado con la autonomía,hay que tener cuidado en no vincular el hecho de que el robot interaccione con seres humanos a su grado de autonomía. Si la relación de los humanos con el robot es de tipo maestro esclavo, y el papel de los humanos es dar órdenes y el del robot obedecerlas, entonces sí cabe hablar de una limitación de la autonomía del robot. Pero si la interacción de los humanos con el robot es de igual a igual, entonces su presencia no tiene por qué estar asociada a restricciones para que el robot pueda tomar sus propias decisiones.

La animatrónica junto con la inteligencia artificial es lo que da como resultado los androides, como se suele conocer a los robots que imitan el comportamiento humano. Tenemos una técnica capaz de dotar del aspecto y comportamiento de seres vivos a máquinas. Es decir, humanizar' a los robots. Pero ya no sólo hablamos que los movimientos sean muy reales, sino que además, parece real gracias a la piel sintética que han usado y al maquillaje.

La empresa Disney está a punto de usar la animatrónica y la inteligencia artificial para simular uno de sus personajes en la vida real: Pascal, uno de los personajes de la película "Enredados".

Por otro lado, Dubai ya está usando policías robots creados por PAL Robotics.


Las técnicas desarrolladas en el campo de la inteligencia artificial son numerosas y ubicuas. Comúnmente cuando un problema es resuelto mediante inteligencia artificial la solución es incorporada en ámbitos de la industria y de la vida diaria de los usuarios de programas de computadora, pero la percepción popular se olvida de los orígenes de estas tecnologías que dejan de ser percibidas como inteligencia artificial. A este fenómeno se le conoce como el efecto IA.


La mayoría de los juegos de mesa y una gran cantidad de problemas informáticos mediante la modelización del problema en estados con la posterior aplicación de un algoritmo de búsqueda entre estos estados. 

La aplicación más evidente es el control de los PNJ en el juego. La búsqueda de ruta es otro de uso común para la IA, buscar un camino para mover un PNJ de un punto en un mapa a otro, teniendo en cuenta el terreno y evitando los obstáculos. Más allá de búsqueda de caminos, la navegación es un subcampo de la IA del juego que se centra en dar a los PNJ la capacidad de navegar en su entorno, la búsqueda de un camino hacia un objetivo, evitando colisiones con otras entidades o colaborar con ellos. La IA también está involucrada con el equilibrio de la dificultad del juego, que consiste en el ajuste de la dificultad de un juego de videojuego en tiempo real basado en la habilidad del jugador, aumentando la dificultad del juego se aumentaría la capacidad de la IA reduciendo así el "tiempo de reacción" a determinados sucesos.

Una de las aplicaciones de la IA en la que es muy fácil entender el funcionamiento y la programación de la misma es por ejemplo en el tic-tac-toe, es decir, "las tres en raya".¿Cómo podría programarse un juego de este tipo?:

Para empezar, el tablero es una estructura de datos de tipo matriz que contiene unas casillas las cuales están ocupadas por un jugador o vacías. Una partida es una secuencia de estados por los que pasa un tablero. Para programar la inteligencia artificial para que pueda ganarnos debemos hacer que aprenda los distintos estados e ir avanzando por los que pueda ganar:



Normalmente para estos juegos se utiliza la estrategia minimax, la cual imita el comportamiento humano tras examinar un cierto número de jugadas anteriormente. En este enfoque existe una función de evaluación que da un valor a cada posible movimiento.



Definition of AI as the study of intelligent agents:







</doc>
<doc id="1504" url="https://es.wikipedia.org/wiki?curid=1504" title="Ichnanthus">
Ichnanthus

Ichnanthus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del oeste de África tropical. Comprende 155 especies descritas y de estas, solo 33 aceptadas.
Son plantas anuales o perennes; con tallos frecuentemente decumbentes en los nudos inferiores; plantas hermafroditas. Hojas frecuentemente caulinares, en ocasiones basales; lígula una membrana esparcida a densamente ciliada; láminas lanceoladas a ovadas, aplanadas, a menudo con la base asimétrica y angostada, pseudopecioladas o sésiles. Inflorescencia una panícula simple o compuesta, generalmente una terminal y conspicuamente exerta de la vaina superior, en algunas especies con 1–varias panículas axilares menos exertas; espiguillas lanceoloides, pareadas, desigualmente pediceladas, comprimidas dorsalmente pero con las glumas prominentemente carinadas de manera que en muchas especies aparecen comprimidas lateralmente, con 2 flósculos; desarticulación por debajo de las glumas y a veces por debajo del flósculo superior; glumas desiguales, carinadas, la inferior generalmente más de la 1/2 del largo de la espiguilla; gluma superior y lema inferior casi iguales, más largas que el flósculo superior, herbáceas; flósculo inferior estéril o estaminado; pálea inferior membranácea; flósculo superior bisexual, comprimido dorsalmente; lema superior endurecida, la raquilla se continúa por abajo de la lema formando un pequeño pedicelo; pedicelo con apéndices membranáceos adnados en la base de la lema y libres en la parte superior (frecuentemente engrosados con aceite en la madurez), o los apéndices reducidos a pequeñas áreas esclerosadas o cicatrices en la base de la lema; lodículas 2; estambres 3; estilos 2. Fruto una cariopsis ovoide a elipsoide; embrión 1/3–1/2 la longitud de la cariopsis, hilo punteado.

El género fue descrito por Ambroise Marie François Joseph Palisot de Beauvois y publicado en "Essai d'une Nouvelle Agrostographie" 56, pl. 12, f. 1. 1812. La especie tipo es: "Ichnanthus panicoides" P. Beauv. 
Número de cromosomas: 2n = 18, 20, 40, y 54. 
Ichnanthus: nombre genérico que deriva de la palabra griega: "chnos" (un paso o de marca), tal vez se refieren a los apéndices debajo del florete superior. 




</doc>
<doc id="1505" url="https://es.wikipedia.org/wiki?curid=1505" title="Isachne">
Isachne

Isachne, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las regiones tropicales y subtropicales del mundo.
El número cromosómico básico del género es x = 10, con números cromosómicos somáticos 2n = 20, 50, y 60 , ya que hay especies diploides y una serie poliploide.



</doc>
<doc id="1506" url="https://es.wikipedia.org/wiki?curid=1506" title="Ischaemum">
Ischaemum

Ischaemum, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las regiones tropicales y subtropicales del mundo.
El género fue descrito por Carlos Linneo y publicado en "Journal of Botany, British and Foreign" 66: 141. 1928.
El nombre del género deriva del griego "ischaimon" (astringente), nombre dado originalmente a "Digitaria sanguinalis" por sus supuestas cualidades astringentes. 
El número cromosómico básico del género es x = 9 o 10, con números cromosómicos somáticos 2n = 18, 20, 40, 54, 56, y 68 , ya que hay especies diploides y una serie poliploide.

Relación de especies



</doc>
<doc id="1507" url="https://es.wikipedia.org/wiki?curid=1507" title="Ixophorus unisetus">
Ixophorus unisetus

Ixophorus, es un género monotípico de plantas herbáceas perteneciente a la familia de las poáceas. Su única especie "Ixophorus unisetus", es originaria de México, distribuyéndose desde México a Brasil y en Cuba.
Son plantas perennes cespitosas; con tallos de 50–140 cm de largo y 0.6–1 mm de ancho, suculentos, erectos, ramificados con la edad; nudos glabros o ligeramente adpreso pilosos; plantas monoicas. Vainas glabras, carinadas; lígula una membrana lacerada o ciliada, 1–2.5 mm de largo; láminas lineares, hasta 75 cm de largo y 10–25 mm de ancho, aplanadas, laxas, glabras. Inflorescencias terminales y axilares, panículas de racimos, panícula 10–25 cm de largo, cilíndrico-ovoide, racimos numerosos, simples, 2–8 cm de largo, escabrosos; cada espiguilla con una cerda subyacente, 7–12.5 mm de largo, víscida, espiguillas 3.5–4.7 mm de largo, lanceoladas y agudas en la antesis, anchamente ovadas en la madurez, subsésiles en 2 hileras a lo largo de los lados inferiores del raquis triquetro; desarticulación por debajo de las glumas, la espiguilla caediza como una unidad; glumas desiguales, herbáceas, gluma inferior anchamente ovada, 0.7–1.5 mm de largo, aguda, 1–3-nervia, gluma superior y lema inferior 3.5–4.7 mm de largo, ocultando al flósculo superior; flósculo inferior estaminado, con 2 lodículas y 3 estambres, las anteras 2–3.4 mm de largo; pálea inferior 2-carinada, tornándose circular en la madurez, con una base cordada y amplias alas cartáceas, mucho más ancha que el resto de la espiguilla; flósculo superior pistilado, 2–3.3 mm de largo, raramente con estambres rudimentarios; lema superior más corta que la espiguilla, elíptica, endurecida, apiculada, papilosa, los márgenes enrollados hacia adentro; pálea endurecida; lodículas 2; estilos 2. Fruto una cariopsis; embrión ca 1/2 de la longitud de la cariopsis, hilo de 1/3 la longitud de la cariopsis, elíptico.
"Ixophorus unisetus" fue descrito por (J.Presl) Schltdl. y publicado en "Linnaea" 31: 747, 420–422. 1861-1862.



</doc>
<doc id="1509" url="https://es.wikipedia.org/wiki?curid=1509" title="Imperio romano">
Imperio romano

El Imperio romano (en latín: "Imperium Rōmānum", "Senātus Populusque Rōmānus" o "Rēs pūblica populī rōmānī", entre otros nombres) fue el tercer periodo de civilización romana en la Antigüedad clásica, posterior a la República romana y caracterizado por una forma de gobierno autocrática. El nacimiento del Imperio viene precedido por la expansión de su capital, Roma, que extendió su control en torno al mar Mediterráneo. Bajo la etapa imperial los dominios de Roma siguieron aumentando hasta llegar a su máxima extensión durante el reinado de Trajano, momento en que abarcaba desde el océano Atlántico al oeste hasta las orillas del mar Caspio, el mar Rojo y el golfo Pérsico al este, y desde el desierto del Sahara al sur hasta las tierras boscosas a orillas de los ríos Rin y Danubio y la frontera con Caledonia al norte. Su superficie máxima estimada sería de unos 6,5 millones de km².

El término es la traducción de la expresión latina «Imperium Romanum», que significa literalmente «El dominio de los romanos». Polibio fue uno de los primeros hombres en documentar la expansión de Roma aún como República.
Durante los casi tres siglos anteriores al gobierno del primer emperador, César Augusto, Roma había adquirido mediante numerosos conflictos bélicos grandes extensiones de territorio que fueron divididas en provincias gobernadas directamente por propretores y procónsules, elegidos anualmente por sorteo entre los senadores que habían sido pretores o cónsules el año anterior. 

Durante la etapa republicana de Roma su principal competidora fue la ciudad púnica de Cartago, cuya expansión por la cuenca sur y oeste del Mediterráneo occidental rivalizaba con la de Roma y que tras las tres guerras púnicas se convirtió en la primera gran víctima de la República. Las guerras púnicas llevaron a Roma a salir de sus fronteras naturales en la península itálica y a adquirir poco a poco nuevos dominios que debía administrar, como Sicilia, Cerdeña, Córcega, Hispania, Iliria, etc.

Los dominios de Roma se hicieron tan extensos que pronto fueron difícilmente gobernables por un Senado incapaz de moverse de la capital ni de tomar decisiones con rapidez. Asimismo, un ejército creciente reveló la importancia que tenía poseer la autoridad sobre las tropas para obtener réditos políticos. Así fue como surgieron personajes ambiciosos cuyo objetivo principal era el poder. Este fue el caso de Julio César, quien no solo amplió los dominios de Roma conquistando la Galia, sino que desafió la autoridad del Senado romano.

El Imperio romano como sistema político surgió tras las guerras civiles que siguieron a la muerte de Julio César, en los momentos finales de la República romana. Tras la guerra civil que lo enfrentó a Pompeyo y al Senado, César se había erigido en mandatario absoluto de Roma y se había hecho nombrar "Dictator perpetuus" (dictador vitalicio). Tal osadía no agradó a los miembros más conservadores del Senado romano, que conspiraron contra él y lo asesinaron durante los Idus de marzo dentro del propio Senado, lo que suponía el restablecimiento de la República, cuyo retorno, sin embargo, sería efímero. El precedente no pasó desapercibido para el joven hijo adoptivo de César, Octavio, quien se convirtió años más tarde en el primer emperador de Roma, tras derrotar en el campo de batalla, primero a los asesinos de César, y más tarde a su antiguo aliado, Marco Antonio, unido a la reina Cleopatra VII de Egipto en una ambiciosa alianza para conquistar Roma.

A su regreso triunfal de Egipto, convertido desde ese momento en provincia romana, la implantación del sistema político imperial sobre los dominios de Roma deviene imparable, aún manteniendo las formas republicanas. Augusto aseguró el poder imperial con importantes reformas y una unidad política y cultural (civilización grecorromana) centrada en los países mediterráneos, que mantendrían su vigencia hasta la llegada de Diocleciano, quien trató de salvar un Imperio que caía hacia el abismo. Fue este último quien, por primera vez, dividió el vasto Imperio para facilitar su gestión. El Imperio se volvió a unir y a separar en diversas ocasiones siguiendo el ritmo de guerras civiles, usurpadores y repartos entre herederos al trono hasta que, a la muerte de Teodosio I el Grande en el año 395, quedó definitivamente dividido.

En el inmenso territorio del Imperio Romano se fundaron o se hicieron grandes e importantes muchas de las principales ciudades de la actual Europa Occidental, el norte de África, Anatolia, el Levante. Ejemplos son: París (Lutecia), Estambul (Constantinopla), Barcelona (Barcino), Zaragoza (Caesaraugusta), Mérida (Emerita Augusta), Cartagena (Carthago Nova), Milán (Mediolanum), Londres, (Londino), Colchester (Camulodunum) o Lyon (Lugdunum) entre otros.

Finalmente en 476 el hérulo Odoacro depuso al último emperador de Occidente, Rómulo Augústulo. El Senado envió las insignias imperiales a Constantinopla, la capital de Oriente, formalizándose así la capitulación del Imperio de Occidente. El Imperio romano oriental proseguiría casi un milenio en pie como el Imperio romano (aunque usualmente se use el moderno nombre historiográfico de Imperio bizantino), hasta que en 1453 Constantinopla cayó bajo el poder del Imperio Otomano.

El legado de Roma fue inmenso; tanto es así que varios fueron los intentos de restauración del Imperio, al menos en su denominación. Destaca el intento de Justiniano I, por medio de sus generales Narsés y Belisario, el de Carlomagno con el Imperio Carolingio o el del Sacro Imperio Romano Germánico, sucesor de este último, pero ninguno llegó jamás a reunificar todos los territorios del Mediterráneo como una vez lograra la Roma de tiempos clásicos.

Con el colapso del Imperio romano de Occidente finaliza oficialmente la Edad Antigua dando inicio la Edad Media.

Los primeros emperadores desde Augusto hasta la muerte de Nerón, es decir, entre 27 a. C. y 68 d. C., formaron la dinastía Julio-Claudia, que tras el periodo del 68 al 69, el año de los cuatro emperadores, dio paso a la dinastía Flavia con tres emperadores del 69 al 96 y a la dinastía Antonina, los 5 buenos emperadores, del 96 al 180. El 180 se inició la dinastía Severa que duró hasta la muerte de Alejandro Severo en el 235. Con la muerte de Alejandro, se da por iniciada la crisis del siglo III

Los sucesores de Augusto no demostraron ser especialmente dotados, lo que evidenciaba las debilidades de un sistema dinástico hereditario. Tiberio, Calígula y Nerón fueron especialmente despóticos e incluso se dejaron llevar por excesos que pusieron a prueba la fortaleza del sistema consolidado bajo la administración de Octavio. 

Esta dinastía de emperadores sobresalió en el aspecto de la administración y la construcción. Mantuvieron protegidas las fronteras mediante campamentos militares y otorgaron derechos de ciudadanía romana a los habitantes de las provincias del imperio. 

Los Cinco Buenos Emperadores llevaron Roma a su culmen territorial, económico y de poder: Nerva; Trajano, de origen hispano y gran conquistador; Adriano, querido emperador que realizó grandes reformas y visitó numerosas partes del imperio; Antonino Pío; y Marco Aurelio, pensador a la par que defensor de las fronteras.

El Imperio romano de Occidente es la parte occidental del Imperio romano, después de su división en Occidente y Oriente, iniciada con la tetrarquía del Emperador Diocleciano (284-305) y efectuada de forma definitiva por el Emperador Teodosio I (379-395), quien lo repartió entre sus dos hijos: Arcadio recibió el Imperio de Oriente y Honorio recibió el de Occidente.

A principios del siglo V, las tribus germánicas, empujadas hacia el oeste por la presión de los pueblos hunos, procedentes de las estepas asiáticas, penetraron en el Imperio romano. Las fronteras cedieron por falta de soldados que las defendiesen y el ejército no pudo impedir que Roma fuese saqueada por visigodos y vándalos. Cada uno de estos pueblos se instaló en una región del imperio donde fundaron reinos independientes. Uno de los más importantes fue el que derivaría a la postre en el Sacro Imperio Romano Germánico. 

El emperador ya no controlaba el Imperio, de tal manera que en el año 476 Odoacro, rey de los hérulos, destituyó a Rómulo Augústulo, un niño de quince años que fue el último emperador romano de Occidente y envió las insignias imperiales a Zenón, emperador romano de Oriente.

A lo largo de los siglos que suceden a la caída del Imperio Romano de Occidente, muchas civilizaciones de la edad media y más tarde, de la edad moderna, se proponen restaurar el Imperio Romano a su antigua gloria. El intento más antiguo y el que más se acercó fue el del Imperio Bizantino, por decisión de Justiniano I, en el siglo VI utilizó a sus mejores generales (Narsés y Belisario) para devolver la antigua gloria del Imperio. 

Tres siglos más tarde, un rey Franco, Carlomagno, hijo de Pipino el Breve, fundó la dinastía Carolingia, convirtiendo el reino Franco en el Imperio Carolingio. Carlomagno se hizo con el poder de la mayoría de territorios en Europa Central, convirtiéndose en la principal potencia de Europa en ese momento. Después de la muerte de Carlomagno, el imperio se dividió en tres, un reino para cada hijo de Carlomagno. A pesar de que fuera muy extenso, no se asemejaba en tamaño ni siquiera al Imperio de Occidente en su apogeo territorial.

Un reino sucesor del Imperio Carolingio se hizo con mucho territorio en Europa, fue entonces cuando fue rebautizado como Sacro Imperio Romano. Este Imperio no fue tan extenso como su antecesor, el Imperio carolingio, pero fue mucho más duradero, llegando hasta la edad contemporánea.

 
El mando supremo del ejército correspondía al Emperador. En provincias el mando correspondía al gobernador provincial (pero éste a su vez estaba supeditado al Emperador que podía apartarlo cuando quisiera), pudiendo también asumirlo temporalmente el Emperador. El número de legiones osciló en toda la época imperial, con un número cercano a la treintena. 

Los caballeros y las clases altas habían desaparecido prácticamente del ejército y las legiones debían reclutar entre los ciudadanos, primero en Italia, pero se reclutaron progresivamente en las provincias donde estaban acantonadas, y si era necesario se recurría a mercenarios extranjeros (sobre todo germanos). Con la entrada de los proletarios del ejército tendió a una profesionalización, si bien estos soldados tenían más facilidad para el saqueo. Los ascensos se ganaban por méritos, por favores o por dinero. El tiempo de servicio fue aumentado progresivamente y no eran excepcionales servicios de treinta o más años. Para ejercer algunos cargos municipales había un cierto tiempo de servicio en el ejército. 

La legión disponía de arsenales ("armamentos") y de talleres de fabricación y reparación. Los soldados recibían un sueldo, donativos imperiales en ocasión del acceso al trono, las fiestas o los motines, regalos ("stillaturae") y el botín de guerra. La ración de alimentos diaria fue creciendo y se le proporcionaba trigo, sal, vino, vinagre, carne fresca y carne salada. 

Los campamentos se convirtieron en plazas fuertes. Disponían de murallas y torreones y se dividían interiormente en cuatro partes marcadas por dos vías perpendiculares. Contenían sala de baños, sala de reuniones, capillas, oficinas, cárcel, hospital y almacenes. Los mercaderes, artistas, prostitutas y otros acudían a sus alrededores y se establecían constituyéndose aglomeraciones urbanas, y crecían las poblaciones civiles ("canabae") y las casas de baños y anfiteatros. Los terrenos próximos se utilizaban como pastos para el ganado, y en general se arrendaban por ello los agricultores de la zona. 

Una legión romana (cuyo emblema era un águila plateada) consistía en diez cohortes (con su respectivo estandarte) cada una de ellas con cinco o seis centurias de ochenta hombres subdivididas en diez contubernios (unidad básica de ocho legionarios que compartían tienda), contando pues cada legión cinco o seis mil hombres de infantería, divididos en cincuenta o sesenta centurias. Contaba también con las guerrillas regulares auxiliares y de caballería ("alae") ciento veinte hombres de caballería. 

El nombramiento de los "legatus legionis", lugartenientes de la legión con funciones de pretor, asistidos por tribunos militares designados todos ellos por el gobernador provincial o por el Emperador, que también podían nombrar a los centuriones. 

Junto a los legados de la legión estaban los "benefiaciarii" (encargados de misiones de confianza), los "strato" (escuderos), los "comentarienses" (archiveros), los "cornicularii" (contadores) y los "actuario" (escribientes). Los tribunos militares se dividían en "laticlavii" (afectos a la administración) y "angusticlavii" (misiones propiamente militares). Los centuriones los auxiliaba un oficial secundario llamado "optio", algunos de los cuales también ejercían funciones administrativas. En caballería el suboficial que mandaba una "turma" (nueve jinetes) era llamado decurión. Otros suboficiales eran el "tesserarius" (equivalente a un sargento), el "signifer" o "vexillarius" (portaestandartes), el "aquilifer" (el portador del águila legionaria), el "campiductor" (instructor) y el "pecunarius" (furriel). 

Las cohortes se estructuraban en diez filas de 40 o 60 hileras que en tiempos de Trajano se redujeron a cinco filas. Con Adriano surgió la cohorte familiar (compuesta de 1200 soldados escogidos) mientras las restantes cohortes fueron llamadas "quingentaries" y contaban 500 soldados. Desde el reinado de Adriano el reclutamiento se hizo exclusivamente en las provincias donde servía la Legión. 

Se estructuraron varias cohortes especializadas: las de infantería (peditata), la de caballería o mixta ("equitativa"), la policial ("togata"), la de vigilancia ("excubitoria"), la de guarnición en una ciudad ("urbana"), la encargada de apagar incendios ("Vigilio") y la encargada de la guardia y custodia imperial o de un caudillo ("Praetoriana "). Esta guardia personal del general en jefe fue habitual en el Imperio. Existía el cuartel general (Guardia Pretoriana o guardia del general en jefe) los miembros tenían más sueldo y estaban dispensados de los trabajos del campamento, y que llegaron a ser los árbitros del Imperio.

Las centurias estaban al mando de centuriones (el centurión de más prestigio era el "primus pilus" habitualmente el más veterano), por encima del cual había seis tribunos de la legión de rango ecuestre, y el "legatus" de la legión, de rango senatorial, que había sido anteriormente pretor (en las provincias donde solo había una legión, el "legatus" de la provincia y el de la Legión era la misma persona).

El equipamiento de los legionarios cambiaba sustancialmente dependiendo del rango. Durante las campañas, los legionarios iban equipados con armadura ("lorica segmentata"), escudo ("scutum"), casco ("galae"), una lanza pesada y una ligera ("pilum"), una espada corta ("gladius"), una daga ("pugio"), un par de sandalias ("caligae"), una "sarcina" (mochila de marcha), y comida y agua para dos semanas, equipo de cocina, dos estacas ("Sude murale") para la construcción de muros, y una pala o cesta.

La Armada romana (en latín "classis", literalmente "flota") comprendió las fuerzas navales del antiguo Estado romano. A pesar de jugar un papel decisivo en la expansión romana por el Mediterráneo, la armada nunca tuvo el prestigio de las legiones romanas. A lo largo de su historia los romanos fueron un pueblo esencialmente terrestre, y dejaron los temas náuticos en manos de pueblos más familiarizados con ellos, como los griegos y los egipcios, para construir barcos y mandarlos. Parcialmente debido a esto, la armada nunca fue totalmente abrazada por el Estado romano, y se consideraba «no romana». En la antigüedad, las armadas y las flotas comerciales no tenían la autonomía logística que en la actualidad. A diferencia de las fuerzas navales modernas, la armada romana, incluso en su apogeo, no existió de forma autónoma, sino que operó como un adjunto del Ejército romano. 

En el transcurso de la primera guerra púnica la armada fue expandida masivamente y jugó un papel vital en la victoria romana y en la ascensión de la República romana a la hegemonía en el Mediterráneo. Durante la primera mitad del siglo II a. C. Roma destruyó Cartago y subyugó los Reinos Helenísticos del este del Mediterráneo, logrando el dominio completo de todas las orillas del mar interior, que ellos llamaron "Mare Nostrum". Las flotas romanas volvieron a tener un papel preponderante en el siglo I a.C. en las guerras contras los piratas y en las guerras civiles que provocaron la caída de la República, cuyas campañas se extendieron a lo largo del Mediterráneo. En el 31 a. C. la batalla de Accio puso fin a las guerras civiles con la victoria final de Augusto y el establecimiento del Imperio romano. 

Durante el período imperial el Mediterráneo fue un pacífico «lago romano» por la ausencia de un rival marítimo, y la armada quedó reducida mayormente a patrullaje y tareas de transporte.

Sin embargo, en las fronteras del Imperio, en las nuevas conquistas o, cada vez más, en la defensa contra las invasiones bárbaras, las flotas romanas estuvieron plenamente implicadas. El declive del Imperio en el siglo III d. C. se sintió en la armada, que quedó reducida a la sombra de sí misma, tanto en tamaño como en capacidad de combate. En las sucesivas oleadas de los pueblos bárbaros contra las fronteras del Imperio la armada sólo pudo desempeñar un papel secundario. A comienzos de siglo V d. C. las fronteras del imperio fueron quebradas y pronto aparecieron reinos bárbaros en las orillas del Mediterráneo occidental. Uno de ellos, el pueblo vándalo, creó una flota propia y atacó las costas del Mediterráneo, incluso llegó a saquear Roma, mientras las disminuidas flotas romanas fueron incapaces de ofrecer resistencia. El Imperio romano de Occidente colapsó en el siglo V d. C. y la posterior armada romana del duradero Imperio romano de Oriente es llamada por los historiadores Armada bizantina.

Las ciudades romanas eran el centro de la cultura, la política y la economía de la época. Base del sistema judicial, administrativo y fiscal eran también muy importantes para el comercio y a su vez albergaban diferentes acontecimientos culturales. Es importante destacar que Roma fue, a diferencia de otros, un imperio fundamentalmente urbano.

Las ciudades romanas estaban comunicadas por amplias calzadas que permitían el rápido desplazamiento de los ejércitos y las caravanas de mercaderes, así como los correos. Las ciudades nuevas se fundaban partiendo siempre de una estructura básica de red ortogonal con dos calles principales, el "cardo" y el "decumano" que se cruzaban en el centro económico y social de la ciudad, el foro, alrededor del cual se erigían templos, monumentos y edificios públicos. También en él se disponían la mayoría de las tiendas y puestos comerciales convirtiendo el foro en punto de paso obligado para todo aquel que visitase la ciudad. Así mismo un cuidado sistema de alcantarillado garantizaba una buena salubridad e higiene de la ciudad romana.

Curiosamente, este riguroso ordenamiento urbanístico, ejemplo del orden romano, nunca se aplicó en la propia Roma, ciudad que surgió mucho antes que el imperio y que ya tenía una estructura un tanto desordenada. El advenimiento del auge del poder imperial motivó su rápido crecimiento con la llegada de multitud de nuevos inmigrantes a la ciudad en busca de fortuna. Roma nunca fue capaz de digerir bien su grandeza acentuándose más aún el caos y la desorganización. La capital construía hacia lo alto, el escaso espacio propició la especulación inmobiliaria y muchas veces se construyó mal y deprisa siendo frecuentes los derrumbes por bloques de pisos de mala calidad. Famosos eran también los atascos de carros en las intrincadas callejuelas romanas. La fortuna sin embargo quiso que la capital imperial se incendiara el año 64 dC, durante el mandato de Nerón. La reconstrucción de los diferentes barrios se realizó conforme a un plan maestro diseñado a base de calles rectas y anchas y grandes parques lo que permitió aumentar muchísimo las condiciones higiénicas de la ciudad.

Por lo demás toda ciudad romana trataba de gozar de las mismas comodidades que la capital y los emperadores gustosos favorecían la propagación del modo de vida romano sabedores de que era la mejor carta de romanización de las futuras generaciones acomodadas que jamás desearían volver al tiempo en que sus antepasados se rebelaban contra Roma. Por ello, allí donde fuera preciso se construían teatros, termas, anfiteatros y circos para el entretenimiento y el ocio de los ciudadanos. También muchas ciudades intelectuales gozaban de prestigiosas bibliotecas y centros de estudio, así fue en Atenas por ejemplo ciudad que siempre presumió de su presuntuosa condición de ser la cuna de la filosofía y el pensamiento racional.

Para traer agua desde todos los rincones se construían acueductos si era preciso, el agua llegaba a veces con tal presión que era necesario construir abundantes fuentes por todas partes lo que aún aumentaba más el encanto de dichas ciudades, que a pesar de estar construidas en tierras secas recibían la llegada de las bien planificadas canalizaciones romanas.

Las casas típicas eran las "insulae" (isla). Solían estar hechas de adobe normalmente de unos tres o cuatro pisos aunque en Roma o en otras ciudades de gran densidad se llegaban a construir verdaderos rascacielos cuya solidez muchas veces fue más que dudosa. La gente rica y de dinero, patricios de buena familia o ricos comerciantes plebeyos que habían hecho fortuna se alojaban en casa de una sola planta con patio interior ("impluvium") recubierto de mosaicos llamadas "domus".

En honor a las victorias se construían columnas, arcos de triunfo, estatuas ecuestres y placas conmemorativas que solían hacer siempre referencia al emperador reinante y sus gloriosas victorias conseguidas en pos de la salvaguarda de la "pax romana" de la que gozaban inconscientes los ciudadanos de la urbe. Era un motivo que se recordaba constantemente para dar sentido a la recaudación imperial, sin dinero no hay ejército, sin ejército no hay seguridad y sin seguridad no hay ciudades ni comercio. Algo que quedaría patente a finales del bajo imperio.

Con la llegada de la crisis del siglo tercero y, particularmente, ya en el tardío imperio cristiano la seguridad de la que disfrutaron durante tiempo las ciudades romanas había desaparecido. Y muchas de ellas, sobre todo las más fronterizas con los limes acechados por los pueblos germanos se vieron obligadas a amurallarse y recluirse en fortificaciones sacrificando calidad de vida por seguridad. Fue un paso hacia atrás que se materializaría con la desaparición del imperio de occidente, la ruralización, el fin de las actividades comerciales y el surgimiento de los castillos medievales.

La economía del Imperio romano era la propia de un imperio esclavista; los esclavos trabajaban, obviamente sin remuneración alguna, lo cual producía una enorme riqueza. Las diferentes ciudades y provincias estaban conectadas por una red de comunicaciones, vías y puertos, que fomentaban el comercio notablemente.

Aunque la vida se centraba en las ciudades, la mayoría de los habitantes vivían en el campo con un buen nivel, donde cultivaban la tierra y cuidaban el ganado. Los cultivos más importantes eran el trigo, la cebada, la viña y los olivos, también árboles frutales, hortalizas y legumbres. Los romanos mejoraron las técnicas agrícolas introduciendo el arado romano, molinos más eficaces, como el grano, el prensado de aceite, técnicas de regadío y el uso de abono.

Desde el punto de vista económico, la base agrícola varía bastante según las zonas.

La sociedad romana original (comienzos de la República) se configura de dos clases sociales que tenían la ciudadanía romana: una aristocracia de propietarios ("patricii", patricios) y una clase popular que luchaba por conseguir derechos ("plebs", plebeyos). Como ya se ha dicho anteriormente, la economía estaba basada en el sistema de producción esclavista, donde la mayoría de los esclavos eran prisioneros de guerra. Existían mercados de esclavos donde se comerciaba con ellos como si fuesen simples mercancías.

Así pues la sociedad romana en sus orígenes estaba dividida en:

Al evolucionar la República y convertirse en Imperio, esta sociedad evolucionó con ella dando origen a nuevos grupos o transformando otros. Ya hacia finales del siglo IV a.C se había formado la clase de los optimates (o aristocracia patricio-plebeya), resultado de la fusión de los antiguos patricios con los plebeyos más ricos. 

En la medida que Roma entró en el gran circuito económico del Mediterráneo se desarrolló la clase de los caballeros (u orden ecuestre), dedicada a los negocios (empresarios mineros, grandes comerciantes, prestamistas, etc.). 

Por su parte, la antigua clase media campesina, propietaria de tierras en Italia, se arruinó con las guerras y con la competencia de los latifundios y los productos agrícolas a bajo precio venidos de las provincias. Los campesinos pobres que la formaban emigraron a Roma y a las grandes ciudades de Italia, transformándose en el proletariado romano, una masa ociosa y llena de vicios, cuyos integrantes solían engrosar la clientela de los políticos profesionales y a quienes vendían sus votos. El proletariado fue sostenido por el aporte económico de sus patrones y, durante el Imperio, por las arcas fiscales y los recursos de los emperadores.

La sociedad siguió evolucionando durante el Imperio.

Se tiene constancia de más de sesenta lenguas diferentes habladas en los territorios que alguna vez formaron parte del Imperio romano. El proceso de romanización que tuvo lugar en los territorios controlados de manera prolongada por el Imperio romano comportó en muchos de ellos un proceso de sustitución lingüística que llevó a la desaparición de lenguas autóctonas. Sin embargo, este proceso no fue siempre de corta duración y típicamente abarcó diversas generaciones e incluso siglos, en los que el bilingüísmo con el latín o incluso el multilingüismo fue frecuente.

La mayor parte de lenguas en la parte europea del Imperio romano eran lenguas indoeuropeas de los grupos anotolio, celta, germánico, greco-armenio e itálico, además de algunas otras lenguas indoeuropeas más difíciles de clasificar (a veces llamadas lenguas paleobalcánicas). Aunque también están testimoniadas lenguas no indoeuropeas autóctonas como el aquitano y las lenguas tirsénicas, cuya principal representante es el etrusco. En el norte de África y Oriente Próximo, también tienen presencia muchas ramas de las lenguas afroasiáticas (egipcio, bereber y semítico).

La religión de los romanos era politeísta (adoraban un gran número de dioses). Los más venerados eran Júpiter, Minerva y Juno. En honor a ellos se construyeron templos y se ofrecieron sacrificios de animales. El emperador era adorado como un dios y en todo el Imperio se practicaba el culto imperial.

También veneraban, en casa, a los dioses protectores del hogar y de la familia; en cada casa había un altar dedicado a esos dioses. Además, los romanos eran muy supersticiosos y, antes de tomar una decisión consultaban la voluntad de los dioses, expresada por medio de los oráculos.

El calendario religioso romano reflejaba la hospitalidad de Roma ante los cultos y divinidades de los territorios conquistados. Originalmente eran pocas las festividades religiosas romanas. Algunas de las más antiguas sobrevivieron hasta el final del imperio pagano, preservando la memoria de la fertilidad y los ritos propiciatorios de un primitivo pueblo agrícola. A pesar de eso, se introdujeron nuevas fiestas que señalaron la asimilación de los nuevos dioses. Llegaron a incorporarse tantas fiestas que los días festivos eran más numerosos que los laborales. Las más importantes eran las fiestas lupercales, saturnales, equiria y de los juegos seculares.

Tiempo después, terminadas las persecuciones contra los cristianos, el cristianismo fue tolerado con el emperador Constantino. Según la leyenda, antes de la batalla de Puente Milvio vio una cruz en el cielo, bajo la cual una inscripción decía «bajo este símbolo vencerás». Al día siguiente grabó en los escudos de todos sus soldados la cruz y obtuvo una gran victoria, si bien sólo se bautizó unos días antes de su muerte. Sólo con el emperador Teodosio I el Grande el cristianismo se convirtió en religión oficial del Imperio.





</doc>
<doc id="1511" url="https://es.wikipedia.org/wiki?curid=1511" title="Internet Control Message Protocol">
Internet Control Message Protocol

El 'Protocolo de Mensajes de Control de Internet' o ICMP (por sus siglas en inglés de "Internet Control Message Protocol") es el sub protocolo de control y notificación de errores del Protocolo de Internet (IP). Como tal, se usa para enviar mensajes de error, indicando por ejemplo que un router o host no puede ser localizado. También puede ser utilizado para transmitir mensajes ICMP Query.

ICMP difiere del propósito de TCP y UDP ya que generalmente no se utiliza directamente por las aplicaciones de usuario en la red. La única excepción es la herramienta ping y traceroute, que envían mensajes de petición Echo ICMP (y recibe mensajes de respuesta Echo) para determinar si un host está disponible, el tiempo que le toma a los paquetes en ir y regresar a ese host y cantidad de hosts por los que pasa.

Este protocolo es parte de la suite de protocolo de Internet, de esta manera se define en RFC 792. Los mensajes de este protocolo se utilizan con fines de diagnóstico o control y se generan en respuesta a los errores en operaciones IP (como se especifica en el RFC 1122). Estos errores del protocolo ICMP se dirigen a la dirección IP de origen del paquete originario.

Podríamos decir, que todos los dispositivos (como intermedio enrutador) reenvían un datagrama IP que disminuye el tiempo de vida en el encabezado IP por uno. Si el tiempo de vida (TTL) resultante es 0, el paquete se descartará y enviará un mensaje ICMP de tiempo de vida superado a la dirección origen del datagrama.

El ICMP inicia después del IPv4 cabecera y se identifica con el protocolo número “1”. Todos los paquetes ICMP tendrán una cabecera de 8 bytes y la sección de datos de tamaño variable. Los primeros 4 bytes de la cabecera serán consistentes. El primer byte es reservado para el tipo de ICMP. El segundo octeto es para el código de ICMP. El tercer y cuarto byte es una suma de comprobación de todo el mensaje ICMP. El contenido de los restantes 4 bytes de la cabecera pueden variar dependiendo de la función del tipo y el código ICMP.

Los mensajes de error de este protocolo contienen una sección de datos que incluye todos los IP de cabecera más los 8 primeros bytes de los datos del paquete IP que ha causado el mensaje de error. El paquete ICMP es encapsulado en un nuevo paquete IP.

Bits 0-7 8-15 16-23 24-31


Un Echo Reply (Respuesta de Eco) en el protocolo ICMP es un mensaje generado como respuesta a un mensaje Echo Request (petición de Eco).

Formato del Mensaje:

Destination Unreachable es un tipo de paquete ICMP cuya función es transportar un mensaje que es generado por un enrutador, y se envía al host de origen, que recibe el mensaje emitido por el enrutador.

El mensaje en sí significa que este router considera inalcanzable el destino al que quiere llegar el host.

Si se recibe de parte del host de destino, significa que el protocolo que se intentó acceder no está activo en aquel momento.

El campo Type tiene el valor 3. El campo código contendrá alguno de los siguientes valores:

La Fuente Saciable: las peticiones que provienen del remitente disminuyen su velocidad sobre la base de los mensajes enviados a un host o router. Este mensaje se puede generar si un router o host esta deficiente en espacio de búfer para procesar esta solicitud, o puede ocurrir que el bufer del host o enrutador este llegando a su límite.

La información es enviada a una velocidad muy alta que parte de un anfitrión o de varios host al mismo tiempo hacia un enrutador en particular perteneciente a la red. Aunque un router tiene capacidades de almacenamiento en búfer, esta se limita dentro de un rango en específico. El enrutador no puede colocar más datos que se excedan de la capacidad de almacenamiento que provee el búfer. De esta forma, si la cola se llena, las informaciones se descartan hasta que la cola ya no este saturada. Pero como no hay mecanismos de confirmación está presente en la capa de red, el usuario no tiene conocimiento si la información ha llegado a su destino con éxito. De ahí algunas medidas correctivas deben ser tomadas por medio de la capa de red para prevenir estos tipos de situaciones. Estas medidas se refieren como fuente de amortiguación. En un mecanismo de enfriamiento fuente, el enrutador considera que la tasa de datos entrantes es más rápido que la velocidad de datos de salida, y envía un mensaje ICMP a los clientes, informándoles deben frenar su velocidad de transferencia de datos o esperar una cantidad de tiempo para enviar nuevamente datos. Al usuario recibir esta notificación automáticamente se desacelerara la velocidad de datos salientes o quedara en espera hasta que pase suficiente cantidad de tiempo lo que le permitirá al router vaciar la cola. Por lo tanto fuente saciar mensaje ICMP actos como el control de flujo en la capa de red.

Donde
Tipo debe establecerse en 4
Código debe establecerse en 0
Encabezado IP y los datos adicionales es utilizado por el emisor para que coincida con la respuesta a la solicitud correspondiente

"Redirect" solicita que los paquetes de datos se envíen en una ruta alternativa. ICMP Redirect es un mecanismo para enrutadores para transferir datos del router a los hosts. El mensaje informa al receptor (hosts) que actualice su información de enrutamiento. Si un anfitrión intenta enviar información a través del router 1 y el router 1 envía la información al router 2 y una ruta directa desde el host al router 2 está disponible (es decir, el anfitrión y el router 2 están en el mismo segmento de Ethernet), entonces el router 1 enviará una notificación de redirección para informar al host que el mejor trayecto para cumplir su destino es a través del router 2. Entonces el anfitrión debe enviar paquetes directamente al router 2. Y este intentará enviar el original datagrama al destino previsto. Sin embargo, si el datagrama contiene datos del enrutamiento, no se enviará esta notificación incluso si hay mejores caminos disponibles.

Donde:

El Echo Request (Petición eco) es un mensaje de control que se envía a un host con la expectativa de recibir de él un Echo Reply (Respuesta eco). Esto es conocido como Ping y es una utilidad del protocolo ICMP, subprotocolo de IP. Todo host debe responder a un Echo Request con un Echo Reply que contenga exactamente los mismos datos que el primero.

Formato del mensaje:


El Tiempo excedido se crea por una puerta de enlace para informar a la fuente de un datagrama debido al tiempo de vida de campo al llegar a cero. Un mensaje sobrepasando el tiempo también puede ser enviado por un host si no logra volver a montar una fragmentación de datagramas dentro de su límite de tiempo.

Los mensajes del tiempo excedido son utilizados por la Ruta de Seguimiento de utilidad para identificar las puertas de enlace en el cambio de los anfitriones.

Donde:
El IP cabecera y los primeros 64 bits de la carga original útil son utilizados por el host de origen para que coincida con el mensaje de tiempo excedido para el datagrama descartado. Para los protocolos de nivel superior, tales como UDP (Datagrama de Protocolo de Usuario) y TCP (Protocolo de Control de Transmisión) el bit de carga útil de 64 bits incluirá la fuente y puertos de destino del paquete descartado.

"Timestamp" Es usada para la sincronización de tiempo. Consiste en el origen del timestamp

Donde:

Respuesta a una timestamp del mensaje. Se compone de la timestamp originario enviado por el remitente del timestamp, así como una timestamp y así recibir una timestamp de la transmisión.

Donde:
Todos los timestamp son en unidades de milisegundos desde la medianoche UT. Si el tiempo no está disponible en milisegundos o no puede ser proporcionado con respecto a la medianoche UT entonces cualquier momento se puede insertar en una timestamp siempre y cuando que el bit de orden superior del timestamp también se establezca como indicador del valor estándar.

se envía normalmente por un host a un router con el fin de obtener una adecuada Máscara de Subred.
Los remitentes deben responder este mensaje con una Solicitud de Dirección de Máscara.

Donde:

ICMP Solicitud de Dirección de Máscara puede ser usada como parte de un proceso de reconocimiento para recabar información sobre la red de destino, por lo tanto, ICMP Solicitud de Dirección de Máscara está desactivando por defecto en Cisco IOS.
La Respuesta a la Dirección de Máscara se utiliza para responder a un mensaje de petición de dirección de máscara con una máscara de subred adecuada.
Donde:

El Destino Inalcanzable se genera por el host o en la puerta de enlace entrante para informar al cliente de que el destino es inalcanzable por alguna razón. Un mensaje de destino inalcanzable se puede generar como resultado de un TCP, UDP o ICMP u otra transmisión.Los Puertos TCP inalcanzables sobre todo responden con TCP RST en lugar de un tipo de destino inalcanzable 3 como era de esperar.

El error no se génera si el datagrama original tiene un IP Multicast de dirección de destino. Las razones para este mensaje pueden incluir: la conexión física con el host no existe (la distancia es infinita), el protocolo indicado o el puerto no está activo, los datos deben ser fragmentados pero el marcador "no fragmentar" está activo.

Donde:

Un mensaje ICMP se encapsula en IP:

ICMP se puede utilizar para transmitir diferentes tipos de mensajes de gestión, que se identifican principalmente por el tipo y el código correspondiente.

Lista de mensajes de control permitidos (incompleta):
(Fuente: IANA ICMP Parameters)



</doc>
<doc id="1512" url="https://es.wikipedia.org/wiki?curid=1512" title="II milenio">
II milenio

El segundo milenio comprende del 1 de enero de 1001 al 31 de diciembre de 2000 (No 1999 como popularmente se cree).










</doc>
<doc id="1515" url="https://es.wikipedia.org/wiki?curid=1515" title="Incunable">
Incunable

Un incunable (del latín "incunabulae", en la cuna) es todo libro impreso durante el siglo XV. Concretamente, antes del día de pascua de 1501, pues en esa época se hacía comenzar el año en este día. Fue posiblemente Cornelius Beughem quien empleó la palabra por primera vez, en su "Incunabula typographiae" (1688). Previamente se atribuye dicho término a Bernhard von Mallinckrodt quien llamaría a esta época “typographicae incunabula” en 1640 en su obra "De ortu et progressu artis typographica".

En este período la industria tipográfica todavía no se había especializado: el impresor era dueño y manipulador de la prensa, fundidor de tipos, fabricante del papel, encuadernador, editor, librero, artesano, artista y erudito. Algunos de ellos dejaban una «marca de agua» o filigrana en el papel que fabricaban, de esa manera sabemos quién la editó; pero hay muchos que carecían de firma y fecha. Hoy en día, estudios científicos que analizan los tipos de fundición utilizados, han ayudado a catalogar la mayoría de las ediciones existentes. Estas ediciones son documentos históricos que, por primera vez, pusieron la cultura al alcance de todos.

El término «incunable» hace referencia a la época en que los libros se hallaban «en su cuna», es decir en la primera «infancia» de la técnica moderna de hacer libros a través de la imprenta. Así, son reconocidos como incunables los libros impresos entre 1453 (fecha de la invención de la imprenta moderna) y 1500, procedentes de unas 1200 imprentas, distribuidas entre 260 ciudades, con un lanzamiento aproximado de 35 000 obras distintas. 

A Johann Gutenberg, de Maguncia, se le atribuye la invención de los caracteres móviles fundidos. Los primeros incunables salieron de su imprenta, y entre ellos destaca la "Biblia de Gutenberg" (1453-55), en latín, de 42 líneas. Durante los primeros treinta años, la imprenta se expandió por Europa occidental y comenzó a dividirse en diferentes actividades especializadas. Al principio, los libros no tenían portada con caracteres en letra gótica y las palabras tenían numerosas abreviaturas, imitando a los códices. Pero ya en el mismo siglo fueron adoptándose otros tipos de letras, especialmente la redonda o romana, la veneciana o itálica y la cursiva, mucho más legibles que las primeras y que al fin prevalecieron sobre éstas (salvo en Alemania) desde comienzos del siglo siguiente. Hacia finales del siglo XVI, se introdujo el tipo "elzeviriano" (del holandés Elzevir) más delgado que los anteriores y después siguieron otros caracteres de fantasía, hasta llegar a la gran variedad que hoy conocemos.

Antes de los tipos metálicos móviles, se usaban planchas de madera fija, que dieron lugar a los "incunables xilográficos", entre los que destaca la "Biblia Pauperum" o "Biblia de los pobres". Los protoincunables son los libros impresos en los primeros talleres, entre 1472 y 1480. A su vez, se denominan post-incunables aquellos libros impresos a principios del siglo XVI que por error o debido a una insuficiente información, han sido clasificados como incunables.

El primer libro español impreso que se conserva es el Sinodal de Aguilafuente, impreso por Juan Párix de Heidelberg (Johannes Parix) en 1472, que contiene actas de una reunión celebrada en Aguilafuente, Segovia. Incunables españoles de gran valor son la Biblia (impresa en valenciano en Valencia en 1478), Los doce trabajos de Hércules (originalmente escrita en catalán, con el título "Los dotze treballs de Hèrcules") de Enrique de Villena (Zamora, 1483), Tirante el Blanco (originalmente escrita en valenciano, con el título "Tirant lo Blanch") de Joanot Martorell (Valencia, 1490), Gramática de la lengua castellana de Antonio de Nebrija (Salamanca, 1492) y la primera edición de La Celestina de Fernando de Rojas, atribuido a Fadrique de Basilea en 1499, afamado impresor que trabajó en Burgos durante treinta años y que dejó tras de sí una importante estirpe de impresores en la ciudad.

Entre las ediciones más importantes de incunables, se encuentran las de Gutenberg, Nicolas Jensen, William Caxton y Aldo Manuzio.

Para conocer los incunables principalmente aquellos que no tienen fecha, hay que fijarse en otras particularidades que los distinguen: 

El catálogo más importante de incunables es posiblemente el "Gesamtkatalog der Wiegendrucke", iniciado en 1925.

Las mayores colecciones del mundo, con el número aproximado de incunables que poseen, están custodiadas en:
La siguiente es una lista de instituciones latinoamericanas que cuentan con colecciones de 'incunables universales', es decir, impresos realizados entre 1450 y 1500. No se incluye en la lista los postincunables (1501-Ca. 1530) o los llamados popularmente 'incunables latinoamericanos', es decir, los primeros impresos realizados en el continente americano, que siempre serían posteriores a 1501.



</doc>
<doc id="1516" url="https://es.wikipedia.org/wiki?curid=1516" title="Instrumento de viento">
Instrumento de viento

Los instrumentos de viento o aerófonos son una familia de instrumentos musicales que producen el sonido por la vibración del viento y de la masa de aire en su interior, sin necesidad de cuerdas o membranas porque solo requiere del uso del viento.
Los aerófonos de metal producen un sonido de timbre fuerte. En este caso, el músico hace vibrar sus labios en una boquilla que genera la frecuencia acústica. Entre los aerófonos de metal podemos nombrar a la trompeta, la tuba y el trombón.

Los instrumentos de viento son aquellos que emiten sonido al exhalar aire a través de la embocadura, caña, lengüeta o boquilla al ser este convenientemente expulsado.

Los instrumentos de viento se pueden clasificar en dos categorías. Estas categorías se dividen atendiendo a cómo se produce el timbre:


Los instrumentos de viento o tubos sonoros pueden clasificarse en función de tres criterios distintos:

Los tubos pueden ser cónicos, cilíndricos o prismáticos:
Prismáticos: instrumentos primitivos y algunos tubos de órgano.

Los tubos se clasifican en tubos de embocadura, de lengüeta (simple o doble) y de boquilla:


</doc>
<doc id="1521" url="https://es.wikipedia.org/wiki?curid=1521" title="Iglesia (organización)">
Iglesia (organización)

Una iglesia refiere tanto a una comunidad local como a una institución que agrupa a cristianos de una misma . En sociología, este término designa a un grupo religioso institucionalizado y con vocación universalista.

La palabra "iglesia" proviene de la voz griega ἐκκλησία (transliterado como "ekklēsía") vía el latín "ecclesia".

El sustantivo posee una doble herencia de significado en la Biblia:

Así, Iglesia en algunos pasajes del Nuevo Testamento podría combinar ambas ideas (la hebrea y la griega) o solo una de ellas, dando por eso profundo y complejo significado a las palabras de Jesús de Nazaret a Simón Pedro recogidas en el Evangelio según san Mateo:

Por otro lado, otros orígenes etimológicos de Iglesia se observan en idiomas distintos al castellano. Mientras que en las lenguas romances "iglesia" deviene del griego "ekklēsía", como ya se ha visto, en las lenguas germánicas (alemán "kirche", inglés "church"), procede del griego popular bizantino ("kyrikē"), que puede significar algo ‘referente al Señor ("kyrios")’; no obstante, no existe unanimidad al respecto.

En algunos pasajes de la Biblia su uso en singular hace referencia a una congregación local y específica, como es el caso del relato en "Hechos de los apóstoles" con respecto a la Iglesia de Jerusalén:
Pero en otros pasajes Pablo de Tarso parece utilizar el vocablo para referirse a un conjunto de congregaciones:
Con todo, los estudiosos concuerdan en que las Sagradas Escrituras hacen poca distinción entre el singular y el plural, por eso, del mismo modo, Iglesia puede hacer referencia a una reunión de creyentes en un hogar, como es el caso de la mencionada en la Epístola a los romanos:
Como asimismo a una reunión de creyentes en una sola ciudad, como los destinatarios de la Primera epístola de san Pablo a los corintios
O a la reunión de creyentes de una provincia, como se refiere San Pablo a las iglesias de Asia en su Primera epístola a los tesalonicenses:
En otros pasajes de la Biblia, particularmente en las epístolas paulinas, se utiliza la palabra Iglesia para designar aquello que los cristianos han definido a lo largo de su historia como "cuerpo místico de Cristo" o, toda la "comunidad universal de los creyentes".

Así ocurre, por ejemplo, en la Epístola a los Efesios donde Pablo de Tarso explica el "eterno propósito redentor de Dios" realizado en una Iglesia en la que participan tanto judíos como no judíos, personas de todas las naciones, tanto esclavos como hombres libres, etc. Un verso de la Epístola a los colosenses deja muy clara esta idea, una Iglesia…

En un primer plano, la Iglesia sería el conjunto de todos los cristianos, congregados en virtud del bautismo. En la mayoría de las denominaciones se cree que todos los bautizados conforman un solo cuerpo con Cristo a la cabeza: la Iglesia sería entonces el cuerpo místico de Cristo.

Lo común de cada Iglesia cristiana y cada cristiano es que, todos (por definición) creen en Cristo, es decir ponen su esperanza y confían en Jesús el Cristo (Jesucristo) para su salvación y redención de los pecados.

La Iglesia católica se ve a sí misma como esta Iglesia total en virtud de la sucesión apostólica desde el apóstol Pedro en la persona del papa, en lo cual divergen los protestantes, que niegan valor a la tradición apostólica. La Iglesia ortodoxa e Iglesia anglicana reconocen jerarquía al papa, mas no autoridad jurisdiccional.

A las comunidades cristianas geográficamente determinadas (un país, una jurisdicción eclesiástica) se les denomina "iglesia particular", sin que ello implique que sean congregaciones diferentes a la Iglesia total, por ejemplo, la iglesia griega.

En la Iglesia católica, suele emplearse para referirse específicamente a cada comunidad bajo la dirección de un mismo prelado: diócesis, vicariatos apostólicos, entre otros.




</doc>
<doc id="1525" url="https://es.wikipedia.org/wiki?curid=1525" title="Isla del Príncipe Eduardo">
Isla del Príncipe Eduardo

Isla del Príncipe Eduardo (nombre oficial en inglés: "Prince Edward Island;" en francés: "Île-du-Prince-Édouard") comúnmente abreviada PE, es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. Su capital y ciudad más poblada es Charlottetown. Ubicada al este del país, es una isla rodeada por el océano Atlántico y separada de Nuevo Brunswick por el estrecho de Northumberland. Con 139 407 habs. en 2008 es la cuarta entidad menos poblada —por delante de Territorios del Noroeste, Yukón y Nunavut, la menos poblada—, con 5660 km², la menos extensa, y con 24,6 hab/km², la más densamente poblada. 

Su capital, Charlottetown, es conocida como la cuna de la Confederación Canadiense, aunque la provincia no se asoció a la Confederación hasta más tarde. Recientemente fue unida al continente americano por el puente de la Confederación.

La isla fue originalmente habitada por los nativos americanos "micmac", quienes la llamaban "Abegweit". 

Posteriormente, pasó a formar parte de Acadia, una colonia francesa. Como tal, la isla era llamada "Île Saint-Jean" (Isla San Juan). Aproximadamente mil acadianos fueron deportados en 1758, cuando los británicos la conquistaron, durante la guerra franco-indígena.

La nueva colonia de "St. John's Islands" quedó prácticamente desierta tras el fin de las hostilidades, salvo por la presencia de un fuerte inglés. Con el fin de atraer personas a la región al menor costo posible, el Capitán Samuel Holland, del tesoro real de Inglaterra, propuso al "Departamento de Comercio y Agricultura" que se llevase a cabo en la región una expedición científica, a fin de alentar el asentamiento y la actividad pesquera, tanto en la isla como en el resto de las colonias británicas en América del Norte, y especialmente en los territorios recién conquistados a Francia (Acadia y Nueva Francia).

La exploración se llevó a cabo entre 1764 y 1766, y durante este tiempo se fundaron tres condados, cada uno de aproximadamente dos mil km². Cada condado fue subdividido en cinco partidos, de 400 km² cada uno. Cada condado tenía su cabecera, mientras que el resto del territorio fue dividido en 67 lotes diferentes, cada uno con aproximadamente 80 km². Posteriormente, se subastaron entre la nobleza británica. 

Los nuevos propietarios de los lotes deberían reclutar a su vez nuevos contratistas, así como financiar el traslado de estos desde Inglaterra (o desde cualquier colonia de esta) hasta la Isla. A su vez, estos tendrían la obligación de trabajar en la los trabajos forestales en la región y, asimismo, pagar una tasa anual a sus señores.

En 1798, Gran Bretaña cambió el nombre de la colonia de Isla San Juan a Isla del Príncipe Eduardo, para distinguirla de otras posesiones suyas en el Atlántico, como Saint John y la ciudad de St. John's. El nuevo nombre de la colonia homenajeaba al cuarto hijo del Rey Jorge III del Reino Unido, Duque de Kent, que por entonces comandaba las tropas británicas en Halifax.

Durante la década de 1840, los habitantes de la Isla del Príncipe Eduardo comenzaron a exigir una mayor autonomía política. El Reino Unido cedió a la presión en 1851, dando a la Isla total control sobre el gobierno, en asuntos internos.

En septiembre de 1864, la Isla del Príncipe Eduardo fue sede de la Conferencia de Charlottetown, que fue el primero de una serie de encuentros que llevaron a la creación de los "Artículos de la Confederación de Canadá", en 1864 - firmada por Ontario, Quebec, Nuevo Brunswick y Nueva Escocia. Sin embargo, la Isla del Príncipe Eduardo, junto con Terranova y Labrador, no estuvieron de acuerdo con los términos de la Confederación y se negaron a entrar en ella. A fines de la década de 1860, aún como colonia británica, políticos de la Isla del Príncipe Eduardo barajaban varias posibilidades: volverse independientes, unirse a Canadá o a los Estados Unidos, o continuar siendo una colonia inglesa. Finalmente, la Isla decidiría unirse a Canadá en 1873.

A principios de la década de 1870, la Isla del Príncipe Eduardo inició la construcción de un ferrocarril, pero rápidamente comenzó a endeudarse. No queriendo responsabilizarse por el pago de la deuda contraída, Inglaterra presionó a su colonia para que nuevamente entablase negociaciones con la Confederación Canadiense. En 1873, el entonces primer ministro de Canadá, John Alexander Macdonald, intentando detener a cualquier precio el peligro que representaba el expansionismo norteamericano, propuso como solución al problema los siguientes términos: Canadá pagaría las deudas contraídas por la Isla del Príncipe Eduardo, compraría todos los lotes que restasen en ella y, también, proporcionaría transporte adecuado entre la isla y el continente; pero ésta, a cambio, tendría que unirse a la Confederación. De este modo, la Colonia aceptó los términos y entró a formar parte de la Confederación Canadiense el 1 de julio de 1873.

Durante las primeras décadas como provincia canadiense, la población de la isla creció gradualmente. Sin embargo, se hizo claro que los establecimientos industriales y comerciales de la provincia no estaban en condiciones de competir con los productos más baratos producidos en las otras provincias de Canadá (principalmente en Ontario y Quebec). La agricultura y la pesca eran las principales fuentes de ingreso de la provincia, pero ni siquiera estos dos sectores podían competir con la industria pesquera de Nuevo Brunswick o de Nueva Escocia, o contra la industria agropecuaria del interior canadiense. 

La provincia se hizo cada vez más dependiente de la ayuda financiera del gobierno canadiense, y su población comenzó a decaer gradualmente en número a partir de la década de 1890. Durante las décadas de 1920 y 1930, la provincia tuvo que gastar más en educación, salud pública y asistencia social y financiera, lo que, a pesar de haber frenado el descenso poblacional de la Isla, aumentó sus problemas financieros. La Gran Depresión de los años 30 solamente vino a agravar la situación financiera de la provincia en su conjunto, que había sido hasta entonces solo precaria, durante las primeras décadas del siglo XX - con excepción de un breve período, durante los años de la Primera Guerra Mundial.

La Isla del Príncipe Eduardo recibió mayor ayuda financiera del gobierno canadiense a partir del inicio de la década de 1940. Esto, aunado a la Segunda Guerra Mundial, generó que diversos servicios públicos, tales como transportes y educación, fuesen drásticamente mejorados; así como que hubiese una recuperación de la industria agraria. Con esto, la Isla del Príncipe Eduardo registró su primer período de crecimiento poblacional, desde el censo nacional de 1891. Desde el inicio de la década de 1940, la población de la provincia ha solamente crecido, aunque muy lentamente, siendo así que fue apenas, durante el inicio de la década de 1970, que la población de la Isla del Príncipe Eduardo superó la que tenía la provincia en 1891.

El gobierno de la Isla del Príncipe Eduardo, en coordinación con el gobierno canadiense, invirtió aún más en educación y en transportes. Para entonces, el turismo ya se había convertido en una de las principales fuentes de ingreso. Además, en 1969, la provincia intentó revitalizar su economía a través de diversos actos, los cuales fracasaron en su objetivo; así que el gobierno de la Isla del Príncipe Eduardo volvió, durante la década de 1980, a dar mayor atención a sus principales sectores económicos: la agricultura, la pesca y a un fuerte turismo en crecimiento. En 1997, el Puente de la Confederación fue inaugurado, ofreciendo a la provincia una conexión directa con el resto del continente e incentivando así el turismo. Esto ayudó a colocar el turismo en la segunda posición como fuente de ingreso de la provincia, atrás solamente de la agricultura.

La isla se conoce como el Jardín del Golfo, ya que la isla se encuentra en el golfo de San Lorenzo, al oeste de la Isla de Cabo Bretón, al norte de la península de Nueva Escocia, y al este de Nuevo Brunswick. Las costas del sur forman el Estrecho de Northumberland. La isla cuenta con dos zonas urbanas. La más grande se centra en el puerto de Charlottetown, ubicada en medio de la costa del sur; consiste en la capital, Charlottetown, varias comunidades residenciales como Cornwall y Stratford, y una franja cada vez más ancha de urbanizaciones y desarrollo urbano. Otra zona urbana se centra en el puerto de Summerside, ubicada en la costa del sur 40 km (25 mi) al oeste del puerto de Charlottetown; consiste ante todo en la ciudad de Summerside. Estos puertos, como todos los puertos naturales de la isla, son creados por rías.

La Isla del Príncipe Eduardo, debido a su localización (rodeada por grandes cuerpos de agua) posee un clima más estable y ameno que el resto del país, registrando las temperaturas más altas de Canadá durante el invierno y las más bajas durante el verano. Por lo cual, el tiempo con el que cuenta la provincia también es muy estable, con condiciones climáticas que poco varían durante un día dado.

Por otra parte, su pequeño tamaño hace que el clima sea en gran medida homogéneo en toda la provincia. La región oeste de la isla posee temperaturas levemente más bajas durante el invierno y más altas en el verano, en relación con la región este, debido a su mayor proximidad con el cuerpo principal del continente.

Durante el invierno, la Isla del Príncipe Eduardo posee una temperatura media de -7°C. La media de las mínimas es de -12 °C y la media de las máximas, de -3 °C. La temperatura más baja que se haya registrado en la provincia es de -37 °C, ocurrida en Alberton, el 26 de enero de 1884. Durante el verano, posee una temperatura media de 19 °C. La media de las mínimas es de 13 °C y la media de las máximas, de 22 °C. Y, a su vez, la temperatura más alta que se haya registrado en la provincia es de 37 °C, ocurrida en Charlottetown, el 19 de agosto de 1935. Su tasa de precipitación media anual de lluvia es de 111 centímetros, mientras que la de nieve es de 276 centímetros.

Históricamente, el Partido Liberal de Canadá ha protagonizado la política de la Isla del Príncipe Eduardo. Más de la mitad de los gobernadores de la provincia han sido liberales y, consecuentemente, más de la mitad de los gobiernos provinciales han sido dominados por una Asamblea compuesta por una mayoría liberal. Los liberales ocupan actualmente los cuatro escaños que a la provincia le corresponden en la Cámara de los Comunes.

Cuando entró a la Confederación, la representación parlamentaria de la provincia era de seis escaños en la Cámara de los Comunes y de cuatro en el Senado. Sin embargo, a medida que el tiempo fue pasando, la población de la provincia no creció proporcionalmente en relación al crecimiento de la del resto del país - especialmente la del oeste de Canadá -, por lo cual disminuyó el número de representantes en la Cámara de los Comunes a cuatro.

La gran mayoría de las localidades de la provincia son administradas por un alcalde y por un consejo municipal. Cerca del 60% de los ingresos que percibe el gobierno de la provincia son por concepto de impuestos. El resto proviene de los ingresos recibidos del gobierno federal y de empréstitos.

El teniente-gobernador representa a la Reina Isabel II como jefe de la Isla del Príncipe Eduardo. El jefe del gobierno en práctica, y también el mayor oficial del poder ejecutivo de la provincia, es el "premier," o primer ministro. El premier es quien encabeza el partido político con más escaños en la Asamblea Legislativa; preside un Consejo Ejecutivo, que es el gabinete de la provincia. Hay unos 25 diferentes ministros en el gabinete, como el Ministro de Educación, el Ministro de Economía, el Ministro de Trabajo, etc. Los ministros renuncian sus posiciones si el gabinete pierde el apoyo de la mayoría de los miembros del parlamento.

El Poder Legislativo de la Isla del Príncipe Eduardo es la Asamblea Legislativa, la cual está compuesta por 27 miembros. Cada uno de ellos es elegido por la población de uno de los 27 distritos electorales de la provincia, para mandatos de hasta cuatro años de duración. Si el Teniente-Gobernador disolviere la Asamblea antes de estos cinco años, a petición del gobernador, se convocará a nuevas elecciones. No hay límite de términos que una persona puede ejercer.

La corte más alta es la Corte Suprema de la Isla del Príncipe Eduardo, compuesta por nueve jueces. Estos jueces son nombrados por el primer ministro de la provincia y aprobada simbólicamente por el teniente-gobernador. Una vez escogidos, los jueces de la corte pueden ejercer sus oficios hasta los 75 años de edad.
Según el censo nacional canadiense de 2006, la población de la Isla del Príncipe Eduardo era de 138 519 habitantes, un crecimiento de 2,4% sobre la población de la provincia en relación a 2001, que era estimada en 135 294 habitantes.

Entre las diez provincias de Canadá, la Isla del Príncipe Eduardo es la provincia de población más densa. Hay sin embargo 32 ciudades canadienses con más habitantes que la Isla del Príncipe Eduardo. Según el censo canadiense de 2001, el mayor grupo étnico de la provincia son los escoceses (38,0%), seguidos por los ingleses (28,7%), irlandeses (27,9%), franceses (2,3%), alemanes (4,0%), y holandeses (3,1%). Casi la mitad de los respondientes se identificaron sencillamente como "canadienses."
Composición racial de la población de la Isla del Príncipe Eduardo:


La provincia está dividida en 3 condados:

La Isla del Príncipe Eduardo posee apenas dos ciudades primarias ("cities"): Charlottetown y Summerside. La provincia también tiene otras siete ciudades secundarias ("towns"): Stratford, Cornwall, Montague, Kensington, Souris, Alberton y Georgetown.

10 mayores municipalidades de la provincia

La economía de la Isla del Príncipe Eduardo está basada principalmente en la agricultura, el turismo y la pesca. Todas estas actividades tienen grandes variaciones a lo largo del año y son susceptibles a impactos externos como, por ejemplo, desastres naturales y depresiones económicas. Esta provincia es extremamente pobre en recursos naturales, como minas minerales, no obstante, existen cantidades todavía no determinadas de gas natural en su parte oriental.

La agricultura es la mayor fuente de ingreso de la economía de la provincia desde que esta fue colonizada por los ingleses - actualmente, la papa es el vegetal más cultivado en la provincia. La Isla del Príncipe Eduardo es el mayor productor de patatas de Canadá - es responsable por un tercio de la producción anual canadiense. Cerca de 1,3 billones de kilos de patatas son producidas anualmente en la provincia, que es también gran productora de semillas de patatas, que son exportadas a más de 20 países alrededor del mundo.

El turismo es la segunda mayor fuente de ingreso de la Isla del Príncipe Eduardo, habiendo superado en importancia a la pesca a mediados del siglo XX. Las principales atracciones turísticas son sus playas, pistas de golf y las atracciones y eventos locales. La estación más dinámica es el verano - meses de julio y agosto - pese a un crecimento del número de turistas norteamericanos en septiembre y en octubre en la provincia (así como en Nuevo Brunswick y Nueva Escocia se está prolongando la estación turística hasta los meses de invierno.

La pesca todavía es la tercera mayor fuente de ingreso de la Isla del Príncipe Eduardo; sin embargo, la provincia es menos dependiente de la industria pesquera de lo que lo son otras provincias canadienses localizadas en costa la costa atlántica (Nuevo Brunswick, Nueva Escocia, Terranova y Labrador). La captura de langostas es la mayor actividad pesquera de la isla, la cual se efectúa en mayo y en septiembre. Por el hecho de que la provincia queda cubierta de hielo oceánico durante los meses de invierno, la pesca está limitada a los meses de verano, al final de la primavera y al inicio del otoño.

El Producto Interno Bruto de Columbia Británica es de más de 2,8 billones de dólares canadienses por año. El sector primario aporta el 5% del PIB de la Isla del Príncipe Eduardo. La agricultura y la ganadería representan juntas el 5% del PIB de la provincia, y emplea aproximadamente 4,6 mil personas. La Isla del Príncipe Eduardo posee cerca de 2 mil tierras de cultivo, que cubren aproximadamente la mitad de la provincia. Apenas Saskatchewan posee un mayor porcentaje de su extensión territorial cubierta por tierras de cultivo. La pesca representa el 4% del PIB de la provincia y emplea aproximadamente 2 mil personas. La silvicultura representa el 1% del PIB de la provincia, empleando cerca de 700 personas.

El sector secundario representa el 16% del PIB de la Isla del Príncipe Eduardo. El valor total de los productos fabricados en la provincia es de 275 millones de dólares canadienses. Los principales productos industriales fabricados en la provincia son principalmente alimentos industrializados, en parte asociado a la industria pesquera de la provincia. La industria manufacturera representa el 10% del PIB de la Isla del Príncipe Eduardo y emplea aproximadamente 6,5 mil personas. La industria de construcción representa el 5% del PIB de la provincia y emplea cerca de 3,8 mil personas. Es despreciable el aporte económico de la explotación minera de la provincia. El único recurso natural presente en la provincia de uso importante para el hombre son las pequeñas reservas de gas natural.

El sector terciario representa el 76% del PIB de la Isla del Príncipe Eduardo. Servicios personales y comunitarios representan el 25% del PIB de la provincia y emplea cerca de 24,1 mil personas. Servicios financieros e inmobiliarios emplean aproximadamente 2,2 mil personas y representa más de 20% del PIB de la Isla del Príncipe Eduardo. Servicios gubernamentales representan el 13% del PIB de la provincia, empleando aproximadamente 5,6 mil personas. El comercio por mayoreo y menudeo representa el 11% del PIB de la provincia y emplea aproximadamente 9,9 mil personas. Transportes y telecomunicaciones representan el 7% del PIB y emplean cerca de 5 mil personas, y las utilidades públicas representan el 1% del PIB de la provincia, empleando cerca de 100 personas. La provincia genera apenas el 40% de la eletricidad que consume, 5% en plantas termoeléctricas de carbón, y 35%, en plantas eólicas. El otro 60% necesita ser comprados de Nuevo Brunswick.

En 1999, se registraron cerca de 24200 estudiantes en las escuelas públicas de la Isla, y unos 1400 profesores. Por otro lado las escuelas privadas atendieron a cerca de 250 estudiantes, empleando aproximadamente a 10 profesores. El sistema de escuelas públicas de la provincia consumió cerca de 143 millones de dólares canadienses, y el gasto de las escuelas públicas por estudiante es de aproximadamente 5,8 mil dólares canadienses.

La Isla del Príncipe Eduardo cuenta con 20 bibliotecas públicas administradas por la provincia. Hay una sola universidad, la Universidad de la Isla del Príncipe Eduardo, en Charlottetown. También hay un sistema de colegios comunitarios, Holland College, con facultades especializadas en varias ciudades. 

Las primeras escuelas de la Isla del Príncipe Eduardo fueron construidas a inicios del siglo XIX. En 1852, el gobierno colonial de la provincia creó un sistema de escuelas públicas e instituyó un impuesto para costear tal sistema. En 1877, la provincia instituyó el Consejo Central de Educación y, en 1945, el Departamento de Educación de la Isla del Príncipe Eduardo.

Actualmente, el Departamento de Educación de la Isla del Príncipe Eduardo dicta las reglas y patrones que todas las instituciones educacionales en la provincia tienen que seguir. Todas las escuelas son directamente administradas por el Departamento de Educación. La atención escolar compete a todos los niños y adolescentes con más de seis años de edad, hasta la graduación de la segundo grado o hasta los veinte años de edad.

La primera biblioteca pública de la Isla del Príncipe Eduardo fue fundada en 1933. Actualmente, las 20 bibliotecas públicas de la provincia son administradas por el Departamento de Educación de la provincia. La Isla del Príncipe Eduardo cuenta con una universidad, la Universidad de la Isla del Príncipe Eduardo, y una facultad, ambas administradas por el Departamento de Educación de la provincia.

En 1997, el Puente de la Confederación fue inaugurado, conectando la Isla del Príncipe Eduardo con Nuevo Brunswick, así reemplazando al servicio del "ferry" entre ambas provincias. 
Hasta hace poco tiempo, el transporte de pasajeros y, principalmente, de carga, hacia dentro y fuera de la provincia, era relativamente caro y demorada 45 minutos, vía "ferry", y esto no contando el horario de atención (servicio restringido por las noches, por ejemplo) o el tiempo de espera entre la salida de un "ferry" y la llegada de otro. Estas embarcaciones conectaban la Isla del Príncipe Eduardo con Nueva Escocia, Nuevo Brunswick y las Islas de la Magdalena.

En 1997, el Puente de la Confederación fue inaugurado, conectando la Isla del Príncipe Eduardo con Nuevo Brunswick, y, así, substituyó el servicio de "ferry" entre ambas provincias, el cual fue descontinuado; mientras que los que había con Nueva Escocia y las Islas de la Magdalena continúan hasta el día de hoy. Actualmente, la provincia posee 4,9 mil kilómetros de vías públicas. Una curiosidad es el hecho de que, hasta el 1 de mayo de 1924, los vehículos transitaban a la izquierda de cualquier vía pública, a diferencia del resto de Canadá, donde lo hacían a la derecha.

Cuando fue inaugurado el Ferrocarril de la Isla del Príncipe Eduardo, en 1873, era un ferrocarril de trocha angosta. Fue convertido en trocha patrón o estándar en 1930. Anteriormente, en 1915, este ferrocarril había pasado al control de "Ferrocarriles Gubernamentales Canadienses", un órgano público federal, que se convirtió en "Ferrocarriles Nacionales Canadienses" (FNC) en 1918. En 1989, FNC decidió abrir mano de sus líneas en la provincia. Actualmente, la Isla del Príncipe Eduardo es la única provincia canadiense sin servicio ferroviario de transporte de carga o de pasajeros. El antiguo ferrocarril que tenía es actualmente un ferrocarril turístico.

El primer periódico publicado en la Isla del Príncipe Eduardo fue el "Journal-Pionner", publicado en 1867, en Summerside. En 1887, la primera edición del "The Guardian" fue publicada en Charlottetown. Estos son publicados hasta el día de hoy, siendo los dos únicos periódicos de circulación diaria de la provincia. La primera estación de radio de la provincia fue fundada en 1924, en Charlottetown. Actualmente, la provincia posee 8 estaciones de radio. Ninguna estación de televisión ha sido fundada todavía en la Isla del Príncipe Eduardo, dependiendo únicamente de las estaciones de radio localizadas en las provincias vecinas de Nuevo Brunswick y Nueva Escocia.




</doc>
<doc id="1526" url="https://es.wikipedia.org/wiki?curid=1526" title="Instrumento de percusión">
Instrumento de percusión

Un instrumento de percusión es un tipo de instrumento musical cuyo sonido se origina al ser golpeado o agitado. Es quizá, la forma más antigua de instrumento musical.

La percusión se distingue por la variedad de timbres que es capaz de producir y por su facilidad de adaptación con otros instrumentos musicales. Cabe destacar que puede obtenerse una gran variedad de sonidos según las baquetas o mazos que se usan para golpear algunos de los instrumentos de percusión.

Un instrumento de percusión puede ser usado para crear patrones de ritmos (batería, tam-tam entre otros) o bien para emitir notas musicales (xilófono).
Suele acompañar a otros con el fin de crear y mantener el ritmo. Unos de los instrumentos de percusión más famosos son el redoblante (tambor) y la batería.

Los instrumentos de percusión pueden clasificarse en dos categorías según la afinación: 

Entre ellos están: el bombo, la caja, el cajón, el afuche, las castañuelas, las claves, el cencerro, el címbalo, el güiro, la matraca, la zambomba, el vibraslap, la quijada, la batería, la tuntaina o victoria

En las orquestas se suele diferenciar entre:

Según otro criterio, se pueden clasificar en cuatro categorías que son:

Esta clasificación tampoco es estricta, por ejemplo, la pandereta es un membranófono y un idiófono porque tiene ambos, en la piel y en los cascabeles.




</doc>
<doc id="1528" url="https://es.wikipedia.org/wiki?curid=1528" title="Iron Maiden">
Iron Maiden

Iron Maiden es una banda británica de "heavy metal", fundada en 1975 por el bajista Steve Harris. Es considerada una de las bandas de Heavy Metal más importantes de todos los tiempos. Ha vendido más de 100 millones de discos en todo el mundo, a pesar de haber contado con poco apoyo de la radio y la televisión comercial durante la mayor parte de su carrera. Sin embargo, la banda basó su éxito en llegar directamente a los aficionados, grabando discos de alta calidad y realizando actuaciones en vivo consideradas de las mejores del género.,

Iron Maiden ha obtenido diversos reconocimientos a lo largo de su carrera como el Premio Ivor Novello para el logro internacional en 2002. En 2005 fueron incluidos en el "Hollywood's RockWalk" en Sunset Boulevard, Los Ángeles. En 2009 fue ganadora del premio Mejor Performance en Vivo en los BRIT Awards, el premio musical más importante del Reino Unido. En el año 2011 también obtuvieron un Grammy, en la categoría de 'Mejor interpretación de Metal', por el tema 'El Dorado'.Además ha ganado el premio de mejor banda metal británica del año en varias ocasiones, en los "Metal Hammer Golden Gods Awards", entre otros reconocimientos.

Durante sus más de 40 años de trayectoria, Iron Maiden ha sido identificada gráficamente por su famosa mascota "Eddie the Head", quien ha aparecido en la gran mayoría de las portadas de sus álbumes y singles, así como en sus presentaciones en vivo.

Tras varias audiciones y cambios en su formación, esta finalmente se consolidó con el vocalista Paul Di'Anno, los guitarristas Dave Murray y Dennis Stratton, y el baterista Clive Burr, siempre bajo el liderazgo del bajista Steve Harris. Luego de muchas giras por todo el Reino Unido, en 1979 lanzan su EP llamado The Soundhouse Tapes, y en 1980, su álbum debut homónimo, el cual llegó al cuarto puesto de las listas británicas, sin mediar promoción masiva alguna. Ese mismo año, Stratton fue reemplazado por el guitarrista Adrian Smith, con quién publicaron el álbum "Killers" (1981). Luego, y tras la salida de Di Anno, ese mismo año, el cantante Bruce Dickinson entró para ocupar el puesto de vocalista para el álbum The Number of the Beast de 1982, el cual llegó al número uno de las listas británicas, marcando el inicio de una serie de lanzamientos de impacto. Para el año 1983 la banda lanzó el álbum Piece of Mind, que contaba como novedad con la salida del baterista Clive Burr, y el ingreso de Nicko McBrain en su reemplazo. A partir de allí, se consolidó la alineación más estable y exitosa que ha tenido la agrupación, la cual ha realizado numerosas giras y álbumes. Iron Maiden ha grabado 16 álbumes de estudio, y es considerada una de las bandas más influyentes no solo para el heavy metal y sus respectivos subgéneros, sino también para diversas agrupaciones de rock, e incluso artistas de otros estilos.
La historia de Iron Maiden parte en el año 1971, cuando Steve Harris inspirado en bandas como Wishbone Ash, Thin Lizzy, UFO, Black Sabbath, Jethro Tull, Genesis, King Crimson, The Who y Deep Purple, entre otros, adquiere un bajo Fender Precision Bass por unas 40 libras esterlinas, y tras dejar atrás la opción de la batería, para la cual no contaba con el espacio suficiente. Inicialmente Steve también tuvo la ilusión de ser jugador de fútbol del West Ham, sin embargo, tras meditarlo comenzó a dedicar todos sus esfuerzos a su otra gran pasión, la música. Esto condujo a la formación de una agrupación musical que llamó "Gypsy's Kiss" en 1972, cuyo primer concierto fue en el mítico reducto "Cart & Horses" en Maryland Point, Stratford.

Tras unos cuantos conciertos bajo el nombre de Gypsy´s Kiss, Steve decide disolver todo eso y cambiarlo por el proyecto "Smiler", cuyos miembros tenían algunos años más que él, lo cual le sirvió para acumular experiencia. Pese a ello, Steve Harris deseaba plasmar sus inquietudes como compositor en mayor grado y el resto de la banda rechazaban sus composiciones por considerarlas "muy complicadas". Esto hizo que el bajista renunciara a Smiler y se propusiera formar su propia agrupación.

De este modo, Harris funda a Iron Maiden el día de Navidad de 1975. El grupo lo componían , en las guitarras, en la batería, Steve Harris por supuesto en el Bajo y en la voz. Steve tenía la idea un sonido inspirado en la banda Wishbone Ash en cuanto a las "guitarras gemelas". Desde ese momento surgieron canciones que hoy en día son emblemáticas para la banda, como “Transylvania”, “Wrathchild” o “Innocent Exile”.

El 1 de mayo de 1976 tuvo lugar el primer concierto de la banda en el Cart & Horses, un pub muy popular del East End de Londres. El fenómeno de voz en voz era cada vez más bullado y los seguidores de la banda empezaron a crecer con cada presentación.

A Steve se le ocurrió el nombre al ver un instrumento de tortura en una vieja película llamada "El hombre de la máscara de hierro". Era un ataúd de metal "(conocida como doncella de hierro)" con docenas de clavos oxidados en su interior donde metían a sus víctimas y las encerraban hasta morir. Grande fue su sorpresa cuando en medio de una presentación en el “Cart & Horses” en Stratford, Londres, lo llamaron para decirle que ya había otra banda con ese nombre, pero tal era la seguridad por parte de Harris y el resto de la banda (en especial Ron “Rebel” Matthews) en lo que estaban haciendo, que sin importarles nada, siguieron adelante con el nombre y la banda.

El vocalista Paul Day al poco tiempo fue sustituido por el cantante anterior (específicamente de la era "Smiler"), , que si bien no tenía una gran voz como Paul Day, sí tenía bastante presencia. Wilcock a su vez le recomendó a Steve un talentoso guitarrista llamado Dave Murray y admirador al igual que Harris, de Wishbone Ash, Fleetwood Mac, Free, Genesis, UFO, Deep Purple, Jimi Hendrix, etc, y a su vez era seguidor y admirador de lo que estaba haciendo Iron Maiden en sus diversas presentaciones en Londres. La idea de integrar a Dave Murray era la de formar una banda con seis miembros y tres guitarristas, curiosamente y por cosas del destino, tal cual es la realidad de la banda hoy en día.

En 1976 el apogeo comercial del punk era bastante fuerte a diferencia de la escena del rock que venía de capa caída, por lo que los ingresos monetarios para la banda eran muy bajos a pesar del gran éxito a nivel underground y de seguidores que estaban teniendo, y fue justamente uno de los motivos por el cual Dave Sullivan y Terry Rance deciden abandonar la banda, ya que cada uno de ellos había contraído matrimonio y debían mantener sus respectivas familias, por lo que se ve imposibilitada la idea de las tres guitarras junto a Dave Murray, que por otro lado había enganchado en gran forma con Steve Harris.

Es por esto que por intermedio del cantante Dennis Wilcock reingresó (Bob ya había estado un muy corto tiempo con Iron Maiden) como el segundo guitarrista. Dennis Wilcock se caracterizaba por una personalidad muy frontal, polémica, manipuladora y egocéntrica por lo que comienza a imponer sus gustos personales y terminando por echar al baterista de la banda Ron “Rebel” Matthews, también al propio reingresado Bob "Bob Sawyer" Angelo, y hasta al mismísimo Dave Murray, simplemente porque no le gustaba su novia, lo cual generó una enorme presión en Steve Harris quien tras evaluar la difícil propuesta de Wilcock de: "se va él o me voy yo" y tras pensar en lo difícil que sería encontrar un nuevo cantante, finalmente optó por acceder a los caprichos de Wilcock sacando a Dave Murray de la banda, en lo que el mismo define en el documental de la banda "Early Days" como una actitud personal totalmente estúpida de su parte.

En 1977 Terry Wapram se integra a la banda en la guitarra, junto al excéntrico Barry Graham Purkis, más conocido como "Thunderstick" en la batería y que venía de la banda Samson. Pero como una sola guitarra no era suficiente para compensar las armonías, decidieron integrar a un tecladista llamado Tony Moore, pero finalmente en la primavera de 1977 es el mismo Dennis Wilcock quien tras un concierto decide retirarse intempestivamente. El norte de la banda oscilaba entre la gran cantidad de seguidores y los cambios que siguieron ya que Steve Harris decide prescindir de Tony Moore en los teclados y Thunderstick en la batería, sin embargo, siguió insistiendo en conformar al fin una agrupación sólida y es así cuando se vuelve a topar con el baterista (había tocado con él en la era "Smiler"). Junto con esto, se le ocurre la idea de reintegrar a Dave Murray para que hiciera dupla con Terry Wapram en las guitarras, pero como este último no quiso debido a que estaba acostumbrado a tocar solo, también fue descartado de la banda. Sin embargo, es así como Dave Murray se reintegra a Iron Maiden conformada hasta ese momento solo por Steve Harris y Doug Sampson. A pesar de las adversidades el trío de músicos siguió firme en su propósito.

De inmediato un compañero de Doug Sampson recomendó a Paul Di'Anno como vocalista para la banda. Paul para entonces se encontraba en una banda llamada "Bird of Prey", y fue del gusto inmediato de Steve Harris y fue en ese mismo año (1977) que se integró a la banda. El grupo estuvo bien por bastante tiempo con un solo guitarrista, compensando con el bajo las partes de la segunda guitarra en canciones como “Iron Maiden”, y fue justamente en este tiempo cuando todo lo ganado fue poco a poco invertido en producción escenográfica y demases, como por ejemplo la "Eddie The Head" detrás de la batería de Doug Sampson.

Aquellos tiempos fueron muy duros para Harris y sus compañeros; eran los años del punk que explotaba por las calles de Londres, con bandas como los Sex Pistols que arrasaban con todo, incluso algunas disqueras le sugirieron a Harris que cambiara la imagen de su grupo, que se cortasen el pelo y que adaptaran su música a los tiempos que corrían, sin embargo Steve Harris tenía una idea muy clara de cómo quería que fuera su grupo y el tipo de música que querían tocar. En sus propias palabras, y en tono un tanto irónico y humorístico: ""no podría haber comenzado una banda de punk... eso habría estado en contra de mi religión"". Di'Anno, por su parte, comentó en aquellos tiempos, ""compositores que alguna vez estuvieron en Fairport Convention están ahora en The Clash, solo viven alterando sus gustos para mantenerse acorde a los tiempos. No veo la razón de eso. Debes mantenerte en la música que te gusta, mantenerte fiel"". Así, Harris mantuvo la agrupación tal y como él creía que debía ser.

Pero si bien es cierto que los cuatro integrantes estaban muy afiatados, definitivamente necesitaban otro guitarrista para seguir evolucionando, fue así como pasaron esporádicamente por la banda acompañando a Dave Murray; Paul Todd, Tony Parsons y Mad Mac. Fueron varias las anécdotas que cuenta Steve Harris alrededor de esta época y estos tres guitarristas, como por ejemplo, el caso de Paul Todd que siendo un gran guitarrista se veía impedido de ensayar por su novia, o Mad Mac que siempre llevaba a su perro a los ensayos, y que partió muy entusiasta, pero tenía una extraña bipolaridad anímica que tras unos meses le impidió seguir en la banda

Como las giras por Gran Bretaña ya eran bastante extensas adquirieron un camión al que transformaron para acarrear los equipos y también para poder dormir durante estas, y le llamaron "La Diosa Verde" por su color verde oscuro. Fue en este contexto en el que en 1978 Paul, Doug, Steve y Dave grabaron The Soundhouse Tapes en los estudios Spaceward en Cambridge, incluso durmiendo en el suelo de la casa de una enfermera que había conocido Paul Di Anno, ya que la "Diosa Verde" no los resguardaba totalmente del frío. Después de haber vendido una impresionante cantidad de copias de quisieron llevarse a casa la cinta original para agregar más temas a la grabación, pero cuando fueron a retirarla se encuentran con la desagradable sorpresa que el “Master” había sido borrado quedando solo el cartucho QIC que es lo que al final resultó como "The Soundhouse Tapes".

Fue por aquel tiempo que conocieron a Neal Kay, un DJ roquero, quien era dueño del primer local de heavy metal de Londres el "Bandwagon". El primer encuentro entre Neal y Steve Harris fue muy especial ya que el mismo Neal reconoce no haber sido muy amable con Steve cuando este le entregó el demo para que lo escuchara, sin embargo cuando se dio el tiempo de oírlo quedó realmente asombrado e impactado por la fuerza de la banda, de hecho el mismo cuenta que es primera vez que le sucedía eso con una banda. Al tiempo temas como "Iron Maiden"o "Prowler" se pondrían a la cabeza de la lista de canciones del "Bandwagon", y ya al momento de tocar en vivo en el mismo recinto la revolución de la banda en la escena metalera londinense era total, y tal como cuenta el mismo Neal Kay, la gente del rock y el heavy metal se rindió a los pies de Iron Maiden en toda Inglaterra.

Después de esto es que conocen a Rod Smallwood quien escuchó los temas de la banda sorprendiéndose gratamente e invitándolos a un par de conciertos en el Windsor Castle en Harrow Road y en el Swan en Hammersmith, pero no todo sería color de rosa ya que junto a la calidad del grupo, la presencia contestataria y la respuesta que Iron Maiden generaba en la audiencia de la época, (que incluso ya era bastante más fuerte que el de las propias bandas punk de moda e imperantes), les trajo algunos problemas en algunos locales en los que se les prohibió tocar por la algarabía que generaban. Pero los problemas vendrían en especial a manos de Paul Di Anno, de hecho la segunda vez que Rod Smallwood se dispuso a ver a la banda en vivo, Paul había sido arrestado por la policía, teniendo que ser el mismo Steve Harris quien asumiera el rol de vocalista (además de bajista) por esa noche, y con un Iron Maiden conformado como un Power trio.

Rod Smallwood lejos de desilusionarse se impactó por la actitud de Steve y Dave sobre el escenario. A partir de ese momento Rod decide asumir el rol de mánager de la banda, y junto con eso el rock británico comenzaba a vivir una nueva etapa, y sobre todo a renacer de la mano de Iron Maiden, haciéndose eco de esto la prensa especializada y los medios que volvían sus ojos al género, y en especial a esta banda que estaba revolucionando absolutamente la escena. Fue en este contexto que aparece el sello EMI interesado en contar con el grupo en sus filas, después de haber visto un par de shows electrizantes como contaran los mismos John Darnley, Martin Haxby y Brian Sheperd de EMI Records, en especial Darnley encargado de la parte rock del sello, y que incluso se hizo admirador de la banda. La idea era de ficharlos para tres discos. Paradójicamente el ritmo vertiginoso que llevaba la banda le pasó la factura a Doug Sampson quien decide retirarse. Paralelamente al retiro de Doug se integra el guitarrista Dennis Stratton justo antes de la grabación del primer álbum, y es el mismo Stratton justamente quien lleva a Clive Burr (al igual que "Thunderstick" proveniente de la banda Samson) para reemplazar a Doug Sampson en los tambores, quedando de este modo lista la agrupación que plasmaría la esperada y siguiente grabación.

El mánager Rod Smallwood logró que Brian Shepherd, presidente del sello discográfico EMI, presenciara el histórico concierto de la banda en el Club Marquee en 1979 el cual calificó como electrizante, y una semana más tarde, Iron Maiden firmaba contrato con la compañía discográfica. Contrato que estaba en competencia con otra banda representativa del NWOBHM, Def Leppard.

Por fin en diciembre de 1979 graban Iron Maiden con Paul Di'Anno en la voz, Steve Harris en bajo y coros, Dave Murray en guitarra, Clive Burr en batería y Dennis Stratton en guitarra y coros, celebrando además la edición del primer sencillo oficial "Running Free" que rápidamente escalaba las listas británicas hasta posicionarse en el puesto treinta y cuatro. Después de "Running Free", la prensa británica fue evidenciando en Paul Di'Anno un paulatino giro en su actitud hacia el grupo.

El 14 de abril de 1980 lanzaron oficialmente el esperado primer álbum de estudio con el nombre Iron Maiden. Si bien recibió excelentes críticas y alabanzas por parte de los medios especializados, y sobre todo por parte de los admiradores que lo califican como una genial pieza maestra con grandes clásicos como "Prowler, Phantom Of the Opera, Transylvania, Running Free, Remember Tomorrow", etc, para Steve Harris no llegó al nivel que hubiera deseado, ya que consideró que el productor discográfico Will Malone no trabajó lo suficiente en el sonido. A pesar de la inconformidad de Harris, el disco tiene un sonido crudo que va acorde con la voz de Di'Anno lo cual lo hace una pieza vital y genial en la que se plasmó la gran energía y magia de aquella época, y que por otro lado llegó al número 4 en las lista británicas, y para celebrarlo, la banda retornó al mítico "Ruskin Arms" que los vio nacer para hacer otro recordado e histórico concierto (además de una gira benéfica). El gran éxito del álbum debut de Iron Maiden no fue casualidad, sino el resultado de la calidad superior que ya los distinguía del resto de las bandas desde hace años, y el apoyo de sus miles de seguidores con los que ya contaban.

Después del primer álbum, el guitarrista Dennis Stratton, que ingresara en la séptima alineación del grupo sale de la banda debido a diferencias musicales. En su reemplazo entró Adrian Smith, el cual era amigo personal de Dave Murray, y que anteriormente había rechazado unirse, ya que estaba muy entusiasmado y cómodo con su banda Urchin, que además estaba teniendo éxito.

Luego vino el tremendo "Killers" lanzado el 2 de febrero de 1981. El productor discográfico fue Martin Birch, que había trabajado con grupos como Deep Purple, Black Sabbath y Fleetwood Mac "(teniendo en su haber la producción de discos clásicos como Machine Head y Heaven and Hell de los mencionados respectivamente)". Al escuchar el material del grupo, Martin Birch le preguntó a Steve Harris por qué no lo habían llamado para el primer disco. La respuesta fue ""Pensamos que eras demasiado famoso para decir que si"". Comparado con el primer disco, si bien quizás no produjo el impacto del anterior, Killers es mucho más acabado en cuanto a sonido. La voz de Di'Anno, llena de pasión y emoción quedó muy bien plasmada en temas como "Purgatory, Wrathchild" o "Killers", etc. Paul Di'Anno poseía un estilo más bien gutural, además de una gran capacidad vocal e increíble energía. No era el típico vocalista de heavy metal que gritaba hasta llegar a las notas más altas posibles, sino que fue a través de su estilo rebelde, despreocupado y contestatario con el que manejaba al público, lo que sumado a sus tremendas composiciones, ayudó enormemente a atraer más y más admiración por la banda.
Es en febrero de ese mismo año que Iron Maiden comienza su primera gran gira mundial, aprovechando la numerosa cantidad de admiradores alrededor del mundo que ya quería verlos en vivo. En Europa salieron de gira con Kiss llegando a ser todo un acontecimiento el hecho de que la banda "soporte" tuvieran tal recepción que incluso llegaba a superar la de los propios Kiss como hasta el mismo mánager de la banda estadounidense reconociera. Lo mismo en una extensa gira por los EE. UU. en donde salieron de tour con muchas bandas, entre ellas Scorpions, Judas Priest, 38 Special, Rainbow, etc.

Su primera gira por Japón y, junto a esta, la grabación del álbum en directo "Maiden Japan", el 23 de mayo de 1981, le valió al grupo la conquista de su primer disco de oro. No obstante, el ascenso de la banda no frenó los cambios que se producirían al interior de la misma. Paul Di' Anno fue expulsado de la agrupación debido a su estilo de vida de excesos con el alcohol y las drogas, que lo tenían física y psicológicamente desgastado. Di' Anno había sido detenido por la policía en varias ocasiones debido a sus abusos, por lo cual había fallado a la banda en momentos claves. Esto motivó a Steve Harris a tomar la decisión de no contar más con él como vocalista. Tras su ausencia, vocalistas como Terry Slesser audicionaron para la banda, pero fue finalmente fue Bruce Dickinson, (otro ex-Samson), quien llegó el mismo año para ocupar el puesto. Cuando la idea de incluir a Dickinson fue propuesta por Steve al mánager Rod Smallwood, este inicialmente se mostró reticente, debido a un problema que él había tenido en el pasado con la banda Samson. Sin embargo, Steve convenció a Rod de que fueran a ver a Bruce en un show de Samson, en el mítico Reading Festival en Inglaterra. Tras ver al vivo la calidad de Dickinson, tanto como vocalista como frontman, a Rod y a Steve no les quedaron dudas de que él era el cantante ideal para Iron Maiden. De esta manera, lo contactaron para que presentara una audición con la banda, y justo cuando interpretó la canción 'Remember Tomorrow', le dijeron que quedaba contratado. Bruce dudó en aceptar el puesto, pues no quería abandonar a sus compañeros de Samson, pues sabía que con su ausencia la banda podría irse abajo (como efectivamente ocurrió). Pero la propuesta de Iron Maiden era bastante tentadora, al tratarse de una banda ya fichada por la gigante EMI Music y que se encontraba girando por toda Europa, Estados Unidos y Asia. Después de meditarlo por varios días, aceptó. El primer concierto de Dickinson con Iron Maiden fue el 26 de octubre de 1981 en Bologna, Italia.

La consagración definitiva de Iron Maiden alrededor del mundo llegó con su tercer álbum de estudio "The Number of the Beast" (29 de marzo de 1982). La gira promocional del disco fue titulada "The Beast On The Road" comenzando en Inglaterra para culminar diez meses más tarde en Japón siendo su segunda visita a este país. Con el sencillo "Run to the Hills", Iron Maiden llegó hasta el número 7 en el Top 40 británico.
Pero fue en plena gira, y mientras su autobús se quedaba parado en la carretera, cuando recibían la noticia: El álbum "The Number of the Beast" era número 1 absoluto en las listas británicas. Se había extendido como la pólvora el éxito de la doncella en el mundo, y también en Estados Unidos, en donde tenían tantos admiradores en el ámbito del rock, como detractores en lo social y “religioso”. Precisamente estos últimos se manifestaron frente a las puertas de uno de sus conciertos acusándolos de apología al satanismo, básicamente por el tema “The Number Of the Beast” que fue el que gatilló toda la cadena de acusaciones. Por lo mismo, y a pesar de ser un fenómeno mundial, en EE. UU., por el contrario, los medios oficiales o de difusión masiva le dan la espalda, en una especie de censura velada o “ley de hielo”, sin embargo, esto no impidió que igual comenzaran a ser un fenómeno de voz en voz, y hasta romper récords de audiencia en los EE. UU., a pesar que los medios nunca se hicieron eco de este fenómeno, no fue así en cambio con bandas como Quiet Riot, Judas Priest, Twisted Sister, o Mötley Crüe, etc, que sí contaron con un importante apoyo mediático y comercial en La Unión.

Antes de la edición de "Piece of Mind" se produjo un cambio más en la formación de la agrupación. Clive Burr abandona la banda por problemas personales y una cierta incapacidad de seguir con el ascendente ritmo y éxito de la banda, en su lugar fue reemplazado por el exbatería de la banda francesa Trust, Nicko McBrain, dejando constancia de sus cualidades como instrumentista, a la vez que añadió una nueva dimensión al sonido de la banda.

El 16 de mayo de 1983 se edita el álbum llamado "Piece of Mind". Literalmente el nombre del álbum se traduce como "pedazo de mente", pero que en un juego de palabras en el idioma inglés, también se pronuncia como "peace of mind", que significa "paz mental" (este juego de palabras siempre ha quedado un poco en el misterio en cuanto a su “porqué”).
Con este álbum consiguieron discos de platino y oro en muchos países.
En junio de ese mismo año lanzaron su gira "World Piece Tour", gira que los llevó a presentarse como cabeza de cartel en el "Rock Pop Festival" de Westfalenhalle en Dortmund (Alemania), compartiendo el escenario con Scorpions, Judas Priest, Def Leppard, Ozzy Osbourne, Quiet Riot, Michael Schenker Group, etc, en diciembre de 1983.

El 3 de septiembre de 1984 fue lanzado al mercado el álbum que para muchos marca la esencia resumida de Iron Maiden, además de ser considerado como una de las más puras y dignas expresiones del Heavy Metal de todos los tiempos: "Powerslave" y que por lo mismo marcó un antes y un después en la escena del heavy metal. El álbum parte con una poderosa "Aces High", seguido de "2 Minutes to Midnight", este último basado en el "Reloj del Apocalipsis" de la Universidad de Chicago que da cuenta simbólicamente del tiempo restante para la guerra nuclear y el fin de la civilización, cuyo tiempo "récord" de cercanía fue 2 minutos para la medianoche, en 1953. Sigue una instrumental notable como “Losfer Words (Big 'Orra)”, “Flash Of The Blade”, etc. El álbum también cuenta con verdaderas obras de arte de larga duración como The Rime of the Ancient Mariner, poema de Samuel Taylor Coleridge y “Powerslave” (autoría íntegra de Bruce Dickinson).

Con este álbum se embarcarían en la mítica The World Slavery Tour, gira que abarcó 23 países y constó de 191 conciertos en 331 días. De esta forma, Dickinson, Harris, McBrain, Smith y Murray aceptaron el desafío; la gira concluye en los Estados Unidos con récords de audiencia a pesar de la prácticamente nula difusión en los medios masivos como se mencionaba anteriormente, lo cual es mencionado incluso por el propio Bruce Dickinson en el concierto del “Live After Death” grabado en Long Beach Arena en California.

Con el lanzamiento de "Powerslave" en 1984, América del Sur los recibe con notable éxito durante el festival "Rock in Rio" que se realizó en Brasil en Jacarepaguá, en la zona oeste de Río de Janeiro en 1985, siendo Iron Maiden catalogados junto a Queen como las dos mejores bandas de todo el histórico festival, que también contó con la participación de bandas como Scorpions, Ozzy Osbourne, George Benson, Yes, AC/DC, etc.

Durante el transcurso de la gira The World Slavery Tour fue registrado en el Long Beach Arena en California el legendario álbum en directo "Live After Death", álbum doble en vivo. La portada del disco incluyó una cita de Howard Phillips Lovecraft, escritor de cuentos de terror con estilo y forma de metaficción. El álbum comienza con el discurso que el primer ministro Sir Winston Churchill pronunció como aliento al pueblo británico ante la inminencia del bombardeo a Londres por parte del ejército Alemán nazi durante la Segunda Guerra Mundial, una introducción para el tema "Aces High".

Así mismo, Bruce Dickinson utilizó el verso "A Hymn" de Gilbert K. Chesterton como apertura del tema "Revelations" basado en el libro de Aleister Crowley.

El 29 de junio de 1986 fue lanzado a la venta el sexto álbum de estudio, quizá uno de los más subvalorados, pero a la vez más extraordinarios trabajos de la banda llamado; "Somewhere in Time", con un nuevo sonido, estilo robótico y futurista, implementaron los sintetizadores, como complemento, otorgando así una nueva era para la banda, con un sonido que claramente apuntaba a lo progresivo, sin dejar la fuerza característica de la banda en especial con canciones como “The Loneliness of the Long Distance Runner” o “Deja Vu”, marcando una gran diferencia con el resto de las bandas de “heavy metal” que en su mayoría estaban apuntando al glam metal. Con este álbum Iron Maiden tiene el gran valor de desmarcarse por completo de la moda imperante sobre todo en los EE. UU. Adrian Smith tuvo una mayor participación creativa pasó a escribir algunas letras y Harris pareció ensimismarse aún más en la cuidadosa elaboración de la nueva propuesta.

El disco contiene otras piezas notables como «Wasted Years», «Stranger In a Strange Land» escritas por Adrian Smith; «Heaven Can Wait», «Alexander the Great"»" por Steve Harris, etc.

Es el séptimo álbum de la banda, un álbum conceptual basado en la historia de El séptimo hijo de Orson Scott Card. Con este álbum se reafirmaron en la vanguardia del sonido, sobre todo respecto del resto de las otras bandas que en su mayoría continuaban con la tendencia de la moda Glam Rock imperante en los EE. UU. que sin embargo con el paso del tiempo desaparecerían de los escenarios al no poder adaptarse a los cambios en las corrientes musicales, es a partir de este vanguardismo y porfía de la banda, que el heavy metal es nuevamente revolucionado y redefinido, sirviendo como máximo ejemplo e inspiración para muchas bandas que comenzarían a nacer en aquella época.

Desde el principio del álbum cortes notables desde su intro y comienzo inmediato de “Moonchild”, “Infinite Dreams”, "The Evil That Men Do", “The Clairvoyant”, “The Prophecy”, “Seventh Son Of a Seventh Son”, etc. marcan también para Iron Maiden una nueva etapa peak que era a su vez la continuación de su álbum predecesor “Somewhere in Time”, sin embargo con "Seventh Son" lograron evolucionar musicalmente a otro nivel mucho más alto, con lo que marcarían un antes y un después tanto en su historia como en sonido, composición y letras definitivo en el mundo del heavy metal, lo cual quedó demostrado en la calidad y temática de sus composiciones y como de una forma iban dando continuidad los temas conforme se avanza en el disco. Es decir, Moonchild marcaba el nacimiento y Only Died Young el supuesto final de nuestro misterioso Séptimo Hijo, también cabe hacer mención que dicho disco fue acompañado de una gran gira promocional así como de una escenografía y juegos de luces. El Tour incluiría gran parte de Europa y EE. UU., con grandes conciertos de los cuales existen numerosas grabaciones no oficiales "Bootlegs" tanto en formato LP, CD, VHS, (actualmente transferidos algunos de ellos a DVD o Blue Ray), siendo el hasta hoy considerado una de sus mejores presentaciones en Inglaterra y que sirve de referencia cuando se pegunta a los miembros de Iron Maiden sobre cuál es uno de sus mejores shows, haciendo mención siempre del festival del Donington Castle “Monsters of Rock”, concretamente el celebrado el 20 de agosto de 1988, en el que fueron cabeza de cartel, acompañados por Kiss, Guns N' Roses, Megadeth, David Lee Roth y Helloween el cual convocó a 107000 asistentes aproximadamente. Después de este concierto para 1990 se limitaría la asistencia a una menor cantidad de asistentes [en 1989 no se llevó a cabo el festival]], la gira se extendería por los principales países europeos como Alemania y España por citar dos ejemplos, de los cuales existen algunas grabaciones no oficiales disponibles, también fue editado un álbum oficial titulado Maiden England, el cual fue extraído de su presentación en vivo del 27 y 28 de Noviembre de ese mismo año en el NEC Birminghan, [National Exhibition Centre de Birminghan, es decir, en la Arena de Birmingham], el cual fue editado en formatos CD Single, VHS Single y la edición especial del "[Box CD & VHS en formato PAL]".

Antes del lanzamiento del álbum "Seventh Son of a Seventh Son" el 11 de abril de 1988, la banda precedió el mismo con un sencillo promocional "Can I Play With Madness" que alcanzó el puesto tres en el Top británico, al que agregó un clip de vídeo, del cual se ocupó personalmente el director de cine Terry Gilliam conocido por su película "Brazil".

Al salir el álbum, este escaló hasta el primer puesto en las listas británicas, donde se mantuvo por varias semanas.

A mediados de 1989 trascendió la noticia de que Adrian Smith pondría en marcha la creación de una agrupación musical, algo que venía madurando desde hacía mucho tiempo y que varias veces debió postergar por las obligaciones que supone ser miembro de Iron Maiden. Así Smith lanzó el álbum "Silver and Gold" con la banda ASAP, ("Adrian Smith And Project o ASAP") (las siglas coinciden con la expresión burocrática "as soon as possible", es decir, "lo más pronto posible"), la integró con unos viejos amigos y él mismo se hizo cargo de la voz.

Bruce Dickinson también puso en marcha su proyecto personal y lanzó el álbum "Tattooed Millionaire", que poco y nada tiene que ver con Maiden y que está más emparentado con un estilo rocanrollero. Tras una sólida carrera en grupo de muchos años la Doncella de Hierro empezaba a dar señas de deseos individuales.

A inicios de 1990, año signado por la anunciada ausencia de Maiden de los escenarios y en el que celebraba sus primeros diez años como estrella de la compañía discográfica EMI, Adrian Smith dejaba la banda en plena planificación del siguiente álbum, que incluso contaría con un tema de su autoría. Según cuenta el mismo Steve Harris, si esta decisión de Smith hubiese sido en otra época, es muy probable que se hubiese ido con una “patada en el trasero”, sin embargo la separación se realizó en términos completamente amistosos y la banda dejó en libertad a su guitarrista. De esta manera, la formación clásica había llegado a su fin. Sin embargo, a los siete días se dio a conocer un comunicado que el ex White Spirit, y ex músico de la banda solista de Ian Gillan, Janick Gers, había sido elegido para reemplazar a Smith.

Gers también había trabajado con Dickinson como guitarrista en el álbum "Tattooed Millionaire" (y su respectiva gira), y para esas fechas ya se encontraba trabajando con el grupo en el material que formaría parte del nuevo disco de Maiden, "No Prayer for the Dying".

"No Prayer for the Dying" debutó el 1 de octubre de 1990 en las listas británicas en el puesto número dos. Después de dos años sin salir al ruedo la "Doncella de Hierro" comenzó la gira ""No Prayer On The Road"". La idea de la banda era volver a un sonido más relacionado con los inicios, y volviendo también a los escenarios más reducidos, dejando de lado las agotadoras producciones gigantescas de años anteriores.

En esta gira pudo verse a un Janick Gers que en vivo marcó una gran diferencia con Adrian Smith y que debido a su entusiasmo sobre el escenario fue la gran sorpresa de cada show.

La gira debió terminar antes de lo planeado, cancelándose las visitas a Japón y Australia debido al comienzo de la Guerra del Golfo. Finalmente la gira finalizó en Salt Lake City, Utah en marzo de 1991.

1992 fue el año del lanzamiento del nuevo álbum de Iron Maiden, "Fear of the Dark". El disco fue lanzado en mayo y en él puede verse a un Eddie mucho más terrorífico que en años anteriores. El nuevo Eddie no fue diseñado por Derek Riggs (sus ideas no coincidían con lo que quería la banda en este disco) sino por un chico joven llamado Melvyn Grant. Este álbum también le dio a la banda otro Número 1 en las listas británicas.

La gigantesca gira mundial de Iron Maiden, llamada "Fear of the Dark" se inició el día 5 de junio de 1992 y la inauguración oficial fue en Reikiavik. Luego la banda se trasladó a los Estados Unidos, Canadá, prosiguiendo su itinerario por América Latina, destacándose un gran escándalo a nivel gubernamental y eclesiástico en Chile, en donde fueron censurados por las autoridades de forma encubierta, generando un escándalo de proporciones en dicho país y la desazón de miles de admiradores muchos de los cuales incluso se cuadraron en marchas por el centro de Santiago en señal de protesta. La fecha que no pudo realizarse en Chile fue reemplazada por Uruguay en la "Estación General Artigas", una estación de trenes abandonada. En dicho lugar, la banda quedó fascinada con la arquitectura de la misma (típica inglesa del siglo XIX), y entre máquinas y vagones de este origen y antigüedad se realizó una sesión fotográfica, que no ha visto la luz, salvo una foto en el aeropuerto (al llegar a territorio uruguayo) en el libreto que acompaña al doble álbum en directo "A Real Live/Dead One".

Concluido el tramo sudamericano, Iron Maiden se dirigió a Europa, donde actuó en muchos países y nuevamente fue cabeza de cartel en el Festival "Monsters of Rock" que tuvo lugar en el circuito de Donington Park, el sábado 22 de agosto de 1992, ante miles de admiradores. El siguiente tramo de la gira los llevó a Australia, Nueva Zelanda, Corea, Taiwán, Indonesia, India y Japón con 7 presentaciones en Nagoya, Fukuoka, Hiroshima, Osaka (con 2 presentaciones), Yokohama y Tokio.

1993 comenzó con una noticia inesperada. Bruce Dickinson abandonaría Iron Maiden. Algunos seguidores se preguntaban si podría ser Iron Maiden sin Bruce Dickinson. El cantante anunció que quería comenzar sus proyectos fuera de la banda, eso sí, hubo tiempo para todo, una nueva gira "Real Live Tour", tres discos en vivo ("Live at Donington", "A Real Live One", que incluía temas pertenecientes a la era posterior a "Live After Death" y "A Real Dead One", que incluía temas de la era anterior a "Live..."), fechas extras, video, etc.

Finalmente el último show y despedida de Bruce Dickinson con Iron Maiden se realizó en un lugar secreto (los Pinewood Studios) y solo para setecientas personas invitadas. Parte de las entradas fueron para el club de Fans y para concursos realizados en medios británicos. El show fue transmitido en vivo por la televisión privada de varios países y retransmitido en toda su extensión una semana más tarde por la BBC. Al show estuvo invitado el ilusionista inglés Simon Drake y todo el conjunto hizo de este espectáculo una despedida especial.

La despedida entre la banda y el vocalista fue caballerosa en un principio. Apenas algún comentario posterior de Steve Harris deja traslucir la incomodidad:

Sin embargo, posteriormente Dickinson comenzó a argumentar sus diferencias respecto a sus ex-compañeros en algunos medios de comunicación, en especial en relación a Steve Harris, a quien calificaba como demasiado “tradicional”.

Antes de la despedida de Bruce, Iron Maiden comenzó a escuchar a distintos candidatos a reemplazarlo. Un requisito era que tenía que ser inglés, argumentado que necesitaban una persona que estuviera al 200 % con la banda, por lo que era muy difícil que una persona de otro país pudiera cumplirlo. Finalmente, la balanza se inclinó por Blaze Bayley, vocalista del grupo Wolfsbane. Wolfsbane no solo tenía cierto peso entre la audiencia heavy británica, sino que Blaze era amigo de la banda desde que ambas salieron de gira juntas en 1990. Como ya había ocurrido en el pasado, a la hora de los cambios en su alineación, Iron Maiden consideró la amistad y empatía para tomar una decisión.

Para el nuevo álbum la Doncella no solo presentaba nuevo cantante, sino que también aparecía con nuevo productor. Desde 1981 cada álbum de estudio de la banda había sido producido o co-producido por Martin Birch. Pero ahora, ya retirado, Steve decidió hacerse cargo de la producción junto a Nigel Green, quien había sido ingeniero en los álbumes "Killers" y "The Number of the Beast," y en la actualidad productor de su propio sello discográfico. Finalmente, después de un año de arduo trabajo, en octubre de 1995 fue lanzado "The X Factor" ('El Factor X') previo inicio de la gira "The X Factour" que los llevó por primera vez a Sudáfrica e Israel. La gira también abarcó el Este de Europa (Rumania, Bulgaria, Eslovenia, Hungría, Polonia y la República Checa); Europa Occidental, Estados Unidos, México, Canadá, Japón y Sudamérica.

Era lógico que la salida de Bruce Dickinson iba a resentir la recepción de un nuevo álbum como fue "The X Factor", sin embargo, el trabajo llegó al Top 8 de los charts británicos, y con muy buenas críticas por parte de los críticos y admiradores más leales, sin embargo, la inevitable comparación con Bruce Dickinson sobre todo una vez de gira afectaron la convocatoria de la banda.

En este álbum, las canciones son más largas y oscuras, sin tantos elementos "gancheros" que hicieron famoso al grupo en los años 80, sin embargo, el primer single “Man On the Edge” contiene parte de esos elementos y fue en un gran éxito en diversos países, al igual que el segundo single; “Lord Of The Flies”. Otra muestra de esa mayor “oscuridad” son temas como “The Edge of Darkness” o “Sign Of The Cross”. Ese enfoque siniestro y oscuro del álbum muy probablemente era el reflejo del difícil momento emocional y personal de Steve Harris en aquellos años, pues atravesaba por el divorcio de su esposa y la muerte de su padre.

Es posible que por todos estos grandes cambios se optara por no utilizar una ilustración típica en la portada, como ha sido siempre costumbre del grupo, a manera de expresar la nueva dirección musical que se había adoptado en el trabajo. Esta vez el fan se encuentra con una portada fotorrealista en la que se ve a Eddie mientras está siendo diseccionado. El excelente trabajo de la portada y del libreto interno es obra del maestro Hugh Syme, autor también del arte gráfico de otros discos del panorama
roquero como "Moving Pictures", "Roll the Bones" o "Counterparts" de Rush, o también "Countdown To Extinction" y "Youthanasia" de Megadeth. Sin duda "The X Factor" es el disco más diferente del clásico estilo de "Iron Maiden" hasta el momento, uno de los más sobrios y valorado solo por los admiradores más devotos.

En 1996 vio la luz "Best Of The Beast", la primera compilación presentada en dos versiones: un disco sencillo de 16 temas o un disco doble de 27 temas. Como aliciente se incluye el tema inédito Virus, grabado durante las sesiones del último disco de estudio.

Durante 1997, en pleno boom de los videojuegos de consolas de 32 bits y de PC, Iron Maiden encarga a la empresa inglesa "Virtual Studio" la realización de un juego basado en su mascota, Eddie, y con temas del grupo como banda sonora, su nombre sería Melt (mirror de la antigua web oficial de Melt). El juego tendría que haber salido en dos formatos, para PC y para PlayStation. Después de varios retrasos, y aunque se llegó hacer una pre-reserva a través del club de admiradores oficial del grupo, el juego fue cancelado debido a la baja calidad del mismo.

A continuación de ese disco, en 1998 fue lanzado "Virtual XI", bajo un concepto mucho más clásico, a diferencia de la oscuridad plasmada en el álbum anterior. El número 11 y las pasiones de Steve Harris como el fútbol y la música, se aunaban en otro trabajo muy interesante, con sintetizadores mucho más lúdicos y “ad hoc” al nuevo álbum, que si bien fue positivamente criticado por los más devotos, también estuvo sujeto a la crítica de los medios masivos y el público en general que seguía extrañando a Bruce Dickinson. Alcanzó el lugar 16 en los charts británicos, la posición más baja de un disco de la banda en toda su carrera.

Mientras la banda gestaba este álbum, encargaron a la compañía de desarrollo multimedia "Synthetic Dimension" la creación de un videojuego basado en el arte gráfico que ha venido acompañando al grupo a lo largo de su carrera y que tuviera como protagonista a Eddie. El videojuego sería llamado "Ed Hunter", y se publicó en 1999 acompañado de un recopilatorio de 20 temas escogidos por los fanáticos en la web oficial de Iron Maiden.

Si bien el círculo más íntimo de admiradores alabaron el Virtual XI, en especial canciones como “The Clansman”, “When Two Worlds Collide” o “Futureal”, la recepción del público en general sobre este trabajo no fue la mejor. Iron Maiden empezó a sufrir de una menor convocatoria de público en sus conciertos, y el desempeño de Blaze en vivo dejaba mucho que desear , su voz tiene un registro mucho más grave que el de Bruce, quien canta varios tonos arriba. Esto hacía que cuando Blaze tenía que interpretar en los conciertos las canciones compuestas para la voz de Bruce, no lograba alcanzar la respectiva nota y se escuchara desafinado. Esto causó inconformidad entre muchos seguidores de la banda e, incluso, al interior de la misma, pues Janick Gers llegó a manifestarle a Steve su descontento por el trabajo de Blaze en vivo.

Tras el concierto de Maiden en Buenos Aires, Argentina, el 12 de diciembre de 1998, con el que concluyó la gira Virtual XI World Tour, se dio por terminada la participación de Blaze en la banda y le fue notificado su despido. Sin embargo, la noticia no se hizo pública en ese momento.

El año 1999 inició con muchas especulaciones y rumores que hablaban de una "supuesta" salida de Blaze y se comentaban posibles reemplazos, entre los que se mencionó a Michael Kiske, ex-Helloween. Sin embargo, solo fue hasta el mes de febrero que inesperadamente se anunció lo que millones de admiradores alrededor del mundo habían esperado: el retorno de Bruce Dickinson. El regreso se produjo por el deseo recíproco de ambas partes y se dio tras una conversación de Bruce con Rod Smallwood, quien era el mánager de él y de Maiden. Smallwood lo veía como una gran posibilidad para Iron Maiden, pero pensaba que Steve Harris no estaría muy convencido, pues tras la salida de Bruce la relación de Steve con el vocalista no había sido la mejor.

Bruce le dijo a Smallwood que regresaba a Maiden con la condición de que Adrian Smith, quien en ese momento era uno de los guitarristas de su banda solista, regresara también. La banda aceptó. No obstante, en una primera conversación con Steve, Adrian le manifestó que no quería que con su regreso se le fuera a quitar el lugar a Janick, a lo que Steve le respondió: "No te preocupes, quiero tres guitarristas". El regreso se selló con un abrazo entre Bruce y Steve, después de varios años de distanciamiento.

De esta manera, se conformó un trío de guitarras y la vuelta de Bruce Dickinson, lo que generó la celebración de los fans y una gran expectativa sobre cómo sonaría la banda con tres guitarras, especialmente en vivo.

Ese mismo año la banda lanzó su videojuego para PC, "Ed Hunter", y como promoción, se realizó la mini-gira llamada The Ed Hunter Tour, que a la vez sirvió como una exitosa "Gira del Reencuentro", y se llevó a cabo por Europa, EE. UU. y Canadá.

Una vez culminada la gira, el grupo se abocó de lleno a la preparación del que sería su duodécimo disco titulado "Brave New World" (2000). Con canciones como “Ghost Of The Navigator”, “The Nomad”, "Out of the Silent Planet", "Blood Brothers", "The Wickerman”, etc, el álbum amalgama y resume el sonido y estilo de sus anteriores álbumes. El trabajo alcanzó en número 7 en las listas británicas y el número 1 en varios países del mundo.

La esperada gira mundial de presentación del álbum incluyó algunos países de América del Sur como Chile, Brasil y Argentina.

Para poner fin a la gira, y broche de oro a la vuelta de Adrian y Bruce a la banda, también se registró otro disco en vivo "Rock in Rio" (2002) grabado durante el festival Rock in Rio (3.ª edición) en Río de Janeiro, Brasil, ante 250.000 personas.
En esta gira, Maiden por primera vez después de muchísimos años tocó el tema "Run to the Hills" solo en los conciertos de Río de Janeiro y Santiago de Chile.
Ese mismo año también se lanzó "Eddie's Archive" una caja recopilatoria de seis CD, que contiene el concierto en el Hammersmith Odeon en 1982 "Beast Over Hammersmith" durante la época de "The Number of the Beast" en 2 CD, la recopilación "The BBC Archives" también de dos discos, y "Best of the B'Sides," dos discos con los lados B que integraron los sencillos de la banda.

En 2003 Iron Maiden se dedica a grabar el nuevo álbum de estudio, "Dance of Death". El primer tema del disco, titulado "Wildest Dreams", fue presentado un tiempo antes en la gira por Europa y EE. UU. llamada "Give Me Ed... Til I'm Dead" que comenzó en la ciudad española de La Coruña y en la que se grabaría el concierto en directo del festival "Rock am Ring" de Alemania. Posteriormente, esa grabación fue puesta en Internet, en el sitio oficial, como promoción. A continuación se lanzó el sencillo "Wildest Dreams", incluyendo una versión orquestal de "Blood Brothers", y una semana después fue lanzado el esperado álbum.

Además del antes mencionado "Wildest Dreams", se lanzó un gran segundo single, titulado "Rainmaker", que incluye una versión orquestal del tema que da título al álbum, "Dance of Death".

Nuevamente se lanzaron a una gira mundial que culminó en Japón y que se publicaría en 2005 un doble CD y DVD en directo titulado "Death on the Road" con el concierto de Dortmund, Alemania. Melvyn Grant, autor de la portada del disco "Fear of the Dark", fue el artista elegido para realizar la portada del directo "Death on the road", tras el rechazo de Derek Riggs debido a la presión a la que fue sometido. Como decisión, el artista no quiso realizar más portadas de Eddie para Iron Maiden, aunque sí creó una versión femenina de Eddie para el disco del grupo tributo compuesto íntegramente por mujeres, "The Iron Maidens".

Culminada la gira, fue lanzado un "Souvenir EP" llamado "No More Lies", que además de contener 4 temas y un par de vídeos, incluye otra clase de "souvenirs" de la banda.

Finalmente, en noviembre de 2004, lanzaron un DVD doble: "The Early Days", que muestra grabaciones inéditas de los primeros años, es decir, la época que va desde el primer álbum, hasta "Piece of Mind". Pero lo principal del DVD es la aparición de los integrantes de la banda desde el periodo 1972 hasta 1983 (incluso los que nunca llegaron a grabar un disco con Maiden). Para promocionar el DVD, se hizo en 2005 una gira que abarcó Europa y parte de América en la que solo se interpretaron temas de los cuatro primeros discos.

En agosto de 2006, Iron Maiden lanza su decimocuarto álbum de estudio titulado "A Matter of Life and Death". Aunque este no es un álbum conceptual, son temas recurrentes la guerra y la religión, al igual que las carátulas e impresos.

Luego continuó una exitosa gira en Norteamérica y Europa, en la cual tocaron el álbum en su totalidad, por primera vez en la historia de la banda. Luego la agrupación anunció el lanzamiento de un álbum en vivo de la reciente gira.

En noviembre de 2006, Iron Maiden y el director Rod Smallwood anunciaron que estaban cortando sus 27 años de vínculos con Sanctuary Music y han comenzado una nueva empresa llamada "Phantom Music Management". Sin embargo, no se hicieron cambios significativos.

Iron Maiden grabó una sesión en directo en la Abbey Road Studios de Live From Abbey Road, en diciembre de 2006. Su ejecución se proyectó en un episodio, junto con sesiones de Natasha Bedingfield y Gipsy Kings en marzo de 2007 en Channel 4 y en junio de 2007 en la Sundance Channel (EE. UU.).

En 2006, la banda confirmó varios de los principales festivales en los que tocarían en el mundo que formarían la gira de "A Matter of Life and Death", en la que tocaban íntegramente el mencionado álbum, creando cierta controversia en algunos admiradores que preferían escuchar más clásicos. Al llegar el año 2007 la gira se denominó "A Matter of the Beast" para celebrar el 25 aniversario del álbum "The Number of the Beast". La banda anunció planes para tocar 5 canciones de "A Matter of Life and Death" y 5 de "The Number of the Beast" como parte de sus conciertos. El 24 de junio terminó la gira en la London's Brixton Academy en la ayuda de Clive Burr MS.

El 31 de octubre de 2007, la banda anuncia su gira mundial "Somewhere Back In Time World Tour" que consiste en sus éxitos de los años 80, con un enfoque específico en los álbumes "Powerslave" y "Somewhere in Time".

La gira da inicio en la ciudad de Mumbai, India, el 1 de febrero del 2008 y termina el día 2 de abril del 2009.

La escenografía de la gira está enfocada en dos de sus más exitosos álbumes: "Powerslave" con esculturas y arquitectura del Antiguo Egipto y ""Somewhere In Time"" con ambiente de un tiempo futurista y la inclusión del Cyborg Eddie.

"Flight 666" es un documental producido por el estudio Banger Productions situado en Toronto, Canadá. El documental muestra las presentaciones hechas por la banda durante su gira mundial "Somewhere Back In Time World Tour". El nuevo estreno fue anunciado para el 21 de abril de 2009.
Consta de 2 DVD´s; uno con el documental completo, y el otro DVD es una recopilación de los temas de la gira, tocados en vivo alrededor del mundo pasando por la India, Australia, Japón, Estados Unidos, México, Costa Rica, Colombia, Brasil, Argentina, Chile, Puerto Rico y Canadá. También como lo fue en Rock in Río, llenando el Foro con 1,2 millones de personas en su presentación nocturna.

El 16 de agosto de 2010 se publicó el álbum "The Final Frontier", es el segundo álbum de duración más larga en toda la historia de la banda superando así a "The X Factor". El álbum alcanzó rápidamente el puesto número 1 en el "Billboard" mundial. Para promover el álbum se hizo una gira llamada "The Final Frontier World Tour" que empezó en junio de 2010. En esta gira se anunció la grabación de un DVD, al estilo "Death on the Road" (grabado íntegramente en Dortmund, Alemania) pero esta vez grabado en su totalidad en Santiago, Chile. "The Final Frontier" requirió más tiempo de grabación ya que el material es diferente a los otros álbumes. El disco fue filtrado 6 días antes de su lanzamiento por internet.

Iron Maiden lanzó nuevo álbum recopilatorio, que contiene los éxitos de 1990 a 2010. Este recopilatorio fue dirigido principalmente al público nuevo que todavía no había escuchado algunos de sus éxitos anteriores. Una de sus características, es que las pocas canciones que se eligieron de los discos "The X Factor" y "Virtual XI", son sus versiones en vivo interpretadas por Bruce, como se había hecho anteriormente en el recopilatorio Somewhere Back In Time.

El verano de 2012 comenzaron la recreación de la gira de 1988 "Seventh Tour Of A Seventh Tour" dedicada al disco del mismo año "Seventh Son Of A Seventh Son", con un setlist similar y algo modificado. Realizaron una de las giras más extensas en Norte América y recibieron una respuesta fascinante por parte del público canadiense y estadounidense.
Bruce Dickinson comentó en una entrevista: “Nos divertimos mucho tocando los shows de Maiden a través de la historia porque nos da la oportunidad de revisar nuestro catálogo y elegir canciones del pasado y combinarlas con algunas más recientes”. “Es increíble ver la reacción por parte del público joven, que nunca han tenido la oportunidad de asistir a alguno de nuestros conciertos tocando esas canciones antiguas. Y para quienes lo hayan visto, les aseguramos muchas sorpresas”.
En verano de 2013, continuaron la gira por Europa llevando la misma producción que la del año pasado. En septiembre, regresaron a EE. UU. para tocar siete conciertos, y posteriormente siguieron por Sudamérica. Un dato novedoso es que tocaron en Paraguay por primera vez el domingo 29 de septiembre del 2013. El 25 de marzo se publicó un nuevo DVD de 1988 remasterizado y con contenidos nunca vistos titulado "Maiden England '88", se trata de la tercera parte de la historia de Iron Maiden (1986-1988) y la continuación de "Live After Death".

El 13 de marzo de 2013 se anunció la muerte del ex-baterista Clive Burr a los 53 años. En el año 2001 Clive fue diagnosticado de esclerosis múltiple en donde quedó en silla de ruedas. El bajista Steve Harris declaro lo siguiente: "Era una persona maravillosa y un baterista increíble que hizo una valiosa contribución al grupo en sus inicios, cuando comenzábamos a tocar". La noticia fue anunciada en la página oficial de la banda. Dickinson afirmó que conoció a Burr cuando éste dejaba Samson en diciembre de 1982. Cuando le diagnosticaron esclerosis múltiple en 2001, sus ex compañeros en Iron Maiden crearon la fundación 'Clive Burr MS Trust' con el fin de ayudarle a recaudar dinero para poder costearse la vida. El grupo también dio varios conciertos en honor de Burr cuando este se encontró con problemas para financiar su casa, según indica la BBC.

Después de 5 años, Iron Maiden vuelve con un nuevo álbum llamado The Book of Souls, publicado el 4 de septiembre de 2015. Junto al álbum se lanzó el sencillo "Speed of Light". The Book of Souls es el álbum de más duración en la historia de la banda, superando a The Final Frontier, y también contiene la canción más larga de Iron Maiden hasta la fecha, titulada "Empire of the Clouds", compuesta por Bruce Dickinson y basada en el desastre aéreo del dirigible británico R.101. El álbum inicialmente iba a lanzarse entre abril y mayo pero tuvieron que atrasar su fecha de lanzamiento debido al cáncer de garganta que afectó al vocalista Bruce Dickinson. El álbum fue bien recibido por la crítica y por fans, y llegó a ser número 1 en 24 países a pocas semanas desde su lanzamiento, ganando disco de oro en el Reino Unido con 110.000 copias vendidas y debutando en el puesto 4 del "Billboard 200". Además, este es el primer álbum doble de Iron Maiden en ser producido a manos de Kevin "Caveman" Shirley. En él se puede observar al Eddie clásico con aspecto maya, y el logo de la banda vuelve a ser puntiagudo como en sus primeros trabajos (desde el primer álbum hasta The X Factor). Se prepara la gira The Book of Souls World Tour en el que actuaron por primera vez en El Salvador y en China.

El viernes 11 de marzo de 2016, la banda realizó su octava presentación en Chile, siendo teloneados por The Raven Age y Anthrax. Al día siguiente, en la mañana del 12 de marzo, después de dar su concierto, la banda estaba por viajar en su avión Ed Force One para dar sus conciertos en Argentina. Sin embargo, vivieron un lamentable accidente con su avión Ed Force One en el Aeropuerto Internacional de Santiago.

Los resultados del imprevisto fueron dos de los motores de la aeronave completamente dañados, dos trabajadores heridos y hospitalizados y la gira de la banda por Sudamérica fue puesta en duda.

Fueron los propios miembros de la banda quienes confirmaron que, a pesar del accidente, continuaron con sus conciertos en Argentina.

La noticia de la fallida maniobra no solo fue cubierta a nivel nacional, sino que también diversos portales internacionales destacaron el tema.

El avión fue reparado 9 días (21 de marzo) después de lo sucedido y nuevamente volaron para seguir con sus conciertos en todo el mundo.

Iron Maiden ha encabezado varios eventos durante su carrera, en especial Rock in Rio; Donington; "Monsters of Rock"; Festivales de Reading y Leeds, Wacken Open Air, Gods of Metal y Rock Am Ring. En 2005 actuaron en el Ozzfest. Nunca más participaron en este último festival, por un altercado que tuvo Dickinson con Sharon Osbourne, exesposa de Ozzy y organizadora del evento. Al final del concierto la señora Osbourne tomó el micrófono e informó al público de que ellos (Ozzfest) «amaban a Iron Maiden y a todo su equipo, pero que Bruce Dickinson era un imbécil».

Las influencias musicales de Iron Maiden incluyen principalmente grupos como UFO, Black Sabbath, Jethro Tull, Genesis, Deep Purple, The Who, Wishbone Ash, Uriah Heep, Free, Jimi Hendrix, Led Zeppelin, Budgie, Kiss, Montrose, Golden Earring. entre otras.

Al ser una de las bandas más importantes del heavy metal, Iron Maiden ha sido una enorme influencia para toda una generación de bandas, como Metallica, Slayer, Megadeth, Anthrax, Venom, Destruction, Sodom, Death, Possessed, Morbid Angel, Cannibal Corpse, Dream Theater, Arch Enemy, The Black Dahlia Murder, Godsmack, Children of Bodom, Manowar,Helloween, Sonata Arctica, Queensrÿche, Paradise Lost, Mayhem, Immortal, Dimmu Borgir, Pantera, Trivium, Opeth, Bullet For My Valentine, Slipknot, Funeral for a Friend, Coheed and Cambria, Lamb of God, Avenged Sevenfold, o The Raven Age (banda liderada por George Harris, hijo del bajista y fundador de Iron Maiden, Steve Harris), entre muchas otras.

Los guitarristas de la banda, Dave Murray, Adrian Smith y Janick Gers, tienen cada uno sus propias influencias individuales y estilo de tocar. Dave Murray es conocido por su técnica de legato que, según él, "evolucionó de forma natural. Cuando era pequeño, yo había oído a Jimi Hendrix usar legato y me gustó ese estilo." Adrian Smith indicó que él "se inspiró en el blues rock en lugar del metal" y sus influencias fueron Johnny Winter y Pat Travers, lo que le llevó a convertirse en un "guitarrista melódico". Janick Gers, por el contrario, prefiere un estilo más improvisado, en gran parte inspirado por Ritchie Blackmore, que, afirma él, contrasta con el sonido "rítmico" de Smith.

El cantante Bruce Dickinson, que normalmente trabaja en colaboración con el guitarrista Adrian Smith, tiene un estilo vocal operístico, inspirado por Arthur Brown, Peter Hammill, Ian Anderson e Ian Gillan, y se le considera frecuentemente uno de los mejores cantantes de heavy metal de todos los tiempos. Aunque Nicko McBrain solo aparece como autor una vez, en el álbum Dance of Death, Harris suele trabajar con él durante el desarrollo de las canciones. Adrian Smith comentó: "A Steve le encanta tocar con él. A menudo trabajaban durante horas repasando las partes de bajo y batería."

A lo largo de su carrera, el estilo de la banda no ha experimentado prácticamente cambios, a pesar de la adición de sintetizadores de guitarra en Somewhere in Time (1986), teclados en Seventh Son of a Seventh Son (1988) y el intento en 1990 de volver a la producción "simple" de su material más antiguo en No Prayer for the Dying. En los últimos años la banda ha comenzado a utilizar elementos más progresivos en sus canciones, descritos por Steve Harris como "no progresivo en el sentido moderno como Dream Theater, sino más en el estilo de los 70 ". Según Steve Harris, Seventh Son of a Seventh Son fue el primer álbum "más progresivo" de la banda, pero no volverían a revisitar este estilo hasta The X Factor, de 1995, que es "como una extensión de Seventh Son..., en lo que concierne al elemento progresivo del mismo". Esta novedad contrasta con el sonido más crudo anterior de la banda que, según AllMusic, tomaba prestados elementos del punk rock, aunque Harris lo niega tajantemente.

Álbumes de estudio




</doc>
<doc id="1532" url="https://es.wikipedia.org/wiki?curid=1532" title="Indoeuropeo">
Indoeuropeo

Indoeuropeo es un término usado para referirse a un conjunto de lenguas actualmente habladas desde la India hasta Europa (de ahí su nombre) con rasgos comunes entre sí y opuestos a las de otras partes del mundo (e incluso de otras en la misma Eurasia): las lenguas indoeuropeas. También se emplea para referirse a los pueblos históricos que originariamente hablaron esas lenguas (pueblos indoeuropeos), a su sociedad (sociedad indoeuropea), a su religión (religión indoeuropea) y a su cultura (cultura indoeuropea).

El término "indoeuropeo" se utiliza principalmente en las ciencias sociales (antropología, antropología lingüística, arqueología, etnología, filología e historia) y muy especialmente en la lingüística histórica. Se ha empleado también en pseudociencia en determinados contextos, por lo que ocasionalmente ha sido objeto de especial polémica ("el problema indoeuropeo"), como justificación de posiciones ideológicas (el nordicismo).

Nació como un concepto filológico, dada la identificación que la filología comparada comenzó a hacer entre un gran conjunto de lenguas actualmente habladas desde la India hasta Europa (de ahí su nombre) con rasgos comunes entre sí y opuestos a las de otras partes del mundo (e incluso de otras en la misma Eurasia): las lenguas indoeuropeas.

Pasó a aplicarse también a los pueblos históricos que originariamente hablaron esas lenguas (pueblos indoeuropeos), a su sociedad (sociedad indoeuropea), a su religión (religión indoeuropea) y a su cultura (cultura indoeuropea).

De forma intercambiable se utilizan los términos indogermano o indogermánico, especialmente en el ámbito de habla alemana, aunque se acuñó inicialmente en francés. El término "indoeuropeo" se empleó inicialmente en inglés. Diferentes denominaciones usadas para el mismo concepto fueron jafético u otras relativas a lo sánscrito, a lo celta (indocelta), a lo ario (arioeuropeo) o a lo tocario.

Los conceptos indoario, indoiranio e indohitita son utilizados de una manera diferenciada, pero confluyente.

No debe confundirse, en cambio, con el concepto de lo indogriego, completamente diferente, pues se refiere a la influencia helenística en la India posterior a Alejandro Magno.

Hay muy distintas hipótesis sobre la ubicación inicial, en el tiempo y en el espacio (alrededor de 4000 a. C., en el entorno de la extensa zona esteparia entre la Europa suroriental y el Asia central -"Urheimat"-) de las que debieron ser "primeras" manifestaciones de lo indoeuropeo: lo protoindoeuropeo; y con ellas, la denominada lengua protoindoeuropea, el pueblo o conjunto de pueblos que la hablarían (pueblo protoindoeuropeo) y la reconstrucción arqueológica de sus posibles rasgos culturales y sociales (religión protoindoeuropea, cultura protoindoeuropea, sociedad protoindoeuropea).
Ambos términos (indoeuropeo y protoindoeuropeo) se usan especialmente en oposición al de preindoeuropeo, que designa al sustrato anterior al de la llegada de los indoeuropeos (o en su caso preindoeuropeos), tanto en India como en Europa o en Anatolia. Para el caso de la protohistoria de España, el término "preindoeuropeo" identifica al área del sur y el este peninsular (Tartessos y el área cultural de los iberos), mientras que el término "indoeuropeo" identifica al área del centro, oeste y norte (identificado a grandes rasgos con el área cultural de lo celta), con la notable excepción de los vascones, de lengua preindoeuropea (el antecedente del euskera).
Por similitud con los conceptos de romanización o arabización, se utiliza el concepto de indoeuropeización para designar a la aculturación que se produjo como consecuencia del contacto con los pueblos indoeuropeos o protoindoeuropeos.

Entre los más importantes indoeuropeístas (los dedicados a estudios indoeuropeos, especialmente la filología indoeuropea) están William Jones, Rasmus Rask, Franz Bopp, Friedrich Schlegel, Jakob Grimm, Georges Dumézil, y Ferdinand de Saussure;, Émile Benveniste, Jerzy Kuryłowicz, André Martinet, Winfred P. Lehmann, Tamaz V. Gamkrelidze y entre los hispanohablantes Francisco García Ayuso, Antonio Tovar, Francisco Rodríguez Adrados y Francisco Villar Liébana.

Como consecuencia del empleo diferente que puede darse al concepto (científico o pseudocientífico), muy diferentes instituciones llevan el nombre de "estudios indoeuropeos":


</doc>
<doc id="1533" url="https://es.wikipedia.org/wiki?curid=1533" title="Ictiología">
Ictiología

​La ictiología es una rama de la zoología dedicada al estudio de los peces. Esta incluye los osteíctios (peces óseos), los condrictios (peces cartilaginosos, tales como el tiburón y la raya) y los agnatos (peces sin mandíbula). Se estima que hay alrededor de 32.700 especies descritas y que cada año son descritas oficialmente 250 nuevas especies. La dificultad en la clasificación radica en la gran variedad que han alcanzado durante el proceso evolutivo y la accesibilidad de los humanos al medio acuático. Por otra parte la ictiología además se ocupa de la biología y comportamiento de los peces.

Las primeras descripciones científicas de peces fueron hechas por Aristóteles, quien mencionó varios. Guillaume Rondelet publicó su "De Piscibus Marinum" describiendo 244 especies. Durante el 1600, los exploradores encontraron nuevos tipos de peces; George Markgraf, en su "Naturalis Brasilae", añadió 100 especies más y en 1686, la "Historia Piscium" de John Ray y Francis Willughby describía más de 400.

El título de "padre de la ictiología" se le atribuye a Peter Artedi , un estudiante de Linneo que identificó cinco órdenes de peces (incluidos cetáceos) y los dividió en géneros. Artedi se ahogó accidentalmente en un canal de Ámsterdam y Linneo publicó sus manuscritos de forma póstuma.

Durante los siglos XVIII y XIX, una constante corriente de especímenes provenientes de todo el mundo inundaron los museos.

En la década de 1780, Marcus Elieser Bloch publicó "Ichthyologia" como una serie de volúmenes de láminas y, tras su muerte, su asociado Johann Gottlob Schneider publicaría el "M. E. Blochii Systemae Ichthyologiae", describiendo 1.519 especies.

La obra "Regne animal distribué d'après son organisation" de Georges Cuvier, publicada entre 1817-1830 fue un paso clave para la clasificación de los peces. Cuvier trabajó con su estudiante Achille Valenciennes para sacar los 22 volúmenes de "Histoire Naturelle des Poissons" en la década de 1830 -que aunque nunca fue completada, describía 4.514 especies.

Albert Günther publicó su "Catalogue of the Fishes of the British Museum" entre 1859 y 1870, describiendo más de 6.800 especies y citando otras 1.700.
Se considera como el más grande ictiólogo de principios del siglo XX a David Starr Jordan, que escribió 650 libros y artículos sobre la materia, además de ocupar el cargo de presidente de la Universidad de Indiana y la Universidad de Stanford.

Cabe hacer mención a la técnica de la Ictioterapia, técnica oriental, mediante la cual una legión de peces remo masajearan toda la epidermis del sujeto en busca de impurezas de las que alimentarse.



</doc>
<doc id="1535" url="https://es.wikipedia.org/wiki?curid=1535" title="Jesús de Nazaret">
Jesús de Nazaret

Jesús de Nazaret, también conocido como Jesús, Cristoo Jesucristo, es la figura central del cristianismo y una de las más influyentes de la cultura occidental. Según la opinión mayoritariamente aceptada en medios académicos, basada en una lectura crítica de los textos sobre su figura, Jesús de Nazaret fue un predicador judío que vivió a comienzos del siglo en las regiones de Galilea y Judea, y fue crucificado en Jerusalén en torno al año 30, bajo el gobierno de Poncio Pilato.

Para la mayoría de las denominaciones cristianas, es el Hijo de Dios y, por extensión, la encarnación de Dios mismo. Su importancia estriba asimismo en la creencia de que, con su muerte y posterior resurrección, redimió al género humano. El judaísmo niega su divinidad, que es incompatible con su concepción de Dios. En el islam, donde se lo conoce como Isa, es considerado uno de los profetas más importantes.

Lo que se conoce de Jesús procede casi exclusivamente de la tradición cristiana —aunque se le menciona en fuentes no cristianas—, especialmente de la utilizada para la composición de los evangelios sinópticos, redactados, según opinión mayoritaria, unos treinta o cuarenta años, como mínimo, después de la muerte de Jesús. La mayoría de los estudiosos considera que mediante el estudio de los evangelios es posible reconstruir tradiciones que se remontan a contemporáneos de Jesús, aunque existen grandes discrepancias entre los investigadores en cuanto a los métodos de análisis de los textos y las conclusiones que de ellos pueden extraerse.

Lo que figura a continuación es un relato de la vida de Jesús tal y como aparece en los cuatro evangelios incluidos en el "Nuevo Testamento", considerados libros sagrados por todas las confesiones cristianas. El relato evangélico es la fuente principal para el conocimiento de Jesús, y constituye la base de las interpretaciones que de su figura hacen las diferentes ramas del cristianismo. Aunque puede contener elementos históricos, expresa fundamentalmente la fe de las comunidades cristianas en la época en que estos textos fueron escritos, y la visión que por entonces tenían de Jesús de Nazaret.

Los relatos referentes al nacimiento e infancia de Jesús proceden exclusivamente del "Evangelio de Mateo" (1,18-2,23) y del de "Lucas" (1,5-2,52).
No hay relatos de este tipo en los evangelios de Marcos y Juan. Las narraciones de Mateo y Lucas difieren entre sí:



En los evangelios de Mateo y de Lucas aparecen sendas genealogías de Jesús (Mt 1, 2-16; Lc 3, 23-38).
La de Mateo se remonta al patriarca Abraham, y la de Lucas a Adán, el primer hombre según el Génesis. Estas dos genealogías son idénticas entre Abrahán y David, pero difieren a partir de este último, ya que la de Mateo hace a Jesús descendiente de Salomón, mientras que, según Lucas, su linaje procedería de Natam, otro de los hijos de David. En ambos casos, lo que se muestra es la ascendencia de José, a pesar de que, según los relatos de la infancia, este solo habría sido el padre adoptivo de Jesús.

La llegada de Jesús fue profetizada por Juan el Bautista (su primo, según el "Evangelio de Lucas"), por quien Jesús fue bautizado en el río Jordán.
Durante el bautismo, el Espíritu de Dios, en forma de paloma, descendió sobre Jesús, y se escuchó la voz de Dios.

Según los "Evangelios" sinópticos, el Espíritu condujo a Jesús al desierto, donde ayunó durante cuarenta días y superó las tentaciones a las que fue sometido por el Demonio.
No se menciona este episodio en el "Evangelio de Juan". Después Jesús marchó a Galilea, se estableció en Cafarnaún, y comenzó a predicar la llegada del Reino de Dios.

Acompañado por sus seguidores, Jesús recorrió las regiones de Galilea y Judea predicando el Evangelio y realizando numerosos milagros. El orden de los hechos y dichos de Jesús varía según los diferentes relatos evangélicos. Tampoco se indica cuánto tiempo duró la vida pública de Jesús, aunque el "Evangelio de Juan" menciona que Jesús celebró la fiesta anual de la Pascua judía (Pésaj) en Jerusalén en tres ocasiones. En cambio los "Evangelios" sinópticos mencionan solo la fiesta de Pascua en la que Jesús fue crucificado.

Gran parte de los hechos de la vida pública de Jesús narrados en los evangelios, tienen como escenario la zona septentrional de Galilea, en las cercanías del mar de Tiberíades, o lago de Genesaret, especialmente la ciudad de Cafarnaúm, pero también otras, como Corozaín o Betsaida.
También visitó, en el sur de la región, localidades como Caná o Naín, y la aldea en la que se había criado, Nazaret, donde fue recibido con hostilidad por sus antiguos convecinos.
Su predicación se extendió también a Judea (según el "Evangelio de Juan", visitó Jerusalén en tres ocasiones desde el comienzo de su vida pública), y estuvo en Jericó y Betania (donde resucitó a Lázaro).

Escogió a sus principales seguidores (llamados en los evangelios «apóstoles»; en griego, ‘enviados’), en número de doce, de entre el pueblo de Galilea. En los sinópticos se menciona la lista siguiente: Simón, llamado Pedro y su hermano Andrés; Santiago el de Zebedeo y su hermano Juan; Felipe y Bartolomé; Tomás y Mateo el publicano; Santiago el de Alfeo y Tadeo; Simón el Zelote y Judas Iscariote, el que posteriormente traicionaría a Jesús (Mt 10,2-4; Mc 3,16-19; Lc 6, 13-16).
Algunos de ellos eran pescadores, como las dos parejas de hermanos formadas respectivamente por Pedro y Andrés, y Juan y Santiago.
Mateo se identifica generalmente con Leví el de Alfeo, un publicano de quien en los tres sinópticos se relata brevemente cómo fue llamado por Jesús (Mt 9,9; Mc 2,14; Lc 5,27-28). lo que acarreó a Jesús numerosos reproches de los fariseos.

El "Evangelio de Juan" solo menciona los nombres de nueve de los apóstoles, aunque en varios pasajes hace referencia a que eran doce.

Predicó tanto en sinagogas como al aire libre, y las muchedumbres se congregaban para escuchar sus palabras. Entre sus discursos, destaca el llamado Sermón de la Montaña, en el "Evangelio de Mateo" (Mt 5-7). Utilizó a menudo parábolas para explicar a sus seguidores el Reino de Dios. Las parábolas de Jesús son breves relatos cuyo contenido es enigmático (a menudo han de ser después explicadas por Jesús). Tienen en general un contenido escatológico y aparecen exclusivamente en los "Evangelios" sinópticos. Entre las más conocidas están la parábola del sembrador (Mt 13,3-9; Mc 4,3-9; Lc 8,5-8), cuyo significado explica Jesús a continuación; la de la semilla que crece (Mc 4,26-29); la del grano de mostaza (Mt 13,31-32; Mc 4,30-32), la del trigo y la cizaña (Mt 13,24-30), la de la oveja perdida (Mt 18,12-14; Lc 15,3-7) y la de la moneda perdida (Lc 15,8-10), la del siervo despiadado (Mt 18, 23-35), la de los obreros enviados a la viña (Mt 20,1-16), la de los dos hijos (Mt 21,28-32), la de los viñadores homicidas (Mt 21,33-42; Mc 12,1-11; Lc 20,9-18); la de los invitados a la boda (Mt 22, 1-14), la de las diez vírgenes (Mt 25,1-13), la de los talentos (Mt 25,14-30; Lc 19,12-27), la del juicio final (Mt 25,31-46). Dos de las más conocidas aparecen solo en el "Evangelio de Lucas:" se trata de la parábola del buen samaritano (Lc 10,30-37) y la del hijo pródigo (Lc 15,11-32). En las parábolas, utiliza Jesús frecuentemente imágenes relacionadas con la vida campesina.

Mantuvo controversias con miembros de algunas de las más importantes sectas religiosas del judaísmo, y muy especialmente con los fariseos, a quienes acusó de hipocresía y de no cuidar lo más importante de la Torá: la justicia, la compasión y la lealtad (Mt 12, 38-40; Lc 20, 45-47).

La originalidad de su mensaje radicaba en la insistencia en el amor a los enemigos (Mt 5,38-48; Lc 6, 27-36) así como en su relación estrechísima con Dios a quien llamaba en arameo con la expresión familiar "Abba" (Padre) que ni Marcos (Mc 14,36) ni Pablo (Rm 8, 15; Gal 4, 6) traducen. Se trata de un Dios cercano que busca a los marginados, a los oprimidos (Lc 4, 18) y a los pecadores (Lc 15) para ofrecerles su misericordia. La oración del Padre nuestro (Mt 6,9-13: Lc 11,1-4), que recomendó utilizar a sus seguidores, es clara expresión de esta relación de cercanía con Dios antes mencionada.

Según los evangelios, durante su ministerio Jesús realizó varios milagros. En total, en los cuatro evangelios canónicos se narran veintisiete milagros, de los cuales catorce son curaciones de distintas enfermedades, cinco exorcismos, tres resurrecciones, dos prodigios de tipo natural y tres signos extraordinarios.



Además, hay varios pasajes que hacen referencia de modo genérico a exorcismos de Jesús (Mc 1,32-34;Mc 3,10-12).



En esos tiempos, los escribas, fariseos y otros, atribuyeron a una confabulación con Belcebú este poder de expulsar a los demonios. Jesús se defendió enérgicamente de estas acusaciones.
Según los relatos evangélicos, Jesús no solo tenía el poder de expulsar demonios, sino que transmitió ese poder a sus seguidores.
Incluso se menciona el caso de un hombre que, sin ser seguidor de Jesús, expulsaba con éxito demonios en su nombre.

Los "Evangelios" sinópticos relatan que Jesús subió a un monte a orar con algunos de los apóstoles, y mientras oraba se transformó el aspecto de su rostro, y su vestido se volvió blanco y resplandeciente. Aparecieron junto a él Moisés y Elías. Los apóstoles dormían mientras tanto, pero al despertar vieron a Jesús junto a Moisés y Elías. Pedro sugirió que hicieran tres tiendas: para Jesús, Moisés y Elías. Entonces apareció una nube y se oyó una voz celestial, que dijo: «Este es mi Hijo elegido, escuchadle». Los discípulos no contaron lo que habían visto.

Según los cuatro evangelios, Jesús fue con sus seguidores a Jerusalén para celebrar allí la fiesta de Pascua. Entró a lomos de un asno, para que se cumplieran las palabras del profeta Zacarías (Zc 9, 9: «He aquí que tu rey viene a ti, manso y montado sobre un asno, sobre un pollino hijo de una bestia de carga»). Fue recibido por una multitud, que lo aclamó como «hijo de David» (en cambio según el "Evangelio de Lucas" fue aclamado solamente por sus discípulos).
En los evangelios de Lucas y de Juan, Jesús es aclamado como rey.

Según los "Evangelios" sinópticos, a continuación fue al Templo de Jerusalén, y expulsó de allí a los cambistas y a los vendedores de animales para los sacrificios rituales (el "Evangelio de Juan", en cambio, sitúa este episodio al comienzo de la vida pública de Jesús, y lo relaciona con una profecía sobre la destrucción del Templo).
Vaticinó la destrucción del Templo y otros acontecimientos futuros.

En Betania, cerca de Jerusalén, fue ungido con perfumes por una mujer.
Según los sinópticos, la noche de Pascua cenó en Jerusalén con los Apóstoles, en lo que la tradición cristiana designa como Última Cena. En el transcurso de esta cena pascual, Jesús predijo que sería traicionado por uno de los Apóstoles, Judas Iscariote. Tomó pan en las manos, diciendo «Tomad y comed, este es mi cuerpo» y, a continuación, cogiendo un cáliz de vino, dijo: «Bebed de él todos, porque esta es la sangre de la Alianza, que será derramada por la multitud para la remisión de los pecados».
Profetizó también, según los sinópticos, que no volvería a beber vino hasta que no lo bebiera de nuevo en el Reino de Dios.

Tras la cena, según los sinópticos, Jesús y sus discípulos fueron a orar al huerto de Getsemaní. Los apóstoles, en lugar de orar, se quedaron dormidos, y Jesús sufrió un momento de fuerte angustia con respecto a su destino, aunque decidió acatar la voluntad de Dios.

Judas había efectivamente traicionado a Jesús, para entregarlo a los príncipes de los sacerdotes y los ancianos de Jerusalén a cambio de treinta piezas de plata.
Acompañado de un grupo armado de espadas y garrotes, enviado por los príncipes de los sacerdotes y los ancianos, llegó a Getsemaní y reveló la identidad de Jesús besándole la mejilla. Jesús fue arrestado. Por parte de sus seguidores hubo un conato de resistencia, pero finalmente todos se dispersaron y huyeron.

Tras su detención, Jesús fue llevado al palacio del sumo sacerdote Caifás. Allí fue juzgado ante el Sanedrín. Se presentaron falsos testigos, pero como sus testimonios no coincidían no fueron aceptados. Finalmente, Caifás preguntó directamente a Jesús si era el Mesías, y Jesús dijo: «Tú lo has dicho». El sumo sacerdote se rasgó las vestiduras ante lo que consideraba una blasfemia. Los miembros del Sanedrín escarnecieron cruelmente a Jesús.
En el "Evangelio de Juan", Jesús fue llevado primero ante Anás, suegro de Caifás, y luego ante este último. Solo se detalla el interrogatorio ante Anás, bastante diferente del que aparece en los sinópticos.
Pedro, que había seguido a Jesús en secreto tras su detención, se encontraba oculto entre los sirvientes del sumo sacerdote. Reconocido como discípulo de Jesús por los sirvientes, le negó tres veces (dos según el "Evangelio de Juan"), como Jesús le había profetizado.

A la mañana siguiente, Jesús fue llevado ante Poncio Pilato, el procurador romano. Tras interrogarle, Pilato no le halló culpable, y pidió a la muchedumbre que eligiera entre liberar a Jesús o a un conocido bandido, llamado Barrabás. La multitud, persuadida por los príncipes de los sacerdotes, pidió que se liberase a Barrabás, y que Jesús fuese crucificado. Pilato se lavó simbólicamente las manos para expresar su inocencia de la muerte de Jesús.

Jesús fue azotado, lo vistieron con un manto rojo, le pusieron en la cabeza una corona de espinas y una caña en su mano derecha. Los soldados romanos se burlaban de él diciendo: «Salud, rey de los judíos».
Fue obligado a cargar la cruz en la que iba a ser crucificado hasta un lugar llamado Gólgota, que en arameo significa ‘lugar del cráneo’. Le ayudó a llevar la cruz un hombre llamado Simón de Cirene.

Dieron de beber a Jesús vino con hiel. Él probó pero no quiso tomarlo. Tras crucificarlo, los soldados se repartieron sus vestiduras. En la cruz, sobre su cabeza, pusieron un cartel en arameo, griego y latín con el motivo de su condena: «Este es Jesús, el rey de los judíos», que a menudo en pinturas se abrevia INRI ("Iesus Nazarenus Rex Iudaeorum", literalmente ‘Jesús de Nazaret, rey de los judíos’). Fue crucificado entre dos ladrones.

Hacia las tres de la tarde, Jesús exclamó: «Elí, Elí, lemá sabactani», que, según el "Evangelio de Mateo" y el "Evangelio de Marcos," en arameo significa: ‘Dios mío, Dios mío, ¿por qué me has abandonado?’.
Las palabras finales de Jesús difieren en los otros dos evangelios. También hay diferencia entre los evangelios en cuanto a qué discípulos de Jesús estuvieron presentes en su crucifixión: en Mateo y Marcos, son varias de las mujeres seguidoras de Jesús; en el "Evangelio de Juan" se menciona también a la madre de Jesús y al «discípulo a quien amaba» (según la tradición cristiana, se trataría del apóstol Juan, aunque en el texto del evangelio no se menciona su nombre).

Un seguidor de Jesús, llamado José de Arimatea, solicitó a Pilato el cuerpo de Jesús la misma tarde del viernes en que había muerto, y lo depositó, envuelto en una sábana, en un sepulcro excavado en la roca. Cubrió el sepulcro con una gran piedra.
Según el "Evangelio de Mateo" (no se menciona en los otros evangelios), al día siguiente, los «príncipes de los sacerdotes y los fariseos» pidieron a Pilato que colocase frente al sepulcro una guardia armada, para evitar que los seguidores de Jesús robasen su cuerpo y difundieran el rumor de que había resucitado. Pilato accedió.

Los cuatro evangelios relatan que Jesús resucitó de entre los muertos al tercer día después de su muerte y se apareció a sus discípulos en varias ocasiones.
En todos ellos, la primera en descubrir la resurrección de Jesús es María Magdalena. Dos de los evangelios (Marcos y Lucas) relatan también su ascensión a los cielos. Los relatos sobre Jesús resucitado varían, sin embargo, según los evangelios:





Según los autores del Nuevo Testamento, la vida de Jesús supuso el cumplimiento de algunas profecías formuladas en ciertos libros del Antiguo Testamento. Los libros bíblicos más citados en este sentido por los primeros cristianos fueron Isaías, Jeremías, los Salmos, Zacarías, Miqueas y Oseas. Para los autores del Nuevo Testamento, en una visión compartida por los cristianos posteriores, en estos textos se anuncia la venida de Jesús de Nazaret, que sería el Mesías que esperaba el pueblo de Israel. A menudo los redactores de los evangelios, sobre todo el autor del "Evangelio de Mateo", citan explícitamente estos textos para subrayar el cumplimiento de estas profecías en la vida y muerte de Jesús. Entre otras cosas, consideran que fueron profetizadas las circunstancias y el lugar de nacimiento de Jesús (Is 7,14; Miq 5,2); su relación con Galilea (Is 9,1); su condición mesiánica (Is 9, 6-7; Is 11, 1-9; Is 15, 5); el papel de precursor de Juan el Bautista (Is 40,3) e incluso su pasión y muerte sacrificial (a este respecto se citan sobre todo cuatro poemas, incluidos en el Deutero Isaías (o Segundo Isaías), que presentan la figura de un siervo de Yahvé, a cuyo sacrificio se atribuye un valor redentor, pero también otros muchos pasajes.

Los judíos, que también consideran sagrados estos libros, no aceptan la creencia cristiana de que estas profecías se refieren a Jesús de Nazaret. Para la investigación histórica actual, el principal interrogante es hasta qué punto estos libros contribuyeron a moldear los relatos evangélicos.

A diferencia de lo que ocurre con otros personajes de la Antigüedad, pero al igual que sucede con otros muchos, no existen evidencias arqueológicas que permitan verificar la existencia de Jesús de Nazaret. La explicación principal que se da a este hecho es que Jesús no alcanzó mientras vivía una relevancia suficiente como para dejar constancia en fuentes arqueológicas, dado que no fue un importante líder político, sino un sencillo predicador itinerante.
Si bien los hallazgos de la arqueología no pueden ser aducidos como prueba de la existencia de Jesús de Nazaret, sí confirman la historicidad de gran número de personajes, lugares y acontecimientos descritos en las fuentes.

Por otro lado, Jesús, como muchos destacados dirigentes religiosos y filósofos de la Antigüedad, no escribió nada, o al menos no hay constancia alguna de que así haya sido. Todas las fuentes para la investigación histórica de Jesús de Nazaret son, por lo tanto, textos escritos por otros autores. El más antiguo documento inequívocamente concerniente a Jesús de Nazaret es el llamado "Papiro P52", que contiene un fragmento del "Evangelio de Juan" y que data, según los cálculos más extendidos, del 125 aproximadamente (es decir, casi un siglo después de la fecha posible de la muerte de Jesús, hacia el año 30).

Si bien los testimonios materiales referentes a la vida de Jesús son muy tardíos, la investigación filológica ha logrado reconstruir la historia de estos textos con un alto grado de probabilidad, lo que arroja como conclusión que los primeros textos sobre Jesús (algunas cartas de Pablo) son posteriores en unos veinte años a la fecha probable de su muerte, y que las principales fuentes de información acerca de su vida (los evangelios canónicos) se redactaron en la segunda mitad del siglo I. Existe un amplio consenso acerca de esta cronología de las fuentes, al igual que es posible datar algunos (muy escasos) testimonios acerca de Jesús en fuentes no cristianas entre la última década del siglo I y el primer cuarto del siglo II.

En el estado actual de conocimientos acerca de Jesús de Nazaret, la opinión predominante en medios académicos es que se trata de un personaje histórico, cuya biografía y mensaje experimentaron modificaciones por parte de los redactores de las fuentes. Existe, sin embargo, una minoría de estudiosos que, desde una crítica radical de las fuentes, consideran probable que Jesús ni siquiera fuese un personaje histórico real, sino una entidad mítica, similar a otras figuras objeto de culto en la Antigüedad.

Son sobre todo las fuentes cristianas, obviamente parciales, las que proporcionan información sobre Jesús de Nazaret. Los textos cristianos reflejan principalmente la fe de las comunidades primitivas, y no pueden considerarse, sin más, documentos históricos.

Los textos en los que la crítica actual cree posible hallar información acerca del Jesús histórico son, principalmente, los tres "Evangelios" sinópticos "(Mateo", "Marcos" y "Lucas)". Secundariamente, proporcionan también información acerca de Jesús de Nazaret otros escritos del "Nuevo Testamento" (el "Evangelio de Juan", las "Epístolas de Pablo de Tarso"), algunos evangelios apócrifos (como el de "Tomás" y el de "Pedro)", y otros textos cristianos.

Por otro lado, existen referencias a Jesús en unas pocas obras no cristianas. En algunos casos se ha puesto en duda su autenticidad (Flavio Josefo), o que se refieran al mismo personaje cuya vida relatan las fuentes cristianas (Suetonio). Apenas aportan alguna información, excepto que fue crucificado en tiempos de Poncio Pilato (Tácito) y que fue considerado un embaucador por los judíos ortodoxos.

Son muy numerosos los escritos cristianos de los siglos I y II en los que se encuentran referencias a Jesús de Nazaret. Sin embargo, solo una pequeña parte de los mismos contiene información útil acerca de él. Todos ellos reflejan, en primer lugar, la fe de los cristianos de la época, y solo secundariamente revelan información biográfica sobre Jesús.

Los principales son:


Los textos más antiguos conocidos relativos a Jesús de Nazaret son las cartas escritas por Pablo de Tarso, consideradas anteriores a los evangelios. Pablo no conoció personalmente a Jesús. Su conocimiento de él y de su mensaje, según sus propias afirmaciones, puede provenir de una doble fuente: por un lado, sostiene en sus escritos que se le apareció el propio Jesús resucitado para revelarle su evangelio, una revelación a la que Pablo concedía gran importancia (Gal 1, 11-12); por otro, también según su propio testimonio, mantuvo contactos con miembros de varias comunidades cristianas, entre ellos varios seguidores de Jesús. Conoció, según él mismo afirma en la "Epístola a los Gálatas", a Pedro (Gal 2, 11-14), Juan (Gal 2, 9), y Santiago, al que se refiere como «hermano del Señor» (Gal 1, 18-19; 1 Cor 15, 7).

Aunque la tradición cristiana atribuye a Pablo catorce epístolas incluidas en el Nuevo Testamento, solo existe consenso entre los investigadores actuales en cuanto a la autenticidad de siete de ellas, que se datan generalmente entre los años 50 y 60 ("Primera epístola a los tesalonicenses", "Epístola a los filipenses", "Epístola a los Gálatas", "Primera epístola a los corintios", "Segunda epístola a los corintios", "Epístola a los romanos" y "Epístola a Filemón"). Estas epístolas son cartas dirigidas por Pablo a comunidades cristianas de diferentes lugares del Imperio romano, o a individuos particulares. En ellas se tratan fundamentalmente aspectos doctrinales del cristianismo. Pablo se interesa sobre todo por el sentido sacrificial y redentor que según él tienen la muerte y resurrección de Jesús, y son escasas sus referencias a la vida de Jesús o al contenido de su predicación.

Sin embargo, las epístolas paulinas sí proporcionan alguna información. En primer lugar, se afirma en ellas que Jesús nació «según la Ley» y que era del linaje de David, «según la carne» (Rom 1, 3), y que los destinatarios de su predicación eran los judíos circuncisos (Rom 15, 8). En segundo lugar, refiere ciertos detalles acerca de su muerte: indica que murió crucificado (2 Cor 13, 4), que fue sepultado y que resucitó al tercer día (1 Cor 15,3-8), y atribuye su muerte a los judíos (1 Tes 2, 14) y también a los «poderosos de este mundo» (1 Cor 2, 8). Además, la "Primera epístola a los corintios" contiene un relato de la Última Cena (1 Cor 11, 23-27), semejante al de los "Evangelios" sinópticos (Mt 26, 26-29; Mc 14, 22-25; Lc 22, 15-20).

Los estudiosos están de acuerdo en que la principal fuente de información acerca de Jesús se encuentra en tres de los cuatro evangelios incluidos en el Nuevo Testamento, los llamados sinópticos: "Mateo", "Marcos" y "Lucas", cuya redacción se sitúa generalmente entre los años 70 y 100.

El punto de vista dominante en la crítica actual es que los evangelios no fueron escritos por testigos personales de la actividad de Jesús. Se cree que fueron escritos en griego por autores que no tenían conocimiento directo del Jesús histórico. Algunos autores, sin embargo, continúan manteniendo el punto de vista tradicional sobre esta cuestión, que los atribuye a personajes citados en el Nuevo Testamento.

Aunque no es aceptada por la totalidad de los críticos, las afinidades entre estos evangelios suelen ser explicadas por la llamada teoría de las dos fuentes, propuesta ya en 1838 por Ch. Weisse, y que fue luego significativamente matizada por B. H. Streeter en 1924. Según esta teoría, el evangelio más antiguo es Marcos (y no Mateo, como se creía anteriormente). Tanto Lucas como Mateo son posteriores, y utilizaron como fuente Marcos, lo que explica el material común entre los tres sinópticos, denominado «de triple tradición». Pero, además, existió una segunda fuente, a la que se dio el nombre de Q, que contenía casi exclusivamente palabras de Jesús, lo cual explica el llamado material de doble tradición, que se encuentra en Mateo y Lucas, pero no en Marcos (Q es hoy considerado un documento independiente, del que incluso existen ediciones críticas).
Por último, tanto Lucas como Mateo contienen material propio, que no se encuentra en ninguna de las dos fuentes hipotéticas.

El grado de fiabilidad que se concede a los evangelios depende de los estudiosos. La opinión más extendida es que son principalmente textos apologéticos, es decir, de propaganda religiosa, cuya intención principal es difundir una imagen de Jesús acorde con la fe de las primitivas comunidades cristianas, pero que contienen, en mayor o menor medida, datos acerca del Jesús histórico. Se ha demostrado que contienen varios errores históricos y geográficos, numerosas incongruencias narrativas y abundantes elementos sobrenaturales que son sin duda expresiones de fe y de los que se discute si tienen o no un origen histórico. Sin embargo, sitúan a Jesús en un marco histórico verosímil, en general acorde con lo conocido mediante fuentes no cristianas, y esbozan una trayectoria biográfica bastante coherente.

La corriente de investigación llamada «historia de las formas», cuyos máximos representantes fueron Rudolf Bultmann y Martin Dibelius, se orientó sobre todo a estudiar la «prehistoria» literaria de los evangelios. Estos autores determinaron que los evangelios (incluido Q, considerado como un «protoevangelio») son compilaciones de unidades literarias menores, denominadas perícopas, que pertenecen a géneros literarios diferentes (narraciones de milagros, diálogos didácticos, enseñanzas éticas, etc.). Estas perícopas tienen su origen último en la tradición oral sobre Jesús, pero solo algunas de ellas se refieren a dichos y hechos verdaderos del Jesús histórico. Más adelante, otra escuela, denominada «historia de la redacción» (o crítica de la redacción), destacó el hecho de que, a la hora de compilar y unificar narrativamente el material de que disponían, los autores de los evangelios respondían a motivaciones teológicas.

Para datar los "Evangelios" sinópticos, un aspecto de particular importancia son las referencias a la destrucción del Templo de Jerusalén. Estudiando estas referencias, la mayoría de los autores coinciden en afirmar que los tres sinópticos, en su estado actual, son posteriores a la destrucción del templo (año 70), en tanto que Q es muy probablemente anterior.

Los autores de los evangelios responden a motivaciones teológicas concretas. En sus obras, intentan armonizar las tradiciones recibidas acerca del Jesús histórico con la fe de las comunidades a las que pertenecen.





Generalmente se considera que el "Evangelio de Juan" es más tardío que los sinópticos (suele datarse en torno al año 100) y que la información que ofrece acerca del Jesús histórico es menos fiable. Muestra una teología más desarrollada, ya que presenta a Jesús como un ser preexistente, sustancialmente unido a Dios, enviado por él para salvar al género humano.
Sin embargo, parece que su autor utilizó fuentes antiguas, en algunos casos independientes de los sinópticos, por ejemplo, en lo relativo a la relación entre Jesús y Juan el Bautista, y al proceso y ejecución de Jesús.
Relata pocos milagros de Jesús (solo siete), para los que posiblemente utilizó como fuente un hipotético "Evangelio de los Signos". En este evangelio son muy numerosas las escenas de la vida de Jesús que no tienen un paralelo en los sinópticos (entre ellas, algunas de las más conocidas, como las bodas de Caná o la resurrección de Lázaro de Betania).

Se denomina evangelios apócrifos a aquellos textos sobre hechos o dichos de Jesús no incluidos en el canon del Nuevo Testamento. Como señala Antonio Piñero, la mayor parte de los apócrifos no aportan información válida sobre el Jesús histórico, ya que se trata de textos bastante tardíos (posteriores a 150), y que utilizan como fuentes los evangelios canónicos.

Existen, sin embargo, algunas excepciones notables: el "Evangelio de Pedro", el "Papiro Egerton 2", los "Papiros de Oxirrinco" y, muy especialmente, el "Evangelio de Tomás".
Sobre la datación de estos textos no hay acuerdo entre los especialistas, pero la posición mayoritaria es que pueden contener información auténtica acerca de Jesús. Dado su carácter fragmentario, sin embargo, se han utilizado sobre todo para confirmar informaciones que también transmiten los evangelios canónicos.


La historicidad de estas referencias es considerada en general bastante dudosa.

Apenas hay menciones de Jesús en fuentes no cristianas de los siglos I y II. Ningún historiador se ocupó por extenso de su historia: solo existen alusiones de pasada, algunas de ellas ambiguas, y una de las de Flavio Josefo (el llamado «Testimonio flaviano») contiene posiblemente alguna interpolación posterior. Sin embargo, todas juntas bastan para certificar su existencia histórica.
Al respecto "The New Encyclopaedia Britannica" afirma: 

Estas fuentes pueden dividirse en:


El primer pasaje de la citada obra que menciona a Jesús es conocido con el nombre de «testimonio Flaviano». Se encuentra en "Antigüedades Judías", 18.3.3. Fue objeto de interpolaciones posteriores por copistas cristianos, y durante muchos años se debatió incluso si en su versión original Josefo aludía a Jesús. Este debate fue resuelto en 1971, al aparecer un manuscrito árabe del siglo X en el que el obispo Agapio de Hierápolis citaba ese texto de Josefo. Ya que la primera copia que se posee de Josefo (la de la Ambrosiana) data del siglo XI, un siglo más tarde, hay que admitir que el texto árabe, anterior, reproduce el de Josefo sin interpolaciones. 

El segundo pasaje no ha solido ser discutido, ya que está estrechamente relacionado con el contexto de la obra y parece improbable que se trate de una interpolación. Se encuentra en "Antigüedades Judías", 20.9.1, y se refiere a la lapidación de Santiago, que el texto identifica como hermano de Jesús, un personaje que es llamado del mismo modo en algunos textos de Pablo de Tarso. Aunque sin consenso absoluto, para la mayor parte de los autores el pasaje es auténtico.


Breves menciones en sendas obras de Suetonio (c. 70-"post" 126), Tácito (61-117) y Plinio el Joven (62-113). Excepto el de Tácito, son más bien referencias a la actividad de los cristianos:


Existen algunos textos más, como el de Luciano de Samósata (segunda mitad del siglo II d.C.), que menciona a "aquel hombre a quien siguen adorando, que fue crucificado en Palestina... aquel sofista crucificado", u otro que, aunque es dudoso, podría ser una referencia a Jesús de Nazaret: se trata de una carta, conservada en siríaco, escrita por un tal Mara Bar-Serapion, en la que se habla de un "rey sabio" condenado a muerte por los judíos. No hay acuerdo sobre si esta carta data del siglo I, II o III de nuestra era, y tampoco está claro si es o no una referencia a Jesús de Nazaret.

La escasez de fuentes no cristianas sugiere que la actividad de Jesús no llamó la atención en su época, aunque según las fuentes cristianas su predicación habría congregado a multitudes. Las fuentes no cristianas aportan solo una imagen muy esquemática al conocimiento de Jesús como personaje histórico.

La investigación histórica de las fuentes cristianas sobre Jesús de Nazaret exige la aplicación de métodos críticos que permitan discernir las tradiciones que se remontan al Jesús histórico de aquellas que constituyen adiciones posteriores, correspondientes a las primitivas comunidades cristianas.

La iniciativa en esta búsqueda partió de investigadores cristianos. Durante la segunda mitad del siglo XIX, su aportación principal se centró en la historia literaria de los evangelios.

Los principales criterios sobre los que existe consenso a la hora de interpretar las fuentes cristianas son, según Antonio Piñero, los siguientes:






No todos los autores, sin embargo, interpretan del mismo modo estos criterios, e incluso hay quienes niegan la validez de algunos de ellos.

El pueblo judío, sin estado propio desde la destrucción del Primer Templo en , en tiempos de Nabucodonosor II, había pasado varias décadas sometido, sucesivamente, a babilonios, persas, la dinastía ptolemaica de Egipto y el Imperio seléucida, sin que se produjeran conflictos de gravedad. En el , sin embargo, el monarca seléucida Antíoco IV Epífanes, decidido a imponer la helenización del territorio, profanó el Templo (el Segundo Templo, reconstruido en época persa), lo que desencadenó una rebelión, acaudillada por una familia sacerdotal, los Macabeos, que tendría como consecuencia el establecimiento de un nuevo estado judío independiente, que duraría hasta el año 

En este año, el general romano Pompeyo intervino en la guerra civil que enfrentaba a dos hermanos de la dinastía asmonea, Hircano II y Aristóbulo II. Con esta intervención dio comienzo el dominio romano en Palestina. Dicho dominio, sin embargo, no se ejerció siempre de forma directa, sino mediante la creación de uno o varios estados clientes, que pagaban tributo a Roma y estaban obligados a aceptar sus directrices. El propio Hircano II fue mantenido por Pompeyo al frente del país, aunque no como rey, sino como etnarca. Posteriormente, tras un intento de recuperar el trono del hijo de Aristóbulo II, Antígono, quien fue apoyado por los partos, el hombre de confianza de Roma fue Herodes, quien no pertenecía a la familia de los asmoneos, sino que era hijo de Antípatro, un general de Hircano II de origen idumeo.

Tras su victoria sobre los partos y los seguidores de Antígono, Herodes fue nombrado rey de Judea por Roma en Su reinado, durante el cual, según opinión mayoritaria, tuvo lugar el nacimiento de Jesús de Nazaret, fue un período relativamente próspero.

A la muerte de Herodes, en , su reino se dividió entre tres de sus hijos: Arquelao fue designado etnarca de Judea, Samaria e Idumea; a Antipas (llamado Herodes Antipas en el Nuevo Testamento) le correspondieron los territorios de Galilea y Perea, que gobernó con el título de tetrarca; por último, Filipo heredó, también como tetrarca, las regiones más remotas: Batanea, Gaulanítide, Traconítide y Auranítide.

Estos nuevos gobernantes correrían diversa suerte. Mientras que Antipas se mantuvo en el poder durante cuarenta y tres años, hasta 39, Arquelao, debido al descontento de sus súbditos, fue depuesto en 6 d. C. por Roma, que pasó a controlar directamente los territorios de Judea, Samaría e Idumea.

En el período en que Jesús desarrolló su actividad, por lo tanto, su territorio de origen, Galilea, formaba parte del reino de Antipas, responsable de la ejecución de Juan el Bautista, y al que una tradición tardía, que solo se encuentra en el "Evangelio de Lucas", hace jugar un papel secundario en el juicio de Jesús. Judea, en cambio, era administrada directamente por un funcionario romano, perteneciente al orden ecuestre, que llevó primero el título de prefecto (hasta el año 41) y luego (desde el 44) el de procurador. En el período de la actividad de Jesús, el prefecto romano era Poncio Pilato.

El prefecto no residía en Jerusalén, sino en Cesarea Marítima, ciudad de la costa mediterránea que había sido fundada por Herodes el Grande, aunque se desplazaba a Jerusalén en algunas ocasiones (por ejemplo, con motivo de la fiesta de Pésaj o Pascua, como se relata en los evangelios, ya que era en estas fiestas, que congregaban a miles de judíos, cuando solían producirse tumultos). Contaba con unos efectivos militares relativamente reducidos (unos 3.000 hombres), y su autoridad estaba supeditada a la del legado de Siria. En tiempos de Jesús, el prefecto tenía el derecho exclusivo de dictar sentencias de muerte "(ius gladii)".

Sin embargo, Judea gozaba de un cierto nivel de autogobierno. En especial, Jerusalén estaba gobernada por la autoridad del sumo sacerdote, y su consejo o Sanedrín. Las competencias exactas del Sanedrín son objeto de controversia, aunque en general se admite que, salvo en casos muy excepcionales, no tenían la potestad de juzgar delitos capitales.

Aunque separada de Judea por la historia, Galilea era en el siglo I una región de religión judía. Tenía, sin embargo, algunos rasgos diferenciales, como una menor importancia del Templo, y una menor presencia de sectas religiosas como los saduceos y los fariseos. Estaba muy expuesta a las influencias helenísticas y presentaba grandes contrastes entre el medio rural y el medio urbano.

Al este de Galilea se encontraban las diez ciudades de la Decápolis, situadas todas ellas al otro lado del río Jordán, a excepción de una, Escitópolis (llamada también Bet Shean). Al noroeste, Galilea limitaba con la región sirofenicia, con ciudades como Tiro, Sidón y Aco/Tolemaida. Al sudoeste se situaba la ciudad de Cesarea Marítima, lugar de residencia del prefecto (luego procurador) romano. Por último, al sur se encontraba otra importante ciudad, Sebaste, así llamada en honor al emperador Augusto.

En pleno corazón de Galilea se encontraban también dos importantes ciudades: Séforis, muy cercana (5 o 6 km) a la localidad de donde era originario Jesús, Nazaret; y Tiberíades, construida por Antipas y cuyo nombre era un homenaje al emperador Tiberio. Tiberíades era la capital de la monarquía de Antipas, y estaba muy próxima a Cafarnaún, ciudad que fue con probabilidad el centro principal de la actividad de Jesús.

Es importante destacar que las ciudades eran focos de influencia de la cultura helenística. En ellas residían las élites, en tanto que en el medio rural habitaba un campesinado empobrecido, del que procedía con toda probabilidad Jesús. Las ciudades eran en general favorables a Roma, como se demostró con ocasión de la primera guerra judeo-romana.

En las fuentes cristianas no se menciona que Jesús visitase ninguna de las ciudades de Galilea ni de su entorno. Sin embargo, dada la proximidad de Tiberíades a los principales lugares mencionados en los evangelios, es difícil pensar que Jesús se sustrajo por completo a la influencia helenística.

El medio campesino, del que procedía Jesús, veía con hostilidad las ciudades. Los campesinos de Galilea soportaban importantes cargas impositivas, tanto del poder político (la monarquía de Antipas), como del religioso (el Templo de Jerusalén), y su situación económica debió de ser bastante difícil.

Galilea fue la región judía más conflictiva durante el siglo I, y los principales movimientos revolucionarios antirromanos, desde la muerte de Herodes el Grande en 4 a. C. hasta la destrucción de Jerusalén en el año 70, se iniciaron en esta región. La lucha contra el Imperio romano fue, según el historiador Geza Vermes, «una actividad galilea general en el primer siglo d. C.».

En tiempos de Jesús, al igual que en la actualidad, el judaísmo era una religión monoteísta, basada en la creencia de un único Dios. Los judíos creían que Dios había elegido a su pueblo, Israel, y había establecido con él una alianza a través de Abraham y Moisés, principalmente. Los actos fundamentales de dicha alianza eran, para los judíos, la vocación de Abraham, el éxodo, y la promulgación de la ley en el Sinaí.
La fidelidad de los judíos a esta alianza se manifestaba, además de en su adoración a su único Dios, en la rigurosidad con que seguían los mandamientos y preceptos de la Torá, o la llamada Ley mosaica; esta regulaba todos los aspectos de la vida de los judíos, como la obligación de circuncidar a los hijos varones, la prohibición de trabajar en sábado, y otras ciertas reglas alimentarias (por ejemplo, la de no comer carne de cerdo) y de purificación.

En el siglo I, el centro del culto a Dios era el Templo de Jerusalén. Era necesario acudir a este tres veces al año (durante las llamadas fiestas de peregrinación), para realizar diversos sacrificios y entregar ofrendas. El culto del Templo era administrado por los sacerdotes y levitas, cuyo número era muy elevado, quienes desempeñaban los llamados oficios sagrados durante las fiestas, tales como custodiar y limpiar el Templo, preparar los animales y la leña para los sacrificios, y cantar salmos durante las celebraciones públicas.
Los sacerdotes y levitas se mantenían con los tributos de los campesinos, obligatorios para todos los judíos.

Pero el Templo no era el único lugar en que se rendía culto a Dios: en época de Jesús existía también la costumbre de reunirse cada sábado en las sinagogas. Mientras que el culto en el Templo estaba dominado por los sacerdotes, la costumbre de reunirse en las sinagogas fue promoviendo la religiosidad de los laicos.
Además, en las sinagogas no se llevaban a cabo sacrificios a diferencia del Templo, sino que tan solo se leían y comentaban los textos sagrados.

En la época de Jesús, existían sectas divergentes dentro del judaísmo. El autor que más información proporciona sobre este tema es Flavio Josefo. Este distingue entre tres sectas principales: la saducea, la esenia y la farisea. Esta última era bastante respetada por el pueblo y estaba constituida principalmente por laicos.

Los fariseos creían en la inmortalidad del alma y eran conocidos por el rigor con que interpretaban la ley, considerando a la tradición como fuente de esta. En cuanto a los saduceos, gran número de ellos formaba parte de la casta sacerdotal, pero en oposición a los fariseos, rechazaban la idea de que la tradición era fuente de ley y negaban también la inmortalidad del alma. Por último, el grupo de los esenios es considerado por la inmensa mayoría de los investigadores como el autor de los denominados manuscritos del Mar Muerto. Constituían una especie de monacato, cuyos seguidores eran estrictos cumplidores de la ley, aunque diferían de los otros grupos religiosos en su interpretación de esta.

Otro aspecto de suma importancia en el judaísmo del siglo I es su concepción apocalíptica: la creencia en una intervención futura de Dios, que restauraría el poder de Israel y tras la que reinarían la paz y armonía universales. Esta idea adquirió gran fuerza en la época en que el pueblo judío fue sometido por la ocupación romana (aunque está ya presente en varios de los libros proféticos de la "Tanaj", especialmente en el "Libro de Isaías)", y se relaciona estrechamente con la creencia en la llegada de un Mesías. Además, es muy mencionada en la llamada literatura intertestamentaria: libros apócrifos generalmente atribuidos a patriarcas u otras figuras destacadas de la Biblia hebrea.

Jesús de Nazaret nació con bastante probabilidad en torno al año 4 a. C., aunque la fecha no puede determinarse con seguridad. Según la opinión hoy mayoritaria entre los estudiosos, su lugar de nacimiento fue la aldea galilea de Nazaret, aunque pudo haber nacido también en Belén, en Judea, cerca de Jerusalén. Es probable que sus padres se llamaran José y María, y que tuviera varios hermanos y hermanas. No hay constancia de que estuviera casado; probablemente era célibe, aunque tampoco hay ninguna fuente que lo afirme. Cuando tenía aproximadamente treinta años, se hizo seguidor de un predicador conocido como Juan el Bautista y, cuando este fue capturado por orden del tetrarca de Galilea, Antipas (o tal vez antes), formó su propio grupo de seguidores. Como predicador itinerante, recorrió varias localidades de Galilea, anunciando una inminente transformación que denominaba Reino de Dios. Predicaba en arameo, aunque es muy probable que conociese también el hebreo, lengua litúrgica del judaísmo, tanto en sinagogas como en casas privadas y al aire libre. Entre sus seguidores había varias mujeres.

Desarrolló su predicación durante un tiempo imposible de concretar, pero que en cualquier caso no excedió de tres años, y muy probablemente fue bastante inferior. Durante su predicación, alcanzó fama en la región como sanador y exorcista. Según su punto de vista, su actividad como taumaturgo anunciaba también el Reino de Dios. Fue acusado de borracho y comilón, amigo de publicanos y prostitutas (Mt 11,19), y de exorcizar con el poder del príncipe de los demonios (Mt, 12, 22-30). Sus familiares lo tuvieron por enajenado (Mc 3,21). Las muchedumbres le inspiraban compasión (Mt 14, 14) y la única vez que habló de su personalidad se autodefinió como manso y humilde de corazón (Mt, 11-29) pero rechazó ser llamado bueno, porque solo Dios es bueno (Mc 10,18). La presencia viva de Jesús generaba en sus discípulos una alegría liberadora: «¿acaso pueden los compañeros del novio ayunar mientras el novio está con ellos? Mientras que tienen con ellos al esposo no pueden ayunar» (Mc 2, 19).

Con motivo de la fiesta de la Pascua, acudió con un grupo de seguidores suyos a Jerusalén. Probablemente por algo que hizo o dijo en relación con el Templo de Jerusalén, aunque no pueden excluirse otros motivos, fue detenido por orden de las autoridades religiosas judías de la ciudad, quienes lo entregaron al prefecto romano, Poncio Pilato, acusado de sedición. Como tal, fue ejecutado, posiblemente en torno al año 30, por orden de las autoridades romanas de Judea. A su muerte, sus seguidores se dispersaron, pero poco después vivieron colectivamente una experiencia que les llevó a creer que había resucitado y que regresaría en un plazo breve para establecer el Reino de Dios que había predicado en vida.

"Jesús" es la forma latinizada del griego Ιησοῦς (Iesoûs), con el que es mencionado en el Nuevo Testamento, escrito en griego. El nombre deriva del hebreo Ieshú, forma abreviada de Yeshúa, la variante más extendida del nombre Yehoshúa, que significa ‘Yahveh salva’, y que designa así mismo a Josué, un conocido personaje del Antiguo Testamento, lugarteniente y sucesor de Moisés.

Se sabe que era un nombre frecuente en la época, ya que en la obra de Flavio Josefo son mencionados unos veinte personajes de igual denominación.
La forma de este nombre en arameo ―el idioma de la Judea del siglo I― es la que con toda probabilidad usó Jesús: Ieshuá (ישׁוע, Yēšûaʿ).

En Marcos y Lucas, Jesús es llamado "Iesoûs hó Nazarēnós" (Ιησοῦς ὅ Ναζαρηνός); en Mateo, Juan y a veces en Lucas se utiliza la forma "Iesoûs hó Nazoraîos" (Ιησοῦς ὅ Ναζωραῖος), que aparece también en Hechos de los Apóstoles.
La interpretación de estos epítetos depende de los autores: para la mayoría, ambos hacen referencia a su localidad de origen, Nazaret; otros, interpretan el epíteto "nazoraîos" (‘nazoreo’) como compuesto de las palabras hebreas "neser" (‘retoño’) y "semah" (‘germen’); según esta interpretación, el epíteto tendría un carácter mesiánico; otros, en cambio, lo interpretan como Nazareo (separado para Yahveh).
El "Diccionario de la lengua española" (de la Real Academia Española) recoge para la palabra «nazareno» la descripción: ‘Hebreo que se consagraba particularmente al culto de Dios, no bebía licor alguno que pudiese embriagar, y no se cortaba la barba ni el cabello’.
Muy posiblemente, en tiempos de Jesús hubiese unos cuantos hombres más que actuasen de esta manera como servicio religioso.

Jesús nació probablemente en Nazaret, en Galilea, ya que en la mayoría de las fuentes se le llama «Jesús de Nazaret», y en la antigüedad solía expresarse de esta forma el lugar de nacimiento.
Sin embargo, dos evangelios (Lucas y Mateo), los únicos que entre los evangelios canónicos hacen referencia a la infancia de Jesús, relatan su nacimiento en Belén, en Judea. Aunque este lugar de nacimiento es el comúnmente aceptado por la tradición cristiana, los investigadores actuales han puesto de relieve que los relatos de Mateo y Lucas están elaborados con temas de la tradición davídica, contienen varios elementos históricamente poco fiables, y muestran una clara intención de demostrar que Jesús era el Mesías, que, según Miq 5,2, debía nacer en Belén.
Son muchos los críticos actuales que consideran que la historia del nacimiento de Jesús en Belén es una adición posterior de los autores de estos evangelios y no se corresponde con la realidad histórica.
Sin embargo, otros autores, la mayoría de ellos católicos, entienden que no hay razones para dudar de la veracidad histórica de Mateo y Lucas en lo referente a este punto.

Aunque Nazaret es citada 12 veces en los evangelios, y las investigaciones arqueológicas indican que el pueblo fue continuamente ocupado desde el siglo VII antes de la era común, «Nazaret» no es mencionada por historiadores o geógrafos de los primeros siglos de la era común. Según John P. Meier, Nazaret era «un lugar insignificante situado en los montes de la Baja Galilea, un pueblo tan oscuro que nunca lo mencionan el Antiguo Testamento, Josefo, Filón, ni la literatura temprana de los rabinos, ni los "pseudepigrapha" del Antiguo Testamento».
Aunque Lc 1, 26 la llama «ciudad», en realidad sería una pobre aldea que debió toda su importancia posterior al hecho cristiano.
El nombre de nazarenos dado a los cristianos palestinenses del siglo I era sin dudas irónico y despectivo, y en tal sentido el nombre de Jesús se acompañó con el título «de Nazaret», un lugar oscuro que en nada lo favorecía, tal lo señalado por Raymond E. Brown.

Con los datos con que se cuenta en el presente, no es posible precisar el año del nacimiento de Jesús de Nazaret. Se considera un dato bastante seguro que la muerte de Herodes el Grande tuvo lugar en el año 4 a. C. De allí que al datar el nacimiento de Jesús, la gran mayoría de los autores se decantan por un rango entre los años 7 y 4 a. C., ya que existe probabilidad a favor de que el nacimiento haya sucedido en los últimos años del reinado de Herodes el Grande.
Algunos autores extienden el plazo probable del nacimiento a 8 a. C., o 3-2 a. C., aunque estas posiciones son hoy claramente minoritarias.

Las fuentes cristianas no ofrecen una cronología absoluta de los acontecimientos de la vida de Jesús, con una sola salvedad: Lc 3,1 fija el comienzo de la actividad de Juan el Bautista en «el año quince del reinado de Tiberio», que posiblemente pueda interpretarse como equivalente a uno de estos años: 27, 28 o 29. Un poco más adelante (Lc 3,23), indica que Jesús contaba aproximadamente 30 años al comienzo de su predicación. Además de situar ―al igual que Mateo― el nacimiento de Jesús al final del reinado de Herodes el Grande, el relato de "Evangelio de Lucas" 2, 1-2 menciona el «censo de Quirino» (cuyo nombre completo y preciso es Publio Sulpicio Quirinio, siendo «Quirino» o «Cirino» probables desviaciones de los copistas), lo que plantea un problema histórico que no se ha resuelto. En "Antigüedades judías", 17.13; 18.1, el historiador Flavio Josefo aludió a un censo bajo Cirino (Quirinio o Quirino) siendo Coponio procurador de Judea. Si se cotejan los versículos de Lucas con todas las crónicas históricas sobre el gobierno de Quirinio en Siria y los empadronamientos que se hicieron bajo el mandato de César Augusto, se llega al hecho de que se desconoce que se haya ordenado un censo que «abarcara a todo el mundo conocido bajo Augusto», y que el censo de Judea, que no incluía a Nazaret, y que se llevó a cabo bajo Quirinio, habría ocurrido unos diez años después de la muerte de Herodes el Grande, es decir, en el año 6 o 7 d. C. y por lo tanto, presumiblemente después del nacimiento de Jesús. Es probable que "post factum", es decir, tras la muerte de Jesús de Nazaret, su nacimiento se haya asociado a recuerdos dispersos de acontecimientos que ocurrieron unos años antes o después del nacimiento en sí. Sobre este punto, Antonio Piñero señaló: «La inmensa mayoría de los investigadores cree que Lucas se refiere «de oídas» al censo de Quirinio del 6 d. C, por tanto unos diez años después del nacimiento de Jesús».

Convencionalmente, se adoptó como la fecha de nacimiento de Jesús la calculada en el siglo VI por Dionisio el Exiguo, basada en cálculos erróneos y que hoy sirve de inicio de la llamada era cristiana; también convencionalmente, en el siglo IV comenzó a celebrarse su nacimiento el 25 de diciembre.

Sobre la familia de Jesús, todos los evangelios están de acuerdo en el nombre de su madre, María y de su padre, José, si bien dos de los evangelios (Mateo y Lucas) contienen relatos, diferentes entre sí, acerca de la concepción milagrosa de Jesús por obra del Espíritu Santo. Según estos relatos, José no habría sido su padre verdadero, sino solo su padre legal, por ser el esposo de María. La mayoría de los investigadores creen que estos relatos son bastante tardíos: no se mencionan en los evangelios de Marcos y de Juan, y existen indicios que permiten sospechar que en tiempo de Jesús este era conocido como «hijo de José».

Los hermanos de Jesús son mencionados en varias ocasiones en los evangelios y en otros libros del Nuevo Testamento.
En Mc 6, 3 se mencionan los nombres de los cuatro hermanos varones de Jesús: Jacob (Santiago), José, Judas y Simeón o Simón, y se indica también la existencia de dos hermanas.

Son numerosas las fuentes que indican la ascendencia davídica de Jesús, a través de José (a pesar de que, como antes se ha dicho, algunos evangelios afirman explícitamente que José no fue el padre biológico de Jesús). Varios pasajes del Nuevo Testamento muestran que era llamado «hijo de David», y que la idea de su origen davídico estaba muy extendida en los primeros años del cristianismo aunque él nunca se refirió a sí mismo como tal. Los críticos no están de acuerdo, sin embargo, en que esta ascendencia davídica sea un dato cierto, dado que puede tratarse de una adición de los evangelistas para demostrar la condición mesiánica de Jesús. Las genealogías de Jesús que aparecen en Mateo y Lucas (Mt 1, 1-16 y Lc 3, 23-31) son diferentes entre sí, aunque ambas vinculan a José, padre legal de Jesús con la estirpe de David.

La actividad de Jesús se inscribió en el marco de la religiosidad judía. De las fuentes se infiere que en general cumplió los preceptos de la Ley mosaica (aunque en ocasiones discrepara de la interpretación que de ella hacían algunos grupos religiosos), y que participó de creencias comunes en el judaísmo del siglo I (como la existencia de demonios o la resurrección de los muertos).

Los investigadores están de acuerdo en que la lengua materna de Jesús fue el arameo. Aunque los evangelios están escritos en griego, contienen frecuentes expresiones en arameo, la mayor parte de ellas atribuidas a Jesús. Además, el arameo era la lengua habitual de los judíos de Galilea. Seguramente el arameo hablado en Galilea era una variante dialectal reconocible, como lo atestigua el hecho de que Pedro sea reconocido por su acento en Jerusalén (véase Mt 26, 73).

No puede aclararse si Jesús hablaba o no griego.
En general se cree que conocía el hebreo, que en la época era solo una lengua religiosa y de cultura, y que sabía leer, ya que en una ocasión se le presenta leyendo el "Libro de Isaías" (escrito en hebreo) en una sinagoga.

Parece ser que tanto Jesús como su padre, José, ejercieron la profesión de carpinteros.
En cualquier caso, hay bastante consenso en cuanto a que procedía de un medio campesino. En su predicación hizo también constantes referencias a las labores agrícolas, y apenas parece interesado por el medio urbano (no hay constancia de que en su predicación visitara nunca las principales ciudades de Galilea, a pesar de que la importante ciudad de Séforis se hallaba a corta distancia de Nazaret).

No se conoce con certeza cuánto tiempo duró la vida pública de Jesús. Los "Evangelios" sinópticos mencionan una sola fiesta de Pascua celebrada por él con sus discípulos en Jerusalén, durante la cual fue detenido y crucificado. Eso parece sugerir que su vida pública duró solamente un año. En el "Evangelio de Juan", por el contrario, se mencionan tres fiestas de Pascua, las tres celebradas por Jesús en Jerusalén, lo que hace suponer que el ministerio de Jesús se prolongó durante dos o tres años. En todos los evangelios solo hay una indicación precisa de fecha, la que se ofrece en Lucas (Lc 3, 1-2), indicando que la actividad de Juan el Bautista se inició el año 15 del mandato de Tiberio, lo que puede coincidir, según diferentes cálculos, con los años 27, 28 o incluso 29 de nuestra era, aunque la mayoría de los autores se inclina por el año 28.

La vida pública de Jesús se inicia, según todos los evangelios, con su bautismo por Juan el Bautista en el río Jordán. Es probable que Jesús iniciase su actividad como seguidor del Bautista.

Seguido de un grupo de fieles, de entre los cuales escogió a sus más allegados, los doce apóstoles o enviados, recorrió en su actividad toda Galilea (especialmente el área en torno a Cafarnaún) y las regiones aledañas de Fenicia, la Decápolis y el territorio de la tetrarquía de Herodes Filipo.

Según las fuentes cristianas, su predicación transmitía un mensaje de esperanza especialmente dirigido a los marginados y pecadores (Lc 15). Posiblemente llegó a congregar a grandes multitudes (se habla, por ejemplo, de cinco mil personas en referencia a la multiplicación de los panes y los peces).
Se trasladó a Jerusalén para celebrar allí la Pascua con sus discípulos, y entró triunfalmente en la ciudad.

En los cuatro evangelios canónicos, el comienzo de la vida pública de Jesús lo marca su bautismo por Juan en el Jordán. Juan el Bautista es un personaje relativamente bien conocido gracias a la información que de él proporciona Flavio Josefo, quien afirma que era «un hombre de bien que incitaba a los judíos [...] a ser justos los unos con los otros y píos hacia Dios, y a ir juntos al bautismo» ("Antigüedades judías", 18, 116-119) y relata que Herodes Antipas lo ejecutó por miedo a que provocase una revuelta.
El mensaje de Juan, tal y como es reflejado por las fuentes, parece bastante semejante al de Jesús; según Mateo, en su predicación hacía referencia al Reino de los Cielos e insistía en la necesidad de un pronto arrepentimiento. El hecho de que Jesús se sometiese al rito bautismal sugiere que probablemente formase inicialmente parte de la comunidad religiosa del Bautista.

En los evangelios, Juan se considera a sí mismo un precursor, declarando que no es digno de desatar la correa de las sandalias de Jesús y que este sustituirá su bautismo de agua por el bautismo «en el Espíritu Santo».
Por su parte, Jesús habla con gran respeto de Juan, afirmando que «entre los que nacen de mujer no se ha levantado otro mayor», si bien añade que «el más pequeño en el Reino de los Cielos es mayor que él».
En el "Evangelio de Juan" se sugiere que entre los discípulos de Jesús y del Bautista llegó a haber cierta rivalidad, pero se deja claro que Juan aceptó siempre su subordinación a Jesús.

Debe tenerse en cuenta que los evangelios fueron escritos por seguidores de Jesús, con la finalidad de conseguir nuevos conversos. Si, como parece, Juan el Bautista fue un personaje relativamente conocido y respetado en su tiempo (como parece demostrarlo el hecho de que Flavio Josefo se refiera a él por extenso), es bastante explicable que los evangelistas lo presenten admitiendo públicamente la superioridad de Jesús.

Del estudio de las fuentes (sobre todo los sinópticos) se infiere que Jesús predicó de forma itinerante en la zona norte de cisjordania hoy Palestina y, preferentemente, en las aldeas que bordeaban el lago de Genesaret. Sus seguidores fueron principalmente de extracción campesina, y le acompañaron también varias mujeres, lo cual resulta inusual en el contexto de los movimientos religiosos del judaísmo. Escogió a doce apóstoles o enviados, posiblemente en representación de las doce tribus de Israel. Ni los nombres de los apóstoles ni los relatos de cómo se unieron a Jesús coinciden en todos los evangelios, pero todos concuerdan en la cifra de doce.

La crítica es prácticamente unánime en considerar que el núcleo de la predicación de Jesús era el anuncio del Reino de Dios. Sin embargo, existen importantes discrepancias a la hora de interpretar qué significa esta expresión en el contexto de la predicación de Jesús. El «Reino de Dios» se anuncia como algo inminente; en este sentido, la predicación de Jesús se inserta en el contexto de la literatura apocalíptica del judaísmo, en la que existe la esperanza de una próxima intervención de Dios en los asuntos humanos. Para entrar en el Reino de Dios que Jesús profetiza es necesaria una transformación interior "(metanoia)" que alcanza todos los ámbitos de la existencia humana; así, quien no se hace como un niño no entrará en el Reino (Mt 18, 1-5) y el perdón es condición para un culto eficaz (Mt, 5, 21-26).

Jesús describió el Reino de Dios utilizando parábolas (véase más arriba), en muchas de las cuales aparece un contraste entre un inicio pequeño e insignificante y un final espléndido (Mt 13,31-34), un padre generoso y unos invitados al banquete ocupados y desagradecidos (Mt 22, 1-14), un rey compasivo y un siervo sin piedad (Mt 18, 21-35), un viñador confiado y unos arrendatarios infieles (Lc 20, 9-19), un sembrador despreocupado y distintos tipos de tierra (Mc 4,1-9).

Hay bastante consenso entre los especialistas en cuanto a que la predicación de Jesús iba dirigida en exclusiva al pueblo de Israel. Según Mateo, así lo dijo: «No soy enviado sino a las ovejas perdidas de la casa de Israel» (Mt 15, 24). Entre los historiadores que no han aceptado esta exclusividad judía se encuentra Ernest Renan, quien se expresaba así en su polémica obra "Vida de Jesús" (1863):

En cualquier caso, se admite que algunos gentiles podrían haber participado de su mensaje. Según los evangelios, sanó a algunos gentiles, como el criado del centurión de Cafarnaún o la hija de la mujer sirofenicia, conmovido por la fe que demostraron.

No hay unanimidad entre los estudiosos con respecto a si Jesús se consideró a sí mismo como el Mesías de Israel, como afirman los evangelios canónicos, o si su identificación como tal pertenece a la teología de las primeras comunidades cristianas. En los sinópticos, y especialmente en el "Evangelio de Marcos", Jesús admite implícitamente que es el Mesías, pero pide en numerosas ocasiones a sus discípulos que no lo divulguen («secreto mesiánico»).

Se considera generalmente un dato histórico que Jesús se designó a sí mismo como «Hijo del Hombre», aunque no está claro si se trata de un título escatológico, como parece desprenderse de su empleo en el Libro de Daniel y otros textos intertestamentarios, o si es un mero circunloquio semítico para hacer referencia a la primera persona del singular.

En líneas generales, la predicación de Jesús se mantuvo en el marco del judaísmo de su época.
En algunos aspectos, sin embargo, entró en conflicto con la interpretación que de la ley judía hacían otros grupos religiosos (fundamentalmente saduceos y fariseos), sobre todo en dos aspectos: la observancia del sábado y la pureza ritual. Existen discrepancias sobre cómo interpretar estos conflictos: como una controversia ética (prioridad del bien del hombre sobre la letra del precepto, de lo interior sobre lo exterior), como una controversia de autoridad (Jesús tiene un poder recibido de lo alto y lo ejerce) o como una controversia escatológica (se inaugura un nuevo tiempo).

En la predicación de Jesús, tienen una gran importancia sus enseñanzas éticas. El centro de la ética de Jesús era el amor al prójimo, al desvalido de quien no se puede recibir contraprestación (Lc 14,13) y, muy especialmente, el amor al enemigo (única manera de distinguirse de los paganos que aman a los que les aman a ellos) (Mt 5,44-48, Lc 6,27-38). Para algunos autores, la ética que Jesús predicaba tiene un carácter provisional, y se orienta sobre todo a la época de preparación del Reino de Dios.
Por ese motivo también, la ética de Jesús enfatiza la renuncia a los bienes materiales. En todo caso, las fuentes coinciden en que no se puede servir a Dios y a las riquezas (Mt 6,24).

Son muchos los especialistas que han llamado la atención acerca de la coincidencia en las fuentes sobre la especial consideración que Jesús parece haber tenido hacia las mujeres de diversa condición, en especial las marginadas, enfermas y pecadoras públicas. Algo, en cierta medida, novedoso para un rabí de la época. Los ejemplos son múltiples: así la encorvada a la que se acerca y cura en sábado llamándola hija de Abraham, título exclusivamente masculino (Lc 13,11); la que sufría una patología femenina extrema que la hacía impura y excluida y que alcanza a tocarle sin que Jesús pueda evitar curarla (Mc 5,25-34); la extranjera pagana, único personaje en los evangelios canónicos que le convence en una discusión, apelando a su corazón con una parábola (Mt 15,28); la viuda a la que Jesús se acerca por propia iniciativa, conmovido (Lc 7,13); la prostituta que le unge, con escándalo de los presentes, y a la que le son perdonados los pecados porque «ha amado mucho» (Lc 7, 37-47); la viuda pobre a la que Jesús ensalza por su generosidad (Mc 12, 41-44); Marta y María, las amigas que le acogen en su casa (Lc 10, 38-42); etc.

Las fuentes sinópticas coinciden también en que entre los discípulos itinerantes de Jesús se encontraban mujeres (María Magdalena, Juana, Salomé...), algo no muy común en una sociedad patriarcal. E incluso afirman que permanecieron al pie de la cruz cuando todos habían huido (Mc 15,40-41). Resulta también paradójico que se reconozca como primeros testigos de la resurrección a mujeres, cuyo testimonio apenas tenía validez en aquel contexto social (Mc 16, 11).

Por otro lado, en sus diatribas contra los escribas y fariseos, Jesús les reprocha que devoren los bienes de las viudas con pretextos religiosos (Lc 20, 18), y a los príncipes de los sacerdotes y a los ancianos del pueblo les llega a asegurar que las prostitutas les precederán en el Reino de Dios (Mt 21, 31).

Por su parte, en el "Evangelio de Juan", destacan algunos personajes femeninos: la enemiga étnica de vida licenciosa que es interlocutora del discurso del «agua viva» y de la «adoración en espíritu y en verdad», que acaba evangelizando a sus convecinos samaritanos; Marta de Betania, protagonista de un diálogo fundamental sobre la «resurrección y la vida»; y la mujer adúltera a la que Jesús salva de morir lapidada conforme a la Ley de Moisés. Incluso la crítica histórica y exegética más exigente reconoce que, más allá del carácter kerigmático de estos relatos, se esconde un trasfondo histórico en donde el predicador judío, Jesús de Nazaret, otorgó una consideración llamativa a las mujeres de su tiempo.

Tanto las fuentes sinópticas como el "Evangelio de Juan" presentan a Jesús como hacedor de milagros. También destaca esta faceta de su actividad el Testimonio Flaviano, donde se indica que «llevó a cabo hechos sorprendentes» ("Antigüedades judías", XVIII, 63), aunque no puede asegurarse que no se trate de una interpolación cristiana posterior.

En líneas generales, la investigación actual no concede credibilidad histórica a los hechos maravillosos de Jesús que tienen que ver con alteraciones de las leyes de la Naturaleza, que se consideran proyección de la fe de los primeros cristianos y, como tales, requieren una interpretación simbólica, no literal. En gran medida los relatos de milagros pueden tener un origen helenístico: Rudolf Bultmann encontró paralelismos entre los relatos de los milagros de Jesús y otros similares de la tradición helenística, lo que le llevó a concluir que «parece probable que los relatos taumatúrgicos tienen generalmente un origen helenístico».

No obstante, se acepta en general que Jesús fue considerado por sus contemporáneos como capaz de curar ciertas enfermedades y de exorcizar demonios, lo que puede interpretarse a la luz de las creencias populares en la Palestina del siglo I. Los sinópticos, y especialmente el "Evangelio de Marcos", ofrecen numerosos testimonios de este tipo de actividad, y no parece probable que se trate de adiciones posteriores. Estos testimonios coinciden además con los de las fuentes talmúdicas, donde se relata que Jesús fue ejecutado como hechicero. Algunos investigadores, como el estadounidense Morton Smith, han llegado a considerar este tipo de prácticas como las más importantes en el magisterio de Jesús, hasta el punto de identificarlo como un mago helenístico, similar a otros, aproximadamente contemporáneos, como Apolonio de Tiana.

La mayoría de las fuentes que hacen referencia a la muerte de Jesús concuerdan en que murió crucificado por orden del entonces prefecto romano en Judea, Poncio Pilato.

Que la orden de la ejecución de Jesús partió de la autoridad romana lo confirma lo que se sabe acerca de los procedimientos jurídicos en las provincias del Imperio romano. Las sentencias capitales eran competencia exclusiva del funcionario romano, que tenía el llamado "ius gladii" (‘derecho de espada’).
Solo los romanos, además, utilizaban la crucifixión como método de ejecución. Para la mayoría de los historiadores y biblistas, la referencia en los cuatro evangelios canónicos a la existencia de una inscripción o "titulus" ―tablilla que tenía por función especificar el motivo de la crucifixión― que contenía el cargo condenatorio de Jesús de Nazaret, constituye uno de los datos más sólidos del carácter histórico de su pasión.
Además, Raymond Edward Brown señala que no resulta verosímil que el cargo por el cual se condenó a Jesús de Nazaret («rey de los judíos») sea una invención, porque nunca se presentó como una confesión cristiana y porque se trató de una inscripción a la vista de todos.

Existen, sin embargo, discrepancias entre los investigadores a la hora de determinar algunas circunstancias de la ejecución. En primer lugar, en cuanto al delito del que fue acusado Jesús y por el cual fue condenado a la pena capital. En segundo lugar, en cuanto al grado de implicación de las autoridades judías de Jerusalén en el juicio y sentencia de Jesús.

Ninguna de las fuentes ofrece una fecha exacta para la muerte de Jesús. Sin embargo, tanto las fuentes sinópticas como el "Evangelio de Juan" coinciden en que Jesús murió un viernes. Según los sinópticos, este viernes coincidió con el primer día de la fiesta de Pésaj (Pascua judía), que se celebraba el día 15 del mes hebreo de nisán. El "Evangelio de Juan", en cambio, indica que la muerte de Jesús ocurrió el día anterior a dicha fiesta (es decir, el 14 de nisán), la tarde en la que en el templo de Jerusalén se sacrificaban los corderos pascuales. Se ha indicado que la información dada por Juan puede estar motivada por su intención de identificar a Jesús como el verdadero Cordero de Dios, ya que su muerte, en el relato joánico, tiene lugar a la misma hora en que en el templo se sacrificaban los corderos para la fiesta de Pascua.

Todas las fuentes están de acuerdo en que la ejecución de Jesús tuvo lugar durante el mandato de Poncio Pilato (26-36). Si se acepta como cierta la información que aportan los sinópticos, la muerte de Jesús pudo haber ocurrido en el 27 o el 34, ya que en estos dos años el 15 de Nisán cayó en viernes. Si se cree, en cambio, que la información más fidedigna es la aportada por el "Evangelio de Juan", las fechas posibles son el 30 y el 33, años en los que el 14 de nisán fue viernes.

Algunos autores han intentado armonizar los datos aportados por los sinópticos y por Juan, apelando al uso de dos calendarios diferentes (un calendario lunar oficial y otro solar, utilizado por los esenios). No hay indicios, sin embargo, de que Jesús siguiese otro calendario diferente del que regía las festividades oficiales.

Aunque la tradición cristiana considera generalmente que, en el momento de su muerte, Jesús tenía 33 años, es perfectamente posible que tuviera una edad superior, dado que, como se ha expresado, posiblemente nació antes del 4 a. C. (año de la muerte de Herodes el Grande).
El número 33 con el tiempo ha acabado adquiriendo un sentido simbólico y ha sido empleado por organizaciones como la masonería, que divide su escalafón en 33 grados (siendo el 33 el grado superior).






Algunos autores niegan de forma absoluta la validez histórica de las fuentes cristianas, y sostienen que la figura de Jesús es el resultado de una falsificación consciente por parte de los primeros cristianos.
Según esta teoría, Jesús no fue un personaje histórico, sino una entidad mítica, producto del sincretismo entre las religiosidades helenística y judía. En la actualidad, los principales defensores de esta teoría en medios académicos son George Albert Wells, Earl Doherty, Alvar Ellegård, Timothy Freke y Peter Gandy.

Los principales argumentos que apoyan esta postura son:



La mayoría de los estudiosos consideran esta teoría bastante inverosímil.
Según Antonio Piñero, desde la década de 1920 «no se considera científico negar la existencia histórica de Jesús debido a la cantidad de pruebas directas o indirectas de su existencia».
Como argumentos que hacen más verosímil la existencia histórica de Jesús, Piñero cita:

Murray J. Harris sugirió además «evidencias institucionales y algunas consideraciones psicológicas» en apoyo del carácter histórico de Jesús; entre estas últimas destacó la improbabilidad psicológica de que un grupo de judíos del siglo I, para quienes la crucifixión era una maldición (Dt 21, 23), inventara una religión cuyo fundador fue crucificado por los romanos, acusado de sedición y alboroto político, y que muriesen por sostener semejante engaño por ellos creado.

Es abismal la diferencia entre la mínima repercusión histórica que la predicación de Jesús alcanzó durante su vida y su influencia posterior en la historia universal. El movimiento religioso iniciado por Jesús, escindido del judaísmo, terminó convirtiéndose en una nueva religión, el cristianismo, que fue ganando adeptos por todo el ámbito del Mediterráneo durante los primeros siglos de nuestra era. A pesar de ser duramente criticada, e incluso perseguida, durante el siglo IV la religión cristiana llegó a ser la religión principal (oficialmente la única a partir del "Edicto de Tesalónica") del Imperio romano. La Iglesia cristiana alcanzó un enorme poder, y mantuvo su estructura fuertemente jerarquizada después de las invasiones bárbaras que marcaron el final del Imperio romano de Occidente. En Oriente, continuó siendo la religión oficial del Imperio bizantino hasta el final de este estado, a mediados del siglo XV, si bien en gran parte de los antiguos territorios orientales del Imperio romano se vio desplazada, a partir del siglo VII, por el avance del islam.

El cristianismo se incorporó a la herencia cultural de Europa, hasta el punto de ser considerado en la actualidad como uno de sus principales rasgos de identidad.
Con la expansión de la cultura europea que comenzó en el siglo XV, esta religión se difundió por otros muchos lugares del mundo, especialmente por América, donde es hoy también la religión más importante. En la actualidad, la religión cristiana, en sus diferentes denominaciones, es la que cuenta con mayor número de seguidores en todo el mundo.

La historia de la Iglesia cristiana, tanto en Oriente como en Occidente, ha sido en gran medida la de la lucha entre diferentes concepciones del cristianismo, que desembocaron en varios cismas, con la consiguiente aparición de nuevas iglesias, por lo que en la actualidad no existe una sola, sino muy variadas confesiones cristianas. Todas estas variantes del cristianismo comparten, sin embargo, una visión de Jesús de Nazaret relativamente unitaria en lo esencial (véase más abajo la sección Jesús en el cristianismo).

El cristianismo, y especialmente la figura de Jesús de Nazaret, ha ejercido hasta la actualidad una enorme influencia en todos los aspectos de la cultura de Europa y de América (sobre algunos aspectos de la influencia de Jesús en la cultura, véanse las secciones Jesús en el arte, Jesús en la literatura, Jesús en el cine).

La figura de Jesús de Nazaret es el centro de todas las religiones denominadas cristianas, aunque existen diferentes interpretaciones acerca de su persona.
En general, para los cristianos, Jesús de Nazaret es el protagonista de un acto único e intransferible, por el cual el hombre adquiere la posibilidad de elevarse por encima de su naturaleza caída y alcanzar la salvación.
Dicho acto se consuma con la resurrección de Jesús de Nazaret. La resurrección es, por tanto, el hecho central del cristianismo y constituye su esperanza soteriológica. Como acto, es privativo de la divinidad e inasequible al hombre. De forma más precisa, la encarnación, la muerte y la resurrección compensan en tres actos sucesivos los tres obstáculos que separaban, según la doctrina cristiana, a Dios del hombre: la naturaleza, el pecado y la muerte.
Por la encarnación del Verbo, la naturaleza divina se hace humana.
Por la muerte de Cristo, se supera el pecado y por su resurrección, la muerte.

Históricamente, el núcleo de la doctrina cristiana quedó fijado en el Concilio de Nicea, con la formulación del símbolo niceno. Este concilio es reconocido por las principales denominaciones cristianas: católicos, ortodoxos y las diferentes iglesias protestantes.
El texto del credo niceno en lo referente a Jesús es el siguiente:

Existen, sin embargo, iglesias no trinitarias que no reconocieron la existencia de una Trinidad de personas en Dios (por ejemplo, el arrianismo, y posteriormente el unitarismo).

Jesús de Nazaret es también considerado la encarnación del Hijo, segunda persona o hipóstasis de la trinidad cristiana. Es Hijo por naturaleza y no por adopción, lo que quiere decir que su divinidad y su humanidad son inseparables. La relación entre la naturaleza divina y humana quedó fijada en el Concilio de Calcedonia en estos términos:

Existen algunas religiones cristianas minoritarias que no comparten las definiciones dogmáticas del Concilio de Nicea, del Concilio de Éfeso y del Concilio de Calcedonia.



Varios movimientos religiosos de filiación cristiana, surgidos a partir de la segunda mitad del siglo XIX, se apartan de las creencias tradicionales de las religiones cristianas mayoritarias en lo referente a la doctrina de la Trinidad, la naturaleza de Cristo y su misión. Por ello se discute por parte de los grupos tradicionales si estos movimientos pueden considerarse propiamente cristianos.

Los mormones (La Iglesia de Jesucristo de los Santos de los Últimos Días) creen que Jesucristo ofrece la salvación en dos aspectos diferentes, de la muerte física y de la muerte espiritual.
La iglesia mormona, fundada en Estados Unidos, también mantiene la creencia de que, después de su resurrección, Jesucristo visitó América y continuó allí su enseñanza.

Los testigos de Jehová consideran a Jesús como el único ser creado por Dios directamente y que actualmente no es un hombre ni el Dios todopoderoso, sino «una poderosa criatura espiritual» entronizado como rey.
También creen que Jesús no es parte de una trinidad, y que no resucitó por sí mismo, sino que Dios lo resucitó.
Los Testigos de Jehová afirman que Jesús no murió en una cruz sino en un madero y por ende no usan la cruz ni ningún otro símbolo.
Otro punto que caracteriza sus creencias es que Jesucristo se convirtió en Rey en el cielo en el año 1914 y el Arcángel Miguel es Jesucristo en su posición celestial.

Para la Ciencia Cristiana (Iglesia Científica de Cristo) de Mary Baker Eddy, Jesús el Cristo tiene una dualidad: uno es Jesús como hombre y la otra es Cristo como la idea divina. Jesús representó Cristo, es decir la verdadera idea de Dios.
Este «Cristo-espíritu» gobernó al Jesús físico.
Con la ascensión desapareció Jesús pero la identidad espiritual o Cristo «continúa existiendo en el orden eterno de la Ciencia Divina, redimiendo los pecados del mundo
Jesús no es Dios sino el Hijo de Dios y uno con Dios en «calidad y no en cantidad».
Dios no es un salvador corpóreo sino un Principio salvador.
La salvación no se logra mediante el perdón sino una reforma y recurso de Espíritu.

Los adventistas del Séptimo Día hacen hincapié, como la mayoría de los grupos adventistas, en una escatología de signo milenarista que considera inminente la Parusía (segunda venida de Cristo), la cual se realizará de modo visible y tangible.

Otros movimientos se apartan bastante más de las creencias cristianas, ya que niegan de plano su misión salvadora.

El judaísmo, religión en cuyo marco se desarrolló la predicación de Jesús, rechaza la creencia de que Jesús es Dios, ya que resulta incompatible con su estricto monoteísmo. Igualmente rechaza su identificación con el Mesías o como profeta.

En líneas generales, puede decirse que el judaísmo prestó escasa atención a Jesús de Nazaret. Sin embargo, un personaje llamado Yeshu (alt: Jeshu, Yeishu, en hebreo: יש"ו) es mencionado en antiguos textos rabínicos, entre ellos el Talmud de Babilonia, redactado en fecha anterior al año 600, y la literatura midrásica, de entre 200 y 700. El nombre es similar, aunque no idéntico, a Yeshúa, que es considerado por muchos autores el nombre original de Jesús en arameo. Además, en varios manuscritos del Talmud de Babilonia aparece con el sobrenombre Ha-Notztri, que puede significar ‘el Nazareno’. Por este motivo, y por ciertas coincidencias entre la historia de Jesús conocida por los evangelios cristianos y la del Yeshu citado en el Talmud, algunos autores han identificado a ambos personajes. Existen, sin embargo, discrepancias sobre este punto.

En los textos rabínicos, Yeshúa es caracterizado desde un punto de vista muy negativo: aparece como un embaucador que empuja a los judíos a apostatar de su religión.

El gnosticismo es un conjunto de religiones heterogéneas que florecieron cuando las religiones locales de Asia entraron en contacto con el helenismo. A pesar de su diversidad de contenidos, comparten algunos rasgos, a veces de estilo y, a veces, de contenido. Por ejemplo, era muy común en ellas atribuir al mundo un origen maligno o defectuoso. Para algunas religiones gnósticas, el mundo había sido creado por malignos demiurgos que tenían al hombre encerrado en la existencia terrenal e ignorante de su condición de prisionero. Para otras, el mundo era el fruto de un fracaso o tragedia creativos. Los que conocían (gnosis) esta verdad podían intentar escapar. En contacto con el cristianismo, aparecieron nuevas variantes gnósticas. Las más destacadas fueron:






Jesús, llamado en lengua árabe `Īsā o `Īsā ibn Maryam (‘Jesús, hijo de María’), es uno de los principales profetas del islam. Según el Corán, fue uno de los profetas más queridos por Dios y, a diferencia de lo que ocurre en el cristianismo, para los musulmanes no tiene carácter divino. Existen notables diferencias entre el relato de los evangelios y la narración coránica de la historia de Jesús.

La virginidad de María es plenamente reconocida (Corán, 3,41; 5,19; 19,22 y ss). Jesús es quien anunció la llegada de Mahoma como último profeta (Corán, 3,75; 61,6), aunque siguen su vida y prédica a través de los textos de los evangelios apócrifos. La muerte de Jesús es tratada de forma compleja, al no reconocer explícitamente su sacrificio, sino que antes de la muerte es sustituido por otro ser ―del que nada se dice―, mientras Jesús asciende con Dios y burla a los judíos (Corán, 3,48; 4,156). La muerte ignominiosa de Jesús no se contempla, aunque sí se afirma su regreso el día del Juicio Final (Corán, 4,157; 43,61) y el descubrimiento, en ese día, de que la obra de Jesús fue verdadera (en el sentido de enviado por Dios). El Corán rechaza la Trinidad (según el concepto del "tawhid"), teniéndola por falsa, y considera a Jesús por «Verbo de Dios», pero no hijo de él.

En un primer momento, el arte cristiano evitó representar a Jesús en forma humana, prefiriendo evocar su figura mediante símbolos, tales como el monograma formado por las letras griegas Χ y Ρ, iniciales del nombre griego Χριστός (Cristo), en unión a veces de Α y Ω, primera y última letras, respectivamente, del alfabeto griego, para indicar que Cristo es el principio y el fin; el símbolo del pez (ΙΧΘΥΣ, "ikhthýs" en griego, acróstico de Ἰησοῦς Χριστός, Θεοῦ Υἱός, Σωτήρ ("Iesoûs Khristós, Theoû Huiós, Sōtḗr:" ‘Jesús Cristo, hijo de Dios, Salvador’); el Cordero de Dios; o incluso mediante símbolos antropomórficos, como el del Buen Pastor.

Más tarde aparecieron representaciones de Cristo, primero presentado como un joven imberbe. A partir del siglo IV fue representado casi exclusivamente con barba. En el arte bizantino se hicieron habituales una serie de representaciones de Jesús, algunas de las cuales, como la imagen del Pantocrátor, tuvieron un amplio desarrollo en el arte europeo medieval.

Desde finales del siglo XIX, son numerosos los autores literarios que han dado su interpretación personal de la figura de Jesús. Entre las obras más destacadas que han tratado el tema pueden citarse:


La figura de Jesús ha sido también el tema de algunas obras de literatura de consumo, a veces en géneros como la ciencia ficción o la novela de misterio:


La vida de Jesús según los relatos del Nuevo Testamento, y generalmente desde una perspectiva cristiana, ha sido un tema frecuente en el cine desde su misma aparición. De hecho, Jesús de Nazaret es uno de los personajes más interpretados. Ya en 1898 su vida fue llevada a la pantalla por Georges Hatot y Louis Lumière en un filme titulado "La Vie et la Passion de Jésus-Christ".
En el cine mudo destaca la superproducción "Rey de reyes" (1927), de Cecil B. DeMille.

El tema fue abordado después en repetidas ocasiones, desde las superproducciones de Hollywood, como "Rey de reyes" (Nicholas Ray, 1961) y "La historia más grande jamás contada" (George Stevens, 1965) o la europea "Jesús de Nazaret" (Franco Zeffirelli, 1977) hasta visiones más austeras como la de Pier Paolo Pasolini ("El Evangelio según San Mateo", 1964). También dieron su personal interpretación de la figura de Jesús autores como Griffith ("Intolerancia", 1916), Wiene ("INRI", 1923), Morayta ("El mártir del Calvario", 1952), Dreyer ("Ordet", 1954), Dassin ("El que debe morir", 1957), Buñuel ("Nazarín", 1958, y "La Vía Láctea", 1969), Wajda ("Pilatus und andere", 1971), Rossellini ("El Mesías", 1975), Arcand ("Jesús de Montreal", 1989) o Cuerda ("Así en el cielo como en la tierra", 1995).

Algunas de las películas más recientes sobre la vida de Jesús no han estado exentas de polémica. Es el caso de "Je vous salue, Marie" (1985) de Jean-Luc Godard o "La última tentación de Cristo" (1988), de Martin Scorsese, basada en la novela homónima de Nikos Kazantzakis y muy criticada en general por su interpretación de Jesús, apartada del punto de vista cristiano tradicional. El filme de Mel Gibson "La Pasión de Cristo" (2004) suscitó en cambio la aprobación de amplios sectores del cristianismo, pero fue tachado de antisemita por algunos miembros de la comunidad judía. En 2014 fue estrenada la película "Hijo de Dios".

El personaje de Jesús ha sido tratado en el cine desde muy variados ángulos.
No faltan, por ejemplo, aproximaciones paródicas a la figura del iniciador del cristianismo como "La vida de Brian" (Terry Jones, 1979), musicales como "Jesucristo Superstar" (Norman Jewison, 1973) o "Godspell" (David Greene, 1973) y filmes de animación como "The Miracle Maker" (Derek W. Hayes y Stanislav Sokolov, 2000).

La vida de Jesús también ha sido convertida en musical y llevada a los escenarios en lugares como Broadway. Entre las aproximaciones líricas a la vida y obra de Jesús destacan "Jesucristo Superstar", ópera rock con música de Andrew Lloyd Webber y libreto de Tim Rice, representada por primera vez en 1970. Mucho más alternativa es la obra "Godspell", con música de Stephen Schartz y libreto de John-Michael Tebelak, representada por primera vez en 1971.








</doc>
<doc id="1537" url="https://es.wikipedia.org/wiki?curid=1537" title="Juan Marsé">
Juan Marsé

Juan Marsé Carbó (Barcelona, 8 de enero de 1933), es un novelista español de la llamada Generación de los 50, concretamente de la denominada Escuela de Barcelona, corriente que involucra a sus amigos: Jaime Gil de Biedma, Carlos Barral, Juan García Hortelano, Manuel Vázquez Montalbán, Juan Goytisolo, Terenci Moix y Eduardo Mendoza.

Recibió el Premio Cervantes en 2008.

Nació en Barcelona con el nombre de Juan Faneca Roca, pero tras la muerte de su madre en el parto fue adoptado por un matrimonio, de quienes tomó sus apellidos, pasándose a llamar Juan Marsé Carbó.

Sin terminar sus estudios, se dedicó desde la adolescencia al oficio de joyero. Trabajó durante algún tiempo en la revista barcelonesa de cine "Arcinema", e inicia su carrera literaria en 1958 con unos relatos que aparecerían en las revistas "Ínsula" y "El Ciervo". En 1959 obtuvo su primer premio literario, el Sésamo de cuentos por su relato "Nada para morir" y dos años más tarde publicó su primera novela "Encerrados con un solo juguete". También en 1959 se instaló en París, ciudad en la que residiría hasta 1962 y en la que desempeña variadas actividades, incluidas las de profesor de español, traductor y mozo de laboratorio en el Departamento de Bioquímica Celular del Instituto Pasteur.

Vuelve a Barcelona, donde publica, en 1962, "Esta cara de la luna", hoy repudiada por el autor y desterrada del catálogo de sus Obras Completas. También colaboró con el mundo publicitario, con el de la empresa editorial y fue guionista cinematográfico. Como periodista ha sido redactor jefe de la revista "Boccaccio" y colaborador de la revista "Por favor", en la que llegó a ocupar el puesto de jefe de redacción.

Se casa en 1966 con Joaquina Hoyas, de la que tendrá dos hijos, Alejandro, que nace en 1968, y Berta, en 1970; en este mismo año aparece su excelente novela "La oscura historia de la prima Montse", donde encontramos las claves del universo literario que ha seguido cultivando hasta el presente.

Asimismo, durante los años 1988-89, publicó quincenalmente un serial en el diario "El País" bajo el título "Aventuras del capitán Blay".

La década de los 90 supone la consagración definitiva del escritor barcelonés. En 1990 recibe Premio Ateneo de Sevilla por "El amante bilingüe"; en 1994 le conceden por "El embrujo de Shanghai" y el Premio de la Crítica.

Su obra ha sido traducida a diversos idiomas (alemán, francés, húngaro, inglés, polaco, portugués, rumano.., etc.) y varias de sus novelas han sido adaptadas al cine y al teatro, como "Últimas tardes con Teresa", "Si te dicen que caí", "La muchacha de las bragas de oro" y "El amante bilingüe", entre otras.

El 21 de abril de 2009, 2 días antes de recibir el Premio Cervantes, se le concedió una urna en la Caja de las Letras.

Es padre de la también escritora Berta Marsé.

Las obras de Marsé se sitúan en Barcelona, y más en concreto el barrio de El Guinardó, donde pasó su infancia, que coincidió con la posguerra, lo que ha influenciado el modo de escribir del autor a lo largo de toda su vida. Las obras de Marsé están, pues, ambientadas en El Guinardó o en barrios barceloneses próximos a éste, y en época de postguerra o durante el franquismo; en ellas, Marsé analiza la degradación moral y social de la posguerra, las diferencias de clase, la memoria de los vencidos, los enfrentamientos entre trabajadores y burgueses universitarios y la infancia perdida, casi siempre apelando a las técnicas del realismo social, pero experimentando a veces con otros mecanismos narrativos más vanguardistas, siempre con varios grados de ironía.








En la película "El cónsul de Sodoma" (Sigfrid Monleón, 2010) Juan Marsé es interpretado por el actor Àlex Brendemühl.




</doc>
<doc id="1540" url="https://es.wikipedia.org/wiki?curid=1540" title="Júpiter (planeta)">
Júpiter (planeta)

Júpiter es el quinto planeta del sistema solar. Forma parte de los denominados planetas exteriores o gaseosos. Recibe su nombre del dios romano Júpiter (Zeus en la mitología griega).

Se trata del planeta que ofrece un mayor brillo a lo largo del año dependiendo de su fase. Es, además, después del Sol, el mayor cuerpo celeste del sistema solar, con una masa casi dos veces y media la de los demás planetas juntos (con una masa 318 veces mayor que la de la Tierra y tres veces mayor que la de Saturno, además de ser, en cuanto a volumen, 1317 veces más grande que la Tierra). También es el planeta más antiguo del sistema solar, siendo incluso más antiguo que el sol; este descubrimiento fue realizado por investigadores de la universidad de Münster en Alemania. 

Júpiter es un cuerpo masivo gaseoso, formado principalmente por hidrógeno y helio, carente de una superficie interior definida. Entre los detalles atmosféricos destacan la Gran Mancha Roja (un enorme anticiclón situado en las latitudes tropicales del hemisferio sur), la estructura de nubes en bandas oscuras y zonas brillantes, y la dinámica atmosférica global determinada por intensos vientos zonales alternantes en latitud y con velocidades de hasta 140 m/s (504 km/h).

Júpiter es el planeta con mayor masa del sistema solar: equivale a unas 2,48 veces la suma de las masas de todos los demás planetas juntos. A pesar de ello, no es el planeta más masivo que se conoce: más de un centenar de planetas extrasolares que han sido descubiertos tienen masas similares o superiores a la de Júpiter. Júpiter también posee la velocidad de rotación más rápida de los planetas del sistema solar: gira en poco menos de diez horas sobre su eje. Esta velocidad de rotación se deduce a partir de las medidas del campo magnético del planeta. La atmósfera se encuentra dividida en regiones con fuertes vientos zonales con periodos de rotación que van desde las 9 h 50 min 30 s, en la zona ecuatorial, a las 9 h 55 min 40 s en el resto del planeta.

El planeta es conocido por una enorme formación meteorológica, la Gran Mancha Roja, fácilmente visible por astrónomos aficionados dado su gran tamaño, superior al de la Tierra. Su atmósfera está permanentemente cubierta de nubes que permiten trazar la dinámica atmosférica y muestran un alto grado de turbulencia.

Tomando como referencia la distancia al Sol, Júpiter es el quinto planeta del sistema solar. Su órbita se sitúa aproximadamente a 5 UA, unos 750 millones de kilómetros del Sol.

La masa de Júpiter es tal que su baricentro con el Sol se sitúa en realidad por encima de su superficie (1,068 de radio solar, desde el centro del Sol). A pesar de ser mucho más grande que la Tierra (con un diámetro once veces mayor), es considerablemente menos denso. El volumen de Júpiter es equivalente al de 1317 tierras, pero su masa es sólo 318 veces mayor. La unidad de masa de Júpiter (M) se utiliza para medir masas de otros planetas gaseosos, sobre todo planetas extrasolares y enanas marrones.

Si bien Júpiter necesitaría tener 80 veces su masa para provocar las reacciones de fusión de hidrógeno necesarias y convertirse en una estrella, la enana roja más pequeña que se conoce tiene sólo un 30% más de radio que Júpiter (aunque tiene mucha más masa). Júpiter irradia más calor del que recibe de la escasa luz solar que le llega hasta esa distancia. La diferencia de calor desencadenada es generada por la inestabilidad Kelvin-Helmholtz mediante contracción adiabática (encogimiento). La consecuencia de este proceso es la contracción del planeta unos dos centímetros al año. Después de su formación, Júpiter era mucho más caliente y tenía un diámetro casi el doble del actual.

Si fuese unas cuatro veces más masivo, el interior podría llegar a comprimirse mucho más a causa de fuerzas gravitacionales mayores, lo que podría dar lugar a una disminución de su volumen, independientemente de que su masa aumentase. Como resultado de ello, se especula que Júpiter podría alcanzar uno de los diámetros más amplios que un planeta de estas características y evolución puede lograr. El proceso de reducción del volumen con aumento de masa podría continuar hasta que se alcanzara una combustión estelar, como en las enanas marrones con una masa 50 veces la de Júpiter. Esto ha llevado a algunos astrónomos a calificarlo como “estrella fracasada”, aunque no queda claro si los procesos involucrados en la formación de planetas como Júpiter se asemejan a los procesos de creación de sistemas estelares múltiples.

La atmósfera de Júpiter no presenta una frontera clara con el interior líquido del planeta; la transición se va produciendo de una manera gradual.
Se compone en su mayoría de hidrógeno (87 %) y helio (13 %), además de contener metano, vapor de agua, amoníaco y sulfuro de hidrógeno, todas estas con < 0,1 % de la composición de la atmósfera total.

El astrónomo aficionado inglés A.S. Williams hizo el primer estudio sistemático sobre la atmósfera de Júpiter en 1896. La atmósfera de Júpiter está dividida en cinturones oscuros llamados bandas y regiones claras llamadas zonas, todos ellos alineados en la dirección de los paralelos. Las bandas y zonas delimitan un sistema de corrientes de viento alternantes en dirección con la latitud y en general de gran intensidad; por ejemplo, los vientos en el ecuador soplan a velocidades en torno a 100 m/s (360 km/h). En la Banda Ecuatorial Norte, los vientos pueden llegar a soplar a 140 m/s (500 km/h). La rápida rotación del planeta (9 h 55 min 30 s) hace que las fuerzas de Coriolis sean muy intensas, siendo determinantes en la dinámica atmosférica del planeta.

El científico inglés Robert Hooke observó en 1664 una gran formación meteorológica que podría ser la Gran Mancha Roja (conocida en inglés por las siglas GRS). Sin embargo, no parecen existir informes posteriores de la observación de tal fenómeno hasta el siglo XX. En todo caso, varía mucho tanto de color como de intensidad. Las imágenes obtenidas por el Observatorio Yerkes a finales del siglo XIX muestran una mancha roja alargada, ocupando el mismo rango de latitudes pero con el doble de extensión longitudinal. A veces, es de un color rojo fuerte, y realmente muy notable, y en otras ocasiones palidece hasta hacerse insignificante. Históricamente, en un principio se pensó que la Gran Mancha Roja era la cima de una montaña gigantesca o una meseta que salía por encima de las nubes. Esta idea fue sin embargo desechada en el siglo XIX al constatarse espectroscópicamente la composición de hidrógeno y helio de la atmósfera y determinarse que se trataba de un planeta fluido. El tamaño actual de la Gran Mancha Roja es aproximadamente unas dos veces y media el de la Tierra. Meteorológicamente, la Gran Mancha Roja es un enorme anticiclón muy estable en el tiempo. Los vientos en la periferia del vórtice tienen una velocidad cercana a los 400 km/h.

En marzo de 2006 se anunció que se había formado una segunda mancha roja aproximadamente de la mitad del tamaño de la Gran Mancha Roja. Esta segunda mancha roja se formó a partir de la fusión de tres grandes óvalos blancos presentes en Júpiter desde los años 1940, denominados BC, DE y FA, y fusionados en uno solo entre los años 1998 y 2000, dando lugar a un único óvalo blanco denominado "Óvalo blanco BA",
cuyo color evolucionó hacia los mismos tonos que la Gran Mancha Roja a comienzos del 2006.
La coloración rojiza de ambas manchas puede producirse cuando los gases de la atmósfera interior del planeta se elevan en la atmósfera y sufren la interacción de la radiación solar. Las mediciones en el infrarrojo sugieren que ambas manchas se elevan por encima de las nubes principales. El paso, por tanto, de óvalo blanco a mancha roja podría ser un síntoma de que la tormenta está ganando fuerza. El 8 de abril de 2006, la cámara de seguimiento avanzada del Hubble tomó nuevas imágenes de la joven tormenta.

Las nubes superiores de Júpiter están formadas probablemente de cristales congelados de amoníaco. El color rojizo viene dado por algún tipo de agente colorante desconocido aunque se sugieren compuestos de azufre o fósforo. Por debajo de las nubes visibles Júpiter posee muy posiblemente nubes más densas de un compuesto químico llamado hidrosulfuro de amonio, NHHS. A una presión en torno a 5-6 Pa existe posiblemente una capa aún más densa de nubes de agua. Una de las pruebas de la existencia de tales nubes la constituye la observación de descargas eléctricas compatibles con tormentas profundas a estos niveles de presión. Tales tormentas convectivas pueden en ocasiones extenderse desde los 5 Pa hasta los 300-500 hPa, unos 150 km en vertical.

A finales de abril de 2010, diferentes astrónomos aficionados advirtieron que Júpiter había alterado el color del cinturón subecuatorial, tradicionalmente oscuro, apareciendo la parte sur completamente blanca y muy homogénea. El fenómeno tuvo lugar cuando Júpiter estaba en oposición con el Sol, siendo por lo tanto, observable desde la Tierra. Se barajan varias hipótesis para explicar este cambio, la considerada más probable es un cambio en la coloración de las nubes sin cambios sustanciales en la altura o cantidad de partículas que las forman. Este fenómeno de desaparición aparente de una banda ocurre de manera semi cíclica en Júpiter habiéndose observado con anterioridad en varias ocasiones, en particular en el año 1993 cuando fue estudiado en detalle.
Galería de imágenes de las nubes de Júpiter

En el interior del planeta el hidrógeno, el helio y el argón (gas noble que se acumula en la superficie de Júpiter), se comprimen progresivamente. El hidrógeno molecular se comprime de tal manera que se transforma en un líquido de carácter metálico a profundidades de unos 15 000 km con respecto a la superficie. Más abajo se espera la existencia de un núcleo rocoso formado principalmente por materiales helados y más densos de unas siete masas terrestres (aunque un modelo reciente aumenta la masa del núcleo central de este planeta entre 14 y 18 masas terrestres, y otros autores piensan que puede no existir tal núcleo, además de existir la posibilidad de que el núcleo fuera mayor en un principio, pero que las corrientes convectivas de hidrógeno metálico caliente le habrían hecho perder masa). La existencia de las diferentes capas viene determinada por el estudio del potencial gravitatorio del planeta medido por las diferentes sondas espaciales. De existir el núcleo interno, probaría la teoría de formación planetaria a partir de un disco de planetesimales. Júpiter es tan masivo que todavía no ha liberado el calor acumulado en su formación y posee, por lo tanto, una importante fuente interna de energía calórica que ha sido medida de manera precisa y equivale a 5,4 W/m². Esto significa que el interior del planeta está mezclado de manera eficaz por lo menos hasta niveles cercanos a las nubes de agua a 5 bar.

El mismo modelo mencionado antes que da una masa mayor al núcleo del planeta, considera que éste tiene una estructura interna formada por cilindros concéntricos que giran a distinta velocidad —los ecuatoriales (que son los externos) más rápido que los internos—, de modo similar al Sol; se espera que la misión JUNO —que fue lanzada en 2011 y que entró en órbita alrededor del planeta el 4 de julio de 2016— pueda determinar con sus mediciones de la gravedad joviana la estructura interna del planeta.

Júpiter tiene una magnetosfera extensa formada por un campo magnético de gran intensidad. El campo magnético de Júpiter podría verse desde la Tierra ocupando un espacio equivalente al de la Luna llena a pesar de estar mucho más lejos. El campo magnético de Júpiter es de hecho la estructura de mayor tamaño en el sistema solar. Las partículas cargadas son recogidas por el campo magnético joviano y conducidas hacia las regiones polares donde producen impresionantes auroras. Por otro lado las partículas expulsadas por los volcanes del satélite Ío forman un toroide de rotación en el que el campo magnético atrapa material adicional que es conducido a través de las líneas de campo sobre la atmósfera superior del planeta.

Se piensa que el origen de la magnetosfera se debe a que en el interior profundo de Júpiter, el hidrógeno se comporta como un metal debido a la altísima presión. Los metales son, por supuesto, excelentes conductores de electrones, y la rotación del planeta produce corrientes, las cuales a su vez producen un extenso campo magnético.

Las sondas Pioneer confirmaron la existencia del campo magnético joviano y su intensidad, siendo más de 10 veces superior al terrestre conteniendo más de 20 000 veces la energía asociada al campo terrestre.
Los Pioneer descubrieron que la onda de choque de la magnetosfera joviana se extiende a 26 millones de kilómetros del planeta, con la cola magnética extendiéndose más allá de la órbita de Saturno.

Las variaciones del viento solar originan rápidas variaciones en tamaño de la magnetosfera. Este aspecto fue estudiado por las sondas Voyager. También se descubrió que átomos cargados eran expulsados de la magnetosfera joviana con gran intensidad y eran capaces de alcanzar la órbita de la Tierra. También se encontraron corrientes eléctricas fluyendo de Júpiter a algunos de sus satélites, particularmente Ío y también en menor medida Europa.

Los principales satélites de Júpiter fueron descubiertos por Galileo Galilei el 7 de enero de 1610, razón por la que se les llama satélites galileanos. Reciben sus nombres de la mitología griega si bien en tiempos de Galileo se los denominaba por números romanos dependiendo de su orden de cercanía al planeta. Originalmente, Galileo bautizó a los satélites como "Mediceos", en honor a Cosme de Médicis, duque de Florencia. El descubrimiento de estos satélites constituyó un punto de inflexión en la ya larga disputa entre los que sostenían la idea de un sistema geocéntrico, es decir, con la Tierra en el centro del universo, y la copernicana (o sistema heliocéntrico, es decir, con el Sol en el centro del sistema solar), en la cual era mucho más fácil explicar el movimiento y la propia existencia de los satélites naturales de Júpiter.

Los cuatro satélites principales son muy distintos entre sí. Ío, el más interior, es un mundo volcánico con una superficie en constante renovación y calentado por efectos de marea provocados por Júpiter y Europa. Europa, el siguiente satélite, es un mundo helado bajo el cual se especula la presencia de océanos líquidos de agua e incluso la presencia de vida. Ganímedes, con un diámetro de 5268 km, es el satélite más grande de todo el sistema solar. Está compuesto por un núcleo de hierro cubierto por un manto rocoso y de hielo. Calisto se caracteriza por ser el cuerpo que presenta mayor cantidad de cráteres producidos por impactos en todo el sistema solar.

Además de los mencionados satélites galileanos, las distintas sondas espaciales enviadas a Júpiter y observaciones desde la Tierra han ampliado el número total de satélites de Júpiter hasta 69. Estos satélites menores se pueden dividir en dos grupos:



Además de sus satélites, el campo gravitacional de Júpiter controla las órbitas de numerosos asteroides que se encuentran situados en los puntos de Lagrange precediendo y siguiendo a Júpiter en su órbita alrededor del Sol. Estos asteroides se denominan asteroides troyanos y se dividen en cuerpos griegos y troyanos para conmemorar la "Ilíada". El primero de estos asteroides en ser descubierto fue 588 Aquiles, por Max Wolf en 1906. En la actualidad se conocen cientos de asteroides troyanos. El mayor de todos ellos es el asteroide 624 Héctor.

Júpiter posee un tenue sistema de anillos que fue descubierto por la sonda Voyager 1 en marzo de 1979. El anillo principal tiene unos 6400 km de anchura, orbita el planeta a 122 800 km de distancia del centro y tiene un espesor vertical inferior a la decena de kilómetros. Su espesor óptico es tan reducido que solamente ha podido ser observado por las sondas espaciales Voyager 1 y 2 y Galileo.

Los anillos tienen tres segmentos: el más interno denominado halo (con forma de toro en vez de anillo), el intermedio que se considera el principal por ser el más brillante y el exterior, más tenue pero de mayor tamaño. Los anillos parecen formados por polvo en vez de hielo como los anillos de Saturno. El anillo principal está compuesto probablemente por material de los satélites Adrastea y Metis; este material se ve arrastrado poco a poco hacia Júpiter gracias a su fuerte gravedad. A su vez se va reponiendo por los impactos sobre estos satélites que se encuentran en la misma órbita que el anillo principal. Los satélites Amaltea y Tebas realizan una tarea similar, proveyendo de material al anillo exterior.

Las teorías de formación del planeta son de dos tipos: 

Ambos modelos tienen implicaciones muy distintas para los modelos generales de formación del sistema solar y de los sistemas de planetas extrasolares. En ambos casos los modelos tienen dificultades para explicar el tamaño y masa total del planeta, su distancia orbital de 5 ua, que parece indicar que Júpiter no se desplazó sustancialmente de la región de formación, y la composición química de su atmósfera, en particular de gases nobles, enriquecidos con respecto al Sol. El estudio de la estructura interna de Júpiter, y en particular, la presencia o ausencia de un núcleo interior permitiría distinguir ambas posibilidades.

Las propiedades del interior del planeta pueden explorarse de manera remota a partir de las perturbaciones gravitatorias detectadas por una sonda espacial cercana.

Actualmente existen propuestas de misiones espaciales para la próxima década que podrían responder a estos interrogantes.

En julio de 1994 el cometa Shoemaker-Levy 9 impactó contra la atmósfera de Júpiter. El cometa había sido disgregado por la acción de la gravedad de Júpiter en 20/22 fragmentos en un paso anterior y cercano por el planeta.

Numerosos observatorios realizaron campañas intensivas de observación del planeta con motivo de este suceso único incluyendo el telescopio espacial Hubble y la sonda Galileo que en aquel momento se encontraba acercándose todavía al planeta. Los impactos mostraron la formación de impresionantes bolas de fuego en los minutos posteriores a cada impacto de cuyo análisis se pudo deducir la masa de cada uno de los fragmentos del cometa. Los restos dejados en la atmósfera se observaron como nubes negras en expansión durante semanas propagándose como ondas de choque. Sus propiedades permitieron analizar tanto propiedades del cometa como de la atmósfera joviana y su interior profundo por métodos análogos a los de la sismología terrestre. Los restos del cometa pudieron ser detectados durante varios años en la alta atmósfera del hemisferio Sur de Júpiter, presentes como partículas finas oscuras y mediante una mayor concentración atmosférica de determinados compuestos químicos aportados por el cometa.

Se ha estimado que Júpiter, debido a su gran masa, perturba las regiones cometarias como la nube de Oort atrayendo la mayoría de los cometas que caen sobre el sistema solar interior. No obstante, también los acerca sobre sí mismo por lo que es difícil estimar la importancia que tiene Júpiter en la llegada de cometas a la Tierra.

El día 19 de julio de 2009 Anthony Wesley, un astrónomo aficionado australiano anunció el descubrimiento de una mancha negra de un tamaño similar al diámetro de la Luna que había aparecido en la atmósfera de Júpiter en la región subpolar sur. Esta mancha estaba causada posiblemente por un impacto asteroidal o cometario con el planeta. Científicos del Laboratorio de Propulsión (JPL) de Pasadena, confirmaron el impacto utilizando el telescopio infrarrojo de NASA (IRTF, NASA Infrared Telescope Facility) ubicado en la isla hawaiana de Mauna Kea.

El objeto causante del impacto, con un diámetro estimado de unos 500 metros, provocó un aumento de la temperatura en las capas altas de la atmósfera joviana en el lugar del impacto y una gran nube de partículas de polvo oscuras que forman la mancha de impacto de gran extensión y que continuó siendo observable durante varios meses de forma progresivamente más tenue al ser dispersados los restos del impacto por los vientos de la atmósfera de Júpiter. Por el momento se desconoce si el objeto que impactó con Júpiter era un asteroide o un cometa. El impacto, descubierto por casualidad, ocurrió 15 años después del impacto del cometa Shoemaker-Levy 9.

El 3 de junio de 2010, casi un año más tarde, Anthony Wesley y Christopher Go (astrónomo aficionado de Filipinas) observaron simultáneamente la aparición de un intenso flash de luz en Júpiter en una región muy localizada que se corresponde con el impacto de un cuerpo asteroidal o cometario de menor tamaño que en 2009. El flash, que duró unos pocos segundos, se produjo en latitudes ecuatoriales y por el momento no parece haber dejado ningún remanente de material observable en la atmósfera joviana.

Júpiter ha sido visitado por varias misiones espaciales de NASA desde 1973.

Las misiones Pioneer 10 y Pioneer 11 realizaron una exploración preliminar con sobrevuelos del planeta.
La sonda Pioneer 10 sobrevoló Júpiter por primera vez en la historia en diciembre de 1973. La sonda Pioneer 11 le siguió justo un año después. Se tomaron las primeras fotos cercanas de Júpiter y de los satélites galileanos, se estudió su atmósfera, se detectó su campo magnético y se estudiaron sus cinturones de radiación.
Las misiones Voyager 1 y Voyager 2 visitaron Júpiter en 1979 revolucionando el conocimiento que se tenía del planeta y sus satélites y descubriendo también su sistema de anillos. Se descubrió que Ío tenía una actividad volcánica extraordinaria y que Júpiter también poseía anillos.
En 1995 la misión Galileo, que constaba de una sonda y un orbitador, inició una misión de exploración del planeta de siete años. Aunque la misión tuvo importantes problemas con la antena principal que retransmitía los datos a la Tierra, consiguió enviar informaciones con una calidad sin precedentes sobre los satélites de Júpiter, descubriendo los océanos subsuperficiales de Europa y varios ejemplos de vulcanismo activo en Ío. La misión concluyó lanzando al orbitador contra el propio planeta para evitar una colisión futura con Europa que pudiera contaminar sus hielos.

En diciembre de 2000 la misión espacial Cassini/Huygens realizó un sobrevuelo lejano en su viaje con destino a Saturno obteniendo un conjunto de datos comparable en cantidad a los sobrevuelos realizados por las Voyager pero con una calidad de las observaciones mejor.
A finales de febrero de 2007 el planeta Júpiter fue visitado por la sonda New Horizons en su viaje a Plutón.

El 5 de julio de 2016 entró en órbita la sonda espacial Juno para estudiar la atmósfera, la magnetosfera y auroras de este planeta.

Están en estudio misiones dedicadas a la observación de Júpiter y su satélite Europa por parte de las agencias espaciales NASA y ESA.

Así como el resto de planetas más externos que la Tierra en su órbita con respecto al Sol, Júpiter puede ocupar cualquier parte de la eclíptica o encontrarse oculto detrás del Sol. No ocurre como con Venus y Mercurio, que por tener sus órbitas más cerca del Sol que la de la Tierra, solo los podemos localizar en dirección al astro. Dado su brillo, Júpiter es visible a simple vista, el cual aparece como una estrella redondeada y de color pálido, siendo el segundo planeta a simple vista más luminoso después de Venus. Con un telescopio, también se puede ver su atmósfera y sus satélites.





</doc>
<doc id="1541" url="https://es.wikipedia.org/wiki?curid=1541" title="Java">
Java

Java hace referencia a varios artículos:





</doc>
<doc id="1548" url="https://es.wikipedia.org/wiki?curid=1548" title="Jackson Day">
Jackson Day

Jackson Day, se celebra el 8 de enero en los Estados Unidos.
Este día rememora la Batalla de Nueva Orleans, la cual es un episodio de la lucha del pueblo norteamericano por lograr su independencia del gobierno británico.

En realidad, no está compuesta por una sola batalla, sino por una serie de ellas comprendidas en el período que abarca desde diciembre de 1814 hasta enero de 1815. La victoria americana en esta región forzó a los británicos a reconocer las pretensiones de los Estados Unidos de Norteamérica sobre Luisiana y la parte occidental de Florida, lo que da origen al fin de la Guerra de Independencia Americana y a la incorporación política del estado de Luisiana a la Unión. El comandante Andrew Jackson lideró las fuerzas norteamericanas durante esta campaña, llamada "del Golfo".


</doc>
<doc id="1549" url="https://es.wikipedia.org/wiki?curid=1549" title="Jamón">
Jamón

El jamón (o anca, pernil, pierna) es el nombre genérico del producto alimenticio obtenido de las patas traseras del cerdo.

En España, la preparación más habitual del jamón es salado en crudo y curado de forma natural. Las patas delanteras del cerdo, pese a tener un proceso idéntico de elaboración, reciben el nombre de "paleta" o "paletilla". También reciben el nombre de "lacón"; palabra que se aplica exclusivamente a la paleta o paletilla de cerdo. Las dos variedades más conocidas de jamón curado son el de España (jamón ibérico, jamón serrano) y el prosciutto italiano.

En diversos países latinoamericanos (como Venezuela, Colombia o México) el nombre de jamón hace referencia solamente al jamón York. 

Las primeras noticias del jamón son del Imperio romano aunque los primeros cerdos ("Sus scrofa domestica") aparecieron a inicios del Neolítico. En Tarraco se encontró un jamón fosilizado de casi dos mil años. Las razas actuales de cerdo ibérico son el producto de largos procesos de selección y adaptación a las condiciones ambientales locales; aunque tampoco se debe descartar el papel jugado por la hibridación con jabalíes.

Este producto tradicionalmente es muy consumido en España, por lo que son distintas las elaboraciones y denominaciones que de él existen. A grandes rasgos se pueden distinguir dos tipos de jamones según la raza del cerdo del que procede, sea cerdo ibérico ("jamón ibérico") o alguna variedad de cerdo blanco ("jamón" o "jamón serrano").

El jamón ibérico procede del cerdo de raza ibérica. Las principales características que lo distinguen en su calidad derivan de la pureza de la raza de los animales, de la cría en régimen extensivo de libertad del cerdo ibérico en dehesas arboladas donde puedan moverse, de la alimentación y de la curación del jamón, que suele extenderse entre los 8 a 36 meses. El jamón ibérico se distingue del resto por su textura, aroma y sabor singulares y distinguibles aunque el sabor varía según el grado de bellota que haya comido el cerdo, y del ejercicio que haya hecho.

Se clasifica generalmente según la cantidad de bellota que haya consumido antes del sacrificio. La clasificación oficial permitida para los jamones ibéricos los agrupa en: Jamón Ibérico de Cebo, Jamón Ibérico de Cebo Campo, Jamón Ibérico de Recebo y Jamón Ibérico de Bellota.

Algunas regiones con tradición de elaboración de jamones crearon, junto con el Ministerio de Medio Ambiente y Medio Rural y Marino, las Denominaciones de Origen, que exigen y controlan que los jamones ibéricos cumplan unas determinadas características para poder llevar su sello de calidad. Las denominaciones de origen reconocidas del cerdo ibérico son: Jamón Ibérico D. O.P. Jamón de Guijuelo, Jamón Ibérico D. O.P. Jabugo, Jamón Ibérico D. O. P. Los Pedroches y Jamón Ibérico D.O. Dehesa de Extremadura. Las denominaciones de origen están protegidas legalmente por el Reglamento Europeo (CE) nº 1151/2012 del Consejo de la Unión Europea. Aparte de ello existen diferentes denominaciones comerciales conocidas por el consumidor español, pero frecuentemente confundidas por su ambigüedad, como serían las de "Jamón de Pata Negra", "Jamón de Jabugo" o "Jamón 5J" o "Valderado" o "Monte Regio" o "Joselito", estas cuatro últimas son marcas de reconocido prestigio en España. Para valorar su calidad sólo existe la clasificación oficial, que además debe quedar plasmada en la etiqueta identificativa de la pieza (vitola). En cuanto a la clasificación, reglamentación y aplicación de la norma en relación al Jamón Ibérico se puede consultar el Real Decreto 1083/2001 y modificaciones posteriores.
El jamón serrano o jamón blanco procede de alguna variedad de raza de cerdo blanco, y el jamón se distingue fácilmente por el color de la piel del pernil. Se le denomina "serrano" cuando se cura en clima de sierra, frío y seco. Actualmente está regulado por el Reglamento comunitario 2082/92, en el que se definen las características del proceso y del producto terminado. Este jamón diferencia tres calidades según su curación: jamón bodega, jamón reserva y jamón gran reserva. Los hay de Almería, Granada, de Salamanca, de Ávila, y de otras muchas regiones. Entre ellas cabe destacar diferentes Denominaciones de origen como el Jamón de Teruel, el Jamón de Trevélez además de otras producciones sin denominación pero con tradición jamonera como el Jamón de chato murciano o el Jamón de cerdo Duroc.

En toda la zona noroeste de España los jamones también se curan tradicionalmente ahumados. El ahumado es un recurso que se emplea en climas húmedos, donde no se puede secar un jamón (o cualquier otro embutido) solamente al aire. También en la parte seca de Castilla, cuando un invierno resulta húmedo las producciones familiares de chacina se ahuman.

El término «"prosciutto"» se refiere a un corte de la carne del cerdo correspondiente al miembro posterior. Aunque en ocasiones puede ser cocinado o ser servido fresco. El "prosciutto" italiano posee múltiples variedades como pueden ser el "prosciutto di Parma", "prosciutto di San Daniele", "prosciutto Sardo", "prosciutto di Carpegna", "prosciutto di Modena", "prosciutto toscano", "prosciutto veneto Berico-Euganeo", "Valle d’Aosta Jambon de Bosses", "prosciutto di Norcia", "prosciutto cotto"...)






</doc>
<doc id="1550" url="https://es.wikipedia.org/wiki?curid=1550" title="Jamón serrano">
Jamón serrano

El jamón serrano es un alimento obtenido a partir de la salazón y secado al aire de las patas traseras del cerdo. Este mismo producto recibe también el nombre de paleta o paletilla cuando se obtiene de las patas delanteras. El "jamón serrano" se contrapone al jamón cocido, también llamado "jamón de York" o "jamón dulce". Se llama "serrano" por la costumbre de curar el jamón en parajes altos de las sierras, donde las bajas temperaturas facilitan la curación.

El cerdo puede ser de raza blanca o bien de la raza llamada ibérica. El jamón de este último es llamado "jamón ibérico", y "jamón de bellota" cuando este último ha ingerido cierta cantidad de bellota durante el período de montanera (engorde). El cerdo blanco no se alimenta con bellota. El jamón y las paletas de cerdo Duroc son un tipo de jamón más infiltrado y con más grasa dorsal que el jamón de cerdo blanco.

En el lenguaje ordinario —especialmente en las cartas de los restaurantes— cuando se ofrece "jamón serrano" se sobreentiende que no se trata de jamón serrano de cerdo ibérico, sino de jamón serrano de cerdo blanco, más barato. Cuando se ofrece jamón cocido o de York se sobrentiende también que se trata de cerdo blanco, pues el jamón ibérico no se suele cocer. Excepcionalmente, sin embargo, algunos establecimientos ofrecen cerdo ibérico cocido, que no ha sido curado previamente.

El jamón serrano curado tiene tres denominaciones: 

Estas denominaciones, son especificadas por el artículo 21, del Real Decreto 474/2014, de 13 de junio, por el que se aprueba la norma de calidad de derivados cárnicos.

La denominación "jamón serrano" está protegida como Especialidad Tradicional Garantizada (E.T.G.) por el Reglamento de la Unión Europea 2082/92, en el que se definen las características del proceso y del producto terminado dentro de esta denominación también hay tres categorías que tiene estipulada esta organización y que podía ser como la anterior del jamón curado de cerdo blanco "bronce para jamones de 9 a 12 meses de curación, plata para los de 12 a 15 meses y oro para los que tengan una curación superior a los 15 meses.



En Portugal se utiliza la palabra "presunto" para denominar este tipo de jamón.
En Argentina se distingue el "jamón serrano" del jamón crudo por estar el primero recubierto de pimentón y por venderse más estacionado.

En el llamado proceso de curación se pueden encontrar tres factores imprescindibles que, al conjugarse, producen una maduración ideal en los jamones.


El pH no debe ser excesivamente alto (<5.8) para minimizar el crecimiento microbiano, no deben ser carnes PSE/DFD, preferible carnes más bien grasas, bien refrigeradas o congeladas, que no tengan fracturas ni hematomas, carnes de buena calidad, baja carga microbiana inicial y preferibles piezas grandes.

La materia prima se puede recepcionar congelada o refrigerada. El peso total de los jamones en sangre tendrán un peso mínimo de 9,5 kilos para aquellos que se presenten con pata y de 9,2 kilos para los jamones sin pata. Y, por último, se tendrá en cuenta la cantidad de contenido graso.

Eliminación de partes de la musculatura, grasa y piel para conferir a las piezas las proporciones y características de redondos, biselados o cortos.

Evitar que se quede sangre retenida en el interior del jamón aplicando presión.
Puede que sea la parte más importante de todo el proceso, ya que la calidad de los jamones curados, serranos e ibéricos, se basa en la mayor o menor actuación de la sal. La salazón de los jamones ayuda en la deshidratación y juega un papel importante en la conservación (agente bacteriostático).

¿En qué consiste? Las piezas se cubren con sal marina con el fin de que ésta penetre homogéneamente en toda la masa muscular. La sal suele ser más gorda en el caso del jamón ibérico, y más fina si se trata de jamón serrano.

¿Cómo se hace? Los jamones se apilan en el suelo o en contenedores, alternando capa de sal–capa de jamón y así sucesivamente. La primera capa y la última son de sal. Como en la hilera que está abajo va a penetrar más la sal por la presión, a mitad del proceso se invierte la posición de las piezas.

La cámara de salazón se encuentra a 3-4 ºC y con una humedad relativa del 80-90%. Parece alta, pero hemos de tener en cuenta que las temperaturas son muy bajas. En definitiva, en esta fase los jamones pierden un 10% de su peso.

Su principal objetivo es la reducción de la aw (actividad de agua) para inhibir la proliferación de microorganismos y aumentar su vida útil, se lleva a cabo cubriendo las piezas en capas de sal:
El tiempo dependerá del peso en contenido graso, desde 0,65 días-2 días/kilo.
Distribución homogénea de la sal.

Cuando el jamón se saca de la pila de salazonado ya ha tomado toda la sal que va a tener hasta el final del proceso. Sin embargo, ésta se encuentra concentrada en la superficie mientras que las regiones del interior prácticamente no contienen sal. Por ello es necesario un período de postsalado o equilibramiento, donde por proceso de difusión se tiende a una distribución uniforme de la concentración salina hasta alcanzar el punto exacto de sal. La duración mínima del equilibramiento es variable y va en función del contenido graso de cada pieza ya que la penetración salina por difusión está muy condicionada por la presencia de grasa. Aunque por lo general este proceso suele tener una duración entre los 50 y 90 días. Otro factor importante es que mientras se está produciendo la penetración de sal al interior del jamón, hay un proceso de salida de agua al exterior, con la consiguiente perdida de humedad desde la superficie. Por ello, es necesario tener un estrecho control de la humedad relativa de la cámara donde se mantengan los jamones, amen del propio control de la temperatura, que desde los 5 °C iniciales ha de evolucionar hasta los 16 o 20 °C en el momento en que se les traslada al secadero natural.

Se realiza para eliminar la sal superficial, para lo cual se introducen los jamones en un recipiente en el que existen cepillos, cuyas púas por frotamiento ayudan a este proceso. Actualmente existen máquinas automáticas para efectuar el lavado y frotamiento de las piezas. 

Es importante que la sal esté limpia y que el lavado sea correcto para evitar que el depósito de la sal en el exterior del jamón inhiba el crecimiento de la flora. 
Hasta aquí, se ha hecho un buen proceso del jamón que puede servir para cualquier tipo que se elabore; ahora empiezan los problemas, ya que el jamón va a quedar expuesto, sin nada que lo proteja, dado el escaso valor antiséptico que se puede asignar a la sal a las variaciones climáticas, contaminación bacteriana, agresiones del medio ambiente, parasitismo, etc.

El lavado también se puede realizar inmediatamente después de sacar la pierna de la sal. Sí se hace esto, hay que dejar la pierna pocos días más (1,5 a 2 días por kg), para que la sal logre ingresar a los tejidos musculares. También se consigue que una vez hecho el lavado, se pueda inocular con el hongo especial, y no volver a intervenir la pierna hasta el final del proceso.

En esta etapa se trasladan los jamones a un secadero natural en el que la humedad y la temperatura se controlan principalmente mediante mecanismos de ventilación. La temperatura oscila entre los 15 º y los 30 ºC durante los 6 a 9 meses que dura el secado, la HR disminuye desde 80 % a 65 % desde 60-150 días (posible estufaje posterior: 25-35 ºC, acelera el secado). En este tiempo, el jamón continúa deshidratándose y también tiene lugar el sudado (difusión de la grasa entre las fibras musculares que permitirá retener el aroma una vez impregnadas).
El jamón sufre un procesos de proteólisis y lipólisis.

Después de una clasificación previa según su peso, calidad y conformación, los jamones y paletas pasan a la bodega donde concluye la última fase de curación, madurando lentamente. Permanecerán entre 6 y 18 meses según la clasificación anterior. En esta fase la temperatura oscila entre los 15 y 25 °C y con humedades relativas en torno al 40-65 %.

Tanto un buen secadero natural, como una buena bodega, deben permitir realizar todas estas operaciones de forma absolutamente natural, sin actuar por ningún procedimiento no consagrado por la tradición y la práctica. 
Es una cuestión de sensibilidad, pues el resultado final dependerá tanto de las características del propio secadero como de la habilidad de las gentes que en el trabajan, y que con una dedicación total y una experiencia manifiesta, han de combinar los factores de altitud, microclima, grado higrométrico, variaciones diarias de temperatura, y velocidad del aire, dirigiendo un proceso cuyo final es la obtención del jamón ibérico de bellota.


Desde el punto de vista nutricional, el proceso de modificación de sus proteínas y sus grasas durante su curación hacen del jamón un producto ligero, con más proteínas y menos grasas que el producto en fresco. Sus proteínas son de alta calidad, es decir, contiene todos los aminoácidos esenciales (100 g de jamón serrano equivalen al 33 % del consumo diario de proteínas recomendado).

Además, es un producto que no necesita colorantes. El jamón serrano es muy digestivo y sano. Contiene ácidos grasos insaturados y es un alimento rico en vitaminas B1 y B6, fósforo, hierro, potasio y zinc. De hecho, un estudio realizado por el "Centro Grand Forks de Investigación de Nutrición Humana", asegura que el serrano es muy recomendable para retrasar la aparición de la fatiga en los deportistas gracias a sus contenidos en vitaminas y minerales.

Posee un buen equilibrio de ácidos grasos, de similar naturaleza que las del aceite de oliva. Además, pese a que está curado en sal, apenas contiene este mineral.

España es el primer productor mundial de jamones y paletas curados. En 2003 superó los 41,5 millones de piezas, de las cuales el 86,5 % corresponde a jamones y el 13,5 % restante a las paletas. España es igualmente el primer consumidor con un consumo por habitante y año de 5 kg.

La Unión Europea es la zona en donde se desarrolla el mayor intercambio comercial de jamones y paletas curados. España ocupa un segundo puesto en el ranking exportador Europeo por detrás de Italia. Los países de la Unión Europea son los principales destinos de las exportaciones españolas de jamón curado. Francia, Alemania y Portugal, conjuntamente, concentran el 75,8% del volumen y el 70,6% del valor total de las expediciones.

El jamón es popular en España para comerlo como tapa en locales o en bocadillo.
Después del corte, la superficie del jamón suele cubrirse con la propia grasa para evitar que se seque. Para ello se cortan rebanadas amplias de los laterales colocándose sobre la superficie del corte "a la vista".


Real Decreto 474/2014, de 13 de junio, por el que se aprueba la norma de calidad de derivados cárnicos.

El origen del jamón - Artículo de la Guía Práctica Del Porcino MERCASA en la web de INTERPORC


</doc>
<doc id="1552" url="https://es.wikipedia.org/wiki?curid=1552" title="Juglandales">
Juglandales

Las Juglandales eran un orden de plantas de flor utilizado en el sistema Cronquist. Se consideraban cercanas a las Fagales, porque tiene flores pequeñas, unisexuales, y agrupadas en amentos (las masculinas), además presenta igual distribución de brácteas y bracteolas; periantio pequeño; gineceo supero bicarpelar y fecumdación por chalazogamia. Sin embargo las plantas más parecidas, son las Julianaceae, que están dentro de Sapindales, se diferencia de las Fagales, por las hojas siempre compuestas, y por ser siempre plantas aromáticas. Gran controversia en la interpretación de las flores y frutos. Fruto en drupa procedente de un gineceo ínfero, otros lo interpretan como semiínfero, considerando que la envuelta carnosa es un hipanto.

En las clasificaciones modernas se considera parte de las Fagales.


</doc>
<doc id="1553" url="https://es.wikipedia.org/wiki?curid=1553" title="Juglandaceae">
Juglandaceae

Juglandaceae, las Juglandáceas, son una familia del orden Fagales. Agrupa unos 8 géneros de árboles caducifolios, monoicos, resinosos y olorosos, en total, unas 50 especies, la mayoría de regiones templadas del hemisferio norte. 

La familia está compuesta por árboles –en raras ocasiones arbustos, en especies extraibéricas–, unisexuales, monoicos, rara vez dioicos, de médula sólida o perforada, generalmente ricos en taninos, a menudo con pequeñas glándulas peltadas, de color amarillo pálido–que al secarse adquieren aspecto de escamas–, y pelos fasciculados o glandulíferos. Las yemas son desnudas o protegidas por catáfilos. Las hojas son caducas, rara vez perennes, alternas –rara vez opuestas o verticiladas–, compuestas, pari- o imparipinnadas, a veces ternadas, pecioladas o sésiles, olorosas con folíolos de enteros a serrados, sin estípulas. La inflorescencia masculina está en amento, solitario o agrupados en panícula, en general lateral, erecto o péndulo, en la base de las ramas del año anterior. La inflorescencia femenina también está en el amento, con numerosas flores y péndulo, o en racimo con pocas flores y erecto, al menos en la fructificación, terminal en las ramas del año –inflorescencia rara vez en panícula andrógina, con el amento central, espiciforme, con todas las flores femeninas (o solo algunas) y los laterales. Las flores masculinas son de brácteas enteras o trilobuladas, soldadas al pedicelo y más o menos soldadas al receptáculo; hay de 0 a 2 bractéolas, soldadas al pedicelo y más o menos soldadas al receptáculo y sépalos, de tal forma que todo el conjunto parecen partes del cáliz. El receptáculo es más o menos plano, corto o alargado; el cáliz tiene 0-4 sépalos, soldados al receptáculo y, en su caso, a brácteas y bractéolas, con 0-4 lóbulos apicales, más o menos irregulares; los estambres, en número de (2)3-50, son sésiles o casi, de anteras glabras o pubescentes dehiscentes longitudinalmente,; el polen tiene 3-9(-16)-poros y es foraminado o rugado; el gineceo es vestigial o inexistente. Las flores femeninas, de brácteas enteras o trilobuladas, y 2(3) bractéolas enteras o más o menos dentadas o lobuladas, todas soldadas solo a la base o hasta el ápice del receptáculo y cáliz; el receptáculo es más o menos cónico u ovoide y el cáliz tiene normalmente 4 sépalos –a veces inexistente–, soldados al receptáculo y, en su caso, a brácteas y bractéolas, normalmente con 4 dientes o lóbulos apicales, más o menos irregulares; los estambres están de ordinario inexistentes, rara vez con algunos vestigiales; el ovario es ínfero, unilocular en la parte superior, y con 2, 4(8) lóculos en la base; los carpelos de 2 –rara vez 3-4 en algunas flores–, están soldados y el estilo tiene 2-4 ramas estilares, a veces muy cortas con estigmas a lo largo de las ramas estilares o solo en su ápice, a veces pequeños y subglobosos; el primordio seminal es de placentación axilar. El fruto en nuez, en el cual, a lo largo de la maduración, normalmente la bráctea o bractéolas y en ocasiones los sépalos crecen, y además a veces engrosan, formando una estructura especializada con 1-3 alas (fruto samaroide); o la cáscara (fruto drupáceo, trima), indehiscente o dehiscente de forma más o menos irregular–, más o menos pétrea, bivalva, con 2, 4(8) lóculos en la base. Hay una sola semilla, en general sin endospermo, relativamente grande, con cotiledones cuadrilóbulados separados por un tabique normal a las 2 valvas y a su sutura.

"Engelhardtia", "Platycarya"); sin. Engelhardtiaceae Reveal & Doweld, Platycaryaceae Doweld


</doc>
<doc id="1554" url="https://es.wikipedia.org/wiki?curid=1554" title="Juan de la Cierva">
Juan de la Cierva

Juan de la Cierva y Codorníu (Murcia, España, 21 de septiembre de 1895-Croydon, Reino Unido, 9 de diciembre de 1936) fue un inventor y científico aeronáutico español, ingeniero de caminos, canales y puertos y aviador. Inventó el autogiro, aparato precursor del actual helicóptero.

Hijo del abogado criminalista, político y empresario Juan de la Cierva y Peñafiel, que llegó a ser ministro en varias ocasiones y alcalde de Murcia, y de María Codorníu Bosch. Su abuelo materno fue el destacado ingeniero de montes Ricardo Codorníu. Desde su infancia destacó su interés por el mundo de la aviación, y junto a su amigo Tomás de Martín-Barbadillo construyó pequeños modelos capaces de volar.

Al estallar la Guerra Civil, de la Cierva ayudó a las fuerzas sublevadas para que éstas consiguieran el avión De Havilland DH.89 Dragon Rapide en el que el general Franco voló desde Gando (islas Canarias) a Tetuán (Marruecos español) para tomar el mando del ejército del norte de África. Su hermano Ricardo fue fusilado por milicias republicanas en Paracuellos del Jarama.

En 1954 le fue otorgado, con carácter póstumo, el título de conde de la Cierva.

Junto con dos compañeros, José Barcala, antiguo compañero de estudios, y Pablo Díaz, hijo de un carpintero, fundó la sociedad B.C.D., cuyas siglas correspondían con las iniciales de sus tres apellidos, que fue pionera en el desarrollo aeronáutico dentro de España, y gracias a su capacidad, en 1912, contando sólo con dieciséis años, Juan de la Cierva logró construir y hacer volar un avión biplano, que recibió la designación BCD-1, y fue apodado "el Cangrejo", con piloto (el francés Mauvais) y pasajero a bordo.

Mientras que el avión es una aeronave de alas fijadas al fuselaje, el autogiro inventado por de la Cierva tiene alas fijadas a un rotor. El autogiro hace su irrupción en el panorama de la aviación sólo veinte años después de la invención de los hermanos Wright.

Juan de la Cierva construyó en Madrid en 1920 su primer autogiro, el Cierva C.1, utilizando fuselaje, ruedas y estabilizador vertical de un monoplano francés Deperdussin de 1911, sobre el que montó dos rotores cuatripalas contrarrotatorios coronados por una superficie vertical destinada a proporcionar control lateral; la planta motriz era un motor Le Rhône de 60 hp. El aparato no llegó a volar, pues el rotor inferior giraba a menos velocidad de la prevista, y el efecto giroscópico y la asimetría de la sustentación hicieron volcar el aparato. A este primer autogiro siguieron dos construcciones también fallidas, el C.2 y el C.3, en las que el inventor intentó, infructuosamente, resolver el problema de la diferencia de sustentación entre la pala que avanza y la que retrocede. Sin embargo, en las pruebas del C.2 se consiguieron algunos saltos de unos dos metros, lo que apuntaba a la viabilidad del invento. La -. de la sustentación del rotor no se resolvería plenamente hasta el prototipo C.4, en el que la Cierva incluyó su revolucionaria idea de articular las palas del rotor en su raíz.

Los primeros ensayos del modelo C.4, construido en 1922 conforme a los nuevos principios, fueron infructuosos. Para su definitiva resolución, la Cierva realizó una completa serie de ensayos en el túnel de viento de circuito cerrado del aeródromo de Cuatro Vientos (obra de Emilio Herrera), por aquel entonces el mejor de Europa. El nuevo aparato corregido se probó exitosamente en enero de 1923 en el aeródromo de Getafe pilotado por el teniente Alejandro Gómez Spencer. Aunque dicho vuelo consistió únicamente en un «salto» de 183 m, demostró la validez del concepto. A finales del mes, el C.4 recorrió en cuatro minutos un circuito cerrado de 4 km en el aeródromo de Cuatro Vientos, cerca de Madrid, a una altura de unos 30 m. La planta motriz del C.4 era un motor Le Rhône 9Ja de 110 hp. En julio de 1923 se utilizó el mismo motor en el C.5, que voló en Getafe. A partir de ese momento, de la Cierva, que había financiado a sus expensas sus experimentos anteriores, contó para sus trabajos con una subvención del gobierno español. 

En 1926, con el apoyo financiero de James George Weir, industrial y aviador escocés, creó en el Reino Unido la sociedad Cierva Autogiro Company para el desarrollo del autogiro, produciendo varios modelos en ese país.

Falleció el 9 de diciembre de 1936 con cuarenta y un años de edad, al estrellarse en el despegue, en el aeropuerto de Croydon, el Douglas DC-2 de KLM en vuelo regular Londres-Ámsterdam en el que viajaba.

Desde el año 2001 el Ministerio de Educación y Ciencia de España otorga el Premio Nacional de Investigación Juan de la Cierva dedicado a la transferencia de tecnología. El objetivo de los Premios Nacionales de Investigación es el reconocimiento de los méritos de los científicos o investigadores españoles que realizan «una gran labor destacada en campos científicos de relevancia internacional, y que contribuyan al avance de la ciencia, al mejor conocimiento del hombre y su convivencia, a la transferencia de tecnología y al progreso de la Humanidad».

Además del premio nacional de investigación que lleva su nombre, en 2004 el Ministerio de Educación y Ciencia de España inició un programa de contratación de investigadores doctores bajo el nombre de Programa Juan de la Cierva, gracias al cual centenares de investigadores españoles y extranjeros desarrollan su actividad.

La memoria de Juan de la Cierva se mantiene viva en varias ciudades con las que tuvo relación: 






</doc>
<doc id="1555" url="https://es.wikipedia.org/wiki?curid=1555" title="Juego">
Juego

Un juego se define como la actividad que realiza uno o más jugadores, empleando su imaginación o herramientas para crear una situación con un número determinado de reglas, con el fin de proporcionar entretenimiento o diversión. Existen juegos competitivos, donde los jugadores tienen que lograr un objetivo, y juegos no competitivos, donde los jugadores buscan simplemente disfrutar de la actividad. Los juegos normalmente se diferencian de los trabajos por el objeto de su realización. Sin embargo, en muchos casos estos no tienen una diferencia demasiado clara. Asimismo, el juego se utiliza como herramienta educativa, pues en la mayoría de los casos funcionan estimulando habilidades prácticas y psicológicas. Dentro de la clasificación del juego encontramos uno muy importante que es el juego simbólico , pues es donde los niños empiezan a tener su aprendizaje y a trabajar su socialización. También un juego es considerado un ejercicio recreativo sometido al concurso de reglas.

La primera referencia sobre juegos que existe es del año 3000 a. C. Los juegos, son considerados como parte de una experiencia humana y están presentes en todas las culturas. Probablemente, las cosquillas, combinadas con la risa, sean una de las primeras actividades lúdicas del ser humano, al tiempo que una de las primeras actividades comunicativas previas a la aparición del lenguaje.

El juego es una actividad inherente al ser humano. Dado que el juego viene antes de la cultura humana no es exclusiva de los humanos, ya que desde antes los animales también juegan.

Etimológicamente, los investigadores refieren que la palabra juego procede de dos vocablos en latín: "iocum y ludus-ludere" ambos hacen referencia a broma, diversión, chiste, y se suelen usar indistintamente junto con la expresión actividad lúdica.

Se han enunciado innumerables definiciones sobre el juego, así, el diccionario de la Real Academia lo contempla como un ejercicio recreativo sometido a reglas en el cual se gana o se pierde.
Sin embargo la propia polisemia de este y la subjetividad de los diferentes autores implican que cualquier definición no sea más que un acercamiento parcial al fenómeno lúdico. Se puede afirmar que el juego, como cualquier realidad sociocultural, es imposible de definir en términos absolutos, y por ello las definiciones describen algunas de sus características. Entre las conceptualizaciones más conocidas apuntamos las siguientes:

En conclusión, estos y otros autores como Roger Caillois, Moreno Palos, etc., incluyen en sus definiciones una serie de características comunes a todas las visiones, de las que algunas de las más representativas son:

Actualmente, al igual que con la definición de juego, existen infinidad de concepciones de deporte según el autor que se tome como referencia: Coubertain, Demeny, Cagigal, Parlebas, García Ferrando, etc.
Realizando también otra síntesis de estos autores podríamos definir deporte y diferenciarlo del simple juego de la siguiente manera:

El deporte es un conjunto de situaciones motrices e intelectuales que se diferencia del juego en que busca la competición con los demás o consigo mismo, en que precisa unas reglas concretas y en que está institucionalizado.


El juego es útil y es necesario para el desarrollo del niño en la medida en que este es el protagonista.

La importancia de la utilidad del juego puede llevar a los adultos a robar el protagonismo al niño, a querer dirigir el juego. La intervención del adulto en los juegos infantiles debe consistir en:


El juego permite al niño:


El juego siempre hace referencia implícita o explícita a las relaciones entre infancia, diversión y educación.

El juego es una actividad que tiene el fin en sí misma, es decir, el individuo realiza la propia actividad para conseguir el objetivo que es ser placentera. El juego tiene un carácter de finalidad intrínseca y es liberador de los conflictos, ya que ignora los problemas o los resuelve.
Una de sus principales características es la sobremotivación, la cual, pretende hacer de una actividad ordinaria una actividad de motivación suplementaria.
El juego temprano y variado contribuye positivamente a todos los aspectos del crecimiento y está vinculado a las cuatro dimensiones básicas del desarrollo infantil que son el psicomotor, el intelectual, el social y finalmente el afectivo-emocional.

Funciones del juego infantil:





El juego social es una conducta sumamente corriente en la práctica totalidad de los mamíferos y algunas aves. Los mamíferos juegan para aprender. De hecho la principal función del juego es aprender. Los mamíferos se caracterizan por un cerebro evolucionado, infancia larga, cuidado parental, amamantamiento de las crías, cacería en grupo, división social y no genética de trabajo. Los mamíferos juegan a cazar en grupo, definir jerarquías, explorar, dividirse el trabajo, entre otros. El juego entre los mamíferos (caninos, felinos, acuáticos, primates) se basa en la imitación y en la exploración por ensayo y error. En los mamíferos hay una ausencia total de juego simbólico.

El juego simbólico se hace sobre representaciones y no sobre cosas reales. Las pinturas rupestres son el primer ejemplo de ¨juego¨ simbólico. Los hombres prehistóricos las utilizaban para actuar sobre los animales a través de sus representaciones. El juego simbólico está claramente presente todos los niños normales a partir de los 2 años de edad. El juego simbólico está presente cuando un niño toma una piedra y juega con ella como si fuera un carro. Este niño está jugando con el carro, no con la piedra.

Los chimpancés y otros primates tienen la capacidad de utilizar representaciones, pueden por ejemplo usar algunas palabras, pero no aparece en ellos ninguna forma de juego simbólico. El juego de los chimpancés tiene las mismas características que el de todos los mamíferos. La aparición del juego simbólico se presenta exclusivamente en los niños, junto con el lenguaje —intrínsecamente simbólico—.

El ser humano puede profundizar y divertirse más en el juego gracias a nuestro lóbulo frontal (también llamado neo-cortex) que es donde se encuentra la imaginación , el juego, el arte , matemáticas etc, lo cual nos diversifica de los demás mamíferos que también juegan y de algunos parientes ya extintos como el neandertal que como no tenían el lóbulo frontal tan desarrollado lo cual producía que no tuvieran una capacidad de resolución de problemas rápida 

En los seres humanos, luego de la aparición de juego simbólico, hacia los 2 años, comienza una etapa de juego social, en el que los niños juegan cada vez más entre sí y con los adultos, utilizando el lenguaje. Este juego social requiere cada vez más el establecimiento de acuerdos y finalmente termina en el juego formal, cuya característica esencial es que es un juego con reglas muy claras. Los juegos de canicas (bola uña) son un excelente ejemplo de juegos infantiles con reglas, hacia los 6 años de edad. Esto no desaparece gracias a la neotemia que es la capacidad de una especie de conservar rasgos de la infancia en la adultez , lo cual nos deja seguir divirtiendonos como niños En la historia de la especie humana es probable que el juego formal aparezca luego de la sedentarización resultado de la agricultura y la escritura. En el juego formal el objeto del juego son las reglas en sí mismas, no las representaciones. Gracias a esta capacidad para establecer reglas y jugar dentro de ellas la especie ha podido construir ¨juegos¨ claves como la democracia, la religión y la ciencia. Crear juegos con reglas es la esencia de la evolución de la civilización. A partir de los 5 años los niños pueden utilizar reglas para manipular los objetos, interactuar socialmente o para generar conocimiento, los tres usos fundamentales del juego y de las reglas.

Los juegos populares están muy ligados a las actividades del pueblo llano, y a lo largo del tiempo han pasado de padres a hijos. De la mayoría de ellos no se conoce el origen: simplemente nacieron de la necesidad que tiene el hombre de jugar, es decir, se trata de actividades espontáneas, creativas y muy motivadoras.

Su reglamento es muy variable, y puede cambiar de una zona geográfica a otra con facilidad; incluso pueden ser conocidos con nombres diferentes según donde se practique.

Los juegos populares suelen tener pocas reglas y normalmente sencillas, y en ellos se utiliza todo tipo de materiales, sin que tengan que ser específicos del propio juego. Todos ellos tienen sus objetivos y un modo determinado de llevarlos a cabo: perseguir, lanzar un objeto a un sitio determinado, conquistar un territorio, conservar o ganar un objeto, etc.
Su práctica no tiene una trascendencia más allá del propio juego, no está institucionalizado, y el gran objetivo del mismo es divertirse.

Con el tiempo, algunos se han ido convirtiendo en un apoyo muy importante dentro de las clases de Educación Física, para desarrollar las distintas capacidades físicas y cualidades motrices, o servir como base de otros juegos y deportes.

Los juegos populares pueden servir como herramienta educativa en el aula en diversas materias ya que en sus retailas, canciones o letras se observa características de cada una de las épocas. Esta tipología puede ser una estrategia divertida en la que las personas que los realizan aprenden al mismo tiempo que se divierten.

Son juegos más solemnes que también han sido transmitidos de generación en generación, pero su origen se remonta a tiempos muy lejanos.

No solamente han pasado de padres a hijos, sino que en su conservación y divulgación han tenido que ver mucho las instituciones y entidades que se han preocupado de que no se perdieran con el paso del tiempo.
Están muy ligados a la historia, cultura y tradiciones de un país, un territorio o una nación. Sus reglamentos son similares, independientemente de donde se desarrollen.

El material de los juegos es específico de los mismos, y está muy ligado a la zona, a las costumbres e incluso a las clases de trabajo que se desarrollaban en el lugar.

Sus practicantes suelen estar organizados en clubes, asociaciones y federaciones.
Existen campeonatos oficiales y competiciones más o menos regladas.

Algunos de estos juegos tradicionales con el tiempo se convirtieron en deportes, denominados tradicionales, de modo que la popularidad que tienen entre los habitantes de un territorio o país compite con la popularidad de otros deportes convencionales.
Algunos ejemplos: la petanca, el chito, los bolos, la rana, etc.

Entre estos, podríamos encontrar juegos que con el tiempo se han convertido en verdaderos deportes ligados a una región, y que solo se practican en ella, llegando a formar parte de las tradiciones culturales. El origen de los juegos y deportes tradicionales está ligado al propio origen de ese pueblo, por ello, los denominan "juegos o deportes autóctonos". Algunos ejemplos son: la Lucha canaria, el silbo, el palo canario, la soga tira, la pelota mano, el lanzamiento de barra, etc.

Los juegos infantiles exteriores se encuentran en parques o centros recreativos, estos juegos tienen la tarea de ser duraderos, divertidos, resistentes y sobre todo seguros debido al público al que van dirigidos, los cuales son niños menores de 10 años en su mayoría.

Estos existieron a partir de la necesidad de tener un entretenimiento más activo y seguro para los niños pequeños donde puedan entretener varios niños a la vez.

La mezcla de materiales es por lo general metal y plástico, pero dependiendo del diseño temático podría incluir otros materiales como madera así como los colores que este pudiera contener.

Una de las ventajas más notables de estos juegos se encuentran:
Estos juegos infantiles pueden tener la combinación de pequeñas resbaladillas así como columpios y otros aditamentos como red para escalar, túneles, etc.

Su tamaño y componentes dependerán siempre del tema bajo el que este diseñado. El principal objetivo de este juego es brindar la seguridad necesaria y la diversión deseada. Es por eso que su diseño debe ser funcional, atractivo para los niños y sobre todo resistente pero no solo a los niños sino también a los factores naturales tales como lluvia, vientos, granizos donde su estructura tiene que mantenerse sin daños graves y sobre todo sin grietas por impactos o resequedad por su larga exposición al sol.

Así los juegos infantiles tienen garantía de que gracias a su calidad y diseño prometen duran varios años y brindar diversión a una gran cantidad de niños sin importar que tanto uso ellos le puedan dar y resistiendo las inclemencias del clima.

Los juegos con tablero, que utilizan como herramienta central un tablero en donde se sigue el estado, los recursos y el progreso de los jugadores usando símbolos físicos. Muchos también implican dados o naipes. La mayoría de los juegos que simulan batallas son de tablero, y este puede representa un mapa en el cual se mueven de forma simbólica los contendientes. Algunos juegos, como el ajedrez y el go son enteramente deterministas, basados solamente en la estrategia. Los juegos infantiles se basan en gran parte en la suerte, como la Oca, en el que apenas se toman decisiones, mientras que el parchís ("parqués" en Colombia, "ludo" en Chile), es una mezcla de suerte y estrategia. El Trivial es aleatorio en tanto que depende de las preguntas que cada jugador consiga.
Los juegos de mesa, son antiguos o tradicionales, pero son considerados de la nueva época o actuales debido a que han ido mejorando su diseño, complementaciones y características.

Los juegos de naipes utilizan como herramienta central una baraja. Esta puede ser española, de 40 ó 48 naipes o francesa de 52 cartas, y depende del juego el uso de una u otra. También hay algunos juegos de magia que utilizan naipes.

Los videojuegos son aquellos que controla un ordenador o computadora, que pueden crear las herramientas virtuales que se utilizarán en un juego, como naipes o dados o elaborados mundos que se pueden manipular.

Un videojuego utiliza unos o más dispositivos de entrada, bien una combinación de teclas y joystick, teclado, ratón, trackball o cualquier otro controlador. En los juegos de ordenador el desarrollo del juego depende de la evolución de las interfaces utilizadas.

A veces, hay una carencia de metas o de oposición, que ha provocado una discusión sobre si estos se deben considerar "juegos" o "juguetes".

Con la conexión a Internet han aparecido nuevos juegos; algunos necesitan un cliente mientras que otros requieren solamente un navegador. El juego de ordenador se ha distribuido por todos los sectores sociales, transformando la forma tradicional de jugar.

Los juegos de rol son un tipo de juego en el que los participantes asumen el papel de los personajes del juego. En su origen el juego se desarrollaba entre un grupo de participantes que inventaban un guion con lápiz y papel. Unidos, los jugadores pueden colaborar en la historia que implica a sus personajes, creando, desarrollando y explorando el escenario, en una aventura fuera de los límites de la vida diaria. Uno de los primeros juegos de rol en ser comercializados fue "Dungeons & Dragons".

Los juegos cooperativos son juegos en los cuales dos o más jugadores no compiten, sino más bien se esfuerzan por conseguir el mismo objetivo y por lo tanto ganan o pierden como un grupo. En otras palabras, son juegos donde grupos de jugadores pueden tomar comportamientos cooperativos, pues los juegos son una competición entre "coaliciones" de jugadores más que entre jugadores individuales. Es como un juego de coordinación, donde los jugadores escogen las estrategias por un proceso de toma de decisiones consensuadas.

El universo del juego popular/tradicional es tan versátil que origina numerosos y distintos intentos de clasificación. Entre las muchas formas de clasificación, queremos destacar en primer lugar la tipología de:

Los juegos pueden clasificarse según otro criterio, y fueron los griegos los que definieron cuatro tipos de juegos de los cuales salieron diversas variables a lo largo de la historia.

Estos cuatro grupos de juegos pueden situarse entre dos extremos, denominados “continuum”: son los conceptos de “paidia” (manifestaciones espontáneas del instinto lúdico) y “ludus” (una evolución de paidia en la que parecen convenciones y técnicas de actuación).

Es pionero en España su trabajo en 1974 sobre los juegos populares y deportes tradicionales de la península. En su estudio bibliográfico hace una clasificación pormenorizada en la que se distinguen las siguientes categorías:


Profesor del INEF de Madrid de la asignatura de Juegos y deportes populares, elaboró en 1992 la siguiente clasificación basada fundamentalmente en criterios asociados al ámbito de la educación física:
Clasifica en 2002 los juegos y deportes populares de Casilla León tomando como base los criterios utilizados por Moreno Palos, distinguiendo:

Revisando de forma crítica estas clasificaciones, afirma en 1996 que la complejidad morfológica y estructural del juego (popular-tradicional) se pone de manifiesto en los numerosos intentos de agrupación.

En la mayoría de las ocasiones las clasificaciones se construyen a partir de criterios superficiales, formales, sin elegir elementos realmente pertinentes y constitutivos de su estructura interna.

Estos criterios morfológicos, debido a las múltiples formas en que puede desarrollarse el juego, presentan excesivas categorías heterogéneas. En este sentido, una de las clasificaciones mostradas por Moreno Palos así lo demuestra. Por eso es preciso construir nuevas propuestas objetivas y rigurosas, edificadas sobre bases teóricas justificables. En esta línea tan solo Pierre Parlebas propone en 1986 algunos criterios objetivos, aunque no se centran de forma específica en clasificar los juegos populares y tradicionales.




</doc>
<doc id="1556" url="https://es.wikipedia.org/wiki?curid=1556" title="Juncaginaceae">
Juncaginaceae

Las juncagináceas (nombre científico Juncaginaceae) son hierbas perennes, acuáticas o palustres, de distribución cosmopolita pero de hábitats principalmente costeros. La familia es reconocida por sistemas de clasificación modernos como el sistema de clasificación APG III (2009) y el APWeb (2001 en adelante). Las juncagináceas se diferencian de otras familias por poseer hojas más o menos unifaciales, una inflorescencia en racimo o espiga, con escapo, y flores con todas sus piezas libres entre sí. 

La familia fue reconocida por el APG III (2009), el Linear APG III (2009) le asignó el número de familia 37. La familia ya había sido reconocida por el APG II (2003).

Los géneros, según el APWeb:


Sinónimos según el APWeb: Heterostylaceae Hutchinson, Lilaeaceae Dumortier, Maundiaceae Nakai, Triglochinaceae Chevalier



</doc>
<doc id="1557" url="https://es.wikipedia.org/wiki?curid=1557" title="Juncaceae">
Juncaceae

Las juncáceas (nombre científico Juncaceae) forman una familia de plantas monocotiledóneas parecidas a los pastos, con hojas lineales que poseen vaina y lámina pero no tienen lígula, inflorescencias normalmente condensadas en glomérulos terminales y se diferencian de los pastos porque las flores poseen tépalos obvios, las hojas son trísticas, y los frutos son cápsulas. Han colonizado todos los ambientes en especial los de las zonas templadas, y se polinizan por viento.

El nombre de la familia fue utilizado en sistemas de clasificación modernos como el sistema de clasificación APG III (2009) y el APWeb (2001 en adelante) en los que es asignado al clado ciperáceas-juncos del orden Poales. En la familia se encuentran los juncos y afines. La importancia económica es limitada, algunas son utilizadas como ornamentales, algunas utilizadas para tejer canastas o sillas.

Hábito: Hierbas, perennes (raramente anuales), sin cuerpos de sílice, cuando perennes usualmente sus tallos son rizomatosos, redondos y macizos.

Hojas alternas, espiraladas, usualmente trísticas (raramente dísticas), bifaciales o unifaciales (más o menos redondeadas, sin reconocer dos lados), basales o a lo largo de la porción más baja del tallo, delgadas, compuestas por vaina (hojas envainadoras) y lámina, la vaina usualmente abierta, la lámina simple, sin dividir, de margen entero, con venación paralela, lineal, plana o cilíndrica. Usualmente con aurículas. Con o sin lígula. Sin estípulas.

Inflorescencias básicamente determinadas, terminales, muy ramificadas, pero usualmente condensadas en un glomérulo, o también pueden ser de flores solitarias, o compuestas por 1-muchas cimas. 

Flores usualmente hermafroditas, pero ocasionalmente unisexuales (entonces plantas dioicas), inconspicuas, regulares, bracteadas, hipóginas.

6 tépalos dispuestos en 2 verticilos (raramente 3 en 1 verticilo, o 4 en 2 verticilos), separados, imbricados, generalmente de color verde, rojo-marrón o negro, pero a veces blancos o amarillentos, escariosos (delgados y como escamas), sin hipanto. Los tépalos externos y los internos están separados.

Androceo con 6 estambres en 2 verticilos (o a veces 3 estambres en 1 verticilo, o 4 en 2 verticilos), diplostémonos cuando en 2 verticilos (el verticilo externo opuesto a los tépalos externos y el interno a los tépalos internos), filamentos separados entre sí y de los tépalos. Anteras basifijas, de dehiscencia longitudinal.

Polen monoporado, en tétradas obvias.

Gineceo súpero, tricarpelar, carpelos connados, 3 o 1 lóculo, con placentación axilar o parietal (ocasionalmente basal), estilo usualmente en 3 ramas, 3 estigmas usualmente elongados, a veces retorcidos. óvulos numerosos (raramente 3 o 1), anátropos, bitégmicos. 

No hay nectarios.

El fruto es una cápsula loculicida (raramente indehiscente).

3 a numerosas semillas, con endosperma con almidón.

Familia cosmopolita, mayormente de regiones templadas y montanas. Muchas veces en hábitats húmedos, pero hay notables excepciones, como "Juncus trifidus". 

Las inconspicuas flores de Juncaceae son predominantemente polinizadas por viento, comúnmente el entrecruzamiento es favorecido por la protandria (en la misma planta las flores masculinas maduran antes), pero algunas especies son autopolinizadas. También puede haber especies polinizadas por insectos.

La dispersión de las pequeñas semillas la produce el viento, el agua, o también pueden ser transportadas por los animales en forma externa (sin consumirlas).

La monofilia de Juncaceae está sostenida por secuencias ITS (Kristiansen "et al." 2005, Roalson 2005), y por análisis de una combinación de genes (Jones "et al." 2007). La monofilia de Juncaceae no estuvo clara hasta hace poco, aun cuando ya se sabía que debía excluirse de ella a "Prionium" (ahora en Thurniaceae). Dos estudios encontraron que Juncaceae no era monofilética, ya que "Oxychloe" fue encontrado como embebido en Cyperaceae, o hermano del resto de Cyperaceae, por Plunkett "et al." 1995, y Muasya "et al." 1998. Según Soltis "et al." (2005), lo que debe haber pasado en los análisis de Plunkett "et al." (1995) y Muasya "et al." (1998), es que el primero puede haber utilizado una colección de hojas que era una mezcla de "Oxychloe" con una ciperácea, y casi seguramente secuenciaron la ciperácea, mientras que en el último la muestra debe haber estado contaminada.

No está claro cuál de los caracteres de la familia es sinapomórfico, muchos son caracteres generalizados en las monocotiledóneas. 

Juncaceae, Cyperaceae y Thurniaceae comparten dos caracteres que pueden ser sinapomorfías: las hojas trísticas y el polen en tétradas. Las 3 familias forman el clado ciperáceas-juncos, ver Poales para una discusión de este clado.

Análisis filogenéticos recientes (Drábková "et al." 2003, Roalson 2005) indican que "Juncus" no es monofilética, de él se desprendieron "Luzula" y un grupo de plantas de los Andes ("Oxychloë" y "Distichia"). El hecho de que "Juncus" es glabro sugiere que esta condición puede ser una sinapomorfía de la familia (aún si fuera homoplásica).

Muchos miembros de esta familia lucen superficialmente como pastos, pero las hojas trísticas, las flores con tépalos obvios, y los frutos capsulares hacen la distinción clara. En algunas especies de "Juncus", la larga bráctea debajo de la inflorescencia está vuelta hacia arriba de forma de parecer una continuación del tallo, y la inflorescencia parece lateral.

La familia fue reconocida por el APG III (2009), el Linear APG III (2009) le asignó el número de familia 98. La familia ya había sido reconocida por el APG II (2003).

6 géneros, cerca de 400 especies. Los géneros más representados son "Juncus" (300 especies) y "Luzula" (80 especies).

Lista de géneros y sus sinónimos, según el APWeb (visitado en enero de 2009): 


"Prionium" ahora pertenece a Thurniaceae.

La importancia económica es limitada.

"Juncus effusus" y "J. squarrosus" son usados para hacer canastas y sillas. 

Unas pocas especies de "Juncus" y "Luzula" son utilizadas como ornamentales.

"Distichia" es utilizada como combustible en Perú.



</doc>
<doc id="1558" url="https://es.wikipedia.org/wiki?curid=1558" title="Juego L">
Juego L

El juego L es un juego abstracto para dos jugadores creado por Edward de Bono en 1972. Se juega con un tablero de 4 x 4 casillas, una pieza en forma de L de dimensiones 3x2 para cada jugador y 2 piezas neutrales que no pertenecen a ninguno de ambos, pero que pueden ser movidas por cualquiera de los dos.

Cada jugador, por turnos, debe mover su pieza L hacia una nueva posición. La pieza puede levantarse, girarse, o volverse del revés y luego colocarse otra vez sobre el tablero en cualquier lugar o posición. Se considera que una posición es nueva si por lo menos una de las casillas cubiertas es diferente. La pieza puede colocarse en cualquier lugar del tablero siempre que cubra una configuración exacta de cuadros no ocupados por ninguna otra pieza. Después de mover la pieza L, el jugador puede, si lo desea, mover una cualquiera de las piezas neutrales a cualquier casilla desocupada.

El objeto del juego es forzar al oponente a una posición desde la cual no puede mover más. Se gana la partida cuando el oponente no puede cambiar la posición de su pieza L (Ésta debe moverse siempre antes de tocar ninguna pieza neutral).



</doc>
<doc id="1559" url="https://es.wikipedia.org/wiki?curid=1559" title="Juglans">
Juglans

Juglans es un género de árboles caducifolios llamados comúnmente nogales, de la familia de las juglandáceas. Lo componen una veintena de especies aceptadas, de las 150 descritas.

El término en latín "Juglans" deriva de "Jovis glans", "bellotas de Júpiter": figuradamente, una nuez apropiada para un dios.

Árboles –rara vez arbustos, en especies extraibéricas–, monoicos. Ramillas de médula perforada. Yemas terminales sésiles, con algunos catafilos en disposición valvar, densamente hirsutos. Hojas caducas, alternas, imparipinnadas; lámina, pecíolo y raquis con glándulas peltadas –que al secarse adquieren aspecto de escamas–; foliolos 5-31, de margen serrado o entero, con pelos no glandulíferos simples o fasciculados, a veces glabros; raquis áptero; peciólulos muy cortos o inexistentes. Inflorescencia masculina en amento, solitario –a menudo superpuestos–, lateral, sésil, péndulo. Inflorescencia femenina en racimo, de (1)2-25 flores, solitario, terminal, erecto en la fructificación. Flores masculinas de bráctea soldada al receptáculo excepto en el ápice, que es pequeño, ovado o lanceolado y entero; bractéolas 2, soldadas al receptáculo y a los sépalos, de ordinario algo más grandes que éstos y externos, de tal forma que en el conjunto hay hasta 6 lóbulos más o menos desiguales –en algunos casos hasta 8(-16); los adicionales se supone que son divisiones de los ápices calicinos–; sépalos 1-4; estambres 7-85(105); anteras glabras o escasamente pelosas. Flores femeninas de bráctea soldada al receptáculo excepto en el ápice, que es pequeño y entero; bractéolas 2, soldadas al receptáculo excepto en el ápice, que es más o menos dentado o lobulado; sépalos 4, soldados al receptáculo en más de 2/3 de su longitud; carpelos 2 –rara vez y en algunas flores 3-4–; estilo normalmente con 2 ramas estilares, recurvadas, con la zona estigmática hacia el interior. Fruto drupáceo (trima); epicarpio/mesocarpio rugoso o liso, indehiscente o dehiscente de forma más o menos irregular (tras la fructificación acaba secándose, se hace correosa y se desprende); nuez de pared más o menos pétrea, rugosa o áspera, con 2 o 4 lóculos en la base. Semillas de cotiledones carnosos, con 2 lóbulos cada uno.

Las veintena de especies aceptadas del género se distribuyen por todas las regiones septentrionales frías desde la Europa sudoriental hasta el este del Japón y más ampliamente en el continente americano, desde el sudeste de Canadá hasta el oeste de California y el sur de Argentina.

El género "Juglans" se divide en cuatro secciones.





El miembro más conocido del género es el nogal común ("J. regia", literalmente "nogal real"), originario de los Balcanes en el sudeste de Europa, sudoeste y centro de Asia hasta el Himalaya y el sudoeste de China. Las nueces son un rasgo tradicional de la cocina iraní; la nación tiene amplios huertos de frutales que son un importante elemento de la economía regional. Tan sólo en Kirguistán hay 230.700 hectáreas de bosques de nogales, donde "J. regia" es el piso dominante (Hemery y Popov 1998). 

El nogal negro americano ("J. nigra") es una especie común en su originario Este de Norteamérica, y también se cultiva ampliamente en otros lugares. Las nueces son comestibles, pero tienen un núcleo más pequeño y una cáscara extremadamente dura, y no se cultivan mucho para la producción de nueces. La madera es particularmente valiosa.

"Juglans hindisii" procede del norte de California, donde se ha usado comercialmente como una sustituta de los nogales comunes. Sus cáscaras no tienen profundas grietas que son características del nogal negro americano.

El "nogal de Japón" ("Juglans ailantifolia") es parecido al nogal blanco "(Juglans cinerea)", pero se distingue por tener hojas más grandes de hasta 90 cm de largo, y unas nueces redondeadas, no ovales. 

El nogal blanco ("J. cinerea") también es originario del este de Norteamérica, donde actualmente es una especie en peligro por una enfermedad causada por el hongo "Sirococcus clavigignenti". Sus hojas tienen 40–60 cm de largo, los frutos son ovalados, la cáscara muy alta, con bordes muy delgados, y el núcleo es especialmente alto en grasa.


Un estudio de ADN nuclear secuenciado del External Transcribed Spacer (ETS) de DNA ribosomal (rDNA), el Internal Transcribed Spacer (ITS) de rDNA, y el segundo intron del gen LEAFY tomado de al menos un individuo de la mayor parte de las especies de "Juglans" ha apoyado varias conclusiones:







En el informe sobre estos resultados no se publicó ningún nombre nuevo para las subdivisiones de las secciones  "Rhysocaryon", para cualquier combinación de las otras secciones, o para "J. olanchana" var. "standleyi".

Las dos especies comerciales más importantes son "J. regia" para madera y nueces, y "J. nigra" para madera. Ambas especies tienen similares exigencias de cultivo y son ampliamente cultivadas en zonas templadas.

Los nogales son especies heliófitas (que exigen luz) y se benefician de la protección contra el viento. También son muy resistentes a la sequía.

Las plantaciones de nogales, denominadas nocedales, con plantas que fijen el nitrógeno como "Elaeagnus × ebbingei" o "Elaeagnus umbellata", y varias especies de "Alnus" incrementan en un 30% la altura y grosor de los árboles (Hemery 2001).

Cuando los cultivos se dedican a la obtención de nueces, se deben seleccionar cultivares compatibles para propósitos de polinización; aunque algunos cultivares se venden como "auto-fértiles" generalmente fructificarán mejor con un compañero de polinización diferente. Existen muchos cultivares diferentes disponibles para los cultivadores que ofrecen diversos hábitos de crecimiento, florecimiento y hojas, sabor del fruto y grosor de la cáscara.



</doc>
<doc id="1560" url="https://es.wikipedia.org/wiki?curid=1560" title="Jürgen Habermas">
Jürgen Habermas

Jürgen Habermas /ˈjʏʁɡn̩ ˈhaːbɐmaːs/ (Düsseldorf, 18 de junio de 1929) es un filósofo y sociólogo alemán, conocido sobre todo por sus trabajos en filosofía práctica (ética, filosofía política y del derecho). Gracias a una actividad regular como profesor en universidades extranjeras, especialmente en Estados Unidos, así como por la traducción de sus trabajos más importantes a más de treinta idiomas, sus teorías son conocidas, estudiadas y discutidas en el mundo entero. Habermas es el miembro más eminente de la segunda generación de la Escuela de Frankfurt y uno de los exponentes de la Teoría crítica desarrollada en el Instituto de Investigación Social. Entre sus aportaciones destacan la construcción teórica de la acción comunicativa y la democracia deliberativa .

Jürgen Habermas estudió filosofía, historia, psicología, literatura alemana y economía en las universidades de Gotinga, Zürich y Bonn. Nicolai Hartmann, Wilhelm Keller, Theodor Litt, Johannes Thyssen, Hermann Wein, y fueron algunos de sus profesores durante los estudios de licenciatura. En 1954, bajo la dirección de los dos últimos profesores citados, defendió en la Universidad de Bonn su tesis doctoral sobre el tema «El Absoluto y la historia: De las discrepancias en el pensamiento de Schelling», que aún hoy en día se mantiene inédita. Entre sus compañeros de estudios, trabó amistad con Karl-Otto Apel, una fructífera relación intelectual que se mantiene hasta el presente.

Con anterioridad, en 1953, publicó su primer artículo: una recensión crítica de la obra de Heidegger "Introducción a la metafísica", que tituló significativamente «Pensar con Heidegger contra Heidegger» ("Mit Heidegger gegen Heidegger denken"), artículo que le proporcionó una cierta notoriedad. En los siguientes años se ganaría la vida mediante colaboraciones con la prensa.

De 1954 a 1959 fue ayudante y colaborador de Adorno en el Instituto de Investigación Social de Fráncfort. En 1960 defendió en Marburgo (bajo la dirección de Wolfgang Abendroth) su escrito de habilitación, centrado en las transformaciones estructurales de la noción de «esfera pública» ("Öffentlichkeit") a lo largo de la historia europea de los últimos tres siglos. Entre 1964 y 1971 ejerció como catedrático en la Universidad de Fráncfort, convirtiéndose en uno de los principales representantes de la segunda generación de la Teoría Crítica. En 1968 publicó "Conocimiento e interés", libro que le concedió una enorme proyección internacional.

De 1971 a 1983 fue director en el Instituto Max Planck para la «investigación de las condiciones de vida del mundo técnico-científico». En 1983 volvió a la Universidad de Fráncfort como catedrático de filosofía y sociología, donde permaneció hasta su jubilación en 1994. Se mantiene, no obstante, activo como docente, especialmente en calidad de «Permanent Visiting Professor» de la Northwestern University (Evanston, Illinois) y como «Theodor Heuss Professor» de The New School (Nueva York).

En 1986, recibió el Premio Gottfried Wilhelm Leibniz de la Deutsche Forschungsgemeinschaft, considerado como la máxima distinción en el ámbito alemán de investigación. En 2001 obtuvo el Premio de la Paz que conceden los libreros alemanes y en 2003, el Premio Príncipe de Asturias de Ciencias Sociales.

Es doctor "honoris causa" por las universidades, entre otras, de Jerusalén, Buenos Aires, Hamburgo, Northwestern University Evanston, Utrecht, Tel Aviv, Atenas y la New School for Social Research de Nueva York, y miembro de la Academia Alemana de la Lengua y la Poesía.

Si bien su pensamiento entronca con la Teoría Crítica de la Escuela de Fráncfort, su obra adopta perfiles propios que le conducen a profundas divergencias con sus maestros y predecesores. Su trabajo está orientado a poner los fundamentos de la teoría social con los que busca analizar las sociedades del capitalismo avanzado.

El pensamiento de Kant tiene un destacado lugar en la obra de Habermas, y el de Karl Marx desempeña un papel decisivo. El estrecho vínculo entre una filosofía de la razón muy ambiciosa en términos normativos y una teoría empírica de la sociedad es una característica del pensamiento de Marx que Habermas hace suya y que lo distingue de otros contemporáneos y, en particular, del sociólogo Niklas Luhmann y del filósofo John Rawls, con quienes, no obstante, comparte preocupaciones comunes.

La integración de filosofía y ciencia social en una teoría crítica de la sociedad es el rasgo distintivo de la obra habermasiana. Aunque Habermas se vale del concepto filosófico de razón y lo emplea explícitamente en términos de filosofía del lenguaje, lo hace para poder desarrollar una teoría social. Se apoya en la idea de una completa transformación de la crítica del conocimiento en crítica de la sociedad. De ahí que resulte unilateral entender a Habermas como mero filósofo de la fundamentación argumentativa y de la ética discursiva.

Su primera gran obra fue su escrito de habilitación (1962), traducido al español como "Historia y crítica de la opinión pública". En este análisis de la transformación estructural de la esfera pública se aproxima de forma crítica al concepto de opinión pública y recupera la visión eminentemente democrática del mismo, con su distinción entre opinión pública manipulada y opinión pública crítica.

En algunas de sus obras posteriores, Habermas tratará de reconstruir el materialismo histórico frente a las nuevas problemáticas de las sociedades del capitalismo tardío. En este sentido, la gran crítica que realizará a Karl Marx será que éste, en su opinión, reduce la praxis humana a una "techné", en el sentido de que Marx le otorga la importancia fundamental al trabajo como eje de la sociedad, en demérito del otro componente de la praxis humana que Habermas rescata como esencial: la interacción mediada por el lenguaje.

A diferencia de Marx, Habermas entiende que el cambio social debe darse en un ámbito simbólico, en el ámbito de la comunicación y el entendimiento entre los sujetos. De este modo, esta crítica se asemeja a la reflexión que realizan Theodor Adorno y Max Horkheimer. Luego de este momento inicial, Habermas repensará esta distinción entre trabajo e interacción como dos momentos irreductibles de la acción y tratará de incluir en la labor productiva (el trabajo) componentes de la interacción, por lo que dirá que es posible pensar un cambio social desde el campo del trabajo.

Habermas considera que existen tres crisis: la crisis de las filosofías de base teológica o metafísica, la crisis de la legitimación del Estado contemporáneo y la crisis del positivismo jurídico. Para superarlas, propone la teoría de la acción comunicativa, con base en la filosofía práctica de Kant, y en la que plantea, no imponer una ley, sino proponer una teoría con aspiración universal.

A partir de la publicación en 1981 de su obra fundamental, la "Teoría de la acción comunicativa", sus análisis y reflexiones se han orientado hacia la fundamentación de la ética discursiva, la defensa de la democracia deliberativa y de los principios del Estado de derecho, así como hacia las bases normativas requeridas para configurar e incluso constitucionalizar una esfera pública mundial.








</doc>
<doc id="1563" url="https://es.wikipedia.org/wiki?curid=1563" title="Jota">
Jota

Jota puede referirse a:





</doc>
<doc id="1564" url="https://es.wikipedia.org/wiki?curid=1564" title="Jota (música)">
Jota (música)

La jota es una danza y cante español extendido por gran parte de la geografía de España.

Varía según las regiones, aunque la jota de Aragón, la jota castellana, la jota manchega, la de León, la de la Comunidad Valenciana, la de Navarra, la de La Rioja, la «montañesa» de Cantabria, la de Asturias, la de Galicia, la de Extremadura, la de la Alta Andalucía y la de Murcia son quizás las más conocidas y populares. Entendida como representación escénica, la jota se canta y se baila acompañándose de castañuelas y los intérpretes suelen ir vestidos con trajes regionales. En Valencia, antiguamente, se bailaba la jota en la ceremonia de los entierros. También se bailaba —y se baila— en Cataluña, y especialmente en la zona de las Tierras del Ebro (Amposta, Tortosa, etc) y en el Campo de Tarragona (jota fogueada). También en Canarias las jotas y rondallas con características peculiares eran la parte del folclore más destacada, hoy día un tanto desplazadas por la protección hacia otros estilos más autóctonos. No obstante, en las islas existe la isa, una pieza musical que deriva de la jota. En Filipinas, los religiosos españoles trasmitieron la jota a los tagalos, que la interpretan en rondallas y acompañada de instrumentos nativos. Las variedades de jota de Aragón, La Rioja y Navarra están emparentadas entre sí y forman las llamadas Jotas del Ebro, siendo unas de las más características de este género. Se celebran concursos y certámenes de jotas del Ebro por todo el territorio español. 

Su nombre proviene del antiguo "xota", este del mozárabe "*šáwta", salto, y este deriva del latín "saltāre", bailar. Algunas teorías dicen que este baile nació en Valencia, proveniente de la palabra en valenciano antiguo "xotar" (botar o saltar), que pasó al castellano como «jota».

Existen documentos escritos que hablan de la jota como baile muy generalizado en el Reino de Valencia en los siglos XIV, XV, XVI, XVII y primera mitad del siglo XVIII (no se ha encontrado ningún documento anterior que hable de la jota ni en Aragón ni en el conjunto de España y la jota aragonesa aparece a finales del siglo XVIII). Destaca un cuadro pintado de la inauguración del Palacio Real, Al-Munia en árabe, que fue construido en 1009 por el rey de Balansiya Abd-Al-Aziz . Para el arabista Henri Péres en el cuadro se ve a hombres y mujeres bailando una jota.

Si la jota nació en Valencia es lógico pensar que los jornaleros de Requena, Utiel y sus comarcas, que bajaban a la Ribera del Júcar a la siega del arroz a finales de septiembre y a la comarca de Lliria y las tierras del Turia a la siega de la alfalfa, del cereal y la cebolla, a su regreso comentaran maravillados el baile que habían visto y que se llamaba jota. Esta danza se extendió por Requena, Utiel y sus comarcas, y seguramente estos mismos jornaleros fueron los que empezaron a transmitirla cuando subían a la siega del cereal a los Reinos de Aragón y de Navarra.

Su ritmo suele ser compaseado en 3/4, aunque algunos autores sostienen que el 6/8 se adapta mejor a la estructura del ciclo coreográfico y estrófico. Las armonizaciones populares más habituales se ciñen a acordes de primera, cuarta y quinta del modo mayor con séptima dominante. Para su interpretación se utilizan guitarras, bandurrias y laúdes. Acordeón en el caso de la navarra, riojana y aragonesa, dulzaina y tamboriles en la castellana, y en el caso de la cántabra, asturiana y gallega gaitas, pitu montañés, panderetas, tambores y bombo. Las versiones de exhibición se cantan y bailan con trajes regionales y castañuelas, lo que no es tan habitual cuando es practicada como diversión o baile social. El contenido de las canciones es muy diverso, desde el patriotismo, hasta la religión o las picardías sexuales. Prevalecen aquellas que tienen utilidad como generadoras de cohesión en el pueblo que las baila.

Los pasos que ejecutan los danzantes se parecen a los del vals, aunque en el caso de la jota hay mucha más variación. La letra, en cuanto a la forma, suele escribirse en cuartetos octosílabos, siendo asonantes el primer y el tercer versos.

Un buen número de compositores no españoles han utilizado el estilo de la jota en obras de inspiración española:

La jota aragonesa es la más conocida de las manifestaciones del folclore musical de Aragón. Su origen podría estar hacia finales del siglo XVIII, y tuvo su mayor esplendor durante el siglo XIX, adquiriendo gran auge tras la Guerra de la Independencia. Desde finales del siglo XIX ha sido llevada a los escenarios como espectáculo. La jota fue incluida en zarzuelas, películas, coreografiada para grandes festivales, y llevada a concursos y certámenes.

La jota aragonesa incluye tanto por baile como canto y rondalla.

El baile lo hacen mujeres y hombres de todas las edades, desde niños de 3 años hasta personas de avanzada edad. Posee gran dificultad sobre todo en los pasos. Se suelen bailar jotas de tres coplas, boleros, fandangos y todo ello se baila en parejas formando diferentes figuras grupales.

El canto es habitualmente solista, aunque también se puede cantar a dúo, compuesto por una voz que lleva la melodía y otra que lleva la octava, también llamada dúo. Se canta a modo grupal como pueden ser boleros, fandangos estribillos y cantos de bodega compuesto por hombres y mujeres. Respecto en el baile, los cantadores acompaña a los bailadores según el tema instrumental y por ello se forma un grupo de bailadores y cantadores que se adecúan al estilo musical. Los cantadores cantan las jotas comprendidas en los tonos mayores y menores desde do hasta si.

En cuanto a la formación de la rondalla no hay límite de edad, puede entrar cualquiera que tenga un mínimo de base musical y ganas de emprender. Las rondallas suelen estar formadas por los instrumentos más reconocibles como la guitarra, la bandurria, el laúd y el guitarrico (este se usa más para rondas), aparte también se pueden introducir nuevos instrumentos a esta formación como el bajo eléctrico, la viola o el contrabajo. La rondalla juega un papel importante pero a la vez muy discreto, se encargan de acompañar a los bailadores en las jotas de baile y a los cantadores en sus jotas tanto solistas, como a dúo o grupales. Las variaciones normalmente son populares aunque también se pueden crear de nueva composición para otras jotas por variar un poco. 

Los estilos de baile, llamados puros, por haberse conservado hasta nuestros días, son los correspondientes a las localidades de Calanda, Alcañiz, Andorra, Albalate del Arzobispo, Huesca, y Zaragoza. Hoy en día existen infinidad de coreografías modernas realizadas por y para los grupos folclóricos, jotas que han sido rescatadas. Entre las más populares en los repertorios se encuentran: "Jota de San Lorenzo" (Huesca), "Jota Repetida "(Teruel), "Jota vieja", "Aragón tierra bravía", "Gigantes y cabezudos", "La Dolores" (estas últimas pertenecen a las zarzuelas del mismo nombre), "la danza de la Olivera", etc.

Muy importantes son también, otros bailes muy relacionados con la jota, como los boleros del siglo XVIII, destacando el de Alcañiz, el de Caspe, y el de Sallent de Gállego, que aunque hoy en día están muy influidos por la jota, en su día gozaron de gran popularidad, y se bailaban acompañados de dulzainas y tambores, como en la Jota Hurtada de Albarracín. Otras danzas singulares, eran la Gitanilla de Andorra, con cintas, hoy coreografiada como Danza de Andorra, la danza de los pañuelos de Remolinos, o las danzas decimonónicas del Pirineo, tales como el Cadril, el Villano, la Canastera o el Tin tan.

Entre los cantantes destacan las figuras de grandes joteros como Pedro Nadal «el Royo del Rabal», Mariano Malandía «el Tuerto de las Tenerías», Juanito Pardo, Cecilio Navarro, Jesús Gracia, José Iranzo Bielsa «el Pastor de Andorra» y del admirado José Oto, considerado el más importante «cantador» de jota aragonesa. Entre las voces femeninas se pueden señalar las de Asunción Delmás, Pilar Gascón, Jacinta Bartolomé, Pascuala Perié, Felisa Galé, Pilar de las Heras o María Blasco.

La jota castellana (tanto la de la parte castellana de Castilla y León, como la de Madrid y la castellano-manchega) se suele acompañar con guitarras, bandurrias, laúdes, dulzaina y tambor.

En Cataluña, la jota es parte del folklore tradicional de las tierras occidentales de la comunidad, y especialmente de las llamadas "Tierras del Ebro". La primera referencia escrita conocida es una condena por parte del obispo de Tortosa, de 1734, si bien se refiere a Calaceite, localidad aragonesa vecina a Cataluña. En los últimos tiempos se ha revalorizado este género musical en la comunidad gracias sobre todo al grupo tortosino "Quico el Célio, el Noi i el Mut de Ferreries"; el gobierno autonómico declaró en 2010 la jota "danza de interés nacional en Catalunya".

Extremadura conserva gran número de bailes y danzas tradicionales autóctonas. Las jotas toman en Extremadura gran variedad de formas y matices, también sobresale el fandango, la rondeña, la jota del triángulo, las paleos, el pindongo, el perantón, sones brincaos y sones llanos.

Los Instrumentos utilizados son la flauta de tres agujeros, la gaita extremeña y tamboril, guitarra, bandurria, laúd, rabel, acordeón, pandero, violín y otros instrumentos de percusión como almireces, castañuelas, sonajas, morteros, cencerros, botella de anís...

Jota de la uva (Olivenza, Badajoz)

En el caso de la jota leonesa es más frecuente el acompañamiento con gaita o flauta de tres agujeros y tamboril. Todo mientras la pareja de bailarines danza manteniendo las manos encima de la cabeza, ocasionalmente acompañados de castañuelas. Estos tipos de jotas se bailan con los característicos pasos saltados, un poco picadas, y son más sobrias y menos movidas y airosas que la de Aragón. La música va frecuentemente acompañada por canciones que reciben el nombre de coplas. Estas a veces tratan del amor, de las bodas (en las que se daban consejos y alabanzas a los novios), de la vida o de su religiosidad, pero casi siempre se caracterizan por su picaresca y gran sentido del humor.

La jota manchega, típica del lugar, tiene como característica propia que tiene rasgos de ronda. A muchas jotas manchegas se las conoce por «Jota del Mantecado», ya que era frecuente cantarlas y bailarlas en fechas cercanas a la Navidad (y también en otras fechas señaladas).

Se denomina jota montañesa a la variedad interpretada en algunas zonas de Cantabria, también conocida como baile "a lo altu y a lo baju" o "a lo ligeru y a lo pesau". Antiguamente interpretada al son de la pandereta para posteriormente entrar el pitu (clarinete en mi bemol) y tambor. En la actualidad se ha incorporado la gaita.

Junto con la aragonesa conforman las famosas jotas del Ebro. Los joteros y joteras de este tipo de cante visten con pantalón o falda blanca, alpargatas blancas con cintas rojas, faja roja, camisa blanca y pañuelo rojo.
Las letras de las canciones son versos populares, en algunos de los casos referidos a temas del día a día tradicional de las personas por los que fueron compuestas. Un ejemplo son las jotas a la vendimia o cantos a Navarra o a La Rioja en sí misma. Otros temas son los familiares, del campo, de tono satírico, de los ciclos agrícolas o del amor y desamor. Se cantaban en las fiestas populares o por los labradores para amenizar las faenas del campo. Normalmente la parte instrumental de la actuación está protagonizada por una rondalla o a veces por instrumentos de viento como la gaita de bota riojana o la dulzaina navarra, tocada en ambas regiones. También muy frecuentemente por un acordeón.

Existen escuelas de jota a lo largo de todo el valle del Ebro a su paso por La Rioja y Navarra, y también es muy popular en Miranda de Ebro, Tudela, entre otras muchas. Se realizan diversos concursos de este arte que es uno de los máximos exponentes de la cultura de esta zona.

El formato habitual consta de 4 versos de los cuales se repiten 3 para llegar a un total de 7 en este orden a, b, a, c, d, d, b. Ejemplo:

El más famoso jotero de la historia de la jota navarra fue Raimundo Lanas. Otros joteros de renombre son Faico y Josefina, Julián Arina, Hermanas Flamariqué Hermanos Anoz o Molviedro. Habitualmente se organizan en agrupaciones de joteros, y son los más conocidos Alma Navarra (con sus versiones de «No te vayas de Navarra», «Pamplona, perla del norte» o «himno de Osasuna»), Navarra Canta o Montaña y Ribera, entre otros muchos grupos. En el caso de la jota riojana cabe mencionar varios intérpretes y compositores de este estilo musical como Pepe Blanco , Teo Echaure , Purita Ugalde "La Riojanita", Antonio García, Ángel Sáez-Benito, Oscar Alesanco o Fidel Ibarra, que actuó ante el Rey Alfonso XIII en 1903 durante su primera visita a la capital riojana y composiciones como "Riojano de pura cepa" (1880), el pasodoble-jota "En la Rioja nací" (1957) , "La jota de Logroño" (1910) , "En la Rioja los riojanos" (1945), "En La Rioja no hay tranvía" (1953) etc... Este estilo musical también tuvo su repercusión en los teatros. Así sucedió con la zarzuela en obras como "El postillón de La Rioja" (1851), de autores no riojanos, que incluye una jota riojana en el primer acto, en "Cameranas" (1933) de José Eizaga" o en "La Riojana" (1898) de Florencio Bello. La jota riojana debido a su especificidad y singularidad ha sido declarada como bien de interés cultural de carácter inmaterial. Actualmente existen grupos que interpretan tanto jota navarra como riojana, por ejemplo "Voces del Ebro".

La jota valenciana recuerda a los bailes de salón por sus candenciosos movimientos.
Muchos pueblos tienen su jota, como la "valenciana" , la "Jota Vallera" (Vall de Uxó), la "cofrentina", la "moixentina" (Mogente), "del postiguet", "la de Carlet o u i dos", "la de Villena", etc.

Existe un patrimonio formado por 9 géneros distintos de música para el baile con sus variantes musicales y coreográficas. Todo ello, sin contar los bailes de plaza, ni las danzas rituales.










También existe una variante de la jota en la región del Chocó, Colombia, que ha sido estudiada por el musicólogo Andrés Pardo Tovar.





</doc>
<doc id="1565" url="https://es.wikipedia.org/wiki?curid=1565" title="Joint Photographic Experts Group">
Joint Photographic Experts Group

Joint Photographic Experts Group (JPEG), traducido al español como Grupo Conjunto de Expertos en Fotografía, es el nombre de un comité de expertos que creó un estándar de compresión y codificación de archivos e imágenes fijas. Este comité fue integrado desde sus inicios por la fusión de varias agrupaciones en un intento de compartir y desarrollar su experiencia en la digitalización de imágenes. La ISO, tres años antes (abril de 1983), había iniciado sus investigaciones en el área.

Además de ser un método de compresión, es a menudo considerado como un formato de archivo. JPEG/Exif es el formato de imagen más común, utilizado por las cámaras fotográficas digitales y otros dispositivos de captura de imagen, junto con JPG/JFIF, que también es otro formato para el almacenamiento y la transmisión de imágenes fotográficas en la World Wide Web. Estas variaciones de formatos a menudo no se distinguen, y se llaman “JPEG”. Los archivos de este tipo se suelen nombrar con la extensión codice_1.

El formato JPEG utiliza habitualmente un algoritmo de compresión con pérdida para reducir el tamaño de los archivos de imágenes, esto significa que al descomprimir o visualizar la imagen no se obtiene exactamente la misma imagen de la que se partía antes de la compresión. Existen también tres variantes del estándar JPEG que comprimen la imagen sin pérdida de datos: JPEG 2000, JPEG-LS y Lossless JPEG. 

El algoritmo de compresión JPEG se basa en dos fenómenos visuales del ojo humano: uno es el hecho de que es mucho más sensible al cambio en la luminancia que en la crominancia; es decir, capta más claramente los cambios de brillo que de color. El otro es que nota con más facilidad pequeños cambios de brillo en zonas homogéneas que en zonas donde la variación es grande; por ejemplo en los bordes de los cuerpos de los objetos.

Una de las características del JPEG es la flexibilidad a la hora de ajustar el grado de compresión. Un grado de compresión muy alto generará un archivo de pequeño tamaño, a costa de una pérdida significativa de calidad. Con una tasa de compresión baja se obtiene una calidad de imagen muy parecida a la del original, pero con un tamaño de archivo mayor.

La pérdida de calidad cuando se realizan sucesivas compresiones es acumulativa. Esto significa que si se comprime una imagen y se descomprime, se perderá calidad de imagen, pero si se vuelve a comprimir una imagen ya comprimida se obtendrá una pérdida todavía mayor. Cada sucesiva compresión causará pérdidas adicionales de calidad. La compresión con pérdida no es conveniente en imágenes o gráficos que tengan textos, líneas o bordes muy definidos, pero sí para archivos que contengan grandes áreas de colores sólidos.

Muchas de las opciones del estándar JPEG se usan poco. Esto es una descripción breve de uno de los muchos métodos usados comúnmente para comprimir imágenes cuando se aplican a una imagen de entrada con 24 bits por pixel (ocho por cada rojo, verde, y azul, o también dicho "8 bits por canal"). Esta opción particular es un método de compresión con pérdida.

Comienza convirtiendo la imagen desde su modelo de color RGB a otro llamado YUV o YCbCr. Este espacio de color es similar al que usan los sistemas de color para televisión PAL y NTSC, pero es mucho más parecido al sistema de televisión (Componentes Analógicas Multiplexadas).

Este espacio de color (YUV) tiene tres componentes:

Las ecuaciones que realizan este cambio de base de RGB a YUV son las siguientes:

Las ecuaciones para el cambio inverso se pueden obtener despejando de las anteriores y se obtienen las siguientes:

Si se analiza el primer trío de ecuaciones veremos que las tres componentes toman como valor mínimo el 16. El canal de luminancia (canal Y) tiene como valor máximo el 235, mientras que los canales de crominancia el 240. Todos estos valores caben en un byte haciendo redondeo al entero más próximo. Durante esta fase no hay pérdida significativa de información, aunque el redondeo introduce un pequeño margen de error imperceptible para el ojo humano.

Una opción que se puede aplicar al guardar la imagen es reducir la información del color respecto a la de brillo (debido al fénomeno visual en el ojo humano comentado anteriormente). Hay varios métodos: si este paso no se aplica, la imagen sigue en su espacio de color YUV (este submuestreo se entiende como ), con lo que la imagen no sufre pérdidas. Puede reducirse la información cromática a la mitad, (reducir en un factor de 2 en dirección horizontal), con lo que el color tiene la mitad de resolución (en horizontal) y el brillo sigue intacto. Otro método, muy usado, es reducir el color a la cuarta parte, , en el que el color se reduce en un factor de 2 en ambas direcciones, horizontal y vertical. Si la imagen de partida estaba en escala de grises (blanco y negro), puede eliminarse por completo la información de color, quedando como 4:0:0.

Algunos programas que permiten el guardado de imágenes en JPEG (como el que usa GIMP) se refieren a estos métodos con "1×1,1×1,1×1" para YUV 4:4:4 (no perder color), "2×1,1×2,1×1" para YUV 4:2:2 y "2×2,1×1,1×1" para el último método, YUV 4:2:0.

Las técnicas algorítmicas usadas para este paso (para su reconstrucción exactamente) suelen ser interpolación bilineal, vecino más próximo, convolución cúbica, Bezier, b-spline y Catmun-Roll.rh

Cada componente de la imagen se divide en pequeños bloques de 8×8 píxeles, que se procesan de forma casi independiente, lo que disminuye notablemente el tiempo de cálculo. De esto resulta la típica formación cuadriculada, que se vuelve visible en las imágenes guardadas con alta compresión. Si la imagen sufrió un submuestreo del color, los colores quedarían en la imagen final en bloques de 8×16 y 16×16 píxeles, según fuese 4:2:2 o 4:2:0.

Después, cada pequeño bloque se convierte al dominio de la frecuencia a través de la transformación discreta de coseno, abreviadamente llamada DCT.

Un ejemplo de uno de esos pequeños bloques de 8×8 inicial es este:

El siguiente proceso es restarles 128 para que queden números entorno al 0, entre -128 y 127.

Se procede a la transformación por DCT de la matriz, y el redondeo de cada elemento al número entero más cercano.

Nótese que el elemento más grande de toda la matriz aparece en la esquina superior izquierda; este es el coeficiente DC.

El ojo humano es muy bueno detectando pequeños cambios de brillo en áreas relativamente grandes, pero no cuando el brillo cambia rápidamente en pequeñas áreas (variación de alta frecuencia). Debido a esta condición, se puede eliminar las altas frecuencias, sin pérdida excesiva de calidad visual. Esto se realiza dividiendo cada componente en el dominio de la frecuencia por una constante para ese componente, y redondeándolo a su número entero más cercano. Este es el proceso en el que se pierde la mayor parte de la información (y calidad) cuando una imagen es procesada por este algoritmo. El resultado de esto es que los componentes de las altas frecuencias, tienden a igualarse a cero, mientras que muchos de los demás, se convierten en números positivos y negativos pequeños.

Una matriz de cuantificación típica es la matriz de Losheller que se usa opcionalmente en el estándar JPEG:

Dividiendo cada coeficiente de la matriz de la imagen transformada entre cada coeficiente de la matriz de cuantificación, se obtiene esta matriz, ya cuantificada:

Por ejemplo, cuantificando el primer elemento, el coeficiente DC, sería así:

La codificación entrópica es una forma especial de la compresión sin pérdida de datos. Para ello se toman los elementos de la matriz siguiendo una forma de zig-zag, poniendo grupos con frecuencias similares juntos, e insertando ceros de codificación, y usando la codificación Huffman para lo que queda. También se puede usar la codificación aritmética, superior a la de Huffman, pero que rara vez se usa, ya que está cubierta por patentes, esta compresión produce archivos un 5% menores, pero a costa de un mayor tiempo de codificación y decodificación, esta pequeña ganancia, puede emplearse también en aplicar un menor grado de compresión a la imagen, y obtener más calidad para un tamaño parecido.

En la matriz anterior, la secuencia en zig-zag, es esta:
−26, −3, 0, −3, −2, −6, 2, −4, 1 −4, 1, 1, 5, 1, 2, −1, 1, −1, 2, 0, 0, 0, 0, 0, −1, −1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0

JPEG tiene un código Huffman para cortar la cadena anterior en el punto en el que el resto de coeficientes sean ceros, y así, ahorrar espacio:
−26, −3, 0, −3, −2, −6, 2, −4, 1 −4, 1, 1, 5, 1, 2, −1, 1, −1, 2, 0, 0, 0, 0, 0, −1, −1, EOB

El resultado tras la compresión, puede variar, en función de la agresividad de los divisores de la matriz de cuantización, a mayor valor de esos divisores, más coeficientes se convierten en ceros, y más se comprime la imagen. Pero mayores compresiones producen mayor ruido en la imagen, empeorando su calidad. Una imagen con una fuerte compresión (1%-15%) puede tener un tamaño de archivo mucho menor, pero tendrá tantas imperfecciones que no será interesante, una compresión muy baja (98%-100%) producirá una imagen de muy alta calidad, pero, tendrá un tamaño tan grande que quizás interese más un formato sin pérdida como PNG.

La mayoría de personas que naveguen por Internet estarán familiarizadas con estas imperfecciones, que son el resultado de lograr una buena compresión. Para evitarlas, se tendrá que reducir el nivel de compresión o aplicar compresión sin pérdida, produciendo mayores ficheros después.

El proceso de decodificación es similar al seguido hasta ahora, sólo que de forma inversa. En este caso, al haber perdido información, los valores finales no coincidirán con los iniciales.

Se toma la información de la matriz, se decodifica, y se pone cada valor en su casilla correspondiente. Después se multiplica cada uno de estos valores por el valor correspondiente de la matriz de cuantización usada, como muchos valores son ceros, sólo se recuperan ( y de forma aproximada) los valores de la esquina superior izquierda.

Después se deshace la transformación DCT:

Y finalmente se suma 128 a cada entrada:

Para comparar las diferencias entre el bloque original y el comprimido, se halla la diferencia entre ambas matrices, la media de sus valores absolutos, da una ligera idea de la calidad perdida:

Se puede observar que las mayores diferencias están cerca de la mancha, y por la parte inferior, entre la esquina izquierda y el centro, notándose más esta última, ya que corre una mancha clara que antes estaba más hacia la esquina. La media de los valores absolutos de las restas es 4.8125, aunque en algunas zonas es mayor.




</doc>
<doc id="1568" url="https://es.wikipedia.org/wiki?curid=1568" title="JavaScript">
JavaScript

JavaScript (abreviado comúnmente JS) es un lenguaje de programación interpretado, dialecto del estándar ECMAScript. Se define como orientado a objetos, basado en prototipos, imperativo, débilmente tipado y dinámico.

Se utiliza principalmente en su forma del lado del cliente ("client-side"), implementado como parte de un navegador web permitiendo mejoras en la interfaz de usuario y páginas web dinámicas aunque existe una forma de JavaScript del lado del servidor(Server-side JavaScript o SSJS). Su uso en aplicaciones externas a la web, por ejemplo en documentos PDF, aplicaciones de escritorio (mayoritariamente widgets) es también significativo.

Desde el 2012, todos los navegadores modernos soportan completamente ECMAScript 5.1, una versión de javascript. Los navegadores más antiguos soportan por lo menos ECMAScript 3. La sexta edición se liberó en julio del 2015.

JavaScript se diseñó con una sintaxis similar a C, aunque adopta nombres y convenciones del lenguaje de programación Java. Sin embargo, Java y JavaScript tienen semánticas y propósitos diferentes.

Todos los navegadores modernos interpretan el código JavaScript integrado en las páginas web. Para interactuar con una página web se provee al lenguaje JavaScript de una implementación del Document Object Model (DOM).

Tradicionalmente se venía utilizando en páginas web HTML para realizar operaciones y únicamente en el marco de la aplicación cliente, sin acceso a funciones del servidor. Actualmente es ampliamente utilizado para enviar y recibir información del servidor junto con ayuda de otras tecnologías como AJAX. JavaScript se interpreta en el agente de usuario al mismo tiempo que las sentencias van descargándose junto con el código HTML.

Desde el lanzamiento en junio de 1997 del estándar ECMAScript 1, han existido las versiones 2, 3 y 5, que es la más usada actualmente (la 4 se abandonó). En junio de 2015 se cerró y publicó la versión ECMAScript 6.

JavaScript fue desarrollado originalmente por Brendan Eich de Netscape con el nombre de "Mocha", el cual fue renombrado posteriormente a "LiveScript", para finalmente quedar como JavaScript. El cambio de nombre coincidió aproximadamente con el momento en que Netscape agregó compatibilidad con la tecnología Java en su navegador web Netscape Navigator en la versión 2.002 en diciembre de 1995. La denominación produjo confusión, dando la impresión de que el lenguaje es una prolongación de Java, y se ha caracterizado por muchos como una estrategia de mercadotecnia de Netscape para obtener prestigio e innovar en el ámbito de los nuevos lenguajes de programación web.

«JAVASCRIPT» es una marca registrada de Oracle Corporation. Es usada con licencia por los productos creados por Netscape Communications y entidades actuales como la Fundación Mozilla.

Microsoft dio como nombre a su dialecto de JavaScript «JScript», para evitar problemas relacionadas con la marca. JScript fue adoptado en la versión 3.0 de Internet Explorer, liberado en agosto de 1996, e incluyó compatibilidad con el Efecto 2000 con las funciones de fecha, una diferencia de los que se basaban en ese momento. Los dialectos pueden parecer tan similares que los términos «JavaScript» y «JScript» a menudo se utilizan indistintamente, pero la especificación de JScript es incompatible con la de ECMA en muchos aspectos.

Para evitar estas incompatibilidades, el World Wide Web Consortium diseñó el estándar Document Object Model (DOM, o Modelo de Objetos del Documento en español), que incorporan Konqueror, las versiones 6 de Internet Explorer y Netscape Navigator, Opera la versión 7, Mozilla Application Suite y Mozilla Firefox desde su primera versión.

En 1997 los autores propusieron JavaScript para que fuera adoptado como estándar de la European Computer Manufacturers 'Association ECMA, que a pesar de su nombre no es europeo sino internacional, con sede en Ginebra. En junio de 1997 fue adoptado como un estándar ECMA, con el nombre de ECMAScript. Poco después también como un estándar ISO.

Netscape introdujo una implementación de script del lado del servidor con Netscape Enterprise Server, lanzada en diciembre de 1994 (poco después del lanzamiento de JavaScript para navegadores web).
A partir de mediados de la década de los 2000, ha habido una proliferación de implementaciones de JavaScript para el lado servidor. Node.js es uno de los notables ejemplos de JavaScript en el lado del servidor, siendo usado en proyectos importantes.

JavaScript se ha convertido en uno de los lenguajes de programación más populares en internet. Al principio, sin embargo, muchos desarrolladores renegaban del lenguaje porque el público al que va dirigido lo formaban publicadores de artículos y demás aficionados, entre otras razones. La llegada de Ajax devolvió JavaScript a la fama y atrajo la atención de muchos otros programadores. Como resultado de esto hubo una proliferación de un conjunto de frameworks y librerías de ámbito general, mejorando las prácticas de programación con JavaScript, y aumentado el uso de JavaScript fuera de los navegadores web, como se ha visto con la proliferación de entornos JavaScript del lado del servidor.
En enero de 2009, el proyecto CommonJS fue inaugurado con el objetivo de especificar una librería para uso de tareas comunes principalmente para el desarrollo fuera del navegador web.

En junio de 2015 se cerró y publicó el estándar ECMAScript 6 con un soporte irregular entre navegadores y que dota a JavaScript de características avanzadas que se echaban de menos y que son de uso habitual en otros lenguajes como, por ejemplo, módulos para organización del código, verdaderas clases para programación orientada a objetos, expresiones de flecha, iteradores, generadores o promesas para programación asíncrona.

La versión 7 de ECMAScript se conoce como ECMAScript 2016, y es la última versión disponible, publicada en junio de 2016. Se trata de la primera versión para la que se usa un nuevo procedimiento de publicación anual y un proceso de desarrollo abierto.

Las siguientes características son comunes a todas las implementaciones que se ajustan al estándar ECMAScript, a menos que especifique explícitamente en caso contrario.

JavaScript es compatible con gran parte de la estructura de programación de C (por ejemplo, sentencias codice_1, bucles codice_2, sentencias codice_3, etc.). Con una salvedad, en parte: en C, el ámbito de las variables alcanza al bloque en el cual fueron definidas; sin embargo JavaScript no es compatible con esto, puesto que el ámbito de las variables es el de la función en la cual fueron declaradas. Esto cambia con la versión de ECMAScript 2015, ya que añade compatibilidad con block scoping por medio de la palabra clave codice_4. Como en C, JavaScript hace distinción entre expresiones y sentencias. Una diferencia sintáctica con respecto a C es la inserción automática de punto y coma, es decir, en JavaScript los puntos y coma que finalizan una sentencia pueden ser omitidos.












JavaScript se encuentra oficialmente bajo la organización de Mozilla Foundation, y periódicamente se añaden nuevas características del lenguaje. Sin embargo, sólo algunos motores JavaScript son compatibles con estas características:


la última versión del lenguaje es ECMAScript 2016 publicada el 17 de junio del 2016

Las variables en JavaScript se definen usando la palabra clave var:

var x; // define la variable x, aunque no tiene ningún valor asignado por defecto
var y = 2; // define la variable y y le asigna el valor 2 a ella

A considerar los comentarios en el ejemplo de arriba, los cuales van precedidos con 2 barras diagonales.

No existen funcionalidades para I/O incluidas en el lenguaje; el entorno de ejecución ya lo proporciona. La especificación ECMAScript en su edición 5.1 hace mención:
... en efecto, no existen provisiones en esta especificación para entrada de datos externos o salida para resultados computados.

Sin embargo, la mayoría de los entornos de ejecución tiene un objeto llamado codice_28 que puede ser usado para imprimir por el flujo de salida de la consola de depuración. He aquí un simple programa que imprime “Hello world!”:

console.log("Hello world!");
Una función recursiva:

function factorial(n) {

Ejemplos de función anónima (o función lambda) y una clausura:

var displayClosure = function() {
var inc = displayClosure();
inc(); // devuelve 1
inc(); // devuelve 2
inc(); // devuelve 3
Las expresiones con invocación automática permiten a las funciones pasarle variables por parámetro dentro de sus propias clausuras.

var v;
v = 1;
var getValue = (function(v) {
}(v));

v = 2;

getValue(); // 1
El siguiente código muestra varias características de JavaScript.

El siguiente ejemplo muestra la salida que debería ser mostrada en la ventana de un navegador.

El uso más común de JavaScript es escribir funciones embebidas o incluidas en páginas HTML y que interactúan con el Document Object Model (DOM o Modelo de Objetos del Documento) de la página. Algunos ejemplos sencillos de este uso son:

Dado que el código JavaScript puede ejecutarse localmente en el navegador del usuario (en lugar de en un servidor remoto), el navegador puede responder a las acciones del usuario con rapidez, haciendo una aplicación más sensible. Por otra parte, el código JavaScript puede detectar acciones de los usuarios que HTML por sí sola no puede, como pulsaciones de teclado. Las aplicaciones como Gmail se aprovechan de esto: la mayor parte de la lógica de la interfaz de usuario está escrita en JavaScript, enviando peticiones al servidor (por ejemplo, el contenido de un mensaje de correo electrónico). La tendencia cada vez mayor por el uso de la programación Ajax explota de manera similar esta técnica.

Un motor de JavaScript (también conocido como intérprete de JavaScript o implementación JavaScript) es un intérprete que interpreta el código fuente de JavaScript y ejecuta la secuencia de comandos en consecuencia. El primer motor de JavaScript fue creado por Brendan Eich en Netscape Communications Corporation, para el navegador web Netscape Navigator. El motor, denominado SpiderMonkey, está implementado en C. Desde entonces, ha sido actualizado (en JavaScript 1.5) para cumplir con el ECMA-262 edición 3. El motor Rhino, creado principalmente por Norris Boyd (antes de Netscape, ahora en Google) es una implementación de JavaScript en Java. Rhino, como SpiderMonkey, es compatible con el ECMA-262 edición 3.

Un navegador web es, con mucho, el entorno de acogida más común para JavaScript. Los navegadores web suelen crear objetos no nativos, dependientes del entorno de ejecución, para representar el Document Object Model (DOM) en JavaScript. El servidor web es otro entorno común de servicios. Un servidor web JavaScript suele exponer sus propios objetos para representar objetos de petición y respuesta HTTP, que un programa JavaScript podría entonces interrogar y manipular para generar dinámicamente páginas web.

Debido a que JavaScript es el único lenguaje por el que los más populares navegadores comparten su apoyo, se ha convertido en un lenguaje al que muchos frameworks en otros lenguajes compilan, a pesar de que JavaScript no fue diseñado para tales propósitos. A pesar de las limitaciones de rendimiento inherentes a su naturaleza dinámica, el aumento de la velocidad de los motores de JavaScript ha hecho de este lenguaje un entorno para la compilación sorprendentemente factible.

A continuación se muestra un breve ejemplo de una página web (ajustadose a las normas del estándar para HTML5) que utiliza JavaScript para el manejo del DOM:

<!DOCTYPE html>
<html>
<head>
</head>
<body>

</body>
</html>

Debido a que JavaScript se ejecuta en entornos muy variados, una parte importante de las pruebas y la depuración es probar y verificar que el código JavaScript funciona correctamente en múltiples navegadores.
La interfaz DOM para acceder y manipular páginas web no es parte del estándar ECMAScript, o de la propia JavaScript. El DOM es definido por los esfuerzos de estandarización del W3C, una organización independiente. En la práctica, las implementaciones que hacen de JavaScript los distintos navegadores difieren tanto entre ellos mismos como de las normas del estándar.

Para hacer frente a estas diferencias, los autores de JavaScript pudieron ser capaces de escribir código compatible con los estándares que también fuera capaz de ejecutarse correctamente en la mayoría de los navegadores, o en su defecto, que al menos se pudiera escribir código capaz de comprobar la presencia de ciertas funcionalidades del navegador y que se comportase de manera diferente si no se dispusiese de dicha funcionalidad. Existen casos en los que dos navegadores pueden llegar a implementar la misma característica, pero con un comportamiento diferente, hecho que a los programadores les puede resultar de ayuda para detectar qué navegador se está ejecutando en ese instante y así cambiar el comportamiento de su escritura para que coincida. Los programadores también suelen utilizar bibliotecas o herramientas que tengan en cuenta las diferencias entre navegadores.

Además, los scripts pueden no funcionar para algunos usuarios. Por ejemplo, un usuario puede:

Para apoyar a estos usuarios, los programadores web suelen crear páginas que sean tolerante a fallos según el agente de usuario (tipo de navegador) que no admita JavaScript. En particular, la página debe seguir siendo útil aunque sin las características adicionales que JavaScript habría añadido. Un enfoque alternativo que muchos encuentran preferible es primero crear contenido utilizando las tecnologías que funcionan en todos los navegadores, y mejorar el contenido para los usuarios que han permitido JavaScript.

Suponiendo que el usuario no haya desactivado la ejecución de código JavaScript, en el lado del cliente JavaScript debe ser escrito tanto con el propósito de mejorar las experiencias de los visitantes con discapacidad visual o física, como el de evitar ocultar información a estos visitantes.

Los lectores de pantalla, utilizados por los ciegos y deficientes visuales, pueden ser tenidos en cuenta por JavaScript y así poder acceder y leer los elementos DOM de la página. El código HTML escrito debe ser lo más conciso, navegable y semánticamente rico posible, tanto si JavaScript se ejecuta como si no.

JavaScript no debería de ser totalmente dependiente de los eventos de ratón del navegador y debería ser accesible para aquellos usuarios que no quieran hacer uso del ratón (informática) para navegar o que opten por utilizar solamente el teclado.
Hay eventos independientes del dispositivo, tales como codice_29 y codice_30 que son preferibles en la mayoría de los casos.

JavaScript no debe ser utilizado para crear confusión o desorientación al usuario web. Por ejemplo, modificar o desactivar la funcionalidad normal del navegador, como cambiar la forma en que el botón de navegar hacia atrás o el evento de actualización se comportan, son prácticas que generalmente son mejores evitar. Igualmente, desencadenar eventos que el usuario puede no tener en cuenta reduce la sensación de control del usuario y provoca cambios inesperados al contenido de la página.

A menudo, el proceso de dotar a una página web compleja el mayor grado accesibilidad posible, se convierte en un problema no trivial donde muchos temas se acaban llevando al debate y a la opinión, siendo necesario el compromiso de todos hasta el final. Sin embargo, los agentes de usuario y las tecnologías de apoyo a personas con discapacidad están en constante evolución y nuevas directrices e información al respecto siguen publicándose en la web.

JavaScript y el DOM permite que existan programadores que hagan un uso inapropiado para introducir scripts que ejecuten código con contenido malicioso sin el consentimiento del usuario y que pueda así comprometer su seguridad.

Los desarrolladores de los navegadores tienen en cuenta este riesgo utilizando dos restricciones.
En primer lugar, los scripts se ejecutan en un sandbox en el que sólo se pueden llevar a cabo acciones relacionadas con la web, no con tareas de programación de propósito general, como la creación de archivos.
En segundo lugar, está limitada por la política del mismo origen: los scripts de un sitio web no tienen acceso a la información enviada a otro sitio web (de otro dominio) como pudiera ser nombres de usuario, contraseñas o cookies. La mayoría de los fallos de seguridad de JavaScript están relacionados con violaciones de cualquiera de estas dos restricciones.

Existen proyectos como AdSafe o Secure ECMA script (SES) que proporcionan mayores niveles de seguridad, en especial en el código creado por terceros (tales como los anuncios).

La Política de Contenido Seguro (CSP) es el método principal previsto para garantizar que sólo código de confianza pueda ser ejecutado en una página web.

Un problema común de seguridad en JavaScript es el cross-site scripting o XSS, una violación de la política de mismo origen. Las vulnerabilidades XSS permiten a un atacante inyectar código JavaScript en páginas web visitadas por el usuario. Una de esas webs podría ser la de un banco, pudiendo el atacante acceder a la aplicación de banca con los privilegios de la víctima, lo que podría revelar información secreta o transferir dinero sin la autorización de la víctima.
Una solución para las vulnerabilidades XSS es utilizar "HTML escaping" cuando se muestre información de fuentes no confiables

Algunos navegadores incluyen una protección parcial contra los ataques XSS reflejados (el atacante está en la misma petición web). El atacante proporciona una URL incluyendo código malicioso. Sin embargo, incluso los usuarios de los navegadores son vulnerables a otros ataques XSS, tales como aquellos en los que el código malicioso se almacena en una base de datos. Sólo el correcto diseño de las aplicaciones Web en la parte servidora puede prevenir totalmente XSS.
Las vulnerabilidades XSS también pueden ocurrir debido a errores de ejecución por los desarrolladores del navegador.

Otra vulnerabilidad es la falsificación de petición de sitio cruzado o CSRF. En CSRF, el código del sitio web atacante engaña al navegador de la víctima, permitiendo al atacante realizar peticiones en nombre de la víctima, haciendo imposible saber a la aplicación de destino (por ejemplo, la de un banco haciendo una transferencia de dinero) saber si la petición ha sido realizada voluntariamente por el usuario o por un ataque CSRF.

El ataque funciona porque, si el sitio de destino hace uso únicamente de las cookies para autenticar las solicitudes de la víctima, las peticiones iniciadas por el código del atacante tendrán las mismas credenciales de acceso legítimo que las solicitudes iniciadas por el propio usuario.

En general, la solución a CSRF consiste en introducir un campo de formulario oculto cuyo valor se utilice para realizar la autenticación, y no sólo por medio de las cookies, en solicitudes que puedan tener efectos duraderos. La comprobación de la cabecera HTTP referer también puede servir de ayuda.

"Hijacking JavaScript" es un tipo de ataque CSRF en el que una etiqueta <script> en el sitio web del atacante explota una vulnerabilidad en la página del sitio de la víctima que le hace devolver información privada, en forma de JSON o código JavaScript. Las posibles soluciones son:

En JavaScript, disponer de un depurador se convierte en necesario cuando se desarrollan grandes aplicaciones, no triviales. Dado que puede haber diferencias de implementación entre los diferentes navegadores (especialmente en cuanto al DOM), es útil tener acceso a un depurador para cada uno de los navegadores a los cuales nuestra aplicación web irá dirigido.

Los depuradores web están disponibles para Internet Explorer, Firefox, Safari, Google Chrome y Opera.

Existen tres depuradores disponibles para Internet Explorer: Microsoft Visual Studio es el más avanzado de los tres, seguido de cerca por Microsoft Script Editor (un componente de Microsoft Office) y, finalmente, Microsoft Script Debugger, que es mucho más básico que el otro dos, aunque es gratuito. El IDE gratuito Microsoft Visual Web Developer Express ofrece una versión limitada de la funcionalidad de depuración de JavaScript en el Microsoft Visual Studio. Internet Explorer ha incluido herramientas de desarrollo desde la versión 8 (se muestra pulsando la tecla F12).
Las aplicaciones web dentro de Firefox se pueden depurar usando el Firebug add-on o el antiguo depurador Venkman. Firefox también tiene integrada una consola de errores básica, que registra y evalúa JavaScript. También registra errores de CSS y advertencias.
Opera incluye un conjunto de herramientas llamado Dragonfly.
El Inspector Web de WebKit incluye un depurador de JavaScript utilizado en Safari, junto con una versión modificada de Google Chrome.

Existen algunas herramientas de ayuda a la depuración, también escritas en JavaScript y construidas para ejecutarse en la Web. Un ejemplo es el programa JSLint, desarrollado por Douglas Crockford, quien ha escrito extensamente sobre el lenguaje. JSLint analiza el código JavaScript para que este quede conforme con un conjunto de normas y directrices y que aseguran su correcto funcionamiento y mantenibilidad.




</doc>
<doc id="1573" url="https://es.wikipedia.org/wiki?curid=1573" title="Planta de interior">
Planta de interior

Se denomina planta de interior a cualquier especie vegetal cultivada en lugares bajo techo, como casas u oficinas. En su gran mayoría, son variedades de climas tropicales que se aclimatan en entornos geográficos ajenos gracias a que el cultivo en interior les proporciona las condiciones adecuadas. No hay que confundirlas con algunas plantas de balcón o de jardín, que se ubican en interiores temporalmente pero que para subsistir requieren periodos más largos al exterior.

Este tipo de plantas se cultivan normalmente con propósitos decorativos o por razones de salud, como purificadores del aire. Pueden agruparse recreando ambientes selváticos, en invernaderos y miradores acristalados; esto fue muy habitual en la época victoriana.
Los principales factores que deberían considerarse en este tipo de plantas son la humedad del suelo, la luz, la humedad ambiental, la temperatura, los fertilizantes, el enmacetado y el control de plagas. 

Tanto el exceso como la escasez de riego pueden ir en detrimento de la planta. La mejor forma de determinar si una planta necesita riego es comprobar la humedad del suelo. Para ello, se toca la superficie de la tierra y se introduce un dedo ligeramente en el sustrato. El suelo puede variar entre muy mojado (como si estuviera recién regado) a muy seco. Típicamente, una planta de interior necesita riego alrededor de una vez por semana, aunque no se recomienda aplicar esta regla con rigidez. Para regar, rociar agua uniformemente sobre la superficie del sustrato hasta que empiece a drenar por el fondo de la maceta, lo que asegura una completa saturación.

A través del proceso de fotosíntesis las plantas convierten la energía solar en energía química, lo cual las hace crecer. Los dos importantes factores a la hora de proporcionar luz a una planta son la "intensidad" y la "duración".

Cada tipo de planta requiere una intensidad de luz diferente. La intensidad (o calidad) de luz es difícil de medir sin un luxómetro, el cual realiza las mediciones en unidades de lux. 100 lux o menos se considera normalmente como "intensidad baja" o luz "indirecta". Una oficina luminosa tiene una iluminación aproximada de 400 lux. 1.000 lux o más se considera iluminación de "alta intensidad". La luz del sol directa en el exterior está en el orden de los 32.000 a 100.000 lux.

La duración de la exposición luminosa es tan importante como la intensidad. La calidad de exposición de entre 8 a 16 horas es ideal para la mayoría de las plantas. En el hemisferio norte, las ventanas con orientación Sur tienen la mayor cantidad de exposición solar, mientras que las orientadas al Oeste, Este y Norte tienen una exposición progresivamente menor. La luz solar directa es ideal, pero la luz solar natural a través de una ventana es imprevisible - los cambios estacionales, la cobertura nubosa y el tratamiento de los cristales pueden afectar a la cantidad de luz entrante.

Las fuentes de luz artificial pueden suministar una alternativa o suplemento a la iluminación recibida de las ventanas. La luz fluorescente proporciona una excelente calidad luminosa, mientras las bombillas incandescentes estándar estimulan muy poco el crecimiento. Los fluorescentes "azules" o "fríos" facilitan la luz necesaria para las plantas de follaje verde, en cambio los "cálidos" o "rojos" son adecuados para las plantas de flor. Existen bombillas fluorescentes que encajan en los casquillos estándar.

Las plantas de interior se cultivan generalmente en suelos especiales llamados "compost de enmacetado" o "sustrato de enmacetado", no en tierra natural. Una buena mezcla de sustrato para macetas incluye acondicionadores de suelo que suministren a la planta nutrientes, soporte, drenaje y aireación adecuados. La mayoría de estos compost contienen una combinación de turba y vermiculita o perlita. Sin embargo la preocupación por los daños medioambientales causados en los marjales están induciendo a sustituir la turba por fibra de coco, un recurso sostenible. 

Si se opta por utilizar tierra natural de la zona se debería, como primera medida, esterilizar por calor, metiendo el sustrato en un horno a 90ºC durante el menos 30 minutos. Esto evitará que la tierra contenga bacterias dañinas. La mayoría de las tierras, en especial aquellas con una alta proporción de arcilla, no drenan lo suficiente como para ser consideradas un medio de crecimiento adecuado para plantas de interior, por lo que se utiliza la turba o la fibra de coco para aumentar la aireación y hacer más absorbentes los suelos pesados. La vermiculita y la perlita ayudan también al drenaje aunque es más recomendable la perlita, ya que no se desmiga tan fácilmente. Si es necesario también se puede usar arena gruesa o gravilla como sustituto para aumentar el drenaje. Estos tres ingredientes se pueden mezclar en varias proporciones para crear diferentes tipos de sustrato de enmacetado. Para plantas que requieran un drenaje rápido, como los cactus, se utiliza más cantidad de arena gruesa, gravilla o perlita. Para las que necesiten mayor cantidad de humedad se usará más turba o fibra de coco. Una buena mezcla de sustrato para todo tipo de plantas consiste en 2 partes de fibra de coco y 1 parte de perlita (o vermiculita). La llamada "mezcla de sustrato pesada" contiene tierra esterilizada, musgo de sphagnum desmigado o fibra de coco y perlita en proporciones iguales. También es posible hacer una mezcla de sustrato que no contenga nada de tierra mezclando a partes iguales turba y perlita (o vermiculita), esta combinación retendrá más la humedad.

La mayoría de las plantas de interior son especies tropicales seleccionadas por su adaptación al crecimiento en un clima que varía entre los 15º a los 25°C, similar al que existe en la mayor parte de las casas. El control de la temperatura en otras plantas con requisitos diferentes necesitará prestar más atención al calentamiento y/o enfriamiento del lugar.

La humedad es algo más difícil de controlar que la temperatura. La mayoría de las plantas prosperan con un 80% de humedad relativa, mientras que la mayor parte de las casas mantienen entre un 20% y un 60%. Además de comprar un humidificador, hay alguna formas caseras que pueden aumentar la humedad. Uno de los más populares es usar pequeños guijarros, cristalitos esmerilados u otro material similar, se coloca una cama de este material en el fondo de la maceta de drenaje de la planta y se llena de agua, la evaporación de esta agua producirá humedad a su alrededor. Otro de los métodos es agrupar las plantas en lugar de colocarlas aisladas en zonas con corrientes de aire.

En condiciones de enmacetado, los nutrientes de la tierra llegan a agotarse al cabo del tiempo, los fertilizantes suministran estos nutrientes artificialmente. Sin embargo, añadir fertilizantes innecesariamente puede ser perjudicial para la planta, por lo que hay considerar algunos síntomas como crecimiento lento, amarilleamiento de las hojas o caída de hojas nuevas para juzgar si el abonado es necesario.

Los fertilizantes se marcan normalmente con números, como 20-20-20. Estos indican el porcentaje de nitrógeno, fósforo y potasio, elementos necesarios para el crecimiento vegetal. La combinación 20-20-20 es generalmente adecuada para plantas verdes, mientras que 10-20-10 es habitualmente mejor para plantas de flor.

La seguridad de un fertilizante depende de la disolución que se pueda hacer del producto. Aunque se puede producir alguna variación dependiendo de la marca, una regla general es diluir una cucharada por cada 3,5 litros de agua. En todos los casos, es más seguro infra-fertilizar que sobre-fertilizar. Esta disolución se utilizará para regar las plantas y se vigilará el crecimiento para determinar si se ha conseguido el efecto deseado y la frecuencia con que debe ser administrada. Las necesidades de abonado pueden variar entre quincenales hasta cada tres meses.

El tamaño de las macetas es un factor importante a considerar. Una maceta demasiado grande provocará el enfermamiento de las raíces debido al exceso de humedad retenida en el sustrato, mientras que una maceta demasiado pequeña restringirá el crecimiento de la planta. En general, una planta puede permanecer en la misma maceta durante aproximadamente dos años. <br>Existen una amplia variedad de macetas, pero normalmente se pueden dividir en dos grupos: las porosas y las no porosas. Las porosas son normalmente de barro, material altamente recomendado ya que proporcionan una mejor aireación, al permitir el paso del aire por los laterales. Las no porosas, como las de cerámica o plástico tienden a mantener más tiempo la humedad y restringen el flujo de aire. Otra característica necesaria son los agujeros de drenaje. Normalmente las macetas vienen con agujeros en el fondo para permitir que escurra el exceso de agua de la tierra y evitar la podredumbre de las raíces. En el caso de que una maceta no posea estos agujeros, se puede crear un mecanismo de drenaje poniendo fragmentos de arcilla o guijarros en el fondo antes de llenarla con el sustrato, lo cual hará que el exceso de agua se deposite en este espacio en lugar de permanecer en la tierra.<br> Las macetas viejas se deben lavar cuidadosamente para eliminar cualquier bacteria, causada por una planta enferma, que hubiera podido quedar.









</doc>
<doc id="1575" url="https://es.wikipedia.org/wiki?curid=1575" title="Japón">
Japón

Japón (, "Nihon" o "Nippon"), oficialmente Estado del Japón (日本国, o "Nippon-koku"), es un país soberano insular del este de Asia. Situado en el océano Pacífico; tiene al oeste el mar del Japón, China, Corea del Norte, Corea del Sur y Rusia, al norte el mar de Ojotsk y al sur el mar de China Oriental y Taiwán. Los caracteres que componen el nombre de Japón significan «el origen del sol», motivo por el que el país también es conocido como la Tierra del Sol Naciente.

Japón es un archipiélago de . El Área del Gran Tokio en la isla de Honshū, donde está la ciudad de Tokio, capital "de facto" de la nación, es la mayor área metropolitana del mundo, con más de treinta millones de residentes.

Los restos arqueológicos indican que el ser humano ha vivido en Japón desde el Paleolítico superior. La primera mención escrita de las islas se encuentra en textos de la antigua China del siglo I d. C. La historia de Japón ha alternado periodos de influencia extranjera con otros muy prolongados de aislamiento total. Desde el siglo XII hasta 1868 Japón estuvo gobernado por sucesivos shogunatos militares que ejercían el poder en nombre del emperador. En el siglo XVII el país entró en un largo periodo de aislamiento que no terminó hasta mediados del siglo XIX. Después de casi dos décadas de conflictos internos e insurrecciones se restauró al emperador Meiji como jefe del Estado en 1868 y se proclamó el Imperio del Japón.

A finales del siglo XIX y principios del XX, los éxitos en la Primera guerra sino-japonesa, en la guerra ruso-japonesa y en la Primera Guerra Mundial permitieron a Japón expandir su imperio y fortalecer sus fuerzas armadas. La Segunda guerra sino-japonesa que se inició en 1937, acabó formando parte de la Segunda Guerra Mundial desde 1941, conflictos que terminaron tras los bombardeos atómicos sobre Hiroshima y Nagasaki en 1945. Desde la adopción de la constitución revisada en 1947, Japón ha mantenido una monarquía constitucional unitaria con un emperador y un órgano de gobierno democrático llamado Dieta.

Japón es desde hace varias décadas, una de las grandes potencias económicas mundiales y en la actualidad es la de acuerdo a su PIB. Asimismo, es el cuarto mayor exportador e importador de mercancías. Aunque Japón renunció oficialmente a su derecho a declarar la guerra tras la Segunda Guerra Mundial, posee unas modernas fuerzas armadas y el mundial para su autodefensa y el mantenimiento de la paz.

Es miembro de la Organización de las Naciones Unidas, el G8, el G4 y la APEC. Japón es el segundo país con la menor , solo por detrás de Singapur, las mujeres japonesas tienen la segunda mayor esperanza de vida y, según la ONU, el país presenta la tercera menor mortalidad infantil del mundo.

El nombre Japón ("Nippon/Nihon" 日本, significado literal: «el origen del sol») tiene un origen chino: pinyin rì běn, Wade-Giles jih pen, el oriente, el lugar desde donde sale el sol. El carácter 日 es la evolución de un círculo con un punto central que representa al sol, y 本 representa la raíz de un árbol y también tiene el significado de origen. La expresión «país del sol naciente» hace referencia a esta etimología del nombre en japonés.

El nombre en japonés, Nippon, es utilizado en sellos y en eventos deportivos internacionales, mientras que Nihon se usa comúnmente dentro de Japón. La versión occidental y española, Japón, proviene del nombre chino. La palabra empleada en el idioma chino mandarín para denominar al país fue registrada por Marco Polo como Cipangu, probablemente su transliteración de rìběnguó (Wade-Giles jih pen kuo). En el idioma malayo la palabra china se transformó en Japang y fue más tarde adoptada por los mercaderes portugueses en el siglo XVI. Estos últimos fueron los primeros en llevar el nombre a Europa.

Según la leyenda descrita en el "Kojiki" y en el "Nihonshoki", Japón fue fundado en el siglo VII a. C. por el emperador Jinmu. Durante los siglos V y VI, el sistema caligráfico chino y el budismo fueron introducidos junto con otras costumbres chinas a través de la península coreana o directamente desde China. Los emperadores fueron gobernantes oficiales, pero el verdadero poder permanecía generalmente en manos de poderosas cortes nobles, regentes o shogunes (gobernadores militares).

Durante el siglo XVI, mercaderes de Portugal, de los Países Bajos, de Inglaterra y de España llegaron a Japón y fundaron misiones cristianas. En 1549, llegó a Japón para predicar el cristianismo el misionero español jesuita San Francisco Javier tras desembarcar en Kagoshima, Kyūshū, aprovechando las rutas comerciales portuguesas. A comienzos del siglo XVII, el shogunato comenzó a sospechar de las misiones cristianas, considerándolas precursoras de una conquista militar por fuerzas europeas y, como medida de protección, ordenó el cierre de Japón a toda relación con el mundo exterior a excepción de contactos restringidos con mercaderes chinos y neerlandeses en la ciudad de Nagasaki. Este aislamiento se prolongó durante 251 años, hasta el año 1854, en que el comodoro estadounidense Matthew Perry forzó la apertura del Japón a Occidente bajo el Tratado de Kanagawa.

Durante un largo período, el restablecido contacto con Occidente provocó cambios en la sociedad japonesa. Tras un fuerte conflicto civil denominado guerra Boshin, el shogunato fue obligado a renunciar y el poder fue devuelto al emperador. La Restauración Meiji de 1868 inició varias reformas. El sistema feudal fue abolido y numerosas instituciones occidentales fueron adoptadas, incluyendo un sistema legal y de gobierno occidentales, junto con otras reformas en lo económico, social y militar que transformaron a Japón en una potencia mundial de nivel medio-alto. Como resultado de la Primera Guerra Sino-Japonesa y de la Guerra Ruso-Japonesa, Japón anexionó Taiwán, Corea y otros territorios a su imperio en expansión.

Así se afianzó de manera definitiva como una potencia mundial y la única de Asia. Después de la Primera Guerra Mundial, 1918, Japón ocupaba una sólida posición en el Lejano Oriente; contaba con la Armada más poderosa de la zona, ejercía gran influencia sobre China y se había beneficiado económicamente de la guerra (se ocupaba de los pedidos de los países asiáticos, a los que el resto de las potencias no lograban atender).

Durante la década de los años 1920, surgieron problemas que la democracia no pudo resolver. Por un lado, los grupos más conservadores como la milicia, los pares, etc. que se encontraban posicionados en la cámara alta del parlamento y en el Consejo, consideraban que la democracia era muy débil. La corrupción dentro del gobierno era insostenible, las acusaciones entre los miembros de la Cámara Baja provocaban continuamente disturbios. El auge comercial que había alcanzado tras la Primera Guerra Mundial disminuyó cuando en 1921, Europa comenzó su recuperación. Tuvo nefastas consecuencias de la Gran depresión, aumento de las tarifas de los países extranjeros para los productos japoneses y la pobreza que se vio reflejada en el norte donde los humildes campesinos culpaban al gobierno nipón de sus desdichas (muchos aldeanos se sumaron al ejército). La suma de estos problemas y la actitud de China, tratando de desplazar los negocios japoneses, derivó en la invasión a Manchuria (septiembre de 1931). Esta invasión se produjo sin la autorización del gobierno nipón.

Cuando el primer ministro Inukai reprobó los actos extremistas, fue asesinado por un grupo de oficiales de marina (15 de mayo de 1932), y su sucesor consideró que debía apoyar las acciones del ejército y así fue que durante los 13 años siguientes: el gobierno adoptó un estricto control de la educación, fortalecimiento del arsenal bélico y una política exterior agresiva orientada a conquistar territorios. Esto culminó en una nueva invasión de Manchuria, desatando la Segunda Guerra Sino-Japonesa.

Japón atacó la base naval estadounidense de Pearl Harbor en diciembre de 1941, lo cual llevó al país norteamericano a declarar la guerra al Imperio Japonés en el marco de la Segunda Guerra Mundial. Después de una larga campaña en el Pacífico, Japón perdió Okinawa y fue forzada a retroceder a las cuatro islas principales. El ejército estadounidense atacó Tokio, Osaka y otras ciudades con bombardeos estratégicos convencionales, y en Hiroshima y Nagasaki con dos bombas atómicas (6 y 9 de agosto de 1945). Japón finalmente aceptó la capitulación incondicional ante el ejército estadounidense el 15 de agosto de 1945 dando con ello fin a la guerra.
Finalizado el conflicto, el ejército estadounidense ocupó el territorio japonés hasta 1952, tras lo cual Japón comenzaría una muy importante recuperación económica que devolvería la prosperidad al archipiélago. Okinawa permaneció ocupada hasta 1972, y actualmente el ejército estadounidense mantiene un centenar de bases en este país. El 17 de enero de 1995 el terremoto de Kōbe causó la muerte de 6433 personas. Durante marzo del mismo año la secta Verdad Suprema llevó a cabo un ataque en el metro de Tokio que causa la muerte a 12 personas y heridas a más de 1000. En octubre de 1998, se condena con la sentencia de cadena perpetua al máximo responsable de la secta, y pena capital a otro de los miembros fundadores. Más tarde, un nuevo ataque terrorista en el aeropuerto de Narita hizo peligrar la celebración de los Juegos Olímpicos de Nagano 1998. La autodenominada Asociación Revolucionaria de Trabajadores no hizo reivindicaciones del hecho y las competiciones se celebraron tal y como estaban previstas en febrero de 1998.

El Partido Democrático de Japón obtuvo una clara victoria en las elecciones generales de 2009, obteniendo 300 escaños de los 480 disponibles.

El 11 de marzo de 2011, a las 2:46 en el epicentro, Japón se vio azotado por un terremoto de 9.0 en la escala sismológica de magnitud de momento, el terremoto de mayor magnitud de su país en 140 años. El epicentro del temblor fue en la costa del este de Honshū, provocó un violento tsunami con olas de 10 metros.
Se calcula que la catástrofe dejó más de pérdidas humanas, desaparecidos y pérdidas económicas por más de 150 mil millones de euros, según datos del gobierno nipón. Este terremoto causó muchos problemas a las centrales nucleares de Japón y provocó grandes fugas radiactivas. Una de las centrales afectadas gravemente fue la central de Fukushima.

El gobierno es descentralizado. Se puede distinguir:



Japón mantiene estrechas relaciones económicas y militares con los Estados Unidos, con el que ha formado una alianza de seguridad, piedra angular de su política exterior. Estado miembro de la Organización de las Naciones Unidas desde 1956, ha sido miembro no permanente del Consejo de Seguridad un total de 20 años, más que ningún otro miembro de la ONU, las últimas veces en 2016 y 2017. También forma parte del Grupo de los cuatro en el que cada miembro busca la condición de miembro permanente en el Consejo de Seguridad. Como miembro del G8, la APEC, la «ASEAN más tres» y participante en la Cumbre de Asia Oriental, Japón participa activamente en los asuntos internacionales. No obstante, el nivel de implicación personal japonesa es extraordinariamente bajo: únicamente el 1,3 % del personal de las organizaciones internacionales multilaterales es japonés. También es el tercer mayor donante de Ayuda oficial al desarrollo en el mundo tras donar millones de dólares en 2004. Contribuyó con tropas no combatientes en la Guerra de Irak, pero posteriormente retiró dichas fuerzas.

Japón tiene varias disputas territoriales con sus vecinos: con Rusia sobre las islas Kuriles del Sur, con Corea del Sur las Rocas de Liancourt, con la República Popular China y Taiwán sobre la islas Senkaku, y con la República Popular China sobre la zona económica exclusiva en torno a Okino Torishima. También se enfrenta a una permanente disputa con Corea del Norte por el secuestro de ciudadanos japoneses y el Programa nuclear norcoreano. Como resultado de la controversia en torno a las islas Kuriles, está técnicamente aún en guerra con Rusia ya que nunca fue firmado ningún tratado para resolver la cuestión.

La capacidad militar japonesa está limitada por el artículo 9 de la Constitución japonesa, por el que renuncia a su derecho a declarar la guerra o utilizar la fuerza militar como medio de resolver las controversias internacionales. El Ministerio de Defensa, rige la capacidad militar japonesa que se compone principalmente de la Fuerza Terrestre de Autodefensa de Japón (JGSDF), la Fuerza Marítima de Autodefensa de Japón (JMSDF) y la Fuerza Aérea de Autodefensa de Japón (JASDF). El Partido Liberal Democrático, el más importante de Japón, continúa intentando reformar el citado precepto constitucional con vistas a la denominación oficial de las Fuerzas de Autodefensa como unas fuerzas armadas, así como a la expansión de sus capacidades y funciones, para que finalmente adquieran un estatus similar al de cualquier otra fuerza armada. Las fuerzas militares japonesas se han utilizado recientemente en las operaciones de mantenimiento de la paz y el despliegue de tropas japonesas en Irak, que fue el primer uso de sus fuerzas militares en el extranjero desde la Segunda Guerra Mundial.

Este país es uno de los países industrializados donde aún se mantiene la pena de muerte. De hecho, se ha revivido la aplicación de la pena capital en Japón; en 2007 se ejecutaron por ahorcamiento a nueve personas, a 15 en 2008 y en 2012 a 16.

Japón está dividido en cuarenta y siete prefecturas, cada una de ellas gobernada por un gobernador, poder legislativo, y burocracia administrativa elegidos. Cada prefectura se divide en ciudades, pueblos y aldeas. En la primera década del siglo XXI, la nación estuvo en una reorganización administrativa, uniendo ciudades, pueblos y villas, las unas con las otras. Este proceso redujo el número de regiones administrativas subprefecturales y se esperaba con ello recortar costes administrativos.
Principalmente, Japón está subdividido en 47 prefecturas, agrupadas en 8 regiones:

Japón es un archipiélago estratovolcánico que comprende 377 915 km² de superficie de los cuales 13 430 km² son agua. Está conformado por 6852 islas que se extienden a lo largo de la costa asiática este del océano Pacífico y en los archipiélagos de Ryukyu, Izu y Ogasawara. Según el censo de 2005 tiene 127,55 millones de habitantes. El país está ubicado al noreste de China y de Taiwán (separado por el mar de China Oriental), levemente al este de Corea (separado por el mar del Japón) y al sur de Siberia, Rusia. Las cuatro islas principales, de norte a sur, son Hokkaidō, Honshu, Shikoku y Kyushu. La isla de Okinawa (600 km al sudoeste de Kyushu) les sigue en magnitud. Cerca del 73 % del país es montañoso, cada isla cuenta con su cadena montañosa. La montaña más alta es el Monte Fuji ("Fujisan"), de 3776 m de altura y le sigue Kitadake, con 3193 m de altura. Debido a que existe tan poco terreno llano en Japón, muchas colinas y laderas son aprovechadas en su totalidad para el cultivo. Como se encuentra situada en una zona de mucha actividad volcánica resultan frecuentes temblores de pequeña magnitud y actividad volcánica ocasional. Terremotos destructivos ocurren varias veces cada siglo, resultando a menudo en tsunamis.

Las islas montañosas del archipiélago forman un arco desde las costas del este de Asia. El territorio nacional incluye las pequeñas islas Bonin u Ogasawara incluyendo la isla Iwo Jima aproximadamente a 1100 kilómetros de las islas principales. La particularidad de que Japón sea un archipiélago produce que ningún punto de Japón esté a más de 150 kilómetros del mar.

Las cuatro islas principales se encuentran separadas por angostos canales y tres de ellas (Honshu, Shikoku y Kyūshū) por el Mar Interior de Seto. En el extremo meridional se encuentran las islas Ryukyu a 970 kilómetros al sur de la tercera gran isla, Kyūshū.

El punto más cercano al continente asiático es la península de Corea que se encuentra a una distancia aproximada de 200 kilómetros. Siempre estuvo conectada con el continente a través de rutas marítimas de comercio: en el norte con Siberia, en el oeste desde las islas Tsushima hacia la península coreana y en el sur con los puertos del sur de China.

Tiene aproximadamente un 84 % de territorio montañoso, el 14 % de la superficie se dedica a actividades agrícola-ganaderas, el 66 % a bosques y el 20 % restante está dedicado a otros usos, debido a que sus islas son una cadena montañosa en la parte sumergida de la plataforma continental, siendo las islas sus picos. Solo cerca del 25 % del territorio es llano y es donde se concentra la población. Una larga cadena montañosa divide el archipiélago por la mitad, una de las cuales se encuentra del lado del océano Pacífico y la otra del lado del mar del Japón (lo cual se aprecia en el mapa topográfico). En la mitad del Pacífico hay escarpadas montañas, de entre 1500 y 3000 metros de altura aproximadamente, que forman profundos valles y desfiladeros. En el centro convergen tres cadenas montañosas: las Hida, las Kiso y las Akaishi, las cuales forman los Alpes Japoneses, siendo Kitadake su montaña más alta con 3193 metros, pero la segunda en altura del país. El punto más elevado del territorio es la cima del monte Fuji a 3776 metros de altura. El monte es un volcán dormido desde 1707 ubicado en la prefectura de Shizuoka.

Ninguna de las llanuras o valles habitados es amplia. La más grande es la llanura de Kanto, en donde está situado Tokio, y solo tiene 17 . Otras llanuras importantes son: la de llanura de Nōbi, que rodea Nagoya; la de Kinki, en el área de Osaka-Kioto; la de Sendai, que rodea la ciudad de Sendai al noreste de Honshū y la de Ishikari en Hokkaidō. La mayoría de estas llanuras están a lo largo de la costa.
La pequeña parte de tierra habitable sufrió diversas modificaciones en su terreno a lo largo de los siglos. Las tierras próximas al mar y a los ríos tiene numerosas construcciones de diques y drenajes, muchas colinas y montañas están cortadas en terrazas escalonadas para aumentar el terreno cultivable y para aumentar el terreno edificable. Este proceso de modificación del medio continúa actualmente con la extensión de la línea costera y la construcción de islas artificiales para las industrias y para el crecimiento del puerto. Un ejemplo de esto es el Aeropuerto Internacional de Kansai, en la bahía de Osaka.

Los ríos de Japón suelen ser rápidos y abruptos, solo unos pocos son navegables y la mayoría suelen tener menos de 300 kilómetros de largo. A pesar de esto, Japón logra aprovechar estos ríos para producir energía hidroeléctrica, aunque este recurso se encuentra explotado casi hasta su capacidad. El río más largo del territorio es el Shinano, el cual nace en la prefectura de Nagano hasta la prefectura de Niigata donde desemboca en el mar del Japón, pero solo tiene 367 kilómetros de largo. La mayor reserva de agua se encuentra en el lago Biwa al noreste de Kioto.

La extensión de la costa navegable especialmente en el mar de Seto, compensa la falta de ríos navegables. La costa pacífica del sur de Tokio tiene la característica de ser larga y de aumentar su profundidad de forma muy gradual debido a la sedimentación.

Es un país lluvioso y con una alta humedad, posee un clima templado con 4 estaciones diferentes bien definidas, gracias a la distancia a la que se encuentra respecto del ecuador. De todas formas el clima del norte es ligeramente frío templado (Hokkaidō) con fuertes veranos y grandes nevadas en invierno, el centro del país es caliente, veranos húmedos e inviernos cortos y en el sur ligeramente subtropical (Kyūshū) con veranos largos, calientes y húmedos e inviernos cortos y suaves. El clima a veces es afectado por los vientos estacionales producidos por los centros ciclónicos y anticiclónicos que se forman en el continente y en el Pacífico (anticiclón o ciclón hawaiano), generando vientos desde el continente hacia el Pacífico en invierno y del Pacífico al continente en verano.

Existen dos factores primarios en la influencia climatológica: la cercanía con el continente asiático y las corrientes oceánicas. El clima desde junio a septiembre es caliente y húmedo por las corrientes de viento tropicales que llegan desde el océano Pacífico y desde el sudeste asiático. Estas corrientes precipitan grandes cantidades de agua al tocar tierra, por lo que el verano es una época de importantes lluvias, que comienzan a principios de junio y duran alrededor de un mes. Le sigue una época de calor y a principios de agosto hasta principios de septiembre, un periodo de tifones, en la cual pasan por Japón 5 ó 6 de ellos y llegan a producir daños significativos. La precipitación anual de lluvias es de 100 a 200 centímetros, pero entre el 70 y el 80 por ciento de estas están concentradas en junio y en septiembre.

En invierno, los centros de alta presión del área siberiana y los centros de baja presión del norte del océano Pacífico, generan vientos fríos que atraviesan Japón de oeste a este, produciendo, importantes nevadas en la costa japonesa del mar del Japón. Como los vientos chocan contra las cadenas montañosas del centro, las grandes alturas terminan por precipitar la humedad de estos vientos en forma de nieve y al pasar por la costa pacífica del país llegan sin portar notables cantidades de humedad, por lo que no son el factor principal de nevadas en la costa pacífica. Además esto provoca que en esta costa, el tiempo en invierno sea seco y de días sin nubes, al contrario del invierno en la costa oeste.

Hay dos corrientes oceánicas que afectan al modelo climático: la corriente cálida de Kuroshio y la corriente fría de Oyashio. La corriente de Kuroshio fluye por el Pacífico desde Taiwán y pasa por Japón bastante al norte de Tokio, es una corriente que lleva mucho calor a la costa este.

Japón tiene nueve ecorregiones que reflejan el clima y la geografía de las islas, la cual va desde pluvisilvas en las islas Ryūkyū y Ogasawara, a bosques templados de frondosas en las regiones templadas de las islas principales, a bosques templados de coníferas en las partes frías de las islas más norteñas.

La fauna comprende 132 especies de mamíferos, 583 especies de aves y 66 especies de reptiles, batracios y peces.


Entre los mamíferos podemos destacar el oso negro asiático, presente en Honshu, y Shikoku, aunque extinto en Kyushu, el oso pardo de Hokkaido (ursus arctos ussuriensis), isla donde no está presente el oso negro; el jabalí, ausente en Hokkaido, pero presente en el resto del archipiélago, el ciervo sika, el serow japonés (especie de antílope parecido al rebeco, que se encuentra en las montañas de Honshu, y en menor medida en Kyushu y Shikoku); el zorro rojo (ausente de Shikoku), la marta japonesa ("Martes melampus"), el tejón japonés (Meles anakuma), presente en las grandes islas, excepto Hokkaido, el tanuki, o perro mapache, distribuido por todo el archipiélago. Es interesante señalar la presencia de dos variedades de gato salvaje, restringidas a pequeñas islas: el gato de Iriomote, isla al sur de las Riukiu, o el gato de Tshushima que solo habita en esta isla, ambas son subespecies del gato leopardo. Existen varidades del zorro volador en Okinawa y en las islas Bonin. El león marino de Steller se concentra en loberías en la costa de Hokkaido, si bien no llega criar. Existe una amenazadísima población de dugongos en las Riukiu, no obstante, la excesiva presión humana, escaso número, y deficientes leyes de protección de la naturaleza en Japón, podrían haber provocado ya su desaparición.
Se extinguieron igualmente los lobos japoneses, tanto en las islas meridionales, como en Hokkaido. Su nombre japonés es okami.

Entre las especies introducidas podemos citar la civeta de las palmeras presente en Honshu; el mapache ("Procyon lotor"), distribuido por Hokkaido y Honshu merced a la liberación de mascotas, el muntjac presente en Honshu (Península de Boso y en Oshima); el coypú de Sudamérica introducido por su piel se ha expandido por Honshu. El único primate es el macaco japonés, que puebla Honshu, Shikoku, Kyushu y alguna isla menor.

Entre las aves más vistosas podemos mencionar: la grulla de Manchuria en Hokkaido, el enorme águila marina de Steller, se trata de la mayor variedad de pigargo, el pigargo común, el águila real, el águila azor asiática, el faisán cobrizo ("Syrmaticus soemmerringii") y el faisán verde ("Phasianus versicolor"); ambos endémicos de Japón, y presentes en Kyushu, Honshu y Shikoku.

La gran variedad de la vegetación japonesa (unas 17.000 especies) se debe al clima y al relieve. Los bosques cubren el 67 % de la superficie del país y se componen en su mayoría de frondosas y coníferas: castaños japoneses, hayas japonesas ("Fagus crenata y Fagus japonica"), arces, tuyas, pino rojo japonés ("Pinus densiflora"), pino coreano ("Pinus koraiensis") y otros ("Pinus parviflora, Pinus thunbergii"). Existen igualmente diversas variedades de robles ("Quercus acuta, Quercus aliena, Quercus dentata, Quercus mongolica, Quercus variabilis"), abedules ("Betula ermanii", "Betula maximowicziana", "Betula platyphylla") y fresnos ("Fraxinus lanuginosa", "Fraxinus mandshurica").

En general, podemos señalar que la vegetación japonesa va de la claramente tropical en las Riukiu, a la propia de los bosques den transición entre la taiga y los templados caducifolios en Hokkaido; pasando por la flora subtropical en el sur de Honshu, Shikoku y Kyushu. Esta última se caracteriza por árboles y arbustos siempre verdes, de hojas brillantes y cerosas. Se trata de una especie de laurisilva, con plantas como (camelias, rododendros, alcanforeros...).

El área templada fría se estiende por el centro de Honshu, sur de Hokkaido, y montañas de las dos islas meridionales. En esta zona encontramos hayas, arces, castaños japoneses y robles como árboles dominantes. Las coníferas en sus distintas y ricas variedades se distribuyen por todo el archipiélago. Las especies vegetales se mezclan en las zonas de contacto haciendo que la vegetación sea especialmente rica y variada, y ofreciendo en buena parte del país un otoño de colores espectaculares, de forma similar a lo que sucede en los bosques de los Apalaches americanos.

Los ciruelos blancos y rojos, los cerezos de floración temprana, así como el bambú y los pinos se han convertido en símbolos tradicionales del país.

Las islas se ubican en una de las zonas geológicamente más inestables y complejas del planeta. En general, es un país altamente sísmico a causa de su ubicación en el Cinturón de Fuego del Pacífico. En Japón se han presentado 5 importantes terremotos en los últimos 15 años.

El grupo insular nipón es, sobre todo, el resultado de continuos e inmensos movimientos oceánicos que ocurrieron durante centenares de millones de años desde mediados del Período Silúrico hasta el Pleistoceno. Este proceso fue como resultado de la subducción tectónica de la placa Filipina y la placa Pacífica debajo de las continentales placa Euroasiática y placa Norteamericana.

La mayor parte del territorio terrestre está asentado sobre la placa de Ojotsk, ubicándose su línea de fricción y ruptura con la placa Euroasiática (sector también conocido como placa Amuria ) al sur de la isla de Honshū. El resto del territorio japonés se encuentra en la segunda placa mencionada. Mientras tanto, el arco de las islas Ryūkyū se encuentran al borde de la placa Filipina.

Por otro lado, la unión de la placa Filipina, la placa Euroasiática y la placa de Okhotsk ocurre en las cercanías del monte Fuji o Fujisan, convergencia con un alto potencial sísmico y vulcanológico.

Esta compleja distribución, origina profundas y extensas fosas oceánicas, especialmente en la costa pacífica del archipiélago. Destaca en particular la Fosa de Japón, de 9000 metros de profundidad, originada por una falla con borde convergente por subducción.

Japón estuvo asociado originalmente a la costa este del continente eurasiático. Las placas se subdujeron, siendo más profundas que la placa Euroasiática. Estos procesos geológicos tiraron a Japón hacia el este, originado la apertura del mar del Japón hace alrededor 15 millones de años y dando lugar a una cuenca submarina de trasarco El estrecho de Tartaria y el Estrecho de Corea fueron abiertos mucho más adelante.

Las colisiones entre estas placas y su posterior hundimiento generaron los arcos de islas de las Kuriles y de Sajalin-Hokkaidô (al norte), el arco de Honshû, que conecta Kyūshū, Shikoku, Honshû y la porción oeste de Hokkaidô (en el centro), y los arcos de las Ryûkyû e Izu-Ogasawara (en el sur).

Japón se sitúa en la zona volcánica denominada como el Cinturón de Fuego del Pacífico. Los temblores de tierra son frecuentes (con una intensidad reducida a moderada) y la actividad volcánica ocasional se siente en forma activa en las islas.
Gran cantidad de fallas tectónicas locales recorren la superficie, originando sismos de regular intensidad. Las más grandes son dos fallas transversales al sur de Honshū: la Línea Tectónica de Itoigawa-Shizuoka y la Línea Tectónica Media Japonesa, ambas fallas transformantes que se encuentran en el límite de las placas de Okhotsk y Euroasiática, a lo largo del sistema montañoso de la isla.

Resultan sumamente destructivos los terremotos, a menudo dando como resultado los tsunamis, con una frecuencia de varias veces en un siglo. Los terremotos principales más recientes incluyen el Gran terremoto de Hanshin-Awaji en 1995, el Terremoto de la costa de Chūetsu de 2007 y el Terremoto y tsunami de Japón de 2011. Las aguas termales son numerosas y se han convertido en centros turísticos.

Cada isla cuenta con su propia cadena montañosa, la cual sigue un eje transversal y las divide por la mitad. En Japón hay alrededor de 200 volcanes; sesenta de ellos están en actividad. El más famoso es el Monte Fuji (Fujisan), de 3776 metros de altura, coronado de nieves perpetuas. Le sigue la montaña Kitadake, con de altura. El Asama es el volcán más activo de todo el archipiélago, y está situado en la isla de Honshu a aproximadamente 100 km de Tokio. Tiene una altura de . Casi la tercera parte del país consiste de terrenos de origen piroclástico. La superficie es fundamentalmente montañosa: solo la quinta parte (el 27 %) está formado por pequeñas llanuras, la mayoría de ellas de tipo aluvial y sedimentario a lo largo de la costa.

Japón es la más grande del mundo, después de los Estados Unidos y China, en torno a 4,5 billones de dólares en términos de PIB nominal y la después de los Estados Unidos y China en términos del poder adquisitivo. Su PIB por hora trabajada es el 18º más alto del mundo desde 2006.

Banca, seguros, bienes raíces, venta al por menor, el transporte y las telecomunicaciones son las principales industrias. Tiene una gran capacidad industrial y es el hogar de algunos de los mayores, mejores y más avanzados tecnológicamente productores de vehículos de motor, equipos electrónicos, máquinas herramientas, acero y metales no-ferrosos, barcos, productos químicos, textiles y alimentos procesados. La construcción ha sido durante mucho tiempo una de las más grandes industrias, con la ayuda de contratos públicos en el sector civil por miles de millones de dólares. Ha elevado la libertad económica, la cooperación entre gobierno e industria, el énfasis en la ciencia y la tecnología, y una fuerte ética de trabajo han contribuido al crecimiento económico. Características notables de la economía de este país, incluyen una fuerte unidad entre productores, manufactureros y distribuidores, reunidos en grupos conocidos como keiretsu y la relativamente baja competencia internacional en los mercados internos. Existen varias modalidades laborales, tales como la garantía de empleo vitalicio en las grandes corporaciones.

Recientemente, algunos encargados de formular las políticas han alentado la reforma y las empresas japonesas han empezado a abandonar algunas de esas normas en un intento de aumentar la rentabilidad. La presión fiscal es menor que en cualquier gran país occidental, siendo del 26,4 % del PIB a partir de 2007. Solo una minoría de empleados japoneses paga cualquier impuesto sobre la renta, el impuesto al valor agregado es de solo 5 %, mientras que las tasas de impuestos a las empresas son altos.

Algunas de las compañías más grandes del país incluyen a Nintendo, Nissan Motors, Toyota Motor, NTT DoCoMo, Canon, Honda, Takeda Pharmaceutical Company, Sony, Suzuki, Panasonic, Toshiba, Nippon Steel, Nippon Oil, Tepco, Mitsubishi Estate, y Seven & I Holding. Es el hogar de algunas de las entidades bancarias más grandes del mundo por activos bancarios. La Bolsa de Valores de Tokio con una capitalización de mercado de más de 549,7 billones de yenes en diciembre del 2006 se erige como la segunda más grande del mundo.

Desde el decenio de 1960 hasta la década de 1980, en términos generales el crecimiento económico real se ha llamado el «milagro japonés»: un 10 % de media en el decenio de 1960, el 5 % de media en el decenio de 1970 y un 4 % promedio en la década de 1980. Este crecimiento se desaceleró notablemente en el decenio de 1990, en gran parte debido a las secuelas del exceso de inversión a finales de los años 1980 y las políticas nacionales destinadas a controlar los excesos especulativos de los mercados inmobiliarios. Los esfuerzos del gobierno para reactivar el crecimiento económico tuvieron poco éxito y fueron obstaculizados en 2000 y 2001 por la desaceleración de la economía mundial. Sin embargo, la economía mostró signos de fuerte recuperación después de 2005. El crecimiento del PIB para ese año fue del 2,8 %, con un cuarto trimestre de expansión a 5,5 %, superando las tasas de crecimiento de los Estados Unidos y la Unión Europea durante el mismo período.

Debido a que solo alrededor del 15 % de la tierra es apta para el cultivo, un sistema de terrazas agrícolas se utiliza para cultivar en áreas pequeñas. Esto ha dado lugar a uno de los más altos niveles de rendimiento de cosechas por unidad de superficie en el mundo, mientras que los subsidios agrícolas y la protección son costosos. Importa alrededor del 50 % de sus necesidades de cereales y otros cultivos, y cubre con importaciones la mayor parte de su oferta de carne. En la pesca comercial de peces, se sitúa en segundo lugar en el mundo detrás de China en el tonelaje de pescado capturado. Mantiene una de las flotas pesqueras más grande del mundo, y representa casi el 15 % de las capturas mundiales.

El transporte está muy desarrollado. A partir de 2004, hay de carreteras pavimentadas, 173 aeropuertos, y de ferrocarriles. Los puertos más importantes incluyen el puerto de Yokohama y el puerto de Nagoya. La mayoría de la energía se produce a partir de petróleo, gas natural y carbón. La energía nuclear en Japón producía hasta hace pocos años un tercio de la electricidad, pero tras el accidente nuclear de Fukushima en 2011 se paralizaron la mayoría de las centrales nucleares del país. Desde entonces, Japón ha dado un giro a su política energética, promocionando otras fuentes de energía renovable, como la energía solar fotovoltaica que se ha incrementado en gran medida.

Los principales socios de las exportaciones son los Estados Unidos 22,8 %, la Unión Europea el 14,5 %, China 14,3 %, Corea del Sur 7,8 %, Taiwán 6,8 % y Hong Kong 5,6 % (datos de 2006). Las principales exportaciones japonesas son equipos de transporte, los vehículos de motor, electrónica, maquinaria eléctrica y productos químicos. Con muy limitados recursos naturales para sostener el desarrollo económico, Japón depende de otras naciones para el suministro de la mayor parte de sus materias primas. Sus principales socios para las importaciones son China 20,5 %, los Estados Unidos 12,0 %, la Unión Europea el 10,3 %, Arabia Saudita 6,4 %, Emiratos Árabes Unidos 5,5 %, 4,8 % Australia, Corea del Sur 4,7 % e Indonesia 4,2 % (datos de 2006). Las principales importaciones realizadas son maquinaria y equipo, combustibles fósiles, productos alimenticios (en particular el sector de la carne), productos químicos, textiles y materias primas para sus industrias. En general, los más grandes socios comerciales del Japón son China y los Estados Unidos.

Tras la finalización de la Segunda Guerra Mundial, Japón entró en un período de crecimiento económico constante que le permitió, durante cuatro décadas consecutivas, escalar puestos a nivel internacional hasta consolidarse como la segunda potencia del planeta en términos de PIB, solo por detrás de Estados Unidos. Si bien este crecimiento se volvió más moderado con la llegada del siglo XXI, Japón sigue representando hoy en día una anomalía socio-económica en la región asiática, en la que mantiene un claro liderazgo a nivel económico (renta per cápita), social y cultural. Internacionalmente, de Japón cabe destacar su madurez demográfica: una altísima densidad de población que, sin embargo, se nutre con una de las tasas de natalidad más bajas del mundo: tan solo un único hijo por mujer, ocupando el puesto n.º 163 del mundo en el ranking de países con mayor índice de natalidad. Datos del Banco Mundial revelan la orientación tecnológica del país: Japón ocupa los últimos puestos en terrenos dedicados al sector primario, y sin embargo ocupa los primeros puestos en la penetración de Internet. Como consecuencia, según el Foro Económico Mundial, Japón es el sexto país del mundo en el Índice de Competitividad Global. En la siguiente tabla se puede analizar el contexto socio-económico de Japón a partir de datos del Banco Mundial, Eurostat y el Foro Económico Mundial:

Japón sufre en la actualidad de un descenso en su índice de natalidad (1,3 hijos por mujer), causado entre otras razones por el elevado coste de criar y educar a un hijo. Si a lo anterior se le añade el hecho de que posee el tercer puesto en la población más longeva del mundo (82,07 años), la combinación de menos nacimientos con decesos más tardíos, hace temer por la viabilidad de su sistema de pensiones y la disponibilidad en el futuro de mano de obra suficiente. En 2005 por primera vez el número de japoneses decreció, pues se registraron menos nacimientos que decesos.

"Shoshika" (少子化) es una palabra de reciente acuñación (años 1990), cuya traducción podría ser «disminución en el número de niños» y que en la actualidad es utilizada para referirse esta carencia de infantes cada vez mayor en la sociedad japonesa.

En respuesta a este problema, el gobierno ha elevado la edad de jubilación, pero se prevé para las próximas décadas la continuidad de esta declinación de la población. Además, en 1999 reforzó las leyes contra la discriminación de las mujeres en el trabajo. A su vez, lanzó tres proyectos: Plan Ángel, Nuevo Plan Ángel y Una Propuesta Más, todos ellos orientados a facilitar que las mujeres puedan trabajar y ser madres a la vez. Pero estas medidas chocan con la fuerte tradición que rige la sociedad japonesa.

Como medida complementaria, las empresas solicitan que se bajen las barreras inmigratorias, para permitir la entrada de mano de obra no cualificada. Este proyecto está fuertemente cuestionado, porque terminaría con la homogeneidad social, provocando inevitables roces sociales. Como plan a largo plazo, las compañías invierten grandes sumas de dinero en investigación y desarrollo de robótica. Actualmente, Japón posee de los robots industriales en todo el mundo.

El 27 de marzo de 1997, el poder legislativo reconoció oficialmente a la etnia ainu como aborígenes autóctonos de Hokkaidō, en lo que suponía la primera consideración de minoría étnica del archipiélago pero el acto fue solamente simbólico, ya que se había inaugurado ese año la presa cuya expropiación de terrenos disparó las reclamaciones ainúes.

En el siglo XXI las japonesas continúan la batalla por un espacio legal, político, económico y social recientemente conquistado más allá del papel secular como responsables de la transmisión de los valores que históricamente han tenido. En la década de los setenta las japonesas comenzaron a tener un protagonismo real en el desarrollo del país, pero fue a principios de los noventa con la crisis económica que azotó el país cuando comenzó su «revolución». Las jóvenes aprovechando las grietas en la sociedad por el sentimiento de crisis rompieron parte de sus ataduras.
La Constitución de 1946 reconoció la igualdad de todos los ciudadanos sin discriminación por raza, credo, sexo, condición social o linaje. En 1985 se promulgó la Ley de Igualdad de Oportunidades, en 1992 la Ley de Baja Maternal y en 2001 la Ley para la Prevención de la Violencia Conyugal, leyes que permitieron a las mujeres japonesas tener las mismas medidas de protección legal que las europeas o las norteamericanas aunque en la práctica ninguna de las dos primeras leyes mencionadas incluye una penalización para las empresas en caso de incumplirlas.

En 2016 el mundo empresarial japonés las mujeres son apenas el 7% en los puestos de mando frente al, por ejemplo, 23 por ciento en Estados Unidos. Según un estudio de Goldman Sachs la economía nipona crecería un 15% si ellas se incorporan al proceso de producción.

Las mujeres japonesas lograron el voto en 1946, pero 70 años después poco han avanzado en el Parlamento. En 2014 tan solo 45 de los 475 escaños estaban ocupados por mujeres. En 2016 seguían infrarepresentadas con un en la cámara que sitúa a Japón en el último puesto del ranking de los 20 países más ricos del mundo.

En 2016 por primera vez una mujer en la historia fue elegida gobernadora de Tokio, Yuriko Koike. Una década antes, en 2007, Koike fue la primera mujer al frente del Ministerio de Defensa de Japón.

Los japoneses incorporan los rasgos de muchas religiones en sus vidas diarias en un proceso conocido como sincretismo. Las calles japonesas se decoran en las fiestas de Tanabata, Obon, Halloween y Navidad. Una oración popular cuando se tienen problemas es "«Kami-sama, Hotoke-sama, dōka otasuke kudasai.»" («Dios y Buda, ayudadme de alguna forma, por favor»), que parece implicar una creencia sincretista. Muchas personas, sobre todo aquellas pertenecientes a generaciones jóvenes, sienten que las religiones son parte de la cultura tradicional.

El budismo es la religión mayoritaria; el sintoísmo fue religión oficial del país hasta el siglo VII y actualmente es la segunda religión en número de seguidores. Debido a la influencia histórica de China, también hay confucianos, taoístas, etc. 

El cristianismo, aunque su práctica es minoritaria, está presente principalmente en sus formas de catolicismo y protestantismo. En el caso de la Iglesia Católica en Japón la autoridad máxima pertenece a la Conferencia de los Obispos Católicos del Japón (カトリック中央協議会 (日本語)) instituída en el año 1941, la cual está en plena comunión con el Papa y la Santa Sede.

Además de sus religiones, las supersticiones japonesas están bastante extendidas en Japón y son utilizadas para enseñar lecciones prácticas sobre diferentes aspectos de la vida.

La cultura japonesa ha evolucionado de manera considerable en los últimos años, desde el país original de la cultura Jōmon a su cultura contemporánea, que combina las influencias de Asia, Europa y Estados Unidos. Las artes tradicionales incluyen la artesanía (ikebana, origami, ukiyo-e, muñecos, lacas, alfarería), actuaciones (bunraku, Kabuki, Noh, rakugo), tradiciones (ceremonia del té, Budō, la arquitectura, los jardines, las espadas) y cocina.

La fusión entre la impresión tradicional en madera y el arte occidental condujo a la creación del manga, un formato japonés de Historieta popular dentro y fuera de Japón. El manga ha influido la animación para la televisión y el cine dando origen al anime y el llamado live action movie, normalmente filmes o teleseries encarnadas por actores y basados en series de animación populares. Las consolas de videojuegos japonesas han prosperado desde el decenio de 1980.

La música de Japón es ecléctica, después de haber tomado prestados los instrumentos, las escalas y estilos de las culturas vecinas. Instrumentos, como el koto, se introdujeron durante los siglos IX y X. El recitativo acompañado del teatro Nō fechan del siglo XIV y la música folclórica popular, con la guitarra shamisen, desde el XVI. La música occidental, presente desde finales del siglo XIX, ahora forma parte integrante de la cultura japonesa. Después de la Segunda guerra mundial, Japón ha sido influido por la música moderna de estadounidenses y europeos, lo que ha dado lugar al J-Pop.

El karaoke es la actividad cultural más ampliamente practicada. En noviembre de 1993, un estudio realizado por la Agencia de Asuntos Culturales encontró que ese año, eran más los japoneses que habían cantado karaoke, que los que habían participado en manifestaciones culturales tradicionales, tales como arreglos florales o la ceremonia del té.

Las primeras obras de la literatura japonesa incluyen Kojiki y Nihonshoki, dos libros de historia y el Man'yōshū, un libro de poemas del siglo VIII, todos escritos en caracteres chinos. En los primeros días de la era Heian, el sistema de transcripción conocido como kana (Hiragana y Katakana) fue creado como fonogramas. Kaguya es considerada la más antigua descripción en japonés. Makura no Sōshi, una reseña de la vida en la corte de Heian, es un libro escrito por Sei Shōnagon. Del siglo XI data la primera novela japonesa, su autora fue una mujer, Murasaki Shikibu, la obra, Genji Monogatari (Leyenda de Genji), a menudo ha sido descrita como la primera novela del mundo. La era Meiji, durante el cual la literatura japonesa integró influencias occidentales, vio el declive de las formas literarias tradicionales. La obra que marcó definitivamente el modelo literario de la literatura japonesa moderna fue "Shōsetsu Shinzui" ("La esencia de la novela", 1885) de Tsubouchi Shōyō. Su díscipulo Futabatei Shimei es considerado como el creador de novela japonesa moderna. Otros autores importantes de la misma época fueron Mori Ōgai, Higuchi Ichiyō, Ishikawa Takuboku, Masaoka Shiki y, el que quizá sea el más conocido de este período, Natsume Sōseki. Posteriormente destacaron Akutagawa Ryūnosuke, Tanizaki Jun'ichirō, Yasunari Kawabata, Yukio Mishima y, más recientemente, Haruki Murakami. Cuenta además con dos , los autores Yasunari Kawabata (1968) y Kenzaburo Oe (1994).

La gastronomía de Japón como cocina nacional ha evolucionado en los siglos a causa de muchos cambios políticos y sociales. En la Edad Antigua la mayoría de la cocina estaba influenciada por la cultura china. La cocina cambió con el advenimiento de la Edad Media, que marcó el comienzo de un abandono del elitismo con la normativa del shogunato. Al principio de la Edad Moderna ocurrieron grandes cambios que introdujeron en Japón la cultura occidental.

El término moderno «comida japonesa» ("nihon ryōri", 日本料理) o "washoku" (和食, washoku) se refiere a dicha comida al estilo tradicional, similar a la que existía antes del final del aislamiento nacional de 1868. En un sentido más amplio de la palabra, podrían incluirse también alimentos cuyos ingredientes o modos de cocinarlos fueron introducidos, posteriormente, del extranjero, pero han sido desarrollados por japoneses que los han hecho suyos. La comida japonesa es conocida por su énfasis en la estacionalidad de los alimentos (旬, "shun"), calidad y presentación de sus ingredientes.

Hay muchas opiniones sobre qué es fundamental en la cocina japonesa. Muchos piensan que el sushi o las comidas elegantes estilizadas del formal kaiseki se originaron como parte de la ceremonia del té. Muchos japoneses, sin embargo, piensan en la comida cotidiana de la gente japonesa, en especial la que existió antes del final de la Era Meiji (1868-1912) o antes de la Segunda Guerra Mundial. Pocos japoneses urbanos modernos conocen su gastronomía tradicional.

Tradicionalmente, se considera al estilo de lucha sumo como el deporte nacional ya que es uno de los más populares deportes entre los espectadores. Las Artes marciales como el judo, el kendō y el karate también son ampliamente practicados y gozan de un considerable número de espectadores en el país. Después de la Restauración Meiji, muchos deportes occidentales fueron introducidos y empezaron a propagarse en el sistema educativo.

La Liga Japonesa de Béisbol Profesional fue establecida en 1936 y hoy en día es el Deporte más popular de Japón. Los padres alientan a sus niños a jugar el deporte más amado por los japoneses, además de que los jugadores profesionales son estrellas en su país. Una muestra de lo que significa el Béisbol para los japoneses es que su Selección nacional ha ganado las dos primeras ediciones del Clásico Mundial de Béisbol.
Desde el establecimiento de la Liga de Fútbol Profesional en 1992, la asociación de fútbol también ha adquirido numerosos seguidores. La selección nacional es considerada como la más fuerte de Asia, siendo campeona a nivel continental en cuatro oportunidades.

El golf es también popular, al igual que el automovilismo y la Fórmula Nippon. En 1997 se completó por parte de Honda el Twin Ring Motegi con el fin de llevar la IndyCar Series a Japón, además la Fórmula 1 viaja frecuentemente a Japón para el Gran Premio que se celebra en ese país, generalmente en Suzuka, pero también ha pasado por Fuji, también el mundial de motociclismo de la FIM liderado por MotoGP hace su incursión para el Gran Premio del Pacífico en el Twin Ring Motegi, frecuentemente también iba a Suzuka, pero luego de la muerte del piloto japonés Daijiro Kato en 2003 la categoría dejó de participar allí. También destacan otros deportes como el boxeo, lucha libre (puroresu), baloncesto, hockey sobre hielo, entre otros.

La mejor participación de Japón en los Juegos Olímpicos fue en 2012 cuando obtuvo 38 medallas. En los Juegos Olímpicos de Pekín 2008 también tuvo una destacada actuación con nueve oros, seis platas y diez bronces, siendo finalmente octava en el medallero solo por detrás de China, , Rusia, Reino Unido, , Australia y Corea del Sur.

Además, Japón acogió los Juegos Asiáticos de 1958 y de 1994. También acogió los Juegos Olímpicos de 1964 en Tokio. En septiembre de 2013, la capital nipona fue elegida sede de los Juegos Olímpicos de verano del año 2020, derrotando a otras dos ciudades candidatas finalistas, Estambul (ciudad de Turquía) y Madrid (capital de España).






</doc>
<doc id="1576" url="https://es.wikipedia.org/wiki?curid=1576" title="Jet lag">
Jet lag

El jet lag, también conocido como síndrome del cambio rápido de zona horaria, síndrome transoceánico, descompensación horaria, disritmia circadiana o síndrome de los husos horarios, es un desequilibrio producido entre el reloj interno de una persona (que marca los periodos de sueño y vigilia) y el nuevo horario que se establece al viajar a largas distancias, a través de varias regiones horarias.

El reloj interno de la persona tiende a prevalecer, por lo que, al viajar de este a oeste o viceversa, tendrá sueño en pleno día y por las noches mantendrá un estado de vigilia. 

Entre los posibles síntomas provocados por el "jet lag" se encuentran: 


Quienes estén sometidos a tratamientos que requieran la administración de medicación según un horario, deben considerar la necesidad de modificarlos según prescripción facultativa para compensar la disritmia circadiana; así, puede ser necesario modificar la dosis y el momento de administración de insulina según el número de zonas horarias atravesadas, el tiempo de permanencia en cada destino, la alimentación y la actividad, por lo que se debe determinar la glucemia con frecuencia. Los regímenes pueden requerir modificación en función del tiempo ahorrado en lugar del tiempo local.

Hay estudios que sugieren que un ejercicio intenso por la mañana temprano el primer día tras un desfase horario puede acelerar la adaptación al nuevo horario mejor que tratamientos de luz o de melatonina.

Es posible minimizar los efectos del "jet lag" siguiendo los siguientes pasos antes, durante y después del vuelo. 

Los pasajeros deben ser asesorados para llegar descansados, haber practicado ejercicio y seguir una dieta saludable. Cuando la persona está en buena forma, es más fácil que esté en buena forma después de aterrizar.

También se recomienda visitar a un médico para planificar las conductas médicas que requieren monitorización, las que incluyen ingesta de medicamentos o cualquier otro detalle necesario.
Otro consejo es adaptarse a la zona horaria de destino antes. Esto incluye comenzar la rutina diaria una hora antes o después de que uno normalmente lo hace, tres a cuatro semanas antes de la salida.

Para prevenir la deshidratación, los pasajeros deben ser alentados a no ingerir alcohol y cafeína. La cafeína no sólo produce deshidratación sino que también altera los patrones de sueño. Por el contrario, la recomendación es beber mucha agua para ayudar a contrarrestar los efectos de la sequedad del ambiente dentro del avión.
A los pasajeros se les anima a ejercitar sus piernas mientras están sentados y a moverse alrededor del avión cuando el signo de cinturón de seguridad esté apagado, cada hora o dos.
Una opción para contrarrestar el "jet lag" es el viaje en segmentos más pequeños si es demasiado largo y pasar la noche en alguna ciudad. Y, por último, intentar ajustar las horas de sueño en el avión para coincidir con la hora de destino.

Una forma útil de reducir al mínimo el desfase horario es adaptarse a la hora local. Asimismo, la exposición a la luz del sol durante el día es eficaz y útil.




</doc>
<doc id="1578" url="https://es.wikipedia.org/wiki?curid=1578" title="John Ford (director de cine)">
John Ford (director de cine)

John Ford (1 de febrero de 1894-31 de agosto de 1973) —bautizado como John Martin Feeney y que comenzó su carrera cinematográfica con el nombre de Jack Ford— fue un actor, director y productor cinematográfico estadounidense, cuatro veces ganador del Premio de la Academia. Con una carrera profesional de más de 50 años, en la que participó en casi todas las facetas del arte cinematográfico antes de dedicarse a la dirección, Ford dirigió más de 140 películas, muchas de ellas de cine mudo, y está ampliamente considerado uno de los cineastas más importantes e influyentes de su generación. Cineastas como Ingmar Bergman y Orson Welles lo consideraban uno de los grandes directores de cine de todos los tiempos.

Fue también marino y militar. Participó en la Segunda Guerra Mundial como oficial de los servicios cinematográficos de la Armada de los Estados Unidos y fue herido en combate durante la batalla de Midway. Tras el final de la guerra continuó siendo reservista, colaboró en la realización de documentales durante la Guerra de Corea y la de Vietnam y alcanzó el grado de contraalmirante.

El futuro John Ford nació el 1 de febrero de 1894 (aunque muchas veces diría que en 1895) en una granja de Cape Elizabeth (Maine) y fue bautizado con el nombre de John Martin Feeney, hijo de dos emigrantes irlandeses que le transmitieron su natal gaélico y el amor a su Irlanda de origen. Su padre, Sean A. Feeney, era oriundo de Galway, al igual que su madre, Barbara «Abbey» Curran, si bien la familia de ésta procedía de las islas Aran. Fue probablemente su madre quien inspiró la permanente asociación del hogar con la figura de una mujer presente a lo largo de su filmografía. Hay dudas acerca del auténtico nombre del pequeño, pues el irlandés «Sean» parece haber sido sustituido por el equivalente anglosajón «John», que dio lugar a que se le conociera familiarmente como «Jack». En cuanto al apellido, se escribe de diversas formas, como O'Fienne u O'Fearna. Además, el mismo Ford dijo muchas veces que su segundo nombre era Aloysius. Todo ello motivó muchas polémicas entre sus biógrafos.

Fue el menor de once o trece hijos. A los cuatro años, las dificultades económicas que atravesaba la familia le obligaron a desplazarse a Portland (Maine), sustituyendo la granja familiar por un apartamento. Allí llegó a completar sus estudios secundarios sin que mostrara más inquietudes artísticas que una habilidad para la caricatura muy apreciada por sus amistades. Comenzó a trabajar en el departamento de publicidad de una fábrica de zapatos, y parece que intentó en vano entrar en la Academia Naval de Annapolis; en cualquier caso, Ford mostraría años después su amor por la Marina.

Su hermano mayor, Frank O'Feeney, se había desplazado a Hollywood en 1911. Allí, con el nombre artístico de Francis Ford, inició una prometedora carrera en la naciente industria cinematográfica. El joven Jack se uniría a él en 1913, trabajando a sus órdenes en diversos oficios: regidor, doble de acción, atrezzista, asistente de su hermano y actor. Pronto adoptó el apellido artístico de Francis y se hizo llamar Jack Ford, para disgusto de sus padres, a quienes no agradaba esa actividad profesional. Estos años le sirvieron al joven Jack para familiarizarse con el cine desde diversos ángulos y en diferentes géneros. Su hermano fue no sólo la primera influencia, sino quizá la más importante en su forma de hacer cine, lo que siempre provocó cierta envidia en Jack. Fuera de la tutela de su hermano, Ford participó como extra en el rodaje de "El nacimiento de una nación" (1915), lo que le permitió conocer la forma de trabajar de David W. Griffith, director por el que Ford siempre sintió respeto. Estos años junto a su hermano le sirvieron para conocer la industria, pero todavía no tenía conciencia de las posibilidades reales de la labor de dirección cinematográfica.

El paso a la dirección de Ford parece una evolución lógica en su carrera, aunque el azar tuvo mucho que ver en tal tránsito. Se suele considerar que su primera película como director es "The Tornado" (1917), en la que también figura como guionista. Se trataba de un "western" de corta duración y mudo, protagonizado por su hermano Francis, y resulta dudoso si John ya era el director o se limitaba todavía a ayudar a su hermano asumiendo cada vez más responsabilidades. La película, de la que no se conserva copia alguna, debió limitarse a una sucesión de acrobacias hechas por los especialistas, pero supuso el comienzo de una larga y brillante carrera profesional. De los 62 filmes de diverso metraje que Ford rodó durante la época muda, solo se conservan entre quince y veinte (algunos mutilados), lo que dificulta hacer una valoración global de su obra en este período de formación.

Afortunadamente para Ford, las películas del Oeste no gozaban de mucho prestigio entonces y los directores de los estudios Universal eran reacios a dirigirlas. Eso provocó un vacío que su hermano Francis aprovechó recomendándole al estudio. Ford rodaría un total de 37 filmes para Universal en cinco años. De allí nació una relación profesional y de amistad entre John Ford y el actor Harry Carey, quienes rodarían juntos un total de veinticinco películas mudas de apresurada realización y creciente rentabilidad. Carey fue la respuesta de Universal a actores como Tom Mix o "Broncho Billy" y, de la mano de Ford, compuso un héroe alejado de los arquetipos tradicionales. Su personaje habitual recibió el nombre de "Cheyenne Harry" ("Cayena", en ciertas versiones hispanas), aunque no era muy diferente cuando recibía otros nombres. El actor fue la segunda influencia en importancia en el cine de Ford tras su hermano Francis. El éxito en taquilla de Carey permitió subir poco a poco el salario de Ford. Parece que las películas tenían una excelente fotografía y unos escenarios exteriores que resaltaban la trama violenta. Sólo se conservan "Straight Shooting" ("A prueba de balas", 1917) y "Hell Bent" ("El cowboy vengador" o "El barranco del diablo", 1918).

En enero de 1920, Ford rueda "The Prince of Avenue A", reseñable por ser su primera película ajena al "western". En el verano de ese año, Ford contrajo matrimonio con Mary France McBride Smith, con quien tendría dos hijos: Patrick (1921), quien llegaría a ser productor y realizador de cine de bajo presupuesto; y Barbara (1922), que trabajaría con el tiempo como montadora. En ese mismo año, su hermano Francis abandona definitivamente la dirección y se centra en el trabajo como actor.

A finales de 1920, Ford filmó "Just Pals" ("Buenos amigos"), su primer trabajo con la productora Fox, con la que mantendría una relación casi en exclusiva hasta 1931 y con la que rodaría más de cincuenta películas a lo largo de su vida. Se trata de un "western" "moderno" ambientado en su propia época y que narra la relación entre un vagabundo y un niño en tono de comedia. Aunque Ford siguió rodando algunas películas con Universal y Carey, la nueva productora le permitió trabajar también con Tom Mix. Por esa época realizó un viaje a Irlanda, donde estableció contacto con el Sinn Féin y con el conflicto anglo-irlandés. Volvió a casa habiendo reforzado sus lazos con la tierra de sus padres.

En 1923, rodó su película de mayor presupuesto hasta entonces: "Cameo Kirby" ("Sota, caballo y rey"), protagonizada por la estrella John Gilbert y coloreada en algunas secuencias. Probablemente la importancia del encargo motivó que por primera vez firmara con su definitivo nombre de John Ford.

En 1924, Ford filmó su mayor producción hasta la fecha, el "western" de tonos épicos "The Iron Horse" ("El caballo de hierro"). La película no estaba concebida inicialmente como una superproducción, pero la Fox no reparó en gastos conforme avanzaba el rodaje, desarrollado durante el primer trimestre del año. El film narra en tono de epopeya la construcción del ferrocarril Transcontinental por las compañías Union Pacific y Central Pacific entre los años 1863 y 1869, trama acompañada de una relación sentimental entre los protagonistas, encarnados por George O'Brien y Madge Bellamy.

El rodaje se desarrolló en difíciles condiciones, pues el numeroso equipo no fue a Nevada preparado para el duro clima propio de la estación. Hubo que improvisar alojamientos adecuados para el numeroso equipo. La productora hizo un importante esfuerzo económico encaminado a potenciar el tono épico. Hubo que construir dos ciudades enteras para las tomas generales. Dado que uno de los ejecutivos de la Fox se había encaprichado con la actriz protagonista, se añadieron posteriormente escenas rodadas sin el concurso de Ford para realzar su papel.

Quizá "El caballo de hierro" no sea la mejor película de la época silente de Ford, pero el director demostró saber hacer frente a las adversidades y dirigir a un numeroso equipo en condiciones difíciles. El resultado fue un éxito de taquilla que permitió que la compañía recuperase con creces su elevada inversión. Ello reforzó la posición de Ford en Fox y en la industria de Hollywood, en general. El tono grandioso del film es compensado con cierta ironía, en la que colaboran los personajes de tres viejos borrachines irlandeses (tipo que se hará habitual en posteriores películas del director).

El éxito de "El caballo de hierro" garantizó a Ford la continuidad como director, y a continuación realizó películas de diversa temática con las que experimentó géneros distintos al "western". Tras la desaparecida "Hearts of Oak", melodrama de ambiente marítimo, Ford rodó "Lightnin"' ("Don Pancho"), comedia sin pretensiones aunque excesivamente larga, cuya acción se desarrolla en el peculiar Hotel Calivada, situado justo sobre el límite fronterizo entre los Estados de California y Nevada. La ubicación dará lugar a diversas situaciones cómicas, en las que destacan el matrimonio que regentea el hotel, personajes que prefiguran otros que poblarán más tarde la obra fordiana (como el Jeeter Lester de "Tobacco Road").

"Kentucky Pride" ("Sangre de pista") permitió a Ford introducirse en el ambiente para él grato de las carreras de caballos. La comedia se inicia desde el punto de vista subjetivo del equino protagonista hasta que pasa a contarnos las historias paralelas de su dueño, un hombre acaudalado que pierde su fortuna y su montura, y el mozo de cuadras, un irlandés interpretado por J. Farrel McDonald y que anticipa futuros personajes de Ford. "The Fighting Heart" ("Corazón intrépido") es un desaparecido melodrama que gira en torno a las consecuencias del alcoholismo, reseñable por suponer la primera aparición de un joven Victor McLaglen en el cine de Ford, del que el actor llegaría a convertirse en un emblema.

The "Shamrock Handicap" ("La hoja de trébol") permite a Ford retomar el tema de la equitación. Narra la historia de un bondadoso aristócrata irlandés arruinado por ser generoso con sus arrendatarios. Ello le obliga a vender su mejor caballo para que compita en los Estados Unidos. Lo que podría haber sido una tragedia, adquiere visos de una optimista historia de superación personal en la que el noble, su hija y su mejor jockey emigrarán a Norteamérica, triunfarán en las carreras y regresarán a la patria victoriosos. Tema muy grato a un emigrante de segunda generación como Ford. También narra una emigración desde Irlanda "Mother Machree" ("¡Madre mía!"), un film con el que la Fox experimentó la sincronización de música e imágenes y cuyo estreno se retrasó dos años. Sólo conservada parcialmente, la película es excesivamente sentimental y discursiva y, aunque cercana a la temática habitual de Ford, está lejos en resultado.

"3 Bad Men" ("Tres hombres malos") está considerada por muchos críticos la mejor película del período silente de Ford. Basada en un hecho histórico, la carrera por la disputa de las tierras libres del Territorio de Dakota, podría haber dado lugar a otra superproducción épica como "El caballo de hierro". Sin embargo, aunque la memorable secuencia de la carrera responde a ese planteamiento, el resto de la película se aparta de él. Oscilando con habilidad entre la comedia y el drama, el film presenta a tres bandidos de buen corazón que deciden defender a una joven huérfana y enfrentarse a un malvado "sheriff". Los forajidos, conscientes de que su tiempo ha pasado, se sacrificarán por la muchacha y su novio, al que ellos mismos han ayudado a elegir, en lo que constituye un indudable anticipo del "western" crepuscular.

La película no fue un éxito de taquilla, pese a estar incluida en el género en el que Ford inició su carrera y con el que había conseguido su mayor éxito. Pasarían años hasta que el director volviera a dirigir su mirada hacia el oeste.

Tras la encorsetada "The Blue Eagle" ("El águila azul"), film de ambiente castrense, Ford conocerá su mayor éxito de la era silente gracias al drama bélico "Four Sons" ("Cuatro hijos"). En este caso, público y crítica caminan de la mano al considerarla una gran película. Aunque hoy permanezca casi olvidada, supuso el encumbramiento de Ford a la misma altura de figuras de la época como el mismísimo Griffith. El film trata temas habituales en Ford, como la guerra, la nostalgia de la patria perdida (Baviera en este caso sustituye a la habitual Irlanda) y la emigración como forma de reconstruir la propia vida.

Ford se despediría del cine silente con tres películas muy diferentes. "The Hangman's House" ("El legado trágico") supone una vuelta a Irlanda desde la perspectiva nacionalista que le caracterizó tras su contacto con el IRA, así como a las carreras de caballos. El film es reseñable por suponer la primera colaboración acreditada de John Wayne a las órdenes de Ford, además de contar de nuevo con Victor McLaglen. "Riley the Cop" ("Policías sin esposas" o "El policía sin esposas"), nuevamente protagonizada por J. Farrell McDonald, es una comedia sin pretensiones relacionada con el "slapstick" en torno a un agente que se vanagloria de no haber efectuado nunca una detención y es enviado en misión al extranjero. "Strong Boy" ("¡Viva la ambición!") estaba también protagonizada por McLaglen y parece haberse perdido. Los dos últimos films fueron estrenados como películas mudas pero con sincronización musical, una técnica utilizada por los estudios en la fase de transición al sonoro.

Ford dirigió más de sesenta películas durante era silenciosa del cine. Aunque su carrera se hubiera truncado con la llegada del sonido, como ocurrió con grandes creadores como D. W. Griffith, Erich von Stroheim o Buster Keaton, su obra sería digna de consideración en la historia del cine. Pero Ford tenía todavía muchas más cosas que aportar.

"Napoleon's Barber" ("El barbero de Napoleón") constituye la primera toma de contacto de Ford con el cine sonoro. Es una película corta de Fox que trata una anécdota ficticia: camino de Waterloo, Napoleón Bonaparte se detiene en una barbería para ser afeitado; el barbero, que no le reconoce, se explaya explicando lo que le haría al Emperador si lo tuviera delante... hasta que acaba reconociéndole. Hoy perdida, la película no parece tener mayor interés que el de la experimentación de Ford con el sonido, discutiendo con los técnicos acerca de los límites de la nueva técnica.

Años después, Ford relató a Peter Bogdanovich cómo las productoras les despidieron a él y otros directores con la llegada del sonoro y les reemplazaron por directores teatrales. Cuando éstos fracasaron en una labor que desconocían por completo, Ford y los demás fueron vueltos a contratar con un aumento de sueldo. Según él, el que los actores declamaran su diálogo durante el rodaje no era nuevo, pues ya se hacía durante la época muda en prevención del público que sabía leer los labios. En cualquier caso, Ford fue de los directores que sobrevivieron al desarrollo técnico; y lo hizo gracias a asumir su condición de asalariado que debía obedecer las reglas impuestas por el patrón.

El primer reto serio del director fue "The Black Watch" (conocida como "Shari, la hechicera" o "Shari, la hechicera oriental" en el ámbito hispano). La Fox buscaba un espectáculo de aventuras exóticas de tinte colonialista británico que guardara ciertas similitudes con "Las cuatro plumas", de la que se había rodado una nueva versión ese mismo año 1929. Nuevamente es uno de los actores predilectos de Ford, Victor McLaglen, quien interpreta al oficial protagonista, secundado por Myrna Loy en el rol femenino. La película está lastrada por el deseo de explotar a ultranza las posibilidades del sonido, por lo que abundan las canciones, música militar y alaridos bélicos. Además, los productores contrataron a un director teatral para que rodara nuevas y "postizas" escenas con los protagonistas, en las que la cámara se situaba en plano fijo y los actores declamaban teatralmente, para nuevo disgusto de Ford. Pese a ello, la película tiene algunos apuntes visuales positivos que llevaron al crítico Tag Gallagher a definirla como un "melodrama neowagneriano".

El anterior film cumplió las expectativas económicas, y Ford recibió un nuevo encargo de Fox: "Salute" (conocida en español como "El triunfo de la audacia" o "La audacia triunfa", 1929). Quizá la menor ambición del encargo le hizo pensar que recibiría menos presiones; o quizá fuera la expectativa de rodar en un ambiente agradable (las instalaciones militares de Peaks Island) en compañía de sus amigos Ward Bond y John Wayne lo que le atrajo. El film, protagonizado de nuevo por George O'Brien, narra en tono de comedia la rivalidad existente entre miembros del Ejército y de la Armada de los Estados Unidos (dos instituciones muy gratas al director) que culminará en un partido de fútbol americano.

"Men Without Women" ("Tragedia submarina") supone la primera colaboración del director de Maine con el escritor Dudley Nichols, fructífera unión que se prolongaría durante catorce películas más. El propio Nichols relataría posteriormente la experiencia admitiendo su total ignorancia inicial acerca de cómo se escribía un guion y cómo Ford le enseñó. Pero Nichols sí sabía contar historias y pronto dominó la técnica cinematográfica. El trabajo conjunto de ambos inspiraría algunas de sus mejores películas. Puesto que el guionista había servido en la Marina, propuso un tema naval para su primer film, algo fácilmente aceptado por el director. La cinta relata la tragedia de la atrapada tripulación de un sumergible que se hunde sin remedio y sus desesperados esfuerzos por sobrevivir. El opresivo ambiente es suavizado mediante el habitual uso del humor en pequeñas situaciones colaterales a la trama principal. Ford recordaría más tarde que se trataba de la primera película rodada en un submarino auténtico. Técnicamente sigue siendo una película muda pero con sonido sincronizado, que incluye música (incluso alguna canción), efectos de sonido y algún diálogo.

En "Born Reckless" ("El intrépido"), de nuevo con ayuda de Nichols, Ford asumió el papel contrario al que había sufrido en "El caballo de hierro" o "The Black Watch", pues tuvo que terminar una película encargada a otro director. Puesto que el proyecto no le gustaba, optó por introducir un partido de béisbol como elemento cómico, de forma semejante a como había hecho en "Salute". Algo similar ocurrió con "Up the River" ("Río arriba"), que contaba con un guion carcelario que disgustaba a Ford. Él y el comediante Bill Colliér reescribieron el guion convirtiéndolo en una hilarante comedia de gran éxito en la que los protagonistas entraban y salían del penal constantemente. El resultado es una extraña mezcla de géneros que dio fama a una inusual pareja formada por los casi debutantes Spencer Tracy y Humphrey Bogart, pero la guionista original se sintió muy molesta con Ford.

Más interés tiene "Seas Beneath" ("Mar de fondo"), nueva aventura marítima de la mano de Dudley Nichols y con la colaboración de George O'Brien. En esta ocasión se relata la actuación de la tripulación de un buque "cazasubmarinos" durante la Gran Guerra. Aunque cierta crítica destaca hallazgos expresivos que dotan de gran "fisicidad" a la acción, como la colocación de una cámara en la popa del submarino durante su emersión, Ford quedó molesto por la imposición por parte del estudio de una actriz protagonista a la que él consideraba incapaz.

Mucho menos reseñable es "The Brat" ("La huerfanita"), comedia de la que Ford sólo recordaba años después una enérgica pelea entre dos mujeres.

"Arrowsmith" (estrenada en España como "El doctor Arrowsmith" y en Argentina como "Médico y amante") es una película interesante por varios motivos. En primer lugar, es el primer trabajo de Ford con una productora distinta de Fox Film Corporation tras una larga relación de exclusividad con ésta; la colaboración con el productor Samuel Goldwyn en una obra ambiciosa no fue sencilla para el director. En segundo lugar, constituye la primera aproximación a un tema que luego reaparecería en Ford, la medicina, esta vez a través de la adaptación de una novela de prestigio del reciente Premio Nobel Sinclair Lewis, libro que había sido, a su vez, galardonado con el Premio Pulitzer. Por último, es el primer esfuerzo serio de Ford por describir en profundidad a un personaje complejo.

Aunque la crítica ha considerado posteriormente que es una película fallida en varios aspectos, obtuvo en 1932 cuatro nominaciones a los Premios Óscar de la Academia, entre ellos el de , siendo la primera vez que una obra de Ford llegaba a obtener este tipo de reconocimiento.

El film tuvo consecuencias de otro tipo. Ford incumplió el contrato firmado con Goldwyn que le prohibía beber durante el rodaje, lo que hizo que fuera sancionado por aquél y que, a continuación, Fox diera por concluido el contrato de exclusividad que había disfrutado durante años. A partir de ese momento, aunque Ford siguió colaborando con Fox, quedó en libertad para desarrollar proyectos con otros estudios. Ello significó un importante cambio en la forma de trabajar de un director acostumbrado hasta entonces a estar en nómina de una compañía.

Ford volvió a trabajar con la compañía de sus inicios, Universal, en el rodaje de "Air Mail" ("Hombres sin miedo", 1932). Allí conocerá al capitán de fragata Frank W. "Spig" Weady, condecorado piloto de aviación de la Marina que colaboró como guionista en éste y otros films (entre ellos, "They Were Expendable", de nuevo con Ford), con el que le llegará a unir una estrecha amistad. La película se ambienta en el mundo de los pilotos dedicados al correo aéreo, y su temática se asemeja a la de la gran película posterior de Howard Hawks "Sólo los ángeles tienen alas" ("Only Angels Have Wings", 1939). No obstante, a Ford le falta la vivencia personal que sí tuvo Hawks y que le permitió impregnar la película de verosimilitud, por lo que el film "fordiano" es mucho más frío que el del cineasta-aviador.

"Flesh" ("Carne", 1932) supone la primera colaboración de Ford con la Metro-Goldwyn-Mayer. En este drama, un fuerte Wallace Beery
debe enfrentarse tanto a una banda de "gangsters" como a una temible "mujer fatal". El nombre de Ford no aparece en los títulos de crédito.

Con "Pilgrimage" ("Peregrinos" o "Peregrinación" en sus estrenos hispanos, 1933) Ford volvió a trabajar con Fox Film Corporation. La película está basada en una narración de I.A.R. Wylie, la misma autora del relato que dio lugar a "Cuatro hijos", el mayor éxito de Ford en la época del cine mudo. Nuevamente la historia versa acerca de las relaciones maternofiliales, pero en este caso la madre es una mujer dura que se niega a que su hijo contraiga matrimonio y rompe con él. El hijo morirá en la guerra y la madre sólo se reconciliará con su nuera y nieto tras conocer a otro soldado que ha tenido una experiencia similar a la de su difunto hijo.

En 1933, Ford aceptó el encargo de realizar una película protagonizada por el popularísimo actor Will Rogers. El éxito de "Doctor Bull" propiciará la realización de otras dos películas, "Judge Priest" (1934) y "Steamboat' Round the Bend" (1935), componiendo un ciclo que, por reunir una serie de características propias, se denomina a veces la "trilogía de Will Rogers".

Recobra a Dudley Nichols para "La patrulla perdida" que mete en escena en 1934 la RKO con Victor McLaglen, a quien ofrecería un nuevo gran papel en "Hangman's house". 
Ford detestará siempre su siguiente película "El mundo en marcha" ambientada en los finales del siglo XIX y principios del XX a pesar de que tiene varias escenas de guerra muy realistas.
Más éxito tuvo "Judge Priest" con Dudley Nichols en el guion y el actor Will Rogers que había dirigido el año antes en "Doctor Bull" y que nuevamente dirigiría en 1935 en la película "Steamboat round the bend", justo antes de que éste muriera en un trágico accidente de avión. Esta película es una de las preferidas del director. Se hizo un remake en 1952 titulado "El Sol brilla para todo el Mundo".

En 1934, Ford comenzó a participar económicamente en sus películas. Se compró un yate al que bautizó "L'Araner" en homenaje a Irlanda que tendría hasta 1970. Rodaría dos películas más y empezaría a tener problemas por la presión de Hollywood. Continuó su amistad con John Wayne, que trabajó con él como figurante en sus primeras películas, en "El delator".

En 1935 fundó, con King Vidor, Lewis Milestone, William A. Wellman, Frank Borzage y Gregory La Cava la Asociación de Directores, reemplazando así la Asociación de Directores de Películas. "El delator", realizada muy rápido para la RKO le permitió abordar el tema de la Irlanda británica. No son un misterio su simpatía hacia el IRA. En esta película se descubre al Ford de los decorados interiores, está lejos de sus grandes producciones y decorados clásicos del oeste.
Con este trabajo, inspirado en el cine expresionista recibe su primer que iría a parar a la Asociación de directores fundada anteriormente.

En 1935, 20th Century Pictures absorbió a la Fox, y pasó a denominarse 20th Century Fox, de Darryl F. Zanuck. Realizó junto a su nuevo productor, un gran admirador de Abraham Lincoln, "Prisionero del odio". Los problemas entre Ford y Zanuck comenzaron por el enfrentamiento a causa del acento sureño de Warner Baxter. Ford estuvo a punto de dejar la 20th Century Fox, pero finalmente accedió a los deseos de Zanuck. Desde entonces mantuvieron una estrecha amistad y admiración.

Dirigió a Katharine Hepburn en "María Estuardo" ("Mary of Scotland") para la RKO en 1936. Dirigió también en 1937 "Huracán sobre la Isla" producida por Samuel Goldwyn.

En 1937 se alistó en el Comité cinematográfico de Ayuda a la República Española para ayudar a los republicanos combatientes en la Guerra Civil Española (1936-1939). Se encargó personalmente de enviar una ambulancia con las Brigadas Internacionales.
Fue muy activo también en la lucha contra el nazismo. En 1938 defendió el bloqueo a la Alemania nazi y es nombrado miembro de la Liga Hollywoodiense Anti-Nazi. La firma del pacto germano-soviético le valió la crítica de los comunistas que le acusaron de "propaganda de guerra".

Con "La diligencia", Ford regresó al "western". En esta película cuenta con John Wayne que recibe la oportunidad de su vida y se convertirá en una gran estrella. Los exteriores se rodaron en Monument Valley.
La película fue nominada a ocho Óscar, de los que consiguió el de actor secundario con Thomas Mitchell y el de banda sonora, y Ford recibió el Premio de la Crítica Cinematográfica Neoyorquina.
"La diligencia" se considera la mejor película del Oeste de todos los tiempos.

Después y junto a Zanuck retomó su pasión por Lincoln y rodaron juntos "El joven Lincoln" con Henry Fonda, que será el protagonista de sus dos películas siguientes: "The Grapes of Wrath" ("Las viñas de la ira", "Viñas de ira" o "Las uvas de la ira") (colaboración número doce con el guionista Nunnally Johnson) y "Corazones indomables".
En 1940 ganó nuevamente el . Su talento por fin es reconocido por los profesionales y la crítica.

Volvió a trabajar con John Wayne en "The Long Voyage Home". La última película de Ford antes de la guerra ("Qué verde era mi valle") fue todo un éxito de público y crítica. Recibió cinco Óscar, entre ellos el de mejor película y mejor dirección (arrebatándoselo a "Citizen Kane" de Orson Welles).

En 1939 Ford tuvo la intuición de que América no tardaría en entrar en la Segunda Guerra Mundial. Se puso a la cabeza de un grupo de cineastas que pidieron a Franklin Roosevelt el boicot a la Alemania nazi y fundó un grupo de gente de Hollywood al servicio de la Armada Americana, llamado Naval Field Photographic Unit. Tras el ataque japonés a Pearl Harbor el 7 de diciembre de 1941, se fundaron otros dos grupos similares.

Durante la guerra, Ford y su equipo recorrieron los teatros de operaciones militares. A principios de 1942 fueron al frente del Pacífico y realizaron para la Marina los documentales "7 de diciembre" (sobre el ataque a Pearl Harbor) y "La batalla de Midway" (una batalla decisiva a partir de la cual Estados Unidos empezó poco a poco a ganar la guerra). Las imágenes del ataque japonés a la isla de Midway fueron rodadas por el mismo Ford. Los dos reportajes le valieron un . Realizó también una pequeña película para las familias de las víctimas de Midway llamada "Escuadrón Torpedo". En 1942 se trasladó al norte de África para cubrir el desembarco. Durante 1943 cubrió múltiples operaciones exteriores así como las victorias de los aliados en "Victoria en Birmania" ("Victory in Burma"). Cubre también en 1944 el desembarco de Normandía. Sigue también al ejército durante la preparación del Proceso de Nuremberg.

De febrero a junio de 1945 rodó "They were expendable" para la Metro-Goldwyn-Mayer, con John Wayne, Robert Montgomery y Donna Reed. Esta es curiosamente la única película de Ford sobre la Segunda Guerra Mundial, en la que tan activamente participó. El dinero recaudado por esta película fue destinado para los veteranos de la Field Photo Unit y la Field Photo Farm.

Después de la guerra regresó a Hollywood y a rodó otra vez en Monumental Valley: "Pasión de los fuertes". En "El fugitivo" (1947) trabajó de nuevo con Henry Fonda, a quien permitía interpretar con total libertad.

La dirigió en 1952, de nuevo en compañía de su actor predilecto, John Wayne. La película trata sobre un boxeador norteamericano, Sean Thorton (interpretado por Wayne), que regresa a su Irlanda natal para recuperar su granja y escapar de su pasado. Allí se enamora de una alegre chica, aunque para conseguirla deberá luchar contra las costumbres locales, incluidos el pago de una dote y la oposición del temperamental hermano de su prometida.

La película obtuvo siete nominaciones a los Óscar, incluyendo mejor película, y fue galardonada por dos. Una de las estatuillas fue a manos de Ford y la otra a los directores de fotografía Winton C. Hoch y Archie Stout. Está considerada como una de las mejores películas de la historia del cine.






</doc>
<doc id="1579" url="https://es.wikipedia.org/wiki?curid=1579" title="Jalisco">
Jalisco

Jalisco es uno de los treinta y un estados que, junto con la Ciudad de México, forman los Estados Unidos Mexicanos. Su capital y ciudad más poblada es Guadalajara. Está ubicado en la región oeste del país, limitando al norte con Nayarit, Zacatecas y Aguascalientes, al noreste con San Luis Potosí, al este con Guanajuato, al sur con Michoacán y Colima, y al oeste con el océano Pacífico. Con 7 844 830 habs. en 2015 es el tercer estado más poblado —por detrás de Estado de México y Veracruz— y con 78 599 km², el séptimo más extenso, por detrás de Chihuahua, Sonora, Coahuila, Durango, Oaxaca y Tamaulipas. Fue fundado el 16 de junio de 1823.

Es parte de la macro región del Bajío Occidente o Centro Occidente de México. Es la tierra de los charros, jaripeos, mariachi, tequila y muchas de las tradiciones culturales que en el mundo se asocian con lo "característicamente mexicano". El clima en el estado va de cálido subhúmedo a semiseco templado, destacando el semicálido subhúmedo con lluvias en verano.

Es la cuarta entidad federativa más poblada de México; y uno de los estados más desarrollados en el país en cuanto a actividades económicas, comerciales y culturales. En ciertas partes de la capital y de algunos municipios, el nivel de vida es comparable a países desarrollados. Pero, al igual que en el resto de México, no es representativo de todos los municipios. 

Se divide en 125 municipios. Su capital es Guadalajara, cuya zona metropolitana está compuesta por los municipios de Guadalajara, Zapopan, Tlaquepaque, Tonalá, Tlajomulco, El Salto, Ixtlahuacán de los Membrillos y Juanacatlán, haciendo de ésta la segunda aglomeración urbana más grande de México, después de la capital. Otras localidades importantes son Puerto Vallarta, San Juan de los Lagos, Tepatitlán de Morelos, Lagos de Moreno, Ameca, Ocotlán, La Barca, Atotonilco el Alto, La Huerta, Arandas, Autlán de Navarro, Ciudad Guzmán, Chapala, Zapotlanejo, Etzatlan.

El nombre de Jalisco proviene de la mezcla de tres palabras del náhuatl: "xal-", que significa arena, "īx-", cara o superficie, y la desinencia de lugar "-co". Significa, de este modo, "En la superficie de arena" o "En el arenal". Durante varios siglos, hasta alrededor de 1836, Jalisco se escribió "Xalisco", con X inicial debido a que era la letra utilizada para reproducir el sonido correspondiente a la J hasta que esta última letra se incorporó al alfabeto latino. Además, en náhuatl la letra X reflejaba el fonema ʃ en AFI, o bien el fonema "sh" inglés.

En la región ha existido presencia humana desde hace 15,000 años aproximadamente según lo indican restos humanos, entre ellos fragmentos de cráneos, y diversidad de vestigios de animales, junto con otros testimonios de objetos manufacturados, descubiertos alrededor de las lagunas de Zacoalco y Chapala, que entonces estaban unidas entre sí. Se han podido localizar puntas de flecha, raspadores de cuerno de venado, agujas, punzones, silbatos, anzuelos y colgantes de hueso o colmillos, percutores de hueso de caballo, e incluso una vértebra de ballena con dos golpes producidos por el filo de un instrumento tosco, que fue localizada a fines del siglo XIX en Zacoalco de Torres.

En 618 d. C. se funda el Reino de Jalisco por los toltecas. Su origen y desarrollo se ubica en el horizonte clásico y en el posclásico. Por lo que se conoce actualmente, el señorío de Jalisco fue uno de los más importantes en la región, con relaciones comerciales que se extendieron hacia los pueblos del centro de Mesoamérica con los que realizaban intercambios de productos agrícolas, así como de artículos necesarios en la vida diaria y de ornato.

El señorío de Jalisco comprendió poblaciones localizadas en el occidente hacia la Bahía de Banderas. En esta región se han localizado importantes restos arqueológicos que demuestran el nivel alcanzado. Entre sus poblaciones principales estaban Tepique, Atemba, Pochotitán, Tecuitazco, Xalcocotán, Zacualpán, Xaltemba, Mazatán. El centro de este señorío se localizaba en las faldas del cerro del Coatepec, elevación que alcanza los 1.560 metros de altitud sobre el nivel mar y que domina todo el valle de Matatipac, en el actual municipio de Xalisco.

Aún, con ello, también existieron más señoríos en tierras jaliscienses a las que se suman los sayultecas, los tecuexes que tenían habitados las zonas de Xallostotitlán, Tzapotlán, Tecpatitlán, Tecomatlán, Ayahualicán, Teocaltitlán, Mexticacán, Acatic y Tonallan que estaban en constantes enfrentamientos con sus vecinos como el señorío de Teocaltiche, poblados por Huachichiles y Caxcanes. Mientras tanto, también destacaron los señoríos de Colima y Autlán en el sur del estado; así como la Tradición Teuchitlán en tierras de Ameca, Tequila, Etzatlán y Teuchitlán donde se ubican las pirámides circulares de Guachimontones. Y en el centro del estado en las tierras de Guadalajara y Tonalá existieron los Cocas, una tribu muy relacionada con los Tecuexes tepatitlenses y que ha medida de que se realizaron cambios comerciales con estos pobladores, surge el gentilicio de "tapatio" para los habitantes de Guadalajara, que ese nombre era dado al trueque que los habitantes precolombinos de Tepatitlán daban a los Cocas. Todas estas tribus menores pero igualmente resaltantes, fueron influenciadas por Toltecas, Chichimecas, Estilo Mezcala, Estilo Chupicuaro, Estilo Nayarit y Estilo Tumbas de Tiro.

Tras la conquista de Tenochtitlán por parte de los españoles, el resto del territorio nacional y parte de lo que hoy son los Estados Unidos de América pasaron a formar parte del Imperio Español. Debido a la baja densidad de población, el territorio de la Nueva Galicia no ocasionó problemas para ser conquistado; sin embargo, en Michoacán, los españoles tuvieron que enfrentarse a los indígenas que ofrecieron fuerte resistencia al invasor.

Una vez sometidos los tarascos, en lo que hoy es el Estado de Michoacán, dos razones primordiales hicieron que los españoles siguieran incursionando en dirección al poniente. Por un lado, la búsqueda de un puerto adecuado para establecer un astillero y zarpar de ahí en busca de las costas asiáticas; por otro, localizar los yacimientos que habían abastecido a los tarascos de metales preciosos.

Así, a fines de 1522, Cristóbal de Olid penetró por la sierra de Mazamitla hasta llegar a lo que hoy es Tamazula. Pronto regresó a Tzintzuntzan, la antigua capital purépecha que servía de base de operaciones, dejando a un primo de Hernán Cortés, llamado Hernando de Saavedra, a cargo de las minas del área explorada.

Por instrucciones de Hernando, Gonzalo de Sandoval fundó una villa de españoles entre Tecomán y el mar, a la que le dio el nombre de Colima el 25 de julio de 1523, con lo que se estableció otra plataforma para dominar la región. Como consecuencia, durante el mes de agosto de 1524, Cortés dispuso que otro pariente suyo, Francisco Cortés de San Buenaventura, fuese su lugarteniente en la Villa de Colima y sus comarcas, que repartiera tierras e indios y realizara expediciones hacia el norte para conocer la costa y buscar metales preciosos.

Los pueblos por los que pasaron y los recibieron en paz fueron convertidos en encomiendas de los españoles, sometiendo a los que se opusieron. De esta manera, desde Colima hasta La Barca, además de ruinas, también se fueron asentando algunos expedicionarios que servirían tanto para facilitar el regreso por el mismo camino que siguió de ida, como para asegurar la potestad de Hernán Cortés en toda el área.

A fines de diciembre de 1529, partió Nuño de Guzmán de la Tenochtitlán comandando a 300 españoles, además de siete u ocho mil indios bien provistos de bastimento y a cargo del transporte de 12 piezas de artillería ligera. De paso por Tzintzuntzan trató de obtener todo el oro que pudiera haber quedado en poder de los tarascos, haciendo incluso que su Caltzontzín fuese muerto después de grandes torturas. Sin embargo, los conquistadores se encontraban lejos de consumar la dominación por completo, ya que mientras algunos grupos de aborígenes se remontaron y asentaron en sitios muy poco accesibles de la Sierra Madre, otros causarían aún más problemática antes de someterse por completo al orden colonial.

Vuelto a la vertiente del Pacífico, después de su malhadada incursión por Durango, el contingente de Guzmán tuvo de permanecer varios meses en Culiacán: debió dejar que pasara la época de lluvias para que bajaran los ríos y consolidar el dominio en la comarca. Para esto último convenía fundar una villa de españoles, fundada el día 29 de septiembre de 1531, con un grupo de españoles y con indios que no serían necesarios para el retorno, mismo que habría de iniciarse el 15 de octubre siguiente.

Después de disponer la fundación de Chiametla para que sirviera de apoyo a la comunicación con el norte, Nuño de Guzmán comandó que se adelantara hasta ahí Cristóbal de Oñate para prevenir su arribo. Ante el vacío que encontró en Tepic, Oñate siguió hasta Ahuacatlán, donde supo que un enviado de la Audiencia, Luis de Castilla, se encontraba con instrucciones de fundar un poblado español por el rumbo de Xalisco para acrecentar el territorio español.

La Corona pensó reproducir en lo posible el mapa peninsular en América, de manera que el noroeste de lo conquistado hasta entonces se llamó igual que el noroeste ibérico, y Nuño procuraba de nuevo conectar Nueva Galicia con la Provincia del Pánuco asentando españoles cerca de Nochistlán.

Vuelto a Nueva España desde principios de 1530, Hernán Cortés esperó a que fuesen cambiados los funcionarios de la Real Audiencia de México para reclamar el gobierno de Tamazula y Amula; pero, además, contraatacó solicitando también Ahuacatlán y Xalisco, argumentando que su enviado Francisco Cortés de San Buenaventura había sido el primero en ocuparlas.

Las cinco villas fundadas por iniciativa de Nuño de Guzmán, San Miguel, Chiametla, Compostela, Purificación y Guadalajara, dieron lugar a la primera división administrativa del territorio. Sin embargo, el número de ellas era demasiado pequeño para imponer el modo de vida a que aspiraban los españoles, y su inestabilidad inicial una muestra de que los lugares elegidos con criterio de conquistador no resultaron ser los más convenientes para la colonización. En efecto, al cabo de una década ninguna villa permanecía en el mismo sitio.

Cuando a principios de 1533 Nuño iba rumbo al Pánuco, visitó el solar donde esta villa se encontraba y comprendió que era demasiado grande el esfuerzo requerido para vivir ahí a cambio de las magras ventajas. En consecuencia, accedió a la petición de buscar otra sede, pero sin que los colonos cruzaran la barranca hacia el sur, a efecto de mantener su presencia en la caxcana. Sin embargo, los moradores no acataron este requisito y, cuando Guzmán volvió a mediados de 1534, se los encontró instalados en el valle de Tonalá, más fértil y poblado que cualquier lugar de toda la caxcana; con la ventaja adicional de que eran una mano de obra más apta por tratarse de indígenas sedentarios.

La presencia de una población hispana en estos lugares no era sólo del interés de Guzmán, como lo muestra el hecho de que, para mejorar la situación jurídica de Guadalajara, en 1539 el Rey atendió la solicitud del cabildo de la villa y le concedió las prerrogativas de ciudad y un flamante escudo de armas. De tal modo los aborígenes de Nueva Galicia pasaron a su nuevo estado llenos de virulencia y, por lo mismo, propensos a insubordinarse.

Poco a poco algunos de estos grupos aislados irían adquiriendo mayor coherencia, de manera que, en 1538, empezaron a surgir síntomas de una incipiente revuelta, llamada Rebelión de los Caxcanes, pues se dio en la región que se conoce como Caxcanes, en Jalisco y Zacatecas; a la larga, acarrearía serias mortificaciones a los españoles y provocaría cambios sustanciales en el mapa político de Nueva Galicia.

Los dos principales jefes indígenas rebeldes que se recuerdan son Coaxícar, en la zona de Hostotipaquillo, y Tenamaxtli, vencedores de Pedro de Alvarado, en Nochistlán, Zacatecas. Este murió a causa de una herida en la Guerra del Mixtón.
A esta rebelión también se le conoce como la Guerra del Mixtón, porque así se llama el monte en donde se dio la batalla más importante; el virrey Antonio de Mendoza aniquiló la resistencia en el Mixtón, en octubre de 1541.

Fue al mediar 1540 cuando Oñate comprendió que no bastaban los recursos neogallegos para hacer frente a la situación y pidió ayuda a Mendoza. Este le mandó algunos refuerzos directamente a Guadalajara y ordenó a Pedro de Alvarado que acudiese perentoriamente en defensa de sus paisanos en peligro. Finalmente el Virrey logró ponerse al frente de uno de los mayores ejércitos que se vieran en acción durante toda la época colonial para acudir a pacificar Nueva Galicia. Se dice que sobrepasaba los 50 mil individuos, mismos que el 29 de septiembre emprendieron el camino de Guadalajara a toda la velocidad que le era posible a un contingente de tal magnitud.

Nueva Galicia había sido "pacificada" "a fuego y sangre", "de seis partes de indios murieron cinco", lo cual significa, simple y llanamente, que había sido asolada por el ejército de Mendoza, pero no que se hubiera instaurado la paz completa. Su debilidad, que le impidiera defenderse por sí sola de la revuelta, se había incrementado. Ahora, a causa de ella, quedaba bajo la autoridad militar del virrey de la Nueva España y éste cargaría a su vez la responsabilidad de protegerla, estableciéndose un lazo de dependencia respecto de la ciudad de México que persistiría durante toda la época colonial.

Las noticias sobre la sangrienta Guerra del Mixtón no sólo corrieron por toda la Nueva España, sino también llamaron la atención de las autoridades peninsulares, quienes decidieron, en 1544, que uno de los oidores de la Audiencia de México, se presentase en Nueva Galicia, ordenase su gobierno en forma provisional y rindiese un informe de la situación. En cuanto al obispo, proponía que fuese alguien del clero regular para que fomentara la evangelización y, en cuanto a la Audiencia, que tuviera injerencia también sobre las comarcas de Zacatula y Colima, y que, para evitar abusos, se diluyese su autoridad entre cuatro oidores. Constancia de que el Consejo de Indias tomó en cuenta lo dicho por el oidor es que no pasó mucho tiempo sin que se llevara a cabo lo que solicitó.

La mayoría de las encomiendas neogallegas fueron concedidas por Nuño de Guzmán a sus seguidores, a más de otras que fueron dispuestas por Antonio de Mendoza en manos de aquellos acompañantes suyos que buscaron radicar en las tierras "pacificadas" y habían hecho méritos suficientes durante la campaña.

Es evidente que durante el virreinato, se representó para los naturales una calamidad mayor que la misma guerra para sojuzgarlos. Trabajos excesivos, escasa alimentación, castigos, epidemias, etc., fueron las causas directas del mayor descalabro demográfico de la historia de México. Se calcula aproximadamente una reducción de un 91% entre 1550 y 1650.

Finalmente, había sido en 1560 cuando Guadalajara se convirtió en capital de la Nueva Galicia. Tanto el presidente Morones como el nuevo obispo, Pedro de Ayala, apoyaron la pretensión guadalajareña y el 10 de mayo del año referido se despachó la cédula que concedió el cambio de residencia. Morones hizo su entrada el 10 de diciembre, pero el franciscano Ayala no tuvo que movilizarse ya que estaba residiendo desde hacía doce meses en el convento que su Orden tenía establecido en Guadalajara.

Los habitantes del occidente neogallego, donde la minería no es una actividad económicamente importante, no podían permanecer impávidos ante la evidencia de que los mayores recursos emigraban sin dejarles provecho, pero no pudieron lograr más, en tanto que el Virrey pretendió incluso pasar la capital de Nueva Galicia a Zacatecas, a lo que sí se negó la Corona española. Pero lo que sí se hizo, en 1571, fue establecer una Caja Real en Zacatecas con todas las de la ley y por completo independiente de la Caja tapatia.

Entre las dificultades más graves enfrentadas por los españoles en su afán de armar una nueva sociedad en el territorio sometido, figuró el problema de la comunicación; en primer término, porque el vencedor aún no acertaba a implantar su idioma; en segundo, porque en la tierra se hablaban diferentes lenguajes, propiciando que hasta el trato entre los mismos nativos fuera incierto.

De tal manera, a pesar de las disposiciones oficiales y de los esfuerzos del clero secular en favor de la castellanización, Nueva Galicia vivió durante el siglo XVI un proceso de nahuatlización, tanto de indios con otras lenguas como de los pocos habitantes españoles, tras el cual sobrevendría el mestizaje de usos y costumbres.

La vida de los neogallegos adinerados, como en el resto de la América española, giraba en torno de sus domicilios. En ellos se nacía y moría; se conmemoraban las festividades privadas y algunas comunes; se divertían y atendían negocios, y sobre todo, se jugaba a los naipes de muy diferentes maneras.

De no ser para acudir al templo o a los eventos públicos, aquella oligarquía salía a las calles solo para lo imprescindible. Raras veces se movían a pie; casi siempre recurrían al caballo o al coche, aunque el tramo por recorrer fuese corto. El medio de locomoción estaba tan ligado al estatus que difícilmente se prescindía de él.

De las casas de españoles sólo salían de vez en cuando a la vía pública, sirvientes y empleados de bajo nivel. Las plazas, con abrevaderos al centro, cumplían más bien una función comercial. En sus contornos se instalaban los vendedores que ponían sus comercios por la mañana y los retiraban por la tarde a fin de guardar la mercancía en los almacenes que cada quien poseía en su casa.

Tres cosas llamaban sobremanera la atención al recién llegado de Europa hacia 1621: una era la propensión a bañarse en los numerosos manantiales, por simple gusto o para curarse llagas y dolores; la segunda consistía en el consumo generalizado de chocolate y la última venía a ser el uso del tabaco (mascado o fumado) reiteradamente.

Una de las obras importantes referentes a la historia novogalaica es la Crónica Miscelánea de la Sancta Provincia de Xalisco, escrita por fray Antonio Tello (1567-1653) y publicada en seis tomos.

Los pudientes gustaban de vivir en el centro; de modo que entre más hacia las afueras habitaba una familia, era, sin duda, más pobre. Hasta fines del siglo XVII, no se sabe de una sola casa particular que haya sido toda de cantera. En realidad, ni los edificios públicos lo eran, excepto la catedral y la iglesia de San Francisco.

De acuerdo con el nivel alcanzado por la educación y la arquitectura neogallegas en el siglo XVII, casi nada puede decirse del desarrollo de las letras y de las artes. Tonalá, por caso, uno de los lugares más poblados cuando los españoles llegaron, mantuvo una destreza alfarera que adquiriría gran renombre gracias al consumo que los habitantes de Guadalajara realizaban de sus productos y a las adquisiciones para enviar a México e, inclusive, a España.

En el campo de las letras, el panorama se vio más retrógrado, debido al hecho de que Guadalajara no dispuso de una imprenta hasta el año 1793.

De tal modo, si no lograban los escritores que sus trabajos se imprimieran fuera de Nueva Galicia, sólo podían aspirar a que se hicieran unas cuantas copias de sus originales y circulasen de mano en mano entre un raquítico grupo de lectores. De cualquier forma, algunos pocos acertaron a ver sus textos en letras de molde.

Bajo tales condiciones, pronto se sintieron los primeros efectos de un incremento de los recursos humanos y económicos que se manifestaría, entre otras cosas, en un acelerado desarrollo de Guadalajara y demás poblaciones importantes de la Provincia de Nueva Galicia.

A comienzos del siglo XVIII, franceses e ingleses daban ya claras muestras de estar interesados en participar también de la colonización en América. Pronto se sumaron los rusos, aumentando la preocupación de las autoridades españolas que vislumbraban una competencia y un peligro para sus dominios más septentrionales, además del riesgo de perder las probables riquezas de las tierras aún no colonizadas. De cualquier modo, la colonización de las tierras aún ajenas a la conquista española ocupó un importante sitio en la historia de Nueva Galicia, sobre todo porque dio lugar a una mayor trascendente metamorfosis económica, política y demográfica experimentada por la región. Guadalajara, por lo tanto, pasó a ser el punto de concentración para una larga serie de intereses de toda índole, principalmente económicos. En 1767, la situación cambiaría súbitamente donde imperaban las misiones de los jesuitas. Carlos III, molesto por su resistencia al poder real más las numerosas acusaciones de que era objeto la Compañía de Jesús, se dispuso a proscribirla y expulsar a todos sus miembros de los dominios españoles.

En Guadalajara el trámite se desarrolló sin mayores contratiempos. La madrugada del 25 de junio, por órdenes del Gobernador, se aprehendió a los 12 jesuitas que había en la ciudad y al día siguiente se les envió a Veracruz, donde fueron embarcados con rumbo a Italia. Después siguieron los jesuitas de lo que hoy son los estados de Nayarit, Sonora, Sinaloa y California.

Los jesuitas fueron sin embargo reemplazados por los franciscanos. Tras el descenso de habitantes sufrido por casi todo el Virreinato hasta mediados del siglo XVII, a causa de las continuas guerras con los indígenas, Nueva Galicia inició un considerable crecimiento que se acentuó a partir de 1720, y más aún después de 1760.

Alrededor de 1713, la población de Guadalajara llegaba a unos siete mil habitantes, en tanto que para 1738 se estimaba en alrededor de 12.000 habitantes, 20.000 a mediados de siglo y casi 35.000 al comenzar el siglo XIX. Guadalajara se transformó rápidamente en un centro de comercio privilegiado. Las alcaldías mayores y los corregimientos pasaron a denominarse "partidos", permaneciendo sujetos a su respectiva intendencia mediante subdelegados impuestos por el propio intendente. Se pensaba acabar con el antiguo contubernio de comerciantes y alcaldes, así como imponer orden en el manejo oficial y, sobre todo, en evitar la evasión de impuestos. La Caja Real de Guadalajara engrosó beneficios, aumentando, por ejemplo, al doble sus ingresos entre 1770 y 1800.

Con un total de 26 partidos políticos, inició en su comando la Intendencia de Guadalajara, pero no tardaron en suscitarse algunos cambios importantes. Después de 1803, Juchipila y Aguascalientes se unieron a Zacatecas; Colima pasó a Guadalajara, y desapareció por completo el gobierno de las fronteras de San Luis de Colotlán, cuyo territorio se adhirió al partido de Bolaños, aunque el subdelegado fijó su residencia en Colotlán. Finalmente, Compostela y el departamento naval de San Blas se convirtieron también en partido de la Intendencia de Guadalajara.

Para dar lugar a la independencia debieron enfrentarse criollos contra peninsulares, formando bandos opuestos perfectamente definidos. A este supuesto se contrapone el hecho ya establecido de cómo muchos de los españoles peninsulares estaban, de por sí, más al servicio de los núcleos criollos privilegiados que al del mismo Rey; ello sin considerar que el criollaje no favorecido, al margen de las familias prominentes, recelaba de ambos grupos, y que más de algún miembro de estas esferas encumbradas aún no digería ni olvidaba su profundo resentimiento por haber sido desplazado por unos y relegado por otros. Con la implantación de las intendencias a partir de 1786, se agravó todavía más la repulsa criolla hacia los empleados públicos "gachupines".

La noticia de que Carlos IV había abdicado a favor de su hijo Fernando se conoció en Guadalajara en julio de 1808, y sus autoridades se aprestaron a organizar la jura del nuevo Rey, tal como se había hecho veinte años atrás con Carlos IV. Sin embargo, el reporte luego informó de 16 de julio de la presionada decisión de Fernando VII de abdicar en favor de su padre y éste en favor de Napoleón Bonaparte. Esta maniobra, conocida como las Abdicaciones de Bayona por los españoles, desató una vertiente oposición de casi todos los americanos. En España y sus colonias se sostenía la Doctrina Suareciana del Poder, cobrando auge la idea de que el pueblo era la fuente originaria del poder y que el Rey no podía disponer de él sin su anuencia. Por eso José I, hermano de Napoleón, era considerado como el rey ilegítimo. En España se desató una serie de oposiciones que involucraban el movimiento juntista y la guerra de la independencia española ante Francia.

Así pues, en el caso particular de México, y ante los hechos que agitaban a la Península, correspondía a los componentes de los ayuntamientos decidir qué se haría. Durante los días sucesivos se presentaron ante el Presidente personas de todas las órdenes ofreciéndose en defensa de "Religión, Rey y Patria". Incluso llegaron enviados de las comunidades indígenas a la capital de Nueva Galicia, para ofrendarse también en aras de Fernando VII.

En abril de 1809, las autoridades de la Intendencia juraron obedecer a la Suprema Junta Central Gubernativa de España e Indias, tal y como se había hecho en la Ciudad de México, en tanto que elegían al obispo Cabañas como su delegado en la Suprema Junta. Pero como el suelo hispano, durante el primer semestre de 1809, resultó atacado por la fuerza invasora, y las perspectivas del triunfo español parecían muy remotas, Cabañas no se movió de Guadalajara. Por otro lado, del sur de América empezaron a llegar noticias revolucionarias: ciudades como Caracas, Buenos Aires y Bogotá habían decidido prescindir del gobierno español y aspiraban a tomar la dirección de sus respectivas provincias.

Guadalajara tuvo noticia de la insurrección encabezada por Miguel Hidalgo en Dolores el 25 de septiembre de 1810. El canónigo José Simeón de Uría, recién electo diputado a las Cortes españolas por la Intendencia de Guadalajara, desde las proximidades de Querétaro envió la voz de alerta a las autoridades neogallegas. Para fines de septiembre, el grito de Dolores resonaba en la Nueva Galicia; dos pequeños grupos sublevados hacían acto de presencia: uno, acaudillado por Navarro, Portugal y Toribio Huidrobo, se desplazaría entre Jalostotitlán, Arandas, Atotonilco y La Barca; otro, guiado por José Antonio "El Amo" Torres, recorrería Sahuayo, Tizapán el Alto, Atoyac y Zacoalco.

El 28 de noviembre, los insurgentes de Mercado se emplazaron frente al puerto requiriendo su rendición, lo cual ocurrió tres días después, no obstante que había elementos suficientes para la defensa. Al apoderarse Torres de Guadalajara, de inmediato informó a Hidalgo y a Allende de sus logros y los invitó a tomar posesión de la recién sometida ciudad. Hidalgo recibió la oferta en Valladolid (hoy Morelia) y, sin tardanza, se trasladó a la sede neogallega al frente de casi siete mil jinetes. El 25 de noviembre acudieron a Tlaquepaque las diversas corporaciones civiles y eclesiásticas de la ciudad para recibirlo y escoltarlo durante su entrada. El 29 de noviembre expidió un primer decreto de abolición de la esclavitud dirigido a toda la Nación, pero una semana más tarde, el 6 de diciembre, emitió otro, más conciso, donde su firma se acompañaba por la de Ignacio López Rayón, en calidad de secretario.

A fin de sofocar la rebelión, avanzaron rumbo a Guadalajara los brigadieres Félix María Calleja y José de la Cruz. Hidalgo, al enterarse de ello, salió a encontrarlos al frente de su "ejército", compuesto por ochenta mil hombres. Entre ellos, iban los siete mil indios de Colotlán que comandaba el cura Calvillo, que sólo sabían manejar la flecha y la honda. Aún cuando la superioridad numérica insurgente logró poner en graves aprietos a su contrario, la mejor disciplina y técnica de éste le hizo ganar la batalla. Acto seguido, los principales caudillos rebeldes, acompañados por una pequeña escolta, escaparon hacia el norte, donde tendría lugar el epílogo de la audaz empresa. Calleja, por su parte, entró en Guadalajara el 21 de enero. Esa misma tarde José de la Cruz apareció también en la ciudad. Desde ese mismo momento se propusieron borrar cualquier vestigio de Hidalgo y acabar con los insurgentes que subsistieran en la Intendencia.

No obstante, allí las ideas de independencia permanecieron en el ánimo popular. Máxime que el gobierno del virreinato continuó mostrándose incapaz de oponer las soluciones conducentes a esa desatada disconformidad. Entre 1811 y 1817 se produjo una "guerra de guerrillas" con tres principales y distintos focos de rebelión: el sur de la Intendencia, el lago de Chapala y la zona alteña vecina al Bajío. A fines de 1812 se levantaron también en armas los pueblos indígenas asentados en la ribera de Chapala y en la isla de Mezcala. La causa directa fue la persecución emprendida contra Encarnación Rosas, un excombatiente aborigen. Para evitar ser aprehendido, Rosas armó a un grupo con hondas y piedras y "recibieron a los gachupines con tanta furia, que derrotados volvieron a Chapala...". Siguió una larga serie de enfrentamientos entre ribereños y soldados de la Intendencia que se prolongarían hasta 1816.

La situación se tranquilizó en Guadalajara en 1814 y la economía criolla experimentó un notable desarrollo. El comercio, por ejemplo, recibió un gran impulso al abrirse el puerto de San Blas al comercio extranjero. Por otro lado, a partir de 1811, un número elevado familias habían emigrado del resto de la Intendencia y otros lugares más remotos a la tranquilizada capital neogallega en busca del refugio y amparo que a sus personas y fortunas se les negaba en los convulsionados lugares donde residían. De esa suerte, Guadalajara alcanzó en 1814 los 60 mil moradores, comparada con la cifra de 30 mil, calculada a principios del propio siglo XIX.

Dado el peligro que la Constitución y el liberalismo imperante en las nuevas Cortes representaban para los grupos más privilegiados de todo el Virreinato, un primer mecanismo defensivo sería el de la oposición dentro de las mismas Cortes. La provincia de Guadalajara colaboró con Iturbide, cuando éste hizo su triunfal entrada a la Ciudad de México, al frente del Ejército Trigarante, el 27 de septiembre de 1821. Más tarde, la Constitución Particular de 1824 de la Nueva Galicia prohibió expresamente la esclavitud en su territorio y sobre cada jefe político recayó la responsabilidad de liberar a cuantos conservaran esa condición.

Lo que enderezaría la nave del país con sólo consumar la Independencia no había sobrevenido como se anhelaba, y hasta hubo quien empezara a considerar erróneo el haberse separado de España. En última instancia, se había realizado un viraje político importante: la Independencia, no esperada especialmente por grandes sectores de la población, ni consumada en la forma imaginada por los insurrectos de 1810. O sea que no se habían realizado las transformaciones sociales indispensables para contrarrestar el agobio en que vivía la inmensa mayoría de los habitantes.

De una o de otra forma, los neogallegos debieron adaptar a su cambiante escenario desde las más sencillas e íntimas costumbres hogareñas, hasta los complejos e impostergables mecanismos de subsistencia. En ello quedaba implícito el allegamiento de nuevas fórmulas de diversión, de transporte, de proceder religioso, de educación y de trato con visitantes – nacionales o extranjeros – que empezaron a recorrer la entidad en busca de contactos mercantiles y de otra índole.

En síntesis, los tiempos de la apacible vida neogallega yacían sepultados en el recuerdo de sus antecesores. El Reino de la Nueva Galicia era a partir de ese momento el Departamento de Jalisco.

Al desaparecer el Imperio, los líderes locales pretendieron una completa autonomía, por lo cual se desató una intensa campaña en favor del federalismo que se apoyó en dos grandes figuras: Francisco Severo Maldonado y Prisciliano Sánchez, ambos respaldados por el propio jefe político Luis Quintanar (¿?-1837).

Desde marzo de 1821, había circulado en Guadalajara el Contrato de asociación para la República de los Estados Unidos del Anáhuac, donde Maldonado sostenía que el sistema federal era el más apropiado para gobernar un territorio de grandes dimensiones y para darle mayor cohesión a los habitantes de cada provincia.

Por su parte, el Pacto Federal de Anáhuac, de Prisciliano Sánchez, aparecido en 1823, aseguraba que el federalismo constituía "un invento feliz" de la política porque se ajustaba a las condiciones naturales del hombre, a fin de representar el único medio capaz de moderar la fuerza del gobierno central y la manera más eficaz para que cada individuo desarrollara con plenitud sus virtudes cívicas. Sobre Don Prisciliano Sánchez existe un muy completo estudio biográfico denominado "Reivindicación de Don Prisciliano Sánchez, Precursor del Federalismo Mexicano y Fundador del Estado de Jalisco," publicado en 2003 por el historiador Marco Antonio Cuevas Contreras.

Por su parte, en México se instaló finalmente el nuevo Congreso Nacional el 7 de noviembre de 1823 y, después de acalorados debates, el 31 de enero de 1824 se aprobó el Acta constitutiva federal, cuyo artículo 50 estipulaba que la república habría de ser organizada bajo las bases del federalismo. Fue remitida de inmediato a todos los estados, siendo jurada el 7 de febrero de 1824 por las autoridades de Jalisco, no obstante que en ella se concedían facultades tales al Congreso General y al Ejecutivo que les permitirían controlar desde el Centro a toda la Nación.

El primer gobernador constitucional, Prisciliano Sánchez, y su vicegobernador, Juan N. Cumplido, lo mismo que la I Legislatura del estado, tomaron posesión de sus cargos el 24 de enero de 1825.

La gestión del primer gobernador, que debía concluir en 1829, se vio interrumpida por su muerte repentina víctima de una infección, el 30 de diciembre de 1826, dando lugar a que Juan N. Cumplido se convirtiera ya en la pieza política principal de Jalisco. Hasta el día de su muerte (en 1851) fue nombrado seis veces gobernador interino en periodos que abarcaron de dos meses a un año, a más de resultar electo en tres ocasiones diputado local.

En general, los sucesores de Prisciliano Sánchez continuaron con la misma línea política de este. En el año de 1827, el Gobierno logró intervenir en el manejo de los diezmos y, en marzo de 1829, se privó a la Iglesia de su opción de adquirir bienes raíces y fundar obras pías.

Por otra parte, el uso extensivo de la libertad de imprenta dio lugar a una profusa Boletería que posibilitó la expresión escrita de todas aquellas ideas que las restricciones anteriores habían acallado. Ahora, ni censura ni tribunal alguno podían impedir y, mucho menos, castigar la crítica abierta de cuanto asunto anduviera en boga.

De 1821 data la primera escuela en Guadalajara sostenida exclusivamente con fondos del Ayuntamiento; pero no fue hasta el gobierno de Prisciliano Sánchez cuando se llevó a cabo una intensa campaña de escolarización, en tanto que la Constitución local sentaba el compromiso de crear escuelas de primeras letras en todos los pueblos de la entidad y de elaborar un plan general de estudios. Este fue publicado el 20 de marzo de 1826 y establecía que la enseñanza oficial en Jalisco habría de ser "pública, gratuita y uniforme", en sus cuatro niveles: municipal, departamental, cantonal y estatal. Asimismo, se clausuraron el colegio de San Juan Bautista y la Universidad de Guadalajara a causa de su marcada tendencia colonial, y se fundó el Instituto del Estado con un programa académico más amplio y acorde a lo que el Gobierno esperaba de la educación superior.

En cuanto a la educación de niñas, el Plan prescribía que también se estableciesen escuelas públicas "en todos los pueblos de Estado" para que aprendieran a "leer, escribir, contar, el dibujo y las labores convenientes a su sexo".

Aunque de hecho ya lo estaba desde el triunfo de los planteamientos de Cuernavaca, no fue sino el 23 de octubre de 1835 cuando el federalismo quedó oficialmente suprimido en todo el país. Jalisco y las demás entidades pasaron por entero a depender de México, mientras los partidarios del centralismo, entusiasmados por el triunfo, se lanzaban a demostrar que las cosas iban a marchar mejor en lo sucesivo. 

En junio de 1836, José Antonio Romero cesó como gobernador interino de Jalisco pues pasó al gabinete presidencial, tomando su lugar el vicegobernador Antonio Escobedo, a quién correspondió dar a conocer las llamadas Siete Leyes Constitucionales que fueron proclamadas en la Ciudad de México el 30 de diciembre de 1836.

En el ahora "departamento" de Jalisco, los tres gobernadores habidos entre 1835 y 1841: Romero, Escobedo y José Justo Corro – quien cubrió un interinato de noviembre a diciembre de 1837 –, fueron fieles ejecutores de la voluntad del Centro, a pesar de que los tres eran jaliscienses de nacimiento.

El entusiasmo que despertó el advenimiento del federalismo se vio empañado pronto por las noticias acerca de la invasión de fuerzas militares de Estados Unidos y de que la corbeta de guerra estadounidense Cyane había anclado en San Blas el 2 de septiembre de 1846. No se sabe con certeza cuánto tiempo permaneció el referido buque bloqueando el puerto, pero es evidente que impidió, o cuando menos dificultó, las operaciones de los comerciantes comarcanos, aparte del sobresalto que sembró entre los moradores.

Si bien es cierto que Jalisco veía transcurrir el asedio de las tropas norteamericanas a distancia, por cuanto éstas no daban trazas de intentar un avance o un desembarco por tierras occidentales, el Gobierno del estado no dejó de preparar dispositivos para la defensa en prevención de que la guerra cambiara su curso inesperadamente. Así, al mediar 1847 cristalizaban las negociaciones tendentes a constituir una alianza con los estados de México, Querétaro, San Luis Potosí, Zacatecas y Aguascalientes, pues se reunió en Lagos con representantes de ellos a discutir las maniobras militares conducentes. A mediados de agosto, el gobernador Angulo concurrió a Zamora con sus colegas de México, Zacatecas y Guanajuato para definir nuevas prevenciones destinadas a la salvaguardia del área.

A principios de enero de 1848 arribaron a San Blas los buques Lexington y Whiton, cuya tripulación se apoderó de algunos bagajes sin importancia. El puerto no fue atacado ni retenido por el enemigo; de cualquier forma, la cercana presencia extranjera intimidó al Gobierno de Jalisco. Muy pronto – el 2 de febrero de 1848 – sobrevino el tratado de Guadalupe Hidalgo que puso fin a la guerra. Conforme a tal pacto, México perdía, además de Texas, la Alta California, Arizona y Nuevo México, que en su conjunto significaban un poco más de la mitad del territorio nacional.

Francia, España e Inglaterra acordaron el 31 de octubre de 1861 intervenir militarmente en la República Mexicana, en virtud de la suspensión de pagos ordenada por el presidente Juárez. Posteriormente, sólo los franceses continuaron con la empresa, en aras de otros fines. Al contrario de la indiferencia mostrada cuando la invasión estadounidense 15 años atrás, esta vez Jalisco se aprontó a movilizarse verdaderamente en defensa de la Nación. El propio Congreso estatuyó, antes de disolverse, que los jaliscienses entre los 18 y los 50 años de edad debían prestar servicio militar, de manera que el 2 de mayo, el gobernador Ogazón pudo disponer la organización de 10 cuerpos de infantería y de caballería.

El 6 de enero de 1864, arribó a la capital de Jalisco el ejército francés llevando a la cabeza al mariscal Aquiles Bazaine, substituto de Forey. Nadie opuso resistencia, pues Arteaga tenía dos días de haber salido con la tropa hacia el sur de Jalisco, dando lugar a las expresiones despectivas de los soldados jaliscienses que hizo públicas Bazaine, vaticinando que la "pacificación sería muy rápida". Mas la guerra de guerrillas resultó a la larga mucho más dañina para el invasor que el enfrentamiento abierto.

A consecuencia de las derrotas sufridas por los franceses en Europa en octubre de 1866, se hizo inminente el total retiro de las fuerzas expedicionarias en México, máxime que el ejército imperial ya mostraba serias cuarteaduras y empezaba a dar graves tumbos en distintas partes del país.

Eran tiempos malos los que venían: la dictadura de Santa Anna, la Revolución de Ayutla y la Guerra de tres años, causaron serios daños a la educación. De este modo, en 1860 – un año antes de la muerte de López Cotilla – sólo subsistían 19 escuelas oficiales en Guadalajara y, peor aún, al restablecerse en 1867 el régimen republicano, luego de la invasión francesa, Guadalajara no contaría más de 11 planteles municipales que atendían un total de 590 niños y 69 niñas.

Benito Juárez fue reelecto Presidente de la República por resolución mayoritaria del Congreso; pero se mantendría en el poder muy debilitado por la disidencia de Lerdo de Tejada y Porfirio Díaz que ya encabezaban sendas facciones de liberales. Debilitamiento que no dejó de repercutir en Jalisco, por cuanto la Unión Liberal se erigió en el principal enemigo del Gobernador, propiciando una enconada lucha política que sólo terminaría cuando los vallartistas consiguieron consolidarse en el poder en 1871. Mientras los diputados esperaban a que concluyera el periodo constitucional de Gómez Cuervo, éste completó el número necesario de magistrados para reinstalar en noviembre al Supremo Tribunal de Justicia, suspendido a raíz del cese de su presidente. En febrero de 1871, la Legislatura estuvo ya constitucionalmente en tiempo hábil para regularizar sus funciones, mas el Gobernador, alegando su mala conducta anterior, no la reconoció.

Hacia 1878, la superficie de Jalisco – calculada entonces en – albergaba en sus doce cantones, 30 departamentos y 118 municipalidades que conformaban la estructura territorial del estado, más del 10% de los 9,5 millones de mexicanos; aunque el Séptimo cantón – Tepic –, con seis departamentos y 28 municipios, de hecho ya no pertenecía a Jalisco desde que, en 1867, había sido convertido en distrito militar. Comoquiera, sus pobladores llegaban a la cifra de 857.000, mayor que la de cualquier otra entidad. Más del 70% vivía en áreas rurales y tenía a la agricultura como principal ocupación, tanto que, en 1877, las cosechas jaliscienses alcanzaron el 16,5% de la productividad de todo el campo nacional. Jalisco era el mayor cultivador de maíz, frijol y trigo. El primer lugar correspondía al maíz y el segundo a los otros dos cereales acompañados de algodón, la caña de azúcar y el tabaco, cuyos respectivos volúmenes, a más de satisfacer la industria local, lograban colocar excedentes en otras partes. En seguida estaba el cultivo del agave que, año tras año, se convertía en creciente riqueza agroindustrial a consecuencia del mayor consumo del "vino mezcla" o tequila, que había sobrevenido a raíz de la fiebre del oro en la Alta California. Asimismo, aunque en cantidad mucho menor, los suelos jaliscienses cosechaban ajonjolí, papa, lenteja, arroz, cebada, chile, comino, garbanzo, haba, etc.

Cuando Porfirio Díaz fue elegido por gran mayoría en febrero de 1877, Ignacio L. Vallarta ganó la presidencia de la Suprema Corte de Justicia, lo que dio vuelo a sus aspiraciones de suceder a Díaz y ocasionó la escisión entre ambos comandantes.

Entre las principales acciones del nuevo gobierno estuvo la de fundar un Monte de Piedad y Caja de Ahorros. Asimismo, promulgar en mayo de 1887 un nuevo Reglamento de Instrucción Primaria por medio del cual el Gobierno del estado absorbía los gastos de la educación elemental y, en junio de 1889, otra Ley Orgánica de Instrucción Pública que imponía el laicismo. Además, a mediados de 1888 inició la construcción de un mercado en Guadalajara y dispuso convenientes reformas a la Escuela de Medicina.

Asimismo, en 1889, Corona pudo vanagloriarse de que la tranquilidad pública se había mantenido "sofocándose pronto y enérgicamente la intentona de algunos malhechores".

La principal acción del gobierno de Ramón Corona se enfocó a promover el comercio mediante la supresión de las alcabalas, a partir de marzo de 1888, y la introducción en Guadalajara del ferrocarril procedente de la ciudad de México, cuyo primer viaje concluyó el 15 de mayo de 1888 en medio de grandes fiestas.

Desde 1882, el gobernador Riestra había conseguido la autorización para fundar el "Banco de Jalisco". Sin embargo, los estatutos propuestos no fueron aprobados porque se contraponían con varios artículos de la Constitución. No fue sino hasta un año después, cuando Tolentino volvió a la carga y el Congreso local lo autorizó para que designara al grupo de accionistas que habría de establecer en definitiva el Banco de Jalisco, institución que efectuaría, exenta de cualquier gravamen, operaciones de depósito, descuento, circulación y emisión de dinero.

En cambio, antes de concluir 1883, sí pudo establecerse una sucursal del Banco Nacional de México, que terminó por potenciar en Jalisco el inicio de las actividades crediticias, en las cuales, además de participar como socio de algunos capitales, el estado se vio favorecido con la apertura de una cuenta de crédito hasta por 30 mil pesos. Años después, en 1889, se establecería también en Guadalajara una sucursal del Banco de Londres y México.

La ganadería, que desde tiempos antiguos había sido una de las actividades económicas más importantes, al declinar el porfiriato también registró un cierto descenso. De tal suerte, si en 1903 tenía un valor superior a 18,5 millones de pesos, para 1909 se hallaba en menos de 17; tal descenso también puede ser valorado por medio del número de bovinos; un millón en 1903 que en 1909 bajó a 735.000. A pesar de ello, hasta 1902 Jalisco fue el primer productor de ganado vacuno y de leche con el 10% de la existencia nacional, y de ganado porcino con el 9%. En lo que se refiere a su precio también subió casi un 40% entre 1890 y 1910.

Para 1895 el valor total de las cosechas en Jalisco casi alcanzó 15 millones de pesos, 8% del total nacional; en 1901 subió a 23 millones (casi el 9%) pero en 1904 bajó a 17 millones (el 7%), y aunque en 1906 tornó a subir, ya no recuperó el nivel de 1901.

El creciente interés por perpetuar el rostro propio encontró un nuevo satisfactor en la cámara fotográfica. Sobre todo porque el costo de una fotografía, mucho más bajo que los honorarios de cualquier pintor, permitieron a muchas más personas poseer la reproducción. En efecto, aun cuando los primeros en fotografiarse fueron los más acaudalados, pronto innumerables fotógrafos ambulantes recorrerían pueblos y ciudades en busca de clientes de menores recursos dispuestos a posar frente a sus voluminosos aparatos. Parece ser que fue Jacobo Gálvez, en 1853, uno de los primeros en traer a Guadalajara, después de su viaje por Europa, los elementos técnicos para reproducir imágenes casi instantáneas: una cámara obscura para fijar imágenes, no en lámina como se hacían ya en aquella época y según el método de Daguerre, sino en papel.

Al finalizar el siglo XIX, quienes se habían mantenido en la cúspide de la pirámide socioeconómica de Jalisco se encontraban de hecho concentrados en Guadalajara, donde gozaban de las crecientes comodidades y mejores perspectivas pecuniarias que el medio ofrecía. Más ahora, esta minoría se encontraba rodeada por una buena cantidad de europeos que se habían asentado en Guadalajara, atraídos por sus posibilidades comerciales, y muchos hasta casados con hijas de los más opulentos, incorporando así sus apellidos a la flor y nata de aquella sociedad.

De 1904 a 1909, Porfirio Díaz eligió Chapala para descansar cada año durante las semanas Santa y de Pascua, con lo cual también colaboró a poner de moda a la población entre las ricas familias tapatías, quienes acabaron transformando la aldea en un verdadero sitio de descanso.

Hacia 1909, aparecieron las lanchas de motor y los deportes acuáticos; en 1910 se fundó el "Yacht Club" y la "Compañía de Fomento", misma que construyó la estación y la vía ferroviaria y fue propietaria del servicio de vapores Vicking y La Tapatía, ambos destrozados por un fuerte oleaje en 1926. Un año antes se había acondicionado el antiguo Camino Real de Guadalajara que mucho impulsaría el flujo turístico sobre Chapala.

Antes de 1908, no hubo en Jalisco una oposición al Gobierno verdaderamente organizada. Más bien se manifestó en reducidos grupos de estudiantes, profesionistas y ciertos mineros y obreros textiles que llevaron a cabo algunas huelgas. De hecho, la crítica de mayor trascendencia se debió a personajes como Roque Estrada, Ignacio Ramos Praslow y Miguel Mendoza López, aglutinados en torno a un partido de nombre "Obrero Socialista", del que emergió una publicación llamada Aurora Socialista. Pero en febrero de 1908, Porfirio Díaz manifestó a un periodista estadounidense su deseo de retirarse pronto del poder y el agrado con que vería a un partido de oposición para las elecciones de 1910.

Acompañado de Roque Estrada, Francisco I. Madero estuvo en Guadalajara en diciembre de 1909. Pese a los obstáculos puestos por el Gobierno, pudo llevar a cabo un mitin que patentizó una gran popularidad; pero mayor aún resultó la concurrencia en mayo de 1910, cuando volvió a Guadalajara ya como candidato formal a la "Presidencia de la República" y con un proyecto más preciso, además de las instancias de corte político que había manejado antes.

Tan pronto como se dieron a conocer los resultados de los sufragios que dieron a Madero el triunfo, el Gobierno de Jalisco se dio a la tarea de restaurar el orden constitucional. Se convocó a elecciones municipales para el 5 de noviembre, manifestándose ya una clara preponderancia del Partido Católico Nacional (PCN), que ganó la mayor parte de las alcaldías. Ello se refrendó al restaurarse el Poder Legislativo local, en marzo de 1912, con doce diputados propuestos por el partido de referencia.

En Jalisco, además de que su Congreso enunció su propuesta de que la propiedad territorial fuese accesible a un mayor número de habitantes, se declaró también en favor de que la condición de los trabajadores mejorara y de que se diera fin a las injusticias. Los cambios, decían, habrían de realizarse mediante una evolución lenta y firme, ""sin lucha de clases, pero con medidas enérgicas"".

En marzo se estableció el descanso dominical obligatorio y en julio se reconoció el derecho de los trabajadores a organizarse y se confirió personalidad jurídica a los sindicatos, a la sazón controlados por el clero en su mayoría. Mas, por otro lado se dispuso la militarización de los empleados comerciales y que cualquier huelga no autorizada fuese reprimida con celeridad.

El 8 de julio de 1914, con Álvaro Obregón al frente, las fuerzas constitucionalistas desplegaron su triunfalismo demostrando su ánimo anticlerical. El avance había transcurrido por la costa del Pacífico, donde las fuerzas de vanguardia de Manuel M. Diéguez, Rafael Buelna y Lucio Blanco habían abierto el camino después de apoderarse de Acaponeta, San Blas y Tepic.

La ocupación de la capital tapatía se realizó pacíficamente, pues la plaza había sido evacuada, pero el gobernador huertista José María Mier y sus tropas fueron sorprendidos en El Castillo por Lucio Blanco y Enrique Estrada: el ejército fue desbandado y Mier resultó muerto.

Las fuerzas revolucionarias no fueron bien recibidas en la capital de Jalisco. No sólo los miembros del clero, como afirmó Obregón, se opusieron al nuevo gobierno. El rechazo se hizo más patente a medida que empezaron a implantarse las reformas y decretos expedidos por el Gobierno constitucionalista.

El 11 de diciembre, Medina derrotó a los carrancistas e hizo que Diéguez se retirara a Ciudad Guzmán, de manera que, en cuanto lo alcanzó Villa, pudieron entrar juntos a Guadalajara sin mayor dificultad. Aquí fueron recibidos con grandes muestras de entusiasmo, dada la esperanza de que anularían las disposiciones constitucionalistas. En primer lugar, Villa nombró gobernador de Jalisco a Julián Medina, quien de inmediato prohibió la moneda carrancista y puso en circulación la propia; a su vez, prometió seguridad tanto al trabajo como a la capital y decretó que los inmuebles de la clase acomodada, confiscados por el general Diéguez, volviesen a sus antiguos propietarios, en tanto que ordenaba reabrir al culto los templos que fueron cerrados durante el gobierno de Diéguez y liberar a los sacerdotes presos.

Para los primeros días de 1915, Diéguez había fortalecido a su ejército y retornaba a Guadalajara, así que reinstaló su gobierno en Guadalajara sin mayor represalia y, de inmediato, se aprestó para continuar la campaña. El 18 de abril de 1915, Diéguez se apoderó nuevamente de Guadalajara, tras derrotar al general Medina que huyó rumbo a Lagos. Después designó a Manuel Aguirre Berlanga, una vez más, como gobernador interino, en tanto él iba en busca de Obregón, que daba los últimos toques a su campaña contra los restos del ejército enemigo.

Por otra parte, el pleito en las entrañas mismas de la Revolución hizo que las resoluciones referentes a un cambio radical en las estructuras socioeconómicas nacionales, reflejadas principalmente en las relaciones obrero-patronales y en la tenencia de la tierra, adquirieran un carácter ambiguo, destacándose mejor la precisión de las propuestas de la doctrina social católica.

La legislación agraria carrancista del 6 de enero de 1915 – incorporada al estado por Diéguez en marzo del mismo año – no había resultado prevalecedora. De ahí las reclamaciones campesinas y que pronto algunos trabajadores agrícolas pasaran a tomar tierras, no obstante que Aguirre Berlanga amenazó con castigar severamente a los autores de tales "atropellos". Los conflictos siguieron hasta el extremo de que el propio Diéguez pidió al Constituyente de Querétaro que la nueva Carta tuviera en mente a los campesinos mestizos pobres y no sólo a los indígenas.

Resultado de la Constitución de 1917 fue también el incremento de la entrega de tierras; sin embargo, no todos los demandantes y necesitados la recibieron de momento. Como la reforma agraria funcionó en relación directa con el apremio campesino, los primeros grupos beneficiados fueron, o bien comunidades indígenas despojadas no mucho antes, o aquellos pueblos mayormente afectados por la crisis de principios de siglo que se habían distinguido por su participación activa en el movimiento revolucionario.

Siendo ya presidente electo, en octubre de 1920, Álvaro Obregón se manifestó partidario de la pequeña propiedad y de que cada campesino tuviese una parcela cedida por los latifundistas. En consecuencia, después de tomar posesión el 1 de diciembre, expidió una serie de decretos encaminados a regular la extensión y funcionamiento de los ejidos e instauró las procuradurías de pueblos para proporcionar a las comunidades el auxilio legal preciso, también legisló sobre las grandes y pequeñas propiedades privadas, declarando inafectables a las que constituían unidades agrícola-industriales de producción.

En el mes de octubre de 1921 fue celebrado en Guadalajara un Congreso de Obreros Libres, en el que estuvieron representados 35 mil trabajadores adheridos a las uniones católicas del país. Todos se manifestaron contra la sindicalización y a favor del mutualismo como forma de organización laboral, además de que condenaron las huelgas y todo aquello que tuviera que ver con los "obreros rojos" de la CROM (Confederación Regional Obrera Mexicana) y de la recién fundada CGT (Confederación General de Trabajadores).

Si bien es cierto que en 1926 las condiciones laborales garantizadas por el poder civil sobrepasaban a las que estaba dispuesto a conceder el régimen, no menos lo es que el problema de la tenencia de la tierra distaba de estar resuelto satisfactoriamente.

Por eso al iniciarse el choque violento entre la Iglesia y el Estado, mientras los obreros desertaban de las filas católicas, éstas se engrosaban con campesinos dispuestos a defender sus medios de subsistencia. 
por Fátima Elizabeth Ramos Ortiz

Jalisco es un estado libre, autónomo y soberano a la federación de México. Su gobierno se divide en tres poderes que son el ejecutivo, legislativo y judicial. El poder ejecutivo está a cargo del gobernador del estado con un período de gobierno de seis años, que es elegido democráticamente, el gobernador es el que tiene que coordinar todos los programas de desarrollo para el estado. El poder legislativo está conformado por los diputados locales que forman el congreso del estado y los eligen por tres años, en él se discuten las reformas a las leyes del estado y el presupuesto. Por último al poder judicial le corresponde aplicar las leyes, el gobernador nombra a los miembros del poder judicial. El actual gobernador es el priísta Aristóteles Sandoval para el período 2013-2018, colocando el fin de 18 años del PAN ejercidos en el estado. Cabe mencionar que en las pasadas elecciones a gobernador, la izquierda tuvo un crecimiento importante, desplazando así al partido que gobernó por 3 sexenios consecutivos al 3. sitio de preferencia.

En total el estado comprende , distribuidos en 12 regiones con una subregión, cada región tiene un municipio sede designado por la importancia y ubicación estratégica de dicho municipio en la región respectiva. La división en regiones es una simple división administrativa que facilita el manejo del estado. Las regiones administrativas son las siguientes:

El Estado de Jalisco se localiza en la zona occidente de la República Mexicana. Se encuentra limitado al norte por los Estados de Zacatecas, Aguascalientes; al noroeste con Nayarit; al noreste con Guanajuato y San Luis Potosí; al sur con Colima; al sureste con Michoacán y al suroeste con el océano Pacífico. Tiene una extensión territorial de 80.137 km², lo que representa el 4,09% de la superficie total de México.

Jalisco tiene problemas de límites territoriales con sus vecinos, en especial con el Estado de Colima, con quien disputa una muy importante zona de la costa. Tradicionalmente los límites entre entidades se han definido por límites naturales, en este caso el límite es un río, casi en su desembocadura en el océano Pacífico. El conflicto limítrofe se inició cuando se modificó el curso del río, quedando la zona de playa en la parte que pertenece a Colima y que Jalisco tiene intención de reclamar por su potencial económico a través del turismo que actualmente recibe como en el Complejo Grand Bay - Isla Navidad. Actualmente la solución del problema entre estos dos estados depende del Senado de la República.

Actualmente Jalisco cuenta ya con la más alta tecnología en cuanto a prevención de desastres naturales, hace poco se colocaron en las costas del estado de Jalisco alarmas de tsunamis(maremotos) con las cuales no contaba.

El estado de Jalisco encierra áreas que corresponden a 4 provincias fisiográficas de México: Eje Neovolcánico, Mesa Central, Sierra Madre Occidental y la Sierra Madre del Sur.

Provincia del Eje Neovolcánico
Representada en el estado por las subprovincias: Bajío Guanajuatense, Sierras y Bajíos Michoacanos, Altos de Jalisco, Chapala, Guadalajara, Sierras de Jalisco, Sierras Neovolcánicas Nayaritas, Volcanes de jalisco y Escarpada Limítrofe del Sur.

Sólo una pequeña porción, al sureste del municipio de San Diego de Alejandría, penetra en el estado de Jalisco y se asocia a un solo sistema de topoforma; el llano de piso rocoso que representa el 0,001% de la superficie total del estado.

Es un rincón muy pequeño de esta subprovincia el que penetra en el estado de Jalisco y abarca parte de los municipios de Ayo el Chico y Degollado; presentando tres sistemas de topoformas: Mesetas Lávicas, Lomerios de Colinas Redondeadas con Terrenos Ondulados y Valles de Laderas Teñidas.

Subprovincia de los Altos de Jalisco 
La mayor parte de esta subprovincia queda dentro del estado de Jalisco, se caracteriza por amplias mesetas de origen volcánico y presenta la mayor densidad de topoformas degradativas, generadas por disección hídrica y abundancia de valles profundos de laderas escarpadas a fines de los caños de la Sierra Madre Occidental. Representa el 17,51% con respecto a la superficie total de la entidad y se distinguen en ella los siguientes sistemas de topoformas: Escudo-Volcanes Aislados o en Conjunto, Pequeña Meseta asociada con lomeríos, Gran Meseta con Cañadas, Meseta Lávica, Meseta Lávica asociada con lomeríos, Meseta Escalonada, Lomerío de Colinas Redondeadas, Lomeríos Suave en Arenisca Conglomerado, Valle de Laderas Escarpadas asociadas a lomeríos, Valle con Terrazas, Cañón y Depresión.

Subprovincia de Chapala 
Esta subprovincia alcanza una magnitud significativa en afallamiento asociado con manifestaciones volcánicas y grabens (áreas hundidas entre sistemas de fallas). Se tiene aquí a 1.500 msnm el mayor lago del país, cuyas aguas ocupan un enorme graben ubicado entre sistemas de grandes fallas este-oeste y otras más pequeñas dirigidas burdamente de norte a sur. Por otro lado, el vulcanismo se desarrolló a lo largo de algunas líneas de fallas y levantó las sierras que bordean el lago. El resultado es un paisaje de origen unitario pero de morfologías combinadas que aportan una notable singularidad a la provincia.

En la subprovincia de Chapala se distinguen 4 regiones o sectores:

1. Una región occidental con importantes sistemas de fallas noroeste-sureste y norte-sur que han generado grabens con esos mismos rumbos y que forman los vasos de los lagos Atotonilco, Zacoalco, San Marcos y Sayula, situados a una altitud de 1.350 msnm.

2. El propio lago de Chapala y las Sierras de Laderas de Escarpa de falla que lo circundan, más su extensión cenagosa al este: La Ciénega de Chapala. El lago, bastante somero, mantenido fundamentalmente por los aportes del río Lerma al que recibe en el extremo oriental.

3. Las sierras afalladas y llanos al norte de los lagos.

4. Las sierras afalladas y la región de lomeríos al sur de los lagos

Dentro del estado de Jalisco la subprovincia de Chapala presenta los siguientes sistemas de topoformas: Sierras de Laderas Abruptas con Cañadas; Sierra de Laderas Tendidas; Sierra con Laderas de Escarpa de Falla; Sierra con Ladera de Escarpa de Fallas y Mesetas; Escudo-Volcanes Aislados o en Conjuntos; Sierra Volcánica con Mesetas; Lomeríos Asociados con Llanos; Lomeríos Suave (tobas); Lomeríos Suaves (conglomerados y areniscas); Valle de Laderas Tendidas; Valle de Laderas Tendidas con Terrenos Ondulados; Depresión; Gran Llano; Pequeño Llano Aislado y Llano Salino.

Subprovincia de Guadalajara 
Esta pequeña subprovincia queda toda dentro del estado de Jalisco ocupando el 3,73% de la superficie. Cubre totalmente los municipios de Antonio Escobedo, El Arenal, Guadalajara y Zapopan, Ahualuco de Mercado, Amatitán, Etzatlán, Hostotipaquillo, Magdalena, San Marcos, Tala, Tequila, Teuchitlán, Tlaquepaque y Tonalá.

La subprovincia se caracteriza por las notables manifestaciones de vulcanismo explosivo, que data de tiempos relativamente recientes y cuyas huellas se observan en la ciudad de Guadalajara y en la sierra de la primavera.

A pesar de ser una subprovincia pequeña es la menos uniforme, teniendo una gran complejidad en su panorama fisiográfico, en el que se encuentran sistemas tan distintos como sierras, mesetas, lomeríos y llanos; sin embargo, en general su litología está constituida por rocas ígneas extrusivas ácidas, vidrios volcánicos (obsidiana) basaltos y nubes ardientes.

Esta subprovincia inserta totalmente en el estado de Jalisco, está constituida por dos tipos básicos de topoformas generales: montañas y mesetas. Entre sus extremos norte y sur, las cadenas montañosas se encuentran acomodadas de tal modo que describen la forma de una burda letra "S".

Dentro del área rodeada por la curva superior de la letra quedarían alojados los sistemas de topoformas más occidentales de la vecina subprovincia de las Sierras de Jalisco. Varias cumbres de los núcleos montañosos de rocas ígneas que componen la sierra se levantan por encima de los 2.000 msnm, en tanto que las superficies más bajas se encuentran a una altitud de 800 msnm.

La subprovincia de las Sierras de Jalisco presenta los siguientes sistemas de topoformas: Gran Sierra Volcánica Compleja o Grandes Estrato-Volcanes, Sierra de Laderas Abruptas, Sierra de Laderas Tendidas, Sierra de Laderas Tendidas con Llanos, Sierra Compleja, Escudo-Volcán Aislado, Meseta Lávica, Mesetas Lávicas asociadas con cañadas, Mesetas Escalonadas asociadas con lomeríos, Mesetas Pequeñas con lomeríos, Lomerío Suave asociado con cañadas, Valle de Laderas Escarpadas, Valle de Laderas Tendidas, Valle de Laderas Tendidas asociado con lomeríos, Cañón y Pequeño Llano Aislado.

Subprovincia de las Sierras Neovolcánicas Nayaritas 
Un pequeño rincón de esta subprovincia del Eje Neovolcánico, penetra en el extremo norte del estado de Jalisco, del que ocupa el 0,007% de la superficie, localizado en parte del municipio de Hostotipaquillo y distribuido en tres sistemas de topoformas que son: una Sierra de Laderas Tendidas, una Meseta Lávica con Cañadas y un Valle Tendido con Terrenos Ondulados.

Subprovincia Volcanes Nevado de Colima y de Fuego"
Esta subprovincia penetra al estado por el este y recibe este nombre debido a sus dos geoformas más representativas, El Nevado de Colima y el Volcán del Fuego. Ocupa apenas el 2,36% de la superficie total estatal; cubriendo totalmente los municipios de Tonila y Zapotitlán de Vadillo y parte de los de Zapotlán El Grande, Tolimán, Tuxcacuesco, Tuxpan, Venustiano Carranza y Zapotiltic. El panorama fisiográfico de la subprovincia está integrado por siete sistemas de topoformas: Gran Sierra Compleja o Grandes Estrato-Volcanes Aislados, representados por el Nevado y el de Fuego, que están constituidos por andesitas (rocas ígneas medias en sílice) y sus altitudes son de 4.240 y 4.220 m respectivamente; Sierra de Laderas Abruptas, que se encuentra sobre la base occidental del Nevado, representada por el Cerro el Petacal, de rocas lávicas sílicas; los Lomeríos Suaves (tobas) asociados con cañadas y los Lomeríos Suaves (arenisca conglomerado) integran las amplias faldas que se extienden en torno a los volcanes, surcadas por arroyos radiales; el Valle de Laderas Escarpadas, que es el sistema de cañadas hondas y ramificadas, que sobre la base occidental de los volcanes han labrado sus cárcavas; el Pequeño Llano Aislado, de origen aluvial que se localiza en el extremo norte; y el Piso de Valle, que está formado por el valle plano y angosto del río Armería.

Subprovincia de la Escarpa Limítrofe del Sur 
Solo una pequeña parte de esta subprovincia penetra en el estado de Jalisco y abarca una porción del municipio de Jilotlán de los Dolores, con un solo sistema de topoformas, la Meseta Lávica asociada con Sierras que es un conjunto de mesetas basálticas escalonadas y que descienden hacia el sur, a altitudes de 1.000 a 1.500 msnm interrumpidas por Escudo-Volcanes también basálticos.

Provincia Mesa Central 
Penetra al estado de Jalisco por el noroeste; ocupa el 3,44% de la superficie total estatal y en ella se presentan parte de tres subdivisiones de la provincia que corresponden a la subprovincia Llanos de Ojuelos y las discontinuidades fisiográficas Sierra de la Cuatralba y Valles Paralelos del suroeste de la Sierra de Guanajuato.

Estas subdivisiones de la provincia poseen patrones característicos de topografía y morfología; presencia y distribución de suelos y vegetación diferentes, por lo que la descripción de suelos, vegetación, posibilidades de uso agrícola, ganadero y forestal, y el estado actual de las formas de producción agrícola, se encuentra referida por regiones

Esta provincia cuenta con una subprovincia llamada Llanos de Ojuelos.

Esta subprovincia penetra al noreste del estado y limita al sur con los Altos de Jalisco; inmediatamente al norte de Encarnación de Díaz. Comprende una porción pequeña de la entidad (2.310,297 km²), que cubre totalmente el municipio de Ojuelos y parte de los de Encarnación de Díaz y Lagos de Moreno. Los sistemas de topoformas más representativos de la subprovincia, dentro del estado son: Las Llanuras de Piso Rocoso, cubiertas por suelos someros de aluvión y salpicadas de pequeñas charcas; y las Mesetas con Cañadas que se encuentran entre las llanuras. Las Sierras Bajas y los Lomeríos probablemente se derivaron de la erosión de mesetas similares a las ya mencionadas; sus laderas son rectas y su elevación es de 2.300 y 2.250 msnm respectivamente. En general, la litología de estos sistemas de topoformas está constituida por rocas de origen volcánico, ricas en sílice.

Provincia de la Sierra Madre Occidental
Esta provincia cuenta con dos subprovincias: La de las Sierras y Valles Zacatecanos y la de Las Mesetas y Cañones del Sur
Subprovincia Mesetas y Cañones del Sur
Esta Subprovincia se encuentra en casi toda la extremidad norte de Jalisco hasta el límite sur del extenso cañón que ha formado el Río Grande de Santiago, quedando su frontera sur-oriental en el estado al norte de la ciudad de Tequila; abarca la totalidad de los municipios Bolaños, Huejuquilla el Alto, Mezquitic, Teocaltiche y Villa Guerrero, y parte de los municipios de Colotlán, Chimaltitlán, Hostotipaquillo, Huejucar, San Martín de Bolaños y Tequila.

Forma parte de la "espina dorsal" de la Sierra Madre Occidental. Su paisaje está constituido por altas mesetas, algunas de ellas enormes, que se interrumpen abruptamente por profundos cañones.

La superficie total de esta subprovincia es de 8.165,349 km² y representan el 10,35% con respecto a la superficie total del estado. Los sistemas de topoformas que se encuentran en esta subprovincia dentro del estado de Jalisco son: Superficie Disectada de Gran Meseta, que son agrupaciones de mesetas de tamaño pequeño; Pequeñas Mesetas; Asociadas a Cañadas; Lomeríos, que se encuentran como pequeños grupos aislados en los Pisos de Valle, generalmente amplios; Lomeríos y Cañadas, Piso de Valle con Terrazas; Piso Amplio de Valle con Lomeríos y por último Cañones.

Según los resultados que arrojó el "II Censo de Población y Vivienda", realizado por el Instituto Nacional de Estadística y Geografía (INEGI) con fecha censal del 12 de junio de 2010, el estado de Jalisco contaba hasta ese año con un total de 8 079 782 habitantes, de dicha cantidad, 4 064 941 eran hombres y 4 014 841 eran mujeres. La tasa de crecimiento anual para la entidad durante el período 2005-2010 fue del 1,7%. Según indica este censo, 4.434.252 de los jaliscienses viven en la zona metropolitana de Guadalajara. La población aumentó aproximadamente 750.000 habitantes desde el último conteo, realizado en 2005. Hoy en día, la población del Estado representa el 6,5% del total del país.

Según el "XII Censo de Población y Vivienda 2010", realizado por el INEGI en Jalisco, hay 1.801.306 viviendas particulares, de las cuales 1 697 299 disponen de agua corriente dentro o fuera de la vivienda, pero en el mismo terreno, lo que representa el 94,2%; 1.754.481 tienen drenaje, lo que equivale al 97,4%, y 1.182.473 cuentan con energía eléctrica, esto es, el 65,6%.

Según el "XII Censo de Población y Vivienda del 2010" (INEGI), en Jalisco hay 1.802.424 hogares, de los cuales el 25% (443 000 hogares) tienen jefatura femenina, es decir, son dirigidos por una mujer, y el 75% (1.359.424 hogares) tienen jefatura masculina, es decir, son dirigidos por un hombre.

Los wixaritari son el grupo étnico más conocido y numeroso del estado de Jalisco, se concentran principalmente al norte del estado en municipios como Mezquitic, Bolaños, Huejuquilla el Alto y Villa Guerrero, aunque comparten asentamientos con otros estados como Nayarit, Durango y Zacatecas. Al sur se encuentra otro grupo indígena nativo de Jalisco, los nahuas, de filiación uto-azteca, quienes radican en los municipios de Tuxpan y Tonila; y en menor proporción los purépechas, mixtecos, mazahuas otomíes y zapotecos.

A mediados del siglo pasado, el incremento de la población de Jalisco en el periodo 1950-1960, presentó una tasa de crecimiento anual del orden del 3,4%. El periodo que comprende 1970-1980 muestra un descenso con respecto a la década precedente, tendencia que se mantiene posteriormente. Se ha observado la disminución en el ritmo de crecimiento hasta llegar a un 1,33% del año 2000 al 2005.
En el Alto Santiago, se encuentra la Zona Metropolitana de Guadalajara (ZMG), la cual es el principal centro de población de la entidad. Una serie de factores ha generado la conurbación de la ciudad de Guadalajara con los municipios limítrofes, lo que ha acelerado el crecimiento de su población.

De acuerdo con cifras de INEGI, para el año 1950 la población total del estado de Jalisco era un poco más de 1,7 millones de habitantes, en el año 2005, ésta asciende a más de 6,7 millones, junto a este significativo aumento se fueron dando diversas transformaciones demográficas a nivel subregión, en especial en el Alto Santiago, que pasó de una participación relativa en la concentración de población del 46,6% al 71,2% en este periodo de tiempo.
Con base en el último registro oficial del año 2005, la población total de la entidad suma 6.752.113 habitantes, lo cual representa el 6,5% de la población total del país (103,3 millones); en lo que se refiere a la población rural, ésta representa el 13,9% de la población total del estado y la población urbana equivale al 86,1%.

La ciudad de Guadalajara, capital de Jalisco, es la sede de la segunda universidad fundada en México, la Universidad de Guadalajara. Esta entidad educativa pública es la segunda en cantidad de estudiantes en el territorio (después de la UNAM), (195.116 estudiantes de profesional medio, bachillerato, técnico superior, licenciatura y posgrado).

También es sede de la que es la primera universidad privada de México, la Universidad Autónoma de Guadalajara, por sus siglas U.A.G. La sede principal de la Universidad Autónoma de Guadalajara es Ciudad Universitaria, ubicada en el municipio de Zapopan; en dicho lugar se encuentra la rectoría y la mayoría de las carreras que se imparten. Cuentan también con el Instituto de Ciencias Biológicas, UAG campus Santa Anita (Tlaquepaque), UAG Campus Tepic, UAG Campus Tabasco, Instituto Autónomo de Educación de Tecomán (IAETAC), el sistema de educación básica y media José Vasconcelos en Baja California, y la primaria Antonio Caso más Santa Anita.

Cuenta con dos campus de la universidad privada más importante del país, el Instituto Tecnológico y de Estudios Superiores de Monterrey (Tec de Monterrey).

El Instituto Tecnológico y de Estudios Superiores de Occidente (ITESO), es una universidad privada con sede en la ciudad de Tlaquepaque, Jalisco, México. Esta institución educativa fue fundada en el año de 1957 y pertenece al Sistema Universitario Jesuita (SUJ) que a su vez forma parte de la Compañía de Jesús. En este sentido la universidad también es nombrada como la Universidad Jesuita de Guadalajara pero es conocida comúnmente como el ITESO.

Ofrece 26 programas de licenciatura, 2 de especialidades, 13 de maestría y 3 doctorados. La matrícula del ITESO es de alrededor de 8.000 estudiantes. La Universidad cuenta sólo con un campus, el cual está ubicado al sur de la Zona Metropolitana de Guadalajara en las inmediaciones de Tlaquepaque donde se encuentran sus diversas instalaciones.

Tres campus de la Universidad del Valle de México, tres campus del TecMilenio (Tlaquepaque, Zapopan y Ejecutivo), la Universidad del Valle de Atemajac con tres campus (Zapopan, Lagos de Moreno y Puerto Vallarta), la Universidad Panamericana, la Universidad Cuauhtémoc, la Universidad Marista de Guadalajara el Instituto Tecnológico Superior de Arandas, el Instituto Tecnológico Superior de Chapala, el Instituto Tecnológico Superior de Cocula, el Instituto Tecnológico Superior de El Grullo, el Instituto Tecnológico Superior de la Huerta, el Instituto Tecnológico Superior de Lagos de Moreno, el Instituto Tecnológico Superior de Mascota, el Instituto Tecnológico Superior de Puerto Vallarta, el Instituto Tecnológico Superior de Tala, el Instituto Tecnológico Superior de Tamazula, el Instituto Tecnológico Superior de Tequila, el Instituto Tecnológico Superior de Zapopan y el Instituto Tecnológico Superior de Zapotlanejo. Además, existe el Centro de Investigación y Asistencia Tecnológica del Estado de Jalisco CIATEJ.

De estos centros educativos 18 poseen carreras de ingeniería y otras carreras afines a la industria de la electrónica, como ingeniería electromecánica, ingeniería en tecnologías electrónicas, en tecnologías de la información y comunicaciones, ingeniería industrial, ingeniería de sistemas, teleinformática, administración de tecnologías de la información, y tecnologías computacionales, entre otras.

Así mismo, en la localidad de Atequiza, Ixtlahuacán de Los Membrillos; cuenta con La Escuela Normal Rural Miguel Hidalgo, fundada a partir de los ideales de la Revolución, es una institución formadora de docentes para el ámbito rural, atendiendo gratuitamente a hijos de campesinos y obreros.

Jalisco, el séptimo estado en extensión y el cuarto más productivo de la república mexicana (después de Ciudad de México, Estado de México y Nuevo León), ha experimentado un importante crecimiento en su actividad económica y comercial durante los últimos años. Entre los principales productos que forman parte de la comercialización del estado destacan los cosméticos, aparatos electrónicos, tecnología, farmacéuticos, construcción, textiles, tabaco, alimentos y bebidas, artículos deportivos, etc. Así mismo, el sector de servicios también ha crecido con intensa pujanza, al igual que el sector turístico y el financiero.

Este desarrollo intensivo del sector comercial en la entidad es superado por la Ciudad de México, el Estado de México y Nuevo León.
La población económicamente activa en el sector agropecuario ha disminuido, mientras que en el sector terciario y secundario ha incrementado su demanda, sobre todo en los servicios y en el comercio. Sin embargo, el estado se distingue por el cultivo de granos como: maíz, sorgo, frijol, arroz, cebada, trigo, caña de azúcar, algodón, cártamo, soya, alfalfa, melón, papa, jitomate, papaya, café, mango, aguacate, plátano, guayaba, sandía y limón agrio. 
Existe ganado porcino, bovino utilizado para abasto, y lechero, ovino, caprino y equino. 
La actividad pesquera se realiza en los puertos de Barra de Navidad, considerado puerto de cabotaje, en Puerto Vallarta, considerado puerto de altura, y en la laguna de Chapala. Las especies que se obtienen son: huachinango, charal, pescado blanco, tortuga, bagre, carpa, camarón, tiburón, mojarra, rana y popocha. 
Su actividad industrial es extractiva, minero metalúrgica, siderúrgica, maquinaria, equipo y material de transporte, productos químicos, madera, textil, eléctrica y electrónica, material fotográfico, alimentaria, bebidas, tequila, cerveza y calzado.

El turismo en Jalisco ha crecido de una manera significativa en los últimos años.
Guachimontones (o Huachimontones) es el nombre de un centro ceremonial y antiguo asentamiento prehispánico ubicado en la ciudad y municipio de Teuchitlán, aproximadamente a una hora al oeste de la ciudad de Guadalajara en el estado de Jalisco. Este asentamiento fue bautizado así por el nombre del lugar donde se descubrió este primer sitio arqueológico, posteriormente se han descubierto otros asentamientos de la misma Tradición Teuchitlán,1 una compleja sociedad que existió probablemente desde 300 a.C. hasta 900 d.C.
Este centro ceremonial incluye varias construcciones con un estilo arquitectónico peculiar, entre ellas varios túmulos cónicos escalonados o pirámides rodeadas de patios circulares, dos juegos de pelota, un anfiteatro y algunas terrazas y edificios.
La palabra Teuchitlán se deriva de la voz Teotzitlán o Teutzitlán que se interpreta como “lugar dedicado a la divinidad”, “lugar del dios Tenoch” o “lugar dedicado al dios reverenciado”.

Posiblemente la fundación del poblado se remonta a los aztecas que lo erigieron en un cerro denominado Huachimontón, al norte de su actual asiento.2 Fue fundado por integrantes de las tribus Nahuatlacas que colonizaron el centro de México en el periodo postclásico, sin embargo se sabe que las construcciones vecinas a Teuchitlán son anteriores a tal colonización. La cultura creadora de las construcciones en Guachimontones recibe el nombre de Tradición Teuchitlán, y tuvo su período de apogeo entre los años 200 y 400 d. C, desapareciendo hacia el año 900 d. C., posiblemente antes del arribo de los colonizadores náhuatl.

Además, de dicho asentamiento, en el centro del estado y en Los Altos de Jalisco se localizan restos de poblados ya en deterioro en los poblados de Valle de Guadalupe, Zapopan, Atotonilco el Alto, Cerro del chiquihuitillo en Pegueros, Cerro encantado en Teocaltiche y Teocaltitlan de Guadalupe en Jalostotitlan, que su mayor influencia arquitectónica tuvo relatividad a los pueblos chichimecas y a la cultura chupicuaro del estado de Guanajuato.



En Jalisco se localiza la segunda ciudad más poblada del país, Guadalajara, que junto con Tlaquepaque, Tonalá, El Salto, Tlajomulco de Zúñiga y Zapopan forman la zona metropolitana de la ciudad. El estado muestra una imagen comercial importante debido a su sistema de comunicaciones y vías férreas, que reflejan un factor importante para ampliar su desarrollo.

El municipio de Villa Hidalgo, el cual está localizado en Los Altos de Jalisco forma una gran importancia en la economía tanto como del estado y del país ya que ocupa el tercer lugar en importancia textil en todo el país, ahí se confeccionan principalmente prendas de tejido de punto.

Jalisco cuenta con los siguientes destinos carreteros: Guadalajara-Mazatlán-Nogales; Ciudad Juárez-Zacatecas-Lagos de Moreno-Oaxaca-Tapachula y Guadalajara-México-Veracruz. Cuenta con instalaciones portuarias que aprovechan las condiciones naturales del estero El Salado en Puerto Vallarta, dentro de la bahía de Banderas. Se conecta con los puertos de Manzanillo y Mazatlán. Posee dos aeropuertos internacionales: el de Guadalajara y Puerto Vallarta, los cuales sitúan a Jalisco dentro de las rutas internacionales más importantes.

Jalisco es uno de los estados más típicos del país, ya que es el símbolo del tequila, mariachi, charrería y mujeres bellas. Es un estado geográficamente privilegiado ya que cuenta con playas como Puerto Vallarta, Barra de Navidad, Melaque, Costalegre y Tenacatita. Así mismo contamos con el lago más grande de México que es Chapala donde se pueden encontrar pueblos típicos como Chapala, Ajijic, Jocotepec y Tizapan el Alto. En el ámbito de turismo religioso contamos con tres de los centros Marianos más visitados en México; San Juan de los Lagos (Virgen de San Juan), Zapopan (Virgen de Zapopan) y Talpa de Allende (Nuestra Señora del Rosario), otros centros religiosos como el Santuario de Santo Toribio Romo (Mártir de la revolución cristera) en Jalostotitlán. 

Las comunicaciones y transportes son dos actividades importantes para el desarrollo social y económico del Estado, ya que su función primordial es la de facilitar la integración social y geográfica del territorio para el traslado de personas y bienes.

La ubicación geográfica de Jalisco en el Occidente de la Nación Mexicana es estratégica, lo que le ha valido una privilegiada comunicación, tanto con el Centro, Sur, Este, Norte de la Nación, como con los Puertos del Pacífico, con las entidades vecinas y al interior del Estado.

La participación de las comunicaciones en la formación del Producto Interno Bruto ha generado el 6% del Estado. La estructura interna de este sector ha experimentado algunos cambios, puesto que la evaluación de las actividades tradicionales de correos y telégrafos, se ha visto contrarrestada ante el rápido crecimiento de la infraestructura telefónica, actividad que aumentó su importancia de manera considerable para 1997. Este aumento pone de manifiesto la integración e intercomunicación que a través de este medio está teniendo la entidad.

El Estado se encuentra comunicado por una amplia red de carreteras, a través de las cuales integra a la entidad con el resto del país y que, conjuntamente con las carreteras estatales, permite comunicación con las 124 cabeceras municipales de la entidad, en una extensión de 25.303,098 km, de los que: 5.148,28 km corresponden a carreteras libres; 5.148,28 km de red Federal y 3.095,46 km de red Estatal; carreteras de cuota 566,10 km; 5.433,70 km a caminos rurales y 14.155,90 de brechas. Sus principales vías de comunicación vinculan a la entidad con el interior de Jalisco, con la capital de la República y con los principales centros industriales, tales como Monterrey, N.L., Saltillo y Torreón, Coah.; Querétaro, Qro.; León y Salamanca, Gto.; San Luis Potosí y el Noroeste, Centro y Sur del país.

El avance logrado en la construcción de caminos, ha impulsado notoriamente a los municipios que se vincularon a la red carretera, los que experimentaron un aumento en su nivel de desarrollo, dado principalmente en las regiones de alto potencial, lo que tuvo un efecto acelerador de la dinámica social y económica de las zonas favorecidas entre las regiones.

La Capital del Estado cuenta con una eficiente red vial, sobre todo en las vías de entrada y salida a la ciudad, así como de vías rápidas que la cruzan, en las que se localizan los pasos a desnivel en los cruces de las vías de ferrocarril y en vías rápidas.


Igualmente existe la vía cuota y libre a Colima, que conecta municipios como Sayula y Zapotlán El Grande con la capital del Estado.



La carretera León-Lagos de Moreno-Aguascalientes y la continuación de la carretera Lagos de Moreno- San Luis Potosí. Así mismo, la carretera Guadalajara-Colotlán, con los ramales a San Martín de Bolaños y Mezquitic, que integran a la región Norte con el resto del Estado.

En la red ferroviaria convergen tres ejes ferroviarios, que une a la entidad con las regiones del Norte de la república, hasta la frontera con los Estados Unidos de Norteamérica; al Sur permitiendo comunicación con el Puerto de Manzanillo y con el Centro de la república a través de la línea Guadalajara-México. El Estado cuenta con una longitud de red ferroviaria de 153,22 km de vías. El sistema ferroviario en la entidad establece vinculación a través de las líneas: Guadalajara-Ocotlán- La Barca-México, Línea en que se localiza la mayor parte de la industria de Jalisco, ya que establece comunicación con el Corredor Industrial del Salto. La segunda línea en importancia vincula a Guadalajara con el puerto de Manzanillo, Colima, uniendo a Guadalajara con Zacoalco de Torres, Sayula, Zapotlán El Grande y Tuxpan. La tercera comunica a Guadalajara con el noroeste del país hacia la frontera norte con los Estados Unidos de Norteamérica por Mexicali, B.C. y Nogales, Son.

Es innegable la importancia del crecimiento de la infraestructura aérea, a pesar de las buenas comunicaciones terrestres en la entidad. Este incremento se ve reflejado no sólo en cuanto al movimiento de pasajeros, sino también en el de transporte de express y carga. La aviación comercial comunica al Estado por medio de un importante número de compañías aéreas nacionales y extranjeras. Para ello cuenta con dos aeropuertos internacionales operados por el grupo aeroportuario del pacífico, el aeropuerto internacional de Guadalajara Don Miguel Hidalgo, el aeropuerto internacional de Puerto Vallarta Lic. Gustavo Díaz Ordaz, el aeropuerto nacional de Unión de San Antonio, Lic. Primo de Verdad y Ramos así como también una aeropista de mediano alcance en Colotlan, Tuxpan, Mascota y recientemente en Tomatlan.

El Aeropuerto Internacional de Guadalajara "Miguel Hidalgo", ubicado en el municipio de Tlajomulco de Zúñiga, se encuentra a 13 km de la ciudad de Guadalajara.

El transporte aéreo en el interior Estado toma también relevancia, ya que cubre las áreas en donde la comunicación terrestre se encuentra escasamente desarrollada. Este transporte de aeronaves pequeñas, se apoya en una terminal anexa al Aeropuerto Internacional de Guadalajara y en 63 aeropistas localizadas en los diversos destinos dentro del Estado, conectando a lugares como: Zapotlán el Grande, Talpa, La Barca, Mascota, Autlán, Barra de Navidad, entre otras.

Jalisco cuenta con un Puerto Marino: Puerto Vallarta, considerado tanto pesquero y de turismo, como de tráfico de altura; últimamente ha adquirido cierta importancia comercial. No obstante, la producción de Jalisco se mueve hacia los mercados exteriores a través del Puerto de Manzanillo localizado en el estado de Colima a 313 kilómetros de Guadalajara por la autopista Guadalajara-Colima, el cual proporciona servicios de altura y cabotaje. Con la reconstrucción y modernización del puerto mencionado, se asegura un tráfico marítimo más fluido y una protección y cuidado mayor a las mercancías.

Las telecomunicaciones han tenido un amplio desarrollo en los últimos años, estando Jalisco comunicado por la red nacional y con el resto del mundo.

El Estado cuenta con una eficiente red telegráfica y postal, así como con un amplio sistema telefónico que permita la comunicación fluida de mensajes, tanto al interior del Estado como al resto del país e internacionalmente, y con un sistema de radiocomunicación que permite integrar aquella área donde la instalación de otros servicios resulta demasiado onerosa.

La Zona Metropolitana de Guadalajara se encuentra unida a la red nacional e internacional de telmex y microondas que constituye la columna vertebral de las telecomunicaciones en el país, canalizado a través del sistema de servicios de teleseñalización, telecontrol, teleinformación y al sistema telefónico de larga distancia, lo que le ha permitido una comunicación mayor con otras grandes ciudades del interior del país y el resto del mundo.

En general todas las cabeceras municipales tienen servicio de correo, quedando por ser incorporadas algunas localidades debido al incremento en la población.

El servicio telefónico es la actividad que presenta más participación y mayor dinamismo en su crecimiento: (7,5% promedio anual del sector). En diciembre de 1997, la cobertura telefónica se incrementó en más de 51.000 líneas con respecto a 1996; en este último año quedaron digitalizadas el 100% de las líneas en la Zona Metropolitana de Guadalajara. El servicio se concentra en la parte central del Estado, principalmente en la Zona Metropolitana de Guadalajara que en marzo de 1998 absorbe 409.969 líneas residenciales instaladas, 61.259 líneas comerciales instaladas y cuenta con 52.435 líneas disponibles. En las áreas rurales se ha visto incrementado el servicio, tratando de integrar a las zonas más aisladas, y en las urbanas, se considera suficiente para cubrir la demanda.

En 1998 en el Estado existían 13,47 líneas por cada mil habitantes.

La cocina jalisciense ha contribuido ampliamente a dar fama internacional a la gastronomía mexicana. Los platillos jaliscienses tienen una relación directa con los productos locales como el maíz, el fríjol, la calabaza, el trigo, el agave y los árboles frutales.

Algunos de los platillos más representativos son: la birria, el pozole blanco o rojo, los sopes, el guacamole, frijoles charros, el menudo, las tortas ahogadas, la carne en su jugo, las enchiladas rojas y verdes, los tamales de elote, el borrego al pastor y los tamales de frijol entre mucha más variedad. Uno de los platillos que se han incorporado en las últimas décadas son los tacos al pastor, sobre todo en el municipio de Atotonilco el Alto aunque el municipio de Arandas es también reconocido por sus tacos.

Entre sus dulces sobresalen el alfajor, palanquetas de cacahuate o pepitas de calabaza, cocadas, dulces en conserva, dulces de leche, la jericalla, perones enmielados rojos, algodones, buñuelos, camote y calabaza enmielada.

Mientras que en sus bebidas el tequila, aguamiel, pulque, tejuino y aguas frescas de horchata y de frutas naturales, marcan la distinción.

La cocina jalisciense es un espacio en el que se unen, por un lado la elaboración de platillos, en los que se distinguen los guisados, salsas, aún las más picantes, dulces y bebidas que se destacan por su apariencia y exquisito sabor, por otro lado los utensilios y productos necesarios para su preparación.

El mariachi por excelencia, destacándose el más viejo e internacional " Vargas de Tecalitlán ", cuyo fundador fue don Silvestre Vargas.

Es variable de acuerdo al municipio, pero es predominante en la totalidad de ellos, el traje de charro para los hombres y para las mujeres, el vestido de listones , ya que se utilizan algunas veces para bailar con esa vestimenta , como el son de la negra , la culebra , el tranchete , etc

En Jalisco se produce una gran variedad de artesanías que han dado fama a numerosos pueblos, como los equipales de Zacoalco, las conservas y lácteos de Tapalpa, los bordados y dulces de los Altos, los artículos de "pita" de Colotlán, la cerámica de Tlaquepaque y Tonalá, entre otras.
Los artículos artesanales son de tal belleza y calidad que han sido muy bien aceptados en el extranjero a donde se exportan.
Estos objetos son elaborados en talleres adaptados en las viviendas donde generalmente participa toda la familia y la técnica para su realización es transmitida de generación en generación.
Entre las artesanías encontramos: Ropa típica de vestir que tiene demanda internacional, joyería, huaraches y sandalias de playa, muebles de madera, curiosidades de conchas y alfarería, aretes y pulseras, anillos y collares de chaquira, alfarería, talabartería; sillas de montar, bordados de tela y pita en cinturones, fundas portanavajas, hebillas de cuero, morrales etc. (piteado), loza de barro, petates y canastas de carrizo, sombreros de soyate y palma, tejidos de lana (sarapes y gabanes), deshilados, rebozos, etc.

Con frecuencia se dice que el deporte nacional de los mexicanos es la charrería, no se atribuye su origen dentro del estado pero si es el estado de Jalisco el que mayor emblema le ha dado a este deporte. Es derivado de las faenas de los caporales en las haciendas ganaderas. Su origen data de la época colonial, y se atribuye a Maximiliano de Habsburgo, segundo emperador de México, la creación del traje de charro en su forma definitiva. La práctica de la charrería está limitada a un sector muy pequeño de la población, debido al elevado costo de la manutención del caballo y de los aperos necesarios (indumentaria, accesorios). El reconocimiento como deporte nacional es más bien honorífico, porque como otros supuestos símbolos mexicanos, no tiene declaración oficial. La versión popular de la charrería es el jaripeo, presente en casi todas las fiestas de los pueblos.

El fútbol es el deporte con más afición en la entidad. Los dos clubes profesionales más populares son el Club Deportivo Guadalajara ("Chivas") y Atlas de Guadalajara ("Zorros"), que se han destacado en la Primera División Mexicana y se enfrentan en el Clásico Tapatío. En tanto, los Leones Negros de la Universidad de Guadalajara disputan actualmente la Liga de Ascenso.

En cuanto al béisbol, los Charros de Jalisco han ganado la Liga Mexicana de Béisbol en 1967 y 1971. En la temporada 2014-15 pasó a disputar la Liga Mexicana del Pacífico.

El boxeo y la lucha libre gozan igualmente de buena reputación. En la primera disciplina hay boxeadores jaliscienses.

La fiesta taurina es también muy seguida, sobre todo en el centro del país, siendo la plaza más importante: La Monumental Plaza de Toros de Guadalajara, también conocida como Plaza de Toros "Nuevo Progreso" del arquitecto tapatío José Manuel Gómez Vázquez Aldana y otras plazas importantes como la de Jalostotitlán y Autlán de Navarro en sus carnavales.

Por otra parte, la ciudad de Guadalajara obtuvo ser sede de los Juegos Panamericanos de 2011 que se iniciaron en el mes de octubre, siendo este el evento deportivo de mayor trascendencia e importancia en el continente americano. 

De igual forma, Guadalajara ha sido sede del evento de fútbol más grande del orbe, el Mundial, pues en el mundial México 1970 tanto como en el mundial México 1986 el Estadio Jalisco albergo diversos partidos de dicha justa mundialista.

El estado a firmado los siguientes acuerdos de hermanamiento:







</doc>
<doc id="1581" url="https://es.wikipedia.org/wiki?curid=1581" title="Juegos de azar">
Juegos de azar

Los juegos de azar son juegos en los cuales las posibilidades de ganar o perder no dependen exclusivamente de la habilidad del jugador, sino que interviene también el azar. La mayoría de ellos son también juegos de apuestas, cuyos premios están determinados por la probabilidad estadística de acertar la combinación elegida; mientras menores sean las probabilidades de obtener la combinación correcta mayor es el premio.

Existen juegos de azar donde la habilidad del jugador puede influir en el desarrollo del juego, como ocurre en los juegos de naipes como el póquer. No obstante el resultado del final del juego depende del azar y las cartas que toquen a cada jugador.

Por cierto tiempo, el premio más elevado otorgado por un juego de azar fue dado en Estados Unidos, en 1998, con 295 millones de dólares, que fue repartido entre 13 operarios; pero esta marca fue superada por otro caso en el año 2012, en el que el ganador obtuvo casi 656 millones de dólares.

Principalmente es útil la destreza del jugador para calcular las posibilidades que se deriven de una o varias acciones, en relación siempre con el azar; además, el jugador debe ser hábil para reducir la probabilidad de resultados desfavorables y aumentar la de los favorables mediante sus acciones. Sin embargo, el componente impredecible que es el azar puede arrebatar la victoria hasta al jugador más experimentado y diestro. 

Los sumerios y asirios utilizaban un hueso extraído del talón de animales denominado astrágalo o talus, que tallaban para que pudieran caer en cuatro posiciones distintas. Los juegos con dados se originaron en los tiempos del Imperio Romano, aunque no se conoce apenas las reglas con las que jugaban. Uno de estos juegos, denominado "hazard", palabra que en inglés y francés significa riesgo o peligro, fue introducido en Europa con la Tercera Cruzada. Las raíces etimológicas del término provienen de la palabra árabe "al-azar", que significa "dado".

El bingo consiste en un bombo con un número determinado de bolas numeradas en su interior (normalmente 75 o 90). Los jugadores juegan con cartones con números aleatorios escritos en ellos, dentro del rango de bolas correspondiente. Un locutor o cantor va sacando bolas del bombo, cantando los números en voz alta. Si un jugador tiene dicho número en su cartón lo tacha, y el juego continua así hasta que alguien consigue marcar todos los números de una línea y el cartón.cuando completa en dicho numero en el cartón el jugador grita BINGO siendo el primero gana el premio mayor

La probabilidad de obtener una línea o el cartón entero depende del número de cartones que están interviniendo en el juego, por lo que dependerá del número de personas que estén jugando así como del número de cartones con que cada participante juegue. Como en este juego se sacan número hasta que alguien “canta bingo”, es decir, posee el cartón con todos los números tachados, la probabilidad depende del número de cartones en juego, así como, del control del jugador sobre sus cartones.

Este sencillo juego, también llamado volado, cara o sello, consiste en lanzar sobre una superficie horizontal una moneda al aire y gana el que eligió la cara vista hacia arriba. Como sólo hay 2 posibles elecciones, la probabilidad de acierto es del 50%.

Los sumerios y asirios utilizaban un hueso extraído del talón de animales como ovejas, ciervos o caballos, denominado astrágalo o talus, que tallaban para que pudieran caer en cuatro posiciones distintas, por lo que son considerados como los precursores de los dados. El juego de los dados consiste en lanzar un objeto de forma poliédrica sobre una superficie horizontal. Los posibles resultados numéricos están marcados en cada una de las caras del poliedro y se eligen tomando, normalmente, el resultado marcado en la cara que queda vista hacia arriba. El dado más convencional cuenta con seis caras por lo que la probabilidad de obtener un número (de los 6) es de 1 entre 6, es decir, 16,67%. Si lanzamos 2 dados de 6 caras será del 4,76%. En China y la India se jugaban los dedos de la mano a los dados.

Su origen se remonta al siglo XV cuando los comerciantes genoveses idearon este sistema como estrategia de venta, al estar constituidos los premios por mercancías.

En un sorteo de un cupón, la probabilidad de que te toque depende, del número de billetes en juego, así como del número de series. Como ejemplo se pondrá el sorteo extraordinario de Navidad en España, donde se ponen en juego 170 series de 85.000 billetes, de los cuales 13.334 se llevan premio. La probabilidad de que nos toque el premio mayor con un solo cupón es de 1 entre 14 millones y medio (170 series x 85.000 billetes).La cuantía del premio a recibir no sólo depende de la probabilidad de acierto, sino también del porcentaje que se devuelva como premio de la cantidad jugada, que suele ser de un 70%.

En cuanto a las quinielas, su acierto depende del número de posibilidades o posibles elecciones. Si hacemos una apuesta sencilla, tenemos que hacer frente a 3 elevado a la 14 de casos posibles, ya que en cada uno de los catorce partidos tenemos tres posibles resultados: 1, X, 2. Por lo tanto, hay que dividir nuestra apuesta (1) entre todas las posibilidades (3 a la 14), con lo que para llevarse el premio hay una probabilidad de 1 entre casi 5 millones. La diferencia con otras formas de apuestas es que aquí, además del azar, existe una mayor probabilidad de acierto, que depende de la diferencia entre los equipos de fútbol en juego.

En este tipo de lotería, se tiene una serie de números, de los cuales una cantidad son los que resultan ganadores. En el caso de que sean 49 y seis los ganadores, la probabilidad que hay de ganar el premio máximo con una apuesta sencilla es de 1 entre 13.983.816, es decir, las posibles combinaciones de 6 números sobre 49 números.

Para participar en el juego, el apostador debe elegir dos números de tres cifras o si lo deseara, la terminal de juego le generará automáticamente la apuesta. Si esos dos números de tres cifras salen en cualquier orden entre los cinco primeros premios del extracto, se consideraran ganadores del juego. El premio se conformará destinando, del total de lo recaudado, un cuarenta por ciento (40%). La probabilidad de acierto es de 1 entre 49850.

Este juego a cambio de una cantidad de dinero se ofrece ocasionalmente un premio. Existen de dos tipos: las máquinas programadas (habituales en salones de juego y bares), en la que, según un programa interno, después de un número de juegos, la máquina ha de devolver una parte del ingreso que se ha realizado (en torno al 70%); las máquinas de azar (habituales en casinos), en las que dependen exclusivamente del azar. El mayor premio de una tragaperras fue dado en Atlantic City (Estados Unidos) con más de diez millones de dólares, que se habían acumulado como «bote» durante años, y a cambio de sólo una moneda de cinco centavos.

El juego de la ruleta, típico de los casinos, debe su origen al matemático francés Blaise Pascal, de ahí que su nombre viene del término francés roulette, que significa rueda pequeña. En un principio poseía 36 números (la suma de los primeros 36 números da el número mágico por excelencia: 666) y a finales del siglo XIX, los hermanos Blanc la modificaron añadiéndole un nuevo número, el 0, y la introdujeron inicialmente en el Casino de Montecarlo. Esta ruleta cuenta con una proporción de premios de 36/37, que deja un margen para la casa del 2,7% (en Europa) o el 5,4% (en EE.UU.) si cuenta con dos ceros.



</doc>
<doc id="1583" url="https://es.wikipedia.org/wiki?curid=1583" title="Juego abstracto">
Juego abstracto

Se identifica como juego abstracto a todo aquel juego en el que no existe un tema o ambientación asociado. Esto es: aquellos en los que los elementos de juego —fichas, dados, tablero, etc.— no representan el comportamiento y características de seres u objetos reales ni imaginarios.

No obstante lo anterior no es infrecuente que, al menos en algunos de los juegos abstractos de mayor antigüedad como el go, el ajedrez o el juego del molino, exista un tema de origen que con el tiempo ha ido perdiendo su representación en la mecánica del juego. Dicha mecánica suele ser simple en cuanto a reglamento, aunque puede permitir un alto grado de complejidad táctica o estratégica.

El término complementario a «juego abstracto» sería juego temático.


</doc>
<doc id="1584" url="https://es.wikipedia.org/wiki?curid=1584" title="Juego temático">
Juego temático

Se denomina juego temático a todo juego que tiene un tema o ambientación asociado. Esto es: a aquel cuyos elementos —fichas, dados, tablero, etc.— representan en alguna medida el comportamiento y características de seres u objetos reales o imaginarios.

El término antónimo a «juego temático» sería «juego abstracto».

Cuando la fidelidad en la representación del tema tratado es alta, con reglas específicas que intentan representar en detalle los comportamientos de cada elemento de juego, los juegos temáticos se conocen también como «juegos de simulación». Este es el caso, por ejemplo, de muchos juegos de tema bélico, en los que cada unidad representada puede llegar a tener reglas específicas que concuerden con las potencialidades o acción real de su contrapartida histórica.

En otros casos, sin embargo, el comportamiento de los elementos de juego sólo se inspira vagamente en el tema que le sirve de inspiración. Este es el caso de muchos de los juegos llamados «de estilo alemán», o «eurogames».



</doc>
<doc id="1586" url="https://es.wikipedia.org/wiki?curid=1586" title="Juego de miniaturas">
Juego de miniaturas

Un juego de miniaturas es un tipo de juego de guerra en el que los elementos móviles del juego (en general miniaturas de plástico o de metal) no se desplazan sobre un tablero dotado de casillas sino sobre una maqueta o un diorama. Mientras que en los juegos de tablero los rangos de las armas y los movimientos de las fichas o miniaturas se contabilizan en casillas, en los juegos de miniaturas las miniaturas se ven desplazadas sobre una superficie no dividida en casillas, por lo que tales rangos y movimientos se contabilizan en centímetros o en otras unidades de medida de las distancias. Otros elementos característicos de esta clase de juegos suelen ser tarjetas que muestran los objetivos por conseguir, pistas o pruebas que superar. Las miniaturas de un juego de miniaturas se comercializan individualmente aunque también pueden comprarse por medio de paquetes sellados con contenido al azar o, al contrario, con un contenido temático determinado.

Los hay de diferentes tipos:

Un juego que hace uso de miniaturas no es necesariamente un juego de miniaturas. En general el término «juego de miniaturas» no se aplica a juegos que hacen uso de un tablero cuya superficie esté dividida en casillas, aunque se usen miniaturas en sus partidas. Juegos como "BattleTech", "Heavy Gear" y "Axis & Allies" por ejemplo, no son juegos de miniaturas. Sin embargo hay juegos comercialmente concebidos para incitar al coleccionismo de miniaturas y a los que se designa por tanto como «juegos de miniaturas coleccionables». Esta clase de juegos sí que puede hacer uso de un tablero, como es el caso, por ejemplo, de "MLB SportsClix" (basado en el baseball), "HeroClix" (basado en superhéroes de historieta), "Halo ActionClix" (basado en la serie de videojuegos "Halo") y "Star Wars Miniatures" (basado en el universo de "Star Wars").



</doc>
<doc id="1590" url="https://es.wikipedia.org/wiki?curid=1590" title="Jijona">
Jijona

Jijona (en valenciano y cooficialmente Xixona) es un municipio español situado en el interior de la provincia de Alicante, en la Comunidad Valenciana, España. Mundialmente famoso por ser el lugar donde se produce el apreciado dulce navideño del turrón, tanto la variedad de Jijona como la de Alicante. Cuenta con 7.057 habitantes (INE 2015).

Situada 25 km al norte de Alicante, la villa está enclavada en las faldas de la Peña Roja. En su término municipal se encuentran el puerto de la Carrasqueta, paso natural (1020 metros al paso de la carretera N-340 para comunicar Alicante con Alcoy). En cambio, el pico de la Carrasqueta se encuentra en Ibi con una altura de 1205 msnm.

Por la parte sudoeste del término pasa el río Montnegre, que proveniente del pantano de Tibi se dirige hacia la Huerta de Alicante. A su paso por el municipio jijonenco se encuentra la pequeña pedanía de Montnegre.

El término municipal está poblado de inmensos bosques de pinos y carrascas en altas montañas de más de 1000 msnm, siendo su punto más alto en la sierra del cuartel 1243 msnm. Lo que da lugar a espectaculares vistas de valles y barrancos en vertical, así como del mar Mediterráneo, debido a su cercanía; sin embargo, otras partes de su término municipal, las más próximas a la costa, sufren de una desertización preocupante.

Tiene un clima mediterráneo seco con inviernos frescos y veranos calurosos. Las precipitaciones son muy escasas, muestra de ello el paisaje subdesértico que posee, con bad-lands, ramblas... Puede sufrir la gota fría en otoño, siendo las épocas más lluviosas la primavera y el otoño. Su paisaje se puede considerar como un subdesierto.

Los primeros indicios de vida humana en el término municipal de Jijona se remontan a la Edad de Bronce (2000-1300 a. C.). La época ibérica marca la culminación de la ocupación del territorio en la Edad Antigua, de la cual hemos de resaltar los grandes poblados de Santa Bárbara y de la "Solaneta de Nuches". En esta época el nombre actual de la ciudad empieza a tomar forma, ya que parece ser era conocida como "Uxonig" (Valle del hierro).

La época paleoandalusí se caracteriza por la existencia de un poblamiento rural disperso, asentado en altura y en las proximidades de una importante vía de comunicación entre los acuíferos de Alecua y Nutxes, del que sólo se han encontrado sus enterramientos, en los yacimientos de "l'Altet, Mas dels Constantins" y "Cotelles".

El actual emplazamiento de la ciudad se remonta a la época almohade, entre finales del siglo XII y comienzos del siglo XIII, siendo el núcleo originario el castillo. 

Se trata de una ciudad históricamente marcada por su condición fronteriza, ya que desde el Tratado de Almizra (1244) se la consideró plaza límite de la Corona de Aragón con la de Castilla. Población árabe llamada "Sexona", que presentaba un castillo almohade del que aún quedan las ruinas, fue conquistada a mediados del siglo XIII, y el 28 de abril de 1268 se le concedió el título de villa real y pasó a tener representantes en las Cortes del Reino de Valencia. En 1337 participó en las Cortes de Valencia convocadas por Pedro IV, rey que se preocupó especialmente de fortificar su castillo en 1338, previendo una invasión musulmana que no se produjo.

En la guerra entre los dos Pedros, cayó en 1364 en manos de Pedro I el Cruel, rey de Castilla, para ser de nuevo reconquistada por Pedro IV el Ceremonioso, quien contó con la ayuda de gentes naturales de Penáguila, Alcoy y Cocentaina, pasando a formar parte de nuevo de la Corona de Aragón.

Durante el siglo XV, Jijona amplió su jurisdicción mediante la adquisición a sus señores feudales de los lugares de Ibi y Torremanzanas. Ibi permaneció bajo la jurisdicción de Jijona desde 1420 hasta 1629, mientras que Torremanzanas lo hizo desde 1472 a 1794. 

Durante la Guerra de Sucesión, fue una villa marcadamente proborbónica, por lo que opuso una fuerte resistencia a las tropas del archiduque Carlos, que asediaron Jijona y obligaron a los habitantes a la rendición en el año 1706. Sin embargo, la población que consiguió huir a las montañas realizó una contraofensiva que terminó con la conquista de la plaza en el 1707. Gracias a su lealtad a Felipe V, éste le otorgó a Jijona los títulos de "Ciudad" y de "leal y fidelísima" en 1708 así como la concesión de añadir a sus Armas una "Flor de Lis". A partir de ese año fue capital del Corregimiento del mismo nombre, el cual comprendía a las ciudades de Jijona y Elche y las villas de Castalla, Biar, Tibi, Ibi y Onil, y los lugares de Torremanzanas, Salinas y Benejama. El Corregimiento de Jijona fue suprimido definitivamente en 1833, con la división provincial.

Por su importancia histórica, el municipio fue dotado de una gran extensión municipal, por lo que Jijona conserva el 5º mayor término municipal de la provincia de Alicante. De su municipio se segregaron durante el siglo XVIII el pueblo de Torremanzanas y el pequeño lugar de La Sarga, en el norte del término; este último volvió a unirse a Jijona unos años después.

Jijona cuenta con 7.575 habitantes (INE 2008).
La población fluctúa según la estación del año; en verano el número de habitantes es menor.

Tradicionalmente, la economía jijonenca se ha basado en una dualidad entre la producción y comercialización de helados en verano y la de turrón en invierno, complementada por la agricultura de secano, en la cual destacaba el cultivo del almendro, cuyo fruto es materia prima para el turrón. Durante los siglos XIX y XX, ha sido natural que durante gran parte del año muchos jijonencos se encontrasen repartidos por toda España o incluso Cuba y otras partes de Iberoamérica vendiendo sus helados y turrones. Existen muchas marcas artesanas y fábricas de turrón. 

Aunque el desarrollo de la economía de la ciudad hoy en día sigue basándose en sus turrones y helados, conocidos en el mundo entero, la fábrica más importante en la localidad es propiedad de Procter & Gamble, fabricante de marcas de higiene íntima.


</div>

En las elecciones de 1995 PP y PSOE quedaron en un empate técnico respecto al número de concejales, aunque las elecciones las ganó el partido popular. Esto obligó al PP a pactar con el CIX (independentistas de Xixona). A mitad de legislatura el PSOE pactó con el CIX y arrebataron la alcaldía al PP, que ganó por mayoría simple en 1999, sacando 6 de los 13 concejales del ayuntamiento. Actualmente gobierna el PSOE con mayoría simple.

Se celebran fiestas de Moros y cristianos en agosto. En Octubre hay otras fiestas de Moros y Cristianos llamadas "Fiestas de los Heladores", ya que estan hechas para los heladores que en verano trabajan.

Las fiestas patronales de la localidad, de Moros y Cristianos, se celebran en agosto, en el fin de semana más cercano al día 24, San Bartolomé, copatrono de Jijona junto a San Sebastián.




</doc>
<doc id="1591" url="https://es.wikipedia.org/wiki?curid=1591" title="Johann Sebastian Bach">
Johann Sebastian Bach

Johann Sebastian Bach (Eisenach, en la actual Turingia, Sacro Imperio Romano Germánico, - Leipzig, en la actual Sajonia, Sacro Imperio Romano Germánico, ) fue un compositor, organista, clavecinista, violinista, violista, maestro de capilla y "Kantor" alemán del periodo barroco.

Fue el miembro más importante de una de las familias de músicos más destacadas de la historia, con más de 35 compositores famosos. Tuvo una gran fama como organista y clavecinista en toda Europa por su gran técnica y capacidad de improvisar música al teclado. Además del órgano y del clavecín, tocaba el violín y la viola da gamba.

Su fecunda obra es considerada la cumbre de la música barroca; destaca en ella su profundidad intelectual, su perfección técnica y su belleza artística, además de la síntesis de los diversos estilos nacionales de su época y del pasado. Bach es considerado el último gran maestro del arte del contrapunto, y fuente de inspiración e influencia para posteriores compositores y músicos, desde Wolfgang Amadeus Mozart pasando por Ludwig van Beethoven, Félix Mendelssohn, Robert Schumann, Franz Liszt, Johannes Brahms y Gustav Mahler hasta músicos más recientes como Arnold Schoenberg, Anton Webern, Paul Hindemith, Igor Stravinsky, Heitor Villa-Lobos o Astor Piazzolla, entre muchos otros.

Entre sus obras más conocidas se encuentran los "Conciertos de Brandeburgo", "El clave bien temperado", la "Misa en si menor", la "Pasión según San Mateo", "El arte de la fuga", "Ofrenda musical", las "Variaciones Goldberg", la "Tocata y fuga en re menor", varios (entre ellas las célebres "BWV 140" y "BWV 147"), el "Concierto italiano", la "Obertura francesa", las "Suites para violonchelo solo", las "Sonatas y partitas para violín solo", los "Conciertos para teclado" y las "Suites para orquesta".

Johann Sebastian Bach perteneció a una de las más destacadas familias musicales de todos los tiempos. Durante más de doscientos años la familia Bach produjo buenos intérpretes y compositores. En aquella época, la Iglesia luterana, el gobierno local y la aristocracia daban una significativa aportación para la formación de músicos profesionales, particularmente en los electorados orientales de Turingia y Sajonia. El padre de Johann Sebastian, Johann Ambrosius Bach, era un talentoso violinista y trompetista en Eisenach, una ciudad con cerca de 6000 habitantes en Turingia. El puesto involucraba la organización de la música profana y la participación en la música eclesiástica. Los tíos de Johann Sebastian eran todos músicos profesionales, desde organistas y músicos de cámara de la corte hasta compositores. Bach era consciente de los logros musicales de su familia, y hacia 1735 esbozó una genealogía, "Ursprung der musikalisch-Bachischen Familie" ("Origen de la familia musical Bach"), buscando la historia de las generaciones de los exitosos músicos de su familia.

Johann Sebastian Bach nació el 21 de marzo de 1685, el mismo año que Georg Friedrich Händel y Domenico Scarlatti. La fecha de su nacimiento corresponde al calendario juliano, pues los alemanes aún no habían adoptado el calendario gregoriano, por el cual la fecha corresponde al 31 de marzo. Fue el octavo hijo (el hijo mayor tenía 14 años cuando Johann Sebastian nació) del matrimonio formado entre Maria Elisabetha Lämmerhirt y Johann Ambrosius Bach, que fue quien probablemente le enseñó a tocar el violín y los fundamentos de la teoría musical. Sus tíos eran todos músicos profesionales, cuyos cargos incluían organistas de iglesia, músicos de cámara de la corte y compositores. Su tío Johann Christoph Bach lo introdujo en la práctica del órgano.

Su madre falleció en 1694, cuando Johann Sebastian tenía nueve años, y su padre —que ya le había dado las primeras lecciones de música— falleció ocho meses después. Johann Sebastian, huérfano con diez años, se fue a vivir y estudiar con su hermano mayor, Johann Christoph Bach, organista en la iglesia de San Miguel (Michaeliskirche) de Ohrdruf, una ciudad cercana. Allí copiaba, estudiaba e interpretaba música, incluyendo la de su propio hermano, a pesar de estar prohibido hacerlo porque las partituras eran muy valiosas y privadas y el papel de ese tipo era costoso. Aprendió teoría musical y composición, además de tocar el órgano, y recibió lecciones de su hermano, que lo adiestró en la interpretación del clavicordio. Johann Christoph le dio a conocer las obras de los grandes compositores del Sur de Alemania de la época, como Johann Pachelbel (que había sido maestro de Johann Christoph) y Johann Jakob Froberger; de compositores del Norte de Alemania; de los franceses, como Jean-Baptiste Lully, Louis Marchand y Marin Marais, así como del clavecinista italiano Girolamo Frescobaldi. También en esa época estudió teología, latín, griego, francés e italiano en el gimnasio (o instituto de enseñanza media) de la localidad.
A los catorce años, Johann Sebastian, junto a su amigo del colegio Georg Erdmann, mayor que él, fue premiado con una matrícula para realizar estudios corales en la prestigiosa Escuela de San Miguel en Luneburgo, no muy lejos del puerto marítimo de Hamburgo, una de las ciudades más grandes del Sacro Imperio Romano. Esto conllevaba un largo viaje con su amigo, que probablemente realizaron en parte a pie y en parte en carroza, aunque no se sabe con certeza. No hay referencias escritas de este período de su vida, pero los dos años de estancia en la escuela parecen haber sido decisivos, por haberle expuesto a una paleta más amplia de la cultura europea que la que había experimentado en Turingia. Además de cantar en el coro a capella, es probable que tocase el órgano con tres teclados y sus clavicémbalos. Quizás entró en contacto con los hijos de los nobles del Norte de Alemania, que eran enviados a esta escuela selectísima para prepararse en sus carreras diplomáticas, gubernamentales y militares.
Aunque existen pocas evidencias históricas que lo sustenten, es casi seguro que durante la estancia en Luneburgo, el joven Bach visitó la iglesia de San Juan (Johanniskirche) y escuchó (y posiblemente tocó) el famoso órgano de la iglesia (construido en 1549 por Jasper Johannsen, y conocido como «el órgano de Böhm» debido a su intérprete más destacado), un instrumento cuyas prestaciones sonoras muy bien pudieron ser la inspiración de la potente "Tocata y fuga en re menor". Dado su innato talento musical, es muy probable asimismo que tuviese un significativo contacto con los organistas destacados del momento en Luneburgo, muy particularmente con Georg Böhm (el organista de la Johanniskirche), así como con organistas de la cercana Hamburgo, como Johann Adam Reincken y Nicolaus Bruhns. Gracias al contacto con estos músicos, Johann Sebastian tuvo acceso probablemente a los instrumentos más grandes y precisos que había tocado hasta entonces. En esta etapa se familiarizó con la música de la tradición académica organística del Norte de Alemania, especialmente con la obra de Dietrich Buxtehude, organista en la iglesia de Santa María de Lübeck, y con manuscritos musicales y tratados de teoría musical que estaban en posesión de aquellos músicos.

En enero de 1703, poco después de terminar los estudios y graduarse en San Miguel y de ser rechazado para el puesto de organista en Sangerhausen, Bach logró un puesto como músico de la corte en la capilla del duque Johann Ernst III, en Weimar, Turingia. No está claro cuál era su papel allí, pero parece que incluía tareas domésticas no musicales. Durante sus siete meses de servicio en Weimar, su reputación como teclista se extendió tanto que fue invitado a inspeccionar el flamante órgano de la iglesia de San Bonifacio (St.-Bonifatius-Kirche, posteriormente Bachkirche, iglesia de Bach) de la cercana ciudad de Arnstadt, a 40 kilómetros al sureste de Weimar, y a dar el concierto inaugural en él. La familia Bach tenía estrechos vínculos con esta vieja ciudad de Turingia, al lado del Thüringenwald, o bosque de Turingia. En agosto de 1703 aceptó el puesto de organista en dicha iglesia, con obligaciones ligeras, un salario relativamente generoso y un buen órgano nuevo, afinado conforme a un sistema nuevo que permitía que se utilizara un mayor número de teclas. En esa época, Bach estaba emprendiendo la composición seria de preludios para órgano; estas obras, inscritas en la tradición del Norte de Alemania de preludios virtuosos e improvisatorios, ya mostraban un estricto control de los motivos (en ellas, una idea musical sencilla y breve se explora en sus consecuencias a través de todo un movimiento). Sin embargo, en estas obras el compositor aún no había desarrollado plenamente su capacidad de organización a gran escala y su técnica contrapuntística (donde dos o más melodías interactúan simultáneamente).
Las fuertes conexiones familiares y el hecho de estar empleado por un entusiasta de la música no impidieron que surgiera tensión entre el joven organista y las autoridades después de varios años en el puesto. Johann Sebastian estaba insatisfecho con el nivel de los cantantes del coro, y su empleador se mostró muy molesto después de que Bach se ausentara de Arnstadt sin autorización durante varios meses en 1705-1706 para visitar en Lübeck al gran maestro Dietrich Buxtehude y asistir a su "Abendmusiken" en la iglesia de Santa María (Marienkirche). Este episodio bien conocido de la vida de Bach implica que tuvo que caminar unos 400 kilómetros de ida y otros tantos de vuelta a pie para pasar tiempo con el hombre al que posiblemente consideraba como la figura máxima entre los organistas alemanes. El viaje reforzó el influjo del estilo de Buxtehude como fundamento de la obra temprana de Bach, y el hecho de que alargase su visita durante varios meses sugiere que el tiempo que pasó con el anciano tuvo un alto valor para su arte. Johann Sebastian quería convertirse en amanuense (asistente o sucesor) de Buxtehude, pero no quiso casarse con su hija, que era la condición para su nombramiento.

A pesar de su cómoda posición en Arnstadt, hacia 1706 parece que Bach se dio cuenta de que necesitaba escapar del entorno familiar y avanzar en su carrera. Le ofrecieron un puesto mejor pagado como organista en la iglesia de San Blas (Divi Blasii) de Mühlhausen, Turingia, una importante ciudad al norte. El año siguiente tomó posesión de este mejor puesto, con paga y condiciones significativamente superiores, incluyendo un buen coro. A los cuatro meses de haber llegado a Mühlhausen, se casó, el 17 de octubre de 1707, con Maria Barbara Bach, una prima suya en segundo grado, con quien tendría siete hijos, de los cuales cuatro alcanzaron la edad adulta. Dos de ellos —Wilhelm Friedemann Bach y Carl Philipp Emanuel Bach— llegaron a ser compositores importantes en el ornamentado estilo rococó que siguió al Barroco.

La iglesia y el ayuntamiento de la ciudad debían de estar orgullosos de su nuevo director musical, ya que de buena gana aceptaron los requerimientos de Bach e invirtieron una gran suma en la renovación del órgano de la iglesia de San Blas, y les agradó tanto la elaborada cantata festiva que Bach escribió para la inauguración del nuevo concejo de la ciudad en 1708 —"Gott ist mein König, BWV 71", claramente al estilo de Buxtehude— que pagaron complacidos la publicación de la obra, y en dos ocasiones, en años posteriores, tuvo que regresar el compositor para dirigirla.

Sin embargo, su estancia en la ciudad terminaría el mismo año, cuando obtuvo un puesto mejor en Weimar.

Transcurrido apenas un año, en 1708, una nueva oferta de trabajo le llegó desde la corte ducal en Weimar. El retorno al lugar de su primera experiencia laboral fue esta vez muy diferente. El puesto de concertino, un excelente salario y la posibilidad de trabajar con músicos profesionales fueron seguramente motivo suficiente para dejar su puesto en Mühlhausen.

Bach se trasladó con su familia a un apartamento muy cercano al palacio ducal. Al año siguiente nació su primer hijo y se unió a ellos la hermana mayor y soltera de Maria Barbara. Permaneció con ellos ayudando en las tareas domésticas hasta su muerte en 1729. En los siguientes años nacieron sus primeros hijos, de los cuales destacan Wilhelm Friedemann Bach y Carl Philipp Emanuel Bach.

A la muerte del príncipe Johann Ernst en 1707, su hermano Wilhelm Ernst había asumido el poder de facto. Por su anterior cercanía con el duque Johann Ernst, que había sido a su vez un avezado músico y admirador de la música italiana, Bach había estudiado y transcrito las obras de Antonio Vivaldi, Arcangelo Corelli y Giuseppe Torelli, entre otros autores italianos, gracias a lo cual había aprendido a escribir aperturas dramáticas, asimilado su dinamismo y emotividad armónica, y aplicado dichas cualidades a sus propias composiciones, que a su vez eran interpretadas por el conjunto musical del duque Wilhelm Ernst.

Este período en la vida de Bach fue fructífero y comenzó una época de composición de obras para teclado y orquestales. Alcanzó el nivel de competencia y confianza para ampliar las estructuras existentes e incluir influencias del exterior. Bach absorbió estos aspectos estilísticos en parte mediante la transcripción de conciertos para cuerda y viento para clavecín y órgano de Vivaldi; muchas de esas obras transcritas son todavía interpretadas con frecuencia. Bach se sintió atraído especialmente con el estilo italiano en el que uno o más instrumentos solistas alternan sección por sección con la orquesta completa a través de un movimiento.

Continuó tocando y componiendo para órgano e interpretando música de concierto con el conjunto del duque. También comenzó a componer preludios y fugas, posteriormente recopilados en su obra monumental "El clave bien temperado" ("Das Wohltemperierte Klavier"), impreso por primera vez en 1801, que consta de dos libros compilados en 1722 y 1744, cada uno de los cuales contiene un preludio y fuga en cada tonalidad mayor y menor.

En el ambiente familiar comenzó a escribir la obra "Orgelbüchlein" ("Pequeño libro para órgano") para su hijo mayor Wilhelm Friedemann, obra didáctica que dejó inconclusa. Contenía corales tradicionales luteranos arreglados en elaboraciones complejas, para formar organistas.

En 1713 le ofrecieron un puesto en Halle cuando aconsejó a las autoridades durante la renovación de Christoph Cuntzius del órgano principal de la galería oeste de la Marktkirche Unser Lieben Frauen. Johann Kuhnau y Bach volvieron a tocar cuando se inauguró en 1716. Los musicólogos debaten si su primera cantata "Christen, ätzet diesen Tag" BWV 63, fue estrenada aquí en 1713, o si fue interpretada para el bicentenario de la Reforma Protestante en 1717.

En 1717 ocurre en Dresde el anecdótico intento de duelo musical con Louis Marchand (se dice que Marchand abandonó la ciudad tras escuchar previamente y a escondidas a Bach). Ese mismo año, con motivo del fallecimiento del maestro de capilla (o "Kapellmeister") de la corte, Bach solicitó el puesto vacante, pero el duque decidió otorgárselo al hijo del fallecido maestro de capilla. Esto lo decepcionó profundamente y lo impulsó a presentar su renuncia, lo que disgustó al duque Wilhelm Ernst, que ordenó su arresto por algunas semanas en el castillo antes de aceptarla. Según una traducción del informe del secretario del tribunal, fue encarcelado durante casi un mes antes de ser despedido desfavorablemente:

Bach comenzó a buscar un trabajo más estable que propiciara sus intereses musicales. El príncipe Leopoldo de Anhalt-Cöthen contrató a Bach como maestro de capilla en 1717. El príncipe Leopoldo, que también era músico, apreciaba su talento, le pagaba bien y le dio un tiempo considerable para componer y tocar. Sin embargo, el príncipe era calvinista y no solía usar música elaborada en sus misas; por esa razón, la mayoría de las obras de Bach de este período fueron profanas. Como ejemplo están las "Suites para orquesta", las seis "Suites para violonchelo solo", las "Sonatas y partitas para violín solo" y los "Conciertos de Brandeburgo". También compuso cantatas profanas para la corte, como "Die Zeit, die Tag und Jahre macht, BWV 134a".

A pesar de haber nacido en el mismo año y de estar separados únicamente por alrededor de 130 kilómetros, Bach y Händel nunca se conocieron. En 1719, Bach realizó un viaje de unos treinta kilómetros desde Köthen hasta Halle con la intención de conocer a Händel, pero éste había abandonado recientemente la ciudad. En 1730, Friedmann, el hijo de Johann Sebastian, viajó a Halle para invitar a Händel a visitar a la familia Bach en Leipzig; sin embargo, dicha visita nunca tuvo lugar. Su mujer, Ana Magdalena, contó cómo le encantaba a su marido transcribir durante horas las partituras de Händel y cómo hablaba siempre de él y de su música con verdadera devoción.

El 7 de julio de 1720, mientras Bach estaba de viaje con el príncipe Leopoldo en Carlsbad (Karlovy Vary), la tragedia llegó a su vida: su esposa, Maria Barbara Bach, murió repentinamente. Algunos especialistas señalan que en memoria de ella compuso la "Partita para violín solo n.º 2, BWV 1004", en especial, su última sección, la «Chacona». Al año siguiente, Bach conoció a Anna Magdalena Wilcke, una joven y talentosa soprano que cantaba en la corte de Köthen. Se casaron el 3 de diciembre de 1721. Pese a la diferencia de edad —ella tenía 17 años menos— tuvieron un matrimonio estable. Juntos tuvieron trece hijos más, seis de los cuales alcanzaron la edad adulta: Gottfried Heinrich, Johann Christoph Friedrich y Johann Christian, que llegaron a ser músicos destacados; Elisabeth Juliane Friederica (1726-81), quien se casó con el alumno de su padre Johann Christoph Altnickol; Johanna Carolina (1737-81); y Regina Susanna (1742-1809).

En 1723, fue nombrado "Kantor" de la Thomasschule en la iglesia luterana de Santo Tomás ("Thomaskirche") de Leipzig y director musical de las principales iglesias de la ciudad, San Nicolás ("Nikolaikirche") y San Pablo ("Paulinerkirche"), la iglesia de la Universidad. Era un prestigioso puesto en la ciudad mercantil líder del Electorado de Sajonia, un electorado vecino de Turingia. Aparte de sus breves ocupaciones en Arnstadt y Mühlhausen, éste fue el primer trabajo estatal de Bach, en una carrera que había estado estrechamente ligada al servicio a la aristocracia.
Este puesto final, que mantuvo durante 27 años hasta su muerte, lo puso en contacto con las maquinaciones políticas de su empleador, el Ayuntamiento de Leipzig, dentro del cual había dos facciones: los absolutistas, leales al monarca sajón en Dresde, Augusto II de Polonia llamado "el Fuerte", y la facción de la ciudad-estado, que representaba los intereses de la clase mercantil, los gremios y los aristócratas menores. Bach fue contratado por los monárquicos, en particular por el alcalde de aquella época, Gottlieb Lange, un abogado joven que había servido en la corte de Dresde. Coincidiendo con el nombramiento de Bach, a la facción de la ciudad-estado se le otorgó el control de la Thomasschule, y Bach fue requerido para varios compromisos con respecto a sus condiciones de trabajo.

El trabajo de Bach le requería instruir a los estudiantes de la Thomasschule en el canto y proveer semanalmente de música sacra a las principales iglesias de la ciudad. Además, tenía que enseñar latín, pero le permitieron emplear a un ayudante para que lo hiciera en su lugar. Le encargaron una cantata para el servicio de los domingos y días festivos en la iglesia durante el año litúrgico. Habitualmente interpretaba sus propias cantatas, muchas de las cuales fueron compuestas durante sus primeros tres años en Leipzig. La primera de ellas fue "Die Elenden sollen essen, BWV 75", representada por primera vez en la Nikolaikirche el 30 de mayo de 1723, el primer domingo después del Domingo de Trinidad. Bach recopiló sus cantatas en ciclos anuales. Cinco son mencionados en sus obituarios, aunque sólo existen tres. La mayoría de estas obras se utilizaban en las lecturas del Evangelio prescritas para cada domingo y día festivo en el año luterano. Bach comenzó un segundo ciclo anual el primer domingo después del de Trinidad de 1724 y compuso únicamente cantatas con coro; muchas de ellas fueron compuestas usando corales, himnos tradicionales de la Iglesia luterana. Entre ellos se incluyen" O Ewigkeit, du Donnerwort, BWV 20; Wachet auf, ruft uns die Stimme, BWV 140; Nun komm, der Heiden Heiland, BWV 62; "y "Wie schön leuchtet der Morgenstern, BWV 1."

Para los ensayos e interpretaciones de estas obras en la iglesia de Santo Tomás, Bach probablemente se sentaba al clave o dirigía frente al coro de espaldas a la congregación. A la derecha del órgano en una galería lateral estarían las maderas, los metales y timbales, y a la izquierda los instrumentos de cuerda pulsada.
El ayuntamiento sólo otorgaba alrededor de ocho instrumentistas permanentes, limitación que fue fuente de constante fricción con Bach, que tuvo que reclutar al resto de los veinte o más músicos requeridos para las partituras medianas o grandes, en la universidad, la Thomasschule y el público. El órgano o el clave era probablemente tocado por el compositor (cuando no estaba de pie dirigiendo), el organista de casa, o uno de sus hijos, Wilhelm Friedemann o Carl Philipp Emanuel.
Bach seleccionaba a los coristas: sopranos y contraltos de la Thomasschule, y tenores y bajos de la Thomasschule y de cualquier lugar de Leipzig. Las intervenciones en bodas y funerales daban un ingreso extra a estos grupos; es probable que para este propósito, y para el entrenamiento escolar, escribiese al menos seis motetes, la mayoría para doble coro. Como parte de su trabajo regular en la iglesia dirigía motetes de la Escuela veneciana y de alemanes como Heinrich Schütz, que servirían como modelos formales para sus propios motetes.

Bach amplió sus horizontes compositivos más allá de la liturgia al hacerse cargo, en marzo de 1729, de la dirección del Collegium Musicum, una sociedad musical de estudiantes fundada en 1703 por Georg Philipp Telemann. Ésta era una de las docenas de sociedades privadas creadas por estudiantes universitarios activos musicalmente que existían en las principales ciudades germanoparlantes y que, lideradas por los músicos profesionales más destacados de cada ciudad, se fueron haciendo progresivamente más importantes en la vida pública musical. En palabras de Christoph Wolff, asumir la dirección fue un movimiento astuto que «consolidó el firme control que ejercía Bach sobre las principales instituciones musicales de Leipzig». Durante todo el año, el Collegium Musicum de Leipzig participaba regularmente en escenarios como la Cafetería Zimmermann (Zimmermannsches Caffeehaus), una cafetería en la calle Sainte-Catherine frente a la plaza del mercado. Muchas de las obras de Bach durante las décadas de 1730 y 1740 fueron escritas para el Collegium Musicum e interpretadas por éste; entre esas obras se encuentran parte de sus "Klavier-Übung" y muchos de sus conciertos para violín y clave.

Si bien está claro que nadie en el ayuntamiento dudaba del genio de Bach, hubo una constante tensión entre el "Kantor", que se consideraba el líder de la música eclesial de la ciudad, y la facción de la ciudad-estado, que lo veía como un maestro de escuela y quería reducir el énfasis en la composición de música tanto para la iglesia como para la Thomasschule. A partir de 1730, la facción de la ciudad-estado estaría encabezada por el teólogo y filólogo Johann August Ernesti. Profesor en la Universidad de Leipzig, Ernesti, junto con buena parte del claustro de la Universidad, propugnaba un cambio de modelo educativo que se reorientaría hacia disciplinas más ilustradas como las ciencias naturales o la filología. Las múltiples prerrogativas de Bach como "Kantor" de Santo Tomás chocaban con esta pretensión, por lo que pronto surgiría una agria disputa entre Bach y Ernesti, que pretendía relegar la importancia de la música a un segundo puesto, y retirar al "Kantor" toda competencia en materia educativa. El nivel de la disputa llegó a tal punto que Bach pidió ayuda al y elector de Sajonia, Augusto III, que intervino a su favor. El hecho de que Bach hiciera intervenir al elector de Sajonia escandalizó a la corporación de Leipzig, que consideraba el asunto un tema local e interpretó la actitud de Bach como propia de alguien con delirios de grandeza. Tras la disputa, las relaciones entre Bach y sus patronos locales se degradarían rápidamente. Sea como fuera, el ayuntamiento nunca cumplió la promesa —que hizo Lange en la entrevista inicial— de ofrecer un salario de 1000 táleros anuales, si bien se ofreció a Bach y a su familia una reducción de impuestos y un buen apartamento en una de las alas de la Thomasschule, que fue renovado con gran gasto en 1732.
En 1733, Bach compuso el «Kyrie» y «Gloria» de la "Misa en si menor". Presentó el manuscrito a Augusto III, en un intento finalmente exitoso de persuadir al monarca para que lo nombrara Compositor Real de la Corte. Posteriormente extendió dicha obra en una misa completa, añadiendo un «Credo», «Sanctus» y «Agnus Dei», cuya música fue sacada casi por completo de sus propias cantatas. El nombramiento de Bach como compositor de la corte fue parte de su larga disputa para conseguir un mayor poder de negociación con el ayuntamiento de Leipzig. Aunque la misa completa probablemente nunca se representó durante la vida del compositor, está considerada entre la obras corales más grandes de todos los tiempos. Entre 1737 y 1739, el antiguo alumno de Bach Carl Gotthelf Gerlach asumió el puesto de director del Collegium Musicum.

En 1747 fue invitado a la corte de Federico II el Grande en el palacio de Sanssouci (Potsdam), donde uno de de sus hijos, Carl Philipp Emanuel, estaba al servicio del monarca como clavecinista de la corte. El rey interpretó un tema para Bach y lo desafió a improvisar una fuga basada en éste. El compositor improvisó una fuga en tres partes en el pianoforte del monarca, entonces una novedad, y posteriormente presentó al rey Federico la "Ofrenda musical", que consistía en fugas, cánones y un trío basado en ese tema. Su fuga en seis partes incluye un tema ligeramente alterado, más adecuado para una extensa elaboración.
Ese mismo año, Bach se unió a la Correspondierende Societät der musicalischen Wissenschaften de Lorenz Christoph Mizler después de una larga preparación formal, necesaria para acceder a la Sociedad. Mizler llamó a su antiguo profesor uno de sus "guten Freunde und Gönner" («buenos amigos y patrocinadores»). Esto es particularmente notable porque Mizler era un apasionado representante de la Ilustración alemana y polaca. La afiliación de Bach tuvo varios efectos. Con ocasión de su entrada en la Sociedad, Bach compuso "Einige canonische Veraenderungen, / über das / Weynacht-Lied: / Vom Himmel hoch da / komm ich her" (BWV 769). En 1746, durante la preparación de la entrada del compositor, Elias Gottlob Haussmann pintó el famoso retrato de Bach. Se tenía que enviar un retrato a cada miembro de la Sociedad. Bach dedicó por este retrato el "Canon triplex a 6" (BWV 1076) a la Sociedad. La Sociedad insistió en realizar un obituario de cada miembro, por lo que Mizler inició la historia de las biografías de Bach en la "Musikalische Bibliothek". A menudo se argumentó que otras obras tardías del compositor pudieron tener conexión con la teoría musical basada en la Sociedad. Una de esas obras fue "El arte de la fuga", que compuso poco antes de su muerte, cuya fuga final Bach nunca completó. Consiste en 18 fugas y cánones complejos basados en un tema simple y fue publicada a título póstumo en 1751.

La última obra de Bach completada fue un preludio coral para órgano, titulado "Vor deinen Thron tret ich hiermit", BWV 668a, que dedicó a su yerno Johann Christoph Altnickol, desde su lecho de muerte. En las notas de los tres pentagramas de la cadencia final, leídas según la denominación germana, se encuentran las iniciales «JSB».

La salud de Bach empeoró en 1749; el 2 de junio, Heinrich von Brühl escribió a uno de los burgomaestres de Leipzig para pedirle que su director de música, Gottlob Harrer, ocupara los cargos de "Thomaskantor" y director musical «ante el eventual [...] fallecimiento del señor Bach». Bach se fue quedando progresivamente más ciego, por lo que el cirujano británico John Taylor lo operó durante su visita a Leipzig entre marzo y abril de 1750.

El 28 de julio de 1750, Johann Sebastian Bach falleció a la edad de 65 años. Un periódico de la época informó que «las infelices consecuencias de su muy poco exitosa operación» fueron la causa de su muerte. Historiadores modernos especulan con que la causa de su muerte fue una apoplejía complicada por una neumonía. Su hijo Carl Emanuel y su alumno Johann Friedrich Agricola escribieron su obituario. Actualmente se cree que su ceguera fue originada por una diabetes sin tratar. Según ciertos médicos, padecía de blefaritis, enfermedad ocular visible en los retratos de sus últimos años.
Las posesiones de Bach incluían cinco clavecines, dos laúd-clave, tres violines, tres violas, dos violonchelos, una viola da gamba, una laúd, una espineta y 52 «libros sagrados», incluyendo obras de Martín Lutero y Flavio Josefo. Inicialmente fue enterrado en el viejo cementerio de San Juan en Leipzig. Su tumba estuvo sin identificar durante casi 150 años hasta que, en 1894, su ataúd fue encontrado finalmente y trasladado a una cripta en la iglesia de San Juan. Este edificio quedó destruido durante un bombardeo del bando aliado durante la Segunda Guerra Mundial, por lo que desde 1950 los restos de Johann Sebastian Bach reposan en una tumba en la iglesia de Santo Tomás de Leipzig.

Johann Sebastian Bach encabezó una familia numerosa con un total de veinte hijos, nacidos entre sus 23 y sus 57 años. Tuvo siete hijos de su primer matrimonio, de los cuales sobrevivieron cuatro, y trece del segundo, de los cuales sobrevivieron sólo cinco. Su primera esposa fue su prima segunda, Maria Barbara Bach (1684-1720), con la que se casó en 1707. Su segunda esposa fue la cantante Anna Magdalena Wilcke (1701-1760), con la que contrajo matrimonio en 1721.



Cinco de los hijos se dedicaron a la música, aunque uno de ellos (Johann Gottfried Bernhard) abandonó su carrera y murió prematuramente a los 24 años. Los otros cuatro llegaron a convertirse en compositores e intérpretes reputados por derecho propio: Wilhelm Friedemann Bach, Carl Philipp Emanuel Bach (de quien Wolfgang Amadeus Mozart tenía muy buena opinión), Johann Christoph Friedrich Bach y Johann Christian Bach, epígono de la época preclásica y una de las influencias principales del propio Mozart.

Sin embargo, la confianza que Bach puso en su hijo mayor, Wilhelm Friedemann, tuvo tristes consecuencias para su legado tras su fallecimiento: el hijo perdió para siempre varias pasiones compuestas por su padre. Los cuidados de Carl Phillip Emanuel sí permitieron conservar una buena parte de las obras maestras paternas.

La obra de Bach se puede dividir en tres grandes períodos bien diferenciados, marcados por las influencias y la asimilación de los estilos de su época, el desarrollo, búsqueda y evolución de su estilo personal, y los puestos profesionales que desempeñó.
El primer período, el de aprendizaje y estudio, va desde 1700 hasta 1713, estando ya en Weimar; en él escribió música para teclado y cantatas sacras, y formó su estilo, que sintetizó toda la tradición de la música clásica europea precedente: la polifonía clásica fijada en tiempos de Giovanni Pierluigi da Palestrina; el primer Barroco de Girolamo Frescobaldi; la música francesa del ; y la de autores alemanes e italianos de su época como Dietrich Buxtehude, Johann Pachelbel y Antonio Vivaldi. De este último copió y adaptó obras desde su juventud: así lo hizo en Weimar, cuando, gracias al duque, pudo versionar algunas de sus obras en sus "Conciertos BWV 592-597" y "BWV 972-987"). Bach también se interesaba en compositores contemporáneos, a quienes estudiaba y con muchos de los cuales mantuvo una relación personal directa. Entre ellos se encontraban Jan Dismas Zelenka, Johann Mattheson, Georg Philipp Telemann, Reinhard Keiser y Georg Friedrich Händel.
El segundo período, ya de plena madurez, empieza en 1713, en Weimar, y acaba en 1740, afincado ya en Leipzig. Bach dominaba los dos estilos principales de su época, el francés y el italiano (progresiones armónicas ya plenamente tonales, claridad melódica y dinamismo rítmico), y, de hecho, su producción estuvo muy influida por el concierto italiano y la suite francesa. Sintetizó en sus obras elementos de ambos junto a rasgos autóctonos alemanes como el complejo contrapunto y textura interna y el coral, del que hace amplio uso en sus obras religiosas. Resulta de todo ello un estilo fácilmente reconocible, moderno pero de claras raíces en el pasado. En Leipzig y Köthen, ya forjado su estilo personal, adquiere un profundo dominio técnico. Es así como hizo amplio uso de la técnica y formas alemanas del órgano (tocatas, preludios, fugas, corales), francesas del clave (suites, oberturas) e italianas del violín (conciertos, sonatas, sinfonías).

[[Archivo:Bach-ornamentguide.jpg|thumb|left|La guía de Bach sobre los ornamentos contenidos en el [[Pequeño libro de Wilhelm Friedemann Bach.]]
El último período de su música va desde la publicación de "[[Clavier-Übung|Klavier-Übung]] III," en 1739, hasta su muerte en 1750. En esta etapa compuso el "[[El arte de la fuga]]". Durante los últimos años de su vida —dominados ya en Alemania por la estética de la [[Ilustración]]— su obra fue considerada anticuada, árida, difícil y saturada de adornos. En este período escribió obras instrumentales singularmente densas, como haría más adelante Beethoven, y su estilo personal se volvió más contrapuntístico, con apenas una leve influencia de la nueva [[música galante]] o estilo pre[[música del Clasicismo|clásico]] naciente en aquellos momentos, que se caracterizaba por su carácter [[Homofonía|homofónico]] y apenas utilizaba el cargado contrapunto que Bach usaba. Así, en 1737, [[Johann Adolph Scheibe]], crítico musical de la nueva mentalidad ilustrada, criticó duramente la música de Bach: «Espera que instrumentistas y cantantes hagan lo mismo que él cuando toca el clavecín».

[[Archivo:Aria.png|thumb|left|"Aria" de las "Variaciones Goldberg", mostrando el uso de ornamentos de Bach.]]
Escribió en casi todos los géneros y formas de su época, en multitud de combinaciones instrumentales y vocales. Culminó y realizó obras destacables en todos ellos e incluso creó géneros nuevos, como la sonata para teclado y un instrumento. Única excepción fue la [[ópera]], género para el cual no compuso, aunque el lenguaje e influencia de la [[ópera seria]] del está presente en toda su producción vocal. La influencia de la ópera se plasma sin embargo especialmente en las [[Anexo:Cantatas de Johann Sebastian Bach|cantatas]], [[Pasiones (Bach)|pasiones]] y [[Oratorio (música)|oratorios]]. "[[Schweigt stille, plaudert nicht, BWV 211]]" (conocida como "Cantata del café") de 1735 es, prácticamente, una pequeña ópera sin representación escénica, y sus pasiones (como la "[[Pasión según San Mateo, BWV 244]]", de 1727) contienen muchos elementos operísticos. Bach, sin embargo, sí conoció directamente la ópera, como en 1735 cuando —acompañado de uno de sus hijos— asistió a la representación de una ópera de Jean Christophe Geiser.

Después de Bach, algunas formas musicales, como las pasiones, las cantatas sacras, las tocatas y las fugas, fueron cayendo en desuso para los grandes compositores. Tras su muerte, la música tomó una dirección en la que su obra no tuvo cabida; él es el punto final respecto a una forma de entender la música que se remontaba a la Edad Media, cuando tenían más importancia la [[polifonía]] que la [[armonía]] o el [[Timbre (acústica)|timbre]]. Pero Bach también fue innovador y abrió caminos para la música del futuro: por ejemplo, fue el primer gran maestro del concierto para teclado. De hecho, el quinto "[[BWV 1050|Concierto de Brandeburgo, BWV 1050]]" (1719), en el cual el teclado adquiere un papel [[Solo (música)|solista]] que hasta entonces nunca había tenido, puede considerarse el primer concierto escrito para teclado, que continuó en la [[Conciertos para clavecín (Bach)|serie de conciertos "BWV 1052-1065"]] (1735). Después, Händel y Vivaldi tomarían ejemplo de esta novedad y compusieron sus "Conciertos para órgano, opus 4" (1735) y "Concierto para clavecín, RTV 780," respectivamente, con lo que se fundó un nuevo género que adquiriría enorme importancia en los siglos posteriores.

[[Archivo:Lama asabthani.tif|thumb|left|Autógrafo de Bach del recitativo con el texto del evangelio de la muerte de Cristo de la Pasión de San Mateo. (Mateo 27: 45-47a).]]

En 1950, [[Wolfgang Schmieder]] elaboró el registro o [[Catálogo musical|catálogo]] de sus obras, que abarca en total 1128 obras. Se conoce por las siglas «BWV», que significan «[[Bach-Werke-Verzeichnis]]» o «Catálogo de las obras de Bach». Es un sistema de numeración usado para identificar las obras del compositor alemán, que se agrupan en dos grandes secciones.

[[Archivo:BWV 248 Libretto.JPG|thumb|"Oratorio de Navidad": impreso impresa del libreto]]
Primero, la [[música vocal]] (BWV 1-524), que comprende [[cantata]]s ([[Anexo:Cantatas de Johann Sebastian Bach|BWV 1-224]]); obras [[coro|corales]] a gran escala (BWV 225-249), incluyendo [[pasión (música)|pasiones]] (BWV 250-524), [[Oratorio (música)|oratorios]] y [[Música coral|corales]], y otras obras [[Música sacra|sacras]].

[[Archivo:Das Wohltemperirte Clavier titlepage 2.jpg|thumb|left|Carátula original de la copia manuscrita de Johann Sebastian Bach de "El clavecín bien temperado". Dice en alemán (con la letra manuscrita de Bach: «El “[instrumento de] teclado bien temperado”, o preludios y fugas en todos los tonos y semitonos, ambos con la tercera mayor o "ut", "re", "mi" y con la tercera menor o "re", "mi" "fa", están compuestos para la práctica y el provecho de los jóvenes músicos deseosos de aprender y para el entretenimiento de aquellos que ya conocen este arte».]]

Después la [[música instrumental]] (BWV 525-1127), que incluye obras para [[órgano (instrumento musical)|órgano]] (BWV 525-748), otras obras para [[instrumento de teclado|teclado]] (BWV 772-994), música para [[laúd]] ([[Composiciones para laúd (Bach)|BWV 995-1000]]), música de cámara (BWV 1001-40), música orquestal (BWV 1041-71), y [[canon (música)|cánones]] y [[fuga]]s (BWV 1072-1126), además de otro tipo de música instrumental como [[concierto]]s (varios para un único solista y otros con hasta cuatro solistas), [[sonata]]s, [[suite]]s, [[obertura]]s, [[preludio]]s, [[Fantasía (música)|fantasías]], [[ricercare]]s, [[Variación (música)|variaciones]] y [[pasacalle]]s. A su vez, dentro de cada una de estas dos divisiones, las obras se agrupan por géneros, y no por fecha de composición. Por esta razón, un número BWV menor no indica una obra cronológicamente temprana. También existe un catálogo elaborado por [[Christoph Wolff]], de menor difusión.

La música vocal de Bach que se conserva consta de 525 obras, aunque sólo 482 de ellas están completas. En su mayoría es [[Música sacra|sacra]] —sólo 24 cantatas, cuatro [[lied]]er y un [[quodlibet]] son [[Música profana|profanos]]— y compuesta para la liturgia de la Iglesia luterana alemana, en la que la música ocupa un importante lugar.

[[Archivo:Goldberg-titlepage.png|thumb|Portada de las "Variaciones Goldberg"]]
La gran mayoría de su música vocal fue compuesta en Leipzig entre los años 1723 y 1741, cuando Bach era [[Kantor (músico)|"Kantor"]] y tenía entre sus obligaciones componer cantatas, pasiones y [[motete]]s para las cinco iglesias más grandes de la ciudad, además de para actos civiles y religiosos, como por ejemplo funerales.

Bach diferenciaba escasamente en estilo sus obras profanas frente a las religiosas. Un ejemplo de ello es la utilización de los mismos textos para la música sacra y la profana, como sucede con la música del «Hosanna» de la "[[Misa en si menor, BWV 232]]", que antes había empleado en una cantata en homenaje a [[Augusto II de Polonia]] con motivo de una de sus visitas oficiales a Leipzig.

Bach compuso pasiones para los servicios del Viernes Santo y oratorios como el [[Oratorio de Navidad, BWV 248|"Oratorio de Navidad"]], que es un conjunto de seis cantatas para uso en la temporada litúrgica de Navidad. [128] [129] [130] Oratorios más cortos son el "[[Oratorio de Pascua, BWV 249|Oratorio de Pascua]]" y el "[[Lobet Gott in seinen Reichen, BWV 11|Oratorio de la Ascensión]]".

Pasión según San Mateo

Ver también: [[Pasión según San Mateo, BWV 244|Pasión según San Mateo]]

Con su doble coro y orquesta, la Pasión según San Mateo es una de las obras más extensas e interpretadas de Bach.

Pasión según San Juan

Ver también: [[Pasión según San Juan, BWV 245|Pasión según San Juan]]

La Pasión según San Juan fue la primera Pasión de Bach compuesta durante su mandato como Thomaskantor en Leipzig.

Según su obituario, Bach habría compuesto ciclos de cinco años de cantatas sagradas, y cantatas de iglesia adicionales, por ejemplo, para bodas y funerales. Aproximadamente 200 de estas obras sagradas son existentes, se estima que dos tercios del número total de cantatas de iglesias que compuso. El sitio web de Bach Digital enumera 50 cantatas seculares conocidas del compositor, aproximadamente la mitad de las cuales son existentes o reconstruibles en gran medida.

Las cantatas de Bach varían mucho en forma e instrumentación, incluidas las de cantantes solistas, coros individuales, grupos instrumentales pequeños y grandes orquestas. Muchas consisten en un gran estribillo de apertura seguido de uno o más pares de recitativos y arias para solistas (o dúos) y una coral final. La melodía de la coral final a menudo aparece como un [[cantus firmus]] en el movimiento de apertura.

Las primeras cantatas de Bach datan de sus años en Arnstadt y Mühlhausen. La más antigua con una fecha conocida es el retraso de "[[Christ lag in Todes Banden, BWV 4]]", para la Semana Santa de 1707, que es una de sus cantatas de coral. "Gottes Zeit ist die allerbeste Zeit, BWV 106", akk "Actus Tragicus", es una cantata funeraria del período de Mühlhausen. Alrededor de 20 cantatas eclesiásticas son de sus últimos años en Weimar, por ejemplo, "[[Ich hatte viel Bekümmernis, BWV 21]]".

Después de asumir su cargo como Thomaskantor a fines de mayo de 1723, Bach realizó una cantata cada domingo y fiesta que correspondía a las lecturas del misal de la semana. Su primer ciclo de cantatas transcurrió desde el primer domingo después de la Trinidad de 1723 hasta el domingo de la Trinidad el año siguiente. Por ejemplo, la cantata H"erz und Mund und Tat und Leben, BWV 147", pertenece a este primer ciclo. El ciclo de cantatas de su segundo año en Leipzig se llama el ciclo de la cantata coral ya que consiste principalmente en obras en el formato de cantata coral. Su tercer ciclo de cantatas se desarrolló durante un período de varios años, seguido por el ciclo Picander de 1728 a 1729.

Las cantatas de iglesia posteriores incluyen las cantatas de coral "[[Ein feste Burg ist unser Gott, BWV 80]]" (versión final) y "[[Wachet auf, ruft uns die Stimme, BWV 140]]". Solo los primeros tres ciclos de Leipzig son más o menos completamente existentes. Además de su propio trabajo, Bach también interpretó cantatas de [[Georg Philipp Telemann|Telemann]] y de su pariente lejano [[Johann Ludwig Bach]]. 

Bach también escribió cantatas seculares, por ejemplo, para miembros de la familia real sajona-polaca y príncipe-electoral (por ejemplo, "Trauer-Ode"), u otras ocasiones públicas o privadas (por ejemplo, la "Cantata de caza"). El texto de estas cantatas era ocasionalmente en dialecto (por ejemplo, "Cantata del campesino") o en italiano (por ejemplo, "Amore traditore"). Muchas de las cantatas seculares se perdieron, pero para algunas de ellas el texto y la ocasión son conocidos, por ejemplo, cuando Picander publicó más tarde su libreto (por ejemplo, las "BWV Anh. 11-12"). Algunas de las cantatas seculares tenían una trama llevada por figuras mitológicas de la antigüedad griega (por ejemplo, "Der Streit zwischen Phoebus und Pan"), otras eran bufas casi en miniatura (por ejemplo la [[Schweigt stille, plaudert nicht, BWV 211|"Cantata del café"]]).

La música a capella de Bach incluye motetes y armonizaciones corales.

Los motetes de Bach (BWV 225-231) son piezas sobre temas sagrados para coro y continuo, con instrumentos que tocan algunas partes. Varios de ellos fueron compuestos para funerales. Los seis motetes ciertamente compuestos por Bach son "Singet dem Herrn ein neues Lied, Der Geist hilft unser Schwachheit auf, Jesu, meine Freude, Fürchte dich nicht, Komm, Jesu, komm" y "Lobet den Herrn, alle Heiden". El motete "Sei Lob und Preis mit Ehren" (BWV 231) es parte del motete compuesto "Jauchzet dem Herrn, alle Welt" (BWV Anh. 160), otras partes del cual pueden basarse en el trabajo de Telemann.

Bach escribió cientos de armonizaciones de corales luteranos.

La música de la iglesia de Bach en latín incluye su "Magnificat", cuatro misas Kyrie-Gloria y su "misa en si menor".

Magníficat

La primera versión del "Magnificat" de Bach data de 1723, pero el trabajo es mejor conocido en su versión de 1733.

Misa en si menor

En 1733 Bach compuso una misa Kyrie-Gloria para la corte de Dresde. Cerca del final de su vida, alrededor de 1748-1749 expandió esta composición a la Misa en Si menor a gran escala. El trabajo nunca se interpretó en su totalidad durante la vida de Bach.

De la música instrumental de Bach se conservan 227 piezas para [[Órgano (instrumento musical)|órgano]], 189 piezas para [[clavicémbalo]], 20 para instrumentos a solo, 16 de cámara, 30 orquestales y 18 especulativas. En total, son 494 las obras instrumentales completas. Están compuestas para una amplia gama de instrumentos de su época, incluso algunos experimentales, como el [[laúd-clave]], aunque especialmente significativos son el órgano, el [[Clave (instrumento musical de teclado)|clavecín]] y el [[violín]].

[[Archivo:Frontespizio Cello Suite.png|thumb|249x249px|Portada de la copia de las suites de cello de [[Anna Magdalena Bach]].|izquierda]]
De su música instrumental sólo los corales para órgano están destinados a su uso en la iglesia. Mucha de ella, especialmente la destinada al teclado, es de carácter didáctico, con frecuencia escritas para el aprendizaje de su hijo [[Wilhelm Friedemann Bach]]. Entre las didácticas destacan "[[El clave bien temperado]]" y las series de suites inglesas y francesas.

El órgano y el clavecín ocupan un papel central en la obra de Bach con más de 400 obras destinadas a ellos, aparte de ser el sostén como [[bajo continuo]] de las obras orquestales, las cantatas, las misas, las pasiones y algunas obras de cámara (que solía dirigir desde el teclado). El clavecín adquiere un papel importante como solista en los conciertos para cuerdas y uno, dos, tres o cuatro teclados.

Su aporte a la literatura musical, avances técnicos y de interpretación, evolución e historia de estos dos instrumentos fue capital, ya que explotó al límite sus capacidades, investigó y mejoró su afinación, recursos y ejecución, y exploró las 24 [[Modo mayor|tonalidades mayores]] y [[Modo menor|menores]] en "[[El clave bien temperado]]", BWV 846-893. Entre sus obras didácticas para clave están las [[Invenciones y sinfonías, BWV 772-801|"Invenciones a dos voces" y las "Sinfonías a tres voces"]].

Entre la música organística de Bach hay que destacar también sus [[preludio coral|preludios corales]], unos 170 aproximadamente. La antología "Orgelbüchlein" ("Pequeño libro para órgano"), que él mismo recopiló en Weimar y en Köthen, comprende breves preludios corales, que muchas veces destinaba a fines educativos. De hecho, tras el título de la "Orgelbüchlein" dice que este «pequeño libro para órgano, en el que se imparte al organista principalmente enseñanza sobre toda suerte de maneras de desarrollar un coral y también para mejorar su técnica del [[Pedalero|pedal]], puesto que en estos corales el pedal está tratado por completo en "[[obbligato]]" (es decir, esencial, no optativo)».

Durante su estancia en Leipzig compiló tres antologías corales para órgano: los seis "[[Corales Schübler]]", que son transcripciones de movimientos de cantata, y dieciocho corales, que revisó entre 1747 y 1749 y que fueron compuestos en épocas anteriores. Todos ellos incluyen composiciones para órgano, como variaciones, fugas, fantasías, tríos y diversos preludios corales.

Bach escribió muchas obras para clave. Las obras más grandes generalmente están destinadas a un clavicémbalo con dos teclados, mientras que interpretarlas en un instrumento con un solo teclado (como un piano) puede proporcionar dificultades técnicas para el cruce de manos. Muchas de sus obras para teclado son antologías que abarcan sistemas teóricos completos de forma enciclopédica.

Desde que en los años 1930 la gran pianista [[Rosalyn Tureck]] comenzara a interpretar estas obras al piano se ha generalizado la interpretación en este instrumento, quizás debido a la riqueza tímbrica y armónica de las obras y la variedad de expresión de las interpretaciones de los grandes pianistas que las han abordado. Aparte de las de Tureck se consideran versiones de referencia de estas obras al piano las de [[Glenn Gould]], [[András Schiff]] y [[Murray Perahia]].

El clave bien temperado, Libros 1 y 2 (BWV 846-893)

Cada libro consta de un preludio y una fuga en cada una de las 24 tonalidades mayores y menores en orden cromático, desde el Do mayor al Do menor (por lo tanto, toda la colección a menudo se conoce como "Los 48"). "Bien temperado" en el título se refiere al temperamento (sistema de afinación); muchos temperamentos antes de la época de Bach no eran lo suficientemente flexibles como para permitir que las composiciones utilizaran más que unas pocas teclas.

Las invenciones y las sinfonías (BWV 772-801)

Estas obras cortas de contrapunto de dos y tres partes están dispuestas en el mismo orden cromático que el "Clave bien temperado", omitiendo algunas de las teclas más raras. Estas piezas fueron diseñadas por Bach con fines educativos.

Las Suites inglesas (BWV 806-811), las Suites francesas (BWV 812-817) y las Partitas para teclado (Clavier-Übung I, BWV 825-830)

Cada colección contiene seis suites construidas sobre el modelo estándar ([[Alemanda|Allemande]]-[[Courante]]-[[Zarabanda|Sarabande]]- (movimiento opcional) -Giga). "[[Suites inglesas|Las Suites inglesas]]" siguen de cerca el modelo tradicional, agregando un preludio antes de la allemande e incluyendo un solo movimiento entre la sarabande y la giga. Las "[[Suites francesas]]" omiten preludios, pero tienen múltiples movimientos entre la sarabande y la giga. Las [[Partitas para teclado (Bach)|"Partitas"]] amplían aún más el modelo con movimientos introductorios elaborados y movimientos misceláneos entre los elementos básicos del modelo.

Las variaciones de Goldberg (BWV 988), un aria con treinta variaciones

La colección tiene una estructura compleja y poco convencional: las variaciones se basan en la línea de bajo del aria, en lugar de su melodía, y los cánones musicales se interpolan según un gran plan. Hay nueve cánones dentro de las treinta variaciones, cada tercera variación es un canon. Estas variaciones se mueven en orden desde el canon al unísono al canon en la novena. Los primeros ocho están en pares (unísono y octava, segundo y séptimo, tercero y sexto, cuarto y quinto). El noveno canon se sostiene por sí mismo debido a diferencias de composición. La variación final, en lugar de ser el canon esperado en el décimo, es una variación libre.

Piezas diversas para clave

Son obras como la "Obertura en el estilo francés (Obertura francesa, BWV 831)" y el "Concierto italiano (BWV 971)" (publicadas conjuntamente como "Clavier-Übung II"), y la "Fantasía y fuga cromática (BWV 903)"

Entre las obras de teclado menos conocidas de Bach hay "Siete toccatas (BWV 910-916)", "Cuatro dúos (BWV 802-805)", "Sonatas para teclado (BWV 963-967)", los "Seis Pequeños Preludios" (BWV 933-938) y la "Aria variata. alla maniera italiana (BWV 989)"

Bach era el más conocido durante su vida como organista, probador de órganos, y compositor de obras para órgano, tanto en géneros como preludios, fantasías, tocatas y preludios corales y fugas. De joven, se estableció una gran reputación por su creatividad y la capacidad de integrar estilos extraños en sus obras para órgano. Una influencia alemana del norte fue ejercida por [[Georg Böhm|Georg Bohm]], con quien Bach entró en contacto en [[Luneburgo|Lüneburg]], y [[Dietrich Buxtehude|Buxtehude]], a quien el joven organista visitó en [[Lübeck]] en 1704 en una situación de excedencia de su trabajo en Arnstadt. Alrededor de este época, Bach copió las obras de numerosos compositores franceses e italianos para hacerse una idea de sus lenguages de composición, y más tarde organizó interpretaciones de los conciertos para violín de [[Antonio Vivaldi|Vivaldi]] y otros para órgano y clave. Durante su período más productivo (1708-1714) compuso una docena de pares de preludios y fugas, cinco Tocatas y fugas, y el "Pequeño libro de órgano", una colección sin terminar de cuarenta y seis preludios corales cortos que muestra las técnicas de composición en el contexto de melodías corales. Después de salir de Weimar, Bach escribió menos para órgano, aunque algunas de sus obras más conocidas, las [[Seis sonatas a trío para órgano, BWV 525-530|"Seis sonatas en trío"]], la "Misa de órganos alemana" las compuso a partir de 1739, y las "Dieciocho corales", revisadas ​​al final de su vida también fueron compuestas después de dejar el Weimar. Bach se dedica más tarde a la consulta sobre los proyectos de órganos, poniendo a prueba los órganos de nueva construcción, e dando recitales de órgano en conciertos de tarde. Las "Variaciones canónicas sobre "Vom Himmel Hoch da Komm Ich her"" y las "[[Corales Schübler]]" son obras para órgano de Bach publicadas en los últimos años de su vida.

Bach conocía bien los [[Instrumento de cuerda|instrumentos de cuerda]], base de la orquesta barroca —cuya música solía escribirse para dos grupos de violines, uno de violas y un bajo continuo que solía incluir [[violonchelo]] y [[contrabajo]]—. Escribió repertorio para violín solista (sonatas y partitas) y violonchelo (suites), aún hoy plenamente vigentes y de alta dificultad técnica. Escribió sonatas para un instrumento en solitario, como la viola de gamba, acompañado de clavecín o continuo, así como sonatas trío (dos instrumentos y continuo).

El conjunto de sus "seis [[Sonatas y partitas para violín solo, BWV 1001-1006|Sonatas y partitas para violín solo]]" "(BWV 1001-1006)" consta de tres sonatas da chiesa en cuatro movimientos y tres partitas con movimientos de baile. 

El conjunto se completó en 1720, pero solo fue publicado en 1802 por Nikolaus Simrock en Bonn. Incluso después de la publicación, se ignoró en gran medida hasta que el célebre violinista [[Joseph Joachim]] comenzó a interpretar estas obras. Actualmente, las "Sonatas y Partitas" de Bach son una parte esencial del repertorio de violín, y se interpretan y graban con frecuencia.

Bach las tituló "Sei Solo a Violino senza Basso accompagnato (Seis Solos para violín sin acompañamiento de bajo)". Estas obras consolidaron firmemente la capacidad técnica del violín como instrumento solista ya establecida por [[Heinrich Ignaz Biber|Heinrich Ignaz Franz Biber]] y los virtuosos italianos del instrumento como [[Giuseppe Torelli]], [[Nicola Matteis]] y [[Arcangelo Corelli]]. Las piezas a menudo sirvieron como arquetipos para piezas de violín solo por generaciones posteriores de compositores, incluyendo a [[Eugène Ysaÿe]] y [[Béla Bartók]]. De entre las versiones modernas se suelen considerar de referencia las de [[Arthur Grumiaux]] y [[Hilary Hahn|Hillary Hahn]].

Sus seis [[Suites para violonchelo solo (Bach)|"Suites para cello (BWV 1007-1012)"]], están ampliamente consideradas como las más profundas del repertorio. Fueron redescubiertas para el público en 1925 por [[Pau Casals]] que, a los 48 años, después de años de estudio las interpretó en público por primera vez y se convirtió en el primero en hacer una grabación de las mismas. Su popularidad creció constantemente desde entonces.​​ Hoy en día, tras la recuperación por parte de Casals, las suites son una de las mayores obras para violonchelo y casi cada violonchelista aspira a tocarlas de la mejor manera posible.​ Los intérpretes más conocidos de este instrumento como [[Mstislav Rostropovich]], [[Emanuel Feuermann]], [[Pierre Fournier]], [[Jacqueline du Pré]], [[Paul Tortelier]], [[André Navarra]], [[Yo-Yo Ma]], [[Gregor Piatigorsky]], [[Mischa Maisky]], [[Janos Starker]], [[Anner Bijlsma]], [[Heinrich Schiff]], [[Pieter Wispelwey]], Mario Brunello y [[Carlos Prieto Jacqué|Carlos Prieto]] han hecho grabaciones de las mismas.

Bach escribió para instrumentos individuales, dúos y conjuntos pequeños. "[[Ofrenda musical, BWV 1079|La Ofrenda musical]]" y "[[El arte de la fuga, BWV 1080|El arte de la fuga]]" son obras contrapuntistas tardías que contienen piezas para combinaciones de instrumentos no especificados. "El arte de la fuga" es una obra que se corresponde muy bien con la concepción contemporánea de la música y por ello ha pasado de ser interpretada por conjuntos barrocos, hoy día todos con instrumentos de época, a ser una parte del repertorio de los principales cuartetos de cuerda. También se interpreta frecuentemente al piano, donde puede apreciarse el carácter trascendente de la composición.

Las obras sobrevivientes en la forma de concierto incluyen dos "conciertos para violín (BWV 1041 en A menor y BWV 1042 en mi mayor)" y un "[[Concierto para dos violines, BWV 1043|Concierto para dos violines en re menor, BWV 1043]]", a menudo denominado concierto "doble" de Bach. Este concierto tiene la particularidad de que la parte del segundo violín es más virtuosística que la del primer solista, lo que hace que los grandes solistas no tengan inconveniente en colaborar y quizá ha contribuido a su popularidad entre el público.

Las obras orquestales más conocidas de Bach son los "[[Conciertos de Brandeburgo|Conciertos de Brandenburgo]]", llamados así porque los presentó con la esperanza de obtener empleo del Margrave Christian Ludwig de Brandenburg-Schwedt en 1721; su solicitud no tuvo éxito. Estas obras son ejemplos del género [[Concerto grosso]].

Bach compuso y transcribió conciertos para de uno a cuatro clavecines. Muchos de los conciertos de clave no eran obras originales, pero se perdieron los arreglos de sus conciertos para otros instrumentos. Varios conciertos de violín, oboe y flauta han sido reconstruidos a partir de estos conciertos para clave.

Además de los conciertos, Bach escribió cuatro "[[Suites para orquesta (Bach)|Suites orquestales]]", cada suite es una serie de bailes estilizados para orquesta, precedida por una obertura francesa.

[[Archivo:Johann Sebastian Bach-Denkmal.JPG|thumb|Estatua de Johann Sebastian Bach en Leipzig.]]

Bach tuvo numerosos alumnos y estudiantes a lo largo de su vida; según el estudioso Hans Löffler, más de ochenta. Entre ellos se cuenta [[Johann Christoph Altnickol]], yerno suyo, que en los últimos años del maestro fue copista de sus obras, además de ayudarlo en la redacción de sus últimas composiciones, como en el caso de uno de sus últimos corales para órgano, el "[[BWV 668]]", el último coral del "[[Dieciocho grandes preludios corales|Ciclo de Leipzig BWV 651-668]]".

Ya en su vejez, cuando la gente se refería al apellido Bach lo hacía pensando en su famoso hijo [[Carl Philipp Emanuel Bach|Carl Phillip]]. En las generaciones posteriores a Bach, sólo algunos compositores y músicos conocían su obra. Básicamente eran sus hijos y sus alumnos. Gracias a ellos se conservó y no cayó en el olvido, mientras que el resto del mundo no tardaría muchos años en olvidarlo después de su muerte, en plena mitad del siglo XVIII.

[[Archivo:Mizler1754p158-BachNekrologFirstPage.pdf|thumb|Primera página del obituario de Bach realizado por [[Carl Philipp Emanuel Bach]] y [[Johann Friedrich Agricola]], publicado en la "Musikalische Bibliothek" de Mizler, parte 1 del volumen 4 ([[1754]]). A pesar de los errores contenidos en el documento, este obituario de menos de 20 páginas es posiblemente la fuente "más rica y fiable" de Bach producida antes del siglo XIX .]]
Lorenz Christoph Mizler, un antiguo alumno, publicó un detallado obituario de Bach (sin atribución) en 1754, cuatro años después de su muerte, en "Musikalische Bibliothek", un periódico musical. El obituario sigue siendo probablemente «la más rica y confiable» de las primeras fuentes documentales sobre el compositor. Después de su muerte, la reputación de Bach como compositor declinó en un primer momento; su obra se consideraba pasada de moda en comparación con el emergente estilo [[Música del Clasicismo|clásico]]. Inicialmente, era más recordado como intérprete y profesor.

Durante finales del y comienzos del , Bach era ampliamente reconocido por su obra para teclado. Músicos célebres, como [[Joseph Haydn]], [[Wolfgang Amadeus Mozart]], [[Ludwig van Beethoven]], [[Felix Mendelssohn]], [[Robert Schumann]] o [[Frédéric Chopin]] estaban entre sus más destacados admiradores y tuvieron un gran aprecio por las obras que conocieron de Bach; comenzaron escribiendo en un estilo más contrapuntístico después de conocer la música de Bach. Beethoven, sin conocer la totalidad de su obra, lo describió como el «"Urvater der Harmonie"» («Padre original de la armonía»). También lo definió con un juego de palabras en [[idioma alemán|alemán]]: «"Nicht Bach, sondern Meer sollte er heissen"», cuya traducción es «No debiera llamarse "Bach" ('[[arroyo]]', en alemán), sino "Meer" ('[[mar]]')».

La reputación de Bach entre el público en general mejoró en parte gracias a la biografía del compositor que realizó [[Johann Nikolaus Forkel]] en 1802. Felix Mendelssohn contribuyó de manera significativa en la recuperación de la reputación de Bach con su representación de la "[[BWV 244|Pasión según San Mateo]]" el 11 de marzo de 1829 en Berlín. Este hecho es destacado, ya que se trataba de música muy antigua para su época. En la actualidad, se acostumbra interpretar obras de otros siglos, mientras que en el período [[Música del Romanticismo|romántico]] no era habitual. En 1850 se fundó la "[[Bach Gesellschaft]]" (Sociedad Bach) para promover las obras del compositor; en 1899, la Sociedad publicó una edición completa de las obras del compositor con poca intervención editorial. En 1900 se fundó la "[[Neue Bachgesellschaft]]" una vez que la antigua sociedad cumplió su meta. En 1838 se reinterpretaron por primera vez las suites BWV 1066-1069.

Durante el , el proceso de reconocimiento tanto musical como del valor pedagógico de algunas de sus obras continuó, quizás más notablemente en la promoción de sus "[[Suites para violonchelo solo]]" por parte de [[Pau Casals]], el primer artista importante que grabó dichas suites. Otra novedad ha sido el crecimiento del movimiento «auténtico» o «[[interpretación historicista]]», que intenta presentar la música como la entendía el compositor originalmente. Como ejemplos, se incluyen la interpretación de las obras para teclado con un clave en lugar de con un piano moderno, el uso de pequeños coros o voces solistas en lugar de grandes elencos al estilo de los preferidos por los intérpretes en el y comienzos del XX, como también las grabaciones de la música integral de órgano en instrumentos del periodo barroco que realizó [[Marie-Claire Alain]], quien también se dedicó a estudiar en profundidad la obra de Bach para interpretarla con los estándares barrocos de su tiempo.

Su música sirvió de influencia para muchos compositores del , entre ellos [[Astor Piazzolla]], quien empleó el contrapunto y la fuga, o [[Brian Wilson]] (de [[The Beach Boys]]), que se inspiró en la música coral de Bach para componer "[[Pet Sounds]]" (1966), un álbum caratulado de "[[pop barroco]]".

La música de Bach es comparada con frecuencia con la «original genialidad» de la literatura de [[William Shakespeare]] y las enseñanzas de [[Isaac Newton]].

[[Archivo:Altes Bachdenkmal (Leipzig) - Holzstich.jpg|thumb|Imagen del [[monumento a Bach]] que Felix Mendelssohn había erigido en Leipzig en 1843.]]
La falta de material impreso impidió una mayor difusión de su obra. Sólo se publicaron tiradas muy reducidas de algunas obras instrumentales para órgano y clave. Muchas de sus obras fueron compuestas para eventos determinados; por lo tanto, fueron interpretadas sólo una o dos veces y no se le ocurría que podría interesarle a alguien escucharlas otra vez. Por eso no se preocupaba por publicarlas.

De la única pieza que existían muchas copias manuscritas era de "El clave bien temperado". Incluso Beethoven tenía una copia a los once años. Mozart lo conocía por haber escuchado hablar de su obra, pero nunca había visto nada suyo impreso. Una vez que escuchó un coro que lo cantaba quedó tan impresionado que pidió ver sus partituras, pero éstas no existían.

En 1844 se hizo la primera interpretación moderna del "Oratorio de Navidad" BWV 248. En 1911 se halló una cantata inédita que se cataloga como "[[BWV 199]]". En 1924 se descubrió un fragmento de cantata, catalogada como "[[BWV 200]]". En 1985 se encontró un manuscrito en [[Halle (Sajonia-Anhalt)|Halle]] que contenía los corales BWV 1090-1120, inéditos hasta entonces. En 2005 se halló un manuscrito que contiene un aria vocal enumerada como BWV 1127.

En 2008 se hace en Berlín una reconstrucción moderna de su cabeza y rostro con técnicas de modelación por ordenador, dando una imagen de fidelidad muy aproximada a la real. Ese mismo año se encontró un manuscrito que contenía un coral para órgano inédito hasta la fecha.

[[Archivo:Deutsche Bundespost - Bedeutende Deutsche - Johann Sebastian Bach - 20 Pfennig.jpg|thumb|Sello postal de la [[República Federal de Alemania]] dedicado a Johann Sebastian Bach.]]
Johann Sebastian Bach es uno de los compositores más conocidos de la música barroca. Se ha utilizado su imagen en diversos formatos artísticos y de otra índole, como pósteres, caricaturas y postales. Se han emitido [[sello postal|sellos postales]] y otros documentos filatélicos y numismáticos en numerosos países del mundo, en muchos casos para conmemorar los aniversarios de su nacimiento y muerte. También se han acuñado monedas, medallas y medallones conmemorativos.

Aparece asimismo en diversos artículos de "[[merchandising]]", como relojes, objetos para fumar (como pipas, vitolas de puro o cajetillas de tabaco), tazas y jarras, muñecos de juguete, o caramelos y chocolatinas.

En Alemania, durante el , se nombraron muchas calles en su honor. Además, se erigieron estatuas y placas conmemorativas en diversos países del mundo, incluidos Alemania, Bélgica, Canadá, China, Finlandia, Francia, Países Bajos, Irlanda, España, Reino Unido y Estados Unidos. También se han realizado bustos y estatuillas con su imagen y aparece en las vidrieras de varias iglesias.

Su música ha sido incluida tres veces —más que ningún otro compositor— en el [[Disco de oro de las Voyager]], una grabación fonográfica que contiene un amplio conjunto de imágenes, sonidos comunes, lenguajes y música de la Tierra, enviada al espacio exterior con las [[Sonda espacial|sondas espaciales]] [[Voyager]].

El [[asteroide]] [[(1814) Bach]], descubierto el 9 de octubre de 1931 por [[Karl Wilhelm Reinmuth]], recibe su nombre en honor al compositor. Así mismo, el cráter de impacto en el planeta [[Mercurio (planeta)|Mercurio]] denominado «[[Bach (cráter)|cráter Bach]]» también lleva su nombre.

En su condición de autor de música religiosa, su nombre figura entre las celebraciones del [[Calendario de Santos Luterano]] y comparte fecha con [[Georg Friedrich Händel]] y [[Heinrich Schütz]]. Además, se le honra con un día festivo del [[Calendario de Santos (iglesia episcopal)|Calendario de Santos de la iglesia episcopal]]. Se celebra el 28 de julio y lo comparte con Händel y [[Henry Purcell]]. Bach y Händel también se conmemoran en el calendario de los santos preparado por la [[Order of Saint Luke]] para uso de la [[Iglesia metodista unida]].

[[Archivo:Bosehaus Leipzig Straßenfront 1.jpg|thumb|Bosehaus, [[Leipzig]], es donde el [[Bach-Archiv Leipzig]] ha estado desde [[1985]].]]
En [[1985]], cuando se cumplieron 300 años de su nacimiento, se editó el primer registro completo de todas las cantatas sacras, dirigido por [[Helmuth Rilling]]. La edición constaba de 69 [[cedés]] y fue realizada por el [[Sello discográfico|sello]] alemán [[Hänssler]]. En 1989 se terminó el ciclo comenzado en 1971 del registro de cantatas realizado por [[Gustav Leonhardt]] y [[Nikolaus Harnoncourt]] y se editó en 60 cedés del sello discográfico [[Teldec]]. Esta grabación fue revolucionaria, pues se aplicó la concepción histórica de la interpretación y se cambió ésta para siempre. En [[2000]] se celebraron los 250 años de su muerte y tres sellos discográficos ([[Brilliant Classics|Brilliant]], Hänssler y [[Teldec]]) publicaron ediciones conmemorativas con toda la música grabada del compositor alemán, en 155, 172 y 160 cedés, respectivamente. Además, durante ese año se celebraron innumerables actos de toda índole dedicados al estudio y divulgación del artista y su obra, especialmente en su Alemania natal.

Se ha mostrado al compositor biográficamente en numerosas ocasiones en el [[cine]], en el [[teatro]] y en la [[televisión]], como por ejemplo: "[[Crónicas de Ana Magdalena Bach]]" (1968), de [[Jean Marie Straub]] y [[Danièle Huillet]], "[[Johann Sebastian Bachs vergebliche Reise in den Ruhm]]" (1980) de [[Victor Vicas]], "Johann Sebastian Bach" (1983) de [[Lothar Bellag]], "[[Ein Denkmal für Johann Sebastian]]" (1984) de [[Peter Milinski]], "[[Mi nombre es Bach]]" (2003) de [[Dominique de Rivaz]] y "[[El silencio antes de Bach]]" (2007) de [[Pere Portabella]]. Además, se ha usado su música en más de 680 películas y programas de televisión.




[[Categoría:Johann Sebastian Bach| ]]
[[Categoría:Clavecinistas de Alemania]]
[[Categoría:Compositores de Alemania del siglo XVIII]]
[[Categoría:Compositores del Barroco de Alemania]]
[[Categoría:Maestros de capilla]]
[[Categoría:Organistas de Alemania]]
[[Categoría:Protestantes de Alemania]]
[[Categoría:Escuelas alemanas de órgano]]
[[Categoría:Familia Bach|Johann Sebastian]]
[[Categoría:Músicos de Alemania del siglo XVIII]]
[[Categoría:Organistas clásicos]]
[[Categoría:Intérpretes de música clásica de Alemania]]

</doc>
<doc id="1593" url="https://es.wikipedia.org/wiki?curid=1593" title="Núcleo (informática)">
Núcleo (informática)

En informática, un núcleo o kernel (de la raíz germánica "Kern", núcleo, hueso) es un "software" que constituye una parte fundamental del sistema operativo, y se define como la parte que se ejecuta en modo privilegiado (conocido también como modo núcleo). Es el principal responsable de facilitar a los distintos programas acceso seguro al "hardware" de la computadora o en forma básica, es el encargado de gestionar recursos, a través de servicios de llamada al sistema. Como hay muchos programas y el acceso al "hardware" es limitado, también se encarga de decidir qué programa podrá usar un dispositivo de hardware y durante cuánto tiempo, lo que se conoce como multiplexado. Acceder al hardware directamente puede ser realmente complejo, por lo que los núcleos suelen implementar una serie de abstracciones del "hardware". Esto permite esconder la complejidad, y proporcionar una interfaz limpia y uniforme al hardware subyacente, lo que facilita su uso al programador.

En algunos sistemas operativos, no existe un núcleo como tal (algo común en sistemas empotrados), debido a que en ciertas arquitecturas no hay distintos modos de ejecución.

Cuando se aplica voltaje al procesador de un dispositivo electrónico, éste ejecuta un reducido código en lenguaje ensamblador localizado en una dirección concreta en la memoria ROM (dirección de "reset") y conocido como "reset code", que a su vez ejecuta una rutina con la que se inicializa el hardware que acompaña al procesador. También en esta fase suele inicializarse el controlador de las interrupciones. Finalizada esta fase se ejecuta el código de arranque ("startup code"), también código en lenguaje ensamblador, cuya tarea más importante es ejecutar el programa principal ("main()") del software de la aplicación.

También puede aplicarse en el caso del sistema operativo IOS.

En informática, los ordenadores son el núcleo del programa informático que se asegura de:

La mayoría de las interfaces de usuario se construyen en torno al concepto de núcleo. La existencia de un núcleo, es decir, de un único programa responsable de la comunicación entre el "hardware" y el programa informático, resulta de compromisos complejos referentes a cuestiones de resultados, seguridad y arquitectura de los procesadores. El núcleo tiene grandes poderes sobre la utilización de los recursos materiales ("hardware"), en particular, de la memoria. 

Los núcleos tienen como funciones básicas garantizar la carga y la ejecución de los procesos, las entradas/salidas y proponer una interfaz entre el espacio núcleo y los programas del espacio del usuario.

Aparte de las funcionalidades básicas, el conjunto de las funciones de los puntos siguientes (incluidos los pilotos materiales, las funciones de redes y sistemas de ficheros o los servicios) necesariamente no son proporcionados por un núcleo de sistema de explotación. Pueden establecerse estas funciones del sistema de explotación tanto en el espacio usuario como en el propio núcleo. Su implantación en el núcleo se hace con el único objetivo de mejorar los resultados. En efecto, según la concepción del núcleo, la misma función llamada desde el espacio usuario o el espacio núcleo tiene un coste temporal obviamente diferente. Si esta llamada de funciones es frecuente, puede resultar útil integrar estas funciones al núcleo para mejorar los resultados.

Un núcleo Unix es un programa escrito casi en su totalidad en lenguaje C, con excepción de una parte del manejo de interrupciones, expresada en el lenguaje ensamblador del procesador en el que opera. Las funciones del núcleo son permitir la existencia de un ambiente en el que sea posible atender a varios usuarios y múltiples tareas en forma concurrente, repartiendo al procesador entre todos ellos, e intentando mantener en grado óptimo la atención individual.

El núcleo opera como asignador de recursos para cualquier proceso que necesite utilizar las facilidades de cómputo. 
Sus funciones principales son:


Reside siempre en la memoria principal y tiene el control sobre la computadora, por lo que ningún otro proceso puede interrumpirlo; sólo pueden llamarlo para que proporcione algún servicio de los ya mencionados. Un proceso llama al núcleo mediante módulos especiales conocidos como llamadas al sistema.

Consta de dos partes principales: la sección de control de procesos y la de control de dispositivos. La primera asigna recursos, programas, procesos y atiende sus requerimientos de servicio; la segunda, supervisa la transferencia de datos entre la memoria principal y los dispositivos del ordenador. En términos generales, cada vez que algún usuario oprime una tecla de una terminal, o que se debe leer o escribir información del disco magnético, se interrumpe al procesador central y el núcleo se encarga de efectuar la operación de transferencia. 

Cuando se inicia la operación de la computadora, debe cargarse en la memoria una copia del núcleo, que reside en el disco magnético (operación denominada bootstrap). Para ello, se deben inicializar algunas interfaces básicas de hardware; entre ellas, el reloj que proporciona interrupciones periódicas. El núcleo también prepara algunas estructuras de datos que abarcan una sección de almacenamiento temporal para transferencia de información entre terminales y procesos, una sección para almacenamiento de descriptores de archivos y una variable que indica la cantidad de memoria principal. 

A continuación, el núcleo inicializa un proceso especial, llamado proceso 0. En Unix, los procesos se crean mediante una llamada a una rutina del sistema (fork), que funciona por un mecanismo de duplicación de procesos. Sin embargo, esto no es suficiente para crear el primero de ellos, por lo que el núcleo asigna una estructura de datos y establece apuntadores a una sección especial de la memoria, llamada tabla de procesos, que contendrá los descriptores de cada uno de los procesos existentes en el sistema. 

Después de haber creado el proceso cero, se hace una copia del mismo, con lo que se crea el proceso uno; éste muy pronto se encargará de "dar vida" al sistema completo, mediante la activación de otros procesos que también forman parte del núcleo. Es decir, se inicia una cadena de activaciones de procesos, entre los cuales destaca el conocido como despachador, o planificador, que es el responsable de decidir cuál proceso se ejecutará y cuáles van a entrar o salir de la memoria central. A partir de ese momento se conoce el número uno como proceso de inicialización del sistema, "init". 

El proceso "init" es el responsable de establecer la estructura de procesos en Unix. Normalmente, es capaz de crear al menos dos estructuras distintas de procesos: el modo monousuario y el multiusuario. Comienza activando el intérprete del lenguaje de control "shell" de Unix en la terminal principal, o consola del sistema, proporcionándole privilegios de superusuario. En la modalidad de un solo usuario la consola permite iniciar una primera sesión, con privilegios especiales, e impide que las otras líneas de comunicación acepten iniciar sesiones nuevas. Esta modalidad se usa con frecuencia para revisar y reparar sistemas de archivos, realizar pruebas de funciones básicas del sistema y para otras actividades que requieren uso exclusivo de la computadora. 

Init crea otro proceso, que espera a que alguien entre en sesión en alguna línea de comunicación. Cuando esto sucede, realiza ajustes en el protocolo de la línea y ejecuta el programa login, que se encarga de atender inicialmente a los nuevos usuarios. Si el nombre de usuario y la contraseña proporcionadas son correctos, entonces entra en operación el programa Shell, que en lo sucesivo se encargará de la atención normal del usuario que se dio de alta en esa terminal. 

A partir de ese momento el responsable de atender al usuario en esa terminal es el intérprete Shell. Cuando se desea terminar la sesión hay que desconectarse de Shell (y, por lo tanto, de Unix), mediante una secuencia especial de teclas (usualmente. < CTL > - D). A partir de ese momento la terminal queda disponible para atender a un nuevo usuario.

No necesariamente se necesita un núcleo para usar una computadora. Los programas pueden cargarse y ejecutarse directamente en una computadora "vacía", siempre que sus autores quieran desarrollarlos sin usar ninguna abstracción del "hardware" ni ninguna ayuda del sistema operativo. Esta era la forma normal de usar muchas de las primeras computadoras: para usar distintos programas se tenía que reiniciar y reconfigurar la computadora cada vez. Con el tiempo, se empezó a dejar en memoria (aún entre distintas ejecuciones) pequeños programas auxiliares, como el cargador y el depurador, o se cargaban desde memoria de sólo lectura. A medida que se fueron desarrollando, se convirtieron en los fundamentos de lo que llegarían a ser los primeros núcleos de sistema operativo.

Hay cuatro grandes tipos de núcleos:

El enfoque micronúcleo consiste en definir una abstracción muy simple sobre el hardware, con un conjunto de primitivas o llamadas al sistema que implementan servicios del sistema operativo mínimos, como la gestión de hilos, el espacio de direccionamiento y la comunicación entre procesos.

El objetivo principal es la separación de la implementación de los servicios básicos y de la política de funcionamiento del sistema. Por ejemplo, el proceso de bloqueo de E/S se puede implementar con un servidor en espacio de usuario ejecutándose encima del micronúcleo. Estos servidores de usuario, utilizados para gestionar las partes de alto nivel del sistema, son muy modulares y simplifican la estructura y diseño del núcleo. Si falla uno de estos servidores, no se colgará el sistema entero, y se podrá reiniciar este módulo independientemente del resto. Sin embargo, la existencia de diferentes módulos independientes origina retardos en la comunicación debido a la copia de variables que se realiza en la comunicación entre módulos.

Algunos ejemplos de micronúcleos:

Frecuentemente se prefieren los núcleos monolíticos frente a los micronúcleos debido al menor nivel de complejidad que comporta el tratar con todo el código de control del sistema en un solo espacio de direccionamiento. Por ejemplo, XNU, el núcleo de Mac OS X, está basado en el núcleo Mach 3.0 y en FreeBSD, en el mismo espacio de direccionamiento para disminuir la latencia que comporta el diseño de micronúcleo convencional.

A principios de los años 90, los núcleos monolíticos se consideraban obsoletos. El diseño de Linux como un núcleo monolítico en lugar de como un micronúcleo fue el tema de una famosa disputa entre Linus Torvalds y Andrew Tanenbaum. Los argumentos de ambas partes en esta discusión presentan algunas motivaciones interesantes.

Los núcleos monolíticos suelen ser más fáciles de diseñar correctamente, y por lo tanto pueden crecer más rápidamente que un sistema basado en micronúcleo, pero hay casos de éxito en ambos bandos. Los micronúcleos suelen usarse en robótica embebida o computadoras médicas, ya que la mayoría de los componentes del sistema operativo residen en su propio espacio de memoria privado y protegido. Esto no sería posible con los núcleos monolíticos, ni siquiera con los modernos que permiten cargar módulos del núcleo.

Aunque Mach es el micronúcleo generalista más conocido, se han desarrollado otros micronúcleos con propósitos más específicos. L3 fue creado para demostrar que los micronúcleos no son necesariamente lentos. La familia de micronúcleos L4 es la descendiente de L3, y una de sus últimas implementaciones, llamada Pistachio, permite ejecutar Linux simultáneamente con otros procesos, en espacios de direccionamiento separados.

QNX es un sistema operativo que ha estado disponible desde principios de los años 80, y tiene un diseño de micronúcleo muy minimalista. Este sistema ha conseguido llegar a las metas del paradigma del micronúcleo con mucho más éxito que Mach. Se usa en situaciones en que no se puede permitir que haya fallos de "software", lo que incluye desde brazos robóticos en naves espaciales, hasta máquinas que pulen cristal donde un pequeño error podría costar mucho dinero.

Mucha gente cree que como Mach básicamente falló en el intento de resolver el conjunto de problemas que los micronúcleos intentaban subsanar, toda la tecnología de micronúcleos es inútil. Los partidarios de Mach afirman que ésta es una actitud estrecha de miras que ha llegado a ser lo suficientemente popular para que mucha gente la acepte como verdad.

Los núcleos híbridos fundamentalmente son micronúcleos que tienen algo de código «no esencial» en espacio de núcleo para que éste se ejecute más rápido de lo que lo haría si estuviera en espacio de usuario. Este fue un compromiso que muchos desarrolladores de los primeros sistemas operativos con arquitectura basada en micronúcleo adoptaron antes que se demostrara que los micronúcleos pueden tener muy buen rendimiento. La mayoría de sistemas operativos modernos pertenecen a esta categoría, siendo el más popular Microsoft Windows. XNU, el núcleo de Mac OS X, también es un micronúcleo modificado, debido a la inclusión de código del núcleo de FreeBSD en el núcleo basado en Mach. DragonFlyBSD es el primer sistema BSD que adopta una arquitectura de núcleo híbrido sin basarse en Mach.

Algunos ejemplos de núcleos híbridos:

Hay gente que confunde el término "núcleo híbrido" con los núcleos monolíticos que pueden cargar módulos después del arranque, lo que es un error. "Híbrido" implica que el núcleo en cuestión usa conceptos de arquitectura o mecanismos tanto del diseño monolítico como del micronúcleo, específicamente el paso de mensajes y la migración de código "no esencial" hacia el espacio de usuario, pero manteniendo cierto código "no esencial" en el propio núcleo por razones de rendimiento.

Los exonúcleos, también conocidos como sistemas operativos verticalmente estructurados, representan una aproximación radicalmente nueva al diseño de sistemas operativos.

La idea subyacente es permitir que el desarrollador tome todas las decisiones relativas al rendimiento del "hardware". Los exonúcleos son extremadamente pequeños, ya que limitan expresamente su funcionalidad a la protección y el multiplexado de los recursos. Se llaman así porque toda la funcionalidad deja de estar residente en memoria y pasa a estar fuera, en bibliotecas dinámicas.

Los diseños de núcleos clásicos (tanto el monolítico como el micronúcleo) abstraen el hardware, escondiendo los recursos bajo una capa de abstracción del "hardware", o detrás de los controladores de dispositivo. En los sistemas clásicos, si se asigna memoria física, nadie puede estar seguro de cuál es su localización real, por ejemplo.

La finalidad de un exonúcleo es permitir a una aplicación que solicite una región específica de la memoria, un bloque de disco concreto, etc., y simplemente asegurarse que los recursos pedidos están disponibles, y que el programa tiene derecho a acceder a ellos.

Debido a que el exonúcleo sólo proporciona una interfaz al hardware de muy bajo nivel, careciendo de todas las funcionalidades de alto nivel de otros sistemas operativos, éste es complementado por una "biblioteca de sistema operativo". Esta biblioteca se comunica con el exonúcleo subyacente, y facilita a los programadores de aplicaciones las funcionalidades que son comunes en otros sistemas operativos.

Algunas de las implicaciones teóricas de un sistema exonúcleo son que es posible tener distintos tipos de sistemas operativos (p. e. Windows, Unix) ejecutándose en un solo exonúcleo, y que los desarrolladores pueden elegir prescindir ó incrementar funcionalidades por motivos de rendimiento.

Actualmente, los diseños exonúcleo están fundamentalmente en fase de estudio y no se usan en ningún sistema popular. Un concepto de sistema operativo es Nemesis, creado por la Universidad de Cambridge, la Universidad de Glasgow, Citrix Systems y el Instituto Sueco de Informática. El MIT también ha diseñado algunos sistemas basados en exonúcleos.
Los exonúcleos se manejan en diferente estructura dado que también cumplen funciones distintas




</doc>
